{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 14, 14, 32)        320       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_1 (LeakyReLU)    (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 7, 7, 64)          18496     \n",
      "_________________________________________________________________\n",
      "zero_padding2d_1 (ZeroPaddin (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 8, 8, 64)          256       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_2 (LeakyReLU)    (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 4, 4, 128)         73856     \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 4, 4, 128)         512       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_3 (LeakyReLU)    (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 4, 4, 256)         295168    \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 4, 4, 256)         1024      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_4 (LeakyReLU)    (None, 4, 4, 256)         0         \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 4, 4, 256)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 4097      \n",
      "=================================================================\n",
      "Total params: 393,729\n",
      "Trainable params: 392,833\n",
      "Non-trainable params: 896\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_2 (Dense)              (None, 6272)              633472    \n",
      "_________________________________________________________________\n",
      "reshape_1 (Reshape)          (None, 7, 7, 128)         0         \n",
      "_________________________________________________________________\n",
      "up_sampling2d_1 (UpSampling2 (None, 14, 14, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 14, 14, 128)       147584    \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 14, 14, 128)       512       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 14, 14, 128)       0         \n",
      "_________________________________________________________________\n",
      "up_sampling2d_2 (UpSampling2 (None, 28, 28, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 28, 28, 64)        73792     \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 28, 28, 64)        256       \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 28, 28, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 28, 28, 1)         577       \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 28, 28, 1)         0         \n",
      "=================================================================\n",
      "Total params: 856,193\n",
      "Trainable params: 855,809\n",
      "Non-trainable params: 384\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/imi432_006/anaconda3/envs/tf/lib/python3.5/site-packages/keras/engine/training.py:490: UserWarning: Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?\n",
      "  'Discrepancy between trainable weights and collected trainable'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0 step:1 [D loss: 1.076746, acc.: 35.16%] [G loss: 1.242499]\n",
      "epoch:0 step:2 [D loss: 0.501441, acc.: 75.78%] [G loss: 1.628726]\n",
      "epoch:0 step:3 [D loss: 0.362110, acc.: 85.16%] [G loss: 2.269358]\n",
      "epoch:0 step:4 [D loss: 0.362636, acc.: 85.16%] [G loss: 2.107854]\n",
      "epoch:0 step:5 [D loss: 0.368652, acc.: 85.94%] [G loss: 1.867027]\n",
      "epoch:0 step:6 [D loss: 0.263538, acc.: 89.06%] [G loss: 1.976107]\n",
      "epoch:0 step:7 [D loss: 0.213480, acc.: 95.31%] [G loss: 1.763083]\n",
      "epoch:0 step:8 [D loss: 0.369741, acc.: 85.94%] [G loss: 1.252625]\n",
      "epoch:0 step:9 [D loss: 0.377612, acc.: 83.59%] [G loss: 1.541014]\n",
      "epoch:0 step:10 [D loss: 0.379740, acc.: 82.03%] [G loss: 1.668240]\n",
      "epoch:0 step:11 [D loss: 0.623777, acc.: 70.31%] [G loss: 1.823322]\n",
      "epoch:0 step:12 [D loss: 0.613963, acc.: 67.97%] [G loss: 1.782833]\n",
      "epoch:0 step:13 [D loss: 0.772434, acc.: 57.03%] [G loss: 1.759863]\n",
      "epoch:0 step:14 [D loss: 0.742470, acc.: 60.94%] [G loss: 1.451238]\n",
      "epoch:0 step:15 [D loss: 0.902387, acc.: 50.00%] [G loss: 1.450539]\n",
      "epoch:0 step:16 [D loss: 0.744448, acc.: 56.25%] [G loss: 1.749671]\n",
      "epoch:0 step:17 [D loss: 0.674915, acc.: 60.16%] [G loss: 2.018630]\n",
      "epoch:0 step:18 [D loss: 0.555378, acc.: 72.66%] [G loss: 2.211860]\n",
      "epoch:0 step:19 [D loss: 0.695308, acc.: 67.97%] [G loss: 1.807712]\n",
      "epoch:0 step:20 [D loss: 0.602129, acc.: 69.53%] [G loss: 1.409809]\n",
      "epoch:0 step:21 [D loss: 0.416598, acc.: 82.03%] [G loss: 0.783421]\n",
      "epoch:0 step:22 [D loss: 0.400798, acc.: 83.59%] [G loss: 0.696063]\n",
      "epoch:0 step:23 [D loss: 0.424779, acc.: 83.59%] [G loss: 0.605484]\n",
      "epoch:0 step:24 [D loss: 0.337485, acc.: 85.16%] [G loss: 0.551241]\n",
      "epoch:0 step:25 [D loss: 0.717067, acc.: 64.06%] [G loss: 1.001020]\n",
      "epoch:0 step:26 [D loss: 1.060905, acc.: 47.66%] [G loss: 1.104891]\n",
      "epoch:0 step:27 [D loss: 1.047775, acc.: 40.62%] [G loss: 2.273531]\n",
      "epoch:0 step:28 [D loss: 0.884316, acc.: 53.12%] [G loss: 2.304388]\n",
      "epoch:0 step:29 [D loss: 0.751096, acc.: 64.06%] [G loss: 2.000821]\n",
      "epoch:0 step:30 [D loss: 0.608105, acc.: 69.53%] [G loss: 1.421924]\n",
      "epoch:0 step:31 [D loss: 0.546067, acc.: 72.66%] [G loss: 2.019269]\n",
      "epoch:0 step:32 [D loss: 0.369872, acc.: 85.16%] [G loss: 2.967248]\n",
      "epoch:0 step:33 [D loss: 0.768520, acc.: 55.47%] [G loss: 3.109199]\n",
      "epoch:0 step:34 [D loss: 0.701192, acc.: 59.38%] [G loss: 2.568368]\n",
      "epoch:0 step:35 [D loss: 0.547878, acc.: 71.09%] [G loss: 2.003424]\n",
      "epoch:0 step:36 [D loss: 0.445021, acc.: 79.69%] [G loss: 1.492977]\n",
      "epoch:0 step:37 [D loss: 0.305426, acc.: 83.59%] [G loss: 1.406235]\n",
      "epoch:0 step:38 [D loss: 0.379421, acc.: 85.16%] [G loss: 1.310333]\n",
      "epoch:0 step:39 [D loss: 0.490041, acc.: 73.44%] [G loss: 1.354494]\n",
      "epoch:0 step:40 [D loss: 0.597612, acc.: 71.09%] [G loss: 1.663316]\n",
      "epoch:0 step:41 [D loss: 0.686741, acc.: 69.53%] [G loss: 1.963836]\n",
      "epoch:0 step:42 [D loss: 0.748420, acc.: 54.69%] [G loss: 1.838359]\n",
      "epoch:0 step:43 [D loss: 0.760571, acc.: 61.72%] [G loss: 1.501470]\n",
      "epoch:0 step:44 [D loss: 0.669627, acc.: 64.84%] [G loss: 1.292164]\n",
      "epoch:0 step:45 [D loss: 0.514624, acc.: 73.44%] [G loss: 1.060444]\n",
      "epoch:0 step:46 [D loss: 0.453057, acc.: 82.81%] [G loss: 0.968901]\n",
      "epoch:0 step:47 [D loss: 0.523521, acc.: 75.00%] [G loss: 0.810389]\n",
      "epoch:0 step:48 [D loss: 0.487626, acc.: 75.78%] [G loss: 0.915478]\n",
      "epoch:0 step:49 [D loss: 0.607155, acc.: 71.09%] [G loss: 1.468034]\n",
      "epoch:0 step:50 [D loss: 0.574508, acc.: 69.53%] [G loss: 2.347876]\n",
      "epoch:0 step:51 [D loss: 0.947453, acc.: 50.00%] [G loss: 2.190449]\n",
      "epoch:0 step:52 [D loss: 0.467670, acc.: 80.47%] [G loss: 2.100540]\n",
      "epoch:0 step:53 [D loss: 0.436233, acc.: 83.59%] [G loss: 1.282948]\n",
      "epoch:0 step:54 [D loss: 0.494320, acc.: 80.47%] [G loss: 1.124937]\n",
      "epoch:0 step:55 [D loss: 0.184266, acc.: 93.75%] [G loss: 1.089038]\n",
      "epoch:0 step:56 [D loss: 0.242280, acc.: 91.41%] [G loss: 0.773503]\n",
      "epoch:0 step:57 [D loss: 0.279745, acc.: 91.41%] [G loss: 0.800855]\n",
      "epoch:0 step:58 [D loss: 0.270616, acc.: 92.19%] [G loss: 0.704073]\n",
      "epoch:0 step:59 [D loss: 0.419939, acc.: 77.34%] [G loss: 1.088568]\n",
      "epoch:0 step:60 [D loss: 0.556544, acc.: 75.00%] [G loss: 1.343199]\n",
      "epoch:0 step:61 [D loss: 0.577735, acc.: 71.09%] [G loss: 1.263621]\n",
      "epoch:0 step:62 [D loss: 0.961514, acc.: 50.78%] [G loss: 1.671856]\n",
      "epoch:0 step:63 [D loss: 1.040830, acc.: 42.19%] [G loss: 1.667269]\n",
      "epoch:0 step:64 [D loss: 1.142471, acc.: 33.59%] [G loss: 1.579901]\n",
      "epoch:0 step:65 [D loss: 0.903774, acc.: 50.00%] [G loss: 1.589744]\n",
      "epoch:0 step:66 [D loss: 0.733160, acc.: 62.50%] [G loss: 1.663544]\n",
      "epoch:0 step:67 [D loss: 0.747956, acc.: 54.69%] [G loss: 1.536532]\n",
      "epoch:0 step:68 [D loss: 0.739573, acc.: 61.72%] [G loss: 1.882965]\n",
      "epoch:0 step:69 [D loss: 0.684218, acc.: 64.84%] [G loss: 2.244499]\n",
      "epoch:0 step:70 [D loss: 0.855467, acc.: 54.69%] [G loss: 1.560054]\n",
      "epoch:0 step:71 [D loss: 0.725838, acc.: 60.94%] [G loss: 1.578234]\n",
      "epoch:0 step:72 [D loss: 0.715727, acc.: 61.72%] [G loss: 1.038658]\n",
      "epoch:0 step:73 [D loss: 1.040972, acc.: 43.75%] [G loss: 1.416334]\n",
      "epoch:0 step:74 [D loss: 0.964517, acc.: 49.22%] [G loss: 1.287241]\n",
      "epoch:0 step:75 [D loss: 0.814245, acc.: 56.25%] [G loss: 1.571786]\n",
      "epoch:0 step:76 [D loss: 0.628232, acc.: 64.06%] [G loss: 1.619036]\n",
      "epoch:0 step:77 [D loss: 0.729467, acc.: 60.94%] [G loss: 1.335410]\n",
      "epoch:0 step:78 [D loss: 0.791918, acc.: 59.38%] [G loss: 1.370011]\n",
      "epoch:0 step:79 [D loss: 0.764773, acc.: 57.81%] [G loss: 1.506489]\n",
      "epoch:0 step:80 [D loss: 0.924479, acc.: 46.09%] [G loss: 1.557407]\n",
      "epoch:0 step:81 [D loss: 0.783086, acc.: 52.34%] [G loss: 1.235098]\n",
      "epoch:0 step:82 [D loss: 0.850738, acc.: 53.12%] [G loss: 1.397627]\n",
      "epoch:0 step:83 [D loss: 0.577943, acc.: 67.97%] [G loss: 1.552495]\n",
      "epoch:0 step:84 [D loss: 0.763163, acc.: 56.25%] [G loss: 1.104181]\n",
      "epoch:0 step:85 [D loss: 0.620974, acc.: 65.62%] [G loss: 1.312899]\n",
      "epoch:0 step:86 [D loss: 0.731639, acc.: 54.69%] [G loss: 1.251019]\n",
      "epoch:0 step:87 [D loss: 0.928403, acc.: 44.53%] [G loss: 1.058882]\n",
      "epoch:0 step:88 [D loss: 0.897878, acc.: 46.88%] [G loss: 1.116262]\n",
      "epoch:0 step:89 [D loss: 0.931900, acc.: 46.09%] [G loss: 1.228881]\n",
      "epoch:0 step:90 [D loss: 0.818065, acc.: 54.69%] [G loss: 1.302036]\n",
      "epoch:0 step:91 [D loss: 0.870672, acc.: 44.53%] [G loss: 1.177694]\n",
      "epoch:0 step:92 [D loss: 0.764892, acc.: 59.38%] [G loss: 1.681406]\n",
      "epoch:0 step:93 [D loss: 0.743742, acc.: 61.72%] [G loss: 1.307220]\n",
      "epoch:0 step:94 [D loss: 0.767909, acc.: 55.47%] [G loss: 1.343539]\n",
      "epoch:0 step:95 [D loss: 0.766828, acc.: 54.69%] [G loss: 1.086185]\n",
      "epoch:0 step:96 [D loss: 0.697865, acc.: 60.94%] [G loss: 1.387701]\n",
      "epoch:0 step:97 [D loss: 0.728519, acc.: 59.38%] [G loss: 1.316956]\n",
      "epoch:0 step:98 [D loss: 0.665546, acc.: 63.28%] [G loss: 1.066903]\n",
      "epoch:0 step:99 [D loss: 0.764248, acc.: 55.47%] [G loss: 1.211775]\n",
      "epoch:0 step:100 [D loss: 0.736081, acc.: 53.12%] [G loss: 1.345560]\n",
      "epoch:0 step:101 [D loss: 0.865547, acc.: 49.22%] [G loss: 1.429912]\n",
      "epoch:0 step:102 [D loss: 0.945316, acc.: 44.53%] [G loss: 1.351199]\n",
      "epoch:0 step:103 [D loss: 0.770768, acc.: 50.00%] [G loss: 1.372547]\n",
      "epoch:0 step:104 [D loss: 0.820233, acc.: 49.22%] [G loss: 1.443114]\n",
      "epoch:0 step:105 [D loss: 0.687563, acc.: 65.62%] [G loss: 1.548595]\n",
      "epoch:0 step:106 [D loss: 0.772452, acc.: 54.69%] [G loss: 1.251369]\n",
      "epoch:0 step:107 [D loss: 0.758658, acc.: 57.03%] [G loss: 1.276965]\n",
      "epoch:0 step:108 [D loss: 0.688260, acc.: 61.72%] [G loss: 1.276907]\n",
      "epoch:0 step:109 [D loss: 0.832183, acc.: 50.00%] [G loss: 1.535252]\n",
      "epoch:0 step:110 [D loss: 0.787029, acc.: 53.91%] [G loss: 1.320885]\n",
      "epoch:0 step:111 [D loss: 0.874161, acc.: 52.34%] [G loss: 1.229369]\n",
      "epoch:0 step:112 [D loss: 0.774776, acc.: 49.22%] [G loss: 1.112286]\n",
      "epoch:0 step:113 [D loss: 0.875311, acc.: 42.19%] [G loss: 1.276536]\n",
      "epoch:0 step:114 [D loss: 0.685199, acc.: 61.72%] [G loss: 1.248819]\n",
      "epoch:0 step:115 [D loss: 0.829256, acc.: 44.53%] [G loss: 1.421996]\n",
      "epoch:0 step:116 [D loss: 0.735324, acc.: 56.25%] [G loss: 1.116448]\n",
      "epoch:0 step:117 [D loss: 0.748720, acc.: 52.34%] [G loss: 1.474657]\n",
      "epoch:0 step:118 [D loss: 0.785863, acc.: 50.78%] [G loss: 1.265008]\n",
      "epoch:0 step:119 [D loss: 0.644987, acc.: 66.41%] [G loss: 1.409407]\n",
      "epoch:0 step:120 [D loss: 0.826794, acc.: 50.78%] [G loss: 1.141048]\n",
      "epoch:0 step:121 [D loss: 0.864870, acc.: 50.78%] [G loss: 1.233448]\n",
      "epoch:0 step:122 [D loss: 0.675099, acc.: 65.62%] [G loss: 1.229978]\n",
      "epoch:0 step:123 [D loss: 0.698428, acc.: 53.91%] [G loss: 1.330891]\n",
      "epoch:0 step:124 [D loss: 0.785192, acc.: 53.12%] [G loss: 1.283569]\n",
      "epoch:0 step:125 [D loss: 0.900567, acc.: 47.66%] [G loss: 1.232669]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0 step:126 [D loss: 0.707632, acc.: 57.03%] [G loss: 1.251627]\n",
      "epoch:0 step:127 [D loss: 0.736849, acc.: 60.16%] [G loss: 1.215515]\n",
      "epoch:0 step:128 [D loss: 0.753354, acc.: 53.91%] [G loss: 1.258323]\n",
      "epoch:0 step:129 [D loss: 0.748187, acc.: 53.91%] [G loss: 1.083571]\n",
      "epoch:0 step:130 [D loss: 0.675359, acc.: 57.81%] [G loss: 1.117549]\n",
      "epoch:0 step:131 [D loss: 0.781838, acc.: 55.47%] [G loss: 1.207138]\n",
      "epoch:0 step:132 [D loss: 0.664388, acc.: 62.50%] [G loss: 1.167876]\n",
      "epoch:0 step:133 [D loss: 0.704462, acc.: 59.38%] [G loss: 1.188114]\n",
      "epoch:0 step:134 [D loss: 0.656916, acc.: 64.84%] [G loss: 1.038236]\n",
      "epoch:0 step:135 [D loss: 0.670578, acc.: 61.72%] [G loss: 1.268355]\n",
      "epoch:0 step:136 [D loss: 0.764708, acc.: 56.25%] [G loss: 0.983205]\n",
      "epoch:0 step:137 [D loss: 0.684785, acc.: 65.62%] [G loss: 1.217371]\n",
      "epoch:0 step:138 [D loss: 0.749515, acc.: 54.69%] [G loss: 1.323973]\n",
      "epoch:0 step:139 [D loss: 0.823349, acc.: 45.31%] [G loss: 1.215836]\n",
      "epoch:0 step:140 [D loss: 0.702694, acc.: 62.50%] [G loss: 1.401350]\n",
      "epoch:0 step:141 [D loss: 0.625077, acc.: 67.19%] [G loss: 1.217673]\n",
      "epoch:0 step:142 [D loss: 0.769334, acc.: 53.91%] [G loss: 1.300920]\n",
      "epoch:0 step:143 [D loss: 0.725953, acc.: 58.59%] [G loss: 1.169160]\n",
      "epoch:0 step:144 [D loss: 0.891008, acc.: 46.09%] [G loss: 1.196910]\n",
      "epoch:0 step:145 [D loss: 0.680450, acc.: 63.28%] [G loss: 1.203615]\n",
      "epoch:0 step:146 [D loss: 0.772898, acc.: 56.25%] [G loss: 1.204446]\n",
      "epoch:0 step:147 [D loss: 0.654315, acc.: 66.41%] [G loss: 1.202509]\n",
      "epoch:0 step:148 [D loss: 0.776967, acc.: 50.00%] [G loss: 1.390169]\n",
      "epoch:0 step:149 [D loss: 0.763815, acc.: 54.69%] [G loss: 1.410779]\n",
      "epoch:0 step:150 [D loss: 0.669083, acc.: 60.16%] [G loss: 1.407967]\n",
      "epoch:0 step:151 [D loss: 0.811880, acc.: 53.91%] [G loss: 1.163565]\n",
      "epoch:0 step:152 [D loss: 0.599798, acc.: 71.88%] [G loss: 1.463703]\n",
      "epoch:0 step:153 [D loss: 0.684958, acc.: 64.06%] [G loss: 1.403957]\n",
      "epoch:0 step:154 [D loss: 0.579207, acc.: 71.09%] [G loss: 1.238087]\n",
      "epoch:0 step:155 [D loss: 0.681697, acc.: 63.28%] [G loss: 1.329802]\n",
      "epoch:0 step:156 [D loss: 0.653521, acc.: 58.59%] [G loss: 1.251833]\n",
      "epoch:0 step:157 [D loss: 0.696951, acc.: 60.16%] [G loss: 1.338723]\n",
      "epoch:0 step:158 [D loss: 0.831983, acc.: 52.34%] [G loss: 1.292332]\n",
      "epoch:0 step:159 [D loss: 0.699734, acc.: 60.16%] [G loss: 1.353726]\n",
      "epoch:0 step:160 [D loss: 0.739546, acc.: 58.59%] [G loss: 1.284014]\n",
      "epoch:0 step:161 [D loss: 0.842276, acc.: 50.00%] [G loss: 1.290051]\n",
      "epoch:0 step:162 [D loss: 0.705546, acc.: 59.38%] [G loss: 1.168760]\n",
      "epoch:0 step:163 [D loss: 0.884677, acc.: 50.00%] [G loss: 1.197604]\n",
      "epoch:0 step:164 [D loss: 0.693579, acc.: 60.16%] [G loss: 1.277669]\n",
      "epoch:0 step:165 [D loss: 0.695217, acc.: 61.72%] [G loss: 1.349719]\n",
      "epoch:0 step:166 [D loss: 0.698528, acc.: 63.28%] [G loss: 1.209545]\n",
      "epoch:0 step:167 [D loss: 0.725958, acc.: 59.38%] [G loss: 1.206176]\n",
      "epoch:0 step:168 [D loss: 0.718597, acc.: 58.59%] [G loss: 1.261410]\n",
      "epoch:0 step:169 [D loss: 0.769187, acc.: 53.91%] [G loss: 1.272695]\n",
      "epoch:0 step:170 [D loss: 0.744246, acc.: 53.12%] [G loss: 1.364810]\n",
      "epoch:0 step:171 [D loss: 0.759484, acc.: 51.56%] [G loss: 1.385747]\n",
      "epoch:0 step:172 [D loss: 0.732149, acc.: 60.16%] [G loss: 1.271448]\n",
      "epoch:0 step:173 [D loss: 0.703925, acc.: 55.47%] [G loss: 1.406316]\n",
      "epoch:0 step:174 [D loss: 0.654423, acc.: 60.94%] [G loss: 1.216026]\n",
      "epoch:0 step:175 [D loss: 0.627113, acc.: 65.62%] [G loss: 1.345859]\n",
      "epoch:0 step:176 [D loss: 0.619555, acc.: 62.50%] [G loss: 1.307614]\n",
      "epoch:0 step:177 [D loss: 0.715095, acc.: 57.81%] [G loss: 1.241892]\n",
      "epoch:0 step:178 [D loss: 0.790966, acc.: 49.22%] [G loss: 1.175875]\n",
      "epoch:0 step:179 [D loss: 0.684191, acc.: 60.94%] [G loss: 1.257502]\n",
      "epoch:0 step:180 [D loss: 0.666149, acc.: 63.28%] [G loss: 1.281195]\n",
      "epoch:0 step:181 [D loss: 0.724676, acc.: 56.25%] [G loss: 1.219130]\n",
      "epoch:0 step:182 [D loss: 0.741372, acc.: 57.03%] [G loss: 1.263273]\n",
      "epoch:0 step:183 [D loss: 0.719010, acc.: 57.03%] [G loss: 1.243263]\n",
      "epoch:0 step:184 [D loss: 0.748606, acc.: 56.25%] [G loss: 1.142272]\n",
      "epoch:0 step:185 [D loss: 0.748504, acc.: 51.56%] [G loss: 1.131376]\n",
      "epoch:0 step:186 [D loss: 0.762681, acc.: 50.78%] [G loss: 1.243606]\n",
      "epoch:0 step:187 [D loss: 0.702516, acc.: 61.72%] [G loss: 1.218090]\n",
      "epoch:0 step:188 [D loss: 0.719213, acc.: 57.03%] [G loss: 1.229026]\n",
      "epoch:0 step:189 [D loss: 0.741332, acc.: 53.12%] [G loss: 1.121313]\n",
      "epoch:0 step:190 [D loss: 0.612642, acc.: 67.19%] [G loss: 1.266361]\n",
      "epoch:0 step:191 [D loss: 0.711995, acc.: 59.38%] [G loss: 1.375767]\n",
      "epoch:0 step:192 [D loss: 0.694884, acc.: 62.50%] [G loss: 1.276112]\n",
      "epoch:0 step:193 [D loss: 0.704228, acc.: 62.50%] [G loss: 1.309721]\n",
      "epoch:0 step:194 [D loss: 0.728832, acc.: 57.03%] [G loss: 1.244372]\n",
      "epoch:0 step:195 [D loss: 0.631905, acc.: 67.97%] [G loss: 1.403946]\n",
      "epoch:0 step:196 [D loss: 0.682478, acc.: 64.84%] [G loss: 1.397547]\n",
      "epoch:0 step:197 [D loss: 0.761538, acc.: 61.72%] [G loss: 1.205569]\n",
      "epoch:0 step:198 [D loss: 0.743381, acc.: 56.25%] [G loss: 1.149405]\n",
      "epoch:0 step:199 [D loss: 0.686986, acc.: 59.38%] [G loss: 1.444916]\n",
      "epoch:0 step:200 [D loss: 0.750944, acc.: 56.25%] [G loss: 1.194385]\n",
      "epoch:0 step:201 [D loss: 0.663680, acc.: 67.19%] [G loss: 1.216453]\n",
      "epoch:0 step:202 [D loss: 0.761925, acc.: 56.25%] [G loss: 1.214368]\n",
      "epoch:0 step:203 [D loss: 0.613735, acc.: 66.41%] [G loss: 1.239114]\n",
      "epoch:0 step:204 [D loss: 0.710772, acc.: 62.50%] [G loss: 1.275241]\n",
      "epoch:0 step:205 [D loss: 0.625311, acc.: 61.72%] [G loss: 1.388217]\n",
      "epoch:0 step:206 [D loss: 0.694909, acc.: 58.59%] [G loss: 1.422791]\n",
      "epoch:0 step:207 [D loss: 0.675516, acc.: 57.81%] [G loss: 1.065699]\n",
      "epoch:0 step:208 [D loss: 0.721155, acc.: 58.59%] [G loss: 1.214461]\n",
      "epoch:0 step:209 [D loss: 0.678801, acc.: 59.38%] [G loss: 1.307669]\n",
      "epoch:0 step:210 [D loss: 0.639358, acc.: 65.62%] [G loss: 1.328039]\n",
      "epoch:0 step:211 [D loss: 0.701520, acc.: 57.03%] [G loss: 1.190730]\n",
      "epoch:0 step:212 [D loss: 0.665062, acc.: 66.41%] [G loss: 1.425664]\n",
      "epoch:0 step:213 [D loss: 0.696707, acc.: 60.16%] [G loss: 1.415197]\n",
      "epoch:0 step:214 [D loss: 0.672714, acc.: 60.16%] [G loss: 1.289236]\n",
      "epoch:0 step:215 [D loss: 0.679185, acc.: 60.16%] [G loss: 1.175028]\n",
      "epoch:0 step:216 [D loss: 0.750136, acc.: 59.38%] [G loss: 1.078996]\n",
      "epoch:0 step:217 [D loss: 0.562197, acc.: 67.97%] [G loss: 1.274597]\n",
      "epoch:0 step:218 [D loss: 0.724561, acc.: 56.25%] [G loss: 1.291951]\n",
      "epoch:0 step:219 [D loss: 0.753178, acc.: 56.25%] [G loss: 1.175297]\n",
      "epoch:0 step:220 [D loss: 0.748607, acc.: 60.94%] [G loss: 1.373823]\n",
      "epoch:0 step:221 [D loss: 0.607291, acc.: 67.97%] [G loss: 1.296805]\n",
      "epoch:0 step:222 [D loss: 0.748788, acc.: 53.91%] [G loss: 1.194123]\n",
      "epoch:0 step:223 [D loss: 0.653625, acc.: 61.72%] [G loss: 1.151655]\n",
      "epoch:0 step:224 [D loss: 0.748463, acc.: 55.47%] [G loss: 1.447032]\n",
      "epoch:0 step:225 [D loss: 0.611116, acc.: 67.19%] [G loss: 1.305350]\n",
      "epoch:0 step:226 [D loss: 0.591772, acc.: 69.53%] [G loss: 1.290590]\n",
      "epoch:0 step:227 [D loss: 0.639034, acc.: 61.72%] [G loss: 1.203341]\n",
      "epoch:0 step:228 [D loss: 0.655267, acc.: 59.38%] [G loss: 1.217625]\n",
      "epoch:0 step:229 [D loss: 0.649398, acc.: 64.06%] [G loss: 1.393663]\n",
      "epoch:0 step:230 [D loss: 0.757172, acc.: 58.59%] [G loss: 1.177518]\n",
      "epoch:0 step:231 [D loss: 0.589098, acc.: 70.31%] [G loss: 1.251462]\n",
      "epoch:0 step:232 [D loss: 0.702659, acc.: 60.16%] [G loss: 1.206203]\n",
      "epoch:0 step:233 [D loss: 0.686816, acc.: 57.81%] [G loss: 1.278566]\n",
      "epoch:0 step:234 [D loss: 0.697161, acc.: 60.94%] [G loss: 1.281758]\n",
      "epoch:0 step:235 [D loss: 0.569456, acc.: 71.09%] [G loss: 1.419781]\n",
      "epoch:0 step:236 [D loss: 0.651735, acc.: 61.72%] [G loss: 1.480988]\n",
      "epoch:0 step:237 [D loss: 0.743278, acc.: 56.25%] [G loss: 1.421980]\n",
      "epoch:0 step:238 [D loss: 0.640832, acc.: 63.28%] [G loss: 1.396123]\n",
      "epoch:0 step:239 [D loss: 0.656511, acc.: 67.19%] [G loss: 1.475283]\n",
      "epoch:0 step:240 [D loss: 0.721326, acc.: 57.03%] [G loss: 1.265838]\n",
      "epoch:0 step:241 [D loss: 0.734387, acc.: 54.69%] [G loss: 1.182667]\n",
      "epoch:0 step:242 [D loss: 0.765362, acc.: 60.94%] [G loss: 1.387142]\n",
      "epoch:0 step:243 [D loss: 0.697843, acc.: 59.38%] [G loss: 1.260962]\n",
      "epoch:0 step:244 [D loss: 0.684760, acc.: 62.50%] [G loss: 1.366361]\n",
      "epoch:0 step:245 [D loss: 0.707722, acc.: 61.72%] [G loss: 1.317296]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0 step:246 [D loss: 0.717446, acc.: 58.59%] [G loss: 1.433088]\n",
      "epoch:0 step:247 [D loss: 0.664619, acc.: 59.38%] [G loss: 1.393497]\n",
      "epoch:0 step:248 [D loss: 0.559866, acc.: 72.66%] [G loss: 1.373027]\n",
      "epoch:0 step:249 [D loss: 0.633241, acc.: 64.06%] [G loss: 1.483352]\n",
      "epoch:0 step:250 [D loss: 0.630457, acc.: 64.84%] [G loss: 1.239668]\n",
      "epoch:0 step:251 [D loss: 0.750393, acc.: 57.81%] [G loss: 1.326765]\n",
      "epoch:0 step:252 [D loss: 0.631058, acc.: 64.84%] [G loss: 1.329925]\n",
      "epoch:0 step:253 [D loss: 0.644621, acc.: 67.19%] [G loss: 1.269240]\n",
      "epoch:0 step:254 [D loss: 0.623187, acc.: 61.72%] [G loss: 1.377875]\n",
      "epoch:0 step:255 [D loss: 0.715221, acc.: 58.59%] [G loss: 1.127068]\n",
      "epoch:0 step:256 [D loss: 0.728075, acc.: 56.25%] [G loss: 1.293053]\n",
      "epoch:0 step:257 [D loss: 0.654516, acc.: 62.50%] [G loss: 1.344739]\n",
      "epoch:0 step:258 [D loss: 0.672306, acc.: 64.84%] [G loss: 1.291071]\n",
      "epoch:0 step:259 [D loss: 0.659917, acc.: 61.72%] [G loss: 1.149823]\n",
      "epoch:0 step:260 [D loss: 0.719914, acc.: 56.25%] [G loss: 1.182750]\n",
      "epoch:0 step:261 [D loss: 0.711263, acc.: 60.94%] [G loss: 1.172048]\n",
      "epoch:0 step:262 [D loss: 0.691811, acc.: 54.69%] [G loss: 1.275167]\n",
      "epoch:0 step:263 [D loss: 0.536550, acc.: 71.88%] [G loss: 1.227561]\n",
      "epoch:0 step:264 [D loss: 0.633747, acc.: 67.97%] [G loss: 1.317564]\n",
      "epoch:0 step:265 [D loss: 0.544081, acc.: 71.09%] [G loss: 1.286930]\n",
      "epoch:0 step:266 [D loss: 0.665297, acc.: 62.50%] [G loss: 1.202467]\n",
      "epoch:0 step:267 [D loss: 0.572865, acc.: 69.53%] [G loss: 1.050042]\n",
      "epoch:0 step:268 [D loss: 0.602457, acc.: 67.97%] [G loss: 1.220189]\n",
      "epoch:0 step:269 [D loss: 0.576897, acc.: 68.75%] [G loss: 1.260081]\n",
      "epoch:0 step:270 [D loss: 0.618806, acc.: 64.06%] [G loss: 1.267174]\n",
      "epoch:0 step:271 [D loss: 0.648014, acc.: 60.94%] [G loss: 1.245800]\n",
      "epoch:0 step:272 [D loss: 0.666393, acc.: 67.19%] [G loss: 1.141023]\n",
      "epoch:0 step:273 [D loss: 0.758281, acc.: 52.34%] [G loss: 1.186000]\n",
      "epoch:0 step:274 [D loss: 0.667618, acc.: 63.28%] [G loss: 1.595133]\n",
      "epoch:0 step:275 [D loss: 0.854150, acc.: 53.91%] [G loss: 1.043576]\n",
      "epoch:0 step:276 [D loss: 0.833404, acc.: 48.44%] [G loss: 1.052601]\n",
      "epoch:0 step:277 [D loss: 0.639192, acc.: 64.06%] [G loss: 1.462477]\n",
      "epoch:0 step:278 [D loss: 0.575085, acc.: 70.31%] [G loss: 1.296204]\n",
      "epoch:0 step:279 [D loss: 0.602022, acc.: 67.97%] [G loss: 1.463207]\n",
      "epoch:0 step:280 [D loss: 0.685019, acc.: 55.47%] [G loss: 1.268045]\n",
      "epoch:0 step:281 [D loss: 0.661342, acc.: 63.28%] [G loss: 1.327331]\n",
      "epoch:0 step:282 [D loss: 0.698752, acc.: 56.25%] [G loss: 1.342242]\n",
      "epoch:0 step:283 [D loss: 0.692023, acc.: 67.97%] [G loss: 1.259219]\n",
      "epoch:0 step:284 [D loss: 0.605424, acc.: 67.97%] [G loss: 1.426766]\n",
      "epoch:0 step:285 [D loss: 0.747385, acc.: 57.81%] [G loss: 1.246964]\n",
      "epoch:0 step:286 [D loss: 0.593271, acc.: 67.19%] [G loss: 1.224667]\n",
      "epoch:0 step:287 [D loss: 0.686393, acc.: 63.28%] [G loss: 1.397581]\n",
      "epoch:0 step:288 [D loss: 0.547859, acc.: 71.88%] [G loss: 1.596470]\n",
      "epoch:0 step:289 [D loss: 0.609885, acc.: 64.06%] [G loss: 1.271394]\n",
      "epoch:0 step:290 [D loss: 0.685637, acc.: 62.50%] [G loss: 1.293550]\n",
      "epoch:0 step:291 [D loss: 0.667920, acc.: 62.50%] [G loss: 1.219185]\n",
      "epoch:0 step:292 [D loss: 0.670332, acc.: 62.50%] [G loss: 1.233982]\n",
      "epoch:0 step:293 [D loss: 0.597236, acc.: 73.44%] [G loss: 1.240680]\n",
      "epoch:0 step:294 [D loss: 0.554005, acc.: 71.88%] [G loss: 1.381054]\n",
      "epoch:0 step:295 [D loss: 0.700688, acc.: 63.28%] [G loss: 1.097322]\n",
      "epoch:0 step:296 [D loss: 0.606895, acc.: 66.41%] [G loss: 1.412580]\n",
      "epoch:0 step:297 [D loss: 0.638223, acc.: 60.16%] [G loss: 1.186953]\n",
      "epoch:0 step:298 [D loss: 0.581547, acc.: 68.75%] [G loss: 1.255846]\n",
      "epoch:0 step:299 [D loss: 0.650452, acc.: 64.06%] [G loss: 1.413037]\n",
      "epoch:0 step:300 [D loss: 0.589272, acc.: 67.97%] [G loss: 1.243204]\n",
      "epoch:0 step:301 [D loss: 0.691901, acc.: 60.94%] [G loss: 1.531277]\n",
      "epoch:0 step:302 [D loss: 0.609069, acc.: 68.75%] [G loss: 1.245993]\n",
      "epoch:0 step:303 [D loss: 0.579039, acc.: 66.41%] [G loss: 1.189851]\n",
      "epoch:0 step:304 [D loss: 0.588212, acc.: 67.97%] [G loss: 1.501440]\n",
      "epoch:0 step:305 [D loss: 0.639791, acc.: 67.19%] [G loss: 1.426871]\n",
      "epoch:0 step:306 [D loss: 0.687891, acc.: 59.38%] [G loss: 1.315042]\n",
      "epoch:0 step:307 [D loss: 0.615790, acc.: 66.41%] [G loss: 1.155348]\n",
      "epoch:0 step:308 [D loss: 0.558062, acc.: 71.88%] [G loss: 1.267235]\n",
      "epoch:0 step:309 [D loss: 0.554243, acc.: 72.66%] [G loss: 1.506793]\n",
      "epoch:0 step:310 [D loss: 0.718042, acc.: 57.03%] [G loss: 1.348265]\n",
      "epoch:0 step:311 [D loss: 0.611550, acc.: 65.62%] [G loss: 1.225343]\n",
      "epoch:0 step:312 [D loss: 0.657056, acc.: 58.59%] [G loss: 1.002942]\n",
      "epoch:0 step:313 [D loss: 0.571562, acc.: 71.88%] [G loss: 1.228655]\n",
      "epoch:0 step:314 [D loss: 0.665565, acc.: 60.94%] [G loss: 1.302278]\n",
      "epoch:0 step:315 [D loss: 0.649204, acc.: 65.62%] [G loss: 1.361845]\n",
      "epoch:0 step:316 [D loss: 0.659278, acc.: 61.72%] [G loss: 1.387049]\n",
      "epoch:0 step:317 [D loss: 0.747949, acc.: 60.94%] [G loss: 1.157583]\n",
      "epoch:0 step:318 [D loss: 0.506580, acc.: 75.78%] [G loss: 1.466734]\n",
      "epoch:0 step:319 [D loss: 0.668593, acc.: 59.38%] [G loss: 1.446744]\n",
      "epoch:0 step:320 [D loss: 0.662969, acc.: 60.16%] [G loss: 1.314531]\n",
      "epoch:0 step:321 [D loss: 0.638100, acc.: 61.72%] [G loss: 1.240920]\n",
      "epoch:0 step:322 [D loss: 0.694212, acc.: 58.59%] [G loss: 1.288066]\n",
      "epoch:0 step:323 [D loss: 0.722840, acc.: 57.03%] [G loss: 1.285431]\n",
      "epoch:0 step:324 [D loss: 0.580219, acc.: 67.19%] [G loss: 1.145275]\n",
      "epoch:0 step:325 [D loss: 0.557194, acc.: 77.34%] [G loss: 1.237868]\n",
      "epoch:0 step:326 [D loss: 0.570429, acc.: 73.44%] [G loss: 1.497143]\n",
      "epoch:0 step:327 [D loss: 0.664552, acc.: 60.16%] [G loss: 1.301964]\n",
      "epoch:0 step:328 [D loss: 0.624722, acc.: 61.72%] [G loss: 1.538063]\n",
      "epoch:0 step:329 [D loss: 0.706496, acc.: 59.38%] [G loss: 1.326476]\n",
      "epoch:0 step:330 [D loss: 0.651797, acc.: 63.28%] [G loss: 1.184698]\n",
      "epoch:0 step:331 [D loss: 0.553145, acc.: 69.53%] [G loss: 1.430519]\n",
      "epoch:0 step:332 [D loss: 0.695135, acc.: 65.62%] [G loss: 1.234774]\n",
      "epoch:0 step:333 [D loss: 0.749325, acc.: 53.91%] [G loss: 1.245918]\n",
      "epoch:0 step:334 [D loss: 0.681392, acc.: 65.62%] [G loss: 1.464993]\n",
      "epoch:0 step:335 [D loss: 0.622941, acc.: 67.19%] [G loss: 1.301970]\n",
      "epoch:0 step:336 [D loss: 0.587875, acc.: 67.19%] [G loss: 1.287861]\n",
      "epoch:0 step:337 [D loss: 0.694866, acc.: 60.16%] [G loss: 1.127947]\n",
      "epoch:0 step:338 [D loss: 0.683973, acc.: 62.50%] [G loss: 1.162678]\n",
      "epoch:0 step:339 [D loss: 0.722660, acc.: 57.81%] [G loss: 1.159970]\n",
      "epoch:0 step:340 [D loss: 0.609563, acc.: 67.97%] [G loss: 1.350186]\n",
      "epoch:0 step:341 [D loss: 0.592195, acc.: 70.31%] [G loss: 1.330204]\n",
      "epoch:0 step:342 [D loss: 0.659057, acc.: 64.06%] [G loss: 1.198770]\n",
      "epoch:0 step:343 [D loss: 0.577917, acc.: 68.75%] [G loss: 1.272239]\n",
      "epoch:0 step:344 [D loss: 0.527897, acc.: 72.66%] [G loss: 1.303278]\n",
      "epoch:0 step:345 [D loss: 0.698053, acc.: 56.25%] [G loss: 1.211731]\n",
      "epoch:0 step:346 [D loss: 0.690934, acc.: 59.38%] [G loss: 1.229291]\n",
      "epoch:0 step:347 [D loss: 0.558275, acc.: 66.41%] [G loss: 1.075909]\n",
      "epoch:0 step:348 [D loss: 0.557683, acc.: 68.75%] [G loss: 1.170672]\n",
      "epoch:0 step:349 [D loss: 0.751797, acc.: 52.34%] [G loss: 1.157319]\n",
      "epoch:0 step:350 [D loss: 0.668726, acc.: 62.50%] [G loss: 1.400699]\n",
      "epoch:0 step:351 [D loss: 0.662571, acc.: 62.50%] [G loss: 1.315476]\n",
      "epoch:0 step:352 [D loss: 0.639888, acc.: 65.62%] [G loss: 1.236044]\n",
      "epoch:0 step:353 [D loss: 0.656511, acc.: 62.50%] [G loss: 1.344454]\n",
      "epoch:0 step:354 [D loss: 0.616510, acc.: 71.09%] [G loss: 1.125322]\n",
      "epoch:0 step:355 [D loss: 0.694004, acc.: 67.19%] [G loss: 1.257602]\n",
      "epoch:0 step:356 [D loss: 0.609156, acc.: 71.09%] [G loss: 1.169176]\n",
      "epoch:0 step:357 [D loss: 0.569225, acc.: 68.75%] [G loss: 1.325356]\n",
      "epoch:0 step:358 [D loss: 0.686324, acc.: 60.16%] [G loss: 1.420905]\n",
      "epoch:0 step:359 [D loss: 0.733296, acc.: 58.59%] [G loss: 1.206769]\n",
      "epoch:0 step:360 [D loss: 0.602396, acc.: 70.31%] [G loss: 1.390007]\n",
      "epoch:0 step:361 [D loss: 0.660854, acc.: 65.62%] [G loss: 1.373808]\n",
      "epoch:0 step:362 [D loss: 0.680296, acc.: 57.81%] [G loss: 1.269154]\n",
      "epoch:0 step:363 [D loss: 0.537182, acc.: 76.56%] [G loss: 1.448913]\n",
      "epoch:0 step:364 [D loss: 0.579150, acc.: 66.41%] [G loss: 1.596973]\n",
      "epoch:0 step:365 [D loss: 0.704300, acc.: 59.38%] [G loss: 1.387247]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0 step:366 [D loss: 0.678832, acc.: 64.06%] [G loss: 1.443969]\n",
      "epoch:0 step:367 [D loss: 0.645144, acc.: 63.28%] [G loss: 1.178865]\n",
      "epoch:0 step:368 [D loss: 0.538463, acc.: 73.44%] [G loss: 1.351813]\n",
      "epoch:0 step:369 [D loss: 0.735675, acc.: 57.81%] [G loss: 1.124520]\n",
      "epoch:0 step:370 [D loss: 0.642813, acc.: 64.84%] [G loss: 1.206058]\n",
      "epoch:0 step:371 [D loss: 0.623203, acc.: 69.53%] [G loss: 1.164607]\n",
      "epoch:0 step:372 [D loss: 0.574523, acc.: 69.53%] [G loss: 1.600712]\n",
      "epoch:0 step:373 [D loss: 0.661554, acc.: 62.50%] [G loss: 1.371954]\n",
      "epoch:0 step:374 [D loss: 0.647679, acc.: 64.84%] [G loss: 1.240712]\n",
      "epoch:0 step:375 [D loss: 0.620578, acc.: 62.50%] [G loss: 1.327078]\n",
      "epoch:0 step:376 [D loss: 0.631469, acc.: 68.75%] [G loss: 1.205203]\n",
      "epoch:0 step:377 [D loss: 0.756104, acc.: 53.12%] [G loss: 1.165049]\n",
      "epoch:0 step:378 [D loss: 0.600005, acc.: 69.53%] [G loss: 1.238625]\n",
      "epoch:0 step:379 [D loss: 0.536430, acc.: 71.09%] [G loss: 1.334875]\n",
      "epoch:0 step:380 [D loss: 0.642756, acc.: 60.94%] [G loss: 1.365665]\n",
      "epoch:0 step:381 [D loss: 0.669900, acc.: 60.94%] [G loss: 1.413416]\n",
      "epoch:0 step:382 [D loss: 0.686267, acc.: 57.81%] [G loss: 1.415185]\n",
      "epoch:0 step:383 [D loss: 0.655620, acc.: 61.72%] [G loss: 1.285738]\n",
      "epoch:0 step:384 [D loss: 0.738402, acc.: 53.91%] [G loss: 1.278616]\n",
      "epoch:0 step:385 [D loss: 0.640926, acc.: 59.38%] [G loss: 1.347793]\n",
      "epoch:0 step:386 [D loss: 0.604094, acc.: 64.06%] [G loss: 1.128764]\n",
      "epoch:0 step:387 [D loss: 0.709800, acc.: 55.47%] [G loss: 1.132364]\n",
      "epoch:0 step:388 [D loss: 0.649231, acc.: 65.62%] [G loss: 1.112250]\n",
      "epoch:0 step:389 [D loss: 0.644932, acc.: 65.62%] [G loss: 1.385835]\n",
      "epoch:0 step:390 [D loss: 0.690208, acc.: 60.94%] [G loss: 1.323738]\n",
      "epoch:0 step:391 [D loss: 0.698796, acc.: 57.81%] [G loss: 1.327799]\n",
      "epoch:0 step:392 [D loss: 0.621374, acc.: 66.41%] [G loss: 1.309807]\n",
      "epoch:0 step:393 [D loss: 0.752879, acc.: 56.25%] [G loss: 1.278620]\n",
      "epoch:0 step:394 [D loss: 0.658202, acc.: 63.28%] [G loss: 1.289539]\n",
      "epoch:0 step:395 [D loss: 0.573036, acc.: 69.53%] [G loss: 1.259195]\n",
      "epoch:0 step:396 [D loss: 0.568325, acc.: 74.22%] [G loss: 1.419541]\n",
      "epoch:0 step:397 [D loss: 0.615923, acc.: 63.28%] [G loss: 1.404418]\n",
      "epoch:0 step:398 [D loss: 0.725894, acc.: 60.16%] [G loss: 1.178524]\n",
      "epoch:0 step:399 [D loss: 0.554197, acc.: 71.09%] [G loss: 1.236615]\n",
      "epoch:0 step:400 [D loss: 0.640142, acc.: 68.75%] [G loss: 1.408855]\n",
      "epoch:0 step:401 [D loss: 0.532384, acc.: 71.88%] [G loss: 1.347391]\n",
      "epoch:0 step:402 [D loss: 0.511439, acc.: 75.78%] [G loss: 1.358583]\n",
      "epoch:0 step:403 [D loss: 0.541895, acc.: 71.09%] [G loss: 1.349385]\n",
      "epoch:0 step:404 [D loss: 0.535573, acc.: 72.66%] [G loss: 1.236267]\n",
      "epoch:0 step:405 [D loss: 0.643237, acc.: 68.75%] [G loss: 1.324979]\n",
      "epoch:0 step:406 [D loss: 0.678133, acc.: 65.62%] [G loss: 1.258385]\n",
      "epoch:0 step:407 [D loss: 0.681432, acc.: 62.50%] [G loss: 1.238808]\n",
      "epoch:0 step:408 [D loss: 0.703137, acc.: 62.50%] [G loss: 1.142875]\n",
      "epoch:0 step:409 [D loss: 0.700581, acc.: 58.59%] [G loss: 1.131269]\n",
      "epoch:0 step:410 [D loss: 0.634983, acc.: 64.06%] [G loss: 1.326450]\n",
      "epoch:0 step:411 [D loss: 0.669401, acc.: 60.94%] [G loss: 1.138870]\n",
      "epoch:0 step:412 [D loss: 0.596791, acc.: 64.84%] [G loss: 1.286963]\n",
      "epoch:0 step:413 [D loss: 0.630975, acc.: 63.28%] [G loss: 1.285613]\n",
      "epoch:0 step:414 [D loss: 0.647727, acc.: 67.19%] [G loss: 1.283539]\n",
      "epoch:0 step:415 [D loss: 0.663978, acc.: 63.28%] [G loss: 1.427494]\n",
      "epoch:0 step:416 [D loss: 0.655562, acc.: 63.28%] [G loss: 1.139667]\n",
      "epoch:0 step:417 [D loss: 0.647498, acc.: 67.19%] [G loss: 1.295404]\n",
      "epoch:0 step:418 [D loss: 0.589885, acc.: 67.19%] [G loss: 1.344967]\n",
      "epoch:0 step:419 [D loss: 0.586324, acc.: 67.19%] [G loss: 1.422314]\n",
      "epoch:0 step:420 [D loss: 0.671397, acc.: 57.81%] [G loss: 1.444277]\n",
      "epoch:0 step:421 [D loss: 0.651660, acc.: 62.50%] [G loss: 1.223433]\n",
      "epoch:0 step:422 [D loss: 0.634464, acc.: 66.41%] [G loss: 1.154515]\n",
      "epoch:0 step:423 [D loss: 0.474151, acc.: 78.91%] [G loss: 1.421986]\n",
      "epoch:0 step:424 [D loss: 0.665878, acc.: 61.72%] [G loss: 1.397326]\n",
      "epoch:0 step:425 [D loss: 0.604920, acc.: 67.97%] [G loss: 1.443221]\n",
      "epoch:0 step:426 [D loss: 0.638359, acc.: 64.06%] [G loss: 1.396170]\n",
      "epoch:0 step:427 [D loss: 0.591345, acc.: 64.84%] [G loss: 1.283117]\n",
      "epoch:0 step:428 [D loss: 0.651319, acc.: 59.38%] [G loss: 1.176703]\n",
      "epoch:0 step:429 [D loss: 0.638279, acc.: 64.06%] [G loss: 1.152427]\n",
      "epoch:0 step:430 [D loss: 0.579989, acc.: 67.19%] [G loss: 1.205689]\n",
      "epoch:0 step:431 [D loss: 0.630797, acc.: 60.94%] [G loss: 1.173426]\n",
      "epoch:0 step:432 [D loss: 0.540841, acc.: 70.31%] [G loss: 1.249879]\n",
      "epoch:0 step:433 [D loss: 0.701597, acc.: 59.38%] [G loss: 1.225774]\n",
      "epoch:0 step:434 [D loss: 0.580415, acc.: 68.75%] [G loss: 1.109921]\n",
      "epoch:0 step:435 [D loss: 0.523601, acc.: 75.78%] [G loss: 1.287034]\n",
      "epoch:0 step:436 [D loss: 0.558420, acc.: 68.75%] [G loss: 1.548890]\n",
      "epoch:0 step:437 [D loss: 0.608915, acc.: 67.19%] [G loss: 1.173977]\n",
      "epoch:0 step:438 [D loss: 0.700681, acc.: 54.69%] [G loss: 1.440693]\n",
      "epoch:0 step:439 [D loss: 0.659575, acc.: 60.16%] [G loss: 1.240758]\n",
      "epoch:0 step:440 [D loss: 0.650815, acc.: 62.50%] [G loss: 1.427157]\n",
      "epoch:0 step:441 [D loss: 0.584980, acc.: 69.53%] [G loss: 1.203636]\n",
      "epoch:0 step:442 [D loss: 0.617979, acc.: 70.31%] [G loss: 1.543745]\n",
      "epoch:0 step:443 [D loss: 0.560520, acc.: 69.53%] [G loss: 1.401046]\n",
      "epoch:0 step:444 [D loss: 0.606457, acc.: 67.97%] [G loss: 1.164163]\n",
      "epoch:0 step:445 [D loss: 0.605548, acc.: 67.19%] [G loss: 1.402749]\n",
      "epoch:0 step:446 [D loss: 0.796597, acc.: 51.56%] [G loss: 1.201573]\n",
      "epoch:0 step:447 [D loss: 0.641393, acc.: 60.94%] [G loss: 1.330948]\n",
      "epoch:0 step:448 [D loss: 0.581124, acc.: 67.97%] [G loss: 1.327478]\n",
      "epoch:0 step:449 [D loss: 0.663685, acc.: 60.94%] [G loss: 1.350588]\n",
      "epoch:0 step:450 [D loss: 0.644752, acc.: 61.72%] [G loss: 1.338078]\n",
      "epoch:0 step:451 [D loss: 0.696065, acc.: 56.25%] [G loss: 1.327589]\n",
      "epoch:0 step:452 [D loss: 0.742541, acc.: 57.81%] [G loss: 1.303877]\n",
      "epoch:0 step:453 [D loss: 0.642579, acc.: 68.75%] [G loss: 1.251676]\n",
      "epoch:0 step:454 [D loss: 0.637662, acc.: 64.06%] [G loss: 1.564019]\n",
      "epoch:0 step:455 [D loss: 0.562827, acc.: 66.41%] [G loss: 1.397923]\n",
      "epoch:0 step:456 [D loss: 0.698429, acc.: 59.38%] [G loss: 1.218137]\n",
      "epoch:0 step:457 [D loss: 0.639730, acc.: 60.94%] [G loss: 1.404563]\n",
      "epoch:0 step:458 [D loss: 0.511821, acc.: 80.47%] [G loss: 1.481658]\n",
      "epoch:0 step:459 [D loss: 0.652269, acc.: 65.62%] [G loss: 1.293528]\n",
      "epoch:0 step:460 [D loss: 0.583305, acc.: 67.97%] [G loss: 1.534731]\n",
      "epoch:0 step:461 [D loss: 0.657459, acc.: 60.94%] [G loss: 1.364490]\n",
      "epoch:0 step:462 [D loss: 0.510130, acc.: 75.78%] [G loss: 1.469651]\n",
      "epoch:0 step:463 [D loss: 0.724202, acc.: 62.50%] [G loss: 1.313534]\n",
      "epoch:0 step:464 [D loss: 0.534145, acc.: 75.00%] [G loss: 1.472123]\n",
      "epoch:0 step:465 [D loss: 0.665517, acc.: 64.06%] [G loss: 1.360656]\n",
      "epoch:0 step:466 [D loss: 0.640971, acc.: 60.16%] [G loss: 1.618612]\n",
      "epoch:0 step:467 [D loss: 0.574574, acc.: 70.31%] [G loss: 1.320387]\n",
      "epoch:0 step:468 [D loss: 0.637709, acc.: 62.50%] [G loss: 1.330794]\n",
      "epoch:0 step:469 [D loss: 0.568714, acc.: 69.53%] [G loss: 1.441014]\n",
      "epoch:0 step:470 [D loss: 0.698029, acc.: 61.72%] [G loss: 1.370388]\n",
      "epoch:0 step:471 [D loss: 0.619519, acc.: 70.31%] [G loss: 1.287904]\n",
      "epoch:0 step:472 [D loss: 0.498326, acc.: 73.44%] [G loss: 1.366780]\n",
      "epoch:0 step:473 [D loss: 0.678156, acc.: 60.16%] [G loss: 1.328526]\n",
      "epoch:0 step:474 [D loss: 0.632576, acc.: 64.06%] [G loss: 1.214846]\n",
      "epoch:0 step:475 [D loss: 0.501026, acc.: 80.47%] [G loss: 1.275844]\n",
      "epoch:0 step:476 [D loss: 0.503203, acc.: 78.91%] [G loss: 1.365513]\n",
      "epoch:0 step:477 [D loss: 0.747357, acc.: 57.81%] [G loss: 1.211666]\n",
      "epoch:0 step:478 [D loss: 0.537500, acc.: 75.00%] [G loss: 1.425304]\n",
      "epoch:0 step:479 [D loss: 0.642217, acc.: 62.50%] [G loss: 1.486943]\n",
      "epoch:0 step:480 [D loss: 0.662901, acc.: 62.50%] [G loss: 1.221920]\n",
      "epoch:0 step:481 [D loss: 0.630958, acc.: 67.19%] [G loss: 1.404280]\n",
      "epoch:0 step:482 [D loss: 0.603402, acc.: 67.97%] [G loss: 1.225961]\n",
      "epoch:0 step:483 [D loss: 0.547480, acc.: 73.44%] [G loss: 1.378803]\n",
      "epoch:0 step:484 [D loss: 0.507738, acc.: 76.56%] [G loss: 1.311364]\n",
      "epoch:0 step:485 [D loss: 0.791665, acc.: 56.25%] [G loss: 1.206347]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0 step:486 [D loss: 0.646773, acc.: 64.84%] [G loss: 1.292238]\n",
      "epoch:0 step:487 [D loss: 0.560263, acc.: 69.53%] [G loss: 1.383506]\n",
      "epoch:0 step:488 [D loss: 0.593415, acc.: 68.75%] [G loss: 1.362840]\n",
      "epoch:0 step:489 [D loss: 0.587109, acc.: 71.88%] [G loss: 1.342793]\n",
      "epoch:0 step:490 [D loss: 0.528936, acc.: 74.22%] [G loss: 1.625888]\n",
      "epoch:0 step:491 [D loss: 0.600332, acc.: 67.19%] [G loss: 1.467377]\n",
      "epoch:0 step:492 [D loss: 0.592350, acc.: 67.19%] [G loss: 1.365737]\n",
      "epoch:0 step:493 [D loss: 0.654384, acc.: 64.84%] [G loss: 1.298808]\n",
      "epoch:0 step:494 [D loss: 0.567108, acc.: 74.22%] [G loss: 1.287546]\n",
      "epoch:0 step:495 [D loss: 0.532790, acc.: 74.22%] [G loss: 1.403288]\n",
      "epoch:0 step:496 [D loss: 0.608471, acc.: 68.75%] [G loss: 1.198597]\n",
      "epoch:0 step:497 [D loss: 0.610261, acc.: 68.75%] [G loss: 1.451158]\n",
      "epoch:0 step:498 [D loss: 0.574717, acc.: 66.41%] [G loss: 1.162747]\n",
      "epoch:0 step:499 [D loss: 0.546842, acc.: 71.88%] [G loss: 1.374092]\n",
      "epoch:0 step:500 [D loss: 0.523483, acc.: 72.66%] [G loss: 1.454436]\n",
      "epoch:0 step:501 [D loss: 0.596701, acc.: 68.75%] [G loss: 1.428224]\n",
      "epoch:0 step:502 [D loss: 0.588513, acc.: 70.31%] [G loss: 1.542625]\n",
      "epoch:0 step:503 [D loss: 0.565175, acc.: 67.97%] [G loss: 1.502539]\n",
      "epoch:0 step:504 [D loss: 0.600527, acc.: 67.19%] [G loss: 1.517768]\n",
      "epoch:0 step:505 [D loss: 0.530361, acc.: 72.66%] [G loss: 1.558290]\n",
      "epoch:0 step:506 [D loss: 0.593410, acc.: 66.41%] [G loss: 1.282919]\n",
      "epoch:0 step:507 [D loss: 0.591491, acc.: 68.75%] [G loss: 1.346228]\n",
      "epoch:0 step:508 [D loss: 0.548721, acc.: 74.22%] [G loss: 1.560338]\n",
      "epoch:0 step:509 [D loss: 0.685829, acc.: 63.28%] [G loss: 1.464428]\n",
      "epoch:0 step:510 [D loss: 0.460444, acc.: 76.56%] [G loss: 1.495833]\n",
      "epoch:0 step:511 [D loss: 0.543677, acc.: 75.78%] [G loss: 1.170112]\n",
      "epoch:0 step:512 [D loss: 0.582663, acc.: 70.31%] [G loss: 1.339960]\n",
      "epoch:0 step:513 [D loss: 0.591027, acc.: 70.31%] [G loss: 1.334823]\n",
      "epoch:0 step:514 [D loss: 0.609928, acc.: 67.97%] [G loss: 1.480847]\n",
      "epoch:0 step:515 [D loss: 0.534601, acc.: 78.12%] [G loss: 1.395470]\n",
      "epoch:0 step:516 [D loss: 0.653804, acc.: 63.28%] [G loss: 1.465572]\n",
      "epoch:0 step:517 [D loss: 0.515346, acc.: 76.56%] [G loss: 1.407139]\n",
      "epoch:0 step:518 [D loss: 0.455694, acc.: 85.16%] [G loss: 1.439758]\n",
      "epoch:0 step:519 [D loss: 0.536769, acc.: 74.22%] [G loss: 1.310638]\n",
      "epoch:0 step:520 [D loss: 0.586548, acc.: 65.62%] [G loss: 1.340959]\n",
      "epoch:0 step:521 [D loss: 0.607369, acc.: 69.53%] [G loss: 1.200769]\n",
      "epoch:0 step:522 [D loss: 0.651893, acc.: 66.41%] [G loss: 1.507056]\n",
      "epoch:0 step:523 [D loss: 0.616661, acc.: 67.19%] [G loss: 1.475815]\n",
      "epoch:0 step:524 [D loss: 0.600960, acc.: 67.19%] [G loss: 1.305412]\n",
      "epoch:0 step:525 [D loss: 0.584533, acc.: 69.53%] [G loss: 1.544274]\n",
      "epoch:0 step:526 [D loss: 0.707279, acc.: 56.25%] [G loss: 1.420250]\n",
      "epoch:0 step:527 [D loss: 0.627241, acc.: 65.62%] [G loss: 1.415980]\n",
      "epoch:0 step:528 [D loss: 0.668653, acc.: 62.50%] [G loss: 1.322467]\n",
      "epoch:0 step:529 [D loss: 0.563795, acc.: 70.31%] [G loss: 1.365631]\n",
      "epoch:0 step:530 [D loss: 0.486783, acc.: 76.56%] [G loss: 1.344267]\n",
      "epoch:0 step:531 [D loss: 0.551006, acc.: 71.09%] [G loss: 1.374662]\n",
      "epoch:0 step:532 [D loss: 0.573217, acc.: 71.88%] [G loss: 1.575016]\n",
      "epoch:0 step:533 [D loss: 0.618044, acc.: 64.06%] [G loss: 1.195294]\n",
      "epoch:0 step:534 [D loss: 0.515538, acc.: 75.00%] [G loss: 1.350711]\n",
      "epoch:0 step:535 [D loss: 0.568555, acc.: 71.09%] [G loss: 1.285236]\n",
      "epoch:0 step:536 [D loss: 0.590487, acc.: 71.88%] [G loss: 1.378207]\n",
      "epoch:0 step:537 [D loss: 0.520470, acc.: 75.00%] [G loss: 1.426331]\n",
      "epoch:0 step:538 [D loss: 0.566591, acc.: 71.09%] [G loss: 1.466051]\n",
      "epoch:0 step:539 [D loss: 0.504935, acc.: 78.91%] [G loss: 1.376272]\n",
      "epoch:0 step:540 [D loss: 0.773921, acc.: 53.12%] [G loss: 1.324433]\n",
      "epoch:0 step:541 [D loss: 0.524678, acc.: 76.56%] [G loss: 1.406572]\n",
      "epoch:0 step:542 [D loss: 0.472877, acc.: 79.69%] [G loss: 1.367519]\n",
      "epoch:0 step:543 [D loss: 0.580721, acc.: 65.62%] [G loss: 1.306572]\n",
      "epoch:0 step:544 [D loss: 0.604477, acc.: 67.19%] [G loss: 1.313359]\n",
      "epoch:0 step:545 [D loss: 0.597724, acc.: 67.19%] [G loss: 1.326654]\n",
      "epoch:0 step:546 [D loss: 0.619907, acc.: 65.62%] [G loss: 1.542205]\n",
      "epoch:0 step:547 [D loss: 0.615089, acc.: 67.97%] [G loss: 1.455076]\n",
      "epoch:0 step:548 [D loss: 0.565999, acc.: 71.88%] [G loss: 1.464322]\n",
      "epoch:0 step:549 [D loss: 0.699667, acc.: 54.69%] [G loss: 1.262612]\n",
      "epoch:0 step:550 [D loss: 0.575270, acc.: 73.44%] [G loss: 1.585484]\n",
      "epoch:0 step:551 [D loss: 0.601537, acc.: 71.88%] [G loss: 1.449858]\n",
      "epoch:0 step:552 [D loss: 0.675840, acc.: 63.28%] [G loss: 1.402117]\n",
      "epoch:0 step:553 [D loss: 0.633645, acc.: 65.62%] [G loss: 1.347329]\n",
      "epoch:0 step:554 [D loss: 0.517514, acc.: 72.66%] [G loss: 1.242607]\n",
      "epoch:0 step:555 [D loss: 0.601423, acc.: 66.41%] [G loss: 1.427885]\n",
      "epoch:0 step:556 [D loss: 0.624526, acc.: 68.75%] [G loss: 1.382255]\n",
      "epoch:0 step:557 [D loss: 0.484562, acc.: 74.22%] [G loss: 1.526316]\n",
      "epoch:0 step:558 [D loss: 0.613997, acc.: 63.28%] [G loss: 1.510938]\n",
      "epoch:0 step:559 [D loss: 0.596515, acc.: 71.09%] [G loss: 1.370237]\n",
      "epoch:0 step:560 [D loss: 0.657498, acc.: 64.84%] [G loss: 1.431466]\n",
      "epoch:0 step:561 [D loss: 0.550772, acc.: 70.31%] [G loss: 1.423721]\n",
      "epoch:0 step:562 [D loss: 0.613265, acc.: 64.84%] [G loss: 1.448455]\n",
      "epoch:0 step:563 [D loss: 0.678440, acc.: 63.28%] [G loss: 1.413842]\n",
      "epoch:0 step:564 [D loss: 0.641322, acc.: 67.19%] [G loss: 1.369141]\n",
      "epoch:0 step:565 [D loss: 0.643372, acc.: 63.28%] [G loss: 1.444678]\n",
      "epoch:0 step:566 [D loss: 0.505050, acc.: 74.22%] [G loss: 1.536450]\n",
      "epoch:0 step:567 [D loss: 0.609077, acc.: 71.09%] [G loss: 1.363502]\n",
      "epoch:0 step:568 [D loss: 0.614847, acc.: 69.53%] [G loss: 1.256710]\n",
      "epoch:0 step:569 [D loss: 0.526230, acc.: 73.44%] [G loss: 1.406922]\n",
      "epoch:0 step:570 [D loss: 0.570269, acc.: 72.66%] [G loss: 1.585198]\n",
      "epoch:0 step:571 [D loss: 0.513990, acc.: 75.78%] [G loss: 1.467024]\n",
      "epoch:0 step:572 [D loss: 0.525871, acc.: 75.00%] [G loss: 1.608883]\n",
      "epoch:0 step:573 [D loss: 0.510799, acc.: 74.22%] [G loss: 1.630568]\n",
      "epoch:0 step:574 [D loss: 0.566324, acc.: 72.66%] [G loss: 1.398314]\n",
      "epoch:0 step:575 [D loss: 0.589401, acc.: 67.97%] [G loss: 1.256743]\n",
      "epoch:0 step:576 [D loss: 0.505138, acc.: 77.34%] [G loss: 1.414855]\n",
      "epoch:0 step:577 [D loss: 0.602875, acc.: 71.88%] [G loss: 1.374356]\n",
      "epoch:0 step:578 [D loss: 0.525075, acc.: 72.66%] [G loss: 1.397438]\n",
      "epoch:0 step:579 [D loss: 0.544591, acc.: 74.22%] [G loss: 1.327618]\n",
      "epoch:0 step:580 [D loss: 0.730577, acc.: 57.03%] [G loss: 1.296454]\n",
      "epoch:0 step:581 [D loss: 0.576358, acc.: 68.75%] [G loss: 1.383724]\n",
      "epoch:0 step:582 [D loss: 0.546435, acc.: 69.53%] [G loss: 1.490676]\n",
      "epoch:0 step:583 [D loss: 0.720691, acc.: 62.50%] [G loss: 1.434768]\n",
      "epoch:0 step:584 [D loss: 0.549443, acc.: 71.88%] [G loss: 1.488081]\n",
      "epoch:0 step:585 [D loss: 0.562113, acc.: 71.88%] [G loss: 1.401398]\n",
      "epoch:0 step:586 [D loss: 0.648537, acc.: 62.50%] [G loss: 1.399690]\n",
      "epoch:0 step:587 [D loss: 0.637683, acc.: 60.94%] [G loss: 1.555943]\n",
      "epoch:0 step:588 [D loss: 0.583322, acc.: 69.53%] [G loss: 1.609995]\n",
      "epoch:0 step:589 [D loss: 0.455612, acc.: 80.47%] [G loss: 1.396203]\n",
      "epoch:0 step:590 [D loss: 0.615749, acc.: 66.41%] [G loss: 1.162205]\n",
      "epoch:0 step:591 [D loss: 0.593520, acc.: 64.84%] [G loss: 1.325735]\n",
      "epoch:0 step:592 [D loss: 0.570732, acc.: 72.66%] [G loss: 1.308254]\n",
      "epoch:0 step:593 [D loss: 0.655095, acc.: 64.84%] [G loss: 1.565549]\n",
      "epoch:0 step:594 [D loss: 0.442597, acc.: 82.81%] [G loss: 1.523669]\n",
      "epoch:0 step:595 [D loss: 0.505795, acc.: 78.91%] [G loss: 1.442681]\n",
      "epoch:0 step:596 [D loss: 0.513401, acc.: 75.78%] [G loss: 1.316595]\n",
      "epoch:0 step:597 [D loss: 0.612117, acc.: 69.53%] [G loss: 1.461040]\n",
      "epoch:0 step:598 [D loss: 0.674263, acc.: 60.94%] [G loss: 1.437033]\n",
      "epoch:0 step:599 [D loss: 0.586729, acc.: 74.22%] [G loss: 1.256640]\n",
      "epoch:0 step:600 [D loss: 0.460629, acc.: 78.91%] [G loss: 1.612041]\n",
      "epoch:0 step:601 [D loss: 0.589808, acc.: 72.66%] [G loss: 1.398942]\n",
      "epoch:0 step:602 [D loss: 0.479587, acc.: 76.56%] [G loss: 1.484680]\n",
      "epoch:0 step:603 [D loss: 0.630628, acc.: 66.41%] [G loss: 1.472395]\n",
      "epoch:0 step:604 [D loss: 0.680180, acc.: 66.41%] [G loss: 1.306418]\n",
      "epoch:0 step:605 [D loss: 0.523677, acc.: 74.22%] [G loss: 1.226632]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0 step:606 [D loss: 0.480253, acc.: 79.69%] [G loss: 1.352331]\n",
      "epoch:0 step:607 [D loss: 0.623561, acc.: 66.41%] [G loss: 1.267615]\n",
      "epoch:0 step:608 [D loss: 0.515059, acc.: 83.59%] [G loss: 1.816729]\n",
      "epoch:0 step:609 [D loss: 0.547004, acc.: 71.88%] [G loss: 1.599530]\n",
      "epoch:0 step:610 [D loss: 0.620875, acc.: 64.84%] [G loss: 1.514948]\n",
      "epoch:0 step:611 [D loss: 0.523229, acc.: 74.22%] [G loss: 1.493499]\n",
      "epoch:0 step:612 [D loss: 0.485658, acc.: 80.47%] [G loss: 1.460582]\n",
      "epoch:0 step:613 [D loss: 0.578901, acc.: 69.53%] [G loss: 1.478567]\n",
      "epoch:0 step:614 [D loss: 0.542229, acc.: 74.22%] [G loss: 1.558451]\n",
      "epoch:0 step:615 [D loss: 0.493886, acc.: 75.78%] [G loss: 1.622061]\n",
      "epoch:0 step:616 [D loss: 0.559003, acc.: 69.53%] [G loss: 1.431953]\n",
      "epoch:0 step:617 [D loss: 0.682954, acc.: 59.38%] [G loss: 1.470732]\n",
      "epoch:0 step:618 [D loss: 0.487797, acc.: 79.69%] [G loss: 1.566044]\n",
      "epoch:0 step:619 [D loss: 0.502760, acc.: 79.69%] [G loss: 1.465136]\n",
      "epoch:0 step:620 [D loss: 0.609004, acc.: 67.19%] [G loss: 1.455501]\n",
      "epoch:0 step:621 [D loss: 0.670589, acc.: 62.50%] [G loss: 1.527774]\n",
      "epoch:0 step:622 [D loss: 0.482692, acc.: 75.78%] [G loss: 1.706626]\n",
      "epoch:0 step:623 [D loss: 0.506635, acc.: 74.22%] [G loss: 1.676768]\n",
      "epoch:0 step:624 [D loss: 0.561186, acc.: 70.31%] [G loss: 1.295392]\n",
      "epoch:0 step:625 [D loss: 0.664884, acc.: 68.75%] [G loss: 1.375882]\n",
      "epoch:0 step:626 [D loss: 0.550205, acc.: 75.78%] [G loss: 1.492754]\n",
      "epoch:0 step:627 [D loss: 0.539492, acc.: 73.44%] [G loss: 1.676520]\n",
      "epoch:0 step:628 [D loss: 0.584114, acc.: 69.53%] [G loss: 1.426588]\n",
      "epoch:0 step:629 [D loss: 0.502516, acc.: 74.22%] [G loss: 1.465685]\n",
      "epoch:0 step:630 [D loss: 0.679099, acc.: 64.84%] [G loss: 1.361211]\n",
      "epoch:0 step:631 [D loss: 0.520845, acc.: 75.78%] [G loss: 1.543196]\n",
      "epoch:0 step:632 [D loss: 0.582815, acc.: 69.53%] [G loss: 1.528516]\n",
      "epoch:0 step:633 [D loss: 0.431789, acc.: 78.12%] [G loss: 1.440031]\n",
      "epoch:0 step:634 [D loss: 0.606481, acc.: 63.28%] [G loss: 1.713721]\n",
      "epoch:0 step:635 [D loss: 0.575474, acc.: 70.31%] [G loss: 1.600568]\n",
      "epoch:0 step:636 [D loss: 0.549482, acc.: 70.31%] [G loss: 1.749933]\n",
      "epoch:0 step:637 [D loss: 0.561609, acc.: 71.88%] [G loss: 1.635052]\n",
      "epoch:0 step:638 [D loss: 0.665176, acc.: 63.28%] [G loss: 1.388611]\n",
      "epoch:0 step:639 [D loss: 0.697950, acc.: 60.94%] [G loss: 1.342743]\n",
      "epoch:0 step:640 [D loss: 0.476012, acc.: 76.56%] [G loss: 1.508375]\n",
      "epoch:0 step:641 [D loss: 0.627324, acc.: 64.84%] [G loss: 1.549253]\n",
      "epoch:0 step:642 [D loss: 0.627665, acc.: 70.31%] [G loss: 1.367788]\n",
      "epoch:0 step:643 [D loss: 0.531353, acc.: 75.78%] [G loss: 1.265711]\n",
      "epoch:0 step:644 [D loss: 0.569332, acc.: 68.75%] [G loss: 1.537058]\n",
      "epoch:0 step:645 [D loss: 0.641977, acc.: 65.62%] [G loss: 1.577802]\n",
      "epoch:0 step:646 [D loss: 0.608926, acc.: 70.31%] [G loss: 1.336976]\n",
      "epoch:0 step:647 [D loss: 0.602768, acc.: 66.41%] [G loss: 1.317836]\n",
      "epoch:0 step:648 [D loss: 0.555221, acc.: 71.09%] [G loss: 1.541126]\n",
      "epoch:0 step:649 [D loss: 0.613394, acc.: 68.75%] [G loss: 1.126998]\n",
      "epoch:0 step:650 [D loss: 0.478515, acc.: 74.22%] [G loss: 1.432401]\n",
      "epoch:0 step:651 [D loss: 0.490496, acc.: 75.00%] [G loss: 1.281794]\n",
      "epoch:0 step:652 [D loss: 0.493120, acc.: 74.22%] [G loss: 1.533230]\n",
      "epoch:0 step:653 [D loss: 0.600111, acc.: 69.53%] [G loss: 1.466512]\n",
      "epoch:0 step:654 [D loss: 0.494077, acc.: 78.91%] [G loss: 1.626515]\n",
      "epoch:0 step:655 [D loss: 0.664491, acc.: 62.50%] [G loss: 1.425776]\n",
      "epoch:0 step:656 [D loss: 0.622865, acc.: 64.84%] [G loss: 1.337572]\n",
      "epoch:0 step:657 [D loss: 0.565971, acc.: 71.09%] [G loss: 1.346231]\n",
      "epoch:0 step:658 [D loss: 0.623780, acc.: 67.97%] [G loss: 1.306017]\n",
      "epoch:0 step:659 [D loss: 0.576364, acc.: 72.66%] [G loss: 1.461563]\n",
      "epoch:0 step:660 [D loss: 0.661832, acc.: 64.06%] [G loss: 1.309640]\n",
      "epoch:0 step:661 [D loss: 0.646271, acc.: 62.50%] [G loss: 1.173376]\n",
      "epoch:0 step:662 [D loss: 0.598521, acc.: 62.50%] [G loss: 1.477688]\n",
      "epoch:0 step:663 [D loss: 0.568881, acc.: 69.53%] [G loss: 1.216076]\n",
      "epoch:0 step:664 [D loss: 0.569752, acc.: 75.00%] [G loss: 1.466476]\n",
      "epoch:0 step:665 [D loss: 0.561463, acc.: 69.53%] [G loss: 1.562525]\n",
      "epoch:0 step:666 [D loss: 0.417287, acc.: 82.81%] [G loss: 1.643977]\n",
      "epoch:0 step:667 [D loss: 0.588116, acc.: 68.75%] [G loss: 1.373635]\n",
      "epoch:0 step:668 [D loss: 0.721461, acc.: 57.03%] [G loss: 1.210762]\n",
      "epoch:0 step:669 [D loss: 0.555946, acc.: 72.66%] [G loss: 1.415517]\n",
      "epoch:0 step:670 [D loss: 0.592703, acc.: 69.53%] [G loss: 1.369275]\n",
      "epoch:0 step:671 [D loss: 0.521272, acc.: 76.56%] [G loss: 1.658868]\n",
      "epoch:0 step:672 [D loss: 0.729432, acc.: 58.59%] [G loss: 1.443698]\n",
      "epoch:0 step:673 [D loss: 0.645494, acc.: 66.41%] [G loss: 1.273358]\n",
      "epoch:0 step:674 [D loss: 0.620963, acc.: 66.41%] [G loss: 1.508502]\n",
      "epoch:0 step:675 [D loss: 0.523916, acc.: 71.88%] [G loss: 1.573858]\n",
      "epoch:0 step:676 [D loss: 0.642718, acc.: 60.94%] [G loss: 1.420229]\n",
      "epoch:0 step:677 [D loss: 0.687398, acc.: 55.47%] [G loss: 1.539554]\n",
      "epoch:0 step:678 [D loss: 0.626976, acc.: 65.62%] [G loss: 1.324290]\n",
      "epoch:0 step:679 [D loss: 0.594265, acc.: 75.00%] [G loss: 1.529903]\n",
      "epoch:0 step:680 [D loss: 0.606446, acc.: 71.09%] [G loss: 1.466212]\n",
      "epoch:0 step:681 [D loss: 0.509097, acc.: 77.34%] [G loss: 1.558059]\n",
      "epoch:0 step:682 [D loss: 0.620603, acc.: 63.28%] [G loss: 1.546632]\n",
      "epoch:0 step:683 [D loss: 0.526629, acc.: 76.56%] [G loss: 1.618032]\n",
      "epoch:0 step:684 [D loss: 0.663665, acc.: 61.72%] [G loss: 1.276529]\n",
      "epoch:0 step:685 [D loss: 0.542495, acc.: 67.19%] [G loss: 1.554904]\n",
      "epoch:0 step:686 [D loss: 0.684296, acc.: 62.50%] [G loss: 1.358204]\n",
      "epoch:0 step:687 [D loss: 0.579104, acc.: 70.31%] [G loss: 1.438756]\n",
      "epoch:0 step:688 [D loss: 0.574156, acc.: 68.75%] [G loss: 1.646361]\n",
      "epoch:0 step:689 [D loss: 0.617736, acc.: 65.62%] [G loss: 1.298143]\n",
      "epoch:0 step:690 [D loss: 0.644934, acc.: 64.84%] [G loss: 1.327568]\n",
      "epoch:0 step:691 [D loss: 0.639773, acc.: 64.06%] [G loss: 1.421083]\n",
      "epoch:0 step:692 [D loss: 0.574324, acc.: 65.62%] [G loss: 1.348502]\n",
      "epoch:0 step:693 [D loss: 0.655146, acc.: 65.62%] [G loss: 1.184620]\n",
      "epoch:0 step:694 [D loss: 0.621340, acc.: 67.19%] [G loss: 1.251143]\n",
      "epoch:0 step:695 [D loss: 0.612065, acc.: 65.62%] [G loss: 1.361055]\n",
      "epoch:0 step:696 [D loss: 0.593296, acc.: 67.19%] [G loss: 1.485853]\n",
      "epoch:0 step:697 [D loss: 0.514630, acc.: 72.66%] [G loss: 1.390312]\n",
      "epoch:0 step:698 [D loss: 0.570246, acc.: 67.97%] [G loss: 1.294392]\n",
      "epoch:0 step:699 [D loss: 0.671996, acc.: 62.50%] [G loss: 1.386692]\n",
      "epoch:0 step:700 [D loss: 0.603177, acc.: 68.75%] [G loss: 1.260857]\n",
      "epoch:0 step:701 [D loss: 0.630942, acc.: 66.41%] [G loss: 1.504156]\n",
      "epoch:0 step:702 [D loss: 0.556656, acc.: 71.09%] [G loss: 1.563975]\n",
      "epoch:0 step:703 [D loss: 0.618533, acc.: 68.75%] [G loss: 1.200936]\n",
      "epoch:0 step:704 [D loss: 0.639113, acc.: 63.28%] [G loss: 1.521604]\n",
      "epoch:0 step:705 [D loss: 0.654022, acc.: 63.28%] [G loss: 1.367465]\n",
      "epoch:0 step:706 [D loss: 0.766000, acc.: 54.69%] [G loss: 1.160302]\n",
      "epoch:0 step:707 [D loss: 0.537271, acc.: 71.09%] [G loss: 1.663941]\n",
      "epoch:0 step:708 [D loss: 0.749919, acc.: 53.91%] [G loss: 1.283425]\n",
      "epoch:0 step:709 [D loss: 0.681510, acc.: 57.03%] [G loss: 1.445122]\n",
      "epoch:0 step:710 [D loss: 0.649402, acc.: 66.41%] [G loss: 1.444458]\n",
      "epoch:0 step:711 [D loss: 0.562961, acc.: 69.53%] [G loss: 1.559535]\n",
      "epoch:0 step:712 [D loss: 0.740301, acc.: 60.16%] [G loss: 1.369466]\n",
      "epoch:0 step:713 [D loss: 0.557132, acc.: 71.88%] [G loss: 1.284200]\n",
      "epoch:0 step:714 [D loss: 0.611902, acc.: 63.28%] [G loss: 1.292404]\n",
      "epoch:0 step:715 [D loss: 0.562191, acc.: 71.09%] [G loss: 1.398229]\n",
      "epoch:0 step:716 [D loss: 0.661435, acc.: 66.41%] [G loss: 1.259502]\n",
      "epoch:0 step:717 [D loss: 0.559371, acc.: 69.53%] [G loss: 1.348761]\n",
      "epoch:0 step:718 [D loss: 0.586157, acc.: 69.53%] [G loss: 1.267723]\n",
      "epoch:0 step:719 [D loss: 0.540103, acc.: 76.56%] [G loss: 1.190349]\n",
      "epoch:0 step:720 [D loss: 0.703816, acc.: 59.38%] [G loss: 1.393003]\n",
      "epoch:0 step:721 [D loss: 0.652906, acc.: 64.84%] [G loss: 1.427950]\n",
      "epoch:0 step:722 [D loss: 0.668700, acc.: 64.06%] [G loss: 1.495855]\n",
      "epoch:0 step:723 [D loss: 0.753608, acc.: 57.81%] [G loss: 1.007236]\n",
      "epoch:0 step:724 [D loss: 0.640220, acc.: 67.19%] [G loss: 1.323357]\n",
      "epoch:0 step:725 [D loss: 0.644327, acc.: 64.06%] [G loss: 1.378225]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0 step:726 [D loss: 0.541268, acc.: 72.66%] [G loss: 1.608533]\n",
      "epoch:0 step:727 [D loss: 0.624748, acc.: 64.06%] [G loss: 1.392166]\n",
      "epoch:0 step:728 [D loss: 0.686153, acc.: 60.16%] [G loss: 1.472081]\n",
      "epoch:0 step:729 [D loss: 0.714354, acc.: 58.59%] [G loss: 1.444057]\n",
      "epoch:0 step:730 [D loss: 0.617446, acc.: 64.06%] [G loss: 1.450606]\n",
      "epoch:0 step:731 [D loss: 0.697700, acc.: 61.72%] [G loss: 1.115328]\n",
      "epoch:0 step:732 [D loss: 0.652286, acc.: 64.84%] [G loss: 1.085765]\n",
      "epoch:0 step:733 [D loss: 0.699193, acc.: 53.91%] [G loss: 1.100386]\n",
      "epoch:0 step:734 [D loss: 0.500306, acc.: 77.34%] [G loss: 1.383259]\n",
      "epoch:0 step:735 [D loss: 0.559584, acc.: 71.88%] [G loss: 1.531255]\n",
      "epoch:0 step:736 [D loss: 0.668705, acc.: 62.50%] [G loss: 1.225948]\n",
      "epoch:0 step:737 [D loss: 0.621553, acc.: 61.72%] [G loss: 1.176630]\n",
      "epoch:0 step:738 [D loss: 0.690325, acc.: 60.94%] [G loss: 1.138630]\n",
      "epoch:0 step:739 [D loss: 0.615466, acc.: 63.28%] [G loss: 1.447729]\n",
      "epoch:0 step:740 [D loss: 0.601928, acc.: 71.88%] [G loss: 1.396373]\n",
      "epoch:0 step:741 [D loss: 0.674131, acc.: 53.91%] [G loss: 1.158194]\n",
      "epoch:0 step:742 [D loss: 0.654405, acc.: 61.72%] [G loss: 1.190677]\n",
      "epoch:0 step:743 [D loss: 0.677683, acc.: 61.72%] [G loss: 1.310022]\n",
      "epoch:0 step:744 [D loss: 0.681903, acc.: 63.28%] [G loss: 1.524497]\n",
      "epoch:0 step:745 [D loss: 0.702126, acc.: 57.81%] [G loss: 1.429706]\n",
      "epoch:0 step:746 [D loss: 0.695724, acc.: 56.25%] [G loss: 1.281434]\n",
      "epoch:0 step:747 [D loss: 0.689802, acc.: 60.16%] [G loss: 1.341665]\n",
      "epoch:0 step:748 [D loss: 0.675135, acc.: 60.94%] [G loss: 1.263099]\n",
      "epoch:0 step:749 [D loss: 0.692145, acc.: 60.16%] [G loss: 1.319986]\n",
      "epoch:0 step:750 [D loss: 0.624702, acc.: 60.94%] [G loss: 1.184502]\n",
      "epoch:0 step:751 [D loss: 0.802589, acc.: 47.66%] [G loss: 1.176666]\n",
      "epoch:0 step:752 [D loss: 0.618458, acc.: 67.97%] [G loss: 1.331188]\n",
      "epoch:0 step:753 [D loss: 0.553284, acc.: 67.97%] [G loss: 1.600016]\n",
      "epoch:0 step:754 [D loss: 0.735836, acc.: 53.91%] [G loss: 1.318807]\n",
      "epoch:0 step:755 [D loss: 0.605121, acc.: 69.53%] [G loss: 1.324694]\n",
      "epoch:0 step:756 [D loss: 0.605017, acc.: 68.75%] [G loss: 1.348566]\n",
      "epoch:0 step:757 [D loss: 0.703170, acc.: 57.81%] [G loss: 1.225963]\n",
      "epoch:0 step:758 [D loss: 0.602771, acc.: 69.53%] [G loss: 1.401001]\n",
      "epoch:0 step:759 [D loss: 0.626233, acc.: 72.66%] [G loss: 1.443325]\n",
      "epoch:0 step:760 [D loss: 0.715002, acc.: 57.03%] [G loss: 1.249606]\n",
      "epoch:0 step:761 [D loss: 0.648796, acc.: 67.19%] [G loss: 1.394562]\n",
      "epoch:0 step:762 [D loss: 0.691828, acc.: 57.81%] [G loss: 1.258814]\n",
      "epoch:0 step:763 [D loss: 0.646751, acc.: 60.94%] [G loss: 1.240566]\n",
      "epoch:0 step:764 [D loss: 0.637343, acc.: 62.50%] [G loss: 1.404132]\n",
      "epoch:0 step:765 [D loss: 0.715800, acc.: 59.38%] [G loss: 1.273922]\n",
      "epoch:0 step:766 [D loss: 0.530577, acc.: 75.00%] [G loss: 1.436156]\n",
      "epoch:0 step:767 [D loss: 0.611874, acc.: 62.50%] [G loss: 1.212304]\n",
      "epoch:0 step:768 [D loss: 0.598604, acc.: 65.62%] [G loss: 1.193991]\n",
      "epoch:0 step:769 [D loss: 0.639422, acc.: 64.06%] [G loss: 1.327385]\n",
      "epoch:0 step:770 [D loss: 0.682841, acc.: 60.16%] [G loss: 1.073878]\n",
      "epoch:0 step:771 [D loss: 0.635480, acc.: 62.50%] [G loss: 1.666214]\n",
      "epoch:0 step:772 [D loss: 0.614822, acc.: 67.97%] [G loss: 1.337519]\n",
      "epoch:0 step:773 [D loss: 0.672381, acc.: 60.94%] [G loss: 1.222537]\n",
      "epoch:0 step:774 [D loss: 0.647448, acc.: 62.50%] [G loss: 1.337879]\n",
      "epoch:0 step:775 [D loss: 0.735150, acc.: 55.47%] [G loss: 1.214867]\n",
      "epoch:0 step:776 [D loss: 0.699181, acc.: 63.28%] [G loss: 1.205598]\n",
      "epoch:0 step:777 [D loss: 0.670826, acc.: 64.06%] [G loss: 1.237527]\n",
      "epoch:0 step:778 [D loss: 0.712435, acc.: 60.16%] [G loss: 1.244150]\n",
      "epoch:0 step:779 [D loss: 0.740382, acc.: 56.25%] [G loss: 1.496463]\n",
      "epoch:0 step:780 [D loss: 0.734480, acc.: 62.50%] [G loss: 1.295041]\n",
      "epoch:0 step:781 [D loss: 0.608851, acc.: 67.97%] [G loss: 1.396736]\n",
      "epoch:0 step:782 [D loss: 0.643384, acc.: 63.28%] [G loss: 1.130147]\n",
      "epoch:0 step:783 [D loss: 0.646124, acc.: 60.94%] [G loss: 1.241693]\n",
      "epoch:0 step:784 [D loss: 0.804620, acc.: 53.12%] [G loss: 1.379442]\n",
      "epoch:0 step:785 [D loss: 0.681379, acc.: 60.16%] [G loss: 1.350612]\n",
      "epoch:0 step:786 [D loss: 0.743484, acc.: 53.91%] [G loss: 1.194855]\n",
      "epoch:0 step:787 [D loss: 0.724577, acc.: 57.81%] [G loss: 1.090174]\n",
      "epoch:0 step:788 [D loss: 0.654538, acc.: 61.72%] [G loss: 1.007465]\n",
      "epoch:0 step:789 [D loss: 0.561586, acc.: 70.31%] [G loss: 1.360891]\n",
      "epoch:0 step:790 [D loss: 0.740632, acc.: 54.69%] [G loss: 1.420688]\n",
      "epoch:0 step:791 [D loss: 0.657346, acc.: 58.59%] [G loss: 1.406607]\n",
      "epoch:0 step:792 [D loss: 0.695262, acc.: 56.25%] [G loss: 1.110412]\n",
      "epoch:0 step:793 [D loss: 0.716638, acc.: 60.94%] [G loss: 1.261467]\n",
      "epoch:0 step:794 [D loss: 0.578415, acc.: 67.97%] [G loss: 1.513769]\n",
      "epoch:0 step:795 [D loss: 0.614508, acc.: 67.97%] [G loss: 1.365866]\n",
      "epoch:0 step:796 [D loss: 0.643488, acc.: 65.62%] [G loss: 1.249536]\n",
      "epoch:0 step:797 [D loss: 0.697880, acc.: 58.59%] [G loss: 1.197654]\n",
      "epoch:0 step:798 [D loss: 0.595992, acc.: 70.31%] [G loss: 1.210419]\n",
      "epoch:0 step:799 [D loss: 0.665112, acc.: 61.72%] [G loss: 1.281556]\n",
      "epoch:0 step:800 [D loss: 0.695637, acc.: 55.47%] [G loss: 1.287170]\n",
      "epoch:0 step:801 [D loss: 0.630529, acc.: 64.84%] [G loss: 1.141829]\n",
      "epoch:0 step:802 [D loss: 0.681522, acc.: 58.59%] [G loss: 1.346081]\n",
      "epoch:0 step:803 [D loss: 0.764920, acc.: 53.12%] [G loss: 1.196022]\n",
      "epoch:0 step:804 [D loss: 0.636592, acc.: 65.62%] [G loss: 1.125468]\n",
      "epoch:0 step:805 [D loss: 0.746858, acc.: 53.12%] [G loss: 1.024622]\n",
      "epoch:0 step:806 [D loss: 0.600971, acc.: 67.19%] [G loss: 1.270287]\n",
      "epoch:0 step:807 [D loss: 0.677496, acc.: 60.16%] [G loss: 1.132235]\n",
      "epoch:0 step:808 [D loss: 0.665209, acc.: 60.94%] [G loss: 1.073605]\n",
      "epoch:0 step:809 [D loss: 0.585769, acc.: 69.53%] [G loss: 1.476361]\n",
      "epoch:0 step:810 [D loss: 0.509799, acc.: 74.22%] [G loss: 1.412341]\n",
      "epoch:0 step:811 [D loss: 0.616906, acc.: 69.53%] [G loss: 1.201374]\n",
      "epoch:0 step:812 [D loss: 0.537832, acc.: 72.66%] [G loss: 1.320069]\n",
      "epoch:0 step:813 [D loss: 0.633431, acc.: 61.72%] [G loss: 1.314667]\n",
      "epoch:0 step:814 [D loss: 0.619965, acc.: 64.84%] [G loss: 1.182960]\n",
      "epoch:0 step:815 [D loss: 0.662192, acc.: 58.59%] [G loss: 1.067144]\n",
      "epoch:0 step:816 [D loss: 0.581877, acc.: 66.41%] [G loss: 1.579863]\n",
      "epoch:0 step:817 [D loss: 0.662615, acc.: 63.28%] [G loss: 1.418712]\n",
      "epoch:0 step:818 [D loss: 0.756419, acc.: 52.34%] [G loss: 1.048937]\n",
      "epoch:0 step:819 [D loss: 0.763480, acc.: 52.34%] [G loss: 1.097461]\n",
      "epoch:0 step:820 [D loss: 0.714447, acc.: 57.81%] [G loss: 1.223283]\n",
      "epoch:0 step:821 [D loss: 0.708154, acc.: 57.81%] [G loss: 1.170386]\n",
      "epoch:0 step:822 [D loss: 0.708355, acc.: 58.59%] [G loss: 1.380667]\n",
      "epoch:0 step:823 [D loss: 0.687771, acc.: 56.25%] [G loss: 1.143424]\n",
      "epoch:0 step:824 [D loss: 0.613528, acc.: 67.19%] [G loss: 1.127857]\n",
      "epoch:0 step:825 [D loss: 0.654162, acc.: 58.59%] [G loss: 1.186957]\n",
      "epoch:0 step:826 [D loss: 0.645427, acc.: 62.50%] [G loss: 1.219155]\n",
      "epoch:0 step:827 [D loss: 0.675622, acc.: 61.72%] [G loss: 1.316923]\n",
      "epoch:0 step:828 [D loss: 0.745623, acc.: 53.91%] [G loss: 1.068100]\n",
      "epoch:0 step:829 [D loss: 0.739416, acc.: 53.12%] [G loss: 1.066647]\n",
      "epoch:0 step:830 [D loss: 0.666620, acc.: 60.94%] [G loss: 1.110884]\n",
      "epoch:0 step:831 [D loss: 0.655505, acc.: 54.69%] [G loss: 1.203823]\n",
      "epoch:0 step:832 [D loss: 0.674819, acc.: 60.16%] [G loss: 1.345278]\n",
      "epoch:0 step:833 [D loss: 0.809541, acc.: 54.69%] [G loss: 1.258472]\n",
      "epoch:0 step:834 [D loss: 0.629887, acc.: 64.84%] [G loss: 1.161724]\n",
      "epoch:0 step:835 [D loss: 0.632075, acc.: 63.28%] [G loss: 1.322890]\n",
      "epoch:0 step:836 [D loss: 0.712348, acc.: 57.81%] [G loss: 1.273671]\n",
      "epoch:0 step:837 [D loss: 0.686371, acc.: 60.16%] [G loss: 1.236654]\n",
      "epoch:0 step:838 [D loss: 0.693396, acc.: 55.47%] [G loss: 1.187775]\n",
      "epoch:0 step:839 [D loss: 0.666081, acc.: 62.50%] [G loss: 1.290343]\n",
      "epoch:0 step:840 [D loss: 0.637046, acc.: 67.19%] [G loss: 1.038463]\n",
      "epoch:0 step:841 [D loss: 0.597766, acc.: 67.19%] [G loss: 1.341752]\n",
      "epoch:0 step:842 [D loss: 0.713621, acc.: 55.47%] [G loss: 1.149309]\n",
      "epoch:0 step:843 [D loss: 0.560536, acc.: 67.19%] [G loss: 1.349523]\n",
      "epoch:0 step:844 [D loss: 0.699669, acc.: 55.47%] [G loss: 1.225901]\n",
      "epoch:0 step:845 [D loss: 0.619962, acc.: 67.97%] [G loss: 1.131088]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0 step:846 [D loss: 0.676247, acc.: 60.94%] [G loss: 1.126432]\n",
      "epoch:0 step:847 [D loss: 0.664687, acc.: 60.16%] [G loss: 1.318038]\n",
      "epoch:0 step:848 [D loss: 0.692286, acc.: 57.03%] [G loss: 1.186935]\n",
      "epoch:0 step:849 [D loss: 0.570546, acc.: 68.75%] [G loss: 1.389122]\n",
      "epoch:0 step:850 [D loss: 0.626907, acc.: 66.41%] [G loss: 1.093586]\n",
      "epoch:0 step:851 [D loss: 0.736889, acc.: 54.69%] [G loss: 1.078016]\n",
      "epoch:0 step:852 [D loss: 0.545638, acc.: 71.09%] [G loss: 1.364219]\n",
      "epoch:0 step:853 [D loss: 0.665161, acc.: 59.38%] [G loss: 1.264614]\n",
      "epoch:0 step:854 [D loss: 0.643979, acc.: 57.03%] [G loss: 1.221511]\n",
      "epoch:0 step:855 [D loss: 0.653374, acc.: 66.41%] [G loss: 1.134705]\n",
      "epoch:0 step:856 [D loss: 0.648148, acc.: 67.97%] [G loss: 1.095306]\n",
      "epoch:0 step:857 [D loss: 0.701146, acc.: 64.84%] [G loss: 1.114272]\n",
      "epoch:0 step:858 [D loss: 0.735106, acc.: 60.94%] [G loss: 1.263461]\n",
      "epoch:0 step:859 [D loss: 0.607214, acc.: 69.53%] [G loss: 1.347562]\n",
      "epoch:0 step:860 [D loss: 0.623989, acc.: 71.88%] [G loss: 1.175452]\n",
      "epoch:0 step:861 [D loss: 0.623325, acc.: 67.19%] [G loss: 1.313021]\n",
      "epoch:0 step:862 [D loss: 0.575965, acc.: 72.66%] [G loss: 1.265594]\n",
      "epoch:0 step:863 [D loss: 0.779409, acc.: 50.00%] [G loss: 1.052746]\n",
      "epoch:0 step:864 [D loss: 0.719372, acc.: 54.69%] [G loss: 1.010385]\n",
      "epoch:0 step:865 [D loss: 0.539440, acc.: 73.44%] [G loss: 1.242556]\n",
      "epoch:0 step:866 [D loss: 0.762858, acc.: 57.03%] [G loss: 1.158073]\n",
      "epoch:0 step:867 [D loss: 0.679303, acc.: 61.72%] [G loss: 1.181728]\n",
      "epoch:0 step:868 [D loss: 0.632270, acc.: 66.41%] [G loss: 1.145941]\n",
      "epoch:0 step:869 [D loss: 0.644006, acc.: 61.72%] [G loss: 1.261938]\n",
      "epoch:0 step:870 [D loss: 0.665023, acc.: 60.94%] [G loss: 1.121473]\n",
      "epoch:0 step:871 [D loss: 0.629389, acc.: 64.06%] [G loss: 1.266635]\n",
      "epoch:0 step:872 [D loss: 0.736434, acc.: 55.47%] [G loss: 1.044278]\n",
      "epoch:0 step:873 [D loss: 0.679488, acc.: 58.59%] [G loss: 1.073584]\n",
      "epoch:0 step:874 [D loss: 0.676632, acc.: 59.38%] [G loss: 1.092050]\n",
      "epoch:0 step:875 [D loss: 0.652760, acc.: 64.06%] [G loss: 1.159500]\n",
      "epoch:0 step:876 [D loss: 0.618590, acc.: 61.72%] [G loss: 1.111199]\n",
      "epoch:0 step:877 [D loss: 0.609549, acc.: 64.84%] [G loss: 1.208671]\n",
      "epoch:0 step:878 [D loss: 0.688702, acc.: 59.38%] [G loss: 1.104098]\n",
      "epoch:0 step:879 [D loss: 0.663304, acc.: 67.19%] [G loss: 1.188468]\n",
      "epoch:0 step:880 [D loss: 0.668281, acc.: 60.16%] [G loss: 1.252006]\n",
      "epoch:0 step:881 [D loss: 0.672582, acc.: 57.81%] [G loss: 1.151205]\n",
      "epoch:0 step:882 [D loss: 0.679542, acc.: 57.03%] [G loss: 1.168698]\n",
      "epoch:0 step:883 [D loss: 0.673824, acc.: 60.94%] [G loss: 1.104052]\n",
      "epoch:0 step:884 [D loss: 0.621026, acc.: 65.62%] [G loss: 1.199382]\n",
      "epoch:0 step:885 [D loss: 0.684511, acc.: 57.81%] [G loss: 1.334722]\n",
      "epoch:0 step:886 [D loss: 0.651064, acc.: 63.28%] [G loss: 1.288100]\n",
      "epoch:0 step:887 [D loss: 0.713189, acc.: 55.47%] [G loss: 1.337498]\n",
      "epoch:0 step:888 [D loss: 0.733561, acc.: 54.69%] [G loss: 1.134329]\n",
      "epoch:0 step:889 [D loss: 0.633669, acc.: 67.97%] [G loss: 1.193626]\n",
      "epoch:0 step:890 [D loss: 0.665574, acc.: 58.59%] [G loss: 1.117369]\n",
      "epoch:0 step:891 [D loss: 0.696844, acc.: 60.16%] [G loss: 1.221157]\n",
      "epoch:0 step:892 [D loss: 0.716550, acc.: 60.94%] [G loss: 1.164742]\n",
      "epoch:0 step:893 [D loss: 0.654595, acc.: 60.94%] [G loss: 1.201424]\n",
      "epoch:0 step:894 [D loss: 0.733425, acc.: 55.47%] [G loss: 0.946891]\n",
      "epoch:0 step:895 [D loss: 0.708459, acc.: 63.28%] [G loss: 1.176028]\n",
      "epoch:0 step:896 [D loss: 0.682835, acc.: 61.72%] [G loss: 1.223613]\n",
      "epoch:0 step:897 [D loss: 0.640881, acc.: 67.19%] [G loss: 1.201413]\n",
      "epoch:0 step:898 [D loss: 0.645707, acc.: 60.16%] [G loss: 1.197753]\n",
      "epoch:0 step:899 [D loss: 0.672498, acc.: 61.72%] [G loss: 1.107037]\n",
      "epoch:0 step:900 [D loss: 0.681817, acc.: 56.25%] [G loss: 0.988068]\n",
      "epoch:0 step:901 [D loss: 0.570113, acc.: 68.75%] [G loss: 1.052277]\n",
      "epoch:0 step:902 [D loss: 0.640574, acc.: 63.28%] [G loss: 1.408292]\n",
      "epoch:0 step:903 [D loss: 0.643788, acc.: 62.50%] [G loss: 1.141618]\n",
      "epoch:0 step:904 [D loss: 0.571473, acc.: 71.09%] [G loss: 0.908270]\n",
      "epoch:0 step:905 [D loss: 0.687447, acc.: 57.81%] [G loss: 1.229651]\n",
      "epoch:0 step:906 [D loss: 0.650081, acc.: 65.62%] [G loss: 1.232540]\n",
      "epoch:0 step:907 [D loss: 0.541427, acc.: 76.56%] [G loss: 1.299041]\n",
      "epoch:0 step:908 [D loss: 0.621720, acc.: 64.06%] [G loss: 1.107562]\n",
      "epoch:0 step:909 [D loss: 0.590327, acc.: 69.53%] [G loss: 1.122190]\n",
      "epoch:0 step:910 [D loss: 0.650106, acc.: 65.62%] [G loss: 1.105678]\n",
      "epoch:0 step:911 [D loss: 0.700902, acc.: 57.03%] [G loss: 0.995807]\n",
      "epoch:0 step:912 [D loss: 0.658091, acc.: 60.16%] [G loss: 1.131994]\n",
      "epoch:0 step:913 [D loss: 0.795138, acc.: 55.47%] [G loss: 1.158378]\n",
      "epoch:0 step:914 [D loss: 0.704546, acc.: 61.72%] [G loss: 1.033672]\n",
      "epoch:0 step:915 [D loss: 0.652413, acc.: 64.84%] [G loss: 1.177678]\n",
      "epoch:0 step:916 [D loss: 0.616551, acc.: 66.41%] [G loss: 1.202067]\n",
      "epoch:0 step:917 [D loss: 0.687134, acc.: 61.72%] [G loss: 1.227823]\n",
      "epoch:0 step:918 [D loss: 0.634301, acc.: 62.50%] [G loss: 1.194618]\n",
      "epoch:0 step:919 [D loss: 0.501682, acc.: 76.56%] [G loss: 1.164630]\n",
      "epoch:0 step:920 [D loss: 0.690212, acc.: 58.59%] [G loss: 1.143593]\n",
      "epoch:0 step:921 [D loss: 0.739525, acc.: 53.91%] [G loss: 1.053734]\n",
      "epoch:0 step:922 [D loss: 0.684085, acc.: 60.16%] [G loss: 1.052957]\n",
      "epoch:0 step:923 [D loss: 0.693613, acc.: 56.25%] [G loss: 1.171533]\n",
      "epoch:0 step:924 [D loss: 0.832393, acc.: 46.88%] [G loss: 0.965251]\n",
      "epoch:0 step:925 [D loss: 0.626869, acc.: 67.97%] [G loss: 1.123989]\n",
      "epoch:0 step:926 [D loss: 0.652467, acc.: 65.62%] [G loss: 1.232743]\n",
      "epoch:0 step:927 [D loss: 0.649497, acc.: 61.72%] [G loss: 1.180763]\n",
      "epoch:0 step:928 [D loss: 0.691234, acc.: 57.03%] [G loss: 1.067769]\n",
      "epoch:0 step:929 [D loss: 0.624350, acc.: 63.28%] [G loss: 1.279634]\n",
      "epoch:0 step:930 [D loss: 0.578392, acc.: 70.31%] [G loss: 1.222831]\n",
      "epoch:0 step:931 [D loss: 0.621520, acc.: 66.41%] [G loss: 1.380878]\n",
      "epoch:0 step:932 [D loss: 0.691562, acc.: 60.16%] [G loss: 1.178524]\n",
      "epoch:0 step:933 [D loss: 0.598739, acc.: 64.06%] [G loss: 1.235293]\n",
      "epoch:0 step:934 [D loss: 0.652769, acc.: 60.94%] [G loss: 1.134192]\n",
      "epoch:0 step:935 [D loss: 0.635184, acc.: 60.94%] [G loss: 1.091707]\n",
      "epoch:0 step:936 [D loss: 0.655435, acc.: 62.50%] [G loss: 1.088253]\n",
      "epoch:0 step:937 [D loss: 0.626467, acc.: 64.06%] [G loss: 1.209421]\n",
      "epoch:1 step:938 [D loss: 0.621549, acc.: 65.62%] [G loss: 1.236598]\n",
      "epoch:1 step:939 [D loss: 0.674211, acc.: 59.38%] [G loss: 1.225095]\n",
      "epoch:1 step:940 [D loss: 0.657714, acc.: 66.41%] [G loss: 1.171048]\n",
      "epoch:1 step:941 [D loss: 0.614533, acc.: 72.66%] [G loss: 1.237192]\n",
      "epoch:1 step:942 [D loss: 0.592239, acc.: 73.44%] [G loss: 1.162321]\n",
      "epoch:1 step:943 [D loss: 0.698566, acc.: 56.25%] [G loss: 1.231924]\n",
      "epoch:1 step:944 [D loss: 0.642635, acc.: 60.16%] [G loss: 1.226720]\n",
      "epoch:1 step:945 [D loss: 0.725821, acc.: 57.03%] [G loss: 0.979107]\n",
      "epoch:1 step:946 [D loss: 0.701650, acc.: 57.81%] [G loss: 1.079444]\n",
      "epoch:1 step:947 [D loss: 0.573798, acc.: 67.19%] [G loss: 1.325049]\n",
      "epoch:1 step:948 [D loss: 0.725893, acc.: 60.94%] [G loss: 1.255814]\n",
      "epoch:1 step:949 [D loss: 0.683520, acc.: 54.69%] [G loss: 1.003726]\n",
      "epoch:1 step:950 [D loss: 0.640941, acc.: 58.59%] [G loss: 1.384482]\n",
      "epoch:1 step:951 [D loss: 0.653404, acc.: 56.25%] [G loss: 1.121448]\n",
      "epoch:1 step:952 [D loss: 0.681555, acc.: 63.28%] [G loss: 1.070282]\n",
      "epoch:1 step:953 [D loss: 0.636011, acc.: 60.16%] [G loss: 1.176716]\n",
      "epoch:1 step:954 [D loss: 0.644204, acc.: 64.06%] [G loss: 1.378570]\n",
      "epoch:1 step:955 [D loss: 0.634632, acc.: 64.84%] [G loss: 1.302776]\n",
      "epoch:1 step:956 [D loss: 0.681334, acc.: 62.50%] [G loss: 1.043683]\n",
      "epoch:1 step:957 [D loss: 0.693884, acc.: 61.72%] [G loss: 1.148979]\n",
      "epoch:1 step:958 [D loss: 0.557811, acc.: 71.09%] [G loss: 1.124835]\n",
      "epoch:1 step:959 [D loss: 0.667230, acc.: 62.50%] [G loss: 1.114363]\n",
      "epoch:1 step:960 [D loss: 0.672854, acc.: 60.94%] [G loss: 1.114446]\n",
      "epoch:1 step:961 [D loss: 0.654314, acc.: 61.72%] [G loss: 1.172614]\n",
      "epoch:1 step:962 [D loss: 0.622878, acc.: 65.62%] [G loss: 1.076249]\n",
      "epoch:1 step:963 [D loss: 0.578674, acc.: 71.09%] [G loss: 1.080257]\n",
      "epoch:1 step:964 [D loss: 0.679257, acc.: 58.59%] [G loss: 1.347927]\n",
      "epoch:1 step:965 [D loss: 0.660015, acc.: 60.16%] [G loss: 1.099193]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:1 step:966 [D loss: 0.593085, acc.: 71.09%] [G loss: 1.138946]\n",
      "epoch:1 step:967 [D loss: 0.669924, acc.: 61.72%] [G loss: 1.078130]\n",
      "epoch:1 step:968 [D loss: 0.538955, acc.: 72.66%] [G loss: 1.208202]\n",
      "epoch:1 step:969 [D loss: 0.648515, acc.: 64.06%] [G loss: 1.148051]\n",
      "epoch:1 step:970 [D loss: 0.682112, acc.: 57.03%] [G loss: 0.993960]\n",
      "epoch:1 step:971 [D loss: 0.697817, acc.: 55.47%] [G loss: 1.209823]\n",
      "epoch:1 step:972 [D loss: 0.627469, acc.: 63.28%] [G loss: 1.154301]\n",
      "epoch:1 step:973 [D loss: 0.559360, acc.: 69.53%] [G loss: 1.258118]\n",
      "epoch:1 step:974 [D loss: 0.727022, acc.: 58.59%] [G loss: 1.179628]\n",
      "epoch:1 step:975 [D loss: 0.751946, acc.: 57.03%] [G loss: 1.410855]\n",
      "epoch:1 step:976 [D loss: 0.727003, acc.: 54.69%] [G loss: 1.046148]\n",
      "epoch:1 step:977 [D loss: 0.797931, acc.: 44.53%] [G loss: 1.170928]\n",
      "epoch:1 step:978 [D loss: 0.676737, acc.: 60.94%] [G loss: 1.124941]\n",
      "epoch:1 step:979 [D loss: 0.588370, acc.: 67.97%] [G loss: 1.272953]\n",
      "epoch:1 step:980 [D loss: 0.678931, acc.: 60.16%] [G loss: 1.209858]\n",
      "epoch:1 step:981 [D loss: 0.674259, acc.: 59.38%] [G loss: 1.009259]\n",
      "epoch:1 step:982 [D loss: 0.709045, acc.: 53.12%] [G loss: 1.156860]\n",
      "epoch:1 step:983 [D loss: 0.566378, acc.: 68.75%] [G loss: 1.243085]\n",
      "epoch:1 step:984 [D loss: 0.737830, acc.: 54.69%] [G loss: 1.087812]\n",
      "epoch:1 step:985 [D loss: 0.571477, acc.: 67.19%] [G loss: 1.136327]\n",
      "epoch:1 step:986 [D loss: 0.628566, acc.: 67.97%] [G loss: 1.091630]\n",
      "epoch:1 step:987 [D loss: 0.636739, acc.: 65.62%] [G loss: 1.207752]\n",
      "epoch:1 step:988 [D loss: 0.690853, acc.: 60.94%] [G loss: 1.224585]\n",
      "epoch:1 step:989 [D loss: 0.586651, acc.: 63.28%] [G loss: 1.309504]\n",
      "epoch:1 step:990 [D loss: 0.713507, acc.: 58.59%] [G loss: 1.217582]\n",
      "epoch:1 step:991 [D loss: 0.631376, acc.: 62.50%] [G loss: 1.119605]\n",
      "epoch:1 step:992 [D loss: 0.553841, acc.: 71.88%] [G loss: 1.179070]\n",
      "epoch:1 step:993 [D loss: 0.737734, acc.: 57.03%] [G loss: 0.959625]\n",
      "epoch:1 step:994 [D loss: 0.726199, acc.: 55.47%] [G loss: 1.149488]\n",
      "epoch:1 step:995 [D loss: 0.563280, acc.: 71.88%] [G loss: 1.255031]\n",
      "epoch:1 step:996 [D loss: 0.570275, acc.: 67.19%] [G loss: 1.186735]\n",
      "epoch:1 step:997 [D loss: 0.689743, acc.: 60.16%] [G loss: 0.998985]\n",
      "epoch:1 step:998 [D loss: 0.624164, acc.: 68.75%] [G loss: 1.192307]\n",
      "epoch:1 step:999 [D loss: 0.715376, acc.: 57.81%] [G loss: 1.371725]\n",
      "epoch:1 step:1000 [D loss: 0.736302, acc.: 53.12%] [G loss: 1.214997]\n",
      "epoch:1 step:1001 [D loss: 0.665148, acc.: 61.72%] [G loss: 1.285988]\n",
      "epoch:1 step:1002 [D loss: 0.586914, acc.: 66.41%] [G loss: 1.009840]\n",
      "epoch:1 step:1003 [D loss: 0.730314, acc.: 57.03%] [G loss: 1.072140]\n",
      "epoch:1 step:1004 [D loss: 0.663104, acc.: 60.16%] [G loss: 1.125015]\n",
      "epoch:1 step:1005 [D loss: 0.582701, acc.: 71.88%] [G loss: 1.230116]\n",
      "epoch:1 step:1006 [D loss: 0.701033, acc.: 60.94%] [G loss: 1.248913]\n",
      "epoch:1 step:1007 [D loss: 0.653905, acc.: 64.84%] [G loss: 1.127631]\n",
      "epoch:1 step:1008 [D loss: 0.620417, acc.: 67.19%] [G loss: 1.006548]\n",
      "epoch:1 step:1009 [D loss: 0.572392, acc.: 70.31%] [G loss: 1.227101]\n",
      "epoch:1 step:1010 [D loss: 0.541701, acc.: 71.09%] [G loss: 1.177271]\n",
      "epoch:1 step:1011 [D loss: 0.655781, acc.: 64.06%] [G loss: 1.197558]\n",
      "epoch:1 step:1012 [D loss: 0.671770, acc.: 57.03%] [G loss: 1.292707]\n",
      "epoch:1 step:1013 [D loss: 0.666745, acc.: 62.50%] [G loss: 1.089097]\n",
      "epoch:1 step:1014 [D loss: 0.640090, acc.: 63.28%] [G loss: 1.162289]\n",
      "epoch:1 step:1015 [D loss: 0.707828, acc.: 59.38%] [G loss: 1.044155]\n",
      "epoch:1 step:1016 [D loss: 0.684135, acc.: 61.72%] [G loss: 1.300238]\n",
      "epoch:1 step:1017 [D loss: 0.698183, acc.: 58.59%] [G loss: 1.180102]\n",
      "epoch:1 step:1018 [D loss: 0.729297, acc.: 53.91%] [G loss: 0.999696]\n",
      "epoch:1 step:1019 [D loss: 0.734732, acc.: 56.25%] [G loss: 1.266612]\n",
      "epoch:1 step:1020 [D loss: 0.772629, acc.: 47.66%] [G loss: 1.111609]\n",
      "epoch:1 step:1021 [D loss: 0.619178, acc.: 67.19%] [G loss: 1.256384]\n",
      "epoch:1 step:1022 [D loss: 0.654377, acc.: 63.28%] [G loss: 1.187497]\n",
      "epoch:1 step:1023 [D loss: 0.616543, acc.: 66.41%] [G loss: 1.258658]\n",
      "epoch:1 step:1024 [D loss: 0.696506, acc.: 56.25%] [G loss: 1.202745]\n",
      "epoch:1 step:1025 [D loss: 0.646027, acc.: 61.72%] [G loss: 0.994784]\n",
      "epoch:1 step:1026 [D loss: 0.630087, acc.: 66.41%] [G loss: 1.041795]\n",
      "epoch:1 step:1027 [D loss: 0.562635, acc.: 77.34%] [G loss: 1.361212]\n",
      "epoch:1 step:1028 [D loss: 0.644338, acc.: 57.81%] [G loss: 1.131210]\n",
      "epoch:1 step:1029 [D loss: 0.646378, acc.: 64.84%] [G loss: 1.265589]\n",
      "epoch:1 step:1030 [D loss: 0.693111, acc.: 58.59%] [G loss: 1.196495]\n",
      "epoch:1 step:1031 [D loss: 0.683331, acc.: 60.16%] [G loss: 1.139248]\n",
      "epoch:1 step:1032 [D loss: 0.626784, acc.: 66.41%] [G loss: 1.115111]\n",
      "epoch:1 step:1033 [D loss: 0.557933, acc.: 73.44%] [G loss: 1.446779]\n",
      "epoch:1 step:1034 [D loss: 0.594988, acc.: 65.62%] [G loss: 1.256916]\n",
      "epoch:1 step:1035 [D loss: 0.629856, acc.: 65.62%] [G loss: 1.247169]\n",
      "epoch:1 step:1036 [D loss: 0.653941, acc.: 66.41%] [G loss: 1.191768]\n",
      "epoch:1 step:1037 [D loss: 0.637952, acc.: 64.06%] [G loss: 1.177004]\n",
      "epoch:1 step:1038 [D loss: 0.670955, acc.: 60.94%] [G loss: 1.285493]\n",
      "epoch:1 step:1039 [D loss: 0.728692, acc.: 57.81%] [G loss: 1.131130]\n",
      "epoch:1 step:1040 [D loss: 0.629149, acc.: 64.06%] [G loss: 1.316419]\n",
      "epoch:1 step:1041 [D loss: 0.599844, acc.: 67.97%] [G loss: 1.139016]\n",
      "epoch:1 step:1042 [D loss: 0.649308, acc.: 60.94%] [G loss: 1.122687]\n",
      "epoch:1 step:1043 [D loss: 0.644108, acc.: 66.41%] [G loss: 1.157523]\n",
      "epoch:1 step:1044 [D loss: 0.657974, acc.: 64.06%] [G loss: 1.273439]\n",
      "epoch:1 step:1045 [D loss: 0.666370, acc.: 58.59%] [G loss: 1.170036]\n",
      "epoch:1 step:1046 [D loss: 0.628491, acc.: 64.84%] [G loss: 1.119847]\n",
      "epoch:1 step:1047 [D loss: 0.640846, acc.: 62.50%] [G loss: 1.287733]\n",
      "epoch:1 step:1048 [D loss: 0.671971, acc.: 57.03%] [G loss: 1.096503]\n",
      "epoch:1 step:1049 [D loss: 0.600578, acc.: 67.97%] [G loss: 1.298196]\n",
      "epoch:1 step:1050 [D loss: 0.630389, acc.: 65.62%] [G loss: 1.297357]\n",
      "epoch:1 step:1051 [D loss: 0.653729, acc.: 65.62%] [G loss: 1.209355]\n",
      "epoch:1 step:1052 [D loss: 0.773770, acc.: 53.12%] [G loss: 1.171696]\n",
      "epoch:1 step:1053 [D loss: 0.675518, acc.: 57.03%] [G loss: 1.007944]\n",
      "epoch:1 step:1054 [D loss: 0.609362, acc.: 67.19%] [G loss: 1.133587]\n",
      "epoch:1 step:1055 [D loss: 0.644539, acc.: 59.38%] [G loss: 1.300333]\n",
      "epoch:1 step:1056 [D loss: 0.684220, acc.: 62.50%] [G loss: 1.260149]\n",
      "epoch:1 step:1057 [D loss: 0.728213, acc.: 57.03%] [G loss: 1.128415]\n",
      "epoch:1 step:1058 [D loss: 0.636725, acc.: 58.59%] [G loss: 1.302843]\n",
      "epoch:1 step:1059 [D loss: 0.701335, acc.: 53.91%] [G loss: 1.230338]\n",
      "epoch:1 step:1060 [D loss: 0.712463, acc.: 59.38%] [G loss: 1.065660]\n",
      "epoch:1 step:1061 [D loss: 0.623258, acc.: 64.84%] [G loss: 1.406202]\n",
      "epoch:1 step:1062 [D loss: 0.624844, acc.: 66.41%] [G loss: 1.130504]\n",
      "epoch:1 step:1063 [D loss: 0.556895, acc.: 71.09%] [G loss: 1.237874]\n",
      "epoch:1 step:1064 [D loss: 0.613845, acc.: 64.84%] [G loss: 1.029846]\n",
      "epoch:1 step:1065 [D loss: 0.643005, acc.: 61.72%] [G loss: 1.189551]\n",
      "epoch:1 step:1066 [D loss: 0.609684, acc.: 62.50%] [G loss: 1.194489]\n",
      "epoch:1 step:1067 [D loss: 0.556448, acc.: 69.53%] [G loss: 1.323321]\n",
      "epoch:1 step:1068 [D loss: 0.677826, acc.: 64.06%] [G loss: 0.898508]\n",
      "epoch:1 step:1069 [D loss: 0.684837, acc.: 56.25%] [G loss: 1.128422]\n",
      "epoch:1 step:1070 [D loss: 0.693483, acc.: 54.69%] [G loss: 1.115403]\n",
      "epoch:1 step:1071 [D loss: 0.637842, acc.: 64.06%] [G loss: 1.312304]\n",
      "epoch:1 step:1072 [D loss: 0.725326, acc.: 53.91%] [G loss: 1.246371]\n",
      "epoch:1 step:1073 [D loss: 0.761567, acc.: 53.12%] [G loss: 1.127016]\n",
      "epoch:1 step:1074 [D loss: 0.716876, acc.: 57.81%] [G loss: 1.085075]\n",
      "epoch:1 step:1075 [D loss: 0.632255, acc.: 64.06%] [G loss: 1.174049]\n",
      "epoch:1 step:1076 [D loss: 0.701464, acc.: 63.28%] [G loss: 1.097497]\n",
      "epoch:1 step:1077 [D loss: 0.696068, acc.: 60.16%] [G loss: 1.022017]\n",
      "epoch:1 step:1078 [D loss: 0.755438, acc.: 45.31%] [G loss: 1.079221]\n",
      "epoch:1 step:1079 [D loss: 0.564201, acc.: 70.31%] [G loss: 1.263703]\n",
      "epoch:1 step:1080 [D loss: 0.700844, acc.: 60.94%] [G loss: 0.982620]\n",
      "epoch:1 step:1081 [D loss: 0.775891, acc.: 52.34%] [G loss: 0.983927]\n",
      "epoch:1 step:1082 [D loss: 0.589682, acc.: 70.31%] [G loss: 1.297796]\n",
      "epoch:1 step:1083 [D loss: 0.621185, acc.: 68.75%] [G loss: 1.323177]\n",
      "epoch:1 step:1084 [D loss: 0.642664, acc.: 64.06%] [G loss: 1.120790]\n",
      "epoch:1 step:1085 [D loss: 0.679912, acc.: 56.25%] [G loss: 1.233740]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:1 step:1086 [D loss: 0.710358, acc.: 57.03%] [G loss: 1.134206]\n",
      "epoch:1 step:1087 [D loss: 0.639452, acc.: 62.50%] [G loss: 1.335245]\n",
      "epoch:1 step:1088 [D loss: 0.739246, acc.: 50.78%] [G loss: 1.069883]\n",
      "epoch:1 step:1089 [D loss: 0.586474, acc.: 69.53%] [G loss: 1.269340]\n",
      "epoch:1 step:1090 [D loss: 0.654334, acc.: 63.28%] [G loss: 1.206709]\n",
      "epoch:1 step:1091 [D loss: 0.711957, acc.: 52.34%] [G loss: 1.008289]\n",
      "epoch:1 step:1092 [D loss: 0.618140, acc.: 68.75%] [G loss: 1.171232]\n",
      "epoch:1 step:1093 [D loss: 0.668652, acc.: 63.28%] [G loss: 1.151901]\n",
      "epoch:1 step:1094 [D loss: 0.667608, acc.: 60.94%] [G loss: 1.206095]\n",
      "epoch:1 step:1095 [D loss: 0.677341, acc.: 57.03%] [G loss: 1.075507]\n",
      "epoch:1 step:1096 [D loss: 0.623392, acc.: 64.84%] [G loss: 1.026870]\n",
      "epoch:1 step:1097 [D loss: 0.582197, acc.: 69.53%] [G loss: 1.179095]\n",
      "epoch:1 step:1098 [D loss: 0.609824, acc.: 66.41%] [G loss: 1.432290]\n",
      "epoch:1 step:1099 [D loss: 0.577991, acc.: 74.22%] [G loss: 1.092301]\n",
      "epoch:1 step:1100 [D loss: 0.644718, acc.: 64.84%] [G loss: 1.268160]\n",
      "epoch:1 step:1101 [D loss: 0.695481, acc.: 55.47%] [G loss: 1.107347]\n",
      "epoch:1 step:1102 [D loss: 0.718978, acc.: 56.25%] [G loss: 1.178956]\n",
      "epoch:1 step:1103 [D loss: 0.681554, acc.: 61.72%] [G loss: 1.202773]\n",
      "epoch:1 step:1104 [D loss: 0.644973, acc.: 64.84%] [G loss: 1.138504]\n",
      "epoch:1 step:1105 [D loss: 0.641862, acc.: 57.81%] [G loss: 1.165854]\n",
      "epoch:1 step:1106 [D loss: 0.628018, acc.: 62.50%] [G loss: 1.149806]\n",
      "epoch:1 step:1107 [D loss: 0.732092, acc.: 53.91%] [G loss: 1.128065]\n",
      "epoch:1 step:1108 [D loss: 0.564649, acc.: 68.75%] [G loss: 1.323996]\n",
      "epoch:1 step:1109 [D loss: 0.623502, acc.: 68.75%] [G loss: 1.361071]\n",
      "epoch:1 step:1110 [D loss: 0.652791, acc.: 61.72%] [G loss: 1.162945]\n",
      "epoch:1 step:1111 [D loss: 0.630619, acc.: 63.28%] [G loss: 0.908701]\n",
      "epoch:1 step:1112 [D loss: 0.646755, acc.: 63.28%] [G loss: 1.062075]\n",
      "epoch:1 step:1113 [D loss: 0.547457, acc.: 71.88%] [G loss: 1.207679]\n",
      "epoch:1 step:1114 [D loss: 0.697807, acc.: 59.38%] [G loss: 0.971546]\n",
      "epoch:1 step:1115 [D loss: 0.706527, acc.: 57.81%] [G loss: 1.000427]\n",
      "epoch:1 step:1116 [D loss: 0.624229, acc.: 68.75%] [G loss: 1.453585]\n",
      "epoch:1 step:1117 [D loss: 0.664387, acc.: 57.81%] [G loss: 1.196266]\n",
      "epoch:1 step:1118 [D loss: 0.705680, acc.: 57.81%] [G loss: 1.177397]\n",
      "epoch:1 step:1119 [D loss: 0.652074, acc.: 59.38%] [G loss: 1.125383]\n",
      "epoch:1 step:1120 [D loss: 0.678052, acc.: 62.50%] [G loss: 1.030881]\n",
      "epoch:1 step:1121 [D loss: 0.562602, acc.: 72.66%] [G loss: 1.166470]\n",
      "epoch:1 step:1122 [D loss: 0.700650, acc.: 56.25%] [G loss: 1.165890]\n",
      "epoch:1 step:1123 [D loss: 0.660518, acc.: 62.50%] [G loss: 0.986179]\n",
      "epoch:1 step:1124 [D loss: 0.642463, acc.: 61.72%] [G loss: 0.915625]\n",
      "epoch:1 step:1125 [D loss: 0.592520, acc.: 63.28%] [G loss: 1.311937]\n",
      "epoch:1 step:1126 [D loss: 0.660726, acc.: 59.38%] [G loss: 1.211965]\n",
      "epoch:1 step:1127 [D loss: 0.604055, acc.: 67.97%] [G loss: 1.209047]\n",
      "epoch:1 step:1128 [D loss: 0.673752, acc.: 62.50%] [G loss: 1.086137]\n",
      "epoch:1 step:1129 [D loss: 0.636678, acc.: 59.38%] [G loss: 1.238732]\n",
      "epoch:1 step:1130 [D loss: 0.706880, acc.: 57.03%] [G loss: 1.091284]\n",
      "epoch:1 step:1131 [D loss: 0.675840, acc.: 61.72%] [G loss: 1.175657]\n",
      "epoch:1 step:1132 [D loss: 0.619872, acc.: 64.06%] [G loss: 1.155510]\n",
      "epoch:1 step:1133 [D loss: 0.630015, acc.: 62.50%] [G loss: 1.179603]\n",
      "epoch:1 step:1134 [D loss: 0.699816, acc.: 64.06%] [G loss: 1.000198]\n",
      "epoch:1 step:1135 [D loss: 0.704016, acc.: 56.25%] [G loss: 1.221968]\n",
      "epoch:1 step:1136 [D loss: 0.632038, acc.: 62.50%] [G loss: 1.062407]\n",
      "epoch:1 step:1137 [D loss: 0.704508, acc.: 57.03%] [G loss: 1.038522]\n",
      "epoch:1 step:1138 [D loss: 0.612327, acc.: 65.62%] [G loss: 1.176809]\n",
      "epoch:1 step:1139 [D loss: 0.647980, acc.: 62.50%] [G loss: 1.089134]\n",
      "epoch:1 step:1140 [D loss: 0.624665, acc.: 65.62%] [G loss: 1.166649]\n",
      "epoch:1 step:1141 [D loss: 0.693817, acc.: 57.81%] [G loss: 1.157839]\n",
      "epoch:1 step:1142 [D loss: 0.613816, acc.: 67.97%] [G loss: 1.169722]\n",
      "epoch:1 step:1143 [D loss: 0.730920, acc.: 52.34%] [G loss: 0.987198]\n",
      "epoch:1 step:1144 [D loss: 0.625020, acc.: 66.41%] [G loss: 1.390486]\n",
      "epoch:1 step:1145 [D loss: 0.668476, acc.: 61.72%] [G loss: 1.184653]\n",
      "epoch:1 step:1146 [D loss: 0.697811, acc.: 57.81%] [G loss: 1.184956]\n",
      "epoch:1 step:1147 [D loss: 0.633130, acc.: 60.94%] [G loss: 1.185985]\n",
      "epoch:1 step:1148 [D loss: 0.723380, acc.: 58.59%] [G loss: 1.147601]\n",
      "epoch:1 step:1149 [D loss: 0.642633, acc.: 66.41%] [G loss: 1.129384]\n",
      "epoch:1 step:1150 [D loss: 0.682545, acc.: 67.97%] [G loss: 1.173026]\n",
      "epoch:1 step:1151 [D loss: 0.606693, acc.: 67.97%] [G loss: 1.136223]\n",
      "epoch:1 step:1152 [D loss: 0.643973, acc.: 63.28%] [G loss: 1.187386]\n",
      "epoch:1 step:1153 [D loss: 0.580108, acc.: 68.75%] [G loss: 1.264159]\n",
      "epoch:1 step:1154 [D loss: 0.607812, acc.: 69.53%] [G loss: 1.333853]\n",
      "epoch:1 step:1155 [D loss: 0.660430, acc.: 57.03%] [G loss: 1.041955]\n",
      "epoch:1 step:1156 [D loss: 0.534898, acc.: 73.44%] [G loss: 1.229517]\n",
      "epoch:1 step:1157 [D loss: 0.622452, acc.: 64.84%] [G loss: 0.993405]\n",
      "epoch:1 step:1158 [D loss: 0.605862, acc.: 64.84%] [G loss: 1.256680]\n",
      "epoch:1 step:1159 [D loss: 0.729267, acc.: 61.72%] [G loss: 1.080892]\n",
      "epoch:1 step:1160 [D loss: 0.608934, acc.: 64.06%] [G loss: 1.030334]\n",
      "epoch:1 step:1161 [D loss: 0.706784, acc.: 55.47%] [G loss: 1.051053]\n",
      "epoch:1 step:1162 [D loss: 0.583821, acc.: 71.88%] [G loss: 1.097446]\n",
      "epoch:1 step:1163 [D loss: 0.636851, acc.: 64.84%] [G loss: 1.139588]\n",
      "epoch:1 step:1164 [D loss: 0.669486, acc.: 60.94%] [G loss: 1.130250]\n",
      "epoch:1 step:1165 [D loss: 0.655306, acc.: 57.03%] [G loss: 1.176210]\n",
      "epoch:1 step:1166 [D loss: 0.614205, acc.: 66.41%] [G loss: 1.096882]\n",
      "epoch:1 step:1167 [D loss: 0.718702, acc.: 57.03%] [G loss: 1.186311]\n",
      "epoch:1 step:1168 [D loss: 0.661382, acc.: 63.28%] [G loss: 1.117988]\n",
      "epoch:1 step:1169 [D loss: 0.654104, acc.: 66.41%] [G loss: 1.081053]\n",
      "epoch:1 step:1170 [D loss: 0.591284, acc.: 66.41%] [G loss: 1.115789]\n",
      "epoch:1 step:1171 [D loss: 0.665487, acc.: 54.69%] [G loss: 1.287482]\n",
      "epoch:1 step:1172 [D loss: 0.599158, acc.: 64.06%] [G loss: 1.136071]\n",
      "epoch:1 step:1173 [D loss: 0.650969, acc.: 60.94%] [G loss: 1.098363]\n",
      "epoch:1 step:1174 [D loss: 0.721320, acc.: 55.47%] [G loss: 1.087777]\n",
      "epoch:1 step:1175 [D loss: 0.646611, acc.: 65.62%] [G loss: 1.329347]\n",
      "epoch:1 step:1176 [D loss: 0.621555, acc.: 62.50%] [G loss: 1.247111]\n",
      "epoch:1 step:1177 [D loss: 0.681460, acc.: 64.06%] [G loss: 1.276042]\n",
      "epoch:1 step:1178 [D loss: 0.628607, acc.: 61.72%] [G loss: 1.183744]\n",
      "epoch:1 step:1179 [D loss: 0.618355, acc.: 67.97%] [G loss: 1.140184]\n",
      "epoch:1 step:1180 [D loss: 0.611012, acc.: 65.62%] [G loss: 1.146866]\n",
      "epoch:1 step:1181 [D loss: 0.758067, acc.: 51.56%] [G loss: 1.155293]\n",
      "epoch:1 step:1182 [D loss: 0.601482, acc.: 68.75%] [G loss: 1.172514]\n",
      "epoch:1 step:1183 [D loss: 0.648373, acc.: 64.84%] [G loss: 0.968737]\n",
      "epoch:1 step:1184 [D loss: 0.659145, acc.: 61.72%] [G loss: 1.101607]\n",
      "epoch:1 step:1185 [D loss: 0.659701, acc.: 64.06%] [G loss: 1.004933]\n",
      "epoch:1 step:1186 [D loss: 0.609200, acc.: 65.62%] [G loss: 1.222014]\n",
      "epoch:1 step:1187 [D loss: 0.667712, acc.: 59.38%] [G loss: 1.019694]\n",
      "epoch:1 step:1188 [D loss: 0.740156, acc.: 57.81%] [G loss: 1.219065]\n",
      "epoch:1 step:1189 [D loss: 0.686960, acc.: 55.47%] [G loss: 1.100385]\n",
      "epoch:1 step:1190 [D loss: 0.627301, acc.: 64.84%] [G loss: 1.250977]\n",
      "epoch:1 step:1191 [D loss: 0.617963, acc.: 66.41%] [G loss: 1.268575]\n",
      "epoch:1 step:1192 [D loss: 0.638582, acc.: 57.03%] [G loss: 1.082875]\n",
      "epoch:1 step:1193 [D loss: 0.636066, acc.: 65.62%] [G loss: 1.159459]\n",
      "epoch:1 step:1194 [D loss: 0.541620, acc.: 72.66%] [G loss: 1.118248]\n",
      "epoch:1 step:1195 [D loss: 0.652059, acc.: 64.06%] [G loss: 1.232296]\n",
      "epoch:1 step:1196 [D loss: 0.674380, acc.: 63.28%] [G loss: 0.997672]\n",
      "epoch:1 step:1197 [D loss: 0.637096, acc.: 65.62%] [G loss: 1.211222]\n",
      "epoch:1 step:1198 [D loss: 0.660917, acc.: 60.16%] [G loss: 0.976349]\n",
      "epoch:1 step:1199 [D loss: 0.662724, acc.: 60.94%] [G loss: 1.083499]\n",
      "epoch:1 step:1200 [D loss: 0.694266, acc.: 53.91%] [G loss: 1.238335]\n",
      "epoch:1 step:1201 [D loss: 0.597474, acc.: 71.09%] [G loss: 1.208429]\n",
      "epoch:1 step:1202 [D loss: 0.562502, acc.: 73.44%] [G loss: 1.174444]\n",
      "epoch:1 step:1203 [D loss: 0.695389, acc.: 57.03%] [G loss: 1.064206]\n",
      "epoch:1 step:1204 [D loss: 0.677800, acc.: 57.81%] [G loss: 1.038127]\n",
      "epoch:1 step:1205 [D loss: 0.510649, acc.: 74.22%] [G loss: 1.228358]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:1 step:1206 [D loss: 0.738171, acc.: 55.47%] [G loss: 1.093430]\n",
      "epoch:1 step:1207 [D loss: 0.688429, acc.: 57.03%] [G loss: 1.071771]\n",
      "epoch:1 step:1208 [D loss: 0.580838, acc.: 67.97%] [G loss: 1.125026]\n",
      "epoch:1 step:1209 [D loss: 0.737682, acc.: 53.91%] [G loss: 1.177817]\n",
      "epoch:1 step:1210 [D loss: 0.648709, acc.: 60.16%] [G loss: 1.165422]\n",
      "epoch:1 step:1211 [D loss: 0.701877, acc.: 61.72%] [G loss: 1.068743]\n",
      "epoch:1 step:1212 [D loss: 0.675116, acc.: 61.72%] [G loss: 1.148264]\n",
      "epoch:1 step:1213 [D loss: 0.710557, acc.: 54.69%] [G loss: 1.117221]\n",
      "epoch:1 step:1214 [D loss: 0.601771, acc.: 72.66%] [G loss: 1.258007]\n",
      "epoch:1 step:1215 [D loss: 0.647367, acc.: 64.84%] [G loss: 1.164244]\n",
      "epoch:1 step:1216 [D loss: 0.702427, acc.: 54.69%] [G loss: 1.119692]\n",
      "epoch:1 step:1217 [D loss: 0.768839, acc.: 50.00%] [G loss: 0.988613]\n",
      "epoch:1 step:1218 [D loss: 0.647511, acc.: 64.06%] [G loss: 1.105375]\n",
      "epoch:1 step:1219 [D loss: 0.552380, acc.: 72.66%] [G loss: 1.094554]\n",
      "epoch:1 step:1220 [D loss: 0.581469, acc.: 68.75%] [G loss: 1.052280]\n",
      "epoch:1 step:1221 [D loss: 0.691793, acc.: 59.38%] [G loss: 0.965824]\n",
      "epoch:1 step:1222 [D loss: 0.656195, acc.: 60.16%] [G loss: 0.987765]\n",
      "epoch:1 step:1223 [D loss: 0.721010, acc.: 53.91%] [G loss: 0.895565]\n",
      "epoch:1 step:1224 [D loss: 0.576378, acc.: 71.88%] [G loss: 1.134289]\n",
      "epoch:1 step:1225 [D loss: 0.592653, acc.: 67.97%] [G loss: 1.137481]\n",
      "epoch:1 step:1226 [D loss: 0.604217, acc.: 67.97%] [G loss: 1.145203]\n",
      "epoch:1 step:1227 [D loss: 0.662068, acc.: 62.50%] [G loss: 1.167039]\n",
      "epoch:1 step:1228 [D loss: 0.618567, acc.: 65.62%] [G loss: 1.097969]\n",
      "epoch:1 step:1229 [D loss: 0.667856, acc.: 60.94%] [G loss: 1.049459]\n",
      "epoch:1 step:1230 [D loss: 0.587865, acc.: 64.84%] [G loss: 1.175821]\n",
      "epoch:1 step:1231 [D loss: 0.617310, acc.: 63.28%] [G loss: 1.185140]\n",
      "epoch:1 step:1232 [D loss: 0.671368, acc.: 58.59%] [G loss: 1.161105]\n",
      "epoch:1 step:1233 [D loss: 0.690873, acc.: 59.38%] [G loss: 1.102716]\n",
      "epoch:1 step:1234 [D loss: 0.644786, acc.: 63.28%] [G loss: 1.166464]\n",
      "epoch:1 step:1235 [D loss: 0.682981, acc.: 60.94%] [G loss: 1.067621]\n",
      "epoch:1 step:1236 [D loss: 0.649957, acc.: 64.06%] [G loss: 1.077120]\n",
      "epoch:1 step:1237 [D loss: 0.700195, acc.: 60.16%] [G loss: 1.115785]\n",
      "epoch:1 step:1238 [D loss: 0.669575, acc.: 53.91%] [G loss: 1.124607]\n",
      "epoch:1 step:1239 [D loss: 0.606612, acc.: 70.31%] [G loss: 1.038566]\n",
      "epoch:1 step:1240 [D loss: 0.601390, acc.: 67.19%] [G loss: 1.269549]\n",
      "epoch:1 step:1241 [D loss: 0.698754, acc.: 63.28%] [G loss: 1.109081]\n",
      "epoch:1 step:1242 [D loss: 0.681984, acc.: 55.47%] [G loss: 1.125245]\n",
      "epoch:1 step:1243 [D loss: 0.672952, acc.: 61.72%] [G loss: 1.247924]\n",
      "epoch:1 step:1244 [D loss: 0.596378, acc.: 67.19%] [G loss: 1.169752]\n",
      "epoch:1 step:1245 [D loss: 0.603581, acc.: 64.06%] [G loss: 1.153292]\n",
      "epoch:1 step:1246 [D loss: 0.574593, acc.: 68.75%] [G loss: 1.239224]\n",
      "epoch:1 step:1247 [D loss: 0.647577, acc.: 64.06%] [G loss: 1.103874]\n",
      "epoch:1 step:1248 [D loss: 0.623246, acc.: 65.62%] [G loss: 1.329532]\n",
      "epoch:1 step:1249 [D loss: 0.643229, acc.: 62.50%] [G loss: 1.126297]\n",
      "epoch:1 step:1250 [D loss: 0.557529, acc.: 71.88%] [G loss: 1.272400]\n",
      "epoch:1 step:1251 [D loss: 0.533573, acc.: 74.22%] [G loss: 1.206207]\n",
      "epoch:1 step:1252 [D loss: 0.560264, acc.: 68.75%] [G loss: 1.270797]\n",
      "epoch:1 step:1253 [D loss: 0.715641, acc.: 54.69%] [G loss: 1.137442]\n",
      "epoch:1 step:1254 [D loss: 0.712396, acc.: 53.12%] [G loss: 1.119237]\n",
      "epoch:1 step:1255 [D loss: 0.681112, acc.: 66.41%] [G loss: 1.132047]\n",
      "epoch:1 step:1256 [D loss: 0.607292, acc.: 65.62%] [G loss: 1.283324]\n",
      "epoch:1 step:1257 [D loss: 0.617083, acc.: 65.62%] [G loss: 1.259135]\n",
      "epoch:1 step:1258 [D loss: 0.614791, acc.: 71.09%] [G loss: 1.188932]\n",
      "epoch:1 step:1259 [D loss: 0.700767, acc.: 55.47%] [G loss: 1.096895]\n",
      "epoch:1 step:1260 [D loss: 0.670429, acc.: 59.38%] [G loss: 1.173303]\n",
      "epoch:1 step:1261 [D loss: 0.622240, acc.: 66.41%] [G loss: 1.055911]\n",
      "epoch:1 step:1262 [D loss: 0.540968, acc.: 71.88%] [G loss: 1.246012]\n",
      "epoch:1 step:1263 [D loss: 0.592645, acc.: 71.88%] [G loss: 1.101480]\n",
      "epoch:1 step:1264 [D loss: 0.619733, acc.: 65.62%] [G loss: 1.118988]\n",
      "epoch:1 step:1265 [D loss: 0.601949, acc.: 71.09%] [G loss: 1.291498]\n",
      "epoch:1 step:1266 [D loss: 0.693614, acc.: 59.38%] [G loss: 1.086723]\n",
      "epoch:1 step:1267 [D loss: 0.635410, acc.: 67.19%] [G loss: 1.226327]\n",
      "epoch:1 step:1268 [D loss: 0.522234, acc.: 75.78%] [G loss: 1.309073]\n",
      "epoch:1 step:1269 [D loss: 0.589145, acc.: 70.31%] [G loss: 1.180878]\n",
      "epoch:1 step:1270 [D loss: 0.662477, acc.: 57.81%] [G loss: 1.302480]\n",
      "epoch:1 step:1271 [D loss: 0.676252, acc.: 60.16%] [G loss: 1.026944]\n",
      "epoch:1 step:1272 [D loss: 0.630561, acc.: 64.06%] [G loss: 1.062242]\n",
      "epoch:1 step:1273 [D loss: 0.673789, acc.: 60.16%] [G loss: 1.082610]\n",
      "epoch:1 step:1274 [D loss: 0.650943, acc.: 62.50%] [G loss: 1.317619]\n",
      "epoch:1 step:1275 [D loss: 0.717713, acc.: 57.03%] [G loss: 1.220876]\n",
      "epoch:1 step:1276 [D loss: 0.748222, acc.: 51.56%] [G loss: 1.064205]\n",
      "epoch:1 step:1277 [D loss: 0.564122, acc.: 71.09%] [G loss: 1.183220]\n",
      "epoch:1 step:1278 [D loss: 0.616978, acc.: 65.62%] [G loss: 1.219006]\n",
      "epoch:1 step:1279 [D loss: 0.640646, acc.: 61.72%] [G loss: 1.331864]\n",
      "epoch:1 step:1280 [D loss: 0.633571, acc.: 62.50%] [G loss: 1.144533]\n",
      "epoch:1 step:1281 [D loss: 0.674054, acc.: 59.38%] [G loss: 1.175876]\n",
      "epoch:1 step:1282 [D loss: 0.658542, acc.: 62.50%] [G loss: 1.062623]\n",
      "epoch:1 step:1283 [D loss: 0.645278, acc.: 59.38%] [G loss: 1.063213]\n",
      "epoch:1 step:1284 [D loss: 0.679514, acc.: 62.50%] [G loss: 0.993796]\n",
      "epoch:1 step:1285 [D loss: 0.736099, acc.: 53.91%] [G loss: 0.980757]\n",
      "epoch:1 step:1286 [D loss: 0.596952, acc.: 67.97%] [G loss: 1.156352]\n",
      "epoch:1 step:1287 [D loss: 0.597496, acc.: 61.72%] [G loss: 1.125486]\n",
      "epoch:1 step:1288 [D loss: 0.703218, acc.: 57.81%] [G loss: 1.117869]\n",
      "epoch:1 step:1289 [D loss: 0.623322, acc.: 64.84%] [G loss: 1.096231]\n",
      "epoch:1 step:1290 [D loss: 0.620470, acc.: 66.41%] [G loss: 1.254653]\n",
      "epoch:1 step:1291 [D loss: 0.667240, acc.: 59.38%] [G loss: 1.077419]\n",
      "epoch:1 step:1292 [D loss: 0.579738, acc.: 70.31%] [G loss: 1.117297]\n",
      "epoch:1 step:1293 [D loss: 0.632983, acc.: 64.84%] [G loss: 1.113410]\n",
      "epoch:1 step:1294 [D loss: 0.687761, acc.: 56.25%] [G loss: 1.078817]\n",
      "epoch:1 step:1295 [D loss: 0.648679, acc.: 65.62%] [G loss: 1.280820]\n",
      "epoch:1 step:1296 [D loss: 0.787679, acc.: 57.03%] [G loss: 1.087963]\n",
      "epoch:1 step:1297 [D loss: 0.626148, acc.: 64.06%] [G loss: 1.198482]\n",
      "epoch:1 step:1298 [D loss: 0.766750, acc.: 48.44%] [G loss: 1.094129]\n",
      "epoch:1 step:1299 [D loss: 0.641449, acc.: 64.84%] [G loss: 1.271436]\n",
      "epoch:1 step:1300 [D loss: 0.619536, acc.: 62.50%] [G loss: 1.203621]\n",
      "epoch:1 step:1301 [D loss: 0.629580, acc.: 65.62%] [G loss: 1.044321]\n",
      "epoch:1 step:1302 [D loss: 0.629129, acc.: 64.84%] [G loss: 1.100927]\n",
      "epoch:1 step:1303 [D loss: 0.651369, acc.: 61.72%] [G loss: 1.281956]\n",
      "epoch:1 step:1304 [D loss: 0.772717, acc.: 54.69%] [G loss: 1.203432]\n",
      "epoch:1 step:1305 [D loss: 0.676680, acc.: 57.03%] [G loss: 1.094223]\n",
      "epoch:1 step:1306 [D loss: 0.646172, acc.: 64.06%] [G loss: 1.050290]\n",
      "epoch:1 step:1307 [D loss: 0.717378, acc.: 54.69%] [G loss: 1.112247]\n",
      "epoch:1 step:1308 [D loss: 0.625480, acc.: 67.97%] [G loss: 1.126240]\n",
      "epoch:1 step:1309 [D loss: 0.625756, acc.: 63.28%] [G loss: 1.241649]\n",
      "epoch:1 step:1310 [D loss: 0.662556, acc.: 60.16%] [G loss: 1.269865]\n",
      "epoch:1 step:1311 [D loss: 0.680553, acc.: 60.94%] [G loss: 1.050155]\n",
      "epoch:1 step:1312 [D loss: 0.662955, acc.: 63.28%] [G loss: 1.132249]\n",
      "epoch:1 step:1313 [D loss: 0.730341, acc.: 57.81%] [G loss: 0.985518]\n",
      "epoch:1 step:1314 [D loss: 0.768845, acc.: 50.78%] [G loss: 1.053736]\n",
      "epoch:1 step:1315 [D loss: 0.609224, acc.: 66.41%] [G loss: 1.261210]\n",
      "epoch:1 step:1316 [D loss: 0.644371, acc.: 61.72%] [G loss: 1.157789]\n",
      "epoch:1 step:1317 [D loss: 0.660311, acc.: 63.28%] [G loss: 1.150700]\n",
      "epoch:1 step:1318 [D loss: 0.669833, acc.: 60.16%] [G loss: 1.046618]\n",
      "epoch:1 step:1319 [D loss: 0.612481, acc.: 67.97%] [G loss: 1.059537]\n",
      "epoch:1 step:1320 [D loss: 0.561149, acc.: 71.88%] [G loss: 1.397838]\n",
      "epoch:1 step:1321 [D loss: 0.738050, acc.: 52.34%] [G loss: 1.091893]\n",
      "epoch:1 step:1322 [D loss: 0.671915, acc.: 64.84%] [G loss: 1.055154]\n",
      "epoch:1 step:1323 [D loss: 0.689650, acc.: 58.59%] [G loss: 1.021810]\n",
      "epoch:1 step:1324 [D loss: 0.641787, acc.: 62.50%] [G loss: 1.152536]\n",
      "epoch:1 step:1325 [D loss: 0.758477, acc.: 50.78%] [G loss: 1.181917]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:1 step:1326 [D loss: 0.570901, acc.: 72.66%] [G loss: 1.030578]\n",
      "epoch:1 step:1327 [D loss: 0.554829, acc.: 71.88%] [G loss: 1.214635]\n",
      "epoch:1 step:1328 [D loss: 0.590714, acc.: 67.19%] [G loss: 1.138646]\n",
      "epoch:1 step:1329 [D loss: 0.646312, acc.: 63.28%] [G loss: 1.156793]\n",
      "epoch:1 step:1330 [D loss: 0.727306, acc.: 58.59%] [G loss: 1.054818]\n",
      "epoch:1 step:1331 [D loss: 0.641755, acc.: 65.62%] [G loss: 1.158549]\n",
      "epoch:1 step:1332 [D loss: 0.677285, acc.: 60.16%] [G loss: 1.006452]\n",
      "epoch:1 step:1333 [D loss: 0.579204, acc.: 69.53%] [G loss: 1.227824]\n",
      "epoch:1 step:1334 [D loss: 0.653608, acc.: 61.72%] [G loss: 1.225208]\n",
      "epoch:1 step:1335 [D loss: 0.641481, acc.: 64.84%] [G loss: 1.007427]\n",
      "epoch:1 step:1336 [D loss: 0.557013, acc.: 73.44%] [G loss: 1.123083]\n",
      "epoch:1 step:1337 [D loss: 0.608752, acc.: 67.97%] [G loss: 1.162734]\n",
      "epoch:1 step:1338 [D loss: 0.704993, acc.: 60.94%] [G loss: 1.286919]\n",
      "epoch:1 step:1339 [D loss: 0.594747, acc.: 66.41%] [G loss: 1.365266]\n",
      "epoch:1 step:1340 [D loss: 0.677196, acc.: 57.03%] [G loss: 1.083269]\n",
      "epoch:1 step:1341 [D loss: 0.609141, acc.: 67.97%] [G loss: 1.050756]\n",
      "epoch:1 step:1342 [D loss: 0.690272, acc.: 58.59%] [G loss: 1.030168]\n",
      "epoch:1 step:1343 [D loss: 0.611555, acc.: 64.84%] [G loss: 1.125463]\n",
      "epoch:1 step:1344 [D loss: 0.640568, acc.: 60.16%] [G loss: 1.180454]\n",
      "epoch:1 step:1345 [D loss: 0.634678, acc.: 67.19%] [G loss: 1.270378]\n",
      "epoch:1 step:1346 [D loss: 0.719955, acc.: 56.25%] [G loss: 1.248605]\n",
      "epoch:1 step:1347 [D loss: 0.648839, acc.: 65.62%] [G loss: 0.996253]\n",
      "epoch:1 step:1348 [D loss: 0.662975, acc.: 60.16%] [G loss: 1.066618]\n",
      "epoch:1 step:1349 [D loss: 0.650839, acc.: 61.72%] [G loss: 1.122927]\n",
      "epoch:1 step:1350 [D loss: 0.658025, acc.: 64.06%] [G loss: 1.155954]\n",
      "epoch:1 step:1351 [D loss: 0.651754, acc.: 67.19%] [G loss: 1.215647]\n",
      "epoch:1 step:1352 [D loss: 0.664826, acc.: 58.59%] [G loss: 1.196801]\n",
      "epoch:1 step:1353 [D loss: 0.667592, acc.: 63.28%] [G loss: 1.235312]\n",
      "epoch:1 step:1354 [D loss: 0.709132, acc.: 64.06%] [G loss: 1.095168]\n",
      "epoch:1 step:1355 [D loss: 0.670617, acc.: 63.28%] [G loss: 1.044050]\n",
      "epoch:1 step:1356 [D loss: 0.591738, acc.: 68.75%] [G loss: 1.201281]\n",
      "epoch:1 step:1357 [D loss: 0.586797, acc.: 71.09%] [G loss: 1.356328]\n",
      "epoch:1 step:1358 [D loss: 0.630033, acc.: 65.62%] [G loss: 1.282494]\n",
      "epoch:1 step:1359 [D loss: 0.692446, acc.: 60.94%] [G loss: 1.190132]\n",
      "epoch:1 step:1360 [D loss: 0.547668, acc.: 71.88%] [G loss: 1.367059]\n",
      "epoch:1 step:1361 [D loss: 0.705167, acc.: 56.25%] [G loss: 1.120529]\n",
      "epoch:1 step:1362 [D loss: 0.604381, acc.: 64.84%] [G loss: 1.229940]\n",
      "epoch:1 step:1363 [D loss: 0.524364, acc.: 75.00%] [G loss: 1.224470]\n",
      "epoch:1 step:1364 [D loss: 0.604723, acc.: 71.88%] [G loss: 1.220630]\n",
      "epoch:1 step:1365 [D loss: 0.563221, acc.: 69.53%] [G loss: 1.027142]\n",
      "epoch:1 step:1366 [D loss: 0.703365, acc.: 55.47%] [G loss: 1.048220]\n",
      "epoch:1 step:1367 [D loss: 0.694360, acc.: 59.38%] [G loss: 1.145814]\n",
      "epoch:1 step:1368 [D loss: 0.651883, acc.: 61.72%] [G loss: 1.119101]\n",
      "epoch:1 step:1369 [D loss: 0.600514, acc.: 64.06%] [G loss: 1.177337]\n",
      "epoch:1 step:1370 [D loss: 0.664647, acc.: 59.38%] [G loss: 1.194411]\n",
      "epoch:1 step:1371 [D loss: 0.703934, acc.: 55.47%] [G loss: 1.153893]\n",
      "epoch:1 step:1372 [D loss: 0.558466, acc.: 71.09%] [G loss: 1.303250]\n",
      "epoch:1 step:1373 [D loss: 0.655590, acc.: 60.94%] [G loss: 1.180392]\n",
      "epoch:1 step:1374 [D loss: 0.781274, acc.: 48.44%] [G loss: 1.027041]\n",
      "epoch:1 step:1375 [D loss: 0.700382, acc.: 53.91%] [G loss: 1.118778]\n",
      "epoch:1 step:1376 [D loss: 0.657567, acc.: 62.50%] [G loss: 1.185821]\n",
      "epoch:1 step:1377 [D loss: 0.629808, acc.: 60.94%] [G loss: 1.264106]\n",
      "epoch:1 step:1378 [D loss: 0.691696, acc.: 56.25%] [G loss: 1.002713]\n",
      "epoch:1 step:1379 [D loss: 0.637500, acc.: 63.28%] [G loss: 1.068326]\n",
      "epoch:1 step:1380 [D loss: 0.607198, acc.: 66.41%] [G loss: 1.264383]\n",
      "epoch:1 step:1381 [D loss: 0.652383, acc.: 62.50%] [G loss: 1.136533]\n",
      "epoch:1 step:1382 [D loss: 0.645068, acc.: 60.94%] [G loss: 1.254206]\n",
      "epoch:1 step:1383 [D loss: 0.684070, acc.: 63.28%] [G loss: 1.061139]\n",
      "epoch:1 step:1384 [D loss: 0.616911, acc.: 64.06%] [G loss: 1.191913]\n",
      "epoch:1 step:1385 [D loss: 0.698937, acc.: 57.81%] [G loss: 1.128548]\n",
      "epoch:1 step:1386 [D loss: 0.630152, acc.: 63.28%] [G loss: 1.102653]\n",
      "epoch:1 step:1387 [D loss: 0.694800, acc.: 54.69%] [G loss: 1.156069]\n",
      "epoch:1 step:1388 [D loss: 0.712596, acc.: 55.47%] [G loss: 1.102157]\n",
      "epoch:1 step:1389 [D loss: 0.672122, acc.: 57.03%] [G loss: 1.193838]\n",
      "epoch:1 step:1390 [D loss: 0.703696, acc.: 59.38%] [G loss: 1.033801]\n",
      "epoch:1 step:1391 [D loss: 0.626671, acc.: 63.28%] [G loss: 1.162708]\n",
      "epoch:1 step:1392 [D loss: 0.650187, acc.: 64.84%] [G loss: 1.252712]\n",
      "epoch:1 step:1393 [D loss: 0.584549, acc.: 72.66%] [G loss: 1.252160]\n",
      "epoch:1 step:1394 [D loss: 0.699738, acc.: 60.94%] [G loss: 1.037014]\n",
      "epoch:1 step:1395 [D loss: 0.723596, acc.: 57.81%] [G loss: 1.151990]\n",
      "epoch:1 step:1396 [D loss: 0.639723, acc.: 64.84%] [G loss: 1.135127]\n",
      "epoch:1 step:1397 [D loss: 0.610488, acc.: 64.06%] [G loss: 1.258623]\n",
      "epoch:1 step:1398 [D loss: 0.714492, acc.: 60.16%] [G loss: 1.054822]\n",
      "epoch:1 step:1399 [D loss: 0.722135, acc.: 50.78%] [G loss: 1.109406]\n",
      "epoch:1 step:1400 [D loss: 0.648590, acc.: 64.06%] [G loss: 1.263527]\n",
      "epoch:1 step:1401 [D loss: 0.699124, acc.: 57.03%] [G loss: 1.128550]\n",
      "epoch:1 step:1402 [D loss: 0.703194, acc.: 56.25%] [G loss: 1.121491]\n",
      "epoch:1 step:1403 [D loss: 0.636204, acc.: 68.75%] [G loss: 1.176633]\n",
      "epoch:1 step:1404 [D loss: 0.553954, acc.: 75.00%] [G loss: 1.078271]\n",
      "epoch:1 step:1405 [D loss: 0.676587, acc.: 57.81%] [G loss: 1.239750]\n",
      "epoch:1 step:1406 [D loss: 0.582459, acc.: 66.41%] [G loss: 1.129383]\n",
      "epoch:1 step:1407 [D loss: 0.675910, acc.: 62.50%] [G loss: 1.109376]\n",
      "epoch:1 step:1408 [D loss: 0.650647, acc.: 60.94%] [G loss: 1.073412]\n",
      "epoch:1 step:1409 [D loss: 0.665067, acc.: 69.53%] [G loss: 1.060093]\n",
      "epoch:1 step:1410 [D loss: 0.595605, acc.: 67.97%] [G loss: 1.183399]\n",
      "epoch:1 step:1411 [D loss: 0.724281, acc.: 56.25%] [G loss: 1.068509]\n",
      "epoch:1 step:1412 [D loss: 0.582373, acc.: 70.31%] [G loss: 1.000744]\n",
      "epoch:1 step:1413 [D loss: 0.653360, acc.: 64.06%] [G loss: 1.244722]\n",
      "epoch:1 step:1414 [D loss: 0.732227, acc.: 53.91%] [G loss: 1.076564]\n",
      "epoch:1 step:1415 [D loss: 0.684594, acc.: 62.50%] [G loss: 1.132632]\n",
      "epoch:1 step:1416 [D loss: 0.694146, acc.: 57.81%] [G loss: 1.201949]\n",
      "epoch:1 step:1417 [D loss: 0.667034, acc.: 57.03%] [G loss: 1.148467]\n",
      "epoch:1 step:1418 [D loss: 0.656864, acc.: 59.38%] [G loss: 1.089683]\n",
      "epoch:1 step:1419 [D loss: 0.559987, acc.: 72.66%] [G loss: 1.189785]\n",
      "epoch:1 step:1420 [D loss: 0.630856, acc.: 62.50%] [G loss: 1.128977]\n",
      "epoch:1 step:1421 [D loss: 0.693174, acc.: 57.03%] [G loss: 0.952519]\n",
      "epoch:1 step:1422 [D loss: 0.654956, acc.: 60.94%] [G loss: 1.156344]\n",
      "epoch:1 step:1423 [D loss: 0.648551, acc.: 64.06%] [G loss: 1.043591]\n",
      "epoch:1 step:1424 [D loss: 0.592568, acc.: 68.75%] [G loss: 1.300946]\n",
      "epoch:1 step:1425 [D loss: 0.606750, acc.: 64.06%] [G loss: 1.168970]\n",
      "epoch:1 step:1426 [D loss: 0.687827, acc.: 55.47%] [G loss: 1.028518]\n",
      "epoch:1 step:1427 [D loss: 0.651043, acc.: 62.50%] [G loss: 1.003179]\n",
      "epoch:1 step:1428 [D loss: 0.582379, acc.: 65.62%] [G loss: 1.187724]\n",
      "epoch:1 step:1429 [D loss: 0.689723, acc.: 58.59%] [G loss: 1.135281]\n",
      "epoch:1 step:1430 [D loss: 0.581796, acc.: 70.31%] [G loss: 1.268469]\n",
      "epoch:1 step:1431 [D loss: 0.634135, acc.: 61.72%] [G loss: 1.088058]\n",
      "epoch:1 step:1432 [D loss: 0.730820, acc.: 55.47%] [G loss: 1.093010]\n",
      "epoch:1 step:1433 [D loss: 0.623679, acc.: 66.41%] [G loss: 1.147364]\n",
      "epoch:1 step:1434 [D loss: 0.609974, acc.: 63.28%] [G loss: 1.085334]\n",
      "epoch:1 step:1435 [D loss: 0.548145, acc.: 71.09%] [G loss: 1.097304]\n",
      "epoch:1 step:1436 [D loss: 0.602943, acc.: 69.53%] [G loss: 1.109847]\n",
      "epoch:1 step:1437 [D loss: 0.634009, acc.: 65.62%] [G loss: 1.179618]\n",
      "epoch:1 step:1438 [D loss: 0.690460, acc.: 57.81%] [G loss: 1.295391]\n",
      "epoch:1 step:1439 [D loss: 0.584695, acc.: 67.97%] [G loss: 1.193728]\n",
      "epoch:1 step:1440 [D loss: 0.607476, acc.: 64.06%] [G loss: 1.101465]\n",
      "epoch:1 step:1441 [D loss: 0.711910, acc.: 57.03%] [G loss: 1.193467]\n",
      "epoch:1 step:1442 [D loss: 0.552801, acc.: 71.88%] [G loss: 1.385705]\n",
      "epoch:1 step:1443 [D loss: 0.634487, acc.: 60.16%] [G loss: 1.049778]\n",
      "epoch:1 step:1444 [D loss: 0.649961, acc.: 64.06%] [G loss: 1.080197]\n",
      "epoch:1 step:1445 [D loss: 0.564563, acc.: 70.31%] [G loss: 1.090005]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:1 step:1446 [D loss: 0.612314, acc.: 67.97%] [G loss: 1.183293]\n",
      "epoch:1 step:1447 [D loss: 0.680551, acc.: 55.47%] [G loss: 1.152079]\n",
      "epoch:1 step:1448 [D loss: 0.628254, acc.: 66.41%] [G loss: 1.190076]\n",
      "epoch:1 step:1449 [D loss: 0.611622, acc.: 69.53%] [G loss: 1.126423]\n",
      "epoch:1 step:1450 [D loss: 0.593934, acc.: 66.41%] [G loss: 1.130235]\n",
      "epoch:1 step:1451 [D loss: 0.647113, acc.: 65.62%] [G loss: 1.128431]\n",
      "epoch:1 step:1452 [D loss: 0.726068, acc.: 55.47%] [G loss: 0.978891]\n",
      "epoch:1 step:1453 [D loss: 0.626514, acc.: 65.62%] [G loss: 1.109751]\n",
      "epoch:1 step:1454 [D loss: 0.673589, acc.: 58.59%] [G loss: 1.128946]\n",
      "epoch:1 step:1455 [D loss: 0.697753, acc.: 54.69%] [G loss: 1.082998]\n",
      "epoch:1 step:1456 [D loss: 0.537984, acc.: 71.88%] [G loss: 1.292605]\n",
      "epoch:1 step:1457 [D loss: 0.589774, acc.: 71.09%] [G loss: 1.124486]\n",
      "epoch:1 step:1458 [D loss: 0.704232, acc.: 57.03%] [G loss: 0.961626]\n",
      "epoch:1 step:1459 [D loss: 0.591139, acc.: 71.09%] [G loss: 1.112359]\n",
      "epoch:1 step:1460 [D loss: 0.619485, acc.: 64.84%] [G loss: 1.235762]\n",
      "epoch:1 step:1461 [D loss: 0.654830, acc.: 58.59%] [G loss: 1.253779]\n",
      "epoch:1 step:1462 [D loss: 0.705980, acc.: 56.25%] [G loss: 0.983758]\n",
      "epoch:1 step:1463 [D loss: 0.757379, acc.: 60.16%] [G loss: 1.022337]\n",
      "epoch:1 step:1464 [D loss: 0.707055, acc.: 60.16%] [G loss: 1.101502]\n",
      "epoch:1 step:1465 [D loss: 0.664605, acc.: 60.16%] [G loss: 1.144021]\n",
      "epoch:1 step:1466 [D loss: 0.659304, acc.: 60.16%] [G loss: 1.252975]\n",
      "epoch:1 step:1467 [D loss: 0.714616, acc.: 52.34%] [G loss: 1.050632]\n",
      "epoch:1 step:1468 [D loss: 0.688392, acc.: 55.47%] [G loss: 1.159034]\n",
      "epoch:1 step:1469 [D loss: 0.641757, acc.: 66.41%] [G loss: 1.101314]\n",
      "epoch:1 step:1470 [D loss: 0.621358, acc.: 63.28%] [G loss: 1.022698]\n",
      "epoch:1 step:1471 [D loss: 0.608391, acc.: 68.75%] [G loss: 1.216821]\n",
      "epoch:1 step:1472 [D loss: 0.643694, acc.: 64.84%] [G loss: 1.148913]\n",
      "epoch:1 step:1473 [D loss: 0.566736, acc.: 72.66%] [G loss: 1.165265]\n",
      "epoch:1 step:1474 [D loss: 0.682778, acc.: 64.06%] [G loss: 1.065623]\n",
      "epoch:1 step:1475 [D loss: 0.639475, acc.: 65.62%] [G loss: 1.050792]\n",
      "epoch:1 step:1476 [D loss: 0.732729, acc.: 54.69%] [G loss: 1.107835]\n",
      "epoch:1 step:1477 [D loss: 0.604412, acc.: 66.41%] [G loss: 1.133609]\n",
      "epoch:1 step:1478 [D loss: 0.559931, acc.: 71.09%] [G loss: 1.114906]\n",
      "epoch:1 step:1479 [D loss: 0.572340, acc.: 71.09%] [G loss: 1.084585]\n",
      "epoch:1 step:1480 [D loss: 0.641922, acc.: 64.06%] [G loss: 1.091835]\n",
      "epoch:1 step:1481 [D loss: 0.568842, acc.: 71.09%] [G loss: 1.043686]\n",
      "epoch:1 step:1482 [D loss: 0.629503, acc.: 64.06%] [G loss: 1.211072]\n",
      "epoch:1 step:1483 [D loss: 0.585977, acc.: 69.53%] [G loss: 1.115474]\n",
      "epoch:1 step:1484 [D loss: 0.659031, acc.: 59.38%] [G loss: 1.215245]\n",
      "epoch:1 step:1485 [D loss: 0.676295, acc.: 59.38%] [G loss: 1.173806]\n",
      "epoch:1 step:1486 [D loss: 0.630012, acc.: 69.53%] [G loss: 1.118018]\n",
      "epoch:1 step:1487 [D loss: 0.569957, acc.: 75.00%] [G loss: 1.222796]\n",
      "epoch:1 step:1488 [D loss: 0.650278, acc.: 63.28%] [G loss: 1.173634]\n",
      "epoch:1 step:1489 [D loss: 0.663920, acc.: 64.84%] [G loss: 1.156302]\n",
      "epoch:1 step:1490 [D loss: 0.642979, acc.: 65.62%] [G loss: 1.118251]\n",
      "epoch:1 step:1491 [D loss: 0.567461, acc.: 71.88%] [G loss: 1.138403]\n",
      "epoch:1 step:1492 [D loss: 0.607285, acc.: 67.19%] [G loss: 1.143312]\n",
      "epoch:1 step:1493 [D loss: 0.683799, acc.: 57.81%] [G loss: 1.141389]\n",
      "epoch:1 step:1494 [D loss: 0.581363, acc.: 71.88%] [G loss: 1.271724]\n",
      "epoch:1 step:1495 [D loss: 0.629089, acc.: 61.72%] [G loss: 1.160243]\n",
      "epoch:1 step:1496 [D loss: 0.645654, acc.: 63.28%] [G loss: 1.041253]\n",
      "epoch:1 step:1497 [D loss: 0.692907, acc.: 61.72%] [G loss: 1.027560]\n",
      "epoch:1 step:1498 [D loss: 0.630808, acc.: 69.53%] [G loss: 1.209412]\n",
      "epoch:1 step:1499 [D loss: 0.627996, acc.: 62.50%] [G loss: 1.396501]\n",
      "epoch:1 step:1500 [D loss: 0.740030, acc.: 52.34%] [G loss: 1.191808]\n",
      "epoch:1 step:1501 [D loss: 0.596767, acc.: 70.31%] [G loss: 1.397665]\n",
      "epoch:1 step:1502 [D loss: 0.631677, acc.: 64.06%] [G loss: 1.263068]\n",
      "epoch:1 step:1503 [D loss: 0.667873, acc.: 61.72%] [G loss: 1.268304]\n",
      "epoch:1 step:1504 [D loss: 0.684681, acc.: 59.38%] [G loss: 1.039389]\n",
      "epoch:1 step:1505 [D loss: 0.739249, acc.: 52.34%] [G loss: 1.100730]\n",
      "epoch:1 step:1506 [D loss: 0.618041, acc.: 67.97%] [G loss: 1.203876]\n",
      "epoch:1 step:1507 [D loss: 0.691268, acc.: 57.03%] [G loss: 1.237611]\n",
      "epoch:1 step:1508 [D loss: 0.632183, acc.: 66.41%] [G loss: 1.357311]\n",
      "epoch:1 step:1509 [D loss: 0.519205, acc.: 74.22%] [G loss: 1.280333]\n",
      "epoch:1 step:1510 [D loss: 0.686315, acc.: 58.59%] [G loss: 1.076927]\n",
      "epoch:1 step:1511 [D loss: 0.676274, acc.: 55.47%] [G loss: 1.051404]\n",
      "epoch:1 step:1512 [D loss: 0.671338, acc.: 57.03%] [G loss: 1.013572]\n",
      "epoch:1 step:1513 [D loss: 0.555125, acc.: 75.00%] [G loss: 1.041848]\n",
      "epoch:1 step:1514 [D loss: 0.646385, acc.: 62.50%] [G loss: 1.079784]\n",
      "epoch:1 step:1515 [D loss: 0.620870, acc.: 67.19%] [G loss: 1.223639]\n",
      "epoch:1 step:1516 [D loss: 0.658658, acc.: 63.28%] [G loss: 1.256261]\n",
      "epoch:1 step:1517 [D loss: 0.692971, acc.: 56.25%] [G loss: 0.995668]\n",
      "epoch:1 step:1518 [D loss: 0.600827, acc.: 65.62%] [G loss: 1.117252]\n",
      "epoch:1 step:1519 [D loss: 0.598453, acc.: 64.06%] [G loss: 1.193123]\n",
      "epoch:1 step:1520 [D loss: 0.781458, acc.: 47.66%] [G loss: 1.004771]\n",
      "epoch:1 step:1521 [D loss: 0.712815, acc.: 53.91%] [G loss: 1.102966]\n",
      "epoch:1 step:1522 [D loss: 0.699295, acc.: 54.69%] [G loss: 1.180087]\n",
      "epoch:1 step:1523 [D loss: 0.717997, acc.: 52.34%] [G loss: 1.314237]\n",
      "epoch:1 step:1524 [D loss: 0.698621, acc.: 63.28%] [G loss: 1.147149]\n",
      "epoch:1 step:1525 [D loss: 0.643586, acc.: 64.84%] [G loss: 1.214896]\n",
      "epoch:1 step:1526 [D loss: 0.614268, acc.: 66.41%] [G loss: 1.078774]\n",
      "epoch:1 step:1527 [D loss: 0.624385, acc.: 62.50%] [G loss: 1.115478]\n",
      "epoch:1 step:1528 [D loss: 0.673711, acc.: 56.25%] [G loss: 1.023008]\n",
      "epoch:1 step:1529 [D loss: 0.598404, acc.: 65.62%] [G loss: 1.000766]\n",
      "epoch:1 step:1530 [D loss: 0.669415, acc.: 60.94%] [G loss: 1.318252]\n",
      "epoch:1 step:1531 [D loss: 0.505032, acc.: 76.56%] [G loss: 1.152916]\n",
      "epoch:1 step:1532 [D loss: 0.645035, acc.: 60.16%] [G loss: 1.118718]\n",
      "epoch:1 step:1533 [D loss: 0.583151, acc.: 69.53%] [G loss: 1.039929]\n",
      "epoch:1 step:1534 [D loss: 0.695026, acc.: 56.25%] [G loss: 1.105327]\n",
      "epoch:1 step:1535 [D loss: 0.686234, acc.: 57.81%] [G loss: 1.041056]\n",
      "epoch:1 step:1536 [D loss: 0.644127, acc.: 64.06%] [G loss: 1.053022]\n",
      "epoch:1 step:1537 [D loss: 0.587915, acc.: 69.53%] [G loss: 1.027188]\n",
      "epoch:1 step:1538 [D loss: 0.746181, acc.: 50.00%] [G loss: 1.047575]\n",
      "epoch:1 step:1539 [D loss: 0.490253, acc.: 77.34%] [G loss: 1.087002]\n",
      "epoch:1 step:1540 [D loss: 0.689971, acc.: 55.47%] [G loss: 1.078363]\n",
      "epoch:1 step:1541 [D loss: 0.746896, acc.: 53.12%] [G loss: 0.999271]\n",
      "epoch:1 step:1542 [D loss: 0.777599, acc.: 51.56%] [G loss: 0.873916]\n",
      "epoch:1 step:1543 [D loss: 0.575765, acc.: 68.75%] [G loss: 1.110486]\n",
      "epoch:1 step:1544 [D loss: 0.649206, acc.: 62.50%] [G loss: 1.301048]\n",
      "epoch:1 step:1545 [D loss: 0.597697, acc.: 69.53%] [G loss: 1.283184]\n",
      "epoch:1 step:1546 [D loss: 0.625116, acc.: 59.38%] [G loss: 1.193656]\n",
      "epoch:1 step:1547 [D loss: 0.692424, acc.: 54.69%] [G loss: 1.154546]\n",
      "epoch:1 step:1548 [D loss: 0.569281, acc.: 72.66%] [G loss: 1.324089]\n",
      "epoch:1 step:1549 [D loss: 0.642641, acc.: 57.03%] [G loss: 1.211475]\n",
      "epoch:1 step:1550 [D loss: 0.632364, acc.: 69.53%] [G loss: 1.295592]\n",
      "epoch:1 step:1551 [D loss: 0.716617, acc.: 58.59%] [G loss: 1.286552]\n",
      "epoch:1 step:1552 [D loss: 0.669400, acc.: 58.59%] [G loss: 1.161003]\n",
      "epoch:1 step:1553 [D loss: 0.625576, acc.: 64.84%] [G loss: 1.125825]\n",
      "epoch:1 step:1554 [D loss: 0.658428, acc.: 63.28%] [G loss: 1.089919]\n",
      "epoch:1 step:1555 [D loss: 0.575581, acc.: 64.84%] [G loss: 1.305856]\n",
      "epoch:1 step:1556 [D loss: 0.658711, acc.: 60.94%] [G loss: 1.143087]\n",
      "epoch:1 step:1557 [D loss: 0.693463, acc.: 55.47%] [G loss: 1.123377]\n",
      "epoch:1 step:1558 [D loss: 0.711400, acc.: 56.25%] [G loss: 1.186222]\n",
      "epoch:1 step:1559 [D loss: 0.734160, acc.: 53.91%] [G loss: 1.011899]\n",
      "epoch:1 step:1560 [D loss: 0.609385, acc.: 64.06%] [G loss: 1.187712]\n",
      "epoch:1 step:1561 [D loss: 0.661583, acc.: 61.72%] [G loss: 1.314741]\n",
      "epoch:1 step:1562 [D loss: 0.650490, acc.: 60.94%] [G loss: 1.127517]\n",
      "epoch:1 step:1563 [D loss: 0.664343, acc.: 57.03%] [G loss: 1.210816]\n",
      "epoch:1 step:1564 [D loss: 0.632430, acc.: 60.94%] [G loss: 1.204777]\n",
      "epoch:1 step:1565 [D loss: 0.757374, acc.: 51.56%] [G loss: 1.011881]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:1 step:1566 [D loss: 0.562288, acc.: 67.19%] [G loss: 1.169888]\n",
      "epoch:1 step:1567 [D loss: 0.689323, acc.: 60.16%] [G loss: 1.000597]\n",
      "epoch:1 step:1568 [D loss: 0.594389, acc.: 67.19%] [G loss: 1.113705]\n",
      "epoch:1 step:1569 [D loss: 0.653729, acc.: 61.72%] [G loss: 1.248262]\n",
      "epoch:1 step:1570 [D loss: 0.596750, acc.: 67.19%] [G loss: 1.214794]\n",
      "epoch:1 step:1571 [D loss: 0.630345, acc.: 65.62%] [G loss: 1.014908]\n",
      "epoch:1 step:1572 [D loss: 0.648256, acc.: 60.94%] [G loss: 1.092251]\n",
      "epoch:1 step:1573 [D loss: 0.680825, acc.: 58.59%] [G loss: 1.100499]\n",
      "epoch:1 step:1574 [D loss: 0.700311, acc.: 55.47%] [G loss: 1.153644]\n",
      "epoch:1 step:1575 [D loss: 0.725547, acc.: 52.34%] [G loss: 1.091231]\n",
      "epoch:1 step:1576 [D loss: 0.710055, acc.: 57.81%] [G loss: 1.151995]\n",
      "epoch:1 step:1577 [D loss: 0.730726, acc.: 53.12%] [G loss: 1.124050]\n",
      "epoch:1 step:1578 [D loss: 0.716946, acc.: 57.81%] [G loss: 0.907054]\n",
      "epoch:1 step:1579 [D loss: 0.679571, acc.: 60.16%] [G loss: 1.047418]\n",
      "epoch:1 step:1580 [D loss: 0.636146, acc.: 60.16%] [G loss: 1.135559]\n",
      "epoch:1 step:1581 [D loss: 0.637339, acc.: 67.97%] [G loss: 1.190567]\n",
      "epoch:1 step:1582 [D loss: 0.631441, acc.: 64.84%] [G loss: 1.146575]\n",
      "epoch:1 step:1583 [D loss: 0.694625, acc.: 62.50%] [G loss: 1.122400]\n",
      "epoch:1 step:1584 [D loss: 0.717368, acc.: 57.81%] [G loss: 1.005318]\n",
      "epoch:1 step:1585 [D loss: 0.641333, acc.: 61.72%] [G loss: 1.240069]\n",
      "epoch:1 step:1586 [D loss: 0.706699, acc.: 54.69%] [G loss: 1.158678]\n",
      "epoch:1 step:1587 [D loss: 0.722256, acc.: 60.94%] [G loss: 1.017015]\n",
      "epoch:1 step:1588 [D loss: 0.701357, acc.: 61.72%] [G loss: 1.038929]\n",
      "epoch:1 step:1589 [D loss: 0.604939, acc.: 67.19%] [G loss: 1.232270]\n",
      "epoch:1 step:1590 [D loss: 0.613189, acc.: 67.19%] [G loss: 1.074717]\n",
      "epoch:1 step:1591 [D loss: 0.691337, acc.: 59.38%] [G loss: 1.082140]\n",
      "epoch:1 step:1592 [D loss: 0.669077, acc.: 61.72%] [G loss: 1.020838]\n",
      "epoch:1 step:1593 [D loss: 0.630822, acc.: 64.84%] [G loss: 1.156033]\n",
      "epoch:1 step:1594 [D loss: 0.667404, acc.: 64.84%] [G loss: 1.150116]\n",
      "epoch:1 step:1595 [D loss: 0.568947, acc.: 71.88%] [G loss: 1.192513]\n",
      "epoch:1 step:1596 [D loss: 0.691858, acc.: 60.16%] [G loss: 1.124404]\n",
      "epoch:1 step:1597 [D loss: 0.645978, acc.: 62.50%] [G loss: 1.087913]\n",
      "epoch:1 step:1598 [D loss: 0.635040, acc.: 64.06%] [G loss: 1.246869]\n",
      "epoch:1 step:1599 [D loss: 0.616668, acc.: 61.72%] [G loss: 1.103524]\n",
      "epoch:1 step:1600 [D loss: 0.699918, acc.: 54.69%] [G loss: 0.985116]\n",
      "epoch:1 step:1601 [D loss: 0.605771, acc.: 68.75%] [G loss: 1.183113]\n",
      "epoch:1 step:1602 [D loss: 0.687647, acc.: 60.16%] [G loss: 1.258709]\n",
      "epoch:1 step:1603 [D loss: 0.617350, acc.: 67.19%] [G loss: 1.090986]\n",
      "epoch:1 step:1604 [D loss: 0.690554, acc.: 59.38%] [G loss: 1.124306]\n",
      "epoch:1 step:1605 [D loss: 0.629482, acc.: 66.41%] [G loss: 1.029696]\n",
      "epoch:1 step:1606 [D loss: 0.636905, acc.: 60.94%] [G loss: 1.131941]\n",
      "epoch:1 step:1607 [D loss: 0.519454, acc.: 75.00%] [G loss: 1.292118]\n",
      "epoch:1 step:1608 [D loss: 0.640918, acc.: 67.97%] [G loss: 1.208569]\n",
      "epoch:1 step:1609 [D loss: 0.692285, acc.: 57.81%] [G loss: 1.123790]\n",
      "epoch:1 step:1610 [D loss: 0.587161, acc.: 70.31%] [G loss: 1.100671]\n",
      "epoch:1 step:1611 [D loss: 0.667968, acc.: 60.94%] [G loss: 1.010444]\n",
      "epoch:1 step:1612 [D loss: 0.650991, acc.: 64.84%] [G loss: 1.167467]\n",
      "epoch:1 step:1613 [D loss: 0.538041, acc.: 74.22%] [G loss: 1.124726]\n",
      "epoch:1 step:1614 [D loss: 0.671770, acc.: 64.06%] [G loss: 1.095156]\n",
      "epoch:1 step:1615 [D loss: 0.683827, acc.: 55.47%] [G loss: 1.028521]\n",
      "epoch:1 step:1616 [D loss: 0.634889, acc.: 60.94%] [G loss: 1.117979]\n",
      "epoch:1 step:1617 [D loss: 0.639930, acc.: 62.50%] [G loss: 1.033255]\n",
      "epoch:1 step:1618 [D loss: 0.634117, acc.: 67.19%] [G loss: 1.141234]\n",
      "epoch:1 step:1619 [D loss: 0.564574, acc.: 65.62%] [G loss: 1.274193]\n",
      "epoch:1 step:1620 [D loss: 0.620076, acc.: 64.84%] [G loss: 1.173268]\n",
      "epoch:1 step:1621 [D loss: 0.656236, acc.: 60.16%] [G loss: 1.146001]\n",
      "epoch:1 step:1622 [D loss: 0.628979, acc.: 67.19%] [G loss: 1.175621]\n",
      "epoch:1 step:1623 [D loss: 0.727765, acc.: 53.91%] [G loss: 1.094150]\n",
      "epoch:1 step:1624 [D loss: 0.671588, acc.: 64.84%] [G loss: 1.040942]\n",
      "epoch:1 step:1625 [D loss: 0.580228, acc.: 71.09%] [G loss: 1.103638]\n",
      "epoch:1 step:1626 [D loss: 0.618695, acc.: 62.50%] [G loss: 1.001039]\n",
      "epoch:1 step:1627 [D loss: 0.651287, acc.: 62.50%] [G loss: 1.067655]\n",
      "epoch:1 step:1628 [D loss: 0.595429, acc.: 69.53%] [G loss: 1.085043]\n",
      "epoch:1 step:1629 [D loss: 0.678142, acc.: 58.59%] [G loss: 1.064524]\n",
      "epoch:1 step:1630 [D loss: 0.659477, acc.: 62.50%] [G loss: 1.205158]\n",
      "epoch:1 step:1631 [D loss: 0.731962, acc.: 53.91%] [G loss: 1.133910]\n",
      "epoch:1 step:1632 [D loss: 0.705309, acc.: 64.06%] [G loss: 1.058602]\n",
      "epoch:1 step:1633 [D loss: 0.671882, acc.: 61.72%] [G loss: 1.151685]\n",
      "epoch:1 step:1634 [D loss: 0.679603, acc.: 61.72%] [G loss: 1.141528]\n",
      "epoch:1 step:1635 [D loss: 0.640069, acc.: 67.19%] [G loss: 1.021770]\n",
      "epoch:1 step:1636 [D loss: 0.740460, acc.: 55.47%] [G loss: 1.105449]\n",
      "epoch:1 step:1637 [D loss: 0.565636, acc.: 73.44%] [G loss: 1.108053]\n",
      "epoch:1 step:1638 [D loss: 0.611363, acc.: 64.84%] [G loss: 1.140687]\n",
      "epoch:1 step:1639 [D loss: 0.608492, acc.: 60.16%] [G loss: 1.156306]\n",
      "epoch:1 step:1640 [D loss: 0.610489, acc.: 64.84%] [G loss: 1.162205]\n",
      "epoch:1 step:1641 [D loss: 0.726375, acc.: 50.00%] [G loss: 1.352631]\n",
      "epoch:1 step:1642 [D loss: 0.627133, acc.: 67.19%] [G loss: 1.225304]\n",
      "epoch:1 step:1643 [D loss: 0.743092, acc.: 57.81%] [G loss: 1.135843]\n",
      "epoch:1 step:1644 [D loss: 0.641217, acc.: 64.06%] [G loss: 1.106971]\n",
      "epoch:1 step:1645 [D loss: 0.673488, acc.: 59.38%] [G loss: 1.103780]\n",
      "epoch:1 step:1646 [D loss: 0.759473, acc.: 51.56%] [G loss: 1.128828]\n",
      "epoch:1 step:1647 [D loss: 0.674738, acc.: 57.81%] [G loss: 1.298733]\n",
      "epoch:1 step:1648 [D loss: 0.698956, acc.: 57.03%] [G loss: 1.151602]\n",
      "epoch:1 step:1649 [D loss: 0.662697, acc.: 60.94%] [G loss: 1.116375]\n",
      "epoch:1 step:1650 [D loss: 0.612124, acc.: 64.84%] [G loss: 1.160766]\n",
      "epoch:1 step:1651 [D loss: 0.592578, acc.: 66.41%] [G loss: 1.223617]\n",
      "epoch:1 step:1652 [D loss: 0.653320, acc.: 59.38%] [G loss: 1.126026]\n",
      "epoch:1 step:1653 [D loss: 0.619283, acc.: 62.50%] [G loss: 1.153697]\n",
      "epoch:1 step:1654 [D loss: 0.616230, acc.: 66.41%] [G loss: 1.009980]\n",
      "epoch:1 step:1655 [D loss: 0.628243, acc.: 63.28%] [G loss: 1.135647]\n",
      "epoch:1 step:1656 [D loss: 0.730706, acc.: 53.12%] [G loss: 1.070656]\n",
      "epoch:1 step:1657 [D loss: 0.582334, acc.: 70.31%] [G loss: 1.131726]\n",
      "epoch:1 step:1658 [D loss: 0.686276, acc.: 60.94%] [G loss: 1.120463]\n",
      "epoch:1 step:1659 [D loss: 0.579569, acc.: 71.88%] [G loss: 1.058443]\n",
      "epoch:1 step:1660 [D loss: 0.673678, acc.: 57.03%] [G loss: 1.070139]\n",
      "epoch:1 step:1661 [D loss: 0.669795, acc.: 56.25%] [G loss: 1.023288]\n",
      "epoch:1 step:1662 [D loss: 0.578333, acc.: 69.53%] [G loss: 1.107231]\n",
      "epoch:1 step:1663 [D loss: 0.606292, acc.: 67.19%] [G loss: 1.173484]\n",
      "epoch:1 step:1664 [D loss: 0.574957, acc.: 71.88%] [G loss: 1.069591]\n",
      "epoch:1 step:1665 [D loss: 0.733071, acc.: 49.22%] [G loss: 0.970371]\n",
      "epoch:1 step:1666 [D loss: 0.607014, acc.: 70.31%] [G loss: 1.398474]\n",
      "epoch:1 step:1667 [D loss: 0.748850, acc.: 53.91%] [G loss: 1.034261]\n",
      "epoch:1 step:1668 [D loss: 0.681511, acc.: 61.72%] [G loss: 1.091481]\n",
      "epoch:1 step:1669 [D loss: 0.572267, acc.: 69.53%] [G loss: 1.184367]\n",
      "epoch:1 step:1670 [D loss: 0.633735, acc.: 63.28%] [G loss: 1.186938]\n",
      "epoch:1 step:1671 [D loss: 0.711267, acc.: 57.03%] [G loss: 1.192626]\n",
      "epoch:1 step:1672 [D loss: 0.595483, acc.: 65.62%] [G loss: 1.225014]\n",
      "epoch:1 step:1673 [D loss: 0.642062, acc.: 56.25%] [G loss: 1.139759]\n",
      "epoch:1 step:1674 [D loss: 0.722071, acc.: 57.03%] [G loss: 1.046179]\n",
      "epoch:1 step:1675 [D loss: 0.592878, acc.: 67.97%] [G loss: 1.183393]\n",
      "epoch:1 step:1676 [D loss: 0.737881, acc.: 46.88%] [G loss: 0.897387]\n",
      "epoch:1 step:1677 [D loss: 0.618890, acc.: 64.06%] [G loss: 1.075700]\n",
      "epoch:1 step:1678 [D loss: 0.668751, acc.: 58.59%] [G loss: 1.182881]\n",
      "epoch:1 step:1679 [D loss: 0.596978, acc.: 68.75%] [G loss: 1.186563]\n",
      "epoch:1 step:1680 [D loss: 0.773517, acc.: 53.12%] [G loss: 1.022588]\n",
      "epoch:1 step:1681 [D loss: 0.645668, acc.: 61.72%] [G loss: 1.071368]\n",
      "epoch:1 step:1682 [D loss: 0.618137, acc.: 67.97%] [G loss: 1.076977]\n",
      "epoch:1 step:1683 [D loss: 0.589195, acc.: 67.19%] [G loss: 1.165893]\n",
      "epoch:1 step:1684 [D loss: 0.745466, acc.: 57.03%] [G loss: 1.162394]\n",
      "epoch:1 step:1685 [D loss: 0.587167, acc.: 65.62%] [G loss: 1.317288]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:1 step:1686 [D loss: 0.731328, acc.: 50.78%] [G loss: 0.977005]\n",
      "epoch:1 step:1687 [D loss: 0.652123, acc.: 59.38%] [G loss: 1.127737]\n",
      "epoch:1 step:1688 [D loss: 0.579625, acc.: 71.88%] [G loss: 1.056093]\n",
      "epoch:1 step:1689 [D loss: 0.624797, acc.: 60.16%] [G loss: 1.104733]\n",
      "epoch:1 step:1690 [D loss: 0.597572, acc.: 69.53%] [G loss: 1.048878]\n",
      "epoch:1 step:1691 [D loss: 0.715811, acc.: 57.81%] [G loss: 1.105521]\n",
      "epoch:1 step:1692 [D loss: 0.612262, acc.: 67.19%] [G loss: 1.088812]\n",
      "epoch:1 step:1693 [D loss: 0.611430, acc.: 64.84%] [G loss: 1.144976]\n",
      "epoch:1 step:1694 [D loss: 0.622609, acc.: 62.50%] [G loss: 1.160085]\n",
      "epoch:1 step:1695 [D loss: 0.621637, acc.: 65.62%] [G loss: 1.014011]\n",
      "epoch:1 step:1696 [D loss: 0.689770, acc.: 58.59%] [G loss: 1.057336]\n",
      "epoch:1 step:1697 [D loss: 0.716629, acc.: 57.81%] [G loss: 1.188955]\n",
      "epoch:1 step:1698 [D loss: 0.730189, acc.: 49.22%] [G loss: 1.049940]\n",
      "epoch:1 step:1699 [D loss: 0.726629, acc.: 51.56%] [G loss: 1.023506]\n",
      "epoch:1 step:1700 [D loss: 0.640474, acc.: 61.72%] [G loss: 1.014788]\n",
      "epoch:1 step:1701 [D loss: 0.589371, acc.: 65.62%] [G loss: 1.125985]\n",
      "epoch:1 step:1702 [D loss: 0.650652, acc.: 60.16%] [G loss: 1.099372]\n",
      "epoch:1 step:1703 [D loss: 0.628221, acc.: 63.28%] [G loss: 1.088088]\n",
      "epoch:1 step:1704 [D loss: 0.623610, acc.: 62.50%] [G loss: 1.236689]\n",
      "epoch:1 step:1705 [D loss: 0.720671, acc.: 54.69%] [G loss: 1.039425]\n",
      "epoch:1 step:1706 [D loss: 0.782570, acc.: 53.12%] [G loss: 1.083910]\n",
      "epoch:1 step:1707 [D loss: 0.645017, acc.: 63.28%] [G loss: 1.141104]\n",
      "epoch:1 step:1708 [D loss: 0.680082, acc.: 54.69%] [G loss: 1.112642]\n",
      "epoch:1 step:1709 [D loss: 0.660463, acc.: 61.72%] [G loss: 1.235133]\n",
      "epoch:1 step:1710 [D loss: 0.721969, acc.: 54.69%] [G loss: 1.292900]\n",
      "epoch:1 step:1711 [D loss: 0.685575, acc.: 57.03%] [G loss: 1.203217]\n",
      "epoch:1 step:1712 [D loss: 0.640476, acc.: 63.28%] [G loss: 1.192665]\n",
      "epoch:1 step:1713 [D loss: 0.637545, acc.: 64.06%] [G loss: 1.151123]\n",
      "epoch:1 step:1714 [D loss: 0.838462, acc.: 43.75%] [G loss: 1.013738]\n",
      "epoch:1 step:1715 [D loss: 0.564993, acc.: 71.09%] [G loss: 1.084008]\n",
      "epoch:1 step:1716 [D loss: 0.530963, acc.: 75.78%] [G loss: 1.072736]\n",
      "epoch:1 step:1717 [D loss: 0.722024, acc.: 58.59%] [G loss: 1.110913]\n",
      "epoch:1 step:1718 [D loss: 0.655907, acc.: 62.50%] [G loss: 1.090473]\n",
      "epoch:1 step:1719 [D loss: 0.751640, acc.: 50.78%] [G loss: 0.934993]\n",
      "epoch:1 step:1720 [D loss: 0.665556, acc.: 59.38%] [G loss: 1.196861]\n",
      "epoch:1 step:1721 [D loss: 0.656936, acc.: 61.72%] [G loss: 1.195571]\n",
      "epoch:1 step:1722 [D loss: 0.668566, acc.: 62.50%] [G loss: 1.136583]\n",
      "epoch:1 step:1723 [D loss: 0.601815, acc.: 66.41%] [G loss: 1.224764]\n",
      "epoch:1 step:1724 [D loss: 0.581769, acc.: 66.41%] [G loss: 1.167065]\n",
      "epoch:1 step:1725 [D loss: 0.642269, acc.: 67.19%] [G loss: 1.228662]\n",
      "epoch:1 step:1726 [D loss: 0.546500, acc.: 72.66%] [G loss: 1.047509]\n",
      "epoch:1 step:1727 [D loss: 0.631091, acc.: 58.59%] [G loss: 1.203387]\n",
      "epoch:1 step:1728 [D loss: 0.685344, acc.: 60.94%] [G loss: 1.102589]\n",
      "epoch:1 step:1729 [D loss: 0.602888, acc.: 71.09%] [G loss: 1.079258]\n",
      "epoch:1 step:1730 [D loss: 0.689739, acc.: 61.72%] [G loss: 0.915419]\n",
      "epoch:1 step:1731 [D loss: 0.587614, acc.: 71.88%] [G loss: 1.196852]\n",
      "epoch:1 step:1732 [D loss: 0.579885, acc.: 67.97%] [G loss: 1.201504]\n",
      "epoch:1 step:1733 [D loss: 0.550866, acc.: 71.09%] [G loss: 1.283322]\n",
      "epoch:1 step:1734 [D loss: 0.705144, acc.: 57.81%] [G loss: 1.044208]\n",
      "epoch:1 step:1735 [D loss: 0.630632, acc.: 64.06%] [G loss: 1.104127]\n",
      "epoch:1 step:1736 [D loss: 0.761372, acc.: 50.00%] [G loss: 1.122181]\n",
      "epoch:1 step:1737 [D loss: 0.571895, acc.: 67.19%] [G loss: 1.225069]\n",
      "epoch:1 step:1738 [D loss: 0.724380, acc.: 52.34%] [G loss: 1.016023]\n",
      "epoch:1 step:1739 [D loss: 0.643657, acc.: 61.72%] [G loss: 0.987932]\n",
      "epoch:1 step:1740 [D loss: 0.670046, acc.: 55.47%] [G loss: 1.043960]\n",
      "epoch:1 step:1741 [D loss: 0.654284, acc.: 60.16%] [G loss: 1.196447]\n",
      "epoch:1 step:1742 [D loss: 0.707588, acc.: 56.25%] [G loss: 1.135241]\n",
      "epoch:1 step:1743 [D loss: 0.651000, acc.: 62.50%] [G loss: 1.051927]\n",
      "epoch:1 step:1744 [D loss: 0.614869, acc.: 71.88%] [G loss: 1.079129]\n",
      "epoch:1 step:1745 [D loss: 0.554104, acc.: 68.75%] [G loss: 1.224829]\n",
      "epoch:1 step:1746 [D loss: 0.614269, acc.: 65.62%] [G loss: 1.175820]\n",
      "epoch:1 step:1747 [D loss: 0.652635, acc.: 62.50%] [G loss: 1.261433]\n",
      "epoch:1 step:1748 [D loss: 0.600217, acc.: 65.62%] [G loss: 1.219748]\n",
      "epoch:1 step:1749 [D loss: 0.692305, acc.: 55.47%] [G loss: 1.067819]\n",
      "epoch:1 step:1750 [D loss: 0.699589, acc.: 53.91%] [G loss: 0.981119]\n",
      "epoch:1 step:1751 [D loss: 0.656378, acc.: 60.94%] [G loss: 1.221095]\n",
      "epoch:1 step:1752 [D loss: 0.667710, acc.: 60.16%] [G loss: 1.047553]\n",
      "epoch:1 step:1753 [D loss: 0.582975, acc.: 71.88%] [G loss: 1.140112]\n",
      "epoch:1 step:1754 [D loss: 0.686700, acc.: 59.38%] [G loss: 1.185958]\n",
      "epoch:1 step:1755 [D loss: 0.697864, acc.: 60.16%] [G loss: 1.077838]\n",
      "epoch:1 step:1756 [D loss: 0.658618, acc.: 57.81%] [G loss: 1.035835]\n",
      "epoch:1 step:1757 [D loss: 0.658693, acc.: 62.50%] [G loss: 1.045765]\n",
      "epoch:1 step:1758 [D loss: 0.732716, acc.: 54.69%] [G loss: 1.197707]\n",
      "epoch:1 step:1759 [D loss: 0.658357, acc.: 64.06%] [G loss: 1.185682]\n",
      "epoch:1 step:1760 [D loss: 0.630663, acc.: 62.50%] [G loss: 1.286057]\n",
      "epoch:1 step:1761 [D loss: 0.703750, acc.: 60.94%] [G loss: 1.140284]\n",
      "epoch:1 step:1762 [D loss: 0.678722, acc.: 62.50%] [G loss: 1.098341]\n",
      "epoch:1 step:1763 [D loss: 0.569472, acc.: 72.66%] [G loss: 1.254431]\n",
      "epoch:1 step:1764 [D loss: 0.782255, acc.: 49.22%] [G loss: 1.043765]\n",
      "epoch:1 step:1765 [D loss: 0.718811, acc.: 58.59%] [G loss: 1.065037]\n",
      "epoch:1 step:1766 [D loss: 0.562371, acc.: 73.44%] [G loss: 1.074449]\n",
      "epoch:1 step:1767 [D loss: 0.728521, acc.: 58.59%] [G loss: 1.104935]\n",
      "epoch:1 step:1768 [D loss: 0.637680, acc.: 60.16%] [G loss: 1.127455]\n",
      "epoch:1 step:1769 [D loss: 0.613662, acc.: 68.75%] [G loss: 1.257722]\n",
      "epoch:1 step:1770 [D loss: 0.705112, acc.: 60.16%] [G loss: 1.022321]\n",
      "epoch:1 step:1771 [D loss: 0.766322, acc.: 48.44%] [G loss: 1.094140]\n",
      "epoch:1 step:1772 [D loss: 0.594579, acc.: 69.53%] [G loss: 1.131464]\n",
      "epoch:1 step:1773 [D loss: 0.604275, acc.: 63.28%] [G loss: 1.110132]\n",
      "epoch:1 step:1774 [D loss: 0.657673, acc.: 63.28%] [G loss: 1.077721]\n",
      "epoch:1 step:1775 [D loss: 0.734142, acc.: 57.81%] [G loss: 0.972315]\n",
      "epoch:1 step:1776 [D loss: 0.683202, acc.: 61.72%] [G loss: 1.014211]\n",
      "epoch:1 step:1777 [D loss: 0.635963, acc.: 67.97%] [G loss: 1.128199]\n",
      "epoch:1 step:1778 [D loss: 0.592136, acc.: 66.41%] [G loss: 1.199042]\n",
      "epoch:1 step:1779 [D loss: 0.643971, acc.: 56.25%] [G loss: 1.239329]\n",
      "epoch:1 step:1780 [D loss: 0.614746, acc.: 61.72%] [G loss: 1.211244]\n",
      "epoch:1 step:1781 [D loss: 0.790321, acc.: 42.19%] [G loss: 0.926191]\n",
      "epoch:1 step:1782 [D loss: 0.594549, acc.: 64.06%] [G loss: 1.056674]\n",
      "epoch:1 step:1783 [D loss: 0.660762, acc.: 61.72%] [G loss: 1.134532]\n",
      "epoch:1 step:1784 [D loss: 0.643893, acc.: 65.62%] [G loss: 0.998014]\n",
      "epoch:1 step:1785 [D loss: 0.629643, acc.: 63.28%] [G loss: 1.024199]\n",
      "epoch:1 step:1786 [D loss: 0.599988, acc.: 70.31%] [G loss: 1.076983]\n",
      "epoch:1 step:1787 [D loss: 0.527099, acc.: 76.56%] [G loss: 1.163865]\n",
      "epoch:1 step:1788 [D loss: 0.743972, acc.: 50.78%] [G loss: 1.013511]\n",
      "epoch:1 step:1789 [D loss: 0.535428, acc.: 71.88%] [G loss: 1.143300]\n",
      "epoch:1 step:1790 [D loss: 0.583998, acc.: 68.75%] [G loss: 0.992691]\n",
      "epoch:1 step:1791 [D loss: 0.675162, acc.: 61.72%] [G loss: 1.040772]\n",
      "epoch:1 step:1792 [D loss: 0.720751, acc.: 48.44%] [G loss: 1.198372]\n",
      "epoch:1 step:1793 [D loss: 0.619409, acc.: 63.28%] [G loss: 1.063036]\n",
      "epoch:1 step:1794 [D loss: 0.666093, acc.: 60.16%] [G loss: 1.177462]\n",
      "epoch:1 step:1795 [D loss: 0.690061, acc.: 50.78%] [G loss: 1.023911]\n",
      "epoch:1 step:1796 [D loss: 0.638457, acc.: 66.41%] [G loss: 1.169796]\n",
      "epoch:1 step:1797 [D loss: 0.603611, acc.: 70.31%] [G loss: 1.230375]\n",
      "epoch:1 step:1798 [D loss: 0.584712, acc.: 71.09%] [G loss: 1.224742]\n",
      "epoch:1 step:1799 [D loss: 0.703592, acc.: 57.03%] [G loss: 0.932742]\n",
      "epoch:1 step:1800 [D loss: 0.651042, acc.: 64.84%] [G loss: 0.980439]\n",
      "epoch:1 step:1801 [D loss: 0.636791, acc.: 64.06%] [G loss: 0.940306]\n",
      "epoch:1 step:1802 [D loss: 0.569173, acc.: 67.97%] [G loss: 1.110082]\n",
      "epoch:1 step:1803 [D loss: 0.585017, acc.: 67.97%] [G loss: 0.991565]\n",
      "epoch:1 step:1804 [D loss: 0.656175, acc.: 62.50%] [G loss: 0.941019]\n",
      "epoch:1 step:1805 [D loss: 0.600993, acc.: 67.97%] [G loss: 1.224010]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:1 step:1806 [D loss: 0.706048, acc.: 55.47%] [G loss: 1.151082]\n",
      "epoch:1 step:1807 [D loss: 0.759615, acc.: 50.78%] [G loss: 1.085653]\n",
      "epoch:1 step:1808 [D loss: 0.626467, acc.: 65.62%] [G loss: 1.033317]\n",
      "epoch:1 step:1809 [D loss: 0.710702, acc.: 57.03%] [G loss: 1.195056]\n",
      "epoch:1 step:1810 [D loss: 0.588309, acc.: 67.19%] [G loss: 1.282501]\n",
      "epoch:1 step:1811 [D loss: 0.649988, acc.: 62.50%] [G loss: 1.103577]\n",
      "epoch:1 step:1812 [D loss: 0.683041, acc.: 57.81%] [G loss: 0.948569]\n",
      "epoch:1 step:1813 [D loss: 0.673944, acc.: 60.16%] [G loss: 1.135718]\n",
      "epoch:1 step:1814 [D loss: 0.611811, acc.: 64.84%] [G loss: 1.221105]\n",
      "epoch:1 step:1815 [D loss: 0.647085, acc.: 67.19%] [G loss: 1.148609]\n",
      "epoch:1 step:1816 [D loss: 0.676657, acc.: 61.72%] [G loss: 1.139347]\n",
      "epoch:1 step:1817 [D loss: 0.619333, acc.: 66.41%] [G loss: 1.061552]\n",
      "epoch:1 step:1818 [D loss: 0.695851, acc.: 59.38%] [G loss: 1.135568]\n",
      "epoch:1 step:1819 [D loss: 0.596470, acc.: 70.31%] [G loss: 1.138881]\n",
      "epoch:1 step:1820 [D loss: 0.707070, acc.: 57.81%] [G loss: 1.160250]\n",
      "epoch:1 step:1821 [D loss: 0.693499, acc.: 56.25%] [G loss: 1.066535]\n",
      "epoch:1 step:1822 [D loss: 0.658748, acc.: 63.28%] [G loss: 1.170922]\n",
      "epoch:1 step:1823 [D loss: 0.630035, acc.: 63.28%] [G loss: 1.023571]\n",
      "epoch:1 step:1824 [D loss: 0.692324, acc.: 53.12%] [G loss: 1.109879]\n",
      "epoch:1 step:1825 [D loss: 0.743469, acc.: 55.47%] [G loss: 0.973796]\n",
      "epoch:1 step:1826 [D loss: 0.667676, acc.: 64.84%] [G loss: 1.132780]\n",
      "epoch:1 step:1827 [D loss: 0.688025, acc.: 54.69%] [G loss: 1.279472]\n",
      "epoch:1 step:1828 [D loss: 0.721589, acc.: 53.91%] [G loss: 0.991910]\n",
      "epoch:1 step:1829 [D loss: 0.709343, acc.: 54.69%] [G loss: 1.049556]\n",
      "epoch:1 step:1830 [D loss: 0.632423, acc.: 64.84%] [G loss: 0.945102]\n",
      "epoch:1 step:1831 [D loss: 0.723762, acc.: 55.47%] [G loss: 0.927184]\n",
      "epoch:1 step:1832 [D loss: 0.642088, acc.: 64.06%] [G loss: 1.043614]\n",
      "epoch:1 step:1833 [D loss: 0.765530, acc.: 53.91%] [G loss: 1.022653]\n",
      "epoch:1 step:1834 [D loss: 0.637106, acc.: 60.94%] [G loss: 0.991312]\n",
      "epoch:1 step:1835 [D loss: 0.610233, acc.: 64.06%] [G loss: 1.156502]\n",
      "epoch:1 step:1836 [D loss: 0.722686, acc.: 58.59%] [G loss: 1.090109]\n",
      "epoch:1 step:1837 [D loss: 0.635561, acc.: 66.41%] [G loss: 1.191656]\n",
      "epoch:1 step:1838 [D loss: 0.668961, acc.: 60.94%] [G loss: 1.106711]\n",
      "epoch:1 step:1839 [D loss: 0.574342, acc.: 71.09%] [G loss: 1.223338]\n",
      "epoch:1 step:1840 [D loss: 0.588480, acc.: 67.97%] [G loss: 1.197317]\n",
      "epoch:1 step:1841 [D loss: 0.641383, acc.: 64.84%] [G loss: 1.067848]\n",
      "epoch:1 step:1842 [D loss: 0.696839, acc.: 57.03%] [G loss: 0.958142]\n",
      "epoch:1 step:1843 [D loss: 0.637684, acc.: 61.72%] [G loss: 1.129134]\n",
      "epoch:1 step:1844 [D loss: 0.677999, acc.: 60.16%] [G loss: 1.092241]\n",
      "epoch:1 step:1845 [D loss: 0.676283, acc.: 58.59%] [G loss: 1.130390]\n",
      "epoch:1 step:1846 [D loss: 0.748796, acc.: 53.91%] [G loss: 0.994715]\n",
      "epoch:1 step:1847 [D loss: 0.627903, acc.: 65.62%] [G loss: 1.099071]\n",
      "epoch:1 step:1848 [D loss: 0.507659, acc.: 72.66%] [G loss: 1.254066]\n",
      "epoch:1 step:1849 [D loss: 0.611163, acc.: 69.53%] [G loss: 1.185505]\n",
      "epoch:1 step:1850 [D loss: 0.600489, acc.: 64.06%] [G loss: 1.207689]\n",
      "epoch:1 step:1851 [D loss: 0.742722, acc.: 53.91%] [G loss: 1.044375]\n",
      "epoch:1 step:1852 [D loss: 0.629827, acc.: 64.06%] [G loss: 1.128498]\n",
      "epoch:1 step:1853 [D loss: 0.636474, acc.: 62.50%] [G loss: 0.958732]\n",
      "epoch:1 step:1854 [D loss: 0.670330, acc.: 59.38%] [G loss: 1.151257]\n",
      "epoch:1 step:1855 [D loss: 0.666267, acc.: 63.28%] [G loss: 1.061172]\n",
      "epoch:1 step:1856 [D loss: 0.611646, acc.: 66.41%] [G loss: 1.093831]\n",
      "epoch:1 step:1857 [D loss: 0.649113, acc.: 65.62%] [G loss: 1.008283]\n",
      "epoch:1 step:1858 [D loss: 0.633406, acc.: 62.50%] [G loss: 1.022755]\n",
      "epoch:1 step:1859 [D loss: 0.703863, acc.: 57.81%] [G loss: 1.032543]\n",
      "epoch:1 step:1860 [D loss: 0.704977, acc.: 55.47%] [G loss: 1.105094]\n",
      "epoch:1 step:1861 [D loss: 0.638195, acc.: 64.06%] [G loss: 1.038683]\n",
      "epoch:1 step:1862 [D loss: 0.704654, acc.: 57.03%] [G loss: 1.104334]\n",
      "epoch:1 step:1863 [D loss: 0.716774, acc.: 53.91%] [G loss: 0.971020]\n",
      "epoch:1 step:1864 [D loss: 0.668512, acc.: 57.03%] [G loss: 1.113958]\n",
      "epoch:1 step:1865 [D loss: 0.573544, acc.: 70.31%] [G loss: 1.139865]\n",
      "epoch:1 step:1866 [D loss: 0.629481, acc.: 63.28%] [G loss: 1.037603]\n",
      "epoch:1 step:1867 [D loss: 0.598393, acc.: 67.97%] [G loss: 1.102524]\n",
      "epoch:1 step:1868 [D loss: 0.616688, acc.: 63.28%] [G loss: 1.143105]\n",
      "epoch:1 step:1869 [D loss: 0.589954, acc.: 70.31%] [G loss: 1.039942]\n",
      "epoch:1 step:1870 [D loss: 0.717511, acc.: 59.38%] [G loss: 0.942622]\n",
      "epoch:1 step:1871 [D loss: 0.653484, acc.: 62.50%] [G loss: 1.061859]\n",
      "epoch:1 step:1872 [D loss: 0.714223, acc.: 57.03%] [G loss: 1.055521]\n",
      "epoch:1 step:1873 [D loss: 0.700907, acc.: 60.16%] [G loss: 1.138607]\n",
      "epoch:1 step:1874 [D loss: 0.660424, acc.: 60.94%] [G loss: 1.238917]\n",
      "epoch:2 step:1875 [D loss: 0.715811, acc.: 57.81%] [G loss: 1.030459]\n",
      "epoch:2 step:1876 [D loss: 0.637996, acc.: 65.62%] [G loss: 1.052461]\n",
      "epoch:2 step:1877 [D loss: 0.622578, acc.: 60.16%] [G loss: 1.036102]\n",
      "epoch:2 step:1878 [D loss: 0.663135, acc.: 64.06%] [G loss: 1.225760]\n",
      "epoch:2 step:1879 [D loss: 0.610317, acc.: 67.19%] [G loss: 1.163774]\n",
      "epoch:2 step:1880 [D loss: 0.699028, acc.: 56.25%] [G loss: 0.933385]\n",
      "epoch:2 step:1881 [D loss: 0.800156, acc.: 50.78%] [G loss: 0.998396]\n",
      "epoch:2 step:1882 [D loss: 0.558403, acc.: 73.44%] [G loss: 1.073267]\n",
      "epoch:2 step:1883 [D loss: 0.680394, acc.: 59.38%] [G loss: 1.087036]\n",
      "epoch:2 step:1884 [D loss: 0.712119, acc.: 57.03%] [G loss: 1.033584]\n",
      "epoch:2 step:1885 [D loss: 0.589783, acc.: 64.84%] [G loss: 1.361851]\n",
      "epoch:2 step:1886 [D loss: 0.715763, acc.: 55.47%] [G loss: 1.028728]\n",
      "epoch:2 step:1887 [D loss: 0.545743, acc.: 72.66%] [G loss: 1.261710]\n",
      "epoch:2 step:1888 [D loss: 0.680212, acc.: 59.38%] [G loss: 1.075553]\n",
      "epoch:2 step:1889 [D loss: 0.624880, acc.: 65.62%] [G loss: 0.945087]\n",
      "epoch:2 step:1890 [D loss: 0.708507, acc.: 56.25%] [G loss: 0.960874]\n",
      "epoch:2 step:1891 [D loss: 0.558412, acc.: 71.88%] [G loss: 1.208905]\n",
      "epoch:2 step:1892 [D loss: 0.657210, acc.: 64.84%] [G loss: 1.162332]\n",
      "epoch:2 step:1893 [D loss: 0.688025, acc.: 60.94%] [G loss: 1.047114]\n",
      "epoch:2 step:1894 [D loss: 0.700177, acc.: 55.47%] [G loss: 1.023243]\n",
      "epoch:2 step:1895 [D loss: 0.687085, acc.: 58.59%] [G loss: 1.082367]\n",
      "epoch:2 step:1896 [D loss: 0.614066, acc.: 65.62%] [G loss: 1.054490]\n",
      "epoch:2 step:1897 [D loss: 0.771354, acc.: 53.91%] [G loss: 1.009550]\n",
      "epoch:2 step:1898 [D loss: 0.616618, acc.: 62.50%] [G loss: 1.178064]\n",
      "epoch:2 step:1899 [D loss: 0.668901, acc.: 62.50%] [G loss: 0.970131]\n",
      "epoch:2 step:1900 [D loss: 0.616575, acc.: 66.41%] [G loss: 1.185237]\n",
      "epoch:2 step:1901 [D loss: 0.648763, acc.: 57.81%] [G loss: 1.093741]\n",
      "epoch:2 step:1902 [D loss: 0.590486, acc.: 65.62%] [G loss: 1.051921]\n",
      "epoch:2 step:1903 [D loss: 0.631197, acc.: 67.97%] [G loss: 1.054446]\n",
      "epoch:2 step:1904 [D loss: 0.572280, acc.: 68.75%] [G loss: 1.124467]\n",
      "epoch:2 step:1905 [D loss: 0.703198, acc.: 52.34%] [G loss: 0.938308]\n",
      "epoch:2 step:1906 [D loss: 0.613061, acc.: 70.31%] [G loss: 1.230499]\n",
      "epoch:2 step:1907 [D loss: 0.635752, acc.: 65.62%] [G loss: 1.085847]\n",
      "epoch:2 step:1908 [D loss: 0.639311, acc.: 61.72%] [G loss: 1.136349]\n",
      "epoch:2 step:1909 [D loss: 0.592084, acc.: 64.06%] [G loss: 1.190495]\n",
      "epoch:2 step:1910 [D loss: 0.598232, acc.: 67.97%] [G loss: 1.130052]\n",
      "epoch:2 step:1911 [D loss: 0.669211, acc.: 60.94%] [G loss: 1.124399]\n",
      "epoch:2 step:1912 [D loss: 0.638132, acc.: 66.41%] [G loss: 1.232085]\n",
      "epoch:2 step:1913 [D loss: 0.638468, acc.: 63.28%] [G loss: 1.139605]\n",
      "epoch:2 step:1914 [D loss: 0.726595, acc.: 55.47%] [G loss: 1.120527]\n",
      "epoch:2 step:1915 [D loss: 0.645527, acc.: 65.62%] [G loss: 1.081942]\n",
      "epoch:2 step:1916 [D loss: 0.632856, acc.: 61.72%] [G loss: 1.122175]\n",
      "epoch:2 step:1917 [D loss: 0.665174, acc.: 60.94%] [G loss: 1.130837]\n",
      "epoch:2 step:1918 [D loss: 0.691627, acc.: 54.69%] [G loss: 1.000103]\n",
      "epoch:2 step:1919 [D loss: 0.597352, acc.: 67.19%] [G loss: 1.078170]\n",
      "epoch:2 step:1920 [D loss: 0.728692, acc.: 50.00%] [G loss: 1.016458]\n",
      "epoch:2 step:1921 [D loss: 0.757983, acc.: 53.91%] [G loss: 0.897404]\n",
      "epoch:2 step:1922 [D loss: 0.715114, acc.: 62.50%] [G loss: 0.950914]\n",
      "epoch:2 step:1923 [D loss: 0.671431, acc.: 63.28%] [G loss: 1.051268]\n",
      "epoch:2 step:1924 [D loss: 0.596870, acc.: 67.19%] [G loss: 1.047543]\n",
      "epoch:2 step:1925 [D loss: 0.773314, acc.: 52.34%] [G loss: 0.904185]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:2 step:1926 [D loss: 0.687823, acc.: 60.16%] [G loss: 1.030375]\n",
      "epoch:2 step:1927 [D loss: 0.555373, acc.: 73.44%] [G loss: 1.216125]\n",
      "epoch:2 step:1928 [D loss: 0.622850, acc.: 68.75%] [G loss: 1.234317]\n",
      "epoch:2 step:1929 [D loss: 0.667974, acc.: 63.28%] [G loss: 1.055523]\n",
      "epoch:2 step:1930 [D loss: 0.706094, acc.: 58.59%] [G loss: 0.988036]\n",
      "epoch:2 step:1931 [D loss: 0.591178, acc.: 68.75%] [G loss: 1.256034]\n",
      "epoch:2 step:1932 [D loss: 0.717833, acc.: 57.81%] [G loss: 1.022762]\n",
      "epoch:2 step:1933 [D loss: 0.678720, acc.: 59.38%] [G loss: 1.043714]\n",
      "epoch:2 step:1934 [D loss: 0.599659, acc.: 66.41%] [G loss: 1.162560]\n",
      "epoch:2 step:1935 [D loss: 0.693495, acc.: 61.72%] [G loss: 1.080992]\n",
      "epoch:2 step:1936 [D loss: 0.678132, acc.: 57.81%] [G loss: 1.162984]\n",
      "epoch:2 step:1937 [D loss: 0.798276, acc.: 46.09%] [G loss: 1.090670]\n",
      "epoch:2 step:1938 [D loss: 0.634323, acc.: 67.97%] [G loss: 1.159069]\n",
      "epoch:2 step:1939 [D loss: 0.667637, acc.: 62.50%] [G loss: 1.061748]\n",
      "epoch:2 step:1940 [D loss: 0.689165, acc.: 58.59%] [G loss: 1.122184]\n",
      "epoch:2 step:1941 [D loss: 0.711349, acc.: 53.91%] [G loss: 0.998539]\n",
      "epoch:2 step:1942 [D loss: 0.640801, acc.: 56.25%] [G loss: 1.066253]\n",
      "epoch:2 step:1943 [D loss: 0.630101, acc.: 65.62%] [G loss: 1.163839]\n",
      "epoch:2 step:1944 [D loss: 0.693403, acc.: 55.47%] [G loss: 1.261845]\n",
      "epoch:2 step:1945 [D loss: 0.697965, acc.: 56.25%] [G loss: 1.141201]\n",
      "epoch:2 step:1946 [D loss: 0.588769, acc.: 66.41%] [G loss: 1.207380]\n",
      "epoch:2 step:1947 [D loss: 0.656559, acc.: 58.59%] [G loss: 1.173162]\n",
      "epoch:2 step:1948 [D loss: 0.669892, acc.: 62.50%] [G loss: 1.268060]\n",
      "epoch:2 step:1949 [D loss: 0.750061, acc.: 53.12%] [G loss: 1.006352]\n",
      "epoch:2 step:1950 [D loss: 0.617805, acc.: 63.28%] [G loss: 1.094193]\n",
      "epoch:2 step:1951 [D loss: 0.621974, acc.: 62.50%] [G loss: 0.968760]\n",
      "epoch:2 step:1952 [D loss: 0.705258, acc.: 58.59%] [G loss: 1.014852]\n",
      "epoch:2 step:1953 [D loss: 0.721647, acc.: 53.91%] [G loss: 1.092657]\n",
      "epoch:2 step:1954 [D loss: 0.711931, acc.: 56.25%] [G loss: 1.026005]\n",
      "epoch:2 step:1955 [D loss: 0.652294, acc.: 56.25%] [G loss: 0.999951]\n",
      "epoch:2 step:1956 [D loss: 0.618641, acc.: 71.88%] [G loss: 0.962151]\n",
      "epoch:2 step:1957 [D loss: 0.658118, acc.: 64.06%] [G loss: 0.944641]\n",
      "epoch:2 step:1958 [D loss: 0.666386, acc.: 60.94%] [G loss: 1.108757]\n",
      "epoch:2 step:1959 [D loss: 0.584460, acc.: 71.09%] [G loss: 1.069449]\n",
      "epoch:2 step:1960 [D loss: 0.642502, acc.: 58.59%] [G loss: 1.098447]\n",
      "epoch:2 step:1961 [D loss: 0.676808, acc.: 58.59%] [G loss: 1.066976]\n",
      "epoch:2 step:1962 [D loss: 0.703776, acc.: 58.59%] [G loss: 1.008894]\n",
      "epoch:2 step:1963 [D loss: 0.765326, acc.: 52.34%] [G loss: 0.980500]\n",
      "epoch:2 step:1964 [D loss: 0.669002, acc.: 59.38%] [G loss: 1.106625]\n",
      "epoch:2 step:1965 [D loss: 0.673737, acc.: 58.59%] [G loss: 1.002156]\n",
      "epoch:2 step:1966 [D loss: 0.631165, acc.: 67.97%] [G loss: 1.043886]\n",
      "epoch:2 step:1967 [D loss: 0.707794, acc.: 53.12%] [G loss: 1.031169]\n",
      "epoch:2 step:1968 [D loss: 0.551735, acc.: 69.53%] [G loss: 1.096690]\n",
      "epoch:2 step:1969 [D loss: 0.672403, acc.: 65.62%] [G loss: 0.944749]\n",
      "epoch:2 step:1970 [D loss: 0.611285, acc.: 69.53%] [G loss: 1.141713]\n",
      "epoch:2 step:1971 [D loss: 0.674142, acc.: 64.84%] [G loss: 0.977674]\n",
      "epoch:2 step:1972 [D loss: 0.706308, acc.: 61.72%] [G loss: 0.962421]\n",
      "epoch:2 step:1973 [D loss: 0.699953, acc.: 57.03%] [G loss: 1.138716]\n",
      "epoch:2 step:1974 [D loss: 0.723696, acc.: 53.12%] [G loss: 0.955956]\n",
      "epoch:2 step:1975 [D loss: 0.566922, acc.: 68.75%] [G loss: 1.274949]\n",
      "epoch:2 step:1976 [D loss: 0.675023, acc.: 59.38%] [G loss: 1.010635]\n",
      "epoch:2 step:1977 [D loss: 0.680437, acc.: 57.81%] [G loss: 1.068691]\n",
      "epoch:2 step:1978 [D loss: 0.605583, acc.: 67.19%] [G loss: 1.159374]\n",
      "epoch:2 step:1979 [D loss: 0.549505, acc.: 74.22%] [G loss: 1.150861]\n",
      "epoch:2 step:1980 [D loss: 0.632523, acc.: 60.16%] [G loss: 1.028522]\n",
      "epoch:2 step:1981 [D loss: 0.621700, acc.: 67.19%] [G loss: 1.054319]\n",
      "epoch:2 step:1982 [D loss: 0.655175, acc.: 64.84%] [G loss: 1.002723]\n",
      "epoch:2 step:1983 [D loss: 0.688662, acc.: 53.91%] [G loss: 1.038405]\n",
      "epoch:2 step:1984 [D loss: 0.607904, acc.: 65.62%] [G loss: 1.229933]\n",
      "epoch:2 step:1985 [D loss: 0.573233, acc.: 72.66%] [G loss: 1.168110]\n",
      "epoch:2 step:1986 [D loss: 0.708562, acc.: 54.69%] [G loss: 1.210887]\n",
      "epoch:2 step:1987 [D loss: 0.570366, acc.: 68.75%] [G loss: 1.082012]\n",
      "epoch:2 step:1988 [D loss: 0.636596, acc.: 59.38%] [G loss: 1.068446]\n",
      "epoch:2 step:1989 [D loss: 0.695477, acc.: 53.91%] [G loss: 1.184574]\n",
      "epoch:2 step:1990 [D loss: 0.582036, acc.: 68.75%] [G loss: 1.026197]\n",
      "epoch:2 step:1991 [D loss: 0.659668, acc.: 56.25%] [G loss: 0.989846]\n",
      "epoch:2 step:1992 [D loss: 0.606424, acc.: 67.97%] [G loss: 1.030123]\n",
      "epoch:2 step:1993 [D loss: 0.684178, acc.: 57.03%] [G loss: 1.263919]\n",
      "epoch:2 step:1994 [D loss: 0.670853, acc.: 56.25%] [G loss: 1.179903]\n",
      "epoch:2 step:1995 [D loss: 0.784955, acc.: 48.44%] [G loss: 1.252321]\n",
      "epoch:2 step:1996 [D loss: 0.608767, acc.: 62.50%] [G loss: 1.087255]\n",
      "epoch:2 step:1997 [D loss: 0.659674, acc.: 57.81%] [G loss: 1.097942]\n",
      "epoch:2 step:1998 [D loss: 0.666106, acc.: 56.25%] [G loss: 1.219714]\n",
      "epoch:2 step:1999 [D loss: 0.690871, acc.: 52.34%] [G loss: 1.163948]\n",
      "epoch:2 step:2000 [D loss: 0.671153, acc.: 57.81%] [G loss: 1.056815]\n",
      "epoch:2 step:2001 [D loss: 0.704708, acc.: 58.59%] [G loss: 1.055666]\n",
      "epoch:2 step:2002 [D loss: 0.643057, acc.: 63.28%] [G loss: 0.936304]\n",
      "epoch:2 step:2003 [D loss: 0.693281, acc.: 57.03%] [G loss: 0.924147]\n",
      "epoch:2 step:2004 [D loss: 0.631246, acc.: 59.38%] [G loss: 1.171240]\n",
      "epoch:2 step:2005 [D loss: 0.655004, acc.: 62.50%] [G loss: 1.098494]\n",
      "epoch:2 step:2006 [D loss: 0.695682, acc.: 58.59%] [G loss: 1.132047]\n",
      "epoch:2 step:2007 [D loss: 0.675502, acc.: 61.72%] [G loss: 0.978180]\n",
      "epoch:2 step:2008 [D loss: 0.615346, acc.: 68.75%] [G loss: 1.011407]\n",
      "epoch:2 step:2009 [D loss: 0.587693, acc.: 65.62%] [G loss: 1.185532]\n",
      "epoch:2 step:2010 [D loss: 0.654694, acc.: 57.81%] [G loss: 1.122284]\n",
      "epoch:2 step:2011 [D loss: 0.616571, acc.: 69.53%] [G loss: 1.097170]\n",
      "epoch:2 step:2012 [D loss: 0.636352, acc.: 61.72%] [G loss: 1.104574]\n",
      "epoch:2 step:2013 [D loss: 0.612299, acc.: 67.19%] [G loss: 1.174479]\n",
      "epoch:2 step:2014 [D loss: 0.607181, acc.: 68.75%] [G loss: 1.063889]\n",
      "epoch:2 step:2015 [D loss: 0.763214, acc.: 52.34%] [G loss: 1.130127]\n",
      "epoch:2 step:2016 [D loss: 0.603144, acc.: 67.19%] [G loss: 1.035470]\n",
      "epoch:2 step:2017 [D loss: 0.697816, acc.: 55.47%] [G loss: 1.220144]\n",
      "epoch:2 step:2018 [D loss: 0.685247, acc.: 56.25%] [G loss: 1.038713]\n",
      "epoch:2 step:2019 [D loss: 0.656546, acc.: 57.81%] [G loss: 1.064521]\n",
      "epoch:2 step:2020 [D loss: 0.626428, acc.: 65.62%] [G loss: 1.101225]\n",
      "epoch:2 step:2021 [D loss: 0.702085, acc.: 62.50%] [G loss: 0.941546]\n",
      "epoch:2 step:2022 [D loss: 0.703426, acc.: 54.69%] [G loss: 1.040686]\n",
      "epoch:2 step:2023 [D loss: 0.625305, acc.: 63.28%] [G loss: 0.999262]\n",
      "epoch:2 step:2024 [D loss: 0.682998, acc.: 58.59%] [G loss: 1.122390]\n",
      "epoch:2 step:2025 [D loss: 0.602015, acc.: 67.19%] [G loss: 1.150304]\n",
      "epoch:2 step:2026 [D loss: 0.604705, acc.: 69.53%] [G loss: 1.045302]\n",
      "epoch:2 step:2027 [D loss: 0.681580, acc.: 58.59%] [G loss: 1.035206]\n",
      "epoch:2 step:2028 [D loss: 0.640893, acc.: 59.38%] [G loss: 1.064978]\n",
      "epoch:2 step:2029 [D loss: 0.716220, acc.: 53.12%] [G loss: 1.034574]\n",
      "epoch:2 step:2030 [D loss: 0.642954, acc.: 57.03%] [G loss: 1.126637]\n",
      "epoch:2 step:2031 [D loss: 0.707816, acc.: 53.12%] [G loss: 1.084907]\n",
      "epoch:2 step:2032 [D loss: 0.695570, acc.: 57.81%] [G loss: 1.082108]\n",
      "epoch:2 step:2033 [D loss: 0.673283, acc.: 57.03%] [G loss: 1.157094]\n",
      "epoch:2 step:2034 [D loss: 0.601218, acc.: 66.41%] [G loss: 1.169166]\n",
      "epoch:2 step:2035 [D loss: 0.691931, acc.: 60.94%] [G loss: 1.056701]\n",
      "epoch:2 step:2036 [D loss: 0.705171, acc.: 57.03%] [G loss: 1.008613]\n",
      "epoch:2 step:2037 [D loss: 0.615679, acc.: 67.97%] [G loss: 1.147700]\n",
      "epoch:2 step:2038 [D loss: 0.645552, acc.: 60.94%] [G loss: 1.138450]\n",
      "epoch:2 step:2039 [D loss: 0.736578, acc.: 57.03%] [G loss: 1.098618]\n",
      "epoch:2 step:2040 [D loss: 0.685807, acc.: 55.47%] [G loss: 1.021840]\n",
      "epoch:2 step:2041 [D loss: 0.608848, acc.: 67.97%] [G loss: 1.212036]\n",
      "epoch:2 step:2042 [D loss: 0.633147, acc.: 60.16%] [G loss: 1.133982]\n",
      "epoch:2 step:2043 [D loss: 0.664596, acc.: 64.06%] [G loss: 1.056200]\n",
      "epoch:2 step:2044 [D loss: 0.680605, acc.: 60.94%] [G loss: 1.079454]\n",
      "epoch:2 step:2045 [D loss: 0.691715, acc.: 57.81%] [G loss: 1.175541]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:2 step:2046 [D loss: 0.571607, acc.: 70.31%] [G loss: 1.398389]\n",
      "epoch:2 step:2047 [D loss: 0.677250, acc.: 58.59%] [G loss: 1.155744]\n",
      "epoch:2 step:2048 [D loss: 0.596177, acc.: 68.75%] [G loss: 1.141137]\n",
      "epoch:2 step:2049 [D loss: 0.752646, acc.: 53.91%] [G loss: 0.949913]\n",
      "epoch:2 step:2050 [D loss: 0.599465, acc.: 70.31%] [G loss: 1.114860]\n",
      "epoch:2 step:2051 [D loss: 0.610554, acc.: 64.84%] [G loss: 1.063194]\n",
      "epoch:2 step:2052 [D loss: 0.697732, acc.: 61.72%] [G loss: 0.961070]\n",
      "epoch:2 step:2053 [D loss: 0.667531, acc.: 64.06%] [G loss: 1.041253]\n",
      "epoch:2 step:2054 [D loss: 0.676026, acc.: 61.72%] [G loss: 1.113682]\n",
      "epoch:2 step:2055 [D loss: 0.658208, acc.: 60.94%] [G loss: 1.002542]\n",
      "epoch:2 step:2056 [D loss: 0.665289, acc.: 60.16%] [G loss: 1.213215]\n",
      "epoch:2 step:2057 [D loss: 0.592258, acc.: 67.19%] [G loss: 0.967283]\n",
      "epoch:2 step:2058 [D loss: 0.635906, acc.: 61.72%] [G loss: 1.133085]\n",
      "epoch:2 step:2059 [D loss: 0.738131, acc.: 53.91%] [G loss: 0.966531]\n",
      "epoch:2 step:2060 [D loss: 0.533367, acc.: 73.44%] [G loss: 1.329105]\n",
      "epoch:2 step:2061 [D loss: 0.615923, acc.: 64.84%] [G loss: 1.433011]\n",
      "epoch:2 step:2062 [D loss: 0.595257, acc.: 64.84%] [G loss: 1.182142]\n",
      "epoch:2 step:2063 [D loss: 0.653039, acc.: 59.38%] [G loss: 1.080015]\n",
      "epoch:2 step:2064 [D loss: 0.543832, acc.: 73.44%] [G loss: 1.005979]\n",
      "epoch:2 step:2065 [D loss: 0.616636, acc.: 65.62%] [G loss: 1.096510]\n",
      "epoch:2 step:2066 [D loss: 0.681514, acc.: 60.94%] [G loss: 0.880267]\n",
      "epoch:2 step:2067 [D loss: 0.622727, acc.: 64.84%] [G loss: 1.113938]\n",
      "epoch:2 step:2068 [D loss: 0.613253, acc.: 68.75%] [G loss: 1.093846]\n",
      "epoch:2 step:2069 [D loss: 0.630980, acc.: 64.84%] [G loss: 1.104755]\n",
      "epoch:2 step:2070 [D loss: 0.567326, acc.: 70.31%] [G loss: 1.138342]\n",
      "epoch:2 step:2071 [D loss: 0.646056, acc.: 64.06%] [G loss: 0.983766]\n",
      "epoch:2 step:2072 [D loss: 0.738086, acc.: 56.25%] [G loss: 0.911569]\n",
      "epoch:2 step:2073 [D loss: 0.580092, acc.: 69.53%] [G loss: 1.112718]\n",
      "epoch:2 step:2074 [D loss: 0.633446, acc.: 64.06%] [G loss: 1.030078]\n",
      "epoch:2 step:2075 [D loss: 0.578210, acc.: 72.66%] [G loss: 0.843937]\n",
      "epoch:2 step:2076 [D loss: 0.538602, acc.: 73.44%] [G loss: 1.086473]\n",
      "epoch:2 step:2077 [D loss: 0.558762, acc.: 72.66%] [G loss: 1.249750]\n",
      "epoch:2 step:2078 [D loss: 0.714649, acc.: 52.34%] [G loss: 0.958027]\n",
      "epoch:2 step:2079 [D loss: 0.753542, acc.: 50.78%] [G loss: 1.046716]\n",
      "epoch:2 step:2080 [D loss: 0.759285, acc.: 48.44%] [G loss: 1.049338]\n",
      "epoch:2 step:2081 [D loss: 0.722076, acc.: 57.03%] [G loss: 0.915820]\n",
      "epoch:2 step:2082 [D loss: 0.494146, acc.: 82.03%] [G loss: 1.181543]\n",
      "epoch:2 step:2083 [D loss: 0.663558, acc.: 62.50%] [G loss: 1.107287]\n",
      "epoch:2 step:2084 [D loss: 0.661669, acc.: 63.28%] [G loss: 1.075835]\n",
      "epoch:2 step:2085 [D loss: 0.586955, acc.: 73.44%] [G loss: 1.079660]\n",
      "epoch:2 step:2086 [D loss: 0.573461, acc.: 72.66%] [G loss: 1.243258]\n",
      "epoch:2 step:2087 [D loss: 0.668061, acc.: 67.19%] [G loss: 1.020716]\n",
      "epoch:2 step:2088 [D loss: 0.725390, acc.: 55.47%] [G loss: 1.051518]\n",
      "epoch:2 step:2089 [D loss: 0.660268, acc.: 61.72%] [G loss: 1.048215]\n",
      "epoch:2 step:2090 [D loss: 0.637158, acc.: 60.16%] [G loss: 1.052164]\n",
      "epoch:2 step:2091 [D loss: 0.595172, acc.: 67.19%] [G loss: 1.096109]\n",
      "epoch:2 step:2092 [D loss: 0.706848, acc.: 56.25%] [G loss: 1.065935]\n",
      "epoch:2 step:2093 [D loss: 0.628415, acc.: 65.62%] [G loss: 1.232969]\n",
      "epoch:2 step:2094 [D loss: 0.678411, acc.: 57.81%] [G loss: 1.128761]\n",
      "epoch:2 step:2095 [D loss: 0.659251, acc.: 60.94%] [G loss: 1.175636]\n",
      "epoch:2 step:2096 [D loss: 0.678862, acc.: 60.94%] [G loss: 1.216478]\n",
      "epoch:2 step:2097 [D loss: 0.597997, acc.: 71.09%] [G loss: 1.295891]\n",
      "epoch:2 step:2098 [D loss: 0.590635, acc.: 68.75%] [G loss: 1.078044]\n",
      "epoch:2 step:2099 [D loss: 0.679669, acc.: 57.81%] [G loss: 0.999211]\n",
      "epoch:2 step:2100 [D loss: 0.636352, acc.: 66.41%] [G loss: 1.133649]\n",
      "epoch:2 step:2101 [D loss: 0.550809, acc.: 69.53%] [G loss: 1.190308]\n",
      "epoch:2 step:2102 [D loss: 0.684944, acc.: 59.38%] [G loss: 0.999695]\n",
      "epoch:2 step:2103 [D loss: 0.630509, acc.: 64.84%] [G loss: 0.992181]\n",
      "epoch:2 step:2104 [D loss: 0.695248, acc.: 53.91%] [G loss: 1.099870]\n",
      "epoch:2 step:2105 [D loss: 0.589279, acc.: 67.19%] [G loss: 1.102216]\n",
      "epoch:2 step:2106 [D loss: 0.690427, acc.: 54.69%] [G loss: 0.988770]\n",
      "epoch:2 step:2107 [D loss: 0.696003, acc.: 60.16%] [G loss: 0.972796]\n",
      "epoch:2 step:2108 [D loss: 0.744327, acc.: 51.56%] [G loss: 0.992856]\n",
      "epoch:2 step:2109 [D loss: 0.631766, acc.: 64.06%] [G loss: 1.295181]\n",
      "epoch:2 step:2110 [D loss: 0.692281, acc.: 53.12%] [G loss: 1.083749]\n",
      "epoch:2 step:2111 [D loss: 0.687208, acc.: 58.59%] [G loss: 1.059673]\n",
      "epoch:2 step:2112 [D loss: 0.625073, acc.: 71.09%] [G loss: 1.037719]\n",
      "epoch:2 step:2113 [D loss: 0.676752, acc.: 57.03%] [G loss: 1.083000]\n",
      "epoch:2 step:2114 [D loss: 0.674618, acc.: 61.72%] [G loss: 1.139600]\n",
      "epoch:2 step:2115 [D loss: 0.591443, acc.: 64.84%] [G loss: 1.145955]\n",
      "epoch:2 step:2116 [D loss: 0.717271, acc.: 53.91%] [G loss: 1.163989]\n",
      "epoch:2 step:2117 [D loss: 0.625585, acc.: 60.94%] [G loss: 1.185533]\n",
      "epoch:2 step:2118 [D loss: 0.639552, acc.: 60.94%] [G loss: 1.140225]\n",
      "epoch:2 step:2119 [D loss: 0.745661, acc.: 50.78%] [G loss: 0.941975]\n",
      "epoch:2 step:2120 [D loss: 0.659094, acc.: 61.72%] [G loss: 1.183207]\n",
      "epoch:2 step:2121 [D loss: 0.617325, acc.: 64.84%] [G loss: 1.120190]\n",
      "epoch:2 step:2122 [D loss: 0.632029, acc.: 64.06%] [G loss: 1.099142]\n",
      "epoch:2 step:2123 [D loss: 0.666771, acc.: 64.84%] [G loss: 1.107832]\n",
      "epoch:2 step:2124 [D loss: 0.653337, acc.: 57.81%] [G loss: 1.099625]\n",
      "epoch:2 step:2125 [D loss: 0.632771, acc.: 64.84%] [G loss: 1.021201]\n",
      "epoch:2 step:2126 [D loss: 0.701073, acc.: 58.59%] [G loss: 1.097436]\n",
      "epoch:2 step:2127 [D loss: 0.620997, acc.: 64.84%] [G loss: 1.088252]\n",
      "epoch:2 step:2128 [D loss: 0.603771, acc.: 68.75%] [G loss: 1.036361]\n",
      "epoch:2 step:2129 [D loss: 0.658650, acc.: 63.28%] [G loss: 1.215107]\n",
      "epoch:2 step:2130 [D loss: 0.619856, acc.: 68.75%] [G loss: 1.178640]\n",
      "epoch:2 step:2131 [D loss: 0.590976, acc.: 66.41%] [G loss: 1.182954]\n",
      "epoch:2 step:2132 [D loss: 0.653629, acc.: 64.06%] [G loss: 1.128010]\n",
      "epoch:2 step:2133 [D loss: 0.615407, acc.: 65.62%] [G loss: 1.160344]\n",
      "epoch:2 step:2134 [D loss: 0.596411, acc.: 66.41%] [G loss: 1.140413]\n",
      "epoch:2 step:2135 [D loss: 0.597431, acc.: 64.06%] [G loss: 1.069765]\n",
      "epoch:2 step:2136 [D loss: 0.703371, acc.: 61.72%] [G loss: 1.070596]\n",
      "epoch:2 step:2137 [D loss: 0.727216, acc.: 50.00%] [G loss: 1.048608]\n",
      "epoch:2 step:2138 [D loss: 0.618615, acc.: 64.84%] [G loss: 0.944790]\n",
      "epoch:2 step:2139 [D loss: 0.638404, acc.: 61.72%] [G loss: 1.106221]\n",
      "epoch:2 step:2140 [D loss: 0.618690, acc.: 65.62%] [G loss: 1.209010]\n",
      "epoch:2 step:2141 [D loss: 0.668782, acc.: 57.03%] [G loss: 1.025424]\n",
      "epoch:2 step:2142 [D loss: 0.602357, acc.: 65.62%] [G loss: 1.021141]\n",
      "epoch:2 step:2143 [D loss: 0.652656, acc.: 63.28%] [G loss: 1.073147]\n",
      "epoch:2 step:2144 [D loss: 0.636526, acc.: 64.06%] [G loss: 1.178348]\n",
      "epoch:2 step:2145 [D loss: 0.620073, acc.: 66.41%] [G loss: 0.997013]\n",
      "epoch:2 step:2146 [D loss: 0.647965, acc.: 62.50%] [G loss: 0.972873]\n",
      "epoch:2 step:2147 [D loss: 0.616890, acc.: 67.19%] [G loss: 1.023663]\n",
      "epoch:2 step:2148 [D loss: 0.654142, acc.: 60.94%] [G loss: 1.163007]\n",
      "epoch:2 step:2149 [D loss: 0.721969, acc.: 56.25%] [G loss: 0.949866]\n",
      "epoch:2 step:2150 [D loss: 0.754823, acc.: 49.22%] [G loss: 1.042631]\n",
      "epoch:2 step:2151 [D loss: 0.647022, acc.: 62.50%] [G loss: 0.923837]\n",
      "epoch:2 step:2152 [D loss: 0.621490, acc.: 64.06%] [G loss: 1.026172]\n",
      "epoch:2 step:2153 [D loss: 0.701003, acc.: 57.81%] [G loss: 1.057212]\n",
      "epoch:2 step:2154 [D loss: 0.641221, acc.: 64.06%] [G loss: 1.096063]\n",
      "epoch:2 step:2155 [D loss: 0.584000, acc.: 73.44%] [G loss: 0.942894]\n",
      "epoch:2 step:2156 [D loss: 0.698481, acc.: 60.94%] [G loss: 0.861320]\n",
      "epoch:2 step:2157 [D loss: 0.629696, acc.: 64.84%] [G loss: 1.003816]\n",
      "epoch:2 step:2158 [D loss: 0.643879, acc.: 66.41%] [G loss: 1.060087]\n",
      "epoch:2 step:2159 [D loss: 0.785730, acc.: 46.09%] [G loss: 1.108032]\n",
      "epoch:2 step:2160 [D loss: 0.649526, acc.: 61.72%] [G loss: 1.088769]\n",
      "epoch:2 step:2161 [D loss: 0.632814, acc.: 61.72%] [G loss: 0.956225]\n",
      "epoch:2 step:2162 [D loss: 0.580524, acc.: 64.84%] [G loss: 1.248400]\n",
      "epoch:2 step:2163 [D loss: 0.733731, acc.: 53.91%] [G loss: 1.111618]\n",
      "epoch:2 step:2164 [D loss: 0.655134, acc.: 61.72%] [G loss: 0.990624]\n",
      "epoch:2 step:2165 [D loss: 0.694625, acc.: 60.94%] [G loss: 1.109985]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:2 step:2166 [D loss: 0.589815, acc.: 69.53%] [G loss: 1.142394]\n",
      "epoch:2 step:2167 [D loss: 0.702219, acc.: 50.78%] [G loss: 0.989723]\n",
      "epoch:2 step:2168 [D loss: 0.674301, acc.: 61.72%] [G loss: 1.127361]\n",
      "epoch:2 step:2169 [D loss: 0.730594, acc.: 59.38%] [G loss: 1.118541]\n",
      "epoch:2 step:2170 [D loss: 0.590073, acc.: 70.31%] [G loss: 1.251623]\n",
      "epoch:2 step:2171 [D loss: 0.661513, acc.: 60.16%] [G loss: 0.991125]\n",
      "epoch:2 step:2172 [D loss: 0.611808, acc.: 65.62%] [G loss: 1.119653]\n",
      "epoch:2 step:2173 [D loss: 0.653510, acc.: 66.41%] [G loss: 1.153435]\n",
      "epoch:2 step:2174 [D loss: 0.725559, acc.: 48.44%] [G loss: 1.101351]\n",
      "epoch:2 step:2175 [D loss: 0.728468, acc.: 55.47%] [G loss: 0.922299]\n",
      "epoch:2 step:2176 [D loss: 0.682101, acc.: 60.94%] [G loss: 1.192568]\n",
      "epoch:2 step:2177 [D loss: 0.642769, acc.: 64.06%] [G loss: 1.025304]\n",
      "epoch:2 step:2178 [D loss: 0.637501, acc.: 61.72%] [G loss: 1.068161]\n",
      "epoch:2 step:2179 [D loss: 0.646973, acc.: 60.94%] [G loss: 1.055848]\n",
      "epoch:2 step:2180 [D loss: 0.623635, acc.: 63.28%] [G loss: 0.938565]\n",
      "epoch:2 step:2181 [D loss: 0.721110, acc.: 53.91%] [G loss: 1.006732]\n",
      "epoch:2 step:2182 [D loss: 0.666247, acc.: 60.94%] [G loss: 0.933431]\n",
      "epoch:2 step:2183 [D loss: 0.588529, acc.: 71.09%] [G loss: 1.147777]\n",
      "epoch:2 step:2184 [D loss: 0.710723, acc.: 61.72%] [G loss: 1.332223]\n",
      "epoch:2 step:2185 [D loss: 0.631923, acc.: 61.72%] [G loss: 1.051161]\n",
      "epoch:2 step:2186 [D loss: 0.644394, acc.: 61.72%] [G loss: 1.002553]\n",
      "epoch:2 step:2187 [D loss: 0.612048, acc.: 68.75%] [G loss: 1.065265]\n",
      "epoch:2 step:2188 [D loss: 0.537284, acc.: 77.34%] [G loss: 1.137622]\n",
      "epoch:2 step:2189 [D loss: 0.558296, acc.: 68.75%] [G loss: 1.160135]\n",
      "epoch:2 step:2190 [D loss: 0.801240, acc.: 47.66%] [G loss: 1.020665]\n",
      "epoch:2 step:2191 [D loss: 0.741559, acc.: 50.00%] [G loss: 1.103431]\n",
      "epoch:2 step:2192 [D loss: 0.661689, acc.: 61.72%] [G loss: 1.132109]\n",
      "epoch:2 step:2193 [D loss: 0.653386, acc.: 61.72%] [G loss: 1.144156]\n",
      "epoch:2 step:2194 [D loss: 0.590940, acc.: 70.31%] [G loss: 1.121107]\n",
      "epoch:2 step:2195 [D loss: 0.665168, acc.: 62.50%] [G loss: 1.025202]\n",
      "epoch:2 step:2196 [D loss: 0.744810, acc.: 59.38%] [G loss: 1.033235]\n",
      "epoch:2 step:2197 [D loss: 0.707616, acc.: 52.34%] [G loss: 1.204326]\n",
      "epoch:2 step:2198 [D loss: 0.702556, acc.: 55.47%] [G loss: 0.993482]\n",
      "epoch:2 step:2199 [D loss: 0.631961, acc.: 64.06%] [G loss: 1.179338]\n",
      "epoch:2 step:2200 [D loss: 0.669039, acc.: 57.03%] [G loss: 1.110924]\n",
      "epoch:2 step:2201 [D loss: 0.556819, acc.: 71.88%] [G loss: 1.294875]\n",
      "epoch:2 step:2202 [D loss: 0.616881, acc.: 66.41%] [G loss: 1.082914]\n",
      "epoch:2 step:2203 [D loss: 0.712982, acc.: 59.38%] [G loss: 0.986808]\n",
      "epoch:2 step:2204 [D loss: 0.630809, acc.: 67.19%] [G loss: 1.056055]\n",
      "epoch:2 step:2205 [D loss: 0.738037, acc.: 57.03%] [G loss: 1.044607]\n",
      "epoch:2 step:2206 [D loss: 0.608569, acc.: 69.53%] [G loss: 1.091628]\n",
      "epoch:2 step:2207 [D loss: 0.673490, acc.: 58.59%] [G loss: 1.186062]\n",
      "epoch:2 step:2208 [D loss: 0.593580, acc.: 68.75%] [G loss: 1.107874]\n",
      "epoch:2 step:2209 [D loss: 0.664561, acc.: 63.28%] [G loss: 1.014367]\n",
      "epoch:2 step:2210 [D loss: 0.604579, acc.: 65.62%] [G loss: 1.114388]\n",
      "epoch:2 step:2211 [D loss: 0.544832, acc.: 72.66%] [G loss: 1.058861]\n",
      "epoch:2 step:2212 [D loss: 0.611876, acc.: 65.62%] [G loss: 1.207621]\n",
      "epoch:2 step:2213 [D loss: 0.733098, acc.: 48.44%] [G loss: 1.094155]\n",
      "epoch:2 step:2214 [D loss: 0.628052, acc.: 60.94%] [G loss: 1.065980]\n",
      "epoch:2 step:2215 [D loss: 0.686923, acc.: 61.72%] [G loss: 1.132390]\n",
      "epoch:2 step:2216 [D loss: 0.581196, acc.: 72.66%] [G loss: 1.098069]\n",
      "epoch:2 step:2217 [D loss: 0.584787, acc.: 68.75%] [G loss: 1.068447]\n",
      "epoch:2 step:2218 [D loss: 0.616442, acc.: 67.19%] [G loss: 1.025998]\n",
      "epoch:2 step:2219 [D loss: 0.619523, acc.: 67.97%] [G loss: 1.030458]\n",
      "epoch:2 step:2220 [D loss: 0.626521, acc.: 60.16%] [G loss: 0.944078]\n",
      "epoch:2 step:2221 [D loss: 0.653222, acc.: 63.28%] [G loss: 0.943110]\n",
      "epoch:2 step:2222 [D loss: 0.619432, acc.: 65.62%] [G loss: 1.049049]\n",
      "epoch:2 step:2223 [D loss: 0.542991, acc.: 71.09%] [G loss: 1.038795]\n",
      "epoch:2 step:2224 [D loss: 0.679981, acc.: 57.03%] [G loss: 1.036766]\n",
      "epoch:2 step:2225 [D loss: 0.693099, acc.: 57.03%] [G loss: 1.071254]\n",
      "epoch:2 step:2226 [D loss: 0.705692, acc.: 53.12%] [G loss: 1.039573]\n",
      "epoch:2 step:2227 [D loss: 0.627145, acc.: 65.62%] [G loss: 0.995272]\n",
      "epoch:2 step:2228 [D loss: 0.693216, acc.: 62.50%] [G loss: 1.010018]\n",
      "epoch:2 step:2229 [D loss: 0.631669, acc.: 67.19%] [G loss: 1.259800]\n",
      "epoch:2 step:2230 [D loss: 0.612126, acc.: 64.84%] [G loss: 1.092683]\n",
      "epoch:2 step:2231 [D loss: 0.655752, acc.: 65.62%] [G loss: 1.300595]\n",
      "epoch:2 step:2232 [D loss: 0.725047, acc.: 57.81%] [G loss: 0.862770]\n",
      "epoch:2 step:2233 [D loss: 0.683121, acc.: 60.94%] [G loss: 1.083023]\n",
      "epoch:2 step:2234 [D loss: 0.590035, acc.: 66.41%] [G loss: 1.188461]\n",
      "epoch:2 step:2235 [D loss: 0.653890, acc.: 64.06%] [G loss: 1.009503]\n",
      "epoch:2 step:2236 [D loss: 0.656730, acc.: 65.62%] [G loss: 1.041216]\n",
      "epoch:2 step:2237 [D loss: 0.625422, acc.: 64.06%] [G loss: 1.159629]\n",
      "epoch:2 step:2238 [D loss: 0.566567, acc.: 73.44%] [G loss: 1.082474]\n",
      "epoch:2 step:2239 [D loss: 0.641232, acc.: 62.50%] [G loss: 1.013370]\n",
      "epoch:2 step:2240 [D loss: 0.581993, acc.: 65.62%] [G loss: 1.093956]\n",
      "epoch:2 step:2241 [D loss: 0.675111, acc.: 59.38%] [G loss: 1.125564]\n",
      "epoch:2 step:2242 [D loss: 0.591480, acc.: 68.75%] [G loss: 1.086653]\n",
      "epoch:2 step:2243 [D loss: 0.653562, acc.: 61.72%] [G loss: 1.054442]\n",
      "epoch:2 step:2244 [D loss: 0.604796, acc.: 71.88%] [G loss: 1.038439]\n",
      "epoch:2 step:2245 [D loss: 0.613314, acc.: 61.72%] [G loss: 1.012603]\n",
      "epoch:2 step:2246 [D loss: 0.549369, acc.: 70.31%] [G loss: 1.373783]\n",
      "epoch:2 step:2247 [D loss: 0.613904, acc.: 67.19%] [G loss: 1.249383]\n",
      "epoch:2 step:2248 [D loss: 0.595059, acc.: 67.97%] [G loss: 1.122694]\n",
      "epoch:2 step:2249 [D loss: 0.773585, acc.: 50.00%] [G loss: 0.875095]\n",
      "epoch:2 step:2250 [D loss: 0.650684, acc.: 60.94%] [G loss: 1.078640]\n",
      "epoch:2 step:2251 [D loss: 0.647174, acc.: 57.03%] [G loss: 1.187786]\n",
      "epoch:2 step:2252 [D loss: 0.710882, acc.: 57.03%] [G loss: 1.062052]\n",
      "epoch:2 step:2253 [D loss: 0.630773, acc.: 61.72%] [G loss: 1.135447]\n",
      "epoch:2 step:2254 [D loss: 0.628965, acc.: 60.94%] [G loss: 1.114257]\n",
      "epoch:2 step:2255 [D loss: 0.725921, acc.: 55.47%] [G loss: 0.977771]\n",
      "epoch:2 step:2256 [D loss: 0.653714, acc.: 60.16%] [G loss: 1.000897]\n",
      "epoch:2 step:2257 [D loss: 0.596719, acc.: 70.31%] [G loss: 1.067887]\n",
      "epoch:2 step:2258 [D loss: 0.687089, acc.: 60.16%] [G loss: 1.128951]\n",
      "epoch:2 step:2259 [D loss: 0.628981, acc.: 67.19%] [G loss: 1.049777]\n",
      "epoch:2 step:2260 [D loss: 0.702311, acc.: 56.25%] [G loss: 0.950532]\n",
      "epoch:2 step:2261 [D loss: 0.670561, acc.: 57.03%] [G loss: 1.135788]\n",
      "epoch:2 step:2262 [D loss: 0.664762, acc.: 61.72%] [G loss: 1.120932]\n",
      "epoch:2 step:2263 [D loss: 0.690976, acc.: 57.03%] [G loss: 1.077129]\n",
      "epoch:2 step:2264 [D loss: 0.619833, acc.: 68.75%] [G loss: 1.296170]\n",
      "epoch:2 step:2265 [D loss: 0.650141, acc.: 58.59%] [G loss: 1.101631]\n",
      "epoch:2 step:2266 [D loss: 0.599162, acc.: 71.88%] [G loss: 1.091218]\n",
      "epoch:2 step:2267 [D loss: 0.689055, acc.: 61.72%] [G loss: 1.122631]\n",
      "epoch:2 step:2268 [D loss: 0.645692, acc.: 63.28%] [G loss: 1.125520]\n",
      "epoch:2 step:2269 [D loss: 0.623644, acc.: 66.41%] [G loss: 0.969155]\n",
      "epoch:2 step:2270 [D loss: 0.599984, acc.: 71.09%] [G loss: 0.974515]\n",
      "epoch:2 step:2271 [D loss: 0.745138, acc.: 55.47%] [G loss: 1.034958]\n",
      "epoch:2 step:2272 [D loss: 0.677072, acc.: 58.59%] [G loss: 1.003086]\n",
      "epoch:2 step:2273 [D loss: 0.627098, acc.: 64.84%] [G loss: 1.126149]\n",
      "epoch:2 step:2274 [D loss: 0.677904, acc.: 63.28%] [G loss: 1.071850]\n",
      "epoch:2 step:2275 [D loss: 0.672550, acc.: 60.94%] [G loss: 1.211157]\n",
      "epoch:2 step:2276 [D loss: 0.593498, acc.: 64.84%] [G loss: 1.236935]\n",
      "epoch:2 step:2277 [D loss: 0.690822, acc.: 58.59%] [G loss: 1.169618]\n",
      "epoch:2 step:2278 [D loss: 0.652378, acc.: 62.50%] [G loss: 1.091025]\n",
      "epoch:2 step:2279 [D loss: 0.720455, acc.: 52.34%] [G loss: 0.949902]\n",
      "epoch:2 step:2280 [D loss: 0.634994, acc.: 66.41%] [G loss: 1.100869]\n",
      "epoch:2 step:2281 [D loss: 0.648802, acc.: 65.62%] [G loss: 0.990237]\n",
      "epoch:2 step:2282 [D loss: 0.602483, acc.: 61.72%] [G loss: 1.110880]\n",
      "epoch:2 step:2283 [D loss: 0.649471, acc.: 64.06%] [G loss: 1.042341]\n",
      "epoch:2 step:2284 [D loss: 0.740440, acc.: 53.91%] [G loss: 1.085243]\n",
      "epoch:2 step:2285 [D loss: 0.655240, acc.: 58.59%] [G loss: 1.053909]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:2 step:2286 [D loss: 0.592737, acc.: 69.53%] [G loss: 1.123357]\n",
      "epoch:2 step:2287 [D loss: 0.652387, acc.: 62.50%] [G loss: 0.993793]\n",
      "epoch:2 step:2288 [D loss: 0.669205, acc.: 60.94%] [G loss: 0.976101]\n",
      "epoch:2 step:2289 [D loss: 0.708564, acc.: 55.47%] [G loss: 1.056328]\n",
      "epoch:2 step:2290 [D loss: 0.602424, acc.: 68.75%] [G loss: 1.295213]\n",
      "epoch:2 step:2291 [D loss: 0.655800, acc.: 65.62%] [G loss: 1.162262]\n",
      "epoch:2 step:2292 [D loss: 0.628044, acc.: 62.50%] [G loss: 0.994842]\n",
      "epoch:2 step:2293 [D loss: 0.653551, acc.: 62.50%] [G loss: 0.927505]\n",
      "epoch:2 step:2294 [D loss: 0.602215, acc.: 65.62%] [G loss: 1.042259]\n",
      "epoch:2 step:2295 [D loss: 0.736534, acc.: 53.12%] [G loss: 0.955075]\n",
      "epoch:2 step:2296 [D loss: 0.686751, acc.: 57.03%] [G loss: 1.072020]\n",
      "epoch:2 step:2297 [D loss: 0.628603, acc.: 63.28%] [G loss: 1.095067]\n",
      "epoch:2 step:2298 [D loss: 0.678080, acc.: 55.47%] [G loss: 1.234857]\n",
      "epoch:2 step:2299 [D loss: 0.669156, acc.: 62.50%] [G loss: 1.023281]\n",
      "epoch:2 step:2300 [D loss: 0.614670, acc.: 67.19%] [G loss: 1.096180]\n",
      "epoch:2 step:2301 [D loss: 0.645815, acc.: 63.28%] [G loss: 1.090622]\n",
      "epoch:2 step:2302 [D loss: 0.682391, acc.: 57.03%] [G loss: 1.075653]\n",
      "epoch:2 step:2303 [D loss: 0.609141, acc.: 65.62%] [G loss: 1.146413]\n",
      "epoch:2 step:2304 [D loss: 0.627246, acc.: 65.62%] [G loss: 1.094352]\n",
      "epoch:2 step:2305 [D loss: 0.658282, acc.: 60.94%] [G loss: 1.074558]\n",
      "epoch:2 step:2306 [D loss: 0.625087, acc.: 64.06%] [G loss: 1.023348]\n",
      "epoch:2 step:2307 [D loss: 0.670712, acc.: 62.50%] [G loss: 1.094409]\n",
      "epoch:2 step:2308 [D loss: 0.722158, acc.: 53.91%] [G loss: 0.930110]\n",
      "epoch:2 step:2309 [D loss: 0.616307, acc.: 67.19%] [G loss: 1.061287]\n",
      "epoch:2 step:2310 [D loss: 0.648953, acc.: 60.16%] [G loss: 1.063751]\n",
      "epoch:2 step:2311 [D loss: 0.671214, acc.: 54.69%] [G loss: 1.200413]\n",
      "epoch:2 step:2312 [D loss: 0.677470, acc.: 59.38%] [G loss: 1.040657]\n",
      "epoch:2 step:2313 [D loss: 0.632956, acc.: 62.50%] [G loss: 1.198437]\n",
      "epoch:2 step:2314 [D loss: 0.602071, acc.: 65.62%] [G loss: 1.009121]\n",
      "epoch:2 step:2315 [D loss: 0.563029, acc.: 71.09%] [G loss: 1.065494]\n",
      "epoch:2 step:2316 [D loss: 0.626176, acc.: 69.53%] [G loss: 1.205707]\n",
      "epoch:2 step:2317 [D loss: 0.649044, acc.: 63.28%] [G loss: 1.099045]\n",
      "epoch:2 step:2318 [D loss: 0.618901, acc.: 61.72%] [G loss: 1.232993]\n",
      "epoch:2 step:2319 [D loss: 0.616457, acc.: 66.41%] [G loss: 1.039402]\n",
      "epoch:2 step:2320 [D loss: 0.704544, acc.: 53.91%] [G loss: 1.124506]\n",
      "epoch:2 step:2321 [D loss: 0.674613, acc.: 63.28%] [G loss: 1.093576]\n",
      "epoch:2 step:2322 [D loss: 0.671120, acc.: 60.94%] [G loss: 1.150811]\n",
      "epoch:2 step:2323 [D loss: 0.637698, acc.: 59.38%] [G loss: 1.023597]\n",
      "epoch:2 step:2324 [D loss: 0.637069, acc.: 66.41%] [G loss: 1.077069]\n",
      "epoch:2 step:2325 [D loss: 0.624350, acc.: 64.06%] [G loss: 1.111919]\n",
      "epoch:2 step:2326 [D loss: 0.682134, acc.: 59.38%] [G loss: 1.199193]\n",
      "epoch:2 step:2327 [D loss: 0.630116, acc.: 65.62%] [G loss: 1.331682]\n",
      "epoch:2 step:2328 [D loss: 0.637368, acc.: 63.28%] [G loss: 1.172613]\n",
      "epoch:2 step:2329 [D loss: 0.601760, acc.: 67.97%] [G loss: 1.083699]\n",
      "epoch:2 step:2330 [D loss: 0.647594, acc.: 65.62%] [G loss: 1.065690]\n",
      "epoch:2 step:2331 [D loss: 0.604133, acc.: 64.84%] [G loss: 1.109178]\n",
      "epoch:2 step:2332 [D loss: 0.619597, acc.: 66.41%] [G loss: 1.066715]\n",
      "epoch:2 step:2333 [D loss: 0.638976, acc.: 64.84%] [G loss: 1.040867]\n",
      "epoch:2 step:2334 [D loss: 0.625636, acc.: 62.50%] [G loss: 1.096644]\n",
      "epoch:2 step:2335 [D loss: 0.657144, acc.: 61.72%] [G loss: 1.024041]\n",
      "epoch:2 step:2336 [D loss: 0.637952, acc.: 68.75%] [G loss: 1.043234]\n",
      "epoch:2 step:2337 [D loss: 0.701449, acc.: 55.47%] [G loss: 0.939039]\n",
      "epoch:2 step:2338 [D loss: 0.616016, acc.: 64.84%] [G loss: 1.038885]\n",
      "epoch:2 step:2339 [D loss: 0.675895, acc.: 60.16%] [G loss: 1.163124]\n",
      "epoch:2 step:2340 [D loss: 0.680939, acc.: 61.72%] [G loss: 1.053717]\n",
      "epoch:2 step:2341 [D loss: 0.617543, acc.: 66.41%] [G loss: 1.179484]\n",
      "epoch:2 step:2342 [D loss: 0.645222, acc.: 63.28%] [G loss: 1.058148]\n",
      "epoch:2 step:2343 [D loss: 0.690572, acc.: 60.94%] [G loss: 1.173835]\n",
      "epoch:2 step:2344 [D loss: 0.684124, acc.: 61.72%] [G loss: 1.061565]\n",
      "epoch:2 step:2345 [D loss: 0.584596, acc.: 72.66%] [G loss: 1.047858]\n",
      "epoch:2 step:2346 [D loss: 0.570505, acc.: 70.31%] [G loss: 1.126208]\n",
      "epoch:2 step:2347 [D loss: 0.705948, acc.: 51.56%] [G loss: 0.847847]\n",
      "epoch:2 step:2348 [D loss: 0.637221, acc.: 67.97%] [G loss: 1.057560]\n",
      "epoch:2 step:2349 [D loss: 0.649540, acc.: 62.50%] [G loss: 0.994869]\n",
      "epoch:2 step:2350 [D loss: 0.608122, acc.: 65.62%] [G loss: 0.926389]\n",
      "epoch:2 step:2351 [D loss: 0.664163, acc.: 68.75%] [G loss: 1.018603]\n",
      "epoch:2 step:2352 [D loss: 0.605944, acc.: 64.84%] [G loss: 1.097401]\n",
      "epoch:2 step:2353 [D loss: 0.669369, acc.: 57.81%] [G loss: 1.042492]\n",
      "epoch:2 step:2354 [D loss: 0.607873, acc.: 63.28%] [G loss: 1.152172]\n",
      "epoch:2 step:2355 [D loss: 0.708255, acc.: 57.03%] [G loss: 1.108895]\n",
      "epoch:2 step:2356 [D loss: 0.645577, acc.: 59.38%] [G loss: 0.872810]\n",
      "epoch:2 step:2357 [D loss: 0.720612, acc.: 54.69%] [G loss: 1.016317]\n",
      "epoch:2 step:2358 [D loss: 0.638462, acc.: 68.75%] [G loss: 1.056536]\n",
      "epoch:2 step:2359 [D loss: 0.663821, acc.: 60.94%] [G loss: 1.081323]\n",
      "epoch:2 step:2360 [D loss: 0.577914, acc.: 67.19%] [G loss: 1.070451]\n",
      "epoch:2 step:2361 [D loss: 0.685557, acc.: 57.03%] [G loss: 1.098311]\n",
      "epoch:2 step:2362 [D loss: 0.595631, acc.: 68.75%] [G loss: 1.106426]\n",
      "epoch:2 step:2363 [D loss: 0.696831, acc.: 59.38%] [G loss: 1.258854]\n",
      "epoch:2 step:2364 [D loss: 0.622483, acc.: 64.06%] [G loss: 1.288291]\n",
      "epoch:2 step:2365 [D loss: 0.628080, acc.: 64.06%] [G loss: 1.144526]\n",
      "epoch:2 step:2366 [D loss: 0.692154, acc.: 63.28%] [G loss: 0.970585]\n",
      "epoch:2 step:2367 [D loss: 0.712203, acc.: 57.81%] [G loss: 0.980383]\n",
      "epoch:2 step:2368 [D loss: 0.670094, acc.: 60.94%] [G loss: 1.115199]\n",
      "epoch:2 step:2369 [D loss: 0.703819, acc.: 53.91%] [G loss: 0.923709]\n",
      "epoch:2 step:2370 [D loss: 0.616745, acc.: 65.62%] [G loss: 1.231916]\n",
      "epoch:2 step:2371 [D loss: 0.724325, acc.: 54.69%] [G loss: 1.109391]\n",
      "epoch:2 step:2372 [D loss: 0.561473, acc.: 71.88%] [G loss: 1.252508]\n",
      "epoch:2 step:2373 [D loss: 0.621843, acc.: 64.06%] [G loss: 1.166763]\n",
      "epoch:2 step:2374 [D loss: 0.679978, acc.: 57.81%] [G loss: 0.992602]\n",
      "epoch:2 step:2375 [D loss: 0.684589, acc.: 57.81%] [G loss: 1.047643]\n",
      "epoch:2 step:2376 [D loss: 0.638234, acc.: 61.72%] [G loss: 1.000326]\n",
      "epoch:2 step:2377 [D loss: 0.688964, acc.: 60.16%] [G loss: 0.994828]\n",
      "epoch:2 step:2378 [D loss: 0.559323, acc.: 75.00%] [G loss: 1.090168]\n",
      "epoch:2 step:2379 [D loss: 0.624232, acc.: 65.62%] [G loss: 1.113101]\n",
      "epoch:2 step:2380 [D loss: 0.642070, acc.: 60.94%] [G loss: 1.127292]\n",
      "epoch:2 step:2381 [D loss: 0.653600, acc.: 60.94%] [G loss: 1.152805]\n",
      "epoch:2 step:2382 [D loss: 0.569138, acc.: 74.22%] [G loss: 1.168934]\n",
      "epoch:2 step:2383 [D loss: 0.636900, acc.: 64.84%] [G loss: 1.229941]\n",
      "epoch:2 step:2384 [D loss: 0.654569, acc.: 61.72%] [G loss: 1.161678]\n",
      "epoch:2 step:2385 [D loss: 0.704262, acc.: 53.12%] [G loss: 1.000020]\n",
      "epoch:2 step:2386 [D loss: 0.650108, acc.: 61.72%] [G loss: 1.044018]\n",
      "epoch:2 step:2387 [D loss: 0.679413, acc.: 57.03%] [G loss: 1.074081]\n",
      "epoch:2 step:2388 [D loss: 0.705223, acc.: 54.69%] [G loss: 1.069113]\n",
      "epoch:2 step:2389 [D loss: 0.649502, acc.: 60.94%] [G loss: 1.136235]\n",
      "epoch:2 step:2390 [D loss: 0.643520, acc.: 62.50%] [G loss: 1.160318]\n",
      "epoch:2 step:2391 [D loss: 0.676371, acc.: 55.47%] [G loss: 1.076097]\n",
      "epoch:2 step:2392 [D loss: 0.665008, acc.: 62.50%] [G loss: 1.083590]\n",
      "epoch:2 step:2393 [D loss: 0.664202, acc.: 62.50%] [G loss: 1.045060]\n",
      "epoch:2 step:2394 [D loss: 0.724834, acc.: 53.12%] [G loss: 1.123449]\n",
      "epoch:2 step:2395 [D loss: 0.641059, acc.: 68.75%] [G loss: 1.056782]\n",
      "epoch:2 step:2396 [D loss: 0.557266, acc.: 72.66%] [G loss: 1.208564]\n",
      "epoch:2 step:2397 [D loss: 0.555386, acc.: 72.66%] [G loss: 1.186981]\n",
      "epoch:2 step:2398 [D loss: 0.720360, acc.: 53.12%] [G loss: 1.059752]\n",
      "epoch:2 step:2399 [D loss: 0.601843, acc.: 67.19%] [G loss: 0.894925]\n",
      "epoch:2 step:2400 [D loss: 0.618134, acc.: 64.84%] [G loss: 1.140102]\n",
      "epoch:2 step:2401 [D loss: 0.712056, acc.: 54.69%] [G loss: 1.041983]\n",
      "epoch:2 step:2402 [D loss: 0.614342, acc.: 64.06%] [G loss: 1.135532]\n",
      "epoch:2 step:2403 [D loss: 0.625286, acc.: 64.06%] [G loss: 1.140313]\n",
      "epoch:2 step:2404 [D loss: 0.575448, acc.: 71.09%] [G loss: 1.139563]\n",
      "epoch:2 step:2405 [D loss: 0.726437, acc.: 55.47%] [G loss: 0.872121]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:2 step:2406 [D loss: 0.610459, acc.: 66.41%] [G loss: 1.042910]\n",
      "epoch:2 step:2407 [D loss: 0.628025, acc.: 64.84%] [G loss: 1.063877]\n",
      "epoch:2 step:2408 [D loss: 0.676849, acc.: 59.38%] [G loss: 1.047347]\n",
      "epoch:2 step:2409 [D loss: 0.579960, acc.: 65.62%] [G loss: 1.135934]\n",
      "epoch:2 step:2410 [D loss: 0.659864, acc.: 60.94%] [G loss: 1.133534]\n",
      "epoch:2 step:2411 [D loss: 0.658894, acc.: 62.50%] [G loss: 1.161885]\n",
      "epoch:2 step:2412 [D loss: 0.699981, acc.: 56.25%] [G loss: 0.988310]\n",
      "epoch:2 step:2413 [D loss: 0.671075, acc.: 63.28%] [G loss: 1.023533]\n",
      "epoch:2 step:2414 [D loss: 0.559361, acc.: 73.44%] [G loss: 1.270305]\n",
      "epoch:2 step:2415 [D loss: 0.701114, acc.: 60.94%] [G loss: 1.048422]\n",
      "epoch:2 step:2416 [D loss: 0.633145, acc.: 62.50%] [G loss: 1.144119]\n",
      "epoch:2 step:2417 [D loss: 0.682211, acc.: 57.03%] [G loss: 1.169555]\n",
      "epoch:2 step:2418 [D loss: 0.643920, acc.: 64.84%] [G loss: 1.025699]\n",
      "epoch:2 step:2419 [D loss: 0.607803, acc.: 62.50%] [G loss: 1.039232]\n",
      "epoch:2 step:2420 [D loss: 0.656361, acc.: 65.62%] [G loss: 0.982714]\n",
      "epoch:2 step:2421 [D loss: 0.677369, acc.: 58.59%] [G loss: 1.050572]\n",
      "epoch:2 step:2422 [D loss: 0.539219, acc.: 71.88%] [G loss: 1.088033]\n",
      "epoch:2 step:2423 [D loss: 0.618191, acc.: 67.97%] [G loss: 1.111276]\n",
      "epoch:2 step:2424 [D loss: 0.597026, acc.: 64.06%] [G loss: 1.290653]\n",
      "epoch:2 step:2425 [D loss: 0.671126, acc.: 60.16%] [G loss: 1.082155]\n",
      "epoch:2 step:2426 [D loss: 0.605509, acc.: 69.53%] [G loss: 1.040189]\n",
      "epoch:2 step:2427 [D loss: 0.711197, acc.: 51.56%] [G loss: 1.000284]\n",
      "epoch:2 step:2428 [D loss: 0.606181, acc.: 61.72%] [G loss: 1.066204]\n",
      "epoch:2 step:2429 [D loss: 0.665554, acc.: 60.16%] [G loss: 1.097833]\n",
      "epoch:2 step:2430 [D loss: 0.713216, acc.: 54.69%] [G loss: 0.980980]\n",
      "epoch:2 step:2431 [D loss: 0.595475, acc.: 67.19%] [G loss: 0.950164]\n",
      "epoch:2 step:2432 [D loss: 0.618617, acc.: 65.62%] [G loss: 1.254267]\n",
      "epoch:2 step:2433 [D loss: 0.602421, acc.: 65.62%] [G loss: 1.023258]\n",
      "epoch:2 step:2434 [D loss: 0.614569, acc.: 64.06%] [G loss: 1.173404]\n",
      "epoch:2 step:2435 [D loss: 0.655926, acc.: 60.94%] [G loss: 1.142828]\n",
      "epoch:2 step:2436 [D loss: 0.742265, acc.: 50.00%] [G loss: 0.990298]\n",
      "epoch:2 step:2437 [D loss: 0.653401, acc.: 62.50%] [G loss: 1.195953]\n",
      "epoch:2 step:2438 [D loss: 0.589078, acc.: 67.19%] [G loss: 1.099649]\n",
      "epoch:2 step:2439 [D loss: 0.589025, acc.: 69.53%] [G loss: 1.242073]\n",
      "epoch:2 step:2440 [D loss: 0.694808, acc.: 58.59%] [G loss: 1.145513]\n",
      "epoch:2 step:2441 [D loss: 0.621262, acc.: 68.75%] [G loss: 0.958589]\n",
      "epoch:2 step:2442 [D loss: 0.721460, acc.: 60.16%] [G loss: 1.113284]\n",
      "epoch:2 step:2443 [D loss: 0.661440, acc.: 59.38%] [G loss: 1.124556]\n",
      "epoch:2 step:2444 [D loss: 0.641691, acc.: 70.31%] [G loss: 1.166328]\n",
      "epoch:2 step:2445 [D loss: 0.624391, acc.: 64.06%] [G loss: 1.131480]\n",
      "epoch:2 step:2446 [D loss: 0.557265, acc.: 70.31%] [G loss: 1.163972]\n",
      "epoch:2 step:2447 [D loss: 0.713912, acc.: 56.25%] [G loss: 0.941020]\n",
      "epoch:2 step:2448 [D loss: 0.576955, acc.: 69.53%] [G loss: 1.039564]\n",
      "epoch:2 step:2449 [D loss: 0.700694, acc.: 58.59%] [G loss: 0.965977]\n",
      "epoch:2 step:2450 [D loss: 0.659600, acc.: 64.84%] [G loss: 1.062731]\n",
      "epoch:2 step:2451 [D loss: 0.614517, acc.: 67.97%] [G loss: 1.198945]\n",
      "epoch:2 step:2452 [D loss: 0.627142, acc.: 67.19%] [G loss: 1.173634]\n",
      "epoch:2 step:2453 [D loss: 0.750066, acc.: 50.00%] [G loss: 1.059894]\n",
      "epoch:2 step:2454 [D loss: 0.665586, acc.: 58.59%] [G loss: 1.011605]\n",
      "epoch:2 step:2455 [D loss: 0.630663, acc.: 62.50%] [G loss: 1.112054]\n",
      "epoch:2 step:2456 [D loss: 0.714860, acc.: 53.12%] [G loss: 1.000631]\n",
      "epoch:2 step:2457 [D loss: 0.634590, acc.: 64.84%] [G loss: 1.117893]\n",
      "epoch:2 step:2458 [D loss: 0.622661, acc.: 69.53%] [G loss: 1.069027]\n",
      "epoch:2 step:2459 [D loss: 0.652251, acc.: 64.06%] [G loss: 1.143496]\n",
      "epoch:2 step:2460 [D loss: 0.698924, acc.: 55.47%] [G loss: 0.993557]\n",
      "epoch:2 step:2461 [D loss: 0.593556, acc.: 68.75%] [G loss: 1.001000]\n",
      "epoch:2 step:2462 [D loss: 0.738956, acc.: 45.31%] [G loss: 1.137616]\n",
      "epoch:2 step:2463 [D loss: 0.626546, acc.: 60.94%] [G loss: 1.135741]\n",
      "epoch:2 step:2464 [D loss: 0.662767, acc.: 63.28%] [G loss: 1.211623]\n",
      "epoch:2 step:2465 [D loss: 0.600749, acc.: 66.41%] [G loss: 1.055879]\n",
      "epoch:2 step:2466 [D loss: 0.701684, acc.: 59.38%] [G loss: 1.004751]\n",
      "epoch:2 step:2467 [D loss: 0.689662, acc.: 57.81%] [G loss: 0.985478]\n",
      "epoch:2 step:2468 [D loss: 0.576078, acc.: 73.44%] [G loss: 1.201793]\n",
      "epoch:2 step:2469 [D loss: 0.695044, acc.: 62.50%] [G loss: 1.032400]\n",
      "epoch:2 step:2470 [D loss: 0.679229, acc.: 54.69%] [G loss: 0.962661]\n",
      "epoch:2 step:2471 [D loss: 0.695300, acc.: 56.25%] [G loss: 1.037948]\n",
      "epoch:2 step:2472 [D loss: 0.632922, acc.: 61.72%] [G loss: 1.070019]\n",
      "epoch:2 step:2473 [D loss: 0.599248, acc.: 68.75%] [G loss: 1.094310]\n",
      "epoch:2 step:2474 [D loss: 0.671520, acc.: 59.38%] [G loss: 0.983490]\n",
      "epoch:2 step:2475 [D loss: 0.761728, acc.: 53.12%] [G loss: 1.012844]\n",
      "epoch:2 step:2476 [D loss: 0.573266, acc.: 75.00%] [G loss: 1.254353]\n",
      "epoch:2 step:2477 [D loss: 0.549375, acc.: 75.78%] [G loss: 1.368390]\n",
      "epoch:2 step:2478 [D loss: 0.753306, acc.: 50.78%] [G loss: 1.105329]\n",
      "epoch:2 step:2479 [D loss: 0.696118, acc.: 57.81%] [G loss: 1.177734]\n",
      "epoch:2 step:2480 [D loss: 0.640772, acc.: 63.28%] [G loss: 1.082595]\n",
      "epoch:2 step:2481 [D loss: 0.715633, acc.: 54.69%] [G loss: 1.016581]\n",
      "epoch:2 step:2482 [D loss: 0.581585, acc.: 69.53%] [G loss: 1.176661]\n",
      "epoch:2 step:2483 [D loss: 0.714081, acc.: 60.94%] [G loss: 1.033066]\n",
      "epoch:2 step:2484 [D loss: 0.594624, acc.: 67.19%] [G loss: 1.139522]\n",
      "epoch:2 step:2485 [D loss: 0.628539, acc.: 62.50%] [G loss: 0.807156]\n",
      "epoch:2 step:2486 [D loss: 0.636312, acc.: 64.06%] [G loss: 1.058663]\n",
      "epoch:2 step:2487 [D loss: 0.608853, acc.: 67.19%] [G loss: 1.091004]\n",
      "epoch:2 step:2488 [D loss: 0.597302, acc.: 64.06%] [G loss: 1.033615]\n",
      "epoch:2 step:2489 [D loss: 0.581080, acc.: 69.53%] [G loss: 1.016121]\n",
      "epoch:2 step:2490 [D loss: 0.569944, acc.: 65.62%] [G loss: 1.162366]\n",
      "epoch:2 step:2491 [D loss: 0.652062, acc.: 63.28%] [G loss: 1.134783]\n",
      "epoch:2 step:2492 [D loss: 0.548335, acc.: 71.09%] [G loss: 1.159034]\n",
      "epoch:2 step:2493 [D loss: 0.593262, acc.: 63.28%] [G loss: 1.162998]\n",
      "epoch:2 step:2494 [D loss: 0.593575, acc.: 74.22%] [G loss: 1.120781]\n",
      "epoch:2 step:2495 [D loss: 0.638973, acc.: 64.84%] [G loss: 0.937401]\n",
      "epoch:2 step:2496 [D loss: 0.637483, acc.: 65.62%] [G loss: 1.278368]\n",
      "epoch:2 step:2497 [D loss: 0.705394, acc.: 56.25%] [G loss: 1.184349]\n",
      "epoch:2 step:2498 [D loss: 0.630335, acc.: 59.38%] [G loss: 1.049286]\n",
      "epoch:2 step:2499 [D loss: 0.633627, acc.: 62.50%] [G loss: 1.090177]\n",
      "epoch:2 step:2500 [D loss: 0.720369, acc.: 50.78%] [G loss: 1.157457]\n",
      "epoch:2 step:2501 [D loss: 0.629743, acc.: 64.06%] [G loss: 1.052348]\n",
      "epoch:2 step:2502 [D loss: 0.760061, acc.: 49.22%] [G loss: 1.031247]\n",
      "epoch:2 step:2503 [D loss: 0.608148, acc.: 64.84%] [G loss: 1.164460]\n",
      "epoch:2 step:2504 [D loss: 0.663431, acc.: 60.16%] [G loss: 1.152087]\n",
      "epoch:2 step:2505 [D loss: 0.627814, acc.: 60.16%] [G loss: 1.119797]\n",
      "epoch:2 step:2506 [D loss: 0.648210, acc.: 63.28%] [G loss: 1.087435]\n",
      "epoch:2 step:2507 [D loss: 0.687135, acc.: 58.59%] [G loss: 1.308441]\n",
      "epoch:2 step:2508 [D loss: 0.565876, acc.: 71.09%] [G loss: 1.113593]\n",
      "epoch:2 step:2509 [D loss: 0.675752, acc.: 60.16%] [G loss: 1.195840]\n",
      "epoch:2 step:2510 [D loss: 0.575548, acc.: 67.19%] [G loss: 1.065495]\n",
      "epoch:2 step:2511 [D loss: 0.511392, acc.: 75.78%] [G loss: 1.146599]\n",
      "epoch:2 step:2512 [D loss: 0.597452, acc.: 64.84%] [G loss: 1.058663]\n",
      "epoch:2 step:2513 [D loss: 0.699284, acc.: 57.03%] [G loss: 1.127405]\n",
      "epoch:2 step:2514 [D loss: 0.595509, acc.: 69.53%] [G loss: 1.222128]\n",
      "epoch:2 step:2515 [D loss: 0.658979, acc.: 57.81%] [G loss: 1.196227]\n",
      "epoch:2 step:2516 [D loss: 0.697481, acc.: 60.16%] [G loss: 1.021271]\n",
      "epoch:2 step:2517 [D loss: 0.665688, acc.: 60.16%] [G loss: 1.170112]\n",
      "epoch:2 step:2518 [D loss: 0.750428, acc.: 49.22%] [G loss: 1.105092]\n",
      "epoch:2 step:2519 [D loss: 0.644300, acc.: 61.72%] [G loss: 1.008532]\n",
      "epoch:2 step:2520 [D loss: 0.726606, acc.: 60.16%] [G loss: 1.069229]\n",
      "epoch:2 step:2521 [D loss: 0.785107, acc.: 44.53%] [G loss: 1.136850]\n",
      "epoch:2 step:2522 [D loss: 0.716345, acc.: 55.47%] [G loss: 1.086034]\n",
      "epoch:2 step:2523 [D loss: 0.706342, acc.: 54.69%] [G loss: 1.130254]\n",
      "epoch:2 step:2524 [D loss: 0.732280, acc.: 58.59%] [G loss: 0.890819]\n",
      "epoch:2 step:2525 [D loss: 0.720320, acc.: 55.47%] [G loss: 1.168300]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:2 step:2526 [D loss: 0.684309, acc.: 57.03%] [G loss: 1.151916]\n",
      "epoch:2 step:2527 [D loss: 0.630719, acc.: 66.41%] [G loss: 1.238769]\n",
      "epoch:2 step:2528 [D loss: 0.581918, acc.: 69.53%] [G loss: 1.137112]\n",
      "epoch:2 step:2529 [D loss: 0.686141, acc.: 57.81%] [G loss: 1.160835]\n",
      "epoch:2 step:2530 [D loss: 0.663222, acc.: 54.69%] [G loss: 1.100334]\n",
      "epoch:2 step:2531 [D loss: 0.703057, acc.: 55.47%] [G loss: 1.017461]\n",
      "epoch:2 step:2532 [D loss: 0.699902, acc.: 55.47%] [G loss: 1.043649]\n",
      "epoch:2 step:2533 [D loss: 0.650525, acc.: 60.16%] [G loss: 1.155442]\n",
      "epoch:2 step:2534 [D loss: 0.618230, acc.: 62.50%] [G loss: 1.099417]\n",
      "epoch:2 step:2535 [D loss: 0.673972, acc.: 63.28%] [G loss: 1.097476]\n",
      "epoch:2 step:2536 [D loss: 0.655065, acc.: 62.50%] [G loss: 1.169936]\n",
      "epoch:2 step:2537 [D loss: 0.655340, acc.: 56.25%] [G loss: 1.015977]\n",
      "epoch:2 step:2538 [D loss: 0.738296, acc.: 53.91%] [G loss: 1.086756]\n",
      "epoch:2 step:2539 [D loss: 0.641109, acc.: 64.06%] [G loss: 1.126691]\n",
      "epoch:2 step:2540 [D loss: 0.572653, acc.: 72.66%] [G loss: 1.023643]\n",
      "epoch:2 step:2541 [D loss: 0.653352, acc.: 60.94%] [G loss: 1.154227]\n",
      "epoch:2 step:2542 [D loss: 0.707464, acc.: 54.69%] [G loss: 1.068327]\n",
      "epoch:2 step:2543 [D loss: 0.603455, acc.: 64.06%] [G loss: 1.034893]\n",
      "epoch:2 step:2544 [D loss: 0.638307, acc.: 66.41%] [G loss: 1.028537]\n",
      "epoch:2 step:2545 [D loss: 0.696293, acc.: 56.25%] [G loss: 1.081151]\n",
      "epoch:2 step:2546 [D loss: 0.713562, acc.: 56.25%] [G loss: 0.992754]\n",
      "epoch:2 step:2547 [D loss: 0.592840, acc.: 67.19%] [G loss: 1.130195]\n",
      "epoch:2 step:2548 [D loss: 0.693412, acc.: 60.16%] [G loss: 0.993975]\n",
      "epoch:2 step:2549 [D loss: 0.731807, acc.: 53.12%] [G loss: 0.926093]\n",
      "epoch:2 step:2550 [D loss: 0.619324, acc.: 64.84%] [G loss: 1.035173]\n",
      "epoch:2 step:2551 [D loss: 0.644361, acc.: 60.16%] [G loss: 1.100231]\n",
      "epoch:2 step:2552 [D loss: 0.605730, acc.: 67.19%] [G loss: 1.166083]\n",
      "epoch:2 step:2553 [D loss: 0.655882, acc.: 60.16%] [G loss: 1.000754]\n",
      "epoch:2 step:2554 [D loss: 0.707332, acc.: 59.38%] [G loss: 1.072136]\n",
      "epoch:2 step:2555 [D loss: 0.629650, acc.: 64.06%] [G loss: 1.048209]\n",
      "epoch:2 step:2556 [D loss: 0.544771, acc.: 71.88%] [G loss: 1.194328]\n",
      "epoch:2 step:2557 [D loss: 0.626546, acc.: 63.28%] [G loss: 1.096112]\n",
      "epoch:2 step:2558 [D loss: 0.571769, acc.: 67.97%] [G loss: 1.191596]\n",
      "epoch:2 step:2559 [D loss: 0.632228, acc.: 64.84%] [G loss: 1.132411]\n",
      "epoch:2 step:2560 [D loss: 0.663065, acc.: 59.38%] [G loss: 1.161546]\n",
      "epoch:2 step:2561 [D loss: 0.656380, acc.: 64.84%] [G loss: 1.058069]\n",
      "epoch:2 step:2562 [D loss: 0.534139, acc.: 73.44%] [G loss: 1.199084]\n",
      "epoch:2 step:2563 [D loss: 0.666130, acc.: 57.81%] [G loss: 1.193818]\n",
      "epoch:2 step:2564 [D loss: 0.590888, acc.: 67.19%] [G loss: 1.206905]\n",
      "epoch:2 step:2565 [D loss: 0.631578, acc.: 67.19%] [G loss: 1.015922]\n",
      "epoch:2 step:2566 [D loss: 0.714417, acc.: 55.47%] [G loss: 1.049084]\n",
      "epoch:2 step:2567 [D loss: 0.690147, acc.: 62.50%] [G loss: 1.025123]\n",
      "epoch:2 step:2568 [D loss: 0.763960, acc.: 50.00%] [G loss: 1.061601]\n",
      "epoch:2 step:2569 [D loss: 0.617359, acc.: 62.50%] [G loss: 1.078214]\n",
      "epoch:2 step:2570 [D loss: 0.556086, acc.: 71.88%] [G loss: 1.207272]\n",
      "epoch:2 step:2571 [D loss: 0.622053, acc.: 65.62%] [G loss: 1.065297]\n",
      "epoch:2 step:2572 [D loss: 0.642833, acc.: 63.28%] [G loss: 0.852649]\n",
      "epoch:2 step:2573 [D loss: 0.653073, acc.: 63.28%] [G loss: 0.985030]\n",
      "epoch:2 step:2574 [D loss: 0.590234, acc.: 67.97%] [G loss: 1.114070]\n",
      "epoch:2 step:2575 [D loss: 0.674914, acc.: 61.72%] [G loss: 1.078460]\n",
      "epoch:2 step:2576 [D loss: 0.516429, acc.: 73.44%] [G loss: 1.048299]\n",
      "epoch:2 step:2577 [D loss: 0.681950, acc.: 56.25%] [G loss: 0.935253]\n",
      "epoch:2 step:2578 [D loss: 0.620081, acc.: 64.06%] [G loss: 0.981179]\n",
      "epoch:2 step:2579 [D loss: 0.666434, acc.: 63.28%] [G loss: 0.942694]\n",
      "epoch:2 step:2580 [D loss: 0.661936, acc.: 60.94%] [G loss: 1.048161]\n",
      "epoch:2 step:2581 [D loss: 0.721346, acc.: 58.59%] [G loss: 0.947488]\n",
      "epoch:2 step:2582 [D loss: 0.618285, acc.: 62.50%] [G loss: 1.247152]\n",
      "epoch:2 step:2583 [D loss: 0.863334, acc.: 43.75%] [G loss: 0.997174]\n",
      "epoch:2 step:2584 [D loss: 0.701076, acc.: 59.38%] [G loss: 0.976722]\n",
      "epoch:2 step:2585 [D loss: 0.628662, acc.: 64.84%] [G loss: 1.115868]\n",
      "epoch:2 step:2586 [D loss: 0.648882, acc.: 62.50%] [G loss: 1.150829]\n",
      "epoch:2 step:2587 [D loss: 0.629854, acc.: 69.53%] [G loss: 1.034216]\n",
      "epoch:2 step:2588 [D loss: 0.698014, acc.: 50.78%] [G loss: 1.030772]\n",
      "epoch:2 step:2589 [D loss: 0.651346, acc.: 60.94%] [G loss: 1.001724]\n",
      "epoch:2 step:2590 [D loss: 0.577465, acc.: 72.66%] [G loss: 1.098589]\n",
      "epoch:2 step:2591 [D loss: 0.663086, acc.: 65.62%] [G loss: 1.193692]\n",
      "epoch:2 step:2592 [D loss: 0.571205, acc.: 69.53%] [G loss: 1.049916]\n",
      "epoch:2 step:2593 [D loss: 0.552938, acc.: 72.66%] [G loss: 1.106359]\n",
      "epoch:2 step:2594 [D loss: 0.599582, acc.: 67.19%] [G loss: 1.159380]\n",
      "epoch:2 step:2595 [D loss: 0.754475, acc.: 54.69%] [G loss: 0.981343]\n",
      "epoch:2 step:2596 [D loss: 0.572397, acc.: 71.88%] [G loss: 1.100121]\n",
      "epoch:2 step:2597 [D loss: 0.689568, acc.: 57.81%] [G loss: 1.096231]\n",
      "epoch:2 step:2598 [D loss: 0.588768, acc.: 66.41%] [G loss: 1.143760]\n",
      "epoch:2 step:2599 [D loss: 0.700668, acc.: 57.81%] [G loss: 1.005973]\n",
      "epoch:2 step:2600 [D loss: 0.646474, acc.: 65.62%] [G loss: 1.098349]\n",
      "epoch:2 step:2601 [D loss: 0.628744, acc.: 62.50%] [G loss: 1.019966]\n",
      "epoch:2 step:2602 [D loss: 0.711290, acc.: 57.81%] [G loss: 1.047385]\n",
      "epoch:2 step:2603 [D loss: 0.727771, acc.: 57.03%] [G loss: 0.977906]\n",
      "epoch:2 step:2604 [D loss: 0.660648, acc.: 64.06%] [G loss: 1.068612]\n",
      "epoch:2 step:2605 [D loss: 0.737101, acc.: 53.91%] [G loss: 1.062591]\n",
      "epoch:2 step:2606 [D loss: 0.622431, acc.: 65.62%] [G loss: 1.023777]\n",
      "epoch:2 step:2607 [D loss: 0.723419, acc.: 57.81%] [G loss: 1.126312]\n",
      "epoch:2 step:2608 [D loss: 0.633078, acc.: 60.16%] [G loss: 0.904794]\n",
      "epoch:2 step:2609 [D loss: 0.618617, acc.: 71.09%] [G loss: 1.106342]\n",
      "epoch:2 step:2610 [D loss: 0.691411, acc.: 57.81%] [G loss: 1.008322]\n",
      "epoch:2 step:2611 [D loss: 0.707256, acc.: 57.03%] [G loss: 1.097203]\n",
      "epoch:2 step:2612 [D loss: 0.647543, acc.: 60.94%] [G loss: 1.065198]\n",
      "epoch:2 step:2613 [D loss: 0.645936, acc.: 60.94%] [G loss: 1.038179]\n",
      "epoch:2 step:2614 [D loss: 0.632798, acc.: 64.06%] [G loss: 1.057517]\n",
      "epoch:2 step:2615 [D loss: 0.665183, acc.: 63.28%] [G loss: 1.109765]\n",
      "epoch:2 step:2616 [D loss: 0.743286, acc.: 53.91%] [G loss: 1.014387]\n",
      "epoch:2 step:2617 [D loss: 0.719434, acc.: 52.34%] [G loss: 1.176542]\n",
      "epoch:2 step:2618 [D loss: 0.628032, acc.: 69.53%] [G loss: 0.991166]\n",
      "epoch:2 step:2619 [D loss: 0.560834, acc.: 73.44%] [G loss: 1.114893]\n",
      "epoch:2 step:2620 [D loss: 0.645485, acc.: 63.28%] [G loss: 0.971532]\n",
      "epoch:2 step:2621 [D loss: 0.719516, acc.: 53.12%] [G loss: 1.011876]\n",
      "epoch:2 step:2622 [D loss: 0.556331, acc.: 71.09%] [G loss: 1.070256]\n",
      "epoch:2 step:2623 [D loss: 0.678796, acc.: 60.94%] [G loss: 1.234457]\n",
      "epoch:2 step:2624 [D loss: 0.695323, acc.: 57.03%] [G loss: 0.987055]\n",
      "epoch:2 step:2625 [D loss: 0.603069, acc.: 65.62%] [G loss: 1.233532]\n",
      "epoch:2 step:2626 [D loss: 0.711568, acc.: 57.81%] [G loss: 1.121966]\n",
      "epoch:2 step:2627 [D loss: 0.615733, acc.: 65.62%] [G loss: 1.043579]\n",
      "epoch:2 step:2628 [D loss: 0.673698, acc.: 63.28%] [G loss: 1.180559]\n",
      "epoch:2 step:2629 [D loss: 0.706381, acc.: 55.47%] [G loss: 0.871286]\n",
      "epoch:2 step:2630 [D loss: 0.637078, acc.: 60.94%] [G loss: 1.062783]\n",
      "epoch:2 step:2631 [D loss: 0.625828, acc.: 60.94%] [G loss: 1.092318]\n",
      "epoch:2 step:2632 [D loss: 0.681479, acc.: 57.03%] [G loss: 1.097727]\n",
      "epoch:2 step:2633 [D loss: 0.636627, acc.: 66.41%] [G loss: 1.023543]\n",
      "epoch:2 step:2634 [D loss: 0.600895, acc.: 65.62%] [G loss: 1.118390]\n",
      "epoch:2 step:2635 [D loss: 0.706648, acc.: 58.59%] [G loss: 0.865458]\n",
      "epoch:2 step:2636 [D loss: 0.695492, acc.: 58.59%] [G loss: 1.073389]\n",
      "epoch:2 step:2637 [D loss: 0.629434, acc.: 60.16%] [G loss: 0.973426]\n",
      "epoch:2 step:2638 [D loss: 0.592418, acc.: 64.06%] [G loss: 0.993626]\n",
      "epoch:2 step:2639 [D loss: 0.597404, acc.: 67.97%] [G loss: 1.094950]\n",
      "epoch:2 step:2640 [D loss: 0.732970, acc.: 49.22%] [G loss: 1.041845]\n",
      "epoch:2 step:2641 [D loss: 0.682716, acc.: 53.12%] [G loss: 1.072293]\n",
      "epoch:2 step:2642 [D loss: 0.686919, acc.: 54.69%] [G loss: 1.064161]\n",
      "epoch:2 step:2643 [D loss: 0.642016, acc.: 64.84%] [G loss: 1.010609]\n",
      "epoch:2 step:2644 [D loss: 0.618451, acc.: 63.28%] [G loss: 1.201287]\n",
      "epoch:2 step:2645 [D loss: 0.642390, acc.: 60.94%] [G loss: 1.029874]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:2 step:2646 [D loss: 0.626459, acc.: 63.28%] [G loss: 1.106230]\n",
      "epoch:2 step:2647 [D loss: 0.697882, acc.: 60.16%] [G loss: 1.094351]\n",
      "epoch:2 step:2648 [D loss: 0.605508, acc.: 69.53%] [G loss: 1.194103]\n",
      "epoch:2 step:2649 [D loss: 0.709851, acc.: 56.25%] [G loss: 1.052256]\n",
      "epoch:2 step:2650 [D loss: 0.675228, acc.: 60.16%] [G loss: 1.210018]\n",
      "epoch:2 step:2651 [D loss: 0.662598, acc.: 57.81%] [G loss: 1.097023]\n",
      "epoch:2 step:2652 [D loss: 0.630441, acc.: 64.84%] [G loss: 1.133920]\n",
      "epoch:2 step:2653 [D loss: 0.663480, acc.: 58.59%] [G loss: 1.153866]\n",
      "epoch:2 step:2654 [D loss: 0.681090, acc.: 56.25%] [G loss: 1.062999]\n",
      "epoch:2 step:2655 [D loss: 0.633402, acc.: 61.72%] [G loss: 1.057645]\n",
      "epoch:2 step:2656 [D loss: 0.628621, acc.: 68.75%] [G loss: 1.008414]\n",
      "epoch:2 step:2657 [D loss: 0.712068, acc.: 57.81%] [G loss: 1.020817]\n",
      "epoch:2 step:2658 [D loss: 0.714783, acc.: 54.69%] [G loss: 1.027565]\n",
      "epoch:2 step:2659 [D loss: 0.695787, acc.: 57.81%] [G loss: 1.064115]\n",
      "epoch:2 step:2660 [D loss: 0.712669, acc.: 54.69%] [G loss: 0.981486]\n",
      "epoch:2 step:2661 [D loss: 0.640574, acc.: 64.84%] [G loss: 0.870523]\n",
      "epoch:2 step:2662 [D loss: 0.696226, acc.: 54.69%] [G loss: 0.926388]\n",
      "epoch:2 step:2663 [D loss: 0.692409, acc.: 55.47%] [G loss: 1.089268]\n",
      "epoch:2 step:2664 [D loss: 0.595192, acc.: 70.31%] [G loss: 1.160924]\n",
      "epoch:2 step:2665 [D loss: 0.632563, acc.: 67.97%] [G loss: 1.225892]\n",
      "epoch:2 step:2666 [D loss: 0.671681, acc.: 60.94%] [G loss: 1.076082]\n",
      "epoch:2 step:2667 [D loss: 0.697295, acc.: 58.59%] [G loss: 0.990821]\n",
      "epoch:2 step:2668 [D loss: 0.655975, acc.: 57.81%] [G loss: 1.045773]\n",
      "epoch:2 step:2669 [D loss: 0.625556, acc.: 67.19%] [G loss: 1.155309]\n",
      "epoch:2 step:2670 [D loss: 0.672897, acc.: 58.59%] [G loss: 0.979570]\n",
      "epoch:2 step:2671 [D loss: 0.679849, acc.: 57.03%] [G loss: 1.188751]\n",
      "epoch:2 step:2672 [D loss: 0.571020, acc.: 67.97%] [G loss: 1.154027]\n",
      "epoch:2 step:2673 [D loss: 0.708972, acc.: 49.22%] [G loss: 1.035471]\n",
      "epoch:2 step:2674 [D loss: 0.674025, acc.: 58.59%] [G loss: 1.088708]\n",
      "epoch:2 step:2675 [D loss: 0.598422, acc.: 71.09%] [G loss: 1.169326]\n",
      "epoch:2 step:2676 [D loss: 0.590900, acc.: 67.19%] [G loss: 1.019453]\n",
      "epoch:2 step:2677 [D loss: 0.638397, acc.: 65.62%] [G loss: 0.929100]\n",
      "epoch:2 step:2678 [D loss: 0.637058, acc.: 61.72%] [G loss: 1.032795]\n",
      "epoch:2 step:2679 [D loss: 0.755376, acc.: 53.12%] [G loss: 0.950844]\n",
      "epoch:2 step:2680 [D loss: 0.626083, acc.: 64.06%] [G loss: 1.073153]\n",
      "epoch:2 step:2681 [D loss: 0.614551, acc.: 67.19%] [G loss: 1.034857]\n",
      "epoch:2 step:2682 [D loss: 0.653274, acc.: 60.94%] [G loss: 1.041778]\n",
      "epoch:2 step:2683 [D loss: 0.598285, acc.: 64.06%] [G loss: 1.116722]\n",
      "epoch:2 step:2684 [D loss: 0.655686, acc.: 63.28%] [G loss: 1.101526]\n",
      "epoch:2 step:2685 [D loss: 0.646431, acc.: 57.81%] [G loss: 1.010358]\n",
      "epoch:2 step:2686 [D loss: 0.561253, acc.: 71.88%] [G loss: 1.043761]\n",
      "epoch:2 step:2687 [D loss: 0.701858, acc.: 64.06%] [G loss: 0.934001]\n",
      "epoch:2 step:2688 [D loss: 0.698864, acc.: 58.59%] [G loss: 1.045693]\n",
      "epoch:2 step:2689 [D loss: 0.689235, acc.: 56.25%] [G loss: 1.125110]\n",
      "epoch:2 step:2690 [D loss: 0.533877, acc.: 76.56%] [G loss: 1.208790]\n",
      "epoch:2 step:2691 [D loss: 0.650554, acc.: 66.41%] [G loss: 1.103322]\n",
      "epoch:2 step:2692 [D loss: 0.655500, acc.: 62.50%] [G loss: 1.004074]\n",
      "epoch:2 step:2693 [D loss: 0.635920, acc.: 63.28%] [G loss: 1.039370]\n",
      "epoch:2 step:2694 [D loss: 0.619637, acc.: 67.97%] [G loss: 1.148107]\n",
      "epoch:2 step:2695 [D loss: 0.565349, acc.: 72.66%] [G loss: 1.277730]\n",
      "epoch:2 step:2696 [D loss: 0.621848, acc.: 64.06%] [G loss: 1.009453]\n",
      "epoch:2 step:2697 [D loss: 0.650862, acc.: 61.72%] [G loss: 0.999330]\n",
      "epoch:2 step:2698 [D loss: 0.698085, acc.: 57.81%] [G loss: 1.065893]\n",
      "epoch:2 step:2699 [D loss: 0.589276, acc.: 69.53%] [G loss: 0.888861]\n",
      "epoch:2 step:2700 [D loss: 0.610512, acc.: 65.62%] [G loss: 1.237449]\n",
      "epoch:2 step:2701 [D loss: 0.659976, acc.: 63.28%] [G loss: 1.235434]\n",
      "epoch:2 step:2702 [D loss: 0.737283, acc.: 54.69%] [G loss: 0.992022]\n",
      "epoch:2 step:2703 [D loss: 0.705130, acc.: 55.47%] [G loss: 1.028573]\n",
      "epoch:2 step:2704 [D loss: 0.676721, acc.: 53.91%] [G loss: 1.146212]\n",
      "epoch:2 step:2705 [D loss: 0.672072, acc.: 60.94%] [G loss: 1.005914]\n",
      "epoch:2 step:2706 [D loss: 0.606064, acc.: 66.41%] [G loss: 1.143787]\n",
      "epoch:2 step:2707 [D loss: 0.691353, acc.: 56.25%] [G loss: 1.004140]\n",
      "epoch:2 step:2708 [D loss: 0.819254, acc.: 42.19%] [G loss: 0.922043]\n",
      "epoch:2 step:2709 [D loss: 0.647833, acc.: 65.62%] [G loss: 0.974716]\n",
      "epoch:2 step:2710 [D loss: 0.667447, acc.: 63.28%] [G loss: 1.075831]\n",
      "epoch:2 step:2711 [D loss: 0.682187, acc.: 57.03%] [G loss: 0.891145]\n",
      "epoch:2 step:2712 [D loss: 0.647221, acc.: 59.38%] [G loss: 1.027228]\n",
      "epoch:2 step:2713 [D loss: 0.736220, acc.: 54.69%] [G loss: 0.911993]\n",
      "epoch:2 step:2714 [D loss: 0.541996, acc.: 74.22%] [G loss: 1.235085]\n",
      "epoch:2 step:2715 [D loss: 0.657162, acc.: 58.59%] [G loss: 1.050469]\n",
      "epoch:2 step:2716 [D loss: 0.648959, acc.: 56.25%] [G loss: 1.187064]\n",
      "epoch:2 step:2717 [D loss: 0.679527, acc.: 57.81%] [G loss: 1.046905]\n",
      "epoch:2 step:2718 [D loss: 0.599254, acc.: 66.41%] [G loss: 0.966243]\n",
      "epoch:2 step:2719 [D loss: 0.619262, acc.: 71.88%] [G loss: 1.019825]\n",
      "epoch:2 step:2720 [D loss: 0.697364, acc.: 55.47%] [G loss: 0.947975]\n",
      "epoch:2 step:2721 [D loss: 0.701468, acc.: 53.91%] [G loss: 0.957470]\n",
      "epoch:2 step:2722 [D loss: 0.623155, acc.: 67.97%] [G loss: 0.956950]\n",
      "epoch:2 step:2723 [D loss: 0.702854, acc.: 56.25%] [G loss: 1.051850]\n",
      "epoch:2 step:2724 [D loss: 0.592086, acc.: 69.53%] [G loss: 1.077631]\n",
      "epoch:2 step:2725 [D loss: 0.673640, acc.: 52.34%] [G loss: 1.034788]\n",
      "epoch:2 step:2726 [D loss: 0.591468, acc.: 66.41%] [G loss: 0.980740]\n",
      "epoch:2 step:2727 [D loss: 0.637042, acc.: 62.50%] [G loss: 1.011662]\n",
      "epoch:2 step:2728 [D loss: 0.676211, acc.: 57.81%] [G loss: 1.120316]\n",
      "epoch:2 step:2729 [D loss: 0.687636, acc.: 57.03%] [G loss: 1.067907]\n",
      "epoch:2 step:2730 [D loss: 0.613401, acc.: 66.41%] [G loss: 1.123179]\n",
      "epoch:2 step:2731 [D loss: 0.620671, acc.: 62.50%] [G loss: 1.096472]\n",
      "epoch:2 step:2732 [D loss: 0.643086, acc.: 61.72%] [G loss: 0.922817]\n",
      "epoch:2 step:2733 [D loss: 0.706045, acc.: 55.47%] [G loss: 0.848313]\n",
      "epoch:2 step:2734 [D loss: 0.647333, acc.: 67.97%] [G loss: 0.918742]\n",
      "epoch:2 step:2735 [D loss: 0.713784, acc.: 57.03%] [G loss: 1.123434]\n",
      "epoch:2 step:2736 [D loss: 0.699459, acc.: 57.81%] [G loss: 1.052311]\n",
      "epoch:2 step:2737 [D loss: 0.683111, acc.: 58.59%] [G loss: 0.947105]\n",
      "epoch:2 step:2738 [D loss: 0.642672, acc.: 59.38%] [G loss: 0.962224]\n",
      "epoch:2 step:2739 [D loss: 0.662723, acc.: 62.50%] [G loss: 1.013003]\n",
      "epoch:2 step:2740 [D loss: 0.576428, acc.: 71.09%] [G loss: 1.063386]\n",
      "epoch:2 step:2741 [D loss: 0.684786, acc.: 54.69%] [G loss: 1.036222]\n",
      "epoch:2 step:2742 [D loss: 0.676762, acc.: 58.59%] [G loss: 0.946945]\n",
      "epoch:2 step:2743 [D loss: 0.670767, acc.: 63.28%] [G loss: 1.074177]\n",
      "epoch:2 step:2744 [D loss: 0.660049, acc.: 62.50%] [G loss: 1.072585]\n",
      "epoch:2 step:2745 [D loss: 0.652583, acc.: 60.94%] [G loss: 1.123764]\n",
      "epoch:2 step:2746 [D loss: 0.661422, acc.: 61.72%] [G loss: 1.029000]\n",
      "epoch:2 step:2747 [D loss: 0.562957, acc.: 70.31%] [G loss: 1.062799]\n",
      "epoch:2 step:2748 [D loss: 0.674055, acc.: 64.84%] [G loss: 0.917296]\n",
      "epoch:2 step:2749 [D loss: 0.545304, acc.: 72.66%] [G loss: 1.201365]\n",
      "epoch:2 step:2750 [D loss: 0.659995, acc.: 60.94%] [G loss: 1.079174]\n",
      "epoch:2 step:2751 [D loss: 0.665178, acc.: 62.50%] [G loss: 1.030153]\n",
      "epoch:2 step:2752 [D loss: 0.682643, acc.: 59.38%] [G loss: 0.903934]\n",
      "epoch:2 step:2753 [D loss: 0.651136, acc.: 64.84%] [G loss: 1.037301]\n",
      "epoch:2 step:2754 [D loss: 0.607793, acc.: 66.41%] [G loss: 1.106874]\n",
      "epoch:2 step:2755 [D loss: 0.673947, acc.: 57.81%] [G loss: 1.064943]\n",
      "epoch:2 step:2756 [D loss: 0.653097, acc.: 63.28%] [G loss: 0.925400]\n",
      "epoch:2 step:2757 [D loss: 0.678999, acc.: 55.47%] [G loss: 1.129628]\n",
      "epoch:2 step:2758 [D loss: 0.711053, acc.: 62.50%] [G loss: 1.056161]\n",
      "epoch:2 step:2759 [D loss: 0.583808, acc.: 74.22%] [G loss: 1.099603]\n",
      "epoch:2 step:2760 [D loss: 0.666067, acc.: 63.28%] [G loss: 0.956464]\n",
      "epoch:2 step:2761 [D loss: 0.698665, acc.: 57.81%] [G loss: 1.212270]\n",
      "epoch:2 step:2762 [D loss: 0.654815, acc.: 64.06%] [G loss: 1.200401]\n",
      "epoch:2 step:2763 [D loss: 0.627303, acc.: 62.50%] [G loss: 1.066163]\n",
      "epoch:2 step:2764 [D loss: 0.684271, acc.: 57.81%] [G loss: 0.998162]\n",
      "epoch:2 step:2765 [D loss: 0.693276, acc.: 53.12%] [G loss: 1.141014]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:2 step:2766 [D loss: 0.680344, acc.: 53.91%] [G loss: 1.023300]\n",
      "epoch:2 step:2767 [D loss: 0.631823, acc.: 67.97%] [G loss: 1.003603]\n",
      "epoch:2 step:2768 [D loss: 0.633761, acc.: 59.38%] [G loss: 1.013381]\n",
      "epoch:2 step:2769 [D loss: 0.529850, acc.: 73.44%] [G loss: 1.132728]\n",
      "epoch:2 step:2770 [D loss: 0.602218, acc.: 70.31%] [G loss: 1.046260]\n",
      "epoch:2 step:2771 [D loss: 0.623273, acc.: 63.28%] [G loss: 1.042385]\n",
      "epoch:2 step:2772 [D loss: 0.659839, acc.: 59.38%] [G loss: 1.032926]\n",
      "epoch:2 step:2773 [D loss: 0.620052, acc.: 64.84%] [G loss: 0.892909]\n",
      "epoch:2 step:2774 [D loss: 0.593961, acc.: 68.75%] [G loss: 1.255372]\n",
      "epoch:2 step:2775 [D loss: 0.699634, acc.: 55.47%] [G loss: 1.109912]\n",
      "epoch:2 step:2776 [D loss: 0.635348, acc.: 59.38%] [G loss: 1.103722]\n",
      "epoch:2 step:2777 [D loss: 0.592139, acc.: 65.62%] [G loss: 1.057445]\n",
      "epoch:2 step:2778 [D loss: 0.588843, acc.: 68.75%] [G loss: 1.114179]\n",
      "epoch:2 step:2779 [D loss: 0.599309, acc.: 67.19%] [G loss: 1.170638]\n",
      "epoch:2 step:2780 [D loss: 0.629251, acc.: 65.62%] [G loss: 1.011842]\n",
      "epoch:2 step:2781 [D loss: 0.702999, acc.: 57.81%] [G loss: 1.084854]\n",
      "epoch:2 step:2782 [D loss: 0.650037, acc.: 57.81%] [G loss: 1.001726]\n",
      "epoch:2 step:2783 [D loss: 0.629193, acc.: 61.72%] [G loss: 1.074976]\n",
      "epoch:2 step:2784 [D loss: 0.676981, acc.: 64.06%] [G loss: 1.128925]\n",
      "epoch:2 step:2785 [D loss: 0.669667, acc.: 58.59%] [G loss: 1.045012]\n",
      "epoch:2 step:2786 [D loss: 0.671235, acc.: 63.28%] [G loss: 1.106094]\n",
      "epoch:2 step:2787 [D loss: 0.656479, acc.: 60.16%] [G loss: 1.036036]\n",
      "epoch:2 step:2788 [D loss: 0.636017, acc.: 53.91%] [G loss: 1.214986]\n",
      "epoch:2 step:2789 [D loss: 0.596008, acc.: 63.28%] [G loss: 1.046592]\n",
      "epoch:2 step:2790 [D loss: 0.628358, acc.: 67.97%] [G loss: 1.152197]\n",
      "epoch:2 step:2791 [D loss: 0.697682, acc.: 57.81%] [G loss: 1.143479]\n",
      "epoch:2 step:2792 [D loss: 0.680215, acc.: 60.16%] [G loss: 1.100722]\n",
      "epoch:2 step:2793 [D loss: 0.543684, acc.: 69.53%] [G loss: 1.202532]\n",
      "epoch:2 step:2794 [D loss: 0.670541, acc.: 67.19%] [G loss: 1.067624]\n",
      "epoch:2 step:2795 [D loss: 0.695610, acc.: 56.25%] [G loss: 0.942728]\n",
      "epoch:2 step:2796 [D loss: 0.594902, acc.: 66.41%] [G loss: 1.083406]\n",
      "epoch:2 step:2797 [D loss: 0.680653, acc.: 63.28%] [G loss: 1.135357]\n",
      "epoch:2 step:2798 [D loss: 0.675697, acc.: 64.06%] [G loss: 1.004754]\n",
      "epoch:2 step:2799 [D loss: 0.718331, acc.: 57.81%] [G loss: 0.989037]\n",
      "epoch:2 step:2800 [D loss: 0.687740, acc.: 57.03%] [G loss: 1.024605]\n",
      "epoch:2 step:2801 [D loss: 0.708537, acc.: 58.59%] [G loss: 1.012092]\n",
      "epoch:2 step:2802 [D loss: 0.592771, acc.: 69.53%] [G loss: 1.135636]\n",
      "epoch:2 step:2803 [D loss: 0.613053, acc.: 64.84%] [G loss: 1.139093]\n",
      "epoch:2 step:2804 [D loss: 0.692004, acc.: 59.38%] [G loss: 1.126760]\n",
      "epoch:2 step:2805 [D loss: 0.590794, acc.: 67.97%] [G loss: 1.238224]\n",
      "epoch:2 step:2806 [D loss: 0.581467, acc.: 68.75%] [G loss: 1.065281]\n",
      "epoch:2 step:2807 [D loss: 0.638000, acc.: 64.84%] [G loss: 1.006857]\n",
      "epoch:2 step:2808 [D loss: 0.660891, acc.: 64.06%] [G loss: 0.915841]\n",
      "epoch:2 step:2809 [D loss: 0.721422, acc.: 53.12%] [G loss: 1.017994]\n",
      "epoch:2 step:2810 [D loss: 0.611812, acc.: 67.19%] [G loss: 1.061268]\n",
      "epoch:2 step:2811 [D loss: 0.746853, acc.: 55.47%] [G loss: 1.153577]\n",
      "epoch:3 step:2812 [D loss: 0.650265, acc.: 64.06%] [G loss: 1.019593]\n",
      "epoch:3 step:2813 [D loss: 0.653084, acc.: 60.16%] [G loss: 0.997722]\n",
      "epoch:3 step:2814 [D loss: 0.570978, acc.: 72.66%] [G loss: 1.011187]\n",
      "epoch:3 step:2815 [D loss: 0.672777, acc.: 55.47%] [G loss: 1.155627]\n",
      "epoch:3 step:2816 [D loss: 0.618693, acc.: 64.06%] [G loss: 0.962753]\n",
      "epoch:3 step:2817 [D loss: 0.727752, acc.: 46.09%] [G loss: 0.988378]\n",
      "epoch:3 step:2818 [D loss: 0.751110, acc.: 51.56%] [G loss: 0.957518]\n",
      "epoch:3 step:2819 [D loss: 0.661837, acc.: 58.59%] [G loss: 1.158674]\n",
      "epoch:3 step:2820 [D loss: 0.578373, acc.: 71.88%] [G loss: 1.136704]\n",
      "epoch:3 step:2821 [D loss: 0.739344, acc.: 54.69%] [G loss: 1.136741]\n",
      "epoch:3 step:2822 [D loss: 0.581080, acc.: 71.88%] [G loss: 1.113062]\n",
      "epoch:3 step:2823 [D loss: 0.617488, acc.: 64.06%] [G loss: 1.117156]\n",
      "epoch:3 step:2824 [D loss: 0.591238, acc.: 64.84%] [G loss: 1.088464]\n",
      "epoch:3 step:2825 [D loss: 0.697955, acc.: 62.50%] [G loss: 0.928166]\n",
      "epoch:3 step:2826 [D loss: 0.645408, acc.: 64.84%] [G loss: 1.067735]\n",
      "epoch:3 step:2827 [D loss: 0.630027, acc.: 64.84%] [G loss: 1.000006]\n",
      "epoch:3 step:2828 [D loss: 0.667400, acc.: 57.03%] [G loss: 1.060355]\n",
      "epoch:3 step:2829 [D loss: 0.755909, acc.: 52.34%] [G loss: 0.982299]\n",
      "epoch:3 step:2830 [D loss: 0.676929, acc.: 57.81%] [G loss: 1.148699]\n",
      "epoch:3 step:2831 [D loss: 0.660490, acc.: 61.72%] [G loss: 1.050070]\n",
      "epoch:3 step:2832 [D loss: 0.628799, acc.: 66.41%] [G loss: 1.049003]\n",
      "epoch:3 step:2833 [D loss: 0.627327, acc.: 71.09%] [G loss: 1.151604]\n",
      "epoch:3 step:2834 [D loss: 0.670173, acc.: 62.50%] [G loss: 1.089666]\n",
      "epoch:3 step:2835 [D loss: 0.578126, acc.: 69.53%] [G loss: 1.290749]\n",
      "epoch:3 step:2836 [D loss: 0.702965, acc.: 59.38%] [G loss: 1.036220]\n",
      "epoch:3 step:2837 [D loss: 0.707200, acc.: 53.91%] [G loss: 1.065293]\n",
      "epoch:3 step:2838 [D loss: 0.667608, acc.: 55.47%] [G loss: 1.075428]\n",
      "epoch:3 step:2839 [D loss: 0.614244, acc.: 67.19%] [G loss: 1.207492]\n",
      "epoch:3 step:2840 [D loss: 0.643604, acc.: 65.62%] [G loss: 1.072393]\n",
      "epoch:3 step:2841 [D loss: 0.670451, acc.: 61.72%] [G loss: 1.165493]\n",
      "epoch:3 step:2842 [D loss: 0.699238, acc.: 52.34%] [G loss: 1.022713]\n",
      "epoch:3 step:2843 [D loss: 0.603227, acc.: 71.09%] [G loss: 1.063581]\n",
      "epoch:3 step:2844 [D loss: 0.636512, acc.: 60.16%] [G loss: 1.050697]\n",
      "epoch:3 step:2845 [D loss: 0.659656, acc.: 61.72%] [G loss: 1.010344]\n",
      "epoch:3 step:2846 [D loss: 0.619785, acc.: 66.41%] [G loss: 0.995261]\n",
      "epoch:3 step:2847 [D loss: 0.607437, acc.: 64.06%] [G loss: 0.986913]\n",
      "epoch:3 step:2848 [D loss: 0.594788, acc.: 71.88%] [G loss: 1.040946]\n",
      "epoch:3 step:2849 [D loss: 0.683192, acc.: 60.94%] [G loss: 0.962487]\n",
      "epoch:3 step:2850 [D loss: 0.705472, acc.: 60.16%] [G loss: 1.149063]\n",
      "epoch:3 step:2851 [D loss: 0.716807, acc.: 57.81%] [G loss: 0.955441]\n",
      "epoch:3 step:2852 [D loss: 0.624690, acc.: 64.84%] [G loss: 0.932136]\n",
      "epoch:3 step:2853 [D loss: 0.690309, acc.: 59.38%] [G loss: 0.903033]\n",
      "epoch:3 step:2854 [D loss: 0.583641, acc.: 69.53%] [G loss: 1.065063]\n",
      "epoch:3 step:2855 [D loss: 0.659311, acc.: 64.84%] [G loss: 1.165297]\n",
      "epoch:3 step:2856 [D loss: 0.691666, acc.: 54.69%] [G loss: 0.874788]\n",
      "epoch:3 step:2857 [D loss: 0.695392, acc.: 57.81%] [G loss: 1.148394]\n",
      "epoch:3 step:2858 [D loss: 0.711758, acc.: 56.25%] [G loss: 1.042263]\n",
      "epoch:3 step:2859 [D loss: 0.625637, acc.: 64.06%] [G loss: 1.045837]\n",
      "epoch:3 step:2860 [D loss: 0.617305, acc.: 67.19%] [G loss: 1.029309]\n",
      "epoch:3 step:2861 [D loss: 0.684419, acc.: 57.81%] [G loss: 1.006392]\n",
      "epoch:3 step:2862 [D loss: 0.560899, acc.: 70.31%] [G loss: 1.051380]\n",
      "epoch:3 step:2863 [D loss: 0.687088, acc.: 56.25%] [G loss: 0.962360]\n",
      "epoch:3 step:2864 [D loss: 0.742188, acc.: 53.12%] [G loss: 1.095583]\n",
      "epoch:3 step:2865 [D loss: 0.715808, acc.: 57.03%] [G loss: 1.020022]\n",
      "epoch:3 step:2866 [D loss: 0.627421, acc.: 57.81%] [G loss: 1.144944]\n",
      "epoch:3 step:2867 [D loss: 0.638543, acc.: 67.19%] [G loss: 1.067419]\n",
      "epoch:3 step:2868 [D loss: 0.732749, acc.: 53.91%] [G loss: 1.095990]\n",
      "epoch:3 step:2869 [D loss: 0.689601, acc.: 61.72%] [G loss: 1.160052]\n",
      "epoch:3 step:2870 [D loss: 0.591958, acc.: 66.41%] [G loss: 1.082532]\n",
      "epoch:3 step:2871 [D loss: 0.546516, acc.: 73.44%] [G loss: 1.296388]\n",
      "epoch:3 step:2872 [D loss: 0.640190, acc.: 64.06%] [G loss: 1.167844]\n",
      "epoch:3 step:2873 [D loss: 0.626315, acc.: 64.84%] [G loss: 1.119809]\n",
      "epoch:3 step:2874 [D loss: 0.672571, acc.: 58.59%] [G loss: 1.033832]\n",
      "epoch:3 step:2875 [D loss: 0.574265, acc.: 71.88%] [G loss: 1.024490]\n",
      "epoch:3 step:2876 [D loss: 0.621202, acc.: 67.19%] [G loss: 1.062276]\n",
      "epoch:3 step:2877 [D loss: 0.607491, acc.: 70.31%] [G loss: 1.102200]\n",
      "epoch:3 step:2878 [D loss: 0.604787, acc.: 69.53%] [G loss: 1.011177]\n",
      "epoch:3 step:2879 [D loss: 0.587443, acc.: 71.09%] [G loss: 1.122809]\n",
      "epoch:3 step:2880 [D loss: 0.641228, acc.: 59.38%] [G loss: 1.130756]\n",
      "epoch:3 step:2881 [D loss: 0.676065, acc.: 59.38%] [G loss: 1.045194]\n",
      "epoch:3 step:2882 [D loss: 0.643531, acc.: 62.50%] [G loss: 0.944205]\n",
      "epoch:3 step:2883 [D loss: 0.647841, acc.: 66.41%] [G loss: 0.981273]\n",
      "epoch:3 step:2884 [D loss: 0.632700, acc.: 64.06%] [G loss: 1.164041]\n",
      "epoch:3 step:2885 [D loss: 0.627978, acc.: 61.72%] [G loss: 1.038708]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:3 step:2886 [D loss: 0.646947, acc.: 62.50%] [G loss: 1.047383]\n",
      "epoch:3 step:2887 [D loss: 0.629913, acc.: 62.50%] [G loss: 1.077883]\n",
      "epoch:3 step:2888 [D loss: 0.690246, acc.: 60.94%] [G loss: 0.977948]\n",
      "epoch:3 step:2889 [D loss: 0.593455, acc.: 68.75%] [G loss: 1.041988]\n",
      "epoch:3 step:2890 [D loss: 0.664618, acc.: 60.94%] [G loss: 0.957336]\n",
      "epoch:3 step:2891 [D loss: 0.583975, acc.: 67.97%] [G loss: 1.088924]\n",
      "epoch:3 step:2892 [D loss: 0.646441, acc.: 64.84%] [G loss: 0.975959]\n",
      "epoch:3 step:2893 [D loss: 0.703398, acc.: 58.59%] [G loss: 0.935784]\n",
      "epoch:3 step:2894 [D loss: 0.669839, acc.: 60.16%] [G loss: 1.024847]\n",
      "epoch:3 step:2895 [D loss: 0.702762, acc.: 55.47%] [G loss: 1.011591]\n",
      "epoch:3 step:2896 [D loss: 0.641799, acc.: 64.06%] [G loss: 1.250217]\n",
      "epoch:3 step:2897 [D loss: 0.671468, acc.: 58.59%] [G loss: 1.267558]\n",
      "epoch:3 step:2898 [D loss: 0.642734, acc.: 64.84%] [G loss: 1.201907]\n",
      "epoch:3 step:2899 [D loss: 0.699271, acc.: 58.59%] [G loss: 0.969926]\n",
      "epoch:3 step:2900 [D loss: 0.729641, acc.: 54.69%] [G loss: 0.998251]\n",
      "epoch:3 step:2901 [D loss: 0.610922, acc.: 70.31%] [G loss: 1.099206]\n",
      "epoch:3 step:2902 [D loss: 0.597178, acc.: 64.06%] [G loss: 1.058753]\n",
      "epoch:3 step:2903 [D loss: 0.632942, acc.: 65.62%] [G loss: 1.112536]\n",
      "epoch:3 step:2904 [D loss: 0.640831, acc.: 63.28%] [G loss: 0.957792]\n",
      "epoch:3 step:2905 [D loss: 0.543270, acc.: 70.31%] [G loss: 1.011647]\n",
      "epoch:3 step:2906 [D loss: 0.664750, acc.: 57.03%] [G loss: 0.974202]\n",
      "epoch:3 step:2907 [D loss: 0.640861, acc.: 65.62%] [G loss: 1.145562]\n",
      "epoch:3 step:2908 [D loss: 0.684394, acc.: 52.34%] [G loss: 1.050918]\n",
      "epoch:3 step:2909 [D loss: 0.572025, acc.: 71.88%] [G loss: 0.972398]\n",
      "epoch:3 step:2910 [D loss: 0.622896, acc.: 64.84%] [G loss: 1.048983]\n",
      "epoch:3 step:2911 [D loss: 0.670414, acc.: 59.38%] [G loss: 0.972935]\n",
      "epoch:3 step:2912 [D loss: 0.610118, acc.: 67.19%] [G loss: 1.030491]\n",
      "epoch:3 step:2913 [D loss: 0.678855, acc.: 59.38%] [G loss: 1.014678]\n",
      "epoch:3 step:2914 [D loss: 0.617693, acc.: 68.75%] [G loss: 1.028141]\n",
      "epoch:3 step:2915 [D loss: 0.662685, acc.: 57.81%] [G loss: 1.180833]\n",
      "epoch:3 step:2916 [D loss: 0.613437, acc.: 66.41%] [G loss: 1.119296]\n",
      "epoch:3 step:2917 [D loss: 0.706456, acc.: 53.91%] [G loss: 1.046004]\n",
      "epoch:3 step:2918 [D loss: 0.583971, acc.: 72.66%] [G loss: 1.226341]\n",
      "epoch:3 step:2919 [D loss: 0.703450, acc.: 63.28%] [G loss: 1.175011]\n",
      "epoch:3 step:2920 [D loss: 0.574412, acc.: 70.31%] [G loss: 1.007293]\n",
      "epoch:3 step:2921 [D loss: 0.700136, acc.: 54.69%] [G loss: 1.038927]\n",
      "epoch:3 step:2922 [D loss: 0.611145, acc.: 68.75%] [G loss: 1.024365]\n",
      "epoch:3 step:2923 [D loss: 0.643820, acc.: 62.50%] [G loss: 0.971044]\n",
      "epoch:3 step:2924 [D loss: 0.617387, acc.: 70.31%] [G loss: 1.076422]\n",
      "epoch:3 step:2925 [D loss: 0.673200, acc.: 61.72%] [G loss: 1.089134]\n",
      "epoch:3 step:2926 [D loss: 0.638712, acc.: 64.84%] [G loss: 1.080252]\n",
      "epoch:3 step:2927 [D loss: 0.614995, acc.: 67.97%] [G loss: 1.039652]\n",
      "epoch:3 step:2928 [D loss: 0.623124, acc.: 67.19%] [G loss: 0.957514]\n",
      "epoch:3 step:2929 [D loss: 0.573865, acc.: 64.06%] [G loss: 1.079304]\n",
      "epoch:3 step:2930 [D loss: 0.675626, acc.: 59.38%] [G loss: 0.957193]\n",
      "epoch:3 step:2931 [D loss: 0.618446, acc.: 67.97%] [G loss: 1.011201]\n",
      "epoch:3 step:2932 [D loss: 0.567705, acc.: 70.31%] [G loss: 1.053841]\n",
      "epoch:3 step:2933 [D loss: 0.587948, acc.: 65.62%] [G loss: 1.141958]\n",
      "epoch:3 step:2934 [D loss: 0.675648, acc.: 55.47%] [G loss: 1.087131]\n",
      "epoch:3 step:2935 [D loss: 0.674556, acc.: 60.16%] [G loss: 1.073409]\n",
      "epoch:3 step:2936 [D loss: 0.602910, acc.: 66.41%] [G loss: 0.885935]\n",
      "epoch:3 step:2937 [D loss: 0.607815, acc.: 67.97%] [G loss: 1.168743]\n",
      "epoch:3 step:2938 [D loss: 0.617682, acc.: 69.53%] [G loss: 1.152913]\n",
      "epoch:3 step:2939 [D loss: 0.648623, acc.: 62.50%] [G loss: 1.177885]\n",
      "epoch:3 step:2940 [D loss: 0.648281, acc.: 64.06%] [G loss: 0.985639]\n",
      "epoch:3 step:2941 [D loss: 0.605677, acc.: 68.75%] [G loss: 1.061455]\n",
      "epoch:3 step:2942 [D loss: 0.631718, acc.: 63.28%] [G loss: 1.071144]\n",
      "epoch:3 step:2943 [D loss: 0.631620, acc.: 57.81%] [G loss: 1.142900]\n",
      "epoch:3 step:2944 [D loss: 0.682890, acc.: 56.25%] [G loss: 0.925961]\n",
      "epoch:3 step:2945 [D loss: 0.610067, acc.: 64.84%] [G loss: 1.003458]\n",
      "epoch:3 step:2946 [D loss: 0.665314, acc.: 57.03%] [G loss: 1.020365]\n",
      "epoch:3 step:2947 [D loss: 0.653902, acc.: 59.38%] [G loss: 0.974590]\n",
      "epoch:3 step:2948 [D loss: 0.630035, acc.: 67.19%] [G loss: 1.060332]\n",
      "epoch:3 step:2949 [D loss: 0.526605, acc.: 80.47%] [G loss: 1.015810]\n",
      "epoch:3 step:2950 [D loss: 0.585372, acc.: 74.22%] [G loss: 1.143282]\n",
      "epoch:3 step:2951 [D loss: 0.715372, acc.: 62.50%] [G loss: 1.035082]\n",
      "epoch:3 step:2952 [D loss: 0.680539, acc.: 61.72%] [G loss: 1.041634]\n",
      "epoch:3 step:2953 [D loss: 0.665674, acc.: 59.38%] [G loss: 1.021471]\n",
      "epoch:3 step:2954 [D loss: 0.633470, acc.: 60.16%] [G loss: 1.118456]\n",
      "epoch:3 step:2955 [D loss: 0.782498, acc.: 50.00%] [G loss: 0.860862]\n",
      "epoch:3 step:2956 [D loss: 0.668217, acc.: 59.38%] [G loss: 1.062405]\n",
      "epoch:3 step:2957 [D loss: 0.677756, acc.: 60.94%] [G loss: 0.985160]\n",
      "epoch:3 step:2958 [D loss: 0.712392, acc.: 59.38%] [G loss: 1.068110]\n",
      "epoch:3 step:2959 [D loss: 0.640627, acc.: 65.62%] [G loss: 1.021790]\n",
      "epoch:3 step:2960 [D loss: 0.655484, acc.: 59.38%] [G loss: 1.120447]\n",
      "epoch:3 step:2961 [D loss: 0.536415, acc.: 78.91%] [G loss: 1.286053]\n",
      "epoch:3 step:2962 [D loss: 0.674646, acc.: 60.16%] [G loss: 0.972272]\n",
      "epoch:3 step:2963 [D loss: 0.611463, acc.: 65.62%] [G loss: 0.966289]\n",
      "epoch:3 step:2964 [D loss: 0.632425, acc.: 65.62%] [G loss: 1.129902]\n",
      "epoch:3 step:2965 [D loss: 0.715467, acc.: 52.34%] [G loss: 1.046802]\n",
      "epoch:3 step:2966 [D loss: 0.662459, acc.: 64.06%] [G loss: 1.078083]\n",
      "epoch:3 step:2967 [D loss: 0.657240, acc.: 60.16%] [G loss: 0.944856]\n",
      "epoch:3 step:2968 [D loss: 0.653346, acc.: 61.72%] [G loss: 1.130057]\n",
      "epoch:3 step:2969 [D loss: 0.701431, acc.: 57.03%] [G loss: 1.020255]\n",
      "epoch:3 step:2970 [D loss: 0.579391, acc.: 65.62%] [G loss: 0.952744]\n",
      "epoch:3 step:2971 [D loss: 0.655089, acc.: 58.59%] [G loss: 0.987445]\n",
      "epoch:3 step:2972 [D loss: 0.570998, acc.: 67.19%] [G loss: 1.161498]\n",
      "epoch:3 step:2973 [D loss: 0.677017, acc.: 63.28%] [G loss: 1.116422]\n",
      "epoch:3 step:2974 [D loss: 0.736252, acc.: 57.03%] [G loss: 0.996618]\n",
      "epoch:3 step:2975 [D loss: 0.582877, acc.: 66.41%] [G loss: 1.004535]\n",
      "epoch:3 step:2976 [D loss: 0.705868, acc.: 58.59%] [G loss: 0.994579]\n",
      "epoch:3 step:2977 [D loss: 0.634498, acc.: 67.97%] [G loss: 0.980943]\n",
      "epoch:3 step:2978 [D loss: 0.607600, acc.: 67.19%] [G loss: 0.954549]\n",
      "epoch:3 step:2979 [D loss: 0.639391, acc.: 57.81%] [G loss: 1.228952]\n",
      "epoch:3 step:2980 [D loss: 0.645295, acc.: 60.16%] [G loss: 1.142783]\n",
      "epoch:3 step:2981 [D loss: 0.679736, acc.: 56.25%] [G loss: 1.109377]\n",
      "epoch:3 step:2982 [D loss: 0.605458, acc.: 68.75%] [G loss: 1.031991]\n",
      "epoch:3 step:2983 [D loss: 0.523999, acc.: 78.12%] [G loss: 1.011023]\n",
      "epoch:3 step:2984 [D loss: 0.609058, acc.: 70.31%] [G loss: 1.006615]\n",
      "epoch:3 step:2985 [D loss: 0.679818, acc.: 56.25%] [G loss: 1.042281]\n",
      "epoch:3 step:2986 [D loss: 0.700666, acc.: 59.38%] [G loss: 1.065544]\n",
      "epoch:3 step:2987 [D loss: 0.557260, acc.: 72.66%] [G loss: 1.107559]\n",
      "epoch:3 step:2988 [D loss: 0.621424, acc.: 68.75%] [G loss: 1.110962]\n",
      "epoch:3 step:2989 [D loss: 0.653193, acc.: 58.59%] [G loss: 1.055264]\n",
      "epoch:3 step:2990 [D loss: 0.630529, acc.: 65.62%] [G loss: 1.035330]\n",
      "epoch:3 step:2991 [D loss: 0.706854, acc.: 57.03%] [G loss: 0.889862]\n",
      "epoch:3 step:2992 [D loss: 0.738930, acc.: 52.34%] [G loss: 0.971440]\n",
      "epoch:3 step:2993 [D loss: 0.623095, acc.: 64.06%] [G loss: 1.125196]\n",
      "epoch:3 step:2994 [D loss: 0.644109, acc.: 63.28%] [G loss: 1.115016]\n",
      "epoch:3 step:2995 [D loss: 0.650674, acc.: 63.28%] [G loss: 1.103973]\n",
      "epoch:3 step:2996 [D loss: 0.703453, acc.: 51.56%] [G loss: 1.043640]\n",
      "epoch:3 step:2997 [D loss: 0.663019, acc.: 57.81%] [G loss: 1.013529]\n",
      "epoch:3 step:2998 [D loss: 0.612814, acc.: 66.41%] [G loss: 1.078722]\n",
      "epoch:3 step:2999 [D loss: 0.669972, acc.: 63.28%] [G loss: 1.002852]\n",
      "epoch:3 step:3000 [D loss: 0.618845, acc.: 69.53%] [G loss: 1.164706]\n",
      "epoch:3 step:3001 [D loss: 0.551105, acc.: 68.75%] [G loss: 1.124477]\n",
      "epoch:3 step:3002 [D loss: 0.652522, acc.: 58.59%] [G loss: 0.986616]\n",
      "epoch:3 step:3003 [D loss: 0.643877, acc.: 63.28%] [G loss: 1.052253]\n",
      "epoch:3 step:3004 [D loss: 0.638038, acc.: 64.06%] [G loss: 1.101204]\n",
      "epoch:3 step:3005 [D loss: 0.659561, acc.: 58.59%] [G loss: 1.012700]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:3 step:3006 [D loss: 0.634011, acc.: 67.97%] [G loss: 1.040576]\n",
      "epoch:3 step:3007 [D loss: 0.647810, acc.: 62.50%] [G loss: 1.025931]\n",
      "epoch:3 step:3008 [D loss: 0.723195, acc.: 57.81%] [G loss: 1.003945]\n",
      "epoch:3 step:3009 [D loss: 0.691607, acc.: 57.81%] [G loss: 1.134613]\n",
      "epoch:3 step:3010 [D loss: 0.675762, acc.: 54.69%] [G loss: 1.050966]\n",
      "epoch:3 step:3011 [D loss: 0.620908, acc.: 64.06%] [G loss: 1.135352]\n",
      "epoch:3 step:3012 [D loss: 0.606900, acc.: 71.09%] [G loss: 0.998472]\n",
      "epoch:3 step:3013 [D loss: 0.642696, acc.: 62.50%] [G loss: 1.066252]\n",
      "epoch:3 step:3014 [D loss: 0.567419, acc.: 71.88%] [G loss: 1.042182]\n",
      "epoch:3 step:3015 [D loss: 0.637213, acc.: 60.94%] [G loss: 1.076218]\n",
      "epoch:3 step:3016 [D loss: 0.588924, acc.: 69.53%] [G loss: 1.106787]\n",
      "epoch:3 step:3017 [D loss: 0.694886, acc.: 58.59%] [G loss: 1.006703]\n",
      "epoch:3 step:3018 [D loss: 0.707848, acc.: 56.25%] [G loss: 0.934316]\n",
      "epoch:3 step:3019 [D loss: 0.639733, acc.: 64.06%] [G loss: 1.028481]\n",
      "epoch:3 step:3020 [D loss: 0.650298, acc.: 67.19%] [G loss: 0.996189]\n",
      "epoch:3 step:3021 [D loss: 0.629351, acc.: 67.97%] [G loss: 1.082998]\n",
      "epoch:3 step:3022 [D loss: 0.719202, acc.: 54.69%] [G loss: 0.951708]\n",
      "epoch:3 step:3023 [D loss: 0.651680, acc.: 58.59%] [G loss: 1.013988]\n",
      "epoch:3 step:3024 [D loss: 0.568348, acc.: 70.31%] [G loss: 1.150723]\n",
      "epoch:3 step:3025 [D loss: 0.624965, acc.: 69.53%] [G loss: 1.124258]\n",
      "epoch:3 step:3026 [D loss: 0.663932, acc.: 60.94%] [G loss: 1.241622]\n",
      "epoch:3 step:3027 [D loss: 0.585257, acc.: 71.09%] [G loss: 1.134569]\n",
      "epoch:3 step:3028 [D loss: 0.649996, acc.: 60.94%] [G loss: 0.933941]\n",
      "epoch:3 step:3029 [D loss: 0.678592, acc.: 60.16%] [G loss: 1.024715]\n",
      "epoch:3 step:3030 [D loss: 0.683366, acc.: 62.50%] [G loss: 1.022758]\n",
      "epoch:3 step:3031 [D loss: 0.641229, acc.: 60.94%] [G loss: 1.051677]\n",
      "epoch:3 step:3032 [D loss: 0.567273, acc.: 71.88%] [G loss: 1.154978]\n",
      "epoch:3 step:3033 [D loss: 0.695909, acc.: 59.38%] [G loss: 0.916158]\n",
      "epoch:3 step:3034 [D loss: 0.655733, acc.: 61.72%] [G loss: 1.041990]\n",
      "epoch:3 step:3035 [D loss: 0.700689, acc.: 60.94%] [G loss: 1.016878]\n",
      "epoch:3 step:3036 [D loss: 0.622144, acc.: 67.19%] [G loss: 1.176416]\n",
      "epoch:3 step:3037 [D loss: 0.624159, acc.: 67.19%] [G loss: 1.111501]\n",
      "epoch:3 step:3038 [D loss: 0.603337, acc.: 68.75%] [G loss: 1.145717]\n",
      "epoch:3 step:3039 [D loss: 0.643483, acc.: 64.84%] [G loss: 1.110784]\n",
      "epoch:3 step:3040 [D loss: 0.622828, acc.: 62.50%] [G loss: 1.123466]\n",
      "epoch:3 step:3041 [D loss: 0.581690, acc.: 74.22%] [G loss: 1.031765]\n",
      "epoch:3 step:3042 [D loss: 0.694507, acc.: 58.59%] [G loss: 1.120296]\n",
      "epoch:3 step:3043 [D loss: 0.692462, acc.: 57.81%] [G loss: 1.096145]\n",
      "epoch:3 step:3044 [D loss: 0.654034, acc.: 65.62%] [G loss: 1.058184]\n",
      "epoch:3 step:3045 [D loss: 0.765207, acc.: 46.88%] [G loss: 0.903656]\n",
      "epoch:3 step:3046 [D loss: 0.588854, acc.: 69.53%] [G loss: 1.040858]\n",
      "epoch:3 step:3047 [D loss: 0.645760, acc.: 64.84%] [G loss: 1.061301]\n",
      "epoch:3 step:3048 [D loss: 0.674534, acc.: 54.69%] [G loss: 1.018312]\n",
      "epoch:3 step:3049 [D loss: 0.631356, acc.: 65.62%] [G loss: 1.012782]\n",
      "epoch:3 step:3050 [D loss: 0.632418, acc.: 67.97%] [G loss: 1.116936]\n",
      "epoch:3 step:3051 [D loss: 0.625284, acc.: 61.72%] [G loss: 0.986205]\n",
      "epoch:3 step:3052 [D loss: 0.684711, acc.: 57.03%] [G loss: 1.047424]\n",
      "epoch:3 step:3053 [D loss: 0.664356, acc.: 57.81%] [G loss: 1.031195]\n",
      "epoch:3 step:3054 [D loss: 0.652839, acc.: 59.38%] [G loss: 0.905199]\n",
      "epoch:3 step:3055 [D loss: 0.623149, acc.: 65.62%] [G loss: 1.081876]\n",
      "epoch:3 step:3056 [D loss: 0.666955, acc.: 62.50%] [G loss: 0.948363]\n",
      "epoch:3 step:3057 [D loss: 0.649413, acc.: 60.16%] [G loss: 0.858945]\n",
      "epoch:3 step:3058 [D loss: 0.626591, acc.: 65.62%] [G loss: 1.049290]\n",
      "epoch:3 step:3059 [D loss: 0.635851, acc.: 64.06%] [G loss: 0.976966]\n",
      "epoch:3 step:3060 [D loss: 0.623072, acc.: 64.06%] [G loss: 1.076411]\n",
      "epoch:3 step:3061 [D loss: 0.708096, acc.: 58.59%] [G loss: 1.126700]\n",
      "epoch:3 step:3062 [D loss: 0.632977, acc.: 64.06%] [G loss: 1.201257]\n",
      "epoch:3 step:3063 [D loss: 0.600740, acc.: 67.19%] [G loss: 1.119841]\n",
      "epoch:3 step:3064 [D loss: 0.561080, acc.: 69.53%] [G loss: 1.129015]\n",
      "epoch:3 step:3065 [D loss: 0.701296, acc.: 60.94%] [G loss: 0.880484]\n",
      "epoch:3 step:3066 [D loss: 0.579519, acc.: 70.31%] [G loss: 0.995336]\n",
      "epoch:3 step:3067 [D loss: 0.665260, acc.: 61.72%] [G loss: 0.940192]\n",
      "epoch:3 step:3068 [D loss: 0.624388, acc.: 64.06%] [G loss: 1.042454]\n",
      "epoch:3 step:3069 [D loss: 0.712302, acc.: 54.69%] [G loss: 0.910798]\n",
      "epoch:3 step:3070 [D loss: 0.649217, acc.: 59.38%] [G loss: 1.113455]\n",
      "epoch:3 step:3071 [D loss: 0.725140, acc.: 51.56%] [G loss: 1.061846]\n",
      "epoch:3 step:3072 [D loss: 0.711610, acc.: 54.69%] [G loss: 1.175153]\n",
      "epoch:3 step:3073 [D loss: 0.656257, acc.: 62.50%] [G loss: 1.144030]\n",
      "epoch:3 step:3074 [D loss: 0.718146, acc.: 55.47%] [G loss: 1.217902]\n",
      "epoch:3 step:3075 [D loss: 0.609215, acc.: 65.62%] [G loss: 1.193152]\n",
      "epoch:3 step:3076 [D loss: 0.672443, acc.: 58.59%] [G loss: 0.954952]\n",
      "epoch:3 step:3077 [D loss: 0.602684, acc.: 64.06%] [G loss: 0.921884]\n",
      "epoch:3 step:3078 [D loss: 0.674160, acc.: 60.94%] [G loss: 0.986483]\n",
      "epoch:3 step:3079 [D loss: 0.574341, acc.: 72.66%] [G loss: 1.126428]\n",
      "epoch:3 step:3080 [D loss: 0.609393, acc.: 69.53%] [G loss: 1.009930]\n",
      "epoch:3 step:3081 [D loss: 0.539985, acc.: 72.66%] [G loss: 1.328600]\n",
      "epoch:3 step:3082 [D loss: 0.610119, acc.: 67.97%] [G loss: 1.241408]\n",
      "epoch:3 step:3083 [D loss: 0.600538, acc.: 65.62%] [G loss: 0.886611]\n",
      "epoch:3 step:3084 [D loss: 0.666382, acc.: 60.16%] [G loss: 1.023671]\n",
      "epoch:3 step:3085 [D loss: 0.722318, acc.: 54.69%] [G loss: 0.925859]\n",
      "epoch:3 step:3086 [D loss: 0.704950, acc.: 56.25%] [G loss: 1.018450]\n",
      "epoch:3 step:3087 [D loss: 0.763417, acc.: 46.09%] [G loss: 1.012424]\n",
      "epoch:3 step:3088 [D loss: 0.636497, acc.: 60.94%] [G loss: 0.981929]\n",
      "epoch:3 step:3089 [D loss: 0.594039, acc.: 69.53%] [G loss: 1.100095]\n",
      "epoch:3 step:3090 [D loss: 0.611676, acc.: 67.97%] [G loss: 1.160371]\n",
      "epoch:3 step:3091 [D loss: 0.740470, acc.: 53.91%] [G loss: 1.008390]\n",
      "epoch:3 step:3092 [D loss: 0.648942, acc.: 62.50%] [G loss: 1.041435]\n",
      "epoch:3 step:3093 [D loss: 0.708506, acc.: 57.81%] [G loss: 1.295714]\n",
      "epoch:3 step:3094 [D loss: 0.667885, acc.: 60.94%] [G loss: 1.157631]\n",
      "epoch:3 step:3095 [D loss: 0.608890, acc.: 68.75%] [G loss: 1.081929]\n",
      "epoch:3 step:3096 [D loss: 0.664834, acc.: 58.59%] [G loss: 1.025987]\n",
      "epoch:3 step:3097 [D loss: 0.700573, acc.: 57.81%] [G loss: 0.949624]\n",
      "epoch:3 step:3098 [D loss: 0.656422, acc.: 65.62%] [G loss: 1.126697]\n",
      "epoch:3 step:3099 [D loss: 0.570927, acc.: 73.44%] [G loss: 1.152272]\n",
      "epoch:3 step:3100 [D loss: 0.632044, acc.: 63.28%] [G loss: 1.078005]\n",
      "epoch:3 step:3101 [D loss: 0.697231, acc.: 55.47%] [G loss: 1.009590]\n",
      "epoch:3 step:3102 [D loss: 0.674653, acc.: 66.41%] [G loss: 1.118002]\n",
      "epoch:3 step:3103 [D loss: 0.726378, acc.: 53.91%] [G loss: 1.089835]\n",
      "epoch:3 step:3104 [D loss: 0.643221, acc.: 65.62%] [G loss: 1.015422]\n",
      "epoch:3 step:3105 [D loss: 0.671015, acc.: 59.38%] [G loss: 1.002829]\n",
      "epoch:3 step:3106 [D loss: 0.636160, acc.: 66.41%] [G loss: 1.057827]\n",
      "epoch:3 step:3107 [D loss: 0.549058, acc.: 73.44%] [G loss: 1.138736]\n",
      "epoch:3 step:3108 [D loss: 0.658808, acc.: 63.28%] [G loss: 0.974741]\n",
      "epoch:3 step:3109 [D loss: 0.692063, acc.: 54.69%] [G loss: 0.949795]\n",
      "epoch:3 step:3110 [D loss: 0.618119, acc.: 65.62%] [G loss: 0.989360]\n",
      "epoch:3 step:3111 [D loss: 0.634074, acc.: 68.75%] [G loss: 0.986336]\n",
      "epoch:3 step:3112 [D loss: 0.663522, acc.: 55.47%] [G loss: 1.025071]\n",
      "epoch:3 step:3113 [D loss: 0.692393, acc.: 57.81%] [G loss: 1.092613]\n",
      "epoch:3 step:3114 [D loss: 0.583588, acc.: 67.97%] [G loss: 1.187863]\n",
      "epoch:3 step:3115 [D loss: 0.589677, acc.: 67.97%] [G loss: 1.103470]\n",
      "epoch:3 step:3116 [D loss: 0.631175, acc.: 64.84%] [G loss: 1.116454]\n",
      "epoch:3 step:3117 [D loss: 0.703699, acc.: 52.34%] [G loss: 1.066068]\n",
      "epoch:3 step:3118 [D loss: 0.663070, acc.: 59.38%] [G loss: 1.142341]\n",
      "epoch:3 step:3119 [D loss: 0.615168, acc.: 67.97%] [G loss: 1.139274]\n",
      "epoch:3 step:3120 [D loss: 0.669792, acc.: 59.38%] [G loss: 0.980767]\n",
      "epoch:3 step:3121 [D loss: 0.782408, acc.: 47.66%] [G loss: 0.995430]\n",
      "epoch:3 step:3122 [D loss: 0.583017, acc.: 72.66%] [G loss: 1.080001]\n",
      "epoch:3 step:3123 [D loss: 0.625317, acc.: 64.06%] [G loss: 0.912104]\n",
      "epoch:3 step:3124 [D loss: 0.590906, acc.: 70.31%] [G loss: 1.031090]\n",
      "epoch:3 step:3125 [D loss: 0.570689, acc.: 75.00%] [G loss: 1.002573]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:3 step:3126 [D loss: 0.573837, acc.: 67.19%] [G loss: 1.139728]\n",
      "epoch:3 step:3127 [D loss: 0.758125, acc.: 53.91%] [G loss: 1.037021]\n",
      "epoch:3 step:3128 [D loss: 0.609780, acc.: 64.84%] [G loss: 1.006347]\n",
      "epoch:3 step:3129 [D loss: 0.682873, acc.: 59.38%] [G loss: 1.027100]\n",
      "epoch:3 step:3130 [D loss: 0.669989, acc.: 57.03%] [G loss: 0.959835]\n",
      "epoch:3 step:3131 [D loss: 0.664824, acc.: 56.25%] [G loss: 1.080619]\n",
      "epoch:3 step:3132 [D loss: 0.700839, acc.: 61.72%] [G loss: 1.080953]\n",
      "epoch:3 step:3133 [D loss: 0.699510, acc.: 58.59%] [G loss: 1.106730]\n",
      "epoch:3 step:3134 [D loss: 0.679959, acc.: 59.38%] [G loss: 1.081320]\n",
      "epoch:3 step:3135 [D loss: 0.638448, acc.: 65.62%] [G loss: 1.033593]\n",
      "epoch:3 step:3136 [D loss: 0.553334, acc.: 72.66%] [G loss: 1.089618]\n",
      "epoch:3 step:3137 [D loss: 0.619705, acc.: 66.41%] [G loss: 1.048486]\n",
      "epoch:3 step:3138 [D loss: 0.667882, acc.: 60.94%] [G loss: 1.078352]\n",
      "epoch:3 step:3139 [D loss: 0.567889, acc.: 74.22%] [G loss: 1.041875]\n",
      "epoch:3 step:3140 [D loss: 0.681127, acc.: 63.28%] [G loss: 0.951254]\n",
      "epoch:3 step:3141 [D loss: 0.687165, acc.: 60.94%] [G loss: 0.923304]\n",
      "epoch:3 step:3142 [D loss: 0.576422, acc.: 74.22%] [G loss: 1.122937]\n",
      "epoch:3 step:3143 [D loss: 0.597807, acc.: 69.53%] [G loss: 1.144028]\n",
      "epoch:3 step:3144 [D loss: 0.738971, acc.: 50.00%] [G loss: 0.981401]\n",
      "epoch:3 step:3145 [D loss: 0.695684, acc.: 57.03%] [G loss: 1.003359]\n",
      "epoch:3 step:3146 [D loss: 0.657949, acc.: 60.94%] [G loss: 1.048742]\n",
      "epoch:3 step:3147 [D loss: 0.605723, acc.: 69.53%] [G loss: 1.025685]\n",
      "epoch:3 step:3148 [D loss: 0.624027, acc.: 65.62%] [G loss: 0.995865]\n",
      "epoch:3 step:3149 [D loss: 0.579551, acc.: 72.66%] [G loss: 0.983663]\n",
      "epoch:3 step:3150 [D loss: 0.651446, acc.: 58.59%] [G loss: 0.957350]\n",
      "epoch:3 step:3151 [D loss: 0.579575, acc.: 71.09%] [G loss: 0.964681]\n",
      "epoch:3 step:3152 [D loss: 0.699486, acc.: 53.91%] [G loss: 1.053085]\n",
      "epoch:3 step:3153 [D loss: 0.649756, acc.: 62.50%] [G loss: 1.033007]\n",
      "epoch:3 step:3154 [D loss: 0.658149, acc.: 60.94%] [G loss: 1.038588]\n",
      "epoch:3 step:3155 [D loss: 0.657600, acc.: 64.06%] [G loss: 0.995352]\n",
      "epoch:3 step:3156 [D loss: 0.632855, acc.: 66.41%] [G loss: 1.086914]\n",
      "epoch:3 step:3157 [D loss: 0.728336, acc.: 54.69%] [G loss: 1.003397]\n",
      "epoch:3 step:3158 [D loss: 0.629582, acc.: 67.19%] [G loss: 1.165316]\n",
      "epoch:3 step:3159 [D loss: 0.745629, acc.: 50.00%] [G loss: 1.000378]\n",
      "epoch:3 step:3160 [D loss: 0.652080, acc.: 61.72%] [G loss: 1.039963]\n",
      "epoch:3 step:3161 [D loss: 0.721307, acc.: 55.47%] [G loss: 1.019996]\n",
      "epoch:3 step:3162 [D loss: 0.615670, acc.: 59.38%] [G loss: 1.008790]\n",
      "epoch:3 step:3163 [D loss: 0.711127, acc.: 59.38%] [G loss: 1.002286]\n",
      "epoch:3 step:3164 [D loss: 0.648804, acc.: 63.28%] [G loss: 1.012010]\n",
      "epoch:3 step:3165 [D loss: 0.673020, acc.: 57.81%] [G loss: 1.134037]\n",
      "epoch:3 step:3166 [D loss: 0.646077, acc.: 64.84%] [G loss: 1.135341]\n",
      "epoch:3 step:3167 [D loss: 0.666028, acc.: 63.28%] [G loss: 0.986660]\n",
      "epoch:3 step:3168 [D loss: 0.704423, acc.: 53.91%] [G loss: 0.979473]\n",
      "epoch:3 step:3169 [D loss: 0.580835, acc.: 70.31%] [G loss: 1.173385]\n",
      "epoch:3 step:3170 [D loss: 0.710904, acc.: 57.81%] [G loss: 0.978984]\n",
      "epoch:3 step:3171 [D loss: 0.589961, acc.: 71.09%] [G loss: 0.984004]\n",
      "epoch:3 step:3172 [D loss: 0.714123, acc.: 56.25%] [G loss: 1.065288]\n",
      "epoch:3 step:3173 [D loss: 0.595791, acc.: 69.53%] [G loss: 1.233941]\n",
      "epoch:3 step:3174 [D loss: 0.602994, acc.: 73.44%] [G loss: 1.242404]\n",
      "epoch:3 step:3175 [D loss: 0.549927, acc.: 75.78%] [G loss: 1.208664]\n",
      "epoch:3 step:3176 [D loss: 0.619909, acc.: 64.84%] [G loss: 1.014678]\n",
      "epoch:3 step:3177 [D loss: 0.549780, acc.: 71.09%] [G loss: 1.105076]\n",
      "epoch:3 step:3178 [D loss: 0.620516, acc.: 64.84%] [G loss: 1.244354]\n",
      "epoch:3 step:3179 [D loss: 0.573369, acc.: 71.88%] [G loss: 1.173580]\n",
      "epoch:3 step:3180 [D loss: 0.783670, acc.: 50.78%] [G loss: 0.951818]\n",
      "epoch:3 step:3181 [D loss: 0.586703, acc.: 67.19%] [G loss: 1.110105]\n",
      "epoch:3 step:3182 [D loss: 0.633008, acc.: 60.16%] [G loss: 1.115230]\n",
      "epoch:3 step:3183 [D loss: 0.720146, acc.: 59.38%] [G loss: 0.982710]\n",
      "epoch:3 step:3184 [D loss: 0.686139, acc.: 53.12%] [G loss: 1.184333]\n",
      "epoch:3 step:3185 [D loss: 0.689458, acc.: 57.81%] [G loss: 1.267720]\n",
      "epoch:3 step:3186 [D loss: 0.718481, acc.: 57.81%] [G loss: 1.112351]\n",
      "epoch:3 step:3187 [D loss: 0.653266, acc.: 62.50%] [G loss: 1.075248]\n",
      "epoch:3 step:3188 [D loss: 0.612386, acc.: 69.53%] [G loss: 0.955997]\n",
      "epoch:3 step:3189 [D loss: 0.710600, acc.: 53.12%] [G loss: 1.004929]\n",
      "epoch:3 step:3190 [D loss: 0.730722, acc.: 54.69%] [G loss: 1.099472]\n",
      "epoch:3 step:3191 [D loss: 0.618343, acc.: 67.97%] [G loss: 1.068671]\n",
      "epoch:3 step:3192 [D loss: 0.764166, acc.: 53.12%] [G loss: 1.135154]\n",
      "epoch:3 step:3193 [D loss: 0.641499, acc.: 62.50%] [G loss: 1.004029]\n",
      "epoch:3 step:3194 [D loss: 0.665271, acc.: 57.81%] [G loss: 1.064701]\n",
      "epoch:3 step:3195 [D loss: 0.793030, acc.: 47.66%] [G loss: 0.996275]\n",
      "epoch:3 step:3196 [D loss: 0.728933, acc.: 50.78%] [G loss: 0.997473]\n",
      "epoch:3 step:3197 [D loss: 0.693460, acc.: 58.59%] [G loss: 1.119855]\n",
      "epoch:3 step:3198 [D loss: 0.566913, acc.: 70.31%] [G loss: 1.220219]\n",
      "epoch:3 step:3199 [D loss: 0.619493, acc.: 64.06%] [G loss: 1.132956]\n",
      "epoch:3 step:3200 [D loss: 0.653078, acc.: 58.59%] [G loss: 1.053772]\n",
      "epoch:3 step:3201 [D loss: 0.590242, acc.: 71.88%] [G loss: 1.132036]\n",
      "epoch:3 step:3202 [D loss: 0.625616, acc.: 65.62%] [G loss: 1.126729]\n",
      "epoch:3 step:3203 [D loss: 0.579711, acc.: 73.44%] [G loss: 1.037793]\n",
      "epoch:3 step:3204 [D loss: 0.550259, acc.: 69.53%] [G loss: 1.169965]\n",
      "epoch:3 step:3205 [D loss: 0.570320, acc.: 69.53%] [G loss: 1.133585]\n",
      "epoch:3 step:3206 [D loss: 0.535094, acc.: 75.78%] [G loss: 1.122819]\n",
      "epoch:3 step:3207 [D loss: 0.581941, acc.: 73.44%] [G loss: 1.098276]\n",
      "epoch:3 step:3208 [D loss: 0.724636, acc.: 47.66%] [G loss: 1.026055]\n",
      "epoch:3 step:3209 [D loss: 0.604250, acc.: 69.53%] [G loss: 1.045084]\n",
      "epoch:3 step:3210 [D loss: 0.574246, acc.: 73.44%] [G loss: 1.165067]\n",
      "epoch:3 step:3211 [D loss: 0.605283, acc.: 67.97%] [G loss: 1.218908]\n",
      "epoch:3 step:3212 [D loss: 0.674354, acc.: 64.06%] [G loss: 0.983236]\n",
      "epoch:3 step:3213 [D loss: 0.543065, acc.: 76.56%] [G loss: 1.075112]\n",
      "epoch:3 step:3214 [D loss: 0.667759, acc.: 64.84%] [G loss: 1.039756]\n",
      "epoch:3 step:3215 [D loss: 0.618619, acc.: 65.62%] [G loss: 1.102993]\n",
      "epoch:3 step:3216 [D loss: 0.668834, acc.: 57.81%] [G loss: 1.117880]\n",
      "epoch:3 step:3217 [D loss: 0.589365, acc.: 71.09%] [G loss: 1.129643]\n",
      "epoch:3 step:3218 [D loss: 0.742969, acc.: 49.22%] [G loss: 1.106308]\n",
      "epoch:3 step:3219 [D loss: 0.673450, acc.: 57.03%] [G loss: 0.904154]\n",
      "epoch:3 step:3220 [D loss: 0.664020, acc.: 60.94%] [G loss: 1.110602]\n",
      "epoch:3 step:3221 [D loss: 0.674130, acc.: 57.81%] [G loss: 1.100890]\n",
      "epoch:3 step:3222 [D loss: 0.630502, acc.: 62.50%] [G loss: 1.134177]\n",
      "epoch:3 step:3223 [D loss: 0.655159, acc.: 62.50%] [G loss: 1.021422]\n",
      "epoch:3 step:3224 [D loss: 0.724784, acc.: 55.47%] [G loss: 1.075514]\n",
      "epoch:3 step:3225 [D loss: 0.662331, acc.: 53.91%] [G loss: 1.002391]\n",
      "epoch:3 step:3226 [D loss: 0.600541, acc.: 68.75%] [G loss: 1.092009]\n",
      "epoch:3 step:3227 [D loss: 0.629720, acc.: 64.06%] [G loss: 0.980323]\n",
      "epoch:3 step:3228 [D loss: 0.581225, acc.: 67.19%] [G loss: 1.079024]\n",
      "epoch:3 step:3229 [D loss: 0.631103, acc.: 59.38%] [G loss: 1.144202]\n",
      "epoch:3 step:3230 [D loss: 0.642168, acc.: 62.50%] [G loss: 1.058696]\n",
      "epoch:3 step:3231 [D loss: 0.708636, acc.: 57.81%] [G loss: 0.965557]\n",
      "epoch:3 step:3232 [D loss: 0.597457, acc.: 69.53%] [G loss: 1.226825]\n",
      "epoch:3 step:3233 [D loss: 0.604868, acc.: 64.84%] [G loss: 1.053221]\n",
      "epoch:3 step:3234 [D loss: 0.571021, acc.: 67.97%] [G loss: 1.074103]\n",
      "epoch:3 step:3235 [D loss: 0.592436, acc.: 69.53%] [G loss: 1.227815]\n",
      "epoch:3 step:3236 [D loss: 0.671207, acc.: 57.03%] [G loss: 1.072386]\n",
      "epoch:3 step:3237 [D loss: 0.630895, acc.: 58.59%] [G loss: 1.209660]\n",
      "epoch:3 step:3238 [D loss: 0.741232, acc.: 47.66%] [G loss: 1.095334]\n",
      "epoch:3 step:3239 [D loss: 0.682900, acc.: 58.59%] [G loss: 0.956485]\n",
      "epoch:3 step:3240 [D loss: 0.671040, acc.: 56.25%] [G loss: 1.017011]\n",
      "epoch:3 step:3241 [D loss: 0.659631, acc.: 62.50%] [G loss: 1.008165]\n",
      "epoch:3 step:3242 [D loss: 0.756768, acc.: 48.44%] [G loss: 0.984218]\n",
      "epoch:3 step:3243 [D loss: 0.697527, acc.: 55.47%] [G loss: 1.004714]\n",
      "epoch:3 step:3244 [D loss: 0.679476, acc.: 60.16%] [G loss: 0.982605]\n",
      "epoch:3 step:3245 [D loss: 0.674347, acc.: 57.81%] [G loss: 1.021836]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:3 step:3246 [D loss: 0.604348, acc.: 66.41%] [G loss: 1.034406]\n",
      "epoch:3 step:3247 [D loss: 0.665890, acc.: 59.38%] [G loss: 1.059387]\n",
      "epoch:3 step:3248 [D loss: 0.746147, acc.: 48.44%] [G loss: 1.039236]\n",
      "epoch:3 step:3249 [D loss: 0.635916, acc.: 65.62%] [G loss: 0.999986]\n",
      "epoch:3 step:3250 [D loss: 0.586183, acc.: 70.31%] [G loss: 0.945578]\n",
      "epoch:3 step:3251 [D loss: 0.656835, acc.: 60.16%] [G loss: 1.047956]\n",
      "epoch:3 step:3252 [D loss: 0.659055, acc.: 63.28%] [G loss: 1.201038]\n",
      "epoch:3 step:3253 [D loss: 0.634334, acc.: 64.84%] [G loss: 1.050489]\n",
      "epoch:3 step:3254 [D loss: 0.656504, acc.: 61.72%] [G loss: 1.110389]\n",
      "epoch:3 step:3255 [D loss: 0.658266, acc.: 64.84%] [G loss: 1.042233]\n",
      "epoch:3 step:3256 [D loss: 0.569069, acc.: 74.22%] [G loss: 1.105955]\n",
      "epoch:3 step:3257 [D loss: 0.672225, acc.: 60.16%] [G loss: 1.042994]\n",
      "epoch:3 step:3258 [D loss: 0.577056, acc.: 70.31%] [G loss: 1.231245]\n",
      "epoch:3 step:3259 [D loss: 0.700888, acc.: 53.91%] [G loss: 0.949817]\n",
      "epoch:3 step:3260 [D loss: 0.542274, acc.: 77.34%] [G loss: 1.034622]\n",
      "epoch:3 step:3261 [D loss: 0.666999, acc.: 66.41%] [G loss: 1.010143]\n",
      "epoch:3 step:3262 [D loss: 0.642466, acc.: 61.72%] [G loss: 1.051595]\n",
      "epoch:3 step:3263 [D loss: 0.637574, acc.: 62.50%] [G loss: 1.057291]\n",
      "epoch:3 step:3264 [D loss: 0.548193, acc.: 74.22%] [G loss: 1.197115]\n",
      "epoch:3 step:3265 [D loss: 0.659225, acc.: 59.38%] [G loss: 1.031495]\n",
      "epoch:3 step:3266 [D loss: 0.642030, acc.: 65.62%] [G loss: 1.041603]\n",
      "epoch:3 step:3267 [D loss: 0.650451, acc.: 60.94%] [G loss: 1.016334]\n",
      "epoch:3 step:3268 [D loss: 0.646674, acc.: 59.38%] [G loss: 1.014773]\n",
      "epoch:3 step:3269 [D loss: 0.568999, acc.: 70.31%] [G loss: 1.121344]\n",
      "epoch:3 step:3270 [D loss: 0.569046, acc.: 72.66%] [G loss: 1.173097]\n",
      "epoch:3 step:3271 [D loss: 0.622164, acc.: 67.19%] [G loss: 1.099289]\n",
      "epoch:3 step:3272 [D loss: 0.691634, acc.: 59.38%] [G loss: 0.896630]\n",
      "epoch:3 step:3273 [D loss: 0.647605, acc.: 60.16%] [G loss: 0.984985]\n",
      "epoch:3 step:3274 [D loss: 0.619640, acc.: 63.28%] [G loss: 1.028983]\n",
      "epoch:3 step:3275 [D loss: 0.629421, acc.: 64.06%] [G loss: 1.107984]\n",
      "epoch:3 step:3276 [D loss: 0.588905, acc.: 69.53%] [G loss: 0.997712]\n",
      "epoch:3 step:3277 [D loss: 0.650511, acc.: 62.50%] [G loss: 1.056882]\n",
      "epoch:3 step:3278 [D loss: 0.602956, acc.: 60.94%] [G loss: 1.117283]\n",
      "epoch:3 step:3279 [D loss: 0.643786, acc.: 65.62%] [G loss: 1.128620]\n",
      "epoch:3 step:3280 [D loss: 0.606554, acc.: 71.09%] [G loss: 0.976387]\n",
      "epoch:3 step:3281 [D loss: 0.726285, acc.: 53.12%] [G loss: 1.029075]\n",
      "epoch:3 step:3282 [D loss: 0.630471, acc.: 62.50%] [G loss: 0.988091]\n",
      "epoch:3 step:3283 [D loss: 0.578033, acc.: 72.66%] [G loss: 1.173649]\n",
      "epoch:3 step:3284 [D loss: 0.701049, acc.: 54.69%] [G loss: 1.136697]\n",
      "epoch:3 step:3285 [D loss: 0.563570, acc.: 75.00%] [G loss: 1.059390]\n",
      "epoch:3 step:3286 [D loss: 0.598057, acc.: 64.84%] [G loss: 1.160788]\n",
      "epoch:3 step:3287 [D loss: 0.648444, acc.: 56.25%] [G loss: 1.012603]\n",
      "epoch:3 step:3288 [D loss: 0.640417, acc.: 64.06%] [G loss: 1.028960]\n",
      "epoch:3 step:3289 [D loss: 0.707084, acc.: 57.81%] [G loss: 1.110038]\n",
      "epoch:3 step:3290 [D loss: 0.702292, acc.: 54.69%] [G loss: 1.042272]\n",
      "epoch:3 step:3291 [D loss: 0.590786, acc.: 64.84%] [G loss: 1.053382]\n",
      "epoch:3 step:3292 [D loss: 0.753976, acc.: 50.00%] [G loss: 0.923736]\n",
      "epoch:3 step:3293 [D loss: 0.679577, acc.: 56.25%] [G loss: 1.129962]\n",
      "epoch:3 step:3294 [D loss: 0.649298, acc.: 57.81%] [G loss: 1.117383]\n",
      "epoch:3 step:3295 [D loss: 0.592922, acc.: 69.53%] [G loss: 0.992473]\n",
      "epoch:3 step:3296 [D loss: 0.667424, acc.: 64.84%] [G loss: 1.017979]\n",
      "epoch:3 step:3297 [D loss: 0.671002, acc.: 60.16%] [G loss: 1.187904]\n",
      "epoch:3 step:3298 [D loss: 0.664914, acc.: 60.94%] [G loss: 1.020146]\n",
      "epoch:3 step:3299 [D loss: 0.656091, acc.: 61.72%] [G loss: 1.083334]\n",
      "epoch:3 step:3300 [D loss: 0.703691, acc.: 54.69%] [G loss: 0.963534]\n",
      "epoch:3 step:3301 [D loss: 0.599741, acc.: 70.31%] [G loss: 1.083649]\n",
      "epoch:3 step:3302 [D loss: 0.575646, acc.: 69.53%] [G loss: 1.109076]\n",
      "epoch:3 step:3303 [D loss: 0.713693, acc.: 52.34%] [G loss: 1.032905]\n",
      "epoch:3 step:3304 [D loss: 0.636858, acc.: 63.28%] [G loss: 1.139068]\n",
      "epoch:3 step:3305 [D loss: 0.612042, acc.: 58.59%] [G loss: 1.049959]\n",
      "epoch:3 step:3306 [D loss: 0.711253, acc.: 60.16%] [G loss: 1.038217]\n",
      "epoch:3 step:3307 [D loss: 0.675324, acc.: 58.59%] [G loss: 1.020452]\n",
      "epoch:3 step:3308 [D loss: 0.692058, acc.: 61.72%] [G loss: 1.012196]\n",
      "epoch:3 step:3309 [D loss: 0.625939, acc.: 66.41%] [G loss: 1.052348]\n",
      "epoch:3 step:3310 [D loss: 0.629211, acc.: 68.75%] [G loss: 1.073361]\n",
      "epoch:3 step:3311 [D loss: 0.656514, acc.: 66.41%] [G loss: 1.097474]\n",
      "epoch:3 step:3312 [D loss: 0.581032, acc.: 71.88%] [G loss: 1.070320]\n",
      "epoch:3 step:3313 [D loss: 0.561925, acc.: 73.44%] [G loss: 1.078453]\n",
      "epoch:3 step:3314 [D loss: 0.597613, acc.: 69.53%] [G loss: 1.167939]\n",
      "epoch:3 step:3315 [D loss: 0.634784, acc.: 64.06%] [G loss: 0.994308]\n",
      "epoch:3 step:3316 [D loss: 0.734814, acc.: 55.47%] [G loss: 1.152259]\n",
      "epoch:3 step:3317 [D loss: 0.637280, acc.: 64.84%] [G loss: 1.076785]\n",
      "epoch:3 step:3318 [D loss: 0.709200, acc.: 56.25%] [G loss: 1.114966]\n",
      "epoch:3 step:3319 [D loss: 0.742590, acc.: 50.78%] [G loss: 1.036578]\n",
      "epoch:3 step:3320 [D loss: 0.660904, acc.: 62.50%] [G loss: 1.028156]\n",
      "epoch:3 step:3321 [D loss: 0.676376, acc.: 60.94%] [G loss: 1.068787]\n",
      "epoch:3 step:3322 [D loss: 0.758896, acc.: 48.44%] [G loss: 1.104805]\n",
      "epoch:3 step:3323 [D loss: 0.546047, acc.: 74.22%] [G loss: 1.227932]\n",
      "epoch:3 step:3324 [D loss: 0.696899, acc.: 56.25%] [G loss: 1.042548]\n",
      "epoch:3 step:3325 [D loss: 0.647435, acc.: 60.94%] [G loss: 1.134630]\n",
      "epoch:3 step:3326 [D loss: 0.588573, acc.: 70.31%] [G loss: 0.977558]\n",
      "epoch:3 step:3327 [D loss: 0.670665, acc.: 57.03%] [G loss: 0.992306]\n",
      "epoch:3 step:3328 [D loss: 0.652885, acc.: 63.28%] [G loss: 1.002637]\n",
      "epoch:3 step:3329 [D loss: 0.653060, acc.: 61.72%] [G loss: 1.031071]\n",
      "epoch:3 step:3330 [D loss: 0.599775, acc.: 69.53%] [G loss: 1.027588]\n",
      "epoch:3 step:3331 [D loss: 0.613680, acc.: 62.50%] [G loss: 1.092490]\n",
      "epoch:3 step:3332 [D loss: 0.779954, acc.: 51.56%] [G loss: 1.156193]\n",
      "epoch:3 step:3333 [D loss: 0.649179, acc.: 64.06%] [G loss: 1.046735]\n",
      "epoch:3 step:3334 [D loss: 0.611425, acc.: 62.50%] [G loss: 1.091796]\n",
      "epoch:3 step:3335 [D loss: 0.615715, acc.: 71.88%] [G loss: 1.062258]\n",
      "epoch:3 step:3336 [D loss: 0.672266, acc.: 60.16%] [G loss: 1.066571]\n",
      "epoch:3 step:3337 [D loss: 0.614462, acc.: 71.09%] [G loss: 1.014924]\n",
      "epoch:3 step:3338 [D loss: 0.631409, acc.: 60.16%] [G loss: 0.994807]\n",
      "epoch:3 step:3339 [D loss: 0.654013, acc.: 64.84%] [G loss: 0.886774]\n",
      "epoch:3 step:3340 [D loss: 0.648625, acc.: 60.94%] [G loss: 1.171216]\n",
      "epoch:3 step:3341 [D loss: 0.689621, acc.: 57.03%] [G loss: 1.050757]\n",
      "epoch:3 step:3342 [D loss: 0.643977, acc.: 64.84%] [G loss: 1.003386]\n",
      "epoch:3 step:3343 [D loss: 0.655410, acc.: 60.94%] [G loss: 1.153317]\n",
      "epoch:3 step:3344 [D loss: 0.677836, acc.: 55.47%] [G loss: 1.137058]\n",
      "epoch:3 step:3345 [D loss: 0.657818, acc.: 60.16%] [G loss: 1.187148]\n",
      "epoch:3 step:3346 [D loss: 0.652805, acc.: 61.72%] [G loss: 1.025045]\n",
      "epoch:3 step:3347 [D loss: 0.602487, acc.: 64.84%] [G loss: 1.131750]\n",
      "epoch:3 step:3348 [D loss: 0.687433, acc.: 58.59%] [G loss: 1.032346]\n",
      "epoch:3 step:3349 [D loss: 0.621653, acc.: 64.06%] [G loss: 0.929649]\n",
      "epoch:3 step:3350 [D loss: 0.582056, acc.: 72.66%] [G loss: 1.011523]\n",
      "epoch:3 step:3351 [D loss: 0.641264, acc.: 64.06%] [G loss: 0.984372]\n",
      "epoch:3 step:3352 [D loss: 0.655535, acc.: 64.84%] [G loss: 1.080838]\n",
      "epoch:3 step:3353 [D loss: 0.589762, acc.: 71.88%] [G loss: 1.112391]\n",
      "epoch:3 step:3354 [D loss: 0.639566, acc.: 60.94%] [G loss: 1.098012]\n",
      "epoch:3 step:3355 [D loss: 0.670797, acc.: 57.03%] [G loss: 0.949709]\n",
      "epoch:3 step:3356 [D loss: 0.602585, acc.: 65.62%] [G loss: 1.020738]\n",
      "epoch:3 step:3357 [D loss: 0.657421, acc.: 63.28%] [G loss: 1.013087]\n",
      "epoch:3 step:3358 [D loss: 0.659809, acc.: 57.03%] [G loss: 0.874329]\n",
      "epoch:3 step:3359 [D loss: 0.715281, acc.: 50.78%] [G loss: 1.097750]\n",
      "epoch:3 step:3360 [D loss: 0.654475, acc.: 67.19%] [G loss: 1.153878]\n",
      "epoch:3 step:3361 [D loss: 0.571884, acc.: 73.44%] [G loss: 1.262242]\n",
      "epoch:3 step:3362 [D loss: 0.676250, acc.: 57.03%] [G loss: 1.080176]\n",
      "epoch:3 step:3363 [D loss: 0.733151, acc.: 53.91%] [G loss: 1.127356]\n",
      "epoch:3 step:3364 [D loss: 0.697863, acc.: 57.03%] [G loss: 1.163873]\n",
      "epoch:3 step:3365 [D loss: 0.656367, acc.: 61.72%] [G loss: 1.033293]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:3 step:3366 [D loss: 0.659261, acc.: 61.72%] [G loss: 1.182581]\n",
      "epoch:3 step:3367 [D loss: 0.756178, acc.: 46.88%] [G loss: 0.965204]\n",
      "epoch:3 step:3368 [D loss: 0.616281, acc.: 64.84%] [G loss: 1.052204]\n",
      "epoch:3 step:3369 [D loss: 0.633926, acc.: 62.50%] [G loss: 1.134558]\n",
      "epoch:3 step:3370 [D loss: 0.607075, acc.: 64.84%] [G loss: 1.103055]\n",
      "epoch:3 step:3371 [D loss: 0.602070, acc.: 67.19%] [G loss: 1.037980]\n",
      "epoch:3 step:3372 [D loss: 0.623741, acc.: 68.75%] [G loss: 1.094845]\n",
      "epoch:3 step:3373 [D loss: 0.643059, acc.: 62.50%] [G loss: 0.991086]\n",
      "epoch:3 step:3374 [D loss: 0.688656, acc.: 59.38%] [G loss: 1.049558]\n",
      "epoch:3 step:3375 [D loss: 0.613990, acc.: 66.41%] [G loss: 1.040770]\n",
      "epoch:3 step:3376 [D loss: 0.646949, acc.: 66.41%] [G loss: 1.100902]\n",
      "epoch:3 step:3377 [D loss: 0.690588, acc.: 54.69%] [G loss: 0.945748]\n",
      "epoch:3 step:3378 [D loss: 0.615130, acc.: 65.62%] [G loss: 1.042856]\n",
      "epoch:3 step:3379 [D loss: 0.724461, acc.: 53.91%] [G loss: 1.050815]\n",
      "epoch:3 step:3380 [D loss: 0.616671, acc.: 64.84%] [G loss: 1.066108]\n",
      "epoch:3 step:3381 [D loss: 0.571122, acc.: 73.44%] [G loss: 1.143023]\n",
      "epoch:3 step:3382 [D loss: 0.657796, acc.: 64.84%] [G loss: 1.154280]\n",
      "epoch:3 step:3383 [D loss: 0.567122, acc.: 70.31%] [G loss: 0.991287]\n",
      "epoch:3 step:3384 [D loss: 0.680490, acc.: 61.72%] [G loss: 1.017906]\n",
      "epoch:3 step:3385 [D loss: 0.719179, acc.: 50.00%] [G loss: 0.899579]\n",
      "epoch:3 step:3386 [D loss: 0.733940, acc.: 50.00%] [G loss: 0.947331]\n",
      "epoch:3 step:3387 [D loss: 0.685471, acc.: 58.59%] [G loss: 1.028510]\n",
      "epoch:3 step:3388 [D loss: 0.682371, acc.: 60.16%] [G loss: 1.000736]\n",
      "epoch:3 step:3389 [D loss: 0.628094, acc.: 63.28%] [G loss: 1.102648]\n",
      "epoch:3 step:3390 [D loss: 0.710631, acc.: 53.91%] [G loss: 1.044582]\n",
      "epoch:3 step:3391 [D loss: 0.669442, acc.: 62.50%] [G loss: 1.099323]\n",
      "epoch:3 step:3392 [D loss: 0.646877, acc.: 63.28%] [G loss: 1.129667]\n",
      "epoch:3 step:3393 [D loss: 0.650426, acc.: 57.81%] [G loss: 0.916556]\n",
      "epoch:3 step:3394 [D loss: 0.680904, acc.: 58.59%] [G loss: 0.975335]\n",
      "epoch:3 step:3395 [D loss: 0.652701, acc.: 66.41%] [G loss: 0.984193]\n",
      "epoch:3 step:3396 [D loss: 0.545282, acc.: 74.22%] [G loss: 1.117123]\n",
      "epoch:3 step:3397 [D loss: 0.674396, acc.: 60.16%] [G loss: 0.899834]\n",
      "epoch:3 step:3398 [D loss: 0.654487, acc.: 65.62%] [G loss: 1.167959]\n",
      "epoch:3 step:3399 [D loss: 0.687871, acc.: 57.81%] [G loss: 1.020773]\n",
      "epoch:3 step:3400 [D loss: 0.660126, acc.: 61.72%] [G loss: 1.015588]\n",
      "epoch:3 step:3401 [D loss: 0.694291, acc.: 61.72%] [G loss: 1.107114]\n",
      "epoch:3 step:3402 [D loss: 0.616599, acc.: 66.41%] [G loss: 1.183269]\n",
      "epoch:3 step:3403 [D loss: 0.581947, acc.: 66.41%] [G loss: 0.999441]\n",
      "epoch:3 step:3404 [D loss: 0.666737, acc.: 59.38%] [G loss: 0.981459]\n",
      "epoch:3 step:3405 [D loss: 0.637184, acc.: 67.97%] [G loss: 1.036283]\n",
      "epoch:3 step:3406 [D loss: 0.682141, acc.: 57.81%] [G loss: 1.029131]\n",
      "epoch:3 step:3407 [D loss: 0.592019, acc.: 69.53%] [G loss: 1.008012]\n",
      "epoch:3 step:3408 [D loss: 0.618482, acc.: 65.62%] [G loss: 1.005213]\n",
      "epoch:3 step:3409 [D loss: 0.699735, acc.: 59.38%] [G loss: 0.911916]\n",
      "epoch:3 step:3410 [D loss: 0.590962, acc.: 67.97%] [G loss: 1.034869]\n",
      "epoch:3 step:3411 [D loss: 0.657448, acc.: 61.72%] [G loss: 0.999866]\n",
      "epoch:3 step:3412 [D loss: 0.680536, acc.: 60.94%] [G loss: 0.933487]\n",
      "epoch:3 step:3413 [D loss: 0.605914, acc.: 62.50%] [G loss: 1.029845]\n",
      "epoch:3 step:3414 [D loss: 0.667526, acc.: 60.94%] [G loss: 0.967381]\n",
      "epoch:3 step:3415 [D loss: 0.736250, acc.: 51.56%] [G loss: 1.030643]\n",
      "epoch:3 step:3416 [D loss: 0.670355, acc.: 64.84%] [G loss: 1.079781]\n",
      "epoch:3 step:3417 [D loss: 0.722241, acc.: 52.34%] [G loss: 1.205343]\n",
      "epoch:3 step:3418 [D loss: 0.694218, acc.: 58.59%] [G loss: 0.997786]\n",
      "epoch:3 step:3419 [D loss: 0.665003, acc.: 59.38%] [G loss: 1.001949]\n",
      "epoch:3 step:3420 [D loss: 0.591820, acc.: 70.31%] [G loss: 1.007826]\n",
      "epoch:3 step:3421 [D loss: 0.665179, acc.: 59.38%] [G loss: 0.960425]\n",
      "epoch:3 step:3422 [D loss: 0.640579, acc.: 65.62%] [G loss: 1.077052]\n",
      "epoch:3 step:3423 [D loss: 0.635849, acc.: 63.28%] [G loss: 1.080287]\n",
      "epoch:3 step:3424 [D loss: 0.656489, acc.: 58.59%] [G loss: 1.030550]\n",
      "epoch:3 step:3425 [D loss: 0.635793, acc.: 69.53%] [G loss: 1.107240]\n",
      "epoch:3 step:3426 [D loss: 0.655741, acc.: 60.16%] [G loss: 1.067025]\n",
      "epoch:3 step:3427 [D loss: 0.606574, acc.: 69.53%] [G loss: 0.926588]\n",
      "epoch:3 step:3428 [D loss: 0.633269, acc.: 61.72%] [G loss: 0.883292]\n",
      "epoch:3 step:3429 [D loss: 0.686463, acc.: 59.38%] [G loss: 0.967632]\n",
      "epoch:3 step:3430 [D loss: 0.613355, acc.: 69.53%] [G loss: 1.094073]\n",
      "epoch:3 step:3431 [D loss: 0.720111, acc.: 51.56%] [G loss: 1.080820]\n",
      "epoch:3 step:3432 [D loss: 0.709092, acc.: 56.25%] [G loss: 0.994731]\n",
      "epoch:3 step:3433 [D loss: 0.664280, acc.: 57.03%] [G loss: 1.022325]\n",
      "epoch:3 step:3434 [D loss: 0.610101, acc.: 66.41%] [G loss: 0.997918]\n",
      "epoch:3 step:3435 [D loss: 0.638142, acc.: 65.62%] [G loss: 1.001084]\n",
      "epoch:3 step:3436 [D loss: 0.636913, acc.: 64.84%] [G loss: 0.940822]\n",
      "epoch:3 step:3437 [D loss: 0.718282, acc.: 53.12%] [G loss: 1.079815]\n",
      "epoch:3 step:3438 [D loss: 0.633448, acc.: 69.53%] [G loss: 1.049919]\n",
      "epoch:3 step:3439 [D loss: 0.702325, acc.: 52.34%] [G loss: 0.964677]\n",
      "epoch:3 step:3440 [D loss: 0.575147, acc.: 69.53%] [G loss: 1.076072]\n",
      "epoch:3 step:3441 [D loss: 0.691499, acc.: 53.91%] [G loss: 0.927891]\n",
      "epoch:3 step:3442 [D loss: 0.520959, acc.: 74.22%] [G loss: 1.201106]\n",
      "epoch:3 step:3443 [D loss: 0.653768, acc.: 61.72%] [G loss: 1.018064]\n",
      "epoch:3 step:3444 [D loss: 0.588556, acc.: 70.31%] [G loss: 1.130935]\n",
      "epoch:3 step:3445 [D loss: 0.641890, acc.: 66.41%] [G loss: 0.944579]\n",
      "epoch:3 step:3446 [D loss: 0.668574, acc.: 64.84%] [G loss: 0.796805]\n",
      "epoch:3 step:3447 [D loss: 0.590093, acc.: 71.88%] [G loss: 1.125358]\n",
      "epoch:3 step:3448 [D loss: 0.597763, acc.: 67.97%] [G loss: 1.158712]\n",
      "epoch:3 step:3449 [D loss: 0.673628, acc.: 57.03%] [G loss: 1.050069]\n",
      "epoch:3 step:3450 [D loss: 0.634631, acc.: 61.72%] [G loss: 1.100811]\n",
      "epoch:3 step:3451 [D loss: 0.660893, acc.: 59.38%] [G loss: 0.966024]\n",
      "epoch:3 step:3452 [D loss: 0.706378, acc.: 55.47%] [G loss: 1.134412]\n",
      "epoch:3 step:3453 [D loss: 0.631515, acc.: 65.62%] [G loss: 1.075766]\n",
      "epoch:3 step:3454 [D loss: 0.680877, acc.: 59.38%] [G loss: 1.169339]\n",
      "epoch:3 step:3455 [D loss: 0.611500, acc.: 65.62%] [G loss: 0.824915]\n",
      "epoch:3 step:3456 [D loss: 0.649693, acc.: 57.03%] [G loss: 1.196363]\n",
      "epoch:3 step:3457 [D loss: 0.608637, acc.: 68.75%] [G loss: 1.107142]\n",
      "epoch:3 step:3458 [D loss: 0.671434, acc.: 57.03%] [G loss: 1.116079]\n",
      "epoch:3 step:3459 [D loss: 0.607126, acc.: 67.19%] [G loss: 1.045035]\n",
      "epoch:3 step:3460 [D loss: 0.642409, acc.: 62.50%] [G loss: 1.116565]\n",
      "epoch:3 step:3461 [D loss: 0.640724, acc.: 68.75%] [G loss: 1.102558]\n",
      "epoch:3 step:3462 [D loss: 0.711663, acc.: 57.03%] [G loss: 1.073640]\n",
      "epoch:3 step:3463 [D loss: 0.697040, acc.: 53.91%] [G loss: 1.012428]\n",
      "epoch:3 step:3464 [D loss: 0.677186, acc.: 61.72%] [G loss: 0.921826]\n",
      "epoch:3 step:3465 [D loss: 0.608760, acc.: 64.06%] [G loss: 1.089647]\n",
      "epoch:3 step:3466 [D loss: 0.741159, acc.: 53.12%] [G loss: 1.054885]\n",
      "epoch:3 step:3467 [D loss: 0.632453, acc.: 64.84%] [G loss: 1.022954]\n",
      "epoch:3 step:3468 [D loss: 0.648943, acc.: 64.06%] [G loss: 1.003921]\n",
      "epoch:3 step:3469 [D loss: 0.591229, acc.: 68.75%] [G loss: 1.100398]\n",
      "epoch:3 step:3470 [D loss: 0.703868, acc.: 57.81%] [G loss: 0.891049]\n",
      "epoch:3 step:3471 [D loss: 0.716930, acc.: 54.69%] [G loss: 1.038376]\n",
      "epoch:3 step:3472 [D loss: 0.773701, acc.: 47.66%] [G loss: 1.070139]\n",
      "epoch:3 step:3473 [D loss: 0.641042, acc.: 69.53%] [G loss: 1.169959]\n",
      "epoch:3 step:3474 [D loss: 0.647103, acc.: 59.38%] [G loss: 0.971823]\n",
      "epoch:3 step:3475 [D loss: 0.635848, acc.: 61.72%] [G loss: 1.098564]\n",
      "epoch:3 step:3476 [D loss: 0.693480, acc.: 57.03%] [G loss: 0.989292]\n",
      "epoch:3 step:3477 [D loss: 0.616810, acc.: 64.84%] [G loss: 1.097769]\n",
      "epoch:3 step:3478 [D loss: 0.619567, acc.: 65.62%] [G loss: 0.988051]\n",
      "epoch:3 step:3479 [D loss: 0.613785, acc.: 64.06%] [G loss: 1.040242]\n",
      "epoch:3 step:3480 [D loss: 0.593212, acc.: 68.75%] [G loss: 0.986335]\n",
      "epoch:3 step:3481 [D loss: 0.637006, acc.: 67.19%] [G loss: 1.161473]\n",
      "epoch:3 step:3482 [D loss: 0.645422, acc.: 62.50%] [G loss: 1.001342]\n",
      "epoch:3 step:3483 [D loss: 0.728622, acc.: 55.47%] [G loss: 0.846375]\n",
      "epoch:3 step:3484 [D loss: 0.693594, acc.: 57.81%] [G loss: 1.066991]\n",
      "epoch:3 step:3485 [D loss: 0.590538, acc.: 65.62%] [G loss: 1.106165]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:3 step:3486 [D loss: 0.745960, acc.: 46.09%] [G loss: 0.868502]\n",
      "epoch:3 step:3487 [D loss: 0.649644, acc.: 59.38%] [G loss: 0.978731]\n",
      "epoch:3 step:3488 [D loss: 0.665853, acc.: 60.16%] [G loss: 1.030748]\n",
      "epoch:3 step:3489 [D loss: 0.718621, acc.: 55.47%] [G loss: 0.889773]\n",
      "epoch:3 step:3490 [D loss: 0.615254, acc.: 60.16%] [G loss: 1.056309]\n",
      "epoch:3 step:3491 [D loss: 0.582480, acc.: 70.31%] [G loss: 1.124901]\n",
      "epoch:3 step:3492 [D loss: 0.623702, acc.: 70.31%] [G loss: 0.942463]\n",
      "epoch:3 step:3493 [D loss: 0.579126, acc.: 72.66%] [G loss: 1.093848]\n",
      "epoch:3 step:3494 [D loss: 0.654559, acc.: 60.16%] [G loss: 1.066664]\n",
      "epoch:3 step:3495 [D loss: 0.617099, acc.: 66.41%] [G loss: 0.923448]\n",
      "epoch:3 step:3496 [D loss: 0.575587, acc.: 67.19%] [G loss: 1.244996]\n",
      "epoch:3 step:3497 [D loss: 0.683673, acc.: 59.38%] [G loss: 1.013427]\n",
      "epoch:3 step:3498 [D loss: 0.694903, acc.: 61.72%] [G loss: 1.036548]\n",
      "epoch:3 step:3499 [D loss: 0.549902, acc.: 73.44%] [G loss: 1.291531]\n",
      "epoch:3 step:3500 [D loss: 0.620097, acc.: 71.09%] [G loss: 1.275623]\n",
      "epoch:3 step:3501 [D loss: 0.695544, acc.: 60.94%] [G loss: 1.019658]\n",
      "epoch:3 step:3502 [D loss: 0.711857, acc.: 53.12%] [G loss: 0.969518]\n",
      "epoch:3 step:3503 [D loss: 0.662071, acc.: 57.81%] [G loss: 1.101553]\n",
      "epoch:3 step:3504 [D loss: 0.606746, acc.: 68.75%] [G loss: 1.017044]\n",
      "epoch:3 step:3505 [D loss: 0.706189, acc.: 50.00%] [G loss: 0.962988]\n",
      "epoch:3 step:3506 [D loss: 0.623135, acc.: 67.19%] [G loss: 1.226846]\n",
      "epoch:3 step:3507 [D loss: 0.659921, acc.: 62.50%] [G loss: 1.070283]\n",
      "epoch:3 step:3508 [D loss: 0.721521, acc.: 56.25%] [G loss: 1.010265]\n",
      "epoch:3 step:3509 [D loss: 0.633890, acc.: 64.06%] [G loss: 1.071482]\n",
      "epoch:3 step:3510 [D loss: 0.677341, acc.: 58.59%] [G loss: 0.995902]\n",
      "epoch:3 step:3511 [D loss: 0.653176, acc.: 57.81%] [G loss: 0.967480]\n",
      "epoch:3 step:3512 [D loss: 0.612884, acc.: 67.97%] [G loss: 1.158991]\n",
      "epoch:3 step:3513 [D loss: 0.522601, acc.: 76.56%] [G loss: 1.007731]\n",
      "epoch:3 step:3514 [D loss: 0.706965, acc.: 57.03%] [G loss: 1.083122]\n",
      "epoch:3 step:3515 [D loss: 0.705339, acc.: 51.56%] [G loss: 1.014537]\n",
      "epoch:3 step:3516 [D loss: 0.571993, acc.: 69.53%] [G loss: 1.192312]\n",
      "epoch:3 step:3517 [D loss: 0.629449, acc.: 60.16%] [G loss: 1.022987]\n",
      "epoch:3 step:3518 [D loss: 0.679680, acc.: 62.50%] [G loss: 1.030801]\n",
      "epoch:3 step:3519 [D loss: 0.679121, acc.: 62.50%] [G loss: 1.158805]\n",
      "epoch:3 step:3520 [D loss: 0.694751, acc.: 59.38%] [G loss: 1.155909]\n",
      "epoch:3 step:3521 [D loss: 0.596525, acc.: 71.88%] [G loss: 0.988662]\n",
      "epoch:3 step:3522 [D loss: 0.576217, acc.: 64.84%] [G loss: 1.045858]\n",
      "epoch:3 step:3523 [D loss: 0.609554, acc.: 68.75%] [G loss: 1.000931]\n",
      "epoch:3 step:3524 [D loss: 0.628431, acc.: 67.19%] [G loss: 1.011822]\n",
      "epoch:3 step:3525 [D loss: 0.612628, acc.: 69.53%] [G loss: 1.153170]\n",
      "epoch:3 step:3526 [D loss: 0.745276, acc.: 51.56%] [G loss: 0.955861]\n",
      "epoch:3 step:3527 [D loss: 0.591640, acc.: 64.84%] [G loss: 1.156666]\n",
      "epoch:3 step:3528 [D loss: 0.619479, acc.: 62.50%] [G loss: 1.061812]\n",
      "epoch:3 step:3529 [D loss: 0.573135, acc.: 70.31%] [G loss: 1.083411]\n",
      "epoch:3 step:3530 [D loss: 0.670776, acc.: 57.03%] [G loss: 0.985044]\n",
      "epoch:3 step:3531 [D loss: 0.610572, acc.: 63.28%] [G loss: 1.032314]\n",
      "epoch:3 step:3532 [D loss: 0.665626, acc.: 61.72%] [G loss: 1.095549]\n",
      "epoch:3 step:3533 [D loss: 0.630864, acc.: 68.75%] [G loss: 1.115505]\n",
      "epoch:3 step:3534 [D loss: 0.631474, acc.: 64.84%] [G loss: 0.960177]\n",
      "epoch:3 step:3535 [D loss: 0.692609, acc.: 53.12%] [G loss: 0.959775]\n",
      "epoch:3 step:3536 [D loss: 0.622176, acc.: 64.84%] [G loss: 1.011147]\n",
      "epoch:3 step:3537 [D loss: 0.657339, acc.: 60.94%] [G loss: 0.989425]\n",
      "epoch:3 step:3538 [D loss: 0.548660, acc.: 71.88%] [G loss: 1.124187]\n",
      "epoch:3 step:3539 [D loss: 0.656938, acc.: 58.59%] [G loss: 1.128999]\n",
      "epoch:3 step:3540 [D loss: 0.712915, acc.: 53.12%] [G loss: 0.995594]\n",
      "epoch:3 step:3541 [D loss: 0.614581, acc.: 67.19%] [G loss: 1.269560]\n",
      "epoch:3 step:3542 [D loss: 0.683375, acc.: 57.03%] [G loss: 1.032561]\n",
      "epoch:3 step:3543 [D loss: 0.732658, acc.: 55.47%] [G loss: 0.789437]\n",
      "epoch:3 step:3544 [D loss: 0.660046, acc.: 59.38%] [G loss: 1.017033]\n",
      "epoch:3 step:3545 [D loss: 0.581949, acc.: 69.53%] [G loss: 1.079642]\n",
      "epoch:3 step:3546 [D loss: 0.627139, acc.: 61.72%] [G loss: 1.048545]\n",
      "epoch:3 step:3547 [D loss: 0.658992, acc.: 61.72%] [G loss: 1.002066]\n",
      "epoch:3 step:3548 [D loss: 0.646715, acc.: 64.06%] [G loss: 1.196263]\n",
      "epoch:3 step:3549 [D loss: 0.746572, acc.: 51.56%] [G loss: 1.014642]\n",
      "epoch:3 step:3550 [D loss: 0.709679, acc.: 58.59%] [G loss: 0.981157]\n",
      "epoch:3 step:3551 [D loss: 0.689872, acc.: 57.81%] [G loss: 1.058984]\n",
      "epoch:3 step:3552 [D loss: 0.694892, acc.: 60.94%] [G loss: 0.992975]\n",
      "epoch:3 step:3553 [D loss: 0.583108, acc.: 71.09%] [G loss: 1.225362]\n",
      "epoch:3 step:3554 [D loss: 0.781820, acc.: 50.78%] [G loss: 0.972973]\n",
      "epoch:3 step:3555 [D loss: 0.620617, acc.: 64.06%] [G loss: 1.034047]\n",
      "epoch:3 step:3556 [D loss: 0.680851, acc.: 61.72%] [G loss: 1.001806]\n",
      "epoch:3 step:3557 [D loss: 0.665025, acc.: 60.16%] [G loss: 1.041690]\n",
      "epoch:3 step:3558 [D loss: 0.637702, acc.: 56.25%] [G loss: 1.031771]\n",
      "epoch:3 step:3559 [D loss: 0.670882, acc.: 60.94%] [G loss: 0.988020]\n",
      "epoch:3 step:3560 [D loss: 0.653762, acc.: 61.72%] [G loss: 1.152622]\n",
      "epoch:3 step:3561 [D loss: 0.668256, acc.: 58.59%] [G loss: 1.075088]\n",
      "epoch:3 step:3562 [D loss: 0.577870, acc.: 67.97%] [G loss: 1.166686]\n",
      "epoch:3 step:3563 [D loss: 0.638104, acc.: 67.19%] [G loss: 1.117458]\n",
      "epoch:3 step:3564 [D loss: 0.615521, acc.: 64.06%] [G loss: 1.174324]\n",
      "epoch:3 step:3565 [D loss: 0.659627, acc.: 61.72%] [G loss: 0.935942]\n",
      "epoch:3 step:3566 [D loss: 0.624596, acc.: 66.41%] [G loss: 0.991145]\n",
      "epoch:3 step:3567 [D loss: 0.674690, acc.: 65.62%] [G loss: 0.894145]\n",
      "epoch:3 step:3568 [D loss: 0.671543, acc.: 63.28%] [G loss: 0.981627]\n",
      "epoch:3 step:3569 [D loss: 0.586466, acc.: 71.88%] [G loss: 1.086083]\n",
      "epoch:3 step:3570 [D loss: 0.645266, acc.: 60.94%] [G loss: 1.177838]\n",
      "epoch:3 step:3571 [D loss: 0.648388, acc.: 62.50%] [G loss: 0.961874]\n",
      "epoch:3 step:3572 [D loss: 0.736685, acc.: 53.12%] [G loss: 1.033517]\n",
      "epoch:3 step:3573 [D loss: 0.670816, acc.: 62.50%] [G loss: 1.068959]\n",
      "epoch:3 step:3574 [D loss: 0.604738, acc.: 65.62%] [G loss: 0.990814]\n",
      "epoch:3 step:3575 [D loss: 0.675655, acc.: 60.94%] [G loss: 1.004876]\n",
      "epoch:3 step:3576 [D loss: 0.623925, acc.: 64.06%] [G loss: 1.159173]\n",
      "epoch:3 step:3577 [D loss: 0.660419, acc.: 58.59%] [G loss: 1.117674]\n",
      "epoch:3 step:3578 [D loss: 0.671633, acc.: 60.16%] [G loss: 1.084999]\n",
      "epoch:3 step:3579 [D loss: 0.636972, acc.: 62.50%] [G loss: 1.140559]\n",
      "epoch:3 step:3580 [D loss: 0.679028, acc.: 57.03%] [G loss: 1.130007]\n",
      "epoch:3 step:3581 [D loss: 0.680617, acc.: 57.03%] [G loss: 1.047099]\n",
      "epoch:3 step:3582 [D loss: 0.682760, acc.: 57.03%] [G loss: 0.907391]\n",
      "epoch:3 step:3583 [D loss: 0.595112, acc.: 64.84%] [G loss: 0.948262]\n",
      "epoch:3 step:3584 [D loss: 0.660386, acc.: 55.47%] [G loss: 0.954456]\n",
      "epoch:3 step:3585 [D loss: 0.608197, acc.: 73.44%] [G loss: 1.035873]\n",
      "epoch:3 step:3586 [D loss: 0.642304, acc.: 65.62%] [G loss: 0.909621]\n",
      "epoch:3 step:3587 [D loss: 0.631808, acc.: 64.84%] [G loss: 1.055423]\n",
      "epoch:3 step:3588 [D loss: 0.701809, acc.: 58.59%] [G loss: 1.042788]\n",
      "epoch:3 step:3589 [D loss: 0.589650, acc.: 65.62%] [G loss: 1.173769]\n",
      "epoch:3 step:3590 [D loss: 0.640456, acc.: 60.94%] [G loss: 1.017728]\n",
      "epoch:3 step:3591 [D loss: 0.655966, acc.: 59.38%] [G loss: 0.989139]\n",
      "epoch:3 step:3592 [D loss: 0.679310, acc.: 59.38%] [G loss: 0.986824]\n",
      "epoch:3 step:3593 [D loss: 0.645329, acc.: 59.38%] [G loss: 0.914371]\n",
      "epoch:3 step:3594 [D loss: 0.621019, acc.: 65.62%] [G loss: 0.937648]\n",
      "epoch:3 step:3595 [D loss: 0.670458, acc.: 58.59%] [G loss: 1.030625]\n",
      "epoch:3 step:3596 [D loss: 0.661588, acc.: 61.72%] [G loss: 1.018739]\n",
      "epoch:3 step:3597 [D loss: 0.728094, acc.: 52.34%] [G loss: 1.083928]\n",
      "epoch:3 step:3598 [D loss: 0.604006, acc.: 70.31%] [G loss: 0.966654]\n",
      "epoch:3 step:3599 [D loss: 0.647030, acc.: 60.16%] [G loss: 1.162593]\n",
      "epoch:3 step:3600 [D loss: 0.675027, acc.: 60.16%] [G loss: 1.073452]\n",
      "epoch:3 step:3601 [D loss: 0.652675, acc.: 61.72%] [G loss: 0.969281]\n",
      "epoch:3 step:3602 [D loss: 0.687967, acc.: 55.47%] [G loss: 1.189820]\n",
      "epoch:3 step:3603 [D loss: 0.570654, acc.: 71.88%] [G loss: 1.119069]\n",
      "epoch:3 step:3604 [D loss: 0.630223, acc.: 64.84%] [G loss: 1.020945]\n",
      "epoch:3 step:3605 [D loss: 0.564603, acc.: 70.31%] [G loss: 1.112177]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:3 step:3606 [D loss: 0.612541, acc.: 67.97%] [G loss: 1.020251]\n",
      "epoch:3 step:3607 [D loss: 0.628767, acc.: 63.28%] [G loss: 0.965147]\n",
      "epoch:3 step:3608 [D loss: 0.705390, acc.: 57.81%] [G loss: 0.965195]\n",
      "epoch:3 step:3609 [D loss: 0.595967, acc.: 67.19%] [G loss: 1.053140]\n",
      "epoch:3 step:3610 [D loss: 0.579571, acc.: 66.41%] [G loss: 1.130074]\n",
      "epoch:3 step:3611 [D loss: 0.676272, acc.: 58.59%] [G loss: 1.040261]\n",
      "epoch:3 step:3612 [D loss: 0.606199, acc.: 64.06%] [G loss: 1.172328]\n",
      "epoch:3 step:3613 [D loss: 0.658220, acc.: 57.81%] [G loss: 1.153412]\n",
      "epoch:3 step:3614 [D loss: 0.744910, acc.: 53.91%] [G loss: 0.879958]\n",
      "epoch:3 step:3615 [D loss: 0.719270, acc.: 55.47%] [G loss: 1.004752]\n",
      "epoch:3 step:3616 [D loss: 0.600231, acc.: 71.09%] [G loss: 1.146106]\n",
      "epoch:3 step:3617 [D loss: 0.607961, acc.: 68.75%] [G loss: 0.929097]\n",
      "epoch:3 step:3618 [D loss: 0.657891, acc.: 55.47%] [G loss: 1.027954]\n",
      "epoch:3 step:3619 [D loss: 0.600643, acc.: 70.31%] [G loss: 1.112575]\n",
      "epoch:3 step:3620 [D loss: 0.679344, acc.: 64.06%] [G loss: 0.849913]\n",
      "epoch:3 step:3621 [D loss: 0.671300, acc.: 60.94%] [G loss: 1.052897]\n",
      "epoch:3 step:3622 [D loss: 0.652439, acc.: 60.16%] [G loss: 1.113658]\n",
      "epoch:3 step:3623 [D loss: 0.691034, acc.: 60.94%] [G loss: 1.056990]\n",
      "epoch:3 step:3624 [D loss: 0.739368, acc.: 45.31%] [G loss: 0.928970]\n",
      "epoch:3 step:3625 [D loss: 0.636502, acc.: 65.62%] [G loss: 1.032490]\n",
      "epoch:3 step:3626 [D loss: 0.692107, acc.: 56.25%] [G loss: 1.029274]\n",
      "epoch:3 step:3627 [D loss: 0.538703, acc.: 76.56%] [G loss: 1.137460]\n",
      "epoch:3 step:3628 [D loss: 0.615349, acc.: 60.16%] [G loss: 1.069795]\n",
      "epoch:3 step:3629 [D loss: 0.597780, acc.: 67.97%] [G loss: 0.949555]\n",
      "epoch:3 step:3630 [D loss: 0.552529, acc.: 70.31%] [G loss: 1.068438]\n",
      "epoch:3 step:3631 [D loss: 0.682798, acc.: 59.38%] [G loss: 1.000102]\n",
      "epoch:3 step:3632 [D loss: 0.658568, acc.: 62.50%] [G loss: 1.052443]\n",
      "epoch:3 step:3633 [D loss: 0.679846, acc.: 59.38%] [G loss: 1.169227]\n",
      "epoch:3 step:3634 [D loss: 0.677963, acc.: 58.59%] [G loss: 1.047611]\n",
      "epoch:3 step:3635 [D loss: 0.657972, acc.: 57.81%] [G loss: 0.861403]\n",
      "epoch:3 step:3636 [D loss: 0.676777, acc.: 57.03%] [G loss: 0.922859]\n",
      "epoch:3 step:3637 [D loss: 0.603402, acc.: 71.09%] [G loss: 0.967496]\n",
      "epoch:3 step:3638 [D loss: 0.608152, acc.: 63.28%] [G loss: 1.248574]\n",
      "epoch:3 step:3639 [D loss: 0.735145, acc.: 50.00%] [G loss: 0.920415]\n",
      "epoch:3 step:3640 [D loss: 0.626668, acc.: 66.41%] [G loss: 1.000375]\n",
      "epoch:3 step:3641 [D loss: 0.749930, acc.: 56.25%] [G loss: 0.925702]\n",
      "epoch:3 step:3642 [D loss: 0.721555, acc.: 52.34%] [G loss: 0.997077]\n",
      "epoch:3 step:3643 [D loss: 0.618440, acc.: 65.62%] [G loss: 1.220315]\n",
      "epoch:3 step:3644 [D loss: 0.675116, acc.: 60.16%] [G loss: 0.955381]\n",
      "epoch:3 step:3645 [D loss: 0.698108, acc.: 56.25%] [G loss: 0.892624]\n",
      "epoch:3 step:3646 [D loss: 0.714643, acc.: 58.59%] [G loss: 1.025695]\n",
      "epoch:3 step:3647 [D loss: 0.673554, acc.: 60.94%] [G loss: 0.921822]\n",
      "epoch:3 step:3648 [D loss: 0.681807, acc.: 60.94%] [G loss: 0.847037]\n",
      "epoch:3 step:3649 [D loss: 0.620171, acc.: 63.28%] [G loss: 0.915069]\n",
      "epoch:3 step:3650 [D loss: 0.619643, acc.: 64.84%] [G loss: 1.149358]\n",
      "epoch:3 step:3651 [D loss: 0.663918, acc.: 63.28%] [G loss: 0.952339]\n",
      "epoch:3 step:3652 [D loss: 0.592599, acc.: 69.53%] [G loss: 1.191103]\n",
      "epoch:3 step:3653 [D loss: 0.584024, acc.: 71.09%] [G loss: 1.091182]\n",
      "epoch:3 step:3654 [D loss: 0.661222, acc.: 62.50%] [G loss: 0.940453]\n",
      "epoch:3 step:3655 [D loss: 0.641867, acc.: 59.38%] [G loss: 1.194995]\n",
      "epoch:3 step:3656 [D loss: 0.637230, acc.: 65.62%] [G loss: 1.066405]\n",
      "epoch:3 step:3657 [D loss: 0.650267, acc.: 60.94%] [G loss: 0.960668]\n",
      "epoch:3 step:3658 [D loss: 0.734241, acc.: 55.47%] [G loss: 0.968093]\n",
      "epoch:3 step:3659 [D loss: 0.622844, acc.: 62.50%] [G loss: 1.182163]\n",
      "epoch:3 step:3660 [D loss: 0.601417, acc.: 68.75%] [G loss: 1.074936]\n",
      "epoch:3 step:3661 [D loss: 0.637563, acc.: 60.16%] [G loss: 0.830383]\n",
      "epoch:3 step:3662 [D loss: 0.732491, acc.: 52.34%] [G loss: 1.013341]\n",
      "epoch:3 step:3663 [D loss: 0.625684, acc.: 63.28%] [G loss: 1.020038]\n",
      "epoch:3 step:3664 [D loss: 0.588933, acc.: 65.62%] [G loss: 1.032127]\n",
      "epoch:3 step:3665 [D loss: 0.614709, acc.: 70.31%] [G loss: 0.916855]\n",
      "epoch:3 step:3666 [D loss: 0.675953, acc.: 58.59%] [G loss: 0.998969]\n",
      "epoch:3 step:3667 [D loss: 0.537266, acc.: 74.22%] [G loss: 1.149421]\n",
      "epoch:3 step:3668 [D loss: 0.674878, acc.: 58.59%] [G loss: 1.103677]\n",
      "epoch:3 step:3669 [D loss: 0.570524, acc.: 67.97%] [G loss: 0.984803]\n",
      "epoch:3 step:3670 [D loss: 0.610226, acc.: 66.41%] [G loss: 0.990603]\n",
      "epoch:3 step:3671 [D loss: 0.591616, acc.: 71.88%] [G loss: 1.112387]\n",
      "epoch:3 step:3672 [D loss: 0.598216, acc.: 64.06%] [G loss: 1.219274]\n",
      "epoch:3 step:3673 [D loss: 0.600263, acc.: 67.97%] [G loss: 1.184293]\n",
      "epoch:3 step:3674 [D loss: 0.700038, acc.: 54.69%] [G loss: 0.971332]\n",
      "epoch:3 step:3675 [D loss: 0.677347, acc.: 62.50%] [G loss: 0.973008]\n",
      "epoch:3 step:3676 [D loss: 0.590502, acc.: 65.62%] [G loss: 1.139209]\n",
      "epoch:3 step:3677 [D loss: 0.656174, acc.: 63.28%] [G loss: 1.122163]\n",
      "epoch:3 step:3678 [D loss: 0.640256, acc.: 65.62%] [G loss: 1.143888]\n",
      "epoch:3 step:3679 [D loss: 0.707995, acc.: 55.47%] [G loss: 1.001997]\n",
      "epoch:3 step:3680 [D loss: 0.567896, acc.: 71.88%] [G loss: 1.100619]\n",
      "epoch:3 step:3681 [D loss: 0.481471, acc.: 83.59%] [G loss: 1.271837]\n",
      "epoch:3 step:3682 [D loss: 0.678735, acc.: 55.47%] [G loss: 1.009918]\n",
      "epoch:3 step:3683 [D loss: 0.687696, acc.: 56.25%] [G loss: 0.961011]\n",
      "epoch:3 step:3684 [D loss: 0.582615, acc.: 67.19%] [G loss: 1.012460]\n",
      "epoch:3 step:3685 [D loss: 0.651115, acc.: 60.94%] [G loss: 0.940427]\n",
      "epoch:3 step:3686 [D loss: 0.679802, acc.: 63.28%] [G loss: 1.030270]\n",
      "epoch:3 step:3687 [D loss: 0.736026, acc.: 52.34%] [G loss: 1.002923]\n",
      "epoch:3 step:3688 [D loss: 0.711917, acc.: 53.12%] [G loss: 0.974770]\n",
      "epoch:3 step:3689 [D loss: 0.692420, acc.: 61.72%] [G loss: 1.083616]\n",
      "epoch:3 step:3690 [D loss: 0.726536, acc.: 53.91%] [G loss: 1.160903]\n",
      "epoch:3 step:3691 [D loss: 0.609873, acc.: 66.41%] [G loss: 1.017213]\n",
      "epoch:3 step:3692 [D loss: 0.676939, acc.: 56.25%] [G loss: 1.109973]\n",
      "epoch:3 step:3693 [D loss: 0.607177, acc.: 61.72%] [G loss: 1.015719]\n",
      "epoch:3 step:3694 [D loss: 0.602937, acc.: 62.50%] [G loss: 1.000610]\n",
      "epoch:3 step:3695 [D loss: 0.657108, acc.: 63.28%] [G loss: 1.068519]\n",
      "epoch:3 step:3696 [D loss: 0.678324, acc.: 60.16%] [G loss: 0.978461]\n",
      "epoch:3 step:3697 [D loss: 0.625750, acc.: 67.97%] [G loss: 1.067971]\n",
      "epoch:3 step:3698 [D loss: 0.640260, acc.: 59.38%] [G loss: 1.122849]\n",
      "epoch:3 step:3699 [D loss: 0.646092, acc.: 59.38%] [G loss: 1.011122]\n",
      "epoch:3 step:3700 [D loss: 0.724759, acc.: 54.69%] [G loss: 0.958918]\n",
      "epoch:3 step:3701 [D loss: 0.592175, acc.: 67.19%] [G loss: 1.069446]\n",
      "epoch:3 step:3702 [D loss: 0.677264, acc.: 64.84%] [G loss: 0.917320]\n",
      "epoch:3 step:3703 [D loss: 0.728686, acc.: 53.91%] [G loss: 1.077252]\n",
      "epoch:3 step:3704 [D loss: 0.603586, acc.: 70.31%] [G loss: 1.105784]\n",
      "epoch:3 step:3705 [D loss: 0.696372, acc.: 53.12%] [G loss: 1.020557]\n",
      "epoch:3 step:3706 [D loss: 0.590052, acc.: 66.41%] [G loss: 0.941014]\n",
      "epoch:3 step:3707 [D loss: 0.581166, acc.: 74.22%] [G loss: 1.095553]\n",
      "epoch:3 step:3708 [D loss: 0.693582, acc.: 53.91%] [G loss: 1.067347]\n",
      "epoch:3 step:3709 [D loss: 0.648525, acc.: 61.72%] [G loss: 1.051357]\n",
      "epoch:3 step:3710 [D loss: 0.646136, acc.: 59.38%] [G loss: 1.100729]\n",
      "epoch:3 step:3711 [D loss: 0.608149, acc.: 67.97%] [G loss: 1.058434]\n",
      "epoch:3 step:3712 [D loss: 0.610901, acc.: 66.41%] [G loss: 1.090111]\n",
      "epoch:3 step:3713 [D loss: 0.686354, acc.: 55.47%] [G loss: 1.196214]\n",
      "epoch:3 step:3714 [D loss: 0.645709, acc.: 65.62%] [G loss: 1.187551]\n",
      "epoch:3 step:3715 [D loss: 0.494933, acc.: 78.91%] [G loss: 1.229427]\n",
      "epoch:3 step:3716 [D loss: 0.626837, acc.: 63.28%] [G loss: 1.121680]\n",
      "epoch:3 step:3717 [D loss: 0.613680, acc.: 68.75%] [G loss: 1.121424]\n",
      "epoch:3 step:3718 [D loss: 0.671532, acc.: 65.62%] [G loss: 0.968337]\n",
      "epoch:3 step:3719 [D loss: 0.675663, acc.: 57.81%] [G loss: 1.092127]\n",
      "epoch:3 step:3720 [D loss: 0.697482, acc.: 50.78%] [G loss: 0.914151]\n",
      "epoch:3 step:3721 [D loss: 0.677551, acc.: 59.38%] [G loss: 1.148387]\n",
      "epoch:3 step:3722 [D loss: 0.634282, acc.: 60.16%] [G loss: 1.145113]\n",
      "epoch:3 step:3723 [D loss: 0.752616, acc.: 50.00%] [G loss: 1.050543]\n",
      "epoch:3 step:3724 [D loss: 0.694798, acc.: 59.38%] [G loss: 1.055293]\n",
      "epoch:3 step:3725 [D loss: 0.632243, acc.: 65.62%] [G loss: 1.193872]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:3 step:3726 [D loss: 0.626894, acc.: 63.28%] [G loss: 1.058813]\n",
      "epoch:3 step:3727 [D loss: 0.551404, acc.: 69.53%] [G loss: 1.136936]\n",
      "epoch:3 step:3728 [D loss: 0.620755, acc.: 65.62%] [G loss: 1.129937]\n",
      "epoch:3 step:3729 [D loss: 0.668100, acc.: 65.62%] [G loss: 0.996926]\n",
      "epoch:3 step:3730 [D loss: 0.596088, acc.: 68.75%] [G loss: 1.228144]\n",
      "epoch:3 step:3731 [D loss: 0.695854, acc.: 54.69%] [G loss: 1.042458]\n",
      "epoch:3 step:3732 [D loss: 0.696848, acc.: 56.25%] [G loss: 1.059440]\n",
      "epoch:3 step:3733 [D loss: 0.632720, acc.: 64.06%] [G loss: 0.932973]\n",
      "epoch:3 step:3734 [D loss: 0.715720, acc.: 58.59%] [G loss: 1.119951]\n",
      "epoch:3 step:3735 [D loss: 0.682791, acc.: 60.94%] [G loss: 1.093590]\n",
      "epoch:3 step:3736 [D loss: 0.672560, acc.: 57.03%] [G loss: 0.894670]\n",
      "epoch:3 step:3737 [D loss: 0.663235, acc.: 61.72%] [G loss: 1.023871]\n",
      "epoch:3 step:3738 [D loss: 0.689593, acc.: 53.91%] [G loss: 0.954070]\n",
      "epoch:3 step:3739 [D loss: 0.596812, acc.: 71.09%] [G loss: 1.165040]\n",
      "epoch:3 step:3740 [D loss: 0.622220, acc.: 69.53%] [G loss: 1.221627]\n",
      "epoch:3 step:3741 [D loss: 0.671417, acc.: 55.47%] [G loss: 1.084324]\n",
      "epoch:3 step:3742 [D loss: 0.620842, acc.: 68.75%] [G loss: 1.067085]\n",
      "epoch:3 step:3743 [D loss: 0.573247, acc.: 68.75%] [G loss: 1.291112]\n",
      "epoch:3 step:3744 [D loss: 0.640423, acc.: 60.16%] [G loss: 1.020016]\n",
      "epoch:3 step:3745 [D loss: 0.633411, acc.: 65.62%] [G loss: 0.988576]\n",
      "epoch:3 step:3746 [D loss: 0.647106, acc.: 61.72%] [G loss: 1.009412]\n",
      "epoch:3 step:3747 [D loss: 0.554990, acc.: 71.09%] [G loss: 0.988010]\n",
      "epoch:3 step:3748 [D loss: 0.683234, acc.: 60.94%] [G loss: 0.970499]\n",
      "epoch:4 step:3749 [D loss: 0.652567, acc.: 65.62%] [G loss: 1.027547]\n",
      "epoch:4 step:3750 [D loss: 0.724725, acc.: 55.47%] [G loss: 1.040717]\n",
      "epoch:4 step:3751 [D loss: 0.624297, acc.: 63.28%] [G loss: 1.100177]\n",
      "epoch:4 step:3752 [D loss: 0.683537, acc.: 58.59%] [G loss: 1.028751]\n",
      "epoch:4 step:3753 [D loss: 0.680956, acc.: 57.03%] [G loss: 0.962327]\n",
      "epoch:4 step:3754 [D loss: 0.742022, acc.: 53.12%] [G loss: 0.973670]\n",
      "epoch:4 step:3755 [D loss: 0.699746, acc.: 53.91%] [G loss: 1.011818]\n",
      "epoch:4 step:3756 [D loss: 0.688949, acc.: 57.81%] [G loss: 0.959333]\n",
      "epoch:4 step:3757 [D loss: 0.570872, acc.: 71.09%] [G loss: 1.021415]\n",
      "epoch:4 step:3758 [D loss: 0.688089, acc.: 57.81%] [G loss: 1.124544]\n",
      "epoch:4 step:3759 [D loss: 0.589323, acc.: 70.31%] [G loss: 0.961793]\n",
      "epoch:4 step:3760 [D loss: 0.651549, acc.: 62.50%] [G loss: 1.112567]\n",
      "epoch:4 step:3761 [D loss: 0.705316, acc.: 58.59%] [G loss: 1.011252]\n",
      "epoch:4 step:3762 [D loss: 0.728068, acc.: 56.25%] [G loss: 1.002224]\n",
      "epoch:4 step:3763 [D loss: 0.607981, acc.: 65.62%] [G loss: 1.052212]\n",
      "epoch:4 step:3764 [D loss: 0.606171, acc.: 67.97%] [G loss: 1.246031]\n",
      "epoch:4 step:3765 [D loss: 0.559483, acc.: 71.09%] [G loss: 1.055676]\n",
      "epoch:4 step:3766 [D loss: 0.653551, acc.: 63.28%] [G loss: 1.220273]\n",
      "epoch:4 step:3767 [D loss: 0.721594, acc.: 53.12%] [G loss: 1.067642]\n",
      "epoch:4 step:3768 [D loss: 0.623281, acc.: 67.97%] [G loss: 1.113851]\n",
      "epoch:4 step:3769 [D loss: 0.776147, acc.: 48.44%] [G loss: 0.971418]\n",
      "epoch:4 step:3770 [D loss: 0.703818, acc.: 53.12%] [G loss: 1.046639]\n",
      "epoch:4 step:3771 [D loss: 0.706344, acc.: 60.94%] [G loss: 0.985373]\n",
      "epoch:4 step:3772 [D loss: 0.596671, acc.: 67.97%] [G loss: 1.067274]\n",
      "epoch:4 step:3773 [D loss: 0.659469, acc.: 60.16%] [G loss: 1.021548]\n",
      "epoch:4 step:3774 [D loss: 0.634948, acc.: 59.38%] [G loss: 0.944478]\n",
      "epoch:4 step:3775 [D loss: 0.597411, acc.: 72.66%] [G loss: 1.085789]\n",
      "epoch:4 step:3776 [D loss: 0.610304, acc.: 67.19%] [G loss: 1.169151]\n",
      "epoch:4 step:3777 [D loss: 0.686102, acc.: 58.59%] [G loss: 1.130347]\n",
      "epoch:4 step:3778 [D loss: 0.685566, acc.: 60.16%] [G loss: 1.133473]\n",
      "epoch:4 step:3779 [D loss: 0.807815, acc.: 43.75%] [G loss: 0.882743]\n",
      "epoch:4 step:3780 [D loss: 0.587202, acc.: 70.31%] [G loss: 1.175810]\n",
      "epoch:4 step:3781 [D loss: 0.624970, acc.: 63.28%] [G loss: 0.924608]\n",
      "epoch:4 step:3782 [D loss: 0.642040, acc.: 54.69%] [G loss: 0.985457]\n",
      "epoch:4 step:3783 [D loss: 0.678632, acc.: 60.16%] [G loss: 1.105725]\n",
      "epoch:4 step:3784 [D loss: 0.662733, acc.: 61.72%] [G loss: 1.120214]\n",
      "epoch:4 step:3785 [D loss: 0.640571, acc.: 67.19%] [G loss: 1.040265]\n",
      "epoch:4 step:3786 [D loss: 0.663149, acc.: 57.81%] [G loss: 1.048400]\n",
      "epoch:4 step:3787 [D loss: 0.671131, acc.: 58.59%] [G loss: 0.925179]\n",
      "epoch:4 step:3788 [D loss: 0.621071, acc.: 63.28%] [G loss: 1.110598]\n",
      "epoch:4 step:3789 [D loss: 0.652224, acc.: 57.81%] [G loss: 1.036108]\n",
      "epoch:4 step:3790 [D loss: 0.549590, acc.: 71.09%] [G loss: 1.213728]\n",
      "epoch:4 step:3791 [D loss: 0.692821, acc.: 56.25%] [G loss: 1.026744]\n",
      "epoch:4 step:3792 [D loss: 0.702374, acc.: 54.69%] [G loss: 1.051901]\n",
      "epoch:4 step:3793 [D loss: 0.716762, acc.: 54.69%] [G loss: 1.127901]\n",
      "epoch:4 step:3794 [D loss: 0.659050, acc.: 64.06%] [G loss: 0.995460]\n",
      "epoch:4 step:3795 [D loss: 0.677783, acc.: 54.69%] [G loss: 1.020990]\n",
      "epoch:4 step:3796 [D loss: 0.632097, acc.: 61.72%] [G loss: 1.084133]\n",
      "epoch:4 step:3797 [D loss: 0.638418, acc.: 60.94%] [G loss: 1.072801]\n",
      "epoch:4 step:3798 [D loss: 0.723773, acc.: 52.34%] [G loss: 1.057623]\n",
      "epoch:4 step:3799 [D loss: 0.634233, acc.: 60.16%] [G loss: 1.017139]\n",
      "epoch:4 step:3800 [D loss: 0.651980, acc.: 56.25%] [G loss: 1.139581]\n",
      "epoch:4 step:3801 [D loss: 0.723149, acc.: 55.47%] [G loss: 0.999199]\n",
      "epoch:4 step:3802 [D loss: 0.643479, acc.: 63.28%] [G loss: 0.962575]\n",
      "epoch:4 step:3803 [D loss: 0.690690, acc.: 53.12%] [G loss: 1.004425]\n",
      "epoch:4 step:3804 [D loss: 0.649846, acc.: 64.06%] [G loss: 0.944747]\n",
      "epoch:4 step:3805 [D loss: 0.651188, acc.: 65.62%] [G loss: 1.097391]\n",
      "epoch:4 step:3806 [D loss: 0.602708, acc.: 66.41%] [G loss: 1.162126]\n",
      "epoch:4 step:3807 [D loss: 0.622691, acc.: 64.84%] [G loss: 0.985855]\n",
      "epoch:4 step:3808 [D loss: 0.589164, acc.: 68.75%] [G loss: 1.041361]\n",
      "epoch:4 step:3809 [D loss: 0.621183, acc.: 63.28%] [G loss: 1.081966]\n",
      "epoch:4 step:3810 [D loss: 0.655300, acc.: 62.50%] [G loss: 1.034089]\n",
      "epoch:4 step:3811 [D loss: 0.696140, acc.: 59.38%] [G loss: 1.064454]\n",
      "epoch:4 step:3812 [D loss: 0.645685, acc.: 67.19%] [G loss: 0.987456]\n",
      "epoch:4 step:3813 [D loss: 0.620453, acc.: 64.06%] [G loss: 1.102783]\n",
      "epoch:4 step:3814 [D loss: 0.743389, acc.: 54.69%] [G loss: 0.956662]\n",
      "epoch:4 step:3815 [D loss: 0.714033, acc.: 54.69%] [G loss: 1.149153]\n",
      "epoch:4 step:3816 [D loss: 0.699762, acc.: 57.81%] [G loss: 1.002100]\n",
      "epoch:4 step:3817 [D loss: 0.667112, acc.: 59.38%] [G loss: 0.926522]\n",
      "epoch:4 step:3818 [D loss: 0.685433, acc.: 53.12%] [G loss: 1.146010]\n",
      "epoch:4 step:3819 [D loss: 0.648528, acc.: 64.06%] [G loss: 1.130522]\n",
      "epoch:4 step:3820 [D loss: 0.675278, acc.: 57.03%] [G loss: 0.966357]\n",
      "epoch:4 step:3821 [D loss: 0.560735, acc.: 71.09%] [G loss: 1.260952]\n",
      "epoch:4 step:3822 [D loss: 0.713600, acc.: 59.38%] [G loss: 0.964377]\n",
      "epoch:4 step:3823 [D loss: 0.657012, acc.: 57.03%] [G loss: 1.125324]\n",
      "epoch:4 step:3824 [D loss: 0.556456, acc.: 72.66%] [G loss: 1.169141]\n",
      "epoch:4 step:3825 [D loss: 0.690448, acc.: 57.03%] [G loss: 0.910623]\n",
      "epoch:4 step:3826 [D loss: 0.709440, acc.: 57.81%] [G loss: 1.103745]\n",
      "epoch:4 step:3827 [D loss: 0.622708, acc.: 64.84%] [G loss: 1.088843]\n",
      "epoch:4 step:3828 [D loss: 0.624018, acc.: 67.97%] [G loss: 1.057692]\n",
      "epoch:4 step:3829 [D loss: 0.676106, acc.: 61.72%] [G loss: 1.110147]\n",
      "epoch:4 step:3830 [D loss: 0.599676, acc.: 71.09%] [G loss: 0.931072]\n",
      "epoch:4 step:3831 [D loss: 0.714524, acc.: 57.03%] [G loss: 0.881301]\n",
      "epoch:4 step:3832 [D loss: 0.682455, acc.: 58.59%] [G loss: 0.941321]\n",
      "epoch:4 step:3833 [D loss: 0.597797, acc.: 68.75%] [G loss: 1.039891]\n",
      "epoch:4 step:3834 [D loss: 0.615888, acc.: 66.41%] [G loss: 1.112662]\n",
      "epoch:4 step:3835 [D loss: 0.724161, acc.: 55.47%] [G loss: 1.000531]\n",
      "epoch:4 step:3836 [D loss: 0.677801, acc.: 53.12%] [G loss: 0.897361]\n",
      "epoch:4 step:3837 [D loss: 0.699213, acc.: 53.12%] [G loss: 0.984179]\n",
      "epoch:4 step:3838 [D loss: 0.624611, acc.: 64.06%] [G loss: 0.897612]\n",
      "epoch:4 step:3839 [D loss: 0.640704, acc.: 64.84%] [G loss: 1.020213]\n",
      "epoch:4 step:3840 [D loss: 0.753173, acc.: 53.91%] [G loss: 0.897427]\n",
      "epoch:4 step:3841 [D loss: 0.608027, acc.: 67.19%] [G loss: 0.999439]\n",
      "epoch:4 step:3842 [D loss: 0.667031, acc.: 64.06%] [G loss: 1.038319]\n",
      "epoch:4 step:3843 [D loss: 0.655151, acc.: 62.50%] [G loss: 1.094734]\n",
      "epoch:4 step:3844 [D loss: 0.588817, acc.: 67.97%] [G loss: 1.004102]\n",
      "epoch:4 step:3845 [D loss: 0.724041, acc.: 53.12%] [G loss: 1.055321]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:4 step:3846 [D loss: 0.569078, acc.: 70.31%] [G loss: 0.988453]\n",
      "epoch:4 step:3847 [D loss: 0.649764, acc.: 60.94%] [G loss: 0.984525]\n",
      "epoch:4 step:3848 [D loss: 0.715030, acc.: 58.59%] [G loss: 1.003686]\n",
      "epoch:4 step:3849 [D loss: 0.618746, acc.: 64.84%] [G loss: 0.870207]\n",
      "epoch:4 step:3850 [D loss: 0.650510, acc.: 62.50%] [G loss: 0.999450]\n",
      "epoch:4 step:3851 [D loss: 0.582441, acc.: 70.31%] [G loss: 1.103145]\n",
      "epoch:4 step:3852 [D loss: 0.648420, acc.: 65.62%] [G loss: 0.972988]\n",
      "epoch:4 step:3853 [D loss: 0.591599, acc.: 71.09%] [G loss: 0.974846]\n",
      "epoch:4 step:3854 [D loss: 0.620769, acc.: 64.06%] [G loss: 1.134577]\n",
      "epoch:4 step:3855 [D loss: 0.583196, acc.: 71.09%] [G loss: 1.199785]\n",
      "epoch:4 step:3856 [D loss: 0.588908, acc.: 67.97%] [G loss: 1.072202]\n",
      "epoch:4 step:3857 [D loss: 0.667191, acc.: 56.25%] [G loss: 1.196736]\n",
      "epoch:4 step:3858 [D loss: 0.696976, acc.: 58.59%] [G loss: 1.067247]\n",
      "epoch:4 step:3859 [D loss: 0.635344, acc.: 64.84%] [G loss: 1.002058]\n",
      "epoch:4 step:3860 [D loss: 0.731093, acc.: 47.66%] [G loss: 1.149124]\n",
      "epoch:4 step:3861 [D loss: 0.679258, acc.: 58.59%] [G loss: 0.946228]\n",
      "epoch:4 step:3862 [D loss: 0.688119, acc.: 58.59%] [G loss: 0.935947]\n",
      "epoch:4 step:3863 [D loss: 0.657985, acc.: 64.84%] [G loss: 1.169501]\n",
      "epoch:4 step:3864 [D loss: 0.640833, acc.: 65.62%] [G loss: 0.991206]\n",
      "epoch:4 step:3865 [D loss: 0.661419, acc.: 59.38%] [G loss: 1.022674]\n",
      "epoch:4 step:3866 [D loss: 0.588728, acc.: 69.53%] [G loss: 1.075401]\n",
      "epoch:4 step:3867 [D loss: 0.688891, acc.: 57.81%] [G loss: 0.965037]\n",
      "epoch:4 step:3868 [D loss: 0.634825, acc.: 60.16%] [G loss: 1.051257]\n",
      "epoch:4 step:3869 [D loss: 0.684176, acc.: 60.94%] [G loss: 1.055702]\n",
      "epoch:4 step:3870 [D loss: 0.664087, acc.: 60.16%] [G loss: 1.136139]\n",
      "epoch:4 step:3871 [D loss: 0.690448, acc.: 56.25%] [G loss: 0.956669]\n",
      "epoch:4 step:3872 [D loss: 0.598978, acc.: 66.41%] [G loss: 1.300163]\n",
      "epoch:4 step:3873 [D loss: 0.532225, acc.: 78.91%] [G loss: 1.059277]\n",
      "epoch:4 step:3874 [D loss: 0.692991, acc.: 56.25%] [G loss: 1.133990]\n",
      "epoch:4 step:3875 [D loss: 0.618609, acc.: 65.62%] [G loss: 1.012963]\n",
      "epoch:4 step:3876 [D loss: 0.643650, acc.: 62.50%] [G loss: 1.089766]\n",
      "epoch:4 step:3877 [D loss: 0.665331, acc.: 63.28%] [G loss: 1.211411]\n",
      "epoch:4 step:3878 [D loss: 0.676863, acc.: 57.03%] [G loss: 1.047233]\n",
      "epoch:4 step:3879 [D loss: 0.607340, acc.: 68.75%] [G loss: 1.121977]\n",
      "epoch:4 step:3880 [D loss: 0.665093, acc.: 61.72%] [G loss: 1.106804]\n",
      "epoch:4 step:3881 [D loss: 0.740094, acc.: 53.12%] [G loss: 1.016809]\n",
      "epoch:4 step:3882 [D loss: 0.641255, acc.: 66.41%] [G loss: 1.112152]\n",
      "epoch:4 step:3883 [D loss: 0.706538, acc.: 59.38%] [G loss: 0.875190]\n",
      "epoch:4 step:3884 [D loss: 0.701369, acc.: 54.69%] [G loss: 1.069495]\n",
      "epoch:4 step:3885 [D loss: 0.674060, acc.: 57.81%] [G loss: 0.962790]\n",
      "epoch:4 step:3886 [D loss: 0.635660, acc.: 60.94%] [G loss: 1.072578]\n",
      "epoch:4 step:3887 [D loss: 0.596614, acc.: 72.66%] [G loss: 0.975132]\n",
      "epoch:4 step:3888 [D loss: 0.628033, acc.: 65.62%] [G loss: 1.126136]\n",
      "epoch:4 step:3889 [D loss: 0.660582, acc.: 60.16%] [G loss: 1.038609]\n",
      "epoch:4 step:3890 [D loss: 0.600789, acc.: 69.53%] [G loss: 0.986724]\n",
      "epoch:4 step:3891 [D loss: 0.637163, acc.: 60.16%] [G loss: 0.884202]\n",
      "epoch:4 step:3892 [D loss: 0.680118, acc.: 59.38%] [G loss: 0.821682]\n",
      "epoch:4 step:3893 [D loss: 0.723453, acc.: 54.69%] [G loss: 1.045822]\n",
      "epoch:4 step:3894 [D loss: 0.547330, acc.: 75.00%] [G loss: 1.062753]\n",
      "epoch:4 step:3895 [D loss: 0.607952, acc.: 62.50%] [G loss: 0.995275]\n",
      "epoch:4 step:3896 [D loss: 0.639008, acc.: 62.50%] [G loss: 1.053390]\n",
      "epoch:4 step:3897 [D loss: 0.676221, acc.: 57.81%] [G loss: 0.949134]\n",
      "epoch:4 step:3898 [D loss: 0.651268, acc.: 57.81%] [G loss: 0.932289]\n",
      "epoch:4 step:3899 [D loss: 0.604696, acc.: 67.97%] [G loss: 1.052663]\n",
      "epoch:4 step:3900 [D loss: 0.737032, acc.: 50.78%] [G loss: 0.910915]\n",
      "epoch:4 step:3901 [D loss: 0.575773, acc.: 71.09%] [G loss: 1.097380]\n",
      "epoch:4 step:3902 [D loss: 0.639721, acc.: 66.41%] [G loss: 0.985702]\n",
      "epoch:4 step:3903 [D loss: 0.691265, acc.: 60.94%] [G loss: 0.993204]\n",
      "epoch:4 step:3904 [D loss: 0.648271, acc.: 61.72%] [G loss: 1.119905]\n",
      "epoch:4 step:3905 [D loss: 0.681354, acc.: 57.03%] [G loss: 1.077516]\n",
      "epoch:4 step:3906 [D loss: 0.585769, acc.: 67.97%] [G loss: 1.170982]\n",
      "epoch:4 step:3907 [D loss: 0.607071, acc.: 71.88%] [G loss: 1.094796]\n",
      "epoch:4 step:3908 [D loss: 0.699635, acc.: 53.12%] [G loss: 1.043022]\n",
      "epoch:4 step:3909 [D loss: 0.623766, acc.: 59.38%] [G loss: 1.086081]\n",
      "epoch:4 step:3910 [D loss: 0.689413, acc.: 57.81%] [G loss: 1.198790]\n",
      "epoch:4 step:3911 [D loss: 0.686006, acc.: 56.25%] [G loss: 1.186147]\n",
      "epoch:4 step:3912 [D loss: 0.581730, acc.: 71.88%] [G loss: 1.034220]\n",
      "epoch:4 step:3913 [D loss: 0.705736, acc.: 50.00%] [G loss: 0.822881]\n",
      "epoch:4 step:3914 [D loss: 0.623229, acc.: 71.09%] [G loss: 0.905112]\n",
      "epoch:4 step:3915 [D loss: 0.595039, acc.: 69.53%] [G loss: 0.988564]\n",
      "epoch:4 step:3916 [D loss: 0.637689, acc.: 65.62%] [G loss: 1.014719]\n",
      "epoch:4 step:3917 [D loss: 0.709201, acc.: 55.47%] [G loss: 0.937536]\n",
      "epoch:4 step:3918 [D loss: 0.597442, acc.: 67.19%] [G loss: 1.120933]\n",
      "epoch:4 step:3919 [D loss: 0.675838, acc.: 57.81%] [G loss: 0.983619]\n",
      "epoch:4 step:3920 [D loss: 0.589754, acc.: 63.28%] [G loss: 1.118197]\n",
      "epoch:4 step:3921 [D loss: 0.670923, acc.: 58.59%] [G loss: 0.849227]\n",
      "epoch:4 step:3922 [D loss: 0.559997, acc.: 74.22%] [G loss: 1.037760]\n",
      "epoch:4 step:3923 [D loss: 0.563000, acc.: 70.31%] [G loss: 1.148834]\n",
      "epoch:4 step:3924 [D loss: 0.690806, acc.: 57.03%] [G loss: 1.053187]\n",
      "epoch:4 step:3925 [D loss: 0.605579, acc.: 68.75%] [G loss: 1.033299]\n",
      "epoch:4 step:3926 [D loss: 0.596563, acc.: 65.62%] [G loss: 1.011557]\n",
      "epoch:4 step:3927 [D loss: 0.710366, acc.: 53.12%] [G loss: 0.941874]\n",
      "epoch:4 step:3928 [D loss: 0.621888, acc.: 59.38%] [G loss: 1.140974]\n",
      "epoch:4 step:3929 [D loss: 0.642166, acc.: 67.97%] [G loss: 0.967033]\n",
      "epoch:4 step:3930 [D loss: 0.645448, acc.: 61.72%] [G loss: 1.138126]\n",
      "epoch:4 step:3931 [D loss: 0.700303, acc.: 57.03%] [G loss: 1.027385]\n",
      "epoch:4 step:3932 [D loss: 0.634945, acc.: 64.06%] [G loss: 1.226421]\n",
      "epoch:4 step:3933 [D loss: 0.614829, acc.: 68.75%] [G loss: 1.070625]\n",
      "epoch:4 step:3934 [D loss: 0.666227, acc.: 61.72%] [G loss: 1.148488]\n",
      "epoch:4 step:3935 [D loss: 0.653948, acc.: 63.28%] [G loss: 1.098044]\n",
      "epoch:4 step:3936 [D loss: 0.636595, acc.: 66.41%] [G loss: 1.092592]\n",
      "epoch:4 step:3937 [D loss: 0.631128, acc.: 68.75%] [G loss: 1.052401]\n",
      "epoch:4 step:3938 [D loss: 0.633130, acc.: 60.94%] [G loss: 1.145699]\n",
      "epoch:4 step:3939 [D loss: 0.594125, acc.: 70.31%] [G loss: 1.015124]\n",
      "epoch:4 step:3940 [D loss: 0.656576, acc.: 63.28%] [G loss: 0.934186]\n",
      "epoch:4 step:3941 [D loss: 0.700779, acc.: 54.69%] [G loss: 1.153460]\n",
      "epoch:4 step:3942 [D loss: 0.700385, acc.: 57.81%] [G loss: 1.010979]\n",
      "epoch:4 step:3943 [D loss: 0.669320, acc.: 57.81%] [G loss: 1.147135]\n",
      "epoch:4 step:3944 [D loss: 0.643759, acc.: 66.41%] [G loss: 0.942428]\n",
      "epoch:4 step:3945 [D loss: 0.666082, acc.: 60.16%] [G loss: 0.941641]\n",
      "epoch:4 step:3946 [D loss: 0.706522, acc.: 55.47%] [G loss: 1.168189]\n",
      "epoch:4 step:3947 [D loss: 0.624393, acc.: 65.62%] [G loss: 0.946443]\n",
      "epoch:4 step:3948 [D loss: 0.688303, acc.: 59.38%] [G loss: 0.953923]\n",
      "epoch:4 step:3949 [D loss: 0.548996, acc.: 75.00%] [G loss: 1.095848]\n",
      "epoch:4 step:3950 [D loss: 0.532354, acc.: 75.00%] [G loss: 1.151416]\n",
      "epoch:4 step:3951 [D loss: 0.612287, acc.: 67.97%] [G loss: 1.080113]\n",
      "epoch:4 step:3952 [D loss: 0.627247, acc.: 65.62%] [G loss: 1.075489]\n",
      "epoch:4 step:3953 [D loss: 0.708424, acc.: 55.47%] [G loss: 1.025079]\n",
      "epoch:4 step:3954 [D loss: 0.697942, acc.: 60.94%] [G loss: 1.022257]\n",
      "epoch:4 step:3955 [D loss: 0.687322, acc.: 56.25%] [G loss: 1.034617]\n",
      "epoch:4 step:3956 [D loss: 0.587815, acc.: 74.22%] [G loss: 1.145483]\n",
      "epoch:4 step:3957 [D loss: 0.674350, acc.: 58.59%] [G loss: 1.114184]\n",
      "epoch:4 step:3958 [D loss: 0.721503, acc.: 46.88%] [G loss: 1.010457]\n",
      "epoch:4 step:3959 [D loss: 0.629411, acc.: 64.06%] [G loss: 1.013747]\n",
      "epoch:4 step:3960 [D loss: 0.643811, acc.: 59.38%] [G loss: 0.999804]\n",
      "epoch:4 step:3961 [D loss: 0.681337, acc.: 59.38%] [G loss: 0.944630]\n",
      "epoch:4 step:3962 [D loss: 0.649631, acc.: 62.50%] [G loss: 0.976146]\n",
      "epoch:4 step:3963 [D loss: 0.640299, acc.: 64.06%] [G loss: 0.949717]\n",
      "epoch:4 step:3964 [D loss: 0.681253, acc.: 60.16%] [G loss: 0.969341]\n",
      "epoch:4 step:3965 [D loss: 0.573360, acc.: 72.66%] [G loss: 1.093315]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:4 step:3966 [D loss: 0.660620, acc.: 56.25%] [G loss: 1.021394]\n",
      "epoch:4 step:3967 [D loss: 0.657987, acc.: 58.59%] [G loss: 1.008745]\n",
      "epoch:4 step:3968 [D loss: 0.636068, acc.: 64.84%] [G loss: 0.959963]\n",
      "epoch:4 step:3969 [D loss: 0.606713, acc.: 70.31%] [G loss: 1.058301]\n",
      "epoch:4 step:3970 [D loss: 0.598400, acc.: 70.31%] [G loss: 1.102853]\n",
      "epoch:4 step:3971 [D loss: 0.644779, acc.: 61.72%] [G loss: 0.982659]\n",
      "epoch:4 step:3972 [D loss: 0.704309, acc.: 53.12%] [G loss: 1.034503]\n",
      "epoch:4 step:3973 [D loss: 0.713229, acc.: 55.47%] [G loss: 0.980140]\n",
      "epoch:4 step:3974 [D loss: 0.664031, acc.: 59.38%] [G loss: 1.154223]\n",
      "epoch:4 step:3975 [D loss: 0.579208, acc.: 69.53%] [G loss: 1.017563]\n",
      "epoch:4 step:3976 [D loss: 0.663474, acc.: 59.38%] [G loss: 1.035262]\n",
      "epoch:4 step:3977 [D loss: 0.606531, acc.: 67.97%] [G loss: 1.108315]\n",
      "epoch:4 step:3978 [D loss: 0.682547, acc.: 56.25%] [G loss: 1.191114]\n",
      "epoch:4 step:3979 [D loss: 0.624590, acc.: 64.84%] [G loss: 0.986368]\n",
      "epoch:4 step:3980 [D loss: 0.603848, acc.: 67.19%] [G loss: 1.081133]\n",
      "epoch:4 step:3981 [D loss: 0.697773, acc.: 56.25%] [G loss: 0.881845]\n",
      "epoch:4 step:3982 [D loss: 0.756740, acc.: 49.22%] [G loss: 1.102892]\n",
      "epoch:4 step:3983 [D loss: 0.586298, acc.: 75.00%] [G loss: 1.110716]\n",
      "epoch:4 step:3984 [D loss: 0.604724, acc.: 65.62%] [G loss: 1.043493]\n",
      "epoch:4 step:3985 [D loss: 0.645178, acc.: 64.84%] [G loss: 1.049396]\n",
      "epoch:4 step:3986 [D loss: 0.664586, acc.: 64.06%] [G loss: 1.067049]\n",
      "epoch:4 step:3987 [D loss: 0.679866, acc.: 53.12%] [G loss: 1.037317]\n",
      "epoch:4 step:3988 [D loss: 0.665214, acc.: 57.03%] [G loss: 0.941751]\n",
      "epoch:4 step:3989 [D loss: 0.670689, acc.: 58.59%] [G loss: 0.950437]\n",
      "epoch:4 step:3990 [D loss: 0.596014, acc.: 67.97%] [G loss: 1.211049]\n",
      "epoch:4 step:3991 [D loss: 0.682111, acc.: 57.81%] [G loss: 1.054066]\n",
      "epoch:4 step:3992 [D loss: 0.616016, acc.: 64.06%] [G loss: 0.913012]\n",
      "epoch:4 step:3993 [D loss: 0.644388, acc.: 62.50%] [G loss: 0.974205]\n",
      "epoch:4 step:3994 [D loss: 0.610611, acc.: 70.31%] [G loss: 1.011163]\n",
      "epoch:4 step:3995 [D loss: 0.635758, acc.: 60.16%] [G loss: 1.039650]\n",
      "epoch:4 step:3996 [D loss: 0.570633, acc.: 71.09%] [G loss: 1.008566]\n",
      "epoch:4 step:3997 [D loss: 0.639798, acc.: 65.62%] [G loss: 1.027066]\n",
      "epoch:4 step:3998 [D loss: 0.666392, acc.: 54.69%] [G loss: 1.089148]\n",
      "epoch:4 step:3999 [D loss: 0.605036, acc.: 65.62%] [G loss: 1.002776]\n",
      "epoch:4 step:4000 [D loss: 0.575321, acc.: 71.88%] [G loss: 1.004022]\n",
      "epoch:4 step:4001 [D loss: 0.636467, acc.: 66.41%] [G loss: 1.019560]\n",
      "epoch:4 step:4002 [D loss: 0.720652, acc.: 56.25%] [G loss: 1.068893]\n",
      "epoch:4 step:4003 [D loss: 0.672439, acc.: 56.25%] [G loss: 1.042973]\n",
      "epoch:4 step:4004 [D loss: 0.689668, acc.: 60.94%] [G loss: 0.962400]\n",
      "epoch:4 step:4005 [D loss: 0.621393, acc.: 65.62%] [G loss: 1.118899]\n",
      "epoch:4 step:4006 [D loss: 0.683455, acc.: 59.38%] [G loss: 1.024730]\n",
      "epoch:4 step:4007 [D loss: 0.625211, acc.: 67.19%] [G loss: 0.987755]\n",
      "epoch:4 step:4008 [D loss: 0.740490, acc.: 50.00%] [G loss: 0.964850]\n",
      "epoch:4 step:4009 [D loss: 0.626630, acc.: 58.59%] [G loss: 1.254581]\n",
      "epoch:4 step:4010 [D loss: 0.668667, acc.: 54.69%] [G loss: 1.188818]\n",
      "epoch:4 step:4011 [D loss: 0.658537, acc.: 64.84%] [G loss: 0.972603]\n",
      "epoch:4 step:4012 [D loss: 0.648729, acc.: 61.72%] [G loss: 0.945637]\n",
      "epoch:4 step:4013 [D loss: 0.659351, acc.: 64.06%] [G loss: 1.153931]\n",
      "epoch:4 step:4014 [D loss: 0.576901, acc.: 65.62%] [G loss: 1.043643]\n",
      "epoch:4 step:4015 [D loss: 0.679855, acc.: 55.47%] [G loss: 0.886555]\n",
      "epoch:4 step:4016 [D loss: 0.606939, acc.: 69.53%] [G loss: 0.931931]\n",
      "epoch:4 step:4017 [D loss: 0.665257, acc.: 64.06%] [G loss: 1.221732]\n",
      "epoch:4 step:4018 [D loss: 0.621994, acc.: 60.94%] [G loss: 1.105153]\n",
      "epoch:4 step:4019 [D loss: 0.632337, acc.: 69.53%] [G loss: 1.051627]\n",
      "epoch:4 step:4020 [D loss: 0.627720, acc.: 62.50%] [G loss: 1.202967]\n",
      "epoch:4 step:4021 [D loss: 0.621417, acc.: 62.50%] [G loss: 1.188497]\n",
      "epoch:4 step:4022 [D loss: 0.660755, acc.: 57.81%] [G loss: 0.912807]\n",
      "epoch:4 step:4023 [D loss: 0.764260, acc.: 51.56%] [G loss: 0.952682]\n",
      "epoch:4 step:4024 [D loss: 0.660824, acc.: 62.50%] [G loss: 0.947188]\n",
      "epoch:4 step:4025 [D loss: 0.640068, acc.: 62.50%] [G loss: 0.967489]\n",
      "epoch:4 step:4026 [D loss: 0.622907, acc.: 64.84%] [G loss: 1.116756]\n",
      "epoch:4 step:4027 [D loss: 0.633792, acc.: 70.31%] [G loss: 1.064478]\n",
      "epoch:4 step:4028 [D loss: 0.670962, acc.: 60.94%] [G loss: 1.084965]\n",
      "epoch:4 step:4029 [D loss: 0.656976, acc.: 66.41%] [G loss: 1.068449]\n",
      "epoch:4 step:4030 [D loss: 0.591872, acc.: 68.75%] [G loss: 1.144118]\n",
      "epoch:4 step:4031 [D loss: 0.620887, acc.: 69.53%] [G loss: 1.006080]\n",
      "epoch:4 step:4032 [D loss: 0.608430, acc.: 63.28%] [G loss: 1.131820]\n",
      "epoch:4 step:4033 [D loss: 0.670641, acc.: 57.81%] [G loss: 1.129047]\n",
      "epoch:4 step:4034 [D loss: 0.620748, acc.: 64.06%] [G loss: 1.083654]\n",
      "epoch:4 step:4035 [D loss: 0.594041, acc.: 65.62%] [G loss: 1.228703]\n",
      "epoch:4 step:4036 [D loss: 0.641078, acc.: 61.72%] [G loss: 1.030551]\n",
      "epoch:4 step:4037 [D loss: 0.618576, acc.: 68.75%] [G loss: 1.189546]\n",
      "epoch:4 step:4038 [D loss: 0.657351, acc.: 60.94%] [G loss: 1.054390]\n",
      "epoch:4 step:4039 [D loss: 0.640861, acc.: 66.41%] [G loss: 1.028620]\n",
      "epoch:4 step:4040 [D loss: 0.685746, acc.: 53.91%] [G loss: 1.086933]\n",
      "epoch:4 step:4041 [D loss: 0.658552, acc.: 66.41%] [G loss: 1.088562]\n",
      "epoch:4 step:4042 [D loss: 0.557769, acc.: 73.44%] [G loss: 1.200250]\n",
      "epoch:4 step:4043 [D loss: 0.708371, acc.: 56.25%] [G loss: 1.108822]\n",
      "epoch:4 step:4044 [D loss: 0.595291, acc.: 69.53%] [G loss: 1.013292]\n",
      "epoch:4 step:4045 [D loss: 0.694511, acc.: 57.81%] [G loss: 0.848695]\n",
      "epoch:4 step:4046 [D loss: 0.661112, acc.: 64.84%] [G loss: 0.985409]\n",
      "epoch:4 step:4047 [D loss: 0.681796, acc.: 58.59%] [G loss: 1.142138]\n",
      "epoch:4 step:4048 [D loss: 0.668028, acc.: 59.38%] [G loss: 1.000204]\n",
      "epoch:4 step:4049 [D loss: 0.673713, acc.: 62.50%] [G loss: 1.221168]\n",
      "epoch:4 step:4050 [D loss: 0.657509, acc.: 62.50%] [G loss: 1.166284]\n",
      "epoch:4 step:4051 [D loss: 0.753457, acc.: 47.66%] [G loss: 0.954859]\n",
      "epoch:4 step:4052 [D loss: 0.647638, acc.: 64.06%] [G loss: 0.968024]\n",
      "epoch:4 step:4053 [D loss: 0.697386, acc.: 57.03%] [G loss: 1.019070]\n",
      "epoch:4 step:4054 [D loss: 0.565905, acc.: 74.22%] [G loss: 1.071972]\n",
      "epoch:4 step:4055 [D loss: 0.714979, acc.: 56.25%] [G loss: 0.942263]\n",
      "epoch:4 step:4056 [D loss: 0.625097, acc.: 65.62%] [G loss: 1.268904]\n",
      "epoch:4 step:4057 [D loss: 0.629575, acc.: 69.53%] [G loss: 1.057393]\n",
      "epoch:4 step:4058 [D loss: 0.682420, acc.: 57.03%] [G loss: 0.943660]\n",
      "epoch:4 step:4059 [D loss: 0.629263, acc.: 64.84%] [G loss: 1.097400]\n",
      "epoch:4 step:4060 [D loss: 0.690417, acc.: 60.16%] [G loss: 1.149116]\n",
      "epoch:4 step:4061 [D loss: 0.694247, acc.: 60.94%] [G loss: 1.116397]\n",
      "epoch:4 step:4062 [D loss: 0.650364, acc.: 59.38%] [G loss: 1.078449]\n",
      "epoch:4 step:4063 [D loss: 0.681229, acc.: 59.38%] [G loss: 1.043816]\n",
      "epoch:4 step:4064 [D loss: 0.758911, acc.: 47.66%] [G loss: 0.870725]\n",
      "epoch:4 step:4065 [D loss: 0.637142, acc.: 57.81%] [G loss: 1.140942]\n",
      "epoch:4 step:4066 [D loss: 0.721283, acc.: 55.47%] [G loss: 1.049020]\n",
      "epoch:4 step:4067 [D loss: 0.596519, acc.: 71.09%] [G loss: 0.982810]\n",
      "epoch:4 step:4068 [D loss: 0.611676, acc.: 64.84%] [G loss: 1.234363]\n",
      "epoch:4 step:4069 [D loss: 0.682565, acc.: 57.81%] [G loss: 0.975332]\n",
      "epoch:4 step:4070 [D loss: 0.656056, acc.: 57.81%] [G loss: 1.003138]\n",
      "epoch:4 step:4071 [D loss: 0.689999, acc.: 58.59%] [G loss: 0.952226]\n",
      "epoch:4 step:4072 [D loss: 0.636965, acc.: 65.62%] [G loss: 1.137661]\n",
      "epoch:4 step:4073 [D loss: 0.619261, acc.: 64.06%] [G loss: 1.036023]\n",
      "epoch:4 step:4074 [D loss: 0.589396, acc.: 70.31%] [G loss: 1.077234]\n",
      "epoch:4 step:4075 [D loss: 0.645923, acc.: 61.72%] [G loss: 1.048871]\n",
      "epoch:4 step:4076 [D loss: 0.613314, acc.: 66.41%] [G loss: 1.154356]\n",
      "epoch:4 step:4077 [D loss: 0.730672, acc.: 56.25%] [G loss: 1.022453]\n",
      "epoch:4 step:4078 [D loss: 0.652491, acc.: 57.03%] [G loss: 0.978104]\n",
      "epoch:4 step:4079 [D loss: 0.653365, acc.: 57.81%] [G loss: 1.153300]\n",
      "epoch:4 step:4080 [D loss: 0.581404, acc.: 75.00%] [G loss: 1.066371]\n",
      "epoch:4 step:4081 [D loss: 0.580658, acc.: 64.84%] [G loss: 1.073933]\n",
      "epoch:4 step:4082 [D loss: 0.689112, acc.: 55.47%] [G loss: 0.893033]\n",
      "epoch:4 step:4083 [D loss: 0.557208, acc.: 74.22%] [G loss: 1.043060]\n",
      "epoch:4 step:4084 [D loss: 0.640145, acc.: 60.16%] [G loss: 0.897915]\n",
      "epoch:4 step:4085 [D loss: 0.623643, acc.: 63.28%] [G loss: 1.030228]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:4 step:4086 [D loss: 0.626385, acc.: 67.97%] [G loss: 1.196937]\n",
      "epoch:4 step:4087 [D loss: 0.606504, acc.: 64.84%] [G loss: 0.953665]\n",
      "epoch:4 step:4088 [D loss: 0.592645, acc.: 66.41%] [G loss: 1.060499]\n",
      "epoch:4 step:4089 [D loss: 0.618114, acc.: 62.50%] [G loss: 1.198195]\n",
      "epoch:4 step:4090 [D loss: 0.663363, acc.: 59.38%] [G loss: 0.970966]\n",
      "epoch:4 step:4091 [D loss: 0.630822, acc.: 66.41%] [G loss: 0.989437]\n",
      "epoch:4 step:4092 [D loss: 0.608677, acc.: 65.62%] [G loss: 0.989977]\n",
      "epoch:4 step:4093 [D loss: 0.665072, acc.: 59.38%] [G loss: 1.043843]\n",
      "epoch:4 step:4094 [D loss: 0.630536, acc.: 67.19%] [G loss: 1.044899]\n",
      "epoch:4 step:4095 [D loss: 0.664127, acc.: 60.16%] [G loss: 0.860102]\n",
      "epoch:4 step:4096 [D loss: 0.788387, acc.: 41.41%] [G loss: 0.973411]\n",
      "epoch:4 step:4097 [D loss: 0.688916, acc.: 55.47%] [G loss: 0.978828]\n",
      "epoch:4 step:4098 [D loss: 0.649968, acc.: 58.59%] [G loss: 0.972657]\n",
      "epoch:4 step:4099 [D loss: 0.631823, acc.: 67.19%] [G loss: 0.912800]\n",
      "epoch:4 step:4100 [D loss: 0.643544, acc.: 60.94%] [G loss: 0.992798]\n",
      "epoch:4 step:4101 [D loss: 0.696990, acc.: 56.25%] [G loss: 0.990986]\n",
      "epoch:4 step:4102 [D loss: 0.648327, acc.: 60.16%] [G loss: 1.028269]\n",
      "epoch:4 step:4103 [D loss: 0.601422, acc.: 68.75%] [G loss: 1.367688]\n",
      "epoch:4 step:4104 [D loss: 0.661678, acc.: 59.38%] [G loss: 0.996334]\n",
      "epoch:4 step:4105 [D loss: 0.683241, acc.: 59.38%] [G loss: 1.091280]\n",
      "epoch:4 step:4106 [D loss: 0.640599, acc.: 63.28%] [G loss: 0.980391]\n",
      "epoch:4 step:4107 [D loss: 0.643042, acc.: 64.06%] [G loss: 0.935476]\n",
      "epoch:4 step:4108 [D loss: 0.622347, acc.: 66.41%] [G loss: 0.962568]\n",
      "epoch:4 step:4109 [D loss: 0.624995, acc.: 64.84%] [G loss: 1.024363]\n",
      "epoch:4 step:4110 [D loss: 0.709327, acc.: 58.59%] [G loss: 1.043514]\n",
      "epoch:4 step:4111 [D loss: 0.660306, acc.: 57.03%] [G loss: 1.142190]\n",
      "epoch:4 step:4112 [D loss: 0.582071, acc.: 69.53%] [G loss: 1.097992]\n",
      "epoch:4 step:4113 [D loss: 0.679749, acc.: 57.03%] [G loss: 1.097617]\n",
      "epoch:4 step:4114 [D loss: 0.606934, acc.: 64.84%] [G loss: 1.086865]\n",
      "epoch:4 step:4115 [D loss: 0.686356, acc.: 58.59%] [G loss: 1.008058]\n",
      "epoch:4 step:4116 [D loss: 0.614087, acc.: 64.06%] [G loss: 0.911235]\n",
      "epoch:4 step:4117 [D loss: 0.737231, acc.: 51.56%] [G loss: 1.096982]\n",
      "epoch:4 step:4118 [D loss: 0.641070, acc.: 64.06%] [G loss: 1.067892]\n",
      "epoch:4 step:4119 [D loss: 0.562037, acc.: 70.31%] [G loss: 1.152639]\n",
      "epoch:4 step:4120 [D loss: 0.707476, acc.: 56.25%] [G loss: 0.953865]\n",
      "epoch:4 step:4121 [D loss: 0.639401, acc.: 63.28%] [G loss: 1.165468]\n",
      "epoch:4 step:4122 [D loss: 0.657096, acc.: 64.84%] [G loss: 0.891264]\n",
      "epoch:4 step:4123 [D loss: 0.706624, acc.: 53.91%] [G loss: 1.068937]\n",
      "epoch:4 step:4124 [D loss: 0.721181, acc.: 48.44%] [G loss: 0.895930]\n",
      "epoch:4 step:4125 [D loss: 0.644958, acc.: 66.41%] [G loss: 1.059510]\n",
      "epoch:4 step:4126 [D loss: 0.693269, acc.: 54.69%] [G loss: 0.947107]\n",
      "epoch:4 step:4127 [D loss: 0.665256, acc.: 57.81%] [G loss: 1.082173]\n",
      "epoch:4 step:4128 [D loss: 0.776966, acc.: 50.00%] [G loss: 1.103927]\n",
      "epoch:4 step:4129 [D loss: 0.660468, acc.: 59.38%] [G loss: 0.993607]\n",
      "epoch:4 step:4130 [D loss: 0.641693, acc.: 62.50%] [G loss: 0.933492]\n",
      "epoch:4 step:4131 [D loss: 0.583828, acc.: 68.75%] [G loss: 1.075152]\n",
      "epoch:4 step:4132 [D loss: 0.622189, acc.: 63.28%] [G loss: 1.080580]\n",
      "epoch:4 step:4133 [D loss: 0.604900, acc.: 62.50%] [G loss: 1.010036]\n",
      "epoch:4 step:4134 [D loss: 0.631758, acc.: 64.06%] [G loss: 1.006258]\n",
      "epoch:4 step:4135 [D loss: 0.568639, acc.: 68.75%] [G loss: 1.129530]\n",
      "epoch:4 step:4136 [D loss: 0.583710, acc.: 70.31%] [G loss: 1.167080]\n",
      "epoch:4 step:4137 [D loss: 0.582515, acc.: 67.19%] [G loss: 1.091939]\n",
      "epoch:4 step:4138 [D loss: 0.656771, acc.: 61.72%] [G loss: 0.964102]\n",
      "epoch:4 step:4139 [D loss: 0.669042, acc.: 59.38%] [G loss: 0.915774]\n",
      "epoch:4 step:4140 [D loss: 0.644432, acc.: 60.16%] [G loss: 0.945451]\n",
      "epoch:4 step:4141 [D loss: 0.672466, acc.: 60.16%] [G loss: 0.979690]\n",
      "epoch:4 step:4142 [D loss: 0.661624, acc.: 60.16%] [G loss: 0.968030]\n",
      "epoch:4 step:4143 [D loss: 0.623202, acc.: 60.94%] [G loss: 1.121281]\n",
      "epoch:4 step:4144 [D loss: 0.592005, acc.: 71.09%] [G loss: 1.185619]\n",
      "epoch:4 step:4145 [D loss: 0.641125, acc.: 64.84%] [G loss: 1.108396]\n",
      "epoch:4 step:4146 [D loss: 0.686643, acc.: 57.03%] [G loss: 0.998110]\n",
      "epoch:4 step:4147 [D loss: 0.534151, acc.: 70.31%] [G loss: 1.053515]\n",
      "epoch:4 step:4148 [D loss: 0.671941, acc.: 60.16%] [G loss: 1.038500]\n",
      "epoch:4 step:4149 [D loss: 0.644424, acc.: 64.84%] [G loss: 1.158055]\n",
      "epoch:4 step:4150 [D loss: 0.621830, acc.: 64.06%] [G loss: 1.071783]\n",
      "epoch:4 step:4151 [D loss: 0.613935, acc.: 67.19%] [G loss: 1.127210]\n",
      "epoch:4 step:4152 [D loss: 0.724237, acc.: 54.69%] [G loss: 1.038151]\n",
      "epoch:4 step:4153 [D loss: 0.711318, acc.: 57.81%] [G loss: 0.940865]\n",
      "epoch:4 step:4154 [D loss: 0.530114, acc.: 74.22%] [G loss: 1.245901]\n",
      "epoch:4 step:4155 [D loss: 0.571584, acc.: 71.88%] [G loss: 1.232072]\n",
      "epoch:4 step:4156 [D loss: 0.679261, acc.: 62.50%] [G loss: 1.091033]\n",
      "epoch:4 step:4157 [D loss: 0.609216, acc.: 67.97%] [G loss: 1.028316]\n",
      "epoch:4 step:4158 [D loss: 0.678001, acc.: 60.94%] [G loss: 0.898686]\n",
      "epoch:4 step:4159 [D loss: 0.593835, acc.: 69.53%] [G loss: 0.979543]\n",
      "epoch:4 step:4160 [D loss: 0.663028, acc.: 61.72%] [G loss: 0.939658]\n",
      "epoch:4 step:4161 [D loss: 0.694155, acc.: 52.34%] [G loss: 0.962933]\n",
      "epoch:4 step:4162 [D loss: 0.637706, acc.: 63.28%] [G loss: 1.087364]\n",
      "epoch:4 step:4163 [D loss: 0.663550, acc.: 58.59%] [G loss: 1.070194]\n",
      "epoch:4 step:4164 [D loss: 0.581882, acc.: 71.09%] [G loss: 1.040012]\n",
      "epoch:4 step:4165 [D loss: 0.653116, acc.: 64.06%] [G loss: 1.022330]\n",
      "epoch:4 step:4166 [D loss: 0.627915, acc.: 64.06%] [G loss: 0.893272]\n",
      "epoch:4 step:4167 [D loss: 0.550152, acc.: 72.66%] [G loss: 1.013502]\n",
      "epoch:4 step:4168 [D loss: 0.575807, acc.: 69.53%] [G loss: 1.029253]\n",
      "epoch:4 step:4169 [D loss: 0.636624, acc.: 64.84%] [G loss: 1.089106]\n",
      "epoch:4 step:4170 [D loss: 0.670167, acc.: 57.81%] [G loss: 1.139318]\n",
      "epoch:4 step:4171 [D loss: 0.604972, acc.: 67.97%] [G loss: 1.008215]\n",
      "epoch:4 step:4172 [D loss: 0.586573, acc.: 67.19%] [G loss: 1.075658]\n",
      "epoch:4 step:4173 [D loss: 0.630016, acc.: 64.84%] [G loss: 1.032823]\n",
      "epoch:4 step:4174 [D loss: 0.647897, acc.: 66.41%] [G loss: 0.944497]\n",
      "epoch:4 step:4175 [D loss: 0.636439, acc.: 60.94%] [G loss: 1.031348]\n",
      "epoch:4 step:4176 [D loss: 0.637201, acc.: 64.84%] [G loss: 0.851651]\n",
      "epoch:4 step:4177 [D loss: 0.612817, acc.: 70.31%] [G loss: 1.087078]\n",
      "epoch:4 step:4178 [D loss: 0.681364, acc.: 57.81%] [G loss: 1.058397]\n",
      "epoch:4 step:4179 [D loss: 0.698274, acc.: 61.72%] [G loss: 1.008654]\n",
      "epoch:4 step:4180 [D loss: 0.631694, acc.: 63.28%] [G loss: 1.061139]\n",
      "epoch:4 step:4181 [D loss: 0.707179, acc.: 54.69%] [G loss: 0.942916]\n",
      "epoch:4 step:4182 [D loss: 0.609367, acc.: 66.41%] [G loss: 1.072278]\n",
      "epoch:4 step:4183 [D loss: 0.635565, acc.: 64.06%] [G loss: 1.046181]\n",
      "epoch:4 step:4184 [D loss: 0.641472, acc.: 64.84%] [G loss: 0.948986]\n",
      "epoch:4 step:4185 [D loss: 0.643987, acc.: 62.50%] [G loss: 1.017449]\n",
      "epoch:4 step:4186 [D loss: 0.618025, acc.: 56.25%] [G loss: 1.078097]\n",
      "epoch:4 step:4187 [D loss: 0.633196, acc.: 59.38%] [G loss: 1.056373]\n",
      "epoch:4 step:4188 [D loss: 0.555875, acc.: 74.22%] [G loss: 0.997307]\n",
      "epoch:4 step:4189 [D loss: 0.586047, acc.: 65.62%] [G loss: 1.107102]\n",
      "epoch:4 step:4190 [D loss: 0.659368, acc.: 64.06%] [G loss: 1.122176]\n",
      "epoch:4 step:4191 [D loss: 0.670989, acc.: 59.38%] [G loss: 1.014136]\n",
      "epoch:4 step:4192 [D loss: 0.691959, acc.: 57.03%] [G loss: 1.090698]\n",
      "epoch:4 step:4193 [D loss: 0.611953, acc.: 62.50%] [G loss: 1.070600]\n",
      "epoch:4 step:4194 [D loss: 0.640962, acc.: 61.72%] [G loss: 1.160959]\n",
      "epoch:4 step:4195 [D loss: 0.596487, acc.: 69.53%] [G loss: 1.139450]\n",
      "epoch:4 step:4196 [D loss: 0.619922, acc.: 67.19%] [G loss: 1.121515]\n",
      "epoch:4 step:4197 [D loss: 0.604553, acc.: 63.28%] [G loss: 1.066295]\n",
      "epoch:4 step:4198 [D loss: 0.636725, acc.: 64.06%] [G loss: 1.107552]\n",
      "epoch:4 step:4199 [D loss: 0.510218, acc.: 77.34%] [G loss: 1.234920]\n",
      "epoch:4 step:4200 [D loss: 0.673927, acc.: 63.28%] [G loss: 1.023506]\n",
      "epoch:4 step:4201 [D loss: 0.586805, acc.: 69.53%] [G loss: 1.119953]\n",
      "epoch:4 step:4202 [D loss: 0.620529, acc.: 60.94%] [G loss: 1.182289]\n",
      "epoch:4 step:4203 [D loss: 0.689746, acc.: 57.03%] [G loss: 1.125754]\n",
      "epoch:4 step:4204 [D loss: 0.584931, acc.: 71.88%] [G loss: 1.136045]\n",
      "epoch:4 step:4205 [D loss: 0.693790, acc.: 60.16%] [G loss: 1.022927]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:4 step:4206 [D loss: 0.592077, acc.: 68.75%] [G loss: 1.030356]\n",
      "epoch:4 step:4207 [D loss: 0.612049, acc.: 67.97%] [G loss: 1.175704]\n",
      "epoch:4 step:4208 [D loss: 0.691221, acc.: 51.56%] [G loss: 1.005479]\n",
      "epoch:4 step:4209 [D loss: 0.602399, acc.: 67.19%] [G loss: 0.999658]\n",
      "epoch:4 step:4210 [D loss: 0.722109, acc.: 55.47%] [G loss: 1.133054]\n",
      "epoch:4 step:4211 [D loss: 0.701943, acc.: 53.91%] [G loss: 1.096704]\n",
      "epoch:4 step:4212 [D loss: 0.609288, acc.: 66.41%] [G loss: 1.029830]\n",
      "epoch:4 step:4213 [D loss: 0.644043, acc.: 66.41%] [G loss: 1.071288]\n",
      "epoch:4 step:4214 [D loss: 0.570974, acc.: 71.09%] [G loss: 1.114029]\n",
      "epoch:4 step:4215 [D loss: 0.708737, acc.: 54.69%] [G loss: 0.972491]\n",
      "epoch:4 step:4216 [D loss: 0.644145, acc.: 61.72%] [G loss: 1.082352]\n",
      "epoch:4 step:4217 [D loss: 0.619155, acc.: 64.06%] [G loss: 1.113875]\n",
      "epoch:4 step:4218 [D loss: 0.679121, acc.: 57.03%] [G loss: 0.972021]\n",
      "epoch:4 step:4219 [D loss: 0.625938, acc.: 65.62%] [G loss: 0.940886]\n",
      "epoch:4 step:4220 [D loss: 0.652166, acc.: 63.28%] [G loss: 1.196954]\n",
      "epoch:4 step:4221 [D loss: 0.701953, acc.: 54.69%] [G loss: 1.038167]\n",
      "epoch:4 step:4222 [D loss: 0.578508, acc.: 72.66%] [G loss: 1.147065]\n",
      "epoch:4 step:4223 [D loss: 0.679118, acc.: 60.94%] [G loss: 1.013373]\n",
      "epoch:4 step:4224 [D loss: 0.669949, acc.: 61.72%] [G loss: 0.972288]\n",
      "epoch:4 step:4225 [D loss: 0.662752, acc.: 57.03%] [G loss: 1.033306]\n",
      "epoch:4 step:4226 [D loss: 0.650784, acc.: 61.72%] [G loss: 1.097581]\n",
      "epoch:4 step:4227 [D loss: 0.703804, acc.: 56.25%] [G loss: 0.878829]\n",
      "epoch:4 step:4228 [D loss: 0.587666, acc.: 67.97%] [G loss: 1.057381]\n",
      "epoch:4 step:4229 [D loss: 0.716622, acc.: 50.00%] [G loss: 0.930867]\n",
      "epoch:4 step:4230 [D loss: 0.643588, acc.: 65.62%] [G loss: 1.229397]\n",
      "epoch:4 step:4231 [D loss: 0.686036, acc.: 60.16%] [G loss: 1.051806]\n",
      "epoch:4 step:4232 [D loss: 0.660531, acc.: 62.50%] [G loss: 1.117382]\n",
      "epoch:4 step:4233 [D loss: 0.654236, acc.: 63.28%] [G loss: 1.108728]\n",
      "epoch:4 step:4234 [D loss: 0.647898, acc.: 60.16%] [G loss: 1.160781]\n",
      "epoch:4 step:4235 [D loss: 0.559999, acc.: 71.88%] [G loss: 1.055275]\n",
      "epoch:4 step:4236 [D loss: 0.635491, acc.: 56.25%] [G loss: 1.164766]\n",
      "epoch:4 step:4237 [D loss: 0.641744, acc.: 65.62%] [G loss: 1.092258]\n",
      "epoch:4 step:4238 [D loss: 0.581302, acc.: 67.19%] [G loss: 1.016111]\n",
      "epoch:4 step:4239 [D loss: 0.532151, acc.: 77.34%] [G loss: 1.129694]\n",
      "epoch:4 step:4240 [D loss: 0.696797, acc.: 58.59%] [G loss: 1.092132]\n",
      "epoch:4 step:4241 [D loss: 0.610914, acc.: 66.41%] [G loss: 1.146501]\n",
      "epoch:4 step:4242 [D loss: 0.690510, acc.: 59.38%] [G loss: 1.095580]\n",
      "epoch:4 step:4243 [D loss: 0.668556, acc.: 58.59%] [G loss: 0.985726]\n",
      "epoch:4 step:4244 [D loss: 0.667135, acc.: 57.81%] [G loss: 1.016776]\n",
      "epoch:4 step:4245 [D loss: 0.604404, acc.: 65.62%] [G loss: 1.051434]\n",
      "epoch:4 step:4246 [D loss: 0.640283, acc.: 64.84%] [G loss: 1.184230]\n",
      "epoch:4 step:4247 [D loss: 0.524466, acc.: 71.88%] [G loss: 0.986587]\n",
      "epoch:4 step:4248 [D loss: 0.689313, acc.: 60.94%] [G loss: 1.073260]\n",
      "epoch:4 step:4249 [D loss: 0.632058, acc.: 63.28%] [G loss: 1.117545]\n",
      "epoch:4 step:4250 [D loss: 0.616267, acc.: 67.97%] [G loss: 0.971082]\n",
      "epoch:4 step:4251 [D loss: 0.688634, acc.: 56.25%] [G loss: 1.050820]\n",
      "epoch:4 step:4252 [D loss: 0.702137, acc.: 57.81%] [G loss: 0.994047]\n",
      "epoch:4 step:4253 [D loss: 0.636575, acc.: 63.28%] [G loss: 1.036379]\n",
      "epoch:4 step:4254 [D loss: 0.716553, acc.: 55.47%] [G loss: 0.972915]\n",
      "epoch:4 step:4255 [D loss: 0.644254, acc.: 60.16%] [G loss: 1.033809]\n",
      "epoch:4 step:4256 [D loss: 0.605453, acc.: 69.53%] [G loss: 1.190522]\n",
      "epoch:4 step:4257 [D loss: 0.611778, acc.: 64.84%] [G loss: 1.126459]\n",
      "epoch:4 step:4258 [D loss: 0.633693, acc.: 64.84%] [G loss: 1.023164]\n",
      "epoch:4 step:4259 [D loss: 0.660725, acc.: 61.72%] [G loss: 1.082489]\n",
      "epoch:4 step:4260 [D loss: 0.530279, acc.: 71.88%] [G loss: 1.091395]\n",
      "epoch:4 step:4261 [D loss: 0.660969, acc.: 62.50%] [G loss: 1.218374]\n",
      "epoch:4 step:4262 [D loss: 0.677203, acc.: 61.72%] [G loss: 1.051715]\n",
      "epoch:4 step:4263 [D loss: 0.667990, acc.: 64.06%] [G loss: 1.151546]\n",
      "epoch:4 step:4264 [D loss: 0.765754, acc.: 52.34%] [G loss: 0.842830]\n",
      "epoch:4 step:4265 [D loss: 0.638906, acc.: 62.50%] [G loss: 1.115103]\n",
      "epoch:4 step:4266 [D loss: 0.657104, acc.: 64.06%] [G loss: 1.250890]\n",
      "epoch:4 step:4267 [D loss: 0.624097, acc.: 61.72%] [G loss: 0.918997]\n",
      "epoch:4 step:4268 [D loss: 0.592212, acc.: 68.75%] [G loss: 0.959152]\n",
      "epoch:4 step:4269 [D loss: 0.679589, acc.: 58.59%] [G loss: 1.043818]\n",
      "epoch:4 step:4270 [D loss: 0.657761, acc.: 61.72%] [G loss: 0.971695]\n",
      "epoch:4 step:4271 [D loss: 0.591892, acc.: 70.31%] [G loss: 0.983687]\n",
      "epoch:4 step:4272 [D loss: 0.628459, acc.: 65.62%] [G loss: 1.033829]\n",
      "epoch:4 step:4273 [D loss: 0.631830, acc.: 67.19%] [G loss: 0.977402]\n",
      "epoch:4 step:4274 [D loss: 0.718455, acc.: 57.81%] [G loss: 0.905234]\n",
      "epoch:4 step:4275 [D loss: 0.563525, acc.: 74.22%] [G loss: 1.206091]\n",
      "epoch:4 step:4276 [D loss: 0.655878, acc.: 60.94%] [G loss: 1.001597]\n",
      "epoch:4 step:4277 [D loss: 0.651400, acc.: 62.50%] [G loss: 1.033645]\n",
      "epoch:4 step:4278 [D loss: 0.625582, acc.: 60.94%] [G loss: 1.112563]\n",
      "epoch:4 step:4279 [D loss: 0.633663, acc.: 64.84%] [G loss: 1.145387]\n",
      "epoch:4 step:4280 [D loss: 0.710285, acc.: 54.69%] [G loss: 0.934605]\n",
      "epoch:4 step:4281 [D loss: 0.659120, acc.: 61.72%] [G loss: 1.010075]\n",
      "epoch:4 step:4282 [D loss: 0.616564, acc.: 62.50%] [G loss: 1.019881]\n",
      "epoch:4 step:4283 [D loss: 0.621712, acc.: 64.84%] [G loss: 1.011610]\n",
      "epoch:4 step:4284 [D loss: 0.642714, acc.: 59.38%] [G loss: 1.051570]\n",
      "epoch:4 step:4285 [D loss: 0.706274, acc.: 57.03%] [G loss: 1.142738]\n",
      "epoch:4 step:4286 [D loss: 0.656174, acc.: 61.72%] [G loss: 0.977622]\n",
      "epoch:4 step:4287 [D loss: 0.583166, acc.: 69.53%] [G loss: 1.053729]\n",
      "epoch:4 step:4288 [D loss: 0.548487, acc.: 71.88%] [G loss: 0.950534]\n",
      "epoch:4 step:4289 [D loss: 0.540722, acc.: 73.44%] [G loss: 1.007358]\n",
      "epoch:4 step:4290 [D loss: 0.647749, acc.: 59.38%] [G loss: 1.013340]\n",
      "epoch:4 step:4291 [D loss: 0.644559, acc.: 64.84%] [G loss: 0.939996]\n",
      "epoch:4 step:4292 [D loss: 0.730096, acc.: 56.25%] [G loss: 0.868152]\n",
      "epoch:4 step:4293 [D loss: 0.645463, acc.: 62.50%] [G loss: 1.119821]\n",
      "epoch:4 step:4294 [D loss: 0.590540, acc.: 66.41%] [G loss: 1.170854]\n",
      "epoch:4 step:4295 [D loss: 0.593355, acc.: 69.53%] [G loss: 1.288701]\n",
      "epoch:4 step:4296 [D loss: 0.818407, acc.: 43.75%] [G loss: 0.911870]\n",
      "epoch:4 step:4297 [D loss: 0.590071, acc.: 66.41%] [G loss: 0.988641]\n",
      "epoch:4 step:4298 [D loss: 0.624814, acc.: 68.75%] [G loss: 0.939130]\n",
      "epoch:4 step:4299 [D loss: 0.584518, acc.: 70.31%] [G loss: 1.061140]\n",
      "epoch:4 step:4300 [D loss: 0.702822, acc.: 57.03%] [G loss: 1.100270]\n",
      "epoch:4 step:4301 [D loss: 0.637703, acc.: 63.28%] [G loss: 1.109892]\n",
      "epoch:4 step:4302 [D loss: 0.715682, acc.: 55.47%] [G loss: 1.093359]\n",
      "epoch:4 step:4303 [D loss: 0.519977, acc.: 72.66%] [G loss: 1.045774]\n",
      "epoch:4 step:4304 [D loss: 0.640282, acc.: 66.41%] [G loss: 1.007604]\n",
      "epoch:4 step:4305 [D loss: 0.625238, acc.: 68.75%] [G loss: 1.106143]\n",
      "epoch:4 step:4306 [D loss: 0.689785, acc.: 56.25%] [G loss: 0.961520]\n",
      "epoch:4 step:4307 [D loss: 0.635134, acc.: 64.84%] [G loss: 0.948135]\n",
      "epoch:4 step:4308 [D loss: 0.647117, acc.: 62.50%] [G loss: 1.107685]\n",
      "epoch:4 step:4309 [D loss: 0.683899, acc.: 58.59%] [G loss: 1.006911]\n",
      "epoch:4 step:4310 [D loss: 0.666211, acc.: 57.03%] [G loss: 1.071622]\n",
      "epoch:4 step:4311 [D loss: 0.707462, acc.: 60.16%] [G loss: 1.056007]\n",
      "epoch:4 step:4312 [D loss: 0.559497, acc.: 72.66%] [G loss: 1.173146]\n",
      "epoch:4 step:4313 [D loss: 0.588009, acc.: 71.09%] [G loss: 1.186922]\n",
      "epoch:4 step:4314 [D loss: 0.669095, acc.: 57.03%] [G loss: 1.101686]\n",
      "epoch:4 step:4315 [D loss: 0.593492, acc.: 67.97%] [G loss: 1.068257]\n",
      "epoch:4 step:4316 [D loss: 0.811512, acc.: 43.75%] [G loss: 0.992498]\n",
      "epoch:4 step:4317 [D loss: 0.681724, acc.: 63.28%] [G loss: 1.039301]\n",
      "epoch:4 step:4318 [D loss: 0.695863, acc.: 57.03%] [G loss: 1.048255]\n",
      "epoch:4 step:4319 [D loss: 0.669710, acc.: 60.16%] [G loss: 0.941703]\n",
      "epoch:4 step:4320 [D loss: 0.547344, acc.: 70.31%] [G loss: 1.006613]\n",
      "epoch:4 step:4321 [D loss: 0.754371, acc.: 49.22%] [G loss: 0.879134]\n",
      "epoch:4 step:4322 [D loss: 0.752803, acc.: 49.22%] [G loss: 0.930599]\n",
      "epoch:4 step:4323 [D loss: 0.562796, acc.: 71.88%] [G loss: 1.086419]\n",
      "epoch:4 step:4324 [D loss: 0.562961, acc.: 71.09%] [G loss: 1.099649]\n",
      "epoch:4 step:4325 [D loss: 0.622108, acc.: 70.31%] [G loss: 1.030345]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:4 step:4326 [D loss: 0.694579, acc.: 59.38%] [G loss: 1.119014]\n",
      "epoch:4 step:4327 [D loss: 0.588460, acc.: 67.19%] [G loss: 1.243760]\n",
      "epoch:4 step:4328 [D loss: 0.761569, acc.: 47.66%] [G loss: 1.106880]\n",
      "epoch:4 step:4329 [D loss: 0.678191, acc.: 57.03%] [G loss: 1.020324]\n",
      "epoch:4 step:4330 [D loss: 0.622640, acc.: 64.06%] [G loss: 1.139469]\n",
      "epoch:4 step:4331 [D loss: 0.656911, acc.: 64.84%] [G loss: 1.075471]\n",
      "epoch:4 step:4332 [D loss: 0.651507, acc.: 60.94%] [G loss: 1.008726]\n",
      "epoch:4 step:4333 [D loss: 0.667060, acc.: 60.16%] [G loss: 1.070229]\n",
      "epoch:4 step:4334 [D loss: 0.635020, acc.: 60.94%] [G loss: 0.912743]\n",
      "epoch:4 step:4335 [D loss: 0.673500, acc.: 59.38%] [G loss: 0.985089]\n",
      "epoch:4 step:4336 [D loss: 0.638347, acc.: 67.19%] [G loss: 1.048802]\n",
      "epoch:4 step:4337 [D loss: 0.685523, acc.: 58.59%] [G loss: 1.054476]\n",
      "epoch:4 step:4338 [D loss: 0.602071, acc.: 67.19%] [G loss: 1.079193]\n",
      "epoch:4 step:4339 [D loss: 0.723520, acc.: 50.78%] [G loss: 0.964717]\n",
      "epoch:4 step:4340 [D loss: 0.630184, acc.: 63.28%] [G loss: 1.065064]\n",
      "epoch:4 step:4341 [D loss: 0.706675, acc.: 57.03%] [G loss: 1.074087]\n",
      "epoch:4 step:4342 [D loss: 0.578698, acc.: 71.09%] [G loss: 1.201067]\n",
      "epoch:4 step:4343 [D loss: 0.680156, acc.: 60.16%] [G loss: 1.051859]\n",
      "epoch:4 step:4344 [D loss: 0.623308, acc.: 66.41%] [G loss: 1.007931]\n",
      "epoch:4 step:4345 [D loss: 0.686291, acc.: 59.38%] [G loss: 1.008136]\n",
      "epoch:4 step:4346 [D loss: 0.623043, acc.: 65.62%] [G loss: 0.954426]\n",
      "epoch:4 step:4347 [D loss: 0.554951, acc.: 75.78%] [G loss: 1.073790]\n",
      "epoch:4 step:4348 [D loss: 0.613392, acc.: 67.97%] [G loss: 1.110520]\n",
      "epoch:4 step:4349 [D loss: 0.723200, acc.: 50.78%] [G loss: 0.997481]\n",
      "epoch:4 step:4350 [D loss: 0.548834, acc.: 79.69%] [G loss: 0.984362]\n",
      "epoch:4 step:4351 [D loss: 0.624507, acc.: 64.84%] [G loss: 1.093693]\n",
      "epoch:4 step:4352 [D loss: 0.610748, acc.: 64.84%] [G loss: 0.895783]\n",
      "epoch:4 step:4353 [D loss: 0.736687, acc.: 46.88%] [G loss: 0.960517]\n",
      "epoch:4 step:4354 [D loss: 0.649539, acc.: 60.94%] [G loss: 1.041886]\n",
      "epoch:4 step:4355 [D loss: 0.664367, acc.: 59.38%] [G loss: 0.931639]\n",
      "epoch:4 step:4356 [D loss: 0.584944, acc.: 75.00%] [G loss: 1.123805]\n",
      "epoch:4 step:4357 [D loss: 0.611762, acc.: 64.84%] [G loss: 0.995678]\n",
      "epoch:4 step:4358 [D loss: 0.671792, acc.: 56.25%] [G loss: 1.114441]\n",
      "epoch:4 step:4359 [D loss: 0.670733, acc.: 60.94%] [G loss: 1.086586]\n",
      "epoch:4 step:4360 [D loss: 0.707686, acc.: 57.81%] [G loss: 1.025889]\n",
      "epoch:4 step:4361 [D loss: 0.566459, acc.: 72.66%] [G loss: 1.029057]\n",
      "epoch:4 step:4362 [D loss: 0.738077, acc.: 52.34%] [G loss: 1.020050]\n",
      "epoch:4 step:4363 [D loss: 0.569862, acc.: 69.53%] [G loss: 1.084429]\n",
      "epoch:4 step:4364 [D loss: 0.581463, acc.: 69.53%] [G loss: 1.016658]\n",
      "epoch:4 step:4365 [D loss: 0.649270, acc.: 63.28%] [G loss: 0.945857]\n",
      "epoch:4 step:4366 [D loss: 0.634655, acc.: 64.06%] [G loss: 0.884406]\n",
      "epoch:4 step:4367 [D loss: 0.562890, acc.: 71.09%] [G loss: 1.119563]\n",
      "epoch:4 step:4368 [D loss: 0.622984, acc.: 64.06%] [G loss: 1.138346]\n",
      "epoch:4 step:4369 [D loss: 0.696811, acc.: 55.47%] [G loss: 0.916407]\n",
      "epoch:4 step:4370 [D loss: 0.651802, acc.: 60.16%] [G loss: 0.940769]\n",
      "epoch:4 step:4371 [D loss: 0.637360, acc.: 63.28%] [G loss: 1.132034]\n",
      "epoch:4 step:4372 [D loss: 0.610001, acc.: 64.06%] [G loss: 1.117158]\n",
      "epoch:4 step:4373 [D loss: 0.597614, acc.: 67.19%] [G loss: 1.133712]\n",
      "epoch:4 step:4374 [D loss: 0.647112, acc.: 58.59%] [G loss: 0.977728]\n",
      "epoch:4 step:4375 [D loss: 0.609330, acc.: 67.19%] [G loss: 1.104910]\n",
      "epoch:4 step:4376 [D loss: 0.731845, acc.: 58.59%] [G loss: 1.235439]\n",
      "epoch:4 step:4377 [D loss: 0.651493, acc.: 60.16%] [G loss: 1.044626]\n",
      "epoch:4 step:4378 [D loss: 0.632434, acc.: 63.28%] [G loss: 0.983306]\n",
      "epoch:4 step:4379 [D loss: 0.583923, acc.: 65.62%] [G loss: 0.963020]\n",
      "epoch:4 step:4380 [D loss: 0.702755, acc.: 57.81%] [G loss: 1.072701]\n",
      "epoch:4 step:4381 [D loss: 0.661356, acc.: 63.28%] [G loss: 1.037806]\n",
      "epoch:4 step:4382 [D loss: 0.607874, acc.: 67.97%] [G loss: 1.074324]\n",
      "epoch:4 step:4383 [D loss: 0.627719, acc.: 67.97%] [G loss: 1.053420]\n",
      "epoch:4 step:4384 [D loss: 0.563568, acc.: 75.78%] [G loss: 1.249170]\n",
      "epoch:4 step:4385 [D loss: 0.687074, acc.: 53.91%] [G loss: 0.917169]\n",
      "epoch:4 step:4386 [D loss: 0.663215, acc.: 57.81%] [G loss: 0.969427]\n",
      "epoch:4 step:4387 [D loss: 0.703936, acc.: 59.38%] [G loss: 1.056384]\n",
      "epoch:4 step:4388 [D loss: 0.741679, acc.: 50.00%] [G loss: 1.094580]\n",
      "epoch:4 step:4389 [D loss: 0.677215, acc.: 58.59%] [G loss: 0.899834]\n",
      "epoch:4 step:4390 [D loss: 0.737497, acc.: 55.47%] [G loss: 0.944747]\n",
      "epoch:4 step:4391 [D loss: 0.636097, acc.: 66.41%] [G loss: 1.039254]\n",
      "epoch:4 step:4392 [D loss: 0.610177, acc.: 70.31%] [G loss: 1.051895]\n",
      "epoch:4 step:4393 [D loss: 0.585387, acc.: 68.75%] [G loss: 1.321528]\n",
      "epoch:4 step:4394 [D loss: 0.700985, acc.: 64.84%] [G loss: 1.128026]\n",
      "epoch:4 step:4395 [D loss: 0.648937, acc.: 63.28%] [G loss: 1.028104]\n",
      "epoch:4 step:4396 [D loss: 0.603460, acc.: 65.62%] [G loss: 1.160039]\n",
      "epoch:4 step:4397 [D loss: 0.718617, acc.: 53.91%] [G loss: 0.993102]\n",
      "epoch:4 step:4398 [D loss: 0.735438, acc.: 53.12%] [G loss: 1.014066]\n",
      "epoch:4 step:4399 [D loss: 0.701626, acc.: 54.69%] [G loss: 1.007127]\n",
      "epoch:4 step:4400 [D loss: 0.617956, acc.: 66.41%] [G loss: 0.879845]\n",
      "epoch:4 step:4401 [D loss: 0.603382, acc.: 73.44%] [G loss: 0.931314]\n",
      "epoch:4 step:4402 [D loss: 0.664234, acc.: 59.38%] [G loss: 0.998305]\n",
      "epoch:4 step:4403 [D loss: 0.601009, acc.: 64.84%] [G loss: 1.058446]\n",
      "epoch:4 step:4404 [D loss: 0.617997, acc.: 63.28%] [G loss: 1.021905]\n",
      "epoch:4 step:4405 [D loss: 0.622213, acc.: 62.50%] [G loss: 1.117669]\n",
      "epoch:4 step:4406 [D loss: 0.641465, acc.: 64.06%] [G loss: 1.098584]\n",
      "epoch:4 step:4407 [D loss: 0.678040, acc.: 58.59%] [G loss: 1.125091]\n",
      "epoch:4 step:4408 [D loss: 0.632639, acc.: 60.94%] [G loss: 1.067649]\n",
      "epoch:4 step:4409 [D loss: 0.691377, acc.: 57.81%] [G loss: 1.079315]\n",
      "epoch:4 step:4410 [D loss: 0.627625, acc.: 63.28%] [G loss: 1.087505]\n",
      "epoch:4 step:4411 [D loss: 0.661208, acc.: 57.03%] [G loss: 0.985260]\n",
      "epoch:4 step:4412 [D loss: 0.637065, acc.: 61.72%] [G loss: 0.956191]\n",
      "epoch:4 step:4413 [D loss: 0.679028, acc.: 57.81%] [G loss: 0.953453]\n",
      "epoch:4 step:4414 [D loss: 0.662509, acc.: 61.72%] [G loss: 1.170032]\n",
      "epoch:4 step:4415 [D loss: 0.619872, acc.: 59.38%] [G loss: 1.197131]\n",
      "epoch:4 step:4416 [D loss: 0.640155, acc.: 67.97%] [G loss: 1.061703]\n",
      "epoch:4 step:4417 [D loss: 0.574818, acc.: 69.53%] [G loss: 1.151780]\n",
      "epoch:4 step:4418 [D loss: 0.586068, acc.: 70.31%] [G loss: 1.260253]\n",
      "epoch:4 step:4419 [D loss: 0.653488, acc.: 63.28%] [G loss: 0.900681]\n",
      "epoch:4 step:4420 [D loss: 0.575034, acc.: 71.09%] [G loss: 1.060688]\n",
      "epoch:4 step:4421 [D loss: 0.734160, acc.: 53.91%] [G loss: 0.896810]\n",
      "epoch:4 step:4422 [D loss: 0.648742, acc.: 60.94%] [G loss: 1.063444]\n",
      "epoch:4 step:4423 [D loss: 0.789914, acc.: 47.66%] [G loss: 1.007226]\n",
      "epoch:4 step:4424 [D loss: 0.646492, acc.: 66.41%] [G loss: 1.070220]\n",
      "epoch:4 step:4425 [D loss: 0.612469, acc.: 64.06%] [G loss: 1.216552]\n",
      "epoch:4 step:4426 [D loss: 0.686069, acc.: 60.16%] [G loss: 1.028520]\n",
      "epoch:4 step:4427 [D loss: 0.683196, acc.: 61.72%] [G loss: 1.097828]\n",
      "epoch:4 step:4428 [D loss: 0.700502, acc.: 58.59%] [G loss: 1.195700]\n",
      "epoch:4 step:4429 [D loss: 0.656788, acc.: 60.16%] [G loss: 1.085546]\n",
      "epoch:4 step:4430 [D loss: 0.599003, acc.: 66.41%] [G loss: 1.187771]\n",
      "epoch:4 step:4431 [D loss: 0.657680, acc.: 61.72%] [G loss: 1.060887]\n",
      "epoch:4 step:4432 [D loss: 0.648894, acc.: 63.28%] [G loss: 1.098268]\n",
      "epoch:4 step:4433 [D loss: 0.659512, acc.: 62.50%] [G loss: 1.056431]\n",
      "epoch:4 step:4434 [D loss: 0.673153, acc.: 58.59%] [G loss: 1.083004]\n",
      "epoch:4 step:4435 [D loss: 0.707652, acc.: 57.81%] [G loss: 0.966085]\n",
      "epoch:4 step:4436 [D loss: 0.616009, acc.: 63.28%] [G loss: 1.121604]\n",
      "epoch:4 step:4437 [D loss: 0.705585, acc.: 53.91%] [G loss: 0.897249]\n",
      "epoch:4 step:4438 [D loss: 0.640333, acc.: 56.25%] [G loss: 0.864833]\n",
      "epoch:4 step:4439 [D loss: 0.734045, acc.: 46.09%] [G loss: 1.048766]\n",
      "epoch:4 step:4440 [D loss: 0.575922, acc.: 75.78%] [G loss: 1.193533]\n",
      "epoch:4 step:4441 [D loss: 0.644627, acc.: 60.16%] [G loss: 1.009826]\n",
      "epoch:4 step:4442 [D loss: 0.726906, acc.: 55.47%] [G loss: 0.985718]\n",
      "epoch:4 step:4443 [D loss: 0.538636, acc.: 73.44%] [G loss: 1.020131]\n",
      "epoch:4 step:4444 [D loss: 0.665033, acc.: 62.50%] [G loss: 1.047793]\n",
      "epoch:4 step:4445 [D loss: 0.706954, acc.: 62.50%] [G loss: 0.906732]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:4 step:4446 [D loss: 0.615414, acc.: 72.66%] [G loss: 1.050384]\n",
      "epoch:4 step:4447 [D loss: 0.669407, acc.: 57.03%] [G loss: 1.018589]\n",
      "epoch:4 step:4448 [D loss: 0.582999, acc.: 67.19%] [G loss: 1.050826]\n",
      "epoch:4 step:4449 [D loss: 0.595435, acc.: 63.28%] [G loss: 1.133852]\n",
      "epoch:4 step:4450 [D loss: 0.536583, acc.: 75.00%] [G loss: 1.227288]\n",
      "epoch:4 step:4451 [D loss: 0.713693, acc.: 56.25%] [G loss: 1.150180]\n",
      "epoch:4 step:4452 [D loss: 0.722798, acc.: 50.00%] [G loss: 1.113694]\n",
      "epoch:4 step:4453 [D loss: 0.546817, acc.: 75.78%] [G loss: 1.202011]\n",
      "epoch:4 step:4454 [D loss: 0.691501, acc.: 57.81%] [G loss: 1.062746]\n",
      "epoch:4 step:4455 [D loss: 0.635612, acc.: 66.41%] [G loss: 1.050719]\n",
      "epoch:4 step:4456 [D loss: 0.626203, acc.: 63.28%] [G loss: 1.036976]\n",
      "epoch:4 step:4457 [D loss: 0.715671, acc.: 56.25%] [G loss: 1.118065]\n",
      "epoch:4 step:4458 [D loss: 0.650023, acc.: 60.16%] [G loss: 1.070951]\n",
      "epoch:4 step:4459 [D loss: 0.546752, acc.: 75.00%] [G loss: 1.206087]\n",
      "epoch:4 step:4460 [D loss: 0.692097, acc.: 57.81%] [G loss: 0.967390]\n",
      "epoch:4 step:4461 [D loss: 0.634547, acc.: 67.97%] [G loss: 0.998121]\n",
      "epoch:4 step:4462 [D loss: 0.745629, acc.: 52.34%] [G loss: 0.997901]\n",
      "epoch:4 step:4463 [D loss: 0.694085, acc.: 61.72%] [G loss: 0.972903]\n",
      "epoch:4 step:4464 [D loss: 0.545564, acc.: 78.12%] [G loss: 1.233239]\n",
      "epoch:4 step:4465 [D loss: 0.689221, acc.: 57.81%] [G loss: 1.107599]\n",
      "epoch:4 step:4466 [D loss: 0.560356, acc.: 67.19%] [G loss: 1.220077]\n",
      "epoch:4 step:4467 [D loss: 0.697163, acc.: 59.38%] [G loss: 1.065950]\n",
      "epoch:4 step:4468 [D loss: 0.689739, acc.: 61.72%] [G loss: 0.916910]\n",
      "epoch:4 step:4469 [D loss: 0.599664, acc.: 67.97%] [G loss: 1.041647]\n",
      "epoch:4 step:4470 [D loss: 0.596232, acc.: 69.53%] [G loss: 1.052199]\n",
      "epoch:4 step:4471 [D loss: 0.653704, acc.: 67.19%] [G loss: 1.001115]\n",
      "epoch:4 step:4472 [D loss: 0.642656, acc.: 62.50%] [G loss: 1.044544]\n",
      "epoch:4 step:4473 [D loss: 0.707206, acc.: 53.91%] [G loss: 0.945155]\n",
      "epoch:4 step:4474 [D loss: 0.673371, acc.: 55.47%] [G loss: 1.016304]\n",
      "epoch:4 step:4475 [D loss: 0.579133, acc.: 72.66%] [G loss: 1.028197]\n",
      "epoch:4 step:4476 [D loss: 0.678903, acc.: 58.59%] [G loss: 1.043655]\n",
      "epoch:4 step:4477 [D loss: 0.608332, acc.: 67.97%] [G loss: 1.057059]\n",
      "epoch:4 step:4478 [D loss: 0.689489, acc.: 55.47%] [G loss: 0.993217]\n",
      "epoch:4 step:4479 [D loss: 0.644439, acc.: 65.62%] [G loss: 0.981299]\n",
      "epoch:4 step:4480 [D loss: 0.741197, acc.: 49.22%] [G loss: 0.988849]\n",
      "epoch:4 step:4481 [D loss: 0.725156, acc.: 56.25%] [G loss: 1.039101]\n",
      "epoch:4 step:4482 [D loss: 0.621902, acc.: 69.53%] [G loss: 1.091920]\n",
      "epoch:4 step:4483 [D loss: 0.650741, acc.: 62.50%] [G loss: 1.112119]\n",
      "epoch:4 step:4484 [D loss: 0.551098, acc.: 74.22%] [G loss: 1.146899]\n",
      "epoch:4 step:4485 [D loss: 0.632183, acc.: 66.41%] [G loss: 1.018723]\n",
      "epoch:4 step:4486 [D loss: 0.734837, acc.: 51.56%] [G loss: 0.893138]\n",
      "epoch:4 step:4487 [D loss: 0.609156, acc.: 69.53%] [G loss: 1.007859]\n",
      "epoch:4 step:4488 [D loss: 0.791337, acc.: 47.66%] [G loss: 0.844226]\n",
      "epoch:4 step:4489 [D loss: 0.706082, acc.: 51.56%] [G loss: 1.034314]\n",
      "epoch:4 step:4490 [D loss: 0.653637, acc.: 60.94%] [G loss: 1.058934]\n",
      "epoch:4 step:4491 [D loss: 0.695591, acc.: 55.47%] [G loss: 1.016078]\n",
      "epoch:4 step:4492 [D loss: 0.674308, acc.: 60.94%] [G loss: 0.920098]\n",
      "epoch:4 step:4493 [D loss: 0.698942, acc.: 53.91%] [G loss: 0.849075]\n",
      "epoch:4 step:4494 [D loss: 0.588853, acc.: 74.22%] [G loss: 1.065622]\n",
      "epoch:4 step:4495 [D loss: 0.641490, acc.: 63.28%] [G loss: 1.098099]\n",
      "epoch:4 step:4496 [D loss: 0.637383, acc.: 65.62%] [G loss: 1.093644]\n",
      "epoch:4 step:4497 [D loss: 0.691537, acc.: 53.91%] [G loss: 1.044908]\n",
      "epoch:4 step:4498 [D loss: 0.692340, acc.: 59.38%] [G loss: 0.945114]\n",
      "epoch:4 step:4499 [D loss: 0.599185, acc.: 64.06%] [G loss: 0.986547]\n",
      "epoch:4 step:4500 [D loss: 0.710029, acc.: 53.12%] [G loss: 1.092153]\n",
      "epoch:4 step:4501 [D loss: 0.649898, acc.: 60.94%] [G loss: 0.920032]\n",
      "epoch:4 step:4502 [D loss: 0.634975, acc.: 61.72%] [G loss: 1.263577]\n",
      "epoch:4 step:4503 [D loss: 0.645033, acc.: 60.16%] [G loss: 1.043509]\n",
      "epoch:4 step:4504 [D loss: 0.715168, acc.: 50.00%] [G loss: 1.041074]\n",
      "epoch:4 step:4505 [D loss: 0.577506, acc.: 76.56%] [G loss: 1.082975]\n",
      "epoch:4 step:4506 [D loss: 0.662434, acc.: 60.16%] [G loss: 1.149343]\n",
      "epoch:4 step:4507 [D loss: 0.605912, acc.: 66.41%] [G loss: 1.126916]\n",
      "epoch:4 step:4508 [D loss: 0.693826, acc.: 51.56%] [G loss: 0.884150]\n",
      "epoch:4 step:4509 [D loss: 0.662219, acc.: 57.81%] [G loss: 1.101689]\n",
      "epoch:4 step:4510 [D loss: 0.766564, acc.: 46.09%] [G loss: 0.938043]\n",
      "epoch:4 step:4511 [D loss: 0.625417, acc.: 67.19%] [G loss: 1.088263]\n",
      "epoch:4 step:4512 [D loss: 0.666334, acc.: 65.62%] [G loss: 1.136642]\n",
      "epoch:4 step:4513 [D loss: 0.638325, acc.: 62.50%] [G loss: 1.158554]\n",
      "epoch:4 step:4514 [D loss: 0.615846, acc.: 67.97%] [G loss: 1.253272]\n",
      "epoch:4 step:4515 [D loss: 0.620377, acc.: 68.75%] [G loss: 0.903589]\n",
      "epoch:4 step:4516 [D loss: 0.667580, acc.: 61.72%] [G loss: 0.796152]\n",
      "epoch:4 step:4517 [D loss: 0.646757, acc.: 60.94%] [G loss: 0.984967]\n",
      "epoch:4 step:4518 [D loss: 0.689540, acc.: 57.81%] [G loss: 0.987785]\n",
      "epoch:4 step:4519 [D loss: 0.609903, acc.: 69.53%] [G loss: 1.105581]\n",
      "epoch:4 step:4520 [D loss: 0.640101, acc.: 65.62%] [G loss: 1.185021]\n",
      "epoch:4 step:4521 [D loss: 0.686284, acc.: 58.59%] [G loss: 1.037873]\n",
      "epoch:4 step:4522 [D loss: 0.637854, acc.: 64.84%] [G loss: 1.037191]\n",
      "epoch:4 step:4523 [D loss: 0.661812, acc.: 60.94%] [G loss: 1.160005]\n",
      "epoch:4 step:4524 [D loss: 0.677591, acc.: 57.81%] [G loss: 1.052140]\n",
      "epoch:4 step:4525 [D loss: 0.723640, acc.: 53.12%] [G loss: 0.993105]\n",
      "epoch:4 step:4526 [D loss: 0.625634, acc.: 64.06%] [G loss: 1.118907]\n",
      "epoch:4 step:4527 [D loss: 0.597620, acc.: 67.19%] [G loss: 1.194309]\n",
      "epoch:4 step:4528 [D loss: 0.711684, acc.: 56.25%] [G loss: 1.047098]\n",
      "epoch:4 step:4529 [D loss: 0.634825, acc.: 60.16%] [G loss: 1.097649]\n",
      "epoch:4 step:4530 [D loss: 0.592984, acc.: 66.41%] [G loss: 1.072359]\n",
      "epoch:4 step:4531 [D loss: 0.583212, acc.: 71.09%] [G loss: 1.158710]\n",
      "epoch:4 step:4532 [D loss: 0.685747, acc.: 61.72%] [G loss: 1.052783]\n",
      "epoch:4 step:4533 [D loss: 0.663420, acc.: 64.06%] [G loss: 0.959275]\n",
      "epoch:4 step:4534 [D loss: 0.748502, acc.: 48.44%] [G loss: 0.963419]\n",
      "epoch:4 step:4535 [D loss: 0.633279, acc.: 60.16%] [G loss: 0.993352]\n",
      "epoch:4 step:4536 [D loss: 0.643886, acc.: 63.28%] [G loss: 1.027259]\n",
      "epoch:4 step:4537 [D loss: 0.645859, acc.: 63.28%] [G loss: 1.077703]\n",
      "epoch:4 step:4538 [D loss: 0.578159, acc.: 70.31%] [G loss: 1.159577]\n",
      "epoch:4 step:4539 [D loss: 0.647888, acc.: 65.62%] [G loss: 1.034991]\n",
      "epoch:4 step:4540 [D loss: 0.598230, acc.: 67.19%] [G loss: 1.163971]\n",
      "epoch:4 step:4541 [D loss: 0.710136, acc.: 57.81%] [G loss: 0.987353]\n",
      "epoch:4 step:4542 [D loss: 0.551378, acc.: 68.75%] [G loss: 1.034824]\n",
      "epoch:4 step:4543 [D loss: 0.580925, acc.: 69.53%] [G loss: 1.151428]\n",
      "epoch:4 step:4544 [D loss: 0.656724, acc.: 67.97%] [G loss: 1.031284]\n",
      "epoch:4 step:4545 [D loss: 0.762749, acc.: 47.66%] [G loss: 0.861594]\n",
      "epoch:4 step:4546 [D loss: 0.629797, acc.: 60.16%] [G loss: 0.975780]\n",
      "epoch:4 step:4547 [D loss: 0.544299, acc.: 79.69%] [G loss: 1.065554]\n",
      "epoch:4 step:4548 [D loss: 0.648141, acc.: 60.94%] [G loss: 1.062324]\n",
      "epoch:4 step:4549 [D loss: 0.620382, acc.: 68.75%] [G loss: 1.116741]\n",
      "epoch:4 step:4550 [D loss: 0.717262, acc.: 53.91%] [G loss: 0.894323]\n",
      "epoch:4 step:4551 [D loss: 0.660565, acc.: 65.62%] [G loss: 0.880752]\n",
      "epoch:4 step:4552 [D loss: 0.673773, acc.: 58.59%] [G loss: 1.013971]\n",
      "epoch:4 step:4553 [D loss: 0.674451, acc.: 51.56%] [G loss: 0.957562]\n",
      "epoch:4 step:4554 [D loss: 0.590747, acc.: 69.53%] [G loss: 1.018139]\n",
      "epoch:4 step:4555 [D loss: 0.636593, acc.: 58.59%] [G loss: 1.013789]\n",
      "epoch:4 step:4556 [D loss: 0.594624, acc.: 67.97%] [G loss: 0.977744]\n",
      "epoch:4 step:4557 [D loss: 0.679055, acc.: 57.81%] [G loss: 1.100850]\n",
      "epoch:4 step:4558 [D loss: 0.677847, acc.: 61.72%] [G loss: 1.083656]\n",
      "epoch:4 step:4559 [D loss: 0.659636, acc.: 60.94%] [G loss: 1.121102]\n",
      "epoch:4 step:4560 [D loss: 0.656379, acc.: 62.50%] [G loss: 0.973965]\n",
      "epoch:4 step:4561 [D loss: 0.623762, acc.: 64.84%] [G loss: 1.074359]\n",
      "epoch:4 step:4562 [D loss: 0.603914, acc.: 70.31%] [G loss: 0.988524]\n",
      "epoch:4 step:4563 [D loss: 0.590843, acc.: 69.53%] [G loss: 1.132933]\n",
      "epoch:4 step:4564 [D loss: 0.582652, acc.: 69.53%] [G loss: 1.162984]\n",
      "epoch:4 step:4565 [D loss: 0.709787, acc.: 53.91%] [G loss: 1.132751]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:4 step:4566 [D loss: 0.681139, acc.: 60.94%] [G loss: 1.041856]\n",
      "epoch:4 step:4567 [D loss: 0.606316, acc.: 66.41%] [G loss: 1.060530]\n",
      "epoch:4 step:4568 [D loss: 0.683397, acc.: 60.16%] [G loss: 0.958084]\n",
      "epoch:4 step:4569 [D loss: 0.618326, acc.: 63.28%] [G loss: 1.164490]\n",
      "epoch:4 step:4570 [D loss: 0.640804, acc.: 71.09%] [G loss: 1.031312]\n",
      "epoch:4 step:4571 [D loss: 0.771582, acc.: 49.22%] [G loss: 0.835555]\n",
      "epoch:4 step:4572 [D loss: 0.602906, acc.: 62.50%] [G loss: 1.121773]\n",
      "epoch:4 step:4573 [D loss: 0.617760, acc.: 65.62%] [G loss: 0.994606]\n",
      "epoch:4 step:4574 [D loss: 0.688762, acc.: 60.94%] [G loss: 1.004315]\n",
      "epoch:4 step:4575 [D loss: 0.620918, acc.: 62.50%] [G loss: 1.269987]\n",
      "epoch:4 step:4576 [D loss: 0.708114, acc.: 54.69%] [G loss: 1.056605]\n",
      "epoch:4 step:4577 [D loss: 0.692125, acc.: 57.03%] [G loss: 0.985370]\n",
      "epoch:4 step:4578 [D loss: 0.658563, acc.: 60.16%] [G loss: 1.047649]\n",
      "epoch:4 step:4579 [D loss: 0.606630, acc.: 68.75%] [G loss: 0.982081]\n",
      "epoch:4 step:4580 [D loss: 0.607545, acc.: 64.84%] [G loss: 1.070596]\n",
      "epoch:4 step:4581 [D loss: 0.660488, acc.: 58.59%] [G loss: 1.042303]\n",
      "epoch:4 step:4582 [D loss: 0.627648, acc.: 61.72%] [G loss: 1.228707]\n",
      "epoch:4 step:4583 [D loss: 0.727828, acc.: 53.91%] [G loss: 0.917856]\n",
      "epoch:4 step:4584 [D loss: 0.628551, acc.: 64.84%] [G loss: 1.095080]\n",
      "epoch:4 step:4585 [D loss: 0.699531, acc.: 54.69%] [G loss: 1.049796]\n",
      "epoch:4 step:4586 [D loss: 0.637378, acc.: 64.84%] [G loss: 0.999180]\n",
      "epoch:4 step:4587 [D loss: 0.690936, acc.: 55.47%] [G loss: 0.999703]\n",
      "epoch:4 step:4588 [D loss: 0.583251, acc.: 67.97%] [G loss: 1.157956]\n",
      "epoch:4 step:4589 [D loss: 0.619864, acc.: 65.62%] [G loss: 0.990956]\n",
      "epoch:4 step:4590 [D loss: 0.651580, acc.: 64.06%] [G loss: 1.127935]\n",
      "epoch:4 step:4591 [D loss: 0.661882, acc.: 57.81%] [G loss: 0.930709]\n",
      "epoch:4 step:4592 [D loss: 0.638417, acc.: 60.94%] [G loss: 1.036705]\n",
      "epoch:4 step:4593 [D loss: 0.678048, acc.: 57.03%] [G loss: 0.921467]\n",
      "epoch:4 step:4594 [D loss: 0.632102, acc.: 60.94%] [G loss: 0.990328]\n",
      "epoch:4 step:4595 [D loss: 0.649504, acc.: 58.59%] [G loss: 0.998386]\n",
      "epoch:4 step:4596 [D loss: 0.555934, acc.: 71.09%] [G loss: 1.026400]\n",
      "epoch:4 step:4597 [D loss: 0.675519, acc.: 62.50%] [G loss: 0.896309]\n",
      "epoch:4 step:4598 [D loss: 0.596649, acc.: 66.41%] [G loss: 1.076806]\n",
      "epoch:4 step:4599 [D loss: 0.730001, acc.: 51.56%] [G loss: 1.091951]\n",
      "epoch:4 step:4600 [D loss: 0.610063, acc.: 62.50%] [G loss: 1.045471]\n",
      "epoch:4 step:4601 [D loss: 0.522791, acc.: 77.34%] [G loss: 1.158995]\n",
      "epoch:4 step:4602 [D loss: 0.683598, acc.: 58.59%] [G loss: 0.858357]\n",
      "epoch:4 step:4603 [D loss: 0.593250, acc.: 67.19%] [G loss: 1.051303]\n",
      "epoch:4 step:4604 [D loss: 0.617279, acc.: 65.62%] [G loss: 1.065934]\n",
      "epoch:4 step:4605 [D loss: 0.742732, acc.: 57.81%] [G loss: 0.992440]\n",
      "epoch:4 step:4606 [D loss: 0.680770, acc.: 57.03%] [G loss: 1.070438]\n",
      "epoch:4 step:4607 [D loss: 0.633060, acc.: 65.62%] [G loss: 1.147490]\n",
      "epoch:4 step:4608 [D loss: 0.623975, acc.: 60.94%] [G loss: 0.983165]\n",
      "epoch:4 step:4609 [D loss: 0.591255, acc.: 69.53%] [G loss: 1.095060]\n",
      "epoch:4 step:4610 [D loss: 0.724269, acc.: 50.78%] [G loss: 0.979760]\n",
      "epoch:4 step:4611 [D loss: 0.681843, acc.: 56.25%] [G loss: 1.015800]\n",
      "epoch:4 step:4612 [D loss: 0.737623, acc.: 49.22%] [G loss: 1.033196]\n",
      "epoch:4 step:4613 [D loss: 0.673229, acc.: 57.81%] [G loss: 1.026034]\n",
      "epoch:4 step:4614 [D loss: 0.576705, acc.: 69.53%] [G loss: 1.141417]\n",
      "epoch:4 step:4615 [D loss: 0.655798, acc.: 61.72%] [G loss: 1.032245]\n",
      "epoch:4 step:4616 [D loss: 0.594245, acc.: 65.62%] [G loss: 1.060951]\n",
      "epoch:4 step:4617 [D loss: 0.588052, acc.: 73.44%] [G loss: 1.060356]\n",
      "epoch:4 step:4618 [D loss: 0.621635, acc.: 65.62%] [G loss: 1.088665]\n",
      "epoch:4 step:4619 [D loss: 0.670828, acc.: 65.62%] [G loss: 1.043478]\n",
      "epoch:4 step:4620 [D loss: 0.708746, acc.: 54.69%] [G loss: 0.937535]\n",
      "epoch:4 step:4621 [D loss: 0.603545, acc.: 64.84%] [G loss: 1.023399]\n",
      "epoch:4 step:4622 [D loss: 0.631574, acc.: 62.50%] [G loss: 1.164341]\n",
      "epoch:4 step:4623 [D loss: 0.613253, acc.: 67.19%] [G loss: 0.940958]\n",
      "epoch:4 step:4624 [D loss: 0.687433, acc.: 56.25%] [G loss: 0.992102]\n",
      "epoch:4 step:4625 [D loss: 0.651134, acc.: 63.28%] [G loss: 1.102332]\n",
      "epoch:4 step:4626 [D loss: 0.707354, acc.: 58.59%] [G loss: 1.063673]\n",
      "epoch:4 step:4627 [D loss: 0.752660, acc.: 51.56%] [G loss: 0.954442]\n",
      "epoch:4 step:4628 [D loss: 0.698722, acc.: 49.22%] [G loss: 0.915165]\n",
      "epoch:4 step:4629 [D loss: 0.676769, acc.: 57.03%] [G loss: 0.885590]\n",
      "epoch:4 step:4630 [D loss: 0.562867, acc.: 74.22%] [G loss: 1.141114]\n",
      "epoch:4 step:4631 [D loss: 0.706634, acc.: 60.94%] [G loss: 1.188743]\n",
      "epoch:4 step:4632 [D loss: 0.666858, acc.: 57.03%] [G loss: 1.087925]\n",
      "epoch:4 step:4633 [D loss: 0.551914, acc.: 75.00%] [G loss: 1.103221]\n",
      "epoch:4 step:4634 [D loss: 0.551500, acc.: 70.31%] [G loss: 0.980703]\n",
      "epoch:4 step:4635 [D loss: 0.599953, acc.: 67.19%] [G loss: 1.132577]\n",
      "epoch:4 step:4636 [D loss: 0.685877, acc.: 56.25%] [G loss: 0.959563]\n",
      "epoch:4 step:4637 [D loss: 0.538882, acc.: 75.78%] [G loss: 1.175174]\n",
      "epoch:4 step:4638 [D loss: 0.590277, acc.: 73.44%] [G loss: 1.062725]\n",
      "epoch:4 step:4639 [D loss: 0.624145, acc.: 60.16%] [G loss: 1.031392]\n",
      "epoch:4 step:4640 [D loss: 0.649371, acc.: 65.62%] [G loss: 0.989238]\n",
      "epoch:4 step:4641 [D loss: 0.653043, acc.: 62.50%] [G loss: 1.090757]\n",
      "epoch:4 step:4642 [D loss: 0.697148, acc.: 57.03%] [G loss: 1.087687]\n",
      "epoch:4 step:4643 [D loss: 0.572010, acc.: 67.97%] [G loss: 1.083297]\n",
      "epoch:4 step:4644 [D loss: 0.649645, acc.: 62.50%] [G loss: 1.099466]\n",
      "epoch:4 step:4645 [D loss: 0.640187, acc.: 53.91%] [G loss: 1.054932]\n",
      "epoch:4 step:4646 [D loss: 0.603552, acc.: 64.84%] [G loss: 1.072757]\n",
      "epoch:4 step:4647 [D loss: 0.568113, acc.: 75.00%] [G loss: 1.170269]\n",
      "epoch:4 step:4648 [D loss: 0.577695, acc.: 73.44%] [G loss: 1.138948]\n",
      "epoch:4 step:4649 [D loss: 0.770293, acc.: 49.22%] [G loss: 1.022911]\n",
      "epoch:4 step:4650 [D loss: 0.557405, acc.: 70.31%] [G loss: 0.964880]\n",
      "epoch:4 step:4651 [D loss: 0.652451, acc.: 61.72%] [G loss: 0.974028]\n",
      "epoch:4 step:4652 [D loss: 0.553161, acc.: 72.66%] [G loss: 0.980199]\n",
      "epoch:4 step:4653 [D loss: 0.690301, acc.: 56.25%] [G loss: 0.927826]\n",
      "epoch:4 step:4654 [D loss: 0.638313, acc.: 61.72%] [G loss: 0.985112]\n",
      "epoch:4 step:4655 [D loss: 0.657306, acc.: 59.38%] [G loss: 1.012040]\n",
      "epoch:4 step:4656 [D loss: 0.685835, acc.: 60.94%] [G loss: 1.166473]\n",
      "epoch:4 step:4657 [D loss: 0.652540, acc.: 58.59%] [G loss: 0.959418]\n",
      "epoch:4 step:4658 [D loss: 0.630161, acc.: 64.84%] [G loss: 1.022765]\n",
      "epoch:4 step:4659 [D loss: 0.639560, acc.: 64.06%] [G loss: 0.886121]\n",
      "epoch:4 step:4660 [D loss: 0.604883, acc.: 64.84%] [G loss: 1.096964]\n",
      "epoch:4 step:4661 [D loss: 0.619531, acc.: 64.84%] [G loss: 1.119593]\n",
      "epoch:4 step:4662 [D loss: 0.664180, acc.: 60.16%] [G loss: 1.116029]\n",
      "epoch:4 step:4663 [D loss: 0.540403, acc.: 75.78%] [G loss: 1.171923]\n",
      "epoch:4 step:4664 [D loss: 0.766422, acc.: 56.25%] [G loss: 0.834651]\n",
      "epoch:4 step:4665 [D loss: 0.614519, acc.: 69.53%] [G loss: 1.041363]\n",
      "epoch:4 step:4666 [D loss: 0.646334, acc.: 64.84%] [G loss: 1.143843]\n",
      "epoch:4 step:4667 [D loss: 0.589202, acc.: 71.09%] [G loss: 1.130995]\n",
      "epoch:4 step:4668 [D loss: 0.605098, acc.: 68.75%] [G loss: 1.085676]\n",
      "epoch:4 step:4669 [D loss: 0.619703, acc.: 65.62%] [G loss: 1.094607]\n",
      "epoch:4 step:4670 [D loss: 0.570301, acc.: 69.53%] [G loss: 1.311658]\n",
      "epoch:4 step:4671 [D loss: 0.639065, acc.: 62.50%] [G loss: 1.011407]\n",
      "epoch:4 step:4672 [D loss: 0.718648, acc.: 53.12%] [G loss: 0.994539]\n",
      "epoch:4 step:4673 [D loss: 0.653284, acc.: 67.19%] [G loss: 0.941975]\n",
      "epoch:4 step:4674 [D loss: 0.628004, acc.: 67.97%] [G loss: 1.049632]\n",
      "epoch:4 step:4675 [D loss: 0.670998, acc.: 65.62%] [G loss: 1.089499]\n",
      "epoch:4 step:4676 [D loss: 0.641712, acc.: 65.62%] [G loss: 1.054131]\n",
      "epoch:4 step:4677 [D loss: 0.726692, acc.: 54.69%] [G loss: 1.037508]\n",
      "epoch:4 step:4678 [D loss: 0.677518, acc.: 65.62%] [G loss: 1.025059]\n",
      "epoch:4 step:4679 [D loss: 0.637806, acc.: 64.84%] [G loss: 1.136886]\n",
      "epoch:4 step:4680 [D loss: 0.594141, acc.: 66.41%] [G loss: 1.300559]\n",
      "epoch:4 step:4681 [D loss: 0.687503, acc.: 61.72%] [G loss: 1.042154]\n",
      "epoch:4 step:4682 [D loss: 0.636184, acc.: 61.72%] [G loss: 1.063145]\n",
      "epoch:4 step:4683 [D loss: 0.608350, acc.: 64.06%] [G loss: 0.991523]\n",
      "epoch:4 step:4684 [D loss: 0.579128, acc.: 74.22%] [G loss: 1.084127]\n",
      "epoch:4 step:4685 [D loss: 0.651966, acc.: 61.72%] [G loss: 1.033301]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:5 step:4686 [D loss: 0.634794, acc.: 67.97%] [G loss: 0.952767]\n",
      "epoch:5 step:4687 [D loss: 0.655842, acc.: 59.38%] [G loss: 1.076285]\n",
      "epoch:5 step:4688 [D loss: 0.636267, acc.: 59.38%] [G loss: 1.022666]\n",
      "epoch:5 step:4689 [D loss: 0.653496, acc.: 63.28%] [G loss: 0.962511]\n",
      "epoch:5 step:4690 [D loss: 0.670802, acc.: 59.38%] [G loss: 0.984502]\n",
      "epoch:5 step:4691 [D loss: 0.682704, acc.: 59.38%] [G loss: 1.000789]\n",
      "epoch:5 step:4692 [D loss: 0.641977, acc.: 63.28%] [G loss: 1.042948]\n",
      "epoch:5 step:4693 [D loss: 0.709337, acc.: 56.25%] [G loss: 0.936632]\n",
      "epoch:5 step:4694 [D loss: 0.653094, acc.: 61.72%] [G loss: 1.004103]\n",
      "epoch:5 step:4695 [D loss: 0.659934, acc.: 66.41%] [G loss: 1.288495]\n",
      "epoch:5 step:4696 [D loss: 0.575166, acc.: 72.66%] [G loss: 1.083502]\n",
      "epoch:5 step:4697 [D loss: 0.629076, acc.: 60.94%] [G loss: 1.078367]\n",
      "epoch:5 step:4698 [D loss: 0.673550, acc.: 60.16%] [G loss: 1.058611]\n",
      "epoch:5 step:4699 [D loss: 0.698871, acc.: 57.81%] [G loss: 1.004900]\n",
      "epoch:5 step:4700 [D loss: 0.682295, acc.: 58.59%] [G loss: 1.027468]\n",
      "epoch:5 step:4701 [D loss: 0.624807, acc.: 67.97%] [G loss: 1.084366]\n",
      "epoch:5 step:4702 [D loss: 0.572538, acc.: 74.22%] [G loss: 1.084996]\n",
      "epoch:5 step:4703 [D loss: 0.735630, acc.: 46.09%] [G loss: 0.964181]\n",
      "epoch:5 step:4704 [D loss: 0.702010, acc.: 57.81%] [G loss: 1.028375]\n",
      "epoch:5 step:4705 [D loss: 0.640230, acc.: 59.38%] [G loss: 1.075144]\n",
      "epoch:5 step:4706 [D loss: 0.577886, acc.: 70.31%] [G loss: 1.033833]\n",
      "epoch:5 step:4707 [D loss: 0.645936, acc.: 60.94%] [G loss: 1.117894]\n",
      "epoch:5 step:4708 [D loss: 0.675163, acc.: 57.81%] [G loss: 0.917030]\n",
      "epoch:5 step:4709 [D loss: 0.612876, acc.: 66.41%] [G loss: 1.101771]\n",
      "epoch:5 step:4710 [D loss: 0.690450, acc.: 59.38%] [G loss: 1.074932]\n",
      "epoch:5 step:4711 [D loss: 0.680309, acc.: 60.94%] [G loss: 1.123609]\n",
      "epoch:5 step:4712 [D loss: 0.623478, acc.: 66.41%] [G loss: 1.093456]\n",
      "epoch:5 step:4713 [D loss: 0.671652, acc.: 61.72%] [G loss: 0.893814]\n",
      "epoch:5 step:4714 [D loss: 0.668029, acc.: 64.84%] [G loss: 1.006348]\n",
      "epoch:5 step:4715 [D loss: 0.620620, acc.: 64.06%] [G loss: 0.943979]\n",
      "epoch:5 step:4716 [D loss: 0.696864, acc.: 59.38%] [G loss: 1.142324]\n",
      "epoch:5 step:4717 [D loss: 0.626833, acc.: 66.41%] [G loss: 0.991530]\n",
      "epoch:5 step:4718 [D loss: 0.682206, acc.: 57.03%] [G loss: 0.959325]\n",
      "epoch:5 step:4719 [D loss: 0.687482, acc.: 53.91%] [G loss: 1.091565]\n",
      "epoch:5 step:4720 [D loss: 0.574027, acc.: 71.09%] [G loss: 1.071667]\n",
      "epoch:5 step:4721 [D loss: 0.606721, acc.: 64.06%] [G loss: 1.011659]\n",
      "epoch:5 step:4722 [D loss: 0.630850, acc.: 64.84%] [G loss: 1.157446]\n",
      "epoch:5 step:4723 [D loss: 0.658298, acc.: 57.03%] [G loss: 1.086331]\n",
      "epoch:5 step:4724 [D loss: 0.651679, acc.: 60.94%] [G loss: 1.015526]\n",
      "epoch:5 step:4725 [D loss: 0.642590, acc.: 62.50%] [G loss: 1.156240]\n",
      "epoch:5 step:4726 [D loss: 0.681636, acc.: 60.16%] [G loss: 1.151714]\n",
      "epoch:5 step:4727 [D loss: 0.591779, acc.: 66.41%] [G loss: 1.089229]\n",
      "epoch:5 step:4728 [D loss: 0.576356, acc.: 72.66%] [G loss: 1.058980]\n",
      "epoch:5 step:4729 [D loss: 0.631030, acc.: 63.28%] [G loss: 0.908864]\n",
      "epoch:5 step:4730 [D loss: 0.631983, acc.: 63.28%] [G loss: 1.179198]\n",
      "epoch:5 step:4731 [D loss: 0.676816, acc.: 62.50%] [G loss: 0.978559]\n",
      "epoch:5 step:4732 [D loss: 0.663559, acc.: 62.50%] [G loss: 0.918000]\n",
      "epoch:5 step:4733 [D loss: 0.683687, acc.: 62.50%] [G loss: 1.072535]\n",
      "epoch:5 step:4734 [D loss: 0.675944, acc.: 60.16%] [G loss: 1.038120]\n",
      "epoch:5 step:4735 [D loss: 0.613057, acc.: 64.06%] [G loss: 1.186577]\n",
      "epoch:5 step:4736 [D loss: 0.652344, acc.: 64.84%] [G loss: 1.152583]\n",
      "epoch:5 step:4737 [D loss: 0.596063, acc.: 69.53%] [G loss: 1.008154]\n",
      "epoch:5 step:4738 [D loss: 0.662316, acc.: 56.25%] [G loss: 1.110907]\n",
      "epoch:5 step:4739 [D loss: 0.619334, acc.: 68.75%] [G loss: 0.888050]\n",
      "epoch:5 step:4740 [D loss: 0.664930, acc.: 57.81%] [G loss: 1.025152]\n",
      "epoch:5 step:4741 [D loss: 0.733981, acc.: 54.69%] [G loss: 0.963470]\n",
      "epoch:5 step:4742 [D loss: 0.689224, acc.: 53.12%] [G loss: 1.032035]\n",
      "epoch:5 step:4743 [D loss: 0.655197, acc.: 62.50%] [G loss: 1.022108]\n",
      "epoch:5 step:4744 [D loss: 0.499533, acc.: 73.44%] [G loss: 1.218511]\n",
      "epoch:5 step:4745 [D loss: 0.562905, acc.: 72.66%] [G loss: 1.123359]\n",
      "epoch:5 step:4746 [D loss: 0.615832, acc.: 66.41%] [G loss: 1.018258]\n",
      "epoch:5 step:4747 [D loss: 0.586192, acc.: 69.53%] [G loss: 1.074777]\n",
      "epoch:5 step:4748 [D loss: 0.685713, acc.: 57.03%] [G loss: 0.956423]\n",
      "epoch:5 step:4749 [D loss: 0.710219, acc.: 57.03%] [G loss: 0.960725]\n",
      "epoch:5 step:4750 [D loss: 0.636255, acc.: 57.81%] [G loss: 1.050391]\n",
      "epoch:5 step:4751 [D loss: 0.758199, acc.: 46.09%] [G loss: 0.935683]\n",
      "epoch:5 step:4752 [D loss: 0.649985, acc.: 64.06%] [G loss: 1.109222]\n",
      "epoch:5 step:4753 [D loss: 0.647557, acc.: 60.16%] [G loss: 1.173010]\n",
      "epoch:5 step:4754 [D loss: 0.622319, acc.: 67.19%] [G loss: 0.919422]\n",
      "epoch:5 step:4755 [D loss: 0.668185, acc.: 54.69%] [G loss: 1.099149]\n",
      "epoch:5 step:4756 [D loss: 0.658080, acc.: 61.72%] [G loss: 0.944826]\n",
      "epoch:5 step:4757 [D loss: 0.589730, acc.: 69.53%] [G loss: 0.914488]\n",
      "epoch:5 step:4758 [D loss: 0.603417, acc.: 70.31%] [G loss: 1.018156]\n",
      "epoch:5 step:4759 [D loss: 0.678194, acc.: 58.59%] [G loss: 0.913767]\n",
      "epoch:5 step:4760 [D loss: 0.636798, acc.: 64.06%] [G loss: 1.016718]\n",
      "epoch:5 step:4761 [D loss: 0.615558, acc.: 60.94%] [G loss: 0.924451]\n",
      "epoch:5 step:4762 [D loss: 0.642020, acc.: 64.06%] [G loss: 0.978757]\n",
      "epoch:5 step:4763 [D loss: 0.671380, acc.: 61.72%] [G loss: 1.073917]\n",
      "epoch:5 step:4764 [D loss: 0.679335, acc.: 59.38%] [G loss: 1.038860]\n",
      "epoch:5 step:4765 [D loss: 0.625912, acc.: 64.84%] [G loss: 1.006499]\n",
      "epoch:5 step:4766 [D loss: 0.652236, acc.: 57.81%] [G loss: 0.944035]\n",
      "epoch:5 step:4767 [D loss: 0.674419, acc.: 52.34%] [G loss: 1.078234]\n",
      "epoch:5 step:4768 [D loss: 0.646101, acc.: 66.41%] [G loss: 1.097922]\n",
      "epoch:5 step:4769 [D loss: 0.677296, acc.: 56.25%] [G loss: 0.956792]\n",
      "epoch:5 step:4770 [D loss: 0.631089, acc.: 64.06%] [G loss: 0.924529]\n",
      "epoch:5 step:4771 [D loss: 0.659015, acc.: 60.16%] [G loss: 1.043407]\n",
      "epoch:5 step:4772 [D loss: 0.647960, acc.: 66.41%] [G loss: 1.004350]\n",
      "epoch:5 step:4773 [D loss: 0.642222, acc.: 67.19%] [G loss: 1.075273]\n",
      "epoch:5 step:4774 [D loss: 0.685278, acc.: 53.91%] [G loss: 0.935333]\n",
      "epoch:5 step:4775 [D loss: 0.668824, acc.: 57.03%] [G loss: 1.028190]\n",
      "epoch:5 step:4776 [D loss: 0.623125, acc.: 67.97%] [G loss: 1.040980]\n",
      "epoch:5 step:4777 [D loss: 0.610085, acc.: 73.44%] [G loss: 1.001048]\n",
      "epoch:5 step:4778 [D loss: 0.649349, acc.: 60.16%] [G loss: 1.015159]\n",
      "epoch:5 step:4779 [D loss: 0.677037, acc.: 59.38%] [G loss: 0.855636]\n",
      "epoch:5 step:4780 [D loss: 0.722513, acc.: 57.81%] [G loss: 1.160416]\n",
      "epoch:5 step:4781 [D loss: 0.670094, acc.: 62.50%] [G loss: 1.023949]\n",
      "epoch:5 step:4782 [D loss: 0.706589, acc.: 58.59%] [G loss: 0.993490]\n",
      "epoch:5 step:4783 [D loss: 0.598703, acc.: 71.09%] [G loss: 1.135637]\n",
      "epoch:5 step:4784 [D loss: 0.672935, acc.: 57.03%] [G loss: 1.018333]\n",
      "epoch:5 step:4785 [D loss: 0.601223, acc.: 67.19%] [G loss: 1.064373]\n",
      "epoch:5 step:4786 [D loss: 0.667053, acc.: 58.59%] [G loss: 0.994350]\n",
      "epoch:5 step:4787 [D loss: 0.653887, acc.: 59.38%] [G loss: 1.087977]\n",
      "epoch:5 step:4788 [D loss: 0.720757, acc.: 55.47%] [G loss: 1.000605]\n",
      "epoch:5 step:4789 [D loss: 0.625504, acc.: 63.28%] [G loss: 1.190109]\n",
      "epoch:5 step:4790 [D loss: 0.629202, acc.: 65.62%] [G loss: 1.054605]\n",
      "epoch:5 step:4791 [D loss: 0.567958, acc.: 70.31%] [G loss: 1.156795]\n",
      "epoch:5 step:4792 [D loss: 0.639784, acc.: 63.28%] [G loss: 0.916166]\n",
      "epoch:5 step:4793 [D loss: 0.594385, acc.: 66.41%] [G loss: 1.038149]\n",
      "epoch:5 step:4794 [D loss: 0.616063, acc.: 65.62%] [G loss: 1.171704]\n",
      "epoch:5 step:4795 [D loss: 0.671627, acc.: 56.25%] [G loss: 1.064709]\n",
      "epoch:5 step:4796 [D loss: 0.687371, acc.: 62.50%] [G loss: 0.923633]\n",
      "epoch:5 step:4797 [D loss: 0.657747, acc.: 60.16%] [G loss: 0.948508]\n",
      "epoch:5 step:4798 [D loss: 0.626674, acc.: 70.31%] [G loss: 1.104728]\n",
      "epoch:5 step:4799 [D loss: 0.650654, acc.: 61.72%] [G loss: 1.104278]\n",
      "epoch:5 step:4800 [D loss: 0.667369, acc.: 58.59%] [G loss: 1.198114]\n",
      "epoch:5 step:4801 [D loss: 0.648217, acc.: 65.62%] [G loss: 1.137600]\n",
      "epoch:5 step:4802 [D loss: 0.622381, acc.: 67.97%] [G loss: 1.055436]\n",
      "epoch:5 step:4803 [D loss: 0.694451, acc.: 53.12%] [G loss: 0.967729]\n",
      "epoch:5 step:4804 [D loss: 0.648722, acc.: 63.28%] [G loss: 0.969146]\n",
      "epoch:5 step:4805 [D loss: 0.616152, acc.: 64.84%] [G loss: 1.142373]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:5 step:4806 [D loss: 0.618546, acc.: 68.75%] [G loss: 1.059839]\n",
      "epoch:5 step:4807 [D loss: 0.597147, acc.: 68.75%] [G loss: 1.023771]\n",
      "epoch:5 step:4808 [D loss: 0.642279, acc.: 60.16%] [G loss: 0.986857]\n",
      "epoch:5 step:4809 [D loss: 0.621369, acc.: 60.94%] [G loss: 0.945463]\n",
      "epoch:5 step:4810 [D loss: 0.630945, acc.: 66.41%] [G loss: 0.947725]\n",
      "epoch:5 step:4811 [D loss: 0.749367, acc.: 53.91%] [G loss: 0.926484]\n",
      "epoch:5 step:4812 [D loss: 0.693654, acc.: 56.25%] [G loss: 0.912159]\n",
      "epoch:5 step:4813 [D loss: 0.619754, acc.: 67.19%] [G loss: 1.047789]\n",
      "epoch:5 step:4814 [D loss: 0.662237, acc.: 57.81%] [G loss: 0.947111]\n",
      "epoch:5 step:4815 [D loss: 0.670279, acc.: 56.25%] [G loss: 0.929704]\n",
      "epoch:5 step:4816 [D loss: 0.629291, acc.: 64.84%] [G loss: 0.946541]\n",
      "epoch:5 step:4817 [D loss: 0.698998, acc.: 55.47%] [G loss: 0.939256]\n",
      "epoch:5 step:4818 [D loss: 0.645743, acc.: 60.94%] [G loss: 1.067938]\n",
      "epoch:5 step:4819 [D loss: 0.677197, acc.: 56.25%] [G loss: 1.081206]\n",
      "epoch:5 step:4820 [D loss: 0.696289, acc.: 54.69%] [G loss: 0.941740]\n",
      "epoch:5 step:4821 [D loss: 0.651120, acc.: 64.06%] [G loss: 0.931458]\n",
      "epoch:5 step:4822 [D loss: 0.616219, acc.: 61.72%] [G loss: 1.047854]\n",
      "epoch:5 step:4823 [D loss: 0.616108, acc.: 69.53%] [G loss: 0.971051]\n",
      "epoch:5 step:4824 [D loss: 0.670520, acc.: 59.38%] [G loss: 0.981178]\n",
      "epoch:5 step:4825 [D loss: 0.640772, acc.: 61.72%] [G loss: 1.137329]\n",
      "epoch:5 step:4826 [D loss: 0.664566, acc.: 60.16%] [G loss: 0.954689]\n",
      "epoch:5 step:4827 [D loss: 0.535035, acc.: 71.09%] [G loss: 1.055005]\n",
      "epoch:5 step:4828 [D loss: 0.659973, acc.: 60.94%] [G loss: 1.062679]\n",
      "epoch:5 step:4829 [D loss: 0.729161, acc.: 54.69%] [G loss: 1.092269]\n",
      "epoch:5 step:4830 [D loss: 0.676943, acc.: 63.28%] [G loss: 0.925171]\n",
      "epoch:5 step:4831 [D loss: 0.619815, acc.: 67.97%] [G loss: 1.040149]\n",
      "epoch:5 step:4832 [D loss: 0.626436, acc.: 69.53%] [G loss: 0.992991]\n",
      "epoch:5 step:4833 [D loss: 0.720834, acc.: 54.69%] [G loss: 1.065059]\n",
      "epoch:5 step:4834 [D loss: 0.695602, acc.: 59.38%] [G loss: 0.964546]\n",
      "epoch:5 step:4835 [D loss: 0.577914, acc.: 74.22%] [G loss: 1.183209]\n",
      "epoch:5 step:4836 [D loss: 0.570167, acc.: 72.66%] [G loss: 0.993290]\n",
      "epoch:5 step:4837 [D loss: 0.620659, acc.: 62.50%] [G loss: 0.963149]\n",
      "epoch:5 step:4838 [D loss: 0.629612, acc.: 60.16%] [G loss: 0.852346]\n",
      "epoch:5 step:4839 [D loss: 0.735737, acc.: 50.78%] [G loss: 1.041565]\n",
      "epoch:5 step:4840 [D loss: 0.703328, acc.: 57.81%] [G loss: 1.171221]\n",
      "epoch:5 step:4841 [D loss: 0.606806, acc.: 70.31%] [G loss: 1.121706]\n",
      "epoch:5 step:4842 [D loss: 0.671754, acc.: 59.38%] [G loss: 1.121761]\n",
      "epoch:5 step:4843 [D loss: 0.574355, acc.: 72.66%] [G loss: 1.180371]\n",
      "epoch:5 step:4844 [D loss: 0.623582, acc.: 61.72%] [G loss: 0.943893]\n",
      "epoch:5 step:4845 [D loss: 0.639159, acc.: 64.84%] [G loss: 0.896623]\n",
      "epoch:5 step:4846 [D loss: 0.544560, acc.: 74.22%] [G loss: 1.083548]\n",
      "epoch:5 step:4847 [D loss: 0.626142, acc.: 61.72%] [G loss: 1.080968]\n",
      "epoch:5 step:4848 [D loss: 0.633314, acc.: 65.62%] [G loss: 1.025154]\n",
      "epoch:5 step:4849 [D loss: 0.693994, acc.: 51.56%] [G loss: 1.006853]\n",
      "epoch:5 step:4850 [D loss: 0.725613, acc.: 51.56%] [G loss: 0.829003]\n",
      "epoch:5 step:4851 [D loss: 0.684853, acc.: 60.16%] [G loss: 1.011113]\n",
      "epoch:5 step:4852 [D loss: 0.641779, acc.: 63.28%] [G loss: 0.981324]\n",
      "epoch:5 step:4853 [D loss: 0.569291, acc.: 71.09%] [G loss: 1.045180]\n",
      "epoch:5 step:4854 [D loss: 0.692380, acc.: 56.25%] [G loss: 0.998838]\n",
      "epoch:5 step:4855 [D loss: 0.578431, acc.: 69.53%] [G loss: 0.977388]\n",
      "epoch:5 step:4856 [D loss: 0.649114, acc.: 63.28%] [G loss: 0.951102]\n",
      "epoch:5 step:4857 [D loss: 0.513319, acc.: 73.44%] [G loss: 1.257796]\n",
      "epoch:5 step:4858 [D loss: 0.708601, acc.: 54.69%] [G loss: 1.065311]\n",
      "epoch:5 step:4859 [D loss: 0.657616, acc.: 60.94%] [G loss: 1.147619]\n",
      "epoch:5 step:4860 [D loss: 0.640286, acc.: 61.72%] [G loss: 1.032711]\n",
      "epoch:5 step:4861 [D loss: 0.602956, acc.: 69.53%] [G loss: 1.130256]\n",
      "epoch:5 step:4862 [D loss: 0.642703, acc.: 62.50%] [G loss: 1.114946]\n",
      "epoch:5 step:4863 [D loss: 0.621288, acc.: 66.41%] [G loss: 1.058836]\n",
      "epoch:5 step:4864 [D loss: 0.685749, acc.: 57.81%] [G loss: 0.967927]\n",
      "epoch:5 step:4865 [D loss: 0.607008, acc.: 62.50%] [G loss: 1.123542]\n",
      "epoch:5 step:4866 [D loss: 0.661805, acc.: 59.38%] [G loss: 0.983872]\n",
      "epoch:5 step:4867 [D loss: 0.575854, acc.: 72.66%] [G loss: 1.157270]\n",
      "epoch:5 step:4868 [D loss: 0.674779, acc.: 59.38%] [G loss: 1.100376]\n",
      "epoch:5 step:4869 [D loss: 0.647560, acc.: 59.38%] [G loss: 0.981466]\n",
      "epoch:5 step:4870 [D loss: 0.659617, acc.: 60.16%] [G loss: 0.967446]\n",
      "epoch:5 step:4871 [D loss: 0.654457, acc.: 60.16%] [G loss: 1.078174]\n",
      "epoch:5 step:4872 [D loss: 0.675569, acc.: 58.59%] [G loss: 1.039890]\n",
      "epoch:5 step:4873 [D loss: 0.648844, acc.: 65.62%] [G loss: 0.968542]\n",
      "epoch:5 step:4874 [D loss: 0.666229, acc.: 58.59%] [G loss: 0.913148]\n",
      "epoch:5 step:4875 [D loss: 0.614516, acc.: 67.19%] [G loss: 0.990764]\n",
      "epoch:5 step:4876 [D loss: 0.565297, acc.: 71.09%] [G loss: 1.080751]\n",
      "epoch:5 step:4877 [D loss: 0.665384, acc.: 57.81%] [G loss: 1.123781]\n",
      "epoch:5 step:4878 [D loss: 0.728487, acc.: 54.69%] [G loss: 1.078328]\n",
      "epoch:5 step:4879 [D loss: 0.658419, acc.: 57.03%] [G loss: 1.103061]\n",
      "epoch:5 step:4880 [D loss: 0.729063, acc.: 57.81%] [G loss: 0.943994]\n",
      "epoch:5 step:4881 [D loss: 0.635417, acc.: 63.28%] [G loss: 1.002182]\n",
      "epoch:5 step:4882 [D loss: 0.671874, acc.: 62.50%] [G loss: 0.932312]\n",
      "epoch:5 step:4883 [D loss: 0.642911, acc.: 62.50%] [G loss: 0.911204]\n",
      "epoch:5 step:4884 [D loss: 0.540530, acc.: 76.56%] [G loss: 1.105418]\n",
      "epoch:5 step:4885 [D loss: 0.623452, acc.: 68.75%] [G loss: 0.945565]\n",
      "epoch:5 step:4886 [D loss: 0.543056, acc.: 72.66%] [G loss: 1.041066]\n",
      "epoch:5 step:4887 [D loss: 0.605053, acc.: 64.84%] [G loss: 1.019453]\n",
      "epoch:5 step:4888 [D loss: 0.522146, acc.: 79.69%] [G loss: 1.202526]\n",
      "epoch:5 step:4889 [D loss: 0.692762, acc.: 56.25%] [G loss: 1.040552]\n",
      "epoch:5 step:4890 [D loss: 0.510896, acc.: 80.47%] [G loss: 1.327025]\n",
      "epoch:5 step:4891 [D loss: 0.738950, acc.: 49.22%] [G loss: 0.912722]\n",
      "epoch:5 step:4892 [D loss: 0.647887, acc.: 62.50%] [G loss: 1.013879]\n",
      "epoch:5 step:4893 [D loss: 0.657618, acc.: 57.81%] [G loss: 1.056481]\n",
      "epoch:5 step:4894 [D loss: 0.568573, acc.: 71.88%] [G loss: 1.018446]\n",
      "epoch:5 step:4895 [D loss: 0.682280, acc.: 61.72%] [G loss: 0.901781]\n",
      "epoch:5 step:4896 [D loss: 0.593821, acc.: 71.09%] [G loss: 0.989036]\n",
      "epoch:5 step:4897 [D loss: 0.587040, acc.: 69.53%] [G loss: 1.093522]\n",
      "epoch:5 step:4898 [D loss: 0.691288, acc.: 61.72%] [G loss: 0.948681]\n",
      "epoch:5 step:4899 [D loss: 0.714968, acc.: 51.56%] [G loss: 1.009108]\n",
      "epoch:5 step:4900 [D loss: 0.568549, acc.: 71.09%] [G loss: 0.983442]\n",
      "epoch:5 step:4901 [D loss: 0.585063, acc.: 67.97%] [G loss: 1.111439]\n",
      "epoch:5 step:4902 [D loss: 0.604339, acc.: 69.53%] [G loss: 0.998064]\n",
      "epoch:5 step:4903 [D loss: 0.596612, acc.: 73.44%] [G loss: 1.162912]\n",
      "epoch:5 step:4904 [D loss: 0.698015, acc.: 56.25%] [G loss: 1.060194]\n",
      "epoch:5 step:4905 [D loss: 0.567559, acc.: 71.09%] [G loss: 1.076048]\n",
      "epoch:5 step:4906 [D loss: 0.662816, acc.: 61.72%] [G loss: 1.077536]\n",
      "epoch:5 step:4907 [D loss: 0.720421, acc.: 47.66%] [G loss: 1.100601]\n",
      "epoch:5 step:4908 [D loss: 0.654504, acc.: 64.06%] [G loss: 1.007576]\n",
      "epoch:5 step:4909 [D loss: 0.595169, acc.: 63.28%] [G loss: 0.918186]\n",
      "epoch:5 step:4910 [D loss: 0.648078, acc.: 60.94%] [G loss: 1.149321]\n",
      "epoch:5 step:4911 [D loss: 0.615786, acc.: 64.06%] [G loss: 1.113618]\n",
      "epoch:5 step:4912 [D loss: 0.590600, acc.: 67.19%] [G loss: 1.253562]\n",
      "epoch:5 step:4913 [D loss: 0.629327, acc.: 70.31%] [G loss: 0.975255]\n",
      "epoch:5 step:4914 [D loss: 0.697466, acc.: 56.25%] [G loss: 0.988325]\n",
      "epoch:5 step:4915 [D loss: 0.701550, acc.: 59.38%] [G loss: 0.864017]\n",
      "epoch:5 step:4916 [D loss: 0.643559, acc.: 60.16%] [G loss: 1.031434]\n",
      "epoch:5 step:4917 [D loss: 0.737535, acc.: 53.12%] [G loss: 0.973761]\n",
      "epoch:5 step:4918 [D loss: 0.583206, acc.: 72.66%] [G loss: 1.190834]\n",
      "epoch:5 step:4919 [D loss: 0.703470, acc.: 54.69%] [G loss: 0.977320]\n",
      "epoch:5 step:4920 [D loss: 0.601054, acc.: 63.28%] [G loss: 1.097537]\n",
      "epoch:5 step:4921 [D loss: 0.569150, acc.: 73.44%] [G loss: 1.004893]\n",
      "epoch:5 step:4922 [D loss: 0.677750, acc.: 58.59%] [G loss: 0.954672]\n",
      "epoch:5 step:4923 [D loss: 0.635430, acc.: 64.06%] [G loss: 1.104402]\n",
      "epoch:5 step:4924 [D loss: 0.614126, acc.: 65.62%] [G loss: 1.077910]\n",
      "epoch:5 step:4925 [D loss: 0.716225, acc.: 54.69%] [G loss: 0.974041]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:5 step:4926 [D loss: 0.646536, acc.: 63.28%] [G loss: 0.983776]\n",
      "epoch:5 step:4927 [D loss: 0.576351, acc.: 65.62%] [G loss: 1.247559]\n",
      "epoch:5 step:4928 [D loss: 0.667377, acc.: 62.50%] [G loss: 0.997047]\n",
      "epoch:5 step:4929 [D loss: 0.633926, acc.: 60.16%] [G loss: 1.085502]\n",
      "epoch:5 step:4930 [D loss: 0.600856, acc.: 71.88%] [G loss: 1.086819]\n",
      "epoch:5 step:4931 [D loss: 0.630180, acc.: 63.28%] [G loss: 0.991701]\n",
      "epoch:5 step:4932 [D loss: 0.608861, acc.: 63.28%] [G loss: 0.979825]\n",
      "epoch:5 step:4933 [D loss: 0.606235, acc.: 65.62%] [G loss: 0.875615]\n",
      "epoch:5 step:4934 [D loss: 0.599216, acc.: 68.75%] [G loss: 1.090166]\n",
      "epoch:5 step:4935 [D loss: 0.650090, acc.: 60.94%] [G loss: 0.918493]\n",
      "epoch:5 step:4936 [D loss: 0.703315, acc.: 51.56%] [G loss: 1.045454]\n",
      "epoch:5 step:4937 [D loss: 0.597347, acc.: 71.09%] [G loss: 1.033508]\n",
      "epoch:5 step:4938 [D loss: 0.644890, acc.: 60.16%] [G loss: 1.141004]\n",
      "epoch:5 step:4939 [D loss: 0.729006, acc.: 53.91%] [G loss: 0.869327]\n",
      "epoch:5 step:4940 [D loss: 0.671744, acc.: 61.72%] [G loss: 0.877960]\n",
      "epoch:5 step:4941 [D loss: 0.645577, acc.: 61.72%] [G loss: 1.079839]\n",
      "epoch:5 step:4942 [D loss: 0.638253, acc.: 62.50%] [G loss: 1.091464]\n",
      "epoch:5 step:4943 [D loss: 0.671085, acc.: 59.38%] [G loss: 0.931253]\n",
      "epoch:5 step:4944 [D loss: 0.631457, acc.: 59.38%] [G loss: 1.121058]\n",
      "epoch:5 step:4945 [D loss: 0.603976, acc.: 64.84%] [G loss: 1.027007]\n",
      "epoch:5 step:4946 [D loss: 0.505703, acc.: 78.91%] [G loss: 1.096247]\n",
      "epoch:5 step:4947 [D loss: 0.637651, acc.: 64.06%] [G loss: 1.108846]\n",
      "epoch:5 step:4948 [D loss: 0.696434, acc.: 56.25%] [G loss: 1.207112]\n",
      "epoch:5 step:4949 [D loss: 0.571051, acc.: 74.22%] [G loss: 1.130381]\n",
      "epoch:5 step:4950 [D loss: 0.610232, acc.: 65.62%] [G loss: 1.049644]\n",
      "epoch:5 step:4951 [D loss: 0.665479, acc.: 64.84%] [G loss: 1.062727]\n",
      "epoch:5 step:4952 [D loss: 0.623733, acc.: 65.62%] [G loss: 1.035391]\n",
      "epoch:5 step:4953 [D loss: 0.631808, acc.: 62.50%] [G loss: 1.137499]\n",
      "epoch:5 step:4954 [D loss: 0.620801, acc.: 67.19%] [G loss: 1.108373]\n",
      "epoch:5 step:4955 [D loss: 0.675329, acc.: 59.38%] [G loss: 1.213541]\n",
      "epoch:5 step:4956 [D loss: 0.660065, acc.: 63.28%] [G loss: 1.045222]\n",
      "epoch:5 step:4957 [D loss: 0.650031, acc.: 60.94%] [G loss: 1.181731]\n",
      "epoch:5 step:4958 [D loss: 0.598257, acc.: 63.28%] [G loss: 1.149536]\n",
      "epoch:5 step:4959 [D loss: 0.693071, acc.: 52.34%] [G loss: 0.959296]\n",
      "epoch:5 step:4960 [D loss: 0.806771, acc.: 42.97%] [G loss: 0.969540]\n",
      "epoch:5 step:4961 [D loss: 0.662189, acc.: 57.03%] [G loss: 1.257954]\n",
      "epoch:5 step:4962 [D loss: 0.608221, acc.: 65.62%] [G loss: 1.040806]\n",
      "epoch:5 step:4963 [D loss: 0.662184, acc.: 61.72%] [G loss: 1.076549]\n",
      "epoch:5 step:4964 [D loss: 0.696532, acc.: 54.69%] [G loss: 0.958874]\n",
      "epoch:5 step:4965 [D loss: 0.637909, acc.: 64.84%] [G loss: 0.935843]\n",
      "epoch:5 step:4966 [D loss: 0.633301, acc.: 60.94%] [G loss: 0.976289]\n",
      "epoch:5 step:4967 [D loss: 0.578617, acc.: 66.41%] [G loss: 1.190912]\n",
      "epoch:5 step:4968 [D loss: 0.603705, acc.: 70.31%] [G loss: 1.211918]\n",
      "epoch:5 step:4969 [D loss: 0.690781, acc.: 57.81%] [G loss: 0.929488]\n",
      "epoch:5 step:4970 [D loss: 0.654930, acc.: 57.03%] [G loss: 1.036313]\n",
      "epoch:5 step:4971 [D loss: 0.689920, acc.: 60.16%] [G loss: 1.032570]\n",
      "epoch:5 step:4972 [D loss: 0.645293, acc.: 63.28%] [G loss: 1.143198]\n",
      "epoch:5 step:4973 [D loss: 0.719661, acc.: 56.25%] [G loss: 1.066160]\n",
      "epoch:5 step:4974 [D loss: 0.664442, acc.: 61.72%] [G loss: 1.014753]\n",
      "epoch:5 step:4975 [D loss: 0.744779, acc.: 51.56%] [G loss: 1.035497]\n",
      "epoch:5 step:4976 [D loss: 0.611187, acc.: 64.84%] [G loss: 1.004459]\n",
      "epoch:5 step:4977 [D loss: 0.611023, acc.: 65.62%] [G loss: 0.955759]\n",
      "epoch:5 step:4978 [D loss: 0.646936, acc.: 64.06%] [G loss: 1.126414]\n",
      "epoch:5 step:4979 [D loss: 0.716544, acc.: 55.47%] [G loss: 0.978530]\n",
      "epoch:5 step:4980 [D loss: 0.645631, acc.: 65.62%] [G loss: 1.004778]\n",
      "epoch:5 step:4981 [D loss: 0.617024, acc.: 70.31%] [G loss: 1.111059]\n",
      "epoch:5 step:4982 [D loss: 0.666151, acc.: 57.81%] [G loss: 0.875078]\n",
      "epoch:5 step:4983 [D loss: 0.604265, acc.: 64.84%] [G loss: 1.180889]\n",
      "epoch:5 step:4984 [D loss: 0.669136, acc.: 57.03%] [G loss: 1.085575]\n",
      "epoch:5 step:4985 [D loss: 0.620215, acc.: 64.06%] [G loss: 0.921128]\n",
      "epoch:5 step:4986 [D loss: 0.734886, acc.: 48.44%] [G loss: 1.060386]\n",
      "epoch:5 step:4987 [D loss: 0.603441, acc.: 65.62%] [G loss: 1.081085]\n",
      "epoch:5 step:4988 [D loss: 0.643053, acc.: 65.62%] [G loss: 0.978298]\n",
      "epoch:5 step:4989 [D loss: 0.659504, acc.: 60.94%] [G loss: 1.177142]\n",
      "epoch:5 step:4990 [D loss: 0.648721, acc.: 68.75%] [G loss: 1.006072]\n",
      "epoch:5 step:4991 [D loss: 0.628611, acc.: 66.41%] [G loss: 1.002815]\n",
      "epoch:5 step:4992 [D loss: 0.683640, acc.: 58.59%] [G loss: 1.020449]\n",
      "epoch:5 step:4993 [D loss: 0.742783, acc.: 50.00%] [G loss: 0.903906]\n",
      "epoch:5 step:4994 [D loss: 0.657397, acc.: 61.72%] [G loss: 1.006630]\n",
      "epoch:5 step:4995 [D loss: 0.661317, acc.: 55.47%] [G loss: 1.023636]\n",
      "epoch:5 step:4996 [D loss: 0.572738, acc.: 71.88%] [G loss: 1.069520]\n",
      "epoch:5 step:4997 [D loss: 0.736402, acc.: 46.88%] [G loss: 0.999612]\n",
      "epoch:5 step:4998 [D loss: 0.653995, acc.: 58.59%] [G loss: 1.083608]\n",
      "epoch:5 step:4999 [D loss: 0.599449, acc.: 65.62%] [G loss: 1.070825]\n",
      "epoch:5 step:5000 [D loss: 0.656144, acc.: 61.72%] [G loss: 0.859543]\n",
      "epoch:5 step:5001 [D loss: 0.740455, acc.: 52.34%] [G loss: 0.904109]\n",
      "epoch:5 step:5002 [D loss: 0.686990, acc.: 59.38%] [G loss: 1.055451]\n",
      "epoch:5 step:5003 [D loss: 0.715789, acc.: 49.22%] [G loss: 0.980379]\n",
      "epoch:5 step:5004 [D loss: 0.572949, acc.: 69.53%] [G loss: 1.021128]\n",
      "epoch:5 step:5005 [D loss: 0.549019, acc.: 74.22%] [G loss: 1.118697]\n",
      "epoch:5 step:5006 [D loss: 0.667387, acc.: 63.28%] [G loss: 1.079275]\n",
      "epoch:5 step:5007 [D loss: 0.727982, acc.: 51.56%] [G loss: 1.006795]\n",
      "epoch:5 step:5008 [D loss: 0.636993, acc.: 64.84%] [G loss: 1.011879]\n",
      "epoch:5 step:5009 [D loss: 0.602733, acc.: 65.62%] [G loss: 0.967469]\n",
      "epoch:5 step:5010 [D loss: 0.605353, acc.: 65.62%] [G loss: 1.025536]\n",
      "epoch:5 step:5011 [D loss: 0.572673, acc.: 73.44%] [G loss: 1.028218]\n",
      "epoch:5 step:5012 [D loss: 0.686864, acc.: 53.12%] [G loss: 1.000563]\n",
      "epoch:5 step:5013 [D loss: 0.585838, acc.: 68.75%] [G loss: 1.099640]\n",
      "epoch:5 step:5014 [D loss: 0.667338, acc.: 57.03%] [G loss: 1.169182]\n",
      "epoch:5 step:5015 [D loss: 0.630692, acc.: 69.53%] [G loss: 0.934832]\n",
      "epoch:5 step:5016 [D loss: 0.606436, acc.: 68.75%] [G loss: 1.101098]\n",
      "epoch:5 step:5017 [D loss: 0.652785, acc.: 64.06%] [G loss: 0.955022]\n",
      "epoch:5 step:5018 [D loss: 0.602320, acc.: 67.97%] [G loss: 0.995871]\n",
      "epoch:5 step:5019 [D loss: 0.694637, acc.: 57.03%] [G loss: 1.049171]\n",
      "epoch:5 step:5020 [D loss: 0.617369, acc.: 67.97%] [G loss: 1.040888]\n",
      "epoch:5 step:5021 [D loss: 0.513509, acc.: 78.91%] [G loss: 1.190627]\n",
      "epoch:5 step:5022 [D loss: 0.630553, acc.: 62.50%] [G loss: 1.124190]\n",
      "epoch:5 step:5023 [D loss: 0.621904, acc.: 61.72%] [G loss: 1.046847]\n",
      "epoch:5 step:5024 [D loss: 0.652745, acc.: 64.06%] [G loss: 1.230779]\n",
      "epoch:5 step:5025 [D loss: 0.632264, acc.: 65.62%] [G loss: 1.016013]\n",
      "epoch:5 step:5026 [D loss: 0.602946, acc.: 68.75%] [G loss: 1.039871]\n",
      "epoch:5 step:5027 [D loss: 0.664787, acc.: 64.84%] [G loss: 1.182251]\n",
      "epoch:5 step:5028 [D loss: 0.616982, acc.: 66.41%] [G loss: 1.085707]\n",
      "epoch:5 step:5029 [D loss: 0.643679, acc.: 61.72%] [G loss: 0.851543]\n",
      "epoch:5 step:5030 [D loss: 0.673448, acc.: 60.16%] [G loss: 1.036417]\n",
      "epoch:5 step:5031 [D loss: 0.713090, acc.: 58.59%] [G loss: 0.990220]\n",
      "epoch:5 step:5032 [D loss: 0.682265, acc.: 57.81%] [G loss: 0.991516]\n",
      "epoch:5 step:5033 [D loss: 0.636716, acc.: 64.06%] [G loss: 0.995455]\n",
      "epoch:5 step:5034 [D loss: 0.610542, acc.: 65.62%] [G loss: 1.129236]\n",
      "epoch:5 step:5035 [D loss: 0.605103, acc.: 71.88%] [G loss: 1.164551]\n",
      "epoch:5 step:5036 [D loss: 0.617186, acc.: 68.75%] [G loss: 1.046052]\n",
      "epoch:5 step:5037 [D loss: 0.686011, acc.: 62.50%] [G loss: 0.846094]\n",
      "epoch:5 step:5038 [D loss: 0.582391, acc.: 71.88%] [G loss: 1.035972]\n",
      "epoch:5 step:5039 [D loss: 0.629048, acc.: 63.28%] [G loss: 1.124492]\n",
      "epoch:5 step:5040 [D loss: 0.612327, acc.: 63.28%] [G loss: 1.173574]\n",
      "epoch:5 step:5041 [D loss: 0.642886, acc.: 57.03%] [G loss: 1.072506]\n",
      "epoch:5 step:5042 [D loss: 0.669586, acc.: 58.59%] [G loss: 1.003181]\n",
      "epoch:5 step:5043 [D loss: 0.651946, acc.: 65.62%] [G loss: 0.976433]\n",
      "epoch:5 step:5044 [D loss: 0.666251, acc.: 64.06%] [G loss: 1.002404]\n",
      "epoch:5 step:5045 [D loss: 0.595090, acc.: 70.31%] [G loss: 0.998934]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:5 step:5046 [D loss: 0.645118, acc.: 64.06%] [G loss: 0.968639]\n",
      "epoch:5 step:5047 [D loss: 0.593953, acc.: 67.19%] [G loss: 0.916078]\n",
      "epoch:5 step:5048 [D loss: 0.602419, acc.: 65.62%] [G loss: 0.997053]\n",
      "epoch:5 step:5049 [D loss: 0.550712, acc.: 75.78%] [G loss: 1.064157]\n",
      "epoch:5 step:5050 [D loss: 0.581835, acc.: 71.88%] [G loss: 1.202371]\n",
      "epoch:5 step:5051 [D loss: 0.585961, acc.: 72.66%] [G loss: 1.109436]\n",
      "epoch:5 step:5052 [D loss: 0.669438, acc.: 60.94%] [G loss: 1.049025]\n",
      "epoch:5 step:5053 [D loss: 0.586932, acc.: 70.31%] [G loss: 1.108806]\n",
      "epoch:5 step:5054 [D loss: 0.671414, acc.: 59.38%] [G loss: 0.942615]\n",
      "epoch:5 step:5055 [D loss: 0.644624, acc.: 63.28%] [G loss: 0.790162]\n",
      "epoch:5 step:5056 [D loss: 0.674721, acc.: 57.81%] [G loss: 1.025977]\n",
      "epoch:5 step:5057 [D loss: 0.558619, acc.: 69.53%] [G loss: 1.164941]\n",
      "epoch:5 step:5058 [D loss: 0.618383, acc.: 64.06%] [G loss: 1.018752]\n",
      "epoch:5 step:5059 [D loss: 0.743069, acc.: 51.56%] [G loss: 1.059027]\n",
      "epoch:5 step:5060 [D loss: 0.659234, acc.: 60.16%] [G loss: 1.082861]\n",
      "epoch:5 step:5061 [D loss: 0.671772, acc.: 60.16%] [G loss: 0.953306]\n",
      "epoch:5 step:5062 [D loss: 0.663600, acc.: 59.38%] [G loss: 0.878142]\n",
      "epoch:5 step:5063 [D loss: 0.685490, acc.: 57.81%] [G loss: 1.076404]\n",
      "epoch:5 step:5064 [D loss: 0.582625, acc.: 70.31%] [G loss: 1.198463]\n",
      "epoch:5 step:5065 [D loss: 0.673145, acc.: 63.28%] [G loss: 0.978853]\n",
      "epoch:5 step:5066 [D loss: 0.659203, acc.: 59.38%] [G loss: 1.032852]\n",
      "epoch:5 step:5067 [D loss: 0.695728, acc.: 57.81%] [G loss: 1.060954]\n",
      "epoch:5 step:5068 [D loss: 0.564064, acc.: 67.97%] [G loss: 1.246117]\n",
      "epoch:5 step:5069 [D loss: 0.597394, acc.: 71.09%] [G loss: 1.002807]\n",
      "epoch:5 step:5070 [D loss: 0.718096, acc.: 51.56%] [G loss: 1.016030]\n",
      "epoch:5 step:5071 [D loss: 0.608257, acc.: 64.06%] [G loss: 0.972097]\n",
      "epoch:5 step:5072 [D loss: 0.621432, acc.: 60.16%] [G loss: 1.152092]\n",
      "epoch:5 step:5073 [D loss: 0.729106, acc.: 50.00%] [G loss: 0.807966]\n",
      "epoch:5 step:5074 [D loss: 0.581290, acc.: 70.31%] [G loss: 0.979854]\n",
      "epoch:5 step:5075 [D loss: 0.669554, acc.: 64.06%] [G loss: 0.963119]\n",
      "epoch:5 step:5076 [D loss: 0.660742, acc.: 67.19%] [G loss: 0.957750]\n",
      "epoch:5 step:5077 [D loss: 0.572472, acc.: 67.19%] [G loss: 1.096035]\n",
      "epoch:5 step:5078 [D loss: 0.655818, acc.: 60.16%] [G loss: 1.011556]\n",
      "epoch:5 step:5079 [D loss: 0.641760, acc.: 62.50%] [G loss: 0.954634]\n",
      "epoch:5 step:5080 [D loss: 0.615024, acc.: 67.97%] [G loss: 1.017496]\n",
      "epoch:5 step:5081 [D loss: 0.670059, acc.: 58.59%] [G loss: 1.175840]\n",
      "epoch:5 step:5082 [D loss: 0.630634, acc.: 64.84%] [G loss: 1.091565]\n",
      "epoch:5 step:5083 [D loss: 0.667450, acc.: 57.81%] [G loss: 1.029581]\n",
      "epoch:5 step:5084 [D loss: 0.591581, acc.: 75.00%] [G loss: 1.080004]\n",
      "epoch:5 step:5085 [D loss: 0.684591, acc.: 57.03%] [G loss: 0.875721]\n",
      "epoch:5 step:5086 [D loss: 0.624299, acc.: 70.31%] [G loss: 1.136393]\n",
      "epoch:5 step:5087 [D loss: 0.636803, acc.: 67.97%] [G loss: 1.133992]\n",
      "epoch:5 step:5088 [D loss: 0.590276, acc.: 67.19%] [G loss: 0.928590]\n",
      "epoch:5 step:5089 [D loss: 0.762825, acc.: 46.09%] [G loss: 0.916011]\n",
      "epoch:5 step:5090 [D loss: 0.624665, acc.: 60.16%] [G loss: 0.940430]\n",
      "epoch:5 step:5091 [D loss: 0.548567, acc.: 78.12%] [G loss: 0.949247]\n",
      "epoch:5 step:5092 [D loss: 0.598947, acc.: 63.28%] [G loss: 0.996492]\n",
      "epoch:5 step:5093 [D loss: 0.590196, acc.: 71.09%] [G loss: 1.008665]\n",
      "epoch:5 step:5094 [D loss: 0.587048, acc.: 71.09%] [G loss: 0.976656]\n",
      "epoch:5 step:5095 [D loss: 0.579005, acc.: 67.19%] [G loss: 1.035853]\n",
      "epoch:5 step:5096 [D loss: 0.612727, acc.: 70.31%] [G loss: 1.204195]\n",
      "epoch:5 step:5097 [D loss: 0.654282, acc.: 57.81%] [G loss: 0.899288]\n",
      "epoch:5 step:5098 [D loss: 0.687589, acc.: 60.16%] [G loss: 0.941729]\n",
      "epoch:5 step:5099 [D loss: 0.644069, acc.: 67.97%] [G loss: 1.020042]\n",
      "epoch:5 step:5100 [D loss: 0.690873, acc.: 60.16%] [G loss: 1.032663]\n",
      "epoch:5 step:5101 [D loss: 0.663373, acc.: 63.28%] [G loss: 1.003992]\n",
      "epoch:5 step:5102 [D loss: 0.643883, acc.: 62.50%] [G loss: 0.889178]\n",
      "epoch:5 step:5103 [D loss: 0.709672, acc.: 57.03%] [G loss: 1.186240]\n",
      "epoch:5 step:5104 [D loss: 0.595044, acc.: 69.53%] [G loss: 1.079056]\n",
      "epoch:5 step:5105 [D loss: 0.666121, acc.: 62.50%] [G loss: 1.108845]\n",
      "epoch:5 step:5106 [D loss: 0.615359, acc.: 64.06%] [G loss: 1.099880]\n",
      "epoch:5 step:5107 [D loss: 0.640296, acc.: 67.19%] [G loss: 1.178056]\n",
      "epoch:5 step:5108 [D loss: 0.625081, acc.: 65.62%] [G loss: 1.034009]\n",
      "epoch:5 step:5109 [D loss: 0.675459, acc.: 57.03%] [G loss: 0.990929]\n",
      "epoch:5 step:5110 [D loss: 0.596203, acc.: 68.75%] [G loss: 0.981694]\n",
      "epoch:5 step:5111 [D loss: 0.595785, acc.: 70.31%] [G loss: 1.102178]\n",
      "epoch:5 step:5112 [D loss: 0.629710, acc.: 64.06%] [G loss: 1.012081]\n",
      "epoch:5 step:5113 [D loss: 0.697986, acc.: 56.25%] [G loss: 1.075735]\n",
      "epoch:5 step:5114 [D loss: 0.616849, acc.: 65.62%] [G loss: 0.956522]\n",
      "epoch:5 step:5115 [D loss: 0.699540, acc.: 53.12%] [G loss: 0.922366]\n",
      "epoch:5 step:5116 [D loss: 0.599686, acc.: 73.44%] [G loss: 1.059990]\n",
      "epoch:5 step:5117 [D loss: 0.621737, acc.: 66.41%] [G loss: 1.170673]\n",
      "epoch:5 step:5118 [D loss: 0.599879, acc.: 67.97%] [G loss: 1.104640]\n",
      "epoch:5 step:5119 [D loss: 0.726891, acc.: 53.12%] [G loss: 1.032328]\n",
      "epoch:5 step:5120 [D loss: 0.673680, acc.: 57.81%] [G loss: 0.888162]\n",
      "epoch:5 step:5121 [D loss: 0.648471, acc.: 64.06%] [G loss: 1.014605]\n",
      "epoch:5 step:5122 [D loss: 0.692798, acc.: 54.69%] [G loss: 1.136020]\n",
      "epoch:5 step:5123 [D loss: 0.651644, acc.: 64.06%] [G loss: 1.188518]\n",
      "epoch:5 step:5124 [D loss: 0.596473, acc.: 68.75%] [G loss: 0.993232]\n",
      "epoch:5 step:5125 [D loss: 0.608603, acc.: 65.62%] [G loss: 1.029016]\n",
      "epoch:5 step:5126 [D loss: 0.564875, acc.: 67.97%] [G loss: 1.148330]\n",
      "epoch:5 step:5127 [D loss: 0.700883, acc.: 58.59%] [G loss: 0.997932]\n",
      "epoch:5 step:5128 [D loss: 0.652291, acc.: 62.50%] [G loss: 1.085170]\n",
      "epoch:5 step:5129 [D loss: 0.600846, acc.: 68.75%] [G loss: 1.149280]\n",
      "epoch:5 step:5130 [D loss: 0.609741, acc.: 67.19%] [G loss: 1.206990]\n",
      "epoch:5 step:5131 [D loss: 0.696408, acc.: 57.81%] [G loss: 0.892646]\n",
      "epoch:5 step:5132 [D loss: 0.677768, acc.: 60.94%] [G loss: 0.972423]\n",
      "epoch:5 step:5133 [D loss: 0.653174, acc.: 57.03%] [G loss: 1.167046]\n",
      "epoch:5 step:5134 [D loss: 0.656971, acc.: 61.72%] [G loss: 1.175533]\n",
      "epoch:5 step:5135 [D loss: 0.626914, acc.: 69.53%] [G loss: 1.003071]\n",
      "epoch:5 step:5136 [D loss: 0.677614, acc.: 58.59%] [G loss: 1.123635]\n",
      "epoch:5 step:5137 [D loss: 0.681411, acc.: 53.91%] [G loss: 0.998859]\n",
      "epoch:5 step:5138 [D loss: 0.587477, acc.: 70.31%] [G loss: 0.979438]\n",
      "epoch:5 step:5139 [D loss: 0.524118, acc.: 77.34%] [G loss: 1.190354]\n",
      "epoch:5 step:5140 [D loss: 0.611548, acc.: 67.19%] [G loss: 1.175585]\n",
      "epoch:5 step:5141 [D loss: 0.653783, acc.: 60.94%] [G loss: 0.943727]\n",
      "epoch:5 step:5142 [D loss: 0.636444, acc.: 65.62%] [G loss: 1.007419]\n",
      "epoch:5 step:5143 [D loss: 0.625946, acc.: 60.94%] [G loss: 1.100454]\n",
      "epoch:5 step:5144 [D loss: 0.582434, acc.: 68.75%] [G loss: 1.052886]\n",
      "epoch:5 step:5145 [D loss: 0.596625, acc.: 68.75%] [G loss: 1.004922]\n",
      "epoch:5 step:5146 [D loss: 0.688324, acc.: 55.47%] [G loss: 1.100762]\n",
      "epoch:5 step:5147 [D loss: 0.622844, acc.: 69.53%] [G loss: 0.949236]\n",
      "epoch:5 step:5148 [D loss: 0.667656, acc.: 58.59%] [G loss: 1.044947]\n",
      "epoch:5 step:5149 [D loss: 0.571665, acc.: 73.44%] [G loss: 0.989291]\n",
      "epoch:5 step:5150 [D loss: 0.649093, acc.: 60.94%] [G loss: 1.045577]\n",
      "epoch:5 step:5151 [D loss: 0.657842, acc.: 59.38%] [G loss: 0.973277]\n",
      "epoch:5 step:5152 [D loss: 0.606305, acc.: 65.62%] [G loss: 1.215110]\n",
      "epoch:5 step:5153 [D loss: 0.596525, acc.: 65.62%] [G loss: 0.979347]\n",
      "epoch:5 step:5154 [D loss: 0.678664, acc.: 59.38%] [G loss: 0.969924]\n",
      "epoch:5 step:5155 [D loss: 0.634663, acc.: 63.28%] [G loss: 1.119896]\n",
      "epoch:5 step:5156 [D loss: 0.639230, acc.: 63.28%] [G loss: 0.986543]\n",
      "epoch:5 step:5157 [D loss: 0.590144, acc.: 71.88%] [G loss: 1.137785]\n",
      "epoch:5 step:5158 [D loss: 0.660451, acc.: 58.59%] [G loss: 1.026269]\n",
      "epoch:5 step:5159 [D loss: 0.620752, acc.: 66.41%] [G loss: 1.078262]\n",
      "epoch:5 step:5160 [D loss: 0.593810, acc.: 67.19%] [G loss: 0.969209]\n",
      "epoch:5 step:5161 [D loss: 0.664462, acc.: 56.25%] [G loss: 1.087823]\n",
      "epoch:5 step:5162 [D loss: 0.634456, acc.: 61.72%] [G loss: 0.940409]\n",
      "epoch:5 step:5163 [D loss: 0.693608, acc.: 60.94%] [G loss: 1.008709]\n",
      "epoch:5 step:5164 [D loss: 0.548658, acc.: 67.19%] [G loss: 1.157578]\n",
      "epoch:5 step:5165 [D loss: 0.690526, acc.: 60.94%] [G loss: 1.097827]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:5 step:5166 [D loss: 0.671041, acc.: 65.62%] [G loss: 0.959785]\n",
      "epoch:5 step:5167 [D loss: 0.661997, acc.: 57.81%] [G loss: 0.872141]\n",
      "epoch:5 step:5168 [D loss: 0.726649, acc.: 51.56%] [G loss: 0.915209]\n",
      "epoch:5 step:5169 [D loss: 0.622528, acc.: 67.97%] [G loss: 1.056107]\n",
      "epoch:5 step:5170 [D loss: 0.656202, acc.: 63.28%] [G loss: 0.983369]\n",
      "epoch:5 step:5171 [D loss: 0.590621, acc.: 66.41%] [G loss: 1.058663]\n",
      "epoch:5 step:5172 [D loss: 0.673037, acc.: 60.94%] [G loss: 0.914313]\n",
      "epoch:5 step:5173 [D loss: 0.579458, acc.: 67.19%] [G loss: 1.204345]\n",
      "epoch:5 step:5174 [D loss: 0.654135, acc.: 62.50%] [G loss: 1.010184]\n",
      "epoch:5 step:5175 [D loss: 0.669291, acc.: 58.59%] [G loss: 1.097304]\n",
      "epoch:5 step:5176 [D loss: 0.597138, acc.: 67.97%] [G loss: 1.181800]\n",
      "epoch:5 step:5177 [D loss: 0.648259, acc.: 68.75%] [G loss: 1.102743]\n",
      "epoch:5 step:5178 [D loss: 0.603922, acc.: 65.62%] [G loss: 1.126224]\n",
      "epoch:5 step:5179 [D loss: 0.594188, acc.: 69.53%] [G loss: 1.049334]\n",
      "epoch:5 step:5180 [D loss: 0.736663, acc.: 50.00%] [G loss: 0.999304]\n",
      "epoch:5 step:5181 [D loss: 0.604367, acc.: 66.41%] [G loss: 1.135232]\n",
      "epoch:5 step:5182 [D loss: 0.687420, acc.: 60.94%] [G loss: 1.114116]\n",
      "epoch:5 step:5183 [D loss: 0.652103, acc.: 64.06%] [G loss: 1.272123]\n",
      "epoch:5 step:5184 [D loss: 0.611413, acc.: 67.97%] [G loss: 0.984229]\n",
      "epoch:5 step:5185 [D loss: 0.689024, acc.: 62.50%] [G loss: 0.991515]\n",
      "epoch:5 step:5186 [D loss: 0.540262, acc.: 74.22%] [G loss: 1.141909]\n",
      "epoch:5 step:5187 [D loss: 0.571232, acc.: 71.09%] [G loss: 1.111856]\n",
      "epoch:5 step:5188 [D loss: 0.619673, acc.: 68.75%] [G loss: 1.011159]\n",
      "epoch:5 step:5189 [D loss: 0.576123, acc.: 67.97%] [G loss: 1.179574]\n",
      "epoch:5 step:5190 [D loss: 0.588946, acc.: 68.75%] [G loss: 1.104033]\n",
      "epoch:5 step:5191 [D loss: 0.657867, acc.: 60.94%] [G loss: 0.907494]\n",
      "epoch:5 step:5192 [D loss: 0.692775, acc.: 56.25%] [G loss: 0.900514]\n",
      "epoch:5 step:5193 [D loss: 0.664910, acc.: 58.59%] [G loss: 1.067996]\n",
      "epoch:5 step:5194 [D loss: 0.645258, acc.: 61.72%] [G loss: 1.012338]\n",
      "epoch:5 step:5195 [D loss: 0.576252, acc.: 71.09%] [G loss: 0.984803]\n",
      "epoch:5 step:5196 [D loss: 0.682644, acc.: 57.03%] [G loss: 1.057770]\n",
      "epoch:5 step:5197 [D loss: 0.680486, acc.: 57.03%] [G loss: 0.901118]\n",
      "epoch:5 step:5198 [D loss: 0.639732, acc.: 61.72%] [G loss: 1.053035]\n",
      "epoch:5 step:5199 [D loss: 0.638326, acc.: 66.41%] [G loss: 1.155428]\n",
      "epoch:5 step:5200 [D loss: 0.569203, acc.: 73.44%] [G loss: 1.075049]\n",
      "epoch:5 step:5201 [D loss: 0.689434, acc.: 54.69%] [G loss: 1.002461]\n",
      "epoch:5 step:5202 [D loss: 0.529535, acc.: 78.91%] [G loss: 1.200971]\n",
      "epoch:5 step:5203 [D loss: 0.692981, acc.: 57.03%] [G loss: 0.933210]\n",
      "epoch:5 step:5204 [D loss: 0.604316, acc.: 70.31%] [G loss: 1.064352]\n",
      "epoch:5 step:5205 [D loss: 0.635731, acc.: 63.28%] [G loss: 1.174117]\n",
      "epoch:5 step:5206 [D loss: 0.653326, acc.: 59.38%] [G loss: 0.925611]\n",
      "epoch:5 step:5207 [D loss: 0.750982, acc.: 52.34%] [G loss: 0.948782]\n",
      "epoch:5 step:5208 [D loss: 0.543635, acc.: 71.09%] [G loss: 1.074257]\n",
      "epoch:5 step:5209 [D loss: 0.612837, acc.: 68.75%] [G loss: 1.159420]\n",
      "epoch:5 step:5210 [D loss: 0.599091, acc.: 67.19%] [G loss: 1.111242]\n",
      "epoch:5 step:5211 [D loss: 0.582971, acc.: 67.97%] [G loss: 1.224067]\n",
      "epoch:5 step:5212 [D loss: 0.585714, acc.: 73.44%] [G loss: 1.029326]\n",
      "epoch:5 step:5213 [D loss: 0.725814, acc.: 56.25%] [G loss: 0.949548]\n",
      "epoch:5 step:5214 [D loss: 0.509595, acc.: 76.56%] [G loss: 1.005389]\n",
      "epoch:5 step:5215 [D loss: 0.578291, acc.: 74.22%] [G loss: 1.025485]\n",
      "epoch:5 step:5216 [D loss: 0.573158, acc.: 76.56%] [G loss: 1.080266]\n",
      "epoch:5 step:5217 [D loss: 0.706587, acc.: 50.00%] [G loss: 1.079595]\n",
      "epoch:5 step:5218 [D loss: 0.634574, acc.: 67.19%] [G loss: 0.980621]\n",
      "epoch:5 step:5219 [D loss: 0.607352, acc.: 67.97%] [G loss: 1.034691]\n",
      "epoch:5 step:5220 [D loss: 0.687111, acc.: 54.69%] [G loss: 0.920107]\n",
      "epoch:5 step:5221 [D loss: 0.651980, acc.: 58.59%] [G loss: 1.001998]\n",
      "epoch:5 step:5222 [D loss: 0.659911, acc.: 57.81%] [G loss: 0.999815]\n",
      "epoch:5 step:5223 [D loss: 0.646963, acc.: 59.38%] [G loss: 1.111275]\n",
      "epoch:5 step:5224 [D loss: 0.565520, acc.: 75.00%] [G loss: 1.090940]\n",
      "epoch:5 step:5225 [D loss: 0.703048, acc.: 57.81%] [G loss: 0.932954]\n",
      "epoch:5 step:5226 [D loss: 0.596469, acc.: 64.84%] [G loss: 1.123564]\n",
      "epoch:5 step:5227 [D loss: 0.612837, acc.: 65.62%] [G loss: 1.195487]\n",
      "epoch:5 step:5228 [D loss: 0.660440, acc.: 60.94%] [G loss: 0.890426]\n",
      "epoch:5 step:5229 [D loss: 0.570310, acc.: 72.66%] [G loss: 1.120185]\n",
      "epoch:5 step:5230 [D loss: 0.617805, acc.: 67.19%] [G loss: 1.063307]\n",
      "epoch:5 step:5231 [D loss: 0.582223, acc.: 74.22%] [G loss: 1.083192]\n",
      "epoch:5 step:5232 [D loss: 0.653653, acc.: 60.94%] [G loss: 1.097904]\n",
      "epoch:5 step:5233 [D loss: 0.640943, acc.: 57.81%] [G loss: 1.147837]\n",
      "epoch:5 step:5234 [D loss: 0.660724, acc.: 64.84%] [G loss: 1.027283]\n",
      "epoch:5 step:5235 [D loss: 0.593257, acc.: 68.75%] [G loss: 1.262466]\n",
      "epoch:5 step:5236 [D loss: 0.654201, acc.: 62.50%] [G loss: 1.081410]\n",
      "epoch:5 step:5237 [D loss: 0.639945, acc.: 67.19%] [G loss: 1.062195]\n",
      "epoch:5 step:5238 [D loss: 0.536422, acc.: 78.12%] [G loss: 1.102806]\n",
      "epoch:5 step:5239 [D loss: 0.625087, acc.: 64.06%] [G loss: 1.026061]\n",
      "epoch:5 step:5240 [D loss: 0.632789, acc.: 64.06%] [G loss: 1.062658]\n",
      "epoch:5 step:5241 [D loss: 0.642576, acc.: 62.50%] [G loss: 1.006636]\n",
      "epoch:5 step:5242 [D loss: 0.621771, acc.: 65.62%] [G loss: 1.072334]\n",
      "epoch:5 step:5243 [D loss: 0.570513, acc.: 70.31%] [G loss: 1.160889]\n",
      "epoch:5 step:5244 [D loss: 0.703365, acc.: 56.25%] [G loss: 0.810235]\n",
      "epoch:5 step:5245 [D loss: 0.617906, acc.: 67.19%] [G loss: 0.980279]\n",
      "epoch:5 step:5246 [D loss: 0.661922, acc.: 60.94%] [G loss: 1.135260]\n",
      "epoch:5 step:5247 [D loss: 0.651109, acc.: 55.47%] [G loss: 1.044650]\n",
      "epoch:5 step:5248 [D loss: 0.574711, acc.: 70.31%] [G loss: 1.107880]\n",
      "epoch:5 step:5249 [D loss: 0.595926, acc.: 67.19%] [G loss: 1.053103]\n",
      "epoch:5 step:5250 [D loss: 0.657739, acc.: 61.72%] [G loss: 0.981993]\n",
      "epoch:5 step:5251 [D loss: 0.677064, acc.: 58.59%] [G loss: 1.053620]\n",
      "epoch:5 step:5252 [D loss: 0.632922, acc.: 64.06%] [G loss: 1.134072]\n",
      "epoch:5 step:5253 [D loss: 0.702028, acc.: 50.00%] [G loss: 1.062059]\n",
      "epoch:5 step:5254 [D loss: 0.640532, acc.: 62.50%] [G loss: 1.003319]\n",
      "epoch:5 step:5255 [D loss: 0.629656, acc.: 64.84%] [G loss: 1.152880]\n",
      "epoch:5 step:5256 [D loss: 0.651885, acc.: 58.59%] [G loss: 1.080636]\n",
      "epoch:5 step:5257 [D loss: 0.519578, acc.: 78.91%] [G loss: 1.268816]\n",
      "epoch:5 step:5258 [D loss: 0.784044, acc.: 43.75%] [G loss: 1.024095]\n",
      "epoch:5 step:5259 [D loss: 0.604633, acc.: 64.06%] [G loss: 1.028249]\n",
      "epoch:5 step:5260 [D loss: 0.638056, acc.: 60.94%] [G loss: 1.134195]\n",
      "epoch:5 step:5261 [D loss: 0.560187, acc.: 75.78%] [G loss: 1.068782]\n",
      "epoch:5 step:5262 [D loss: 0.635106, acc.: 57.81%] [G loss: 1.138299]\n",
      "epoch:5 step:5263 [D loss: 0.640538, acc.: 62.50%] [G loss: 1.011556]\n",
      "epoch:5 step:5264 [D loss: 0.625767, acc.: 65.62%] [G loss: 1.167486]\n",
      "epoch:5 step:5265 [D loss: 0.723463, acc.: 50.78%] [G loss: 0.930110]\n",
      "epoch:5 step:5266 [D loss: 0.662084, acc.: 57.03%] [G loss: 1.068356]\n",
      "epoch:5 step:5267 [D loss: 0.633127, acc.: 62.50%] [G loss: 1.143740]\n",
      "epoch:5 step:5268 [D loss: 0.657138, acc.: 64.06%] [G loss: 0.952829]\n",
      "epoch:5 step:5269 [D loss: 0.594954, acc.: 68.75%] [G loss: 1.150831]\n",
      "epoch:5 step:5270 [D loss: 0.602091, acc.: 69.53%] [G loss: 1.157662]\n",
      "epoch:5 step:5271 [D loss: 0.664551, acc.: 64.06%] [G loss: 1.058197]\n",
      "epoch:5 step:5272 [D loss: 0.646823, acc.: 64.84%] [G loss: 1.220724]\n",
      "epoch:5 step:5273 [D loss: 0.581173, acc.: 73.44%] [G loss: 1.084776]\n",
      "epoch:5 step:5274 [D loss: 0.686932, acc.: 54.69%] [G loss: 0.910239]\n",
      "epoch:5 step:5275 [D loss: 0.576366, acc.: 71.09%] [G loss: 1.071894]\n",
      "epoch:5 step:5276 [D loss: 0.558902, acc.: 70.31%] [G loss: 0.984799]\n",
      "epoch:5 step:5277 [D loss: 0.604178, acc.: 67.97%] [G loss: 0.999082]\n",
      "epoch:5 step:5278 [D loss: 0.726053, acc.: 57.03%] [G loss: 0.984434]\n",
      "epoch:5 step:5279 [D loss: 0.609968, acc.: 71.88%] [G loss: 1.010353]\n",
      "epoch:5 step:5280 [D loss: 0.636958, acc.: 63.28%] [G loss: 1.008915]\n",
      "epoch:5 step:5281 [D loss: 0.646393, acc.: 59.38%] [G loss: 1.025960]\n",
      "epoch:5 step:5282 [D loss: 0.671846, acc.: 55.47%] [G loss: 1.008847]\n",
      "epoch:5 step:5283 [D loss: 0.617568, acc.: 69.53%] [G loss: 1.014895]\n",
      "epoch:5 step:5284 [D loss: 0.550298, acc.: 73.44%] [G loss: 1.172572]\n",
      "epoch:5 step:5285 [D loss: 0.614127, acc.: 71.09%] [G loss: 1.064488]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:5 step:5286 [D loss: 0.597284, acc.: 67.19%] [G loss: 0.945666]\n",
      "epoch:5 step:5287 [D loss: 0.609175, acc.: 65.62%] [G loss: 1.058676]\n",
      "epoch:5 step:5288 [D loss: 0.663754, acc.: 57.03%] [G loss: 1.144745]\n",
      "epoch:5 step:5289 [D loss: 0.730175, acc.: 49.22%] [G loss: 1.026860]\n",
      "epoch:5 step:5290 [D loss: 0.617894, acc.: 65.62%] [G loss: 0.993685]\n",
      "epoch:5 step:5291 [D loss: 0.634654, acc.: 59.38%] [G loss: 1.182705]\n",
      "epoch:5 step:5292 [D loss: 0.692221, acc.: 57.03%] [G loss: 1.111225]\n",
      "epoch:5 step:5293 [D loss: 0.656052, acc.: 64.06%] [G loss: 1.080904]\n",
      "epoch:5 step:5294 [D loss: 0.693593, acc.: 56.25%] [G loss: 1.033417]\n",
      "epoch:5 step:5295 [D loss: 0.677587, acc.: 57.81%] [G loss: 1.080109]\n",
      "epoch:5 step:5296 [D loss: 0.697792, acc.: 56.25%] [G loss: 0.931518]\n",
      "epoch:5 step:5297 [D loss: 0.619617, acc.: 66.41%] [G loss: 1.121825]\n",
      "epoch:5 step:5298 [D loss: 0.635108, acc.: 68.75%] [G loss: 1.103837]\n",
      "epoch:5 step:5299 [D loss: 0.598625, acc.: 67.97%] [G loss: 1.054464]\n",
      "epoch:5 step:5300 [D loss: 0.601347, acc.: 64.06%] [G loss: 1.069466]\n",
      "epoch:5 step:5301 [D loss: 0.622752, acc.: 69.53%] [G loss: 1.197095]\n",
      "epoch:5 step:5302 [D loss: 0.625886, acc.: 70.31%] [G loss: 1.050025]\n",
      "epoch:5 step:5303 [D loss: 0.603369, acc.: 69.53%] [G loss: 0.998628]\n",
      "epoch:5 step:5304 [D loss: 0.641387, acc.: 64.84%] [G loss: 1.083418]\n",
      "epoch:5 step:5305 [D loss: 0.666207, acc.: 62.50%] [G loss: 0.984563]\n",
      "epoch:5 step:5306 [D loss: 0.709337, acc.: 54.69%] [G loss: 0.928801]\n",
      "epoch:5 step:5307 [D loss: 0.607355, acc.: 65.62%] [G loss: 1.029909]\n",
      "epoch:5 step:5308 [D loss: 0.615035, acc.: 64.84%] [G loss: 1.142634]\n",
      "epoch:5 step:5309 [D loss: 0.624458, acc.: 66.41%] [G loss: 1.108019]\n",
      "epoch:5 step:5310 [D loss: 0.659887, acc.: 58.59%] [G loss: 0.942827]\n",
      "epoch:5 step:5311 [D loss: 0.718233, acc.: 52.34%] [G loss: 1.034139]\n",
      "epoch:5 step:5312 [D loss: 0.601150, acc.: 65.62%] [G loss: 1.056980]\n",
      "epoch:5 step:5313 [D loss: 0.683444, acc.: 54.69%] [G loss: 1.065345]\n",
      "epoch:5 step:5314 [D loss: 0.675804, acc.: 57.03%] [G loss: 1.114372]\n",
      "epoch:5 step:5315 [D loss: 0.668472, acc.: 58.59%] [G loss: 1.059790]\n",
      "epoch:5 step:5316 [D loss: 0.627822, acc.: 61.72%] [G loss: 1.007375]\n",
      "epoch:5 step:5317 [D loss: 0.702744, acc.: 55.47%] [G loss: 0.967337]\n",
      "epoch:5 step:5318 [D loss: 0.650383, acc.: 58.59%] [G loss: 1.029722]\n",
      "epoch:5 step:5319 [D loss: 0.639239, acc.: 63.28%] [G loss: 1.135463]\n",
      "epoch:5 step:5320 [D loss: 0.699565, acc.: 58.59%] [G loss: 1.151206]\n",
      "epoch:5 step:5321 [D loss: 0.648845, acc.: 62.50%] [G loss: 1.052365]\n",
      "epoch:5 step:5322 [D loss: 0.606070, acc.: 62.50%] [G loss: 1.212976]\n",
      "epoch:5 step:5323 [D loss: 0.679279, acc.: 60.94%] [G loss: 1.004273]\n",
      "epoch:5 step:5324 [D loss: 0.666735, acc.: 60.94%] [G loss: 1.059587]\n",
      "epoch:5 step:5325 [D loss: 0.646814, acc.: 57.81%] [G loss: 1.049414]\n",
      "epoch:5 step:5326 [D loss: 0.670774, acc.: 57.81%] [G loss: 0.965467]\n",
      "epoch:5 step:5327 [D loss: 0.626468, acc.: 63.28%] [G loss: 1.174300]\n",
      "epoch:5 step:5328 [D loss: 0.682536, acc.: 55.47%] [G loss: 1.000255]\n",
      "epoch:5 step:5329 [D loss: 0.567635, acc.: 74.22%] [G loss: 0.909740]\n",
      "epoch:5 step:5330 [D loss: 0.646228, acc.: 60.94%] [G loss: 1.005168]\n",
      "epoch:5 step:5331 [D loss: 0.677841, acc.: 56.25%] [G loss: 0.971045]\n",
      "epoch:5 step:5332 [D loss: 0.645401, acc.: 60.94%] [G loss: 1.124080]\n",
      "epoch:5 step:5333 [D loss: 0.634071, acc.: 66.41%] [G loss: 1.180821]\n",
      "epoch:5 step:5334 [D loss: 0.596771, acc.: 64.84%] [G loss: 1.214219]\n",
      "epoch:5 step:5335 [D loss: 0.642468, acc.: 60.94%] [G loss: 0.863303]\n",
      "epoch:5 step:5336 [D loss: 0.728805, acc.: 53.91%] [G loss: 1.006521]\n",
      "epoch:5 step:5337 [D loss: 0.543510, acc.: 76.56%] [G loss: 1.049088]\n",
      "epoch:5 step:5338 [D loss: 0.563489, acc.: 70.31%] [G loss: 1.161360]\n",
      "epoch:5 step:5339 [D loss: 0.571630, acc.: 71.88%] [G loss: 1.191127]\n",
      "epoch:5 step:5340 [D loss: 0.615156, acc.: 69.53%] [G loss: 0.987334]\n",
      "epoch:5 step:5341 [D loss: 0.602883, acc.: 68.75%] [G loss: 1.134848]\n",
      "epoch:5 step:5342 [D loss: 0.638773, acc.: 62.50%] [G loss: 1.069510]\n",
      "epoch:5 step:5343 [D loss: 0.680119, acc.: 57.03%] [G loss: 0.972646]\n",
      "epoch:5 step:5344 [D loss: 0.652694, acc.: 57.03%] [G loss: 0.946872]\n",
      "epoch:5 step:5345 [D loss: 0.685324, acc.: 57.03%] [G loss: 0.899430]\n",
      "epoch:5 step:5346 [D loss: 0.625291, acc.: 60.94%] [G loss: 1.104413]\n",
      "epoch:5 step:5347 [D loss: 0.622100, acc.: 64.06%] [G loss: 1.087017]\n",
      "epoch:5 step:5348 [D loss: 0.597915, acc.: 67.97%] [G loss: 1.000723]\n",
      "epoch:5 step:5349 [D loss: 0.641685, acc.: 66.41%] [G loss: 1.045857]\n",
      "epoch:5 step:5350 [D loss: 0.625696, acc.: 67.19%] [G loss: 1.075626]\n",
      "epoch:5 step:5351 [D loss: 0.499986, acc.: 78.12%] [G loss: 1.143177]\n",
      "epoch:5 step:5352 [D loss: 0.657791, acc.: 61.72%] [G loss: 1.110511]\n",
      "epoch:5 step:5353 [D loss: 0.588736, acc.: 65.62%] [G loss: 1.125043]\n",
      "epoch:5 step:5354 [D loss: 0.558460, acc.: 71.09%] [G loss: 1.128412]\n",
      "epoch:5 step:5355 [D loss: 0.561143, acc.: 71.09%] [G loss: 1.235396]\n",
      "epoch:5 step:5356 [D loss: 0.613017, acc.: 67.97%] [G loss: 1.104961]\n",
      "epoch:5 step:5357 [D loss: 0.639587, acc.: 59.38%] [G loss: 1.033184]\n",
      "epoch:5 step:5358 [D loss: 0.730767, acc.: 48.44%] [G loss: 1.002709]\n",
      "epoch:5 step:5359 [D loss: 0.652391, acc.: 62.50%] [G loss: 1.019610]\n",
      "epoch:5 step:5360 [D loss: 0.620988, acc.: 67.19%] [G loss: 1.050018]\n",
      "epoch:5 step:5361 [D loss: 0.666539, acc.: 58.59%] [G loss: 1.162982]\n",
      "epoch:5 step:5362 [D loss: 0.582449, acc.: 69.53%] [G loss: 1.141563]\n",
      "epoch:5 step:5363 [D loss: 0.595386, acc.: 67.97%] [G loss: 0.899468]\n",
      "epoch:5 step:5364 [D loss: 0.641821, acc.: 59.38%] [G loss: 0.980116]\n",
      "epoch:5 step:5365 [D loss: 0.633454, acc.: 64.84%] [G loss: 1.010550]\n",
      "epoch:5 step:5366 [D loss: 0.639884, acc.: 63.28%] [G loss: 1.207006]\n",
      "epoch:5 step:5367 [D loss: 0.630156, acc.: 63.28%] [G loss: 1.027848]\n",
      "epoch:5 step:5368 [D loss: 0.800969, acc.: 48.44%] [G loss: 0.896250]\n",
      "epoch:5 step:5369 [D loss: 0.688018, acc.: 57.03%] [G loss: 1.174274]\n",
      "epoch:5 step:5370 [D loss: 0.694740, acc.: 55.47%] [G loss: 1.012788]\n",
      "epoch:5 step:5371 [D loss: 0.588764, acc.: 71.88%] [G loss: 1.076364]\n",
      "epoch:5 step:5372 [D loss: 0.581743, acc.: 71.09%] [G loss: 1.165851]\n",
      "epoch:5 step:5373 [D loss: 0.645060, acc.: 66.41%] [G loss: 0.994615]\n",
      "epoch:5 step:5374 [D loss: 0.576963, acc.: 75.00%] [G loss: 1.173982]\n",
      "epoch:5 step:5375 [D loss: 0.634521, acc.: 61.72%] [G loss: 0.999953]\n",
      "epoch:5 step:5376 [D loss: 0.653614, acc.: 61.72%] [G loss: 1.086527]\n",
      "epoch:5 step:5377 [D loss: 0.622183, acc.: 67.19%] [G loss: 1.011328]\n",
      "epoch:5 step:5378 [D loss: 0.667944, acc.: 57.03%] [G loss: 1.119703]\n",
      "epoch:5 step:5379 [D loss: 0.695781, acc.: 57.03%] [G loss: 0.977499]\n",
      "epoch:5 step:5380 [D loss: 0.747531, acc.: 48.44%] [G loss: 1.003144]\n",
      "epoch:5 step:5381 [D loss: 0.707744, acc.: 56.25%] [G loss: 1.051425]\n",
      "epoch:5 step:5382 [D loss: 0.671455, acc.: 58.59%] [G loss: 1.214155]\n",
      "epoch:5 step:5383 [D loss: 0.674474, acc.: 60.94%] [G loss: 1.095185]\n",
      "epoch:5 step:5384 [D loss: 0.748944, acc.: 56.25%] [G loss: 1.126717]\n",
      "epoch:5 step:5385 [D loss: 0.584114, acc.: 68.75%] [G loss: 1.131895]\n",
      "epoch:5 step:5386 [D loss: 0.571770, acc.: 73.44%] [G loss: 1.222748]\n",
      "epoch:5 step:5387 [D loss: 0.578034, acc.: 68.75%] [G loss: 0.996919]\n",
      "epoch:5 step:5388 [D loss: 0.764666, acc.: 51.56%] [G loss: 1.124842]\n",
      "epoch:5 step:5389 [D loss: 0.652350, acc.: 62.50%] [G loss: 1.134248]\n",
      "epoch:5 step:5390 [D loss: 0.670863, acc.: 62.50%] [G loss: 1.204910]\n",
      "epoch:5 step:5391 [D loss: 0.643103, acc.: 64.84%] [G loss: 0.905540]\n",
      "epoch:5 step:5392 [D loss: 0.560121, acc.: 67.97%] [G loss: 0.959761]\n",
      "epoch:5 step:5393 [D loss: 0.570956, acc.: 68.75%] [G loss: 1.283546]\n",
      "epoch:5 step:5394 [D loss: 0.761724, acc.: 54.69%] [G loss: 0.972312]\n",
      "epoch:5 step:5395 [D loss: 0.678142, acc.: 56.25%] [G loss: 1.190626]\n",
      "epoch:5 step:5396 [D loss: 0.599326, acc.: 70.31%] [G loss: 1.053126]\n",
      "epoch:5 step:5397 [D loss: 0.609164, acc.: 67.19%] [G loss: 0.996458]\n",
      "epoch:5 step:5398 [D loss: 0.634254, acc.: 66.41%] [G loss: 1.079378]\n",
      "epoch:5 step:5399 [D loss: 0.678824, acc.: 53.91%] [G loss: 0.991898]\n",
      "epoch:5 step:5400 [D loss: 0.691611, acc.: 57.81%] [G loss: 0.924733]\n",
      "epoch:5 step:5401 [D loss: 0.493832, acc.: 76.56%] [G loss: 1.248824]\n",
      "epoch:5 step:5402 [D loss: 0.682980, acc.: 59.38%] [G loss: 1.172342]\n",
      "epoch:5 step:5403 [D loss: 0.599594, acc.: 66.41%] [G loss: 1.182818]\n",
      "epoch:5 step:5404 [D loss: 0.542605, acc.: 73.44%] [G loss: 1.175265]\n",
      "epoch:5 step:5405 [D loss: 0.634168, acc.: 59.38%] [G loss: 1.118412]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:5 step:5406 [D loss: 0.683308, acc.: 57.03%] [G loss: 1.039411]\n",
      "epoch:5 step:5407 [D loss: 0.704119, acc.: 58.59%] [G loss: 1.082355]\n",
      "epoch:5 step:5408 [D loss: 0.703868, acc.: 53.12%] [G loss: 0.827915]\n",
      "epoch:5 step:5409 [D loss: 0.597326, acc.: 65.62%] [G loss: 1.085972]\n",
      "epoch:5 step:5410 [D loss: 0.710355, acc.: 56.25%] [G loss: 0.973874]\n",
      "epoch:5 step:5411 [D loss: 0.704493, acc.: 56.25%] [G loss: 0.902733]\n",
      "epoch:5 step:5412 [D loss: 0.588810, acc.: 71.88%] [G loss: 1.142913]\n",
      "epoch:5 step:5413 [D loss: 0.627240, acc.: 69.53%] [G loss: 1.006094]\n",
      "epoch:5 step:5414 [D loss: 0.599507, acc.: 67.97%] [G loss: 1.137928]\n",
      "epoch:5 step:5415 [D loss: 0.768007, acc.: 48.44%] [G loss: 0.936532]\n",
      "epoch:5 step:5416 [D loss: 0.686961, acc.: 63.28%] [G loss: 0.955713]\n",
      "epoch:5 step:5417 [D loss: 0.670208, acc.: 58.59%] [G loss: 0.995950]\n",
      "epoch:5 step:5418 [D loss: 0.633020, acc.: 62.50%] [G loss: 1.007903]\n",
      "epoch:5 step:5419 [D loss: 0.589235, acc.: 67.19%] [G loss: 1.121836]\n",
      "epoch:5 step:5420 [D loss: 0.667396, acc.: 62.50%] [G loss: 0.920972]\n",
      "epoch:5 step:5421 [D loss: 0.603397, acc.: 63.28%] [G loss: 1.013026]\n",
      "epoch:5 step:5422 [D loss: 0.705114, acc.: 62.50%] [G loss: 1.100594]\n",
      "epoch:5 step:5423 [D loss: 0.617404, acc.: 63.28%] [G loss: 0.968172]\n",
      "epoch:5 step:5424 [D loss: 0.579023, acc.: 68.75%] [G loss: 1.110818]\n",
      "epoch:5 step:5425 [D loss: 0.663173, acc.: 56.25%] [G loss: 0.931078]\n",
      "epoch:5 step:5426 [D loss: 0.693362, acc.: 56.25%] [G loss: 0.983395]\n",
      "epoch:5 step:5427 [D loss: 0.626442, acc.: 64.84%] [G loss: 1.155055]\n",
      "epoch:5 step:5428 [D loss: 0.734046, acc.: 55.47%] [G loss: 1.110585]\n",
      "epoch:5 step:5429 [D loss: 0.641214, acc.: 65.62%] [G loss: 0.962144]\n",
      "epoch:5 step:5430 [D loss: 0.608841, acc.: 67.97%] [G loss: 1.013902]\n",
      "epoch:5 step:5431 [D loss: 0.629783, acc.: 68.75%] [G loss: 1.097169]\n",
      "epoch:5 step:5432 [D loss: 0.609296, acc.: 63.28%] [G loss: 1.048611]\n",
      "epoch:5 step:5433 [D loss: 0.523235, acc.: 81.25%] [G loss: 1.165531]\n",
      "epoch:5 step:5434 [D loss: 0.729153, acc.: 53.91%] [G loss: 1.197797]\n",
      "epoch:5 step:5435 [D loss: 0.756524, acc.: 46.88%] [G loss: 0.898357]\n",
      "epoch:5 step:5436 [D loss: 0.564777, acc.: 72.66%] [G loss: 1.143739]\n",
      "epoch:5 step:5437 [D loss: 0.637796, acc.: 65.62%] [G loss: 1.009414]\n",
      "epoch:5 step:5438 [D loss: 0.699789, acc.: 55.47%] [G loss: 0.930123]\n",
      "epoch:5 step:5439 [D loss: 0.601993, acc.: 64.84%] [G loss: 0.939604]\n",
      "epoch:5 step:5440 [D loss: 0.588035, acc.: 64.06%] [G loss: 0.973706]\n",
      "epoch:5 step:5441 [D loss: 0.619830, acc.: 64.84%] [G loss: 1.071645]\n",
      "epoch:5 step:5442 [D loss: 0.582373, acc.: 70.31%] [G loss: 0.976883]\n",
      "epoch:5 step:5443 [D loss: 0.628441, acc.: 66.41%] [G loss: 0.913183]\n",
      "epoch:5 step:5444 [D loss: 0.617638, acc.: 64.84%] [G loss: 1.008729]\n",
      "epoch:5 step:5445 [D loss: 0.646414, acc.: 60.16%] [G loss: 0.937787]\n",
      "epoch:5 step:5446 [D loss: 0.595980, acc.: 65.62%] [G loss: 1.101045]\n",
      "epoch:5 step:5447 [D loss: 0.675775, acc.: 60.94%] [G loss: 1.021747]\n",
      "epoch:5 step:5448 [D loss: 0.602685, acc.: 68.75%] [G loss: 1.066088]\n",
      "epoch:5 step:5449 [D loss: 0.616834, acc.: 67.19%] [G loss: 1.133173]\n",
      "epoch:5 step:5450 [D loss: 0.641839, acc.: 60.16%] [G loss: 1.029810]\n",
      "epoch:5 step:5451 [D loss: 0.550457, acc.: 68.75%] [G loss: 1.125173]\n",
      "epoch:5 step:5452 [D loss: 0.598582, acc.: 67.19%] [G loss: 1.077187]\n",
      "epoch:5 step:5453 [D loss: 0.596652, acc.: 66.41%] [G loss: 1.025334]\n",
      "epoch:5 step:5454 [D loss: 0.642795, acc.: 69.53%] [G loss: 1.078706]\n",
      "epoch:5 step:5455 [D loss: 0.615835, acc.: 64.06%] [G loss: 1.074604]\n",
      "epoch:5 step:5456 [D loss: 0.677535, acc.: 57.03%] [G loss: 0.960314]\n",
      "epoch:5 step:5457 [D loss: 0.707123, acc.: 50.78%] [G loss: 1.177443]\n",
      "epoch:5 step:5458 [D loss: 0.697405, acc.: 58.59%] [G loss: 1.068725]\n",
      "epoch:5 step:5459 [D loss: 0.587803, acc.: 67.97%] [G loss: 1.104908]\n",
      "epoch:5 step:5460 [D loss: 0.692145, acc.: 54.69%] [G loss: 0.917858]\n",
      "epoch:5 step:5461 [D loss: 0.676710, acc.: 60.16%] [G loss: 1.080442]\n",
      "epoch:5 step:5462 [D loss: 0.570202, acc.: 71.09%] [G loss: 1.111180]\n",
      "epoch:5 step:5463 [D loss: 0.592938, acc.: 66.41%] [G loss: 0.952364]\n",
      "epoch:5 step:5464 [D loss: 0.656911, acc.: 57.81%] [G loss: 0.972972]\n",
      "epoch:5 step:5465 [D loss: 0.691696, acc.: 60.16%] [G loss: 1.010818]\n",
      "epoch:5 step:5466 [D loss: 0.569281, acc.: 70.31%] [G loss: 0.964775]\n",
      "epoch:5 step:5467 [D loss: 0.710074, acc.: 53.91%] [G loss: 0.908288]\n",
      "epoch:5 step:5468 [D loss: 0.692971, acc.: 55.47%] [G loss: 1.018382]\n",
      "epoch:5 step:5469 [D loss: 0.643456, acc.: 64.06%] [G loss: 1.038047]\n",
      "epoch:5 step:5470 [D loss: 0.721653, acc.: 52.34%] [G loss: 0.964364]\n",
      "epoch:5 step:5471 [D loss: 0.710499, acc.: 50.78%] [G loss: 0.958103]\n",
      "epoch:5 step:5472 [D loss: 0.583463, acc.: 66.41%] [G loss: 1.140969]\n",
      "epoch:5 step:5473 [D loss: 0.712723, acc.: 53.91%] [G loss: 0.974222]\n",
      "epoch:5 step:5474 [D loss: 0.599387, acc.: 70.31%] [G loss: 1.008022]\n",
      "epoch:5 step:5475 [D loss: 0.635433, acc.: 59.38%] [G loss: 1.010126]\n",
      "epoch:5 step:5476 [D loss: 0.698426, acc.: 55.47%] [G loss: 0.978560]\n",
      "epoch:5 step:5477 [D loss: 0.638131, acc.: 66.41%] [G loss: 1.148947]\n",
      "epoch:5 step:5478 [D loss: 0.750897, acc.: 53.12%] [G loss: 1.102660]\n",
      "epoch:5 step:5479 [D loss: 0.634242, acc.: 64.06%] [G loss: 1.111421]\n",
      "epoch:5 step:5480 [D loss: 0.622139, acc.: 64.84%] [G loss: 1.021987]\n",
      "epoch:5 step:5481 [D loss: 0.629215, acc.: 58.59%] [G loss: 1.104344]\n",
      "epoch:5 step:5482 [D loss: 0.685261, acc.: 60.94%] [G loss: 1.062642]\n",
      "epoch:5 step:5483 [D loss: 0.594622, acc.: 71.88%] [G loss: 1.098807]\n",
      "epoch:5 step:5484 [D loss: 0.526740, acc.: 76.56%] [G loss: 1.186122]\n",
      "epoch:5 step:5485 [D loss: 0.650829, acc.: 63.28%] [G loss: 0.959997]\n",
      "epoch:5 step:5486 [D loss: 0.694604, acc.: 59.38%] [G loss: 1.039746]\n",
      "epoch:5 step:5487 [D loss: 0.618765, acc.: 68.75%] [G loss: 1.021136]\n",
      "epoch:5 step:5488 [D loss: 0.626940, acc.: 61.72%] [G loss: 1.070425]\n",
      "epoch:5 step:5489 [D loss: 0.590742, acc.: 71.88%] [G loss: 1.298023]\n",
      "epoch:5 step:5490 [D loss: 0.616885, acc.: 68.75%] [G loss: 0.912169]\n",
      "epoch:5 step:5491 [D loss: 0.633157, acc.: 64.84%] [G loss: 1.060387]\n",
      "epoch:5 step:5492 [D loss: 0.653311, acc.: 58.59%] [G loss: 1.080102]\n",
      "epoch:5 step:5493 [D loss: 0.603881, acc.: 67.97%] [G loss: 1.147092]\n",
      "epoch:5 step:5494 [D loss: 0.581001, acc.: 67.97%] [G loss: 0.977194]\n",
      "epoch:5 step:5495 [D loss: 0.643586, acc.: 62.50%] [G loss: 1.130069]\n",
      "epoch:5 step:5496 [D loss: 0.608649, acc.: 62.50%] [G loss: 1.059855]\n",
      "epoch:5 step:5497 [D loss: 0.640377, acc.: 65.62%] [G loss: 1.127672]\n",
      "epoch:5 step:5498 [D loss: 0.647277, acc.: 60.16%] [G loss: 1.056961]\n",
      "epoch:5 step:5499 [D loss: 0.632096, acc.: 64.06%] [G loss: 0.915605]\n",
      "epoch:5 step:5500 [D loss: 0.619380, acc.: 68.75%] [G loss: 1.104216]\n",
      "epoch:5 step:5501 [D loss: 0.534737, acc.: 73.44%] [G loss: 1.035948]\n",
      "epoch:5 step:5502 [D loss: 0.688356, acc.: 57.81%] [G loss: 1.050627]\n",
      "epoch:5 step:5503 [D loss: 0.608841, acc.: 71.09%] [G loss: 1.134055]\n",
      "epoch:5 step:5504 [D loss: 0.600084, acc.: 64.84%] [G loss: 1.134007]\n",
      "epoch:5 step:5505 [D loss: 0.654627, acc.: 60.16%] [G loss: 1.054777]\n",
      "epoch:5 step:5506 [D loss: 0.654951, acc.: 58.59%] [G loss: 1.035290]\n",
      "epoch:5 step:5507 [D loss: 0.598354, acc.: 70.31%] [G loss: 1.079717]\n",
      "epoch:5 step:5508 [D loss: 0.643296, acc.: 64.06%] [G loss: 1.116700]\n",
      "epoch:5 step:5509 [D loss: 0.764089, acc.: 49.22%] [G loss: 1.024216]\n",
      "epoch:5 step:5510 [D loss: 0.550260, acc.: 71.88%] [G loss: 1.026069]\n",
      "epoch:5 step:5511 [D loss: 0.642753, acc.: 67.19%] [G loss: 1.056490]\n",
      "epoch:5 step:5512 [D loss: 0.581366, acc.: 69.53%] [G loss: 1.045036]\n",
      "epoch:5 step:5513 [D loss: 0.680516, acc.: 65.62%] [G loss: 0.933454]\n",
      "epoch:5 step:5514 [D loss: 0.585729, acc.: 72.66%] [G loss: 1.098934]\n",
      "epoch:5 step:5515 [D loss: 0.651635, acc.: 59.38%] [G loss: 1.143308]\n",
      "epoch:5 step:5516 [D loss: 0.613947, acc.: 68.75%] [G loss: 0.986149]\n",
      "epoch:5 step:5517 [D loss: 0.681968, acc.: 60.94%] [G loss: 1.063048]\n",
      "epoch:5 step:5518 [D loss: 0.623332, acc.: 68.75%] [G loss: 1.227070]\n",
      "epoch:5 step:5519 [D loss: 0.612359, acc.: 69.53%] [G loss: 1.061608]\n",
      "epoch:5 step:5520 [D loss: 0.740202, acc.: 53.12%] [G loss: 0.987472]\n",
      "epoch:5 step:5521 [D loss: 0.700646, acc.: 57.03%] [G loss: 1.117277]\n",
      "epoch:5 step:5522 [D loss: 0.736118, acc.: 48.44%] [G loss: 1.078223]\n",
      "epoch:5 step:5523 [D loss: 0.611495, acc.: 67.19%] [G loss: 1.199148]\n",
      "epoch:5 step:5524 [D loss: 0.641666, acc.: 62.50%] [G loss: 1.163623]\n",
      "epoch:5 step:5525 [D loss: 0.658700, acc.: 64.84%] [G loss: 0.926541]\n",
      "epoch:5 step:5526 [D loss: 0.590542, acc.: 73.44%] [G loss: 1.127055]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:5 step:5527 [D loss: 0.554372, acc.: 76.56%] [G loss: 1.206349]\n",
      "epoch:5 step:5528 [D loss: 0.679291, acc.: 57.81%] [G loss: 0.976839]\n",
      "epoch:5 step:5529 [D loss: 0.785570, acc.: 46.09%] [G loss: 0.871762]\n",
      "epoch:5 step:5530 [D loss: 0.736620, acc.: 53.12%] [G loss: 1.069837]\n",
      "epoch:5 step:5531 [D loss: 0.677741, acc.: 57.81%] [G loss: 1.123326]\n",
      "epoch:5 step:5532 [D loss: 0.595441, acc.: 68.75%] [G loss: 1.026133]\n",
      "epoch:5 step:5533 [D loss: 0.660079, acc.: 65.62%] [G loss: 1.041903]\n",
      "epoch:5 step:5534 [D loss: 0.600180, acc.: 69.53%] [G loss: 0.974463]\n",
      "epoch:5 step:5535 [D loss: 0.605158, acc.: 70.31%] [G loss: 0.987522]\n",
      "epoch:5 step:5536 [D loss: 0.750309, acc.: 47.66%] [G loss: 0.989974]\n",
      "epoch:5 step:5537 [D loss: 0.591934, acc.: 68.75%] [G loss: 1.121826]\n",
      "epoch:5 step:5538 [D loss: 0.684776, acc.: 54.69%] [G loss: 0.970804]\n",
      "epoch:5 step:5539 [D loss: 0.651582, acc.: 64.84%] [G loss: 1.046772]\n",
      "epoch:5 step:5540 [D loss: 0.629913, acc.: 63.28%] [G loss: 1.131526]\n",
      "epoch:5 step:5541 [D loss: 0.594464, acc.: 68.75%] [G loss: 1.024896]\n",
      "epoch:5 step:5542 [D loss: 0.713125, acc.: 59.38%] [G loss: 0.960744]\n",
      "epoch:5 step:5543 [D loss: 0.661098, acc.: 62.50%] [G loss: 1.014902]\n",
      "epoch:5 step:5544 [D loss: 0.668916, acc.: 63.28%] [G loss: 0.964118]\n",
      "epoch:5 step:5545 [D loss: 0.591952, acc.: 67.19%] [G loss: 1.075056]\n",
      "epoch:5 step:5546 [D loss: 0.625653, acc.: 67.19%] [G loss: 0.947483]\n",
      "epoch:5 step:5547 [D loss: 0.715885, acc.: 57.81%] [G loss: 0.992801]\n",
      "epoch:5 step:5548 [D loss: 0.688098, acc.: 60.94%] [G loss: 0.901545]\n",
      "epoch:5 step:5549 [D loss: 0.644693, acc.: 64.84%] [G loss: 1.120190]\n",
      "epoch:5 step:5550 [D loss: 0.654582, acc.: 59.38%] [G loss: 0.996822]\n",
      "epoch:5 step:5551 [D loss: 0.572887, acc.: 71.88%] [G loss: 1.052579]\n",
      "epoch:5 step:5552 [D loss: 0.580100, acc.: 62.50%] [G loss: 1.050847]\n",
      "epoch:5 step:5553 [D loss: 0.591497, acc.: 70.31%] [G loss: 0.989236]\n",
      "epoch:5 step:5554 [D loss: 0.652938, acc.: 59.38%] [G loss: 1.059431]\n",
      "epoch:5 step:5555 [D loss: 0.751649, acc.: 55.47%] [G loss: 1.059934]\n",
      "epoch:5 step:5556 [D loss: 0.661543, acc.: 59.38%] [G loss: 0.902671]\n",
      "epoch:5 step:5557 [D loss: 0.672634, acc.: 63.28%] [G loss: 0.897534]\n",
      "epoch:5 step:5558 [D loss: 0.592066, acc.: 70.31%] [G loss: 1.082136]\n",
      "epoch:5 step:5559 [D loss: 0.624717, acc.: 59.38%] [G loss: 1.137758]\n",
      "epoch:5 step:5560 [D loss: 0.648801, acc.: 64.84%] [G loss: 1.081655]\n",
      "epoch:5 step:5561 [D loss: 0.604976, acc.: 67.97%] [G loss: 1.151519]\n",
      "epoch:5 step:5562 [D loss: 0.570767, acc.: 71.88%] [G loss: 1.114284]\n",
      "epoch:5 step:5563 [D loss: 0.665925, acc.: 59.38%] [G loss: 1.065954]\n",
      "epoch:5 step:5564 [D loss: 0.721714, acc.: 54.69%] [G loss: 0.905985]\n",
      "epoch:5 step:5565 [D loss: 0.626837, acc.: 60.94%] [G loss: 0.883915]\n",
      "epoch:5 step:5566 [D loss: 0.668417, acc.: 59.38%] [G loss: 1.026325]\n",
      "epoch:5 step:5567 [D loss: 0.522702, acc.: 75.78%] [G loss: 1.235075]\n",
      "epoch:5 step:5568 [D loss: 0.659319, acc.: 62.50%] [G loss: 1.056107]\n",
      "epoch:5 step:5569 [D loss: 0.643309, acc.: 62.50%] [G loss: 0.934031]\n",
      "epoch:5 step:5570 [D loss: 0.627680, acc.: 60.94%] [G loss: 1.113005]\n",
      "epoch:5 step:5571 [D loss: 0.584578, acc.: 72.66%] [G loss: 1.152515]\n",
      "epoch:5 step:5572 [D loss: 0.580831, acc.: 65.62%] [G loss: 0.990801]\n",
      "epoch:5 step:5573 [D loss: 0.703433, acc.: 57.03%] [G loss: 1.148767]\n",
      "epoch:5 step:5574 [D loss: 0.654034, acc.: 64.84%] [G loss: 1.144735]\n",
      "epoch:5 step:5575 [D loss: 0.645015, acc.: 60.94%] [G loss: 0.982343]\n",
      "epoch:5 step:5576 [D loss: 0.721105, acc.: 51.56%] [G loss: 0.941022]\n",
      "epoch:5 step:5577 [D loss: 0.677996, acc.: 56.25%] [G loss: 1.025234]\n",
      "epoch:5 step:5578 [D loss: 0.638331, acc.: 67.19%] [G loss: 1.164236]\n",
      "epoch:5 step:5579 [D loss: 0.574489, acc.: 70.31%] [G loss: 1.143079]\n",
      "epoch:5 step:5580 [D loss: 0.665111, acc.: 58.59%] [G loss: 0.971877]\n",
      "epoch:5 step:5581 [D loss: 0.624134, acc.: 65.62%] [G loss: 0.951461]\n",
      "epoch:5 step:5582 [D loss: 0.626878, acc.: 66.41%] [G loss: 0.990105]\n",
      "epoch:5 step:5583 [D loss: 0.640794, acc.: 61.72%] [G loss: 0.973173]\n",
      "epoch:5 step:5584 [D loss: 0.617301, acc.: 63.28%] [G loss: 1.052899]\n",
      "epoch:5 step:5585 [D loss: 0.639142, acc.: 64.06%] [G loss: 1.038516]\n",
      "epoch:5 step:5586 [D loss: 0.659095, acc.: 60.94%] [G loss: 0.953560]\n",
      "epoch:5 step:5587 [D loss: 0.624302, acc.: 60.94%] [G loss: 0.981063]\n",
      "epoch:5 step:5588 [D loss: 0.607005, acc.: 65.62%] [G loss: 1.039653]\n",
      "epoch:5 step:5589 [D loss: 0.576765, acc.: 70.31%] [G loss: 1.133848]\n",
      "epoch:5 step:5590 [D loss: 0.650119, acc.: 60.94%] [G loss: 1.156053]\n",
      "epoch:5 step:5591 [D loss: 0.640337, acc.: 64.06%] [G loss: 1.155202]\n",
      "epoch:5 step:5592 [D loss: 0.693606, acc.: 55.47%] [G loss: 1.059929]\n",
      "epoch:5 step:5593 [D loss: 0.687153, acc.: 57.03%] [G loss: 1.198875]\n",
      "epoch:5 step:5594 [D loss: 0.657205, acc.: 62.50%] [G loss: 1.129309]\n",
      "epoch:5 step:5595 [D loss: 0.708258, acc.: 51.56%] [G loss: 0.999972]\n",
      "epoch:5 step:5596 [D loss: 0.652051, acc.: 60.94%] [G loss: 1.025552]\n",
      "epoch:5 step:5597 [D loss: 0.613937, acc.: 62.50%] [G loss: 1.091400]\n",
      "epoch:5 step:5598 [D loss: 0.707838, acc.: 55.47%] [G loss: 0.959321]\n",
      "epoch:5 step:5599 [D loss: 0.675358, acc.: 57.81%] [G loss: 1.010781]\n",
      "epoch:5 step:5600 [D loss: 0.704379, acc.: 54.69%] [G loss: 1.103808]\n",
      "epoch:5 step:5601 [D loss: 0.604394, acc.: 69.53%] [G loss: 1.146839]\n",
      "epoch:5 step:5602 [D loss: 0.687756, acc.: 54.69%] [G loss: 1.021776]\n",
      "epoch:5 step:5603 [D loss: 0.647787, acc.: 66.41%] [G loss: 1.107136]\n",
      "epoch:5 step:5604 [D loss: 0.586793, acc.: 67.97%] [G loss: 1.054636]\n",
      "epoch:5 step:5605 [D loss: 0.693357, acc.: 56.25%] [G loss: 1.014544]\n",
      "epoch:5 step:5606 [D loss: 0.552677, acc.: 73.44%] [G loss: 1.138204]\n",
      "epoch:5 step:5607 [D loss: 0.634513, acc.: 60.94%] [G loss: 1.130799]\n",
      "epoch:5 step:5608 [D loss: 0.605918, acc.: 67.19%] [G loss: 1.080016]\n",
      "epoch:5 step:5609 [D loss: 0.579612, acc.: 69.53%] [G loss: 1.006567]\n",
      "epoch:5 step:5610 [D loss: 0.635643, acc.: 63.28%] [G loss: 0.843665]\n",
      "epoch:5 step:5611 [D loss: 0.568296, acc.: 71.09%] [G loss: 1.112843]\n",
      "epoch:5 step:5612 [D loss: 0.610857, acc.: 67.19%] [G loss: 0.979621]\n",
      "epoch:5 step:5613 [D loss: 0.571367, acc.: 75.00%] [G loss: 0.950292]\n",
      "epoch:5 step:5614 [D loss: 0.587566, acc.: 69.53%] [G loss: 0.999616]\n",
      "epoch:5 step:5615 [D loss: 0.623989, acc.: 63.28%] [G loss: 1.057124]\n",
      "epoch:5 step:5616 [D loss: 0.624911, acc.: 68.75%] [G loss: 0.989478]\n",
      "epoch:5 step:5617 [D loss: 0.642965, acc.: 60.16%] [G loss: 1.026124]\n",
      "epoch:5 step:5618 [D loss: 0.680571, acc.: 60.94%] [G loss: 0.997409]\n",
      "epoch:5 step:5619 [D loss: 0.592386, acc.: 71.88%] [G loss: 1.000364]\n",
      "epoch:5 step:5620 [D loss: 0.603774, acc.: 65.62%] [G loss: 1.050385]\n",
      "epoch:5 step:5621 [D loss: 0.660829, acc.: 57.81%] [G loss: 1.230886]\n",
      "epoch:5 step:5622 [D loss: 0.616462, acc.: 67.97%] [G loss: 1.003534]\n",
      "epoch:6 step:5623 [D loss: 0.631466, acc.: 62.50%] [G loss: 1.008579]\n",
      "epoch:6 step:5624 [D loss: 0.654413, acc.: 57.81%] [G loss: 0.969007]\n",
      "epoch:6 step:5625 [D loss: 0.691720, acc.: 55.47%] [G loss: 1.042696]\n",
      "epoch:6 step:5626 [D loss: 0.631103, acc.: 62.50%] [G loss: 1.118808]\n",
      "epoch:6 step:5627 [D loss: 0.657289, acc.: 64.06%] [G loss: 1.032826]\n",
      "epoch:6 step:5628 [D loss: 0.593951, acc.: 66.41%] [G loss: 1.081261]\n",
      "epoch:6 step:5629 [D loss: 0.662174, acc.: 59.38%] [G loss: 0.971159]\n",
      "epoch:6 step:5630 [D loss: 0.544920, acc.: 74.22%] [G loss: 1.152059]\n",
      "epoch:6 step:5631 [D loss: 0.655950, acc.: 62.50%] [G loss: 0.972746]\n",
      "epoch:6 step:5632 [D loss: 0.587996, acc.: 67.97%] [G loss: 1.156686]\n",
      "epoch:6 step:5633 [D loss: 0.572604, acc.: 67.19%] [G loss: 1.007760]\n",
      "epoch:6 step:5634 [D loss: 0.604203, acc.: 69.53%] [G loss: 1.052953]\n",
      "epoch:6 step:5635 [D loss: 0.588213, acc.: 66.41%] [G loss: 1.118611]\n",
      "epoch:6 step:5636 [D loss: 0.655037, acc.: 64.06%] [G loss: 1.055943]\n",
      "epoch:6 step:5637 [D loss: 0.713752, acc.: 54.69%] [G loss: 1.034948]\n",
      "epoch:6 step:5638 [D loss: 0.541985, acc.: 73.44%] [G loss: 1.249731]\n",
      "epoch:6 step:5639 [D loss: 0.577861, acc.: 67.97%] [G loss: 1.101914]\n",
      "epoch:6 step:5640 [D loss: 0.676223, acc.: 59.38%] [G loss: 1.167498]\n",
      "epoch:6 step:5641 [D loss: 0.690426, acc.: 58.59%] [G loss: 0.819718]\n",
      "epoch:6 step:5642 [D loss: 0.584241, acc.: 70.31%] [G loss: 0.936969]\n",
      "epoch:6 step:5643 [D loss: 0.626289, acc.: 71.09%] [G loss: 1.211969]\n",
      "epoch:6 step:5644 [D loss: 0.636049, acc.: 63.28%] [G loss: 1.069481]\n",
      "epoch:6 step:5645 [D loss: 0.562358, acc.: 73.44%] [G loss: 1.100789]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:6 step:5646 [D loss: 0.638763, acc.: 62.50%] [G loss: 1.018917]\n",
      "epoch:6 step:5647 [D loss: 0.606870, acc.: 69.53%] [G loss: 1.089024]\n",
      "epoch:6 step:5648 [D loss: 0.686412, acc.: 52.34%] [G loss: 1.095828]\n",
      "epoch:6 step:5649 [D loss: 0.646456, acc.: 64.06%] [G loss: 1.088350]\n",
      "epoch:6 step:5650 [D loss: 0.582000, acc.: 70.31%] [G loss: 1.158987]\n",
      "epoch:6 step:5651 [D loss: 0.652817, acc.: 61.72%] [G loss: 0.929627]\n",
      "epoch:6 step:5652 [D loss: 0.541672, acc.: 73.44%] [G loss: 1.111569]\n",
      "epoch:6 step:5653 [D loss: 0.700968, acc.: 54.69%] [G loss: 1.071619]\n",
      "epoch:6 step:5654 [D loss: 0.581173, acc.: 72.66%] [G loss: 0.997079]\n",
      "epoch:6 step:5655 [D loss: 0.559396, acc.: 71.09%] [G loss: 1.184727]\n",
      "epoch:6 step:5656 [D loss: 0.719966, acc.: 56.25%] [G loss: 0.974524]\n",
      "epoch:6 step:5657 [D loss: 0.537494, acc.: 73.44%] [G loss: 1.058419]\n",
      "epoch:6 step:5658 [D loss: 0.605311, acc.: 68.75%] [G loss: 1.048917]\n",
      "epoch:6 step:5659 [D loss: 0.677219, acc.: 60.94%] [G loss: 1.192954]\n",
      "epoch:6 step:5660 [D loss: 0.608538, acc.: 65.62%] [G loss: 1.173780]\n",
      "epoch:6 step:5661 [D loss: 0.717444, acc.: 54.69%] [G loss: 1.142394]\n",
      "epoch:6 step:5662 [D loss: 0.640439, acc.: 67.97%] [G loss: 0.950901]\n",
      "epoch:6 step:5663 [D loss: 0.631836, acc.: 65.62%] [G loss: 0.848977]\n",
      "epoch:6 step:5664 [D loss: 0.607613, acc.: 64.84%] [G loss: 0.996259]\n",
      "epoch:6 step:5665 [D loss: 0.612819, acc.: 64.84%] [G loss: 1.053248]\n",
      "epoch:6 step:5666 [D loss: 0.641114, acc.: 61.72%] [G loss: 0.937825]\n",
      "epoch:6 step:5667 [D loss: 0.587455, acc.: 72.66%] [G loss: 0.982447]\n",
      "epoch:6 step:5668 [D loss: 0.721583, acc.: 57.81%] [G loss: 1.110645]\n",
      "epoch:6 step:5669 [D loss: 0.704669, acc.: 53.12%] [G loss: 0.965574]\n",
      "epoch:6 step:5670 [D loss: 0.695737, acc.: 60.16%] [G loss: 0.960173]\n",
      "epoch:6 step:5671 [D loss: 0.524198, acc.: 78.91%] [G loss: 1.139343]\n",
      "epoch:6 step:5672 [D loss: 0.643738, acc.: 60.16%] [G loss: 1.027470]\n",
      "epoch:6 step:5673 [D loss: 0.679438, acc.: 57.03%] [G loss: 0.965536]\n",
      "epoch:6 step:5674 [D loss: 0.650672, acc.: 60.16%] [G loss: 0.947945]\n",
      "epoch:6 step:5675 [D loss: 0.667711, acc.: 60.94%] [G loss: 1.051802]\n",
      "epoch:6 step:5676 [D loss: 0.620970, acc.: 66.41%] [G loss: 1.041385]\n",
      "epoch:6 step:5677 [D loss: 0.638537, acc.: 64.84%] [G loss: 1.175352]\n",
      "epoch:6 step:5678 [D loss: 0.676473, acc.: 62.50%] [G loss: 1.122164]\n",
      "epoch:6 step:5679 [D loss: 0.695108, acc.: 55.47%] [G loss: 0.986197]\n",
      "epoch:6 step:5680 [D loss: 0.646805, acc.: 61.72%] [G loss: 0.982008]\n",
      "epoch:6 step:5681 [D loss: 0.558332, acc.: 74.22%] [G loss: 1.117017]\n",
      "epoch:6 step:5682 [D loss: 0.561546, acc.: 69.53%] [G loss: 1.113887]\n",
      "epoch:6 step:5683 [D loss: 0.547651, acc.: 74.22%] [G loss: 1.057389]\n",
      "epoch:6 step:5684 [D loss: 0.677501, acc.: 54.69%] [G loss: 1.131933]\n",
      "epoch:6 step:5685 [D loss: 0.643904, acc.: 63.28%] [G loss: 0.931375]\n",
      "epoch:6 step:5686 [D loss: 0.611668, acc.: 70.31%] [G loss: 1.042295]\n",
      "epoch:6 step:5687 [D loss: 0.606698, acc.: 67.97%] [G loss: 1.049820]\n",
      "epoch:6 step:5688 [D loss: 0.695298, acc.: 53.91%] [G loss: 1.124205]\n",
      "epoch:6 step:5689 [D loss: 0.635022, acc.: 65.62%] [G loss: 1.117619]\n",
      "epoch:6 step:5690 [D loss: 0.589660, acc.: 67.97%] [G loss: 1.083683]\n",
      "epoch:6 step:5691 [D loss: 0.608628, acc.: 67.97%] [G loss: 0.964456]\n",
      "epoch:6 step:5692 [D loss: 0.674561, acc.: 60.94%] [G loss: 1.018553]\n",
      "epoch:6 step:5693 [D loss: 0.690293, acc.: 58.59%] [G loss: 1.075959]\n",
      "epoch:6 step:5694 [D loss: 0.607625, acc.: 67.19%] [G loss: 1.060374]\n",
      "epoch:6 step:5695 [D loss: 0.555881, acc.: 75.78%] [G loss: 1.242650]\n",
      "epoch:6 step:5696 [D loss: 0.648954, acc.: 64.06%] [G loss: 1.094415]\n",
      "epoch:6 step:5697 [D loss: 0.671441, acc.: 64.06%] [G loss: 1.094728]\n",
      "epoch:6 step:5698 [D loss: 0.630384, acc.: 65.62%] [G loss: 0.993460]\n",
      "epoch:6 step:5699 [D loss: 0.643497, acc.: 63.28%] [G loss: 1.143675]\n",
      "epoch:6 step:5700 [D loss: 0.624065, acc.: 65.62%] [G loss: 1.135884]\n",
      "epoch:6 step:5701 [D loss: 0.740173, acc.: 53.91%] [G loss: 1.164021]\n",
      "epoch:6 step:5702 [D loss: 0.696000, acc.: 58.59%] [G loss: 1.005709]\n",
      "epoch:6 step:5703 [D loss: 0.636714, acc.: 58.59%] [G loss: 1.114509]\n",
      "epoch:6 step:5704 [D loss: 0.708088, acc.: 53.12%] [G loss: 1.167909]\n",
      "epoch:6 step:5705 [D loss: 0.695130, acc.: 53.91%] [G loss: 1.042196]\n",
      "epoch:6 step:5706 [D loss: 0.644934, acc.: 62.50%] [G loss: 1.163859]\n",
      "epoch:6 step:5707 [D loss: 0.641245, acc.: 61.72%] [G loss: 1.037684]\n",
      "epoch:6 step:5708 [D loss: 0.705504, acc.: 59.38%] [G loss: 1.070904]\n",
      "epoch:6 step:5709 [D loss: 0.560433, acc.: 77.34%] [G loss: 1.139377]\n",
      "epoch:6 step:5710 [D loss: 0.575526, acc.: 70.31%] [G loss: 1.155725]\n",
      "epoch:6 step:5711 [D loss: 0.631616, acc.: 64.06%] [G loss: 0.990908]\n",
      "epoch:6 step:5712 [D loss: 0.585804, acc.: 68.75%] [G loss: 1.240778]\n",
      "epoch:6 step:5713 [D loss: 0.580471, acc.: 67.19%] [G loss: 1.061329]\n",
      "epoch:6 step:5714 [D loss: 0.631859, acc.: 64.06%] [G loss: 0.970422]\n",
      "epoch:6 step:5715 [D loss: 0.627021, acc.: 67.97%] [G loss: 0.864320]\n",
      "epoch:6 step:5716 [D loss: 0.636254, acc.: 64.84%] [G loss: 1.127910]\n",
      "epoch:6 step:5717 [D loss: 0.673005, acc.: 55.47%] [G loss: 0.987590]\n",
      "epoch:6 step:5718 [D loss: 0.626743, acc.: 63.28%] [G loss: 0.974960]\n",
      "epoch:6 step:5719 [D loss: 0.670627, acc.: 62.50%] [G loss: 1.025720]\n",
      "epoch:6 step:5720 [D loss: 0.660605, acc.: 58.59%] [G loss: 1.013477]\n",
      "epoch:6 step:5721 [D loss: 0.693292, acc.: 61.72%] [G loss: 1.207357]\n",
      "epoch:6 step:5722 [D loss: 0.572607, acc.: 71.88%] [G loss: 0.984417]\n",
      "epoch:6 step:5723 [D loss: 0.659319, acc.: 64.84%] [G loss: 0.933271]\n",
      "epoch:6 step:5724 [D loss: 0.630322, acc.: 61.72%] [G loss: 1.074592]\n",
      "epoch:6 step:5725 [D loss: 0.614367, acc.: 60.16%] [G loss: 1.060185]\n",
      "epoch:6 step:5726 [D loss: 0.639328, acc.: 65.62%] [G loss: 0.991467]\n",
      "epoch:6 step:5727 [D loss: 0.604301, acc.: 63.28%] [G loss: 0.952648]\n",
      "epoch:6 step:5728 [D loss: 0.619554, acc.: 66.41%] [G loss: 1.220977]\n",
      "epoch:6 step:5729 [D loss: 0.668066, acc.: 57.03%] [G loss: 1.032414]\n",
      "epoch:6 step:5730 [D loss: 0.586979, acc.: 67.97%] [G loss: 1.014216]\n",
      "epoch:6 step:5731 [D loss: 0.608096, acc.: 65.62%] [G loss: 1.159133]\n",
      "epoch:6 step:5732 [D loss: 0.640645, acc.: 66.41%] [G loss: 0.996053]\n",
      "epoch:6 step:5733 [D loss: 0.655939, acc.: 60.94%] [G loss: 1.037035]\n",
      "epoch:6 step:5734 [D loss: 0.655468, acc.: 60.94%] [G loss: 0.846848]\n",
      "epoch:6 step:5735 [D loss: 0.535310, acc.: 79.69%] [G loss: 0.985996]\n",
      "epoch:6 step:5736 [D loss: 0.597397, acc.: 71.09%] [G loss: 1.158633]\n",
      "epoch:6 step:5737 [D loss: 0.612462, acc.: 67.19%] [G loss: 0.905973]\n",
      "epoch:6 step:5738 [D loss: 0.552182, acc.: 76.56%] [G loss: 1.180794]\n",
      "epoch:6 step:5739 [D loss: 0.606777, acc.: 66.41%] [G loss: 1.047660]\n",
      "epoch:6 step:5740 [D loss: 0.594789, acc.: 67.97%] [G loss: 1.025246]\n",
      "epoch:6 step:5741 [D loss: 0.694067, acc.: 62.50%] [G loss: 0.962276]\n",
      "epoch:6 step:5742 [D loss: 0.650978, acc.: 60.16%] [G loss: 0.956853]\n",
      "epoch:6 step:5743 [D loss: 0.642438, acc.: 64.06%] [G loss: 1.046595]\n",
      "epoch:6 step:5744 [D loss: 0.575749, acc.: 67.97%] [G loss: 1.025995]\n",
      "epoch:6 step:5745 [D loss: 0.592620, acc.: 68.75%] [G loss: 1.018871]\n",
      "epoch:6 step:5746 [D loss: 0.662430, acc.: 60.16%] [G loss: 1.035403]\n",
      "epoch:6 step:5747 [D loss: 0.581803, acc.: 69.53%] [G loss: 1.080476]\n",
      "epoch:6 step:5748 [D loss: 0.683834, acc.: 57.03%] [G loss: 1.081741]\n",
      "epoch:6 step:5749 [D loss: 0.724879, acc.: 57.03%] [G loss: 0.964824]\n",
      "epoch:6 step:5750 [D loss: 0.657874, acc.: 57.81%] [G loss: 1.075700]\n",
      "epoch:6 step:5751 [D loss: 0.607782, acc.: 66.41%] [G loss: 1.183257]\n",
      "epoch:6 step:5752 [D loss: 0.687796, acc.: 55.47%] [G loss: 1.131097]\n",
      "epoch:6 step:5753 [D loss: 0.641872, acc.: 62.50%] [G loss: 1.033685]\n",
      "epoch:6 step:5754 [D loss: 0.654924, acc.: 60.94%] [G loss: 1.165374]\n",
      "epoch:6 step:5755 [D loss: 0.576258, acc.: 66.41%] [G loss: 1.213782]\n",
      "epoch:6 step:5756 [D loss: 0.617396, acc.: 64.06%] [G loss: 1.082264]\n",
      "epoch:6 step:5757 [D loss: 0.680307, acc.: 57.03%] [G loss: 1.086638]\n",
      "epoch:6 step:5758 [D loss: 0.661987, acc.: 60.94%] [G loss: 0.963010]\n",
      "epoch:6 step:5759 [D loss: 0.610811, acc.: 57.81%] [G loss: 1.283839]\n",
      "epoch:6 step:5760 [D loss: 0.629850, acc.: 66.41%] [G loss: 0.886667]\n",
      "epoch:6 step:5761 [D loss: 0.604762, acc.: 68.75%] [G loss: 1.053102]\n",
      "epoch:6 step:5762 [D loss: 0.674313, acc.: 59.38%] [G loss: 0.932712]\n",
      "epoch:6 step:5763 [D loss: 0.582222, acc.: 69.53%] [G loss: 0.968977]\n",
      "epoch:6 step:5764 [D loss: 0.606974, acc.: 61.72%] [G loss: 0.976114]\n",
      "epoch:6 step:5765 [D loss: 0.602664, acc.: 68.75%] [G loss: 1.081918]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:6 step:5766 [D loss: 0.660922, acc.: 56.25%] [G loss: 1.081882]\n",
      "epoch:6 step:5767 [D loss: 0.610196, acc.: 67.19%] [G loss: 1.026920]\n",
      "epoch:6 step:5768 [D loss: 0.663927, acc.: 65.62%] [G loss: 1.210754]\n",
      "epoch:6 step:5769 [D loss: 0.580574, acc.: 70.31%] [G loss: 1.184379]\n",
      "epoch:6 step:5770 [D loss: 0.616216, acc.: 66.41%] [G loss: 0.969222]\n",
      "epoch:6 step:5771 [D loss: 0.711122, acc.: 58.59%] [G loss: 1.035864]\n",
      "epoch:6 step:5772 [D loss: 0.609098, acc.: 64.06%] [G loss: 1.083339]\n",
      "epoch:6 step:5773 [D loss: 0.625267, acc.: 65.62%] [G loss: 1.095862]\n",
      "epoch:6 step:5774 [D loss: 0.680648, acc.: 57.81%] [G loss: 1.112124]\n",
      "epoch:6 step:5775 [D loss: 0.558246, acc.: 73.44%] [G loss: 1.135877]\n",
      "epoch:6 step:5776 [D loss: 0.692493, acc.: 59.38%] [G loss: 1.231284]\n",
      "epoch:6 step:5777 [D loss: 0.617674, acc.: 65.62%] [G loss: 1.118157]\n",
      "epoch:6 step:5778 [D loss: 0.589797, acc.: 66.41%] [G loss: 1.084916]\n",
      "epoch:6 step:5779 [D loss: 0.714545, acc.: 55.47%] [G loss: 0.930993]\n",
      "epoch:6 step:5780 [D loss: 0.590826, acc.: 71.88%] [G loss: 1.103868]\n",
      "epoch:6 step:5781 [D loss: 0.561539, acc.: 76.56%] [G loss: 1.146609]\n",
      "epoch:6 step:5782 [D loss: 0.540343, acc.: 75.00%] [G loss: 1.066577]\n",
      "epoch:6 step:5783 [D loss: 0.547116, acc.: 68.75%] [G loss: 1.097039]\n",
      "epoch:6 step:5784 [D loss: 0.616936, acc.: 65.62%] [G loss: 1.066047]\n",
      "epoch:6 step:5785 [D loss: 0.703006, acc.: 60.94%] [G loss: 1.100326]\n",
      "epoch:6 step:5786 [D loss: 0.641455, acc.: 63.28%] [G loss: 0.988641]\n",
      "epoch:6 step:5787 [D loss: 0.718695, acc.: 55.47%] [G loss: 1.040634]\n",
      "epoch:6 step:5788 [D loss: 0.625535, acc.: 64.84%] [G loss: 0.943135]\n",
      "epoch:6 step:5789 [D loss: 0.760282, acc.: 53.12%] [G loss: 0.918465]\n",
      "epoch:6 step:5790 [D loss: 0.644356, acc.: 59.38%] [G loss: 1.024761]\n",
      "epoch:6 step:5791 [D loss: 0.640727, acc.: 60.16%] [G loss: 1.107151]\n",
      "epoch:6 step:5792 [D loss: 0.700277, acc.: 53.91%] [G loss: 1.019845]\n",
      "epoch:6 step:5793 [D loss: 0.684738, acc.: 57.81%] [G loss: 1.040698]\n",
      "epoch:6 step:5794 [D loss: 0.611087, acc.: 67.97%] [G loss: 0.932085]\n",
      "epoch:6 step:5795 [D loss: 0.677992, acc.: 60.16%] [G loss: 1.035645]\n",
      "epoch:6 step:5796 [D loss: 0.677127, acc.: 57.81%] [G loss: 1.082627]\n",
      "epoch:6 step:5797 [D loss: 0.577545, acc.: 70.31%] [G loss: 1.037933]\n",
      "epoch:6 step:5798 [D loss: 0.642574, acc.: 64.84%] [G loss: 1.096906]\n",
      "epoch:6 step:5799 [D loss: 0.580892, acc.: 71.09%] [G loss: 1.129618]\n",
      "epoch:6 step:5800 [D loss: 0.634297, acc.: 60.94%] [G loss: 1.180713]\n",
      "epoch:6 step:5801 [D loss: 0.731159, acc.: 55.47%] [G loss: 1.101949]\n",
      "epoch:6 step:5802 [D loss: 0.624962, acc.: 62.50%] [G loss: 1.098887]\n",
      "epoch:6 step:5803 [D loss: 0.637804, acc.: 65.62%] [G loss: 1.021193]\n",
      "epoch:6 step:5804 [D loss: 0.554295, acc.: 75.00%] [G loss: 1.117279]\n",
      "epoch:6 step:5805 [D loss: 0.620814, acc.: 66.41%] [G loss: 1.066688]\n",
      "epoch:6 step:5806 [D loss: 0.590192, acc.: 64.06%] [G loss: 1.130732]\n",
      "epoch:6 step:5807 [D loss: 0.656325, acc.: 63.28%] [G loss: 1.258677]\n",
      "epoch:6 step:5808 [D loss: 0.557846, acc.: 71.88%] [G loss: 1.083533]\n",
      "epoch:6 step:5809 [D loss: 0.555529, acc.: 71.88%] [G loss: 1.218533]\n",
      "epoch:6 step:5810 [D loss: 0.601676, acc.: 69.53%] [G loss: 1.077545]\n",
      "epoch:6 step:5811 [D loss: 0.601337, acc.: 67.19%] [G loss: 1.092808]\n",
      "epoch:6 step:5812 [D loss: 0.649028, acc.: 66.41%] [G loss: 1.035453]\n",
      "epoch:6 step:5813 [D loss: 0.586105, acc.: 70.31%] [G loss: 1.014894]\n",
      "epoch:6 step:5814 [D loss: 0.637723, acc.: 63.28%] [G loss: 1.034025]\n",
      "epoch:6 step:5815 [D loss: 0.654207, acc.: 63.28%] [G loss: 1.121708]\n",
      "epoch:6 step:5816 [D loss: 0.611346, acc.: 62.50%] [G loss: 1.255290]\n",
      "epoch:6 step:5817 [D loss: 0.743573, acc.: 50.78%] [G loss: 1.076416]\n",
      "epoch:6 step:5818 [D loss: 0.625417, acc.: 66.41%] [G loss: 1.050911]\n",
      "epoch:6 step:5819 [D loss: 0.620749, acc.: 66.41%] [G loss: 1.066649]\n",
      "epoch:6 step:5820 [D loss: 0.596763, acc.: 70.31%] [G loss: 1.132365]\n",
      "epoch:6 step:5821 [D loss: 0.611181, acc.: 67.97%] [G loss: 1.128618]\n",
      "epoch:6 step:5822 [D loss: 0.773750, acc.: 50.00%] [G loss: 1.003343]\n",
      "epoch:6 step:5823 [D loss: 0.644746, acc.: 63.28%] [G loss: 1.014741]\n",
      "epoch:6 step:5824 [D loss: 0.561673, acc.: 73.44%] [G loss: 1.206901]\n",
      "epoch:6 step:5825 [D loss: 0.600010, acc.: 68.75%] [G loss: 1.192426]\n",
      "epoch:6 step:5826 [D loss: 0.660197, acc.: 59.38%] [G loss: 0.979924]\n",
      "epoch:6 step:5827 [D loss: 0.655112, acc.: 67.19%] [G loss: 0.986493]\n",
      "epoch:6 step:5828 [D loss: 0.684952, acc.: 53.12%] [G loss: 0.970390]\n",
      "epoch:6 step:5829 [D loss: 0.684269, acc.: 61.72%] [G loss: 0.934637]\n",
      "epoch:6 step:5830 [D loss: 0.617003, acc.: 65.62%] [G loss: 1.188491]\n",
      "epoch:6 step:5831 [D loss: 0.624844, acc.: 59.38%] [G loss: 1.008535]\n",
      "epoch:6 step:5832 [D loss: 0.570354, acc.: 71.88%] [G loss: 1.157302]\n",
      "epoch:6 step:5833 [D loss: 0.663953, acc.: 64.06%] [G loss: 0.943750]\n",
      "epoch:6 step:5834 [D loss: 0.552426, acc.: 75.78%] [G loss: 0.954832]\n",
      "epoch:6 step:5835 [D loss: 0.650558, acc.: 60.16%] [G loss: 1.082269]\n",
      "epoch:6 step:5836 [D loss: 0.680368, acc.: 57.81%] [G loss: 1.083884]\n",
      "epoch:6 step:5837 [D loss: 0.693836, acc.: 59.38%] [G loss: 0.970904]\n",
      "epoch:6 step:5838 [D loss: 0.654273, acc.: 57.81%] [G loss: 0.942949]\n",
      "epoch:6 step:5839 [D loss: 0.595518, acc.: 70.31%] [G loss: 1.063483]\n",
      "epoch:6 step:5840 [D loss: 0.584315, acc.: 72.66%] [G loss: 1.057034]\n",
      "epoch:6 step:5841 [D loss: 0.645489, acc.: 62.50%] [G loss: 0.997194]\n",
      "epoch:6 step:5842 [D loss: 0.619178, acc.: 68.75%] [G loss: 1.035603]\n",
      "epoch:6 step:5843 [D loss: 0.633348, acc.: 60.94%] [G loss: 1.049362]\n",
      "epoch:6 step:5844 [D loss: 0.717320, acc.: 50.00%] [G loss: 0.848290]\n",
      "epoch:6 step:5845 [D loss: 0.640663, acc.: 66.41%] [G loss: 1.017797]\n",
      "epoch:6 step:5846 [D loss: 0.676861, acc.: 62.50%] [G loss: 0.935501]\n",
      "epoch:6 step:5847 [D loss: 0.626579, acc.: 65.62%] [G loss: 0.977638]\n",
      "epoch:6 step:5848 [D loss: 0.641112, acc.: 61.72%] [G loss: 1.145123]\n",
      "epoch:6 step:5849 [D loss: 0.630658, acc.: 67.19%] [G loss: 1.084094]\n",
      "epoch:6 step:5850 [D loss: 0.753668, acc.: 50.78%] [G loss: 0.855578]\n",
      "epoch:6 step:5851 [D loss: 0.741211, acc.: 54.69%] [G loss: 0.869488]\n",
      "epoch:6 step:5852 [D loss: 0.620383, acc.: 64.84%] [G loss: 1.148852]\n",
      "epoch:6 step:5853 [D loss: 0.684896, acc.: 60.94%] [G loss: 1.168357]\n",
      "epoch:6 step:5854 [D loss: 0.716948, acc.: 59.38%] [G loss: 1.134682]\n",
      "epoch:6 step:5855 [D loss: 0.579042, acc.: 70.31%] [G loss: 1.140931]\n",
      "epoch:6 step:5856 [D loss: 0.641168, acc.: 60.94%] [G loss: 1.024331]\n",
      "epoch:6 step:5857 [D loss: 0.549761, acc.: 75.78%] [G loss: 1.445631]\n",
      "epoch:6 step:5858 [D loss: 0.590986, acc.: 67.97%] [G loss: 1.191264]\n",
      "epoch:6 step:5859 [D loss: 0.677689, acc.: 60.16%] [G loss: 1.038228]\n",
      "epoch:6 step:5860 [D loss: 0.653307, acc.: 59.38%] [G loss: 1.041706]\n",
      "epoch:6 step:5861 [D loss: 0.678506, acc.: 60.94%] [G loss: 0.891935]\n",
      "epoch:6 step:5862 [D loss: 0.667580, acc.: 60.16%] [G loss: 1.054553]\n",
      "epoch:6 step:5863 [D loss: 0.694522, acc.: 57.81%] [G loss: 1.014711]\n",
      "epoch:6 step:5864 [D loss: 0.703680, acc.: 54.69%] [G loss: 1.090927]\n",
      "epoch:6 step:5865 [D loss: 0.610100, acc.: 64.06%] [G loss: 0.896305]\n",
      "epoch:6 step:5866 [D loss: 0.657269, acc.: 62.50%] [G loss: 1.073479]\n",
      "epoch:6 step:5867 [D loss: 0.632688, acc.: 61.72%] [G loss: 1.159331]\n",
      "epoch:6 step:5868 [D loss: 0.609026, acc.: 67.19%] [G loss: 0.935496]\n",
      "epoch:6 step:5869 [D loss: 0.592917, acc.: 68.75%] [G loss: 0.982971]\n",
      "epoch:6 step:5870 [D loss: 0.684516, acc.: 57.81%] [G loss: 0.946516]\n",
      "epoch:6 step:5871 [D loss: 0.578610, acc.: 70.31%] [G loss: 1.071875]\n",
      "epoch:6 step:5872 [D loss: 0.619750, acc.: 65.62%] [G loss: 1.028739]\n",
      "epoch:6 step:5873 [D loss: 0.665799, acc.: 59.38%] [G loss: 0.968415]\n",
      "epoch:6 step:5874 [D loss: 0.571022, acc.: 68.75%] [G loss: 1.119285]\n",
      "epoch:6 step:5875 [D loss: 0.638620, acc.: 62.50%] [G loss: 1.098834]\n",
      "epoch:6 step:5876 [D loss: 0.642177, acc.: 59.38%] [G loss: 1.106816]\n",
      "epoch:6 step:5877 [D loss: 0.583890, acc.: 70.31%] [G loss: 1.099828]\n",
      "epoch:6 step:5878 [D loss: 0.695159, acc.: 56.25%] [G loss: 1.066275]\n",
      "epoch:6 step:5879 [D loss: 0.684119, acc.: 57.03%] [G loss: 1.027489]\n",
      "epoch:6 step:5880 [D loss: 0.597532, acc.: 69.53%] [G loss: 1.348702]\n",
      "epoch:6 step:5881 [D loss: 0.655008, acc.: 63.28%] [G loss: 1.078117]\n",
      "epoch:6 step:5882 [D loss: 0.573576, acc.: 69.53%] [G loss: 1.218369]\n",
      "epoch:6 step:5883 [D loss: 0.602750, acc.: 67.19%] [G loss: 1.173215]\n",
      "epoch:6 step:5884 [D loss: 0.624745, acc.: 63.28%] [G loss: 1.042363]\n",
      "epoch:6 step:5885 [D loss: 0.726025, acc.: 53.12%] [G loss: 0.941079]\n",
      "epoch:6 step:5886 [D loss: 0.635863, acc.: 60.94%] [G loss: 1.021527]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:6 step:5887 [D loss: 0.608295, acc.: 63.28%] [G loss: 1.096154]\n",
      "epoch:6 step:5888 [D loss: 0.613943, acc.: 67.97%] [G loss: 1.106535]\n",
      "epoch:6 step:5889 [D loss: 0.549443, acc.: 73.44%] [G loss: 1.099737]\n",
      "epoch:6 step:5890 [D loss: 0.629505, acc.: 65.62%] [G loss: 1.126184]\n",
      "epoch:6 step:5891 [D loss: 0.644852, acc.: 65.62%] [G loss: 1.093817]\n",
      "epoch:6 step:5892 [D loss: 0.654652, acc.: 63.28%] [G loss: 1.083051]\n",
      "epoch:6 step:5893 [D loss: 0.585700, acc.: 74.22%] [G loss: 1.167830]\n",
      "epoch:6 step:5894 [D loss: 0.611768, acc.: 64.84%] [G loss: 1.068230]\n",
      "epoch:6 step:5895 [D loss: 0.638111, acc.: 68.75%] [G loss: 1.119016]\n",
      "epoch:6 step:5896 [D loss: 0.627334, acc.: 60.94%] [G loss: 1.019204]\n",
      "epoch:6 step:5897 [D loss: 0.631040, acc.: 60.94%] [G loss: 1.132643]\n",
      "epoch:6 step:5898 [D loss: 0.654482, acc.: 60.94%] [G loss: 1.103097]\n",
      "epoch:6 step:5899 [D loss: 0.587739, acc.: 69.53%] [G loss: 1.028779]\n",
      "epoch:6 step:5900 [D loss: 0.705073, acc.: 55.47%] [G loss: 1.092693]\n",
      "epoch:6 step:5901 [D loss: 0.662443, acc.: 56.25%] [G loss: 1.170650]\n",
      "epoch:6 step:5902 [D loss: 0.690034, acc.: 54.69%] [G loss: 0.959300]\n",
      "epoch:6 step:5903 [D loss: 0.570824, acc.: 68.75%] [G loss: 0.901026]\n",
      "epoch:6 step:5904 [D loss: 0.666688, acc.: 57.81%] [G loss: 1.015631]\n",
      "epoch:6 step:5905 [D loss: 0.607177, acc.: 67.19%] [G loss: 1.063313]\n",
      "epoch:6 step:5906 [D loss: 0.651978, acc.: 63.28%] [G loss: 1.124689]\n",
      "epoch:6 step:5907 [D loss: 0.580290, acc.: 71.88%] [G loss: 1.167104]\n",
      "epoch:6 step:5908 [D loss: 0.602288, acc.: 67.97%] [G loss: 1.126382]\n",
      "epoch:6 step:5909 [D loss: 0.577864, acc.: 72.66%] [G loss: 1.202226]\n",
      "epoch:6 step:5910 [D loss: 0.628627, acc.: 67.19%] [G loss: 1.076013]\n",
      "epoch:6 step:5911 [D loss: 0.625569, acc.: 65.62%] [G loss: 1.169957]\n",
      "epoch:6 step:5912 [D loss: 0.700912, acc.: 57.03%] [G loss: 0.867852]\n",
      "epoch:6 step:5913 [D loss: 0.584494, acc.: 68.75%] [G loss: 1.082460]\n",
      "epoch:6 step:5914 [D loss: 0.715442, acc.: 55.47%] [G loss: 0.938105]\n",
      "epoch:6 step:5915 [D loss: 0.678243, acc.: 57.81%] [G loss: 1.047634]\n",
      "epoch:6 step:5916 [D loss: 0.610216, acc.: 66.41%] [G loss: 1.076457]\n",
      "epoch:6 step:5917 [D loss: 0.638413, acc.: 66.41%] [G loss: 1.105481]\n",
      "epoch:6 step:5918 [D loss: 0.575770, acc.: 72.66%] [G loss: 1.018259]\n",
      "epoch:6 step:5919 [D loss: 0.618511, acc.: 64.06%] [G loss: 1.140549]\n",
      "epoch:6 step:5920 [D loss: 0.689274, acc.: 62.50%] [G loss: 0.950360]\n",
      "epoch:6 step:5921 [D loss: 0.586073, acc.: 70.31%] [G loss: 1.138199]\n",
      "epoch:6 step:5922 [D loss: 0.511342, acc.: 75.00%] [G loss: 1.068136]\n",
      "epoch:6 step:5923 [D loss: 0.744781, acc.: 54.69%] [G loss: 1.078334]\n",
      "epoch:6 step:5924 [D loss: 0.628807, acc.: 64.84%] [G loss: 0.925138]\n",
      "epoch:6 step:5925 [D loss: 0.565598, acc.: 70.31%] [G loss: 0.975792]\n",
      "epoch:6 step:5926 [D loss: 0.696115, acc.: 58.59%] [G loss: 1.053640]\n",
      "epoch:6 step:5927 [D loss: 0.638966, acc.: 61.72%] [G loss: 1.085802]\n",
      "epoch:6 step:5928 [D loss: 0.698531, acc.: 53.91%] [G loss: 1.063540]\n",
      "epoch:6 step:5929 [D loss: 0.668339, acc.: 57.81%] [G loss: 1.025845]\n",
      "epoch:6 step:5930 [D loss: 0.615757, acc.: 64.84%] [G loss: 1.017638]\n",
      "epoch:6 step:5931 [D loss: 0.520217, acc.: 72.66%] [G loss: 1.208658]\n",
      "epoch:6 step:5932 [D loss: 0.721868, acc.: 59.38%] [G loss: 1.085820]\n",
      "epoch:6 step:5933 [D loss: 0.652825, acc.: 59.38%] [G loss: 0.983020]\n",
      "epoch:6 step:5934 [D loss: 0.657979, acc.: 59.38%] [G loss: 1.202496]\n",
      "epoch:6 step:5935 [D loss: 0.653331, acc.: 63.28%] [G loss: 1.118688]\n",
      "epoch:6 step:5936 [D loss: 0.563151, acc.: 76.56%] [G loss: 1.119841]\n",
      "epoch:6 step:5937 [D loss: 0.612031, acc.: 67.97%] [G loss: 1.135191]\n",
      "epoch:6 step:5938 [D loss: 0.709601, acc.: 56.25%] [G loss: 0.886899]\n",
      "epoch:6 step:5939 [D loss: 0.662699, acc.: 60.94%] [G loss: 1.301152]\n",
      "epoch:6 step:5940 [D loss: 0.696820, acc.: 55.47%] [G loss: 1.089239]\n",
      "epoch:6 step:5941 [D loss: 0.618804, acc.: 64.06%] [G loss: 1.168551]\n",
      "epoch:6 step:5942 [D loss: 0.596141, acc.: 67.97%] [G loss: 1.017398]\n",
      "epoch:6 step:5943 [D loss: 0.638139, acc.: 64.84%] [G loss: 1.105156]\n",
      "epoch:6 step:5944 [D loss: 0.743951, acc.: 51.56%] [G loss: 1.009036]\n",
      "epoch:6 step:5945 [D loss: 0.704844, acc.: 60.16%] [G loss: 1.061895]\n",
      "epoch:6 step:5946 [D loss: 0.605226, acc.: 69.53%] [G loss: 1.157540]\n",
      "epoch:6 step:5947 [D loss: 0.604834, acc.: 65.62%] [G loss: 0.992528]\n",
      "epoch:6 step:5948 [D loss: 0.681552, acc.: 58.59%] [G loss: 0.958965]\n",
      "epoch:6 step:5949 [D loss: 0.613569, acc.: 67.19%] [G loss: 1.057710]\n",
      "epoch:6 step:5950 [D loss: 0.622408, acc.: 64.06%] [G loss: 0.893322]\n",
      "epoch:6 step:5951 [D loss: 0.604260, acc.: 70.31%] [G loss: 0.998694]\n",
      "epoch:6 step:5952 [D loss: 0.708871, acc.: 58.59%] [G loss: 1.068856]\n",
      "epoch:6 step:5953 [D loss: 0.606474, acc.: 67.19%] [G loss: 0.981359]\n",
      "epoch:6 step:5954 [D loss: 0.605382, acc.: 71.88%] [G loss: 1.083611]\n",
      "epoch:6 step:5955 [D loss: 0.654674, acc.: 60.16%] [G loss: 0.981386]\n",
      "epoch:6 step:5956 [D loss: 0.586401, acc.: 72.66%] [G loss: 1.050149]\n",
      "epoch:6 step:5957 [D loss: 0.600494, acc.: 67.97%] [G loss: 1.018390]\n",
      "epoch:6 step:5958 [D loss: 0.506496, acc.: 76.56%] [G loss: 1.165670]\n",
      "epoch:6 step:5959 [D loss: 0.727784, acc.: 48.44%] [G loss: 1.067816]\n",
      "epoch:6 step:5960 [D loss: 0.580456, acc.: 71.09%] [G loss: 0.955899]\n",
      "epoch:6 step:5961 [D loss: 0.639364, acc.: 66.41%] [G loss: 1.062523]\n",
      "epoch:6 step:5962 [D loss: 0.714753, acc.: 57.03%] [G loss: 0.976025]\n",
      "epoch:6 step:5963 [D loss: 0.628183, acc.: 65.62%] [G loss: 1.069987]\n",
      "epoch:6 step:5964 [D loss: 0.635504, acc.: 64.84%] [G loss: 1.014670]\n",
      "epoch:6 step:5965 [D loss: 0.548990, acc.: 71.88%] [G loss: 1.144625]\n",
      "epoch:6 step:5966 [D loss: 0.726350, acc.: 55.47%] [G loss: 0.897241]\n",
      "epoch:6 step:5967 [D loss: 0.624402, acc.: 61.72%] [G loss: 0.924895]\n",
      "epoch:6 step:5968 [D loss: 0.641531, acc.: 67.19%] [G loss: 1.210554]\n",
      "epoch:6 step:5969 [D loss: 0.642585, acc.: 63.28%] [G loss: 1.062862]\n",
      "epoch:6 step:5970 [D loss: 0.747608, acc.: 49.22%] [G loss: 0.967442]\n",
      "epoch:6 step:5971 [D loss: 0.641994, acc.: 64.84%] [G loss: 0.852315]\n",
      "epoch:6 step:5972 [D loss: 0.637139, acc.: 64.84%] [G loss: 1.141733]\n",
      "epoch:6 step:5973 [D loss: 0.711557, acc.: 52.34%] [G loss: 1.072420]\n",
      "epoch:6 step:5974 [D loss: 0.676279, acc.: 53.91%] [G loss: 0.966039]\n",
      "epoch:6 step:5975 [D loss: 0.551405, acc.: 73.44%] [G loss: 0.868872]\n",
      "epoch:6 step:5976 [D loss: 0.657804, acc.: 59.38%] [G loss: 1.006995]\n",
      "epoch:6 step:5977 [D loss: 0.597639, acc.: 70.31%] [G loss: 0.927617]\n",
      "epoch:6 step:5978 [D loss: 0.629180, acc.: 63.28%] [G loss: 1.056936]\n",
      "epoch:6 step:5979 [D loss: 0.631481, acc.: 65.62%] [G loss: 1.176226]\n",
      "epoch:6 step:5980 [D loss: 0.686131, acc.: 62.50%] [G loss: 0.968445]\n",
      "epoch:6 step:5981 [D loss: 0.663222, acc.: 57.81%] [G loss: 1.063629]\n",
      "epoch:6 step:5982 [D loss: 0.591300, acc.: 67.97%] [G loss: 1.220801]\n",
      "epoch:6 step:5983 [D loss: 0.651602, acc.: 62.50%] [G loss: 0.961021]\n",
      "epoch:6 step:5984 [D loss: 0.600067, acc.: 65.62%] [G loss: 1.047148]\n",
      "epoch:6 step:5985 [D loss: 0.630982, acc.: 66.41%] [G loss: 1.027919]\n",
      "epoch:6 step:5986 [D loss: 0.664099, acc.: 60.94%] [G loss: 1.041175]\n",
      "epoch:6 step:5987 [D loss: 0.633146, acc.: 66.41%] [G loss: 1.152567]\n",
      "epoch:6 step:5988 [D loss: 0.690333, acc.: 59.38%] [G loss: 0.938015]\n",
      "epoch:6 step:5989 [D loss: 0.621436, acc.: 66.41%] [G loss: 1.159856]\n",
      "epoch:6 step:5990 [D loss: 0.642874, acc.: 58.59%] [G loss: 1.042390]\n",
      "epoch:6 step:5991 [D loss: 0.595644, acc.: 67.97%] [G loss: 1.155545]\n",
      "epoch:6 step:5992 [D loss: 0.651102, acc.: 60.16%] [G loss: 1.121487]\n",
      "epoch:6 step:5993 [D loss: 0.686806, acc.: 57.81%] [G loss: 1.013280]\n",
      "epoch:6 step:5994 [D loss: 0.591827, acc.: 67.19%] [G loss: 1.043556]\n",
      "epoch:6 step:5995 [D loss: 0.621143, acc.: 67.97%] [G loss: 0.959087]\n",
      "epoch:6 step:5996 [D loss: 0.691307, acc.: 60.16%] [G loss: 1.017605]\n",
      "epoch:6 step:5997 [D loss: 0.658249, acc.: 63.28%] [G loss: 1.215063]\n",
      "epoch:6 step:5998 [D loss: 0.742845, acc.: 48.44%] [G loss: 0.854892]\n",
      "epoch:6 step:5999 [D loss: 0.582100, acc.: 72.66%] [G loss: 0.966643]\n",
      "epoch:6 step:6000 [D loss: 0.580775, acc.: 71.09%] [G loss: 1.108892]\n",
      "epoch:6 step:6001 [D loss: 0.567924, acc.: 71.09%] [G loss: 1.179014]\n",
      "epoch:6 step:6002 [D loss: 0.603554, acc.: 63.28%] [G loss: 1.060338]\n",
      "epoch:6 step:6003 [D loss: 0.686665, acc.: 56.25%] [G loss: 0.982862]\n",
      "epoch:6 step:6004 [D loss: 0.640868, acc.: 67.19%] [G loss: 1.167815]\n",
      "epoch:6 step:6005 [D loss: 0.600145, acc.: 65.62%] [G loss: 1.044327]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:6 step:6006 [D loss: 0.659414, acc.: 61.72%] [G loss: 1.028899]\n",
      "epoch:6 step:6007 [D loss: 0.585476, acc.: 71.09%] [G loss: 1.114353]\n",
      "epoch:6 step:6008 [D loss: 0.595565, acc.: 71.88%] [G loss: 1.053346]\n",
      "epoch:6 step:6009 [D loss: 0.581841, acc.: 71.09%] [G loss: 1.001252]\n",
      "epoch:6 step:6010 [D loss: 0.716663, acc.: 53.91%] [G loss: 1.123221]\n",
      "epoch:6 step:6011 [D loss: 0.669000, acc.: 57.81%] [G loss: 1.250009]\n",
      "epoch:6 step:6012 [D loss: 0.665400, acc.: 64.06%] [G loss: 1.055728]\n",
      "epoch:6 step:6013 [D loss: 0.646610, acc.: 61.72%] [G loss: 1.132137]\n",
      "epoch:6 step:6014 [D loss: 0.547850, acc.: 74.22%] [G loss: 1.138984]\n",
      "epoch:6 step:6015 [D loss: 0.638764, acc.: 64.06%] [G loss: 1.096313]\n",
      "epoch:6 step:6016 [D loss: 0.607271, acc.: 64.84%] [G loss: 1.099479]\n",
      "epoch:6 step:6017 [D loss: 0.618934, acc.: 66.41%] [G loss: 1.051922]\n",
      "epoch:6 step:6018 [D loss: 0.670355, acc.: 59.38%] [G loss: 1.074463]\n",
      "epoch:6 step:6019 [D loss: 0.667081, acc.: 57.81%] [G loss: 1.119446]\n",
      "epoch:6 step:6020 [D loss: 0.646541, acc.: 63.28%] [G loss: 1.077855]\n",
      "epoch:6 step:6021 [D loss: 0.607955, acc.: 69.53%] [G loss: 1.183149]\n",
      "epoch:6 step:6022 [D loss: 0.672137, acc.: 57.03%] [G loss: 1.040192]\n",
      "epoch:6 step:6023 [D loss: 0.590298, acc.: 71.09%] [G loss: 1.156132]\n",
      "epoch:6 step:6024 [D loss: 0.562661, acc.: 75.00%] [G loss: 0.968677]\n",
      "epoch:6 step:6025 [D loss: 0.661918, acc.: 57.03%] [G loss: 1.032068]\n",
      "epoch:6 step:6026 [D loss: 0.706612, acc.: 56.25%] [G loss: 0.940476]\n",
      "epoch:6 step:6027 [D loss: 0.572450, acc.: 75.00%] [G loss: 1.096464]\n",
      "epoch:6 step:6028 [D loss: 0.555018, acc.: 73.44%] [G loss: 1.102176]\n",
      "epoch:6 step:6029 [D loss: 0.666906, acc.: 60.16%] [G loss: 0.968265]\n",
      "epoch:6 step:6030 [D loss: 0.546258, acc.: 76.56%] [G loss: 1.054262]\n",
      "epoch:6 step:6031 [D loss: 0.622905, acc.: 67.97%] [G loss: 1.136030]\n",
      "epoch:6 step:6032 [D loss: 0.643579, acc.: 62.50%] [G loss: 1.126646]\n",
      "epoch:6 step:6033 [D loss: 0.713655, acc.: 53.91%] [G loss: 0.915704]\n",
      "epoch:6 step:6034 [D loss: 0.587052, acc.: 67.97%] [G loss: 1.048288]\n",
      "epoch:6 step:6035 [D loss: 0.565903, acc.: 75.00%] [G loss: 1.097829]\n",
      "epoch:6 step:6036 [D loss: 0.593060, acc.: 71.09%] [G loss: 0.921502]\n",
      "epoch:6 step:6037 [D loss: 0.636245, acc.: 65.62%] [G loss: 1.040918]\n",
      "epoch:6 step:6038 [D loss: 0.645838, acc.: 64.06%] [G loss: 1.091009]\n",
      "epoch:6 step:6039 [D loss: 0.629174, acc.: 60.94%] [G loss: 0.992554]\n",
      "epoch:6 step:6040 [D loss: 0.625135, acc.: 65.62%] [G loss: 1.093215]\n",
      "epoch:6 step:6041 [D loss: 0.608133, acc.: 64.06%] [G loss: 1.155855]\n",
      "epoch:6 step:6042 [D loss: 0.573646, acc.: 67.97%] [G loss: 1.262243]\n",
      "epoch:6 step:6043 [D loss: 0.618906, acc.: 69.53%] [G loss: 1.040998]\n",
      "epoch:6 step:6044 [D loss: 0.568816, acc.: 75.00%] [G loss: 1.230187]\n",
      "epoch:6 step:6045 [D loss: 0.643760, acc.: 67.19%] [G loss: 1.071842]\n",
      "epoch:6 step:6046 [D loss: 0.568457, acc.: 68.75%] [G loss: 1.105979]\n",
      "epoch:6 step:6047 [D loss: 0.651518, acc.: 65.62%] [G loss: 1.072598]\n",
      "epoch:6 step:6048 [D loss: 0.709864, acc.: 58.59%] [G loss: 1.120800]\n",
      "epoch:6 step:6049 [D loss: 0.629745, acc.: 64.84%] [G loss: 1.027131]\n",
      "epoch:6 step:6050 [D loss: 0.676067, acc.: 56.25%] [G loss: 1.070867]\n",
      "epoch:6 step:6051 [D loss: 0.705543, acc.: 52.34%] [G loss: 1.058784]\n",
      "epoch:6 step:6052 [D loss: 0.650662, acc.: 66.41%] [G loss: 0.998453]\n",
      "epoch:6 step:6053 [D loss: 0.605643, acc.: 70.31%] [G loss: 1.122439]\n",
      "epoch:6 step:6054 [D loss: 0.653722, acc.: 60.94%] [G loss: 1.122842]\n",
      "epoch:6 step:6055 [D loss: 0.630862, acc.: 66.41%] [G loss: 1.044242]\n",
      "epoch:6 step:6056 [D loss: 0.686309, acc.: 59.38%] [G loss: 0.996558]\n",
      "epoch:6 step:6057 [D loss: 0.571881, acc.: 74.22%] [G loss: 1.132887]\n",
      "epoch:6 step:6058 [D loss: 0.555794, acc.: 73.44%] [G loss: 1.068232]\n",
      "epoch:6 step:6059 [D loss: 0.675717, acc.: 57.03%] [G loss: 1.001735]\n",
      "epoch:6 step:6060 [D loss: 0.623906, acc.: 67.97%] [G loss: 1.040211]\n",
      "epoch:6 step:6061 [D loss: 0.685412, acc.: 60.16%] [G loss: 0.986874]\n",
      "epoch:6 step:6062 [D loss: 0.521024, acc.: 76.56%] [G loss: 1.128414]\n",
      "epoch:6 step:6063 [D loss: 0.601768, acc.: 70.31%] [G loss: 1.128882]\n",
      "epoch:6 step:6064 [D loss: 0.660436, acc.: 62.50%] [G loss: 1.053708]\n",
      "epoch:6 step:6065 [D loss: 0.720538, acc.: 57.03%] [G loss: 0.950329]\n",
      "epoch:6 step:6066 [D loss: 0.621154, acc.: 65.62%] [G loss: 1.017030]\n",
      "epoch:6 step:6067 [D loss: 0.589585, acc.: 65.62%] [G loss: 1.053920]\n",
      "epoch:6 step:6068 [D loss: 0.656992, acc.: 60.16%] [G loss: 1.146149]\n",
      "epoch:6 step:6069 [D loss: 0.567374, acc.: 75.00%] [G loss: 1.042005]\n",
      "epoch:6 step:6070 [D loss: 0.668759, acc.: 58.59%] [G loss: 1.030661]\n",
      "epoch:6 step:6071 [D loss: 0.566549, acc.: 71.88%] [G loss: 1.031034]\n",
      "epoch:6 step:6072 [D loss: 0.579903, acc.: 71.09%] [G loss: 1.092264]\n",
      "epoch:6 step:6073 [D loss: 0.699075, acc.: 60.94%] [G loss: 1.098696]\n",
      "epoch:6 step:6074 [D loss: 0.593588, acc.: 69.53%] [G loss: 1.136050]\n",
      "epoch:6 step:6075 [D loss: 0.566686, acc.: 73.44%] [G loss: 1.121406]\n",
      "epoch:6 step:6076 [D loss: 0.611473, acc.: 69.53%] [G loss: 1.017747]\n",
      "epoch:6 step:6077 [D loss: 0.622072, acc.: 66.41%] [G loss: 1.082124]\n",
      "epoch:6 step:6078 [D loss: 0.619606, acc.: 64.06%] [G loss: 1.042070]\n",
      "epoch:6 step:6079 [D loss: 0.649575, acc.: 59.38%] [G loss: 0.920199]\n",
      "epoch:6 step:6080 [D loss: 0.622970, acc.: 66.41%] [G loss: 1.033934]\n",
      "epoch:6 step:6081 [D loss: 0.613759, acc.: 66.41%] [G loss: 1.147530]\n",
      "epoch:6 step:6082 [D loss: 0.569899, acc.: 69.53%] [G loss: 1.065675]\n",
      "epoch:6 step:6083 [D loss: 0.667909, acc.: 63.28%] [G loss: 1.095654]\n",
      "epoch:6 step:6084 [D loss: 0.587438, acc.: 70.31%] [G loss: 1.078813]\n",
      "epoch:6 step:6085 [D loss: 0.692291, acc.: 57.03%] [G loss: 1.005868]\n",
      "epoch:6 step:6086 [D loss: 0.606272, acc.: 64.06%] [G loss: 1.240883]\n",
      "epoch:6 step:6087 [D loss: 0.596089, acc.: 65.62%] [G loss: 1.014302]\n",
      "epoch:6 step:6088 [D loss: 0.637084, acc.: 62.50%] [G loss: 1.105137]\n",
      "epoch:6 step:6089 [D loss: 0.649545, acc.: 62.50%] [G loss: 1.147902]\n",
      "epoch:6 step:6090 [D loss: 0.563778, acc.: 73.44%] [G loss: 1.122204]\n",
      "epoch:6 step:6091 [D loss: 0.594556, acc.: 69.53%] [G loss: 1.224248]\n",
      "epoch:6 step:6092 [D loss: 0.791737, acc.: 46.09%] [G loss: 0.922698]\n",
      "epoch:6 step:6093 [D loss: 0.560408, acc.: 67.97%] [G loss: 1.118270]\n",
      "epoch:6 step:6094 [D loss: 0.664101, acc.: 57.81%] [G loss: 1.123098]\n",
      "epoch:6 step:6095 [D loss: 0.633765, acc.: 57.81%] [G loss: 0.971165]\n",
      "epoch:6 step:6096 [D loss: 0.627904, acc.: 60.16%] [G loss: 1.083646]\n",
      "epoch:6 step:6097 [D loss: 0.572016, acc.: 67.19%] [G loss: 1.222390]\n",
      "epoch:6 step:6098 [D loss: 0.562664, acc.: 71.09%] [G loss: 1.112612]\n",
      "epoch:6 step:6099 [D loss: 0.706769, acc.: 57.03%] [G loss: 1.120464]\n",
      "epoch:6 step:6100 [D loss: 0.610644, acc.: 67.97%] [G loss: 0.969765]\n",
      "epoch:6 step:6101 [D loss: 0.567716, acc.: 71.09%] [G loss: 1.176426]\n",
      "epoch:6 step:6102 [D loss: 0.577028, acc.: 69.53%] [G loss: 1.052363]\n",
      "epoch:6 step:6103 [D loss: 0.725281, acc.: 53.12%] [G loss: 1.150871]\n",
      "epoch:6 step:6104 [D loss: 0.574008, acc.: 71.88%] [G loss: 1.232124]\n",
      "epoch:6 step:6105 [D loss: 0.633666, acc.: 64.06%] [G loss: 1.248400]\n",
      "epoch:6 step:6106 [D loss: 0.634770, acc.: 66.41%] [G loss: 0.932139]\n",
      "epoch:6 step:6107 [D loss: 0.639258, acc.: 63.28%] [G loss: 1.237855]\n",
      "epoch:6 step:6108 [D loss: 0.569698, acc.: 72.66%] [G loss: 1.041446]\n",
      "epoch:6 step:6109 [D loss: 0.670564, acc.: 58.59%] [G loss: 0.975896]\n",
      "epoch:6 step:6110 [D loss: 0.580073, acc.: 67.97%] [G loss: 1.048450]\n",
      "epoch:6 step:6111 [D loss: 0.618962, acc.: 63.28%] [G loss: 1.010668]\n",
      "epoch:6 step:6112 [D loss: 0.582759, acc.: 71.09%] [G loss: 1.180583]\n",
      "epoch:6 step:6113 [D loss: 0.553428, acc.: 71.09%] [G loss: 1.049486]\n",
      "epoch:6 step:6114 [D loss: 0.702482, acc.: 57.81%] [G loss: 0.967482]\n",
      "epoch:6 step:6115 [D loss: 0.548988, acc.: 70.31%] [G loss: 1.174465]\n",
      "epoch:6 step:6116 [D loss: 0.580860, acc.: 72.66%] [G loss: 1.075494]\n",
      "epoch:6 step:6117 [D loss: 0.642625, acc.: 64.06%] [G loss: 0.998746]\n",
      "epoch:6 step:6118 [D loss: 0.662218, acc.: 59.38%] [G loss: 0.892579]\n",
      "epoch:6 step:6119 [D loss: 0.639948, acc.: 58.59%] [G loss: 1.119685]\n",
      "epoch:6 step:6120 [D loss: 0.624544, acc.: 64.84%] [G loss: 1.108046]\n",
      "epoch:6 step:6121 [D loss: 0.589754, acc.: 70.31%] [G loss: 0.950355]\n",
      "epoch:6 step:6122 [D loss: 0.666801, acc.: 55.47%] [G loss: 1.039030]\n",
      "epoch:6 step:6123 [D loss: 0.669767, acc.: 59.38%] [G loss: 0.933711]\n",
      "epoch:6 step:6124 [D loss: 0.588062, acc.: 67.19%] [G loss: 0.930122]\n",
      "epoch:6 step:6125 [D loss: 0.660107, acc.: 62.50%] [G loss: 1.049667]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:6 step:6126 [D loss: 0.683095, acc.: 63.28%] [G loss: 1.059603]\n",
      "epoch:6 step:6127 [D loss: 0.645300, acc.: 62.50%] [G loss: 1.079883]\n",
      "epoch:6 step:6128 [D loss: 0.580141, acc.: 68.75%] [G loss: 1.098654]\n",
      "epoch:6 step:6129 [D loss: 0.669314, acc.: 60.16%] [G loss: 1.152979]\n",
      "epoch:6 step:6130 [D loss: 0.633342, acc.: 63.28%] [G loss: 0.922633]\n",
      "epoch:6 step:6131 [D loss: 0.629886, acc.: 66.41%] [G loss: 1.127847]\n",
      "epoch:6 step:6132 [D loss: 0.635591, acc.: 61.72%] [G loss: 1.045365]\n",
      "epoch:6 step:6133 [D loss: 0.619614, acc.: 60.94%] [G loss: 1.213806]\n",
      "epoch:6 step:6134 [D loss: 0.516472, acc.: 82.03%] [G loss: 1.074886]\n",
      "epoch:6 step:6135 [D loss: 0.584818, acc.: 73.44%] [G loss: 1.114696]\n",
      "epoch:6 step:6136 [D loss: 0.720776, acc.: 51.56%] [G loss: 0.938188]\n",
      "epoch:6 step:6137 [D loss: 0.600334, acc.: 71.88%] [G loss: 1.014121]\n",
      "epoch:6 step:6138 [D loss: 0.676032, acc.: 57.03%] [G loss: 1.063907]\n",
      "epoch:6 step:6139 [D loss: 0.653321, acc.: 65.62%] [G loss: 0.923556]\n",
      "epoch:6 step:6140 [D loss: 0.585171, acc.: 68.75%] [G loss: 0.939706]\n",
      "epoch:6 step:6141 [D loss: 0.632744, acc.: 68.75%] [G loss: 1.125348]\n",
      "epoch:6 step:6142 [D loss: 0.681154, acc.: 59.38%] [G loss: 1.076894]\n",
      "epoch:6 step:6143 [D loss: 0.630696, acc.: 66.41%] [G loss: 1.066611]\n",
      "epoch:6 step:6144 [D loss: 0.676101, acc.: 58.59%] [G loss: 0.939501]\n",
      "epoch:6 step:6145 [D loss: 0.570850, acc.: 70.31%] [G loss: 1.119630]\n",
      "epoch:6 step:6146 [D loss: 0.580458, acc.: 68.75%] [G loss: 1.142131]\n",
      "epoch:6 step:6147 [D loss: 0.715311, acc.: 52.34%] [G loss: 0.935865]\n",
      "epoch:6 step:6148 [D loss: 0.687245, acc.: 58.59%] [G loss: 1.208979]\n",
      "epoch:6 step:6149 [D loss: 0.658770, acc.: 59.38%] [G loss: 1.062556]\n",
      "epoch:6 step:6150 [D loss: 0.631247, acc.: 70.31%] [G loss: 1.177404]\n",
      "epoch:6 step:6151 [D loss: 0.623626, acc.: 64.06%] [G loss: 0.990887]\n",
      "epoch:6 step:6152 [D loss: 0.611835, acc.: 64.84%] [G loss: 1.170184]\n",
      "epoch:6 step:6153 [D loss: 0.594746, acc.: 70.31%] [G loss: 1.047091]\n",
      "epoch:6 step:6154 [D loss: 0.651794, acc.: 61.72%] [G loss: 0.974219]\n",
      "epoch:6 step:6155 [D loss: 0.749654, acc.: 53.12%] [G loss: 0.950768]\n",
      "epoch:6 step:6156 [D loss: 0.660891, acc.: 60.16%] [G loss: 0.993021]\n",
      "epoch:6 step:6157 [D loss: 0.642068, acc.: 65.62%] [G loss: 1.105130]\n",
      "epoch:6 step:6158 [D loss: 0.642682, acc.: 61.72%] [G loss: 1.037237]\n",
      "epoch:6 step:6159 [D loss: 0.660219, acc.: 60.16%] [G loss: 1.096320]\n",
      "epoch:6 step:6160 [D loss: 0.669889, acc.: 57.81%] [G loss: 1.112186]\n",
      "epoch:6 step:6161 [D loss: 0.627375, acc.: 67.97%] [G loss: 1.041170]\n",
      "epoch:6 step:6162 [D loss: 0.681932, acc.: 58.59%] [G loss: 1.102746]\n",
      "epoch:6 step:6163 [D loss: 0.627543, acc.: 65.62%] [G loss: 1.157055]\n",
      "epoch:6 step:6164 [D loss: 0.661696, acc.: 60.16%] [G loss: 1.089727]\n",
      "epoch:6 step:6165 [D loss: 0.640266, acc.: 65.62%] [G loss: 1.097991]\n",
      "epoch:6 step:6166 [D loss: 0.681190, acc.: 57.03%] [G loss: 1.171690]\n",
      "epoch:6 step:6167 [D loss: 0.634011, acc.: 68.75%] [G loss: 1.126426]\n",
      "epoch:6 step:6168 [D loss: 0.623382, acc.: 64.06%] [G loss: 0.981196]\n",
      "epoch:6 step:6169 [D loss: 0.634225, acc.: 59.38%] [G loss: 1.050246]\n",
      "epoch:6 step:6170 [D loss: 0.578426, acc.: 75.00%] [G loss: 1.129714]\n",
      "epoch:6 step:6171 [D loss: 0.628416, acc.: 64.84%] [G loss: 1.137565]\n",
      "epoch:6 step:6172 [D loss: 0.573969, acc.: 72.66%] [G loss: 1.072554]\n",
      "epoch:6 step:6173 [D loss: 0.564721, acc.: 70.31%] [G loss: 0.935661]\n",
      "epoch:6 step:6174 [D loss: 0.637650, acc.: 61.72%] [G loss: 1.092031]\n",
      "epoch:6 step:6175 [D loss: 0.645559, acc.: 64.06%] [G loss: 1.095602]\n",
      "epoch:6 step:6176 [D loss: 0.602636, acc.: 71.09%] [G loss: 1.187737]\n",
      "epoch:6 step:6177 [D loss: 0.631179, acc.: 64.84%] [G loss: 0.996115]\n",
      "epoch:6 step:6178 [D loss: 0.613544, acc.: 64.84%] [G loss: 0.953148]\n",
      "epoch:6 step:6179 [D loss: 0.632829, acc.: 67.19%] [G loss: 1.043231]\n",
      "epoch:6 step:6180 [D loss: 0.620634, acc.: 68.75%] [G loss: 1.008529]\n",
      "epoch:6 step:6181 [D loss: 0.566787, acc.: 71.09%] [G loss: 1.064503]\n",
      "epoch:6 step:6182 [D loss: 0.623514, acc.: 64.06%] [G loss: 1.108122]\n",
      "epoch:6 step:6183 [D loss: 0.621989, acc.: 63.28%] [G loss: 0.923990]\n",
      "epoch:6 step:6184 [D loss: 0.617292, acc.: 67.19%] [G loss: 1.124966]\n",
      "epoch:6 step:6185 [D loss: 0.632481, acc.: 62.50%] [G loss: 0.933429]\n",
      "epoch:6 step:6186 [D loss: 0.612226, acc.: 61.72%] [G loss: 1.038966]\n",
      "epoch:6 step:6187 [D loss: 0.582814, acc.: 70.31%] [G loss: 0.980148]\n",
      "epoch:6 step:6188 [D loss: 0.623633, acc.: 63.28%] [G loss: 1.107629]\n",
      "epoch:6 step:6189 [D loss: 0.634337, acc.: 61.72%] [G loss: 1.007738]\n",
      "epoch:6 step:6190 [D loss: 0.645507, acc.: 67.19%] [G loss: 0.945698]\n",
      "epoch:6 step:6191 [D loss: 0.593736, acc.: 66.41%] [G loss: 1.070435]\n",
      "epoch:6 step:6192 [D loss: 0.626123, acc.: 67.19%] [G loss: 0.875992]\n",
      "epoch:6 step:6193 [D loss: 0.704435, acc.: 62.50%] [G loss: 0.996520]\n",
      "epoch:6 step:6194 [D loss: 0.546923, acc.: 75.00%] [G loss: 0.967096]\n",
      "epoch:6 step:6195 [D loss: 0.696114, acc.: 53.12%] [G loss: 1.104542]\n",
      "epoch:6 step:6196 [D loss: 0.607057, acc.: 65.62%] [G loss: 0.978079]\n",
      "epoch:6 step:6197 [D loss: 0.744733, acc.: 53.12%] [G loss: 0.787877]\n",
      "epoch:6 step:6198 [D loss: 0.557062, acc.: 72.66%] [G loss: 1.193562]\n",
      "epoch:6 step:6199 [D loss: 0.589278, acc.: 70.31%] [G loss: 1.144241]\n",
      "epoch:6 step:6200 [D loss: 0.587612, acc.: 68.75%] [G loss: 1.182675]\n",
      "epoch:6 step:6201 [D loss: 0.609473, acc.: 64.06%] [G loss: 1.021265]\n",
      "epoch:6 step:6202 [D loss: 0.617280, acc.: 67.97%] [G loss: 1.118866]\n",
      "epoch:6 step:6203 [D loss: 0.666455, acc.: 57.81%] [G loss: 1.214022]\n",
      "epoch:6 step:6204 [D loss: 0.577945, acc.: 70.31%] [G loss: 1.002623]\n",
      "epoch:6 step:6205 [D loss: 0.467332, acc.: 81.25%] [G loss: 1.280326]\n",
      "epoch:6 step:6206 [D loss: 0.582418, acc.: 67.97%] [G loss: 1.024183]\n",
      "epoch:6 step:6207 [D loss: 0.670889, acc.: 61.72%] [G loss: 1.099252]\n",
      "epoch:6 step:6208 [D loss: 0.626344, acc.: 63.28%] [G loss: 1.109552]\n",
      "epoch:6 step:6209 [D loss: 0.674229, acc.: 54.69%] [G loss: 1.025542]\n",
      "epoch:6 step:6210 [D loss: 0.635823, acc.: 60.16%] [G loss: 1.099231]\n",
      "epoch:6 step:6211 [D loss: 0.657118, acc.: 64.06%] [G loss: 1.024806]\n",
      "epoch:6 step:6212 [D loss: 0.616539, acc.: 66.41%] [G loss: 1.020234]\n",
      "epoch:6 step:6213 [D loss: 0.626750, acc.: 61.72%] [G loss: 1.113791]\n",
      "epoch:6 step:6214 [D loss: 0.597937, acc.: 65.62%] [G loss: 1.076727]\n",
      "epoch:6 step:6215 [D loss: 0.766195, acc.: 47.66%] [G loss: 0.988184]\n",
      "epoch:6 step:6216 [D loss: 0.669853, acc.: 58.59%] [G loss: 1.108688]\n",
      "epoch:6 step:6217 [D loss: 0.675475, acc.: 57.03%] [G loss: 1.127193]\n",
      "epoch:6 step:6218 [D loss: 0.664854, acc.: 60.94%] [G loss: 1.096894]\n",
      "epoch:6 step:6219 [D loss: 0.709777, acc.: 53.91%] [G loss: 0.989309]\n",
      "epoch:6 step:6220 [D loss: 0.696813, acc.: 54.69%] [G loss: 0.972395]\n",
      "epoch:6 step:6221 [D loss: 0.617061, acc.: 66.41%] [G loss: 0.915726]\n",
      "epoch:6 step:6222 [D loss: 0.641232, acc.: 60.16%] [G loss: 1.038175]\n",
      "epoch:6 step:6223 [D loss: 0.838676, acc.: 44.53%] [G loss: 0.868571]\n",
      "epoch:6 step:6224 [D loss: 0.558238, acc.: 77.34%] [G loss: 1.033896]\n",
      "epoch:6 step:6225 [D loss: 0.661471, acc.: 57.03%] [G loss: 1.042294]\n",
      "epoch:6 step:6226 [D loss: 0.607913, acc.: 64.84%] [G loss: 1.027002]\n",
      "epoch:6 step:6227 [D loss: 0.587786, acc.: 67.97%] [G loss: 1.116283]\n",
      "epoch:6 step:6228 [D loss: 0.662366, acc.: 60.16%] [G loss: 0.989396]\n",
      "epoch:6 step:6229 [D loss: 0.720912, acc.: 54.69%] [G loss: 0.896584]\n",
      "epoch:6 step:6230 [D loss: 0.614883, acc.: 65.62%] [G loss: 1.148088]\n",
      "epoch:6 step:6231 [D loss: 0.661769, acc.: 58.59%] [G loss: 1.124732]\n",
      "epoch:6 step:6232 [D loss: 0.633195, acc.: 67.19%] [G loss: 1.114790]\n",
      "epoch:6 step:6233 [D loss: 0.685049, acc.: 50.78%] [G loss: 1.025820]\n",
      "epoch:6 step:6234 [D loss: 0.706639, acc.: 54.69%] [G loss: 1.122623]\n",
      "epoch:6 step:6235 [D loss: 0.553923, acc.: 71.09%] [G loss: 1.149843]\n",
      "epoch:6 step:6236 [D loss: 0.632912, acc.: 65.62%] [G loss: 0.983952]\n",
      "epoch:6 step:6237 [D loss: 0.580362, acc.: 73.44%] [G loss: 1.063580]\n",
      "epoch:6 step:6238 [D loss: 0.594385, acc.: 64.06%] [G loss: 1.120645]\n",
      "epoch:6 step:6239 [D loss: 0.663457, acc.: 63.28%] [G loss: 1.037031]\n",
      "epoch:6 step:6240 [D loss: 0.602150, acc.: 67.19%] [G loss: 1.056020]\n",
      "epoch:6 step:6241 [D loss: 0.684201, acc.: 56.25%] [G loss: 1.113560]\n",
      "epoch:6 step:6242 [D loss: 0.645978, acc.: 60.94%] [G loss: 1.089510]\n",
      "epoch:6 step:6243 [D loss: 0.778319, acc.: 48.44%] [G loss: 0.903165]\n",
      "epoch:6 step:6244 [D loss: 0.685039, acc.: 60.16%] [G loss: 0.957236]\n",
      "epoch:6 step:6245 [D loss: 0.681131, acc.: 58.59%] [G loss: 1.029978]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:6 step:6246 [D loss: 0.637865, acc.: 64.06%] [G loss: 0.991981]\n",
      "epoch:6 step:6247 [D loss: 0.639884, acc.: 65.62%] [G loss: 1.167447]\n",
      "epoch:6 step:6248 [D loss: 0.618114, acc.: 64.84%] [G loss: 1.248751]\n",
      "epoch:6 step:6249 [D loss: 0.553006, acc.: 74.22%] [G loss: 1.161373]\n",
      "epoch:6 step:6250 [D loss: 0.711060, acc.: 57.03%] [G loss: 0.983934]\n",
      "epoch:6 step:6251 [D loss: 0.594867, acc.: 70.31%] [G loss: 0.969039]\n",
      "epoch:6 step:6252 [D loss: 0.608063, acc.: 64.84%] [G loss: 1.040891]\n",
      "epoch:6 step:6253 [D loss: 0.583879, acc.: 73.44%] [G loss: 1.061299]\n",
      "epoch:6 step:6254 [D loss: 0.657156, acc.: 60.94%] [G loss: 1.071321]\n",
      "epoch:6 step:6255 [D loss: 0.614470, acc.: 67.19%] [G loss: 1.055100]\n",
      "epoch:6 step:6256 [D loss: 0.601367, acc.: 66.41%] [G loss: 0.971582]\n",
      "epoch:6 step:6257 [D loss: 0.577487, acc.: 73.44%] [G loss: 1.276501]\n",
      "epoch:6 step:6258 [D loss: 0.650668, acc.: 64.06%] [G loss: 1.060639]\n",
      "epoch:6 step:6259 [D loss: 0.542912, acc.: 76.56%] [G loss: 1.160215]\n",
      "epoch:6 step:6260 [D loss: 0.640168, acc.: 63.28%] [G loss: 1.176970]\n",
      "epoch:6 step:6261 [D loss: 0.699533, acc.: 56.25%] [G loss: 1.087151]\n",
      "epoch:6 step:6262 [D loss: 0.569279, acc.: 71.88%] [G loss: 1.012394]\n",
      "epoch:6 step:6263 [D loss: 0.676811, acc.: 59.38%] [G loss: 1.071244]\n",
      "epoch:6 step:6264 [D loss: 0.678527, acc.: 57.81%] [G loss: 1.010952]\n",
      "epoch:6 step:6265 [D loss: 0.663117, acc.: 57.03%] [G loss: 1.055159]\n",
      "epoch:6 step:6266 [D loss: 0.568388, acc.: 71.88%] [G loss: 1.190374]\n",
      "epoch:6 step:6267 [D loss: 0.672538, acc.: 60.94%] [G loss: 1.170492]\n",
      "epoch:6 step:6268 [D loss: 0.616000, acc.: 67.97%] [G loss: 1.101713]\n",
      "epoch:6 step:6269 [D loss: 0.612240, acc.: 71.09%] [G loss: 1.043075]\n",
      "epoch:6 step:6270 [D loss: 0.572775, acc.: 67.97%] [G loss: 0.983909]\n",
      "epoch:6 step:6271 [D loss: 0.671126, acc.: 55.47%] [G loss: 1.075903]\n",
      "epoch:6 step:6272 [D loss: 0.694470, acc.: 59.38%] [G loss: 1.006996]\n",
      "epoch:6 step:6273 [D loss: 0.725444, acc.: 55.47%] [G loss: 1.061027]\n",
      "epoch:6 step:6274 [D loss: 0.590558, acc.: 71.09%] [G loss: 1.266398]\n",
      "epoch:6 step:6275 [D loss: 0.591035, acc.: 71.09%] [G loss: 1.104377]\n",
      "epoch:6 step:6276 [D loss: 0.660390, acc.: 58.59%] [G loss: 1.197797]\n",
      "epoch:6 step:6277 [D loss: 0.672797, acc.: 61.72%] [G loss: 1.000947]\n",
      "epoch:6 step:6278 [D loss: 0.565987, acc.: 73.44%] [G loss: 1.004530]\n",
      "epoch:6 step:6279 [D loss: 0.672658, acc.: 56.25%] [G loss: 1.067294]\n",
      "epoch:6 step:6280 [D loss: 0.723437, acc.: 53.12%] [G loss: 0.893979]\n",
      "epoch:6 step:6281 [D loss: 0.604257, acc.: 68.75%] [G loss: 1.084553]\n",
      "epoch:6 step:6282 [D loss: 0.614528, acc.: 66.41%] [G loss: 0.958219]\n",
      "epoch:6 step:6283 [D loss: 0.603487, acc.: 63.28%] [G loss: 1.039260]\n",
      "epoch:6 step:6284 [D loss: 0.572774, acc.: 72.66%] [G loss: 1.051332]\n",
      "epoch:6 step:6285 [D loss: 0.644092, acc.: 60.16%] [G loss: 1.248991]\n",
      "epoch:6 step:6286 [D loss: 0.730153, acc.: 54.69%] [G loss: 0.898751]\n",
      "epoch:6 step:6287 [D loss: 0.697344, acc.: 53.91%] [G loss: 1.106034]\n",
      "epoch:6 step:6288 [D loss: 0.558868, acc.: 69.53%] [G loss: 1.060905]\n",
      "epoch:6 step:6289 [D loss: 0.670998, acc.: 63.28%] [G loss: 1.049888]\n",
      "epoch:6 step:6290 [D loss: 0.681925, acc.: 52.34%] [G loss: 1.117364]\n",
      "epoch:6 step:6291 [D loss: 0.654704, acc.: 57.81%] [G loss: 0.912919]\n",
      "epoch:6 step:6292 [D loss: 0.680971, acc.: 59.38%] [G loss: 1.048549]\n",
      "epoch:6 step:6293 [D loss: 0.663584, acc.: 60.16%] [G loss: 1.218949]\n",
      "epoch:6 step:6294 [D loss: 0.572184, acc.: 71.09%] [G loss: 1.175236]\n",
      "epoch:6 step:6295 [D loss: 0.710471, acc.: 60.94%] [G loss: 0.954167]\n",
      "epoch:6 step:6296 [D loss: 0.616151, acc.: 66.41%] [G loss: 1.110192]\n",
      "epoch:6 step:6297 [D loss: 0.598436, acc.: 68.75%] [G loss: 1.141425]\n",
      "epoch:6 step:6298 [D loss: 0.523353, acc.: 76.56%] [G loss: 1.215427]\n",
      "epoch:6 step:6299 [D loss: 0.617500, acc.: 62.50%] [G loss: 1.108261]\n",
      "epoch:6 step:6300 [D loss: 0.631785, acc.: 64.06%] [G loss: 1.039470]\n",
      "epoch:6 step:6301 [D loss: 0.657743, acc.: 64.06%] [G loss: 1.028747]\n",
      "epoch:6 step:6302 [D loss: 0.683128, acc.: 56.25%] [G loss: 1.055633]\n",
      "epoch:6 step:6303 [D loss: 0.631049, acc.: 64.06%] [G loss: 1.098718]\n",
      "epoch:6 step:6304 [D loss: 0.599901, acc.: 67.19%] [G loss: 1.041809]\n",
      "epoch:6 step:6305 [D loss: 0.682172, acc.: 57.81%] [G loss: 0.936817]\n",
      "epoch:6 step:6306 [D loss: 0.561016, acc.: 71.09%] [G loss: 1.266265]\n",
      "epoch:6 step:6307 [D loss: 0.636464, acc.: 71.88%] [G loss: 1.121990]\n",
      "epoch:6 step:6308 [D loss: 0.639791, acc.: 67.19%] [G loss: 1.080872]\n",
      "epoch:6 step:6309 [D loss: 0.624985, acc.: 66.41%] [G loss: 1.051205]\n",
      "epoch:6 step:6310 [D loss: 0.633644, acc.: 64.84%] [G loss: 1.101218]\n",
      "epoch:6 step:6311 [D loss: 0.630185, acc.: 69.53%] [G loss: 1.009550]\n",
      "epoch:6 step:6312 [D loss: 0.620807, acc.: 65.62%] [G loss: 0.975628]\n",
      "epoch:6 step:6313 [D loss: 0.698100, acc.: 53.91%] [G loss: 1.061646]\n",
      "epoch:6 step:6314 [D loss: 0.647071, acc.: 63.28%] [G loss: 1.111886]\n",
      "epoch:6 step:6315 [D loss: 0.669874, acc.: 62.50%] [G loss: 1.025227]\n",
      "epoch:6 step:6316 [D loss: 0.663772, acc.: 57.81%] [G loss: 0.893078]\n",
      "epoch:6 step:6317 [D loss: 0.667418, acc.: 59.38%] [G loss: 0.932523]\n",
      "epoch:6 step:6318 [D loss: 0.688996, acc.: 56.25%] [G loss: 1.022194]\n",
      "epoch:6 step:6319 [D loss: 0.600753, acc.: 70.31%] [G loss: 1.126088]\n",
      "epoch:6 step:6320 [D loss: 0.595272, acc.: 68.75%] [G loss: 1.136160]\n",
      "epoch:6 step:6321 [D loss: 0.580538, acc.: 73.44%] [G loss: 1.110022]\n",
      "epoch:6 step:6322 [D loss: 0.676035, acc.: 60.16%] [G loss: 0.979240]\n",
      "epoch:6 step:6323 [D loss: 0.557342, acc.: 67.97%] [G loss: 1.018006]\n",
      "epoch:6 step:6324 [D loss: 0.516885, acc.: 78.12%] [G loss: 1.161602]\n",
      "epoch:6 step:6325 [D loss: 0.637990, acc.: 65.62%] [G loss: 1.079570]\n",
      "epoch:6 step:6326 [D loss: 0.674569, acc.: 57.03%] [G loss: 1.138562]\n",
      "epoch:6 step:6327 [D loss: 0.593480, acc.: 68.75%] [G loss: 1.072433]\n",
      "epoch:6 step:6328 [D loss: 0.648215, acc.: 65.62%] [G loss: 0.992183]\n",
      "epoch:6 step:6329 [D loss: 0.619318, acc.: 64.84%] [G loss: 0.973951]\n",
      "epoch:6 step:6330 [D loss: 0.629584, acc.: 63.28%] [G loss: 0.954263]\n",
      "epoch:6 step:6331 [D loss: 0.729894, acc.: 57.03%] [G loss: 1.147031]\n",
      "epoch:6 step:6332 [D loss: 0.692137, acc.: 51.56%] [G loss: 1.034090]\n",
      "epoch:6 step:6333 [D loss: 0.601458, acc.: 69.53%] [G loss: 1.231739]\n",
      "epoch:6 step:6334 [D loss: 0.618911, acc.: 65.62%] [G loss: 1.120359]\n",
      "epoch:6 step:6335 [D loss: 0.605214, acc.: 63.28%] [G loss: 1.314730]\n",
      "epoch:6 step:6336 [D loss: 0.672877, acc.: 61.72%] [G loss: 0.946050]\n",
      "epoch:6 step:6337 [D loss: 0.682337, acc.: 58.59%] [G loss: 1.015137]\n",
      "epoch:6 step:6338 [D loss: 0.556208, acc.: 76.56%] [G loss: 1.060372]\n",
      "epoch:6 step:6339 [D loss: 0.553772, acc.: 75.00%] [G loss: 1.101486]\n",
      "epoch:6 step:6340 [D loss: 0.550449, acc.: 74.22%] [G loss: 0.974547]\n",
      "epoch:6 step:6341 [D loss: 0.611254, acc.: 64.84%] [G loss: 1.024662]\n",
      "epoch:6 step:6342 [D loss: 0.617734, acc.: 60.94%] [G loss: 1.107555]\n",
      "epoch:6 step:6343 [D loss: 0.662954, acc.: 64.06%] [G loss: 0.907322]\n",
      "epoch:6 step:6344 [D loss: 0.604173, acc.: 67.97%] [G loss: 1.090039]\n",
      "epoch:6 step:6345 [D loss: 0.653256, acc.: 61.72%] [G loss: 1.032009]\n",
      "epoch:6 step:6346 [D loss: 0.674212, acc.: 63.28%] [G loss: 1.049880]\n",
      "epoch:6 step:6347 [D loss: 0.698242, acc.: 55.47%] [G loss: 1.111652]\n",
      "epoch:6 step:6348 [D loss: 0.652007, acc.: 64.06%] [G loss: 1.097380]\n",
      "epoch:6 step:6349 [D loss: 0.658365, acc.: 63.28%] [G loss: 1.189181]\n",
      "epoch:6 step:6350 [D loss: 0.660605, acc.: 58.59%] [G loss: 0.944800]\n",
      "epoch:6 step:6351 [D loss: 0.670062, acc.: 58.59%] [G loss: 1.068520]\n",
      "epoch:6 step:6352 [D loss: 0.677959, acc.: 60.16%] [G loss: 1.111860]\n",
      "epoch:6 step:6353 [D loss: 0.762130, acc.: 51.56%] [G loss: 1.175588]\n",
      "epoch:6 step:6354 [D loss: 0.608462, acc.: 66.41%] [G loss: 0.907516]\n",
      "epoch:6 step:6355 [D loss: 0.697125, acc.: 54.69%] [G loss: 0.925209]\n",
      "epoch:6 step:6356 [D loss: 0.543314, acc.: 77.34%] [G loss: 1.122519]\n",
      "epoch:6 step:6357 [D loss: 0.614033, acc.: 66.41%] [G loss: 1.144501]\n",
      "epoch:6 step:6358 [D loss: 0.672433, acc.: 60.16%] [G loss: 1.077449]\n",
      "epoch:6 step:6359 [D loss: 0.646209, acc.: 61.72%] [G loss: 1.119727]\n",
      "epoch:6 step:6360 [D loss: 0.603283, acc.: 68.75%] [G loss: 1.232869]\n",
      "epoch:6 step:6361 [D loss: 0.669986, acc.: 60.16%] [G loss: 0.975317]\n",
      "epoch:6 step:6362 [D loss: 0.655973, acc.: 65.62%] [G loss: 0.915714]\n",
      "epoch:6 step:6363 [D loss: 0.651681, acc.: 65.62%] [G loss: 1.043005]\n",
      "epoch:6 step:6364 [D loss: 0.592352, acc.: 65.62%] [G loss: 1.134264]\n",
      "epoch:6 step:6365 [D loss: 0.675467, acc.: 59.38%] [G loss: 0.930200]\n",
      "epoch:6 step:6366 [D loss: 0.615105, acc.: 67.19%] [G loss: 1.032134]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:6 step:6367 [D loss: 0.557541, acc.: 73.44%] [G loss: 1.223365]\n",
      "epoch:6 step:6368 [D loss: 0.589981, acc.: 65.62%] [G loss: 1.202055]\n",
      "epoch:6 step:6369 [D loss: 0.653693, acc.: 63.28%] [G loss: 0.911238]\n",
      "epoch:6 step:6370 [D loss: 0.588326, acc.: 68.75%] [G loss: 1.232258]\n",
      "epoch:6 step:6371 [D loss: 0.661510, acc.: 61.72%] [G loss: 1.055461]\n",
      "epoch:6 step:6372 [D loss: 0.717334, acc.: 52.34%] [G loss: 1.043322]\n",
      "epoch:6 step:6373 [D loss: 0.606158, acc.: 67.19%] [G loss: 1.105793]\n",
      "epoch:6 step:6374 [D loss: 0.700413, acc.: 54.69%] [G loss: 0.991087]\n",
      "epoch:6 step:6375 [D loss: 0.713579, acc.: 55.47%] [G loss: 0.998712]\n",
      "epoch:6 step:6376 [D loss: 0.605877, acc.: 62.50%] [G loss: 1.103600]\n",
      "epoch:6 step:6377 [D loss: 0.629305, acc.: 62.50%] [G loss: 1.108374]\n",
      "epoch:6 step:6378 [D loss: 0.731878, acc.: 49.22%] [G loss: 1.012366]\n",
      "epoch:6 step:6379 [D loss: 0.592047, acc.: 67.19%] [G loss: 1.042876]\n",
      "epoch:6 step:6380 [D loss: 0.715577, acc.: 53.91%] [G loss: 1.084319]\n",
      "epoch:6 step:6381 [D loss: 0.582782, acc.: 67.97%] [G loss: 1.171246]\n",
      "epoch:6 step:6382 [D loss: 0.607644, acc.: 63.28%] [G loss: 1.027113]\n",
      "epoch:6 step:6383 [D loss: 0.677849, acc.: 60.16%] [G loss: 1.070902]\n",
      "epoch:6 step:6384 [D loss: 0.714279, acc.: 53.91%] [G loss: 1.055060]\n",
      "epoch:6 step:6385 [D loss: 0.599953, acc.: 72.66%] [G loss: 1.110327]\n",
      "epoch:6 step:6386 [D loss: 0.655953, acc.: 62.50%] [G loss: 1.114880]\n",
      "epoch:6 step:6387 [D loss: 0.622444, acc.: 63.28%] [G loss: 1.037544]\n",
      "epoch:6 step:6388 [D loss: 0.600166, acc.: 69.53%] [G loss: 1.163748]\n",
      "epoch:6 step:6389 [D loss: 0.663372, acc.: 58.59%] [G loss: 1.001910]\n",
      "epoch:6 step:6390 [D loss: 0.609568, acc.: 67.19%] [G loss: 1.073160]\n",
      "epoch:6 step:6391 [D loss: 0.646256, acc.: 61.72%] [G loss: 1.137095]\n",
      "epoch:6 step:6392 [D loss: 0.632048, acc.: 64.06%] [G loss: 1.026174]\n",
      "epoch:6 step:6393 [D loss: 0.703656, acc.: 57.03%] [G loss: 1.073275]\n",
      "epoch:6 step:6394 [D loss: 0.547556, acc.: 75.78%] [G loss: 1.164448]\n",
      "epoch:6 step:6395 [D loss: 0.594125, acc.: 65.62%] [G loss: 1.115384]\n",
      "epoch:6 step:6396 [D loss: 0.672911, acc.: 50.00%] [G loss: 1.029552]\n",
      "epoch:6 step:6397 [D loss: 0.634512, acc.: 61.72%] [G loss: 1.026570]\n",
      "epoch:6 step:6398 [D loss: 0.650831, acc.: 64.84%] [G loss: 1.331674]\n",
      "epoch:6 step:6399 [D loss: 0.532856, acc.: 72.66%] [G loss: 1.035026]\n",
      "epoch:6 step:6400 [D loss: 0.614852, acc.: 68.75%] [G loss: 0.987458]\n",
      "epoch:6 step:6401 [D loss: 0.642422, acc.: 65.62%] [G loss: 0.959153]\n",
      "epoch:6 step:6402 [D loss: 0.696022, acc.: 55.47%] [G loss: 0.981025]\n",
      "epoch:6 step:6403 [D loss: 0.693232, acc.: 57.03%] [G loss: 0.987403]\n",
      "epoch:6 step:6404 [D loss: 0.674631, acc.: 60.94%] [G loss: 0.936475]\n",
      "epoch:6 step:6405 [D loss: 0.641851, acc.: 63.28%] [G loss: 1.124416]\n",
      "epoch:6 step:6406 [D loss: 0.713076, acc.: 56.25%] [G loss: 1.018687]\n",
      "epoch:6 step:6407 [D loss: 0.616000, acc.: 67.19%] [G loss: 1.013532]\n",
      "epoch:6 step:6408 [D loss: 0.656795, acc.: 62.50%] [G loss: 1.148614]\n",
      "epoch:6 step:6409 [D loss: 0.548689, acc.: 76.56%] [G loss: 1.083695]\n",
      "epoch:6 step:6410 [D loss: 0.722288, acc.: 51.56%] [G loss: 1.129805]\n",
      "epoch:6 step:6411 [D loss: 0.598056, acc.: 67.97%] [G loss: 1.007437]\n",
      "epoch:6 step:6412 [D loss: 0.641332, acc.: 62.50%] [G loss: 1.125239]\n",
      "epoch:6 step:6413 [D loss: 0.655430, acc.: 64.06%] [G loss: 1.170651]\n",
      "epoch:6 step:6414 [D loss: 0.657505, acc.: 62.50%] [G loss: 0.971475]\n",
      "epoch:6 step:6415 [D loss: 0.729914, acc.: 50.00%] [G loss: 0.953493]\n",
      "epoch:6 step:6416 [D loss: 0.601778, acc.: 67.97%] [G loss: 1.011733]\n",
      "epoch:6 step:6417 [D loss: 0.564376, acc.: 67.97%] [G loss: 1.185173]\n",
      "epoch:6 step:6418 [D loss: 0.611677, acc.: 63.28%] [G loss: 1.284445]\n",
      "epoch:6 step:6419 [D loss: 0.664531, acc.: 59.38%] [G loss: 1.076994]\n",
      "epoch:6 step:6420 [D loss: 0.565699, acc.: 74.22%] [G loss: 1.047303]\n",
      "epoch:6 step:6421 [D loss: 0.550043, acc.: 72.66%] [G loss: 1.145940]\n",
      "epoch:6 step:6422 [D loss: 0.649067, acc.: 63.28%] [G loss: 0.990410]\n",
      "epoch:6 step:6423 [D loss: 0.583533, acc.: 70.31%] [G loss: 0.954195]\n",
      "epoch:6 step:6424 [D loss: 0.611980, acc.: 62.50%] [G loss: 1.122532]\n",
      "epoch:6 step:6425 [D loss: 0.650345, acc.: 64.06%] [G loss: 0.936435]\n",
      "epoch:6 step:6426 [D loss: 0.729013, acc.: 57.81%] [G loss: 0.939910]\n",
      "epoch:6 step:6427 [D loss: 0.604220, acc.: 67.97%] [G loss: 1.054089]\n",
      "epoch:6 step:6428 [D loss: 0.561913, acc.: 75.78%] [G loss: 1.067230]\n",
      "epoch:6 step:6429 [D loss: 0.599895, acc.: 68.75%] [G loss: 1.147803]\n",
      "epoch:6 step:6430 [D loss: 0.608063, acc.: 66.41%] [G loss: 1.111493]\n",
      "epoch:6 step:6431 [D loss: 0.632012, acc.: 64.06%] [G loss: 1.000438]\n",
      "epoch:6 step:6432 [D loss: 0.579524, acc.: 65.62%] [G loss: 0.938764]\n",
      "epoch:6 step:6433 [D loss: 0.638577, acc.: 63.28%] [G loss: 1.011495]\n",
      "epoch:6 step:6434 [D loss: 0.671618, acc.: 57.03%] [G loss: 0.974699]\n",
      "epoch:6 step:6435 [D loss: 0.683897, acc.: 56.25%] [G loss: 1.059428]\n",
      "epoch:6 step:6436 [D loss: 0.712997, acc.: 52.34%] [G loss: 1.031761]\n",
      "epoch:6 step:6437 [D loss: 0.588489, acc.: 71.09%] [G loss: 1.174213]\n",
      "epoch:6 step:6438 [D loss: 0.562354, acc.: 72.66%] [G loss: 1.079845]\n",
      "epoch:6 step:6439 [D loss: 0.633700, acc.: 64.84%] [G loss: 1.097396]\n",
      "epoch:6 step:6440 [D loss: 0.541916, acc.: 75.00%] [G loss: 1.302466]\n",
      "epoch:6 step:6441 [D loss: 0.640496, acc.: 64.84%] [G loss: 1.049392]\n",
      "epoch:6 step:6442 [D loss: 0.764482, acc.: 51.56%] [G loss: 1.103576]\n",
      "epoch:6 step:6443 [D loss: 0.626436, acc.: 59.38%] [G loss: 0.987257]\n",
      "epoch:6 step:6444 [D loss: 0.605372, acc.: 69.53%] [G loss: 1.177013]\n",
      "epoch:6 step:6445 [D loss: 0.614369, acc.: 66.41%] [G loss: 1.086058]\n",
      "epoch:6 step:6446 [D loss: 0.562203, acc.: 69.53%] [G loss: 1.008036]\n",
      "epoch:6 step:6447 [D loss: 0.669471, acc.: 55.47%] [G loss: 0.923834]\n",
      "epoch:6 step:6448 [D loss: 0.549830, acc.: 75.78%] [G loss: 1.080504]\n",
      "epoch:6 step:6449 [D loss: 0.573065, acc.: 73.44%] [G loss: 1.260074]\n",
      "epoch:6 step:6450 [D loss: 0.735400, acc.: 53.91%] [G loss: 1.042901]\n",
      "epoch:6 step:6451 [D loss: 0.658907, acc.: 59.38%] [G loss: 0.842679]\n",
      "epoch:6 step:6452 [D loss: 0.623371, acc.: 60.16%] [G loss: 1.076133]\n",
      "epoch:6 step:6453 [D loss: 0.569004, acc.: 75.78%] [G loss: 1.134245]\n",
      "epoch:6 step:6454 [D loss: 0.653600, acc.: 67.19%] [G loss: 1.067807]\n",
      "epoch:6 step:6455 [D loss: 0.575093, acc.: 72.66%] [G loss: 1.136234]\n",
      "epoch:6 step:6456 [D loss: 0.668667, acc.: 55.47%] [G loss: 1.067075]\n",
      "epoch:6 step:6457 [D loss: 0.606802, acc.: 67.19%] [G loss: 1.120493]\n",
      "epoch:6 step:6458 [D loss: 0.695982, acc.: 57.81%] [G loss: 0.995851]\n",
      "epoch:6 step:6459 [D loss: 0.735556, acc.: 51.56%] [G loss: 0.907193]\n",
      "epoch:6 step:6460 [D loss: 0.648004, acc.: 62.50%] [G loss: 1.091817]\n",
      "epoch:6 step:6461 [D loss: 0.651013, acc.: 66.41%] [G loss: 1.006653]\n",
      "epoch:6 step:6462 [D loss: 0.613992, acc.: 67.19%] [G loss: 1.044707]\n",
      "epoch:6 step:6463 [D loss: 0.573433, acc.: 69.53%] [G loss: 0.956578]\n",
      "epoch:6 step:6464 [D loss: 0.652688, acc.: 62.50%] [G loss: 1.107545]\n",
      "epoch:6 step:6465 [D loss: 0.603909, acc.: 69.53%] [G loss: 1.238691]\n",
      "epoch:6 step:6466 [D loss: 0.607528, acc.: 64.84%] [G loss: 0.881788]\n",
      "epoch:6 step:6467 [D loss: 0.608345, acc.: 64.06%] [G loss: 1.070709]\n",
      "epoch:6 step:6468 [D loss: 0.570781, acc.: 77.34%] [G loss: 1.327554]\n",
      "epoch:6 step:6469 [D loss: 0.611726, acc.: 65.62%] [G loss: 1.155329]\n",
      "epoch:6 step:6470 [D loss: 0.676841, acc.: 61.72%] [G loss: 1.052295]\n",
      "epoch:6 step:6471 [D loss: 0.564867, acc.: 75.00%] [G loss: 1.139340]\n",
      "epoch:6 step:6472 [D loss: 0.534146, acc.: 74.22%] [G loss: 1.089231]\n",
      "epoch:6 step:6473 [D loss: 0.641030, acc.: 63.28%] [G loss: 1.040633]\n",
      "epoch:6 step:6474 [D loss: 0.588059, acc.: 72.66%] [G loss: 1.055709]\n",
      "epoch:6 step:6475 [D loss: 0.546570, acc.: 69.53%] [G loss: 0.992939]\n",
      "epoch:6 step:6476 [D loss: 0.578034, acc.: 71.88%] [G loss: 1.249213]\n",
      "epoch:6 step:6477 [D loss: 0.722909, acc.: 57.81%] [G loss: 1.056259]\n",
      "epoch:6 step:6478 [D loss: 0.571561, acc.: 71.09%] [G loss: 1.038360]\n",
      "epoch:6 step:6479 [D loss: 0.636927, acc.: 60.94%] [G loss: 1.048591]\n",
      "epoch:6 step:6480 [D loss: 0.663332, acc.: 57.81%] [G loss: 0.883538]\n",
      "epoch:6 step:6481 [D loss: 0.722617, acc.: 53.12%] [G loss: 1.033756]\n",
      "epoch:6 step:6482 [D loss: 0.714048, acc.: 57.03%] [G loss: 1.098495]\n",
      "epoch:6 step:6483 [D loss: 0.592731, acc.: 72.66%] [G loss: 1.309638]\n",
      "epoch:6 step:6484 [D loss: 0.669671, acc.: 57.81%] [G loss: 1.135616]\n",
      "epoch:6 step:6485 [D loss: 0.718284, acc.: 51.56%] [G loss: 1.043144]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:6 step:6486 [D loss: 0.632893, acc.: 64.06%] [G loss: 1.173305]\n",
      "epoch:6 step:6487 [D loss: 0.647546, acc.: 62.50%] [G loss: 0.998565]\n",
      "epoch:6 step:6488 [D loss: 0.681360, acc.: 61.72%] [G loss: 1.077946]\n",
      "epoch:6 step:6489 [D loss: 0.623148, acc.: 64.06%] [G loss: 1.236848]\n",
      "epoch:6 step:6490 [D loss: 0.609684, acc.: 64.06%] [G loss: 1.078947]\n",
      "epoch:6 step:6491 [D loss: 0.569156, acc.: 74.22%] [G loss: 1.144931]\n",
      "epoch:6 step:6492 [D loss: 0.635761, acc.: 64.84%] [G loss: 1.234316]\n",
      "epoch:6 step:6493 [D loss: 0.578256, acc.: 71.09%] [G loss: 1.085631]\n",
      "epoch:6 step:6494 [D loss: 0.755948, acc.: 53.12%] [G loss: 0.938382]\n",
      "epoch:6 step:6495 [D loss: 0.616700, acc.: 66.41%] [G loss: 1.033414]\n",
      "epoch:6 step:6496 [D loss: 0.634719, acc.: 61.72%] [G loss: 1.133812]\n",
      "epoch:6 step:6497 [D loss: 0.637774, acc.: 64.06%] [G loss: 1.132811]\n",
      "epoch:6 step:6498 [D loss: 0.606274, acc.: 67.19%] [G loss: 0.964306]\n",
      "epoch:6 step:6499 [D loss: 0.576068, acc.: 67.97%] [G loss: 0.992968]\n",
      "epoch:6 step:6500 [D loss: 0.653002, acc.: 59.38%] [G loss: 1.074495]\n",
      "epoch:6 step:6501 [D loss: 0.613160, acc.: 65.62%] [G loss: 1.001962]\n",
      "epoch:6 step:6502 [D loss: 0.565895, acc.: 73.44%] [G loss: 1.083938]\n",
      "epoch:6 step:6503 [D loss: 0.703008, acc.: 58.59%] [G loss: 0.917654]\n",
      "epoch:6 step:6504 [D loss: 0.604292, acc.: 64.06%] [G loss: 1.200249]\n",
      "epoch:6 step:6505 [D loss: 0.710690, acc.: 55.47%] [G loss: 1.086658]\n",
      "epoch:6 step:6506 [D loss: 0.625021, acc.: 66.41%] [G loss: 1.133379]\n",
      "epoch:6 step:6507 [D loss: 0.647971, acc.: 58.59%] [G loss: 1.038411]\n",
      "epoch:6 step:6508 [D loss: 0.549966, acc.: 78.12%] [G loss: 1.135988]\n",
      "epoch:6 step:6509 [D loss: 0.671449, acc.: 60.16%] [G loss: 0.979355]\n",
      "epoch:6 step:6510 [D loss: 0.689752, acc.: 53.91%] [G loss: 0.910070]\n",
      "epoch:6 step:6511 [D loss: 0.617663, acc.: 66.41%] [G loss: 1.145094]\n",
      "epoch:6 step:6512 [D loss: 0.623829, acc.: 64.06%] [G loss: 1.051135]\n",
      "epoch:6 step:6513 [D loss: 0.746089, acc.: 47.66%] [G loss: 0.979452]\n",
      "epoch:6 step:6514 [D loss: 0.684070, acc.: 55.47%] [G loss: 0.964638]\n",
      "epoch:6 step:6515 [D loss: 0.562643, acc.: 71.88%] [G loss: 1.257191]\n",
      "epoch:6 step:6516 [D loss: 0.670870, acc.: 59.38%] [G loss: 1.111887]\n",
      "epoch:6 step:6517 [D loss: 0.647379, acc.: 60.16%] [G loss: 1.131629]\n",
      "epoch:6 step:6518 [D loss: 0.688813, acc.: 56.25%] [G loss: 1.127706]\n",
      "epoch:6 step:6519 [D loss: 0.626522, acc.: 62.50%] [G loss: 0.985306]\n",
      "epoch:6 step:6520 [D loss: 0.624689, acc.: 63.28%] [G loss: 1.022845]\n",
      "epoch:6 step:6521 [D loss: 0.637854, acc.: 59.38%] [G loss: 1.064919]\n",
      "epoch:6 step:6522 [D loss: 0.562161, acc.: 71.88%] [G loss: 1.094962]\n",
      "epoch:6 step:6523 [D loss: 0.628451, acc.: 64.84%] [G loss: 1.112221]\n",
      "epoch:6 step:6524 [D loss: 0.581631, acc.: 67.19%] [G loss: 1.141343]\n",
      "epoch:6 step:6525 [D loss: 0.606869, acc.: 67.19%] [G loss: 0.960718]\n",
      "epoch:6 step:6526 [D loss: 0.584510, acc.: 66.41%] [G loss: 1.011069]\n",
      "epoch:6 step:6527 [D loss: 0.595121, acc.: 65.62%] [G loss: 1.121402]\n",
      "epoch:6 step:6528 [D loss: 0.606075, acc.: 72.66%] [G loss: 1.065816]\n",
      "epoch:6 step:6529 [D loss: 0.637516, acc.: 63.28%] [G loss: 1.067484]\n",
      "epoch:6 step:6530 [D loss: 0.648503, acc.: 59.38%] [G loss: 0.989817]\n",
      "epoch:6 step:6531 [D loss: 0.690533, acc.: 58.59%] [G loss: 1.078275]\n",
      "epoch:6 step:6532 [D loss: 0.623280, acc.: 72.66%] [G loss: 1.150220]\n",
      "epoch:6 step:6533 [D loss: 0.639003, acc.: 61.72%] [G loss: 1.146529]\n",
      "epoch:6 step:6534 [D loss: 0.618039, acc.: 70.31%] [G loss: 1.047164]\n",
      "epoch:6 step:6535 [D loss: 0.639328, acc.: 62.50%] [G loss: 1.106756]\n",
      "epoch:6 step:6536 [D loss: 0.526331, acc.: 75.78%] [G loss: 1.064859]\n",
      "epoch:6 step:6537 [D loss: 0.622880, acc.: 67.19%] [G loss: 0.969006]\n",
      "epoch:6 step:6538 [D loss: 0.612099, acc.: 63.28%] [G loss: 1.018311]\n",
      "epoch:6 step:6539 [D loss: 0.556882, acc.: 71.88%] [G loss: 1.115351]\n",
      "epoch:6 step:6540 [D loss: 0.724124, acc.: 53.12%] [G loss: 1.148648]\n",
      "epoch:6 step:6541 [D loss: 0.543687, acc.: 73.44%] [G loss: 1.116210]\n",
      "epoch:6 step:6542 [D loss: 0.596616, acc.: 70.31%] [G loss: 1.193836]\n",
      "epoch:6 step:6543 [D loss: 0.655337, acc.: 61.72%] [G loss: 1.123188]\n",
      "epoch:6 step:6544 [D loss: 0.524776, acc.: 77.34%] [G loss: 1.104513]\n",
      "epoch:6 step:6545 [D loss: 0.628965, acc.: 64.84%] [G loss: 1.120860]\n",
      "epoch:6 step:6546 [D loss: 0.696383, acc.: 55.47%] [G loss: 0.881268]\n",
      "epoch:6 step:6547 [D loss: 0.591307, acc.: 67.97%] [G loss: 1.002423]\n",
      "epoch:6 step:6548 [D loss: 0.609418, acc.: 65.62%] [G loss: 1.054920]\n",
      "epoch:6 step:6549 [D loss: 0.638015, acc.: 67.19%] [G loss: 0.977798]\n",
      "epoch:6 step:6550 [D loss: 0.623749, acc.: 68.75%] [G loss: 1.118474]\n",
      "epoch:6 step:6551 [D loss: 0.625905, acc.: 63.28%] [G loss: 1.017649]\n",
      "epoch:6 step:6552 [D loss: 0.570144, acc.: 69.53%] [G loss: 1.209177]\n",
      "epoch:6 step:6553 [D loss: 0.683210, acc.: 58.59%] [G loss: 1.152488]\n",
      "epoch:6 step:6554 [D loss: 0.586415, acc.: 65.62%] [G loss: 1.047438]\n",
      "epoch:6 step:6555 [D loss: 0.637118, acc.: 61.72%] [G loss: 1.196561]\n",
      "epoch:6 step:6556 [D loss: 0.557343, acc.: 70.31%] [G loss: 1.077018]\n",
      "epoch:6 step:6557 [D loss: 0.665125, acc.: 60.16%] [G loss: 0.942922]\n",
      "epoch:6 step:6558 [D loss: 0.626683, acc.: 63.28%] [G loss: 0.944301]\n",
      "epoch:6 step:6559 [D loss: 0.692580, acc.: 58.59%] [G loss: 1.038174]\n",
      "epoch:7 step:6560 [D loss: 0.621667, acc.: 65.62%] [G loss: 0.961348]\n",
      "epoch:7 step:6561 [D loss: 0.715703, acc.: 52.34%] [G loss: 0.916077]\n",
      "epoch:7 step:6562 [D loss: 0.748514, acc.: 50.00%] [G loss: 0.970761]\n",
      "epoch:7 step:6563 [D loss: 0.660773, acc.: 62.50%] [G loss: 1.096102]\n",
      "epoch:7 step:6564 [D loss: 0.697849, acc.: 54.69%] [G loss: 1.040364]\n",
      "epoch:7 step:6565 [D loss: 0.709775, acc.: 53.12%] [G loss: 1.076640]\n",
      "epoch:7 step:6566 [D loss: 0.705087, acc.: 54.69%] [G loss: 1.006094]\n",
      "epoch:7 step:6567 [D loss: 0.599736, acc.: 63.28%] [G loss: 0.999082]\n",
      "epoch:7 step:6568 [D loss: 0.712321, acc.: 56.25%] [G loss: 1.069152]\n",
      "epoch:7 step:6569 [D loss: 0.652805, acc.: 58.59%] [G loss: 1.022160]\n",
      "epoch:7 step:6570 [D loss: 0.504604, acc.: 83.59%] [G loss: 1.076677]\n",
      "epoch:7 step:6571 [D loss: 0.648441, acc.: 58.59%] [G loss: 1.093928]\n",
      "epoch:7 step:6572 [D loss: 0.609649, acc.: 62.50%] [G loss: 1.142368]\n",
      "epoch:7 step:6573 [D loss: 0.639187, acc.: 66.41%] [G loss: 1.015615]\n",
      "epoch:7 step:6574 [D loss: 0.604197, acc.: 66.41%] [G loss: 1.020334]\n",
      "epoch:7 step:6575 [D loss: 0.631863, acc.: 61.72%] [G loss: 1.077604]\n",
      "epoch:7 step:6576 [D loss: 0.622067, acc.: 64.06%] [G loss: 1.056617]\n",
      "epoch:7 step:6577 [D loss: 0.625031, acc.: 65.62%] [G loss: 1.078413]\n",
      "epoch:7 step:6578 [D loss: 0.606310, acc.: 71.09%] [G loss: 1.047786]\n",
      "epoch:7 step:6579 [D loss: 0.543863, acc.: 75.78%] [G loss: 1.323324]\n",
      "epoch:7 step:6580 [D loss: 0.654528, acc.: 58.59%] [G loss: 1.063942]\n",
      "epoch:7 step:6581 [D loss: 0.540484, acc.: 72.66%] [G loss: 1.206448]\n",
      "epoch:7 step:6582 [D loss: 0.701624, acc.: 56.25%] [G loss: 0.940952]\n",
      "epoch:7 step:6583 [D loss: 0.651234, acc.: 62.50%] [G loss: 1.060771]\n",
      "epoch:7 step:6584 [D loss: 0.640137, acc.: 60.16%] [G loss: 1.096130]\n",
      "epoch:7 step:6585 [D loss: 0.724095, acc.: 51.56%] [G loss: 1.118707]\n",
      "epoch:7 step:6586 [D loss: 0.676411, acc.: 58.59%] [G loss: 1.104467]\n",
      "epoch:7 step:6587 [D loss: 0.564395, acc.: 71.88%] [G loss: 1.190902]\n",
      "epoch:7 step:6588 [D loss: 0.710210, acc.: 55.47%] [G loss: 1.042524]\n",
      "epoch:7 step:6589 [D loss: 0.644320, acc.: 64.06%] [G loss: 1.105525]\n",
      "epoch:7 step:6590 [D loss: 0.715976, acc.: 57.81%] [G loss: 1.083848]\n",
      "epoch:7 step:6591 [D loss: 0.572874, acc.: 67.97%] [G loss: 1.046470]\n",
      "epoch:7 step:6592 [D loss: 0.680372, acc.: 62.50%] [G loss: 0.943519]\n",
      "epoch:7 step:6593 [D loss: 0.710196, acc.: 54.69%] [G loss: 1.161621]\n",
      "epoch:7 step:6594 [D loss: 0.629704, acc.: 64.06%] [G loss: 1.030434]\n",
      "epoch:7 step:6595 [D loss: 0.634176, acc.: 64.06%] [G loss: 1.017057]\n",
      "epoch:7 step:6596 [D loss: 0.613793, acc.: 67.97%] [G loss: 1.040900]\n",
      "epoch:7 step:6597 [D loss: 0.635448, acc.: 65.62%] [G loss: 1.207144]\n",
      "epoch:7 step:6598 [D loss: 0.586193, acc.: 67.19%] [G loss: 1.080714]\n",
      "epoch:7 step:6599 [D loss: 0.689975, acc.: 57.03%] [G loss: 1.120347]\n",
      "epoch:7 step:6600 [D loss: 0.537970, acc.: 77.34%] [G loss: 1.154246]\n",
      "epoch:7 step:6601 [D loss: 0.599390, acc.: 67.19%] [G loss: 1.091395]\n",
      "epoch:7 step:6602 [D loss: 0.564592, acc.: 77.34%] [G loss: 1.203373]\n",
      "epoch:7 step:6603 [D loss: 0.615773, acc.: 68.75%] [G loss: 0.953454]\n",
      "epoch:7 step:6604 [D loss: 0.667314, acc.: 61.72%] [G loss: 0.993902]\n",
      "epoch:7 step:6605 [D loss: 0.679752, acc.: 57.81%] [G loss: 1.086613]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:7 step:6606 [D loss: 0.699794, acc.: 53.12%] [G loss: 0.984056]\n",
      "epoch:7 step:6607 [D loss: 0.598216, acc.: 67.19%] [G loss: 0.870759]\n",
      "epoch:7 step:6608 [D loss: 0.601554, acc.: 65.62%] [G loss: 0.950949]\n",
      "epoch:7 step:6609 [D loss: 0.583058, acc.: 71.09%] [G loss: 0.962859]\n",
      "epoch:7 step:6610 [D loss: 0.624503, acc.: 66.41%] [G loss: 1.039058]\n",
      "epoch:7 step:6611 [D loss: 0.627272, acc.: 64.84%] [G loss: 1.057148]\n",
      "epoch:7 step:6612 [D loss: 0.579503, acc.: 71.09%] [G loss: 1.094010]\n",
      "epoch:7 step:6613 [D loss: 0.675413, acc.: 60.94%] [G loss: 0.984675]\n",
      "epoch:7 step:6614 [D loss: 0.695177, acc.: 57.81%] [G loss: 1.030836]\n",
      "epoch:7 step:6615 [D loss: 0.611255, acc.: 64.06%] [G loss: 0.930811]\n",
      "epoch:7 step:6616 [D loss: 0.661412, acc.: 66.41%] [G loss: 1.025202]\n",
      "epoch:7 step:6617 [D loss: 0.667720, acc.: 60.94%] [G loss: 1.062805]\n",
      "epoch:7 step:6618 [D loss: 0.571334, acc.: 67.97%] [G loss: 0.945744]\n",
      "epoch:7 step:6619 [D loss: 0.551754, acc.: 73.44%] [G loss: 1.103431]\n",
      "epoch:7 step:6620 [D loss: 0.599663, acc.: 64.84%] [G loss: 1.186783]\n",
      "epoch:7 step:6621 [D loss: 0.636926, acc.: 61.72%] [G loss: 1.178486]\n",
      "epoch:7 step:6622 [D loss: 0.629580, acc.: 62.50%] [G loss: 1.119689]\n",
      "epoch:7 step:6623 [D loss: 0.596895, acc.: 67.19%] [G loss: 1.081430]\n",
      "epoch:7 step:6624 [D loss: 0.590975, acc.: 69.53%] [G loss: 1.038607]\n",
      "epoch:7 step:6625 [D loss: 0.600383, acc.: 67.97%] [G loss: 0.994098]\n",
      "epoch:7 step:6626 [D loss: 0.633951, acc.: 67.19%] [G loss: 1.096785]\n",
      "epoch:7 step:6627 [D loss: 0.644345, acc.: 64.84%] [G loss: 1.069815]\n",
      "epoch:7 step:6628 [D loss: 0.589191, acc.: 67.19%] [G loss: 1.078661]\n",
      "epoch:7 step:6629 [D loss: 0.644484, acc.: 62.50%] [G loss: 1.139226]\n",
      "epoch:7 step:6630 [D loss: 0.619428, acc.: 67.19%] [G loss: 1.034400]\n",
      "epoch:7 step:6631 [D loss: 0.698399, acc.: 60.94%] [G loss: 0.993691]\n",
      "epoch:7 step:6632 [D loss: 0.577967, acc.: 70.31%] [G loss: 1.012693]\n",
      "epoch:7 step:6633 [D loss: 0.634257, acc.: 64.06%] [G loss: 1.130578]\n",
      "epoch:7 step:6634 [D loss: 0.551806, acc.: 74.22%] [G loss: 1.135877]\n",
      "epoch:7 step:6635 [D loss: 0.621755, acc.: 65.62%] [G loss: 1.274497]\n",
      "epoch:7 step:6636 [D loss: 0.723077, acc.: 53.91%] [G loss: 1.000464]\n",
      "epoch:7 step:6637 [D loss: 0.595342, acc.: 68.75%] [G loss: 1.168411]\n",
      "epoch:7 step:6638 [D loss: 0.691776, acc.: 59.38%] [G loss: 1.084021]\n",
      "epoch:7 step:6639 [D loss: 0.614064, acc.: 66.41%] [G loss: 1.088014]\n",
      "epoch:7 step:6640 [D loss: 0.621379, acc.: 64.06%] [G loss: 1.209549]\n",
      "epoch:7 step:6641 [D loss: 0.697262, acc.: 57.03%] [G loss: 1.033640]\n",
      "epoch:7 step:6642 [D loss: 0.633860, acc.: 65.62%] [G loss: 1.074490]\n",
      "epoch:7 step:6643 [D loss: 0.680158, acc.: 58.59%] [G loss: 1.025044]\n",
      "epoch:7 step:6644 [D loss: 0.725898, acc.: 51.56%] [G loss: 0.945168]\n",
      "epoch:7 step:6645 [D loss: 0.621492, acc.: 64.06%] [G loss: 1.099848]\n",
      "epoch:7 step:6646 [D loss: 0.653669, acc.: 61.72%] [G loss: 1.067282]\n",
      "epoch:7 step:6647 [D loss: 0.566972, acc.: 75.00%] [G loss: 1.103117]\n",
      "epoch:7 step:6648 [D loss: 0.545724, acc.: 75.78%] [G loss: 1.232662]\n",
      "epoch:7 step:6649 [D loss: 0.565943, acc.: 71.09%] [G loss: 0.992351]\n",
      "epoch:7 step:6650 [D loss: 0.612145, acc.: 71.09%] [G loss: 0.969032]\n",
      "epoch:7 step:6651 [D loss: 0.600441, acc.: 66.41%] [G loss: 1.077081]\n",
      "epoch:7 step:6652 [D loss: 0.659302, acc.: 62.50%] [G loss: 1.024874]\n",
      "epoch:7 step:6653 [D loss: 0.663959, acc.: 60.94%] [G loss: 1.139441]\n",
      "epoch:7 step:6654 [D loss: 0.622568, acc.: 68.75%] [G loss: 1.125744]\n",
      "epoch:7 step:6655 [D loss: 0.685275, acc.: 60.94%] [G loss: 1.057431]\n",
      "epoch:7 step:6656 [D loss: 0.589626, acc.: 67.97%] [G loss: 1.046709]\n",
      "epoch:7 step:6657 [D loss: 0.602751, acc.: 64.06%] [G loss: 0.996712]\n",
      "epoch:7 step:6658 [D loss: 0.654544, acc.: 57.81%] [G loss: 1.199052]\n",
      "epoch:7 step:6659 [D loss: 0.646395, acc.: 60.16%] [G loss: 0.985690]\n",
      "epoch:7 step:6660 [D loss: 0.594754, acc.: 65.62%] [G loss: 0.930996]\n",
      "epoch:7 step:6661 [D loss: 0.618660, acc.: 64.06%] [G loss: 1.114432]\n",
      "epoch:7 step:6662 [D loss: 0.652955, acc.: 60.94%] [G loss: 0.964341]\n",
      "epoch:7 step:6663 [D loss: 0.605612, acc.: 64.06%] [G loss: 1.149593]\n",
      "epoch:7 step:6664 [D loss: 0.576606, acc.: 70.31%] [G loss: 1.178951]\n",
      "epoch:7 step:6665 [D loss: 0.576428, acc.: 71.09%] [G loss: 1.076045]\n",
      "epoch:7 step:6666 [D loss: 0.645190, acc.: 65.62%] [G loss: 0.973993]\n",
      "epoch:7 step:6667 [D loss: 0.547288, acc.: 73.44%] [G loss: 1.095297]\n",
      "epoch:7 step:6668 [D loss: 0.630572, acc.: 67.19%] [G loss: 1.026989]\n",
      "epoch:7 step:6669 [D loss: 0.640327, acc.: 64.06%] [G loss: 1.056497]\n",
      "epoch:7 step:6670 [D loss: 0.596741, acc.: 64.84%] [G loss: 1.216280]\n",
      "epoch:7 step:6671 [D loss: 0.589296, acc.: 66.41%] [G loss: 1.057083]\n",
      "epoch:7 step:6672 [D loss: 0.575439, acc.: 69.53%] [G loss: 0.941305]\n",
      "epoch:7 step:6673 [D loss: 0.625637, acc.: 72.66%] [G loss: 1.036158]\n",
      "epoch:7 step:6674 [D loss: 0.607361, acc.: 71.09%] [G loss: 0.974686]\n",
      "epoch:7 step:6675 [D loss: 0.729007, acc.: 56.25%] [G loss: 0.914448]\n",
      "epoch:7 step:6676 [D loss: 0.683773, acc.: 52.34%] [G loss: 1.005668]\n",
      "epoch:7 step:6677 [D loss: 0.705079, acc.: 60.94%] [G loss: 0.909607]\n",
      "epoch:7 step:6678 [D loss: 0.671333, acc.: 57.03%] [G loss: 0.988848]\n",
      "epoch:7 step:6679 [D loss: 0.668645, acc.: 53.91%] [G loss: 1.020623]\n",
      "epoch:7 step:6680 [D loss: 0.688973, acc.: 53.91%] [G loss: 1.313000]\n",
      "epoch:7 step:6681 [D loss: 0.670598, acc.: 59.38%] [G loss: 0.948123]\n",
      "epoch:7 step:6682 [D loss: 0.723885, acc.: 51.56%] [G loss: 1.166068]\n",
      "epoch:7 step:6683 [D loss: 0.580282, acc.: 67.19%] [G loss: 1.107516]\n",
      "epoch:7 step:6684 [D loss: 0.612107, acc.: 64.06%] [G loss: 1.190602]\n",
      "epoch:7 step:6685 [D loss: 0.693539, acc.: 62.50%] [G loss: 1.036343]\n",
      "epoch:7 step:6686 [D loss: 0.594825, acc.: 67.97%] [G loss: 0.950786]\n",
      "epoch:7 step:6687 [D loss: 0.569337, acc.: 71.09%] [G loss: 1.084011]\n",
      "epoch:7 step:6688 [D loss: 0.576267, acc.: 71.88%] [G loss: 1.290083]\n",
      "epoch:7 step:6689 [D loss: 0.564380, acc.: 70.31%] [G loss: 0.847868]\n",
      "epoch:7 step:6690 [D loss: 0.587734, acc.: 72.66%] [G loss: 1.174327]\n",
      "epoch:7 step:6691 [D loss: 0.759655, acc.: 50.00%] [G loss: 1.010095]\n",
      "epoch:7 step:6692 [D loss: 0.606380, acc.: 63.28%] [G loss: 1.148276]\n",
      "epoch:7 step:6693 [D loss: 0.608288, acc.: 64.06%] [G loss: 1.009815]\n",
      "epoch:7 step:6694 [D loss: 0.607228, acc.: 64.84%] [G loss: 1.002636]\n",
      "epoch:7 step:6695 [D loss: 0.580269, acc.: 70.31%] [G loss: 0.962891]\n",
      "epoch:7 step:6696 [D loss: 0.636580, acc.: 60.16%] [G loss: 1.044576]\n",
      "epoch:7 step:6697 [D loss: 0.580047, acc.: 67.97%] [G loss: 0.981063]\n",
      "epoch:7 step:6698 [D loss: 0.615378, acc.: 67.19%] [G loss: 1.144334]\n",
      "epoch:7 step:6699 [D loss: 0.668503, acc.: 60.94%] [G loss: 0.936376]\n",
      "epoch:7 step:6700 [D loss: 0.676872, acc.: 57.81%] [G loss: 1.060095]\n",
      "epoch:7 step:6701 [D loss: 0.655268, acc.: 62.50%] [G loss: 1.060566]\n",
      "epoch:7 step:6702 [D loss: 0.709770, acc.: 55.47%] [G loss: 1.128285]\n",
      "epoch:7 step:6703 [D loss: 0.641949, acc.: 59.38%] [G loss: 1.061486]\n",
      "epoch:7 step:6704 [D loss: 0.652738, acc.: 59.38%] [G loss: 0.872591]\n",
      "epoch:7 step:6705 [D loss: 0.533778, acc.: 76.56%] [G loss: 1.117751]\n",
      "epoch:7 step:6706 [D loss: 0.591206, acc.: 70.31%] [G loss: 1.150989]\n",
      "epoch:7 step:6707 [D loss: 0.587294, acc.: 71.09%] [G loss: 1.139119]\n",
      "epoch:7 step:6708 [D loss: 0.709058, acc.: 51.56%] [G loss: 0.905033]\n",
      "epoch:7 step:6709 [D loss: 0.627408, acc.: 65.62%] [G loss: 1.202311]\n",
      "epoch:7 step:6710 [D loss: 0.631235, acc.: 70.31%] [G loss: 1.097853]\n",
      "epoch:7 step:6711 [D loss: 0.656102, acc.: 60.94%] [G loss: 1.067161]\n",
      "epoch:7 step:6712 [D loss: 0.506569, acc.: 75.00%] [G loss: 1.177567]\n",
      "epoch:7 step:6713 [D loss: 0.712318, acc.: 55.47%] [G loss: 0.977125]\n",
      "epoch:7 step:6714 [D loss: 0.693514, acc.: 61.72%] [G loss: 0.876431]\n",
      "epoch:7 step:6715 [D loss: 0.610490, acc.: 66.41%] [G loss: 1.185662]\n",
      "epoch:7 step:6716 [D loss: 0.664516, acc.: 60.94%] [G loss: 1.019129]\n",
      "epoch:7 step:6717 [D loss: 0.615938, acc.: 64.06%] [G loss: 1.127260]\n",
      "epoch:7 step:6718 [D loss: 0.642673, acc.: 60.94%] [G loss: 0.956134]\n",
      "epoch:7 step:6719 [D loss: 0.546643, acc.: 78.12%] [G loss: 1.172090]\n",
      "epoch:7 step:6720 [D loss: 0.535825, acc.: 74.22%] [G loss: 1.216595]\n",
      "epoch:7 step:6721 [D loss: 0.664671, acc.: 59.38%] [G loss: 1.014344]\n",
      "epoch:7 step:6722 [D loss: 0.694816, acc.: 58.59%] [G loss: 0.947664]\n",
      "epoch:7 step:6723 [D loss: 0.682071, acc.: 63.28%] [G loss: 1.072038]\n",
      "epoch:7 step:6724 [D loss: 0.638520, acc.: 64.84%] [G loss: 1.026954]\n",
      "epoch:7 step:6725 [D loss: 0.661478, acc.: 60.94%] [G loss: 1.144181]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:7 step:6726 [D loss: 0.587160, acc.: 70.31%] [G loss: 1.231831]\n",
      "epoch:7 step:6727 [D loss: 0.664237, acc.: 54.69%] [G loss: 0.912625]\n",
      "epoch:7 step:6728 [D loss: 0.663931, acc.: 60.16%] [G loss: 1.014656]\n",
      "epoch:7 step:6729 [D loss: 0.652814, acc.: 59.38%] [G loss: 1.068352]\n",
      "epoch:7 step:6730 [D loss: 0.638916, acc.: 62.50%] [G loss: 1.031371]\n",
      "epoch:7 step:6731 [D loss: 0.540303, acc.: 75.78%] [G loss: 1.167874]\n",
      "epoch:7 step:6732 [D loss: 0.645047, acc.: 64.06%] [G loss: 1.090395]\n",
      "epoch:7 step:6733 [D loss: 0.539415, acc.: 74.22%] [G loss: 1.034015]\n",
      "epoch:7 step:6734 [D loss: 0.588926, acc.: 65.62%] [G loss: 1.109949]\n",
      "epoch:7 step:6735 [D loss: 0.580682, acc.: 67.19%] [G loss: 0.961626]\n",
      "epoch:7 step:6736 [D loss: 0.584045, acc.: 72.66%] [G loss: 0.902164]\n",
      "epoch:7 step:6737 [D loss: 0.637382, acc.: 60.94%] [G loss: 1.068769]\n",
      "epoch:7 step:6738 [D loss: 0.802899, acc.: 42.97%] [G loss: 0.980443]\n",
      "epoch:7 step:6739 [D loss: 0.629056, acc.: 66.41%] [G loss: 1.123749]\n",
      "epoch:7 step:6740 [D loss: 0.594586, acc.: 66.41%] [G loss: 1.024866]\n",
      "epoch:7 step:6741 [D loss: 0.502581, acc.: 80.47%] [G loss: 0.965832]\n",
      "epoch:7 step:6742 [D loss: 0.693862, acc.: 53.12%] [G loss: 1.067491]\n",
      "epoch:7 step:6743 [D loss: 0.602092, acc.: 68.75%] [G loss: 1.160803]\n",
      "epoch:7 step:6744 [D loss: 0.687800, acc.: 53.91%] [G loss: 0.932652]\n",
      "epoch:7 step:6745 [D loss: 0.582694, acc.: 71.09%] [G loss: 1.106286]\n",
      "epoch:7 step:6746 [D loss: 0.583383, acc.: 69.53%] [G loss: 1.063122]\n",
      "epoch:7 step:6747 [D loss: 0.651196, acc.: 60.16%] [G loss: 1.058763]\n",
      "epoch:7 step:6748 [D loss: 0.580346, acc.: 71.88%] [G loss: 1.070777]\n",
      "epoch:7 step:6749 [D loss: 0.575836, acc.: 71.88%] [G loss: 1.058674]\n",
      "epoch:7 step:6750 [D loss: 0.607424, acc.: 66.41%] [G loss: 1.045448]\n",
      "epoch:7 step:6751 [D loss: 0.619541, acc.: 68.75%] [G loss: 1.055863]\n",
      "epoch:7 step:6752 [D loss: 0.705081, acc.: 53.91%] [G loss: 0.989205]\n",
      "epoch:7 step:6753 [D loss: 0.713331, acc.: 57.03%] [G loss: 1.026575]\n",
      "epoch:7 step:6754 [D loss: 0.693579, acc.: 57.81%] [G loss: 0.852090]\n",
      "epoch:7 step:6755 [D loss: 0.576447, acc.: 70.31%] [G loss: 1.196941]\n",
      "epoch:7 step:6756 [D loss: 0.594501, acc.: 70.31%] [G loss: 1.212430]\n",
      "epoch:7 step:6757 [D loss: 0.613099, acc.: 67.97%] [G loss: 1.085929]\n",
      "epoch:7 step:6758 [D loss: 0.651043, acc.: 53.91%] [G loss: 1.058540]\n",
      "epoch:7 step:6759 [D loss: 0.741368, acc.: 53.91%] [G loss: 0.907716]\n",
      "epoch:7 step:6760 [D loss: 0.480790, acc.: 81.25%] [G loss: 1.213368]\n",
      "epoch:7 step:6761 [D loss: 0.665372, acc.: 66.41%] [G loss: 0.957563]\n",
      "epoch:7 step:6762 [D loss: 0.561588, acc.: 74.22%] [G loss: 1.103611]\n",
      "epoch:7 step:6763 [D loss: 0.640608, acc.: 63.28%] [G loss: 1.092604]\n",
      "epoch:7 step:6764 [D loss: 0.631543, acc.: 65.62%] [G loss: 1.148890]\n",
      "epoch:7 step:6765 [D loss: 0.631509, acc.: 65.62%] [G loss: 1.072744]\n",
      "epoch:7 step:6766 [D loss: 0.620586, acc.: 60.94%] [G loss: 1.086491]\n",
      "epoch:7 step:6767 [D loss: 0.541805, acc.: 72.66%] [G loss: 1.174788]\n",
      "epoch:7 step:6768 [D loss: 0.679859, acc.: 57.03%] [G loss: 0.949833]\n",
      "epoch:7 step:6769 [D loss: 0.666698, acc.: 64.84%] [G loss: 0.961437]\n",
      "epoch:7 step:6770 [D loss: 0.624739, acc.: 62.50%] [G loss: 1.031446]\n",
      "epoch:7 step:6771 [D loss: 0.570635, acc.: 71.09%] [G loss: 1.151971]\n",
      "epoch:7 step:6772 [D loss: 0.635801, acc.: 64.06%] [G loss: 1.193003]\n",
      "epoch:7 step:6773 [D loss: 0.741172, acc.: 51.56%] [G loss: 0.953249]\n",
      "epoch:7 step:6774 [D loss: 0.674674, acc.: 60.16%] [G loss: 1.072947]\n",
      "epoch:7 step:6775 [D loss: 0.617486, acc.: 65.62%] [G loss: 1.019764]\n",
      "epoch:7 step:6776 [D loss: 0.585256, acc.: 71.09%] [G loss: 1.103277]\n",
      "epoch:7 step:6777 [D loss: 0.652954, acc.: 64.06%] [G loss: 1.090340]\n",
      "epoch:7 step:6778 [D loss: 0.687820, acc.: 60.16%] [G loss: 1.001198]\n",
      "epoch:7 step:6779 [D loss: 0.640764, acc.: 64.06%] [G loss: 1.221351]\n",
      "epoch:7 step:6780 [D loss: 0.545313, acc.: 75.78%] [G loss: 1.030400]\n",
      "epoch:7 step:6781 [D loss: 0.713083, acc.: 57.03%] [G loss: 0.884456]\n",
      "epoch:7 step:6782 [D loss: 0.641415, acc.: 60.16%] [G loss: 0.991625]\n",
      "epoch:7 step:6783 [D loss: 0.701817, acc.: 60.94%] [G loss: 1.125477]\n",
      "epoch:7 step:6784 [D loss: 0.633123, acc.: 63.28%] [G loss: 1.111773]\n",
      "epoch:7 step:6785 [D loss: 0.636225, acc.: 67.19%] [G loss: 1.033624]\n",
      "epoch:7 step:6786 [D loss: 0.592473, acc.: 69.53%] [G loss: 1.000457]\n",
      "epoch:7 step:6787 [D loss: 0.653728, acc.: 66.41%] [G loss: 1.144292]\n",
      "epoch:7 step:6788 [D loss: 0.584820, acc.: 75.78%] [G loss: 1.251676]\n",
      "epoch:7 step:6789 [D loss: 0.637543, acc.: 61.72%] [G loss: 1.154412]\n",
      "epoch:7 step:6790 [D loss: 0.598219, acc.: 71.09%] [G loss: 1.015115]\n",
      "epoch:7 step:6791 [D loss: 0.695714, acc.: 57.81%] [G loss: 0.953637]\n",
      "epoch:7 step:6792 [D loss: 0.603006, acc.: 67.19%] [G loss: 1.041331]\n",
      "epoch:7 step:6793 [D loss: 0.600345, acc.: 63.28%] [G loss: 1.048715]\n",
      "epoch:7 step:6794 [D loss: 0.567481, acc.: 70.31%] [G loss: 1.099588]\n",
      "epoch:7 step:6795 [D loss: 0.657115, acc.: 60.94%] [G loss: 1.045596]\n",
      "epoch:7 step:6796 [D loss: 0.567578, acc.: 67.97%] [G loss: 1.155924]\n",
      "epoch:7 step:6797 [D loss: 0.681244, acc.: 59.38%] [G loss: 1.007221]\n",
      "epoch:7 step:6798 [D loss: 0.597662, acc.: 68.75%] [G loss: 0.906350]\n",
      "epoch:7 step:6799 [D loss: 0.621459, acc.: 63.28%] [G loss: 0.958301]\n",
      "epoch:7 step:6800 [D loss: 0.723217, acc.: 53.12%] [G loss: 0.898382]\n",
      "epoch:7 step:6801 [D loss: 0.621041, acc.: 62.50%] [G loss: 0.980788]\n",
      "epoch:7 step:6802 [D loss: 0.565754, acc.: 71.88%] [G loss: 1.043740]\n",
      "epoch:7 step:6803 [D loss: 0.646868, acc.: 64.06%] [G loss: 1.208071]\n",
      "epoch:7 step:6804 [D loss: 0.719397, acc.: 51.56%] [G loss: 1.011722]\n",
      "epoch:7 step:6805 [D loss: 0.556406, acc.: 69.53%] [G loss: 1.035864]\n",
      "epoch:7 step:6806 [D loss: 0.599885, acc.: 67.97%] [G loss: 1.028578]\n",
      "epoch:7 step:6807 [D loss: 0.583932, acc.: 69.53%] [G loss: 1.194272]\n",
      "epoch:7 step:6808 [D loss: 0.652930, acc.: 60.16%] [G loss: 1.002558]\n",
      "epoch:7 step:6809 [D loss: 0.558074, acc.: 75.78%] [G loss: 1.252203]\n",
      "epoch:7 step:6810 [D loss: 0.646418, acc.: 59.38%] [G loss: 1.084659]\n",
      "epoch:7 step:6811 [D loss: 0.696378, acc.: 61.72%] [G loss: 0.876549]\n",
      "epoch:7 step:6812 [D loss: 0.701903, acc.: 54.69%] [G loss: 0.949137]\n",
      "epoch:7 step:6813 [D loss: 0.700448, acc.: 55.47%] [G loss: 1.007647]\n",
      "epoch:7 step:6814 [D loss: 0.660180, acc.: 57.81%] [G loss: 0.932381]\n",
      "epoch:7 step:6815 [D loss: 0.613905, acc.: 67.97%] [G loss: 1.088925]\n",
      "epoch:7 step:6816 [D loss: 0.661018, acc.: 60.94%] [G loss: 0.992883]\n",
      "epoch:7 step:6817 [D loss: 0.668872, acc.: 61.72%] [G loss: 1.141781]\n",
      "epoch:7 step:6818 [D loss: 0.699410, acc.: 53.91%] [G loss: 1.126657]\n",
      "epoch:7 step:6819 [D loss: 0.568260, acc.: 71.88%] [G loss: 1.074107]\n",
      "epoch:7 step:6820 [D loss: 0.625051, acc.: 65.62%] [G loss: 1.136051]\n",
      "epoch:7 step:6821 [D loss: 0.667896, acc.: 60.94%] [G loss: 0.980215]\n",
      "epoch:7 step:6822 [D loss: 0.755632, acc.: 48.44%] [G loss: 0.871403]\n",
      "epoch:7 step:6823 [D loss: 0.686817, acc.: 56.25%] [G loss: 1.043048]\n",
      "epoch:7 step:6824 [D loss: 0.580207, acc.: 76.56%] [G loss: 1.347269]\n",
      "epoch:7 step:6825 [D loss: 0.563883, acc.: 73.44%] [G loss: 1.007336]\n",
      "epoch:7 step:6826 [D loss: 0.614941, acc.: 64.84%] [G loss: 1.022354]\n",
      "epoch:7 step:6827 [D loss: 0.620506, acc.: 66.41%] [G loss: 0.914450]\n",
      "epoch:7 step:6828 [D loss: 0.603670, acc.: 65.62%] [G loss: 1.117280]\n",
      "epoch:7 step:6829 [D loss: 0.584938, acc.: 72.66%] [G loss: 1.262605]\n",
      "epoch:7 step:6830 [D loss: 0.623509, acc.: 57.81%] [G loss: 1.100353]\n",
      "epoch:7 step:6831 [D loss: 0.654654, acc.: 60.16%] [G loss: 1.020638]\n",
      "epoch:7 step:6832 [D loss: 0.625390, acc.: 65.62%] [G loss: 1.214047]\n",
      "epoch:7 step:6833 [D loss: 0.623595, acc.: 62.50%] [G loss: 1.029760]\n",
      "epoch:7 step:6834 [D loss: 0.650282, acc.: 60.16%] [G loss: 0.946736]\n",
      "epoch:7 step:6835 [D loss: 0.656307, acc.: 60.16%] [G loss: 1.146003]\n",
      "epoch:7 step:6836 [D loss: 0.564477, acc.: 69.53%] [G loss: 0.999565]\n",
      "epoch:7 step:6837 [D loss: 0.619092, acc.: 64.06%] [G loss: 1.125405]\n",
      "epoch:7 step:6838 [D loss: 0.625856, acc.: 63.28%] [G loss: 1.027907]\n",
      "epoch:7 step:6839 [D loss: 0.617163, acc.: 66.41%] [G loss: 1.167063]\n",
      "epoch:7 step:6840 [D loss: 0.572244, acc.: 74.22%] [G loss: 1.156035]\n",
      "epoch:7 step:6841 [D loss: 0.660399, acc.: 61.72%] [G loss: 0.951600]\n",
      "epoch:7 step:6842 [D loss: 0.595999, acc.: 67.97%] [G loss: 1.293882]\n",
      "epoch:7 step:6843 [D loss: 0.706446, acc.: 60.16%] [G loss: 0.931481]\n",
      "epoch:7 step:6844 [D loss: 0.702462, acc.: 56.25%] [G loss: 0.888558]\n",
      "epoch:7 step:6845 [D loss: 0.662838, acc.: 53.91%] [G loss: 1.216859]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:7 step:6846 [D loss: 0.568136, acc.: 69.53%] [G loss: 1.132587]\n",
      "epoch:7 step:6847 [D loss: 0.713424, acc.: 46.09%] [G loss: 0.986102]\n",
      "epoch:7 step:6848 [D loss: 0.614977, acc.: 66.41%] [G loss: 1.211454]\n",
      "epoch:7 step:6849 [D loss: 0.597125, acc.: 66.41%] [G loss: 1.053181]\n",
      "epoch:7 step:6850 [D loss: 0.627421, acc.: 60.16%] [G loss: 1.172241]\n",
      "epoch:7 step:6851 [D loss: 0.712493, acc.: 54.69%] [G loss: 0.885092]\n",
      "epoch:7 step:6852 [D loss: 0.596101, acc.: 64.84%] [G loss: 1.118901]\n",
      "epoch:7 step:6853 [D loss: 0.596725, acc.: 67.19%] [G loss: 1.204214]\n",
      "epoch:7 step:6854 [D loss: 0.644915, acc.: 61.72%] [G loss: 0.960746]\n",
      "epoch:7 step:6855 [D loss: 0.581671, acc.: 70.31%] [G loss: 1.203853]\n",
      "epoch:7 step:6856 [D loss: 0.649794, acc.: 67.19%] [G loss: 1.086983]\n",
      "epoch:7 step:6857 [D loss: 0.662019, acc.: 60.94%] [G loss: 1.325433]\n",
      "epoch:7 step:6858 [D loss: 0.679978, acc.: 60.16%] [G loss: 0.994413]\n",
      "epoch:7 step:6859 [D loss: 0.621994, acc.: 67.19%] [G loss: 1.081769]\n",
      "epoch:7 step:6860 [D loss: 0.620437, acc.: 64.84%] [G loss: 1.037701]\n",
      "epoch:7 step:6861 [D loss: 0.619807, acc.: 63.28%] [G loss: 1.206119]\n",
      "epoch:7 step:6862 [D loss: 0.599134, acc.: 67.97%] [G loss: 1.160102]\n",
      "epoch:7 step:6863 [D loss: 0.545217, acc.: 74.22%] [G loss: 1.119421]\n",
      "epoch:7 step:6864 [D loss: 0.610808, acc.: 67.19%] [G loss: 1.020761]\n",
      "epoch:7 step:6865 [D loss: 0.679522, acc.: 60.16%] [G loss: 1.001960]\n",
      "epoch:7 step:6866 [D loss: 0.655070, acc.: 64.84%] [G loss: 1.180421]\n",
      "epoch:7 step:6867 [D loss: 0.672593, acc.: 56.25%] [G loss: 0.884498]\n",
      "epoch:7 step:6868 [D loss: 0.561719, acc.: 75.00%] [G loss: 0.903056]\n",
      "epoch:7 step:6869 [D loss: 0.697625, acc.: 54.69%] [G loss: 1.005214]\n",
      "epoch:7 step:6870 [D loss: 0.595771, acc.: 68.75%] [G loss: 1.190767]\n",
      "epoch:7 step:6871 [D loss: 0.703999, acc.: 59.38%] [G loss: 0.944353]\n",
      "epoch:7 step:6872 [D loss: 0.591875, acc.: 64.84%] [G loss: 1.086053]\n",
      "epoch:7 step:6873 [D loss: 0.617273, acc.: 66.41%] [G loss: 1.126797]\n",
      "epoch:7 step:6874 [D loss: 0.725198, acc.: 52.34%] [G loss: 0.962403]\n",
      "epoch:7 step:6875 [D loss: 0.658955, acc.: 64.06%] [G loss: 1.002861]\n",
      "epoch:7 step:6876 [D loss: 0.648812, acc.: 61.72%] [G loss: 0.981484]\n",
      "epoch:7 step:6877 [D loss: 0.689824, acc.: 59.38%] [G loss: 1.006077]\n",
      "epoch:7 step:6878 [D loss: 0.603777, acc.: 64.06%] [G loss: 1.048083]\n",
      "epoch:7 step:6879 [D loss: 0.597288, acc.: 71.09%] [G loss: 1.211666]\n",
      "epoch:7 step:6880 [D loss: 0.678897, acc.: 56.25%] [G loss: 1.059618]\n",
      "epoch:7 step:6881 [D loss: 0.563109, acc.: 75.00%] [G loss: 1.310727]\n",
      "epoch:7 step:6882 [D loss: 0.677995, acc.: 57.81%] [G loss: 1.057212]\n",
      "epoch:7 step:6883 [D loss: 0.635178, acc.: 63.28%] [G loss: 0.980664]\n",
      "epoch:7 step:6884 [D loss: 0.592401, acc.: 70.31%] [G loss: 1.014040]\n",
      "epoch:7 step:6885 [D loss: 0.716596, acc.: 55.47%] [G loss: 0.982393]\n",
      "epoch:7 step:6886 [D loss: 0.557075, acc.: 71.88%] [G loss: 1.087443]\n",
      "epoch:7 step:6887 [D loss: 0.513692, acc.: 75.00%] [G loss: 1.215501]\n",
      "epoch:7 step:6888 [D loss: 0.620895, acc.: 68.75%] [G loss: 0.957431]\n",
      "epoch:7 step:6889 [D loss: 0.621212, acc.: 66.41%] [G loss: 1.053820]\n",
      "epoch:7 step:6890 [D loss: 0.666872, acc.: 62.50%] [G loss: 0.992949]\n",
      "epoch:7 step:6891 [D loss: 0.677129, acc.: 53.12%] [G loss: 1.052188]\n",
      "epoch:7 step:6892 [D loss: 0.675248, acc.: 62.50%] [G loss: 1.059046]\n",
      "epoch:7 step:6893 [D loss: 0.591893, acc.: 70.31%] [G loss: 1.057051]\n",
      "epoch:7 step:6894 [D loss: 0.570665, acc.: 74.22%] [G loss: 1.043005]\n",
      "epoch:7 step:6895 [D loss: 0.518523, acc.: 77.34%] [G loss: 1.092505]\n",
      "epoch:7 step:6896 [D loss: 0.636438, acc.: 68.75%] [G loss: 1.047701]\n",
      "epoch:7 step:6897 [D loss: 0.543918, acc.: 73.44%] [G loss: 1.151694]\n",
      "epoch:7 step:6898 [D loss: 0.685506, acc.: 57.81%] [G loss: 1.014503]\n",
      "epoch:7 step:6899 [D loss: 0.559131, acc.: 73.44%] [G loss: 1.140229]\n",
      "epoch:7 step:6900 [D loss: 0.610204, acc.: 65.62%] [G loss: 1.126725]\n",
      "epoch:7 step:6901 [D loss: 0.623276, acc.: 64.84%] [G loss: 0.932746]\n",
      "epoch:7 step:6902 [D loss: 0.651402, acc.: 62.50%] [G loss: 1.180330]\n",
      "epoch:7 step:6903 [D loss: 0.663510, acc.: 64.84%] [G loss: 1.034905]\n",
      "epoch:7 step:6904 [D loss: 0.658723, acc.: 63.28%] [G loss: 1.132158]\n",
      "epoch:7 step:6905 [D loss: 0.667512, acc.: 62.50%] [G loss: 1.051619]\n",
      "epoch:7 step:6906 [D loss: 0.594660, acc.: 67.97%] [G loss: 1.099806]\n",
      "epoch:7 step:6907 [D loss: 0.577712, acc.: 70.31%] [G loss: 1.047261]\n",
      "epoch:7 step:6908 [D loss: 0.606725, acc.: 64.06%] [G loss: 1.176299]\n",
      "epoch:7 step:6909 [D loss: 0.765505, acc.: 49.22%] [G loss: 0.893444]\n",
      "epoch:7 step:6910 [D loss: 0.646834, acc.: 63.28%] [G loss: 1.118248]\n",
      "epoch:7 step:6911 [D loss: 0.653962, acc.: 60.16%] [G loss: 1.025305]\n",
      "epoch:7 step:6912 [D loss: 0.673870, acc.: 58.59%] [G loss: 1.082006]\n",
      "epoch:7 step:6913 [D loss: 0.616853, acc.: 69.53%] [G loss: 1.002552]\n",
      "epoch:7 step:6914 [D loss: 0.656778, acc.: 65.62%] [G loss: 1.113581]\n",
      "epoch:7 step:6915 [D loss: 0.533204, acc.: 76.56%] [G loss: 1.243164]\n",
      "epoch:7 step:6916 [D loss: 0.620406, acc.: 65.62%] [G loss: 1.179680]\n",
      "epoch:7 step:6917 [D loss: 0.637410, acc.: 58.59%] [G loss: 1.084401]\n",
      "epoch:7 step:6918 [D loss: 0.627500, acc.: 65.62%] [G loss: 1.037441]\n",
      "epoch:7 step:6919 [D loss: 0.574168, acc.: 69.53%] [G loss: 1.102494]\n",
      "epoch:7 step:6920 [D loss: 0.580040, acc.: 71.88%] [G loss: 1.370293]\n",
      "epoch:7 step:6921 [D loss: 0.634868, acc.: 60.94%] [G loss: 1.092357]\n",
      "epoch:7 step:6922 [D loss: 0.586503, acc.: 74.22%] [G loss: 1.216551]\n",
      "epoch:7 step:6923 [D loss: 0.606305, acc.: 62.50%] [G loss: 1.083639]\n",
      "epoch:7 step:6924 [D loss: 0.692601, acc.: 60.16%] [G loss: 1.023598]\n",
      "epoch:7 step:6925 [D loss: 0.640745, acc.: 64.06%] [G loss: 0.989248]\n",
      "epoch:7 step:6926 [D loss: 0.715901, acc.: 54.69%] [G loss: 1.009783]\n",
      "epoch:7 step:6927 [D loss: 0.622937, acc.: 69.53%] [G loss: 0.975938]\n",
      "epoch:7 step:6928 [D loss: 0.602651, acc.: 69.53%] [G loss: 1.080414]\n",
      "epoch:7 step:6929 [D loss: 0.640486, acc.: 57.03%] [G loss: 1.173287]\n",
      "epoch:7 step:6930 [D loss: 0.687073, acc.: 60.94%] [G loss: 1.020277]\n",
      "epoch:7 step:6931 [D loss: 0.613996, acc.: 67.97%] [G loss: 1.085672]\n",
      "epoch:7 step:6932 [D loss: 0.630945, acc.: 60.94%] [G loss: 1.074533]\n",
      "epoch:7 step:6933 [D loss: 0.655472, acc.: 58.59%] [G loss: 1.129613]\n",
      "epoch:7 step:6934 [D loss: 0.731919, acc.: 50.78%] [G loss: 0.987857]\n",
      "epoch:7 step:6935 [D loss: 0.641284, acc.: 57.81%] [G loss: 0.931764]\n",
      "epoch:7 step:6936 [D loss: 0.644230, acc.: 64.84%] [G loss: 1.067382]\n",
      "epoch:7 step:6937 [D loss: 0.567832, acc.: 68.75%] [G loss: 1.231365]\n",
      "epoch:7 step:6938 [D loss: 0.524354, acc.: 78.12%] [G loss: 1.198121]\n",
      "epoch:7 step:6939 [D loss: 0.676210, acc.: 60.16%] [G loss: 0.974772]\n",
      "epoch:7 step:6940 [D loss: 0.657584, acc.: 58.59%] [G loss: 1.095701]\n",
      "epoch:7 step:6941 [D loss: 0.704761, acc.: 57.81%] [G loss: 1.150018]\n",
      "epoch:7 step:6942 [D loss: 0.629611, acc.: 62.50%] [G loss: 1.017238]\n",
      "epoch:7 step:6943 [D loss: 0.612437, acc.: 71.09%] [G loss: 1.208213]\n",
      "epoch:7 step:6944 [D loss: 0.609416, acc.: 67.19%] [G loss: 1.003589]\n",
      "epoch:7 step:6945 [D loss: 0.631953, acc.: 66.41%] [G loss: 1.047238]\n",
      "epoch:7 step:6946 [D loss: 0.584657, acc.: 69.53%] [G loss: 1.045002]\n",
      "epoch:7 step:6947 [D loss: 0.641024, acc.: 61.72%] [G loss: 1.123772]\n",
      "epoch:7 step:6948 [D loss: 0.598006, acc.: 65.62%] [G loss: 1.058097]\n",
      "epoch:7 step:6949 [D loss: 0.700375, acc.: 60.94%] [G loss: 1.060088]\n",
      "epoch:7 step:6950 [D loss: 0.627122, acc.: 67.97%] [G loss: 0.950256]\n",
      "epoch:7 step:6951 [D loss: 0.597666, acc.: 64.06%] [G loss: 0.978144]\n",
      "epoch:7 step:6952 [D loss: 0.630018, acc.: 64.84%] [G loss: 1.066425]\n",
      "epoch:7 step:6953 [D loss: 0.564786, acc.: 72.66%] [G loss: 1.155711]\n",
      "epoch:7 step:6954 [D loss: 0.621309, acc.: 60.94%] [G loss: 0.912978]\n",
      "epoch:7 step:6955 [D loss: 0.566473, acc.: 70.31%] [G loss: 1.071427]\n",
      "epoch:7 step:6956 [D loss: 0.698090, acc.: 56.25%] [G loss: 1.034998]\n",
      "epoch:7 step:6957 [D loss: 0.635947, acc.: 62.50%] [G loss: 0.984555]\n",
      "epoch:7 step:6958 [D loss: 0.636702, acc.: 64.84%] [G loss: 1.053944]\n",
      "epoch:7 step:6959 [D loss: 0.565378, acc.: 72.66%] [G loss: 1.048916]\n",
      "epoch:7 step:6960 [D loss: 0.580876, acc.: 66.41%] [G loss: 1.136775]\n",
      "epoch:7 step:6961 [D loss: 0.570883, acc.: 75.78%] [G loss: 1.175786]\n",
      "epoch:7 step:6962 [D loss: 0.628091, acc.: 59.38%] [G loss: 1.017780]\n",
      "epoch:7 step:6963 [D loss: 0.654053, acc.: 61.72%] [G loss: 0.998457]\n",
      "epoch:7 step:6964 [D loss: 0.533004, acc.: 73.44%] [G loss: 1.249834]\n",
      "epoch:7 step:6965 [D loss: 0.611023, acc.: 67.19%] [G loss: 1.154291]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:7 step:6966 [D loss: 0.664807, acc.: 60.16%] [G loss: 1.121642]\n",
      "epoch:7 step:6967 [D loss: 0.684941, acc.: 56.25%] [G loss: 1.046417]\n",
      "epoch:7 step:6968 [D loss: 0.591668, acc.: 71.09%] [G loss: 1.302474]\n",
      "epoch:7 step:6969 [D loss: 0.724471, acc.: 53.91%] [G loss: 1.035433]\n",
      "epoch:7 step:6970 [D loss: 0.574301, acc.: 75.78%] [G loss: 1.139710]\n",
      "epoch:7 step:6971 [D loss: 0.646000, acc.: 60.94%] [G loss: 1.049172]\n",
      "epoch:7 step:6972 [D loss: 0.577702, acc.: 70.31%] [G loss: 1.153209]\n",
      "epoch:7 step:6973 [D loss: 0.587363, acc.: 69.53%] [G loss: 1.231877]\n",
      "epoch:7 step:6974 [D loss: 0.530079, acc.: 77.34%] [G loss: 1.127977]\n",
      "epoch:7 step:6975 [D loss: 0.632754, acc.: 62.50%] [G loss: 0.873786]\n",
      "epoch:7 step:6976 [D loss: 0.597731, acc.: 66.41%] [G loss: 1.100286]\n",
      "epoch:7 step:6977 [D loss: 0.671229, acc.: 55.47%] [G loss: 0.985942]\n",
      "epoch:7 step:6978 [D loss: 0.548712, acc.: 72.66%] [G loss: 1.207271]\n",
      "epoch:7 step:6979 [D loss: 0.587897, acc.: 67.19%] [G loss: 0.981137]\n",
      "epoch:7 step:6980 [D loss: 0.604632, acc.: 68.75%] [G loss: 1.030797]\n",
      "epoch:7 step:6981 [D loss: 0.667061, acc.: 63.28%] [G loss: 0.973306]\n",
      "epoch:7 step:6982 [D loss: 0.569001, acc.: 75.00%] [G loss: 1.089798]\n",
      "epoch:7 step:6983 [D loss: 0.624981, acc.: 66.41%] [G loss: 1.076680]\n",
      "epoch:7 step:6984 [D loss: 0.682699, acc.: 59.38%] [G loss: 1.056427]\n",
      "epoch:7 step:6985 [D loss: 0.640627, acc.: 64.84%] [G loss: 1.221389]\n",
      "epoch:7 step:6986 [D loss: 0.705588, acc.: 56.25%] [G loss: 0.971872]\n",
      "epoch:7 step:6987 [D loss: 0.576421, acc.: 73.44%] [G loss: 0.992330]\n",
      "epoch:7 step:6988 [D loss: 0.636422, acc.: 57.81%] [G loss: 0.950737]\n",
      "epoch:7 step:6989 [D loss: 0.706104, acc.: 53.91%] [G loss: 0.986203]\n",
      "epoch:7 step:6990 [D loss: 0.670217, acc.: 57.03%] [G loss: 1.093269]\n",
      "epoch:7 step:6991 [D loss: 0.557651, acc.: 71.88%] [G loss: 1.071693]\n",
      "epoch:7 step:6992 [D loss: 0.664567, acc.: 64.84%] [G loss: 1.119433]\n",
      "epoch:7 step:6993 [D loss: 0.778928, acc.: 47.66%] [G loss: 1.100887]\n",
      "epoch:7 step:6994 [D loss: 0.637927, acc.: 66.41%] [G loss: 1.056892]\n",
      "epoch:7 step:6995 [D loss: 0.558215, acc.: 71.09%] [G loss: 1.182458]\n",
      "epoch:7 step:6996 [D loss: 0.817305, acc.: 46.09%] [G loss: 1.141499]\n",
      "epoch:7 step:6997 [D loss: 0.639827, acc.: 60.16%] [G loss: 1.129552]\n",
      "epoch:7 step:6998 [D loss: 0.534973, acc.: 77.34%] [G loss: 1.020090]\n",
      "epoch:7 step:6999 [D loss: 0.732568, acc.: 51.56%] [G loss: 1.022287]\n",
      "epoch:7 step:7000 [D loss: 0.563696, acc.: 69.53%] [G loss: 1.137610]\n",
      "epoch:7 step:7001 [D loss: 0.666539, acc.: 62.50%] [G loss: 1.009269]\n",
      "epoch:7 step:7002 [D loss: 0.560597, acc.: 75.00%] [G loss: 1.212520]\n",
      "epoch:7 step:7003 [D loss: 0.609265, acc.: 63.28%] [G loss: 1.074719]\n",
      "epoch:7 step:7004 [D loss: 0.530967, acc.: 75.78%] [G loss: 1.076855]\n",
      "epoch:7 step:7005 [D loss: 0.677401, acc.: 56.25%] [G loss: 1.140381]\n",
      "epoch:7 step:7006 [D loss: 0.576452, acc.: 71.88%] [G loss: 1.025992]\n",
      "epoch:7 step:7007 [D loss: 0.623578, acc.: 61.72%] [G loss: 1.201866]\n",
      "epoch:7 step:7008 [D loss: 0.613511, acc.: 70.31%] [G loss: 1.101625]\n",
      "epoch:7 step:7009 [D loss: 0.545936, acc.: 71.88%] [G loss: 1.133388]\n",
      "epoch:7 step:7010 [D loss: 0.594760, acc.: 66.41%] [G loss: 0.945076]\n",
      "epoch:7 step:7011 [D loss: 0.668812, acc.: 65.62%] [G loss: 1.174980]\n",
      "epoch:7 step:7012 [D loss: 0.598140, acc.: 66.41%] [G loss: 1.026482]\n",
      "epoch:7 step:7013 [D loss: 0.601370, acc.: 66.41%] [G loss: 1.073666]\n",
      "epoch:7 step:7014 [D loss: 0.594711, acc.: 69.53%] [G loss: 1.137153]\n",
      "epoch:7 step:7015 [D loss: 0.727852, acc.: 50.78%] [G loss: 0.982329]\n",
      "epoch:7 step:7016 [D loss: 0.611734, acc.: 65.62%] [G loss: 1.063254]\n",
      "epoch:7 step:7017 [D loss: 0.648313, acc.: 63.28%] [G loss: 1.081097]\n",
      "epoch:7 step:7018 [D loss: 0.645573, acc.: 66.41%] [G loss: 1.020028]\n",
      "epoch:7 step:7019 [D loss: 0.581109, acc.: 68.75%] [G loss: 0.974620]\n",
      "epoch:7 step:7020 [D loss: 0.670310, acc.: 57.81%] [G loss: 1.024941]\n",
      "epoch:7 step:7021 [D loss: 0.622595, acc.: 64.06%] [G loss: 1.061168]\n",
      "epoch:7 step:7022 [D loss: 0.701201, acc.: 49.22%] [G loss: 1.086096]\n",
      "epoch:7 step:7023 [D loss: 0.565815, acc.: 72.66%] [G loss: 1.035191]\n",
      "epoch:7 step:7024 [D loss: 0.659668, acc.: 58.59%] [G loss: 1.048874]\n",
      "epoch:7 step:7025 [D loss: 0.647583, acc.: 60.16%] [G loss: 0.988425]\n",
      "epoch:7 step:7026 [D loss: 0.650077, acc.: 58.59%] [G loss: 1.005739]\n",
      "epoch:7 step:7027 [D loss: 0.567668, acc.: 73.44%] [G loss: 1.114828]\n",
      "epoch:7 step:7028 [D loss: 0.606634, acc.: 65.62%] [G loss: 1.068591]\n",
      "epoch:7 step:7029 [D loss: 0.662525, acc.: 62.50%] [G loss: 1.116155]\n",
      "epoch:7 step:7030 [D loss: 0.636962, acc.: 64.84%] [G loss: 1.023861]\n",
      "epoch:7 step:7031 [D loss: 0.572810, acc.: 74.22%] [G loss: 0.983034]\n",
      "epoch:7 step:7032 [D loss: 0.513764, acc.: 79.69%] [G loss: 1.024602]\n",
      "epoch:7 step:7033 [D loss: 0.595404, acc.: 71.09%] [G loss: 1.223455]\n",
      "epoch:7 step:7034 [D loss: 0.604842, acc.: 68.75%] [G loss: 1.160009]\n",
      "epoch:7 step:7035 [D loss: 0.564307, acc.: 72.66%] [G loss: 1.264167]\n",
      "epoch:7 step:7036 [D loss: 0.702477, acc.: 56.25%] [G loss: 1.091379]\n",
      "epoch:7 step:7037 [D loss: 0.584520, acc.: 71.09%] [G loss: 1.052082]\n",
      "epoch:7 step:7038 [D loss: 0.541074, acc.: 72.66%] [G loss: 1.150286]\n",
      "epoch:7 step:7039 [D loss: 0.711085, acc.: 50.78%] [G loss: 1.024183]\n",
      "epoch:7 step:7040 [D loss: 0.709147, acc.: 57.81%] [G loss: 0.979722]\n",
      "epoch:7 step:7041 [D loss: 0.578711, acc.: 69.53%] [G loss: 1.112200]\n",
      "epoch:7 step:7042 [D loss: 0.745798, acc.: 50.00%] [G loss: 1.069176]\n",
      "epoch:7 step:7043 [D loss: 0.593204, acc.: 71.88%] [G loss: 1.161596]\n",
      "epoch:7 step:7044 [D loss: 0.568449, acc.: 72.66%] [G loss: 1.222503]\n",
      "epoch:7 step:7045 [D loss: 0.622008, acc.: 64.06%] [G loss: 1.052610]\n",
      "epoch:7 step:7046 [D loss: 0.593756, acc.: 65.62%] [G loss: 1.210305]\n",
      "epoch:7 step:7047 [D loss: 0.602963, acc.: 66.41%] [G loss: 1.016080]\n",
      "epoch:7 step:7048 [D loss: 0.632689, acc.: 63.28%] [G loss: 0.937021]\n",
      "epoch:7 step:7049 [D loss: 0.575270, acc.: 71.88%] [G loss: 1.288227]\n",
      "epoch:7 step:7050 [D loss: 0.611150, acc.: 67.97%] [G loss: 0.958471]\n",
      "epoch:7 step:7051 [D loss: 0.687561, acc.: 61.72%] [G loss: 1.160422]\n",
      "epoch:7 step:7052 [D loss: 0.590715, acc.: 69.53%] [G loss: 1.009223]\n",
      "epoch:7 step:7053 [D loss: 0.640503, acc.: 70.31%] [G loss: 1.085387]\n",
      "epoch:7 step:7054 [D loss: 0.666194, acc.: 63.28%] [G loss: 0.918843]\n",
      "epoch:7 step:7055 [D loss: 0.647034, acc.: 62.50%] [G loss: 1.260952]\n",
      "epoch:7 step:7056 [D loss: 0.676071, acc.: 62.50%] [G loss: 1.209803]\n",
      "epoch:7 step:7057 [D loss: 0.580331, acc.: 71.88%] [G loss: 0.914257]\n",
      "epoch:7 step:7058 [D loss: 0.633696, acc.: 64.06%] [G loss: 1.105511]\n",
      "epoch:7 step:7059 [D loss: 0.654689, acc.: 63.28%] [G loss: 1.073965]\n",
      "epoch:7 step:7060 [D loss: 0.614157, acc.: 64.84%] [G loss: 1.049164]\n",
      "epoch:7 step:7061 [D loss: 0.494539, acc.: 82.81%] [G loss: 1.228715]\n",
      "epoch:7 step:7062 [D loss: 0.682473, acc.: 60.94%] [G loss: 0.939328]\n",
      "epoch:7 step:7063 [D loss: 0.581580, acc.: 75.78%] [G loss: 1.044956]\n",
      "epoch:7 step:7064 [D loss: 0.647479, acc.: 66.41%] [G loss: 1.056061]\n",
      "epoch:7 step:7065 [D loss: 0.581127, acc.: 71.88%] [G loss: 1.006866]\n",
      "epoch:7 step:7066 [D loss: 0.586784, acc.: 67.97%] [G loss: 1.088414]\n",
      "epoch:7 step:7067 [D loss: 0.617793, acc.: 69.53%] [G loss: 1.122199]\n",
      "epoch:7 step:7068 [D loss: 0.627368, acc.: 64.06%] [G loss: 1.080427]\n",
      "epoch:7 step:7069 [D loss: 0.638924, acc.: 63.28%] [G loss: 0.976713]\n",
      "epoch:7 step:7070 [D loss: 0.612785, acc.: 64.84%] [G loss: 1.071890]\n",
      "epoch:7 step:7071 [D loss: 0.618204, acc.: 68.75%] [G loss: 1.206124]\n",
      "epoch:7 step:7072 [D loss: 0.635308, acc.: 66.41%] [G loss: 1.084013]\n",
      "epoch:7 step:7073 [D loss: 0.620790, acc.: 67.97%] [G loss: 1.140200]\n",
      "epoch:7 step:7074 [D loss: 0.639933, acc.: 60.94%] [G loss: 1.107645]\n",
      "epoch:7 step:7075 [D loss: 0.600732, acc.: 70.31%] [G loss: 1.202572]\n",
      "epoch:7 step:7076 [D loss: 0.587600, acc.: 69.53%] [G loss: 1.109033]\n",
      "epoch:7 step:7077 [D loss: 0.730223, acc.: 51.56%] [G loss: 0.949534]\n",
      "epoch:7 step:7078 [D loss: 0.649986, acc.: 60.16%] [G loss: 0.969150]\n",
      "epoch:7 step:7079 [D loss: 0.640334, acc.: 60.94%] [G loss: 0.961034]\n",
      "epoch:7 step:7080 [D loss: 0.723600, acc.: 57.03%] [G loss: 1.043665]\n",
      "epoch:7 step:7081 [D loss: 0.624139, acc.: 66.41%] [G loss: 1.084792]\n",
      "epoch:7 step:7082 [D loss: 0.513472, acc.: 78.91%] [G loss: 1.057107]\n",
      "epoch:7 step:7083 [D loss: 0.601020, acc.: 67.97%] [G loss: 1.092522]\n",
      "epoch:7 step:7084 [D loss: 0.653076, acc.: 59.38%] [G loss: 1.163564]\n",
      "epoch:7 step:7085 [D loss: 0.703776, acc.: 52.34%] [G loss: 1.016132]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:7 step:7086 [D loss: 0.668569, acc.: 53.91%] [G loss: 1.057215]\n",
      "epoch:7 step:7087 [D loss: 0.585292, acc.: 72.66%] [G loss: 1.078551]\n",
      "epoch:7 step:7088 [D loss: 0.602332, acc.: 71.88%] [G loss: 0.955171]\n",
      "epoch:7 step:7089 [D loss: 0.667853, acc.: 62.50%] [G loss: 0.935726]\n",
      "epoch:7 step:7090 [D loss: 0.652287, acc.: 59.38%] [G loss: 1.063159]\n",
      "epoch:7 step:7091 [D loss: 0.713958, acc.: 50.78%] [G loss: 0.979396]\n",
      "epoch:7 step:7092 [D loss: 0.635023, acc.: 61.72%] [G loss: 0.885917]\n",
      "epoch:7 step:7093 [D loss: 0.602084, acc.: 69.53%] [G loss: 0.949416]\n",
      "epoch:7 step:7094 [D loss: 0.636344, acc.: 64.84%] [G loss: 1.081412]\n",
      "epoch:7 step:7095 [D loss: 0.677126, acc.: 57.03%] [G loss: 0.983507]\n",
      "epoch:7 step:7096 [D loss: 0.667194, acc.: 59.38%] [G loss: 1.092906]\n",
      "epoch:7 step:7097 [D loss: 0.653927, acc.: 64.06%] [G loss: 1.117759]\n",
      "epoch:7 step:7098 [D loss: 0.601781, acc.: 69.53%] [G loss: 1.043148]\n",
      "epoch:7 step:7099 [D loss: 0.601981, acc.: 69.53%] [G loss: 1.073440]\n",
      "epoch:7 step:7100 [D loss: 0.563345, acc.: 74.22%] [G loss: 1.066568]\n",
      "epoch:7 step:7101 [D loss: 0.580560, acc.: 70.31%] [G loss: 1.211982]\n",
      "epoch:7 step:7102 [D loss: 0.625176, acc.: 64.06%] [G loss: 0.991217]\n",
      "epoch:7 step:7103 [D loss: 0.680408, acc.: 54.69%] [G loss: 1.026232]\n",
      "epoch:7 step:7104 [D loss: 0.669506, acc.: 53.91%] [G loss: 1.202180]\n",
      "epoch:7 step:7105 [D loss: 0.617034, acc.: 64.84%] [G loss: 1.199494]\n",
      "epoch:7 step:7106 [D loss: 0.689513, acc.: 60.16%] [G loss: 1.094084]\n",
      "epoch:7 step:7107 [D loss: 0.602252, acc.: 65.62%] [G loss: 1.200011]\n",
      "epoch:7 step:7108 [D loss: 0.639884, acc.: 64.84%] [G loss: 0.964954]\n",
      "epoch:7 step:7109 [D loss: 0.656763, acc.: 60.94%] [G loss: 1.013962]\n",
      "epoch:7 step:7110 [D loss: 0.636926, acc.: 67.19%] [G loss: 0.894299]\n",
      "epoch:7 step:7111 [D loss: 0.602160, acc.: 67.97%] [G loss: 1.215185]\n",
      "epoch:7 step:7112 [D loss: 0.647607, acc.: 66.41%] [G loss: 0.869656]\n",
      "epoch:7 step:7113 [D loss: 0.617606, acc.: 64.84%] [G loss: 1.141511]\n",
      "epoch:7 step:7114 [D loss: 0.577548, acc.: 67.19%] [G loss: 0.951076]\n",
      "epoch:7 step:7115 [D loss: 0.666979, acc.: 61.72%] [G loss: 0.973383]\n",
      "epoch:7 step:7116 [D loss: 0.550840, acc.: 74.22%] [G loss: 1.061467]\n",
      "epoch:7 step:7117 [D loss: 0.676656, acc.: 55.47%] [G loss: 1.081409]\n",
      "epoch:7 step:7118 [D loss: 0.596793, acc.: 67.97%] [G loss: 1.069006]\n",
      "epoch:7 step:7119 [D loss: 0.654080, acc.: 60.16%] [G loss: 1.120139]\n",
      "epoch:7 step:7120 [D loss: 0.649781, acc.: 60.94%] [G loss: 0.998891]\n",
      "epoch:7 step:7121 [D loss: 0.683914, acc.: 62.50%] [G loss: 1.088963]\n",
      "epoch:7 step:7122 [D loss: 0.624317, acc.: 64.06%] [G loss: 1.260954]\n",
      "epoch:7 step:7123 [D loss: 0.565243, acc.: 71.09%] [G loss: 1.191404]\n",
      "epoch:7 step:7124 [D loss: 0.589573, acc.: 67.97%] [G loss: 1.143577]\n",
      "epoch:7 step:7125 [D loss: 0.617004, acc.: 71.88%] [G loss: 1.093228]\n",
      "epoch:7 step:7126 [D loss: 0.573244, acc.: 71.09%] [G loss: 1.000662]\n",
      "epoch:7 step:7127 [D loss: 0.741676, acc.: 49.22%] [G loss: 0.862457]\n",
      "epoch:7 step:7128 [D loss: 0.616600, acc.: 67.97%] [G loss: 0.853524]\n",
      "epoch:7 step:7129 [D loss: 0.683989, acc.: 57.81%] [G loss: 1.163643]\n",
      "epoch:7 step:7130 [D loss: 0.597362, acc.: 70.31%] [G loss: 0.925003]\n",
      "epoch:7 step:7131 [D loss: 0.593021, acc.: 64.84%] [G loss: 1.088290]\n",
      "epoch:7 step:7132 [D loss: 0.639899, acc.: 63.28%] [G loss: 1.015530]\n",
      "epoch:7 step:7133 [D loss: 0.616607, acc.: 63.28%] [G loss: 0.968799]\n",
      "epoch:7 step:7134 [D loss: 0.663426, acc.: 58.59%] [G loss: 1.009283]\n",
      "epoch:7 step:7135 [D loss: 0.532397, acc.: 75.00%] [G loss: 1.100703]\n",
      "epoch:7 step:7136 [D loss: 0.711527, acc.: 53.12%] [G loss: 1.021335]\n",
      "epoch:7 step:7137 [D loss: 0.622275, acc.: 66.41%] [G loss: 1.051218]\n",
      "epoch:7 step:7138 [D loss: 0.651392, acc.: 60.94%] [G loss: 1.107171]\n",
      "epoch:7 step:7139 [D loss: 0.533072, acc.: 78.12%] [G loss: 1.156327]\n",
      "epoch:7 step:7140 [D loss: 0.572836, acc.: 65.62%] [G loss: 1.166194]\n",
      "epoch:7 step:7141 [D loss: 0.603474, acc.: 64.06%] [G loss: 0.996851]\n",
      "epoch:7 step:7142 [D loss: 0.624517, acc.: 64.84%] [G loss: 1.131355]\n",
      "epoch:7 step:7143 [D loss: 0.558923, acc.: 77.34%] [G loss: 1.151977]\n",
      "epoch:7 step:7144 [D loss: 0.667261, acc.: 64.84%] [G loss: 1.036555]\n",
      "epoch:7 step:7145 [D loss: 0.611347, acc.: 66.41%] [G loss: 1.144314]\n",
      "epoch:7 step:7146 [D loss: 0.624874, acc.: 68.75%] [G loss: 1.117559]\n",
      "epoch:7 step:7147 [D loss: 0.723156, acc.: 56.25%] [G loss: 0.991109]\n",
      "epoch:7 step:7148 [D loss: 0.582539, acc.: 67.97%] [G loss: 0.972022]\n",
      "epoch:7 step:7149 [D loss: 0.634617, acc.: 62.50%] [G loss: 0.994442]\n",
      "epoch:7 step:7150 [D loss: 0.629340, acc.: 64.84%] [G loss: 1.136977]\n",
      "epoch:7 step:7151 [D loss: 0.627653, acc.: 64.84%] [G loss: 1.193865]\n",
      "epoch:7 step:7152 [D loss: 0.681136, acc.: 56.25%] [G loss: 0.967756]\n",
      "epoch:7 step:7153 [D loss: 0.573058, acc.: 70.31%] [G loss: 1.073011]\n",
      "epoch:7 step:7154 [D loss: 0.607277, acc.: 66.41%] [G loss: 1.033738]\n",
      "epoch:7 step:7155 [D loss: 0.573218, acc.: 70.31%] [G loss: 0.916533]\n",
      "epoch:7 step:7156 [D loss: 0.580713, acc.: 71.09%] [G loss: 1.179308]\n",
      "epoch:7 step:7157 [D loss: 0.607944, acc.: 67.97%] [G loss: 1.160890]\n",
      "epoch:7 step:7158 [D loss: 0.643362, acc.: 65.62%] [G loss: 1.121000]\n",
      "epoch:7 step:7159 [D loss: 0.615134, acc.: 70.31%] [G loss: 0.988644]\n",
      "epoch:7 step:7160 [D loss: 0.797035, acc.: 50.78%] [G loss: 1.100730]\n",
      "epoch:7 step:7161 [D loss: 0.517365, acc.: 75.78%] [G loss: 1.093528]\n",
      "epoch:7 step:7162 [D loss: 0.590765, acc.: 64.06%] [G loss: 1.216788]\n",
      "epoch:7 step:7163 [D loss: 0.674222, acc.: 56.25%] [G loss: 1.032144]\n",
      "epoch:7 step:7164 [D loss: 0.669069, acc.: 67.19%] [G loss: 1.032372]\n",
      "epoch:7 step:7165 [D loss: 0.649539, acc.: 60.16%] [G loss: 1.083566]\n",
      "epoch:7 step:7166 [D loss: 0.538510, acc.: 74.22%] [G loss: 1.226036]\n",
      "epoch:7 step:7167 [D loss: 0.596061, acc.: 71.09%] [G loss: 1.138759]\n",
      "epoch:7 step:7168 [D loss: 0.697068, acc.: 58.59%] [G loss: 1.123882]\n",
      "epoch:7 step:7169 [D loss: 0.647096, acc.: 60.16%] [G loss: 1.089524]\n",
      "epoch:7 step:7170 [D loss: 0.710131, acc.: 53.12%] [G loss: 1.120415]\n",
      "epoch:7 step:7171 [D loss: 0.601568, acc.: 65.62%] [G loss: 1.099999]\n",
      "epoch:7 step:7172 [D loss: 0.531850, acc.: 76.56%] [G loss: 1.142593]\n",
      "epoch:7 step:7173 [D loss: 0.630344, acc.: 68.75%] [G loss: 1.073380]\n",
      "epoch:7 step:7174 [D loss: 0.629846, acc.: 64.06%] [G loss: 0.877114]\n",
      "epoch:7 step:7175 [D loss: 0.560241, acc.: 75.00%] [G loss: 1.030353]\n",
      "epoch:7 step:7176 [D loss: 0.692358, acc.: 62.50%] [G loss: 1.175338]\n",
      "epoch:7 step:7177 [D loss: 0.598505, acc.: 66.41%] [G loss: 1.123651]\n",
      "epoch:7 step:7178 [D loss: 0.630165, acc.: 66.41%] [G loss: 0.960030]\n",
      "epoch:7 step:7179 [D loss: 0.741243, acc.: 51.56%] [G loss: 1.062591]\n",
      "epoch:7 step:7180 [D loss: 0.640256, acc.: 61.72%] [G loss: 1.066379]\n",
      "epoch:7 step:7181 [D loss: 0.670755, acc.: 63.28%] [G loss: 1.005829]\n",
      "epoch:7 step:7182 [D loss: 0.634324, acc.: 64.84%] [G loss: 1.078908]\n",
      "epoch:7 step:7183 [D loss: 0.673046, acc.: 64.84%] [G loss: 1.152677]\n",
      "epoch:7 step:7184 [D loss: 0.546826, acc.: 74.22%] [G loss: 1.064053]\n",
      "epoch:7 step:7185 [D loss: 0.588993, acc.: 64.06%] [G loss: 1.159775]\n",
      "epoch:7 step:7186 [D loss: 0.608424, acc.: 64.84%] [G loss: 1.058157]\n",
      "epoch:7 step:7187 [D loss: 0.724787, acc.: 55.47%] [G loss: 0.984754]\n",
      "epoch:7 step:7188 [D loss: 0.656234, acc.: 59.38%] [G loss: 1.087019]\n",
      "epoch:7 step:7189 [D loss: 0.732753, acc.: 50.00%] [G loss: 0.949776]\n",
      "epoch:7 step:7190 [D loss: 0.613521, acc.: 64.84%] [G loss: 1.069861]\n",
      "epoch:7 step:7191 [D loss: 0.637210, acc.: 60.94%] [G loss: 1.031773]\n",
      "epoch:7 step:7192 [D loss: 0.666848, acc.: 55.47%] [G loss: 1.150951]\n",
      "epoch:7 step:7193 [D loss: 0.667222, acc.: 60.94%] [G loss: 1.093289]\n",
      "epoch:7 step:7194 [D loss: 0.664090, acc.: 60.94%] [G loss: 1.032472]\n",
      "epoch:7 step:7195 [D loss: 0.629421, acc.: 63.28%] [G loss: 1.168684]\n",
      "epoch:7 step:7196 [D loss: 0.632920, acc.: 60.16%] [G loss: 1.174766]\n",
      "epoch:7 step:7197 [D loss: 0.585095, acc.: 66.41%] [G loss: 1.081042]\n",
      "epoch:7 step:7198 [D loss: 0.685985, acc.: 57.81%] [G loss: 0.931392]\n",
      "epoch:7 step:7199 [D loss: 0.648017, acc.: 61.72%] [G loss: 1.045156]\n",
      "epoch:7 step:7200 [D loss: 0.577090, acc.: 67.19%] [G loss: 1.167222]\n",
      "epoch:7 step:7201 [D loss: 0.651227, acc.: 64.84%] [G loss: 0.940206]\n",
      "epoch:7 step:7202 [D loss: 0.646918, acc.: 60.16%] [G loss: 1.041262]\n",
      "epoch:7 step:7203 [D loss: 0.596660, acc.: 73.44%] [G loss: 1.081813]\n",
      "epoch:7 step:7204 [D loss: 0.694988, acc.: 56.25%] [G loss: 0.947059]\n",
      "epoch:7 step:7205 [D loss: 0.574821, acc.: 69.53%] [G loss: 1.111645]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:7 step:7206 [D loss: 0.638835, acc.: 65.62%] [G loss: 1.052370]\n",
      "epoch:7 step:7207 [D loss: 0.619549, acc.: 63.28%] [G loss: 1.282907]\n",
      "epoch:7 step:7208 [D loss: 0.604455, acc.: 67.19%] [G loss: 1.168145]\n",
      "epoch:7 step:7209 [D loss: 0.579758, acc.: 71.09%] [G loss: 1.007757]\n",
      "epoch:7 step:7210 [D loss: 0.603202, acc.: 69.53%] [G loss: 1.094371]\n",
      "epoch:7 step:7211 [D loss: 0.595183, acc.: 62.50%] [G loss: 0.989541]\n",
      "epoch:7 step:7212 [D loss: 0.613249, acc.: 67.19%] [G loss: 1.121168]\n",
      "epoch:7 step:7213 [D loss: 0.637394, acc.: 64.06%] [G loss: 1.157659]\n",
      "epoch:7 step:7214 [D loss: 0.663035, acc.: 62.50%] [G loss: 1.150328]\n",
      "epoch:7 step:7215 [D loss: 0.581118, acc.: 73.44%] [G loss: 0.960931]\n",
      "epoch:7 step:7216 [D loss: 0.588774, acc.: 66.41%] [G loss: 1.104507]\n",
      "epoch:7 step:7217 [D loss: 0.628952, acc.: 65.62%] [G loss: 0.963481]\n",
      "epoch:7 step:7218 [D loss: 0.569763, acc.: 69.53%] [G loss: 1.178171]\n",
      "epoch:7 step:7219 [D loss: 0.616744, acc.: 65.62%] [G loss: 0.909079]\n",
      "epoch:7 step:7220 [D loss: 0.648662, acc.: 60.16%] [G loss: 1.070140]\n",
      "epoch:7 step:7221 [D loss: 0.665208, acc.: 57.81%] [G loss: 1.093765]\n",
      "epoch:7 step:7222 [D loss: 0.659357, acc.: 66.41%] [G loss: 1.145196]\n",
      "epoch:7 step:7223 [D loss: 0.704732, acc.: 52.34%] [G loss: 1.155101]\n",
      "epoch:7 step:7224 [D loss: 0.658953, acc.: 62.50%] [G loss: 0.982690]\n",
      "epoch:7 step:7225 [D loss: 0.575252, acc.: 65.62%] [G loss: 1.144249]\n",
      "epoch:7 step:7226 [D loss: 0.608557, acc.: 64.84%] [G loss: 1.043118]\n",
      "epoch:7 step:7227 [D loss: 0.589319, acc.: 67.19%] [G loss: 1.266139]\n",
      "epoch:7 step:7228 [D loss: 0.624313, acc.: 65.62%] [G loss: 1.096642]\n",
      "epoch:7 step:7229 [D loss: 0.514469, acc.: 78.12%] [G loss: 1.226797]\n",
      "epoch:7 step:7230 [D loss: 0.651145, acc.: 60.94%] [G loss: 1.050345]\n",
      "epoch:7 step:7231 [D loss: 0.577941, acc.: 73.44%] [G loss: 0.978694]\n",
      "epoch:7 step:7232 [D loss: 0.608179, acc.: 65.62%] [G loss: 0.920218]\n",
      "epoch:7 step:7233 [D loss: 0.565502, acc.: 72.66%] [G loss: 1.004570]\n",
      "epoch:7 step:7234 [D loss: 0.617304, acc.: 69.53%] [G loss: 1.214934]\n",
      "epoch:7 step:7235 [D loss: 0.575505, acc.: 75.78%] [G loss: 0.985053]\n",
      "epoch:7 step:7236 [D loss: 0.644404, acc.: 63.28%] [G loss: 1.059798]\n",
      "epoch:7 step:7237 [D loss: 0.551378, acc.: 75.78%] [G loss: 1.301641]\n",
      "epoch:7 step:7238 [D loss: 0.633786, acc.: 63.28%] [G loss: 1.048238]\n",
      "epoch:7 step:7239 [D loss: 0.630626, acc.: 65.62%] [G loss: 1.212752]\n",
      "epoch:7 step:7240 [D loss: 0.595837, acc.: 67.97%] [G loss: 1.265404]\n",
      "epoch:7 step:7241 [D loss: 0.645600, acc.: 65.62%] [G loss: 1.239506]\n",
      "epoch:7 step:7242 [D loss: 0.658309, acc.: 64.84%] [G loss: 1.031384]\n",
      "epoch:7 step:7243 [D loss: 0.629202, acc.: 62.50%] [G loss: 1.102080]\n",
      "epoch:7 step:7244 [D loss: 0.671372, acc.: 60.94%] [G loss: 0.963333]\n",
      "epoch:7 step:7245 [D loss: 0.544077, acc.: 78.12%] [G loss: 1.063696]\n",
      "epoch:7 step:7246 [D loss: 0.591338, acc.: 63.28%] [G loss: 1.155841]\n",
      "epoch:7 step:7247 [D loss: 0.626523, acc.: 64.06%] [G loss: 1.125555]\n",
      "epoch:7 step:7248 [D loss: 0.676959, acc.: 59.38%] [G loss: 1.026760]\n",
      "epoch:7 step:7249 [D loss: 0.660426, acc.: 61.72%] [G loss: 0.955802]\n",
      "epoch:7 step:7250 [D loss: 0.630863, acc.: 65.62%] [G loss: 1.060179]\n",
      "epoch:7 step:7251 [D loss: 0.573735, acc.: 71.09%] [G loss: 1.217190]\n",
      "epoch:7 step:7252 [D loss: 0.657495, acc.: 62.50%] [G loss: 1.099716]\n",
      "epoch:7 step:7253 [D loss: 0.661406, acc.: 64.06%] [G loss: 0.975494]\n",
      "epoch:7 step:7254 [D loss: 0.685426, acc.: 58.59%] [G loss: 0.979245]\n",
      "epoch:7 step:7255 [D loss: 0.704746, acc.: 54.69%] [G loss: 1.008013]\n",
      "epoch:7 step:7256 [D loss: 0.606136, acc.: 66.41%] [G loss: 1.131194]\n",
      "epoch:7 step:7257 [D loss: 0.630991, acc.: 65.62%] [G loss: 1.055732]\n",
      "epoch:7 step:7258 [D loss: 0.690961, acc.: 60.94%] [G loss: 1.094204]\n",
      "epoch:7 step:7259 [D loss: 0.637969, acc.: 63.28%] [G loss: 1.071960]\n",
      "epoch:7 step:7260 [D loss: 0.643219, acc.: 65.62%] [G loss: 1.064391]\n",
      "epoch:7 step:7261 [D loss: 0.550353, acc.: 75.00%] [G loss: 1.274129]\n",
      "epoch:7 step:7262 [D loss: 0.653331, acc.: 60.16%] [G loss: 1.206810]\n",
      "epoch:7 step:7263 [D loss: 0.681971, acc.: 58.59%] [G loss: 1.067766]\n",
      "epoch:7 step:7264 [D loss: 0.604056, acc.: 67.19%] [G loss: 1.059970]\n",
      "epoch:7 step:7265 [D loss: 0.627172, acc.: 61.72%] [G loss: 1.160318]\n",
      "epoch:7 step:7266 [D loss: 0.571714, acc.: 71.88%] [G loss: 1.249933]\n",
      "epoch:7 step:7267 [D loss: 0.658990, acc.: 57.81%] [G loss: 1.178142]\n",
      "epoch:7 step:7268 [D loss: 0.623019, acc.: 65.62%] [G loss: 1.197615]\n",
      "epoch:7 step:7269 [D loss: 0.564966, acc.: 73.44%] [G loss: 1.121338]\n",
      "epoch:7 step:7270 [D loss: 0.569128, acc.: 73.44%] [G loss: 0.959278]\n",
      "epoch:7 step:7271 [D loss: 0.566487, acc.: 67.97%] [G loss: 1.040912]\n",
      "epoch:7 step:7272 [D loss: 0.575377, acc.: 67.19%] [G loss: 1.013822]\n",
      "epoch:7 step:7273 [D loss: 0.742905, acc.: 51.56%] [G loss: 1.045355]\n",
      "epoch:7 step:7274 [D loss: 0.628477, acc.: 64.06%] [G loss: 0.921764]\n",
      "epoch:7 step:7275 [D loss: 0.513789, acc.: 76.56%] [G loss: 1.096236]\n",
      "epoch:7 step:7276 [D loss: 0.642755, acc.: 62.50%] [G loss: 1.133438]\n",
      "epoch:7 step:7277 [D loss: 0.560215, acc.: 71.09%] [G loss: 1.161387]\n",
      "epoch:7 step:7278 [D loss: 0.562999, acc.: 73.44%] [G loss: 1.326373]\n",
      "epoch:7 step:7279 [D loss: 0.686593, acc.: 58.59%] [G loss: 0.963849]\n",
      "epoch:7 step:7280 [D loss: 0.564399, acc.: 70.31%] [G loss: 1.150752]\n",
      "epoch:7 step:7281 [D loss: 0.703380, acc.: 53.12%] [G loss: 0.939985]\n",
      "epoch:7 step:7282 [D loss: 0.654795, acc.: 60.16%] [G loss: 1.041816]\n",
      "epoch:7 step:7283 [D loss: 0.596732, acc.: 65.62%] [G loss: 1.003542]\n",
      "epoch:7 step:7284 [D loss: 0.608430, acc.: 66.41%] [G loss: 1.232194]\n",
      "epoch:7 step:7285 [D loss: 0.648186, acc.: 62.50%] [G loss: 1.067847]\n",
      "epoch:7 step:7286 [D loss: 0.533301, acc.: 74.22%] [G loss: 1.198091]\n",
      "epoch:7 step:7287 [D loss: 0.626401, acc.: 64.84%] [G loss: 1.195278]\n",
      "epoch:7 step:7288 [D loss: 0.639916, acc.: 67.19%] [G loss: 1.144616]\n",
      "epoch:7 step:7289 [D loss: 0.695781, acc.: 55.47%] [G loss: 1.044266]\n",
      "epoch:7 step:7290 [D loss: 0.651054, acc.: 60.16%] [G loss: 0.937663]\n",
      "epoch:7 step:7291 [D loss: 0.649943, acc.: 61.72%] [G loss: 1.028502]\n",
      "epoch:7 step:7292 [D loss: 0.601193, acc.: 67.97%] [G loss: 1.122804]\n",
      "epoch:7 step:7293 [D loss: 0.554130, acc.: 71.09%] [G loss: 1.247114]\n",
      "epoch:7 step:7294 [D loss: 0.636957, acc.: 64.06%] [G loss: 0.962456]\n",
      "epoch:7 step:7295 [D loss: 0.683498, acc.: 57.03%] [G loss: 0.957805]\n",
      "epoch:7 step:7296 [D loss: 0.589368, acc.: 71.09%] [G loss: 0.995398]\n",
      "epoch:7 step:7297 [D loss: 0.682074, acc.: 59.38%] [G loss: 0.944715]\n",
      "epoch:7 step:7298 [D loss: 0.617361, acc.: 64.06%] [G loss: 1.211895]\n",
      "epoch:7 step:7299 [D loss: 0.624703, acc.: 64.06%] [G loss: 0.962053]\n",
      "epoch:7 step:7300 [D loss: 0.604297, acc.: 70.31%] [G loss: 0.891467]\n",
      "epoch:7 step:7301 [D loss: 0.619168, acc.: 67.19%] [G loss: 1.024373]\n",
      "epoch:7 step:7302 [D loss: 0.555424, acc.: 71.88%] [G loss: 1.348235]\n",
      "epoch:7 step:7303 [D loss: 0.602662, acc.: 67.19%] [G loss: 1.153815]\n",
      "epoch:7 step:7304 [D loss: 0.671766, acc.: 57.81%] [G loss: 1.011306]\n",
      "epoch:7 step:7305 [D loss: 0.583705, acc.: 67.19%] [G loss: 1.044166]\n",
      "epoch:7 step:7306 [D loss: 0.770212, acc.: 50.00%] [G loss: 0.973457]\n",
      "epoch:7 step:7307 [D loss: 0.543265, acc.: 71.88%] [G loss: 1.039401]\n",
      "epoch:7 step:7308 [D loss: 0.726279, acc.: 55.47%] [G loss: 0.968514]\n",
      "epoch:7 step:7309 [D loss: 0.658503, acc.: 57.03%] [G loss: 1.129746]\n",
      "epoch:7 step:7310 [D loss: 0.633970, acc.: 64.06%] [G loss: 1.007490]\n",
      "epoch:7 step:7311 [D loss: 0.650684, acc.: 60.16%] [G loss: 1.073155]\n",
      "epoch:7 step:7312 [D loss: 0.635404, acc.: 64.06%] [G loss: 1.134705]\n",
      "epoch:7 step:7313 [D loss: 0.633687, acc.: 64.06%] [G loss: 1.141301]\n",
      "epoch:7 step:7314 [D loss: 0.668233, acc.: 59.38%] [G loss: 0.976613]\n",
      "epoch:7 step:7315 [D loss: 0.600355, acc.: 67.19%] [G loss: 1.077994]\n",
      "epoch:7 step:7316 [D loss: 0.559065, acc.: 71.88%] [G loss: 1.198737]\n",
      "epoch:7 step:7317 [D loss: 0.604805, acc.: 65.62%] [G loss: 1.042937]\n",
      "epoch:7 step:7318 [D loss: 0.626494, acc.: 60.94%] [G loss: 1.072912]\n",
      "epoch:7 step:7319 [D loss: 0.590230, acc.: 71.09%] [G loss: 1.176455]\n",
      "epoch:7 step:7320 [D loss: 0.660214, acc.: 61.72%] [G loss: 0.971541]\n",
      "epoch:7 step:7321 [D loss: 0.678244, acc.: 62.50%] [G loss: 1.153306]\n",
      "epoch:7 step:7322 [D loss: 0.687402, acc.: 60.94%] [G loss: 0.916119]\n",
      "epoch:7 step:7323 [D loss: 0.599937, acc.: 69.53%] [G loss: 1.152898]\n",
      "epoch:7 step:7324 [D loss: 0.702297, acc.: 55.47%] [G loss: 0.983123]\n",
      "epoch:7 step:7325 [D loss: 0.707116, acc.: 56.25%] [G loss: 0.908877]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:7 step:7326 [D loss: 0.650977, acc.: 58.59%] [G loss: 1.061208]\n",
      "epoch:7 step:7327 [D loss: 0.607820, acc.: 66.41%] [G loss: 1.053145]\n",
      "epoch:7 step:7328 [D loss: 0.620078, acc.: 61.72%] [G loss: 1.133413]\n",
      "epoch:7 step:7329 [D loss: 0.624439, acc.: 67.19%] [G loss: 0.993621]\n",
      "epoch:7 step:7330 [D loss: 0.615549, acc.: 65.62%] [G loss: 1.131127]\n",
      "epoch:7 step:7331 [D loss: 0.524652, acc.: 78.91%] [G loss: 0.990449]\n",
      "epoch:7 step:7332 [D loss: 0.737175, acc.: 48.44%] [G loss: 1.035951]\n",
      "epoch:7 step:7333 [D loss: 0.564958, acc.: 69.53%] [G loss: 0.904086]\n",
      "epoch:7 step:7334 [D loss: 0.584040, acc.: 74.22%] [G loss: 0.977940]\n",
      "epoch:7 step:7335 [D loss: 0.644259, acc.: 61.72%] [G loss: 0.911194]\n",
      "epoch:7 step:7336 [D loss: 0.662509, acc.: 63.28%] [G loss: 1.047326]\n",
      "epoch:7 step:7337 [D loss: 0.656997, acc.: 64.06%] [G loss: 1.051209]\n",
      "epoch:7 step:7338 [D loss: 0.643103, acc.: 64.84%] [G loss: 1.033553]\n",
      "epoch:7 step:7339 [D loss: 0.667069, acc.: 57.81%] [G loss: 0.965244]\n",
      "epoch:7 step:7340 [D loss: 0.586851, acc.: 71.88%] [G loss: 0.903380]\n",
      "epoch:7 step:7341 [D loss: 0.658296, acc.: 57.81%] [G loss: 0.977345]\n",
      "epoch:7 step:7342 [D loss: 0.638188, acc.: 55.47%] [G loss: 0.935430]\n",
      "epoch:7 step:7343 [D loss: 0.642459, acc.: 60.16%] [G loss: 1.126808]\n",
      "epoch:7 step:7344 [D loss: 0.663161, acc.: 60.94%] [G loss: 0.923374]\n",
      "epoch:7 step:7345 [D loss: 0.741047, acc.: 50.78%] [G loss: 0.967888]\n",
      "epoch:7 step:7346 [D loss: 0.636101, acc.: 63.28%] [G loss: 1.053394]\n",
      "epoch:7 step:7347 [D loss: 0.571918, acc.: 71.09%] [G loss: 1.188216]\n",
      "epoch:7 step:7348 [D loss: 0.673295, acc.: 61.72%] [G loss: 1.023905]\n",
      "epoch:7 step:7349 [D loss: 0.606819, acc.: 67.19%] [G loss: 1.311082]\n",
      "epoch:7 step:7350 [D loss: 0.604513, acc.: 71.09%] [G loss: 1.137907]\n",
      "epoch:7 step:7351 [D loss: 0.689044, acc.: 53.12%] [G loss: 1.121415]\n",
      "epoch:7 step:7352 [D loss: 0.539866, acc.: 71.09%] [G loss: 1.248039]\n",
      "epoch:7 step:7353 [D loss: 0.473128, acc.: 81.25%] [G loss: 1.265745]\n",
      "epoch:7 step:7354 [D loss: 0.559196, acc.: 75.00%] [G loss: 1.169618]\n",
      "epoch:7 step:7355 [D loss: 0.606435, acc.: 65.62%] [G loss: 1.139595]\n",
      "epoch:7 step:7356 [D loss: 0.603852, acc.: 67.97%] [G loss: 1.036201]\n",
      "epoch:7 step:7357 [D loss: 0.581069, acc.: 72.66%] [G loss: 0.955395]\n",
      "epoch:7 step:7358 [D loss: 0.635893, acc.: 60.94%] [G loss: 0.959256]\n",
      "epoch:7 step:7359 [D loss: 0.637625, acc.: 64.06%] [G loss: 1.153440]\n",
      "epoch:7 step:7360 [D loss: 0.614136, acc.: 66.41%] [G loss: 1.092061]\n",
      "epoch:7 step:7361 [D loss: 0.605864, acc.: 69.53%] [G loss: 0.913869]\n",
      "epoch:7 step:7362 [D loss: 0.681988, acc.: 57.81%] [G loss: 0.960115]\n",
      "epoch:7 step:7363 [D loss: 0.652796, acc.: 63.28%] [G loss: 0.893911]\n",
      "epoch:7 step:7364 [D loss: 0.686061, acc.: 52.34%] [G loss: 1.100614]\n",
      "epoch:7 step:7365 [D loss: 0.526696, acc.: 78.12%] [G loss: 1.017085]\n",
      "epoch:7 step:7366 [D loss: 0.626192, acc.: 65.62%] [G loss: 1.074839]\n",
      "epoch:7 step:7367 [D loss: 0.585606, acc.: 72.66%] [G loss: 1.095185]\n",
      "epoch:7 step:7368 [D loss: 0.575698, acc.: 67.19%] [G loss: 0.975015]\n",
      "epoch:7 step:7369 [D loss: 0.692950, acc.: 60.16%] [G loss: 1.023559]\n",
      "epoch:7 step:7370 [D loss: 0.696837, acc.: 60.94%] [G loss: 1.050691]\n",
      "epoch:7 step:7371 [D loss: 0.543665, acc.: 77.34%] [G loss: 1.144563]\n",
      "epoch:7 step:7372 [D loss: 0.764253, acc.: 50.00%] [G loss: 1.052479]\n",
      "epoch:7 step:7373 [D loss: 0.590837, acc.: 66.41%] [G loss: 1.200297]\n",
      "epoch:7 step:7374 [D loss: 0.605022, acc.: 64.84%] [G loss: 1.238890]\n",
      "epoch:7 step:7375 [D loss: 0.564481, acc.: 71.88%] [G loss: 1.160025]\n",
      "epoch:7 step:7376 [D loss: 0.702045, acc.: 57.03%] [G loss: 1.229146]\n",
      "epoch:7 step:7377 [D loss: 0.578108, acc.: 68.75%] [G loss: 1.308409]\n",
      "epoch:7 step:7378 [D loss: 0.566820, acc.: 73.44%] [G loss: 1.043971]\n",
      "epoch:7 step:7379 [D loss: 0.729657, acc.: 48.44%] [G loss: 1.007612]\n",
      "epoch:7 step:7380 [D loss: 0.670293, acc.: 63.28%] [G loss: 1.046263]\n",
      "epoch:7 step:7381 [D loss: 0.579256, acc.: 67.97%] [G loss: 1.077797]\n",
      "epoch:7 step:7382 [D loss: 0.708476, acc.: 53.91%] [G loss: 1.018836]\n",
      "epoch:7 step:7383 [D loss: 0.683996, acc.: 63.28%] [G loss: 1.035004]\n",
      "epoch:7 step:7384 [D loss: 0.576376, acc.: 67.97%] [G loss: 1.046299]\n",
      "epoch:7 step:7385 [D loss: 0.608352, acc.: 71.88%] [G loss: 1.345454]\n",
      "epoch:7 step:7386 [D loss: 0.629339, acc.: 65.62%] [G loss: 0.970645]\n",
      "epoch:7 step:7387 [D loss: 0.770029, acc.: 44.53%] [G loss: 0.923185]\n",
      "epoch:7 step:7388 [D loss: 0.676877, acc.: 57.03%] [G loss: 0.973860]\n",
      "epoch:7 step:7389 [D loss: 0.592685, acc.: 67.19%] [G loss: 1.199270]\n",
      "epoch:7 step:7390 [D loss: 0.636704, acc.: 61.72%] [G loss: 1.058180]\n",
      "epoch:7 step:7391 [D loss: 0.601108, acc.: 68.75%] [G loss: 1.112713]\n",
      "epoch:7 step:7392 [D loss: 0.641593, acc.: 66.41%] [G loss: 1.163325]\n",
      "epoch:7 step:7393 [D loss: 0.645846, acc.: 64.06%] [G loss: 0.929509]\n",
      "epoch:7 step:7394 [D loss: 0.589325, acc.: 71.09%] [G loss: 1.109559]\n",
      "epoch:7 step:7395 [D loss: 0.645195, acc.: 65.62%] [G loss: 1.247210]\n",
      "epoch:7 step:7396 [D loss: 0.589957, acc.: 67.97%] [G loss: 1.160829]\n",
      "epoch:7 step:7397 [D loss: 0.570866, acc.: 71.09%] [G loss: 1.067633]\n",
      "epoch:7 step:7398 [D loss: 0.635582, acc.: 67.97%] [G loss: 0.986645]\n",
      "epoch:7 step:7399 [D loss: 0.648098, acc.: 60.16%] [G loss: 1.013891]\n",
      "epoch:7 step:7400 [D loss: 0.600982, acc.: 66.41%] [G loss: 1.074532]\n",
      "epoch:7 step:7401 [D loss: 0.611364, acc.: 68.75%] [G loss: 1.109372]\n",
      "epoch:7 step:7402 [D loss: 0.547117, acc.: 75.00%] [G loss: 0.994925]\n",
      "epoch:7 step:7403 [D loss: 0.607305, acc.: 68.75%] [G loss: 1.140870]\n",
      "epoch:7 step:7404 [D loss: 0.627990, acc.: 62.50%] [G loss: 1.019234]\n",
      "epoch:7 step:7405 [D loss: 0.689157, acc.: 53.91%] [G loss: 1.044333]\n",
      "epoch:7 step:7406 [D loss: 0.550947, acc.: 69.53%] [G loss: 0.911541]\n",
      "epoch:7 step:7407 [D loss: 0.613559, acc.: 65.62%] [G loss: 1.116007]\n",
      "epoch:7 step:7408 [D loss: 0.576420, acc.: 71.09%] [G loss: 1.069308]\n",
      "epoch:7 step:7409 [D loss: 0.675134, acc.: 56.25%] [G loss: 0.988751]\n",
      "epoch:7 step:7410 [D loss: 0.711364, acc.: 57.03%] [G loss: 1.141849]\n",
      "epoch:7 step:7411 [D loss: 0.606914, acc.: 66.41%] [G loss: 0.957815]\n",
      "epoch:7 step:7412 [D loss: 0.543277, acc.: 77.34%] [G loss: 1.165148]\n",
      "epoch:7 step:7413 [D loss: 0.577018, acc.: 71.88%] [G loss: 1.131850]\n",
      "epoch:7 step:7414 [D loss: 0.712686, acc.: 54.69%] [G loss: 0.933506]\n",
      "epoch:7 step:7415 [D loss: 0.585430, acc.: 69.53%] [G loss: 0.936728]\n",
      "epoch:7 step:7416 [D loss: 0.593790, acc.: 71.09%] [G loss: 1.164018]\n",
      "epoch:7 step:7417 [D loss: 0.631269, acc.: 60.94%] [G loss: 1.007806]\n",
      "epoch:7 step:7418 [D loss: 0.635328, acc.: 60.16%] [G loss: 1.031334]\n",
      "epoch:7 step:7419 [D loss: 0.620692, acc.: 66.41%] [G loss: 1.054456]\n",
      "epoch:7 step:7420 [D loss: 0.496551, acc.: 82.03%] [G loss: 1.135413]\n",
      "epoch:7 step:7421 [D loss: 0.694312, acc.: 59.38%] [G loss: 1.176276]\n",
      "epoch:7 step:7422 [D loss: 0.671795, acc.: 63.28%] [G loss: 1.140013]\n",
      "epoch:7 step:7423 [D loss: 0.673810, acc.: 57.03%] [G loss: 1.021591]\n",
      "epoch:7 step:7424 [D loss: 0.659345, acc.: 65.62%] [G loss: 1.116165]\n",
      "epoch:7 step:7425 [D loss: 0.602848, acc.: 64.84%] [G loss: 1.307856]\n",
      "epoch:7 step:7426 [D loss: 0.664098, acc.: 62.50%] [G loss: 1.169930]\n",
      "epoch:7 step:7427 [D loss: 0.626398, acc.: 66.41%] [G loss: 1.068505]\n",
      "epoch:7 step:7428 [D loss: 0.581251, acc.: 67.97%] [G loss: 0.875053]\n",
      "epoch:7 step:7429 [D loss: 0.540487, acc.: 75.00%] [G loss: 1.309047]\n",
      "epoch:7 step:7430 [D loss: 0.616628, acc.: 68.75%] [G loss: 1.104676]\n",
      "epoch:7 step:7431 [D loss: 0.660448, acc.: 62.50%] [G loss: 1.088358]\n",
      "epoch:7 step:7432 [D loss: 0.569304, acc.: 68.75%] [G loss: 1.111828]\n",
      "epoch:7 step:7433 [D loss: 0.702820, acc.: 53.91%] [G loss: 1.150891]\n",
      "epoch:7 step:7434 [D loss: 0.568952, acc.: 68.75%] [G loss: 1.265664]\n",
      "epoch:7 step:7435 [D loss: 0.607200, acc.: 69.53%] [G loss: 1.204333]\n",
      "epoch:7 step:7436 [D loss: 0.669479, acc.: 59.38%] [G loss: 0.974446]\n",
      "epoch:7 step:7437 [D loss: 0.642860, acc.: 60.94%] [G loss: 0.964476]\n",
      "epoch:7 step:7438 [D loss: 0.676626, acc.: 57.81%] [G loss: 0.887598]\n",
      "epoch:7 step:7439 [D loss: 0.630559, acc.: 60.16%] [G loss: 0.796470]\n",
      "epoch:7 step:7440 [D loss: 0.721721, acc.: 48.44%] [G loss: 1.061530]\n",
      "epoch:7 step:7441 [D loss: 0.581100, acc.: 66.41%] [G loss: 1.292748]\n",
      "epoch:7 step:7442 [D loss: 0.656044, acc.: 57.81%] [G loss: 1.229555]\n",
      "epoch:7 step:7443 [D loss: 0.574881, acc.: 71.09%] [G loss: 1.122726]\n",
      "epoch:7 step:7444 [D loss: 0.571159, acc.: 72.66%] [G loss: 1.099846]\n",
      "epoch:7 step:7445 [D loss: 0.649238, acc.: 58.59%] [G loss: 1.011434]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:7 step:7446 [D loss: 0.704354, acc.: 57.81%] [G loss: 1.266483]\n",
      "epoch:7 step:7447 [D loss: 0.683888, acc.: 61.72%] [G loss: 1.096008]\n",
      "epoch:7 step:7448 [D loss: 0.718704, acc.: 55.47%] [G loss: 1.049902]\n",
      "epoch:7 step:7449 [D loss: 0.624389, acc.: 66.41%] [G loss: 1.049673]\n",
      "epoch:7 step:7450 [D loss: 0.597723, acc.: 67.97%] [G loss: 1.127930]\n",
      "epoch:7 step:7451 [D loss: 0.577364, acc.: 69.53%] [G loss: 1.125508]\n",
      "epoch:7 step:7452 [D loss: 0.634389, acc.: 64.84%] [G loss: 1.140885]\n",
      "epoch:7 step:7453 [D loss: 0.742691, acc.: 54.69%] [G loss: 0.912217]\n",
      "epoch:7 step:7454 [D loss: 0.638529, acc.: 63.28%] [G loss: 1.067460]\n",
      "epoch:7 step:7455 [D loss: 0.708579, acc.: 52.34%] [G loss: 0.916123]\n",
      "epoch:7 step:7456 [D loss: 0.598282, acc.: 69.53%] [G loss: 1.162883]\n",
      "epoch:7 step:7457 [D loss: 0.590268, acc.: 68.75%] [G loss: 1.065924]\n",
      "epoch:7 step:7458 [D loss: 0.528364, acc.: 76.56%] [G loss: 1.051939]\n",
      "epoch:7 step:7459 [D loss: 0.569156, acc.: 71.88%] [G loss: 0.991401]\n",
      "epoch:7 step:7460 [D loss: 0.631018, acc.: 66.41%] [G loss: 1.105150]\n",
      "epoch:7 step:7461 [D loss: 0.671180, acc.: 59.38%] [G loss: 1.027901]\n",
      "epoch:7 step:7462 [D loss: 0.532365, acc.: 75.00%] [G loss: 1.115338]\n",
      "epoch:7 step:7463 [D loss: 0.597276, acc.: 69.53%] [G loss: 1.103402]\n",
      "epoch:7 step:7464 [D loss: 0.663350, acc.: 57.03%] [G loss: 0.911277]\n",
      "epoch:7 step:7465 [D loss: 0.615058, acc.: 67.97%] [G loss: 1.002684]\n",
      "epoch:7 step:7466 [D loss: 0.558074, acc.: 72.66%] [G loss: 1.197817]\n",
      "epoch:7 step:7467 [D loss: 0.721876, acc.: 50.78%] [G loss: 1.078426]\n",
      "epoch:7 step:7468 [D loss: 0.656602, acc.: 62.50%] [G loss: 1.085570]\n",
      "epoch:7 step:7469 [D loss: 0.575517, acc.: 71.09%] [G loss: 1.059921]\n",
      "epoch:7 step:7470 [D loss: 0.506228, acc.: 74.22%] [G loss: 1.153298]\n",
      "epoch:7 step:7471 [D loss: 0.622774, acc.: 65.62%] [G loss: 1.013810]\n",
      "epoch:7 step:7472 [D loss: 0.620795, acc.: 63.28%] [G loss: 1.170095]\n",
      "epoch:7 step:7473 [D loss: 0.584623, acc.: 62.50%] [G loss: 0.983656]\n",
      "epoch:7 step:7474 [D loss: 0.610677, acc.: 65.62%] [G loss: 1.028785]\n",
      "epoch:7 step:7475 [D loss: 0.612842, acc.: 68.75%] [G loss: 1.035520]\n",
      "epoch:7 step:7476 [D loss: 0.589098, acc.: 70.31%] [G loss: 1.133289]\n",
      "epoch:7 step:7477 [D loss: 0.538780, acc.: 74.22%] [G loss: 1.156299]\n",
      "epoch:7 step:7478 [D loss: 0.581258, acc.: 68.75%] [G loss: 1.232652]\n",
      "epoch:7 step:7479 [D loss: 0.657062, acc.: 63.28%] [G loss: 0.944784]\n",
      "epoch:7 step:7480 [D loss: 0.614458, acc.: 64.06%] [G loss: 1.090852]\n",
      "epoch:7 step:7481 [D loss: 0.614489, acc.: 60.94%] [G loss: 1.009311]\n",
      "epoch:7 step:7482 [D loss: 0.593989, acc.: 66.41%] [G loss: 1.271224]\n",
      "epoch:7 step:7483 [D loss: 0.620681, acc.: 65.62%] [G loss: 0.959060]\n",
      "epoch:7 step:7484 [D loss: 0.563285, acc.: 70.31%] [G loss: 1.398796]\n",
      "epoch:7 step:7485 [D loss: 0.652853, acc.: 59.38%] [G loss: 1.054308]\n",
      "epoch:7 step:7486 [D loss: 0.634689, acc.: 62.50%] [G loss: 1.216593]\n",
      "epoch:7 step:7487 [D loss: 0.592737, acc.: 68.75%] [G loss: 1.017915]\n",
      "epoch:7 step:7488 [D loss: 0.568922, acc.: 68.75%] [G loss: 1.190033]\n",
      "epoch:7 step:7489 [D loss: 0.623979, acc.: 65.62%] [G loss: 1.107712]\n",
      "epoch:7 step:7490 [D loss: 0.586148, acc.: 68.75%] [G loss: 1.340719]\n",
      "epoch:7 step:7491 [D loss: 0.622089, acc.: 67.19%] [G loss: 1.296118]\n",
      "epoch:7 step:7492 [D loss: 0.659409, acc.: 53.12%] [G loss: 1.061031]\n",
      "epoch:7 step:7493 [D loss: 0.690435, acc.: 57.81%] [G loss: 1.081958]\n",
      "epoch:7 step:7494 [D loss: 0.681212, acc.: 57.03%] [G loss: 1.006038]\n",
      "epoch:7 step:7495 [D loss: 0.641375, acc.: 59.38%] [G loss: 1.070724]\n",
      "epoch:7 step:7496 [D loss: 0.602216, acc.: 67.97%] [G loss: 1.054846]\n",
      "epoch:8 step:7497 [D loss: 0.644841, acc.: 60.16%] [G loss: 1.215865]\n",
      "epoch:8 step:7498 [D loss: 0.699335, acc.: 56.25%] [G loss: 1.022377]\n",
      "epoch:8 step:7499 [D loss: 0.637628, acc.: 63.28%] [G loss: 1.023521]\n",
      "epoch:8 step:7500 [D loss: 0.625756, acc.: 63.28%] [G loss: 1.046475]\n",
      "epoch:8 step:7501 [D loss: 0.653001, acc.: 57.81%] [G loss: 0.986801]\n",
      "epoch:8 step:7502 [D loss: 0.725612, acc.: 54.69%] [G loss: 0.985394]\n",
      "epoch:8 step:7503 [D loss: 0.707735, acc.: 51.56%] [G loss: 1.001004]\n",
      "epoch:8 step:7504 [D loss: 0.566911, acc.: 70.31%] [G loss: 1.039567]\n",
      "epoch:8 step:7505 [D loss: 0.628870, acc.: 71.88%] [G loss: 1.156108]\n",
      "epoch:8 step:7506 [D loss: 0.685828, acc.: 61.72%] [G loss: 1.034378]\n",
      "epoch:8 step:7507 [D loss: 0.576711, acc.: 71.88%] [G loss: 1.205077]\n",
      "epoch:8 step:7508 [D loss: 0.584197, acc.: 67.97%] [G loss: 0.955197]\n",
      "epoch:8 step:7509 [D loss: 0.623850, acc.: 67.19%] [G loss: 1.161333]\n",
      "epoch:8 step:7510 [D loss: 0.684689, acc.: 60.16%] [G loss: 1.042770]\n",
      "epoch:8 step:7511 [D loss: 0.583290, acc.: 64.84%] [G loss: 1.094855]\n",
      "epoch:8 step:7512 [D loss: 0.657159, acc.: 58.59%] [G loss: 1.021600]\n",
      "epoch:8 step:7513 [D loss: 0.601182, acc.: 67.97%] [G loss: 1.056875]\n",
      "epoch:8 step:7514 [D loss: 0.604158, acc.: 67.97%] [G loss: 1.125813]\n",
      "epoch:8 step:7515 [D loss: 0.623505, acc.: 66.41%] [G loss: 1.082823]\n",
      "epoch:8 step:7516 [D loss: 0.579008, acc.: 65.62%] [G loss: 1.123085]\n",
      "epoch:8 step:7517 [D loss: 0.684284, acc.: 63.28%] [G loss: 0.910469]\n",
      "epoch:8 step:7518 [D loss: 0.578026, acc.: 69.53%] [G loss: 1.050442]\n",
      "epoch:8 step:7519 [D loss: 0.693397, acc.: 54.69%] [G loss: 1.100657]\n",
      "epoch:8 step:7520 [D loss: 0.606082, acc.: 71.09%] [G loss: 0.961111]\n",
      "epoch:8 step:7521 [D loss: 0.575591, acc.: 72.66%] [G loss: 1.216703]\n",
      "epoch:8 step:7522 [D loss: 0.672848, acc.: 60.94%] [G loss: 1.197777]\n",
      "epoch:8 step:7523 [D loss: 0.563330, acc.: 71.88%] [G loss: 1.268049]\n",
      "epoch:8 step:7524 [D loss: 0.619496, acc.: 64.84%] [G loss: 1.020153]\n",
      "epoch:8 step:7525 [D loss: 0.524820, acc.: 79.69%] [G loss: 1.203844]\n",
      "epoch:8 step:7526 [D loss: 0.646762, acc.: 66.41%] [G loss: 0.998821]\n",
      "epoch:8 step:7527 [D loss: 0.644580, acc.: 60.16%] [G loss: 1.113745]\n",
      "epoch:8 step:7528 [D loss: 0.660902, acc.: 58.59%] [G loss: 0.997748]\n",
      "epoch:8 step:7529 [D loss: 0.625982, acc.: 67.19%] [G loss: 1.248516]\n",
      "epoch:8 step:7530 [D loss: 0.647813, acc.: 61.72%] [G loss: 1.153087]\n",
      "epoch:8 step:7531 [D loss: 0.515237, acc.: 74.22%] [G loss: 1.145032]\n",
      "epoch:8 step:7532 [D loss: 0.655801, acc.: 65.62%] [G loss: 1.042402]\n",
      "epoch:8 step:7533 [D loss: 0.587244, acc.: 63.28%] [G loss: 1.021809]\n",
      "epoch:8 step:7534 [D loss: 0.625992, acc.: 66.41%] [G loss: 1.045751]\n",
      "epoch:8 step:7535 [D loss: 0.671556, acc.: 58.59%] [G loss: 1.168072]\n",
      "epoch:8 step:7536 [D loss: 0.681351, acc.: 57.81%] [G loss: 1.038231]\n",
      "epoch:8 step:7537 [D loss: 0.636108, acc.: 64.06%] [G loss: 1.095248]\n",
      "epoch:8 step:7538 [D loss: 0.567710, acc.: 71.09%] [G loss: 1.273642]\n",
      "epoch:8 step:7539 [D loss: 0.652003, acc.: 60.94%] [G loss: 0.990016]\n",
      "epoch:8 step:7540 [D loss: 0.666085, acc.: 62.50%] [G loss: 1.043567]\n",
      "epoch:8 step:7541 [D loss: 0.588675, acc.: 67.97%] [G loss: 1.169753]\n",
      "epoch:8 step:7542 [D loss: 0.689753, acc.: 57.03%] [G loss: 1.098459]\n",
      "epoch:8 step:7543 [D loss: 0.579355, acc.: 64.06%] [G loss: 1.082100]\n",
      "epoch:8 step:7544 [D loss: 0.739011, acc.: 53.91%] [G loss: 1.031146]\n",
      "epoch:8 step:7545 [D loss: 0.587120, acc.: 65.62%] [G loss: 1.157214]\n",
      "epoch:8 step:7546 [D loss: 0.505097, acc.: 81.25%] [G loss: 1.120840]\n",
      "epoch:8 step:7547 [D loss: 0.652649, acc.: 60.94%] [G loss: 1.080987]\n",
      "epoch:8 step:7548 [D loss: 0.608800, acc.: 67.97%] [G loss: 1.093197]\n",
      "epoch:8 step:7549 [D loss: 0.562722, acc.: 70.31%] [G loss: 1.130368]\n",
      "epoch:8 step:7550 [D loss: 0.563728, acc.: 68.75%] [G loss: 1.081827]\n",
      "epoch:8 step:7551 [D loss: 0.666164, acc.: 57.81%] [G loss: 1.090007]\n",
      "epoch:8 step:7552 [D loss: 0.726987, acc.: 51.56%] [G loss: 1.122694]\n",
      "epoch:8 step:7553 [D loss: 0.595443, acc.: 73.44%] [G loss: 1.134552]\n",
      "epoch:8 step:7554 [D loss: 0.600340, acc.: 67.97%] [G loss: 1.192185]\n",
      "epoch:8 step:7555 [D loss: 0.577885, acc.: 73.44%] [G loss: 1.057987]\n",
      "epoch:8 step:7556 [D loss: 0.630725, acc.: 63.28%] [G loss: 1.341366]\n",
      "epoch:8 step:7557 [D loss: 0.775460, acc.: 49.22%] [G loss: 0.991003]\n",
      "epoch:8 step:7558 [D loss: 0.684507, acc.: 60.94%] [G loss: 1.157666]\n",
      "epoch:8 step:7559 [D loss: 0.656771, acc.: 60.16%] [G loss: 1.074621]\n",
      "epoch:8 step:7560 [D loss: 0.605897, acc.: 64.06%] [G loss: 1.157370]\n",
      "epoch:8 step:7561 [D loss: 0.599467, acc.: 67.19%] [G loss: 1.197737]\n",
      "epoch:8 step:7562 [D loss: 0.647076, acc.: 63.28%] [G loss: 0.916043]\n",
      "epoch:8 step:7563 [D loss: 0.569316, acc.: 71.09%] [G loss: 1.123880]\n",
      "epoch:8 step:7564 [D loss: 0.503317, acc.: 79.69%] [G loss: 1.207977]\n",
      "epoch:8 step:7565 [D loss: 0.718714, acc.: 52.34%] [G loss: 0.924978]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:8 step:7566 [D loss: 0.652340, acc.: 58.59%] [G loss: 1.094626]\n",
      "epoch:8 step:7567 [D loss: 0.638666, acc.: 64.06%] [G loss: 1.195211]\n",
      "epoch:8 step:7568 [D loss: 0.558501, acc.: 67.19%] [G loss: 1.227500]\n",
      "epoch:8 step:7569 [D loss: 0.648096, acc.: 64.84%] [G loss: 1.279976]\n",
      "epoch:8 step:7570 [D loss: 0.540048, acc.: 75.00%] [G loss: 1.413476]\n",
      "epoch:8 step:7571 [D loss: 0.624828, acc.: 62.50%] [G loss: 1.071952]\n",
      "epoch:8 step:7572 [D loss: 0.583348, acc.: 72.66%] [G loss: 1.283738]\n",
      "epoch:8 step:7573 [D loss: 0.616190, acc.: 65.62%] [G loss: 1.019363]\n",
      "epoch:8 step:7574 [D loss: 0.740821, acc.: 52.34%] [G loss: 1.044837]\n",
      "epoch:8 step:7575 [D loss: 0.660398, acc.: 57.81%] [G loss: 0.949391]\n",
      "epoch:8 step:7576 [D loss: 0.645507, acc.: 54.69%] [G loss: 1.249339]\n",
      "epoch:8 step:7577 [D loss: 0.720567, acc.: 53.91%] [G loss: 1.048237]\n",
      "epoch:8 step:7578 [D loss: 0.675660, acc.: 60.16%] [G loss: 1.107939]\n",
      "epoch:8 step:7579 [D loss: 0.671699, acc.: 58.59%] [G loss: 1.087202]\n",
      "epoch:8 step:7580 [D loss: 0.697057, acc.: 59.38%] [G loss: 1.041263]\n",
      "epoch:8 step:7581 [D loss: 0.685295, acc.: 60.94%] [G loss: 0.965035]\n",
      "epoch:8 step:7582 [D loss: 0.667935, acc.: 57.81%] [G loss: 1.063941]\n",
      "epoch:8 step:7583 [D loss: 0.659636, acc.: 60.16%] [G loss: 1.036639]\n",
      "epoch:8 step:7584 [D loss: 0.556411, acc.: 72.66%] [G loss: 1.152702]\n",
      "epoch:8 step:7585 [D loss: 0.677894, acc.: 61.72%] [G loss: 0.966431]\n",
      "epoch:8 step:7586 [D loss: 0.528357, acc.: 73.44%] [G loss: 1.033449]\n",
      "epoch:8 step:7587 [D loss: 0.702171, acc.: 55.47%] [G loss: 1.253731]\n",
      "epoch:8 step:7588 [D loss: 0.695007, acc.: 57.81%] [G loss: 1.076011]\n",
      "epoch:8 step:7589 [D loss: 0.607867, acc.: 67.97%] [G loss: 1.260391]\n",
      "epoch:8 step:7590 [D loss: 0.556756, acc.: 72.66%] [G loss: 1.124619]\n",
      "epoch:8 step:7591 [D loss: 0.595532, acc.: 66.41%] [G loss: 1.015891]\n",
      "epoch:8 step:7592 [D loss: 0.597005, acc.: 63.28%] [G loss: 0.984537]\n",
      "epoch:8 step:7593 [D loss: 0.644302, acc.: 62.50%] [G loss: 1.037411]\n",
      "epoch:8 step:7594 [D loss: 0.596588, acc.: 67.97%] [G loss: 1.001779]\n",
      "epoch:8 step:7595 [D loss: 0.692777, acc.: 57.81%] [G loss: 1.163906]\n",
      "epoch:8 step:7596 [D loss: 0.667350, acc.: 59.38%] [G loss: 0.984700]\n",
      "epoch:8 step:7597 [D loss: 0.619599, acc.: 64.84%] [G loss: 0.946793]\n",
      "epoch:8 step:7598 [D loss: 0.573449, acc.: 67.97%] [G loss: 1.262475]\n",
      "epoch:8 step:7599 [D loss: 0.578869, acc.: 68.75%] [G loss: 1.029395]\n",
      "epoch:8 step:7600 [D loss: 0.641430, acc.: 71.09%] [G loss: 1.195965]\n",
      "epoch:8 step:7601 [D loss: 0.565596, acc.: 71.88%] [G loss: 1.185773]\n",
      "epoch:8 step:7602 [D loss: 0.604499, acc.: 68.75%] [G loss: 1.059637]\n",
      "epoch:8 step:7603 [D loss: 0.558093, acc.: 67.97%] [G loss: 1.052350]\n",
      "epoch:8 step:7604 [D loss: 0.574967, acc.: 70.31%] [G loss: 1.123920]\n",
      "epoch:8 step:7605 [D loss: 0.599297, acc.: 70.31%] [G loss: 1.116142]\n",
      "epoch:8 step:7606 [D loss: 0.700851, acc.: 53.12%] [G loss: 0.925506]\n",
      "epoch:8 step:7607 [D loss: 0.721051, acc.: 53.91%] [G loss: 0.894399]\n",
      "epoch:8 step:7608 [D loss: 0.630718, acc.: 64.06%] [G loss: 1.055059]\n",
      "epoch:8 step:7609 [D loss: 0.599541, acc.: 68.75%] [G loss: 1.121906]\n",
      "epoch:8 step:7610 [D loss: 0.674193, acc.: 60.16%] [G loss: 1.183820]\n",
      "epoch:8 step:7611 [D loss: 0.644319, acc.: 64.84%] [G loss: 1.256841]\n",
      "epoch:8 step:7612 [D loss: 0.655488, acc.: 61.72%] [G loss: 0.977507]\n",
      "epoch:8 step:7613 [D loss: 0.651516, acc.: 57.81%] [G loss: 0.991107]\n",
      "epoch:8 step:7614 [D loss: 0.704856, acc.: 53.12%] [G loss: 1.008260]\n",
      "epoch:8 step:7615 [D loss: 0.585192, acc.: 70.31%] [G loss: 1.223342]\n",
      "epoch:8 step:7616 [D loss: 0.680076, acc.: 60.16%] [G loss: 0.922251]\n",
      "epoch:8 step:7617 [D loss: 0.671597, acc.: 57.03%] [G loss: 0.965812]\n",
      "epoch:8 step:7618 [D loss: 0.558296, acc.: 74.22%] [G loss: 1.050139]\n",
      "epoch:8 step:7619 [D loss: 0.668286, acc.: 57.81%] [G loss: 0.966522]\n",
      "epoch:8 step:7620 [D loss: 0.614170, acc.: 62.50%] [G loss: 1.148593]\n",
      "epoch:8 step:7621 [D loss: 0.549637, acc.: 76.56%] [G loss: 1.121446]\n",
      "epoch:8 step:7622 [D loss: 0.636309, acc.: 64.84%] [G loss: 1.039555]\n",
      "epoch:8 step:7623 [D loss: 0.615716, acc.: 64.84%] [G loss: 0.995196]\n",
      "epoch:8 step:7624 [D loss: 0.606980, acc.: 71.09%] [G loss: 1.081208]\n",
      "epoch:8 step:7625 [D loss: 0.637795, acc.: 65.62%] [G loss: 1.027858]\n",
      "epoch:8 step:7626 [D loss: 0.668750, acc.: 57.81%] [G loss: 1.049687]\n",
      "epoch:8 step:7627 [D loss: 0.623523, acc.: 67.19%] [G loss: 1.020060]\n",
      "epoch:8 step:7628 [D loss: 0.635736, acc.: 63.28%] [G loss: 1.181932]\n",
      "epoch:8 step:7629 [D loss: 0.646743, acc.: 61.72%] [G loss: 1.128050]\n",
      "epoch:8 step:7630 [D loss: 0.644817, acc.: 58.59%] [G loss: 1.155477]\n",
      "epoch:8 step:7631 [D loss: 0.597627, acc.: 71.09%] [G loss: 1.202270]\n",
      "epoch:8 step:7632 [D loss: 0.645213, acc.: 64.06%] [G loss: 0.952300]\n",
      "epoch:8 step:7633 [D loss: 0.626912, acc.: 60.94%] [G loss: 1.135704]\n",
      "epoch:8 step:7634 [D loss: 0.578985, acc.: 71.88%] [G loss: 1.259008]\n",
      "epoch:8 step:7635 [D loss: 0.644477, acc.: 65.62%] [G loss: 1.174475]\n",
      "epoch:8 step:7636 [D loss: 0.644307, acc.: 67.97%] [G loss: 1.096393]\n",
      "epoch:8 step:7637 [D loss: 0.672504, acc.: 58.59%] [G loss: 1.110071]\n",
      "epoch:8 step:7638 [D loss: 0.639194, acc.: 64.84%] [G loss: 0.965629]\n",
      "epoch:8 step:7639 [D loss: 0.652470, acc.: 60.16%] [G loss: 1.261042]\n",
      "epoch:8 step:7640 [D loss: 0.600049, acc.: 67.19%] [G loss: 1.457038]\n",
      "epoch:8 step:7641 [D loss: 0.636504, acc.: 67.19%] [G loss: 0.864045]\n",
      "epoch:8 step:7642 [D loss: 0.595952, acc.: 67.19%] [G loss: 0.911555]\n",
      "epoch:8 step:7643 [D loss: 0.661476, acc.: 64.84%] [G loss: 1.200904]\n",
      "epoch:8 step:7644 [D loss: 0.607371, acc.: 65.62%] [G loss: 1.162007]\n",
      "epoch:8 step:7645 [D loss: 0.661859, acc.: 62.50%] [G loss: 1.196521]\n",
      "epoch:8 step:7646 [D loss: 0.639219, acc.: 66.41%] [G loss: 1.131749]\n",
      "epoch:8 step:7647 [D loss: 0.579271, acc.: 69.53%] [G loss: 1.061760]\n",
      "epoch:8 step:7648 [D loss: 0.627148, acc.: 64.84%] [G loss: 0.933106]\n",
      "epoch:8 step:7649 [D loss: 0.690688, acc.: 59.38%] [G loss: 1.080163]\n",
      "epoch:8 step:7650 [D loss: 0.614232, acc.: 61.72%] [G loss: 1.068344]\n",
      "epoch:8 step:7651 [D loss: 0.669511, acc.: 59.38%] [G loss: 1.182662]\n",
      "epoch:8 step:7652 [D loss: 0.575319, acc.: 70.31%] [G loss: 1.101859]\n",
      "epoch:8 step:7653 [D loss: 0.722269, acc.: 53.91%] [G loss: 0.963977]\n",
      "epoch:8 step:7654 [D loss: 0.609114, acc.: 70.31%] [G loss: 1.145586]\n",
      "epoch:8 step:7655 [D loss: 0.519809, acc.: 76.56%] [G loss: 1.234705]\n",
      "epoch:8 step:7656 [D loss: 0.668166, acc.: 56.25%] [G loss: 1.019982]\n",
      "epoch:8 step:7657 [D loss: 0.584266, acc.: 67.19%] [G loss: 1.125378]\n",
      "epoch:8 step:7658 [D loss: 0.668534, acc.: 58.59%] [G loss: 1.267817]\n",
      "epoch:8 step:7659 [D loss: 0.645018, acc.: 63.28%] [G loss: 1.138442]\n",
      "epoch:8 step:7660 [D loss: 0.613080, acc.: 63.28%] [G loss: 0.948604]\n",
      "epoch:8 step:7661 [D loss: 0.612429, acc.: 67.97%] [G loss: 1.229330]\n",
      "epoch:8 step:7662 [D loss: 0.561417, acc.: 71.09%] [G loss: 1.073200]\n",
      "epoch:8 step:7663 [D loss: 0.611607, acc.: 65.62%] [G loss: 0.950146]\n",
      "epoch:8 step:7664 [D loss: 0.625501, acc.: 65.62%] [G loss: 1.162705]\n",
      "epoch:8 step:7665 [D loss: 0.586431, acc.: 65.62%] [G loss: 1.063935]\n",
      "epoch:8 step:7666 [D loss: 0.597842, acc.: 61.72%] [G loss: 1.000009]\n",
      "epoch:8 step:7667 [D loss: 0.620510, acc.: 64.84%] [G loss: 1.083352]\n",
      "epoch:8 step:7668 [D loss: 0.659667, acc.: 60.94%] [G loss: 0.929029]\n",
      "epoch:8 step:7669 [D loss: 0.602033, acc.: 70.31%] [G loss: 1.068145]\n",
      "epoch:8 step:7670 [D loss: 0.558637, acc.: 67.97%] [G loss: 1.167177]\n",
      "epoch:8 step:7671 [D loss: 0.700932, acc.: 57.03%] [G loss: 0.854854]\n",
      "epoch:8 step:7672 [D loss: 0.573649, acc.: 69.53%] [G loss: 1.186790]\n",
      "epoch:8 step:7673 [D loss: 0.540022, acc.: 71.88%] [G loss: 1.084785]\n",
      "epoch:8 step:7674 [D loss: 0.707755, acc.: 59.38%] [G loss: 0.949047]\n",
      "epoch:8 step:7675 [D loss: 0.692510, acc.: 59.38%] [G loss: 1.126827]\n",
      "epoch:8 step:7676 [D loss: 0.564677, acc.: 68.75%] [G loss: 1.153767]\n",
      "epoch:8 step:7677 [D loss: 0.654292, acc.: 60.94%] [G loss: 0.936216]\n",
      "epoch:8 step:7678 [D loss: 0.536645, acc.: 75.00%] [G loss: 1.238720]\n",
      "epoch:8 step:7679 [D loss: 0.570317, acc.: 70.31%] [G loss: 1.063298]\n",
      "epoch:8 step:7680 [D loss: 0.566918, acc.: 71.09%] [G loss: 1.052840]\n",
      "epoch:8 step:7681 [D loss: 0.622680, acc.: 64.84%] [G loss: 0.962140]\n",
      "epoch:8 step:7682 [D loss: 0.557254, acc.: 73.44%] [G loss: 1.071133]\n",
      "epoch:8 step:7683 [D loss: 0.546479, acc.: 71.09%] [G loss: 1.057441]\n",
      "epoch:8 step:7684 [D loss: 0.665294, acc.: 61.72%] [G loss: 1.058194]\n",
      "epoch:8 step:7685 [D loss: 0.643093, acc.: 61.72%] [G loss: 1.000293]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:8 step:7686 [D loss: 0.656703, acc.: 61.72%] [G loss: 0.910670]\n",
      "epoch:8 step:7687 [D loss: 0.578460, acc.: 67.97%] [G loss: 1.321224]\n",
      "epoch:8 step:7688 [D loss: 0.614700, acc.: 70.31%] [G loss: 1.073994]\n",
      "epoch:8 step:7689 [D loss: 0.682991, acc.: 54.69%] [G loss: 1.037534]\n",
      "epoch:8 step:7690 [D loss: 0.588608, acc.: 64.84%] [G loss: 1.056459]\n",
      "epoch:8 step:7691 [D loss: 0.556156, acc.: 70.31%] [G loss: 1.256925]\n",
      "epoch:8 step:7692 [D loss: 0.599591, acc.: 68.75%] [G loss: 1.040331]\n",
      "epoch:8 step:7693 [D loss: 0.584321, acc.: 69.53%] [G loss: 1.108180]\n",
      "epoch:8 step:7694 [D loss: 0.666096, acc.: 60.94%] [G loss: 1.063174]\n",
      "epoch:8 step:7695 [D loss: 0.567084, acc.: 69.53%] [G loss: 1.249546]\n",
      "epoch:8 step:7696 [D loss: 0.581836, acc.: 69.53%] [G loss: 1.248569]\n",
      "epoch:8 step:7697 [D loss: 0.619135, acc.: 67.19%] [G loss: 1.014609]\n",
      "epoch:8 step:7698 [D loss: 0.490902, acc.: 79.69%] [G loss: 1.111878]\n",
      "epoch:8 step:7699 [D loss: 0.530564, acc.: 77.34%] [G loss: 1.090283]\n",
      "epoch:8 step:7700 [D loss: 0.505368, acc.: 82.03%] [G loss: 1.362483]\n",
      "epoch:8 step:7701 [D loss: 0.630864, acc.: 63.28%] [G loss: 1.112518]\n",
      "epoch:8 step:7702 [D loss: 0.683228, acc.: 63.28%] [G loss: 0.973324]\n",
      "epoch:8 step:7703 [D loss: 0.609267, acc.: 71.09%] [G loss: 1.083263]\n",
      "epoch:8 step:7704 [D loss: 0.534850, acc.: 73.44%] [G loss: 1.036781]\n",
      "epoch:8 step:7705 [D loss: 0.727781, acc.: 53.12%] [G loss: 1.131367]\n",
      "epoch:8 step:7706 [D loss: 0.690693, acc.: 59.38%] [G loss: 1.100745]\n",
      "epoch:8 step:7707 [D loss: 0.532717, acc.: 75.78%] [G loss: 1.230442]\n",
      "epoch:8 step:7708 [D loss: 0.616967, acc.: 67.19%] [G loss: 1.249275]\n",
      "epoch:8 step:7709 [D loss: 0.663208, acc.: 66.41%] [G loss: 1.192358]\n",
      "epoch:8 step:7710 [D loss: 0.755555, acc.: 48.44%] [G loss: 1.156996]\n",
      "epoch:8 step:7711 [D loss: 0.689319, acc.: 63.28%] [G loss: 0.967425]\n",
      "epoch:8 step:7712 [D loss: 0.605930, acc.: 71.88%] [G loss: 1.064840]\n",
      "epoch:8 step:7713 [D loss: 0.582477, acc.: 67.19%] [G loss: 1.144346]\n",
      "epoch:8 step:7714 [D loss: 0.665113, acc.: 62.50%] [G loss: 1.062019]\n",
      "epoch:8 step:7715 [D loss: 0.581172, acc.: 67.19%] [G loss: 1.204110]\n",
      "epoch:8 step:7716 [D loss: 0.592226, acc.: 67.97%] [G loss: 0.985182]\n",
      "epoch:8 step:7717 [D loss: 0.699716, acc.: 60.94%] [G loss: 0.923775]\n",
      "epoch:8 step:7718 [D loss: 0.674143, acc.: 59.38%] [G loss: 1.096272]\n",
      "epoch:8 step:7719 [D loss: 0.582075, acc.: 66.41%] [G loss: 1.257010]\n",
      "epoch:8 step:7720 [D loss: 0.665626, acc.: 66.41%] [G loss: 1.055635]\n",
      "epoch:8 step:7721 [D loss: 0.629971, acc.: 66.41%] [G loss: 1.029078]\n",
      "epoch:8 step:7722 [D loss: 0.635706, acc.: 64.06%] [G loss: 1.196792]\n",
      "epoch:8 step:7723 [D loss: 0.589119, acc.: 68.75%] [G loss: 0.950421]\n",
      "epoch:8 step:7724 [D loss: 0.665765, acc.: 58.59%] [G loss: 1.104774]\n",
      "epoch:8 step:7725 [D loss: 0.650548, acc.: 62.50%] [G loss: 0.993996]\n",
      "epoch:8 step:7726 [D loss: 0.606237, acc.: 68.75%] [G loss: 1.234279]\n",
      "epoch:8 step:7727 [D loss: 0.684013, acc.: 50.78%] [G loss: 1.054274]\n",
      "epoch:8 step:7728 [D loss: 0.663803, acc.: 60.16%] [G loss: 1.130769]\n",
      "epoch:8 step:7729 [D loss: 0.650438, acc.: 64.84%] [G loss: 1.145126]\n",
      "epoch:8 step:7730 [D loss: 0.662834, acc.: 71.09%] [G loss: 1.063803]\n",
      "epoch:8 step:7731 [D loss: 0.693320, acc.: 52.34%] [G loss: 0.894214]\n",
      "epoch:8 step:7732 [D loss: 0.540735, acc.: 73.44%] [G loss: 1.084151]\n",
      "epoch:8 step:7733 [D loss: 0.701297, acc.: 57.03%] [G loss: 1.105437]\n",
      "epoch:8 step:7734 [D loss: 0.626598, acc.: 60.16%] [G loss: 1.081973]\n",
      "epoch:8 step:7735 [D loss: 0.672619, acc.: 61.72%] [G loss: 1.046881]\n",
      "epoch:8 step:7736 [D loss: 0.658146, acc.: 58.59%] [G loss: 0.928752]\n",
      "epoch:8 step:7737 [D loss: 0.627426, acc.: 71.09%] [G loss: 0.991583]\n",
      "epoch:8 step:7738 [D loss: 0.723831, acc.: 53.12%] [G loss: 0.843263]\n",
      "epoch:8 step:7739 [D loss: 0.593459, acc.: 67.19%] [G loss: 0.972314]\n",
      "epoch:8 step:7740 [D loss: 0.626125, acc.: 67.97%] [G loss: 1.169333]\n",
      "epoch:8 step:7741 [D loss: 0.657253, acc.: 62.50%] [G loss: 1.072697]\n",
      "epoch:8 step:7742 [D loss: 0.613205, acc.: 66.41%] [G loss: 0.999618]\n",
      "epoch:8 step:7743 [D loss: 0.546198, acc.: 78.12%] [G loss: 1.108878]\n",
      "epoch:8 step:7744 [D loss: 0.567927, acc.: 70.31%] [G loss: 1.147416]\n",
      "epoch:8 step:7745 [D loss: 0.621324, acc.: 64.06%] [G loss: 1.049229]\n",
      "epoch:8 step:7746 [D loss: 0.678599, acc.: 64.84%] [G loss: 1.027739]\n",
      "epoch:8 step:7747 [D loss: 0.595222, acc.: 67.97%] [G loss: 1.083747]\n",
      "epoch:8 step:7748 [D loss: 0.505211, acc.: 77.34%] [G loss: 1.169182]\n",
      "epoch:8 step:7749 [D loss: 0.657731, acc.: 64.06%] [G loss: 1.020328]\n",
      "epoch:8 step:7750 [D loss: 0.688796, acc.: 61.72%] [G loss: 1.156931]\n",
      "epoch:8 step:7751 [D loss: 0.630786, acc.: 59.38%] [G loss: 1.062739]\n",
      "epoch:8 step:7752 [D loss: 0.633926, acc.: 65.62%] [G loss: 1.094012]\n",
      "epoch:8 step:7753 [D loss: 0.557212, acc.: 73.44%] [G loss: 1.250873]\n",
      "epoch:8 step:7754 [D loss: 0.643823, acc.: 63.28%] [G loss: 0.950388]\n",
      "epoch:8 step:7755 [D loss: 0.639879, acc.: 62.50%] [G loss: 1.022323]\n",
      "epoch:8 step:7756 [D loss: 0.682485, acc.: 59.38%] [G loss: 0.947682]\n",
      "epoch:8 step:7757 [D loss: 0.663166, acc.: 61.72%] [G loss: 1.048705]\n",
      "epoch:8 step:7758 [D loss: 0.725736, acc.: 54.69%] [G loss: 0.977232]\n",
      "epoch:8 step:7759 [D loss: 0.601691, acc.: 70.31%] [G loss: 1.117014]\n",
      "epoch:8 step:7760 [D loss: 0.669276, acc.: 62.50%] [G loss: 1.008835]\n",
      "epoch:8 step:7761 [D loss: 0.599877, acc.: 69.53%] [G loss: 1.106861]\n",
      "epoch:8 step:7762 [D loss: 0.650746, acc.: 56.25%] [G loss: 1.007044]\n",
      "epoch:8 step:7763 [D loss: 0.542144, acc.: 80.47%] [G loss: 1.049443]\n",
      "epoch:8 step:7764 [D loss: 0.617869, acc.: 67.97%] [G loss: 0.979719]\n",
      "epoch:8 step:7765 [D loss: 0.576800, acc.: 69.53%] [G loss: 1.046655]\n",
      "epoch:8 step:7766 [D loss: 0.577493, acc.: 71.88%] [G loss: 1.175812]\n",
      "epoch:8 step:7767 [D loss: 0.589420, acc.: 71.09%] [G loss: 1.106846]\n",
      "epoch:8 step:7768 [D loss: 0.590481, acc.: 66.41%] [G loss: 1.080942]\n",
      "epoch:8 step:7769 [D loss: 0.615234, acc.: 70.31%] [G loss: 1.233109]\n",
      "epoch:8 step:7770 [D loss: 0.687598, acc.: 60.94%] [G loss: 1.170828]\n",
      "epoch:8 step:7771 [D loss: 0.767247, acc.: 51.56%] [G loss: 1.213821]\n",
      "epoch:8 step:7772 [D loss: 0.794252, acc.: 48.44%] [G loss: 0.978681]\n",
      "epoch:8 step:7773 [D loss: 0.648615, acc.: 62.50%] [G loss: 0.958487]\n",
      "epoch:8 step:7774 [D loss: 0.616692, acc.: 65.62%] [G loss: 1.030806]\n",
      "epoch:8 step:7775 [D loss: 0.751137, acc.: 54.69%] [G loss: 1.129379]\n",
      "epoch:8 step:7776 [D loss: 0.704300, acc.: 57.03%] [G loss: 1.083735]\n",
      "epoch:8 step:7777 [D loss: 0.618535, acc.: 65.62%] [G loss: 0.999630]\n",
      "epoch:8 step:7778 [D loss: 0.615106, acc.: 68.75%] [G loss: 1.107335]\n",
      "epoch:8 step:7779 [D loss: 0.578060, acc.: 68.75%] [G loss: 1.023681]\n",
      "epoch:8 step:7780 [D loss: 0.601971, acc.: 68.75%] [G loss: 0.950528]\n",
      "epoch:8 step:7781 [D loss: 0.614565, acc.: 70.31%] [G loss: 1.106919]\n",
      "epoch:8 step:7782 [D loss: 0.647878, acc.: 59.38%] [G loss: 1.134467]\n",
      "epoch:8 step:7783 [D loss: 0.547145, acc.: 77.34%] [G loss: 1.047184]\n",
      "epoch:8 step:7784 [D loss: 0.692217, acc.: 57.03%] [G loss: 1.014481]\n",
      "epoch:8 step:7785 [D loss: 0.573444, acc.: 73.44%] [G loss: 1.195505]\n",
      "epoch:8 step:7786 [D loss: 0.575185, acc.: 66.41%] [G loss: 1.011831]\n",
      "epoch:8 step:7787 [D loss: 0.576103, acc.: 71.09%] [G loss: 1.037163]\n",
      "epoch:8 step:7788 [D loss: 0.648688, acc.: 61.72%] [G loss: 1.127126]\n",
      "epoch:8 step:7789 [D loss: 0.581369, acc.: 69.53%] [G loss: 1.093356]\n",
      "epoch:8 step:7790 [D loss: 0.613303, acc.: 61.72%] [G loss: 1.106292]\n",
      "epoch:8 step:7791 [D loss: 0.572675, acc.: 69.53%] [G loss: 0.976153]\n",
      "epoch:8 step:7792 [D loss: 0.621594, acc.: 65.62%] [G loss: 1.148621]\n",
      "epoch:8 step:7793 [D loss: 0.648923, acc.: 63.28%] [G loss: 1.198587]\n",
      "epoch:8 step:7794 [D loss: 0.680265, acc.: 58.59%] [G loss: 1.017202]\n",
      "epoch:8 step:7795 [D loss: 0.759119, acc.: 48.44%] [G loss: 1.003035]\n",
      "epoch:8 step:7796 [D loss: 0.569923, acc.: 71.09%] [G loss: 0.956092]\n",
      "epoch:8 step:7797 [D loss: 0.650344, acc.: 57.81%] [G loss: 0.998910]\n",
      "epoch:8 step:7798 [D loss: 0.573134, acc.: 71.09%] [G loss: 1.055333]\n",
      "epoch:8 step:7799 [D loss: 0.668624, acc.: 64.84%] [G loss: 0.949259]\n",
      "epoch:8 step:7800 [D loss: 0.585315, acc.: 69.53%] [G loss: 0.969608]\n",
      "epoch:8 step:7801 [D loss: 0.658681, acc.: 59.38%] [G loss: 0.963052]\n",
      "epoch:8 step:7802 [D loss: 0.598149, acc.: 71.09%] [G loss: 1.157433]\n",
      "epoch:8 step:7803 [D loss: 0.646835, acc.: 64.84%] [G loss: 1.181402]\n",
      "epoch:8 step:7804 [D loss: 0.641411, acc.: 67.19%] [G loss: 1.080115]\n",
      "epoch:8 step:7805 [D loss: 0.584228, acc.: 66.41%] [G loss: 1.197689]\n",
      "epoch:8 step:7806 [D loss: 0.665415, acc.: 64.84%] [G loss: 1.211080]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:8 step:7807 [D loss: 0.712582, acc.: 56.25%] [G loss: 1.050047]\n",
      "epoch:8 step:7808 [D loss: 0.706112, acc.: 58.59%] [G loss: 1.128308]\n",
      "epoch:8 step:7809 [D loss: 0.651430, acc.: 60.16%] [G loss: 1.045318]\n",
      "epoch:8 step:7810 [D loss: 0.587813, acc.: 66.41%] [G loss: 1.042663]\n",
      "epoch:8 step:7811 [D loss: 0.584198, acc.: 68.75%] [G loss: 1.186838]\n",
      "epoch:8 step:7812 [D loss: 0.611710, acc.: 67.97%] [G loss: 0.984596]\n",
      "epoch:8 step:7813 [D loss: 0.562196, acc.: 70.31%] [G loss: 1.075107]\n",
      "epoch:8 step:7814 [D loss: 0.613493, acc.: 67.19%] [G loss: 1.053417]\n",
      "epoch:8 step:7815 [D loss: 0.759505, acc.: 53.12%] [G loss: 0.824868]\n",
      "epoch:8 step:7816 [D loss: 0.619860, acc.: 60.94%] [G loss: 1.008264]\n",
      "epoch:8 step:7817 [D loss: 0.693751, acc.: 59.38%] [G loss: 1.033846]\n",
      "epoch:8 step:7818 [D loss: 0.724554, acc.: 54.69%] [G loss: 0.927979]\n",
      "epoch:8 step:7819 [D loss: 0.582578, acc.: 66.41%] [G loss: 1.069378]\n",
      "epoch:8 step:7820 [D loss: 0.551958, acc.: 71.09%] [G loss: 0.942091]\n",
      "epoch:8 step:7821 [D loss: 0.645622, acc.: 60.16%] [G loss: 1.098601]\n",
      "epoch:8 step:7822 [D loss: 0.697108, acc.: 60.16%] [G loss: 1.025096]\n",
      "epoch:8 step:7823 [D loss: 0.570923, acc.: 69.53%] [G loss: 1.315422]\n",
      "epoch:8 step:7824 [D loss: 0.556349, acc.: 74.22%] [G loss: 1.125645]\n",
      "epoch:8 step:7825 [D loss: 0.670071, acc.: 57.03%] [G loss: 1.066450]\n",
      "epoch:8 step:7826 [D loss: 0.635280, acc.: 64.84%] [G loss: 1.152143]\n",
      "epoch:8 step:7827 [D loss: 0.676072, acc.: 59.38%] [G loss: 1.097486]\n",
      "epoch:8 step:7828 [D loss: 0.625638, acc.: 65.62%] [G loss: 0.941169]\n",
      "epoch:8 step:7829 [D loss: 0.564280, acc.: 74.22%] [G loss: 1.051032]\n",
      "epoch:8 step:7830 [D loss: 0.656827, acc.: 64.06%] [G loss: 0.997901]\n",
      "epoch:8 step:7831 [D loss: 0.580249, acc.: 71.09%] [G loss: 1.058417]\n",
      "epoch:8 step:7832 [D loss: 0.603136, acc.: 70.31%] [G loss: 1.251064]\n",
      "epoch:8 step:7833 [D loss: 0.602751, acc.: 68.75%] [G loss: 1.074334]\n",
      "epoch:8 step:7834 [D loss: 0.584507, acc.: 69.53%] [G loss: 1.260518]\n",
      "epoch:8 step:7835 [D loss: 0.674268, acc.: 57.03%] [G loss: 1.119906]\n",
      "epoch:8 step:7836 [D loss: 0.623113, acc.: 61.72%] [G loss: 1.202244]\n",
      "epoch:8 step:7837 [D loss: 0.670652, acc.: 62.50%] [G loss: 1.228590]\n",
      "epoch:8 step:7838 [D loss: 0.587083, acc.: 71.09%] [G loss: 1.087105]\n",
      "epoch:8 step:7839 [D loss: 0.645814, acc.: 61.72%] [G loss: 1.120266]\n",
      "epoch:8 step:7840 [D loss: 0.653789, acc.: 56.25%] [G loss: 1.110752]\n",
      "epoch:8 step:7841 [D loss: 0.607429, acc.: 64.84%] [G loss: 1.220345]\n",
      "epoch:8 step:7842 [D loss: 0.670342, acc.: 57.81%] [G loss: 1.094875]\n",
      "epoch:8 step:7843 [D loss: 0.695174, acc.: 57.81%] [G loss: 0.989436]\n",
      "epoch:8 step:7844 [D loss: 0.670067, acc.: 60.16%] [G loss: 0.929362]\n",
      "epoch:8 step:7845 [D loss: 0.601557, acc.: 67.97%] [G loss: 0.891390]\n",
      "epoch:8 step:7846 [D loss: 0.712521, acc.: 59.38%] [G loss: 1.042855]\n",
      "epoch:8 step:7847 [D loss: 0.595908, acc.: 73.44%] [G loss: 1.037528]\n",
      "epoch:8 step:7848 [D loss: 0.684886, acc.: 61.72%] [G loss: 0.910056]\n",
      "epoch:8 step:7849 [D loss: 0.619815, acc.: 63.28%] [G loss: 1.087971]\n",
      "epoch:8 step:7850 [D loss: 0.652591, acc.: 63.28%] [G loss: 1.051598]\n",
      "epoch:8 step:7851 [D loss: 0.619398, acc.: 64.06%] [G loss: 1.124820]\n",
      "epoch:8 step:7852 [D loss: 0.615619, acc.: 70.31%] [G loss: 1.151338]\n",
      "epoch:8 step:7853 [D loss: 0.593259, acc.: 64.06%] [G loss: 1.013003]\n",
      "epoch:8 step:7854 [D loss: 0.643379, acc.: 62.50%] [G loss: 1.112672]\n",
      "epoch:8 step:7855 [D loss: 0.646941, acc.: 64.84%] [G loss: 0.964682]\n",
      "epoch:8 step:7856 [D loss: 0.626163, acc.: 61.72%] [G loss: 1.094180]\n",
      "epoch:8 step:7857 [D loss: 0.596583, acc.: 71.09%] [G loss: 0.954570]\n",
      "epoch:8 step:7858 [D loss: 0.580196, acc.: 65.62%] [G loss: 1.169310]\n",
      "epoch:8 step:7859 [D loss: 0.621946, acc.: 67.19%] [G loss: 1.162585]\n",
      "epoch:8 step:7860 [D loss: 0.557030, acc.: 73.44%] [G loss: 0.998372]\n",
      "epoch:8 step:7861 [D loss: 0.598654, acc.: 62.50%] [G loss: 1.229060]\n",
      "epoch:8 step:7862 [D loss: 0.611908, acc.: 68.75%] [G loss: 0.962037]\n",
      "epoch:8 step:7863 [D loss: 0.767908, acc.: 57.81%] [G loss: 1.052768]\n",
      "epoch:8 step:7864 [D loss: 0.606526, acc.: 64.84%] [G loss: 1.153360]\n",
      "epoch:8 step:7865 [D loss: 0.668979, acc.: 59.38%] [G loss: 1.003112]\n",
      "epoch:8 step:7866 [D loss: 0.602220, acc.: 64.84%] [G loss: 1.022380]\n",
      "epoch:8 step:7867 [D loss: 0.668408, acc.: 63.28%] [G loss: 1.114611]\n",
      "epoch:8 step:7868 [D loss: 0.627616, acc.: 68.75%] [G loss: 1.174599]\n",
      "epoch:8 step:7869 [D loss: 0.611034, acc.: 70.31%] [G loss: 1.057241]\n",
      "epoch:8 step:7870 [D loss: 0.677560, acc.: 53.91%] [G loss: 1.134887]\n",
      "epoch:8 step:7871 [D loss: 0.611113, acc.: 64.06%] [G loss: 1.119849]\n",
      "epoch:8 step:7872 [D loss: 0.639641, acc.: 58.59%] [G loss: 1.063789]\n",
      "epoch:8 step:7873 [D loss: 0.566549, acc.: 73.44%] [G loss: 1.198011]\n",
      "epoch:8 step:7874 [D loss: 0.615706, acc.: 70.31%] [G loss: 1.101540]\n",
      "epoch:8 step:7875 [D loss: 0.672913, acc.: 60.16%] [G loss: 1.090491]\n",
      "epoch:8 step:7876 [D loss: 0.668052, acc.: 60.16%] [G loss: 1.007646]\n",
      "epoch:8 step:7877 [D loss: 0.637912, acc.: 61.72%] [G loss: 1.235248]\n",
      "epoch:8 step:7878 [D loss: 0.589801, acc.: 72.66%] [G loss: 1.111423]\n",
      "epoch:8 step:7879 [D loss: 0.599730, acc.: 64.84%] [G loss: 1.078091]\n",
      "epoch:8 step:7880 [D loss: 0.657655, acc.: 64.06%] [G loss: 1.070818]\n",
      "epoch:8 step:7881 [D loss: 0.723883, acc.: 57.81%] [G loss: 1.115161]\n",
      "epoch:8 step:7882 [D loss: 0.646199, acc.: 64.84%] [G loss: 1.008019]\n",
      "epoch:8 step:7883 [D loss: 0.641206, acc.: 63.28%] [G loss: 0.877084]\n",
      "epoch:8 step:7884 [D loss: 0.643940, acc.: 63.28%] [G loss: 1.052964]\n",
      "epoch:8 step:7885 [D loss: 0.710751, acc.: 54.69%] [G loss: 0.958789]\n",
      "epoch:8 step:7886 [D loss: 0.557253, acc.: 77.34%] [G loss: 1.047578]\n",
      "epoch:8 step:7887 [D loss: 0.719535, acc.: 52.34%] [G loss: 1.100598]\n",
      "epoch:8 step:7888 [D loss: 0.650994, acc.: 59.38%] [G loss: 0.932871]\n",
      "epoch:8 step:7889 [D loss: 0.687320, acc.: 61.72%] [G loss: 1.117116]\n",
      "epoch:8 step:7890 [D loss: 0.633363, acc.: 64.06%] [G loss: 1.019904]\n",
      "epoch:8 step:7891 [D loss: 0.610955, acc.: 62.50%] [G loss: 1.141655]\n",
      "epoch:8 step:7892 [D loss: 0.630393, acc.: 64.06%] [G loss: 1.004837]\n",
      "epoch:8 step:7893 [D loss: 0.642235, acc.: 62.50%] [G loss: 1.044127]\n",
      "epoch:8 step:7894 [D loss: 0.679850, acc.: 57.03%] [G loss: 1.076318]\n",
      "epoch:8 step:7895 [D loss: 0.558724, acc.: 70.31%] [G loss: 1.018210]\n",
      "epoch:8 step:7896 [D loss: 0.587764, acc.: 63.28%] [G loss: 1.018495]\n",
      "epoch:8 step:7897 [D loss: 0.571786, acc.: 72.66%] [G loss: 1.087684]\n",
      "epoch:8 step:7898 [D loss: 0.567181, acc.: 76.56%] [G loss: 0.964779]\n",
      "epoch:8 step:7899 [D loss: 0.554478, acc.: 71.88%] [G loss: 1.203045]\n",
      "epoch:8 step:7900 [D loss: 0.707229, acc.: 53.12%] [G loss: 0.958335]\n",
      "epoch:8 step:7901 [D loss: 0.610311, acc.: 66.41%] [G loss: 1.041783]\n",
      "epoch:8 step:7902 [D loss: 0.582890, acc.: 67.19%] [G loss: 0.987540]\n",
      "epoch:8 step:7903 [D loss: 0.671095, acc.: 60.94%] [G loss: 0.993277]\n",
      "epoch:8 step:7904 [D loss: 0.631741, acc.: 67.19%] [G loss: 0.910061]\n",
      "epoch:8 step:7905 [D loss: 0.589857, acc.: 69.53%] [G loss: 1.136935]\n",
      "epoch:8 step:7906 [D loss: 0.652869, acc.: 61.72%] [G loss: 1.004486]\n",
      "epoch:8 step:7907 [D loss: 0.734521, acc.: 56.25%] [G loss: 0.898730]\n",
      "epoch:8 step:7908 [D loss: 0.679930, acc.: 59.38%] [G loss: 1.077533]\n",
      "epoch:8 step:7909 [D loss: 0.601565, acc.: 66.41%] [G loss: 1.171768]\n",
      "epoch:8 step:7910 [D loss: 0.593210, acc.: 66.41%] [G loss: 1.155500]\n",
      "epoch:8 step:7911 [D loss: 0.709892, acc.: 56.25%] [G loss: 1.005128]\n",
      "epoch:8 step:7912 [D loss: 0.745817, acc.: 50.00%] [G loss: 1.038533]\n",
      "epoch:8 step:7913 [D loss: 0.609675, acc.: 64.06%] [G loss: 1.108214]\n",
      "epoch:8 step:7914 [D loss: 0.613582, acc.: 68.75%] [G loss: 1.135423]\n",
      "epoch:8 step:7915 [D loss: 0.645645, acc.: 62.50%] [G loss: 0.900224]\n",
      "epoch:8 step:7916 [D loss: 0.619058, acc.: 66.41%] [G loss: 0.933862]\n",
      "epoch:8 step:7917 [D loss: 0.549634, acc.: 77.34%] [G loss: 1.201035]\n",
      "epoch:8 step:7918 [D loss: 0.654111, acc.: 62.50%] [G loss: 1.099551]\n",
      "epoch:8 step:7919 [D loss: 0.671295, acc.: 62.50%] [G loss: 1.122724]\n",
      "epoch:8 step:7920 [D loss: 0.613888, acc.: 62.50%] [G loss: 0.996196]\n",
      "epoch:8 step:7921 [D loss: 0.735322, acc.: 51.56%] [G loss: 1.105178]\n",
      "epoch:8 step:7922 [D loss: 0.666971, acc.: 55.47%] [G loss: 1.163499]\n",
      "epoch:8 step:7923 [D loss: 0.659187, acc.: 64.84%] [G loss: 1.060236]\n",
      "epoch:8 step:7924 [D loss: 0.746247, acc.: 47.66%] [G loss: 1.063612]\n",
      "epoch:8 step:7925 [D loss: 0.672677, acc.: 59.38%] [G loss: 1.074381]\n",
      "epoch:8 step:7926 [D loss: 0.534322, acc.: 75.78%] [G loss: 1.187816]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:8 step:7927 [D loss: 0.610611, acc.: 64.06%] [G loss: 1.050473]\n",
      "epoch:8 step:7928 [D loss: 0.556541, acc.: 74.22%] [G loss: 1.064528]\n",
      "epoch:8 step:7929 [D loss: 0.611029, acc.: 67.97%] [G loss: 1.189532]\n",
      "epoch:8 step:7930 [D loss: 0.697543, acc.: 59.38%] [G loss: 1.037346]\n",
      "epoch:8 step:7931 [D loss: 0.702785, acc.: 54.69%] [G loss: 1.009518]\n",
      "epoch:8 step:7932 [D loss: 0.588461, acc.: 70.31%] [G loss: 1.199383]\n",
      "epoch:8 step:7933 [D loss: 0.625788, acc.: 64.06%] [G loss: 1.071947]\n",
      "epoch:8 step:7934 [D loss: 0.559277, acc.: 71.09%] [G loss: 1.145603]\n",
      "epoch:8 step:7935 [D loss: 0.539166, acc.: 73.44%] [G loss: 1.114179]\n",
      "epoch:8 step:7936 [D loss: 0.574343, acc.: 75.78%] [G loss: 1.033135]\n",
      "epoch:8 step:7937 [D loss: 0.531800, acc.: 72.66%] [G loss: 1.119871]\n",
      "epoch:8 step:7938 [D loss: 0.592613, acc.: 67.97%] [G loss: 0.993916]\n",
      "epoch:8 step:7939 [D loss: 0.537343, acc.: 75.78%] [G loss: 1.147589]\n",
      "epoch:8 step:7940 [D loss: 0.640011, acc.: 67.19%] [G loss: 0.931019]\n",
      "epoch:8 step:7941 [D loss: 0.547731, acc.: 71.09%] [G loss: 1.281471]\n",
      "epoch:8 step:7942 [D loss: 0.562352, acc.: 69.53%] [G loss: 1.320844]\n",
      "epoch:8 step:7943 [D loss: 0.671038, acc.: 56.25%] [G loss: 1.021334]\n",
      "epoch:8 step:7944 [D loss: 0.545482, acc.: 76.56%] [G loss: 1.013475]\n",
      "epoch:8 step:7945 [D loss: 0.610092, acc.: 68.75%] [G loss: 1.092395]\n",
      "epoch:8 step:7946 [D loss: 0.640075, acc.: 60.16%] [G loss: 1.214658]\n",
      "epoch:8 step:7947 [D loss: 0.546143, acc.: 75.00%] [G loss: 1.152079]\n",
      "epoch:8 step:7948 [D loss: 0.594095, acc.: 67.19%] [G loss: 1.202542]\n",
      "epoch:8 step:7949 [D loss: 0.494190, acc.: 78.12%] [G loss: 1.079077]\n",
      "epoch:8 step:7950 [D loss: 0.532866, acc.: 80.47%] [G loss: 1.012996]\n",
      "epoch:8 step:7951 [D loss: 0.617573, acc.: 64.06%] [G loss: 1.280115]\n",
      "epoch:8 step:7952 [D loss: 0.703464, acc.: 52.34%] [G loss: 0.942168]\n",
      "epoch:8 step:7953 [D loss: 0.636915, acc.: 60.16%] [G loss: 1.017891]\n",
      "epoch:8 step:7954 [D loss: 0.537559, acc.: 71.88%] [G loss: 1.161062]\n",
      "epoch:8 step:7955 [D loss: 0.672848, acc.: 57.81%] [G loss: 1.120193]\n",
      "epoch:8 step:7956 [D loss: 0.622824, acc.: 60.94%] [G loss: 0.921272]\n",
      "epoch:8 step:7957 [D loss: 0.634952, acc.: 61.72%] [G loss: 1.075366]\n",
      "epoch:8 step:7958 [D loss: 0.603869, acc.: 65.62%] [G loss: 1.154289]\n",
      "epoch:8 step:7959 [D loss: 0.693831, acc.: 57.03%] [G loss: 0.853638]\n",
      "epoch:8 step:7960 [D loss: 0.527811, acc.: 71.88%] [G loss: 1.106084]\n",
      "epoch:8 step:7961 [D loss: 0.645823, acc.: 60.94%] [G loss: 1.042284]\n",
      "epoch:8 step:7962 [D loss: 0.569970, acc.: 68.75%] [G loss: 1.053382]\n",
      "epoch:8 step:7963 [D loss: 0.673781, acc.: 62.50%] [G loss: 1.103102]\n",
      "epoch:8 step:7964 [D loss: 0.590323, acc.: 68.75%] [G loss: 1.178526]\n",
      "epoch:8 step:7965 [D loss: 0.609793, acc.: 64.84%] [G loss: 1.200251]\n",
      "epoch:8 step:7966 [D loss: 0.708393, acc.: 57.81%] [G loss: 0.981080]\n",
      "epoch:8 step:7967 [D loss: 0.574838, acc.: 66.41%] [G loss: 1.135135]\n",
      "epoch:8 step:7968 [D loss: 0.582789, acc.: 67.19%] [G loss: 1.190555]\n",
      "epoch:8 step:7969 [D loss: 0.597787, acc.: 71.09%] [G loss: 1.215174]\n",
      "epoch:8 step:7970 [D loss: 0.624529, acc.: 62.50%] [G loss: 1.010178]\n",
      "epoch:8 step:7971 [D loss: 0.642015, acc.: 61.72%] [G loss: 0.970176]\n",
      "epoch:8 step:7972 [D loss: 0.657651, acc.: 60.94%] [G loss: 0.883471]\n",
      "epoch:8 step:7973 [D loss: 0.689991, acc.: 56.25%] [G loss: 1.229454]\n",
      "epoch:8 step:7974 [D loss: 0.597651, acc.: 67.19%] [G loss: 1.190269]\n",
      "epoch:8 step:7975 [D loss: 0.588583, acc.: 67.19%] [G loss: 1.136269]\n",
      "epoch:8 step:7976 [D loss: 0.629708, acc.: 66.41%] [G loss: 1.198972]\n",
      "epoch:8 step:7977 [D loss: 0.691385, acc.: 59.38%] [G loss: 0.924068]\n",
      "epoch:8 step:7978 [D loss: 0.570690, acc.: 73.44%] [G loss: 1.104805]\n",
      "epoch:8 step:7979 [D loss: 0.668829, acc.: 64.84%] [G loss: 1.002041]\n",
      "epoch:8 step:7980 [D loss: 0.682923, acc.: 55.47%] [G loss: 1.055539]\n",
      "epoch:8 step:7981 [D loss: 0.656239, acc.: 60.94%] [G loss: 1.030722]\n",
      "epoch:8 step:7982 [D loss: 0.624580, acc.: 62.50%] [G loss: 1.007496]\n",
      "epoch:8 step:7983 [D loss: 0.603823, acc.: 62.50%] [G loss: 0.956126]\n",
      "epoch:8 step:7984 [D loss: 0.504132, acc.: 80.47%] [G loss: 1.173624]\n",
      "epoch:8 step:7985 [D loss: 0.678492, acc.: 57.81%] [G loss: 1.152426]\n",
      "epoch:8 step:7986 [D loss: 0.575442, acc.: 71.88%] [G loss: 1.205779]\n",
      "epoch:8 step:7987 [D loss: 0.579314, acc.: 69.53%] [G loss: 1.035781]\n",
      "epoch:8 step:7988 [D loss: 0.621982, acc.: 63.28%] [G loss: 1.174393]\n",
      "epoch:8 step:7989 [D loss: 0.589471, acc.: 70.31%] [G loss: 1.184810]\n",
      "epoch:8 step:7990 [D loss: 0.513991, acc.: 79.69%] [G loss: 1.294565]\n",
      "epoch:8 step:7991 [D loss: 0.596238, acc.: 65.62%] [G loss: 0.967389]\n",
      "epoch:8 step:7992 [D loss: 0.603672, acc.: 70.31%] [G loss: 0.887874]\n",
      "epoch:8 step:7993 [D loss: 0.639473, acc.: 58.59%] [G loss: 0.892187]\n",
      "epoch:8 step:7994 [D loss: 0.605107, acc.: 69.53%] [G loss: 1.134030]\n",
      "epoch:8 step:7995 [D loss: 0.683544, acc.: 59.38%] [G loss: 0.961478]\n",
      "epoch:8 step:7996 [D loss: 0.623169, acc.: 63.28%] [G loss: 0.961394]\n",
      "epoch:8 step:7997 [D loss: 0.586172, acc.: 67.97%] [G loss: 1.063407]\n",
      "epoch:8 step:7998 [D loss: 0.522337, acc.: 73.44%] [G loss: 1.040247]\n",
      "epoch:8 step:7999 [D loss: 0.759247, acc.: 54.69%] [G loss: 1.161279]\n",
      "epoch:8 step:8000 [D loss: 0.600961, acc.: 67.19%] [G loss: 1.165856]\n",
      "epoch:8 step:8001 [D loss: 0.550324, acc.: 71.88%] [G loss: 1.247577]\n",
      "epoch:8 step:8002 [D loss: 0.636491, acc.: 62.50%] [G loss: 1.154708]\n",
      "epoch:8 step:8003 [D loss: 0.648555, acc.: 60.16%] [G loss: 1.114954]\n",
      "epoch:8 step:8004 [D loss: 0.630259, acc.: 64.06%] [G loss: 1.162415]\n",
      "epoch:8 step:8005 [D loss: 0.632209, acc.: 62.50%] [G loss: 1.012198]\n",
      "epoch:8 step:8006 [D loss: 0.536659, acc.: 75.78%] [G loss: 1.274732]\n",
      "epoch:8 step:8007 [D loss: 0.708574, acc.: 57.81%] [G loss: 1.087945]\n",
      "epoch:8 step:8008 [D loss: 0.558360, acc.: 72.66%] [G loss: 1.021447]\n",
      "epoch:8 step:8009 [D loss: 0.570738, acc.: 67.97%] [G loss: 1.074913]\n",
      "epoch:8 step:8010 [D loss: 0.623223, acc.: 64.06%] [G loss: 1.220802]\n",
      "epoch:8 step:8011 [D loss: 0.512743, acc.: 76.56%] [G loss: 1.250724]\n",
      "epoch:8 step:8012 [D loss: 0.633315, acc.: 63.28%] [G loss: 1.216724]\n",
      "epoch:8 step:8013 [D loss: 0.735097, acc.: 52.34%] [G loss: 1.088389]\n",
      "epoch:8 step:8014 [D loss: 0.667786, acc.: 64.84%] [G loss: 1.018964]\n",
      "epoch:8 step:8015 [D loss: 0.616960, acc.: 63.28%] [G loss: 0.982543]\n",
      "epoch:8 step:8016 [D loss: 0.656912, acc.: 64.06%] [G loss: 1.210377]\n",
      "epoch:8 step:8017 [D loss: 0.621006, acc.: 67.97%] [G loss: 1.114221]\n",
      "epoch:8 step:8018 [D loss: 0.656224, acc.: 64.84%] [G loss: 1.165176]\n",
      "epoch:8 step:8019 [D loss: 0.535482, acc.: 75.00%] [G loss: 1.142988]\n",
      "epoch:8 step:8020 [D loss: 0.602669, acc.: 69.53%] [G loss: 1.133498]\n",
      "epoch:8 step:8021 [D loss: 0.674538, acc.: 58.59%] [G loss: 1.023339]\n",
      "epoch:8 step:8022 [D loss: 0.698434, acc.: 57.03%] [G loss: 0.921765]\n",
      "epoch:8 step:8023 [D loss: 0.682179, acc.: 49.22%] [G loss: 1.288805]\n",
      "epoch:8 step:8024 [D loss: 0.563778, acc.: 71.88%] [G loss: 1.160107]\n",
      "epoch:8 step:8025 [D loss: 0.665236, acc.: 59.38%] [G loss: 1.058360]\n",
      "epoch:8 step:8026 [D loss: 0.625059, acc.: 63.28%] [G loss: 0.992848]\n",
      "epoch:8 step:8027 [D loss: 0.483342, acc.: 83.59%] [G loss: 1.251150]\n",
      "epoch:8 step:8028 [D loss: 0.707697, acc.: 56.25%] [G loss: 0.939957]\n",
      "epoch:8 step:8029 [D loss: 0.648794, acc.: 63.28%] [G loss: 0.954485]\n",
      "epoch:8 step:8030 [D loss: 0.607083, acc.: 64.06%] [G loss: 1.177045]\n",
      "epoch:8 step:8031 [D loss: 0.652924, acc.: 60.16%] [G loss: 1.123975]\n",
      "epoch:8 step:8032 [D loss: 0.672587, acc.: 62.50%] [G loss: 0.928280]\n",
      "epoch:8 step:8033 [D loss: 0.638089, acc.: 62.50%] [G loss: 0.992542]\n",
      "epoch:8 step:8034 [D loss: 0.662793, acc.: 61.72%] [G loss: 0.954280]\n",
      "epoch:8 step:8035 [D loss: 0.605662, acc.: 71.88%] [G loss: 1.109507]\n",
      "epoch:8 step:8036 [D loss: 0.564156, acc.: 70.31%] [G loss: 1.193943]\n",
      "epoch:8 step:8037 [D loss: 0.607478, acc.: 65.62%] [G loss: 1.245686]\n",
      "epoch:8 step:8038 [D loss: 0.557951, acc.: 70.31%] [G loss: 0.986541]\n",
      "epoch:8 step:8039 [D loss: 0.671726, acc.: 64.06%] [G loss: 1.136834]\n",
      "epoch:8 step:8040 [D loss: 0.763552, acc.: 50.00%] [G loss: 1.035618]\n",
      "epoch:8 step:8041 [D loss: 0.716282, acc.: 54.69%] [G loss: 1.010382]\n",
      "epoch:8 step:8042 [D loss: 0.563674, acc.: 74.22%] [G loss: 1.203898]\n",
      "epoch:8 step:8043 [D loss: 0.693506, acc.: 55.47%] [G loss: 0.888400]\n",
      "epoch:8 step:8044 [D loss: 0.726195, acc.: 53.91%] [G loss: 0.913381]\n",
      "epoch:8 step:8045 [D loss: 0.624851, acc.: 64.06%] [G loss: 1.241689]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:8 step:8046 [D loss: 0.654686, acc.: 57.81%] [G loss: 1.045161]\n",
      "epoch:8 step:8047 [D loss: 0.696852, acc.: 60.94%] [G loss: 1.066123]\n",
      "epoch:8 step:8048 [D loss: 0.643577, acc.: 62.50%] [G loss: 1.172262]\n",
      "epoch:8 step:8049 [D loss: 0.575082, acc.: 71.09%] [G loss: 1.144484]\n",
      "epoch:8 step:8050 [D loss: 0.684207, acc.: 56.25%] [G loss: 1.012439]\n",
      "epoch:8 step:8051 [D loss: 0.604012, acc.: 68.75%] [G loss: 1.185244]\n",
      "epoch:8 step:8052 [D loss: 0.623661, acc.: 64.06%] [G loss: 1.054561]\n",
      "epoch:8 step:8053 [D loss: 0.595148, acc.: 70.31%] [G loss: 1.130314]\n",
      "epoch:8 step:8054 [D loss: 0.554237, acc.: 75.78%] [G loss: 1.123563]\n",
      "epoch:8 step:8055 [D loss: 0.643317, acc.: 63.28%] [G loss: 1.152184]\n",
      "epoch:8 step:8056 [D loss: 0.624033, acc.: 64.06%] [G loss: 1.189274]\n",
      "epoch:8 step:8057 [D loss: 0.605074, acc.: 67.19%] [G loss: 1.045016]\n",
      "epoch:8 step:8058 [D loss: 0.596353, acc.: 68.75%] [G loss: 1.069819]\n",
      "epoch:8 step:8059 [D loss: 0.593942, acc.: 70.31%] [G loss: 0.976127]\n",
      "epoch:8 step:8060 [D loss: 0.537461, acc.: 75.78%] [G loss: 0.956606]\n",
      "epoch:8 step:8061 [D loss: 0.542601, acc.: 78.12%] [G loss: 1.101543]\n",
      "epoch:8 step:8062 [D loss: 0.593356, acc.: 67.97%] [G loss: 0.975735]\n",
      "epoch:8 step:8063 [D loss: 0.586976, acc.: 64.06%] [G loss: 1.025351]\n",
      "epoch:8 step:8064 [D loss: 0.722328, acc.: 51.56%] [G loss: 0.810850]\n",
      "epoch:8 step:8065 [D loss: 0.572158, acc.: 75.78%] [G loss: 1.075141]\n",
      "epoch:8 step:8066 [D loss: 0.685439, acc.: 54.69%] [G loss: 0.970794]\n",
      "epoch:8 step:8067 [D loss: 0.674005, acc.: 59.38%] [G loss: 1.204953]\n",
      "epoch:8 step:8068 [D loss: 0.575618, acc.: 71.88%] [G loss: 1.074776]\n",
      "epoch:8 step:8069 [D loss: 0.665232, acc.: 60.94%] [G loss: 1.146291]\n",
      "epoch:8 step:8070 [D loss: 0.612999, acc.: 64.84%] [G loss: 1.076325]\n",
      "epoch:8 step:8071 [D loss: 0.610722, acc.: 64.06%] [G loss: 1.272663]\n",
      "epoch:8 step:8072 [D loss: 0.604145, acc.: 65.62%] [G loss: 0.970586]\n",
      "epoch:8 step:8073 [D loss: 0.683301, acc.: 60.94%] [G loss: 1.167515]\n",
      "epoch:8 step:8074 [D loss: 0.514689, acc.: 80.47%] [G loss: 1.216141]\n",
      "epoch:8 step:8075 [D loss: 0.624517, acc.: 62.50%] [G loss: 1.216336]\n",
      "epoch:8 step:8076 [D loss: 0.604527, acc.: 67.97%] [G loss: 1.015867]\n",
      "epoch:8 step:8077 [D loss: 0.623644, acc.: 64.06%] [G loss: 1.108762]\n",
      "epoch:8 step:8078 [D loss: 0.749887, acc.: 50.00%] [G loss: 1.125878]\n",
      "epoch:8 step:8079 [D loss: 0.673441, acc.: 60.94%] [G loss: 0.903560]\n",
      "epoch:8 step:8080 [D loss: 0.649106, acc.: 63.28%] [G loss: 1.206095]\n",
      "epoch:8 step:8081 [D loss: 0.596304, acc.: 68.75%] [G loss: 1.140556]\n",
      "epoch:8 step:8082 [D loss: 0.623476, acc.: 71.88%] [G loss: 1.005667]\n",
      "epoch:8 step:8083 [D loss: 0.514128, acc.: 80.47%] [G loss: 1.197367]\n",
      "epoch:8 step:8084 [D loss: 0.583385, acc.: 70.31%] [G loss: 1.261036]\n",
      "epoch:8 step:8085 [D loss: 0.641914, acc.: 64.84%] [G loss: 1.159370]\n",
      "epoch:8 step:8086 [D loss: 0.554770, acc.: 69.53%] [G loss: 1.153005]\n",
      "epoch:8 step:8087 [D loss: 0.581762, acc.: 71.09%] [G loss: 0.961062]\n",
      "epoch:8 step:8088 [D loss: 0.588724, acc.: 67.19%] [G loss: 1.184285]\n",
      "epoch:8 step:8089 [D loss: 0.631656, acc.: 60.94%] [G loss: 1.179214]\n",
      "epoch:8 step:8090 [D loss: 0.573969, acc.: 74.22%] [G loss: 1.209635]\n",
      "epoch:8 step:8091 [D loss: 0.728413, acc.: 50.78%] [G loss: 0.883070]\n",
      "epoch:8 step:8092 [D loss: 0.595548, acc.: 68.75%] [G loss: 1.174701]\n",
      "epoch:8 step:8093 [D loss: 0.606697, acc.: 66.41%] [G loss: 1.244437]\n",
      "epoch:8 step:8094 [D loss: 0.657645, acc.: 57.81%] [G loss: 1.067222]\n",
      "epoch:8 step:8095 [D loss: 0.569737, acc.: 68.75%] [G loss: 1.133032]\n",
      "epoch:8 step:8096 [D loss: 0.533892, acc.: 75.00%] [G loss: 1.156210]\n",
      "epoch:8 step:8097 [D loss: 0.683324, acc.: 54.69%] [G loss: 1.069273]\n",
      "epoch:8 step:8098 [D loss: 0.542652, acc.: 73.44%] [G loss: 1.166351]\n",
      "epoch:8 step:8099 [D loss: 0.678230, acc.: 57.81%] [G loss: 1.158822]\n",
      "epoch:8 step:8100 [D loss: 0.686361, acc.: 53.91%] [G loss: 1.170342]\n",
      "epoch:8 step:8101 [D loss: 0.677315, acc.: 63.28%] [G loss: 0.872513]\n",
      "epoch:8 step:8102 [D loss: 0.782249, acc.: 52.34%] [G loss: 1.053365]\n",
      "epoch:8 step:8103 [D loss: 0.633718, acc.: 65.62%] [G loss: 1.078688]\n",
      "epoch:8 step:8104 [D loss: 0.582836, acc.: 65.62%] [G loss: 1.324753]\n",
      "epoch:8 step:8105 [D loss: 0.671556, acc.: 58.59%] [G loss: 0.945869]\n",
      "epoch:8 step:8106 [D loss: 0.639620, acc.: 64.84%] [G loss: 1.064961]\n",
      "epoch:8 step:8107 [D loss: 0.706602, acc.: 58.59%] [G loss: 1.045640]\n",
      "epoch:8 step:8108 [D loss: 0.615705, acc.: 66.41%] [G loss: 1.054339]\n",
      "epoch:8 step:8109 [D loss: 0.773847, acc.: 48.44%] [G loss: 1.031968]\n",
      "epoch:8 step:8110 [D loss: 0.664933, acc.: 60.16%] [G loss: 1.273189]\n",
      "epoch:8 step:8111 [D loss: 0.551872, acc.: 73.44%] [G loss: 1.194770]\n",
      "epoch:8 step:8112 [D loss: 0.519607, acc.: 76.56%] [G loss: 1.162062]\n",
      "epoch:8 step:8113 [D loss: 0.693501, acc.: 59.38%] [G loss: 1.007266]\n",
      "epoch:8 step:8114 [D loss: 0.575661, acc.: 71.88%] [G loss: 1.039764]\n",
      "epoch:8 step:8115 [D loss: 0.744527, acc.: 52.34%] [G loss: 0.897756]\n",
      "epoch:8 step:8116 [D loss: 0.713160, acc.: 53.91%] [G loss: 0.967613]\n",
      "epoch:8 step:8117 [D loss: 0.729103, acc.: 53.91%] [G loss: 0.954724]\n",
      "epoch:8 step:8118 [D loss: 0.539016, acc.: 70.31%] [G loss: 1.215967]\n",
      "epoch:8 step:8119 [D loss: 0.636814, acc.: 65.62%] [G loss: 0.957262]\n",
      "epoch:8 step:8120 [D loss: 0.593828, acc.: 65.62%] [G loss: 1.224688]\n",
      "epoch:8 step:8121 [D loss: 0.561067, acc.: 70.31%] [G loss: 1.085128]\n",
      "epoch:8 step:8122 [D loss: 0.621939, acc.: 64.06%] [G loss: 1.104006]\n",
      "epoch:8 step:8123 [D loss: 0.512488, acc.: 78.91%] [G loss: 0.981853]\n",
      "epoch:8 step:8124 [D loss: 0.596515, acc.: 69.53%] [G loss: 1.223115]\n",
      "epoch:8 step:8125 [D loss: 0.731228, acc.: 50.78%] [G loss: 0.795447]\n",
      "epoch:8 step:8126 [D loss: 0.613688, acc.: 69.53%] [G loss: 1.102419]\n",
      "epoch:8 step:8127 [D loss: 0.591573, acc.: 70.31%] [G loss: 1.117179]\n",
      "epoch:8 step:8128 [D loss: 0.657363, acc.: 61.72%] [G loss: 1.061159]\n",
      "epoch:8 step:8129 [D loss: 0.561685, acc.: 74.22%] [G loss: 1.112028]\n",
      "epoch:8 step:8130 [D loss: 0.548334, acc.: 72.66%] [G loss: 1.110712]\n",
      "epoch:8 step:8131 [D loss: 0.581675, acc.: 71.88%] [G loss: 1.402836]\n",
      "epoch:8 step:8132 [D loss: 0.688276, acc.: 57.81%] [G loss: 1.115561]\n",
      "epoch:8 step:8133 [D loss: 0.608909, acc.: 66.41%] [G loss: 1.106035]\n",
      "epoch:8 step:8134 [D loss: 0.615072, acc.: 66.41%] [G loss: 0.911687]\n",
      "epoch:8 step:8135 [D loss: 0.726978, acc.: 51.56%] [G loss: 0.933673]\n",
      "epoch:8 step:8136 [D loss: 0.720581, acc.: 52.34%] [G loss: 1.053411]\n",
      "epoch:8 step:8137 [D loss: 0.594301, acc.: 64.84%] [G loss: 1.040107]\n",
      "epoch:8 step:8138 [D loss: 0.634388, acc.: 61.72%] [G loss: 1.075186]\n",
      "epoch:8 step:8139 [D loss: 0.665875, acc.: 63.28%] [G loss: 1.182374]\n",
      "epoch:8 step:8140 [D loss: 0.657235, acc.: 58.59%] [G loss: 1.081911]\n",
      "epoch:8 step:8141 [D loss: 0.575229, acc.: 72.66%] [G loss: 1.027361]\n",
      "epoch:8 step:8142 [D loss: 0.623152, acc.: 67.97%] [G loss: 1.077479]\n",
      "epoch:8 step:8143 [D loss: 0.611340, acc.: 71.09%] [G loss: 0.963414]\n",
      "epoch:8 step:8144 [D loss: 0.533843, acc.: 74.22%] [G loss: 1.188335]\n",
      "epoch:8 step:8145 [D loss: 0.555128, acc.: 72.66%] [G loss: 1.034209]\n",
      "epoch:8 step:8146 [D loss: 0.643169, acc.: 65.62%] [G loss: 1.045591]\n",
      "epoch:8 step:8147 [D loss: 0.643696, acc.: 67.19%] [G loss: 0.966505]\n",
      "epoch:8 step:8148 [D loss: 0.703862, acc.: 53.91%] [G loss: 1.056873]\n",
      "epoch:8 step:8149 [D loss: 0.566079, acc.: 74.22%] [G loss: 1.039838]\n",
      "epoch:8 step:8150 [D loss: 0.569650, acc.: 71.88%] [G loss: 1.209382]\n",
      "epoch:8 step:8151 [D loss: 0.615249, acc.: 67.97%] [G loss: 1.119362]\n",
      "epoch:8 step:8152 [D loss: 0.628886, acc.: 64.06%] [G loss: 1.082421]\n",
      "epoch:8 step:8153 [D loss: 0.678992, acc.: 58.59%] [G loss: 0.934812]\n",
      "epoch:8 step:8154 [D loss: 0.564975, acc.: 72.66%] [G loss: 1.022947]\n",
      "epoch:8 step:8155 [D loss: 0.619198, acc.: 64.84%] [G loss: 1.045326]\n",
      "epoch:8 step:8156 [D loss: 0.581918, acc.: 71.09%] [G loss: 1.112604]\n",
      "epoch:8 step:8157 [D loss: 0.718063, acc.: 55.47%] [G loss: 0.994047]\n",
      "epoch:8 step:8158 [D loss: 0.677307, acc.: 53.91%] [G loss: 1.088622]\n",
      "epoch:8 step:8159 [D loss: 0.697840, acc.: 63.28%] [G loss: 1.097195]\n",
      "epoch:8 step:8160 [D loss: 0.739717, acc.: 61.72%] [G loss: 1.015460]\n",
      "epoch:8 step:8161 [D loss: 0.615822, acc.: 65.62%] [G loss: 1.146544]\n",
      "epoch:8 step:8162 [D loss: 0.600990, acc.: 67.19%] [G loss: 1.083547]\n",
      "epoch:8 step:8163 [D loss: 0.576242, acc.: 69.53%] [G loss: 0.996261]\n",
      "epoch:8 step:8164 [D loss: 0.658409, acc.: 58.59%] [G loss: 1.220438]\n",
      "epoch:8 step:8165 [D loss: 0.537085, acc.: 74.22%] [G loss: 1.107975]\n",
      "epoch:8 step:8166 [D loss: 0.639028, acc.: 60.94%] [G loss: 1.036321]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:8 step:8167 [D loss: 0.664467, acc.: 60.16%] [G loss: 1.029718]\n",
      "epoch:8 step:8168 [D loss: 0.544858, acc.: 74.22%] [G loss: 1.153739]\n",
      "epoch:8 step:8169 [D loss: 0.669707, acc.: 61.72%] [G loss: 1.139260]\n",
      "epoch:8 step:8170 [D loss: 0.630736, acc.: 63.28%] [G loss: 1.093716]\n",
      "epoch:8 step:8171 [D loss: 0.649910, acc.: 63.28%] [G loss: 1.127352]\n",
      "epoch:8 step:8172 [D loss: 0.588511, acc.: 64.06%] [G loss: 1.103209]\n",
      "epoch:8 step:8173 [D loss: 0.648226, acc.: 65.62%] [G loss: 1.122614]\n",
      "epoch:8 step:8174 [D loss: 0.561795, acc.: 74.22%] [G loss: 1.065796]\n",
      "epoch:8 step:8175 [D loss: 0.589734, acc.: 66.41%] [G loss: 1.101285]\n",
      "epoch:8 step:8176 [D loss: 0.660071, acc.: 63.28%] [G loss: 1.154091]\n",
      "epoch:8 step:8177 [D loss: 0.534753, acc.: 77.34%] [G loss: 1.087945]\n",
      "epoch:8 step:8178 [D loss: 0.624222, acc.: 64.06%] [G loss: 1.149421]\n",
      "epoch:8 step:8179 [D loss: 0.682110, acc.: 61.72%] [G loss: 1.037869]\n",
      "epoch:8 step:8180 [D loss: 0.538337, acc.: 75.00%] [G loss: 1.048164]\n",
      "epoch:8 step:8181 [D loss: 0.693190, acc.: 60.94%] [G loss: 1.061147]\n",
      "epoch:8 step:8182 [D loss: 0.594417, acc.: 68.75%] [G loss: 1.105337]\n",
      "epoch:8 step:8183 [D loss: 0.587184, acc.: 70.31%] [G loss: 1.111968]\n",
      "epoch:8 step:8184 [D loss: 0.570743, acc.: 71.88%] [G loss: 1.035831]\n",
      "epoch:8 step:8185 [D loss: 0.614874, acc.: 64.06%] [G loss: 1.344437]\n",
      "epoch:8 step:8186 [D loss: 0.564512, acc.: 70.31%] [G loss: 1.148443]\n",
      "epoch:8 step:8187 [D loss: 0.606147, acc.: 65.62%] [G loss: 1.213702]\n",
      "epoch:8 step:8188 [D loss: 0.549234, acc.: 75.00%] [G loss: 1.183383]\n",
      "epoch:8 step:8189 [D loss: 0.680002, acc.: 57.03%] [G loss: 1.036192]\n",
      "epoch:8 step:8190 [D loss: 0.558833, acc.: 72.66%] [G loss: 1.319103]\n",
      "epoch:8 step:8191 [D loss: 0.561072, acc.: 71.09%] [G loss: 1.253515]\n",
      "epoch:8 step:8192 [D loss: 0.628160, acc.: 70.31%] [G loss: 1.061333]\n",
      "epoch:8 step:8193 [D loss: 0.610857, acc.: 68.75%] [G loss: 1.211826]\n",
      "epoch:8 step:8194 [D loss: 0.654551, acc.: 59.38%] [G loss: 0.899892]\n",
      "epoch:8 step:8195 [D loss: 0.640103, acc.: 64.06%] [G loss: 1.050722]\n",
      "epoch:8 step:8196 [D loss: 0.673419, acc.: 60.16%] [G loss: 1.153975]\n",
      "epoch:8 step:8197 [D loss: 0.544732, acc.: 73.44%] [G loss: 1.021124]\n",
      "epoch:8 step:8198 [D loss: 0.540236, acc.: 79.69%] [G loss: 1.047877]\n",
      "epoch:8 step:8199 [D loss: 0.646613, acc.: 62.50%] [G loss: 1.235174]\n",
      "epoch:8 step:8200 [D loss: 0.630948, acc.: 67.19%] [G loss: 1.045758]\n",
      "epoch:8 step:8201 [D loss: 0.504999, acc.: 81.25%] [G loss: 1.062845]\n",
      "epoch:8 step:8202 [D loss: 0.626129, acc.: 65.62%] [G loss: 1.233886]\n",
      "epoch:8 step:8203 [D loss: 0.563669, acc.: 65.62%] [G loss: 1.041304]\n",
      "epoch:8 step:8204 [D loss: 0.641516, acc.: 60.16%] [G loss: 1.023788]\n",
      "epoch:8 step:8205 [D loss: 0.786988, acc.: 44.53%] [G loss: 0.841646]\n",
      "epoch:8 step:8206 [D loss: 0.646816, acc.: 60.94%] [G loss: 0.982503]\n",
      "epoch:8 step:8207 [D loss: 0.639645, acc.: 67.19%] [G loss: 1.162601]\n",
      "epoch:8 step:8208 [D loss: 0.617022, acc.: 63.28%] [G loss: 1.144331]\n",
      "epoch:8 step:8209 [D loss: 0.673639, acc.: 54.69%] [G loss: 0.953467]\n",
      "epoch:8 step:8210 [D loss: 0.634093, acc.: 59.38%] [G loss: 1.103227]\n",
      "epoch:8 step:8211 [D loss: 0.619289, acc.: 67.19%] [G loss: 1.116719]\n",
      "epoch:8 step:8212 [D loss: 0.637094, acc.: 63.28%] [G loss: 1.175508]\n",
      "epoch:8 step:8213 [D loss: 0.633278, acc.: 64.84%] [G loss: 1.071022]\n",
      "epoch:8 step:8214 [D loss: 0.606672, acc.: 67.97%] [G loss: 1.077168]\n",
      "epoch:8 step:8215 [D loss: 0.660481, acc.: 57.03%] [G loss: 1.198416]\n",
      "epoch:8 step:8216 [D loss: 0.604197, acc.: 64.06%] [G loss: 1.050882]\n",
      "epoch:8 step:8217 [D loss: 0.552308, acc.: 69.53%] [G loss: 1.145695]\n",
      "epoch:8 step:8218 [D loss: 0.623843, acc.: 63.28%] [G loss: 0.942609]\n",
      "epoch:8 step:8219 [D loss: 0.623007, acc.: 63.28%] [G loss: 1.099787]\n",
      "epoch:8 step:8220 [D loss: 0.589279, acc.: 71.09%] [G loss: 1.152828]\n",
      "epoch:8 step:8221 [D loss: 0.600768, acc.: 65.62%] [G loss: 1.147421]\n",
      "epoch:8 step:8222 [D loss: 0.597581, acc.: 73.44%] [G loss: 0.998881]\n",
      "epoch:8 step:8223 [D loss: 0.508355, acc.: 78.91%] [G loss: 1.243540]\n",
      "epoch:8 step:8224 [D loss: 0.692909, acc.: 57.03%] [G loss: 1.021915]\n",
      "epoch:8 step:8225 [D loss: 0.605973, acc.: 71.09%] [G loss: 0.920619]\n",
      "epoch:8 step:8226 [D loss: 0.609233, acc.: 64.06%] [G loss: 1.245341]\n",
      "epoch:8 step:8227 [D loss: 0.743407, acc.: 54.69%] [G loss: 0.995754]\n",
      "epoch:8 step:8228 [D loss: 0.626778, acc.: 68.75%] [G loss: 0.923810]\n",
      "epoch:8 step:8229 [D loss: 0.629311, acc.: 62.50%] [G loss: 1.102989]\n",
      "epoch:8 step:8230 [D loss: 0.470561, acc.: 85.16%] [G loss: 1.283792]\n",
      "epoch:8 step:8231 [D loss: 0.679509, acc.: 60.94%] [G loss: 1.030667]\n",
      "epoch:8 step:8232 [D loss: 0.722506, acc.: 57.03%] [G loss: 0.895930]\n",
      "epoch:8 step:8233 [D loss: 0.700210, acc.: 55.47%] [G loss: 0.938298]\n",
      "epoch:8 step:8234 [D loss: 0.654913, acc.: 62.50%] [G loss: 1.066571]\n",
      "epoch:8 step:8235 [D loss: 0.637621, acc.: 65.62%] [G loss: 1.085630]\n",
      "epoch:8 step:8236 [D loss: 0.554151, acc.: 77.34%] [G loss: 1.131781]\n",
      "epoch:8 step:8237 [D loss: 0.590041, acc.: 68.75%] [G loss: 0.857289]\n",
      "epoch:8 step:8238 [D loss: 0.620837, acc.: 64.84%] [G loss: 1.005363]\n",
      "epoch:8 step:8239 [D loss: 0.661079, acc.: 60.94%] [G loss: 1.086642]\n",
      "epoch:8 step:8240 [D loss: 0.525102, acc.: 84.38%] [G loss: 1.049318]\n",
      "epoch:8 step:8241 [D loss: 0.547213, acc.: 72.66%] [G loss: 1.194147]\n",
      "epoch:8 step:8242 [D loss: 0.720904, acc.: 55.47%] [G loss: 0.982120]\n",
      "epoch:8 step:8243 [D loss: 0.593395, acc.: 66.41%] [G loss: 1.110432]\n",
      "epoch:8 step:8244 [D loss: 0.544188, acc.: 75.00%] [G loss: 1.172386]\n",
      "epoch:8 step:8245 [D loss: 0.746648, acc.: 51.56%] [G loss: 1.038709]\n",
      "epoch:8 step:8246 [D loss: 0.604547, acc.: 67.19%] [G loss: 1.121703]\n",
      "epoch:8 step:8247 [D loss: 0.667911, acc.: 60.94%] [G loss: 1.096531]\n",
      "epoch:8 step:8248 [D loss: 0.615590, acc.: 62.50%] [G loss: 1.133567]\n",
      "epoch:8 step:8249 [D loss: 0.613250, acc.: 67.97%] [G loss: 1.156678]\n",
      "epoch:8 step:8250 [D loss: 0.690117, acc.: 55.47%] [G loss: 1.123182]\n",
      "epoch:8 step:8251 [D loss: 0.653997, acc.: 60.94%] [G loss: 0.999831]\n",
      "epoch:8 step:8252 [D loss: 0.582671, acc.: 70.31%] [G loss: 1.272863]\n",
      "epoch:8 step:8253 [D loss: 0.671571, acc.: 61.72%] [G loss: 1.143758]\n",
      "epoch:8 step:8254 [D loss: 0.603639, acc.: 66.41%] [G loss: 1.294073]\n",
      "epoch:8 step:8255 [D loss: 0.642210, acc.: 67.97%] [G loss: 0.917000]\n",
      "epoch:8 step:8256 [D loss: 0.558256, acc.: 75.78%] [G loss: 1.107493]\n",
      "epoch:8 step:8257 [D loss: 0.683434, acc.: 57.03%] [G loss: 1.107323]\n",
      "epoch:8 step:8258 [D loss: 0.632010, acc.: 58.59%] [G loss: 0.976082]\n",
      "epoch:8 step:8259 [D loss: 0.601272, acc.: 66.41%] [G loss: 0.898659]\n",
      "epoch:8 step:8260 [D loss: 0.575693, acc.: 63.28%] [G loss: 1.213085]\n",
      "epoch:8 step:8261 [D loss: 0.603970, acc.: 72.66%] [G loss: 1.157326]\n",
      "epoch:8 step:8262 [D loss: 0.589300, acc.: 69.53%] [G loss: 1.127708]\n",
      "epoch:8 step:8263 [D loss: 0.675747, acc.: 62.50%] [G loss: 0.869038]\n",
      "epoch:8 step:8264 [D loss: 0.620462, acc.: 60.16%] [G loss: 1.170408]\n",
      "epoch:8 step:8265 [D loss: 0.597063, acc.: 67.19%] [G loss: 1.236915]\n",
      "epoch:8 step:8266 [D loss: 0.628272, acc.: 57.03%] [G loss: 1.137650]\n",
      "epoch:8 step:8267 [D loss: 0.642423, acc.: 63.28%] [G loss: 0.971684]\n",
      "epoch:8 step:8268 [D loss: 0.605610, acc.: 67.19%] [G loss: 1.054486]\n",
      "epoch:8 step:8269 [D loss: 0.679734, acc.: 59.38%] [G loss: 1.128689]\n",
      "epoch:8 step:8270 [D loss: 0.625732, acc.: 63.28%] [G loss: 1.375812]\n",
      "epoch:8 step:8271 [D loss: 0.625832, acc.: 64.84%] [G loss: 1.236213]\n",
      "epoch:8 step:8272 [D loss: 0.612730, acc.: 65.62%] [G loss: 1.143707]\n",
      "epoch:8 step:8273 [D loss: 0.646676, acc.: 62.50%] [G loss: 1.011343]\n",
      "epoch:8 step:8274 [D loss: 0.566237, acc.: 75.00%] [G loss: 1.236039]\n",
      "epoch:8 step:8275 [D loss: 0.658432, acc.: 64.84%] [G loss: 1.102221]\n",
      "epoch:8 step:8276 [D loss: 0.682998, acc.: 57.03%] [G loss: 1.003717]\n",
      "epoch:8 step:8277 [D loss: 0.628280, acc.: 63.28%] [G loss: 0.965535]\n",
      "epoch:8 step:8278 [D loss: 0.549897, acc.: 73.44%] [G loss: 0.992408]\n",
      "epoch:8 step:8279 [D loss: 0.553553, acc.: 73.44%] [G loss: 1.110819]\n",
      "epoch:8 step:8280 [D loss: 0.677068, acc.: 60.16%] [G loss: 1.129451]\n",
      "epoch:8 step:8281 [D loss: 0.654643, acc.: 63.28%] [G loss: 1.042885]\n",
      "epoch:8 step:8282 [D loss: 0.569667, acc.: 73.44%] [G loss: 1.174072]\n",
      "epoch:8 step:8283 [D loss: 0.566765, acc.: 69.53%] [G loss: 1.031586]\n",
      "epoch:8 step:8284 [D loss: 0.752143, acc.: 55.47%] [G loss: 0.908223]\n",
      "epoch:8 step:8285 [D loss: 0.565513, acc.: 71.88%] [G loss: 1.084792]\n",
      "epoch:8 step:8286 [D loss: 0.647307, acc.: 59.38%] [G loss: 1.045715]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:8 step:8287 [D loss: 0.626362, acc.: 70.31%] [G loss: 1.129491]\n",
      "epoch:8 step:8288 [D loss: 0.704569, acc.: 58.59%] [G loss: 1.066305]\n",
      "epoch:8 step:8289 [D loss: 0.647915, acc.: 62.50%] [G loss: 0.933235]\n",
      "epoch:8 step:8290 [D loss: 0.592440, acc.: 67.19%] [G loss: 1.246360]\n",
      "epoch:8 step:8291 [D loss: 0.570130, acc.: 74.22%] [G loss: 1.075098]\n",
      "epoch:8 step:8292 [D loss: 0.707286, acc.: 55.47%] [G loss: 1.081750]\n",
      "epoch:8 step:8293 [D loss: 0.604791, acc.: 64.06%] [G loss: 1.033734]\n",
      "epoch:8 step:8294 [D loss: 0.527607, acc.: 74.22%] [G loss: 1.078760]\n",
      "epoch:8 step:8295 [D loss: 0.647987, acc.: 57.81%] [G loss: 0.980720]\n",
      "epoch:8 step:8296 [D loss: 0.551564, acc.: 75.00%] [G loss: 1.092952]\n",
      "epoch:8 step:8297 [D loss: 0.677958, acc.: 57.81%] [G loss: 0.851876]\n",
      "epoch:8 step:8298 [D loss: 0.723658, acc.: 53.12%] [G loss: 1.084934]\n",
      "epoch:8 step:8299 [D loss: 0.654558, acc.: 64.06%] [G loss: 0.927872]\n",
      "epoch:8 step:8300 [D loss: 0.630534, acc.: 62.50%] [G loss: 1.153859]\n",
      "epoch:8 step:8301 [D loss: 0.635841, acc.: 68.75%] [G loss: 1.039255]\n",
      "epoch:8 step:8302 [D loss: 0.535750, acc.: 74.22%] [G loss: 0.888277]\n",
      "epoch:8 step:8303 [D loss: 0.625679, acc.: 59.38%] [G loss: 1.249294]\n",
      "epoch:8 step:8304 [D loss: 0.622211, acc.: 67.19%] [G loss: 1.164593]\n",
      "epoch:8 step:8305 [D loss: 0.615144, acc.: 67.97%] [G loss: 1.332598]\n",
      "epoch:8 step:8306 [D loss: 0.639717, acc.: 64.06%] [G loss: 1.172817]\n",
      "epoch:8 step:8307 [D loss: 0.620028, acc.: 65.62%] [G loss: 1.125434]\n",
      "epoch:8 step:8308 [D loss: 0.643434, acc.: 62.50%] [G loss: 0.966234]\n",
      "epoch:8 step:8309 [D loss: 0.694977, acc.: 58.59%] [G loss: 1.117312]\n",
      "epoch:8 step:8310 [D loss: 0.523583, acc.: 74.22%] [G loss: 1.124928]\n",
      "epoch:8 step:8311 [D loss: 0.687511, acc.: 54.69%] [G loss: 1.136478]\n",
      "epoch:8 step:8312 [D loss: 0.513340, acc.: 78.91%] [G loss: 1.245582]\n",
      "epoch:8 step:8313 [D loss: 0.730485, acc.: 55.47%] [G loss: 1.119472]\n",
      "epoch:8 step:8314 [D loss: 0.629921, acc.: 67.19%] [G loss: 1.071027]\n",
      "epoch:8 step:8315 [D loss: 0.549610, acc.: 75.00%] [G loss: 1.280715]\n",
      "epoch:8 step:8316 [D loss: 0.653337, acc.: 64.84%] [G loss: 1.141394]\n",
      "epoch:8 step:8317 [D loss: 0.540993, acc.: 70.31%] [G loss: 1.041745]\n",
      "epoch:8 step:8318 [D loss: 0.570050, acc.: 71.88%] [G loss: 1.158558]\n",
      "epoch:8 step:8319 [D loss: 0.656131, acc.: 66.41%] [G loss: 1.089410]\n",
      "epoch:8 step:8320 [D loss: 0.628157, acc.: 68.75%] [G loss: 0.953642]\n",
      "epoch:8 step:8321 [D loss: 0.576325, acc.: 74.22%] [G loss: 1.250277]\n",
      "epoch:8 step:8322 [D loss: 0.485491, acc.: 80.47%] [G loss: 1.263227]\n",
      "epoch:8 step:8323 [D loss: 0.583892, acc.: 67.19%] [G loss: 1.108226]\n",
      "epoch:8 step:8324 [D loss: 0.680507, acc.: 57.03%] [G loss: 1.098680]\n",
      "epoch:8 step:8325 [D loss: 0.648907, acc.: 59.38%] [G loss: 0.959126]\n",
      "epoch:8 step:8326 [D loss: 0.598579, acc.: 72.66%] [G loss: 1.051538]\n",
      "epoch:8 step:8327 [D loss: 0.662446, acc.: 57.81%] [G loss: 1.121401]\n",
      "epoch:8 step:8328 [D loss: 0.571083, acc.: 68.75%] [G loss: 1.023238]\n",
      "epoch:8 step:8329 [D loss: 0.608467, acc.: 67.19%] [G loss: 0.948668]\n",
      "epoch:8 step:8330 [D loss: 0.682985, acc.: 57.81%] [G loss: 0.906829]\n",
      "epoch:8 step:8331 [D loss: 0.587001, acc.: 70.31%] [G loss: 1.295113]\n",
      "epoch:8 step:8332 [D loss: 0.667335, acc.: 63.28%] [G loss: 1.147156]\n",
      "epoch:8 step:8333 [D loss: 0.589407, acc.: 71.88%] [G loss: 1.124028]\n",
      "epoch:8 step:8334 [D loss: 0.679848, acc.: 57.81%] [G loss: 1.005828]\n",
      "epoch:8 step:8335 [D loss: 0.691739, acc.: 53.12%] [G loss: 0.958979]\n",
      "epoch:8 step:8336 [D loss: 0.598428, acc.: 71.88%] [G loss: 1.151027]\n",
      "epoch:8 step:8337 [D loss: 0.583061, acc.: 67.97%] [G loss: 1.141945]\n",
      "epoch:8 step:8338 [D loss: 0.540681, acc.: 78.12%] [G loss: 1.065945]\n",
      "epoch:8 step:8339 [D loss: 0.729768, acc.: 53.12%] [G loss: 0.915651]\n",
      "epoch:8 step:8340 [D loss: 0.682250, acc.: 55.47%] [G loss: 1.154546]\n",
      "epoch:8 step:8341 [D loss: 0.622253, acc.: 62.50%] [G loss: 1.200952]\n",
      "epoch:8 step:8342 [D loss: 0.659781, acc.: 60.94%] [G loss: 1.161432]\n",
      "epoch:8 step:8343 [D loss: 0.528270, acc.: 75.00%] [G loss: 1.404776]\n",
      "epoch:8 step:8344 [D loss: 0.614497, acc.: 64.06%] [G loss: 1.072508]\n",
      "epoch:8 step:8345 [D loss: 0.618320, acc.: 65.62%] [G loss: 1.055733]\n",
      "epoch:8 step:8346 [D loss: 0.611600, acc.: 64.84%] [G loss: 1.073720]\n",
      "epoch:8 step:8347 [D loss: 0.628287, acc.: 69.53%] [G loss: 1.065842]\n",
      "epoch:8 step:8348 [D loss: 0.550586, acc.: 76.56%] [G loss: 1.077635]\n",
      "epoch:8 step:8349 [D loss: 0.460949, acc.: 82.03%] [G loss: 1.182834]\n",
      "epoch:8 step:8350 [D loss: 0.631819, acc.: 64.84%] [G loss: 1.102052]\n",
      "epoch:8 step:8351 [D loss: 0.592721, acc.: 69.53%] [G loss: 1.280903]\n",
      "epoch:8 step:8352 [D loss: 0.573198, acc.: 68.75%] [G loss: 0.905902]\n",
      "epoch:8 step:8353 [D loss: 0.634130, acc.: 61.72%] [G loss: 1.108232]\n",
      "epoch:8 step:8354 [D loss: 0.570855, acc.: 72.66%] [G loss: 1.133199]\n",
      "epoch:8 step:8355 [D loss: 0.591724, acc.: 70.31%] [G loss: 0.967794]\n",
      "epoch:8 step:8356 [D loss: 0.567560, acc.: 67.97%] [G loss: 1.009402]\n",
      "epoch:8 step:8357 [D loss: 0.566819, acc.: 73.44%] [G loss: 1.013056]\n",
      "epoch:8 step:8358 [D loss: 0.691200, acc.: 58.59%] [G loss: 1.209574]\n",
      "epoch:8 step:8359 [D loss: 0.652221, acc.: 65.62%] [G loss: 1.026520]\n",
      "epoch:8 step:8360 [D loss: 0.612340, acc.: 62.50%] [G loss: 0.991504]\n",
      "epoch:8 step:8361 [D loss: 0.662429, acc.: 62.50%] [G loss: 1.019832]\n",
      "epoch:8 step:8362 [D loss: 0.561394, acc.: 68.75%] [G loss: 1.165499]\n",
      "epoch:8 step:8363 [D loss: 0.672256, acc.: 59.38%] [G loss: 1.064871]\n",
      "epoch:8 step:8364 [D loss: 0.611603, acc.: 67.97%] [G loss: 1.310989]\n",
      "epoch:8 step:8365 [D loss: 0.542334, acc.: 73.44%] [G loss: 1.163651]\n",
      "epoch:8 step:8366 [D loss: 0.609074, acc.: 67.19%] [G loss: 1.161921]\n",
      "epoch:8 step:8367 [D loss: 0.637355, acc.: 67.19%] [G loss: 1.046956]\n",
      "epoch:8 step:8368 [D loss: 0.609243, acc.: 67.97%] [G loss: 1.063004]\n",
      "epoch:8 step:8369 [D loss: 0.529252, acc.: 74.22%] [G loss: 1.287200]\n",
      "epoch:8 step:8370 [D loss: 0.717909, acc.: 54.69%] [G loss: 0.901858]\n",
      "epoch:8 step:8371 [D loss: 0.540764, acc.: 75.00%] [G loss: 1.051989]\n",
      "epoch:8 step:8372 [D loss: 0.636154, acc.: 63.28%] [G loss: 1.187156]\n",
      "epoch:8 step:8373 [D loss: 0.588409, acc.: 71.88%] [G loss: 1.134652]\n",
      "epoch:8 step:8374 [D loss: 0.586954, acc.: 71.09%] [G loss: 0.972746]\n",
      "epoch:8 step:8375 [D loss: 0.664305, acc.: 60.16%] [G loss: 1.100805]\n",
      "epoch:8 step:8376 [D loss: 0.588985, acc.: 64.84%] [G loss: 1.153374]\n",
      "epoch:8 step:8377 [D loss: 0.663245, acc.: 57.03%] [G loss: 1.075675]\n",
      "epoch:8 step:8378 [D loss: 0.599110, acc.: 70.31%] [G loss: 1.198012]\n",
      "epoch:8 step:8379 [D loss: 0.588895, acc.: 67.19%] [G loss: 1.241830]\n",
      "epoch:8 step:8380 [D loss: 0.536442, acc.: 75.78%] [G loss: 1.102377]\n",
      "epoch:8 step:8381 [D loss: 0.549344, acc.: 71.88%] [G loss: 1.257416]\n",
      "epoch:8 step:8382 [D loss: 0.667959, acc.: 61.72%] [G loss: 0.911394]\n",
      "epoch:8 step:8383 [D loss: 0.605966, acc.: 68.75%] [G loss: 0.927266]\n",
      "epoch:8 step:8384 [D loss: 0.663544, acc.: 60.16%] [G loss: 1.120496]\n",
      "epoch:8 step:8385 [D loss: 0.622284, acc.: 66.41%] [G loss: 1.099761]\n",
      "epoch:8 step:8386 [D loss: 0.581121, acc.: 67.97%] [G loss: 1.058133]\n",
      "epoch:8 step:8387 [D loss: 0.671239, acc.: 59.38%] [G loss: 0.986154]\n",
      "epoch:8 step:8388 [D loss: 0.579841, acc.: 67.19%] [G loss: 1.114695]\n",
      "epoch:8 step:8389 [D loss: 0.649646, acc.: 59.38%] [G loss: 1.090301]\n",
      "epoch:8 step:8390 [D loss: 0.589997, acc.: 68.75%] [G loss: 1.055533]\n",
      "epoch:8 step:8391 [D loss: 0.545562, acc.: 76.56%] [G loss: 1.041016]\n",
      "epoch:8 step:8392 [D loss: 0.713925, acc.: 60.16%] [G loss: 1.083170]\n",
      "epoch:8 step:8393 [D loss: 0.560820, acc.: 75.78%] [G loss: 1.235398]\n",
      "epoch:8 step:8394 [D loss: 0.579629, acc.: 69.53%] [G loss: 1.060377]\n",
      "epoch:8 step:8395 [D loss: 0.694001, acc.: 55.47%] [G loss: 0.908619]\n",
      "epoch:8 step:8396 [D loss: 0.639377, acc.: 64.06%] [G loss: 1.157217]\n",
      "epoch:8 step:8397 [D loss: 0.619648, acc.: 62.50%] [G loss: 1.126816]\n",
      "epoch:8 step:8398 [D loss: 0.611996, acc.: 63.28%] [G loss: 1.017526]\n",
      "epoch:8 step:8399 [D loss: 0.574586, acc.: 71.09%] [G loss: 1.151188]\n",
      "epoch:8 step:8400 [D loss: 0.692368, acc.: 59.38%] [G loss: 1.088298]\n",
      "epoch:8 step:8401 [D loss: 0.590792, acc.: 67.19%] [G loss: 1.320933]\n",
      "epoch:8 step:8402 [D loss: 0.574140, acc.: 65.62%] [G loss: 1.023367]\n",
      "epoch:8 step:8403 [D loss: 0.530892, acc.: 73.44%] [G loss: 1.181191]\n",
      "epoch:8 step:8404 [D loss: 0.781277, acc.: 44.53%] [G loss: 1.007687]\n",
      "epoch:8 step:8405 [D loss: 0.719265, acc.: 52.34%] [G loss: 0.988746]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:8 step:8406 [D loss: 0.559937, acc.: 74.22%] [G loss: 1.031687]\n",
      "epoch:8 step:8407 [D loss: 0.554855, acc.: 72.66%] [G loss: 1.116833]\n",
      "epoch:8 step:8408 [D loss: 0.687780, acc.: 62.50%] [G loss: 1.150925]\n",
      "epoch:8 step:8409 [D loss: 0.709613, acc.: 56.25%] [G loss: 1.024663]\n",
      "epoch:8 step:8410 [D loss: 0.640359, acc.: 64.84%] [G loss: 0.984061]\n",
      "epoch:8 step:8411 [D loss: 0.546737, acc.: 70.31%] [G loss: 1.203686]\n",
      "epoch:8 step:8412 [D loss: 0.643608, acc.: 62.50%] [G loss: 1.099817]\n",
      "epoch:8 step:8413 [D loss: 0.689342, acc.: 55.47%] [G loss: 1.010437]\n",
      "epoch:8 step:8414 [D loss: 0.609615, acc.: 61.72%] [G loss: 1.204673]\n",
      "epoch:8 step:8415 [D loss: 0.585567, acc.: 65.62%] [G loss: 1.161024]\n",
      "epoch:8 step:8416 [D loss: 0.685994, acc.: 57.03%] [G loss: 1.040407]\n",
      "epoch:8 step:8417 [D loss: 0.574535, acc.: 71.88%] [G loss: 1.111778]\n",
      "epoch:8 step:8418 [D loss: 0.643323, acc.: 66.41%] [G loss: 0.982556]\n",
      "epoch:8 step:8419 [D loss: 0.672810, acc.: 63.28%] [G loss: 1.032444]\n",
      "epoch:8 step:8420 [D loss: 0.633448, acc.: 65.62%] [G loss: 1.044848]\n",
      "epoch:8 step:8421 [D loss: 0.695360, acc.: 55.47%] [G loss: 1.066841]\n",
      "epoch:8 step:8422 [D loss: 0.675203, acc.: 59.38%] [G loss: 1.118640]\n",
      "epoch:8 step:8423 [D loss: 0.659384, acc.: 64.06%] [G loss: 1.118830]\n",
      "epoch:8 step:8424 [D loss: 0.612250, acc.: 63.28%] [G loss: 1.018268]\n",
      "epoch:8 step:8425 [D loss: 0.657336, acc.: 63.28%] [G loss: 1.018264]\n",
      "epoch:8 step:8426 [D loss: 0.609721, acc.: 67.19%] [G loss: 1.043529]\n",
      "epoch:8 step:8427 [D loss: 0.612138, acc.: 66.41%] [G loss: 1.238795]\n",
      "epoch:8 step:8428 [D loss: 0.601644, acc.: 64.84%] [G loss: 1.096013]\n",
      "epoch:8 step:8429 [D loss: 0.653247, acc.: 68.75%] [G loss: 1.228345]\n",
      "epoch:8 step:8430 [D loss: 0.599873, acc.: 66.41%] [G loss: 1.110099]\n",
      "epoch:8 step:8431 [D loss: 0.624727, acc.: 67.19%] [G loss: 1.011856]\n",
      "epoch:8 step:8432 [D loss: 0.570231, acc.: 74.22%] [G loss: 1.038736]\n",
      "epoch:8 step:8433 [D loss: 0.676488, acc.: 58.59%] [G loss: 0.899711]\n",
      "epoch:9 step:8434 [D loss: 0.694904, acc.: 59.38%] [G loss: 1.269570]\n",
      "epoch:9 step:8435 [D loss: 0.687626, acc.: 54.69%] [G loss: 1.103912]\n",
      "epoch:9 step:8436 [D loss: 0.696609, acc.: 53.91%] [G loss: 0.996479]\n",
      "epoch:9 step:8437 [D loss: 0.653666, acc.: 63.28%] [G loss: 1.002581]\n",
      "epoch:9 step:8438 [D loss: 0.575649, acc.: 68.75%] [G loss: 1.396368]\n",
      "epoch:9 step:8439 [D loss: 0.698755, acc.: 50.78%] [G loss: 1.044791]\n",
      "epoch:9 step:8440 [D loss: 0.657114, acc.: 64.84%] [G loss: 1.032406]\n",
      "epoch:9 step:8441 [D loss: 0.588597, acc.: 67.19%] [G loss: 1.008031]\n",
      "epoch:9 step:8442 [D loss: 0.565964, acc.: 71.88%] [G loss: 0.895723]\n",
      "epoch:9 step:8443 [D loss: 0.572778, acc.: 71.88%] [G loss: 1.126307]\n",
      "epoch:9 step:8444 [D loss: 0.537707, acc.: 75.78%] [G loss: 1.102509]\n",
      "epoch:9 step:8445 [D loss: 0.513549, acc.: 78.91%] [G loss: 1.083736]\n",
      "epoch:9 step:8446 [D loss: 0.686387, acc.: 58.59%] [G loss: 1.049555]\n",
      "epoch:9 step:8447 [D loss: 0.720945, acc.: 57.81%] [G loss: 1.019276]\n",
      "epoch:9 step:8448 [D loss: 0.528034, acc.: 74.22%] [G loss: 1.051450]\n",
      "epoch:9 step:8449 [D loss: 0.570583, acc.: 73.44%] [G loss: 1.175285]\n",
      "epoch:9 step:8450 [D loss: 0.605199, acc.: 64.84%] [G loss: 1.286916]\n",
      "epoch:9 step:8451 [D loss: 0.664573, acc.: 59.38%] [G loss: 1.062840]\n",
      "epoch:9 step:8452 [D loss: 0.637195, acc.: 62.50%] [G loss: 1.074299]\n",
      "epoch:9 step:8453 [D loss: 0.605256, acc.: 61.72%] [G loss: 1.005079]\n",
      "epoch:9 step:8454 [D loss: 0.730686, acc.: 52.34%] [G loss: 1.106610]\n",
      "epoch:9 step:8455 [D loss: 0.662757, acc.: 57.03%] [G loss: 1.070794]\n",
      "epoch:9 step:8456 [D loss: 0.675501, acc.: 60.16%] [G loss: 1.054576]\n",
      "epoch:9 step:8457 [D loss: 0.657001, acc.: 60.16%] [G loss: 1.341687]\n",
      "epoch:9 step:8458 [D loss: 0.561848, acc.: 70.31%] [G loss: 1.272821]\n",
      "epoch:9 step:8459 [D loss: 0.696345, acc.: 61.72%] [G loss: 1.022899]\n",
      "epoch:9 step:8460 [D loss: 0.535677, acc.: 75.00%] [G loss: 1.232883]\n",
      "epoch:9 step:8461 [D loss: 0.644436, acc.: 58.59%] [G loss: 0.958587]\n",
      "epoch:9 step:8462 [D loss: 0.641789, acc.: 64.06%] [G loss: 1.070077]\n",
      "epoch:9 step:8463 [D loss: 0.710113, acc.: 53.91%] [G loss: 0.978930]\n",
      "epoch:9 step:8464 [D loss: 0.695456, acc.: 56.25%] [G loss: 1.182348]\n",
      "epoch:9 step:8465 [D loss: 0.536048, acc.: 70.31%] [G loss: 1.099668]\n",
      "epoch:9 step:8466 [D loss: 0.668758, acc.: 61.72%] [G loss: 1.117923]\n",
      "epoch:9 step:8467 [D loss: 0.561663, acc.: 68.75%] [G loss: 1.171548]\n",
      "epoch:9 step:8468 [D loss: 0.546311, acc.: 73.44%] [G loss: 1.150832]\n",
      "epoch:9 step:8469 [D loss: 0.541292, acc.: 72.66%] [G loss: 1.177423]\n",
      "epoch:9 step:8470 [D loss: 0.600589, acc.: 70.31%] [G loss: 1.099856]\n",
      "epoch:9 step:8471 [D loss: 0.568426, acc.: 68.75%] [G loss: 1.112867]\n",
      "epoch:9 step:8472 [D loss: 0.636163, acc.: 65.62%] [G loss: 1.058868]\n",
      "epoch:9 step:8473 [D loss: 0.628643, acc.: 63.28%] [G loss: 1.078202]\n",
      "epoch:9 step:8474 [D loss: 0.572814, acc.: 69.53%] [G loss: 1.025937]\n",
      "epoch:9 step:8475 [D loss: 0.578235, acc.: 66.41%] [G loss: 1.123025]\n",
      "epoch:9 step:8476 [D loss: 0.613789, acc.: 66.41%] [G loss: 1.036431]\n",
      "epoch:9 step:8477 [D loss: 0.577727, acc.: 68.75%] [G loss: 0.990980]\n",
      "epoch:9 step:8478 [D loss: 0.696202, acc.: 53.91%] [G loss: 0.972096]\n",
      "epoch:9 step:8479 [D loss: 0.734724, acc.: 57.03%] [G loss: 1.119689]\n",
      "epoch:9 step:8480 [D loss: 0.695804, acc.: 58.59%] [G loss: 0.992573]\n",
      "epoch:9 step:8481 [D loss: 0.576717, acc.: 67.97%] [G loss: 1.027365]\n",
      "epoch:9 step:8482 [D loss: 0.649166, acc.: 64.84%] [G loss: 1.200710]\n",
      "epoch:9 step:8483 [D loss: 0.585341, acc.: 66.41%] [G loss: 1.061959]\n",
      "epoch:9 step:8484 [D loss: 0.488661, acc.: 80.47%] [G loss: 1.068885]\n",
      "epoch:9 step:8485 [D loss: 0.572032, acc.: 71.88%] [G loss: 1.159570]\n",
      "epoch:9 step:8486 [D loss: 0.584508, acc.: 65.62%] [G loss: 0.967712]\n",
      "epoch:9 step:8487 [D loss: 0.632759, acc.: 66.41%] [G loss: 1.196438]\n",
      "epoch:9 step:8488 [D loss: 0.647443, acc.: 67.19%] [G loss: 1.003613]\n",
      "epoch:9 step:8489 [D loss: 0.603144, acc.: 64.06%] [G loss: 0.905290]\n",
      "epoch:9 step:8490 [D loss: 0.695832, acc.: 60.16%] [G loss: 1.202568]\n",
      "epoch:9 step:8491 [D loss: 0.554562, acc.: 71.09%] [G loss: 1.030089]\n",
      "epoch:9 step:8492 [D loss: 0.598908, acc.: 68.75%] [G loss: 1.058650]\n",
      "epoch:9 step:8493 [D loss: 0.606744, acc.: 64.06%] [G loss: 1.023752]\n",
      "epoch:9 step:8494 [D loss: 0.599924, acc.: 66.41%] [G loss: 1.025092]\n",
      "epoch:9 step:8495 [D loss: 0.622012, acc.: 64.06%] [G loss: 1.232928]\n",
      "epoch:9 step:8496 [D loss: 0.639011, acc.: 61.72%] [G loss: 1.216661]\n",
      "epoch:9 step:8497 [D loss: 0.669758, acc.: 62.50%] [G loss: 0.961259]\n",
      "epoch:9 step:8498 [D loss: 0.635232, acc.: 61.72%] [G loss: 0.992734]\n",
      "epoch:9 step:8499 [D loss: 0.740528, acc.: 59.38%] [G loss: 1.095646]\n",
      "epoch:9 step:8500 [D loss: 0.692828, acc.: 57.03%] [G loss: 1.334961]\n",
      "epoch:9 step:8501 [D loss: 0.650672, acc.: 57.81%] [G loss: 0.938825]\n",
      "epoch:9 step:8502 [D loss: 0.651292, acc.: 61.72%] [G loss: 1.102492]\n",
      "epoch:9 step:8503 [D loss: 0.591151, acc.: 65.62%] [G loss: 1.309024]\n",
      "epoch:9 step:8504 [D loss: 0.721669, acc.: 57.81%] [G loss: 0.826461]\n",
      "epoch:9 step:8505 [D loss: 0.635698, acc.: 63.28%] [G loss: 1.257967]\n",
      "epoch:9 step:8506 [D loss: 0.546579, acc.: 67.97%] [G loss: 1.040980]\n",
      "epoch:9 step:8507 [D loss: 0.626351, acc.: 64.06%] [G loss: 1.225509]\n",
      "epoch:9 step:8508 [D loss: 0.586649, acc.: 71.88%] [G loss: 1.125604]\n",
      "epoch:9 step:8509 [D loss: 0.606376, acc.: 65.62%] [G loss: 1.206367]\n",
      "epoch:9 step:8510 [D loss: 0.613820, acc.: 68.75%] [G loss: 1.105169]\n",
      "epoch:9 step:8511 [D loss: 0.623080, acc.: 67.19%] [G loss: 1.245930]\n",
      "epoch:9 step:8512 [D loss: 0.675600, acc.: 59.38%] [G loss: 1.027702]\n",
      "epoch:9 step:8513 [D loss: 0.690629, acc.: 56.25%] [G loss: 1.206171]\n",
      "epoch:9 step:8514 [D loss: 0.650950, acc.: 62.50%] [G loss: 1.139439]\n",
      "epoch:9 step:8515 [D loss: 0.562781, acc.: 75.00%] [G loss: 1.100288]\n",
      "epoch:9 step:8516 [D loss: 0.580515, acc.: 71.88%] [G loss: 1.063811]\n",
      "epoch:9 step:8517 [D loss: 0.598894, acc.: 65.62%] [G loss: 1.077314]\n",
      "epoch:9 step:8518 [D loss: 0.623371, acc.: 71.09%] [G loss: 1.135672]\n",
      "epoch:9 step:8519 [D loss: 0.679457, acc.: 57.03%] [G loss: 1.025950]\n",
      "epoch:9 step:8520 [D loss: 0.591495, acc.: 66.41%] [G loss: 1.107024]\n",
      "epoch:9 step:8521 [D loss: 0.575306, acc.: 71.09%] [G loss: 1.003390]\n",
      "epoch:9 step:8522 [D loss: 0.683884, acc.: 57.81%] [G loss: 1.133334]\n",
      "epoch:9 step:8523 [D loss: 0.610381, acc.: 69.53%] [G loss: 1.145585]\n",
      "epoch:9 step:8524 [D loss: 0.640054, acc.: 66.41%] [G loss: 1.195032]\n",
      "epoch:9 step:8525 [D loss: 0.598008, acc.: 66.41%] [G loss: 1.158673]\n",
      "epoch:9 step:8526 [D loss: 0.581517, acc.: 71.88%] [G loss: 0.993885]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:9 step:8527 [D loss: 0.706951, acc.: 51.56%] [G loss: 1.044656]\n",
      "epoch:9 step:8528 [D loss: 0.714742, acc.: 53.91%] [G loss: 0.957486]\n",
      "epoch:9 step:8529 [D loss: 0.576003, acc.: 69.53%] [G loss: 1.075276]\n",
      "epoch:9 step:8530 [D loss: 0.734169, acc.: 50.00%] [G loss: 1.211966]\n",
      "epoch:9 step:8531 [D loss: 0.665319, acc.: 64.06%] [G loss: 1.017157]\n",
      "epoch:9 step:8532 [D loss: 0.634392, acc.: 64.06%] [G loss: 1.180365]\n",
      "epoch:9 step:8533 [D loss: 0.611717, acc.: 66.41%] [G loss: 1.087714]\n",
      "epoch:9 step:8534 [D loss: 0.654042, acc.: 62.50%] [G loss: 0.969727]\n",
      "epoch:9 step:8535 [D loss: 0.614220, acc.: 67.97%] [G loss: 1.157319]\n",
      "epoch:9 step:8536 [D loss: 0.603774, acc.: 63.28%] [G loss: 1.154745]\n",
      "epoch:9 step:8537 [D loss: 0.581944, acc.: 69.53%] [G loss: 1.059987]\n",
      "epoch:9 step:8538 [D loss: 0.632348, acc.: 62.50%] [G loss: 1.163524]\n",
      "epoch:9 step:8539 [D loss: 0.683787, acc.: 61.72%] [G loss: 1.196035]\n",
      "epoch:9 step:8540 [D loss: 0.586434, acc.: 71.88%] [G loss: 1.028344]\n",
      "epoch:9 step:8541 [D loss: 0.569285, acc.: 71.09%] [G loss: 1.222480]\n",
      "epoch:9 step:8542 [D loss: 0.557871, acc.: 76.56%] [G loss: 1.054775]\n",
      "epoch:9 step:8543 [D loss: 0.705989, acc.: 57.81%] [G loss: 0.913026]\n",
      "epoch:9 step:8544 [D loss: 0.800288, acc.: 42.19%] [G loss: 0.942410]\n",
      "epoch:9 step:8545 [D loss: 0.612457, acc.: 69.53%] [G loss: 1.079965]\n",
      "epoch:9 step:8546 [D loss: 0.572650, acc.: 66.41%] [G loss: 1.134155]\n",
      "epoch:9 step:8547 [D loss: 0.603569, acc.: 66.41%] [G loss: 1.233431]\n",
      "epoch:9 step:8548 [D loss: 0.736874, acc.: 51.56%] [G loss: 1.137511]\n",
      "epoch:9 step:8549 [D loss: 0.640587, acc.: 60.94%] [G loss: 1.191345]\n",
      "epoch:9 step:8550 [D loss: 0.623240, acc.: 68.75%] [G loss: 1.117083]\n",
      "epoch:9 step:8551 [D loss: 0.617369, acc.: 64.84%] [G loss: 1.092441]\n",
      "epoch:9 step:8552 [D loss: 0.662147, acc.: 61.72%] [G loss: 0.960734]\n",
      "epoch:9 step:8553 [D loss: 0.684182, acc.: 60.16%] [G loss: 1.118238]\n",
      "epoch:9 step:8554 [D loss: 0.652607, acc.: 62.50%] [G loss: 1.018639]\n",
      "epoch:9 step:8555 [D loss: 0.603466, acc.: 69.53%] [G loss: 1.022167]\n",
      "epoch:9 step:8556 [D loss: 0.585424, acc.: 65.62%] [G loss: 0.993070]\n",
      "epoch:9 step:8557 [D loss: 0.516217, acc.: 76.56%] [G loss: 1.228970]\n",
      "epoch:9 step:8558 [D loss: 0.628251, acc.: 64.84%] [G loss: 0.948966]\n",
      "epoch:9 step:8559 [D loss: 0.761450, acc.: 46.88%] [G loss: 0.864350]\n",
      "epoch:9 step:8560 [D loss: 0.711676, acc.: 54.69%] [G loss: 1.059193]\n",
      "epoch:9 step:8561 [D loss: 0.595351, acc.: 68.75%] [G loss: 0.929259]\n",
      "epoch:9 step:8562 [D loss: 0.584013, acc.: 65.62%] [G loss: 1.330139]\n",
      "epoch:9 step:8563 [D loss: 0.547334, acc.: 71.88%] [G loss: 1.329207]\n",
      "epoch:9 step:8564 [D loss: 0.615437, acc.: 68.75%] [G loss: 1.220501]\n",
      "epoch:9 step:8565 [D loss: 0.704434, acc.: 56.25%] [G loss: 1.112933]\n",
      "epoch:9 step:8566 [D loss: 0.591208, acc.: 71.09%] [G loss: 1.110912]\n",
      "epoch:9 step:8567 [D loss: 0.719505, acc.: 55.47%] [G loss: 1.124530]\n",
      "epoch:9 step:8568 [D loss: 0.665248, acc.: 57.81%] [G loss: 0.980479]\n",
      "epoch:9 step:8569 [D loss: 0.615455, acc.: 65.62%] [G loss: 1.108074]\n",
      "epoch:9 step:8570 [D loss: 0.656004, acc.: 62.50%] [G loss: 0.953434]\n",
      "epoch:9 step:8571 [D loss: 0.558725, acc.: 70.31%] [G loss: 1.179291]\n",
      "epoch:9 step:8572 [D loss: 0.651425, acc.: 60.16%] [G loss: 0.858740]\n",
      "epoch:9 step:8573 [D loss: 0.553816, acc.: 73.44%] [G loss: 1.095990]\n",
      "epoch:9 step:8574 [D loss: 0.605145, acc.: 69.53%] [G loss: 0.985769]\n",
      "epoch:9 step:8575 [D loss: 0.512470, acc.: 75.78%] [G loss: 1.335642]\n",
      "epoch:9 step:8576 [D loss: 0.625750, acc.: 63.28%] [G loss: 1.168941]\n",
      "epoch:9 step:8577 [D loss: 0.794227, acc.: 40.62%] [G loss: 0.995708]\n",
      "epoch:9 step:8578 [D loss: 0.689633, acc.: 57.81%] [G loss: 0.916092]\n",
      "epoch:9 step:8579 [D loss: 0.665710, acc.: 61.72%] [G loss: 1.048257]\n",
      "epoch:9 step:8580 [D loss: 0.595803, acc.: 68.75%] [G loss: 1.140722]\n",
      "epoch:9 step:8581 [D loss: 0.665081, acc.: 60.94%] [G loss: 1.105514]\n",
      "epoch:9 step:8582 [D loss: 0.554612, acc.: 73.44%] [G loss: 1.103178]\n",
      "epoch:9 step:8583 [D loss: 0.632823, acc.: 62.50%] [G loss: 1.139787]\n",
      "epoch:9 step:8584 [D loss: 0.673258, acc.: 61.72%] [G loss: 1.095508]\n",
      "epoch:9 step:8585 [D loss: 0.705374, acc.: 53.91%] [G loss: 0.946722]\n",
      "epoch:9 step:8586 [D loss: 0.562545, acc.: 74.22%] [G loss: 1.200668]\n",
      "epoch:9 step:8587 [D loss: 0.606856, acc.: 64.84%] [G loss: 0.996308]\n",
      "epoch:9 step:8588 [D loss: 0.736413, acc.: 52.34%] [G loss: 0.908835]\n",
      "epoch:9 step:8589 [D loss: 0.653235, acc.: 60.16%] [G loss: 1.026274]\n",
      "epoch:9 step:8590 [D loss: 0.638436, acc.: 60.16%] [G loss: 1.145291]\n",
      "epoch:9 step:8591 [D loss: 0.509561, acc.: 75.00%] [G loss: 1.159771]\n",
      "epoch:9 step:8592 [D loss: 0.557842, acc.: 74.22%] [G loss: 1.047218]\n",
      "epoch:9 step:8593 [D loss: 0.605400, acc.: 63.28%] [G loss: 1.093965]\n",
      "epoch:9 step:8594 [D loss: 0.564943, acc.: 70.31%] [G loss: 1.092843]\n",
      "epoch:9 step:8595 [D loss: 0.568954, acc.: 67.97%] [G loss: 1.173261]\n",
      "epoch:9 step:8596 [D loss: 0.671356, acc.: 58.59%] [G loss: 0.980113]\n",
      "epoch:9 step:8597 [D loss: 0.608791, acc.: 67.19%] [G loss: 1.068068]\n",
      "epoch:9 step:8598 [D loss: 0.728366, acc.: 52.34%] [G loss: 0.990314]\n",
      "epoch:9 step:8599 [D loss: 0.683243, acc.: 56.25%] [G loss: 1.310508]\n",
      "epoch:9 step:8600 [D loss: 0.592775, acc.: 68.75%] [G loss: 1.144777]\n",
      "epoch:9 step:8601 [D loss: 0.596973, acc.: 65.62%] [G loss: 1.181018]\n",
      "epoch:9 step:8602 [D loss: 0.709501, acc.: 55.47%] [G loss: 1.077857]\n",
      "epoch:9 step:8603 [D loss: 0.605810, acc.: 66.41%] [G loss: 0.969535]\n",
      "epoch:9 step:8604 [D loss: 0.657593, acc.: 57.03%] [G loss: 1.110578]\n",
      "epoch:9 step:8605 [D loss: 0.668431, acc.: 61.72%] [G loss: 1.104712]\n",
      "epoch:9 step:8606 [D loss: 0.678254, acc.: 57.03%] [G loss: 1.004612]\n",
      "epoch:9 step:8607 [D loss: 0.688314, acc.: 55.47%] [G loss: 1.120363]\n",
      "epoch:9 step:8608 [D loss: 0.603891, acc.: 66.41%] [G loss: 1.262647]\n",
      "epoch:9 step:8609 [D loss: 0.614858, acc.: 66.41%] [G loss: 1.064489]\n",
      "epoch:9 step:8610 [D loss: 0.657647, acc.: 58.59%] [G loss: 1.247812]\n",
      "epoch:9 step:8611 [D loss: 0.618477, acc.: 65.62%] [G loss: 1.029768]\n",
      "epoch:9 step:8612 [D loss: 0.647946, acc.: 62.50%] [G loss: 1.135829]\n",
      "epoch:9 step:8613 [D loss: 0.564331, acc.: 67.97%] [G loss: 1.137556]\n",
      "epoch:9 step:8614 [D loss: 0.631289, acc.: 57.03%] [G loss: 1.093744]\n",
      "epoch:9 step:8615 [D loss: 0.582388, acc.: 71.09%] [G loss: 0.984758]\n",
      "epoch:9 step:8616 [D loss: 0.586488, acc.: 71.09%] [G loss: 1.203097]\n",
      "epoch:9 step:8617 [D loss: 0.624006, acc.: 64.06%] [G loss: 1.205763]\n",
      "epoch:9 step:8618 [D loss: 0.559207, acc.: 68.75%] [G loss: 1.225754]\n",
      "epoch:9 step:8619 [D loss: 0.577319, acc.: 69.53%] [G loss: 1.132245]\n",
      "epoch:9 step:8620 [D loss: 0.541396, acc.: 73.44%] [G loss: 1.110450]\n",
      "epoch:9 step:8621 [D loss: 0.559889, acc.: 75.00%] [G loss: 1.069484]\n",
      "epoch:9 step:8622 [D loss: 0.631706, acc.: 57.81%] [G loss: 0.976301]\n",
      "epoch:9 step:8623 [D loss: 0.596131, acc.: 62.50%] [G loss: 1.139874]\n",
      "epoch:9 step:8624 [D loss: 0.625546, acc.: 65.62%] [G loss: 0.945830]\n",
      "epoch:9 step:8625 [D loss: 0.622673, acc.: 60.94%] [G loss: 1.208791]\n",
      "epoch:9 step:8626 [D loss: 0.736824, acc.: 52.34%] [G loss: 1.028372]\n",
      "epoch:9 step:8627 [D loss: 0.620602, acc.: 64.84%] [G loss: 1.195644]\n",
      "epoch:9 step:8628 [D loss: 0.611038, acc.: 66.41%] [G loss: 1.246998]\n",
      "epoch:9 step:8629 [D loss: 0.590644, acc.: 70.31%] [G loss: 1.087033]\n",
      "epoch:9 step:8630 [D loss: 0.576429, acc.: 64.84%] [G loss: 1.051193]\n",
      "epoch:9 step:8631 [D loss: 0.579590, acc.: 70.31%] [G loss: 1.051831]\n",
      "epoch:9 step:8632 [D loss: 0.570196, acc.: 69.53%] [G loss: 1.064585]\n",
      "epoch:9 step:8633 [D loss: 0.662372, acc.: 57.03%] [G loss: 1.282405]\n",
      "epoch:9 step:8634 [D loss: 0.560332, acc.: 71.88%] [G loss: 1.140332]\n",
      "epoch:9 step:8635 [D loss: 0.613888, acc.: 67.97%] [G loss: 1.025846]\n",
      "epoch:9 step:8636 [D loss: 0.536836, acc.: 76.56%] [G loss: 1.210075]\n",
      "epoch:9 step:8637 [D loss: 0.526645, acc.: 76.56%] [G loss: 1.060331]\n",
      "epoch:9 step:8638 [D loss: 0.695823, acc.: 61.72%] [G loss: 0.886461]\n",
      "epoch:9 step:8639 [D loss: 0.651025, acc.: 57.03%] [G loss: 0.843079]\n",
      "epoch:9 step:8640 [D loss: 0.642614, acc.: 64.84%] [G loss: 1.024654]\n",
      "epoch:9 step:8641 [D loss: 0.590866, acc.: 71.88%] [G loss: 1.134319]\n",
      "epoch:9 step:8642 [D loss: 0.661969, acc.: 59.38%] [G loss: 1.186813]\n",
      "epoch:9 step:8643 [D loss: 0.658885, acc.: 63.28%] [G loss: 1.012326]\n",
      "epoch:9 step:8644 [D loss: 0.571740, acc.: 71.09%] [G loss: 1.197673]\n",
      "epoch:9 step:8645 [D loss: 0.501705, acc.: 82.81%] [G loss: 1.072697]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:9 step:8646 [D loss: 0.632493, acc.: 66.41%] [G loss: 1.113444]\n",
      "epoch:9 step:8647 [D loss: 0.619714, acc.: 61.72%] [G loss: 1.160253]\n",
      "epoch:9 step:8648 [D loss: 0.550025, acc.: 75.00%] [G loss: 1.344785]\n",
      "epoch:9 step:8649 [D loss: 0.773062, acc.: 47.66%] [G loss: 0.918508]\n",
      "epoch:9 step:8650 [D loss: 0.605983, acc.: 64.84%] [G loss: 1.086197]\n",
      "epoch:9 step:8651 [D loss: 0.669506, acc.: 57.81%] [G loss: 1.112005]\n",
      "epoch:9 step:8652 [D loss: 0.659977, acc.: 60.16%] [G loss: 0.973341]\n",
      "epoch:9 step:8653 [D loss: 0.575845, acc.: 70.31%] [G loss: 1.090031]\n",
      "epoch:9 step:8654 [D loss: 0.560252, acc.: 71.09%] [G loss: 1.204887]\n",
      "epoch:9 step:8655 [D loss: 0.780182, acc.: 49.22%] [G loss: 1.035944]\n",
      "epoch:9 step:8656 [D loss: 0.532321, acc.: 76.56%] [G loss: 1.043042]\n",
      "epoch:9 step:8657 [D loss: 0.613485, acc.: 67.19%] [G loss: 0.999227]\n",
      "epoch:9 step:8658 [D loss: 0.579071, acc.: 68.75%] [G loss: 0.879820]\n",
      "epoch:9 step:8659 [D loss: 0.660769, acc.: 58.59%] [G loss: 1.049419]\n",
      "epoch:9 step:8660 [D loss: 0.537176, acc.: 75.78%] [G loss: 1.228593]\n",
      "epoch:9 step:8661 [D loss: 0.635917, acc.: 59.38%] [G loss: 0.981391]\n",
      "epoch:9 step:8662 [D loss: 0.632207, acc.: 61.72%] [G loss: 1.081020]\n",
      "epoch:9 step:8663 [D loss: 0.628949, acc.: 63.28%] [G loss: 0.911396]\n",
      "epoch:9 step:8664 [D loss: 0.605461, acc.: 69.53%] [G loss: 1.007513]\n",
      "epoch:9 step:8665 [D loss: 0.682844, acc.: 59.38%] [G loss: 1.151893]\n",
      "epoch:9 step:8666 [D loss: 0.741067, acc.: 53.91%] [G loss: 1.139219]\n",
      "epoch:9 step:8667 [D loss: 0.564698, acc.: 71.09%] [G loss: 1.356183]\n",
      "epoch:9 step:8668 [D loss: 0.637394, acc.: 66.41%] [G loss: 1.086392]\n",
      "epoch:9 step:8669 [D loss: 0.549166, acc.: 73.44%] [G loss: 1.223008]\n",
      "epoch:9 step:8670 [D loss: 0.747528, acc.: 50.78%] [G loss: 1.100146]\n",
      "epoch:9 step:8671 [D loss: 0.617563, acc.: 64.06%] [G loss: 0.900580]\n",
      "epoch:9 step:8672 [D loss: 0.605875, acc.: 69.53%] [G loss: 1.278505]\n",
      "epoch:9 step:8673 [D loss: 0.635346, acc.: 60.16%] [G loss: 0.892056]\n",
      "epoch:9 step:8674 [D loss: 0.619637, acc.: 67.19%] [G loss: 1.008350]\n",
      "epoch:9 step:8675 [D loss: 0.669993, acc.: 54.69%] [G loss: 1.154928]\n",
      "epoch:9 step:8676 [D loss: 0.595181, acc.: 64.84%] [G loss: 1.098011]\n",
      "epoch:9 step:8677 [D loss: 0.580266, acc.: 70.31%] [G loss: 1.178429]\n",
      "epoch:9 step:8678 [D loss: 0.610855, acc.: 64.84%] [G loss: 1.286837]\n",
      "epoch:9 step:8679 [D loss: 0.663263, acc.: 58.59%] [G loss: 0.999783]\n",
      "epoch:9 step:8680 [D loss: 0.648220, acc.: 64.84%] [G loss: 0.975215]\n",
      "epoch:9 step:8681 [D loss: 0.639090, acc.: 64.84%] [G loss: 1.090701]\n",
      "epoch:9 step:8682 [D loss: 0.573643, acc.: 71.09%] [G loss: 1.237139]\n",
      "epoch:9 step:8683 [D loss: 0.611851, acc.: 66.41%] [G loss: 1.137056]\n",
      "epoch:9 step:8684 [D loss: 0.640252, acc.: 66.41%] [G loss: 1.011560]\n",
      "epoch:9 step:8685 [D loss: 0.566272, acc.: 70.31%] [G loss: 1.088561]\n",
      "epoch:9 step:8686 [D loss: 0.622453, acc.: 60.16%] [G loss: 1.249122]\n",
      "epoch:9 step:8687 [D loss: 0.679729, acc.: 60.16%] [G loss: 0.971762]\n",
      "epoch:9 step:8688 [D loss: 0.646053, acc.: 58.59%] [G loss: 1.034362]\n",
      "epoch:9 step:8689 [D loss: 0.602112, acc.: 68.75%] [G loss: 1.013681]\n",
      "epoch:9 step:8690 [D loss: 0.593423, acc.: 68.75%] [G loss: 1.084350]\n",
      "epoch:9 step:8691 [D loss: 0.648962, acc.: 63.28%] [G loss: 1.039763]\n",
      "epoch:9 step:8692 [D loss: 0.583288, acc.: 69.53%] [G loss: 1.195407]\n",
      "epoch:9 step:8693 [D loss: 0.559536, acc.: 70.31%] [G loss: 1.022759]\n",
      "epoch:9 step:8694 [D loss: 0.632053, acc.: 65.62%] [G loss: 1.062415]\n",
      "epoch:9 step:8695 [D loss: 0.667756, acc.: 55.47%] [G loss: 1.068886]\n",
      "epoch:9 step:8696 [D loss: 0.723302, acc.: 59.38%] [G loss: 1.012865]\n",
      "epoch:9 step:8697 [D loss: 0.557481, acc.: 73.44%] [G loss: 1.045471]\n",
      "epoch:9 step:8698 [D loss: 0.544834, acc.: 75.00%] [G loss: 1.223348]\n",
      "epoch:9 step:8699 [D loss: 0.606803, acc.: 60.94%] [G loss: 1.066593]\n",
      "epoch:9 step:8700 [D loss: 0.726607, acc.: 59.38%] [G loss: 1.079078]\n",
      "epoch:9 step:8701 [D loss: 0.552656, acc.: 74.22%] [G loss: 1.302523]\n",
      "epoch:9 step:8702 [D loss: 0.556067, acc.: 67.19%] [G loss: 1.229783]\n",
      "epoch:9 step:8703 [D loss: 0.613202, acc.: 65.62%] [G loss: 0.916340]\n",
      "epoch:9 step:8704 [D loss: 0.568703, acc.: 74.22%] [G loss: 1.090851]\n",
      "epoch:9 step:8705 [D loss: 0.630805, acc.: 64.06%] [G loss: 0.911379]\n",
      "epoch:9 step:8706 [D loss: 0.651195, acc.: 60.16%] [G loss: 1.002893]\n",
      "epoch:9 step:8707 [D loss: 0.487504, acc.: 81.25%] [G loss: 1.286316]\n",
      "epoch:9 step:8708 [D loss: 0.647234, acc.: 64.06%] [G loss: 1.140132]\n",
      "epoch:9 step:8709 [D loss: 0.622247, acc.: 63.28%] [G loss: 1.110022]\n",
      "epoch:9 step:8710 [D loss: 0.570088, acc.: 71.88%] [G loss: 0.985216]\n",
      "epoch:9 step:8711 [D loss: 0.551567, acc.: 77.34%] [G loss: 1.165810]\n",
      "epoch:9 step:8712 [D loss: 0.640468, acc.: 64.06%] [G loss: 0.922978]\n",
      "epoch:9 step:8713 [D loss: 0.613033, acc.: 68.75%] [G loss: 1.329776]\n",
      "epoch:9 step:8714 [D loss: 0.573741, acc.: 68.75%] [G loss: 1.142162]\n",
      "epoch:9 step:8715 [D loss: 0.570902, acc.: 67.19%] [G loss: 0.898961]\n",
      "epoch:9 step:8716 [D loss: 0.604148, acc.: 64.06%] [G loss: 1.073095]\n",
      "epoch:9 step:8717 [D loss: 0.600022, acc.: 66.41%] [G loss: 1.028302]\n",
      "epoch:9 step:8718 [D loss: 0.651312, acc.: 60.94%] [G loss: 1.056876]\n",
      "epoch:9 step:8719 [D loss: 0.650121, acc.: 64.06%] [G loss: 1.119115]\n",
      "epoch:9 step:8720 [D loss: 0.535334, acc.: 73.44%] [G loss: 1.088642]\n",
      "epoch:9 step:8721 [D loss: 0.653686, acc.: 67.19%] [G loss: 1.042167]\n",
      "epoch:9 step:8722 [D loss: 0.614748, acc.: 65.62%] [G loss: 1.231059]\n",
      "epoch:9 step:8723 [D loss: 0.655797, acc.: 63.28%] [G loss: 0.943119]\n",
      "epoch:9 step:8724 [D loss: 0.553762, acc.: 74.22%] [G loss: 1.191318]\n",
      "epoch:9 step:8725 [D loss: 0.654754, acc.: 60.16%] [G loss: 0.860400]\n",
      "epoch:9 step:8726 [D loss: 0.628333, acc.: 63.28%] [G loss: 1.078391]\n",
      "epoch:9 step:8727 [D loss: 0.585108, acc.: 71.09%] [G loss: 1.106716]\n",
      "epoch:9 step:8728 [D loss: 0.672205, acc.: 61.72%] [G loss: 1.095975]\n",
      "epoch:9 step:8729 [D loss: 0.575674, acc.: 71.88%] [G loss: 1.109810]\n",
      "epoch:9 step:8730 [D loss: 0.772703, acc.: 51.56%] [G loss: 1.154185]\n",
      "epoch:9 step:8731 [D loss: 0.691095, acc.: 59.38%] [G loss: 1.068963]\n",
      "epoch:9 step:8732 [D loss: 0.713693, acc.: 50.00%] [G loss: 1.116617]\n",
      "epoch:9 step:8733 [D loss: 0.619124, acc.: 64.84%] [G loss: 0.952148]\n",
      "epoch:9 step:8734 [D loss: 0.674779, acc.: 60.94%] [G loss: 1.099266]\n",
      "epoch:9 step:8735 [D loss: 0.615243, acc.: 67.19%] [G loss: 1.173913]\n",
      "epoch:9 step:8736 [D loss: 0.673635, acc.: 58.59%] [G loss: 1.157358]\n",
      "epoch:9 step:8737 [D loss: 0.588384, acc.: 69.53%] [G loss: 1.012717]\n",
      "epoch:9 step:8738 [D loss: 0.648245, acc.: 60.94%] [G loss: 1.153095]\n",
      "epoch:9 step:8739 [D loss: 0.689942, acc.: 58.59%] [G loss: 1.134303]\n",
      "epoch:9 step:8740 [D loss: 0.654036, acc.: 64.06%] [G loss: 0.978747]\n",
      "epoch:9 step:8741 [D loss: 0.614924, acc.: 66.41%] [G loss: 1.166456]\n",
      "epoch:9 step:8742 [D loss: 0.571162, acc.: 74.22%] [G loss: 1.470496]\n",
      "epoch:9 step:8743 [D loss: 0.693830, acc.: 58.59%] [G loss: 1.123050]\n",
      "epoch:9 step:8744 [D loss: 0.609069, acc.: 68.75%] [G loss: 1.114292]\n",
      "epoch:9 step:8745 [D loss: 0.664361, acc.: 58.59%] [G loss: 0.927832]\n",
      "epoch:9 step:8746 [D loss: 0.617402, acc.: 63.28%] [G loss: 1.042727]\n",
      "epoch:9 step:8747 [D loss: 0.599330, acc.: 66.41%] [G loss: 1.221310]\n",
      "epoch:9 step:8748 [D loss: 0.510319, acc.: 78.91%] [G loss: 1.138298]\n",
      "epoch:9 step:8749 [D loss: 0.728814, acc.: 60.94%] [G loss: 1.023978]\n",
      "epoch:9 step:8750 [D loss: 0.667113, acc.: 62.50%] [G loss: 0.934123]\n",
      "epoch:9 step:8751 [D loss: 0.589652, acc.: 67.97%] [G loss: 1.256270]\n",
      "epoch:9 step:8752 [D loss: 0.540772, acc.: 74.22%] [G loss: 0.993293]\n",
      "epoch:9 step:8753 [D loss: 0.603008, acc.: 66.41%] [G loss: 1.110402]\n",
      "epoch:9 step:8754 [D loss: 0.668815, acc.: 57.81%] [G loss: 0.892809]\n",
      "epoch:9 step:8755 [D loss: 0.623962, acc.: 63.28%] [G loss: 1.045927]\n",
      "epoch:9 step:8756 [D loss: 0.549411, acc.: 77.34%] [G loss: 0.976898]\n",
      "epoch:9 step:8757 [D loss: 0.600897, acc.: 65.62%] [G loss: 1.056880]\n",
      "epoch:9 step:8758 [D loss: 0.601739, acc.: 65.62%] [G loss: 1.246194]\n",
      "epoch:9 step:8759 [D loss: 0.608571, acc.: 67.97%] [G loss: 1.245120]\n",
      "epoch:9 step:8760 [D loss: 0.574697, acc.: 71.09%] [G loss: 1.096052]\n",
      "epoch:9 step:8761 [D loss: 0.607727, acc.: 67.97%] [G loss: 1.068567]\n",
      "epoch:9 step:8762 [D loss: 0.637783, acc.: 64.06%] [G loss: 1.255852]\n",
      "epoch:9 step:8763 [D loss: 0.611922, acc.: 67.19%] [G loss: 1.068419]\n",
      "epoch:9 step:8764 [D loss: 0.606043, acc.: 69.53%] [G loss: 1.020771]\n",
      "epoch:9 step:8765 [D loss: 0.637845, acc.: 61.72%] [G loss: 1.113020]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:9 step:8766 [D loss: 0.647875, acc.: 60.94%] [G loss: 1.144999]\n",
      "epoch:9 step:8767 [D loss: 0.584747, acc.: 68.75%] [G loss: 1.168329]\n",
      "epoch:9 step:8768 [D loss: 0.522861, acc.: 72.66%] [G loss: 1.006778]\n",
      "epoch:9 step:8769 [D loss: 0.539146, acc.: 75.78%] [G loss: 1.198009]\n",
      "epoch:9 step:8770 [D loss: 0.646854, acc.: 62.50%] [G loss: 1.137468]\n",
      "epoch:9 step:8771 [D loss: 0.614055, acc.: 69.53%] [G loss: 1.163741]\n",
      "epoch:9 step:8772 [D loss: 0.673424, acc.: 59.38%] [G loss: 1.097256]\n",
      "epoch:9 step:8773 [D loss: 0.528424, acc.: 71.88%] [G loss: 1.058475]\n",
      "epoch:9 step:8774 [D loss: 0.644344, acc.: 62.50%] [G loss: 1.170026]\n",
      "epoch:9 step:8775 [D loss: 0.621623, acc.: 68.75%] [G loss: 1.002134]\n",
      "epoch:9 step:8776 [D loss: 0.664765, acc.: 59.38%] [G loss: 1.041004]\n",
      "epoch:9 step:8777 [D loss: 0.520450, acc.: 76.56%] [G loss: 1.054208]\n",
      "epoch:9 step:8778 [D loss: 0.653625, acc.: 61.72%] [G loss: 1.025520]\n",
      "epoch:9 step:8779 [D loss: 0.657719, acc.: 64.84%] [G loss: 1.090704]\n",
      "epoch:9 step:8780 [D loss: 0.630735, acc.: 62.50%] [G loss: 1.132843]\n",
      "epoch:9 step:8781 [D loss: 0.653609, acc.: 58.59%] [G loss: 0.878572]\n",
      "epoch:9 step:8782 [D loss: 0.589493, acc.: 69.53%] [G loss: 1.183383]\n",
      "epoch:9 step:8783 [D loss: 0.701097, acc.: 57.81%] [G loss: 0.973043]\n",
      "epoch:9 step:8784 [D loss: 0.674885, acc.: 61.72%] [G loss: 1.097251]\n",
      "epoch:9 step:8785 [D loss: 0.629373, acc.: 59.38%] [G loss: 1.103130]\n",
      "epoch:9 step:8786 [D loss: 0.627006, acc.: 64.84%] [G loss: 1.069700]\n",
      "epoch:9 step:8787 [D loss: 0.578277, acc.: 70.31%] [G loss: 1.309422]\n",
      "epoch:9 step:8788 [D loss: 0.664214, acc.: 64.84%] [G loss: 1.023881]\n",
      "epoch:9 step:8789 [D loss: 0.612460, acc.: 64.84%] [G loss: 1.119535]\n",
      "epoch:9 step:8790 [D loss: 0.687555, acc.: 54.69%] [G loss: 1.047876]\n",
      "epoch:9 step:8791 [D loss: 0.648504, acc.: 64.06%] [G loss: 1.132727]\n",
      "epoch:9 step:8792 [D loss: 0.629365, acc.: 61.72%] [G loss: 0.990910]\n",
      "epoch:9 step:8793 [D loss: 0.505483, acc.: 79.69%] [G loss: 1.243097]\n",
      "epoch:9 step:8794 [D loss: 0.628867, acc.: 60.94%] [G loss: 1.123108]\n",
      "epoch:9 step:8795 [D loss: 0.622488, acc.: 71.09%] [G loss: 1.213936]\n",
      "epoch:9 step:8796 [D loss: 0.546364, acc.: 73.44%] [G loss: 0.980865]\n",
      "epoch:9 step:8797 [D loss: 0.585748, acc.: 68.75%] [G loss: 0.963962]\n",
      "epoch:9 step:8798 [D loss: 0.574597, acc.: 75.78%] [G loss: 1.178113]\n",
      "epoch:9 step:8799 [D loss: 0.581523, acc.: 69.53%] [G loss: 1.370883]\n",
      "epoch:9 step:8800 [D loss: 0.723657, acc.: 53.91%] [G loss: 1.138955]\n",
      "epoch:9 step:8801 [D loss: 0.499824, acc.: 80.47%] [G loss: 1.072787]\n",
      "epoch:9 step:8802 [D loss: 0.667471, acc.: 58.59%] [G loss: 0.982426]\n",
      "epoch:9 step:8803 [D loss: 0.640296, acc.: 58.59%] [G loss: 1.022056]\n",
      "epoch:9 step:8804 [D loss: 0.567607, acc.: 74.22%] [G loss: 1.145340]\n",
      "epoch:9 step:8805 [D loss: 0.545255, acc.: 70.31%] [G loss: 1.185441]\n",
      "epoch:9 step:8806 [D loss: 0.617741, acc.: 65.62%] [G loss: 1.152783]\n",
      "epoch:9 step:8807 [D loss: 0.740137, acc.: 53.12%] [G loss: 1.008483]\n",
      "epoch:9 step:8808 [D loss: 0.709004, acc.: 58.59%] [G loss: 1.009609]\n",
      "epoch:9 step:8809 [D loss: 0.722503, acc.: 57.81%] [G loss: 0.821061]\n",
      "epoch:9 step:8810 [D loss: 0.642428, acc.: 59.38%] [G loss: 1.033989]\n",
      "epoch:9 step:8811 [D loss: 0.557883, acc.: 72.66%] [G loss: 1.200383]\n",
      "epoch:9 step:8812 [D loss: 0.641403, acc.: 68.75%] [G loss: 1.051499]\n",
      "epoch:9 step:8813 [D loss: 0.723102, acc.: 53.91%] [G loss: 1.036201]\n",
      "epoch:9 step:8814 [D loss: 0.540568, acc.: 75.78%] [G loss: 1.146410]\n",
      "epoch:9 step:8815 [D loss: 0.665218, acc.: 59.38%] [G loss: 0.956193]\n",
      "epoch:9 step:8816 [D loss: 0.562711, acc.: 68.75%] [G loss: 1.330469]\n",
      "epoch:9 step:8817 [D loss: 0.619608, acc.: 67.97%] [G loss: 1.168038]\n",
      "epoch:9 step:8818 [D loss: 0.627163, acc.: 64.06%] [G loss: 1.117177]\n",
      "epoch:9 step:8819 [D loss: 0.608261, acc.: 71.88%] [G loss: 1.158252]\n",
      "epoch:9 step:8820 [D loss: 0.586867, acc.: 71.88%] [G loss: 1.259459]\n",
      "epoch:9 step:8821 [D loss: 0.598803, acc.: 67.97%] [G loss: 1.121446]\n",
      "epoch:9 step:8822 [D loss: 0.604123, acc.: 67.19%] [G loss: 1.222995]\n",
      "epoch:9 step:8823 [D loss: 0.668622, acc.: 61.72%] [G loss: 1.010383]\n",
      "epoch:9 step:8824 [D loss: 0.592870, acc.: 70.31%] [G loss: 1.092621]\n",
      "epoch:9 step:8825 [D loss: 0.534279, acc.: 75.00%] [G loss: 1.228182]\n",
      "epoch:9 step:8826 [D loss: 0.663943, acc.: 56.25%] [G loss: 0.996881]\n",
      "epoch:9 step:8827 [D loss: 0.498221, acc.: 78.12%] [G loss: 1.066818]\n",
      "epoch:9 step:8828 [D loss: 0.564239, acc.: 74.22%] [G loss: 1.216909]\n",
      "epoch:9 step:8829 [D loss: 0.538522, acc.: 75.78%] [G loss: 1.255060]\n",
      "epoch:9 step:8830 [D loss: 0.635815, acc.: 67.97%] [G loss: 1.098620]\n",
      "epoch:9 step:8831 [D loss: 0.588040, acc.: 70.31%] [G loss: 1.096057]\n",
      "epoch:9 step:8832 [D loss: 0.587351, acc.: 67.19%] [G loss: 1.128690]\n",
      "epoch:9 step:8833 [D loss: 0.738275, acc.: 58.59%] [G loss: 1.063000]\n",
      "epoch:9 step:8834 [D loss: 0.553335, acc.: 71.09%] [G loss: 1.173160]\n",
      "epoch:9 step:8835 [D loss: 0.645554, acc.: 61.72%] [G loss: 1.063246]\n",
      "epoch:9 step:8836 [D loss: 0.638720, acc.: 60.94%] [G loss: 1.285626]\n",
      "epoch:9 step:8837 [D loss: 0.605525, acc.: 68.75%] [G loss: 1.076947]\n",
      "epoch:9 step:8838 [D loss: 0.560156, acc.: 72.66%] [G loss: 0.994748]\n",
      "epoch:9 step:8839 [D loss: 0.661628, acc.: 60.94%] [G loss: 0.883953]\n",
      "epoch:9 step:8840 [D loss: 0.637576, acc.: 61.72%] [G loss: 1.120798]\n",
      "epoch:9 step:8841 [D loss: 0.581253, acc.: 67.19%] [G loss: 1.128766]\n",
      "epoch:9 step:8842 [D loss: 0.562886, acc.: 71.88%] [G loss: 1.209603]\n",
      "epoch:9 step:8843 [D loss: 0.726455, acc.: 53.91%] [G loss: 1.085415]\n",
      "epoch:9 step:8844 [D loss: 0.727109, acc.: 51.56%] [G loss: 0.941574]\n",
      "epoch:9 step:8845 [D loss: 0.641497, acc.: 61.72%] [G loss: 1.058033]\n",
      "epoch:9 step:8846 [D loss: 0.640327, acc.: 64.06%] [G loss: 1.254435]\n",
      "epoch:9 step:8847 [D loss: 0.549537, acc.: 71.88%] [G loss: 1.163846]\n",
      "epoch:9 step:8848 [D loss: 0.642173, acc.: 64.84%] [G loss: 1.067596]\n",
      "epoch:9 step:8849 [D loss: 0.670213, acc.: 59.38%] [G loss: 1.004068]\n",
      "epoch:9 step:8850 [D loss: 0.541323, acc.: 72.66%] [G loss: 1.365653]\n",
      "epoch:9 step:8851 [D loss: 0.634372, acc.: 64.06%] [G loss: 1.030274]\n",
      "epoch:9 step:8852 [D loss: 0.533317, acc.: 73.44%] [G loss: 1.105208]\n",
      "epoch:9 step:8853 [D loss: 0.706628, acc.: 60.94%] [G loss: 1.038740]\n",
      "epoch:9 step:8854 [D loss: 0.627631, acc.: 66.41%] [G loss: 1.193219]\n",
      "epoch:9 step:8855 [D loss: 0.526363, acc.: 71.88%] [G loss: 1.093499]\n",
      "epoch:9 step:8856 [D loss: 0.630270, acc.: 65.62%] [G loss: 1.047442]\n",
      "epoch:9 step:8857 [D loss: 0.592119, acc.: 67.97%] [G loss: 1.101116]\n",
      "epoch:9 step:8858 [D loss: 0.540688, acc.: 75.00%] [G loss: 1.177723]\n",
      "epoch:9 step:8859 [D loss: 0.650061, acc.: 63.28%] [G loss: 1.014050]\n",
      "epoch:9 step:8860 [D loss: 0.635154, acc.: 67.19%] [G loss: 0.966221]\n",
      "epoch:9 step:8861 [D loss: 0.641420, acc.: 62.50%] [G loss: 1.135322]\n",
      "epoch:9 step:8862 [D loss: 0.609290, acc.: 70.31%] [G loss: 1.080409]\n",
      "epoch:9 step:8863 [D loss: 0.607992, acc.: 69.53%] [G loss: 1.204180]\n",
      "epoch:9 step:8864 [D loss: 0.636290, acc.: 67.97%] [G loss: 1.008719]\n",
      "epoch:9 step:8865 [D loss: 0.601941, acc.: 67.97%] [G loss: 1.010695]\n",
      "epoch:9 step:8866 [D loss: 0.556527, acc.: 73.44%] [G loss: 1.061054]\n",
      "epoch:9 step:8867 [D loss: 0.677275, acc.: 54.69%] [G loss: 0.996325]\n",
      "epoch:9 step:8868 [D loss: 0.578569, acc.: 71.09%] [G loss: 1.031490]\n",
      "epoch:9 step:8869 [D loss: 0.606725, acc.: 67.97%] [G loss: 0.918209]\n",
      "epoch:9 step:8870 [D loss: 0.747424, acc.: 46.88%] [G loss: 0.950280]\n",
      "epoch:9 step:8871 [D loss: 0.644528, acc.: 59.38%] [G loss: 1.040237]\n",
      "epoch:9 step:8872 [D loss: 0.670346, acc.: 58.59%] [G loss: 1.092982]\n",
      "epoch:9 step:8873 [D loss: 0.630980, acc.: 64.06%] [G loss: 1.049717]\n",
      "epoch:9 step:8874 [D loss: 0.649332, acc.: 60.94%] [G loss: 1.274232]\n",
      "epoch:9 step:8875 [D loss: 0.651625, acc.: 60.94%] [G loss: 1.106723]\n",
      "epoch:9 step:8876 [D loss: 0.598996, acc.: 67.97%] [G loss: 1.258459]\n",
      "epoch:9 step:8877 [D loss: 0.668711, acc.: 59.38%] [G loss: 0.991119]\n",
      "epoch:9 step:8878 [D loss: 0.591442, acc.: 68.75%] [G loss: 1.055629]\n",
      "epoch:9 step:8879 [D loss: 0.617089, acc.: 65.62%] [G loss: 1.041186]\n",
      "epoch:9 step:8880 [D loss: 0.615495, acc.: 63.28%] [G loss: 1.099573]\n",
      "epoch:9 step:8881 [D loss: 0.607926, acc.: 64.06%] [G loss: 1.127605]\n",
      "epoch:9 step:8882 [D loss: 0.588881, acc.: 70.31%] [G loss: 1.134910]\n",
      "epoch:9 step:8883 [D loss: 0.655401, acc.: 60.16%] [G loss: 1.230332]\n",
      "epoch:9 step:8884 [D loss: 0.535820, acc.: 76.56%] [G loss: 1.237417]\n",
      "epoch:9 step:8885 [D loss: 0.713334, acc.: 55.47%] [G loss: 1.261792]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:9 step:8886 [D loss: 0.504060, acc.: 77.34%] [G loss: 1.308471]\n",
      "epoch:9 step:8887 [D loss: 0.539116, acc.: 77.34%] [G loss: 1.104641]\n",
      "epoch:9 step:8888 [D loss: 0.634037, acc.: 64.84%] [G loss: 1.106101]\n",
      "epoch:9 step:8889 [D loss: 0.714589, acc.: 52.34%] [G loss: 0.981965]\n",
      "epoch:9 step:8890 [D loss: 0.629400, acc.: 61.72%] [G loss: 0.960652]\n",
      "epoch:9 step:8891 [D loss: 0.570269, acc.: 71.88%] [G loss: 1.063013]\n",
      "epoch:9 step:8892 [D loss: 0.634505, acc.: 64.06%] [G loss: 1.276007]\n",
      "epoch:9 step:8893 [D loss: 0.558669, acc.: 75.00%] [G loss: 1.029786]\n",
      "epoch:9 step:8894 [D loss: 0.685807, acc.: 61.72%] [G loss: 1.089368]\n",
      "epoch:9 step:8895 [D loss: 0.615945, acc.: 68.75%] [G loss: 1.145470]\n",
      "epoch:9 step:8896 [D loss: 0.692689, acc.: 58.59%] [G loss: 1.033508]\n",
      "epoch:9 step:8897 [D loss: 0.659280, acc.: 60.94%] [G loss: 1.080419]\n",
      "epoch:9 step:8898 [D loss: 0.631391, acc.: 60.16%] [G loss: 1.004058]\n",
      "epoch:9 step:8899 [D loss: 0.572056, acc.: 74.22%] [G loss: 1.121574]\n",
      "epoch:9 step:8900 [D loss: 0.586601, acc.: 67.97%] [G loss: 1.208188]\n",
      "epoch:9 step:8901 [D loss: 0.610526, acc.: 67.19%] [G loss: 1.120787]\n",
      "epoch:9 step:8902 [D loss: 0.546319, acc.: 71.09%] [G loss: 1.106903]\n",
      "epoch:9 step:8903 [D loss: 0.690181, acc.: 57.81%] [G loss: 1.002572]\n",
      "epoch:9 step:8904 [D loss: 0.553771, acc.: 70.31%] [G loss: 1.181733]\n",
      "epoch:9 step:8905 [D loss: 0.621786, acc.: 61.72%] [G loss: 1.125969]\n",
      "epoch:9 step:8906 [D loss: 0.558750, acc.: 70.31%] [G loss: 1.145193]\n",
      "epoch:9 step:8907 [D loss: 0.605335, acc.: 67.19%] [G loss: 1.104292]\n",
      "epoch:9 step:8908 [D loss: 0.585615, acc.: 67.19%] [G loss: 1.069773]\n",
      "epoch:9 step:8909 [D loss: 0.580086, acc.: 70.31%] [G loss: 1.321140]\n",
      "epoch:9 step:8910 [D loss: 0.558587, acc.: 74.22%] [G loss: 0.973515]\n",
      "epoch:9 step:8911 [D loss: 0.658532, acc.: 62.50%] [G loss: 1.038608]\n",
      "epoch:9 step:8912 [D loss: 0.543079, acc.: 75.78%] [G loss: 1.035185]\n",
      "epoch:9 step:8913 [D loss: 0.588753, acc.: 68.75%] [G loss: 1.247831]\n",
      "epoch:9 step:8914 [D loss: 0.667605, acc.: 62.50%] [G loss: 1.141498]\n",
      "epoch:9 step:8915 [D loss: 0.579034, acc.: 71.88%] [G loss: 0.936260]\n",
      "epoch:9 step:8916 [D loss: 0.645795, acc.: 61.72%] [G loss: 1.114120]\n",
      "epoch:9 step:8917 [D loss: 0.627134, acc.: 68.75%] [G loss: 1.116659]\n",
      "epoch:9 step:8918 [D loss: 0.715092, acc.: 61.72%] [G loss: 1.085832]\n",
      "epoch:9 step:8919 [D loss: 0.684659, acc.: 64.06%] [G loss: 1.065441]\n",
      "epoch:9 step:8920 [D loss: 0.608213, acc.: 67.19%] [G loss: 1.135067]\n",
      "epoch:9 step:8921 [D loss: 0.675455, acc.: 61.72%] [G loss: 1.073817]\n",
      "epoch:9 step:8922 [D loss: 0.545710, acc.: 73.44%] [G loss: 1.134564]\n",
      "epoch:9 step:8923 [D loss: 0.564480, acc.: 71.88%] [G loss: 1.247076]\n",
      "epoch:9 step:8924 [D loss: 0.547460, acc.: 75.78%] [G loss: 1.085694]\n",
      "epoch:9 step:8925 [D loss: 0.644359, acc.: 65.62%] [G loss: 1.160594]\n",
      "epoch:9 step:8926 [D loss: 0.614911, acc.: 67.19%] [G loss: 1.139163]\n",
      "epoch:9 step:8927 [D loss: 0.609313, acc.: 68.75%] [G loss: 1.202741]\n",
      "epoch:9 step:8928 [D loss: 0.552542, acc.: 71.88%] [G loss: 1.045412]\n",
      "epoch:9 step:8929 [D loss: 0.614125, acc.: 71.88%] [G loss: 1.118552]\n",
      "epoch:9 step:8930 [D loss: 0.609253, acc.: 67.19%] [G loss: 1.106547]\n",
      "epoch:9 step:8931 [D loss: 0.559067, acc.: 71.09%] [G loss: 1.131574]\n",
      "epoch:9 step:8932 [D loss: 0.573241, acc.: 71.88%] [G loss: 1.495746]\n",
      "epoch:9 step:8933 [D loss: 0.577773, acc.: 67.97%] [G loss: 1.128936]\n",
      "epoch:9 step:8934 [D loss: 0.555409, acc.: 71.88%] [G loss: 0.977002]\n",
      "epoch:9 step:8935 [D loss: 0.565463, acc.: 73.44%] [G loss: 1.038448]\n",
      "epoch:9 step:8936 [D loss: 0.609445, acc.: 61.72%] [G loss: 1.190913]\n",
      "epoch:9 step:8937 [D loss: 0.653606, acc.: 63.28%] [G loss: 1.141291]\n",
      "epoch:9 step:8938 [D loss: 0.662860, acc.: 61.72%] [G loss: 1.143182]\n",
      "epoch:9 step:8939 [D loss: 0.576905, acc.: 67.97%] [G loss: 1.204825]\n",
      "epoch:9 step:8940 [D loss: 0.706727, acc.: 53.91%] [G loss: 1.052111]\n",
      "epoch:9 step:8941 [D loss: 0.637864, acc.: 63.28%] [G loss: 1.089535]\n",
      "epoch:9 step:8942 [D loss: 0.615677, acc.: 63.28%] [G loss: 1.033003]\n",
      "epoch:9 step:8943 [D loss: 0.641003, acc.: 64.84%] [G loss: 1.298159]\n",
      "epoch:9 step:8944 [D loss: 0.675028, acc.: 58.59%] [G loss: 1.208859]\n",
      "epoch:9 step:8945 [D loss: 0.525250, acc.: 75.78%] [G loss: 1.209935]\n",
      "epoch:9 step:8946 [D loss: 0.658642, acc.: 62.50%] [G loss: 1.036151]\n",
      "epoch:9 step:8947 [D loss: 0.684816, acc.: 59.38%] [G loss: 1.144974]\n",
      "epoch:9 step:8948 [D loss: 0.648864, acc.: 60.94%] [G loss: 1.116073]\n",
      "epoch:9 step:8949 [D loss: 0.601728, acc.: 71.09%] [G loss: 1.327503]\n",
      "epoch:9 step:8950 [D loss: 0.615080, acc.: 66.41%] [G loss: 1.107281]\n",
      "epoch:9 step:8951 [D loss: 0.617325, acc.: 68.75%] [G loss: 1.097698]\n",
      "epoch:9 step:8952 [D loss: 0.694566, acc.: 60.16%] [G loss: 1.123787]\n",
      "epoch:9 step:8953 [D loss: 0.707524, acc.: 56.25%] [G loss: 1.054652]\n",
      "epoch:9 step:8954 [D loss: 0.655253, acc.: 57.03%] [G loss: 0.964957]\n",
      "epoch:9 step:8955 [D loss: 0.736944, acc.: 50.00%] [G loss: 0.930534]\n",
      "epoch:9 step:8956 [D loss: 0.562068, acc.: 71.88%] [G loss: 1.229294]\n",
      "epoch:9 step:8957 [D loss: 0.640091, acc.: 64.06%] [G loss: 1.223662]\n",
      "epoch:9 step:8958 [D loss: 0.635443, acc.: 60.94%] [G loss: 1.180016]\n",
      "epoch:9 step:8959 [D loss: 0.702875, acc.: 55.47%] [G loss: 1.049715]\n",
      "epoch:9 step:8960 [D loss: 0.650190, acc.: 69.53%] [G loss: 0.926675]\n",
      "epoch:9 step:8961 [D loss: 0.569283, acc.: 69.53%] [G loss: 1.086162]\n",
      "epoch:9 step:8962 [D loss: 0.468105, acc.: 84.38%] [G loss: 1.130729]\n",
      "epoch:9 step:8963 [D loss: 0.626738, acc.: 64.84%] [G loss: 1.036239]\n",
      "epoch:9 step:8964 [D loss: 0.613668, acc.: 62.50%] [G loss: 1.063563]\n",
      "epoch:9 step:8965 [D loss: 0.646306, acc.: 63.28%] [G loss: 1.039038]\n",
      "epoch:9 step:8966 [D loss: 0.709846, acc.: 55.47%] [G loss: 1.019394]\n",
      "epoch:9 step:8967 [D loss: 0.581694, acc.: 67.97%] [G loss: 1.234045]\n",
      "epoch:9 step:8968 [D loss: 0.618578, acc.: 60.94%] [G loss: 1.199007]\n",
      "epoch:9 step:8969 [D loss: 0.618016, acc.: 62.50%] [G loss: 1.025811]\n",
      "epoch:9 step:8970 [D loss: 0.684276, acc.: 59.38%] [G loss: 0.932672]\n",
      "epoch:9 step:8971 [D loss: 0.466074, acc.: 83.59%] [G loss: 1.297559]\n",
      "epoch:9 step:8972 [D loss: 0.520282, acc.: 75.00%] [G loss: 1.043410]\n",
      "epoch:9 step:8973 [D loss: 0.531268, acc.: 76.56%] [G loss: 1.043695]\n",
      "epoch:9 step:8974 [D loss: 0.594515, acc.: 68.75%] [G loss: 1.161642]\n",
      "epoch:9 step:8975 [D loss: 0.527983, acc.: 76.56%] [G loss: 1.165894]\n",
      "epoch:9 step:8976 [D loss: 0.634334, acc.: 66.41%] [G loss: 1.043473]\n",
      "epoch:9 step:8977 [D loss: 0.650028, acc.: 60.94%] [G loss: 1.159186]\n",
      "epoch:9 step:8978 [D loss: 0.628501, acc.: 64.06%] [G loss: 1.245032]\n",
      "epoch:9 step:8979 [D loss: 0.562121, acc.: 70.31%] [G loss: 1.261857]\n",
      "epoch:9 step:8980 [D loss: 0.700683, acc.: 61.72%] [G loss: 1.163965]\n",
      "epoch:9 step:8981 [D loss: 0.558991, acc.: 72.66%] [G loss: 1.241100]\n",
      "epoch:9 step:8982 [D loss: 0.536328, acc.: 70.31%] [G loss: 1.165311]\n",
      "epoch:9 step:8983 [D loss: 0.568136, acc.: 74.22%] [G loss: 1.094812]\n",
      "epoch:9 step:8984 [D loss: 0.677901, acc.: 63.28%] [G loss: 1.041304]\n",
      "epoch:9 step:8985 [D loss: 0.711394, acc.: 53.91%] [G loss: 1.050987]\n",
      "epoch:9 step:8986 [D loss: 0.622380, acc.: 68.75%] [G loss: 1.141157]\n",
      "epoch:9 step:8987 [D loss: 0.589471, acc.: 67.19%] [G loss: 1.129612]\n",
      "epoch:9 step:8988 [D loss: 0.655935, acc.: 64.84%] [G loss: 1.028658]\n",
      "epoch:9 step:8989 [D loss: 0.691370, acc.: 57.03%] [G loss: 0.881195]\n",
      "epoch:9 step:8990 [D loss: 0.651743, acc.: 63.28%] [G loss: 1.002328]\n",
      "epoch:9 step:8991 [D loss: 0.600016, acc.: 71.88%] [G loss: 1.116673]\n",
      "epoch:9 step:8992 [D loss: 0.530598, acc.: 73.44%] [G loss: 1.302304]\n",
      "epoch:9 step:8993 [D loss: 0.646208, acc.: 61.72%] [G loss: 1.162800]\n",
      "epoch:9 step:8994 [D loss: 0.695046, acc.: 57.81%] [G loss: 1.102517]\n",
      "epoch:9 step:8995 [D loss: 0.580284, acc.: 70.31%] [G loss: 1.131643]\n",
      "epoch:9 step:8996 [D loss: 0.578865, acc.: 72.66%] [G loss: 1.315269]\n",
      "epoch:9 step:8997 [D loss: 0.541668, acc.: 75.00%] [G loss: 1.080083]\n",
      "epoch:9 step:8998 [D loss: 0.652661, acc.: 58.59%] [G loss: 1.159430]\n",
      "epoch:9 step:8999 [D loss: 0.717004, acc.: 57.03%] [G loss: 1.145437]\n",
      "epoch:9 step:9000 [D loss: 0.600746, acc.: 69.53%] [G loss: 1.025965]\n",
      "epoch:9 step:9001 [D loss: 0.771566, acc.: 53.91%] [G loss: 1.228252]\n",
      "epoch:9 step:9002 [D loss: 0.576881, acc.: 66.41%] [G loss: 1.334460]\n",
      "epoch:9 step:9003 [D loss: 0.577086, acc.: 67.19%] [G loss: 1.103573]\n",
      "epoch:9 step:9004 [D loss: 0.562934, acc.: 71.88%] [G loss: 1.046198]\n",
      "epoch:9 step:9005 [D loss: 0.573230, acc.: 73.44%] [G loss: 1.060271]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:9 step:9006 [D loss: 0.654183, acc.: 59.38%] [G loss: 1.063981]\n",
      "epoch:9 step:9007 [D loss: 0.672289, acc.: 60.94%] [G loss: 0.948400]\n",
      "epoch:9 step:9008 [D loss: 0.591933, acc.: 71.09%] [G loss: 1.035450]\n",
      "epoch:9 step:9009 [D loss: 0.514713, acc.: 80.47%] [G loss: 1.148183]\n",
      "epoch:9 step:9010 [D loss: 0.695776, acc.: 56.25%] [G loss: 1.011765]\n",
      "epoch:9 step:9011 [D loss: 0.554460, acc.: 73.44%] [G loss: 1.140461]\n",
      "epoch:9 step:9012 [D loss: 0.617094, acc.: 70.31%] [G loss: 1.174504]\n",
      "epoch:9 step:9013 [D loss: 0.602765, acc.: 69.53%] [G loss: 0.969193]\n",
      "epoch:9 step:9014 [D loss: 0.709137, acc.: 52.34%] [G loss: 1.133677]\n",
      "epoch:9 step:9015 [D loss: 0.569357, acc.: 68.75%] [G loss: 1.175515]\n",
      "epoch:9 step:9016 [D loss: 0.668280, acc.: 65.62%] [G loss: 1.088886]\n",
      "epoch:9 step:9017 [D loss: 0.506078, acc.: 75.00%] [G loss: 1.349599]\n",
      "epoch:9 step:9018 [D loss: 0.550266, acc.: 69.53%] [G loss: 1.264369]\n",
      "epoch:9 step:9019 [D loss: 0.710378, acc.: 53.91%] [G loss: 1.200121]\n",
      "epoch:9 step:9020 [D loss: 0.626777, acc.: 62.50%] [G loss: 1.121321]\n",
      "epoch:9 step:9021 [D loss: 0.629623, acc.: 67.19%] [G loss: 1.218030]\n",
      "epoch:9 step:9022 [D loss: 0.596762, acc.: 69.53%] [G loss: 1.039201]\n",
      "epoch:9 step:9023 [D loss: 0.630863, acc.: 59.38%] [G loss: 1.055217]\n",
      "epoch:9 step:9024 [D loss: 0.507653, acc.: 77.34%] [G loss: 1.095355]\n",
      "epoch:9 step:9025 [D loss: 0.539444, acc.: 74.22%] [G loss: 1.083568]\n",
      "epoch:9 step:9026 [D loss: 0.726890, acc.: 57.81%] [G loss: 0.858720]\n",
      "epoch:9 step:9027 [D loss: 0.593136, acc.: 70.31%] [G loss: 0.909222]\n",
      "epoch:9 step:9028 [D loss: 0.681825, acc.: 58.59%] [G loss: 1.004744]\n",
      "epoch:9 step:9029 [D loss: 0.638779, acc.: 69.53%] [G loss: 1.194637]\n",
      "epoch:9 step:9030 [D loss: 0.686937, acc.: 59.38%] [G loss: 1.039221]\n",
      "epoch:9 step:9031 [D loss: 0.638491, acc.: 63.28%] [G loss: 1.268393]\n",
      "epoch:9 step:9032 [D loss: 0.618475, acc.: 67.97%] [G loss: 1.078861]\n",
      "epoch:9 step:9033 [D loss: 0.588542, acc.: 67.97%] [G loss: 1.037917]\n",
      "epoch:9 step:9034 [D loss: 0.650555, acc.: 63.28%] [G loss: 1.122171]\n",
      "epoch:9 step:9035 [D loss: 0.547834, acc.: 76.56%] [G loss: 1.245595]\n",
      "epoch:9 step:9036 [D loss: 0.625149, acc.: 65.62%] [G loss: 1.029804]\n",
      "epoch:9 step:9037 [D loss: 0.632591, acc.: 61.72%] [G loss: 0.975405]\n",
      "epoch:9 step:9038 [D loss: 0.645817, acc.: 67.97%] [G loss: 0.864299]\n",
      "epoch:9 step:9039 [D loss: 0.628564, acc.: 60.94%] [G loss: 1.126720]\n",
      "epoch:9 step:9040 [D loss: 0.639406, acc.: 62.50%] [G loss: 1.078819]\n",
      "epoch:9 step:9041 [D loss: 0.506580, acc.: 75.00%] [G loss: 1.060823]\n",
      "epoch:9 step:9042 [D loss: 0.597426, acc.: 69.53%] [G loss: 1.192405]\n",
      "epoch:9 step:9043 [D loss: 0.624821, acc.: 62.50%] [G loss: 1.095082]\n",
      "epoch:9 step:9044 [D loss: 0.680529, acc.: 62.50%] [G loss: 1.187285]\n",
      "epoch:9 step:9045 [D loss: 0.558797, acc.: 71.09%] [G loss: 1.143934]\n",
      "epoch:9 step:9046 [D loss: 0.632130, acc.: 69.53%] [G loss: 1.114173]\n",
      "epoch:9 step:9047 [D loss: 0.647635, acc.: 60.16%] [G loss: 1.177223]\n",
      "epoch:9 step:9048 [D loss: 0.539633, acc.: 78.12%] [G loss: 1.345244]\n",
      "epoch:9 step:9049 [D loss: 0.536810, acc.: 72.66%] [G loss: 1.316784]\n",
      "epoch:9 step:9050 [D loss: 0.647181, acc.: 60.94%] [G loss: 1.240965]\n",
      "epoch:9 step:9051 [D loss: 0.574731, acc.: 70.31%] [G loss: 0.987178]\n",
      "epoch:9 step:9052 [D loss: 0.557617, acc.: 73.44%] [G loss: 1.245990]\n",
      "epoch:9 step:9053 [D loss: 0.623937, acc.: 64.84%] [G loss: 1.222516]\n",
      "epoch:9 step:9054 [D loss: 0.673067, acc.: 60.16%] [G loss: 1.045934]\n",
      "epoch:9 step:9055 [D loss: 0.594399, acc.: 69.53%] [G loss: 1.348226]\n",
      "epoch:9 step:9056 [D loss: 0.708573, acc.: 57.03%] [G loss: 1.013379]\n",
      "epoch:9 step:9057 [D loss: 0.593034, acc.: 67.97%] [G loss: 1.044562]\n",
      "epoch:9 step:9058 [D loss: 0.598746, acc.: 66.41%] [G loss: 0.976704]\n",
      "epoch:9 step:9059 [D loss: 0.568028, acc.: 74.22%] [G loss: 1.075858]\n",
      "epoch:9 step:9060 [D loss: 0.445914, acc.: 84.38%] [G loss: 1.225806]\n",
      "epoch:9 step:9061 [D loss: 0.626037, acc.: 64.84%] [G loss: 1.178874]\n",
      "epoch:9 step:9062 [D loss: 0.603420, acc.: 70.31%] [G loss: 1.079243]\n",
      "epoch:9 step:9063 [D loss: 0.633550, acc.: 65.62%] [G loss: 1.007793]\n",
      "epoch:9 step:9064 [D loss: 0.719839, acc.: 51.56%] [G loss: 0.919113]\n",
      "epoch:9 step:9065 [D loss: 0.636206, acc.: 60.94%] [G loss: 1.017985]\n",
      "epoch:9 step:9066 [D loss: 0.513910, acc.: 81.25%] [G loss: 1.165697]\n",
      "epoch:9 step:9067 [D loss: 0.530337, acc.: 74.22%] [G loss: 1.249722]\n",
      "epoch:9 step:9068 [D loss: 0.586330, acc.: 74.22%] [G loss: 1.121066]\n",
      "epoch:9 step:9069 [D loss: 0.610270, acc.: 67.19%] [G loss: 1.126849]\n",
      "epoch:9 step:9070 [D loss: 0.624657, acc.: 64.06%] [G loss: 1.094777]\n",
      "epoch:9 step:9071 [D loss: 0.644548, acc.: 67.97%] [G loss: 1.038757]\n",
      "epoch:9 step:9072 [D loss: 0.560212, acc.: 74.22%] [G loss: 1.107479]\n",
      "epoch:9 step:9073 [D loss: 0.584765, acc.: 70.31%] [G loss: 1.016582]\n",
      "epoch:9 step:9074 [D loss: 0.674990, acc.: 60.16%] [G loss: 0.949485]\n",
      "epoch:9 step:9075 [D loss: 0.563317, acc.: 75.00%] [G loss: 1.251412]\n",
      "epoch:9 step:9076 [D loss: 0.711972, acc.: 58.59%] [G loss: 0.983468]\n",
      "epoch:9 step:9077 [D loss: 0.549951, acc.: 72.66%] [G loss: 1.236765]\n",
      "epoch:9 step:9078 [D loss: 0.632535, acc.: 65.62%] [G loss: 1.051986]\n",
      "epoch:9 step:9079 [D loss: 0.608524, acc.: 64.84%] [G loss: 1.195761]\n",
      "epoch:9 step:9080 [D loss: 0.702592, acc.: 54.69%] [G loss: 1.109266]\n",
      "epoch:9 step:9081 [D loss: 0.497248, acc.: 75.78%] [G loss: 1.074277]\n",
      "epoch:9 step:9082 [D loss: 0.680660, acc.: 55.47%] [G loss: 1.066034]\n",
      "epoch:9 step:9083 [D loss: 0.627091, acc.: 64.06%] [G loss: 1.114928]\n",
      "epoch:9 step:9084 [D loss: 0.633819, acc.: 62.50%] [G loss: 0.925036]\n",
      "epoch:9 step:9085 [D loss: 0.573889, acc.: 72.66%] [G loss: 1.189871]\n",
      "epoch:9 step:9086 [D loss: 0.757291, acc.: 53.91%] [G loss: 1.053118]\n",
      "epoch:9 step:9087 [D loss: 0.541673, acc.: 75.00%] [G loss: 1.248298]\n",
      "epoch:9 step:9088 [D loss: 0.656975, acc.: 60.16%] [G loss: 1.116351]\n",
      "epoch:9 step:9089 [D loss: 0.475282, acc.: 77.34%] [G loss: 1.161255]\n",
      "epoch:9 step:9090 [D loss: 0.663678, acc.: 58.59%] [G loss: 1.144341]\n",
      "epoch:9 step:9091 [D loss: 0.714976, acc.: 56.25%] [G loss: 1.021270]\n",
      "epoch:9 step:9092 [D loss: 0.491996, acc.: 78.12%] [G loss: 1.251618]\n",
      "epoch:9 step:9093 [D loss: 0.628753, acc.: 64.06%] [G loss: 0.892857]\n",
      "epoch:9 step:9094 [D loss: 0.556238, acc.: 75.78%] [G loss: 1.372368]\n",
      "epoch:9 step:9095 [D loss: 0.679257, acc.: 56.25%] [G loss: 0.970394]\n",
      "epoch:9 step:9096 [D loss: 0.641446, acc.: 63.28%] [G loss: 1.081121]\n",
      "epoch:9 step:9097 [D loss: 0.651986, acc.: 65.62%] [G loss: 1.143769]\n",
      "epoch:9 step:9098 [D loss: 0.712915, acc.: 54.69%] [G loss: 1.003551]\n",
      "epoch:9 step:9099 [D loss: 0.538908, acc.: 73.44%] [G loss: 1.205234]\n",
      "epoch:9 step:9100 [D loss: 0.697813, acc.: 53.91%] [G loss: 1.059404]\n",
      "epoch:9 step:9101 [D loss: 0.668296, acc.: 61.72%] [G loss: 0.963427]\n",
      "epoch:9 step:9102 [D loss: 0.563509, acc.: 67.97%] [G loss: 1.125953]\n",
      "epoch:9 step:9103 [D loss: 0.709735, acc.: 53.91%] [G loss: 1.016439]\n",
      "epoch:9 step:9104 [D loss: 0.580231, acc.: 73.44%] [G loss: 1.141761]\n",
      "epoch:9 step:9105 [D loss: 0.569333, acc.: 75.00%] [G loss: 1.124068]\n",
      "epoch:9 step:9106 [D loss: 0.601360, acc.: 68.75%] [G loss: 1.178684]\n",
      "epoch:9 step:9107 [D loss: 0.566292, acc.: 69.53%] [G loss: 1.125440]\n",
      "epoch:9 step:9108 [D loss: 0.701233, acc.: 54.69%] [G loss: 1.018263]\n",
      "epoch:9 step:9109 [D loss: 0.687297, acc.: 57.03%] [G loss: 1.014588]\n",
      "epoch:9 step:9110 [D loss: 0.510137, acc.: 75.00%] [G loss: 1.280016]\n",
      "epoch:9 step:9111 [D loss: 0.645746, acc.: 64.06%] [G loss: 1.094880]\n",
      "epoch:9 step:9112 [D loss: 0.594329, acc.: 62.50%] [G loss: 1.115894]\n",
      "epoch:9 step:9113 [D loss: 0.650016, acc.: 65.62%] [G loss: 1.142823]\n",
      "epoch:9 step:9114 [D loss: 0.598923, acc.: 72.66%] [G loss: 1.040385]\n",
      "epoch:9 step:9115 [D loss: 0.613901, acc.: 60.94%] [G loss: 1.103676]\n",
      "epoch:9 step:9116 [D loss: 0.613947, acc.: 71.09%] [G loss: 1.101581]\n",
      "epoch:9 step:9117 [D loss: 0.517709, acc.: 78.91%] [G loss: 1.083559]\n",
      "epoch:9 step:9118 [D loss: 0.633667, acc.: 64.06%] [G loss: 1.178412]\n",
      "epoch:9 step:9119 [D loss: 0.561146, acc.: 68.75%] [G loss: 1.254394]\n",
      "epoch:9 step:9120 [D loss: 0.578513, acc.: 64.84%] [G loss: 1.317438]\n",
      "epoch:9 step:9121 [D loss: 0.586217, acc.: 67.97%] [G loss: 1.118303]\n",
      "epoch:9 step:9122 [D loss: 0.632489, acc.: 59.38%] [G loss: 1.313636]\n",
      "epoch:9 step:9123 [D loss: 0.634967, acc.: 67.19%] [G loss: 1.150038]\n",
      "epoch:9 step:9124 [D loss: 0.563150, acc.: 70.31%] [G loss: 1.327355]\n",
      "epoch:9 step:9125 [D loss: 0.591705, acc.: 68.75%] [G loss: 1.209971]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:9 step:9126 [D loss: 0.571285, acc.: 72.66%] [G loss: 0.926328]\n",
      "epoch:9 step:9127 [D loss: 0.626894, acc.: 62.50%] [G loss: 1.208775]\n",
      "epoch:9 step:9128 [D loss: 0.559000, acc.: 73.44%] [G loss: 1.191968]\n",
      "epoch:9 step:9129 [D loss: 0.586237, acc.: 67.19%] [G loss: 1.233529]\n",
      "epoch:9 step:9130 [D loss: 0.592099, acc.: 69.53%] [G loss: 1.145325]\n",
      "epoch:9 step:9131 [D loss: 0.661208, acc.: 60.94%] [G loss: 1.114630]\n",
      "epoch:9 step:9132 [D loss: 0.549662, acc.: 71.88%] [G loss: 1.233403]\n",
      "epoch:9 step:9133 [D loss: 0.665410, acc.: 66.41%] [G loss: 1.005752]\n",
      "epoch:9 step:9134 [D loss: 0.582514, acc.: 69.53%] [G loss: 1.074182]\n",
      "epoch:9 step:9135 [D loss: 0.501035, acc.: 78.91%] [G loss: 1.264713]\n",
      "epoch:9 step:9136 [D loss: 0.740440, acc.: 52.34%] [G loss: 0.963216]\n",
      "epoch:9 step:9137 [D loss: 0.652724, acc.: 64.06%] [G loss: 1.019591]\n",
      "epoch:9 step:9138 [D loss: 0.656935, acc.: 59.38%] [G loss: 1.082328]\n",
      "epoch:9 step:9139 [D loss: 0.634685, acc.: 65.62%] [G loss: 1.085202]\n",
      "epoch:9 step:9140 [D loss: 0.592553, acc.: 64.06%] [G loss: 1.067799]\n",
      "epoch:9 step:9141 [D loss: 0.589774, acc.: 73.44%] [G loss: 1.197700]\n",
      "epoch:9 step:9142 [D loss: 0.635135, acc.: 60.94%] [G loss: 1.297308]\n",
      "epoch:9 step:9143 [D loss: 0.624035, acc.: 61.72%] [G loss: 0.860318]\n",
      "epoch:9 step:9144 [D loss: 0.570759, acc.: 72.66%] [G loss: 0.974864]\n",
      "epoch:9 step:9145 [D loss: 0.683663, acc.: 58.59%] [G loss: 0.796067]\n",
      "epoch:9 step:9146 [D loss: 0.524123, acc.: 75.00%] [G loss: 1.079398]\n",
      "epoch:9 step:9147 [D loss: 0.671393, acc.: 58.59%] [G loss: 1.197731]\n",
      "epoch:9 step:9148 [D loss: 0.591353, acc.: 70.31%] [G loss: 1.406637]\n",
      "epoch:9 step:9149 [D loss: 0.515038, acc.: 79.69%] [G loss: 1.487463]\n",
      "epoch:9 step:9150 [D loss: 0.557433, acc.: 70.31%] [G loss: 1.158298]\n",
      "epoch:9 step:9151 [D loss: 0.528898, acc.: 76.56%] [G loss: 1.221353]\n",
      "epoch:9 step:9152 [D loss: 0.613846, acc.: 70.31%] [G loss: 1.350508]\n",
      "epoch:9 step:9153 [D loss: 0.630947, acc.: 61.72%] [G loss: 1.236341]\n",
      "epoch:9 step:9154 [D loss: 0.632636, acc.: 66.41%] [G loss: 1.021845]\n",
      "epoch:9 step:9155 [D loss: 0.611173, acc.: 67.97%] [G loss: 1.213735]\n",
      "epoch:9 step:9156 [D loss: 0.578468, acc.: 70.31%] [G loss: 1.174376]\n",
      "epoch:9 step:9157 [D loss: 0.624689, acc.: 64.84%] [G loss: 1.039339]\n",
      "epoch:9 step:9158 [D loss: 0.671070, acc.: 57.81%] [G loss: 1.174028]\n",
      "epoch:9 step:9159 [D loss: 0.633695, acc.: 65.62%] [G loss: 1.168058]\n",
      "epoch:9 step:9160 [D loss: 0.587994, acc.: 70.31%] [G loss: 1.226982]\n",
      "epoch:9 step:9161 [D loss: 0.754421, acc.: 53.12%] [G loss: 1.022497]\n",
      "epoch:9 step:9162 [D loss: 0.635098, acc.: 57.03%] [G loss: 0.970098]\n",
      "epoch:9 step:9163 [D loss: 0.658735, acc.: 61.72%] [G loss: 1.189503]\n",
      "epoch:9 step:9164 [D loss: 0.687051, acc.: 57.81%] [G loss: 1.548518]\n",
      "epoch:9 step:9165 [D loss: 0.602791, acc.: 62.50%] [G loss: 1.116604]\n",
      "epoch:9 step:9166 [D loss: 0.618357, acc.: 64.06%] [G loss: 1.129331]\n",
      "epoch:9 step:9167 [D loss: 0.523288, acc.: 76.56%] [G loss: 0.989071]\n",
      "epoch:9 step:9168 [D loss: 0.671595, acc.: 60.94%] [G loss: 1.032474]\n",
      "epoch:9 step:9169 [D loss: 0.571375, acc.: 76.56%] [G loss: 1.132843]\n",
      "epoch:9 step:9170 [D loss: 0.681793, acc.: 63.28%] [G loss: 1.107337]\n",
      "epoch:9 step:9171 [D loss: 0.619492, acc.: 66.41%] [G loss: 1.206083]\n",
      "epoch:9 step:9172 [D loss: 0.638683, acc.: 57.81%] [G loss: 0.928502]\n",
      "epoch:9 step:9173 [D loss: 0.556309, acc.: 70.31%] [G loss: 1.077261]\n",
      "epoch:9 step:9174 [D loss: 0.568909, acc.: 67.19%] [G loss: 1.247137]\n",
      "epoch:9 step:9175 [D loss: 0.626204, acc.: 61.72%] [G loss: 1.000944]\n",
      "epoch:9 step:9176 [D loss: 0.604828, acc.: 61.72%] [G loss: 1.062466]\n",
      "epoch:9 step:9177 [D loss: 0.713882, acc.: 51.56%] [G loss: 0.942207]\n",
      "epoch:9 step:9178 [D loss: 0.588991, acc.: 68.75%] [G loss: 1.138673]\n",
      "epoch:9 step:9179 [D loss: 0.656790, acc.: 62.50%] [G loss: 0.945345]\n",
      "epoch:9 step:9180 [D loss: 0.575317, acc.: 67.97%] [G loss: 1.202464]\n",
      "epoch:9 step:9181 [D loss: 0.558018, acc.: 71.88%] [G loss: 1.232244]\n",
      "epoch:9 step:9182 [D loss: 0.682978, acc.: 57.03%] [G loss: 0.928844]\n",
      "epoch:9 step:9183 [D loss: 0.621762, acc.: 64.84%] [G loss: 1.062935]\n",
      "epoch:9 step:9184 [D loss: 0.648114, acc.: 62.50%] [G loss: 1.217803]\n",
      "epoch:9 step:9185 [D loss: 0.688665, acc.: 60.94%] [G loss: 1.133934]\n",
      "epoch:9 step:9186 [D loss: 0.764277, acc.: 49.22%] [G loss: 0.904510]\n",
      "epoch:9 step:9187 [D loss: 0.611058, acc.: 67.97%] [G loss: 1.090096]\n",
      "epoch:9 step:9188 [D loss: 0.579878, acc.: 71.09%] [G loss: 1.309350]\n",
      "epoch:9 step:9189 [D loss: 0.571041, acc.: 68.75%] [G loss: 1.189391]\n",
      "epoch:9 step:9190 [D loss: 0.728592, acc.: 57.03%] [G loss: 0.862475]\n",
      "epoch:9 step:9191 [D loss: 0.642157, acc.: 67.97%] [G loss: 1.069238]\n",
      "epoch:9 step:9192 [D loss: 0.575870, acc.: 67.19%] [G loss: 1.280406]\n",
      "epoch:9 step:9193 [D loss: 0.565866, acc.: 68.75%] [G loss: 1.088042]\n",
      "epoch:9 step:9194 [D loss: 0.582350, acc.: 70.31%] [G loss: 1.228125]\n",
      "epoch:9 step:9195 [D loss: 0.670435, acc.: 60.94%] [G loss: 1.113051]\n",
      "epoch:9 step:9196 [D loss: 0.534867, acc.: 77.34%] [G loss: 0.937678]\n",
      "epoch:9 step:9197 [D loss: 0.665275, acc.: 58.59%] [G loss: 1.079582]\n",
      "epoch:9 step:9198 [D loss: 0.598089, acc.: 67.19%] [G loss: 0.994199]\n",
      "epoch:9 step:9199 [D loss: 0.649317, acc.: 65.62%] [G loss: 1.243084]\n",
      "epoch:9 step:9200 [D loss: 0.633455, acc.: 61.72%] [G loss: 1.093137]\n",
      "epoch:9 step:9201 [D loss: 0.606206, acc.: 67.19%] [G loss: 1.212557]\n",
      "epoch:9 step:9202 [D loss: 0.619682, acc.: 65.62%] [G loss: 1.130403]\n",
      "epoch:9 step:9203 [D loss: 0.560395, acc.: 75.78%] [G loss: 1.242991]\n",
      "epoch:9 step:9204 [D loss: 0.588879, acc.: 66.41%] [G loss: 1.122265]\n",
      "epoch:9 step:9205 [D loss: 0.556559, acc.: 69.53%] [G loss: 1.100152]\n",
      "epoch:9 step:9206 [D loss: 0.628438, acc.: 60.94%] [G loss: 1.363186]\n",
      "epoch:9 step:9207 [D loss: 0.665661, acc.: 59.38%] [G loss: 1.118216]\n",
      "epoch:9 step:9208 [D loss: 0.532569, acc.: 76.56%] [G loss: 1.138869]\n",
      "epoch:9 step:9209 [D loss: 0.563259, acc.: 76.56%] [G loss: 1.005629]\n",
      "epoch:9 step:9210 [D loss: 0.620083, acc.: 61.72%] [G loss: 1.137589]\n",
      "epoch:9 step:9211 [D loss: 0.595628, acc.: 70.31%] [G loss: 1.215448]\n",
      "epoch:9 step:9212 [D loss: 0.543515, acc.: 71.09%] [G loss: 1.452573]\n",
      "epoch:9 step:9213 [D loss: 0.871026, acc.: 36.72%] [G loss: 0.837832]\n",
      "epoch:9 step:9214 [D loss: 0.742271, acc.: 50.78%] [G loss: 1.044466]\n",
      "epoch:9 step:9215 [D loss: 0.667740, acc.: 59.38%] [G loss: 1.056603]\n",
      "epoch:9 step:9216 [D loss: 0.567540, acc.: 65.62%] [G loss: 1.085221]\n",
      "epoch:9 step:9217 [D loss: 0.640992, acc.: 64.84%] [G loss: 1.106795]\n",
      "epoch:9 step:9218 [D loss: 0.551518, acc.: 73.44%] [G loss: 1.069353]\n",
      "epoch:9 step:9219 [D loss: 0.585765, acc.: 65.62%] [G loss: 1.083135]\n",
      "epoch:9 step:9220 [D loss: 0.601003, acc.: 69.53%] [G loss: 0.958328]\n",
      "epoch:9 step:9221 [D loss: 0.683328, acc.: 57.81%] [G loss: 1.076879]\n",
      "epoch:9 step:9222 [D loss: 0.657634, acc.: 61.72%] [G loss: 1.172129]\n",
      "epoch:9 step:9223 [D loss: 0.640415, acc.: 56.25%] [G loss: 1.029729]\n",
      "epoch:9 step:9224 [D loss: 0.578894, acc.: 73.44%] [G loss: 1.230277]\n",
      "epoch:9 step:9225 [D loss: 0.602862, acc.: 62.50%] [G loss: 1.127380]\n",
      "epoch:9 step:9226 [D loss: 0.625948, acc.: 62.50%] [G loss: 0.960134]\n",
      "epoch:9 step:9227 [D loss: 0.571923, acc.: 71.88%] [G loss: 0.931987]\n",
      "epoch:9 step:9228 [D loss: 0.665948, acc.: 61.72%] [G loss: 1.128294]\n",
      "epoch:9 step:9229 [D loss: 0.566692, acc.: 68.75%] [G loss: 1.164966]\n",
      "epoch:9 step:9230 [D loss: 0.646422, acc.: 61.72%] [G loss: 1.187477]\n",
      "epoch:9 step:9231 [D loss: 0.664389, acc.: 59.38%] [G loss: 1.075072]\n",
      "epoch:9 step:9232 [D loss: 0.520342, acc.: 75.00%] [G loss: 0.992855]\n",
      "epoch:9 step:9233 [D loss: 0.523071, acc.: 76.56%] [G loss: 1.276323]\n",
      "epoch:9 step:9234 [D loss: 0.623259, acc.: 60.16%] [G loss: 1.025475]\n",
      "epoch:9 step:9235 [D loss: 0.673762, acc.: 56.25%] [G loss: 1.122640]\n",
      "epoch:9 step:9236 [D loss: 0.630366, acc.: 63.28%] [G loss: 1.139320]\n",
      "epoch:9 step:9237 [D loss: 0.551669, acc.: 70.31%] [G loss: 1.184255]\n",
      "epoch:9 step:9238 [D loss: 0.654904, acc.: 57.81%] [G loss: 1.029316]\n",
      "epoch:9 step:9239 [D loss: 0.542244, acc.: 75.78%] [G loss: 1.212667]\n",
      "epoch:9 step:9240 [D loss: 0.636211, acc.: 64.06%] [G loss: 1.134172]\n",
      "epoch:9 step:9241 [D loss: 0.643182, acc.: 63.28%] [G loss: 1.052092]\n",
      "epoch:9 step:9242 [D loss: 0.565016, acc.: 71.09%] [G loss: 1.068951]\n",
      "epoch:9 step:9243 [D loss: 0.547087, acc.: 71.88%] [G loss: 1.191976]\n",
      "epoch:9 step:9244 [D loss: 0.655098, acc.: 64.06%] [G loss: 1.038852]\n",
      "epoch:9 step:9245 [D loss: 0.508123, acc.: 79.69%] [G loss: 1.019263]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:9 step:9246 [D loss: 0.691068, acc.: 55.47%] [G loss: 1.101577]\n",
      "epoch:9 step:9247 [D loss: 0.575855, acc.: 68.75%] [G loss: 1.042515]\n",
      "epoch:9 step:9248 [D loss: 0.557033, acc.: 71.88%] [G loss: 1.287868]\n",
      "epoch:9 step:9249 [D loss: 0.592988, acc.: 71.09%] [G loss: 0.853449]\n",
      "epoch:9 step:9250 [D loss: 0.577625, acc.: 71.88%] [G loss: 1.075682]\n",
      "epoch:9 step:9251 [D loss: 0.605694, acc.: 63.28%] [G loss: 1.071408]\n",
      "epoch:9 step:9252 [D loss: 0.715510, acc.: 53.91%] [G loss: 1.118878]\n",
      "epoch:9 step:9253 [D loss: 0.596426, acc.: 70.31%] [G loss: 1.121649]\n",
      "epoch:9 step:9254 [D loss: 0.679187, acc.: 58.59%] [G loss: 1.172807]\n",
      "epoch:9 step:9255 [D loss: 0.668440, acc.: 58.59%] [G loss: 1.140893]\n",
      "epoch:9 step:9256 [D loss: 0.639294, acc.: 62.50%] [G loss: 0.959115]\n",
      "epoch:9 step:9257 [D loss: 0.600318, acc.: 66.41%] [G loss: 1.265638]\n",
      "epoch:9 step:9258 [D loss: 0.595765, acc.: 65.62%] [G loss: 0.894297]\n",
      "epoch:9 step:9259 [D loss: 0.538521, acc.: 78.12%] [G loss: 1.189148]\n",
      "epoch:9 step:9260 [D loss: 0.540254, acc.: 75.00%] [G loss: 1.218656]\n",
      "epoch:9 step:9261 [D loss: 0.733001, acc.: 57.81%] [G loss: 1.086090]\n",
      "epoch:9 step:9262 [D loss: 0.663281, acc.: 62.50%] [G loss: 1.142615]\n",
      "epoch:9 step:9263 [D loss: 0.613622, acc.: 65.62%] [G loss: 1.064200]\n",
      "epoch:9 step:9264 [D loss: 0.669469, acc.: 60.16%] [G loss: 1.138170]\n",
      "epoch:9 step:9265 [D loss: 0.584702, acc.: 70.31%] [G loss: 1.040135]\n",
      "epoch:9 step:9266 [D loss: 0.692428, acc.: 50.78%] [G loss: 0.938651]\n",
      "epoch:9 step:9267 [D loss: 0.609310, acc.: 69.53%] [G loss: 1.076888]\n",
      "epoch:9 step:9268 [D loss: 0.573431, acc.: 71.88%] [G loss: 1.382861]\n",
      "epoch:9 step:9269 [D loss: 0.641678, acc.: 62.50%] [G loss: 1.192014]\n",
      "epoch:9 step:9270 [D loss: 0.710061, acc.: 57.03%] [G loss: 0.907453]\n",
      "epoch:9 step:9271 [D loss: 0.543587, acc.: 72.66%] [G loss: 1.223100]\n",
      "epoch:9 step:9272 [D loss: 0.680396, acc.: 63.28%] [G loss: 1.127746]\n",
      "epoch:9 step:9273 [D loss: 0.634127, acc.: 68.75%] [G loss: 1.035277]\n",
      "epoch:9 step:9274 [D loss: 0.601243, acc.: 66.41%] [G loss: 1.013131]\n",
      "epoch:9 step:9275 [D loss: 0.565975, acc.: 69.53%] [G loss: 1.265636]\n",
      "epoch:9 step:9276 [D loss: 0.648480, acc.: 63.28%] [G loss: 1.254709]\n",
      "epoch:9 step:9277 [D loss: 0.649091, acc.: 62.50%] [G loss: 0.961307]\n",
      "epoch:9 step:9278 [D loss: 0.599241, acc.: 65.62%] [G loss: 1.024817]\n",
      "epoch:9 step:9279 [D loss: 0.595456, acc.: 67.19%] [G loss: 1.094052]\n",
      "epoch:9 step:9280 [D loss: 0.561541, acc.: 71.88%] [G loss: 1.211509]\n",
      "epoch:9 step:9281 [D loss: 0.685178, acc.: 55.47%] [G loss: 1.063218]\n",
      "epoch:9 step:9282 [D loss: 0.561784, acc.: 70.31%] [G loss: 1.321836]\n",
      "epoch:9 step:9283 [D loss: 0.621356, acc.: 64.06%] [G loss: 1.273552]\n",
      "epoch:9 step:9284 [D loss: 0.571098, acc.: 71.09%] [G loss: 1.320053]\n",
      "epoch:9 step:9285 [D loss: 0.538084, acc.: 76.56%] [G loss: 1.137523]\n",
      "epoch:9 step:9286 [D loss: 0.546640, acc.: 76.56%] [G loss: 1.054522]\n",
      "epoch:9 step:9287 [D loss: 0.543807, acc.: 71.09%] [G loss: 1.017263]\n",
      "epoch:9 step:9288 [D loss: 0.682124, acc.: 60.16%] [G loss: 0.937945]\n",
      "epoch:9 step:9289 [D loss: 0.634424, acc.: 67.97%] [G loss: 0.846276]\n",
      "epoch:9 step:9290 [D loss: 0.633949, acc.: 64.06%] [G loss: 1.271615]\n",
      "epoch:9 step:9291 [D loss: 0.688150, acc.: 60.16%] [G loss: 1.274183]\n",
      "epoch:9 step:9292 [D loss: 0.564037, acc.: 69.53%] [G loss: 1.315572]\n",
      "epoch:9 step:9293 [D loss: 0.699295, acc.: 54.69%] [G loss: 1.135491]\n",
      "epoch:9 step:9294 [D loss: 0.534363, acc.: 75.00%] [G loss: 1.016793]\n",
      "epoch:9 step:9295 [D loss: 0.757456, acc.: 47.66%] [G loss: 0.898379]\n",
      "epoch:9 step:9296 [D loss: 0.553393, acc.: 72.66%] [G loss: 1.170944]\n",
      "epoch:9 step:9297 [D loss: 0.734930, acc.: 52.34%] [G loss: 1.021149]\n",
      "epoch:9 step:9298 [D loss: 0.660768, acc.: 59.38%] [G loss: 1.077057]\n",
      "epoch:9 step:9299 [D loss: 0.562995, acc.: 71.88%] [G loss: 1.411189]\n",
      "epoch:9 step:9300 [D loss: 0.583109, acc.: 69.53%] [G loss: 1.122487]\n",
      "epoch:9 step:9301 [D loss: 0.586542, acc.: 70.31%] [G loss: 1.045351]\n",
      "epoch:9 step:9302 [D loss: 0.479751, acc.: 78.12%] [G loss: 1.152352]\n",
      "epoch:9 step:9303 [D loss: 0.541778, acc.: 75.78%] [G loss: 1.263661]\n",
      "epoch:9 step:9304 [D loss: 0.640271, acc.: 59.38%] [G loss: 1.125226]\n",
      "epoch:9 step:9305 [D loss: 0.633149, acc.: 57.81%] [G loss: 0.991225]\n",
      "epoch:9 step:9306 [D loss: 0.417630, acc.: 87.50%] [G loss: 1.316927]\n",
      "epoch:9 step:9307 [D loss: 0.624528, acc.: 67.97%] [G loss: 1.102709]\n",
      "epoch:9 step:9308 [D loss: 0.537011, acc.: 72.66%] [G loss: 1.258115]\n",
      "epoch:9 step:9309 [D loss: 0.671804, acc.: 61.72%] [G loss: 1.152842]\n",
      "epoch:9 step:9310 [D loss: 0.555093, acc.: 70.31%] [G loss: 1.287158]\n",
      "epoch:9 step:9311 [D loss: 0.678034, acc.: 55.47%] [G loss: 0.921434]\n",
      "epoch:9 step:9312 [D loss: 0.614292, acc.: 67.19%] [G loss: 1.135941]\n",
      "epoch:9 step:9313 [D loss: 0.559536, acc.: 74.22%] [G loss: 1.166943]\n",
      "epoch:9 step:9314 [D loss: 0.694625, acc.: 58.59%] [G loss: 1.034420]\n",
      "epoch:9 step:9315 [D loss: 0.539348, acc.: 71.88%] [G loss: 1.401806]\n",
      "epoch:9 step:9316 [D loss: 0.568008, acc.: 73.44%] [G loss: 1.053527]\n",
      "epoch:9 step:9317 [D loss: 0.635621, acc.: 64.84%] [G loss: 0.991428]\n",
      "epoch:9 step:9318 [D loss: 0.601078, acc.: 67.97%] [G loss: 1.287558]\n",
      "epoch:9 step:9319 [D loss: 0.547039, acc.: 77.34%] [G loss: 1.194855]\n",
      "epoch:9 step:9320 [D loss: 0.656340, acc.: 63.28%] [G loss: 1.059617]\n",
      "epoch:9 step:9321 [D loss: 0.673944, acc.: 53.91%] [G loss: 1.017328]\n",
      "epoch:9 step:9322 [D loss: 0.622542, acc.: 63.28%] [G loss: 1.123522]\n",
      "epoch:9 step:9323 [D loss: 0.530781, acc.: 78.91%] [G loss: 1.177459]\n",
      "epoch:9 step:9324 [D loss: 0.578258, acc.: 69.53%] [G loss: 1.194861]\n",
      "epoch:9 step:9325 [D loss: 0.620746, acc.: 64.84%] [G loss: 1.049185]\n",
      "epoch:9 step:9326 [D loss: 0.491454, acc.: 78.91%] [G loss: 1.382057]\n",
      "epoch:9 step:9327 [D loss: 0.670463, acc.: 63.28%] [G loss: 1.035540]\n",
      "epoch:9 step:9328 [D loss: 0.641633, acc.: 66.41%] [G loss: 1.014908]\n",
      "epoch:9 step:9329 [D loss: 0.688667, acc.: 58.59%] [G loss: 1.236844]\n",
      "epoch:9 step:9330 [D loss: 0.563745, acc.: 74.22%] [G loss: 1.328741]\n",
      "epoch:9 step:9331 [D loss: 0.596733, acc.: 70.31%] [G loss: 1.193720]\n",
      "epoch:9 step:9332 [D loss: 0.521739, acc.: 78.91%] [G loss: 1.151958]\n",
      "epoch:9 step:9333 [D loss: 0.662985, acc.: 60.94%] [G loss: 1.112389]\n",
      "epoch:9 step:9334 [D loss: 0.630423, acc.: 65.62%] [G loss: 1.063788]\n",
      "epoch:9 step:9335 [D loss: 0.586972, acc.: 71.09%] [G loss: 1.210367]\n",
      "epoch:9 step:9336 [D loss: 0.515001, acc.: 75.00%] [G loss: 1.041383]\n",
      "epoch:9 step:9337 [D loss: 0.637910, acc.: 63.28%] [G loss: 1.077984]\n",
      "epoch:9 step:9338 [D loss: 0.576811, acc.: 70.31%] [G loss: 1.405064]\n",
      "epoch:9 step:9339 [D loss: 0.536792, acc.: 75.00%] [G loss: 1.548569]\n",
      "epoch:9 step:9340 [D loss: 0.622597, acc.: 64.84%] [G loss: 1.093729]\n",
      "epoch:9 step:9341 [D loss: 0.690133, acc.: 61.72%] [G loss: 0.932677]\n",
      "epoch:9 step:9342 [D loss: 0.626032, acc.: 60.94%] [G loss: 1.093498]\n",
      "epoch:9 step:9343 [D loss: 0.663529, acc.: 63.28%] [G loss: 1.138432]\n",
      "epoch:9 step:9344 [D loss: 0.534909, acc.: 71.88%] [G loss: 1.276495]\n",
      "epoch:9 step:9345 [D loss: 0.554749, acc.: 72.66%] [G loss: 1.015301]\n",
      "epoch:9 step:9346 [D loss: 0.653434, acc.: 64.06%] [G loss: 0.999204]\n",
      "epoch:9 step:9347 [D loss: 0.510540, acc.: 76.56%] [G loss: 1.123852]\n",
      "epoch:9 step:9348 [D loss: 0.618037, acc.: 66.41%] [G loss: 1.222524]\n",
      "epoch:9 step:9349 [D loss: 0.575494, acc.: 67.97%] [G loss: 1.062886]\n",
      "epoch:9 step:9350 [D loss: 0.542818, acc.: 76.56%] [G loss: 1.187603]\n",
      "epoch:9 step:9351 [D loss: 0.509622, acc.: 75.00%] [G loss: 1.373592]\n",
      "epoch:9 step:9352 [D loss: 0.558162, acc.: 75.00%] [G loss: 0.975308]\n",
      "epoch:9 step:9353 [D loss: 0.725488, acc.: 55.47%] [G loss: 1.049749]\n",
      "epoch:9 step:9354 [D loss: 0.701173, acc.: 59.38%] [G loss: 1.061513]\n",
      "epoch:9 step:9355 [D loss: 0.538841, acc.: 71.09%] [G loss: 1.167908]\n",
      "epoch:9 step:9356 [D loss: 0.588992, acc.: 67.97%] [G loss: 1.068260]\n",
      "epoch:9 step:9357 [D loss: 0.571340, acc.: 69.53%] [G loss: 1.077791]\n",
      "epoch:9 step:9358 [D loss: 0.581556, acc.: 71.09%] [G loss: 1.049428]\n",
      "epoch:9 step:9359 [D loss: 0.625766, acc.: 64.84%] [G loss: 1.001012]\n",
      "epoch:9 step:9360 [D loss: 0.688370, acc.: 53.12%] [G loss: 1.024175]\n",
      "epoch:9 step:9361 [D loss: 0.610683, acc.: 67.97%] [G loss: 1.224893]\n",
      "epoch:9 step:9362 [D loss: 0.606972, acc.: 64.84%] [G loss: 1.224690]\n",
      "epoch:9 step:9363 [D loss: 0.615039, acc.: 64.06%] [G loss: 1.164566]\n",
      "epoch:9 step:9364 [D loss: 0.570806, acc.: 65.62%] [G loss: 1.163135]\n",
      "epoch:9 step:9365 [D loss: 0.581302, acc.: 68.75%] [G loss: 1.131193]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:9 step:9366 [D loss: 0.718160, acc.: 57.03%] [G loss: 0.924907]\n",
      "epoch:9 step:9367 [D loss: 0.658400, acc.: 62.50%] [G loss: 0.896933]\n",
      "epoch:9 step:9368 [D loss: 0.622816, acc.: 63.28%] [G loss: 1.099563]\n",
      "epoch:9 step:9369 [D loss: 0.595200, acc.: 66.41%] [G loss: 1.192169]\n",
      "epoch:9 step:9370 [D loss: 0.686043, acc.: 60.16%] [G loss: 0.994106]\n",
      "epoch:10 step:9371 [D loss: 0.655693, acc.: 64.06%] [G loss: 0.985099]\n",
      "epoch:10 step:9372 [D loss: 0.721609, acc.: 56.25%] [G loss: 1.070685]\n",
      "epoch:10 step:9373 [D loss: 0.662413, acc.: 59.38%] [G loss: 0.991161]\n",
      "epoch:10 step:9374 [D loss: 0.653963, acc.: 63.28%] [G loss: 1.203379]\n",
      "epoch:10 step:9375 [D loss: 0.672056, acc.: 65.62%] [G loss: 1.167486]\n",
      "epoch:10 step:9376 [D loss: 0.677269, acc.: 56.25%] [G loss: 1.280075]\n",
      "epoch:10 step:9377 [D loss: 0.652199, acc.: 58.59%] [G loss: 1.079212]\n",
      "epoch:10 step:9378 [D loss: 0.642228, acc.: 60.16%] [G loss: 1.034919]\n",
      "epoch:10 step:9379 [D loss: 0.508063, acc.: 75.78%] [G loss: 1.103314]\n",
      "epoch:10 step:9380 [D loss: 0.571386, acc.: 71.09%] [G loss: 1.291399]\n",
      "epoch:10 step:9381 [D loss: 0.594229, acc.: 69.53%] [G loss: 1.172459]\n",
      "epoch:10 step:9382 [D loss: 0.617663, acc.: 66.41%] [G loss: 1.079789]\n",
      "epoch:10 step:9383 [D loss: 0.643062, acc.: 64.06%] [G loss: 1.129131]\n",
      "epoch:10 step:9384 [D loss: 0.606380, acc.: 60.16%] [G loss: 0.985479]\n",
      "epoch:10 step:9385 [D loss: 0.516879, acc.: 75.78%] [G loss: 1.210233]\n",
      "epoch:10 step:9386 [D loss: 0.681735, acc.: 57.81%] [G loss: 1.083036]\n",
      "epoch:10 step:9387 [D loss: 0.562128, acc.: 71.88%] [G loss: 1.155130]\n",
      "epoch:10 step:9388 [D loss: 0.710556, acc.: 56.25%] [G loss: 0.873560]\n",
      "epoch:10 step:9389 [D loss: 0.620723, acc.: 60.16%] [G loss: 1.204201]\n",
      "epoch:10 step:9390 [D loss: 0.557804, acc.: 70.31%] [G loss: 1.048105]\n",
      "epoch:10 step:9391 [D loss: 0.650742, acc.: 67.19%] [G loss: 1.185106]\n",
      "epoch:10 step:9392 [D loss: 0.535998, acc.: 75.00%] [G loss: 1.181614]\n",
      "epoch:10 step:9393 [D loss: 0.606086, acc.: 66.41%] [G loss: 1.079552]\n",
      "epoch:10 step:9394 [D loss: 0.508001, acc.: 77.34%] [G loss: 1.077794]\n",
      "epoch:10 step:9395 [D loss: 0.645125, acc.: 63.28%] [G loss: 1.052200]\n",
      "epoch:10 step:9396 [D loss: 0.584732, acc.: 69.53%] [G loss: 1.030308]\n",
      "epoch:10 step:9397 [D loss: 0.522402, acc.: 82.03%] [G loss: 1.170420]\n",
      "epoch:10 step:9398 [D loss: 0.634173, acc.: 64.06%] [G loss: 1.107388]\n",
      "epoch:10 step:9399 [D loss: 0.604310, acc.: 67.19%] [G loss: 1.182821]\n",
      "epoch:10 step:9400 [D loss: 0.665715, acc.: 60.16%] [G loss: 0.972534]\n",
      "epoch:10 step:9401 [D loss: 0.585674, acc.: 67.97%] [G loss: 1.068033]\n",
      "epoch:10 step:9402 [D loss: 0.595722, acc.: 68.75%] [G loss: 1.172949]\n",
      "epoch:10 step:9403 [D loss: 0.616908, acc.: 68.75%] [G loss: 1.145938]\n",
      "epoch:10 step:9404 [D loss: 0.595774, acc.: 68.75%] [G loss: 1.075850]\n",
      "epoch:10 step:9405 [D loss: 0.547763, acc.: 75.78%] [G loss: 1.352345]\n",
      "epoch:10 step:9406 [D loss: 0.544849, acc.: 67.97%] [G loss: 1.295436]\n",
      "epoch:10 step:9407 [D loss: 0.502289, acc.: 77.34%] [G loss: 1.255892]\n",
      "epoch:10 step:9408 [D loss: 0.611675, acc.: 67.97%] [G loss: 1.084519]\n",
      "epoch:10 step:9409 [D loss: 0.732582, acc.: 56.25%] [G loss: 0.966282]\n",
      "epoch:10 step:9410 [D loss: 0.699128, acc.: 55.47%] [G loss: 1.015461]\n",
      "epoch:10 step:9411 [D loss: 0.550529, acc.: 68.75%] [G loss: 1.258610]\n",
      "epoch:10 step:9412 [D loss: 0.578266, acc.: 66.41%] [G loss: 1.387103]\n",
      "epoch:10 step:9413 [D loss: 0.589249, acc.: 66.41%] [G loss: 1.204412]\n",
      "epoch:10 step:9414 [D loss: 0.639379, acc.: 65.62%] [G loss: 1.157142]\n",
      "epoch:10 step:9415 [D loss: 0.643129, acc.: 62.50%] [G loss: 0.988561]\n",
      "epoch:10 step:9416 [D loss: 0.637996, acc.: 61.72%] [G loss: 0.955900]\n",
      "epoch:10 step:9417 [D loss: 0.678499, acc.: 60.94%] [G loss: 1.036625]\n",
      "epoch:10 step:9418 [D loss: 0.602808, acc.: 70.31%] [G loss: 1.163877]\n",
      "epoch:10 step:9419 [D loss: 0.550261, acc.: 71.09%] [G loss: 1.111221]\n",
      "epoch:10 step:9420 [D loss: 0.640318, acc.: 68.75%] [G loss: 1.080244]\n",
      "epoch:10 step:9421 [D loss: 0.648105, acc.: 66.41%] [G loss: 1.082663]\n",
      "epoch:10 step:9422 [D loss: 0.532363, acc.: 74.22%] [G loss: 1.244479]\n",
      "epoch:10 step:9423 [D loss: 0.587744, acc.: 69.53%] [G loss: 1.152741]\n",
      "epoch:10 step:9424 [D loss: 0.517940, acc.: 78.12%] [G loss: 1.322116]\n",
      "epoch:10 step:9425 [D loss: 0.618721, acc.: 61.72%] [G loss: 1.037791]\n",
      "epoch:10 step:9426 [D loss: 0.540062, acc.: 75.00%] [G loss: 1.164625]\n",
      "epoch:10 step:9427 [D loss: 0.627940, acc.: 59.38%] [G loss: 1.084348]\n",
      "epoch:10 step:9428 [D loss: 0.547371, acc.: 77.34%] [G loss: 1.077473]\n",
      "epoch:10 step:9429 [D loss: 0.506529, acc.: 80.47%] [G loss: 1.186670]\n",
      "epoch:10 step:9430 [D loss: 0.460113, acc.: 84.38%] [G loss: 1.109809]\n",
      "epoch:10 step:9431 [D loss: 0.736921, acc.: 56.25%] [G loss: 1.193528]\n",
      "epoch:10 step:9432 [D loss: 0.487047, acc.: 81.25%] [G loss: 1.148158]\n",
      "epoch:10 step:9433 [D loss: 0.577103, acc.: 74.22%] [G loss: 1.166632]\n",
      "epoch:10 step:9434 [D loss: 0.663435, acc.: 57.03%] [G loss: 1.007776]\n",
      "epoch:10 step:9435 [D loss: 0.611648, acc.: 67.97%] [G loss: 0.938327]\n",
      "epoch:10 step:9436 [D loss: 0.653022, acc.: 64.84%] [G loss: 1.157751]\n",
      "epoch:10 step:9437 [D loss: 0.579862, acc.: 70.31%] [G loss: 1.156012]\n",
      "epoch:10 step:9438 [D loss: 0.580094, acc.: 67.19%] [G loss: 1.192652]\n",
      "epoch:10 step:9439 [D loss: 0.551264, acc.: 70.31%] [G loss: 1.094601]\n",
      "epoch:10 step:9440 [D loss: 0.564711, acc.: 66.41%] [G loss: 1.189463]\n",
      "epoch:10 step:9441 [D loss: 0.605029, acc.: 68.75%] [G loss: 1.141575]\n",
      "epoch:10 step:9442 [D loss: 0.577594, acc.: 68.75%] [G loss: 1.199117]\n",
      "epoch:10 step:9443 [D loss: 0.581869, acc.: 67.97%] [G loss: 1.138308]\n",
      "epoch:10 step:9444 [D loss: 0.652956, acc.: 63.28%] [G loss: 1.221031]\n",
      "epoch:10 step:9445 [D loss: 0.610460, acc.: 72.66%] [G loss: 1.069886]\n",
      "epoch:10 step:9446 [D loss: 0.622009, acc.: 65.62%] [G loss: 1.289028]\n",
      "epoch:10 step:9447 [D loss: 0.627544, acc.: 61.72%] [G loss: 1.147829]\n",
      "epoch:10 step:9448 [D loss: 0.754500, acc.: 49.22%] [G loss: 1.110816]\n",
      "epoch:10 step:9449 [D loss: 0.723381, acc.: 57.03%] [G loss: 1.056135]\n",
      "epoch:10 step:9450 [D loss: 0.513509, acc.: 75.00%] [G loss: 1.437558]\n",
      "epoch:10 step:9451 [D loss: 0.678505, acc.: 60.94%] [G loss: 0.892346]\n",
      "epoch:10 step:9452 [D loss: 0.587939, acc.: 70.31%] [G loss: 1.030156]\n",
      "epoch:10 step:9453 [D loss: 0.727290, acc.: 50.00%] [G loss: 0.854183]\n",
      "epoch:10 step:9454 [D loss: 0.530727, acc.: 75.00%] [G loss: 1.142462]\n",
      "epoch:10 step:9455 [D loss: 0.577713, acc.: 72.66%] [G loss: 1.175397]\n",
      "epoch:10 step:9456 [D loss: 0.634172, acc.: 69.53%] [G loss: 1.289410]\n",
      "epoch:10 step:9457 [D loss: 0.635088, acc.: 67.97%] [G loss: 1.109507]\n",
      "epoch:10 step:9458 [D loss: 0.624092, acc.: 64.06%] [G loss: 1.007358]\n",
      "epoch:10 step:9459 [D loss: 0.566161, acc.: 71.09%] [G loss: 1.162210]\n",
      "epoch:10 step:9460 [D loss: 0.608925, acc.: 68.75%] [G loss: 1.115207]\n",
      "epoch:10 step:9461 [D loss: 0.615466, acc.: 63.28%] [G loss: 1.137550]\n",
      "epoch:10 step:9462 [D loss: 0.551063, acc.: 74.22%] [G loss: 1.269990]\n",
      "epoch:10 step:9463 [D loss: 0.625057, acc.: 68.75%] [G loss: 0.998305]\n",
      "epoch:10 step:9464 [D loss: 0.484475, acc.: 81.25%] [G loss: 1.102210]\n",
      "epoch:10 step:9465 [D loss: 0.606308, acc.: 71.09%] [G loss: 1.206061]\n",
      "epoch:10 step:9466 [D loss: 0.586380, acc.: 68.75%] [G loss: 1.142428]\n",
      "epoch:10 step:9467 [D loss: 0.751497, acc.: 48.44%] [G loss: 1.220351]\n",
      "epoch:10 step:9468 [D loss: 0.572941, acc.: 69.53%] [G loss: 1.121170]\n",
      "epoch:10 step:9469 [D loss: 0.701547, acc.: 53.91%] [G loss: 1.216557]\n",
      "epoch:10 step:9470 [D loss: 0.685624, acc.: 60.16%] [G loss: 1.159752]\n",
      "epoch:10 step:9471 [D loss: 0.638079, acc.: 64.06%] [G loss: 1.248621]\n",
      "epoch:10 step:9472 [D loss: 0.671573, acc.: 58.59%] [G loss: 1.011385]\n",
      "epoch:10 step:9473 [D loss: 0.520258, acc.: 75.78%] [G loss: 1.306342]\n",
      "epoch:10 step:9474 [D loss: 0.650372, acc.: 57.81%] [G loss: 1.143876]\n",
      "epoch:10 step:9475 [D loss: 0.669474, acc.: 62.50%] [G loss: 1.027342]\n",
      "epoch:10 step:9476 [D loss: 0.678825, acc.: 60.16%] [G loss: 1.214343]\n",
      "epoch:10 step:9477 [D loss: 0.535177, acc.: 75.78%] [G loss: 1.253645]\n",
      "epoch:10 step:9478 [D loss: 0.671716, acc.: 57.81%] [G loss: 1.005978]\n",
      "epoch:10 step:9479 [D loss: 0.688609, acc.: 59.38%] [G loss: 1.126341]\n",
      "epoch:10 step:9480 [D loss: 0.633139, acc.: 63.28%] [G loss: 1.079100]\n",
      "epoch:10 step:9481 [D loss: 0.628205, acc.: 61.72%] [G loss: 0.959037]\n",
      "epoch:10 step:9482 [D loss: 0.667750, acc.: 57.81%] [G loss: 0.811281]\n",
      "epoch:10 step:9483 [D loss: 0.537226, acc.: 75.78%] [G loss: 0.999068]\n",
      "epoch:10 step:9484 [D loss: 0.555874, acc.: 71.88%] [G loss: 1.054850]\n",
      "epoch:10 step:9485 [D loss: 0.679704, acc.: 58.59%] [G loss: 0.994627]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:10 step:9486 [D loss: 0.675330, acc.: 54.69%] [G loss: 1.029267]\n",
      "epoch:10 step:9487 [D loss: 0.624600, acc.: 61.72%] [G loss: 1.336051]\n",
      "epoch:10 step:9488 [D loss: 0.656245, acc.: 57.03%] [G loss: 1.141294]\n",
      "epoch:10 step:9489 [D loss: 0.571766, acc.: 71.09%] [G loss: 1.157275]\n",
      "epoch:10 step:9490 [D loss: 0.610839, acc.: 63.28%] [G loss: 1.011321]\n",
      "epoch:10 step:9491 [D loss: 0.533088, acc.: 77.34%] [G loss: 0.924264]\n",
      "epoch:10 step:9492 [D loss: 0.687351, acc.: 56.25%] [G loss: 0.891375]\n",
      "epoch:10 step:9493 [D loss: 0.651910, acc.: 60.94%] [G loss: 1.186491]\n",
      "epoch:10 step:9494 [D loss: 0.553754, acc.: 71.88%] [G loss: 1.059003]\n",
      "epoch:10 step:9495 [D loss: 0.590183, acc.: 69.53%] [G loss: 1.151781]\n",
      "epoch:10 step:9496 [D loss: 0.677539, acc.: 58.59%] [G loss: 1.177108]\n",
      "epoch:10 step:9497 [D loss: 0.752734, acc.: 51.56%] [G loss: 0.906524]\n",
      "epoch:10 step:9498 [D loss: 0.626079, acc.: 65.62%] [G loss: 1.077626]\n",
      "epoch:10 step:9499 [D loss: 0.580674, acc.: 68.75%] [G loss: 1.093803]\n",
      "epoch:10 step:9500 [D loss: 0.608813, acc.: 70.31%] [G loss: 1.111574]\n",
      "epoch:10 step:9501 [D loss: 0.550201, acc.: 69.53%] [G loss: 1.304825]\n",
      "epoch:10 step:9502 [D loss: 0.726090, acc.: 55.47%] [G loss: 1.151140]\n",
      "epoch:10 step:9503 [D loss: 0.570915, acc.: 70.31%] [G loss: 1.039787]\n",
      "epoch:10 step:9504 [D loss: 0.597732, acc.: 66.41%] [G loss: 1.145450]\n",
      "epoch:10 step:9505 [D loss: 0.604340, acc.: 66.41%] [G loss: 1.134284]\n",
      "epoch:10 step:9506 [D loss: 0.801439, acc.: 49.22%] [G loss: 1.056417]\n",
      "epoch:10 step:9507 [D loss: 0.614211, acc.: 66.41%] [G loss: 1.009704]\n",
      "epoch:10 step:9508 [D loss: 0.627897, acc.: 70.31%] [G loss: 1.143344]\n",
      "epoch:10 step:9509 [D loss: 0.589848, acc.: 70.31%] [G loss: 1.307570]\n",
      "epoch:10 step:9510 [D loss: 0.702014, acc.: 52.34%] [G loss: 1.107019]\n",
      "epoch:10 step:9511 [D loss: 0.717137, acc.: 57.03%] [G loss: 1.083105]\n",
      "epoch:10 step:9512 [D loss: 0.606896, acc.: 69.53%] [G loss: 1.054059]\n",
      "epoch:10 step:9513 [D loss: 0.607916, acc.: 67.19%] [G loss: 1.052682]\n",
      "epoch:10 step:9514 [D loss: 0.677864, acc.: 60.16%] [G loss: 1.057328]\n",
      "epoch:10 step:9515 [D loss: 0.623694, acc.: 67.19%] [G loss: 1.191401]\n",
      "epoch:10 step:9516 [D loss: 0.547803, acc.: 75.78%] [G loss: 1.149755]\n",
      "epoch:10 step:9517 [D loss: 0.609151, acc.: 66.41%] [G loss: 1.165098]\n",
      "epoch:10 step:9518 [D loss: 0.591298, acc.: 66.41%] [G loss: 1.089567]\n",
      "epoch:10 step:9519 [D loss: 0.536072, acc.: 75.78%] [G loss: 1.164128]\n",
      "epoch:10 step:9520 [D loss: 0.616827, acc.: 67.97%] [G loss: 0.918046]\n",
      "epoch:10 step:9521 [D loss: 0.568510, acc.: 70.31%] [G loss: 1.171012]\n",
      "epoch:10 step:9522 [D loss: 0.678082, acc.: 57.81%] [G loss: 0.881814]\n",
      "epoch:10 step:9523 [D loss: 0.663371, acc.: 60.16%] [G loss: 1.014227]\n",
      "epoch:10 step:9524 [D loss: 0.624574, acc.: 67.19%] [G loss: 1.084487]\n",
      "epoch:10 step:9525 [D loss: 0.540125, acc.: 72.66%] [G loss: 1.237713]\n",
      "epoch:10 step:9526 [D loss: 0.624292, acc.: 71.09%] [G loss: 1.023876]\n",
      "epoch:10 step:9527 [D loss: 0.785174, acc.: 44.53%] [G loss: 1.006607]\n",
      "epoch:10 step:9528 [D loss: 0.542378, acc.: 78.12%] [G loss: 0.996074]\n",
      "epoch:10 step:9529 [D loss: 0.595061, acc.: 67.19%] [G loss: 1.051499]\n",
      "epoch:10 step:9530 [D loss: 0.544967, acc.: 72.66%] [G loss: 1.106076]\n",
      "epoch:10 step:9531 [D loss: 0.567432, acc.: 69.53%] [G loss: 1.254148]\n",
      "epoch:10 step:9532 [D loss: 0.608602, acc.: 64.84%] [G loss: 1.074392]\n",
      "epoch:10 step:9533 [D loss: 0.603186, acc.: 65.62%] [G loss: 1.205080]\n",
      "epoch:10 step:9534 [D loss: 0.565043, acc.: 75.00%] [G loss: 1.121669]\n",
      "epoch:10 step:9535 [D loss: 0.727413, acc.: 55.47%] [G loss: 1.035489]\n",
      "epoch:10 step:9536 [D loss: 0.539597, acc.: 78.12%] [G loss: 1.047431]\n",
      "epoch:10 step:9537 [D loss: 0.489021, acc.: 82.03%] [G loss: 0.944150]\n",
      "epoch:10 step:9538 [D loss: 0.647694, acc.: 60.94%] [G loss: 0.941808]\n",
      "epoch:10 step:9539 [D loss: 0.681543, acc.: 63.28%] [G loss: 1.062987]\n",
      "epoch:10 step:9540 [D loss: 0.659631, acc.: 60.16%] [G loss: 0.982124]\n",
      "epoch:10 step:9541 [D loss: 0.645658, acc.: 62.50%] [G loss: 1.065408]\n",
      "epoch:10 step:9542 [D loss: 0.589986, acc.: 68.75%] [G loss: 1.151990]\n",
      "epoch:10 step:9543 [D loss: 0.609275, acc.: 67.97%] [G loss: 1.442250]\n",
      "epoch:10 step:9544 [D loss: 0.545967, acc.: 71.09%] [G loss: 1.151543]\n",
      "epoch:10 step:9545 [D loss: 0.635921, acc.: 62.50%] [G loss: 1.307683]\n",
      "epoch:10 step:9546 [D loss: 0.613874, acc.: 70.31%] [G loss: 1.109373]\n",
      "epoch:10 step:9547 [D loss: 0.539949, acc.: 78.12%] [G loss: 1.120654]\n",
      "epoch:10 step:9548 [D loss: 0.672182, acc.: 63.28%] [G loss: 1.115645]\n",
      "epoch:10 step:9549 [D loss: 0.544354, acc.: 76.56%] [G loss: 1.072388]\n",
      "epoch:10 step:9550 [D loss: 0.725574, acc.: 54.69%] [G loss: 0.975415]\n",
      "epoch:10 step:9551 [D loss: 0.506247, acc.: 82.03%] [G loss: 1.145516]\n",
      "epoch:10 step:9552 [D loss: 0.628926, acc.: 64.84%] [G loss: 1.118303]\n",
      "epoch:10 step:9553 [D loss: 0.586422, acc.: 73.44%] [G loss: 1.214340]\n",
      "epoch:10 step:9554 [D loss: 0.640376, acc.: 63.28%] [G loss: 0.980259]\n",
      "epoch:10 step:9555 [D loss: 0.674501, acc.: 56.25%] [G loss: 0.976691]\n",
      "epoch:10 step:9556 [D loss: 0.590747, acc.: 69.53%] [G loss: 1.089264]\n",
      "epoch:10 step:9557 [D loss: 0.637589, acc.: 65.62%] [G loss: 1.148967]\n",
      "epoch:10 step:9558 [D loss: 0.629811, acc.: 60.16%] [G loss: 1.103134]\n",
      "epoch:10 step:9559 [D loss: 0.720897, acc.: 54.69%] [G loss: 1.217817]\n",
      "epoch:10 step:9560 [D loss: 0.664096, acc.: 60.16%] [G loss: 1.194830]\n",
      "epoch:10 step:9561 [D loss: 0.572503, acc.: 71.09%] [G loss: 1.248810]\n",
      "epoch:10 step:9562 [D loss: 0.636300, acc.: 62.50%] [G loss: 1.213821]\n",
      "epoch:10 step:9563 [D loss: 0.648414, acc.: 63.28%] [G loss: 1.233565]\n",
      "epoch:10 step:9564 [D loss: 0.561015, acc.: 72.66%] [G loss: 1.095429]\n",
      "epoch:10 step:9565 [D loss: 0.474670, acc.: 78.91%] [G loss: 1.204005]\n",
      "epoch:10 step:9566 [D loss: 0.620057, acc.: 69.53%] [G loss: 1.000881]\n",
      "epoch:10 step:9567 [D loss: 0.567614, acc.: 71.09%] [G loss: 1.318179]\n",
      "epoch:10 step:9568 [D loss: 0.575308, acc.: 71.88%] [G loss: 1.028381]\n",
      "epoch:10 step:9569 [D loss: 0.631281, acc.: 61.72%] [G loss: 0.984969]\n",
      "epoch:10 step:9570 [D loss: 0.616220, acc.: 70.31%] [G loss: 1.181582]\n",
      "epoch:10 step:9571 [D loss: 0.552393, acc.: 71.09%] [G loss: 1.319452]\n",
      "epoch:10 step:9572 [D loss: 0.663486, acc.: 60.94%] [G loss: 0.905643]\n",
      "epoch:10 step:9573 [D loss: 0.631372, acc.: 63.28%] [G loss: 1.263989]\n",
      "epoch:10 step:9574 [D loss: 0.573625, acc.: 70.31%] [G loss: 1.206740]\n",
      "epoch:10 step:9575 [D loss: 0.713426, acc.: 57.81%] [G loss: 1.225560]\n",
      "epoch:10 step:9576 [D loss: 0.608064, acc.: 71.88%] [G loss: 1.117128]\n",
      "epoch:10 step:9577 [D loss: 0.545995, acc.: 68.75%] [G loss: 1.234600]\n",
      "epoch:10 step:9578 [D loss: 0.527497, acc.: 75.78%] [G loss: 1.101248]\n",
      "epoch:10 step:9579 [D loss: 0.624427, acc.: 71.88%] [G loss: 1.057738]\n",
      "epoch:10 step:9580 [D loss: 0.580065, acc.: 70.31%] [G loss: 1.089069]\n",
      "epoch:10 step:9581 [D loss: 0.539358, acc.: 73.44%] [G loss: 1.172279]\n",
      "epoch:10 step:9582 [D loss: 0.601490, acc.: 69.53%] [G loss: 1.256273]\n",
      "epoch:10 step:9583 [D loss: 0.647252, acc.: 64.84%] [G loss: 1.180043]\n",
      "epoch:10 step:9584 [D loss: 0.608954, acc.: 67.19%] [G loss: 1.097848]\n",
      "epoch:10 step:9585 [D loss: 0.711889, acc.: 53.91%] [G loss: 1.197009]\n",
      "epoch:10 step:9586 [D loss: 0.626938, acc.: 66.41%] [G loss: 1.287942]\n",
      "epoch:10 step:9587 [D loss: 0.594664, acc.: 64.06%] [G loss: 0.888042]\n",
      "epoch:10 step:9588 [D loss: 0.745906, acc.: 50.78%] [G loss: 0.964710]\n",
      "epoch:10 step:9589 [D loss: 0.707889, acc.: 56.25%] [G loss: 1.174011]\n",
      "epoch:10 step:9590 [D loss: 0.639388, acc.: 61.72%] [G loss: 1.180094]\n",
      "epoch:10 step:9591 [D loss: 0.579047, acc.: 72.66%] [G loss: 1.240757]\n",
      "epoch:10 step:9592 [D loss: 0.598007, acc.: 66.41%] [G loss: 1.204595]\n",
      "epoch:10 step:9593 [D loss: 0.558660, acc.: 71.88%] [G loss: 1.299516]\n",
      "epoch:10 step:9594 [D loss: 0.660622, acc.: 63.28%] [G loss: 0.870312]\n",
      "epoch:10 step:9595 [D loss: 0.575636, acc.: 70.31%] [G loss: 1.086139]\n",
      "epoch:10 step:9596 [D loss: 0.690558, acc.: 60.94%] [G loss: 1.194269]\n",
      "epoch:10 step:9597 [D loss: 0.542684, acc.: 74.22%] [G loss: 1.196356]\n",
      "epoch:10 step:9598 [D loss: 0.645820, acc.: 62.50%] [G loss: 0.992750]\n",
      "epoch:10 step:9599 [D loss: 0.562676, acc.: 71.88%] [G loss: 1.123403]\n",
      "epoch:10 step:9600 [D loss: 0.587029, acc.: 69.53%] [G loss: 1.028269]\n",
      "epoch:10 step:9601 [D loss: 0.573006, acc.: 67.19%] [G loss: 1.202513]\n",
      "epoch:10 step:9602 [D loss: 0.698422, acc.: 54.69%] [G loss: 1.084347]\n",
      "epoch:10 step:9603 [D loss: 0.653383, acc.: 66.41%] [G loss: 1.140678]\n",
      "epoch:10 step:9604 [D loss: 0.678845, acc.: 56.25%] [G loss: 1.283924]\n",
      "epoch:10 step:9605 [D loss: 0.632867, acc.: 67.19%] [G loss: 1.196054]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:10 step:9606 [D loss: 0.574126, acc.: 70.31%] [G loss: 1.186163]\n",
      "epoch:10 step:9607 [D loss: 0.697396, acc.: 57.81%] [G loss: 1.137513]\n",
      "epoch:10 step:9608 [D loss: 0.649595, acc.: 60.16%] [G loss: 0.952999]\n",
      "epoch:10 step:9609 [D loss: 0.565652, acc.: 71.09%] [G loss: 1.164228]\n",
      "epoch:10 step:9610 [D loss: 0.622550, acc.: 67.97%] [G loss: 1.101054]\n",
      "epoch:10 step:9611 [D loss: 0.595262, acc.: 72.66%] [G loss: 1.370670]\n",
      "epoch:10 step:9612 [D loss: 0.706438, acc.: 58.59%] [G loss: 1.393898]\n",
      "epoch:10 step:9613 [D loss: 0.531675, acc.: 75.78%] [G loss: 1.276801]\n",
      "epoch:10 step:9614 [D loss: 0.651471, acc.: 60.94%] [G loss: 1.220254]\n",
      "epoch:10 step:9615 [D loss: 0.678351, acc.: 58.59%] [G loss: 1.033319]\n",
      "epoch:10 step:9616 [D loss: 0.630617, acc.: 67.97%] [G loss: 1.068864]\n",
      "epoch:10 step:9617 [D loss: 0.607750, acc.: 63.28%] [G loss: 1.259415]\n",
      "epoch:10 step:9618 [D loss: 0.625679, acc.: 67.19%] [G loss: 1.256322]\n",
      "epoch:10 step:9619 [D loss: 0.547769, acc.: 72.66%] [G loss: 1.094242]\n",
      "epoch:10 step:9620 [D loss: 0.604439, acc.: 68.75%] [G loss: 1.185297]\n",
      "epoch:10 step:9621 [D loss: 0.643969, acc.: 62.50%] [G loss: 1.085411]\n",
      "epoch:10 step:9622 [D loss: 0.550974, acc.: 70.31%] [G loss: 1.229702]\n",
      "epoch:10 step:9623 [D loss: 0.666861, acc.: 59.38%] [G loss: 1.062212]\n",
      "epoch:10 step:9624 [D loss: 0.576341, acc.: 69.53%] [G loss: 1.268259]\n",
      "epoch:10 step:9625 [D loss: 0.675466, acc.: 54.69%] [G loss: 1.266056]\n",
      "epoch:10 step:9626 [D loss: 0.661352, acc.: 57.81%] [G loss: 1.182881]\n",
      "epoch:10 step:9627 [D loss: 0.657005, acc.: 63.28%] [G loss: 1.115245]\n",
      "epoch:10 step:9628 [D loss: 0.592842, acc.: 67.19%] [G loss: 1.179934]\n",
      "epoch:10 step:9629 [D loss: 0.555398, acc.: 71.88%] [G loss: 1.206978]\n",
      "epoch:10 step:9630 [D loss: 0.575838, acc.: 65.62%] [G loss: 1.248397]\n",
      "epoch:10 step:9631 [D loss: 0.658759, acc.: 60.94%] [G loss: 1.229257]\n",
      "epoch:10 step:9632 [D loss: 0.577540, acc.: 68.75%] [G loss: 1.027306]\n",
      "epoch:10 step:9633 [D loss: 0.688150, acc.: 57.03%] [G loss: 1.132969]\n",
      "epoch:10 step:9634 [D loss: 0.622980, acc.: 62.50%] [G loss: 1.202587]\n",
      "epoch:10 step:9635 [D loss: 0.582489, acc.: 72.66%] [G loss: 1.109967]\n",
      "epoch:10 step:9636 [D loss: 0.629357, acc.: 68.75%] [G loss: 1.222954]\n",
      "epoch:10 step:9637 [D loss: 0.628103, acc.: 64.06%] [G loss: 1.007463]\n",
      "epoch:10 step:9638 [D loss: 0.654521, acc.: 64.06%] [G loss: 0.894672]\n",
      "epoch:10 step:9639 [D loss: 0.575152, acc.: 73.44%] [G loss: 1.165234]\n",
      "epoch:10 step:9640 [D loss: 0.576286, acc.: 70.31%] [G loss: 1.235010]\n",
      "epoch:10 step:9641 [D loss: 0.616420, acc.: 66.41%] [G loss: 1.129956]\n",
      "epoch:10 step:9642 [D loss: 0.605515, acc.: 67.19%] [G loss: 0.970846]\n",
      "epoch:10 step:9643 [D loss: 0.797714, acc.: 45.31%] [G loss: 0.996369]\n",
      "epoch:10 step:9644 [D loss: 0.519457, acc.: 71.88%] [G loss: 1.268855]\n",
      "epoch:10 step:9645 [D loss: 0.767300, acc.: 53.12%] [G loss: 1.194689]\n",
      "epoch:10 step:9646 [D loss: 0.637883, acc.: 66.41%] [G loss: 1.180809]\n",
      "epoch:10 step:9647 [D loss: 0.594521, acc.: 67.19%] [G loss: 1.185029]\n",
      "epoch:10 step:9648 [D loss: 0.609738, acc.: 68.75%] [G loss: 1.214141]\n",
      "epoch:10 step:9649 [D loss: 0.696521, acc.: 57.81%] [G loss: 0.957028]\n",
      "epoch:10 step:9650 [D loss: 0.646629, acc.: 65.62%] [G loss: 0.967031]\n",
      "epoch:10 step:9651 [D loss: 0.601407, acc.: 70.31%] [G loss: 1.170279]\n",
      "epoch:10 step:9652 [D loss: 0.547863, acc.: 74.22%] [G loss: 1.377566]\n",
      "epoch:10 step:9653 [D loss: 0.567722, acc.: 70.31%] [G loss: 1.063787]\n",
      "epoch:10 step:9654 [D loss: 0.642229, acc.: 62.50%] [G loss: 0.970282]\n",
      "epoch:10 step:9655 [D loss: 0.603360, acc.: 70.31%] [G loss: 1.062025]\n",
      "epoch:10 step:9656 [D loss: 0.609097, acc.: 66.41%] [G loss: 1.130553]\n",
      "epoch:10 step:9657 [D loss: 0.503864, acc.: 76.56%] [G loss: 1.211534]\n",
      "epoch:10 step:9658 [D loss: 0.572477, acc.: 70.31%] [G loss: 1.274164]\n",
      "epoch:10 step:9659 [D loss: 0.558082, acc.: 68.75%] [G loss: 1.157431]\n",
      "epoch:10 step:9660 [D loss: 0.714503, acc.: 53.12%] [G loss: 1.087446]\n",
      "epoch:10 step:9661 [D loss: 0.570915, acc.: 71.09%] [G loss: 1.206857]\n",
      "epoch:10 step:9662 [D loss: 0.677984, acc.: 48.44%] [G loss: 1.112876]\n",
      "epoch:10 step:9663 [D loss: 0.569369, acc.: 74.22%] [G loss: 1.171906]\n",
      "epoch:10 step:9664 [D loss: 0.719684, acc.: 57.03%] [G loss: 0.998681]\n",
      "epoch:10 step:9665 [D loss: 0.602283, acc.: 66.41%] [G loss: 1.108400]\n",
      "epoch:10 step:9666 [D loss: 0.602039, acc.: 70.31%] [G loss: 0.978236]\n",
      "epoch:10 step:9667 [D loss: 0.529663, acc.: 72.66%] [G loss: 1.017776]\n",
      "epoch:10 step:9668 [D loss: 0.615057, acc.: 68.75%] [G loss: 0.962385]\n",
      "epoch:10 step:9669 [D loss: 0.568022, acc.: 70.31%] [G loss: 1.161439]\n",
      "epoch:10 step:9670 [D loss: 0.664353, acc.: 62.50%] [G loss: 0.873789]\n",
      "epoch:10 step:9671 [D loss: 0.654186, acc.: 64.06%] [G loss: 1.022062]\n",
      "epoch:10 step:9672 [D loss: 0.557393, acc.: 70.31%] [G loss: 1.133700]\n",
      "epoch:10 step:9673 [D loss: 0.643297, acc.: 60.94%] [G loss: 1.018640]\n",
      "epoch:10 step:9674 [D loss: 0.716953, acc.: 57.03%] [G loss: 0.972122]\n",
      "epoch:10 step:9675 [D loss: 0.650411, acc.: 58.59%] [G loss: 1.074436]\n",
      "epoch:10 step:9676 [D loss: 0.638724, acc.: 69.53%] [G loss: 1.077647]\n",
      "epoch:10 step:9677 [D loss: 0.650937, acc.: 54.69%] [G loss: 1.174027]\n",
      "epoch:10 step:9678 [D loss: 0.588142, acc.: 67.97%] [G loss: 1.204231]\n",
      "epoch:10 step:9679 [D loss: 0.604267, acc.: 67.97%] [G loss: 1.103409]\n",
      "epoch:10 step:9680 [D loss: 0.568419, acc.: 70.31%] [G loss: 1.227322]\n",
      "epoch:10 step:9681 [D loss: 0.563039, acc.: 71.88%] [G loss: 1.292154]\n",
      "epoch:10 step:9682 [D loss: 0.656020, acc.: 59.38%] [G loss: 1.127122]\n",
      "epoch:10 step:9683 [D loss: 0.686837, acc.: 53.91%] [G loss: 1.319059]\n",
      "epoch:10 step:9684 [D loss: 0.621034, acc.: 62.50%] [G loss: 0.984311]\n",
      "epoch:10 step:9685 [D loss: 0.653887, acc.: 61.72%] [G loss: 1.015309]\n",
      "epoch:10 step:9686 [D loss: 0.692881, acc.: 54.69%] [G loss: 1.126362]\n",
      "epoch:10 step:9687 [D loss: 0.572646, acc.: 73.44%] [G loss: 1.116464]\n",
      "epoch:10 step:9688 [D loss: 0.668901, acc.: 57.03%] [G loss: 1.099622]\n",
      "epoch:10 step:9689 [D loss: 0.521639, acc.: 81.25%] [G loss: 1.159971]\n",
      "epoch:10 step:9690 [D loss: 0.645979, acc.: 63.28%] [G loss: 1.118280]\n",
      "epoch:10 step:9691 [D loss: 0.650060, acc.: 62.50%] [G loss: 1.228650]\n",
      "epoch:10 step:9692 [D loss: 0.680870, acc.: 57.03%] [G loss: 1.050493]\n",
      "epoch:10 step:9693 [D loss: 0.578547, acc.: 71.09%] [G loss: 1.054039]\n",
      "epoch:10 step:9694 [D loss: 0.641708, acc.: 60.94%] [G loss: 1.082030]\n",
      "epoch:10 step:9695 [D loss: 0.695002, acc.: 57.03%] [G loss: 0.984178]\n",
      "epoch:10 step:9696 [D loss: 0.599635, acc.: 67.19%] [G loss: 1.096312]\n",
      "epoch:10 step:9697 [D loss: 0.662947, acc.: 60.94%] [G loss: 1.182836]\n",
      "epoch:10 step:9698 [D loss: 0.596565, acc.: 69.53%] [G loss: 1.059915]\n",
      "epoch:10 step:9699 [D loss: 0.702303, acc.: 58.59%] [G loss: 1.065410]\n",
      "epoch:10 step:9700 [D loss: 0.650064, acc.: 63.28%] [G loss: 1.072561]\n",
      "epoch:10 step:9701 [D loss: 0.524140, acc.: 74.22%] [G loss: 1.175641]\n",
      "epoch:10 step:9702 [D loss: 0.696065, acc.: 55.47%] [G loss: 1.051479]\n",
      "epoch:10 step:9703 [D loss: 0.729230, acc.: 49.22%] [G loss: 1.113511]\n",
      "epoch:10 step:9704 [D loss: 0.635599, acc.: 61.72%] [G loss: 1.052558]\n",
      "epoch:10 step:9705 [D loss: 0.563741, acc.: 71.09%] [G loss: 1.122309]\n",
      "epoch:10 step:9706 [D loss: 0.567908, acc.: 67.19%] [G loss: 1.122298]\n",
      "epoch:10 step:9707 [D loss: 0.677143, acc.: 53.91%] [G loss: 1.023847]\n",
      "epoch:10 step:9708 [D loss: 0.583749, acc.: 67.97%] [G loss: 0.976647]\n",
      "epoch:10 step:9709 [D loss: 0.596995, acc.: 72.66%] [G loss: 1.206925]\n",
      "epoch:10 step:9710 [D loss: 0.555775, acc.: 68.75%] [G loss: 1.192020]\n",
      "epoch:10 step:9711 [D loss: 0.697595, acc.: 55.47%] [G loss: 1.080277]\n",
      "epoch:10 step:9712 [D loss: 0.622908, acc.: 63.28%] [G loss: 1.194713]\n",
      "epoch:10 step:9713 [D loss: 0.655134, acc.: 65.62%] [G loss: 1.096158]\n",
      "epoch:10 step:9714 [D loss: 0.620354, acc.: 63.28%] [G loss: 1.353603]\n",
      "epoch:10 step:9715 [D loss: 0.592532, acc.: 64.84%] [G loss: 1.239490]\n",
      "epoch:10 step:9716 [D loss: 0.606197, acc.: 62.50%] [G loss: 1.298485]\n",
      "epoch:10 step:9717 [D loss: 0.639205, acc.: 64.84%] [G loss: 1.127571]\n",
      "epoch:10 step:9718 [D loss: 0.567522, acc.: 69.53%] [G loss: 1.081604]\n",
      "epoch:10 step:9719 [D loss: 0.547613, acc.: 74.22%] [G loss: 1.063039]\n",
      "epoch:10 step:9720 [D loss: 0.720374, acc.: 56.25%] [G loss: 1.131302]\n",
      "epoch:10 step:9721 [D loss: 0.627723, acc.: 64.84%] [G loss: 1.100379]\n",
      "epoch:10 step:9722 [D loss: 0.700171, acc.: 54.69%] [G loss: 1.042820]\n",
      "epoch:10 step:9723 [D loss: 0.529044, acc.: 71.88%] [G loss: 1.320822]\n",
      "epoch:10 step:9724 [D loss: 0.615786, acc.: 62.50%] [G loss: 1.046693]\n",
      "epoch:10 step:9725 [D loss: 0.540690, acc.: 72.66%] [G loss: 1.184983]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:10 step:9726 [D loss: 0.582044, acc.: 68.75%] [G loss: 1.106536]\n",
      "epoch:10 step:9727 [D loss: 0.635393, acc.: 64.84%] [G loss: 1.306665]\n",
      "epoch:10 step:9728 [D loss: 0.609050, acc.: 71.09%] [G loss: 1.296813]\n",
      "epoch:10 step:9729 [D loss: 0.644248, acc.: 64.84%] [G loss: 0.937260]\n",
      "epoch:10 step:9730 [D loss: 0.549988, acc.: 75.00%] [G loss: 1.095226]\n",
      "epoch:10 step:9731 [D loss: 0.547942, acc.: 71.09%] [G loss: 1.223243]\n",
      "epoch:10 step:9732 [D loss: 0.614842, acc.: 64.06%] [G loss: 1.125374]\n",
      "epoch:10 step:9733 [D loss: 0.669940, acc.: 60.16%] [G loss: 1.047622]\n",
      "epoch:10 step:9734 [D loss: 0.675808, acc.: 54.69%] [G loss: 1.027096]\n",
      "epoch:10 step:9735 [D loss: 0.638857, acc.: 67.97%] [G loss: 0.965313]\n",
      "epoch:10 step:9736 [D loss: 0.568926, acc.: 72.66%] [G loss: 1.266556]\n",
      "epoch:10 step:9737 [D loss: 0.572110, acc.: 69.53%] [G loss: 1.281334]\n",
      "epoch:10 step:9738 [D loss: 0.535620, acc.: 74.22%] [G loss: 1.346348]\n",
      "epoch:10 step:9739 [D loss: 0.638005, acc.: 62.50%] [G loss: 1.088868]\n",
      "epoch:10 step:9740 [D loss: 0.588508, acc.: 73.44%] [G loss: 1.126417]\n",
      "epoch:10 step:9741 [D loss: 0.691961, acc.: 61.72%] [G loss: 1.301321]\n",
      "epoch:10 step:9742 [D loss: 0.506797, acc.: 78.12%] [G loss: 1.353263]\n",
      "epoch:10 step:9743 [D loss: 0.528571, acc.: 80.47%] [G loss: 1.275091]\n",
      "epoch:10 step:9744 [D loss: 0.727127, acc.: 50.00%] [G loss: 0.943009]\n",
      "epoch:10 step:9745 [D loss: 0.675908, acc.: 60.16%] [G loss: 1.177767]\n",
      "epoch:10 step:9746 [D loss: 0.616282, acc.: 67.19%] [G loss: 1.082739]\n",
      "epoch:10 step:9747 [D loss: 0.613465, acc.: 62.50%] [G loss: 1.124463]\n",
      "epoch:10 step:9748 [D loss: 0.575025, acc.: 72.66%] [G loss: 1.234675]\n",
      "epoch:10 step:9749 [D loss: 0.540893, acc.: 71.09%] [G loss: 1.246089]\n",
      "epoch:10 step:9750 [D loss: 0.604049, acc.: 65.62%] [G loss: 1.020955]\n",
      "epoch:10 step:9751 [D loss: 0.538151, acc.: 70.31%] [G loss: 1.005195]\n",
      "epoch:10 step:9752 [D loss: 0.615107, acc.: 69.53%] [G loss: 1.102614]\n",
      "epoch:10 step:9753 [D loss: 0.631130, acc.: 63.28%] [G loss: 1.084769]\n",
      "epoch:10 step:9754 [D loss: 0.706386, acc.: 56.25%] [G loss: 0.970179]\n",
      "epoch:10 step:9755 [D loss: 0.612478, acc.: 64.06%] [G loss: 1.088962]\n",
      "epoch:10 step:9756 [D loss: 0.614793, acc.: 67.97%] [G loss: 1.213976]\n",
      "epoch:10 step:9757 [D loss: 0.622780, acc.: 64.06%] [G loss: 1.128368]\n",
      "epoch:10 step:9758 [D loss: 0.621890, acc.: 65.62%] [G loss: 1.299207]\n",
      "epoch:10 step:9759 [D loss: 0.686808, acc.: 60.16%] [G loss: 1.013907]\n",
      "epoch:10 step:9760 [D loss: 0.612933, acc.: 60.16%] [G loss: 1.066862]\n",
      "epoch:10 step:9761 [D loss: 0.707234, acc.: 55.47%] [G loss: 1.063142]\n",
      "epoch:10 step:9762 [D loss: 0.537012, acc.: 72.66%] [G loss: 1.230771]\n",
      "epoch:10 step:9763 [D loss: 0.713757, acc.: 59.38%] [G loss: 1.119161]\n",
      "epoch:10 step:9764 [D loss: 0.665985, acc.: 60.16%] [G loss: 1.059279]\n",
      "epoch:10 step:9765 [D loss: 0.668629, acc.: 57.81%] [G loss: 1.140417]\n",
      "epoch:10 step:9766 [D loss: 0.636020, acc.: 61.72%] [G loss: 1.278897]\n",
      "epoch:10 step:9767 [D loss: 0.603295, acc.: 66.41%] [G loss: 1.249646]\n",
      "epoch:10 step:9768 [D loss: 0.709395, acc.: 57.03%] [G loss: 1.155929]\n",
      "epoch:10 step:9769 [D loss: 0.595875, acc.: 70.31%] [G loss: 1.280334]\n",
      "epoch:10 step:9770 [D loss: 0.611016, acc.: 64.06%] [G loss: 1.128520]\n",
      "epoch:10 step:9771 [D loss: 0.537925, acc.: 71.88%] [G loss: 1.091920]\n",
      "epoch:10 step:9772 [D loss: 0.605389, acc.: 72.66%] [G loss: 1.073486]\n",
      "epoch:10 step:9773 [D loss: 0.648684, acc.: 68.75%] [G loss: 1.129778]\n",
      "epoch:10 step:9774 [D loss: 0.642955, acc.: 62.50%] [G loss: 1.023316]\n",
      "epoch:10 step:9775 [D loss: 0.525963, acc.: 78.91%] [G loss: 1.203479]\n",
      "epoch:10 step:9776 [D loss: 0.552202, acc.: 74.22%] [G loss: 1.275636]\n",
      "epoch:10 step:9777 [D loss: 0.694394, acc.: 60.94%] [G loss: 1.192906]\n",
      "epoch:10 step:9778 [D loss: 0.596743, acc.: 71.88%] [G loss: 1.077172]\n",
      "epoch:10 step:9779 [D loss: 0.713745, acc.: 50.78%] [G loss: 1.095078]\n",
      "epoch:10 step:9780 [D loss: 0.634786, acc.: 61.72%] [G loss: 1.087431]\n",
      "epoch:10 step:9781 [D loss: 0.573424, acc.: 71.09%] [G loss: 1.263649]\n",
      "epoch:10 step:9782 [D loss: 0.543349, acc.: 72.66%] [G loss: 1.242138]\n",
      "epoch:10 step:9783 [D loss: 0.665921, acc.: 59.38%] [G loss: 1.075647]\n",
      "epoch:10 step:9784 [D loss: 0.588797, acc.: 71.88%] [G loss: 0.958906]\n",
      "epoch:10 step:9785 [D loss: 0.609790, acc.: 67.19%] [G loss: 1.060354]\n",
      "epoch:10 step:9786 [D loss: 0.549257, acc.: 71.88%] [G loss: 1.360930]\n",
      "epoch:10 step:9787 [D loss: 0.600007, acc.: 63.28%] [G loss: 1.011502]\n",
      "epoch:10 step:9788 [D loss: 0.597316, acc.: 69.53%] [G loss: 1.102461]\n",
      "epoch:10 step:9789 [D loss: 0.548602, acc.: 70.31%] [G loss: 0.987274]\n",
      "epoch:10 step:9790 [D loss: 0.597113, acc.: 72.66%] [G loss: 1.023773]\n",
      "epoch:10 step:9791 [D loss: 0.614846, acc.: 63.28%] [G loss: 0.997947]\n",
      "epoch:10 step:9792 [D loss: 0.556036, acc.: 70.31%] [G loss: 1.186799]\n",
      "epoch:10 step:9793 [D loss: 0.720126, acc.: 54.69%] [G loss: 0.953344]\n",
      "epoch:10 step:9794 [D loss: 0.573200, acc.: 75.00%] [G loss: 1.044495]\n",
      "epoch:10 step:9795 [D loss: 0.658809, acc.: 55.47%] [G loss: 1.194685]\n",
      "epoch:10 step:9796 [D loss: 0.663344, acc.: 63.28%] [G loss: 1.312650]\n",
      "epoch:10 step:9797 [D loss: 0.711938, acc.: 48.44%] [G loss: 0.844297]\n",
      "epoch:10 step:9798 [D loss: 0.544945, acc.: 70.31%] [G loss: 1.231716]\n",
      "epoch:10 step:9799 [D loss: 0.555113, acc.: 69.53%] [G loss: 1.100100]\n",
      "epoch:10 step:9800 [D loss: 0.598319, acc.: 64.84%] [G loss: 1.061405]\n",
      "epoch:10 step:9801 [D loss: 0.561842, acc.: 71.09%] [G loss: 0.883026]\n",
      "epoch:10 step:9802 [D loss: 0.579240, acc.: 70.31%] [G loss: 1.061308]\n",
      "epoch:10 step:9803 [D loss: 0.552319, acc.: 73.44%] [G loss: 0.965411]\n",
      "epoch:10 step:9804 [D loss: 0.642915, acc.: 64.84%] [G loss: 1.037477]\n",
      "epoch:10 step:9805 [D loss: 0.665425, acc.: 60.16%] [G loss: 1.033606]\n",
      "epoch:10 step:9806 [D loss: 0.601426, acc.: 68.75%] [G loss: 1.054637]\n",
      "epoch:10 step:9807 [D loss: 0.702497, acc.: 55.47%] [G loss: 1.053959]\n",
      "epoch:10 step:9808 [D loss: 0.712349, acc.: 57.81%] [G loss: 0.967619]\n",
      "epoch:10 step:9809 [D loss: 0.609348, acc.: 67.19%] [G loss: 1.271295]\n",
      "epoch:10 step:9810 [D loss: 0.568397, acc.: 73.44%] [G loss: 1.183629]\n",
      "epoch:10 step:9811 [D loss: 0.586455, acc.: 67.97%] [G loss: 1.118086]\n",
      "epoch:10 step:9812 [D loss: 0.464010, acc.: 83.59%] [G loss: 1.227395]\n",
      "epoch:10 step:9813 [D loss: 0.651680, acc.: 60.16%] [G loss: 0.999837]\n",
      "epoch:10 step:9814 [D loss: 0.782778, acc.: 47.66%] [G loss: 0.936370]\n",
      "epoch:10 step:9815 [D loss: 0.528089, acc.: 78.12%] [G loss: 1.448623]\n",
      "epoch:10 step:9816 [D loss: 0.660923, acc.: 58.59%] [G loss: 1.256627]\n",
      "epoch:10 step:9817 [D loss: 0.601773, acc.: 69.53%] [G loss: 1.330403]\n",
      "epoch:10 step:9818 [D loss: 0.621958, acc.: 64.84%] [G loss: 1.131997]\n",
      "epoch:10 step:9819 [D loss: 0.597600, acc.: 68.75%] [G loss: 0.907470]\n",
      "epoch:10 step:9820 [D loss: 0.573608, acc.: 71.09%] [G loss: 1.154762]\n",
      "epoch:10 step:9821 [D loss: 0.506424, acc.: 76.56%] [G loss: 1.266231]\n",
      "epoch:10 step:9822 [D loss: 0.716880, acc.: 54.69%] [G loss: 1.214602]\n",
      "epoch:10 step:9823 [D loss: 0.473660, acc.: 81.25%] [G loss: 1.175570]\n",
      "epoch:10 step:9824 [D loss: 0.549799, acc.: 74.22%] [G loss: 1.490914]\n",
      "epoch:10 step:9825 [D loss: 0.516351, acc.: 75.00%] [G loss: 1.050131]\n",
      "epoch:10 step:9826 [D loss: 0.533688, acc.: 75.00%] [G loss: 1.235508]\n",
      "epoch:10 step:9827 [D loss: 0.583266, acc.: 68.75%] [G loss: 1.135310]\n",
      "epoch:10 step:9828 [D loss: 0.548693, acc.: 74.22%] [G loss: 1.302647]\n",
      "epoch:10 step:9829 [D loss: 0.550382, acc.: 75.78%] [G loss: 1.183167]\n",
      "epoch:10 step:9830 [D loss: 0.578600, acc.: 66.41%] [G loss: 1.038233]\n",
      "epoch:10 step:9831 [D loss: 0.748626, acc.: 50.78%] [G loss: 1.133153]\n",
      "epoch:10 step:9832 [D loss: 0.656419, acc.: 58.59%] [G loss: 0.965939]\n",
      "epoch:10 step:9833 [D loss: 0.700130, acc.: 55.47%] [G loss: 1.174511]\n",
      "epoch:10 step:9834 [D loss: 0.491110, acc.: 80.47%] [G loss: 1.210304]\n",
      "epoch:10 step:9835 [D loss: 0.719935, acc.: 53.91%] [G loss: 0.922018]\n",
      "epoch:10 step:9836 [D loss: 0.679507, acc.: 56.25%] [G loss: 1.162576]\n",
      "epoch:10 step:9837 [D loss: 0.532251, acc.: 77.34%] [G loss: 1.147358]\n",
      "epoch:10 step:9838 [D loss: 0.562865, acc.: 69.53%] [G loss: 1.258038]\n",
      "epoch:10 step:9839 [D loss: 0.521860, acc.: 74.22%] [G loss: 1.293711]\n",
      "epoch:10 step:9840 [D loss: 0.698789, acc.: 54.69%] [G loss: 1.185487]\n",
      "epoch:10 step:9841 [D loss: 0.572625, acc.: 64.84%] [G loss: 1.181618]\n",
      "epoch:10 step:9842 [D loss: 0.663352, acc.: 61.72%] [G loss: 1.155475]\n",
      "epoch:10 step:9843 [D loss: 0.571078, acc.: 68.75%] [G loss: 1.159290]\n",
      "epoch:10 step:9844 [D loss: 0.674328, acc.: 57.03%] [G loss: 1.084769]\n",
      "epoch:10 step:9845 [D loss: 0.553201, acc.: 74.22%] [G loss: 1.161227]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:10 step:9846 [D loss: 0.561836, acc.: 69.53%] [G loss: 1.008127]\n",
      "epoch:10 step:9847 [D loss: 0.670459, acc.: 57.81%] [G loss: 0.874559]\n",
      "epoch:10 step:9848 [D loss: 0.725039, acc.: 52.34%] [G loss: 0.981909]\n",
      "epoch:10 step:9849 [D loss: 0.691608, acc.: 60.94%] [G loss: 1.201671]\n",
      "epoch:10 step:9850 [D loss: 0.620456, acc.: 59.38%] [G loss: 1.173837]\n",
      "epoch:10 step:9851 [D loss: 0.670443, acc.: 57.81%] [G loss: 1.114089]\n",
      "epoch:10 step:9852 [D loss: 0.719863, acc.: 55.47%] [G loss: 1.026837]\n",
      "epoch:10 step:9853 [D loss: 0.662863, acc.: 60.94%] [G loss: 1.335112]\n",
      "epoch:10 step:9854 [D loss: 0.552823, acc.: 71.88%] [G loss: 1.292663]\n",
      "epoch:10 step:9855 [D loss: 0.656754, acc.: 58.59%] [G loss: 1.175157]\n",
      "epoch:10 step:9856 [D loss: 0.538469, acc.: 72.66%] [G loss: 1.183353]\n",
      "epoch:10 step:9857 [D loss: 0.567034, acc.: 70.31%] [G loss: 1.284352]\n",
      "epoch:10 step:9858 [D loss: 0.527426, acc.: 74.22%] [G loss: 1.251146]\n",
      "epoch:10 step:9859 [D loss: 0.663355, acc.: 60.16%] [G loss: 1.049764]\n",
      "epoch:10 step:9860 [D loss: 0.545804, acc.: 71.09%] [G loss: 1.014168]\n",
      "epoch:10 step:9861 [D loss: 0.536855, acc.: 74.22%] [G loss: 1.325961]\n",
      "epoch:10 step:9862 [D loss: 0.564646, acc.: 68.75%] [G loss: 1.124987]\n",
      "epoch:10 step:9863 [D loss: 0.662923, acc.: 62.50%] [G loss: 1.098464]\n",
      "epoch:10 step:9864 [D loss: 0.587867, acc.: 71.09%] [G loss: 1.003174]\n",
      "epoch:10 step:9865 [D loss: 0.689179, acc.: 61.72%] [G loss: 1.130872]\n",
      "epoch:10 step:9866 [D loss: 0.684073, acc.: 53.91%] [G loss: 0.926337]\n",
      "epoch:10 step:9867 [D loss: 0.691683, acc.: 52.34%] [G loss: 1.240921]\n",
      "epoch:10 step:9868 [D loss: 0.640660, acc.: 63.28%] [G loss: 1.110330]\n",
      "epoch:10 step:9869 [D loss: 0.557807, acc.: 71.09%] [G loss: 1.347032]\n",
      "epoch:10 step:9870 [D loss: 0.669123, acc.: 62.50%] [G loss: 1.080310]\n",
      "epoch:10 step:9871 [D loss: 0.554318, acc.: 69.53%] [G loss: 1.214306]\n",
      "epoch:10 step:9872 [D loss: 0.559428, acc.: 72.66%] [G loss: 1.136062]\n",
      "epoch:10 step:9873 [D loss: 0.625638, acc.: 65.62%] [G loss: 1.165667]\n",
      "epoch:10 step:9874 [D loss: 0.592827, acc.: 67.19%] [G loss: 1.253615]\n",
      "epoch:10 step:9875 [D loss: 0.547852, acc.: 73.44%] [G loss: 1.144030]\n",
      "epoch:10 step:9876 [D loss: 0.599861, acc.: 71.88%] [G loss: 1.220029]\n",
      "epoch:10 step:9877 [D loss: 0.662368, acc.: 62.50%] [G loss: 1.037780]\n",
      "epoch:10 step:9878 [D loss: 0.712501, acc.: 55.47%] [G loss: 1.110493]\n",
      "epoch:10 step:9879 [D loss: 0.572931, acc.: 72.66%] [G loss: 1.186166]\n",
      "epoch:10 step:9880 [D loss: 0.642425, acc.: 59.38%] [G loss: 1.138740]\n",
      "epoch:10 step:9881 [D loss: 0.596166, acc.: 67.19%] [G loss: 1.153798]\n",
      "epoch:10 step:9882 [D loss: 0.509709, acc.: 73.44%] [G loss: 1.039765]\n",
      "epoch:10 step:9883 [D loss: 0.476472, acc.: 82.03%] [G loss: 1.458776]\n",
      "epoch:10 step:9884 [D loss: 0.546636, acc.: 72.66%] [G loss: 1.196404]\n",
      "epoch:10 step:9885 [D loss: 0.573782, acc.: 69.53%] [G loss: 1.312674]\n",
      "epoch:10 step:9886 [D loss: 0.654680, acc.: 61.72%] [G loss: 1.093295]\n",
      "epoch:10 step:9887 [D loss: 0.594658, acc.: 69.53%] [G loss: 1.099124]\n",
      "epoch:10 step:9888 [D loss: 0.654854, acc.: 61.72%] [G loss: 1.001511]\n",
      "epoch:10 step:9889 [D loss: 0.555758, acc.: 72.66%] [G loss: 1.119729]\n",
      "epoch:10 step:9890 [D loss: 0.566089, acc.: 74.22%] [G loss: 1.189586]\n",
      "epoch:10 step:9891 [D loss: 0.612262, acc.: 68.75%] [G loss: 1.343058]\n",
      "epoch:10 step:9892 [D loss: 0.679879, acc.: 62.50%] [G loss: 1.105300]\n",
      "epoch:10 step:9893 [D loss: 0.604916, acc.: 63.28%] [G loss: 1.042526]\n",
      "epoch:10 step:9894 [D loss: 0.523393, acc.: 76.56%] [G loss: 1.339181]\n",
      "epoch:10 step:9895 [D loss: 0.649409, acc.: 66.41%] [G loss: 0.963514]\n",
      "epoch:10 step:9896 [D loss: 0.678580, acc.: 54.69%] [G loss: 1.218717]\n",
      "epoch:10 step:9897 [D loss: 0.622526, acc.: 67.97%] [G loss: 1.098834]\n",
      "epoch:10 step:9898 [D loss: 0.502670, acc.: 80.47%] [G loss: 1.067183]\n",
      "epoch:10 step:9899 [D loss: 0.542773, acc.: 70.31%] [G loss: 0.990424]\n",
      "epoch:10 step:9900 [D loss: 0.700538, acc.: 57.81%] [G loss: 0.945315]\n",
      "epoch:10 step:9901 [D loss: 0.602693, acc.: 70.31%] [G loss: 1.187980]\n",
      "epoch:10 step:9902 [D loss: 0.598963, acc.: 67.97%] [G loss: 1.191250]\n",
      "epoch:10 step:9903 [D loss: 0.674883, acc.: 62.50%] [G loss: 1.090841]\n",
      "epoch:10 step:9904 [D loss: 0.582748, acc.: 72.66%] [G loss: 1.079178]\n",
      "epoch:10 step:9905 [D loss: 0.634876, acc.: 64.84%] [G loss: 1.081992]\n",
      "epoch:10 step:9906 [D loss: 0.556424, acc.: 72.66%] [G loss: 1.012514]\n",
      "epoch:10 step:9907 [D loss: 0.600861, acc.: 64.06%] [G loss: 1.085476]\n",
      "epoch:10 step:9908 [D loss: 0.601525, acc.: 69.53%] [G loss: 1.007500]\n",
      "epoch:10 step:9909 [D loss: 0.563846, acc.: 70.31%] [G loss: 1.160355]\n",
      "epoch:10 step:9910 [D loss: 0.573568, acc.: 68.75%] [G loss: 1.070965]\n",
      "epoch:10 step:9911 [D loss: 0.536737, acc.: 78.12%] [G loss: 1.152796]\n",
      "epoch:10 step:9912 [D loss: 0.537457, acc.: 75.78%] [G loss: 1.249096]\n",
      "epoch:10 step:9913 [D loss: 0.522393, acc.: 75.78%] [G loss: 1.180785]\n",
      "epoch:10 step:9914 [D loss: 0.574817, acc.: 70.31%] [G loss: 1.301124]\n",
      "epoch:10 step:9915 [D loss: 0.624140, acc.: 69.53%] [G loss: 1.115525]\n",
      "epoch:10 step:9916 [D loss: 0.610399, acc.: 71.09%] [G loss: 1.013343]\n",
      "epoch:10 step:9917 [D loss: 0.584442, acc.: 71.09%] [G loss: 1.093542]\n",
      "epoch:10 step:9918 [D loss: 0.606575, acc.: 61.72%] [G loss: 1.050351]\n",
      "epoch:10 step:9919 [D loss: 0.586740, acc.: 67.19%] [G loss: 1.157364]\n",
      "epoch:10 step:9920 [D loss: 0.452941, acc.: 86.72%] [G loss: 1.331492]\n",
      "epoch:10 step:9921 [D loss: 0.590616, acc.: 65.62%] [G loss: 1.079823]\n",
      "epoch:10 step:9922 [D loss: 0.557315, acc.: 73.44%] [G loss: 1.173091]\n",
      "epoch:10 step:9923 [D loss: 0.562342, acc.: 71.09%] [G loss: 1.085966]\n",
      "epoch:10 step:9924 [D loss: 0.692355, acc.: 56.25%] [G loss: 0.758131]\n",
      "epoch:10 step:9925 [D loss: 0.587560, acc.: 69.53%] [G loss: 1.005439]\n",
      "epoch:10 step:9926 [D loss: 0.608362, acc.: 65.62%] [G loss: 1.221075]\n",
      "epoch:10 step:9927 [D loss: 0.610536, acc.: 67.97%] [G loss: 1.023397]\n",
      "epoch:10 step:9928 [D loss: 0.591051, acc.: 67.97%] [G loss: 1.138916]\n",
      "epoch:10 step:9929 [D loss: 0.596496, acc.: 67.97%] [G loss: 0.969409]\n",
      "epoch:10 step:9930 [D loss: 0.586471, acc.: 66.41%] [G loss: 1.070428]\n",
      "epoch:10 step:9931 [D loss: 0.697501, acc.: 56.25%] [G loss: 1.044282]\n",
      "epoch:10 step:9932 [D loss: 0.557841, acc.: 71.88%] [G loss: 1.244371]\n",
      "epoch:10 step:9933 [D loss: 0.599483, acc.: 70.31%] [G loss: 1.195276]\n",
      "epoch:10 step:9934 [D loss: 0.626846, acc.: 62.50%] [G loss: 1.078196]\n",
      "epoch:10 step:9935 [D loss: 0.526055, acc.: 74.22%] [G loss: 1.069247]\n",
      "epoch:10 step:9936 [D loss: 0.652296, acc.: 60.16%] [G loss: 1.015409]\n",
      "epoch:10 step:9937 [D loss: 0.552611, acc.: 74.22%] [G loss: 1.197279]\n",
      "epoch:10 step:9938 [D loss: 0.702548, acc.: 57.03%] [G loss: 1.132311]\n",
      "epoch:10 step:9939 [D loss: 0.654708, acc.: 64.06%] [G loss: 1.142874]\n",
      "epoch:10 step:9940 [D loss: 0.616121, acc.: 62.50%] [G loss: 1.184016]\n",
      "epoch:10 step:9941 [D loss: 0.552806, acc.: 71.88%] [G loss: 1.505903]\n",
      "epoch:10 step:9942 [D loss: 0.558819, acc.: 73.44%] [G loss: 1.222417]\n",
      "epoch:10 step:9943 [D loss: 0.783313, acc.: 39.84%] [G loss: 1.042115]\n",
      "epoch:10 step:9944 [D loss: 0.544717, acc.: 69.53%] [G loss: 1.127974]\n",
      "epoch:10 step:9945 [D loss: 0.679086, acc.: 56.25%] [G loss: 0.856525]\n",
      "epoch:10 step:9946 [D loss: 0.584323, acc.: 67.97%] [G loss: 1.122908]\n",
      "epoch:10 step:9947 [D loss: 0.647250, acc.: 61.72%] [G loss: 1.014662]\n",
      "epoch:10 step:9948 [D loss: 0.648418, acc.: 60.16%] [G loss: 1.109180]\n",
      "epoch:10 step:9949 [D loss: 0.623624, acc.: 66.41%] [G loss: 1.082920]\n",
      "epoch:10 step:9950 [D loss: 0.578376, acc.: 73.44%] [G loss: 1.035026]\n",
      "epoch:10 step:9951 [D loss: 0.590960, acc.: 69.53%] [G loss: 1.058905]\n",
      "epoch:10 step:9952 [D loss: 0.608031, acc.: 67.19%] [G loss: 1.071611]\n",
      "epoch:10 step:9953 [D loss: 0.597339, acc.: 67.97%] [G loss: 0.998615]\n",
      "epoch:10 step:9954 [D loss: 0.679975, acc.: 55.47%] [G loss: 1.111068]\n",
      "epoch:10 step:9955 [D loss: 0.665736, acc.: 59.38%] [G loss: 1.057995]\n",
      "epoch:10 step:9956 [D loss: 0.641102, acc.: 60.94%] [G loss: 1.083107]\n",
      "epoch:10 step:9957 [D loss: 0.591824, acc.: 70.31%] [G loss: 1.202244]\n",
      "epoch:10 step:9958 [D loss: 0.555480, acc.: 75.00%] [G loss: 1.122187]\n",
      "epoch:10 step:9959 [D loss: 0.614110, acc.: 62.50%] [G loss: 0.978060]\n",
      "epoch:10 step:9960 [D loss: 0.550446, acc.: 71.09%] [G loss: 1.166328]\n",
      "epoch:10 step:9961 [D loss: 0.656350, acc.: 60.94%] [G loss: 0.915501]\n",
      "epoch:10 step:9962 [D loss: 0.648765, acc.: 62.50%] [G loss: 1.175395]\n",
      "epoch:10 step:9963 [D loss: 0.715442, acc.: 53.91%] [G loss: 1.022682]\n",
      "epoch:10 step:9964 [D loss: 0.532073, acc.: 75.00%] [G loss: 1.289412]\n",
      "epoch:10 step:9965 [D loss: 0.622842, acc.: 68.75%] [G loss: 1.182956]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:10 step:9966 [D loss: 0.589957, acc.: 70.31%] [G loss: 1.009347]\n",
      "epoch:10 step:9967 [D loss: 0.623836, acc.: 64.84%] [G loss: 1.297948]\n",
      "epoch:10 step:9968 [D loss: 0.551170, acc.: 72.66%] [G loss: 1.225221]\n",
      "epoch:10 step:9969 [D loss: 0.545712, acc.: 74.22%] [G loss: 0.976198]\n",
      "epoch:10 step:9970 [D loss: 0.579554, acc.: 75.78%] [G loss: 1.257985]\n",
      "epoch:10 step:9971 [D loss: 0.748707, acc.: 54.69%] [G loss: 0.964718]\n",
      "epoch:10 step:9972 [D loss: 0.523150, acc.: 78.12%] [G loss: 1.148951]\n",
      "epoch:10 step:9973 [D loss: 0.554059, acc.: 73.44%] [G loss: 1.211002]\n",
      "epoch:10 step:9974 [D loss: 0.647941, acc.: 63.28%] [G loss: 1.102875]\n",
      "epoch:10 step:9975 [D loss: 0.582637, acc.: 70.31%] [G loss: 0.919669]\n",
      "epoch:10 step:9976 [D loss: 0.648006, acc.: 61.72%] [G loss: 1.021068]\n",
      "epoch:10 step:9977 [D loss: 0.605055, acc.: 68.75%] [G loss: 1.039005]\n",
      "epoch:10 step:9978 [D loss: 0.537373, acc.: 75.00%] [G loss: 1.290686]\n",
      "epoch:10 step:9979 [D loss: 0.589716, acc.: 66.41%] [G loss: 1.139232]\n",
      "epoch:10 step:9980 [D loss: 0.601598, acc.: 63.28%] [G loss: 1.037903]\n",
      "epoch:10 step:9981 [D loss: 0.692359, acc.: 54.69%] [G loss: 0.996988]\n",
      "epoch:10 step:9982 [D loss: 0.591085, acc.: 66.41%] [G loss: 1.107417]\n",
      "epoch:10 step:9983 [D loss: 0.599951, acc.: 69.53%] [G loss: 1.303325]\n",
      "epoch:10 step:9984 [D loss: 0.655373, acc.: 59.38%] [G loss: 1.229815]\n",
      "epoch:10 step:9985 [D loss: 0.628474, acc.: 63.28%] [G loss: 1.221523]\n",
      "epoch:10 step:9986 [D loss: 0.582860, acc.: 71.09%] [G loss: 1.360956]\n",
      "epoch:10 step:9987 [D loss: 0.599755, acc.: 67.19%] [G loss: 1.155756]\n",
      "epoch:10 step:9988 [D loss: 0.561392, acc.: 68.75%] [G loss: 1.204359]\n",
      "epoch:10 step:9989 [D loss: 0.774134, acc.: 54.69%] [G loss: 1.180995]\n",
      "epoch:10 step:9990 [D loss: 0.575146, acc.: 67.97%] [G loss: 1.129210]\n",
      "epoch:10 step:9991 [D loss: 0.590762, acc.: 67.97%] [G loss: 0.993022]\n",
      "epoch:10 step:9992 [D loss: 0.716433, acc.: 56.25%] [G loss: 0.952517]\n",
      "epoch:10 step:9993 [D loss: 0.641862, acc.: 64.84%] [G loss: 1.197095]\n",
      "epoch:10 step:9994 [D loss: 0.557921, acc.: 71.09%] [G loss: 1.417776]\n",
      "epoch:10 step:9995 [D loss: 0.742042, acc.: 52.34%] [G loss: 1.016263]\n",
      "epoch:10 step:9996 [D loss: 0.614277, acc.: 72.66%] [G loss: 1.145632]\n",
      "epoch:10 step:9997 [D loss: 0.557217, acc.: 69.53%] [G loss: 1.331827]\n",
      "epoch:10 step:9998 [D loss: 0.531861, acc.: 72.66%] [G loss: 1.238127]\n",
      "epoch:10 step:9999 [D loss: 0.573711, acc.: 73.44%] [G loss: 1.183180]\n",
      "epoch:10 step:10000 [D loss: 0.583188, acc.: 71.09%] [G loss: 1.040296]\n",
      "epoch:10 step:10001 [D loss: 0.487898, acc.: 77.34%] [G loss: 1.191504]\n",
      "epoch:10 step:10002 [D loss: 0.659263, acc.: 60.94%] [G loss: 0.871541]\n",
      "epoch:10 step:10003 [D loss: 0.605538, acc.: 68.75%] [G loss: 0.879766]\n",
      "epoch:10 step:10004 [D loss: 0.527093, acc.: 70.31%] [G loss: 1.139958]\n",
      "epoch:10 step:10005 [D loss: 0.590385, acc.: 64.06%] [G loss: 1.194352]\n",
      "epoch:10 step:10006 [D loss: 0.763753, acc.: 49.22%] [G loss: 0.921808]\n",
      "epoch:10 step:10007 [D loss: 0.514880, acc.: 73.44%] [G loss: 1.183772]\n",
      "epoch:10 step:10008 [D loss: 0.583775, acc.: 71.09%] [G loss: 1.244384]\n",
      "epoch:10 step:10009 [D loss: 0.682104, acc.: 54.69%] [G loss: 1.243006]\n",
      "epoch:10 step:10010 [D loss: 0.705074, acc.: 53.91%] [G loss: 1.209452]\n",
      "epoch:10 step:10011 [D loss: 0.596310, acc.: 67.97%] [G loss: 0.952433]\n",
      "epoch:10 step:10012 [D loss: 0.538992, acc.: 68.75%] [G loss: 1.174636]\n",
      "epoch:10 step:10013 [D loss: 0.710995, acc.: 55.47%] [G loss: 1.159567]\n",
      "epoch:10 step:10014 [D loss: 0.711306, acc.: 55.47%] [G loss: 1.123154]\n",
      "epoch:10 step:10015 [D loss: 0.586416, acc.: 70.31%] [G loss: 1.102181]\n",
      "epoch:10 step:10016 [D loss: 0.692601, acc.: 57.81%] [G loss: 0.960898]\n",
      "epoch:10 step:10017 [D loss: 0.649235, acc.: 63.28%] [G loss: 1.156602]\n",
      "epoch:10 step:10018 [D loss: 0.571639, acc.: 68.75%] [G loss: 1.152966]\n",
      "epoch:10 step:10019 [D loss: 0.561567, acc.: 70.31%] [G loss: 1.058466]\n",
      "epoch:10 step:10020 [D loss: 0.597330, acc.: 70.31%] [G loss: 1.069828]\n",
      "epoch:10 step:10021 [D loss: 0.584891, acc.: 74.22%] [G loss: 1.120323]\n",
      "epoch:10 step:10022 [D loss: 0.627939, acc.: 64.06%] [G loss: 1.205416]\n",
      "epoch:10 step:10023 [D loss: 0.615274, acc.: 64.06%] [G loss: 1.044358]\n",
      "epoch:10 step:10024 [D loss: 0.527699, acc.: 76.56%] [G loss: 1.032773]\n",
      "epoch:10 step:10025 [D loss: 0.551209, acc.: 76.56%] [G loss: 1.289887]\n",
      "epoch:10 step:10026 [D loss: 0.660599, acc.: 61.72%] [G loss: 0.985126]\n",
      "epoch:10 step:10027 [D loss: 0.586075, acc.: 66.41%] [G loss: 1.278472]\n",
      "epoch:10 step:10028 [D loss: 0.659051, acc.: 61.72%] [G loss: 1.235582]\n",
      "epoch:10 step:10029 [D loss: 0.598554, acc.: 65.62%] [G loss: 1.019409]\n",
      "epoch:10 step:10030 [D loss: 0.570126, acc.: 66.41%] [G loss: 1.161695]\n",
      "epoch:10 step:10031 [D loss: 0.653692, acc.: 63.28%] [G loss: 0.991414]\n",
      "epoch:10 step:10032 [D loss: 0.690424, acc.: 61.72%] [G loss: 1.223265]\n",
      "epoch:10 step:10033 [D loss: 0.741036, acc.: 52.34%] [G loss: 1.209977]\n",
      "epoch:10 step:10034 [D loss: 0.593212, acc.: 66.41%] [G loss: 1.169961]\n",
      "epoch:10 step:10035 [D loss: 0.664161, acc.: 61.72%] [G loss: 1.202569]\n",
      "epoch:10 step:10036 [D loss: 0.631020, acc.: 64.06%] [G loss: 1.197072]\n",
      "epoch:10 step:10037 [D loss: 0.609177, acc.: 67.19%] [G loss: 1.155930]\n",
      "epoch:10 step:10038 [D loss: 0.622902, acc.: 66.41%] [G loss: 1.109093]\n",
      "epoch:10 step:10039 [D loss: 0.576352, acc.: 71.88%] [G loss: 1.069415]\n",
      "epoch:10 step:10040 [D loss: 0.498001, acc.: 78.12%] [G loss: 1.278131]\n",
      "epoch:10 step:10041 [D loss: 0.622261, acc.: 67.19%] [G loss: 1.079642]\n",
      "epoch:10 step:10042 [D loss: 0.578386, acc.: 68.75%] [G loss: 1.111395]\n",
      "epoch:10 step:10043 [D loss: 0.631335, acc.: 64.84%] [G loss: 0.914932]\n",
      "epoch:10 step:10044 [D loss: 0.731784, acc.: 55.47%] [G loss: 1.073218]\n",
      "epoch:10 step:10045 [D loss: 0.602701, acc.: 68.75%] [G loss: 1.179251]\n",
      "epoch:10 step:10046 [D loss: 0.524156, acc.: 75.78%] [G loss: 1.232426]\n",
      "epoch:10 step:10047 [D loss: 0.579626, acc.: 71.09%] [G loss: 0.989266]\n",
      "epoch:10 step:10048 [D loss: 0.547567, acc.: 73.44%] [G loss: 1.031812]\n",
      "epoch:10 step:10049 [D loss: 0.617164, acc.: 68.75%] [G loss: 1.063566]\n",
      "epoch:10 step:10050 [D loss: 0.601661, acc.: 67.97%] [G loss: 1.190626]\n",
      "epoch:10 step:10051 [D loss: 0.573980, acc.: 71.88%] [G loss: 1.172069]\n",
      "epoch:10 step:10052 [D loss: 0.575553, acc.: 70.31%] [G loss: 1.170467]\n",
      "epoch:10 step:10053 [D loss: 0.703298, acc.: 57.81%] [G loss: 1.238567]\n",
      "epoch:10 step:10054 [D loss: 0.640570, acc.: 65.62%] [G loss: 1.416198]\n",
      "epoch:10 step:10055 [D loss: 0.567654, acc.: 71.09%] [G loss: 1.205992]\n",
      "epoch:10 step:10056 [D loss: 0.575654, acc.: 69.53%] [G loss: 1.173631]\n",
      "epoch:10 step:10057 [D loss: 0.569414, acc.: 72.66%] [G loss: 1.100327]\n",
      "epoch:10 step:10058 [D loss: 0.649259, acc.: 63.28%] [G loss: 1.014986]\n",
      "epoch:10 step:10059 [D loss: 0.598423, acc.: 70.31%] [G loss: 1.169330]\n",
      "epoch:10 step:10060 [D loss: 0.546930, acc.: 75.78%] [G loss: 0.969950]\n",
      "epoch:10 step:10061 [D loss: 0.581257, acc.: 65.62%] [G loss: 1.081200]\n",
      "epoch:10 step:10062 [D loss: 0.634698, acc.: 63.28%] [G loss: 1.048724]\n",
      "epoch:10 step:10063 [D loss: 0.705515, acc.: 52.34%] [G loss: 1.011122]\n",
      "epoch:10 step:10064 [D loss: 0.648240, acc.: 69.53%] [G loss: 1.151109]\n",
      "epoch:10 step:10065 [D loss: 0.678481, acc.: 58.59%] [G loss: 1.178499]\n",
      "epoch:10 step:10066 [D loss: 0.642883, acc.: 64.06%] [G loss: 0.995503]\n",
      "epoch:10 step:10067 [D loss: 0.552577, acc.: 72.66%] [G loss: 1.066563]\n",
      "epoch:10 step:10068 [D loss: 0.588887, acc.: 69.53%] [G loss: 1.006122]\n",
      "epoch:10 step:10069 [D loss: 0.575486, acc.: 72.66%] [G loss: 1.181322]\n",
      "epoch:10 step:10070 [D loss: 0.636334, acc.: 65.62%] [G loss: 1.041352]\n",
      "epoch:10 step:10071 [D loss: 0.598711, acc.: 64.84%] [G loss: 1.111516]\n",
      "epoch:10 step:10072 [D loss: 0.593213, acc.: 69.53%] [G loss: 1.071569]\n",
      "epoch:10 step:10073 [D loss: 0.648040, acc.: 62.50%] [G loss: 1.117175]\n",
      "epoch:10 step:10074 [D loss: 0.719264, acc.: 54.69%] [G loss: 1.058840]\n",
      "epoch:10 step:10075 [D loss: 0.613363, acc.: 67.97%] [G loss: 1.099139]\n",
      "epoch:10 step:10076 [D loss: 0.608738, acc.: 67.97%] [G loss: 1.311397]\n",
      "epoch:10 step:10077 [D loss: 0.642867, acc.: 61.72%] [G loss: 1.098641]\n",
      "epoch:10 step:10078 [D loss: 0.593360, acc.: 66.41%] [G loss: 1.113972]\n",
      "epoch:10 step:10079 [D loss: 0.690706, acc.: 58.59%] [G loss: 1.118156]\n",
      "epoch:10 step:10080 [D loss: 0.618433, acc.: 67.19%] [G loss: 1.182214]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:10 step:10081 [D loss: 0.565678, acc.: 73.44%] [G loss: 1.070897]\n",
      "epoch:10 step:10082 [D loss: 0.601062, acc.: 66.41%] [G loss: 1.178276]\n",
      "epoch:10 step:10083 [D loss: 0.629524, acc.: 64.84%] [G loss: 1.162220]\n",
      "epoch:10 step:10084 [D loss: 0.669195, acc.: 53.12%] [G loss: 1.025437]\n",
      "epoch:10 step:10085 [D loss: 0.536926, acc.: 71.88%] [G loss: 1.161175]\n",
      "epoch:10 step:10086 [D loss: 0.502519, acc.: 75.00%] [G loss: 1.212411]\n",
      "epoch:10 step:10087 [D loss: 0.630763, acc.: 67.19%] [G loss: 1.016992]\n",
      "epoch:10 step:10088 [D loss: 0.451919, acc.: 84.38%] [G loss: 1.353727]\n",
      "epoch:10 step:10089 [D loss: 0.667299, acc.: 59.38%] [G loss: 1.216918]\n",
      "epoch:10 step:10090 [D loss: 0.629987, acc.: 64.06%] [G loss: 1.189689]\n",
      "epoch:10 step:10091 [D loss: 0.658077, acc.: 61.72%] [G loss: 1.013041]\n",
      "epoch:10 step:10092 [D loss: 0.561393, acc.: 72.66%] [G loss: 1.083187]\n",
      "epoch:10 step:10093 [D loss: 0.567193, acc.: 68.75%] [G loss: 1.219507]\n",
      "epoch:10 step:10094 [D loss: 0.538852, acc.: 73.44%] [G loss: 1.168560]\n",
      "epoch:10 step:10095 [D loss: 0.643088, acc.: 64.06%] [G loss: 1.109111]\n",
      "epoch:10 step:10096 [D loss: 0.609451, acc.: 63.28%] [G loss: 1.204347]\n",
      "epoch:10 step:10097 [D loss: 0.543845, acc.: 75.00%] [G loss: 1.178267]\n",
      "epoch:10 step:10098 [D loss: 0.667505, acc.: 60.16%] [G loss: 1.175405]\n",
      "epoch:10 step:10099 [D loss: 0.608697, acc.: 65.62%] [G loss: 1.210327]\n",
      "epoch:10 step:10100 [D loss: 0.523810, acc.: 75.78%] [G loss: 1.320519]\n",
      "epoch:10 step:10101 [D loss: 0.677097, acc.: 60.16%] [G loss: 1.070575]\n",
      "epoch:10 step:10102 [D loss: 0.631470, acc.: 64.06%] [G loss: 1.155980]\n",
      "epoch:10 step:10103 [D loss: 0.632053, acc.: 62.50%] [G loss: 1.080939]\n",
      "epoch:10 step:10104 [D loss: 0.499969, acc.: 79.69%] [G loss: 1.103361]\n",
      "epoch:10 step:10105 [D loss: 0.581930, acc.: 67.97%] [G loss: 1.214589]\n",
      "epoch:10 step:10106 [D loss: 0.487847, acc.: 78.91%] [G loss: 1.223467]\n",
      "epoch:10 step:10107 [D loss: 0.650577, acc.: 57.81%] [G loss: 1.017145]\n",
      "epoch:10 step:10108 [D loss: 0.625021, acc.: 63.28%] [G loss: 1.143524]\n",
      "epoch:10 step:10109 [D loss: 0.634869, acc.: 64.06%] [G loss: 1.126355]\n",
      "epoch:10 step:10110 [D loss: 0.567840, acc.: 70.31%] [G loss: 1.081357]\n",
      "epoch:10 step:10111 [D loss: 0.568603, acc.: 70.31%] [G loss: 1.182854]\n",
      "epoch:10 step:10112 [D loss: 0.668876, acc.: 58.59%] [G loss: 1.148641]\n",
      "epoch:10 step:10113 [D loss: 0.653029, acc.: 63.28%] [G loss: 0.986895]\n",
      "epoch:10 step:10114 [D loss: 0.531315, acc.: 75.00%] [G loss: 0.915920]\n",
      "epoch:10 step:10115 [D loss: 0.632493, acc.: 63.28%] [G loss: 1.017516]\n",
      "epoch:10 step:10116 [D loss: 0.625647, acc.: 60.16%] [G loss: 1.046428]\n",
      "epoch:10 step:10117 [D loss: 0.528686, acc.: 74.22%] [G loss: 1.155432]\n",
      "epoch:10 step:10118 [D loss: 0.531957, acc.: 74.22%] [G loss: 1.159840]\n",
      "epoch:10 step:10119 [D loss: 0.584683, acc.: 67.97%] [G loss: 1.197158]\n",
      "epoch:10 step:10120 [D loss: 0.738836, acc.: 50.78%] [G loss: 0.887453]\n",
      "epoch:10 step:10121 [D loss: 0.698517, acc.: 57.81%] [G loss: 1.089330]\n",
      "epoch:10 step:10122 [D loss: 0.711668, acc.: 56.25%] [G loss: 1.304636]\n",
      "epoch:10 step:10123 [D loss: 0.568366, acc.: 67.97%] [G loss: 1.153811]\n",
      "epoch:10 step:10124 [D loss: 0.570102, acc.: 71.09%] [G loss: 1.203104]\n",
      "epoch:10 step:10125 [D loss: 0.616368, acc.: 67.97%] [G loss: 1.067968]\n",
      "epoch:10 step:10126 [D loss: 0.617632, acc.: 67.97%] [G loss: 0.996096]\n",
      "epoch:10 step:10127 [D loss: 0.538693, acc.: 69.53%] [G loss: 0.999570]\n",
      "epoch:10 step:10128 [D loss: 0.653519, acc.: 61.72%] [G loss: 1.032643]\n",
      "epoch:10 step:10129 [D loss: 0.619128, acc.: 62.50%] [G loss: 1.161494]\n",
      "epoch:10 step:10130 [D loss: 0.526714, acc.: 75.00%] [G loss: 0.985643]\n",
      "epoch:10 step:10131 [D loss: 0.717410, acc.: 53.12%] [G loss: 1.060380]\n",
      "epoch:10 step:10132 [D loss: 0.626452, acc.: 65.62%] [G loss: 1.097735]\n",
      "epoch:10 step:10133 [D loss: 0.686136, acc.: 55.47%] [G loss: 1.133721]\n",
      "epoch:10 step:10134 [D loss: 0.593592, acc.: 70.31%] [G loss: 1.160378]\n",
      "epoch:10 step:10135 [D loss: 0.683035, acc.: 56.25%] [G loss: 0.821017]\n",
      "epoch:10 step:10136 [D loss: 0.613241, acc.: 65.62%] [G loss: 1.102612]\n",
      "epoch:10 step:10137 [D loss: 0.642734, acc.: 65.62%] [G loss: 1.281285]\n",
      "epoch:10 step:10138 [D loss: 0.518535, acc.: 75.00%] [G loss: 1.300503]\n",
      "epoch:10 step:10139 [D loss: 0.686079, acc.: 60.16%] [G loss: 0.934022]\n",
      "epoch:10 step:10140 [D loss: 0.654613, acc.: 60.94%] [G loss: 0.960492]\n",
      "epoch:10 step:10141 [D loss: 0.720807, acc.: 51.56%] [G loss: 1.050482]\n",
      "epoch:10 step:10142 [D loss: 0.571254, acc.: 69.53%] [G loss: 1.072029]\n",
      "epoch:10 step:10143 [D loss: 0.587707, acc.: 64.84%] [G loss: 1.128867]\n",
      "epoch:10 step:10144 [D loss: 0.496207, acc.: 81.25%] [G loss: 1.058468]\n",
      "epoch:10 step:10145 [D loss: 0.556331, acc.: 68.75%] [G loss: 1.079739]\n",
      "epoch:10 step:10146 [D loss: 0.529707, acc.: 76.56%] [G loss: 1.180509]\n",
      "epoch:10 step:10147 [D loss: 0.647108, acc.: 64.84%] [G loss: 1.066582]\n",
      "epoch:10 step:10148 [D loss: 0.583716, acc.: 75.00%] [G loss: 0.919178]\n",
      "epoch:10 step:10149 [D loss: 0.706174, acc.: 57.03%] [G loss: 1.135750]\n",
      "epoch:10 step:10150 [D loss: 0.734799, acc.: 48.44%] [G loss: 0.970401]\n",
      "epoch:10 step:10151 [D loss: 0.559087, acc.: 71.88%] [G loss: 1.265953]\n",
      "epoch:10 step:10152 [D loss: 0.669216, acc.: 62.50%] [G loss: 0.881704]\n",
      "epoch:10 step:10153 [D loss: 0.523232, acc.: 72.66%] [G loss: 1.211317]\n",
      "epoch:10 step:10154 [D loss: 0.630785, acc.: 65.62%] [G loss: 1.054279]\n",
      "epoch:10 step:10155 [D loss: 0.562841, acc.: 74.22%] [G loss: 1.391330]\n",
      "epoch:10 step:10156 [D loss: 0.745860, acc.: 48.44%] [G loss: 1.041586]\n",
      "epoch:10 step:10157 [D loss: 0.567602, acc.: 69.53%] [G loss: 1.306590]\n",
      "epoch:10 step:10158 [D loss: 0.706259, acc.: 53.12%] [G loss: 1.041822]\n",
      "epoch:10 step:10159 [D loss: 0.656393, acc.: 64.06%] [G loss: 1.046034]\n",
      "epoch:10 step:10160 [D loss: 0.603195, acc.: 64.84%] [G loss: 1.044862]\n",
      "epoch:10 step:10161 [D loss: 0.660065, acc.: 60.16%] [G loss: 1.004749]\n",
      "epoch:10 step:10162 [D loss: 0.613123, acc.: 64.84%] [G loss: 1.219683]\n",
      "epoch:10 step:10163 [D loss: 0.584484, acc.: 68.75%] [G loss: 1.166955]\n",
      "epoch:10 step:10164 [D loss: 0.521359, acc.: 71.09%] [G loss: 1.257382]\n",
      "epoch:10 step:10165 [D loss: 0.755100, acc.: 52.34%] [G loss: 1.075185]\n",
      "epoch:10 step:10166 [D loss: 0.650722, acc.: 63.28%] [G loss: 0.967025]\n",
      "epoch:10 step:10167 [D loss: 0.603322, acc.: 67.97%] [G loss: 1.284449]\n",
      "epoch:10 step:10168 [D loss: 0.595837, acc.: 70.31%] [G loss: 1.136700]\n",
      "epoch:10 step:10169 [D loss: 0.521460, acc.: 76.56%] [G loss: 1.198723]\n",
      "epoch:10 step:10170 [D loss: 0.535683, acc.: 77.34%] [G loss: 1.188174]\n",
      "epoch:10 step:10171 [D loss: 0.627821, acc.: 60.94%] [G loss: 0.918298]\n",
      "epoch:10 step:10172 [D loss: 0.636376, acc.: 62.50%] [G loss: 0.987539]\n",
      "epoch:10 step:10173 [D loss: 0.615864, acc.: 60.16%] [G loss: 1.105571]\n",
      "epoch:10 step:10174 [D loss: 0.640010, acc.: 60.16%] [G loss: 1.066856]\n",
      "epoch:10 step:10175 [D loss: 0.687150, acc.: 56.25%] [G loss: 1.044948]\n",
      "epoch:10 step:10176 [D loss: 0.593594, acc.: 69.53%] [G loss: 1.048130]\n",
      "epoch:10 step:10177 [D loss: 0.568916, acc.: 70.31%] [G loss: 1.179444]\n",
      "epoch:10 step:10178 [D loss: 0.570179, acc.: 69.53%] [G loss: 1.241539]\n",
      "epoch:10 step:10179 [D loss: 0.535800, acc.: 75.00%] [G loss: 1.223114]\n",
      "epoch:10 step:10180 [D loss: 0.598999, acc.: 71.88%] [G loss: 1.333037]\n",
      "epoch:10 step:10181 [D loss: 0.550482, acc.: 72.66%] [G loss: 1.246614]\n",
      "epoch:10 step:10182 [D loss: 0.632525, acc.: 66.41%] [G loss: 1.123231]\n",
      "epoch:10 step:10183 [D loss: 0.706766, acc.: 58.59%] [G loss: 1.152343]\n",
      "epoch:10 step:10184 [D loss: 0.587536, acc.: 73.44%] [G loss: 1.017246]\n",
      "epoch:10 step:10185 [D loss: 0.668442, acc.: 59.38%] [G loss: 1.123289]\n",
      "epoch:10 step:10186 [D loss: 0.603126, acc.: 71.88%] [G loss: 1.272410]\n",
      "epoch:10 step:10187 [D loss: 0.541313, acc.: 75.00%] [G loss: 1.333408]\n",
      "epoch:10 step:10188 [D loss: 0.514417, acc.: 74.22%] [G loss: 1.261776]\n",
      "epoch:10 step:10189 [D loss: 0.600366, acc.: 66.41%] [G loss: 1.160277]\n",
      "epoch:10 step:10190 [D loss: 0.675247, acc.: 55.47%] [G loss: 0.858730]\n",
      "epoch:10 step:10191 [D loss: 0.601081, acc.: 71.09%] [G loss: 1.040713]\n",
      "epoch:10 step:10192 [D loss: 0.572721, acc.: 67.19%] [G loss: 1.349721]\n",
      "epoch:10 step:10193 [D loss: 0.658296, acc.: 60.94%] [G loss: 1.145876]\n",
      "epoch:10 step:10194 [D loss: 0.590995, acc.: 70.31%] [G loss: 0.867783]\n",
      "epoch:10 step:10195 [D loss: 0.658447, acc.: 60.16%] [G loss: 0.824961]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:10 step:10196 [D loss: 0.435928, acc.: 85.16%] [G loss: 1.313236]\n",
      "epoch:10 step:10197 [D loss: 0.601986, acc.: 72.66%] [G loss: 0.960663]\n",
      "epoch:10 step:10198 [D loss: 0.541739, acc.: 74.22%] [G loss: 1.190449]\n",
      "epoch:10 step:10199 [D loss: 0.584017, acc.: 64.84%] [G loss: 1.111133]\n",
      "epoch:10 step:10200 [D loss: 0.665367, acc.: 61.72%] [G loss: 0.919964]\n",
      "epoch:10 step:10201 [D loss: 0.577174, acc.: 67.19%] [G loss: 1.055923]\n",
      "epoch:10 step:10202 [D loss: 0.690936, acc.: 53.91%] [G loss: 0.971819]\n",
      "epoch:10 step:10203 [D loss: 0.603130, acc.: 70.31%] [G loss: 1.325738]\n",
      "epoch:10 step:10204 [D loss: 0.749901, acc.: 53.12%] [G loss: 1.056150]\n",
      "epoch:10 step:10205 [D loss: 0.574729, acc.: 67.19%] [G loss: 1.060093]\n",
      "epoch:10 step:10206 [D loss: 0.667937, acc.: 61.72%] [G loss: 1.069518]\n",
      "epoch:10 step:10207 [D loss: 0.649343, acc.: 62.50%] [G loss: 1.113215]\n",
      "epoch:10 step:10208 [D loss: 0.618445, acc.: 64.06%] [G loss: 1.061615]\n",
      "epoch:10 step:10209 [D loss: 0.651917, acc.: 59.38%] [G loss: 1.120160]\n",
      "epoch:10 step:10210 [D loss: 0.578348, acc.: 67.97%] [G loss: 1.126674]\n",
      "epoch:10 step:10211 [D loss: 0.637343, acc.: 66.41%] [G loss: 0.896428]\n",
      "epoch:10 step:10212 [D loss: 0.645086, acc.: 60.94%] [G loss: 0.987329]\n",
      "epoch:10 step:10213 [D loss: 0.591422, acc.: 65.62%] [G loss: 1.223768]\n",
      "epoch:10 step:10214 [D loss: 0.675123, acc.: 57.03%] [G loss: 1.012355]\n",
      "epoch:10 step:10215 [D loss: 0.591126, acc.: 64.06%] [G loss: 1.114637]\n",
      "epoch:10 step:10216 [D loss: 0.749229, acc.: 53.12%] [G loss: 0.926185]\n",
      "epoch:10 step:10217 [D loss: 0.604321, acc.: 70.31%] [G loss: 1.125752]\n",
      "epoch:10 step:10218 [D loss: 0.533046, acc.: 75.78%] [G loss: 1.318385]\n",
      "epoch:10 step:10219 [D loss: 0.579614, acc.: 71.09%] [G loss: 1.237227]\n",
      "epoch:10 step:10220 [D loss: 0.605150, acc.: 63.28%] [G loss: 0.991040]\n",
      "epoch:10 step:10221 [D loss: 0.674685, acc.: 59.38%] [G loss: 1.228322]\n",
      "epoch:10 step:10222 [D loss: 0.511955, acc.: 74.22%] [G loss: 1.190726]\n",
      "epoch:10 step:10223 [D loss: 0.552683, acc.: 74.22%] [G loss: 1.052392]\n",
      "epoch:10 step:10224 [D loss: 0.504870, acc.: 76.56%] [G loss: 1.272330]\n",
      "epoch:10 step:10225 [D loss: 0.605394, acc.: 71.88%] [G loss: 0.981647]\n",
      "epoch:10 step:10226 [D loss: 0.635395, acc.: 64.84%] [G loss: 1.103240]\n",
      "epoch:10 step:10227 [D loss: 0.614874, acc.: 65.62%] [G loss: 1.128988]\n",
      "epoch:10 step:10228 [D loss: 0.661568, acc.: 62.50%] [G loss: 1.065098]\n",
      "epoch:10 step:10229 [D loss: 0.580011, acc.: 66.41%] [G loss: 0.985404]\n",
      "epoch:10 step:10230 [D loss: 0.531058, acc.: 74.22%] [G loss: 1.093959]\n",
      "epoch:10 step:10231 [D loss: 0.585768, acc.: 68.75%] [G loss: 0.885713]\n",
      "epoch:10 step:10232 [D loss: 0.631864, acc.: 59.38%] [G loss: 1.244998]\n",
      "epoch:10 step:10233 [D loss: 0.563735, acc.: 72.66%] [G loss: 1.127394]\n",
      "epoch:10 step:10234 [D loss: 0.626668, acc.: 65.62%] [G loss: 1.069027]\n",
      "epoch:10 step:10235 [D loss: 0.603324, acc.: 67.97%] [G loss: 0.947971]\n",
      "epoch:10 step:10236 [D loss: 0.590634, acc.: 74.22%] [G loss: 1.232418]\n",
      "epoch:10 step:10237 [D loss: 0.600546, acc.: 64.84%] [G loss: 1.261655]\n",
      "epoch:10 step:10238 [D loss: 0.521211, acc.: 75.78%] [G loss: 1.357821]\n",
      "epoch:10 step:10239 [D loss: 0.573383, acc.: 73.44%] [G loss: 1.420288]\n",
      "epoch:10 step:10240 [D loss: 0.505280, acc.: 75.00%] [G loss: 1.125619]\n",
      "epoch:10 step:10241 [D loss: 0.598046, acc.: 63.28%] [G loss: 1.050947]\n",
      "epoch:10 step:10242 [D loss: 0.607353, acc.: 65.62%] [G loss: 1.245807]\n",
      "epoch:10 step:10243 [D loss: 0.499344, acc.: 74.22%] [G loss: 1.310163]\n",
      "epoch:10 step:10244 [D loss: 0.665084, acc.: 62.50%] [G loss: 1.056676]\n",
      "epoch:10 step:10245 [D loss: 0.559239, acc.: 70.31%] [G loss: 1.027744]\n",
      "epoch:10 step:10246 [D loss: 0.561117, acc.: 70.31%] [G loss: 1.168978]\n",
      "epoch:10 step:10247 [D loss: 0.636865, acc.: 63.28%] [G loss: 1.171006]\n",
      "epoch:10 step:10248 [D loss: 0.672304, acc.: 58.59%] [G loss: 1.079779]\n",
      "epoch:10 step:10249 [D loss: 0.692792, acc.: 53.91%] [G loss: 1.180206]\n",
      "epoch:10 step:10250 [D loss: 0.619831, acc.: 66.41%] [G loss: 1.048455]\n",
      "epoch:10 step:10251 [D loss: 0.636684, acc.: 64.06%] [G loss: 1.029507]\n",
      "epoch:10 step:10252 [D loss: 0.551518, acc.: 71.09%] [G loss: 1.016914]\n",
      "epoch:10 step:10253 [D loss: 0.705981, acc.: 55.47%] [G loss: 0.926624]\n",
      "epoch:10 step:10254 [D loss: 0.604069, acc.: 70.31%] [G loss: 1.306901]\n",
      "epoch:10 step:10255 [D loss: 0.541630, acc.: 75.00%] [G loss: 1.140488]\n",
      "epoch:10 step:10256 [D loss: 0.634599, acc.: 64.06%] [G loss: 1.138700]\n",
      "epoch:10 step:10257 [D loss: 0.609019, acc.: 64.84%] [G loss: 0.929843]\n",
      "epoch:10 step:10258 [D loss: 0.599643, acc.: 64.06%] [G loss: 1.135220]\n",
      "epoch:10 step:10259 [D loss: 0.721680, acc.: 49.22%] [G loss: 1.078021]\n",
      "epoch:10 step:10260 [D loss: 0.720512, acc.: 56.25%] [G loss: 0.902385]\n",
      "epoch:10 step:10261 [D loss: 0.658712, acc.: 60.16%] [G loss: 1.080218]\n",
      "epoch:10 step:10262 [D loss: 0.602243, acc.: 63.28%] [G loss: 1.117515]\n",
      "epoch:10 step:10263 [D loss: 0.661213, acc.: 57.81%] [G loss: 1.016543]\n",
      "epoch:10 step:10264 [D loss: 0.649971, acc.: 64.84%] [G loss: 1.316142]\n",
      "epoch:10 step:10265 [D loss: 0.581522, acc.: 71.09%] [G loss: 1.196023]\n",
      "epoch:10 step:10266 [D loss: 0.645299, acc.: 60.94%] [G loss: 1.160099]\n",
      "epoch:10 step:10267 [D loss: 0.662664, acc.: 58.59%] [G loss: 1.135362]\n",
      "epoch:10 step:10268 [D loss: 0.625046, acc.: 69.53%] [G loss: 1.221686]\n",
      "epoch:10 step:10269 [D loss: 0.524181, acc.: 76.56%] [G loss: 1.217364]\n",
      "epoch:10 step:10270 [D loss: 0.555479, acc.: 72.66%] [G loss: 1.224605]\n",
      "epoch:10 step:10271 [D loss: 0.654467, acc.: 62.50%] [G loss: 0.972055]\n",
      "epoch:10 step:10272 [D loss: 0.669504, acc.: 64.84%] [G loss: 1.285334]\n",
      "epoch:10 step:10273 [D loss: 0.605745, acc.: 70.31%] [G loss: 1.080756]\n",
      "epoch:10 step:10274 [D loss: 0.530372, acc.: 75.00%] [G loss: 1.194218]\n",
      "epoch:10 step:10275 [D loss: 0.576766, acc.: 71.09%] [G loss: 0.983373]\n",
      "epoch:10 step:10276 [D loss: 0.617661, acc.: 62.50%] [G loss: 1.193003]\n",
      "epoch:10 step:10277 [D loss: 0.717361, acc.: 53.12%] [G loss: 1.276492]\n",
      "epoch:10 step:10278 [D loss: 0.712445, acc.: 50.00%] [G loss: 0.919940]\n",
      "epoch:10 step:10279 [D loss: 0.680489, acc.: 56.25%] [G loss: 0.967652]\n",
      "epoch:10 step:10280 [D loss: 0.512330, acc.: 81.25%] [G loss: 1.105083]\n",
      "epoch:10 step:10281 [D loss: 0.626306, acc.: 64.06%] [G loss: 1.154763]\n",
      "epoch:10 step:10282 [D loss: 0.780366, acc.: 49.22%] [G loss: 1.011502]\n",
      "epoch:10 step:10283 [D loss: 0.636576, acc.: 65.62%] [G loss: 1.058908]\n",
      "epoch:10 step:10284 [D loss: 0.719220, acc.: 53.91%] [G loss: 1.130099]\n",
      "epoch:10 step:10285 [D loss: 0.588425, acc.: 71.09%] [G loss: 0.997264]\n",
      "epoch:10 step:10286 [D loss: 0.592754, acc.: 70.31%] [G loss: 1.125929]\n",
      "epoch:10 step:10287 [D loss: 0.533506, acc.: 74.22%] [G loss: 1.156060]\n",
      "epoch:10 step:10288 [D loss: 0.633333, acc.: 64.84%] [G loss: 1.166573]\n",
      "epoch:10 step:10289 [D loss: 0.633290, acc.: 60.94%] [G loss: 1.027566]\n",
      "epoch:10 step:10290 [D loss: 0.740314, acc.: 54.69%] [G loss: 1.002246]\n",
      "epoch:10 step:10291 [D loss: 0.665177, acc.: 60.16%] [G loss: 1.036202]\n",
      "epoch:10 step:10292 [D loss: 0.518177, acc.: 75.78%] [G loss: 1.126742]\n",
      "epoch:10 step:10293 [D loss: 0.684110, acc.: 61.72%] [G loss: 1.185860]\n",
      "epoch:10 step:10294 [D loss: 0.588153, acc.: 68.75%] [G loss: 1.267560]\n",
      "epoch:10 step:10295 [D loss: 0.517503, acc.: 72.66%] [G loss: 1.142335]\n",
      "epoch:10 step:10296 [D loss: 0.577521, acc.: 71.88%] [G loss: 1.025490]\n",
      "epoch:10 step:10297 [D loss: 0.619991, acc.: 65.62%] [G loss: 1.112697]\n",
      "epoch:10 step:10298 [D loss: 0.572307, acc.: 68.75%] [G loss: 0.856352]\n",
      "epoch:10 step:10299 [D loss: 0.617572, acc.: 65.62%] [G loss: 1.188767]\n",
      "epoch:10 step:10300 [D loss: 0.517499, acc.: 75.00%] [G loss: 0.982118]\n",
      "epoch:10 step:10301 [D loss: 0.670288, acc.: 62.50%] [G loss: 1.026018]\n",
      "epoch:10 step:10302 [D loss: 0.711070, acc.: 53.91%] [G loss: 1.128439]\n",
      "epoch:10 step:10303 [D loss: 0.741783, acc.: 51.56%] [G loss: 0.994015]\n",
      "epoch:10 step:10304 [D loss: 0.625296, acc.: 64.06%] [G loss: 0.993280]\n",
      "epoch:10 step:10305 [D loss: 0.577758, acc.: 71.09%] [G loss: 1.088922]\n",
      "epoch:10 step:10306 [D loss: 0.615526, acc.: 64.84%] [G loss: 1.080864]\n",
      "epoch:10 step:10307 [D loss: 0.625017, acc.: 62.50%] [G loss: 1.274652]\n",
      "epoch:11 step:10308 [D loss: 0.774081, acc.: 51.56%] [G loss: 0.940052]\n",
      "epoch:11 step:10309 [D loss: 0.602882, acc.: 66.41%] [G loss: 1.195085]\n",
      "epoch:11 step:10310 [D loss: 0.647366, acc.: 58.59%] [G loss: 0.998590]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:11 step:10311 [D loss: 0.578433, acc.: 68.75%] [G loss: 1.216448]\n",
      "epoch:11 step:10312 [D loss: 0.640806, acc.: 66.41%] [G loss: 0.991031]\n",
      "epoch:11 step:10313 [D loss: 0.613411, acc.: 67.97%] [G loss: 1.119755]\n",
      "epoch:11 step:10314 [D loss: 0.754585, acc.: 48.44%] [G loss: 1.083838]\n",
      "epoch:11 step:10315 [D loss: 0.651145, acc.: 58.59%] [G loss: 0.935857]\n",
      "epoch:11 step:10316 [D loss: 0.661920, acc.: 60.94%] [G loss: 1.046476]\n",
      "epoch:11 step:10317 [D loss: 0.637133, acc.: 65.62%] [G loss: 1.135487]\n",
      "epoch:11 step:10318 [D loss: 0.534971, acc.: 76.56%] [G loss: 1.232983]\n",
      "epoch:11 step:10319 [D loss: 0.564665, acc.: 71.09%] [G loss: 1.177657]\n",
      "epoch:11 step:10320 [D loss: 0.586632, acc.: 69.53%] [G loss: 1.343372]\n",
      "epoch:11 step:10321 [D loss: 0.616386, acc.: 68.75%] [G loss: 1.182971]\n",
      "epoch:11 step:10322 [D loss: 0.477602, acc.: 81.25%] [G loss: 1.134785]\n",
      "epoch:11 step:10323 [D loss: 0.516866, acc.: 74.22%] [G loss: 1.017069]\n",
      "epoch:11 step:10324 [D loss: 0.667293, acc.: 61.72%] [G loss: 1.022471]\n",
      "epoch:11 step:10325 [D loss: 0.594307, acc.: 65.62%] [G loss: 0.928305]\n",
      "epoch:11 step:10326 [D loss: 0.662726, acc.: 59.38%] [G loss: 1.052908]\n",
      "epoch:11 step:10327 [D loss: 0.602713, acc.: 66.41%] [G loss: 1.027917]\n",
      "epoch:11 step:10328 [D loss: 0.654985, acc.: 60.94%] [G loss: 1.248937]\n",
      "epoch:11 step:10329 [D loss: 0.505844, acc.: 79.69%] [G loss: 1.205706]\n",
      "epoch:11 step:10330 [D loss: 0.650643, acc.: 57.81%] [G loss: 0.986784]\n",
      "epoch:11 step:10331 [D loss: 0.595305, acc.: 67.97%] [G loss: 1.194392]\n",
      "epoch:11 step:10332 [D loss: 0.642134, acc.: 60.94%] [G loss: 1.105196]\n",
      "epoch:11 step:10333 [D loss: 0.583247, acc.: 71.88%] [G loss: 1.165263]\n",
      "epoch:11 step:10334 [D loss: 0.617034, acc.: 66.41%] [G loss: 0.963130]\n",
      "epoch:11 step:10335 [D loss: 0.551697, acc.: 73.44%] [G loss: 1.373852]\n",
      "epoch:11 step:10336 [D loss: 0.665783, acc.: 58.59%] [G loss: 1.187227]\n",
      "epoch:11 step:10337 [D loss: 0.584642, acc.: 71.09%] [G loss: 1.077812]\n",
      "epoch:11 step:10338 [D loss: 0.646438, acc.: 64.84%] [G loss: 1.098510]\n",
      "epoch:11 step:10339 [D loss: 0.580130, acc.: 69.53%] [G loss: 1.104149]\n",
      "epoch:11 step:10340 [D loss: 0.530665, acc.: 76.56%] [G loss: 1.410701]\n",
      "epoch:11 step:10341 [D loss: 0.664802, acc.: 59.38%] [G loss: 1.056121]\n",
      "epoch:11 step:10342 [D loss: 0.634729, acc.: 61.72%] [G loss: 1.241411]\n",
      "epoch:11 step:10343 [D loss: 0.578279, acc.: 68.75%] [G loss: 1.037084]\n",
      "epoch:11 step:10344 [D loss: 0.693485, acc.: 60.16%] [G loss: 0.829293]\n",
      "epoch:11 step:10345 [D loss: 0.632387, acc.: 64.84%] [G loss: 1.306089]\n",
      "epoch:11 step:10346 [D loss: 0.626824, acc.: 63.28%] [G loss: 1.348461]\n",
      "epoch:11 step:10347 [D loss: 0.642349, acc.: 59.38%] [G loss: 0.991484]\n",
      "epoch:11 step:10348 [D loss: 0.590105, acc.: 71.09%] [G loss: 0.980789]\n",
      "epoch:11 step:10349 [D loss: 0.522194, acc.: 76.56%] [G loss: 1.151912]\n",
      "epoch:11 step:10350 [D loss: 0.604765, acc.: 69.53%] [G loss: 1.252549]\n",
      "epoch:11 step:10351 [D loss: 0.509698, acc.: 75.00%] [G loss: 1.285449]\n",
      "epoch:11 step:10352 [D loss: 0.575513, acc.: 73.44%] [G loss: 1.092012]\n",
      "epoch:11 step:10353 [D loss: 0.675426, acc.: 62.50%] [G loss: 1.231624]\n",
      "epoch:11 step:10354 [D loss: 0.613756, acc.: 65.62%] [G loss: 0.941787]\n",
      "epoch:11 step:10355 [D loss: 0.662670, acc.: 59.38%] [G loss: 1.005390]\n",
      "epoch:11 step:10356 [D loss: 0.568682, acc.: 67.97%] [G loss: 1.063792]\n",
      "epoch:11 step:10357 [D loss: 0.595150, acc.: 66.41%] [G loss: 1.192658]\n",
      "epoch:11 step:10358 [D loss: 0.678782, acc.: 58.59%] [G loss: 1.257185]\n",
      "epoch:11 step:10359 [D loss: 0.590118, acc.: 70.31%] [G loss: 1.262955]\n",
      "epoch:11 step:10360 [D loss: 0.535880, acc.: 70.31%] [G loss: 1.181085]\n",
      "epoch:11 step:10361 [D loss: 0.604213, acc.: 67.19%] [G loss: 0.920834]\n",
      "epoch:11 step:10362 [D loss: 0.669116, acc.: 62.50%] [G loss: 0.934050]\n",
      "epoch:11 step:10363 [D loss: 0.636782, acc.: 62.50%] [G loss: 1.340458]\n",
      "epoch:11 step:10364 [D loss: 0.614333, acc.: 64.06%] [G loss: 1.088105]\n",
      "epoch:11 step:10365 [D loss: 0.764113, acc.: 50.00%] [G loss: 1.076213]\n",
      "epoch:11 step:10366 [D loss: 0.483077, acc.: 76.56%] [G loss: 1.144898]\n",
      "epoch:11 step:10367 [D loss: 0.500265, acc.: 76.56%] [G loss: 1.225234]\n",
      "epoch:11 step:10368 [D loss: 0.520277, acc.: 77.34%] [G loss: 1.246087]\n",
      "epoch:11 step:10369 [D loss: 0.575777, acc.: 72.66%] [G loss: 1.124748]\n",
      "epoch:11 step:10370 [D loss: 0.570312, acc.: 70.31%] [G loss: 1.024714]\n",
      "epoch:11 step:10371 [D loss: 0.609949, acc.: 65.62%] [G loss: 1.165968]\n",
      "epoch:11 step:10372 [D loss: 0.536242, acc.: 74.22%] [G loss: 1.284523]\n",
      "epoch:11 step:10373 [D loss: 0.691547, acc.: 56.25%] [G loss: 0.918942]\n",
      "epoch:11 step:10374 [D loss: 0.580594, acc.: 67.19%] [G loss: 1.001688]\n",
      "epoch:11 step:10375 [D loss: 0.602556, acc.: 71.88%] [G loss: 1.071385]\n",
      "epoch:11 step:10376 [D loss: 0.593186, acc.: 72.66%] [G loss: 1.257945]\n",
      "epoch:11 step:10377 [D loss: 0.656399, acc.: 62.50%] [G loss: 1.056001]\n",
      "epoch:11 step:10378 [D loss: 0.618356, acc.: 64.06%] [G loss: 0.904853]\n",
      "epoch:11 step:10379 [D loss: 0.580158, acc.: 67.19%] [G loss: 1.262543]\n",
      "epoch:11 step:10380 [D loss: 0.459656, acc.: 82.03%] [G loss: 1.228578]\n",
      "epoch:11 step:10381 [D loss: 0.685601, acc.: 57.81%] [G loss: 1.059181]\n",
      "epoch:11 step:10382 [D loss: 0.597960, acc.: 67.97%] [G loss: 1.132538]\n",
      "epoch:11 step:10383 [D loss: 0.639829, acc.: 62.50%] [G loss: 1.044958]\n",
      "epoch:11 step:10384 [D loss: 0.591299, acc.: 70.31%] [G loss: 1.191304]\n",
      "epoch:11 step:10385 [D loss: 0.596814, acc.: 69.53%] [G loss: 1.063374]\n",
      "epoch:11 step:10386 [D loss: 0.627026, acc.: 71.09%] [G loss: 0.975566]\n",
      "epoch:11 step:10387 [D loss: 0.614922, acc.: 66.41%] [G loss: 1.197220]\n",
      "epoch:11 step:10388 [D loss: 0.691925, acc.: 58.59%] [G loss: 0.979484]\n",
      "epoch:11 step:10389 [D loss: 0.638779, acc.: 67.19%] [G loss: 1.131375]\n",
      "epoch:11 step:10390 [D loss: 0.667211, acc.: 64.06%] [G loss: 1.161750]\n",
      "epoch:11 step:10391 [D loss: 0.664070, acc.: 64.06%] [G loss: 1.094053]\n",
      "epoch:11 step:10392 [D loss: 0.599225, acc.: 67.19%] [G loss: 1.057434]\n",
      "epoch:11 step:10393 [D loss: 0.706825, acc.: 59.38%] [G loss: 1.119919]\n",
      "epoch:11 step:10394 [D loss: 0.679656, acc.: 60.94%] [G loss: 1.012016]\n",
      "epoch:11 step:10395 [D loss: 0.634538, acc.: 65.62%] [G loss: 1.213940]\n",
      "epoch:11 step:10396 [D loss: 0.630341, acc.: 61.72%] [G loss: 1.113194]\n",
      "epoch:11 step:10397 [D loss: 0.518196, acc.: 75.78%] [G loss: 1.104898]\n",
      "epoch:11 step:10398 [D loss: 0.631306, acc.: 64.84%] [G loss: 1.171969]\n",
      "epoch:11 step:10399 [D loss: 0.609553, acc.: 67.19%] [G loss: 1.045504]\n",
      "epoch:11 step:10400 [D loss: 0.688506, acc.: 56.25%] [G loss: 1.031122]\n",
      "epoch:11 step:10401 [D loss: 0.648389, acc.: 60.94%] [G loss: 1.146762]\n",
      "epoch:11 step:10402 [D loss: 0.629713, acc.: 64.06%] [G loss: 1.002500]\n",
      "epoch:11 step:10403 [D loss: 0.546470, acc.: 74.22%] [G loss: 1.287582]\n",
      "epoch:11 step:10404 [D loss: 0.586325, acc.: 73.44%] [G loss: 1.256323]\n",
      "epoch:11 step:10405 [D loss: 0.581757, acc.: 73.44%] [G loss: 1.173744]\n",
      "epoch:11 step:10406 [D loss: 0.625593, acc.: 64.06%] [G loss: 1.228750]\n",
      "epoch:11 step:10407 [D loss: 0.630345, acc.: 66.41%] [G loss: 1.023203]\n",
      "epoch:11 step:10408 [D loss: 0.621790, acc.: 66.41%] [G loss: 0.932252]\n",
      "epoch:11 step:10409 [D loss: 0.778379, acc.: 51.56%] [G loss: 1.160830]\n",
      "epoch:11 step:10410 [D loss: 0.676382, acc.: 59.38%] [G loss: 1.125040]\n",
      "epoch:11 step:10411 [D loss: 0.596613, acc.: 68.75%] [G loss: 1.301292]\n",
      "epoch:11 step:10412 [D loss: 0.644546, acc.: 61.72%] [G loss: 1.257604]\n",
      "epoch:11 step:10413 [D loss: 0.651340, acc.: 62.50%] [G loss: 0.950333]\n",
      "epoch:11 step:10414 [D loss: 0.613625, acc.: 65.62%] [G loss: 1.120057]\n",
      "epoch:11 step:10415 [D loss: 0.681220, acc.: 55.47%] [G loss: 0.992675]\n",
      "epoch:11 step:10416 [D loss: 0.607751, acc.: 64.84%] [G loss: 1.058039]\n",
      "epoch:11 step:10417 [D loss: 0.664294, acc.: 64.06%] [G loss: 1.139947]\n",
      "epoch:11 step:10418 [D loss: 0.758989, acc.: 50.00%] [G loss: 1.116040]\n",
      "epoch:11 step:10419 [D loss: 0.696093, acc.: 56.25%] [G loss: 0.895957]\n",
      "epoch:11 step:10420 [D loss: 0.584832, acc.: 69.53%] [G loss: 1.226025]\n",
      "epoch:11 step:10421 [D loss: 0.580353, acc.: 68.75%] [G loss: 1.421606]\n",
      "epoch:11 step:10422 [D loss: 0.706544, acc.: 60.16%] [G loss: 1.083578]\n",
      "epoch:11 step:10423 [D loss: 0.690544, acc.: 57.81%] [G loss: 1.170280]\n",
      "epoch:11 step:10424 [D loss: 0.597104, acc.: 68.75%] [G loss: 1.153529]\n",
      "epoch:11 step:10425 [D loss: 0.571577, acc.: 69.53%] [G loss: 1.245338]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:11 step:10426 [D loss: 0.680035, acc.: 57.03%] [G loss: 1.059598]\n",
      "epoch:11 step:10427 [D loss: 0.738182, acc.: 54.69%] [G loss: 0.978810]\n",
      "epoch:11 step:10428 [D loss: 0.628707, acc.: 59.38%] [G loss: 0.955340]\n",
      "epoch:11 step:10429 [D loss: 0.683359, acc.: 60.16%] [G loss: 1.016948]\n",
      "epoch:11 step:10430 [D loss: 0.561353, acc.: 74.22%] [G loss: 1.238413]\n",
      "epoch:11 step:10431 [D loss: 0.554945, acc.: 69.53%] [G loss: 0.999149]\n",
      "epoch:11 step:10432 [D loss: 0.573341, acc.: 65.62%] [G loss: 1.126674]\n",
      "epoch:11 step:10433 [D loss: 0.633967, acc.: 60.94%] [G loss: 1.165071]\n",
      "epoch:11 step:10434 [D loss: 0.612939, acc.: 64.06%] [G loss: 1.021816]\n",
      "epoch:11 step:10435 [D loss: 0.545562, acc.: 77.34%] [G loss: 1.170723]\n",
      "epoch:11 step:10436 [D loss: 0.582934, acc.: 65.62%] [G loss: 1.237857]\n",
      "epoch:11 step:10437 [D loss: 0.526762, acc.: 78.12%] [G loss: 1.330692]\n",
      "epoch:11 step:10438 [D loss: 0.588457, acc.: 72.66%] [G loss: 1.156537]\n",
      "epoch:11 step:10439 [D loss: 0.630731, acc.: 60.16%] [G loss: 1.240360]\n",
      "epoch:11 step:10440 [D loss: 0.644184, acc.: 59.38%] [G loss: 1.190301]\n",
      "epoch:11 step:10441 [D loss: 0.655894, acc.: 60.94%] [G loss: 1.156030]\n",
      "epoch:11 step:10442 [D loss: 0.694458, acc.: 57.81%] [G loss: 0.946427]\n",
      "epoch:11 step:10443 [D loss: 0.576703, acc.: 71.88%] [G loss: 1.142781]\n",
      "epoch:11 step:10444 [D loss: 0.613267, acc.: 68.75%] [G loss: 0.936961]\n",
      "epoch:11 step:10445 [D loss: 0.723449, acc.: 53.91%] [G loss: 0.881262]\n",
      "epoch:11 step:10446 [D loss: 0.671090, acc.: 64.06%] [G loss: 1.220848]\n",
      "epoch:11 step:10447 [D loss: 0.646726, acc.: 67.19%] [G loss: 1.106410]\n",
      "epoch:11 step:10448 [D loss: 0.690500, acc.: 54.69%] [G loss: 0.924304]\n",
      "epoch:11 step:10449 [D loss: 0.607558, acc.: 66.41%] [G loss: 0.875532]\n",
      "epoch:11 step:10450 [D loss: 0.588326, acc.: 67.97%] [G loss: 1.139668]\n",
      "epoch:11 step:10451 [D loss: 0.684439, acc.: 57.03%] [G loss: 0.983791]\n",
      "epoch:11 step:10452 [D loss: 0.570547, acc.: 74.22%] [G loss: 1.012924]\n",
      "epoch:11 step:10453 [D loss: 0.599726, acc.: 61.72%] [G loss: 1.071149]\n",
      "epoch:11 step:10454 [D loss: 0.635480, acc.: 65.62%] [G loss: 1.099663]\n",
      "epoch:11 step:10455 [D loss: 0.558054, acc.: 75.78%] [G loss: 1.118924]\n",
      "epoch:11 step:10456 [D loss: 0.606088, acc.: 67.19%] [G loss: 1.016397]\n",
      "epoch:11 step:10457 [D loss: 0.546524, acc.: 71.09%] [G loss: 1.326643]\n",
      "epoch:11 step:10458 [D loss: 0.534609, acc.: 75.00%] [G loss: 1.224706]\n",
      "epoch:11 step:10459 [D loss: 0.581540, acc.: 69.53%] [G loss: 1.233095]\n",
      "epoch:11 step:10460 [D loss: 0.525743, acc.: 76.56%] [G loss: 1.384107]\n",
      "epoch:11 step:10461 [D loss: 0.716040, acc.: 54.69%] [G loss: 1.090654]\n",
      "epoch:11 step:10462 [D loss: 0.626756, acc.: 62.50%] [G loss: 1.011762]\n",
      "epoch:11 step:10463 [D loss: 0.506998, acc.: 73.44%] [G loss: 1.335519]\n",
      "epoch:11 step:10464 [D loss: 0.640680, acc.: 60.16%] [G loss: 0.998806]\n",
      "epoch:11 step:10465 [D loss: 0.626506, acc.: 65.62%] [G loss: 1.341090]\n",
      "epoch:11 step:10466 [D loss: 0.552232, acc.: 71.09%] [G loss: 1.243819]\n",
      "epoch:11 step:10467 [D loss: 0.569161, acc.: 71.09%] [G loss: 1.248313]\n",
      "epoch:11 step:10468 [D loss: 0.546510, acc.: 71.88%] [G loss: 1.078373]\n",
      "epoch:11 step:10469 [D loss: 0.654131, acc.: 59.38%] [G loss: 1.075660]\n",
      "epoch:11 step:10470 [D loss: 0.623512, acc.: 67.97%] [G loss: 1.117730]\n",
      "epoch:11 step:10471 [D loss: 0.519902, acc.: 79.69%] [G loss: 0.991690]\n",
      "epoch:11 step:10472 [D loss: 0.690589, acc.: 53.12%] [G loss: 0.940586]\n",
      "epoch:11 step:10473 [D loss: 0.568774, acc.: 70.31%] [G loss: 1.081042]\n",
      "epoch:11 step:10474 [D loss: 0.523550, acc.: 74.22%] [G loss: 1.026287]\n",
      "epoch:11 step:10475 [D loss: 0.684612, acc.: 53.12%] [G loss: 1.171156]\n",
      "epoch:11 step:10476 [D loss: 0.604552, acc.: 69.53%] [G loss: 1.347410]\n",
      "epoch:11 step:10477 [D loss: 0.701074, acc.: 54.69%] [G loss: 1.115174]\n",
      "epoch:11 step:10478 [D loss: 0.615538, acc.: 60.94%] [G loss: 1.338547]\n",
      "epoch:11 step:10479 [D loss: 0.584790, acc.: 64.84%] [G loss: 1.198243]\n",
      "epoch:11 step:10480 [D loss: 0.634820, acc.: 58.59%] [G loss: 1.219725]\n",
      "epoch:11 step:10481 [D loss: 0.628037, acc.: 64.06%] [G loss: 1.181532]\n",
      "epoch:11 step:10482 [D loss: 0.571316, acc.: 74.22%] [G loss: 1.422076]\n",
      "epoch:11 step:10483 [D loss: 0.584549, acc.: 72.66%] [G loss: 0.989063]\n",
      "epoch:11 step:10484 [D loss: 0.621650, acc.: 62.50%] [G loss: 1.130592]\n",
      "epoch:11 step:10485 [D loss: 0.511455, acc.: 80.47%] [G loss: 1.052851]\n",
      "epoch:11 step:10486 [D loss: 0.644095, acc.: 61.72%] [G loss: 1.086968]\n",
      "epoch:11 step:10487 [D loss: 0.560930, acc.: 69.53%] [G loss: 0.936157]\n",
      "epoch:11 step:10488 [D loss: 0.629669, acc.: 64.06%] [G loss: 1.235964]\n",
      "epoch:11 step:10489 [D loss: 0.603756, acc.: 68.75%] [G loss: 1.025597]\n",
      "epoch:11 step:10490 [D loss: 0.632268, acc.: 60.94%] [G loss: 1.379016]\n",
      "epoch:11 step:10491 [D loss: 0.664090, acc.: 60.16%] [G loss: 1.130485]\n",
      "epoch:11 step:10492 [D loss: 0.602794, acc.: 66.41%] [G loss: 1.084121]\n",
      "epoch:11 step:10493 [D loss: 0.613452, acc.: 60.16%] [G loss: 1.188521]\n",
      "epoch:11 step:10494 [D loss: 0.510117, acc.: 80.47%] [G loss: 1.045924]\n",
      "epoch:11 step:10495 [D loss: 0.496404, acc.: 75.78%] [G loss: 1.278053]\n",
      "epoch:11 step:10496 [D loss: 0.621614, acc.: 63.28%] [G loss: 0.864158]\n",
      "epoch:11 step:10497 [D loss: 0.607041, acc.: 66.41%] [G loss: 1.249442]\n",
      "epoch:11 step:10498 [D loss: 0.552965, acc.: 76.56%] [G loss: 1.205256]\n",
      "epoch:11 step:10499 [D loss: 0.601129, acc.: 64.06%] [G loss: 1.035593]\n",
      "epoch:11 step:10500 [D loss: 0.644825, acc.: 60.16%] [G loss: 1.159896]\n",
      "epoch:11 step:10501 [D loss: 0.666450, acc.: 58.59%] [G loss: 0.912515]\n",
      "epoch:11 step:10502 [D loss: 0.661463, acc.: 62.50%] [G loss: 1.065257]\n",
      "epoch:11 step:10503 [D loss: 0.655370, acc.: 62.50%] [G loss: 1.157124]\n",
      "epoch:11 step:10504 [D loss: 0.562760, acc.: 71.88%] [G loss: 1.151879]\n",
      "epoch:11 step:10505 [D loss: 0.551822, acc.: 71.88%] [G loss: 1.336865]\n",
      "epoch:11 step:10506 [D loss: 0.639522, acc.: 65.62%] [G loss: 1.093297]\n",
      "epoch:11 step:10507 [D loss: 0.621313, acc.: 62.50%] [G loss: 1.169808]\n",
      "epoch:11 step:10508 [D loss: 0.535100, acc.: 74.22%] [G loss: 1.290141]\n",
      "epoch:11 step:10509 [D loss: 0.457048, acc.: 78.91%] [G loss: 1.359400]\n",
      "epoch:11 step:10510 [D loss: 0.641253, acc.: 67.97%] [G loss: 1.204631]\n",
      "epoch:11 step:10511 [D loss: 0.627860, acc.: 67.19%] [G loss: 1.343086]\n",
      "epoch:11 step:10512 [D loss: 0.678364, acc.: 62.50%] [G loss: 1.100859]\n",
      "epoch:11 step:10513 [D loss: 0.649780, acc.: 62.50%] [G loss: 1.057078]\n",
      "epoch:11 step:10514 [D loss: 0.543306, acc.: 73.44%] [G loss: 1.158017]\n",
      "epoch:11 step:10515 [D loss: 0.527581, acc.: 74.22%] [G loss: 1.122450]\n",
      "epoch:11 step:10516 [D loss: 0.511562, acc.: 77.34%] [G loss: 1.085767]\n",
      "epoch:11 step:10517 [D loss: 0.570709, acc.: 71.09%] [G loss: 1.078192]\n",
      "epoch:11 step:10518 [D loss: 0.538839, acc.: 80.47%] [G loss: 1.133890]\n",
      "epoch:11 step:10519 [D loss: 0.589273, acc.: 72.66%] [G loss: 1.190791]\n",
      "epoch:11 step:10520 [D loss: 0.600885, acc.: 69.53%] [G loss: 0.961836]\n",
      "epoch:11 step:10521 [D loss: 0.714142, acc.: 54.69%] [G loss: 0.959419]\n",
      "epoch:11 step:10522 [D loss: 0.670634, acc.: 56.25%] [G loss: 0.817472]\n",
      "epoch:11 step:10523 [D loss: 0.668513, acc.: 60.16%] [G loss: 0.962592]\n",
      "epoch:11 step:10524 [D loss: 0.552016, acc.: 73.44%] [G loss: 1.137666]\n",
      "epoch:11 step:10525 [D loss: 0.553406, acc.: 71.09%] [G loss: 1.061056]\n",
      "epoch:11 step:10526 [D loss: 0.704907, acc.: 53.91%] [G loss: 1.082942]\n",
      "epoch:11 step:10527 [D loss: 0.707325, acc.: 55.47%] [G loss: 1.237962]\n",
      "epoch:11 step:10528 [D loss: 0.608553, acc.: 67.19%] [G loss: 1.095340]\n",
      "epoch:11 step:10529 [D loss: 0.745192, acc.: 51.56%] [G loss: 1.182333]\n",
      "epoch:11 step:10530 [D loss: 0.712943, acc.: 58.59%] [G loss: 1.109191]\n",
      "epoch:11 step:10531 [D loss: 0.595321, acc.: 73.44%] [G loss: 1.474072]\n",
      "epoch:11 step:10532 [D loss: 0.557378, acc.: 71.09%] [G loss: 1.207415]\n",
      "epoch:11 step:10533 [D loss: 0.601222, acc.: 67.97%] [G loss: 0.947911]\n",
      "epoch:11 step:10534 [D loss: 0.569565, acc.: 68.75%] [G loss: 1.172798]\n",
      "epoch:11 step:10535 [D loss: 0.539840, acc.: 78.91%] [G loss: 1.209617]\n",
      "epoch:11 step:10536 [D loss: 0.582965, acc.: 70.31%] [G loss: 1.279179]\n",
      "epoch:11 step:10537 [D loss: 0.566337, acc.: 72.66%] [G loss: 1.123133]\n",
      "epoch:11 step:10538 [D loss: 0.601996, acc.: 67.19%] [G loss: 1.075238]\n",
      "epoch:11 step:10539 [D loss: 0.651981, acc.: 60.94%] [G loss: 1.162163]\n",
      "epoch:11 step:10540 [D loss: 0.572299, acc.: 69.53%] [G loss: 1.046145]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:11 step:10541 [D loss: 0.804888, acc.: 45.31%] [G loss: 0.927379]\n",
      "epoch:11 step:10542 [D loss: 0.566869, acc.: 70.31%] [G loss: 1.156587]\n",
      "epoch:11 step:10543 [D loss: 0.572575, acc.: 76.56%] [G loss: 1.317008]\n",
      "epoch:11 step:10544 [D loss: 0.642004, acc.: 63.28%] [G loss: 1.055101]\n",
      "epoch:11 step:10545 [D loss: 0.668326, acc.: 57.03%] [G loss: 1.090149]\n",
      "epoch:11 step:10546 [D loss: 0.520066, acc.: 73.44%] [G loss: 1.066128]\n",
      "epoch:11 step:10547 [D loss: 0.677170, acc.: 59.38%] [G loss: 1.214087]\n",
      "epoch:11 step:10548 [D loss: 0.616425, acc.: 61.72%] [G loss: 1.115270]\n",
      "epoch:11 step:10549 [D loss: 0.685773, acc.: 57.03%] [G loss: 1.052640]\n",
      "epoch:11 step:10550 [D loss: 0.544692, acc.: 77.34%] [G loss: 1.308288]\n",
      "epoch:11 step:10551 [D loss: 0.650204, acc.: 60.94%] [G loss: 1.187577]\n",
      "epoch:11 step:10552 [D loss: 0.587726, acc.: 70.31%] [G loss: 1.265277]\n",
      "epoch:11 step:10553 [D loss: 0.608993, acc.: 67.19%] [G loss: 1.006179]\n",
      "epoch:11 step:10554 [D loss: 0.589226, acc.: 67.97%] [G loss: 0.957732]\n",
      "epoch:11 step:10555 [D loss: 0.652516, acc.: 64.84%] [G loss: 1.128355]\n",
      "epoch:11 step:10556 [D loss: 0.536781, acc.: 72.66%] [G loss: 1.113576]\n",
      "epoch:11 step:10557 [D loss: 0.607136, acc.: 67.19%] [G loss: 1.098831]\n",
      "epoch:11 step:10558 [D loss: 0.683148, acc.: 60.94%] [G loss: 1.113691]\n",
      "epoch:11 step:10559 [D loss: 0.577614, acc.: 69.53%] [G loss: 1.233816]\n",
      "epoch:11 step:10560 [D loss: 0.624296, acc.: 62.50%] [G loss: 1.015612]\n",
      "epoch:11 step:10561 [D loss: 0.598641, acc.: 68.75%] [G loss: 1.368593]\n",
      "epoch:11 step:10562 [D loss: 0.613261, acc.: 64.84%] [G loss: 1.363413]\n",
      "epoch:11 step:10563 [D loss: 0.616088, acc.: 68.75%] [G loss: 1.163768]\n",
      "epoch:11 step:10564 [D loss: 0.514970, acc.: 75.00%] [G loss: 1.144764]\n",
      "epoch:11 step:10565 [D loss: 0.616386, acc.: 66.41%] [G loss: 1.010963]\n",
      "epoch:11 step:10566 [D loss: 0.682910, acc.: 57.03%] [G loss: 1.130364]\n",
      "epoch:11 step:10567 [D loss: 0.634093, acc.: 62.50%] [G loss: 1.007582]\n",
      "epoch:11 step:10568 [D loss: 0.556383, acc.: 75.00%] [G loss: 1.265584]\n",
      "epoch:11 step:10569 [D loss: 0.720971, acc.: 54.69%] [G loss: 1.055505]\n",
      "epoch:11 step:10570 [D loss: 0.688427, acc.: 56.25%] [G loss: 1.190718]\n",
      "epoch:11 step:10571 [D loss: 0.638783, acc.: 61.72%] [G loss: 1.006226]\n",
      "epoch:11 step:10572 [D loss: 0.554999, acc.: 73.44%] [G loss: 1.266064]\n",
      "epoch:11 step:10573 [D loss: 0.568005, acc.: 71.09%] [G loss: 0.986573]\n",
      "epoch:11 step:10574 [D loss: 0.604964, acc.: 70.31%] [G loss: 1.293235]\n",
      "epoch:11 step:10575 [D loss: 0.541962, acc.: 75.78%] [G loss: 1.264482]\n",
      "epoch:11 step:10576 [D loss: 0.580329, acc.: 68.75%] [G loss: 1.125462]\n",
      "epoch:11 step:10577 [D loss: 0.603754, acc.: 67.19%] [G loss: 1.062856]\n",
      "epoch:11 step:10578 [D loss: 0.625799, acc.: 57.81%] [G loss: 0.998259]\n",
      "epoch:11 step:10579 [D loss: 0.555668, acc.: 76.56%] [G loss: 0.979620]\n",
      "epoch:11 step:10580 [D loss: 0.703711, acc.: 60.16%] [G loss: 0.967312]\n",
      "epoch:11 step:10581 [D loss: 0.652588, acc.: 62.50%] [G loss: 1.107163]\n",
      "epoch:11 step:10582 [D loss: 0.711551, acc.: 53.91%] [G loss: 1.004892]\n",
      "epoch:11 step:10583 [D loss: 0.712906, acc.: 54.69%] [G loss: 1.127259]\n",
      "epoch:11 step:10584 [D loss: 0.623377, acc.: 66.41%] [G loss: 1.084175]\n",
      "epoch:11 step:10585 [D loss: 0.603164, acc.: 64.06%] [G loss: 1.174507]\n",
      "epoch:11 step:10586 [D loss: 0.607492, acc.: 67.97%] [G loss: 1.215882]\n",
      "epoch:11 step:10587 [D loss: 0.700896, acc.: 58.59%] [G loss: 1.048982]\n",
      "epoch:11 step:10588 [D loss: 0.563097, acc.: 68.75%] [G loss: 0.896708]\n",
      "epoch:11 step:10589 [D loss: 0.655393, acc.: 63.28%] [G loss: 1.155676]\n",
      "epoch:11 step:10590 [D loss: 0.455045, acc.: 82.03%] [G loss: 1.545394]\n",
      "epoch:11 step:10591 [D loss: 0.615292, acc.: 67.97%] [G loss: 1.042857]\n",
      "epoch:11 step:10592 [D loss: 0.566167, acc.: 70.31%] [G loss: 1.205252]\n",
      "epoch:11 step:10593 [D loss: 0.569161, acc.: 67.19%] [G loss: 1.020339]\n",
      "epoch:11 step:10594 [D loss: 0.617235, acc.: 65.62%] [G loss: 1.010938]\n",
      "epoch:11 step:10595 [D loss: 0.675273, acc.: 65.62%] [G loss: 1.083790]\n",
      "epoch:11 step:10596 [D loss: 0.531050, acc.: 73.44%] [G loss: 1.264263]\n",
      "epoch:11 step:10597 [D loss: 0.518784, acc.: 73.44%] [G loss: 1.388854]\n",
      "epoch:11 step:10598 [D loss: 0.691160, acc.: 59.38%] [G loss: 1.052823]\n",
      "epoch:11 step:10599 [D loss: 0.581569, acc.: 67.97%] [G loss: 1.221686]\n",
      "epoch:11 step:10600 [D loss: 0.601884, acc.: 67.97%] [G loss: 1.023554]\n",
      "epoch:11 step:10601 [D loss: 0.652177, acc.: 58.59%] [G loss: 0.868245]\n",
      "epoch:11 step:10602 [D loss: 0.706322, acc.: 56.25%] [G loss: 1.061664]\n",
      "epoch:11 step:10603 [D loss: 0.616216, acc.: 64.84%] [G loss: 0.874159]\n",
      "epoch:11 step:10604 [D loss: 0.665765, acc.: 65.62%] [G loss: 1.082043]\n",
      "epoch:11 step:10605 [D loss: 0.664959, acc.: 60.16%] [G loss: 0.914125]\n",
      "epoch:11 step:10606 [D loss: 0.686224, acc.: 58.59%] [G loss: 1.055169]\n",
      "epoch:11 step:10607 [D loss: 0.549528, acc.: 72.66%] [G loss: 1.175336]\n",
      "epoch:11 step:10608 [D loss: 0.606921, acc.: 66.41%] [G loss: 1.240736]\n",
      "epoch:11 step:10609 [D loss: 0.684492, acc.: 60.16%] [G loss: 1.052392]\n",
      "epoch:11 step:10610 [D loss: 0.674387, acc.: 60.16%] [G loss: 1.093609]\n",
      "epoch:11 step:10611 [D loss: 0.650318, acc.: 60.94%] [G loss: 0.909566]\n",
      "epoch:11 step:10612 [D loss: 0.598756, acc.: 64.84%] [G loss: 1.107521]\n",
      "epoch:11 step:10613 [D loss: 0.561357, acc.: 71.09%] [G loss: 1.108664]\n",
      "epoch:11 step:10614 [D loss: 0.511714, acc.: 78.91%] [G loss: 1.283388]\n",
      "epoch:11 step:10615 [D loss: 0.640500, acc.: 64.84%] [G loss: 0.974837]\n",
      "epoch:11 step:10616 [D loss: 0.550389, acc.: 75.78%] [G loss: 0.933594]\n",
      "epoch:11 step:10617 [D loss: 0.706158, acc.: 59.38%] [G loss: 0.886845]\n",
      "epoch:11 step:10618 [D loss: 0.649355, acc.: 62.50%] [G loss: 1.174328]\n",
      "epoch:11 step:10619 [D loss: 0.689284, acc.: 60.16%] [G loss: 1.050975]\n",
      "epoch:11 step:10620 [D loss: 0.653702, acc.: 59.38%] [G loss: 1.004425]\n",
      "epoch:11 step:10621 [D loss: 0.612752, acc.: 68.75%] [G loss: 1.026705]\n",
      "epoch:11 step:10622 [D loss: 0.566847, acc.: 69.53%] [G loss: 1.195367]\n",
      "epoch:11 step:10623 [D loss: 0.580860, acc.: 68.75%] [G loss: 1.133108]\n",
      "epoch:11 step:10624 [D loss: 0.666239, acc.: 64.84%] [G loss: 1.385554]\n",
      "epoch:11 step:10625 [D loss: 0.583862, acc.: 67.97%] [G loss: 1.211344]\n",
      "epoch:11 step:10626 [D loss: 0.626805, acc.: 61.72%] [G loss: 1.121141]\n",
      "epoch:11 step:10627 [D loss: 0.604596, acc.: 65.62%] [G loss: 1.215993]\n",
      "epoch:11 step:10628 [D loss: 0.635262, acc.: 61.72%] [G loss: 1.090078]\n",
      "epoch:11 step:10629 [D loss: 0.526837, acc.: 75.78%] [G loss: 1.145782]\n",
      "epoch:11 step:10630 [D loss: 0.533892, acc.: 75.00%] [G loss: 1.049162]\n",
      "epoch:11 step:10631 [D loss: 0.574505, acc.: 67.19%] [G loss: 1.249964]\n",
      "epoch:11 step:10632 [D loss: 0.635262, acc.: 66.41%] [G loss: 1.071817]\n",
      "epoch:11 step:10633 [D loss: 0.626475, acc.: 61.72%] [G loss: 1.013929]\n",
      "epoch:11 step:10634 [D loss: 0.521752, acc.: 78.91%] [G loss: 1.372567]\n",
      "epoch:11 step:10635 [D loss: 0.527801, acc.: 75.00%] [G loss: 1.305964]\n",
      "epoch:11 step:10636 [D loss: 0.625338, acc.: 59.38%] [G loss: 0.935962]\n",
      "epoch:11 step:10637 [D loss: 0.651110, acc.: 64.06%] [G loss: 1.118922]\n",
      "epoch:11 step:10638 [D loss: 0.547849, acc.: 67.97%] [G loss: 1.049137]\n",
      "epoch:11 step:10639 [D loss: 0.601531, acc.: 60.16%] [G loss: 1.134798]\n",
      "epoch:11 step:10640 [D loss: 0.615648, acc.: 63.28%] [G loss: 0.936992]\n",
      "epoch:11 step:10641 [D loss: 0.705377, acc.: 56.25%] [G loss: 1.037731]\n",
      "epoch:11 step:10642 [D loss: 0.569141, acc.: 74.22%] [G loss: 1.132555]\n",
      "epoch:11 step:10643 [D loss: 0.565423, acc.: 67.97%] [G loss: 1.097677]\n",
      "epoch:11 step:10644 [D loss: 0.652078, acc.: 63.28%] [G loss: 1.188447]\n",
      "epoch:11 step:10645 [D loss: 0.564319, acc.: 72.66%] [G loss: 1.079980]\n",
      "epoch:11 step:10646 [D loss: 0.604841, acc.: 68.75%] [G loss: 1.245467]\n",
      "epoch:11 step:10647 [D loss: 0.590970, acc.: 66.41%] [G loss: 1.056557]\n",
      "epoch:11 step:10648 [D loss: 0.712694, acc.: 52.34%] [G loss: 1.130687]\n",
      "epoch:11 step:10649 [D loss: 0.745590, acc.: 57.03%] [G loss: 0.910541]\n",
      "epoch:11 step:10650 [D loss: 0.678451, acc.: 57.03%] [G loss: 1.190844]\n",
      "epoch:11 step:10651 [D loss: 0.601575, acc.: 68.75%] [G loss: 1.046932]\n",
      "epoch:11 step:10652 [D loss: 0.627668, acc.: 67.19%] [G loss: 1.103235]\n",
      "epoch:11 step:10653 [D loss: 0.620685, acc.: 62.50%] [G loss: 1.021069]\n",
      "epoch:11 step:10654 [D loss: 0.650891, acc.: 58.59%] [G loss: 1.038251]\n",
      "epoch:11 step:10655 [D loss: 0.602430, acc.: 67.19%] [G loss: 1.158599]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:11 step:10656 [D loss: 0.530900, acc.: 76.56%] [G loss: 1.247445]\n",
      "epoch:11 step:10657 [D loss: 0.602914, acc.: 67.19%] [G loss: 1.075503]\n",
      "epoch:11 step:10658 [D loss: 0.641971, acc.: 61.72%] [G loss: 1.176641]\n",
      "epoch:11 step:10659 [D loss: 0.618892, acc.: 62.50%] [G loss: 1.090813]\n",
      "epoch:11 step:10660 [D loss: 0.596427, acc.: 64.84%] [G loss: 1.087288]\n",
      "epoch:11 step:10661 [D loss: 0.605152, acc.: 68.75%] [G loss: 1.154314]\n",
      "epoch:11 step:10662 [D loss: 0.656253, acc.: 67.97%] [G loss: 1.019260]\n",
      "epoch:11 step:10663 [D loss: 0.525985, acc.: 75.78%] [G loss: 1.255669]\n",
      "epoch:11 step:10664 [D loss: 0.553387, acc.: 67.97%] [G loss: 1.094924]\n",
      "epoch:11 step:10665 [D loss: 0.592025, acc.: 72.66%] [G loss: 1.043622]\n",
      "epoch:11 step:10666 [D loss: 0.565643, acc.: 65.62%] [G loss: 1.206430]\n",
      "epoch:11 step:10667 [D loss: 0.639816, acc.: 64.06%] [G loss: 0.854226]\n",
      "epoch:11 step:10668 [D loss: 0.451190, acc.: 79.69%] [G loss: 1.148014]\n",
      "epoch:11 step:10669 [D loss: 0.565763, acc.: 71.88%] [G loss: 1.187881]\n",
      "epoch:11 step:10670 [D loss: 0.698640, acc.: 60.16%] [G loss: 1.032395]\n",
      "epoch:11 step:10671 [D loss: 0.594284, acc.: 66.41%] [G loss: 1.205191]\n",
      "epoch:11 step:10672 [D loss: 0.590624, acc.: 67.19%] [G loss: 0.993707]\n",
      "epoch:11 step:10673 [D loss: 0.642036, acc.: 68.75%] [G loss: 1.108047]\n",
      "epoch:11 step:10674 [D loss: 0.658423, acc.: 64.84%] [G loss: 1.031294]\n",
      "epoch:11 step:10675 [D loss: 0.552529, acc.: 74.22%] [G loss: 1.244891]\n",
      "epoch:11 step:10676 [D loss: 0.612968, acc.: 62.50%] [G loss: 1.039712]\n",
      "epoch:11 step:10677 [D loss: 0.617992, acc.: 66.41%] [G loss: 0.973605]\n",
      "epoch:11 step:10678 [D loss: 0.622504, acc.: 67.97%] [G loss: 1.135304]\n",
      "epoch:11 step:10679 [D loss: 0.598452, acc.: 68.75%] [G loss: 1.139572]\n",
      "epoch:11 step:10680 [D loss: 0.606159, acc.: 64.84%] [G loss: 1.264419]\n",
      "epoch:11 step:10681 [D loss: 0.603787, acc.: 60.94%] [G loss: 1.329288]\n",
      "epoch:11 step:10682 [D loss: 0.634052, acc.: 61.72%] [G loss: 0.999738]\n",
      "epoch:11 step:10683 [D loss: 0.636814, acc.: 66.41%] [G loss: 1.095092]\n",
      "epoch:11 step:10684 [D loss: 0.588149, acc.: 69.53%] [G loss: 1.095433]\n",
      "epoch:11 step:10685 [D loss: 0.692472, acc.: 57.81%] [G loss: 1.100779]\n",
      "epoch:11 step:10686 [D loss: 0.547698, acc.: 73.44%] [G loss: 1.013110]\n",
      "epoch:11 step:10687 [D loss: 0.515902, acc.: 78.91%] [G loss: 1.375040]\n",
      "epoch:11 step:10688 [D loss: 0.551308, acc.: 70.31%] [G loss: 1.188474]\n",
      "epoch:11 step:10689 [D loss: 0.757475, acc.: 50.00%] [G loss: 1.227751]\n",
      "epoch:11 step:10690 [D loss: 0.629897, acc.: 66.41%] [G loss: 1.158236]\n",
      "epoch:11 step:10691 [D loss: 0.529992, acc.: 75.00%] [G loss: 1.277528]\n",
      "epoch:11 step:10692 [D loss: 0.517859, acc.: 77.34%] [G loss: 1.308522]\n",
      "epoch:11 step:10693 [D loss: 0.767841, acc.: 45.31%] [G loss: 1.024332]\n",
      "epoch:11 step:10694 [D loss: 0.598690, acc.: 65.62%] [G loss: 1.094237]\n",
      "epoch:11 step:10695 [D loss: 0.552251, acc.: 74.22%] [G loss: 1.360465]\n",
      "epoch:11 step:10696 [D loss: 0.637146, acc.: 61.72%] [G loss: 1.293965]\n",
      "epoch:11 step:10697 [D loss: 0.536686, acc.: 71.88%] [G loss: 1.291579]\n",
      "epoch:11 step:10698 [D loss: 0.659707, acc.: 60.16%] [G loss: 1.052865]\n",
      "epoch:11 step:10699 [D loss: 0.563012, acc.: 71.88%] [G loss: 1.301587]\n",
      "epoch:11 step:10700 [D loss: 0.718401, acc.: 54.69%] [G loss: 1.047624]\n",
      "epoch:11 step:10701 [D loss: 0.533029, acc.: 75.78%] [G loss: 1.463594]\n",
      "epoch:11 step:10702 [D loss: 0.662682, acc.: 57.03%] [G loss: 1.235826]\n",
      "epoch:11 step:10703 [D loss: 0.580985, acc.: 69.53%] [G loss: 1.147805]\n",
      "epoch:11 step:10704 [D loss: 0.666804, acc.: 62.50%] [G loss: 1.194044]\n",
      "epoch:11 step:10705 [D loss: 0.600331, acc.: 67.19%] [G loss: 1.078101]\n",
      "epoch:11 step:10706 [D loss: 0.491557, acc.: 78.91%] [G loss: 1.241322]\n",
      "epoch:11 step:10707 [D loss: 0.653108, acc.: 60.16%] [G loss: 1.105797]\n",
      "epoch:11 step:10708 [D loss: 0.564333, acc.: 71.88%] [G loss: 1.156893]\n",
      "epoch:11 step:10709 [D loss: 0.542594, acc.: 70.31%] [G loss: 1.222197]\n",
      "epoch:11 step:10710 [D loss: 0.658919, acc.: 57.03%] [G loss: 1.145746]\n",
      "epoch:11 step:10711 [D loss: 0.568197, acc.: 65.62%] [G loss: 1.264401]\n",
      "epoch:11 step:10712 [D loss: 0.531983, acc.: 75.00%] [G loss: 1.163615]\n",
      "epoch:11 step:10713 [D loss: 0.464294, acc.: 81.25%] [G loss: 1.428222]\n",
      "epoch:11 step:10714 [D loss: 0.656178, acc.: 64.06%] [G loss: 1.332190]\n",
      "epoch:11 step:10715 [D loss: 0.539539, acc.: 74.22%] [G loss: 1.328971]\n",
      "epoch:11 step:10716 [D loss: 0.643173, acc.: 65.62%] [G loss: 0.970265]\n",
      "epoch:11 step:10717 [D loss: 0.665332, acc.: 62.50%] [G loss: 1.186394]\n",
      "epoch:11 step:10718 [D loss: 0.580618, acc.: 69.53%] [G loss: 1.018595]\n",
      "epoch:11 step:10719 [D loss: 0.664072, acc.: 61.72%] [G loss: 1.033616]\n",
      "epoch:11 step:10720 [D loss: 0.674772, acc.: 59.38%] [G loss: 1.120950]\n",
      "epoch:11 step:10721 [D loss: 0.453183, acc.: 81.25%] [G loss: 1.205880]\n",
      "epoch:11 step:10722 [D loss: 0.624735, acc.: 61.72%] [G loss: 0.976779]\n",
      "epoch:11 step:10723 [D loss: 0.586328, acc.: 71.09%] [G loss: 1.078012]\n",
      "epoch:11 step:10724 [D loss: 0.656352, acc.: 62.50%] [G loss: 1.051767]\n",
      "epoch:11 step:10725 [D loss: 0.651981, acc.: 64.06%] [G loss: 1.034478]\n",
      "epoch:11 step:10726 [D loss: 0.580886, acc.: 70.31%] [G loss: 1.242985]\n",
      "epoch:11 step:10727 [D loss: 0.581703, acc.: 66.41%] [G loss: 1.299915]\n",
      "epoch:11 step:10728 [D loss: 0.649212, acc.: 55.47%] [G loss: 1.003020]\n",
      "epoch:11 step:10729 [D loss: 0.669952, acc.: 60.94%] [G loss: 1.263983]\n",
      "epoch:11 step:10730 [D loss: 0.665094, acc.: 57.03%] [G loss: 0.947922]\n",
      "epoch:11 step:10731 [D loss: 0.654492, acc.: 55.47%] [G loss: 1.027442]\n",
      "epoch:11 step:10732 [D loss: 0.696107, acc.: 56.25%] [G loss: 1.145147]\n",
      "epoch:11 step:10733 [D loss: 0.645781, acc.: 64.84%] [G loss: 1.121296]\n",
      "epoch:11 step:10734 [D loss: 0.671206, acc.: 57.03%] [G loss: 1.027447]\n",
      "epoch:11 step:10735 [D loss: 0.630586, acc.: 61.72%] [G loss: 1.077832]\n",
      "epoch:11 step:10736 [D loss: 0.586422, acc.: 70.31%] [G loss: 0.952985]\n",
      "epoch:11 step:10737 [D loss: 0.673295, acc.: 64.06%] [G loss: 1.128607]\n",
      "epoch:11 step:10738 [D loss: 0.601732, acc.: 64.06%] [G loss: 1.039641]\n",
      "epoch:11 step:10739 [D loss: 0.609370, acc.: 69.53%] [G loss: 1.153803]\n",
      "epoch:11 step:10740 [D loss: 0.550810, acc.: 75.00%] [G loss: 1.127271]\n",
      "epoch:11 step:10741 [D loss: 0.721488, acc.: 52.34%] [G loss: 1.042761]\n",
      "epoch:11 step:10742 [D loss: 0.598976, acc.: 65.62%] [G loss: 1.092318]\n",
      "epoch:11 step:10743 [D loss: 0.569921, acc.: 71.88%] [G loss: 1.008660]\n",
      "epoch:11 step:10744 [D loss: 0.683093, acc.: 59.38%] [G loss: 0.992898]\n",
      "epoch:11 step:10745 [D loss: 0.640644, acc.: 67.19%] [G loss: 1.049926]\n",
      "epoch:11 step:10746 [D loss: 0.592577, acc.: 71.09%] [G loss: 1.300718]\n",
      "epoch:11 step:10747 [D loss: 0.598050, acc.: 67.97%] [G loss: 1.174349]\n",
      "epoch:11 step:10748 [D loss: 0.561824, acc.: 75.00%] [G loss: 0.984387]\n",
      "epoch:11 step:10749 [D loss: 0.552498, acc.: 75.00%] [G loss: 1.163881]\n",
      "epoch:11 step:10750 [D loss: 0.637655, acc.: 61.72%] [G loss: 1.094376]\n",
      "epoch:11 step:10751 [D loss: 0.633048, acc.: 62.50%] [G loss: 1.223851]\n",
      "epoch:11 step:10752 [D loss: 0.528855, acc.: 75.78%] [G loss: 1.240043]\n",
      "epoch:11 step:10753 [D loss: 0.709219, acc.: 59.38%] [G loss: 1.113877]\n",
      "epoch:11 step:10754 [D loss: 0.639886, acc.: 58.59%] [G loss: 1.023453]\n",
      "epoch:11 step:10755 [D loss: 0.549159, acc.: 67.97%] [G loss: 1.360119]\n",
      "epoch:11 step:10756 [D loss: 0.575204, acc.: 71.88%] [G loss: 1.042243]\n",
      "epoch:11 step:10757 [D loss: 0.619444, acc.: 64.84%] [G loss: 1.244684]\n",
      "epoch:11 step:10758 [D loss: 0.483896, acc.: 75.00%] [G loss: 1.325495]\n",
      "epoch:11 step:10759 [D loss: 0.588272, acc.: 67.19%] [G loss: 1.105063]\n",
      "epoch:11 step:10760 [D loss: 0.587763, acc.: 69.53%] [G loss: 1.278608]\n",
      "epoch:11 step:10761 [D loss: 0.640646, acc.: 61.72%] [G loss: 1.016518]\n",
      "epoch:11 step:10762 [D loss: 0.529492, acc.: 76.56%] [G loss: 1.164639]\n",
      "epoch:11 step:10763 [D loss: 0.642723, acc.: 65.62%] [G loss: 0.992501]\n",
      "epoch:11 step:10764 [D loss: 0.729465, acc.: 53.12%] [G loss: 0.954505]\n",
      "epoch:11 step:10765 [D loss: 0.515623, acc.: 76.56%] [G loss: 1.274805]\n",
      "epoch:11 step:10766 [D loss: 0.621749, acc.: 65.62%] [G loss: 1.132631]\n",
      "epoch:11 step:10767 [D loss: 0.567588, acc.: 69.53%] [G loss: 1.367826]\n",
      "epoch:11 step:10768 [D loss: 0.621422, acc.: 64.06%] [G loss: 1.211590]\n",
      "epoch:11 step:10769 [D loss: 0.661917, acc.: 64.06%] [G loss: 0.988941]\n",
      "epoch:11 step:10770 [D loss: 0.706383, acc.: 57.03%] [G loss: 1.105631]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:11 step:10771 [D loss: 0.601641, acc.: 67.97%] [G loss: 1.000177]\n",
      "epoch:11 step:10772 [D loss: 0.493695, acc.: 77.34%] [G loss: 1.386719]\n",
      "epoch:11 step:10773 [D loss: 0.633045, acc.: 63.28%] [G loss: 0.985014]\n",
      "epoch:11 step:10774 [D loss: 0.562870, acc.: 72.66%] [G loss: 1.031281]\n",
      "epoch:11 step:10775 [D loss: 0.551346, acc.: 72.66%] [G loss: 1.250083]\n",
      "epoch:11 step:10776 [D loss: 0.581683, acc.: 70.31%] [G loss: 1.135086]\n",
      "epoch:11 step:10777 [D loss: 0.622953, acc.: 67.97%] [G loss: 1.183271]\n",
      "epoch:11 step:10778 [D loss: 0.594694, acc.: 66.41%] [G loss: 1.059682]\n",
      "epoch:11 step:10779 [D loss: 0.628574, acc.: 59.38%] [G loss: 1.306912]\n",
      "epoch:11 step:10780 [D loss: 0.509325, acc.: 77.34%] [G loss: 1.299566]\n",
      "epoch:11 step:10781 [D loss: 0.521113, acc.: 76.56%] [G loss: 1.503183]\n",
      "epoch:11 step:10782 [D loss: 0.606418, acc.: 67.97%] [G loss: 1.104754]\n",
      "epoch:11 step:10783 [D loss: 0.636529, acc.: 63.28%] [G loss: 1.079575]\n",
      "epoch:11 step:10784 [D loss: 0.728854, acc.: 57.81%] [G loss: 1.066161]\n",
      "epoch:11 step:10785 [D loss: 0.578679, acc.: 70.31%] [G loss: 1.357619]\n",
      "epoch:11 step:10786 [D loss: 0.621161, acc.: 65.62%] [G loss: 1.105616]\n",
      "epoch:11 step:10787 [D loss: 0.588305, acc.: 67.19%] [G loss: 1.156848]\n",
      "epoch:11 step:10788 [D loss: 0.731826, acc.: 53.91%] [G loss: 1.071199]\n",
      "epoch:11 step:10789 [D loss: 0.628585, acc.: 64.84%] [G loss: 1.253820]\n",
      "epoch:11 step:10790 [D loss: 0.710275, acc.: 63.28%] [G loss: 1.015435]\n",
      "epoch:11 step:10791 [D loss: 0.626736, acc.: 64.06%] [G loss: 1.070589]\n",
      "epoch:11 step:10792 [D loss: 0.626405, acc.: 65.62%] [G loss: 1.137297]\n",
      "epoch:11 step:10793 [D loss: 0.627239, acc.: 61.72%] [G loss: 1.062631]\n",
      "epoch:11 step:10794 [D loss: 0.552252, acc.: 77.34%] [G loss: 1.265062]\n",
      "epoch:11 step:10795 [D loss: 0.546772, acc.: 76.56%] [G loss: 1.087366]\n",
      "epoch:11 step:10796 [D loss: 0.527412, acc.: 75.78%] [G loss: 1.318581]\n",
      "epoch:11 step:10797 [D loss: 0.562625, acc.: 72.66%] [G loss: 1.250649]\n",
      "epoch:11 step:10798 [D loss: 0.558396, acc.: 76.56%] [G loss: 1.066254]\n",
      "epoch:11 step:10799 [D loss: 0.600116, acc.: 64.06%] [G loss: 1.308173]\n",
      "epoch:11 step:10800 [D loss: 0.559322, acc.: 72.66%] [G loss: 1.068365]\n",
      "epoch:11 step:10801 [D loss: 0.542200, acc.: 71.09%] [G loss: 1.214635]\n",
      "epoch:11 step:10802 [D loss: 0.755971, acc.: 51.56%] [G loss: 1.184727]\n",
      "epoch:11 step:10803 [D loss: 0.518251, acc.: 75.78%] [G loss: 1.427211]\n",
      "epoch:11 step:10804 [D loss: 0.697335, acc.: 60.16%] [G loss: 1.158412]\n",
      "epoch:11 step:10805 [D loss: 0.557555, acc.: 69.53%] [G loss: 1.180942]\n",
      "epoch:11 step:10806 [D loss: 0.644550, acc.: 60.94%] [G loss: 1.035107]\n",
      "epoch:11 step:10807 [D loss: 0.604487, acc.: 67.19%] [G loss: 1.135885]\n",
      "epoch:11 step:10808 [D loss: 0.509507, acc.: 77.34%] [G loss: 1.312136]\n",
      "epoch:11 step:10809 [D loss: 0.480934, acc.: 79.69%] [G loss: 1.061395]\n",
      "epoch:11 step:10810 [D loss: 0.568595, acc.: 74.22%] [G loss: 1.178523]\n",
      "epoch:11 step:10811 [D loss: 0.604823, acc.: 65.62%] [G loss: 1.089795]\n",
      "epoch:11 step:10812 [D loss: 0.510952, acc.: 79.69%] [G loss: 1.154026]\n",
      "epoch:11 step:10813 [D loss: 0.537715, acc.: 70.31%] [G loss: 1.189965]\n",
      "epoch:11 step:10814 [D loss: 0.700867, acc.: 60.94%] [G loss: 1.216701]\n",
      "epoch:11 step:10815 [D loss: 0.629521, acc.: 65.62%] [G loss: 1.103718]\n",
      "epoch:11 step:10816 [D loss: 0.590764, acc.: 65.62%] [G loss: 1.138245]\n",
      "epoch:11 step:10817 [D loss: 0.687238, acc.: 57.03%] [G loss: 1.070480]\n",
      "epoch:11 step:10818 [D loss: 0.632405, acc.: 64.84%] [G loss: 1.161171]\n",
      "epoch:11 step:10819 [D loss: 0.642067, acc.: 63.28%] [G loss: 1.163993]\n",
      "epoch:11 step:10820 [D loss: 0.501731, acc.: 75.78%] [G loss: 1.154984]\n",
      "epoch:11 step:10821 [D loss: 0.626691, acc.: 62.50%] [G loss: 1.344149]\n",
      "epoch:11 step:10822 [D loss: 0.609746, acc.: 66.41%] [G loss: 1.274427]\n",
      "epoch:11 step:10823 [D loss: 0.652301, acc.: 62.50%] [G loss: 1.062504]\n",
      "epoch:11 step:10824 [D loss: 0.683088, acc.: 59.38%] [G loss: 1.169929]\n",
      "epoch:11 step:10825 [D loss: 0.543338, acc.: 72.66%] [G loss: 1.085788]\n",
      "epoch:11 step:10826 [D loss: 0.573758, acc.: 73.44%] [G loss: 1.356080]\n",
      "epoch:11 step:10827 [D loss: 0.597128, acc.: 71.88%] [G loss: 1.086523]\n",
      "epoch:11 step:10828 [D loss: 0.571529, acc.: 66.41%] [G loss: 1.144926]\n",
      "epoch:11 step:10829 [D loss: 0.665245, acc.: 64.06%] [G loss: 1.178714]\n",
      "epoch:11 step:10830 [D loss: 0.569155, acc.: 68.75%] [G loss: 1.073865]\n",
      "epoch:11 step:10831 [D loss: 0.481838, acc.: 78.12%] [G loss: 1.381384]\n",
      "epoch:11 step:10832 [D loss: 0.663532, acc.: 57.81%] [G loss: 1.260348]\n",
      "epoch:11 step:10833 [D loss: 0.687084, acc.: 59.38%] [G loss: 1.026123]\n",
      "epoch:11 step:10834 [D loss: 0.592803, acc.: 70.31%] [G loss: 1.042828]\n",
      "epoch:11 step:10835 [D loss: 0.618447, acc.: 66.41%] [G loss: 1.262135]\n",
      "epoch:11 step:10836 [D loss: 0.542333, acc.: 74.22%] [G loss: 1.336744]\n",
      "epoch:11 step:10837 [D loss: 0.687475, acc.: 58.59%] [G loss: 0.922981]\n",
      "epoch:11 step:10838 [D loss: 0.621330, acc.: 67.97%] [G loss: 0.994326]\n",
      "epoch:11 step:10839 [D loss: 0.610656, acc.: 68.75%] [G loss: 1.163653]\n",
      "epoch:11 step:10840 [D loss: 0.600446, acc.: 66.41%] [G loss: 1.305081]\n",
      "epoch:11 step:10841 [D loss: 0.576570, acc.: 64.06%] [G loss: 1.203931]\n",
      "epoch:11 step:10842 [D loss: 0.655075, acc.: 64.84%] [G loss: 1.060491]\n",
      "epoch:11 step:10843 [D loss: 0.518218, acc.: 75.78%] [G loss: 1.103069]\n",
      "epoch:11 step:10844 [D loss: 0.667843, acc.: 61.72%] [G loss: 1.332694]\n",
      "epoch:11 step:10845 [D loss: 0.630945, acc.: 64.06%] [G loss: 1.092025]\n",
      "epoch:11 step:10846 [D loss: 0.540452, acc.: 71.09%] [G loss: 1.273503]\n",
      "epoch:11 step:10847 [D loss: 0.702436, acc.: 57.81%] [G loss: 1.013144]\n",
      "epoch:11 step:10848 [D loss: 0.618923, acc.: 63.28%] [G loss: 1.270401]\n",
      "epoch:11 step:10849 [D loss: 0.552590, acc.: 73.44%] [G loss: 1.418256]\n",
      "epoch:11 step:10850 [D loss: 0.602432, acc.: 67.19%] [G loss: 1.332158]\n",
      "epoch:11 step:10851 [D loss: 0.654204, acc.: 64.84%] [G loss: 1.096524]\n",
      "epoch:11 step:10852 [D loss: 0.622502, acc.: 64.06%] [G loss: 1.281136]\n",
      "epoch:11 step:10853 [D loss: 0.605734, acc.: 69.53%] [G loss: 1.110973]\n",
      "epoch:11 step:10854 [D loss: 0.749809, acc.: 54.69%] [G loss: 1.273623]\n",
      "epoch:11 step:10855 [D loss: 0.654936, acc.: 63.28%] [G loss: 1.078016]\n",
      "epoch:11 step:10856 [D loss: 0.603118, acc.: 65.62%] [G loss: 1.117151]\n",
      "epoch:11 step:10857 [D loss: 0.573506, acc.: 73.44%] [G loss: 1.166895]\n",
      "epoch:11 step:10858 [D loss: 0.712120, acc.: 57.81%] [G loss: 1.175340]\n",
      "epoch:11 step:10859 [D loss: 0.500895, acc.: 78.91%] [G loss: 1.374672]\n",
      "epoch:11 step:10860 [D loss: 0.710421, acc.: 54.69%] [G loss: 1.282634]\n",
      "epoch:11 step:10861 [D loss: 0.610000, acc.: 67.97%] [G loss: 1.273355]\n",
      "epoch:11 step:10862 [D loss: 0.600730, acc.: 68.75%] [G loss: 1.191790]\n",
      "epoch:11 step:10863 [D loss: 0.624957, acc.: 67.19%] [G loss: 1.240022]\n",
      "epoch:11 step:10864 [D loss: 0.580233, acc.: 67.19%] [G loss: 1.103336]\n",
      "epoch:11 step:10865 [D loss: 0.512799, acc.: 75.78%] [G loss: 1.118596]\n",
      "epoch:11 step:10866 [D loss: 0.595581, acc.: 69.53%] [G loss: 1.086010]\n",
      "epoch:11 step:10867 [D loss: 0.681108, acc.: 60.16%] [G loss: 1.202097]\n",
      "epoch:11 step:10868 [D loss: 0.657814, acc.: 63.28%] [G loss: 0.912431]\n",
      "epoch:11 step:10869 [D loss: 0.605247, acc.: 67.97%] [G loss: 0.987031]\n",
      "epoch:11 step:10870 [D loss: 0.667397, acc.: 60.94%] [G loss: 1.024798]\n",
      "epoch:11 step:10871 [D loss: 0.560950, acc.: 70.31%] [G loss: 1.157466]\n",
      "epoch:11 step:10872 [D loss: 0.598522, acc.: 66.41%] [G loss: 1.195955]\n",
      "epoch:11 step:10873 [D loss: 0.551936, acc.: 73.44%] [G loss: 1.245254]\n",
      "epoch:11 step:10874 [D loss: 0.601345, acc.: 67.97%] [G loss: 1.008806]\n",
      "epoch:11 step:10875 [D loss: 0.576909, acc.: 71.88%] [G loss: 1.311421]\n",
      "epoch:11 step:10876 [D loss: 0.565035, acc.: 71.09%] [G loss: 1.151798]\n",
      "epoch:11 step:10877 [D loss: 0.588561, acc.: 69.53%] [G loss: 1.294580]\n",
      "epoch:11 step:10878 [D loss: 0.576068, acc.: 68.75%] [G loss: 1.269265]\n",
      "epoch:11 step:10879 [D loss: 0.517631, acc.: 75.00%] [G loss: 1.294513]\n",
      "epoch:11 step:10880 [D loss: 0.633503, acc.: 63.28%] [G loss: 1.242005]\n",
      "epoch:11 step:10881 [D loss: 0.636976, acc.: 66.41%] [G loss: 1.071194]\n",
      "epoch:11 step:10882 [D loss: 0.559374, acc.: 72.66%] [G loss: 1.123800]\n",
      "epoch:11 step:10883 [D loss: 0.527947, acc.: 75.78%] [G loss: 1.245959]\n",
      "epoch:11 step:10884 [D loss: 0.552235, acc.: 74.22%] [G loss: 1.159985]\n",
      "epoch:11 step:10885 [D loss: 0.508995, acc.: 79.69%] [G loss: 1.067502]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:11 step:10886 [D loss: 0.609783, acc.: 67.19%] [G loss: 1.007703]\n",
      "epoch:11 step:10887 [D loss: 0.702655, acc.: 53.91%] [G loss: 1.187695]\n",
      "epoch:11 step:10888 [D loss: 0.574695, acc.: 70.31%] [G loss: 1.302277]\n",
      "epoch:11 step:10889 [D loss: 0.579577, acc.: 67.97%] [G loss: 1.088605]\n",
      "epoch:11 step:10890 [D loss: 0.558909, acc.: 73.44%] [G loss: 1.042236]\n",
      "epoch:11 step:10891 [D loss: 0.659897, acc.: 61.72%] [G loss: 1.181985]\n",
      "epoch:11 step:10892 [D loss: 0.597049, acc.: 64.84%] [G loss: 1.182648]\n",
      "epoch:11 step:10893 [D loss: 0.646206, acc.: 63.28%] [G loss: 1.222460]\n",
      "epoch:11 step:10894 [D loss: 0.567586, acc.: 66.41%] [G loss: 1.191032]\n",
      "epoch:11 step:10895 [D loss: 0.639052, acc.: 61.72%] [G loss: 1.011669]\n",
      "epoch:11 step:10896 [D loss: 0.691605, acc.: 53.91%] [G loss: 0.946126]\n",
      "epoch:11 step:10897 [D loss: 0.565543, acc.: 71.88%] [G loss: 1.060940]\n",
      "epoch:11 step:10898 [D loss: 0.499564, acc.: 77.34%] [G loss: 1.367216]\n",
      "epoch:11 step:10899 [D loss: 0.604002, acc.: 67.19%] [G loss: 1.253814]\n",
      "epoch:11 step:10900 [D loss: 0.760946, acc.: 53.91%] [G loss: 1.123119]\n",
      "epoch:11 step:10901 [D loss: 0.549999, acc.: 74.22%] [G loss: 1.126470]\n",
      "epoch:11 step:10902 [D loss: 0.606904, acc.: 69.53%] [G loss: 1.223472]\n",
      "epoch:11 step:10903 [D loss: 0.575403, acc.: 67.19%] [G loss: 1.295060]\n",
      "epoch:11 step:10904 [D loss: 0.658539, acc.: 59.38%] [G loss: 1.168330]\n",
      "epoch:11 step:10905 [D loss: 0.631782, acc.: 64.06%] [G loss: 1.296980]\n",
      "epoch:11 step:10906 [D loss: 0.565802, acc.: 69.53%] [G loss: 1.011389]\n",
      "epoch:11 step:10907 [D loss: 0.570703, acc.: 69.53%] [G loss: 0.940994]\n",
      "epoch:11 step:10908 [D loss: 0.667431, acc.: 62.50%] [G loss: 1.180395]\n",
      "epoch:11 step:10909 [D loss: 0.502846, acc.: 78.12%] [G loss: 1.169359]\n",
      "epoch:11 step:10910 [D loss: 0.651691, acc.: 64.06%] [G loss: 1.190030]\n",
      "epoch:11 step:10911 [D loss: 0.596113, acc.: 64.06%] [G loss: 1.164710]\n",
      "epoch:11 step:10912 [D loss: 0.660385, acc.: 58.59%] [G loss: 1.106271]\n",
      "epoch:11 step:10913 [D loss: 0.617846, acc.: 67.97%] [G loss: 1.047253]\n",
      "epoch:11 step:10914 [D loss: 0.655523, acc.: 62.50%] [G loss: 0.997784]\n",
      "epoch:11 step:10915 [D loss: 0.634687, acc.: 59.38%] [G loss: 1.185042]\n",
      "epoch:11 step:10916 [D loss: 0.676405, acc.: 57.81%] [G loss: 1.009986]\n",
      "epoch:11 step:10917 [D loss: 0.624003, acc.: 65.62%] [G loss: 1.130082]\n",
      "epoch:11 step:10918 [D loss: 0.667356, acc.: 59.38%] [G loss: 1.064611]\n",
      "epoch:11 step:10919 [D loss: 0.594695, acc.: 65.62%] [G loss: 1.196014]\n",
      "epoch:11 step:10920 [D loss: 0.647887, acc.: 60.16%] [G loss: 1.042414]\n",
      "epoch:11 step:10921 [D loss: 0.558442, acc.: 70.31%] [G loss: 1.065463]\n",
      "epoch:11 step:10922 [D loss: 0.629581, acc.: 60.16%] [G loss: 0.991372]\n",
      "epoch:11 step:10923 [D loss: 0.539628, acc.: 74.22%] [G loss: 1.273523]\n",
      "epoch:11 step:10924 [D loss: 0.711457, acc.: 59.38%] [G loss: 1.286952]\n",
      "epoch:11 step:10925 [D loss: 0.658974, acc.: 62.50%] [G loss: 1.421557]\n",
      "epoch:11 step:10926 [D loss: 0.629689, acc.: 64.84%] [G loss: 1.199144]\n",
      "epoch:11 step:10927 [D loss: 0.565234, acc.: 75.00%] [G loss: 1.233667]\n",
      "epoch:11 step:10928 [D loss: 0.601407, acc.: 64.84%] [G loss: 0.963095]\n",
      "epoch:11 step:10929 [D loss: 0.601532, acc.: 65.62%] [G loss: 1.089470]\n",
      "epoch:11 step:10930 [D loss: 0.567438, acc.: 64.84%] [G loss: 1.056226]\n",
      "epoch:11 step:10931 [D loss: 0.578246, acc.: 67.19%] [G loss: 1.097500]\n",
      "epoch:11 step:10932 [D loss: 0.744310, acc.: 57.03%] [G loss: 1.055536]\n",
      "epoch:11 step:10933 [D loss: 0.501998, acc.: 74.22%] [G loss: 1.276957]\n",
      "epoch:11 step:10934 [D loss: 0.580765, acc.: 68.75%] [G loss: 1.173302]\n",
      "epoch:11 step:10935 [D loss: 0.629569, acc.: 66.41%] [G loss: 1.255281]\n",
      "epoch:11 step:10936 [D loss: 0.706404, acc.: 61.72%] [G loss: 1.201051]\n",
      "epoch:11 step:10937 [D loss: 0.661918, acc.: 57.81%] [G loss: 1.215727]\n",
      "epoch:11 step:10938 [D loss: 0.609912, acc.: 66.41%] [G loss: 0.962520]\n",
      "epoch:11 step:10939 [D loss: 0.676085, acc.: 57.81%] [G loss: 1.057969]\n",
      "epoch:11 step:10940 [D loss: 0.678435, acc.: 60.16%] [G loss: 1.226876]\n",
      "epoch:11 step:10941 [D loss: 0.593130, acc.: 65.62%] [G loss: 1.232386]\n",
      "epoch:11 step:10942 [D loss: 0.538131, acc.: 75.78%] [G loss: 1.305581]\n",
      "epoch:11 step:10943 [D loss: 0.627733, acc.: 64.84%] [G loss: 0.985254]\n",
      "epoch:11 step:10944 [D loss: 0.610954, acc.: 65.62%] [G loss: 1.239083]\n",
      "epoch:11 step:10945 [D loss: 0.692264, acc.: 59.38%] [G loss: 1.153284]\n",
      "epoch:11 step:10946 [D loss: 0.555775, acc.: 70.31%] [G loss: 1.047393]\n",
      "epoch:11 step:10947 [D loss: 0.678467, acc.: 64.06%] [G loss: 1.213066]\n",
      "epoch:11 step:10948 [D loss: 0.594731, acc.: 67.97%] [G loss: 1.129687]\n",
      "epoch:11 step:10949 [D loss: 0.672711, acc.: 55.47%] [G loss: 1.014850]\n",
      "epoch:11 step:10950 [D loss: 0.662853, acc.: 59.38%] [G loss: 1.300997]\n",
      "epoch:11 step:10951 [D loss: 0.545878, acc.: 71.88%] [G loss: 0.927964]\n",
      "epoch:11 step:10952 [D loss: 0.615747, acc.: 65.62%] [G loss: 1.177990]\n",
      "epoch:11 step:10953 [D loss: 0.689761, acc.: 58.59%] [G loss: 1.003222]\n",
      "epoch:11 step:10954 [D loss: 0.612558, acc.: 65.62%] [G loss: 0.998297]\n",
      "epoch:11 step:10955 [D loss: 0.613365, acc.: 64.06%] [G loss: 1.012191]\n",
      "epoch:11 step:10956 [D loss: 0.630956, acc.: 62.50%] [G loss: 1.138245]\n",
      "epoch:11 step:10957 [D loss: 0.596910, acc.: 72.66%] [G loss: 1.091321]\n",
      "epoch:11 step:10958 [D loss: 0.631947, acc.: 66.41%] [G loss: 1.058937]\n",
      "epoch:11 step:10959 [D loss: 0.723092, acc.: 58.59%] [G loss: 1.192424]\n",
      "epoch:11 step:10960 [D loss: 0.563279, acc.: 75.00%] [G loss: 1.202066]\n",
      "epoch:11 step:10961 [D loss: 0.577023, acc.: 69.53%] [G loss: 1.294820]\n",
      "epoch:11 step:10962 [D loss: 0.507098, acc.: 80.47%] [G loss: 1.155034]\n",
      "epoch:11 step:10963 [D loss: 0.473626, acc.: 79.69%] [G loss: 1.132437]\n",
      "epoch:11 step:10964 [D loss: 0.648306, acc.: 64.84%] [G loss: 1.268674]\n",
      "epoch:11 step:10965 [D loss: 0.614817, acc.: 69.53%] [G loss: 0.979126]\n",
      "epoch:11 step:10966 [D loss: 0.552318, acc.: 74.22%] [G loss: 1.172267]\n",
      "epoch:11 step:10967 [D loss: 0.643854, acc.: 63.28%] [G loss: 1.118605]\n",
      "epoch:11 step:10968 [D loss: 0.553911, acc.: 70.31%] [G loss: 1.170048]\n",
      "epoch:11 step:10969 [D loss: 0.639184, acc.: 61.72%] [G loss: 0.995773]\n",
      "epoch:11 step:10970 [D loss: 0.558173, acc.: 75.00%] [G loss: 1.252007]\n",
      "epoch:11 step:10971 [D loss: 0.673820, acc.: 57.03%] [G loss: 1.067209]\n",
      "epoch:11 step:10972 [D loss: 0.686857, acc.: 61.72%] [G loss: 1.218283]\n",
      "epoch:11 step:10973 [D loss: 0.520255, acc.: 76.56%] [G loss: 1.124128]\n",
      "epoch:11 step:10974 [D loss: 0.617530, acc.: 67.19%] [G loss: 1.136914]\n",
      "epoch:11 step:10975 [D loss: 0.698653, acc.: 53.91%] [G loss: 1.027811]\n",
      "epoch:11 step:10976 [D loss: 0.571407, acc.: 71.09%] [G loss: 1.141015]\n",
      "epoch:11 step:10977 [D loss: 0.568316, acc.: 70.31%] [G loss: 1.085563]\n",
      "epoch:11 step:10978 [D loss: 0.618490, acc.: 70.31%] [G loss: 1.294429]\n",
      "epoch:11 step:10979 [D loss: 0.629183, acc.: 67.19%] [G loss: 1.086381]\n",
      "epoch:11 step:10980 [D loss: 0.568255, acc.: 70.31%] [G loss: 1.281819]\n",
      "epoch:11 step:10981 [D loss: 0.577446, acc.: 69.53%] [G loss: 1.218689]\n",
      "epoch:11 step:10982 [D loss: 0.728207, acc.: 58.59%] [G loss: 1.021237]\n",
      "epoch:11 step:10983 [D loss: 0.661867, acc.: 59.38%] [G loss: 0.964495]\n",
      "epoch:11 step:10984 [D loss: 0.468132, acc.: 82.03%] [G loss: 1.337738]\n",
      "epoch:11 step:10985 [D loss: 0.624102, acc.: 67.97%] [G loss: 1.264703]\n",
      "epoch:11 step:10986 [D loss: 0.606226, acc.: 68.75%] [G loss: 1.412156]\n",
      "epoch:11 step:10987 [D loss: 0.488040, acc.: 81.25%] [G loss: 1.208612]\n",
      "epoch:11 step:10988 [D loss: 0.609554, acc.: 66.41%] [G loss: 1.129010]\n",
      "epoch:11 step:10989 [D loss: 0.695768, acc.: 50.78%] [G loss: 1.179658]\n",
      "epoch:11 step:10990 [D loss: 0.711103, acc.: 58.59%] [G loss: 1.226145]\n",
      "epoch:11 step:10991 [D loss: 0.518644, acc.: 76.56%] [G loss: 1.409881]\n",
      "epoch:11 step:10992 [D loss: 0.596953, acc.: 64.06%] [G loss: 1.055708]\n",
      "epoch:11 step:10993 [D loss: 0.690543, acc.: 59.38%] [G loss: 1.159989]\n",
      "epoch:11 step:10994 [D loss: 0.575649, acc.: 66.41%] [G loss: 1.197697]\n",
      "epoch:11 step:10995 [D loss: 0.603173, acc.: 67.19%] [G loss: 1.348502]\n",
      "epoch:11 step:10996 [D loss: 0.739937, acc.: 50.00%] [G loss: 1.084601]\n",
      "epoch:11 step:10997 [D loss: 0.736965, acc.: 49.22%] [G loss: 1.048204]\n",
      "epoch:11 step:10998 [D loss: 0.586749, acc.: 71.88%] [G loss: 1.362286]\n",
      "epoch:11 step:10999 [D loss: 0.653785, acc.: 65.62%] [G loss: 1.062213]\n",
      "epoch:11 step:11000 [D loss: 0.641350, acc.: 59.38%] [G loss: 1.121362]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:11 step:11001 [D loss: 0.669895, acc.: 62.50%] [G loss: 1.115890]\n",
      "epoch:11 step:11002 [D loss: 0.543709, acc.: 75.00%] [G loss: 1.147225]\n",
      "epoch:11 step:11003 [D loss: 0.543627, acc.: 69.53%] [G loss: 1.149266]\n",
      "epoch:11 step:11004 [D loss: 0.542698, acc.: 76.56%] [G loss: 1.259205]\n",
      "epoch:11 step:11005 [D loss: 0.594921, acc.: 67.19%] [G loss: 1.028044]\n",
      "epoch:11 step:11006 [D loss: 0.576515, acc.: 70.31%] [G loss: 1.076170]\n",
      "epoch:11 step:11007 [D loss: 0.525763, acc.: 76.56%] [G loss: 1.276025]\n",
      "epoch:11 step:11008 [D loss: 0.518777, acc.: 73.44%] [G loss: 1.160972]\n",
      "epoch:11 step:11009 [D loss: 0.527045, acc.: 74.22%] [G loss: 0.931702]\n",
      "epoch:11 step:11010 [D loss: 0.631855, acc.: 63.28%] [G loss: 1.051067]\n",
      "epoch:11 step:11011 [D loss: 0.556300, acc.: 71.09%] [G loss: 1.288052]\n",
      "epoch:11 step:11012 [D loss: 0.618809, acc.: 65.62%] [G loss: 1.116687]\n",
      "epoch:11 step:11013 [D loss: 0.635420, acc.: 71.88%] [G loss: 0.908587]\n",
      "epoch:11 step:11014 [D loss: 0.501053, acc.: 73.44%] [G loss: 1.065247]\n",
      "epoch:11 step:11015 [D loss: 0.462219, acc.: 81.25%] [G loss: 1.066290]\n",
      "epoch:11 step:11016 [D loss: 0.613794, acc.: 68.75%] [G loss: 1.109643]\n",
      "epoch:11 step:11017 [D loss: 0.541780, acc.: 73.44%] [G loss: 1.055241]\n",
      "epoch:11 step:11018 [D loss: 0.504625, acc.: 80.47%] [G loss: 1.285819]\n",
      "epoch:11 step:11019 [D loss: 0.676545, acc.: 56.25%] [G loss: 1.035437]\n",
      "epoch:11 step:11020 [D loss: 0.614498, acc.: 67.19%] [G loss: 1.227372]\n",
      "epoch:11 step:11021 [D loss: 0.592732, acc.: 63.28%] [G loss: 1.446451]\n",
      "epoch:11 step:11022 [D loss: 0.588659, acc.: 68.75%] [G loss: 1.170703]\n",
      "epoch:11 step:11023 [D loss: 0.509704, acc.: 78.12%] [G loss: 1.128847]\n",
      "epoch:11 step:11024 [D loss: 0.626909, acc.: 63.28%] [G loss: 0.960670]\n",
      "epoch:11 step:11025 [D loss: 0.474722, acc.: 79.69%] [G loss: 1.252186]\n",
      "epoch:11 step:11026 [D loss: 0.595401, acc.: 67.19%] [G loss: 1.165355]\n",
      "epoch:11 step:11027 [D loss: 0.654879, acc.: 63.28%] [G loss: 1.015239]\n",
      "epoch:11 step:11028 [D loss: 0.581902, acc.: 67.19%] [G loss: 0.969375]\n",
      "epoch:11 step:11029 [D loss: 0.614820, acc.: 67.19%] [G loss: 1.110624]\n",
      "epoch:11 step:11030 [D loss: 0.573894, acc.: 71.09%] [G loss: 1.193393]\n",
      "epoch:11 step:11031 [D loss: 0.558301, acc.: 72.66%] [G loss: 1.225800]\n",
      "epoch:11 step:11032 [D loss: 0.676290, acc.: 60.16%] [G loss: 0.994336]\n",
      "epoch:11 step:11033 [D loss: 0.608952, acc.: 66.41%] [G loss: 1.207854]\n",
      "epoch:11 step:11034 [D loss: 0.533089, acc.: 72.66%] [G loss: 1.050761]\n",
      "epoch:11 step:11035 [D loss: 0.765321, acc.: 54.69%] [G loss: 1.009305]\n",
      "epoch:11 step:11036 [D loss: 0.571563, acc.: 68.75%] [G loss: 1.156450]\n",
      "epoch:11 step:11037 [D loss: 0.543590, acc.: 75.00%] [G loss: 1.313243]\n",
      "epoch:11 step:11038 [D loss: 0.721786, acc.: 52.34%] [G loss: 1.153006]\n",
      "epoch:11 step:11039 [D loss: 0.603621, acc.: 62.50%] [G loss: 1.057976]\n",
      "epoch:11 step:11040 [D loss: 0.702402, acc.: 56.25%] [G loss: 1.149112]\n",
      "epoch:11 step:11041 [D loss: 0.533151, acc.: 75.78%] [G loss: 1.186726]\n",
      "epoch:11 step:11042 [D loss: 0.651435, acc.: 56.25%] [G loss: 1.197199]\n",
      "epoch:11 step:11043 [D loss: 0.558196, acc.: 71.09%] [G loss: 1.080377]\n",
      "epoch:11 step:11044 [D loss: 0.635516, acc.: 60.94%] [G loss: 1.078287]\n",
      "epoch:11 step:11045 [D loss: 0.686328, acc.: 56.25%] [G loss: 1.026358]\n",
      "epoch:11 step:11046 [D loss: 0.668611, acc.: 60.16%] [G loss: 0.964120]\n",
      "epoch:11 step:11047 [D loss: 0.642818, acc.: 60.16%] [G loss: 1.400745]\n",
      "epoch:11 step:11048 [D loss: 0.561065, acc.: 71.88%] [G loss: 1.212285]\n",
      "epoch:11 step:11049 [D loss: 0.706775, acc.: 61.72%] [G loss: 0.956390]\n",
      "epoch:11 step:11050 [D loss: 0.538761, acc.: 71.88%] [G loss: 1.223794]\n",
      "epoch:11 step:11051 [D loss: 0.496707, acc.: 84.38%] [G loss: 1.355163]\n",
      "epoch:11 step:11052 [D loss: 0.511800, acc.: 78.12%] [G loss: 1.319034]\n",
      "epoch:11 step:11053 [D loss: 0.568926, acc.: 73.44%] [G loss: 1.046950]\n",
      "epoch:11 step:11054 [D loss: 0.543882, acc.: 73.44%] [G loss: 1.258553]\n",
      "epoch:11 step:11055 [D loss: 0.586413, acc.: 70.31%] [G loss: 1.208742]\n",
      "epoch:11 step:11056 [D loss: 0.570777, acc.: 70.31%] [G loss: 1.366470]\n",
      "epoch:11 step:11057 [D loss: 0.632038, acc.: 64.06%] [G loss: 0.979909]\n",
      "epoch:11 step:11058 [D loss: 0.680974, acc.: 55.47%] [G loss: 1.152892]\n",
      "epoch:11 step:11059 [D loss: 0.752403, acc.: 53.12%] [G loss: 1.151750]\n",
      "epoch:11 step:11060 [D loss: 0.598533, acc.: 65.62%] [G loss: 1.045120]\n",
      "epoch:11 step:11061 [D loss: 0.653612, acc.: 67.19%] [G loss: 1.266278]\n",
      "epoch:11 step:11062 [D loss: 0.558881, acc.: 74.22%] [G loss: 1.261663]\n",
      "epoch:11 step:11063 [D loss: 0.625068, acc.: 63.28%] [G loss: 1.128266]\n",
      "epoch:11 step:11064 [D loss: 0.637550, acc.: 56.25%] [G loss: 1.011035]\n",
      "epoch:11 step:11065 [D loss: 0.599528, acc.: 69.53%] [G loss: 1.260269]\n",
      "epoch:11 step:11066 [D loss: 0.633254, acc.: 61.72%] [G loss: 1.092887]\n",
      "epoch:11 step:11067 [D loss: 0.578099, acc.: 68.75%] [G loss: 1.063129]\n",
      "epoch:11 step:11068 [D loss: 0.628080, acc.: 64.84%] [G loss: 1.229769]\n",
      "epoch:11 step:11069 [D loss: 0.544550, acc.: 76.56%] [G loss: 1.147747]\n",
      "epoch:11 step:11070 [D loss: 0.593944, acc.: 67.19%] [G loss: 1.121444]\n",
      "epoch:11 step:11071 [D loss: 0.573162, acc.: 70.31%] [G loss: 1.099880]\n",
      "epoch:11 step:11072 [D loss: 0.625371, acc.: 63.28%] [G loss: 1.087027]\n",
      "epoch:11 step:11073 [D loss: 0.526114, acc.: 75.78%] [G loss: 1.152257]\n",
      "epoch:11 step:11074 [D loss: 0.649184, acc.: 60.16%] [G loss: 1.138415]\n",
      "epoch:11 step:11075 [D loss: 0.601421, acc.: 67.19%] [G loss: 1.254359]\n",
      "epoch:11 step:11076 [D loss: 0.591871, acc.: 71.09%] [G loss: 1.195221]\n",
      "epoch:11 step:11077 [D loss: 0.603555, acc.: 69.53%] [G loss: 1.061842]\n",
      "epoch:11 step:11078 [D loss: 0.591066, acc.: 71.09%] [G loss: 0.995086]\n",
      "epoch:11 step:11079 [D loss: 0.626147, acc.: 57.81%] [G loss: 1.291386]\n",
      "epoch:11 step:11080 [D loss: 0.665814, acc.: 57.03%] [G loss: 1.202174]\n",
      "epoch:11 step:11081 [D loss: 0.581791, acc.: 67.97%] [G loss: 1.097049]\n",
      "epoch:11 step:11082 [D loss: 0.577354, acc.: 70.31%] [G loss: 1.150764]\n",
      "epoch:11 step:11083 [D loss: 0.503763, acc.: 79.69%] [G loss: 1.169930]\n",
      "epoch:11 step:11084 [D loss: 0.542148, acc.: 73.44%] [G loss: 1.067753]\n",
      "epoch:11 step:11085 [D loss: 0.562351, acc.: 76.56%] [G loss: 1.070347]\n",
      "epoch:11 step:11086 [D loss: 0.595141, acc.: 69.53%] [G loss: 1.120653]\n",
      "epoch:11 step:11087 [D loss: 0.657850, acc.: 59.38%] [G loss: 1.240136]\n",
      "epoch:11 step:11088 [D loss: 0.648213, acc.: 59.38%] [G loss: 0.833600]\n",
      "epoch:11 step:11089 [D loss: 0.509559, acc.: 75.78%] [G loss: 1.289932]\n",
      "epoch:11 step:11090 [D loss: 0.559498, acc.: 74.22%] [G loss: 1.270836]\n",
      "epoch:11 step:11091 [D loss: 0.652920, acc.: 57.03%] [G loss: 1.089464]\n",
      "epoch:11 step:11092 [D loss: 0.625024, acc.: 66.41%] [G loss: 1.253881]\n",
      "epoch:11 step:11093 [D loss: 0.547401, acc.: 71.88%] [G loss: 1.282076]\n",
      "epoch:11 step:11094 [D loss: 0.602335, acc.: 70.31%] [G loss: 0.989112]\n",
      "epoch:11 step:11095 [D loss: 0.558470, acc.: 75.00%] [G loss: 1.284358]\n",
      "epoch:11 step:11096 [D loss: 0.545440, acc.: 76.56%] [G loss: 1.010647]\n",
      "epoch:11 step:11097 [D loss: 0.669262, acc.: 61.72%] [G loss: 1.268523]\n",
      "epoch:11 step:11098 [D loss: 0.625656, acc.: 64.84%] [G loss: 1.176525]\n",
      "epoch:11 step:11099 [D loss: 0.666513, acc.: 57.81%] [G loss: 1.172835]\n",
      "epoch:11 step:11100 [D loss: 0.563373, acc.: 71.09%] [G loss: 1.105911]\n",
      "epoch:11 step:11101 [D loss: 0.583394, acc.: 69.53%] [G loss: 1.055843]\n",
      "epoch:11 step:11102 [D loss: 0.655199, acc.: 62.50%] [G loss: 1.126457]\n",
      "epoch:11 step:11103 [D loss: 0.593084, acc.: 66.41%] [G loss: 0.999932]\n",
      "epoch:11 step:11104 [D loss: 0.678028, acc.: 62.50%] [G loss: 1.237683]\n",
      "epoch:11 step:11105 [D loss: 0.650183, acc.: 61.72%] [G loss: 1.030538]\n",
      "epoch:11 step:11106 [D loss: 0.606781, acc.: 68.75%] [G loss: 1.090070]\n",
      "epoch:11 step:11107 [D loss: 0.583187, acc.: 69.53%] [G loss: 1.360041]\n",
      "epoch:11 step:11108 [D loss: 0.557384, acc.: 71.09%] [G loss: 1.219082]\n",
      "epoch:11 step:11109 [D loss: 0.653165, acc.: 56.25%] [G loss: 1.233243]\n",
      "epoch:11 step:11110 [D loss: 0.525713, acc.: 73.44%] [G loss: 1.201188]\n",
      "epoch:11 step:11111 [D loss: 0.553456, acc.: 65.62%] [G loss: 1.180882]\n",
      "epoch:11 step:11112 [D loss: 0.576051, acc.: 71.88%] [G loss: 1.282437]\n",
      "epoch:11 step:11113 [D loss: 0.512767, acc.: 75.00%] [G loss: 1.168341]\n",
      "epoch:11 step:11114 [D loss: 0.518122, acc.: 75.78%] [G loss: 1.000008]\n",
      "epoch:11 step:11115 [D loss: 0.604411, acc.: 68.75%] [G loss: 1.068857]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:11 step:11116 [D loss: 0.549987, acc.: 71.88%] [G loss: 1.140386]\n",
      "epoch:11 step:11117 [D loss: 0.599146, acc.: 64.84%] [G loss: 1.230104]\n",
      "epoch:11 step:11118 [D loss: 0.551716, acc.: 65.62%] [G loss: 1.051921]\n",
      "epoch:11 step:11119 [D loss: 0.593793, acc.: 64.06%] [G loss: 1.154626]\n",
      "epoch:11 step:11120 [D loss: 0.665317, acc.: 57.03%] [G loss: 0.996512]\n",
      "epoch:11 step:11121 [D loss: 0.612855, acc.: 71.09%] [G loss: 1.030697]\n",
      "epoch:11 step:11122 [D loss: 0.617185, acc.: 66.41%] [G loss: 1.232345]\n",
      "epoch:11 step:11123 [D loss: 0.501432, acc.: 77.34%] [G loss: 1.054355]\n",
      "epoch:11 step:11124 [D loss: 0.709112, acc.: 60.94%] [G loss: 1.138759]\n",
      "epoch:11 step:11125 [D loss: 0.536137, acc.: 75.78%] [G loss: 1.363382]\n",
      "epoch:11 step:11126 [D loss: 0.607213, acc.: 64.06%] [G loss: 1.237154]\n",
      "epoch:11 step:11127 [D loss: 0.584194, acc.: 73.44%] [G loss: 1.148604]\n",
      "epoch:11 step:11128 [D loss: 0.583568, acc.: 61.72%] [G loss: 1.145826]\n",
      "epoch:11 step:11129 [D loss: 0.559400, acc.: 69.53%] [G loss: 1.143202]\n",
      "epoch:11 step:11130 [D loss: 0.650424, acc.: 65.62%] [G loss: 1.286171]\n",
      "epoch:11 step:11131 [D loss: 0.593989, acc.: 67.97%] [G loss: 1.152154]\n",
      "epoch:11 step:11132 [D loss: 0.528277, acc.: 71.09%] [G loss: 1.078490]\n",
      "epoch:11 step:11133 [D loss: 0.550320, acc.: 71.88%] [G loss: 1.103960]\n",
      "epoch:11 step:11134 [D loss: 0.554316, acc.: 71.88%] [G loss: 1.109910]\n",
      "epoch:11 step:11135 [D loss: 0.733253, acc.: 52.34%] [G loss: 0.942312]\n",
      "epoch:11 step:11136 [D loss: 0.629330, acc.: 64.06%] [G loss: 1.030300]\n",
      "epoch:11 step:11137 [D loss: 0.631349, acc.: 64.84%] [G loss: 1.083302]\n",
      "epoch:11 step:11138 [D loss: 0.735171, acc.: 50.78%] [G loss: 1.091139]\n",
      "epoch:11 step:11139 [D loss: 0.631950, acc.: 67.19%] [G loss: 1.020101]\n",
      "epoch:11 step:11140 [D loss: 0.595468, acc.: 69.53%] [G loss: 1.172711]\n",
      "epoch:11 step:11141 [D loss: 0.664220, acc.: 62.50%] [G loss: 1.232148]\n",
      "epoch:11 step:11142 [D loss: 0.648162, acc.: 62.50%] [G loss: 1.151111]\n",
      "epoch:11 step:11143 [D loss: 0.765919, acc.: 46.88%] [G loss: 0.943500]\n",
      "epoch:11 step:11144 [D loss: 0.634289, acc.: 64.84%] [G loss: 1.349894]\n",
      "epoch:11 step:11145 [D loss: 0.703546, acc.: 58.59%] [G loss: 0.988405]\n",
      "epoch:11 step:11146 [D loss: 0.567114, acc.: 74.22%] [G loss: 1.299002]\n",
      "epoch:11 step:11147 [D loss: 0.630962, acc.: 66.41%] [G loss: 1.228060]\n",
      "epoch:11 step:11148 [D loss: 0.563998, acc.: 69.53%] [G loss: 1.191340]\n",
      "epoch:11 step:11149 [D loss: 0.555363, acc.: 73.44%] [G loss: 1.098592]\n",
      "epoch:11 step:11150 [D loss: 0.681413, acc.: 54.69%] [G loss: 1.473889]\n",
      "epoch:11 step:11151 [D loss: 0.812318, acc.: 46.09%] [G loss: 0.802476]\n",
      "epoch:11 step:11152 [D loss: 0.621476, acc.: 65.62%] [G loss: 1.194196]\n",
      "epoch:11 step:11153 [D loss: 0.610118, acc.: 67.19%] [G loss: 1.035392]\n",
      "epoch:11 step:11154 [D loss: 0.538238, acc.: 73.44%] [G loss: 1.339397]\n",
      "epoch:11 step:11155 [D loss: 0.677763, acc.: 57.03%] [G loss: 1.152322]\n",
      "epoch:11 step:11156 [D loss: 0.619479, acc.: 67.19%] [G loss: 1.186616]\n",
      "epoch:11 step:11157 [D loss: 0.491849, acc.: 78.12%] [G loss: 1.135699]\n",
      "epoch:11 step:11158 [D loss: 0.801153, acc.: 45.31%] [G loss: 0.966850]\n",
      "epoch:11 step:11159 [D loss: 0.579224, acc.: 75.00%] [G loss: 1.108965]\n",
      "epoch:11 step:11160 [D loss: 0.649596, acc.: 62.50%] [G loss: 1.104160]\n",
      "epoch:11 step:11161 [D loss: 0.568440, acc.: 69.53%] [G loss: 1.409468]\n",
      "epoch:11 step:11162 [D loss: 0.626211, acc.: 64.84%] [G loss: 1.042865]\n",
      "epoch:11 step:11163 [D loss: 0.562644, acc.: 71.09%] [G loss: 1.166183]\n",
      "epoch:11 step:11164 [D loss: 0.590347, acc.: 67.97%] [G loss: 1.071357]\n",
      "epoch:11 step:11165 [D loss: 0.559037, acc.: 70.31%] [G loss: 1.477666]\n",
      "epoch:11 step:11166 [D loss: 0.632621, acc.: 57.81%] [G loss: 1.134903]\n",
      "epoch:11 step:11167 [D loss: 0.643953, acc.: 64.06%] [G loss: 1.087514]\n",
      "epoch:11 step:11168 [D loss: 0.608971, acc.: 68.75%] [G loss: 0.979893]\n",
      "epoch:11 step:11169 [D loss: 0.543360, acc.: 72.66%] [G loss: 1.263327]\n",
      "epoch:11 step:11170 [D loss: 0.545986, acc.: 74.22%] [G loss: 1.310622]\n",
      "epoch:11 step:11171 [D loss: 0.611850, acc.: 65.62%] [G loss: 1.209462]\n",
      "epoch:11 step:11172 [D loss: 0.668673, acc.: 60.94%] [G loss: 1.124402]\n",
      "epoch:11 step:11173 [D loss: 0.589845, acc.: 69.53%] [G loss: 1.169994]\n",
      "epoch:11 step:11174 [D loss: 0.658327, acc.: 58.59%] [G loss: 1.166092]\n",
      "epoch:11 step:11175 [D loss: 0.582476, acc.: 66.41%] [G loss: 1.255681]\n",
      "epoch:11 step:11176 [D loss: 0.674884, acc.: 59.38%] [G loss: 0.925510]\n",
      "epoch:11 step:11177 [D loss: 0.626561, acc.: 65.62%] [G loss: 1.259724]\n",
      "epoch:11 step:11178 [D loss: 0.612244, acc.: 69.53%] [G loss: 1.098600]\n",
      "epoch:11 step:11179 [D loss: 0.605115, acc.: 67.19%] [G loss: 1.101551]\n",
      "epoch:11 step:11180 [D loss: 0.470816, acc.: 77.34%] [G loss: 1.585709]\n",
      "epoch:11 step:11181 [D loss: 0.544908, acc.: 72.66%] [G loss: 1.150113]\n",
      "epoch:11 step:11182 [D loss: 0.534118, acc.: 75.00%] [G loss: 1.199853]\n",
      "epoch:11 step:11183 [D loss: 0.663150, acc.: 61.72%] [G loss: 0.930238]\n",
      "epoch:11 step:11184 [D loss: 0.660766, acc.: 60.94%] [G loss: 1.195304]\n",
      "epoch:11 step:11185 [D loss: 0.655604, acc.: 62.50%] [G loss: 1.097435]\n",
      "epoch:11 step:11186 [D loss: 0.646883, acc.: 65.62%] [G loss: 1.241941]\n",
      "epoch:11 step:11187 [D loss: 0.589448, acc.: 67.19%] [G loss: 1.130261]\n",
      "epoch:11 step:11188 [D loss: 0.661796, acc.: 59.38%] [G loss: 1.176478]\n",
      "epoch:11 step:11189 [D loss: 0.507869, acc.: 78.91%] [G loss: 1.064486]\n",
      "epoch:11 step:11190 [D loss: 0.586297, acc.: 71.09%] [G loss: 1.199558]\n",
      "epoch:11 step:11191 [D loss: 0.545086, acc.: 71.88%] [G loss: 1.240367]\n",
      "epoch:11 step:11192 [D loss: 0.510903, acc.: 76.56%] [G loss: 1.153251]\n",
      "epoch:11 step:11193 [D loss: 0.565089, acc.: 67.19%] [G loss: 1.003542]\n",
      "epoch:11 step:11194 [D loss: 0.450698, acc.: 82.81%] [G loss: 1.405462]\n",
      "epoch:11 step:11195 [D loss: 0.647687, acc.: 59.38%] [G loss: 1.200805]\n",
      "epoch:11 step:11196 [D loss: 0.648828, acc.: 64.84%] [G loss: 1.263239]\n",
      "epoch:11 step:11197 [D loss: 0.623666, acc.: 63.28%] [G loss: 1.113036]\n",
      "epoch:11 step:11198 [D loss: 0.579874, acc.: 69.53%] [G loss: 1.140509]\n",
      "epoch:11 step:11199 [D loss: 0.574906, acc.: 65.62%] [G loss: 1.100734]\n",
      "epoch:11 step:11200 [D loss: 0.691040, acc.: 59.38%] [G loss: 1.121903]\n",
      "epoch:11 step:11201 [D loss: 0.662402, acc.: 61.72%] [G loss: 1.324220]\n",
      "epoch:11 step:11202 [D loss: 0.557324, acc.: 65.62%] [G loss: 1.206938]\n",
      "epoch:11 step:11203 [D loss: 0.600133, acc.: 66.41%] [G loss: 1.207187]\n",
      "epoch:11 step:11204 [D loss: 0.618811, acc.: 64.06%] [G loss: 1.360314]\n",
      "epoch:11 step:11205 [D loss: 0.484682, acc.: 80.47%] [G loss: 1.355774]\n",
      "epoch:11 step:11206 [D loss: 0.489650, acc.: 78.12%] [G loss: 1.176283]\n",
      "epoch:11 step:11207 [D loss: 0.611600, acc.: 63.28%] [G loss: 1.001040]\n",
      "epoch:11 step:11208 [D loss: 0.683334, acc.: 60.16%] [G loss: 1.292126]\n",
      "epoch:11 step:11209 [D loss: 0.567954, acc.: 71.88%] [G loss: 1.199988]\n",
      "epoch:11 step:11210 [D loss: 0.479911, acc.: 80.47%] [G loss: 1.300832]\n",
      "epoch:11 step:11211 [D loss: 0.595728, acc.: 69.53%] [G loss: 1.202184]\n",
      "epoch:11 step:11212 [D loss: 0.583064, acc.: 71.09%] [G loss: 1.064406]\n",
      "epoch:11 step:11213 [D loss: 0.687260, acc.: 57.03%] [G loss: 0.944485]\n",
      "epoch:11 step:11214 [D loss: 0.554314, acc.: 75.78%] [G loss: 1.213275]\n",
      "epoch:11 step:11215 [D loss: 0.591495, acc.: 63.28%] [G loss: 1.172367]\n",
      "epoch:11 step:11216 [D loss: 0.585595, acc.: 70.31%] [G loss: 1.150363]\n",
      "epoch:11 step:11217 [D loss: 0.563408, acc.: 69.53%] [G loss: 1.168515]\n",
      "epoch:11 step:11218 [D loss: 0.530071, acc.: 74.22%] [G loss: 1.309387]\n",
      "epoch:11 step:11219 [D loss: 0.710274, acc.: 57.03%] [G loss: 1.054366]\n",
      "epoch:11 step:11220 [D loss: 0.566309, acc.: 72.66%] [G loss: 1.132546]\n",
      "epoch:11 step:11221 [D loss: 0.595773, acc.: 69.53%] [G loss: 1.297227]\n",
      "epoch:11 step:11222 [D loss: 0.575617, acc.: 69.53%] [G loss: 1.239101]\n",
      "epoch:11 step:11223 [D loss: 0.518425, acc.: 73.44%] [G loss: 1.127059]\n",
      "epoch:11 step:11224 [D loss: 0.580285, acc.: 72.66%] [G loss: 1.230772]\n",
      "epoch:11 step:11225 [D loss: 0.484327, acc.: 82.81%] [G loss: 1.187619]\n",
      "epoch:11 step:11226 [D loss: 0.545935, acc.: 73.44%] [G loss: 1.064106]\n",
      "epoch:11 step:11227 [D loss: 0.609119, acc.: 63.28%] [G loss: 1.001411]\n",
      "epoch:11 step:11228 [D loss: 0.678114, acc.: 58.59%] [G loss: 1.075335]\n",
      "epoch:11 step:11229 [D loss: 0.557360, acc.: 72.66%] [G loss: 1.267290]\n",
      "epoch:11 step:11230 [D loss: 0.664314, acc.: 60.16%] [G loss: 1.047049]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:11 step:11231 [D loss: 0.588150, acc.: 68.75%] [G loss: 1.218309]\n",
      "epoch:11 step:11232 [D loss: 0.585324, acc.: 69.53%] [G loss: 1.145050]\n",
      "epoch:11 step:11233 [D loss: 0.617761, acc.: 67.97%] [G loss: 1.071159]\n",
      "epoch:11 step:11234 [D loss: 0.617661, acc.: 63.28%] [G loss: 1.242401]\n",
      "epoch:11 step:11235 [D loss: 0.488282, acc.: 78.91%] [G loss: 1.398485]\n",
      "epoch:11 step:11236 [D loss: 0.577574, acc.: 67.97%] [G loss: 1.016417]\n",
      "epoch:11 step:11237 [D loss: 0.561048, acc.: 76.56%] [G loss: 1.416700]\n",
      "epoch:11 step:11238 [D loss: 0.646179, acc.: 60.16%] [G loss: 1.302222]\n",
      "epoch:11 step:11239 [D loss: 0.596088, acc.: 67.19%] [G loss: 1.167191]\n",
      "epoch:11 step:11240 [D loss: 0.626815, acc.: 64.84%] [G loss: 1.089438]\n",
      "epoch:11 step:11241 [D loss: 0.516961, acc.: 75.78%] [G loss: 0.915789]\n",
      "epoch:11 step:11242 [D loss: 0.519390, acc.: 74.22%] [G loss: 1.115183]\n",
      "epoch:11 step:11243 [D loss: 0.523938, acc.: 73.44%] [G loss: 1.095805]\n",
      "epoch:11 step:11244 [D loss: 0.700965, acc.: 52.34%] [G loss: 1.303475]\n",
      "epoch:12 step:11245 [D loss: 0.627241, acc.: 61.72%] [G loss: 1.071429]\n",
      "epoch:12 step:11246 [D loss: 0.624063, acc.: 64.84%] [G loss: 1.205120]\n",
      "epoch:12 step:11247 [D loss: 0.679601, acc.: 62.50%] [G loss: 1.159557]\n",
      "epoch:12 step:11248 [D loss: 0.637303, acc.: 67.97%] [G loss: 1.081827]\n",
      "epoch:12 step:11249 [D loss: 0.697046, acc.: 56.25%] [G loss: 1.112766]\n",
      "epoch:12 step:11250 [D loss: 0.728100, acc.: 57.03%] [G loss: 1.096256]\n",
      "epoch:12 step:11251 [D loss: 0.643928, acc.: 67.19%] [G loss: 1.085249]\n",
      "epoch:12 step:11252 [D loss: 0.502268, acc.: 81.25%] [G loss: 1.177961]\n",
      "epoch:12 step:11253 [D loss: 0.586570, acc.: 65.62%] [G loss: 1.427368]\n",
      "epoch:12 step:11254 [D loss: 0.647185, acc.: 68.75%] [G loss: 1.148409]\n",
      "epoch:12 step:11255 [D loss: 0.630311, acc.: 66.41%] [G loss: 1.114338]\n",
      "epoch:12 step:11256 [D loss: 0.603268, acc.: 69.53%] [G loss: 1.400326]\n",
      "epoch:12 step:11257 [D loss: 0.565660, acc.: 70.31%] [G loss: 1.134177]\n",
      "epoch:12 step:11258 [D loss: 0.610865, acc.: 65.62%] [G loss: 1.249419]\n",
      "epoch:12 step:11259 [D loss: 0.579842, acc.: 68.75%] [G loss: 1.124789]\n",
      "epoch:12 step:11260 [D loss: 0.618970, acc.: 67.19%] [G loss: 0.980557]\n",
      "epoch:12 step:11261 [D loss: 0.589817, acc.: 66.41%] [G loss: 1.314776]\n",
      "epoch:12 step:11262 [D loss: 0.615415, acc.: 63.28%] [G loss: 1.016740]\n",
      "epoch:12 step:11263 [D loss: 0.697704, acc.: 59.38%] [G loss: 1.138289]\n",
      "epoch:12 step:11264 [D loss: 0.573907, acc.: 72.66%] [G loss: 1.237542]\n",
      "epoch:12 step:11265 [D loss: 0.738335, acc.: 56.25%] [G loss: 1.262168]\n",
      "epoch:12 step:11266 [D loss: 0.583391, acc.: 68.75%] [G loss: 1.304201]\n",
      "epoch:12 step:11267 [D loss: 0.599302, acc.: 71.09%] [G loss: 1.095291]\n",
      "epoch:12 step:11268 [D loss: 0.493208, acc.: 78.12%] [G loss: 1.345838]\n",
      "epoch:12 step:11269 [D loss: 0.841678, acc.: 50.00%] [G loss: 1.121121]\n",
      "epoch:12 step:11270 [D loss: 0.659755, acc.: 60.16%] [G loss: 1.028123]\n",
      "epoch:12 step:11271 [D loss: 0.552367, acc.: 71.88%] [G loss: 0.962610]\n",
      "epoch:12 step:11272 [D loss: 0.610491, acc.: 65.62%] [G loss: 1.077386]\n",
      "epoch:12 step:11273 [D loss: 0.621768, acc.: 63.28%] [G loss: 1.419587]\n",
      "epoch:12 step:11274 [D loss: 0.724857, acc.: 56.25%] [G loss: 1.027921]\n",
      "epoch:12 step:11275 [D loss: 0.620150, acc.: 63.28%] [G loss: 1.146132]\n",
      "epoch:12 step:11276 [D loss: 0.584361, acc.: 66.41%] [G loss: 1.163583]\n",
      "epoch:12 step:11277 [D loss: 0.611973, acc.: 66.41%] [G loss: 1.131149]\n",
      "epoch:12 step:11278 [D loss: 0.581397, acc.: 71.09%] [G loss: 0.994295]\n",
      "epoch:12 step:11279 [D loss: 0.630415, acc.: 62.50%] [G loss: 1.233189]\n",
      "epoch:12 step:11280 [D loss: 0.527805, acc.: 77.34%] [G loss: 1.135312]\n",
      "epoch:12 step:11281 [D loss: 0.601126, acc.: 65.62%] [G loss: 1.227437]\n",
      "epoch:12 step:11282 [D loss: 0.682731, acc.: 61.72%] [G loss: 0.917402]\n",
      "epoch:12 step:11283 [D loss: 0.633283, acc.: 65.62%] [G loss: 1.220662]\n",
      "epoch:12 step:11284 [D loss: 0.615351, acc.: 66.41%] [G loss: 1.152989]\n",
      "epoch:12 step:11285 [D loss: 0.551499, acc.: 76.56%] [G loss: 1.051784]\n",
      "epoch:12 step:11286 [D loss: 0.594408, acc.: 68.75%] [G loss: 1.125669]\n",
      "epoch:12 step:11287 [D loss: 0.551812, acc.: 75.00%] [G loss: 1.438870]\n",
      "epoch:12 step:11288 [D loss: 0.651217, acc.: 64.06%] [G loss: 1.005509]\n",
      "epoch:12 step:11289 [D loss: 0.554463, acc.: 70.31%] [G loss: 1.372816]\n",
      "epoch:12 step:11290 [D loss: 0.725530, acc.: 52.34%] [G loss: 1.321320]\n",
      "epoch:12 step:11291 [D loss: 0.461821, acc.: 81.25%] [G loss: 1.203724]\n",
      "epoch:12 step:11292 [D loss: 0.639212, acc.: 64.06%] [G loss: 1.109728]\n",
      "epoch:12 step:11293 [D loss: 0.660260, acc.: 59.38%] [G loss: 1.010983]\n",
      "epoch:12 step:11294 [D loss: 0.558253, acc.: 74.22%] [G loss: 1.392190]\n",
      "epoch:12 step:11295 [D loss: 0.568654, acc.: 71.88%] [G loss: 1.143411]\n",
      "epoch:12 step:11296 [D loss: 0.616920, acc.: 67.97%] [G loss: 0.918828]\n",
      "epoch:12 step:11297 [D loss: 0.460391, acc.: 79.69%] [G loss: 1.252524]\n",
      "epoch:12 step:11298 [D loss: 0.476245, acc.: 82.03%] [G loss: 1.265333]\n",
      "epoch:12 step:11299 [D loss: 0.696411, acc.: 60.16%] [G loss: 1.128604]\n",
      "epoch:12 step:11300 [D loss: 0.594628, acc.: 64.06%] [G loss: 1.086556]\n",
      "epoch:12 step:11301 [D loss: 0.648208, acc.: 67.19%] [G loss: 1.034146]\n",
      "epoch:12 step:11302 [D loss: 0.681370, acc.: 55.47%] [G loss: 1.041011]\n",
      "epoch:12 step:11303 [D loss: 0.496579, acc.: 78.12%] [G loss: 1.200274]\n",
      "epoch:12 step:11304 [D loss: 0.697853, acc.: 55.47%] [G loss: 1.106703]\n",
      "epoch:12 step:11305 [D loss: 0.639427, acc.: 64.06%] [G loss: 1.148758]\n",
      "epoch:12 step:11306 [D loss: 0.653695, acc.: 62.50%] [G loss: 1.047917]\n",
      "epoch:12 step:11307 [D loss: 0.701972, acc.: 53.91%] [G loss: 1.238861]\n",
      "epoch:12 step:11308 [D loss: 0.622086, acc.: 64.84%] [G loss: 0.828954]\n",
      "epoch:12 step:11309 [D loss: 0.542035, acc.: 71.09%] [G loss: 1.154097]\n",
      "epoch:12 step:11310 [D loss: 0.517580, acc.: 76.56%] [G loss: 1.241711]\n",
      "epoch:12 step:11311 [D loss: 0.647154, acc.: 64.84%] [G loss: 0.985735]\n",
      "epoch:12 step:11312 [D loss: 0.571324, acc.: 69.53%] [G loss: 1.162476]\n",
      "epoch:12 step:11313 [D loss: 0.526762, acc.: 78.91%] [G loss: 1.356058]\n",
      "epoch:12 step:11314 [D loss: 0.634946, acc.: 67.97%] [G loss: 0.936566]\n",
      "epoch:12 step:11315 [D loss: 0.539045, acc.: 72.66%] [G loss: 1.332003]\n",
      "epoch:12 step:11316 [D loss: 0.623443, acc.: 67.97%] [G loss: 1.014971]\n",
      "epoch:12 step:11317 [D loss: 0.497843, acc.: 78.91%] [G loss: 1.575857]\n",
      "epoch:12 step:11318 [D loss: 0.517548, acc.: 75.00%] [G loss: 1.352171]\n",
      "epoch:12 step:11319 [D loss: 0.574525, acc.: 70.31%] [G loss: 1.070491]\n",
      "epoch:12 step:11320 [D loss: 0.629025, acc.: 64.84%] [G loss: 1.049447]\n",
      "epoch:12 step:11321 [D loss: 0.543538, acc.: 74.22%] [G loss: 1.235207]\n",
      "epoch:12 step:11322 [D loss: 0.631517, acc.: 60.94%] [G loss: 0.993417]\n",
      "epoch:12 step:11323 [D loss: 0.553876, acc.: 74.22%] [G loss: 1.376259]\n",
      "epoch:12 step:11324 [D loss: 0.574552, acc.: 71.88%] [G loss: 1.398276]\n",
      "epoch:12 step:11325 [D loss: 0.609668, acc.: 66.41%] [G loss: 1.003338]\n",
      "epoch:12 step:11326 [D loss: 0.574589, acc.: 71.88%] [G loss: 1.152910]\n",
      "epoch:12 step:11327 [D loss: 0.681450, acc.: 60.94%] [G loss: 0.966199]\n",
      "epoch:12 step:11328 [D loss: 0.642977, acc.: 68.75%] [G loss: 1.181194]\n",
      "epoch:12 step:11329 [D loss: 0.547072, acc.: 74.22%] [G loss: 1.133832]\n",
      "epoch:12 step:11330 [D loss: 0.579442, acc.: 67.97%] [G loss: 1.230344]\n",
      "epoch:12 step:11331 [D loss: 0.593017, acc.: 69.53%] [G loss: 1.045095]\n",
      "epoch:12 step:11332 [D loss: 0.559948, acc.: 71.88%] [G loss: 1.181556]\n",
      "epoch:12 step:11333 [D loss: 0.618492, acc.: 68.75%] [G loss: 1.007764]\n",
      "epoch:12 step:11334 [D loss: 0.543610, acc.: 74.22%] [G loss: 1.189331]\n",
      "epoch:12 step:11335 [D loss: 0.555559, acc.: 70.31%] [G loss: 1.083838]\n",
      "epoch:12 step:11336 [D loss: 0.506071, acc.: 76.56%] [G loss: 1.167109]\n",
      "epoch:12 step:11337 [D loss: 0.606341, acc.: 66.41%] [G loss: 1.059405]\n",
      "epoch:12 step:11338 [D loss: 0.607576, acc.: 70.31%] [G loss: 1.201534]\n",
      "epoch:12 step:11339 [D loss: 0.651784, acc.: 59.38%] [G loss: 1.265379]\n",
      "epoch:12 step:11340 [D loss: 0.534699, acc.: 75.00%] [G loss: 1.253297]\n",
      "epoch:12 step:11341 [D loss: 0.574812, acc.: 66.41%] [G loss: 1.293060]\n",
      "epoch:12 step:11342 [D loss: 0.624750, acc.: 64.84%] [G loss: 1.281130]\n",
      "epoch:12 step:11343 [D loss: 0.703342, acc.: 57.03%] [G loss: 1.093584]\n",
      "epoch:12 step:11344 [D loss: 0.532718, acc.: 77.34%] [G loss: 1.276474]\n",
      "epoch:12 step:11345 [D loss: 0.647068, acc.: 59.38%] [G loss: 1.126082]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:12 step:11346 [D loss: 0.677373, acc.: 57.81%] [G loss: 1.409232]\n",
      "epoch:12 step:11347 [D loss: 0.586592, acc.: 71.09%] [G loss: 0.960323]\n",
      "epoch:12 step:11348 [D loss: 0.509671, acc.: 76.56%] [G loss: 1.335828]\n",
      "epoch:12 step:11349 [D loss: 0.574942, acc.: 66.41%] [G loss: 1.243000]\n",
      "epoch:12 step:11350 [D loss: 0.611059, acc.: 63.28%] [G loss: 0.940616]\n",
      "epoch:12 step:11351 [D loss: 0.549167, acc.: 71.09%] [G loss: 1.338963]\n",
      "epoch:12 step:11352 [D loss: 0.561836, acc.: 72.66%] [G loss: 1.115468]\n",
      "epoch:12 step:11353 [D loss: 0.603288, acc.: 71.09%] [G loss: 1.075900]\n",
      "epoch:12 step:11354 [D loss: 0.522285, acc.: 78.12%] [G loss: 1.094694]\n",
      "epoch:12 step:11355 [D loss: 0.589507, acc.: 71.09%] [G loss: 1.260442]\n",
      "epoch:12 step:11356 [D loss: 0.617923, acc.: 65.62%] [G loss: 0.975272]\n",
      "epoch:12 step:11357 [D loss: 0.643782, acc.: 63.28%] [G loss: 1.169656]\n",
      "epoch:12 step:11358 [D loss: 0.615885, acc.: 66.41%] [G loss: 1.134405]\n",
      "epoch:12 step:11359 [D loss: 0.659116, acc.: 58.59%] [G loss: 1.142252]\n",
      "epoch:12 step:11360 [D loss: 0.588234, acc.: 68.75%] [G loss: 1.252973]\n",
      "epoch:12 step:11361 [D loss: 0.578066, acc.: 69.53%] [G loss: 1.288780]\n",
      "epoch:12 step:11362 [D loss: 0.592512, acc.: 66.41%] [G loss: 1.113942]\n",
      "epoch:12 step:11363 [D loss: 0.556832, acc.: 72.66%] [G loss: 1.240240]\n",
      "epoch:12 step:11364 [D loss: 0.548873, acc.: 73.44%] [G loss: 0.978730]\n",
      "epoch:12 step:11365 [D loss: 0.627984, acc.: 68.75%] [G loss: 1.139156]\n",
      "epoch:12 step:11366 [D loss: 0.686708, acc.: 54.69%] [G loss: 1.225430]\n",
      "epoch:12 step:11367 [D loss: 0.556772, acc.: 67.97%] [G loss: 1.009859]\n",
      "epoch:12 step:11368 [D loss: 0.626824, acc.: 65.62%] [G loss: 1.068362]\n",
      "epoch:12 step:11369 [D loss: 0.544033, acc.: 75.78%] [G loss: 1.334796]\n",
      "epoch:12 step:11370 [D loss: 0.678804, acc.: 60.16%] [G loss: 1.259533]\n",
      "epoch:12 step:11371 [D loss: 0.642094, acc.: 61.72%] [G loss: 1.034209]\n",
      "epoch:12 step:11372 [D loss: 0.542843, acc.: 78.12%] [G loss: 1.101783]\n",
      "epoch:12 step:11373 [D loss: 0.609567, acc.: 64.06%] [G loss: 1.215100]\n",
      "epoch:12 step:11374 [D loss: 0.556759, acc.: 72.66%] [G loss: 1.256507]\n",
      "epoch:12 step:11375 [D loss: 0.521003, acc.: 72.66%] [G loss: 1.205166]\n",
      "epoch:12 step:11376 [D loss: 0.690215, acc.: 54.69%] [G loss: 1.277108]\n",
      "epoch:12 step:11377 [D loss: 0.535074, acc.: 75.78%] [G loss: 1.227556]\n",
      "epoch:12 step:11378 [D loss: 0.581803, acc.: 71.88%] [G loss: 1.427153]\n",
      "epoch:12 step:11379 [D loss: 0.622721, acc.: 60.16%] [G loss: 1.087482]\n",
      "epoch:12 step:11380 [D loss: 0.721522, acc.: 53.12%] [G loss: 1.049500]\n",
      "epoch:12 step:11381 [D loss: 0.647506, acc.: 63.28%] [G loss: 1.293851]\n",
      "epoch:12 step:11382 [D loss: 0.571697, acc.: 67.97%] [G loss: 1.083191]\n",
      "epoch:12 step:11383 [D loss: 0.653642, acc.: 58.59%] [G loss: 1.049587]\n",
      "epoch:12 step:11384 [D loss: 0.661400, acc.: 64.84%] [G loss: 1.155177]\n",
      "epoch:12 step:11385 [D loss: 0.665640, acc.: 59.38%] [G loss: 1.230837]\n",
      "epoch:12 step:11386 [D loss: 0.646960, acc.: 58.59%] [G loss: 1.125276]\n",
      "epoch:12 step:11387 [D loss: 0.594007, acc.: 66.41%] [G loss: 1.146558]\n",
      "epoch:12 step:11388 [D loss: 0.703353, acc.: 52.34%] [G loss: 1.271888]\n",
      "epoch:12 step:11389 [D loss: 0.513431, acc.: 75.78%] [G loss: 1.250134]\n",
      "epoch:12 step:11390 [D loss: 0.683596, acc.: 57.03%] [G loss: 1.080306]\n",
      "epoch:12 step:11391 [D loss: 0.680777, acc.: 60.16%] [G loss: 1.017918]\n",
      "epoch:12 step:11392 [D loss: 0.585018, acc.: 68.75%] [G loss: 1.166824]\n",
      "epoch:12 step:11393 [D loss: 0.641460, acc.: 64.84%] [G loss: 1.033969]\n",
      "epoch:12 step:11394 [D loss: 0.607787, acc.: 64.84%] [G loss: 1.118122]\n",
      "epoch:12 step:11395 [D loss: 0.645427, acc.: 65.62%] [G loss: 1.269465]\n",
      "epoch:12 step:11396 [D loss: 0.591693, acc.: 69.53%] [G loss: 1.335838]\n",
      "epoch:12 step:11397 [D loss: 0.553346, acc.: 78.91%] [G loss: 1.250081]\n",
      "epoch:12 step:11398 [D loss: 0.597650, acc.: 70.31%] [G loss: 1.118379]\n",
      "epoch:12 step:11399 [D loss: 0.588913, acc.: 64.84%] [G loss: 1.085725]\n",
      "epoch:12 step:11400 [D loss: 0.571390, acc.: 71.09%] [G loss: 1.365016]\n",
      "epoch:12 step:11401 [D loss: 0.699518, acc.: 55.47%] [G loss: 1.063070]\n",
      "epoch:12 step:11402 [D loss: 0.463284, acc.: 79.69%] [G loss: 1.523106]\n",
      "epoch:12 step:11403 [D loss: 0.516151, acc.: 73.44%] [G loss: 1.244443]\n",
      "epoch:12 step:11404 [D loss: 0.611803, acc.: 61.72%] [G loss: 1.220177]\n",
      "epoch:12 step:11405 [D loss: 0.701538, acc.: 53.91%] [G loss: 1.488381]\n",
      "epoch:12 step:11406 [D loss: 0.719418, acc.: 56.25%] [G loss: 1.090088]\n",
      "epoch:12 step:11407 [D loss: 0.605761, acc.: 62.50%] [G loss: 1.098083]\n",
      "epoch:12 step:11408 [D loss: 0.636171, acc.: 65.62%] [G loss: 1.254235]\n",
      "epoch:12 step:11409 [D loss: 0.697658, acc.: 60.16%] [G loss: 0.981752]\n",
      "epoch:12 step:11410 [D loss: 0.731540, acc.: 60.16%] [G loss: 1.203881]\n",
      "epoch:12 step:11411 [D loss: 0.615520, acc.: 67.19%] [G loss: 0.964042]\n",
      "epoch:12 step:11412 [D loss: 0.627386, acc.: 63.28%] [G loss: 1.262822]\n",
      "epoch:12 step:11413 [D loss: 0.506742, acc.: 71.09%] [G loss: 1.198338]\n",
      "epoch:12 step:11414 [D loss: 0.647064, acc.: 68.75%] [G loss: 1.063937]\n",
      "epoch:12 step:11415 [D loss: 0.674358, acc.: 60.94%] [G loss: 1.056066]\n",
      "epoch:12 step:11416 [D loss: 0.527431, acc.: 77.34%] [G loss: 1.069448]\n",
      "epoch:12 step:11417 [D loss: 0.632775, acc.: 66.41%] [G loss: 1.106581]\n",
      "epoch:12 step:11418 [D loss: 0.587399, acc.: 72.66%] [G loss: 1.124567]\n",
      "epoch:12 step:11419 [D loss: 0.537220, acc.: 75.00%] [G loss: 1.020908]\n",
      "epoch:12 step:11420 [D loss: 0.631964, acc.: 60.94%] [G loss: 1.211342]\n",
      "epoch:12 step:11421 [D loss: 0.620300, acc.: 67.19%] [G loss: 1.272991]\n",
      "epoch:12 step:11422 [D loss: 0.554955, acc.: 74.22%] [G loss: 1.215539]\n",
      "epoch:12 step:11423 [D loss: 0.673074, acc.: 59.38%] [G loss: 1.229129]\n",
      "epoch:12 step:11424 [D loss: 0.521910, acc.: 73.44%] [G loss: 1.254452]\n",
      "epoch:12 step:11425 [D loss: 0.595587, acc.: 67.19%] [G loss: 1.473080]\n",
      "epoch:12 step:11426 [D loss: 0.538370, acc.: 72.66%] [G loss: 0.977355]\n",
      "epoch:12 step:11427 [D loss: 0.628135, acc.: 60.16%] [G loss: 1.187753]\n",
      "epoch:12 step:11428 [D loss: 0.639814, acc.: 64.06%] [G loss: 1.026702]\n",
      "epoch:12 step:11429 [D loss: 0.561471, acc.: 71.09%] [G loss: 1.102292]\n",
      "epoch:12 step:11430 [D loss: 0.480287, acc.: 78.12%] [G loss: 1.206310]\n",
      "epoch:12 step:11431 [D loss: 0.539494, acc.: 71.09%] [G loss: 1.217019]\n",
      "epoch:12 step:11432 [D loss: 0.537755, acc.: 75.00%] [G loss: 1.199129]\n",
      "epoch:12 step:11433 [D loss: 0.619232, acc.: 63.28%] [G loss: 1.077907]\n",
      "epoch:12 step:11434 [D loss: 0.627700, acc.: 67.19%] [G loss: 0.996087]\n",
      "epoch:12 step:11435 [D loss: 0.607279, acc.: 66.41%] [G loss: 1.117310]\n",
      "epoch:12 step:11436 [D loss: 0.613755, acc.: 68.75%] [G loss: 1.166648]\n",
      "epoch:12 step:11437 [D loss: 0.677702, acc.: 59.38%] [G loss: 1.234838]\n",
      "epoch:12 step:11438 [D loss: 0.648285, acc.: 60.94%] [G loss: 1.159872]\n",
      "epoch:12 step:11439 [D loss: 0.629095, acc.: 67.19%] [G loss: 1.022478]\n",
      "epoch:12 step:11440 [D loss: 0.571513, acc.: 70.31%] [G loss: 1.052021]\n",
      "epoch:12 step:11441 [D loss: 0.623612, acc.: 70.31%] [G loss: 1.073615]\n",
      "epoch:12 step:11442 [D loss: 0.649086, acc.: 66.41%] [G loss: 1.192104]\n",
      "epoch:12 step:11443 [D loss: 0.519911, acc.: 77.34%] [G loss: 1.217492]\n",
      "epoch:12 step:11444 [D loss: 0.631234, acc.: 60.94%] [G loss: 1.118920]\n",
      "epoch:12 step:11445 [D loss: 0.520666, acc.: 78.12%] [G loss: 1.393936]\n",
      "epoch:12 step:11446 [D loss: 0.612360, acc.: 67.97%] [G loss: 1.179918]\n",
      "epoch:12 step:11447 [D loss: 0.560722, acc.: 75.00%] [G loss: 1.250804]\n",
      "epoch:12 step:11448 [D loss: 0.583817, acc.: 68.75%] [G loss: 1.145317]\n",
      "epoch:12 step:11449 [D loss: 0.603158, acc.: 67.19%] [G loss: 1.506726]\n",
      "epoch:12 step:11450 [D loss: 0.707532, acc.: 58.59%] [G loss: 1.138530]\n",
      "epoch:12 step:11451 [D loss: 0.656183, acc.: 62.50%] [G loss: 1.143760]\n",
      "epoch:12 step:11452 [D loss: 0.563662, acc.: 67.97%] [G loss: 1.152778]\n",
      "epoch:12 step:11453 [D loss: 0.638027, acc.: 62.50%] [G loss: 1.042958]\n",
      "epoch:12 step:11454 [D loss: 0.590995, acc.: 71.09%] [G loss: 1.129842]\n",
      "epoch:12 step:11455 [D loss: 0.493376, acc.: 78.91%] [G loss: 1.116890]\n",
      "epoch:12 step:11456 [D loss: 0.609309, acc.: 64.84%] [G loss: 1.219069]\n",
      "epoch:12 step:11457 [D loss: 0.552714, acc.: 67.97%] [G loss: 1.298154]\n",
      "epoch:12 step:11458 [D loss: 0.672673, acc.: 66.41%] [G loss: 0.965923]\n",
      "epoch:12 step:11459 [D loss: 0.675472, acc.: 63.28%] [G loss: 1.029742]\n",
      "epoch:12 step:11460 [D loss: 0.537096, acc.: 71.09%] [G loss: 1.097827]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:12 step:11461 [D loss: 0.569994, acc.: 72.66%] [G loss: 1.050150]\n",
      "epoch:12 step:11462 [D loss: 0.645939, acc.: 63.28%] [G loss: 1.169886]\n",
      "epoch:12 step:11463 [D loss: 0.629586, acc.: 62.50%] [G loss: 1.069639]\n",
      "epoch:12 step:11464 [D loss: 0.634938, acc.: 63.28%] [G loss: 1.329317]\n",
      "epoch:12 step:11465 [D loss: 0.649702, acc.: 64.84%] [G loss: 1.036620]\n",
      "epoch:12 step:11466 [D loss: 0.555185, acc.: 73.44%] [G loss: 1.045759]\n",
      "epoch:12 step:11467 [D loss: 0.598801, acc.: 67.19%] [G loss: 1.043663]\n",
      "epoch:12 step:11468 [D loss: 0.593154, acc.: 69.53%] [G loss: 1.213554]\n",
      "epoch:12 step:11469 [D loss: 0.617831, acc.: 66.41%] [G loss: 1.122667]\n",
      "epoch:12 step:11470 [D loss: 0.629300, acc.: 62.50%] [G loss: 1.134956]\n",
      "epoch:12 step:11471 [D loss: 0.591589, acc.: 66.41%] [G loss: 1.223166]\n",
      "epoch:12 step:11472 [D loss: 0.637668, acc.: 64.06%] [G loss: 1.200697]\n",
      "epoch:12 step:11473 [D loss: 0.608341, acc.: 67.19%] [G loss: 1.172725]\n",
      "epoch:12 step:11474 [D loss: 0.654019, acc.: 61.72%] [G loss: 1.255924]\n",
      "epoch:12 step:11475 [D loss: 0.593573, acc.: 67.97%] [G loss: 1.078382]\n",
      "epoch:12 step:11476 [D loss: 0.625234, acc.: 63.28%] [G loss: 1.147428]\n",
      "epoch:12 step:11477 [D loss: 0.722203, acc.: 52.34%] [G loss: 1.089473]\n",
      "epoch:12 step:11478 [D loss: 0.743456, acc.: 55.47%] [G loss: 1.102247]\n",
      "epoch:12 step:11479 [D loss: 0.593214, acc.: 71.09%] [G loss: 1.248175]\n",
      "epoch:12 step:11480 [D loss: 0.509325, acc.: 74.22%] [G loss: 1.212938]\n",
      "epoch:12 step:11481 [D loss: 0.685317, acc.: 60.94%] [G loss: 0.943570]\n",
      "epoch:12 step:11482 [D loss: 0.633986, acc.: 64.84%] [G loss: 1.210193]\n",
      "epoch:12 step:11483 [D loss: 0.633465, acc.: 67.97%] [G loss: 1.129711]\n",
      "epoch:12 step:11484 [D loss: 0.691607, acc.: 56.25%] [G loss: 1.263775]\n",
      "epoch:12 step:11485 [D loss: 0.666933, acc.: 62.50%] [G loss: 1.068707]\n",
      "epoch:12 step:11486 [D loss: 0.692686, acc.: 59.38%] [G loss: 1.117716]\n",
      "epoch:12 step:11487 [D loss: 0.587143, acc.: 68.75%] [G loss: 1.229561]\n",
      "epoch:12 step:11488 [D loss: 0.579284, acc.: 68.75%] [G loss: 1.058163]\n",
      "epoch:12 step:11489 [D loss: 0.611253, acc.: 71.88%] [G loss: 1.031877]\n",
      "epoch:12 step:11490 [D loss: 0.552822, acc.: 71.09%] [G loss: 1.129830]\n",
      "epoch:12 step:11491 [D loss: 0.715498, acc.: 53.12%] [G loss: 1.068996]\n",
      "epoch:12 step:11492 [D loss: 0.531290, acc.: 74.22%] [G loss: 1.003248]\n",
      "epoch:12 step:11493 [D loss: 0.546112, acc.: 72.66%] [G loss: 1.259467]\n",
      "epoch:12 step:11494 [D loss: 0.602271, acc.: 67.97%] [G loss: 1.212923]\n",
      "epoch:12 step:11495 [D loss: 0.691196, acc.: 62.50%] [G loss: 1.244852]\n",
      "epoch:12 step:11496 [D loss: 0.531652, acc.: 78.12%] [G loss: 1.167032]\n",
      "epoch:12 step:11497 [D loss: 0.708085, acc.: 61.72%] [G loss: 1.226069]\n",
      "epoch:12 step:11498 [D loss: 0.588784, acc.: 64.84%] [G loss: 1.198760]\n",
      "epoch:12 step:11499 [D loss: 0.637319, acc.: 67.19%] [G loss: 1.390341]\n",
      "epoch:12 step:11500 [D loss: 0.627457, acc.: 68.75%] [G loss: 1.147716]\n",
      "epoch:12 step:11501 [D loss: 0.632556, acc.: 65.62%] [G loss: 1.034626]\n",
      "epoch:12 step:11502 [D loss: 0.568141, acc.: 71.88%] [G loss: 1.328726]\n",
      "epoch:12 step:11503 [D loss: 0.604980, acc.: 66.41%] [G loss: 1.238168]\n",
      "epoch:12 step:11504 [D loss: 0.558464, acc.: 71.88%] [G loss: 0.998118]\n",
      "epoch:12 step:11505 [D loss: 0.674016, acc.: 56.25%] [G loss: 1.267858]\n",
      "epoch:12 step:11506 [D loss: 0.567946, acc.: 71.09%] [G loss: 1.089010]\n",
      "epoch:12 step:11507 [D loss: 0.687089, acc.: 58.59%] [G loss: 1.085350]\n",
      "epoch:12 step:11508 [D loss: 0.510874, acc.: 77.34%] [G loss: 1.445676]\n",
      "epoch:12 step:11509 [D loss: 0.480127, acc.: 82.03%] [G loss: 1.147509]\n",
      "epoch:12 step:11510 [D loss: 0.595569, acc.: 67.97%] [G loss: 1.033498]\n",
      "epoch:12 step:11511 [D loss: 0.563513, acc.: 71.88%] [G loss: 1.263506]\n",
      "epoch:12 step:11512 [D loss: 0.663435, acc.: 64.06%] [G loss: 0.975557]\n",
      "epoch:12 step:11513 [D loss: 0.566676, acc.: 71.88%] [G loss: 1.018052]\n",
      "epoch:12 step:11514 [D loss: 0.651934, acc.: 64.84%] [G loss: 0.979489]\n",
      "epoch:12 step:11515 [D loss: 0.650827, acc.: 54.69%] [G loss: 1.436343]\n",
      "epoch:12 step:11516 [D loss: 0.517417, acc.: 75.00%] [G loss: 1.389897]\n",
      "epoch:12 step:11517 [D loss: 0.631670, acc.: 64.84%] [G loss: 1.348467]\n",
      "epoch:12 step:11518 [D loss: 0.614658, acc.: 68.75%] [G loss: 1.155452]\n",
      "epoch:12 step:11519 [D loss: 0.695542, acc.: 60.16%] [G loss: 0.998538]\n",
      "epoch:12 step:11520 [D loss: 0.733831, acc.: 52.34%] [G loss: 1.218140]\n",
      "epoch:12 step:11521 [D loss: 0.534011, acc.: 71.09%] [G loss: 1.011842]\n",
      "epoch:12 step:11522 [D loss: 0.697093, acc.: 58.59%] [G loss: 0.873104]\n",
      "epoch:12 step:11523 [D loss: 0.559938, acc.: 71.09%] [G loss: 1.386164]\n",
      "epoch:12 step:11524 [D loss: 0.618309, acc.: 69.53%] [G loss: 1.275190]\n",
      "epoch:12 step:11525 [D loss: 0.545137, acc.: 73.44%] [G loss: 1.274503]\n",
      "epoch:12 step:11526 [D loss: 0.641240, acc.: 64.84%] [G loss: 1.129716]\n",
      "epoch:12 step:11527 [D loss: 0.599836, acc.: 66.41%] [G loss: 1.252643]\n",
      "epoch:12 step:11528 [D loss: 0.557652, acc.: 71.88%] [G loss: 1.203103]\n",
      "epoch:12 step:11529 [D loss: 0.624151, acc.: 65.62%] [G loss: 0.966842]\n",
      "epoch:12 step:11530 [D loss: 0.595665, acc.: 67.97%] [G loss: 1.116495]\n",
      "epoch:12 step:11531 [D loss: 0.587554, acc.: 74.22%] [G loss: 1.104216]\n",
      "epoch:12 step:11532 [D loss: 0.595160, acc.: 69.53%] [G loss: 1.251920]\n",
      "epoch:12 step:11533 [D loss: 0.601857, acc.: 67.19%] [G loss: 1.205192]\n",
      "epoch:12 step:11534 [D loss: 0.490869, acc.: 81.25%] [G loss: 1.299129]\n",
      "epoch:12 step:11535 [D loss: 0.544088, acc.: 72.66%] [G loss: 1.205073]\n",
      "epoch:12 step:11536 [D loss: 0.631232, acc.: 70.31%] [G loss: 1.026650]\n",
      "epoch:12 step:11537 [D loss: 0.712501, acc.: 60.94%] [G loss: 0.891028]\n",
      "epoch:12 step:11538 [D loss: 0.642444, acc.: 64.84%] [G loss: 1.189369]\n",
      "epoch:12 step:11539 [D loss: 0.602875, acc.: 67.19%] [G loss: 1.008229]\n",
      "epoch:12 step:11540 [D loss: 0.499905, acc.: 78.12%] [G loss: 1.169177]\n",
      "epoch:12 step:11541 [D loss: 0.605432, acc.: 71.09%] [G loss: 1.012100]\n",
      "epoch:12 step:11542 [D loss: 0.683297, acc.: 64.06%] [G loss: 1.076285]\n",
      "epoch:12 step:11543 [D loss: 0.631571, acc.: 57.81%] [G loss: 1.245491]\n",
      "epoch:12 step:11544 [D loss: 0.590416, acc.: 66.41%] [G loss: 1.269983]\n",
      "epoch:12 step:11545 [D loss: 0.775785, acc.: 52.34%] [G loss: 1.006935]\n",
      "epoch:12 step:11546 [D loss: 0.594796, acc.: 66.41%] [G loss: 1.057149]\n",
      "epoch:12 step:11547 [D loss: 0.588626, acc.: 72.66%] [G loss: 1.345422]\n",
      "epoch:12 step:11548 [D loss: 0.607905, acc.: 67.97%] [G loss: 1.105117]\n",
      "epoch:12 step:11549 [D loss: 0.606161, acc.: 68.75%] [G loss: 1.212059]\n",
      "epoch:12 step:11550 [D loss: 0.481861, acc.: 82.03%] [G loss: 1.319483]\n",
      "epoch:12 step:11551 [D loss: 0.633245, acc.: 68.75%] [G loss: 1.047980]\n",
      "epoch:12 step:11552 [D loss: 0.573141, acc.: 73.44%] [G loss: 1.145384]\n",
      "epoch:12 step:11553 [D loss: 0.501427, acc.: 75.78%] [G loss: 1.304818]\n",
      "epoch:12 step:11554 [D loss: 0.711055, acc.: 60.94%] [G loss: 1.071146]\n",
      "epoch:12 step:11555 [D loss: 0.639526, acc.: 59.38%] [G loss: 1.019465]\n",
      "epoch:12 step:11556 [D loss: 0.684357, acc.: 59.38%] [G loss: 1.185343]\n",
      "epoch:12 step:11557 [D loss: 0.737571, acc.: 52.34%] [G loss: 1.196513]\n",
      "epoch:12 step:11558 [D loss: 0.613791, acc.: 62.50%] [G loss: 1.237917]\n",
      "epoch:12 step:11559 [D loss: 0.640813, acc.: 60.94%] [G loss: 1.015164]\n",
      "epoch:12 step:11560 [D loss: 0.599065, acc.: 72.66%] [G loss: 1.055359]\n",
      "epoch:12 step:11561 [D loss: 0.619152, acc.: 67.19%] [G loss: 1.023715]\n",
      "epoch:12 step:11562 [D loss: 0.755331, acc.: 50.78%] [G loss: 1.020848]\n",
      "epoch:12 step:11563 [D loss: 0.695301, acc.: 57.81%] [G loss: 1.199145]\n",
      "epoch:12 step:11564 [D loss: 0.563516, acc.: 73.44%] [G loss: 1.146448]\n",
      "epoch:12 step:11565 [D loss: 0.673764, acc.: 60.94%] [G loss: 1.247943]\n",
      "epoch:12 step:11566 [D loss: 0.744765, acc.: 57.81%] [G loss: 1.067344]\n",
      "epoch:12 step:11567 [D loss: 0.611122, acc.: 62.50%] [G loss: 1.266295]\n",
      "epoch:12 step:11568 [D loss: 0.496412, acc.: 78.12%] [G loss: 1.173800]\n",
      "epoch:12 step:11569 [D loss: 0.527013, acc.: 74.22%] [G loss: 1.130694]\n",
      "epoch:12 step:11570 [D loss: 0.505647, acc.: 80.47%] [G loss: 1.040110]\n",
      "epoch:12 step:11571 [D loss: 0.546517, acc.: 75.78%] [G loss: 1.250292]\n",
      "epoch:12 step:11572 [D loss: 0.572213, acc.: 67.97%] [G loss: 1.147201]\n",
      "epoch:12 step:11573 [D loss: 0.643592, acc.: 65.62%] [G loss: 1.266356]\n",
      "epoch:12 step:11574 [D loss: 0.583151, acc.: 68.75%] [G loss: 1.255083]\n",
      "epoch:12 step:11575 [D loss: 0.584729, acc.: 70.31%] [G loss: 1.362906]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:12 step:11576 [D loss: 0.667053, acc.: 63.28%] [G loss: 0.962550]\n",
      "epoch:12 step:11577 [D loss: 0.627915, acc.: 67.19%] [G loss: 1.202324]\n",
      "epoch:12 step:11578 [D loss: 0.754355, acc.: 50.00%] [G loss: 1.077500]\n",
      "epoch:12 step:11579 [D loss: 0.671200, acc.: 55.47%] [G loss: 1.126195]\n",
      "epoch:12 step:11580 [D loss: 0.451625, acc.: 83.59%] [G loss: 1.597838]\n",
      "epoch:12 step:11581 [D loss: 0.601400, acc.: 65.62%] [G loss: 1.269780]\n",
      "epoch:12 step:11582 [D loss: 0.583189, acc.: 68.75%] [G loss: 1.254196]\n",
      "epoch:12 step:11583 [D loss: 0.690315, acc.: 57.03%] [G loss: 1.154043]\n",
      "epoch:12 step:11584 [D loss: 0.475256, acc.: 82.03%] [G loss: 1.085634]\n",
      "epoch:12 step:11585 [D loss: 0.571560, acc.: 74.22%] [G loss: 1.091146]\n",
      "epoch:12 step:11586 [D loss: 0.570995, acc.: 72.66%] [G loss: 1.156047]\n",
      "epoch:12 step:11587 [D loss: 0.675551, acc.: 57.81%] [G loss: 0.886928]\n",
      "epoch:12 step:11588 [D loss: 0.503755, acc.: 75.00%] [G loss: 1.274168]\n",
      "epoch:12 step:11589 [D loss: 0.484179, acc.: 79.69%] [G loss: 1.107412]\n",
      "epoch:12 step:11590 [D loss: 0.658630, acc.: 57.03%] [G loss: 1.067744]\n",
      "epoch:12 step:11591 [D loss: 0.716630, acc.: 58.59%] [G loss: 0.988116]\n",
      "epoch:12 step:11592 [D loss: 0.608988, acc.: 64.06%] [G loss: 1.093890]\n",
      "epoch:12 step:11593 [D loss: 0.615563, acc.: 66.41%] [G loss: 1.223780]\n",
      "epoch:12 step:11594 [D loss: 0.766173, acc.: 50.00%] [G loss: 1.214805]\n",
      "epoch:12 step:11595 [D loss: 0.661195, acc.: 62.50%] [G loss: 1.392477]\n",
      "epoch:12 step:11596 [D loss: 0.642272, acc.: 65.62%] [G loss: 1.124247]\n",
      "epoch:12 step:11597 [D loss: 0.624017, acc.: 66.41%] [G loss: 1.122359]\n",
      "epoch:12 step:11598 [D loss: 0.586920, acc.: 67.19%] [G loss: 1.078107]\n",
      "epoch:12 step:11599 [D loss: 0.641801, acc.: 65.62%] [G loss: 1.105689]\n",
      "epoch:12 step:11600 [D loss: 0.586215, acc.: 67.97%] [G loss: 1.039081]\n",
      "epoch:12 step:11601 [D loss: 0.607356, acc.: 69.53%] [G loss: 1.122736]\n",
      "epoch:12 step:11602 [D loss: 0.672157, acc.: 61.72%] [G loss: 1.167240]\n",
      "epoch:12 step:11603 [D loss: 0.734660, acc.: 51.56%] [G loss: 1.247062]\n",
      "epoch:12 step:11604 [D loss: 0.482043, acc.: 81.25%] [G loss: 1.261300]\n",
      "epoch:12 step:11605 [D loss: 0.611436, acc.: 65.62%] [G loss: 1.034007]\n",
      "epoch:12 step:11606 [D loss: 0.634959, acc.: 64.84%] [G loss: 1.361455]\n",
      "epoch:12 step:11607 [D loss: 0.544493, acc.: 69.53%] [G loss: 1.129698]\n",
      "epoch:12 step:11608 [D loss: 0.567709, acc.: 72.66%] [G loss: 1.337958]\n",
      "epoch:12 step:11609 [D loss: 0.522824, acc.: 76.56%] [G loss: 1.379231]\n",
      "epoch:12 step:11610 [D loss: 0.590560, acc.: 64.06%] [G loss: 1.161845]\n",
      "epoch:12 step:11611 [D loss: 0.658695, acc.: 61.72%] [G loss: 1.068481]\n",
      "epoch:12 step:11612 [D loss: 0.598499, acc.: 67.97%] [G loss: 1.122204]\n",
      "epoch:12 step:11613 [D loss: 0.599110, acc.: 67.97%] [G loss: 1.203993]\n",
      "epoch:12 step:11614 [D loss: 0.668915, acc.: 53.12%] [G loss: 0.996737]\n",
      "epoch:12 step:11615 [D loss: 0.698824, acc.: 56.25%] [G loss: 1.017766]\n",
      "epoch:12 step:11616 [D loss: 0.605006, acc.: 66.41%] [G loss: 1.315169]\n",
      "epoch:12 step:11617 [D loss: 0.641646, acc.: 65.62%] [G loss: 1.222526]\n",
      "epoch:12 step:11618 [D loss: 0.619575, acc.: 63.28%] [G loss: 1.221860]\n",
      "epoch:12 step:11619 [D loss: 0.682395, acc.: 57.81%] [G loss: 1.241136]\n",
      "epoch:12 step:11620 [D loss: 0.668836, acc.: 64.06%] [G loss: 0.873762]\n",
      "epoch:12 step:11621 [D loss: 0.571103, acc.: 70.31%] [G loss: 1.217489]\n",
      "epoch:12 step:11622 [D loss: 0.593852, acc.: 65.62%] [G loss: 1.200930]\n",
      "epoch:12 step:11623 [D loss: 0.524766, acc.: 72.66%] [G loss: 1.371079]\n",
      "epoch:12 step:11624 [D loss: 0.655289, acc.: 65.62%] [G loss: 1.103117]\n",
      "epoch:12 step:11625 [D loss: 0.637383, acc.: 64.06%] [G loss: 1.201995]\n",
      "epoch:12 step:11626 [D loss: 0.474047, acc.: 78.12%] [G loss: 1.319535]\n",
      "epoch:12 step:11627 [D loss: 0.554496, acc.: 70.31%] [G loss: 1.112953]\n",
      "epoch:12 step:11628 [D loss: 0.576543, acc.: 71.09%] [G loss: 0.963578]\n",
      "epoch:12 step:11629 [D loss: 0.509891, acc.: 79.69%] [G loss: 1.355312]\n",
      "epoch:12 step:11630 [D loss: 0.684907, acc.: 57.03%] [G loss: 1.052734]\n",
      "epoch:12 step:11631 [D loss: 0.535738, acc.: 80.47%] [G loss: 1.111130]\n",
      "epoch:12 step:11632 [D loss: 0.502630, acc.: 75.78%] [G loss: 1.100093]\n",
      "epoch:12 step:11633 [D loss: 0.622891, acc.: 60.16%] [G loss: 1.080431]\n",
      "epoch:12 step:11634 [D loss: 0.708511, acc.: 58.59%] [G loss: 1.073514]\n",
      "epoch:12 step:11635 [D loss: 0.604309, acc.: 71.09%] [G loss: 1.043257]\n",
      "epoch:12 step:11636 [D loss: 0.562116, acc.: 75.78%] [G loss: 1.098020]\n",
      "epoch:12 step:11637 [D loss: 0.761501, acc.: 50.78%] [G loss: 0.768741]\n",
      "epoch:12 step:11638 [D loss: 0.591476, acc.: 70.31%] [G loss: 1.237890]\n",
      "epoch:12 step:11639 [D loss: 0.548588, acc.: 71.88%] [G loss: 1.341991]\n",
      "epoch:12 step:11640 [D loss: 0.605404, acc.: 68.75%] [G loss: 1.239341]\n",
      "epoch:12 step:11641 [D loss: 0.650922, acc.: 63.28%] [G loss: 1.081535]\n",
      "epoch:12 step:11642 [D loss: 0.603867, acc.: 64.06%] [G loss: 1.098652]\n",
      "epoch:12 step:11643 [D loss: 0.597028, acc.: 64.84%] [G loss: 1.022717]\n",
      "epoch:12 step:11644 [D loss: 0.618359, acc.: 66.41%] [G loss: 1.029070]\n",
      "epoch:12 step:11645 [D loss: 0.564439, acc.: 68.75%] [G loss: 1.123397]\n",
      "epoch:12 step:11646 [D loss: 0.513437, acc.: 76.56%] [G loss: 1.171651]\n",
      "epoch:12 step:11647 [D loss: 0.546174, acc.: 71.09%] [G loss: 1.349880]\n",
      "epoch:12 step:11648 [D loss: 0.670655, acc.: 64.84%] [G loss: 0.917926]\n",
      "epoch:12 step:11649 [D loss: 0.583465, acc.: 70.31%] [G loss: 1.235749]\n",
      "epoch:12 step:11650 [D loss: 0.566896, acc.: 77.34%] [G loss: 0.987641]\n",
      "epoch:12 step:11651 [D loss: 0.772407, acc.: 57.03%] [G loss: 1.094657]\n",
      "epoch:12 step:11652 [D loss: 0.601247, acc.: 64.84%] [G loss: 1.094238]\n",
      "epoch:12 step:11653 [D loss: 0.591622, acc.: 73.44%] [G loss: 1.171897]\n",
      "epoch:12 step:11654 [D loss: 0.589686, acc.: 65.62%] [G loss: 1.239413]\n",
      "epoch:12 step:11655 [D loss: 0.586447, acc.: 67.19%] [G loss: 1.027078]\n",
      "epoch:12 step:11656 [D loss: 0.604689, acc.: 70.31%] [G loss: 1.078070]\n",
      "epoch:12 step:11657 [D loss: 0.576527, acc.: 71.09%] [G loss: 0.897119]\n",
      "epoch:12 step:11658 [D loss: 0.589845, acc.: 70.31%] [G loss: 1.270383]\n",
      "epoch:12 step:11659 [D loss: 0.620350, acc.: 64.06%] [G loss: 0.973171]\n",
      "epoch:12 step:11660 [D loss: 0.581016, acc.: 67.19%] [G loss: 1.111196]\n",
      "epoch:12 step:11661 [D loss: 0.549369, acc.: 71.88%] [G loss: 1.112747]\n",
      "epoch:12 step:11662 [D loss: 0.564292, acc.: 70.31%] [G loss: 1.102368]\n",
      "epoch:12 step:11663 [D loss: 0.521602, acc.: 78.12%] [G loss: 1.087373]\n",
      "epoch:12 step:11664 [D loss: 0.534146, acc.: 73.44%] [G loss: 1.065450]\n",
      "epoch:12 step:11665 [D loss: 0.632898, acc.: 67.97%] [G loss: 1.007440]\n",
      "epoch:12 step:11666 [D loss: 0.565293, acc.: 72.66%] [G loss: 0.972465]\n",
      "epoch:12 step:11667 [D loss: 0.718776, acc.: 53.91%] [G loss: 1.100165]\n",
      "epoch:12 step:11668 [D loss: 0.486806, acc.: 77.34%] [G loss: 1.096353]\n",
      "epoch:12 step:11669 [D loss: 0.762114, acc.: 51.56%] [G loss: 1.079118]\n",
      "epoch:12 step:11670 [D loss: 0.573305, acc.: 70.31%] [G loss: 0.976289]\n",
      "epoch:12 step:11671 [D loss: 0.722449, acc.: 50.78%] [G loss: 1.056048]\n",
      "epoch:12 step:11672 [D loss: 0.648679, acc.: 62.50%] [G loss: 1.215408]\n",
      "epoch:12 step:11673 [D loss: 0.551378, acc.: 72.66%] [G loss: 1.131341]\n",
      "epoch:12 step:11674 [D loss: 0.647042, acc.: 67.19%] [G loss: 1.088818]\n",
      "epoch:12 step:11675 [D loss: 0.572132, acc.: 71.88%] [G loss: 1.200250]\n",
      "epoch:12 step:11676 [D loss: 0.637535, acc.: 71.09%] [G loss: 1.320127]\n",
      "epoch:12 step:11677 [D loss: 0.548143, acc.: 71.09%] [G loss: 1.318058]\n",
      "epoch:12 step:11678 [D loss: 0.571080, acc.: 69.53%] [G loss: 1.235797]\n",
      "epoch:12 step:11679 [D loss: 0.505692, acc.: 75.00%] [G loss: 1.126292]\n",
      "epoch:12 step:11680 [D loss: 0.535327, acc.: 76.56%] [G loss: 1.123211]\n",
      "epoch:12 step:11681 [D loss: 0.695542, acc.: 57.81%] [G loss: 1.008405]\n",
      "epoch:12 step:11682 [D loss: 0.576163, acc.: 68.75%] [G loss: 0.992834]\n",
      "epoch:12 step:11683 [D loss: 0.522859, acc.: 75.00%] [G loss: 1.411296]\n",
      "epoch:12 step:11684 [D loss: 0.578910, acc.: 71.88%] [G loss: 1.336745]\n",
      "epoch:12 step:11685 [D loss: 0.587292, acc.: 68.75%] [G loss: 1.209258]\n",
      "epoch:12 step:11686 [D loss: 0.614458, acc.: 67.19%] [G loss: 1.201755]\n",
      "epoch:12 step:11687 [D loss: 0.592155, acc.: 66.41%] [G loss: 1.204701]\n",
      "epoch:12 step:11688 [D loss: 0.421048, acc.: 85.94%] [G loss: 1.307556]\n",
      "epoch:12 step:11689 [D loss: 0.581118, acc.: 69.53%] [G loss: 1.155311]\n",
      "epoch:12 step:11690 [D loss: 0.603179, acc.: 66.41%] [G loss: 1.172257]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:12 step:11691 [D loss: 0.568009, acc.: 74.22%] [G loss: 1.139779]\n",
      "epoch:12 step:11692 [D loss: 0.632176, acc.: 60.94%] [G loss: 0.963278]\n",
      "epoch:12 step:11693 [D loss: 0.450146, acc.: 83.59%] [G loss: 1.282496]\n",
      "epoch:12 step:11694 [D loss: 0.639575, acc.: 64.84%] [G loss: 1.211604]\n",
      "epoch:12 step:11695 [D loss: 0.563732, acc.: 71.09%] [G loss: 1.312735]\n",
      "epoch:12 step:11696 [D loss: 0.686971, acc.: 56.25%] [G loss: 1.264006]\n",
      "epoch:12 step:11697 [D loss: 0.585787, acc.: 65.62%] [G loss: 1.175389]\n",
      "epoch:12 step:11698 [D loss: 0.532756, acc.: 74.22%] [G loss: 1.124726]\n",
      "epoch:12 step:11699 [D loss: 0.641925, acc.: 64.06%] [G loss: 1.276844]\n",
      "epoch:12 step:11700 [D loss: 0.624110, acc.: 64.06%] [G loss: 1.125814]\n",
      "epoch:12 step:11701 [D loss: 0.539839, acc.: 74.22%] [G loss: 1.136893]\n",
      "epoch:12 step:11702 [D loss: 0.532613, acc.: 71.88%] [G loss: 1.275755]\n",
      "epoch:12 step:11703 [D loss: 0.550642, acc.: 73.44%] [G loss: 1.093765]\n",
      "epoch:12 step:11704 [D loss: 0.710337, acc.: 53.91%] [G loss: 1.010011]\n",
      "epoch:12 step:11705 [D loss: 0.651955, acc.: 64.84%] [G loss: 1.256194]\n",
      "epoch:12 step:11706 [D loss: 0.625899, acc.: 64.06%] [G loss: 1.144528]\n",
      "epoch:12 step:11707 [D loss: 0.653971, acc.: 60.94%] [G loss: 1.084472]\n",
      "epoch:12 step:11708 [D loss: 0.575222, acc.: 69.53%] [G loss: 0.983809]\n",
      "epoch:12 step:11709 [D loss: 0.566092, acc.: 71.88%] [G loss: 1.033542]\n",
      "epoch:12 step:11710 [D loss: 0.611024, acc.: 68.75%] [G loss: 1.163548]\n",
      "epoch:12 step:11711 [D loss: 0.493587, acc.: 82.03%] [G loss: 1.224298]\n",
      "epoch:12 step:11712 [D loss: 0.536674, acc.: 75.00%] [G loss: 1.268777]\n",
      "epoch:12 step:11713 [D loss: 0.572932, acc.: 67.97%] [G loss: 1.034471]\n",
      "epoch:12 step:11714 [D loss: 0.601572, acc.: 64.06%] [G loss: 1.277718]\n",
      "epoch:12 step:11715 [D loss: 0.472774, acc.: 82.03%] [G loss: 1.222555]\n",
      "epoch:12 step:11716 [D loss: 0.614552, acc.: 66.41%] [G loss: 1.340611]\n",
      "epoch:12 step:11717 [D loss: 0.569845, acc.: 73.44%] [G loss: 1.163345]\n",
      "epoch:12 step:11718 [D loss: 0.556865, acc.: 74.22%] [G loss: 1.152370]\n",
      "epoch:12 step:11719 [D loss: 0.576724, acc.: 70.31%] [G loss: 1.213941]\n",
      "epoch:12 step:11720 [D loss: 0.582971, acc.: 64.84%] [G loss: 1.224474]\n",
      "epoch:12 step:11721 [D loss: 0.760675, acc.: 55.47%] [G loss: 1.156571]\n",
      "epoch:12 step:11722 [D loss: 0.624718, acc.: 65.62%] [G loss: 1.250818]\n",
      "epoch:12 step:11723 [D loss: 0.701216, acc.: 56.25%] [G loss: 1.202397]\n",
      "epoch:12 step:11724 [D loss: 0.542654, acc.: 74.22%] [G loss: 1.327530]\n",
      "epoch:12 step:11725 [D loss: 0.645302, acc.: 62.50%] [G loss: 1.129208]\n",
      "epoch:12 step:11726 [D loss: 0.576517, acc.: 67.97%] [G loss: 0.994839]\n",
      "epoch:12 step:11727 [D loss: 0.657224, acc.: 63.28%] [G loss: 0.987034]\n",
      "epoch:12 step:11728 [D loss: 0.601029, acc.: 65.62%] [G loss: 1.287656]\n",
      "epoch:12 step:11729 [D loss: 0.604608, acc.: 71.09%] [G loss: 0.898899]\n",
      "epoch:12 step:11730 [D loss: 0.555903, acc.: 72.66%] [G loss: 1.253303]\n",
      "epoch:12 step:11731 [D loss: 0.550675, acc.: 68.75%] [G loss: 1.053018]\n",
      "epoch:12 step:11732 [D loss: 0.578699, acc.: 71.09%] [G loss: 1.122368]\n",
      "epoch:12 step:11733 [D loss: 0.562271, acc.: 73.44%] [G loss: 1.232723]\n",
      "epoch:12 step:11734 [D loss: 0.626061, acc.: 64.84%] [G loss: 1.239977]\n",
      "epoch:12 step:11735 [D loss: 0.552934, acc.: 72.66%] [G loss: 0.988348]\n",
      "epoch:12 step:11736 [D loss: 0.617850, acc.: 62.50%] [G loss: 1.146677]\n",
      "epoch:12 step:11737 [D loss: 0.691042, acc.: 60.94%] [G loss: 1.166411]\n",
      "epoch:12 step:11738 [D loss: 0.617953, acc.: 60.16%] [G loss: 1.192642]\n",
      "epoch:12 step:11739 [D loss: 0.631205, acc.: 64.84%] [G loss: 1.089085]\n",
      "epoch:12 step:11740 [D loss: 0.590108, acc.: 67.97%] [G loss: 0.972280]\n",
      "epoch:12 step:11741 [D loss: 0.759104, acc.: 51.56%] [G loss: 1.001382]\n",
      "epoch:12 step:11742 [D loss: 0.581975, acc.: 66.41%] [G loss: 1.017258]\n",
      "epoch:12 step:11743 [D loss: 0.611847, acc.: 62.50%] [G loss: 1.159131]\n",
      "epoch:12 step:11744 [D loss: 0.603267, acc.: 68.75%] [G loss: 1.161695]\n",
      "epoch:12 step:11745 [D loss: 0.614406, acc.: 63.28%] [G loss: 1.219993]\n",
      "epoch:12 step:11746 [D loss: 0.572265, acc.: 73.44%] [G loss: 1.034439]\n",
      "epoch:12 step:11747 [D loss: 0.526780, acc.: 75.00%] [G loss: 1.151965]\n",
      "epoch:12 step:11748 [D loss: 0.543789, acc.: 78.12%] [G loss: 1.075845]\n",
      "epoch:12 step:11749 [D loss: 0.609704, acc.: 60.16%] [G loss: 1.124119]\n",
      "epoch:12 step:11750 [D loss: 0.563158, acc.: 68.75%] [G loss: 1.216984]\n",
      "epoch:12 step:11751 [D loss: 0.637711, acc.: 61.72%] [G loss: 1.311940]\n",
      "epoch:12 step:11752 [D loss: 0.610390, acc.: 67.19%] [G loss: 1.107481]\n",
      "epoch:12 step:11753 [D loss: 0.505157, acc.: 76.56%] [G loss: 1.395034]\n",
      "epoch:12 step:11754 [D loss: 0.643713, acc.: 59.38%] [G loss: 1.106038]\n",
      "epoch:12 step:11755 [D loss: 0.571186, acc.: 72.66%] [G loss: 0.970258]\n",
      "epoch:12 step:11756 [D loss: 0.537117, acc.: 75.78%] [G loss: 1.589508]\n",
      "epoch:12 step:11757 [D loss: 0.563923, acc.: 71.09%] [G loss: 1.157630]\n",
      "epoch:12 step:11758 [D loss: 0.574450, acc.: 65.62%] [G loss: 1.243207]\n",
      "epoch:12 step:11759 [D loss: 0.519963, acc.: 77.34%] [G loss: 1.380729]\n",
      "epoch:12 step:11760 [D loss: 0.593981, acc.: 69.53%] [G loss: 1.024339]\n",
      "epoch:12 step:11761 [D loss: 0.606254, acc.: 64.06%] [G loss: 1.021025]\n",
      "epoch:12 step:11762 [D loss: 0.602052, acc.: 68.75%] [G loss: 1.129435]\n",
      "epoch:12 step:11763 [D loss: 0.491238, acc.: 78.91%] [G loss: 1.262375]\n",
      "epoch:12 step:11764 [D loss: 0.476131, acc.: 78.12%] [G loss: 1.040940]\n",
      "epoch:12 step:11765 [D loss: 0.637234, acc.: 62.50%] [G loss: 1.141504]\n",
      "epoch:12 step:11766 [D loss: 0.725139, acc.: 51.56%] [G loss: 1.019164]\n",
      "epoch:12 step:11767 [D loss: 0.596265, acc.: 67.97%] [G loss: 0.971116]\n",
      "epoch:12 step:11768 [D loss: 0.603699, acc.: 65.62%] [G loss: 1.071388]\n",
      "epoch:12 step:11769 [D loss: 0.574138, acc.: 70.31%] [G loss: 1.115479]\n",
      "epoch:12 step:11770 [D loss: 0.571070, acc.: 71.09%] [G loss: 1.242849]\n",
      "epoch:12 step:11771 [D loss: 0.701120, acc.: 60.16%] [G loss: 1.233841]\n",
      "epoch:12 step:11772 [D loss: 0.572326, acc.: 75.78%] [G loss: 1.063185]\n",
      "epoch:12 step:11773 [D loss: 0.610716, acc.: 68.75%] [G loss: 0.956319]\n",
      "epoch:12 step:11774 [D loss: 0.625059, acc.: 59.38%] [G loss: 1.143473]\n",
      "epoch:12 step:11775 [D loss: 0.619485, acc.: 65.62%] [G loss: 1.182937]\n",
      "epoch:12 step:11776 [D loss: 0.675981, acc.: 58.59%] [G loss: 1.007698]\n",
      "epoch:12 step:11777 [D loss: 0.737492, acc.: 55.47%] [G loss: 1.206234]\n",
      "epoch:12 step:11778 [D loss: 0.621130, acc.: 67.19%] [G loss: 1.095126]\n",
      "epoch:12 step:11779 [D loss: 0.564437, acc.: 69.53%] [G loss: 1.355919]\n",
      "epoch:12 step:11780 [D loss: 0.633323, acc.: 62.50%] [G loss: 1.098184]\n",
      "epoch:12 step:11781 [D loss: 0.578511, acc.: 64.06%] [G loss: 1.040240]\n",
      "epoch:12 step:11782 [D loss: 0.615235, acc.: 69.53%] [G loss: 0.939427]\n",
      "epoch:12 step:11783 [D loss: 0.560015, acc.: 74.22%] [G loss: 1.084147]\n",
      "epoch:12 step:11784 [D loss: 0.581872, acc.: 71.09%] [G loss: 1.293229]\n",
      "epoch:12 step:11785 [D loss: 0.514440, acc.: 79.69%] [G loss: 1.230740]\n",
      "epoch:12 step:11786 [D loss: 0.590522, acc.: 67.19%] [G loss: 1.201199]\n",
      "epoch:12 step:11787 [D loss: 0.610038, acc.: 61.72%] [G loss: 1.261571]\n",
      "epoch:12 step:11788 [D loss: 0.596966, acc.: 70.31%] [G loss: 1.186540]\n",
      "epoch:12 step:11789 [D loss: 0.583557, acc.: 69.53%] [G loss: 1.151376]\n",
      "epoch:12 step:11790 [D loss: 0.469076, acc.: 82.03%] [G loss: 1.455671]\n",
      "epoch:12 step:11791 [D loss: 0.674156, acc.: 61.72%] [G loss: 1.217919]\n",
      "epoch:12 step:11792 [D loss: 0.678475, acc.: 58.59%] [G loss: 1.165332]\n",
      "epoch:12 step:11793 [D loss: 0.582789, acc.: 64.06%] [G loss: 1.162477]\n",
      "epoch:12 step:11794 [D loss: 0.545485, acc.: 71.88%] [G loss: 1.230272]\n",
      "epoch:12 step:11795 [D loss: 0.577970, acc.: 71.88%] [G loss: 1.180784]\n",
      "epoch:12 step:11796 [D loss: 0.670573, acc.: 66.41%] [G loss: 1.220455]\n",
      "epoch:12 step:11797 [D loss: 0.638337, acc.: 66.41%] [G loss: 1.196510]\n",
      "epoch:12 step:11798 [D loss: 0.663248, acc.: 66.41%] [G loss: 0.933640]\n",
      "epoch:12 step:11799 [D loss: 0.555875, acc.: 73.44%] [G loss: 0.986029]\n",
      "epoch:12 step:11800 [D loss: 0.605196, acc.: 68.75%] [G loss: 1.158627]\n",
      "epoch:12 step:11801 [D loss: 0.474993, acc.: 78.12%] [G loss: 1.275636]\n",
      "epoch:12 step:11802 [D loss: 0.527278, acc.: 76.56%] [G loss: 1.112337]\n",
      "epoch:12 step:11803 [D loss: 0.566983, acc.: 67.97%] [G loss: 0.935528]\n",
      "epoch:12 step:11804 [D loss: 0.579018, acc.: 69.53%] [G loss: 1.164804]\n",
      "epoch:12 step:11805 [D loss: 0.504221, acc.: 78.91%] [G loss: 1.174119]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:12 step:11806 [D loss: 0.557767, acc.: 71.09%] [G loss: 1.370157]\n",
      "epoch:12 step:11807 [D loss: 0.582984, acc.: 68.75%] [G loss: 1.126988]\n",
      "epoch:12 step:11808 [D loss: 0.591759, acc.: 65.62%] [G loss: 1.243213]\n",
      "epoch:12 step:11809 [D loss: 0.507786, acc.: 73.44%] [G loss: 1.093528]\n",
      "epoch:12 step:11810 [D loss: 0.527324, acc.: 79.69%] [G loss: 1.233529]\n",
      "epoch:12 step:11811 [D loss: 0.446707, acc.: 82.81%] [G loss: 1.470001]\n",
      "epoch:12 step:11812 [D loss: 0.704545, acc.: 56.25%] [G loss: 1.060676]\n",
      "epoch:12 step:11813 [D loss: 0.556632, acc.: 70.31%] [G loss: 1.040328]\n",
      "epoch:12 step:11814 [D loss: 0.661329, acc.: 61.72%] [G loss: 1.182244]\n",
      "epoch:12 step:11815 [D loss: 0.586293, acc.: 71.09%] [G loss: 1.184774]\n",
      "epoch:12 step:11816 [D loss: 0.472443, acc.: 79.69%] [G loss: 1.345917]\n",
      "epoch:12 step:11817 [D loss: 0.779178, acc.: 49.22%] [G loss: 1.273324]\n",
      "epoch:12 step:11818 [D loss: 0.663876, acc.: 64.84%] [G loss: 1.157144]\n",
      "epoch:12 step:11819 [D loss: 0.665806, acc.: 62.50%] [G loss: 1.134892]\n",
      "epoch:12 step:11820 [D loss: 0.536881, acc.: 75.78%] [G loss: 1.189951]\n",
      "epoch:12 step:11821 [D loss: 0.538279, acc.: 74.22%] [G loss: 1.161669]\n",
      "epoch:12 step:11822 [D loss: 0.666731, acc.: 64.84%] [G loss: 1.147775]\n",
      "epoch:12 step:11823 [D loss: 0.574728, acc.: 75.00%] [G loss: 1.065996]\n",
      "epoch:12 step:11824 [D loss: 0.574901, acc.: 73.44%] [G loss: 1.146682]\n",
      "epoch:12 step:11825 [D loss: 0.626863, acc.: 60.94%] [G loss: 0.960333]\n",
      "epoch:12 step:11826 [D loss: 0.577023, acc.: 67.97%] [G loss: 1.310586]\n",
      "epoch:12 step:11827 [D loss: 0.485205, acc.: 79.69%] [G loss: 1.469420]\n",
      "epoch:12 step:11828 [D loss: 0.659826, acc.: 64.84%] [G loss: 1.010529]\n",
      "epoch:12 step:11829 [D loss: 0.613551, acc.: 64.84%] [G loss: 1.219734]\n",
      "epoch:12 step:11830 [D loss: 0.545585, acc.: 75.00%] [G loss: 1.403627]\n",
      "epoch:12 step:11831 [D loss: 0.584864, acc.: 72.66%] [G loss: 1.126894]\n",
      "epoch:12 step:11832 [D loss: 0.593129, acc.: 64.06%] [G loss: 1.057328]\n",
      "epoch:12 step:11833 [D loss: 0.676724, acc.: 56.25%] [G loss: 1.128391]\n",
      "epoch:12 step:11834 [D loss: 0.663447, acc.: 59.38%] [G loss: 1.077609]\n",
      "epoch:12 step:11835 [D loss: 0.478686, acc.: 80.47%] [G loss: 1.404270]\n",
      "epoch:12 step:11836 [D loss: 0.682357, acc.: 60.94%] [G loss: 1.083723]\n",
      "epoch:12 step:11837 [D loss: 0.653942, acc.: 65.62%] [G loss: 1.018055]\n",
      "epoch:12 step:11838 [D loss: 0.597738, acc.: 71.88%] [G loss: 1.168034]\n",
      "epoch:12 step:11839 [D loss: 0.493789, acc.: 77.34%] [G loss: 1.421687]\n",
      "epoch:12 step:11840 [D loss: 0.636089, acc.: 64.84%] [G loss: 1.141462]\n",
      "epoch:12 step:11841 [D loss: 0.652939, acc.: 62.50%] [G loss: 0.902521]\n",
      "epoch:12 step:11842 [D loss: 0.675510, acc.: 59.38%] [G loss: 0.999421]\n",
      "epoch:12 step:11843 [D loss: 0.516232, acc.: 75.00%] [G loss: 1.284998]\n",
      "epoch:12 step:11844 [D loss: 0.530771, acc.: 71.09%] [G loss: 1.330035]\n",
      "epoch:12 step:11845 [D loss: 0.682454, acc.: 56.25%] [G loss: 1.167531]\n",
      "epoch:12 step:11846 [D loss: 0.533763, acc.: 76.56%] [G loss: 1.269498]\n",
      "epoch:12 step:11847 [D loss: 0.655216, acc.: 58.59%] [G loss: 1.012681]\n",
      "epoch:12 step:11848 [D loss: 0.653787, acc.: 60.16%] [G loss: 1.105930]\n",
      "epoch:12 step:11849 [D loss: 0.663073, acc.: 63.28%] [G loss: 1.035058]\n",
      "epoch:12 step:11850 [D loss: 0.636827, acc.: 62.50%] [G loss: 1.272161]\n",
      "epoch:12 step:11851 [D loss: 0.605240, acc.: 68.75%] [G loss: 1.190289]\n",
      "epoch:12 step:11852 [D loss: 0.635903, acc.: 63.28%] [G loss: 1.401615]\n",
      "epoch:12 step:11853 [D loss: 0.652479, acc.: 64.06%] [G loss: 1.237349]\n",
      "epoch:12 step:11854 [D loss: 0.598161, acc.: 64.06%] [G loss: 1.130931]\n",
      "epoch:12 step:11855 [D loss: 0.595082, acc.: 67.19%] [G loss: 1.182042]\n",
      "epoch:12 step:11856 [D loss: 0.693233, acc.: 55.47%] [G loss: 1.138365]\n",
      "epoch:12 step:11857 [D loss: 0.518577, acc.: 75.78%] [G loss: 1.203833]\n",
      "epoch:12 step:11858 [D loss: 0.612895, acc.: 64.84%] [G loss: 1.218524]\n",
      "epoch:12 step:11859 [D loss: 0.551040, acc.: 71.09%] [G loss: 1.300740]\n",
      "epoch:12 step:11860 [D loss: 0.564281, acc.: 70.31%] [G loss: 1.327582]\n",
      "epoch:12 step:11861 [D loss: 0.411668, acc.: 88.28%] [G loss: 1.199466]\n",
      "epoch:12 step:11862 [D loss: 0.641794, acc.: 61.72%] [G loss: 1.110303]\n",
      "epoch:12 step:11863 [D loss: 0.618397, acc.: 63.28%] [G loss: 1.032734]\n",
      "epoch:12 step:11864 [D loss: 0.684014, acc.: 53.91%] [G loss: 1.069933]\n",
      "epoch:12 step:11865 [D loss: 0.625759, acc.: 61.72%] [G loss: 1.061927]\n",
      "epoch:12 step:11866 [D loss: 0.480554, acc.: 78.12%] [G loss: 1.309802]\n",
      "epoch:12 step:11867 [D loss: 0.751711, acc.: 50.00%] [G loss: 0.960940]\n",
      "epoch:12 step:11868 [D loss: 0.664342, acc.: 64.06%] [G loss: 0.942829]\n",
      "epoch:12 step:11869 [D loss: 0.561732, acc.: 67.19%] [G loss: 1.131644]\n",
      "epoch:12 step:11870 [D loss: 0.552924, acc.: 69.53%] [G loss: 1.216673]\n",
      "epoch:12 step:11871 [D loss: 0.556111, acc.: 70.31%] [G loss: 1.340574]\n",
      "epoch:12 step:11872 [D loss: 0.619005, acc.: 70.31%] [G loss: 1.089805]\n",
      "epoch:12 step:11873 [D loss: 0.534228, acc.: 71.88%] [G loss: 1.042220]\n",
      "epoch:12 step:11874 [D loss: 0.663932, acc.: 64.06%] [G loss: 1.225733]\n",
      "epoch:12 step:11875 [D loss: 0.553345, acc.: 73.44%] [G loss: 1.175392]\n",
      "epoch:12 step:11876 [D loss: 0.563552, acc.: 70.31%] [G loss: 1.155928]\n",
      "epoch:12 step:11877 [D loss: 0.614995, acc.: 60.94%] [G loss: 1.194873]\n",
      "epoch:12 step:11878 [D loss: 0.631474, acc.: 68.75%] [G loss: 1.206109]\n",
      "epoch:12 step:11879 [D loss: 0.560466, acc.: 69.53%] [G loss: 1.100762]\n",
      "epoch:12 step:11880 [D loss: 0.640709, acc.: 66.41%] [G loss: 1.098841]\n",
      "epoch:12 step:11881 [D loss: 0.650320, acc.: 65.62%] [G loss: 1.241014]\n",
      "epoch:12 step:11882 [D loss: 0.605747, acc.: 66.41%] [G loss: 1.216953]\n",
      "epoch:12 step:11883 [D loss: 0.594414, acc.: 67.97%] [G loss: 1.293590]\n",
      "epoch:12 step:11884 [D loss: 0.511700, acc.: 80.47%] [G loss: 1.169904]\n",
      "epoch:12 step:11885 [D loss: 0.655623, acc.: 60.94%] [G loss: 1.023319]\n",
      "epoch:12 step:11886 [D loss: 0.511945, acc.: 78.91%] [G loss: 1.357917]\n",
      "epoch:12 step:11887 [D loss: 0.664518, acc.: 62.50%] [G loss: 1.107458]\n",
      "epoch:12 step:11888 [D loss: 0.555086, acc.: 74.22%] [G loss: 1.098199]\n",
      "epoch:12 step:11889 [D loss: 0.545036, acc.: 73.44%] [G loss: 1.101676]\n",
      "epoch:12 step:11890 [D loss: 0.598991, acc.: 69.53%] [G loss: 1.072814]\n",
      "epoch:12 step:11891 [D loss: 0.639409, acc.: 61.72%] [G loss: 1.423050]\n",
      "epoch:12 step:11892 [D loss: 0.499953, acc.: 78.91%] [G loss: 1.157689]\n",
      "epoch:12 step:11893 [D loss: 0.643881, acc.: 63.28%] [G loss: 0.947975]\n",
      "epoch:12 step:11894 [D loss: 0.539426, acc.: 71.09%] [G loss: 1.173307]\n",
      "epoch:12 step:11895 [D loss: 0.552444, acc.: 71.09%] [G loss: 1.052609]\n",
      "epoch:12 step:11896 [D loss: 0.649127, acc.: 64.06%] [G loss: 1.012176]\n",
      "epoch:12 step:11897 [D loss: 0.535342, acc.: 76.56%] [G loss: 1.362173]\n",
      "epoch:12 step:11898 [D loss: 0.492768, acc.: 77.34%] [G loss: 1.072292]\n",
      "epoch:12 step:11899 [D loss: 0.578598, acc.: 72.66%] [G loss: 1.289352]\n",
      "epoch:12 step:11900 [D loss: 0.509318, acc.: 75.78%] [G loss: 1.114818]\n",
      "epoch:12 step:11901 [D loss: 0.636519, acc.: 65.62%] [G loss: 1.154974]\n",
      "epoch:12 step:11902 [D loss: 0.692897, acc.: 59.38%] [G loss: 1.084949]\n",
      "epoch:12 step:11903 [D loss: 0.545852, acc.: 69.53%] [G loss: 1.312463]\n",
      "epoch:12 step:11904 [D loss: 0.556702, acc.: 71.88%] [G loss: 1.235317]\n",
      "epoch:12 step:11905 [D loss: 0.667515, acc.: 60.94%] [G loss: 0.986223]\n",
      "epoch:12 step:11906 [D loss: 0.708643, acc.: 56.25%] [G loss: 1.134179]\n",
      "epoch:12 step:11907 [D loss: 0.752638, acc.: 50.78%] [G loss: 0.984020]\n",
      "epoch:12 step:11908 [D loss: 0.590013, acc.: 71.09%] [G loss: 0.894551]\n",
      "epoch:12 step:11909 [D loss: 0.631569, acc.: 64.84%] [G loss: 1.099278]\n",
      "epoch:12 step:11910 [D loss: 0.605188, acc.: 64.84%] [G loss: 1.214453]\n",
      "epoch:12 step:11911 [D loss: 0.636502, acc.: 64.06%] [G loss: 1.161557]\n",
      "epoch:12 step:11912 [D loss: 0.602699, acc.: 71.09%] [G loss: 1.137219]\n",
      "epoch:12 step:11913 [D loss: 0.707609, acc.: 61.72%] [G loss: 1.287574]\n",
      "epoch:12 step:11914 [D loss: 0.561780, acc.: 72.66%] [G loss: 1.568147]\n",
      "epoch:12 step:11915 [D loss: 0.538886, acc.: 74.22%] [G loss: 1.313459]\n",
      "epoch:12 step:11916 [D loss: 0.634152, acc.: 64.06%] [G loss: 1.169192]\n",
      "epoch:12 step:11917 [D loss: 0.776007, acc.: 51.56%] [G loss: 1.017241]\n",
      "epoch:12 step:11918 [D loss: 0.632772, acc.: 60.16%] [G loss: 1.202189]\n",
      "epoch:12 step:11919 [D loss: 0.593341, acc.: 69.53%] [G loss: 0.984017]\n",
      "epoch:12 step:11920 [D loss: 0.667083, acc.: 60.94%] [G loss: 1.164904]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:12 step:11921 [D loss: 0.567893, acc.: 70.31%] [G loss: 1.297636]\n",
      "epoch:12 step:11922 [D loss: 0.590826, acc.: 68.75%] [G loss: 1.268070]\n",
      "epoch:12 step:11923 [D loss: 0.574705, acc.: 67.97%] [G loss: 1.349580]\n",
      "epoch:12 step:11924 [D loss: 0.571139, acc.: 70.31%] [G loss: 1.208097]\n",
      "epoch:12 step:11925 [D loss: 0.572371, acc.: 65.62%] [G loss: 1.211812]\n",
      "epoch:12 step:11926 [D loss: 0.641109, acc.: 60.16%] [G loss: 1.157109]\n",
      "epoch:12 step:11927 [D loss: 0.700162, acc.: 56.25%] [G loss: 1.154384]\n",
      "epoch:12 step:11928 [D loss: 0.521013, acc.: 76.56%] [G loss: 1.316541]\n",
      "epoch:12 step:11929 [D loss: 0.640804, acc.: 67.19%] [G loss: 1.215939]\n",
      "epoch:12 step:11930 [D loss: 0.587029, acc.: 68.75%] [G loss: 1.238828]\n",
      "epoch:12 step:11931 [D loss: 0.544143, acc.: 75.78%] [G loss: 0.958593]\n",
      "epoch:12 step:11932 [D loss: 0.566291, acc.: 74.22%] [G loss: 1.241341]\n",
      "epoch:12 step:11933 [D loss: 0.702979, acc.: 56.25%] [G loss: 1.109642]\n",
      "epoch:12 step:11934 [D loss: 0.496652, acc.: 75.78%] [G loss: 0.886606]\n",
      "epoch:12 step:11935 [D loss: 0.609487, acc.: 66.41%] [G loss: 1.232836]\n",
      "epoch:12 step:11936 [D loss: 0.702577, acc.: 56.25%] [G loss: 1.126911]\n",
      "epoch:12 step:11937 [D loss: 0.678994, acc.: 59.38%] [G loss: 1.362082]\n",
      "epoch:12 step:11938 [D loss: 0.610920, acc.: 62.50%] [G loss: 1.163167]\n",
      "epoch:12 step:11939 [D loss: 0.645012, acc.: 60.94%] [G loss: 1.072752]\n",
      "epoch:12 step:11940 [D loss: 0.582155, acc.: 71.09%] [G loss: 1.438618]\n",
      "epoch:12 step:11941 [D loss: 0.615491, acc.: 62.50%] [G loss: 1.107977]\n",
      "epoch:12 step:11942 [D loss: 0.584289, acc.: 67.19%] [G loss: 1.167497]\n",
      "epoch:12 step:11943 [D loss: 0.585138, acc.: 68.75%] [G loss: 1.135222]\n",
      "epoch:12 step:11944 [D loss: 0.591365, acc.: 69.53%] [G loss: 1.182746]\n",
      "epoch:12 step:11945 [D loss: 0.556044, acc.: 74.22%] [G loss: 0.961291]\n",
      "epoch:12 step:11946 [D loss: 0.476951, acc.: 79.69%] [G loss: 1.296593]\n",
      "epoch:12 step:11947 [D loss: 0.699204, acc.: 55.47%] [G loss: 1.200394]\n",
      "epoch:12 step:11948 [D loss: 0.624334, acc.: 63.28%] [G loss: 1.156981]\n",
      "epoch:12 step:11949 [D loss: 0.697130, acc.: 58.59%] [G loss: 1.272837]\n",
      "epoch:12 step:11950 [D loss: 0.605589, acc.: 67.19%] [G loss: 1.240776]\n",
      "epoch:12 step:11951 [D loss: 0.682968, acc.: 60.94%] [G loss: 1.216202]\n",
      "epoch:12 step:11952 [D loss: 0.608217, acc.: 64.06%] [G loss: 0.944480]\n",
      "epoch:12 step:11953 [D loss: 0.739542, acc.: 56.25%] [G loss: 0.979986]\n",
      "epoch:12 step:11954 [D loss: 0.520459, acc.: 81.25%] [G loss: 1.127372]\n",
      "epoch:12 step:11955 [D loss: 0.493319, acc.: 78.91%] [G loss: 1.189586]\n",
      "epoch:12 step:11956 [D loss: 0.651302, acc.: 62.50%] [G loss: 1.209336]\n",
      "epoch:12 step:11957 [D loss: 0.628247, acc.: 69.53%] [G loss: 1.164845]\n",
      "epoch:12 step:11958 [D loss: 0.607964, acc.: 71.88%] [G loss: 1.153158]\n",
      "epoch:12 step:11959 [D loss: 0.618185, acc.: 67.97%] [G loss: 1.271834]\n",
      "epoch:12 step:11960 [D loss: 0.527393, acc.: 77.34%] [G loss: 1.083321]\n",
      "epoch:12 step:11961 [D loss: 0.595357, acc.: 70.31%] [G loss: 0.975933]\n",
      "epoch:12 step:11962 [D loss: 0.513342, acc.: 74.22%] [G loss: 1.170686]\n",
      "epoch:12 step:11963 [D loss: 0.540176, acc.: 75.00%] [G loss: 1.103189]\n",
      "epoch:12 step:11964 [D loss: 0.608088, acc.: 68.75%] [G loss: 1.167901]\n",
      "epoch:12 step:11965 [D loss: 0.588213, acc.: 70.31%] [G loss: 1.282222]\n",
      "epoch:12 step:11966 [D loss: 0.714496, acc.: 56.25%] [G loss: 1.155506]\n",
      "epoch:12 step:11967 [D loss: 0.549283, acc.: 77.34%] [G loss: 1.345164]\n",
      "epoch:12 step:11968 [D loss: 0.661616, acc.: 67.19%] [G loss: 1.167330]\n",
      "epoch:12 step:11969 [D loss: 0.502807, acc.: 77.34%] [G loss: 1.368770]\n",
      "epoch:12 step:11970 [D loss: 0.614340, acc.: 62.50%] [G loss: 0.919001]\n",
      "epoch:12 step:11971 [D loss: 0.591656, acc.: 67.19%] [G loss: 1.054466]\n",
      "epoch:12 step:11972 [D loss: 0.624114, acc.: 60.94%] [G loss: 1.145147]\n",
      "epoch:12 step:11973 [D loss: 0.578730, acc.: 69.53%] [G loss: 1.231070]\n",
      "epoch:12 step:11974 [D loss: 0.575342, acc.: 67.97%] [G loss: 1.210503]\n",
      "epoch:12 step:11975 [D loss: 0.655402, acc.: 64.84%] [G loss: 1.074872]\n",
      "epoch:12 step:11976 [D loss: 0.699088, acc.: 57.81%] [G loss: 1.032344]\n",
      "epoch:12 step:11977 [D loss: 0.609577, acc.: 67.19%] [G loss: 1.036065]\n",
      "epoch:12 step:11978 [D loss: 0.611752, acc.: 66.41%] [G loss: 1.179550]\n",
      "epoch:12 step:11979 [D loss: 0.580261, acc.: 69.53%] [G loss: 1.102615]\n",
      "epoch:12 step:11980 [D loss: 0.497575, acc.: 78.91%] [G loss: 1.230784]\n",
      "epoch:12 step:11981 [D loss: 0.539487, acc.: 71.09%] [G loss: 1.110170]\n",
      "epoch:12 step:11982 [D loss: 0.759187, acc.: 53.12%] [G loss: 0.938019]\n",
      "epoch:12 step:11983 [D loss: 0.535716, acc.: 75.78%] [G loss: 1.260566]\n",
      "epoch:12 step:11984 [D loss: 0.522366, acc.: 72.66%] [G loss: 1.409700]\n",
      "epoch:12 step:11985 [D loss: 0.569525, acc.: 67.97%] [G loss: 1.074397]\n",
      "epoch:12 step:11986 [D loss: 0.559223, acc.: 73.44%] [G loss: 0.938030]\n",
      "epoch:12 step:11987 [D loss: 0.563957, acc.: 74.22%] [G loss: 1.122307]\n",
      "epoch:12 step:11988 [D loss: 0.699162, acc.: 58.59%] [G loss: 1.183099]\n",
      "epoch:12 step:11989 [D loss: 0.668296, acc.: 61.72%] [G loss: 1.295184]\n",
      "epoch:12 step:11990 [D loss: 0.560018, acc.: 68.75%] [G loss: 1.201249]\n",
      "epoch:12 step:11991 [D loss: 0.573206, acc.: 71.09%] [G loss: 1.108212]\n",
      "epoch:12 step:11992 [D loss: 0.599135, acc.: 70.31%] [G loss: 1.148597]\n",
      "epoch:12 step:11993 [D loss: 0.636607, acc.: 66.41%] [G loss: 1.106856]\n",
      "epoch:12 step:11994 [D loss: 0.562012, acc.: 75.00%] [G loss: 1.093550]\n",
      "epoch:12 step:11995 [D loss: 0.588052, acc.: 68.75%] [G loss: 1.036489]\n",
      "epoch:12 step:11996 [D loss: 0.501240, acc.: 79.69%] [G loss: 1.152570]\n",
      "epoch:12 step:11997 [D loss: 0.559401, acc.: 74.22%] [G loss: 1.329710]\n",
      "epoch:12 step:11998 [D loss: 0.536971, acc.: 77.34%] [G loss: 1.263950]\n",
      "epoch:12 step:11999 [D loss: 0.739970, acc.: 53.91%] [G loss: 1.003667]\n",
      "epoch:12 step:12000 [D loss: 0.616352, acc.: 64.06%] [G loss: 1.094172]\n",
      "epoch:12 step:12001 [D loss: 0.662785, acc.: 67.97%] [G loss: 1.117562]\n",
      "epoch:12 step:12002 [D loss: 0.595559, acc.: 66.41%] [G loss: 1.020000]\n",
      "epoch:12 step:12003 [D loss: 0.537026, acc.: 74.22%] [G loss: 1.141765]\n",
      "epoch:12 step:12004 [D loss: 0.568637, acc.: 70.31%] [G loss: 1.252625]\n",
      "epoch:12 step:12005 [D loss: 0.623186, acc.: 61.72%] [G loss: 1.308051]\n",
      "epoch:12 step:12006 [D loss: 0.567034, acc.: 71.09%] [G loss: 1.065289]\n",
      "epoch:12 step:12007 [D loss: 0.595457, acc.: 67.19%] [G loss: 1.061009]\n",
      "epoch:12 step:12008 [D loss: 0.552154, acc.: 76.56%] [G loss: 1.141776]\n",
      "epoch:12 step:12009 [D loss: 0.501355, acc.: 73.44%] [G loss: 1.093958]\n",
      "epoch:12 step:12010 [D loss: 0.612571, acc.: 67.97%] [G loss: 1.160160]\n",
      "epoch:12 step:12011 [D loss: 0.507238, acc.: 78.12%] [G loss: 1.427555]\n",
      "epoch:12 step:12012 [D loss: 0.570701, acc.: 70.31%] [G loss: 1.154639]\n",
      "epoch:12 step:12013 [D loss: 0.500990, acc.: 74.22%] [G loss: 1.340798]\n",
      "epoch:12 step:12014 [D loss: 0.609442, acc.: 69.53%] [G loss: 1.234000]\n",
      "epoch:12 step:12015 [D loss: 0.624465, acc.: 68.75%] [G loss: 1.164574]\n",
      "epoch:12 step:12016 [D loss: 0.655732, acc.: 61.72%] [G loss: 1.238586]\n",
      "epoch:12 step:12017 [D loss: 0.602169, acc.: 64.06%] [G loss: 0.902862]\n",
      "epoch:12 step:12018 [D loss: 0.573014, acc.: 68.75%] [G loss: 1.111550]\n",
      "epoch:12 step:12019 [D loss: 0.663528, acc.: 57.03%] [G loss: 1.331930]\n",
      "epoch:12 step:12020 [D loss: 0.536763, acc.: 76.56%] [G loss: 1.372583]\n",
      "epoch:12 step:12021 [D loss: 0.543895, acc.: 73.44%] [G loss: 1.404148]\n",
      "epoch:12 step:12022 [D loss: 0.560881, acc.: 66.41%] [G loss: 1.009064]\n",
      "epoch:12 step:12023 [D loss: 0.581692, acc.: 72.66%] [G loss: 1.149024]\n",
      "epoch:12 step:12024 [D loss: 0.632165, acc.: 60.94%] [G loss: 1.264604]\n",
      "epoch:12 step:12025 [D loss: 0.624661, acc.: 67.19%] [G loss: 1.059863]\n",
      "epoch:12 step:12026 [D loss: 0.545299, acc.: 76.56%] [G loss: 1.055937]\n",
      "epoch:12 step:12027 [D loss: 0.625606, acc.: 64.06%] [G loss: 1.052233]\n",
      "epoch:12 step:12028 [D loss: 0.564475, acc.: 69.53%] [G loss: 1.032729]\n",
      "epoch:12 step:12029 [D loss: 0.603743, acc.: 67.19%] [G loss: 1.018253]\n",
      "epoch:12 step:12030 [D loss: 0.689468, acc.: 61.72%] [G loss: 1.083569]\n",
      "epoch:12 step:12031 [D loss: 0.460514, acc.: 82.03%] [G loss: 1.001362]\n",
      "epoch:12 step:12032 [D loss: 0.684791, acc.: 58.59%] [G loss: 1.195752]\n",
      "epoch:12 step:12033 [D loss: 0.528221, acc.: 76.56%] [G loss: 1.253244]\n",
      "epoch:12 step:12034 [D loss: 0.574422, acc.: 71.09%] [G loss: 1.140378]\n",
      "epoch:12 step:12035 [D loss: 0.656200, acc.: 65.62%] [G loss: 1.099728]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:12 step:12036 [D loss: 0.752035, acc.: 53.91%] [G loss: 1.042990]\n",
      "epoch:12 step:12037 [D loss: 0.561553, acc.: 70.31%] [G loss: 1.323634]\n",
      "epoch:12 step:12038 [D loss: 0.556678, acc.: 73.44%] [G loss: 1.147867]\n",
      "epoch:12 step:12039 [D loss: 0.677549, acc.: 63.28%] [G loss: 1.281081]\n",
      "epoch:12 step:12040 [D loss: 0.602390, acc.: 66.41%] [G loss: 1.231535]\n",
      "epoch:12 step:12041 [D loss: 0.573844, acc.: 75.00%] [G loss: 1.188857]\n",
      "epoch:12 step:12042 [D loss: 0.582689, acc.: 71.09%] [G loss: 1.083519]\n",
      "epoch:12 step:12043 [D loss: 0.675859, acc.: 64.84%] [G loss: 1.159039]\n",
      "epoch:12 step:12044 [D loss: 0.575180, acc.: 72.66%] [G loss: 1.262056]\n",
      "epoch:12 step:12045 [D loss: 0.599385, acc.: 67.19%] [G loss: 1.210551]\n",
      "epoch:12 step:12046 [D loss: 0.624166, acc.: 61.72%] [G loss: 1.070855]\n",
      "epoch:12 step:12047 [D loss: 0.583190, acc.: 70.31%] [G loss: 1.246274]\n",
      "epoch:12 step:12048 [D loss: 0.522366, acc.: 77.34%] [G loss: 1.123101]\n",
      "epoch:12 step:12049 [D loss: 0.547983, acc.: 73.44%] [G loss: 1.111665]\n",
      "epoch:12 step:12050 [D loss: 0.564891, acc.: 71.09%] [G loss: 1.235704]\n",
      "epoch:12 step:12051 [D loss: 0.578625, acc.: 66.41%] [G loss: 1.217342]\n",
      "epoch:12 step:12052 [D loss: 0.541142, acc.: 69.53%] [G loss: 1.191347]\n",
      "epoch:12 step:12053 [D loss: 0.625084, acc.: 64.06%] [G loss: 1.224941]\n",
      "epoch:12 step:12054 [D loss: 0.556226, acc.: 68.75%] [G loss: 1.263793]\n",
      "epoch:12 step:12055 [D loss: 0.633762, acc.: 64.84%] [G loss: 1.230683]\n",
      "epoch:12 step:12056 [D loss: 0.856143, acc.: 43.75%] [G loss: 1.007428]\n",
      "epoch:12 step:12057 [D loss: 0.629620, acc.: 65.62%] [G loss: 1.124057]\n",
      "epoch:12 step:12058 [D loss: 0.543644, acc.: 73.44%] [G loss: 1.295235]\n",
      "epoch:12 step:12059 [D loss: 0.622326, acc.: 65.62%] [G loss: 1.346825]\n",
      "epoch:12 step:12060 [D loss: 0.540886, acc.: 67.97%] [G loss: 1.162428]\n",
      "epoch:12 step:12061 [D loss: 0.738913, acc.: 55.47%] [G loss: 0.930846]\n",
      "epoch:12 step:12062 [D loss: 0.610613, acc.: 64.06%] [G loss: 1.162788]\n",
      "epoch:12 step:12063 [D loss: 0.576277, acc.: 71.09%] [G loss: 1.112411]\n",
      "epoch:12 step:12064 [D loss: 0.579666, acc.: 70.31%] [G loss: 1.285849]\n",
      "epoch:12 step:12065 [D loss: 0.651388, acc.: 62.50%] [G loss: 1.119234]\n",
      "epoch:12 step:12066 [D loss: 0.574761, acc.: 66.41%] [G loss: 1.284611]\n",
      "epoch:12 step:12067 [D loss: 0.748802, acc.: 53.12%] [G loss: 1.118226]\n",
      "epoch:12 step:12068 [D loss: 0.623556, acc.: 71.88%] [G loss: 1.127177]\n",
      "epoch:12 step:12069 [D loss: 0.621317, acc.: 62.50%] [G loss: 1.104726]\n",
      "epoch:12 step:12070 [D loss: 0.542234, acc.: 76.56%] [G loss: 1.238814]\n",
      "epoch:12 step:12071 [D loss: 0.616932, acc.: 63.28%] [G loss: 1.099910]\n",
      "epoch:12 step:12072 [D loss: 0.623227, acc.: 62.50%] [G loss: 1.218954]\n",
      "epoch:12 step:12073 [D loss: 0.723892, acc.: 57.81%] [G loss: 1.232559]\n",
      "epoch:12 step:12074 [D loss: 0.585546, acc.: 67.19%] [G loss: 0.946386]\n",
      "epoch:12 step:12075 [D loss: 0.704601, acc.: 56.25%] [G loss: 1.053103]\n",
      "epoch:12 step:12076 [D loss: 0.533345, acc.: 66.41%] [G loss: 1.135262]\n",
      "epoch:12 step:12077 [D loss: 0.544832, acc.: 71.09%] [G loss: 1.302710]\n",
      "epoch:12 step:12078 [D loss: 0.664194, acc.: 56.25%] [G loss: 1.142251]\n",
      "epoch:12 step:12079 [D loss: 0.643776, acc.: 67.19%] [G loss: 1.128975]\n",
      "epoch:12 step:12080 [D loss: 0.727780, acc.: 56.25%] [G loss: 1.063712]\n",
      "epoch:12 step:12081 [D loss: 0.606197, acc.: 60.94%] [G loss: 1.113730]\n",
      "epoch:12 step:12082 [D loss: 0.643302, acc.: 64.84%] [G loss: 0.852623]\n",
      "epoch:12 step:12083 [D loss: 0.585344, acc.: 66.41%] [G loss: 1.108121]\n",
      "epoch:12 step:12084 [D loss: 0.559651, acc.: 70.31%] [G loss: 1.029532]\n",
      "epoch:12 step:12085 [D loss: 0.585579, acc.: 69.53%] [G loss: 1.053767]\n",
      "epoch:12 step:12086 [D loss: 0.636744, acc.: 62.50%] [G loss: 1.172029]\n",
      "epoch:12 step:12087 [D loss: 0.610986, acc.: 65.62%] [G loss: 1.252731]\n",
      "epoch:12 step:12088 [D loss: 0.621635, acc.: 67.97%] [G loss: 1.166276]\n",
      "epoch:12 step:12089 [D loss: 0.656337, acc.: 60.94%] [G loss: 1.412394]\n",
      "epoch:12 step:12090 [D loss: 0.636349, acc.: 62.50%] [G loss: 1.161653]\n",
      "epoch:12 step:12091 [D loss: 0.700615, acc.: 56.25%] [G loss: 0.820595]\n",
      "epoch:12 step:12092 [D loss: 0.581880, acc.: 71.09%] [G loss: 1.103164]\n",
      "epoch:12 step:12093 [D loss: 0.535017, acc.: 75.00%] [G loss: 1.121401]\n",
      "epoch:12 step:12094 [D loss: 0.527122, acc.: 74.22%] [G loss: 1.336457]\n",
      "epoch:12 step:12095 [D loss: 0.694244, acc.: 56.25%] [G loss: 0.984277]\n",
      "epoch:12 step:12096 [D loss: 0.537037, acc.: 73.44%] [G loss: 1.134997]\n",
      "epoch:12 step:12097 [D loss: 0.550630, acc.: 71.09%] [G loss: 1.362240]\n",
      "epoch:12 step:12098 [D loss: 0.637752, acc.: 64.06%] [G loss: 1.095077]\n",
      "epoch:12 step:12099 [D loss: 0.668258, acc.: 60.94%] [G loss: 1.139210]\n",
      "epoch:12 step:12100 [D loss: 0.520717, acc.: 77.34%] [G loss: 1.184465]\n",
      "epoch:12 step:12101 [D loss: 0.617999, acc.: 64.84%] [G loss: 1.317642]\n",
      "epoch:12 step:12102 [D loss: 0.552573, acc.: 74.22%] [G loss: 1.116262]\n",
      "epoch:12 step:12103 [D loss: 0.631337, acc.: 72.66%] [G loss: 0.980943]\n",
      "epoch:12 step:12104 [D loss: 0.548310, acc.: 74.22%] [G loss: 1.146282]\n",
      "epoch:12 step:12105 [D loss: 0.612312, acc.: 64.06%] [G loss: 1.031504]\n",
      "epoch:12 step:12106 [D loss: 0.573920, acc.: 71.09%] [G loss: 1.107648]\n",
      "epoch:12 step:12107 [D loss: 0.643845, acc.: 67.97%] [G loss: 1.090065]\n",
      "epoch:12 step:12108 [D loss: 0.582698, acc.: 67.97%] [G loss: 0.996553]\n",
      "epoch:12 step:12109 [D loss: 0.574319, acc.: 65.62%] [G loss: 1.362947]\n",
      "epoch:12 step:12110 [D loss: 0.641750, acc.: 64.06%] [G loss: 1.194885]\n",
      "epoch:12 step:12111 [D loss: 0.574784, acc.: 70.31%] [G loss: 1.160396]\n",
      "epoch:12 step:12112 [D loss: 0.586476, acc.: 69.53%] [G loss: 1.207645]\n",
      "epoch:12 step:12113 [D loss: 0.600686, acc.: 66.41%] [G loss: 1.024756]\n",
      "epoch:12 step:12114 [D loss: 0.545435, acc.: 72.66%] [G loss: 1.318418]\n",
      "epoch:12 step:12115 [D loss: 0.613782, acc.: 67.19%] [G loss: 1.102219]\n",
      "epoch:12 step:12116 [D loss: 0.618584, acc.: 66.41%] [G loss: 1.119138]\n",
      "epoch:12 step:12117 [D loss: 0.473048, acc.: 84.38%] [G loss: 1.245470]\n",
      "epoch:12 step:12118 [D loss: 0.572955, acc.: 74.22%] [G loss: 1.235372]\n",
      "epoch:12 step:12119 [D loss: 0.555612, acc.: 68.75%] [G loss: 1.227963]\n",
      "epoch:12 step:12120 [D loss: 0.665726, acc.: 62.50%] [G loss: 1.006583]\n",
      "epoch:12 step:12121 [D loss: 0.554774, acc.: 69.53%] [G loss: 1.133630]\n",
      "epoch:12 step:12122 [D loss: 0.675684, acc.: 57.03%] [G loss: 1.139051]\n",
      "epoch:12 step:12123 [D loss: 0.661997, acc.: 63.28%] [G loss: 1.471627]\n",
      "epoch:12 step:12124 [D loss: 0.555413, acc.: 73.44%] [G loss: 1.063445]\n",
      "epoch:12 step:12125 [D loss: 0.794764, acc.: 50.00%] [G loss: 1.084610]\n",
      "epoch:12 step:12126 [D loss: 0.420833, acc.: 83.59%] [G loss: 1.424271]\n",
      "epoch:12 step:12127 [D loss: 0.543892, acc.: 74.22%] [G loss: 1.429085]\n",
      "epoch:12 step:12128 [D loss: 0.559246, acc.: 71.09%] [G loss: 1.228437]\n",
      "epoch:12 step:12129 [D loss: 0.550138, acc.: 72.66%] [G loss: 1.287338]\n",
      "epoch:12 step:12130 [D loss: 0.585663, acc.: 71.88%] [G loss: 1.126511]\n",
      "epoch:12 step:12131 [D loss: 0.529309, acc.: 72.66%] [G loss: 1.426354]\n",
      "epoch:12 step:12132 [D loss: 0.640584, acc.: 63.28%] [G loss: 1.270845]\n",
      "epoch:12 step:12133 [D loss: 0.776263, acc.: 51.56%] [G loss: 0.962520]\n",
      "epoch:12 step:12134 [D loss: 0.633896, acc.: 56.25%] [G loss: 1.173001]\n",
      "epoch:12 step:12135 [D loss: 0.620168, acc.: 70.31%] [G loss: 1.052417]\n",
      "epoch:12 step:12136 [D loss: 0.550567, acc.: 68.75%] [G loss: 1.003650]\n",
      "epoch:12 step:12137 [D loss: 0.578433, acc.: 72.66%] [G loss: 1.023104]\n",
      "epoch:12 step:12138 [D loss: 0.549451, acc.: 76.56%] [G loss: 1.062783]\n",
      "epoch:12 step:12139 [D loss: 0.611004, acc.: 67.19%] [G loss: 1.307689]\n",
      "epoch:12 step:12140 [D loss: 0.589159, acc.: 65.62%] [G loss: 1.233953]\n",
      "epoch:12 step:12141 [D loss: 0.590142, acc.: 71.09%] [G loss: 1.195074]\n",
      "epoch:12 step:12142 [D loss: 0.521019, acc.: 79.69%] [G loss: 1.100857]\n",
      "epoch:12 step:12143 [D loss: 0.555453, acc.: 73.44%] [G loss: 0.982397]\n",
      "epoch:12 step:12144 [D loss: 0.491189, acc.: 77.34%] [G loss: 1.554057]\n",
      "epoch:12 step:12145 [D loss: 0.701965, acc.: 61.72%] [G loss: 1.063967]\n",
      "epoch:12 step:12146 [D loss: 0.604406, acc.: 69.53%] [G loss: 0.885968]\n",
      "epoch:12 step:12147 [D loss: 0.557406, acc.: 71.88%] [G loss: 1.087259]\n",
      "epoch:12 step:12148 [D loss: 0.612876, acc.: 69.53%] [G loss: 1.184586]\n",
      "epoch:12 step:12149 [D loss: 0.749223, acc.: 49.22%] [G loss: 0.969119]\n",
      "epoch:12 step:12150 [D loss: 0.613067, acc.: 62.50%] [G loss: 1.243308]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:12 step:12151 [D loss: 0.663477, acc.: 66.41%] [G loss: 1.186717]\n",
      "epoch:12 step:12152 [D loss: 0.673950, acc.: 60.94%] [G loss: 1.193514]\n",
      "epoch:12 step:12153 [D loss: 0.627685, acc.: 64.84%] [G loss: 1.198201]\n",
      "epoch:12 step:12154 [D loss: 0.585694, acc.: 69.53%] [G loss: 1.263563]\n",
      "epoch:12 step:12155 [D loss: 0.634535, acc.: 67.19%] [G loss: 1.154423]\n",
      "epoch:12 step:12156 [D loss: 0.595945, acc.: 64.84%] [G loss: 1.209697]\n",
      "epoch:12 step:12157 [D loss: 0.586640, acc.: 71.88%] [G loss: 1.159917]\n",
      "epoch:12 step:12158 [D loss: 0.578977, acc.: 65.62%] [G loss: 1.208117]\n",
      "epoch:12 step:12159 [D loss: 0.521931, acc.: 71.09%] [G loss: 1.168168]\n",
      "epoch:12 step:12160 [D loss: 0.616715, acc.: 62.50%] [G loss: 1.051184]\n",
      "epoch:12 step:12161 [D loss: 0.772410, acc.: 45.31%] [G loss: 0.822325]\n",
      "epoch:12 step:12162 [D loss: 0.588099, acc.: 64.06%] [G loss: 1.331280]\n",
      "epoch:12 step:12163 [D loss: 0.472665, acc.: 78.91%] [G loss: 1.436043]\n",
      "epoch:12 step:12164 [D loss: 0.601223, acc.: 65.62%] [G loss: 1.265558]\n",
      "epoch:12 step:12165 [D loss: 0.555354, acc.: 75.00%] [G loss: 0.979936]\n",
      "epoch:12 step:12166 [D loss: 0.676671, acc.: 58.59%] [G loss: 1.244962]\n",
      "epoch:12 step:12167 [D loss: 0.594003, acc.: 68.75%] [G loss: 1.060290]\n",
      "epoch:12 step:12168 [D loss: 0.578071, acc.: 70.31%] [G loss: 1.122611]\n",
      "epoch:12 step:12169 [D loss: 0.625125, acc.: 66.41%] [G loss: 1.290015]\n",
      "epoch:12 step:12170 [D loss: 0.607550, acc.: 62.50%] [G loss: 1.013355]\n",
      "epoch:12 step:12171 [D loss: 0.601338, acc.: 67.19%] [G loss: 1.214083]\n",
      "epoch:12 step:12172 [D loss: 0.499247, acc.: 76.56%] [G loss: 1.314647]\n",
      "epoch:12 step:12173 [D loss: 0.586847, acc.: 70.31%] [G loss: 1.389616]\n",
      "epoch:12 step:12174 [D loss: 0.550280, acc.: 72.66%] [G loss: 1.258080]\n",
      "epoch:12 step:12175 [D loss: 0.725161, acc.: 55.47%] [G loss: 1.167589]\n",
      "epoch:12 step:12176 [D loss: 0.615867, acc.: 62.50%] [G loss: 1.059371]\n",
      "epoch:12 step:12177 [D loss: 0.641999, acc.: 64.06%] [G loss: 1.089060]\n",
      "epoch:12 step:12178 [D loss: 0.532607, acc.: 71.09%] [G loss: 1.100913]\n",
      "epoch:12 step:12179 [D loss: 0.563154, acc.: 74.22%] [G loss: 1.134389]\n",
      "epoch:12 step:12180 [D loss: 0.616352, acc.: 61.72%] [G loss: 1.192432]\n",
      "epoch:12 step:12181 [D loss: 0.638761, acc.: 61.72%] [G loss: 1.337422]\n",
      "epoch:13 step:12182 [D loss: 0.589438, acc.: 69.53%] [G loss: 1.136173]\n",
      "epoch:13 step:12183 [D loss: 0.567026, acc.: 74.22%] [G loss: 1.358993]\n",
      "epoch:13 step:12184 [D loss: 0.675454, acc.: 63.28%] [G loss: 1.356167]\n",
      "epoch:13 step:12185 [D loss: 0.543354, acc.: 72.66%] [G loss: 1.223970]\n",
      "epoch:13 step:12186 [D loss: 0.639284, acc.: 57.81%] [G loss: 1.097307]\n",
      "epoch:13 step:12187 [D loss: 0.686977, acc.: 55.47%] [G loss: 1.145202]\n",
      "epoch:13 step:12188 [D loss: 0.526284, acc.: 75.78%] [G loss: 1.196670]\n",
      "epoch:13 step:12189 [D loss: 0.634302, acc.: 67.97%] [G loss: 1.334598]\n",
      "epoch:13 step:12190 [D loss: 0.532200, acc.: 78.91%] [G loss: 1.195727]\n",
      "epoch:13 step:12191 [D loss: 0.625658, acc.: 65.62%] [G loss: 1.132727]\n",
      "epoch:13 step:12192 [D loss: 0.437854, acc.: 87.50%] [G loss: 1.026429]\n",
      "epoch:13 step:12193 [D loss: 0.550815, acc.: 76.56%] [G loss: 1.048312]\n",
      "epoch:13 step:12194 [D loss: 0.582743, acc.: 69.53%] [G loss: 1.377357]\n",
      "epoch:13 step:12195 [D loss: 0.602811, acc.: 67.19%] [G loss: 1.089465]\n",
      "epoch:13 step:12196 [D loss: 0.421888, acc.: 83.59%] [G loss: 1.296041]\n",
      "epoch:13 step:12197 [D loss: 0.589336, acc.: 70.31%] [G loss: 1.198068]\n",
      "epoch:13 step:12198 [D loss: 0.550365, acc.: 75.00%] [G loss: 1.193350]\n",
      "epoch:13 step:12199 [D loss: 0.585690, acc.: 68.75%] [G loss: 1.246061]\n",
      "epoch:13 step:12200 [D loss: 0.625576, acc.: 65.62%] [G loss: 1.404910]\n",
      "epoch:13 step:12201 [D loss: 0.508616, acc.: 75.78%] [G loss: 1.231731]\n",
      "epoch:13 step:12202 [D loss: 0.726315, acc.: 57.81%] [G loss: 1.077234]\n",
      "epoch:13 step:12203 [D loss: 0.666926, acc.: 60.94%] [G loss: 1.144570]\n",
      "epoch:13 step:12204 [D loss: 0.652620, acc.: 65.62%] [G loss: 1.303598]\n",
      "epoch:13 step:12205 [D loss: 0.576969, acc.: 67.97%] [G loss: 1.199929]\n",
      "epoch:13 step:12206 [D loss: 0.651113, acc.: 64.06%] [G loss: 1.112917]\n",
      "epoch:13 step:12207 [D loss: 0.668997, acc.: 62.50%] [G loss: 1.137766]\n",
      "epoch:13 step:12208 [D loss: 0.588886, acc.: 65.62%] [G loss: 1.206582]\n",
      "epoch:13 step:12209 [D loss: 0.616995, acc.: 64.84%] [G loss: 1.277198]\n",
      "epoch:13 step:12210 [D loss: 0.707626, acc.: 50.78%] [G loss: 1.078649]\n",
      "epoch:13 step:12211 [D loss: 0.509565, acc.: 76.56%] [G loss: 1.246270]\n",
      "epoch:13 step:12212 [D loss: 0.667031, acc.: 57.03%] [G loss: 1.026889]\n",
      "epoch:13 step:12213 [D loss: 0.528379, acc.: 74.22%] [G loss: 1.127903]\n",
      "epoch:13 step:12214 [D loss: 0.686411, acc.: 58.59%] [G loss: 0.922448]\n",
      "epoch:13 step:12215 [D loss: 0.573898, acc.: 70.31%] [G loss: 1.298204]\n",
      "epoch:13 step:12216 [D loss: 0.551062, acc.: 69.53%] [G loss: 1.098503]\n",
      "epoch:13 step:12217 [D loss: 0.561138, acc.: 72.66%] [G loss: 1.308249]\n",
      "epoch:13 step:12218 [D loss: 0.601508, acc.: 69.53%] [G loss: 1.168138]\n",
      "epoch:13 step:12219 [D loss: 0.784610, acc.: 51.56%] [G loss: 1.089858]\n",
      "epoch:13 step:12220 [D loss: 0.633855, acc.: 64.84%] [G loss: 1.038053]\n",
      "epoch:13 step:12221 [D loss: 0.656207, acc.: 62.50%] [G loss: 1.255840]\n",
      "epoch:13 step:12222 [D loss: 0.535986, acc.: 71.09%] [G loss: 1.209436]\n",
      "epoch:13 step:12223 [D loss: 0.621509, acc.: 67.19%] [G loss: 1.094583]\n",
      "epoch:13 step:12224 [D loss: 0.683761, acc.: 57.03%] [G loss: 1.127078]\n",
      "epoch:13 step:12225 [D loss: 0.573000, acc.: 71.88%] [G loss: 1.167016]\n",
      "epoch:13 step:12226 [D loss: 0.643955, acc.: 61.72%] [G loss: 1.179755]\n",
      "epoch:13 step:12227 [D loss: 0.711591, acc.: 55.47%] [G loss: 1.073564]\n",
      "epoch:13 step:12228 [D loss: 0.697325, acc.: 56.25%] [G loss: 0.977004]\n",
      "epoch:13 step:12229 [D loss: 0.641024, acc.: 60.94%] [G loss: 0.934210]\n",
      "epoch:13 step:12230 [D loss: 0.587439, acc.: 67.19%] [G loss: 1.330897]\n",
      "epoch:13 step:12231 [D loss: 0.541235, acc.: 75.00%] [G loss: 1.121389]\n",
      "epoch:13 step:12232 [D loss: 0.599797, acc.: 68.75%] [G loss: 1.355973]\n",
      "epoch:13 step:12233 [D loss: 0.582912, acc.: 68.75%] [G loss: 1.365452]\n",
      "epoch:13 step:12234 [D loss: 0.618962, acc.: 69.53%] [G loss: 1.108080]\n",
      "epoch:13 step:12235 [D loss: 0.575767, acc.: 70.31%] [G loss: 1.207965]\n",
      "epoch:13 step:12236 [D loss: 0.654868, acc.: 63.28%] [G loss: 1.102223]\n",
      "epoch:13 step:12237 [D loss: 0.562752, acc.: 71.88%] [G loss: 1.321045]\n",
      "epoch:13 step:12238 [D loss: 0.625516, acc.: 64.84%] [G loss: 1.114046]\n",
      "epoch:13 step:12239 [D loss: 0.589264, acc.: 71.09%] [G loss: 0.987083]\n",
      "epoch:13 step:12240 [D loss: 0.446542, acc.: 85.16%] [G loss: 1.397717]\n",
      "epoch:13 step:12241 [D loss: 0.601537, acc.: 67.19%] [G loss: 1.267395]\n",
      "epoch:13 step:12242 [D loss: 0.618655, acc.: 66.41%] [G loss: 1.143319]\n",
      "epoch:13 step:12243 [D loss: 0.483917, acc.: 83.59%] [G loss: 1.032825]\n",
      "epoch:13 step:12244 [D loss: 0.554300, acc.: 70.31%] [G loss: 1.244591]\n",
      "epoch:13 step:12245 [D loss: 0.619499, acc.: 64.84%] [G loss: 1.109161]\n",
      "epoch:13 step:12246 [D loss: 0.584923, acc.: 68.75%] [G loss: 1.155387]\n",
      "epoch:13 step:12247 [D loss: 0.654754, acc.: 60.16%] [G loss: 1.331169]\n",
      "epoch:13 step:12248 [D loss: 0.679394, acc.: 61.72%] [G loss: 1.245602]\n",
      "epoch:13 step:12249 [D loss: 0.730928, acc.: 54.69%] [G loss: 1.010694]\n",
      "epoch:13 step:12250 [D loss: 0.599142, acc.: 69.53%] [G loss: 1.110121]\n",
      "epoch:13 step:12251 [D loss: 0.642844, acc.: 66.41%] [G loss: 1.036364]\n",
      "epoch:13 step:12252 [D loss: 0.630322, acc.: 61.72%] [G loss: 1.190408]\n",
      "epoch:13 step:12253 [D loss: 0.700891, acc.: 57.81%] [G loss: 1.120024]\n",
      "epoch:13 step:12254 [D loss: 0.522506, acc.: 79.69%] [G loss: 1.258124]\n",
      "epoch:13 step:12255 [D loss: 0.605160, acc.: 69.53%] [G loss: 1.066039]\n",
      "epoch:13 step:12256 [D loss: 0.555027, acc.: 71.09%] [G loss: 1.039459]\n",
      "epoch:13 step:12257 [D loss: 0.625008, acc.: 64.84%] [G loss: 1.232267]\n",
      "epoch:13 step:12258 [D loss: 0.635693, acc.: 62.50%] [G loss: 1.314323]\n",
      "epoch:13 step:12259 [D loss: 0.666658, acc.: 51.56%] [G loss: 1.091396]\n",
      "epoch:13 step:12260 [D loss: 0.555411, acc.: 70.31%] [G loss: 1.149070]\n",
      "epoch:13 step:12261 [D loss: 0.537485, acc.: 75.00%] [G loss: 1.282082]\n",
      "epoch:13 step:12262 [D loss: 0.651376, acc.: 66.41%] [G loss: 1.160999]\n",
      "epoch:13 step:12263 [D loss: 0.472153, acc.: 82.03%] [G loss: 1.115538]\n",
      "epoch:13 step:12264 [D loss: 0.628518, acc.: 69.53%] [G loss: 1.093618]\n",
      "epoch:13 step:12265 [D loss: 0.589776, acc.: 67.97%] [G loss: 1.278477]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:13 step:12266 [D loss: 0.526847, acc.: 77.34%] [G loss: 1.098445]\n",
      "epoch:13 step:12267 [D loss: 0.732535, acc.: 51.56%] [G loss: 1.184530]\n",
      "epoch:13 step:12268 [D loss: 0.678395, acc.: 60.94%] [G loss: 1.081702]\n",
      "epoch:13 step:12269 [D loss: 0.563788, acc.: 69.53%] [G loss: 1.144747]\n",
      "epoch:13 step:12270 [D loss: 0.553167, acc.: 75.78%] [G loss: 1.294479]\n",
      "epoch:13 step:12271 [D loss: 0.521641, acc.: 76.56%] [G loss: 1.298595]\n",
      "epoch:13 step:12272 [D loss: 0.550629, acc.: 71.09%] [G loss: 1.259656]\n",
      "epoch:13 step:12273 [D loss: 0.562710, acc.: 71.88%] [G loss: 1.254317]\n",
      "epoch:13 step:12274 [D loss: 0.615143, acc.: 64.84%] [G loss: 0.988432]\n",
      "epoch:13 step:12275 [D loss: 0.549266, acc.: 75.00%] [G loss: 1.261884]\n",
      "epoch:13 step:12276 [D loss: 0.626611, acc.: 64.06%] [G loss: 1.031547]\n",
      "epoch:13 step:12277 [D loss: 0.604956, acc.: 67.19%] [G loss: 1.287696]\n",
      "epoch:13 step:12278 [D loss: 0.662368, acc.: 59.38%] [G loss: 0.979231]\n",
      "epoch:13 step:12279 [D loss: 0.504050, acc.: 78.12%] [G loss: 1.615796]\n",
      "epoch:13 step:12280 [D loss: 0.727192, acc.: 50.00%] [G loss: 0.916074]\n",
      "epoch:13 step:12281 [D loss: 0.588333, acc.: 68.75%] [G loss: 1.120564]\n",
      "epoch:13 step:12282 [D loss: 0.424936, acc.: 85.16%] [G loss: 1.522394]\n",
      "epoch:13 step:12283 [D loss: 0.650892, acc.: 60.94%] [G loss: 1.225661]\n",
      "epoch:13 step:12284 [D loss: 0.413798, acc.: 85.94%] [G loss: 1.526428]\n",
      "epoch:13 step:12285 [D loss: 0.598368, acc.: 64.06%] [G loss: 1.151190]\n",
      "epoch:13 step:12286 [D loss: 0.596715, acc.: 67.19%] [G loss: 1.123778]\n",
      "epoch:13 step:12287 [D loss: 0.675428, acc.: 56.25%] [G loss: 1.014643]\n",
      "epoch:13 step:12288 [D loss: 0.514931, acc.: 76.56%] [G loss: 1.017699]\n",
      "epoch:13 step:12289 [D loss: 0.475009, acc.: 82.03%] [G loss: 0.965690]\n",
      "epoch:13 step:12290 [D loss: 0.472566, acc.: 78.12%] [G loss: 1.434560]\n",
      "epoch:13 step:12291 [D loss: 0.716368, acc.: 57.03%] [G loss: 0.963231]\n",
      "epoch:13 step:12292 [D loss: 0.650482, acc.: 60.16%] [G loss: 0.907200]\n",
      "epoch:13 step:12293 [D loss: 0.475660, acc.: 79.69%] [G loss: 1.208365]\n",
      "epoch:13 step:12294 [D loss: 0.677192, acc.: 61.72%] [G loss: 1.006800]\n",
      "epoch:13 step:12295 [D loss: 0.480420, acc.: 80.47%] [G loss: 1.143958]\n",
      "epoch:13 step:12296 [D loss: 0.612150, acc.: 60.94%] [G loss: 1.000103]\n",
      "epoch:13 step:12297 [D loss: 0.591740, acc.: 66.41%] [G loss: 1.360782]\n",
      "epoch:13 step:12298 [D loss: 0.492374, acc.: 77.34%] [G loss: 1.314141]\n",
      "epoch:13 step:12299 [D loss: 0.646665, acc.: 64.06%] [G loss: 1.160380]\n",
      "epoch:13 step:12300 [D loss: 0.707447, acc.: 55.47%] [G loss: 1.056663]\n",
      "epoch:13 step:12301 [D loss: 0.714683, acc.: 54.69%] [G loss: 1.078008]\n",
      "epoch:13 step:12302 [D loss: 0.729973, acc.: 58.59%] [G loss: 1.088397]\n",
      "epoch:13 step:12303 [D loss: 0.536168, acc.: 74.22%] [G loss: 1.102961]\n",
      "epoch:13 step:12304 [D loss: 0.605861, acc.: 65.62%] [G loss: 1.242257]\n",
      "epoch:13 step:12305 [D loss: 0.596070, acc.: 64.84%] [G loss: 1.119331]\n",
      "epoch:13 step:12306 [D loss: 0.524820, acc.: 78.12%] [G loss: 1.315346]\n",
      "epoch:13 step:12307 [D loss: 0.572746, acc.: 75.00%] [G loss: 1.154032]\n",
      "epoch:13 step:12308 [D loss: 0.587265, acc.: 64.84%] [G loss: 1.161955]\n",
      "epoch:13 step:12309 [D loss: 0.576836, acc.: 70.31%] [G loss: 1.192091]\n",
      "epoch:13 step:12310 [D loss: 0.638965, acc.: 64.06%] [G loss: 1.170037]\n",
      "epoch:13 step:12311 [D loss: 0.530912, acc.: 73.44%] [G loss: 1.252713]\n",
      "epoch:13 step:12312 [D loss: 0.489477, acc.: 80.47%] [G loss: 0.974204]\n",
      "epoch:13 step:12313 [D loss: 0.574667, acc.: 67.97%] [G loss: 1.088226]\n",
      "epoch:13 step:12314 [D loss: 0.607228, acc.: 64.84%] [G loss: 1.151344]\n",
      "epoch:13 step:12315 [D loss: 0.555420, acc.: 69.53%] [G loss: 1.346342]\n",
      "epoch:13 step:12316 [D loss: 0.627347, acc.: 67.97%] [G loss: 1.085509]\n",
      "epoch:13 step:12317 [D loss: 0.765653, acc.: 51.56%] [G loss: 1.071046]\n",
      "epoch:13 step:12318 [D loss: 0.520724, acc.: 74.22%] [G loss: 1.090405]\n",
      "epoch:13 step:12319 [D loss: 0.534649, acc.: 75.00%] [G loss: 1.163733]\n",
      "epoch:13 step:12320 [D loss: 0.599659, acc.: 70.31%] [G loss: 0.957679]\n",
      "epoch:13 step:12321 [D loss: 0.597042, acc.: 66.41%] [G loss: 0.957066]\n",
      "epoch:13 step:12322 [D loss: 0.631894, acc.: 64.84%] [G loss: 1.097502]\n",
      "epoch:13 step:12323 [D loss: 0.649957, acc.: 64.84%] [G loss: 1.261071]\n",
      "epoch:13 step:12324 [D loss: 0.663517, acc.: 62.50%] [G loss: 1.114929]\n",
      "epoch:13 step:12325 [D loss: 0.563137, acc.: 71.09%] [G loss: 1.309220]\n",
      "epoch:13 step:12326 [D loss: 0.695333, acc.: 51.56%] [G loss: 0.970849]\n",
      "epoch:13 step:12327 [D loss: 0.586721, acc.: 67.97%] [G loss: 1.065958]\n",
      "epoch:13 step:12328 [D loss: 0.616217, acc.: 65.62%] [G loss: 1.184950]\n",
      "epoch:13 step:12329 [D loss: 0.604703, acc.: 66.41%] [G loss: 1.026277]\n",
      "epoch:13 step:12330 [D loss: 0.696400, acc.: 60.94%] [G loss: 1.063718]\n",
      "epoch:13 step:12331 [D loss: 0.532469, acc.: 75.78%] [G loss: 1.180027]\n",
      "epoch:13 step:12332 [D loss: 0.618039, acc.: 66.41%] [G loss: 1.309836]\n",
      "epoch:13 step:12333 [D loss: 0.524368, acc.: 77.34%] [G loss: 1.392832]\n",
      "epoch:13 step:12334 [D loss: 0.495977, acc.: 78.91%] [G loss: 1.298837]\n",
      "epoch:13 step:12335 [D loss: 0.556986, acc.: 73.44%] [G loss: 1.329593]\n",
      "epoch:13 step:12336 [D loss: 0.574007, acc.: 66.41%] [G loss: 1.095115]\n",
      "epoch:13 step:12337 [D loss: 0.572165, acc.: 74.22%] [G loss: 1.074627]\n",
      "epoch:13 step:12338 [D loss: 0.630409, acc.: 62.50%] [G loss: 1.226434]\n",
      "epoch:13 step:12339 [D loss: 0.630598, acc.: 69.53%] [G loss: 1.026171]\n",
      "epoch:13 step:12340 [D loss: 0.488395, acc.: 82.81%] [G loss: 1.178557]\n",
      "epoch:13 step:12341 [D loss: 0.544665, acc.: 73.44%] [G loss: 1.234403]\n",
      "epoch:13 step:12342 [D loss: 0.640898, acc.: 63.28%] [G loss: 1.156430]\n",
      "epoch:13 step:12343 [D loss: 0.557871, acc.: 73.44%] [G loss: 1.425301]\n",
      "epoch:13 step:12344 [D loss: 0.698502, acc.: 52.34%] [G loss: 1.102225]\n",
      "epoch:13 step:12345 [D loss: 0.617907, acc.: 64.06%] [G loss: 1.048450]\n",
      "epoch:13 step:12346 [D loss: 0.729393, acc.: 54.69%] [G loss: 1.028046]\n",
      "epoch:13 step:12347 [D loss: 0.609019, acc.: 67.19%] [G loss: 1.081539]\n",
      "epoch:13 step:12348 [D loss: 0.493172, acc.: 79.69%] [G loss: 1.134541]\n",
      "epoch:13 step:12349 [D loss: 0.574318, acc.: 69.53%] [G loss: 1.106829]\n",
      "epoch:13 step:12350 [D loss: 0.632041, acc.: 62.50%] [G loss: 1.110672]\n",
      "epoch:13 step:12351 [D loss: 0.536593, acc.: 75.00%] [G loss: 1.176162]\n",
      "epoch:13 step:12352 [D loss: 0.669243, acc.: 60.16%] [G loss: 1.243050]\n",
      "epoch:13 step:12353 [D loss: 0.597602, acc.: 67.97%] [G loss: 1.120738]\n",
      "epoch:13 step:12354 [D loss: 0.620734, acc.: 69.53%] [G loss: 1.267374]\n",
      "epoch:13 step:12355 [D loss: 0.625519, acc.: 66.41%] [G loss: 1.193989]\n",
      "epoch:13 step:12356 [D loss: 0.631760, acc.: 66.41%] [G loss: 1.211230]\n",
      "epoch:13 step:12357 [D loss: 0.587664, acc.: 72.66%] [G loss: 1.283272]\n",
      "epoch:13 step:12358 [D loss: 0.582445, acc.: 75.00%] [G loss: 1.149279]\n",
      "epoch:13 step:12359 [D loss: 0.514197, acc.: 78.12%] [G loss: 1.072276]\n",
      "epoch:13 step:12360 [D loss: 0.558237, acc.: 75.78%] [G loss: 1.265628]\n",
      "epoch:13 step:12361 [D loss: 0.507799, acc.: 79.69%] [G loss: 1.370027]\n",
      "epoch:13 step:12362 [D loss: 0.564350, acc.: 66.41%] [G loss: 1.226094]\n",
      "epoch:13 step:12363 [D loss: 0.624763, acc.: 64.84%] [G loss: 1.068935]\n",
      "epoch:13 step:12364 [D loss: 0.529844, acc.: 75.00%] [G loss: 1.221283]\n",
      "epoch:13 step:12365 [D loss: 0.690377, acc.: 59.38%] [G loss: 0.975896]\n",
      "epoch:13 step:12366 [D loss: 0.573227, acc.: 74.22%] [G loss: 1.289923]\n",
      "epoch:13 step:12367 [D loss: 0.599727, acc.: 68.75%] [G loss: 1.334687]\n",
      "epoch:13 step:12368 [D loss: 0.526780, acc.: 77.34%] [G loss: 1.231509]\n",
      "epoch:13 step:12369 [D loss: 0.639462, acc.: 65.62%] [G loss: 1.124000]\n",
      "epoch:13 step:12370 [D loss: 0.607560, acc.: 72.66%] [G loss: 1.216681]\n",
      "epoch:13 step:12371 [D loss: 0.615420, acc.: 68.75%] [G loss: 1.488841]\n",
      "epoch:13 step:12372 [D loss: 0.464119, acc.: 82.81%] [G loss: 1.231699]\n",
      "epoch:13 step:12373 [D loss: 0.605276, acc.: 67.97%] [G loss: 1.243886]\n",
      "epoch:13 step:12374 [D loss: 0.692161, acc.: 60.16%] [G loss: 1.162150]\n",
      "epoch:13 step:12375 [D loss: 0.610671, acc.: 63.28%] [G loss: 1.333711]\n",
      "epoch:13 step:12376 [D loss: 0.786077, acc.: 50.00%] [G loss: 0.945284]\n",
      "epoch:13 step:12377 [D loss: 0.655575, acc.: 60.94%] [G loss: 1.114888]\n",
      "epoch:13 step:12378 [D loss: 0.579216, acc.: 69.53%] [G loss: 1.030219]\n",
      "epoch:13 step:12379 [D loss: 0.652747, acc.: 64.84%] [G loss: 1.223917]\n",
      "epoch:13 step:12380 [D loss: 0.770815, acc.: 53.12%] [G loss: 0.934092]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:13 step:12381 [D loss: 0.595476, acc.: 64.06%] [G loss: 1.222659]\n",
      "epoch:13 step:12382 [D loss: 0.575416, acc.: 67.97%] [G loss: 1.207123]\n",
      "epoch:13 step:12383 [D loss: 0.636057, acc.: 65.62%] [G loss: 1.037175]\n",
      "epoch:13 step:12384 [D loss: 0.509451, acc.: 78.12%] [G loss: 1.123628]\n",
      "epoch:13 step:12385 [D loss: 0.551638, acc.: 74.22%] [G loss: 1.395076]\n",
      "epoch:13 step:12386 [D loss: 0.668242, acc.: 60.94%] [G loss: 1.220033]\n",
      "epoch:13 step:12387 [D loss: 0.587392, acc.: 68.75%] [G loss: 0.992018]\n",
      "epoch:13 step:12388 [D loss: 0.660761, acc.: 61.72%] [G loss: 0.970583]\n",
      "epoch:13 step:12389 [D loss: 0.524544, acc.: 77.34%] [G loss: 1.055024]\n",
      "epoch:13 step:12390 [D loss: 0.712133, acc.: 59.38%] [G loss: 1.251572]\n",
      "epoch:13 step:12391 [D loss: 0.656290, acc.: 60.16%] [G loss: 1.183494]\n",
      "epoch:13 step:12392 [D loss: 0.532866, acc.: 76.56%] [G loss: 1.261058]\n",
      "epoch:13 step:12393 [D loss: 0.601068, acc.: 71.09%] [G loss: 1.026783]\n",
      "epoch:13 step:12394 [D loss: 0.582488, acc.: 70.31%] [G loss: 1.010802]\n",
      "epoch:13 step:12395 [D loss: 0.705609, acc.: 60.94%] [G loss: 0.947369]\n",
      "epoch:13 step:12396 [D loss: 0.623348, acc.: 61.72%] [G loss: 1.096267]\n",
      "epoch:13 step:12397 [D loss: 0.571019, acc.: 70.31%] [G loss: 1.113199]\n",
      "epoch:13 step:12398 [D loss: 0.504936, acc.: 71.09%] [G loss: 1.095752]\n",
      "epoch:13 step:12399 [D loss: 0.612596, acc.: 65.62%] [G loss: 0.993107]\n",
      "epoch:13 step:12400 [D loss: 0.580183, acc.: 70.31%] [G loss: 1.139373]\n",
      "epoch:13 step:12401 [D loss: 0.646666, acc.: 65.62%] [G loss: 1.175749]\n",
      "epoch:13 step:12402 [D loss: 0.550991, acc.: 67.19%] [G loss: 1.327527]\n",
      "epoch:13 step:12403 [D loss: 0.675157, acc.: 57.03%] [G loss: 1.190400]\n",
      "epoch:13 step:12404 [D loss: 0.502004, acc.: 75.00%] [G loss: 1.251397]\n",
      "epoch:13 step:12405 [D loss: 0.605450, acc.: 67.19%] [G loss: 1.122662]\n",
      "epoch:13 step:12406 [D loss: 0.525567, acc.: 72.66%] [G loss: 1.180294]\n",
      "epoch:13 step:12407 [D loss: 0.533719, acc.: 77.34%] [G loss: 1.396885]\n",
      "epoch:13 step:12408 [D loss: 0.628125, acc.: 64.84%] [G loss: 1.008150]\n",
      "epoch:13 step:12409 [D loss: 0.627828, acc.: 66.41%] [G loss: 1.340801]\n",
      "epoch:13 step:12410 [D loss: 0.630645, acc.: 63.28%] [G loss: 1.352810]\n",
      "epoch:13 step:12411 [D loss: 0.580456, acc.: 68.75%] [G loss: 1.328496]\n",
      "epoch:13 step:12412 [D loss: 0.584476, acc.: 69.53%] [G loss: 1.425556]\n",
      "epoch:13 step:12413 [D loss: 0.513292, acc.: 75.78%] [G loss: 1.320273]\n",
      "epoch:13 step:12414 [D loss: 0.730864, acc.: 56.25%] [G loss: 1.351710]\n",
      "epoch:13 step:12415 [D loss: 0.663110, acc.: 64.06%] [G loss: 1.024040]\n",
      "epoch:13 step:12416 [D loss: 0.685377, acc.: 61.72%] [G loss: 1.033746]\n",
      "epoch:13 step:12417 [D loss: 0.604358, acc.: 66.41%] [G loss: 0.918185]\n",
      "epoch:13 step:12418 [D loss: 0.638955, acc.: 64.84%] [G loss: 0.978020]\n",
      "epoch:13 step:12419 [D loss: 0.753169, acc.: 51.56%] [G loss: 1.205244]\n",
      "epoch:13 step:12420 [D loss: 0.565831, acc.: 69.53%] [G loss: 1.184086]\n",
      "epoch:13 step:12421 [D loss: 0.592061, acc.: 71.09%] [G loss: 1.310303]\n",
      "epoch:13 step:12422 [D loss: 0.599877, acc.: 68.75%] [G loss: 1.118012]\n",
      "epoch:13 step:12423 [D loss: 0.733142, acc.: 53.91%] [G loss: 0.999595]\n",
      "epoch:13 step:12424 [D loss: 0.536366, acc.: 75.00%] [G loss: 1.056166]\n",
      "epoch:13 step:12425 [D loss: 0.514045, acc.: 72.66%] [G loss: 1.037331]\n",
      "epoch:13 step:12426 [D loss: 0.587079, acc.: 71.88%] [G loss: 1.051697]\n",
      "epoch:13 step:12427 [D loss: 0.544403, acc.: 71.88%] [G loss: 1.293665]\n",
      "epoch:13 step:12428 [D loss: 0.652746, acc.: 60.94%] [G loss: 0.970331]\n",
      "epoch:13 step:12429 [D loss: 0.536202, acc.: 72.66%] [G loss: 1.272282]\n",
      "epoch:13 step:12430 [D loss: 0.670167, acc.: 66.41%] [G loss: 1.147034]\n",
      "epoch:13 step:12431 [D loss: 0.624876, acc.: 65.62%] [G loss: 1.260427]\n",
      "epoch:13 step:12432 [D loss: 0.625963, acc.: 60.94%] [G loss: 1.231101]\n",
      "epoch:13 step:12433 [D loss: 0.498288, acc.: 79.69%] [G loss: 1.303206]\n",
      "epoch:13 step:12434 [D loss: 0.568952, acc.: 72.66%] [G loss: 1.322638]\n",
      "epoch:13 step:12435 [D loss: 0.605018, acc.: 68.75%] [G loss: 1.021064]\n",
      "epoch:13 step:12436 [D loss: 0.670161, acc.: 53.91%] [G loss: 1.153593]\n",
      "epoch:13 step:12437 [D loss: 0.586711, acc.: 72.66%] [G loss: 1.118139]\n",
      "epoch:13 step:12438 [D loss: 0.489303, acc.: 76.56%] [G loss: 1.220651]\n",
      "epoch:13 step:12439 [D loss: 0.600588, acc.: 69.53%] [G loss: 1.073199]\n",
      "epoch:13 step:12440 [D loss: 0.589444, acc.: 64.06%] [G loss: 1.039007]\n",
      "epoch:13 step:12441 [D loss: 0.628177, acc.: 64.06%] [G loss: 1.018021]\n",
      "epoch:13 step:12442 [D loss: 0.572500, acc.: 69.53%] [G loss: 1.010519]\n",
      "epoch:13 step:12443 [D loss: 0.726949, acc.: 54.69%] [G loss: 1.272692]\n",
      "epoch:13 step:12444 [D loss: 0.547573, acc.: 70.31%] [G loss: 1.234778]\n",
      "epoch:13 step:12445 [D loss: 0.603680, acc.: 60.94%] [G loss: 1.076845]\n",
      "epoch:13 step:12446 [D loss: 0.532638, acc.: 71.88%] [G loss: 1.233450]\n",
      "epoch:13 step:12447 [D loss: 0.634392, acc.: 63.28%] [G loss: 1.147231]\n",
      "epoch:13 step:12448 [D loss: 0.578321, acc.: 71.09%] [G loss: 1.229979]\n",
      "epoch:13 step:12449 [D loss: 0.589697, acc.: 71.09%] [G loss: 1.061695]\n",
      "epoch:13 step:12450 [D loss: 0.468794, acc.: 80.47%] [G loss: 1.299472]\n",
      "epoch:13 step:12451 [D loss: 0.615359, acc.: 67.19%] [G loss: 1.151198]\n",
      "epoch:13 step:12452 [D loss: 0.465885, acc.: 85.16%] [G loss: 1.224343]\n",
      "epoch:13 step:12453 [D loss: 0.598216, acc.: 67.19%] [G loss: 1.173324]\n",
      "epoch:13 step:12454 [D loss: 0.643354, acc.: 60.94%] [G loss: 1.170083]\n",
      "epoch:13 step:12455 [D loss: 0.682954, acc.: 57.03%] [G loss: 1.008339]\n",
      "epoch:13 step:12456 [D loss: 0.616399, acc.: 64.84%] [G loss: 1.348285]\n",
      "epoch:13 step:12457 [D loss: 0.721572, acc.: 55.47%] [G loss: 1.175699]\n",
      "epoch:13 step:12458 [D loss: 0.496010, acc.: 78.12%] [G loss: 1.320192]\n",
      "epoch:13 step:12459 [D loss: 0.563876, acc.: 71.88%] [G loss: 1.185160]\n",
      "epoch:13 step:12460 [D loss: 0.750510, acc.: 52.34%] [G loss: 0.953178]\n",
      "epoch:13 step:12461 [D loss: 0.555181, acc.: 72.66%] [G loss: 1.231796]\n",
      "epoch:13 step:12462 [D loss: 0.565184, acc.: 74.22%] [G loss: 1.251103]\n",
      "epoch:13 step:12463 [D loss: 0.626214, acc.: 65.62%] [G loss: 1.107274]\n",
      "epoch:13 step:12464 [D loss: 0.672891, acc.: 57.81%] [G loss: 1.255339]\n",
      "epoch:13 step:12465 [D loss: 0.675191, acc.: 60.16%] [G loss: 1.345687]\n",
      "epoch:13 step:12466 [D loss: 0.664864, acc.: 57.03%] [G loss: 1.176331]\n",
      "epoch:13 step:12467 [D loss: 0.644666, acc.: 66.41%] [G loss: 1.018817]\n",
      "epoch:13 step:12468 [D loss: 0.664543, acc.: 60.94%] [G loss: 1.034567]\n",
      "epoch:13 step:12469 [D loss: 0.548615, acc.: 71.09%] [G loss: 1.215652]\n",
      "epoch:13 step:12470 [D loss: 0.590584, acc.: 67.19%] [G loss: 1.193263]\n",
      "epoch:13 step:12471 [D loss: 0.577846, acc.: 61.72%] [G loss: 1.318681]\n",
      "epoch:13 step:12472 [D loss: 0.534845, acc.: 75.78%] [G loss: 1.232629]\n",
      "epoch:13 step:12473 [D loss: 0.673565, acc.: 60.94%] [G loss: 1.271271]\n",
      "epoch:13 step:12474 [D loss: 0.545647, acc.: 73.44%] [G loss: 1.203292]\n",
      "epoch:13 step:12475 [D loss: 0.547275, acc.: 76.56%] [G loss: 1.183748]\n",
      "epoch:13 step:12476 [D loss: 0.530094, acc.: 74.22%] [G loss: 1.186854]\n",
      "epoch:13 step:12477 [D loss: 0.533364, acc.: 71.09%] [G loss: 1.273925]\n",
      "epoch:13 step:12478 [D loss: 0.687670, acc.: 57.81%] [G loss: 0.977883]\n",
      "epoch:13 step:12479 [D loss: 0.683517, acc.: 64.06%] [G loss: 1.168667]\n",
      "epoch:13 step:12480 [D loss: 0.780868, acc.: 50.78%] [G loss: 1.095720]\n",
      "epoch:13 step:12481 [D loss: 0.571144, acc.: 68.75%] [G loss: 1.219799]\n",
      "epoch:13 step:12482 [D loss: 0.634231, acc.: 68.75%] [G loss: 1.105376]\n",
      "epoch:13 step:12483 [D loss: 0.541368, acc.: 78.91%] [G loss: 1.408835]\n",
      "epoch:13 step:12484 [D loss: 0.571567, acc.: 63.28%] [G loss: 1.314322]\n",
      "epoch:13 step:12485 [D loss: 0.560663, acc.: 70.31%] [G loss: 1.376505]\n",
      "epoch:13 step:12486 [D loss: 0.653967, acc.: 61.72%] [G loss: 1.287810]\n",
      "epoch:13 step:12487 [D loss: 0.596092, acc.: 67.97%] [G loss: 1.019075]\n",
      "epoch:13 step:12488 [D loss: 0.666569, acc.: 58.59%] [G loss: 1.283491]\n",
      "epoch:13 step:12489 [D loss: 0.548436, acc.: 72.66%] [G loss: 1.061516]\n",
      "epoch:13 step:12490 [D loss: 0.466610, acc.: 79.69%] [G loss: 1.117522]\n",
      "epoch:13 step:12491 [D loss: 0.618606, acc.: 67.19%] [G loss: 1.250926]\n",
      "epoch:13 step:12492 [D loss: 0.569482, acc.: 71.09%] [G loss: 1.273003]\n",
      "epoch:13 step:12493 [D loss: 0.552241, acc.: 70.31%] [G loss: 1.043974]\n",
      "epoch:13 step:12494 [D loss: 0.612324, acc.: 67.97%] [G loss: 1.128403]\n",
      "epoch:13 step:12495 [D loss: 0.532934, acc.: 73.44%] [G loss: 0.973560]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:13 step:12496 [D loss: 0.546118, acc.: 74.22%] [G loss: 1.200114]\n",
      "epoch:13 step:12497 [D loss: 0.690485, acc.: 60.94%] [G loss: 1.094820]\n",
      "epoch:13 step:12498 [D loss: 0.683681, acc.: 61.72%] [G loss: 1.273497]\n",
      "epoch:13 step:12499 [D loss: 0.532112, acc.: 77.34%] [G loss: 1.223533]\n",
      "epoch:13 step:12500 [D loss: 0.563152, acc.: 72.66%] [G loss: 1.161353]\n",
      "epoch:13 step:12501 [D loss: 0.624976, acc.: 64.06%] [G loss: 0.865249]\n",
      "epoch:13 step:12502 [D loss: 0.647143, acc.: 63.28%] [G loss: 1.328395]\n",
      "epoch:13 step:12503 [D loss: 0.646043, acc.: 61.72%] [G loss: 1.125689]\n",
      "epoch:13 step:12504 [D loss: 0.557095, acc.: 67.19%] [G loss: 1.242622]\n",
      "epoch:13 step:12505 [D loss: 0.547707, acc.: 77.34%] [G loss: 1.124452]\n",
      "epoch:13 step:12506 [D loss: 0.569790, acc.: 71.88%] [G loss: 1.165418]\n",
      "epoch:13 step:12507 [D loss: 0.719477, acc.: 53.91%] [G loss: 1.085274]\n",
      "epoch:13 step:12508 [D loss: 0.481144, acc.: 78.12%] [G loss: 1.272290]\n",
      "epoch:13 step:12509 [D loss: 0.471201, acc.: 82.03%] [G loss: 1.362967]\n",
      "epoch:13 step:12510 [D loss: 0.707341, acc.: 57.03%] [G loss: 0.852325]\n",
      "epoch:13 step:12511 [D loss: 0.714616, acc.: 54.69%] [G loss: 1.132140]\n",
      "epoch:13 step:12512 [D loss: 0.525088, acc.: 78.12%] [G loss: 1.235554]\n",
      "epoch:13 step:12513 [D loss: 0.643599, acc.: 60.94%] [G loss: 1.201150]\n",
      "epoch:13 step:12514 [D loss: 0.625369, acc.: 67.19%] [G loss: 1.140029]\n",
      "epoch:13 step:12515 [D loss: 0.522808, acc.: 77.34%] [G loss: 1.015926]\n",
      "epoch:13 step:12516 [D loss: 0.591588, acc.: 66.41%] [G loss: 1.435769]\n",
      "epoch:13 step:12517 [D loss: 0.536833, acc.: 76.56%] [G loss: 1.078363]\n",
      "epoch:13 step:12518 [D loss: 0.688202, acc.: 61.72%] [G loss: 1.206058]\n",
      "epoch:13 step:12519 [D loss: 0.557945, acc.: 69.53%] [G loss: 1.113726]\n",
      "epoch:13 step:12520 [D loss: 0.661552, acc.: 62.50%] [G loss: 1.046818]\n",
      "epoch:13 step:12521 [D loss: 0.473804, acc.: 80.47%] [G loss: 1.592682]\n",
      "epoch:13 step:12522 [D loss: 0.639733, acc.: 64.06%] [G loss: 1.154623]\n",
      "epoch:13 step:12523 [D loss: 0.573015, acc.: 71.09%] [G loss: 1.217464]\n",
      "epoch:13 step:12524 [D loss: 0.555498, acc.: 71.09%] [G loss: 1.071031]\n",
      "epoch:13 step:12525 [D loss: 0.685664, acc.: 57.03%] [G loss: 1.065054]\n",
      "epoch:13 step:12526 [D loss: 0.502519, acc.: 75.00%] [G loss: 1.326084]\n",
      "epoch:13 step:12527 [D loss: 0.677902, acc.: 61.72%] [G loss: 1.132803]\n",
      "epoch:13 step:12528 [D loss: 0.675720, acc.: 60.16%] [G loss: 0.917986]\n",
      "epoch:13 step:12529 [D loss: 0.543166, acc.: 71.09%] [G loss: 1.114321]\n",
      "epoch:13 step:12530 [D loss: 0.567428, acc.: 66.41%] [G loss: 1.152423]\n",
      "epoch:13 step:12531 [D loss: 0.640222, acc.: 67.19%] [G loss: 0.985445]\n",
      "epoch:13 step:12532 [D loss: 0.560919, acc.: 66.41%] [G loss: 1.213852]\n",
      "epoch:13 step:12533 [D loss: 0.580074, acc.: 67.19%] [G loss: 1.107245]\n",
      "epoch:13 step:12534 [D loss: 0.672182, acc.: 59.38%] [G loss: 1.033787]\n",
      "epoch:13 step:12535 [D loss: 0.638367, acc.: 70.31%] [G loss: 0.966849]\n",
      "epoch:13 step:12536 [D loss: 0.560760, acc.: 72.66%] [G loss: 1.170700]\n",
      "epoch:13 step:12537 [D loss: 0.561646, acc.: 67.97%] [G loss: 1.204654]\n",
      "epoch:13 step:12538 [D loss: 0.536651, acc.: 71.88%] [G loss: 1.187073]\n",
      "epoch:13 step:12539 [D loss: 0.594936, acc.: 67.19%] [G loss: 1.140609]\n",
      "epoch:13 step:12540 [D loss: 0.611753, acc.: 60.94%] [G loss: 1.130454]\n",
      "epoch:13 step:12541 [D loss: 0.560606, acc.: 71.88%] [G loss: 0.960829]\n",
      "epoch:13 step:12542 [D loss: 0.610180, acc.: 67.97%] [G loss: 1.099113]\n",
      "epoch:13 step:12543 [D loss: 0.752668, acc.: 47.66%] [G loss: 1.067401]\n",
      "epoch:13 step:12544 [D loss: 0.555789, acc.: 73.44%] [G loss: 1.229631]\n",
      "epoch:13 step:12545 [D loss: 0.578420, acc.: 62.50%] [G loss: 1.319330]\n",
      "epoch:13 step:12546 [D loss: 0.553292, acc.: 72.66%] [G loss: 1.454268]\n",
      "epoch:13 step:12547 [D loss: 0.566901, acc.: 71.88%] [G loss: 1.106686]\n",
      "epoch:13 step:12548 [D loss: 0.609567, acc.: 70.31%] [G loss: 1.205665]\n",
      "epoch:13 step:12549 [D loss: 0.550437, acc.: 74.22%] [G loss: 1.205981]\n",
      "epoch:13 step:12550 [D loss: 0.526048, acc.: 76.56%] [G loss: 1.473359]\n",
      "epoch:13 step:12551 [D loss: 0.641019, acc.: 64.06%] [G loss: 1.285863]\n",
      "epoch:13 step:12552 [D loss: 0.520757, acc.: 71.09%] [G loss: 1.305831]\n",
      "epoch:13 step:12553 [D loss: 0.537610, acc.: 72.66%] [G loss: 1.253923]\n",
      "epoch:13 step:12554 [D loss: 0.491053, acc.: 77.34%] [G loss: 1.080397]\n",
      "epoch:13 step:12555 [D loss: 0.629279, acc.: 67.19%] [G loss: 1.149674]\n",
      "epoch:13 step:12556 [D loss: 0.653435, acc.: 66.41%] [G loss: 1.172904]\n",
      "epoch:13 step:12557 [D loss: 0.548733, acc.: 75.00%] [G loss: 1.044672]\n",
      "epoch:13 step:12558 [D loss: 0.633117, acc.: 67.19%] [G loss: 1.049521]\n",
      "epoch:13 step:12559 [D loss: 0.641197, acc.: 67.19%] [G loss: 1.004989]\n",
      "epoch:13 step:12560 [D loss: 0.462226, acc.: 81.25%] [G loss: 1.427817]\n",
      "epoch:13 step:12561 [D loss: 0.814299, acc.: 47.66%] [G loss: 1.097450]\n",
      "epoch:13 step:12562 [D loss: 0.604410, acc.: 65.62%] [G loss: 1.241451]\n",
      "epoch:13 step:12563 [D loss: 0.539117, acc.: 75.00%] [G loss: 1.213592]\n",
      "epoch:13 step:12564 [D loss: 0.570490, acc.: 67.97%] [G loss: 1.230557]\n",
      "epoch:13 step:12565 [D loss: 0.577976, acc.: 71.09%] [G loss: 1.300877]\n",
      "epoch:13 step:12566 [D loss: 0.655158, acc.: 59.38%] [G loss: 0.915755]\n",
      "epoch:13 step:12567 [D loss: 0.464211, acc.: 82.03%] [G loss: 1.356406]\n",
      "epoch:13 step:12568 [D loss: 0.493978, acc.: 82.03%] [G loss: 1.076636]\n",
      "epoch:13 step:12569 [D loss: 0.687387, acc.: 56.25%] [G loss: 0.954320]\n",
      "epoch:13 step:12570 [D loss: 0.622700, acc.: 61.72%] [G loss: 1.344482]\n",
      "epoch:13 step:12571 [D loss: 0.574291, acc.: 67.97%] [G loss: 1.080679]\n",
      "epoch:13 step:12572 [D loss: 0.686626, acc.: 63.28%] [G loss: 0.971889]\n",
      "epoch:13 step:12573 [D loss: 0.489394, acc.: 78.91%] [G loss: 1.146943]\n",
      "epoch:13 step:12574 [D loss: 0.682412, acc.: 57.81%] [G loss: 1.037265]\n",
      "epoch:13 step:12575 [D loss: 0.654346, acc.: 62.50%] [G loss: 0.998539]\n",
      "epoch:13 step:12576 [D loss: 0.545713, acc.: 75.78%] [G loss: 1.157662]\n",
      "epoch:13 step:12577 [D loss: 0.598312, acc.: 64.06%] [G loss: 1.148176]\n",
      "epoch:13 step:12578 [D loss: 0.595241, acc.: 68.75%] [G loss: 1.288627]\n",
      "epoch:13 step:12579 [D loss: 0.641155, acc.: 67.97%] [G loss: 1.040477]\n",
      "epoch:13 step:12580 [D loss: 0.622784, acc.: 64.06%] [G loss: 1.072287]\n",
      "epoch:13 step:12581 [D loss: 0.583073, acc.: 68.75%] [G loss: 1.369231]\n",
      "epoch:13 step:12582 [D loss: 0.571063, acc.: 75.00%] [G loss: 1.107529]\n",
      "epoch:13 step:12583 [D loss: 0.524339, acc.: 75.78%] [G loss: 1.275286]\n",
      "epoch:13 step:12584 [D loss: 0.632909, acc.: 56.25%] [G loss: 1.049990]\n",
      "epoch:13 step:12585 [D loss: 0.664984, acc.: 60.94%] [G loss: 1.179262]\n",
      "epoch:13 step:12586 [D loss: 0.492376, acc.: 76.56%] [G loss: 1.200031]\n",
      "epoch:13 step:12587 [D loss: 0.644411, acc.: 64.06%] [G loss: 1.131960]\n",
      "epoch:13 step:12588 [D loss: 0.543097, acc.: 74.22%] [G loss: 1.186882]\n",
      "epoch:13 step:12589 [D loss: 0.620260, acc.: 63.28%] [G loss: 1.135459]\n",
      "epoch:13 step:12590 [D loss: 0.551100, acc.: 70.31%] [G loss: 1.047872]\n",
      "epoch:13 step:12591 [D loss: 0.700498, acc.: 58.59%] [G loss: 1.171374]\n",
      "epoch:13 step:12592 [D loss: 0.568591, acc.: 67.97%] [G loss: 1.323698]\n",
      "epoch:13 step:12593 [D loss: 0.617731, acc.: 67.19%] [G loss: 1.225027]\n",
      "epoch:13 step:12594 [D loss: 0.537708, acc.: 75.00%] [G loss: 1.129670]\n",
      "epoch:13 step:12595 [D loss: 0.629490, acc.: 67.97%] [G loss: 1.177271]\n",
      "epoch:13 step:12596 [D loss: 0.547685, acc.: 71.09%] [G loss: 1.128019]\n",
      "epoch:13 step:12597 [D loss: 0.631506, acc.: 60.16%] [G loss: 0.878601]\n",
      "epoch:13 step:12598 [D loss: 0.610960, acc.: 62.50%] [G loss: 1.060702]\n",
      "epoch:13 step:12599 [D loss: 0.608661, acc.: 64.06%] [G loss: 1.220250]\n",
      "epoch:13 step:12600 [D loss: 0.554085, acc.: 72.66%] [G loss: 1.418639]\n",
      "epoch:13 step:12601 [D loss: 0.478016, acc.: 80.47%] [G loss: 1.137356]\n",
      "epoch:13 step:12602 [D loss: 0.658283, acc.: 62.50%] [G loss: 0.796841]\n",
      "epoch:13 step:12603 [D loss: 0.660396, acc.: 57.81%] [G loss: 0.917971]\n",
      "epoch:13 step:12604 [D loss: 0.602765, acc.: 67.19%] [G loss: 1.244178]\n",
      "epoch:13 step:12605 [D loss: 0.544062, acc.: 75.78%] [G loss: 1.057687]\n",
      "epoch:13 step:12606 [D loss: 0.597634, acc.: 66.41%] [G loss: 1.106680]\n",
      "epoch:13 step:12607 [D loss: 0.701339, acc.: 54.69%] [G loss: 1.037979]\n",
      "epoch:13 step:12608 [D loss: 0.575708, acc.: 64.84%] [G loss: 1.213549]\n",
      "epoch:13 step:12609 [D loss: 0.637849, acc.: 58.59%] [G loss: 0.975992]\n",
      "epoch:13 step:12610 [D loss: 0.626193, acc.: 68.75%] [G loss: 0.955636]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:13 step:12611 [D loss: 0.645661, acc.: 57.81%] [G loss: 1.135462]\n",
      "epoch:13 step:12612 [D loss: 0.553631, acc.: 67.97%] [G loss: 1.546315]\n",
      "epoch:13 step:12613 [D loss: 0.510151, acc.: 76.56%] [G loss: 1.165831]\n",
      "epoch:13 step:12614 [D loss: 0.594405, acc.: 68.75%] [G loss: 1.279062]\n",
      "epoch:13 step:12615 [D loss: 0.595062, acc.: 72.66%] [G loss: 1.230175]\n",
      "epoch:13 step:12616 [D loss: 0.531070, acc.: 75.78%] [G loss: 1.123498]\n",
      "epoch:13 step:12617 [D loss: 0.477297, acc.: 76.56%] [G loss: 1.259147]\n",
      "epoch:13 step:12618 [D loss: 0.637245, acc.: 65.62%] [G loss: 1.299350]\n",
      "epoch:13 step:12619 [D loss: 0.513097, acc.: 78.91%] [G loss: 0.876057]\n",
      "epoch:13 step:12620 [D loss: 0.570905, acc.: 73.44%] [G loss: 1.127218]\n",
      "epoch:13 step:12621 [D loss: 0.672996, acc.: 60.16%] [G loss: 1.220343]\n",
      "epoch:13 step:12622 [D loss: 0.571349, acc.: 71.88%] [G loss: 1.094199]\n",
      "epoch:13 step:12623 [D loss: 0.507286, acc.: 78.12%] [G loss: 1.468273]\n",
      "epoch:13 step:12624 [D loss: 0.609840, acc.: 65.62%] [G loss: 1.037758]\n",
      "epoch:13 step:12625 [D loss: 0.581666, acc.: 68.75%] [G loss: 1.298720]\n",
      "epoch:13 step:12626 [D loss: 0.519654, acc.: 71.88%] [G loss: 1.100854]\n",
      "epoch:13 step:12627 [D loss: 0.573091, acc.: 73.44%] [G loss: 1.193917]\n",
      "epoch:13 step:12628 [D loss: 0.663659, acc.: 61.72%] [G loss: 1.215213]\n",
      "epoch:13 step:12629 [D loss: 0.626967, acc.: 66.41%] [G loss: 1.085594]\n",
      "epoch:13 step:12630 [D loss: 0.548681, acc.: 71.88%] [G loss: 0.988206]\n",
      "epoch:13 step:12631 [D loss: 0.624555, acc.: 63.28%] [G loss: 1.288368]\n",
      "epoch:13 step:12632 [D loss: 0.429717, acc.: 86.72%] [G loss: 1.346600]\n",
      "epoch:13 step:12633 [D loss: 0.662668, acc.: 62.50%] [G loss: 1.230841]\n",
      "epoch:13 step:12634 [D loss: 0.522619, acc.: 75.78%] [G loss: 0.993072]\n",
      "epoch:13 step:12635 [D loss: 0.581423, acc.: 70.31%] [G loss: 1.329175]\n",
      "epoch:13 step:12636 [D loss: 0.613031, acc.: 64.84%] [G loss: 1.294468]\n",
      "epoch:13 step:12637 [D loss: 0.656225, acc.: 62.50%] [G loss: 1.195264]\n",
      "epoch:13 step:12638 [D loss: 0.709844, acc.: 55.47%] [G loss: 1.105671]\n",
      "epoch:13 step:12639 [D loss: 0.569422, acc.: 66.41%] [G loss: 1.335271]\n",
      "epoch:13 step:12640 [D loss: 0.467256, acc.: 79.69%] [G loss: 1.157687]\n",
      "epoch:13 step:12641 [D loss: 0.534626, acc.: 74.22%] [G loss: 1.013809]\n",
      "epoch:13 step:12642 [D loss: 0.621424, acc.: 61.72%] [G loss: 1.045111]\n",
      "epoch:13 step:12643 [D loss: 0.581541, acc.: 69.53%] [G loss: 1.197042]\n",
      "epoch:13 step:12644 [D loss: 0.592366, acc.: 65.62%] [G loss: 1.067496]\n",
      "epoch:13 step:12645 [D loss: 0.559562, acc.: 70.31%] [G loss: 0.979359]\n",
      "epoch:13 step:12646 [D loss: 0.564729, acc.: 68.75%] [G loss: 1.222006]\n",
      "epoch:13 step:12647 [D loss: 0.702547, acc.: 57.81%] [G loss: 0.956514]\n",
      "epoch:13 step:12648 [D loss: 0.578140, acc.: 68.75%] [G loss: 1.187380]\n",
      "epoch:13 step:12649 [D loss: 0.469425, acc.: 82.81%] [G loss: 1.450360]\n",
      "epoch:13 step:12650 [D loss: 0.530073, acc.: 75.78%] [G loss: 1.346541]\n",
      "epoch:13 step:12651 [D loss: 0.702182, acc.: 54.69%] [G loss: 1.157834]\n",
      "epoch:13 step:12652 [D loss: 0.649550, acc.: 59.38%] [G loss: 1.059879]\n",
      "epoch:13 step:12653 [D loss: 0.536946, acc.: 75.78%] [G loss: 1.005513]\n",
      "epoch:13 step:12654 [D loss: 0.516742, acc.: 76.56%] [G loss: 1.214380]\n",
      "epoch:13 step:12655 [D loss: 0.613212, acc.: 66.41%] [G loss: 1.310364]\n",
      "epoch:13 step:12656 [D loss: 0.519879, acc.: 74.22%] [G loss: 1.231511]\n",
      "epoch:13 step:12657 [D loss: 0.574417, acc.: 70.31%] [G loss: 1.198186]\n",
      "epoch:13 step:12658 [D loss: 0.617372, acc.: 60.94%] [G loss: 1.247026]\n",
      "epoch:13 step:12659 [D loss: 0.682107, acc.: 59.38%] [G loss: 1.171361]\n",
      "epoch:13 step:12660 [D loss: 0.640580, acc.: 62.50%] [G loss: 1.085880]\n",
      "epoch:13 step:12661 [D loss: 0.583018, acc.: 68.75%] [G loss: 1.164473]\n",
      "epoch:13 step:12662 [D loss: 0.581586, acc.: 68.75%] [G loss: 1.064721]\n",
      "epoch:13 step:12663 [D loss: 0.607443, acc.: 66.41%] [G loss: 1.189850]\n",
      "epoch:13 step:12664 [D loss: 0.526605, acc.: 77.34%] [G loss: 1.353783]\n",
      "epoch:13 step:12665 [D loss: 0.468429, acc.: 83.59%] [G loss: 1.167090]\n",
      "epoch:13 step:12666 [D loss: 0.581865, acc.: 71.09%] [G loss: 1.225067]\n",
      "epoch:13 step:12667 [D loss: 0.537728, acc.: 72.66%] [G loss: 1.180520]\n",
      "epoch:13 step:12668 [D loss: 0.539430, acc.: 71.88%] [G loss: 1.227519]\n",
      "epoch:13 step:12669 [D loss: 0.479172, acc.: 82.81%] [G loss: 1.340423]\n",
      "epoch:13 step:12670 [D loss: 0.594488, acc.: 73.44%] [G loss: 1.159327]\n",
      "epoch:13 step:12671 [D loss: 0.654315, acc.: 65.62%] [G loss: 1.118607]\n",
      "epoch:13 step:12672 [D loss: 0.525631, acc.: 77.34%] [G loss: 1.394951]\n",
      "epoch:13 step:12673 [D loss: 0.604998, acc.: 68.75%] [G loss: 1.133276]\n",
      "epoch:13 step:12674 [D loss: 0.562158, acc.: 69.53%] [G loss: 1.304423]\n",
      "epoch:13 step:12675 [D loss: 0.510435, acc.: 78.12%] [G loss: 1.327884]\n",
      "epoch:13 step:12676 [D loss: 0.694515, acc.: 56.25%] [G loss: 1.106041]\n",
      "epoch:13 step:12677 [D loss: 0.536555, acc.: 74.22%] [G loss: 1.172804]\n",
      "epoch:13 step:12678 [D loss: 0.664608, acc.: 61.72%] [G loss: 1.239804]\n",
      "epoch:13 step:12679 [D loss: 0.588699, acc.: 70.31%] [G loss: 1.311762]\n",
      "epoch:13 step:12680 [D loss: 0.524155, acc.: 75.78%] [G loss: 1.360737]\n",
      "epoch:13 step:12681 [D loss: 0.632565, acc.: 60.94%] [G loss: 1.201180]\n",
      "epoch:13 step:12682 [D loss: 0.599675, acc.: 67.97%] [G loss: 0.986787]\n",
      "epoch:13 step:12683 [D loss: 0.561725, acc.: 72.66%] [G loss: 1.404909]\n",
      "epoch:13 step:12684 [D loss: 0.518511, acc.: 75.78%] [G loss: 1.198890]\n",
      "epoch:13 step:12685 [D loss: 0.657116, acc.: 60.16%] [G loss: 1.068546]\n",
      "epoch:13 step:12686 [D loss: 0.506623, acc.: 73.44%] [G loss: 1.254408]\n",
      "epoch:13 step:12687 [D loss: 0.596536, acc.: 62.50%] [G loss: 1.136747]\n",
      "epoch:13 step:12688 [D loss: 0.706245, acc.: 60.16%] [G loss: 1.223110]\n",
      "epoch:13 step:12689 [D loss: 0.525678, acc.: 73.44%] [G loss: 1.232534]\n",
      "epoch:13 step:12690 [D loss: 0.563014, acc.: 68.75%] [G loss: 1.130914]\n",
      "epoch:13 step:12691 [D loss: 0.615792, acc.: 71.09%] [G loss: 0.963443]\n",
      "epoch:13 step:12692 [D loss: 0.623460, acc.: 67.19%] [G loss: 1.106180]\n",
      "epoch:13 step:12693 [D loss: 0.573992, acc.: 68.75%] [G loss: 1.110847]\n",
      "epoch:13 step:12694 [D loss: 0.515851, acc.: 75.00%] [G loss: 1.096822]\n",
      "epoch:13 step:12695 [D loss: 0.547656, acc.: 76.56%] [G loss: 1.181208]\n",
      "epoch:13 step:12696 [D loss: 0.452026, acc.: 82.81%] [G loss: 1.263542]\n",
      "epoch:13 step:12697 [D loss: 0.553771, acc.: 74.22%] [G loss: 1.255791]\n",
      "epoch:13 step:12698 [D loss: 0.590219, acc.: 71.09%] [G loss: 1.103500]\n",
      "epoch:13 step:12699 [D loss: 0.587944, acc.: 64.84%] [G loss: 1.258183]\n",
      "epoch:13 step:12700 [D loss: 0.612956, acc.: 70.31%] [G loss: 1.341222]\n",
      "epoch:13 step:12701 [D loss: 0.622511, acc.: 64.84%] [G loss: 1.527057]\n",
      "epoch:13 step:12702 [D loss: 0.636053, acc.: 61.72%] [G loss: 1.393174]\n",
      "epoch:13 step:12703 [D loss: 0.612602, acc.: 64.84%] [G loss: 1.304682]\n",
      "epoch:13 step:12704 [D loss: 0.522237, acc.: 78.91%] [G loss: 1.366349]\n",
      "epoch:13 step:12705 [D loss: 0.498444, acc.: 80.47%] [G loss: 1.191403]\n",
      "epoch:13 step:12706 [D loss: 0.575646, acc.: 73.44%] [G loss: 1.185301]\n",
      "epoch:13 step:12707 [D loss: 0.738463, acc.: 57.81%] [G loss: 1.174225]\n",
      "epoch:13 step:12708 [D loss: 0.639079, acc.: 60.94%] [G loss: 1.126959]\n",
      "epoch:13 step:12709 [D loss: 0.589350, acc.: 69.53%] [G loss: 1.074586]\n",
      "epoch:13 step:12710 [D loss: 0.540916, acc.: 77.34%] [G loss: 1.333230]\n",
      "epoch:13 step:12711 [D loss: 0.702859, acc.: 53.91%] [G loss: 0.967984]\n",
      "epoch:13 step:12712 [D loss: 0.568136, acc.: 70.31%] [G loss: 1.165914]\n",
      "epoch:13 step:12713 [D loss: 0.554753, acc.: 77.34%] [G loss: 1.039157]\n",
      "epoch:13 step:12714 [D loss: 0.584287, acc.: 65.62%] [G loss: 0.931385]\n",
      "epoch:13 step:12715 [D loss: 0.728035, acc.: 54.69%] [G loss: 1.139457]\n",
      "epoch:13 step:12716 [D loss: 0.563267, acc.: 68.75%] [G loss: 1.490335]\n",
      "epoch:13 step:12717 [D loss: 0.654684, acc.: 65.62%] [G loss: 1.367662]\n",
      "epoch:13 step:12718 [D loss: 0.686059, acc.: 61.72%] [G loss: 1.123123]\n",
      "epoch:13 step:12719 [D loss: 0.556789, acc.: 69.53%] [G loss: 1.233932]\n",
      "epoch:13 step:12720 [D loss: 0.627665, acc.: 68.75%] [G loss: 1.175898]\n",
      "epoch:13 step:12721 [D loss: 0.499950, acc.: 80.47%] [G loss: 1.232893]\n",
      "epoch:13 step:12722 [D loss: 0.631662, acc.: 64.06%] [G loss: 0.956385]\n",
      "epoch:13 step:12723 [D loss: 0.549417, acc.: 75.78%] [G loss: 1.281441]\n",
      "epoch:13 step:12724 [D loss: 0.569693, acc.: 68.75%] [G loss: 0.820603]\n",
      "epoch:13 step:12725 [D loss: 0.540293, acc.: 72.66%] [G loss: 1.191418]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:13 step:12726 [D loss: 0.505165, acc.: 75.00%] [G loss: 1.153821]\n",
      "epoch:13 step:12727 [D loss: 0.625204, acc.: 65.62%] [G loss: 1.045838]\n",
      "epoch:13 step:12728 [D loss: 0.554161, acc.: 69.53%] [G loss: 1.402210]\n",
      "epoch:13 step:12729 [D loss: 0.597715, acc.: 62.50%] [G loss: 1.249865]\n",
      "epoch:13 step:12730 [D loss: 0.577757, acc.: 69.53%] [G loss: 1.171438]\n",
      "epoch:13 step:12731 [D loss: 0.510908, acc.: 79.69%] [G loss: 1.403717]\n",
      "epoch:13 step:12732 [D loss: 0.650716, acc.: 60.16%] [G loss: 1.056211]\n",
      "epoch:13 step:12733 [D loss: 0.549885, acc.: 71.09%] [G loss: 1.341814]\n",
      "epoch:13 step:12734 [D loss: 0.642646, acc.: 62.50%] [G loss: 1.254970]\n",
      "epoch:13 step:12735 [D loss: 0.630136, acc.: 60.16%] [G loss: 1.274659]\n",
      "epoch:13 step:12736 [D loss: 0.643393, acc.: 62.50%] [G loss: 1.028215]\n",
      "epoch:13 step:12737 [D loss: 0.628689, acc.: 67.19%] [G loss: 1.231941]\n",
      "epoch:13 step:12738 [D loss: 0.665699, acc.: 59.38%] [G loss: 1.217717]\n",
      "epoch:13 step:12739 [D loss: 0.568249, acc.: 70.31%] [G loss: 1.242647]\n",
      "epoch:13 step:12740 [D loss: 0.598271, acc.: 66.41%] [G loss: 1.182277]\n",
      "epoch:13 step:12741 [D loss: 0.593425, acc.: 67.19%] [G loss: 1.121600]\n",
      "epoch:13 step:12742 [D loss: 0.513039, acc.: 71.88%] [G loss: 1.424697]\n",
      "epoch:13 step:12743 [D loss: 0.557692, acc.: 71.88%] [G loss: 1.078299]\n",
      "epoch:13 step:12744 [D loss: 0.597530, acc.: 68.75%] [G loss: 1.303071]\n",
      "epoch:13 step:12745 [D loss: 0.546270, acc.: 75.00%] [G loss: 1.335516]\n",
      "epoch:13 step:12746 [D loss: 0.545019, acc.: 78.12%] [G loss: 1.353688]\n",
      "epoch:13 step:12747 [D loss: 0.580243, acc.: 64.06%] [G loss: 1.486989]\n",
      "epoch:13 step:12748 [D loss: 0.636011, acc.: 61.72%] [G loss: 1.321915]\n",
      "epoch:13 step:12749 [D loss: 0.629044, acc.: 64.06%] [G loss: 1.511916]\n",
      "epoch:13 step:12750 [D loss: 0.631644, acc.: 61.72%] [G loss: 1.042841]\n",
      "epoch:13 step:12751 [D loss: 0.607490, acc.: 67.19%] [G loss: 1.307634]\n",
      "epoch:13 step:12752 [D loss: 0.478702, acc.: 82.03%] [G loss: 1.205439]\n",
      "epoch:13 step:12753 [D loss: 0.473536, acc.: 82.03%] [G loss: 1.321338]\n",
      "epoch:13 step:12754 [D loss: 0.697262, acc.: 52.34%] [G loss: 1.332243]\n",
      "epoch:13 step:12755 [D loss: 0.579728, acc.: 71.88%] [G loss: 1.186683]\n",
      "epoch:13 step:12756 [D loss: 0.541537, acc.: 70.31%] [G loss: 1.068726]\n",
      "epoch:13 step:12757 [D loss: 0.536601, acc.: 75.78%] [G loss: 1.086383]\n",
      "epoch:13 step:12758 [D loss: 0.605111, acc.: 71.09%] [G loss: 1.346600]\n",
      "epoch:13 step:12759 [D loss: 0.518439, acc.: 76.56%] [G loss: 1.123869]\n",
      "epoch:13 step:12760 [D loss: 0.570875, acc.: 69.53%] [G loss: 1.034745]\n",
      "epoch:13 step:12761 [D loss: 0.583505, acc.: 69.53%] [G loss: 1.049076]\n",
      "epoch:13 step:12762 [D loss: 0.547775, acc.: 66.41%] [G loss: 1.281483]\n",
      "epoch:13 step:12763 [D loss: 0.599538, acc.: 66.41%] [G loss: 1.074792]\n",
      "epoch:13 step:12764 [D loss: 0.563159, acc.: 73.44%] [G loss: 1.150207]\n",
      "epoch:13 step:12765 [D loss: 0.604494, acc.: 67.97%] [G loss: 1.370647]\n",
      "epoch:13 step:12766 [D loss: 0.756785, acc.: 52.34%] [G loss: 0.946323]\n",
      "epoch:13 step:12767 [D loss: 0.615091, acc.: 70.31%] [G loss: 1.229326]\n",
      "epoch:13 step:12768 [D loss: 0.651023, acc.: 58.59%] [G loss: 1.233367]\n",
      "epoch:13 step:12769 [D loss: 0.663701, acc.: 63.28%] [G loss: 1.186658]\n",
      "epoch:13 step:12770 [D loss: 0.502716, acc.: 75.78%] [G loss: 1.284761]\n",
      "epoch:13 step:12771 [D loss: 0.397280, acc.: 92.19%] [G loss: 1.547022]\n",
      "epoch:13 step:12772 [D loss: 0.579558, acc.: 67.97%] [G loss: 1.140831]\n",
      "epoch:13 step:12773 [D loss: 0.592925, acc.: 71.09%] [G loss: 0.979326]\n",
      "epoch:13 step:12774 [D loss: 0.740601, acc.: 52.34%] [G loss: 0.935776]\n",
      "epoch:13 step:12775 [D loss: 0.544238, acc.: 70.31%] [G loss: 1.307593]\n",
      "epoch:13 step:12776 [D loss: 0.611290, acc.: 68.75%] [G loss: 1.066000]\n",
      "epoch:13 step:12777 [D loss: 0.596576, acc.: 67.97%] [G loss: 1.151780]\n",
      "epoch:13 step:12778 [D loss: 0.587310, acc.: 69.53%] [G loss: 1.114882]\n",
      "epoch:13 step:12779 [D loss: 0.765552, acc.: 52.34%] [G loss: 1.102209]\n",
      "epoch:13 step:12780 [D loss: 0.647707, acc.: 65.62%] [G loss: 0.952545]\n",
      "epoch:13 step:12781 [D loss: 0.503197, acc.: 75.00%] [G loss: 1.135580]\n",
      "epoch:13 step:12782 [D loss: 0.706367, acc.: 56.25%] [G loss: 1.169795]\n",
      "epoch:13 step:12783 [D loss: 0.567701, acc.: 71.88%] [G loss: 1.301573]\n",
      "epoch:13 step:12784 [D loss: 0.592790, acc.: 70.31%] [G loss: 1.440910]\n",
      "epoch:13 step:12785 [D loss: 0.663250, acc.: 61.72%] [G loss: 1.203612]\n",
      "epoch:13 step:12786 [D loss: 0.607074, acc.: 65.62%] [G loss: 1.135182]\n",
      "epoch:13 step:12787 [D loss: 0.693228, acc.: 55.47%] [G loss: 1.285791]\n",
      "epoch:13 step:12788 [D loss: 0.623380, acc.: 65.62%] [G loss: 1.082677]\n",
      "epoch:13 step:12789 [D loss: 0.604873, acc.: 63.28%] [G loss: 1.238527]\n",
      "epoch:13 step:12790 [D loss: 0.607037, acc.: 64.06%] [G loss: 1.106743]\n",
      "epoch:13 step:12791 [D loss: 0.577996, acc.: 62.50%] [G loss: 1.377523]\n",
      "epoch:13 step:12792 [D loss: 0.592373, acc.: 64.84%] [G loss: 1.023241]\n",
      "epoch:13 step:12793 [D loss: 0.534775, acc.: 72.66%] [G loss: 1.207137]\n",
      "epoch:13 step:12794 [D loss: 0.493999, acc.: 78.91%] [G loss: 1.497446]\n",
      "epoch:13 step:12795 [D loss: 0.671520, acc.: 61.72%] [G loss: 1.007595]\n",
      "epoch:13 step:12796 [D loss: 0.614101, acc.: 67.19%] [G loss: 1.610720]\n",
      "epoch:13 step:12797 [D loss: 0.514721, acc.: 77.34%] [G loss: 1.260195]\n",
      "epoch:13 step:12798 [D loss: 0.716308, acc.: 57.03%] [G loss: 1.400866]\n",
      "epoch:13 step:12799 [D loss: 0.516475, acc.: 78.12%] [G loss: 1.093403]\n",
      "epoch:13 step:12800 [D loss: 0.658953, acc.: 64.06%] [G loss: 1.166464]\n",
      "epoch:13 step:12801 [D loss: 0.609624, acc.: 67.19%] [G loss: 1.310786]\n",
      "epoch:13 step:12802 [D loss: 0.623626, acc.: 63.28%] [G loss: 1.174343]\n",
      "epoch:13 step:12803 [D loss: 0.681438, acc.: 59.38%] [G loss: 0.769615]\n",
      "epoch:13 step:12804 [D loss: 0.552844, acc.: 73.44%] [G loss: 1.177322]\n",
      "epoch:13 step:12805 [D loss: 0.599247, acc.: 69.53%] [G loss: 1.238995]\n",
      "epoch:13 step:12806 [D loss: 0.522575, acc.: 71.09%] [G loss: 1.331800]\n",
      "epoch:13 step:12807 [D loss: 0.570069, acc.: 70.31%] [G loss: 1.195048]\n",
      "epoch:13 step:12808 [D loss: 0.555614, acc.: 69.53%] [G loss: 1.446648]\n",
      "epoch:13 step:12809 [D loss: 0.655505, acc.: 64.84%] [G loss: 1.076858]\n",
      "epoch:13 step:12810 [D loss: 0.567961, acc.: 70.31%] [G loss: 1.297302]\n",
      "epoch:13 step:12811 [D loss: 0.751855, acc.: 55.47%] [G loss: 1.041260]\n",
      "epoch:13 step:12812 [D loss: 0.539312, acc.: 74.22%] [G loss: 1.303375]\n",
      "epoch:13 step:12813 [D loss: 0.581722, acc.: 67.97%] [G loss: 1.001574]\n",
      "epoch:13 step:12814 [D loss: 0.556813, acc.: 70.31%] [G loss: 1.300700]\n",
      "epoch:13 step:12815 [D loss: 0.573422, acc.: 67.19%] [G loss: 1.203441]\n",
      "epoch:13 step:12816 [D loss: 0.720490, acc.: 53.12%] [G loss: 1.217282]\n",
      "epoch:13 step:12817 [D loss: 0.515994, acc.: 78.12%] [G loss: 1.159965]\n",
      "epoch:13 step:12818 [D loss: 0.673370, acc.: 61.72%] [G loss: 0.889317]\n",
      "epoch:13 step:12819 [D loss: 0.587663, acc.: 67.97%] [G loss: 1.044387]\n",
      "epoch:13 step:12820 [D loss: 0.545253, acc.: 73.44%] [G loss: 1.251052]\n",
      "epoch:13 step:12821 [D loss: 0.678062, acc.: 60.16%] [G loss: 1.027824]\n",
      "epoch:13 step:12822 [D loss: 0.549788, acc.: 69.53%] [G loss: 1.222071]\n",
      "epoch:13 step:12823 [D loss: 0.551866, acc.: 76.56%] [G loss: 1.270262]\n",
      "epoch:13 step:12824 [D loss: 0.644203, acc.: 65.62%] [G loss: 0.904128]\n",
      "epoch:13 step:12825 [D loss: 0.542337, acc.: 73.44%] [G loss: 1.211787]\n",
      "epoch:13 step:12826 [D loss: 0.640675, acc.: 61.72%] [G loss: 1.046694]\n",
      "epoch:13 step:12827 [D loss: 0.625525, acc.: 66.41%] [G loss: 1.180668]\n",
      "epoch:13 step:12828 [D loss: 0.592596, acc.: 61.72%] [G loss: 1.126368]\n",
      "epoch:13 step:12829 [D loss: 0.545847, acc.: 74.22%] [G loss: 1.006605]\n",
      "epoch:13 step:12830 [D loss: 0.552066, acc.: 70.31%] [G loss: 1.186519]\n",
      "epoch:13 step:12831 [D loss: 0.503997, acc.: 80.47%] [G loss: 1.107125]\n",
      "epoch:13 step:12832 [D loss: 0.518912, acc.: 78.12%] [G loss: 1.231128]\n",
      "epoch:13 step:12833 [D loss: 0.588081, acc.: 72.66%] [G loss: 1.102255]\n",
      "epoch:13 step:12834 [D loss: 0.616279, acc.: 71.09%] [G loss: 1.096607]\n",
      "epoch:13 step:12835 [D loss: 0.614504, acc.: 64.06%] [G loss: 1.213630]\n",
      "epoch:13 step:12836 [D loss: 0.601214, acc.: 64.84%] [G loss: 1.083263]\n",
      "epoch:13 step:12837 [D loss: 0.563369, acc.: 71.09%] [G loss: 1.079072]\n",
      "epoch:13 step:12838 [D loss: 0.680858, acc.: 61.72%] [G loss: 0.877345]\n",
      "epoch:13 step:12839 [D loss: 0.615084, acc.: 71.88%] [G loss: 1.290397]\n",
      "epoch:13 step:12840 [D loss: 0.611863, acc.: 69.53%] [G loss: 1.105948]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:13 step:12841 [D loss: 0.580918, acc.: 70.31%] [G loss: 1.244909]\n",
      "epoch:13 step:12842 [D loss: 0.601704, acc.: 67.97%] [G loss: 1.063222]\n",
      "epoch:13 step:12843 [D loss: 0.681296, acc.: 56.25%] [G loss: 1.154452]\n",
      "epoch:13 step:12844 [D loss: 0.627668, acc.: 67.19%] [G loss: 1.088477]\n",
      "epoch:13 step:12845 [D loss: 0.648139, acc.: 62.50%] [G loss: 1.101423]\n",
      "epoch:13 step:12846 [D loss: 0.684627, acc.: 62.50%] [G loss: 0.877138]\n",
      "epoch:13 step:12847 [D loss: 0.503112, acc.: 78.91%] [G loss: 1.004553]\n",
      "epoch:13 step:12848 [D loss: 0.553470, acc.: 74.22%] [G loss: 1.251019]\n",
      "epoch:13 step:12849 [D loss: 0.594687, acc.: 68.75%] [G loss: 1.177131]\n",
      "epoch:13 step:12850 [D loss: 0.536313, acc.: 67.97%] [G loss: 1.399867]\n",
      "epoch:13 step:12851 [D loss: 0.691480, acc.: 53.91%] [G loss: 1.289150]\n",
      "epoch:13 step:12852 [D loss: 0.600887, acc.: 69.53%] [G loss: 0.954422]\n",
      "epoch:13 step:12853 [D loss: 0.589002, acc.: 68.75%] [G loss: 1.308220]\n",
      "epoch:13 step:12854 [D loss: 0.589972, acc.: 67.97%] [G loss: 1.139726]\n",
      "epoch:13 step:12855 [D loss: 0.656759, acc.: 61.72%] [G loss: 1.136130]\n",
      "epoch:13 step:12856 [D loss: 0.574970, acc.: 71.09%] [G loss: 1.271085]\n",
      "epoch:13 step:12857 [D loss: 0.656623, acc.: 66.41%] [G loss: 0.996820]\n",
      "epoch:13 step:12858 [D loss: 0.640891, acc.: 62.50%] [G loss: 1.093197]\n",
      "epoch:13 step:12859 [D loss: 0.666824, acc.: 60.94%] [G loss: 0.924796]\n",
      "epoch:13 step:12860 [D loss: 0.696836, acc.: 56.25%] [G loss: 1.206643]\n",
      "epoch:13 step:12861 [D loss: 0.588957, acc.: 66.41%] [G loss: 1.093283]\n",
      "epoch:13 step:12862 [D loss: 0.626898, acc.: 64.06%] [G loss: 1.216344]\n",
      "epoch:13 step:12863 [D loss: 0.474714, acc.: 78.91%] [G loss: 1.213123]\n",
      "epoch:13 step:12864 [D loss: 0.602250, acc.: 71.88%] [G loss: 1.057875]\n",
      "epoch:13 step:12865 [D loss: 0.481727, acc.: 77.34%] [G loss: 1.197866]\n",
      "epoch:13 step:12866 [D loss: 0.565905, acc.: 62.50%] [G loss: 1.206335]\n",
      "epoch:13 step:12867 [D loss: 0.594405, acc.: 65.62%] [G loss: 1.168892]\n",
      "epoch:13 step:12868 [D loss: 0.587185, acc.: 68.75%] [G loss: 1.350315]\n",
      "epoch:13 step:12869 [D loss: 0.453733, acc.: 81.25%] [G loss: 1.361702]\n",
      "epoch:13 step:12870 [D loss: 0.642118, acc.: 64.06%] [G loss: 1.090750]\n",
      "epoch:13 step:12871 [D loss: 0.503954, acc.: 77.34%] [G loss: 1.294558]\n",
      "epoch:13 step:12872 [D loss: 0.555504, acc.: 74.22%] [G loss: 1.183839]\n",
      "epoch:13 step:12873 [D loss: 0.542361, acc.: 73.44%] [G loss: 1.256222]\n",
      "epoch:13 step:12874 [D loss: 0.717835, acc.: 53.91%] [G loss: 1.003821]\n",
      "epoch:13 step:12875 [D loss: 0.495731, acc.: 80.47%] [G loss: 1.117220]\n",
      "epoch:13 step:12876 [D loss: 0.660483, acc.: 61.72%] [G loss: 1.251531]\n",
      "epoch:13 step:12877 [D loss: 0.599046, acc.: 71.88%] [G loss: 1.217657]\n",
      "epoch:13 step:12878 [D loss: 0.663482, acc.: 68.75%] [G loss: 1.191723]\n",
      "epoch:13 step:12879 [D loss: 0.570160, acc.: 68.75%] [G loss: 1.243163]\n",
      "epoch:13 step:12880 [D loss: 0.649246, acc.: 59.38%] [G loss: 1.166595]\n",
      "epoch:13 step:12881 [D loss: 0.542098, acc.: 76.56%] [G loss: 1.057085]\n",
      "epoch:13 step:12882 [D loss: 0.534294, acc.: 74.22%] [G loss: 1.360118]\n",
      "epoch:13 step:12883 [D loss: 0.516559, acc.: 73.44%] [G loss: 1.120331]\n",
      "epoch:13 step:12884 [D loss: 0.709043, acc.: 58.59%] [G loss: 1.162406]\n",
      "epoch:13 step:12885 [D loss: 0.693256, acc.: 58.59%] [G loss: 1.330636]\n",
      "epoch:13 step:12886 [D loss: 0.622907, acc.: 67.19%] [G loss: 1.258571]\n",
      "epoch:13 step:12887 [D loss: 0.635986, acc.: 64.06%] [G loss: 1.316524]\n",
      "epoch:13 step:12888 [D loss: 0.573452, acc.: 71.88%] [G loss: 1.307615]\n",
      "epoch:13 step:12889 [D loss: 0.538266, acc.: 73.44%] [G loss: 1.289546]\n",
      "epoch:13 step:12890 [D loss: 0.774284, acc.: 53.12%] [G loss: 0.807525]\n",
      "epoch:13 step:12891 [D loss: 0.526416, acc.: 75.78%] [G loss: 1.029018]\n",
      "epoch:13 step:12892 [D loss: 0.582341, acc.: 75.00%] [G loss: 1.220726]\n",
      "epoch:13 step:12893 [D loss: 0.709352, acc.: 51.56%] [G loss: 1.019326]\n",
      "epoch:13 step:12894 [D loss: 0.540987, acc.: 78.12%] [G loss: 1.091096]\n",
      "epoch:13 step:12895 [D loss: 0.671684, acc.: 60.16%] [G loss: 1.050318]\n",
      "epoch:13 step:12896 [D loss: 0.697744, acc.: 57.81%] [G loss: 1.211900]\n",
      "epoch:13 step:12897 [D loss: 0.494814, acc.: 75.78%] [G loss: 1.214897]\n",
      "epoch:13 step:12898 [D loss: 0.606336, acc.: 65.62%] [G loss: 1.040309]\n",
      "epoch:13 step:12899 [D loss: 0.490753, acc.: 78.91%] [G loss: 1.578924]\n",
      "epoch:13 step:12900 [D loss: 0.574240, acc.: 67.97%] [G loss: 1.284162]\n",
      "epoch:13 step:12901 [D loss: 0.532409, acc.: 78.12%] [G loss: 1.216863]\n",
      "epoch:13 step:12902 [D loss: 0.489889, acc.: 78.91%] [G loss: 1.142093]\n",
      "epoch:13 step:12903 [D loss: 0.680737, acc.: 60.94%] [G loss: 0.995185]\n",
      "epoch:13 step:12904 [D loss: 0.591516, acc.: 72.66%] [G loss: 1.003240]\n",
      "epoch:13 step:12905 [D loss: 0.527038, acc.: 74.22%] [G loss: 1.199795]\n",
      "epoch:13 step:12906 [D loss: 0.618008, acc.: 65.62%] [G loss: 1.313967]\n",
      "epoch:13 step:12907 [D loss: 0.581569, acc.: 73.44%] [G loss: 1.099888]\n",
      "epoch:13 step:12908 [D loss: 0.449246, acc.: 85.16%] [G loss: 1.171466]\n",
      "epoch:13 step:12909 [D loss: 0.631763, acc.: 62.50%] [G loss: 1.002168]\n",
      "epoch:13 step:12910 [D loss: 0.653711, acc.: 62.50%] [G loss: 0.991625]\n",
      "epoch:13 step:12911 [D loss: 0.621849, acc.: 64.06%] [G loss: 1.226036]\n",
      "epoch:13 step:12912 [D loss: 0.659287, acc.: 57.81%] [G loss: 1.174662]\n",
      "epoch:13 step:12913 [D loss: 0.615849, acc.: 68.75%] [G loss: 1.109523]\n",
      "epoch:13 step:12914 [D loss: 0.548331, acc.: 68.75%] [G loss: 1.039626]\n",
      "epoch:13 step:12915 [D loss: 0.568594, acc.: 64.06%] [G loss: 1.207788]\n",
      "epoch:13 step:12916 [D loss: 0.502647, acc.: 81.25%] [G loss: 1.185596]\n",
      "epoch:13 step:12917 [D loss: 0.558308, acc.: 72.66%] [G loss: 1.082253]\n",
      "epoch:13 step:12918 [D loss: 0.616845, acc.: 61.72%] [G loss: 1.333653]\n",
      "epoch:13 step:12919 [D loss: 0.706045, acc.: 59.38%] [G loss: 0.929288]\n",
      "epoch:13 step:12920 [D loss: 0.663801, acc.: 62.50%] [G loss: 1.011642]\n",
      "epoch:13 step:12921 [D loss: 0.665903, acc.: 60.94%] [G loss: 1.076647]\n",
      "epoch:13 step:12922 [D loss: 0.714875, acc.: 53.91%] [G loss: 1.072409]\n",
      "epoch:13 step:12923 [D loss: 0.621331, acc.: 63.28%] [G loss: 1.063913]\n",
      "epoch:13 step:12924 [D loss: 0.667294, acc.: 59.38%] [G loss: 1.141273]\n",
      "epoch:13 step:12925 [D loss: 0.543534, acc.: 71.09%] [G loss: 1.044075]\n",
      "epoch:13 step:12926 [D loss: 0.555155, acc.: 71.88%] [G loss: 1.051961]\n",
      "epoch:13 step:12927 [D loss: 0.596577, acc.: 67.97%] [G loss: 1.199223]\n",
      "epoch:13 step:12928 [D loss: 0.675044, acc.: 54.69%] [G loss: 0.953128]\n",
      "epoch:13 step:12929 [D loss: 0.542325, acc.: 76.56%] [G loss: 1.083100]\n",
      "epoch:13 step:12930 [D loss: 0.740110, acc.: 55.47%] [G loss: 1.183310]\n",
      "epoch:13 step:12931 [D loss: 0.695427, acc.: 57.03%] [G loss: 1.090483]\n",
      "epoch:13 step:12932 [D loss: 0.557566, acc.: 70.31%] [G loss: 1.103699]\n",
      "epoch:13 step:12933 [D loss: 0.608694, acc.: 64.84%] [G loss: 1.194412]\n",
      "epoch:13 step:12934 [D loss: 0.607531, acc.: 64.06%] [G loss: 1.342550]\n",
      "epoch:13 step:12935 [D loss: 0.647920, acc.: 62.50%] [G loss: 1.014019]\n",
      "epoch:13 step:12936 [D loss: 0.562124, acc.: 72.66%] [G loss: 1.187003]\n",
      "epoch:13 step:12937 [D loss: 0.679257, acc.: 59.38%] [G loss: 1.133048]\n",
      "epoch:13 step:12938 [D loss: 0.495911, acc.: 78.91%] [G loss: 1.321587]\n",
      "epoch:13 step:12939 [D loss: 0.508315, acc.: 74.22%] [G loss: 1.200931]\n",
      "epoch:13 step:12940 [D loss: 0.545591, acc.: 72.66%] [G loss: 1.321540]\n",
      "epoch:13 step:12941 [D loss: 0.569815, acc.: 74.22%] [G loss: 1.071584]\n",
      "epoch:13 step:12942 [D loss: 0.584999, acc.: 71.88%] [G loss: 1.073413]\n",
      "epoch:13 step:12943 [D loss: 0.488177, acc.: 78.91%] [G loss: 1.254812]\n",
      "epoch:13 step:12944 [D loss: 0.560804, acc.: 72.66%] [G loss: 1.104865]\n",
      "epoch:13 step:12945 [D loss: 0.591545, acc.: 70.31%] [G loss: 1.138594]\n",
      "epoch:13 step:12946 [D loss: 0.551580, acc.: 70.31%] [G loss: 1.192695]\n",
      "epoch:13 step:12947 [D loss: 0.386355, acc.: 89.06%] [G loss: 1.160662]\n",
      "epoch:13 step:12948 [D loss: 0.612563, acc.: 67.19%] [G loss: 1.368328]\n",
      "epoch:13 step:12949 [D loss: 0.581115, acc.: 71.09%] [G loss: 0.947903]\n",
      "epoch:13 step:12950 [D loss: 0.571725, acc.: 74.22%] [G loss: 1.233312]\n",
      "epoch:13 step:12951 [D loss: 0.580381, acc.: 67.97%] [G loss: 1.146046]\n",
      "epoch:13 step:12952 [D loss: 0.627561, acc.: 67.97%] [G loss: 1.233993]\n",
      "epoch:13 step:12953 [D loss: 0.584884, acc.: 69.53%] [G loss: 1.137335]\n",
      "epoch:13 step:12954 [D loss: 0.591476, acc.: 70.31%] [G loss: 1.375367]\n",
      "epoch:13 step:12955 [D loss: 0.629026, acc.: 64.06%] [G loss: 1.076269]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:13 step:12956 [D loss: 0.554140, acc.: 71.88%] [G loss: 1.359143]\n",
      "epoch:13 step:12957 [D loss: 0.517833, acc.: 77.34%] [G loss: 1.316027]\n",
      "epoch:13 step:12958 [D loss: 0.642188, acc.: 60.94%] [G loss: 1.118237]\n",
      "epoch:13 step:12959 [D loss: 0.590154, acc.: 68.75%] [G loss: 1.042430]\n",
      "epoch:13 step:12960 [D loss: 0.563028, acc.: 67.19%] [G loss: 1.055919]\n",
      "epoch:13 step:12961 [D loss: 0.680492, acc.: 60.16%] [G loss: 1.226904]\n",
      "epoch:13 step:12962 [D loss: 0.526614, acc.: 78.12%] [G loss: 1.213454]\n",
      "epoch:13 step:12963 [D loss: 0.508016, acc.: 75.78%] [G loss: 1.110294]\n",
      "epoch:13 step:12964 [D loss: 0.490499, acc.: 77.34%] [G loss: 1.340152]\n",
      "epoch:13 step:12965 [D loss: 0.634790, acc.: 59.38%] [G loss: 1.178444]\n",
      "epoch:13 step:12966 [D loss: 0.563099, acc.: 71.09%] [G loss: 1.296648]\n",
      "epoch:13 step:12967 [D loss: 0.575737, acc.: 67.19%] [G loss: 1.184430]\n",
      "epoch:13 step:12968 [D loss: 0.654782, acc.: 62.50%] [G loss: 1.184457]\n",
      "epoch:13 step:12969 [D loss: 0.563801, acc.: 67.97%] [G loss: 1.063990]\n",
      "epoch:13 step:12970 [D loss: 0.560247, acc.: 71.09%] [G loss: 1.391571]\n",
      "epoch:13 step:12971 [D loss: 0.602209, acc.: 67.97%] [G loss: 1.539901]\n",
      "epoch:13 step:12972 [D loss: 0.555679, acc.: 70.31%] [G loss: 1.246619]\n",
      "epoch:13 step:12973 [D loss: 0.545547, acc.: 74.22%] [G loss: 1.383060]\n",
      "epoch:13 step:12974 [D loss: 0.656715, acc.: 65.62%] [G loss: 1.378783]\n",
      "epoch:13 step:12975 [D loss: 0.501788, acc.: 75.78%] [G loss: 1.137827]\n",
      "epoch:13 step:12976 [D loss: 0.565418, acc.: 73.44%] [G loss: 1.086167]\n",
      "epoch:13 step:12977 [D loss: 0.542050, acc.: 75.00%] [G loss: 1.313496]\n",
      "epoch:13 step:12978 [D loss: 0.564571, acc.: 68.75%] [G loss: 1.134744]\n",
      "epoch:13 step:12979 [D loss: 0.598323, acc.: 67.97%] [G loss: 1.148816]\n",
      "epoch:13 step:12980 [D loss: 0.475859, acc.: 78.91%] [G loss: 1.362665]\n",
      "epoch:13 step:12981 [D loss: 0.633824, acc.: 60.94%] [G loss: 1.386413]\n",
      "epoch:13 step:12982 [D loss: 0.646365, acc.: 63.28%] [G loss: 1.153741]\n",
      "epoch:13 step:12983 [D loss: 0.660359, acc.: 61.72%] [G loss: 1.122437]\n",
      "epoch:13 step:12984 [D loss: 0.556222, acc.: 72.66%] [G loss: 1.080457]\n",
      "epoch:13 step:12985 [D loss: 0.495033, acc.: 79.69%] [G loss: 1.307915]\n",
      "epoch:13 step:12986 [D loss: 0.632233, acc.: 61.72%] [G loss: 1.148591]\n",
      "epoch:13 step:12987 [D loss: 0.564247, acc.: 70.31%] [G loss: 1.126527]\n",
      "epoch:13 step:12988 [D loss: 0.542969, acc.: 71.88%] [G loss: 1.315287]\n",
      "epoch:13 step:12989 [D loss: 0.482346, acc.: 79.69%] [G loss: 1.355774]\n",
      "epoch:13 step:12990 [D loss: 0.631813, acc.: 61.72%] [G loss: 1.457002]\n",
      "epoch:13 step:12991 [D loss: 0.548711, acc.: 69.53%] [G loss: 1.216360]\n",
      "epoch:13 step:12992 [D loss: 0.586318, acc.: 71.88%] [G loss: 1.309991]\n",
      "epoch:13 step:12993 [D loss: 0.605041, acc.: 70.31%] [G loss: 1.165076]\n",
      "epoch:13 step:12994 [D loss: 0.633332, acc.: 64.06%] [G loss: 1.498364]\n",
      "epoch:13 step:12995 [D loss: 0.552526, acc.: 69.53%] [G loss: 1.311799]\n",
      "epoch:13 step:12996 [D loss: 0.543447, acc.: 69.53%] [G loss: 1.222004]\n",
      "epoch:13 step:12997 [D loss: 0.677244, acc.: 57.03%] [G loss: 1.380796]\n",
      "epoch:13 step:12998 [D loss: 0.628150, acc.: 67.97%] [G loss: 1.129852]\n",
      "epoch:13 step:12999 [D loss: 0.596197, acc.: 66.41%] [G loss: 1.130002]\n",
      "epoch:13 step:13000 [D loss: 0.713419, acc.: 59.38%] [G loss: 1.060716]\n",
      "epoch:13 step:13001 [D loss: 0.653255, acc.: 64.06%] [G loss: 1.325513]\n",
      "epoch:13 step:13002 [D loss: 0.549475, acc.: 71.88%] [G loss: 1.126621]\n",
      "epoch:13 step:13003 [D loss: 0.668525, acc.: 56.25%] [G loss: 1.041587]\n",
      "epoch:13 step:13004 [D loss: 0.704109, acc.: 53.12%] [G loss: 1.277958]\n",
      "epoch:13 step:13005 [D loss: 0.637032, acc.: 66.41%] [G loss: 1.263671]\n",
      "epoch:13 step:13006 [D loss: 0.536579, acc.: 71.88%] [G loss: 1.159881]\n",
      "epoch:13 step:13007 [D loss: 0.573766, acc.: 67.19%] [G loss: 1.117326]\n",
      "epoch:13 step:13008 [D loss: 0.695505, acc.: 60.16%] [G loss: 1.106806]\n",
      "epoch:13 step:13009 [D loss: 0.668414, acc.: 60.94%] [G loss: 1.277784]\n",
      "epoch:13 step:13010 [D loss: 0.555672, acc.: 71.88%] [G loss: 1.227231]\n",
      "epoch:13 step:13011 [D loss: 0.485086, acc.: 79.69%] [G loss: 1.136101]\n",
      "epoch:13 step:13012 [D loss: 0.647088, acc.: 64.06%] [G loss: 1.258571]\n",
      "epoch:13 step:13013 [D loss: 0.673423, acc.: 58.59%] [G loss: 1.011480]\n",
      "epoch:13 step:13014 [D loss: 0.637577, acc.: 66.41%] [G loss: 1.212911]\n",
      "epoch:13 step:13015 [D loss: 0.671222, acc.: 60.94%] [G loss: 1.155885]\n",
      "epoch:13 step:13016 [D loss: 0.574570, acc.: 76.56%] [G loss: 1.085353]\n",
      "epoch:13 step:13017 [D loss: 0.671545, acc.: 59.38%] [G loss: 1.008601]\n",
      "epoch:13 step:13018 [D loss: 0.621101, acc.: 61.72%] [G loss: 1.104787]\n",
      "epoch:13 step:13019 [D loss: 0.619668, acc.: 69.53%] [G loss: 1.012606]\n",
      "epoch:13 step:13020 [D loss: 0.547436, acc.: 74.22%] [G loss: 1.202269]\n",
      "epoch:13 step:13021 [D loss: 0.556109, acc.: 71.88%] [G loss: 1.227792]\n",
      "epoch:13 step:13022 [D loss: 0.553161, acc.: 76.56%] [G loss: 1.026567]\n",
      "epoch:13 step:13023 [D loss: 0.511120, acc.: 75.78%] [G loss: 1.113649]\n",
      "epoch:13 step:13024 [D loss: 0.641726, acc.: 60.16%] [G loss: 0.973754]\n",
      "epoch:13 step:13025 [D loss: 0.635694, acc.: 61.72%] [G loss: 1.156728]\n",
      "epoch:13 step:13026 [D loss: 0.623214, acc.: 67.97%] [G loss: 1.163212]\n",
      "epoch:13 step:13027 [D loss: 0.522415, acc.: 73.44%] [G loss: 1.196487]\n",
      "epoch:13 step:13028 [D loss: 0.559725, acc.: 70.31%] [G loss: 1.180011]\n",
      "epoch:13 step:13029 [D loss: 0.434569, acc.: 81.25%] [G loss: 1.393242]\n",
      "epoch:13 step:13030 [D loss: 0.594841, acc.: 65.62%] [G loss: 1.177173]\n",
      "epoch:13 step:13031 [D loss: 0.650929, acc.: 60.16%] [G loss: 1.452760]\n",
      "epoch:13 step:13032 [D loss: 0.724410, acc.: 56.25%] [G loss: 0.934923]\n",
      "epoch:13 step:13033 [D loss: 0.567860, acc.: 69.53%] [G loss: 1.233556]\n",
      "epoch:13 step:13034 [D loss: 0.535318, acc.: 74.22%] [G loss: 1.217964]\n",
      "epoch:13 step:13035 [D loss: 0.654685, acc.: 58.59%] [G loss: 1.167547]\n",
      "epoch:13 step:13036 [D loss: 0.651442, acc.: 58.59%] [G loss: 1.023213]\n",
      "epoch:13 step:13037 [D loss: 0.474787, acc.: 80.47%] [G loss: 1.449005]\n",
      "epoch:13 step:13038 [D loss: 0.589112, acc.: 67.19%] [G loss: 1.037727]\n",
      "epoch:13 step:13039 [D loss: 0.535223, acc.: 71.09%] [G loss: 1.249670]\n",
      "epoch:13 step:13040 [D loss: 0.521698, acc.: 78.91%] [G loss: 1.324305]\n",
      "epoch:13 step:13041 [D loss: 0.635954, acc.: 60.16%] [G loss: 1.123406]\n",
      "epoch:13 step:13042 [D loss: 0.544806, acc.: 70.31%] [G loss: 1.233196]\n",
      "epoch:13 step:13043 [D loss: 0.542770, acc.: 72.66%] [G loss: 1.061314]\n",
      "epoch:13 step:13044 [D loss: 0.662989, acc.: 63.28%] [G loss: 0.970240]\n",
      "epoch:13 step:13045 [D loss: 0.613860, acc.: 66.41%] [G loss: 1.138683]\n",
      "epoch:13 step:13046 [D loss: 0.639977, acc.: 64.06%] [G loss: 1.199122]\n",
      "epoch:13 step:13047 [D loss: 0.620332, acc.: 65.62%] [G loss: 0.965407]\n",
      "epoch:13 step:13048 [D loss: 0.555340, acc.: 73.44%] [G loss: 1.352176]\n",
      "epoch:13 step:13049 [D loss: 0.511176, acc.: 75.78%] [G loss: 1.275404]\n",
      "epoch:13 step:13050 [D loss: 0.639428, acc.: 60.94%] [G loss: 1.155473]\n",
      "epoch:13 step:13051 [D loss: 0.523059, acc.: 75.78%] [G loss: 1.200095]\n",
      "epoch:13 step:13052 [D loss: 0.530911, acc.: 74.22%] [G loss: 1.494235]\n",
      "epoch:13 step:13053 [D loss: 0.564389, acc.: 70.31%] [G loss: 1.158631]\n",
      "epoch:13 step:13054 [D loss: 0.564666, acc.: 70.31%] [G loss: 1.095424]\n",
      "epoch:13 step:13055 [D loss: 0.629296, acc.: 64.06%] [G loss: 1.271075]\n",
      "epoch:13 step:13056 [D loss: 0.574756, acc.: 73.44%] [G loss: 1.236236]\n",
      "epoch:13 step:13057 [D loss: 0.517801, acc.: 75.00%] [G loss: 1.105975]\n",
      "epoch:13 step:13058 [D loss: 0.716091, acc.: 59.38%] [G loss: 1.063911]\n",
      "epoch:13 step:13059 [D loss: 0.616627, acc.: 61.72%] [G loss: 1.192915]\n",
      "epoch:13 step:13060 [D loss: 0.634625, acc.: 64.06%] [G loss: 1.244943]\n",
      "epoch:13 step:13061 [D loss: 0.513028, acc.: 74.22%] [G loss: 1.084887]\n",
      "epoch:13 step:13062 [D loss: 0.641483, acc.: 60.16%] [G loss: 1.161190]\n",
      "epoch:13 step:13063 [D loss: 0.554638, acc.: 75.78%] [G loss: 1.252179]\n",
      "epoch:13 step:13064 [D loss: 0.690615, acc.: 56.25%] [G loss: 1.097208]\n",
      "epoch:13 step:13065 [D loss: 0.480414, acc.: 81.25%] [G loss: 1.184852]\n",
      "epoch:13 step:13066 [D loss: 0.539488, acc.: 71.88%] [G loss: 1.264457]\n",
      "epoch:13 step:13067 [D loss: 0.705997, acc.: 56.25%] [G loss: 1.084051]\n",
      "epoch:13 step:13068 [D loss: 0.680543, acc.: 57.81%] [G loss: 1.131857]\n",
      "epoch:13 step:13069 [D loss: 0.623794, acc.: 67.19%] [G loss: 1.099423]\n",
      "epoch:13 step:13070 [D loss: 0.615822, acc.: 66.41%] [G loss: 1.326975]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:13 step:13071 [D loss: 0.665212, acc.: 57.81%] [G loss: 1.068962]\n",
      "epoch:13 step:13072 [D loss: 0.573151, acc.: 68.75%] [G loss: 1.190534]\n",
      "epoch:13 step:13073 [D loss: 0.524701, acc.: 71.88%] [G loss: 1.007721]\n",
      "epoch:13 step:13074 [D loss: 0.662983, acc.: 64.06%] [G loss: 0.951168]\n",
      "epoch:13 step:13075 [D loss: 0.621646, acc.: 69.53%] [G loss: 1.121315]\n",
      "epoch:13 step:13076 [D loss: 0.594277, acc.: 69.53%] [G loss: 1.164102]\n",
      "epoch:13 step:13077 [D loss: 0.629287, acc.: 68.75%] [G loss: 1.144522]\n",
      "epoch:13 step:13078 [D loss: 0.532321, acc.: 73.44%] [G loss: 1.197781]\n",
      "epoch:13 step:13079 [D loss: 0.512579, acc.: 78.12%] [G loss: 1.133204]\n",
      "epoch:13 step:13080 [D loss: 0.574086, acc.: 69.53%] [G loss: 1.345985]\n",
      "epoch:13 step:13081 [D loss: 0.496078, acc.: 75.78%] [G loss: 1.184489]\n",
      "epoch:13 step:13082 [D loss: 0.531529, acc.: 71.88%] [G loss: 1.200652]\n",
      "epoch:13 step:13083 [D loss: 0.484677, acc.: 78.12%] [G loss: 1.534740]\n",
      "epoch:13 step:13084 [D loss: 0.599432, acc.: 68.75%] [G loss: 1.378342]\n",
      "epoch:13 step:13085 [D loss: 0.457875, acc.: 81.25%] [G loss: 1.127387]\n",
      "epoch:13 step:13086 [D loss: 0.560612, acc.: 72.66%] [G loss: 0.889285]\n",
      "epoch:13 step:13087 [D loss: 0.494544, acc.: 78.12%] [G loss: 1.289198]\n",
      "epoch:13 step:13088 [D loss: 0.681570, acc.: 64.84%] [G loss: 1.064891]\n",
      "epoch:13 step:13089 [D loss: 0.634816, acc.: 66.41%] [G loss: 1.195282]\n",
      "epoch:13 step:13090 [D loss: 0.556828, acc.: 75.00%] [G loss: 1.290869]\n",
      "epoch:13 step:13091 [D loss: 0.512779, acc.: 75.78%] [G loss: 1.453242]\n",
      "epoch:13 step:13092 [D loss: 0.557075, acc.: 76.56%] [G loss: 1.064243]\n",
      "epoch:13 step:13093 [D loss: 0.718847, acc.: 50.78%] [G loss: 1.017409]\n",
      "epoch:13 step:13094 [D loss: 0.631817, acc.: 65.62%] [G loss: 1.177540]\n",
      "epoch:13 step:13095 [D loss: 0.661700, acc.: 62.50%] [G loss: 1.159952]\n",
      "epoch:13 step:13096 [D loss: 0.498709, acc.: 78.91%] [G loss: 1.081773]\n",
      "epoch:13 step:13097 [D loss: 0.587899, acc.: 70.31%] [G loss: 1.293301]\n",
      "epoch:13 step:13098 [D loss: 0.634904, acc.: 65.62%] [G loss: 1.364797]\n",
      "epoch:13 step:13099 [D loss: 0.643768, acc.: 63.28%] [G loss: 1.182323]\n",
      "epoch:13 step:13100 [D loss: 0.517579, acc.: 75.00%] [G loss: 1.347537]\n",
      "epoch:13 step:13101 [D loss: 0.546682, acc.: 72.66%] [G loss: 1.205537]\n",
      "epoch:13 step:13102 [D loss: 0.563770, acc.: 65.62%] [G loss: 1.016051]\n",
      "epoch:13 step:13103 [D loss: 0.599855, acc.: 66.41%] [G loss: 1.063376]\n",
      "epoch:13 step:13104 [D loss: 0.646507, acc.: 61.72%] [G loss: 1.134779]\n",
      "epoch:13 step:13105 [D loss: 0.666605, acc.: 60.16%] [G loss: 1.184772]\n",
      "epoch:13 step:13106 [D loss: 0.545498, acc.: 74.22%] [G loss: 1.431572]\n",
      "epoch:13 step:13107 [D loss: 0.580489, acc.: 69.53%] [G loss: 1.230092]\n",
      "epoch:13 step:13108 [D loss: 0.683867, acc.: 59.38%] [G loss: 1.226323]\n",
      "epoch:13 step:13109 [D loss: 0.603135, acc.: 63.28%] [G loss: 1.034138]\n",
      "epoch:13 step:13110 [D loss: 0.619279, acc.: 64.06%] [G loss: 1.134305]\n",
      "epoch:13 step:13111 [D loss: 0.634905, acc.: 64.06%] [G loss: 1.311265]\n",
      "epoch:13 step:13112 [D loss: 0.621430, acc.: 64.06%] [G loss: 1.019238]\n",
      "epoch:13 step:13113 [D loss: 0.613389, acc.: 67.19%] [G loss: 0.990864]\n",
      "epoch:13 step:13114 [D loss: 0.651678, acc.: 60.94%] [G loss: 1.144820]\n",
      "epoch:13 step:13115 [D loss: 0.523727, acc.: 75.00%] [G loss: 1.139798]\n",
      "epoch:13 step:13116 [D loss: 0.530247, acc.: 74.22%] [G loss: 1.204064]\n",
      "epoch:13 step:13117 [D loss: 0.651557, acc.: 64.06%] [G loss: 1.385651]\n",
      "epoch:13 step:13118 [D loss: 0.592959, acc.: 67.19%] [G loss: 1.182994]\n",
      "epoch:14 step:13119 [D loss: 0.616347, acc.: 63.28%] [G loss: 1.005535]\n",
      "epoch:14 step:13120 [D loss: 0.612569, acc.: 62.50%] [G loss: 1.138393]\n",
      "epoch:14 step:13121 [D loss: 0.638507, acc.: 57.81%] [G loss: 1.179717]\n",
      "epoch:14 step:13122 [D loss: 0.595963, acc.: 67.19%] [G loss: 1.179579]\n",
      "epoch:14 step:13123 [D loss: 0.648164, acc.: 60.16%] [G loss: 1.010673]\n",
      "epoch:14 step:13124 [D loss: 0.639446, acc.: 63.28%] [G loss: 0.942478]\n",
      "epoch:14 step:13125 [D loss: 0.683589, acc.: 57.81%] [G loss: 1.030269]\n",
      "epoch:14 step:13126 [D loss: 0.558301, acc.: 73.44%] [G loss: 1.018038]\n",
      "epoch:14 step:13127 [D loss: 0.617851, acc.: 65.62%] [G loss: 1.442939]\n",
      "epoch:14 step:13128 [D loss: 0.589692, acc.: 70.31%] [G loss: 1.194858]\n",
      "epoch:14 step:13129 [D loss: 0.626747, acc.: 64.06%] [G loss: 1.181630]\n",
      "epoch:14 step:13130 [D loss: 0.495138, acc.: 81.25%] [G loss: 1.328004]\n",
      "epoch:14 step:13131 [D loss: 0.527333, acc.: 72.66%] [G loss: 1.334896]\n",
      "epoch:14 step:13132 [D loss: 0.617752, acc.: 63.28%] [G loss: 1.253083]\n",
      "epoch:14 step:13133 [D loss: 0.527087, acc.: 73.44%] [G loss: 1.439426]\n",
      "epoch:14 step:13134 [D loss: 0.607957, acc.: 59.38%] [G loss: 1.244025]\n",
      "epoch:14 step:13135 [D loss: 0.599958, acc.: 65.62%] [G loss: 1.167060]\n",
      "epoch:14 step:13136 [D loss: 0.656931, acc.: 60.16%] [G loss: 0.854254]\n",
      "epoch:14 step:13137 [D loss: 0.623417, acc.: 64.84%] [G loss: 1.053046]\n",
      "epoch:14 step:13138 [D loss: 0.592578, acc.: 65.62%] [G loss: 1.460978]\n",
      "epoch:14 step:13139 [D loss: 0.655499, acc.: 64.84%] [G loss: 1.074048]\n",
      "epoch:14 step:13140 [D loss: 0.513434, acc.: 78.12%] [G loss: 1.265361]\n",
      "epoch:14 step:13141 [D loss: 0.655811, acc.: 56.25%] [G loss: 1.160658]\n",
      "epoch:14 step:13142 [D loss: 0.580193, acc.: 74.22%] [G loss: 1.157933]\n",
      "epoch:14 step:13143 [D loss: 0.617442, acc.: 64.06%] [G loss: 1.194144]\n",
      "epoch:14 step:13144 [D loss: 0.593489, acc.: 64.06%] [G loss: 1.092996]\n",
      "epoch:14 step:13145 [D loss: 0.464375, acc.: 79.69%] [G loss: 1.204278]\n",
      "epoch:14 step:13146 [D loss: 0.611305, acc.: 62.50%] [G loss: 0.896190]\n",
      "epoch:14 step:13147 [D loss: 0.700157, acc.: 57.81%] [G loss: 1.038292]\n",
      "epoch:14 step:13148 [D loss: 0.668900, acc.: 63.28%] [G loss: 1.062569]\n",
      "epoch:14 step:13149 [D loss: 0.686770, acc.: 57.03%] [G loss: 1.123734]\n",
      "epoch:14 step:13150 [D loss: 0.589899, acc.: 67.19%] [G loss: 1.377396]\n",
      "epoch:14 step:13151 [D loss: 0.643290, acc.: 62.50%] [G loss: 1.234640]\n",
      "epoch:14 step:13152 [D loss: 0.541686, acc.: 71.09%] [G loss: 1.434160]\n",
      "epoch:14 step:13153 [D loss: 0.524873, acc.: 73.44%] [G loss: 1.391593]\n",
      "epoch:14 step:13154 [D loss: 0.561764, acc.: 72.66%] [G loss: 1.351290]\n",
      "epoch:14 step:13155 [D loss: 0.480499, acc.: 78.91%] [G loss: 1.168663]\n",
      "epoch:14 step:13156 [D loss: 0.602590, acc.: 66.41%] [G loss: 1.260287]\n",
      "epoch:14 step:13157 [D loss: 0.616101, acc.: 68.75%] [G loss: 1.116322]\n",
      "epoch:14 step:13158 [D loss: 0.573381, acc.: 68.75%] [G loss: 1.231435]\n",
      "epoch:14 step:13159 [D loss: 0.471375, acc.: 78.91%] [G loss: 1.401855]\n",
      "epoch:14 step:13160 [D loss: 0.617200, acc.: 65.62%] [G loss: 1.000724]\n",
      "epoch:14 step:13161 [D loss: 0.565440, acc.: 71.09%] [G loss: 1.289002]\n",
      "epoch:14 step:13162 [D loss: 0.688876, acc.: 55.47%] [G loss: 1.358978]\n",
      "epoch:14 step:13163 [D loss: 0.623228, acc.: 67.19%] [G loss: 1.264734]\n",
      "epoch:14 step:13164 [D loss: 0.720717, acc.: 58.59%] [G loss: 1.045129]\n",
      "epoch:14 step:13165 [D loss: 0.656558, acc.: 61.72%] [G loss: 1.121260]\n",
      "epoch:14 step:13166 [D loss: 0.606772, acc.: 67.97%] [G loss: 1.178703]\n",
      "epoch:14 step:13167 [D loss: 0.501664, acc.: 72.66%] [G loss: 1.326136]\n",
      "epoch:14 step:13168 [D loss: 0.593091, acc.: 67.97%] [G loss: 1.157048]\n",
      "epoch:14 step:13169 [D loss: 0.599692, acc.: 66.41%] [G loss: 1.060718]\n",
      "epoch:14 step:13170 [D loss: 0.568194, acc.: 73.44%] [G loss: 1.229812]\n",
      "epoch:14 step:13171 [D loss: 0.466638, acc.: 82.81%] [G loss: 1.097358]\n",
      "epoch:14 step:13172 [D loss: 0.467831, acc.: 82.03%] [G loss: 1.519181]\n",
      "epoch:14 step:13173 [D loss: 0.535787, acc.: 74.22%] [G loss: 1.371748]\n",
      "epoch:14 step:13174 [D loss: 0.574286, acc.: 67.19%] [G loss: 1.096120]\n",
      "epoch:14 step:13175 [D loss: 0.548957, acc.: 73.44%] [G loss: 1.128958]\n",
      "epoch:14 step:13176 [D loss: 0.616339, acc.: 60.94%] [G loss: 1.064199]\n",
      "epoch:14 step:13177 [D loss: 0.513892, acc.: 79.69%] [G loss: 1.092058]\n",
      "epoch:14 step:13178 [D loss: 0.562527, acc.: 72.66%] [G loss: 1.207403]\n",
      "epoch:14 step:13179 [D loss: 0.608964, acc.: 69.53%] [G loss: 1.167701]\n",
      "epoch:14 step:13180 [D loss: 0.547478, acc.: 74.22%] [G loss: 1.342575]\n",
      "epoch:14 step:13181 [D loss: 0.470279, acc.: 79.69%] [G loss: 1.028333]\n",
      "epoch:14 step:13182 [D loss: 0.705907, acc.: 60.16%] [G loss: 1.214041]\n",
      "epoch:14 step:13183 [D loss: 0.507902, acc.: 73.44%] [G loss: 1.080737]\n",
      "epoch:14 step:13184 [D loss: 0.641427, acc.: 67.19%] [G loss: 1.126456]\n",
      "epoch:14 step:13185 [D loss: 0.499986, acc.: 75.78%] [G loss: 1.268029]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:14 step:13186 [D loss: 0.586368, acc.: 68.75%] [G loss: 1.116348]\n",
      "epoch:14 step:13187 [D loss: 0.553465, acc.: 76.56%] [G loss: 1.183608]\n",
      "epoch:14 step:13188 [D loss: 0.582981, acc.: 70.31%] [G loss: 1.343277]\n",
      "epoch:14 step:13189 [D loss: 0.621131, acc.: 64.06%] [G loss: 0.975498]\n",
      "epoch:14 step:13190 [D loss: 0.525263, acc.: 76.56%] [G loss: 1.078648]\n",
      "epoch:14 step:13191 [D loss: 0.462870, acc.: 79.69%] [G loss: 1.292295]\n",
      "epoch:14 step:13192 [D loss: 0.591287, acc.: 70.31%] [G loss: 1.227908]\n",
      "epoch:14 step:13193 [D loss: 0.616738, acc.: 63.28%] [G loss: 1.305735]\n",
      "epoch:14 step:13194 [D loss: 0.497306, acc.: 76.56%] [G loss: 1.609904]\n",
      "epoch:14 step:13195 [D loss: 0.572672, acc.: 76.56%] [G loss: 1.128513]\n",
      "epoch:14 step:13196 [D loss: 0.839118, acc.: 43.75%] [G loss: 1.038532]\n",
      "epoch:14 step:13197 [D loss: 0.629926, acc.: 63.28%] [G loss: 1.152772]\n",
      "epoch:14 step:13198 [D loss: 0.556433, acc.: 73.44%] [G loss: 1.258599]\n",
      "epoch:14 step:13199 [D loss: 0.600100, acc.: 71.09%] [G loss: 1.294084]\n",
      "epoch:14 step:13200 [D loss: 0.680632, acc.: 64.06%] [G loss: 1.229700]\n",
      "epoch:14 step:13201 [D loss: 0.637569, acc.: 62.50%] [G loss: 0.997150]\n",
      "epoch:14 step:13202 [D loss: 0.727193, acc.: 56.25%] [G loss: 1.030513]\n",
      "epoch:14 step:13203 [D loss: 0.579822, acc.: 71.09%] [G loss: 1.017121]\n",
      "epoch:14 step:13204 [D loss: 0.664146, acc.: 62.50%] [G loss: 1.182003]\n",
      "epoch:14 step:13205 [D loss: 0.687099, acc.: 56.25%] [G loss: 1.100525]\n",
      "epoch:14 step:13206 [D loss: 0.652856, acc.: 64.06%] [G loss: 1.135221]\n",
      "epoch:14 step:13207 [D loss: 0.563313, acc.: 67.97%] [G loss: 1.328248]\n",
      "epoch:14 step:13208 [D loss: 0.524925, acc.: 75.78%] [G loss: 1.303596]\n",
      "epoch:14 step:13209 [D loss: 0.549580, acc.: 70.31%] [G loss: 1.350468]\n",
      "epoch:14 step:13210 [D loss: 0.570153, acc.: 68.75%] [G loss: 0.999443]\n",
      "epoch:14 step:13211 [D loss: 0.600895, acc.: 67.19%] [G loss: 1.118727]\n",
      "epoch:14 step:13212 [D loss: 0.474651, acc.: 81.25%] [G loss: 1.386335]\n",
      "epoch:14 step:13213 [D loss: 0.627889, acc.: 64.06%] [G loss: 1.047410]\n",
      "epoch:14 step:13214 [D loss: 0.624264, acc.: 65.62%] [G loss: 1.070230]\n",
      "epoch:14 step:13215 [D loss: 0.596701, acc.: 69.53%] [G loss: 1.033624]\n",
      "epoch:14 step:13216 [D loss: 0.608463, acc.: 66.41%] [G loss: 1.074631]\n",
      "epoch:14 step:13217 [D loss: 0.676772, acc.: 60.16%] [G loss: 1.245389]\n",
      "epoch:14 step:13218 [D loss: 0.595262, acc.: 63.28%] [G loss: 1.185716]\n",
      "epoch:14 step:13219 [D loss: 0.693784, acc.: 60.94%] [G loss: 1.031485]\n",
      "epoch:14 step:13220 [D loss: 0.836296, acc.: 45.31%] [G loss: 0.806163]\n",
      "epoch:14 step:13221 [D loss: 0.526677, acc.: 73.44%] [G loss: 1.277726]\n",
      "epoch:14 step:13222 [D loss: 0.642093, acc.: 64.06%] [G loss: 1.090621]\n",
      "epoch:14 step:13223 [D loss: 0.652590, acc.: 60.94%] [G loss: 1.327712]\n",
      "epoch:14 step:13224 [D loss: 0.607000, acc.: 70.31%] [G loss: 1.314773]\n",
      "epoch:14 step:13225 [D loss: 0.535951, acc.: 71.88%] [G loss: 0.962991]\n",
      "epoch:14 step:13226 [D loss: 0.591458, acc.: 67.97%] [G loss: 0.929467]\n",
      "epoch:14 step:13227 [D loss: 0.650551, acc.: 57.81%] [G loss: 1.250410]\n",
      "epoch:14 step:13228 [D loss: 0.643467, acc.: 62.50%] [G loss: 1.023329]\n",
      "epoch:14 step:13229 [D loss: 0.668693, acc.: 60.16%] [G loss: 0.970733]\n",
      "epoch:14 step:13230 [D loss: 0.609267, acc.: 70.31%] [G loss: 1.278308]\n",
      "epoch:14 step:13231 [D loss: 0.536826, acc.: 71.09%] [G loss: 1.219281]\n",
      "epoch:14 step:13232 [D loss: 0.616105, acc.: 66.41%] [G loss: 1.256513]\n",
      "epoch:14 step:13233 [D loss: 0.599765, acc.: 65.62%] [G loss: 0.983624]\n",
      "epoch:14 step:13234 [D loss: 0.654187, acc.: 63.28%] [G loss: 1.479308]\n",
      "epoch:14 step:13235 [D loss: 0.579023, acc.: 67.19%] [G loss: 1.236349]\n",
      "epoch:14 step:13236 [D loss: 0.569939, acc.: 72.66%] [G loss: 0.998821]\n",
      "epoch:14 step:13237 [D loss: 0.510584, acc.: 78.12%] [G loss: 0.968138]\n",
      "epoch:14 step:13238 [D loss: 0.675206, acc.: 64.06%] [G loss: 1.063292]\n",
      "epoch:14 step:13239 [D loss: 0.645166, acc.: 64.84%] [G loss: 1.370759]\n",
      "epoch:14 step:13240 [D loss: 0.622026, acc.: 68.75%] [G loss: 1.126026]\n",
      "epoch:14 step:13241 [D loss: 0.586870, acc.: 67.97%] [G loss: 1.258054]\n",
      "epoch:14 step:13242 [D loss: 0.550252, acc.: 73.44%] [G loss: 1.359816]\n",
      "epoch:14 step:13243 [D loss: 0.657213, acc.: 64.84%] [G loss: 1.209141]\n",
      "epoch:14 step:13244 [D loss: 0.584342, acc.: 68.75%] [G loss: 1.158604]\n",
      "epoch:14 step:13245 [D loss: 0.543377, acc.: 72.66%] [G loss: 1.324273]\n",
      "epoch:14 step:13246 [D loss: 0.569094, acc.: 73.44%] [G loss: 1.196656]\n",
      "epoch:14 step:13247 [D loss: 0.575880, acc.: 73.44%] [G loss: 1.177850]\n",
      "epoch:14 step:13248 [D loss: 0.530616, acc.: 77.34%] [G loss: 1.273764]\n",
      "epoch:14 step:13249 [D loss: 0.573763, acc.: 69.53%] [G loss: 1.144139]\n",
      "epoch:14 step:13250 [D loss: 0.560284, acc.: 69.53%] [G loss: 1.142182]\n",
      "epoch:14 step:13251 [D loss: 0.550246, acc.: 72.66%] [G loss: 1.098574]\n",
      "epoch:14 step:13252 [D loss: 0.574010, acc.: 71.09%] [G loss: 1.329021]\n",
      "epoch:14 step:13253 [D loss: 0.619915, acc.: 66.41%] [G loss: 1.220434]\n",
      "epoch:14 step:13254 [D loss: 0.783668, acc.: 49.22%] [G loss: 0.982907]\n",
      "epoch:14 step:13255 [D loss: 0.647096, acc.: 66.41%] [G loss: 1.207343]\n",
      "epoch:14 step:13256 [D loss: 0.501055, acc.: 78.12%] [G loss: 1.395106]\n",
      "epoch:14 step:13257 [D loss: 0.647666, acc.: 66.41%] [G loss: 1.037251]\n",
      "epoch:14 step:13258 [D loss: 0.656873, acc.: 64.84%] [G loss: 1.061245]\n",
      "epoch:14 step:13259 [D loss: 0.644131, acc.: 63.28%] [G loss: 1.046957]\n",
      "epoch:14 step:13260 [D loss: 0.584544, acc.: 61.72%] [G loss: 1.136221]\n",
      "epoch:14 step:13261 [D loss: 0.647137, acc.: 61.72%] [G loss: 0.890058]\n",
      "epoch:14 step:13262 [D loss: 0.639495, acc.: 62.50%] [G loss: 1.066945]\n",
      "epoch:14 step:13263 [D loss: 0.550281, acc.: 74.22%] [G loss: 1.511440]\n",
      "epoch:14 step:13264 [D loss: 0.582403, acc.: 67.19%] [G loss: 1.047550]\n",
      "epoch:14 step:13265 [D loss: 0.633207, acc.: 66.41%] [G loss: 1.239305]\n",
      "epoch:14 step:13266 [D loss: 0.638627, acc.: 63.28%] [G loss: 1.116604]\n",
      "epoch:14 step:13267 [D loss: 0.664176, acc.: 60.16%] [G loss: 1.209919]\n",
      "epoch:14 step:13268 [D loss: 0.598592, acc.: 72.66%] [G loss: 1.386649]\n",
      "epoch:14 step:13269 [D loss: 0.567310, acc.: 72.66%] [G loss: 1.353439]\n",
      "epoch:14 step:13270 [D loss: 0.599061, acc.: 63.28%] [G loss: 1.183729]\n",
      "epoch:14 step:13271 [D loss: 0.583258, acc.: 67.19%] [G loss: 1.173316]\n",
      "epoch:14 step:13272 [D loss: 0.535193, acc.: 75.78%] [G loss: 1.030196]\n",
      "epoch:14 step:13273 [D loss: 0.646416, acc.: 62.50%] [G loss: 1.158723]\n",
      "epoch:14 step:13274 [D loss: 0.564644, acc.: 71.09%] [G loss: 1.099540]\n",
      "epoch:14 step:13275 [D loss: 0.620570, acc.: 68.75%] [G loss: 1.229531]\n",
      "epoch:14 step:13276 [D loss: 0.452165, acc.: 82.81%] [G loss: 1.448934]\n",
      "epoch:14 step:13277 [D loss: 0.592890, acc.: 66.41%] [G loss: 1.180063]\n",
      "epoch:14 step:13278 [D loss: 0.596809, acc.: 68.75%] [G loss: 1.189163]\n",
      "epoch:14 step:13279 [D loss: 0.605053, acc.: 67.97%] [G loss: 1.196485]\n",
      "epoch:14 step:13280 [D loss: 0.599056, acc.: 64.06%] [G loss: 1.467102]\n",
      "epoch:14 step:13281 [D loss: 0.670660, acc.: 59.38%] [G loss: 1.148863]\n",
      "epoch:14 step:13282 [D loss: 0.541341, acc.: 71.88%] [G loss: 1.178005]\n",
      "epoch:14 step:13283 [D loss: 0.551591, acc.: 73.44%] [G loss: 1.432619]\n",
      "epoch:14 step:13284 [D loss: 0.618808, acc.: 63.28%] [G loss: 1.232503]\n",
      "epoch:14 step:13285 [D loss: 0.578623, acc.: 70.31%] [G loss: 1.245260]\n",
      "epoch:14 step:13286 [D loss: 0.619299, acc.: 63.28%] [G loss: 1.093229]\n",
      "epoch:14 step:13287 [D loss: 0.602213, acc.: 67.19%] [G loss: 1.267715]\n",
      "epoch:14 step:13288 [D loss: 0.628402, acc.: 64.84%] [G loss: 1.206210]\n",
      "epoch:14 step:13289 [D loss: 0.591573, acc.: 67.19%] [G loss: 1.257233]\n",
      "epoch:14 step:13290 [D loss: 0.555270, acc.: 74.22%] [G loss: 1.033153]\n",
      "epoch:14 step:13291 [D loss: 0.603067, acc.: 64.06%] [G loss: 1.210395]\n",
      "epoch:14 step:13292 [D loss: 0.513868, acc.: 79.69%] [G loss: 1.227087]\n",
      "epoch:14 step:13293 [D loss: 0.628461, acc.: 67.97%] [G loss: 1.124434]\n",
      "epoch:14 step:13294 [D loss: 0.484231, acc.: 78.91%] [G loss: 1.183447]\n",
      "epoch:14 step:13295 [D loss: 0.566455, acc.: 69.53%] [G loss: 1.132432]\n",
      "epoch:14 step:13296 [D loss: 0.516942, acc.: 71.88%] [G loss: 1.276588]\n",
      "epoch:14 step:13297 [D loss: 0.570170, acc.: 74.22%] [G loss: 0.860423]\n",
      "epoch:14 step:13298 [D loss: 0.500605, acc.: 74.22%] [G loss: 1.211035]\n",
      "epoch:14 step:13299 [D loss: 0.625876, acc.: 60.16%] [G loss: 1.068690]\n",
      "epoch:14 step:13300 [D loss: 0.481610, acc.: 82.03%] [G loss: 1.193056]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:14 step:13301 [D loss: 0.691649, acc.: 59.38%] [G loss: 1.241539]\n",
      "epoch:14 step:13302 [D loss: 0.646267, acc.: 62.50%] [G loss: 1.364772]\n",
      "epoch:14 step:13303 [D loss: 0.634637, acc.: 63.28%] [G loss: 1.229851]\n",
      "epoch:14 step:13304 [D loss: 0.714219, acc.: 57.81%] [G loss: 1.103346]\n",
      "epoch:14 step:13305 [D loss: 0.579871, acc.: 68.75%] [G loss: 1.327713]\n",
      "epoch:14 step:13306 [D loss: 0.526599, acc.: 75.78%] [G loss: 1.100005]\n",
      "epoch:14 step:13307 [D loss: 0.631089, acc.: 64.06%] [G loss: 1.167884]\n",
      "epoch:14 step:13308 [D loss: 0.639073, acc.: 68.75%] [G loss: 1.213552]\n",
      "epoch:14 step:13309 [D loss: 0.473832, acc.: 82.03%] [G loss: 1.318682]\n",
      "epoch:14 step:13310 [D loss: 0.602715, acc.: 67.97%] [G loss: 1.244116]\n",
      "epoch:14 step:13311 [D loss: 0.563060, acc.: 69.53%] [G loss: 1.200281]\n",
      "epoch:14 step:13312 [D loss: 0.576559, acc.: 67.97%] [G loss: 1.092540]\n",
      "epoch:14 step:13313 [D loss: 0.495336, acc.: 75.78%] [G loss: 1.292199]\n",
      "epoch:14 step:13314 [D loss: 0.606577, acc.: 64.84%] [G loss: 1.235342]\n",
      "epoch:14 step:13315 [D loss: 0.714125, acc.: 50.00%] [G loss: 1.235873]\n",
      "epoch:14 step:13316 [D loss: 0.594202, acc.: 67.97%] [G loss: 1.168684]\n",
      "epoch:14 step:13317 [D loss: 0.626861, acc.: 63.28%] [G loss: 1.068017]\n",
      "epoch:14 step:13318 [D loss: 0.656835, acc.: 64.06%] [G loss: 0.944101]\n",
      "epoch:14 step:13319 [D loss: 0.533831, acc.: 74.22%] [G loss: 1.345537]\n",
      "epoch:14 step:13320 [D loss: 0.546382, acc.: 73.44%] [G loss: 1.273536]\n",
      "epoch:14 step:13321 [D loss: 0.453355, acc.: 81.25%] [G loss: 1.158749]\n",
      "epoch:14 step:13322 [D loss: 0.548853, acc.: 74.22%] [G loss: 1.574195]\n",
      "epoch:14 step:13323 [D loss: 0.640854, acc.: 64.84%] [G loss: 1.100714]\n",
      "epoch:14 step:13324 [D loss: 0.552405, acc.: 67.19%] [G loss: 1.233035]\n",
      "epoch:14 step:13325 [D loss: 0.569179, acc.: 70.31%] [G loss: 1.201770]\n",
      "epoch:14 step:13326 [D loss: 0.501796, acc.: 80.47%] [G loss: 1.136332]\n",
      "epoch:14 step:13327 [D loss: 0.720045, acc.: 51.56%] [G loss: 1.042573]\n",
      "epoch:14 step:13328 [D loss: 0.637959, acc.: 65.62%] [G loss: 1.119970]\n",
      "epoch:14 step:13329 [D loss: 0.543325, acc.: 72.66%] [G loss: 1.265394]\n",
      "epoch:14 step:13330 [D loss: 0.721474, acc.: 54.69%] [G loss: 1.072909]\n",
      "epoch:14 step:13331 [D loss: 0.544672, acc.: 71.09%] [G loss: 1.564925]\n",
      "epoch:14 step:13332 [D loss: 0.566337, acc.: 74.22%] [G loss: 1.198059]\n",
      "epoch:14 step:13333 [D loss: 0.704786, acc.: 56.25%] [G loss: 1.296162]\n",
      "epoch:14 step:13334 [D loss: 0.651244, acc.: 62.50%] [G loss: 1.096109]\n",
      "epoch:14 step:13335 [D loss: 0.513211, acc.: 74.22%] [G loss: 1.217794]\n",
      "epoch:14 step:13336 [D loss: 0.662871, acc.: 63.28%] [G loss: 1.321601]\n",
      "epoch:14 step:13337 [D loss: 0.577267, acc.: 69.53%] [G loss: 1.305029]\n",
      "epoch:14 step:13338 [D loss: 0.613306, acc.: 67.19%] [G loss: 1.264313]\n",
      "epoch:14 step:13339 [D loss: 0.667927, acc.: 64.06%] [G loss: 1.074387]\n",
      "epoch:14 step:13340 [D loss: 0.535085, acc.: 71.88%] [G loss: 1.284887]\n",
      "epoch:14 step:13341 [D loss: 0.656339, acc.: 62.50%] [G loss: 0.923620]\n",
      "epoch:14 step:13342 [D loss: 0.560826, acc.: 69.53%] [G loss: 1.054440]\n",
      "epoch:14 step:13343 [D loss: 0.562430, acc.: 71.88%] [G loss: 1.199908]\n",
      "epoch:14 step:13344 [D loss: 0.622692, acc.: 66.41%] [G loss: 1.082309]\n",
      "epoch:14 step:13345 [D loss: 0.725050, acc.: 51.56%] [G loss: 1.056439]\n",
      "epoch:14 step:13346 [D loss: 0.520441, acc.: 79.69%] [G loss: 1.137981]\n",
      "epoch:14 step:13347 [D loss: 0.578950, acc.: 68.75%] [G loss: 1.138530]\n",
      "epoch:14 step:13348 [D loss: 0.580008, acc.: 71.09%] [G loss: 1.021169]\n",
      "epoch:14 step:13349 [D loss: 0.620723, acc.: 66.41%] [G loss: 1.020862]\n",
      "epoch:14 step:13350 [D loss: 0.589526, acc.: 71.88%] [G loss: 1.155649]\n",
      "epoch:14 step:13351 [D loss: 0.534199, acc.: 77.34%] [G loss: 1.378361]\n",
      "epoch:14 step:13352 [D loss: 0.651452, acc.: 65.62%] [G loss: 1.170650]\n",
      "epoch:14 step:13353 [D loss: 0.509799, acc.: 81.25%] [G loss: 1.029586]\n",
      "epoch:14 step:13354 [D loss: 0.645360, acc.: 64.84%] [G loss: 0.949731]\n",
      "epoch:14 step:13355 [D loss: 0.577987, acc.: 68.75%] [G loss: 1.239475]\n",
      "epoch:14 step:13356 [D loss: 0.779563, acc.: 50.00%] [G loss: 1.165633]\n",
      "epoch:14 step:13357 [D loss: 0.623242, acc.: 62.50%] [G loss: 1.207495]\n",
      "epoch:14 step:13358 [D loss: 0.612336, acc.: 66.41%] [G loss: 1.203623]\n",
      "epoch:14 step:13359 [D loss: 0.603505, acc.: 67.19%] [G loss: 1.188973]\n",
      "epoch:14 step:13360 [D loss: 0.758846, acc.: 54.69%] [G loss: 1.021885]\n",
      "epoch:14 step:13361 [D loss: 0.542943, acc.: 73.44%] [G loss: 1.420158]\n",
      "epoch:14 step:13362 [D loss: 0.554138, acc.: 69.53%] [G loss: 1.135419]\n",
      "epoch:14 step:13363 [D loss: 0.643474, acc.: 61.72%] [G loss: 1.128208]\n",
      "epoch:14 step:13364 [D loss: 0.512528, acc.: 71.88%] [G loss: 1.322854]\n",
      "epoch:14 step:13365 [D loss: 0.558004, acc.: 75.00%] [G loss: 1.290664]\n",
      "epoch:14 step:13366 [D loss: 0.553718, acc.: 72.66%] [G loss: 1.082170]\n",
      "epoch:14 step:13367 [D loss: 0.507818, acc.: 75.00%] [G loss: 1.217811]\n",
      "epoch:14 step:13368 [D loss: 0.638698, acc.: 64.84%] [G loss: 1.240644]\n",
      "epoch:14 step:13369 [D loss: 0.493395, acc.: 80.47%] [G loss: 1.249621]\n",
      "epoch:14 step:13370 [D loss: 0.629066, acc.: 62.50%] [G loss: 1.158656]\n",
      "epoch:14 step:13371 [D loss: 0.599740, acc.: 64.06%] [G loss: 1.178403]\n",
      "epoch:14 step:13372 [D loss: 0.612580, acc.: 64.84%] [G loss: 1.209489]\n",
      "epoch:14 step:13373 [D loss: 0.603886, acc.: 67.97%] [G loss: 1.054223]\n",
      "epoch:14 step:13374 [D loss: 0.608437, acc.: 64.06%] [G loss: 1.178548]\n",
      "epoch:14 step:13375 [D loss: 0.612184, acc.: 59.38%] [G loss: 0.946740]\n",
      "epoch:14 step:13376 [D loss: 0.520115, acc.: 75.78%] [G loss: 1.212826]\n",
      "epoch:14 step:13377 [D loss: 0.655971, acc.: 65.62%] [G loss: 1.135545]\n",
      "epoch:14 step:13378 [D loss: 0.555845, acc.: 71.09%] [G loss: 1.126987]\n",
      "epoch:14 step:13379 [D loss: 0.618425, acc.: 67.19%] [G loss: 1.181471]\n",
      "epoch:14 step:13380 [D loss: 0.659348, acc.: 61.72%] [G loss: 1.137581]\n",
      "epoch:14 step:13381 [D loss: 0.670913, acc.: 57.03%] [G loss: 1.167935]\n",
      "epoch:14 step:13382 [D loss: 0.623428, acc.: 62.50%] [G loss: 1.256047]\n",
      "epoch:14 step:13383 [D loss: 0.476887, acc.: 82.03%] [G loss: 1.475724]\n",
      "epoch:14 step:13384 [D loss: 0.575584, acc.: 71.88%] [G loss: 1.142959]\n",
      "epoch:14 step:13385 [D loss: 0.655363, acc.: 59.38%] [G loss: 1.093969]\n",
      "epoch:14 step:13386 [D loss: 0.510934, acc.: 75.78%] [G loss: 1.239404]\n",
      "epoch:14 step:13387 [D loss: 0.543295, acc.: 72.66%] [G loss: 1.390180]\n",
      "epoch:14 step:13388 [D loss: 0.526250, acc.: 75.78%] [G loss: 1.465788]\n",
      "epoch:14 step:13389 [D loss: 0.566215, acc.: 69.53%] [G loss: 1.299975]\n",
      "epoch:14 step:13390 [D loss: 0.556856, acc.: 70.31%] [G loss: 1.260750]\n",
      "epoch:14 step:13391 [D loss: 0.610155, acc.: 67.97%] [G loss: 1.140636]\n",
      "epoch:14 step:13392 [D loss: 0.534804, acc.: 73.44%] [G loss: 1.309968]\n",
      "epoch:14 step:13393 [D loss: 0.629171, acc.: 63.28%] [G loss: 0.964919]\n",
      "epoch:14 step:13394 [D loss: 0.708615, acc.: 53.91%] [G loss: 0.837672]\n",
      "epoch:14 step:13395 [D loss: 0.601287, acc.: 70.31%] [G loss: 1.134091]\n",
      "epoch:14 step:13396 [D loss: 0.517548, acc.: 77.34%] [G loss: 1.404627]\n",
      "epoch:14 step:13397 [D loss: 0.584665, acc.: 68.75%] [G loss: 1.515488]\n",
      "epoch:14 step:13398 [D loss: 0.591587, acc.: 70.31%] [G loss: 1.434213]\n",
      "epoch:14 step:13399 [D loss: 0.600599, acc.: 64.84%] [G loss: 1.076431]\n",
      "epoch:14 step:13400 [D loss: 0.608556, acc.: 66.41%] [G loss: 1.140592]\n",
      "epoch:14 step:13401 [D loss: 0.600954, acc.: 65.62%] [G loss: 1.355008]\n",
      "epoch:14 step:13402 [D loss: 0.624009, acc.: 68.75%] [G loss: 1.064213]\n",
      "epoch:14 step:13403 [D loss: 0.587428, acc.: 72.66%] [G loss: 1.266236]\n",
      "epoch:14 step:13404 [D loss: 0.531521, acc.: 79.69%] [G loss: 1.189866]\n",
      "epoch:14 step:13405 [D loss: 0.506683, acc.: 78.91%] [G loss: 1.072840]\n",
      "epoch:14 step:13406 [D loss: 0.602043, acc.: 71.88%] [G loss: 1.241767]\n",
      "epoch:14 step:13407 [D loss: 0.549814, acc.: 73.44%] [G loss: 1.026953]\n",
      "epoch:14 step:13408 [D loss: 0.465878, acc.: 82.81%] [G loss: 1.258030]\n",
      "epoch:14 step:13409 [D loss: 0.625531, acc.: 65.62%] [G loss: 1.130740]\n",
      "epoch:14 step:13410 [D loss: 0.666125, acc.: 60.94%] [G loss: 1.285173]\n",
      "epoch:14 step:13411 [D loss: 0.716074, acc.: 57.03%] [G loss: 1.045727]\n",
      "epoch:14 step:13412 [D loss: 0.591089, acc.: 69.53%] [G loss: 1.077243]\n",
      "epoch:14 step:13413 [D loss: 0.643812, acc.: 67.19%] [G loss: 1.095558]\n",
      "epoch:14 step:13414 [D loss: 0.605530, acc.: 67.19%] [G loss: 1.129365]\n",
      "epoch:14 step:13415 [D loss: 0.658514, acc.: 66.41%] [G loss: 1.158610]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:14 step:13416 [D loss: 0.655277, acc.: 57.81%] [G loss: 1.116267]\n",
      "epoch:14 step:13417 [D loss: 0.702572, acc.: 59.38%] [G loss: 1.265534]\n",
      "epoch:14 step:13418 [D loss: 0.491290, acc.: 77.34%] [G loss: 1.356297]\n",
      "epoch:14 step:13419 [D loss: 0.695130, acc.: 60.94%] [G loss: 1.213666]\n",
      "epoch:14 step:13420 [D loss: 0.695300, acc.: 60.16%] [G loss: 0.991328]\n",
      "epoch:14 step:13421 [D loss: 0.675689, acc.: 62.50%] [G loss: 1.076076]\n",
      "epoch:14 step:13422 [D loss: 0.705137, acc.: 62.50%] [G loss: 1.052683]\n",
      "epoch:14 step:13423 [D loss: 0.611342, acc.: 64.84%] [G loss: 1.524713]\n",
      "epoch:14 step:13424 [D loss: 0.661628, acc.: 57.03%] [G loss: 1.213070]\n",
      "epoch:14 step:13425 [D loss: 0.565689, acc.: 70.31%] [G loss: 1.211914]\n",
      "epoch:14 step:13426 [D loss: 0.536169, acc.: 73.44%] [G loss: 1.183148]\n",
      "epoch:14 step:13427 [D loss: 0.492070, acc.: 78.91%] [G loss: 1.437050]\n",
      "epoch:14 step:13428 [D loss: 0.570851, acc.: 73.44%] [G loss: 1.569677]\n",
      "epoch:14 step:13429 [D loss: 0.496212, acc.: 78.91%] [G loss: 1.396619]\n",
      "epoch:14 step:13430 [D loss: 0.659743, acc.: 58.59%] [G loss: 1.037455]\n",
      "epoch:14 step:13431 [D loss: 0.531787, acc.: 78.12%] [G loss: 1.259433]\n",
      "epoch:14 step:13432 [D loss: 0.614412, acc.: 67.97%] [G loss: 1.078306]\n",
      "epoch:14 step:13433 [D loss: 0.503214, acc.: 78.12%] [G loss: 1.097350]\n",
      "epoch:14 step:13434 [D loss: 0.693543, acc.: 50.00%] [G loss: 1.223765]\n",
      "epoch:14 step:13435 [D loss: 0.606235, acc.: 64.84%] [G loss: 1.351948]\n",
      "epoch:14 step:13436 [D loss: 0.661719, acc.: 62.50%] [G loss: 0.987657]\n",
      "epoch:14 step:13437 [D loss: 0.678263, acc.: 60.94%] [G loss: 0.905498]\n",
      "epoch:14 step:13438 [D loss: 0.510512, acc.: 75.00%] [G loss: 1.133287]\n",
      "epoch:14 step:13439 [D loss: 0.634697, acc.: 67.97%] [G loss: 1.376461]\n",
      "epoch:14 step:13440 [D loss: 0.526328, acc.: 74.22%] [G loss: 1.195313]\n",
      "epoch:14 step:13441 [D loss: 0.592776, acc.: 67.97%] [G loss: 1.089909]\n",
      "epoch:14 step:13442 [D loss: 0.659050, acc.: 60.94%] [G loss: 0.860274]\n",
      "epoch:14 step:13443 [D loss: 0.514450, acc.: 76.56%] [G loss: 1.422716]\n",
      "epoch:14 step:13444 [D loss: 0.621406, acc.: 66.41%] [G loss: 1.381847]\n",
      "epoch:14 step:13445 [D loss: 0.518761, acc.: 78.91%] [G loss: 1.089376]\n",
      "epoch:14 step:13446 [D loss: 0.544324, acc.: 71.88%] [G loss: 1.126227]\n",
      "epoch:14 step:13447 [D loss: 0.553596, acc.: 70.31%] [G loss: 1.293249]\n",
      "epoch:14 step:13448 [D loss: 0.592957, acc.: 67.97%] [G loss: 1.114207]\n",
      "epoch:14 step:13449 [D loss: 0.538829, acc.: 75.78%] [G loss: 1.091972]\n",
      "epoch:14 step:13450 [D loss: 0.526252, acc.: 77.34%] [G loss: 1.216299]\n",
      "epoch:14 step:13451 [D loss: 0.618569, acc.: 67.19%] [G loss: 1.210499]\n",
      "epoch:14 step:13452 [D loss: 0.520611, acc.: 74.22%] [G loss: 1.123975]\n",
      "epoch:14 step:13453 [D loss: 0.624329, acc.: 64.84%] [G loss: 1.052067]\n",
      "epoch:14 step:13454 [D loss: 0.480048, acc.: 74.22%] [G loss: 1.240855]\n",
      "epoch:14 step:13455 [D loss: 0.759045, acc.: 51.56%] [G loss: 0.985632]\n",
      "epoch:14 step:13456 [D loss: 0.520944, acc.: 75.00%] [G loss: 1.281852]\n",
      "epoch:14 step:13457 [D loss: 0.519839, acc.: 75.00%] [G loss: 1.372903]\n",
      "epoch:14 step:13458 [D loss: 0.561199, acc.: 73.44%] [G loss: 1.339118]\n",
      "epoch:14 step:13459 [D loss: 0.581030, acc.: 71.09%] [G loss: 1.307865]\n",
      "epoch:14 step:13460 [D loss: 0.627176, acc.: 67.19%] [G loss: 1.113739]\n",
      "epoch:14 step:13461 [D loss: 0.607435, acc.: 67.97%] [G loss: 1.035798]\n",
      "epoch:14 step:13462 [D loss: 0.586919, acc.: 70.31%] [G loss: 1.116130]\n",
      "epoch:14 step:13463 [D loss: 0.592682, acc.: 67.97%] [G loss: 1.416198]\n",
      "epoch:14 step:13464 [D loss: 0.656801, acc.: 59.38%] [G loss: 1.355632]\n",
      "epoch:14 step:13465 [D loss: 0.613455, acc.: 67.97%] [G loss: 1.281944]\n",
      "epoch:14 step:13466 [D loss: 0.563311, acc.: 71.09%] [G loss: 1.263588]\n",
      "epoch:14 step:13467 [D loss: 0.650791, acc.: 56.25%] [G loss: 1.381556]\n",
      "epoch:14 step:13468 [D loss: 0.589434, acc.: 69.53%] [G loss: 1.384187]\n",
      "epoch:14 step:13469 [D loss: 0.682210, acc.: 61.72%] [G loss: 1.083939]\n",
      "epoch:14 step:13470 [D loss: 0.569982, acc.: 72.66%] [G loss: 1.330740]\n",
      "epoch:14 step:13471 [D loss: 0.540319, acc.: 76.56%] [G loss: 1.109217]\n",
      "epoch:14 step:13472 [D loss: 0.525884, acc.: 72.66%] [G loss: 1.226452]\n",
      "epoch:14 step:13473 [D loss: 0.611726, acc.: 64.06%] [G loss: 1.447000]\n",
      "epoch:14 step:13474 [D loss: 0.586425, acc.: 71.09%] [G loss: 1.212737]\n",
      "epoch:14 step:13475 [D loss: 0.514066, acc.: 78.91%] [G loss: 1.466766]\n",
      "epoch:14 step:13476 [D loss: 0.635253, acc.: 64.06%] [G loss: 1.072884]\n",
      "epoch:14 step:13477 [D loss: 0.585641, acc.: 67.19%] [G loss: 1.257204]\n",
      "epoch:14 step:13478 [D loss: 0.470199, acc.: 78.12%] [G loss: 1.159731]\n",
      "epoch:14 step:13479 [D loss: 0.586224, acc.: 66.41%] [G loss: 1.366066]\n",
      "epoch:14 step:13480 [D loss: 0.594616, acc.: 67.97%] [G loss: 1.045250]\n",
      "epoch:14 step:13481 [D loss: 0.566468, acc.: 73.44%] [G loss: 1.188297]\n",
      "epoch:14 step:13482 [D loss: 0.518854, acc.: 75.78%] [G loss: 1.203015]\n",
      "epoch:14 step:13483 [D loss: 0.555648, acc.: 75.00%] [G loss: 1.152096]\n",
      "epoch:14 step:13484 [D loss: 0.645480, acc.: 64.84%] [G loss: 1.428673]\n",
      "epoch:14 step:13485 [D loss: 0.693252, acc.: 63.28%] [G loss: 1.016373]\n",
      "epoch:14 step:13486 [D loss: 0.491156, acc.: 79.69%] [G loss: 1.237116]\n",
      "epoch:14 step:13487 [D loss: 0.644234, acc.: 61.72%] [G loss: 1.123854]\n",
      "epoch:14 step:13488 [D loss: 0.543443, acc.: 73.44%] [G loss: 1.238999]\n",
      "epoch:14 step:13489 [D loss: 0.548401, acc.: 71.88%] [G loss: 1.070269]\n",
      "epoch:14 step:13490 [D loss: 0.622529, acc.: 67.19%] [G loss: 1.144152]\n",
      "epoch:14 step:13491 [D loss: 0.579755, acc.: 70.31%] [G loss: 1.175596]\n",
      "epoch:14 step:13492 [D loss: 0.562083, acc.: 71.88%] [G loss: 1.215010]\n",
      "epoch:14 step:13493 [D loss: 0.748717, acc.: 50.00%] [G loss: 1.015876]\n",
      "epoch:14 step:13494 [D loss: 0.735646, acc.: 49.22%] [G loss: 1.139098]\n",
      "epoch:14 step:13495 [D loss: 0.557352, acc.: 64.84%] [G loss: 1.063922]\n",
      "epoch:14 step:13496 [D loss: 0.785659, acc.: 54.69%] [G loss: 1.393503]\n",
      "epoch:14 step:13497 [D loss: 0.565168, acc.: 72.66%] [G loss: 1.129005]\n",
      "epoch:14 step:13498 [D loss: 0.697724, acc.: 58.59%] [G loss: 1.127996]\n",
      "epoch:14 step:13499 [D loss: 0.595600, acc.: 68.75%] [G loss: 0.976089]\n",
      "epoch:14 step:13500 [D loss: 0.589155, acc.: 68.75%] [G loss: 1.046092]\n",
      "epoch:14 step:13501 [D loss: 0.716589, acc.: 56.25%] [G loss: 1.097051]\n",
      "epoch:14 step:13502 [D loss: 0.520314, acc.: 78.91%] [G loss: 1.370690]\n",
      "epoch:14 step:13503 [D loss: 0.713344, acc.: 53.12%] [G loss: 1.152111]\n",
      "epoch:14 step:13504 [D loss: 0.596383, acc.: 70.31%] [G loss: 1.046834]\n",
      "epoch:14 step:13505 [D loss: 0.562391, acc.: 69.53%] [G loss: 1.050143]\n",
      "epoch:14 step:13506 [D loss: 0.639052, acc.: 62.50%] [G loss: 1.377134]\n",
      "epoch:14 step:13507 [D loss: 0.641673, acc.: 64.06%] [G loss: 1.095711]\n",
      "epoch:14 step:13508 [D loss: 0.688695, acc.: 59.38%] [G loss: 1.538701]\n",
      "epoch:14 step:13509 [D loss: 0.628733, acc.: 69.53%] [G loss: 1.170858]\n",
      "epoch:14 step:13510 [D loss: 0.530772, acc.: 77.34%] [G loss: 1.377672]\n",
      "epoch:14 step:13511 [D loss: 0.711581, acc.: 56.25%] [G loss: 1.096985]\n",
      "epoch:14 step:13512 [D loss: 0.480504, acc.: 78.91%] [G loss: 0.980670]\n",
      "epoch:14 step:13513 [D loss: 0.526596, acc.: 71.09%] [G loss: 1.160764]\n",
      "epoch:14 step:13514 [D loss: 0.617297, acc.: 69.53%] [G loss: 1.034227]\n",
      "epoch:14 step:13515 [D loss: 0.832896, acc.: 45.31%] [G loss: 0.937174]\n",
      "epoch:14 step:13516 [D loss: 0.546091, acc.: 75.00%] [G loss: 1.099634]\n",
      "epoch:14 step:13517 [D loss: 0.593288, acc.: 66.41%] [G loss: 1.063915]\n",
      "epoch:14 step:13518 [D loss: 0.720214, acc.: 55.47%] [G loss: 1.225582]\n",
      "epoch:14 step:13519 [D loss: 0.546670, acc.: 73.44%] [G loss: 1.377792]\n",
      "epoch:14 step:13520 [D loss: 0.591016, acc.: 65.62%] [G loss: 1.256171]\n",
      "epoch:14 step:13521 [D loss: 0.751024, acc.: 53.91%] [G loss: 0.920586]\n",
      "epoch:14 step:13522 [D loss: 0.655708, acc.: 65.62%] [G loss: 0.980961]\n",
      "epoch:14 step:13523 [D loss: 0.537929, acc.: 76.56%] [G loss: 1.346750]\n",
      "epoch:14 step:13524 [D loss: 0.560176, acc.: 76.56%] [G loss: 1.182477]\n",
      "epoch:14 step:13525 [D loss: 0.661357, acc.: 64.84%] [G loss: 1.269165]\n",
      "epoch:14 step:13526 [D loss: 0.540887, acc.: 74.22%] [G loss: 1.236693]\n",
      "epoch:14 step:13527 [D loss: 0.539984, acc.: 68.75%] [G loss: 1.154835]\n",
      "epoch:14 step:13528 [D loss: 0.580096, acc.: 71.09%] [G loss: 1.275730]\n",
      "epoch:14 step:13529 [D loss: 0.525890, acc.: 75.78%] [G loss: 1.301291]\n",
      "epoch:14 step:13530 [D loss: 0.600249, acc.: 70.31%] [G loss: 1.288995]\n",
      "epoch:14 step:13531 [D loss: 0.505597, acc.: 73.44%] [G loss: 1.215941]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:14 step:13532 [D loss: 0.535861, acc.: 74.22%] [G loss: 1.119666]\n",
      "epoch:14 step:13533 [D loss: 0.627431, acc.: 64.06%] [G loss: 1.181580]\n",
      "epoch:14 step:13534 [D loss: 0.618419, acc.: 68.75%] [G loss: 1.077572]\n",
      "epoch:14 step:13535 [D loss: 0.568944, acc.: 69.53%] [G loss: 1.251074]\n",
      "epoch:14 step:13536 [D loss: 0.644671, acc.: 67.19%] [G loss: 1.144331]\n",
      "epoch:14 step:13537 [D loss: 0.594027, acc.: 69.53%] [G loss: 1.007960]\n",
      "epoch:14 step:13538 [D loss: 0.491983, acc.: 74.22%] [G loss: 1.163993]\n",
      "epoch:14 step:13539 [D loss: 0.500616, acc.: 78.91%] [G loss: 1.267028]\n",
      "epoch:14 step:13540 [D loss: 0.522394, acc.: 76.56%] [G loss: 1.286972]\n",
      "epoch:14 step:13541 [D loss: 0.623733, acc.: 67.19%] [G loss: 1.203007]\n",
      "epoch:14 step:13542 [D loss: 0.548277, acc.: 75.00%] [G loss: 1.327377]\n",
      "epoch:14 step:13543 [D loss: 0.693508, acc.: 64.84%] [G loss: 1.010245]\n",
      "epoch:14 step:13544 [D loss: 0.551722, acc.: 69.53%] [G loss: 1.454459]\n",
      "epoch:14 step:13545 [D loss: 0.690237, acc.: 61.72%] [G loss: 1.211038]\n",
      "epoch:14 step:13546 [D loss: 0.650308, acc.: 62.50%] [G loss: 1.166157]\n",
      "epoch:14 step:13547 [D loss: 0.578582, acc.: 69.53%] [G loss: 1.327887]\n",
      "epoch:14 step:13548 [D loss: 0.601209, acc.: 66.41%] [G loss: 0.954613]\n",
      "epoch:14 step:13549 [D loss: 0.658931, acc.: 61.72%] [G loss: 1.187521]\n",
      "epoch:14 step:13550 [D loss: 0.591251, acc.: 66.41%] [G loss: 1.040925]\n",
      "epoch:14 step:13551 [D loss: 0.559708, acc.: 70.31%] [G loss: 1.033314]\n",
      "epoch:14 step:13552 [D loss: 0.672355, acc.: 58.59%] [G loss: 1.028560]\n",
      "epoch:14 step:13553 [D loss: 0.580779, acc.: 68.75%] [G loss: 0.921474]\n",
      "epoch:14 step:13554 [D loss: 0.606807, acc.: 64.84%] [G loss: 1.137692]\n",
      "epoch:14 step:13555 [D loss: 0.572259, acc.: 70.31%] [G loss: 1.342859]\n",
      "epoch:14 step:13556 [D loss: 0.583917, acc.: 67.19%] [G loss: 1.178672]\n",
      "epoch:14 step:13557 [D loss: 0.622900, acc.: 64.06%] [G loss: 1.148211]\n",
      "epoch:14 step:13558 [D loss: 0.621771, acc.: 65.62%] [G loss: 1.021933]\n",
      "epoch:14 step:13559 [D loss: 0.565620, acc.: 71.88%] [G loss: 1.355205]\n",
      "epoch:14 step:13560 [D loss: 0.635645, acc.: 67.97%] [G loss: 1.071233]\n",
      "epoch:14 step:13561 [D loss: 0.513472, acc.: 79.69%] [G loss: 1.338805]\n",
      "epoch:14 step:13562 [D loss: 0.544498, acc.: 72.66%] [G loss: 1.492214]\n",
      "epoch:14 step:13563 [D loss: 0.513138, acc.: 77.34%] [G loss: 1.049878]\n",
      "epoch:14 step:13564 [D loss: 0.832954, acc.: 40.62%] [G loss: 1.026780]\n",
      "epoch:14 step:13565 [D loss: 0.553879, acc.: 71.09%] [G loss: 1.201579]\n",
      "epoch:14 step:13566 [D loss: 0.654199, acc.: 64.06%] [G loss: 1.180902]\n",
      "epoch:14 step:13567 [D loss: 0.475814, acc.: 82.03%] [G loss: 1.389938]\n",
      "epoch:14 step:13568 [D loss: 0.510387, acc.: 78.91%] [G loss: 1.460671]\n",
      "epoch:14 step:13569 [D loss: 0.496921, acc.: 79.69%] [G loss: 1.325397]\n",
      "epoch:14 step:13570 [D loss: 0.571770, acc.: 67.97%] [G loss: 1.370947]\n",
      "epoch:14 step:13571 [D loss: 0.557525, acc.: 72.66%] [G loss: 1.201962]\n",
      "epoch:14 step:13572 [D loss: 0.550345, acc.: 76.56%] [G loss: 1.397338]\n",
      "epoch:14 step:13573 [D loss: 0.518616, acc.: 78.91%] [G loss: 1.167487]\n",
      "epoch:14 step:13574 [D loss: 0.609859, acc.: 62.50%] [G loss: 1.378354]\n",
      "epoch:14 step:13575 [D loss: 0.673999, acc.: 60.16%] [G loss: 1.048993]\n",
      "epoch:14 step:13576 [D loss: 0.487331, acc.: 78.91%] [G loss: 1.154967]\n",
      "epoch:14 step:13577 [D loss: 0.495940, acc.: 82.81%] [G loss: 1.352246]\n",
      "epoch:14 step:13578 [D loss: 0.608887, acc.: 67.19%] [G loss: 1.193704]\n",
      "epoch:14 step:13579 [D loss: 0.593056, acc.: 65.62%] [G loss: 1.347492]\n",
      "epoch:14 step:13580 [D loss: 0.622937, acc.: 67.97%] [G loss: 0.961498]\n",
      "epoch:14 step:13581 [D loss: 0.676715, acc.: 60.16%] [G loss: 1.071816]\n",
      "epoch:14 step:13582 [D loss: 0.609906, acc.: 64.84%] [G loss: 1.122988]\n",
      "epoch:14 step:13583 [D loss: 0.663223, acc.: 54.69%] [G loss: 1.061906]\n",
      "epoch:14 step:13584 [D loss: 0.586246, acc.: 75.78%] [G loss: 1.315411]\n",
      "epoch:14 step:13585 [D loss: 0.460663, acc.: 82.81%] [G loss: 1.393042]\n",
      "epoch:14 step:13586 [D loss: 0.623857, acc.: 71.09%] [G loss: 1.550671]\n",
      "epoch:14 step:13587 [D loss: 0.624854, acc.: 69.53%] [G loss: 1.258951]\n",
      "epoch:14 step:13588 [D loss: 0.591060, acc.: 67.19%] [G loss: 1.448390]\n",
      "epoch:14 step:13589 [D loss: 0.615168, acc.: 64.84%] [G loss: 1.147435]\n",
      "epoch:14 step:13590 [D loss: 0.701133, acc.: 57.03%] [G loss: 1.383668]\n",
      "epoch:14 step:13591 [D loss: 0.595419, acc.: 67.19%] [G loss: 1.420022]\n",
      "epoch:14 step:13592 [D loss: 0.526297, acc.: 75.78%] [G loss: 1.420991]\n",
      "epoch:14 step:13593 [D loss: 0.508720, acc.: 78.91%] [G loss: 1.418825]\n",
      "epoch:14 step:13594 [D loss: 0.434499, acc.: 82.81%] [G loss: 1.506710]\n",
      "epoch:14 step:13595 [D loss: 0.599512, acc.: 74.22%] [G loss: 1.120096]\n",
      "epoch:14 step:13596 [D loss: 0.602124, acc.: 67.19%] [G loss: 1.207615]\n",
      "epoch:14 step:13597 [D loss: 0.541206, acc.: 76.56%] [G loss: 1.380663]\n",
      "epoch:14 step:13598 [D loss: 0.736929, acc.: 51.56%] [G loss: 1.063709]\n",
      "epoch:14 step:13599 [D loss: 0.725403, acc.: 56.25%] [G loss: 1.107818]\n",
      "epoch:14 step:13600 [D loss: 0.574553, acc.: 65.62%] [G loss: 1.024588]\n",
      "epoch:14 step:13601 [D loss: 0.678295, acc.: 60.94%] [G loss: 1.231289]\n",
      "epoch:14 step:13602 [D loss: 0.569849, acc.: 71.88%] [G loss: 1.052549]\n",
      "epoch:14 step:13603 [D loss: 0.554369, acc.: 71.09%] [G loss: 1.250460]\n",
      "epoch:14 step:13604 [D loss: 0.493918, acc.: 77.34%] [G loss: 1.237608]\n",
      "epoch:14 step:13605 [D loss: 0.529202, acc.: 72.66%] [G loss: 1.309187]\n",
      "epoch:14 step:13606 [D loss: 0.587992, acc.: 67.97%] [G loss: 0.954693]\n",
      "epoch:14 step:13607 [D loss: 0.627243, acc.: 65.62%] [G loss: 0.965945]\n",
      "epoch:14 step:13608 [D loss: 0.648723, acc.: 63.28%] [G loss: 1.126861]\n",
      "epoch:14 step:13609 [D loss: 0.466398, acc.: 81.25%] [G loss: 1.286185]\n",
      "epoch:14 step:13610 [D loss: 0.640666, acc.: 64.06%] [G loss: 1.181313]\n",
      "epoch:14 step:13611 [D loss: 0.621034, acc.: 60.16%] [G loss: 1.359840]\n",
      "epoch:14 step:13612 [D loss: 0.566067, acc.: 68.75%] [G loss: 1.376237]\n",
      "epoch:14 step:13613 [D loss: 0.615245, acc.: 70.31%] [G loss: 1.189963]\n",
      "epoch:14 step:13614 [D loss: 0.553308, acc.: 71.88%] [G loss: 1.241791]\n",
      "epoch:14 step:13615 [D loss: 0.578578, acc.: 67.19%] [G loss: 1.267413]\n",
      "epoch:14 step:13616 [D loss: 0.630721, acc.: 64.84%] [G loss: 1.216576]\n",
      "epoch:14 step:13617 [D loss: 0.530226, acc.: 73.44%] [G loss: 1.317710]\n",
      "epoch:14 step:13618 [D loss: 0.636920, acc.: 61.72%] [G loss: 1.391532]\n",
      "epoch:14 step:13619 [D loss: 0.583622, acc.: 73.44%] [G loss: 1.381263]\n",
      "epoch:14 step:13620 [D loss: 0.652937, acc.: 63.28%] [G loss: 1.210743]\n",
      "epoch:14 step:13621 [D loss: 0.627138, acc.: 71.09%] [G loss: 1.043590]\n",
      "epoch:14 step:13622 [D loss: 0.651454, acc.: 59.38%] [G loss: 1.185309]\n",
      "epoch:14 step:13623 [D loss: 0.591285, acc.: 68.75%] [G loss: 1.292090]\n",
      "epoch:14 step:13624 [D loss: 0.502196, acc.: 78.12%] [G loss: 1.301850]\n",
      "epoch:14 step:13625 [D loss: 0.642758, acc.: 57.03%] [G loss: 1.244166]\n",
      "epoch:14 step:13626 [D loss: 0.552239, acc.: 75.78%] [G loss: 1.239635]\n",
      "epoch:14 step:13627 [D loss: 0.563401, acc.: 72.66%] [G loss: 0.977473]\n",
      "epoch:14 step:13628 [D loss: 0.578026, acc.: 67.19%] [G loss: 1.124875]\n",
      "epoch:14 step:13629 [D loss: 0.578308, acc.: 71.09%] [G loss: 1.018845]\n",
      "epoch:14 step:13630 [D loss: 0.511985, acc.: 78.91%] [G loss: 1.240249]\n",
      "epoch:14 step:13631 [D loss: 0.427463, acc.: 85.16%] [G loss: 1.355594]\n",
      "epoch:14 step:13632 [D loss: 0.630461, acc.: 67.19%] [G loss: 1.194342]\n",
      "epoch:14 step:13633 [D loss: 0.642300, acc.: 67.97%] [G loss: 1.180663]\n",
      "epoch:14 step:13634 [D loss: 0.566296, acc.: 71.88%] [G loss: 1.157953]\n",
      "epoch:14 step:13635 [D loss: 0.567160, acc.: 70.31%] [G loss: 1.271538]\n",
      "epoch:14 step:13636 [D loss: 0.547391, acc.: 71.09%] [G loss: 1.324801]\n",
      "epoch:14 step:13637 [D loss: 0.581931, acc.: 72.66%] [G loss: 1.431242]\n",
      "epoch:14 step:13638 [D loss: 0.543624, acc.: 76.56%] [G loss: 1.320995]\n",
      "epoch:14 step:13639 [D loss: 0.648929, acc.: 64.84%] [G loss: 1.051315]\n",
      "epoch:14 step:13640 [D loss: 0.599712, acc.: 71.09%] [G loss: 1.174267]\n",
      "epoch:14 step:13641 [D loss: 0.611930, acc.: 67.97%] [G loss: 1.090146]\n",
      "epoch:14 step:13642 [D loss: 0.548897, acc.: 73.44%] [G loss: 1.232720]\n",
      "epoch:14 step:13643 [D loss: 0.615210, acc.: 67.97%] [G loss: 1.029501]\n",
      "epoch:14 step:13644 [D loss: 0.749932, acc.: 50.00%] [G loss: 1.140652]\n",
      "epoch:14 step:13645 [D loss: 0.625145, acc.: 70.31%] [G loss: 1.245287]\n",
      "epoch:14 step:13646 [D loss: 0.492818, acc.: 78.12%] [G loss: 1.376906]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:14 step:13647 [D loss: 0.618309, acc.: 65.62%] [G loss: 1.155556]\n",
      "epoch:14 step:13648 [D loss: 0.566430, acc.: 70.31%] [G loss: 1.120963]\n",
      "epoch:14 step:13649 [D loss: 0.558247, acc.: 71.88%] [G loss: 1.256072]\n",
      "epoch:14 step:13650 [D loss: 0.674138, acc.: 62.50%] [G loss: 1.101364]\n",
      "epoch:14 step:13651 [D loss: 0.605437, acc.: 66.41%] [G loss: 1.060200]\n",
      "epoch:14 step:13652 [D loss: 0.588940, acc.: 71.88%] [G loss: 1.143823]\n",
      "epoch:14 step:13653 [D loss: 0.636307, acc.: 66.41%] [G loss: 1.382077]\n",
      "epoch:14 step:13654 [D loss: 0.555361, acc.: 71.88%] [G loss: 1.121989]\n",
      "epoch:14 step:13655 [D loss: 0.626985, acc.: 68.75%] [G loss: 1.033837]\n",
      "epoch:14 step:13656 [D loss: 0.550256, acc.: 72.66%] [G loss: 1.154208]\n",
      "epoch:14 step:13657 [D loss: 0.490547, acc.: 75.78%] [G loss: 1.202890]\n",
      "epoch:14 step:13658 [D loss: 0.666853, acc.: 60.94%] [G loss: 1.227194]\n",
      "epoch:14 step:13659 [D loss: 0.539850, acc.: 78.91%] [G loss: 1.279539]\n",
      "epoch:14 step:13660 [D loss: 0.581897, acc.: 67.97%] [G loss: 1.322411]\n",
      "epoch:14 step:13661 [D loss: 0.584440, acc.: 70.31%] [G loss: 1.296786]\n",
      "epoch:14 step:13662 [D loss: 0.557832, acc.: 69.53%] [G loss: 1.287175]\n",
      "epoch:14 step:13663 [D loss: 0.624940, acc.: 63.28%] [G loss: 1.246442]\n",
      "epoch:14 step:13664 [D loss: 0.520852, acc.: 77.34%] [G loss: 1.215080]\n",
      "epoch:14 step:13665 [D loss: 0.685312, acc.: 61.72%] [G loss: 1.109042]\n",
      "epoch:14 step:13666 [D loss: 0.653037, acc.: 60.94%] [G loss: 1.125570]\n",
      "epoch:14 step:13667 [D loss: 0.518342, acc.: 71.88%] [G loss: 1.120869]\n",
      "epoch:14 step:13668 [D loss: 0.518750, acc.: 75.78%] [G loss: 0.881344]\n",
      "epoch:14 step:13669 [D loss: 0.668271, acc.: 60.94%] [G loss: 1.484679]\n",
      "epoch:14 step:13670 [D loss: 0.547672, acc.: 75.00%] [G loss: 1.135812]\n",
      "epoch:14 step:13671 [D loss: 0.666904, acc.: 63.28%] [G loss: 1.146377]\n",
      "epoch:14 step:13672 [D loss: 0.617965, acc.: 64.06%] [G loss: 1.255224]\n",
      "epoch:14 step:13673 [D loss: 0.600162, acc.: 70.31%] [G loss: 1.093720]\n",
      "epoch:14 step:13674 [D loss: 0.577422, acc.: 72.66%] [G loss: 1.348615]\n",
      "epoch:14 step:13675 [D loss: 0.616175, acc.: 64.84%] [G loss: 1.119704]\n",
      "epoch:14 step:13676 [D loss: 0.614091, acc.: 66.41%] [G loss: 1.137571]\n",
      "epoch:14 step:13677 [D loss: 0.576683, acc.: 69.53%] [G loss: 1.171241]\n",
      "epoch:14 step:13678 [D loss: 0.635185, acc.: 62.50%] [G loss: 1.234547]\n",
      "epoch:14 step:13679 [D loss: 0.694638, acc.: 57.03%] [G loss: 0.987635]\n",
      "epoch:14 step:13680 [D loss: 0.553519, acc.: 68.75%] [G loss: 1.071422]\n",
      "epoch:14 step:13681 [D loss: 0.576503, acc.: 64.84%] [G loss: 1.023630]\n",
      "epoch:14 step:13682 [D loss: 0.588106, acc.: 70.31%] [G loss: 1.243658]\n",
      "epoch:14 step:13683 [D loss: 0.539915, acc.: 71.88%] [G loss: 1.164638]\n",
      "epoch:14 step:13684 [D loss: 0.555210, acc.: 71.09%] [G loss: 0.971828]\n",
      "epoch:14 step:13685 [D loss: 0.539025, acc.: 71.09%] [G loss: 1.254973]\n",
      "epoch:14 step:13686 [D loss: 0.668633, acc.: 62.50%] [G loss: 1.044892]\n",
      "epoch:14 step:13687 [D loss: 0.606889, acc.: 66.41%] [G loss: 1.226294]\n",
      "epoch:14 step:13688 [D loss: 0.648630, acc.: 61.72%] [G loss: 1.269008]\n",
      "epoch:14 step:13689 [D loss: 0.685468, acc.: 62.50%] [G loss: 1.031126]\n",
      "epoch:14 step:13690 [D loss: 0.481914, acc.: 78.91%] [G loss: 1.204180]\n",
      "epoch:14 step:13691 [D loss: 0.607205, acc.: 67.19%] [G loss: 1.171766]\n",
      "epoch:14 step:13692 [D loss: 0.544658, acc.: 75.00%] [G loss: 1.098308]\n",
      "epoch:14 step:13693 [D loss: 0.585124, acc.: 68.75%] [G loss: 1.219152]\n",
      "epoch:14 step:13694 [D loss: 0.464004, acc.: 83.59%] [G loss: 1.285476]\n",
      "epoch:14 step:13695 [D loss: 0.615677, acc.: 64.84%] [G loss: 1.200597]\n",
      "epoch:14 step:13696 [D loss: 0.583106, acc.: 72.66%] [G loss: 1.022401]\n",
      "epoch:14 step:13697 [D loss: 0.713981, acc.: 57.81%] [G loss: 1.471782]\n",
      "epoch:14 step:13698 [D loss: 0.542208, acc.: 78.12%] [G loss: 1.481332]\n",
      "epoch:14 step:13699 [D loss: 0.529447, acc.: 74.22%] [G loss: 1.041603]\n",
      "epoch:14 step:13700 [D loss: 0.549629, acc.: 71.88%] [G loss: 1.254506]\n",
      "epoch:14 step:13701 [D loss: 0.601174, acc.: 61.72%] [G loss: 1.008535]\n",
      "epoch:14 step:13702 [D loss: 0.542218, acc.: 75.78%] [G loss: 1.090043]\n",
      "epoch:14 step:13703 [D loss: 0.661589, acc.: 61.72%] [G loss: 1.362175]\n",
      "epoch:14 step:13704 [D loss: 0.521800, acc.: 77.34%] [G loss: 1.190073]\n",
      "epoch:14 step:13705 [D loss: 0.466512, acc.: 78.12%] [G loss: 1.399244]\n",
      "epoch:14 step:13706 [D loss: 0.717300, acc.: 58.59%] [G loss: 1.108677]\n",
      "epoch:14 step:13707 [D loss: 0.631615, acc.: 61.72%] [G loss: 1.235833]\n",
      "epoch:14 step:13708 [D loss: 0.487020, acc.: 80.47%] [G loss: 1.261533]\n",
      "epoch:14 step:13709 [D loss: 0.627288, acc.: 60.94%] [G loss: 0.977166]\n",
      "epoch:14 step:13710 [D loss: 0.596853, acc.: 69.53%] [G loss: 1.278393]\n",
      "epoch:14 step:13711 [D loss: 0.604675, acc.: 67.19%] [G loss: 1.160593]\n",
      "epoch:14 step:13712 [D loss: 0.499860, acc.: 73.44%] [G loss: 1.239933]\n",
      "epoch:14 step:13713 [D loss: 0.511654, acc.: 78.12%] [G loss: 1.058852]\n",
      "epoch:14 step:13714 [D loss: 0.587481, acc.: 69.53%] [G loss: 1.432498]\n",
      "epoch:14 step:13715 [D loss: 0.614977, acc.: 62.50%] [G loss: 1.347433]\n",
      "epoch:14 step:13716 [D loss: 0.724326, acc.: 60.16%] [G loss: 1.123348]\n",
      "epoch:14 step:13717 [D loss: 0.513866, acc.: 74.22%] [G loss: 1.320712]\n",
      "epoch:14 step:13718 [D loss: 0.575033, acc.: 73.44%] [G loss: 1.391408]\n",
      "epoch:14 step:13719 [D loss: 0.688167, acc.: 57.81%] [G loss: 1.170063]\n",
      "epoch:14 step:13720 [D loss: 0.513896, acc.: 74.22%] [G loss: 1.113142]\n",
      "epoch:14 step:13721 [D loss: 0.497463, acc.: 76.56%] [G loss: 1.001201]\n",
      "epoch:14 step:13722 [D loss: 0.613486, acc.: 68.75%] [G loss: 1.190031]\n",
      "epoch:14 step:13723 [D loss: 0.508798, acc.: 75.00%] [G loss: 0.992093]\n",
      "epoch:14 step:13724 [D loss: 0.553298, acc.: 69.53%] [G loss: 1.113761]\n",
      "epoch:14 step:13725 [D loss: 0.603255, acc.: 64.84%] [G loss: 1.062188]\n",
      "epoch:14 step:13726 [D loss: 0.505435, acc.: 76.56%] [G loss: 1.307254]\n",
      "epoch:14 step:13727 [D loss: 0.635768, acc.: 63.28%] [G loss: 1.196763]\n",
      "epoch:14 step:13728 [D loss: 0.807964, acc.: 46.88%] [G loss: 0.946729]\n",
      "epoch:14 step:13729 [D loss: 0.581682, acc.: 69.53%] [G loss: 1.433975]\n",
      "epoch:14 step:13730 [D loss: 0.659443, acc.: 59.38%] [G loss: 1.067484]\n",
      "epoch:14 step:13731 [D loss: 0.556641, acc.: 71.09%] [G loss: 1.146886]\n",
      "epoch:14 step:13732 [D loss: 0.580764, acc.: 69.53%] [G loss: 1.336308]\n",
      "epoch:14 step:13733 [D loss: 0.556476, acc.: 67.19%] [G loss: 1.153782]\n",
      "epoch:14 step:13734 [D loss: 0.642774, acc.: 69.53%] [G loss: 0.915344]\n",
      "epoch:14 step:13735 [D loss: 0.652536, acc.: 60.16%] [G loss: 1.043197]\n",
      "epoch:14 step:13736 [D loss: 0.688931, acc.: 60.16%] [G loss: 1.276705]\n",
      "epoch:14 step:13737 [D loss: 0.626485, acc.: 62.50%] [G loss: 1.202901]\n",
      "epoch:14 step:13738 [D loss: 0.657513, acc.: 59.38%] [G loss: 1.326386]\n",
      "epoch:14 step:13739 [D loss: 0.658001, acc.: 60.16%] [G loss: 1.169308]\n",
      "epoch:14 step:13740 [D loss: 0.612344, acc.: 67.97%] [G loss: 1.250551]\n",
      "epoch:14 step:13741 [D loss: 0.668828, acc.: 59.38%] [G loss: 1.121622]\n",
      "epoch:14 step:13742 [D loss: 0.621508, acc.: 63.28%] [G loss: 1.060460]\n",
      "epoch:14 step:13743 [D loss: 0.616892, acc.: 65.62%] [G loss: 0.983230]\n",
      "epoch:14 step:13744 [D loss: 0.513279, acc.: 73.44%] [G loss: 1.173371]\n",
      "epoch:14 step:13745 [D loss: 0.592548, acc.: 67.97%] [G loss: 1.088183]\n",
      "epoch:14 step:13746 [D loss: 0.641634, acc.: 60.16%] [G loss: 1.202058]\n",
      "epoch:14 step:13747 [D loss: 0.648573, acc.: 60.94%] [G loss: 1.252043]\n",
      "epoch:14 step:13748 [D loss: 0.614316, acc.: 64.84%] [G loss: 1.295398]\n",
      "epoch:14 step:13749 [D loss: 0.540930, acc.: 71.09%] [G loss: 1.068026]\n",
      "epoch:14 step:13750 [D loss: 0.530962, acc.: 71.88%] [G loss: 1.353598]\n",
      "epoch:14 step:13751 [D loss: 0.624210, acc.: 64.84%] [G loss: 1.193257]\n",
      "epoch:14 step:13752 [D loss: 0.634061, acc.: 64.84%] [G loss: 1.271646]\n",
      "epoch:14 step:13753 [D loss: 0.606212, acc.: 65.62%] [G loss: 1.269314]\n",
      "epoch:14 step:13754 [D loss: 0.625895, acc.: 67.19%] [G loss: 1.046556]\n",
      "epoch:14 step:13755 [D loss: 0.618741, acc.: 65.62%] [G loss: 1.189722]\n",
      "epoch:14 step:13756 [D loss: 0.472911, acc.: 78.12%] [G loss: 1.182235]\n",
      "epoch:14 step:13757 [D loss: 0.599019, acc.: 66.41%] [G loss: 1.128753]\n",
      "epoch:14 step:13758 [D loss: 0.455733, acc.: 84.38%] [G loss: 1.458693]\n",
      "epoch:14 step:13759 [D loss: 0.506935, acc.: 79.69%] [G loss: 1.537547]\n",
      "epoch:14 step:13760 [D loss: 0.661353, acc.: 64.84%] [G loss: 1.407729]\n",
      "epoch:14 step:13761 [D loss: 0.819661, acc.: 44.53%] [G loss: 0.934794]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:14 step:13762 [D loss: 0.533736, acc.: 70.31%] [G loss: 1.158687]\n",
      "epoch:14 step:13763 [D loss: 0.508867, acc.: 78.12%] [G loss: 1.143629]\n",
      "epoch:14 step:13764 [D loss: 0.595664, acc.: 65.62%] [G loss: 1.241226]\n",
      "epoch:14 step:13765 [D loss: 0.562394, acc.: 75.00%] [G loss: 1.155636]\n",
      "epoch:14 step:13766 [D loss: 0.513981, acc.: 74.22%] [G loss: 1.156514]\n",
      "epoch:14 step:13767 [D loss: 0.522187, acc.: 75.00%] [G loss: 1.203392]\n",
      "epoch:14 step:13768 [D loss: 0.560537, acc.: 71.09%] [G loss: 1.329891]\n",
      "epoch:14 step:13769 [D loss: 0.515656, acc.: 75.00%] [G loss: 1.339891]\n",
      "epoch:14 step:13770 [D loss: 0.599030, acc.: 70.31%] [G loss: 1.004527]\n",
      "epoch:14 step:13771 [D loss: 0.646563, acc.: 64.84%] [G loss: 1.267455]\n",
      "epoch:14 step:13772 [D loss: 0.483507, acc.: 78.91%] [G loss: 1.377781]\n",
      "epoch:14 step:13773 [D loss: 0.569485, acc.: 67.19%] [G loss: 1.189567]\n",
      "epoch:14 step:13774 [D loss: 0.514060, acc.: 78.91%] [G loss: 1.072103]\n",
      "epoch:14 step:13775 [D loss: 0.587290, acc.: 68.75%] [G loss: 1.094434]\n",
      "epoch:14 step:13776 [D loss: 0.622421, acc.: 67.97%] [G loss: 1.020962]\n",
      "epoch:14 step:13777 [D loss: 0.678702, acc.: 64.06%] [G loss: 1.152668]\n",
      "epoch:14 step:13778 [D loss: 0.610469, acc.: 69.53%] [G loss: 1.294714]\n",
      "epoch:14 step:13779 [D loss: 0.627566, acc.: 67.19%] [G loss: 1.178878]\n",
      "epoch:14 step:13780 [D loss: 0.697634, acc.: 57.03%] [G loss: 1.292489]\n",
      "epoch:14 step:13781 [D loss: 0.748577, acc.: 57.03%] [G loss: 1.121272]\n",
      "epoch:14 step:13782 [D loss: 0.601551, acc.: 61.72%] [G loss: 1.405015]\n",
      "epoch:14 step:13783 [D loss: 0.483188, acc.: 78.91%] [G loss: 1.192405]\n",
      "epoch:14 step:13784 [D loss: 0.687364, acc.: 56.25%] [G loss: 1.223424]\n",
      "epoch:14 step:13785 [D loss: 0.514962, acc.: 73.44%] [G loss: 1.317076]\n",
      "epoch:14 step:13786 [D loss: 0.685427, acc.: 57.81%] [G loss: 1.123154]\n",
      "epoch:14 step:13787 [D loss: 0.482456, acc.: 81.25%] [G loss: 0.998598]\n",
      "epoch:14 step:13788 [D loss: 0.551127, acc.: 71.88%] [G loss: 1.043952]\n",
      "epoch:14 step:13789 [D loss: 0.660045, acc.: 60.94%] [G loss: 1.109865]\n",
      "epoch:14 step:13790 [D loss: 0.481920, acc.: 75.78%] [G loss: 1.198480]\n",
      "epoch:14 step:13791 [D loss: 0.593232, acc.: 66.41%] [G loss: 1.145804]\n",
      "epoch:14 step:13792 [D loss: 0.518745, acc.: 76.56%] [G loss: 1.123278]\n",
      "epoch:14 step:13793 [D loss: 0.630553, acc.: 66.41%] [G loss: 1.277949]\n",
      "epoch:14 step:13794 [D loss: 0.628523, acc.: 64.06%] [G loss: 1.256586]\n",
      "epoch:14 step:13795 [D loss: 0.597114, acc.: 69.53%] [G loss: 1.171321]\n",
      "epoch:14 step:13796 [D loss: 0.668965, acc.: 63.28%] [G loss: 1.143301]\n",
      "epoch:14 step:13797 [D loss: 0.541907, acc.: 76.56%] [G loss: 1.045813]\n",
      "epoch:14 step:13798 [D loss: 0.666389, acc.: 64.84%] [G loss: 1.231802]\n",
      "epoch:14 step:13799 [D loss: 0.642389, acc.: 63.28%] [G loss: 1.185045]\n",
      "epoch:14 step:13800 [D loss: 0.691231, acc.: 58.59%] [G loss: 1.011618]\n",
      "epoch:14 step:13801 [D loss: 0.692366, acc.: 60.16%] [G loss: 1.084404]\n",
      "epoch:14 step:13802 [D loss: 0.630427, acc.: 67.19%] [G loss: 1.094819]\n",
      "epoch:14 step:13803 [D loss: 0.667396, acc.: 60.16%] [G loss: 1.112114]\n",
      "epoch:14 step:13804 [D loss: 0.581158, acc.: 71.09%] [G loss: 1.280965]\n",
      "epoch:14 step:13805 [D loss: 0.562329, acc.: 68.75%] [G loss: 1.309743]\n",
      "epoch:14 step:13806 [D loss: 0.596757, acc.: 70.31%] [G loss: 1.100136]\n",
      "epoch:14 step:13807 [D loss: 0.581855, acc.: 69.53%] [G loss: 1.256481]\n",
      "epoch:14 step:13808 [D loss: 0.564581, acc.: 73.44%] [G loss: 1.208586]\n",
      "epoch:14 step:13809 [D loss: 0.664206, acc.: 66.41%] [G loss: 1.178830]\n",
      "epoch:14 step:13810 [D loss: 0.561248, acc.: 67.19%] [G loss: 1.300330]\n",
      "epoch:14 step:13811 [D loss: 0.494846, acc.: 78.12%] [G loss: 1.268509]\n",
      "epoch:14 step:13812 [D loss: 0.803323, acc.: 55.47%] [G loss: 1.043221]\n",
      "epoch:14 step:13813 [D loss: 0.578323, acc.: 66.41%] [G loss: 1.008026]\n",
      "epoch:14 step:13814 [D loss: 0.645381, acc.: 61.72%] [G loss: 0.999759]\n",
      "epoch:14 step:13815 [D loss: 0.560349, acc.: 72.66%] [G loss: 1.294692]\n",
      "epoch:14 step:13816 [D loss: 0.644953, acc.: 61.72%] [G loss: 1.049659]\n",
      "epoch:14 step:13817 [D loss: 0.588509, acc.: 65.62%] [G loss: 0.995928]\n",
      "epoch:14 step:13818 [D loss: 0.707163, acc.: 60.94%] [G loss: 1.039908]\n",
      "epoch:14 step:13819 [D loss: 0.394961, acc.: 87.50%] [G loss: 1.297608]\n",
      "epoch:14 step:13820 [D loss: 0.532827, acc.: 73.44%] [G loss: 1.360499]\n",
      "epoch:14 step:13821 [D loss: 0.582721, acc.: 67.97%] [G loss: 1.389350]\n",
      "epoch:14 step:13822 [D loss: 0.616132, acc.: 65.62%] [G loss: 1.140922]\n",
      "epoch:14 step:13823 [D loss: 0.576423, acc.: 71.09%] [G loss: 1.166059]\n",
      "epoch:14 step:13824 [D loss: 0.506263, acc.: 74.22%] [G loss: 1.030371]\n",
      "epoch:14 step:13825 [D loss: 0.577608, acc.: 74.22%] [G loss: 1.167155]\n",
      "epoch:14 step:13826 [D loss: 0.562245, acc.: 67.97%] [G loss: 1.154392]\n",
      "epoch:14 step:13827 [D loss: 0.578111, acc.: 67.19%] [G loss: 1.086510]\n",
      "epoch:14 step:13828 [D loss: 0.575181, acc.: 67.19%] [G loss: 1.153340]\n",
      "epoch:14 step:13829 [D loss: 0.477018, acc.: 82.81%] [G loss: 1.433813]\n",
      "epoch:14 step:13830 [D loss: 0.586042, acc.: 67.97%] [G loss: 1.218550]\n",
      "epoch:14 step:13831 [D loss: 0.545623, acc.: 70.31%] [G loss: 1.107830]\n",
      "epoch:14 step:13832 [D loss: 0.671418, acc.: 55.47%] [G loss: 1.257971]\n",
      "epoch:14 step:13833 [D loss: 0.761827, acc.: 55.47%] [G loss: 1.178665]\n",
      "epoch:14 step:13834 [D loss: 0.531094, acc.: 72.66%] [G loss: 1.417652]\n",
      "epoch:14 step:13835 [D loss: 0.643193, acc.: 67.97%] [G loss: 1.353491]\n",
      "epoch:14 step:13836 [D loss: 0.514021, acc.: 72.66%] [G loss: 1.369539]\n",
      "epoch:14 step:13837 [D loss: 0.562854, acc.: 71.88%] [G loss: 1.338595]\n",
      "epoch:14 step:13838 [D loss: 0.671041, acc.: 66.41%] [G loss: 1.233167]\n",
      "epoch:14 step:13839 [D loss: 0.635582, acc.: 67.97%] [G loss: 1.066716]\n",
      "epoch:14 step:13840 [D loss: 0.614209, acc.: 66.41%] [G loss: 1.257861]\n",
      "epoch:14 step:13841 [D loss: 0.693446, acc.: 55.47%] [G loss: 0.930225]\n",
      "epoch:14 step:13842 [D loss: 0.629402, acc.: 62.50%] [G loss: 1.163921]\n",
      "epoch:14 step:13843 [D loss: 0.592134, acc.: 69.53%] [G loss: 1.582567]\n",
      "epoch:14 step:13844 [D loss: 0.513682, acc.: 74.22%] [G loss: 1.225510]\n",
      "epoch:14 step:13845 [D loss: 0.569222, acc.: 69.53%] [G loss: 1.139296]\n",
      "epoch:14 step:13846 [D loss: 0.578205, acc.: 67.19%] [G loss: 1.219987]\n",
      "epoch:14 step:13847 [D loss: 0.600334, acc.: 67.19%] [G loss: 1.305336]\n",
      "epoch:14 step:13848 [D loss: 0.574542, acc.: 71.88%] [G loss: 0.978783]\n",
      "epoch:14 step:13849 [D loss: 0.649715, acc.: 64.06%] [G loss: 1.241468]\n",
      "epoch:14 step:13850 [D loss: 0.595489, acc.: 66.41%] [G loss: 1.214126]\n",
      "epoch:14 step:13851 [D loss: 0.557770, acc.: 66.41%] [G loss: 1.220111]\n",
      "epoch:14 step:13852 [D loss: 0.586846, acc.: 67.97%] [G loss: 1.250398]\n",
      "epoch:14 step:13853 [D loss: 0.661653, acc.: 60.16%] [G loss: 1.141018]\n",
      "epoch:14 step:13854 [D loss: 0.562639, acc.: 69.53%] [G loss: 1.198285]\n",
      "epoch:14 step:13855 [D loss: 0.594736, acc.: 67.97%] [G loss: 1.264797]\n",
      "epoch:14 step:13856 [D loss: 0.707056, acc.: 53.91%] [G loss: 1.213637]\n",
      "epoch:14 step:13857 [D loss: 0.736706, acc.: 55.47%] [G loss: 0.831990]\n",
      "epoch:14 step:13858 [D loss: 0.618057, acc.: 61.72%] [G loss: 0.866018]\n",
      "epoch:14 step:13859 [D loss: 0.502302, acc.: 75.00%] [G loss: 1.218499]\n",
      "epoch:14 step:13860 [D loss: 0.615078, acc.: 71.09%] [G loss: 1.107566]\n",
      "epoch:14 step:13861 [D loss: 0.505129, acc.: 80.47%] [G loss: 1.051394]\n",
      "epoch:14 step:13862 [D loss: 0.570088, acc.: 67.19%] [G loss: 1.165487]\n",
      "epoch:14 step:13863 [D loss: 0.666688, acc.: 58.59%] [G loss: 1.423849]\n",
      "epoch:14 step:13864 [D loss: 0.608349, acc.: 71.88%] [G loss: 1.411191]\n",
      "epoch:14 step:13865 [D loss: 0.571752, acc.: 67.19%] [G loss: 1.342967]\n",
      "epoch:14 step:13866 [D loss: 0.581454, acc.: 70.31%] [G loss: 1.179643]\n",
      "epoch:14 step:13867 [D loss: 0.729968, acc.: 49.22%] [G loss: 0.875091]\n",
      "epoch:14 step:13868 [D loss: 0.544392, acc.: 70.31%] [G loss: 1.128994]\n",
      "epoch:14 step:13869 [D loss: 0.513544, acc.: 77.34%] [G loss: 1.204427]\n",
      "epoch:14 step:13870 [D loss: 0.631717, acc.: 60.94%] [G loss: 1.156609]\n",
      "epoch:14 step:13871 [D loss: 0.605693, acc.: 67.97%] [G loss: 1.032477]\n",
      "epoch:14 step:13872 [D loss: 0.523915, acc.: 75.00%] [G loss: 1.267250]\n",
      "epoch:14 step:13873 [D loss: 0.448756, acc.: 82.03%] [G loss: 1.633223]\n",
      "epoch:14 step:13874 [D loss: 0.581371, acc.: 63.28%] [G loss: 1.173056]\n",
      "epoch:14 step:13875 [D loss: 0.548812, acc.: 69.53%] [G loss: 1.336713]\n",
      "epoch:14 step:13876 [D loss: 0.577985, acc.: 70.31%] [G loss: 1.307600]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:14 step:13877 [D loss: 0.573419, acc.: 67.97%] [G loss: 1.271709]\n",
      "epoch:14 step:13878 [D loss: 0.640327, acc.: 60.94%] [G loss: 1.198532]\n",
      "epoch:14 step:13879 [D loss: 0.561683, acc.: 71.88%] [G loss: 1.315672]\n",
      "epoch:14 step:13880 [D loss: 0.456933, acc.: 82.81%] [G loss: 1.194749]\n",
      "epoch:14 step:13881 [D loss: 0.694669, acc.: 57.03%] [G loss: 1.095800]\n",
      "epoch:14 step:13882 [D loss: 0.521746, acc.: 75.78%] [G loss: 1.378680]\n",
      "epoch:14 step:13883 [D loss: 0.505973, acc.: 75.00%] [G loss: 1.124059]\n",
      "epoch:14 step:13884 [D loss: 0.478733, acc.: 77.34%] [G loss: 1.514740]\n",
      "epoch:14 step:13885 [D loss: 0.661414, acc.: 61.72%] [G loss: 1.410464]\n",
      "epoch:14 step:13886 [D loss: 0.576137, acc.: 68.75%] [G loss: 1.127633]\n",
      "epoch:14 step:13887 [D loss: 0.519736, acc.: 76.56%] [G loss: 1.203219]\n",
      "epoch:14 step:13888 [D loss: 0.648556, acc.: 62.50%] [G loss: 1.162970]\n",
      "epoch:14 step:13889 [D loss: 0.687815, acc.: 62.50%] [G loss: 0.986922]\n",
      "epoch:14 step:13890 [D loss: 0.543124, acc.: 71.09%] [G loss: 1.128321]\n",
      "epoch:14 step:13891 [D loss: 0.597149, acc.: 67.97%] [G loss: 1.368948]\n",
      "epoch:14 step:13892 [D loss: 0.604328, acc.: 68.75%] [G loss: 1.301945]\n",
      "epoch:14 step:13893 [D loss: 0.538211, acc.: 72.66%] [G loss: 1.417396]\n",
      "epoch:14 step:13894 [D loss: 0.532216, acc.: 73.44%] [G loss: 1.327130]\n",
      "epoch:14 step:13895 [D loss: 0.612437, acc.: 64.84%] [G loss: 1.020070]\n",
      "epoch:14 step:13896 [D loss: 0.622867, acc.: 64.84%] [G loss: 1.067076]\n",
      "epoch:14 step:13897 [D loss: 0.590418, acc.: 64.84%] [G loss: 1.265225]\n",
      "epoch:14 step:13898 [D loss: 0.608072, acc.: 67.97%] [G loss: 1.399714]\n",
      "epoch:14 step:13899 [D loss: 0.617704, acc.: 64.84%] [G loss: 1.361101]\n",
      "epoch:14 step:13900 [D loss: 0.616336, acc.: 59.38%] [G loss: 1.069829]\n",
      "epoch:14 step:13901 [D loss: 0.586259, acc.: 69.53%] [G loss: 0.880612]\n",
      "epoch:14 step:13902 [D loss: 0.565155, acc.: 69.53%] [G loss: 1.297385]\n",
      "epoch:14 step:13903 [D loss: 0.538832, acc.: 71.09%] [G loss: 1.266596]\n",
      "epoch:14 step:13904 [D loss: 0.697784, acc.: 59.38%] [G loss: 1.291052]\n",
      "epoch:14 step:13905 [D loss: 0.618661, acc.: 67.97%] [G loss: 1.211927]\n",
      "epoch:14 step:13906 [D loss: 0.629453, acc.: 64.06%] [G loss: 1.294029]\n",
      "epoch:14 step:13907 [D loss: 0.536201, acc.: 74.22%] [G loss: 1.495058]\n",
      "epoch:14 step:13908 [D loss: 0.552785, acc.: 73.44%] [G loss: 1.322505]\n",
      "epoch:14 step:13909 [D loss: 0.601970, acc.: 71.09%] [G loss: 1.106519]\n",
      "epoch:14 step:13910 [D loss: 0.559516, acc.: 69.53%] [G loss: 1.253595]\n",
      "epoch:14 step:13911 [D loss: 0.572000, acc.: 71.09%] [G loss: 1.204514]\n",
      "epoch:14 step:13912 [D loss: 0.551622, acc.: 70.31%] [G loss: 1.349576]\n",
      "epoch:14 step:13913 [D loss: 0.632171, acc.: 59.38%] [G loss: 1.202846]\n",
      "epoch:14 step:13914 [D loss: 0.566259, acc.: 69.53%] [G loss: 1.247505]\n",
      "epoch:14 step:13915 [D loss: 0.662023, acc.: 62.50%] [G loss: 1.320183]\n",
      "epoch:14 step:13916 [D loss: 0.647175, acc.: 62.50%] [G loss: 1.160074]\n",
      "epoch:14 step:13917 [D loss: 0.639585, acc.: 65.62%] [G loss: 1.305076]\n",
      "epoch:14 step:13918 [D loss: 0.647195, acc.: 63.28%] [G loss: 1.096211]\n",
      "epoch:14 step:13919 [D loss: 0.545499, acc.: 71.88%] [G loss: 1.176166]\n",
      "epoch:14 step:13920 [D loss: 0.779405, acc.: 53.12%] [G loss: 1.212532]\n",
      "epoch:14 step:13921 [D loss: 0.653516, acc.: 60.94%] [G loss: 1.101712]\n",
      "epoch:14 step:13922 [D loss: 0.559583, acc.: 72.66%] [G loss: 1.625638]\n",
      "epoch:14 step:13923 [D loss: 0.732322, acc.: 54.69%] [G loss: 1.150621]\n",
      "epoch:14 step:13924 [D loss: 0.547626, acc.: 75.00%] [G loss: 1.004721]\n",
      "epoch:14 step:13925 [D loss: 0.525330, acc.: 77.34%] [G loss: 1.245871]\n",
      "epoch:14 step:13926 [D loss: 0.522430, acc.: 78.91%] [G loss: 1.155346]\n",
      "epoch:14 step:13927 [D loss: 0.536589, acc.: 74.22%] [G loss: 1.093015]\n",
      "epoch:14 step:13928 [D loss: 0.525529, acc.: 75.00%] [G loss: 1.442706]\n",
      "epoch:14 step:13929 [D loss: 0.659762, acc.: 56.25%] [G loss: 1.314878]\n",
      "epoch:14 step:13930 [D loss: 0.641490, acc.: 68.75%] [G loss: 1.120028]\n",
      "epoch:14 step:13931 [D loss: 0.719849, acc.: 51.56%] [G loss: 1.095699]\n",
      "epoch:14 step:13932 [D loss: 0.562934, acc.: 73.44%] [G loss: 1.516373]\n",
      "epoch:14 step:13933 [D loss: 0.480198, acc.: 75.78%] [G loss: 1.328441]\n",
      "epoch:14 step:13934 [D loss: 0.538538, acc.: 73.44%] [G loss: 1.261452]\n",
      "epoch:14 step:13935 [D loss: 0.665720, acc.: 60.16%] [G loss: 1.276169]\n",
      "epoch:14 step:13936 [D loss: 0.516246, acc.: 75.78%] [G loss: 1.406598]\n",
      "epoch:14 step:13937 [D loss: 0.588179, acc.: 65.62%] [G loss: 1.285088]\n",
      "epoch:14 step:13938 [D loss: 0.477418, acc.: 79.69%] [G loss: 1.288149]\n",
      "epoch:14 step:13939 [D loss: 0.730946, acc.: 59.38%] [G loss: 1.082539]\n",
      "epoch:14 step:13940 [D loss: 0.685374, acc.: 60.94%] [G loss: 1.001884]\n",
      "epoch:14 step:13941 [D loss: 0.613688, acc.: 61.72%] [G loss: 0.964886]\n",
      "epoch:14 step:13942 [D loss: 0.689702, acc.: 58.59%] [G loss: 1.051159]\n",
      "epoch:14 step:13943 [D loss: 0.641258, acc.: 65.62%] [G loss: 1.250942]\n",
      "epoch:14 step:13944 [D loss: 0.559218, acc.: 75.00%] [G loss: 1.538618]\n",
      "epoch:14 step:13945 [D loss: 0.547028, acc.: 74.22%] [G loss: 1.261454]\n",
      "epoch:14 step:13946 [D loss: 0.514824, acc.: 76.56%] [G loss: 1.437307]\n",
      "epoch:14 step:13947 [D loss: 0.656532, acc.: 62.50%] [G loss: 0.931473]\n",
      "epoch:14 step:13948 [D loss: 0.516266, acc.: 78.12%] [G loss: 1.152843]\n",
      "epoch:14 step:13949 [D loss: 0.596222, acc.: 65.62%] [G loss: 1.181677]\n",
      "epoch:14 step:13950 [D loss: 0.551825, acc.: 75.00%] [G loss: 1.287314]\n",
      "epoch:14 step:13951 [D loss: 0.613027, acc.: 65.62%] [G loss: 1.184163]\n",
      "epoch:14 step:13952 [D loss: 0.538821, acc.: 78.12%] [G loss: 1.509014]\n",
      "epoch:14 step:13953 [D loss: 0.636056, acc.: 63.28%] [G loss: 1.063547]\n",
      "epoch:14 step:13954 [D loss: 0.757568, acc.: 51.56%] [G loss: 1.211396]\n",
      "epoch:14 step:13955 [D loss: 0.593163, acc.: 67.19%] [G loss: 1.169181]\n",
      "epoch:14 step:13956 [D loss: 0.486468, acc.: 77.34%] [G loss: 1.153956]\n",
      "epoch:14 step:13957 [D loss: 0.621697, acc.: 67.19%] [G loss: 1.272810]\n",
      "epoch:14 step:13958 [D loss: 0.506541, acc.: 75.00%] [G loss: 1.273297]\n",
      "epoch:14 step:13959 [D loss: 0.544837, acc.: 73.44%] [G loss: 1.267226]\n",
      "epoch:14 step:13960 [D loss: 0.662361, acc.: 60.94%] [G loss: 1.084938]\n",
      "epoch:14 step:13961 [D loss: 0.652134, acc.: 59.38%] [G loss: 1.072902]\n",
      "epoch:14 step:13962 [D loss: 0.544225, acc.: 72.66%] [G loss: 1.066500]\n",
      "epoch:14 step:13963 [D loss: 0.511569, acc.: 75.00%] [G loss: 1.429448]\n",
      "epoch:14 step:13964 [D loss: 0.669324, acc.: 60.94%] [G loss: 1.075431]\n",
      "epoch:14 step:13965 [D loss: 0.560358, acc.: 74.22%] [G loss: 0.905671]\n",
      "epoch:14 step:13966 [D loss: 0.674254, acc.: 58.59%] [G loss: 0.950596]\n",
      "epoch:14 step:13967 [D loss: 0.681591, acc.: 67.19%] [G loss: 0.938300]\n",
      "epoch:14 step:13968 [D loss: 0.607403, acc.: 65.62%] [G loss: 1.161437]\n",
      "epoch:14 step:13969 [D loss: 0.665066, acc.: 61.72%] [G loss: 1.134734]\n",
      "epoch:14 step:13970 [D loss: 0.542961, acc.: 71.09%] [G loss: 1.225756]\n",
      "epoch:14 step:13971 [D loss: 0.482688, acc.: 79.69%] [G loss: 1.228798]\n",
      "epoch:14 step:13972 [D loss: 0.627211, acc.: 67.97%] [G loss: 1.186861]\n",
      "epoch:14 step:13973 [D loss: 0.623772, acc.: 60.94%] [G loss: 1.128340]\n",
      "epoch:14 step:13974 [D loss: 0.558683, acc.: 71.09%] [G loss: 1.044445]\n",
      "epoch:14 step:13975 [D loss: 0.538863, acc.: 76.56%] [G loss: 1.428364]\n",
      "epoch:14 step:13976 [D loss: 0.541943, acc.: 73.44%] [G loss: 1.305482]\n",
      "epoch:14 step:13977 [D loss: 0.487316, acc.: 79.69%] [G loss: 1.504803]\n",
      "epoch:14 step:13978 [D loss: 0.670114, acc.: 57.81%] [G loss: 0.994125]\n",
      "epoch:14 step:13979 [D loss: 0.520852, acc.: 77.34%] [G loss: 1.090631]\n",
      "epoch:14 step:13980 [D loss: 0.535910, acc.: 71.09%] [G loss: 1.154932]\n",
      "epoch:14 step:13981 [D loss: 0.524611, acc.: 75.78%] [G loss: 0.978228]\n",
      "epoch:14 step:13982 [D loss: 0.685450, acc.: 54.69%] [G loss: 1.278725]\n",
      "epoch:14 step:13983 [D loss: 0.517590, acc.: 75.00%] [G loss: 0.992421]\n",
      "epoch:14 step:13984 [D loss: 0.573318, acc.: 71.88%] [G loss: 1.455964]\n",
      "epoch:14 step:13985 [D loss: 0.578290, acc.: 68.75%] [G loss: 1.294062]\n",
      "epoch:14 step:13986 [D loss: 0.562252, acc.: 74.22%] [G loss: 1.176473]\n",
      "epoch:14 step:13987 [D loss: 0.680606, acc.: 58.59%] [G loss: 1.052048]\n",
      "epoch:14 step:13988 [D loss: 0.508433, acc.: 75.78%] [G loss: 1.298991]\n",
      "epoch:14 step:13989 [D loss: 0.586180, acc.: 68.75%] [G loss: 1.035766]\n",
      "epoch:14 step:13990 [D loss: 0.551294, acc.: 67.19%] [G loss: 1.668944]\n",
      "epoch:14 step:13991 [D loss: 0.611422, acc.: 67.97%] [G loss: 0.930585]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:14 step:13992 [D loss: 0.556284, acc.: 68.75%] [G loss: 1.389904]\n",
      "epoch:14 step:13993 [D loss: 0.631027, acc.: 63.28%] [G loss: 1.226093]\n",
      "epoch:14 step:13994 [D loss: 0.626827, acc.: 64.84%] [G loss: 1.150650]\n",
      "epoch:14 step:13995 [D loss: 0.540472, acc.: 71.09%] [G loss: 1.072591]\n",
      "epoch:14 step:13996 [D loss: 0.600005, acc.: 65.62%] [G loss: 1.014289]\n",
      "epoch:14 step:13997 [D loss: 0.747457, acc.: 52.34%] [G loss: 0.937554]\n",
      "epoch:14 step:13998 [D loss: 0.555663, acc.: 72.66%] [G loss: 0.876584]\n",
      "epoch:14 step:13999 [D loss: 0.536858, acc.: 74.22%] [G loss: 1.019426]\n",
      "epoch:14 step:14000 [D loss: 0.572927, acc.: 70.31%] [G loss: 1.137631]\n",
      "epoch:14 step:14001 [D loss: 0.656787, acc.: 64.84%] [G loss: 1.253285]\n",
      "epoch:14 step:14002 [D loss: 0.593510, acc.: 67.19%] [G loss: 1.172177]\n",
      "epoch:14 step:14003 [D loss: 0.599428, acc.: 67.97%] [G loss: 1.165881]\n",
      "epoch:14 step:14004 [D loss: 0.540322, acc.: 72.66%] [G loss: 1.314994]\n",
      "epoch:14 step:14005 [D loss: 0.637297, acc.: 66.41%] [G loss: 1.104209]\n",
      "epoch:14 step:14006 [D loss: 0.590432, acc.: 70.31%] [G loss: 1.282810]\n",
      "epoch:14 step:14007 [D loss: 0.550827, acc.: 69.53%] [G loss: 1.253043]\n",
      "epoch:14 step:14008 [D loss: 0.552701, acc.: 75.78%] [G loss: 1.364587]\n",
      "epoch:14 step:14009 [D loss: 0.638955, acc.: 57.81%] [G loss: 1.094901]\n",
      "epoch:14 step:14010 [D loss: 0.606262, acc.: 65.62%] [G loss: 1.465183]\n",
      "epoch:14 step:14011 [D loss: 0.656929, acc.: 63.28%] [G loss: 1.095589]\n",
      "epoch:14 step:14012 [D loss: 0.499203, acc.: 77.34%] [G loss: 1.402826]\n",
      "epoch:14 step:14013 [D loss: 0.606517, acc.: 65.62%] [G loss: 1.078027]\n",
      "epoch:14 step:14014 [D loss: 0.575812, acc.: 69.53%] [G loss: 1.291779]\n",
      "epoch:14 step:14015 [D loss: 0.629069, acc.: 67.97%] [G loss: 0.968540]\n",
      "epoch:14 step:14016 [D loss: 0.487249, acc.: 76.56%] [G loss: 1.305832]\n",
      "epoch:14 step:14017 [D loss: 0.561796, acc.: 71.09%] [G loss: 1.064618]\n",
      "epoch:14 step:14018 [D loss: 0.635963, acc.: 64.06%] [G loss: 1.184093]\n",
      "epoch:14 step:14019 [D loss: 0.676731, acc.: 57.03%] [G loss: 1.062888]\n",
      "epoch:14 step:14020 [D loss: 0.623228, acc.: 62.50%] [G loss: 1.394680]\n",
      "epoch:14 step:14021 [D loss: 0.482979, acc.: 78.91%] [G loss: 1.328843]\n",
      "epoch:14 step:14022 [D loss: 0.597531, acc.: 67.19%] [G loss: 1.176823]\n",
      "epoch:14 step:14023 [D loss: 0.565679, acc.: 67.97%] [G loss: 1.252306]\n",
      "epoch:14 step:14024 [D loss: 0.519325, acc.: 75.78%] [G loss: 1.557393]\n",
      "epoch:14 step:14025 [D loss: 0.609212, acc.: 72.66%] [G loss: 1.370181]\n",
      "epoch:14 step:14026 [D loss: 0.641088, acc.: 60.94%] [G loss: 1.001214]\n",
      "epoch:14 step:14027 [D loss: 0.552019, acc.: 72.66%] [G loss: 1.246141]\n",
      "epoch:14 step:14028 [D loss: 0.605214, acc.: 66.41%] [G loss: 1.155438]\n",
      "epoch:14 step:14029 [D loss: 0.545903, acc.: 67.97%] [G loss: 1.180524]\n",
      "epoch:14 step:14030 [D loss: 0.587660, acc.: 68.75%] [G loss: 1.294950]\n",
      "epoch:14 step:14031 [D loss: 0.612603, acc.: 62.50%] [G loss: 1.234831]\n",
      "epoch:14 step:14032 [D loss: 0.529407, acc.: 72.66%] [G loss: 1.000088]\n",
      "epoch:14 step:14033 [D loss: 0.538282, acc.: 75.78%] [G loss: 1.329459]\n",
      "epoch:14 step:14034 [D loss: 0.490656, acc.: 78.12%] [G loss: 1.297988]\n",
      "epoch:14 step:14035 [D loss: 0.575880, acc.: 67.19%] [G loss: 1.351466]\n",
      "epoch:14 step:14036 [D loss: 0.518963, acc.: 75.00%] [G loss: 0.888795]\n",
      "epoch:14 step:14037 [D loss: 0.579527, acc.: 69.53%] [G loss: 1.159976]\n",
      "epoch:14 step:14038 [D loss: 0.580418, acc.: 72.66%] [G loss: 0.925409]\n",
      "epoch:14 step:14039 [D loss: 0.682088, acc.: 54.69%] [G loss: 1.256361]\n",
      "epoch:14 step:14040 [D loss: 0.675473, acc.: 58.59%] [G loss: 1.186240]\n",
      "epoch:14 step:14041 [D loss: 0.670932, acc.: 61.72%] [G loss: 1.261186]\n",
      "epoch:14 step:14042 [D loss: 0.711129, acc.: 57.81%] [G loss: 1.046650]\n",
      "epoch:14 step:14043 [D loss: 0.598384, acc.: 64.84%] [G loss: 1.140324]\n",
      "epoch:14 step:14044 [D loss: 0.497520, acc.: 79.69%] [G loss: 1.438564]\n",
      "epoch:14 step:14045 [D loss: 0.665547, acc.: 64.06%] [G loss: 1.198125]\n",
      "epoch:14 step:14046 [D loss: 0.432613, acc.: 82.81%] [G loss: 1.298847]\n",
      "epoch:14 step:14047 [D loss: 0.586027, acc.: 71.09%] [G loss: 0.984051]\n",
      "epoch:14 step:14048 [D loss: 0.545055, acc.: 74.22%] [G loss: 1.481550]\n",
      "epoch:14 step:14049 [D loss: 0.591269, acc.: 66.41%] [G loss: 1.039719]\n",
      "epoch:14 step:14050 [D loss: 0.611667, acc.: 67.97%] [G loss: 1.265130]\n",
      "epoch:14 step:14051 [D loss: 0.636400, acc.: 59.38%] [G loss: 1.350749]\n",
      "epoch:14 step:14052 [D loss: 0.582682, acc.: 68.75%] [G loss: 1.318956]\n",
      "epoch:14 step:14053 [D loss: 0.450339, acc.: 83.59%] [G loss: 1.418812]\n",
      "epoch:14 step:14054 [D loss: 0.539973, acc.: 69.53%] [G loss: 1.259534]\n",
      "epoch:14 step:14055 [D loss: 0.640984, acc.: 67.19%] [G loss: 1.291524]\n",
      "epoch:15 step:14056 [D loss: 0.726992, acc.: 52.34%] [G loss: 1.123991]\n",
      "epoch:15 step:14057 [D loss: 0.610421, acc.: 67.19%] [G loss: 1.177494]\n",
      "epoch:15 step:14058 [D loss: 0.664599, acc.: 60.94%] [G loss: 0.941106]\n",
      "epoch:15 step:14059 [D loss: 0.513346, acc.: 78.12%] [G loss: 1.234537]\n",
      "epoch:15 step:14060 [D loss: 0.690838, acc.: 60.94%] [G loss: 1.072488]\n",
      "epoch:15 step:14061 [D loss: 0.632038, acc.: 66.41%] [G loss: 1.363014]\n",
      "epoch:15 step:14062 [D loss: 0.550014, acc.: 71.88%] [G loss: 1.228971]\n",
      "epoch:15 step:14063 [D loss: 0.542957, acc.: 74.22%] [G loss: 1.198583]\n",
      "epoch:15 step:14064 [D loss: 0.536687, acc.: 75.78%] [G loss: 1.452359]\n",
      "epoch:15 step:14065 [D loss: 0.645111, acc.: 68.75%] [G loss: 1.039341]\n",
      "epoch:15 step:14066 [D loss: 0.390914, acc.: 85.94%] [G loss: 1.527348]\n",
      "epoch:15 step:14067 [D loss: 0.644783, acc.: 60.16%] [G loss: 1.127478]\n",
      "epoch:15 step:14068 [D loss: 0.579118, acc.: 68.75%] [G loss: 1.032102]\n",
      "epoch:15 step:14069 [D loss: 0.686721, acc.: 60.16%] [G loss: 1.048181]\n",
      "epoch:15 step:14070 [D loss: 0.541691, acc.: 76.56%] [G loss: 1.382211]\n",
      "epoch:15 step:14071 [D loss: 0.656398, acc.: 63.28%] [G loss: 1.382799]\n",
      "epoch:15 step:14072 [D loss: 0.504336, acc.: 82.81%] [G loss: 1.394663]\n",
      "epoch:15 step:14073 [D loss: 0.572286, acc.: 73.44%] [G loss: 1.313787]\n",
      "epoch:15 step:14074 [D loss: 0.586771, acc.: 71.09%] [G loss: 1.028038]\n",
      "epoch:15 step:14075 [D loss: 0.497142, acc.: 76.56%] [G loss: 1.306122]\n",
      "epoch:15 step:14076 [D loss: 0.696518, acc.: 60.16%] [G loss: 1.166428]\n",
      "epoch:15 step:14077 [D loss: 0.524015, acc.: 72.66%] [G loss: 1.205799]\n",
      "epoch:15 step:14078 [D loss: 0.647536, acc.: 63.28%] [G loss: 1.054433]\n",
      "epoch:15 step:14079 [D loss: 0.518990, acc.: 75.00%] [G loss: 1.174249]\n",
      "epoch:15 step:14080 [D loss: 0.607260, acc.: 66.41%] [G loss: 1.192536]\n",
      "epoch:15 step:14081 [D loss: 0.610407, acc.: 64.06%] [G loss: 1.591532]\n",
      "epoch:15 step:14082 [D loss: 0.660362, acc.: 59.38%] [G loss: 1.057527]\n",
      "epoch:15 step:14083 [D loss: 0.579308, acc.: 69.53%] [G loss: 1.231595]\n",
      "epoch:15 step:14084 [D loss: 0.638829, acc.: 63.28%] [G loss: 1.056587]\n",
      "epoch:15 step:14085 [D loss: 0.641348, acc.: 64.84%] [G loss: 1.158046]\n",
      "epoch:15 step:14086 [D loss: 0.625612, acc.: 65.62%] [G loss: 1.064586]\n",
      "epoch:15 step:14087 [D loss: 0.623976, acc.: 65.62%] [G loss: 1.427728]\n",
      "epoch:15 step:14088 [D loss: 0.559616, acc.: 75.78%] [G loss: 1.078941]\n",
      "epoch:15 step:14089 [D loss: 0.604942, acc.: 64.06%] [G loss: 1.016775]\n",
      "epoch:15 step:14090 [D loss: 0.599726, acc.: 67.19%] [G loss: 1.277651]\n",
      "epoch:15 step:14091 [D loss: 0.544336, acc.: 73.44%] [G loss: 1.294380]\n",
      "epoch:15 step:14092 [D loss: 0.494651, acc.: 77.34%] [G loss: 1.464348]\n",
      "epoch:15 step:14093 [D loss: 0.596434, acc.: 72.66%] [G loss: 1.263618]\n",
      "epoch:15 step:14094 [D loss: 0.593949, acc.: 64.06%] [G loss: 1.117907]\n",
      "epoch:15 step:14095 [D loss: 0.612891, acc.: 67.19%] [G loss: 1.368189]\n",
      "epoch:15 step:14096 [D loss: 0.607364, acc.: 67.19%] [G loss: 1.142800]\n",
      "epoch:15 step:14097 [D loss: 0.535515, acc.: 73.44%] [G loss: 1.145357]\n",
      "epoch:15 step:14098 [D loss: 0.720169, acc.: 57.03%] [G loss: 1.187963]\n",
      "epoch:15 step:14099 [D loss: 0.698954, acc.: 57.81%] [G loss: 1.234018]\n",
      "epoch:15 step:14100 [D loss: 0.499741, acc.: 73.44%] [G loss: 1.274132]\n",
      "epoch:15 step:14101 [D loss: 0.555265, acc.: 67.97%] [G loss: 1.060672]\n",
      "epoch:15 step:14102 [D loss: 0.638575, acc.: 65.62%] [G loss: 1.166452]\n",
      "epoch:15 step:14103 [D loss: 0.567021, acc.: 78.12%] [G loss: 1.197182]\n",
      "epoch:15 step:14104 [D loss: 0.555001, acc.: 70.31%] [G loss: 1.286684]\n",
      "epoch:15 step:14105 [D loss: 0.466220, acc.: 78.12%] [G loss: 1.410201]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:15 step:14106 [D loss: 0.624630, acc.: 67.19%] [G loss: 1.443643]\n",
      "epoch:15 step:14107 [D loss: 0.565715, acc.: 71.88%] [G loss: 0.972214]\n",
      "epoch:15 step:14108 [D loss: 0.565923, acc.: 70.31%] [G loss: 1.231347]\n",
      "epoch:15 step:14109 [D loss: 0.585049, acc.: 66.41%] [G loss: 1.198402]\n",
      "epoch:15 step:14110 [D loss: 0.691836, acc.: 63.28%] [G loss: 1.203070]\n",
      "epoch:15 step:14111 [D loss: 0.602600, acc.: 67.97%] [G loss: 1.272731]\n",
      "epoch:15 step:14112 [D loss: 0.555207, acc.: 71.09%] [G loss: 1.120625]\n",
      "epoch:15 step:14113 [D loss: 0.611213, acc.: 67.19%] [G loss: 1.218869]\n",
      "epoch:15 step:14114 [D loss: 0.553162, acc.: 71.09%] [G loss: 1.341083]\n",
      "epoch:15 step:14115 [D loss: 0.533196, acc.: 76.56%] [G loss: 1.306620]\n",
      "epoch:15 step:14116 [D loss: 0.723183, acc.: 57.81%] [G loss: 1.046257]\n",
      "epoch:15 step:14117 [D loss: 0.547671, acc.: 71.88%] [G loss: 1.413404]\n",
      "epoch:15 step:14118 [D loss: 0.627038, acc.: 60.16%] [G loss: 1.166911]\n",
      "epoch:15 step:14119 [D loss: 0.514366, acc.: 75.78%] [G loss: 1.056930]\n",
      "epoch:15 step:14120 [D loss: 0.472506, acc.: 76.56%] [G loss: 1.210223]\n",
      "epoch:15 step:14121 [D loss: 0.554057, acc.: 68.75%] [G loss: 1.064931]\n",
      "epoch:15 step:14122 [D loss: 0.536416, acc.: 71.88%] [G loss: 1.533444]\n",
      "epoch:15 step:14123 [D loss: 0.569325, acc.: 70.31%] [G loss: 1.063959]\n",
      "epoch:15 step:14124 [D loss: 0.504092, acc.: 79.69%] [G loss: 1.370785]\n",
      "epoch:15 step:14125 [D loss: 0.672141, acc.: 63.28%] [G loss: 1.094783]\n",
      "epoch:15 step:14126 [D loss: 0.602981, acc.: 70.31%] [G loss: 1.365640]\n",
      "epoch:15 step:14127 [D loss: 0.667614, acc.: 56.25%] [G loss: 1.086043]\n",
      "epoch:15 step:14128 [D loss: 0.495793, acc.: 78.91%] [G loss: 1.255547]\n",
      "epoch:15 step:14129 [D loss: 0.523850, acc.: 78.12%] [G loss: 1.133664]\n",
      "epoch:15 step:14130 [D loss: 0.611376, acc.: 66.41%] [G loss: 1.049049]\n",
      "epoch:15 step:14131 [D loss: 0.560999, acc.: 71.88%] [G loss: 1.252099]\n",
      "epoch:15 step:14132 [D loss: 0.629814, acc.: 71.88%] [G loss: 1.257954]\n",
      "epoch:15 step:14133 [D loss: 0.550743, acc.: 71.88%] [G loss: 1.124878]\n",
      "epoch:15 step:14134 [D loss: 0.635428, acc.: 67.19%] [G loss: 1.453099]\n",
      "epoch:15 step:14135 [D loss: 0.541195, acc.: 73.44%] [G loss: 1.052373]\n",
      "epoch:15 step:14136 [D loss: 0.527675, acc.: 71.09%] [G loss: 1.422032]\n",
      "epoch:15 step:14137 [D loss: 0.503977, acc.: 80.47%] [G loss: 1.465061]\n",
      "epoch:15 step:14138 [D loss: 0.635857, acc.: 61.72%] [G loss: 1.130806]\n",
      "epoch:15 step:14139 [D loss: 0.596533, acc.: 61.72%] [G loss: 1.357171]\n",
      "epoch:15 step:14140 [D loss: 0.453407, acc.: 81.25%] [G loss: 1.670081]\n",
      "epoch:15 step:14141 [D loss: 0.678874, acc.: 62.50%] [G loss: 1.062620]\n",
      "epoch:15 step:14142 [D loss: 0.646254, acc.: 62.50%] [G loss: 1.283454]\n",
      "epoch:15 step:14143 [D loss: 0.551422, acc.: 75.78%] [G loss: 1.100664]\n",
      "epoch:15 step:14144 [D loss: 0.581306, acc.: 71.09%] [G loss: 1.267113]\n",
      "epoch:15 step:14145 [D loss: 0.544605, acc.: 71.09%] [G loss: 1.333574]\n",
      "epoch:15 step:14146 [D loss: 0.535675, acc.: 73.44%] [G loss: 1.330977]\n",
      "epoch:15 step:14147 [D loss: 0.584497, acc.: 66.41%] [G loss: 1.168913]\n",
      "epoch:15 step:14148 [D loss: 0.507716, acc.: 76.56%] [G loss: 1.137514]\n",
      "epoch:15 step:14149 [D loss: 0.531865, acc.: 76.56%] [G loss: 1.148794]\n",
      "epoch:15 step:14150 [D loss: 0.601000, acc.: 64.84%] [G loss: 1.280341]\n",
      "epoch:15 step:14151 [D loss: 0.580312, acc.: 70.31%] [G loss: 1.259786]\n",
      "epoch:15 step:14152 [D loss: 0.700468, acc.: 59.38%] [G loss: 1.223127]\n",
      "epoch:15 step:14153 [D loss: 0.606889, acc.: 66.41%] [G loss: 1.056257]\n",
      "epoch:15 step:14154 [D loss: 0.543343, acc.: 76.56%] [G loss: 1.201657]\n",
      "epoch:15 step:14155 [D loss: 0.583880, acc.: 67.19%] [G loss: 1.262488]\n",
      "epoch:15 step:14156 [D loss: 0.572196, acc.: 71.09%] [G loss: 1.273244]\n",
      "epoch:15 step:14157 [D loss: 0.664318, acc.: 62.50%] [G loss: 0.909759]\n",
      "epoch:15 step:14158 [D loss: 0.501008, acc.: 78.12%] [G loss: 1.127339]\n",
      "epoch:15 step:14159 [D loss: 0.583151, acc.: 65.62%] [G loss: 1.089047]\n",
      "epoch:15 step:14160 [D loss: 0.478548, acc.: 81.25%] [G loss: 1.137605]\n",
      "epoch:15 step:14161 [D loss: 0.561554, acc.: 67.19%] [G loss: 1.158965]\n",
      "epoch:15 step:14162 [D loss: 0.557132, acc.: 73.44%] [G loss: 1.317479]\n",
      "epoch:15 step:14163 [D loss: 0.560701, acc.: 71.09%] [G loss: 1.206144]\n",
      "epoch:15 step:14164 [D loss: 0.830956, acc.: 50.00%] [G loss: 1.039146]\n",
      "epoch:15 step:14165 [D loss: 0.732435, acc.: 50.00%] [G loss: 1.113844]\n",
      "epoch:15 step:14166 [D loss: 0.550792, acc.: 72.66%] [G loss: 1.173818]\n",
      "epoch:15 step:14167 [D loss: 0.553918, acc.: 70.31%] [G loss: 1.179724]\n",
      "epoch:15 step:14168 [D loss: 0.569950, acc.: 71.88%] [G loss: 1.240284]\n",
      "epoch:15 step:14169 [D loss: 0.507887, acc.: 73.44%] [G loss: 1.255543]\n",
      "epoch:15 step:14170 [D loss: 0.475282, acc.: 85.16%] [G loss: 1.300144]\n",
      "epoch:15 step:14171 [D loss: 0.572823, acc.: 75.00%] [G loss: 1.250135]\n",
      "epoch:15 step:14172 [D loss: 0.584410, acc.: 69.53%] [G loss: 1.340938]\n",
      "epoch:15 step:14173 [D loss: 0.772694, acc.: 42.97%] [G loss: 1.041044]\n",
      "epoch:15 step:14174 [D loss: 0.662894, acc.: 65.62%] [G loss: 1.157986]\n",
      "epoch:15 step:14175 [D loss: 0.744866, acc.: 49.22%] [G loss: 1.088978]\n",
      "epoch:15 step:14176 [D loss: 0.634413, acc.: 61.72%] [G loss: 1.047682]\n",
      "epoch:15 step:14177 [D loss: 0.635452, acc.: 63.28%] [G loss: 1.168248]\n",
      "epoch:15 step:14178 [D loss: 0.482320, acc.: 78.12%] [G loss: 1.102344]\n",
      "epoch:15 step:14179 [D loss: 0.674660, acc.: 61.72%] [G loss: 1.147060]\n",
      "epoch:15 step:14180 [D loss: 0.452310, acc.: 85.94%] [G loss: 1.210712]\n",
      "epoch:15 step:14181 [D loss: 0.624293, acc.: 62.50%] [G loss: 1.301890]\n",
      "epoch:15 step:14182 [D loss: 0.560975, acc.: 66.41%] [G loss: 1.378629]\n",
      "epoch:15 step:14183 [D loss: 0.522474, acc.: 78.91%] [G loss: 1.176266]\n",
      "epoch:15 step:14184 [D loss: 0.573626, acc.: 73.44%] [G loss: 1.439933]\n",
      "epoch:15 step:14185 [D loss: 0.491446, acc.: 82.03%] [G loss: 1.136482]\n",
      "epoch:15 step:14186 [D loss: 0.536610, acc.: 73.44%] [G loss: 1.345351]\n",
      "epoch:15 step:14187 [D loss: 0.751053, acc.: 52.34%] [G loss: 1.022037]\n",
      "epoch:15 step:14188 [D loss: 0.559293, acc.: 72.66%] [G loss: 1.157158]\n",
      "epoch:15 step:14189 [D loss: 0.568958, acc.: 72.66%] [G loss: 0.973128]\n",
      "epoch:15 step:14190 [D loss: 0.631463, acc.: 64.06%] [G loss: 0.979286]\n",
      "epoch:15 step:14191 [D loss: 0.654397, acc.: 64.06%] [G loss: 1.292248]\n",
      "epoch:15 step:14192 [D loss: 0.585728, acc.: 66.41%] [G loss: 1.263186]\n",
      "epoch:15 step:14193 [D loss: 0.599386, acc.: 65.62%] [G loss: 1.236990]\n",
      "epoch:15 step:14194 [D loss: 0.595657, acc.: 64.84%] [G loss: 1.211856]\n",
      "epoch:15 step:14195 [D loss: 0.692578, acc.: 62.50%] [G loss: 1.235452]\n",
      "epoch:15 step:14196 [D loss: 0.663947, acc.: 56.25%] [G loss: 1.282900]\n",
      "epoch:15 step:14197 [D loss: 0.550927, acc.: 66.41%] [G loss: 1.234787]\n",
      "epoch:15 step:14198 [D loss: 0.641348, acc.: 60.94%] [G loss: 1.108691]\n",
      "epoch:15 step:14199 [D loss: 0.742505, acc.: 53.91%] [G loss: 1.240597]\n",
      "epoch:15 step:14200 [D loss: 0.576337, acc.: 69.53%] [G loss: 1.145255]\n",
      "epoch:15 step:14201 [D loss: 0.500017, acc.: 77.34%] [G loss: 1.258206]\n",
      "epoch:15 step:14202 [D loss: 0.584654, acc.: 68.75%] [G loss: 1.139642]\n",
      "epoch:15 step:14203 [D loss: 0.596291, acc.: 65.62%] [G loss: 1.225785]\n",
      "epoch:15 step:14204 [D loss: 0.544200, acc.: 70.31%] [G loss: 1.035518]\n",
      "epoch:15 step:14205 [D loss: 0.533575, acc.: 77.34%] [G loss: 1.509195]\n",
      "epoch:15 step:14206 [D loss: 0.730368, acc.: 53.91%] [G loss: 0.986312]\n",
      "epoch:15 step:14207 [D loss: 0.540237, acc.: 73.44%] [G loss: 1.109434]\n",
      "epoch:15 step:14208 [D loss: 0.510492, acc.: 73.44%] [G loss: 1.339949]\n",
      "epoch:15 step:14209 [D loss: 0.643017, acc.: 64.06%] [G loss: 1.237862]\n",
      "epoch:15 step:14210 [D loss: 0.613145, acc.: 63.28%] [G loss: 1.353333]\n",
      "epoch:15 step:14211 [D loss: 0.582322, acc.: 69.53%] [G loss: 1.268219]\n",
      "epoch:15 step:14212 [D loss: 0.628435, acc.: 66.41%] [G loss: 1.586094]\n",
      "epoch:15 step:14213 [D loss: 0.569696, acc.: 69.53%] [G loss: 1.026563]\n",
      "epoch:15 step:14214 [D loss: 0.655717, acc.: 63.28%] [G loss: 1.387971]\n",
      "epoch:15 step:14215 [D loss: 0.535255, acc.: 78.12%] [G loss: 1.339376]\n",
      "epoch:15 step:14216 [D loss: 0.480222, acc.: 81.25%] [G loss: 1.164305]\n",
      "epoch:15 step:14217 [D loss: 0.666217, acc.: 57.03%] [G loss: 1.043578]\n",
      "epoch:15 step:14218 [D loss: 0.676049, acc.: 64.06%] [G loss: 1.170815]\n",
      "epoch:15 step:14219 [D loss: 0.597134, acc.: 63.28%] [G loss: 1.135473]\n",
      "epoch:15 step:14220 [D loss: 0.646616, acc.: 67.97%] [G loss: 1.090508]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:15 step:14221 [D loss: 0.660044, acc.: 61.72%] [G loss: 1.036215]\n",
      "epoch:15 step:14222 [D loss: 0.616514, acc.: 70.31%] [G loss: 0.995155]\n",
      "epoch:15 step:14223 [D loss: 0.694860, acc.: 59.38%] [G loss: 1.252316]\n",
      "epoch:15 step:14224 [D loss: 0.613442, acc.: 67.19%] [G loss: 1.119642]\n",
      "epoch:15 step:14225 [D loss: 0.627000, acc.: 65.62%] [G loss: 0.952285]\n",
      "epoch:15 step:14226 [D loss: 0.574983, acc.: 73.44%] [G loss: 1.184030]\n",
      "epoch:15 step:14227 [D loss: 0.532973, acc.: 75.00%] [G loss: 1.230818]\n",
      "epoch:15 step:14228 [D loss: 0.668666, acc.: 57.81%] [G loss: 1.363886]\n",
      "epoch:15 step:14229 [D loss: 0.412549, acc.: 90.62%] [G loss: 1.477417]\n",
      "epoch:15 step:14230 [D loss: 0.607294, acc.: 67.97%] [G loss: 1.314848]\n",
      "epoch:15 step:14231 [D loss: 0.571763, acc.: 68.75%] [G loss: 1.204337]\n",
      "epoch:15 step:14232 [D loss: 0.512028, acc.: 75.00%] [G loss: 1.266095]\n",
      "epoch:15 step:14233 [D loss: 0.649403, acc.: 61.72%] [G loss: 1.075978]\n",
      "epoch:15 step:14234 [D loss: 0.683478, acc.: 59.38%] [G loss: 1.222704]\n",
      "epoch:15 step:14235 [D loss: 0.518665, acc.: 75.78%] [G loss: 1.186000]\n",
      "epoch:15 step:14236 [D loss: 0.548209, acc.: 72.66%] [G loss: 1.464314]\n",
      "epoch:15 step:14237 [D loss: 0.472522, acc.: 76.56%] [G loss: 1.342129]\n",
      "epoch:15 step:14238 [D loss: 0.599342, acc.: 68.75%] [G loss: 1.259483]\n",
      "epoch:15 step:14239 [D loss: 0.590397, acc.: 70.31%] [G loss: 1.136747]\n",
      "epoch:15 step:14240 [D loss: 0.533772, acc.: 74.22%] [G loss: 1.152198]\n",
      "epoch:15 step:14241 [D loss: 0.508239, acc.: 75.78%] [G loss: 1.460490]\n",
      "epoch:15 step:14242 [D loss: 0.496979, acc.: 77.34%] [G loss: 0.957651]\n",
      "epoch:15 step:14243 [D loss: 0.579571, acc.: 67.19%] [G loss: 1.387597]\n",
      "epoch:15 step:14244 [D loss: 0.626452, acc.: 64.06%] [G loss: 1.122803]\n",
      "epoch:15 step:14245 [D loss: 0.643144, acc.: 60.94%] [G loss: 1.095723]\n",
      "epoch:15 step:14246 [D loss: 0.599427, acc.: 70.31%] [G loss: 1.219687]\n",
      "epoch:15 step:14247 [D loss: 0.626099, acc.: 63.28%] [G loss: 1.140144]\n",
      "epoch:15 step:14248 [D loss: 0.540644, acc.: 75.78%] [G loss: 1.107888]\n",
      "epoch:15 step:14249 [D loss: 0.674952, acc.: 60.16%] [G loss: 0.869563]\n",
      "epoch:15 step:14250 [D loss: 0.553002, acc.: 71.09%] [G loss: 1.155244]\n",
      "epoch:15 step:14251 [D loss: 0.548327, acc.: 75.78%] [G loss: 1.169539]\n",
      "epoch:15 step:14252 [D loss: 0.623753, acc.: 63.28%] [G loss: 1.089929]\n",
      "epoch:15 step:14253 [D loss: 0.489672, acc.: 76.56%] [G loss: 1.286955]\n",
      "epoch:15 step:14254 [D loss: 0.521634, acc.: 71.88%] [G loss: 1.113989]\n",
      "epoch:15 step:14255 [D loss: 0.542690, acc.: 70.31%] [G loss: 1.058192]\n",
      "epoch:15 step:14256 [D loss: 0.405363, acc.: 89.06%] [G loss: 1.444512]\n",
      "epoch:15 step:14257 [D loss: 0.454864, acc.: 81.25%] [G loss: 1.277211]\n",
      "epoch:15 step:14258 [D loss: 0.487900, acc.: 78.91%] [G loss: 1.454050]\n",
      "epoch:15 step:14259 [D loss: 0.563269, acc.: 69.53%] [G loss: 1.296242]\n",
      "epoch:15 step:14260 [D loss: 0.605405, acc.: 71.88%] [G loss: 1.480345]\n",
      "epoch:15 step:14261 [D loss: 0.633498, acc.: 63.28%] [G loss: 1.289185]\n",
      "epoch:15 step:14262 [D loss: 0.566844, acc.: 71.09%] [G loss: 1.369742]\n",
      "epoch:15 step:14263 [D loss: 0.507661, acc.: 77.34%] [G loss: 1.392876]\n",
      "epoch:15 step:14264 [D loss: 0.683843, acc.: 58.59%] [G loss: 1.198148]\n",
      "epoch:15 step:14265 [D loss: 0.487857, acc.: 82.03%] [G loss: 1.109361]\n",
      "epoch:15 step:14266 [D loss: 0.613901, acc.: 69.53%] [G loss: 1.150425]\n",
      "epoch:15 step:14267 [D loss: 0.532318, acc.: 75.00%] [G loss: 1.350337]\n",
      "epoch:15 step:14268 [D loss: 0.552296, acc.: 68.75%] [G loss: 1.420266]\n",
      "epoch:15 step:14269 [D loss: 0.589256, acc.: 71.09%] [G loss: 1.256812]\n",
      "epoch:15 step:14270 [D loss: 0.769319, acc.: 49.22%] [G loss: 0.945030]\n",
      "epoch:15 step:14271 [D loss: 0.454823, acc.: 83.59%] [G loss: 1.218961]\n",
      "epoch:15 step:14272 [D loss: 0.607354, acc.: 69.53%] [G loss: 1.202872]\n",
      "epoch:15 step:14273 [D loss: 0.524807, acc.: 75.00%] [G loss: 1.556656]\n",
      "epoch:15 step:14274 [D loss: 0.632709, acc.: 67.97%] [G loss: 0.967153]\n",
      "epoch:15 step:14275 [D loss: 0.592904, acc.: 72.66%] [G loss: 1.335544]\n",
      "epoch:15 step:14276 [D loss: 0.560962, acc.: 69.53%] [G loss: 1.180080]\n",
      "epoch:15 step:14277 [D loss: 0.564652, acc.: 71.88%] [G loss: 1.307318]\n",
      "epoch:15 step:14278 [D loss: 0.602486, acc.: 67.19%] [G loss: 1.340696]\n",
      "epoch:15 step:14279 [D loss: 0.582641, acc.: 67.97%] [G loss: 0.962717]\n",
      "epoch:15 step:14280 [D loss: 0.496184, acc.: 77.34%] [G loss: 1.330122]\n",
      "epoch:15 step:14281 [D loss: 0.594959, acc.: 67.19%] [G loss: 1.067436]\n",
      "epoch:15 step:14282 [D loss: 0.610978, acc.: 67.97%] [G loss: 1.071915]\n",
      "epoch:15 step:14283 [D loss: 0.539080, acc.: 76.56%] [G loss: 1.103320]\n",
      "epoch:15 step:14284 [D loss: 0.625465, acc.: 64.06%] [G loss: 0.955005]\n",
      "epoch:15 step:14285 [D loss: 0.542368, acc.: 71.09%] [G loss: 1.025771]\n",
      "epoch:15 step:14286 [D loss: 0.492496, acc.: 80.47%] [G loss: 1.384806]\n",
      "epoch:15 step:14287 [D loss: 0.531171, acc.: 79.69%] [G loss: 1.329111]\n",
      "epoch:15 step:14288 [D loss: 0.579247, acc.: 69.53%] [G loss: 1.135672]\n",
      "epoch:15 step:14289 [D loss: 0.584090, acc.: 71.88%] [G loss: 0.996195]\n",
      "epoch:15 step:14290 [D loss: 0.559787, acc.: 71.09%] [G loss: 1.132049]\n",
      "epoch:15 step:14291 [D loss: 0.632529, acc.: 64.06%] [G loss: 1.161564]\n",
      "epoch:15 step:14292 [D loss: 0.637476, acc.: 61.72%] [G loss: 1.290883]\n",
      "epoch:15 step:14293 [D loss: 0.579597, acc.: 68.75%] [G loss: 1.099918]\n",
      "epoch:15 step:14294 [D loss: 0.480090, acc.: 80.47%] [G loss: 1.182774]\n",
      "epoch:15 step:14295 [D loss: 0.626978, acc.: 66.41%] [G loss: 1.152962]\n",
      "epoch:15 step:14296 [D loss: 0.552705, acc.: 71.09%] [G loss: 1.287265]\n",
      "epoch:15 step:14297 [D loss: 0.720545, acc.: 57.03%] [G loss: 1.073730]\n",
      "epoch:15 step:14298 [D loss: 0.661934, acc.: 56.25%] [G loss: 1.114591]\n",
      "epoch:15 step:14299 [D loss: 0.498547, acc.: 80.47%] [G loss: 1.185017]\n",
      "epoch:15 step:14300 [D loss: 0.682528, acc.: 62.50%] [G loss: 1.098824]\n",
      "epoch:15 step:14301 [D loss: 0.472928, acc.: 79.69%] [G loss: 1.483706]\n",
      "epoch:15 step:14302 [D loss: 0.591234, acc.: 72.66%] [G loss: 1.438227]\n",
      "epoch:15 step:14303 [D loss: 0.607166, acc.: 64.84%] [G loss: 1.295498]\n",
      "epoch:15 step:14304 [D loss: 0.492735, acc.: 76.56%] [G loss: 1.366308]\n",
      "epoch:15 step:14305 [D loss: 0.528750, acc.: 72.66%] [G loss: 1.218266]\n",
      "epoch:15 step:14306 [D loss: 0.578772, acc.: 69.53%] [G loss: 1.228429]\n",
      "epoch:15 step:14307 [D loss: 0.605179, acc.: 71.09%] [G loss: 1.252180]\n",
      "epoch:15 step:14308 [D loss: 0.450977, acc.: 82.03%] [G loss: 1.305277]\n",
      "epoch:15 step:14309 [D loss: 0.566931, acc.: 72.66%] [G loss: 1.157117]\n",
      "epoch:15 step:14310 [D loss: 0.524319, acc.: 78.12%] [G loss: 1.391676]\n",
      "epoch:15 step:14311 [D loss: 0.549060, acc.: 75.00%] [G loss: 1.286668]\n",
      "epoch:15 step:14312 [D loss: 0.583698, acc.: 67.19%] [G loss: 1.108072]\n",
      "epoch:15 step:14313 [D loss: 0.493427, acc.: 77.34%] [G loss: 1.215749]\n",
      "epoch:15 step:14314 [D loss: 0.627244, acc.: 62.50%] [G loss: 1.104715]\n",
      "epoch:15 step:14315 [D loss: 0.470238, acc.: 82.81%] [G loss: 1.166639]\n",
      "epoch:15 step:14316 [D loss: 0.571306, acc.: 75.78%] [G loss: 1.304032]\n",
      "epoch:15 step:14317 [D loss: 0.702931, acc.: 57.03%] [G loss: 1.071443]\n",
      "epoch:15 step:14318 [D loss: 0.683846, acc.: 60.94%] [G loss: 1.194898]\n",
      "epoch:15 step:14319 [D loss: 0.692152, acc.: 58.59%] [G loss: 1.086405]\n",
      "epoch:15 step:14320 [D loss: 0.538381, acc.: 73.44%] [G loss: 1.413662]\n",
      "epoch:15 step:14321 [D loss: 0.599251, acc.: 69.53%] [G loss: 1.190052]\n",
      "epoch:15 step:14322 [D loss: 0.567327, acc.: 68.75%] [G loss: 1.141749]\n",
      "epoch:15 step:14323 [D loss: 0.548954, acc.: 76.56%] [G loss: 1.426443]\n",
      "epoch:15 step:14324 [D loss: 0.443827, acc.: 80.47%] [G loss: 1.270823]\n",
      "epoch:15 step:14325 [D loss: 0.568020, acc.: 69.53%] [G loss: 1.097531]\n",
      "epoch:15 step:14326 [D loss: 0.552367, acc.: 69.53%] [G loss: 1.242958]\n",
      "epoch:15 step:14327 [D loss: 0.647438, acc.: 61.72%] [G loss: 1.036039]\n",
      "epoch:15 step:14328 [D loss: 0.642047, acc.: 62.50%] [G loss: 1.070426]\n",
      "epoch:15 step:14329 [D loss: 0.588344, acc.: 68.75%] [G loss: 0.995135]\n",
      "epoch:15 step:14330 [D loss: 0.704105, acc.: 59.38%] [G loss: 1.204388]\n",
      "epoch:15 step:14331 [D loss: 0.830826, acc.: 45.31%] [G loss: 0.987577]\n",
      "epoch:15 step:14332 [D loss: 0.490072, acc.: 79.69%] [G loss: 1.141268]\n",
      "epoch:15 step:14333 [D loss: 0.610851, acc.: 68.75%] [G loss: 1.019257]\n",
      "epoch:15 step:14334 [D loss: 0.657757, acc.: 60.94%] [G loss: 1.236036]\n",
      "epoch:15 step:14335 [D loss: 0.565660, acc.: 72.66%] [G loss: 1.061273]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:15 step:14336 [D loss: 0.569411, acc.: 71.09%] [G loss: 1.250830]\n",
      "epoch:15 step:14337 [D loss: 0.551607, acc.: 76.56%] [G loss: 1.116196]\n",
      "epoch:15 step:14338 [D loss: 0.548185, acc.: 76.56%] [G loss: 1.213012]\n",
      "epoch:15 step:14339 [D loss: 0.715507, acc.: 56.25%] [G loss: 1.186061]\n",
      "epoch:15 step:14340 [D loss: 0.508748, acc.: 77.34%] [G loss: 1.173801]\n",
      "epoch:15 step:14341 [D loss: 0.605578, acc.: 67.97%] [G loss: 1.301971]\n",
      "epoch:15 step:14342 [D loss: 0.706475, acc.: 57.03%] [G loss: 1.055463]\n",
      "epoch:15 step:14343 [D loss: 0.486232, acc.: 75.78%] [G loss: 1.088098]\n",
      "epoch:15 step:14344 [D loss: 0.564562, acc.: 67.97%] [G loss: 1.366436]\n",
      "epoch:15 step:14345 [D loss: 0.472853, acc.: 78.12%] [G loss: 1.438242]\n",
      "epoch:15 step:14346 [D loss: 0.746515, acc.: 53.91%] [G loss: 1.175695]\n",
      "epoch:15 step:14347 [D loss: 0.591451, acc.: 67.19%] [G loss: 1.155452]\n",
      "epoch:15 step:14348 [D loss: 0.638266, acc.: 65.62%] [G loss: 1.337536]\n",
      "epoch:15 step:14349 [D loss: 0.494890, acc.: 77.34%] [G loss: 1.428353]\n",
      "epoch:15 step:14350 [D loss: 0.615981, acc.: 67.97%] [G loss: 1.101127]\n",
      "epoch:15 step:14351 [D loss: 0.508010, acc.: 72.66%] [G loss: 1.393152]\n",
      "epoch:15 step:14352 [D loss: 0.595904, acc.: 65.62%] [G loss: 1.189448]\n",
      "epoch:15 step:14353 [D loss: 0.565457, acc.: 73.44%] [G loss: 1.103252]\n",
      "epoch:15 step:14354 [D loss: 0.549332, acc.: 70.31%] [G loss: 1.272038]\n",
      "epoch:15 step:14355 [D loss: 0.529963, acc.: 76.56%] [G loss: 1.289856]\n",
      "epoch:15 step:14356 [D loss: 0.446560, acc.: 79.69%] [G loss: 1.498571]\n",
      "epoch:15 step:14357 [D loss: 0.641120, acc.: 67.97%] [G loss: 1.184330]\n",
      "epoch:15 step:14358 [D loss: 0.590089, acc.: 64.84%] [G loss: 1.080814]\n",
      "epoch:15 step:14359 [D loss: 0.577026, acc.: 68.75%] [G loss: 1.216947]\n",
      "epoch:15 step:14360 [D loss: 0.630911, acc.: 64.84%] [G loss: 1.215816]\n",
      "epoch:15 step:14361 [D loss: 0.645941, acc.: 65.62%] [G loss: 1.152720]\n",
      "epoch:15 step:14362 [D loss: 0.600201, acc.: 66.41%] [G loss: 1.111292]\n",
      "epoch:15 step:14363 [D loss: 0.603110, acc.: 67.19%] [G loss: 1.355177]\n",
      "epoch:15 step:14364 [D loss: 0.598446, acc.: 67.97%] [G loss: 1.106242]\n",
      "epoch:15 step:14365 [D loss: 0.613041, acc.: 64.06%] [G loss: 1.243142]\n",
      "epoch:15 step:14366 [D loss: 0.497576, acc.: 72.66%] [G loss: 1.373441]\n",
      "epoch:15 step:14367 [D loss: 0.548403, acc.: 74.22%] [G loss: 1.100649]\n",
      "epoch:15 step:14368 [D loss: 0.597497, acc.: 67.19%] [G loss: 0.842188]\n",
      "epoch:15 step:14369 [D loss: 0.659687, acc.: 61.72%] [G loss: 0.971139]\n",
      "epoch:15 step:14370 [D loss: 0.514960, acc.: 77.34%] [G loss: 1.442756]\n",
      "epoch:15 step:14371 [D loss: 0.578877, acc.: 66.41%] [G loss: 1.244642]\n",
      "epoch:15 step:14372 [D loss: 0.564291, acc.: 68.75%] [G loss: 1.246471]\n",
      "epoch:15 step:14373 [D loss: 0.690339, acc.: 60.16%] [G loss: 1.202796]\n",
      "epoch:15 step:14374 [D loss: 0.581768, acc.: 68.75%] [G loss: 1.142875]\n",
      "epoch:15 step:14375 [D loss: 0.672046, acc.: 59.38%] [G loss: 1.188922]\n",
      "epoch:15 step:14376 [D loss: 0.587133, acc.: 64.06%] [G loss: 1.263488]\n",
      "epoch:15 step:14377 [D loss: 0.607241, acc.: 65.62%] [G loss: 1.170625]\n",
      "epoch:15 step:14378 [D loss: 0.639256, acc.: 63.28%] [G loss: 0.971211]\n",
      "epoch:15 step:14379 [D loss: 0.605167, acc.: 65.62%] [G loss: 0.989292]\n",
      "epoch:15 step:14380 [D loss: 0.472163, acc.: 80.47%] [G loss: 1.268204]\n",
      "epoch:15 step:14381 [D loss: 0.630108, acc.: 64.84%] [G loss: 1.287119]\n",
      "epoch:15 step:14382 [D loss: 0.548154, acc.: 75.00%] [G loss: 1.257023]\n",
      "epoch:15 step:14383 [D loss: 0.543680, acc.: 68.75%] [G loss: 1.296323]\n",
      "epoch:15 step:14384 [D loss: 0.616874, acc.: 60.94%] [G loss: 1.156582]\n",
      "epoch:15 step:14385 [D loss: 0.767787, acc.: 54.69%] [G loss: 1.163373]\n",
      "epoch:15 step:14386 [D loss: 0.617890, acc.: 64.84%] [G loss: 0.732611]\n",
      "epoch:15 step:14387 [D loss: 0.604320, acc.: 70.31%] [G loss: 1.162675]\n",
      "epoch:15 step:14388 [D loss: 0.661677, acc.: 58.59%] [G loss: 1.222076]\n",
      "epoch:15 step:14389 [D loss: 0.570411, acc.: 72.66%] [G loss: 1.044396]\n",
      "epoch:15 step:14390 [D loss: 0.621897, acc.: 66.41%] [G loss: 1.104719]\n",
      "epoch:15 step:14391 [D loss: 0.584670, acc.: 68.75%] [G loss: 1.141078]\n",
      "epoch:15 step:14392 [D loss: 0.642327, acc.: 61.72%] [G loss: 1.087072]\n",
      "epoch:15 step:14393 [D loss: 0.473113, acc.: 79.69%] [G loss: 1.309860]\n",
      "epoch:15 step:14394 [D loss: 0.530960, acc.: 76.56%] [G loss: 1.280726]\n",
      "epoch:15 step:14395 [D loss: 0.650802, acc.: 67.97%] [G loss: 1.021497]\n",
      "epoch:15 step:14396 [D loss: 0.553706, acc.: 73.44%] [G loss: 1.014141]\n",
      "epoch:15 step:14397 [D loss: 0.611235, acc.: 67.97%] [G loss: 1.222893]\n",
      "epoch:15 step:14398 [D loss: 0.536412, acc.: 74.22%] [G loss: 1.051334]\n",
      "epoch:15 step:14399 [D loss: 0.572894, acc.: 64.84%] [G loss: 1.147392]\n",
      "epoch:15 step:14400 [D loss: 0.568312, acc.: 72.66%] [G loss: 1.197663]\n",
      "epoch:15 step:14401 [D loss: 0.554199, acc.: 72.66%] [G loss: 1.113918]\n",
      "epoch:15 step:14402 [D loss: 0.642353, acc.: 62.50%] [G loss: 1.175266]\n",
      "epoch:15 step:14403 [D loss: 0.474195, acc.: 77.34%] [G loss: 1.355786]\n",
      "epoch:15 step:14404 [D loss: 0.532856, acc.: 71.09%] [G loss: 0.987634]\n",
      "epoch:15 step:14405 [D loss: 0.558910, acc.: 71.09%] [G loss: 1.189701]\n",
      "epoch:15 step:14406 [D loss: 0.574081, acc.: 71.09%] [G loss: 1.066257]\n",
      "epoch:15 step:14407 [D loss: 0.734203, acc.: 53.12%] [G loss: 1.079913]\n",
      "epoch:15 step:14408 [D loss: 0.475989, acc.: 78.91%] [G loss: 1.271284]\n",
      "epoch:15 step:14409 [D loss: 0.576950, acc.: 70.31%] [G loss: 1.022665]\n",
      "epoch:15 step:14410 [D loss: 0.569771, acc.: 70.31%] [G loss: 1.084931]\n",
      "epoch:15 step:14411 [D loss: 0.574953, acc.: 68.75%] [G loss: 1.507671]\n",
      "epoch:15 step:14412 [D loss: 0.503935, acc.: 71.88%] [G loss: 1.114205]\n",
      "epoch:15 step:14413 [D loss: 0.638213, acc.: 61.72%] [G loss: 1.068537]\n",
      "epoch:15 step:14414 [D loss: 0.754451, acc.: 47.66%] [G loss: 1.185008]\n",
      "epoch:15 step:14415 [D loss: 0.522941, acc.: 77.34%] [G loss: 1.330422]\n",
      "epoch:15 step:14416 [D loss: 0.624061, acc.: 67.19%] [G loss: 1.556723]\n",
      "epoch:15 step:14417 [D loss: 0.543646, acc.: 75.00%] [G loss: 1.257702]\n",
      "epoch:15 step:14418 [D loss: 0.515480, acc.: 75.78%] [G loss: 0.972539]\n",
      "epoch:15 step:14419 [D loss: 0.570670, acc.: 68.75%] [G loss: 1.127007]\n",
      "epoch:15 step:14420 [D loss: 0.582546, acc.: 69.53%] [G loss: 1.160473]\n",
      "epoch:15 step:14421 [D loss: 0.568959, acc.: 72.66%] [G loss: 1.025641]\n",
      "epoch:15 step:14422 [D loss: 0.506961, acc.: 80.47%] [G loss: 1.295118]\n",
      "epoch:15 step:14423 [D loss: 0.524182, acc.: 79.69%] [G loss: 1.429847]\n",
      "epoch:15 step:14424 [D loss: 0.578100, acc.: 71.09%] [G loss: 1.336702]\n",
      "epoch:15 step:14425 [D loss: 0.621117, acc.: 70.31%] [G loss: 1.157066]\n",
      "epoch:15 step:14426 [D loss: 0.595670, acc.: 71.09%] [G loss: 1.270365]\n",
      "epoch:15 step:14427 [D loss: 0.542750, acc.: 72.66%] [G loss: 1.191425]\n",
      "epoch:15 step:14428 [D loss: 0.668611, acc.: 64.84%] [G loss: 1.188955]\n",
      "epoch:15 step:14429 [D loss: 0.700867, acc.: 56.25%] [G loss: 1.343252]\n",
      "epoch:15 step:14430 [D loss: 0.699596, acc.: 62.50%] [G loss: 1.233086]\n",
      "epoch:15 step:14431 [D loss: 0.600964, acc.: 69.53%] [G loss: 1.321685]\n",
      "epoch:15 step:14432 [D loss: 0.442926, acc.: 84.38%] [G loss: 1.228985]\n",
      "epoch:15 step:14433 [D loss: 0.574845, acc.: 71.09%] [G loss: 1.189328]\n",
      "epoch:15 step:14434 [D loss: 0.548964, acc.: 71.09%] [G loss: 1.194155]\n",
      "epoch:15 step:14435 [D loss: 0.494336, acc.: 76.56%] [G loss: 1.113489]\n",
      "epoch:15 step:14436 [D loss: 0.597954, acc.: 71.88%] [G loss: 1.135737]\n",
      "epoch:15 step:14437 [D loss: 0.637106, acc.: 57.03%] [G loss: 1.195417]\n",
      "epoch:15 step:14438 [D loss: 0.564879, acc.: 70.31%] [G loss: 1.052362]\n",
      "epoch:15 step:14439 [D loss: 0.563780, acc.: 73.44%] [G loss: 1.130190]\n",
      "epoch:15 step:14440 [D loss: 0.585374, acc.: 66.41%] [G loss: 1.279457]\n",
      "epoch:15 step:14441 [D loss: 0.706643, acc.: 58.59%] [G loss: 1.078668]\n",
      "epoch:15 step:14442 [D loss: 0.502763, acc.: 78.12%] [G loss: 1.088061]\n",
      "epoch:15 step:14443 [D loss: 0.556076, acc.: 68.75%] [G loss: 1.199808]\n",
      "epoch:15 step:14444 [D loss: 0.662369, acc.: 58.59%] [G loss: 1.133604]\n",
      "epoch:15 step:14445 [D loss: 0.523455, acc.: 78.91%] [G loss: 1.344146]\n",
      "epoch:15 step:14446 [D loss: 0.737876, acc.: 51.56%] [G loss: 1.215960]\n",
      "epoch:15 step:14447 [D loss: 0.504683, acc.: 77.34%] [G loss: 1.403671]\n",
      "epoch:15 step:14448 [D loss: 0.609102, acc.: 71.09%] [G loss: 1.271971]\n",
      "epoch:15 step:14449 [D loss: 0.549161, acc.: 75.78%] [G loss: 1.212293]\n",
      "epoch:15 step:14450 [D loss: 0.552465, acc.: 70.31%] [G loss: 1.233090]\n",
      "epoch:15 step:14451 [D loss: 0.689267, acc.: 62.50%] [G loss: 1.059530]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:15 step:14452 [D loss: 0.659293, acc.: 61.72%] [G loss: 1.279584]\n",
      "epoch:15 step:14453 [D loss: 0.490681, acc.: 82.03%] [G loss: 1.177936]\n",
      "epoch:15 step:14454 [D loss: 0.591391, acc.: 68.75%] [G loss: 1.120043]\n",
      "epoch:15 step:14455 [D loss: 0.579319, acc.: 63.28%] [G loss: 1.300121]\n",
      "epoch:15 step:14456 [D loss: 0.669754, acc.: 64.06%] [G loss: 1.326693]\n",
      "epoch:15 step:14457 [D loss: 0.618404, acc.: 67.97%] [G loss: 1.201882]\n",
      "epoch:15 step:14458 [D loss: 0.561430, acc.: 69.53%] [G loss: 1.312903]\n",
      "epoch:15 step:14459 [D loss: 0.632300, acc.: 62.50%] [G loss: 1.271988]\n",
      "epoch:15 step:14460 [D loss: 0.563072, acc.: 70.31%] [G loss: 1.280992]\n",
      "epoch:15 step:14461 [D loss: 0.496812, acc.: 78.12%] [G loss: 1.154083]\n",
      "epoch:15 step:14462 [D loss: 0.577308, acc.: 64.06%] [G loss: 1.534672]\n",
      "epoch:15 step:14463 [D loss: 0.695326, acc.: 57.03%] [G loss: 1.151785]\n",
      "epoch:15 step:14464 [D loss: 0.569211, acc.: 71.09%] [G loss: 1.326760]\n",
      "epoch:15 step:14465 [D loss: 0.750476, acc.: 48.44%] [G loss: 0.960297]\n",
      "epoch:15 step:14466 [D loss: 0.539068, acc.: 71.88%] [G loss: 1.197586]\n",
      "epoch:15 step:14467 [D loss: 0.558055, acc.: 72.66%] [G loss: 1.257594]\n",
      "epoch:15 step:14468 [D loss: 0.662952, acc.: 60.16%] [G loss: 1.202672]\n",
      "epoch:15 step:14469 [D loss: 0.684039, acc.: 57.03%] [G loss: 1.189905]\n",
      "epoch:15 step:14470 [D loss: 0.446842, acc.: 81.25%] [G loss: 1.322952]\n",
      "epoch:15 step:14471 [D loss: 0.529845, acc.: 72.66%] [G loss: 1.344181]\n",
      "epoch:15 step:14472 [D loss: 0.592525, acc.: 66.41%] [G loss: 1.145857]\n",
      "epoch:15 step:14473 [D loss: 0.685654, acc.: 60.94%] [G loss: 1.100900]\n",
      "epoch:15 step:14474 [D loss: 0.618925, acc.: 67.97%] [G loss: 1.303313]\n",
      "epoch:15 step:14475 [D loss: 0.458996, acc.: 81.25%] [G loss: 1.369800]\n",
      "epoch:15 step:14476 [D loss: 0.584124, acc.: 71.88%] [G loss: 1.224144]\n",
      "epoch:15 step:14477 [D loss: 0.659042, acc.: 60.94%] [G loss: 1.213341]\n",
      "epoch:15 step:14478 [D loss: 0.472392, acc.: 80.47%] [G loss: 1.349519]\n",
      "epoch:15 step:14479 [D loss: 0.612822, acc.: 60.94%] [G loss: 1.158436]\n",
      "epoch:15 step:14480 [D loss: 0.624233, acc.: 69.53%] [G loss: 1.211113]\n",
      "epoch:15 step:14481 [D loss: 0.597377, acc.: 66.41%] [G loss: 1.269843]\n",
      "epoch:15 step:14482 [D loss: 0.612646, acc.: 67.97%] [G loss: 1.292900]\n",
      "epoch:15 step:14483 [D loss: 0.682417, acc.: 58.59%] [G loss: 1.182156]\n",
      "epoch:15 step:14484 [D loss: 0.593030, acc.: 63.28%] [G loss: 1.341801]\n",
      "epoch:15 step:14485 [D loss: 0.537231, acc.: 74.22%] [G loss: 1.282450]\n",
      "epoch:15 step:14486 [D loss: 0.621822, acc.: 66.41%] [G loss: 1.295796]\n",
      "epoch:15 step:14487 [D loss: 0.500128, acc.: 72.66%] [G loss: 1.284277]\n",
      "epoch:15 step:14488 [D loss: 0.761079, acc.: 53.12%] [G loss: 0.854985]\n",
      "epoch:15 step:14489 [D loss: 0.659403, acc.: 61.72%] [G loss: 1.271981]\n",
      "epoch:15 step:14490 [D loss: 0.557670, acc.: 70.31%] [G loss: 1.350367]\n",
      "epoch:15 step:14491 [D loss: 0.636195, acc.: 64.06%] [G loss: 1.021755]\n",
      "epoch:15 step:14492 [D loss: 0.628643, acc.: 64.06%] [G loss: 1.370053]\n",
      "epoch:15 step:14493 [D loss: 0.550644, acc.: 76.56%] [G loss: 1.173655]\n",
      "epoch:15 step:14494 [D loss: 0.596350, acc.: 70.31%] [G loss: 1.425288]\n",
      "epoch:15 step:14495 [D loss: 0.601953, acc.: 64.84%] [G loss: 1.282832]\n",
      "epoch:15 step:14496 [D loss: 0.580474, acc.: 71.09%] [G loss: 1.127639]\n",
      "epoch:15 step:14497 [D loss: 0.572459, acc.: 67.19%] [G loss: 0.968371]\n",
      "epoch:15 step:14498 [D loss: 0.485484, acc.: 78.12%] [G loss: 1.165371]\n",
      "epoch:15 step:14499 [D loss: 0.544975, acc.: 73.44%] [G loss: 1.229818]\n",
      "epoch:15 step:14500 [D loss: 0.623414, acc.: 67.19%] [G loss: 1.354023]\n",
      "epoch:15 step:14501 [D loss: 0.753444, acc.: 52.34%] [G loss: 1.280406]\n",
      "epoch:15 step:14502 [D loss: 0.651253, acc.: 60.94%] [G loss: 1.302780]\n",
      "epoch:15 step:14503 [D loss: 0.702361, acc.: 62.50%] [G loss: 1.097124]\n",
      "epoch:15 step:14504 [D loss: 0.598094, acc.: 69.53%] [G loss: 1.285533]\n",
      "epoch:15 step:14505 [D loss: 0.579208, acc.: 71.09%] [G loss: 1.194859]\n",
      "epoch:15 step:14506 [D loss: 0.511014, acc.: 76.56%] [G loss: 1.414199]\n",
      "epoch:15 step:14507 [D loss: 0.647050, acc.: 61.72%] [G loss: 1.084914]\n",
      "epoch:15 step:14508 [D loss: 0.531733, acc.: 72.66%] [G loss: 1.358300]\n",
      "epoch:15 step:14509 [D loss: 0.583695, acc.: 67.97%] [G loss: 1.205955]\n",
      "epoch:15 step:14510 [D loss: 0.431627, acc.: 86.72%] [G loss: 1.176163]\n",
      "epoch:15 step:14511 [D loss: 0.538728, acc.: 72.66%] [G loss: 1.409532]\n",
      "epoch:15 step:14512 [D loss: 0.765609, acc.: 50.00%] [G loss: 1.028800]\n",
      "epoch:15 step:14513 [D loss: 0.508891, acc.: 77.34%] [G loss: 1.331914]\n",
      "epoch:15 step:14514 [D loss: 0.636732, acc.: 67.19%] [G loss: 1.170518]\n",
      "epoch:15 step:14515 [D loss: 0.536140, acc.: 76.56%] [G loss: 1.277484]\n",
      "epoch:15 step:14516 [D loss: 0.665797, acc.: 60.16%] [G loss: 1.258185]\n",
      "epoch:15 step:14517 [D loss: 0.547852, acc.: 70.31%] [G loss: 1.510890]\n",
      "epoch:15 step:14518 [D loss: 0.678325, acc.: 60.94%] [G loss: 1.349745]\n",
      "epoch:15 step:14519 [D loss: 0.604593, acc.: 68.75%] [G loss: 0.925330]\n",
      "epoch:15 step:14520 [D loss: 0.577039, acc.: 78.12%] [G loss: 1.369228]\n",
      "epoch:15 step:14521 [D loss: 0.614508, acc.: 65.62%] [G loss: 1.048239]\n",
      "epoch:15 step:14522 [D loss: 0.457838, acc.: 82.03%] [G loss: 1.317440]\n",
      "epoch:15 step:14523 [D loss: 0.604585, acc.: 69.53%] [G loss: 1.366292]\n",
      "epoch:15 step:14524 [D loss: 0.540156, acc.: 73.44%] [G loss: 1.475806]\n",
      "epoch:15 step:14525 [D loss: 0.729285, acc.: 55.47%] [G loss: 1.031522]\n",
      "epoch:15 step:14526 [D loss: 0.625964, acc.: 61.72%] [G loss: 0.990811]\n",
      "epoch:15 step:14527 [D loss: 0.485457, acc.: 81.25%] [G loss: 1.511983]\n",
      "epoch:15 step:14528 [D loss: 0.485766, acc.: 78.91%] [G loss: 1.246317]\n",
      "epoch:15 step:14529 [D loss: 0.641084, acc.: 65.62%] [G loss: 1.171267]\n",
      "epoch:15 step:14530 [D loss: 0.586827, acc.: 71.09%] [G loss: 1.093827]\n",
      "epoch:15 step:14531 [D loss: 0.617403, acc.: 67.19%] [G loss: 1.488002]\n",
      "epoch:15 step:14532 [D loss: 0.635901, acc.: 65.62%] [G loss: 1.208103]\n",
      "epoch:15 step:14533 [D loss: 0.571430, acc.: 71.88%] [G loss: 1.356699]\n",
      "epoch:15 step:14534 [D loss: 0.554253, acc.: 73.44%] [G loss: 1.406706]\n",
      "epoch:15 step:14535 [D loss: 0.445074, acc.: 81.25%] [G loss: 1.314530]\n",
      "epoch:15 step:14536 [D loss: 0.644017, acc.: 59.38%] [G loss: 1.215181]\n",
      "epoch:15 step:14537 [D loss: 0.529590, acc.: 73.44%] [G loss: 1.382537]\n",
      "epoch:15 step:14538 [D loss: 0.729713, acc.: 58.59%] [G loss: 0.996651]\n",
      "epoch:15 step:14539 [D loss: 0.578605, acc.: 66.41%] [G loss: 0.921346]\n",
      "epoch:15 step:14540 [D loss: 0.726010, acc.: 51.56%] [G loss: 0.858818]\n",
      "epoch:15 step:14541 [D loss: 0.523699, acc.: 79.69%] [G loss: 1.016025]\n",
      "epoch:15 step:14542 [D loss: 0.559612, acc.: 67.97%] [G loss: 1.349841]\n",
      "epoch:15 step:14543 [D loss: 0.530488, acc.: 70.31%] [G loss: 1.254293]\n",
      "epoch:15 step:14544 [D loss: 0.654307, acc.: 58.59%] [G loss: 1.152652]\n",
      "epoch:15 step:14545 [D loss: 0.444668, acc.: 83.59%] [G loss: 1.222786]\n",
      "epoch:15 step:14546 [D loss: 0.484320, acc.: 80.47%] [G loss: 1.112327]\n",
      "epoch:15 step:14547 [D loss: 0.597767, acc.: 66.41%] [G loss: 1.546441]\n",
      "epoch:15 step:14548 [D loss: 0.632738, acc.: 63.28%] [G loss: 1.166908]\n",
      "epoch:15 step:14549 [D loss: 0.595769, acc.: 67.97%] [G loss: 1.241023]\n",
      "epoch:15 step:14550 [D loss: 0.489630, acc.: 78.91%] [G loss: 1.236839]\n",
      "epoch:15 step:14551 [D loss: 0.551912, acc.: 74.22%] [G loss: 1.217229]\n",
      "epoch:15 step:14552 [D loss: 0.597406, acc.: 71.09%] [G loss: 1.217067]\n",
      "epoch:15 step:14553 [D loss: 0.582603, acc.: 71.09%] [G loss: 1.442896]\n",
      "epoch:15 step:14554 [D loss: 0.513730, acc.: 75.00%] [G loss: 1.162262]\n",
      "epoch:15 step:14555 [D loss: 0.641433, acc.: 61.72%] [G loss: 1.120431]\n",
      "epoch:15 step:14556 [D loss: 0.695982, acc.: 56.25%] [G loss: 1.112614]\n",
      "epoch:15 step:14557 [D loss: 0.673304, acc.: 59.38%] [G loss: 1.182829]\n",
      "epoch:15 step:14558 [D loss: 0.601095, acc.: 70.31%] [G loss: 1.249300]\n",
      "epoch:15 step:14559 [D loss: 0.644616, acc.: 71.88%] [G loss: 1.465712]\n",
      "epoch:15 step:14560 [D loss: 0.505342, acc.: 77.34%] [G loss: 1.254135]\n",
      "epoch:15 step:14561 [D loss: 0.570498, acc.: 73.44%] [G loss: 1.194967]\n",
      "epoch:15 step:14562 [D loss: 0.616231, acc.: 63.28%] [G loss: 1.250647]\n",
      "epoch:15 step:14563 [D loss: 0.547019, acc.: 69.53%] [G loss: 1.064554]\n",
      "epoch:15 step:14564 [D loss: 0.568903, acc.: 66.41%] [G loss: 1.186302]\n",
      "epoch:15 step:14565 [D loss: 0.539706, acc.: 76.56%] [G loss: 1.291185]\n",
      "epoch:15 step:14566 [D loss: 0.611056, acc.: 66.41%] [G loss: 1.268065]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:15 step:14567 [D loss: 0.583303, acc.: 71.88%] [G loss: 1.277672]\n",
      "epoch:15 step:14568 [D loss: 0.456978, acc.: 79.69%] [G loss: 1.112486]\n",
      "epoch:15 step:14569 [D loss: 0.550285, acc.: 70.31%] [G loss: 1.211876]\n",
      "epoch:15 step:14570 [D loss: 0.661939, acc.: 58.59%] [G loss: 1.068316]\n",
      "epoch:15 step:14571 [D loss: 0.655190, acc.: 60.16%] [G loss: 1.204851]\n",
      "epoch:15 step:14572 [D loss: 0.744133, acc.: 55.47%] [G loss: 1.095389]\n",
      "epoch:15 step:14573 [D loss: 0.640777, acc.: 66.41%] [G loss: 1.268094]\n",
      "epoch:15 step:14574 [D loss: 0.587475, acc.: 62.50%] [G loss: 1.072835]\n",
      "epoch:15 step:14575 [D loss: 0.586860, acc.: 67.19%] [G loss: 1.223589]\n",
      "epoch:15 step:14576 [D loss: 0.605206, acc.: 64.06%] [G loss: 1.246156]\n",
      "epoch:15 step:14577 [D loss: 0.616717, acc.: 67.19%] [G loss: 1.484444]\n",
      "epoch:15 step:14578 [D loss: 0.693063, acc.: 57.03%] [G loss: 1.193053]\n",
      "epoch:15 step:14579 [D loss: 0.573388, acc.: 73.44%] [G loss: 1.286508]\n",
      "epoch:15 step:14580 [D loss: 0.529211, acc.: 73.44%] [G loss: 1.253434]\n",
      "epoch:15 step:14581 [D loss: 0.636446, acc.: 62.50%] [G loss: 1.089163]\n",
      "epoch:15 step:14582 [D loss: 0.551685, acc.: 71.88%] [G loss: 1.351760]\n",
      "epoch:15 step:14583 [D loss: 0.499583, acc.: 73.44%] [G loss: 1.162256]\n",
      "epoch:15 step:14584 [D loss: 0.567302, acc.: 70.31%] [G loss: 1.209215]\n",
      "epoch:15 step:14585 [D loss: 0.498260, acc.: 78.91%] [G loss: 1.429727]\n",
      "epoch:15 step:14586 [D loss: 0.671103, acc.: 57.81%] [G loss: 1.453655]\n",
      "epoch:15 step:14587 [D loss: 0.622810, acc.: 64.84%] [G loss: 1.204517]\n",
      "epoch:15 step:14588 [D loss: 0.552409, acc.: 72.66%] [G loss: 1.258255]\n",
      "epoch:15 step:14589 [D loss: 0.600013, acc.: 67.19%] [G loss: 1.177886]\n",
      "epoch:15 step:14590 [D loss: 0.556146, acc.: 75.00%] [G loss: 1.276774]\n",
      "epoch:15 step:14591 [D loss: 0.686578, acc.: 62.50%] [G loss: 1.011033]\n",
      "epoch:15 step:14592 [D loss: 0.554209, acc.: 70.31%] [G loss: 1.152025]\n",
      "epoch:15 step:14593 [D loss: 0.625701, acc.: 68.75%] [G loss: 1.071872]\n",
      "epoch:15 step:14594 [D loss: 0.455204, acc.: 85.16%] [G loss: 1.275954]\n",
      "epoch:15 step:14595 [D loss: 0.485975, acc.: 78.91%] [G loss: 1.271378]\n",
      "epoch:15 step:14596 [D loss: 0.454210, acc.: 82.81%] [G loss: 1.401568]\n",
      "epoch:15 step:14597 [D loss: 0.587621, acc.: 66.41%] [G loss: 1.311614]\n",
      "epoch:15 step:14598 [D loss: 0.553500, acc.: 68.75%] [G loss: 1.128545]\n",
      "epoch:15 step:14599 [D loss: 0.595537, acc.: 71.09%] [G loss: 1.023418]\n",
      "epoch:15 step:14600 [D loss: 0.641761, acc.: 64.06%] [G loss: 1.100125]\n",
      "epoch:15 step:14601 [D loss: 0.674176, acc.: 58.59%] [G loss: 1.257590]\n",
      "epoch:15 step:14602 [D loss: 0.482759, acc.: 78.91%] [G loss: 1.428488]\n",
      "epoch:15 step:14603 [D loss: 0.667826, acc.: 64.06%] [G loss: 1.139785]\n",
      "epoch:15 step:14604 [D loss: 0.593724, acc.: 66.41%] [G loss: 1.276602]\n",
      "epoch:15 step:14605 [D loss: 0.463694, acc.: 81.25%] [G loss: 0.861983]\n",
      "epoch:15 step:14606 [D loss: 0.660444, acc.: 63.28%] [G loss: 1.070136]\n",
      "epoch:15 step:14607 [D loss: 0.555558, acc.: 71.09%] [G loss: 1.263740]\n",
      "epoch:15 step:14608 [D loss: 0.669970, acc.: 59.38%] [G loss: 1.145202]\n",
      "epoch:15 step:14609 [D loss: 0.559787, acc.: 71.88%] [G loss: 1.195163]\n",
      "epoch:15 step:14610 [D loss: 0.593934, acc.: 68.75%] [G loss: 1.058176]\n",
      "epoch:15 step:14611 [D loss: 0.519112, acc.: 79.69%] [G loss: 1.072737]\n",
      "epoch:15 step:14612 [D loss: 0.469663, acc.: 81.25%] [G loss: 0.977847]\n",
      "epoch:15 step:14613 [D loss: 0.569955, acc.: 71.09%] [G loss: 1.232088]\n",
      "epoch:15 step:14614 [D loss: 0.613609, acc.: 64.84%] [G loss: 1.091367]\n",
      "epoch:15 step:14615 [D loss: 0.733584, acc.: 52.34%] [G loss: 1.294409]\n",
      "epoch:15 step:14616 [D loss: 0.582705, acc.: 67.97%] [G loss: 1.291543]\n",
      "epoch:15 step:14617 [D loss: 0.502294, acc.: 80.47%] [G loss: 1.190192]\n",
      "epoch:15 step:14618 [D loss: 0.565867, acc.: 71.88%] [G loss: 1.144686]\n",
      "epoch:15 step:14619 [D loss: 0.612199, acc.: 70.31%] [G loss: 1.135292]\n",
      "epoch:15 step:14620 [D loss: 0.460742, acc.: 82.03%] [G loss: 1.321874]\n",
      "epoch:15 step:14621 [D loss: 0.402517, acc.: 89.06%] [G loss: 1.572106]\n",
      "epoch:15 step:14622 [D loss: 0.520247, acc.: 77.34%] [G loss: 1.169600]\n",
      "epoch:15 step:14623 [D loss: 0.619904, acc.: 66.41%] [G loss: 1.184681]\n",
      "epoch:15 step:14624 [D loss: 0.528256, acc.: 75.00%] [G loss: 1.094872]\n",
      "epoch:15 step:14625 [D loss: 0.647989, acc.: 62.50%] [G loss: 1.066251]\n",
      "epoch:15 step:14626 [D loss: 0.650661, acc.: 60.16%] [G loss: 0.964575]\n",
      "epoch:15 step:14627 [D loss: 0.437862, acc.: 83.59%] [G loss: 1.374974]\n",
      "epoch:15 step:14628 [D loss: 0.752317, acc.: 50.00%] [G loss: 1.206971]\n",
      "epoch:15 step:14629 [D loss: 0.621424, acc.: 67.19%] [G loss: 1.138573]\n",
      "epoch:15 step:14630 [D loss: 0.579971, acc.: 70.31%] [G loss: 0.827540]\n",
      "epoch:15 step:14631 [D loss: 0.395624, acc.: 85.94%] [G loss: 1.474833]\n",
      "epoch:15 step:14632 [D loss: 0.517235, acc.: 76.56%] [G loss: 1.285062]\n",
      "epoch:15 step:14633 [D loss: 0.637592, acc.: 64.84%] [G loss: 1.138106]\n",
      "epoch:15 step:14634 [D loss: 0.577093, acc.: 71.09%] [G loss: 1.377969]\n",
      "epoch:15 step:14635 [D loss: 0.646210, acc.: 60.94%] [G loss: 1.050162]\n",
      "epoch:15 step:14636 [D loss: 0.490022, acc.: 81.25%] [G loss: 1.257009]\n",
      "epoch:15 step:14637 [D loss: 0.636305, acc.: 64.84%] [G loss: 1.392763]\n",
      "epoch:15 step:14638 [D loss: 0.568011, acc.: 69.53%] [G loss: 1.065777]\n",
      "epoch:15 step:14639 [D loss: 0.589743, acc.: 70.31%] [G loss: 1.216787]\n",
      "epoch:15 step:14640 [D loss: 0.535344, acc.: 75.78%] [G loss: 1.249763]\n",
      "epoch:15 step:14641 [D loss: 0.512271, acc.: 71.88%] [G loss: 1.438641]\n",
      "epoch:15 step:14642 [D loss: 0.708418, acc.: 58.59%] [G loss: 0.999014]\n",
      "epoch:15 step:14643 [D loss: 0.784400, acc.: 54.69%] [G loss: 1.150993]\n",
      "epoch:15 step:14644 [D loss: 0.560104, acc.: 69.53%] [G loss: 1.066855]\n",
      "epoch:15 step:14645 [D loss: 0.511676, acc.: 75.00%] [G loss: 1.239381]\n",
      "epoch:15 step:14646 [D loss: 0.551377, acc.: 72.66%] [G loss: 1.026749]\n",
      "epoch:15 step:14647 [D loss: 0.500957, acc.: 77.34%] [G loss: 1.435142]\n",
      "epoch:15 step:14648 [D loss: 0.639664, acc.: 61.72%] [G loss: 1.172900]\n",
      "epoch:15 step:14649 [D loss: 0.718471, acc.: 59.38%] [G loss: 1.028705]\n",
      "epoch:15 step:14650 [D loss: 0.628427, acc.: 67.97%] [G loss: 1.058164]\n",
      "epoch:15 step:14651 [D loss: 0.559759, acc.: 75.78%] [G loss: 1.243226]\n",
      "epoch:15 step:14652 [D loss: 0.628604, acc.: 69.53%] [G loss: 1.284019]\n",
      "epoch:15 step:14653 [D loss: 0.608861, acc.: 72.66%] [G loss: 1.197786]\n",
      "epoch:15 step:14654 [D loss: 0.581662, acc.: 71.88%] [G loss: 1.164317]\n",
      "epoch:15 step:14655 [D loss: 0.540266, acc.: 73.44%] [G loss: 1.444928]\n",
      "epoch:15 step:14656 [D loss: 0.694473, acc.: 60.16%] [G loss: 1.167847]\n",
      "epoch:15 step:14657 [D loss: 0.482386, acc.: 82.03%] [G loss: 1.297513]\n",
      "epoch:15 step:14658 [D loss: 0.630806, acc.: 66.41%] [G loss: 1.061024]\n",
      "epoch:15 step:14659 [D loss: 0.559530, acc.: 69.53%] [G loss: 1.130818]\n",
      "epoch:15 step:14660 [D loss: 0.645361, acc.: 68.75%] [G loss: 0.991804]\n",
      "epoch:15 step:14661 [D loss: 0.704785, acc.: 54.69%] [G loss: 1.103462]\n",
      "epoch:15 step:14662 [D loss: 0.547994, acc.: 72.66%] [G loss: 1.235417]\n",
      "epoch:15 step:14663 [D loss: 0.600064, acc.: 68.75%] [G loss: 1.465733]\n",
      "epoch:15 step:14664 [D loss: 0.671803, acc.: 59.38%] [G loss: 1.279075]\n",
      "epoch:15 step:14665 [D loss: 0.590197, acc.: 71.09%] [G loss: 1.390256]\n",
      "epoch:15 step:14666 [D loss: 0.609416, acc.: 62.50%] [G loss: 1.459198]\n",
      "epoch:15 step:14667 [D loss: 0.567116, acc.: 67.19%] [G loss: 1.335048]\n",
      "epoch:15 step:14668 [D loss: 0.646475, acc.: 59.38%] [G loss: 1.434954]\n",
      "epoch:15 step:14669 [D loss: 0.603970, acc.: 73.44%] [G loss: 1.109835]\n",
      "epoch:15 step:14670 [D loss: 0.615632, acc.: 64.84%] [G loss: 1.346198]\n",
      "epoch:15 step:14671 [D loss: 0.464267, acc.: 84.38%] [G loss: 1.291678]\n",
      "epoch:15 step:14672 [D loss: 0.504019, acc.: 77.34%] [G loss: 1.129457]\n",
      "epoch:15 step:14673 [D loss: 0.503302, acc.: 78.91%] [G loss: 1.348292]\n",
      "epoch:15 step:14674 [D loss: 0.727990, acc.: 57.03%] [G loss: 0.986645]\n",
      "epoch:15 step:14675 [D loss: 0.622791, acc.: 70.31%] [G loss: 1.118108]\n",
      "epoch:15 step:14676 [D loss: 0.595274, acc.: 68.75%] [G loss: 1.365973]\n",
      "epoch:15 step:14677 [D loss: 0.503930, acc.: 82.03%] [G loss: 1.403188]\n",
      "epoch:15 step:14678 [D loss: 0.571740, acc.: 67.19%] [G loss: 1.067338]\n",
      "epoch:15 step:14679 [D loss: 0.629212, acc.: 63.28%] [G loss: 1.315819]\n",
      "epoch:15 step:14680 [D loss: 0.424552, acc.: 82.81%] [G loss: 1.243412]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:15 step:14681 [D loss: 0.459698, acc.: 75.78%] [G loss: 1.597866]\n",
      "epoch:15 step:14682 [D loss: 0.481568, acc.: 81.25%] [G loss: 1.402928]\n",
      "epoch:15 step:14683 [D loss: 0.619598, acc.: 64.84%] [G loss: 1.333809]\n",
      "epoch:15 step:14684 [D loss: 0.640960, acc.: 60.16%] [G loss: 1.267423]\n",
      "epoch:15 step:14685 [D loss: 0.709881, acc.: 59.38%] [G loss: 1.309987]\n",
      "epoch:15 step:14686 [D loss: 0.521686, acc.: 74.22%] [G loss: 1.415062]\n",
      "epoch:15 step:14687 [D loss: 0.557463, acc.: 75.00%] [G loss: 1.382226]\n",
      "epoch:15 step:14688 [D loss: 0.438622, acc.: 82.03%] [G loss: 1.015977]\n",
      "epoch:15 step:14689 [D loss: 0.590687, acc.: 71.88%] [G loss: 1.139234]\n",
      "epoch:15 step:14690 [D loss: 0.574736, acc.: 67.97%] [G loss: 1.062942]\n",
      "epoch:15 step:14691 [D loss: 0.564690, acc.: 69.53%] [G loss: 1.270516]\n",
      "epoch:15 step:14692 [D loss: 0.638884, acc.: 61.72%] [G loss: 1.377832]\n",
      "epoch:15 step:14693 [D loss: 0.553103, acc.: 71.09%] [G loss: 1.064678]\n",
      "epoch:15 step:14694 [D loss: 0.598243, acc.: 67.97%] [G loss: 1.124502]\n",
      "epoch:15 step:14695 [D loss: 0.555912, acc.: 76.56%] [G loss: 1.300195]\n",
      "epoch:15 step:14696 [D loss: 0.577983, acc.: 70.31%] [G loss: 1.042385]\n",
      "epoch:15 step:14697 [D loss: 0.625239, acc.: 64.84%] [G loss: 1.023876]\n",
      "epoch:15 step:14698 [D loss: 0.659561, acc.: 65.62%] [G loss: 1.001560]\n",
      "epoch:15 step:14699 [D loss: 0.618308, acc.: 65.62%] [G loss: 1.436267]\n",
      "epoch:15 step:14700 [D loss: 0.434265, acc.: 81.25%] [G loss: 1.331774]\n",
      "epoch:15 step:14701 [D loss: 0.452117, acc.: 82.81%] [G loss: 1.165993]\n",
      "epoch:15 step:14702 [D loss: 0.625612, acc.: 67.97%] [G loss: 0.980235]\n",
      "epoch:15 step:14703 [D loss: 0.592695, acc.: 67.97%] [G loss: 1.076277]\n",
      "epoch:15 step:14704 [D loss: 0.482933, acc.: 77.34%] [G loss: 1.421073]\n",
      "epoch:15 step:14705 [D loss: 0.578243, acc.: 71.09%] [G loss: 1.258176]\n",
      "epoch:15 step:14706 [D loss: 0.530757, acc.: 77.34%] [G loss: 1.352738]\n",
      "epoch:15 step:14707 [D loss: 0.613890, acc.: 66.41%] [G loss: 1.153220]\n",
      "epoch:15 step:14708 [D loss: 0.567079, acc.: 71.88%] [G loss: 0.996804]\n",
      "epoch:15 step:14709 [D loss: 0.534465, acc.: 70.31%] [G loss: 1.124611]\n",
      "epoch:15 step:14710 [D loss: 0.668354, acc.: 59.38%] [G loss: 1.062146]\n",
      "epoch:15 step:14711 [D loss: 0.429282, acc.: 86.72%] [G loss: 1.309049]\n",
      "epoch:15 step:14712 [D loss: 0.558076, acc.: 69.53%] [G loss: 1.425685]\n",
      "epoch:15 step:14713 [D loss: 0.734557, acc.: 56.25%] [G loss: 1.293518]\n",
      "epoch:15 step:14714 [D loss: 0.593283, acc.: 65.62%] [G loss: 1.149575]\n",
      "epoch:15 step:14715 [D loss: 0.618646, acc.: 67.19%] [G loss: 1.265876]\n",
      "epoch:15 step:14716 [D loss: 0.627620, acc.: 63.28%] [G loss: 1.167479]\n",
      "epoch:15 step:14717 [D loss: 0.651720, acc.: 66.41%] [G loss: 1.265154]\n",
      "epoch:15 step:14718 [D loss: 0.571996, acc.: 72.66%] [G loss: 1.272362]\n",
      "epoch:15 step:14719 [D loss: 0.654882, acc.: 63.28%] [G loss: 1.390735]\n",
      "epoch:15 step:14720 [D loss: 0.648806, acc.: 58.59%] [G loss: 1.103208]\n",
      "epoch:15 step:14721 [D loss: 0.539062, acc.: 70.31%] [G loss: 1.421073]\n",
      "epoch:15 step:14722 [D loss: 0.599347, acc.: 66.41%] [G loss: 1.578927]\n",
      "epoch:15 step:14723 [D loss: 0.537282, acc.: 75.00%] [G loss: 1.254287]\n",
      "epoch:15 step:14724 [D loss: 0.630729, acc.: 67.19%] [G loss: 1.086834]\n",
      "epoch:15 step:14725 [D loss: 0.408781, acc.: 85.94%] [G loss: 1.355183]\n",
      "epoch:15 step:14726 [D loss: 0.584089, acc.: 65.62%] [G loss: 1.144823]\n",
      "epoch:15 step:14727 [D loss: 0.542484, acc.: 71.88%] [G loss: 1.225973]\n",
      "epoch:15 step:14728 [D loss: 0.681659, acc.: 60.94%] [G loss: 0.928692]\n",
      "epoch:15 step:14729 [D loss: 0.628673, acc.: 69.53%] [G loss: 1.290802]\n",
      "epoch:15 step:14730 [D loss: 0.599590, acc.: 67.97%] [G loss: 0.933341]\n",
      "epoch:15 step:14731 [D loss: 0.534785, acc.: 74.22%] [G loss: 1.161929]\n",
      "epoch:15 step:14732 [D loss: 0.544116, acc.: 71.09%] [G loss: 1.336916]\n",
      "epoch:15 step:14733 [D loss: 0.553516, acc.: 67.97%] [G loss: 1.306668]\n",
      "epoch:15 step:14734 [D loss: 0.554173, acc.: 71.88%] [G loss: 1.279538]\n",
      "epoch:15 step:14735 [D loss: 0.740270, acc.: 59.38%] [G loss: 1.311791]\n",
      "epoch:15 step:14736 [D loss: 0.679457, acc.: 61.72%] [G loss: 1.119939]\n",
      "epoch:15 step:14737 [D loss: 0.522446, acc.: 72.66%] [G loss: 1.173565]\n",
      "epoch:15 step:14738 [D loss: 0.660284, acc.: 62.50%] [G loss: 1.154560]\n",
      "epoch:15 step:14739 [D loss: 0.602106, acc.: 67.19%] [G loss: 1.167033]\n",
      "epoch:15 step:14740 [D loss: 0.635073, acc.: 64.84%] [G loss: 0.994524]\n",
      "epoch:15 step:14741 [D loss: 0.560996, acc.: 69.53%] [G loss: 1.508743]\n",
      "epoch:15 step:14742 [D loss: 0.613050, acc.: 67.19%] [G loss: 1.287247]\n",
      "epoch:15 step:14743 [D loss: 0.540677, acc.: 70.31%] [G loss: 1.379547]\n",
      "epoch:15 step:14744 [D loss: 0.705453, acc.: 54.69%] [G loss: 1.240791]\n",
      "epoch:15 step:14745 [D loss: 0.598519, acc.: 65.62%] [G loss: 1.147202]\n",
      "epoch:15 step:14746 [D loss: 0.695284, acc.: 57.81%] [G loss: 1.387349]\n",
      "epoch:15 step:14747 [D loss: 0.553575, acc.: 72.66%] [G loss: 1.374234]\n",
      "epoch:15 step:14748 [D loss: 0.602725, acc.: 65.62%] [G loss: 1.292387]\n",
      "epoch:15 step:14749 [D loss: 0.548949, acc.: 78.12%] [G loss: 1.334435]\n",
      "epoch:15 step:14750 [D loss: 0.595700, acc.: 67.97%] [G loss: 1.208697]\n",
      "epoch:15 step:14751 [D loss: 0.528953, acc.: 75.00%] [G loss: 1.340171]\n",
      "epoch:15 step:14752 [D loss: 0.549502, acc.: 77.34%] [G loss: 1.277158]\n",
      "epoch:15 step:14753 [D loss: 0.625194, acc.: 67.97%] [G loss: 1.094500]\n",
      "epoch:15 step:14754 [D loss: 0.621205, acc.: 68.75%] [G loss: 1.209883]\n",
      "epoch:15 step:14755 [D loss: 0.561518, acc.: 71.09%] [G loss: 1.342287]\n",
      "epoch:15 step:14756 [D loss: 0.438608, acc.: 83.59%] [G loss: 1.442329]\n",
      "epoch:15 step:14757 [D loss: 0.488685, acc.: 80.47%] [G loss: 1.363688]\n",
      "epoch:15 step:14758 [D loss: 0.664251, acc.: 60.16%] [G loss: 1.103747]\n",
      "epoch:15 step:14759 [D loss: 0.672713, acc.: 61.72%] [G loss: 1.004414]\n",
      "epoch:15 step:14760 [D loss: 0.601751, acc.: 67.19%] [G loss: 1.087707]\n",
      "epoch:15 step:14761 [D loss: 0.500645, acc.: 78.12%] [G loss: 1.149468]\n",
      "epoch:15 step:14762 [D loss: 0.540300, acc.: 74.22%] [G loss: 1.055133]\n",
      "epoch:15 step:14763 [D loss: 0.528971, acc.: 75.00%] [G loss: 1.153327]\n",
      "epoch:15 step:14764 [D loss: 0.681743, acc.: 60.16%] [G loss: 1.255524]\n",
      "epoch:15 step:14765 [D loss: 0.553788, acc.: 71.88%] [G loss: 1.477795]\n",
      "epoch:15 step:14766 [D loss: 0.688791, acc.: 61.72%] [G loss: 1.247962]\n",
      "epoch:15 step:14767 [D loss: 0.510990, acc.: 78.12%] [G loss: 1.344721]\n",
      "epoch:15 step:14768 [D loss: 0.567197, acc.: 72.66%] [G loss: 1.227434]\n",
      "epoch:15 step:14769 [D loss: 0.583992, acc.: 68.75%] [G loss: 1.445701]\n",
      "epoch:15 step:14770 [D loss: 0.641350, acc.: 64.06%] [G loss: 1.096764]\n",
      "epoch:15 step:14771 [D loss: 0.668038, acc.: 59.38%] [G loss: 1.174091]\n",
      "epoch:15 step:14772 [D loss: 0.500473, acc.: 77.34%] [G loss: 1.560013]\n",
      "epoch:15 step:14773 [D loss: 0.532989, acc.: 74.22%] [G loss: 1.183218]\n",
      "epoch:15 step:14774 [D loss: 0.574383, acc.: 71.09%] [G loss: 1.254966]\n",
      "epoch:15 step:14775 [D loss: 0.735102, acc.: 50.00%] [G loss: 0.978790]\n",
      "epoch:15 step:14776 [D loss: 0.536828, acc.: 71.88%] [G loss: 1.177559]\n",
      "epoch:15 step:14777 [D loss: 0.488839, acc.: 75.78%] [G loss: 1.378199]\n",
      "epoch:15 step:14778 [D loss: 0.707475, acc.: 50.78%] [G loss: 1.028111]\n",
      "epoch:15 step:14779 [D loss: 0.667037, acc.: 64.06%] [G loss: 1.196321]\n",
      "epoch:15 step:14780 [D loss: 0.445496, acc.: 82.03%] [G loss: 1.350114]\n",
      "epoch:15 step:14781 [D loss: 0.555109, acc.: 72.66%] [G loss: 1.461037]\n",
      "epoch:15 step:14782 [D loss: 0.518194, acc.: 74.22%] [G loss: 1.016320]\n",
      "epoch:15 step:14783 [D loss: 0.542813, acc.: 75.78%] [G loss: 1.085539]\n",
      "epoch:15 step:14784 [D loss: 0.435951, acc.: 84.38%] [G loss: 1.202682]\n",
      "epoch:15 step:14785 [D loss: 0.564544, acc.: 68.75%] [G loss: 1.190696]\n",
      "epoch:15 step:14786 [D loss: 0.586698, acc.: 67.97%] [G loss: 1.102062]\n",
      "epoch:15 step:14787 [D loss: 0.540944, acc.: 73.44%] [G loss: 1.297927]\n",
      "epoch:15 step:14788 [D loss: 0.645222, acc.: 67.19%] [G loss: 1.321988]\n",
      "epoch:15 step:14789 [D loss: 0.553668, acc.: 72.66%] [G loss: 1.347593]\n",
      "epoch:15 step:14790 [D loss: 0.548760, acc.: 70.31%] [G loss: 1.251672]\n",
      "epoch:15 step:14791 [D loss: 0.600408, acc.: 66.41%] [G loss: 1.298194]\n",
      "epoch:15 step:14792 [D loss: 0.508448, acc.: 75.00%] [G loss: 1.447987]\n",
      "epoch:15 step:14793 [D loss: 0.556430, acc.: 72.66%] [G loss: 1.116321]\n",
      "epoch:15 step:14794 [D loss: 0.616297, acc.: 65.62%] [G loss: 1.188545]\n",
      "epoch:15 step:14795 [D loss: 0.646749, acc.: 62.50%] [G loss: 1.272650]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:15 step:14796 [D loss: 0.485525, acc.: 80.47%] [G loss: 1.308108]\n",
      "epoch:15 step:14797 [D loss: 0.656749, acc.: 64.06%] [G loss: 0.998248]\n",
      "epoch:15 step:14798 [D loss: 0.580466, acc.: 67.97%] [G loss: 1.318606]\n",
      "epoch:15 step:14799 [D loss: 0.598686, acc.: 63.28%] [G loss: 1.187135]\n",
      "epoch:15 step:14800 [D loss: 0.568615, acc.: 70.31%] [G loss: 1.158392]\n",
      "epoch:15 step:14801 [D loss: 0.542049, acc.: 72.66%] [G loss: 1.027768]\n",
      "epoch:15 step:14802 [D loss: 0.584243, acc.: 66.41%] [G loss: 1.170414]\n",
      "epoch:15 step:14803 [D loss: 0.566628, acc.: 70.31%] [G loss: 1.392532]\n",
      "epoch:15 step:14804 [D loss: 0.493830, acc.: 73.44%] [G loss: 1.361594]\n",
      "epoch:15 step:14805 [D loss: 0.729180, acc.: 53.91%] [G loss: 0.895227]\n",
      "epoch:15 step:14806 [D loss: 0.575451, acc.: 72.66%] [G loss: 1.163163]\n",
      "epoch:15 step:14807 [D loss: 0.511484, acc.: 73.44%] [G loss: 1.242692]\n",
      "epoch:15 step:14808 [D loss: 0.449431, acc.: 82.03%] [G loss: 1.283884]\n",
      "epoch:15 step:14809 [D loss: 0.639094, acc.: 66.41%] [G loss: 1.219611]\n",
      "epoch:15 step:14810 [D loss: 0.663849, acc.: 61.72%] [G loss: 1.230829]\n",
      "epoch:15 step:14811 [D loss: 0.556378, acc.: 64.06%] [G loss: 1.088687]\n",
      "epoch:15 step:14812 [D loss: 0.503318, acc.: 75.78%] [G loss: 1.451259]\n",
      "epoch:15 step:14813 [D loss: 0.648282, acc.: 60.94%] [G loss: 1.185030]\n",
      "epoch:15 step:14814 [D loss: 0.765692, acc.: 54.69%] [G loss: 1.036730]\n",
      "epoch:15 step:14815 [D loss: 0.582366, acc.: 70.31%] [G loss: 1.256967]\n",
      "epoch:15 step:14816 [D loss: 0.673389, acc.: 60.16%] [G loss: 1.056971]\n",
      "epoch:15 step:14817 [D loss: 0.498935, acc.: 78.12%] [G loss: 1.367701]\n",
      "epoch:15 step:14818 [D loss: 0.595298, acc.: 66.41%] [G loss: 1.139571]\n",
      "epoch:15 step:14819 [D loss: 0.530372, acc.: 76.56%] [G loss: 1.291478]\n",
      "epoch:15 step:14820 [D loss: 0.609515, acc.: 67.19%] [G loss: 1.064876]\n",
      "epoch:15 step:14821 [D loss: 0.450007, acc.: 80.47%] [G loss: 1.489417]\n",
      "epoch:15 step:14822 [D loss: 0.589516, acc.: 69.53%] [G loss: 1.329582]\n",
      "epoch:15 step:14823 [D loss: 0.550898, acc.: 71.88%] [G loss: 1.278099]\n",
      "epoch:15 step:14824 [D loss: 0.499405, acc.: 74.22%] [G loss: 1.443818]\n",
      "epoch:15 step:14825 [D loss: 0.545215, acc.: 67.97%] [G loss: 1.286254]\n",
      "epoch:15 step:14826 [D loss: 0.553310, acc.: 77.34%] [G loss: 1.265049]\n",
      "epoch:15 step:14827 [D loss: 0.529115, acc.: 78.12%] [G loss: 1.388219]\n",
      "epoch:15 step:14828 [D loss: 0.629016, acc.: 65.62%] [G loss: 1.245191]\n",
      "epoch:15 step:14829 [D loss: 0.554489, acc.: 70.31%] [G loss: 1.474973]\n",
      "epoch:15 step:14830 [D loss: 0.579903, acc.: 68.75%] [G loss: 1.086253]\n",
      "epoch:15 step:14831 [D loss: 0.539845, acc.: 70.31%] [G loss: 1.159094]\n",
      "epoch:15 step:14832 [D loss: 0.651063, acc.: 59.38%] [G loss: 1.128299]\n",
      "epoch:15 step:14833 [D loss: 0.598572, acc.: 70.31%] [G loss: 1.133565]\n",
      "epoch:15 step:14834 [D loss: 0.620537, acc.: 60.94%] [G loss: 1.200049]\n",
      "epoch:15 step:14835 [D loss: 0.657980, acc.: 60.16%] [G loss: 1.383430]\n",
      "epoch:15 step:14836 [D loss: 0.566517, acc.: 67.19%] [G loss: 1.344874]\n",
      "epoch:15 step:14837 [D loss: 0.593908, acc.: 67.19%] [G loss: 1.150325]\n",
      "epoch:15 step:14838 [D loss: 0.565430, acc.: 69.53%] [G loss: 1.162601]\n",
      "epoch:15 step:14839 [D loss: 0.680173, acc.: 57.81%] [G loss: 1.373625]\n",
      "epoch:15 step:14840 [D loss: 0.487678, acc.: 79.69%] [G loss: 1.197266]\n",
      "epoch:15 step:14841 [D loss: 0.599616, acc.: 63.28%] [G loss: 1.223225]\n",
      "epoch:15 step:14842 [D loss: 0.511214, acc.: 75.78%] [G loss: 1.105924]\n",
      "epoch:15 step:14843 [D loss: 0.754229, acc.: 51.56%] [G loss: 1.138860]\n",
      "epoch:15 step:14844 [D loss: 0.551110, acc.: 72.66%] [G loss: 1.039920]\n",
      "epoch:15 step:14845 [D loss: 0.548680, acc.: 74.22%] [G loss: 1.332779]\n",
      "epoch:15 step:14846 [D loss: 0.640612, acc.: 62.50%] [G loss: 1.439893]\n",
      "epoch:15 step:14847 [D loss: 0.518305, acc.: 74.22%] [G loss: 1.425497]\n",
      "epoch:15 step:14848 [D loss: 0.598130, acc.: 63.28%] [G loss: 0.994979]\n",
      "epoch:15 step:14849 [D loss: 0.489799, acc.: 76.56%] [G loss: 1.433551]\n",
      "epoch:15 step:14850 [D loss: 0.600628, acc.: 67.19%] [G loss: 1.102553]\n",
      "epoch:15 step:14851 [D loss: 0.518135, acc.: 78.12%] [G loss: 1.194695]\n",
      "epoch:15 step:14852 [D loss: 0.511033, acc.: 79.69%] [G loss: 1.308347]\n",
      "epoch:15 step:14853 [D loss: 0.538671, acc.: 77.34%] [G loss: 1.120954]\n",
      "epoch:15 step:14854 [D loss: 0.491654, acc.: 82.03%] [G loss: 1.128095]\n",
      "epoch:15 step:14855 [D loss: 0.521134, acc.: 68.75%] [G loss: 1.474552]\n",
      "epoch:15 step:14856 [D loss: 0.557084, acc.: 68.75%] [G loss: 1.257943]\n",
      "epoch:15 step:14857 [D loss: 0.644430, acc.: 63.28%] [G loss: 1.164277]\n",
      "epoch:15 step:14858 [D loss: 0.472434, acc.: 75.78%] [G loss: 1.421241]\n",
      "epoch:15 step:14859 [D loss: 0.475716, acc.: 76.56%] [G loss: 1.260378]\n",
      "epoch:15 step:14860 [D loss: 0.643848, acc.: 62.50%] [G loss: 1.083438]\n",
      "epoch:15 step:14861 [D loss: 0.514439, acc.: 78.91%] [G loss: 1.278641]\n",
      "epoch:15 step:14862 [D loss: 0.622178, acc.: 67.19%] [G loss: 1.284204]\n",
      "epoch:15 step:14863 [D loss: 0.593421, acc.: 69.53%] [G loss: 1.194449]\n",
      "epoch:15 step:14864 [D loss: 0.516490, acc.: 76.56%] [G loss: 1.367146]\n",
      "epoch:15 step:14865 [D loss: 0.499387, acc.: 75.00%] [G loss: 1.459072]\n",
      "epoch:15 step:14866 [D loss: 0.631963, acc.: 68.75%] [G loss: 1.112267]\n",
      "epoch:15 step:14867 [D loss: 0.616669, acc.: 65.62%] [G loss: 1.221975]\n",
      "epoch:15 step:14868 [D loss: 0.613682, acc.: 65.62%] [G loss: 1.139750]\n",
      "epoch:15 step:14869 [D loss: 0.441103, acc.: 85.16%] [G loss: 1.491647]\n",
      "epoch:15 step:14870 [D loss: 0.567326, acc.: 70.31%] [G loss: 1.352216]\n",
      "epoch:15 step:14871 [D loss: 0.478990, acc.: 80.47%] [G loss: 1.299664]\n",
      "epoch:15 step:14872 [D loss: 0.558264, acc.: 71.88%] [G loss: 1.219477]\n",
      "epoch:15 step:14873 [D loss: 0.552303, acc.: 69.53%] [G loss: 1.196380]\n",
      "epoch:15 step:14874 [D loss: 0.586463, acc.: 71.09%] [G loss: 1.460092]\n",
      "epoch:15 step:14875 [D loss: 0.577164, acc.: 68.75%] [G loss: 1.307720]\n",
      "epoch:15 step:14876 [D loss: 0.657152, acc.: 61.72%] [G loss: 1.413220]\n",
      "epoch:15 step:14877 [D loss: 0.589768, acc.: 69.53%] [G loss: 1.309876]\n",
      "epoch:15 step:14878 [D loss: 0.593501, acc.: 71.09%] [G loss: 1.359848]\n",
      "epoch:15 step:14879 [D loss: 0.627676, acc.: 61.72%] [G loss: 1.004786]\n",
      "epoch:15 step:14880 [D loss: 0.513919, acc.: 75.78%] [G loss: 1.134569]\n",
      "epoch:15 step:14881 [D loss: 0.596264, acc.: 67.19%] [G loss: 1.101817]\n",
      "epoch:15 step:14882 [D loss: 0.501273, acc.: 77.34%] [G loss: 1.508267]\n",
      "epoch:15 step:14883 [D loss: 0.669122, acc.: 60.16%] [G loss: 1.324432]\n",
      "epoch:15 step:14884 [D loss: 0.478662, acc.: 81.25%] [G loss: 1.161591]\n",
      "epoch:15 step:14885 [D loss: 0.586881, acc.: 70.31%] [G loss: 1.000258]\n",
      "epoch:15 step:14886 [D loss: 0.552520, acc.: 75.00%] [G loss: 1.346494]\n",
      "epoch:15 step:14887 [D loss: 0.624221, acc.: 64.84%] [G loss: 1.150443]\n",
      "epoch:15 step:14888 [D loss: 0.569122, acc.: 70.31%] [G loss: 1.495333]\n",
      "epoch:15 step:14889 [D loss: 0.549343, acc.: 71.09%] [G loss: 1.076759]\n",
      "epoch:15 step:14890 [D loss: 0.526426, acc.: 71.88%] [G loss: 1.159750]\n",
      "epoch:15 step:14891 [D loss: 0.666342, acc.: 62.50%] [G loss: 1.275961]\n",
      "epoch:15 step:14892 [D loss: 0.693681, acc.: 56.25%] [G loss: 1.448458]\n",
      "epoch:15 step:14893 [D loss: 0.474619, acc.: 79.69%] [G loss: 1.314381]\n",
      "epoch:15 step:14894 [D loss: 0.656681, acc.: 65.62%] [G loss: 1.046493]\n",
      "epoch:15 step:14895 [D loss: 0.611601, acc.: 70.31%] [G loss: 1.398596]\n",
      "epoch:15 step:14896 [D loss: 0.457894, acc.: 78.12%] [G loss: 1.278711]\n",
      "epoch:15 step:14897 [D loss: 0.593201, acc.: 67.19%] [G loss: 1.171526]\n",
      "epoch:15 step:14898 [D loss: 0.637952, acc.: 64.06%] [G loss: 1.075511]\n",
      "epoch:15 step:14899 [D loss: 0.652839, acc.: 63.28%] [G loss: 1.120484]\n",
      "epoch:15 step:14900 [D loss: 0.586383, acc.: 66.41%] [G loss: 1.235705]\n",
      "epoch:15 step:14901 [D loss: 0.574539, acc.: 64.84%] [G loss: 1.057974]\n",
      "epoch:15 step:14902 [D loss: 0.704546, acc.: 57.81%] [G loss: 1.040068]\n",
      "epoch:15 step:14903 [D loss: 0.480184, acc.: 78.12%] [G loss: 1.322427]\n",
      "epoch:15 step:14904 [D loss: 0.571601, acc.: 69.53%] [G loss: 1.356818]\n",
      "epoch:15 step:14905 [D loss: 0.481758, acc.: 78.91%] [G loss: 1.353731]\n",
      "epoch:15 step:14906 [D loss: 0.672523, acc.: 59.38%] [G loss: 1.245265]\n",
      "epoch:15 step:14907 [D loss: 0.613559, acc.: 68.75%] [G loss: 1.345787]\n",
      "epoch:15 step:14908 [D loss: 0.650236, acc.: 61.72%] [G loss: 1.262106]\n",
      "epoch:15 step:14909 [D loss: 0.612409, acc.: 63.28%] [G loss: 1.288874]\n",
      "epoch:15 step:14910 [D loss: 0.671443, acc.: 63.28%] [G loss: 1.102375]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:15 step:14911 [D loss: 0.432021, acc.: 85.16%] [G loss: 1.270849]\n",
      "epoch:15 step:14912 [D loss: 0.584008, acc.: 70.31%] [G loss: 1.210834]\n",
      "epoch:15 step:14913 [D loss: 0.528757, acc.: 81.25%] [G loss: 1.343717]\n",
      "epoch:15 step:14914 [D loss: 0.599648, acc.: 68.75%] [G loss: 1.429501]\n",
      "epoch:15 step:14915 [D loss: 0.528747, acc.: 79.69%] [G loss: 1.157510]\n",
      "epoch:15 step:14916 [D loss: 0.620671, acc.: 64.06%] [G loss: 0.987826]\n",
      "epoch:15 step:14917 [D loss: 0.639386, acc.: 60.94%] [G loss: 1.374584]\n",
      "epoch:15 step:14918 [D loss: 0.643533, acc.: 59.38%] [G loss: 1.122671]\n",
      "epoch:15 step:14919 [D loss: 0.664014, acc.: 60.16%] [G loss: 1.427028]\n",
      "epoch:15 step:14920 [D loss: 0.601578, acc.: 71.88%] [G loss: 1.187033]\n",
      "epoch:15 step:14921 [D loss: 0.429629, acc.: 82.81%] [G loss: 1.267993]\n",
      "epoch:15 step:14922 [D loss: 0.668786, acc.: 61.72%] [G loss: 1.363240]\n",
      "epoch:15 step:14923 [D loss: 0.487402, acc.: 78.12%] [G loss: 1.208664]\n",
      "epoch:15 step:14924 [D loss: 0.616432, acc.: 63.28%] [G loss: 0.992356]\n",
      "epoch:15 step:14925 [D loss: 0.659689, acc.: 64.06%] [G loss: 1.304243]\n",
      "epoch:15 step:14926 [D loss: 0.633772, acc.: 67.19%] [G loss: 1.195706]\n",
      "epoch:15 step:14927 [D loss: 0.706937, acc.: 60.94%] [G loss: 1.215760]\n",
      "epoch:15 step:14928 [D loss: 0.588377, acc.: 70.31%] [G loss: 1.280013]\n",
      "epoch:15 step:14929 [D loss: 0.468757, acc.: 78.12%] [G loss: 1.243011]\n",
      "epoch:15 step:14930 [D loss: 0.549739, acc.: 70.31%] [G loss: 1.208229]\n",
      "epoch:15 step:14931 [D loss: 0.619803, acc.: 64.84%] [G loss: 1.290490]\n",
      "epoch:15 step:14932 [D loss: 0.491807, acc.: 78.91%] [G loss: 1.255510]\n",
      "epoch:15 step:14933 [D loss: 0.623721, acc.: 66.41%] [G loss: 1.108685]\n",
      "epoch:15 step:14934 [D loss: 0.670867, acc.: 59.38%] [G loss: 1.243909]\n",
      "epoch:15 step:14935 [D loss: 0.518101, acc.: 75.00%] [G loss: 1.317220]\n",
      "epoch:15 step:14936 [D loss: 0.626750, acc.: 64.84%] [G loss: 1.445826]\n",
      "epoch:15 step:14937 [D loss: 0.425552, acc.: 83.59%] [G loss: 1.425629]\n",
      "epoch:15 step:14938 [D loss: 0.621844, acc.: 69.53%] [G loss: 1.327035]\n",
      "epoch:15 step:14939 [D loss: 0.593009, acc.: 70.31%] [G loss: 1.018205]\n",
      "epoch:15 step:14940 [D loss: 0.670909, acc.: 60.16%] [G loss: 1.085958]\n",
      "epoch:15 step:14941 [D loss: 0.536713, acc.: 73.44%] [G loss: 1.505083]\n",
      "epoch:15 step:14942 [D loss: 0.554818, acc.: 75.00%] [G loss: 1.254301]\n",
      "epoch:15 step:14943 [D loss: 0.567910, acc.: 70.31%] [G loss: 1.203513]\n",
      "epoch:15 step:14944 [D loss: 0.554305, acc.: 70.31%] [G loss: 1.267697]\n",
      "epoch:15 step:14945 [D loss: 0.620657, acc.: 67.19%] [G loss: 1.097025]\n",
      "epoch:15 step:14946 [D loss: 0.624106, acc.: 67.19%] [G loss: 1.091530]\n",
      "epoch:15 step:14947 [D loss: 0.595855, acc.: 67.97%] [G loss: 1.213369]\n",
      "epoch:15 step:14948 [D loss: 0.603874, acc.: 64.84%] [G loss: 1.088004]\n",
      "epoch:15 step:14949 [D loss: 0.475106, acc.: 78.12%] [G loss: 1.481679]\n",
      "epoch:15 step:14950 [D loss: 0.543052, acc.: 70.31%] [G loss: 1.288507]\n",
      "epoch:15 step:14951 [D loss: 0.569024, acc.: 75.00%] [G loss: 1.202144]\n",
      "epoch:15 step:14952 [D loss: 0.582885, acc.: 73.44%] [G loss: 1.178470]\n",
      "epoch:15 step:14953 [D loss: 0.501914, acc.: 78.91%] [G loss: 1.188369]\n",
      "epoch:15 step:14954 [D loss: 0.791013, acc.: 52.34%] [G loss: 1.018842]\n",
      "epoch:15 step:14955 [D loss: 0.477290, acc.: 78.12%] [G loss: 1.300528]\n",
      "epoch:15 step:14956 [D loss: 0.652158, acc.: 57.81%] [G loss: 0.936052]\n",
      "epoch:15 step:14957 [D loss: 0.558823, acc.: 71.09%] [G loss: 1.078146]\n",
      "epoch:15 step:14958 [D loss: 0.513391, acc.: 75.00%] [G loss: 1.508236]\n",
      "epoch:15 step:14959 [D loss: 0.513776, acc.: 79.69%] [G loss: 1.035961]\n",
      "epoch:15 step:14960 [D loss: 0.573522, acc.: 72.66%] [G loss: 1.460236]\n",
      "epoch:15 step:14961 [D loss: 0.720293, acc.: 57.81%] [G loss: 0.910470]\n",
      "epoch:15 step:14962 [D loss: 0.494199, acc.: 75.78%] [G loss: 1.489518]\n",
      "epoch:15 step:14963 [D loss: 0.702252, acc.: 54.69%] [G loss: 1.088907]\n",
      "epoch:15 step:14964 [D loss: 0.663616, acc.: 63.28%] [G loss: 1.210794]\n",
      "epoch:15 step:14965 [D loss: 0.445506, acc.: 83.59%] [G loss: 1.321273]\n",
      "epoch:15 step:14966 [D loss: 0.642048, acc.: 65.62%] [G loss: 1.359798]\n",
      "epoch:15 step:14967 [D loss: 0.619605, acc.: 63.28%] [G loss: 1.130979]\n",
      "epoch:15 step:14968 [D loss: 0.520728, acc.: 78.12%] [G loss: 1.255505]\n",
      "epoch:15 step:14969 [D loss: 0.544732, acc.: 67.97%] [G loss: 1.058583]\n",
      "epoch:15 step:14970 [D loss: 0.500309, acc.: 78.12%] [G loss: 1.273432]\n",
      "epoch:15 step:14971 [D loss: 0.456079, acc.: 82.81%] [G loss: 1.203575]\n",
      "epoch:15 step:14972 [D loss: 0.577326, acc.: 67.19%] [G loss: 1.147090]\n",
      "epoch:15 step:14973 [D loss: 0.606604, acc.: 65.62%] [G loss: 0.938380]\n",
      "epoch:15 step:14974 [D loss: 0.457690, acc.: 78.12%] [G loss: 1.342330]\n",
      "epoch:15 step:14975 [D loss: 0.630149, acc.: 66.41%] [G loss: 1.354843]\n",
      "epoch:15 step:14976 [D loss: 0.656588, acc.: 64.84%] [G loss: 1.119390]\n",
      "epoch:15 step:14977 [D loss: 0.482134, acc.: 78.12%] [G loss: 1.304770]\n",
      "epoch:15 step:14978 [D loss: 0.517151, acc.: 74.22%] [G loss: 1.334356]\n",
      "epoch:15 step:14979 [D loss: 0.558830, acc.: 78.12%] [G loss: 1.010272]\n",
      "epoch:15 step:14980 [D loss: 0.657770, acc.: 62.50%] [G loss: 0.990707]\n",
      "epoch:15 step:14981 [D loss: 0.536350, acc.: 67.19%] [G loss: 1.214007]\n",
      "epoch:15 step:14982 [D loss: 0.618176, acc.: 67.19%] [G loss: 1.191915]\n",
      "epoch:15 step:14983 [D loss: 0.477343, acc.: 81.25%] [G loss: 1.514919]\n",
      "epoch:15 step:14984 [D loss: 0.565034, acc.: 67.97%] [G loss: 1.301891]\n",
      "epoch:15 step:14985 [D loss: 0.605175, acc.: 67.19%] [G loss: 1.214268]\n",
      "epoch:15 step:14986 [D loss: 0.705147, acc.: 60.94%] [G loss: 0.989540]\n",
      "epoch:15 step:14987 [D loss: 0.648808, acc.: 66.41%] [G loss: 1.126166]\n",
      "epoch:15 step:14988 [D loss: 0.696535, acc.: 59.38%] [G loss: 1.439311]\n",
      "epoch:15 step:14989 [D loss: 0.619794, acc.: 67.19%] [G loss: 1.350373]\n",
      "epoch:15 step:14990 [D loss: 0.498735, acc.: 81.25%] [G loss: 1.370224]\n",
      "epoch:15 step:14991 [D loss: 0.523887, acc.: 79.69%] [G loss: 1.124922]\n",
      "epoch:15 step:14992 [D loss: 0.616414, acc.: 67.19%] [G loss: 1.011826]\n",
      "epoch:16 step:14993 [D loss: 0.691331, acc.: 59.38%] [G loss: 1.072160]\n",
      "epoch:16 step:14994 [D loss: 0.692182, acc.: 59.38%] [G loss: 0.989198]\n",
      "epoch:16 step:14995 [D loss: 0.554049, acc.: 70.31%] [G loss: 1.202047]\n",
      "epoch:16 step:14996 [D loss: 0.578250, acc.: 67.19%] [G loss: 1.383046]\n",
      "epoch:16 step:14997 [D loss: 0.565476, acc.: 72.66%] [G loss: 1.153661]\n",
      "epoch:16 step:14998 [D loss: 0.656475, acc.: 59.38%] [G loss: 1.048734]\n",
      "epoch:16 step:14999 [D loss: 0.694123, acc.: 58.59%] [G loss: 1.119999]\n",
      "epoch:16 step:15000 [D loss: 0.510622, acc.: 75.78%] [G loss: 1.219507]\n",
      "epoch:16 step:15001 [D loss: 0.507795, acc.: 75.78%] [G loss: 1.301169]\n",
      "epoch:16 step:15002 [D loss: 0.661369, acc.: 61.72%] [G loss: 1.325371]\n",
      "epoch:16 step:15003 [D loss: 0.544809, acc.: 79.69%] [G loss: 1.296354]\n",
      "epoch:16 step:15004 [D loss: 0.544505, acc.: 71.09%] [G loss: 1.414651]\n",
      "epoch:16 step:15005 [D loss: 0.584200, acc.: 69.53%] [G loss: 1.452354]\n",
      "epoch:16 step:15006 [D loss: 0.714714, acc.: 58.59%] [G loss: 0.984779]\n",
      "epoch:16 step:15007 [D loss: 0.557729, acc.: 73.44%] [G loss: 1.200627]\n",
      "epoch:16 step:15008 [D loss: 0.536040, acc.: 74.22%] [G loss: 1.176438]\n",
      "epoch:16 step:15009 [D loss: 0.466230, acc.: 82.81%] [G loss: 1.352566]\n",
      "epoch:16 step:15010 [D loss: 0.721351, acc.: 57.81%] [G loss: 1.039236]\n",
      "epoch:16 step:15011 [D loss: 0.576086, acc.: 67.97%] [G loss: 1.238901]\n",
      "epoch:16 step:15012 [D loss: 0.662140, acc.: 64.06%] [G loss: 0.889223]\n",
      "epoch:16 step:15013 [D loss: 0.575871, acc.: 71.09%] [G loss: 1.245492]\n",
      "epoch:16 step:15014 [D loss: 0.587514, acc.: 63.28%] [G loss: 1.268683]\n",
      "epoch:16 step:15015 [D loss: 0.556681, acc.: 69.53%] [G loss: 1.308437]\n",
      "epoch:16 step:15016 [D loss: 0.519623, acc.: 74.22%] [G loss: 1.324748]\n",
      "epoch:16 step:15017 [D loss: 0.632364, acc.: 64.84%] [G loss: 1.242151]\n",
      "epoch:16 step:15018 [D loss: 0.556257, acc.: 72.66%] [G loss: 0.911237]\n",
      "epoch:16 step:15019 [D loss: 0.540239, acc.: 74.22%] [G loss: 1.374324]\n",
      "epoch:16 step:15020 [D loss: 0.576857, acc.: 69.53%] [G loss: 1.283007]\n",
      "epoch:16 step:15021 [D loss: 0.555497, acc.: 71.09%] [G loss: 1.136384]\n",
      "epoch:16 step:15022 [D loss: 0.610311, acc.: 71.09%] [G loss: 1.092415]\n",
      "epoch:16 step:15023 [D loss: 0.693709, acc.: 57.81%] [G loss: 1.051971]\n",
      "epoch:16 step:15024 [D loss: 0.469639, acc.: 82.81%] [G loss: 1.268930]\n",
      "epoch:16 step:15025 [D loss: 0.711828, acc.: 57.81%] [G loss: 0.980679]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:16 step:15026 [D loss: 0.554481, acc.: 71.09%] [G loss: 1.328895]\n",
      "epoch:16 step:15027 [D loss: 0.493506, acc.: 78.12%] [G loss: 1.088256]\n",
      "epoch:16 step:15028 [D loss: 0.553860, acc.: 78.12%] [G loss: 1.222615]\n",
      "epoch:16 step:15029 [D loss: 0.624985, acc.: 60.94%] [G loss: 1.406022]\n",
      "epoch:16 step:15030 [D loss: 0.662787, acc.: 65.62%] [G loss: 1.299993]\n",
      "epoch:16 step:15031 [D loss: 0.611888, acc.: 64.84%] [G loss: 1.365991]\n",
      "epoch:16 step:15032 [D loss: 0.592327, acc.: 67.97%] [G loss: 1.072918]\n",
      "epoch:16 step:15033 [D loss: 0.523289, acc.: 72.66%] [G loss: 1.288960]\n",
      "epoch:16 step:15034 [D loss: 0.528082, acc.: 75.00%] [G loss: 1.098642]\n",
      "epoch:16 step:15035 [D loss: 0.730784, acc.: 56.25%] [G loss: 0.991991]\n",
      "epoch:16 step:15036 [D loss: 0.618642, acc.: 60.16%] [G loss: 1.336928]\n",
      "epoch:16 step:15037 [D loss: 0.661046, acc.: 64.06%] [G loss: 1.207339]\n",
      "epoch:16 step:15038 [D loss: 0.688575, acc.: 60.16%] [G loss: 1.403591]\n",
      "epoch:16 step:15039 [D loss: 0.631134, acc.: 64.84%] [G loss: 1.190637]\n",
      "epoch:16 step:15040 [D loss: 0.579281, acc.: 64.06%] [G loss: 1.201177]\n",
      "epoch:16 step:15041 [D loss: 0.641358, acc.: 67.19%] [G loss: 1.109831]\n",
      "epoch:16 step:15042 [D loss: 0.462725, acc.: 77.34%] [G loss: 1.157427]\n",
      "epoch:16 step:15043 [D loss: 0.540695, acc.: 73.44%] [G loss: 1.196246]\n",
      "epoch:16 step:15044 [D loss: 0.662466, acc.: 67.97%] [G loss: 1.001190]\n",
      "epoch:16 step:15045 [D loss: 0.491450, acc.: 80.47%] [G loss: 1.489536]\n",
      "epoch:16 step:15046 [D loss: 0.520506, acc.: 72.66%] [G loss: 1.172539]\n",
      "epoch:16 step:15047 [D loss: 0.665583, acc.: 58.59%] [G loss: 1.194826]\n",
      "epoch:16 step:15048 [D loss: 0.509456, acc.: 74.22%] [G loss: 1.200044]\n",
      "epoch:16 step:15049 [D loss: 0.673114, acc.: 62.50%] [G loss: 1.074877]\n",
      "epoch:16 step:15050 [D loss: 0.559250, acc.: 75.78%] [G loss: 1.270899]\n",
      "epoch:16 step:15051 [D loss: 0.504267, acc.: 80.47%] [G loss: 1.203191]\n",
      "epoch:16 step:15052 [D loss: 0.574615, acc.: 68.75%] [G loss: 1.194002]\n",
      "epoch:16 step:15053 [D loss: 0.623211, acc.: 66.41%] [G loss: 1.288615]\n",
      "epoch:16 step:15054 [D loss: 0.651186, acc.: 63.28%] [G loss: 0.849339]\n",
      "epoch:16 step:15055 [D loss: 0.676320, acc.: 61.72%] [G loss: 1.097917]\n",
      "epoch:16 step:15056 [D loss: 0.637804, acc.: 62.50%] [G loss: 1.131601]\n",
      "epoch:16 step:15057 [D loss: 0.541942, acc.: 72.66%] [G loss: 1.241292]\n",
      "epoch:16 step:15058 [D loss: 0.614106, acc.: 64.06%] [G loss: 1.402012]\n",
      "epoch:16 step:15059 [D loss: 0.686728, acc.: 57.03%] [G loss: 1.203516]\n",
      "epoch:16 step:15060 [D loss: 0.685052, acc.: 60.16%] [G loss: 0.886949]\n",
      "epoch:16 step:15061 [D loss: 0.430382, acc.: 81.25%] [G loss: 1.369069]\n",
      "epoch:16 step:15062 [D loss: 0.762529, acc.: 51.56%] [G loss: 1.076793]\n",
      "epoch:16 step:15063 [D loss: 0.550167, acc.: 73.44%] [G loss: 1.155898]\n",
      "epoch:16 step:15064 [D loss: 0.599353, acc.: 70.31%] [G loss: 1.226762]\n",
      "epoch:16 step:15065 [D loss: 0.498469, acc.: 78.91%] [G loss: 1.349089]\n",
      "epoch:16 step:15066 [D loss: 0.504089, acc.: 76.56%] [G loss: 1.535829]\n",
      "epoch:16 step:15067 [D loss: 0.535109, acc.: 76.56%] [G loss: 1.354067]\n",
      "epoch:16 step:15068 [D loss: 0.611521, acc.: 70.31%] [G loss: 1.192941]\n",
      "epoch:16 step:15069 [D loss: 0.589385, acc.: 73.44%] [G loss: 1.202078]\n",
      "epoch:16 step:15070 [D loss: 0.596391, acc.: 64.06%] [G loss: 1.337147]\n",
      "epoch:16 step:15071 [D loss: 0.604723, acc.: 66.41%] [G loss: 0.830418]\n",
      "epoch:16 step:15072 [D loss: 0.741085, acc.: 57.03%] [G loss: 0.968340]\n",
      "epoch:16 step:15073 [D loss: 0.575873, acc.: 66.41%] [G loss: 1.455392]\n",
      "epoch:16 step:15074 [D loss: 0.589838, acc.: 60.94%] [G loss: 1.311286]\n",
      "epoch:16 step:15075 [D loss: 0.627991, acc.: 60.16%] [G loss: 1.047870]\n",
      "epoch:16 step:15076 [D loss: 0.694811, acc.: 62.50%] [G loss: 1.132581]\n",
      "epoch:16 step:15077 [D loss: 0.555344, acc.: 71.88%] [G loss: 1.303577]\n",
      "epoch:16 step:15078 [D loss: 0.585979, acc.: 67.19%] [G loss: 1.131884]\n",
      "epoch:16 step:15079 [D loss: 0.518272, acc.: 76.56%] [G loss: 1.368660]\n",
      "epoch:16 step:15080 [D loss: 0.652220, acc.: 64.06%] [G loss: 1.019063]\n",
      "epoch:16 step:15081 [D loss: 0.596437, acc.: 67.97%] [G loss: 1.169281]\n",
      "epoch:16 step:15082 [D loss: 0.599960, acc.: 71.09%] [G loss: 1.272650]\n",
      "epoch:16 step:15083 [D loss: 0.547202, acc.: 71.88%] [G loss: 1.327513]\n",
      "epoch:16 step:15084 [D loss: 0.503829, acc.: 78.12%] [G loss: 1.327049]\n",
      "epoch:16 step:15085 [D loss: 0.609278, acc.: 68.75%] [G loss: 1.157353]\n",
      "epoch:16 step:15086 [D loss: 0.489149, acc.: 77.34%] [G loss: 1.259799]\n",
      "epoch:16 step:15087 [D loss: 0.642581, acc.: 68.75%] [G loss: 1.219122]\n",
      "epoch:16 step:15088 [D loss: 0.608751, acc.: 65.62%] [G loss: 1.001328]\n",
      "epoch:16 step:15089 [D loss: 0.549370, acc.: 73.44%] [G loss: 1.327958]\n",
      "epoch:16 step:15090 [D loss: 0.542061, acc.: 72.66%] [G loss: 1.430318]\n",
      "epoch:16 step:15091 [D loss: 0.545888, acc.: 74.22%] [G loss: 1.399436]\n",
      "epoch:16 step:15092 [D loss: 0.532629, acc.: 76.56%] [G loss: 1.057160]\n",
      "epoch:16 step:15093 [D loss: 0.609607, acc.: 68.75%] [G loss: 1.023983]\n",
      "epoch:16 step:15094 [D loss: 0.656317, acc.: 62.50%] [G loss: 1.076458]\n",
      "epoch:16 step:15095 [D loss: 0.434399, acc.: 82.81%] [G loss: 1.473150]\n",
      "epoch:16 step:15096 [D loss: 0.569487, acc.: 72.66%] [G loss: 1.373703]\n",
      "epoch:16 step:15097 [D loss: 0.505204, acc.: 74.22%] [G loss: 1.279369]\n",
      "epoch:16 step:15098 [D loss: 0.656304, acc.: 62.50%] [G loss: 1.320294]\n",
      "epoch:16 step:15099 [D loss: 0.566547, acc.: 73.44%] [G loss: 1.567558]\n",
      "epoch:16 step:15100 [D loss: 0.500575, acc.: 77.34%] [G loss: 1.287314]\n",
      "epoch:16 step:15101 [D loss: 0.593766, acc.: 70.31%] [G loss: 1.383410]\n",
      "epoch:16 step:15102 [D loss: 0.754835, acc.: 49.22%] [G loss: 1.093107]\n",
      "epoch:16 step:15103 [D loss: 0.596802, acc.: 69.53%] [G loss: 1.260557]\n",
      "epoch:16 step:15104 [D loss: 0.575115, acc.: 71.88%] [G loss: 1.113001]\n",
      "epoch:16 step:15105 [D loss: 0.549943, acc.: 70.31%] [G loss: 1.314613]\n",
      "epoch:16 step:15106 [D loss: 0.523879, acc.: 71.88%] [G loss: 1.159667]\n",
      "epoch:16 step:15107 [D loss: 0.661765, acc.: 62.50%] [G loss: 1.034484]\n",
      "epoch:16 step:15108 [D loss: 0.606497, acc.: 67.19%] [G loss: 1.272458]\n",
      "epoch:16 step:15109 [D loss: 0.582691, acc.: 69.53%] [G loss: 0.920763]\n",
      "epoch:16 step:15110 [D loss: 0.651659, acc.: 55.47%] [G loss: 1.247745]\n",
      "epoch:16 step:15111 [D loss: 0.595384, acc.: 70.31%] [G loss: 0.988145]\n",
      "epoch:16 step:15112 [D loss: 0.582076, acc.: 70.31%] [G loss: 1.357489]\n",
      "epoch:16 step:15113 [D loss: 0.506847, acc.: 78.12%] [G loss: 1.480788]\n",
      "epoch:16 step:15114 [D loss: 0.658423, acc.: 66.41%] [G loss: 1.283564]\n",
      "epoch:16 step:15115 [D loss: 0.645919, acc.: 58.59%] [G loss: 1.239595]\n",
      "epoch:16 step:15116 [D loss: 0.623233, acc.: 65.62%] [G loss: 1.331775]\n",
      "epoch:16 step:15117 [D loss: 0.513902, acc.: 74.22%] [G loss: 1.380363]\n",
      "epoch:16 step:15118 [D loss: 0.544879, acc.: 71.88%] [G loss: 1.294311]\n",
      "epoch:16 step:15119 [D loss: 0.540248, acc.: 73.44%] [G loss: 1.193055]\n",
      "epoch:16 step:15120 [D loss: 0.626593, acc.: 67.97%] [G loss: 1.125134]\n",
      "epoch:16 step:15121 [D loss: 0.500644, acc.: 79.69%] [G loss: 1.256140]\n",
      "epoch:16 step:15122 [D loss: 0.586431, acc.: 72.66%] [G loss: 1.230201]\n",
      "epoch:16 step:15123 [D loss: 0.497741, acc.: 77.34%] [G loss: 1.396654]\n",
      "epoch:16 step:15124 [D loss: 0.766896, acc.: 56.25%] [G loss: 1.014225]\n",
      "epoch:16 step:15125 [D loss: 0.540224, acc.: 71.88%] [G loss: 1.279291]\n",
      "epoch:16 step:15126 [D loss: 0.585627, acc.: 64.84%] [G loss: 1.412272]\n",
      "epoch:16 step:15127 [D loss: 0.594418, acc.: 67.97%] [G loss: 1.210951]\n",
      "epoch:16 step:15128 [D loss: 0.745017, acc.: 53.91%] [G loss: 1.092330]\n",
      "epoch:16 step:15129 [D loss: 0.498667, acc.: 78.12%] [G loss: 1.222327]\n",
      "epoch:16 step:15130 [D loss: 0.499190, acc.: 75.78%] [G loss: 1.288338]\n",
      "epoch:16 step:15131 [D loss: 0.685686, acc.: 55.47%] [G loss: 1.005604]\n",
      "epoch:16 step:15132 [D loss: 0.669861, acc.: 59.38%] [G loss: 1.139065]\n",
      "epoch:16 step:15133 [D loss: 0.622752, acc.: 63.28%] [G loss: 1.340453]\n",
      "epoch:16 step:15134 [D loss: 0.669777, acc.: 57.03%] [G loss: 1.289016]\n",
      "epoch:16 step:15135 [D loss: 0.602805, acc.: 66.41%] [G loss: 1.427741]\n",
      "epoch:16 step:15136 [D loss: 0.657007, acc.: 64.84%] [G loss: 1.360675]\n",
      "epoch:16 step:15137 [D loss: 0.560739, acc.: 68.75%] [G loss: 1.289462]\n",
      "epoch:16 step:15138 [D loss: 0.661766, acc.: 60.94%] [G loss: 1.346002]\n",
      "epoch:16 step:15139 [D loss: 0.585815, acc.: 66.41%] [G loss: 1.193359]\n",
      "epoch:16 step:15140 [D loss: 0.594700, acc.: 64.06%] [G loss: 1.173471]\n",
      "epoch:16 step:15141 [D loss: 0.571985, acc.: 71.09%] [G loss: 1.190726]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:16 step:15142 [D loss: 0.599509, acc.: 67.19%] [G loss: 1.182724]\n",
      "epoch:16 step:15143 [D loss: 0.683040, acc.: 61.72%] [G loss: 1.206526]\n",
      "epoch:16 step:15144 [D loss: 0.707161, acc.: 60.16%] [G loss: 1.419876]\n",
      "epoch:16 step:15145 [D loss: 0.553449, acc.: 75.00%] [G loss: 1.331584]\n",
      "epoch:16 step:15146 [D loss: 0.656032, acc.: 59.38%] [G loss: 1.078890]\n",
      "epoch:16 step:15147 [D loss: 0.668462, acc.: 60.94%] [G loss: 0.972097]\n",
      "epoch:16 step:15148 [D loss: 0.555152, acc.: 70.31%] [G loss: 1.113226]\n",
      "epoch:16 step:15149 [D loss: 0.593824, acc.: 64.06%] [G loss: 1.495213]\n",
      "epoch:16 step:15150 [D loss: 0.691813, acc.: 56.25%] [G loss: 1.004634]\n",
      "epoch:16 step:15151 [D loss: 0.699691, acc.: 58.59%] [G loss: 0.999803]\n",
      "epoch:16 step:15152 [D loss: 0.579419, acc.: 70.31%] [G loss: 1.240342]\n",
      "epoch:16 step:15153 [D loss: 0.569300, acc.: 71.88%] [G loss: 1.101255]\n",
      "epoch:16 step:15154 [D loss: 0.532093, acc.: 78.12%] [G loss: 1.294698]\n",
      "epoch:16 step:15155 [D loss: 0.566295, acc.: 72.66%] [G loss: 1.242185]\n",
      "epoch:16 step:15156 [D loss: 0.441651, acc.: 82.81%] [G loss: 1.150556]\n",
      "epoch:16 step:15157 [D loss: 0.605946, acc.: 69.53%] [G loss: 1.122286]\n",
      "epoch:16 step:15158 [D loss: 0.612931, acc.: 69.53%] [G loss: 1.294122]\n",
      "epoch:16 step:15159 [D loss: 0.553884, acc.: 71.88%] [G loss: 1.121185]\n",
      "epoch:16 step:15160 [D loss: 0.595476, acc.: 68.75%] [G loss: 1.320393]\n",
      "epoch:16 step:15161 [D loss: 0.649668, acc.: 63.28%] [G loss: 1.028192]\n",
      "epoch:16 step:15162 [D loss: 0.502760, acc.: 78.12%] [G loss: 1.232344]\n",
      "epoch:16 step:15163 [D loss: 0.696582, acc.: 52.34%] [G loss: 1.205889]\n",
      "epoch:16 step:15164 [D loss: 0.526869, acc.: 77.34%] [G loss: 1.215250]\n",
      "epoch:16 step:15165 [D loss: 0.529141, acc.: 76.56%] [G loss: 1.428972]\n",
      "epoch:16 step:15166 [D loss: 0.569278, acc.: 71.88%] [G loss: 1.178857]\n",
      "epoch:16 step:15167 [D loss: 0.661716, acc.: 60.16%] [G loss: 1.280840]\n",
      "epoch:16 step:15168 [D loss: 0.589441, acc.: 66.41%] [G loss: 1.158890]\n",
      "epoch:16 step:15169 [D loss: 0.625027, acc.: 66.41%] [G loss: 1.502682]\n",
      "epoch:16 step:15170 [D loss: 0.523777, acc.: 75.00%] [G loss: 1.504622]\n",
      "epoch:16 step:15171 [D loss: 0.795820, acc.: 52.34%] [G loss: 1.001492]\n",
      "epoch:16 step:15172 [D loss: 0.526325, acc.: 71.88%] [G loss: 1.853028]\n",
      "epoch:16 step:15173 [D loss: 0.516157, acc.: 76.56%] [G loss: 1.331504]\n",
      "epoch:16 step:15174 [D loss: 0.538161, acc.: 77.34%] [G loss: 1.166742]\n",
      "epoch:16 step:15175 [D loss: 0.537639, acc.: 75.78%] [G loss: 1.401646]\n",
      "epoch:16 step:15176 [D loss: 0.560015, acc.: 67.97%] [G loss: 1.145664]\n",
      "epoch:16 step:15177 [D loss: 0.464457, acc.: 82.03%] [G loss: 1.359398]\n",
      "epoch:16 step:15178 [D loss: 0.542014, acc.: 71.88%] [G loss: 1.318227]\n",
      "epoch:16 step:15179 [D loss: 0.610218, acc.: 66.41%] [G loss: 1.066516]\n",
      "epoch:16 step:15180 [D loss: 0.545726, acc.: 74.22%] [G loss: 1.374272]\n",
      "epoch:16 step:15181 [D loss: 0.535341, acc.: 73.44%] [G loss: 1.433234]\n",
      "epoch:16 step:15182 [D loss: 0.643576, acc.: 62.50%] [G loss: 1.367283]\n",
      "epoch:16 step:15183 [D loss: 0.636532, acc.: 62.50%] [G loss: 1.066553]\n",
      "epoch:16 step:15184 [D loss: 0.651599, acc.: 64.06%] [G loss: 1.261845]\n",
      "epoch:16 step:15185 [D loss: 0.535881, acc.: 71.88%] [G loss: 1.472601]\n",
      "epoch:16 step:15186 [D loss: 0.672600, acc.: 60.16%] [G loss: 1.188400]\n",
      "epoch:16 step:15187 [D loss: 0.617950, acc.: 67.97%] [G loss: 1.383089]\n",
      "epoch:16 step:15188 [D loss: 0.530544, acc.: 73.44%] [G loss: 1.354598]\n",
      "epoch:16 step:15189 [D loss: 0.520765, acc.: 74.22%] [G loss: 1.264686]\n",
      "epoch:16 step:15190 [D loss: 0.627293, acc.: 68.75%] [G loss: 1.048641]\n",
      "epoch:16 step:15191 [D loss: 0.365195, acc.: 90.62%] [G loss: 1.139835]\n",
      "epoch:16 step:15192 [D loss: 0.605770, acc.: 63.28%] [G loss: 1.178496]\n",
      "epoch:16 step:15193 [D loss: 0.583892, acc.: 68.75%] [G loss: 1.092743]\n",
      "epoch:16 step:15194 [D loss: 0.508559, acc.: 75.78%] [G loss: 1.443686]\n",
      "epoch:16 step:15195 [D loss: 0.517211, acc.: 78.91%] [G loss: 1.077522]\n",
      "epoch:16 step:15196 [D loss: 0.523811, acc.: 72.66%] [G loss: 1.490497]\n",
      "epoch:16 step:15197 [D loss: 0.674732, acc.: 64.06%] [G loss: 1.223212]\n",
      "epoch:16 step:15198 [D loss: 0.653475, acc.: 61.72%] [G loss: 1.356663]\n",
      "epoch:16 step:15199 [D loss: 0.689970, acc.: 57.03%] [G loss: 1.265211]\n",
      "epoch:16 step:15200 [D loss: 0.514876, acc.: 76.56%] [G loss: 1.288421]\n",
      "epoch:16 step:15201 [D loss: 0.696981, acc.: 50.00%] [G loss: 1.012977]\n",
      "epoch:16 step:15202 [D loss: 0.601544, acc.: 68.75%] [G loss: 1.185472]\n",
      "epoch:16 step:15203 [D loss: 0.555441, acc.: 71.09%] [G loss: 1.130693]\n",
      "epoch:16 step:15204 [D loss: 0.515285, acc.: 75.78%] [G loss: 1.387408]\n",
      "epoch:16 step:15205 [D loss: 0.694430, acc.: 60.94%] [G loss: 1.333836]\n",
      "epoch:16 step:15206 [D loss: 0.730411, acc.: 49.22%] [G loss: 1.112420]\n",
      "epoch:16 step:15207 [D loss: 0.652038, acc.: 54.69%] [G loss: 1.370227]\n",
      "epoch:16 step:15208 [D loss: 0.630431, acc.: 65.62%] [G loss: 1.198676]\n",
      "epoch:16 step:15209 [D loss: 0.513899, acc.: 71.88%] [G loss: 1.622923]\n",
      "epoch:16 step:15210 [D loss: 0.512772, acc.: 77.34%] [G loss: 1.096806]\n",
      "epoch:16 step:15211 [D loss: 0.592468, acc.: 71.09%] [G loss: 1.054370]\n",
      "epoch:16 step:15212 [D loss: 0.593037, acc.: 64.84%] [G loss: 1.414565]\n",
      "epoch:16 step:15213 [D loss: 0.644774, acc.: 64.06%] [G loss: 1.215467]\n",
      "epoch:16 step:15214 [D loss: 0.637157, acc.: 67.97%] [G loss: 1.262250]\n",
      "epoch:16 step:15215 [D loss: 0.718318, acc.: 57.81%] [G loss: 0.976614]\n",
      "epoch:16 step:15216 [D loss: 0.596968, acc.: 70.31%] [G loss: 1.205130]\n",
      "epoch:16 step:15217 [D loss: 0.563332, acc.: 71.88%] [G loss: 1.341719]\n",
      "epoch:16 step:15218 [D loss: 0.551648, acc.: 71.09%] [G loss: 1.247767]\n",
      "epoch:16 step:15219 [D loss: 0.595238, acc.: 69.53%] [G loss: 1.243809]\n",
      "epoch:16 step:15220 [D loss: 0.684698, acc.: 60.94%] [G loss: 1.095477]\n",
      "epoch:16 step:15221 [D loss: 0.534732, acc.: 72.66%] [G loss: 1.176946]\n",
      "epoch:16 step:15222 [D loss: 0.598026, acc.: 66.41%] [G loss: 1.279373]\n",
      "epoch:16 step:15223 [D loss: 0.633417, acc.: 64.84%] [G loss: 1.035915]\n",
      "epoch:16 step:15224 [D loss: 0.562811, acc.: 67.97%] [G loss: 1.102322]\n",
      "epoch:16 step:15225 [D loss: 0.604484, acc.: 65.62%] [G loss: 1.260931]\n",
      "epoch:16 step:15226 [D loss: 0.669984, acc.: 61.72%] [G loss: 1.007972]\n",
      "epoch:16 step:15227 [D loss: 0.582430, acc.: 67.97%] [G loss: 1.207131]\n",
      "epoch:16 step:15228 [D loss: 0.632510, acc.: 64.06%] [G loss: 1.531775]\n",
      "epoch:16 step:15229 [D loss: 0.571911, acc.: 74.22%] [G loss: 1.273140]\n",
      "epoch:16 step:15230 [D loss: 0.589354, acc.: 69.53%] [G loss: 1.280890]\n",
      "epoch:16 step:15231 [D loss: 0.530557, acc.: 71.09%] [G loss: 1.176100]\n",
      "epoch:16 step:15232 [D loss: 0.544503, acc.: 70.31%] [G loss: 1.240268]\n",
      "epoch:16 step:15233 [D loss: 0.516729, acc.: 77.34%] [G loss: 1.273045]\n",
      "epoch:16 step:15234 [D loss: 0.578070, acc.: 70.31%] [G loss: 1.303080]\n",
      "epoch:16 step:15235 [D loss: 0.563254, acc.: 74.22%] [G loss: 0.972139]\n",
      "epoch:16 step:15236 [D loss: 0.532629, acc.: 71.88%] [G loss: 1.156967]\n",
      "epoch:16 step:15237 [D loss: 0.618071, acc.: 62.50%] [G loss: 1.261742]\n",
      "epoch:16 step:15238 [D loss: 0.553905, acc.: 71.88%] [G loss: 1.220490]\n",
      "epoch:16 step:15239 [D loss: 0.557913, acc.: 69.53%] [G loss: 1.123042]\n",
      "epoch:16 step:15240 [D loss: 0.642078, acc.: 64.84%] [G loss: 1.289411]\n",
      "epoch:16 step:15241 [D loss: 0.392387, acc.: 89.06%] [G loss: 1.416904]\n",
      "epoch:16 step:15242 [D loss: 0.593515, acc.: 66.41%] [G loss: 1.144401]\n",
      "epoch:16 step:15243 [D loss: 0.590980, acc.: 67.97%] [G loss: 1.294575]\n",
      "epoch:16 step:15244 [D loss: 0.598423, acc.: 65.62%] [G loss: 1.175683]\n",
      "epoch:16 step:15245 [D loss: 0.562858, acc.: 76.56%] [G loss: 1.211620]\n",
      "epoch:16 step:15246 [D loss: 0.578145, acc.: 71.09%] [G loss: 1.392367]\n",
      "epoch:16 step:15247 [D loss: 0.545759, acc.: 68.75%] [G loss: 1.002789]\n",
      "epoch:16 step:15248 [D loss: 0.543610, acc.: 72.66%] [G loss: 1.287383]\n",
      "epoch:16 step:15249 [D loss: 0.505330, acc.: 78.12%] [G loss: 1.091678]\n",
      "epoch:16 step:15250 [D loss: 0.549753, acc.: 71.88%] [G loss: 1.258079]\n",
      "epoch:16 step:15251 [D loss: 0.621517, acc.: 62.50%] [G loss: 1.265957]\n",
      "epoch:16 step:15252 [D loss: 0.636605, acc.: 64.84%] [G loss: 1.210767]\n",
      "epoch:16 step:15253 [D loss: 0.490987, acc.: 78.91%] [G loss: 1.467788]\n",
      "epoch:16 step:15254 [D loss: 0.658504, acc.: 62.50%] [G loss: 0.950210]\n",
      "epoch:16 step:15255 [D loss: 0.760751, acc.: 52.34%] [G loss: 1.092965]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:16 step:15256 [D loss: 0.447998, acc.: 79.69%] [G loss: 1.314509]\n",
      "epoch:16 step:15257 [D loss: 0.543952, acc.: 75.00%] [G loss: 1.445680]\n",
      "epoch:16 step:15258 [D loss: 0.493809, acc.: 75.00%] [G loss: 1.420975]\n",
      "epoch:16 step:15259 [D loss: 0.601647, acc.: 69.53%] [G loss: 1.076218]\n",
      "epoch:16 step:15260 [D loss: 0.467140, acc.: 82.03%] [G loss: 1.092746]\n",
      "epoch:16 step:15261 [D loss: 0.540732, acc.: 69.53%] [G loss: 1.128242]\n",
      "epoch:16 step:15262 [D loss: 0.672921, acc.: 61.72%] [G loss: 1.087113]\n",
      "epoch:16 step:15263 [D loss: 0.591807, acc.: 68.75%] [G loss: 1.526628]\n",
      "epoch:16 step:15264 [D loss: 0.580757, acc.: 70.31%] [G loss: 1.298823]\n",
      "epoch:16 step:15265 [D loss: 0.700667, acc.: 55.47%] [G loss: 1.179000]\n",
      "epoch:16 step:15266 [D loss: 0.535349, acc.: 75.00%] [G loss: 1.021334]\n",
      "epoch:16 step:15267 [D loss: 0.593701, acc.: 69.53%] [G loss: 1.395508]\n",
      "epoch:16 step:15268 [D loss: 0.727951, acc.: 50.78%] [G loss: 1.107015]\n",
      "epoch:16 step:15269 [D loss: 0.565387, acc.: 71.88%] [G loss: 1.191944]\n",
      "epoch:16 step:15270 [D loss: 0.462221, acc.: 81.25%] [G loss: 1.524083]\n",
      "epoch:16 step:15271 [D loss: 0.578654, acc.: 67.97%] [G loss: 1.041233]\n",
      "epoch:16 step:15272 [D loss: 0.560412, acc.: 72.66%] [G loss: 1.162893]\n",
      "epoch:16 step:15273 [D loss: 0.422695, acc.: 82.03%] [G loss: 1.468227]\n",
      "epoch:16 step:15274 [D loss: 0.507120, acc.: 75.78%] [G loss: 1.177897]\n",
      "epoch:16 step:15275 [D loss: 0.516586, acc.: 75.78%] [G loss: 1.273439]\n",
      "epoch:16 step:15276 [D loss: 0.669570, acc.: 66.41%] [G loss: 1.041630]\n",
      "epoch:16 step:15277 [D loss: 0.556832, acc.: 74.22%] [G loss: 1.482197]\n",
      "epoch:16 step:15278 [D loss: 0.613046, acc.: 65.62%] [G loss: 1.024528]\n",
      "epoch:16 step:15279 [D loss: 0.613977, acc.: 65.62%] [G loss: 1.205170]\n",
      "epoch:16 step:15280 [D loss: 0.611387, acc.: 68.75%] [G loss: 1.200789]\n",
      "epoch:16 step:15281 [D loss: 0.610105, acc.: 63.28%] [G loss: 1.249402]\n",
      "epoch:16 step:15282 [D loss: 0.536252, acc.: 74.22%] [G loss: 1.134003]\n",
      "epoch:16 step:15283 [D loss: 0.516654, acc.: 78.12%] [G loss: 1.343698]\n",
      "epoch:16 step:15284 [D loss: 0.615449, acc.: 68.75%] [G loss: 1.301644]\n",
      "epoch:16 step:15285 [D loss: 0.566575, acc.: 71.88%] [G loss: 1.282577]\n",
      "epoch:16 step:15286 [D loss: 0.533105, acc.: 75.78%] [G loss: 1.014638]\n",
      "epoch:16 step:15287 [D loss: 0.513330, acc.: 76.56%] [G loss: 1.133503]\n",
      "epoch:16 step:15288 [D loss: 0.568634, acc.: 71.88%] [G loss: 1.302621]\n",
      "epoch:16 step:15289 [D loss: 0.628562, acc.: 71.09%] [G loss: 1.067870]\n",
      "epoch:16 step:15290 [D loss: 0.641026, acc.: 63.28%] [G loss: 1.281446]\n",
      "epoch:16 step:15291 [D loss: 0.478045, acc.: 78.91%] [G loss: 1.150806]\n",
      "epoch:16 step:15292 [D loss: 0.562017, acc.: 70.31%] [G loss: 1.238506]\n",
      "epoch:16 step:15293 [D loss: 0.606669, acc.: 65.62%] [G loss: 1.036826]\n",
      "epoch:16 step:15294 [D loss: 0.658113, acc.: 64.84%] [G loss: 1.067679]\n",
      "epoch:16 step:15295 [D loss: 0.574944, acc.: 64.84%] [G loss: 1.401119]\n",
      "epoch:16 step:15296 [D loss: 0.510199, acc.: 75.78%] [G loss: 1.475610]\n",
      "epoch:16 step:15297 [D loss: 0.613132, acc.: 70.31%] [G loss: 1.232094]\n",
      "epoch:16 step:15298 [D loss: 0.656077, acc.: 60.16%] [G loss: 1.203313]\n",
      "epoch:16 step:15299 [D loss: 0.681806, acc.: 62.50%] [G loss: 1.052708]\n",
      "epoch:16 step:15300 [D loss: 0.633799, acc.: 59.38%] [G loss: 0.965504]\n",
      "epoch:16 step:15301 [D loss: 0.517057, acc.: 78.12%] [G loss: 1.266881]\n",
      "epoch:16 step:15302 [D loss: 0.655188, acc.: 63.28%] [G loss: 1.221726]\n",
      "epoch:16 step:15303 [D loss: 0.669719, acc.: 60.16%] [G loss: 1.232727]\n",
      "epoch:16 step:15304 [D loss: 0.592119, acc.: 65.62%] [G loss: 1.272481]\n",
      "epoch:16 step:15305 [D loss: 0.678981, acc.: 59.38%] [G loss: 1.176329]\n",
      "epoch:16 step:15306 [D loss: 0.549944, acc.: 74.22%] [G loss: 1.295697]\n",
      "epoch:16 step:15307 [D loss: 0.554265, acc.: 75.78%] [G loss: 1.051430]\n",
      "epoch:16 step:15308 [D loss: 0.646055, acc.: 60.94%] [G loss: 1.262492]\n",
      "epoch:16 step:15309 [D loss: 0.468355, acc.: 82.03%] [G loss: 1.424547]\n",
      "epoch:16 step:15310 [D loss: 0.606320, acc.: 66.41%] [G loss: 1.259403]\n",
      "epoch:16 step:15311 [D loss: 0.553295, acc.: 71.88%] [G loss: 1.135764]\n",
      "epoch:16 step:15312 [D loss: 0.509977, acc.: 79.69%] [G loss: 1.422729]\n",
      "epoch:16 step:15313 [D loss: 0.588486, acc.: 70.31%] [G loss: 1.357698]\n",
      "epoch:16 step:15314 [D loss: 0.668184, acc.: 66.41%] [G loss: 1.247746]\n",
      "epoch:16 step:15315 [D loss: 0.613280, acc.: 65.62%] [G loss: 1.230056]\n",
      "epoch:16 step:15316 [D loss: 0.544449, acc.: 72.66%] [G loss: 1.448255]\n",
      "epoch:16 step:15317 [D loss: 0.581192, acc.: 69.53%] [G loss: 1.438218]\n",
      "epoch:16 step:15318 [D loss: 0.557538, acc.: 69.53%] [G loss: 1.160525]\n",
      "epoch:16 step:15319 [D loss: 0.616727, acc.: 61.72%] [G loss: 1.236829]\n",
      "epoch:16 step:15320 [D loss: 0.575866, acc.: 71.09%] [G loss: 1.351063]\n",
      "epoch:16 step:15321 [D loss: 0.648974, acc.: 63.28%] [G loss: 1.182286]\n",
      "epoch:16 step:15322 [D loss: 0.666191, acc.: 61.72%] [G loss: 1.170421]\n",
      "epoch:16 step:15323 [D loss: 0.599441, acc.: 64.06%] [G loss: 1.249580]\n",
      "epoch:16 step:15324 [D loss: 0.597264, acc.: 65.62%] [G loss: 1.188241]\n",
      "epoch:16 step:15325 [D loss: 0.612717, acc.: 67.19%] [G loss: 1.611281]\n",
      "epoch:16 step:15326 [D loss: 0.561687, acc.: 69.53%] [G loss: 1.184226]\n",
      "epoch:16 step:15327 [D loss: 0.526045, acc.: 73.44%] [G loss: 1.069005]\n",
      "epoch:16 step:15328 [D loss: 0.557452, acc.: 67.19%] [G loss: 1.004320]\n",
      "epoch:16 step:15329 [D loss: 0.638322, acc.: 66.41%] [G loss: 1.065818]\n",
      "epoch:16 step:15330 [D loss: 0.528340, acc.: 77.34%] [G loss: 1.486947]\n",
      "epoch:16 step:15331 [D loss: 0.589664, acc.: 67.19%] [G loss: 1.252565]\n",
      "epoch:16 step:15332 [D loss: 0.620917, acc.: 63.28%] [G loss: 1.589071]\n",
      "epoch:16 step:15333 [D loss: 0.609136, acc.: 66.41%] [G loss: 1.204056]\n",
      "epoch:16 step:15334 [D loss: 0.603294, acc.: 64.84%] [G loss: 1.148776]\n",
      "epoch:16 step:15335 [D loss: 0.632743, acc.: 64.84%] [G loss: 1.047019]\n",
      "epoch:16 step:15336 [D loss: 0.594055, acc.: 68.75%] [G loss: 1.230684]\n",
      "epoch:16 step:15337 [D loss: 0.476687, acc.: 84.38%] [G loss: 1.469104]\n",
      "epoch:16 step:15338 [D loss: 0.669175, acc.: 58.59%] [G loss: 1.288387]\n",
      "epoch:16 step:15339 [D loss: 0.573379, acc.: 71.09%] [G loss: 1.137124]\n",
      "epoch:16 step:15340 [D loss: 0.495421, acc.: 80.47%] [G loss: 1.138560]\n",
      "epoch:16 step:15341 [D loss: 0.548445, acc.: 70.31%] [G loss: 1.247078]\n",
      "epoch:16 step:15342 [D loss: 0.467218, acc.: 77.34%] [G loss: 1.290246]\n",
      "epoch:16 step:15343 [D loss: 0.524080, acc.: 75.00%] [G loss: 1.507659]\n",
      "epoch:16 step:15344 [D loss: 0.594420, acc.: 62.50%] [G loss: 1.063332]\n",
      "epoch:16 step:15345 [D loss: 0.500504, acc.: 77.34%] [G loss: 1.470389]\n",
      "epoch:16 step:15346 [D loss: 0.599456, acc.: 65.62%] [G loss: 1.133875]\n",
      "epoch:16 step:15347 [D loss: 0.580557, acc.: 72.66%] [G loss: 1.158201]\n",
      "epoch:16 step:15348 [D loss: 0.480473, acc.: 79.69%] [G loss: 1.302314]\n",
      "epoch:16 step:15349 [D loss: 0.606336, acc.: 68.75%] [G loss: 1.259872]\n",
      "epoch:16 step:15350 [D loss: 0.680920, acc.: 60.94%] [G loss: 1.103962]\n",
      "epoch:16 step:15351 [D loss: 0.586821, acc.: 67.19%] [G loss: 1.163559]\n",
      "epoch:16 step:15352 [D loss: 0.549986, acc.: 73.44%] [G loss: 1.350713]\n",
      "epoch:16 step:15353 [D loss: 0.623665, acc.: 67.19%] [G loss: 1.237878]\n",
      "epoch:16 step:15354 [D loss: 0.614700, acc.: 67.19%] [G loss: 1.123097]\n",
      "epoch:16 step:15355 [D loss: 0.524659, acc.: 80.47%] [G loss: 1.089005]\n",
      "epoch:16 step:15356 [D loss: 0.562615, acc.: 70.31%] [G loss: 1.294063]\n",
      "epoch:16 step:15357 [D loss: 0.542487, acc.: 76.56%] [G loss: 1.263892]\n",
      "epoch:16 step:15358 [D loss: 0.695331, acc.: 57.81%] [G loss: 1.340635]\n",
      "epoch:16 step:15359 [D loss: 0.758200, acc.: 53.91%] [G loss: 0.984107]\n",
      "epoch:16 step:15360 [D loss: 0.614946, acc.: 65.62%] [G loss: 1.285618]\n",
      "epoch:16 step:15361 [D loss: 0.619167, acc.: 67.19%] [G loss: 1.118888]\n",
      "epoch:16 step:15362 [D loss: 0.612036, acc.: 67.97%] [G loss: 1.332253]\n",
      "epoch:16 step:15363 [D loss: 0.533486, acc.: 69.53%] [G loss: 1.390271]\n",
      "epoch:16 step:15364 [D loss: 0.571680, acc.: 72.66%] [G loss: 1.288413]\n",
      "epoch:16 step:15365 [D loss: 0.539156, acc.: 73.44%] [G loss: 1.375695]\n",
      "epoch:16 step:15366 [D loss: 0.707347, acc.: 54.69%] [G loss: 1.008820]\n",
      "epoch:16 step:15367 [D loss: 0.657242, acc.: 61.72%] [G loss: 1.242987]\n",
      "epoch:16 step:15368 [D loss: 0.592070, acc.: 71.09%] [G loss: 1.302083]\n",
      "epoch:16 step:15369 [D loss: 0.550598, acc.: 75.00%] [G loss: 1.136387]\n",
      "epoch:16 step:15370 [D loss: 0.528208, acc.: 75.00%] [G loss: 0.876534]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:16 step:15371 [D loss: 0.573482, acc.: 68.75%] [G loss: 1.391236]\n",
      "epoch:16 step:15372 [D loss: 0.570163, acc.: 71.88%] [G loss: 1.278533]\n",
      "epoch:16 step:15373 [D loss: 0.445000, acc.: 85.16%] [G loss: 1.128535]\n",
      "epoch:16 step:15374 [D loss: 0.659096, acc.: 64.84%] [G loss: 1.170334]\n",
      "epoch:16 step:15375 [D loss: 0.596246, acc.: 67.97%] [G loss: 1.182897]\n",
      "epoch:16 step:15376 [D loss: 0.578643, acc.: 70.31%] [G loss: 1.175748]\n",
      "epoch:16 step:15377 [D loss: 0.542185, acc.: 76.56%] [G loss: 1.120560]\n",
      "epoch:16 step:15378 [D loss: 0.485077, acc.: 78.91%] [G loss: 1.278578]\n",
      "epoch:16 step:15379 [D loss: 0.605562, acc.: 69.53%] [G loss: 1.325817]\n",
      "epoch:16 step:15380 [D loss: 0.632394, acc.: 63.28%] [G loss: 1.379766]\n",
      "epoch:16 step:15381 [D loss: 0.548150, acc.: 76.56%] [G loss: 1.600443]\n",
      "epoch:16 step:15382 [D loss: 0.624971, acc.: 61.72%] [G loss: 1.243032]\n",
      "epoch:16 step:15383 [D loss: 0.708638, acc.: 57.03%] [G loss: 1.049733]\n",
      "epoch:16 step:15384 [D loss: 0.564782, acc.: 72.66%] [G loss: 1.067589]\n",
      "epoch:16 step:15385 [D loss: 0.628577, acc.: 67.97%] [G loss: 1.445820]\n",
      "epoch:16 step:15386 [D loss: 0.598235, acc.: 67.97%] [G loss: 1.212304]\n",
      "epoch:16 step:15387 [D loss: 0.577379, acc.: 71.88%] [G loss: 1.041165]\n",
      "epoch:16 step:15388 [D loss: 0.516967, acc.: 74.22%] [G loss: 1.266701]\n",
      "epoch:16 step:15389 [D loss: 0.821008, acc.: 47.66%] [G loss: 1.143298]\n",
      "epoch:16 step:15390 [D loss: 0.546853, acc.: 71.09%] [G loss: 1.137834]\n",
      "epoch:16 step:15391 [D loss: 0.530099, acc.: 71.09%] [G loss: 1.592193]\n",
      "epoch:16 step:15392 [D loss: 0.619192, acc.: 65.62%] [G loss: 0.926302]\n",
      "epoch:16 step:15393 [D loss: 0.619209, acc.: 64.84%] [G loss: 1.125864]\n",
      "epoch:16 step:15394 [D loss: 0.640786, acc.: 68.75%] [G loss: 1.108025]\n",
      "epoch:16 step:15395 [D loss: 0.530746, acc.: 75.00%] [G loss: 1.323651]\n",
      "epoch:16 step:15396 [D loss: 0.592090, acc.: 67.19%] [G loss: 1.143227]\n",
      "epoch:16 step:15397 [D loss: 0.677382, acc.: 60.16%] [G loss: 1.174633]\n",
      "epoch:16 step:15398 [D loss: 0.411699, acc.: 86.72%] [G loss: 1.678364]\n",
      "epoch:16 step:15399 [D loss: 0.524656, acc.: 75.78%] [G loss: 0.929857]\n",
      "epoch:16 step:15400 [D loss: 0.514144, acc.: 78.12%] [G loss: 1.270647]\n",
      "epoch:16 step:15401 [D loss: 0.583937, acc.: 67.97%] [G loss: 1.460205]\n",
      "epoch:16 step:15402 [D loss: 0.574073, acc.: 65.62%] [G loss: 1.332195]\n",
      "epoch:16 step:15403 [D loss: 0.636088, acc.: 64.06%] [G loss: 1.145907]\n",
      "epoch:16 step:15404 [D loss: 0.712824, acc.: 58.59%] [G loss: 1.107512]\n",
      "epoch:16 step:15405 [D loss: 0.698154, acc.: 57.81%] [G loss: 1.323298]\n",
      "epoch:16 step:15406 [D loss: 0.619447, acc.: 67.19%] [G loss: 1.159720]\n",
      "epoch:16 step:15407 [D loss: 0.610386, acc.: 68.75%] [G loss: 1.135399]\n",
      "epoch:16 step:15408 [D loss: 0.529885, acc.: 74.22%] [G loss: 1.278198]\n",
      "epoch:16 step:15409 [D loss: 0.627454, acc.: 64.06%] [G loss: 1.011007]\n",
      "epoch:16 step:15410 [D loss: 0.637302, acc.: 66.41%] [G loss: 1.217282]\n",
      "epoch:16 step:15411 [D loss: 0.457513, acc.: 80.47%] [G loss: 1.144629]\n",
      "epoch:16 step:15412 [D loss: 0.621537, acc.: 67.19%] [G loss: 1.206948]\n",
      "epoch:16 step:15413 [D loss: 0.521973, acc.: 71.09%] [G loss: 1.171045]\n",
      "epoch:16 step:15414 [D loss: 0.712888, acc.: 53.91%] [G loss: 1.115937]\n",
      "epoch:16 step:15415 [D loss: 0.561392, acc.: 69.53%] [G loss: 1.127321]\n",
      "epoch:16 step:15416 [D loss: 0.537672, acc.: 71.88%] [G loss: 1.296586]\n",
      "epoch:16 step:15417 [D loss: 0.551861, acc.: 69.53%] [G loss: 1.224357]\n",
      "epoch:16 step:15418 [D loss: 0.562217, acc.: 69.53%] [G loss: 1.369892]\n",
      "epoch:16 step:15419 [D loss: 0.794650, acc.: 49.22%] [G loss: 1.336146]\n",
      "epoch:16 step:15420 [D loss: 0.644918, acc.: 63.28%] [G loss: 1.020164]\n",
      "epoch:16 step:15421 [D loss: 0.530854, acc.: 71.88%] [G loss: 1.082226]\n",
      "epoch:16 step:15422 [D loss: 0.612338, acc.: 65.62%] [G loss: 1.190805]\n",
      "epoch:16 step:15423 [D loss: 0.514475, acc.: 78.12%] [G loss: 1.271610]\n",
      "epoch:16 step:15424 [D loss: 0.641184, acc.: 65.62%] [G loss: 1.099281]\n",
      "epoch:16 step:15425 [D loss: 0.780448, acc.: 52.34%] [G loss: 1.029713]\n",
      "epoch:16 step:15426 [D loss: 0.644602, acc.: 60.16%] [G loss: 1.336050]\n",
      "epoch:16 step:15427 [D loss: 0.584311, acc.: 67.19%] [G loss: 1.016115]\n",
      "epoch:16 step:15428 [D loss: 0.565334, acc.: 78.12%] [G loss: 1.366445]\n",
      "epoch:16 step:15429 [D loss: 0.629304, acc.: 63.28%] [G loss: 1.415056]\n",
      "epoch:16 step:15430 [D loss: 0.618346, acc.: 66.41%] [G loss: 1.262645]\n",
      "epoch:16 step:15431 [D loss: 0.604207, acc.: 64.06%] [G loss: 1.251989]\n",
      "epoch:16 step:15432 [D loss: 0.592684, acc.: 69.53%] [G loss: 1.249256]\n",
      "epoch:16 step:15433 [D loss: 0.669751, acc.: 64.84%] [G loss: 1.445064]\n",
      "epoch:16 step:15434 [D loss: 0.593077, acc.: 70.31%] [G loss: 1.367561]\n",
      "epoch:16 step:15435 [D loss: 0.551513, acc.: 74.22%] [G loss: 1.436282]\n",
      "epoch:16 step:15436 [D loss: 0.502078, acc.: 77.34%] [G loss: 1.461657]\n",
      "epoch:16 step:15437 [D loss: 0.566662, acc.: 74.22%] [G loss: 1.005463]\n",
      "epoch:16 step:15438 [D loss: 0.517864, acc.: 78.91%] [G loss: 1.523724]\n",
      "epoch:16 step:15439 [D loss: 0.465188, acc.: 78.12%] [G loss: 1.312049]\n",
      "epoch:16 step:15440 [D loss: 0.561793, acc.: 68.75%] [G loss: 1.560969]\n",
      "epoch:16 step:15441 [D loss: 0.680453, acc.: 63.28%] [G loss: 0.958850]\n",
      "epoch:16 step:15442 [D loss: 0.645109, acc.: 67.97%] [G loss: 0.987054]\n",
      "epoch:16 step:15443 [D loss: 0.537831, acc.: 78.91%] [G loss: 1.157647]\n",
      "epoch:16 step:15444 [D loss: 0.461977, acc.: 83.59%] [G loss: 1.059463]\n",
      "epoch:16 step:15445 [D loss: 0.729488, acc.: 57.03%] [G loss: 1.120474]\n",
      "epoch:16 step:15446 [D loss: 0.670759, acc.: 62.50%] [G loss: 1.347305]\n",
      "epoch:16 step:15447 [D loss: 0.623653, acc.: 65.62%] [G loss: 1.322063]\n",
      "epoch:16 step:15448 [D loss: 0.753095, acc.: 54.69%] [G loss: 1.197338]\n",
      "epoch:16 step:15449 [D loss: 0.730501, acc.: 57.03%] [G loss: 1.276702]\n",
      "epoch:16 step:15450 [D loss: 0.529266, acc.: 73.44%] [G loss: 1.530501]\n",
      "epoch:16 step:15451 [D loss: 0.519272, acc.: 75.78%] [G loss: 1.159797]\n",
      "epoch:16 step:15452 [D loss: 0.602912, acc.: 67.97%] [G loss: 1.360309]\n",
      "epoch:16 step:15453 [D loss: 0.746411, acc.: 54.69%] [G loss: 1.131156]\n",
      "epoch:16 step:15454 [D loss: 0.570284, acc.: 73.44%] [G loss: 1.279809]\n",
      "epoch:16 step:15455 [D loss: 0.734044, acc.: 57.03%] [G loss: 1.187932]\n",
      "epoch:16 step:15456 [D loss: 0.604561, acc.: 64.06%] [G loss: 1.561675]\n",
      "epoch:16 step:15457 [D loss: 0.637668, acc.: 59.38%] [G loss: 1.399470]\n",
      "epoch:16 step:15458 [D loss: 0.585804, acc.: 69.53%] [G loss: 1.540766]\n",
      "epoch:16 step:15459 [D loss: 0.497011, acc.: 77.34%] [G loss: 1.438261]\n",
      "epoch:16 step:15460 [D loss: 0.531341, acc.: 72.66%] [G loss: 1.436558]\n",
      "epoch:16 step:15461 [D loss: 0.606884, acc.: 67.19%] [G loss: 1.323801]\n",
      "epoch:16 step:15462 [D loss: 0.686574, acc.: 57.03%] [G loss: 1.160769]\n",
      "epoch:16 step:15463 [D loss: 0.614137, acc.: 65.62%] [G loss: 1.152870]\n",
      "epoch:16 step:15464 [D loss: 0.589426, acc.: 69.53%] [G loss: 1.293957]\n",
      "epoch:16 step:15465 [D loss: 0.605628, acc.: 64.06%] [G loss: 1.414245]\n",
      "epoch:16 step:15466 [D loss: 0.574074, acc.: 70.31%] [G loss: 1.180090]\n",
      "epoch:16 step:15467 [D loss: 0.461313, acc.: 80.47%] [G loss: 1.383023]\n",
      "epoch:16 step:15468 [D loss: 0.522879, acc.: 76.56%] [G loss: 1.126070]\n",
      "epoch:16 step:15469 [D loss: 0.662010, acc.: 57.81%] [G loss: 1.361866]\n",
      "epoch:16 step:15470 [D loss: 0.586544, acc.: 67.97%] [G loss: 1.219891]\n",
      "epoch:16 step:15471 [D loss: 0.490810, acc.: 81.25%] [G loss: 1.691794]\n",
      "epoch:16 step:15472 [D loss: 0.559868, acc.: 68.75%] [G loss: 1.287408]\n",
      "epoch:16 step:15473 [D loss: 0.602246, acc.: 68.75%] [G loss: 1.224360]\n",
      "epoch:16 step:15474 [D loss: 0.694284, acc.: 63.28%] [G loss: 0.881378]\n",
      "epoch:16 step:15475 [D loss: 0.604474, acc.: 65.62%] [G loss: 1.162152]\n",
      "epoch:16 step:15476 [D loss: 0.567294, acc.: 68.75%] [G loss: 1.093495]\n",
      "epoch:16 step:15477 [D loss: 0.544632, acc.: 71.09%] [G loss: 1.022643]\n",
      "epoch:16 step:15478 [D loss: 0.439491, acc.: 79.69%] [G loss: 1.223861]\n",
      "epoch:16 step:15479 [D loss: 0.645336, acc.: 57.81%] [G loss: 1.123901]\n",
      "epoch:16 step:15480 [D loss: 0.590998, acc.: 67.19%] [G loss: 1.283931]\n",
      "epoch:16 step:15481 [D loss: 0.503772, acc.: 78.12%] [G loss: 1.461727]\n",
      "epoch:16 step:15482 [D loss: 0.439126, acc.: 84.38%] [G loss: 1.232355]\n",
      "epoch:16 step:15483 [D loss: 0.609083, acc.: 67.97%] [G loss: 1.008425]\n",
      "epoch:16 step:15484 [D loss: 0.516130, acc.: 75.78%] [G loss: 1.494754]\n",
      "epoch:16 step:15485 [D loss: 0.691606, acc.: 61.72%] [G loss: 1.050447]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:16 step:15486 [D loss: 0.508317, acc.: 73.44%] [G loss: 1.422217]\n",
      "epoch:16 step:15487 [D loss: 0.659875, acc.: 61.72%] [G loss: 1.059556]\n",
      "epoch:16 step:15488 [D loss: 0.660509, acc.: 62.50%] [G loss: 1.327253]\n",
      "epoch:16 step:15489 [D loss: 0.429338, acc.: 85.94%] [G loss: 1.536910]\n",
      "epoch:16 step:15490 [D loss: 0.488270, acc.: 78.12%] [G loss: 1.155620]\n",
      "epoch:16 step:15491 [D loss: 0.517198, acc.: 73.44%] [G loss: 1.015593]\n",
      "epoch:16 step:15492 [D loss: 0.564440, acc.: 72.66%] [G loss: 1.128501]\n",
      "epoch:16 step:15493 [D loss: 0.582298, acc.: 70.31%] [G loss: 1.264098]\n",
      "epoch:16 step:15494 [D loss: 0.534657, acc.: 74.22%] [G loss: 1.006638]\n",
      "epoch:16 step:15495 [D loss: 0.590077, acc.: 69.53%] [G loss: 1.002996]\n",
      "epoch:16 step:15496 [D loss: 0.578469, acc.: 66.41%] [G loss: 1.298985]\n",
      "epoch:16 step:15497 [D loss: 0.499044, acc.: 78.91%] [G loss: 1.650554]\n",
      "epoch:16 step:15498 [D loss: 0.549000, acc.: 72.66%] [G loss: 1.468325]\n",
      "epoch:16 step:15499 [D loss: 0.726477, acc.: 53.91%] [G loss: 1.079404]\n",
      "epoch:16 step:15500 [D loss: 0.530445, acc.: 78.91%] [G loss: 1.126394]\n",
      "epoch:16 step:15501 [D loss: 0.614119, acc.: 70.31%] [G loss: 1.077771]\n",
      "epoch:16 step:15502 [D loss: 0.607502, acc.: 65.62%] [G loss: 1.350858]\n",
      "epoch:16 step:15503 [D loss: 0.466250, acc.: 81.25%] [G loss: 1.109847]\n",
      "epoch:16 step:15504 [D loss: 0.601569, acc.: 70.31%] [G loss: 1.279670]\n",
      "epoch:16 step:15505 [D loss: 0.485170, acc.: 78.12%] [G loss: 1.278890]\n",
      "epoch:16 step:15506 [D loss: 0.558158, acc.: 74.22%] [G loss: 1.481006]\n",
      "epoch:16 step:15507 [D loss: 0.690286, acc.: 60.16%] [G loss: 1.052210]\n",
      "epoch:16 step:15508 [D loss: 0.561842, acc.: 65.62%] [G loss: 1.224706]\n",
      "epoch:16 step:15509 [D loss: 0.562642, acc.: 72.66%] [G loss: 1.179204]\n",
      "epoch:16 step:15510 [D loss: 0.573713, acc.: 71.88%] [G loss: 1.036897]\n",
      "epoch:16 step:15511 [D loss: 0.592201, acc.: 69.53%] [G loss: 1.422249]\n",
      "epoch:16 step:15512 [D loss: 0.517536, acc.: 78.12%] [G loss: 1.045663]\n",
      "epoch:16 step:15513 [D loss: 0.656847, acc.: 60.16%] [G loss: 0.980079]\n",
      "epoch:16 step:15514 [D loss: 0.596964, acc.: 69.53%] [G loss: 1.394335]\n",
      "epoch:16 step:15515 [D loss: 0.580426, acc.: 67.97%] [G loss: 1.385578]\n",
      "epoch:16 step:15516 [D loss: 0.627069, acc.: 64.06%] [G loss: 1.160350]\n",
      "epoch:16 step:15517 [D loss: 0.496307, acc.: 78.91%] [G loss: 1.302003]\n",
      "epoch:16 step:15518 [D loss: 0.561354, acc.: 67.97%] [G loss: 1.306454]\n",
      "epoch:16 step:15519 [D loss: 0.612225, acc.: 62.50%] [G loss: 1.107678]\n",
      "epoch:16 step:15520 [D loss: 0.515863, acc.: 72.66%] [G loss: 1.281778]\n",
      "epoch:16 step:15521 [D loss: 0.569639, acc.: 71.88%] [G loss: 1.375664]\n",
      "epoch:16 step:15522 [D loss: 0.634327, acc.: 66.41%] [G loss: 1.022689]\n",
      "epoch:16 step:15523 [D loss: 0.513056, acc.: 75.00%] [G loss: 1.250690]\n",
      "epoch:16 step:15524 [D loss: 0.570896, acc.: 67.19%] [G loss: 1.254668]\n",
      "epoch:16 step:15525 [D loss: 0.540045, acc.: 68.75%] [G loss: 1.117248]\n",
      "epoch:16 step:15526 [D loss: 0.582442, acc.: 69.53%] [G loss: 1.409315]\n",
      "epoch:16 step:15527 [D loss: 0.633018, acc.: 65.62%] [G loss: 1.308855]\n",
      "epoch:16 step:15528 [D loss: 0.589111, acc.: 64.84%] [G loss: 0.942984]\n",
      "epoch:16 step:15529 [D loss: 0.563844, acc.: 66.41%] [G loss: 1.172926]\n",
      "epoch:16 step:15530 [D loss: 0.757161, acc.: 50.78%] [G loss: 0.938246]\n",
      "epoch:16 step:15531 [D loss: 0.618597, acc.: 68.75%] [G loss: 1.021254]\n",
      "epoch:16 step:15532 [D loss: 0.445809, acc.: 78.91%] [G loss: 1.180768]\n",
      "epoch:16 step:15533 [D loss: 0.501697, acc.: 78.91%] [G loss: 1.273983]\n",
      "epoch:16 step:15534 [D loss: 0.644580, acc.: 64.84%] [G loss: 1.330366]\n",
      "epoch:16 step:15535 [D loss: 0.564187, acc.: 71.09%] [G loss: 1.089813]\n",
      "epoch:16 step:15536 [D loss: 0.603884, acc.: 66.41%] [G loss: 1.201055]\n",
      "epoch:16 step:15537 [D loss: 0.636879, acc.: 66.41%] [G loss: 1.116555]\n",
      "epoch:16 step:15538 [D loss: 0.497993, acc.: 78.12%] [G loss: 1.214500]\n",
      "epoch:16 step:15539 [D loss: 0.628329, acc.: 65.62%] [G loss: 1.269022]\n",
      "epoch:16 step:15540 [D loss: 0.535099, acc.: 72.66%] [G loss: 1.055888]\n",
      "epoch:16 step:15541 [D loss: 0.609433, acc.: 66.41%] [G loss: 1.092275]\n",
      "epoch:16 step:15542 [D loss: 0.618081, acc.: 63.28%] [G loss: 1.372407]\n",
      "epoch:16 step:15543 [D loss: 0.585147, acc.: 69.53%] [G loss: 1.406399]\n",
      "epoch:16 step:15544 [D loss: 0.547801, acc.: 76.56%] [G loss: 0.967244]\n",
      "epoch:16 step:15545 [D loss: 0.624283, acc.: 65.62%] [G loss: 1.196105]\n",
      "epoch:16 step:15546 [D loss: 0.566897, acc.: 71.09%] [G loss: 1.107116]\n",
      "epoch:16 step:15547 [D loss: 0.576918, acc.: 70.31%] [G loss: 1.417773]\n",
      "epoch:16 step:15548 [D loss: 0.536710, acc.: 69.53%] [G loss: 1.234475]\n",
      "epoch:16 step:15549 [D loss: 0.581009, acc.: 67.97%] [G loss: 1.092989]\n",
      "epoch:16 step:15550 [D loss: 0.488900, acc.: 77.34%] [G loss: 1.456883]\n",
      "epoch:16 step:15551 [D loss: 0.537094, acc.: 68.75%] [G loss: 1.369094]\n",
      "epoch:16 step:15552 [D loss: 0.621908, acc.: 61.72%] [G loss: 1.261593]\n",
      "epoch:16 step:15553 [D loss: 0.562100, acc.: 73.44%] [G loss: 1.328336]\n",
      "epoch:16 step:15554 [D loss: 0.514468, acc.: 76.56%] [G loss: 1.274283]\n",
      "epoch:16 step:15555 [D loss: 0.621530, acc.: 67.19%] [G loss: 1.412202]\n",
      "epoch:16 step:15556 [D loss: 0.530696, acc.: 75.00%] [G loss: 1.278564]\n",
      "epoch:16 step:15557 [D loss: 0.719008, acc.: 59.38%] [G loss: 1.122945]\n",
      "epoch:16 step:15558 [D loss: 0.428519, acc.: 82.03%] [G loss: 1.418178]\n",
      "epoch:16 step:15559 [D loss: 0.601224, acc.: 64.84%] [G loss: 1.230626]\n",
      "epoch:16 step:15560 [D loss: 0.622225, acc.: 61.72%] [G loss: 1.316190]\n",
      "epoch:16 step:15561 [D loss: 0.565763, acc.: 73.44%] [G loss: 1.110603]\n",
      "epoch:16 step:15562 [D loss: 0.632546, acc.: 59.38%] [G loss: 1.195376]\n",
      "epoch:16 step:15563 [D loss: 0.470312, acc.: 78.12%] [G loss: 1.304147]\n",
      "epoch:16 step:15564 [D loss: 0.458959, acc.: 79.69%] [G loss: 1.248706]\n",
      "epoch:16 step:15565 [D loss: 0.575441, acc.: 72.66%] [G loss: 1.265536]\n",
      "epoch:16 step:15566 [D loss: 0.530521, acc.: 73.44%] [G loss: 1.314090]\n",
      "epoch:16 step:15567 [D loss: 0.690506, acc.: 61.72%] [G loss: 1.263272]\n",
      "epoch:16 step:15568 [D loss: 0.487931, acc.: 80.47%] [G loss: 0.896820]\n",
      "epoch:16 step:15569 [D loss: 0.630529, acc.: 66.41%] [G loss: 1.220599]\n",
      "epoch:16 step:15570 [D loss: 0.725899, acc.: 56.25%] [G loss: 1.055147]\n",
      "epoch:16 step:15571 [D loss: 0.575845, acc.: 71.88%] [G loss: 1.228632]\n",
      "epoch:16 step:15572 [D loss: 0.633819, acc.: 63.28%] [G loss: 1.057902]\n",
      "epoch:16 step:15573 [D loss: 0.572285, acc.: 71.88%] [G loss: 1.193048]\n",
      "epoch:16 step:15574 [D loss: 0.609893, acc.: 67.19%] [G loss: 1.467418]\n",
      "epoch:16 step:15575 [D loss: 0.631581, acc.: 64.84%] [G loss: 1.162638]\n",
      "epoch:16 step:15576 [D loss: 0.490784, acc.: 76.56%] [G loss: 1.175826]\n",
      "epoch:16 step:15577 [D loss: 0.563650, acc.: 64.84%] [G loss: 1.393103]\n",
      "epoch:16 step:15578 [D loss: 0.604634, acc.: 67.97%] [G loss: 1.054835]\n",
      "epoch:16 step:15579 [D loss: 0.541170, acc.: 70.31%] [G loss: 1.199674]\n",
      "epoch:16 step:15580 [D loss: 0.566293, acc.: 67.97%] [G loss: 1.407405]\n",
      "epoch:16 step:15581 [D loss: 0.544605, acc.: 72.66%] [G loss: 1.224067]\n",
      "epoch:16 step:15582 [D loss: 0.577539, acc.: 68.75%] [G loss: 1.358547]\n",
      "epoch:16 step:15583 [D loss: 0.500408, acc.: 76.56%] [G loss: 0.901309]\n",
      "epoch:16 step:15584 [D loss: 0.595562, acc.: 63.28%] [G loss: 1.311283]\n",
      "epoch:16 step:15585 [D loss: 0.535147, acc.: 71.09%] [G loss: 1.534822]\n",
      "epoch:16 step:15586 [D loss: 0.573699, acc.: 68.75%] [G loss: 1.328712]\n",
      "epoch:16 step:15587 [D loss: 0.643959, acc.: 60.94%] [G loss: 1.231043]\n",
      "epoch:16 step:15588 [D loss: 0.597597, acc.: 68.75%] [G loss: 1.328231]\n",
      "epoch:16 step:15589 [D loss: 0.667638, acc.: 60.94%] [G loss: 1.000632]\n",
      "epoch:16 step:15590 [D loss: 0.585981, acc.: 72.66%] [G loss: 1.064931]\n",
      "epoch:16 step:15591 [D loss: 0.667996, acc.: 61.72%] [G loss: 0.913282]\n",
      "epoch:16 step:15592 [D loss: 0.571908, acc.: 67.97%] [G loss: 1.123795]\n",
      "epoch:16 step:15593 [D loss: 0.739478, acc.: 52.34%] [G loss: 1.301302]\n",
      "epoch:16 step:15594 [D loss: 0.475473, acc.: 79.69%] [G loss: 1.376527]\n",
      "epoch:16 step:15595 [D loss: 0.603343, acc.: 64.06%] [G loss: 1.164697]\n",
      "epoch:16 step:15596 [D loss: 0.659333, acc.: 62.50%] [G loss: 1.173064]\n",
      "epoch:16 step:15597 [D loss: 0.577983, acc.: 69.53%] [G loss: 1.394127]\n",
      "epoch:16 step:15598 [D loss: 0.590674, acc.: 68.75%] [G loss: 1.296260]\n",
      "epoch:16 step:15599 [D loss: 0.554192, acc.: 70.31%] [G loss: 1.038107]\n",
      "epoch:16 step:15600 [D loss: 0.513836, acc.: 78.12%] [G loss: 1.164571]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:16 step:15601 [D loss: 0.571145, acc.: 71.09%] [G loss: 1.173481]\n",
      "epoch:16 step:15602 [D loss: 0.596836, acc.: 67.97%] [G loss: 1.140064]\n",
      "epoch:16 step:15603 [D loss: 0.562199, acc.: 71.88%] [G loss: 1.021247]\n",
      "epoch:16 step:15604 [D loss: 0.579373, acc.: 70.31%] [G loss: 1.200056]\n",
      "epoch:16 step:15605 [D loss: 0.605313, acc.: 64.06%] [G loss: 0.962755]\n",
      "epoch:16 step:15606 [D loss: 0.594095, acc.: 66.41%] [G loss: 1.401955]\n",
      "epoch:16 step:15607 [D loss: 0.642498, acc.: 60.16%] [G loss: 1.103586]\n",
      "epoch:16 step:15608 [D loss: 0.503345, acc.: 78.12%] [G loss: 1.510263]\n",
      "epoch:16 step:15609 [D loss: 0.610102, acc.: 64.84%] [G loss: 1.190211]\n",
      "epoch:16 step:15610 [D loss: 0.551485, acc.: 71.88%] [G loss: 1.213167]\n",
      "epoch:16 step:15611 [D loss: 0.692053, acc.: 53.91%] [G loss: 1.389549]\n",
      "epoch:16 step:15612 [D loss: 0.543977, acc.: 75.78%] [G loss: 1.331274]\n",
      "epoch:16 step:15613 [D loss: 0.655733, acc.: 64.84%] [G loss: 1.110623]\n",
      "epoch:16 step:15614 [D loss: 0.490835, acc.: 75.78%] [G loss: 1.247109]\n",
      "epoch:16 step:15615 [D loss: 0.584973, acc.: 68.75%] [G loss: 1.284113]\n",
      "epoch:16 step:15616 [D loss: 0.539303, acc.: 67.97%] [G loss: 1.350427]\n",
      "epoch:16 step:15617 [D loss: 0.551114, acc.: 71.09%] [G loss: 1.165992]\n",
      "epoch:16 step:15618 [D loss: 0.439341, acc.: 83.59%] [G loss: 1.501799]\n",
      "epoch:16 step:15619 [D loss: 0.435611, acc.: 86.72%] [G loss: 1.502839]\n",
      "epoch:16 step:15620 [D loss: 0.558617, acc.: 71.88%] [G loss: 1.300198]\n",
      "epoch:16 step:15621 [D loss: 0.713355, acc.: 57.81%] [G loss: 1.074159]\n",
      "epoch:16 step:15622 [D loss: 0.645443, acc.: 60.94%] [G loss: 1.153068]\n",
      "epoch:16 step:15623 [D loss: 0.583640, acc.: 71.88%] [G loss: 1.174410]\n",
      "epoch:16 step:15624 [D loss: 0.580418, acc.: 77.34%] [G loss: 1.203071]\n",
      "epoch:16 step:15625 [D loss: 0.478171, acc.: 78.12%] [G loss: 1.540820]\n",
      "epoch:16 step:15626 [D loss: 0.588453, acc.: 71.09%] [G loss: 1.102534]\n",
      "epoch:16 step:15627 [D loss: 0.692712, acc.: 59.38%] [G loss: 1.234502]\n",
      "epoch:16 step:15628 [D loss: 0.597333, acc.: 67.97%] [G loss: 1.035318]\n",
      "epoch:16 step:15629 [D loss: 0.462937, acc.: 79.69%] [G loss: 1.530124]\n",
      "epoch:16 step:15630 [D loss: 0.581314, acc.: 69.53%] [G loss: 1.293604]\n",
      "epoch:16 step:15631 [D loss: 0.689375, acc.: 62.50%] [G loss: 1.239273]\n",
      "epoch:16 step:15632 [D loss: 0.587244, acc.: 71.88%] [G loss: 1.114245]\n",
      "epoch:16 step:15633 [D loss: 0.521856, acc.: 75.00%] [G loss: 1.302080]\n",
      "epoch:16 step:15634 [D loss: 0.555108, acc.: 69.53%] [G loss: 1.089476]\n",
      "epoch:16 step:15635 [D loss: 0.645565, acc.: 60.94%] [G loss: 1.120940]\n",
      "epoch:16 step:15636 [D loss: 0.684471, acc.: 57.81%] [G loss: 1.097848]\n",
      "epoch:16 step:15637 [D loss: 0.543532, acc.: 78.12%] [G loss: 1.054154]\n",
      "epoch:16 step:15638 [D loss: 0.730207, acc.: 55.47%] [G loss: 0.974835]\n",
      "epoch:16 step:15639 [D loss: 0.696636, acc.: 58.59%] [G loss: 1.051105]\n",
      "epoch:16 step:15640 [D loss: 0.569157, acc.: 67.97%] [G loss: 1.176672]\n",
      "epoch:16 step:15641 [D loss: 0.472727, acc.: 78.91%] [G loss: 1.343133]\n",
      "epoch:16 step:15642 [D loss: 0.553547, acc.: 71.88%] [G loss: 1.266262]\n",
      "epoch:16 step:15643 [D loss: 0.587671, acc.: 68.75%] [G loss: 1.425973]\n",
      "epoch:16 step:15644 [D loss: 0.581506, acc.: 68.75%] [G loss: 1.153896]\n",
      "epoch:16 step:15645 [D loss: 0.595826, acc.: 67.19%] [G loss: 1.389542]\n",
      "epoch:16 step:15646 [D loss: 0.488976, acc.: 78.91%] [G loss: 1.120248]\n",
      "epoch:16 step:15647 [D loss: 0.620280, acc.: 66.41%] [G loss: 1.175261]\n",
      "epoch:16 step:15648 [D loss: 0.552788, acc.: 76.56%] [G loss: 1.200549]\n",
      "epoch:16 step:15649 [D loss: 0.415898, acc.: 83.59%] [G loss: 1.539245]\n",
      "epoch:16 step:15650 [D loss: 0.799968, acc.: 46.88%] [G loss: 0.962117]\n",
      "epoch:16 step:15651 [D loss: 0.564370, acc.: 74.22%] [G loss: 1.041398]\n",
      "epoch:16 step:15652 [D loss: 0.598171, acc.: 67.97%] [G loss: 1.233133]\n",
      "epoch:16 step:15653 [D loss: 0.647898, acc.: 57.81%] [G loss: 1.317951]\n",
      "epoch:16 step:15654 [D loss: 0.816733, acc.: 45.31%] [G loss: 1.236616]\n",
      "epoch:16 step:15655 [D loss: 0.619655, acc.: 66.41%] [G loss: 1.138725]\n",
      "epoch:16 step:15656 [D loss: 0.522364, acc.: 72.66%] [G loss: 1.009731]\n",
      "epoch:16 step:15657 [D loss: 0.673783, acc.: 60.16%] [G loss: 1.114026]\n",
      "epoch:16 step:15658 [D loss: 0.544654, acc.: 74.22%] [G loss: 1.229726]\n",
      "epoch:16 step:15659 [D loss: 0.624492, acc.: 63.28%] [G loss: 1.631949]\n",
      "epoch:16 step:15660 [D loss: 0.647262, acc.: 61.72%] [G loss: 1.260646]\n",
      "epoch:16 step:15661 [D loss: 0.483176, acc.: 81.25%] [G loss: 1.318792]\n",
      "epoch:16 step:15662 [D loss: 0.533229, acc.: 73.44%] [G loss: 1.440989]\n",
      "epoch:16 step:15663 [D loss: 0.520059, acc.: 71.88%] [G loss: 1.164524]\n",
      "epoch:16 step:15664 [D loss: 0.535552, acc.: 69.53%] [G loss: 1.036480]\n",
      "epoch:16 step:15665 [D loss: 0.617606, acc.: 67.97%] [G loss: 1.299788]\n",
      "epoch:16 step:15666 [D loss: 0.534414, acc.: 71.09%] [G loss: 1.287260]\n",
      "epoch:16 step:15667 [D loss: 0.584109, acc.: 66.41%] [G loss: 1.149582]\n",
      "epoch:16 step:15668 [D loss: 0.642979, acc.: 63.28%] [G loss: 0.993413]\n",
      "epoch:16 step:15669 [D loss: 0.465613, acc.: 79.69%] [G loss: 1.241737]\n",
      "epoch:16 step:15670 [D loss: 0.605582, acc.: 64.84%] [G loss: 1.164771]\n",
      "epoch:16 step:15671 [D loss: 0.587871, acc.: 68.75%] [G loss: 1.138673]\n",
      "epoch:16 step:15672 [D loss: 0.552694, acc.: 71.09%] [G loss: 1.397013]\n",
      "epoch:16 step:15673 [D loss: 0.561104, acc.: 69.53%] [G loss: 1.146312]\n",
      "epoch:16 step:15674 [D loss: 0.510620, acc.: 78.91%] [G loss: 1.482864]\n",
      "epoch:16 step:15675 [D loss: 0.788721, acc.: 52.34%] [G loss: 1.016980]\n",
      "epoch:16 step:15676 [D loss: 0.605960, acc.: 67.19%] [G loss: 1.231498]\n",
      "epoch:16 step:15677 [D loss: 0.609063, acc.: 68.75%] [G loss: 1.157515]\n",
      "epoch:16 step:15678 [D loss: 0.452505, acc.: 83.59%] [G loss: 1.565444]\n",
      "epoch:16 step:15679 [D loss: 0.533100, acc.: 72.66%] [G loss: 1.428787]\n",
      "epoch:16 step:15680 [D loss: 0.640465, acc.: 64.84%] [G loss: 1.452199]\n",
      "epoch:16 step:15681 [D loss: 0.593235, acc.: 72.66%] [G loss: 1.342438]\n",
      "epoch:16 step:15682 [D loss: 0.549497, acc.: 75.00%] [G loss: 1.289503]\n",
      "epoch:16 step:15683 [D loss: 0.779801, acc.: 53.91%] [G loss: 1.334302]\n",
      "epoch:16 step:15684 [D loss: 0.578709, acc.: 67.19%] [G loss: 1.076995]\n",
      "epoch:16 step:15685 [D loss: 0.604426, acc.: 67.97%] [G loss: 1.408821]\n",
      "epoch:16 step:15686 [D loss: 0.549791, acc.: 71.09%] [G loss: 1.377516]\n",
      "epoch:16 step:15687 [D loss: 0.525904, acc.: 76.56%] [G loss: 1.375421]\n",
      "epoch:16 step:15688 [D loss: 0.606963, acc.: 62.50%] [G loss: 1.272586]\n",
      "epoch:16 step:15689 [D loss: 0.580768, acc.: 74.22%] [G loss: 1.138906]\n",
      "epoch:16 step:15690 [D loss: 0.520751, acc.: 74.22%] [G loss: 1.390458]\n",
      "epoch:16 step:15691 [D loss: 0.542214, acc.: 72.66%] [G loss: 1.162504]\n",
      "epoch:16 step:15692 [D loss: 0.576387, acc.: 67.97%] [G loss: 0.987149]\n",
      "epoch:16 step:15693 [D loss: 0.407219, acc.: 83.59%] [G loss: 1.560067]\n",
      "epoch:16 step:15694 [D loss: 0.462636, acc.: 77.34%] [G loss: 1.336186]\n",
      "epoch:16 step:15695 [D loss: 0.806754, acc.: 50.00%] [G loss: 1.428111]\n",
      "epoch:16 step:15696 [D loss: 0.738669, acc.: 50.78%] [G loss: 1.248989]\n",
      "epoch:16 step:15697 [D loss: 0.555185, acc.: 69.53%] [G loss: 1.278528]\n",
      "epoch:16 step:15698 [D loss: 0.503445, acc.: 73.44%] [G loss: 1.402574]\n",
      "epoch:16 step:15699 [D loss: 0.477085, acc.: 84.38%] [G loss: 1.203486]\n",
      "epoch:16 step:15700 [D loss: 0.599608, acc.: 67.97%] [G loss: 1.361130]\n",
      "epoch:16 step:15701 [D loss: 0.758381, acc.: 54.69%] [G loss: 1.523766]\n",
      "epoch:16 step:15702 [D loss: 0.546512, acc.: 75.00%] [G loss: 1.214306]\n",
      "epoch:16 step:15703 [D loss: 0.534168, acc.: 73.44%] [G loss: 1.284159]\n",
      "epoch:16 step:15704 [D loss: 0.600099, acc.: 74.22%] [G loss: 1.249853]\n",
      "epoch:16 step:15705 [D loss: 0.600169, acc.: 70.31%] [G loss: 1.217355]\n",
      "epoch:16 step:15706 [D loss: 0.572852, acc.: 72.66%] [G loss: 1.017503]\n",
      "epoch:16 step:15707 [D loss: 0.648843, acc.: 60.94%] [G loss: 1.204445]\n",
      "epoch:16 step:15708 [D loss: 0.508398, acc.: 76.56%] [G loss: 1.403700]\n",
      "epoch:16 step:15709 [D loss: 0.515196, acc.: 75.00%] [G loss: 1.301344]\n",
      "epoch:16 step:15710 [D loss: 0.374933, acc.: 89.84%] [G loss: 1.368915]\n",
      "epoch:16 step:15711 [D loss: 0.634385, acc.: 65.62%] [G loss: 1.541737]\n",
      "epoch:16 step:15712 [D loss: 0.541840, acc.: 73.44%] [G loss: 1.302141]\n",
      "epoch:16 step:15713 [D loss: 0.681123, acc.: 53.12%] [G loss: 1.051748]\n",
      "epoch:16 step:15714 [D loss: 0.565061, acc.: 70.31%] [G loss: 1.091201]\n",
      "epoch:16 step:15715 [D loss: 0.429908, acc.: 88.28%] [G loss: 1.108109]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:16 step:15716 [D loss: 0.632469, acc.: 59.38%] [G loss: 1.161501]\n",
      "epoch:16 step:15717 [D loss: 0.631247, acc.: 62.50%] [G loss: 1.114760]\n",
      "epoch:16 step:15718 [D loss: 0.566619, acc.: 72.66%] [G loss: 1.306852]\n",
      "epoch:16 step:15719 [D loss: 0.554202, acc.: 71.88%] [G loss: 1.451435]\n",
      "epoch:16 step:15720 [D loss: 0.644776, acc.: 59.38%] [G loss: 1.146148]\n",
      "epoch:16 step:15721 [D loss: 0.579755, acc.: 71.09%] [G loss: 1.134097]\n",
      "epoch:16 step:15722 [D loss: 0.648958, acc.: 64.06%] [G loss: 1.031512]\n",
      "epoch:16 step:15723 [D loss: 0.574167, acc.: 71.88%] [G loss: 1.109559]\n",
      "epoch:16 step:15724 [D loss: 0.492298, acc.: 75.78%] [G loss: 1.273794]\n",
      "epoch:16 step:15725 [D loss: 0.490023, acc.: 75.78%] [G loss: 1.441758]\n",
      "epoch:16 step:15726 [D loss: 0.653055, acc.: 59.38%] [G loss: 1.134046]\n",
      "epoch:16 step:15727 [D loss: 0.560171, acc.: 71.09%] [G loss: 1.428755]\n",
      "epoch:16 step:15728 [D loss: 0.587102, acc.: 68.75%] [G loss: 1.363877]\n",
      "epoch:16 step:15729 [D loss: 0.570764, acc.: 67.97%] [G loss: 1.321248]\n",
      "epoch:16 step:15730 [D loss: 0.786801, acc.: 50.00%] [G loss: 1.054054]\n",
      "epoch:16 step:15731 [D loss: 0.550117, acc.: 78.12%] [G loss: 1.681237]\n",
      "epoch:16 step:15732 [D loss: 0.619074, acc.: 64.06%] [G loss: 1.083585]\n",
      "epoch:16 step:15733 [D loss: 0.681014, acc.: 64.06%] [G loss: 0.972336]\n",
      "epoch:16 step:15734 [D loss: 0.618611, acc.: 64.84%] [G loss: 0.996103]\n",
      "epoch:16 step:15735 [D loss: 0.549257, acc.: 75.78%] [G loss: 1.169285]\n",
      "epoch:16 step:15736 [D loss: 0.582753, acc.: 71.88%] [G loss: 1.023574]\n",
      "epoch:16 step:15737 [D loss: 0.532513, acc.: 75.00%] [G loss: 1.221828]\n",
      "epoch:16 step:15738 [D loss: 0.595443, acc.: 71.09%] [G loss: 1.427601]\n",
      "epoch:16 step:15739 [D loss: 0.374984, acc.: 87.50%] [G loss: 1.291705]\n",
      "epoch:16 step:15740 [D loss: 0.601908, acc.: 68.75%] [G loss: 1.335621]\n",
      "epoch:16 step:15741 [D loss: 0.694389, acc.: 57.81%] [G loss: 1.322771]\n",
      "epoch:16 step:15742 [D loss: 0.771704, acc.: 53.12%] [G loss: 1.048043]\n",
      "epoch:16 step:15743 [D loss: 0.593785, acc.: 64.06%] [G loss: 1.432406]\n",
      "epoch:16 step:15744 [D loss: 0.582285, acc.: 67.19%] [G loss: 1.133376]\n",
      "epoch:16 step:15745 [D loss: 0.581342, acc.: 67.97%] [G loss: 1.105128]\n",
      "epoch:16 step:15746 [D loss: 0.543961, acc.: 71.09%] [G loss: 1.311010]\n",
      "epoch:16 step:15747 [D loss: 0.476786, acc.: 77.34%] [G loss: 1.520225]\n",
      "epoch:16 step:15748 [D loss: 0.431076, acc.: 81.25%] [G loss: 1.236111]\n",
      "epoch:16 step:15749 [D loss: 0.593678, acc.: 73.44%] [G loss: 1.208445]\n",
      "epoch:16 step:15750 [D loss: 0.573682, acc.: 68.75%] [G loss: 1.324405]\n",
      "epoch:16 step:15751 [D loss: 0.463373, acc.: 82.03%] [G loss: 1.364476]\n",
      "epoch:16 step:15752 [D loss: 0.519159, acc.: 74.22%] [G loss: 1.195106]\n",
      "epoch:16 step:15753 [D loss: 0.586007, acc.: 70.31%] [G loss: 1.183554]\n",
      "epoch:16 step:15754 [D loss: 0.691991, acc.: 66.41%] [G loss: 1.162789]\n",
      "epoch:16 step:15755 [D loss: 0.645408, acc.: 59.38%] [G loss: 1.495652]\n",
      "epoch:16 step:15756 [D loss: 0.526560, acc.: 73.44%] [G loss: 1.371707]\n",
      "epoch:16 step:15757 [D loss: 0.531392, acc.: 71.88%] [G loss: 1.493959]\n",
      "epoch:16 step:15758 [D loss: 0.557728, acc.: 73.44%] [G loss: 1.418439]\n",
      "epoch:16 step:15759 [D loss: 0.525650, acc.: 76.56%] [G loss: 1.337577]\n",
      "epoch:16 step:15760 [D loss: 0.588992, acc.: 66.41%] [G loss: 1.345680]\n",
      "epoch:16 step:15761 [D loss: 0.609147, acc.: 64.84%] [G loss: 1.063621]\n",
      "epoch:16 step:15762 [D loss: 0.642296, acc.: 69.53%] [G loss: 1.084295]\n",
      "epoch:16 step:15763 [D loss: 0.432270, acc.: 90.62%] [G loss: 1.338619]\n",
      "epoch:16 step:15764 [D loss: 0.597877, acc.: 64.84%] [G loss: 1.279578]\n",
      "epoch:16 step:15765 [D loss: 0.534532, acc.: 76.56%] [G loss: 1.192309]\n",
      "epoch:16 step:15766 [D loss: 0.531648, acc.: 76.56%] [G loss: 0.941084]\n",
      "epoch:16 step:15767 [D loss: 0.580037, acc.: 71.09%] [G loss: 1.061180]\n",
      "epoch:16 step:15768 [D loss: 0.450266, acc.: 82.03%] [G loss: 1.425899]\n",
      "epoch:16 step:15769 [D loss: 0.697821, acc.: 60.94%] [G loss: 1.064084]\n",
      "epoch:16 step:15770 [D loss: 0.520877, acc.: 76.56%] [G loss: 1.181938]\n",
      "epoch:16 step:15771 [D loss: 0.532522, acc.: 75.00%] [G loss: 1.431602]\n",
      "epoch:16 step:15772 [D loss: 0.601361, acc.: 70.31%] [G loss: 1.086641]\n",
      "epoch:16 step:15773 [D loss: 0.757833, acc.: 53.91%] [G loss: 0.943012]\n",
      "epoch:16 step:15774 [D loss: 0.427881, acc.: 85.94%] [G loss: 1.443279]\n",
      "epoch:16 step:15775 [D loss: 0.559423, acc.: 73.44%] [G loss: 1.023995]\n",
      "epoch:16 step:15776 [D loss: 0.458163, acc.: 76.56%] [G loss: 1.543736]\n",
      "epoch:16 step:15777 [D loss: 0.394345, acc.: 84.38%] [G loss: 1.804826]\n",
      "epoch:16 step:15778 [D loss: 0.697774, acc.: 58.59%] [G loss: 1.139624]\n",
      "epoch:16 step:15779 [D loss: 0.536289, acc.: 77.34%] [G loss: 1.464590]\n",
      "epoch:16 step:15780 [D loss: 0.554005, acc.: 71.09%] [G loss: 1.330651]\n",
      "epoch:16 step:15781 [D loss: 0.501387, acc.: 81.25%] [G loss: 1.260554]\n",
      "epoch:16 step:15782 [D loss: 0.543362, acc.: 75.00%] [G loss: 1.264582]\n",
      "epoch:16 step:15783 [D loss: 0.605070, acc.: 67.19%] [G loss: 1.227030]\n",
      "epoch:16 step:15784 [D loss: 0.585974, acc.: 67.19%] [G loss: 1.425260]\n",
      "epoch:16 step:15785 [D loss: 0.607020, acc.: 71.88%] [G loss: 1.375654]\n",
      "epoch:16 step:15786 [D loss: 0.573336, acc.: 68.75%] [G loss: 1.194109]\n",
      "epoch:16 step:15787 [D loss: 0.397896, acc.: 86.72%] [G loss: 1.552417]\n",
      "epoch:16 step:15788 [D loss: 0.541386, acc.: 70.31%] [G loss: 1.426312]\n",
      "epoch:16 step:15789 [D loss: 0.465303, acc.: 81.25%] [G loss: 1.329401]\n",
      "epoch:16 step:15790 [D loss: 0.530246, acc.: 71.88%] [G loss: 1.272700]\n",
      "epoch:16 step:15791 [D loss: 0.538274, acc.: 71.88%] [G loss: 0.895880]\n",
      "epoch:16 step:15792 [D loss: 0.565613, acc.: 71.09%] [G loss: 1.504898]\n",
      "epoch:16 step:15793 [D loss: 0.556365, acc.: 74.22%] [G loss: 0.982412]\n",
      "epoch:16 step:15794 [D loss: 0.655691, acc.: 60.94%] [G loss: 1.119613]\n",
      "epoch:16 step:15795 [D loss: 0.546444, acc.: 73.44%] [G loss: 1.247089]\n",
      "epoch:16 step:15796 [D loss: 0.487307, acc.: 78.91%] [G loss: 1.192496]\n",
      "epoch:16 step:15797 [D loss: 0.572092, acc.: 73.44%] [G loss: 0.897189]\n",
      "epoch:16 step:15798 [D loss: 0.493364, acc.: 79.69%] [G loss: 1.288000]\n",
      "epoch:16 step:15799 [D loss: 0.641364, acc.: 59.38%] [G loss: 1.326153]\n",
      "epoch:16 step:15800 [D loss: 0.506017, acc.: 72.66%] [G loss: 1.130919]\n",
      "epoch:16 step:15801 [D loss: 0.649585, acc.: 65.62%] [G loss: 1.143864]\n",
      "epoch:16 step:15802 [D loss: 0.534727, acc.: 71.88%] [G loss: 1.450269]\n",
      "epoch:16 step:15803 [D loss: 0.621314, acc.: 64.84%] [G loss: 1.336257]\n",
      "epoch:16 step:15804 [D loss: 0.514940, acc.: 75.78%] [G loss: 1.154409]\n",
      "epoch:16 step:15805 [D loss: 0.524973, acc.: 74.22%] [G loss: 1.346323]\n",
      "epoch:16 step:15806 [D loss: 0.495129, acc.: 79.69%] [G loss: 1.132520]\n",
      "epoch:16 step:15807 [D loss: 0.568259, acc.: 68.75%] [G loss: 1.015158]\n",
      "epoch:16 step:15808 [D loss: 0.462003, acc.: 78.12%] [G loss: 1.198794]\n",
      "epoch:16 step:15809 [D loss: 0.550437, acc.: 72.66%] [G loss: 1.364854]\n",
      "epoch:16 step:15810 [D loss: 0.529800, acc.: 77.34%] [G loss: 1.136940]\n",
      "epoch:16 step:15811 [D loss: 0.682190, acc.: 57.03%] [G loss: 1.045126]\n",
      "epoch:16 step:15812 [D loss: 0.608406, acc.: 64.06%] [G loss: 1.072241]\n",
      "epoch:16 step:15813 [D loss: 0.737053, acc.: 53.91%] [G loss: 1.010434]\n",
      "epoch:16 step:15814 [D loss: 0.751422, acc.: 53.12%] [G loss: 1.231670]\n",
      "epoch:16 step:15815 [D loss: 0.614256, acc.: 66.41%] [G loss: 1.393203]\n",
      "epoch:16 step:15816 [D loss: 0.630570, acc.: 60.16%] [G loss: 1.224185]\n",
      "epoch:16 step:15817 [D loss: 0.575026, acc.: 71.09%] [G loss: 1.246501]\n",
      "epoch:16 step:15818 [D loss: 0.592678, acc.: 63.28%] [G loss: 1.435841]\n",
      "epoch:16 step:15819 [D loss: 0.622300, acc.: 68.75%] [G loss: 1.137881]\n",
      "epoch:16 step:15820 [D loss: 0.524460, acc.: 78.91%] [G loss: 1.411358]\n",
      "epoch:16 step:15821 [D loss: 0.649839, acc.: 67.97%] [G loss: 1.435067]\n",
      "epoch:16 step:15822 [D loss: 0.648582, acc.: 62.50%] [G loss: 1.207349]\n",
      "epoch:16 step:15823 [D loss: 0.619192, acc.: 65.62%] [G loss: 1.352824]\n",
      "epoch:16 step:15824 [D loss: 0.628963, acc.: 64.06%] [G loss: 1.413591]\n",
      "epoch:16 step:15825 [D loss: 0.712009, acc.: 60.94%] [G loss: 1.318460]\n",
      "epoch:16 step:15826 [D loss: 0.580233, acc.: 71.09%] [G loss: 1.185022]\n",
      "epoch:16 step:15827 [D loss: 0.468668, acc.: 79.69%] [G loss: 1.280827]\n",
      "epoch:16 step:15828 [D loss: 0.661222, acc.: 64.06%] [G loss: 1.096252]\n",
      "epoch:16 step:15829 [D loss: 0.542696, acc.: 74.22%] [G loss: 1.437486]\n",
      "epoch:16 step:15830 [D loss: 0.439170, acc.: 83.59%] [G loss: 1.171996]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:16 step:15831 [D loss: 0.533003, acc.: 71.09%] [G loss: 1.390309]\n",
      "epoch:16 step:15832 [D loss: 0.652797, acc.: 67.19%] [G loss: 1.404109]\n",
      "epoch:16 step:15833 [D loss: 0.665341, acc.: 63.28%] [G loss: 1.370057]\n",
      "epoch:16 step:15834 [D loss: 0.580865, acc.: 71.09%] [G loss: 1.245641]\n",
      "epoch:16 step:15835 [D loss: 0.546288, acc.: 71.09%] [G loss: 1.418351]\n",
      "epoch:16 step:15836 [D loss: 0.662315, acc.: 57.03%] [G loss: 1.428915]\n",
      "epoch:16 step:15837 [D loss: 0.603161, acc.: 71.09%] [G loss: 1.294004]\n",
      "epoch:16 step:15838 [D loss: 0.432738, acc.: 84.38%] [G loss: 1.246381]\n",
      "epoch:16 step:15839 [D loss: 0.586914, acc.: 68.75%] [G loss: 1.128926]\n",
      "epoch:16 step:15840 [D loss: 0.726670, acc.: 56.25%] [G loss: 1.059304]\n",
      "epoch:16 step:15841 [D loss: 0.464766, acc.: 81.25%] [G loss: 1.329485]\n",
      "epoch:16 step:15842 [D loss: 0.470842, acc.: 79.69%] [G loss: 1.382386]\n",
      "epoch:16 step:15843 [D loss: 0.592482, acc.: 64.84%] [G loss: 1.160087]\n",
      "epoch:16 step:15844 [D loss: 0.578696, acc.: 71.09%] [G loss: 1.059592]\n",
      "epoch:16 step:15845 [D loss: 0.627017, acc.: 62.50%] [G loss: 1.026900]\n",
      "epoch:16 step:15846 [D loss: 0.606203, acc.: 67.97%] [G loss: 0.984927]\n",
      "epoch:16 step:15847 [D loss: 0.628913, acc.: 66.41%] [G loss: 1.349605]\n",
      "epoch:16 step:15848 [D loss: 0.555524, acc.: 77.34%] [G loss: 1.363940]\n",
      "epoch:16 step:15849 [D loss: 0.674471, acc.: 57.81%] [G loss: 1.204858]\n",
      "epoch:16 step:15850 [D loss: 0.479141, acc.: 80.47%] [G loss: 1.624247]\n",
      "epoch:16 step:15851 [D loss: 0.471298, acc.: 76.56%] [G loss: 1.407831]\n",
      "epoch:16 step:15852 [D loss: 0.653242, acc.: 64.84%] [G loss: 1.220762]\n",
      "epoch:16 step:15853 [D loss: 0.503517, acc.: 75.78%] [G loss: 1.282275]\n",
      "epoch:16 step:15854 [D loss: 0.683025, acc.: 61.72%] [G loss: 1.454006]\n",
      "epoch:16 step:15855 [D loss: 0.601724, acc.: 70.31%] [G loss: 0.956520]\n",
      "epoch:16 step:15856 [D loss: 0.687765, acc.: 62.50%] [G loss: 1.091180]\n",
      "epoch:16 step:15857 [D loss: 0.605778, acc.: 68.75%] [G loss: 1.445695]\n",
      "epoch:16 step:15858 [D loss: 0.493397, acc.: 78.12%] [G loss: 1.367062]\n",
      "epoch:16 step:15859 [D loss: 0.757041, acc.: 53.91%] [G loss: 1.153852]\n",
      "epoch:16 step:15860 [D loss: 0.609028, acc.: 68.75%] [G loss: 1.357546]\n",
      "epoch:16 step:15861 [D loss: 0.426284, acc.: 85.94%] [G loss: 1.481686]\n",
      "epoch:16 step:15862 [D loss: 0.579101, acc.: 72.66%] [G loss: 1.184106]\n",
      "epoch:16 step:15863 [D loss: 0.576165, acc.: 68.75%] [G loss: 1.524626]\n",
      "epoch:16 step:15864 [D loss: 0.665922, acc.: 60.16%] [G loss: 1.162735]\n",
      "epoch:16 step:15865 [D loss: 0.479916, acc.: 78.12%] [G loss: 1.246519]\n",
      "epoch:16 step:15866 [D loss: 0.496315, acc.: 75.78%] [G loss: 1.398273]\n",
      "epoch:16 step:15867 [D loss: 0.535623, acc.: 71.09%] [G loss: 1.309218]\n",
      "epoch:16 step:15868 [D loss: 0.695893, acc.: 54.69%] [G loss: 1.143424]\n",
      "epoch:16 step:15869 [D loss: 0.644654, acc.: 64.84%] [G loss: 1.111897]\n",
      "epoch:16 step:15870 [D loss: 0.724810, acc.: 53.91%] [G loss: 1.215393]\n",
      "epoch:16 step:15871 [D loss: 0.589869, acc.: 68.75%] [G loss: 1.147417]\n",
      "epoch:16 step:15872 [D loss: 0.689665, acc.: 61.72%] [G loss: 1.086464]\n",
      "epoch:16 step:15873 [D loss: 0.660025, acc.: 61.72%] [G loss: 1.113603]\n",
      "epoch:16 step:15874 [D loss: 0.495065, acc.: 76.56%] [G loss: 1.566721]\n",
      "epoch:16 step:15875 [D loss: 0.701274, acc.: 58.59%] [G loss: 1.470197]\n",
      "epoch:16 step:15876 [D loss: 0.586895, acc.: 68.75%] [G loss: 1.159755]\n",
      "epoch:16 step:15877 [D loss: 0.689526, acc.: 60.94%] [G loss: 1.437096]\n",
      "epoch:16 step:15878 [D loss: 0.602302, acc.: 64.84%] [G loss: 1.058420]\n",
      "epoch:16 step:15879 [D loss: 0.585447, acc.: 70.31%] [G loss: 0.946139]\n",
      "epoch:16 step:15880 [D loss: 0.563141, acc.: 73.44%] [G loss: 1.365827]\n",
      "epoch:16 step:15881 [D loss: 0.692626, acc.: 59.38%] [G loss: 1.179674]\n",
      "epoch:16 step:15882 [D loss: 0.522990, acc.: 74.22%] [G loss: 1.209132]\n",
      "epoch:16 step:15883 [D loss: 0.647356, acc.: 67.19%] [G loss: 1.458769]\n",
      "epoch:16 step:15884 [D loss: 0.507240, acc.: 73.44%] [G loss: 1.414222]\n",
      "epoch:16 step:15885 [D loss: 0.638367, acc.: 67.19%] [G loss: 1.404847]\n",
      "epoch:16 step:15886 [D loss: 0.555942, acc.: 75.00%] [G loss: 1.115676]\n",
      "epoch:16 step:15887 [D loss: 0.343270, acc.: 90.62%] [G loss: 1.407012]\n",
      "epoch:16 step:15888 [D loss: 0.640930, acc.: 59.38%] [G loss: 0.938945]\n",
      "epoch:16 step:15889 [D loss: 0.608035, acc.: 69.53%] [G loss: 1.367903]\n",
      "epoch:16 step:15890 [D loss: 0.627413, acc.: 66.41%] [G loss: 1.154908]\n",
      "epoch:16 step:15891 [D loss: 0.589139, acc.: 67.19%] [G loss: 1.319456]\n",
      "epoch:16 step:15892 [D loss: 0.496736, acc.: 75.78%] [G loss: 1.252281]\n",
      "epoch:16 step:15893 [D loss: 0.588700, acc.: 64.06%] [G loss: 1.037337]\n",
      "epoch:16 step:15894 [D loss: 0.508305, acc.: 75.00%] [G loss: 1.353813]\n",
      "epoch:16 step:15895 [D loss: 0.692099, acc.: 57.81%] [G loss: 1.236424]\n",
      "epoch:16 step:15896 [D loss: 0.491779, acc.: 76.56%] [G loss: 1.205482]\n",
      "epoch:16 step:15897 [D loss: 0.687044, acc.: 60.16%] [G loss: 1.149336]\n",
      "epoch:16 step:15898 [D loss: 0.608019, acc.: 66.41%] [G loss: 1.205169]\n",
      "epoch:16 step:15899 [D loss: 0.514682, acc.: 76.56%] [G loss: 1.424019]\n",
      "epoch:16 step:15900 [D loss: 0.629144, acc.: 60.94%] [G loss: 1.103162]\n",
      "epoch:16 step:15901 [D loss: 0.565889, acc.: 69.53%] [G loss: 1.345053]\n",
      "epoch:16 step:15902 [D loss: 0.524242, acc.: 72.66%] [G loss: 1.444182]\n",
      "epoch:16 step:15903 [D loss: 0.521762, acc.: 75.78%] [G loss: 1.622411]\n",
      "epoch:16 step:15904 [D loss: 0.631357, acc.: 71.88%] [G loss: 1.318463]\n",
      "epoch:16 step:15905 [D loss: 0.523749, acc.: 78.12%] [G loss: 0.890800]\n",
      "epoch:16 step:15906 [D loss: 0.652233, acc.: 64.06%] [G loss: 1.300623]\n",
      "epoch:16 step:15907 [D loss: 0.531443, acc.: 74.22%] [G loss: 1.485080]\n",
      "epoch:16 step:15908 [D loss: 0.596701, acc.: 65.62%] [G loss: 1.340562]\n",
      "epoch:16 step:15909 [D loss: 0.543204, acc.: 72.66%] [G loss: 1.151667]\n",
      "epoch:16 step:15910 [D loss: 0.519163, acc.: 73.44%] [G loss: 1.289553]\n",
      "epoch:16 step:15911 [D loss: 0.496057, acc.: 82.81%] [G loss: 1.154718]\n",
      "epoch:16 step:15912 [D loss: 0.653312, acc.: 63.28%] [G loss: 1.262682]\n",
      "epoch:16 step:15913 [D loss: 0.648284, acc.: 65.62%] [G loss: 1.235007]\n",
      "epoch:16 step:15914 [D loss: 0.638812, acc.: 69.53%] [G loss: 1.283093]\n",
      "epoch:16 step:15915 [D loss: 0.647642, acc.: 60.94%] [G loss: 0.975330]\n",
      "epoch:16 step:15916 [D loss: 0.479467, acc.: 79.69%] [G loss: 1.350444]\n",
      "epoch:16 step:15917 [D loss: 0.566579, acc.: 71.09%] [G loss: 0.949908]\n",
      "epoch:16 step:15918 [D loss: 0.579940, acc.: 67.97%] [G loss: 1.451538]\n",
      "epoch:16 step:15919 [D loss: 0.588177, acc.: 68.75%] [G loss: 1.101958]\n",
      "epoch:16 step:15920 [D loss: 0.436250, acc.: 80.47%] [G loss: 1.517507]\n",
      "epoch:16 step:15921 [D loss: 0.724601, acc.: 56.25%] [G loss: 1.256888]\n",
      "epoch:16 step:15922 [D loss: 0.554617, acc.: 72.66%] [G loss: 1.132684]\n",
      "epoch:16 step:15923 [D loss: 0.605514, acc.: 67.19%] [G loss: 1.427346]\n",
      "epoch:16 step:15924 [D loss: 0.462181, acc.: 78.91%] [G loss: 0.927082]\n",
      "epoch:16 step:15925 [D loss: 0.568960, acc.: 68.75%] [G loss: 1.161691]\n",
      "epoch:16 step:15926 [D loss: 0.662344, acc.: 60.94%] [G loss: 1.342847]\n",
      "epoch:16 step:15927 [D loss: 0.539469, acc.: 72.66%] [G loss: 1.241090]\n",
      "epoch:16 step:15928 [D loss: 0.545932, acc.: 74.22%] [G loss: 1.467554]\n",
      "epoch:16 step:15929 [D loss: 0.636104, acc.: 67.97%] [G loss: 1.298768]\n",
      "epoch:17 step:15930 [D loss: 0.561955, acc.: 69.53%] [G loss: 0.874804]\n",
      "epoch:17 step:15931 [D loss: 0.674201, acc.: 64.06%] [G loss: 0.940422]\n",
      "epoch:17 step:15932 [D loss: 0.607449, acc.: 64.84%] [G loss: 0.806566]\n",
      "epoch:17 step:15933 [D loss: 0.597739, acc.: 67.97%] [G loss: 0.986976]\n",
      "epoch:17 step:15934 [D loss: 0.539032, acc.: 77.34%] [G loss: 1.339339]\n",
      "epoch:17 step:15935 [D loss: 0.569367, acc.: 67.19%] [G loss: 1.350554]\n",
      "epoch:17 step:15936 [D loss: 0.744239, acc.: 54.69%] [G loss: 1.288194]\n",
      "epoch:17 step:15937 [D loss: 0.573428, acc.: 71.88%] [G loss: 0.997854]\n",
      "epoch:17 step:15938 [D loss: 0.584717, acc.: 66.41%] [G loss: 1.260415]\n",
      "epoch:17 step:15939 [D loss: 0.578031, acc.: 67.19%] [G loss: 1.378245]\n",
      "epoch:17 step:15940 [D loss: 0.487020, acc.: 77.34%] [G loss: 1.260956]\n",
      "epoch:17 step:15941 [D loss: 0.536997, acc.: 72.66%] [G loss: 1.438811]\n",
      "epoch:17 step:15942 [D loss: 0.537266, acc.: 75.78%] [G loss: 1.308539]\n",
      "epoch:17 step:15943 [D loss: 0.584965, acc.: 69.53%] [G loss: 1.226701]\n",
      "epoch:17 step:15944 [D loss: 0.439788, acc.: 80.47%] [G loss: 1.434094]\n",
      "epoch:17 step:15945 [D loss: 0.514012, acc.: 75.78%] [G loss: 1.326762]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:17 step:15946 [D loss: 0.527763, acc.: 70.31%] [G loss: 1.384615]\n",
      "epoch:17 step:15947 [D loss: 0.685800, acc.: 59.38%] [G loss: 1.194722]\n",
      "epoch:17 step:15948 [D loss: 0.620235, acc.: 64.84%] [G loss: 1.141689]\n",
      "epoch:17 step:15949 [D loss: 0.578440, acc.: 65.62%] [G loss: 1.410533]\n",
      "epoch:17 step:15950 [D loss: 0.652971, acc.: 61.72%] [G loss: 1.049808]\n",
      "epoch:17 step:15951 [D loss: 0.527722, acc.: 70.31%] [G loss: 1.328125]\n",
      "epoch:17 step:15952 [D loss: 0.604415, acc.: 67.19%] [G loss: 1.312120]\n",
      "epoch:17 step:15953 [D loss: 0.598928, acc.: 71.09%] [G loss: 1.320774]\n",
      "epoch:17 step:15954 [D loss: 0.601410, acc.: 67.97%] [G loss: 1.233828]\n",
      "epoch:17 step:15955 [D loss: 0.441872, acc.: 82.03%] [G loss: 1.205081]\n",
      "epoch:17 step:15956 [D loss: 0.583422, acc.: 68.75%] [G loss: 1.422076]\n",
      "epoch:17 step:15957 [D loss: 0.708470, acc.: 52.34%] [G loss: 1.107533]\n",
      "epoch:17 step:15958 [D loss: 0.594352, acc.: 68.75%] [G loss: 1.049613]\n",
      "epoch:17 step:15959 [D loss: 0.543095, acc.: 71.88%] [G loss: 1.138361]\n",
      "epoch:17 step:15960 [D loss: 0.698358, acc.: 59.38%] [G loss: 1.025495]\n",
      "epoch:17 step:15961 [D loss: 0.610197, acc.: 66.41%] [G loss: 1.125566]\n",
      "epoch:17 step:15962 [D loss: 0.576400, acc.: 69.53%] [G loss: 1.209726]\n",
      "epoch:17 step:15963 [D loss: 0.603427, acc.: 67.19%] [G loss: 1.449365]\n",
      "epoch:17 step:15964 [D loss: 0.508549, acc.: 73.44%] [G loss: 1.366302]\n",
      "epoch:17 step:15965 [D loss: 0.498493, acc.: 73.44%] [G loss: 1.480707]\n",
      "epoch:17 step:15966 [D loss: 0.602041, acc.: 69.53%] [G loss: 1.297144]\n",
      "epoch:17 step:15967 [D loss: 0.523428, acc.: 75.78%] [G loss: 1.303157]\n",
      "epoch:17 step:15968 [D loss: 0.677209, acc.: 64.06%] [G loss: 1.579348]\n",
      "epoch:17 step:15969 [D loss: 0.625941, acc.: 67.19%] [G loss: 0.996799]\n",
      "epoch:17 step:15970 [D loss: 0.494454, acc.: 78.91%] [G loss: 1.348772]\n",
      "epoch:17 step:15971 [D loss: 0.523655, acc.: 77.34%] [G loss: 1.635429]\n",
      "epoch:17 step:15972 [D loss: 0.570793, acc.: 67.97%] [G loss: 1.425555]\n",
      "epoch:17 step:15973 [D loss: 0.560756, acc.: 69.53%] [G loss: 1.280350]\n",
      "epoch:17 step:15974 [D loss: 0.482732, acc.: 78.12%] [G loss: 1.124110]\n",
      "epoch:17 step:15975 [D loss: 0.689850, acc.: 60.16%] [G loss: 1.021136]\n",
      "epoch:17 step:15976 [D loss: 0.698295, acc.: 55.47%] [G loss: 1.186255]\n",
      "epoch:17 step:15977 [D loss: 0.651040, acc.: 59.38%] [G loss: 1.350761]\n",
      "epoch:17 step:15978 [D loss: 0.595257, acc.: 67.97%] [G loss: 1.388031]\n",
      "epoch:17 step:15979 [D loss: 0.585276, acc.: 68.75%] [G loss: 1.318596]\n",
      "epoch:17 step:15980 [D loss: 0.628195, acc.: 66.41%] [G loss: 1.446791]\n",
      "epoch:17 step:15981 [D loss: 0.639060, acc.: 62.50%] [G loss: 1.231923]\n",
      "epoch:17 step:15982 [D loss: 0.540199, acc.: 72.66%] [G loss: 1.619495]\n",
      "epoch:17 step:15983 [D loss: 0.506195, acc.: 76.56%] [G loss: 1.309912]\n",
      "epoch:17 step:15984 [D loss: 0.662173, acc.: 57.81%] [G loss: 1.317490]\n",
      "epoch:17 step:15985 [D loss: 0.557940, acc.: 75.78%] [G loss: 1.518786]\n",
      "epoch:17 step:15986 [D loss: 0.577746, acc.: 63.28%] [G loss: 1.382845]\n",
      "epoch:17 step:15987 [D loss: 0.656427, acc.: 60.16%] [G loss: 1.216498]\n",
      "epoch:17 step:15988 [D loss: 0.485434, acc.: 75.78%] [G loss: 1.168832]\n",
      "epoch:17 step:15989 [D loss: 0.501112, acc.: 82.03%] [G loss: 1.471857]\n",
      "epoch:17 step:15990 [D loss: 0.613510, acc.: 67.97%] [G loss: 1.145014]\n",
      "epoch:17 step:15991 [D loss: 0.550965, acc.: 72.66%] [G loss: 1.314773]\n",
      "epoch:17 step:15992 [D loss: 0.675334, acc.: 53.91%] [G loss: 0.966899]\n",
      "epoch:17 step:15993 [D loss: 0.511434, acc.: 75.00%] [G loss: 1.431413]\n",
      "epoch:17 step:15994 [D loss: 0.434225, acc.: 84.38%] [G loss: 1.563462]\n",
      "epoch:17 step:15995 [D loss: 0.724584, acc.: 52.34%] [G loss: 1.085054]\n",
      "epoch:17 step:15996 [D loss: 0.658874, acc.: 63.28%] [G loss: 1.089173]\n",
      "epoch:17 step:15997 [D loss: 0.538608, acc.: 80.47%] [G loss: 1.158747]\n",
      "epoch:17 step:15998 [D loss: 0.551040, acc.: 73.44%] [G loss: 1.252803]\n",
      "epoch:17 step:15999 [D loss: 0.620950, acc.: 66.41%] [G loss: 1.228412]\n",
      "epoch:17 step:16000 [D loss: 0.492226, acc.: 75.78%] [G loss: 1.479760]\n",
      "epoch:17 step:16001 [D loss: 0.724788, acc.: 53.12%] [G loss: 1.118342]\n",
      "epoch:17 step:16002 [D loss: 0.536870, acc.: 74.22%] [G loss: 1.157353]\n",
      "epoch:17 step:16003 [D loss: 0.490288, acc.: 79.69%] [G loss: 1.540029]\n",
      "epoch:17 step:16004 [D loss: 0.507201, acc.: 75.00%] [G loss: 1.521171]\n",
      "epoch:17 step:16005 [D loss: 0.499454, acc.: 78.12%] [G loss: 1.188602]\n",
      "epoch:17 step:16006 [D loss: 0.683979, acc.: 58.59%] [G loss: 1.168006]\n",
      "epoch:17 step:16007 [D loss: 0.570054, acc.: 71.88%] [G loss: 1.420561]\n",
      "epoch:17 step:16008 [D loss: 0.573856, acc.: 68.75%] [G loss: 1.287425]\n",
      "epoch:17 step:16009 [D loss: 0.567271, acc.: 71.88%] [G loss: 1.500290]\n",
      "epoch:17 step:16010 [D loss: 0.562200, acc.: 73.44%] [G loss: 1.255977]\n",
      "epoch:17 step:16011 [D loss: 0.599230, acc.: 67.19%] [G loss: 0.888132]\n",
      "epoch:17 step:16012 [D loss: 0.633573, acc.: 60.94%] [G loss: 1.524932]\n",
      "epoch:17 step:16013 [D loss: 0.646763, acc.: 64.06%] [G loss: 1.002012]\n",
      "epoch:17 step:16014 [D loss: 0.490880, acc.: 79.69%] [G loss: 1.171625]\n",
      "epoch:17 step:16015 [D loss: 0.700560, acc.: 53.12%] [G loss: 1.195953]\n",
      "epoch:17 step:16016 [D loss: 0.755469, acc.: 51.56%] [G loss: 1.118011]\n",
      "epoch:17 step:16017 [D loss: 0.585199, acc.: 69.53%] [G loss: 1.536180]\n",
      "epoch:17 step:16018 [D loss: 0.511217, acc.: 75.78%] [G loss: 1.458304]\n",
      "epoch:17 step:16019 [D loss: 0.523691, acc.: 75.00%] [G loss: 1.220223]\n",
      "epoch:17 step:16020 [D loss: 0.468787, acc.: 78.12%] [G loss: 1.205377]\n",
      "epoch:17 step:16021 [D loss: 0.463870, acc.: 79.69%] [G loss: 1.529001]\n",
      "epoch:17 step:16022 [D loss: 0.600856, acc.: 65.62%] [G loss: 1.149537]\n",
      "epoch:17 step:16023 [D loss: 0.539124, acc.: 71.09%] [G loss: 1.218093]\n",
      "epoch:17 step:16024 [D loss: 0.555483, acc.: 72.66%] [G loss: 1.323248]\n",
      "epoch:17 step:16025 [D loss: 0.564578, acc.: 70.31%] [G loss: 1.241229]\n",
      "epoch:17 step:16026 [D loss: 0.497550, acc.: 78.91%] [G loss: 1.494863]\n",
      "epoch:17 step:16027 [D loss: 0.573828, acc.: 67.19%] [G loss: 1.332883]\n",
      "epoch:17 step:16028 [D loss: 0.569842, acc.: 71.09%] [G loss: 1.352689]\n",
      "epoch:17 step:16029 [D loss: 0.598762, acc.: 67.97%] [G loss: 0.976674]\n",
      "epoch:17 step:16030 [D loss: 0.615980, acc.: 67.19%] [G loss: 1.656728]\n",
      "epoch:17 step:16031 [D loss: 0.527949, acc.: 73.44%] [G loss: 1.330251]\n",
      "epoch:17 step:16032 [D loss: 0.701498, acc.: 56.25%] [G loss: 1.354163]\n",
      "epoch:17 step:16033 [D loss: 0.576272, acc.: 70.31%] [G loss: 1.298617]\n",
      "epoch:17 step:16034 [D loss: 0.595274, acc.: 60.94%] [G loss: 1.127584]\n",
      "epoch:17 step:16035 [D loss: 0.496296, acc.: 78.12%] [G loss: 1.161186]\n",
      "epoch:17 step:16036 [D loss: 0.495150, acc.: 74.22%] [G loss: 1.473681]\n",
      "epoch:17 step:16037 [D loss: 0.529981, acc.: 72.66%] [G loss: 1.232052]\n",
      "epoch:17 step:16038 [D loss: 0.544224, acc.: 74.22%] [G loss: 1.330337]\n",
      "epoch:17 step:16039 [D loss: 0.614920, acc.: 62.50%] [G loss: 1.200537]\n",
      "epoch:17 step:16040 [D loss: 0.653895, acc.: 63.28%] [G loss: 0.952379]\n",
      "epoch:17 step:16041 [D loss: 0.587820, acc.: 71.88%] [G loss: 1.653089]\n",
      "epoch:17 step:16042 [D loss: 0.615620, acc.: 65.62%] [G loss: 1.364373]\n",
      "epoch:17 step:16043 [D loss: 0.579812, acc.: 72.66%] [G loss: 1.122616]\n",
      "epoch:17 step:16044 [D loss: 0.492381, acc.: 73.44%] [G loss: 1.337862]\n",
      "epoch:17 step:16045 [D loss: 0.598209, acc.: 70.31%] [G loss: 1.339612]\n",
      "epoch:17 step:16046 [D loss: 0.637717, acc.: 61.72%] [G loss: 1.074904]\n",
      "epoch:17 step:16047 [D loss: 0.618553, acc.: 64.06%] [G loss: 1.187086]\n",
      "epoch:17 step:16048 [D loss: 0.571705, acc.: 67.97%] [G loss: 1.238395]\n",
      "epoch:17 step:16049 [D loss: 0.647489, acc.: 64.06%] [G loss: 1.150753]\n",
      "epoch:17 step:16050 [D loss: 0.557121, acc.: 73.44%] [G loss: 1.179210]\n",
      "epoch:17 step:16051 [D loss: 0.616542, acc.: 65.62%] [G loss: 1.180973]\n",
      "epoch:17 step:16052 [D loss: 0.527253, acc.: 71.09%] [G loss: 1.234881]\n",
      "epoch:17 step:16053 [D loss: 0.537870, acc.: 74.22%] [G loss: 1.154309]\n",
      "epoch:17 step:16054 [D loss: 0.628147, acc.: 71.09%] [G loss: 1.106653]\n",
      "epoch:17 step:16055 [D loss: 0.696230, acc.: 59.38%] [G loss: 0.959034]\n",
      "epoch:17 step:16056 [D loss: 0.579510, acc.: 69.53%] [G loss: 1.306131]\n",
      "epoch:17 step:16057 [D loss: 0.572007, acc.: 74.22%] [G loss: 1.300566]\n",
      "epoch:17 step:16058 [D loss: 0.592826, acc.: 64.06%] [G loss: 0.980582]\n",
      "epoch:17 step:16059 [D loss: 0.581345, acc.: 66.41%] [G loss: 1.400742]\n",
      "epoch:17 step:16060 [D loss: 0.565133, acc.: 71.88%] [G loss: 1.404379]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:17 step:16061 [D loss: 0.539808, acc.: 75.78%] [G loss: 1.166785]\n",
      "epoch:17 step:16062 [D loss: 0.565934, acc.: 67.97%] [G loss: 1.195392]\n",
      "epoch:17 step:16063 [D loss: 0.516823, acc.: 75.78%] [G loss: 1.370154]\n",
      "epoch:17 step:16064 [D loss: 0.640695, acc.: 64.84%] [G loss: 1.204069]\n",
      "epoch:17 step:16065 [D loss: 0.536547, acc.: 73.44%] [G loss: 1.064487]\n",
      "epoch:17 step:16066 [D loss: 0.627700, acc.: 67.97%] [G loss: 1.111988]\n",
      "epoch:17 step:16067 [D loss: 0.522117, acc.: 76.56%] [G loss: 1.182973]\n",
      "epoch:17 step:16068 [D loss: 0.641525, acc.: 64.06%] [G loss: 1.218834]\n",
      "epoch:17 step:16069 [D loss: 0.665669, acc.: 64.06%] [G loss: 1.109541]\n",
      "epoch:17 step:16070 [D loss: 0.793325, acc.: 48.44%] [G loss: 0.955519]\n",
      "epoch:17 step:16071 [D loss: 0.496111, acc.: 77.34%] [G loss: 1.432581]\n",
      "epoch:17 step:16072 [D loss: 0.524246, acc.: 74.22%] [G loss: 1.158484]\n",
      "epoch:17 step:16073 [D loss: 0.604067, acc.: 69.53%] [G loss: 1.112116]\n",
      "epoch:17 step:16074 [D loss: 0.568794, acc.: 74.22%] [G loss: 1.595712]\n",
      "epoch:17 step:16075 [D loss: 0.630798, acc.: 64.84%] [G loss: 1.160898]\n",
      "epoch:17 step:16076 [D loss: 0.484394, acc.: 77.34%] [G loss: 1.405608]\n",
      "epoch:17 step:16077 [D loss: 0.474303, acc.: 76.56%] [G loss: 1.343419]\n",
      "epoch:17 step:16078 [D loss: 0.731390, acc.: 57.81%] [G loss: 0.975945]\n",
      "epoch:17 step:16079 [D loss: 0.619729, acc.: 66.41%] [G loss: 1.257379]\n",
      "epoch:17 step:16080 [D loss: 0.491135, acc.: 82.03%] [G loss: 1.198948]\n",
      "epoch:17 step:16081 [D loss: 0.531277, acc.: 78.91%] [G loss: 1.459846]\n",
      "epoch:17 step:16082 [D loss: 0.597590, acc.: 71.88%] [G loss: 1.290432]\n",
      "epoch:17 step:16083 [D loss: 0.567257, acc.: 71.88%] [G loss: 1.126733]\n",
      "epoch:17 step:16084 [D loss: 0.608969, acc.: 62.50%] [G loss: 1.179057]\n",
      "epoch:17 step:16085 [D loss: 0.500180, acc.: 75.78%] [G loss: 1.396098]\n",
      "epoch:17 step:16086 [D loss: 0.642702, acc.: 64.84%] [G loss: 1.164530]\n",
      "epoch:17 step:16087 [D loss: 0.534217, acc.: 76.56%] [G loss: 1.482893]\n",
      "epoch:17 step:16088 [D loss: 0.599725, acc.: 66.41%] [G loss: 1.194956]\n",
      "epoch:17 step:16089 [D loss: 0.533267, acc.: 75.78%] [G loss: 1.641434]\n",
      "epoch:17 step:16090 [D loss: 0.624721, acc.: 65.62%] [G loss: 1.352299]\n",
      "epoch:17 step:16091 [D loss: 0.725288, acc.: 56.25%] [G loss: 0.932925]\n",
      "epoch:17 step:16092 [D loss: 0.563998, acc.: 67.97%] [G loss: 1.420517]\n",
      "epoch:17 step:16093 [D loss: 0.560361, acc.: 78.12%] [G loss: 1.356869]\n",
      "epoch:17 step:16094 [D loss: 0.647969, acc.: 67.97%] [G loss: 1.289569]\n",
      "epoch:17 step:16095 [D loss: 0.602238, acc.: 69.53%] [G loss: 1.274057]\n",
      "epoch:17 step:16096 [D loss: 0.623279, acc.: 64.84%] [G loss: 1.243517]\n",
      "epoch:17 step:16097 [D loss: 0.486679, acc.: 79.69%] [G loss: 1.382962]\n",
      "epoch:17 step:16098 [D loss: 0.671314, acc.: 61.72%] [G loss: 1.027321]\n",
      "epoch:17 step:16099 [D loss: 0.595187, acc.: 69.53%] [G loss: 1.479402]\n",
      "epoch:17 step:16100 [D loss: 0.640116, acc.: 60.16%] [G loss: 1.152918]\n",
      "epoch:17 step:16101 [D loss: 0.431478, acc.: 79.69%] [G loss: 1.043131]\n",
      "epoch:17 step:16102 [D loss: 0.451341, acc.: 84.38%] [G loss: 1.323805]\n",
      "epoch:17 step:16103 [D loss: 0.544627, acc.: 73.44%] [G loss: 1.395940]\n",
      "epoch:17 step:16104 [D loss: 0.588154, acc.: 71.09%] [G loss: 1.330554]\n",
      "epoch:17 step:16105 [D loss: 0.575136, acc.: 67.19%] [G loss: 1.279537]\n",
      "epoch:17 step:16106 [D loss: 0.497312, acc.: 80.47%] [G loss: 1.451733]\n",
      "epoch:17 step:16107 [D loss: 0.595213, acc.: 60.94%] [G loss: 1.383425]\n",
      "epoch:17 step:16108 [D loss: 0.571511, acc.: 71.09%] [G loss: 1.018438]\n",
      "epoch:17 step:16109 [D loss: 0.488505, acc.: 76.56%] [G loss: 1.296229]\n",
      "epoch:17 step:16110 [D loss: 0.705184, acc.: 53.91%] [G loss: 1.066328]\n",
      "epoch:17 step:16111 [D loss: 0.548904, acc.: 70.31%] [G loss: 1.151631]\n",
      "epoch:17 step:16112 [D loss: 0.568418, acc.: 72.66%] [G loss: 1.478383]\n",
      "epoch:17 step:16113 [D loss: 0.626903, acc.: 60.94%] [G loss: 1.177928]\n",
      "epoch:17 step:16114 [D loss: 0.588205, acc.: 68.75%] [G loss: 1.174388]\n",
      "epoch:17 step:16115 [D loss: 0.614508, acc.: 63.28%] [G loss: 1.412546]\n",
      "epoch:17 step:16116 [D loss: 0.500399, acc.: 77.34%] [G loss: 1.322842]\n",
      "epoch:17 step:16117 [D loss: 0.543197, acc.: 69.53%] [G loss: 1.063071]\n",
      "epoch:17 step:16118 [D loss: 0.694809, acc.: 57.81%] [G loss: 1.243608]\n",
      "epoch:17 step:16119 [D loss: 0.775550, acc.: 57.03%] [G loss: 1.006585]\n",
      "epoch:17 step:16120 [D loss: 0.570650, acc.: 72.66%] [G loss: 1.330670]\n",
      "epoch:17 step:16121 [D loss: 0.572228, acc.: 71.88%] [G loss: 1.362247]\n",
      "epoch:17 step:16122 [D loss: 0.582958, acc.: 67.97%] [G loss: 1.410491]\n",
      "epoch:17 step:16123 [D loss: 0.602324, acc.: 71.88%] [G loss: 1.101708]\n",
      "epoch:17 step:16124 [D loss: 0.599431, acc.: 72.66%] [G loss: 1.093628]\n",
      "epoch:17 step:16125 [D loss: 0.595959, acc.: 66.41%] [G loss: 1.304750]\n",
      "epoch:17 step:16126 [D loss: 0.549393, acc.: 72.66%] [G loss: 1.328987]\n",
      "epoch:17 step:16127 [D loss: 0.479571, acc.: 75.78%] [G loss: 1.452339]\n",
      "epoch:17 step:16128 [D loss: 0.531248, acc.: 71.09%] [G loss: 1.160826]\n",
      "epoch:17 step:16129 [D loss: 0.683101, acc.: 53.91%] [G loss: 1.320870]\n",
      "epoch:17 step:16130 [D loss: 0.469026, acc.: 81.25%] [G loss: 1.673345]\n",
      "epoch:17 step:16131 [D loss: 0.567197, acc.: 69.53%] [G loss: 1.123084]\n",
      "epoch:17 step:16132 [D loss: 0.539414, acc.: 71.88%] [G loss: 1.007401]\n",
      "epoch:17 step:16133 [D loss: 0.514384, acc.: 76.56%] [G loss: 1.552181]\n",
      "epoch:17 step:16134 [D loss: 0.613838, acc.: 64.84%] [G loss: 1.168303]\n",
      "epoch:17 step:16135 [D loss: 0.519857, acc.: 76.56%] [G loss: 1.419084]\n",
      "epoch:17 step:16136 [D loss: 0.771772, acc.: 48.44%] [G loss: 1.105850]\n",
      "epoch:17 step:16137 [D loss: 0.529920, acc.: 75.78%] [G loss: 1.318610]\n",
      "epoch:17 step:16138 [D loss: 0.604688, acc.: 66.41%] [G loss: 1.516077]\n",
      "epoch:17 step:16139 [D loss: 0.527101, acc.: 78.12%] [G loss: 1.318688]\n",
      "epoch:17 step:16140 [D loss: 0.469453, acc.: 82.81%] [G loss: 1.301047]\n",
      "epoch:17 step:16141 [D loss: 0.670717, acc.: 60.94%] [G loss: 1.215483]\n",
      "epoch:17 step:16142 [D loss: 0.599882, acc.: 69.53%] [G loss: 1.093166]\n",
      "epoch:17 step:16143 [D loss: 0.647167, acc.: 60.94%] [G loss: 1.084174]\n",
      "epoch:17 step:16144 [D loss: 0.594426, acc.: 66.41%] [G loss: 1.203684]\n",
      "epoch:17 step:16145 [D loss: 0.551565, acc.: 73.44%] [G loss: 1.226278]\n",
      "epoch:17 step:16146 [D loss: 0.439521, acc.: 77.34%] [G loss: 1.448360]\n",
      "epoch:17 step:16147 [D loss: 0.603622, acc.: 67.19%] [G loss: 1.230286]\n",
      "epoch:17 step:16148 [D loss: 0.623766, acc.: 64.06%] [G loss: 1.271179]\n",
      "epoch:17 step:16149 [D loss: 0.611104, acc.: 65.62%] [G loss: 1.178606]\n",
      "epoch:17 step:16150 [D loss: 0.633128, acc.: 63.28%] [G loss: 1.279459]\n",
      "epoch:17 step:16151 [D loss: 0.729623, acc.: 57.81%] [G loss: 0.914186]\n",
      "epoch:17 step:16152 [D loss: 0.524773, acc.: 72.66%] [G loss: 1.355046]\n",
      "epoch:17 step:16153 [D loss: 0.590171, acc.: 67.19%] [G loss: 1.346616]\n",
      "epoch:17 step:16154 [D loss: 0.562032, acc.: 69.53%] [G loss: 1.542778]\n",
      "epoch:17 step:16155 [D loss: 0.515216, acc.: 77.34%] [G loss: 1.156568]\n",
      "epoch:17 step:16156 [D loss: 0.620398, acc.: 64.84%] [G loss: 1.097773]\n",
      "epoch:17 step:16157 [D loss: 0.506929, acc.: 75.00%] [G loss: 1.139140]\n",
      "epoch:17 step:16158 [D loss: 0.525928, acc.: 73.44%] [G loss: 1.114738]\n",
      "epoch:17 step:16159 [D loss: 0.525501, acc.: 73.44%] [G loss: 1.571720]\n",
      "epoch:17 step:16160 [D loss: 0.603265, acc.: 67.97%] [G loss: 1.401054]\n",
      "epoch:17 step:16161 [D loss: 0.629169, acc.: 66.41%] [G loss: 1.353041]\n",
      "epoch:17 step:16162 [D loss: 0.565263, acc.: 71.88%] [G loss: 1.480395]\n",
      "epoch:17 step:16163 [D loss: 0.580617, acc.: 68.75%] [G loss: 1.214581]\n",
      "epoch:17 step:16164 [D loss: 0.572829, acc.: 65.62%] [G loss: 1.228310]\n",
      "epoch:17 step:16165 [D loss: 0.607487, acc.: 69.53%] [G loss: 1.350177]\n",
      "epoch:17 step:16166 [D loss: 0.629468, acc.: 65.62%] [G loss: 1.021391]\n",
      "epoch:17 step:16167 [D loss: 0.664207, acc.: 57.81%] [G loss: 0.992683]\n",
      "epoch:17 step:16168 [D loss: 0.576727, acc.: 65.62%] [G loss: 1.440077]\n",
      "epoch:17 step:16169 [D loss: 0.793405, acc.: 49.22%] [G loss: 0.938705]\n",
      "epoch:17 step:16170 [D loss: 0.510535, acc.: 72.66%] [G loss: 1.289514]\n",
      "epoch:17 step:16171 [D loss: 0.647351, acc.: 67.19%] [G loss: 1.050391]\n",
      "epoch:17 step:16172 [D loss: 0.563616, acc.: 68.75%] [G loss: 1.295227]\n",
      "epoch:17 step:16173 [D loss: 0.638946, acc.: 63.28%] [G loss: 1.078077]\n",
      "epoch:17 step:16174 [D loss: 0.583869, acc.: 68.75%] [G loss: 1.258270]\n",
      "epoch:17 step:16175 [D loss: 0.508741, acc.: 78.91%] [G loss: 1.398011]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:17 step:16176 [D loss: 0.649430, acc.: 58.59%] [G loss: 1.195954]\n",
      "epoch:17 step:16177 [D loss: 0.561993, acc.: 65.62%] [G loss: 1.458400]\n",
      "epoch:17 step:16178 [D loss: 0.418283, acc.: 84.38%] [G loss: 1.421267]\n",
      "epoch:17 step:16179 [D loss: 0.603204, acc.: 65.62%] [G loss: 1.224534]\n",
      "epoch:17 step:16180 [D loss: 0.507330, acc.: 79.69%] [G loss: 1.015086]\n",
      "epoch:17 step:16181 [D loss: 0.503812, acc.: 77.34%] [G loss: 1.377366]\n",
      "epoch:17 step:16182 [D loss: 0.532222, acc.: 77.34%] [G loss: 1.300034]\n",
      "epoch:17 step:16183 [D loss: 0.451325, acc.: 80.47%] [G loss: 1.208278]\n",
      "epoch:17 step:16184 [D loss: 0.614849, acc.: 71.09%] [G loss: 1.297773]\n",
      "epoch:17 step:16185 [D loss: 0.532628, acc.: 75.78%] [G loss: 1.478714]\n",
      "epoch:17 step:16186 [D loss: 0.569098, acc.: 68.75%] [G loss: 1.354670]\n",
      "epoch:17 step:16187 [D loss: 0.566734, acc.: 71.09%] [G loss: 1.130544]\n",
      "epoch:17 step:16188 [D loss: 0.523774, acc.: 72.66%] [G loss: 1.258845]\n",
      "epoch:17 step:16189 [D loss: 0.528247, acc.: 77.34%] [G loss: 0.925430]\n",
      "epoch:17 step:16190 [D loss: 0.519437, acc.: 72.66%] [G loss: 1.187777]\n",
      "epoch:17 step:16191 [D loss: 0.650118, acc.: 62.50%] [G loss: 1.181625]\n",
      "epoch:17 step:16192 [D loss: 0.616705, acc.: 66.41%] [G loss: 1.488755]\n",
      "epoch:17 step:16193 [D loss: 0.527926, acc.: 75.78%] [G loss: 1.028613]\n",
      "epoch:17 step:16194 [D loss: 0.495691, acc.: 78.12%] [G loss: 1.307478]\n",
      "epoch:17 step:16195 [D loss: 0.543599, acc.: 70.31%] [G loss: 1.165604]\n",
      "epoch:17 step:16196 [D loss: 0.546757, acc.: 78.12%] [G loss: 1.494659]\n",
      "epoch:17 step:16197 [D loss: 0.594665, acc.: 67.97%] [G loss: 1.224844]\n",
      "epoch:17 step:16198 [D loss: 0.513085, acc.: 74.22%] [G loss: 1.263108]\n",
      "epoch:17 step:16199 [D loss: 0.580438, acc.: 69.53%] [G loss: 1.361157]\n",
      "epoch:17 step:16200 [D loss: 0.649464, acc.: 65.62%] [G loss: 1.231482]\n",
      "epoch:17 step:16201 [D loss: 0.498673, acc.: 74.22%] [G loss: 1.275008]\n",
      "epoch:17 step:16202 [D loss: 0.647795, acc.: 60.16%] [G loss: 1.102747]\n",
      "epoch:17 step:16203 [D loss: 0.424387, acc.: 89.06%] [G loss: 1.517492]\n",
      "epoch:17 step:16204 [D loss: 0.641612, acc.: 60.94%] [G loss: 1.157303]\n",
      "epoch:17 step:16205 [D loss: 0.610654, acc.: 66.41%] [G loss: 1.323172]\n",
      "epoch:17 step:16206 [D loss: 0.557129, acc.: 68.75%] [G loss: 1.043186]\n",
      "epoch:17 step:16207 [D loss: 0.620408, acc.: 67.97%] [G loss: 1.168994]\n",
      "epoch:17 step:16208 [D loss: 0.683254, acc.: 58.59%] [G loss: 1.136422]\n",
      "epoch:17 step:16209 [D loss: 0.724984, acc.: 57.81%] [G loss: 1.329712]\n",
      "epoch:17 step:16210 [D loss: 0.512516, acc.: 72.66%] [G loss: 1.221886]\n",
      "epoch:17 step:16211 [D loss: 0.662735, acc.: 62.50%] [G loss: 1.218382]\n",
      "epoch:17 step:16212 [D loss: 0.524124, acc.: 73.44%] [G loss: 1.617417]\n",
      "epoch:17 step:16213 [D loss: 0.644165, acc.: 65.62%] [G loss: 1.089890]\n",
      "epoch:17 step:16214 [D loss: 0.578092, acc.: 71.88%] [G loss: 1.180959]\n",
      "epoch:17 step:16215 [D loss: 0.641517, acc.: 63.28%] [G loss: 1.034997]\n",
      "epoch:17 step:16216 [D loss: 0.519346, acc.: 76.56%] [G loss: 1.271434]\n",
      "epoch:17 step:16217 [D loss: 0.554492, acc.: 71.88%] [G loss: 1.090245]\n",
      "epoch:17 step:16218 [D loss: 0.686155, acc.: 57.81%] [G loss: 0.937752]\n",
      "epoch:17 step:16219 [D loss: 0.596147, acc.: 64.84%] [G loss: 1.176626]\n",
      "epoch:17 step:16220 [D loss: 0.475263, acc.: 74.22%] [G loss: 1.341953]\n",
      "epoch:17 step:16221 [D loss: 0.684217, acc.: 60.16%] [G loss: 1.206501]\n",
      "epoch:17 step:16222 [D loss: 0.656601, acc.: 58.59%] [G loss: 1.159246]\n",
      "epoch:17 step:16223 [D loss: 0.458638, acc.: 82.03%] [G loss: 1.234360]\n",
      "epoch:17 step:16224 [D loss: 0.613085, acc.: 68.75%] [G loss: 0.927369]\n",
      "epoch:17 step:16225 [D loss: 0.538031, acc.: 74.22%] [G loss: 1.377350]\n",
      "epoch:17 step:16226 [D loss: 0.595196, acc.: 70.31%] [G loss: 1.356729]\n",
      "epoch:17 step:16227 [D loss: 0.604676, acc.: 65.62%] [G loss: 1.204686]\n",
      "epoch:17 step:16228 [D loss: 0.701594, acc.: 58.59%] [G loss: 0.880031]\n",
      "epoch:17 step:16229 [D loss: 0.503481, acc.: 76.56%] [G loss: 1.174567]\n",
      "epoch:17 step:16230 [D loss: 0.539079, acc.: 73.44%] [G loss: 1.155649]\n",
      "epoch:17 step:16231 [D loss: 0.594800, acc.: 67.97%] [G loss: 1.135009]\n",
      "epoch:17 step:16232 [D loss: 0.636499, acc.: 65.62%] [G loss: 1.043140]\n",
      "epoch:17 step:16233 [D loss: 0.550752, acc.: 73.44%] [G loss: 1.125844]\n",
      "epoch:17 step:16234 [D loss: 0.551340, acc.: 69.53%] [G loss: 1.303379]\n",
      "epoch:17 step:16235 [D loss: 0.590695, acc.: 71.88%] [G loss: 1.004986]\n",
      "epoch:17 step:16236 [D loss: 0.547268, acc.: 73.44%] [G loss: 0.951467]\n",
      "epoch:17 step:16237 [D loss: 0.519872, acc.: 73.44%] [G loss: 1.487010]\n",
      "epoch:17 step:16238 [D loss: 0.589617, acc.: 65.62%] [G loss: 1.407212]\n",
      "epoch:17 step:16239 [D loss: 0.567019, acc.: 72.66%] [G loss: 1.399900]\n",
      "epoch:17 step:16240 [D loss: 0.529056, acc.: 77.34%] [G loss: 1.319099]\n",
      "epoch:17 step:16241 [D loss: 0.688370, acc.: 59.38%] [G loss: 1.144238]\n",
      "epoch:17 step:16242 [D loss: 0.529254, acc.: 73.44%] [G loss: 1.138499]\n",
      "epoch:17 step:16243 [D loss: 0.646452, acc.: 64.06%] [G loss: 1.186481]\n",
      "epoch:17 step:16244 [D loss: 0.574209, acc.: 69.53%] [G loss: 1.356263]\n",
      "epoch:17 step:16245 [D loss: 0.495225, acc.: 78.12%] [G loss: 1.408048]\n",
      "epoch:17 step:16246 [D loss: 0.561295, acc.: 67.97%] [G loss: 1.475297]\n",
      "epoch:17 step:16247 [D loss: 0.740077, acc.: 49.22%] [G loss: 1.107815]\n",
      "epoch:17 step:16248 [D loss: 0.661018, acc.: 58.59%] [G loss: 1.330396]\n",
      "epoch:17 step:16249 [D loss: 0.544235, acc.: 70.31%] [G loss: 1.210977]\n",
      "epoch:17 step:16250 [D loss: 0.549058, acc.: 71.09%] [G loss: 1.326847]\n",
      "epoch:17 step:16251 [D loss: 0.580617, acc.: 71.09%] [G loss: 1.241622]\n",
      "epoch:17 step:16252 [D loss: 0.492644, acc.: 82.03%] [G loss: 1.356506]\n",
      "epoch:17 step:16253 [D loss: 0.580260, acc.: 67.97%] [G loss: 1.175249]\n",
      "epoch:17 step:16254 [D loss: 0.511077, acc.: 73.44%] [G loss: 0.939798]\n",
      "epoch:17 step:16255 [D loss: 0.664193, acc.: 61.72%] [G loss: 0.985515]\n",
      "epoch:17 step:16256 [D loss: 0.567699, acc.: 71.09%] [G loss: 1.585432]\n",
      "epoch:17 step:16257 [D loss: 0.540719, acc.: 73.44%] [G loss: 1.550111]\n",
      "epoch:17 step:16258 [D loss: 0.559048, acc.: 69.53%] [G loss: 1.383169]\n",
      "epoch:17 step:16259 [D loss: 0.547820, acc.: 72.66%] [G loss: 1.109698]\n",
      "epoch:17 step:16260 [D loss: 0.568512, acc.: 73.44%] [G loss: 1.276811]\n",
      "epoch:17 step:16261 [D loss: 0.569416, acc.: 72.66%] [G loss: 1.380419]\n",
      "epoch:17 step:16262 [D loss: 0.588446, acc.: 71.09%] [G loss: 1.227251]\n",
      "epoch:17 step:16263 [D loss: 0.648507, acc.: 66.41%] [G loss: 1.332881]\n",
      "epoch:17 step:16264 [D loss: 0.592934, acc.: 66.41%] [G loss: 1.232460]\n",
      "epoch:17 step:16265 [D loss: 0.475349, acc.: 80.47%] [G loss: 1.403102]\n",
      "epoch:17 step:16266 [D loss: 0.692911, acc.: 63.28%] [G loss: 1.355586]\n",
      "epoch:17 step:16267 [D loss: 0.525770, acc.: 71.09%] [G loss: 1.334147]\n",
      "epoch:17 step:16268 [D loss: 0.535148, acc.: 72.66%] [G loss: 1.241727]\n",
      "epoch:17 step:16269 [D loss: 0.683672, acc.: 63.28%] [G loss: 1.213299]\n",
      "epoch:17 step:16270 [D loss: 0.613916, acc.: 69.53%] [G loss: 1.317173]\n",
      "epoch:17 step:16271 [D loss: 0.541960, acc.: 71.88%] [G loss: 1.439266]\n",
      "epoch:17 step:16272 [D loss: 0.617211, acc.: 65.62%] [G loss: 1.550796]\n",
      "epoch:17 step:16273 [D loss: 0.568941, acc.: 69.53%] [G loss: 1.398826]\n",
      "epoch:17 step:16274 [D loss: 0.456911, acc.: 79.69%] [G loss: 1.476932]\n",
      "epoch:17 step:16275 [D loss: 0.752360, acc.: 48.44%] [G loss: 1.221135]\n",
      "epoch:17 step:16276 [D loss: 0.610911, acc.: 64.06%] [G loss: 1.316803]\n",
      "epoch:17 step:16277 [D loss: 0.591383, acc.: 69.53%] [G loss: 1.357228]\n",
      "epoch:17 step:16278 [D loss: 0.594470, acc.: 71.88%] [G loss: 1.430838]\n",
      "epoch:17 step:16279 [D loss: 0.539521, acc.: 78.12%] [G loss: 1.075889]\n",
      "epoch:17 step:16280 [D loss: 0.587579, acc.: 67.19%] [G loss: 1.161226]\n",
      "epoch:17 step:16281 [D loss: 0.575960, acc.: 71.88%] [G loss: 1.476765]\n",
      "epoch:17 step:16282 [D loss: 0.621139, acc.: 67.19%] [G loss: 1.126343]\n",
      "epoch:17 step:16283 [D loss: 0.503697, acc.: 75.00%] [G loss: 1.586692]\n",
      "epoch:17 step:16284 [D loss: 0.631434, acc.: 64.06%] [G loss: 1.272291]\n",
      "epoch:17 step:16285 [D loss: 0.453813, acc.: 79.69%] [G loss: 1.345643]\n",
      "epoch:17 step:16286 [D loss: 0.511292, acc.: 75.00%] [G loss: 1.402877]\n",
      "epoch:17 step:16287 [D loss: 0.524763, acc.: 71.88%] [G loss: 1.404500]\n",
      "epoch:17 step:16288 [D loss: 0.698605, acc.: 58.59%] [G loss: 0.979415]\n",
      "epoch:17 step:16289 [D loss: 0.635400, acc.: 63.28%] [G loss: 1.141378]\n",
      "epoch:17 step:16290 [D loss: 0.610291, acc.: 70.31%] [G loss: 1.300332]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:17 step:16291 [D loss: 0.522302, acc.: 75.00%] [G loss: 1.490101]\n",
      "epoch:17 step:16292 [D loss: 0.488482, acc.: 80.47%] [G loss: 1.325248]\n",
      "epoch:17 step:16293 [D loss: 0.451625, acc.: 85.16%] [G loss: 1.586105]\n",
      "epoch:17 step:16294 [D loss: 0.585321, acc.: 65.62%] [G loss: 1.053102]\n",
      "epoch:17 step:16295 [D loss: 0.690319, acc.: 58.59%] [G loss: 1.287532]\n",
      "epoch:17 step:16296 [D loss: 0.595924, acc.: 69.53%] [G loss: 1.444370]\n",
      "epoch:17 step:16297 [D loss: 0.508925, acc.: 78.91%] [G loss: 1.344120]\n",
      "epoch:17 step:16298 [D loss: 0.522614, acc.: 76.56%] [G loss: 1.264365]\n",
      "epoch:17 step:16299 [D loss: 0.573777, acc.: 71.09%] [G loss: 1.341833]\n",
      "epoch:17 step:16300 [D loss: 0.551546, acc.: 71.09%] [G loss: 1.179404]\n",
      "epoch:17 step:16301 [D loss: 0.487001, acc.: 75.00%] [G loss: 1.383477]\n",
      "epoch:17 step:16302 [D loss: 0.735232, acc.: 55.47%] [G loss: 1.242212]\n",
      "epoch:17 step:16303 [D loss: 0.510683, acc.: 73.44%] [G loss: 1.134551]\n",
      "epoch:17 step:16304 [D loss: 0.693277, acc.: 60.94%] [G loss: 1.421188]\n",
      "epoch:17 step:16305 [D loss: 0.702013, acc.: 60.94%] [G loss: 1.312367]\n",
      "epoch:17 step:16306 [D loss: 0.531541, acc.: 73.44%] [G loss: 1.214445]\n",
      "epoch:17 step:16307 [D loss: 0.494580, acc.: 77.34%] [G loss: 1.201956]\n",
      "epoch:17 step:16308 [D loss: 0.597617, acc.: 71.88%] [G loss: 1.393723]\n",
      "epoch:17 step:16309 [D loss: 0.640914, acc.: 61.72%] [G loss: 0.992976]\n",
      "epoch:17 step:16310 [D loss: 0.664667, acc.: 60.94%] [G loss: 0.922594]\n",
      "epoch:17 step:16311 [D loss: 0.606568, acc.: 64.06%] [G loss: 1.326138]\n",
      "epoch:17 step:16312 [D loss: 0.597077, acc.: 66.41%] [G loss: 1.230728]\n",
      "epoch:17 step:16313 [D loss: 0.547018, acc.: 77.34%] [G loss: 1.130511]\n",
      "epoch:17 step:16314 [D loss: 0.552134, acc.: 67.19%] [G loss: 1.580018]\n",
      "epoch:17 step:16315 [D loss: 0.603216, acc.: 67.97%] [G loss: 1.385960]\n",
      "epoch:17 step:16316 [D loss: 0.461810, acc.: 80.47%] [G loss: 1.101605]\n",
      "epoch:17 step:16317 [D loss: 0.631173, acc.: 65.62%] [G loss: 1.310304]\n",
      "epoch:17 step:16318 [D loss: 0.654319, acc.: 60.94%] [G loss: 1.266125]\n",
      "epoch:17 step:16319 [D loss: 0.600446, acc.: 65.62%] [G loss: 1.146360]\n",
      "epoch:17 step:16320 [D loss: 0.727750, acc.: 57.81%] [G loss: 1.187480]\n",
      "epoch:17 step:16321 [D loss: 0.597620, acc.: 64.84%] [G loss: 1.131174]\n",
      "epoch:17 step:16322 [D loss: 0.670688, acc.: 60.94%] [G loss: 1.054595]\n",
      "epoch:17 step:16323 [D loss: 0.618209, acc.: 68.75%] [G loss: 1.124870]\n",
      "epoch:17 step:16324 [D loss: 0.526825, acc.: 72.66%] [G loss: 1.369840]\n",
      "epoch:17 step:16325 [D loss: 0.514923, acc.: 75.78%] [G loss: 1.334811]\n",
      "epoch:17 step:16326 [D loss: 0.602964, acc.: 67.19%] [G loss: 1.208915]\n",
      "epoch:17 step:16327 [D loss: 0.588588, acc.: 70.31%] [G loss: 1.166783]\n",
      "epoch:17 step:16328 [D loss: 0.478003, acc.: 76.56%] [G loss: 1.355476]\n",
      "epoch:17 step:16329 [D loss: 0.712609, acc.: 54.69%] [G loss: 0.994313]\n",
      "epoch:17 step:16330 [D loss: 0.653785, acc.: 60.16%] [G loss: 1.149515]\n",
      "epoch:17 step:16331 [D loss: 0.479019, acc.: 78.91%] [G loss: 1.576216]\n",
      "epoch:17 step:16332 [D loss: 0.669608, acc.: 58.59%] [G loss: 1.372061]\n",
      "epoch:17 step:16333 [D loss: 0.584947, acc.: 70.31%] [G loss: 1.290457]\n",
      "epoch:17 step:16334 [D loss: 0.633289, acc.: 59.38%] [G loss: 0.904400]\n",
      "epoch:17 step:16335 [D loss: 0.441209, acc.: 84.38%] [G loss: 1.401153]\n",
      "epoch:17 step:16336 [D loss: 0.686723, acc.: 55.47%] [G loss: 1.226317]\n",
      "epoch:17 step:16337 [D loss: 0.646109, acc.: 66.41%] [G loss: 1.246572]\n",
      "epoch:17 step:16338 [D loss: 0.543391, acc.: 74.22%] [G loss: 1.443539]\n",
      "epoch:17 step:16339 [D loss: 0.531153, acc.: 69.53%] [G loss: 1.365812]\n",
      "epoch:17 step:16340 [D loss: 0.599309, acc.: 67.97%] [G loss: 1.155858]\n",
      "epoch:17 step:16341 [D loss: 0.609350, acc.: 65.62%] [G loss: 1.286437]\n",
      "epoch:17 step:16342 [D loss: 0.634951, acc.: 65.62%] [G loss: 1.284571]\n",
      "epoch:17 step:16343 [D loss: 0.629884, acc.: 68.75%] [G loss: 1.195157]\n",
      "epoch:17 step:16344 [D loss: 0.537177, acc.: 71.09%] [G loss: 1.089022]\n",
      "epoch:17 step:16345 [D loss: 0.482180, acc.: 80.47%] [G loss: 1.372932]\n",
      "epoch:17 step:16346 [D loss: 0.575547, acc.: 71.88%] [G loss: 1.615186]\n",
      "epoch:17 step:16347 [D loss: 0.625449, acc.: 62.50%] [G loss: 1.231713]\n",
      "epoch:17 step:16348 [D loss: 0.446696, acc.: 82.03%] [G loss: 1.438047]\n",
      "epoch:17 step:16349 [D loss: 0.474862, acc.: 78.91%] [G loss: 1.147432]\n",
      "epoch:17 step:16350 [D loss: 0.594711, acc.: 67.97%] [G loss: 1.314496]\n",
      "epoch:17 step:16351 [D loss: 0.620007, acc.: 64.06%] [G loss: 1.441832]\n",
      "epoch:17 step:16352 [D loss: 0.619683, acc.: 62.50%] [G loss: 1.208431]\n",
      "epoch:17 step:16353 [D loss: 0.505960, acc.: 78.12%] [G loss: 1.483361]\n",
      "epoch:17 step:16354 [D loss: 0.624445, acc.: 66.41%] [G loss: 1.231843]\n",
      "epoch:17 step:16355 [D loss: 0.472958, acc.: 78.91%] [G loss: 1.349111]\n",
      "epoch:17 step:16356 [D loss: 0.594805, acc.: 71.09%] [G loss: 1.370912]\n",
      "epoch:17 step:16357 [D loss: 0.509451, acc.: 76.56%] [G loss: 1.399912]\n",
      "epoch:17 step:16358 [D loss: 0.616989, acc.: 62.50%] [G loss: 1.460665]\n",
      "epoch:17 step:16359 [D loss: 0.543204, acc.: 72.66%] [G loss: 1.355240]\n",
      "epoch:17 step:16360 [D loss: 0.507122, acc.: 72.66%] [G loss: 1.169944]\n",
      "epoch:17 step:16361 [D loss: 0.557996, acc.: 70.31%] [G loss: 0.900472]\n",
      "epoch:17 step:16362 [D loss: 0.448923, acc.: 83.59%] [G loss: 1.269678]\n",
      "epoch:17 step:16363 [D loss: 0.705363, acc.: 55.47%] [G loss: 1.157471]\n",
      "epoch:17 step:16364 [D loss: 0.583742, acc.: 68.75%] [G loss: 1.075737]\n",
      "epoch:17 step:16365 [D loss: 0.609412, acc.: 64.84%] [G loss: 1.356032]\n",
      "epoch:17 step:16366 [D loss: 0.605825, acc.: 64.06%] [G loss: 1.033478]\n",
      "epoch:17 step:16367 [D loss: 0.503634, acc.: 76.56%] [G loss: 1.078641]\n",
      "epoch:17 step:16368 [D loss: 0.570368, acc.: 75.00%] [G loss: 1.179393]\n",
      "epoch:17 step:16369 [D loss: 0.608998, acc.: 69.53%] [G loss: 1.373271]\n",
      "epoch:17 step:16370 [D loss: 0.594316, acc.: 71.09%] [G loss: 1.300379]\n",
      "epoch:17 step:16371 [D loss: 0.697534, acc.: 61.72%] [G loss: 0.891957]\n",
      "epoch:17 step:16372 [D loss: 0.490192, acc.: 81.25%] [G loss: 1.344634]\n",
      "epoch:17 step:16373 [D loss: 0.648726, acc.: 68.75%] [G loss: 1.241313]\n",
      "epoch:17 step:16374 [D loss: 0.582996, acc.: 71.09%] [G loss: 0.954618]\n",
      "epoch:17 step:16375 [D loss: 0.662657, acc.: 60.94%] [G loss: 1.109038]\n",
      "epoch:17 step:16376 [D loss: 0.446441, acc.: 80.47%] [G loss: 1.332976]\n",
      "epoch:17 step:16377 [D loss: 0.663497, acc.: 57.03%] [G loss: 1.159312]\n",
      "epoch:17 step:16378 [D loss: 0.618041, acc.: 64.84%] [G loss: 1.208056]\n",
      "epoch:17 step:16379 [D loss: 0.599417, acc.: 65.62%] [G loss: 1.144503]\n",
      "epoch:17 step:16380 [D loss: 0.560674, acc.: 70.31%] [G loss: 1.390401]\n",
      "epoch:17 step:16381 [D loss: 0.545478, acc.: 71.88%] [G loss: 1.292145]\n",
      "epoch:17 step:16382 [D loss: 0.621632, acc.: 61.72%] [G loss: 1.365226]\n",
      "epoch:17 step:16383 [D loss: 0.543429, acc.: 71.09%] [G loss: 1.242962]\n",
      "epoch:17 step:16384 [D loss: 0.441030, acc.: 84.38%] [G loss: 1.590872]\n",
      "epoch:17 step:16385 [D loss: 0.659936, acc.: 62.50%] [G loss: 1.159557]\n",
      "epoch:17 step:16386 [D loss: 0.726366, acc.: 55.47%] [G loss: 0.975890]\n",
      "epoch:17 step:16387 [D loss: 0.455023, acc.: 81.25%] [G loss: 1.357945]\n",
      "epoch:17 step:16388 [D loss: 0.596335, acc.: 70.31%] [G loss: 1.515089]\n",
      "epoch:17 step:16389 [D loss: 0.557410, acc.: 68.75%] [G loss: 1.452982]\n",
      "epoch:17 step:16390 [D loss: 0.714749, acc.: 63.28%] [G loss: 1.357490]\n",
      "epoch:17 step:16391 [D loss: 0.686122, acc.: 62.50%] [G loss: 1.186415]\n",
      "epoch:17 step:16392 [D loss: 0.630767, acc.: 67.19%] [G loss: 1.219021]\n",
      "epoch:17 step:16393 [D loss: 0.578196, acc.: 72.66%] [G loss: 1.370944]\n",
      "epoch:17 step:16394 [D loss: 0.635265, acc.: 65.62%] [G loss: 1.412757]\n",
      "epoch:17 step:16395 [D loss: 0.549451, acc.: 75.00%] [G loss: 1.306509]\n",
      "epoch:17 step:16396 [D loss: 0.560163, acc.: 71.09%] [G loss: 1.343604]\n",
      "epoch:17 step:16397 [D loss: 0.500126, acc.: 74.22%] [G loss: 1.324746]\n",
      "epoch:17 step:16398 [D loss: 0.627534, acc.: 65.62%] [G loss: 1.312559]\n",
      "epoch:17 step:16399 [D loss: 0.618855, acc.: 65.62%] [G loss: 1.276893]\n",
      "epoch:17 step:16400 [D loss: 0.626648, acc.: 67.19%] [G loss: 0.988907]\n",
      "epoch:17 step:16401 [D loss: 0.661337, acc.: 63.28%] [G loss: 1.087204]\n",
      "epoch:17 step:16402 [D loss: 0.486819, acc.: 79.69%] [G loss: 1.197335]\n",
      "epoch:17 step:16403 [D loss: 0.654678, acc.: 62.50%] [G loss: 1.342149]\n",
      "epoch:17 step:16404 [D loss: 0.531964, acc.: 75.00%] [G loss: 1.231735]\n",
      "epoch:17 step:16405 [D loss: 0.498308, acc.: 71.88%] [G loss: 1.133507]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:17 step:16406 [D loss: 0.438047, acc.: 82.81%] [G loss: 1.133016]\n",
      "epoch:17 step:16407 [D loss: 0.607037, acc.: 66.41%] [G loss: 1.176512]\n",
      "epoch:17 step:16408 [D loss: 0.508106, acc.: 76.56%] [G loss: 1.003542]\n",
      "epoch:17 step:16409 [D loss: 0.629957, acc.: 66.41%] [G loss: 0.940913]\n",
      "epoch:17 step:16410 [D loss: 0.683736, acc.: 56.25%] [G loss: 0.914182]\n",
      "epoch:17 step:16411 [D loss: 0.524185, acc.: 75.78%] [G loss: 1.068598]\n",
      "epoch:17 step:16412 [D loss: 0.654660, acc.: 57.81%] [G loss: 1.263417]\n",
      "epoch:17 step:16413 [D loss: 0.494701, acc.: 79.69%] [G loss: 1.458472]\n",
      "epoch:17 step:16414 [D loss: 0.638191, acc.: 57.81%] [G loss: 0.980477]\n",
      "epoch:17 step:16415 [D loss: 0.509586, acc.: 72.66%] [G loss: 1.244357]\n",
      "epoch:17 step:16416 [D loss: 0.502940, acc.: 77.34%] [G loss: 1.361979]\n",
      "epoch:17 step:16417 [D loss: 0.410112, acc.: 87.50%] [G loss: 1.238880]\n",
      "epoch:17 step:16418 [D loss: 0.544936, acc.: 73.44%] [G loss: 1.325950]\n",
      "epoch:17 step:16419 [D loss: 0.539787, acc.: 75.78%] [G loss: 1.302347]\n",
      "epoch:17 step:16420 [D loss: 0.477668, acc.: 80.47%] [G loss: 1.388593]\n",
      "epoch:17 step:16421 [D loss: 0.640886, acc.: 67.19%] [G loss: 1.099223]\n",
      "epoch:17 step:16422 [D loss: 0.644183, acc.: 64.84%] [G loss: 1.034478]\n",
      "epoch:17 step:16423 [D loss: 0.580960, acc.: 70.31%] [G loss: 1.173749]\n",
      "epoch:17 step:16424 [D loss: 0.590300, acc.: 67.19%] [G loss: 1.471469]\n",
      "epoch:17 step:16425 [D loss: 0.553371, acc.: 75.00%] [G loss: 1.289966]\n",
      "epoch:17 step:16426 [D loss: 0.538425, acc.: 73.44%] [G loss: 1.275459]\n",
      "epoch:17 step:16427 [D loss: 0.472514, acc.: 82.03%] [G loss: 1.340614]\n",
      "epoch:17 step:16428 [D loss: 0.447994, acc.: 78.91%] [G loss: 1.323613]\n",
      "epoch:17 step:16429 [D loss: 0.708493, acc.: 62.50%] [G loss: 1.209774]\n",
      "epoch:17 step:16430 [D loss: 0.610808, acc.: 68.75%] [G loss: 1.121177]\n",
      "epoch:17 step:16431 [D loss: 0.613356, acc.: 68.75%] [G loss: 1.190052]\n",
      "epoch:17 step:16432 [D loss: 0.545793, acc.: 68.75%] [G loss: 1.430440]\n",
      "epoch:17 step:16433 [D loss: 0.522697, acc.: 72.66%] [G loss: 1.090308]\n",
      "epoch:17 step:16434 [D loss: 0.536118, acc.: 75.00%] [G loss: 1.100038]\n",
      "epoch:17 step:16435 [D loss: 0.506776, acc.: 75.00%] [G loss: 1.277694]\n",
      "epoch:17 step:16436 [D loss: 0.569144, acc.: 67.97%] [G loss: 1.232262]\n",
      "epoch:17 step:16437 [D loss: 0.641506, acc.: 65.62%] [G loss: 1.268761]\n",
      "epoch:17 step:16438 [D loss: 0.519439, acc.: 75.78%] [G loss: 1.251632]\n",
      "epoch:17 step:16439 [D loss: 0.631893, acc.: 64.84%] [G loss: 1.311936]\n",
      "epoch:17 step:16440 [D loss: 0.671492, acc.: 62.50%] [G loss: 1.222641]\n",
      "epoch:17 step:16441 [D loss: 0.500363, acc.: 75.78%] [G loss: 1.191394]\n",
      "epoch:17 step:16442 [D loss: 0.647661, acc.: 62.50%] [G loss: 1.255594]\n",
      "epoch:17 step:16443 [D loss: 0.543035, acc.: 75.78%] [G loss: 1.386534]\n",
      "epoch:17 step:16444 [D loss: 0.697614, acc.: 59.38%] [G loss: 1.177045]\n",
      "epoch:17 step:16445 [D loss: 0.685974, acc.: 57.03%] [G loss: 1.411242]\n",
      "epoch:17 step:16446 [D loss: 0.503599, acc.: 75.78%] [G loss: 1.257503]\n",
      "epoch:17 step:16447 [D loss: 0.568060, acc.: 71.88%] [G loss: 1.190792]\n",
      "epoch:17 step:16448 [D loss: 0.513627, acc.: 75.00%] [G loss: 1.213346]\n",
      "epoch:17 step:16449 [D loss: 0.496933, acc.: 70.31%] [G loss: 1.259403]\n",
      "epoch:17 step:16450 [D loss: 0.576451, acc.: 64.06%] [G loss: 1.344647]\n",
      "epoch:17 step:16451 [D loss: 0.495377, acc.: 79.69%] [G loss: 1.091159]\n",
      "epoch:17 step:16452 [D loss: 0.627515, acc.: 64.84%] [G loss: 1.248654]\n",
      "epoch:17 step:16453 [D loss: 0.469437, acc.: 78.91%] [G loss: 1.452695]\n",
      "epoch:17 step:16454 [D loss: 0.576271, acc.: 72.66%] [G loss: 1.208081]\n",
      "epoch:17 step:16455 [D loss: 0.598618, acc.: 69.53%] [G loss: 1.119356]\n",
      "epoch:17 step:16456 [D loss: 0.564923, acc.: 69.53%] [G loss: 1.011093]\n",
      "epoch:17 step:16457 [D loss: 0.591708, acc.: 69.53%] [G loss: 1.088525]\n",
      "epoch:17 step:16458 [D loss: 0.490673, acc.: 75.78%] [G loss: 1.417378]\n",
      "epoch:17 step:16459 [D loss: 0.495251, acc.: 77.34%] [G loss: 1.340201]\n",
      "epoch:17 step:16460 [D loss: 0.495310, acc.: 75.78%] [G loss: 1.212604]\n",
      "epoch:17 step:16461 [D loss: 0.741008, acc.: 50.00%] [G loss: 1.080222]\n",
      "epoch:17 step:16462 [D loss: 0.612749, acc.: 64.84%] [G loss: 1.121911]\n",
      "epoch:17 step:16463 [D loss: 0.585952, acc.: 70.31%] [G loss: 1.092656]\n",
      "epoch:17 step:16464 [D loss: 0.463427, acc.: 81.25%] [G loss: 1.242053]\n",
      "epoch:17 step:16465 [D loss: 0.804759, acc.: 44.53%] [G loss: 1.053207]\n",
      "epoch:17 step:16466 [D loss: 0.566511, acc.: 70.31%] [G loss: 1.381816]\n",
      "epoch:17 step:16467 [D loss: 0.517867, acc.: 75.78%] [G loss: 0.982463]\n",
      "epoch:17 step:16468 [D loss: 0.460978, acc.: 82.03%] [G loss: 1.467823]\n",
      "epoch:17 step:16469 [D loss: 0.488352, acc.: 79.69%] [G loss: 1.164537]\n",
      "epoch:17 step:16470 [D loss: 0.536463, acc.: 78.91%] [G loss: 1.419535]\n",
      "epoch:17 step:16471 [D loss: 0.500914, acc.: 80.47%] [G loss: 1.456773]\n",
      "epoch:17 step:16472 [D loss: 0.677910, acc.: 54.69%] [G loss: 1.117280]\n",
      "epoch:17 step:16473 [D loss: 0.584965, acc.: 69.53%] [G loss: 1.494932]\n",
      "epoch:17 step:16474 [D loss: 0.561208, acc.: 72.66%] [G loss: 1.145665]\n",
      "epoch:17 step:16475 [D loss: 0.527317, acc.: 74.22%] [G loss: 1.304269]\n",
      "epoch:17 step:16476 [D loss: 0.711009, acc.: 53.12%] [G loss: 1.177531]\n",
      "epoch:17 step:16477 [D loss: 0.798027, acc.: 46.09%] [G loss: 0.878826]\n",
      "epoch:17 step:16478 [D loss: 0.565106, acc.: 65.62%] [G loss: 1.299884]\n",
      "epoch:17 step:16479 [D loss: 0.561241, acc.: 75.00%] [G loss: 1.379931]\n",
      "epoch:17 step:16480 [D loss: 0.683104, acc.: 60.16%] [G loss: 1.449739]\n",
      "epoch:17 step:16481 [D loss: 0.598437, acc.: 69.53%] [G loss: 1.174662]\n",
      "epoch:17 step:16482 [D loss: 0.592533, acc.: 68.75%] [G loss: 1.424721]\n",
      "epoch:17 step:16483 [D loss: 0.544918, acc.: 71.09%] [G loss: 1.161646]\n",
      "epoch:17 step:16484 [D loss: 0.550188, acc.: 71.88%] [G loss: 1.291104]\n",
      "epoch:17 step:16485 [D loss: 0.612678, acc.: 66.41%] [G loss: 1.088492]\n",
      "epoch:17 step:16486 [D loss: 0.420915, acc.: 85.94%] [G loss: 1.419105]\n",
      "epoch:17 step:16487 [D loss: 0.531935, acc.: 72.66%] [G loss: 1.336391]\n",
      "epoch:17 step:16488 [D loss: 0.670970, acc.: 63.28%] [G loss: 1.045690]\n",
      "epoch:17 step:16489 [D loss: 0.542713, acc.: 75.78%] [G loss: 1.226480]\n",
      "epoch:17 step:16490 [D loss: 0.608616, acc.: 69.53%] [G loss: 1.137024]\n",
      "epoch:17 step:16491 [D loss: 0.432949, acc.: 83.59%] [G loss: 1.468975]\n",
      "epoch:17 step:16492 [D loss: 0.698030, acc.: 59.38%] [G loss: 1.394869]\n",
      "epoch:17 step:16493 [D loss: 0.505032, acc.: 77.34%] [G loss: 1.288613]\n",
      "epoch:17 step:16494 [D loss: 0.554080, acc.: 71.09%] [G loss: 1.301116]\n",
      "epoch:17 step:16495 [D loss: 0.565700, acc.: 67.19%] [G loss: 1.298059]\n",
      "epoch:17 step:16496 [D loss: 0.519029, acc.: 74.22%] [G loss: 1.290023]\n",
      "epoch:17 step:16497 [D loss: 0.585060, acc.: 69.53%] [G loss: 1.211031]\n",
      "epoch:17 step:16498 [D loss: 0.571441, acc.: 71.09%] [G loss: 1.488897]\n",
      "epoch:17 step:16499 [D loss: 0.597269, acc.: 69.53%] [G loss: 1.218962]\n",
      "epoch:17 step:16500 [D loss: 0.516301, acc.: 73.44%] [G loss: 0.954995]\n",
      "epoch:17 step:16501 [D loss: 0.548198, acc.: 74.22%] [G loss: 1.261454]\n",
      "epoch:17 step:16502 [D loss: 0.457529, acc.: 80.47%] [G loss: 1.521670]\n",
      "epoch:17 step:16503 [D loss: 0.611302, acc.: 67.19%] [G loss: 1.101138]\n",
      "epoch:17 step:16504 [D loss: 0.494295, acc.: 74.22%] [G loss: 1.355460]\n",
      "epoch:17 step:16505 [D loss: 0.544521, acc.: 71.09%] [G loss: 1.360981]\n",
      "epoch:17 step:16506 [D loss: 0.671239, acc.: 55.47%] [G loss: 1.300555]\n",
      "epoch:17 step:16507 [D loss: 0.590766, acc.: 66.41%] [G loss: 1.025614]\n",
      "epoch:17 step:16508 [D loss: 0.598219, acc.: 70.31%] [G loss: 1.255050]\n",
      "epoch:17 step:16509 [D loss: 0.589410, acc.: 67.97%] [G loss: 1.625288]\n",
      "epoch:17 step:16510 [D loss: 0.576703, acc.: 68.75%] [G loss: 1.298111]\n",
      "epoch:17 step:16511 [D loss: 0.437919, acc.: 82.81%] [G loss: 1.400775]\n",
      "epoch:17 step:16512 [D loss: 0.571787, acc.: 71.88%] [G loss: 1.221234]\n",
      "epoch:17 step:16513 [D loss: 0.563812, acc.: 74.22%] [G loss: 1.274054]\n",
      "epoch:17 step:16514 [D loss: 0.665386, acc.: 61.72%] [G loss: 1.213508]\n",
      "epoch:17 step:16515 [D loss: 0.524827, acc.: 73.44%] [G loss: 1.426146]\n",
      "epoch:17 step:16516 [D loss: 0.549053, acc.: 71.88%] [G loss: 1.119868]\n",
      "epoch:17 step:16517 [D loss: 0.603332, acc.: 70.31%] [G loss: 1.432532]\n",
      "epoch:17 step:16518 [D loss: 0.658453, acc.: 63.28%] [G loss: 1.054938]\n",
      "epoch:17 step:16519 [D loss: 0.455689, acc.: 81.25%] [G loss: 1.408862]\n",
      "epoch:17 step:16520 [D loss: 0.485547, acc.: 81.25%] [G loss: 1.489434]\n",
      "epoch:17 step:16521 [D loss: 0.435140, acc.: 83.59%] [G loss: 1.527292]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:17 step:16522 [D loss: 0.763952, acc.: 50.00%] [G loss: 1.324659]\n",
      "epoch:17 step:16523 [D loss: 0.596787, acc.: 65.62%] [G loss: 1.453995]\n",
      "epoch:17 step:16524 [D loss: 0.508971, acc.: 76.56%] [G loss: 1.597582]\n",
      "epoch:17 step:16525 [D loss: 0.492775, acc.: 78.91%] [G loss: 1.383855]\n",
      "epoch:17 step:16526 [D loss: 0.515363, acc.: 78.12%] [G loss: 1.182825]\n",
      "epoch:17 step:16527 [D loss: 0.570809, acc.: 71.09%] [G loss: 1.367066]\n",
      "epoch:17 step:16528 [D loss: 0.457637, acc.: 85.16%] [G loss: 1.481310]\n",
      "epoch:17 step:16529 [D loss: 0.549113, acc.: 75.78%] [G loss: 1.474530]\n",
      "epoch:17 step:16530 [D loss: 0.838489, acc.: 46.09%] [G loss: 1.043129]\n",
      "epoch:17 step:16531 [D loss: 0.425418, acc.: 84.38%] [G loss: 1.384535]\n",
      "epoch:17 step:16532 [D loss: 0.662905, acc.: 58.59%] [G loss: 1.261919]\n",
      "epoch:17 step:16533 [D loss: 0.682447, acc.: 60.94%] [G loss: 1.515006]\n",
      "epoch:17 step:16534 [D loss: 0.710120, acc.: 58.59%] [G loss: 1.357708]\n",
      "epoch:17 step:16535 [D loss: 0.691444, acc.: 59.38%] [G loss: 1.097280]\n",
      "epoch:17 step:16536 [D loss: 0.544998, acc.: 75.78%] [G loss: 1.330823]\n",
      "epoch:17 step:16537 [D loss: 0.647076, acc.: 66.41%] [G loss: 1.247486]\n",
      "epoch:17 step:16538 [D loss: 0.506889, acc.: 76.56%] [G loss: 1.527909]\n",
      "epoch:17 step:16539 [D loss: 0.641996, acc.: 64.06%] [G loss: 1.468642]\n",
      "epoch:17 step:16540 [D loss: 0.745574, acc.: 51.56%] [G loss: 1.215524]\n",
      "epoch:17 step:16541 [D loss: 0.558232, acc.: 73.44%] [G loss: 1.652760]\n",
      "epoch:17 step:16542 [D loss: 0.516948, acc.: 75.00%] [G loss: 1.387603]\n",
      "epoch:17 step:16543 [D loss: 0.556283, acc.: 70.31%] [G loss: 1.342279]\n",
      "epoch:17 step:16544 [D loss: 0.538329, acc.: 78.12%] [G loss: 1.075455]\n",
      "epoch:17 step:16545 [D loss: 0.541085, acc.: 72.66%] [G loss: 1.610937]\n",
      "epoch:17 step:16546 [D loss: 0.585805, acc.: 71.09%] [G loss: 1.317122]\n",
      "epoch:17 step:16547 [D loss: 0.483410, acc.: 75.00%] [G loss: 1.599854]\n",
      "epoch:17 step:16548 [D loss: 0.733495, acc.: 60.16%] [G loss: 1.281929]\n",
      "epoch:17 step:16549 [D loss: 0.549630, acc.: 74.22%] [G loss: 1.051380]\n",
      "epoch:17 step:16550 [D loss: 0.638676, acc.: 63.28%] [G loss: 1.257250]\n",
      "epoch:17 step:16551 [D loss: 0.619054, acc.: 65.62%] [G loss: 1.033391]\n",
      "epoch:17 step:16552 [D loss: 0.600459, acc.: 67.19%] [G loss: 0.866725]\n",
      "epoch:17 step:16553 [D loss: 0.610681, acc.: 70.31%] [G loss: 1.077192]\n",
      "epoch:17 step:16554 [D loss: 0.627798, acc.: 67.19%] [G loss: 1.221062]\n",
      "epoch:17 step:16555 [D loss: 0.542094, acc.: 74.22%] [G loss: 1.453636]\n",
      "epoch:17 step:16556 [D loss: 0.499948, acc.: 78.91%] [G loss: 1.500008]\n",
      "epoch:17 step:16557 [D loss: 0.639623, acc.: 63.28%] [G loss: 1.070174]\n",
      "epoch:17 step:16558 [D loss: 0.601213, acc.: 67.97%] [G loss: 1.188765]\n",
      "epoch:17 step:16559 [D loss: 0.598629, acc.: 66.41%] [G loss: 1.465711]\n",
      "epoch:17 step:16560 [D loss: 0.493166, acc.: 75.78%] [G loss: 1.096051]\n",
      "epoch:17 step:16561 [D loss: 0.465409, acc.: 81.25%] [G loss: 1.294939]\n",
      "epoch:17 step:16562 [D loss: 0.552088, acc.: 72.66%] [G loss: 1.493754]\n",
      "epoch:17 step:16563 [D loss: 0.540521, acc.: 72.66%] [G loss: 1.236945]\n",
      "epoch:17 step:16564 [D loss: 0.525055, acc.: 76.56%] [G loss: 1.318305]\n",
      "epoch:17 step:16565 [D loss: 0.525729, acc.: 70.31%] [G loss: 1.123319]\n",
      "epoch:17 step:16566 [D loss: 0.740054, acc.: 54.69%] [G loss: 0.988767]\n",
      "epoch:17 step:16567 [D loss: 0.586186, acc.: 67.19%] [G loss: 1.112989]\n",
      "epoch:17 step:16568 [D loss: 0.559014, acc.: 71.09%] [G loss: 1.242611]\n",
      "epoch:17 step:16569 [D loss: 0.494398, acc.: 72.66%] [G loss: 1.518896]\n",
      "epoch:17 step:16570 [D loss: 0.629630, acc.: 64.06%] [G loss: 0.894744]\n",
      "epoch:17 step:16571 [D loss: 0.593619, acc.: 68.75%] [G loss: 0.993441]\n",
      "epoch:17 step:16572 [D loss: 0.829271, acc.: 42.97%] [G loss: 1.014586]\n",
      "epoch:17 step:16573 [D loss: 0.593125, acc.: 67.97%] [G loss: 1.124629]\n",
      "epoch:17 step:16574 [D loss: 0.541650, acc.: 76.56%] [G loss: 1.501227]\n",
      "epoch:17 step:16575 [D loss: 0.563893, acc.: 67.97%] [G loss: 1.213435]\n",
      "epoch:17 step:16576 [D loss: 0.503275, acc.: 80.47%] [G loss: 1.301199]\n",
      "epoch:17 step:16577 [D loss: 0.491864, acc.: 79.69%] [G loss: 1.452593]\n",
      "epoch:17 step:16578 [D loss: 0.612247, acc.: 69.53%] [G loss: 0.776990]\n",
      "epoch:17 step:16579 [D loss: 0.563669, acc.: 71.88%] [G loss: 1.325405]\n",
      "epoch:17 step:16580 [D loss: 0.446221, acc.: 83.59%] [G loss: 1.552445]\n",
      "epoch:17 step:16581 [D loss: 0.596131, acc.: 70.31%] [G loss: 1.242680]\n",
      "epoch:17 step:16582 [D loss: 0.633060, acc.: 66.41%] [G loss: 1.108006]\n",
      "epoch:17 step:16583 [D loss: 0.583003, acc.: 73.44%] [G loss: 1.112354]\n",
      "epoch:17 step:16584 [D loss: 0.581550, acc.: 66.41%] [G loss: 1.268138]\n",
      "epoch:17 step:16585 [D loss: 0.640700, acc.: 66.41%] [G loss: 1.253025]\n",
      "epoch:17 step:16586 [D loss: 0.537275, acc.: 71.88%] [G loss: 1.440300]\n",
      "epoch:17 step:16587 [D loss: 0.712349, acc.: 60.16%] [G loss: 1.122104]\n",
      "epoch:17 step:16588 [D loss: 0.532046, acc.: 75.78%] [G loss: 1.378515]\n",
      "epoch:17 step:16589 [D loss: 0.507803, acc.: 76.56%] [G loss: 1.233653]\n",
      "epoch:17 step:16590 [D loss: 0.551784, acc.: 71.09%] [G loss: 1.007024]\n",
      "epoch:17 step:16591 [D loss: 0.511414, acc.: 79.69%] [G loss: 1.099701]\n",
      "epoch:17 step:16592 [D loss: 0.674656, acc.: 60.94%] [G loss: 0.988911]\n",
      "epoch:17 step:16593 [D loss: 0.601871, acc.: 68.75%] [G loss: 1.102868]\n",
      "epoch:17 step:16594 [D loss: 0.700009, acc.: 59.38%] [G loss: 0.971532]\n",
      "epoch:17 step:16595 [D loss: 0.550308, acc.: 73.44%] [G loss: 1.188565]\n",
      "epoch:17 step:16596 [D loss: 0.520045, acc.: 71.88%] [G loss: 1.250707]\n",
      "epoch:17 step:16597 [D loss: 0.613538, acc.: 64.84%] [G loss: 1.239986]\n",
      "epoch:17 step:16598 [D loss: 0.434241, acc.: 84.38%] [G loss: 1.393523]\n",
      "epoch:17 step:16599 [D loss: 0.480060, acc.: 77.34%] [G loss: 1.435657]\n",
      "epoch:17 step:16600 [D loss: 0.548881, acc.: 71.09%] [G loss: 1.140126]\n",
      "epoch:17 step:16601 [D loss: 0.442007, acc.: 78.91%] [G loss: 1.263582]\n",
      "epoch:17 step:16602 [D loss: 0.795773, acc.: 45.31%] [G loss: 1.196863]\n",
      "epoch:17 step:16603 [D loss: 0.629112, acc.: 65.62%] [G loss: 1.033430]\n",
      "epoch:17 step:16604 [D loss: 0.600442, acc.: 64.06%] [G loss: 1.134332]\n",
      "epoch:17 step:16605 [D loss: 0.572343, acc.: 71.88%] [G loss: 1.412040]\n",
      "epoch:17 step:16606 [D loss: 0.414037, acc.: 83.59%] [G loss: 1.453086]\n",
      "epoch:17 step:16607 [D loss: 0.642201, acc.: 64.06%] [G loss: 1.074047]\n",
      "epoch:17 step:16608 [D loss: 0.584444, acc.: 67.19%] [G loss: 1.343529]\n",
      "epoch:17 step:16609 [D loss: 0.578464, acc.: 67.97%] [G loss: 1.383008]\n",
      "epoch:17 step:16610 [D loss: 0.490049, acc.: 80.47%] [G loss: 1.299315]\n",
      "epoch:17 step:16611 [D loss: 0.511561, acc.: 75.00%] [G loss: 1.235690]\n",
      "epoch:17 step:16612 [D loss: 0.634896, acc.: 67.19%] [G loss: 1.368814]\n",
      "epoch:17 step:16613 [D loss: 0.667418, acc.: 60.16%] [G loss: 1.216167]\n",
      "epoch:17 step:16614 [D loss: 0.546651, acc.: 71.88%] [G loss: 1.497482]\n",
      "epoch:17 step:16615 [D loss: 0.461153, acc.: 81.25%] [G loss: 1.240356]\n",
      "epoch:17 step:16616 [D loss: 0.489491, acc.: 78.12%] [G loss: 1.645175]\n",
      "epoch:17 step:16617 [D loss: 0.639156, acc.: 65.62%] [G loss: 1.273040]\n",
      "epoch:17 step:16618 [D loss: 0.765671, acc.: 48.44%] [G loss: 1.469569]\n",
      "epoch:17 step:16619 [D loss: 0.528404, acc.: 72.66%] [G loss: 1.270917]\n",
      "epoch:17 step:16620 [D loss: 0.632639, acc.: 63.28%] [G loss: 1.316055]\n",
      "epoch:17 step:16621 [D loss: 0.575877, acc.: 71.88%] [G loss: 1.212398]\n",
      "epoch:17 step:16622 [D loss: 0.782308, acc.: 57.03%] [G loss: 1.078881]\n",
      "epoch:17 step:16623 [D loss: 0.657006, acc.: 66.41%] [G loss: 1.177909]\n",
      "epoch:17 step:16624 [D loss: 0.608461, acc.: 64.84%] [G loss: 1.152111]\n",
      "epoch:17 step:16625 [D loss: 0.637562, acc.: 63.28%] [G loss: 1.341619]\n",
      "epoch:17 step:16626 [D loss: 0.568868, acc.: 65.62%] [G loss: 1.453741]\n",
      "epoch:17 step:16627 [D loss: 0.601716, acc.: 64.84%] [G loss: 1.257227]\n",
      "epoch:17 step:16628 [D loss: 0.738751, acc.: 54.69%] [G loss: 1.227375]\n",
      "epoch:17 step:16629 [D loss: 0.642744, acc.: 63.28%] [G loss: 1.088734]\n",
      "epoch:17 step:16630 [D loss: 0.499668, acc.: 76.56%] [G loss: 1.319062]\n",
      "epoch:17 step:16631 [D loss: 0.535211, acc.: 72.66%] [G loss: 1.228784]\n",
      "epoch:17 step:16632 [D loss: 0.656024, acc.: 63.28%] [G loss: 1.467393]\n",
      "epoch:17 step:16633 [D loss: 0.589977, acc.: 65.62%] [G loss: 1.533395]\n",
      "epoch:17 step:16634 [D loss: 0.638545, acc.: 63.28%] [G loss: 1.381036]\n",
      "epoch:17 step:16635 [D loss: 0.528911, acc.: 73.44%] [G loss: 1.362756]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:17 step:16636 [D loss: 0.621826, acc.: 62.50%] [G loss: 1.281952]\n",
      "epoch:17 step:16637 [D loss: 0.511925, acc.: 75.00%] [G loss: 1.467722]\n",
      "epoch:17 step:16638 [D loss: 0.746475, acc.: 52.34%] [G loss: 1.030578]\n",
      "epoch:17 step:16639 [D loss: 0.495022, acc.: 76.56%] [G loss: 1.232206]\n",
      "epoch:17 step:16640 [D loss: 0.515042, acc.: 75.78%] [G loss: 1.088858]\n",
      "epoch:17 step:16641 [D loss: 0.461176, acc.: 79.69%] [G loss: 1.188334]\n",
      "epoch:17 step:16642 [D loss: 0.725955, acc.: 64.84%] [G loss: 1.184069]\n",
      "epoch:17 step:16643 [D loss: 0.668780, acc.: 64.84%] [G loss: 1.144835]\n",
      "epoch:17 step:16644 [D loss: 0.571892, acc.: 73.44%] [G loss: 1.141554]\n",
      "epoch:17 step:16645 [D loss: 0.588852, acc.: 68.75%] [G loss: 1.240138]\n",
      "epoch:17 step:16646 [D loss: 0.511813, acc.: 76.56%] [G loss: 1.134979]\n",
      "epoch:17 step:16647 [D loss: 0.473847, acc.: 79.69%] [G loss: 1.200421]\n",
      "epoch:17 step:16648 [D loss: 0.670239, acc.: 57.03%] [G loss: 1.279667]\n",
      "epoch:17 step:16649 [D loss: 0.605021, acc.: 66.41%] [G loss: 1.163306]\n",
      "epoch:17 step:16650 [D loss: 0.615680, acc.: 64.84%] [G loss: 1.326985]\n",
      "epoch:17 step:16651 [D loss: 0.482358, acc.: 77.34%] [G loss: 1.258090]\n",
      "epoch:17 step:16652 [D loss: 0.488322, acc.: 75.00%] [G loss: 0.972615]\n",
      "epoch:17 step:16653 [D loss: 0.519199, acc.: 71.88%] [G loss: 1.125863]\n",
      "epoch:17 step:16654 [D loss: 0.521630, acc.: 72.66%] [G loss: 1.397231]\n",
      "epoch:17 step:16655 [D loss: 0.517131, acc.: 72.66%] [G loss: 1.233528]\n",
      "epoch:17 step:16656 [D loss: 0.497361, acc.: 77.34%] [G loss: 1.503321]\n",
      "epoch:17 step:16657 [D loss: 0.536885, acc.: 70.31%] [G loss: 1.250905]\n",
      "epoch:17 step:16658 [D loss: 0.527419, acc.: 73.44%] [G loss: 1.281524]\n",
      "epoch:17 step:16659 [D loss: 0.654048, acc.: 60.94%] [G loss: 1.258446]\n",
      "epoch:17 step:16660 [D loss: 0.598970, acc.: 66.41%] [G loss: 1.374608]\n",
      "epoch:17 step:16661 [D loss: 0.557521, acc.: 72.66%] [G loss: 1.242591]\n",
      "epoch:17 step:16662 [D loss: 0.536097, acc.: 65.62%] [G loss: 1.205087]\n",
      "epoch:17 step:16663 [D loss: 0.483861, acc.: 82.03%] [G loss: 1.333957]\n",
      "epoch:17 step:16664 [D loss: 0.631649, acc.: 64.06%] [G loss: 1.088161]\n",
      "epoch:17 step:16665 [D loss: 0.607314, acc.: 64.84%] [G loss: 1.128525]\n",
      "epoch:17 step:16666 [D loss: 0.562838, acc.: 69.53%] [G loss: 1.117951]\n",
      "epoch:17 step:16667 [D loss: 0.576942, acc.: 68.75%] [G loss: 1.115761]\n",
      "epoch:17 step:16668 [D loss: 0.566803, acc.: 74.22%] [G loss: 1.264631]\n",
      "epoch:17 step:16669 [D loss: 0.482164, acc.: 81.25%] [G loss: 1.365090]\n",
      "epoch:17 step:16670 [D loss: 0.601321, acc.: 65.62%] [G loss: 1.091352]\n",
      "epoch:17 step:16671 [D loss: 0.498540, acc.: 77.34%] [G loss: 1.242822]\n",
      "epoch:17 step:16672 [D loss: 0.644486, acc.: 61.72%] [G loss: 1.381553]\n",
      "epoch:17 step:16673 [D loss: 0.573986, acc.: 75.00%] [G loss: 1.477929]\n",
      "epoch:17 step:16674 [D loss: 0.460120, acc.: 81.25%] [G loss: 1.362008]\n",
      "epoch:17 step:16675 [D loss: 0.450998, acc.: 78.91%] [G loss: 1.159289]\n",
      "epoch:17 step:16676 [D loss: 0.635370, acc.: 69.53%] [G loss: 1.096446]\n",
      "epoch:17 step:16677 [D loss: 0.675214, acc.: 60.16%] [G loss: 1.310603]\n",
      "epoch:17 step:16678 [D loss: 0.569016, acc.: 66.41%] [G loss: 1.532854]\n",
      "epoch:17 step:16679 [D loss: 0.654033, acc.: 61.72%] [G loss: 1.643465]\n",
      "epoch:17 step:16680 [D loss: 0.531335, acc.: 71.88%] [G loss: 1.476578]\n",
      "epoch:17 step:16681 [D loss: 0.557456, acc.: 71.09%] [G loss: 1.380989]\n",
      "epoch:17 step:16682 [D loss: 0.633995, acc.: 65.62%] [G loss: 0.906960]\n",
      "epoch:17 step:16683 [D loss: 0.435490, acc.: 85.94%] [G loss: 1.444746]\n",
      "epoch:17 step:16684 [D loss: 0.604954, acc.: 65.62%] [G loss: 1.278905]\n",
      "epoch:17 step:16685 [D loss: 0.650988, acc.: 60.16%] [G loss: 1.103862]\n",
      "epoch:17 step:16686 [D loss: 0.431208, acc.: 82.81%] [G loss: 1.571615]\n",
      "epoch:17 step:16687 [D loss: 0.533185, acc.: 79.69%] [G loss: 1.519557]\n",
      "epoch:17 step:16688 [D loss: 0.496272, acc.: 77.34%] [G loss: 1.336820]\n",
      "epoch:17 step:16689 [D loss: 0.538496, acc.: 75.00%] [G loss: 1.523485]\n",
      "epoch:17 step:16690 [D loss: 0.674977, acc.: 61.72%] [G loss: 1.122154]\n",
      "epoch:17 step:16691 [D loss: 0.534531, acc.: 75.00%] [G loss: 1.056103]\n",
      "epoch:17 step:16692 [D loss: 0.507465, acc.: 79.69%] [G loss: 1.188500]\n",
      "epoch:17 step:16693 [D loss: 0.521349, acc.: 76.56%] [G loss: 1.294041]\n",
      "epoch:17 step:16694 [D loss: 0.417862, acc.: 85.94%] [G loss: 1.306374]\n",
      "epoch:17 step:16695 [D loss: 0.468110, acc.: 80.47%] [G loss: 1.320189]\n",
      "epoch:17 step:16696 [D loss: 0.576450, acc.: 69.53%] [G loss: 0.968783]\n",
      "epoch:17 step:16697 [D loss: 0.573690, acc.: 70.31%] [G loss: 1.335625]\n",
      "epoch:17 step:16698 [D loss: 0.535705, acc.: 75.78%] [G loss: 1.182677]\n",
      "epoch:17 step:16699 [D loss: 0.523990, acc.: 77.34%] [G loss: 1.272517]\n",
      "epoch:17 step:16700 [D loss: 0.477178, acc.: 81.25%] [G loss: 1.333311]\n",
      "epoch:17 step:16701 [D loss: 0.360835, acc.: 90.62%] [G loss: 1.609269]\n",
      "epoch:17 step:16702 [D loss: 0.620403, acc.: 68.75%] [G loss: 1.440089]\n",
      "epoch:17 step:16703 [D loss: 0.512168, acc.: 75.00%] [G loss: 1.256920]\n",
      "epoch:17 step:16704 [D loss: 0.519184, acc.: 72.66%] [G loss: 1.338835]\n",
      "epoch:17 step:16705 [D loss: 0.548364, acc.: 70.31%] [G loss: 1.277190]\n",
      "epoch:17 step:16706 [D loss: 0.494142, acc.: 78.91%] [G loss: 1.449712]\n",
      "epoch:17 step:16707 [D loss: 0.593806, acc.: 72.66%] [G loss: 1.476168]\n",
      "epoch:17 step:16708 [D loss: 0.617613, acc.: 64.84%] [G loss: 1.289973]\n",
      "epoch:17 step:16709 [D loss: 0.664990, acc.: 56.25%] [G loss: 1.085974]\n",
      "epoch:17 step:16710 [D loss: 0.516831, acc.: 73.44%] [G loss: 1.312463]\n",
      "epoch:17 step:16711 [D loss: 0.600852, acc.: 68.75%] [G loss: 1.101010]\n",
      "epoch:17 step:16712 [D loss: 0.672385, acc.: 60.94%] [G loss: 1.394400]\n",
      "epoch:17 step:16713 [D loss: 0.595934, acc.: 65.62%] [G loss: 1.593836]\n",
      "epoch:17 step:16714 [D loss: 0.487313, acc.: 75.00%] [G loss: 1.237377]\n",
      "epoch:17 step:16715 [D loss: 0.617106, acc.: 66.41%] [G loss: 1.313450]\n",
      "epoch:17 step:16716 [D loss: 0.596794, acc.: 67.19%] [G loss: 1.363164]\n",
      "epoch:17 step:16717 [D loss: 0.639659, acc.: 61.72%] [G loss: 1.530028]\n",
      "epoch:17 step:16718 [D loss: 0.627684, acc.: 65.62%] [G loss: 1.345777]\n",
      "epoch:17 step:16719 [D loss: 0.648970, acc.: 63.28%] [G loss: 1.337045]\n",
      "epoch:17 step:16720 [D loss: 0.549283, acc.: 71.88%] [G loss: 1.452364]\n",
      "epoch:17 step:16721 [D loss: 0.531430, acc.: 75.00%] [G loss: 1.222247]\n",
      "epoch:17 step:16722 [D loss: 0.382104, acc.: 89.06%] [G loss: 1.214734]\n",
      "epoch:17 step:16723 [D loss: 0.456779, acc.: 82.81%] [G loss: 1.748803]\n",
      "epoch:17 step:16724 [D loss: 0.538584, acc.: 71.88%] [G loss: 1.414579]\n",
      "epoch:17 step:16725 [D loss: 0.477664, acc.: 78.91%] [G loss: 1.511607]\n",
      "epoch:17 step:16726 [D loss: 0.495910, acc.: 75.00%] [G loss: 1.319334]\n",
      "epoch:17 step:16727 [D loss: 0.603778, acc.: 64.84%] [G loss: 1.097971]\n",
      "epoch:17 step:16728 [D loss: 0.501944, acc.: 75.78%] [G loss: 1.158095]\n",
      "epoch:17 step:16729 [D loss: 0.591855, acc.: 71.88%] [G loss: 1.396891]\n",
      "epoch:17 step:16730 [D loss: 0.575922, acc.: 68.75%] [G loss: 0.941820]\n",
      "epoch:17 step:16731 [D loss: 0.628518, acc.: 59.38%] [G loss: 1.142004]\n",
      "epoch:17 step:16732 [D loss: 0.485595, acc.: 78.91%] [G loss: 1.274731]\n",
      "epoch:17 step:16733 [D loss: 0.613219, acc.: 66.41%] [G loss: 1.333104]\n",
      "epoch:17 step:16734 [D loss: 0.630702, acc.: 64.84%] [G loss: 1.336072]\n",
      "epoch:17 step:16735 [D loss: 0.481707, acc.: 75.78%] [G loss: 1.083208]\n",
      "epoch:17 step:16736 [D loss: 0.682524, acc.: 59.38%] [G loss: 1.340229]\n",
      "epoch:17 step:16737 [D loss: 0.613187, acc.: 64.84%] [G loss: 1.172209]\n",
      "epoch:17 step:16738 [D loss: 0.640098, acc.: 62.50%] [G loss: 1.403851]\n",
      "epoch:17 step:16739 [D loss: 0.529388, acc.: 76.56%] [G loss: 1.727988]\n",
      "epoch:17 step:16740 [D loss: 0.597842, acc.: 59.38%] [G loss: 1.148850]\n",
      "epoch:17 step:16741 [D loss: 0.523915, acc.: 78.91%] [G loss: 1.475950]\n",
      "epoch:17 step:16742 [D loss: 0.750881, acc.: 56.25%] [G loss: 1.062282]\n",
      "epoch:17 step:16743 [D loss: 0.444334, acc.: 83.59%] [G loss: 1.453280]\n",
      "epoch:17 step:16744 [D loss: 0.615718, acc.: 69.53%] [G loss: 1.594947]\n",
      "epoch:17 step:16745 [D loss: 0.561727, acc.: 71.88%] [G loss: 1.508963]\n",
      "epoch:17 step:16746 [D loss: 0.678218, acc.: 64.84%] [G loss: 1.159225]\n",
      "epoch:17 step:16747 [D loss: 0.531663, acc.: 74.22%] [G loss: 1.649501]\n",
      "epoch:17 step:16748 [D loss: 0.555915, acc.: 72.66%] [G loss: 1.355684]\n",
      "epoch:17 step:16749 [D loss: 0.517252, acc.: 71.09%] [G loss: 1.303371]\n",
      "epoch:17 step:16750 [D loss: 0.467702, acc.: 78.91%] [G loss: 1.357224]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:17 step:16751 [D loss: 0.566570, acc.: 72.66%] [G loss: 1.256246]\n",
      "epoch:17 step:16752 [D loss: 0.638013, acc.: 67.97%] [G loss: 1.200795]\n",
      "epoch:17 step:16753 [D loss: 0.632324, acc.: 65.62%] [G loss: 1.365430]\n",
      "epoch:17 step:16754 [D loss: 0.615551, acc.: 65.62%] [G loss: 1.197607]\n",
      "epoch:17 step:16755 [D loss: 0.663769, acc.: 57.03%] [G loss: 1.202566]\n",
      "epoch:17 step:16756 [D loss: 0.600832, acc.: 68.75%] [G loss: 1.569170]\n",
      "epoch:17 step:16757 [D loss: 0.683472, acc.: 61.72%] [G loss: 1.368555]\n",
      "epoch:17 step:16758 [D loss: 0.628934, acc.: 61.72%] [G loss: 1.056349]\n",
      "epoch:17 step:16759 [D loss: 0.539772, acc.: 74.22%] [G loss: 1.282784]\n",
      "epoch:17 step:16760 [D loss: 0.665446, acc.: 63.28%] [G loss: 1.285334]\n",
      "epoch:17 step:16761 [D loss: 0.513880, acc.: 75.78%] [G loss: 1.576414]\n",
      "epoch:17 step:16762 [D loss: 0.577509, acc.: 72.66%] [G loss: 1.338346]\n",
      "epoch:17 step:16763 [D loss: 0.503191, acc.: 76.56%] [G loss: 1.636135]\n",
      "epoch:17 step:16764 [D loss: 0.611434, acc.: 71.88%] [G loss: 1.179653]\n",
      "epoch:17 step:16765 [D loss: 0.646528, acc.: 61.72%] [G loss: 1.452136]\n",
      "epoch:17 step:16766 [D loss: 0.618198, acc.: 63.28%] [G loss: 1.078837]\n",
      "epoch:17 step:16767 [D loss: 0.570511, acc.: 65.62%] [G loss: 1.085683]\n",
      "epoch:17 step:16768 [D loss: 0.545882, acc.: 69.53%] [G loss: 1.198287]\n",
      "epoch:17 step:16769 [D loss: 0.493086, acc.: 77.34%] [G loss: 1.605803]\n",
      "epoch:17 step:16770 [D loss: 0.507648, acc.: 75.00%] [G loss: 1.458509]\n",
      "epoch:17 step:16771 [D loss: 0.668936, acc.: 65.62%] [G loss: 1.256705]\n",
      "epoch:17 step:16772 [D loss: 0.623576, acc.: 67.19%] [G loss: 1.056765]\n",
      "epoch:17 step:16773 [D loss: 0.602399, acc.: 68.75%] [G loss: 1.239516]\n",
      "epoch:17 step:16774 [D loss: 0.581266, acc.: 67.97%] [G loss: 1.277962]\n",
      "epoch:17 step:16775 [D loss: 0.632172, acc.: 63.28%] [G loss: 0.971048]\n",
      "epoch:17 step:16776 [D loss: 0.620616, acc.: 63.28%] [G loss: 0.944401]\n",
      "epoch:17 step:16777 [D loss: 0.537721, acc.: 75.00%] [G loss: 1.436653]\n",
      "epoch:17 step:16778 [D loss: 0.607204, acc.: 67.19%] [G loss: 1.057150]\n",
      "epoch:17 step:16779 [D loss: 0.599727, acc.: 71.09%] [G loss: 1.103563]\n",
      "epoch:17 step:16780 [D loss: 0.690748, acc.: 61.72%] [G loss: 1.194601]\n",
      "epoch:17 step:16781 [D loss: 0.479940, acc.: 73.44%] [G loss: 1.352333]\n",
      "epoch:17 step:16782 [D loss: 0.581241, acc.: 66.41%] [G loss: 1.272976]\n",
      "epoch:17 step:16783 [D loss: 0.697813, acc.: 56.25%] [G loss: 0.890019]\n",
      "epoch:17 step:16784 [D loss: 0.523142, acc.: 76.56%] [G loss: 1.234887]\n",
      "epoch:17 step:16785 [D loss: 0.543323, acc.: 73.44%] [G loss: 0.966868]\n",
      "epoch:17 step:16786 [D loss: 0.527562, acc.: 75.78%] [G loss: 1.253716]\n",
      "epoch:17 step:16787 [D loss: 0.473934, acc.: 78.91%] [G loss: 1.118528]\n",
      "epoch:17 step:16788 [D loss: 0.468286, acc.: 76.56%] [G loss: 1.326771]\n",
      "epoch:17 step:16789 [D loss: 0.523844, acc.: 75.00%] [G loss: 1.144879]\n",
      "epoch:17 step:16790 [D loss: 0.599373, acc.: 71.09%] [G loss: 1.194073]\n",
      "epoch:17 step:16791 [D loss: 0.627727, acc.: 66.41%] [G loss: 1.292652]\n",
      "epoch:17 step:16792 [D loss: 0.633338, acc.: 64.06%] [G loss: 1.731505]\n",
      "epoch:17 step:16793 [D loss: 0.614440, acc.: 70.31%] [G loss: 1.250851]\n",
      "epoch:17 step:16794 [D loss: 0.604089, acc.: 69.53%] [G loss: 1.083277]\n",
      "epoch:17 step:16795 [D loss: 0.445386, acc.: 78.12%] [G loss: 1.451466]\n",
      "epoch:17 step:16796 [D loss: 0.698209, acc.: 59.38%] [G loss: 1.112089]\n",
      "epoch:17 step:16797 [D loss: 0.534890, acc.: 72.66%] [G loss: 1.184243]\n",
      "epoch:17 step:16798 [D loss: 0.524646, acc.: 73.44%] [G loss: 1.038968]\n",
      "epoch:17 step:16799 [D loss: 0.535528, acc.: 69.53%] [G loss: 1.355219]\n",
      "epoch:17 step:16800 [D loss: 0.644980, acc.: 62.50%] [G loss: 1.380112]\n",
      "epoch:17 step:16801 [D loss: 0.606170, acc.: 67.97%] [G loss: 1.424621]\n",
      "epoch:17 step:16802 [D loss: 0.396474, acc.: 82.81%] [G loss: 1.395514]\n",
      "epoch:17 step:16803 [D loss: 0.480507, acc.: 81.25%] [G loss: 1.178931]\n",
      "epoch:17 step:16804 [D loss: 0.494979, acc.: 80.47%] [G loss: 1.090025]\n",
      "epoch:17 step:16805 [D loss: 0.713827, acc.: 55.47%] [G loss: 0.983194]\n",
      "epoch:17 step:16806 [D loss: 0.425155, acc.: 84.38%] [G loss: 1.663578]\n",
      "epoch:17 step:16807 [D loss: 0.585189, acc.: 61.72%] [G loss: 1.145322]\n",
      "epoch:17 step:16808 [D loss: 0.641204, acc.: 63.28%] [G loss: 1.407125]\n",
      "epoch:17 step:16809 [D loss: 0.456012, acc.: 82.81%] [G loss: 1.443645]\n",
      "epoch:17 step:16810 [D loss: 0.584213, acc.: 72.66%] [G loss: 1.352513]\n",
      "epoch:17 step:16811 [D loss: 0.513941, acc.: 73.44%] [G loss: 1.237127]\n",
      "epoch:17 step:16812 [D loss: 0.623498, acc.: 63.28%] [G loss: 1.370928]\n",
      "epoch:17 step:16813 [D loss: 0.591897, acc.: 65.62%] [G loss: 1.163260]\n",
      "epoch:17 step:16814 [D loss: 0.483756, acc.: 77.34%] [G loss: 1.309763]\n",
      "epoch:17 step:16815 [D loss: 0.565045, acc.: 69.53%] [G loss: 1.272373]\n",
      "epoch:17 step:16816 [D loss: 0.699281, acc.: 60.94%] [G loss: 1.182387]\n",
      "epoch:17 step:16817 [D loss: 0.617259, acc.: 65.62%] [G loss: 1.062954]\n",
      "epoch:17 step:16818 [D loss: 0.564752, acc.: 77.34%] [G loss: 1.230216]\n",
      "epoch:17 step:16819 [D loss: 0.585450, acc.: 71.88%] [G loss: 1.454605]\n",
      "epoch:17 step:16820 [D loss: 0.569726, acc.: 73.44%] [G loss: 0.893592]\n",
      "epoch:17 step:16821 [D loss: 0.510777, acc.: 75.00%] [G loss: 1.495723]\n",
      "epoch:17 step:16822 [D loss: 0.559671, acc.: 69.53%] [G loss: 1.274314]\n",
      "epoch:17 step:16823 [D loss: 0.567982, acc.: 75.78%] [G loss: 1.136556]\n",
      "epoch:17 step:16824 [D loss: 0.569279, acc.: 69.53%] [G loss: 1.358271]\n",
      "epoch:17 step:16825 [D loss: 0.498775, acc.: 74.22%] [G loss: 1.634694]\n",
      "epoch:17 step:16826 [D loss: 0.544706, acc.: 72.66%] [G loss: 1.457022]\n",
      "epoch:17 step:16827 [D loss: 0.477735, acc.: 78.91%] [G loss: 1.455227]\n",
      "epoch:17 step:16828 [D loss: 0.576045, acc.: 64.06%] [G loss: 1.338720]\n",
      "epoch:17 step:16829 [D loss: 0.430391, acc.: 80.47%] [G loss: 1.428297]\n",
      "epoch:17 step:16830 [D loss: 0.472857, acc.: 82.03%] [G loss: 1.112695]\n",
      "epoch:17 step:16831 [D loss: 0.639654, acc.: 66.41%] [G loss: 1.139269]\n",
      "epoch:17 step:16832 [D loss: 0.537015, acc.: 76.56%] [G loss: 1.480397]\n",
      "epoch:17 step:16833 [D loss: 0.559759, acc.: 74.22%] [G loss: 1.036499]\n",
      "epoch:17 step:16834 [D loss: 0.545304, acc.: 71.09%] [G loss: 1.172256]\n",
      "epoch:17 step:16835 [D loss: 0.550923, acc.: 71.09%] [G loss: 1.219799]\n",
      "epoch:17 step:16836 [D loss: 0.649159, acc.: 63.28%] [G loss: 1.265361]\n",
      "epoch:17 step:16837 [D loss: 0.578489, acc.: 67.97%] [G loss: 1.023933]\n",
      "epoch:17 step:16838 [D loss: 0.559860, acc.: 69.53%] [G loss: 1.099665]\n",
      "epoch:17 step:16839 [D loss: 0.525026, acc.: 78.12%] [G loss: 1.108138]\n",
      "epoch:17 step:16840 [D loss: 0.590271, acc.: 67.19%] [G loss: 1.137968]\n",
      "epoch:17 step:16841 [D loss: 0.555048, acc.: 75.00%] [G loss: 1.219230]\n",
      "epoch:17 step:16842 [D loss: 0.702241, acc.: 56.25%] [G loss: 1.191061]\n",
      "epoch:17 step:16843 [D loss: 0.493069, acc.: 75.00%] [G loss: 1.513300]\n",
      "epoch:17 step:16844 [D loss: 0.547742, acc.: 70.31%] [G loss: 1.430381]\n",
      "epoch:17 step:16845 [D loss: 0.617862, acc.: 67.19%] [G loss: 1.363010]\n",
      "epoch:17 step:16846 [D loss: 0.517807, acc.: 73.44%] [G loss: 1.144891]\n",
      "epoch:17 step:16847 [D loss: 0.511593, acc.: 76.56%] [G loss: 1.341211]\n",
      "epoch:17 step:16848 [D loss: 0.565293, acc.: 71.09%] [G loss: 1.391643]\n",
      "epoch:17 step:16849 [D loss: 0.526996, acc.: 75.00%] [G loss: 1.521839]\n",
      "epoch:17 step:16850 [D loss: 0.633776, acc.: 63.28%] [G loss: 1.159787]\n",
      "epoch:17 step:16851 [D loss: 0.643997, acc.: 64.06%] [G loss: 1.018692]\n",
      "epoch:17 step:16852 [D loss: 0.535616, acc.: 75.78%] [G loss: 1.317955]\n",
      "epoch:17 step:16853 [D loss: 0.490778, acc.: 79.69%] [G loss: 1.144605]\n",
      "epoch:17 step:16854 [D loss: 0.624180, acc.: 65.62%] [G loss: 1.341620]\n",
      "epoch:17 step:16855 [D loss: 0.651728, acc.: 67.97%] [G loss: 0.864401]\n",
      "epoch:17 step:16856 [D loss: 0.598602, acc.: 67.19%] [G loss: 1.400542]\n",
      "epoch:17 step:16857 [D loss: 0.549516, acc.: 71.09%] [G loss: 1.511530]\n",
      "epoch:17 step:16858 [D loss: 0.654590, acc.: 59.38%] [G loss: 1.102412]\n",
      "epoch:17 step:16859 [D loss: 0.509040, acc.: 78.12%] [G loss: 1.248318]\n",
      "epoch:17 step:16860 [D loss: 0.820681, acc.: 47.66%] [G loss: 0.852105]\n",
      "epoch:17 step:16861 [D loss: 0.531273, acc.: 75.00%] [G loss: 1.224973]\n",
      "epoch:17 step:16862 [D loss: 0.538443, acc.: 76.56%] [G loss: 1.100364]\n",
      "epoch:17 step:16863 [D loss: 0.545942, acc.: 75.78%] [G loss: 1.253689]\n",
      "epoch:17 step:16864 [D loss: 0.657798, acc.: 57.81%] [G loss: 1.297383]\n",
      "epoch:17 step:16865 [D loss: 0.525889, acc.: 75.00%] [G loss: 1.115915]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:17 step:16866 [D loss: 0.562232, acc.: 71.88%] [G loss: 1.010798]\n",
      "epoch:18 step:16867 [D loss: 0.579645, acc.: 70.31%] [G loss: 1.082304]\n",
      "epoch:18 step:16868 [D loss: 0.552088, acc.: 73.44%] [G loss: 1.539400]\n",
      "epoch:18 step:16869 [D loss: 0.611948, acc.: 61.72%] [G loss: 1.229267]\n",
      "epoch:18 step:16870 [D loss: 0.558105, acc.: 71.88%] [G loss: 1.140942]\n",
      "epoch:18 step:16871 [D loss: 0.555336, acc.: 73.44%] [G loss: 1.113600]\n",
      "epoch:18 step:16872 [D loss: 0.512161, acc.: 75.78%] [G loss: 1.205521]\n",
      "epoch:18 step:16873 [D loss: 0.661238, acc.: 64.06%] [G loss: 1.221478]\n",
      "epoch:18 step:16874 [D loss: 0.455388, acc.: 79.69%] [G loss: 1.268136]\n",
      "epoch:18 step:16875 [D loss: 0.473054, acc.: 78.91%] [G loss: 1.364861]\n",
      "epoch:18 step:16876 [D loss: 0.745909, acc.: 57.03%] [G loss: 1.215426]\n",
      "epoch:18 step:16877 [D loss: 0.481760, acc.: 75.00%] [G loss: 1.136507]\n",
      "epoch:18 step:16878 [D loss: 0.574745, acc.: 66.41%] [G loss: 1.331733]\n",
      "epoch:18 step:16879 [D loss: 0.488376, acc.: 75.78%] [G loss: 1.221685]\n",
      "epoch:18 step:16880 [D loss: 0.601016, acc.: 69.53%] [G loss: 1.318079]\n",
      "epoch:18 step:16881 [D loss: 0.471258, acc.: 81.25%] [G loss: 1.437887]\n",
      "epoch:18 step:16882 [D loss: 0.604801, acc.: 70.31%] [G loss: 1.067354]\n",
      "epoch:18 step:16883 [D loss: 0.562950, acc.: 71.09%] [G loss: 1.325773]\n",
      "epoch:18 step:16884 [D loss: 0.607354, acc.: 60.94%] [G loss: 1.006832]\n",
      "epoch:18 step:16885 [D loss: 0.581094, acc.: 71.88%] [G loss: 1.321401]\n",
      "epoch:18 step:16886 [D loss: 0.489052, acc.: 77.34%] [G loss: 1.528210]\n",
      "epoch:18 step:16887 [D loss: 0.715763, acc.: 58.59%] [G loss: 1.099456]\n",
      "epoch:18 step:16888 [D loss: 0.539632, acc.: 71.88%] [G loss: 1.423196]\n",
      "epoch:18 step:16889 [D loss: 0.535835, acc.: 75.00%] [G loss: 1.218856]\n",
      "epoch:18 step:16890 [D loss: 0.507793, acc.: 74.22%] [G loss: 1.578990]\n",
      "epoch:18 step:16891 [D loss: 0.656950, acc.: 60.94%] [G loss: 1.296513]\n",
      "epoch:18 step:16892 [D loss: 0.708202, acc.: 62.50%] [G loss: 1.333506]\n",
      "epoch:18 step:16893 [D loss: 0.625583, acc.: 62.50%] [G loss: 1.173988]\n",
      "epoch:18 step:16894 [D loss: 0.597320, acc.: 66.41%] [G loss: 1.350956]\n",
      "epoch:18 step:16895 [D loss: 0.742607, acc.: 58.59%] [G loss: 1.029277]\n",
      "epoch:18 step:16896 [D loss: 0.549119, acc.: 71.09%] [G loss: 1.481344]\n",
      "epoch:18 step:16897 [D loss: 0.642535, acc.: 64.06%] [G loss: 1.080195]\n",
      "epoch:18 step:16898 [D loss: 0.456920, acc.: 85.16%] [G loss: 1.404116]\n",
      "epoch:18 step:16899 [D loss: 0.471546, acc.: 78.12%] [G loss: 1.397889]\n",
      "epoch:18 step:16900 [D loss: 0.718337, acc.: 54.69%] [G loss: 1.072361]\n",
      "epoch:18 step:16901 [D loss: 0.516352, acc.: 74.22%] [G loss: 1.344212]\n",
      "epoch:18 step:16902 [D loss: 0.590011, acc.: 67.19%] [G loss: 1.448138]\n",
      "epoch:18 step:16903 [D loss: 0.375433, acc.: 92.19%] [G loss: 1.106352]\n",
      "epoch:18 step:16904 [D loss: 0.587050, acc.: 73.44%] [G loss: 1.194757]\n",
      "epoch:18 step:16905 [D loss: 0.482472, acc.: 78.12%] [G loss: 1.018969]\n",
      "epoch:18 step:16906 [D loss: 0.605145, acc.: 67.97%] [G loss: 1.020932]\n",
      "epoch:18 step:16907 [D loss: 0.597730, acc.: 67.19%] [G loss: 1.140868]\n",
      "epoch:18 step:16908 [D loss: 0.472065, acc.: 82.81%] [G loss: 1.334515]\n",
      "epoch:18 step:16909 [D loss: 0.712454, acc.: 60.16%] [G loss: 1.347394]\n",
      "epoch:18 step:16910 [D loss: 0.584106, acc.: 73.44%] [G loss: 1.359732]\n",
      "epoch:18 step:16911 [D loss: 0.600247, acc.: 64.84%] [G loss: 1.215070]\n",
      "epoch:18 step:16912 [D loss: 0.731343, acc.: 53.91%] [G loss: 1.449080]\n",
      "epoch:18 step:16913 [D loss: 0.537733, acc.: 71.09%] [G loss: 1.121545]\n",
      "epoch:18 step:16914 [D loss: 0.513693, acc.: 77.34%] [G loss: 1.617910]\n",
      "epoch:18 step:16915 [D loss: 0.630111, acc.: 62.50%] [G loss: 1.356085]\n",
      "epoch:18 step:16916 [D loss: 0.414290, acc.: 83.59%] [G loss: 1.381729]\n",
      "epoch:18 step:16917 [D loss: 0.593962, acc.: 65.62%] [G loss: 1.057531]\n",
      "epoch:18 step:16918 [D loss: 0.601786, acc.: 68.75%] [G loss: 0.772060]\n",
      "epoch:18 step:16919 [D loss: 0.462549, acc.: 83.59%] [G loss: 1.231360]\n",
      "epoch:18 step:16920 [D loss: 0.424270, acc.: 83.59%] [G loss: 1.194293]\n",
      "epoch:18 step:16921 [D loss: 0.610834, acc.: 69.53%] [G loss: 1.371446]\n",
      "epoch:18 step:16922 [D loss: 0.680152, acc.: 60.94%] [G loss: 1.053641]\n",
      "epoch:18 step:16923 [D loss: 0.599096, acc.: 66.41%] [G loss: 1.212353]\n",
      "epoch:18 step:16924 [D loss: 0.598890, acc.: 69.53%] [G loss: 1.187521]\n",
      "epoch:18 step:16925 [D loss: 0.549590, acc.: 70.31%] [G loss: 1.268206]\n",
      "epoch:18 step:16926 [D loss: 0.565751, acc.: 67.19%] [G loss: 1.271978]\n",
      "epoch:18 step:16927 [D loss: 0.530729, acc.: 77.34%] [G loss: 1.645975]\n",
      "epoch:18 step:16928 [D loss: 0.555085, acc.: 73.44%] [G loss: 1.444150]\n",
      "epoch:18 step:16929 [D loss: 0.546422, acc.: 72.66%] [G loss: 1.594747]\n",
      "epoch:18 step:16930 [D loss: 0.493191, acc.: 76.56%] [G loss: 1.580810]\n",
      "epoch:18 step:16931 [D loss: 0.535609, acc.: 74.22%] [G loss: 1.126254]\n",
      "epoch:18 step:16932 [D loss: 0.595378, acc.: 69.53%] [G loss: 1.438338]\n",
      "epoch:18 step:16933 [D loss: 0.534880, acc.: 79.69%] [G loss: 1.420252]\n",
      "epoch:18 step:16934 [D loss: 0.483057, acc.: 80.47%] [G loss: 1.332020]\n",
      "epoch:18 step:16935 [D loss: 0.484947, acc.: 75.78%] [G loss: 1.530457]\n",
      "epoch:18 step:16936 [D loss: 0.608462, acc.: 69.53%] [G loss: 1.089833]\n",
      "epoch:18 step:16937 [D loss: 0.541037, acc.: 73.44%] [G loss: 1.169799]\n",
      "epoch:18 step:16938 [D loss: 0.636954, acc.: 62.50%] [G loss: 1.170460]\n",
      "epoch:18 step:16939 [D loss: 0.605882, acc.: 67.97%] [G loss: 1.091307]\n",
      "epoch:18 step:16940 [D loss: 0.575435, acc.: 73.44%] [G loss: 1.241166]\n",
      "epoch:18 step:16941 [D loss: 0.564041, acc.: 72.66%] [G loss: 1.097151]\n",
      "epoch:18 step:16942 [D loss: 0.652678, acc.: 60.94%] [G loss: 1.215602]\n",
      "epoch:18 step:16943 [D loss: 0.558625, acc.: 71.09%] [G loss: 1.357930]\n",
      "epoch:18 step:16944 [D loss: 0.567826, acc.: 69.53%] [G loss: 1.443089]\n",
      "epoch:18 step:16945 [D loss: 0.529828, acc.: 80.47%] [G loss: 1.508505]\n",
      "epoch:18 step:16946 [D loss: 0.622041, acc.: 65.62%] [G loss: 0.773191]\n",
      "epoch:18 step:16947 [D loss: 0.655267, acc.: 60.16%] [G loss: 1.192611]\n",
      "epoch:18 step:16948 [D loss: 0.539573, acc.: 75.78%] [G loss: 1.315665]\n",
      "epoch:18 step:16949 [D loss: 0.628993, acc.: 63.28%] [G loss: 1.105266]\n",
      "epoch:18 step:16950 [D loss: 0.711190, acc.: 54.69%] [G loss: 1.207832]\n",
      "epoch:18 step:16951 [D loss: 0.608106, acc.: 64.06%] [G loss: 1.157955]\n",
      "epoch:18 step:16952 [D loss: 0.652718, acc.: 62.50%] [G loss: 1.075159]\n",
      "epoch:18 step:16953 [D loss: 0.588196, acc.: 61.72%] [G loss: 1.683792]\n",
      "epoch:18 step:16954 [D loss: 0.632558, acc.: 60.94%] [G loss: 1.410484]\n",
      "epoch:18 step:16955 [D loss: 0.643880, acc.: 63.28%] [G loss: 1.238649]\n",
      "epoch:18 step:16956 [D loss: 0.610839, acc.: 68.75%] [G loss: 1.174441]\n",
      "epoch:18 step:16957 [D loss: 0.520630, acc.: 73.44%] [G loss: 1.342143]\n",
      "epoch:18 step:16958 [D loss: 0.471393, acc.: 78.91%] [G loss: 1.343112]\n",
      "epoch:18 step:16959 [D loss: 0.457672, acc.: 78.12%] [G loss: 1.305165]\n",
      "epoch:18 step:16960 [D loss: 0.527684, acc.: 76.56%] [G loss: 1.452965]\n",
      "epoch:18 step:16961 [D loss: 0.634434, acc.: 64.06%] [G loss: 1.372741]\n",
      "epoch:18 step:16962 [D loss: 0.571822, acc.: 67.97%] [G loss: 1.370597]\n",
      "epoch:18 step:16963 [D loss: 0.474711, acc.: 76.56%] [G loss: 1.538566]\n",
      "epoch:18 step:16964 [D loss: 0.648662, acc.: 64.84%] [G loss: 1.161689]\n",
      "epoch:18 step:16965 [D loss: 0.568526, acc.: 68.75%] [G loss: 1.357005]\n",
      "epoch:18 step:16966 [D loss: 0.518949, acc.: 71.09%] [G loss: 1.291239]\n",
      "epoch:18 step:16967 [D loss: 0.648122, acc.: 66.41%] [G loss: 1.396245]\n",
      "epoch:18 step:16968 [D loss: 0.695184, acc.: 57.81%] [G loss: 1.356352]\n",
      "epoch:18 step:16969 [D loss: 0.556727, acc.: 73.44%] [G loss: 1.408826]\n",
      "epoch:18 step:16970 [D loss: 0.479490, acc.: 78.12%] [G loss: 1.703414]\n",
      "epoch:18 step:16971 [D loss: 0.480874, acc.: 78.12%] [G loss: 1.644846]\n",
      "epoch:18 step:16972 [D loss: 0.623731, acc.: 64.84%] [G loss: 1.386779]\n",
      "epoch:18 step:16973 [D loss: 0.533835, acc.: 75.78%] [G loss: 1.226036]\n",
      "epoch:18 step:16974 [D loss: 0.513656, acc.: 77.34%] [G loss: 1.381511]\n",
      "epoch:18 step:16975 [D loss: 0.525516, acc.: 77.34%] [G loss: 1.426132]\n",
      "epoch:18 step:16976 [D loss: 0.727146, acc.: 52.34%] [G loss: 1.143353]\n",
      "epoch:18 step:16977 [D loss: 0.616577, acc.: 61.72%] [G loss: 1.018587]\n",
      "epoch:18 step:16978 [D loss: 0.479502, acc.: 78.12%] [G loss: 1.212948]\n",
      "epoch:18 step:16979 [D loss: 0.598239, acc.: 71.09%] [G loss: 1.034472]\n",
      "epoch:18 step:16980 [D loss: 0.440185, acc.: 82.81%] [G loss: 1.355630]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:18 step:16981 [D loss: 0.513688, acc.: 72.66%] [G loss: 1.195923]\n",
      "epoch:18 step:16982 [D loss: 0.540089, acc.: 71.09%] [G loss: 1.299968]\n",
      "epoch:18 step:16983 [D loss: 0.584360, acc.: 67.19%] [G loss: 1.099115]\n",
      "epoch:18 step:16984 [D loss: 0.719817, acc.: 52.34%] [G loss: 1.220242]\n",
      "epoch:18 step:16985 [D loss: 0.624041, acc.: 72.66%] [G loss: 1.068064]\n",
      "epoch:18 step:16986 [D loss: 0.694456, acc.: 56.25%] [G loss: 1.099506]\n",
      "epoch:18 step:16987 [D loss: 0.557899, acc.: 69.53%] [G loss: 1.167844]\n",
      "epoch:18 step:16988 [D loss: 0.592303, acc.: 70.31%] [G loss: 1.350998]\n",
      "epoch:18 step:16989 [D loss: 0.665732, acc.: 60.94%] [G loss: 1.143292]\n",
      "epoch:18 step:16990 [D loss: 0.488815, acc.: 73.44%] [G loss: 1.490800]\n",
      "epoch:18 step:16991 [D loss: 0.593265, acc.: 71.88%] [G loss: 1.186531]\n",
      "epoch:18 step:16992 [D loss: 0.549272, acc.: 73.44%] [G loss: 1.225708]\n",
      "epoch:18 step:16993 [D loss: 0.439381, acc.: 84.38%] [G loss: 1.340497]\n",
      "epoch:18 step:16994 [D loss: 0.555755, acc.: 72.66%] [G loss: 1.335127]\n",
      "epoch:18 step:16995 [D loss: 0.608838, acc.: 66.41%] [G loss: 1.215075]\n",
      "epoch:18 step:16996 [D loss: 0.546262, acc.: 71.88%] [G loss: 1.318020]\n",
      "epoch:18 step:16997 [D loss: 0.501979, acc.: 77.34%] [G loss: 1.230482]\n",
      "epoch:18 step:16998 [D loss: 0.623386, acc.: 63.28%] [G loss: 1.358636]\n",
      "epoch:18 step:16999 [D loss: 0.474279, acc.: 82.03%] [G loss: 1.167036]\n",
      "epoch:18 step:17000 [D loss: 0.561215, acc.: 70.31%] [G loss: 1.109011]\n",
      "epoch:18 step:17001 [D loss: 0.461093, acc.: 73.44%] [G loss: 1.470869]\n",
      "epoch:18 step:17002 [D loss: 0.691161, acc.: 60.94%] [G loss: 1.185338]\n",
      "epoch:18 step:17003 [D loss: 0.593308, acc.: 67.19%] [G loss: 1.101312]\n",
      "epoch:18 step:17004 [D loss: 0.445131, acc.: 81.25%] [G loss: 1.102290]\n",
      "epoch:18 step:17005 [D loss: 0.581039, acc.: 72.66%] [G loss: 1.232080]\n",
      "epoch:18 step:17006 [D loss: 0.744457, acc.: 50.00%] [G loss: 1.060722]\n",
      "epoch:18 step:17007 [D loss: 0.681269, acc.: 60.94%] [G loss: 1.036064]\n",
      "epoch:18 step:17008 [D loss: 0.514334, acc.: 79.69%] [G loss: 1.296426]\n",
      "epoch:18 step:17009 [D loss: 0.607134, acc.: 65.62%] [G loss: 1.176574]\n",
      "epoch:18 step:17010 [D loss: 0.721105, acc.: 59.38%] [G loss: 1.742236]\n",
      "epoch:18 step:17011 [D loss: 0.714612, acc.: 60.16%] [G loss: 1.142455]\n",
      "epoch:18 step:17012 [D loss: 0.600621, acc.: 72.66%] [G loss: 1.198217]\n",
      "epoch:18 step:17013 [D loss: 0.643972, acc.: 64.84%] [G loss: 1.143692]\n",
      "epoch:18 step:17014 [D loss: 0.499999, acc.: 75.78%] [G loss: 1.169938]\n",
      "epoch:18 step:17015 [D loss: 0.550616, acc.: 69.53%] [G loss: 1.638178]\n",
      "epoch:18 step:17016 [D loss: 0.720802, acc.: 59.38%] [G loss: 1.099083]\n",
      "epoch:18 step:17017 [D loss: 0.607762, acc.: 67.19%] [G loss: 1.327938]\n",
      "epoch:18 step:17018 [D loss: 0.516240, acc.: 77.34%] [G loss: 1.101415]\n",
      "epoch:18 step:17019 [D loss: 0.565128, acc.: 74.22%] [G loss: 1.369065]\n",
      "epoch:18 step:17020 [D loss: 0.567894, acc.: 68.75%] [G loss: 1.290973]\n",
      "epoch:18 step:17021 [D loss: 0.746819, acc.: 53.12%] [G loss: 1.153252]\n",
      "epoch:18 step:17022 [D loss: 0.521360, acc.: 79.69%] [G loss: 1.311738]\n",
      "epoch:18 step:17023 [D loss: 0.578790, acc.: 66.41%] [G loss: 1.471642]\n",
      "epoch:18 step:17024 [D loss: 0.540636, acc.: 75.78%] [G loss: 1.134157]\n",
      "epoch:18 step:17025 [D loss: 0.585215, acc.: 67.97%] [G loss: 1.303297]\n",
      "epoch:18 step:17026 [D loss: 0.522781, acc.: 72.66%] [G loss: 1.338115]\n",
      "epoch:18 step:17027 [D loss: 0.556603, acc.: 68.75%] [G loss: 1.208806]\n",
      "epoch:18 step:17028 [D loss: 0.602371, acc.: 69.53%] [G loss: 1.449296]\n",
      "epoch:18 step:17029 [D loss: 0.550741, acc.: 74.22%] [G loss: 1.222803]\n",
      "epoch:18 step:17030 [D loss: 0.514131, acc.: 76.56%] [G loss: 1.270760]\n",
      "epoch:18 step:17031 [D loss: 0.688594, acc.: 61.72%] [G loss: 1.274517]\n",
      "epoch:18 step:17032 [D loss: 0.666993, acc.: 54.69%] [G loss: 1.306656]\n",
      "epoch:18 step:17033 [D loss: 0.537988, acc.: 70.31%] [G loss: 1.096849]\n",
      "epoch:18 step:17034 [D loss: 0.516418, acc.: 74.22%] [G loss: 1.532680]\n",
      "epoch:18 step:17035 [D loss: 0.535628, acc.: 73.44%] [G loss: 1.675934]\n",
      "epoch:18 step:17036 [D loss: 0.584122, acc.: 64.84%] [G loss: 1.414329]\n",
      "epoch:18 step:17037 [D loss: 0.617413, acc.: 64.06%] [G loss: 0.985618]\n",
      "epoch:18 step:17038 [D loss: 0.493070, acc.: 75.78%] [G loss: 1.297571]\n",
      "epoch:18 step:17039 [D loss: 0.688528, acc.: 60.94%] [G loss: 1.388345]\n",
      "epoch:18 step:17040 [D loss: 0.602315, acc.: 66.41%] [G loss: 1.470051]\n",
      "epoch:18 step:17041 [D loss: 0.496827, acc.: 76.56%] [G loss: 1.389976]\n",
      "epoch:18 step:17042 [D loss: 0.501333, acc.: 79.69%] [G loss: 1.271038]\n",
      "epoch:18 step:17043 [D loss: 0.500822, acc.: 79.69%] [G loss: 1.243943]\n",
      "epoch:18 step:17044 [D loss: 0.616730, acc.: 63.28%] [G loss: 1.327916]\n",
      "epoch:18 step:17045 [D loss: 0.530813, acc.: 73.44%] [G loss: 1.156952]\n",
      "epoch:18 step:17046 [D loss: 0.603143, acc.: 67.19%] [G loss: 1.173546]\n",
      "epoch:18 step:17047 [D loss: 0.632228, acc.: 67.19%] [G loss: 1.180148]\n",
      "epoch:18 step:17048 [D loss: 0.553105, acc.: 70.31%] [G loss: 1.391303]\n",
      "epoch:18 step:17049 [D loss: 0.590253, acc.: 72.66%] [G loss: 1.359276]\n",
      "epoch:18 step:17050 [D loss: 0.722462, acc.: 55.47%] [G loss: 1.219351]\n",
      "epoch:18 step:17051 [D loss: 0.520508, acc.: 75.00%] [G loss: 1.189195]\n",
      "epoch:18 step:17052 [D loss: 0.552654, acc.: 69.53%] [G loss: 1.475754]\n",
      "epoch:18 step:17053 [D loss: 0.496134, acc.: 78.12%] [G loss: 1.233995]\n",
      "epoch:18 step:17054 [D loss: 0.671045, acc.: 64.06%] [G loss: 1.278715]\n",
      "epoch:18 step:17055 [D loss: 0.575848, acc.: 65.62%] [G loss: 1.312108]\n",
      "epoch:18 step:17056 [D loss: 0.617862, acc.: 69.53%] [G loss: 1.161362]\n",
      "epoch:18 step:17057 [D loss: 0.515023, acc.: 75.00%] [G loss: 1.456910]\n",
      "epoch:18 step:17058 [D loss: 0.462306, acc.: 77.34%] [G loss: 1.361872]\n",
      "epoch:18 step:17059 [D loss: 0.574437, acc.: 74.22%] [G loss: 1.250283]\n",
      "epoch:18 step:17060 [D loss: 0.573508, acc.: 75.00%] [G loss: 1.125003]\n",
      "epoch:18 step:17061 [D loss: 0.487206, acc.: 78.91%] [G loss: 1.073192]\n",
      "epoch:18 step:17062 [D loss: 0.498772, acc.: 73.44%] [G loss: 1.088128]\n",
      "epoch:18 step:17063 [D loss: 0.481722, acc.: 82.03%] [G loss: 1.107694]\n",
      "epoch:18 step:17064 [D loss: 0.574811, acc.: 67.19%] [G loss: 1.285119]\n",
      "epoch:18 step:17065 [D loss: 0.458913, acc.: 78.91%] [G loss: 1.271577]\n",
      "epoch:18 step:17066 [D loss: 0.617397, acc.: 65.62%] [G loss: 1.501387]\n",
      "epoch:18 step:17067 [D loss: 0.451787, acc.: 78.12%] [G loss: 1.557817]\n",
      "epoch:18 step:17068 [D loss: 0.486141, acc.: 80.47%] [G loss: 1.473459]\n",
      "epoch:18 step:17069 [D loss: 0.533522, acc.: 76.56%] [G loss: 1.433262]\n",
      "epoch:18 step:17070 [D loss: 0.556604, acc.: 66.41%] [G loss: 1.351678]\n",
      "epoch:18 step:17071 [D loss: 0.551588, acc.: 70.31%] [G loss: 1.120353]\n",
      "epoch:18 step:17072 [D loss: 0.461517, acc.: 78.12%] [G loss: 1.766150]\n",
      "epoch:18 step:17073 [D loss: 0.663689, acc.: 63.28%] [G loss: 1.128363]\n",
      "epoch:18 step:17074 [D loss: 0.449724, acc.: 79.69%] [G loss: 1.353287]\n",
      "epoch:18 step:17075 [D loss: 0.488724, acc.: 78.12%] [G loss: 1.411429]\n",
      "epoch:18 step:17076 [D loss: 0.577677, acc.: 64.84%] [G loss: 1.057647]\n",
      "epoch:18 step:17077 [D loss: 0.490110, acc.: 78.91%] [G loss: 1.473878]\n",
      "epoch:18 step:17078 [D loss: 0.495493, acc.: 77.34%] [G loss: 1.525547]\n",
      "epoch:18 step:17079 [D loss: 0.551557, acc.: 71.88%] [G loss: 1.060157]\n",
      "epoch:18 step:17080 [D loss: 0.574166, acc.: 74.22%] [G loss: 1.221396]\n",
      "epoch:18 step:17081 [D loss: 0.665327, acc.: 60.16%] [G loss: 1.266669]\n",
      "epoch:18 step:17082 [D loss: 0.616489, acc.: 65.62%] [G loss: 1.243366]\n",
      "epoch:18 step:17083 [D loss: 0.612087, acc.: 64.84%] [G loss: 1.110890]\n",
      "epoch:18 step:17084 [D loss: 0.602111, acc.: 70.31%] [G loss: 1.429709]\n",
      "epoch:18 step:17085 [D loss: 0.615255, acc.: 69.53%] [G loss: 1.330064]\n",
      "epoch:18 step:17086 [D loss: 0.632252, acc.: 62.50%] [G loss: 1.196672]\n",
      "epoch:18 step:17087 [D loss: 0.703696, acc.: 61.72%] [G loss: 1.209284]\n",
      "epoch:18 step:17088 [D loss: 0.557336, acc.: 76.56%] [G loss: 1.231703]\n",
      "epoch:18 step:17089 [D loss: 0.483440, acc.: 79.69%] [G loss: 1.086781]\n",
      "epoch:18 step:17090 [D loss: 0.558506, acc.: 68.75%] [G loss: 1.406646]\n",
      "epoch:18 step:17091 [D loss: 0.588702, acc.: 70.31%] [G loss: 1.291157]\n",
      "epoch:18 step:17092 [D loss: 0.559073, acc.: 69.53%] [G loss: 1.063710]\n",
      "epoch:18 step:17093 [D loss: 0.540468, acc.: 71.09%] [G loss: 1.412866]\n",
      "epoch:18 step:17094 [D loss: 0.550112, acc.: 70.31%] [G loss: 0.879830]\n",
      "epoch:18 step:17095 [D loss: 0.523658, acc.: 74.22%] [G loss: 1.177699]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:18 step:17096 [D loss: 0.511355, acc.: 74.22%] [G loss: 1.328876]\n",
      "epoch:18 step:17097 [D loss: 0.636145, acc.: 64.06%] [G loss: 1.385372]\n",
      "epoch:18 step:17098 [D loss: 0.556558, acc.: 73.44%] [G loss: 1.110693]\n",
      "epoch:18 step:17099 [D loss: 0.542410, acc.: 73.44%] [G loss: 1.296484]\n",
      "epoch:18 step:17100 [D loss: 0.477323, acc.: 76.56%] [G loss: 1.196368]\n",
      "epoch:18 step:17101 [D loss: 0.553546, acc.: 73.44%] [G loss: 1.094234]\n",
      "epoch:18 step:17102 [D loss: 0.536580, acc.: 75.78%] [G loss: 1.144759]\n",
      "epoch:18 step:17103 [D loss: 0.568553, acc.: 71.88%] [G loss: 1.415100]\n",
      "epoch:18 step:17104 [D loss: 0.525938, acc.: 71.88%] [G loss: 1.451241]\n",
      "epoch:18 step:17105 [D loss: 0.573498, acc.: 71.09%] [G loss: 1.307955]\n",
      "epoch:18 step:17106 [D loss: 0.535668, acc.: 72.66%] [G loss: 1.438318]\n",
      "epoch:18 step:17107 [D loss: 0.490428, acc.: 79.69%] [G loss: 1.551041]\n",
      "epoch:18 step:17108 [D loss: 0.577207, acc.: 68.75%] [G loss: 1.141297]\n",
      "epoch:18 step:17109 [D loss: 0.682948, acc.: 61.72%] [G loss: 1.359750]\n",
      "epoch:18 step:17110 [D loss: 0.613376, acc.: 66.41%] [G loss: 1.199819]\n",
      "epoch:18 step:17111 [D loss: 0.659425, acc.: 60.16%] [G loss: 1.104492]\n",
      "epoch:18 step:17112 [D loss: 0.530924, acc.: 73.44%] [G loss: 1.510333]\n",
      "epoch:18 step:17113 [D loss: 0.753827, acc.: 47.66%] [G loss: 1.080918]\n",
      "epoch:18 step:17114 [D loss: 0.628990, acc.: 60.94%] [G loss: 1.021052]\n",
      "epoch:18 step:17115 [D loss: 0.442918, acc.: 81.25%] [G loss: 1.340703]\n",
      "epoch:18 step:17116 [D loss: 0.593952, acc.: 72.66%] [G loss: 1.250712]\n",
      "epoch:18 step:17117 [D loss: 0.542900, acc.: 73.44%] [G loss: 1.289858]\n",
      "epoch:18 step:17118 [D loss: 0.465306, acc.: 80.47%] [G loss: 1.286182]\n",
      "epoch:18 step:17119 [D loss: 0.606467, acc.: 65.62%] [G loss: 1.452001]\n",
      "epoch:18 step:17120 [D loss: 0.600553, acc.: 71.09%] [G loss: 1.129786]\n",
      "epoch:18 step:17121 [D loss: 0.510509, acc.: 73.44%] [G loss: 1.046367]\n",
      "epoch:18 step:17122 [D loss: 0.785900, acc.: 54.69%] [G loss: 1.056962]\n",
      "epoch:18 step:17123 [D loss: 0.557420, acc.: 76.56%] [G loss: 1.229900]\n",
      "epoch:18 step:17124 [D loss: 0.590993, acc.: 67.97%] [G loss: 1.435410]\n",
      "epoch:18 step:17125 [D loss: 0.652139, acc.: 64.84%] [G loss: 1.200209]\n",
      "epoch:18 step:17126 [D loss: 0.657349, acc.: 60.94%] [G loss: 1.341428]\n",
      "epoch:18 step:17127 [D loss: 0.612833, acc.: 70.31%] [G loss: 1.303842]\n",
      "epoch:18 step:17128 [D loss: 0.672772, acc.: 64.06%] [G loss: 1.181269]\n",
      "epoch:18 step:17129 [D loss: 0.767412, acc.: 49.22%] [G loss: 1.130046]\n",
      "epoch:18 step:17130 [D loss: 0.448248, acc.: 76.56%] [G loss: 1.373964]\n",
      "epoch:18 step:17131 [D loss: 0.437013, acc.: 82.81%] [G loss: 1.528480]\n",
      "epoch:18 step:17132 [D loss: 0.560956, acc.: 71.09%] [G loss: 1.338156]\n",
      "epoch:18 step:17133 [D loss: 0.589286, acc.: 67.97%] [G loss: 1.098143]\n",
      "epoch:18 step:17134 [D loss: 0.577318, acc.: 67.97%] [G loss: 1.383477]\n",
      "epoch:18 step:17135 [D loss: 0.568172, acc.: 66.41%] [G loss: 1.299626]\n",
      "epoch:18 step:17136 [D loss: 0.535381, acc.: 74.22%] [G loss: 1.392795]\n",
      "epoch:18 step:17137 [D loss: 0.476934, acc.: 72.66%] [G loss: 1.524468]\n",
      "epoch:18 step:17138 [D loss: 0.545303, acc.: 75.00%] [G loss: 1.291736]\n",
      "epoch:18 step:17139 [D loss: 0.505129, acc.: 76.56%] [G loss: 1.133537]\n",
      "epoch:18 step:17140 [D loss: 0.614262, acc.: 66.41%] [G loss: 1.132762]\n",
      "epoch:18 step:17141 [D loss: 0.648593, acc.: 64.06%] [G loss: 1.118942]\n",
      "epoch:18 step:17142 [D loss: 0.770828, acc.: 44.53%] [G loss: 1.014510]\n",
      "epoch:18 step:17143 [D loss: 0.688835, acc.: 60.16%] [G loss: 1.025440]\n",
      "epoch:18 step:17144 [D loss: 0.538267, acc.: 75.00%] [G loss: 1.413037]\n",
      "epoch:18 step:17145 [D loss: 0.641345, acc.: 63.28%] [G loss: 1.104302]\n",
      "epoch:18 step:17146 [D loss: 0.610975, acc.: 60.94%] [G loss: 1.076592]\n",
      "epoch:18 step:17147 [D loss: 0.569155, acc.: 69.53%] [G loss: 1.472567]\n",
      "epoch:18 step:17148 [D loss: 0.430352, acc.: 84.38%] [G loss: 1.120041]\n",
      "epoch:18 step:17149 [D loss: 0.511117, acc.: 75.78%] [G loss: 1.210805]\n",
      "epoch:18 step:17150 [D loss: 0.514198, acc.: 77.34%] [G loss: 1.447073]\n",
      "epoch:18 step:17151 [D loss: 0.529653, acc.: 71.09%] [G loss: 1.248680]\n",
      "epoch:18 step:17152 [D loss: 0.582304, acc.: 72.66%] [G loss: 1.121762]\n",
      "epoch:18 step:17153 [D loss: 0.492587, acc.: 77.34%] [G loss: 1.252979]\n",
      "epoch:18 step:17154 [D loss: 0.657797, acc.: 57.03%] [G loss: 1.390664]\n",
      "epoch:18 step:17155 [D loss: 0.720092, acc.: 57.81%] [G loss: 1.223536]\n",
      "epoch:18 step:17156 [D loss: 0.544794, acc.: 69.53%] [G loss: 1.696431]\n",
      "epoch:18 step:17157 [D loss: 0.671331, acc.: 58.59%] [G loss: 1.219223]\n",
      "epoch:18 step:17158 [D loss: 0.610257, acc.: 63.28%] [G loss: 1.174279]\n",
      "epoch:18 step:17159 [D loss: 0.616520, acc.: 64.06%] [G loss: 1.230038]\n",
      "epoch:18 step:17160 [D loss: 0.643815, acc.: 63.28%] [G loss: 1.183996]\n",
      "epoch:18 step:17161 [D loss: 0.646053, acc.: 61.72%] [G loss: 1.530801]\n",
      "epoch:18 step:17162 [D loss: 0.586672, acc.: 67.19%] [G loss: 1.313531]\n",
      "epoch:18 step:17163 [D loss: 0.710149, acc.: 59.38%] [G loss: 1.457621]\n",
      "epoch:18 step:17164 [D loss: 0.704229, acc.: 62.50%] [G loss: 1.286436]\n",
      "epoch:18 step:17165 [D loss: 0.727533, acc.: 57.03%] [G loss: 1.370054]\n",
      "epoch:18 step:17166 [D loss: 0.520366, acc.: 76.56%] [G loss: 1.241877]\n",
      "epoch:18 step:17167 [D loss: 0.623350, acc.: 62.50%] [G loss: 1.240155]\n",
      "epoch:18 step:17168 [D loss: 0.521443, acc.: 78.12%] [G loss: 1.147634]\n",
      "epoch:18 step:17169 [D loss: 0.511896, acc.: 71.88%] [G loss: 1.326580]\n",
      "epoch:18 step:17170 [D loss: 0.766732, acc.: 55.47%] [G loss: 1.187767]\n",
      "epoch:18 step:17171 [D loss: 0.563913, acc.: 69.53%] [G loss: 1.457586]\n",
      "epoch:18 step:17172 [D loss: 0.415661, acc.: 86.72%] [G loss: 1.331565]\n",
      "epoch:18 step:17173 [D loss: 0.690602, acc.: 62.50%] [G loss: 1.335303]\n",
      "epoch:18 step:17174 [D loss: 0.476366, acc.: 78.91%] [G loss: 1.115342]\n",
      "epoch:18 step:17175 [D loss: 0.564382, acc.: 73.44%] [G loss: 1.112557]\n",
      "epoch:18 step:17176 [D loss: 0.670123, acc.: 57.81%] [G loss: 1.366860]\n",
      "epoch:18 step:17177 [D loss: 0.519863, acc.: 78.91%] [G loss: 1.605104]\n",
      "epoch:18 step:17178 [D loss: 0.705274, acc.: 57.81%] [G loss: 1.297094]\n",
      "epoch:18 step:17179 [D loss: 0.673814, acc.: 60.16%] [G loss: 1.172999]\n",
      "epoch:18 step:17180 [D loss: 0.536210, acc.: 70.31%] [G loss: 1.010078]\n",
      "epoch:18 step:17181 [D loss: 0.584827, acc.: 68.75%] [G loss: 1.222832]\n",
      "epoch:18 step:17182 [D loss: 0.665806, acc.: 63.28%] [G loss: 1.410824]\n",
      "epoch:18 step:17183 [D loss: 0.656590, acc.: 60.16%] [G loss: 1.470657]\n",
      "epoch:18 step:17184 [D loss: 0.642630, acc.: 61.72%] [G loss: 1.291176]\n",
      "epoch:18 step:17185 [D loss: 0.784308, acc.: 54.69%] [G loss: 1.063397]\n",
      "epoch:18 step:17186 [D loss: 0.512670, acc.: 77.34%] [G loss: 1.096902]\n",
      "epoch:18 step:17187 [D loss: 0.502706, acc.: 76.56%] [G loss: 1.251377]\n",
      "epoch:18 step:17188 [D loss: 0.570764, acc.: 67.97%] [G loss: 1.168507]\n",
      "epoch:18 step:17189 [D loss: 0.662448, acc.: 61.72%] [G loss: 1.338206]\n",
      "epoch:18 step:17190 [D loss: 0.499647, acc.: 75.00%] [G loss: 1.589921]\n",
      "epoch:18 step:17191 [D loss: 0.607553, acc.: 61.72%] [G loss: 1.612740]\n",
      "epoch:18 step:17192 [D loss: 0.470631, acc.: 82.81%] [G loss: 1.411792]\n",
      "epoch:18 step:17193 [D loss: 0.565078, acc.: 71.88%] [G loss: 1.370524]\n",
      "epoch:18 step:17194 [D loss: 0.608490, acc.: 65.62%] [G loss: 0.993317]\n",
      "epoch:18 step:17195 [D loss: 0.506411, acc.: 78.12%] [G loss: 1.500861]\n",
      "epoch:18 step:17196 [D loss: 0.550610, acc.: 75.78%] [G loss: 1.387597]\n",
      "epoch:18 step:17197 [D loss: 0.403976, acc.: 83.59%] [G loss: 1.241988]\n",
      "epoch:18 step:17198 [D loss: 0.529631, acc.: 75.78%] [G loss: 1.039290]\n",
      "epoch:18 step:17199 [D loss: 0.463100, acc.: 78.91%] [G loss: 1.531090]\n",
      "epoch:18 step:17200 [D loss: 0.536465, acc.: 72.66%] [G loss: 1.374879]\n",
      "epoch:18 step:17201 [D loss: 0.495756, acc.: 74.22%] [G loss: 1.275022]\n",
      "epoch:18 step:17202 [D loss: 0.448448, acc.: 78.91%] [G loss: 1.376716]\n",
      "epoch:18 step:17203 [D loss: 0.657171, acc.: 55.47%] [G loss: 1.693122]\n",
      "epoch:18 step:17204 [D loss: 0.488512, acc.: 80.47%] [G loss: 1.075281]\n",
      "epoch:18 step:17205 [D loss: 0.467248, acc.: 78.12%] [G loss: 1.443171]\n",
      "epoch:18 step:17206 [D loss: 0.471220, acc.: 82.81%] [G loss: 1.505617]\n",
      "epoch:18 step:17207 [D loss: 0.637466, acc.: 60.16%] [G loss: 1.259612]\n",
      "epoch:18 step:17208 [D loss: 0.717303, acc.: 57.81%] [G loss: 1.170478]\n",
      "epoch:18 step:17209 [D loss: 0.657843, acc.: 62.50%] [G loss: 1.247265]\n",
      "epoch:18 step:17210 [D loss: 0.565052, acc.: 67.97%] [G loss: 1.183055]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:18 step:17211 [D loss: 0.536743, acc.: 71.09%] [G loss: 1.181201]\n",
      "epoch:18 step:17212 [D loss: 0.518799, acc.: 78.91%] [G loss: 1.185610]\n",
      "epoch:18 step:17213 [D loss: 0.535223, acc.: 72.66%] [G loss: 1.465575]\n",
      "epoch:18 step:17214 [D loss: 0.752089, acc.: 54.69%] [G loss: 1.362387]\n",
      "epoch:18 step:17215 [D loss: 0.527317, acc.: 73.44%] [G loss: 1.242525]\n",
      "epoch:18 step:17216 [D loss: 0.661038, acc.: 65.62%] [G loss: 1.472019]\n",
      "epoch:18 step:17217 [D loss: 0.498659, acc.: 77.34%] [G loss: 1.343676]\n",
      "epoch:18 step:17218 [D loss: 0.545908, acc.: 75.78%] [G loss: 1.217841]\n",
      "epoch:18 step:17219 [D loss: 0.553243, acc.: 73.44%] [G loss: 1.177482]\n",
      "epoch:18 step:17220 [D loss: 0.493829, acc.: 83.59%] [G loss: 1.146900]\n",
      "epoch:18 step:17221 [D loss: 0.578172, acc.: 69.53%] [G loss: 1.281493]\n",
      "epoch:18 step:17222 [D loss: 0.568944, acc.: 77.34%] [G loss: 1.246415]\n",
      "epoch:18 step:17223 [D loss: 0.633062, acc.: 62.50%] [G loss: 1.016143]\n",
      "epoch:18 step:17224 [D loss: 0.629918, acc.: 67.19%] [G loss: 1.372247]\n",
      "epoch:18 step:17225 [D loss: 0.481816, acc.: 79.69%] [G loss: 1.243212]\n",
      "epoch:18 step:17226 [D loss: 0.598855, acc.: 60.94%] [G loss: 1.414376]\n",
      "epoch:18 step:17227 [D loss: 0.607501, acc.: 67.19%] [G loss: 1.039857]\n",
      "epoch:18 step:17228 [D loss: 0.482044, acc.: 75.78%] [G loss: 1.356401]\n",
      "epoch:18 step:17229 [D loss: 0.530675, acc.: 74.22%] [G loss: 1.165501]\n",
      "epoch:18 step:17230 [D loss: 0.433813, acc.: 84.38%] [G loss: 1.525149]\n",
      "epoch:18 step:17231 [D loss: 0.632893, acc.: 64.06%] [G loss: 1.524726]\n",
      "epoch:18 step:17232 [D loss: 0.576971, acc.: 70.31%] [G loss: 1.129117]\n",
      "epoch:18 step:17233 [D loss: 0.584744, acc.: 70.31%] [G loss: 1.258792]\n",
      "epoch:18 step:17234 [D loss: 0.512384, acc.: 72.66%] [G loss: 1.609522]\n",
      "epoch:18 step:17235 [D loss: 0.683830, acc.: 56.25%] [G loss: 1.030051]\n",
      "epoch:18 step:17236 [D loss: 0.576410, acc.: 70.31%] [G loss: 1.274331]\n",
      "epoch:18 step:17237 [D loss: 0.503302, acc.: 71.09%] [G loss: 1.402533]\n",
      "epoch:18 step:17238 [D loss: 0.557053, acc.: 69.53%] [G loss: 1.501978]\n",
      "epoch:18 step:17239 [D loss: 0.587701, acc.: 68.75%] [G loss: 1.347827]\n",
      "epoch:18 step:17240 [D loss: 0.656161, acc.: 63.28%] [G loss: 1.246380]\n",
      "epoch:18 step:17241 [D loss: 0.721655, acc.: 53.91%] [G loss: 1.186256]\n",
      "epoch:18 step:17242 [D loss: 0.669619, acc.: 60.16%] [G loss: 1.311725]\n",
      "epoch:18 step:17243 [D loss: 0.381669, acc.: 85.16%] [G loss: 1.198105]\n",
      "epoch:18 step:17244 [D loss: 0.599937, acc.: 68.75%] [G loss: 0.943524]\n",
      "epoch:18 step:17245 [D loss: 0.566588, acc.: 75.00%] [G loss: 0.998971]\n",
      "epoch:18 step:17246 [D loss: 0.452923, acc.: 78.12%] [G loss: 1.455017]\n",
      "epoch:18 step:17247 [D loss: 0.436313, acc.: 81.25%] [G loss: 1.622526]\n",
      "epoch:18 step:17248 [D loss: 0.648426, acc.: 64.84%] [G loss: 1.324520]\n",
      "epoch:18 step:17249 [D loss: 0.515901, acc.: 75.00%] [G loss: 1.336626]\n",
      "epoch:18 step:17250 [D loss: 0.585695, acc.: 64.06%] [G loss: 1.298943]\n",
      "epoch:18 step:17251 [D loss: 0.626793, acc.: 65.62%] [G loss: 1.661010]\n",
      "epoch:18 step:17252 [D loss: 0.584510, acc.: 67.19%] [G loss: 1.365722]\n",
      "epoch:18 step:17253 [D loss: 0.543676, acc.: 78.12%] [G loss: 1.288163]\n",
      "epoch:18 step:17254 [D loss: 0.468208, acc.: 77.34%] [G loss: 1.425847]\n",
      "epoch:18 step:17255 [D loss: 0.550027, acc.: 70.31%] [G loss: 1.295145]\n",
      "epoch:18 step:17256 [D loss: 0.649146, acc.: 60.94%] [G loss: 1.140608]\n",
      "epoch:18 step:17257 [D loss: 0.571738, acc.: 71.88%] [G loss: 1.076233]\n",
      "epoch:18 step:17258 [D loss: 0.596832, acc.: 67.97%] [G loss: 1.481854]\n",
      "epoch:18 step:17259 [D loss: 0.700593, acc.: 55.47%] [G loss: 1.090333]\n",
      "epoch:18 step:17260 [D loss: 0.615009, acc.: 65.62%] [G loss: 1.212741]\n",
      "epoch:18 step:17261 [D loss: 0.577194, acc.: 65.62%] [G loss: 1.561348]\n",
      "epoch:18 step:17262 [D loss: 0.657676, acc.: 67.19%] [G loss: 1.591395]\n",
      "epoch:18 step:17263 [D loss: 0.584738, acc.: 72.66%] [G loss: 1.326685]\n",
      "epoch:18 step:17264 [D loss: 0.496460, acc.: 76.56%] [G loss: 1.295197]\n",
      "epoch:18 step:17265 [D loss: 0.593088, acc.: 71.09%] [G loss: 1.157557]\n",
      "epoch:18 step:17266 [D loss: 0.472306, acc.: 79.69%] [G loss: 1.426721]\n",
      "epoch:18 step:17267 [D loss: 0.628483, acc.: 64.84%] [G loss: 1.052052]\n",
      "epoch:18 step:17268 [D loss: 0.444593, acc.: 82.03%] [G loss: 1.029282]\n",
      "epoch:18 step:17269 [D loss: 0.612222, acc.: 61.72%] [G loss: 1.087723]\n",
      "epoch:18 step:17270 [D loss: 0.544459, acc.: 68.75%] [G loss: 1.541383]\n",
      "epoch:18 step:17271 [D loss: 0.500199, acc.: 75.78%] [G loss: 1.364165]\n",
      "epoch:18 step:17272 [D loss: 0.549062, acc.: 68.75%] [G loss: 1.335632]\n",
      "epoch:18 step:17273 [D loss: 0.650668, acc.: 66.41%] [G loss: 0.913473]\n",
      "epoch:18 step:17274 [D loss: 0.430164, acc.: 85.16%] [G loss: 1.300738]\n",
      "epoch:18 step:17275 [D loss: 0.568066, acc.: 72.66%] [G loss: 1.336463]\n",
      "epoch:18 step:17276 [D loss: 0.567481, acc.: 73.44%] [G loss: 1.366452]\n",
      "epoch:18 step:17277 [D loss: 0.491821, acc.: 80.47%] [G loss: 1.711324]\n",
      "epoch:18 step:17278 [D loss: 0.663280, acc.: 61.72%] [G loss: 1.152957]\n",
      "epoch:18 step:17279 [D loss: 0.598857, acc.: 67.97%] [G loss: 1.138399]\n",
      "epoch:18 step:17280 [D loss: 0.605222, acc.: 66.41%] [G loss: 1.202328]\n",
      "epoch:18 step:17281 [D loss: 0.523715, acc.: 73.44%] [G loss: 1.095159]\n",
      "epoch:18 step:17282 [D loss: 0.487631, acc.: 77.34%] [G loss: 1.241645]\n",
      "epoch:18 step:17283 [D loss: 0.633326, acc.: 60.94%] [G loss: 1.285049]\n",
      "epoch:18 step:17284 [D loss: 0.717276, acc.: 55.47%] [G loss: 1.031444]\n",
      "epoch:18 step:17285 [D loss: 0.454808, acc.: 85.16%] [G loss: 1.394812]\n",
      "epoch:18 step:17286 [D loss: 0.579686, acc.: 71.09%] [G loss: 1.465861]\n",
      "epoch:18 step:17287 [D loss: 0.646747, acc.: 64.84%] [G loss: 1.334172]\n",
      "epoch:18 step:17288 [D loss: 0.631985, acc.: 64.06%] [G loss: 1.282521]\n",
      "epoch:18 step:17289 [D loss: 0.668264, acc.: 60.16%] [G loss: 1.189271]\n",
      "epoch:18 step:17290 [D loss: 0.619989, acc.: 64.06%] [G loss: 1.339291]\n",
      "epoch:18 step:17291 [D loss: 0.575666, acc.: 68.75%] [G loss: 1.579481]\n",
      "epoch:18 step:17292 [D loss: 0.507395, acc.: 79.69%] [G loss: 1.326093]\n",
      "epoch:18 step:17293 [D loss: 0.646287, acc.: 67.97%] [G loss: 1.219489]\n",
      "epoch:18 step:17294 [D loss: 0.557800, acc.: 70.31%] [G loss: 1.004466]\n",
      "epoch:18 step:17295 [D loss: 0.500506, acc.: 73.44%] [G loss: 1.216143]\n",
      "epoch:18 step:17296 [D loss: 0.578126, acc.: 71.88%] [G loss: 1.484745]\n",
      "epoch:18 step:17297 [D loss: 0.520945, acc.: 74.22%] [G loss: 1.143841]\n",
      "epoch:18 step:17298 [D loss: 0.496050, acc.: 78.12%] [G loss: 1.040032]\n",
      "epoch:18 step:17299 [D loss: 0.542750, acc.: 75.00%] [G loss: 1.340111]\n",
      "epoch:18 step:17300 [D loss: 0.559943, acc.: 70.31%] [G loss: 1.358604]\n",
      "epoch:18 step:17301 [D loss: 0.468941, acc.: 80.47%] [G loss: 1.402370]\n",
      "epoch:18 step:17302 [D loss: 0.534590, acc.: 72.66%] [G loss: 1.439396]\n",
      "epoch:18 step:17303 [D loss: 0.461515, acc.: 80.47%] [G loss: 1.360219]\n",
      "epoch:18 step:17304 [D loss: 0.566443, acc.: 71.88%] [G loss: 1.337874]\n",
      "epoch:18 step:17305 [D loss: 0.549975, acc.: 74.22%] [G loss: 1.085205]\n",
      "epoch:18 step:17306 [D loss: 0.551734, acc.: 71.88%] [G loss: 1.245339]\n",
      "epoch:18 step:17307 [D loss: 0.469892, acc.: 80.47%] [G loss: 1.247047]\n",
      "epoch:18 step:17308 [D loss: 0.667959, acc.: 64.84%] [G loss: 1.235960]\n",
      "epoch:18 step:17309 [D loss: 0.618974, acc.: 67.97%] [G loss: 1.301311]\n",
      "epoch:18 step:17310 [D loss: 0.420425, acc.: 85.94%] [G loss: 1.479800]\n",
      "epoch:18 step:17311 [D loss: 0.562935, acc.: 71.09%] [G loss: 1.259319]\n",
      "epoch:18 step:17312 [D loss: 0.635709, acc.: 66.41%] [G loss: 1.126433]\n",
      "epoch:18 step:17313 [D loss: 0.580671, acc.: 68.75%] [G loss: 0.970054]\n",
      "epoch:18 step:17314 [D loss: 0.563035, acc.: 70.31%] [G loss: 1.013306]\n",
      "epoch:18 step:17315 [D loss: 0.557281, acc.: 71.09%] [G loss: 1.005537]\n",
      "epoch:18 step:17316 [D loss: 0.780720, acc.: 52.34%] [G loss: 1.238633]\n",
      "epoch:18 step:17317 [D loss: 0.454064, acc.: 82.03%] [G loss: 1.402900]\n",
      "epoch:18 step:17318 [D loss: 0.572696, acc.: 67.19%] [G loss: 1.353257]\n",
      "epoch:18 step:17319 [D loss: 0.449261, acc.: 80.47%] [G loss: 1.420388]\n",
      "epoch:18 step:17320 [D loss: 0.545280, acc.: 73.44%] [G loss: 1.218166]\n",
      "epoch:18 step:17321 [D loss: 0.525010, acc.: 75.78%] [G loss: 1.246705]\n",
      "epoch:18 step:17322 [D loss: 0.641048, acc.: 63.28%] [G loss: 1.272316]\n",
      "epoch:18 step:17323 [D loss: 0.633163, acc.: 61.72%] [G loss: 1.162475]\n",
      "epoch:18 step:17324 [D loss: 0.499539, acc.: 78.91%] [G loss: 1.249694]\n",
      "epoch:18 step:17325 [D loss: 0.488560, acc.: 76.56%] [G loss: 1.301055]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:18 step:17326 [D loss: 0.603706, acc.: 68.75%] [G loss: 1.110281]\n",
      "epoch:18 step:17327 [D loss: 0.532646, acc.: 71.88%] [G loss: 1.346674]\n",
      "epoch:18 step:17328 [D loss: 0.713156, acc.: 57.81%] [G loss: 1.068305]\n",
      "epoch:18 step:17329 [D loss: 0.690783, acc.: 59.38%] [G loss: 1.456549]\n",
      "epoch:18 step:17330 [D loss: 0.514182, acc.: 71.09%] [G loss: 1.538717]\n",
      "epoch:18 step:17331 [D loss: 0.862054, acc.: 42.97%] [G loss: 1.065660]\n",
      "epoch:18 step:17332 [D loss: 0.532484, acc.: 71.09%] [G loss: 1.526927]\n",
      "epoch:18 step:17333 [D loss: 0.386307, acc.: 84.38%] [G loss: 1.671682]\n",
      "epoch:18 step:17334 [D loss: 0.483411, acc.: 82.03%] [G loss: 1.597573]\n",
      "epoch:18 step:17335 [D loss: 0.539470, acc.: 71.09%] [G loss: 1.358540]\n",
      "epoch:18 step:17336 [D loss: 0.727417, acc.: 58.59%] [G loss: 1.119847]\n",
      "epoch:18 step:17337 [D loss: 0.537663, acc.: 70.31%] [G loss: 1.390090]\n",
      "epoch:18 step:17338 [D loss: 0.677047, acc.: 60.16%] [G loss: 1.173354]\n",
      "epoch:18 step:17339 [D loss: 0.519264, acc.: 71.09%] [G loss: 1.105021]\n",
      "epoch:18 step:17340 [D loss: 0.627162, acc.: 63.28%] [G loss: 1.305516]\n",
      "epoch:18 step:17341 [D loss: 0.485503, acc.: 79.69%] [G loss: 1.449283]\n",
      "epoch:18 step:17342 [D loss: 0.475075, acc.: 78.91%] [G loss: 1.464776]\n",
      "epoch:18 step:17343 [D loss: 0.638016, acc.: 63.28%] [G loss: 1.401465]\n",
      "epoch:18 step:17344 [D loss: 0.480791, acc.: 78.12%] [G loss: 1.133124]\n",
      "epoch:18 step:17345 [D loss: 0.497289, acc.: 82.03%] [G loss: 1.476567]\n",
      "epoch:18 step:17346 [D loss: 0.599869, acc.: 68.75%] [G loss: 1.198058]\n",
      "epoch:18 step:17347 [D loss: 0.594718, acc.: 67.97%] [G loss: 1.464682]\n",
      "epoch:18 step:17348 [D loss: 0.541525, acc.: 71.88%] [G loss: 1.296647]\n",
      "epoch:18 step:17349 [D loss: 0.708194, acc.: 60.94%] [G loss: 1.168262]\n",
      "epoch:18 step:17350 [D loss: 0.447114, acc.: 79.69%] [G loss: 1.165624]\n",
      "epoch:18 step:17351 [D loss: 0.642984, acc.: 67.97%] [G loss: 1.273875]\n",
      "epoch:18 step:17352 [D loss: 0.539899, acc.: 75.00%] [G loss: 1.314177]\n",
      "epoch:18 step:17353 [D loss: 0.414752, acc.: 85.16%] [G loss: 1.463699]\n",
      "epoch:18 step:17354 [D loss: 0.654949, acc.: 63.28%] [G loss: 1.169170]\n",
      "epoch:18 step:17355 [D loss: 0.572857, acc.: 71.09%] [G loss: 1.247362]\n",
      "epoch:18 step:17356 [D loss: 0.519707, acc.: 76.56%] [G loss: 1.163390]\n",
      "epoch:18 step:17357 [D loss: 0.576091, acc.: 69.53%] [G loss: 1.265706]\n",
      "epoch:18 step:17358 [D loss: 0.646494, acc.: 64.06%] [G loss: 1.061984]\n",
      "epoch:18 step:17359 [D loss: 0.449797, acc.: 80.47%] [G loss: 1.215786]\n",
      "epoch:18 step:17360 [D loss: 0.611351, acc.: 70.31%] [G loss: 1.238594]\n",
      "epoch:18 step:17361 [D loss: 0.621414, acc.: 69.53%] [G loss: 1.147355]\n",
      "epoch:18 step:17362 [D loss: 0.494167, acc.: 77.34%] [G loss: 1.385768]\n",
      "epoch:18 step:17363 [D loss: 0.703040, acc.: 60.16%] [G loss: 1.316286]\n",
      "epoch:18 step:17364 [D loss: 0.542108, acc.: 71.09%] [G loss: 0.967586]\n",
      "epoch:18 step:17365 [D loss: 0.463025, acc.: 79.69%] [G loss: 1.694608]\n",
      "epoch:18 step:17366 [D loss: 0.697213, acc.: 56.25%] [G loss: 1.491381]\n",
      "epoch:18 step:17367 [D loss: 0.499255, acc.: 73.44%] [G loss: 1.249730]\n",
      "epoch:18 step:17368 [D loss: 0.568814, acc.: 65.62%] [G loss: 1.143432]\n",
      "epoch:18 step:17369 [D loss: 0.520220, acc.: 75.78%] [G loss: 1.242431]\n",
      "epoch:18 step:17370 [D loss: 0.656799, acc.: 61.72%] [G loss: 1.015716]\n",
      "epoch:18 step:17371 [D loss: 0.430800, acc.: 81.25%] [G loss: 1.330116]\n",
      "epoch:18 step:17372 [D loss: 0.510563, acc.: 75.00%] [G loss: 1.226156]\n",
      "epoch:18 step:17373 [D loss: 0.630719, acc.: 64.84%] [G loss: 1.290564]\n",
      "epoch:18 step:17374 [D loss: 0.625553, acc.: 67.97%] [G loss: 1.376971]\n",
      "epoch:18 step:17375 [D loss: 0.572250, acc.: 72.66%] [G loss: 1.147153]\n",
      "epoch:18 step:17376 [D loss: 0.587659, acc.: 69.53%] [G loss: 1.166270]\n",
      "epoch:18 step:17377 [D loss: 0.447301, acc.: 81.25%] [G loss: 1.283075]\n",
      "epoch:18 step:17378 [D loss: 0.516959, acc.: 78.12%] [G loss: 1.284888]\n",
      "epoch:18 step:17379 [D loss: 0.596641, acc.: 67.97%] [G loss: 1.342255]\n",
      "epoch:18 step:17380 [D loss: 0.538043, acc.: 71.09%] [G loss: 1.179320]\n",
      "epoch:18 step:17381 [D loss: 0.475776, acc.: 77.34%] [G loss: 1.529492]\n",
      "epoch:18 step:17382 [D loss: 0.483922, acc.: 78.12%] [G loss: 1.334893]\n",
      "epoch:18 step:17383 [D loss: 0.473466, acc.: 76.56%] [G loss: 1.200602]\n",
      "epoch:18 step:17384 [D loss: 0.388941, acc.: 89.06%] [G loss: 1.603351]\n",
      "epoch:18 step:17385 [D loss: 0.543028, acc.: 72.66%] [G loss: 1.275952]\n",
      "epoch:18 step:17386 [D loss: 0.581606, acc.: 67.19%] [G loss: 0.958318]\n",
      "epoch:18 step:17387 [D loss: 0.555222, acc.: 75.00%] [G loss: 1.334971]\n",
      "epoch:18 step:17388 [D loss: 0.565542, acc.: 74.22%] [G loss: 1.155020]\n",
      "epoch:18 step:17389 [D loss: 0.525189, acc.: 74.22%] [G loss: 1.500445]\n",
      "epoch:18 step:17390 [D loss: 0.599569, acc.: 69.53%] [G loss: 1.140370]\n",
      "epoch:18 step:17391 [D loss: 0.666585, acc.: 57.81%] [G loss: 1.046285]\n",
      "epoch:18 step:17392 [D loss: 0.750397, acc.: 56.25%] [G loss: 1.058381]\n",
      "epoch:18 step:17393 [D loss: 0.478239, acc.: 80.47%] [G loss: 1.460032]\n",
      "epoch:18 step:17394 [D loss: 0.622216, acc.: 67.19%] [G loss: 1.124949]\n",
      "epoch:18 step:17395 [D loss: 0.481559, acc.: 82.81%] [G loss: 1.353037]\n",
      "epoch:18 step:17396 [D loss: 0.525522, acc.: 76.56%] [G loss: 1.190575]\n",
      "epoch:18 step:17397 [D loss: 0.552070, acc.: 68.75%] [G loss: 1.643180]\n",
      "epoch:18 step:17398 [D loss: 0.530512, acc.: 71.09%] [G loss: 1.471069]\n",
      "epoch:18 step:17399 [D loss: 0.640159, acc.: 66.41%] [G loss: 1.219113]\n",
      "epoch:18 step:17400 [D loss: 0.609580, acc.: 68.75%] [G loss: 1.185901]\n",
      "epoch:18 step:17401 [D loss: 0.579367, acc.: 75.00%] [G loss: 1.263886]\n",
      "epoch:18 step:17402 [D loss: 0.612340, acc.: 68.75%] [G loss: 1.226112]\n",
      "epoch:18 step:17403 [D loss: 0.519275, acc.: 75.00%] [G loss: 1.570498]\n",
      "epoch:18 step:17404 [D loss: 0.686070, acc.: 59.38%] [G loss: 1.001506]\n",
      "epoch:18 step:17405 [D loss: 0.555022, acc.: 71.09%] [G loss: 1.269585]\n",
      "epoch:18 step:17406 [D loss: 0.605330, acc.: 68.75%] [G loss: 1.057795]\n",
      "epoch:18 step:17407 [D loss: 0.431900, acc.: 82.03%] [G loss: 1.159214]\n",
      "epoch:18 step:17408 [D loss: 0.597148, acc.: 61.72%] [G loss: 1.070292]\n",
      "epoch:18 step:17409 [D loss: 0.707757, acc.: 59.38%] [G loss: 1.409284]\n",
      "epoch:18 step:17410 [D loss: 0.653824, acc.: 64.84%] [G loss: 1.683907]\n",
      "epoch:18 step:17411 [D loss: 0.696644, acc.: 60.94%] [G loss: 1.172617]\n",
      "epoch:18 step:17412 [D loss: 0.593758, acc.: 69.53%] [G loss: 1.022118]\n",
      "epoch:18 step:17413 [D loss: 0.577186, acc.: 67.19%] [G loss: 1.533934]\n",
      "epoch:18 step:17414 [D loss: 0.649548, acc.: 64.84%] [G loss: 0.990277]\n",
      "epoch:18 step:17415 [D loss: 0.554892, acc.: 75.00%] [G loss: 1.395734]\n",
      "epoch:18 step:17416 [D loss: 0.592404, acc.: 73.44%] [G loss: 1.327601]\n",
      "epoch:18 step:17417 [D loss: 0.599486, acc.: 69.53%] [G loss: 1.531126]\n",
      "epoch:18 step:17418 [D loss: 0.570024, acc.: 75.00%] [G loss: 1.675460]\n",
      "epoch:18 step:17419 [D loss: 0.559173, acc.: 67.97%] [G loss: 1.148119]\n",
      "epoch:18 step:17420 [D loss: 0.770388, acc.: 53.12%] [G loss: 1.258179]\n",
      "epoch:18 step:17421 [D loss: 0.585503, acc.: 69.53%] [G loss: 1.409433]\n",
      "epoch:18 step:17422 [D loss: 0.635119, acc.: 66.41%] [G loss: 1.216338]\n",
      "epoch:18 step:17423 [D loss: 0.639991, acc.: 66.41%] [G loss: 1.278487]\n",
      "epoch:18 step:17424 [D loss: 0.598748, acc.: 66.41%] [G loss: 1.097634]\n",
      "epoch:18 step:17425 [D loss: 0.497897, acc.: 80.47%] [G loss: 1.682755]\n",
      "epoch:18 step:17426 [D loss: 0.560214, acc.: 72.66%] [G loss: 1.227772]\n",
      "epoch:18 step:17427 [D loss: 0.643937, acc.: 63.28%] [G loss: 1.032119]\n",
      "epoch:18 step:17428 [D loss: 0.557860, acc.: 69.53%] [G loss: 1.373118]\n",
      "epoch:18 step:17429 [D loss: 0.436498, acc.: 82.81%] [G loss: 1.668234]\n",
      "epoch:18 step:17430 [D loss: 0.607231, acc.: 68.75%] [G loss: 1.115806]\n",
      "epoch:18 step:17431 [D loss: 0.583227, acc.: 71.09%] [G loss: 0.915834]\n",
      "epoch:18 step:17432 [D loss: 0.662064, acc.: 60.16%] [G loss: 1.074183]\n",
      "epoch:18 step:17433 [D loss: 0.778390, acc.: 50.00%] [G loss: 1.185984]\n",
      "epoch:18 step:17434 [D loss: 0.630563, acc.: 62.50%] [G loss: 1.244087]\n",
      "epoch:18 step:17435 [D loss: 0.567153, acc.: 67.97%] [G loss: 1.228576]\n",
      "epoch:18 step:17436 [D loss: 0.599775, acc.: 67.19%] [G loss: 1.522881]\n",
      "epoch:18 step:17437 [D loss: 0.483185, acc.: 78.12%] [G loss: 1.107448]\n",
      "epoch:18 step:17438 [D loss: 0.438923, acc.: 84.38%] [G loss: 1.392175]\n",
      "epoch:18 step:17439 [D loss: 0.669282, acc.: 62.50%] [G loss: 1.216578]\n",
      "epoch:18 step:17440 [D loss: 0.794955, acc.: 49.22%] [G loss: 1.026572]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:18 step:17441 [D loss: 0.579241, acc.: 70.31%] [G loss: 1.342911]\n",
      "epoch:18 step:17442 [D loss: 0.527725, acc.: 73.44%] [G loss: 1.377919]\n",
      "epoch:18 step:17443 [D loss: 0.667744, acc.: 60.94%] [G loss: 1.012098]\n",
      "epoch:18 step:17444 [D loss: 0.555941, acc.: 70.31%] [G loss: 1.409562]\n",
      "epoch:18 step:17445 [D loss: 0.587779, acc.: 71.88%] [G loss: 1.350748]\n",
      "epoch:18 step:17446 [D loss: 0.579814, acc.: 70.31%] [G loss: 0.982961]\n",
      "epoch:18 step:17447 [D loss: 0.564555, acc.: 70.31%] [G loss: 1.083859]\n",
      "epoch:18 step:17448 [D loss: 0.593013, acc.: 70.31%] [G loss: 1.207522]\n",
      "epoch:18 step:17449 [D loss: 0.544128, acc.: 68.75%] [G loss: 1.481179]\n",
      "epoch:18 step:17450 [D loss: 0.611358, acc.: 68.75%] [G loss: 1.159444]\n",
      "epoch:18 step:17451 [D loss: 0.481434, acc.: 76.56%] [G loss: 1.408417]\n",
      "epoch:18 step:17452 [D loss: 0.569640, acc.: 71.88%] [G loss: 0.985715]\n",
      "epoch:18 step:17453 [D loss: 0.599830, acc.: 64.84%] [G loss: 1.291438]\n",
      "epoch:18 step:17454 [D loss: 0.596024, acc.: 68.75%] [G loss: 1.386833]\n",
      "epoch:18 step:17455 [D loss: 0.508652, acc.: 75.00%] [G loss: 1.198504]\n",
      "epoch:18 step:17456 [D loss: 0.539133, acc.: 78.12%] [G loss: 1.211724]\n",
      "epoch:18 step:17457 [D loss: 0.496290, acc.: 75.00%] [G loss: 1.291924]\n",
      "epoch:18 step:17458 [D loss: 0.523181, acc.: 75.78%] [G loss: 1.797077]\n",
      "epoch:18 step:17459 [D loss: 0.647944, acc.: 60.16%] [G loss: 1.332550]\n",
      "epoch:18 step:17460 [D loss: 0.542584, acc.: 68.75%] [G loss: 1.393543]\n",
      "epoch:18 step:17461 [D loss: 0.586745, acc.: 66.41%] [G loss: 1.309603]\n",
      "epoch:18 step:17462 [D loss: 0.462136, acc.: 82.03%] [G loss: 1.739068]\n",
      "epoch:18 step:17463 [D loss: 0.688382, acc.: 55.47%] [G loss: 0.875723]\n",
      "epoch:18 step:17464 [D loss: 0.634652, acc.: 67.97%] [G loss: 1.040626]\n",
      "epoch:18 step:17465 [D loss: 0.505018, acc.: 74.22%] [G loss: 1.183517]\n",
      "epoch:18 step:17466 [D loss: 0.454941, acc.: 76.56%] [G loss: 1.243818]\n",
      "epoch:18 step:17467 [D loss: 0.661095, acc.: 63.28%] [G loss: 1.259362]\n",
      "epoch:18 step:17468 [D loss: 0.525672, acc.: 75.00%] [G loss: 1.494707]\n",
      "epoch:18 step:17469 [D loss: 0.601531, acc.: 71.09%] [G loss: 1.106472]\n",
      "epoch:18 step:17470 [D loss: 0.569771, acc.: 74.22%] [G loss: 1.387604]\n",
      "epoch:18 step:17471 [D loss: 0.741409, acc.: 51.56%] [G loss: 1.379195]\n",
      "epoch:18 step:17472 [D loss: 0.792749, acc.: 49.22%] [G loss: 1.383288]\n",
      "epoch:18 step:17473 [D loss: 0.436407, acc.: 82.03%] [G loss: 1.531923]\n",
      "epoch:18 step:17474 [D loss: 0.631859, acc.: 66.41%] [G loss: 1.334746]\n",
      "epoch:18 step:17475 [D loss: 0.620147, acc.: 66.41%] [G loss: 1.083710]\n",
      "epoch:18 step:17476 [D loss: 0.480666, acc.: 78.12%] [G loss: 1.491105]\n",
      "epoch:18 step:17477 [D loss: 0.444407, acc.: 83.59%] [G loss: 1.345050]\n",
      "epoch:18 step:17478 [D loss: 0.500954, acc.: 75.78%] [G loss: 1.180329]\n",
      "epoch:18 step:17479 [D loss: 0.469188, acc.: 80.47%] [G loss: 1.200317]\n",
      "epoch:18 step:17480 [D loss: 0.672673, acc.: 62.50%] [G loss: 1.069052]\n",
      "epoch:18 step:17481 [D loss: 0.501871, acc.: 77.34%] [G loss: 1.362445]\n",
      "epoch:18 step:17482 [D loss: 0.573817, acc.: 70.31%] [G loss: 1.111123]\n",
      "epoch:18 step:17483 [D loss: 0.507935, acc.: 76.56%] [G loss: 1.431433]\n",
      "epoch:18 step:17484 [D loss: 0.603547, acc.: 66.41%] [G loss: 1.293961]\n",
      "epoch:18 step:17485 [D loss: 0.572089, acc.: 73.44%] [G loss: 1.063920]\n",
      "epoch:18 step:17486 [D loss: 0.635616, acc.: 63.28%] [G loss: 1.050018]\n",
      "epoch:18 step:17487 [D loss: 0.637511, acc.: 65.62%] [G loss: 1.237575]\n",
      "epoch:18 step:17488 [D loss: 0.595554, acc.: 66.41%] [G loss: 1.455987]\n",
      "epoch:18 step:17489 [D loss: 0.584237, acc.: 74.22%] [G loss: 1.345184]\n",
      "epoch:18 step:17490 [D loss: 0.520777, acc.: 76.56%] [G loss: 1.469359]\n",
      "epoch:18 step:17491 [D loss: 0.473785, acc.: 79.69%] [G loss: 1.425459]\n",
      "epoch:18 step:17492 [D loss: 0.557458, acc.: 71.88%] [G loss: 1.399030]\n",
      "epoch:18 step:17493 [D loss: 0.576227, acc.: 69.53%] [G loss: 1.484987]\n",
      "epoch:18 step:17494 [D loss: 0.675619, acc.: 60.16%] [G loss: 1.241395]\n",
      "epoch:18 step:17495 [D loss: 0.533624, acc.: 75.78%] [G loss: 1.253464]\n",
      "epoch:18 step:17496 [D loss: 0.550090, acc.: 71.88%] [G loss: 1.181705]\n",
      "epoch:18 step:17497 [D loss: 0.491081, acc.: 81.25%] [G loss: 0.859133]\n",
      "epoch:18 step:17498 [D loss: 0.403113, acc.: 85.94%] [G loss: 1.272912]\n",
      "epoch:18 step:17499 [D loss: 0.527219, acc.: 74.22%] [G loss: 1.389273]\n",
      "epoch:18 step:17500 [D loss: 0.561570, acc.: 70.31%] [G loss: 0.879346]\n",
      "epoch:18 step:17501 [D loss: 0.566909, acc.: 67.19%] [G loss: 1.191605]\n",
      "epoch:18 step:17502 [D loss: 0.596538, acc.: 64.84%] [G loss: 1.172889]\n",
      "epoch:18 step:17503 [D loss: 0.491996, acc.: 80.47%] [G loss: 1.288730]\n",
      "epoch:18 step:17504 [D loss: 0.571646, acc.: 70.31%] [G loss: 1.385793]\n",
      "epoch:18 step:17505 [D loss: 0.694576, acc.: 60.94%] [G loss: 1.248112]\n",
      "epoch:18 step:17506 [D loss: 0.581793, acc.: 68.75%] [G loss: 1.144778]\n",
      "epoch:18 step:17507 [D loss: 0.559293, acc.: 70.31%] [G loss: 1.429053]\n",
      "epoch:18 step:17508 [D loss: 0.509636, acc.: 76.56%] [G loss: 1.198714]\n",
      "epoch:18 step:17509 [D loss: 0.682799, acc.: 60.16%] [G loss: 0.989685]\n",
      "epoch:18 step:17510 [D loss: 0.626715, acc.: 68.75%] [G loss: 1.088095]\n",
      "epoch:18 step:17511 [D loss: 0.586066, acc.: 66.41%] [G loss: 1.256742]\n",
      "epoch:18 step:17512 [D loss: 0.721991, acc.: 61.72%] [G loss: 1.220883]\n",
      "epoch:18 step:17513 [D loss: 0.462783, acc.: 78.12%] [G loss: 1.122484]\n",
      "epoch:18 step:17514 [D loss: 0.432117, acc.: 78.91%] [G loss: 1.343814]\n",
      "epoch:18 step:17515 [D loss: 0.493636, acc.: 79.69%] [G loss: 1.000450]\n",
      "epoch:18 step:17516 [D loss: 0.550699, acc.: 69.53%] [G loss: 1.220204]\n",
      "epoch:18 step:17517 [D loss: 0.439007, acc.: 84.38%] [G loss: 1.647892]\n",
      "epoch:18 step:17518 [D loss: 0.678072, acc.: 56.25%] [G loss: 1.082378]\n",
      "epoch:18 step:17519 [D loss: 0.657469, acc.: 61.72%] [G loss: 1.350220]\n",
      "epoch:18 step:17520 [D loss: 0.646309, acc.: 60.94%] [G loss: 1.120973]\n",
      "epoch:18 step:17521 [D loss: 0.590445, acc.: 67.19%] [G loss: 1.423466]\n",
      "epoch:18 step:17522 [D loss: 0.544365, acc.: 71.09%] [G loss: 1.134920]\n",
      "epoch:18 step:17523 [D loss: 0.632475, acc.: 65.62%] [G loss: 1.136539]\n",
      "epoch:18 step:17524 [D loss: 0.720076, acc.: 59.38%] [G loss: 1.321814]\n",
      "epoch:18 step:17525 [D loss: 0.619817, acc.: 64.06%] [G loss: 1.127361]\n",
      "epoch:18 step:17526 [D loss: 0.545018, acc.: 71.88%] [G loss: 1.228102]\n",
      "epoch:18 step:17527 [D loss: 0.643026, acc.: 61.72%] [G loss: 1.236102]\n",
      "epoch:18 step:17528 [D loss: 0.549997, acc.: 71.88%] [G loss: 1.476028]\n",
      "epoch:18 step:17529 [D loss: 0.582604, acc.: 70.31%] [G loss: 1.425596]\n",
      "epoch:18 step:17530 [D loss: 0.740463, acc.: 57.81%] [G loss: 1.298576]\n",
      "epoch:18 step:17531 [D loss: 0.551998, acc.: 72.66%] [G loss: 1.421424]\n",
      "epoch:18 step:17532 [D loss: 0.482888, acc.: 75.78%] [G loss: 1.463125]\n",
      "epoch:18 step:17533 [D loss: 0.544229, acc.: 72.66%] [G loss: 1.237032]\n",
      "epoch:18 step:17534 [D loss: 0.642548, acc.: 65.62%] [G loss: 1.411028]\n",
      "epoch:18 step:17535 [D loss: 0.556659, acc.: 73.44%] [G loss: 1.213578]\n",
      "epoch:18 step:17536 [D loss: 0.525865, acc.: 72.66%] [G loss: 1.500958]\n",
      "epoch:18 step:17537 [D loss: 0.670977, acc.: 60.16%] [G loss: 1.205129]\n",
      "epoch:18 step:17538 [D loss: 0.615853, acc.: 66.41%] [G loss: 1.297451]\n",
      "epoch:18 step:17539 [D loss: 0.590749, acc.: 70.31%] [G loss: 1.159594]\n",
      "epoch:18 step:17540 [D loss: 0.522376, acc.: 71.09%] [G loss: 1.083261]\n",
      "epoch:18 step:17541 [D loss: 0.645192, acc.: 59.38%] [G loss: 1.305888]\n",
      "epoch:18 step:17542 [D loss: 0.595676, acc.: 67.19%] [G loss: 1.291449]\n",
      "epoch:18 step:17543 [D loss: 0.498084, acc.: 78.91%] [G loss: 1.460537]\n",
      "epoch:18 step:17544 [D loss: 0.629597, acc.: 63.28%] [G loss: 0.979720]\n",
      "epoch:18 step:17545 [D loss: 0.618100, acc.: 64.84%] [G loss: 1.402943]\n",
      "epoch:18 step:17546 [D loss: 0.551884, acc.: 73.44%] [G loss: 1.182733]\n",
      "epoch:18 step:17547 [D loss: 0.504558, acc.: 73.44%] [G loss: 1.264826]\n",
      "epoch:18 step:17548 [D loss: 0.605447, acc.: 66.41%] [G loss: 1.297467]\n",
      "epoch:18 step:17549 [D loss: 0.669968, acc.: 54.69%] [G loss: 1.303677]\n",
      "epoch:18 step:17550 [D loss: 0.544222, acc.: 75.78%] [G loss: 1.159503]\n",
      "epoch:18 step:17551 [D loss: 0.593545, acc.: 71.09%] [G loss: 1.353823]\n",
      "epoch:18 step:17552 [D loss: 0.654719, acc.: 59.38%] [G loss: 1.401827]\n",
      "epoch:18 step:17553 [D loss: 0.554254, acc.: 72.66%] [G loss: 1.280753]\n",
      "epoch:18 step:17554 [D loss: 0.574286, acc.: 69.53%] [G loss: 1.252948]\n",
      "epoch:18 step:17555 [D loss: 0.743966, acc.: 51.56%] [G loss: 1.195516]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:18 step:17556 [D loss: 0.508647, acc.: 72.66%] [G loss: 1.206053]\n",
      "epoch:18 step:17557 [D loss: 0.764497, acc.: 57.03%] [G loss: 0.985238]\n",
      "epoch:18 step:17558 [D loss: 0.592576, acc.: 70.31%] [G loss: 1.266893]\n",
      "epoch:18 step:17559 [D loss: 0.611934, acc.: 69.53%] [G loss: 1.102722]\n",
      "epoch:18 step:17560 [D loss: 0.511116, acc.: 78.91%] [G loss: 1.347287]\n",
      "epoch:18 step:17561 [D loss: 0.496626, acc.: 76.56%] [G loss: 1.255933]\n",
      "epoch:18 step:17562 [D loss: 0.513628, acc.: 78.12%] [G loss: 1.071071]\n",
      "epoch:18 step:17563 [D loss: 0.671640, acc.: 60.16%] [G loss: 0.957994]\n",
      "epoch:18 step:17564 [D loss: 0.609012, acc.: 67.19%] [G loss: 1.643643]\n",
      "epoch:18 step:17565 [D loss: 0.537415, acc.: 76.56%] [G loss: 1.310035]\n",
      "epoch:18 step:17566 [D loss: 0.438244, acc.: 82.03%] [G loss: 1.284247]\n",
      "epoch:18 step:17567 [D loss: 0.449438, acc.: 80.47%] [G loss: 1.360436]\n",
      "epoch:18 step:17568 [D loss: 0.538027, acc.: 71.88%] [G loss: 1.668394]\n",
      "epoch:18 step:17569 [D loss: 0.693117, acc.: 59.38%] [G loss: 1.413546]\n",
      "epoch:18 step:17570 [D loss: 0.757900, acc.: 52.34%] [G loss: 1.348447]\n",
      "epoch:18 step:17571 [D loss: 0.538819, acc.: 75.00%] [G loss: 1.321853]\n",
      "epoch:18 step:17572 [D loss: 0.663574, acc.: 58.59%] [G loss: 1.196015]\n",
      "epoch:18 step:17573 [D loss: 0.597193, acc.: 68.75%] [G loss: 1.380114]\n",
      "epoch:18 step:17574 [D loss: 0.488215, acc.: 81.25%] [G loss: 1.402794]\n",
      "epoch:18 step:17575 [D loss: 0.724102, acc.: 56.25%] [G loss: 1.403951]\n",
      "epoch:18 step:17576 [D loss: 0.514997, acc.: 76.56%] [G loss: 1.186477]\n",
      "epoch:18 step:17577 [D loss: 0.585737, acc.: 71.88%] [G loss: 1.558054]\n",
      "epoch:18 step:17578 [D loss: 0.675955, acc.: 58.59%] [G loss: 1.248348]\n",
      "epoch:18 step:17579 [D loss: 0.661424, acc.: 62.50%] [G loss: 1.246124]\n",
      "epoch:18 step:17580 [D loss: 0.630563, acc.: 63.28%] [G loss: 1.456126]\n",
      "epoch:18 step:17581 [D loss: 0.552418, acc.: 72.66%] [G loss: 1.493016]\n",
      "epoch:18 step:17582 [D loss: 0.517021, acc.: 75.78%] [G loss: 1.376451]\n",
      "epoch:18 step:17583 [D loss: 0.557700, acc.: 75.00%] [G loss: 1.052760]\n",
      "epoch:18 step:17584 [D loss: 0.624684, acc.: 66.41%] [G loss: 1.312964]\n",
      "epoch:18 step:17585 [D loss: 0.699859, acc.: 57.03%] [G loss: 0.999298]\n",
      "epoch:18 step:17586 [D loss: 0.523077, acc.: 71.09%] [G loss: 1.219958]\n",
      "epoch:18 step:17587 [D loss: 0.621782, acc.: 64.06%] [G loss: 1.191886]\n",
      "epoch:18 step:17588 [D loss: 0.738211, acc.: 54.69%] [G loss: 1.347124]\n",
      "epoch:18 step:17589 [D loss: 0.586455, acc.: 69.53%] [G loss: 1.254586]\n",
      "epoch:18 step:17590 [D loss: 0.529461, acc.: 79.69%] [G loss: 1.565365]\n",
      "epoch:18 step:17591 [D loss: 0.509506, acc.: 74.22%] [G loss: 1.416720]\n",
      "epoch:18 step:17592 [D loss: 0.694432, acc.: 60.16%] [G loss: 1.140436]\n",
      "epoch:18 step:17593 [D loss: 0.635911, acc.: 60.16%] [G loss: 1.246589]\n",
      "epoch:18 step:17594 [D loss: 0.647729, acc.: 64.84%] [G loss: 1.087109]\n",
      "epoch:18 step:17595 [D loss: 0.608872, acc.: 64.06%] [G loss: 1.535474]\n",
      "epoch:18 step:17596 [D loss: 0.548296, acc.: 70.31%] [G loss: 1.642761]\n",
      "epoch:18 step:17597 [D loss: 0.691991, acc.: 57.81%] [G loss: 1.225733]\n",
      "epoch:18 step:17598 [D loss: 0.666441, acc.: 60.16%] [G loss: 1.496797]\n",
      "epoch:18 step:17599 [D loss: 0.495957, acc.: 77.34%] [G loss: 1.137101]\n",
      "epoch:18 step:17600 [D loss: 0.487883, acc.: 76.56%] [G loss: 1.406806]\n",
      "epoch:18 step:17601 [D loss: 0.623548, acc.: 67.19%] [G loss: 1.151599]\n",
      "epoch:18 step:17602 [D loss: 0.633255, acc.: 64.84%] [G loss: 1.095692]\n",
      "epoch:18 step:17603 [D loss: 0.560422, acc.: 71.09%] [G loss: 1.112268]\n",
      "epoch:18 step:17604 [D loss: 0.716971, acc.: 58.59%] [G loss: 0.999553]\n",
      "epoch:18 step:17605 [D loss: 0.643348, acc.: 63.28%] [G loss: 1.164568]\n",
      "epoch:18 step:17606 [D loss: 0.736153, acc.: 52.34%] [G loss: 1.147943]\n",
      "epoch:18 step:17607 [D loss: 0.560205, acc.: 72.66%] [G loss: 1.340432]\n",
      "epoch:18 step:17608 [D loss: 0.498342, acc.: 78.12%] [G loss: 1.494994]\n",
      "epoch:18 step:17609 [D loss: 0.805871, acc.: 45.31%] [G loss: 1.188231]\n",
      "epoch:18 step:17610 [D loss: 0.503468, acc.: 72.66%] [G loss: 1.461718]\n",
      "epoch:18 step:17611 [D loss: 0.538037, acc.: 70.31%] [G loss: 1.462348]\n",
      "epoch:18 step:17612 [D loss: 0.486394, acc.: 79.69%] [G loss: 1.218805]\n",
      "epoch:18 step:17613 [D loss: 0.491689, acc.: 78.12%] [G loss: 1.252338]\n",
      "epoch:18 step:17614 [D loss: 0.488979, acc.: 77.34%] [G loss: 1.553946]\n",
      "epoch:18 step:17615 [D loss: 0.825349, acc.: 46.09%] [G loss: 1.119180]\n",
      "epoch:18 step:17616 [D loss: 0.513248, acc.: 75.00%] [G loss: 1.038578]\n",
      "epoch:18 step:17617 [D loss: 0.584668, acc.: 71.09%] [G loss: 1.169123]\n",
      "epoch:18 step:17618 [D loss: 0.701081, acc.: 60.94%] [G loss: 0.942018]\n",
      "epoch:18 step:17619 [D loss: 0.643954, acc.: 64.84%] [G loss: 1.117193]\n",
      "epoch:18 step:17620 [D loss: 0.462884, acc.: 78.91%] [G loss: 1.435469]\n",
      "epoch:18 step:17621 [D loss: 0.473159, acc.: 78.12%] [G loss: 1.309021]\n",
      "epoch:18 step:17622 [D loss: 0.555463, acc.: 73.44%] [G loss: 1.247641]\n",
      "epoch:18 step:17623 [D loss: 0.487961, acc.: 79.69%] [G loss: 1.295920]\n",
      "epoch:18 step:17624 [D loss: 0.527451, acc.: 72.66%] [G loss: 1.065233]\n",
      "epoch:18 step:17625 [D loss: 0.389962, acc.: 85.16%] [G loss: 1.461020]\n",
      "epoch:18 step:17626 [D loss: 0.572022, acc.: 72.66%] [G loss: 1.515851]\n",
      "epoch:18 step:17627 [D loss: 0.706953, acc.: 63.28%] [G loss: 1.200319]\n",
      "epoch:18 step:17628 [D loss: 0.445140, acc.: 78.12%] [G loss: 1.581372]\n",
      "epoch:18 step:17629 [D loss: 0.606104, acc.: 70.31%] [G loss: 1.010211]\n",
      "epoch:18 step:17630 [D loss: 0.478287, acc.: 78.12%] [G loss: 1.392367]\n",
      "epoch:18 step:17631 [D loss: 0.526950, acc.: 72.66%] [G loss: 1.138188]\n",
      "epoch:18 step:17632 [D loss: 0.556730, acc.: 71.09%] [G loss: 0.997003]\n",
      "epoch:18 step:17633 [D loss: 0.451579, acc.: 79.69%] [G loss: 1.257491]\n",
      "epoch:18 step:17634 [D loss: 0.682905, acc.: 59.38%] [G loss: 1.321407]\n",
      "epoch:18 step:17635 [D loss: 0.554366, acc.: 70.31%] [G loss: 1.271860]\n",
      "epoch:18 step:17636 [D loss: 0.569359, acc.: 71.09%] [G loss: 1.379535]\n",
      "epoch:18 step:17637 [D loss: 0.498312, acc.: 71.09%] [G loss: 1.469020]\n",
      "epoch:18 step:17638 [D loss: 0.606719, acc.: 69.53%] [G loss: 1.059834]\n",
      "epoch:18 step:17639 [D loss: 0.576635, acc.: 70.31%] [G loss: 1.161050]\n",
      "epoch:18 step:17640 [D loss: 0.574817, acc.: 75.00%] [G loss: 1.291661]\n",
      "epoch:18 step:17641 [D loss: 0.574534, acc.: 71.09%] [G loss: 1.367680]\n",
      "epoch:18 step:17642 [D loss: 0.556810, acc.: 73.44%] [G loss: 1.336398]\n",
      "epoch:18 step:17643 [D loss: 0.477399, acc.: 78.91%] [G loss: 1.727609]\n",
      "epoch:18 step:17644 [D loss: 0.594071, acc.: 68.75%] [G loss: 1.358278]\n",
      "epoch:18 step:17645 [D loss: 0.712368, acc.: 57.81%] [G loss: 1.278507]\n",
      "epoch:18 step:17646 [D loss: 0.655548, acc.: 64.84%] [G loss: 1.418161]\n",
      "epoch:18 step:17647 [D loss: 0.484077, acc.: 81.25%] [G loss: 1.357490]\n",
      "epoch:18 step:17648 [D loss: 0.470789, acc.: 80.47%] [G loss: 1.369440]\n",
      "epoch:18 step:17649 [D loss: 0.509408, acc.: 71.88%] [G loss: 1.247120]\n",
      "epoch:18 step:17650 [D loss: 0.697836, acc.: 60.94%] [G loss: 1.123422]\n",
      "epoch:18 step:17651 [D loss: 0.504110, acc.: 75.78%] [G loss: 1.810104]\n",
      "epoch:18 step:17652 [D loss: 0.645597, acc.: 60.16%] [G loss: 1.516517]\n",
      "epoch:18 step:17653 [D loss: 0.626968, acc.: 67.97%] [G loss: 1.042028]\n",
      "epoch:18 step:17654 [D loss: 0.575265, acc.: 66.41%] [G loss: 1.102744]\n",
      "epoch:18 step:17655 [D loss: 0.701893, acc.: 62.50%] [G loss: 1.305436]\n",
      "epoch:18 step:17656 [D loss: 0.414329, acc.: 86.72%] [G loss: 1.324106]\n",
      "epoch:18 step:17657 [D loss: 0.506755, acc.: 78.12%] [G loss: 1.280638]\n",
      "epoch:18 step:17658 [D loss: 0.494645, acc.: 75.78%] [G loss: 1.604396]\n",
      "epoch:18 step:17659 [D loss: 0.577609, acc.: 65.62%] [G loss: 1.518234]\n",
      "epoch:18 step:17660 [D loss: 0.489434, acc.: 79.69%] [G loss: 1.099759]\n",
      "epoch:18 step:17661 [D loss: 0.621332, acc.: 63.28%] [G loss: 1.218859]\n",
      "epoch:18 step:17662 [D loss: 0.597437, acc.: 68.75%] [G loss: 0.993012]\n",
      "epoch:18 step:17663 [D loss: 0.538924, acc.: 71.09%] [G loss: 1.492488]\n",
      "epoch:18 step:17664 [D loss: 0.627200, acc.: 61.72%] [G loss: 1.131642]\n",
      "epoch:18 step:17665 [D loss: 0.535381, acc.: 71.09%] [G loss: 1.337727]\n",
      "epoch:18 step:17666 [D loss: 0.509633, acc.: 76.56%] [G loss: 1.125706]\n",
      "epoch:18 step:17667 [D loss: 0.659136, acc.: 60.16%] [G loss: 1.156065]\n",
      "epoch:18 step:17668 [D loss: 0.576746, acc.: 68.75%] [G loss: 1.048754]\n",
      "epoch:18 step:17669 [D loss: 0.617252, acc.: 57.81%] [G loss: 0.937202]\n",
      "epoch:18 step:17670 [D loss: 0.658946, acc.: 64.84%] [G loss: 0.902605]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:18 step:17671 [D loss: 0.638553, acc.: 63.28%] [G loss: 1.302247]\n",
      "epoch:18 step:17672 [D loss: 0.459773, acc.: 78.91%] [G loss: 1.350061]\n",
      "epoch:18 step:17673 [D loss: 0.579620, acc.: 66.41%] [G loss: 1.434989]\n",
      "epoch:18 step:17674 [D loss: 0.515991, acc.: 75.00%] [G loss: 1.330913]\n",
      "epoch:18 step:17675 [D loss: 0.598864, acc.: 69.53%] [G loss: 1.278662]\n",
      "epoch:18 step:17676 [D loss: 0.468463, acc.: 79.69%] [G loss: 1.323004]\n",
      "epoch:18 step:17677 [D loss: 0.686884, acc.: 56.25%] [G loss: 1.261038]\n",
      "epoch:18 step:17678 [D loss: 0.591193, acc.: 65.62%] [G loss: 1.151993]\n",
      "epoch:18 step:17679 [D loss: 0.537766, acc.: 75.00%] [G loss: 1.608193]\n",
      "epoch:18 step:17680 [D loss: 0.517247, acc.: 75.78%] [G loss: 1.348338]\n",
      "epoch:18 step:17681 [D loss: 0.578944, acc.: 67.19%] [G loss: 1.467024]\n",
      "epoch:18 step:17682 [D loss: 0.519319, acc.: 75.00%] [G loss: 1.615388]\n",
      "epoch:18 step:17683 [D loss: 0.509537, acc.: 75.00%] [G loss: 1.097917]\n",
      "epoch:18 step:17684 [D loss: 0.614546, acc.: 69.53%] [G loss: 1.254765]\n",
      "epoch:18 step:17685 [D loss: 0.596076, acc.: 69.53%] [G loss: 1.454203]\n",
      "epoch:18 step:17686 [D loss: 0.635090, acc.: 67.97%] [G loss: 1.158707]\n",
      "epoch:18 step:17687 [D loss: 0.832934, acc.: 51.56%] [G loss: 1.053418]\n",
      "epoch:18 step:17688 [D loss: 0.492106, acc.: 81.25%] [G loss: 1.412504]\n",
      "epoch:18 step:17689 [D loss: 0.662243, acc.: 60.16%] [G loss: 1.206362]\n",
      "epoch:18 step:17690 [D loss: 0.668422, acc.: 64.06%] [G loss: 1.455815]\n",
      "epoch:18 step:17691 [D loss: 0.572781, acc.: 70.31%] [G loss: 1.140821]\n",
      "epoch:18 step:17692 [D loss: 0.664671, acc.: 57.03%] [G loss: 1.099881]\n",
      "epoch:18 step:17693 [D loss: 0.534277, acc.: 72.66%] [G loss: 1.083173]\n",
      "epoch:18 step:17694 [D loss: 0.686127, acc.: 56.25%] [G loss: 1.190058]\n",
      "epoch:18 step:17695 [D loss: 0.572497, acc.: 67.97%] [G loss: 1.139520]\n",
      "epoch:18 step:17696 [D loss: 0.517843, acc.: 78.12%] [G loss: 1.271050]\n",
      "epoch:18 step:17697 [D loss: 0.625533, acc.: 64.84%] [G loss: 1.071161]\n",
      "epoch:18 step:17698 [D loss: 0.673117, acc.: 64.06%] [G loss: 1.633984]\n",
      "epoch:18 step:17699 [D loss: 0.511876, acc.: 78.12%] [G loss: 1.425721]\n",
      "epoch:18 step:17700 [D loss: 0.579147, acc.: 69.53%] [G loss: 1.044085]\n",
      "epoch:18 step:17701 [D loss: 0.460393, acc.: 79.69%] [G loss: 1.358859]\n",
      "epoch:18 step:17702 [D loss: 0.678760, acc.: 60.16%] [G loss: 1.211296]\n",
      "epoch:18 step:17703 [D loss: 0.570437, acc.: 72.66%] [G loss: 1.503666]\n",
      "epoch:18 step:17704 [D loss: 0.437292, acc.: 85.16%] [G loss: 1.555489]\n",
      "epoch:18 step:17705 [D loss: 0.516220, acc.: 71.88%] [G loss: 1.409303]\n",
      "epoch:18 step:17706 [D loss: 0.575532, acc.: 67.97%] [G loss: 1.080366]\n",
      "epoch:18 step:17707 [D loss: 0.500772, acc.: 73.44%] [G loss: 1.474548]\n",
      "epoch:18 step:17708 [D loss: 0.513907, acc.: 78.12%] [G loss: 1.358653]\n",
      "epoch:18 step:17709 [D loss: 0.502406, acc.: 75.00%] [G loss: 1.435678]\n",
      "epoch:18 step:17710 [D loss: 0.584521, acc.: 69.53%] [G loss: 1.264723]\n",
      "epoch:18 step:17711 [D loss: 0.600010, acc.: 68.75%] [G loss: 1.010266]\n",
      "epoch:18 step:17712 [D loss: 0.542647, acc.: 71.09%] [G loss: 1.036691]\n",
      "epoch:18 step:17713 [D loss: 0.561922, acc.: 67.97%] [G loss: 1.306190]\n",
      "epoch:18 step:17714 [D loss: 0.553419, acc.: 71.09%] [G loss: 1.387617]\n",
      "epoch:18 step:17715 [D loss: 0.474048, acc.: 78.12%] [G loss: 1.248786]\n",
      "epoch:18 step:17716 [D loss: 0.478673, acc.: 72.66%] [G loss: 1.210093]\n",
      "epoch:18 step:17717 [D loss: 0.700625, acc.: 53.91%] [G loss: 0.896019]\n",
      "epoch:18 step:17718 [D loss: 0.409746, acc.: 88.28%] [G loss: 1.789642]\n",
      "epoch:18 step:17719 [D loss: 0.717051, acc.: 56.25%] [G loss: 1.294220]\n",
      "epoch:18 step:17720 [D loss: 0.557582, acc.: 72.66%] [G loss: 0.977642]\n",
      "epoch:18 step:17721 [D loss: 0.643880, acc.: 59.38%] [G loss: 1.389545]\n",
      "epoch:18 step:17722 [D loss: 0.569692, acc.: 65.62%] [G loss: 0.879242]\n",
      "epoch:18 step:17723 [D loss: 0.488569, acc.: 77.34%] [G loss: 1.308910]\n",
      "epoch:18 step:17724 [D loss: 0.486435, acc.: 78.91%] [G loss: 1.588103]\n",
      "epoch:18 step:17725 [D loss: 0.643413, acc.: 65.62%] [G loss: 1.211933]\n",
      "epoch:18 step:17726 [D loss: 0.706718, acc.: 57.81%] [G loss: 1.312792]\n",
      "epoch:18 step:17727 [D loss: 0.632852, acc.: 69.53%] [G loss: 0.942577]\n",
      "epoch:18 step:17728 [D loss: 0.563829, acc.: 74.22%] [G loss: 1.520500]\n",
      "epoch:18 step:17729 [D loss: 0.727875, acc.: 53.91%] [G loss: 1.231370]\n",
      "epoch:18 step:17730 [D loss: 0.486233, acc.: 73.44%] [G loss: 1.633230]\n",
      "epoch:18 step:17731 [D loss: 0.600499, acc.: 67.19%] [G loss: 1.265251]\n",
      "epoch:18 step:17732 [D loss: 0.577433, acc.: 71.09%] [G loss: 0.914462]\n",
      "epoch:18 step:17733 [D loss: 0.494169, acc.: 78.91%] [G loss: 1.338026]\n",
      "epoch:18 step:17734 [D loss: 0.478269, acc.: 78.12%] [G loss: 1.493471]\n",
      "epoch:18 step:17735 [D loss: 0.558560, acc.: 70.31%] [G loss: 0.920716]\n",
      "epoch:18 step:17736 [D loss: 0.688298, acc.: 54.69%] [G loss: 1.205006]\n",
      "epoch:18 step:17737 [D loss: 0.523857, acc.: 72.66%] [G loss: 1.298947]\n",
      "epoch:18 step:17738 [D loss: 0.541949, acc.: 73.44%] [G loss: 1.292291]\n",
      "epoch:18 step:17739 [D loss: 0.460982, acc.: 83.59%] [G loss: 1.549867]\n",
      "epoch:18 step:17740 [D loss: 0.483755, acc.: 82.81%] [G loss: 1.503372]\n",
      "epoch:18 step:17741 [D loss: 0.563149, acc.: 76.56%] [G loss: 1.461393]\n",
      "epoch:18 step:17742 [D loss: 0.537116, acc.: 71.09%] [G loss: 1.325984]\n",
      "epoch:18 step:17743 [D loss: 0.463809, acc.: 76.56%] [G loss: 1.264043]\n",
      "epoch:18 step:17744 [D loss: 0.490229, acc.: 76.56%] [G loss: 1.201408]\n",
      "epoch:18 step:17745 [D loss: 0.688698, acc.: 61.72%] [G loss: 1.313831]\n",
      "epoch:18 step:17746 [D loss: 0.617452, acc.: 64.84%] [G loss: 0.957815]\n",
      "epoch:18 step:17747 [D loss: 0.527350, acc.: 75.00%] [G loss: 1.341367]\n",
      "epoch:18 step:17748 [D loss: 0.498430, acc.: 78.91%] [G loss: 1.330456]\n",
      "epoch:18 step:17749 [D loss: 0.683221, acc.: 57.03%] [G loss: 1.343717]\n",
      "epoch:18 step:17750 [D loss: 0.553679, acc.: 72.66%] [G loss: 1.267919]\n",
      "epoch:18 step:17751 [D loss: 0.556364, acc.: 70.31%] [G loss: 1.363359]\n",
      "epoch:18 step:17752 [D loss: 0.631004, acc.: 64.06%] [G loss: 1.407432]\n",
      "epoch:18 step:17753 [D loss: 0.520132, acc.: 77.34%] [G loss: 1.048444]\n",
      "epoch:18 step:17754 [D loss: 0.660748, acc.: 68.75%] [G loss: 0.851592]\n",
      "epoch:18 step:17755 [D loss: 0.697344, acc.: 60.16%] [G loss: 1.022089]\n",
      "epoch:18 step:17756 [D loss: 0.501730, acc.: 81.25%] [G loss: 1.239224]\n",
      "epoch:18 step:17757 [D loss: 0.736430, acc.: 53.91%] [G loss: 1.087031]\n",
      "epoch:18 step:17758 [D loss: 0.355888, acc.: 88.28%] [G loss: 1.201413]\n",
      "epoch:18 step:17759 [D loss: 0.580898, acc.: 68.75%] [G loss: 1.074550]\n",
      "epoch:18 step:17760 [D loss: 0.468825, acc.: 80.47%] [G loss: 1.387432]\n",
      "epoch:18 step:17761 [D loss: 0.570043, acc.: 69.53%] [G loss: 1.277014]\n",
      "epoch:18 step:17762 [D loss: 0.580874, acc.: 72.66%] [G loss: 1.350560]\n",
      "epoch:18 step:17763 [D loss: 0.612515, acc.: 66.41%] [G loss: 1.264105]\n",
      "epoch:18 step:17764 [D loss: 0.567971, acc.: 70.31%] [G loss: 1.343668]\n",
      "epoch:18 step:17765 [D loss: 0.602083, acc.: 67.19%] [G loss: 1.202876]\n",
      "epoch:18 step:17766 [D loss: 0.460700, acc.: 78.12%] [G loss: 1.519392]\n",
      "epoch:18 step:17767 [D loss: 0.578106, acc.: 71.09%] [G loss: 1.442255]\n",
      "epoch:18 step:17768 [D loss: 0.639100, acc.: 67.97%] [G loss: 0.969340]\n",
      "epoch:18 step:17769 [D loss: 0.427073, acc.: 80.47%] [G loss: 1.412485]\n",
      "epoch:18 step:17770 [D loss: 0.475321, acc.: 80.47%] [G loss: 1.512826]\n",
      "epoch:18 step:17771 [D loss: 0.623190, acc.: 64.06%] [G loss: 1.071580]\n",
      "epoch:18 step:17772 [D loss: 0.473039, acc.: 82.03%] [G loss: 1.537893]\n",
      "epoch:18 step:17773 [D loss: 0.784343, acc.: 53.12%] [G loss: 1.134966]\n",
      "epoch:18 step:17774 [D loss: 0.649432, acc.: 65.62%] [G loss: 1.287526]\n",
      "epoch:18 step:17775 [D loss: 0.471538, acc.: 79.69%] [G loss: 1.643537]\n",
      "epoch:18 step:17776 [D loss: 0.505081, acc.: 75.78%] [G loss: 1.422217]\n",
      "epoch:18 step:17777 [D loss: 0.463574, acc.: 79.69%] [G loss: 1.336539]\n",
      "epoch:18 step:17778 [D loss: 0.637797, acc.: 66.41%] [G loss: 1.399768]\n",
      "epoch:18 step:17779 [D loss: 0.669066, acc.: 56.25%] [G loss: 1.218182]\n",
      "epoch:18 step:17780 [D loss: 0.607821, acc.: 71.09%] [G loss: 1.170076]\n",
      "epoch:18 step:17781 [D loss: 0.643128, acc.: 64.84%] [G loss: 1.303168]\n",
      "epoch:18 step:17782 [D loss: 0.528249, acc.: 75.78%] [G loss: 1.445757]\n",
      "epoch:18 step:17783 [D loss: 0.520537, acc.: 72.66%] [G loss: 1.223752]\n",
      "epoch:18 step:17784 [D loss: 0.490807, acc.: 75.78%] [G loss: 1.177384]\n",
      "epoch:18 step:17785 [D loss: 0.522187, acc.: 77.34%] [G loss: 1.293798]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:18 step:17786 [D loss: 0.520056, acc.: 74.22%] [G loss: 1.373514]\n",
      "epoch:18 step:17787 [D loss: 0.645939, acc.: 64.06%] [G loss: 1.116005]\n",
      "epoch:18 step:17788 [D loss: 0.659146, acc.: 62.50%] [G loss: 1.062159]\n",
      "epoch:18 step:17789 [D loss: 0.660795, acc.: 61.72%] [G loss: 1.614486]\n",
      "epoch:18 step:17790 [D loss: 0.583477, acc.: 67.97%] [G loss: 1.171780]\n",
      "epoch:18 step:17791 [D loss: 0.510684, acc.: 72.66%] [G loss: 1.462004]\n",
      "epoch:18 step:17792 [D loss: 0.568799, acc.: 68.75%] [G loss: 1.038154]\n",
      "epoch:18 step:17793 [D loss: 0.550955, acc.: 73.44%] [G loss: 1.313805]\n",
      "epoch:18 step:17794 [D loss: 0.464898, acc.: 77.34%] [G loss: 1.296186]\n",
      "epoch:18 step:17795 [D loss: 0.612328, acc.: 67.19%] [G loss: 0.992776]\n",
      "epoch:18 step:17796 [D loss: 0.691906, acc.: 58.59%] [G loss: 1.478189]\n",
      "epoch:18 step:17797 [D loss: 0.616651, acc.: 63.28%] [G loss: 1.353988]\n",
      "epoch:18 step:17798 [D loss: 0.504725, acc.: 74.22%] [G loss: 1.244201]\n",
      "epoch:18 step:17799 [D loss: 0.635792, acc.: 65.62%] [G loss: 1.382441]\n",
      "epoch:18 step:17800 [D loss: 0.562699, acc.: 68.75%] [G loss: 1.345951]\n",
      "epoch:18 step:17801 [D loss: 0.512377, acc.: 74.22%] [G loss: 1.185453]\n",
      "epoch:18 step:17802 [D loss: 0.457067, acc.: 82.81%] [G loss: 1.412071]\n",
      "epoch:18 step:17803 [D loss: 0.657938, acc.: 66.41%] [G loss: 1.416887]\n",
      "epoch:19 step:17804 [D loss: 0.580177, acc.: 71.09%] [G loss: 1.245804]\n",
      "epoch:19 step:17805 [D loss: 0.658159, acc.: 63.28%] [G loss: 1.063298]\n",
      "epoch:19 step:17806 [D loss: 0.679197, acc.: 61.72%] [G loss: 1.114385]\n",
      "epoch:19 step:17807 [D loss: 0.592699, acc.: 66.41%] [G loss: 1.336011]\n",
      "epoch:19 step:17808 [D loss: 0.538227, acc.: 78.12%] [G loss: 1.357515]\n",
      "epoch:19 step:17809 [D loss: 0.555047, acc.: 70.31%] [G loss: 1.578008]\n",
      "epoch:19 step:17810 [D loss: 0.688646, acc.: 62.50%] [G loss: 1.614147]\n",
      "epoch:19 step:17811 [D loss: 0.606426, acc.: 61.72%] [G loss: 1.417324]\n",
      "epoch:19 step:17812 [D loss: 0.460262, acc.: 82.03%] [G loss: 1.369801]\n",
      "epoch:19 step:17813 [D loss: 0.578298, acc.: 68.75%] [G loss: 1.554489]\n",
      "epoch:19 step:17814 [D loss: 0.427626, acc.: 80.47%] [G loss: 1.348097]\n",
      "epoch:19 step:17815 [D loss: 0.540417, acc.: 78.91%] [G loss: 1.392938]\n",
      "epoch:19 step:17816 [D loss: 0.599482, acc.: 67.19%] [G loss: 1.028509]\n",
      "epoch:19 step:17817 [D loss: 0.591954, acc.: 64.84%] [G loss: 1.464855]\n",
      "epoch:19 step:17818 [D loss: 0.503603, acc.: 78.12%] [G loss: 1.501128]\n",
      "epoch:19 step:17819 [D loss: 0.512740, acc.: 79.69%] [G loss: 1.313277]\n",
      "epoch:19 step:17820 [D loss: 0.563463, acc.: 74.22%] [G loss: 1.589622]\n",
      "epoch:19 step:17821 [D loss: 0.538738, acc.: 71.09%] [G loss: 1.255917]\n",
      "epoch:19 step:17822 [D loss: 0.523209, acc.: 76.56%] [G loss: 1.532025]\n",
      "epoch:19 step:17823 [D loss: 0.501166, acc.: 78.91%] [G loss: 1.427823]\n",
      "epoch:19 step:17824 [D loss: 0.650361, acc.: 63.28%] [G loss: 1.259536]\n",
      "epoch:19 step:17825 [D loss: 0.521903, acc.: 71.88%] [G loss: 1.575799]\n",
      "epoch:19 step:17826 [D loss: 0.556952, acc.: 71.09%] [G loss: 1.225735]\n",
      "epoch:19 step:17827 [D loss: 0.507478, acc.: 78.91%] [G loss: 1.278819]\n",
      "epoch:19 step:17828 [D loss: 0.609919, acc.: 64.84%] [G loss: 1.383238]\n",
      "epoch:19 step:17829 [D loss: 0.524121, acc.: 73.44%] [G loss: 1.226296]\n",
      "epoch:19 step:17830 [D loss: 0.509937, acc.: 78.12%] [G loss: 1.450719]\n",
      "epoch:19 step:17831 [D loss: 0.534486, acc.: 72.66%] [G loss: 1.079072]\n",
      "epoch:19 step:17832 [D loss: 0.585393, acc.: 67.97%] [G loss: 1.053875]\n",
      "epoch:19 step:17833 [D loss: 0.602559, acc.: 65.62%] [G loss: 1.292466]\n",
      "epoch:19 step:17834 [D loss: 0.594481, acc.: 66.41%] [G loss: 1.354928]\n",
      "epoch:19 step:17835 [D loss: 0.507667, acc.: 78.12%] [G loss: 1.327307]\n",
      "epoch:19 step:17836 [D loss: 0.637140, acc.: 61.72%] [G loss: 1.290082]\n",
      "epoch:19 step:17837 [D loss: 0.707022, acc.: 55.47%] [G loss: 1.365148]\n",
      "epoch:19 step:17838 [D loss: 0.523050, acc.: 74.22%] [G loss: 1.395625]\n",
      "epoch:19 step:17839 [D loss: 0.501736, acc.: 74.22%] [G loss: 1.036195]\n",
      "epoch:19 step:17840 [D loss: 0.533535, acc.: 75.00%] [G loss: 1.112190]\n",
      "epoch:19 step:17841 [D loss: 0.621173, acc.: 63.28%] [G loss: 1.452298]\n",
      "epoch:19 step:17842 [D loss: 0.582134, acc.: 67.97%] [G loss: 1.272215]\n",
      "epoch:19 step:17843 [D loss: 0.578231, acc.: 73.44%] [G loss: 0.990550]\n",
      "epoch:19 step:17844 [D loss: 0.582367, acc.: 70.31%] [G loss: 0.874009]\n",
      "epoch:19 step:17845 [D loss: 0.545991, acc.: 67.19%] [G loss: 1.216588]\n",
      "epoch:19 step:17846 [D loss: 0.484736, acc.: 78.12%] [G loss: 1.560790]\n",
      "epoch:19 step:17847 [D loss: 0.672482, acc.: 67.97%] [G loss: 1.483069]\n",
      "epoch:19 step:17848 [D loss: 0.542322, acc.: 71.09%] [G loss: 1.047589]\n",
      "epoch:19 step:17849 [D loss: 0.745457, acc.: 53.12%] [G loss: 1.328667]\n",
      "epoch:19 step:17850 [D loss: 0.495251, acc.: 76.56%] [G loss: 1.163823]\n",
      "epoch:19 step:17851 [D loss: 0.730765, acc.: 57.81%] [G loss: 1.003096]\n",
      "epoch:19 step:17852 [D loss: 0.502561, acc.: 78.91%] [G loss: 1.387053]\n",
      "epoch:19 step:17853 [D loss: 0.539416, acc.: 71.09%] [G loss: 1.309610]\n",
      "epoch:19 step:17854 [D loss: 0.600463, acc.: 67.97%] [G loss: 1.270891]\n",
      "epoch:19 step:17855 [D loss: 0.581251, acc.: 71.09%] [G loss: 0.974968]\n",
      "epoch:19 step:17856 [D loss: 0.648343, acc.: 63.28%] [G loss: 1.348166]\n",
      "epoch:19 step:17857 [D loss: 0.510457, acc.: 77.34%] [G loss: 1.408624]\n",
      "epoch:19 step:17858 [D loss: 0.675699, acc.: 63.28%] [G loss: 1.260515]\n",
      "epoch:19 step:17859 [D loss: 0.637507, acc.: 61.72%] [G loss: 1.505898]\n",
      "epoch:19 step:17860 [D loss: 0.694490, acc.: 60.16%] [G loss: 1.321080]\n",
      "epoch:19 step:17861 [D loss: 0.581796, acc.: 66.41%] [G loss: 1.517536]\n",
      "epoch:19 step:17862 [D loss: 0.431793, acc.: 80.47%] [G loss: 1.485499]\n",
      "epoch:19 step:17863 [D loss: 0.454640, acc.: 78.12%] [G loss: 1.301985]\n",
      "epoch:19 step:17864 [D loss: 0.652049, acc.: 64.06%] [G loss: 0.950192]\n",
      "epoch:19 step:17865 [D loss: 0.575458, acc.: 69.53%] [G loss: 1.501104]\n",
      "epoch:19 step:17866 [D loss: 0.491029, acc.: 81.25%] [G loss: 1.332809]\n",
      "epoch:19 step:17867 [D loss: 0.670084, acc.: 57.03%] [G loss: 1.317501]\n",
      "epoch:19 step:17868 [D loss: 0.378015, acc.: 88.28%] [G loss: 1.766246]\n",
      "epoch:19 step:17869 [D loss: 0.731371, acc.: 52.34%] [G loss: 1.326158]\n",
      "epoch:19 step:17870 [D loss: 0.466233, acc.: 78.91%] [G loss: 1.558447]\n",
      "epoch:19 step:17871 [D loss: 0.661612, acc.: 64.06%] [G loss: 0.924539]\n",
      "epoch:19 step:17872 [D loss: 0.432174, acc.: 80.47%] [G loss: 1.451500]\n",
      "epoch:19 step:17873 [D loss: 0.662876, acc.: 60.16%] [G loss: 1.307261]\n",
      "epoch:19 step:17874 [D loss: 0.554638, acc.: 71.88%] [G loss: 1.486645]\n",
      "epoch:19 step:17875 [D loss: 0.574111, acc.: 68.75%] [G loss: 1.296647]\n",
      "epoch:19 step:17876 [D loss: 0.530714, acc.: 70.31%] [G loss: 1.499554]\n",
      "epoch:19 step:17877 [D loss: 0.594728, acc.: 68.75%] [G loss: 1.296871]\n",
      "epoch:19 step:17878 [D loss: 0.604790, acc.: 63.28%] [G loss: 1.300194]\n",
      "epoch:19 step:17879 [D loss: 0.519660, acc.: 76.56%] [G loss: 1.290192]\n",
      "epoch:19 step:17880 [D loss: 0.494891, acc.: 77.34%] [G loss: 1.226536]\n",
      "epoch:19 step:17881 [D loss: 0.490227, acc.: 82.03%] [G loss: 1.367505]\n",
      "epoch:19 step:17882 [D loss: 0.628472, acc.: 67.97%] [G loss: 1.192454]\n",
      "epoch:19 step:17883 [D loss: 0.461395, acc.: 79.69%] [G loss: 1.532063]\n",
      "epoch:19 step:17884 [D loss: 0.705487, acc.: 60.94%] [G loss: 1.135604]\n",
      "epoch:19 step:17885 [D loss: 0.583250, acc.: 64.84%] [G loss: 1.298778]\n",
      "epoch:19 step:17886 [D loss: 0.566482, acc.: 67.97%] [G loss: 1.442920]\n",
      "epoch:19 step:17887 [D loss: 0.670749, acc.: 60.94%] [G loss: 1.047578]\n",
      "epoch:19 step:17888 [D loss: 0.604033, acc.: 64.06%] [G loss: 1.397270]\n",
      "epoch:19 step:17889 [D loss: 0.604410, acc.: 64.84%] [G loss: 1.357163]\n",
      "epoch:19 step:17890 [D loss: 0.572342, acc.: 74.22%] [G loss: 1.603474]\n",
      "epoch:19 step:17891 [D loss: 0.459332, acc.: 80.47%] [G loss: 1.522734]\n",
      "epoch:19 step:17892 [D loss: 0.674829, acc.: 60.94%] [G loss: 1.306460]\n",
      "epoch:19 step:17893 [D loss: 0.440237, acc.: 80.47%] [G loss: 1.317562]\n",
      "epoch:19 step:17894 [D loss: 0.485979, acc.: 75.00%] [G loss: 1.395602]\n",
      "epoch:19 step:17895 [D loss: 0.515933, acc.: 71.88%] [G loss: 1.248444]\n",
      "epoch:19 step:17896 [D loss: 0.465250, acc.: 77.34%] [G loss: 1.380913]\n",
      "epoch:19 step:17897 [D loss: 0.415644, acc.: 84.38%] [G loss: 1.531512]\n",
      "epoch:19 step:17898 [D loss: 0.717099, acc.: 58.59%] [G loss: 1.560226]\n",
      "epoch:19 step:17899 [D loss: 0.548392, acc.: 68.75%] [G loss: 1.355271]\n",
      "epoch:19 step:17900 [D loss: 0.718736, acc.: 57.81%] [G loss: 1.033874]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:19 step:17901 [D loss: 0.525059, acc.: 75.00%] [G loss: 1.279775]\n",
      "epoch:19 step:17902 [D loss: 0.556113, acc.: 67.97%] [G loss: 1.364062]\n",
      "epoch:19 step:17903 [D loss: 0.661592, acc.: 64.84%] [G loss: 1.067502]\n",
      "epoch:19 step:17904 [D loss: 0.486791, acc.: 80.47%] [G loss: 1.240839]\n",
      "epoch:19 step:17905 [D loss: 0.703568, acc.: 56.25%] [G loss: 0.938976]\n",
      "epoch:19 step:17906 [D loss: 0.520159, acc.: 72.66%] [G loss: 1.079307]\n",
      "epoch:19 step:17907 [D loss: 0.539918, acc.: 74.22%] [G loss: 1.648797]\n",
      "epoch:19 step:17908 [D loss: 0.535936, acc.: 77.34%] [G loss: 1.320807]\n",
      "epoch:19 step:17909 [D loss: 0.584327, acc.: 73.44%] [G loss: 1.496559]\n",
      "epoch:19 step:17910 [D loss: 0.539871, acc.: 71.88%] [G loss: 1.181581]\n",
      "epoch:19 step:17911 [D loss: 0.608209, acc.: 66.41%] [G loss: 1.164425]\n",
      "epoch:19 step:17912 [D loss: 0.680203, acc.: 59.38%] [G loss: 1.175254]\n",
      "epoch:19 step:17913 [D loss: 0.679931, acc.: 58.59%] [G loss: 1.268464]\n",
      "epoch:19 step:17914 [D loss: 0.679279, acc.: 64.06%] [G loss: 1.234924]\n",
      "epoch:19 step:17915 [D loss: 0.644650, acc.: 57.81%] [G loss: 1.248241]\n",
      "epoch:19 step:17916 [D loss: 0.474767, acc.: 78.91%] [G loss: 1.430646]\n",
      "epoch:19 step:17917 [D loss: 0.460900, acc.: 81.25%] [G loss: 1.176328]\n",
      "epoch:19 step:17918 [D loss: 0.548217, acc.: 69.53%] [G loss: 1.465482]\n",
      "epoch:19 step:17919 [D loss: 0.535039, acc.: 71.88%] [G loss: 1.233773]\n",
      "epoch:19 step:17920 [D loss: 0.573876, acc.: 73.44%] [G loss: 1.237337]\n",
      "epoch:19 step:17921 [D loss: 0.649611, acc.: 64.84%] [G loss: 1.390576]\n",
      "epoch:19 step:17922 [D loss: 0.408855, acc.: 83.59%] [G loss: 1.270100]\n",
      "epoch:19 step:17923 [D loss: 0.560065, acc.: 73.44%] [G loss: 1.602033]\n",
      "epoch:19 step:17924 [D loss: 0.494582, acc.: 75.00%] [G loss: 1.240408]\n",
      "epoch:19 step:17925 [D loss: 0.764311, acc.: 53.91%] [G loss: 0.953006]\n",
      "epoch:19 step:17926 [D loss: 0.504069, acc.: 77.34%] [G loss: 1.573053]\n",
      "epoch:19 step:17927 [D loss: 0.630723, acc.: 61.72%] [G loss: 1.296036]\n",
      "epoch:19 step:17928 [D loss: 0.510091, acc.: 75.78%] [G loss: 1.207001]\n",
      "epoch:19 step:17929 [D loss: 0.692328, acc.: 58.59%] [G loss: 1.072874]\n",
      "epoch:19 step:17930 [D loss: 0.614261, acc.: 66.41%] [G loss: 1.259476]\n",
      "epoch:19 step:17931 [D loss: 0.687316, acc.: 59.38%] [G loss: 1.330570]\n",
      "epoch:19 step:17932 [D loss: 0.515040, acc.: 75.00%] [G loss: 1.397644]\n",
      "epoch:19 step:17933 [D loss: 0.565896, acc.: 71.09%] [G loss: 1.472748]\n",
      "epoch:19 step:17934 [D loss: 0.584801, acc.: 69.53%] [G loss: 1.159763]\n",
      "epoch:19 step:17935 [D loss: 0.576360, acc.: 67.97%] [G loss: 1.172701]\n",
      "epoch:19 step:17936 [D loss: 0.519362, acc.: 78.12%] [G loss: 1.205856]\n",
      "epoch:19 step:17937 [D loss: 0.604863, acc.: 67.19%] [G loss: 1.421981]\n",
      "epoch:19 step:17938 [D loss: 0.607952, acc.: 63.28%] [G loss: 1.117810]\n",
      "epoch:19 step:17939 [D loss: 0.763855, acc.: 55.47%] [G loss: 1.123287]\n",
      "epoch:19 step:17940 [D loss: 0.492580, acc.: 75.00%] [G loss: 1.259453]\n",
      "epoch:19 step:17941 [D loss: 0.480219, acc.: 80.47%] [G loss: 1.504440]\n",
      "epoch:19 step:17942 [D loss: 0.745310, acc.: 50.00%] [G loss: 1.073759]\n",
      "epoch:19 step:17943 [D loss: 0.592287, acc.: 68.75%] [G loss: 1.410437]\n",
      "epoch:19 step:17944 [D loss: 0.618638, acc.: 63.28%] [G loss: 1.286011]\n",
      "epoch:19 step:17945 [D loss: 0.493067, acc.: 76.56%] [G loss: 1.085747]\n",
      "epoch:19 step:17946 [D loss: 0.616951, acc.: 67.19%] [G loss: 1.133633]\n",
      "epoch:19 step:17947 [D loss: 0.559832, acc.: 70.31%] [G loss: 1.193816]\n",
      "epoch:19 step:17948 [D loss: 0.672596, acc.: 64.06%] [G loss: 1.321758]\n",
      "epoch:19 step:17949 [D loss: 0.624923, acc.: 64.06%] [G loss: 1.395026]\n",
      "epoch:19 step:17950 [D loss: 0.566628, acc.: 70.31%] [G loss: 1.526972]\n",
      "epoch:19 step:17951 [D loss: 0.540394, acc.: 70.31%] [G loss: 1.266401]\n",
      "epoch:19 step:17952 [D loss: 0.532827, acc.: 72.66%] [G loss: 1.191580]\n",
      "epoch:19 step:17953 [D loss: 0.569355, acc.: 67.97%] [G loss: 1.179085]\n",
      "epoch:19 step:17954 [D loss: 0.531962, acc.: 72.66%] [G loss: 1.264289]\n",
      "epoch:19 step:17955 [D loss: 0.550782, acc.: 74.22%] [G loss: 1.193439]\n",
      "epoch:19 step:17956 [D loss: 0.529093, acc.: 74.22%] [G loss: 1.277127]\n",
      "epoch:19 step:17957 [D loss: 0.517659, acc.: 71.88%] [G loss: 1.672916]\n",
      "epoch:19 step:17958 [D loss: 0.609936, acc.: 67.97%] [G loss: 1.400369]\n",
      "epoch:19 step:17959 [D loss: 0.467136, acc.: 79.69%] [G loss: 1.403088]\n",
      "epoch:19 step:17960 [D loss: 0.636871, acc.: 66.41%] [G loss: 1.110679]\n",
      "epoch:19 step:17961 [D loss: 0.569604, acc.: 68.75%] [G loss: 1.262107]\n",
      "epoch:19 step:17962 [D loss: 0.554155, acc.: 69.53%] [G loss: 1.427268]\n",
      "epoch:19 step:17963 [D loss: 0.488169, acc.: 76.56%] [G loss: 1.370585]\n",
      "epoch:19 step:17964 [D loss: 0.548087, acc.: 72.66%] [G loss: 1.125853]\n",
      "epoch:19 step:17965 [D loss: 0.603952, acc.: 72.66%] [G loss: 1.300939]\n",
      "epoch:19 step:17966 [D loss: 0.696826, acc.: 58.59%] [G loss: 1.128507]\n",
      "epoch:19 step:17967 [D loss: 0.586490, acc.: 67.19%] [G loss: 1.269809]\n",
      "epoch:19 step:17968 [D loss: 0.578274, acc.: 68.75%] [G loss: 1.219315]\n",
      "epoch:19 step:17969 [D loss: 0.453578, acc.: 80.47%] [G loss: 1.610727]\n",
      "epoch:19 step:17970 [D loss: 0.453842, acc.: 82.03%] [G loss: 1.154127]\n",
      "epoch:19 step:17971 [D loss: 0.550814, acc.: 75.78%] [G loss: 1.097869]\n",
      "epoch:19 step:17972 [D loss: 0.623900, acc.: 64.84%] [G loss: 1.059730]\n",
      "epoch:19 step:17973 [D loss: 0.608281, acc.: 63.28%] [G loss: 1.005409]\n",
      "epoch:19 step:17974 [D loss: 0.691473, acc.: 58.59%] [G loss: 1.510804]\n",
      "epoch:19 step:17975 [D loss: 0.559514, acc.: 75.78%] [G loss: 1.447671]\n",
      "epoch:19 step:17976 [D loss: 0.679583, acc.: 60.94%] [G loss: 1.474531]\n",
      "epoch:19 step:17977 [D loss: 0.563301, acc.: 71.09%] [G loss: 1.516009]\n",
      "epoch:19 step:17978 [D loss: 0.580334, acc.: 66.41%] [G loss: 1.436432]\n",
      "epoch:19 step:17979 [D loss: 0.607693, acc.: 67.97%] [G loss: 1.203892]\n",
      "epoch:19 step:17980 [D loss: 0.570779, acc.: 68.75%] [G loss: 1.199567]\n",
      "epoch:19 step:17981 [D loss: 0.509602, acc.: 69.53%] [G loss: 1.231063]\n",
      "epoch:19 step:17982 [D loss: 0.615403, acc.: 68.75%] [G loss: 1.299449]\n",
      "epoch:19 step:17983 [D loss: 0.436406, acc.: 83.59%] [G loss: 1.316581]\n",
      "epoch:19 step:17984 [D loss: 0.527747, acc.: 78.12%] [G loss: 1.385538]\n",
      "epoch:19 step:17985 [D loss: 0.454522, acc.: 79.69%] [G loss: 1.571304]\n",
      "epoch:19 step:17986 [D loss: 0.599331, acc.: 67.19%] [G loss: 1.261400]\n",
      "epoch:19 step:17987 [D loss: 0.708452, acc.: 58.59%] [G loss: 1.061648]\n",
      "epoch:19 step:17988 [D loss: 0.587121, acc.: 71.88%] [G loss: 1.323267]\n",
      "epoch:19 step:17989 [D loss: 0.588539, acc.: 71.09%] [G loss: 0.994292]\n",
      "epoch:19 step:17990 [D loss: 0.487522, acc.: 80.47%] [G loss: 1.154886]\n",
      "epoch:19 step:17991 [D loss: 0.528401, acc.: 70.31%] [G loss: 0.981455]\n",
      "epoch:19 step:17992 [D loss: 0.473718, acc.: 78.12%] [G loss: 1.234594]\n",
      "epoch:19 step:17993 [D loss: 0.613608, acc.: 70.31%] [G loss: 1.302678]\n",
      "epoch:19 step:17994 [D loss: 0.598345, acc.: 70.31%] [G loss: 1.247493]\n",
      "epoch:19 step:17995 [D loss: 0.453533, acc.: 82.03%] [G loss: 1.402700]\n",
      "epoch:19 step:17996 [D loss: 0.689644, acc.: 61.72%] [G loss: 0.933395]\n",
      "epoch:19 step:17997 [D loss: 0.648895, acc.: 60.94%] [G loss: 1.198599]\n",
      "epoch:19 step:17998 [D loss: 0.590590, acc.: 69.53%] [G loss: 1.224913]\n",
      "epoch:19 step:17999 [D loss: 0.579554, acc.: 68.75%] [G loss: 1.258497]\n",
      "epoch:19 step:18000 [D loss: 0.648955, acc.: 67.97%] [G loss: 1.035378]\n",
      "epoch:19 step:18001 [D loss: 0.523625, acc.: 77.34%] [G loss: 1.557186]\n",
      "epoch:19 step:18002 [D loss: 0.554713, acc.: 70.31%] [G loss: 1.307425]\n",
      "epoch:19 step:18003 [D loss: 0.611134, acc.: 67.19%] [G loss: 1.477618]\n",
      "epoch:19 step:18004 [D loss: 0.498834, acc.: 77.34%] [G loss: 1.458819]\n",
      "epoch:19 step:18005 [D loss: 0.607901, acc.: 67.19%] [G loss: 1.604595]\n",
      "epoch:19 step:18006 [D loss: 0.471041, acc.: 75.78%] [G loss: 1.192261]\n",
      "epoch:19 step:18007 [D loss: 0.348358, acc.: 89.06%] [G loss: 1.745584]\n",
      "epoch:19 step:18008 [D loss: 0.503301, acc.: 72.66%] [G loss: 1.309651]\n",
      "epoch:19 step:18009 [D loss: 0.513194, acc.: 74.22%] [G loss: 0.898902]\n",
      "epoch:19 step:18010 [D loss: 0.591868, acc.: 70.31%] [G loss: 1.218847]\n",
      "epoch:19 step:18011 [D loss: 0.505807, acc.: 75.00%] [G loss: 1.576853]\n",
      "epoch:19 step:18012 [D loss: 0.597301, acc.: 71.09%] [G loss: 1.100383]\n",
      "epoch:19 step:18013 [D loss: 0.625411, acc.: 67.19%] [G loss: 1.191825]\n",
      "epoch:19 step:18014 [D loss: 0.561964, acc.: 68.75%] [G loss: 1.221817]\n",
      "epoch:19 step:18015 [D loss: 0.573705, acc.: 70.31%] [G loss: 1.392019]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:19 step:18016 [D loss: 0.544529, acc.: 72.66%] [G loss: 1.357131]\n",
      "epoch:19 step:18017 [D loss: 0.467373, acc.: 78.91%] [G loss: 1.313204]\n",
      "epoch:19 step:18018 [D loss: 0.736880, acc.: 53.12%] [G loss: 1.055097]\n",
      "epoch:19 step:18019 [D loss: 0.643380, acc.: 62.50%] [G loss: 1.171167]\n",
      "epoch:19 step:18020 [D loss: 0.602175, acc.: 68.75%] [G loss: 1.288680]\n",
      "epoch:19 step:18021 [D loss: 0.558160, acc.: 72.66%] [G loss: 1.467212]\n",
      "epoch:19 step:18022 [D loss: 0.551330, acc.: 71.09%] [G loss: 1.444263]\n",
      "epoch:19 step:18023 [D loss: 0.535683, acc.: 75.00%] [G loss: 1.229899]\n",
      "epoch:19 step:18024 [D loss: 0.724283, acc.: 54.69%] [G loss: 1.163793]\n",
      "epoch:19 step:18025 [D loss: 0.447048, acc.: 84.38%] [G loss: 1.409535]\n",
      "epoch:19 step:18026 [D loss: 0.497502, acc.: 76.56%] [G loss: 1.554070]\n",
      "epoch:19 step:18027 [D loss: 0.607421, acc.: 69.53%] [G loss: 1.034087]\n",
      "epoch:19 step:18028 [D loss: 0.658268, acc.: 63.28%] [G loss: 1.483975]\n",
      "epoch:19 step:18029 [D loss: 0.460654, acc.: 79.69%] [G loss: 1.498389]\n",
      "epoch:19 step:18030 [D loss: 0.570782, acc.: 70.31%] [G loss: 1.113951]\n",
      "epoch:19 step:18031 [D loss: 0.589476, acc.: 69.53%] [G loss: 1.137190]\n",
      "epoch:19 step:18032 [D loss: 0.598576, acc.: 65.62%] [G loss: 1.120832]\n",
      "epoch:19 step:18033 [D loss: 0.511552, acc.: 78.12%] [G loss: 1.209895]\n",
      "epoch:19 step:18034 [D loss: 0.570341, acc.: 71.88%] [G loss: 1.235180]\n",
      "epoch:19 step:18035 [D loss: 0.626281, acc.: 61.72%] [G loss: 1.141781]\n",
      "epoch:19 step:18036 [D loss: 0.502631, acc.: 76.56%] [G loss: 1.355285]\n",
      "epoch:19 step:18037 [D loss: 0.736472, acc.: 56.25%] [G loss: 1.272102]\n",
      "epoch:19 step:18038 [D loss: 0.395082, acc.: 86.72%] [G loss: 1.554227]\n",
      "epoch:19 step:18039 [D loss: 0.543879, acc.: 71.09%] [G loss: 1.274777]\n",
      "epoch:19 step:18040 [D loss: 0.763172, acc.: 53.91%] [G loss: 1.229989]\n",
      "epoch:19 step:18041 [D loss: 0.625484, acc.: 64.84%] [G loss: 1.299215]\n",
      "epoch:19 step:18042 [D loss: 0.518190, acc.: 82.81%] [G loss: 1.238259]\n",
      "epoch:19 step:18043 [D loss: 0.553620, acc.: 72.66%] [G loss: 1.044655]\n",
      "epoch:19 step:18044 [D loss: 0.496881, acc.: 75.78%] [G loss: 1.400521]\n",
      "epoch:19 step:18045 [D loss: 0.542278, acc.: 75.00%] [G loss: 1.226146]\n",
      "epoch:19 step:18046 [D loss: 0.678107, acc.: 60.16%] [G loss: 0.991580]\n",
      "epoch:19 step:18047 [D loss: 0.606829, acc.: 66.41%] [G loss: 1.412464]\n",
      "epoch:19 step:18048 [D loss: 0.589211, acc.: 68.75%] [G loss: 1.187967]\n",
      "epoch:19 step:18049 [D loss: 0.648745, acc.: 64.84%] [G loss: 1.311841]\n",
      "epoch:19 step:18050 [D loss: 0.544756, acc.: 73.44%] [G loss: 1.444905]\n",
      "epoch:19 step:18051 [D loss: 0.748489, acc.: 54.69%] [G loss: 1.472871]\n",
      "epoch:19 step:18052 [D loss: 0.558472, acc.: 66.41%] [G loss: 1.170092]\n",
      "epoch:19 step:18053 [D loss: 0.670101, acc.: 60.94%] [G loss: 1.322798]\n",
      "epoch:19 step:18054 [D loss: 0.604145, acc.: 67.19%] [G loss: 1.391226]\n",
      "epoch:19 step:18055 [D loss: 0.494233, acc.: 77.34%] [G loss: 1.442334]\n",
      "epoch:19 step:18056 [D loss: 0.504175, acc.: 75.00%] [G loss: 1.143210]\n",
      "epoch:19 step:18057 [D loss: 0.514647, acc.: 77.34%] [G loss: 1.347798]\n",
      "epoch:19 step:18058 [D loss: 0.483055, acc.: 74.22%] [G loss: 1.460196]\n",
      "epoch:19 step:18059 [D loss: 0.651068, acc.: 64.84%] [G loss: 1.225413]\n",
      "epoch:19 step:18060 [D loss: 0.464588, acc.: 80.47%] [G loss: 1.191825]\n",
      "epoch:19 step:18061 [D loss: 0.626360, acc.: 66.41%] [G loss: 1.295191]\n",
      "epoch:19 step:18062 [D loss: 0.448370, acc.: 82.81%] [G loss: 1.289999]\n",
      "epoch:19 step:18063 [D loss: 0.626986, acc.: 68.75%] [G loss: 1.571165]\n",
      "epoch:19 step:18064 [D loss: 0.522063, acc.: 75.00%] [G loss: 1.175340]\n",
      "epoch:19 step:18065 [D loss: 0.600481, acc.: 66.41%] [G loss: 1.175315]\n",
      "epoch:19 step:18066 [D loss: 0.604409, acc.: 69.53%] [G loss: 1.112050]\n",
      "epoch:19 step:18067 [D loss: 0.536020, acc.: 70.31%] [G loss: 1.337111]\n",
      "epoch:19 step:18068 [D loss: 0.743704, acc.: 53.12%] [G loss: 1.336621]\n",
      "epoch:19 step:18069 [D loss: 0.455677, acc.: 82.81%] [G loss: 1.318263]\n",
      "epoch:19 step:18070 [D loss: 0.453271, acc.: 82.03%] [G loss: 1.407784]\n",
      "epoch:19 step:18071 [D loss: 0.616560, acc.: 67.97%] [G loss: 1.301673]\n",
      "epoch:19 step:18072 [D loss: 0.461818, acc.: 78.91%] [G loss: 1.403417]\n",
      "epoch:19 step:18073 [D loss: 0.395704, acc.: 87.50%] [G loss: 1.367915]\n",
      "epoch:19 step:18074 [D loss: 0.380388, acc.: 82.81%] [G loss: 1.290082]\n",
      "epoch:19 step:18075 [D loss: 0.509610, acc.: 77.34%] [G loss: 1.192571]\n",
      "epoch:19 step:18076 [D loss: 0.632682, acc.: 63.28%] [G loss: 1.182633]\n",
      "epoch:19 step:18077 [D loss: 0.567078, acc.: 71.09%] [G loss: 1.132114]\n",
      "epoch:19 step:18078 [D loss: 0.738762, acc.: 57.03%] [G loss: 1.530059]\n",
      "epoch:19 step:18079 [D loss: 0.646251, acc.: 64.06%] [G loss: 1.314864]\n",
      "epoch:19 step:18080 [D loss: 0.548464, acc.: 73.44%] [G loss: 1.249004]\n",
      "epoch:19 step:18081 [D loss: 0.566956, acc.: 71.09%] [G loss: 1.084203]\n",
      "epoch:19 step:18082 [D loss: 0.590962, acc.: 67.97%] [G loss: 1.183817]\n",
      "epoch:19 step:18083 [D loss: 0.556647, acc.: 68.75%] [G loss: 1.737829]\n",
      "epoch:19 step:18084 [D loss: 0.456573, acc.: 82.03%] [G loss: 1.514086]\n",
      "epoch:19 step:18085 [D loss: 0.476003, acc.: 76.56%] [G loss: 1.457541]\n",
      "epoch:19 step:18086 [D loss: 0.511059, acc.: 75.00%] [G loss: 1.360415]\n",
      "epoch:19 step:18087 [D loss: 0.497201, acc.: 79.69%] [G loss: 1.141277]\n",
      "epoch:19 step:18088 [D loss: 0.490686, acc.: 79.69%] [G loss: 1.575069]\n",
      "epoch:19 step:18089 [D loss: 0.534550, acc.: 71.88%] [G loss: 1.342714]\n",
      "epoch:19 step:18090 [D loss: 0.490043, acc.: 76.56%] [G loss: 1.264176]\n",
      "epoch:19 step:18091 [D loss: 0.687798, acc.: 57.81%] [G loss: 1.274311]\n",
      "epoch:19 step:18092 [D loss: 0.653989, acc.: 60.16%] [G loss: 1.066847]\n",
      "epoch:19 step:18093 [D loss: 0.716202, acc.: 57.81%] [G loss: 0.971340]\n",
      "epoch:19 step:18094 [D loss: 0.539769, acc.: 68.75%] [G loss: 1.433860]\n",
      "epoch:19 step:18095 [D loss: 0.466011, acc.: 83.59%] [G loss: 1.332268]\n",
      "epoch:19 step:18096 [D loss: 0.625136, acc.: 67.19%] [G loss: 1.064996]\n",
      "epoch:19 step:18097 [D loss: 0.640803, acc.: 62.50%] [G loss: 1.109260]\n",
      "epoch:19 step:18098 [D loss: 0.565534, acc.: 75.00%] [G loss: 1.235406]\n",
      "epoch:19 step:18099 [D loss: 0.502691, acc.: 78.12%] [G loss: 1.393484]\n",
      "epoch:19 step:18100 [D loss: 0.678389, acc.: 58.59%] [G loss: 1.285243]\n",
      "epoch:19 step:18101 [D loss: 0.732572, acc.: 48.44%] [G loss: 1.509017]\n",
      "epoch:19 step:18102 [D loss: 0.420639, acc.: 87.50%] [G loss: 1.439170]\n",
      "epoch:19 step:18103 [D loss: 0.608603, acc.: 67.19%] [G loss: 1.237807]\n",
      "epoch:19 step:18104 [D loss: 0.630751, acc.: 68.75%] [G loss: 1.178611]\n",
      "epoch:19 step:18105 [D loss: 0.515565, acc.: 73.44%] [G loss: 1.495458]\n",
      "epoch:19 step:18106 [D loss: 0.701046, acc.: 54.69%] [G loss: 1.020906]\n",
      "epoch:19 step:18107 [D loss: 0.724235, acc.: 56.25%] [G loss: 1.242911]\n",
      "epoch:19 step:18108 [D loss: 0.541050, acc.: 78.91%] [G loss: 1.405043]\n",
      "epoch:19 step:18109 [D loss: 0.508766, acc.: 77.34%] [G loss: 1.311444]\n",
      "epoch:19 step:18110 [D loss: 0.583039, acc.: 68.75%] [G loss: 1.476560]\n",
      "epoch:19 step:18111 [D loss: 0.535510, acc.: 71.88%] [G loss: 1.359754]\n",
      "epoch:19 step:18112 [D loss: 0.551956, acc.: 71.88%] [G loss: 1.145120]\n",
      "epoch:19 step:18113 [D loss: 0.559442, acc.: 76.56%] [G loss: 1.530328]\n",
      "epoch:19 step:18114 [D loss: 0.462149, acc.: 80.47%] [G loss: 1.462535]\n",
      "epoch:19 step:18115 [D loss: 0.651852, acc.: 63.28%] [G loss: 1.230903]\n",
      "epoch:19 step:18116 [D loss: 0.745205, acc.: 54.69%] [G loss: 1.097149]\n",
      "epoch:19 step:18117 [D loss: 0.555713, acc.: 71.88%] [G loss: 1.309268]\n",
      "epoch:19 step:18118 [D loss: 0.608091, acc.: 65.62%] [G loss: 1.402541]\n",
      "epoch:19 step:18119 [D loss: 0.489656, acc.: 75.78%] [G loss: 1.544482]\n",
      "epoch:19 step:18120 [D loss: 0.567823, acc.: 73.44%] [G loss: 1.442942]\n",
      "epoch:19 step:18121 [D loss: 0.696723, acc.: 60.94%] [G loss: 1.243129]\n",
      "epoch:19 step:18122 [D loss: 0.608687, acc.: 67.19%] [G loss: 1.027749]\n",
      "epoch:19 step:18123 [D loss: 0.492489, acc.: 77.34%] [G loss: 1.429075]\n",
      "epoch:19 step:18124 [D loss: 0.679976, acc.: 60.94%] [G loss: 1.478410]\n",
      "epoch:19 step:18125 [D loss: 0.555033, acc.: 68.75%] [G loss: 1.316541]\n",
      "epoch:19 step:18126 [D loss: 0.651196, acc.: 64.06%] [G loss: 1.435453]\n",
      "epoch:19 step:18127 [D loss: 0.504746, acc.: 71.09%] [G loss: 1.438460]\n",
      "epoch:19 step:18128 [D loss: 0.494106, acc.: 75.78%] [G loss: 1.321060]\n",
      "epoch:19 step:18129 [D loss: 0.560419, acc.: 72.66%] [G loss: 1.256123]\n",
      "epoch:19 step:18130 [D loss: 0.484126, acc.: 80.47%] [G loss: 1.295037]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:19 step:18131 [D loss: 0.581598, acc.: 67.19%] [G loss: 1.388572]\n",
      "epoch:19 step:18132 [D loss: 0.550917, acc.: 69.53%] [G loss: 1.295064]\n",
      "epoch:19 step:18133 [D loss: 0.640566, acc.: 67.97%] [G loss: 1.081812]\n",
      "epoch:19 step:18134 [D loss: 0.598687, acc.: 67.97%] [G loss: 1.177557]\n",
      "epoch:19 step:18135 [D loss: 0.717752, acc.: 56.25%] [G loss: 1.116679]\n",
      "epoch:19 step:18136 [D loss: 0.563095, acc.: 70.31%] [G loss: 1.145872]\n",
      "epoch:19 step:18137 [D loss: 0.485470, acc.: 76.56%] [G loss: 1.408142]\n",
      "epoch:19 step:18138 [D loss: 0.507828, acc.: 75.00%] [G loss: 1.549347]\n",
      "epoch:19 step:18139 [D loss: 0.544063, acc.: 76.56%] [G loss: 1.151250]\n",
      "epoch:19 step:18140 [D loss: 0.555534, acc.: 69.53%] [G loss: 1.249988]\n",
      "epoch:19 step:18141 [D loss: 0.496290, acc.: 74.22%] [G loss: 1.417450]\n",
      "epoch:19 step:18142 [D loss: 0.556334, acc.: 73.44%] [G loss: 1.321413]\n",
      "epoch:19 step:18143 [D loss: 0.560611, acc.: 71.09%] [G loss: 1.198427]\n",
      "epoch:19 step:18144 [D loss: 0.673312, acc.: 60.16%] [G loss: 1.411614]\n",
      "epoch:19 step:18145 [D loss: 0.632903, acc.: 64.84%] [G loss: 1.194373]\n",
      "epoch:19 step:18146 [D loss: 0.561547, acc.: 71.09%] [G loss: 1.182080]\n",
      "epoch:19 step:18147 [D loss: 0.501803, acc.: 77.34%] [G loss: 1.615317]\n",
      "epoch:19 step:18148 [D loss: 0.557044, acc.: 70.31%] [G loss: 1.420845]\n",
      "epoch:19 step:18149 [D loss: 0.570338, acc.: 71.88%] [G loss: 1.366199]\n",
      "epoch:19 step:18150 [D loss: 0.618642, acc.: 63.28%] [G loss: 1.443730]\n",
      "epoch:19 step:18151 [D loss: 0.609207, acc.: 68.75%] [G loss: 1.295896]\n",
      "epoch:19 step:18152 [D loss: 0.535020, acc.: 72.66%] [G loss: 1.365119]\n",
      "epoch:19 step:18153 [D loss: 0.438861, acc.: 84.38%] [G loss: 1.410685]\n",
      "epoch:19 step:18154 [D loss: 0.529906, acc.: 71.88%] [G loss: 1.157986]\n",
      "epoch:19 step:18155 [D loss: 0.575369, acc.: 74.22%] [G loss: 1.344357]\n",
      "epoch:19 step:18156 [D loss: 0.607315, acc.: 65.62%] [G loss: 1.074894]\n",
      "epoch:19 step:18157 [D loss: 0.514490, acc.: 78.12%] [G loss: 1.414910]\n",
      "epoch:19 step:18158 [D loss: 0.462180, acc.: 80.47%] [G loss: 1.091379]\n",
      "epoch:19 step:18159 [D loss: 0.575824, acc.: 75.78%] [G loss: 1.554168]\n",
      "epoch:19 step:18160 [D loss: 0.634935, acc.: 62.50%] [G loss: 1.227928]\n",
      "epoch:19 step:18161 [D loss: 0.492228, acc.: 77.34%] [G loss: 1.298542]\n",
      "epoch:19 step:18162 [D loss: 0.705539, acc.: 56.25%] [G loss: 1.193496]\n",
      "epoch:19 step:18163 [D loss: 0.493467, acc.: 79.69%] [G loss: 1.284719]\n",
      "epoch:19 step:18164 [D loss: 0.594537, acc.: 69.53%] [G loss: 1.467548]\n",
      "epoch:19 step:18165 [D loss: 0.478374, acc.: 77.34%] [G loss: 1.317779]\n",
      "epoch:19 step:18166 [D loss: 0.465609, acc.: 84.38%] [G loss: 1.260834]\n",
      "epoch:19 step:18167 [D loss: 0.511546, acc.: 76.56%] [G loss: 1.272506]\n",
      "epoch:19 step:18168 [D loss: 0.644401, acc.: 63.28%] [G loss: 0.989589]\n",
      "epoch:19 step:18169 [D loss: 0.609959, acc.: 66.41%] [G loss: 1.287341]\n",
      "epoch:19 step:18170 [D loss: 0.531417, acc.: 76.56%] [G loss: 1.000857]\n",
      "epoch:19 step:18171 [D loss: 0.478655, acc.: 78.12%] [G loss: 1.136780]\n",
      "epoch:19 step:18172 [D loss: 0.543615, acc.: 75.00%] [G loss: 1.366554]\n",
      "epoch:19 step:18173 [D loss: 0.550352, acc.: 73.44%] [G loss: 1.437546]\n",
      "epoch:19 step:18174 [D loss: 0.597364, acc.: 63.28%] [G loss: 1.177190]\n",
      "epoch:19 step:18175 [D loss: 0.603806, acc.: 67.19%] [G loss: 1.659964]\n",
      "epoch:19 step:18176 [D loss: 0.474888, acc.: 82.03%] [G loss: 1.359640]\n",
      "epoch:19 step:18177 [D loss: 0.732005, acc.: 53.12%] [G loss: 1.373508]\n",
      "epoch:19 step:18178 [D loss: 0.617652, acc.: 64.84%] [G loss: 1.091640]\n",
      "epoch:19 step:18179 [D loss: 0.730747, acc.: 54.69%] [G loss: 1.291855]\n",
      "epoch:19 step:18180 [D loss: 0.511039, acc.: 74.22%] [G loss: 1.561199]\n",
      "epoch:19 step:18181 [D loss: 0.621021, acc.: 65.62%] [G loss: 1.163964]\n",
      "epoch:19 step:18182 [D loss: 0.525194, acc.: 76.56%] [G loss: 1.322676]\n",
      "epoch:19 step:18183 [D loss: 0.662738, acc.: 60.16%] [G loss: 1.180550]\n",
      "epoch:19 step:18184 [D loss: 0.625105, acc.: 64.06%] [G loss: 1.373744]\n",
      "epoch:19 step:18185 [D loss: 0.542493, acc.: 74.22%] [G loss: 1.382397]\n",
      "epoch:19 step:18186 [D loss: 0.584124, acc.: 67.97%] [G loss: 1.400369]\n",
      "epoch:19 step:18187 [D loss: 0.567262, acc.: 68.75%] [G loss: 1.395005]\n",
      "epoch:19 step:18188 [D loss: 0.711191, acc.: 60.16%] [G loss: 1.489769]\n",
      "epoch:19 step:18189 [D loss: 0.543358, acc.: 71.88%] [G loss: 1.319441]\n",
      "epoch:19 step:18190 [D loss: 0.471206, acc.: 78.91%] [G loss: 1.408587]\n",
      "epoch:19 step:18191 [D loss: 0.609125, acc.: 67.19%] [G loss: 1.330858]\n",
      "epoch:19 step:18192 [D loss: 0.538462, acc.: 73.44%] [G loss: 1.286248]\n",
      "epoch:19 step:18193 [D loss: 0.565856, acc.: 72.66%] [G loss: 1.089768]\n",
      "epoch:19 step:18194 [D loss: 0.606966, acc.: 71.09%] [G loss: 1.204041]\n",
      "epoch:19 step:18195 [D loss: 0.435085, acc.: 81.25%] [G loss: 1.284484]\n",
      "epoch:19 step:18196 [D loss: 0.580213, acc.: 67.97%] [G loss: 1.279248]\n",
      "epoch:19 step:18197 [D loss: 0.561549, acc.: 70.31%] [G loss: 1.615473]\n",
      "epoch:19 step:18198 [D loss: 0.512671, acc.: 75.00%] [G loss: 1.378201]\n",
      "epoch:19 step:18199 [D loss: 0.641060, acc.: 69.53%] [G loss: 1.258988]\n",
      "epoch:19 step:18200 [D loss: 0.629059, acc.: 67.97%] [G loss: 1.437830]\n",
      "epoch:19 step:18201 [D loss: 0.553177, acc.: 67.97%] [G loss: 1.413012]\n",
      "epoch:19 step:18202 [D loss: 0.587570, acc.: 64.84%] [G loss: 1.387174]\n",
      "epoch:19 step:18203 [D loss: 0.458316, acc.: 74.22%] [G loss: 1.690971]\n",
      "epoch:19 step:18204 [D loss: 0.460226, acc.: 76.56%] [G loss: 1.113944]\n",
      "epoch:19 step:18205 [D loss: 0.544746, acc.: 75.78%] [G loss: 1.444898]\n",
      "epoch:19 step:18206 [D loss: 0.489921, acc.: 74.22%] [G loss: 1.451717]\n",
      "epoch:19 step:18207 [D loss: 0.541270, acc.: 74.22%] [G loss: 1.182798]\n",
      "epoch:19 step:18208 [D loss: 0.546815, acc.: 69.53%] [G loss: 1.255336]\n",
      "epoch:19 step:18209 [D loss: 0.576027, acc.: 72.66%] [G loss: 1.327232]\n",
      "epoch:19 step:18210 [D loss: 0.486773, acc.: 77.34%] [G loss: 1.211275]\n",
      "epoch:19 step:18211 [D loss: 0.422717, acc.: 82.81%] [G loss: 1.494017]\n",
      "epoch:19 step:18212 [D loss: 0.543049, acc.: 74.22%] [G loss: 1.082894]\n",
      "epoch:19 step:18213 [D loss: 0.609729, acc.: 71.09%] [G loss: 1.133795]\n",
      "epoch:19 step:18214 [D loss: 0.619022, acc.: 64.84%] [G loss: 1.232580]\n",
      "epoch:19 step:18215 [D loss: 0.760311, acc.: 56.25%] [G loss: 1.378379]\n",
      "epoch:19 step:18216 [D loss: 0.517191, acc.: 71.88%] [G loss: 1.219820]\n",
      "epoch:19 step:18217 [D loss: 0.523871, acc.: 75.78%] [G loss: 1.230689]\n",
      "epoch:19 step:18218 [D loss: 0.645390, acc.: 66.41%] [G loss: 0.953490]\n",
      "epoch:19 step:18219 [D loss: 0.574594, acc.: 70.31%] [G loss: 1.435022]\n",
      "epoch:19 step:18220 [D loss: 0.547102, acc.: 74.22%] [G loss: 1.540004]\n",
      "epoch:19 step:18221 [D loss: 0.617220, acc.: 69.53%] [G loss: 1.820508]\n",
      "epoch:19 step:18222 [D loss: 0.495199, acc.: 76.56%] [G loss: 1.479031]\n",
      "epoch:19 step:18223 [D loss: 0.635446, acc.: 67.19%] [G loss: 1.214199]\n",
      "epoch:19 step:18224 [D loss: 0.604680, acc.: 67.97%] [G loss: 1.380697]\n",
      "epoch:19 step:18225 [D loss: 0.526037, acc.: 72.66%] [G loss: 1.180080]\n",
      "epoch:19 step:18226 [D loss: 0.570500, acc.: 67.19%] [G loss: 1.277772]\n",
      "epoch:19 step:18227 [D loss: 0.547821, acc.: 70.31%] [G loss: 1.440853]\n",
      "epoch:19 step:18228 [D loss: 0.502857, acc.: 78.12%] [G loss: 1.441171]\n",
      "epoch:19 step:18229 [D loss: 0.521024, acc.: 76.56%] [G loss: 1.220584]\n",
      "epoch:19 step:18230 [D loss: 0.649246, acc.: 60.94%] [G loss: 1.350548]\n",
      "epoch:19 step:18231 [D loss: 0.580302, acc.: 68.75%] [G loss: 1.058239]\n",
      "epoch:19 step:18232 [D loss: 0.478164, acc.: 80.47%] [G loss: 1.646096]\n",
      "epoch:19 step:18233 [D loss: 0.609248, acc.: 61.72%] [G loss: 1.128703]\n",
      "epoch:19 step:18234 [D loss: 0.543950, acc.: 71.09%] [G loss: 1.563465]\n",
      "epoch:19 step:18235 [D loss: 0.558282, acc.: 72.66%] [G loss: 1.250890]\n",
      "epoch:19 step:18236 [D loss: 0.532166, acc.: 75.00%] [G loss: 1.209249]\n",
      "epoch:19 step:18237 [D loss: 0.643379, acc.: 64.06%] [G loss: 1.158401]\n",
      "epoch:19 step:18238 [D loss: 0.626735, acc.: 67.19%] [G loss: 1.214360]\n",
      "epoch:19 step:18239 [D loss: 0.614922, acc.: 64.84%] [G loss: 1.230913]\n",
      "epoch:19 step:18240 [D loss: 0.508987, acc.: 78.91%] [G loss: 1.439537]\n",
      "epoch:19 step:18241 [D loss: 0.576391, acc.: 68.75%] [G loss: 1.490686]\n",
      "epoch:19 step:18242 [D loss: 0.575217, acc.: 69.53%] [G loss: 1.380818]\n",
      "epoch:19 step:18243 [D loss: 0.637424, acc.: 61.72%] [G loss: 1.317896]\n",
      "epoch:19 step:18244 [D loss: 0.419745, acc.: 81.25%] [G loss: 1.365912]\n",
      "epoch:19 step:18245 [D loss: 0.515302, acc.: 72.66%] [G loss: 1.361979]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:19 step:18246 [D loss: 0.493543, acc.: 78.91%] [G loss: 1.420677]\n",
      "epoch:19 step:18247 [D loss: 0.699451, acc.: 60.16%] [G loss: 1.315532]\n",
      "epoch:19 step:18248 [D loss: 0.648190, acc.: 64.84%] [G loss: 1.063290]\n",
      "epoch:19 step:18249 [D loss: 0.568363, acc.: 64.84%] [G loss: 1.272362]\n",
      "epoch:19 step:18250 [D loss: 0.526640, acc.: 76.56%] [G loss: 1.549309]\n",
      "epoch:19 step:18251 [D loss: 0.651994, acc.: 66.41%] [G loss: 1.327683]\n",
      "epoch:19 step:18252 [D loss: 0.501650, acc.: 76.56%] [G loss: 1.508266]\n",
      "epoch:19 step:18253 [D loss: 0.672048, acc.: 60.94%] [G loss: 1.102320]\n",
      "epoch:19 step:18254 [D loss: 0.552859, acc.: 71.88%] [G loss: 1.337457]\n",
      "epoch:19 step:18255 [D loss: 0.547122, acc.: 71.09%] [G loss: 1.208362]\n",
      "epoch:19 step:18256 [D loss: 0.629103, acc.: 65.62%] [G loss: 1.406036]\n",
      "epoch:19 step:18257 [D loss: 0.643735, acc.: 64.06%] [G loss: 1.752352]\n",
      "epoch:19 step:18258 [D loss: 0.564355, acc.: 67.97%] [G loss: 1.275890]\n",
      "epoch:19 step:18259 [D loss: 0.706103, acc.: 55.47%] [G loss: 1.184298]\n",
      "epoch:19 step:18260 [D loss: 0.627212, acc.: 62.50%] [G loss: 1.317397]\n",
      "epoch:19 step:18261 [D loss: 0.519469, acc.: 77.34%] [G loss: 1.072294]\n",
      "epoch:19 step:18262 [D loss: 0.680750, acc.: 60.16%] [G loss: 1.003655]\n",
      "epoch:19 step:18263 [D loss: 0.555559, acc.: 68.75%] [G loss: 1.306128]\n",
      "epoch:19 step:18264 [D loss: 0.756052, acc.: 54.69%] [G loss: 1.197394]\n",
      "epoch:19 step:18265 [D loss: 0.720317, acc.: 56.25%] [G loss: 1.038435]\n",
      "epoch:19 step:18266 [D loss: 0.691828, acc.: 66.41%] [G loss: 1.256805]\n",
      "epoch:19 step:18267 [D loss: 0.623535, acc.: 60.94%] [G loss: 1.302979]\n",
      "epoch:19 step:18268 [D loss: 0.490765, acc.: 77.34%] [G loss: 1.819032]\n",
      "epoch:19 step:18269 [D loss: 0.686857, acc.: 55.47%] [G loss: 1.175268]\n",
      "epoch:19 step:18270 [D loss: 0.474262, acc.: 81.25%] [G loss: 1.324973]\n",
      "epoch:19 step:18271 [D loss: 0.533813, acc.: 73.44%] [G loss: 1.338283]\n",
      "epoch:19 step:18272 [D loss: 0.621154, acc.: 67.19%] [G loss: 1.547089]\n",
      "epoch:19 step:18273 [D loss: 0.801358, acc.: 46.09%] [G loss: 1.232294]\n",
      "epoch:19 step:18274 [D loss: 0.641338, acc.: 66.41%] [G loss: 1.189678]\n",
      "epoch:19 step:18275 [D loss: 0.595600, acc.: 68.75%] [G loss: 1.157470]\n",
      "epoch:19 step:18276 [D loss: 0.428071, acc.: 82.81%] [G loss: 1.739257]\n",
      "epoch:19 step:18277 [D loss: 0.602463, acc.: 68.75%] [G loss: 1.210803]\n",
      "epoch:19 step:18278 [D loss: 0.559569, acc.: 69.53%] [G loss: 1.648668]\n",
      "epoch:19 step:18279 [D loss: 0.433880, acc.: 81.25%] [G loss: 1.848178]\n",
      "epoch:19 step:18280 [D loss: 0.551648, acc.: 72.66%] [G loss: 1.295127]\n",
      "epoch:19 step:18281 [D loss: 0.612098, acc.: 70.31%] [G loss: 0.961980]\n",
      "epoch:19 step:18282 [D loss: 0.403235, acc.: 88.28%] [G loss: 1.273980]\n",
      "epoch:19 step:18283 [D loss: 0.456080, acc.: 81.25%] [G loss: 1.376647]\n",
      "epoch:19 step:18284 [D loss: 0.581939, acc.: 66.41%] [G loss: 1.126954]\n",
      "epoch:19 step:18285 [D loss: 0.550421, acc.: 72.66%] [G loss: 1.128154]\n",
      "epoch:19 step:18286 [D loss: 0.652086, acc.: 63.28%] [G loss: 1.111995]\n",
      "epoch:19 step:18287 [D loss: 0.436126, acc.: 85.16%] [G loss: 1.180164]\n",
      "epoch:19 step:18288 [D loss: 0.542533, acc.: 75.00%] [G loss: 1.624274]\n",
      "epoch:19 step:18289 [D loss: 0.455674, acc.: 80.47%] [G loss: 1.217556]\n",
      "epoch:19 step:18290 [D loss: 0.459581, acc.: 79.69%] [G loss: 1.223673]\n",
      "epoch:19 step:18291 [D loss: 0.503314, acc.: 77.34%] [G loss: 1.338984]\n",
      "epoch:19 step:18292 [D loss: 0.578873, acc.: 64.06%] [G loss: 1.494611]\n",
      "epoch:19 step:18293 [D loss: 0.643647, acc.: 64.06%] [G loss: 1.002311]\n",
      "epoch:19 step:18294 [D loss: 0.519784, acc.: 75.00%] [G loss: 1.378519]\n",
      "epoch:19 step:18295 [D loss: 0.699634, acc.: 54.69%] [G loss: 1.473266]\n",
      "epoch:19 step:18296 [D loss: 0.589778, acc.: 75.78%] [G loss: 1.545905]\n",
      "epoch:19 step:18297 [D loss: 0.572096, acc.: 68.75%] [G loss: 1.331581]\n",
      "epoch:19 step:18298 [D loss: 0.591731, acc.: 68.75%] [G loss: 1.444376]\n",
      "epoch:19 step:18299 [D loss: 0.612879, acc.: 67.19%] [G loss: 1.334567]\n",
      "epoch:19 step:18300 [D loss: 0.579156, acc.: 70.31%] [G loss: 1.358029]\n",
      "epoch:19 step:18301 [D loss: 0.405686, acc.: 83.59%] [G loss: 1.429500]\n",
      "epoch:19 step:18302 [D loss: 0.502171, acc.: 76.56%] [G loss: 1.296327]\n",
      "epoch:19 step:18303 [D loss: 0.567919, acc.: 73.44%] [G loss: 1.272539]\n",
      "epoch:19 step:18304 [D loss: 0.540023, acc.: 72.66%] [G loss: 1.284349]\n",
      "epoch:19 step:18305 [D loss: 0.522748, acc.: 72.66%] [G loss: 1.673826]\n",
      "epoch:19 step:18306 [D loss: 0.564966, acc.: 73.44%] [G loss: 1.160701]\n",
      "epoch:19 step:18307 [D loss: 0.550427, acc.: 74.22%] [G loss: 1.598369]\n",
      "epoch:19 step:18308 [D loss: 0.559576, acc.: 69.53%] [G loss: 1.088607]\n",
      "epoch:19 step:18309 [D loss: 0.577261, acc.: 69.53%] [G loss: 1.095030]\n",
      "epoch:19 step:18310 [D loss: 0.661130, acc.: 60.94%] [G loss: 1.120003]\n",
      "epoch:19 step:18311 [D loss: 0.617236, acc.: 67.19%] [G loss: 1.402778]\n",
      "epoch:19 step:18312 [D loss: 0.565439, acc.: 68.75%] [G loss: 1.550816]\n",
      "epoch:19 step:18313 [D loss: 0.557325, acc.: 71.88%] [G loss: 1.332718]\n",
      "epoch:19 step:18314 [D loss: 0.516596, acc.: 75.78%] [G loss: 1.305195]\n",
      "epoch:19 step:18315 [D loss: 0.592856, acc.: 70.31%] [G loss: 1.135907]\n",
      "epoch:19 step:18316 [D loss: 0.519554, acc.: 77.34%] [G loss: 1.514888]\n",
      "epoch:19 step:18317 [D loss: 0.462854, acc.: 81.25%] [G loss: 1.217713]\n",
      "epoch:19 step:18318 [D loss: 0.481407, acc.: 83.59%] [G loss: 1.102205]\n",
      "epoch:19 step:18319 [D loss: 0.691615, acc.: 59.38%] [G loss: 1.283063]\n",
      "epoch:19 step:18320 [D loss: 0.467246, acc.: 82.03%] [G loss: 1.486344]\n",
      "epoch:19 step:18321 [D loss: 0.594788, acc.: 70.31%] [G loss: 1.363780]\n",
      "epoch:19 step:18322 [D loss: 0.608799, acc.: 67.19%] [G loss: 1.278661]\n",
      "epoch:19 step:18323 [D loss: 0.519650, acc.: 70.31%] [G loss: 0.904014]\n",
      "epoch:19 step:18324 [D loss: 0.597776, acc.: 71.09%] [G loss: 1.047602]\n",
      "epoch:19 step:18325 [D loss: 0.691109, acc.: 60.94%] [G loss: 0.937518]\n",
      "epoch:19 step:18326 [D loss: 0.547159, acc.: 71.88%] [G loss: 1.374411]\n",
      "epoch:19 step:18327 [D loss: 0.555618, acc.: 74.22%] [G loss: 1.458440]\n",
      "epoch:19 step:18328 [D loss: 0.660572, acc.: 57.81%] [G loss: 1.442634]\n",
      "epoch:19 step:18329 [D loss: 0.440605, acc.: 82.81%] [G loss: 1.139601]\n",
      "epoch:19 step:18330 [D loss: 0.673494, acc.: 62.50%] [G loss: 1.165283]\n",
      "epoch:19 step:18331 [D loss: 0.566645, acc.: 74.22%] [G loss: 1.121872]\n",
      "epoch:19 step:18332 [D loss: 0.626240, acc.: 60.16%] [G loss: 1.157960]\n",
      "epoch:19 step:18333 [D loss: 0.595352, acc.: 67.19%] [G loss: 1.172559]\n",
      "epoch:19 step:18334 [D loss: 0.557796, acc.: 67.19%] [G loss: 1.455547]\n",
      "epoch:19 step:18335 [D loss: 0.604016, acc.: 67.19%] [G loss: 1.198970]\n",
      "epoch:19 step:18336 [D loss: 0.501151, acc.: 79.69%] [G loss: 1.251331]\n",
      "epoch:19 step:18337 [D loss: 0.519742, acc.: 74.22%] [G loss: 1.184623]\n",
      "epoch:19 step:18338 [D loss: 0.480769, acc.: 76.56%] [G loss: 1.385141]\n",
      "epoch:19 step:18339 [D loss: 0.632505, acc.: 61.72%] [G loss: 1.317576]\n",
      "epoch:19 step:18340 [D loss: 0.619219, acc.: 67.19%] [G loss: 1.291188]\n",
      "epoch:19 step:18341 [D loss: 0.623024, acc.: 65.62%] [G loss: 1.285015]\n",
      "epoch:19 step:18342 [D loss: 0.507049, acc.: 74.22%] [G loss: 1.157021]\n",
      "epoch:19 step:18343 [D loss: 0.576116, acc.: 74.22%] [G loss: 1.458955]\n",
      "epoch:19 step:18344 [D loss: 0.433736, acc.: 83.59%] [G loss: 1.512176]\n",
      "epoch:19 step:18345 [D loss: 0.727366, acc.: 61.72%] [G loss: 1.280524]\n",
      "epoch:19 step:18346 [D loss: 0.598334, acc.: 71.88%] [G loss: 1.383836]\n",
      "epoch:19 step:18347 [D loss: 0.748789, acc.: 47.66%] [G loss: 0.974847]\n",
      "epoch:19 step:18348 [D loss: 0.496686, acc.: 75.00%] [G loss: 1.287663]\n",
      "epoch:19 step:18349 [D loss: 0.583568, acc.: 76.56%] [G loss: 1.082836]\n",
      "epoch:19 step:18350 [D loss: 0.487999, acc.: 76.56%] [G loss: 1.148070]\n",
      "epoch:19 step:18351 [D loss: 0.629181, acc.: 60.16%] [G loss: 1.395340]\n",
      "epoch:19 step:18352 [D loss: 0.593959, acc.: 67.97%] [G loss: 1.099301]\n",
      "epoch:19 step:18353 [D loss: 0.452607, acc.: 85.16%] [G loss: 1.307485]\n",
      "epoch:19 step:18354 [D loss: 0.524214, acc.: 75.78%] [G loss: 1.075015]\n",
      "epoch:19 step:18355 [D loss: 0.484155, acc.: 83.59%] [G loss: 1.182517]\n",
      "epoch:19 step:18356 [D loss: 0.549988, acc.: 76.56%] [G loss: 1.218682]\n",
      "epoch:19 step:18357 [D loss: 0.619623, acc.: 64.84%] [G loss: 1.453181]\n",
      "epoch:19 step:18358 [D loss: 0.570440, acc.: 68.75%] [G loss: 1.456756]\n",
      "epoch:19 step:18359 [D loss: 0.510010, acc.: 75.78%] [G loss: 1.199130]\n",
      "epoch:19 step:18360 [D loss: 0.602338, acc.: 66.41%] [G loss: 1.227118]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:19 step:18361 [D loss: 0.625599, acc.: 67.97%] [G loss: 1.351927]\n",
      "epoch:19 step:18362 [D loss: 0.563741, acc.: 71.88%] [G loss: 1.479492]\n",
      "epoch:19 step:18363 [D loss: 0.562068, acc.: 69.53%] [G loss: 1.234848]\n",
      "epoch:19 step:18364 [D loss: 0.567592, acc.: 73.44%] [G loss: 1.157211]\n",
      "epoch:19 step:18365 [D loss: 0.572573, acc.: 71.88%] [G loss: 1.344254]\n",
      "epoch:19 step:18366 [D loss: 0.557120, acc.: 71.09%] [G loss: 1.100794]\n",
      "epoch:19 step:18367 [D loss: 0.536533, acc.: 66.41%] [G loss: 1.237696]\n",
      "epoch:19 step:18368 [D loss: 0.653716, acc.: 64.84%] [G loss: 1.069537]\n",
      "epoch:19 step:18369 [D loss: 0.472729, acc.: 78.12%] [G loss: 1.083346]\n",
      "epoch:19 step:18370 [D loss: 0.547943, acc.: 75.00%] [G loss: 1.219731]\n",
      "epoch:19 step:18371 [D loss: 0.742385, acc.: 55.47%] [G loss: 1.105910]\n",
      "epoch:19 step:18372 [D loss: 0.422704, acc.: 83.59%] [G loss: 1.249259]\n",
      "epoch:19 step:18373 [D loss: 0.599262, acc.: 65.62%] [G loss: 1.143021]\n",
      "epoch:19 step:18374 [D loss: 0.479085, acc.: 76.56%] [G loss: 1.423624]\n",
      "epoch:19 step:18375 [D loss: 0.413071, acc.: 85.94%] [G loss: 1.464727]\n",
      "epoch:19 step:18376 [D loss: 0.655260, acc.: 66.41%] [G loss: 1.256788]\n",
      "epoch:19 step:18377 [D loss: 0.578374, acc.: 70.31%] [G loss: 0.901347]\n",
      "epoch:19 step:18378 [D loss: 0.510485, acc.: 76.56%] [G loss: 1.226286]\n",
      "epoch:19 step:18379 [D loss: 0.429169, acc.: 83.59%] [G loss: 1.411725]\n",
      "epoch:19 step:18380 [D loss: 0.525796, acc.: 71.88%] [G loss: 1.341490]\n",
      "epoch:19 step:18381 [D loss: 0.546220, acc.: 74.22%] [G loss: 1.024798]\n",
      "epoch:19 step:18382 [D loss: 0.557077, acc.: 71.88%] [G loss: 1.168766]\n",
      "epoch:19 step:18383 [D loss: 0.578837, acc.: 67.97%] [G loss: 1.252532]\n",
      "epoch:19 step:18384 [D loss: 0.570254, acc.: 70.31%] [G loss: 1.156178]\n",
      "epoch:19 step:18385 [D loss: 0.522162, acc.: 74.22%] [G loss: 1.020951]\n",
      "epoch:19 step:18386 [D loss: 0.616647, acc.: 63.28%] [G loss: 1.461778]\n",
      "epoch:19 step:18387 [D loss: 0.571534, acc.: 68.75%] [G loss: 1.300169]\n",
      "epoch:19 step:18388 [D loss: 0.580917, acc.: 71.09%] [G loss: 1.298549]\n",
      "epoch:19 step:18389 [D loss: 0.581508, acc.: 67.19%] [G loss: 1.332764]\n",
      "epoch:19 step:18390 [D loss: 0.524592, acc.: 77.34%] [G loss: 1.280286]\n",
      "epoch:19 step:18391 [D loss: 0.436717, acc.: 78.91%] [G loss: 1.553073]\n",
      "epoch:19 step:18392 [D loss: 0.462898, acc.: 79.69%] [G loss: 1.895184]\n",
      "epoch:19 step:18393 [D loss: 0.570795, acc.: 72.66%] [G loss: 1.271429]\n",
      "epoch:19 step:18394 [D loss: 0.429368, acc.: 86.72%] [G loss: 1.547516]\n",
      "epoch:19 step:18395 [D loss: 0.504490, acc.: 71.88%] [G loss: 1.154553]\n",
      "epoch:19 step:18396 [D loss: 0.724608, acc.: 51.56%] [G loss: 1.056343]\n",
      "epoch:19 step:18397 [D loss: 0.457607, acc.: 80.47%] [G loss: 1.376069]\n",
      "epoch:19 step:18398 [D loss: 0.528741, acc.: 71.88%] [G loss: 1.346811]\n",
      "epoch:19 step:18399 [D loss: 0.408637, acc.: 84.38%] [G loss: 1.718128]\n",
      "epoch:19 step:18400 [D loss: 0.603031, acc.: 67.97%] [G loss: 0.989305]\n",
      "epoch:19 step:18401 [D loss: 0.566999, acc.: 70.31%] [G loss: 1.476844]\n",
      "epoch:19 step:18402 [D loss: 0.409829, acc.: 82.81%] [G loss: 1.310542]\n",
      "epoch:19 step:18403 [D loss: 0.434966, acc.: 79.69%] [G loss: 1.315774]\n",
      "epoch:19 step:18404 [D loss: 0.875778, acc.: 47.66%] [G loss: 1.061312]\n",
      "epoch:19 step:18405 [D loss: 0.550114, acc.: 73.44%] [G loss: 1.337432]\n",
      "epoch:19 step:18406 [D loss: 0.564903, acc.: 69.53%] [G loss: 1.105841]\n",
      "epoch:19 step:18407 [D loss: 0.528256, acc.: 73.44%] [G loss: 1.361971]\n",
      "epoch:19 step:18408 [D loss: 0.504742, acc.: 76.56%] [G loss: 1.442441]\n",
      "epoch:19 step:18409 [D loss: 0.678945, acc.: 60.94%] [G loss: 1.279332]\n",
      "epoch:19 step:18410 [D loss: 0.434823, acc.: 82.03%] [G loss: 1.449197]\n",
      "epoch:19 step:18411 [D loss: 0.555668, acc.: 71.88%] [G loss: 1.308148]\n",
      "epoch:19 step:18412 [D loss: 0.586812, acc.: 67.97%] [G loss: 1.211027]\n",
      "epoch:19 step:18413 [D loss: 0.651999, acc.: 61.72%] [G loss: 1.149985]\n",
      "epoch:19 step:18414 [D loss: 0.557749, acc.: 71.88%] [G loss: 1.458660]\n",
      "epoch:19 step:18415 [D loss: 0.691699, acc.: 60.16%] [G loss: 1.294703]\n",
      "epoch:19 step:18416 [D loss: 0.581340, acc.: 71.88%] [G loss: 1.280602]\n",
      "epoch:19 step:18417 [D loss: 0.617139, acc.: 67.97%] [G loss: 1.287369]\n",
      "epoch:19 step:18418 [D loss: 0.652016, acc.: 65.62%] [G loss: 1.135145]\n",
      "epoch:19 step:18419 [D loss: 0.432372, acc.: 82.81%] [G loss: 1.621104]\n",
      "epoch:19 step:18420 [D loss: 0.529543, acc.: 76.56%] [G loss: 1.165657]\n",
      "epoch:19 step:18421 [D loss: 0.427365, acc.: 82.81%] [G loss: 1.112699]\n",
      "epoch:19 step:18422 [D loss: 0.688969, acc.: 62.50%] [G loss: 1.212871]\n",
      "epoch:19 step:18423 [D loss: 0.612371, acc.: 62.50%] [G loss: 1.189177]\n",
      "epoch:19 step:18424 [D loss: 0.604282, acc.: 64.84%] [G loss: 1.786908]\n",
      "epoch:19 step:18425 [D loss: 0.521562, acc.: 74.22%] [G loss: 1.194902]\n",
      "epoch:19 step:18426 [D loss: 0.509634, acc.: 77.34%] [G loss: 1.179442]\n",
      "epoch:19 step:18427 [D loss: 0.733231, acc.: 55.47%] [G loss: 1.136271]\n",
      "epoch:19 step:18428 [D loss: 0.407819, acc.: 86.72%] [G loss: 1.308293]\n",
      "epoch:19 step:18429 [D loss: 0.550631, acc.: 74.22%] [G loss: 1.427883]\n",
      "epoch:19 step:18430 [D loss: 0.595387, acc.: 71.88%] [G loss: 1.223735]\n",
      "epoch:19 step:18431 [D loss: 0.642105, acc.: 61.72%] [G loss: 1.072112]\n",
      "epoch:19 step:18432 [D loss: 0.564574, acc.: 71.09%] [G loss: 1.326248]\n",
      "epoch:19 step:18433 [D loss: 0.604244, acc.: 70.31%] [G loss: 1.174777]\n",
      "epoch:19 step:18434 [D loss: 0.445136, acc.: 80.47%] [G loss: 1.182365]\n",
      "epoch:19 step:18435 [D loss: 0.543211, acc.: 71.88%] [G loss: 1.245040]\n",
      "epoch:19 step:18436 [D loss: 0.588270, acc.: 69.53%] [G loss: 1.325596]\n",
      "epoch:19 step:18437 [D loss: 0.456838, acc.: 85.16%] [G loss: 1.565247]\n",
      "epoch:19 step:18438 [D loss: 0.567752, acc.: 68.75%] [G loss: 1.471155]\n",
      "epoch:19 step:18439 [D loss: 0.454371, acc.: 80.47%] [G loss: 1.767710]\n",
      "epoch:19 step:18440 [D loss: 0.569309, acc.: 69.53%] [G loss: 1.441627]\n",
      "epoch:19 step:18441 [D loss: 0.524591, acc.: 73.44%] [G loss: 1.141218]\n",
      "epoch:19 step:18442 [D loss: 0.621617, acc.: 67.19%] [G loss: 0.831800]\n",
      "epoch:19 step:18443 [D loss: 0.431281, acc.: 85.94%] [G loss: 1.089707]\n",
      "epoch:19 step:18444 [D loss: 0.501008, acc.: 78.91%] [G loss: 1.467259]\n",
      "epoch:19 step:18445 [D loss: 0.428468, acc.: 84.38%] [G loss: 1.297828]\n",
      "epoch:19 step:18446 [D loss: 0.708671, acc.: 54.69%] [G loss: 1.042018]\n",
      "epoch:19 step:18447 [D loss: 0.601310, acc.: 67.19%] [G loss: 1.360943]\n",
      "epoch:19 step:18448 [D loss: 0.580437, acc.: 70.31%] [G loss: 1.231025]\n",
      "epoch:19 step:18449 [D loss: 0.605298, acc.: 64.84%] [G loss: 1.036418]\n",
      "epoch:19 step:18450 [D loss: 0.551076, acc.: 72.66%] [G loss: 1.406528]\n",
      "epoch:19 step:18451 [D loss: 0.498395, acc.: 71.88%] [G loss: 1.304163]\n",
      "epoch:19 step:18452 [D loss: 0.523558, acc.: 78.12%] [G loss: 1.414252]\n",
      "epoch:19 step:18453 [D loss: 0.775544, acc.: 54.69%] [G loss: 1.264981]\n",
      "epoch:19 step:18454 [D loss: 0.489573, acc.: 78.91%] [G loss: 1.394900]\n",
      "epoch:19 step:18455 [D loss: 0.464379, acc.: 79.69%] [G loss: 1.161746]\n",
      "epoch:19 step:18456 [D loss: 0.562408, acc.: 71.09%] [G loss: 1.103064]\n",
      "epoch:19 step:18457 [D loss: 0.611185, acc.: 67.97%] [G loss: 1.360940]\n",
      "epoch:19 step:18458 [D loss: 0.635844, acc.: 69.53%] [G loss: 1.256106]\n",
      "epoch:19 step:18459 [D loss: 0.510083, acc.: 76.56%] [G loss: 1.007902]\n",
      "epoch:19 step:18460 [D loss: 0.770877, acc.: 50.00%] [G loss: 1.258131]\n",
      "epoch:19 step:18461 [D loss: 0.564884, acc.: 74.22%] [G loss: 1.216953]\n",
      "epoch:19 step:18462 [D loss: 0.542912, acc.: 75.00%] [G loss: 1.262616]\n",
      "epoch:19 step:18463 [D loss: 0.644918, acc.: 62.50%] [G loss: 1.386869]\n",
      "epoch:19 step:18464 [D loss: 0.701665, acc.: 64.06%] [G loss: 1.357329]\n",
      "epoch:19 step:18465 [D loss: 0.559924, acc.: 73.44%] [G loss: 1.237236]\n",
      "epoch:19 step:18466 [D loss: 0.460379, acc.: 82.03%] [G loss: 1.293426]\n",
      "epoch:19 step:18467 [D loss: 0.587498, acc.: 66.41%] [G loss: 1.355056]\n",
      "epoch:19 step:18468 [D loss: 0.575002, acc.: 69.53%] [G loss: 1.357430]\n",
      "epoch:19 step:18469 [D loss: 0.410736, acc.: 82.81%] [G loss: 1.340543]\n",
      "epoch:19 step:18470 [D loss: 0.493164, acc.: 75.78%] [G loss: 1.341554]\n",
      "epoch:19 step:18471 [D loss: 0.600437, acc.: 70.31%] [G loss: 1.585623]\n",
      "epoch:19 step:18472 [D loss: 0.439192, acc.: 78.12%] [G loss: 1.538470]\n",
      "epoch:19 step:18473 [D loss: 0.522373, acc.: 78.12%] [G loss: 1.150812]\n",
      "epoch:19 step:18474 [D loss: 0.432934, acc.: 82.81%] [G loss: 1.310286]\n",
      "epoch:19 step:18475 [D loss: 0.473818, acc.: 77.34%] [G loss: 1.210284]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:19 step:18476 [D loss: 0.646956, acc.: 62.50%] [G loss: 1.289930]\n",
      "epoch:19 step:18477 [D loss: 0.546682, acc.: 71.88%] [G loss: 1.691298]\n",
      "epoch:19 step:18478 [D loss: 0.507976, acc.: 75.78%] [G loss: 1.093698]\n",
      "epoch:19 step:18479 [D loss: 0.613955, acc.: 68.75%] [G loss: 1.160016]\n",
      "epoch:19 step:18480 [D loss: 0.445387, acc.: 81.25%] [G loss: 1.227259]\n",
      "epoch:19 step:18481 [D loss: 0.576544, acc.: 63.28%] [G loss: 1.226670]\n",
      "epoch:19 step:18482 [D loss: 0.660602, acc.: 62.50%] [G loss: 1.148732]\n",
      "epoch:19 step:18483 [D loss: 0.594119, acc.: 66.41%] [G loss: 1.438542]\n",
      "epoch:19 step:18484 [D loss: 0.609431, acc.: 67.19%] [G loss: 1.357394]\n",
      "epoch:19 step:18485 [D loss: 0.552510, acc.: 76.56%] [G loss: 1.312708]\n",
      "epoch:19 step:18486 [D loss: 0.495406, acc.: 78.91%] [G loss: 1.247568]\n",
      "epoch:19 step:18487 [D loss: 0.810306, acc.: 56.25%] [G loss: 1.140993]\n",
      "epoch:19 step:18488 [D loss: 0.524215, acc.: 75.00%] [G loss: 1.439602]\n",
      "epoch:19 step:18489 [D loss: 0.445462, acc.: 82.03%] [G loss: 1.442401]\n",
      "epoch:19 step:18490 [D loss: 0.494526, acc.: 83.59%] [G loss: 1.329179]\n",
      "epoch:19 step:18491 [D loss: 0.438525, acc.: 82.03%] [G loss: 1.464415]\n",
      "epoch:19 step:18492 [D loss: 0.608925, acc.: 64.06%] [G loss: 1.181116]\n",
      "epoch:19 step:18493 [D loss: 0.604118, acc.: 70.31%] [G loss: 1.404689]\n",
      "epoch:19 step:18494 [D loss: 0.615957, acc.: 67.19%] [G loss: 1.538812]\n",
      "epoch:19 step:18495 [D loss: 0.485210, acc.: 78.91%] [G loss: 1.192097]\n",
      "epoch:19 step:18496 [D loss: 0.603786, acc.: 65.62%] [G loss: 1.087632]\n",
      "epoch:19 step:18497 [D loss: 0.589507, acc.: 67.97%] [G loss: 1.217965]\n",
      "epoch:19 step:18498 [D loss: 0.552263, acc.: 71.88%] [G loss: 1.548672]\n",
      "epoch:19 step:18499 [D loss: 0.617711, acc.: 67.97%] [G loss: 1.272554]\n",
      "epoch:19 step:18500 [D loss: 0.597884, acc.: 68.75%] [G loss: 1.007680]\n",
      "epoch:19 step:18501 [D loss: 0.613890, acc.: 63.28%] [G loss: 1.464041]\n",
      "epoch:19 step:18502 [D loss: 0.538224, acc.: 71.88%] [G loss: 1.506769]\n",
      "epoch:19 step:18503 [D loss: 0.790141, acc.: 50.78%] [G loss: 1.055148]\n",
      "epoch:19 step:18504 [D loss: 0.487498, acc.: 76.56%] [G loss: 1.404209]\n",
      "epoch:19 step:18505 [D loss: 0.484693, acc.: 78.91%] [G loss: 1.566189]\n",
      "epoch:19 step:18506 [D loss: 0.610952, acc.: 65.62%] [G loss: 1.554511]\n",
      "epoch:19 step:18507 [D loss: 0.617714, acc.: 64.84%] [G loss: 1.296184]\n",
      "epoch:19 step:18508 [D loss: 0.629198, acc.: 66.41%] [G loss: 1.253429]\n",
      "epoch:19 step:18509 [D loss: 0.604990, acc.: 67.97%] [G loss: 1.298423]\n",
      "epoch:19 step:18510 [D loss: 0.447359, acc.: 82.81%] [G loss: 1.755627]\n",
      "epoch:19 step:18511 [D loss: 0.633438, acc.: 64.06%] [G loss: 1.227002]\n",
      "epoch:19 step:18512 [D loss: 0.617660, acc.: 62.50%] [G loss: 1.462852]\n",
      "epoch:19 step:18513 [D loss: 0.719327, acc.: 60.94%] [G loss: 1.385480]\n",
      "epoch:19 step:18514 [D loss: 0.470781, acc.: 80.47%] [G loss: 1.824703]\n",
      "epoch:19 step:18515 [D loss: 0.599354, acc.: 70.31%] [G loss: 1.377257]\n",
      "epoch:19 step:18516 [D loss: 0.531057, acc.: 73.44%] [G loss: 1.371498]\n",
      "epoch:19 step:18517 [D loss: 0.521664, acc.: 76.56%] [G loss: 1.027418]\n",
      "epoch:19 step:18518 [D loss: 0.587773, acc.: 64.84%] [G loss: 1.321306]\n",
      "epoch:19 step:18519 [D loss: 0.544529, acc.: 75.00%] [G loss: 1.328934]\n",
      "epoch:19 step:18520 [D loss: 0.565121, acc.: 75.78%] [G loss: 1.356807]\n",
      "epoch:19 step:18521 [D loss: 0.519851, acc.: 71.09%] [G loss: 1.538961]\n",
      "epoch:19 step:18522 [D loss: 0.621066, acc.: 67.19%] [G loss: 1.623331]\n",
      "epoch:19 step:18523 [D loss: 0.531509, acc.: 75.00%] [G loss: 1.574708]\n",
      "epoch:19 step:18524 [D loss: 0.505973, acc.: 78.91%] [G loss: 1.417760]\n",
      "epoch:19 step:18525 [D loss: 0.574439, acc.: 71.88%] [G loss: 1.261325]\n",
      "epoch:19 step:18526 [D loss: 0.797724, acc.: 55.47%] [G loss: 1.062981]\n",
      "epoch:19 step:18527 [D loss: 0.643280, acc.: 60.94%] [G loss: 1.237058]\n",
      "epoch:19 step:18528 [D loss: 0.527050, acc.: 74.22%] [G loss: 1.576621]\n",
      "epoch:19 step:18529 [D loss: 0.589669, acc.: 70.31%] [G loss: 1.442144]\n",
      "epoch:19 step:18530 [D loss: 0.476531, acc.: 79.69%] [G loss: 1.474932]\n",
      "epoch:19 step:18531 [D loss: 0.591276, acc.: 63.28%] [G loss: 0.855006]\n",
      "epoch:19 step:18532 [D loss: 0.507045, acc.: 75.00%] [G loss: 1.418178]\n",
      "epoch:19 step:18533 [D loss: 0.565348, acc.: 69.53%] [G loss: 1.151431]\n",
      "epoch:19 step:18534 [D loss: 0.645777, acc.: 65.62%] [G loss: 1.026332]\n",
      "epoch:19 step:18535 [D loss: 0.564713, acc.: 70.31%] [G loss: 1.464946]\n",
      "epoch:19 step:18536 [D loss: 0.553007, acc.: 71.88%] [G loss: 1.323812]\n",
      "epoch:19 step:18537 [D loss: 0.478929, acc.: 81.25%] [G loss: 0.916386]\n",
      "epoch:19 step:18538 [D loss: 0.501626, acc.: 77.34%] [G loss: 1.452825]\n",
      "epoch:19 step:18539 [D loss: 0.493703, acc.: 77.34%] [G loss: 1.572268]\n",
      "epoch:19 step:18540 [D loss: 0.378574, acc.: 86.72%] [G loss: 1.478628]\n",
      "epoch:19 step:18541 [D loss: 0.729858, acc.: 59.38%] [G loss: 1.357086]\n",
      "epoch:19 step:18542 [D loss: 0.550692, acc.: 73.44%] [G loss: 1.054365]\n",
      "epoch:19 step:18543 [D loss: 0.573670, acc.: 72.66%] [G loss: 1.275794]\n",
      "epoch:19 step:18544 [D loss: 0.728541, acc.: 58.59%] [G loss: 1.185415]\n",
      "epoch:19 step:18545 [D loss: 0.646044, acc.: 65.62%] [G loss: 1.245051]\n",
      "epoch:19 step:18546 [D loss: 0.528524, acc.: 73.44%] [G loss: 1.633869]\n",
      "epoch:19 step:18547 [D loss: 0.518905, acc.: 75.78%] [G loss: 1.278463]\n",
      "epoch:19 step:18548 [D loss: 0.564626, acc.: 69.53%] [G loss: 1.339611]\n",
      "epoch:19 step:18549 [D loss: 0.514236, acc.: 75.00%] [G loss: 1.487419]\n",
      "epoch:19 step:18550 [D loss: 0.565102, acc.: 69.53%] [G loss: 1.367344]\n",
      "epoch:19 step:18551 [D loss: 0.578356, acc.: 69.53%] [G loss: 1.720915]\n",
      "epoch:19 step:18552 [D loss: 0.656234, acc.: 58.59%] [G loss: 1.342362]\n",
      "epoch:19 step:18553 [D loss: 0.626805, acc.: 61.72%] [G loss: 1.053923]\n",
      "epoch:19 step:18554 [D loss: 0.496982, acc.: 79.69%] [G loss: 1.408099]\n",
      "epoch:19 step:18555 [D loss: 0.638826, acc.: 67.19%] [G loss: 1.537112]\n",
      "epoch:19 step:18556 [D loss: 0.340937, acc.: 90.62%] [G loss: 1.402039]\n",
      "epoch:19 step:18557 [D loss: 0.501147, acc.: 73.44%] [G loss: 1.347848]\n",
      "epoch:19 step:18558 [D loss: 0.602930, acc.: 66.41%] [G loss: 1.147962]\n",
      "epoch:19 step:18559 [D loss: 0.675548, acc.: 63.28%] [G loss: 1.252276]\n",
      "epoch:19 step:18560 [D loss: 0.507510, acc.: 75.78%] [G loss: 1.377531]\n",
      "epoch:19 step:18561 [D loss: 0.533782, acc.: 72.66%] [G loss: 1.081803]\n",
      "epoch:19 step:18562 [D loss: 0.485045, acc.: 80.47%] [G loss: 1.420244]\n",
      "epoch:19 step:18563 [D loss: 0.366111, acc.: 85.16%] [G loss: 1.628439]\n",
      "epoch:19 step:18564 [D loss: 0.625738, acc.: 73.44%] [G loss: 1.230380]\n",
      "epoch:19 step:18565 [D loss: 0.570031, acc.: 72.66%] [G loss: 1.430930]\n",
      "epoch:19 step:18566 [D loss: 0.499567, acc.: 71.88%] [G loss: 1.433102]\n",
      "epoch:19 step:18567 [D loss: 0.476279, acc.: 82.03%] [G loss: 1.148012]\n",
      "epoch:19 step:18568 [D loss: 0.463941, acc.: 78.12%] [G loss: 1.716370]\n",
      "epoch:19 step:18569 [D loss: 0.474341, acc.: 76.56%] [G loss: 1.258212]\n",
      "epoch:19 step:18570 [D loss: 0.422152, acc.: 84.38%] [G loss: 1.411042]\n",
      "epoch:19 step:18571 [D loss: 0.573621, acc.: 64.84%] [G loss: 1.123674]\n",
      "epoch:19 step:18572 [D loss: 0.627896, acc.: 64.84%] [G loss: 1.354100]\n",
      "epoch:19 step:18573 [D loss: 0.540267, acc.: 71.88%] [G loss: 1.159913]\n",
      "epoch:19 step:18574 [D loss: 0.560480, acc.: 70.31%] [G loss: 1.292172]\n",
      "epoch:19 step:18575 [D loss: 0.528484, acc.: 72.66%] [G loss: 1.656104]\n",
      "epoch:19 step:18576 [D loss: 0.745500, acc.: 54.69%] [G loss: 1.294129]\n",
      "epoch:19 step:18577 [D loss: 0.568665, acc.: 71.09%] [G loss: 1.282853]\n",
      "epoch:19 step:18578 [D loss: 0.710180, acc.: 61.72%] [G loss: 1.058874]\n",
      "epoch:19 step:18579 [D loss: 0.552065, acc.: 71.88%] [G loss: 1.253293]\n",
      "epoch:19 step:18580 [D loss: 0.442540, acc.: 84.38%] [G loss: 1.507983]\n",
      "epoch:19 step:18581 [D loss: 0.425752, acc.: 83.59%] [G loss: 1.686017]\n",
      "epoch:19 step:18582 [D loss: 0.572146, acc.: 69.53%] [G loss: 1.465697]\n",
      "epoch:19 step:18583 [D loss: 0.624104, acc.: 62.50%] [G loss: 1.268242]\n",
      "epoch:19 step:18584 [D loss: 0.607834, acc.: 73.44%] [G loss: 1.255092]\n",
      "epoch:19 step:18585 [D loss: 0.536229, acc.: 74.22%] [G loss: 1.109689]\n",
      "epoch:19 step:18586 [D loss: 0.464084, acc.: 78.12%] [G loss: 1.223258]\n",
      "epoch:19 step:18587 [D loss: 0.529674, acc.: 69.53%] [G loss: 1.529830]\n",
      "epoch:19 step:18588 [D loss: 0.428035, acc.: 86.72%] [G loss: 1.419049]\n",
      "epoch:19 step:18589 [D loss: 0.767378, acc.: 53.91%] [G loss: 1.143695]\n",
      "epoch:19 step:18590 [D loss: 0.626478, acc.: 60.94%] [G loss: 1.445182]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:19 step:18591 [D loss: 0.488699, acc.: 79.69%] [G loss: 1.275218]\n",
      "epoch:19 step:18592 [D loss: 0.451116, acc.: 83.59%] [G loss: 1.266714]\n",
      "epoch:19 step:18593 [D loss: 0.547007, acc.: 68.75%] [G loss: 1.201697]\n",
      "epoch:19 step:18594 [D loss: 0.497675, acc.: 72.66%] [G loss: 1.158125]\n",
      "epoch:19 step:18595 [D loss: 0.610000, acc.: 67.97%] [G loss: 1.192161]\n",
      "epoch:19 step:18596 [D loss: 0.509566, acc.: 74.22%] [G loss: 1.583563]\n",
      "epoch:19 step:18597 [D loss: 0.610610, acc.: 62.50%] [G loss: 1.526146]\n",
      "epoch:19 step:18598 [D loss: 0.611607, acc.: 69.53%] [G loss: 1.119661]\n",
      "epoch:19 step:18599 [D loss: 0.440053, acc.: 82.03%] [G loss: 1.129978]\n",
      "epoch:19 step:18600 [D loss: 0.559076, acc.: 70.31%] [G loss: 1.421635]\n",
      "epoch:19 step:18601 [D loss: 0.707947, acc.: 60.94%] [G loss: 1.066822]\n",
      "epoch:19 step:18602 [D loss: 0.534909, acc.: 75.78%] [G loss: 1.374709]\n",
      "epoch:19 step:18603 [D loss: 0.437992, acc.: 84.38%] [G loss: 1.337842]\n",
      "epoch:19 step:18604 [D loss: 0.590492, acc.: 64.06%] [G loss: 1.216287]\n",
      "epoch:19 step:18605 [D loss: 0.801280, acc.: 47.66%] [G loss: 1.265886]\n",
      "epoch:19 step:18606 [D loss: 0.613771, acc.: 66.41%] [G loss: 1.395077]\n",
      "epoch:19 step:18607 [D loss: 0.589562, acc.: 68.75%] [G loss: 1.440267]\n",
      "epoch:19 step:18608 [D loss: 0.640123, acc.: 66.41%] [G loss: 1.551560]\n",
      "epoch:19 step:18609 [D loss: 0.596489, acc.: 70.31%] [G loss: 1.464143]\n",
      "epoch:19 step:18610 [D loss: 0.537273, acc.: 74.22%] [G loss: 1.374139]\n",
      "epoch:19 step:18611 [D loss: 0.577923, acc.: 67.19%] [G loss: 1.602754]\n",
      "epoch:19 step:18612 [D loss: 0.420453, acc.: 81.25%] [G loss: 1.490482]\n",
      "epoch:19 step:18613 [D loss: 0.493190, acc.: 77.34%] [G loss: 1.538138]\n",
      "epoch:19 step:18614 [D loss: 0.721175, acc.: 59.38%] [G loss: 1.431914]\n",
      "epoch:19 step:18615 [D loss: 0.658134, acc.: 64.84%] [G loss: 1.506364]\n",
      "epoch:19 step:18616 [D loss: 0.503367, acc.: 76.56%] [G loss: 1.476192]\n",
      "epoch:19 step:18617 [D loss: 0.497887, acc.: 76.56%] [G loss: 1.122185]\n",
      "epoch:19 step:18618 [D loss: 0.496135, acc.: 76.56%] [G loss: 1.408779]\n",
      "epoch:19 step:18619 [D loss: 0.528299, acc.: 76.56%] [G loss: 1.349319]\n",
      "epoch:19 step:18620 [D loss: 0.760618, acc.: 49.22%] [G loss: 0.936063]\n",
      "epoch:19 step:18621 [D loss: 0.517257, acc.: 75.00%] [G loss: 1.432158]\n",
      "epoch:19 step:18622 [D loss: 0.482283, acc.: 79.69%] [G loss: 1.225454]\n",
      "epoch:19 step:18623 [D loss: 0.586743, acc.: 71.09%] [G loss: 1.483769]\n",
      "epoch:19 step:18624 [D loss: 0.493171, acc.: 76.56%] [G loss: 1.606061]\n",
      "epoch:19 step:18625 [D loss: 0.499330, acc.: 77.34%] [G loss: 1.233560]\n",
      "epoch:19 step:18626 [D loss: 0.602960, acc.: 69.53%] [G loss: 0.878892]\n",
      "epoch:19 step:18627 [D loss: 0.443137, acc.: 81.25%] [G loss: 1.314474]\n",
      "epoch:19 step:18628 [D loss: 0.559959, acc.: 71.88%] [G loss: 1.285669]\n",
      "epoch:19 step:18629 [D loss: 0.604449, acc.: 66.41%] [G loss: 1.215757]\n",
      "epoch:19 step:18630 [D loss: 0.550558, acc.: 75.78%] [G loss: 1.495637]\n",
      "epoch:19 step:18631 [D loss: 0.863630, acc.: 41.41%] [G loss: 0.979682]\n",
      "epoch:19 step:18632 [D loss: 0.724887, acc.: 54.69%] [G loss: 1.435890]\n",
      "epoch:19 step:18633 [D loss: 0.552743, acc.: 70.31%] [G loss: 1.232433]\n",
      "epoch:19 step:18634 [D loss: 0.832960, acc.: 46.09%] [G loss: 1.074635]\n",
      "epoch:19 step:18635 [D loss: 0.691203, acc.: 61.72%] [G loss: 1.169275]\n",
      "epoch:19 step:18636 [D loss: 0.698703, acc.: 56.25%] [G loss: 1.382643]\n",
      "epoch:19 step:18637 [D loss: 0.665342, acc.: 60.16%] [G loss: 1.095787]\n",
      "epoch:19 step:18638 [D loss: 0.696945, acc.: 59.38%] [G loss: 1.593281]\n",
      "epoch:19 step:18639 [D loss: 0.578967, acc.: 70.31%] [G loss: 1.473184]\n",
      "epoch:19 step:18640 [D loss: 0.607088, acc.: 67.97%] [G loss: 1.155344]\n",
      "epoch:19 step:18641 [D loss: 0.542800, acc.: 71.88%] [G loss: 1.069784]\n",
      "epoch:19 step:18642 [D loss: 0.661038, acc.: 62.50%] [G loss: 1.230529]\n",
      "epoch:19 step:18643 [D loss: 0.503732, acc.: 78.91%] [G loss: 1.483453]\n",
      "epoch:19 step:18644 [D loss: 0.663469, acc.: 64.84%] [G loss: 1.478158]\n",
      "epoch:19 step:18645 [D loss: 0.498505, acc.: 76.56%] [G loss: 1.477072]\n",
      "epoch:19 step:18646 [D loss: 0.522581, acc.: 75.00%] [G loss: 1.464518]\n",
      "epoch:19 step:18647 [D loss: 0.747713, acc.: 52.34%] [G loss: 1.101228]\n",
      "epoch:19 step:18648 [D loss: 0.592333, acc.: 68.75%] [G loss: 1.031885]\n",
      "epoch:19 step:18649 [D loss: 0.536279, acc.: 71.88%] [G loss: 1.234862]\n",
      "epoch:19 step:18650 [D loss: 0.656273, acc.: 60.94%] [G loss: 1.093415]\n",
      "epoch:19 step:18651 [D loss: 0.581157, acc.: 69.53%] [G loss: 1.196912]\n",
      "epoch:19 step:18652 [D loss: 0.606690, acc.: 68.75%] [G loss: 1.443557]\n",
      "epoch:19 step:18653 [D loss: 0.532333, acc.: 71.09%] [G loss: 1.373383]\n",
      "epoch:19 step:18654 [D loss: 0.618092, acc.: 68.75%] [G loss: 1.378749]\n",
      "epoch:19 step:18655 [D loss: 0.450931, acc.: 82.81%] [G loss: 1.506911]\n",
      "epoch:19 step:18656 [D loss: 0.601572, acc.: 65.62%] [G loss: 1.022050]\n",
      "epoch:19 step:18657 [D loss: 0.608820, acc.: 67.19%] [G loss: 1.300301]\n",
      "epoch:19 step:18658 [D loss: 0.619166, acc.: 63.28%] [G loss: 1.302546]\n",
      "epoch:19 step:18659 [D loss: 0.567432, acc.: 68.75%] [G loss: 1.385756]\n",
      "epoch:19 step:18660 [D loss: 0.605462, acc.: 65.62%] [G loss: 1.053640]\n",
      "epoch:19 step:18661 [D loss: 0.638181, acc.: 60.16%] [G loss: 1.261555]\n",
      "epoch:19 step:18662 [D loss: 0.508512, acc.: 71.88%] [G loss: 1.364486]\n",
      "epoch:19 step:18663 [D loss: 0.477520, acc.: 77.34%] [G loss: 1.227527]\n",
      "epoch:19 step:18664 [D loss: 0.651110, acc.: 60.16%] [G loss: 1.055682]\n",
      "epoch:19 step:18665 [D loss: 0.618151, acc.: 65.62%] [G loss: 1.307382]\n",
      "epoch:19 step:18666 [D loss: 0.579038, acc.: 67.19%] [G loss: 1.418688]\n",
      "epoch:19 step:18667 [D loss: 0.461279, acc.: 84.38%] [G loss: 1.323826]\n",
      "epoch:19 step:18668 [D loss: 0.638115, acc.: 71.88%] [G loss: 1.119986]\n",
      "epoch:19 step:18669 [D loss: 0.589012, acc.: 69.53%] [G loss: 1.494859]\n",
      "epoch:19 step:18670 [D loss: 0.651814, acc.: 60.16%] [G loss: 1.444856]\n",
      "epoch:19 step:18671 [D loss: 0.550276, acc.: 71.09%] [G loss: 1.176734]\n",
      "epoch:19 step:18672 [D loss: 0.525213, acc.: 72.66%] [G loss: 1.356970]\n",
      "epoch:19 step:18673 [D loss: 0.625952, acc.: 67.97%] [G loss: 1.222265]\n",
      "epoch:19 step:18674 [D loss: 0.653214, acc.: 60.94%] [G loss: 1.346388]\n",
      "epoch:19 step:18675 [D loss: 0.458066, acc.: 75.00%] [G loss: 1.409565]\n",
      "epoch:19 step:18676 [D loss: 0.522068, acc.: 71.88%] [G loss: 1.203242]\n",
      "epoch:19 step:18677 [D loss: 0.496251, acc.: 72.66%] [G loss: 1.624598]\n",
      "epoch:19 step:18678 [D loss: 0.615506, acc.: 60.94%] [G loss: 1.153101]\n",
      "epoch:19 step:18679 [D loss: 0.620532, acc.: 66.41%] [G loss: 1.228122]\n",
      "epoch:19 step:18680 [D loss: 0.631919, acc.: 61.72%] [G loss: 1.558308]\n",
      "epoch:19 step:18681 [D loss: 0.551957, acc.: 76.56%] [G loss: 1.321064]\n",
      "epoch:19 step:18682 [D loss: 0.599513, acc.: 66.41%] [G loss: 1.476520]\n",
      "epoch:19 step:18683 [D loss: 0.460776, acc.: 80.47%] [G loss: 1.339359]\n",
      "epoch:19 step:18684 [D loss: 0.666426, acc.: 57.81%] [G loss: 1.238286]\n",
      "epoch:19 step:18685 [D loss: 0.491416, acc.: 79.69%] [G loss: 1.514103]\n",
      "epoch:19 step:18686 [D loss: 0.828524, acc.: 47.66%] [G loss: 1.182221]\n",
      "epoch:19 step:18687 [D loss: 0.378294, acc.: 91.41%] [G loss: 1.478390]\n",
      "epoch:19 step:18688 [D loss: 0.526254, acc.: 73.44%] [G loss: 1.692708]\n",
      "epoch:19 step:18689 [D loss: 0.613696, acc.: 65.62%] [G loss: 1.166416]\n",
      "epoch:19 step:18690 [D loss: 0.690792, acc.: 61.72%] [G loss: 1.163880]\n",
      "epoch:19 step:18691 [D loss: 0.639913, acc.: 67.19%] [G loss: 1.063835]\n",
      "epoch:19 step:18692 [D loss: 0.560034, acc.: 75.00%] [G loss: 1.293327]\n",
      "epoch:19 step:18693 [D loss: 0.567173, acc.: 69.53%] [G loss: 1.095891]\n",
      "epoch:19 step:18694 [D loss: 0.650224, acc.: 64.84%] [G loss: 1.377429]\n",
      "epoch:19 step:18695 [D loss: 0.594475, acc.: 70.31%] [G loss: 1.243901]\n",
      "epoch:19 step:18696 [D loss: 0.479651, acc.: 76.56%] [G loss: 1.084759]\n",
      "epoch:19 step:18697 [D loss: 0.513402, acc.: 78.12%] [G loss: 1.510787]\n",
      "epoch:19 step:18698 [D loss: 0.527216, acc.: 73.44%] [G loss: 1.449447]\n",
      "epoch:19 step:18699 [D loss: 0.411303, acc.: 85.94%] [G loss: 1.127808]\n",
      "epoch:19 step:18700 [D loss: 0.556107, acc.: 75.78%] [G loss: 1.310963]\n",
      "epoch:19 step:18701 [D loss: 0.442042, acc.: 84.38%] [G loss: 1.402615]\n",
      "epoch:19 step:18702 [D loss: 0.594462, acc.: 66.41%] [G loss: 1.170459]\n",
      "epoch:19 step:18703 [D loss: 0.634649, acc.: 61.72%] [G loss: 0.938174]\n",
      "epoch:19 step:18704 [D loss: 0.513567, acc.: 76.56%] [G loss: 1.145173]\n",
      "epoch:19 step:18705 [D loss: 0.593352, acc.: 67.97%] [G loss: 1.107685]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:19 step:18706 [D loss: 0.523309, acc.: 76.56%] [G loss: 1.417911]\n",
      "epoch:19 step:18707 [D loss: 0.436682, acc.: 81.25%] [G loss: 1.385693]\n",
      "epoch:19 step:18708 [D loss: 0.640466, acc.: 66.41%] [G loss: 1.363652]\n",
      "epoch:19 step:18709 [D loss: 0.472277, acc.: 76.56%] [G loss: 1.370869]\n",
      "epoch:19 step:18710 [D loss: 0.601905, acc.: 67.97%] [G loss: 1.059419]\n",
      "epoch:19 step:18711 [D loss: 0.611515, acc.: 64.06%] [G loss: 1.541599]\n",
      "epoch:19 step:18712 [D loss: 0.536820, acc.: 72.66%] [G loss: 1.839371]\n",
      "epoch:19 step:18713 [D loss: 0.581945, acc.: 69.53%] [G loss: 1.353473]\n",
      "epoch:19 step:18714 [D loss: 0.641284, acc.: 66.41%] [G loss: 1.261654]\n",
      "epoch:19 step:18715 [D loss: 0.581864, acc.: 68.75%] [G loss: 1.258380]\n",
      "epoch:19 step:18716 [D loss: 0.538762, acc.: 70.31%] [G loss: 1.388224]\n",
      "epoch:19 step:18717 [D loss: 0.475684, acc.: 77.34%] [G loss: 1.362222]\n",
      "epoch:19 step:18718 [D loss: 0.516828, acc.: 68.75%] [G loss: 1.583623]\n",
      "epoch:19 step:18719 [D loss: 0.582611, acc.: 69.53%] [G loss: 1.329598]\n",
      "epoch:19 step:18720 [D loss: 0.545541, acc.: 73.44%] [G loss: 1.261826]\n",
      "epoch:19 step:18721 [D loss: 0.425089, acc.: 86.72%] [G loss: 1.378439]\n",
      "epoch:19 step:18722 [D loss: 0.497963, acc.: 74.22%] [G loss: 1.264820]\n",
      "epoch:19 step:18723 [D loss: 0.607417, acc.: 71.88%] [G loss: 1.158302]\n",
      "epoch:19 step:18724 [D loss: 0.719333, acc.: 59.38%] [G loss: 1.349596]\n",
      "epoch:19 step:18725 [D loss: 0.586182, acc.: 70.31%] [G loss: 1.780279]\n",
      "epoch:19 step:18726 [D loss: 0.756019, acc.: 53.12%] [G loss: 1.346374]\n",
      "epoch:19 step:18727 [D loss: 0.563129, acc.: 71.88%] [G loss: 1.253640]\n",
      "epoch:19 step:18728 [D loss: 0.585447, acc.: 64.84%] [G loss: 1.155356]\n",
      "epoch:19 step:18729 [D loss: 0.516904, acc.: 76.56%] [G loss: 1.389565]\n",
      "epoch:19 step:18730 [D loss: 0.924370, acc.: 36.72%] [G loss: 0.955864]\n",
      "epoch:19 step:18731 [D loss: 0.444409, acc.: 82.03%] [G loss: 1.243489]\n",
      "epoch:19 step:18732 [D loss: 0.700147, acc.: 56.25%] [G loss: 1.294998]\n",
      "epoch:19 step:18733 [D loss: 0.615272, acc.: 59.38%] [G loss: 1.077297]\n",
      "epoch:19 step:18734 [D loss: 0.610587, acc.: 66.41%] [G loss: 1.316012]\n",
      "epoch:19 step:18735 [D loss: 0.401444, acc.: 79.69%] [G loss: 1.389025]\n",
      "epoch:19 step:18736 [D loss: 0.671110, acc.: 61.72%] [G loss: 1.209304]\n",
      "epoch:19 step:18737 [D loss: 0.533931, acc.: 72.66%] [G loss: 1.273891]\n",
      "epoch:19 step:18738 [D loss: 0.534711, acc.: 75.78%] [G loss: 1.275981]\n",
      "epoch:19 step:18739 [D loss: 0.626932, acc.: 64.84%] [G loss: 1.173669]\n",
      "epoch:19 step:18740 [D loss: 0.676829, acc.: 56.25%] [G loss: 1.110181]\n",
      "epoch:20 step:18741 [D loss: 0.517206, acc.: 74.22%] [G loss: 1.459618]\n",
      "epoch:20 step:18742 [D loss: 0.649857, acc.: 64.06%] [G loss: 1.355281]\n",
      "epoch:20 step:18743 [D loss: 0.587476, acc.: 71.88%] [G loss: 1.085896]\n",
      "epoch:20 step:18744 [D loss: 0.510282, acc.: 75.78%] [G loss: 1.435888]\n",
      "epoch:20 step:18745 [D loss: 0.614332, acc.: 65.62%] [G loss: 1.380362]\n",
      "epoch:20 step:18746 [D loss: 0.706897, acc.: 57.81%] [G loss: 1.164072]\n",
      "epoch:20 step:18747 [D loss: 0.658543, acc.: 60.94%] [G loss: 1.312458]\n",
      "epoch:20 step:18748 [D loss: 0.587935, acc.: 66.41%] [G loss: 1.380294]\n",
      "epoch:20 step:18749 [D loss: 0.589548, acc.: 70.31%] [G loss: 1.494088]\n",
      "epoch:20 step:18750 [D loss: 0.489527, acc.: 75.78%] [G loss: 1.521097]\n",
      "epoch:20 step:18751 [D loss: 0.546674, acc.: 75.78%] [G loss: 1.503559]\n",
      "epoch:20 step:18752 [D loss: 0.565646, acc.: 67.19%] [G loss: 1.608035]\n",
      "epoch:20 step:18753 [D loss: 0.495889, acc.: 72.66%] [G loss: 1.088356]\n",
      "epoch:20 step:18754 [D loss: 0.539241, acc.: 72.66%] [G loss: 1.149132]\n",
      "epoch:20 step:18755 [D loss: 0.484685, acc.: 75.78%] [G loss: 1.434715]\n",
      "epoch:20 step:18756 [D loss: 0.510413, acc.: 70.31%] [G loss: 1.087679]\n",
      "epoch:20 step:18757 [D loss: 0.578765, acc.: 75.00%] [G loss: 1.561345]\n",
      "epoch:20 step:18758 [D loss: 0.667467, acc.: 61.72%] [G loss: 1.122821]\n",
      "epoch:20 step:18759 [D loss: 0.604308, acc.: 65.62%] [G loss: 1.113807]\n",
      "epoch:20 step:18760 [D loss: 0.481968, acc.: 75.78%] [G loss: 1.574713]\n",
      "epoch:20 step:18761 [D loss: 0.485919, acc.: 77.34%] [G loss: 1.109713]\n",
      "epoch:20 step:18762 [D loss: 0.525305, acc.: 78.12%] [G loss: 1.193441]\n",
      "epoch:20 step:18763 [D loss: 0.576302, acc.: 71.09%] [G loss: 1.177724]\n",
      "epoch:20 step:18764 [D loss: 0.520148, acc.: 74.22%] [G loss: 1.510546]\n",
      "epoch:20 step:18765 [D loss: 0.656817, acc.: 57.03%] [G loss: 1.058989]\n",
      "epoch:20 step:18766 [D loss: 0.625750, acc.: 65.62%] [G loss: 1.006042]\n",
      "epoch:20 step:18767 [D loss: 0.491692, acc.: 78.12%] [G loss: 1.316135]\n",
      "epoch:20 step:18768 [D loss: 0.478522, acc.: 79.69%] [G loss: 1.366658]\n",
      "epoch:20 step:18769 [D loss: 0.643057, acc.: 67.19%] [G loss: 1.405660]\n",
      "epoch:20 step:18770 [D loss: 0.608629, acc.: 67.97%] [G loss: 1.383764]\n",
      "epoch:20 step:18771 [D loss: 0.597754, acc.: 67.19%] [G loss: 1.398912]\n",
      "epoch:20 step:18772 [D loss: 0.495614, acc.: 77.34%] [G loss: 1.404029]\n",
      "epoch:20 step:18773 [D loss: 0.421623, acc.: 85.94%] [G loss: 1.162796]\n",
      "epoch:20 step:18774 [D loss: 0.585004, acc.: 71.09%] [G loss: 1.218244]\n",
      "epoch:20 step:18775 [D loss: 0.565785, acc.: 71.88%] [G loss: 1.038780]\n",
      "epoch:20 step:18776 [D loss: 0.456418, acc.: 79.69%] [G loss: 1.020304]\n",
      "epoch:20 step:18777 [D loss: 0.464630, acc.: 80.47%] [G loss: 1.314638]\n",
      "epoch:20 step:18778 [D loss: 0.443404, acc.: 80.47%] [G loss: 1.576157]\n",
      "epoch:20 step:18779 [D loss: 0.638081, acc.: 64.06%] [G loss: 1.156369]\n",
      "epoch:20 step:18780 [D loss: 0.698247, acc.: 60.94%] [G loss: 1.317562]\n",
      "epoch:20 step:18781 [D loss: 0.574768, acc.: 71.09%] [G loss: 0.993003]\n",
      "epoch:20 step:18782 [D loss: 0.635950, acc.: 65.62%] [G loss: 1.119692]\n",
      "epoch:20 step:18783 [D loss: 0.553722, acc.: 70.31%] [G loss: 1.196370]\n",
      "epoch:20 step:18784 [D loss: 0.562338, acc.: 72.66%] [G loss: 1.545800]\n",
      "epoch:20 step:18785 [D loss: 0.587285, acc.: 67.19%] [G loss: 1.331065]\n",
      "epoch:20 step:18786 [D loss: 0.656452, acc.: 64.84%] [G loss: 1.141628]\n",
      "epoch:20 step:18787 [D loss: 0.581395, acc.: 67.19%] [G loss: 1.313679]\n",
      "epoch:20 step:18788 [D loss: 0.494811, acc.: 78.91%] [G loss: 1.416732]\n",
      "epoch:20 step:18789 [D loss: 0.609307, acc.: 65.62%] [G loss: 1.051397]\n",
      "epoch:20 step:18790 [D loss: 0.512890, acc.: 72.66%] [G loss: 1.448913]\n",
      "epoch:20 step:18791 [D loss: 0.559119, acc.: 72.66%] [G loss: 1.632070]\n",
      "epoch:20 step:18792 [D loss: 0.556141, acc.: 69.53%] [G loss: 1.303697]\n",
      "epoch:20 step:18793 [D loss: 0.516039, acc.: 74.22%] [G loss: 1.249670]\n",
      "epoch:20 step:18794 [D loss: 0.543844, acc.: 69.53%] [G loss: 1.519798]\n",
      "epoch:20 step:18795 [D loss: 0.498313, acc.: 78.12%] [G loss: 1.396987]\n",
      "epoch:20 step:18796 [D loss: 0.743405, acc.: 55.47%] [G loss: 1.169925]\n",
      "epoch:20 step:18797 [D loss: 0.586737, acc.: 67.19%] [G loss: 1.541306]\n",
      "epoch:20 step:18798 [D loss: 0.530663, acc.: 79.69%] [G loss: 1.325628]\n",
      "epoch:20 step:18799 [D loss: 0.485974, acc.: 79.69%] [G loss: 1.394332]\n",
      "epoch:20 step:18800 [D loss: 0.494943, acc.: 79.69%] [G loss: 1.289031]\n",
      "epoch:20 step:18801 [D loss: 0.737214, acc.: 52.34%] [G loss: 1.301586]\n",
      "epoch:20 step:18802 [D loss: 0.602870, acc.: 71.09%] [G loss: 1.256783]\n",
      "epoch:20 step:18803 [D loss: 0.579955, acc.: 71.09%] [G loss: 1.108814]\n",
      "epoch:20 step:18804 [D loss: 0.596071, acc.: 65.62%] [G loss: 1.241129]\n",
      "epoch:20 step:18805 [D loss: 0.498092, acc.: 75.00%] [G loss: 1.460220]\n",
      "epoch:20 step:18806 [D loss: 0.625593, acc.: 61.72%] [G loss: 1.335521]\n",
      "epoch:20 step:18807 [D loss: 0.684338, acc.: 57.03%] [G loss: 0.838921]\n",
      "epoch:20 step:18808 [D loss: 0.668682, acc.: 57.03%] [G loss: 1.143910]\n",
      "epoch:20 step:18809 [D loss: 0.689848, acc.: 64.06%] [G loss: 1.210238]\n",
      "epoch:20 step:18810 [D loss: 0.647681, acc.: 64.06%] [G loss: 1.103939]\n",
      "epoch:20 step:18811 [D loss: 0.621664, acc.: 64.06%] [G loss: 1.246122]\n",
      "epoch:20 step:18812 [D loss: 0.529957, acc.: 74.22%] [G loss: 1.379265]\n",
      "epoch:20 step:18813 [D loss: 0.398507, acc.: 86.72%] [G loss: 1.096808]\n",
      "epoch:20 step:18814 [D loss: 0.462837, acc.: 82.81%] [G loss: 1.403291]\n",
      "epoch:20 step:18815 [D loss: 0.568465, acc.: 68.75%] [G loss: 1.343508]\n",
      "epoch:20 step:18816 [D loss: 0.590723, acc.: 67.97%] [G loss: 1.135334]\n",
      "epoch:20 step:18817 [D loss: 0.694106, acc.: 56.25%] [G loss: 1.568665]\n",
      "epoch:20 step:18818 [D loss: 0.649674, acc.: 65.62%] [G loss: 1.089700]\n",
      "epoch:20 step:18819 [D loss: 0.538676, acc.: 75.78%] [G loss: 1.382423]\n",
      "epoch:20 step:18820 [D loss: 0.615110, acc.: 66.41%] [G loss: 1.239572]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:20 step:18821 [D loss: 0.548921, acc.: 75.78%] [G loss: 1.424552]\n",
      "epoch:20 step:18822 [D loss: 0.508973, acc.: 77.34%] [G loss: 1.304029]\n",
      "epoch:20 step:18823 [D loss: 0.578385, acc.: 72.66%] [G loss: 1.078872]\n",
      "epoch:20 step:18824 [D loss: 0.564716, acc.: 70.31%] [G loss: 1.516666]\n",
      "epoch:20 step:18825 [D loss: 0.720886, acc.: 57.81%] [G loss: 1.177076]\n",
      "epoch:20 step:18826 [D loss: 0.547770, acc.: 71.88%] [G loss: 1.696556]\n",
      "epoch:20 step:18827 [D loss: 0.733281, acc.: 49.22%] [G loss: 1.381038]\n",
      "epoch:20 step:18828 [D loss: 0.450533, acc.: 81.25%] [G loss: 1.363574]\n",
      "epoch:20 step:18829 [D loss: 0.625505, acc.: 69.53%] [G loss: 1.450077]\n",
      "epoch:20 step:18830 [D loss: 0.485716, acc.: 77.34%] [G loss: 1.544802]\n",
      "epoch:20 step:18831 [D loss: 0.519010, acc.: 76.56%] [G loss: 1.581343]\n",
      "epoch:20 step:18832 [D loss: 0.560352, acc.: 71.09%] [G loss: 1.248204]\n",
      "epoch:20 step:18833 [D loss: 0.602564, acc.: 62.50%] [G loss: 1.232139]\n",
      "epoch:20 step:18834 [D loss: 0.338287, acc.: 89.06%] [G loss: 1.555773]\n",
      "epoch:20 step:18835 [D loss: 0.577774, acc.: 67.97%] [G loss: 1.311297]\n",
      "epoch:20 step:18836 [D loss: 0.505663, acc.: 76.56%] [G loss: 1.516006]\n",
      "epoch:20 step:18837 [D loss: 0.515300, acc.: 78.12%] [G loss: 1.437031]\n",
      "epoch:20 step:18838 [D loss: 0.597241, acc.: 69.53%] [G loss: 1.099522]\n",
      "epoch:20 step:18839 [D loss: 0.577857, acc.: 72.66%] [G loss: 1.279961]\n",
      "epoch:20 step:18840 [D loss: 0.441164, acc.: 80.47%] [G loss: 1.580312]\n",
      "epoch:20 step:18841 [D loss: 0.655867, acc.: 61.72%] [G loss: 1.004953]\n",
      "epoch:20 step:18842 [D loss: 0.665435, acc.: 63.28%] [G loss: 1.328688]\n",
      "epoch:20 step:18843 [D loss: 0.598324, acc.: 71.09%] [G loss: 1.441374]\n",
      "epoch:20 step:18844 [D loss: 0.720208, acc.: 55.47%] [G loss: 1.093716]\n",
      "epoch:20 step:18845 [D loss: 0.591740, acc.: 72.66%] [G loss: 1.139960]\n",
      "epoch:20 step:18846 [D loss: 0.586449, acc.: 67.97%] [G loss: 1.165290]\n",
      "epoch:20 step:18847 [D loss: 0.639783, acc.: 67.97%] [G loss: 1.361739]\n",
      "epoch:20 step:18848 [D loss: 0.515181, acc.: 74.22%] [G loss: 1.268967]\n",
      "epoch:20 step:18849 [D loss: 0.434656, acc.: 78.12%] [G loss: 1.511821]\n",
      "epoch:20 step:18850 [D loss: 0.667354, acc.: 58.59%] [G loss: 1.121932]\n",
      "epoch:20 step:18851 [D loss: 0.521954, acc.: 76.56%] [G loss: 1.100732]\n",
      "epoch:20 step:18852 [D loss: 0.459025, acc.: 82.03%] [G loss: 1.330407]\n",
      "epoch:20 step:18853 [D loss: 0.495720, acc.: 78.91%] [G loss: 1.522760]\n",
      "epoch:20 step:18854 [D loss: 0.539590, acc.: 73.44%] [G loss: 1.645105]\n",
      "epoch:20 step:18855 [D loss: 0.553911, acc.: 75.00%] [G loss: 1.606511]\n",
      "epoch:20 step:18856 [D loss: 0.451927, acc.: 82.03%] [G loss: 1.256160]\n",
      "epoch:20 step:18857 [D loss: 0.492993, acc.: 75.78%] [G loss: 1.518825]\n",
      "epoch:20 step:18858 [D loss: 0.601822, acc.: 67.19%] [G loss: 1.317036]\n",
      "epoch:20 step:18859 [D loss: 0.445006, acc.: 79.69%] [G loss: 1.238251]\n",
      "epoch:20 step:18860 [D loss: 0.636583, acc.: 64.84%] [G loss: 1.372799]\n",
      "epoch:20 step:18861 [D loss: 0.519136, acc.: 71.88%] [G loss: 1.260756]\n",
      "epoch:20 step:18862 [D loss: 0.654665, acc.: 58.59%] [G loss: 0.958025]\n",
      "epoch:20 step:18863 [D loss: 0.430192, acc.: 81.25%] [G loss: 1.355521]\n",
      "epoch:20 step:18864 [D loss: 0.528984, acc.: 72.66%] [G loss: 1.347718]\n",
      "epoch:20 step:18865 [D loss: 0.418225, acc.: 87.50%] [G loss: 1.319938]\n",
      "epoch:20 step:18866 [D loss: 0.686581, acc.: 57.81%] [G loss: 1.190953]\n",
      "epoch:20 step:18867 [D loss: 0.660718, acc.: 64.06%] [G loss: 1.336941]\n",
      "epoch:20 step:18868 [D loss: 0.537855, acc.: 71.88%] [G loss: 1.033072]\n",
      "epoch:20 step:18869 [D loss: 0.504562, acc.: 78.91%] [G loss: 1.335159]\n",
      "epoch:20 step:18870 [D loss: 0.600209, acc.: 70.31%] [G loss: 1.450336]\n",
      "epoch:20 step:18871 [D loss: 0.551009, acc.: 77.34%] [G loss: 1.490008]\n",
      "epoch:20 step:18872 [D loss: 0.557344, acc.: 68.75%] [G loss: 1.231150]\n",
      "epoch:20 step:18873 [D loss: 0.476661, acc.: 77.34%] [G loss: 1.243842]\n",
      "epoch:20 step:18874 [D loss: 0.548728, acc.: 72.66%] [G loss: 1.275835]\n",
      "epoch:20 step:18875 [D loss: 0.581795, acc.: 66.41%] [G loss: 1.250683]\n",
      "epoch:20 step:18876 [D loss: 0.586080, acc.: 67.97%] [G loss: 1.261974]\n",
      "epoch:20 step:18877 [D loss: 0.495181, acc.: 75.00%] [G loss: 1.615141]\n",
      "epoch:20 step:18878 [D loss: 0.667670, acc.: 64.06%] [G loss: 1.127144]\n",
      "epoch:20 step:18879 [D loss: 0.658208, acc.: 61.72%] [G loss: 1.290922]\n",
      "epoch:20 step:18880 [D loss: 0.460653, acc.: 79.69%] [G loss: 1.159178]\n",
      "epoch:20 step:18881 [D loss: 0.603277, acc.: 67.97%] [G loss: 1.113357]\n",
      "epoch:20 step:18882 [D loss: 0.526864, acc.: 71.88%] [G loss: 1.257762]\n",
      "epoch:20 step:18883 [D loss: 0.461087, acc.: 78.12%] [G loss: 1.061075]\n",
      "epoch:20 step:18884 [D loss: 0.709485, acc.: 61.72%] [G loss: 1.209175]\n",
      "epoch:20 step:18885 [D loss: 0.385861, acc.: 88.28%] [G loss: 1.319839]\n",
      "epoch:20 step:18886 [D loss: 0.554254, acc.: 76.56%] [G loss: 1.112931]\n",
      "epoch:20 step:18887 [D loss: 0.508713, acc.: 75.78%] [G loss: 1.530404]\n",
      "epoch:20 step:18888 [D loss: 0.575036, acc.: 67.19%] [G loss: 0.780136]\n",
      "epoch:20 step:18889 [D loss: 0.632076, acc.: 65.62%] [G loss: 1.354916]\n",
      "epoch:20 step:18890 [D loss: 0.572068, acc.: 69.53%] [G loss: 1.061569]\n",
      "epoch:20 step:18891 [D loss: 0.431240, acc.: 81.25%] [G loss: 1.452659]\n",
      "epoch:20 step:18892 [D loss: 0.701785, acc.: 58.59%] [G loss: 1.384709]\n",
      "epoch:20 step:18893 [D loss: 0.519838, acc.: 69.53%] [G loss: 1.537445]\n",
      "epoch:20 step:18894 [D loss: 0.468140, acc.: 76.56%] [G loss: 1.415620]\n",
      "epoch:20 step:18895 [D loss: 0.560223, acc.: 69.53%] [G loss: 1.417054]\n",
      "epoch:20 step:18896 [D loss: 0.604926, acc.: 69.53%] [G loss: 1.317736]\n",
      "epoch:20 step:18897 [D loss: 0.657287, acc.: 62.50%] [G loss: 1.373571]\n",
      "epoch:20 step:18898 [D loss: 0.561126, acc.: 76.56%] [G loss: 1.181263]\n",
      "epoch:20 step:18899 [D loss: 0.447307, acc.: 81.25%] [G loss: 1.702138]\n",
      "epoch:20 step:18900 [D loss: 0.513750, acc.: 76.56%] [G loss: 1.189568]\n",
      "epoch:20 step:18901 [D loss: 0.664237, acc.: 62.50%] [G loss: 1.060779]\n",
      "epoch:20 step:18902 [D loss: 0.699301, acc.: 55.47%] [G loss: 1.082829]\n",
      "epoch:20 step:18903 [D loss: 0.649203, acc.: 63.28%] [G loss: 1.243288]\n",
      "epoch:20 step:18904 [D loss: 0.503055, acc.: 78.91%] [G loss: 1.335255]\n",
      "epoch:20 step:18905 [D loss: 0.526170, acc.: 73.44%] [G loss: 1.338789]\n",
      "epoch:20 step:18906 [D loss: 0.498576, acc.: 76.56%] [G loss: 1.428785]\n",
      "epoch:20 step:18907 [D loss: 0.638196, acc.: 62.50%] [G loss: 1.106223]\n",
      "epoch:20 step:18908 [D loss: 0.584658, acc.: 71.88%] [G loss: 1.266483]\n",
      "epoch:20 step:18909 [D loss: 0.561829, acc.: 68.75%] [G loss: 1.431516]\n",
      "epoch:20 step:18910 [D loss: 0.533658, acc.: 73.44%] [G loss: 1.506549]\n",
      "epoch:20 step:18911 [D loss: 0.623836, acc.: 65.62%] [G loss: 1.234852]\n",
      "epoch:20 step:18912 [D loss: 0.451010, acc.: 82.81%] [G loss: 1.315282]\n",
      "epoch:20 step:18913 [D loss: 0.522850, acc.: 77.34%] [G loss: 1.341132]\n",
      "epoch:20 step:18914 [D loss: 0.533753, acc.: 75.00%] [G loss: 1.221934]\n",
      "epoch:20 step:18915 [D loss: 0.564593, acc.: 71.09%] [G loss: 1.387405]\n",
      "epoch:20 step:18916 [D loss: 0.524870, acc.: 76.56%] [G loss: 1.288518]\n",
      "epoch:20 step:18917 [D loss: 0.487450, acc.: 79.69%] [G loss: 1.269470]\n",
      "epoch:20 step:18918 [D loss: 0.561316, acc.: 70.31%] [G loss: 1.062278]\n",
      "epoch:20 step:18919 [D loss: 0.547721, acc.: 73.44%] [G loss: 1.402291]\n",
      "epoch:20 step:18920 [D loss: 0.519448, acc.: 74.22%] [G loss: 1.613258]\n",
      "epoch:20 step:18921 [D loss: 0.519359, acc.: 74.22%] [G loss: 1.545323]\n",
      "epoch:20 step:18922 [D loss: 0.448911, acc.: 81.25%] [G loss: 1.575673]\n",
      "epoch:20 step:18923 [D loss: 0.380823, acc.: 88.28%] [G loss: 1.810839]\n",
      "epoch:20 step:18924 [D loss: 0.646326, acc.: 65.62%] [G loss: 1.185141]\n",
      "epoch:20 step:18925 [D loss: 0.434918, acc.: 82.81%] [G loss: 1.361143]\n",
      "epoch:20 step:18926 [D loss: 0.419311, acc.: 81.25%] [G loss: 1.666867]\n",
      "epoch:20 step:18927 [D loss: 0.605931, acc.: 66.41%] [G loss: 1.179167]\n",
      "epoch:20 step:18928 [D loss: 0.578552, acc.: 69.53%] [G loss: 1.462157]\n",
      "epoch:20 step:18929 [D loss: 0.691099, acc.: 60.94%] [G loss: 1.016973]\n",
      "epoch:20 step:18930 [D loss: 0.534516, acc.: 73.44%] [G loss: 1.244848]\n",
      "epoch:20 step:18931 [D loss: 0.462767, acc.: 83.59%] [G loss: 1.080689]\n",
      "epoch:20 step:18932 [D loss: 0.614874, acc.: 64.06%] [G loss: 1.454978]\n",
      "epoch:20 step:18933 [D loss: 0.581310, acc.: 64.84%] [G loss: 1.210458]\n",
      "epoch:20 step:18934 [D loss: 0.700081, acc.: 59.38%] [G loss: 1.396237]\n",
      "epoch:20 step:18935 [D loss: 0.680354, acc.: 57.03%] [G loss: 1.084594]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:20 step:18936 [D loss: 0.481259, acc.: 75.78%] [G loss: 1.500633]\n",
      "epoch:20 step:18937 [D loss: 0.485546, acc.: 78.91%] [G loss: 1.649968]\n",
      "epoch:20 step:18938 [D loss: 0.544966, acc.: 69.53%] [G loss: 1.414142]\n",
      "epoch:20 step:18939 [D loss: 0.566880, acc.: 71.09%] [G loss: 1.085654]\n",
      "epoch:20 step:18940 [D loss: 0.517234, acc.: 75.78%] [G loss: 1.269545]\n",
      "epoch:20 step:18941 [D loss: 0.456707, acc.: 81.25%] [G loss: 1.351748]\n",
      "epoch:20 step:18942 [D loss: 0.677533, acc.: 57.81%] [G loss: 1.296726]\n",
      "epoch:20 step:18943 [D loss: 0.510913, acc.: 76.56%] [G loss: 1.361001]\n",
      "epoch:20 step:18944 [D loss: 0.467292, acc.: 76.56%] [G loss: 1.711394]\n",
      "epoch:20 step:18945 [D loss: 0.733881, acc.: 56.25%] [G loss: 1.573807]\n",
      "epoch:20 step:18946 [D loss: 0.537781, acc.: 74.22%] [G loss: 1.450729]\n",
      "epoch:20 step:18947 [D loss: 0.598812, acc.: 66.41%] [G loss: 1.273707]\n",
      "epoch:20 step:18948 [D loss: 0.365174, acc.: 89.06%] [G loss: 1.700535]\n",
      "epoch:20 step:18949 [D loss: 0.546810, acc.: 73.44%] [G loss: 1.304162]\n",
      "epoch:20 step:18950 [D loss: 0.652283, acc.: 65.62%] [G loss: 0.995830]\n",
      "epoch:20 step:18951 [D loss: 0.468717, acc.: 77.34%] [G loss: 1.402609]\n",
      "epoch:20 step:18952 [D loss: 0.496686, acc.: 78.91%] [G loss: 1.412737]\n",
      "epoch:20 step:18953 [D loss: 0.659769, acc.: 62.50%] [G loss: 1.249731]\n",
      "epoch:20 step:18954 [D loss: 0.660871, acc.: 67.19%] [G loss: 1.164679]\n",
      "epoch:20 step:18955 [D loss: 0.663176, acc.: 65.62%] [G loss: 1.051370]\n",
      "epoch:20 step:18956 [D loss: 0.507138, acc.: 75.78%] [G loss: 1.737040]\n",
      "epoch:20 step:18957 [D loss: 0.544142, acc.: 81.25%] [G loss: 1.348755]\n",
      "epoch:20 step:18958 [D loss: 0.523606, acc.: 76.56%] [G loss: 1.318910]\n",
      "epoch:20 step:18959 [D loss: 0.660851, acc.: 63.28%] [G loss: 1.214154]\n",
      "epoch:20 step:18960 [D loss: 0.643272, acc.: 66.41%] [G loss: 1.126139]\n",
      "epoch:20 step:18961 [D loss: 0.670777, acc.: 60.16%] [G loss: 1.394988]\n",
      "epoch:20 step:18962 [D loss: 0.583779, acc.: 67.19%] [G loss: 1.669902]\n",
      "epoch:20 step:18963 [D loss: 0.611987, acc.: 67.97%] [G loss: 1.474496]\n",
      "epoch:20 step:18964 [D loss: 0.597839, acc.: 69.53%] [G loss: 1.429976]\n",
      "epoch:20 step:18965 [D loss: 0.589259, acc.: 70.31%] [G loss: 1.107389]\n",
      "epoch:20 step:18966 [D loss: 0.530725, acc.: 76.56%] [G loss: 1.145029]\n",
      "epoch:20 step:18967 [D loss: 0.499929, acc.: 80.47%] [G loss: 1.279287]\n",
      "epoch:20 step:18968 [D loss: 0.530127, acc.: 74.22%] [G loss: 1.171911]\n",
      "epoch:20 step:18969 [D loss: 0.611850, acc.: 71.88%] [G loss: 0.887730]\n",
      "epoch:20 step:18970 [D loss: 0.532153, acc.: 78.12%] [G loss: 1.318659]\n",
      "epoch:20 step:18971 [D loss: 0.672492, acc.: 60.16%] [G loss: 1.396568]\n",
      "epoch:20 step:18972 [D loss: 0.630842, acc.: 64.06%] [G loss: 1.336504]\n",
      "epoch:20 step:18973 [D loss: 0.640389, acc.: 67.19%] [G loss: 1.192248]\n",
      "epoch:20 step:18974 [D loss: 0.566394, acc.: 71.88%] [G loss: 1.237148]\n",
      "epoch:20 step:18975 [D loss: 0.577653, acc.: 67.19%] [G loss: 1.243003]\n",
      "epoch:20 step:18976 [D loss: 0.585753, acc.: 67.19%] [G loss: 1.609176]\n",
      "epoch:20 step:18977 [D loss: 0.675971, acc.: 55.47%] [G loss: 1.453226]\n",
      "epoch:20 step:18978 [D loss: 0.617226, acc.: 67.19%] [G loss: 1.409043]\n",
      "epoch:20 step:18979 [D loss: 0.595043, acc.: 67.97%] [G loss: 0.992601]\n",
      "epoch:20 step:18980 [D loss: 0.566389, acc.: 74.22%] [G loss: 1.582875]\n",
      "epoch:20 step:18981 [D loss: 0.555727, acc.: 74.22%] [G loss: 1.234534]\n",
      "epoch:20 step:18982 [D loss: 0.623507, acc.: 68.75%] [G loss: 1.298544]\n",
      "epoch:20 step:18983 [D loss: 0.607074, acc.: 66.41%] [G loss: 1.123996]\n",
      "epoch:20 step:18984 [D loss: 0.503930, acc.: 76.56%] [G loss: 1.179234]\n",
      "epoch:20 step:18985 [D loss: 0.509017, acc.: 75.78%] [G loss: 1.323451]\n",
      "epoch:20 step:18986 [D loss: 0.724145, acc.: 53.91%] [G loss: 1.417170]\n",
      "epoch:20 step:18987 [D loss: 0.750229, acc.: 57.03%] [G loss: 1.331457]\n",
      "epoch:20 step:18988 [D loss: 0.577027, acc.: 73.44%] [G loss: 1.387643]\n",
      "epoch:20 step:18989 [D loss: 0.401785, acc.: 84.38%] [G loss: 1.554794]\n",
      "epoch:20 step:18990 [D loss: 0.545439, acc.: 69.53%] [G loss: 1.338644]\n",
      "epoch:20 step:18991 [D loss: 0.474726, acc.: 78.12%] [G loss: 1.020598]\n",
      "epoch:20 step:18992 [D loss: 0.490698, acc.: 77.34%] [G loss: 1.043628]\n",
      "epoch:20 step:18993 [D loss: 0.509867, acc.: 76.56%] [G loss: 1.268125]\n",
      "epoch:20 step:18994 [D loss: 0.599809, acc.: 66.41%] [G loss: 1.343593]\n",
      "epoch:20 step:18995 [D loss: 0.531473, acc.: 73.44%] [G loss: 1.370067]\n",
      "epoch:20 step:18996 [D loss: 0.532643, acc.: 72.66%] [G loss: 1.432180]\n",
      "epoch:20 step:18997 [D loss: 0.645414, acc.: 65.62%] [G loss: 1.267330]\n",
      "epoch:20 step:18998 [D loss: 0.590226, acc.: 73.44%] [G loss: 1.525199]\n",
      "epoch:20 step:18999 [D loss: 0.597272, acc.: 67.97%] [G loss: 0.903013]\n",
      "epoch:20 step:19000 [D loss: 0.530517, acc.: 71.88%] [G loss: 1.283505]\n",
      "epoch:20 step:19001 [D loss: 0.580654, acc.: 68.75%] [G loss: 1.158704]\n",
      "epoch:20 step:19002 [D loss: 0.649665, acc.: 61.72%] [G loss: 1.470961]\n",
      "epoch:20 step:19003 [D loss: 0.796941, acc.: 48.44%] [G loss: 1.079579]\n",
      "epoch:20 step:19004 [D loss: 0.533058, acc.: 72.66%] [G loss: 1.510872]\n",
      "epoch:20 step:19005 [D loss: 0.361663, acc.: 90.62%] [G loss: 1.430763]\n",
      "epoch:20 step:19006 [D loss: 0.622096, acc.: 67.97%] [G loss: 1.198730]\n",
      "epoch:20 step:19007 [D loss: 0.697679, acc.: 60.94%] [G loss: 1.463676]\n",
      "epoch:20 step:19008 [D loss: 0.481815, acc.: 76.56%] [G loss: 1.399149]\n",
      "epoch:20 step:19009 [D loss: 0.507639, acc.: 75.78%] [G loss: 1.497766]\n",
      "epoch:20 step:19010 [D loss: 0.402400, acc.: 87.50%] [G loss: 1.610776]\n",
      "epoch:20 step:19011 [D loss: 0.435952, acc.: 81.25%] [G loss: 1.552617]\n",
      "epoch:20 step:19012 [D loss: 0.721195, acc.: 54.69%] [G loss: 1.337118]\n",
      "epoch:20 step:19013 [D loss: 0.759608, acc.: 54.69%] [G loss: 1.129827]\n",
      "epoch:20 step:19014 [D loss: 0.499363, acc.: 74.22%] [G loss: 1.457354]\n",
      "epoch:20 step:19015 [D loss: 0.771908, acc.: 53.91%] [G loss: 1.245863]\n",
      "epoch:20 step:19016 [D loss: 0.743219, acc.: 58.59%] [G loss: 1.037413]\n",
      "epoch:20 step:19017 [D loss: 0.585001, acc.: 69.53%] [G loss: 1.355578]\n",
      "epoch:20 step:19018 [D loss: 0.635625, acc.: 65.62%] [G loss: 1.281745]\n",
      "epoch:20 step:19019 [D loss: 0.790371, acc.: 50.78%] [G loss: 1.138018]\n",
      "epoch:20 step:19020 [D loss: 0.518244, acc.: 75.00%] [G loss: 1.285456]\n",
      "epoch:20 step:19021 [D loss: 0.566841, acc.: 71.09%] [G loss: 1.766304]\n",
      "epoch:20 step:19022 [D loss: 0.593393, acc.: 67.97%] [G loss: 1.104952]\n",
      "epoch:20 step:19023 [D loss: 0.540112, acc.: 69.53%] [G loss: 1.651120]\n",
      "epoch:20 step:19024 [D loss: 0.663566, acc.: 62.50%] [G loss: 1.616588]\n",
      "epoch:20 step:19025 [D loss: 0.480390, acc.: 79.69%] [G loss: 1.215676]\n",
      "epoch:20 step:19026 [D loss: 0.530803, acc.: 72.66%] [G loss: 0.863635]\n",
      "epoch:20 step:19027 [D loss: 0.506796, acc.: 79.69%] [G loss: 1.124690]\n",
      "epoch:20 step:19028 [D loss: 0.542239, acc.: 73.44%] [G loss: 1.724998]\n",
      "epoch:20 step:19029 [D loss: 0.501379, acc.: 78.12%] [G loss: 1.334664]\n",
      "epoch:20 step:19030 [D loss: 0.578361, acc.: 69.53%] [G loss: 1.210370]\n",
      "epoch:20 step:19031 [D loss: 0.647764, acc.: 64.84%] [G loss: 1.056434]\n",
      "epoch:20 step:19032 [D loss: 0.552462, acc.: 73.44%] [G loss: 1.352252]\n",
      "epoch:20 step:19033 [D loss: 0.669967, acc.: 62.50%] [G loss: 1.197927]\n",
      "epoch:20 step:19034 [D loss: 0.649999, acc.: 64.06%] [G loss: 1.114685]\n",
      "epoch:20 step:19035 [D loss: 0.632082, acc.: 70.31%] [G loss: 1.349883]\n",
      "epoch:20 step:19036 [D loss: 0.542243, acc.: 68.75%] [G loss: 1.222536]\n",
      "epoch:20 step:19037 [D loss: 0.590622, acc.: 70.31%] [G loss: 1.017340]\n",
      "epoch:20 step:19038 [D loss: 0.710992, acc.: 58.59%] [G loss: 1.270433]\n",
      "epoch:20 step:19039 [D loss: 0.594614, acc.: 70.31%] [G loss: 1.222366]\n",
      "epoch:20 step:19040 [D loss: 0.579746, acc.: 72.66%] [G loss: 1.189919]\n",
      "epoch:20 step:19041 [D loss: 0.606961, acc.: 68.75%] [G loss: 1.259541]\n",
      "epoch:20 step:19042 [D loss: 0.527322, acc.: 76.56%] [G loss: 1.654651]\n",
      "epoch:20 step:19043 [D loss: 0.557571, acc.: 74.22%] [G loss: 1.155649]\n",
      "epoch:20 step:19044 [D loss: 0.481777, acc.: 78.12%] [G loss: 1.410041]\n",
      "epoch:20 step:19045 [D loss: 0.573278, acc.: 72.66%] [G loss: 1.340525]\n",
      "epoch:20 step:19046 [D loss: 0.528769, acc.: 78.12%] [G loss: 1.441879]\n",
      "epoch:20 step:19047 [D loss: 0.598788, acc.: 65.62%] [G loss: 1.353790]\n",
      "epoch:20 step:19048 [D loss: 0.553668, acc.: 69.53%] [G loss: 1.344198]\n",
      "epoch:20 step:19049 [D loss: 0.533409, acc.: 71.09%] [G loss: 1.359723]\n",
      "epoch:20 step:19050 [D loss: 0.712198, acc.: 61.72%] [G loss: 1.201531]\n",
      "epoch:20 step:19051 [D loss: 0.511438, acc.: 78.91%] [G loss: 0.991843]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:20 step:19052 [D loss: 0.559656, acc.: 72.66%] [G loss: 1.242035]\n",
      "epoch:20 step:19053 [D loss: 0.542704, acc.: 71.88%] [G loss: 1.015052]\n",
      "epoch:20 step:19054 [D loss: 0.523187, acc.: 72.66%] [G loss: 1.500979]\n",
      "epoch:20 step:19055 [D loss: 0.546127, acc.: 69.53%] [G loss: 1.231623]\n",
      "epoch:20 step:19056 [D loss: 0.459756, acc.: 82.03%] [G loss: 1.644370]\n",
      "epoch:20 step:19057 [D loss: 0.489190, acc.: 75.78%] [G loss: 1.444286]\n",
      "epoch:20 step:19058 [D loss: 0.507375, acc.: 75.00%] [G loss: 1.131098]\n",
      "epoch:20 step:19059 [D loss: 0.622668, acc.: 67.19%] [G loss: 1.382594]\n",
      "epoch:20 step:19060 [D loss: 0.628395, acc.: 67.19%] [G loss: 1.285607]\n",
      "epoch:20 step:19061 [D loss: 0.791906, acc.: 49.22%] [G loss: 1.368332]\n",
      "epoch:20 step:19062 [D loss: 0.572107, acc.: 73.44%] [G loss: 1.408880]\n",
      "epoch:20 step:19063 [D loss: 0.639941, acc.: 65.62%] [G loss: 0.883206]\n",
      "epoch:20 step:19064 [D loss: 0.523920, acc.: 71.09%] [G loss: 1.196704]\n",
      "epoch:20 step:19065 [D loss: 0.627579, acc.: 64.84%] [G loss: 1.451023]\n",
      "epoch:20 step:19066 [D loss: 0.516938, acc.: 71.88%] [G loss: 1.313529]\n",
      "epoch:20 step:19067 [D loss: 0.389950, acc.: 84.38%] [G loss: 1.523201]\n",
      "epoch:20 step:19068 [D loss: 0.613116, acc.: 66.41%] [G loss: 1.438190]\n",
      "epoch:20 step:19069 [D loss: 0.550426, acc.: 69.53%] [G loss: 1.252361]\n",
      "epoch:20 step:19070 [D loss: 0.538723, acc.: 71.88%] [G loss: 1.158403]\n",
      "epoch:20 step:19071 [D loss: 0.534136, acc.: 76.56%] [G loss: 1.567024]\n",
      "epoch:20 step:19072 [D loss: 0.559124, acc.: 69.53%] [G loss: 1.502592]\n",
      "epoch:20 step:19073 [D loss: 0.567491, acc.: 75.78%] [G loss: 1.462445]\n",
      "epoch:20 step:19074 [D loss: 0.532529, acc.: 71.88%] [G loss: 1.576560]\n",
      "epoch:20 step:19075 [D loss: 0.666498, acc.: 64.84%] [G loss: 1.100235]\n",
      "epoch:20 step:19076 [D loss: 0.375489, acc.: 83.59%] [G loss: 1.288579]\n",
      "epoch:20 step:19077 [D loss: 0.649164, acc.: 62.50%] [G loss: 1.147752]\n",
      "epoch:20 step:19078 [D loss: 0.555369, acc.: 71.88%] [G loss: 1.202077]\n",
      "epoch:20 step:19079 [D loss: 0.457053, acc.: 80.47%] [G loss: 1.490924]\n",
      "epoch:20 step:19080 [D loss: 0.553557, acc.: 70.31%] [G loss: 1.155770]\n",
      "epoch:20 step:19081 [D loss: 0.668133, acc.: 60.94%] [G loss: 0.914876]\n",
      "epoch:20 step:19082 [D loss: 0.651323, acc.: 64.06%] [G loss: 1.309827]\n",
      "epoch:20 step:19083 [D loss: 0.755276, acc.: 48.44%] [G loss: 1.139811]\n",
      "epoch:20 step:19084 [D loss: 0.505995, acc.: 77.34%] [G loss: 1.279021]\n",
      "epoch:20 step:19085 [D loss: 0.659842, acc.: 60.94%] [G loss: 1.547887]\n",
      "epoch:20 step:19086 [D loss: 0.629779, acc.: 68.75%] [G loss: 1.006279]\n",
      "epoch:20 step:19087 [D loss: 0.744563, acc.: 56.25%] [G loss: 1.068610]\n",
      "epoch:20 step:19088 [D loss: 0.633344, acc.: 65.62%] [G loss: 1.163379]\n",
      "epoch:20 step:19089 [D loss: 0.506618, acc.: 77.34%] [G loss: 1.628361]\n",
      "epoch:20 step:19090 [D loss: 0.650417, acc.: 60.16%] [G loss: 1.280075]\n",
      "epoch:20 step:19091 [D loss: 0.539817, acc.: 74.22%] [G loss: 1.479356]\n",
      "epoch:20 step:19092 [D loss: 0.518060, acc.: 75.00%] [G loss: 1.317337]\n",
      "epoch:20 step:19093 [D loss: 0.605090, acc.: 66.41%] [G loss: 1.368020]\n",
      "epoch:20 step:19094 [D loss: 0.527650, acc.: 71.09%] [G loss: 1.227412]\n",
      "epoch:20 step:19095 [D loss: 0.663271, acc.: 59.38%] [G loss: 1.130433]\n",
      "epoch:20 step:19096 [D loss: 0.554047, acc.: 73.44%] [G loss: 1.443394]\n",
      "epoch:20 step:19097 [D loss: 0.504090, acc.: 77.34%] [G loss: 1.527458]\n",
      "epoch:20 step:19098 [D loss: 0.521623, acc.: 71.88%] [G loss: 1.303033]\n",
      "epoch:20 step:19099 [D loss: 0.681998, acc.: 61.72%] [G loss: 1.265800]\n",
      "epoch:20 step:19100 [D loss: 0.431057, acc.: 84.38%] [G loss: 1.446915]\n",
      "epoch:20 step:19101 [D loss: 0.442928, acc.: 82.81%] [G loss: 1.265031]\n",
      "epoch:20 step:19102 [D loss: 0.522243, acc.: 78.12%] [G loss: 1.517897]\n",
      "epoch:20 step:19103 [D loss: 0.487956, acc.: 78.91%] [G loss: 1.306183]\n",
      "epoch:20 step:19104 [D loss: 0.736118, acc.: 53.91%] [G loss: 1.289842]\n",
      "epoch:20 step:19105 [D loss: 0.467542, acc.: 75.78%] [G loss: 1.789113]\n",
      "epoch:20 step:19106 [D loss: 0.541592, acc.: 76.56%] [G loss: 1.276512]\n",
      "epoch:20 step:19107 [D loss: 0.461250, acc.: 75.00%] [G loss: 1.252482]\n",
      "epoch:20 step:19108 [D loss: 0.557779, acc.: 71.88%] [G loss: 1.100588]\n",
      "epoch:20 step:19109 [D loss: 0.551036, acc.: 73.44%] [G loss: 1.076867]\n",
      "epoch:20 step:19110 [D loss: 0.559932, acc.: 73.44%] [G loss: 1.328486]\n",
      "epoch:20 step:19111 [D loss: 0.446732, acc.: 81.25%] [G loss: 1.364688]\n",
      "epoch:20 step:19112 [D loss: 0.472955, acc.: 77.34%] [G loss: 1.163860]\n",
      "epoch:20 step:19113 [D loss: 0.488125, acc.: 78.12%] [G loss: 1.223840]\n",
      "epoch:20 step:19114 [D loss: 0.928823, acc.: 41.41%] [G loss: 0.918696]\n",
      "epoch:20 step:19115 [D loss: 0.542479, acc.: 72.66%] [G loss: 1.541682]\n",
      "epoch:20 step:19116 [D loss: 0.755438, acc.: 53.91%] [G loss: 1.276197]\n",
      "epoch:20 step:19117 [D loss: 0.573518, acc.: 69.53%] [G loss: 1.255516]\n",
      "epoch:20 step:19118 [D loss: 0.593165, acc.: 64.06%] [G loss: 1.288963]\n",
      "epoch:20 step:19119 [D loss: 0.526346, acc.: 75.78%] [G loss: 1.503823]\n",
      "epoch:20 step:19120 [D loss: 0.466011, acc.: 79.69%] [G loss: 1.368024]\n",
      "epoch:20 step:19121 [D loss: 0.408585, acc.: 87.50%] [G loss: 1.727277]\n",
      "epoch:20 step:19122 [D loss: 0.516623, acc.: 75.00%] [G loss: 1.264749]\n",
      "epoch:20 step:19123 [D loss: 0.776303, acc.: 56.25%] [G loss: 1.465764]\n",
      "epoch:20 step:19124 [D loss: 0.542125, acc.: 73.44%] [G loss: 1.308551]\n",
      "epoch:20 step:19125 [D loss: 0.532753, acc.: 72.66%] [G loss: 1.565980]\n",
      "epoch:20 step:19126 [D loss: 0.634556, acc.: 63.28%] [G loss: 1.067618]\n",
      "epoch:20 step:19127 [D loss: 0.486770, acc.: 76.56%] [G loss: 1.661827]\n",
      "epoch:20 step:19128 [D loss: 0.695362, acc.: 55.47%] [G loss: 1.310856]\n",
      "epoch:20 step:19129 [D loss: 0.485111, acc.: 77.34%] [G loss: 1.390638]\n",
      "epoch:20 step:19130 [D loss: 0.573582, acc.: 70.31%] [G loss: 1.257097]\n",
      "epoch:20 step:19131 [D loss: 0.644393, acc.: 61.72%] [G loss: 1.237583]\n",
      "epoch:20 step:19132 [D loss: 0.605190, acc.: 70.31%] [G loss: 1.363938]\n",
      "epoch:20 step:19133 [D loss: 0.817648, acc.: 46.09%] [G loss: 1.117831]\n",
      "epoch:20 step:19134 [D loss: 0.529624, acc.: 71.09%] [G loss: 1.445858]\n",
      "epoch:20 step:19135 [D loss: 0.623099, acc.: 62.50%] [G loss: 1.390357]\n",
      "epoch:20 step:19136 [D loss: 0.485539, acc.: 78.12%] [G loss: 1.356264]\n",
      "epoch:20 step:19137 [D loss: 0.520575, acc.: 68.75%] [G loss: 1.240061]\n",
      "epoch:20 step:19138 [D loss: 0.705803, acc.: 56.25%] [G loss: 1.191307]\n",
      "epoch:20 step:19139 [D loss: 0.555804, acc.: 73.44%] [G loss: 1.130510]\n",
      "epoch:20 step:19140 [D loss: 0.556747, acc.: 73.44%] [G loss: 1.053981]\n",
      "epoch:20 step:19141 [D loss: 0.516757, acc.: 75.78%] [G loss: 1.368411]\n",
      "epoch:20 step:19142 [D loss: 0.466058, acc.: 82.03%] [G loss: 1.540854]\n",
      "epoch:20 step:19143 [D loss: 0.626002, acc.: 64.84%] [G loss: 1.150443]\n",
      "epoch:20 step:19144 [D loss: 0.560951, acc.: 69.53%] [G loss: 1.447341]\n",
      "epoch:20 step:19145 [D loss: 0.438664, acc.: 81.25%] [G loss: 1.395263]\n",
      "epoch:20 step:19146 [D loss: 0.556702, acc.: 77.34%] [G loss: 1.421732]\n",
      "epoch:20 step:19147 [D loss: 0.743846, acc.: 53.91%] [G loss: 1.135228]\n",
      "epoch:20 step:19148 [D loss: 0.487092, acc.: 75.78%] [G loss: 1.177655]\n",
      "epoch:20 step:19149 [D loss: 0.629492, acc.: 66.41%] [G loss: 1.411104]\n",
      "epoch:20 step:19150 [D loss: 0.588407, acc.: 66.41%] [G loss: 1.207447]\n",
      "epoch:20 step:19151 [D loss: 0.501857, acc.: 76.56%] [G loss: 1.361300]\n",
      "epoch:20 step:19152 [D loss: 0.575578, acc.: 71.09%] [G loss: 1.357440]\n",
      "epoch:20 step:19153 [D loss: 0.600583, acc.: 68.75%] [G loss: 1.326638]\n",
      "epoch:20 step:19154 [D loss: 0.723093, acc.: 57.03%] [G loss: 0.972617]\n",
      "epoch:20 step:19155 [D loss: 0.578827, acc.: 69.53%] [G loss: 1.208491]\n",
      "epoch:20 step:19156 [D loss: 0.566748, acc.: 69.53%] [G loss: 1.460439]\n",
      "epoch:20 step:19157 [D loss: 0.622370, acc.: 69.53%] [G loss: 1.484079]\n",
      "epoch:20 step:19158 [D loss: 0.601660, acc.: 65.62%] [G loss: 1.068102]\n",
      "epoch:20 step:19159 [D loss: 0.524848, acc.: 75.78%] [G loss: 1.421240]\n",
      "epoch:20 step:19160 [D loss: 0.615762, acc.: 67.19%] [G loss: 1.137134]\n",
      "epoch:20 step:19161 [D loss: 0.660629, acc.: 64.06%] [G loss: 1.085840]\n",
      "epoch:20 step:19162 [D loss: 0.504027, acc.: 77.34%] [G loss: 1.191485]\n",
      "epoch:20 step:19163 [D loss: 0.438343, acc.: 85.94%] [G loss: 1.362131]\n",
      "epoch:20 step:19164 [D loss: 0.506706, acc.: 83.59%] [G loss: 1.302665]\n",
      "epoch:20 step:19165 [D loss: 0.551330, acc.: 71.88%] [G loss: 1.327684]\n",
      "epoch:20 step:19166 [D loss: 0.493287, acc.: 77.34%] [G loss: 1.231686]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:20 step:19167 [D loss: 0.690925, acc.: 60.16%] [G loss: 1.270323]\n",
      "epoch:20 step:19168 [D loss: 0.510856, acc.: 72.66%] [G loss: 1.305321]\n",
      "epoch:20 step:19169 [D loss: 0.547198, acc.: 74.22%] [G loss: 1.412233]\n",
      "epoch:20 step:19170 [D loss: 0.443366, acc.: 82.03%] [G loss: 1.329683]\n",
      "epoch:20 step:19171 [D loss: 0.600340, acc.: 62.50%] [G loss: 1.492727]\n",
      "epoch:20 step:19172 [D loss: 0.572970, acc.: 69.53%] [G loss: 1.205239]\n",
      "epoch:20 step:19173 [D loss: 0.536899, acc.: 74.22%] [G loss: 1.121593]\n",
      "epoch:20 step:19174 [D loss: 0.491041, acc.: 81.25%] [G loss: 1.311714]\n",
      "epoch:20 step:19175 [D loss: 0.528223, acc.: 76.56%] [G loss: 1.109818]\n",
      "epoch:20 step:19176 [D loss: 0.537839, acc.: 75.78%] [G loss: 1.556660]\n",
      "epoch:20 step:19177 [D loss: 0.553281, acc.: 74.22%] [G loss: 1.436867]\n",
      "epoch:20 step:19178 [D loss: 0.633076, acc.: 66.41%] [G loss: 1.223033]\n",
      "epoch:20 step:19179 [D loss: 0.636577, acc.: 61.72%] [G loss: 1.400185]\n",
      "epoch:20 step:19180 [D loss: 0.663206, acc.: 59.38%] [G loss: 1.207306]\n",
      "epoch:20 step:19181 [D loss: 0.433034, acc.: 82.81%] [G loss: 1.469441]\n",
      "epoch:20 step:19182 [D loss: 0.737825, acc.: 50.00%] [G loss: 1.334563]\n",
      "epoch:20 step:19183 [D loss: 0.501554, acc.: 74.22%] [G loss: 1.427873]\n",
      "epoch:20 step:19184 [D loss: 0.514003, acc.: 75.00%] [G loss: 1.237390]\n",
      "epoch:20 step:19185 [D loss: 0.442448, acc.: 79.69%] [G loss: 1.417998]\n",
      "epoch:20 step:19186 [D loss: 0.687922, acc.: 60.16%] [G loss: 1.174376]\n",
      "epoch:20 step:19187 [D loss: 0.605755, acc.: 67.97%] [G loss: 1.272142]\n",
      "epoch:20 step:19188 [D loss: 0.655465, acc.: 59.38%] [G loss: 1.003529]\n",
      "epoch:20 step:19189 [D loss: 0.564766, acc.: 69.53%] [G loss: 1.347312]\n",
      "epoch:20 step:19190 [D loss: 0.532815, acc.: 70.31%] [G loss: 1.427825]\n",
      "epoch:20 step:19191 [D loss: 0.473295, acc.: 77.34%] [G loss: 1.348340]\n",
      "epoch:20 step:19192 [D loss: 0.600152, acc.: 63.28%] [G loss: 1.320639]\n",
      "epoch:20 step:19193 [D loss: 0.568429, acc.: 69.53%] [G loss: 1.805628]\n",
      "epoch:20 step:19194 [D loss: 0.581673, acc.: 67.19%] [G loss: 1.271870]\n",
      "epoch:20 step:19195 [D loss: 0.519761, acc.: 74.22%] [G loss: 0.932875]\n",
      "epoch:20 step:19196 [D loss: 0.567416, acc.: 71.09%] [G loss: 1.264656]\n",
      "epoch:20 step:19197 [D loss: 0.695330, acc.: 60.16%] [G loss: 1.183308]\n",
      "epoch:20 step:19198 [D loss: 0.469154, acc.: 84.38%] [G loss: 1.301222]\n",
      "epoch:20 step:19199 [D loss: 0.605930, acc.: 64.06%] [G loss: 1.635438]\n",
      "epoch:20 step:19200 [D loss: 0.490715, acc.: 78.12%] [G loss: 1.345104]\n",
      "epoch:20 step:19201 [D loss: 0.860554, acc.: 44.53%] [G loss: 1.156014]\n",
      "epoch:20 step:19202 [D loss: 0.527702, acc.: 73.44%] [G loss: 1.178861]\n",
      "epoch:20 step:19203 [D loss: 0.617496, acc.: 66.41%] [G loss: 0.951965]\n",
      "epoch:20 step:19204 [D loss: 0.589519, acc.: 67.19%] [G loss: 1.293982]\n",
      "epoch:20 step:19205 [D loss: 0.713436, acc.: 51.56%] [G loss: 1.511529]\n",
      "epoch:20 step:19206 [D loss: 0.688632, acc.: 62.50%] [G loss: 1.155042]\n",
      "epoch:20 step:19207 [D loss: 0.533584, acc.: 73.44%] [G loss: 1.356580]\n",
      "epoch:20 step:19208 [D loss: 0.414624, acc.: 83.59%] [G loss: 1.669239]\n",
      "epoch:20 step:19209 [D loss: 0.572962, acc.: 70.31%] [G loss: 1.472218]\n",
      "epoch:20 step:19210 [D loss: 0.575129, acc.: 71.88%] [G loss: 1.201369]\n",
      "epoch:20 step:19211 [D loss: 0.564695, acc.: 72.66%] [G loss: 1.202294]\n",
      "epoch:20 step:19212 [D loss: 0.515463, acc.: 72.66%] [G loss: 1.332993]\n",
      "epoch:20 step:19213 [D loss: 0.577178, acc.: 72.66%] [G loss: 1.273992]\n",
      "epoch:20 step:19214 [D loss: 0.588645, acc.: 71.09%] [G loss: 1.159881]\n",
      "epoch:20 step:19215 [D loss: 0.439898, acc.: 82.03%] [G loss: 1.846845]\n",
      "epoch:20 step:19216 [D loss: 0.653652, acc.: 58.59%] [G loss: 1.069629]\n",
      "epoch:20 step:19217 [D loss: 0.518888, acc.: 73.44%] [G loss: 1.629039]\n",
      "epoch:20 step:19218 [D loss: 0.536787, acc.: 74.22%] [G loss: 1.385951]\n",
      "epoch:20 step:19219 [D loss: 0.499645, acc.: 75.78%] [G loss: 1.295557]\n",
      "epoch:20 step:19220 [D loss: 0.568992, acc.: 71.09%] [G loss: 1.631212]\n",
      "epoch:20 step:19221 [D loss: 0.759794, acc.: 53.12%] [G loss: 1.033095]\n",
      "epoch:20 step:19222 [D loss: 0.630193, acc.: 64.84%] [G loss: 1.123616]\n",
      "epoch:20 step:19223 [D loss: 0.672813, acc.: 64.06%] [G loss: 1.255245]\n",
      "epoch:20 step:19224 [D loss: 0.509151, acc.: 74.22%] [G loss: 1.151858]\n",
      "epoch:20 step:19225 [D loss: 0.544673, acc.: 69.53%] [G loss: 1.344424]\n",
      "epoch:20 step:19226 [D loss: 0.627387, acc.: 61.72%] [G loss: 1.013189]\n",
      "epoch:20 step:19227 [D loss: 0.417666, acc.: 82.03%] [G loss: 1.507877]\n",
      "epoch:20 step:19228 [D loss: 0.525333, acc.: 73.44%] [G loss: 1.634939]\n",
      "epoch:20 step:19229 [D loss: 0.577692, acc.: 69.53%] [G loss: 1.352328]\n",
      "epoch:20 step:19230 [D loss: 0.580276, acc.: 67.19%] [G loss: 1.289304]\n",
      "epoch:20 step:19231 [D loss: 0.431885, acc.: 80.47%] [G loss: 1.515714]\n",
      "epoch:20 step:19232 [D loss: 0.534763, acc.: 75.00%] [G loss: 1.634932]\n",
      "epoch:20 step:19233 [D loss: 0.466063, acc.: 83.59%] [G loss: 1.267833]\n",
      "epoch:20 step:19234 [D loss: 0.497645, acc.: 75.00%] [G loss: 1.312669]\n",
      "epoch:20 step:19235 [D loss: 0.615672, acc.: 63.28%] [G loss: 1.210394]\n",
      "epoch:20 step:19236 [D loss: 0.567632, acc.: 73.44%] [G loss: 1.456963]\n",
      "epoch:20 step:19237 [D loss: 0.647126, acc.: 62.50%] [G loss: 1.072138]\n",
      "epoch:20 step:19238 [D loss: 0.523874, acc.: 73.44%] [G loss: 1.353456]\n",
      "epoch:20 step:19239 [D loss: 0.580517, acc.: 77.34%] [G loss: 1.169560]\n",
      "epoch:20 step:19240 [D loss: 0.590495, acc.: 72.66%] [G loss: 1.206339]\n",
      "epoch:20 step:19241 [D loss: 0.587076, acc.: 67.19%] [G loss: 1.466012]\n",
      "epoch:20 step:19242 [D loss: 0.562173, acc.: 69.53%] [G loss: 1.242793]\n",
      "epoch:20 step:19243 [D loss: 0.550090, acc.: 75.00%] [G loss: 1.147593]\n",
      "epoch:20 step:19244 [D loss: 0.557346, acc.: 74.22%] [G loss: 1.054198]\n",
      "epoch:20 step:19245 [D loss: 0.542752, acc.: 69.53%] [G loss: 1.272873]\n",
      "epoch:20 step:19246 [D loss: 0.456216, acc.: 78.12%] [G loss: 1.092729]\n",
      "epoch:20 step:19247 [D loss: 0.596491, acc.: 65.62%] [G loss: 1.056942]\n",
      "epoch:20 step:19248 [D loss: 0.572610, acc.: 68.75%] [G loss: 1.428673]\n",
      "epoch:20 step:19249 [D loss: 0.546768, acc.: 71.09%] [G loss: 1.368580]\n",
      "epoch:20 step:19250 [D loss: 0.590385, acc.: 70.31%] [G loss: 1.391592]\n",
      "epoch:20 step:19251 [D loss: 0.691526, acc.: 56.25%] [G loss: 1.060688]\n",
      "epoch:20 step:19252 [D loss: 0.359290, acc.: 88.28%] [G loss: 1.491956]\n",
      "epoch:20 step:19253 [D loss: 0.705943, acc.: 60.94%] [G loss: 1.204389]\n",
      "epoch:20 step:19254 [D loss: 0.697003, acc.: 58.59%] [G loss: 1.286519]\n",
      "epoch:20 step:19255 [D loss: 0.582333, acc.: 70.31%] [G loss: 1.459018]\n",
      "epoch:20 step:19256 [D loss: 0.544083, acc.: 68.75%] [G loss: 1.589686]\n",
      "epoch:20 step:19257 [D loss: 0.436617, acc.: 84.38%] [G loss: 1.278805]\n",
      "epoch:20 step:19258 [D loss: 0.441624, acc.: 78.91%] [G loss: 1.233538]\n",
      "epoch:20 step:19259 [D loss: 0.602141, acc.: 67.19%] [G loss: 1.359651]\n",
      "epoch:20 step:19260 [D loss: 0.578084, acc.: 67.19%] [G loss: 1.192995]\n",
      "epoch:20 step:19261 [D loss: 0.608994, acc.: 65.62%] [G loss: 1.326666]\n",
      "epoch:20 step:19262 [D loss: 0.633860, acc.: 67.19%] [G loss: 1.138410]\n",
      "epoch:20 step:19263 [D loss: 0.523441, acc.: 72.66%] [G loss: 1.106176]\n",
      "epoch:20 step:19264 [D loss: 0.440716, acc.: 78.91%] [G loss: 1.555786]\n",
      "epoch:20 step:19265 [D loss: 0.563236, acc.: 71.09%] [G loss: 1.398848]\n",
      "epoch:20 step:19266 [D loss: 0.631299, acc.: 66.41%] [G loss: 1.070976]\n",
      "epoch:20 step:19267 [D loss: 0.600593, acc.: 67.97%] [G loss: 1.093177]\n",
      "epoch:20 step:19268 [D loss: 0.494713, acc.: 75.78%] [G loss: 1.373867]\n",
      "epoch:20 step:19269 [D loss: 0.562743, acc.: 70.31%] [G loss: 1.083178]\n",
      "epoch:20 step:19270 [D loss: 0.433950, acc.: 81.25%] [G loss: 1.619046]\n",
      "epoch:20 step:19271 [D loss: 0.417827, acc.: 82.81%] [G loss: 1.711524]\n",
      "epoch:20 step:19272 [D loss: 0.652322, acc.: 64.84%] [G loss: 1.310898]\n",
      "epoch:20 step:19273 [D loss: 0.487932, acc.: 78.91%] [G loss: 1.442150]\n",
      "epoch:20 step:19274 [D loss: 0.683776, acc.: 56.25%] [G loss: 1.305480]\n",
      "epoch:20 step:19275 [D loss: 0.578609, acc.: 67.97%] [G loss: 1.284459]\n",
      "epoch:20 step:19276 [D loss: 0.588526, acc.: 73.44%] [G loss: 1.567484]\n",
      "epoch:20 step:19277 [D loss: 0.545960, acc.: 67.97%] [G loss: 1.009290]\n",
      "epoch:20 step:19278 [D loss: 0.551892, acc.: 67.19%] [G loss: 1.243764]\n",
      "epoch:20 step:19279 [D loss: 0.604183, acc.: 62.50%] [G loss: 1.196144]\n",
      "epoch:20 step:19280 [D loss: 0.342105, acc.: 89.84%] [G loss: 1.932913]\n",
      "epoch:20 step:19281 [D loss: 0.433079, acc.: 83.59%] [G loss: 1.781221]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:20 step:19282 [D loss: 0.540033, acc.: 72.66%] [G loss: 1.481788]\n",
      "epoch:20 step:19283 [D loss: 0.589602, acc.: 71.09%] [G loss: 1.063853]\n",
      "epoch:20 step:19284 [D loss: 0.550526, acc.: 78.91%] [G loss: 1.677037]\n",
      "epoch:20 step:19285 [D loss: 0.545546, acc.: 69.53%] [G loss: 1.744785]\n",
      "epoch:20 step:19286 [D loss: 0.495663, acc.: 77.34%] [G loss: 1.240342]\n",
      "epoch:20 step:19287 [D loss: 0.616712, acc.: 69.53%] [G loss: 1.264752]\n",
      "epoch:20 step:19288 [D loss: 0.608595, acc.: 67.19%] [G loss: 1.138397]\n",
      "epoch:20 step:19289 [D loss: 0.651332, acc.: 64.06%] [G loss: 1.006432]\n",
      "epoch:20 step:19290 [D loss: 0.396373, acc.: 85.16%] [G loss: 1.572821]\n",
      "epoch:20 step:19291 [D loss: 0.684194, acc.: 60.94%] [G loss: 1.073516]\n",
      "epoch:20 step:19292 [D loss: 0.480575, acc.: 78.91%] [G loss: 1.384627]\n",
      "epoch:20 step:19293 [D loss: 0.672296, acc.: 60.94%] [G loss: 1.006025]\n",
      "epoch:20 step:19294 [D loss: 0.533357, acc.: 74.22%] [G loss: 1.324215]\n",
      "epoch:20 step:19295 [D loss: 0.413919, acc.: 85.16%] [G loss: 1.453336]\n",
      "epoch:20 step:19296 [D loss: 0.641506, acc.: 67.19%] [G loss: 1.126036]\n",
      "epoch:20 step:19297 [D loss: 0.482264, acc.: 78.12%] [G loss: 1.252771]\n",
      "epoch:20 step:19298 [D loss: 0.575353, acc.: 70.31%] [G loss: 0.919634]\n",
      "epoch:20 step:19299 [D loss: 0.610415, acc.: 69.53%] [G loss: 1.309675]\n",
      "epoch:20 step:19300 [D loss: 0.610572, acc.: 64.84%] [G loss: 1.280269]\n",
      "epoch:20 step:19301 [D loss: 0.650820, acc.: 61.72%] [G loss: 1.523969]\n",
      "epoch:20 step:19302 [D loss: 0.452640, acc.: 80.47%] [G loss: 1.342080]\n",
      "epoch:20 step:19303 [D loss: 0.389660, acc.: 85.94%] [G loss: 1.408994]\n",
      "epoch:20 step:19304 [D loss: 0.531958, acc.: 73.44%] [G loss: 1.405065]\n",
      "epoch:20 step:19305 [D loss: 0.558941, acc.: 69.53%] [G loss: 1.234003]\n",
      "epoch:20 step:19306 [D loss: 0.748412, acc.: 52.34%] [G loss: 1.227405]\n",
      "epoch:20 step:19307 [D loss: 0.618651, acc.: 71.09%] [G loss: 1.438588]\n",
      "epoch:20 step:19308 [D loss: 0.573954, acc.: 69.53%] [G loss: 1.327248]\n",
      "epoch:20 step:19309 [D loss: 0.463815, acc.: 78.91%] [G loss: 1.519378]\n",
      "epoch:20 step:19310 [D loss: 0.640531, acc.: 66.41%] [G loss: 1.428711]\n",
      "epoch:20 step:19311 [D loss: 0.398086, acc.: 84.38%] [G loss: 1.913578]\n",
      "epoch:20 step:19312 [D loss: 0.410086, acc.: 83.59%] [G loss: 1.364877]\n",
      "epoch:20 step:19313 [D loss: 0.484312, acc.: 78.12%] [G loss: 1.492368]\n",
      "epoch:20 step:19314 [D loss: 0.541025, acc.: 73.44%] [G loss: 1.547887]\n",
      "epoch:20 step:19315 [D loss: 0.494545, acc.: 76.56%] [G loss: 1.119475]\n",
      "epoch:20 step:19316 [D loss: 0.522153, acc.: 73.44%] [G loss: 1.719574]\n",
      "epoch:20 step:19317 [D loss: 0.591246, acc.: 66.41%] [G loss: 1.121424]\n",
      "epoch:20 step:19318 [D loss: 0.566104, acc.: 68.75%] [G loss: 1.200669]\n",
      "epoch:20 step:19319 [D loss: 0.529803, acc.: 72.66%] [G loss: 1.457862]\n",
      "epoch:20 step:19320 [D loss: 0.574445, acc.: 71.88%] [G loss: 0.916076]\n",
      "epoch:20 step:19321 [D loss: 0.532621, acc.: 71.09%] [G loss: 1.088467]\n",
      "epoch:20 step:19322 [D loss: 0.666859, acc.: 63.28%] [G loss: 1.041332]\n",
      "epoch:20 step:19323 [D loss: 0.461278, acc.: 82.03%] [G loss: 1.272303]\n",
      "epoch:20 step:19324 [D loss: 0.681412, acc.: 53.91%] [G loss: 1.516822]\n",
      "epoch:20 step:19325 [D loss: 0.580236, acc.: 68.75%] [G loss: 1.440587]\n",
      "epoch:20 step:19326 [D loss: 0.507627, acc.: 78.91%] [G loss: 1.086024]\n",
      "epoch:20 step:19327 [D loss: 0.599303, acc.: 70.31%] [G loss: 1.259433]\n",
      "epoch:20 step:19328 [D loss: 0.692162, acc.: 57.81%] [G loss: 1.084872]\n",
      "epoch:20 step:19329 [D loss: 0.618735, acc.: 68.75%] [G loss: 1.380072]\n",
      "epoch:20 step:19330 [D loss: 0.560069, acc.: 73.44%] [G loss: 1.154294]\n",
      "epoch:20 step:19331 [D loss: 0.567003, acc.: 69.53%] [G loss: 1.050714]\n",
      "epoch:20 step:19332 [D loss: 0.585852, acc.: 71.88%] [G loss: 1.369755]\n",
      "epoch:20 step:19333 [D loss: 0.685578, acc.: 61.72%] [G loss: 1.083884]\n",
      "epoch:20 step:19334 [D loss: 0.580170, acc.: 68.75%] [G loss: 1.357059]\n",
      "epoch:20 step:19335 [D loss: 0.517657, acc.: 75.78%] [G loss: 1.367046]\n",
      "epoch:20 step:19336 [D loss: 0.559088, acc.: 72.66%] [G loss: 1.266506]\n",
      "epoch:20 step:19337 [D loss: 0.627377, acc.: 66.41%] [G loss: 1.096217]\n",
      "epoch:20 step:19338 [D loss: 0.588952, acc.: 67.19%] [G loss: 1.147680]\n",
      "epoch:20 step:19339 [D loss: 0.573653, acc.: 72.66%] [G loss: 1.130693]\n",
      "epoch:20 step:19340 [D loss: 0.502376, acc.: 78.91%] [G loss: 1.247841]\n",
      "epoch:20 step:19341 [D loss: 0.632994, acc.: 60.94%] [G loss: 1.293288]\n",
      "epoch:20 step:19342 [D loss: 0.394279, acc.: 85.94%] [G loss: 1.396108]\n",
      "epoch:20 step:19343 [D loss: 0.631510, acc.: 64.84%] [G loss: 0.986051]\n",
      "epoch:20 step:19344 [D loss: 0.791449, acc.: 53.91%] [G loss: 1.103809]\n",
      "epoch:20 step:19345 [D loss: 0.657895, acc.: 62.50%] [G loss: 1.374547]\n",
      "epoch:20 step:19346 [D loss: 0.573047, acc.: 66.41%] [G loss: 1.543046]\n",
      "epoch:20 step:19347 [D loss: 0.463427, acc.: 80.47%] [G loss: 1.344497]\n",
      "epoch:20 step:19348 [D loss: 0.644468, acc.: 64.06%] [G loss: 1.300849]\n",
      "epoch:20 step:19349 [D loss: 0.504464, acc.: 71.09%] [G loss: 1.280627]\n",
      "epoch:20 step:19350 [D loss: 0.437455, acc.: 80.47%] [G loss: 1.530078]\n",
      "epoch:20 step:19351 [D loss: 0.542351, acc.: 74.22%] [G loss: 1.112594]\n",
      "epoch:20 step:19352 [D loss: 0.501462, acc.: 80.47%] [G loss: 1.452048]\n",
      "epoch:20 step:19353 [D loss: 0.569637, acc.: 67.97%] [G loss: 1.355817]\n",
      "epoch:20 step:19354 [D loss: 0.546124, acc.: 72.66%] [G loss: 1.184638]\n",
      "epoch:20 step:19355 [D loss: 0.498918, acc.: 78.12%] [G loss: 1.351389]\n",
      "epoch:20 step:19356 [D loss: 0.637412, acc.: 65.62%] [G loss: 1.456977]\n",
      "epoch:20 step:19357 [D loss: 0.523103, acc.: 75.00%] [G loss: 1.107893]\n",
      "epoch:20 step:19358 [D loss: 0.515449, acc.: 76.56%] [G loss: 1.433924]\n",
      "epoch:20 step:19359 [D loss: 0.572267, acc.: 68.75%] [G loss: 1.273863]\n",
      "epoch:20 step:19360 [D loss: 0.597653, acc.: 70.31%] [G loss: 1.024079]\n",
      "epoch:20 step:19361 [D loss: 0.562041, acc.: 66.41%] [G loss: 1.288694]\n",
      "epoch:20 step:19362 [D loss: 0.693222, acc.: 53.91%] [G loss: 0.989044]\n",
      "epoch:20 step:19363 [D loss: 0.620030, acc.: 67.97%] [G loss: 1.235811]\n",
      "epoch:20 step:19364 [D loss: 0.677520, acc.: 55.47%] [G loss: 1.021923]\n",
      "epoch:20 step:19365 [D loss: 0.449907, acc.: 78.91%] [G loss: 1.461694]\n",
      "epoch:20 step:19366 [D loss: 0.502922, acc.: 78.12%] [G loss: 1.342812]\n",
      "epoch:20 step:19367 [D loss: 0.389796, acc.: 85.94%] [G loss: 1.505598]\n",
      "epoch:20 step:19368 [D loss: 0.779255, acc.: 51.56%] [G loss: 1.217334]\n",
      "epoch:20 step:19369 [D loss: 0.507810, acc.: 77.34%] [G loss: 1.227628]\n",
      "epoch:20 step:19370 [D loss: 0.477437, acc.: 80.47%] [G loss: 1.203368]\n",
      "epoch:20 step:19371 [D loss: 0.610785, acc.: 68.75%] [G loss: 1.088418]\n",
      "epoch:20 step:19372 [D loss: 0.510205, acc.: 79.69%] [G loss: 1.325617]\n",
      "epoch:20 step:19373 [D loss: 0.641973, acc.: 64.84%] [G loss: 1.438171]\n",
      "epoch:20 step:19374 [D loss: 0.481305, acc.: 82.03%] [G loss: 1.338396]\n",
      "epoch:20 step:19375 [D loss: 0.534790, acc.: 75.78%] [G loss: 1.286291]\n",
      "epoch:20 step:19376 [D loss: 0.577101, acc.: 66.41%] [G loss: 1.354035]\n",
      "epoch:20 step:19377 [D loss: 0.526245, acc.: 75.78%] [G loss: 1.042987]\n",
      "epoch:20 step:19378 [D loss: 0.669834, acc.: 61.72%] [G loss: 1.273375]\n",
      "epoch:20 step:19379 [D loss: 0.634647, acc.: 64.84%] [G loss: 1.468404]\n",
      "epoch:20 step:19380 [D loss: 0.466035, acc.: 81.25%] [G loss: 1.607348]\n",
      "epoch:20 step:19381 [D loss: 0.605408, acc.: 64.84%] [G loss: 1.188402]\n",
      "epoch:20 step:19382 [D loss: 0.448292, acc.: 84.38%] [G loss: 1.290360]\n",
      "epoch:20 step:19383 [D loss: 0.773251, acc.: 45.31%] [G loss: 1.234587]\n",
      "epoch:20 step:19384 [D loss: 0.582063, acc.: 65.62%] [G loss: 1.312137]\n",
      "epoch:20 step:19385 [D loss: 0.401440, acc.: 85.16%] [G loss: 1.369992]\n",
      "epoch:20 step:19386 [D loss: 0.547857, acc.: 69.53%] [G loss: 1.176634]\n",
      "epoch:20 step:19387 [D loss: 0.595453, acc.: 69.53%] [G loss: 1.009145]\n",
      "epoch:20 step:19388 [D loss: 0.443075, acc.: 82.81%] [G loss: 1.249701]\n",
      "epoch:20 step:19389 [D loss: 0.553159, acc.: 71.09%] [G loss: 1.272077]\n",
      "epoch:20 step:19390 [D loss: 0.615031, acc.: 72.66%] [G loss: 1.573390]\n",
      "epoch:20 step:19391 [D loss: 0.510566, acc.: 71.09%] [G loss: 1.457369]\n",
      "epoch:20 step:19392 [D loss: 0.561371, acc.: 72.66%] [G loss: 1.422557]\n",
      "epoch:20 step:19393 [D loss: 0.600012, acc.: 70.31%] [G loss: 1.214946]\n",
      "epoch:20 step:19394 [D loss: 0.601249, acc.: 66.41%] [G loss: 1.131333]\n",
      "epoch:20 step:19395 [D loss: 0.615436, acc.: 59.38%] [G loss: 1.199126]\n",
      "epoch:20 step:19396 [D loss: 0.543175, acc.: 75.00%] [G loss: 1.476291]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:20 step:19397 [D loss: 0.632353, acc.: 67.19%] [G loss: 1.143561]\n",
      "epoch:20 step:19398 [D loss: 0.605179, acc.: 65.62%] [G loss: 1.305396]\n",
      "epoch:20 step:19399 [D loss: 0.447388, acc.: 85.94%] [G loss: 1.242465]\n",
      "epoch:20 step:19400 [D loss: 0.613925, acc.: 67.97%] [G loss: 1.157733]\n",
      "epoch:20 step:19401 [D loss: 0.477313, acc.: 75.00%] [G loss: 1.765205]\n",
      "epoch:20 step:19402 [D loss: 0.752549, acc.: 54.69%] [G loss: 1.004139]\n",
      "epoch:20 step:19403 [D loss: 0.538319, acc.: 73.44%] [G loss: 1.505956]\n",
      "epoch:20 step:19404 [D loss: 0.564154, acc.: 71.88%] [G loss: 1.306924]\n",
      "epoch:20 step:19405 [D loss: 0.573659, acc.: 71.88%] [G loss: 1.237329]\n",
      "epoch:20 step:19406 [D loss: 0.617568, acc.: 63.28%] [G loss: 1.350161]\n",
      "epoch:20 step:19407 [D loss: 0.538711, acc.: 74.22%] [G loss: 1.242237]\n",
      "epoch:20 step:19408 [D loss: 0.558017, acc.: 71.88%] [G loss: 1.614730]\n",
      "epoch:20 step:19409 [D loss: 0.597019, acc.: 71.88%] [G loss: 1.057408]\n",
      "epoch:20 step:19410 [D loss: 0.542646, acc.: 74.22%] [G loss: 1.291201]\n",
      "epoch:20 step:19411 [D loss: 0.640659, acc.: 67.97%] [G loss: 1.190494]\n",
      "epoch:20 step:19412 [D loss: 0.645950, acc.: 61.72%] [G loss: 1.437723]\n",
      "epoch:20 step:19413 [D loss: 0.659995, acc.: 64.06%] [G loss: 1.219403]\n",
      "epoch:20 step:19414 [D loss: 0.378613, acc.: 85.16%] [G loss: 1.428020]\n",
      "epoch:20 step:19415 [D loss: 0.674376, acc.: 64.06%] [G loss: 1.391500]\n",
      "epoch:20 step:19416 [D loss: 0.516142, acc.: 76.56%] [G loss: 1.362804]\n",
      "epoch:20 step:19417 [D loss: 0.552346, acc.: 69.53%] [G loss: 1.382477]\n",
      "epoch:20 step:19418 [D loss: 0.523723, acc.: 77.34%] [G loss: 1.200852]\n",
      "epoch:20 step:19419 [D loss: 0.501287, acc.: 75.78%] [G loss: 1.267251]\n",
      "epoch:20 step:19420 [D loss: 0.629650, acc.: 66.41%] [G loss: 1.338225]\n",
      "epoch:20 step:19421 [D loss: 0.536061, acc.: 78.12%] [G loss: 1.144379]\n",
      "epoch:20 step:19422 [D loss: 0.408594, acc.: 85.16%] [G loss: 1.670327]\n",
      "epoch:20 step:19423 [D loss: 0.652770, acc.: 60.94%] [G loss: 1.336579]\n",
      "epoch:20 step:19424 [D loss: 0.655728, acc.: 63.28%] [G loss: 1.213360]\n",
      "epoch:20 step:19425 [D loss: 0.536609, acc.: 73.44%] [G loss: 1.916852]\n",
      "epoch:20 step:19426 [D loss: 0.570262, acc.: 64.06%] [G loss: 1.753304]\n",
      "epoch:20 step:19427 [D loss: 0.502725, acc.: 78.91%] [G loss: 1.608920]\n",
      "epoch:20 step:19428 [D loss: 0.536213, acc.: 70.31%] [G loss: 1.322594]\n",
      "epoch:20 step:19429 [D loss: 0.655571, acc.: 60.94%] [G loss: 1.395248]\n",
      "epoch:20 step:19430 [D loss: 0.545772, acc.: 78.91%] [G loss: 1.508296]\n",
      "epoch:20 step:19431 [D loss: 0.580649, acc.: 67.19%] [G loss: 1.332963]\n",
      "epoch:20 step:19432 [D loss: 0.580979, acc.: 67.19%] [G loss: 1.280082]\n",
      "epoch:20 step:19433 [D loss: 0.636029, acc.: 61.72%] [G loss: 1.338778]\n",
      "epoch:20 step:19434 [D loss: 0.439592, acc.: 82.81%] [G loss: 1.223213]\n",
      "epoch:20 step:19435 [D loss: 0.500859, acc.: 74.22%] [G loss: 1.366059]\n",
      "epoch:20 step:19436 [D loss: 0.573324, acc.: 72.66%] [G loss: 1.328702]\n",
      "epoch:20 step:19437 [D loss: 0.458934, acc.: 77.34%] [G loss: 1.432538]\n",
      "epoch:20 step:19438 [D loss: 0.436689, acc.: 80.47%] [G loss: 1.295894]\n",
      "epoch:20 step:19439 [D loss: 0.614169, acc.: 69.53%] [G loss: 0.969187]\n",
      "epoch:20 step:19440 [D loss: 0.455416, acc.: 83.59%] [G loss: 1.513298]\n",
      "epoch:20 step:19441 [D loss: 0.410167, acc.: 80.47%] [G loss: 0.928752]\n",
      "epoch:20 step:19442 [D loss: 0.619387, acc.: 64.06%] [G loss: 1.463172]\n",
      "epoch:20 step:19443 [D loss: 0.662665, acc.: 60.16%] [G loss: 1.322098]\n",
      "epoch:20 step:19444 [D loss: 0.706859, acc.: 60.16%] [G loss: 1.282739]\n",
      "epoch:20 step:19445 [D loss: 0.565344, acc.: 70.31%] [G loss: 1.680740]\n",
      "epoch:20 step:19446 [D loss: 0.668909, acc.: 66.41%] [G loss: 1.392288]\n",
      "epoch:20 step:19447 [D loss: 0.468242, acc.: 78.12%] [G loss: 1.579499]\n",
      "epoch:20 step:19448 [D loss: 0.506914, acc.: 74.22%] [G loss: 1.376740]\n",
      "epoch:20 step:19449 [D loss: 0.699936, acc.: 57.03%] [G loss: 1.017070]\n",
      "epoch:20 step:19450 [D loss: 0.408466, acc.: 81.25%] [G loss: 1.265483]\n",
      "epoch:20 step:19451 [D loss: 0.551264, acc.: 75.00%] [G loss: 1.403158]\n",
      "epoch:20 step:19452 [D loss: 0.599578, acc.: 69.53%] [G loss: 1.293633]\n",
      "epoch:20 step:19453 [D loss: 0.575075, acc.: 69.53%] [G loss: 1.445256]\n",
      "epoch:20 step:19454 [D loss: 0.695000, acc.: 53.12%] [G loss: 1.449610]\n",
      "epoch:20 step:19455 [D loss: 0.591299, acc.: 67.97%] [G loss: 0.992406]\n",
      "epoch:20 step:19456 [D loss: 0.605442, acc.: 66.41%] [G loss: 1.183761]\n",
      "epoch:20 step:19457 [D loss: 0.527664, acc.: 70.31%] [G loss: 1.191759]\n",
      "epoch:20 step:19458 [D loss: 0.425658, acc.: 85.16%] [G loss: 1.250336]\n",
      "epoch:20 step:19459 [D loss: 0.669910, acc.: 60.94%] [G loss: 1.258466]\n",
      "epoch:20 step:19460 [D loss: 0.477094, acc.: 78.91%] [G loss: 1.238602]\n",
      "epoch:20 step:19461 [D loss: 0.511212, acc.: 74.22%] [G loss: 1.008155]\n",
      "epoch:20 step:19462 [D loss: 0.674829, acc.: 64.06%] [G loss: 1.088988]\n",
      "epoch:20 step:19463 [D loss: 0.533744, acc.: 76.56%] [G loss: 1.493073]\n",
      "epoch:20 step:19464 [D loss: 0.554920, acc.: 71.09%] [G loss: 1.175050]\n",
      "epoch:20 step:19465 [D loss: 0.588651, acc.: 71.88%] [G loss: 1.334106]\n",
      "epoch:20 step:19466 [D loss: 0.560833, acc.: 75.00%] [G loss: 1.115870]\n",
      "epoch:20 step:19467 [D loss: 0.456268, acc.: 75.78%] [G loss: 1.237108]\n",
      "epoch:20 step:19468 [D loss: 0.678726, acc.: 54.69%] [G loss: 1.013329]\n",
      "epoch:20 step:19469 [D loss: 0.573837, acc.: 68.75%] [G loss: 1.504742]\n",
      "epoch:20 step:19470 [D loss: 0.584059, acc.: 67.19%] [G loss: 1.145827]\n",
      "epoch:20 step:19471 [D loss: 0.604723, acc.: 74.22%] [G loss: 1.059496]\n",
      "epoch:20 step:19472 [D loss: 0.459987, acc.: 79.69%] [G loss: 1.586304]\n",
      "epoch:20 step:19473 [D loss: 0.488979, acc.: 75.78%] [G loss: 1.173344]\n",
      "epoch:20 step:19474 [D loss: 0.530821, acc.: 70.31%] [G loss: 1.189379]\n",
      "epoch:20 step:19475 [D loss: 0.618983, acc.: 64.06%] [G loss: 1.506616]\n",
      "epoch:20 step:19476 [D loss: 0.394428, acc.: 84.38%] [G loss: 1.607663]\n",
      "epoch:20 step:19477 [D loss: 0.684220, acc.: 63.28%] [G loss: 1.061063]\n",
      "epoch:20 step:19478 [D loss: 0.672634, acc.: 63.28%] [G loss: 1.245057]\n",
      "epoch:20 step:19479 [D loss: 0.657938, acc.: 62.50%] [G loss: 1.473726]\n",
      "epoch:20 step:19480 [D loss: 0.509692, acc.: 75.78%] [G loss: 1.157616]\n",
      "epoch:20 step:19481 [D loss: 0.479458, acc.: 79.69%] [G loss: 1.180757]\n",
      "epoch:20 step:19482 [D loss: 0.458948, acc.: 80.47%] [G loss: 1.433124]\n",
      "epoch:20 step:19483 [D loss: 0.688751, acc.: 60.16%] [G loss: 0.849003]\n",
      "epoch:20 step:19484 [D loss: 0.507915, acc.: 74.22%] [G loss: 1.240517]\n",
      "epoch:20 step:19485 [D loss: 0.520277, acc.: 75.00%] [G loss: 1.241871]\n",
      "epoch:20 step:19486 [D loss: 0.589930, acc.: 77.34%] [G loss: 1.314667]\n",
      "epoch:20 step:19487 [D loss: 0.487611, acc.: 79.69%] [G loss: 1.234054]\n",
      "epoch:20 step:19488 [D loss: 0.553446, acc.: 67.97%] [G loss: 1.017859]\n",
      "epoch:20 step:19489 [D loss: 0.683522, acc.: 60.94%] [G loss: 1.316031]\n",
      "epoch:20 step:19490 [D loss: 0.573933, acc.: 73.44%] [G loss: 1.286998]\n",
      "epoch:20 step:19491 [D loss: 0.586197, acc.: 65.62%] [G loss: 0.990166]\n",
      "epoch:20 step:19492 [D loss: 0.632720, acc.: 62.50%] [G loss: 1.362868]\n",
      "epoch:20 step:19493 [D loss: 0.437016, acc.: 82.03%] [G loss: 1.526022]\n",
      "epoch:20 step:19494 [D loss: 0.590772, acc.: 71.88%] [G loss: 1.308583]\n",
      "epoch:20 step:19495 [D loss: 0.424975, acc.: 86.72%] [G loss: 1.374714]\n",
      "epoch:20 step:19496 [D loss: 0.485232, acc.: 77.34%] [G loss: 1.419705]\n",
      "epoch:20 step:19497 [D loss: 0.542551, acc.: 77.34%] [G loss: 1.207423]\n",
      "epoch:20 step:19498 [D loss: 0.471748, acc.: 80.47%] [G loss: 1.383519]\n",
      "epoch:20 step:19499 [D loss: 0.515540, acc.: 75.00%] [G loss: 1.703089]\n",
      "epoch:20 step:19500 [D loss: 0.390883, acc.: 83.59%] [G loss: 1.417134]\n",
      "epoch:20 step:19501 [D loss: 0.683768, acc.: 60.94%] [G loss: 1.427498]\n",
      "epoch:20 step:19502 [D loss: 0.774684, acc.: 51.56%] [G loss: 1.116741]\n",
      "epoch:20 step:19503 [D loss: 0.478197, acc.: 77.34%] [G loss: 1.603171]\n",
      "epoch:20 step:19504 [D loss: 0.576733, acc.: 67.19%] [G loss: 1.204869]\n",
      "epoch:20 step:19505 [D loss: 0.592913, acc.: 67.97%] [G loss: 1.560568]\n",
      "epoch:20 step:19506 [D loss: 0.511924, acc.: 75.78%] [G loss: 1.128488]\n",
      "epoch:20 step:19507 [D loss: 0.431033, acc.: 83.59%] [G loss: 1.676297]\n",
      "epoch:20 step:19508 [D loss: 0.565980, acc.: 73.44%] [G loss: 1.230531]\n",
      "epoch:20 step:19509 [D loss: 0.534606, acc.: 73.44%] [G loss: 1.269030]\n",
      "epoch:20 step:19510 [D loss: 0.622991, acc.: 67.97%] [G loss: 1.342165]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:20 step:19511 [D loss: 0.495404, acc.: 78.12%] [G loss: 1.119769]\n",
      "epoch:20 step:19512 [D loss: 0.609804, acc.: 65.62%] [G loss: 1.042029]\n",
      "epoch:20 step:19513 [D loss: 0.624640, acc.: 67.19%] [G loss: 1.308361]\n",
      "epoch:20 step:19514 [D loss: 0.445052, acc.: 82.03%] [G loss: 1.212347]\n",
      "epoch:20 step:19515 [D loss: 0.617075, acc.: 67.97%] [G loss: 1.521294]\n",
      "epoch:20 step:19516 [D loss: 0.449094, acc.: 78.91%] [G loss: 1.583475]\n",
      "epoch:20 step:19517 [D loss: 0.507152, acc.: 77.34%] [G loss: 1.408296]\n",
      "epoch:20 step:19518 [D loss: 0.580779, acc.: 70.31%] [G loss: 1.211930]\n",
      "epoch:20 step:19519 [D loss: 0.534235, acc.: 75.78%] [G loss: 1.210566]\n",
      "epoch:20 step:19520 [D loss: 0.618070, acc.: 67.97%] [G loss: 1.248357]\n",
      "epoch:20 step:19521 [D loss: 0.569800, acc.: 69.53%] [G loss: 0.996545]\n",
      "epoch:20 step:19522 [D loss: 0.533079, acc.: 73.44%] [G loss: 1.214172]\n",
      "epoch:20 step:19523 [D loss: 0.625586, acc.: 61.72%] [G loss: 1.322585]\n",
      "epoch:20 step:19524 [D loss: 0.652153, acc.: 65.62%] [G loss: 1.319261]\n",
      "epoch:20 step:19525 [D loss: 0.408687, acc.: 86.72%] [G loss: 1.371680]\n",
      "epoch:20 step:19526 [D loss: 0.527396, acc.: 72.66%] [G loss: 1.403537]\n",
      "epoch:20 step:19527 [D loss: 0.635795, acc.: 69.53%] [G loss: 1.160078]\n",
      "epoch:20 step:19528 [D loss: 0.533715, acc.: 72.66%] [G loss: 1.407229]\n",
      "epoch:20 step:19529 [D loss: 0.584265, acc.: 74.22%] [G loss: 1.370508]\n",
      "epoch:20 step:19530 [D loss: 0.635084, acc.: 64.06%] [G loss: 1.492815]\n",
      "epoch:20 step:19531 [D loss: 0.518651, acc.: 71.88%] [G loss: 1.068261]\n",
      "epoch:20 step:19532 [D loss: 0.519951, acc.: 75.00%] [G loss: 1.510604]\n",
      "epoch:20 step:19533 [D loss: 0.578383, acc.: 67.97%] [G loss: 1.226670]\n",
      "epoch:20 step:19534 [D loss: 0.547916, acc.: 71.09%] [G loss: 1.371693]\n",
      "epoch:20 step:19535 [D loss: 0.456789, acc.: 75.78%] [G loss: 1.483876]\n",
      "epoch:20 step:19536 [D loss: 0.535937, acc.: 73.44%] [G loss: 1.249523]\n",
      "epoch:20 step:19537 [D loss: 0.582303, acc.: 67.19%] [G loss: 1.483311]\n",
      "epoch:20 step:19538 [D loss: 0.489243, acc.: 79.69%] [G loss: 1.257668]\n",
      "epoch:20 step:19539 [D loss: 0.479872, acc.: 79.69%] [G loss: 1.207055]\n",
      "epoch:20 step:19540 [D loss: 0.537973, acc.: 75.00%] [G loss: 1.137710]\n",
      "epoch:20 step:19541 [D loss: 0.617670, acc.: 66.41%] [G loss: 1.225554]\n",
      "epoch:20 step:19542 [D loss: 0.571107, acc.: 70.31%] [G loss: 1.191866]\n",
      "epoch:20 step:19543 [D loss: 0.635690, acc.: 67.97%] [G loss: 1.120921]\n",
      "epoch:20 step:19544 [D loss: 0.397370, acc.: 84.38%] [G loss: 1.686814]\n",
      "epoch:20 step:19545 [D loss: 0.549416, acc.: 73.44%] [G loss: 1.554303]\n",
      "epoch:20 step:19546 [D loss: 0.601345, acc.: 67.19%] [G loss: 1.362255]\n",
      "epoch:20 step:19547 [D loss: 0.568400, acc.: 70.31%] [G loss: 1.330003]\n",
      "epoch:20 step:19548 [D loss: 0.575150, acc.: 69.53%] [G loss: 1.371770]\n",
      "epoch:20 step:19549 [D loss: 0.485900, acc.: 78.12%] [G loss: 1.539395]\n",
      "epoch:20 step:19550 [D loss: 0.521404, acc.: 75.78%] [G loss: 1.259962]\n",
      "epoch:20 step:19551 [D loss: 0.445980, acc.: 82.81%] [G loss: 1.165407]\n",
      "epoch:20 step:19552 [D loss: 0.544372, acc.: 71.88%] [G loss: 1.385868]\n",
      "epoch:20 step:19553 [D loss: 0.597876, acc.: 71.88%] [G loss: 1.483737]\n",
      "epoch:20 step:19554 [D loss: 0.548635, acc.: 74.22%] [G loss: 1.206419]\n",
      "epoch:20 step:19555 [D loss: 0.814436, acc.: 50.00%] [G loss: 1.080242]\n",
      "epoch:20 step:19556 [D loss: 0.508499, acc.: 75.78%] [G loss: 1.700548]\n",
      "epoch:20 step:19557 [D loss: 0.744676, acc.: 50.00%] [G loss: 1.351913]\n",
      "epoch:20 step:19558 [D loss: 0.436651, acc.: 79.69%] [G loss: 1.445456]\n",
      "epoch:20 step:19559 [D loss: 0.567369, acc.: 67.19%] [G loss: 1.132096]\n",
      "epoch:20 step:19560 [D loss: 0.617069, acc.: 66.41%] [G loss: 1.070087]\n",
      "epoch:20 step:19561 [D loss: 0.608839, acc.: 60.16%] [G loss: 1.075906]\n",
      "epoch:20 step:19562 [D loss: 0.563432, acc.: 70.31%] [G loss: 1.507653]\n",
      "epoch:20 step:19563 [D loss: 0.495250, acc.: 80.47%] [G loss: 1.463055]\n",
      "epoch:20 step:19564 [D loss: 0.550439, acc.: 71.09%] [G loss: 1.495998]\n",
      "epoch:20 step:19565 [D loss: 0.532623, acc.: 75.00%] [G loss: 1.528613]\n",
      "epoch:20 step:19566 [D loss: 0.686399, acc.: 64.06%] [G loss: 1.016557]\n",
      "epoch:20 step:19567 [D loss: 0.597135, acc.: 69.53%] [G loss: 1.532064]\n",
      "epoch:20 step:19568 [D loss: 0.631244, acc.: 63.28%] [G loss: 1.547178]\n",
      "epoch:20 step:19569 [D loss: 0.656695, acc.: 62.50%] [G loss: 1.141906]\n",
      "epoch:20 step:19570 [D loss: 0.458715, acc.: 81.25%] [G loss: 1.166152]\n",
      "epoch:20 step:19571 [D loss: 0.648766, acc.: 63.28%] [G loss: 1.309552]\n",
      "epoch:20 step:19572 [D loss: 0.516242, acc.: 75.78%] [G loss: 1.227876]\n",
      "epoch:20 step:19573 [D loss: 0.509876, acc.: 76.56%] [G loss: 1.282266]\n",
      "epoch:20 step:19574 [D loss: 0.571755, acc.: 71.09%] [G loss: 1.377377]\n",
      "epoch:20 step:19575 [D loss: 0.661453, acc.: 60.94%] [G loss: 1.220782]\n",
      "epoch:20 step:19576 [D loss: 0.620100, acc.: 64.06%] [G loss: 1.148783]\n",
      "epoch:20 step:19577 [D loss: 0.792183, acc.: 49.22%] [G loss: 1.194941]\n",
      "epoch:20 step:19578 [D loss: 0.397137, acc.: 83.59%] [G loss: 1.457715]\n",
      "epoch:20 step:19579 [D loss: 0.572761, acc.: 69.53%] [G loss: 1.307095]\n",
      "epoch:20 step:19580 [D loss: 0.645815, acc.: 67.19%] [G loss: 1.247178]\n",
      "epoch:20 step:19581 [D loss: 0.594071, acc.: 64.84%] [G loss: 1.195992]\n",
      "epoch:20 step:19582 [D loss: 0.591319, acc.: 68.75%] [G loss: 1.253363]\n",
      "epoch:20 step:19583 [D loss: 0.553353, acc.: 70.31%] [G loss: 1.001446]\n",
      "epoch:20 step:19584 [D loss: 0.542203, acc.: 73.44%] [G loss: 1.484720]\n",
      "epoch:20 step:19585 [D loss: 0.530688, acc.: 73.44%] [G loss: 1.257722]\n",
      "epoch:20 step:19586 [D loss: 0.526369, acc.: 72.66%] [G loss: 1.355067]\n",
      "epoch:20 step:19587 [D loss: 0.435481, acc.: 83.59%] [G loss: 1.333986]\n",
      "epoch:20 step:19588 [D loss: 0.508958, acc.: 78.12%] [G loss: 1.180028]\n",
      "epoch:20 step:19589 [D loss: 0.435906, acc.: 82.03%] [G loss: 1.395414]\n",
      "epoch:20 step:19590 [D loss: 0.504557, acc.: 78.12%] [G loss: 1.313272]\n",
      "epoch:20 step:19591 [D loss: 0.551691, acc.: 71.88%] [G loss: 1.418067]\n",
      "epoch:20 step:19592 [D loss: 0.556804, acc.: 75.78%] [G loss: 1.281083]\n",
      "epoch:20 step:19593 [D loss: 0.492763, acc.: 72.66%] [G loss: 1.281369]\n",
      "epoch:20 step:19594 [D loss: 0.562967, acc.: 70.31%] [G loss: 1.286534]\n",
      "epoch:20 step:19595 [D loss: 0.551134, acc.: 75.00%] [G loss: 1.055982]\n",
      "epoch:20 step:19596 [D loss: 0.389976, acc.: 89.06%] [G loss: 1.208753]\n",
      "epoch:20 step:19597 [D loss: 0.477893, acc.: 75.00%] [G loss: 1.373271]\n",
      "epoch:20 step:19598 [D loss: 0.464351, acc.: 83.59%] [G loss: 1.432586]\n",
      "epoch:20 step:19599 [D loss: 0.725004, acc.: 57.03%] [G loss: 1.525778]\n",
      "epoch:20 step:19600 [D loss: 0.540161, acc.: 71.09%] [G loss: 1.110617]\n",
      "epoch:20 step:19601 [D loss: 0.627681, acc.: 63.28%] [G loss: 1.064854]\n",
      "epoch:20 step:19602 [D loss: 0.606981, acc.: 63.28%] [G loss: 1.695353]\n",
      "epoch:20 step:19603 [D loss: 0.588678, acc.: 67.19%] [G loss: 1.340088]\n",
      "epoch:20 step:19604 [D loss: 0.700330, acc.: 63.28%] [G loss: 1.527679]\n",
      "epoch:20 step:19605 [D loss: 0.587192, acc.: 73.44%] [G loss: 1.172528]\n",
      "epoch:20 step:19606 [D loss: 0.501538, acc.: 78.12%] [G loss: 1.252913]\n",
      "epoch:20 step:19607 [D loss: 0.628789, acc.: 65.62%] [G loss: 1.286347]\n",
      "epoch:20 step:19608 [D loss: 0.509177, acc.: 77.34%] [G loss: 0.974182]\n",
      "epoch:20 step:19609 [D loss: 0.378069, acc.: 87.50%] [G loss: 1.377128]\n",
      "epoch:20 step:19610 [D loss: 0.499960, acc.: 78.91%] [G loss: 1.241872]\n",
      "epoch:20 step:19611 [D loss: 0.475296, acc.: 75.78%] [G loss: 1.592933]\n",
      "epoch:20 step:19612 [D loss: 0.644703, acc.: 66.41%] [G loss: 1.057194]\n",
      "epoch:20 step:19613 [D loss: 0.427203, acc.: 78.91%] [G loss: 1.436730]\n",
      "epoch:20 step:19614 [D loss: 0.591352, acc.: 67.19%] [G loss: 1.590139]\n",
      "epoch:20 step:19615 [D loss: 0.609381, acc.: 67.97%] [G loss: 1.000094]\n",
      "epoch:20 step:19616 [D loss: 0.672934, acc.: 60.94%] [G loss: 1.055491]\n",
      "epoch:20 step:19617 [D loss: 0.668612, acc.: 64.84%] [G loss: 1.178018]\n",
      "epoch:20 step:19618 [D loss: 0.507328, acc.: 75.00%] [G loss: 1.259693]\n",
      "epoch:20 step:19619 [D loss: 0.609332, acc.: 68.75%] [G loss: 1.447425]\n",
      "epoch:20 step:19620 [D loss: 0.522354, acc.: 74.22%] [G loss: 1.184802]\n",
      "epoch:20 step:19621 [D loss: 0.628821, acc.: 66.41%] [G loss: 0.898754]\n",
      "epoch:20 step:19622 [D loss: 0.506938, acc.: 72.66%] [G loss: 1.425334]\n",
      "epoch:20 step:19623 [D loss: 0.593962, acc.: 73.44%] [G loss: 1.105296]\n",
      "epoch:20 step:19624 [D loss: 0.622834, acc.: 67.19%] [G loss: 1.242630]\n",
      "epoch:20 step:19625 [D loss: 0.417208, acc.: 84.38%] [G loss: 1.291888]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:20 step:19626 [D loss: 0.553655, acc.: 72.66%] [G loss: 1.693169]\n",
      "epoch:20 step:19627 [D loss: 0.577124, acc.: 67.19%] [G loss: 1.445446]\n",
      "epoch:20 step:19628 [D loss: 0.730995, acc.: 55.47%] [G loss: 1.452830]\n",
      "epoch:20 step:19629 [D loss: 0.553214, acc.: 73.44%] [G loss: 1.107512]\n",
      "epoch:20 step:19630 [D loss: 0.661570, acc.: 57.03%] [G loss: 0.868930]\n",
      "epoch:20 step:19631 [D loss: 0.581085, acc.: 71.88%] [G loss: 1.563439]\n",
      "epoch:20 step:19632 [D loss: 0.554005, acc.: 75.00%] [G loss: 1.359621]\n",
      "epoch:20 step:19633 [D loss: 0.648504, acc.: 64.06%] [G loss: 1.494993]\n",
      "epoch:20 step:19634 [D loss: 0.565773, acc.: 71.88%] [G loss: 1.337429]\n",
      "epoch:20 step:19635 [D loss: 0.601564, acc.: 68.75%] [G loss: 1.320411]\n",
      "epoch:20 step:19636 [D loss: 0.460336, acc.: 76.56%] [G loss: 1.169480]\n",
      "epoch:20 step:19637 [D loss: 0.632585, acc.: 63.28%] [G loss: 1.155352]\n",
      "epoch:20 step:19638 [D loss: 0.542983, acc.: 73.44%] [G loss: 1.197679]\n",
      "epoch:20 step:19639 [D loss: 0.680484, acc.: 62.50%] [G loss: 1.180254]\n",
      "epoch:20 step:19640 [D loss: 0.585801, acc.: 69.53%] [G loss: 1.196718]\n",
      "epoch:20 step:19641 [D loss: 0.668593, acc.: 57.03%] [G loss: 1.158402]\n",
      "epoch:20 step:19642 [D loss: 0.497596, acc.: 76.56%] [G loss: 1.097037]\n",
      "epoch:20 step:19643 [D loss: 0.477441, acc.: 75.78%] [G loss: 1.428462]\n",
      "epoch:20 step:19644 [D loss: 0.536141, acc.: 71.88%] [G loss: 1.485226]\n",
      "epoch:20 step:19645 [D loss: 0.575786, acc.: 74.22%] [G loss: 1.256172]\n",
      "epoch:20 step:19646 [D loss: 0.624442, acc.: 65.62%] [G loss: 1.130307]\n",
      "epoch:20 step:19647 [D loss: 0.603956, acc.: 67.97%] [G loss: 1.418591]\n",
      "epoch:20 step:19648 [D loss: 0.609805, acc.: 69.53%] [G loss: 1.080785]\n",
      "epoch:20 step:19649 [D loss: 0.532914, acc.: 75.78%] [G loss: 1.370686]\n",
      "epoch:20 step:19650 [D loss: 0.633527, acc.: 67.19%] [G loss: 1.233371]\n",
      "epoch:20 step:19651 [D loss: 0.674352, acc.: 59.38%] [G loss: 0.958653]\n",
      "epoch:20 step:19652 [D loss: 0.560310, acc.: 70.31%] [G loss: 1.235469]\n",
      "epoch:20 step:19653 [D loss: 0.523841, acc.: 75.00%] [G loss: 1.495945]\n",
      "epoch:20 step:19654 [D loss: 0.602617, acc.: 65.62%] [G loss: 1.204288]\n",
      "epoch:20 step:19655 [D loss: 0.671978, acc.: 60.94%] [G loss: 1.196518]\n",
      "epoch:20 step:19656 [D loss: 0.614256, acc.: 64.84%] [G loss: 1.520994]\n",
      "epoch:20 step:19657 [D loss: 0.549674, acc.: 71.09%] [G loss: 1.209315]\n",
      "epoch:20 step:19658 [D loss: 0.421098, acc.: 88.28%] [G loss: 1.243937]\n",
      "epoch:20 step:19659 [D loss: 0.697704, acc.: 63.28%] [G loss: 1.289386]\n",
      "epoch:20 step:19660 [D loss: 0.566036, acc.: 71.88%] [G loss: 1.109406]\n",
      "epoch:20 step:19661 [D loss: 0.505571, acc.: 73.44%] [G loss: 1.155394]\n",
      "epoch:20 step:19662 [D loss: 0.544228, acc.: 79.69%] [G loss: 1.312557]\n",
      "epoch:20 step:19663 [D loss: 0.473367, acc.: 78.12%] [G loss: 1.280705]\n",
      "epoch:20 step:19664 [D loss: 0.705576, acc.: 61.72%] [G loss: 1.320818]\n",
      "epoch:20 step:19665 [D loss: 0.473268, acc.: 78.91%] [G loss: 1.173143]\n",
      "epoch:20 step:19666 [D loss: 0.472576, acc.: 78.12%] [G loss: 1.718889]\n",
      "epoch:20 step:19667 [D loss: 0.607881, acc.: 69.53%] [G loss: 1.122749]\n",
      "epoch:20 step:19668 [D loss: 0.512201, acc.: 75.00%] [G loss: 1.323351]\n",
      "epoch:20 step:19669 [D loss: 0.509092, acc.: 78.12%] [G loss: 1.343330]\n",
      "epoch:20 step:19670 [D loss: 0.516188, acc.: 71.88%] [G loss: 1.388839]\n",
      "epoch:20 step:19671 [D loss: 0.558689, acc.: 71.88%] [G loss: 1.577176]\n",
      "epoch:20 step:19672 [D loss: 0.568057, acc.: 72.66%] [G loss: 1.301785]\n",
      "epoch:20 step:19673 [D loss: 0.581470, acc.: 64.06%] [G loss: 1.250001]\n",
      "epoch:20 step:19674 [D loss: 0.596243, acc.: 70.31%] [G loss: 1.306964]\n",
      "epoch:20 step:19675 [D loss: 0.493642, acc.: 79.69%] [G loss: 1.794402]\n",
      "epoch:20 step:19676 [D loss: 0.609208, acc.: 69.53%] [G loss: 1.174361]\n",
      "epoch:20 step:19677 [D loss: 0.603527, acc.: 67.97%] [G loss: 1.200938]\n",
      "epoch:21 step:19678 [D loss: 0.582239, acc.: 67.97%] [G loss: 1.070396]\n",
      "epoch:21 step:19679 [D loss: 0.518095, acc.: 75.00%] [G loss: 1.173311]\n",
      "epoch:21 step:19680 [D loss: 0.533144, acc.: 75.78%] [G loss: 1.289247]\n",
      "epoch:21 step:19681 [D loss: 0.800125, acc.: 53.91%] [G loss: 1.301800]\n",
      "epoch:21 step:19682 [D loss: 0.489120, acc.: 75.00%] [G loss: 1.711527]\n",
      "epoch:21 step:19683 [D loss: 0.719663, acc.: 52.34%] [G loss: 1.014097]\n",
      "epoch:21 step:19684 [D loss: 0.564883, acc.: 67.97%] [G loss: 1.035148]\n",
      "epoch:21 step:19685 [D loss: 0.749089, acc.: 58.59%] [G loss: 1.208173]\n",
      "epoch:21 step:19686 [D loss: 0.553303, acc.: 73.44%] [G loss: 1.325390]\n",
      "epoch:21 step:19687 [D loss: 0.490307, acc.: 81.25%] [G loss: 1.442801]\n",
      "epoch:21 step:19688 [D loss: 0.650444, acc.: 65.62%] [G loss: 1.125278]\n",
      "epoch:21 step:19689 [D loss: 0.490489, acc.: 74.22%] [G loss: 1.402082]\n",
      "epoch:21 step:19690 [D loss: 0.607791, acc.: 67.97%] [G loss: 0.958971]\n",
      "epoch:21 step:19691 [D loss: 0.571089, acc.: 73.44%] [G loss: 1.312411]\n",
      "epoch:21 step:19692 [D loss: 0.483445, acc.: 77.34%] [G loss: 1.377697]\n",
      "epoch:21 step:19693 [D loss: 0.630719, acc.: 67.19%] [G loss: 1.286026]\n",
      "epoch:21 step:19694 [D loss: 0.645203, acc.: 61.72%] [G loss: 1.467953]\n",
      "epoch:21 step:19695 [D loss: 0.482815, acc.: 81.25%] [G loss: 1.704035]\n",
      "epoch:21 step:19696 [D loss: 0.668723, acc.: 68.75%] [G loss: 1.231092]\n",
      "epoch:21 step:19697 [D loss: 0.459655, acc.: 78.12%] [G loss: 1.558837]\n",
      "epoch:21 step:19698 [D loss: 0.548677, acc.: 74.22%] [G loss: 1.309602]\n",
      "epoch:21 step:19699 [D loss: 0.706194, acc.: 54.69%] [G loss: 1.017674]\n",
      "epoch:21 step:19700 [D loss: 0.564682, acc.: 72.66%] [G loss: 1.418571]\n",
      "epoch:21 step:19701 [D loss: 0.510919, acc.: 74.22%] [G loss: 1.445060]\n",
      "epoch:21 step:19702 [D loss: 0.640851, acc.: 64.84%] [G loss: 1.142626]\n",
      "epoch:21 step:19703 [D loss: 0.662103, acc.: 60.94%] [G loss: 1.064319]\n",
      "epoch:21 step:19704 [D loss: 0.425900, acc.: 79.69%] [G loss: 1.619716]\n",
      "epoch:21 step:19705 [D loss: 0.659542, acc.: 64.06%] [G loss: 1.051546]\n",
      "epoch:21 step:19706 [D loss: 0.646271, acc.: 63.28%] [G loss: 1.362447]\n",
      "epoch:21 step:19707 [D loss: 0.567571, acc.: 70.31%] [G loss: 1.262582]\n",
      "epoch:21 step:19708 [D loss: 0.561395, acc.: 71.88%] [G loss: 1.262369]\n",
      "epoch:21 step:19709 [D loss: 0.426975, acc.: 82.03%] [G loss: 1.439538]\n",
      "epoch:21 step:19710 [D loss: 0.692126, acc.: 52.34%] [G loss: 1.026087]\n",
      "epoch:21 step:19711 [D loss: 0.496262, acc.: 79.69%] [G loss: 1.394221]\n",
      "epoch:21 step:19712 [D loss: 0.538233, acc.: 70.31%] [G loss: 1.569206]\n",
      "epoch:21 step:19713 [D loss: 0.561080, acc.: 67.97%] [G loss: 1.326049]\n",
      "epoch:21 step:19714 [D loss: 0.516897, acc.: 76.56%] [G loss: 1.343106]\n",
      "epoch:21 step:19715 [D loss: 0.472477, acc.: 77.34%] [G loss: 1.676035]\n",
      "epoch:21 step:19716 [D loss: 0.523102, acc.: 75.78%] [G loss: 1.408572]\n",
      "epoch:21 step:19717 [D loss: 0.620228, acc.: 62.50%] [G loss: 1.266767]\n",
      "epoch:21 step:19718 [D loss: 0.457808, acc.: 78.91%] [G loss: 1.395264]\n",
      "epoch:21 step:19719 [D loss: 0.590916, acc.: 61.72%] [G loss: 1.546358]\n",
      "epoch:21 step:19720 [D loss: 0.593299, acc.: 70.31%] [G loss: 1.429203]\n",
      "epoch:21 step:19721 [D loss: 0.632386, acc.: 62.50%] [G loss: 1.292254]\n",
      "epoch:21 step:19722 [D loss: 0.432626, acc.: 83.59%] [G loss: 1.326254]\n",
      "epoch:21 step:19723 [D loss: 0.473104, acc.: 84.38%] [G loss: 1.362584]\n",
      "epoch:21 step:19724 [D loss: 0.497523, acc.: 74.22%] [G loss: 1.102009]\n",
      "epoch:21 step:19725 [D loss: 0.596755, acc.: 70.31%] [G loss: 1.044560]\n",
      "epoch:21 step:19726 [D loss: 0.589112, acc.: 64.06%] [G loss: 1.103361]\n",
      "epoch:21 step:19727 [D loss: 0.494116, acc.: 77.34%] [G loss: 1.460878]\n",
      "epoch:21 step:19728 [D loss: 0.629592, acc.: 65.62%] [G loss: 1.380281]\n",
      "epoch:21 step:19729 [D loss: 0.570373, acc.: 73.44%] [G loss: 1.240677]\n",
      "epoch:21 step:19730 [D loss: 0.624723, acc.: 65.62%] [G loss: 1.280450]\n",
      "epoch:21 step:19731 [D loss: 0.613766, acc.: 66.41%] [G loss: 1.351008]\n",
      "epoch:21 step:19732 [D loss: 0.533836, acc.: 74.22%] [G loss: 1.198737]\n",
      "epoch:21 step:19733 [D loss: 0.469814, acc.: 76.56%] [G loss: 1.438548]\n",
      "epoch:21 step:19734 [D loss: 0.599042, acc.: 69.53%] [G loss: 1.303101]\n",
      "epoch:21 step:19735 [D loss: 0.562973, acc.: 72.66%] [G loss: 1.213410]\n",
      "epoch:21 step:19736 [D loss: 0.573416, acc.: 71.09%] [G loss: 1.345909]\n",
      "epoch:21 step:19737 [D loss: 0.576196, acc.: 67.97%] [G loss: 1.546540]\n",
      "epoch:21 step:19738 [D loss: 0.592993, acc.: 61.72%] [G loss: 1.241483]\n",
      "epoch:21 step:19739 [D loss: 0.570154, acc.: 68.75%] [G loss: 1.086916]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:21 step:19740 [D loss: 0.527269, acc.: 75.00%] [G loss: 1.242303]\n",
      "epoch:21 step:19741 [D loss: 0.660893, acc.: 66.41%] [G loss: 0.847224]\n",
      "epoch:21 step:19742 [D loss: 0.719180, acc.: 57.03%] [G loss: 1.075371]\n",
      "epoch:21 step:19743 [D loss: 0.654075, acc.: 63.28%] [G loss: 1.237248]\n",
      "epoch:21 step:19744 [D loss: 0.522976, acc.: 75.78%] [G loss: 1.400103]\n",
      "epoch:21 step:19745 [D loss: 0.578161, acc.: 69.53%] [G loss: 1.268632]\n",
      "epoch:21 step:19746 [D loss: 0.504885, acc.: 75.78%] [G loss: 1.727395]\n",
      "epoch:21 step:19747 [D loss: 0.592829, acc.: 66.41%] [G loss: 1.214020]\n",
      "epoch:21 step:19748 [D loss: 0.491031, acc.: 78.12%] [G loss: 1.567565]\n",
      "epoch:21 step:19749 [D loss: 0.495030, acc.: 74.22%] [G loss: 1.441235]\n",
      "epoch:21 step:19750 [D loss: 0.524723, acc.: 73.44%] [G loss: 1.445185]\n",
      "epoch:21 step:19751 [D loss: 0.580036, acc.: 68.75%] [G loss: 1.156558]\n",
      "epoch:21 step:19752 [D loss: 0.548045, acc.: 75.00%] [G loss: 2.000181]\n",
      "epoch:21 step:19753 [D loss: 0.556197, acc.: 70.31%] [G loss: 1.181426]\n",
      "epoch:21 step:19754 [D loss: 0.527437, acc.: 78.91%] [G loss: 1.416297]\n",
      "epoch:21 step:19755 [D loss: 0.501990, acc.: 72.66%] [G loss: 1.346915]\n",
      "epoch:21 step:19756 [D loss: 0.531889, acc.: 78.91%] [G loss: 0.846664]\n",
      "epoch:21 step:19757 [D loss: 0.576026, acc.: 71.88%] [G loss: 1.798247]\n",
      "epoch:21 step:19758 [D loss: 0.685899, acc.: 57.03%] [G loss: 1.024439]\n",
      "epoch:21 step:19759 [D loss: 0.450536, acc.: 80.47%] [G loss: 1.563495]\n",
      "epoch:21 step:19760 [D loss: 0.630138, acc.: 62.50%] [G loss: 1.440897]\n",
      "epoch:21 step:19761 [D loss: 0.692954, acc.: 59.38%] [G loss: 1.413397]\n",
      "epoch:21 step:19762 [D loss: 0.484943, acc.: 75.00%] [G loss: 1.374547]\n",
      "epoch:21 step:19763 [D loss: 0.533167, acc.: 70.31%] [G loss: 1.147894]\n",
      "epoch:21 step:19764 [D loss: 0.635353, acc.: 60.94%] [G loss: 1.362113]\n",
      "epoch:21 step:19765 [D loss: 0.577518, acc.: 66.41%] [G loss: 0.973304]\n",
      "epoch:21 step:19766 [D loss: 0.512834, acc.: 74.22%] [G loss: 1.353179]\n",
      "epoch:21 step:19767 [D loss: 0.504596, acc.: 78.12%] [G loss: 1.332090]\n",
      "epoch:21 step:19768 [D loss: 0.688429, acc.: 55.47%] [G loss: 0.908078]\n",
      "epoch:21 step:19769 [D loss: 0.413224, acc.: 86.72%] [G loss: 1.340213]\n",
      "epoch:21 step:19770 [D loss: 0.675963, acc.: 64.06%] [G loss: 1.093575]\n",
      "epoch:21 step:19771 [D loss: 0.524381, acc.: 73.44%] [G loss: 1.264089]\n",
      "epoch:21 step:19772 [D loss: 0.601069, acc.: 68.75%] [G loss: 1.202036]\n",
      "epoch:21 step:19773 [D loss: 0.515715, acc.: 75.00%] [G loss: 1.312987]\n",
      "epoch:21 step:19774 [D loss: 0.668979, acc.: 55.47%] [G loss: 1.238445]\n",
      "epoch:21 step:19775 [D loss: 0.562788, acc.: 71.09%] [G loss: 1.175576]\n",
      "epoch:21 step:19776 [D loss: 0.545123, acc.: 71.88%] [G loss: 1.579159]\n",
      "epoch:21 step:19777 [D loss: 0.399195, acc.: 82.81%] [G loss: 1.769666]\n",
      "epoch:21 step:19778 [D loss: 0.582603, acc.: 73.44%] [G loss: 1.763752]\n",
      "epoch:21 step:19779 [D loss: 0.708660, acc.: 56.25%] [G loss: 1.411150]\n",
      "epoch:21 step:19780 [D loss: 0.535882, acc.: 71.88%] [G loss: 1.075759]\n",
      "epoch:21 step:19781 [D loss: 0.549665, acc.: 73.44%] [G loss: 1.120718]\n",
      "epoch:21 step:19782 [D loss: 0.564301, acc.: 65.62%] [G loss: 1.353134]\n",
      "epoch:21 step:19783 [D loss: 0.603094, acc.: 71.88%] [G loss: 1.614789]\n",
      "epoch:21 step:19784 [D loss: 0.499369, acc.: 77.34%] [G loss: 1.469059]\n",
      "epoch:21 step:19785 [D loss: 0.597521, acc.: 67.19%] [G loss: 1.295421]\n",
      "epoch:21 step:19786 [D loss: 0.564528, acc.: 75.78%] [G loss: 1.268584]\n",
      "epoch:21 step:19787 [D loss: 0.649947, acc.: 57.81%] [G loss: 1.404975]\n",
      "epoch:21 step:19788 [D loss: 0.607777, acc.: 67.97%] [G loss: 1.250539]\n",
      "epoch:21 step:19789 [D loss: 0.513567, acc.: 74.22%] [G loss: 1.247020]\n",
      "epoch:21 step:19790 [D loss: 0.505428, acc.: 77.34%] [G loss: 1.291412]\n",
      "epoch:21 step:19791 [D loss: 0.608389, acc.: 71.88%] [G loss: 1.705097]\n",
      "epoch:21 step:19792 [D loss: 0.394330, acc.: 89.06%] [G loss: 1.570621]\n",
      "epoch:21 step:19793 [D loss: 0.525889, acc.: 72.66%] [G loss: 1.453402]\n",
      "epoch:21 step:19794 [D loss: 0.527705, acc.: 71.88%] [G loss: 1.180355]\n",
      "epoch:21 step:19795 [D loss: 0.600706, acc.: 65.62%] [G loss: 1.599584]\n",
      "epoch:21 step:19796 [D loss: 0.457492, acc.: 78.91%] [G loss: 1.242590]\n",
      "epoch:21 step:19797 [D loss: 0.725588, acc.: 55.47%] [G loss: 1.208674]\n",
      "epoch:21 step:19798 [D loss: 0.573574, acc.: 68.75%] [G loss: 1.383545]\n",
      "epoch:21 step:19799 [D loss: 0.614040, acc.: 61.72%] [G loss: 1.246527]\n",
      "epoch:21 step:19800 [D loss: 0.487559, acc.: 78.12%] [G loss: 1.280865]\n",
      "epoch:21 step:19801 [D loss: 0.527418, acc.: 71.88%] [G loss: 1.247983]\n",
      "epoch:21 step:19802 [D loss: 0.690496, acc.: 58.59%] [G loss: 1.044302]\n",
      "epoch:21 step:19803 [D loss: 0.555220, acc.: 71.88%] [G loss: 1.458637]\n",
      "epoch:21 step:19804 [D loss: 0.642447, acc.: 63.28%] [G loss: 1.429007]\n",
      "epoch:21 step:19805 [D loss: 0.599268, acc.: 70.31%] [G loss: 1.362093]\n",
      "epoch:21 step:19806 [D loss: 0.425972, acc.: 84.38%] [G loss: 1.350819]\n",
      "epoch:21 step:19807 [D loss: 0.617515, acc.: 68.75%] [G loss: 1.249159]\n",
      "epoch:21 step:19808 [D loss: 0.558914, acc.: 71.88%] [G loss: 1.548322]\n",
      "epoch:21 step:19809 [D loss: 0.667337, acc.: 59.38%] [G loss: 0.988805]\n",
      "epoch:21 step:19810 [D loss: 0.440894, acc.: 85.16%] [G loss: 1.442463]\n",
      "epoch:21 step:19811 [D loss: 0.642859, acc.: 60.16%] [G loss: 1.335579]\n",
      "epoch:21 step:19812 [D loss: 0.524928, acc.: 76.56%] [G loss: 1.716805]\n",
      "epoch:21 step:19813 [D loss: 0.793515, acc.: 50.78%] [G loss: 1.373208]\n",
      "epoch:21 step:19814 [D loss: 0.600865, acc.: 65.62%] [G loss: 1.568100]\n",
      "epoch:21 step:19815 [D loss: 0.606730, acc.: 64.84%] [G loss: 1.675103]\n",
      "epoch:21 step:19816 [D loss: 0.725678, acc.: 57.03%] [G loss: 1.295613]\n",
      "epoch:21 step:19817 [D loss: 0.586215, acc.: 67.19%] [G loss: 1.108629]\n",
      "epoch:21 step:19818 [D loss: 0.802555, acc.: 53.12%] [G loss: 1.223457]\n",
      "epoch:21 step:19819 [D loss: 0.434258, acc.: 84.38%] [G loss: 1.394080]\n",
      "epoch:21 step:19820 [D loss: 0.650986, acc.: 67.97%] [G loss: 1.170323]\n",
      "epoch:21 step:19821 [D loss: 0.663510, acc.: 60.16%] [G loss: 1.106803]\n",
      "epoch:21 step:19822 [D loss: 0.625825, acc.: 66.41%] [G loss: 1.257232]\n",
      "epoch:21 step:19823 [D loss: 0.612735, acc.: 67.19%] [G loss: 1.377259]\n",
      "epoch:21 step:19824 [D loss: 0.603949, acc.: 67.97%] [G loss: 1.254084]\n",
      "epoch:21 step:19825 [D loss: 0.466540, acc.: 75.78%] [G loss: 1.575675]\n",
      "epoch:21 step:19826 [D loss: 0.498931, acc.: 78.12%] [G loss: 1.560469]\n",
      "epoch:21 step:19827 [D loss: 0.607222, acc.: 67.97%] [G loss: 1.273540]\n",
      "epoch:21 step:19828 [D loss: 0.461905, acc.: 80.47%] [G loss: 1.073404]\n",
      "epoch:21 step:19829 [D loss: 0.620988, acc.: 66.41%] [G loss: 1.216825]\n",
      "epoch:21 step:19830 [D loss: 0.623984, acc.: 64.84%] [G loss: 0.991978]\n",
      "epoch:21 step:19831 [D loss: 0.547254, acc.: 71.09%] [G loss: 1.280782]\n",
      "epoch:21 step:19832 [D loss: 0.531223, acc.: 70.31%] [G loss: 1.423118]\n",
      "epoch:21 step:19833 [D loss: 0.520734, acc.: 74.22%] [G loss: 1.339237]\n",
      "epoch:21 step:19834 [D loss: 0.497659, acc.: 75.00%] [G loss: 1.194224]\n",
      "epoch:21 step:19835 [D loss: 0.751909, acc.: 52.34%] [G loss: 1.504373]\n",
      "epoch:21 step:19836 [D loss: 0.561394, acc.: 72.66%] [G loss: 1.203709]\n",
      "epoch:21 step:19837 [D loss: 0.466075, acc.: 75.78%] [G loss: 1.268822]\n",
      "epoch:21 step:19838 [D loss: 0.508816, acc.: 76.56%] [G loss: 1.242545]\n",
      "epoch:21 step:19839 [D loss: 0.509506, acc.: 75.78%] [G loss: 1.343186]\n",
      "epoch:21 step:19840 [D loss: 0.614672, acc.: 65.62%] [G loss: 1.291751]\n",
      "epoch:21 step:19841 [D loss: 0.570366, acc.: 72.66%] [G loss: 1.284212]\n",
      "epoch:21 step:19842 [D loss: 0.458668, acc.: 78.12%] [G loss: 1.488269]\n",
      "epoch:21 step:19843 [D loss: 0.589540, acc.: 71.09%] [G loss: 1.368770]\n",
      "epoch:21 step:19844 [D loss: 0.603436, acc.: 64.84%] [G loss: 1.216208]\n",
      "epoch:21 step:19845 [D loss: 0.608856, acc.: 69.53%] [G loss: 1.145258]\n",
      "epoch:21 step:19846 [D loss: 0.494983, acc.: 73.44%] [G loss: 1.587397]\n",
      "epoch:21 step:19847 [D loss: 0.728712, acc.: 54.69%] [G loss: 1.236418]\n",
      "epoch:21 step:19848 [D loss: 0.496801, acc.: 73.44%] [G loss: 1.235199]\n",
      "epoch:21 step:19849 [D loss: 0.516471, acc.: 75.78%] [G loss: 1.387426]\n",
      "epoch:21 step:19850 [D loss: 0.513137, acc.: 72.66%] [G loss: 1.239366]\n",
      "epoch:21 step:19851 [D loss: 0.685328, acc.: 59.38%] [G loss: 1.239811]\n",
      "epoch:21 step:19852 [D loss: 0.493027, acc.: 74.22%] [G loss: 1.405638]\n",
      "epoch:21 step:19853 [D loss: 0.625085, acc.: 67.19%] [G loss: 1.284853]\n",
      "epoch:21 step:19854 [D loss: 0.512348, acc.: 71.09%] [G loss: 1.388941]\n",
      "epoch:21 step:19855 [D loss: 0.509301, acc.: 77.34%] [G loss: 1.548923]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:21 step:19856 [D loss: 0.637147, acc.: 65.62%] [G loss: 1.556577]\n",
      "epoch:21 step:19857 [D loss: 0.431918, acc.: 85.16%] [G loss: 1.541371]\n",
      "epoch:21 step:19858 [D loss: 0.545645, acc.: 71.09%] [G loss: 1.488444]\n",
      "epoch:21 step:19859 [D loss: 0.446014, acc.: 81.25%] [G loss: 1.851350]\n",
      "epoch:21 step:19860 [D loss: 0.524155, acc.: 75.00%] [G loss: 1.627051]\n",
      "epoch:21 step:19861 [D loss: 0.632571, acc.: 62.50%] [G loss: 1.200343]\n",
      "epoch:21 step:19862 [D loss: 0.461347, acc.: 79.69%] [G loss: 1.229949]\n",
      "epoch:21 step:19863 [D loss: 0.600041, acc.: 68.75%] [G loss: 1.190400]\n",
      "epoch:21 step:19864 [D loss: 0.480579, acc.: 78.12%] [G loss: 1.340185]\n",
      "epoch:21 step:19865 [D loss: 0.589332, acc.: 71.88%] [G loss: 1.459084]\n",
      "epoch:21 step:19866 [D loss: 0.605555, acc.: 71.09%] [G loss: 1.348290]\n",
      "epoch:21 step:19867 [D loss: 0.608495, acc.: 71.09%] [G loss: 1.295199]\n",
      "epoch:21 step:19868 [D loss: 0.650385, acc.: 68.75%] [G loss: 1.154647]\n",
      "epoch:21 step:19869 [D loss: 0.514274, acc.: 73.44%] [G loss: 1.323250]\n",
      "epoch:21 step:19870 [D loss: 0.723905, acc.: 60.16%] [G loss: 1.061038]\n",
      "epoch:21 step:19871 [D loss: 0.679392, acc.: 60.94%] [G loss: 1.183702]\n",
      "epoch:21 step:19872 [D loss: 0.584016, acc.: 71.09%] [G loss: 1.400923]\n",
      "epoch:21 step:19873 [D loss: 0.586894, acc.: 66.41%] [G loss: 1.369499]\n",
      "epoch:21 step:19874 [D loss: 0.472588, acc.: 77.34%] [G loss: 1.470760]\n",
      "epoch:21 step:19875 [D loss: 0.534539, acc.: 74.22%] [G loss: 1.519364]\n",
      "epoch:21 step:19876 [D loss: 0.434855, acc.: 81.25%] [G loss: 1.832273]\n",
      "epoch:21 step:19877 [D loss: 0.587339, acc.: 65.62%] [G loss: 1.702925]\n",
      "epoch:21 step:19878 [D loss: 0.475812, acc.: 78.91%] [G loss: 1.250088]\n",
      "epoch:21 step:19879 [D loss: 0.464359, acc.: 78.91%] [G loss: 1.531575]\n",
      "epoch:21 step:19880 [D loss: 0.575719, acc.: 75.00%] [G loss: 1.168774]\n",
      "epoch:21 step:19881 [D loss: 0.510885, acc.: 72.66%] [G loss: 1.299349]\n",
      "epoch:21 step:19882 [D loss: 0.558890, acc.: 71.09%] [G loss: 1.193888]\n",
      "epoch:21 step:19883 [D loss: 0.536343, acc.: 71.09%] [G loss: 0.986234]\n",
      "epoch:21 step:19884 [D loss: 0.611115, acc.: 65.62%] [G loss: 1.203061]\n",
      "epoch:21 step:19885 [D loss: 0.604884, acc.: 67.19%] [G loss: 1.369253]\n",
      "epoch:21 step:19886 [D loss: 0.506349, acc.: 74.22%] [G loss: 1.312406]\n",
      "epoch:21 step:19887 [D loss: 0.572249, acc.: 73.44%] [G loss: 0.817958]\n",
      "epoch:21 step:19888 [D loss: 0.469257, acc.: 82.81%] [G loss: 1.479539]\n",
      "epoch:21 step:19889 [D loss: 0.564970, acc.: 71.09%] [G loss: 1.030713]\n",
      "epoch:21 step:19890 [D loss: 0.498890, acc.: 71.88%] [G loss: 1.322348]\n",
      "epoch:21 step:19891 [D loss: 0.596518, acc.: 65.62%] [G loss: 1.015777]\n",
      "epoch:21 step:19892 [D loss: 0.730220, acc.: 57.81%] [G loss: 1.105840]\n",
      "epoch:21 step:19893 [D loss: 0.471597, acc.: 76.56%] [G loss: 1.213865]\n",
      "epoch:21 step:19894 [D loss: 0.468145, acc.: 79.69%] [G loss: 1.339148]\n",
      "epoch:21 step:19895 [D loss: 0.584888, acc.: 67.97%] [G loss: 1.122245]\n",
      "epoch:21 step:19896 [D loss: 0.461705, acc.: 82.81%] [G loss: 1.444714]\n",
      "epoch:21 step:19897 [D loss: 0.629325, acc.: 63.28%] [G loss: 1.014807]\n",
      "epoch:21 step:19898 [D loss: 0.578195, acc.: 70.31%] [G loss: 1.219173]\n",
      "epoch:21 step:19899 [D loss: 0.592454, acc.: 70.31%] [G loss: 1.077230]\n",
      "epoch:21 step:19900 [D loss: 0.562000, acc.: 75.00%] [G loss: 1.456454]\n",
      "epoch:21 step:19901 [D loss: 0.598512, acc.: 64.06%] [G loss: 0.935220]\n",
      "epoch:21 step:19902 [D loss: 0.444289, acc.: 79.69%] [G loss: 1.464250]\n",
      "epoch:21 step:19903 [D loss: 0.510222, acc.: 74.22%] [G loss: 1.246924]\n",
      "epoch:21 step:19904 [D loss: 0.801700, acc.: 50.00%] [G loss: 1.237515]\n",
      "epoch:21 step:19905 [D loss: 0.574350, acc.: 72.66%] [G loss: 1.575680]\n",
      "epoch:21 step:19906 [D loss: 0.704299, acc.: 61.72%] [G loss: 1.177293]\n",
      "epoch:21 step:19907 [D loss: 0.662764, acc.: 57.03%] [G loss: 1.382343]\n",
      "epoch:21 step:19908 [D loss: 0.532934, acc.: 76.56%] [G loss: 1.466776]\n",
      "epoch:21 step:19909 [D loss: 0.662261, acc.: 62.50%] [G loss: 1.471612]\n",
      "epoch:21 step:19910 [D loss: 0.775035, acc.: 54.69%] [G loss: 1.651593]\n",
      "epoch:21 step:19911 [D loss: 0.500177, acc.: 76.56%] [G loss: 1.505855]\n",
      "epoch:21 step:19912 [D loss: 0.619501, acc.: 67.97%] [G loss: 1.068972]\n",
      "epoch:21 step:19913 [D loss: 0.609985, acc.: 70.31%] [G loss: 1.210001]\n",
      "epoch:21 step:19914 [D loss: 0.700530, acc.: 63.28%] [G loss: 1.233114]\n",
      "epoch:21 step:19915 [D loss: 0.661187, acc.: 61.72%] [G loss: 1.004629]\n",
      "epoch:21 step:19916 [D loss: 0.574876, acc.: 71.09%] [G loss: 1.191849]\n",
      "epoch:21 step:19917 [D loss: 0.614132, acc.: 70.31%] [G loss: 1.094672]\n",
      "epoch:21 step:19918 [D loss: 0.509101, acc.: 75.00%] [G loss: 1.399494]\n",
      "epoch:21 step:19919 [D loss: 0.730046, acc.: 60.16%] [G loss: 1.172219]\n",
      "epoch:21 step:19920 [D loss: 0.549176, acc.: 73.44%] [G loss: 1.236245]\n",
      "epoch:21 step:19921 [D loss: 0.534522, acc.: 68.75%] [G loss: 1.094340]\n",
      "epoch:21 step:19922 [D loss: 0.570154, acc.: 72.66%] [G loss: 1.210452]\n",
      "epoch:21 step:19923 [D loss: 0.472635, acc.: 74.22%] [G loss: 1.524782]\n",
      "epoch:21 step:19924 [D loss: 0.514162, acc.: 69.53%] [G loss: 1.567361]\n",
      "epoch:21 step:19925 [D loss: 0.692277, acc.: 60.16%] [G loss: 1.271497]\n",
      "epoch:21 step:19926 [D loss: 0.470411, acc.: 80.47%] [G loss: 1.419275]\n",
      "epoch:21 step:19927 [D loss: 0.586135, acc.: 64.06%] [G loss: 1.403365]\n",
      "epoch:21 step:19928 [D loss: 0.608426, acc.: 64.84%] [G loss: 1.162727]\n",
      "epoch:21 step:19929 [D loss: 0.538532, acc.: 72.66%] [G loss: 1.587443]\n",
      "epoch:21 step:19930 [D loss: 0.585389, acc.: 68.75%] [G loss: 1.128778]\n",
      "epoch:21 step:19931 [D loss: 0.544543, acc.: 72.66%] [G loss: 1.308933]\n",
      "epoch:21 step:19932 [D loss: 0.570561, acc.: 75.78%] [G loss: 1.336326]\n",
      "epoch:21 step:19933 [D loss: 0.574147, acc.: 73.44%] [G loss: 1.254410]\n",
      "epoch:21 step:19934 [D loss: 0.577272, acc.: 70.31%] [G loss: 1.389223]\n",
      "epoch:21 step:19935 [D loss: 0.571080, acc.: 69.53%] [G loss: 1.183829]\n",
      "epoch:21 step:19936 [D loss: 0.719514, acc.: 60.16%] [G loss: 1.038756]\n",
      "epoch:21 step:19937 [D loss: 0.454819, acc.: 79.69%] [G loss: 1.467457]\n",
      "epoch:21 step:19938 [D loss: 0.799773, acc.: 50.78%] [G loss: 1.090554]\n",
      "epoch:21 step:19939 [D loss: 0.629973, acc.: 65.62%] [G loss: 1.302537]\n",
      "epoch:21 step:19940 [D loss: 0.680511, acc.: 61.72%] [G loss: 1.176858]\n",
      "epoch:21 step:19941 [D loss: 0.440607, acc.: 82.03%] [G loss: 1.556349]\n",
      "epoch:21 step:19942 [D loss: 0.576302, acc.: 71.88%] [G loss: 1.391083]\n",
      "epoch:21 step:19943 [D loss: 0.580735, acc.: 73.44%] [G loss: 1.494923]\n",
      "epoch:21 step:19944 [D loss: 0.596609, acc.: 70.31%] [G loss: 0.976704]\n",
      "epoch:21 step:19945 [D loss: 0.486219, acc.: 80.47%] [G loss: 1.057133]\n",
      "epoch:21 step:19946 [D loss: 0.473837, acc.: 77.34%] [G loss: 1.402374]\n",
      "epoch:21 step:19947 [D loss: 0.467574, acc.: 82.03%] [G loss: 1.497628]\n",
      "epoch:21 step:19948 [D loss: 0.345454, acc.: 89.06%] [G loss: 1.371732]\n",
      "epoch:21 step:19949 [D loss: 0.495729, acc.: 76.56%] [G loss: 1.995728]\n",
      "epoch:21 step:19950 [D loss: 0.613854, acc.: 67.19%] [G loss: 0.892201]\n",
      "epoch:21 step:19951 [D loss: 0.555448, acc.: 66.41%] [G loss: 0.995052]\n",
      "epoch:21 step:19952 [D loss: 0.641700, acc.: 65.62%] [G loss: 1.055571]\n",
      "epoch:21 step:19953 [D loss: 0.716392, acc.: 57.03%] [G loss: 1.002987]\n",
      "epoch:21 step:19954 [D loss: 0.376224, acc.: 86.72%] [G loss: 1.153443]\n",
      "epoch:21 step:19955 [D loss: 0.619348, acc.: 58.59%] [G loss: 1.198675]\n",
      "epoch:21 step:19956 [D loss: 0.631913, acc.: 64.84%] [G loss: 1.246531]\n",
      "epoch:21 step:19957 [D loss: 0.590916, acc.: 71.88%] [G loss: 1.230720]\n",
      "epoch:21 step:19958 [D loss: 0.501789, acc.: 78.12%] [G loss: 1.292533]\n",
      "epoch:21 step:19959 [D loss: 0.572338, acc.: 71.09%] [G loss: 1.243742]\n",
      "epoch:21 step:19960 [D loss: 0.454860, acc.: 78.91%] [G loss: 1.410753]\n",
      "epoch:21 step:19961 [D loss: 0.585505, acc.: 69.53%] [G loss: 1.374742]\n",
      "epoch:21 step:19962 [D loss: 0.540439, acc.: 75.78%] [G loss: 1.041255]\n",
      "epoch:21 step:19963 [D loss: 0.484971, acc.: 75.78%] [G loss: 1.607255]\n",
      "epoch:21 step:19964 [D loss: 0.451942, acc.: 83.59%] [G loss: 1.160779]\n",
      "epoch:21 step:19965 [D loss: 0.524794, acc.: 74.22%] [G loss: 1.437321]\n",
      "epoch:21 step:19966 [D loss: 0.452286, acc.: 80.47%] [G loss: 0.819753]\n",
      "epoch:21 step:19967 [D loss: 0.603548, acc.: 71.88%] [G loss: 1.325607]\n",
      "epoch:21 step:19968 [D loss: 0.507184, acc.: 78.91%] [G loss: 1.247203]\n",
      "epoch:21 step:19969 [D loss: 0.590775, acc.: 71.09%] [G loss: 1.475876]\n",
      "epoch:21 step:19970 [D loss: 0.561408, acc.: 75.00%] [G loss: 1.245268]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:21 step:19971 [D loss: 0.521439, acc.: 73.44%] [G loss: 1.267852]\n",
      "epoch:21 step:19972 [D loss: 0.588923, acc.: 69.53%] [G loss: 1.411288]\n",
      "epoch:21 step:19973 [D loss: 0.539104, acc.: 74.22%] [G loss: 1.366054]\n",
      "epoch:21 step:19974 [D loss: 0.622403, acc.: 64.84%] [G loss: 1.138114]\n",
      "epoch:21 step:19975 [D loss: 0.689098, acc.: 57.81%] [G loss: 1.085456]\n",
      "epoch:21 step:19976 [D loss: 0.594465, acc.: 70.31%] [G loss: 1.013509]\n",
      "epoch:21 step:19977 [D loss: 0.380941, acc.: 84.38%] [G loss: 1.531153]\n",
      "epoch:21 step:19978 [D loss: 0.629606, acc.: 63.28%] [G loss: 1.278422]\n",
      "epoch:21 step:19979 [D loss: 0.445792, acc.: 75.78%] [G loss: 1.322351]\n",
      "epoch:21 step:19980 [D loss: 0.607372, acc.: 71.88%] [G loss: 1.268971]\n",
      "epoch:21 step:19981 [D loss: 0.421506, acc.: 85.16%] [G loss: 1.337728]\n",
      "epoch:21 step:19982 [D loss: 0.599871, acc.: 66.41%] [G loss: 1.459549]\n",
      "epoch:21 step:19983 [D loss: 0.530027, acc.: 74.22%] [G loss: 1.245285]\n",
      "epoch:21 step:19984 [D loss: 0.464883, acc.: 80.47%] [G loss: 1.376822]\n",
      "epoch:21 step:19985 [D loss: 0.493395, acc.: 78.12%] [G loss: 1.377795]\n",
      "epoch:21 step:19986 [D loss: 0.520279, acc.: 76.56%] [G loss: 1.229284]\n",
      "epoch:21 step:19987 [D loss: 0.542154, acc.: 71.09%] [G loss: 1.588223]\n",
      "epoch:21 step:19988 [D loss: 0.484018, acc.: 78.12%] [G loss: 1.443082]\n",
      "epoch:21 step:19989 [D loss: 0.563039, acc.: 71.09%] [G loss: 1.409607]\n",
      "epoch:21 step:19990 [D loss: 0.620945, acc.: 67.97%] [G loss: 1.107248]\n",
      "epoch:21 step:19991 [D loss: 0.475862, acc.: 77.34%] [G loss: 1.219549]\n",
      "epoch:21 step:19992 [D loss: 0.567662, acc.: 72.66%] [G loss: 1.452357]\n",
      "epoch:21 step:19993 [D loss: 0.577924, acc.: 72.66%] [G loss: 1.461325]\n",
      "epoch:21 step:19994 [D loss: 0.566839, acc.: 68.75%] [G loss: 1.085666]\n",
      "epoch:21 step:19995 [D loss: 0.622775, acc.: 67.97%] [G loss: 1.270265]\n",
      "epoch:21 step:19996 [D loss: 0.563144, acc.: 72.66%] [G loss: 1.433818]\n",
      "epoch:21 step:19997 [D loss: 0.715011, acc.: 53.12%] [G loss: 1.080666]\n",
      "epoch:21 step:19998 [D loss: 0.624597, acc.: 66.41%] [G loss: 1.192516]\n",
      "epoch:21 step:19999 [D loss: 0.542583, acc.: 71.09%] [G loss: 1.367728]\n",
      "epoch:21 step:20000 [D loss: 0.572654, acc.: 66.41%] [G loss: 1.357863]\n",
      "epoch:21 step:20001 [D loss: 0.682667, acc.: 60.94%] [G loss: 1.436960]\n",
      "epoch:21 step:20002 [D loss: 0.552295, acc.: 68.75%] [G loss: 0.990851]\n",
      "epoch:21 step:20003 [D loss: 0.632278, acc.: 62.50%] [G loss: 1.420557]\n",
      "epoch:21 step:20004 [D loss: 0.382846, acc.: 88.28%] [G loss: 1.567864]\n",
      "epoch:21 step:20005 [D loss: 0.502402, acc.: 72.66%] [G loss: 1.798051]\n",
      "epoch:21 step:20006 [D loss: 0.684249, acc.: 59.38%] [G loss: 1.426134]\n",
      "epoch:21 step:20007 [D loss: 0.599264, acc.: 67.97%] [G loss: 1.376071]\n",
      "epoch:21 step:20008 [D loss: 0.487246, acc.: 76.56%] [G loss: 1.242772]\n",
      "epoch:21 step:20009 [D loss: 0.638394, acc.: 66.41%] [G loss: 1.314963]\n",
      "epoch:21 step:20010 [D loss: 0.608759, acc.: 64.84%] [G loss: 1.616152]\n",
      "epoch:21 step:20011 [D loss: 0.481313, acc.: 77.34%] [G loss: 1.521610]\n",
      "epoch:21 step:20012 [D loss: 0.600038, acc.: 67.97%] [G loss: 1.051843]\n",
      "epoch:21 step:20013 [D loss: 0.423133, acc.: 82.81%] [G loss: 1.385637]\n",
      "epoch:21 step:20014 [D loss: 0.446348, acc.: 82.03%] [G loss: 1.290357]\n",
      "epoch:21 step:20015 [D loss: 0.424705, acc.: 81.25%] [G loss: 1.525518]\n",
      "epoch:21 step:20016 [D loss: 0.548326, acc.: 74.22%] [G loss: 1.153918]\n",
      "epoch:21 step:20017 [D loss: 0.528297, acc.: 71.88%] [G loss: 0.883107]\n",
      "epoch:21 step:20018 [D loss: 0.551495, acc.: 72.66%] [G loss: 1.238590]\n",
      "epoch:21 step:20019 [D loss: 0.516359, acc.: 76.56%] [G loss: 1.677536]\n",
      "epoch:21 step:20020 [D loss: 0.625775, acc.: 67.19%] [G loss: 1.258813]\n",
      "epoch:21 step:20021 [D loss: 0.603145, acc.: 63.28%] [G loss: 1.086834]\n",
      "epoch:21 step:20022 [D loss: 0.552982, acc.: 71.09%] [G loss: 1.354183]\n",
      "epoch:21 step:20023 [D loss: 0.535736, acc.: 75.00%] [G loss: 1.282876]\n",
      "epoch:21 step:20024 [D loss: 0.756547, acc.: 54.69%] [G loss: 1.300294]\n",
      "epoch:21 step:20025 [D loss: 0.566340, acc.: 67.19%] [G loss: 1.491197]\n",
      "epoch:21 step:20026 [D loss: 0.435137, acc.: 82.03%] [G loss: 1.279840]\n",
      "epoch:21 step:20027 [D loss: 0.527521, acc.: 73.44%] [G loss: 1.229832]\n",
      "epoch:21 step:20028 [D loss: 0.649665, acc.: 65.62%] [G loss: 1.162973]\n",
      "epoch:21 step:20029 [D loss: 0.448016, acc.: 78.91%] [G loss: 1.273188]\n",
      "epoch:21 step:20030 [D loss: 0.455350, acc.: 82.03%] [G loss: 1.498711]\n",
      "epoch:21 step:20031 [D loss: 0.582058, acc.: 67.19%] [G loss: 1.048427]\n",
      "epoch:21 step:20032 [D loss: 0.487779, acc.: 75.00%] [G loss: 1.524549]\n",
      "epoch:21 step:20033 [D loss: 0.509845, acc.: 76.56%] [G loss: 1.296710]\n",
      "epoch:21 step:20034 [D loss: 0.594451, acc.: 70.31%] [G loss: 1.261297]\n",
      "epoch:21 step:20035 [D loss: 0.612339, acc.: 64.06%] [G loss: 1.139566]\n",
      "epoch:21 step:20036 [D loss: 0.613565, acc.: 64.84%] [G loss: 1.459518]\n",
      "epoch:21 step:20037 [D loss: 0.576075, acc.: 71.09%] [G loss: 1.347081]\n",
      "epoch:21 step:20038 [D loss: 0.536819, acc.: 67.97%] [G loss: 1.415483]\n",
      "epoch:21 step:20039 [D loss: 0.459978, acc.: 79.69%] [G loss: 1.490538]\n",
      "epoch:21 step:20040 [D loss: 0.520257, acc.: 77.34%] [G loss: 1.417773]\n",
      "epoch:21 step:20041 [D loss: 0.592581, acc.: 64.84%] [G loss: 1.016757]\n",
      "epoch:21 step:20042 [D loss: 0.734083, acc.: 54.69%] [G loss: 1.109147]\n",
      "epoch:21 step:20043 [D loss: 0.479001, acc.: 82.81%] [G loss: 1.681471]\n",
      "epoch:21 step:20044 [D loss: 0.589034, acc.: 71.09%] [G loss: 1.225973]\n",
      "epoch:21 step:20045 [D loss: 0.606675, acc.: 66.41%] [G loss: 1.176630]\n",
      "epoch:21 step:20046 [D loss: 0.579598, acc.: 67.97%] [G loss: 1.804845]\n",
      "epoch:21 step:20047 [D loss: 0.516106, acc.: 73.44%] [G loss: 1.293221]\n",
      "epoch:21 step:20048 [D loss: 0.542426, acc.: 70.31%] [G loss: 1.499778]\n",
      "epoch:21 step:20049 [D loss: 0.561476, acc.: 66.41%] [G loss: 1.184011]\n",
      "epoch:21 step:20050 [D loss: 0.576183, acc.: 71.09%] [G loss: 1.183825]\n",
      "epoch:21 step:20051 [D loss: 0.663590, acc.: 64.06%] [G loss: 1.347064]\n",
      "epoch:21 step:20052 [D loss: 0.511097, acc.: 75.78%] [G loss: 1.585302]\n",
      "epoch:21 step:20053 [D loss: 0.816249, acc.: 49.22%] [G loss: 0.577277]\n",
      "epoch:21 step:20054 [D loss: 0.491230, acc.: 80.47%] [G loss: 1.401499]\n",
      "epoch:21 step:20055 [D loss: 0.501122, acc.: 76.56%] [G loss: 1.250431]\n",
      "epoch:21 step:20056 [D loss: 0.536584, acc.: 76.56%] [G loss: 1.266719]\n",
      "epoch:21 step:20057 [D loss: 0.453626, acc.: 82.03%] [G loss: 1.573723]\n",
      "epoch:21 step:20058 [D loss: 0.591658, acc.: 67.19%] [G loss: 1.400287]\n",
      "epoch:21 step:20059 [D loss: 0.590530, acc.: 72.66%] [G loss: 1.245148]\n",
      "epoch:21 step:20060 [D loss: 0.448363, acc.: 78.91%] [G loss: 1.396205]\n",
      "epoch:21 step:20061 [D loss: 0.528045, acc.: 75.00%] [G loss: 1.298263]\n",
      "epoch:21 step:20062 [D loss: 0.732305, acc.: 60.16%] [G loss: 1.058431]\n",
      "epoch:21 step:20063 [D loss: 0.585441, acc.: 70.31%] [G loss: 1.554344]\n",
      "epoch:21 step:20064 [D loss: 0.528493, acc.: 69.53%] [G loss: 1.461960]\n",
      "epoch:21 step:20065 [D loss: 0.584831, acc.: 63.28%] [G loss: 1.297996]\n",
      "epoch:21 step:20066 [D loss: 0.653333, acc.: 63.28%] [G loss: 1.146305]\n",
      "epoch:21 step:20067 [D loss: 0.572109, acc.: 67.19%] [G loss: 1.440742]\n",
      "epoch:21 step:20068 [D loss: 0.656557, acc.: 64.84%] [G loss: 1.007661]\n",
      "epoch:21 step:20069 [D loss: 0.475277, acc.: 82.03%] [G loss: 1.154751]\n",
      "epoch:21 step:20070 [D loss: 0.508897, acc.: 78.91%] [G loss: 1.088717]\n",
      "epoch:21 step:20071 [D loss: 0.743805, acc.: 54.69%] [G loss: 1.136552]\n",
      "epoch:21 step:20072 [D loss: 0.480347, acc.: 79.69%] [G loss: 1.196718]\n",
      "epoch:21 step:20073 [D loss: 0.492646, acc.: 78.91%] [G loss: 1.171813]\n",
      "epoch:21 step:20074 [D loss: 0.664294, acc.: 59.38%] [G loss: 1.350172]\n",
      "epoch:21 step:20075 [D loss: 0.530830, acc.: 76.56%] [G loss: 1.275961]\n",
      "epoch:21 step:20076 [D loss: 0.522514, acc.: 71.88%] [G loss: 1.087212]\n",
      "epoch:21 step:20077 [D loss: 0.574717, acc.: 69.53%] [G loss: 1.246571]\n",
      "epoch:21 step:20078 [D loss: 0.581078, acc.: 71.88%] [G loss: 1.450503]\n",
      "epoch:21 step:20079 [D loss: 0.773184, acc.: 53.91%] [G loss: 1.338085]\n",
      "epoch:21 step:20080 [D loss: 0.624969, acc.: 67.97%] [G loss: 1.071422]\n",
      "epoch:21 step:20081 [D loss: 0.632699, acc.: 64.84%] [G loss: 1.229394]\n",
      "epoch:21 step:20082 [D loss: 0.520268, acc.: 74.22%] [G loss: 1.275274]\n",
      "epoch:21 step:20083 [D loss: 0.493879, acc.: 76.56%] [G loss: 1.260602]\n",
      "epoch:21 step:20084 [D loss: 0.675089, acc.: 57.81%] [G loss: 1.432216]\n",
      "epoch:21 step:20085 [D loss: 0.487128, acc.: 73.44%] [G loss: 1.158685]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:21 step:20086 [D loss: 0.586977, acc.: 73.44%] [G loss: 1.454940]\n",
      "epoch:21 step:20087 [D loss: 0.584642, acc.: 63.28%] [G loss: 1.430815]\n",
      "epoch:21 step:20088 [D loss: 0.503362, acc.: 76.56%] [G loss: 1.415286]\n",
      "epoch:21 step:20089 [D loss: 0.695035, acc.: 53.91%] [G loss: 0.972315]\n",
      "epoch:21 step:20090 [D loss: 0.505619, acc.: 75.78%] [G loss: 1.260454]\n",
      "epoch:21 step:20091 [D loss: 0.628859, acc.: 69.53%] [G loss: 1.294065]\n",
      "epoch:21 step:20092 [D loss: 0.454877, acc.: 78.91%] [G loss: 1.266920]\n",
      "epoch:21 step:20093 [D loss: 0.671473, acc.: 60.16%] [G loss: 1.340568]\n",
      "epoch:21 step:20094 [D loss: 0.517001, acc.: 72.66%] [G loss: 1.467452]\n",
      "epoch:21 step:20095 [D loss: 0.551984, acc.: 75.00%] [G loss: 1.119996]\n",
      "epoch:21 step:20096 [D loss: 0.610729, acc.: 67.97%] [G loss: 1.296059]\n",
      "epoch:21 step:20097 [D loss: 0.472807, acc.: 73.44%] [G loss: 1.479768]\n",
      "epoch:21 step:20098 [D loss: 0.621294, acc.: 67.97%] [G loss: 0.967629]\n",
      "epoch:21 step:20099 [D loss: 0.472430, acc.: 81.25%] [G loss: 1.444694]\n",
      "epoch:21 step:20100 [D loss: 0.544334, acc.: 71.09%] [G loss: 1.359188]\n",
      "epoch:21 step:20101 [D loss: 0.549517, acc.: 72.66%] [G loss: 1.564785]\n",
      "epoch:21 step:20102 [D loss: 0.689803, acc.: 57.81%] [G loss: 1.192640]\n",
      "epoch:21 step:20103 [D loss: 0.476107, acc.: 78.12%] [G loss: 1.340557]\n",
      "epoch:21 step:20104 [D loss: 0.775239, acc.: 57.03%] [G loss: 1.271590]\n",
      "epoch:21 step:20105 [D loss: 0.622313, acc.: 64.84%] [G loss: 1.340056]\n",
      "epoch:21 step:20106 [D loss: 0.658260, acc.: 61.72%] [G loss: 1.126768]\n",
      "epoch:21 step:20107 [D loss: 0.558877, acc.: 74.22%] [G loss: 1.316340]\n",
      "epoch:21 step:20108 [D loss: 0.629259, acc.: 58.59%] [G loss: 1.153350]\n",
      "epoch:21 step:20109 [D loss: 0.581529, acc.: 69.53%] [G loss: 1.336198]\n",
      "epoch:21 step:20110 [D loss: 0.660936, acc.: 64.06%] [G loss: 1.230265]\n",
      "epoch:21 step:20111 [D loss: 0.701383, acc.: 63.28%] [G loss: 1.329946]\n",
      "epoch:21 step:20112 [D loss: 0.573657, acc.: 64.06%] [G loss: 1.241594]\n",
      "epoch:21 step:20113 [D loss: 0.633992, acc.: 61.72%] [G loss: 1.010655]\n",
      "epoch:21 step:20114 [D loss: 0.696837, acc.: 59.38%] [G loss: 1.505507]\n",
      "epoch:21 step:20115 [D loss: 0.528278, acc.: 74.22%] [G loss: 1.456301]\n",
      "epoch:21 step:20116 [D loss: 0.539220, acc.: 73.44%] [G loss: 0.967504]\n",
      "epoch:21 step:20117 [D loss: 0.519570, acc.: 77.34%] [G loss: 1.520515]\n",
      "epoch:21 step:20118 [D loss: 0.469613, acc.: 79.69%] [G loss: 1.845988]\n",
      "epoch:21 step:20119 [D loss: 0.580306, acc.: 69.53%] [G loss: 1.404887]\n",
      "epoch:21 step:20120 [D loss: 0.519098, acc.: 77.34%] [G loss: 1.322703]\n",
      "epoch:21 step:20121 [D loss: 0.516901, acc.: 71.88%] [G loss: 1.539062]\n",
      "epoch:21 step:20122 [D loss: 0.588022, acc.: 64.06%] [G loss: 1.203513]\n",
      "epoch:21 step:20123 [D loss: 0.543044, acc.: 72.66%] [G loss: 1.461079]\n",
      "epoch:21 step:20124 [D loss: 0.422843, acc.: 82.81%] [G loss: 1.130596]\n",
      "epoch:21 step:20125 [D loss: 0.695906, acc.: 62.50%] [G loss: 1.230408]\n",
      "epoch:21 step:20126 [D loss: 0.518365, acc.: 76.56%] [G loss: 1.097469]\n",
      "epoch:21 step:20127 [D loss: 0.626132, acc.: 64.84%] [G loss: 1.583872]\n",
      "epoch:21 step:20128 [D loss: 0.423658, acc.: 82.03%] [G loss: 1.664244]\n",
      "epoch:21 step:20129 [D loss: 0.483380, acc.: 78.91%] [G loss: 1.349445]\n",
      "epoch:21 step:20130 [D loss: 0.531574, acc.: 71.88%] [G loss: 1.574030]\n",
      "epoch:21 step:20131 [D loss: 0.490874, acc.: 80.47%] [G loss: 1.404407]\n",
      "epoch:21 step:20132 [D loss: 0.551201, acc.: 73.44%] [G loss: 1.470876]\n",
      "epoch:21 step:20133 [D loss: 0.470403, acc.: 81.25%] [G loss: 1.743037]\n",
      "epoch:21 step:20134 [D loss: 0.719148, acc.: 58.59%] [G loss: 1.304420]\n",
      "epoch:21 step:20135 [D loss: 0.510132, acc.: 77.34%] [G loss: 1.546541]\n",
      "epoch:21 step:20136 [D loss: 0.467743, acc.: 81.25%] [G loss: 1.757423]\n",
      "epoch:21 step:20137 [D loss: 0.547678, acc.: 68.75%] [G loss: 1.380949]\n",
      "epoch:21 step:20138 [D loss: 0.606902, acc.: 65.62%] [G loss: 1.447130]\n",
      "epoch:21 step:20139 [D loss: 0.535645, acc.: 71.09%] [G loss: 1.293689]\n",
      "epoch:21 step:20140 [D loss: 0.661035, acc.: 62.50%] [G loss: 1.584179]\n",
      "epoch:21 step:20141 [D loss: 0.564816, acc.: 72.66%] [G loss: 1.209433]\n",
      "epoch:21 step:20142 [D loss: 0.725072, acc.: 55.47%] [G loss: 1.258705]\n",
      "epoch:21 step:20143 [D loss: 0.587956, acc.: 65.62%] [G loss: 1.246446]\n",
      "epoch:21 step:20144 [D loss: 0.422642, acc.: 84.38%] [G loss: 1.342527]\n",
      "epoch:21 step:20145 [D loss: 0.497600, acc.: 75.00%] [G loss: 1.302663]\n",
      "epoch:21 step:20146 [D loss: 0.540339, acc.: 71.09%] [G loss: 1.342858]\n",
      "epoch:21 step:20147 [D loss: 0.695401, acc.: 62.50%] [G loss: 1.401742]\n",
      "epoch:21 step:20148 [D loss: 0.539814, acc.: 70.31%] [G loss: 1.040501]\n",
      "epoch:21 step:20149 [D loss: 0.558091, acc.: 73.44%] [G loss: 1.138079]\n",
      "epoch:21 step:20150 [D loss: 0.420961, acc.: 80.47%] [G loss: 1.591426]\n",
      "epoch:21 step:20151 [D loss: 0.576699, acc.: 66.41%] [G loss: 1.369005]\n",
      "epoch:21 step:20152 [D loss: 0.421154, acc.: 79.69%] [G loss: 1.406458]\n",
      "epoch:21 step:20153 [D loss: 0.403928, acc.: 87.50%] [G loss: 1.484155]\n",
      "epoch:21 step:20154 [D loss: 0.504824, acc.: 75.78%] [G loss: 1.481645]\n",
      "epoch:21 step:20155 [D loss: 0.461482, acc.: 77.34%] [G loss: 1.411889]\n",
      "epoch:21 step:20156 [D loss: 0.600470, acc.: 67.19%] [G loss: 1.043990]\n",
      "epoch:21 step:20157 [D loss: 0.596681, acc.: 62.50%] [G loss: 1.475547]\n",
      "epoch:21 step:20158 [D loss: 0.672971, acc.: 64.06%] [G loss: 1.449299]\n",
      "epoch:21 step:20159 [D loss: 0.439407, acc.: 82.81%] [G loss: 1.435391]\n",
      "epoch:21 step:20160 [D loss: 0.556570, acc.: 73.44%] [G loss: 1.312942]\n",
      "epoch:21 step:20161 [D loss: 0.556631, acc.: 70.31%] [G loss: 1.554859]\n",
      "epoch:21 step:20162 [D loss: 0.605604, acc.: 70.31%] [G loss: 1.664768]\n",
      "epoch:21 step:20163 [D loss: 0.586505, acc.: 71.09%] [G loss: 1.225591]\n",
      "epoch:21 step:20164 [D loss: 0.491575, acc.: 79.69%] [G loss: 1.351762]\n",
      "epoch:21 step:20165 [D loss: 0.562228, acc.: 67.97%] [G loss: 1.083512]\n",
      "epoch:21 step:20166 [D loss: 0.658683, acc.: 59.38%] [G loss: 1.304107]\n",
      "epoch:21 step:20167 [D loss: 0.408482, acc.: 84.38%] [G loss: 1.319086]\n",
      "epoch:21 step:20168 [D loss: 0.456367, acc.: 80.47%] [G loss: 1.457436]\n",
      "epoch:21 step:20169 [D loss: 0.591643, acc.: 67.19%] [G loss: 1.339468]\n",
      "epoch:21 step:20170 [D loss: 0.598403, acc.: 71.09%] [G loss: 1.339406]\n",
      "epoch:21 step:20171 [D loss: 0.584593, acc.: 72.66%] [G loss: 1.326807]\n",
      "epoch:21 step:20172 [D loss: 0.544523, acc.: 74.22%] [G loss: 1.419775]\n",
      "epoch:21 step:20173 [D loss: 0.591335, acc.: 67.97%] [G loss: 1.591635]\n",
      "epoch:21 step:20174 [D loss: 0.647571, acc.: 58.59%] [G loss: 1.186887]\n",
      "epoch:21 step:20175 [D loss: 0.541714, acc.: 78.12%] [G loss: 1.240750]\n",
      "epoch:21 step:20176 [D loss: 0.485107, acc.: 75.00%] [G loss: 1.315055]\n",
      "epoch:21 step:20177 [D loss: 0.543658, acc.: 78.91%] [G loss: 1.174753]\n",
      "epoch:21 step:20178 [D loss: 0.575543, acc.: 71.88%] [G loss: 1.524588]\n",
      "epoch:21 step:20179 [D loss: 0.609090, acc.: 66.41%] [G loss: 1.579938]\n",
      "epoch:21 step:20180 [D loss: 0.579730, acc.: 72.66%] [G loss: 1.203184]\n",
      "epoch:21 step:20181 [D loss: 0.657227, acc.: 62.50%] [G loss: 1.201160]\n",
      "epoch:21 step:20182 [D loss: 0.473976, acc.: 78.91%] [G loss: 1.572943]\n",
      "epoch:21 step:20183 [D loss: 0.430812, acc.: 84.38%] [G loss: 1.325746]\n",
      "epoch:21 step:20184 [D loss: 0.477001, acc.: 78.91%] [G loss: 1.564177]\n",
      "epoch:21 step:20185 [D loss: 0.478559, acc.: 77.34%] [G loss: 1.096819]\n",
      "epoch:21 step:20186 [D loss: 0.557278, acc.: 73.44%] [G loss: 1.093313]\n",
      "epoch:21 step:20187 [D loss: 0.673354, acc.: 60.94%] [G loss: 1.003495]\n",
      "epoch:21 step:20188 [D loss: 0.443889, acc.: 78.12%] [G loss: 1.342722]\n",
      "epoch:21 step:20189 [D loss: 0.468544, acc.: 82.03%] [G loss: 1.380142]\n",
      "epoch:21 step:20190 [D loss: 0.525999, acc.: 71.09%] [G loss: 1.086682]\n",
      "epoch:21 step:20191 [D loss: 0.502832, acc.: 78.12%] [G loss: 1.145370]\n",
      "epoch:21 step:20192 [D loss: 0.552738, acc.: 72.66%] [G loss: 1.143030]\n",
      "epoch:21 step:20193 [D loss: 0.524240, acc.: 77.34%] [G loss: 1.387067]\n",
      "epoch:21 step:20194 [D loss: 0.638900, acc.: 60.94%] [G loss: 1.678607]\n",
      "epoch:21 step:20195 [D loss: 0.633365, acc.: 63.28%] [G loss: 1.312520]\n",
      "epoch:21 step:20196 [D loss: 0.483533, acc.: 75.00%] [G loss: 1.448640]\n",
      "epoch:21 step:20197 [D loss: 0.499882, acc.: 77.34%] [G loss: 1.144953]\n",
      "epoch:21 step:20198 [D loss: 0.601976, acc.: 67.97%] [G loss: 1.366120]\n",
      "epoch:21 step:20199 [D loss: 0.560988, acc.: 68.75%] [G loss: 0.949419]\n",
      "epoch:21 step:20200 [D loss: 0.598315, acc.: 66.41%] [G loss: 0.899335]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:21 step:20201 [D loss: 0.501220, acc.: 71.09%] [G loss: 1.508070]\n",
      "epoch:21 step:20202 [D loss: 0.508975, acc.: 81.25%] [G loss: 0.914732]\n",
      "epoch:21 step:20203 [D loss: 0.477634, acc.: 78.91%] [G loss: 1.410005]\n",
      "epoch:21 step:20204 [D loss: 0.591141, acc.: 67.97%] [G loss: 1.177161]\n",
      "epoch:21 step:20205 [D loss: 0.568959, acc.: 69.53%] [G loss: 1.178234]\n",
      "epoch:21 step:20206 [D loss: 0.522913, acc.: 72.66%] [G loss: 1.162625]\n",
      "epoch:21 step:20207 [D loss: 0.625984, acc.: 66.41%] [G loss: 1.598696]\n",
      "epoch:21 step:20208 [D loss: 0.453653, acc.: 80.47%] [G loss: 1.702598]\n",
      "epoch:21 step:20209 [D loss: 0.610683, acc.: 67.97%] [G loss: 1.447841]\n",
      "epoch:21 step:20210 [D loss: 0.660754, acc.: 60.94%] [G loss: 1.180476]\n",
      "epoch:21 step:20211 [D loss: 0.568988, acc.: 72.66%] [G loss: 1.248865]\n",
      "epoch:21 step:20212 [D loss: 0.516388, acc.: 75.78%] [G loss: 1.348640]\n",
      "epoch:21 step:20213 [D loss: 0.743269, acc.: 50.78%] [G loss: 1.422405]\n",
      "epoch:21 step:20214 [D loss: 0.665006, acc.: 53.12%] [G loss: 1.194164]\n",
      "epoch:21 step:20215 [D loss: 0.675265, acc.: 63.28%] [G loss: 1.268072]\n",
      "epoch:21 step:20216 [D loss: 0.432204, acc.: 85.94%] [G loss: 1.244149]\n",
      "epoch:21 step:20217 [D loss: 0.532197, acc.: 75.00%] [G loss: 1.621471]\n",
      "epoch:21 step:20218 [D loss: 0.497428, acc.: 75.00%] [G loss: 1.624676]\n",
      "epoch:21 step:20219 [D loss: 0.614073, acc.: 65.62%] [G loss: 1.535150]\n",
      "epoch:21 step:20220 [D loss: 0.575923, acc.: 73.44%] [G loss: 1.215862]\n",
      "epoch:21 step:20221 [D loss: 0.651826, acc.: 64.06%] [G loss: 1.443062]\n",
      "epoch:21 step:20222 [D loss: 0.583652, acc.: 65.62%] [G loss: 1.055585]\n",
      "epoch:21 step:20223 [D loss: 0.427182, acc.: 81.25%] [G loss: 1.418666]\n",
      "epoch:21 step:20224 [D loss: 0.517747, acc.: 76.56%] [G loss: 1.375123]\n",
      "epoch:21 step:20225 [D loss: 0.555696, acc.: 73.44%] [G loss: 1.267773]\n",
      "epoch:21 step:20226 [D loss: 0.527336, acc.: 71.88%] [G loss: 1.146942]\n",
      "epoch:21 step:20227 [D loss: 0.393899, acc.: 88.28%] [G loss: 1.545697]\n",
      "epoch:21 step:20228 [D loss: 0.624725, acc.: 64.06%] [G loss: 1.143765]\n",
      "epoch:21 step:20229 [D loss: 0.486282, acc.: 76.56%] [G loss: 1.314649]\n",
      "epoch:21 step:20230 [D loss: 0.476645, acc.: 81.25%] [G loss: 1.310237]\n",
      "epoch:21 step:20231 [D loss: 0.503869, acc.: 74.22%] [G loss: 1.375599]\n",
      "epoch:21 step:20232 [D loss: 0.615515, acc.: 66.41%] [G loss: 1.181376]\n",
      "epoch:21 step:20233 [D loss: 0.549519, acc.: 68.75%] [G loss: 0.961925]\n",
      "epoch:21 step:20234 [D loss: 0.664185, acc.: 62.50%] [G loss: 1.270035]\n",
      "epoch:21 step:20235 [D loss: 0.701002, acc.: 58.59%] [G loss: 1.129210]\n",
      "epoch:21 step:20236 [D loss: 0.589133, acc.: 65.62%] [G loss: 1.654249]\n",
      "epoch:21 step:20237 [D loss: 0.520455, acc.: 75.78%] [G loss: 1.445989]\n",
      "epoch:21 step:20238 [D loss: 0.632800, acc.: 67.97%] [G loss: 1.377896]\n",
      "epoch:21 step:20239 [D loss: 0.605219, acc.: 68.75%] [G loss: 1.272726]\n",
      "epoch:21 step:20240 [D loss: 0.560141, acc.: 72.66%] [G loss: 1.145767]\n",
      "epoch:21 step:20241 [D loss: 0.516126, acc.: 72.66%] [G loss: 1.210234]\n",
      "epoch:21 step:20242 [D loss: 0.616983, acc.: 66.41%] [G loss: 1.419728]\n",
      "epoch:21 step:20243 [D loss: 0.648488, acc.: 64.84%] [G loss: 1.164901]\n",
      "epoch:21 step:20244 [D loss: 0.522949, acc.: 76.56%] [G loss: 1.557390]\n",
      "epoch:21 step:20245 [D loss: 0.539838, acc.: 75.00%] [G loss: 1.244127]\n",
      "epoch:21 step:20246 [D loss: 0.503437, acc.: 78.91%] [G loss: 1.376318]\n",
      "epoch:21 step:20247 [D loss: 0.666306, acc.: 61.72%] [G loss: 1.344142]\n",
      "epoch:21 step:20248 [D loss: 0.526049, acc.: 77.34%] [G loss: 1.174112]\n",
      "epoch:21 step:20249 [D loss: 0.479253, acc.: 75.78%] [G loss: 1.747021]\n",
      "epoch:21 step:20250 [D loss: 0.662025, acc.: 63.28%] [G loss: 1.458486]\n",
      "epoch:21 step:20251 [D loss: 0.560598, acc.: 74.22%] [G loss: 1.371211]\n",
      "epoch:21 step:20252 [D loss: 0.632343, acc.: 68.75%] [G loss: 1.393604]\n",
      "epoch:21 step:20253 [D loss: 0.467143, acc.: 82.03%] [G loss: 1.223007]\n",
      "epoch:21 step:20254 [D loss: 0.609900, acc.: 71.09%] [G loss: 1.069157]\n",
      "epoch:21 step:20255 [D loss: 0.667814, acc.: 61.72%] [G loss: 1.093290]\n",
      "epoch:21 step:20256 [D loss: 0.548123, acc.: 70.31%] [G loss: 1.096960]\n",
      "epoch:21 step:20257 [D loss: 0.577690, acc.: 67.19%] [G loss: 1.421604]\n",
      "epoch:21 step:20258 [D loss: 0.738762, acc.: 57.03%] [G loss: 1.155484]\n",
      "epoch:21 step:20259 [D loss: 0.566616, acc.: 66.41%] [G loss: 1.564209]\n",
      "epoch:21 step:20260 [D loss: 0.539722, acc.: 71.09%] [G loss: 1.393751]\n",
      "epoch:21 step:20261 [D loss: 0.662982, acc.: 61.72%] [G loss: 1.474571]\n",
      "epoch:21 step:20262 [D loss: 0.459286, acc.: 79.69%] [G loss: 1.788909]\n",
      "epoch:21 step:20263 [D loss: 0.631974, acc.: 64.06%] [G loss: 1.316951]\n",
      "epoch:21 step:20264 [D loss: 0.584894, acc.: 69.53%] [G loss: 1.931621]\n",
      "epoch:21 step:20265 [D loss: 0.477956, acc.: 79.69%] [G loss: 1.744034]\n",
      "epoch:21 step:20266 [D loss: 0.494247, acc.: 74.22%] [G loss: 1.484673]\n",
      "epoch:21 step:20267 [D loss: 0.534293, acc.: 71.88%] [G loss: 1.161316]\n",
      "epoch:21 step:20268 [D loss: 0.548417, acc.: 69.53%] [G loss: 1.174871]\n",
      "epoch:21 step:20269 [D loss: 0.624298, acc.: 64.84%] [G loss: 1.112478]\n",
      "epoch:21 step:20270 [D loss: 0.662963, acc.: 58.59%] [G loss: 1.136561]\n",
      "epoch:21 step:20271 [D loss: 0.466244, acc.: 78.91%] [G loss: 1.376620]\n",
      "epoch:21 step:20272 [D loss: 0.557962, acc.: 72.66%] [G loss: 1.071177]\n",
      "epoch:21 step:20273 [D loss: 0.707038, acc.: 61.72%] [G loss: 1.205696]\n",
      "epoch:21 step:20274 [D loss: 0.544282, acc.: 73.44%] [G loss: 1.315992]\n",
      "epoch:21 step:20275 [D loss: 0.542694, acc.: 71.09%] [G loss: 1.456829]\n",
      "epoch:21 step:20276 [D loss: 0.527089, acc.: 71.88%] [G loss: 1.458096]\n",
      "epoch:21 step:20277 [D loss: 0.515167, acc.: 77.34%] [G loss: 1.447687]\n",
      "epoch:21 step:20278 [D loss: 0.892407, acc.: 40.62%] [G loss: 1.388403]\n",
      "epoch:21 step:20279 [D loss: 0.673825, acc.: 64.06%] [G loss: 1.290852]\n",
      "epoch:21 step:20280 [D loss: 0.556005, acc.: 68.75%] [G loss: 1.129408]\n",
      "epoch:21 step:20281 [D loss: 0.565722, acc.: 64.84%] [G loss: 1.219988]\n",
      "epoch:21 step:20282 [D loss: 0.594442, acc.: 68.75%] [G loss: 1.197442]\n",
      "epoch:21 step:20283 [D loss: 0.555185, acc.: 73.44%] [G loss: 1.277238]\n",
      "epoch:21 step:20284 [D loss: 0.530830, acc.: 71.88%] [G loss: 1.214366]\n",
      "epoch:21 step:20285 [D loss: 0.642596, acc.: 67.97%] [G loss: 1.291755]\n",
      "epoch:21 step:20286 [D loss: 0.563876, acc.: 69.53%] [G loss: 1.430422]\n",
      "epoch:21 step:20287 [D loss: 0.612089, acc.: 67.19%] [G loss: 1.371812]\n",
      "epoch:21 step:20288 [D loss: 0.571358, acc.: 71.09%] [G loss: 1.387301]\n",
      "epoch:21 step:20289 [D loss: 0.585269, acc.: 67.97%] [G loss: 0.968909]\n",
      "epoch:21 step:20290 [D loss: 0.515768, acc.: 78.91%] [G loss: 1.224508]\n",
      "epoch:21 step:20291 [D loss: 0.523306, acc.: 75.00%] [G loss: 1.208229]\n",
      "epoch:21 step:20292 [D loss: 0.585554, acc.: 64.06%] [G loss: 1.417226]\n",
      "epoch:21 step:20293 [D loss: 0.587261, acc.: 71.88%] [G loss: 1.500072]\n",
      "epoch:21 step:20294 [D loss: 0.724576, acc.: 52.34%] [G loss: 1.418468]\n",
      "epoch:21 step:20295 [D loss: 0.650081, acc.: 64.06%] [G loss: 1.073694]\n",
      "epoch:21 step:20296 [D loss: 0.727979, acc.: 53.12%] [G loss: 1.128108]\n",
      "epoch:21 step:20297 [D loss: 0.488052, acc.: 78.91%] [G loss: 1.525080]\n",
      "epoch:21 step:20298 [D loss: 0.586692, acc.: 66.41%] [G loss: 1.074355]\n",
      "epoch:21 step:20299 [D loss: 0.631981, acc.: 63.28%] [G loss: 1.144322]\n",
      "epoch:21 step:20300 [D loss: 0.514902, acc.: 68.75%] [G loss: 1.317033]\n",
      "epoch:21 step:20301 [D loss: 0.649663, acc.: 57.81%] [G loss: 1.154047]\n",
      "epoch:21 step:20302 [D loss: 0.455561, acc.: 77.34%] [G loss: 1.521141]\n",
      "epoch:21 step:20303 [D loss: 0.615072, acc.: 62.50%] [G loss: 1.272294]\n",
      "epoch:21 step:20304 [D loss: 0.457824, acc.: 78.12%] [G loss: 1.587280]\n",
      "epoch:21 step:20305 [D loss: 0.548293, acc.: 74.22%] [G loss: 1.496400]\n",
      "epoch:21 step:20306 [D loss: 0.552976, acc.: 69.53%] [G loss: 1.077837]\n",
      "epoch:21 step:20307 [D loss: 0.645822, acc.: 62.50%] [G loss: 1.275301]\n",
      "epoch:21 step:20308 [D loss: 0.515502, acc.: 75.78%] [G loss: 1.655770]\n",
      "epoch:21 step:20309 [D loss: 0.562861, acc.: 71.09%] [G loss: 1.238526]\n",
      "epoch:21 step:20310 [D loss: 0.509478, acc.: 76.56%] [G loss: 1.970518]\n",
      "epoch:21 step:20311 [D loss: 0.495083, acc.: 75.00%] [G loss: 1.603710]\n",
      "epoch:21 step:20312 [D loss: 0.620306, acc.: 62.50%] [G loss: 1.265120]\n",
      "epoch:21 step:20313 [D loss: 0.480231, acc.: 77.34%] [G loss: 1.371065]\n",
      "epoch:21 step:20314 [D loss: 0.564769, acc.: 70.31%] [G loss: 1.413219]\n",
      "epoch:21 step:20315 [D loss: 0.527175, acc.: 76.56%] [G loss: 1.297710]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:21 step:20316 [D loss: 0.591832, acc.: 71.09%] [G loss: 1.202455]\n",
      "epoch:21 step:20317 [D loss: 0.464716, acc.: 83.59%] [G loss: 1.282503]\n",
      "epoch:21 step:20318 [D loss: 0.469491, acc.: 81.25%] [G loss: 1.455569]\n",
      "epoch:21 step:20319 [D loss: 0.530659, acc.: 71.88%] [G loss: 1.095833]\n",
      "epoch:21 step:20320 [D loss: 0.849617, acc.: 46.09%] [G loss: 1.321219]\n",
      "epoch:21 step:20321 [D loss: 0.558847, acc.: 68.75%] [G loss: 1.487808]\n",
      "epoch:21 step:20322 [D loss: 0.484697, acc.: 81.25%] [G loss: 1.424705]\n",
      "epoch:21 step:20323 [D loss: 0.517947, acc.: 75.78%] [G loss: 1.654349]\n",
      "epoch:21 step:20324 [D loss: 0.688000, acc.: 61.72%] [G loss: 1.248202]\n",
      "epoch:21 step:20325 [D loss: 0.461251, acc.: 82.03%] [G loss: 1.284299]\n",
      "epoch:21 step:20326 [D loss: 0.601834, acc.: 66.41%] [G loss: 1.500379]\n",
      "epoch:21 step:20327 [D loss: 0.583510, acc.: 71.88%] [G loss: 1.312683]\n",
      "epoch:21 step:20328 [D loss: 0.449652, acc.: 78.91%] [G loss: 1.167946]\n",
      "epoch:21 step:20329 [D loss: 0.740589, acc.: 50.78%] [G loss: 1.571932]\n",
      "epoch:21 step:20330 [D loss: 0.683543, acc.: 54.69%] [G loss: 1.476324]\n",
      "epoch:21 step:20331 [D loss: 0.543413, acc.: 67.19%] [G loss: 1.458047]\n",
      "epoch:21 step:20332 [D loss: 0.501987, acc.: 74.22%] [G loss: 1.926981]\n",
      "epoch:21 step:20333 [D loss: 0.449944, acc.: 80.47%] [G loss: 1.241922]\n",
      "epoch:21 step:20334 [D loss: 0.528138, acc.: 75.00%] [G loss: 1.323899]\n",
      "epoch:21 step:20335 [D loss: 0.503915, acc.: 77.34%] [G loss: 1.395518]\n",
      "epoch:21 step:20336 [D loss: 0.671294, acc.: 60.94%] [G loss: 1.314237]\n",
      "epoch:21 step:20337 [D loss: 0.544763, acc.: 73.44%] [G loss: 1.260468]\n",
      "epoch:21 step:20338 [D loss: 0.394656, acc.: 84.38%] [G loss: 1.492882]\n",
      "epoch:21 step:20339 [D loss: 0.652850, acc.: 60.94%] [G loss: 1.153359]\n",
      "epoch:21 step:20340 [D loss: 0.556108, acc.: 70.31%] [G loss: 1.159950]\n",
      "epoch:21 step:20341 [D loss: 0.738826, acc.: 56.25%] [G loss: 1.079739]\n",
      "epoch:21 step:20342 [D loss: 0.479400, acc.: 80.47%] [G loss: 1.234346]\n",
      "epoch:21 step:20343 [D loss: 0.512477, acc.: 72.66%] [G loss: 1.175915]\n",
      "epoch:21 step:20344 [D loss: 0.572094, acc.: 71.88%] [G loss: 1.479491]\n",
      "epoch:21 step:20345 [D loss: 0.601495, acc.: 67.97%] [G loss: 1.355011]\n",
      "epoch:21 step:20346 [D loss: 0.596611, acc.: 69.53%] [G loss: 1.147174]\n",
      "epoch:21 step:20347 [D loss: 0.537781, acc.: 74.22%] [G loss: 1.444734]\n",
      "epoch:21 step:20348 [D loss: 0.595637, acc.: 70.31%] [G loss: 1.456644]\n",
      "epoch:21 step:20349 [D loss: 0.599358, acc.: 67.97%] [G loss: 1.103138]\n",
      "epoch:21 step:20350 [D loss: 0.444535, acc.: 79.69%] [G loss: 1.251814]\n",
      "epoch:21 step:20351 [D loss: 0.541144, acc.: 67.97%] [G loss: 1.150730]\n",
      "epoch:21 step:20352 [D loss: 0.630000, acc.: 61.72%] [G loss: 1.149907]\n",
      "epoch:21 step:20353 [D loss: 0.449566, acc.: 82.03%] [G loss: 1.292656]\n",
      "epoch:21 step:20354 [D loss: 0.542263, acc.: 72.66%] [G loss: 1.251976]\n",
      "epoch:21 step:20355 [D loss: 0.507187, acc.: 74.22%] [G loss: 1.502187]\n",
      "epoch:21 step:20356 [D loss: 0.476478, acc.: 78.91%] [G loss: 1.472094]\n",
      "epoch:21 step:20357 [D loss: 0.670580, acc.: 64.84%] [G loss: 1.204580]\n",
      "epoch:21 step:20358 [D loss: 0.576724, acc.: 71.88%] [G loss: 1.427598]\n",
      "epoch:21 step:20359 [D loss: 0.493173, acc.: 78.91%] [G loss: 1.440985]\n",
      "epoch:21 step:20360 [D loss: 0.607849, acc.: 67.19%] [G loss: 1.630699]\n",
      "epoch:21 step:20361 [D loss: 0.462691, acc.: 79.69%] [G loss: 1.361751]\n",
      "epoch:21 step:20362 [D loss: 0.542411, acc.: 72.66%] [G loss: 1.227662]\n",
      "epoch:21 step:20363 [D loss: 0.475379, acc.: 84.38%] [G loss: 1.042230]\n",
      "epoch:21 step:20364 [D loss: 0.619860, acc.: 67.97%] [G loss: 1.338043]\n",
      "epoch:21 step:20365 [D loss: 0.439961, acc.: 86.72%] [G loss: 1.590499]\n",
      "epoch:21 step:20366 [D loss: 0.622694, acc.: 64.84%] [G loss: 1.174377]\n",
      "epoch:21 step:20367 [D loss: 0.620006, acc.: 64.84%] [G loss: 1.358941]\n",
      "epoch:21 step:20368 [D loss: 0.543737, acc.: 73.44%] [G loss: 1.590275]\n",
      "epoch:21 step:20369 [D loss: 0.569899, acc.: 64.84%] [G loss: 1.361776]\n",
      "epoch:21 step:20370 [D loss: 0.714908, acc.: 58.59%] [G loss: 1.334803]\n",
      "epoch:21 step:20371 [D loss: 0.574116, acc.: 73.44%] [G loss: 1.633939]\n",
      "epoch:21 step:20372 [D loss: 0.633420, acc.: 64.06%] [G loss: 1.323133]\n",
      "epoch:21 step:20373 [D loss: 0.573458, acc.: 67.19%] [G loss: 1.011365]\n",
      "epoch:21 step:20374 [D loss: 0.463514, acc.: 78.91%] [G loss: 1.838273]\n",
      "epoch:21 step:20375 [D loss: 0.684354, acc.: 68.75%] [G loss: 1.268933]\n",
      "epoch:21 step:20376 [D loss: 0.527034, acc.: 72.66%] [G loss: 1.732759]\n",
      "epoch:21 step:20377 [D loss: 0.427380, acc.: 85.16%] [G loss: 1.875032]\n",
      "epoch:21 step:20378 [D loss: 0.561480, acc.: 75.78%] [G loss: 1.349812]\n",
      "epoch:21 step:20379 [D loss: 0.512405, acc.: 75.00%] [G loss: 1.675324]\n",
      "epoch:21 step:20380 [D loss: 0.729148, acc.: 57.03%] [G loss: 1.377497]\n",
      "epoch:21 step:20381 [D loss: 0.623883, acc.: 63.28%] [G loss: 1.127880]\n",
      "epoch:21 step:20382 [D loss: 0.491539, acc.: 78.91%] [G loss: 0.939110]\n",
      "epoch:21 step:20383 [D loss: 0.568311, acc.: 69.53%] [G loss: 1.309306]\n",
      "epoch:21 step:20384 [D loss: 0.513185, acc.: 77.34%] [G loss: 1.274103]\n",
      "epoch:21 step:20385 [D loss: 0.652267, acc.: 64.84%] [G loss: 1.083927]\n",
      "epoch:21 step:20386 [D loss: 0.761345, acc.: 53.91%] [G loss: 1.367551]\n",
      "epoch:21 step:20387 [D loss: 0.693690, acc.: 64.84%] [G loss: 1.094534]\n",
      "epoch:21 step:20388 [D loss: 0.435111, acc.: 79.69%] [G loss: 1.581039]\n",
      "epoch:21 step:20389 [D loss: 0.600300, acc.: 68.75%] [G loss: 1.247238]\n",
      "epoch:21 step:20390 [D loss: 0.601286, acc.: 71.88%] [G loss: 1.385647]\n",
      "epoch:21 step:20391 [D loss: 0.750892, acc.: 57.81%] [G loss: 1.362046]\n",
      "epoch:21 step:20392 [D loss: 0.691927, acc.: 60.16%] [G loss: 1.184780]\n",
      "epoch:21 step:20393 [D loss: 0.616714, acc.: 64.84%] [G loss: 0.973622]\n",
      "epoch:21 step:20394 [D loss: 0.436913, acc.: 80.47%] [G loss: 1.176962]\n",
      "epoch:21 step:20395 [D loss: 0.436074, acc.: 82.03%] [G loss: 1.194963]\n",
      "epoch:21 step:20396 [D loss: 0.537888, acc.: 72.66%] [G loss: 0.937724]\n",
      "epoch:21 step:20397 [D loss: 0.486588, acc.: 74.22%] [G loss: 1.281448]\n",
      "epoch:21 step:20398 [D loss: 0.721255, acc.: 57.81%] [G loss: 1.051549]\n",
      "epoch:21 step:20399 [D loss: 0.564149, acc.: 67.97%] [G loss: 1.119702]\n",
      "epoch:21 step:20400 [D loss: 0.559429, acc.: 74.22%] [G loss: 1.370383]\n",
      "epoch:21 step:20401 [D loss: 0.464024, acc.: 83.59%] [G loss: 1.593554]\n",
      "epoch:21 step:20402 [D loss: 0.616297, acc.: 61.72%] [G loss: 1.162661]\n",
      "epoch:21 step:20403 [D loss: 0.638775, acc.: 63.28%] [G loss: 0.998892]\n",
      "epoch:21 step:20404 [D loss: 0.620006, acc.: 67.19%] [G loss: 1.415773]\n",
      "epoch:21 step:20405 [D loss: 0.730970, acc.: 50.78%] [G loss: 1.102352]\n",
      "epoch:21 step:20406 [D loss: 0.688756, acc.: 59.38%] [G loss: 1.314185]\n",
      "epoch:21 step:20407 [D loss: 0.655284, acc.: 60.94%] [G loss: 1.321808]\n",
      "epoch:21 step:20408 [D loss: 0.712010, acc.: 55.47%] [G loss: 1.096064]\n",
      "epoch:21 step:20409 [D loss: 0.466917, acc.: 79.69%] [G loss: 1.426369]\n",
      "epoch:21 step:20410 [D loss: 0.678269, acc.: 64.84%] [G loss: 1.247380]\n",
      "epoch:21 step:20411 [D loss: 0.584936, acc.: 68.75%] [G loss: 1.536053]\n",
      "epoch:21 step:20412 [D loss: 0.568156, acc.: 66.41%] [G loss: 1.284441]\n",
      "epoch:21 step:20413 [D loss: 0.416255, acc.: 82.81%] [G loss: 1.282583]\n",
      "epoch:21 step:20414 [D loss: 0.564954, acc.: 65.62%] [G loss: 1.430784]\n",
      "epoch:21 step:20415 [D loss: 0.635417, acc.: 62.50%] [G loss: 1.163765]\n",
      "epoch:21 step:20416 [D loss: 0.553844, acc.: 74.22%] [G loss: 1.597733]\n",
      "epoch:21 step:20417 [D loss: 0.742588, acc.: 53.91%] [G loss: 1.331535]\n",
      "epoch:21 step:20418 [D loss: 0.518129, acc.: 74.22%] [G loss: 1.396964]\n",
      "epoch:21 step:20419 [D loss: 0.647586, acc.: 60.16%] [G loss: 1.443307]\n",
      "epoch:21 step:20420 [D loss: 0.554471, acc.: 73.44%] [G loss: 1.278188]\n",
      "epoch:21 step:20421 [D loss: 0.424085, acc.: 82.81%] [G loss: 1.373995]\n",
      "epoch:21 step:20422 [D loss: 0.462226, acc.: 75.78%] [G loss: 1.459345]\n",
      "epoch:21 step:20423 [D loss: 0.545787, acc.: 70.31%] [G loss: 1.339293]\n",
      "epoch:21 step:20424 [D loss: 0.554263, acc.: 68.75%] [G loss: 1.205594]\n",
      "epoch:21 step:20425 [D loss: 0.512547, acc.: 72.66%] [G loss: 1.567164]\n",
      "epoch:21 step:20426 [D loss: 0.579395, acc.: 70.31%] [G loss: 1.484198]\n",
      "epoch:21 step:20427 [D loss: 0.680838, acc.: 60.94%] [G loss: 1.305607]\n",
      "epoch:21 step:20428 [D loss: 0.683709, acc.: 60.94%] [G loss: 1.074704]\n",
      "epoch:21 step:20429 [D loss: 0.515169, acc.: 75.78%] [G loss: 1.287645]\n",
      "epoch:21 step:20430 [D loss: 0.455850, acc.: 81.25%] [G loss: 1.443239]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:21 step:20431 [D loss: 0.687672, acc.: 61.72%] [G loss: 1.428876]\n",
      "epoch:21 step:20432 [D loss: 0.488615, acc.: 76.56%] [G loss: 1.822261]\n",
      "epoch:21 step:20433 [D loss: 0.544573, acc.: 77.34%] [G loss: 1.427763]\n",
      "epoch:21 step:20434 [D loss: 0.502536, acc.: 75.78%] [G loss: 1.461821]\n",
      "epoch:21 step:20435 [D loss: 0.527005, acc.: 71.88%] [G loss: 1.257044]\n",
      "epoch:21 step:20436 [D loss: 0.332185, acc.: 91.41%] [G loss: 1.233110]\n",
      "epoch:21 step:20437 [D loss: 0.478309, acc.: 77.34%] [G loss: 1.543154]\n",
      "epoch:21 step:20438 [D loss: 0.523777, acc.: 74.22%] [G loss: 1.222993]\n",
      "epoch:21 step:20439 [D loss: 0.528281, acc.: 73.44%] [G loss: 1.419169]\n",
      "epoch:21 step:20440 [D loss: 0.513507, acc.: 75.00%] [G loss: 1.516089]\n",
      "epoch:21 step:20441 [D loss: 0.462195, acc.: 79.69%] [G loss: 1.534817]\n",
      "epoch:21 step:20442 [D loss: 0.539545, acc.: 78.91%] [G loss: 1.177173]\n",
      "epoch:21 step:20443 [D loss: 0.640985, acc.: 64.06%] [G loss: 0.985991]\n",
      "epoch:21 step:20444 [D loss: 0.333662, acc.: 89.06%] [G loss: 1.458367]\n",
      "epoch:21 step:20445 [D loss: 0.535077, acc.: 67.97%] [G loss: 1.319638]\n",
      "epoch:21 step:20446 [D loss: 0.406775, acc.: 85.16%] [G loss: 1.659776]\n",
      "epoch:21 step:20447 [D loss: 0.531022, acc.: 75.78%] [G loss: 1.104370]\n",
      "epoch:21 step:20448 [D loss: 0.513212, acc.: 80.47%] [G loss: 1.658837]\n",
      "epoch:21 step:20449 [D loss: 0.421471, acc.: 83.59%] [G loss: 1.344172]\n",
      "epoch:21 step:20450 [D loss: 0.739836, acc.: 51.56%] [G loss: 1.011679]\n",
      "epoch:21 step:20451 [D loss: 0.368930, acc.: 89.84%] [G loss: 1.460432]\n",
      "epoch:21 step:20452 [D loss: 0.515547, acc.: 75.78%] [G loss: 1.645014]\n",
      "epoch:21 step:20453 [D loss: 0.394247, acc.: 82.81%] [G loss: 1.871679]\n",
      "epoch:21 step:20454 [D loss: 0.542277, acc.: 75.00%] [G loss: 1.178055]\n",
      "epoch:21 step:20455 [D loss: 0.652372, acc.: 64.06%] [G loss: 1.183767]\n",
      "epoch:21 step:20456 [D loss: 0.537349, acc.: 75.78%] [G loss: 1.256665]\n",
      "epoch:21 step:20457 [D loss: 0.651686, acc.: 64.84%] [G loss: 0.895010]\n",
      "epoch:21 step:20458 [D loss: 0.523590, acc.: 73.44%] [G loss: 1.407477]\n",
      "epoch:21 step:20459 [D loss: 0.550720, acc.: 76.56%] [G loss: 1.448950]\n",
      "epoch:21 step:20460 [D loss: 0.429398, acc.: 84.38%] [G loss: 1.430228]\n",
      "epoch:21 step:20461 [D loss: 0.542065, acc.: 74.22%] [G loss: 1.222218]\n",
      "epoch:21 step:20462 [D loss: 0.385491, acc.: 82.81%] [G loss: 1.761190]\n",
      "epoch:21 step:20463 [D loss: 0.588959, acc.: 69.53%] [G loss: 1.292121]\n",
      "epoch:21 step:20464 [D loss: 0.582903, acc.: 64.84%] [G loss: 1.327425]\n",
      "epoch:21 step:20465 [D loss: 0.504239, acc.: 79.69%] [G loss: 1.259154]\n",
      "epoch:21 step:20466 [D loss: 0.581254, acc.: 72.66%] [G loss: 0.959749]\n",
      "epoch:21 step:20467 [D loss: 0.537136, acc.: 74.22%] [G loss: 1.073899]\n",
      "epoch:21 step:20468 [D loss: 0.558411, acc.: 72.66%] [G loss: 1.021880]\n",
      "epoch:21 step:20469 [D loss: 0.531633, acc.: 78.12%] [G loss: 1.618109]\n",
      "epoch:21 step:20470 [D loss: 0.609402, acc.: 61.72%] [G loss: 1.351122]\n",
      "epoch:21 step:20471 [D loss: 0.501889, acc.: 77.34%] [G loss: 1.333073]\n",
      "epoch:21 step:20472 [D loss: 0.572600, acc.: 71.09%] [G loss: 1.543828]\n",
      "epoch:21 step:20473 [D loss: 0.543415, acc.: 67.97%] [G loss: 1.718041]\n",
      "epoch:21 step:20474 [D loss: 0.542742, acc.: 77.34%] [G loss: 1.405919]\n",
      "epoch:21 step:20475 [D loss: 0.584312, acc.: 71.09%] [G loss: 1.360673]\n",
      "epoch:21 step:20476 [D loss: 0.571962, acc.: 71.09%] [G loss: 1.318705]\n",
      "epoch:21 step:20477 [D loss: 0.363496, acc.: 86.72%] [G loss: 1.292341]\n",
      "epoch:21 step:20478 [D loss: 0.681843, acc.: 60.16%] [G loss: 1.267660]\n",
      "epoch:21 step:20479 [D loss: 0.672376, acc.: 63.28%] [G loss: 1.172133]\n",
      "epoch:21 step:20480 [D loss: 0.694553, acc.: 61.72%] [G loss: 1.307209]\n",
      "epoch:21 step:20481 [D loss: 0.482163, acc.: 81.25%] [G loss: 1.722472]\n",
      "epoch:21 step:20482 [D loss: 0.606040, acc.: 68.75%] [G loss: 1.346541]\n",
      "epoch:21 step:20483 [D loss: 0.582225, acc.: 71.88%] [G loss: 1.205127]\n",
      "epoch:21 step:20484 [D loss: 0.587603, acc.: 67.19%] [G loss: 1.446044]\n",
      "epoch:21 step:20485 [D loss: 0.615657, acc.: 69.53%] [G loss: 1.464266]\n",
      "epoch:21 step:20486 [D loss: 0.361549, acc.: 86.72%] [G loss: 1.580472]\n",
      "epoch:21 step:20487 [D loss: 0.546333, acc.: 69.53%] [G loss: 1.199307]\n",
      "epoch:21 step:20488 [D loss: 0.684632, acc.: 57.81%] [G loss: 1.489612]\n",
      "epoch:21 step:20489 [D loss: 0.389393, acc.: 87.50%] [G loss: 1.381925]\n",
      "epoch:21 step:20490 [D loss: 0.523673, acc.: 75.00%] [G loss: 1.236450]\n",
      "epoch:21 step:20491 [D loss: 0.481434, acc.: 81.25%] [G loss: 1.410991]\n",
      "epoch:21 step:20492 [D loss: 0.635164, acc.: 66.41%] [G loss: 1.301570]\n",
      "epoch:21 step:20493 [D loss: 0.464210, acc.: 79.69%] [G loss: 1.472939]\n",
      "epoch:21 step:20494 [D loss: 0.623476, acc.: 66.41%] [G loss: 1.214686]\n",
      "epoch:21 step:20495 [D loss: 0.609402, acc.: 68.75%] [G loss: 1.720582]\n",
      "epoch:21 step:20496 [D loss: 0.483980, acc.: 78.91%] [G loss: 1.079904]\n",
      "epoch:21 step:20497 [D loss: 0.737028, acc.: 57.03%] [G loss: 1.123185]\n",
      "epoch:21 step:20498 [D loss: 0.536474, acc.: 71.88%] [G loss: 1.318094]\n",
      "epoch:21 step:20499 [D loss: 0.573256, acc.: 71.88%] [G loss: 1.307033]\n",
      "epoch:21 step:20500 [D loss: 0.674374, acc.: 63.28%] [G loss: 1.056356]\n",
      "epoch:21 step:20501 [D loss: 0.543480, acc.: 75.00%] [G loss: 1.747251]\n",
      "epoch:21 step:20502 [D loss: 0.500177, acc.: 78.91%] [G loss: 1.376299]\n",
      "epoch:21 step:20503 [D loss: 0.553532, acc.: 74.22%] [G loss: 1.416895]\n",
      "epoch:21 step:20504 [D loss: 0.470886, acc.: 79.69%] [G loss: 1.473086]\n",
      "epoch:21 step:20505 [D loss: 0.649069, acc.: 63.28%] [G loss: 1.267513]\n",
      "epoch:21 step:20506 [D loss: 0.563842, acc.: 75.00%] [G loss: 1.479426]\n",
      "epoch:21 step:20507 [D loss: 0.643829, acc.: 63.28%] [G loss: 1.147040]\n",
      "epoch:21 step:20508 [D loss: 0.716816, acc.: 57.81%] [G loss: 1.078303]\n",
      "epoch:21 step:20509 [D loss: 0.443576, acc.: 77.34%] [G loss: 1.295941]\n",
      "epoch:21 step:20510 [D loss: 0.532469, acc.: 72.66%] [G loss: 1.328848]\n",
      "epoch:21 step:20511 [D loss: 0.633611, acc.: 63.28%] [G loss: 1.307269]\n",
      "epoch:21 step:20512 [D loss: 0.493218, acc.: 75.78%] [G loss: 1.023690]\n",
      "epoch:21 step:20513 [D loss: 0.494387, acc.: 76.56%] [G loss: 1.629316]\n",
      "epoch:21 step:20514 [D loss: 0.671459, acc.: 61.72%] [G loss: 1.343210]\n",
      "epoch:21 step:20515 [D loss: 0.362681, acc.: 88.28%] [G loss: 1.651768]\n",
      "epoch:21 step:20516 [D loss: 0.563598, acc.: 67.97%] [G loss: 1.259759]\n",
      "epoch:21 step:20517 [D loss: 0.467437, acc.: 77.34%] [G loss: 1.630410]\n",
      "epoch:21 step:20518 [D loss: 0.460115, acc.: 78.91%] [G loss: 1.446966]\n",
      "epoch:21 step:20519 [D loss: 0.512473, acc.: 75.00%] [G loss: 1.854310]\n",
      "epoch:21 step:20520 [D loss: 0.657158, acc.: 60.16%] [G loss: 1.120053]\n",
      "epoch:21 step:20521 [D loss: 0.630640, acc.: 64.84%] [G loss: 1.593681]\n",
      "epoch:21 step:20522 [D loss: 0.638989, acc.: 62.50%] [G loss: 1.168075]\n",
      "epoch:21 step:20523 [D loss: 0.658424, acc.: 64.06%] [G loss: 1.572092]\n",
      "epoch:21 step:20524 [D loss: 0.566364, acc.: 67.19%] [G loss: 1.412343]\n",
      "epoch:21 step:20525 [D loss: 0.713792, acc.: 55.47%] [G loss: 1.390081]\n",
      "epoch:21 step:20526 [D loss: 0.547200, acc.: 70.31%] [G loss: 1.404434]\n",
      "epoch:21 step:20527 [D loss: 0.452344, acc.: 78.91%] [G loss: 1.586104]\n",
      "epoch:21 step:20528 [D loss: 0.726988, acc.: 57.03%] [G loss: 1.234246]\n",
      "epoch:21 step:20529 [D loss: 0.544888, acc.: 74.22%] [G loss: 1.486332]\n",
      "epoch:21 step:20530 [D loss: 0.594519, acc.: 70.31%] [G loss: 1.483346]\n",
      "epoch:21 step:20531 [D loss: 0.613825, acc.: 68.75%] [G loss: 1.139757]\n",
      "epoch:21 step:20532 [D loss: 0.598224, acc.: 64.06%] [G loss: 1.173925]\n",
      "epoch:21 step:20533 [D loss: 0.553492, acc.: 72.66%] [G loss: 1.424823]\n",
      "epoch:21 step:20534 [D loss: 0.466590, acc.: 78.91%] [G loss: 1.093809]\n",
      "epoch:21 step:20535 [D loss: 0.385397, acc.: 86.72%] [G loss: 1.644148]\n",
      "epoch:21 step:20536 [D loss: 0.548909, acc.: 71.88%] [G loss: 1.644531]\n",
      "epoch:21 step:20537 [D loss: 0.590593, acc.: 69.53%] [G loss: 1.298160]\n",
      "epoch:21 step:20538 [D loss: 0.469090, acc.: 78.12%] [G loss: 1.302702]\n",
      "epoch:21 step:20539 [D loss: 0.584494, acc.: 71.09%] [G loss: 1.305118]\n",
      "epoch:21 step:20540 [D loss: 0.542031, acc.: 73.44%] [G loss: 1.287908]\n",
      "epoch:21 step:20541 [D loss: 0.627264, acc.: 67.97%] [G loss: 1.044495]\n",
      "epoch:21 step:20542 [D loss: 0.564040, acc.: 69.53%] [G loss: 1.309811]\n",
      "epoch:21 step:20543 [D loss: 0.512257, acc.: 75.78%] [G loss: 1.351354]\n",
      "epoch:21 step:20544 [D loss: 0.720967, acc.: 57.81%] [G loss: 1.273919]\n",
      "epoch:21 step:20545 [D loss: 0.600483, acc.: 70.31%] [G loss: 1.415841]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:21 step:20546 [D loss: 0.420226, acc.: 81.25%] [G loss: 1.355072]\n",
      "epoch:21 step:20547 [D loss: 0.494174, acc.: 78.12%] [G loss: 1.335046]\n",
      "epoch:21 step:20548 [D loss: 0.640900, acc.: 62.50%] [G loss: 1.251994]\n",
      "epoch:21 step:20549 [D loss: 0.446519, acc.: 81.25%] [G loss: 1.391170]\n",
      "epoch:21 step:20550 [D loss: 0.490010, acc.: 74.22%] [G loss: 1.458940]\n",
      "epoch:21 step:20551 [D loss: 0.565116, acc.: 70.31%] [G loss: 1.156802]\n",
      "epoch:21 step:20552 [D loss: 0.605802, acc.: 69.53%] [G loss: 1.489659]\n",
      "epoch:21 step:20553 [D loss: 0.640897, acc.: 67.19%] [G loss: 1.338376]\n",
      "epoch:21 step:20554 [D loss: 0.590331, acc.: 67.19%] [G loss: 1.528553]\n",
      "epoch:21 step:20555 [D loss: 0.540999, acc.: 74.22%] [G loss: 1.117546]\n",
      "epoch:21 step:20556 [D loss: 0.550948, acc.: 76.56%] [G loss: 1.238205]\n",
      "epoch:21 step:20557 [D loss: 0.491391, acc.: 79.69%] [G loss: 1.380738]\n",
      "epoch:21 step:20558 [D loss: 0.500199, acc.: 74.22%] [G loss: 1.042675]\n",
      "epoch:21 step:20559 [D loss: 0.524355, acc.: 74.22%] [G loss: 1.225030]\n",
      "epoch:21 step:20560 [D loss: 0.522224, acc.: 75.78%] [G loss: 1.232059]\n",
      "epoch:21 step:20561 [D loss: 0.477642, acc.: 78.12%] [G loss: 1.784412]\n",
      "epoch:21 step:20562 [D loss: 0.499629, acc.: 76.56%] [G loss: 1.478252]\n",
      "epoch:21 step:20563 [D loss: 0.434519, acc.: 81.25%] [G loss: 1.607661]\n",
      "epoch:21 step:20564 [D loss: 0.522012, acc.: 71.88%] [G loss: 1.220928]\n",
      "epoch:21 step:20565 [D loss: 0.497758, acc.: 78.12%] [G loss: 1.181713]\n",
      "epoch:21 step:20566 [D loss: 0.608902, acc.: 66.41%] [G loss: 1.020847]\n",
      "epoch:21 step:20567 [D loss: 0.556312, acc.: 69.53%] [G loss: 1.047691]\n",
      "epoch:21 step:20568 [D loss: 0.592591, acc.: 67.97%] [G loss: 1.202159]\n",
      "epoch:21 step:20569 [D loss: 0.580785, acc.: 68.75%] [G loss: 1.317239]\n",
      "epoch:21 step:20570 [D loss: 0.574542, acc.: 65.62%] [G loss: 1.072307]\n",
      "epoch:21 step:20571 [D loss: 0.527537, acc.: 76.56%] [G loss: 1.265542]\n",
      "epoch:21 step:20572 [D loss: 0.487226, acc.: 79.69%] [G loss: 1.528017]\n",
      "epoch:21 step:20573 [D loss: 0.607050, acc.: 65.62%] [G loss: 1.389514]\n",
      "epoch:21 step:20574 [D loss: 0.498386, acc.: 76.56%] [G loss: 1.214593]\n",
      "epoch:21 step:20575 [D loss: 0.574748, acc.: 71.09%] [G loss: 0.951557]\n",
      "epoch:21 step:20576 [D loss: 0.420516, acc.: 82.81%] [G loss: 1.517485]\n",
      "epoch:21 step:20577 [D loss: 0.497940, acc.: 76.56%] [G loss: 1.352164]\n",
      "epoch:21 step:20578 [D loss: 0.623153, acc.: 64.06%] [G loss: 1.104727]\n",
      "epoch:21 step:20579 [D loss: 0.679735, acc.: 61.72%] [G loss: 0.948329]\n",
      "epoch:21 step:20580 [D loss: 0.580582, acc.: 70.31%] [G loss: 1.249092]\n",
      "epoch:21 step:20581 [D loss: 0.508758, acc.: 76.56%] [G loss: 1.495873]\n",
      "epoch:21 step:20582 [D loss: 0.516884, acc.: 78.12%] [G loss: 1.343068]\n",
      "epoch:21 step:20583 [D loss: 0.579216, acc.: 71.09%] [G loss: 1.424292]\n",
      "epoch:21 step:20584 [D loss: 0.543656, acc.: 74.22%] [G loss: 1.172542]\n",
      "epoch:21 step:20585 [D loss: 0.470260, acc.: 75.00%] [G loss: 1.190540]\n",
      "epoch:21 step:20586 [D loss: 0.518114, acc.: 75.00%] [G loss: 1.444120]\n",
      "epoch:21 step:20587 [D loss: 0.447961, acc.: 80.47%] [G loss: 1.640308]\n",
      "epoch:21 step:20588 [D loss: 0.506395, acc.: 78.91%] [G loss: 1.471442]\n",
      "epoch:21 step:20589 [D loss: 0.480527, acc.: 79.69%] [G loss: 1.431484]\n",
      "epoch:21 step:20590 [D loss: 0.446367, acc.: 82.81%] [G loss: 1.514799]\n",
      "epoch:21 step:20591 [D loss: 0.558414, acc.: 68.75%] [G loss: 1.157025]\n",
      "epoch:21 step:20592 [D loss: 0.480324, acc.: 78.91%] [G loss: 1.362600]\n",
      "epoch:21 step:20593 [D loss: 0.579444, acc.: 66.41%] [G loss: 0.921541]\n",
      "epoch:21 step:20594 [D loss: 0.524146, acc.: 76.56%] [G loss: 1.372153]\n",
      "epoch:21 step:20595 [D loss: 0.578309, acc.: 65.62%] [G loss: 1.631060]\n",
      "epoch:21 step:20596 [D loss: 0.635700, acc.: 67.97%] [G loss: 1.296269]\n",
      "epoch:21 step:20597 [D loss: 0.563518, acc.: 74.22%] [G loss: 1.619567]\n",
      "epoch:21 step:20598 [D loss: 0.707866, acc.: 63.28%] [G loss: 1.506468]\n",
      "epoch:21 step:20599 [D loss: 0.491667, acc.: 75.00%] [G loss: 1.360539]\n",
      "epoch:21 step:20600 [D loss: 0.633786, acc.: 64.06%] [G loss: 1.285926]\n",
      "epoch:21 step:20601 [D loss: 0.451968, acc.: 81.25%] [G loss: 1.099137]\n",
      "epoch:21 step:20602 [D loss: 0.752792, acc.: 58.59%] [G loss: 1.184303]\n",
      "epoch:21 step:20603 [D loss: 0.603194, acc.: 64.84%] [G loss: 1.008314]\n",
      "epoch:21 step:20604 [D loss: 0.604226, acc.: 67.97%] [G loss: 1.093447]\n",
      "epoch:21 step:20605 [D loss: 0.469088, acc.: 79.69%] [G loss: 1.132914]\n",
      "epoch:21 step:20606 [D loss: 0.573526, acc.: 69.53%] [G loss: 1.178839]\n",
      "epoch:21 step:20607 [D loss: 0.566440, acc.: 71.09%] [G loss: 1.368795]\n",
      "epoch:21 step:20608 [D loss: 0.633554, acc.: 64.84%] [G loss: 1.294212]\n",
      "epoch:21 step:20609 [D loss: 0.409688, acc.: 85.94%] [G loss: 0.978323]\n",
      "epoch:21 step:20610 [D loss: 0.643183, acc.: 64.84%] [G loss: 1.317360]\n",
      "epoch:21 step:20611 [D loss: 0.482352, acc.: 78.12%] [G loss: 1.392725]\n",
      "epoch:21 step:20612 [D loss: 0.489571, acc.: 77.34%] [G loss: 1.140473]\n",
      "epoch:21 step:20613 [D loss: 0.460998, acc.: 77.34%] [G loss: 1.412126]\n",
      "epoch:21 step:20614 [D loss: 0.428880, acc.: 84.38%] [G loss: 1.629899]\n",
      "epoch:22 step:20615 [D loss: 0.532530, acc.: 75.78%] [G loss: 1.586268]\n",
      "epoch:22 step:20616 [D loss: 0.560200, acc.: 67.97%] [G loss: 1.224371]\n",
      "epoch:22 step:20617 [D loss: 0.579716, acc.: 71.09%] [G loss: 1.463048]\n",
      "epoch:22 step:20618 [D loss: 0.552831, acc.: 70.31%] [G loss: 1.140032]\n",
      "epoch:22 step:20619 [D loss: 0.571414, acc.: 75.78%] [G loss: 1.453660]\n",
      "epoch:22 step:20620 [D loss: 0.601947, acc.: 62.50%] [G loss: 1.456071]\n",
      "epoch:22 step:20621 [D loss: 0.697866, acc.: 59.38%] [G loss: 1.305888]\n",
      "epoch:22 step:20622 [D loss: 0.588760, acc.: 71.09%] [G loss: 1.288029]\n",
      "epoch:22 step:20623 [D loss: 0.552259, acc.: 73.44%] [G loss: 1.357848]\n",
      "epoch:22 step:20624 [D loss: 0.629129, acc.: 65.62%] [G loss: 1.417212]\n",
      "epoch:22 step:20625 [D loss: 0.498452, acc.: 78.91%] [G loss: 1.292162]\n",
      "epoch:22 step:20626 [D loss: 0.604797, acc.: 69.53%] [G loss: 1.016466]\n",
      "epoch:22 step:20627 [D loss: 0.538091, acc.: 71.88%] [G loss: 1.428809]\n",
      "epoch:22 step:20628 [D loss: 0.673434, acc.: 61.72%] [G loss: 1.225172]\n",
      "epoch:22 step:20629 [D loss: 0.495444, acc.: 71.09%] [G loss: 1.299912]\n",
      "epoch:22 step:20630 [D loss: 0.642180, acc.: 67.19%] [G loss: 1.448549]\n",
      "epoch:22 step:20631 [D loss: 0.533438, acc.: 71.88%] [G loss: 1.408270]\n",
      "epoch:22 step:20632 [D loss: 0.599833, acc.: 69.53%] [G loss: 1.381026]\n",
      "epoch:22 step:20633 [D loss: 0.745810, acc.: 54.69%] [G loss: 1.049032]\n",
      "epoch:22 step:20634 [D loss: 0.562560, acc.: 72.66%] [G loss: 1.242855]\n",
      "epoch:22 step:20635 [D loss: 0.613086, acc.: 65.62%] [G loss: 1.244702]\n",
      "epoch:22 step:20636 [D loss: 0.467201, acc.: 82.03%] [G loss: 1.410969]\n",
      "epoch:22 step:20637 [D loss: 0.614406, acc.: 64.84%] [G loss: 1.053054]\n",
      "epoch:22 step:20638 [D loss: 0.528645, acc.: 77.34%] [G loss: 1.386895]\n",
      "epoch:22 step:20639 [D loss: 0.451992, acc.: 76.56%] [G loss: 1.608147]\n",
      "epoch:22 step:20640 [D loss: 0.461759, acc.: 78.12%] [G loss: 0.927874]\n",
      "epoch:22 step:20641 [D loss: 0.514443, acc.: 74.22%] [G loss: 1.522518]\n",
      "epoch:22 step:20642 [D loss: 0.547274, acc.: 67.19%] [G loss: 1.653676]\n",
      "epoch:22 step:20643 [D loss: 0.576362, acc.: 72.66%] [G loss: 1.278808]\n",
      "epoch:22 step:20644 [D loss: 0.486283, acc.: 77.34%] [G loss: 1.354913]\n",
      "epoch:22 step:20645 [D loss: 0.669225, acc.: 64.06%] [G loss: 1.454602]\n",
      "epoch:22 step:20646 [D loss: 0.512474, acc.: 75.78%] [G loss: 1.180801]\n",
      "epoch:22 step:20647 [D loss: 0.505128, acc.: 71.88%] [G loss: 1.421398]\n",
      "epoch:22 step:20648 [D loss: 0.617450, acc.: 65.62%] [G loss: 1.484005]\n",
      "epoch:22 step:20649 [D loss: 0.511867, acc.: 75.78%] [G loss: 1.611532]\n",
      "epoch:22 step:20650 [D loss: 0.599981, acc.: 62.50%] [G loss: 1.130264]\n",
      "epoch:22 step:20651 [D loss: 0.494965, acc.: 78.12%] [G loss: 1.306885]\n",
      "epoch:22 step:20652 [D loss: 0.726140, acc.: 52.34%] [G loss: 1.111344]\n",
      "epoch:22 step:20653 [D loss: 0.651592, acc.: 59.38%] [G loss: 1.337052]\n",
      "epoch:22 step:20654 [D loss: 0.603987, acc.: 67.19%] [G loss: 1.197047]\n",
      "epoch:22 step:20655 [D loss: 0.448928, acc.: 78.91%] [G loss: 1.364035]\n",
      "epoch:22 step:20656 [D loss: 0.659901, acc.: 59.38%] [G loss: 1.338891]\n",
      "epoch:22 step:20657 [D loss: 0.571305, acc.: 71.88%] [G loss: 1.160269]\n",
      "epoch:22 step:20658 [D loss: 0.512029, acc.: 76.56%] [G loss: 1.659723]\n",
      "epoch:22 step:20659 [D loss: 0.471655, acc.: 75.78%] [G loss: 1.364423]\n",
      "epoch:22 step:20660 [D loss: 0.614000, acc.: 65.62%] [G loss: 1.225968]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:22 step:20661 [D loss: 0.643598, acc.: 66.41%] [G loss: 1.147750]\n",
      "epoch:22 step:20662 [D loss: 0.511488, acc.: 77.34%] [G loss: 1.340119]\n",
      "epoch:22 step:20663 [D loss: 0.661969, acc.: 61.72%] [G loss: 1.319890]\n",
      "epoch:22 step:20664 [D loss: 0.446370, acc.: 82.81%] [G loss: 1.373920]\n",
      "epoch:22 step:20665 [D loss: 0.657740, acc.: 64.06%] [G loss: 1.708825]\n",
      "epoch:22 step:20666 [D loss: 0.434723, acc.: 83.59%] [G loss: 1.177891]\n",
      "epoch:22 step:20667 [D loss: 0.494134, acc.: 74.22%] [G loss: 1.508267]\n",
      "epoch:22 step:20668 [D loss: 0.498089, acc.: 79.69%] [G loss: 1.408517]\n",
      "epoch:22 step:20669 [D loss: 0.510526, acc.: 78.12%] [G loss: 1.196774]\n",
      "epoch:22 step:20670 [D loss: 0.574935, acc.: 72.66%] [G loss: 1.148704]\n",
      "epoch:22 step:20671 [D loss: 0.542586, acc.: 75.00%] [G loss: 1.372832]\n",
      "epoch:22 step:20672 [D loss: 0.746608, acc.: 50.00%] [G loss: 1.362114]\n",
      "epoch:22 step:20673 [D loss: 0.454333, acc.: 83.59%] [G loss: 1.404970]\n",
      "epoch:22 step:20674 [D loss: 0.423397, acc.: 86.72%] [G loss: 1.326256]\n",
      "epoch:22 step:20675 [D loss: 0.589001, acc.: 68.75%] [G loss: 1.599592]\n",
      "epoch:22 step:20676 [D loss: 0.533622, acc.: 76.56%] [G loss: 1.616159]\n",
      "epoch:22 step:20677 [D loss: 0.461151, acc.: 80.47%] [G loss: 1.493597]\n",
      "epoch:22 step:20678 [D loss: 0.666201, acc.: 59.38%] [G loss: 1.207336]\n",
      "epoch:22 step:20679 [D loss: 0.545126, acc.: 69.53%] [G loss: 1.653011]\n",
      "epoch:22 step:20680 [D loss: 0.535866, acc.: 71.09%] [G loss: 1.502430]\n",
      "epoch:22 step:20681 [D loss: 0.468890, acc.: 81.25%] [G loss: 1.687606]\n",
      "epoch:22 step:20682 [D loss: 0.555504, acc.: 71.09%] [G loss: 1.429568]\n",
      "epoch:22 step:20683 [D loss: 0.424272, acc.: 80.47%] [G loss: 1.413204]\n",
      "epoch:22 step:20684 [D loss: 0.534122, acc.: 72.66%] [G loss: 1.397148]\n",
      "epoch:22 step:20685 [D loss: 0.597167, acc.: 64.84%] [G loss: 1.417933]\n",
      "epoch:22 step:20686 [D loss: 0.626374, acc.: 62.50%] [G loss: 1.187917]\n",
      "epoch:22 step:20687 [D loss: 0.389829, acc.: 85.94%] [G loss: 1.520822]\n",
      "epoch:22 step:20688 [D loss: 0.501315, acc.: 73.44%] [G loss: 1.373051]\n",
      "epoch:22 step:20689 [D loss: 0.505719, acc.: 73.44%] [G loss: 1.132986]\n",
      "epoch:22 step:20690 [D loss: 0.512413, acc.: 75.78%] [G loss: 0.990298]\n",
      "epoch:22 step:20691 [D loss: 0.491985, acc.: 77.34%] [G loss: 1.514570]\n",
      "epoch:22 step:20692 [D loss: 0.755968, acc.: 50.00%] [G loss: 0.753414]\n",
      "epoch:22 step:20693 [D loss: 0.481878, acc.: 81.25%] [G loss: 0.917250]\n",
      "epoch:22 step:20694 [D loss: 0.627021, acc.: 64.84%] [G loss: 1.111513]\n",
      "epoch:22 step:20695 [D loss: 0.617484, acc.: 63.28%] [G loss: 1.349728]\n",
      "epoch:22 step:20696 [D loss: 0.556697, acc.: 69.53%] [G loss: 1.536424]\n",
      "epoch:22 step:20697 [D loss: 0.831632, acc.: 49.22%] [G loss: 1.323050]\n",
      "epoch:22 step:20698 [D loss: 0.607878, acc.: 66.41%] [G loss: 1.262444]\n",
      "epoch:22 step:20699 [D loss: 0.478175, acc.: 81.25%] [G loss: 1.555887]\n",
      "epoch:22 step:20700 [D loss: 0.567171, acc.: 71.88%] [G loss: 1.248554]\n",
      "epoch:22 step:20701 [D loss: 0.499463, acc.: 78.91%] [G loss: 1.452428]\n",
      "epoch:22 step:20702 [D loss: 0.574213, acc.: 75.00%] [G loss: 1.499635]\n",
      "epoch:22 step:20703 [D loss: 0.539644, acc.: 71.88%] [G loss: 1.193384]\n",
      "epoch:22 step:20704 [D loss: 0.610371, acc.: 66.41%] [G loss: 1.333405]\n",
      "epoch:22 step:20705 [D loss: 0.691260, acc.: 59.38%] [G loss: 1.734209]\n",
      "epoch:22 step:20706 [D loss: 0.494389, acc.: 78.91%] [G loss: 1.747321]\n",
      "epoch:22 step:20707 [D loss: 0.482415, acc.: 71.88%] [G loss: 1.364468]\n",
      "epoch:22 step:20708 [D loss: 0.600259, acc.: 64.06%] [G loss: 1.192762]\n",
      "epoch:22 step:20709 [D loss: 0.610579, acc.: 65.62%] [G loss: 1.324258]\n",
      "epoch:22 step:20710 [D loss: 0.445741, acc.: 82.81%] [G loss: 1.468906]\n",
      "epoch:22 step:20711 [D loss: 0.562680, acc.: 68.75%] [G loss: 1.494564]\n",
      "epoch:22 step:20712 [D loss: 0.374890, acc.: 85.94%] [G loss: 1.614067]\n",
      "epoch:22 step:20713 [D loss: 0.550446, acc.: 71.09%] [G loss: 1.583759]\n",
      "epoch:22 step:20714 [D loss: 0.516765, acc.: 78.12%] [G loss: 1.305191]\n",
      "epoch:22 step:20715 [D loss: 0.597508, acc.: 68.75%] [G loss: 1.353003]\n",
      "epoch:22 step:20716 [D loss: 0.603020, acc.: 67.97%] [G loss: 1.033738]\n",
      "epoch:22 step:20717 [D loss: 0.511341, acc.: 75.00%] [G loss: 1.543929]\n",
      "epoch:22 step:20718 [D loss: 0.521352, acc.: 74.22%] [G loss: 1.460670]\n",
      "epoch:22 step:20719 [D loss: 0.547788, acc.: 72.66%] [G loss: 1.689780]\n",
      "epoch:22 step:20720 [D loss: 0.553707, acc.: 71.09%] [G loss: 1.504118]\n",
      "epoch:22 step:20721 [D loss: 0.573861, acc.: 69.53%] [G loss: 1.289428]\n",
      "epoch:22 step:20722 [D loss: 0.519507, acc.: 76.56%] [G loss: 1.151511]\n",
      "epoch:22 step:20723 [D loss: 0.614185, acc.: 67.97%] [G loss: 1.144603]\n",
      "epoch:22 step:20724 [D loss: 0.568908, acc.: 70.31%] [G loss: 1.383308]\n",
      "epoch:22 step:20725 [D loss: 0.576582, acc.: 67.19%] [G loss: 1.299140]\n",
      "epoch:22 step:20726 [D loss: 0.681954, acc.: 62.50%] [G loss: 1.646608]\n",
      "epoch:22 step:20727 [D loss: 0.523683, acc.: 75.78%] [G loss: 1.487157]\n",
      "epoch:22 step:20728 [D loss: 0.497047, acc.: 78.12%] [G loss: 1.492148]\n",
      "epoch:22 step:20729 [D loss: 0.502360, acc.: 74.22%] [G loss: 1.110006]\n",
      "epoch:22 step:20730 [D loss: 0.533331, acc.: 72.66%] [G loss: 1.673799]\n",
      "epoch:22 step:20731 [D loss: 0.447488, acc.: 85.16%] [G loss: 1.698627]\n",
      "epoch:22 step:20732 [D loss: 0.642996, acc.: 60.16%] [G loss: 1.353079]\n",
      "epoch:22 step:20733 [D loss: 0.514597, acc.: 76.56%] [G loss: 1.279231]\n",
      "epoch:22 step:20734 [D loss: 0.895354, acc.: 46.88%] [G loss: 1.584027]\n",
      "epoch:22 step:20735 [D loss: 0.537455, acc.: 73.44%] [G loss: 1.471584]\n",
      "epoch:22 step:20736 [D loss: 0.461478, acc.: 78.12%] [G loss: 1.382888]\n",
      "epoch:22 step:20737 [D loss: 0.678868, acc.: 63.28%] [G loss: 1.033598]\n",
      "epoch:22 step:20738 [D loss: 0.550147, acc.: 72.66%] [G loss: 1.556602]\n",
      "epoch:22 step:20739 [D loss: 0.568897, acc.: 69.53%] [G loss: 1.158427]\n",
      "epoch:22 step:20740 [D loss: 0.595579, acc.: 69.53%] [G loss: 1.698479]\n",
      "epoch:22 step:20741 [D loss: 0.518273, acc.: 78.12%] [G loss: 1.222933]\n",
      "epoch:22 step:20742 [D loss: 0.413613, acc.: 81.25%] [G loss: 1.690729]\n",
      "epoch:22 step:20743 [D loss: 0.537609, acc.: 71.09%] [G loss: 1.126307]\n",
      "epoch:22 step:20744 [D loss: 0.365629, acc.: 84.38%] [G loss: 1.535027]\n",
      "epoch:22 step:20745 [D loss: 0.446489, acc.: 83.59%] [G loss: 1.472952]\n",
      "epoch:22 step:20746 [D loss: 0.634171, acc.: 64.06%] [G loss: 1.055102]\n",
      "epoch:22 step:20747 [D loss: 0.571345, acc.: 68.75%] [G loss: 1.038909]\n",
      "epoch:22 step:20748 [D loss: 0.472321, acc.: 80.47%] [G loss: 1.740855]\n",
      "epoch:22 step:20749 [D loss: 0.715195, acc.: 55.47%] [G loss: 1.252210]\n",
      "epoch:22 step:20750 [D loss: 0.773659, acc.: 50.00%] [G loss: 1.149478]\n",
      "epoch:22 step:20751 [D loss: 0.507945, acc.: 74.22%] [G loss: 1.174351]\n",
      "epoch:22 step:20752 [D loss: 0.584329, acc.: 68.75%] [G loss: 1.155292]\n",
      "epoch:22 step:20753 [D loss: 0.781714, acc.: 47.66%] [G loss: 1.365430]\n",
      "epoch:22 step:20754 [D loss: 0.609368, acc.: 68.75%] [G loss: 1.656375]\n",
      "epoch:22 step:20755 [D loss: 0.756587, acc.: 48.44%] [G loss: 1.173804]\n",
      "epoch:22 step:20756 [D loss: 0.634514, acc.: 61.72%] [G loss: 1.358655]\n",
      "epoch:22 step:20757 [D loss: 0.577829, acc.: 64.84%] [G loss: 1.421751]\n",
      "epoch:22 step:20758 [D loss: 0.617590, acc.: 66.41%] [G loss: 1.411448]\n",
      "epoch:22 step:20759 [D loss: 0.489919, acc.: 77.34%] [G loss: 1.585951]\n",
      "epoch:22 step:20760 [D loss: 0.519984, acc.: 75.78%] [G loss: 1.446793]\n",
      "epoch:22 step:20761 [D loss: 0.433412, acc.: 83.59%] [G loss: 1.755577]\n",
      "epoch:22 step:20762 [D loss: 0.497319, acc.: 75.78%] [G loss: 1.605875]\n",
      "epoch:22 step:20763 [D loss: 0.580637, acc.: 73.44%] [G loss: 1.806636]\n",
      "epoch:22 step:20764 [D loss: 0.608573, acc.: 71.88%] [G loss: 1.372272]\n",
      "epoch:22 step:20765 [D loss: 0.608726, acc.: 62.50%] [G loss: 1.323794]\n",
      "epoch:22 step:20766 [D loss: 0.515251, acc.: 72.66%] [G loss: 1.598198]\n",
      "epoch:22 step:20767 [D loss: 0.639373, acc.: 64.84%] [G loss: 1.232124]\n",
      "epoch:22 step:20768 [D loss: 0.561572, acc.: 70.31%] [G loss: 1.254151]\n",
      "epoch:22 step:20769 [D loss: 0.687080, acc.: 60.94%] [G loss: 1.183924]\n",
      "epoch:22 step:20770 [D loss: 0.571792, acc.: 68.75%] [G loss: 1.377195]\n",
      "epoch:22 step:20771 [D loss: 0.588285, acc.: 65.62%] [G loss: 1.633463]\n",
      "epoch:22 step:20772 [D loss: 0.542934, acc.: 70.31%] [G loss: 1.685920]\n",
      "epoch:22 step:20773 [D loss: 0.406381, acc.: 85.94%] [G loss: 1.692737]\n",
      "epoch:22 step:20774 [D loss: 0.606237, acc.: 65.62%] [G loss: 1.340277]\n",
      "epoch:22 step:20775 [D loss: 0.541558, acc.: 71.09%] [G loss: 1.090189]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:22 step:20776 [D loss: 0.682275, acc.: 59.38%] [G loss: 1.232501]\n",
      "epoch:22 step:20777 [D loss: 0.536954, acc.: 72.66%] [G loss: 1.443071]\n",
      "epoch:22 step:20778 [D loss: 0.603011, acc.: 70.31%] [G loss: 1.462031]\n",
      "epoch:22 step:20779 [D loss: 0.585615, acc.: 68.75%] [G loss: 1.376157]\n",
      "epoch:22 step:20780 [D loss: 0.569595, acc.: 66.41%] [G loss: 1.396572]\n",
      "epoch:22 step:20781 [D loss: 0.578117, acc.: 71.88%] [G loss: 1.298440]\n",
      "epoch:22 step:20782 [D loss: 0.482202, acc.: 78.12%] [G loss: 1.388412]\n",
      "epoch:22 step:20783 [D loss: 0.504007, acc.: 77.34%] [G loss: 1.174597]\n",
      "epoch:22 step:20784 [D loss: 0.488331, acc.: 78.12%] [G loss: 1.259646]\n",
      "epoch:22 step:20785 [D loss: 0.597717, acc.: 64.84%] [G loss: 1.572765]\n",
      "epoch:22 step:20786 [D loss: 0.395970, acc.: 85.16%] [G loss: 1.801033]\n",
      "epoch:22 step:20787 [D loss: 0.555169, acc.: 71.09%] [G loss: 1.548183]\n",
      "epoch:22 step:20788 [D loss: 0.517013, acc.: 75.78%] [G loss: 1.439190]\n",
      "epoch:22 step:20789 [D loss: 0.543664, acc.: 70.31%] [G loss: 1.462360]\n",
      "epoch:22 step:20790 [D loss: 0.531457, acc.: 71.09%] [G loss: 1.698409]\n",
      "epoch:22 step:20791 [D loss: 0.472808, acc.: 80.47%] [G loss: 1.239760]\n",
      "epoch:22 step:20792 [D loss: 0.598047, acc.: 65.62%] [G loss: 1.348837]\n",
      "epoch:22 step:20793 [D loss: 0.527437, acc.: 78.12%] [G loss: 1.294335]\n",
      "epoch:22 step:20794 [D loss: 0.416424, acc.: 85.16%] [G loss: 1.158152]\n",
      "epoch:22 step:20795 [D loss: 0.612418, acc.: 67.97%] [G loss: 1.161477]\n",
      "epoch:22 step:20796 [D loss: 0.499276, acc.: 76.56%] [G loss: 1.346045]\n",
      "epoch:22 step:20797 [D loss: 0.463396, acc.: 78.12%] [G loss: 1.417547]\n",
      "epoch:22 step:20798 [D loss: 0.541903, acc.: 75.00%] [G loss: 1.330977]\n",
      "epoch:22 step:20799 [D loss: 0.601302, acc.: 60.16%] [G loss: 1.467673]\n",
      "epoch:22 step:20800 [D loss: 0.583690, acc.: 66.41%] [G loss: 1.429000]\n",
      "epoch:22 step:20801 [D loss: 0.552596, acc.: 71.09%] [G loss: 1.330393]\n",
      "epoch:22 step:20802 [D loss: 0.512368, acc.: 75.78%] [G loss: 1.471173]\n",
      "epoch:22 step:20803 [D loss: 0.566544, acc.: 71.09%] [G loss: 1.442031]\n",
      "epoch:22 step:20804 [D loss: 0.809808, acc.: 52.34%] [G loss: 1.276820]\n",
      "epoch:22 step:20805 [D loss: 0.584435, acc.: 67.19%] [G loss: 1.233082]\n",
      "epoch:22 step:20806 [D loss: 0.673223, acc.: 62.50%] [G loss: 1.148147]\n",
      "epoch:22 step:20807 [D loss: 0.512856, acc.: 75.78%] [G loss: 1.461348]\n",
      "epoch:22 step:20808 [D loss: 0.661532, acc.: 54.69%] [G loss: 1.611321]\n",
      "epoch:22 step:20809 [D loss: 0.524948, acc.: 74.22%] [G loss: 1.252545]\n",
      "epoch:22 step:20810 [D loss: 0.513190, acc.: 75.00%] [G loss: 1.235587]\n",
      "epoch:22 step:20811 [D loss: 0.534347, acc.: 75.00%] [G loss: 1.122176]\n",
      "epoch:22 step:20812 [D loss: 0.477593, acc.: 76.56%] [G loss: 1.158894]\n",
      "epoch:22 step:20813 [D loss: 0.487118, acc.: 80.47%] [G loss: 1.077098]\n",
      "epoch:22 step:20814 [D loss: 0.620540, acc.: 69.53%] [G loss: 1.510297]\n",
      "epoch:22 step:20815 [D loss: 0.487348, acc.: 75.00%] [G loss: 1.285473]\n",
      "epoch:22 step:20816 [D loss: 0.477376, acc.: 75.00%] [G loss: 1.287416]\n",
      "epoch:22 step:20817 [D loss: 0.427743, acc.: 84.38%] [G loss: 1.515185]\n",
      "epoch:22 step:20818 [D loss: 0.445499, acc.: 79.69%] [G loss: 1.378360]\n",
      "epoch:22 step:20819 [D loss: 0.592064, acc.: 69.53%] [G loss: 1.361151]\n",
      "epoch:22 step:20820 [D loss: 0.498790, acc.: 75.00%] [G loss: 1.298808]\n",
      "epoch:22 step:20821 [D loss: 0.637272, acc.: 64.06%] [G loss: 1.242649]\n",
      "epoch:22 step:20822 [D loss: 0.582914, acc.: 68.75%] [G loss: 1.690963]\n",
      "epoch:22 step:20823 [D loss: 0.644482, acc.: 66.41%] [G loss: 1.535125]\n",
      "epoch:22 step:20824 [D loss: 0.703290, acc.: 59.38%] [G loss: 1.155759]\n",
      "epoch:22 step:20825 [D loss: 0.536314, acc.: 72.66%] [G loss: 1.353831]\n",
      "epoch:22 step:20826 [D loss: 0.649834, acc.: 61.72%] [G loss: 1.378249]\n",
      "epoch:22 step:20827 [D loss: 0.646797, acc.: 64.06%] [G loss: 1.425048]\n",
      "epoch:22 step:20828 [D loss: 0.585542, acc.: 62.50%] [G loss: 1.262637]\n",
      "epoch:22 step:20829 [D loss: 0.625940, acc.: 60.94%] [G loss: 1.115811]\n",
      "epoch:22 step:20830 [D loss: 0.663731, acc.: 62.50%] [G loss: 1.105894]\n",
      "epoch:22 step:20831 [D loss: 0.548154, acc.: 67.97%] [G loss: 1.482073]\n",
      "epoch:22 step:20832 [D loss: 0.489442, acc.: 78.91%] [G loss: 1.597097]\n",
      "epoch:22 step:20833 [D loss: 0.577502, acc.: 69.53%] [G loss: 1.802107]\n",
      "epoch:22 step:20834 [D loss: 0.607912, acc.: 68.75%] [G loss: 1.266547]\n",
      "epoch:22 step:20835 [D loss: 0.645052, acc.: 69.53%] [G loss: 1.107324]\n",
      "epoch:22 step:20836 [D loss: 0.574310, acc.: 71.88%] [G loss: 1.341920]\n",
      "epoch:22 step:20837 [D loss: 0.561635, acc.: 69.53%] [G loss: 1.454636]\n",
      "epoch:22 step:20838 [D loss: 0.591926, acc.: 63.28%] [G loss: 1.297489]\n",
      "epoch:22 step:20839 [D loss: 0.554144, acc.: 71.09%] [G loss: 1.453035]\n",
      "epoch:22 step:20840 [D loss: 0.634062, acc.: 64.06%] [G loss: 1.785656]\n",
      "epoch:22 step:20841 [D loss: 0.574478, acc.: 69.53%] [G loss: 1.498175]\n",
      "epoch:22 step:20842 [D loss: 0.619882, acc.: 65.62%] [G loss: 1.428532]\n",
      "epoch:22 step:20843 [D loss: 0.476279, acc.: 80.47%] [G loss: 1.416402]\n",
      "epoch:22 step:20844 [D loss: 0.540644, acc.: 71.09%] [G loss: 1.504478]\n",
      "epoch:22 step:20845 [D loss: 0.567019, acc.: 68.75%] [G loss: 1.562331]\n",
      "epoch:22 step:20846 [D loss: 0.582226, acc.: 71.09%] [G loss: 1.238369]\n",
      "epoch:22 step:20847 [D loss: 0.614391, acc.: 67.19%] [G loss: 1.562626]\n",
      "epoch:22 step:20848 [D loss: 0.654291, acc.: 67.19%] [G loss: 1.200773]\n",
      "epoch:22 step:20849 [D loss: 0.590185, acc.: 73.44%] [G loss: 1.208687]\n",
      "epoch:22 step:20850 [D loss: 0.393993, acc.: 82.03%] [G loss: 1.560729]\n",
      "epoch:22 step:20851 [D loss: 0.583085, acc.: 67.97%] [G loss: 1.457747]\n",
      "epoch:22 step:20852 [D loss: 0.563201, acc.: 70.31%] [G loss: 1.436538]\n",
      "epoch:22 step:20853 [D loss: 0.373825, acc.: 84.38%] [G loss: 1.666942]\n",
      "epoch:22 step:20854 [D loss: 0.695503, acc.: 56.25%] [G loss: 1.342204]\n",
      "epoch:22 step:20855 [D loss: 0.478042, acc.: 78.12%] [G loss: 1.395037]\n",
      "epoch:22 step:20856 [D loss: 0.768598, acc.: 49.22%] [G loss: 1.051232]\n",
      "epoch:22 step:20857 [D loss: 0.470311, acc.: 82.03%] [G loss: 1.214634]\n",
      "epoch:22 step:20858 [D loss: 0.512162, acc.: 75.78%] [G loss: 1.410275]\n",
      "epoch:22 step:20859 [D loss: 0.479383, acc.: 80.47%] [G loss: 1.469059]\n",
      "epoch:22 step:20860 [D loss: 0.428691, acc.: 82.81%] [G loss: 1.629193]\n",
      "epoch:22 step:20861 [D loss: 0.454125, acc.: 80.47%] [G loss: 1.192086]\n",
      "epoch:22 step:20862 [D loss: 0.447171, acc.: 82.03%] [G loss: 1.582479]\n",
      "epoch:22 step:20863 [D loss: 0.517952, acc.: 79.69%] [G loss: 1.443655]\n",
      "epoch:22 step:20864 [D loss: 0.525017, acc.: 70.31%] [G loss: 1.375436]\n",
      "epoch:22 step:20865 [D loss: 0.494108, acc.: 75.78%] [G loss: 1.413385]\n",
      "epoch:22 step:20866 [D loss: 0.630697, acc.: 68.75%] [G loss: 1.293559]\n",
      "epoch:22 step:20867 [D loss: 0.569981, acc.: 69.53%] [G loss: 1.329291]\n",
      "epoch:22 step:20868 [D loss: 0.521426, acc.: 73.44%] [G loss: 1.176705]\n",
      "epoch:22 step:20869 [D loss: 0.597221, acc.: 67.97%] [G loss: 1.417229]\n",
      "epoch:22 step:20870 [D loss: 0.459600, acc.: 83.59%] [G loss: 1.327955]\n",
      "epoch:22 step:20871 [D loss: 0.401321, acc.: 82.81%] [G loss: 1.694876]\n",
      "epoch:22 step:20872 [D loss: 0.479986, acc.: 78.12%] [G loss: 1.358190]\n",
      "epoch:22 step:20873 [D loss: 0.607342, acc.: 64.06%] [G loss: 1.053187]\n",
      "epoch:22 step:20874 [D loss: 0.634294, acc.: 63.28%] [G loss: 1.432838]\n",
      "epoch:22 step:20875 [D loss: 0.559847, acc.: 70.31%] [G loss: 1.628197]\n",
      "epoch:22 step:20876 [D loss: 0.789359, acc.: 49.22%] [G loss: 1.529787]\n",
      "epoch:22 step:20877 [D loss: 0.575434, acc.: 65.62%] [G loss: 1.561686]\n",
      "epoch:22 step:20878 [D loss: 0.604524, acc.: 64.06%] [G loss: 1.435647]\n",
      "epoch:22 step:20879 [D loss: 0.523820, acc.: 73.44%] [G loss: 1.599568]\n",
      "epoch:22 step:20880 [D loss: 0.504665, acc.: 75.00%] [G loss: 1.691052]\n",
      "epoch:22 step:20881 [D loss: 0.768220, acc.: 53.91%] [G loss: 1.270354]\n",
      "epoch:22 step:20882 [D loss: 0.564362, acc.: 68.75%] [G loss: 1.359552]\n",
      "epoch:22 step:20883 [D loss: 0.471134, acc.: 77.34%] [G loss: 1.732389]\n",
      "epoch:22 step:20884 [D loss: 0.419989, acc.: 82.81%] [G loss: 1.728760]\n",
      "epoch:22 step:20885 [D loss: 0.560508, acc.: 66.41%] [G loss: 1.670682]\n",
      "epoch:22 step:20886 [D loss: 0.773153, acc.: 54.69%] [G loss: 1.337656]\n",
      "epoch:22 step:20887 [D loss: 0.446785, acc.: 83.59%] [G loss: 1.410975]\n",
      "epoch:22 step:20888 [D loss: 0.600063, acc.: 70.31%] [G loss: 1.422927]\n",
      "epoch:22 step:20889 [D loss: 0.537335, acc.: 73.44%] [G loss: 1.520376]\n",
      "epoch:22 step:20890 [D loss: 0.636681, acc.: 66.41%] [G loss: 1.034135]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:22 step:20891 [D loss: 0.458294, acc.: 76.56%] [G loss: 1.138000]\n",
      "epoch:22 step:20892 [D loss: 0.646473, acc.: 60.94%] [G loss: 1.254693]\n",
      "epoch:22 step:20893 [D loss: 0.647249, acc.: 63.28%] [G loss: 1.009362]\n",
      "epoch:22 step:20894 [D loss: 0.542263, acc.: 67.19%] [G loss: 1.380892]\n",
      "epoch:22 step:20895 [D loss: 0.502856, acc.: 76.56%] [G loss: 1.360098]\n",
      "epoch:22 step:20896 [D loss: 0.452885, acc.: 79.69%] [G loss: 1.304368]\n",
      "epoch:22 step:20897 [D loss: 0.391841, acc.: 87.50%] [G loss: 1.587488]\n",
      "epoch:22 step:20898 [D loss: 0.587031, acc.: 66.41%] [G loss: 1.439125]\n",
      "epoch:22 step:20899 [D loss: 0.473869, acc.: 75.00%] [G loss: 1.747106]\n",
      "epoch:22 step:20900 [D loss: 0.466309, acc.: 83.59%] [G loss: 1.715479]\n",
      "epoch:22 step:20901 [D loss: 0.429602, acc.: 87.50%] [G loss: 1.613317]\n",
      "epoch:22 step:20902 [D loss: 0.631846, acc.: 68.75%] [G loss: 1.404884]\n",
      "epoch:22 step:20903 [D loss: 0.550320, acc.: 71.09%] [G loss: 1.326254]\n",
      "epoch:22 step:20904 [D loss: 0.528761, acc.: 79.69%] [G loss: 1.546255]\n",
      "epoch:22 step:20905 [D loss: 0.501554, acc.: 74.22%] [G loss: 1.610001]\n",
      "epoch:22 step:20906 [D loss: 0.569953, acc.: 64.06%] [G loss: 1.305855]\n",
      "epoch:22 step:20907 [D loss: 0.565874, acc.: 72.66%] [G loss: 1.602382]\n",
      "epoch:22 step:20908 [D loss: 0.520737, acc.: 77.34%] [G loss: 1.441946]\n",
      "epoch:22 step:20909 [D loss: 0.655721, acc.: 62.50%] [G loss: 1.365779]\n",
      "epoch:22 step:20910 [D loss: 0.444774, acc.: 83.59%] [G loss: 1.502343]\n",
      "epoch:22 step:20911 [D loss: 0.816199, acc.: 46.09%] [G loss: 1.101098]\n",
      "epoch:22 step:20912 [D loss: 0.682923, acc.: 56.25%] [G loss: 1.413346]\n",
      "epoch:22 step:20913 [D loss: 0.610626, acc.: 64.06%] [G loss: 1.491643]\n",
      "epoch:22 step:20914 [D loss: 0.604499, acc.: 65.62%] [G loss: 1.173889]\n",
      "epoch:22 step:20915 [D loss: 0.677079, acc.: 61.72%] [G loss: 1.275281]\n",
      "epoch:22 step:20916 [D loss: 0.565652, acc.: 69.53%] [G loss: 1.221123]\n",
      "epoch:22 step:20917 [D loss: 0.623872, acc.: 67.19%] [G loss: 1.023643]\n",
      "epoch:22 step:20918 [D loss: 0.652456, acc.: 64.06%] [G loss: 1.179962]\n",
      "epoch:22 step:20919 [D loss: 0.550090, acc.: 72.66%] [G loss: 1.570194]\n",
      "epoch:22 step:20920 [D loss: 0.581771, acc.: 65.62%] [G loss: 1.797834]\n",
      "epoch:22 step:20921 [D loss: 0.621130, acc.: 67.19%] [G loss: 1.187533]\n",
      "epoch:22 step:20922 [D loss: 0.584160, acc.: 72.66%] [G loss: 1.154135]\n",
      "epoch:22 step:20923 [D loss: 0.470531, acc.: 81.25%] [G loss: 1.414298]\n",
      "epoch:22 step:20924 [D loss: 0.528868, acc.: 76.56%] [G loss: 1.506611]\n",
      "epoch:22 step:20925 [D loss: 0.438539, acc.: 82.03%] [G loss: 1.512604]\n",
      "epoch:22 step:20926 [D loss: 0.587406, acc.: 68.75%] [G loss: 1.362604]\n",
      "epoch:22 step:20927 [D loss: 0.656101, acc.: 65.62%] [G loss: 1.404092]\n",
      "epoch:22 step:20928 [D loss: 0.575049, acc.: 71.88%] [G loss: 1.133969]\n",
      "epoch:22 step:20929 [D loss: 0.632943, acc.: 70.31%] [G loss: 1.739618]\n",
      "epoch:22 step:20930 [D loss: 0.664236, acc.: 64.84%] [G loss: 1.147805]\n",
      "epoch:22 step:20931 [D loss: 0.629227, acc.: 64.06%] [G loss: 1.237021]\n",
      "epoch:22 step:20932 [D loss: 0.641974, acc.: 64.06%] [G loss: 1.245926]\n",
      "epoch:22 step:20933 [D loss: 0.586365, acc.: 67.19%] [G loss: 1.458206]\n",
      "epoch:22 step:20934 [D loss: 0.586915, acc.: 71.09%] [G loss: 1.273568]\n",
      "epoch:22 step:20935 [D loss: 0.706161, acc.: 62.50%] [G loss: 1.203394]\n",
      "epoch:22 step:20936 [D loss: 0.535162, acc.: 73.44%] [G loss: 1.773139]\n",
      "epoch:22 step:20937 [D loss: 0.492232, acc.: 78.91%] [G loss: 1.275566]\n",
      "epoch:22 step:20938 [D loss: 0.622823, acc.: 63.28%] [G loss: 1.394806]\n",
      "epoch:22 step:20939 [D loss: 0.588410, acc.: 67.19%] [G loss: 1.214129]\n",
      "epoch:22 step:20940 [D loss: 0.581792, acc.: 71.88%] [G loss: 1.291780]\n",
      "epoch:22 step:20941 [D loss: 0.389071, acc.: 83.59%] [G loss: 1.524323]\n",
      "epoch:22 step:20942 [D loss: 0.571392, acc.: 70.31%] [G loss: 1.301581]\n",
      "epoch:22 step:20943 [D loss: 0.594230, acc.: 73.44%] [G loss: 1.468462]\n",
      "epoch:22 step:20944 [D loss: 0.604820, acc.: 71.88%] [G loss: 1.834816]\n",
      "epoch:22 step:20945 [D loss: 0.590615, acc.: 69.53%] [G loss: 1.495221]\n",
      "epoch:22 step:20946 [D loss: 0.665298, acc.: 53.91%] [G loss: 1.117574]\n",
      "epoch:22 step:20947 [D loss: 0.448141, acc.: 78.91%] [G loss: 1.281056]\n",
      "epoch:22 step:20948 [D loss: 0.495361, acc.: 79.69%] [G loss: 1.121682]\n",
      "epoch:22 step:20949 [D loss: 0.596740, acc.: 67.97%] [G loss: 0.804521]\n",
      "epoch:22 step:20950 [D loss: 0.413906, acc.: 83.59%] [G loss: 1.458860]\n",
      "epoch:22 step:20951 [D loss: 0.640728, acc.: 64.84%] [G loss: 1.260228]\n",
      "epoch:22 step:20952 [D loss: 0.466131, acc.: 78.91%] [G loss: 1.394843]\n",
      "epoch:22 step:20953 [D loss: 0.418720, acc.: 85.94%] [G loss: 1.728342]\n",
      "epoch:22 step:20954 [D loss: 0.674840, acc.: 57.03%] [G loss: 1.241510]\n",
      "epoch:22 step:20955 [D loss: 0.783062, acc.: 51.56%] [G loss: 1.195527]\n",
      "epoch:22 step:20956 [D loss: 0.593768, acc.: 66.41%] [G loss: 1.220698]\n",
      "epoch:22 step:20957 [D loss: 0.665948, acc.: 62.50%] [G loss: 1.426223]\n",
      "epoch:22 step:20958 [D loss: 0.526181, acc.: 74.22%] [G loss: 1.416924]\n",
      "epoch:22 step:20959 [D loss: 0.442236, acc.: 85.16%] [G loss: 1.267591]\n",
      "epoch:22 step:20960 [D loss: 0.619053, acc.: 67.97%] [G loss: 1.227798]\n",
      "epoch:22 step:20961 [D loss: 0.631996, acc.: 65.62%] [G loss: 1.323792]\n",
      "epoch:22 step:20962 [D loss: 0.572304, acc.: 69.53%] [G loss: 1.638472]\n",
      "epoch:22 step:20963 [D loss: 0.389430, acc.: 87.50%] [G loss: 1.119160]\n",
      "epoch:22 step:20964 [D loss: 0.503459, acc.: 72.66%] [G loss: 1.298464]\n",
      "epoch:22 step:20965 [D loss: 0.630512, acc.: 63.28%] [G loss: 1.039616]\n",
      "epoch:22 step:20966 [D loss: 0.650348, acc.: 60.16%] [G loss: 0.984775]\n",
      "epoch:22 step:20967 [D loss: 0.565815, acc.: 71.88%] [G loss: 1.047623]\n",
      "epoch:22 step:20968 [D loss: 0.409921, acc.: 85.16%] [G loss: 1.581705]\n",
      "epoch:22 step:20969 [D loss: 0.642567, acc.: 65.62%] [G loss: 1.085147]\n",
      "epoch:22 step:20970 [D loss: 0.473356, acc.: 79.69%] [G loss: 1.233886]\n",
      "epoch:22 step:20971 [D loss: 0.585464, acc.: 68.75%] [G loss: 1.060035]\n",
      "epoch:22 step:20972 [D loss: 0.753396, acc.: 53.12%] [G loss: 0.991525]\n",
      "epoch:22 step:20973 [D loss: 0.570762, acc.: 68.75%] [G loss: 0.957690]\n",
      "epoch:22 step:20974 [D loss: 0.560087, acc.: 70.31%] [G loss: 1.226003]\n",
      "epoch:22 step:20975 [D loss: 0.573839, acc.: 71.09%] [G loss: 1.183324]\n",
      "epoch:22 step:20976 [D loss: 0.711928, acc.: 52.34%] [G loss: 0.976517]\n",
      "epoch:22 step:20977 [D loss: 0.531135, acc.: 75.00%] [G loss: 1.461184]\n",
      "epoch:22 step:20978 [D loss: 0.589378, acc.: 70.31%] [G loss: 1.339621]\n",
      "epoch:22 step:20979 [D loss: 0.664521, acc.: 60.16%] [G loss: 1.163521]\n",
      "epoch:22 step:20980 [D loss: 0.527644, acc.: 71.88%] [G loss: 1.443959]\n",
      "epoch:22 step:20981 [D loss: 0.823773, acc.: 46.09%] [G loss: 1.233115]\n",
      "epoch:22 step:20982 [D loss: 0.510213, acc.: 75.00%] [G loss: 1.387903]\n",
      "epoch:22 step:20983 [D loss: 0.545388, acc.: 72.66%] [G loss: 1.306554]\n",
      "epoch:22 step:20984 [D loss: 0.654489, acc.: 64.84%] [G loss: 1.075908]\n",
      "epoch:22 step:20985 [D loss: 0.539010, acc.: 71.09%] [G loss: 1.134923]\n",
      "epoch:22 step:20986 [D loss: 0.599800, acc.: 67.19%] [G loss: 1.580663]\n",
      "epoch:22 step:20987 [D loss: 0.506726, acc.: 73.44%] [G loss: 1.393463]\n",
      "epoch:22 step:20988 [D loss: 0.714426, acc.: 58.59%] [G loss: 1.135699]\n",
      "epoch:22 step:20989 [D loss: 0.573654, acc.: 67.97%] [G loss: 1.153520]\n",
      "epoch:22 step:20990 [D loss: 0.679110, acc.: 62.50%] [G loss: 1.069911]\n",
      "epoch:22 step:20991 [D loss: 0.446667, acc.: 78.12%] [G loss: 1.075025]\n",
      "epoch:22 step:20992 [D loss: 0.588513, acc.: 65.62%] [G loss: 1.004010]\n",
      "epoch:22 step:20993 [D loss: 0.628731, acc.: 64.06%] [G loss: 1.218172]\n",
      "epoch:22 step:20994 [D loss: 0.563606, acc.: 69.53%] [G loss: 1.168216]\n",
      "epoch:22 step:20995 [D loss: 0.566925, acc.: 69.53%] [G loss: 1.613630]\n",
      "epoch:22 step:20996 [D loss: 0.668921, acc.: 59.38%] [G loss: 1.006929]\n",
      "epoch:22 step:20997 [D loss: 0.622117, acc.: 67.19%] [G loss: 1.232913]\n",
      "epoch:22 step:20998 [D loss: 0.414274, acc.: 83.59%] [G loss: 1.487186]\n",
      "epoch:22 step:20999 [D loss: 0.571009, acc.: 68.75%] [G loss: 1.132538]\n",
      "epoch:22 step:21000 [D loss: 0.708568, acc.: 58.59%] [G loss: 1.291764]\n",
      "epoch:22 step:21001 [D loss: 0.493561, acc.: 73.44%] [G loss: 1.398044]\n",
      "epoch:22 step:21002 [D loss: 0.672457, acc.: 64.06%] [G loss: 1.506814]\n",
      "epoch:22 step:21003 [D loss: 0.605858, acc.: 67.97%] [G loss: 1.307237]\n",
      "epoch:22 step:21004 [D loss: 0.588301, acc.: 69.53%] [G loss: 1.466154]\n",
      "epoch:22 step:21005 [D loss: 0.541329, acc.: 71.09%] [G loss: 1.434489]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:22 step:21006 [D loss: 0.496061, acc.: 78.12%] [G loss: 1.512465]\n",
      "epoch:22 step:21007 [D loss: 0.495244, acc.: 76.56%] [G loss: 1.259728]\n",
      "epoch:22 step:21008 [D loss: 0.648546, acc.: 57.81%] [G loss: 1.195916]\n",
      "epoch:22 step:21009 [D loss: 0.415193, acc.: 81.25%] [G loss: 1.364263]\n",
      "epoch:22 step:21010 [D loss: 0.475191, acc.: 77.34%] [G loss: 1.194777]\n",
      "epoch:22 step:21011 [D loss: 0.673529, acc.: 60.16%] [G loss: 1.594738]\n",
      "epoch:22 step:21012 [D loss: 0.583655, acc.: 67.97%] [G loss: 1.406567]\n",
      "epoch:22 step:21013 [D loss: 0.493746, acc.: 76.56%] [G loss: 1.214841]\n",
      "epoch:22 step:21014 [D loss: 0.589212, acc.: 64.84%] [G loss: 1.174609]\n",
      "epoch:22 step:21015 [D loss: 0.658058, acc.: 61.72%] [G loss: 1.167183]\n",
      "epoch:22 step:21016 [D loss: 0.461666, acc.: 76.56%] [G loss: 1.515887]\n",
      "epoch:22 step:21017 [D loss: 0.601441, acc.: 70.31%] [G loss: 1.605244]\n",
      "epoch:22 step:21018 [D loss: 0.654787, acc.: 64.06%] [G loss: 1.168355]\n",
      "epoch:22 step:21019 [D loss: 0.475716, acc.: 76.56%] [G loss: 1.518339]\n",
      "epoch:22 step:21020 [D loss: 0.427017, acc.: 82.81%] [G loss: 1.531582]\n",
      "epoch:22 step:21021 [D loss: 0.787586, acc.: 48.44%] [G loss: 1.130303]\n",
      "epoch:22 step:21022 [D loss: 0.491966, acc.: 79.69%] [G loss: 1.236430]\n",
      "epoch:22 step:21023 [D loss: 0.636502, acc.: 65.62%] [G loss: 1.216442]\n",
      "epoch:22 step:21024 [D loss: 0.650525, acc.: 66.41%] [G loss: 1.003875]\n",
      "epoch:22 step:21025 [D loss: 0.350678, acc.: 91.41%] [G loss: 1.221107]\n",
      "epoch:22 step:21026 [D loss: 0.485479, acc.: 80.47%] [G loss: 1.094029]\n",
      "epoch:22 step:21027 [D loss: 0.626932, acc.: 63.28%] [G loss: 1.233282]\n",
      "epoch:22 step:21028 [D loss: 0.474011, acc.: 77.34%] [G loss: 1.450317]\n",
      "epoch:22 step:21029 [D loss: 0.508193, acc.: 78.91%] [G loss: 1.236111]\n",
      "epoch:22 step:21030 [D loss: 0.661843, acc.: 60.16%] [G loss: 1.409805]\n",
      "epoch:22 step:21031 [D loss: 0.662954, acc.: 68.75%] [G loss: 1.047429]\n",
      "epoch:22 step:21032 [D loss: 0.473849, acc.: 76.56%] [G loss: 1.146768]\n",
      "epoch:22 step:21033 [D loss: 0.655170, acc.: 61.72%] [G loss: 1.141519]\n",
      "epoch:22 step:21034 [D loss: 0.451170, acc.: 89.06%] [G loss: 1.332532]\n",
      "epoch:22 step:21035 [D loss: 0.603262, acc.: 70.31%] [G loss: 1.223606]\n",
      "epoch:22 step:21036 [D loss: 0.625985, acc.: 67.19%] [G loss: 1.455456]\n",
      "epoch:22 step:21037 [D loss: 0.594644, acc.: 67.97%] [G loss: 1.214606]\n",
      "epoch:22 step:21038 [D loss: 0.582814, acc.: 64.06%] [G loss: 1.198263]\n",
      "epoch:22 step:21039 [D loss: 0.563476, acc.: 70.31%] [G loss: 1.368328]\n",
      "epoch:22 step:21040 [D loss: 0.724316, acc.: 56.25%] [G loss: 1.142504]\n",
      "epoch:22 step:21041 [D loss: 0.753190, acc.: 53.91%] [G loss: 1.513586]\n",
      "epoch:22 step:21042 [D loss: 0.641255, acc.: 64.06%] [G loss: 1.387088]\n",
      "epoch:22 step:21043 [D loss: 0.586537, acc.: 71.09%] [G loss: 1.147909]\n",
      "epoch:22 step:21044 [D loss: 0.503096, acc.: 78.91%] [G loss: 1.203005]\n",
      "epoch:22 step:21045 [D loss: 0.575021, acc.: 70.31%] [G loss: 1.110260]\n",
      "epoch:22 step:21046 [D loss: 0.416110, acc.: 81.25%] [G loss: 1.433524]\n",
      "epoch:22 step:21047 [D loss: 0.560898, acc.: 74.22%] [G loss: 1.544222]\n",
      "epoch:22 step:21048 [D loss: 0.575570, acc.: 68.75%] [G loss: 1.444100]\n",
      "epoch:22 step:21049 [D loss: 0.542467, acc.: 74.22%] [G loss: 1.461023]\n",
      "epoch:22 step:21050 [D loss: 0.462105, acc.: 81.25%] [G loss: 1.349265]\n",
      "epoch:22 step:21051 [D loss: 0.544422, acc.: 72.66%] [G loss: 1.321074]\n",
      "epoch:22 step:21052 [D loss: 0.562115, acc.: 67.19%] [G loss: 1.758256]\n",
      "epoch:22 step:21053 [D loss: 0.607160, acc.: 66.41%] [G loss: 1.081387]\n",
      "epoch:22 step:21054 [D loss: 0.494642, acc.: 78.91%] [G loss: 1.523774]\n",
      "epoch:22 step:21055 [D loss: 0.421874, acc.: 82.03%] [G loss: 1.472540]\n",
      "epoch:22 step:21056 [D loss: 0.608296, acc.: 64.84%] [G loss: 1.466928]\n",
      "epoch:22 step:21057 [D loss: 0.535776, acc.: 73.44%] [G loss: 1.607252]\n",
      "epoch:22 step:21058 [D loss: 0.519365, acc.: 70.31%] [G loss: 1.624700]\n",
      "epoch:22 step:21059 [D loss: 0.485181, acc.: 77.34%] [G loss: 1.586081]\n",
      "epoch:22 step:21060 [D loss: 0.624326, acc.: 68.75%] [G loss: 1.631826]\n",
      "epoch:22 step:21061 [D loss: 0.618707, acc.: 63.28%] [G loss: 1.382695]\n",
      "epoch:22 step:21062 [D loss: 0.563513, acc.: 65.62%] [G loss: 1.637918]\n",
      "epoch:22 step:21063 [D loss: 0.526227, acc.: 76.56%] [G loss: 1.328101]\n",
      "epoch:22 step:21064 [D loss: 0.627508, acc.: 59.38%] [G loss: 1.457005]\n",
      "epoch:22 step:21065 [D loss: 0.450060, acc.: 82.03%] [G loss: 1.390380]\n",
      "epoch:22 step:21066 [D loss: 0.469058, acc.: 81.25%] [G loss: 1.174228]\n",
      "epoch:22 step:21067 [D loss: 0.470999, acc.: 81.25%] [G loss: 1.439343]\n",
      "epoch:22 step:21068 [D loss: 0.508871, acc.: 79.69%] [G loss: 1.058636]\n",
      "epoch:22 step:21069 [D loss: 0.460563, acc.: 76.56%] [G loss: 1.394881]\n",
      "epoch:22 step:21070 [D loss: 0.702638, acc.: 57.81%] [G loss: 1.639214]\n",
      "epoch:22 step:21071 [D loss: 0.933412, acc.: 37.50%] [G loss: 1.201959]\n",
      "epoch:22 step:21072 [D loss: 0.477316, acc.: 79.69%] [G loss: 1.331927]\n",
      "epoch:22 step:21073 [D loss: 0.522128, acc.: 73.44%] [G loss: 1.353987]\n",
      "epoch:22 step:21074 [D loss: 0.618571, acc.: 64.06%] [G loss: 1.564617]\n",
      "epoch:22 step:21075 [D loss: 0.528922, acc.: 72.66%] [G loss: 1.451443]\n",
      "epoch:22 step:21076 [D loss: 0.404111, acc.: 85.94%] [G loss: 1.209592]\n",
      "epoch:22 step:21077 [D loss: 0.533438, acc.: 71.09%] [G loss: 1.551919]\n",
      "epoch:22 step:21078 [D loss: 0.523788, acc.: 73.44%] [G loss: 0.923010]\n",
      "epoch:22 step:21079 [D loss: 0.540758, acc.: 69.53%] [G loss: 1.228837]\n",
      "epoch:22 step:21080 [D loss: 0.577577, acc.: 70.31%] [G loss: 1.349038]\n",
      "epoch:22 step:21081 [D loss: 0.560114, acc.: 71.09%] [G loss: 1.192208]\n",
      "epoch:22 step:21082 [D loss: 0.498014, acc.: 75.00%] [G loss: 1.284126]\n",
      "epoch:22 step:21083 [D loss: 0.531720, acc.: 75.78%] [G loss: 1.640854]\n",
      "epoch:22 step:21084 [D loss: 0.731253, acc.: 53.91%] [G loss: 1.201285]\n",
      "epoch:22 step:21085 [D loss: 0.472167, acc.: 76.56%] [G loss: 1.226698]\n",
      "epoch:22 step:21086 [D loss: 0.598683, acc.: 68.75%] [G loss: 1.135450]\n",
      "epoch:22 step:21087 [D loss: 0.590881, acc.: 67.97%] [G loss: 1.213008]\n",
      "epoch:22 step:21088 [D loss: 0.484188, acc.: 78.91%] [G loss: 1.498715]\n",
      "epoch:22 step:21089 [D loss: 0.659926, acc.: 60.94%] [G loss: 1.080499]\n",
      "epoch:22 step:21090 [D loss: 0.502287, acc.: 81.25%] [G loss: 1.207587]\n",
      "epoch:22 step:21091 [D loss: 0.470056, acc.: 78.91%] [G loss: 1.024047]\n",
      "epoch:22 step:21092 [D loss: 0.585265, acc.: 69.53%] [G loss: 1.317355]\n",
      "epoch:22 step:21093 [D loss: 0.471871, acc.: 75.00%] [G loss: 1.393472]\n",
      "epoch:22 step:21094 [D loss: 0.630920, acc.: 64.84%] [G loss: 1.301620]\n",
      "epoch:22 step:21095 [D loss: 0.585517, acc.: 67.19%] [G loss: 1.341134]\n",
      "epoch:22 step:21096 [D loss: 0.489949, acc.: 81.25%] [G loss: 1.232535]\n",
      "epoch:22 step:21097 [D loss: 0.502845, acc.: 74.22%] [G loss: 1.233733]\n",
      "epoch:22 step:21098 [D loss: 0.546692, acc.: 70.31%] [G loss: 1.276498]\n",
      "epoch:22 step:21099 [D loss: 0.676742, acc.: 59.38%] [G loss: 0.974211]\n",
      "epoch:22 step:21100 [D loss: 0.618828, acc.: 62.50%] [G loss: 1.329137]\n",
      "epoch:22 step:21101 [D loss: 0.720694, acc.: 56.25%] [G loss: 1.339382]\n",
      "epoch:22 step:21102 [D loss: 0.506067, acc.: 75.00%] [G loss: 1.349094]\n",
      "epoch:22 step:21103 [D loss: 0.730025, acc.: 57.03%] [G loss: 1.103588]\n",
      "epoch:22 step:21104 [D loss: 0.428607, acc.: 81.25%] [G loss: 1.512834]\n",
      "epoch:22 step:21105 [D loss: 0.672685, acc.: 63.28%] [G loss: 1.425283]\n",
      "epoch:22 step:21106 [D loss: 0.470653, acc.: 79.69%] [G loss: 1.546675]\n",
      "epoch:22 step:21107 [D loss: 0.445389, acc.: 82.03%] [G loss: 1.853412]\n",
      "epoch:22 step:21108 [D loss: 0.547650, acc.: 71.88%] [G loss: 0.950605]\n",
      "epoch:22 step:21109 [D loss: 0.590024, acc.: 71.09%] [G loss: 1.208255]\n",
      "epoch:22 step:21110 [D loss: 0.624282, acc.: 63.28%] [G loss: 1.317808]\n",
      "epoch:22 step:21111 [D loss: 0.459796, acc.: 80.47%] [G loss: 1.490870]\n",
      "epoch:22 step:21112 [D loss: 0.549037, acc.: 72.66%] [G loss: 1.302561]\n",
      "epoch:22 step:21113 [D loss: 0.389105, acc.: 87.50%] [G loss: 1.565315]\n",
      "epoch:22 step:21114 [D loss: 0.696527, acc.: 61.72%] [G loss: 1.315721]\n",
      "epoch:22 step:21115 [D loss: 0.509981, acc.: 76.56%] [G loss: 1.241719]\n",
      "epoch:22 step:21116 [D loss: 0.645696, acc.: 73.44%] [G loss: 1.453097]\n",
      "epoch:22 step:21117 [D loss: 0.424972, acc.: 83.59%] [G loss: 1.945923]\n",
      "epoch:22 step:21118 [D loss: 0.575983, acc.: 68.75%] [G loss: 1.896587]\n",
      "epoch:22 step:21119 [D loss: 0.566794, acc.: 67.19%] [G loss: 1.447241]\n",
      "epoch:22 step:21120 [D loss: 0.520684, acc.: 71.88%] [G loss: 0.980669]\n",
      "epoch:22 step:21121 [D loss: 0.690434, acc.: 60.16%] [G loss: 1.171785]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:22 step:21122 [D loss: 0.533204, acc.: 75.00%] [G loss: 1.163390]\n",
      "epoch:22 step:21123 [D loss: 0.531096, acc.: 75.00%] [G loss: 1.315113]\n",
      "epoch:22 step:21124 [D loss: 0.506557, acc.: 72.66%] [G loss: 1.737216]\n",
      "epoch:22 step:21125 [D loss: 0.425870, acc.: 81.25%] [G loss: 1.593526]\n",
      "epoch:22 step:21126 [D loss: 0.490696, acc.: 78.12%] [G loss: 1.579887]\n",
      "epoch:22 step:21127 [D loss: 0.516224, acc.: 74.22%] [G loss: 1.466941]\n",
      "epoch:22 step:21128 [D loss: 0.492874, acc.: 74.22%] [G loss: 1.409977]\n",
      "epoch:22 step:21129 [D loss: 0.510151, acc.: 81.25%] [G loss: 1.563215]\n",
      "epoch:22 step:21130 [D loss: 0.566188, acc.: 71.88%] [G loss: 1.210466]\n",
      "epoch:22 step:21131 [D loss: 0.410936, acc.: 87.50%] [G loss: 1.550679]\n",
      "epoch:22 step:21132 [D loss: 0.568462, acc.: 72.66%] [G loss: 1.242858]\n",
      "epoch:22 step:21133 [D loss: 0.572391, acc.: 68.75%] [G loss: 1.024832]\n",
      "epoch:22 step:21134 [D loss: 0.624484, acc.: 64.06%] [G loss: 1.401346]\n",
      "epoch:22 step:21135 [D loss: 0.634607, acc.: 65.62%] [G loss: 1.304054]\n",
      "epoch:22 step:21136 [D loss: 0.601515, acc.: 66.41%] [G loss: 1.086516]\n",
      "epoch:22 step:21137 [D loss: 0.565143, acc.: 70.31%] [G loss: 1.243257]\n",
      "epoch:22 step:21138 [D loss: 0.501019, acc.: 76.56%] [G loss: 1.168794]\n",
      "epoch:22 step:21139 [D loss: 0.581823, acc.: 72.66%] [G loss: 1.409864]\n",
      "epoch:22 step:21140 [D loss: 0.622920, acc.: 63.28%] [G loss: 1.037088]\n",
      "epoch:22 step:21141 [D loss: 0.494586, acc.: 78.12%] [G loss: 1.272281]\n",
      "epoch:22 step:21142 [D loss: 0.466823, acc.: 80.47%] [G loss: 1.395815]\n",
      "epoch:22 step:21143 [D loss: 0.653978, acc.: 62.50%] [G loss: 1.338894]\n",
      "epoch:22 step:21144 [D loss: 0.604207, acc.: 66.41%] [G loss: 1.257972]\n",
      "epoch:22 step:21145 [D loss: 0.548339, acc.: 73.44%] [G loss: 1.529050]\n",
      "epoch:22 step:21146 [D loss: 0.739219, acc.: 57.81%] [G loss: 1.343983]\n",
      "epoch:22 step:21147 [D loss: 0.443481, acc.: 79.69%] [G loss: 1.411258]\n",
      "epoch:22 step:21148 [D loss: 0.619544, acc.: 67.19%] [G loss: 1.486850]\n",
      "epoch:22 step:21149 [D loss: 0.619686, acc.: 61.72%] [G loss: 1.197775]\n",
      "epoch:22 step:21150 [D loss: 0.589857, acc.: 69.53%] [G loss: 1.164664]\n",
      "epoch:22 step:21151 [D loss: 0.596168, acc.: 67.97%] [G loss: 1.459033]\n",
      "epoch:22 step:21152 [D loss: 0.634162, acc.: 62.50%] [G loss: 1.303056]\n",
      "epoch:22 step:21153 [D loss: 0.512366, acc.: 73.44%] [G loss: 1.250932]\n",
      "epoch:22 step:21154 [D loss: 0.400713, acc.: 85.16%] [G loss: 1.546745]\n",
      "epoch:22 step:21155 [D loss: 0.661321, acc.: 60.16%] [G loss: 1.477111]\n",
      "epoch:22 step:21156 [D loss: 0.509567, acc.: 72.66%] [G loss: 1.607360]\n",
      "epoch:22 step:21157 [D loss: 0.607328, acc.: 65.62%] [G loss: 1.053853]\n",
      "epoch:22 step:21158 [D loss: 0.504697, acc.: 74.22%] [G loss: 1.657723]\n",
      "epoch:22 step:21159 [D loss: 0.596830, acc.: 68.75%] [G loss: 1.209799]\n",
      "epoch:22 step:21160 [D loss: 0.616295, acc.: 65.62%] [G loss: 1.249862]\n",
      "epoch:22 step:21161 [D loss: 0.557230, acc.: 74.22%] [G loss: 1.556127]\n",
      "epoch:22 step:21162 [D loss: 0.803211, acc.: 48.44%] [G loss: 1.261538]\n",
      "epoch:22 step:21163 [D loss: 0.580723, acc.: 67.19%] [G loss: 1.109322]\n",
      "epoch:22 step:21164 [D loss: 0.541925, acc.: 75.00%] [G loss: 1.407263]\n",
      "epoch:22 step:21165 [D loss: 0.550156, acc.: 73.44%] [G loss: 1.377090]\n",
      "epoch:22 step:21166 [D loss: 0.421253, acc.: 85.16%] [G loss: 1.461148]\n",
      "epoch:22 step:21167 [D loss: 0.433755, acc.: 78.12%] [G loss: 1.354136]\n",
      "epoch:22 step:21168 [D loss: 0.560319, acc.: 71.09%] [G loss: 1.380285]\n",
      "epoch:22 step:21169 [D loss: 0.628490, acc.: 66.41%] [G loss: 1.182771]\n",
      "epoch:22 step:21170 [D loss: 0.501936, acc.: 75.78%] [G loss: 1.475324]\n",
      "epoch:22 step:21171 [D loss: 0.549328, acc.: 71.88%] [G loss: 1.255999]\n",
      "epoch:22 step:21172 [D loss: 0.597957, acc.: 67.19%] [G loss: 1.337110]\n",
      "epoch:22 step:21173 [D loss: 0.535867, acc.: 71.09%] [G loss: 1.396705]\n",
      "epoch:22 step:21174 [D loss: 0.484692, acc.: 78.12%] [G loss: 1.277550]\n",
      "epoch:22 step:21175 [D loss: 0.491526, acc.: 73.44%] [G loss: 1.099975]\n",
      "epoch:22 step:21176 [D loss: 0.540761, acc.: 72.66%] [G loss: 1.126405]\n",
      "epoch:22 step:21177 [D loss: 0.552529, acc.: 73.44%] [G loss: 1.329095]\n",
      "epoch:22 step:21178 [D loss: 0.528153, acc.: 73.44%] [G loss: 1.069978]\n",
      "epoch:22 step:21179 [D loss: 0.586520, acc.: 68.75%] [G loss: 1.663792]\n",
      "epoch:22 step:21180 [D loss: 0.546856, acc.: 71.88%] [G loss: 1.879657]\n",
      "epoch:22 step:21181 [D loss: 0.418353, acc.: 86.72%] [G loss: 1.607115]\n",
      "epoch:22 step:21182 [D loss: 0.639184, acc.: 63.28%] [G loss: 1.478047]\n",
      "epoch:22 step:21183 [D loss: 0.656683, acc.: 62.50%] [G loss: 1.408547]\n",
      "epoch:22 step:21184 [D loss: 0.477457, acc.: 81.25%] [G loss: 1.749649]\n",
      "epoch:22 step:21185 [D loss: 0.674344, acc.: 61.72%] [G loss: 1.213921]\n",
      "epoch:22 step:21186 [D loss: 0.494244, acc.: 79.69%] [G loss: 1.317841]\n",
      "epoch:22 step:21187 [D loss: 0.546699, acc.: 73.44%] [G loss: 1.426899]\n",
      "epoch:22 step:21188 [D loss: 0.687210, acc.: 63.28%] [G loss: 0.958347]\n",
      "epoch:22 step:21189 [D loss: 0.740824, acc.: 53.91%] [G loss: 1.277960]\n",
      "epoch:22 step:21190 [D loss: 0.365532, acc.: 88.28%] [G loss: 1.537995]\n",
      "epoch:22 step:21191 [D loss: 0.643349, acc.: 57.03%] [G loss: 1.317892]\n",
      "epoch:22 step:21192 [D loss: 0.561530, acc.: 72.66%] [G loss: 1.310388]\n",
      "epoch:22 step:21193 [D loss: 0.580094, acc.: 67.97%] [G loss: 1.385927]\n",
      "epoch:22 step:21194 [D loss: 0.504918, acc.: 75.78%] [G loss: 1.250669]\n",
      "epoch:22 step:21195 [D loss: 0.543999, acc.: 71.09%] [G loss: 1.087955]\n",
      "epoch:22 step:21196 [D loss: 0.645339, acc.: 60.94%] [G loss: 1.558228]\n",
      "epoch:22 step:21197 [D loss: 0.603313, acc.: 67.97%] [G loss: 1.297641]\n",
      "epoch:22 step:21198 [D loss: 0.581201, acc.: 66.41%] [G loss: 1.268015]\n",
      "epoch:22 step:21199 [D loss: 0.620666, acc.: 58.59%] [G loss: 1.444060]\n",
      "epoch:22 step:21200 [D loss: 0.537023, acc.: 76.56%] [G loss: 1.349629]\n",
      "epoch:22 step:21201 [D loss: 0.548735, acc.: 67.19%] [G loss: 1.645068]\n",
      "epoch:22 step:21202 [D loss: 0.636605, acc.: 64.84%] [G loss: 1.415550]\n",
      "epoch:22 step:21203 [D loss: 0.609031, acc.: 65.62%] [G loss: 1.592852]\n",
      "epoch:22 step:21204 [D loss: 0.415563, acc.: 84.38%] [G loss: 1.530200]\n",
      "epoch:22 step:21205 [D loss: 0.592956, acc.: 67.19%] [G loss: 1.380908]\n",
      "epoch:22 step:21206 [D loss: 0.591209, acc.: 71.88%] [G loss: 1.217307]\n",
      "epoch:22 step:21207 [D loss: 0.493632, acc.: 76.56%] [G loss: 1.208553]\n",
      "epoch:22 step:21208 [D loss: 0.545329, acc.: 75.00%] [G loss: 1.701699]\n",
      "epoch:22 step:21209 [D loss: 0.595824, acc.: 69.53%] [G loss: 1.472377]\n",
      "epoch:22 step:21210 [D loss: 0.484560, acc.: 75.00%] [G loss: 1.427061]\n",
      "epoch:22 step:21211 [D loss: 0.652353, acc.: 69.53%] [G loss: 1.415420]\n",
      "epoch:22 step:21212 [D loss: 0.522509, acc.: 72.66%] [G loss: 1.529545]\n",
      "epoch:22 step:21213 [D loss: 0.518304, acc.: 76.56%] [G loss: 1.717802]\n",
      "epoch:22 step:21214 [D loss: 0.531327, acc.: 76.56%] [G loss: 1.072811]\n",
      "epoch:22 step:21215 [D loss: 0.712462, acc.: 53.91%] [G loss: 1.383988]\n",
      "epoch:22 step:21216 [D loss: 0.526208, acc.: 76.56%] [G loss: 1.589271]\n",
      "epoch:22 step:21217 [D loss: 0.582597, acc.: 71.88%] [G loss: 1.321890]\n",
      "epoch:22 step:21218 [D loss: 0.622063, acc.: 64.06%] [G loss: 1.194201]\n",
      "epoch:22 step:21219 [D loss: 0.471344, acc.: 82.03%] [G loss: 1.282213]\n",
      "epoch:22 step:21220 [D loss: 0.488017, acc.: 78.91%] [G loss: 1.024101]\n",
      "epoch:22 step:21221 [D loss: 0.527447, acc.: 74.22%] [G loss: 1.400405]\n",
      "epoch:22 step:21222 [D loss: 0.619185, acc.: 64.06%] [G loss: 1.494765]\n",
      "epoch:22 step:21223 [D loss: 0.624050, acc.: 66.41%] [G loss: 1.286866]\n",
      "epoch:22 step:21224 [D loss: 0.481416, acc.: 79.69%] [G loss: 1.538857]\n",
      "epoch:22 step:21225 [D loss: 0.568410, acc.: 71.88%] [G loss: 1.367281]\n",
      "epoch:22 step:21226 [D loss: 0.591208, acc.: 66.41%] [G loss: 1.458914]\n",
      "epoch:22 step:21227 [D loss: 0.698024, acc.: 58.59%] [G loss: 1.486280]\n",
      "epoch:22 step:21228 [D loss: 0.563522, acc.: 72.66%] [G loss: 1.305060]\n",
      "epoch:22 step:21229 [D loss: 0.471910, acc.: 80.47%] [G loss: 1.577469]\n",
      "epoch:22 step:21230 [D loss: 0.551501, acc.: 71.09%] [G loss: 1.390671]\n",
      "epoch:22 step:21231 [D loss: 0.732103, acc.: 53.91%] [G loss: 1.114938]\n",
      "epoch:22 step:21232 [D loss: 0.524267, acc.: 71.88%] [G loss: 1.299303]\n",
      "epoch:22 step:21233 [D loss: 0.640590, acc.: 61.72%] [G loss: 1.280252]\n",
      "epoch:22 step:21234 [D loss: 0.517898, acc.: 75.78%] [G loss: 1.126272]\n",
      "epoch:22 step:21235 [D loss: 0.577097, acc.: 70.31%] [G loss: 1.342509]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:22 step:21236 [D loss: 0.702338, acc.: 64.84%] [G loss: 1.491851]\n",
      "epoch:22 step:21237 [D loss: 0.517240, acc.: 76.56%] [G loss: 1.341496]\n",
      "epoch:22 step:21238 [D loss: 0.600976, acc.: 68.75%] [G loss: 1.478197]\n",
      "epoch:22 step:21239 [D loss: 0.540670, acc.: 69.53%] [G loss: 1.498233]\n",
      "epoch:22 step:21240 [D loss: 0.607518, acc.: 66.41%] [G loss: 1.489610]\n",
      "epoch:22 step:21241 [D loss: 0.573175, acc.: 72.66%] [G loss: 1.409306]\n",
      "epoch:22 step:21242 [D loss: 0.547830, acc.: 73.44%] [G loss: 1.530380]\n",
      "epoch:22 step:21243 [D loss: 0.666467, acc.: 57.81%] [G loss: 1.239144]\n",
      "epoch:22 step:21244 [D loss: 0.560839, acc.: 72.66%] [G loss: 1.128126]\n",
      "epoch:22 step:21245 [D loss: 0.636850, acc.: 63.28%] [G loss: 1.232185]\n",
      "epoch:22 step:21246 [D loss: 0.504366, acc.: 77.34%] [G loss: 1.467377]\n",
      "epoch:22 step:21247 [D loss: 0.643342, acc.: 64.84%] [G loss: 1.624867]\n",
      "epoch:22 step:21248 [D loss: 0.610050, acc.: 70.31%] [G loss: 1.481429]\n",
      "epoch:22 step:21249 [D loss: 0.754222, acc.: 48.44%] [G loss: 1.222864]\n",
      "epoch:22 step:21250 [D loss: 0.502140, acc.: 78.12%] [G loss: 1.236548]\n",
      "epoch:22 step:21251 [D loss: 0.676345, acc.: 64.06%] [G loss: 1.293261]\n",
      "epoch:22 step:21252 [D loss: 0.546033, acc.: 72.66%] [G loss: 1.630270]\n",
      "epoch:22 step:21253 [D loss: 0.612520, acc.: 67.19%] [G loss: 1.375632]\n",
      "epoch:22 step:21254 [D loss: 0.576124, acc.: 66.41%] [G loss: 1.306566]\n",
      "epoch:22 step:21255 [D loss: 0.564609, acc.: 71.09%] [G loss: 1.351703]\n",
      "epoch:22 step:21256 [D loss: 0.481318, acc.: 75.78%] [G loss: 1.623177]\n",
      "epoch:22 step:21257 [D loss: 0.538517, acc.: 73.44%] [G loss: 1.131978]\n",
      "epoch:22 step:21258 [D loss: 0.606473, acc.: 67.19%] [G loss: 1.466273]\n",
      "epoch:22 step:21259 [D loss: 0.514250, acc.: 75.78%] [G loss: 1.407233]\n",
      "epoch:22 step:21260 [D loss: 0.588356, acc.: 70.31%] [G loss: 0.945899]\n",
      "epoch:22 step:21261 [D loss: 0.371336, acc.: 86.72%] [G loss: 1.999959]\n",
      "epoch:22 step:21262 [D loss: 0.442438, acc.: 82.03%] [G loss: 1.495776]\n",
      "epoch:22 step:21263 [D loss: 0.430445, acc.: 84.38%] [G loss: 1.545404]\n",
      "epoch:22 step:21264 [D loss: 0.578955, acc.: 67.19%] [G loss: 1.402524]\n",
      "epoch:22 step:21265 [D loss: 0.369114, acc.: 82.03%] [G loss: 1.825994]\n",
      "epoch:22 step:21266 [D loss: 0.541579, acc.: 74.22%] [G loss: 1.354196]\n",
      "epoch:22 step:21267 [D loss: 0.577948, acc.: 71.88%] [G loss: 1.332555]\n",
      "epoch:22 step:21268 [D loss: 0.570385, acc.: 69.53%] [G loss: 1.000425]\n",
      "epoch:22 step:21269 [D loss: 0.549490, acc.: 78.12%] [G loss: 1.183052]\n",
      "epoch:22 step:21270 [D loss: 0.621649, acc.: 61.72%] [G loss: 1.073311]\n",
      "epoch:22 step:21271 [D loss: 0.709941, acc.: 58.59%] [G loss: 1.287300]\n",
      "epoch:22 step:21272 [D loss: 0.546749, acc.: 68.75%] [G loss: 1.344100]\n",
      "epoch:22 step:21273 [D loss: 0.498759, acc.: 75.78%] [G loss: 1.555809]\n",
      "epoch:22 step:21274 [D loss: 0.723795, acc.: 61.72%] [G loss: 1.059287]\n",
      "epoch:22 step:21275 [D loss: 0.542260, acc.: 71.09%] [G loss: 1.141848]\n",
      "epoch:22 step:21276 [D loss: 0.501866, acc.: 78.12%] [G loss: 1.401695]\n",
      "epoch:22 step:21277 [D loss: 0.622517, acc.: 67.97%] [G loss: 1.108467]\n",
      "epoch:22 step:21278 [D loss: 0.518947, acc.: 73.44%] [G loss: 1.276599]\n",
      "epoch:22 step:21279 [D loss: 0.555434, acc.: 70.31%] [G loss: 1.336918]\n",
      "epoch:22 step:21280 [D loss: 0.460476, acc.: 78.12%] [G loss: 1.544345]\n",
      "epoch:22 step:21281 [D loss: 0.600723, acc.: 67.19%] [G loss: 1.343519]\n",
      "epoch:22 step:21282 [D loss: 0.641619, acc.: 63.28%] [G loss: 1.268707]\n",
      "epoch:22 step:21283 [D loss: 0.604347, acc.: 68.75%] [G loss: 1.571613]\n",
      "epoch:22 step:21284 [D loss: 0.643997, acc.: 68.75%] [G loss: 1.631936]\n",
      "epoch:22 step:21285 [D loss: 0.653889, acc.: 60.16%] [G loss: 1.284336]\n",
      "epoch:22 step:21286 [D loss: 0.472606, acc.: 76.56%] [G loss: 1.402912]\n",
      "epoch:22 step:21287 [D loss: 0.518593, acc.: 76.56%] [G loss: 1.504525]\n",
      "epoch:22 step:21288 [D loss: 0.574614, acc.: 68.75%] [G loss: 1.420370]\n",
      "epoch:22 step:21289 [D loss: 0.679160, acc.: 64.06%] [G loss: 1.325278]\n",
      "epoch:22 step:21290 [D loss: 0.440577, acc.: 82.03%] [G loss: 1.430562]\n",
      "epoch:22 step:21291 [D loss: 0.510139, acc.: 72.66%] [G loss: 1.192950]\n",
      "epoch:22 step:21292 [D loss: 0.695623, acc.: 57.03%] [G loss: 1.004395]\n",
      "epoch:22 step:21293 [D loss: 0.518719, acc.: 75.78%] [G loss: 1.010023]\n",
      "epoch:22 step:21294 [D loss: 0.712023, acc.: 55.47%] [G loss: 1.310930]\n",
      "epoch:22 step:21295 [D loss: 0.553649, acc.: 69.53%] [G loss: 1.501366]\n",
      "epoch:22 step:21296 [D loss: 0.610651, acc.: 65.62%] [G loss: 1.211650]\n",
      "epoch:22 step:21297 [D loss: 0.765306, acc.: 51.56%] [G loss: 1.173137]\n",
      "epoch:22 step:21298 [D loss: 0.685312, acc.: 61.72%] [G loss: 1.141198]\n",
      "epoch:22 step:21299 [D loss: 0.540689, acc.: 75.00%] [G loss: 1.421051]\n",
      "epoch:22 step:21300 [D loss: 0.554290, acc.: 71.09%] [G loss: 0.886542]\n",
      "epoch:22 step:21301 [D loss: 0.422494, acc.: 81.25%] [G loss: 1.733801]\n",
      "epoch:22 step:21302 [D loss: 0.669631, acc.: 58.59%] [G loss: 1.301061]\n",
      "epoch:22 step:21303 [D loss: 0.530693, acc.: 73.44%] [G loss: 1.406900]\n",
      "epoch:22 step:21304 [D loss: 0.537992, acc.: 71.88%] [G loss: 1.021724]\n",
      "epoch:22 step:21305 [D loss: 0.726376, acc.: 50.00%] [G loss: 1.248232]\n",
      "epoch:22 step:21306 [D loss: 0.526942, acc.: 72.66%] [G loss: 1.386929]\n",
      "epoch:22 step:21307 [D loss: 0.605991, acc.: 60.94%] [G loss: 1.424513]\n",
      "epoch:22 step:21308 [D loss: 0.611820, acc.: 67.19%] [G loss: 1.295370]\n",
      "epoch:22 step:21309 [D loss: 0.526411, acc.: 74.22%] [G loss: 1.600582]\n",
      "epoch:22 step:21310 [D loss: 0.587682, acc.: 69.53%] [G loss: 1.684535]\n",
      "epoch:22 step:21311 [D loss: 0.499324, acc.: 79.69%] [G loss: 1.379009]\n",
      "epoch:22 step:21312 [D loss: 0.522039, acc.: 75.78%] [G loss: 1.268560]\n",
      "epoch:22 step:21313 [D loss: 0.620434, acc.: 63.28%] [G loss: 1.114218]\n",
      "epoch:22 step:21314 [D loss: 0.514188, acc.: 72.66%] [G loss: 1.639186]\n",
      "epoch:22 step:21315 [D loss: 0.309720, acc.: 89.06%] [G loss: 1.832219]\n",
      "epoch:22 step:21316 [D loss: 0.474461, acc.: 83.59%] [G loss: 1.564232]\n",
      "epoch:22 step:21317 [D loss: 0.578312, acc.: 66.41%] [G loss: 1.207199]\n",
      "epoch:22 step:21318 [D loss: 0.806348, acc.: 49.22%] [G loss: 0.957120]\n",
      "epoch:22 step:21319 [D loss: 0.474467, acc.: 76.56%] [G loss: 1.423254]\n",
      "epoch:22 step:21320 [D loss: 0.638738, acc.: 60.16%] [G loss: 0.991284]\n",
      "epoch:22 step:21321 [D loss: 0.533194, acc.: 74.22%] [G loss: 1.093339]\n",
      "epoch:22 step:21322 [D loss: 0.525203, acc.: 76.56%] [G loss: 1.418347]\n",
      "epoch:22 step:21323 [D loss: 0.587278, acc.: 64.84%] [G loss: 1.267255]\n",
      "epoch:22 step:21324 [D loss: 0.402791, acc.: 85.16%] [G loss: 1.362979]\n",
      "epoch:22 step:21325 [D loss: 0.548897, acc.: 70.31%] [G loss: 1.556275]\n",
      "epoch:22 step:21326 [D loss: 0.635450, acc.: 65.62%] [G loss: 0.866272]\n",
      "epoch:22 step:21327 [D loss: 0.601565, acc.: 70.31%] [G loss: 1.270836]\n",
      "epoch:22 step:21328 [D loss: 0.529000, acc.: 75.00%] [G loss: 1.398416]\n",
      "epoch:22 step:21329 [D loss: 0.628372, acc.: 65.62%] [G loss: 1.472576]\n",
      "epoch:22 step:21330 [D loss: 0.579001, acc.: 71.09%] [G loss: 1.199085]\n",
      "epoch:22 step:21331 [D loss: 0.698903, acc.: 63.28%] [G loss: 1.185199]\n",
      "epoch:22 step:21332 [D loss: 0.514660, acc.: 76.56%] [G loss: 1.064424]\n",
      "epoch:22 step:21333 [D loss: 0.519302, acc.: 76.56%] [G loss: 1.496806]\n",
      "epoch:22 step:21334 [D loss: 0.579891, acc.: 61.72%] [G loss: 1.139577]\n",
      "epoch:22 step:21335 [D loss: 0.637489, acc.: 66.41%] [G loss: 1.273416]\n",
      "epoch:22 step:21336 [D loss: 0.671553, acc.: 61.72%] [G loss: 1.172128]\n",
      "epoch:22 step:21337 [D loss: 0.661910, acc.: 66.41%] [G loss: 1.376665]\n",
      "epoch:22 step:21338 [D loss: 0.541915, acc.: 73.44%] [G loss: 1.716693]\n",
      "epoch:22 step:21339 [D loss: 0.587444, acc.: 71.09%] [G loss: 1.347850]\n",
      "epoch:22 step:21340 [D loss: 0.555554, acc.: 65.62%] [G loss: 1.324350]\n",
      "epoch:22 step:21341 [D loss: 0.526978, acc.: 71.09%] [G loss: 1.320057]\n",
      "epoch:22 step:21342 [D loss: 0.642247, acc.: 62.50%] [G loss: 1.524305]\n",
      "epoch:22 step:21343 [D loss: 0.626966, acc.: 63.28%] [G loss: 1.253825]\n",
      "epoch:22 step:21344 [D loss: 0.850076, acc.: 46.09%] [G loss: 1.115424]\n",
      "epoch:22 step:21345 [D loss: 0.468858, acc.: 78.91%] [G loss: 1.288132]\n",
      "epoch:22 step:21346 [D loss: 0.597921, acc.: 65.62%] [G loss: 1.196834]\n",
      "epoch:22 step:21347 [D loss: 0.592122, acc.: 67.97%] [G loss: 1.327518]\n",
      "epoch:22 step:21348 [D loss: 0.496441, acc.: 78.91%] [G loss: 1.262069]\n",
      "epoch:22 step:21349 [D loss: 0.540025, acc.: 74.22%] [G loss: 1.478330]\n",
      "epoch:22 step:21350 [D loss: 0.375136, acc.: 85.94%] [G loss: 1.374870]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:22 step:21351 [D loss: 0.675768, acc.: 58.59%] [G loss: 1.286353]\n",
      "epoch:22 step:21352 [D loss: 0.690413, acc.: 59.38%] [G loss: 1.106679]\n",
      "epoch:22 step:21353 [D loss: 0.405145, acc.: 85.16%] [G loss: 1.401414]\n",
      "epoch:22 step:21354 [D loss: 0.676246, acc.: 59.38%] [G loss: 1.582915]\n",
      "epoch:22 step:21355 [D loss: 0.411716, acc.: 85.16%] [G loss: 1.495684]\n",
      "epoch:22 step:21356 [D loss: 0.569131, acc.: 67.97%] [G loss: 1.356328]\n",
      "epoch:22 step:21357 [D loss: 0.657861, acc.: 64.06%] [G loss: 1.674354]\n",
      "epoch:22 step:21358 [D loss: 0.645357, acc.: 61.72%] [G loss: 1.178359]\n",
      "epoch:22 step:21359 [D loss: 0.527790, acc.: 74.22%] [G loss: 1.249178]\n",
      "epoch:22 step:21360 [D loss: 0.593743, acc.: 67.97%] [G loss: 1.213918]\n",
      "epoch:22 step:21361 [D loss: 0.461546, acc.: 81.25%] [G loss: 1.422508]\n",
      "epoch:22 step:21362 [D loss: 0.616279, acc.: 66.41%] [G loss: 1.181711]\n",
      "epoch:22 step:21363 [D loss: 0.726990, acc.: 53.91%] [G loss: 1.280470]\n",
      "epoch:22 step:21364 [D loss: 0.601480, acc.: 65.62%] [G loss: 0.795297]\n",
      "epoch:22 step:21365 [D loss: 0.642683, acc.: 69.53%] [G loss: 0.799335]\n",
      "epoch:22 step:21366 [D loss: 0.580281, acc.: 70.31%] [G loss: 1.524139]\n",
      "epoch:22 step:21367 [D loss: 0.531038, acc.: 74.22%] [G loss: 1.261772]\n",
      "epoch:22 step:21368 [D loss: 0.515245, acc.: 77.34%] [G loss: 1.338135]\n",
      "epoch:22 step:21369 [D loss: 0.484303, acc.: 76.56%] [G loss: 1.548645]\n",
      "epoch:22 step:21370 [D loss: 0.640445, acc.: 60.16%] [G loss: 1.398709]\n",
      "epoch:22 step:21371 [D loss: 0.659755, acc.: 60.94%] [G loss: 1.157940]\n",
      "epoch:22 step:21372 [D loss: 0.559281, acc.: 69.53%] [G loss: 1.536143]\n",
      "epoch:22 step:21373 [D loss: 0.564307, acc.: 75.78%] [G loss: 1.244073]\n",
      "epoch:22 step:21374 [D loss: 0.608998, acc.: 67.97%] [G loss: 1.544708]\n",
      "epoch:22 step:21375 [D loss: 0.619057, acc.: 64.84%] [G loss: 1.145296]\n",
      "epoch:22 step:21376 [D loss: 0.543792, acc.: 70.31%] [G loss: 1.440770]\n",
      "epoch:22 step:21377 [D loss: 0.487753, acc.: 75.78%] [G loss: 1.150191]\n",
      "epoch:22 step:21378 [D loss: 0.441178, acc.: 83.59%] [G loss: 1.108062]\n",
      "epoch:22 step:21379 [D loss: 0.651685, acc.: 65.62%] [G loss: 1.388672]\n",
      "epoch:22 step:21380 [D loss: 0.430145, acc.: 82.81%] [G loss: 1.386134]\n",
      "epoch:22 step:21381 [D loss: 0.591138, acc.: 70.31%] [G loss: 1.497285]\n",
      "epoch:22 step:21382 [D loss: 0.536958, acc.: 74.22%] [G loss: 1.440377]\n",
      "epoch:22 step:21383 [D loss: 0.466222, acc.: 77.34%] [G loss: 1.387503]\n",
      "epoch:22 step:21384 [D loss: 0.555636, acc.: 71.88%] [G loss: 1.371671]\n",
      "epoch:22 step:21385 [D loss: 0.529486, acc.: 74.22%] [G loss: 1.277629]\n",
      "epoch:22 step:21386 [D loss: 0.538165, acc.: 74.22%] [G loss: 1.340616]\n",
      "epoch:22 step:21387 [D loss: 0.561586, acc.: 71.88%] [G loss: 1.197912]\n",
      "epoch:22 step:21388 [D loss: 0.483201, acc.: 77.34%] [G loss: 1.557029]\n",
      "epoch:22 step:21389 [D loss: 0.596272, acc.: 66.41%] [G loss: 1.496822]\n",
      "epoch:22 step:21390 [D loss: 0.607804, acc.: 64.06%] [G loss: 1.495767]\n",
      "epoch:22 step:21391 [D loss: 0.523229, acc.: 70.31%] [G loss: 1.200851]\n",
      "epoch:22 step:21392 [D loss: 0.458441, acc.: 77.34%] [G loss: 1.389290]\n",
      "epoch:22 step:21393 [D loss: 0.816905, acc.: 47.66%] [G loss: 1.377847]\n",
      "epoch:22 step:21394 [D loss: 0.524562, acc.: 75.78%] [G loss: 1.562917]\n",
      "epoch:22 step:21395 [D loss: 0.491186, acc.: 78.12%] [G loss: 1.389604]\n",
      "epoch:22 step:21396 [D loss: 0.524156, acc.: 73.44%] [G loss: 1.495850]\n",
      "epoch:22 step:21397 [D loss: 0.646440, acc.: 64.06%] [G loss: 1.340479]\n",
      "epoch:22 step:21398 [D loss: 0.715510, acc.: 55.47%] [G loss: 0.942589]\n",
      "epoch:22 step:21399 [D loss: 0.445808, acc.: 81.25%] [G loss: 1.704245]\n",
      "epoch:22 step:21400 [D loss: 0.486073, acc.: 80.47%] [G loss: 1.488249]\n",
      "epoch:22 step:21401 [D loss: 0.369861, acc.: 87.50%] [G loss: 1.177747]\n",
      "epoch:22 step:21402 [D loss: 0.556334, acc.: 69.53%] [G loss: 1.654502]\n",
      "epoch:22 step:21403 [D loss: 0.544116, acc.: 73.44%] [G loss: 1.421807]\n",
      "epoch:22 step:21404 [D loss: 0.438624, acc.: 81.25%] [G loss: 1.297948]\n",
      "epoch:22 step:21405 [D loss: 0.682083, acc.: 63.28%] [G loss: 1.387261]\n",
      "epoch:22 step:21406 [D loss: 0.515643, acc.: 75.78%] [G loss: 1.217752]\n",
      "epoch:22 step:21407 [D loss: 0.608545, acc.: 66.41%] [G loss: 1.491171]\n",
      "epoch:22 step:21408 [D loss: 0.498267, acc.: 79.69%] [G loss: 1.409335]\n",
      "epoch:22 step:21409 [D loss: 0.505904, acc.: 75.00%] [G loss: 1.363360]\n",
      "epoch:22 step:21410 [D loss: 0.490617, acc.: 79.69%] [G loss: 1.216334]\n",
      "epoch:22 step:21411 [D loss: 0.513590, acc.: 77.34%] [G loss: 1.406836]\n",
      "epoch:22 step:21412 [D loss: 0.548525, acc.: 76.56%] [G loss: 1.423273]\n",
      "epoch:22 step:21413 [D loss: 0.678387, acc.: 60.16%] [G loss: 0.951631]\n",
      "epoch:22 step:21414 [D loss: 0.514540, acc.: 75.78%] [G loss: 1.421825]\n",
      "epoch:22 step:21415 [D loss: 0.523236, acc.: 71.88%] [G loss: 1.141139]\n",
      "epoch:22 step:21416 [D loss: 0.520986, acc.: 69.53%] [G loss: 1.306294]\n",
      "epoch:22 step:21417 [D loss: 0.686248, acc.: 58.59%] [G loss: 1.266619]\n",
      "epoch:22 step:21418 [D loss: 0.479563, acc.: 80.47%] [G loss: 1.531201]\n",
      "epoch:22 step:21419 [D loss: 0.639040, acc.: 64.84%] [G loss: 1.279359]\n",
      "epoch:22 step:21420 [D loss: 0.529417, acc.: 78.91%] [G loss: 1.656571]\n",
      "epoch:22 step:21421 [D loss: 0.505749, acc.: 73.44%] [G loss: 1.522000]\n",
      "epoch:22 step:21422 [D loss: 0.525194, acc.: 71.09%] [G loss: 1.365509]\n",
      "epoch:22 step:21423 [D loss: 0.448244, acc.: 83.59%] [G loss: 1.150486]\n",
      "epoch:22 step:21424 [D loss: 0.494630, acc.: 78.91%] [G loss: 1.674980]\n",
      "epoch:22 step:21425 [D loss: 0.606709, acc.: 66.41%] [G loss: 1.552814]\n",
      "epoch:22 step:21426 [D loss: 0.664948, acc.: 57.81%] [G loss: 1.162465]\n",
      "epoch:22 step:21427 [D loss: 0.711030, acc.: 56.25%] [G loss: 1.182596]\n",
      "epoch:22 step:21428 [D loss: 0.551898, acc.: 75.78%] [G loss: 1.332783]\n",
      "epoch:22 step:21429 [D loss: 0.486941, acc.: 77.34%] [G loss: 1.275081]\n",
      "epoch:22 step:21430 [D loss: 0.557292, acc.: 66.41%] [G loss: 1.285028]\n",
      "epoch:22 step:21431 [D loss: 0.516223, acc.: 75.00%] [G loss: 1.190579]\n",
      "epoch:22 step:21432 [D loss: 0.546590, acc.: 72.66%] [G loss: 1.707644]\n",
      "epoch:22 step:21433 [D loss: 0.442490, acc.: 82.81%] [G loss: 1.373054]\n",
      "epoch:22 step:21434 [D loss: 0.711880, acc.: 57.03%] [G loss: 1.413168]\n",
      "epoch:22 step:21435 [D loss: 0.521189, acc.: 74.22%] [G loss: 1.491228]\n",
      "epoch:22 step:21436 [D loss: 0.530086, acc.: 73.44%] [G loss: 1.393716]\n",
      "epoch:22 step:21437 [D loss: 0.606285, acc.: 67.19%] [G loss: 1.493692]\n",
      "epoch:22 step:21438 [D loss: 0.542409, acc.: 75.78%] [G loss: 1.136868]\n",
      "epoch:22 step:21439 [D loss: 0.507360, acc.: 77.34%] [G loss: 1.101354]\n",
      "epoch:22 step:21440 [D loss: 0.555311, acc.: 71.09%] [G loss: 1.244238]\n",
      "epoch:22 step:21441 [D loss: 0.480576, acc.: 75.00%] [G loss: 1.481326]\n",
      "epoch:22 step:21442 [D loss: 0.557069, acc.: 70.31%] [G loss: 1.460295]\n",
      "epoch:22 step:21443 [D loss: 0.665359, acc.: 62.50%] [G loss: 1.191980]\n",
      "epoch:22 step:21444 [D loss: 0.530179, acc.: 75.00%] [G loss: 0.913450]\n",
      "epoch:22 step:21445 [D loss: 0.693761, acc.: 58.59%] [G loss: 0.895996]\n",
      "epoch:22 step:21446 [D loss: 0.399799, acc.: 85.16%] [G loss: 1.393204]\n",
      "epoch:22 step:21447 [D loss: 0.550030, acc.: 74.22%] [G loss: 1.234295]\n",
      "epoch:22 step:21448 [D loss: 0.648553, acc.: 68.75%] [G loss: 1.375178]\n",
      "epoch:22 step:21449 [D loss: 0.479933, acc.: 78.12%] [G loss: 1.178199]\n",
      "epoch:22 step:21450 [D loss: 0.604005, acc.: 67.19%] [G loss: 1.052789]\n",
      "epoch:22 step:21451 [D loss: 0.669091, acc.: 57.03%] [G loss: 1.305193]\n",
      "epoch:22 step:21452 [D loss: 0.539731, acc.: 71.09%] [G loss: 1.187074]\n",
      "epoch:22 step:21453 [D loss: 0.531909, acc.: 70.31%] [G loss: 1.233342]\n",
      "epoch:22 step:21454 [D loss: 0.517465, acc.: 72.66%] [G loss: 1.540938]\n",
      "epoch:22 step:21455 [D loss: 0.568502, acc.: 66.41%] [G loss: 1.553019]\n",
      "epoch:22 step:21456 [D loss: 0.540188, acc.: 72.66%] [G loss: 1.497190]\n",
      "epoch:22 step:21457 [D loss: 0.751790, acc.: 57.03%] [G loss: 1.378745]\n",
      "epoch:22 step:21458 [D loss: 0.782634, acc.: 51.56%] [G loss: 0.907440]\n",
      "epoch:22 step:21459 [D loss: 0.571557, acc.: 67.19%] [G loss: 1.326632]\n",
      "epoch:22 step:21460 [D loss: 0.567013, acc.: 67.19%] [G loss: 1.359731]\n",
      "epoch:22 step:21461 [D loss: 0.672768, acc.: 60.94%] [G loss: 0.841121]\n",
      "epoch:22 step:21462 [D loss: 0.517658, acc.: 75.78%] [G loss: 1.598437]\n",
      "epoch:22 step:21463 [D loss: 0.572338, acc.: 71.88%] [G loss: 1.191918]\n",
      "epoch:22 step:21464 [D loss: 0.406593, acc.: 83.59%] [G loss: 1.588422]\n",
      "epoch:22 step:21465 [D loss: 0.686427, acc.: 57.81%] [G loss: 1.152201]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:22 step:21466 [D loss: 0.543345, acc.: 79.69%] [G loss: 1.181855]\n",
      "epoch:22 step:21467 [D loss: 0.540558, acc.: 77.34%] [G loss: 1.545126]\n",
      "epoch:22 step:21468 [D loss: 0.598447, acc.: 65.62%] [G loss: 1.385464]\n",
      "epoch:22 step:21469 [D loss: 0.683822, acc.: 58.59%] [G loss: 1.425229]\n",
      "epoch:22 step:21470 [D loss: 0.437068, acc.: 79.69%] [G loss: 1.788909]\n",
      "epoch:22 step:21471 [D loss: 0.551575, acc.: 70.31%] [G loss: 1.145703]\n",
      "epoch:22 step:21472 [D loss: 0.483162, acc.: 76.56%] [G loss: 1.260368]\n",
      "epoch:22 step:21473 [D loss: 0.699237, acc.: 54.69%] [G loss: 1.658701]\n",
      "epoch:22 step:21474 [D loss: 0.417710, acc.: 82.03%] [G loss: 1.651506]\n",
      "epoch:22 step:21475 [D loss: 0.489792, acc.: 80.47%] [G loss: 1.322707]\n",
      "epoch:22 step:21476 [D loss: 0.625660, acc.: 67.19%] [G loss: 1.511664]\n",
      "epoch:22 step:21477 [D loss: 0.588512, acc.: 69.53%] [G loss: 1.096722]\n",
      "epoch:22 step:21478 [D loss: 0.604910, acc.: 66.41%] [G loss: 1.584181]\n",
      "epoch:22 step:21479 [D loss: 0.594498, acc.: 66.41%] [G loss: 1.173001]\n",
      "epoch:22 step:21480 [D loss: 0.514455, acc.: 78.12%] [G loss: 1.323988]\n",
      "epoch:22 step:21481 [D loss: 0.667439, acc.: 64.84%] [G loss: 1.078238]\n",
      "epoch:22 step:21482 [D loss: 0.429102, acc.: 82.03%] [G loss: 1.381516]\n",
      "epoch:22 step:21483 [D loss: 0.548816, acc.: 71.88%] [G loss: 1.471061]\n",
      "epoch:22 step:21484 [D loss: 0.654987, acc.: 60.94%] [G loss: 1.145798]\n",
      "epoch:22 step:21485 [D loss: 0.432879, acc.: 87.50%] [G loss: 1.450008]\n",
      "epoch:22 step:21486 [D loss: 0.453884, acc.: 78.91%] [G loss: 1.519667]\n",
      "epoch:22 step:21487 [D loss: 0.425447, acc.: 81.25%] [G loss: 1.505840]\n",
      "epoch:22 step:21488 [D loss: 0.449958, acc.: 80.47%] [G loss: 1.209098]\n",
      "epoch:22 step:21489 [D loss: 0.414849, acc.: 84.38%] [G loss: 1.490859]\n",
      "epoch:22 step:21490 [D loss: 0.452920, acc.: 82.03%] [G loss: 1.232483]\n",
      "epoch:22 step:21491 [D loss: 0.628315, acc.: 66.41%] [G loss: 1.058989]\n",
      "epoch:22 step:21492 [D loss: 0.704157, acc.: 59.38%] [G loss: 0.875331]\n",
      "epoch:22 step:21493 [D loss: 0.583238, acc.: 67.97%] [G loss: 1.193916]\n",
      "epoch:22 step:21494 [D loss: 0.540347, acc.: 76.56%] [G loss: 1.834440]\n",
      "epoch:22 step:21495 [D loss: 0.651733, acc.: 64.06%] [G loss: 1.379426]\n",
      "epoch:22 step:21496 [D loss: 0.475747, acc.: 79.69%] [G loss: 1.616634]\n",
      "epoch:22 step:21497 [D loss: 0.645677, acc.: 60.16%] [G loss: 1.408563]\n",
      "epoch:22 step:21498 [D loss: 0.526866, acc.: 74.22%] [G loss: 1.607303]\n",
      "epoch:22 step:21499 [D loss: 0.585689, acc.: 67.19%] [G loss: 1.390491]\n",
      "epoch:22 step:21500 [D loss: 0.582405, acc.: 71.09%] [G loss: 1.212496]\n",
      "epoch:22 step:21501 [D loss: 0.556428, acc.: 67.97%] [G loss: 1.288150]\n",
      "epoch:22 step:21502 [D loss: 0.592185, acc.: 67.19%] [G loss: 1.147910]\n",
      "epoch:22 step:21503 [D loss: 0.683876, acc.: 61.72%] [G loss: 1.146527]\n",
      "epoch:22 step:21504 [D loss: 0.668471, acc.: 58.59%] [G loss: 1.430812]\n",
      "epoch:22 step:21505 [D loss: 0.672495, acc.: 60.94%] [G loss: 1.401126]\n",
      "epoch:22 step:21506 [D loss: 0.433353, acc.: 83.59%] [G loss: 1.378147]\n",
      "epoch:22 step:21507 [D loss: 0.544720, acc.: 71.09%] [G loss: 1.186743]\n",
      "epoch:22 step:21508 [D loss: 0.739491, acc.: 54.69%] [G loss: 1.253338]\n",
      "epoch:22 step:21509 [D loss: 0.531773, acc.: 78.12%] [G loss: 1.831401]\n",
      "epoch:22 step:21510 [D loss: 0.603953, acc.: 64.84%] [G loss: 1.516309]\n",
      "epoch:22 step:21511 [D loss: 0.577093, acc.: 74.22%] [G loss: 1.550896]\n",
      "epoch:22 step:21512 [D loss: 0.494503, acc.: 75.00%] [G loss: 1.599704]\n",
      "epoch:22 step:21513 [D loss: 0.469813, acc.: 79.69%] [G loss: 1.576052]\n",
      "epoch:22 step:21514 [D loss: 0.493914, acc.: 75.00%] [G loss: 1.368571]\n",
      "epoch:22 step:21515 [D loss: 0.680167, acc.: 60.94%] [G loss: 1.040220]\n",
      "epoch:22 step:21516 [D loss: 0.467882, acc.: 81.25%] [G loss: 1.366387]\n",
      "epoch:22 step:21517 [D loss: 0.516394, acc.: 70.31%] [G loss: 1.220667]\n",
      "epoch:22 step:21518 [D loss: 0.427181, acc.: 82.03%] [G loss: 1.489198]\n",
      "epoch:22 step:21519 [D loss: 0.491389, acc.: 77.34%] [G loss: 1.212550]\n",
      "epoch:22 step:21520 [D loss: 0.583987, acc.: 71.09%] [G loss: 1.457580]\n",
      "epoch:22 step:21521 [D loss: 0.503336, acc.: 78.12%] [G loss: 1.479580]\n",
      "epoch:22 step:21522 [D loss: 0.613730, acc.: 68.75%] [G loss: 1.476273]\n",
      "epoch:22 step:21523 [D loss: 0.715131, acc.: 62.50%] [G loss: 1.087446]\n",
      "epoch:22 step:21524 [D loss: 0.613714, acc.: 66.41%] [G loss: 1.092917]\n",
      "epoch:22 step:21525 [D loss: 0.640225, acc.: 66.41%] [G loss: 1.065444]\n",
      "epoch:22 step:21526 [D loss: 0.591285, acc.: 67.19%] [G loss: 1.252429]\n",
      "epoch:22 step:21527 [D loss: 0.581421, acc.: 66.41%] [G loss: 1.452190]\n",
      "epoch:22 step:21528 [D loss: 0.544440, acc.: 71.88%] [G loss: 1.168313]\n",
      "epoch:22 step:21529 [D loss: 0.550105, acc.: 75.78%] [G loss: 1.118598]\n",
      "epoch:22 step:21530 [D loss: 0.509904, acc.: 76.56%] [G loss: 1.295914]\n",
      "epoch:22 step:21531 [D loss: 0.545227, acc.: 75.00%] [G loss: 1.439387]\n",
      "epoch:22 step:21532 [D loss: 0.410867, acc.: 86.72%] [G loss: 1.201931]\n",
      "epoch:22 step:21533 [D loss: 0.457080, acc.: 82.81%] [G loss: 1.330040]\n",
      "epoch:22 step:21534 [D loss: 0.527643, acc.: 77.34%] [G loss: 1.495274]\n",
      "epoch:22 step:21535 [D loss: 0.665318, acc.: 60.94%] [G loss: 1.212334]\n",
      "epoch:22 step:21536 [D loss: 0.496384, acc.: 72.66%] [G loss: 1.544301]\n",
      "epoch:22 step:21537 [D loss: 0.559672, acc.: 71.09%] [G loss: 1.342662]\n",
      "epoch:22 step:21538 [D loss: 0.607354, acc.: 68.75%] [G loss: 1.200192]\n",
      "epoch:22 step:21539 [D loss: 0.638464, acc.: 71.09%] [G loss: 1.292052]\n",
      "epoch:22 step:21540 [D loss: 0.449859, acc.: 82.81%] [G loss: 1.110604]\n",
      "epoch:22 step:21541 [D loss: 0.686730, acc.: 61.72%] [G loss: 0.997114]\n",
      "epoch:22 step:21542 [D loss: 0.515924, acc.: 75.00%] [G loss: 1.053280]\n",
      "epoch:22 step:21543 [D loss: 0.619249, acc.: 62.50%] [G loss: 1.070674]\n",
      "epoch:22 step:21544 [D loss: 0.508206, acc.: 75.78%] [G loss: 1.267602]\n",
      "epoch:22 step:21545 [D loss: 0.682287, acc.: 58.59%] [G loss: 1.159550]\n",
      "epoch:22 step:21546 [D loss: 0.516567, acc.: 76.56%] [G loss: 1.491578]\n",
      "epoch:22 step:21547 [D loss: 0.531182, acc.: 73.44%] [G loss: 1.381275]\n",
      "epoch:22 step:21548 [D loss: 0.580473, acc.: 73.44%] [G loss: 1.494879]\n",
      "epoch:22 step:21549 [D loss: 0.515207, acc.: 78.12%] [G loss: 1.596110]\n",
      "epoch:22 step:21550 [D loss: 0.418755, acc.: 85.94%] [G loss: 1.618729]\n",
      "epoch:22 step:21551 [D loss: 0.506381, acc.: 76.56%] [G loss: 1.379498]\n",
      "epoch:23 step:21552 [D loss: 0.572131, acc.: 69.53%] [G loss: 1.202726]\n",
      "epoch:23 step:21553 [D loss: 0.548670, acc.: 72.66%] [G loss: 1.598491]\n",
      "epoch:23 step:21554 [D loss: 0.506113, acc.: 74.22%] [G loss: 1.405506]\n",
      "epoch:23 step:21555 [D loss: 0.685622, acc.: 61.72%] [G loss: 0.905747]\n",
      "epoch:23 step:21556 [D loss: 0.737251, acc.: 59.38%] [G loss: 0.976982]\n",
      "epoch:23 step:21557 [D loss: 0.585295, acc.: 71.88%] [G loss: 1.581319]\n",
      "epoch:23 step:21558 [D loss: 0.680253, acc.: 60.94%] [G loss: 1.254260]\n",
      "epoch:23 step:21559 [D loss: 0.496382, acc.: 78.12%] [G loss: 1.773069]\n",
      "epoch:23 step:21560 [D loss: 0.570498, acc.: 71.09%] [G loss: 1.473511]\n",
      "epoch:23 step:21561 [D loss: 0.629897, acc.: 67.19%] [G loss: 1.331458]\n",
      "epoch:23 step:21562 [D loss: 0.586618, acc.: 67.19%] [G loss: 1.500334]\n",
      "epoch:23 step:21563 [D loss: 0.527978, acc.: 74.22%] [G loss: 1.507078]\n",
      "epoch:23 step:21564 [D loss: 0.531024, acc.: 73.44%] [G loss: 1.280311]\n",
      "epoch:23 step:21565 [D loss: 0.535116, acc.: 73.44%] [G loss: 1.427814]\n",
      "epoch:23 step:21566 [D loss: 0.604649, acc.: 68.75%] [G loss: 1.295905]\n",
      "epoch:23 step:21567 [D loss: 0.750425, acc.: 53.12%] [G loss: 1.175707]\n",
      "epoch:23 step:21568 [D loss: 0.657756, acc.: 61.72%] [G loss: 1.494199]\n",
      "epoch:23 step:21569 [D loss: 0.576003, acc.: 68.75%] [G loss: 1.065263]\n",
      "epoch:23 step:21570 [D loss: 0.641691, acc.: 68.75%] [G loss: 1.610164]\n",
      "epoch:23 step:21571 [D loss: 0.624239, acc.: 67.19%] [G loss: 1.017540]\n",
      "epoch:23 step:21572 [D loss: 0.528182, acc.: 75.00%] [G loss: 1.347719]\n",
      "epoch:23 step:21573 [D loss: 0.511814, acc.: 77.34%] [G loss: 1.416264]\n",
      "epoch:23 step:21574 [D loss: 0.541127, acc.: 75.00%] [G loss: 1.550005]\n",
      "epoch:23 step:21575 [D loss: 0.572121, acc.: 67.19%] [G loss: 1.159517]\n",
      "epoch:23 step:21576 [D loss: 0.616141, acc.: 65.62%] [G loss: 1.076010]\n",
      "epoch:23 step:21577 [D loss: 0.659851, acc.: 59.38%] [G loss: 0.996394]\n",
      "epoch:23 step:21578 [D loss: 0.481126, acc.: 78.12%] [G loss: 1.095343]\n",
      "epoch:23 step:21579 [D loss: 0.533513, acc.: 74.22%] [G loss: 1.298337]\n",
      "epoch:23 step:21580 [D loss: 0.694910, acc.: 62.50%] [G loss: 0.966627]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:23 step:21581 [D loss: 0.510345, acc.: 77.34%] [G loss: 1.294203]\n",
      "epoch:23 step:21582 [D loss: 0.536847, acc.: 69.53%] [G loss: 1.330110]\n",
      "epoch:23 step:21583 [D loss: 0.438469, acc.: 82.03%] [G loss: 1.313943]\n",
      "epoch:23 step:21584 [D loss: 0.544780, acc.: 69.53%] [G loss: 0.861441]\n",
      "epoch:23 step:21585 [D loss: 0.635796, acc.: 69.53%] [G loss: 1.472247]\n",
      "epoch:23 step:21586 [D loss: 0.404687, acc.: 82.03%] [G loss: 2.136016]\n",
      "epoch:23 step:21587 [D loss: 0.494569, acc.: 75.00%] [G loss: 1.466580]\n",
      "epoch:23 step:21588 [D loss: 0.576710, acc.: 72.66%] [G loss: 1.030232]\n",
      "epoch:23 step:21589 [D loss: 0.533293, acc.: 75.00%] [G loss: 1.647118]\n",
      "epoch:23 step:21590 [D loss: 0.565548, acc.: 67.97%] [G loss: 1.197818]\n",
      "epoch:23 step:21591 [D loss: 0.727810, acc.: 60.94%] [G loss: 1.386102]\n",
      "epoch:23 step:21592 [D loss: 0.523765, acc.: 73.44%] [G loss: 1.323240]\n",
      "epoch:23 step:21593 [D loss: 0.599264, acc.: 73.44%] [G loss: 1.230078]\n",
      "epoch:23 step:21594 [D loss: 0.848184, acc.: 51.56%] [G loss: 0.983006]\n",
      "epoch:23 step:21595 [D loss: 0.518032, acc.: 81.25%] [G loss: 1.594493]\n",
      "epoch:23 step:21596 [D loss: 0.467349, acc.: 82.03%] [G loss: 1.138740]\n",
      "epoch:23 step:21597 [D loss: 0.696661, acc.: 55.47%] [G loss: 1.321351]\n",
      "epoch:23 step:21598 [D loss: 0.550147, acc.: 74.22%] [G loss: 1.418763]\n",
      "epoch:23 step:21599 [D loss: 0.574892, acc.: 67.97%] [G loss: 0.974019]\n",
      "epoch:23 step:21600 [D loss: 0.626142, acc.: 62.50%] [G loss: 1.344940]\n",
      "epoch:23 step:21601 [D loss: 0.476912, acc.: 78.91%] [G loss: 1.165273]\n",
      "epoch:23 step:21602 [D loss: 0.658784, acc.: 62.50%] [G loss: 1.198954]\n",
      "epoch:23 step:21603 [D loss: 0.580989, acc.: 70.31%] [G loss: 1.550804]\n",
      "epoch:23 step:21604 [D loss: 0.409860, acc.: 84.38%] [G loss: 1.427821]\n",
      "epoch:23 step:21605 [D loss: 0.522527, acc.: 71.09%] [G loss: 1.407144]\n",
      "epoch:23 step:21606 [D loss: 0.597409, acc.: 67.97%] [G loss: 1.400873]\n",
      "epoch:23 step:21607 [D loss: 0.529342, acc.: 75.00%] [G loss: 1.362048]\n",
      "epoch:23 step:21608 [D loss: 0.495058, acc.: 74.22%] [G loss: 1.319694]\n",
      "epoch:23 step:21609 [D loss: 0.649457, acc.: 63.28%] [G loss: 1.389178]\n",
      "epoch:23 step:21610 [D loss: 0.512405, acc.: 71.88%] [G loss: 1.111977]\n",
      "epoch:23 step:21611 [D loss: 0.561005, acc.: 73.44%] [G loss: 1.507445]\n",
      "epoch:23 step:21612 [D loss: 0.464917, acc.: 82.81%] [G loss: 1.712515]\n",
      "epoch:23 step:21613 [D loss: 0.491924, acc.: 75.00%] [G loss: 1.614635]\n",
      "epoch:23 step:21614 [D loss: 0.454176, acc.: 79.69%] [G loss: 1.610313]\n",
      "epoch:23 step:21615 [D loss: 0.475876, acc.: 77.34%] [G loss: 1.201987]\n",
      "epoch:23 step:21616 [D loss: 0.532571, acc.: 70.31%] [G loss: 1.432078]\n",
      "epoch:23 step:21617 [D loss: 0.439277, acc.: 87.50%] [G loss: 1.724707]\n",
      "epoch:23 step:21618 [D loss: 0.572320, acc.: 67.97%] [G loss: 1.717707]\n",
      "epoch:23 step:21619 [D loss: 0.579337, acc.: 68.75%] [G loss: 1.398255]\n",
      "epoch:23 step:21620 [D loss: 0.537237, acc.: 71.09%] [G loss: 1.113392]\n",
      "epoch:23 step:21621 [D loss: 0.610938, acc.: 64.06%] [G loss: 1.632492]\n",
      "epoch:23 step:21622 [D loss: 0.610443, acc.: 66.41%] [G loss: 1.285151]\n",
      "epoch:23 step:21623 [D loss: 0.555185, acc.: 68.75%] [G loss: 1.077762]\n",
      "epoch:23 step:21624 [D loss: 0.472766, acc.: 77.34%] [G loss: 1.170852]\n",
      "epoch:23 step:21625 [D loss: 0.330364, acc.: 89.84%] [G loss: 1.113445]\n",
      "epoch:23 step:21626 [D loss: 0.696628, acc.: 57.03%] [G loss: 1.137459]\n",
      "epoch:23 step:21627 [D loss: 0.540327, acc.: 75.78%] [G loss: 1.575903]\n",
      "epoch:23 step:21628 [D loss: 0.598397, acc.: 63.28%] [G loss: 1.226062]\n",
      "epoch:23 step:21629 [D loss: 0.586522, acc.: 66.41%] [G loss: 1.261418]\n",
      "epoch:23 step:21630 [D loss: 0.441721, acc.: 80.47%] [G loss: 1.709095]\n",
      "epoch:23 step:21631 [D loss: 0.525807, acc.: 75.78%] [G loss: 1.293364]\n",
      "epoch:23 step:21632 [D loss: 0.676270, acc.: 61.72%] [G loss: 1.470879]\n",
      "epoch:23 step:21633 [D loss: 0.581876, acc.: 69.53%] [G loss: 1.241431]\n",
      "epoch:23 step:21634 [D loss: 0.670886, acc.: 64.84%] [G loss: 1.454720]\n",
      "epoch:23 step:21635 [D loss: 0.672319, acc.: 57.81%] [G loss: 1.153806]\n",
      "epoch:23 step:21636 [D loss: 0.497740, acc.: 79.69%] [G loss: 1.430737]\n",
      "epoch:23 step:21637 [D loss: 0.473457, acc.: 77.34%] [G loss: 1.294143]\n",
      "epoch:23 step:21638 [D loss: 0.624118, acc.: 69.53%] [G loss: 1.210511]\n",
      "epoch:23 step:21639 [D loss: 0.529315, acc.: 71.88%] [G loss: 1.468992]\n",
      "epoch:23 step:21640 [D loss: 0.514950, acc.: 77.34%] [G loss: 1.344150]\n",
      "epoch:23 step:21641 [D loss: 0.644532, acc.: 61.72%] [G loss: 1.469347]\n",
      "epoch:23 step:21642 [D loss: 0.587379, acc.: 67.19%] [G loss: 1.736645]\n",
      "epoch:23 step:21643 [D loss: 0.457618, acc.: 82.81%] [G loss: 1.725722]\n",
      "epoch:23 step:21644 [D loss: 0.760766, acc.: 50.00%] [G loss: 1.620552]\n",
      "epoch:23 step:21645 [D loss: 0.572490, acc.: 70.31%] [G loss: 1.534022]\n",
      "epoch:23 step:21646 [D loss: 0.439449, acc.: 84.38%] [G loss: 1.292174]\n",
      "epoch:23 step:21647 [D loss: 0.486504, acc.: 75.78%] [G loss: 1.756817]\n",
      "epoch:23 step:21648 [D loss: 0.620954, acc.: 64.84%] [G loss: 1.264051]\n",
      "epoch:23 step:21649 [D loss: 0.447680, acc.: 82.03%] [G loss: 1.262304]\n",
      "epoch:23 step:21650 [D loss: 0.596160, acc.: 67.19%] [G loss: 1.360248]\n",
      "epoch:23 step:21651 [D loss: 0.580442, acc.: 66.41%] [G loss: 1.653435]\n",
      "epoch:23 step:21652 [D loss: 0.451916, acc.: 79.69%] [G loss: 1.235646]\n",
      "epoch:23 step:21653 [D loss: 0.705492, acc.: 55.47%] [G loss: 1.410569]\n",
      "epoch:23 step:21654 [D loss: 0.472211, acc.: 81.25%] [G loss: 1.286174]\n",
      "epoch:23 step:21655 [D loss: 0.558460, acc.: 74.22%] [G loss: 1.340130]\n",
      "epoch:23 step:21656 [D loss: 0.519136, acc.: 75.78%] [G loss: 1.306255]\n",
      "epoch:23 step:21657 [D loss: 0.617235, acc.: 67.97%] [G loss: 1.471368]\n",
      "epoch:23 step:21658 [D loss: 0.530683, acc.: 72.66%] [G loss: 1.395574]\n",
      "epoch:23 step:21659 [D loss: 0.560678, acc.: 68.75%] [G loss: 1.295538]\n",
      "epoch:23 step:21660 [D loss: 0.763627, acc.: 57.81%] [G loss: 1.269019]\n",
      "epoch:23 step:21661 [D loss: 0.748329, acc.: 56.25%] [G loss: 1.285149]\n",
      "epoch:23 step:21662 [D loss: 0.500874, acc.: 75.78%] [G loss: 1.535312]\n",
      "epoch:23 step:21663 [D loss: 0.540241, acc.: 70.31%] [G loss: 1.463688]\n",
      "epoch:23 step:21664 [D loss: 0.407714, acc.: 85.94%] [G loss: 1.216038]\n",
      "epoch:23 step:21665 [D loss: 0.410649, acc.: 87.50%] [G loss: 1.609613]\n",
      "epoch:23 step:21666 [D loss: 0.537550, acc.: 73.44%] [G loss: 1.323289]\n",
      "epoch:23 step:21667 [D loss: 0.688940, acc.: 60.16%] [G loss: 1.068485]\n",
      "epoch:23 step:21668 [D loss: 0.542565, acc.: 70.31%] [G loss: 1.301544]\n",
      "epoch:23 step:21669 [D loss: 0.541713, acc.: 71.09%] [G loss: 1.210680]\n",
      "epoch:23 step:21670 [D loss: 0.425254, acc.: 82.81%] [G loss: 1.630178]\n",
      "epoch:23 step:21671 [D loss: 0.616045, acc.: 64.06%] [G loss: 1.192216]\n",
      "epoch:23 step:21672 [D loss: 0.744658, acc.: 52.34%] [G loss: 1.249757]\n",
      "epoch:23 step:21673 [D loss: 0.554500, acc.: 74.22%] [G loss: 1.287484]\n",
      "epoch:23 step:21674 [D loss: 0.360227, acc.: 88.28%] [G loss: 1.442465]\n",
      "epoch:23 step:21675 [D loss: 0.467064, acc.: 75.78%] [G loss: 1.530316]\n",
      "epoch:23 step:21676 [D loss: 0.589715, acc.: 67.19%] [G loss: 1.204358]\n",
      "epoch:23 step:21677 [D loss: 0.668911, acc.: 67.19%] [G loss: 0.810282]\n",
      "epoch:23 step:21678 [D loss: 0.564865, acc.: 72.66%] [G loss: 1.137955]\n",
      "epoch:23 step:21679 [D loss: 0.545669, acc.: 75.78%] [G loss: 1.181197]\n",
      "epoch:23 step:21680 [D loss: 0.436373, acc.: 82.03%] [G loss: 1.373423]\n",
      "epoch:23 step:21681 [D loss: 0.417737, acc.: 82.81%] [G loss: 1.553513]\n",
      "epoch:23 step:21682 [D loss: 0.537332, acc.: 75.78%] [G loss: 1.262913]\n",
      "epoch:23 step:21683 [D loss: 0.446265, acc.: 80.47%] [G loss: 1.467709]\n",
      "epoch:23 step:21684 [D loss: 0.420056, acc.: 81.25%] [G loss: 1.349002]\n",
      "epoch:23 step:21685 [D loss: 0.596757, acc.: 69.53%] [G loss: 1.285146]\n",
      "epoch:23 step:21686 [D loss: 0.494981, acc.: 71.88%] [G loss: 1.655975]\n",
      "epoch:23 step:21687 [D loss: 0.542506, acc.: 71.09%] [G loss: 1.417986]\n",
      "epoch:23 step:21688 [D loss: 0.298143, acc.: 92.19%] [G loss: 1.856931]\n",
      "epoch:23 step:21689 [D loss: 0.718902, acc.: 57.81%] [G loss: 1.161613]\n",
      "epoch:23 step:21690 [D loss: 0.498481, acc.: 77.34%] [G loss: 1.178070]\n",
      "epoch:23 step:21691 [D loss: 0.536839, acc.: 72.66%] [G loss: 1.415335]\n",
      "epoch:23 step:21692 [D loss: 0.701125, acc.: 62.50%] [G loss: 1.556628]\n",
      "epoch:23 step:21693 [D loss: 0.386006, acc.: 83.59%] [G loss: 1.433869]\n",
      "epoch:23 step:21694 [D loss: 0.477366, acc.: 75.78%] [G loss: 1.557841]\n",
      "epoch:23 step:21695 [D loss: 0.699663, acc.: 56.25%] [G loss: 0.849992]\n",
      "epoch:23 step:21696 [D loss: 0.537290, acc.: 70.31%] [G loss: 1.378710]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:23 step:21697 [D loss: 0.586981, acc.: 66.41%] [G loss: 1.121111]\n",
      "epoch:23 step:21698 [D loss: 0.565736, acc.: 71.09%] [G loss: 1.512721]\n",
      "epoch:23 step:21699 [D loss: 0.459068, acc.: 81.25%] [G loss: 1.345690]\n",
      "epoch:23 step:21700 [D loss: 0.436023, acc.: 81.25%] [G loss: 1.574403]\n",
      "epoch:23 step:21701 [D loss: 0.479362, acc.: 77.34%] [G loss: 1.673683]\n",
      "epoch:23 step:21702 [D loss: 0.532071, acc.: 75.00%] [G loss: 1.239589]\n",
      "epoch:23 step:21703 [D loss: 0.554681, acc.: 71.09%] [G loss: 1.370203]\n",
      "epoch:23 step:21704 [D loss: 0.503126, acc.: 78.91%] [G loss: 1.299050]\n",
      "epoch:23 step:21705 [D loss: 0.705788, acc.: 57.81%] [G loss: 1.523839]\n",
      "epoch:23 step:21706 [D loss: 0.562132, acc.: 69.53%] [G loss: 1.248441]\n",
      "epoch:23 step:21707 [D loss: 0.521081, acc.: 77.34%] [G loss: 1.655891]\n",
      "epoch:23 step:21708 [D loss: 0.597205, acc.: 67.97%] [G loss: 1.292266]\n",
      "epoch:23 step:21709 [D loss: 0.514496, acc.: 73.44%] [G loss: 1.455199]\n",
      "epoch:23 step:21710 [D loss: 0.518793, acc.: 74.22%] [G loss: 1.732957]\n",
      "epoch:23 step:21711 [D loss: 0.540877, acc.: 72.66%] [G loss: 1.328453]\n",
      "epoch:23 step:21712 [D loss: 0.598760, acc.: 67.19%] [G loss: 1.116212]\n",
      "epoch:23 step:21713 [D loss: 0.583172, acc.: 69.53%] [G loss: 1.634006]\n",
      "epoch:23 step:21714 [D loss: 0.657737, acc.: 62.50%] [G loss: 1.519158]\n",
      "epoch:23 step:21715 [D loss: 0.444144, acc.: 82.03%] [G loss: 1.341604]\n",
      "epoch:23 step:21716 [D loss: 0.522201, acc.: 76.56%] [G loss: 1.070291]\n",
      "epoch:23 step:21717 [D loss: 0.552978, acc.: 67.97%] [G loss: 1.519312]\n",
      "epoch:23 step:21718 [D loss: 0.503961, acc.: 79.69%] [G loss: 1.491181]\n",
      "epoch:23 step:21719 [D loss: 0.656334, acc.: 60.94%] [G loss: 1.114613]\n",
      "epoch:23 step:21720 [D loss: 0.535157, acc.: 71.88%] [G loss: 1.494941]\n",
      "epoch:23 step:21721 [D loss: 0.471607, acc.: 79.69%] [G loss: 1.158164]\n",
      "epoch:23 step:21722 [D loss: 0.717549, acc.: 52.34%] [G loss: 1.143318]\n",
      "epoch:23 step:21723 [D loss: 0.430904, acc.: 82.03%] [G loss: 1.169324]\n",
      "epoch:23 step:21724 [D loss: 0.604026, acc.: 69.53%] [G loss: 1.500411]\n",
      "epoch:23 step:21725 [D loss: 0.648939, acc.: 59.38%] [G loss: 1.307692]\n",
      "epoch:23 step:21726 [D loss: 0.646050, acc.: 64.84%] [G loss: 1.575548]\n",
      "epoch:23 step:21727 [D loss: 0.388196, acc.: 85.94%] [G loss: 1.514880]\n",
      "epoch:23 step:21728 [D loss: 0.531866, acc.: 72.66%] [G loss: 1.171906]\n",
      "epoch:23 step:21729 [D loss: 0.463643, acc.: 78.91%] [G loss: 1.205035]\n",
      "epoch:23 step:21730 [D loss: 0.515343, acc.: 75.00%] [G loss: 1.359792]\n",
      "epoch:23 step:21731 [D loss: 0.536511, acc.: 73.44%] [G loss: 1.691844]\n",
      "epoch:23 step:21732 [D loss: 0.448395, acc.: 78.91%] [G loss: 1.847736]\n",
      "epoch:23 step:21733 [D loss: 0.540707, acc.: 76.56%] [G loss: 1.528732]\n",
      "epoch:23 step:21734 [D loss: 0.436911, acc.: 81.25%] [G loss: 1.749060]\n",
      "epoch:23 step:21735 [D loss: 0.607577, acc.: 65.62%] [G loss: 1.551930]\n",
      "epoch:23 step:21736 [D loss: 0.584626, acc.: 68.75%] [G loss: 1.469331]\n",
      "epoch:23 step:21737 [D loss: 0.594447, acc.: 69.53%] [G loss: 1.429375]\n",
      "epoch:23 step:21738 [D loss: 0.516657, acc.: 71.88%] [G loss: 1.491417]\n",
      "epoch:23 step:21739 [D loss: 0.582089, acc.: 71.88%] [G loss: 1.461907]\n",
      "epoch:23 step:21740 [D loss: 0.577357, acc.: 68.75%] [G loss: 1.409273]\n",
      "epoch:23 step:21741 [D loss: 0.455585, acc.: 82.03%] [G loss: 0.993614]\n",
      "epoch:23 step:21742 [D loss: 0.533841, acc.: 71.09%] [G loss: 1.367253]\n",
      "epoch:23 step:21743 [D loss: 0.571047, acc.: 70.31%] [G loss: 1.516350]\n",
      "epoch:23 step:21744 [D loss: 0.597560, acc.: 66.41%] [G loss: 1.143950]\n",
      "epoch:23 step:21745 [D loss: 0.630895, acc.: 65.62%] [G loss: 1.588568]\n",
      "epoch:23 step:21746 [D loss: 0.670482, acc.: 66.41%] [G loss: 1.045676]\n",
      "epoch:23 step:21747 [D loss: 0.601327, acc.: 67.97%] [G loss: 1.188349]\n",
      "epoch:23 step:21748 [D loss: 0.470630, acc.: 81.25%] [G loss: 1.382806]\n",
      "epoch:23 step:21749 [D loss: 0.615201, acc.: 63.28%] [G loss: 1.029396]\n",
      "epoch:23 step:21750 [D loss: 0.466811, acc.: 78.91%] [G loss: 1.365778]\n",
      "epoch:23 step:21751 [D loss: 0.518558, acc.: 79.69%] [G loss: 1.233339]\n",
      "epoch:23 step:21752 [D loss: 0.508004, acc.: 73.44%] [G loss: 1.026186]\n",
      "epoch:23 step:21753 [D loss: 0.537982, acc.: 74.22%] [G loss: 1.378109]\n",
      "epoch:23 step:21754 [D loss: 0.471431, acc.: 77.34%] [G loss: 1.452201]\n",
      "epoch:23 step:21755 [D loss: 0.420389, acc.: 85.16%] [G loss: 1.259119]\n",
      "epoch:23 step:21756 [D loss: 0.565347, acc.: 67.97%] [G loss: 1.692104]\n",
      "epoch:23 step:21757 [D loss: 0.631698, acc.: 64.84%] [G loss: 1.502341]\n",
      "epoch:23 step:21758 [D loss: 0.693709, acc.: 60.16%] [G loss: 1.259922]\n",
      "epoch:23 step:21759 [D loss: 0.550994, acc.: 73.44%] [G loss: 1.256603]\n",
      "epoch:23 step:21760 [D loss: 0.618823, acc.: 68.75%] [G loss: 1.415937]\n",
      "epoch:23 step:21761 [D loss: 0.473188, acc.: 78.12%] [G loss: 1.597635]\n",
      "epoch:23 step:21762 [D loss: 0.440864, acc.: 79.69%] [G loss: 1.685714]\n",
      "epoch:23 step:21763 [D loss: 0.511573, acc.: 76.56%] [G loss: 1.173705]\n",
      "epoch:23 step:21764 [D loss: 0.429712, acc.: 84.38%] [G loss: 1.715708]\n",
      "epoch:23 step:21765 [D loss: 0.552987, acc.: 67.19%] [G loss: 1.202935]\n",
      "epoch:23 step:21766 [D loss: 0.737936, acc.: 53.91%] [G loss: 1.140864]\n",
      "epoch:23 step:21767 [D loss: 0.548762, acc.: 72.66%] [G loss: 1.225651]\n",
      "epoch:23 step:21768 [D loss: 0.608802, acc.: 70.31%] [G loss: 1.179535]\n",
      "epoch:23 step:21769 [D loss: 0.501536, acc.: 74.22%] [G loss: 1.508118]\n",
      "epoch:23 step:21770 [D loss: 0.680187, acc.: 60.94%] [G loss: 1.281638]\n",
      "epoch:23 step:21771 [D loss: 0.564964, acc.: 72.66%] [G loss: 1.166192]\n",
      "epoch:23 step:21772 [D loss: 0.620216, acc.: 65.62%] [G loss: 1.136467]\n",
      "epoch:23 step:21773 [D loss: 0.617834, acc.: 66.41%] [G loss: 0.857067]\n",
      "epoch:23 step:21774 [D loss: 0.592295, acc.: 66.41%] [G loss: 1.076977]\n",
      "epoch:23 step:21775 [D loss: 0.679032, acc.: 64.06%] [G loss: 1.447006]\n",
      "epoch:23 step:21776 [D loss: 0.513051, acc.: 78.12%] [G loss: 1.713614]\n",
      "epoch:23 step:21777 [D loss: 0.568740, acc.: 71.88%] [G loss: 1.317161]\n",
      "epoch:23 step:21778 [D loss: 0.473540, acc.: 80.47%] [G loss: 1.330961]\n",
      "epoch:23 step:21779 [D loss: 0.736319, acc.: 56.25%] [G loss: 1.474470]\n",
      "epoch:23 step:21780 [D loss: 0.644241, acc.: 64.06%] [G loss: 1.704258]\n",
      "epoch:23 step:21781 [D loss: 0.659354, acc.: 64.06%] [G loss: 1.326518]\n",
      "epoch:23 step:21782 [D loss: 0.504390, acc.: 75.78%] [G loss: 1.553326]\n",
      "epoch:23 step:21783 [D loss: 0.725389, acc.: 58.59%] [G loss: 1.355088]\n",
      "epoch:23 step:21784 [D loss: 0.554244, acc.: 68.75%] [G loss: 1.295852]\n",
      "epoch:23 step:21785 [D loss: 0.607003, acc.: 67.97%] [G loss: 1.392641]\n",
      "epoch:23 step:21786 [D loss: 0.566040, acc.: 71.88%] [G loss: 1.314932]\n",
      "epoch:23 step:21787 [D loss: 0.470244, acc.: 72.66%] [G loss: 1.020055]\n",
      "epoch:23 step:21788 [D loss: 0.594372, acc.: 66.41%] [G loss: 1.468391]\n",
      "epoch:23 step:21789 [D loss: 0.495541, acc.: 77.34%] [G loss: 1.434635]\n",
      "epoch:23 step:21790 [D loss: 0.490318, acc.: 78.12%] [G loss: 1.360105]\n",
      "epoch:23 step:21791 [D loss: 0.515000, acc.: 72.66%] [G loss: 1.590020]\n",
      "epoch:23 step:21792 [D loss: 0.469684, acc.: 77.34%] [G loss: 1.397631]\n",
      "epoch:23 step:21793 [D loss: 0.604797, acc.: 64.84%] [G loss: 1.361519]\n",
      "epoch:23 step:21794 [D loss: 0.484616, acc.: 75.00%] [G loss: 1.251258]\n",
      "epoch:23 step:21795 [D loss: 0.730604, acc.: 56.25%] [G loss: 1.360783]\n",
      "epoch:23 step:21796 [D loss: 0.538834, acc.: 67.97%] [G loss: 1.429638]\n",
      "epoch:23 step:21797 [D loss: 0.562108, acc.: 74.22%] [G loss: 1.378774]\n",
      "epoch:23 step:21798 [D loss: 0.580104, acc.: 70.31%] [G loss: 1.416755]\n",
      "epoch:23 step:21799 [D loss: 0.526003, acc.: 75.00%] [G loss: 1.339000]\n",
      "epoch:23 step:21800 [D loss: 0.418361, acc.: 82.03%] [G loss: 1.405907]\n",
      "epoch:23 step:21801 [D loss: 0.584843, acc.: 70.31%] [G loss: 1.404425]\n",
      "epoch:23 step:21802 [D loss: 0.630319, acc.: 70.31%] [G loss: 1.430162]\n",
      "epoch:23 step:21803 [D loss: 0.422154, acc.: 85.16%] [G loss: 1.412697]\n",
      "epoch:23 step:21804 [D loss: 0.589510, acc.: 66.41%] [G loss: 1.255850]\n",
      "epoch:23 step:21805 [D loss: 0.482162, acc.: 75.00%] [G loss: 1.444299]\n",
      "epoch:23 step:21806 [D loss: 0.576295, acc.: 66.41%] [G loss: 1.092276]\n",
      "epoch:23 step:21807 [D loss: 0.567166, acc.: 68.75%] [G loss: 1.244098]\n",
      "epoch:23 step:21808 [D loss: 0.568793, acc.: 71.09%] [G loss: 1.325665]\n",
      "epoch:23 step:21809 [D loss: 0.739844, acc.: 57.03%] [G loss: 1.144191]\n",
      "epoch:23 step:21810 [D loss: 0.506931, acc.: 75.78%] [G loss: 1.764562]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:23 step:21811 [D loss: 0.559534, acc.: 70.31%] [G loss: 1.399970]\n",
      "epoch:23 step:21812 [D loss: 0.519548, acc.: 77.34%] [G loss: 1.085809]\n",
      "epoch:23 step:21813 [D loss: 0.595180, acc.: 66.41%] [G loss: 1.347218]\n",
      "epoch:23 step:21814 [D loss: 0.559415, acc.: 68.75%] [G loss: 1.354965]\n",
      "epoch:23 step:21815 [D loss: 0.541554, acc.: 71.09%] [G loss: 1.338700]\n",
      "epoch:23 step:21816 [D loss: 0.436316, acc.: 82.81%] [G loss: 1.223560]\n",
      "epoch:23 step:21817 [D loss: 0.639227, acc.: 62.50%] [G loss: 1.187534]\n",
      "epoch:23 step:21818 [D loss: 0.518630, acc.: 73.44%] [G loss: 1.376443]\n",
      "epoch:23 step:21819 [D loss: 0.580310, acc.: 66.41%] [G loss: 1.038072]\n",
      "epoch:23 step:21820 [D loss: 0.383419, acc.: 85.94%] [G loss: 1.231453]\n",
      "epoch:23 step:21821 [D loss: 0.515457, acc.: 73.44%] [G loss: 1.397087]\n",
      "epoch:23 step:21822 [D loss: 0.395670, acc.: 87.50%] [G loss: 1.735085]\n",
      "epoch:23 step:21823 [D loss: 0.575247, acc.: 66.41%] [G loss: 1.305735]\n",
      "epoch:23 step:21824 [D loss: 0.578755, acc.: 71.88%] [G loss: 1.386560]\n",
      "epoch:23 step:21825 [D loss: 0.451665, acc.: 80.47%] [G loss: 1.287044]\n",
      "epoch:23 step:21826 [D loss: 0.691256, acc.: 60.16%] [G loss: 1.064939]\n",
      "epoch:23 step:21827 [D loss: 0.765420, acc.: 55.47%] [G loss: 1.341260]\n",
      "epoch:23 step:21828 [D loss: 0.621863, acc.: 64.06%] [G loss: 1.217950]\n",
      "epoch:23 step:21829 [D loss: 0.475050, acc.: 78.91%] [G loss: 1.825498]\n",
      "epoch:23 step:21830 [D loss: 0.652671, acc.: 63.28%] [G loss: 0.991097]\n",
      "epoch:23 step:21831 [D loss: 0.488247, acc.: 78.12%] [G loss: 1.114137]\n",
      "epoch:23 step:21832 [D loss: 0.670565, acc.: 57.81%] [G loss: 1.339403]\n",
      "epoch:23 step:21833 [D loss: 0.580746, acc.: 71.88%] [G loss: 1.004107]\n",
      "epoch:23 step:21834 [D loss: 0.633308, acc.: 64.06%] [G loss: 1.631568]\n",
      "epoch:23 step:21835 [D loss: 0.319868, acc.: 93.75%] [G loss: 1.555869]\n",
      "epoch:23 step:21836 [D loss: 0.558571, acc.: 69.53%] [G loss: 1.620572]\n",
      "epoch:23 step:21837 [D loss: 0.528681, acc.: 77.34%] [G loss: 1.294488]\n",
      "epoch:23 step:21838 [D loss: 0.535727, acc.: 72.66%] [G loss: 1.138902]\n",
      "epoch:23 step:21839 [D loss: 0.558264, acc.: 71.88%] [G loss: 1.162441]\n",
      "epoch:23 step:21840 [D loss: 0.576295, acc.: 71.09%] [G loss: 1.377046]\n",
      "epoch:23 step:21841 [D loss: 0.468136, acc.: 79.69%] [G loss: 1.633232]\n",
      "epoch:23 step:21842 [D loss: 0.603161, acc.: 67.19%] [G loss: 1.298650]\n",
      "epoch:23 step:21843 [D loss: 0.595801, acc.: 70.31%] [G loss: 1.159907]\n",
      "epoch:23 step:21844 [D loss: 0.719267, acc.: 57.81%] [G loss: 1.498565]\n",
      "epoch:23 step:21845 [D loss: 0.430581, acc.: 81.25%] [G loss: 1.299050]\n",
      "epoch:23 step:21846 [D loss: 0.593630, acc.: 66.41%] [G loss: 1.160416]\n",
      "epoch:23 step:21847 [D loss: 0.490081, acc.: 77.34%] [G loss: 2.005313]\n",
      "epoch:23 step:21848 [D loss: 0.677563, acc.: 63.28%] [G loss: 1.425598]\n",
      "epoch:23 step:21849 [D loss: 0.590688, acc.: 73.44%] [G loss: 1.428358]\n",
      "epoch:23 step:21850 [D loss: 0.547580, acc.: 71.88%] [G loss: 1.318472]\n",
      "epoch:23 step:21851 [D loss: 0.669053, acc.: 63.28%] [G loss: 1.373796]\n",
      "epoch:23 step:21852 [D loss: 0.665235, acc.: 61.72%] [G loss: 1.421235]\n",
      "epoch:23 step:21853 [D loss: 0.521286, acc.: 73.44%] [G loss: 1.748182]\n",
      "epoch:23 step:21854 [D loss: 0.753384, acc.: 55.47%] [G loss: 1.335082]\n",
      "epoch:23 step:21855 [D loss: 0.510304, acc.: 75.78%] [G loss: 1.480154]\n",
      "epoch:23 step:21856 [D loss: 0.567382, acc.: 71.88%] [G loss: 1.400148]\n",
      "epoch:23 step:21857 [D loss: 0.724540, acc.: 55.47%] [G loss: 1.294023]\n",
      "epoch:23 step:21858 [D loss: 0.540035, acc.: 68.75%] [G loss: 1.217473]\n",
      "epoch:23 step:21859 [D loss: 0.470714, acc.: 82.81%] [G loss: 1.300514]\n",
      "epoch:23 step:21860 [D loss: 0.485381, acc.: 78.12%] [G loss: 1.664863]\n",
      "epoch:23 step:21861 [D loss: 0.715392, acc.: 55.47%] [G loss: 1.057735]\n",
      "epoch:23 step:21862 [D loss: 0.680578, acc.: 60.94%] [G loss: 0.983144]\n",
      "epoch:23 step:21863 [D loss: 0.516802, acc.: 77.34%] [G loss: 1.522606]\n",
      "epoch:23 step:21864 [D loss: 0.556918, acc.: 75.00%] [G loss: 1.244645]\n",
      "epoch:23 step:21865 [D loss: 0.511815, acc.: 74.22%] [G loss: 1.313009]\n",
      "epoch:23 step:21866 [D loss: 0.483840, acc.: 77.34%] [G loss: 1.294099]\n",
      "epoch:23 step:21867 [D loss: 0.510957, acc.: 77.34%] [G loss: 1.388659]\n",
      "epoch:23 step:21868 [D loss: 0.471871, acc.: 75.78%] [G loss: 1.313456]\n",
      "epoch:23 step:21869 [D loss: 0.523938, acc.: 78.12%] [G loss: 1.352780]\n",
      "epoch:23 step:21870 [D loss: 0.460792, acc.: 76.56%] [G loss: 1.765294]\n",
      "epoch:23 step:21871 [D loss: 0.484476, acc.: 76.56%] [G loss: 1.333031]\n",
      "epoch:23 step:21872 [D loss: 0.552495, acc.: 72.66%] [G loss: 1.255493]\n",
      "epoch:23 step:21873 [D loss: 0.537715, acc.: 74.22%] [G loss: 1.246985]\n",
      "epoch:23 step:21874 [D loss: 0.427981, acc.: 81.25%] [G loss: 1.563396]\n",
      "epoch:23 step:21875 [D loss: 0.643174, acc.: 65.62%] [G loss: 1.365225]\n",
      "epoch:23 step:21876 [D loss: 0.543659, acc.: 71.88%] [G loss: 1.627010]\n",
      "epoch:23 step:21877 [D loss: 0.553712, acc.: 72.66%] [G loss: 1.323124]\n",
      "epoch:23 step:21878 [D loss: 0.395380, acc.: 85.94%] [G loss: 1.571858]\n",
      "epoch:23 step:21879 [D loss: 0.437655, acc.: 80.47%] [G loss: 1.069225]\n",
      "epoch:23 step:21880 [D loss: 0.737477, acc.: 57.03%] [G loss: 1.273082]\n",
      "epoch:23 step:21881 [D loss: 0.509264, acc.: 78.12%] [G loss: 1.371828]\n",
      "epoch:23 step:21882 [D loss: 0.490376, acc.: 80.47%] [G loss: 1.556913]\n",
      "epoch:23 step:21883 [D loss: 0.606670, acc.: 67.97%] [G loss: 1.362407]\n",
      "epoch:23 step:21884 [D loss: 0.644563, acc.: 67.19%] [G loss: 1.479958]\n",
      "epoch:23 step:21885 [D loss: 0.649441, acc.: 63.28%] [G loss: 1.301474]\n",
      "epoch:23 step:21886 [D loss: 0.582537, acc.: 72.66%] [G loss: 1.339156]\n",
      "epoch:23 step:21887 [D loss: 0.606343, acc.: 64.84%] [G loss: 1.172431]\n",
      "epoch:23 step:21888 [D loss: 0.544397, acc.: 75.00%] [G loss: 1.636076]\n",
      "epoch:23 step:21889 [D loss: 0.422527, acc.: 85.16%] [G loss: 1.502519]\n",
      "epoch:23 step:21890 [D loss: 0.597037, acc.: 69.53%] [G loss: 1.700665]\n",
      "epoch:23 step:21891 [D loss: 0.493350, acc.: 77.34%] [G loss: 1.214232]\n",
      "epoch:23 step:21892 [D loss: 0.539589, acc.: 76.56%] [G loss: 1.364210]\n",
      "epoch:23 step:21893 [D loss: 0.625015, acc.: 65.62%] [G loss: 1.341642]\n",
      "epoch:23 step:21894 [D loss: 0.743892, acc.: 55.47%] [G loss: 1.444979]\n",
      "epoch:23 step:21895 [D loss: 0.608786, acc.: 61.72%] [G loss: 1.549060]\n",
      "epoch:23 step:21896 [D loss: 0.576072, acc.: 67.19%] [G loss: 1.499205]\n",
      "epoch:23 step:21897 [D loss: 0.702763, acc.: 60.16%] [G loss: 1.379025]\n",
      "epoch:23 step:21898 [D loss: 0.650162, acc.: 59.38%] [G loss: 1.568697]\n",
      "epoch:23 step:21899 [D loss: 0.511031, acc.: 73.44%] [G loss: 1.244148]\n",
      "epoch:23 step:21900 [D loss: 0.539863, acc.: 74.22%] [G loss: 1.119575]\n",
      "epoch:23 step:21901 [D loss: 0.518718, acc.: 75.78%] [G loss: 1.420423]\n",
      "epoch:23 step:21902 [D loss: 0.616855, acc.: 67.97%] [G loss: 0.880898]\n",
      "epoch:23 step:21903 [D loss: 0.619889, acc.: 67.97%] [G loss: 1.422446]\n",
      "epoch:23 step:21904 [D loss: 0.552105, acc.: 69.53%] [G loss: 1.366021]\n",
      "epoch:23 step:21905 [D loss: 0.465105, acc.: 80.47%] [G loss: 1.502229]\n",
      "epoch:23 step:21906 [D loss: 0.665729, acc.: 57.03%] [G loss: 1.417567]\n",
      "epoch:23 step:21907 [D loss: 0.612080, acc.: 66.41%] [G loss: 1.219153]\n",
      "epoch:23 step:21908 [D loss: 0.444796, acc.: 82.03%] [G loss: 1.323187]\n",
      "epoch:23 step:21909 [D loss: 0.526502, acc.: 73.44%] [G loss: 1.422679]\n",
      "epoch:23 step:21910 [D loss: 0.570830, acc.: 72.66%] [G loss: 1.429581]\n",
      "epoch:23 step:21911 [D loss: 0.559205, acc.: 67.19%] [G loss: 1.181470]\n",
      "epoch:23 step:21912 [D loss: 0.507393, acc.: 74.22%] [G loss: 1.462296]\n",
      "epoch:23 step:21913 [D loss: 0.429637, acc.: 87.50%] [G loss: 1.066844]\n",
      "epoch:23 step:21914 [D loss: 0.482542, acc.: 77.34%] [G loss: 1.572631]\n",
      "epoch:23 step:21915 [D loss: 0.416916, acc.: 82.03%] [G loss: 1.499537]\n",
      "epoch:23 step:21916 [D loss: 0.558807, acc.: 71.88%] [G loss: 1.430864]\n",
      "epoch:23 step:21917 [D loss: 0.483192, acc.: 80.47%] [G loss: 1.361649]\n",
      "epoch:23 step:21918 [D loss: 0.444259, acc.: 83.59%] [G loss: 1.379815]\n",
      "epoch:23 step:21919 [D loss: 0.416400, acc.: 80.47%] [G loss: 1.288465]\n",
      "epoch:23 step:21920 [D loss: 0.648775, acc.: 61.72%] [G loss: 1.289227]\n",
      "epoch:23 step:21921 [D loss: 0.609563, acc.: 67.97%] [G loss: 1.382450]\n",
      "epoch:23 step:21922 [D loss: 0.643763, acc.: 60.94%] [G loss: 1.539398]\n",
      "epoch:23 step:21923 [D loss: 0.443082, acc.: 78.12%] [G loss: 1.560701]\n",
      "epoch:23 step:21924 [D loss: 0.685682, acc.: 57.81%] [G loss: 1.026919]\n",
      "epoch:23 step:21925 [D loss: 0.633655, acc.: 60.16%] [G loss: 1.313293]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:23 step:21926 [D loss: 0.615943, acc.: 69.53%] [G loss: 1.207670]\n",
      "epoch:23 step:21927 [D loss: 0.584642, acc.: 67.19%] [G loss: 1.037050]\n",
      "epoch:23 step:21928 [D loss: 0.488374, acc.: 75.00%] [G loss: 1.379779]\n",
      "epoch:23 step:21929 [D loss: 0.521203, acc.: 76.56%] [G loss: 1.203113]\n",
      "epoch:23 step:21930 [D loss: 0.445137, acc.: 84.38%] [G loss: 1.300309]\n",
      "epoch:23 step:21931 [D loss: 0.364500, acc.: 86.72%] [G loss: 1.459482]\n",
      "epoch:23 step:21932 [D loss: 0.527787, acc.: 71.88%] [G loss: 1.648854]\n",
      "epoch:23 step:21933 [D loss: 0.576358, acc.: 68.75%] [G loss: 1.665533]\n",
      "epoch:23 step:21934 [D loss: 0.500633, acc.: 74.22%] [G loss: 1.203634]\n",
      "epoch:23 step:21935 [D loss: 0.456237, acc.: 77.34%] [G loss: 1.327793]\n",
      "epoch:23 step:21936 [D loss: 0.607251, acc.: 65.62%] [G loss: 1.103316]\n",
      "epoch:23 step:21937 [D loss: 0.444072, acc.: 82.81%] [G loss: 1.296994]\n",
      "epoch:23 step:21938 [D loss: 0.587968, acc.: 72.66%] [G loss: 1.077370]\n",
      "epoch:23 step:21939 [D loss: 0.582798, acc.: 66.41%] [G loss: 1.382971]\n",
      "epoch:23 step:21940 [D loss: 0.617568, acc.: 59.38%] [G loss: 1.547560]\n",
      "epoch:23 step:21941 [D loss: 0.535327, acc.: 71.09%] [G loss: 1.560523]\n",
      "epoch:23 step:21942 [D loss: 0.676707, acc.: 62.50%] [G loss: 1.261844]\n",
      "epoch:23 step:21943 [D loss: 0.509571, acc.: 74.22%] [G loss: 1.539196]\n",
      "epoch:23 step:21944 [D loss: 0.506710, acc.: 76.56%] [G loss: 1.369201]\n",
      "epoch:23 step:21945 [D loss: 0.688175, acc.: 67.19%] [G loss: 1.523646]\n",
      "epoch:23 step:21946 [D loss: 0.638957, acc.: 64.06%] [G loss: 1.107566]\n",
      "epoch:23 step:21947 [D loss: 0.628162, acc.: 62.50%] [G loss: 1.123977]\n",
      "epoch:23 step:21948 [D loss: 0.482580, acc.: 80.47%] [G loss: 1.396437]\n",
      "epoch:23 step:21949 [D loss: 0.612732, acc.: 69.53%] [G loss: 1.463203]\n",
      "epoch:23 step:21950 [D loss: 0.418378, acc.: 83.59%] [G loss: 1.008284]\n",
      "epoch:23 step:21951 [D loss: 0.633150, acc.: 65.62%] [G loss: 1.175681]\n",
      "epoch:23 step:21952 [D loss: 0.451294, acc.: 79.69%] [G loss: 1.225072]\n",
      "epoch:23 step:21953 [D loss: 0.476062, acc.: 75.78%] [G loss: 1.110063]\n",
      "epoch:23 step:21954 [D loss: 0.684244, acc.: 66.41%] [G loss: 1.518044]\n",
      "epoch:23 step:21955 [D loss: 0.661773, acc.: 60.94%] [G loss: 1.301569]\n",
      "epoch:23 step:21956 [D loss: 0.560396, acc.: 71.88%] [G loss: 1.399397]\n",
      "epoch:23 step:21957 [D loss: 0.563057, acc.: 69.53%] [G loss: 1.470292]\n",
      "epoch:23 step:21958 [D loss: 0.498128, acc.: 78.91%] [G loss: 1.585785]\n",
      "epoch:23 step:21959 [D loss: 0.579186, acc.: 67.19%] [G loss: 1.715520]\n",
      "epoch:23 step:21960 [D loss: 0.545599, acc.: 70.31%] [G loss: 1.455890]\n",
      "epoch:23 step:21961 [D loss: 0.442478, acc.: 82.81%] [G loss: 1.601187]\n",
      "epoch:23 step:21962 [D loss: 0.741148, acc.: 50.78%] [G loss: 1.108914]\n",
      "epoch:23 step:21963 [D loss: 0.613599, acc.: 64.06%] [G loss: 1.643746]\n",
      "epoch:23 step:21964 [D loss: 0.651470, acc.: 66.41%] [G loss: 1.319459]\n",
      "epoch:23 step:21965 [D loss: 0.450840, acc.: 81.25%] [G loss: 1.213552]\n",
      "epoch:23 step:21966 [D loss: 0.439399, acc.: 81.25%] [G loss: 1.279516]\n",
      "epoch:23 step:21967 [D loss: 0.515377, acc.: 74.22%] [G loss: 1.427255]\n",
      "epoch:23 step:21968 [D loss: 0.544111, acc.: 73.44%] [G loss: 1.282468]\n",
      "epoch:23 step:21969 [D loss: 0.612857, acc.: 60.94%] [G loss: 1.253389]\n",
      "epoch:23 step:21970 [D loss: 0.521472, acc.: 77.34%] [G loss: 1.269840]\n",
      "epoch:23 step:21971 [D loss: 0.378033, acc.: 85.16%] [G loss: 1.282619]\n",
      "epoch:23 step:21972 [D loss: 0.642263, acc.: 60.94%] [G loss: 1.473400]\n",
      "epoch:23 step:21973 [D loss: 0.645478, acc.: 62.50%] [G loss: 1.275522]\n",
      "epoch:23 step:21974 [D loss: 0.623570, acc.: 65.62%] [G loss: 1.469192]\n",
      "epoch:23 step:21975 [D loss: 0.543473, acc.: 75.00%] [G loss: 1.462393]\n",
      "epoch:23 step:21976 [D loss: 0.582917, acc.: 75.00%] [G loss: 1.204234]\n",
      "epoch:23 step:21977 [D loss: 0.466674, acc.: 78.91%] [G loss: 2.051370]\n",
      "epoch:23 step:21978 [D loss: 0.582969, acc.: 73.44%] [G loss: 1.133178]\n",
      "epoch:23 step:21979 [D loss: 0.595004, acc.: 70.31%] [G loss: 1.406946]\n",
      "epoch:23 step:21980 [D loss: 0.480407, acc.: 77.34%] [G loss: 1.376511]\n",
      "epoch:23 step:21981 [D loss: 0.500537, acc.: 78.12%] [G loss: 1.451074]\n",
      "epoch:23 step:21982 [D loss: 0.710968, acc.: 60.16%] [G loss: 1.210454]\n",
      "epoch:23 step:21983 [D loss: 0.369073, acc.: 89.06%] [G loss: 1.501355]\n",
      "epoch:23 step:21984 [D loss: 0.479289, acc.: 81.25%] [G loss: 1.674069]\n",
      "epoch:23 step:21985 [D loss: 0.659416, acc.: 67.19%] [G loss: 0.988667]\n",
      "epoch:23 step:21986 [D loss: 0.525946, acc.: 75.00%] [G loss: 1.278755]\n",
      "epoch:23 step:21987 [D loss: 0.525772, acc.: 78.91%] [G loss: 1.239860]\n",
      "epoch:23 step:21988 [D loss: 0.698483, acc.: 56.25%] [G loss: 1.576063]\n",
      "epoch:23 step:21989 [D loss: 0.512932, acc.: 75.00%] [G loss: 1.561137]\n",
      "epoch:23 step:21990 [D loss: 0.515989, acc.: 76.56%] [G loss: 1.270000]\n",
      "epoch:23 step:21991 [D loss: 0.596239, acc.: 66.41%] [G loss: 1.368758]\n",
      "epoch:23 step:21992 [D loss: 0.540928, acc.: 72.66%] [G loss: 1.452944]\n",
      "epoch:23 step:21993 [D loss: 0.638188, acc.: 64.06%] [G loss: 1.352832]\n",
      "epoch:23 step:21994 [D loss: 0.686386, acc.: 63.28%] [G loss: 1.290650]\n",
      "epoch:23 step:21995 [D loss: 0.548518, acc.: 72.66%] [G loss: 1.380322]\n",
      "epoch:23 step:21996 [D loss: 0.464703, acc.: 82.03%] [G loss: 1.316010]\n",
      "epoch:23 step:21997 [D loss: 0.617169, acc.: 63.28%] [G loss: 1.319367]\n",
      "epoch:23 step:21998 [D loss: 0.440685, acc.: 83.59%] [G loss: 1.633990]\n",
      "epoch:23 step:21999 [D loss: 0.510956, acc.: 75.00%] [G loss: 1.471937]\n",
      "epoch:23 step:22000 [D loss: 0.564806, acc.: 74.22%] [G loss: 1.209613]\n",
      "epoch:23 step:22001 [D loss: 0.591277, acc.: 67.97%] [G loss: 1.200894]\n",
      "epoch:23 step:22002 [D loss: 0.523407, acc.: 74.22%] [G loss: 1.504313]\n",
      "epoch:23 step:22003 [D loss: 0.548628, acc.: 73.44%] [G loss: 1.185778]\n",
      "epoch:23 step:22004 [D loss: 0.500697, acc.: 78.91%] [G loss: 1.662482]\n",
      "epoch:23 step:22005 [D loss: 0.626204, acc.: 67.97%] [G loss: 1.114197]\n",
      "epoch:23 step:22006 [D loss: 0.437032, acc.: 82.81%] [G loss: 1.644000]\n",
      "epoch:23 step:22007 [D loss: 0.658074, acc.: 64.06%] [G loss: 1.178716]\n",
      "epoch:23 step:22008 [D loss: 0.723061, acc.: 53.91%] [G loss: 1.249600]\n",
      "epoch:23 step:22009 [D loss: 0.483740, acc.: 76.56%] [G loss: 1.304224]\n",
      "epoch:23 step:22010 [D loss: 0.413377, acc.: 82.03%] [G loss: 1.622481]\n",
      "epoch:23 step:22011 [D loss: 0.630902, acc.: 64.06%] [G loss: 1.290103]\n",
      "epoch:23 step:22012 [D loss: 0.647508, acc.: 62.50%] [G loss: 1.233938]\n",
      "epoch:23 step:22013 [D loss: 0.574873, acc.: 68.75%] [G loss: 1.233425]\n",
      "epoch:23 step:22014 [D loss: 0.619737, acc.: 64.84%] [G loss: 1.258824]\n",
      "epoch:23 step:22015 [D loss: 0.555141, acc.: 71.88%] [G loss: 1.417371]\n",
      "epoch:23 step:22016 [D loss: 0.597426, acc.: 67.19%] [G loss: 1.640923]\n",
      "epoch:23 step:22017 [D loss: 0.506304, acc.: 76.56%] [G loss: 1.180297]\n",
      "epoch:23 step:22018 [D loss: 0.476233, acc.: 75.00%] [G loss: 1.174870]\n",
      "epoch:23 step:22019 [D loss: 0.384647, acc.: 86.72%] [G loss: 1.594900]\n",
      "epoch:23 step:22020 [D loss: 0.595213, acc.: 71.88%] [G loss: 1.187777]\n",
      "epoch:23 step:22021 [D loss: 0.605267, acc.: 71.88%] [G loss: 1.144978]\n",
      "epoch:23 step:22022 [D loss: 0.605228, acc.: 67.19%] [G loss: 1.188466]\n",
      "epoch:23 step:22023 [D loss: 0.619621, acc.: 70.31%] [G loss: 1.136141]\n",
      "epoch:23 step:22024 [D loss: 0.527196, acc.: 71.88%] [G loss: 1.354241]\n",
      "epoch:23 step:22025 [D loss: 0.487372, acc.: 78.91%] [G loss: 1.616009]\n",
      "epoch:23 step:22026 [D loss: 0.530255, acc.: 72.66%] [G loss: 1.568263]\n",
      "epoch:23 step:22027 [D loss: 0.631445, acc.: 64.06%] [G loss: 1.138722]\n",
      "epoch:23 step:22028 [D loss: 0.716440, acc.: 57.81%] [G loss: 1.476602]\n",
      "epoch:23 step:22029 [D loss: 0.643063, acc.: 64.84%] [G loss: 1.024735]\n",
      "epoch:23 step:22030 [D loss: 0.387657, acc.: 89.06%] [G loss: 1.546948]\n",
      "epoch:23 step:22031 [D loss: 0.574363, acc.: 70.31%] [G loss: 1.667213]\n",
      "epoch:23 step:22032 [D loss: 0.619261, acc.: 67.97%] [G loss: 1.334015]\n",
      "epoch:23 step:22033 [D loss: 0.662121, acc.: 59.38%] [G loss: 0.974317]\n",
      "epoch:23 step:22034 [D loss: 0.543004, acc.: 71.88%] [G loss: 1.225851]\n",
      "epoch:23 step:22035 [D loss: 0.593668, acc.: 69.53%] [G loss: 1.668854]\n",
      "epoch:23 step:22036 [D loss: 0.636690, acc.: 65.62%] [G loss: 1.194910]\n",
      "epoch:23 step:22037 [D loss: 0.442023, acc.: 83.59%] [G loss: 1.637204]\n",
      "epoch:23 step:22038 [D loss: 0.486656, acc.: 78.12%] [G loss: 1.421738]\n",
      "epoch:23 step:22039 [D loss: 0.550198, acc.: 73.44%] [G loss: 1.050199]\n",
      "epoch:23 step:22040 [D loss: 0.572231, acc.: 67.19%] [G loss: 1.040650]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:23 step:22041 [D loss: 0.620296, acc.: 60.94%] [G loss: 1.217811]\n",
      "epoch:23 step:22042 [D loss: 0.411857, acc.: 83.59%] [G loss: 1.425737]\n",
      "epoch:23 step:22043 [D loss: 0.506645, acc.: 76.56%] [G loss: 1.548026]\n",
      "epoch:23 step:22044 [D loss: 0.460640, acc.: 78.91%] [G loss: 1.344011]\n",
      "epoch:23 step:22045 [D loss: 0.475730, acc.: 79.69%] [G loss: 1.290189]\n",
      "epoch:23 step:22046 [D loss: 0.610253, acc.: 67.19%] [G loss: 1.228193]\n",
      "epoch:23 step:22047 [D loss: 0.556806, acc.: 71.88%] [G loss: 1.474663]\n",
      "epoch:23 step:22048 [D loss: 0.558039, acc.: 71.09%] [G loss: 1.253166]\n",
      "epoch:23 step:22049 [D loss: 0.457982, acc.: 77.34%] [G loss: 1.454916]\n",
      "epoch:23 step:22050 [D loss: 0.413836, acc.: 85.94%] [G loss: 1.644146]\n",
      "epoch:23 step:22051 [D loss: 0.626233, acc.: 64.84%] [G loss: 1.254604]\n",
      "epoch:23 step:22052 [D loss: 0.449541, acc.: 78.12%] [G loss: 1.399792]\n",
      "epoch:23 step:22053 [D loss: 0.497468, acc.: 77.34%] [G loss: 1.697309]\n",
      "epoch:23 step:22054 [D loss: 0.482255, acc.: 81.25%] [G loss: 1.137649]\n",
      "epoch:23 step:22055 [D loss: 0.506300, acc.: 75.78%] [G loss: 1.404191]\n",
      "epoch:23 step:22056 [D loss: 0.445295, acc.: 82.03%] [G loss: 1.368918]\n",
      "epoch:23 step:22057 [D loss: 0.467916, acc.: 78.12%] [G loss: 1.866596]\n",
      "epoch:23 step:22058 [D loss: 0.503681, acc.: 75.78%] [G loss: 1.338121]\n",
      "epoch:23 step:22059 [D loss: 0.535850, acc.: 69.53%] [G loss: 1.276893]\n",
      "epoch:23 step:22060 [D loss: 0.586595, acc.: 71.09%] [G loss: 1.440568]\n",
      "epoch:23 step:22061 [D loss: 0.378148, acc.: 85.16%] [G loss: 1.754052]\n",
      "epoch:23 step:22062 [D loss: 0.566411, acc.: 75.78%] [G loss: 1.438664]\n",
      "epoch:23 step:22063 [D loss: 0.520387, acc.: 76.56%] [G loss: 1.613775]\n",
      "epoch:23 step:22064 [D loss: 0.342566, acc.: 92.19%] [G loss: 2.015679]\n",
      "epoch:23 step:22065 [D loss: 0.487496, acc.: 80.47%] [G loss: 1.553003]\n",
      "epoch:23 step:22066 [D loss: 0.577833, acc.: 73.44%] [G loss: 1.023856]\n",
      "epoch:23 step:22067 [D loss: 0.531479, acc.: 69.53%] [G loss: 1.343753]\n",
      "epoch:23 step:22068 [D loss: 0.492938, acc.: 78.12%] [G loss: 1.210458]\n",
      "epoch:23 step:22069 [D loss: 0.478923, acc.: 82.03%] [G loss: 1.929417]\n",
      "epoch:23 step:22070 [D loss: 0.536660, acc.: 71.88%] [G loss: 1.714056]\n",
      "epoch:23 step:22071 [D loss: 0.511448, acc.: 75.00%] [G loss: 1.524311]\n",
      "epoch:23 step:22072 [D loss: 0.457050, acc.: 82.03%] [G loss: 1.103801]\n",
      "epoch:23 step:22073 [D loss: 0.495069, acc.: 74.22%] [G loss: 1.036172]\n",
      "epoch:23 step:22074 [D loss: 0.472692, acc.: 82.03%] [G loss: 1.477919]\n",
      "epoch:23 step:22075 [D loss: 0.527902, acc.: 75.00%] [G loss: 1.223974]\n",
      "epoch:23 step:22076 [D loss: 0.544611, acc.: 67.97%] [G loss: 1.366610]\n",
      "epoch:23 step:22077 [D loss: 0.612515, acc.: 67.19%] [G loss: 1.166371]\n",
      "epoch:23 step:22078 [D loss: 0.583320, acc.: 71.09%] [G loss: 1.393239]\n",
      "epoch:23 step:22079 [D loss: 0.512237, acc.: 74.22%] [G loss: 1.323110]\n",
      "epoch:23 step:22080 [D loss: 0.500665, acc.: 78.91%] [G loss: 1.400324]\n",
      "epoch:23 step:22081 [D loss: 0.568223, acc.: 73.44%] [G loss: 1.307188]\n",
      "epoch:23 step:22082 [D loss: 0.599518, acc.: 70.31%] [G loss: 1.199568]\n",
      "epoch:23 step:22083 [D loss: 0.493327, acc.: 74.22%] [G loss: 1.447992]\n",
      "epoch:23 step:22084 [D loss: 0.534338, acc.: 74.22%] [G loss: 1.316901]\n",
      "epoch:23 step:22085 [D loss: 0.651638, acc.: 63.28%] [G loss: 1.141366]\n",
      "epoch:23 step:22086 [D loss: 0.627186, acc.: 65.62%] [G loss: 1.460939]\n",
      "epoch:23 step:22087 [D loss: 0.518943, acc.: 74.22%] [G loss: 1.262209]\n",
      "epoch:23 step:22088 [D loss: 0.480176, acc.: 82.81%] [G loss: 1.722140]\n",
      "epoch:23 step:22089 [D loss: 0.682665, acc.: 57.03%] [G loss: 1.096107]\n",
      "epoch:23 step:22090 [D loss: 0.417293, acc.: 80.47%] [G loss: 1.762539]\n",
      "epoch:23 step:22091 [D loss: 0.475984, acc.: 77.34%] [G loss: 1.568585]\n",
      "epoch:23 step:22092 [D loss: 0.524499, acc.: 71.09%] [G loss: 1.464452]\n",
      "epoch:23 step:22093 [D loss: 0.598934, acc.: 67.97%] [G loss: 1.511827]\n",
      "epoch:23 step:22094 [D loss: 0.614398, acc.: 66.41%] [G loss: 1.382345]\n",
      "epoch:23 step:22095 [D loss: 0.469237, acc.: 78.91%] [G loss: 1.354941]\n",
      "epoch:23 step:22096 [D loss: 0.566431, acc.: 67.19%] [G loss: 1.775286]\n",
      "epoch:23 step:22097 [D loss: 0.676230, acc.: 59.38%] [G loss: 1.290017]\n",
      "epoch:23 step:22098 [D loss: 0.596256, acc.: 68.75%] [G loss: 1.477098]\n",
      "epoch:23 step:22099 [D loss: 0.597396, acc.: 67.97%] [G loss: 1.251033]\n",
      "epoch:23 step:22100 [D loss: 0.445973, acc.: 80.47%] [G loss: 1.511937]\n",
      "epoch:23 step:22101 [D loss: 0.604709, acc.: 69.53%] [G loss: 1.560177]\n",
      "epoch:23 step:22102 [D loss: 0.718641, acc.: 57.03%] [G loss: 1.137226]\n",
      "epoch:23 step:22103 [D loss: 0.305185, acc.: 92.97%] [G loss: 1.706725]\n",
      "epoch:23 step:22104 [D loss: 0.533001, acc.: 78.91%] [G loss: 1.434055]\n",
      "epoch:23 step:22105 [D loss: 0.631497, acc.: 66.41%] [G loss: 0.991848]\n",
      "epoch:23 step:22106 [D loss: 0.478314, acc.: 76.56%] [G loss: 1.131398]\n",
      "epoch:23 step:22107 [D loss: 0.487057, acc.: 75.00%] [G loss: 1.476840]\n",
      "epoch:23 step:22108 [D loss: 0.442278, acc.: 79.69%] [G loss: 1.339854]\n",
      "epoch:23 step:22109 [D loss: 0.588596, acc.: 70.31%] [G loss: 1.311316]\n",
      "epoch:23 step:22110 [D loss: 0.602328, acc.: 71.09%] [G loss: 1.213276]\n",
      "epoch:23 step:22111 [D loss: 0.468152, acc.: 81.25%] [G loss: 1.794087]\n",
      "epoch:23 step:22112 [D loss: 0.661065, acc.: 59.38%] [G loss: 1.335024]\n",
      "epoch:23 step:22113 [D loss: 0.556900, acc.: 71.09%] [G loss: 2.087088]\n",
      "epoch:23 step:22114 [D loss: 0.544456, acc.: 72.66%] [G loss: 1.406505]\n",
      "epoch:23 step:22115 [D loss: 0.572624, acc.: 71.09%] [G loss: 1.219917]\n",
      "epoch:23 step:22116 [D loss: 0.505492, acc.: 76.56%] [G loss: 1.377961]\n",
      "epoch:23 step:22117 [D loss: 0.494411, acc.: 75.78%] [G loss: 1.632312]\n",
      "epoch:23 step:22118 [D loss: 0.777607, acc.: 52.34%] [G loss: 1.136456]\n",
      "epoch:23 step:22119 [D loss: 0.830307, acc.: 47.66%] [G loss: 1.627868]\n",
      "epoch:23 step:22120 [D loss: 0.533050, acc.: 70.31%] [G loss: 1.623310]\n",
      "epoch:23 step:22121 [D loss: 0.621393, acc.: 65.62%] [G loss: 1.254054]\n",
      "epoch:23 step:22122 [D loss: 0.538577, acc.: 70.31%] [G loss: 1.170460]\n",
      "epoch:23 step:22123 [D loss: 0.485976, acc.: 75.78%] [G loss: 1.617869]\n",
      "epoch:23 step:22124 [D loss: 0.597329, acc.: 67.19%] [G loss: 1.446740]\n",
      "epoch:23 step:22125 [D loss: 0.733215, acc.: 50.00%] [G loss: 0.878267]\n",
      "epoch:23 step:22126 [D loss: 0.508156, acc.: 76.56%] [G loss: 1.715070]\n",
      "epoch:23 step:22127 [D loss: 0.525911, acc.: 72.66%] [G loss: 1.092791]\n",
      "epoch:23 step:22128 [D loss: 0.543497, acc.: 74.22%] [G loss: 1.649105]\n",
      "epoch:23 step:22129 [D loss: 0.570910, acc.: 65.62%] [G loss: 1.473982]\n",
      "epoch:23 step:22130 [D loss: 0.644457, acc.: 60.94%] [G loss: 1.302741]\n",
      "epoch:23 step:22131 [D loss: 0.463663, acc.: 75.78%] [G loss: 1.357866]\n",
      "epoch:23 step:22132 [D loss: 0.507128, acc.: 74.22%] [G loss: 1.226810]\n",
      "epoch:23 step:22133 [D loss: 0.422187, acc.: 85.94%] [G loss: 1.529088]\n",
      "epoch:23 step:22134 [D loss: 0.487451, acc.: 78.91%] [G loss: 1.271534]\n",
      "epoch:23 step:22135 [D loss: 0.490597, acc.: 75.78%] [G loss: 1.384798]\n",
      "epoch:23 step:22136 [D loss: 0.604385, acc.: 67.97%] [G loss: 1.373654]\n",
      "epoch:23 step:22137 [D loss: 0.470204, acc.: 78.91%] [G loss: 1.552339]\n",
      "epoch:23 step:22138 [D loss: 0.654293, acc.: 67.97%] [G loss: 1.158025]\n",
      "epoch:23 step:22139 [D loss: 0.637765, acc.: 61.72%] [G loss: 1.483479]\n",
      "epoch:23 step:22140 [D loss: 0.520443, acc.: 73.44%] [G loss: 1.176636]\n",
      "epoch:23 step:22141 [D loss: 0.596857, acc.: 67.97%] [G loss: 1.425133]\n",
      "epoch:23 step:22142 [D loss: 0.680056, acc.: 65.62%] [G loss: 1.314168]\n",
      "epoch:23 step:22143 [D loss: 0.510816, acc.: 75.78%] [G loss: 1.469478]\n",
      "epoch:23 step:22144 [D loss: 0.591855, acc.: 71.88%] [G loss: 1.593483]\n",
      "epoch:23 step:22145 [D loss: 0.619300, acc.: 65.62%] [G loss: 1.469298]\n",
      "epoch:23 step:22146 [D loss: 0.546286, acc.: 74.22%] [G loss: 1.328721]\n",
      "epoch:23 step:22147 [D loss: 0.568168, acc.: 66.41%] [G loss: 1.481344]\n",
      "epoch:23 step:22148 [D loss: 0.406650, acc.: 86.72%] [G loss: 1.771076]\n",
      "epoch:23 step:22149 [D loss: 0.788918, acc.: 47.66%] [G loss: 1.406287]\n",
      "epoch:23 step:22150 [D loss: 0.346961, acc.: 89.06%] [G loss: 1.658932]\n",
      "epoch:23 step:22151 [D loss: 0.410949, acc.: 82.81%] [G loss: 1.488037]\n",
      "epoch:23 step:22152 [D loss: 0.728128, acc.: 58.59%] [G loss: 1.332255]\n",
      "epoch:23 step:22153 [D loss: 0.526584, acc.: 79.69%] [G loss: 1.326805]\n",
      "epoch:23 step:22154 [D loss: 0.602312, acc.: 67.19%] [G loss: 1.221689]\n",
      "epoch:23 step:22155 [D loss: 0.676691, acc.: 62.50%] [G loss: 0.976968]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:23 step:22156 [D loss: 0.507383, acc.: 76.56%] [G loss: 1.030030]\n",
      "epoch:23 step:22157 [D loss: 0.669587, acc.: 63.28%] [G loss: 1.319439]\n",
      "epoch:23 step:22158 [D loss: 0.492864, acc.: 82.03%] [G loss: 1.520814]\n",
      "epoch:23 step:22159 [D loss: 0.526361, acc.: 75.00%] [G loss: 1.175357]\n",
      "epoch:23 step:22160 [D loss: 0.623955, acc.: 67.19%] [G loss: 1.447306]\n",
      "epoch:23 step:22161 [D loss: 0.469525, acc.: 74.22%] [G loss: 1.661191]\n",
      "epoch:23 step:22162 [D loss: 0.653736, acc.: 60.16%] [G loss: 1.613161]\n",
      "epoch:23 step:22163 [D loss: 0.654310, acc.: 63.28%] [G loss: 1.562347]\n",
      "epoch:23 step:22164 [D loss: 0.528038, acc.: 73.44%] [G loss: 1.336048]\n",
      "epoch:23 step:22165 [D loss: 0.620703, acc.: 68.75%] [G loss: 1.473758]\n",
      "epoch:23 step:22166 [D loss: 0.458867, acc.: 80.47%] [G loss: 1.702935]\n",
      "epoch:23 step:22167 [D loss: 0.695721, acc.: 60.16%] [G loss: 1.262713]\n",
      "epoch:23 step:22168 [D loss: 0.662668, acc.: 59.38%] [G loss: 1.549345]\n",
      "epoch:23 step:22169 [D loss: 0.548281, acc.: 74.22%] [G loss: 1.912185]\n",
      "epoch:23 step:22170 [D loss: 0.699405, acc.: 56.25%] [G loss: 1.476054]\n",
      "epoch:23 step:22171 [D loss: 0.559503, acc.: 68.75%] [G loss: 1.520583]\n",
      "epoch:23 step:22172 [D loss: 0.546005, acc.: 72.66%] [G loss: 0.876534]\n",
      "epoch:23 step:22173 [D loss: 0.759416, acc.: 56.25%] [G loss: 1.156774]\n",
      "epoch:23 step:22174 [D loss: 0.539849, acc.: 76.56%] [G loss: 1.303911]\n",
      "epoch:23 step:22175 [D loss: 0.680642, acc.: 58.59%] [G loss: 1.539170]\n",
      "epoch:23 step:22176 [D loss: 0.556221, acc.: 68.75%] [G loss: 1.557027]\n",
      "epoch:23 step:22177 [D loss: 0.651457, acc.: 67.19%] [G loss: 1.065956]\n",
      "epoch:23 step:22178 [D loss: 0.540283, acc.: 71.88%] [G loss: 1.274119]\n",
      "epoch:23 step:22179 [D loss: 0.618818, acc.: 67.97%] [G loss: 1.215189]\n",
      "epoch:23 step:22180 [D loss: 0.562541, acc.: 70.31%] [G loss: 1.470119]\n",
      "epoch:23 step:22181 [D loss: 0.454396, acc.: 79.69%] [G loss: 1.326486]\n",
      "epoch:23 step:22182 [D loss: 0.485453, acc.: 77.34%] [G loss: 1.705937]\n",
      "epoch:23 step:22183 [D loss: 0.617332, acc.: 63.28%] [G loss: 1.642385]\n",
      "epoch:23 step:22184 [D loss: 0.538866, acc.: 71.88%] [G loss: 1.692663]\n",
      "epoch:23 step:22185 [D loss: 0.641468, acc.: 64.06%] [G loss: 1.833018]\n",
      "epoch:23 step:22186 [D loss: 0.654433, acc.: 62.50%] [G loss: 1.212376]\n",
      "epoch:23 step:22187 [D loss: 0.521733, acc.: 72.66%] [G loss: 1.229581]\n",
      "epoch:23 step:22188 [D loss: 0.516544, acc.: 70.31%] [G loss: 1.085338]\n",
      "epoch:23 step:22189 [D loss: 0.533479, acc.: 75.78%] [G loss: 1.314953]\n",
      "epoch:23 step:22190 [D loss: 0.589636, acc.: 71.88%] [G loss: 1.550789]\n",
      "epoch:23 step:22191 [D loss: 0.563448, acc.: 69.53%] [G loss: 1.576260]\n",
      "epoch:23 step:22192 [D loss: 0.679066, acc.: 62.50%] [G loss: 1.415604]\n",
      "epoch:23 step:22193 [D loss: 0.458442, acc.: 80.47%] [G loss: 1.392556]\n",
      "epoch:23 step:22194 [D loss: 0.691812, acc.: 62.50%] [G loss: 1.546436]\n",
      "epoch:23 step:22195 [D loss: 0.722919, acc.: 57.81%] [G loss: 1.026350]\n",
      "epoch:23 step:22196 [D loss: 0.500339, acc.: 75.78%] [G loss: 1.400756]\n",
      "epoch:23 step:22197 [D loss: 0.662848, acc.: 64.06%] [G loss: 1.457896]\n",
      "epoch:23 step:22198 [D loss: 0.533659, acc.: 74.22%] [G loss: 1.535318]\n",
      "epoch:23 step:22199 [D loss: 0.520472, acc.: 71.88%] [G loss: 1.424500]\n",
      "epoch:23 step:22200 [D loss: 0.570425, acc.: 70.31%] [G loss: 1.471686]\n",
      "epoch:23 step:22201 [D loss: 0.483272, acc.: 78.12%] [G loss: 1.474497]\n",
      "epoch:23 step:22202 [D loss: 0.351096, acc.: 89.84%] [G loss: 1.928895]\n",
      "epoch:23 step:22203 [D loss: 0.618510, acc.: 65.62%] [G loss: 1.139427]\n",
      "epoch:23 step:22204 [D loss: 0.612522, acc.: 65.62%] [G loss: 1.783872]\n",
      "epoch:23 step:22205 [D loss: 0.524233, acc.: 76.56%] [G loss: 1.361627]\n",
      "epoch:23 step:22206 [D loss: 0.520264, acc.: 71.09%] [G loss: 1.239198]\n",
      "epoch:23 step:22207 [D loss: 0.647225, acc.: 62.50%] [G loss: 1.642583]\n",
      "epoch:23 step:22208 [D loss: 0.687884, acc.: 60.94%] [G loss: 1.263418]\n",
      "epoch:23 step:22209 [D loss: 0.597302, acc.: 66.41%] [G loss: 1.418002]\n",
      "epoch:23 step:22210 [D loss: 0.579042, acc.: 70.31%] [G loss: 1.641020]\n",
      "epoch:23 step:22211 [D loss: 0.607281, acc.: 66.41%] [G loss: 1.244197]\n",
      "epoch:23 step:22212 [D loss: 0.678649, acc.: 60.94%] [G loss: 1.047426]\n",
      "epoch:23 step:22213 [D loss: 0.723977, acc.: 57.03%] [G loss: 1.239020]\n",
      "epoch:23 step:22214 [D loss: 0.502756, acc.: 78.12%] [G loss: 1.305689]\n",
      "epoch:23 step:22215 [D loss: 0.570611, acc.: 71.09%] [G loss: 1.361716]\n",
      "epoch:23 step:22216 [D loss: 0.576089, acc.: 72.66%] [G loss: 1.157064]\n",
      "epoch:23 step:22217 [D loss: 0.562472, acc.: 69.53%] [G loss: 1.290714]\n",
      "epoch:23 step:22218 [D loss: 0.440596, acc.: 81.25%] [G loss: 1.535190]\n",
      "epoch:23 step:22219 [D loss: 0.792511, acc.: 60.16%] [G loss: 1.530832]\n",
      "epoch:23 step:22220 [D loss: 0.503668, acc.: 71.88%] [G loss: 1.457123]\n",
      "epoch:23 step:22221 [D loss: 0.664609, acc.: 64.06%] [G loss: 1.391877]\n",
      "epoch:23 step:22222 [D loss: 0.651930, acc.: 64.84%] [G loss: 1.571839]\n",
      "epoch:23 step:22223 [D loss: 0.540189, acc.: 72.66%] [G loss: 1.254300]\n",
      "epoch:23 step:22224 [D loss: 0.642130, acc.: 64.84%] [G loss: 1.272256]\n",
      "epoch:23 step:22225 [D loss: 0.408622, acc.: 84.38%] [G loss: 1.480747]\n",
      "epoch:23 step:22226 [D loss: 0.734613, acc.: 60.16%] [G loss: 1.391977]\n",
      "epoch:23 step:22227 [D loss: 0.567032, acc.: 70.31%] [G loss: 1.539056]\n",
      "epoch:23 step:22228 [D loss: 0.529219, acc.: 71.88%] [G loss: 1.682315]\n",
      "epoch:23 step:22229 [D loss: 0.620875, acc.: 67.97%] [G loss: 1.383516]\n",
      "epoch:23 step:22230 [D loss: 0.608183, acc.: 66.41%] [G loss: 1.029068]\n",
      "epoch:23 step:22231 [D loss: 0.645114, acc.: 63.28%] [G loss: 1.133503]\n",
      "epoch:23 step:22232 [D loss: 0.666909, acc.: 64.06%] [G loss: 1.249578]\n",
      "epoch:23 step:22233 [D loss: 0.330590, acc.: 91.41%] [G loss: 1.771239]\n",
      "epoch:23 step:22234 [D loss: 0.780753, acc.: 50.78%] [G loss: 0.945559]\n",
      "epoch:23 step:22235 [D loss: 0.700960, acc.: 60.94%] [G loss: 1.627768]\n",
      "epoch:23 step:22236 [D loss: 0.550801, acc.: 73.44%] [G loss: 1.430815]\n",
      "epoch:23 step:22237 [D loss: 0.518925, acc.: 75.00%] [G loss: 1.371655]\n",
      "epoch:23 step:22238 [D loss: 0.422841, acc.: 83.59%] [G loss: 1.747473]\n",
      "epoch:23 step:22239 [D loss: 0.513893, acc.: 76.56%] [G loss: 1.927632]\n",
      "epoch:23 step:22240 [D loss: 0.726646, acc.: 57.03%] [G loss: 1.311369]\n",
      "epoch:23 step:22241 [D loss: 0.488819, acc.: 77.34%] [G loss: 1.154005]\n",
      "epoch:23 step:22242 [D loss: 0.500251, acc.: 78.12%] [G loss: 1.583169]\n",
      "epoch:23 step:22243 [D loss: 0.476024, acc.: 78.12%] [G loss: 1.564913]\n",
      "epoch:23 step:22244 [D loss: 0.543813, acc.: 72.66%] [G loss: 1.175267]\n",
      "epoch:23 step:22245 [D loss: 0.738050, acc.: 54.69%] [G loss: 1.191854]\n",
      "epoch:23 step:22246 [D loss: 0.460120, acc.: 79.69%] [G loss: 1.322603]\n",
      "epoch:23 step:22247 [D loss: 0.599562, acc.: 67.19%] [G loss: 1.170559]\n",
      "epoch:23 step:22248 [D loss: 0.663876, acc.: 61.72%] [G loss: 1.500648]\n",
      "epoch:23 step:22249 [D loss: 0.635970, acc.: 65.62%] [G loss: 1.573349]\n",
      "epoch:23 step:22250 [D loss: 0.487764, acc.: 75.00%] [G loss: 1.713552]\n",
      "epoch:23 step:22251 [D loss: 0.527388, acc.: 73.44%] [G loss: 1.413286]\n",
      "epoch:23 step:22252 [D loss: 0.432743, acc.: 82.81%] [G loss: 1.742341]\n",
      "epoch:23 step:22253 [D loss: 0.395202, acc.: 85.16%] [G loss: 1.550013]\n",
      "epoch:23 step:22254 [D loss: 0.615151, acc.: 66.41%] [G loss: 1.338525]\n",
      "epoch:23 step:22255 [D loss: 0.515948, acc.: 75.00%] [G loss: 0.973660]\n",
      "epoch:23 step:22256 [D loss: 0.557812, acc.: 70.31%] [G loss: 1.422234]\n",
      "epoch:23 step:22257 [D loss: 0.537283, acc.: 74.22%] [G loss: 1.199554]\n",
      "epoch:23 step:22258 [D loss: 0.472616, acc.: 78.91%] [G loss: 1.144219]\n",
      "epoch:23 step:22259 [D loss: 0.512285, acc.: 72.66%] [G loss: 1.511318]\n",
      "epoch:23 step:22260 [D loss: 0.602441, acc.: 65.62%] [G loss: 1.344495]\n",
      "epoch:23 step:22261 [D loss: 0.642899, acc.: 65.62%] [G loss: 1.358272]\n",
      "epoch:23 step:22262 [D loss: 0.482447, acc.: 75.78%] [G loss: 1.758307]\n",
      "epoch:23 step:22263 [D loss: 0.662713, acc.: 60.16%] [G loss: 1.321841]\n",
      "epoch:23 step:22264 [D loss: 0.579051, acc.: 66.41%] [G loss: 1.341237]\n",
      "epoch:23 step:22265 [D loss: 0.828239, acc.: 42.97%] [G loss: 0.926074]\n",
      "epoch:23 step:22266 [D loss: 0.633139, acc.: 63.28%] [G loss: 1.489493]\n",
      "epoch:23 step:22267 [D loss: 0.543256, acc.: 77.34%] [G loss: 1.265902]\n",
      "epoch:23 step:22268 [D loss: 0.502672, acc.: 75.00%] [G loss: 1.366210]\n",
      "epoch:23 step:22269 [D loss: 0.391723, acc.: 88.28%] [G loss: 1.338340]\n",
      "epoch:23 step:22270 [D loss: 0.470394, acc.: 81.25%] [G loss: 1.252036]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:23 step:22271 [D loss: 0.483837, acc.: 76.56%] [G loss: 1.731449]\n",
      "epoch:23 step:22272 [D loss: 0.467140, acc.: 78.91%] [G loss: 1.358729]\n",
      "epoch:23 step:22273 [D loss: 0.662051, acc.: 61.72%] [G loss: 1.430232]\n",
      "epoch:23 step:22274 [D loss: 0.644134, acc.: 61.72%] [G loss: 1.147334]\n",
      "epoch:23 step:22275 [D loss: 0.592374, acc.: 67.19%] [G loss: 0.849891]\n",
      "epoch:23 step:22276 [D loss: 0.671935, acc.: 58.59%] [G loss: 1.256232]\n",
      "epoch:23 step:22277 [D loss: 0.638394, acc.: 67.19%] [G loss: 1.617174]\n",
      "epoch:23 step:22278 [D loss: 0.499798, acc.: 75.78%] [G loss: 1.266129]\n",
      "epoch:23 step:22279 [D loss: 0.513525, acc.: 77.34%] [G loss: 1.892615]\n",
      "epoch:23 step:22280 [D loss: 0.539357, acc.: 73.44%] [G loss: 1.522980]\n",
      "epoch:23 step:22281 [D loss: 0.510067, acc.: 77.34%] [G loss: 1.126814]\n",
      "epoch:23 step:22282 [D loss: 0.675791, acc.: 64.06%] [G loss: 1.065590]\n",
      "epoch:23 step:22283 [D loss: 0.501740, acc.: 78.12%] [G loss: 1.460307]\n",
      "epoch:23 step:22284 [D loss: 0.507079, acc.: 71.88%] [G loss: 1.078420]\n",
      "epoch:23 step:22285 [D loss: 0.619876, acc.: 66.41%] [G loss: 1.280673]\n",
      "epoch:23 step:22286 [D loss: 0.540656, acc.: 71.88%] [G loss: 1.152139]\n",
      "epoch:23 step:22287 [D loss: 0.579298, acc.: 70.31%] [G loss: 1.275860]\n",
      "epoch:23 step:22288 [D loss: 0.581056, acc.: 70.31%] [G loss: 1.432585]\n",
      "epoch:23 step:22289 [D loss: 0.653746, acc.: 60.94%] [G loss: 1.380032]\n",
      "epoch:23 step:22290 [D loss: 0.669667, acc.: 64.84%] [G loss: 1.044673]\n",
      "epoch:23 step:22291 [D loss: 0.568406, acc.: 71.88%] [G loss: 1.616770]\n",
      "epoch:23 step:22292 [D loss: 0.642231, acc.: 60.94%] [G loss: 0.977318]\n",
      "epoch:23 step:22293 [D loss: 0.563453, acc.: 72.66%] [G loss: 1.133658]\n",
      "epoch:23 step:22294 [D loss: 0.570773, acc.: 71.88%] [G loss: 1.379461]\n",
      "epoch:23 step:22295 [D loss: 0.411989, acc.: 82.81%] [G loss: 1.393573]\n",
      "epoch:23 step:22296 [D loss: 0.557676, acc.: 73.44%] [G loss: 1.483516]\n",
      "epoch:23 step:22297 [D loss: 0.534486, acc.: 71.88%] [G loss: 1.500170]\n",
      "epoch:23 step:22298 [D loss: 0.511433, acc.: 74.22%] [G loss: 1.314385]\n",
      "epoch:23 step:22299 [D loss: 0.671709, acc.: 64.06%] [G loss: 1.365033]\n",
      "epoch:23 step:22300 [D loss: 0.578779, acc.: 70.31%] [G loss: 1.289139]\n",
      "epoch:23 step:22301 [D loss: 0.469668, acc.: 81.25%] [G loss: 1.042211]\n",
      "epoch:23 step:22302 [D loss: 0.475114, acc.: 79.69%] [G loss: 1.646686]\n",
      "epoch:23 step:22303 [D loss: 0.670973, acc.: 59.38%] [G loss: 1.319182]\n",
      "epoch:23 step:22304 [D loss: 0.427340, acc.: 82.03%] [G loss: 1.548337]\n",
      "epoch:23 step:22305 [D loss: 0.712760, acc.: 60.94%] [G loss: 1.392243]\n",
      "epoch:23 step:22306 [D loss: 0.439242, acc.: 83.59%] [G loss: 1.677888]\n",
      "epoch:23 step:22307 [D loss: 0.596224, acc.: 67.97%] [G loss: 1.280514]\n",
      "epoch:23 step:22308 [D loss: 0.566353, acc.: 74.22%] [G loss: 1.161320]\n",
      "epoch:23 step:22309 [D loss: 0.577201, acc.: 67.19%] [G loss: 1.369043]\n",
      "epoch:23 step:22310 [D loss: 0.423143, acc.: 85.16%] [G loss: 1.385803]\n",
      "epoch:23 step:22311 [D loss: 0.397064, acc.: 85.16%] [G loss: 1.793749]\n",
      "epoch:23 step:22312 [D loss: 0.668334, acc.: 63.28%] [G loss: 1.172900]\n",
      "epoch:23 step:22313 [D loss: 0.735599, acc.: 50.78%] [G loss: 1.149208]\n",
      "epoch:23 step:22314 [D loss: 0.535688, acc.: 75.00%] [G loss: 1.428369]\n",
      "epoch:23 step:22315 [D loss: 0.503056, acc.: 76.56%] [G loss: 1.445504]\n",
      "epoch:23 step:22316 [D loss: 0.444498, acc.: 82.03%] [G loss: 1.478363]\n",
      "epoch:23 step:22317 [D loss: 0.557024, acc.: 68.75%] [G loss: 1.401560]\n",
      "epoch:23 step:22318 [D loss: 0.511372, acc.: 77.34%] [G loss: 1.498115]\n",
      "epoch:23 step:22319 [D loss: 0.524459, acc.: 74.22%] [G loss: 1.409457]\n",
      "epoch:23 step:22320 [D loss: 0.578437, acc.: 69.53%] [G loss: 1.229185]\n",
      "epoch:23 step:22321 [D loss: 0.579805, acc.: 69.53%] [G loss: 1.468309]\n",
      "epoch:23 step:22322 [D loss: 0.517636, acc.: 76.56%] [G loss: 1.919101]\n",
      "epoch:23 step:22323 [D loss: 0.722861, acc.: 60.94%] [G loss: 1.137830]\n",
      "epoch:23 step:22324 [D loss: 0.542798, acc.: 74.22%] [G loss: 1.308492]\n",
      "epoch:23 step:22325 [D loss: 0.571098, acc.: 71.09%] [G loss: 1.447901]\n",
      "epoch:23 step:22326 [D loss: 0.691059, acc.: 60.16%] [G loss: 1.202523]\n",
      "epoch:23 step:22327 [D loss: 0.558055, acc.: 71.09%] [G loss: 1.272559]\n",
      "epoch:23 step:22328 [D loss: 0.541227, acc.: 67.19%] [G loss: 1.308827]\n",
      "epoch:23 step:22329 [D loss: 0.499246, acc.: 78.91%] [G loss: 1.259041]\n",
      "epoch:23 step:22330 [D loss: 0.531946, acc.: 78.91%] [G loss: 1.478497]\n",
      "epoch:23 step:22331 [D loss: 0.661848, acc.: 59.38%] [G loss: 0.963544]\n",
      "epoch:23 step:22332 [D loss: 0.507608, acc.: 77.34%] [G loss: 0.892813]\n",
      "epoch:23 step:22333 [D loss: 0.425901, acc.: 81.25%] [G loss: 1.347513]\n",
      "epoch:23 step:22334 [D loss: 0.534168, acc.: 72.66%] [G loss: 1.330436]\n",
      "epoch:23 step:22335 [D loss: 0.506157, acc.: 76.56%] [G loss: 1.200112]\n",
      "epoch:23 step:22336 [D loss: 0.405854, acc.: 82.81%] [G loss: 1.576442]\n",
      "epoch:23 step:22337 [D loss: 0.605559, acc.: 61.72%] [G loss: 1.144705]\n",
      "epoch:23 step:22338 [D loss: 0.586220, acc.: 69.53%] [G loss: 1.272942]\n",
      "epoch:23 step:22339 [D loss: 0.561131, acc.: 69.53%] [G loss: 1.218416]\n",
      "epoch:23 step:22340 [D loss: 0.741144, acc.: 53.12%] [G loss: 1.108834]\n",
      "epoch:23 step:22341 [D loss: 0.512231, acc.: 73.44%] [G loss: 1.183391]\n",
      "epoch:23 step:22342 [D loss: 0.528435, acc.: 70.31%] [G loss: 1.480524]\n",
      "epoch:23 step:22343 [D loss: 0.633409, acc.: 67.97%] [G loss: 1.381237]\n",
      "epoch:23 step:22344 [D loss: 0.567788, acc.: 67.19%] [G loss: 1.454484]\n",
      "epoch:23 step:22345 [D loss: 0.403412, acc.: 90.62%] [G loss: 1.939376]\n",
      "epoch:23 step:22346 [D loss: 0.581303, acc.: 66.41%] [G loss: 1.524715]\n",
      "epoch:23 step:22347 [D loss: 0.527825, acc.: 71.88%] [G loss: 1.113499]\n",
      "epoch:23 step:22348 [D loss: 0.586269, acc.: 67.97%] [G loss: 1.525662]\n",
      "epoch:23 step:22349 [D loss: 0.707944, acc.: 60.16%] [G loss: 1.381463]\n",
      "epoch:23 step:22350 [D loss: 0.789322, acc.: 50.78%] [G loss: 1.193604]\n",
      "epoch:23 step:22351 [D loss: 0.422118, acc.: 85.94%] [G loss: 1.367512]\n",
      "epoch:23 step:22352 [D loss: 0.611828, acc.: 65.62%] [G loss: 1.257358]\n",
      "epoch:23 step:22353 [D loss: 0.495219, acc.: 77.34%] [G loss: 0.941939]\n",
      "epoch:23 step:22354 [D loss: 0.595588, acc.: 67.19%] [G loss: 1.235632]\n",
      "epoch:23 step:22355 [D loss: 0.515531, acc.: 74.22%] [G loss: 1.354588]\n",
      "epoch:23 step:22356 [D loss: 0.535884, acc.: 77.34%] [G loss: 1.474461]\n",
      "epoch:23 step:22357 [D loss: 0.443941, acc.: 82.03%] [G loss: 1.356298]\n",
      "epoch:23 step:22358 [D loss: 0.534570, acc.: 70.31%] [G loss: 1.455311]\n",
      "epoch:23 step:22359 [D loss: 0.536095, acc.: 75.00%] [G loss: 1.224270]\n",
      "epoch:23 step:22360 [D loss: 0.562669, acc.: 73.44%] [G loss: 1.195797]\n",
      "epoch:23 step:22361 [D loss: 0.403497, acc.: 85.94%] [G loss: 1.157296]\n",
      "epoch:23 step:22362 [D loss: 0.495442, acc.: 78.12%] [G loss: 1.313154]\n",
      "epoch:23 step:22363 [D loss: 0.436642, acc.: 83.59%] [G loss: 1.387303]\n",
      "epoch:23 step:22364 [D loss: 0.523216, acc.: 75.78%] [G loss: 1.756609]\n",
      "epoch:23 step:22365 [D loss: 0.541177, acc.: 71.88%] [G loss: 1.449757]\n",
      "epoch:23 step:22366 [D loss: 0.575868, acc.: 69.53%] [G loss: 1.471329]\n",
      "epoch:23 step:22367 [D loss: 0.514451, acc.: 74.22%] [G loss: 1.319734]\n",
      "epoch:23 step:22368 [D loss: 0.522238, acc.: 78.91%] [G loss: 1.572549]\n",
      "epoch:23 step:22369 [D loss: 0.583182, acc.: 68.75%] [G loss: 1.114584]\n",
      "epoch:23 step:22370 [D loss: 0.582580, acc.: 69.53%] [G loss: 1.324685]\n",
      "epoch:23 step:22371 [D loss: 0.701538, acc.: 60.16%] [G loss: 0.962037]\n",
      "epoch:23 step:22372 [D loss: 0.549500, acc.: 68.75%] [G loss: 1.449864]\n",
      "epoch:23 step:22373 [D loss: 0.824714, acc.: 50.00%] [G loss: 1.060853]\n",
      "epoch:23 step:22374 [D loss: 0.603212, acc.: 65.62%] [G loss: 1.070711]\n",
      "epoch:23 step:22375 [D loss: 0.546906, acc.: 77.34%] [G loss: 1.651766]\n",
      "epoch:23 step:22376 [D loss: 0.406947, acc.: 82.03%] [G loss: 1.252044]\n",
      "epoch:23 step:22377 [D loss: 0.639547, acc.: 61.72%] [G loss: 1.649739]\n",
      "epoch:23 step:22378 [D loss: 0.555994, acc.: 71.88%] [G loss: 1.399664]\n",
      "epoch:23 step:22379 [D loss: 0.791610, acc.: 50.00%] [G loss: 0.953362]\n",
      "epoch:23 step:22380 [D loss: 0.564059, acc.: 71.88%] [G loss: 1.277578]\n",
      "epoch:23 step:22381 [D loss: 0.533939, acc.: 72.66%] [G loss: 1.357392]\n",
      "epoch:23 step:22382 [D loss: 0.604302, acc.: 68.75%] [G loss: 1.170682]\n",
      "epoch:23 step:22383 [D loss: 0.688164, acc.: 61.72%] [G loss: 1.176519]\n",
      "epoch:23 step:22384 [D loss: 0.656737, acc.: 64.84%] [G loss: 1.086982]\n",
      "epoch:23 step:22385 [D loss: 0.566751, acc.: 70.31%] [G loss: 1.266017]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:23 step:22386 [D loss: 0.576151, acc.: 74.22%] [G loss: 1.186138]\n",
      "epoch:23 step:22387 [D loss: 0.535457, acc.: 78.12%] [G loss: 1.181534]\n",
      "epoch:23 step:22388 [D loss: 0.581512, acc.: 67.97%] [G loss: 1.157387]\n",
      "epoch:23 step:22389 [D loss: 0.373871, acc.: 87.50%] [G loss: 1.504707]\n",
      "epoch:23 step:22390 [D loss: 0.468736, acc.: 81.25%] [G loss: 1.522798]\n",
      "epoch:23 step:22391 [D loss: 0.561880, acc.: 70.31%] [G loss: 1.064001]\n",
      "epoch:23 step:22392 [D loss: 0.532977, acc.: 73.44%] [G loss: 1.469120]\n",
      "epoch:23 step:22393 [D loss: 0.477035, acc.: 78.91%] [G loss: 1.294800]\n",
      "epoch:23 step:22394 [D loss: 0.640543, acc.: 64.06%] [G loss: 1.184149]\n",
      "epoch:23 step:22395 [D loss: 0.615271, acc.: 64.06%] [G loss: 1.619720]\n",
      "epoch:23 step:22396 [D loss: 0.510956, acc.: 74.22%] [G loss: 1.267380]\n",
      "epoch:23 step:22397 [D loss: 0.662046, acc.: 66.41%] [G loss: 1.116201]\n",
      "epoch:23 step:22398 [D loss: 0.485935, acc.: 78.91%] [G loss: 1.381798]\n",
      "epoch:23 step:22399 [D loss: 0.642021, acc.: 68.75%] [G loss: 1.383124]\n",
      "epoch:23 step:22400 [D loss: 0.470948, acc.: 79.69%] [G loss: 1.371614]\n",
      "epoch:23 step:22401 [D loss: 0.468864, acc.: 80.47%] [G loss: 1.434759]\n",
      "epoch:23 step:22402 [D loss: 0.531493, acc.: 76.56%] [G loss: 1.203560]\n",
      "epoch:23 step:22403 [D loss: 0.549935, acc.: 75.00%] [G loss: 1.373319]\n",
      "epoch:23 step:22404 [D loss: 0.752046, acc.: 59.38%] [G loss: 1.086764]\n",
      "epoch:23 step:22405 [D loss: 0.644648, acc.: 61.72%] [G loss: 1.129959]\n",
      "epoch:23 step:22406 [D loss: 0.678137, acc.: 58.59%] [G loss: 1.042163]\n",
      "epoch:23 step:22407 [D loss: 0.471759, acc.: 79.69%] [G loss: 1.408042]\n",
      "epoch:23 step:22408 [D loss: 0.611281, acc.: 67.97%] [G loss: 1.441823]\n",
      "epoch:23 step:22409 [D loss: 0.487613, acc.: 80.47%] [G loss: 1.415663]\n",
      "epoch:23 step:22410 [D loss: 0.714257, acc.: 56.25%] [G loss: 1.381981]\n",
      "epoch:23 step:22411 [D loss: 0.543580, acc.: 74.22%] [G loss: 1.298524]\n",
      "epoch:23 step:22412 [D loss: 0.535119, acc.: 73.44%] [G loss: 1.530714]\n",
      "epoch:23 step:22413 [D loss: 0.684163, acc.: 62.50%] [G loss: 1.353455]\n",
      "epoch:23 step:22414 [D loss: 0.467830, acc.: 78.91%] [G loss: 1.502615]\n",
      "epoch:23 step:22415 [D loss: 0.709743, acc.: 60.16%] [G loss: 1.226680]\n",
      "epoch:23 step:22416 [D loss: 0.547914, acc.: 73.44%] [G loss: 1.540935]\n",
      "epoch:23 step:22417 [D loss: 0.551164, acc.: 75.00%] [G loss: 1.042434]\n",
      "epoch:23 step:22418 [D loss: 0.569679, acc.: 70.31%] [G loss: 1.054117]\n",
      "epoch:23 step:22419 [D loss: 0.430054, acc.: 82.81%] [G loss: 1.305867]\n",
      "epoch:23 step:22420 [D loss: 0.546687, acc.: 71.88%] [G loss: 1.323104]\n",
      "epoch:23 step:22421 [D loss: 0.402457, acc.: 85.16%] [G loss: 1.624846]\n",
      "epoch:23 step:22422 [D loss: 0.551092, acc.: 75.00%] [G loss: 1.232274]\n",
      "epoch:23 step:22423 [D loss: 0.442462, acc.: 81.25%] [G loss: 1.585021]\n",
      "epoch:23 step:22424 [D loss: 0.349775, acc.: 90.62%] [G loss: 1.436489]\n",
      "epoch:23 step:22425 [D loss: 0.503069, acc.: 76.56%] [G loss: 1.289068]\n",
      "epoch:23 step:22426 [D loss: 0.588430, acc.: 64.84%] [G loss: 1.257713]\n",
      "epoch:23 step:22427 [D loss: 0.633327, acc.: 66.41%] [G loss: 1.500444]\n",
      "epoch:23 step:22428 [D loss: 0.579548, acc.: 71.88%] [G loss: 1.518436]\n",
      "epoch:23 step:22429 [D loss: 0.528329, acc.: 75.78%] [G loss: 1.741975]\n",
      "epoch:23 step:22430 [D loss: 0.582001, acc.: 70.31%] [G loss: 1.167856]\n",
      "epoch:23 step:22431 [D loss: 0.598702, acc.: 66.41%] [G loss: 1.276354]\n",
      "epoch:23 step:22432 [D loss: 0.668450, acc.: 61.72%] [G loss: 1.512170]\n",
      "epoch:23 step:22433 [D loss: 0.437522, acc.: 80.47%] [G loss: 1.235567]\n",
      "epoch:23 step:22434 [D loss: 0.621407, acc.: 68.75%] [G loss: 1.060501]\n",
      "epoch:23 step:22435 [D loss: 0.496794, acc.: 77.34%] [G loss: 1.576435]\n",
      "epoch:23 step:22436 [D loss: 0.547150, acc.: 75.00%] [G loss: 1.427689]\n",
      "epoch:23 step:22437 [D loss: 0.577284, acc.: 68.75%] [G loss: 1.395282]\n",
      "epoch:23 step:22438 [D loss: 0.583641, acc.: 71.88%] [G loss: 1.192506]\n",
      "epoch:23 step:22439 [D loss: 0.589540, acc.: 69.53%] [G loss: 1.479956]\n",
      "epoch:23 step:22440 [D loss: 0.726100, acc.: 55.47%] [G loss: 1.198160]\n",
      "epoch:23 step:22441 [D loss: 0.600711, acc.: 67.19%] [G loss: 1.476929]\n",
      "epoch:23 step:22442 [D loss: 0.730343, acc.: 56.25%] [G loss: 1.078434]\n",
      "epoch:23 step:22443 [D loss: 0.519692, acc.: 74.22%] [G loss: 1.352733]\n",
      "epoch:23 step:22444 [D loss: 0.533959, acc.: 74.22%] [G loss: 1.182641]\n",
      "epoch:23 step:22445 [D loss: 0.745923, acc.: 53.12%] [G loss: 0.969020]\n",
      "epoch:23 step:22446 [D loss: 0.411144, acc.: 83.59%] [G loss: 1.195315]\n",
      "epoch:23 step:22447 [D loss: 0.475312, acc.: 79.69%] [G loss: 1.424646]\n",
      "epoch:23 step:22448 [D loss: 0.628859, acc.: 67.97%] [G loss: 1.100341]\n",
      "epoch:23 step:22449 [D loss: 0.589063, acc.: 72.66%] [G loss: 1.216905]\n",
      "epoch:23 step:22450 [D loss: 0.538334, acc.: 73.44%] [G loss: 1.526144]\n",
      "epoch:23 step:22451 [D loss: 0.663251, acc.: 64.06%] [G loss: 1.099770]\n",
      "epoch:23 step:22452 [D loss: 0.479348, acc.: 79.69%] [G loss: 1.542816]\n",
      "epoch:23 step:22453 [D loss: 0.485299, acc.: 80.47%] [G loss: 1.266851]\n",
      "epoch:23 step:22454 [D loss: 0.525573, acc.: 72.66%] [G loss: 1.427157]\n",
      "epoch:23 step:22455 [D loss: 0.526961, acc.: 75.78%] [G loss: 1.231716]\n",
      "epoch:23 step:22456 [D loss: 0.535687, acc.: 74.22%] [G loss: 1.609523]\n",
      "epoch:23 step:22457 [D loss: 0.731490, acc.: 61.72%] [G loss: 0.938669]\n",
      "epoch:23 step:22458 [D loss: 0.588620, acc.: 67.97%] [G loss: 1.345799]\n",
      "epoch:23 step:22459 [D loss: 0.479096, acc.: 77.34%] [G loss: 1.578672]\n",
      "epoch:23 step:22460 [D loss: 0.485933, acc.: 78.12%] [G loss: 1.557357]\n",
      "epoch:23 step:22461 [D loss: 0.589899, acc.: 69.53%] [G loss: 1.203728]\n",
      "epoch:23 step:22462 [D loss: 0.583611, acc.: 67.19%] [G loss: 1.314494]\n",
      "epoch:23 step:22463 [D loss: 0.576471, acc.: 70.31%] [G loss: 1.366995]\n",
      "epoch:23 step:22464 [D loss: 0.599699, acc.: 67.19%] [G loss: 1.273061]\n",
      "epoch:23 step:22465 [D loss: 0.736514, acc.: 57.03%] [G loss: 1.396398]\n",
      "epoch:23 step:22466 [D loss: 0.430566, acc.: 88.28%] [G loss: 1.323394]\n",
      "epoch:23 step:22467 [D loss: 0.501530, acc.: 76.56%] [G loss: 1.241124]\n",
      "epoch:23 step:22468 [D loss: 0.542743, acc.: 75.78%] [G loss: 1.533967]\n",
      "epoch:23 step:22469 [D loss: 0.607245, acc.: 67.97%] [G loss: 1.550484]\n",
      "epoch:23 step:22470 [D loss: 0.469851, acc.: 80.47%] [G loss: 1.314456]\n",
      "epoch:23 step:22471 [D loss: 0.594852, acc.: 70.31%] [G loss: 1.291138]\n",
      "epoch:23 step:22472 [D loss: 0.515529, acc.: 76.56%] [G loss: 1.196715]\n",
      "epoch:23 step:22473 [D loss: 0.559017, acc.: 75.78%] [G loss: 1.405530]\n",
      "epoch:23 step:22474 [D loss: 0.528491, acc.: 75.00%] [G loss: 1.461564]\n",
      "epoch:23 step:22475 [D loss: 0.580809, acc.: 71.09%] [G loss: 1.053104]\n",
      "epoch:23 step:22476 [D loss: 0.656222, acc.: 64.06%] [G loss: 1.460394]\n",
      "epoch:23 step:22477 [D loss: 0.561027, acc.: 71.09%] [G loss: 1.129772]\n",
      "epoch:23 step:22478 [D loss: 0.617248, acc.: 68.75%] [G loss: 1.375121]\n",
      "epoch:23 step:22479 [D loss: 0.491907, acc.: 75.78%] [G loss: 1.472630]\n",
      "epoch:23 step:22480 [D loss: 0.583845, acc.: 71.88%] [G loss: 1.213312]\n",
      "epoch:23 step:22481 [D loss: 0.481367, acc.: 76.56%] [G loss: 1.222639]\n",
      "epoch:23 step:22482 [D loss: 0.514625, acc.: 73.44%] [G loss: 1.430717]\n",
      "epoch:23 step:22483 [D loss: 0.498657, acc.: 79.69%] [G loss: 1.329547]\n",
      "epoch:23 step:22484 [D loss: 0.683046, acc.: 60.16%] [G loss: 1.066223]\n",
      "epoch:23 step:22485 [D loss: 0.559944, acc.: 67.97%] [G loss: 1.557561]\n",
      "epoch:23 step:22486 [D loss: 0.515868, acc.: 72.66%] [G loss: 1.096658]\n",
      "epoch:23 step:22487 [D loss: 0.468821, acc.: 77.34%] [G loss: 1.612479]\n",
      "epoch:23 step:22488 [D loss: 0.757938, acc.: 57.03%] [G loss: 1.257588]\n",
      "epoch:24 step:22489 [D loss: 0.554074, acc.: 75.78%] [G loss: 1.270703]\n",
      "epoch:24 step:22490 [D loss: 0.596643, acc.: 73.44%] [G loss: 1.404669]\n",
      "epoch:24 step:22491 [D loss: 0.551515, acc.: 67.97%] [G loss: 1.378760]\n",
      "epoch:24 step:22492 [D loss: 0.701064, acc.: 63.28%] [G loss: 1.332066]\n",
      "epoch:24 step:22493 [D loss: 0.669042, acc.: 58.59%] [G loss: 1.304548]\n",
      "epoch:24 step:22494 [D loss: 0.551052, acc.: 71.09%] [G loss: 1.422219]\n",
      "epoch:24 step:22495 [D loss: 0.912925, acc.: 46.88%] [G loss: 0.915185]\n",
      "epoch:24 step:22496 [D loss: 0.542174, acc.: 74.22%] [G loss: 1.310725]\n",
      "epoch:24 step:22497 [D loss: 0.467107, acc.: 79.69%] [G loss: 1.435918]\n",
      "epoch:24 step:22498 [D loss: 0.603709, acc.: 66.41%] [G loss: 1.448404]\n",
      "epoch:24 step:22499 [D loss: 0.577767, acc.: 63.28%] [G loss: 1.562650]\n",
      "epoch:24 step:22500 [D loss: 0.463904, acc.: 80.47%] [G loss: 1.250738]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:24 step:22501 [D loss: 0.745651, acc.: 60.16%] [G loss: 1.103877]\n",
      "epoch:24 step:22502 [D loss: 0.493104, acc.: 80.47%] [G loss: 1.222498]\n",
      "epoch:24 step:22503 [D loss: 0.704786, acc.: 57.81%] [G loss: 1.003972]\n",
      "epoch:24 step:22504 [D loss: 0.587799, acc.: 68.75%] [G loss: 1.528722]\n",
      "epoch:24 step:22505 [D loss: 0.593012, acc.: 73.44%] [G loss: 1.274076]\n",
      "epoch:24 step:22506 [D loss: 0.643801, acc.: 66.41%] [G loss: 1.453330]\n",
      "epoch:24 step:22507 [D loss: 0.522537, acc.: 71.88%] [G loss: 1.112674]\n",
      "epoch:24 step:22508 [D loss: 0.668740, acc.: 57.03%] [G loss: 1.495842]\n",
      "epoch:24 step:22509 [D loss: 0.557624, acc.: 73.44%] [G loss: 1.268542]\n",
      "epoch:24 step:22510 [D loss: 0.450178, acc.: 79.69%] [G loss: 1.581603]\n",
      "epoch:24 step:22511 [D loss: 0.557229, acc.: 70.31%] [G loss: 1.644143]\n",
      "epoch:24 step:22512 [D loss: 0.507035, acc.: 71.88%] [G loss: 1.532153]\n",
      "epoch:24 step:22513 [D loss: 0.713996, acc.: 60.94%] [G loss: 1.508847]\n",
      "epoch:24 step:22514 [D loss: 0.587537, acc.: 73.44%] [G loss: 1.539546]\n",
      "epoch:24 step:22515 [D loss: 0.559393, acc.: 74.22%] [G loss: 1.316880]\n",
      "epoch:24 step:22516 [D loss: 0.350444, acc.: 90.62%] [G loss: 1.636416]\n",
      "epoch:24 step:22517 [D loss: 0.675050, acc.: 59.38%] [G loss: 1.445409]\n",
      "epoch:24 step:22518 [D loss: 0.350604, acc.: 86.72%] [G loss: 1.370870]\n",
      "epoch:24 step:22519 [D loss: 0.776821, acc.: 55.47%] [G loss: 1.230652]\n",
      "epoch:24 step:22520 [D loss: 0.466058, acc.: 76.56%] [G loss: 1.318290]\n",
      "epoch:24 step:22521 [D loss: 0.463376, acc.: 78.91%] [G loss: 1.377861]\n",
      "epoch:24 step:22522 [D loss: 0.508799, acc.: 75.78%] [G loss: 1.080595]\n",
      "epoch:24 step:22523 [D loss: 0.510585, acc.: 78.12%] [G loss: 1.780556]\n",
      "epoch:24 step:22524 [D loss: 0.603451, acc.: 60.16%] [G loss: 1.202141]\n",
      "epoch:24 step:22525 [D loss: 0.484797, acc.: 75.78%] [G loss: 1.680506]\n",
      "epoch:24 step:22526 [D loss: 0.693302, acc.: 63.28%] [G loss: 1.078940]\n",
      "epoch:24 step:22527 [D loss: 0.571850, acc.: 65.62%] [G loss: 1.101379]\n",
      "epoch:24 step:22528 [D loss: 0.553992, acc.: 71.88%] [G loss: 1.186478]\n",
      "epoch:24 step:22529 [D loss: 0.401432, acc.: 88.28%] [G loss: 1.450075]\n",
      "epoch:24 step:22530 [D loss: 0.463775, acc.: 78.12%] [G loss: 1.476040]\n",
      "epoch:24 step:22531 [D loss: 0.525093, acc.: 72.66%] [G loss: 1.594652]\n",
      "epoch:24 step:22532 [D loss: 0.808743, acc.: 53.91%] [G loss: 0.946304]\n",
      "epoch:24 step:22533 [D loss: 0.435515, acc.: 83.59%] [G loss: 1.298300]\n",
      "epoch:24 step:22534 [D loss: 0.640959, acc.: 67.19%] [G loss: 1.800944]\n",
      "epoch:24 step:22535 [D loss: 0.478759, acc.: 78.12%] [G loss: 1.611622]\n",
      "epoch:24 step:22536 [D loss: 0.491610, acc.: 76.56%] [G loss: 1.360545]\n",
      "epoch:24 step:22537 [D loss: 0.599966, acc.: 67.19%] [G loss: 1.040162]\n",
      "epoch:24 step:22538 [D loss: 0.465168, acc.: 80.47%] [G loss: 1.638202]\n",
      "epoch:24 step:22539 [D loss: 0.725425, acc.: 59.38%] [G loss: 1.365430]\n",
      "epoch:24 step:22540 [D loss: 0.571017, acc.: 67.97%] [G loss: 1.454366]\n",
      "epoch:24 step:22541 [D loss: 0.448448, acc.: 79.69%] [G loss: 1.443969]\n",
      "epoch:24 step:22542 [D loss: 0.563345, acc.: 71.88%] [G loss: 1.368643]\n",
      "epoch:24 step:22543 [D loss: 0.450450, acc.: 78.12%] [G loss: 1.723928]\n",
      "epoch:24 step:22544 [D loss: 0.795994, acc.: 50.00%] [G loss: 1.026345]\n",
      "epoch:24 step:22545 [D loss: 0.603604, acc.: 67.97%] [G loss: 1.167566]\n",
      "epoch:24 step:22546 [D loss: 0.575478, acc.: 67.97%] [G loss: 1.470156]\n",
      "epoch:24 step:22547 [D loss: 0.497626, acc.: 81.25%] [G loss: 1.332080]\n",
      "epoch:24 step:22548 [D loss: 0.518101, acc.: 74.22%] [G loss: 1.358614]\n",
      "epoch:24 step:22549 [D loss: 0.575149, acc.: 73.44%] [G loss: 1.381925]\n",
      "epoch:24 step:22550 [D loss: 0.464863, acc.: 83.59%] [G loss: 1.453951]\n",
      "epoch:24 step:22551 [D loss: 0.591489, acc.: 71.88%] [G loss: 1.263114]\n",
      "epoch:24 step:22552 [D loss: 0.591041, acc.: 68.75%] [G loss: 1.366246]\n",
      "epoch:24 step:22553 [D loss: 0.517442, acc.: 73.44%] [G loss: 1.252290]\n",
      "epoch:24 step:22554 [D loss: 0.755082, acc.: 54.69%] [G loss: 1.015621]\n",
      "epoch:24 step:22555 [D loss: 0.529155, acc.: 74.22%] [G loss: 1.470902]\n",
      "epoch:24 step:22556 [D loss: 0.480458, acc.: 79.69%] [G loss: 1.377904]\n",
      "epoch:24 step:22557 [D loss: 0.552625, acc.: 71.09%] [G loss: 1.507553]\n",
      "epoch:24 step:22558 [D loss: 0.574701, acc.: 69.53%] [G loss: 1.277906]\n",
      "epoch:24 step:22559 [D loss: 0.661479, acc.: 62.50%] [G loss: 1.445890]\n",
      "epoch:24 step:22560 [D loss: 0.435517, acc.: 77.34%] [G loss: 1.441523]\n",
      "epoch:24 step:22561 [D loss: 0.487621, acc.: 75.00%] [G loss: 1.158036]\n",
      "epoch:24 step:22562 [D loss: 0.566116, acc.: 72.66%] [G loss: 1.332385]\n",
      "epoch:24 step:22563 [D loss: 0.517925, acc.: 76.56%] [G loss: 1.458863]\n",
      "epoch:24 step:22564 [D loss: 0.416885, acc.: 80.47%] [G loss: 1.456247]\n",
      "epoch:24 step:22565 [D loss: 0.584586, acc.: 71.88%] [G loss: 1.240181]\n",
      "epoch:24 step:22566 [D loss: 0.622003, acc.: 65.62%] [G loss: 1.544152]\n",
      "epoch:24 step:22567 [D loss: 0.517950, acc.: 78.12%] [G loss: 1.063074]\n",
      "epoch:24 step:22568 [D loss: 0.497574, acc.: 76.56%] [G loss: 1.166997]\n",
      "epoch:24 step:22569 [D loss: 0.532387, acc.: 70.31%] [G loss: 1.036150]\n",
      "epoch:24 step:22570 [D loss: 0.483520, acc.: 73.44%] [G loss: 1.608243]\n",
      "epoch:24 step:22571 [D loss: 0.681493, acc.: 57.81%] [G loss: 0.947083]\n",
      "epoch:24 step:22572 [D loss: 0.650421, acc.: 60.94%] [G loss: 1.228245]\n",
      "epoch:24 step:22573 [D loss: 0.448553, acc.: 82.81%] [G loss: 1.407949]\n",
      "epoch:24 step:22574 [D loss: 0.612557, acc.: 66.41%] [G loss: 1.100156]\n",
      "epoch:24 step:22575 [D loss: 0.439033, acc.: 82.03%] [G loss: 1.242502]\n",
      "epoch:24 step:22576 [D loss: 0.645286, acc.: 64.06%] [G loss: 1.436609]\n",
      "epoch:24 step:22577 [D loss: 0.676100, acc.: 60.94%] [G loss: 1.584726]\n",
      "epoch:24 step:22578 [D loss: 0.438448, acc.: 81.25%] [G loss: 1.532906]\n",
      "epoch:24 step:22579 [D loss: 0.484186, acc.: 82.81%] [G loss: 1.383733]\n",
      "epoch:24 step:22580 [D loss: 0.481798, acc.: 77.34%] [G loss: 1.358203]\n",
      "epoch:24 step:22581 [D loss: 0.536209, acc.: 69.53%] [G loss: 1.688762]\n",
      "epoch:24 step:22582 [D loss: 0.504388, acc.: 77.34%] [G loss: 1.481605]\n",
      "epoch:24 step:22583 [D loss: 0.469294, acc.: 80.47%] [G loss: 1.058741]\n",
      "epoch:24 step:22584 [D loss: 0.571223, acc.: 72.66%] [G loss: 1.184269]\n",
      "epoch:24 step:22585 [D loss: 0.730588, acc.: 56.25%] [G loss: 1.216049]\n",
      "epoch:24 step:22586 [D loss: 0.631631, acc.: 64.06%] [G loss: 1.286162]\n",
      "epoch:24 step:22587 [D loss: 0.523715, acc.: 69.53%] [G loss: 1.335266]\n",
      "epoch:24 step:22588 [D loss: 0.603830, acc.: 67.19%] [G loss: 1.576968]\n",
      "epoch:24 step:22589 [D loss: 0.360811, acc.: 90.62%] [G loss: 1.755912]\n",
      "epoch:24 step:22590 [D loss: 0.766983, acc.: 57.81%] [G loss: 1.244081]\n",
      "epoch:24 step:22591 [D loss: 0.722671, acc.: 56.25%] [G loss: 1.457003]\n",
      "epoch:24 step:22592 [D loss: 0.524161, acc.: 75.78%] [G loss: 1.530747]\n",
      "epoch:24 step:22593 [D loss: 0.540379, acc.: 74.22%] [G loss: 1.421966]\n",
      "epoch:24 step:22594 [D loss: 0.561985, acc.: 70.31%] [G loss: 1.391656]\n",
      "epoch:24 step:22595 [D loss: 0.479021, acc.: 79.69%] [G loss: 1.500638]\n",
      "epoch:24 step:22596 [D loss: 0.483243, acc.: 75.78%] [G loss: 1.376924]\n",
      "epoch:24 step:22597 [D loss: 0.588238, acc.: 67.19%] [G loss: 1.103235]\n",
      "epoch:24 step:22598 [D loss: 0.606773, acc.: 66.41%] [G loss: 1.505750]\n",
      "epoch:24 step:22599 [D loss: 0.647557, acc.: 59.38%] [G loss: 1.087927]\n",
      "epoch:24 step:22600 [D loss: 0.638885, acc.: 66.41%] [G loss: 1.229197]\n",
      "epoch:24 step:22601 [D loss: 0.627052, acc.: 65.62%] [G loss: 0.774585]\n",
      "epoch:24 step:22602 [D loss: 0.468967, acc.: 82.81%] [G loss: 1.170108]\n",
      "epoch:24 step:22603 [D loss: 0.478949, acc.: 76.56%] [G loss: 1.452298]\n",
      "epoch:24 step:22604 [D loss: 0.632365, acc.: 65.62%] [G loss: 1.520303]\n",
      "epoch:24 step:22605 [D loss: 0.598318, acc.: 67.19%] [G loss: 1.469320]\n",
      "epoch:24 step:22606 [D loss: 0.451001, acc.: 82.03%] [G loss: 1.626755]\n",
      "epoch:24 step:22607 [D loss: 0.531273, acc.: 73.44%] [G loss: 1.575110]\n",
      "epoch:24 step:22608 [D loss: 0.763495, acc.: 50.78%] [G loss: 1.144658]\n",
      "epoch:24 step:22609 [D loss: 0.743328, acc.: 55.47%] [G loss: 1.138790]\n",
      "epoch:24 step:22610 [D loss: 0.515933, acc.: 75.00%] [G loss: 1.649942]\n",
      "epoch:24 step:22611 [D loss: 0.566868, acc.: 68.75%] [G loss: 1.054541]\n",
      "epoch:24 step:22612 [D loss: 0.499200, acc.: 73.44%] [G loss: 1.295535]\n",
      "epoch:24 step:22613 [D loss: 0.511941, acc.: 73.44%] [G loss: 1.335666]\n",
      "epoch:24 step:22614 [D loss: 0.703525, acc.: 60.16%] [G loss: 1.206467]\n",
      "epoch:24 step:22615 [D loss: 0.423026, acc.: 82.81%] [G loss: 1.411442]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:24 step:22616 [D loss: 0.519236, acc.: 78.12%] [G loss: 1.320924]\n",
      "epoch:24 step:22617 [D loss: 0.590593, acc.: 70.31%] [G loss: 1.529787]\n",
      "epoch:24 step:22618 [D loss: 0.557336, acc.: 70.31%] [G loss: 1.377709]\n",
      "epoch:24 step:22619 [D loss: 0.404934, acc.: 86.72%] [G loss: 1.613281]\n",
      "epoch:24 step:22620 [D loss: 0.661671, acc.: 62.50%] [G loss: 1.012681]\n",
      "epoch:24 step:22621 [D loss: 0.553429, acc.: 69.53%] [G loss: 1.161683]\n",
      "epoch:24 step:22622 [D loss: 0.639780, acc.: 63.28%] [G loss: 1.301009]\n",
      "epoch:24 step:22623 [D loss: 0.436048, acc.: 80.47%] [G loss: 1.753164]\n",
      "epoch:24 step:22624 [D loss: 0.654866, acc.: 62.50%] [G loss: 1.410878]\n",
      "epoch:24 step:22625 [D loss: 0.664852, acc.: 61.72%] [G loss: 1.065593]\n",
      "epoch:24 step:22626 [D loss: 0.638678, acc.: 64.06%] [G loss: 1.070668]\n",
      "epoch:24 step:22627 [D loss: 0.570284, acc.: 71.88%] [G loss: 1.169039]\n",
      "epoch:24 step:22628 [D loss: 0.535223, acc.: 75.78%] [G loss: 1.072790]\n",
      "epoch:24 step:22629 [D loss: 0.464327, acc.: 80.47%] [G loss: 1.254392]\n",
      "epoch:24 step:22630 [D loss: 0.368796, acc.: 87.50%] [G loss: 1.679127]\n",
      "epoch:24 step:22631 [D loss: 0.618332, acc.: 67.19%] [G loss: 1.345937]\n",
      "epoch:24 step:22632 [D loss: 0.539544, acc.: 74.22%] [G loss: 1.270548]\n",
      "epoch:24 step:22633 [D loss: 0.585169, acc.: 71.09%] [G loss: 1.218637]\n",
      "epoch:24 step:22634 [D loss: 0.707950, acc.: 57.81%] [G loss: 1.186052]\n",
      "epoch:24 step:22635 [D loss: 0.407638, acc.: 84.38%] [G loss: 1.787756]\n",
      "epoch:24 step:22636 [D loss: 0.440977, acc.: 83.59%] [G loss: 1.385417]\n",
      "epoch:24 step:22637 [D loss: 0.682090, acc.: 62.50%] [G loss: 1.505214]\n",
      "epoch:24 step:22638 [D loss: 0.422022, acc.: 82.03%] [G loss: 1.713392]\n",
      "epoch:24 step:22639 [D loss: 0.683429, acc.: 60.16%] [G loss: 1.340023]\n",
      "epoch:24 step:22640 [D loss: 0.696412, acc.: 61.72%] [G loss: 1.194953]\n",
      "epoch:24 step:22641 [D loss: 0.538603, acc.: 73.44%] [G loss: 1.389543]\n",
      "epoch:24 step:22642 [D loss: 0.461363, acc.: 76.56%] [G loss: 1.575711]\n",
      "epoch:24 step:22643 [D loss: 0.692072, acc.: 62.50%] [G loss: 1.138505]\n",
      "epoch:24 step:22644 [D loss: 0.487514, acc.: 77.34%] [G loss: 1.198395]\n",
      "epoch:24 step:22645 [D loss: 0.605694, acc.: 64.84%] [G loss: 1.430096]\n",
      "epoch:24 step:22646 [D loss: 0.654329, acc.: 60.16%] [G loss: 1.197051]\n",
      "epoch:24 step:22647 [D loss: 0.491645, acc.: 77.34%] [G loss: 1.327736]\n",
      "epoch:24 step:22648 [D loss: 0.453358, acc.: 81.25%] [G loss: 1.460130]\n",
      "epoch:24 step:22649 [D loss: 0.563978, acc.: 76.56%] [G loss: 1.349810]\n",
      "epoch:24 step:22650 [D loss: 0.608719, acc.: 70.31%] [G loss: 1.378335]\n",
      "epoch:24 step:22651 [D loss: 0.607196, acc.: 64.84%] [G loss: 1.228554]\n",
      "epoch:24 step:22652 [D loss: 0.489315, acc.: 75.00%] [G loss: 1.390865]\n",
      "epoch:24 step:22653 [D loss: 0.446100, acc.: 80.47%] [G loss: 1.447881]\n",
      "epoch:24 step:22654 [D loss: 0.580891, acc.: 70.31%] [G loss: 1.466128]\n",
      "epoch:24 step:22655 [D loss: 0.423428, acc.: 80.47%] [G loss: 1.628794]\n",
      "epoch:24 step:22656 [D loss: 0.488417, acc.: 77.34%] [G loss: 1.309793]\n",
      "epoch:24 step:22657 [D loss: 0.546666, acc.: 72.66%] [G loss: 1.600084]\n",
      "epoch:24 step:22658 [D loss: 0.543492, acc.: 71.09%] [G loss: 1.550805]\n",
      "epoch:24 step:22659 [D loss: 0.610693, acc.: 70.31%] [G loss: 1.614527]\n",
      "epoch:24 step:22660 [D loss: 0.419314, acc.: 82.81%] [G loss: 1.435180]\n",
      "epoch:24 step:22661 [D loss: 0.764034, acc.: 53.91%] [G loss: 1.084511]\n",
      "epoch:24 step:22662 [D loss: 0.468679, acc.: 76.56%] [G loss: 1.716390]\n",
      "epoch:24 step:22663 [D loss: 0.493718, acc.: 78.91%] [G loss: 1.545784]\n",
      "epoch:24 step:22664 [D loss: 0.483715, acc.: 80.47%] [G loss: 1.206573]\n",
      "epoch:24 step:22665 [D loss: 0.482682, acc.: 79.69%] [G loss: 1.322092]\n",
      "epoch:24 step:22666 [D loss: 0.443563, acc.: 82.03%] [G loss: 1.607678]\n",
      "epoch:24 step:22667 [D loss: 0.401450, acc.: 83.59%] [G loss: 1.415419]\n",
      "epoch:24 step:22668 [D loss: 0.513753, acc.: 71.09%] [G loss: 1.127292]\n",
      "epoch:24 step:22669 [D loss: 0.590082, acc.: 67.19%] [G loss: 1.274699]\n",
      "epoch:24 step:22670 [D loss: 0.390889, acc.: 87.50%] [G loss: 1.544762]\n",
      "epoch:24 step:22671 [D loss: 0.614166, acc.: 67.97%] [G loss: 1.471150]\n",
      "epoch:24 step:22672 [D loss: 0.486421, acc.: 78.12%] [G loss: 1.453264]\n",
      "epoch:24 step:22673 [D loss: 0.547168, acc.: 75.00%] [G loss: 1.154663]\n",
      "epoch:24 step:22674 [D loss: 0.675092, acc.: 60.94%] [G loss: 1.356470]\n",
      "epoch:24 step:22675 [D loss: 0.482652, acc.: 78.91%] [G loss: 1.368838]\n",
      "epoch:24 step:22676 [D loss: 0.536917, acc.: 69.53%] [G loss: 1.375586]\n",
      "epoch:24 step:22677 [D loss: 0.665255, acc.: 60.94%] [G loss: 1.257191]\n",
      "epoch:24 step:22678 [D loss: 0.768861, acc.: 53.91%] [G loss: 1.585280]\n",
      "epoch:24 step:22679 [D loss: 0.681246, acc.: 64.06%] [G loss: 1.241345]\n",
      "epoch:24 step:22680 [D loss: 0.556936, acc.: 67.97%] [G loss: 1.435304]\n",
      "epoch:24 step:22681 [D loss: 0.576203, acc.: 71.09%] [G loss: 1.477303]\n",
      "epoch:24 step:22682 [D loss: 0.553567, acc.: 72.66%] [G loss: 1.262500]\n",
      "epoch:24 step:22683 [D loss: 0.586819, acc.: 69.53%] [G loss: 1.336106]\n",
      "epoch:24 step:22684 [D loss: 0.518234, acc.: 75.00%] [G loss: 1.634970]\n",
      "epoch:24 step:22685 [D loss: 0.434021, acc.: 82.81%] [G loss: 1.639964]\n",
      "epoch:24 step:22686 [D loss: 0.519244, acc.: 78.12%] [G loss: 1.324339]\n",
      "epoch:24 step:22687 [D loss: 0.586851, acc.: 67.19%] [G loss: 1.487007]\n",
      "epoch:24 step:22688 [D loss: 0.546048, acc.: 74.22%] [G loss: 1.346606]\n",
      "epoch:24 step:22689 [D loss: 0.398388, acc.: 84.38%] [G loss: 1.447659]\n",
      "epoch:24 step:22690 [D loss: 0.496238, acc.: 78.91%] [G loss: 1.393385]\n",
      "epoch:24 step:22691 [D loss: 0.341555, acc.: 92.19%] [G loss: 1.633543]\n",
      "epoch:24 step:22692 [D loss: 0.327263, acc.: 92.97%] [G loss: 1.911490]\n",
      "epoch:24 step:22693 [D loss: 0.542758, acc.: 75.78%] [G loss: 1.263754]\n",
      "epoch:24 step:22694 [D loss: 0.608211, acc.: 68.75%] [G loss: 1.004742]\n",
      "epoch:24 step:22695 [D loss: 0.572884, acc.: 70.31%] [G loss: 1.407878]\n",
      "epoch:24 step:22696 [D loss: 0.576170, acc.: 65.62%] [G loss: 1.074981]\n",
      "epoch:24 step:22697 [D loss: 0.613457, acc.: 62.50%] [G loss: 1.184382]\n",
      "epoch:24 step:22698 [D loss: 0.612135, acc.: 64.84%] [G loss: 1.115705]\n",
      "epoch:24 step:22699 [D loss: 0.417134, acc.: 85.94%] [G loss: 1.547731]\n",
      "epoch:24 step:22700 [D loss: 0.699936, acc.: 57.03%] [G loss: 1.346843]\n",
      "epoch:24 step:22701 [D loss: 0.545364, acc.: 75.00%] [G loss: 1.317817]\n",
      "epoch:24 step:22702 [D loss: 0.545006, acc.: 73.44%] [G loss: 1.098699]\n",
      "epoch:24 step:22703 [D loss: 0.412522, acc.: 85.16%] [G loss: 1.228511]\n",
      "epoch:24 step:22704 [D loss: 0.523736, acc.: 77.34%] [G loss: 1.046267]\n",
      "epoch:24 step:22705 [D loss: 0.516493, acc.: 69.53%] [G loss: 1.387707]\n",
      "epoch:24 step:22706 [D loss: 0.431755, acc.: 82.03%] [G loss: 1.396986]\n",
      "epoch:24 step:22707 [D loss: 0.667812, acc.: 61.72%] [G loss: 1.465873]\n",
      "epoch:24 step:22708 [D loss: 0.482960, acc.: 78.91%] [G loss: 1.247360]\n",
      "epoch:24 step:22709 [D loss: 0.570831, acc.: 70.31%] [G loss: 1.318171]\n",
      "epoch:24 step:22710 [D loss: 0.655948, acc.: 59.38%] [G loss: 1.192001]\n",
      "epoch:24 step:22711 [D loss: 0.500767, acc.: 79.69%] [G loss: 1.395949]\n",
      "epoch:24 step:22712 [D loss: 0.525959, acc.: 72.66%] [G loss: 1.170880]\n",
      "epoch:24 step:22713 [D loss: 0.460336, acc.: 78.91%] [G loss: 1.877776]\n",
      "epoch:24 step:22714 [D loss: 0.435692, acc.: 82.81%] [G loss: 1.647423]\n",
      "epoch:24 step:22715 [D loss: 0.538475, acc.: 73.44%] [G loss: 1.468502]\n",
      "epoch:24 step:22716 [D loss: 0.631644, acc.: 66.41%] [G loss: 1.002839]\n",
      "epoch:24 step:22717 [D loss: 0.562924, acc.: 69.53%] [G loss: 1.174531]\n",
      "epoch:24 step:22718 [D loss: 0.531524, acc.: 69.53%] [G loss: 1.490104]\n",
      "epoch:24 step:22719 [D loss: 0.519543, acc.: 75.78%] [G loss: 1.310630]\n",
      "epoch:24 step:22720 [D loss: 0.628807, acc.: 67.97%] [G loss: 0.958300]\n",
      "epoch:24 step:22721 [D loss: 0.571902, acc.: 63.28%] [G loss: 1.106468]\n",
      "epoch:24 step:22722 [D loss: 0.627721, acc.: 68.75%] [G loss: 1.310983]\n",
      "epoch:24 step:22723 [D loss: 0.568394, acc.: 73.44%] [G loss: 1.412156]\n",
      "epoch:24 step:22724 [D loss: 0.476492, acc.: 78.12%] [G loss: 1.296513]\n",
      "epoch:24 step:22725 [D loss: 0.710463, acc.: 59.38%] [G loss: 0.949032]\n",
      "epoch:24 step:22726 [D loss: 0.822999, acc.: 46.88%] [G loss: 0.950208]\n",
      "epoch:24 step:22727 [D loss: 0.563970, acc.: 72.66%] [G loss: 1.095929]\n",
      "epoch:24 step:22728 [D loss: 0.582913, acc.: 71.88%] [G loss: 1.217620]\n",
      "epoch:24 step:22729 [D loss: 0.508616, acc.: 75.78%] [G loss: 1.164462]\n",
      "epoch:24 step:22730 [D loss: 0.558682, acc.: 72.66%] [G loss: 1.276463]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:24 step:22731 [D loss: 0.545647, acc.: 72.66%] [G loss: 1.399020]\n",
      "epoch:24 step:22732 [D loss: 0.481248, acc.: 81.25%] [G loss: 1.685268]\n",
      "epoch:24 step:22733 [D loss: 0.498277, acc.: 73.44%] [G loss: 1.992558]\n",
      "epoch:24 step:22734 [D loss: 0.536073, acc.: 73.44%] [G loss: 1.475591]\n",
      "epoch:24 step:22735 [D loss: 0.734397, acc.: 56.25%] [G loss: 1.107758]\n",
      "epoch:24 step:22736 [D loss: 0.562616, acc.: 67.19%] [G loss: 1.259108]\n",
      "epoch:24 step:22737 [D loss: 0.511492, acc.: 75.78%] [G loss: 1.630222]\n",
      "epoch:24 step:22738 [D loss: 0.516994, acc.: 71.88%] [G loss: 1.989558]\n",
      "epoch:24 step:22739 [D loss: 0.675356, acc.: 61.72%] [G loss: 1.514630]\n",
      "epoch:24 step:22740 [D loss: 0.536598, acc.: 76.56%] [G loss: 1.559474]\n",
      "epoch:24 step:22741 [D loss: 0.592895, acc.: 65.62%] [G loss: 1.356233]\n",
      "epoch:24 step:22742 [D loss: 0.683705, acc.: 58.59%] [G loss: 1.035712]\n",
      "epoch:24 step:22743 [D loss: 0.586394, acc.: 70.31%] [G loss: 1.206339]\n",
      "epoch:24 step:22744 [D loss: 0.524011, acc.: 78.91%] [G loss: 1.563482]\n",
      "epoch:24 step:22745 [D loss: 0.590097, acc.: 72.66%] [G loss: 1.527628]\n",
      "epoch:24 step:22746 [D loss: 0.430179, acc.: 83.59%] [G loss: 1.452335]\n",
      "epoch:24 step:22747 [D loss: 0.574545, acc.: 70.31%] [G loss: 1.264854]\n",
      "epoch:24 step:22748 [D loss: 0.521820, acc.: 77.34%] [G loss: 0.992491]\n",
      "epoch:24 step:22749 [D loss: 0.669695, acc.: 62.50%] [G loss: 1.070944]\n",
      "epoch:24 step:22750 [D loss: 0.642231, acc.: 67.19%] [G loss: 0.945344]\n",
      "epoch:24 step:22751 [D loss: 0.592811, acc.: 63.28%] [G loss: 1.409211]\n",
      "epoch:24 step:22752 [D loss: 0.529090, acc.: 72.66%] [G loss: 1.451973]\n",
      "epoch:24 step:22753 [D loss: 0.437935, acc.: 83.59%] [G loss: 1.908049]\n",
      "epoch:24 step:22754 [D loss: 0.488319, acc.: 76.56%] [G loss: 1.182212]\n",
      "epoch:24 step:22755 [D loss: 0.671913, acc.: 60.16%] [G loss: 1.661017]\n",
      "epoch:24 step:22756 [D loss: 0.603400, acc.: 68.75%] [G loss: 1.423941]\n",
      "epoch:24 step:22757 [D loss: 0.390914, acc.: 84.38%] [G loss: 1.566398]\n",
      "epoch:24 step:22758 [D loss: 0.514052, acc.: 78.12%] [G loss: 1.503273]\n",
      "epoch:24 step:22759 [D loss: 0.341374, acc.: 90.62%] [G loss: 1.566403]\n",
      "epoch:24 step:22760 [D loss: 0.586332, acc.: 71.88%] [G loss: 1.120154]\n",
      "epoch:24 step:22761 [D loss: 0.532203, acc.: 72.66%] [G loss: 1.164532]\n",
      "epoch:24 step:22762 [D loss: 0.461201, acc.: 78.91%] [G loss: 1.455988]\n",
      "epoch:24 step:22763 [D loss: 0.749155, acc.: 50.78%] [G loss: 1.016403]\n",
      "epoch:24 step:22764 [D loss: 0.639455, acc.: 67.19%] [G loss: 1.441925]\n",
      "epoch:24 step:22765 [D loss: 0.502975, acc.: 80.47%] [G loss: 1.279441]\n",
      "epoch:24 step:22766 [D loss: 0.589273, acc.: 65.62%] [G loss: 1.047294]\n",
      "epoch:24 step:22767 [D loss: 0.671120, acc.: 61.72%] [G loss: 1.458301]\n",
      "epoch:24 step:22768 [D loss: 0.625819, acc.: 67.97%] [G loss: 1.546729]\n",
      "epoch:24 step:22769 [D loss: 0.437763, acc.: 82.81%] [G loss: 1.507342]\n",
      "epoch:24 step:22770 [D loss: 0.618041, acc.: 66.41%] [G loss: 1.394603]\n",
      "epoch:24 step:22771 [D loss: 0.636067, acc.: 64.06%] [G loss: 1.338865]\n",
      "epoch:24 step:22772 [D loss: 0.581254, acc.: 68.75%] [G loss: 1.292736]\n",
      "epoch:24 step:22773 [D loss: 0.505828, acc.: 73.44%] [G loss: 1.711404]\n",
      "epoch:24 step:22774 [D loss: 0.560523, acc.: 74.22%] [G loss: 1.287998]\n",
      "epoch:24 step:22775 [D loss: 0.709287, acc.: 64.84%] [G loss: 1.216129]\n",
      "epoch:24 step:22776 [D loss: 0.671490, acc.: 65.62%] [G loss: 1.398445]\n",
      "epoch:24 step:22777 [D loss: 0.502890, acc.: 75.78%] [G loss: 1.167437]\n",
      "epoch:24 step:22778 [D loss: 0.500090, acc.: 73.44%] [G loss: 1.356857]\n",
      "epoch:24 step:22779 [D loss: 0.484226, acc.: 76.56%] [G loss: 1.454931]\n",
      "epoch:24 step:22780 [D loss: 0.507527, acc.: 75.00%] [G loss: 1.191142]\n",
      "epoch:24 step:22781 [D loss: 0.669792, acc.: 60.16%] [G loss: 1.182610]\n",
      "epoch:24 step:22782 [D loss: 0.523430, acc.: 74.22%] [G loss: 1.217528]\n",
      "epoch:24 step:22783 [D loss: 0.671193, acc.: 64.06%] [G loss: 1.562224]\n",
      "epoch:24 step:22784 [D loss: 0.639246, acc.: 60.94%] [G loss: 1.705386]\n",
      "epoch:24 step:22785 [D loss: 0.585148, acc.: 75.00%] [G loss: 1.107363]\n",
      "epoch:24 step:22786 [D loss: 0.630886, acc.: 70.31%] [G loss: 1.218776]\n",
      "epoch:24 step:22787 [D loss: 0.655128, acc.: 60.94%] [G loss: 1.527407]\n",
      "epoch:24 step:22788 [D loss: 0.445183, acc.: 82.03%] [G loss: 1.416505]\n",
      "epoch:24 step:22789 [D loss: 0.512278, acc.: 77.34%] [G loss: 1.397493]\n",
      "epoch:24 step:22790 [D loss: 0.539389, acc.: 75.78%] [G loss: 1.370093]\n",
      "epoch:24 step:22791 [D loss: 0.633579, acc.: 69.53%] [G loss: 1.124758]\n",
      "epoch:24 step:22792 [D loss: 0.790272, acc.: 49.22%] [G loss: 1.104098]\n",
      "epoch:24 step:22793 [D loss: 0.491635, acc.: 78.12%] [G loss: 1.363069]\n",
      "epoch:24 step:22794 [D loss: 0.699917, acc.: 57.03%] [G loss: 1.026111]\n",
      "epoch:24 step:22795 [D loss: 0.551923, acc.: 74.22%] [G loss: 1.179264]\n",
      "epoch:24 step:22796 [D loss: 0.557457, acc.: 71.09%] [G loss: 1.379059]\n",
      "epoch:24 step:22797 [D loss: 0.466467, acc.: 75.00%] [G loss: 0.916127]\n",
      "epoch:24 step:22798 [D loss: 0.566028, acc.: 67.19%] [G loss: 1.501353]\n",
      "epoch:24 step:22799 [D loss: 0.550802, acc.: 67.97%] [G loss: 1.004089]\n",
      "epoch:24 step:22800 [D loss: 0.560040, acc.: 74.22%] [G loss: 1.884737]\n",
      "epoch:24 step:22801 [D loss: 0.688628, acc.: 62.50%] [G loss: 1.323395]\n",
      "epoch:24 step:22802 [D loss: 0.476133, acc.: 82.03%] [G loss: 1.390030]\n",
      "epoch:24 step:22803 [D loss: 0.582362, acc.: 67.19%] [G loss: 1.307703]\n",
      "epoch:24 step:22804 [D loss: 0.594450, acc.: 64.06%] [G loss: 1.564181]\n",
      "epoch:24 step:22805 [D loss: 0.641792, acc.: 64.84%] [G loss: 1.194867]\n",
      "epoch:24 step:22806 [D loss: 0.616827, acc.: 67.97%] [G loss: 1.166626]\n",
      "epoch:24 step:22807 [D loss: 0.666375, acc.: 58.59%] [G loss: 1.248725]\n",
      "epoch:24 step:22808 [D loss: 0.542931, acc.: 73.44%] [G loss: 1.614088]\n",
      "epoch:24 step:22809 [D loss: 0.463898, acc.: 79.69%] [G loss: 1.501675]\n",
      "epoch:24 step:22810 [D loss: 0.624264, acc.: 65.62%] [G loss: 1.550456]\n",
      "epoch:24 step:22811 [D loss: 0.550276, acc.: 71.88%] [G loss: 1.310390]\n",
      "epoch:24 step:22812 [D loss: 0.451463, acc.: 82.81%] [G loss: 1.423937]\n",
      "epoch:24 step:22813 [D loss: 0.549176, acc.: 72.66%] [G loss: 1.384104]\n",
      "epoch:24 step:22814 [D loss: 0.376008, acc.: 89.06%] [G loss: 1.614507]\n",
      "epoch:24 step:22815 [D loss: 0.402460, acc.: 85.16%] [G loss: 1.292043]\n",
      "epoch:24 step:22816 [D loss: 0.434376, acc.: 85.94%] [G loss: 1.672543]\n",
      "epoch:24 step:22817 [D loss: 0.602499, acc.: 65.62%] [G loss: 1.450046]\n",
      "epoch:24 step:22818 [D loss: 0.543208, acc.: 71.09%] [G loss: 1.542991]\n",
      "epoch:24 step:22819 [D loss: 0.467046, acc.: 78.91%] [G loss: 1.361084]\n",
      "epoch:24 step:22820 [D loss: 0.740579, acc.: 52.34%] [G loss: 1.170805]\n",
      "epoch:24 step:22821 [D loss: 0.516699, acc.: 76.56%] [G loss: 1.776008]\n",
      "epoch:24 step:22822 [D loss: 0.618138, acc.: 71.88%] [G loss: 1.511290]\n",
      "epoch:24 step:22823 [D loss: 0.513418, acc.: 78.12%] [G loss: 1.735536]\n",
      "epoch:24 step:22824 [D loss: 0.539452, acc.: 73.44%] [G loss: 1.284410]\n",
      "epoch:24 step:22825 [D loss: 0.538680, acc.: 73.44%] [G loss: 1.737854]\n",
      "epoch:24 step:22826 [D loss: 0.381592, acc.: 85.94%] [G loss: 1.653468]\n",
      "epoch:24 step:22827 [D loss: 0.558313, acc.: 71.88%] [G loss: 1.374908]\n",
      "epoch:24 step:22828 [D loss: 0.459729, acc.: 80.47%] [G loss: 1.451360]\n",
      "epoch:24 step:22829 [D loss: 0.479779, acc.: 78.12%] [G loss: 1.242129]\n",
      "epoch:24 step:22830 [D loss: 0.496119, acc.: 75.00%] [G loss: 1.176113]\n",
      "epoch:24 step:22831 [D loss: 0.883753, acc.: 45.31%] [G loss: 1.484076]\n",
      "epoch:24 step:22832 [D loss: 0.578962, acc.: 65.62%] [G loss: 1.349114]\n",
      "epoch:24 step:22833 [D loss: 0.534015, acc.: 74.22%] [G loss: 1.216561]\n",
      "epoch:24 step:22834 [D loss: 0.554974, acc.: 72.66%] [G loss: 1.684015]\n",
      "epoch:24 step:22835 [D loss: 0.613290, acc.: 64.84%] [G loss: 1.181314]\n",
      "epoch:24 step:22836 [D loss: 0.598046, acc.: 65.62%] [G loss: 1.462926]\n",
      "epoch:24 step:22837 [D loss: 0.461302, acc.: 82.03%] [G loss: 1.589285]\n",
      "epoch:24 step:22838 [D loss: 0.626429, acc.: 64.06%] [G loss: 1.368222]\n",
      "epoch:24 step:22839 [D loss: 0.590168, acc.: 65.62%] [G loss: 1.388036]\n",
      "epoch:24 step:22840 [D loss: 0.511754, acc.: 74.22%] [G loss: 1.300293]\n",
      "epoch:24 step:22841 [D loss: 0.640402, acc.: 66.41%] [G loss: 1.245004]\n",
      "epoch:24 step:22842 [D loss: 0.484879, acc.: 78.12%] [G loss: 1.182880]\n",
      "epoch:24 step:22843 [D loss: 0.586977, acc.: 66.41%] [G loss: 1.217323]\n",
      "epoch:24 step:22844 [D loss: 0.499239, acc.: 78.91%] [G loss: 1.440601]\n",
      "epoch:24 step:22845 [D loss: 0.554377, acc.: 71.09%] [G loss: 1.346108]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:24 step:22846 [D loss: 0.703768, acc.: 60.16%] [G loss: 1.328704]\n",
      "epoch:24 step:22847 [D loss: 0.583240, acc.: 71.09%] [G loss: 1.341633]\n",
      "epoch:24 step:22848 [D loss: 0.616860, acc.: 57.81%] [G loss: 1.278280]\n",
      "epoch:24 step:22849 [D loss: 0.672296, acc.: 59.38%] [G loss: 1.075577]\n",
      "epoch:24 step:22850 [D loss: 0.430996, acc.: 85.16%] [G loss: 1.636763]\n",
      "epoch:24 step:22851 [D loss: 0.422715, acc.: 84.38%] [G loss: 1.574433]\n",
      "epoch:24 step:22852 [D loss: 0.503955, acc.: 75.00%] [G loss: 1.272658]\n",
      "epoch:24 step:22853 [D loss: 0.586641, acc.: 72.66%] [G loss: 1.496202]\n",
      "epoch:24 step:22854 [D loss: 0.426279, acc.: 85.16%] [G loss: 1.463655]\n",
      "epoch:24 step:22855 [D loss: 0.700305, acc.: 62.50%] [G loss: 1.090443]\n",
      "epoch:24 step:22856 [D loss: 0.477574, acc.: 79.69%] [G loss: 1.377780]\n",
      "epoch:24 step:22857 [D loss: 0.554865, acc.: 68.75%] [G loss: 1.372113]\n",
      "epoch:24 step:22858 [D loss: 0.460703, acc.: 80.47%] [G loss: 1.352864]\n",
      "epoch:24 step:22859 [D loss: 0.452622, acc.: 79.69%] [G loss: 1.572013]\n",
      "epoch:24 step:22860 [D loss: 0.631539, acc.: 61.72%] [G loss: 1.076411]\n",
      "epoch:24 step:22861 [D loss: 0.656891, acc.: 61.72%] [G loss: 1.317869]\n",
      "epoch:24 step:22862 [D loss: 0.635173, acc.: 61.72%] [G loss: 1.354171]\n",
      "epoch:24 step:22863 [D loss: 0.712254, acc.: 58.59%] [G loss: 1.505062]\n",
      "epoch:24 step:22864 [D loss: 0.574522, acc.: 70.31%] [G loss: 1.276482]\n",
      "epoch:24 step:22865 [D loss: 0.619475, acc.: 62.50%] [G loss: 1.380250]\n",
      "epoch:24 step:22866 [D loss: 0.402067, acc.: 88.28%] [G loss: 1.249431]\n",
      "epoch:24 step:22867 [D loss: 0.616260, acc.: 69.53%] [G loss: 1.550110]\n",
      "epoch:24 step:22868 [D loss: 0.555051, acc.: 73.44%] [G loss: 1.435366]\n",
      "epoch:24 step:22869 [D loss: 0.638889, acc.: 66.41%] [G loss: 1.413908]\n",
      "epoch:24 step:22870 [D loss: 0.546099, acc.: 72.66%] [G loss: 1.763880]\n",
      "epoch:24 step:22871 [D loss: 0.522111, acc.: 75.78%] [G loss: 1.138368]\n",
      "epoch:24 step:22872 [D loss: 0.579185, acc.: 67.97%] [G loss: 1.432446]\n",
      "epoch:24 step:22873 [D loss: 0.557187, acc.: 71.09%] [G loss: 1.187464]\n",
      "epoch:24 step:22874 [D loss: 0.510267, acc.: 74.22%] [G loss: 1.276379]\n",
      "epoch:24 step:22875 [D loss: 0.565148, acc.: 71.09%] [G loss: 1.319526]\n",
      "epoch:24 step:22876 [D loss: 0.699055, acc.: 61.72%] [G loss: 1.254294]\n",
      "epoch:24 step:22877 [D loss: 0.612393, acc.: 68.75%] [G loss: 1.313046]\n",
      "epoch:24 step:22878 [D loss: 0.701832, acc.: 57.81%] [G loss: 1.142669]\n",
      "epoch:24 step:22879 [D loss: 0.657150, acc.: 63.28%] [G loss: 1.502384]\n",
      "epoch:24 step:22880 [D loss: 0.597883, acc.: 65.62%] [G loss: 1.443599]\n",
      "epoch:24 step:22881 [D loss: 0.667138, acc.: 64.06%] [G loss: 1.075546]\n",
      "epoch:24 step:22882 [D loss: 0.460094, acc.: 75.00%] [G loss: 1.330878]\n",
      "epoch:24 step:22883 [D loss: 0.519639, acc.: 72.66%] [G loss: 1.255020]\n",
      "epoch:24 step:22884 [D loss: 0.611894, acc.: 64.06%] [G loss: 1.270332]\n",
      "epoch:24 step:22885 [D loss: 0.611036, acc.: 69.53%] [G loss: 1.414657]\n",
      "epoch:24 step:22886 [D loss: 0.454858, acc.: 81.25%] [G loss: 1.416243]\n",
      "epoch:24 step:22887 [D loss: 0.487917, acc.: 78.12%] [G loss: 1.465739]\n",
      "epoch:24 step:22888 [D loss: 0.525489, acc.: 75.00%] [G loss: 1.273033]\n",
      "epoch:24 step:22889 [D loss: 0.609096, acc.: 71.88%] [G loss: 0.950158]\n",
      "epoch:24 step:22890 [D loss: 0.474203, acc.: 77.34%] [G loss: 1.436053]\n",
      "epoch:24 step:22891 [D loss: 0.658287, acc.: 64.84%] [G loss: 1.349600]\n",
      "epoch:24 step:22892 [D loss: 0.545149, acc.: 73.44%] [G loss: 1.113011]\n",
      "epoch:24 step:22893 [D loss: 0.576216, acc.: 71.09%] [G loss: 1.357118]\n",
      "epoch:24 step:22894 [D loss: 0.492234, acc.: 78.12%] [G loss: 1.188448]\n",
      "epoch:24 step:22895 [D loss: 0.516704, acc.: 71.88%] [G loss: 1.175898]\n",
      "epoch:24 step:22896 [D loss: 0.597669, acc.: 71.09%] [G loss: 1.316977]\n",
      "epoch:24 step:22897 [D loss: 0.703985, acc.: 59.38%] [G loss: 1.211521]\n",
      "epoch:24 step:22898 [D loss: 0.516128, acc.: 78.91%] [G loss: 1.547033]\n",
      "epoch:24 step:22899 [D loss: 0.567378, acc.: 71.09%] [G loss: 1.272388]\n",
      "epoch:24 step:22900 [D loss: 0.594839, acc.: 70.31%] [G loss: 1.208930]\n",
      "epoch:24 step:22901 [D loss: 0.636359, acc.: 62.50%] [G loss: 1.226712]\n",
      "epoch:24 step:22902 [D loss: 0.531541, acc.: 71.09%] [G loss: 1.352809]\n",
      "epoch:24 step:22903 [D loss: 0.473813, acc.: 76.56%] [G loss: 1.669919]\n",
      "epoch:24 step:22904 [D loss: 0.447283, acc.: 81.25%] [G loss: 1.238089]\n",
      "epoch:24 step:22905 [D loss: 0.663330, acc.: 67.19%] [G loss: 1.631230]\n",
      "epoch:24 step:22906 [D loss: 0.555817, acc.: 75.00%] [G loss: 1.072585]\n",
      "epoch:24 step:22907 [D loss: 0.517473, acc.: 76.56%] [G loss: 1.416926]\n",
      "epoch:24 step:22908 [D loss: 0.462691, acc.: 82.03%] [G loss: 1.210050]\n",
      "epoch:24 step:22909 [D loss: 0.480209, acc.: 78.91%] [G loss: 1.648171]\n",
      "epoch:24 step:22910 [D loss: 0.570249, acc.: 75.00%] [G loss: 1.108295]\n",
      "epoch:24 step:22911 [D loss: 0.576799, acc.: 67.97%] [G loss: 0.830378]\n",
      "epoch:24 step:22912 [D loss: 0.542584, acc.: 66.41%] [G loss: 1.315806]\n",
      "epoch:24 step:22913 [D loss: 0.410617, acc.: 85.94%] [G loss: 1.697056]\n",
      "epoch:24 step:22914 [D loss: 0.580560, acc.: 70.31%] [G loss: 1.611767]\n",
      "epoch:24 step:22915 [D loss: 0.662533, acc.: 57.81%] [G loss: 0.906073]\n",
      "epoch:24 step:22916 [D loss: 0.610555, acc.: 67.97%] [G loss: 1.555691]\n",
      "epoch:24 step:22917 [D loss: 0.578320, acc.: 66.41%] [G loss: 0.894674]\n",
      "epoch:24 step:22918 [D loss: 0.500000, acc.: 77.34%] [G loss: 1.095486]\n",
      "epoch:24 step:22919 [D loss: 0.592717, acc.: 67.19%] [G loss: 1.117558]\n",
      "epoch:24 step:22920 [D loss: 0.530814, acc.: 72.66%] [G loss: 1.112233]\n",
      "epoch:24 step:22921 [D loss: 0.445581, acc.: 75.00%] [G loss: 1.279658]\n",
      "epoch:24 step:22922 [D loss: 0.749576, acc.: 50.00%] [G loss: 1.172125]\n",
      "epoch:24 step:22923 [D loss: 0.701451, acc.: 60.94%] [G loss: 1.541345]\n",
      "epoch:24 step:22924 [D loss: 0.524066, acc.: 71.88%] [G loss: 1.082791]\n",
      "epoch:24 step:22925 [D loss: 0.621139, acc.: 64.06%] [G loss: 1.564606]\n",
      "epoch:24 step:22926 [D loss: 0.636762, acc.: 64.06%] [G loss: 1.282503]\n",
      "epoch:24 step:22927 [D loss: 0.669941, acc.: 57.03%] [G loss: 1.381280]\n",
      "epoch:24 step:22928 [D loss: 0.535992, acc.: 71.09%] [G loss: 1.729793]\n",
      "epoch:24 step:22929 [D loss: 0.605427, acc.: 64.84%] [G loss: 1.315562]\n",
      "epoch:24 step:22930 [D loss: 0.594746, acc.: 69.53%] [G loss: 1.302363]\n",
      "epoch:24 step:22931 [D loss: 0.665249, acc.: 64.06%] [G loss: 1.073960]\n",
      "epoch:24 step:22932 [D loss: 0.546746, acc.: 70.31%] [G loss: 1.398226]\n",
      "epoch:24 step:22933 [D loss: 0.573852, acc.: 67.97%] [G loss: 1.429257]\n",
      "epoch:24 step:22934 [D loss: 0.618357, acc.: 71.09%] [G loss: 1.211051]\n",
      "epoch:24 step:22935 [D loss: 0.433824, acc.: 79.69%] [G loss: 1.600729]\n",
      "epoch:24 step:22936 [D loss: 0.576716, acc.: 75.00%] [G loss: 1.749669]\n",
      "epoch:24 step:22937 [D loss: 0.630480, acc.: 59.38%] [G loss: 1.468678]\n",
      "epoch:24 step:22938 [D loss: 0.635956, acc.: 62.50%] [G loss: 1.396916]\n",
      "epoch:24 step:22939 [D loss: 0.556677, acc.: 71.88%] [G loss: 1.540267]\n",
      "epoch:24 step:22940 [D loss: 0.581882, acc.: 73.44%] [G loss: 1.246879]\n",
      "epoch:24 step:22941 [D loss: 0.588390, acc.: 66.41%] [G loss: 1.390820]\n",
      "epoch:24 step:22942 [D loss: 0.591842, acc.: 71.88%] [G loss: 1.281346]\n",
      "epoch:24 step:22943 [D loss: 0.388315, acc.: 86.72%] [G loss: 1.409234]\n",
      "epoch:24 step:22944 [D loss: 0.778755, acc.: 50.00%] [G loss: 1.119929]\n",
      "epoch:24 step:22945 [D loss: 0.607548, acc.: 67.19%] [G loss: 0.967804]\n",
      "epoch:24 step:22946 [D loss: 0.479317, acc.: 76.56%] [G loss: 1.494964]\n",
      "epoch:24 step:22947 [D loss: 0.633481, acc.: 65.62%] [G loss: 1.101396]\n",
      "epoch:24 step:22948 [D loss: 0.561845, acc.: 78.12%] [G loss: 1.380000]\n",
      "epoch:24 step:22949 [D loss: 0.636705, acc.: 64.84%] [G loss: 1.170493]\n",
      "epoch:24 step:22950 [D loss: 0.502955, acc.: 77.34%] [G loss: 1.461137]\n",
      "epoch:24 step:22951 [D loss: 0.610705, acc.: 71.09%] [G loss: 1.308991]\n",
      "epoch:24 step:22952 [D loss: 0.466016, acc.: 78.12%] [G loss: 1.300015]\n",
      "epoch:24 step:22953 [D loss: 0.513649, acc.: 75.00%] [G loss: 1.450265]\n",
      "epoch:24 step:22954 [D loss: 0.585503, acc.: 67.97%] [G loss: 1.416897]\n",
      "epoch:24 step:22955 [D loss: 0.481402, acc.: 76.56%] [G loss: 1.365746]\n",
      "epoch:24 step:22956 [D loss: 0.497340, acc.: 74.22%] [G loss: 1.657964]\n",
      "epoch:24 step:22957 [D loss: 0.643902, acc.: 64.84%] [G loss: 1.246119]\n",
      "epoch:24 step:22958 [D loss: 0.607319, acc.: 64.06%] [G loss: 1.714713]\n",
      "epoch:24 step:22959 [D loss: 0.593914, acc.: 68.75%] [G loss: 1.273787]\n",
      "epoch:24 step:22960 [D loss: 0.576537, acc.: 70.31%] [G loss: 1.160834]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:24 step:22961 [D loss: 0.566744, acc.: 71.88%] [G loss: 1.466954]\n",
      "epoch:24 step:22962 [D loss: 0.493621, acc.: 75.78%] [G loss: 1.490550]\n",
      "epoch:24 step:22963 [D loss: 0.436469, acc.: 82.81%] [G loss: 1.652022]\n",
      "epoch:24 step:22964 [D loss: 0.525534, acc.: 74.22%] [G loss: 1.398774]\n",
      "epoch:24 step:22965 [D loss: 0.636567, acc.: 67.19%] [G loss: 1.831389]\n",
      "epoch:24 step:22966 [D loss: 0.549584, acc.: 70.31%] [G loss: 1.214515]\n",
      "epoch:24 step:22967 [D loss: 0.533134, acc.: 73.44%] [G loss: 1.531555]\n",
      "epoch:24 step:22968 [D loss: 0.590527, acc.: 69.53%] [G loss: 1.609172]\n",
      "epoch:24 step:22969 [D loss: 0.464748, acc.: 78.12%] [G loss: 1.575618]\n",
      "epoch:24 step:22970 [D loss: 0.529955, acc.: 71.88%] [G loss: 1.774241]\n",
      "epoch:24 step:22971 [D loss: 0.542471, acc.: 73.44%] [G loss: 1.894591]\n",
      "epoch:24 step:22972 [D loss: 0.520245, acc.: 76.56%] [G loss: 1.527187]\n",
      "epoch:24 step:22973 [D loss: 0.610924, acc.: 68.75%] [G loss: 1.331164]\n",
      "epoch:24 step:22974 [D loss: 0.649474, acc.: 60.94%] [G loss: 1.460768]\n",
      "epoch:24 step:22975 [D loss: 0.470372, acc.: 76.56%] [G loss: 1.483889]\n",
      "epoch:24 step:22976 [D loss: 0.418558, acc.: 82.81%] [G loss: 1.308913]\n",
      "epoch:24 step:22977 [D loss: 0.642583, acc.: 66.41%] [G loss: 1.640269]\n",
      "epoch:24 step:22978 [D loss: 0.631186, acc.: 66.41%] [G loss: 1.228118]\n",
      "epoch:24 step:22979 [D loss: 0.689792, acc.: 55.47%] [G loss: 1.111989]\n",
      "epoch:24 step:22980 [D loss: 0.485266, acc.: 78.12%] [G loss: 1.497091]\n",
      "epoch:24 step:22981 [D loss: 0.623917, acc.: 64.84%] [G loss: 1.499792]\n",
      "epoch:24 step:22982 [D loss: 0.513453, acc.: 74.22%] [G loss: 1.483214]\n",
      "epoch:24 step:22983 [D loss: 0.597555, acc.: 70.31%] [G loss: 1.619520]\n",
      "epoch:24 step:22984 [D loss: 0.707048, acc.: 60.94%] [G loss: 1.494532]\n",
      "epoch:24 step:22985 [D loss: 0.459694, acc.: 79.69%] [G loss: 1.332374]\n",
      "epoch:24 step:22986 [D loss: 0.438881, acc.: 81.25%] [G loss: 1.704909]\n",
      "epoch:24 step:22987 [D loss: 0.536673, acc.: 69.53%] [G loss: 1.473967]\n",
      "epoch:24 step:22988 [D loss: 0.615684, acc.: 64.84%] [G loss: 1.681274]\n",
      "epoch:24 step:22989 [D loss: 0.527106, acc.: 67.19%] [G loss: 1.605299]\n",
      "epoch:24 step:22990 [D loss: 0.646391, acc.: 67.19%] [G loss: 1.392149]\n",
      "epoch:24 step:22991 [D loss: 0.533320, acc.: 72.66%] [G loss: 1.233292]\n",
      "epoch:24 step:22992 [D loss: 0.631715, acc.: 67.19%] [G loss: 1.595328]\n",
      "epoch:24 step:22993 [D loss: 0.551143, acc.: 77.34%] [G loss: 1.429889]\n",
      "epoch:24 step:22994 [D loss: 0.500890, acc.: 72.66%] [G loss: 1.158465]\n",
      "epoch:24 step:22995 [D loss: 0.556338, acc.: 68.75%] [G loss: 1.329194]\n",
      "epoch:24 step:22996 [D loss: 0.477488, acc.: 76.56%] [G loss: 1.380088]\n",
      "epoch:24 step:22997 [D loss: 0.604694, acc.: 66.41%] [G loss: 1.353488]\n",
      "epoch:24 step:22998 [D loss: 0.473117, acc.: 77.34%] [G loss: 1.518014]\n",
      "epoch:24 step:22999 [D loss: 0.663397, acc.: 62.50%] [G loss: 1.121737]\n",
      "epoch:24 step:23000 [D loss: 0.494795, acc.: 78.12%] [G loss: 1.463804]\n",
      "epoch:24 step:23001 [D loss: 0.552280, acc.: 70.31%] [G loss: 1.568390]\n",
      "epoch:24 step:23002 [D loss: 0.481578, acc.: 77.34%] [G loss: 1.493156]\n",
      "epoch:24 step:23003 [D loss: 0.494277, acc.: 76.56%] [G loss: 1.572436]\n",
      "epoch:24 step:23004 [D loss: 0.572318, acc.: 66.41%] [G loss: 1.240542]\n",
      "epoch:24 step:23005 [D loss: 0.413605, acc.: 87.50%] [G loss: 1.375382]\n",
      "epoch:24 step:23006 [D loss: 0.602821, acc.: 67.19%] [G loss: 1.252042]\n",
      "epoch:24 step:23007 [D loss: 0.506542, acc.: 75.78%] [G loss: 1.363573]\n",
      "epoch:24 step:23008 [D loss: 0.602971, acc.: 68.75%] [G loss: 1.554580]\n",
      "epoch:24 step:23009 [D loss: 0.553889, acc.: 74.22%] [G loss: 1.228877]\n",
      "epoch:24 step:23010 [D loss: 0.525669, acc.: 75.78%] [G loss: 1.250312]\n",
      "epoch:24 step:23011 [D loss: 0.454170, acc.: 78.91%] [G loss: 1.326661]\n",
      "epoch:24 step:23012 [D loss: 0.506590, acc.: 75.78%] [G loss: 1.731444]\n",
      "epoch:24 step:23013 [D loss: 0.470041, acc.: 79.69%] [G loss: 1.534803]\n",
      "epoch:24 step:23014 [D loss: 0.638452, acc.: 62.50%] [G loss: 1.262724]\n",
      "epoch:24 step:23015 [D loss: 0.505874, acc.: 75.78%] [G loss: 1.426531]\n",
      "epoch:24 step:23016 [D loss: 0.655308, acc.: 61.72%] [G loss: 1.147725]\n",
      "epoch:24 step:23017 [D loss: 0.503636, acc.: 74.22%] [G loss: 1.625592]\n",
      "epoch:24 step:23018 [D loss: 0.587421, acc.: 67.19%] [G loss: 1.246597]\n",
      "epoch:24 step:23019 [D loss: 0.445952, acc.: 77.34%] [G loss: 1.371986]\n",
      "epoch:24 step:23020 [D loss: 0.720626, acc.: 55.47%] [G loss: 1.471777]\n",
      "epoch:24 step:23021 [D loss: 0.607605, acc.: 67.19%] [G loss: 1.744201]\n",
      "epoch:24 step:23022 [D loss: 0.645825, acc.: 64.84%] [G loss: 1.442717]\n",
      "epoch:24 step:23023 [D loss: 0.539345, acc.: 70.31%] [G loss: 1.428874]\n",
      "epoch:24 step:23024 [D loss: 0.863699, acc.: 44.53%] [G loss: 1.023005]\n",
      "epoch:24 step:23025 [D loss: 0.673981, acc.: 62.50%] [G loss: 1.086797]\n",
      "epoch:24 step:23026 [D loss: 0.614290, acc.: 71.09%] [G loss: 1.436300]\n",
      "epoch:24 step:23027 [D loss: 0.586358, acc.: 67.97%] [G loss: 1.235466]\n",
      "epoch:24 step:23028 [D loss: 0.527283, acc.: 71.88%] [G loss: 1.476430]\n",
      "epoch:24 step:23029 [D loss: 0.512249, acc.: 76.56%] [G loss: 1.422635]\n",
      "epoch:24 step:23030 [D loss: 0.686837, acc.: 60.94%] [G loss: 1.240861]\n",
      "epoch:24 step:23031 [D loss: 0.434981, acc.: 80.47%] [G loss: 1.297031]\n",
      "epoch:24 step:23032 [D loss: 0.431930, acc.: 82.81%] [G loss: 1.398695]\n",
      "epoch:24 step:23033 [D loss: 0.534476, acc.: 73.44%] [G loss: 1.436246]\n",
      "epoch:24 step:23034 [D loss: 0.482583, acc.: 74.22%] [G loss: 1.398967]\n",
      "epoch:24 step:23035 [D loss: 0.516013, acc.: 73.44%] [G loss: 0.948838]\n",
      "epoch:24 step:23036 [D loss: 0.522098, acc.: 73.44%] [G loss: 1.237869]\n",
      "epoch:24 step:23037 [D loss: 0.545467, acc.: 76.56%] [G loss: 1.122968]\n",
      "epoch:24 step:23038 [D loss: 0.459927, acc.: 78.91%] [G loss: 1.812145]\n",
      "epoch:24 step:23039 [D loss: 0.520181, acc.: 75.00%] [G loss: 1.382943]\n",
      "epoch:24 step:23040 [D loss: 0.509811, acc.: 73.44%] [G loss: 1.589628]\n",
      "epoch:24 step:23041 [D loss: 0.620677, acc.: 60.94%] [G loss: 1.139675]\n",
      "epoch:24 step:23042 [D loss: 0.597895, acc.: 68.75%] [G loss: 1.008240]\n",
      "epoch:24 step:23043 [D loss: 0.400780, acc.: 83.59%] [G loss: 1.399685]\n",
      "epoch:24 step:23044 [D loss: 0.628071, acc.: 60.16%] [G loss: 1.258686]\n",
      "epoch:24 step:23045 [D loss: 0.544934, acc.: 71.09%] [G loss: 1.434907]\n",
      "epoch:24 step:23046 [D loss: 0.478699, acc.: 78.12%] [G loss: 1.512454]\n",
      "epoch:24 step:23047 [D loss: 0.483664, acc.: 75.00%] [G loss: 1.719152]\n",
      "epoch:24 step:23048 [D loss: 0.666013, acc.: 63.28%] [G loss: 1.107147]\n",
      "epoch:24 step:23049 [D loss: 0.530158, acc.: 77.34%] [G loss: 1.458133]\n",
      "epoch:24 step:23050 [D loss: 0.564678, acc.: 67.19%] [G loss: 1.237828]\n",
      "epoch:24 step:23051 [D loss: 0.549490, acc.: 72.66%] [G loss: 1.131115]\n",
      "epoch:24 step:23052 [D loss: 0.619999, acc.: 67.97%] [G loss: 1.227173]\n",
      "epoch:24 step:23053 [D loss: 0.543406, acc.: 74.22%] [G loss: 1.224269]\n",
      "epoch:24 step:23054 [D loss: 0.500145, acc.: 78.12%] [G loss: 1.322227]\n",
      "epoch:24 step:23055 [D loss: 0.426077, acc.: 80.47%] [G loss: 1.025815]\n",
      "epoch:24 step:23056 [D loss: 0.607350, acc.: 68.75%] [G loss: 1.190324]\n",
      "epoch:24 step:23057 [D loss: 0.521968, acc.: 71.88%] [G loss: 1.318024]\n",
      "epoch:24 step:23058 [D loss: 0.475504, acc.: 79.69%] [G loss: 1.440437]\n",
      "epoch:24 step:23059 [D loss: 0.649767, acc.: 64.06%] [G loss: 1.246491]\n",
      "epoch:24 step:23060 [D loss: 0.351495, acc.: 86.72%] [G loss: 1.521400]\n",
      "epoch:24 step:23061 [D loss: 0.518108, acc.: 76.56%] [G loss: 1.730200]\n",
      "epoch:24 step:23062 [D loss: 0.518045, acc.: 76.56%] [G loss: 1.193646]\n",
      "epoch:24 step:23063 [D loss: 0.663939, acc.: 64.06%] [G loss: 1.650360]\n",
      "epoch:24 step:23064 [D loss: 0.430279, acc.: 81.25%] [G loss: 1.599767]\n",
      "epoch:24 step:23065 [D loss: 0.617206, acc.: 67.97%] [G loss: 1.453124]\n",
      "epoch:24 step:23066 [D loss: 0.565034, acc.: 72.66%] [G loss: 1.953376]\n",
      "epoch:24 step:23067 [D loss: 0.711974, acc.: 60.16%] [G loss: 1.340802]\n",
      "epoch:24 step:23068 [D loss: 0.533170, acc.: 75.78%] [G loss: 1.412208]\n",
      "epoch:24 step:23069 [D loss: 0.485462, acc.: 75.78%] [G loss: 1.416638]\n",
      "epoch:24 step:23070 [D loss: 0.624135, acc.: 63.28%] [G loss: 1.181279]\n",
      "epoch:24 step:23071 [D loss: 0.452491, acc.: 82.03%] [G loss: 1.437004]\n",
      "epoch:24 step:23072 [D loss: 0.484932, acc.: 77.34%] [G loss: 1.817037]\n",
      "epoch:24 step:23073 [D loss: 0.598723, acc.: 69.53%] [G loss: 1.104653]\n",
      "epoch:24 step:23074 [D loss: 0.444487, acc.: 80.47%] [G loss: 1.296872]\n",
      "epoch:24 step:23075 [D loss: 0.456518, acc.: 79.69%] [G loss: 1.567213]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:24 step:23076 [D loss: 0.589731, acc.: 67.97%] [G loss: 1.333497]\n",
      "epoch:24 step:23077 [D loss: 0.628589, acc.: 67.19%] [G loss: 1.123209]\n",
      "epoch:24 step:23078 [D loss: 0.511535, acc.: 72.66%] [G loss: 1.449156]\n",
      "epoch:24 step:23079 [D loss: 0.497539, acc.: 77.34%] [G loss: 1.682198]\n",
      "epoch:24 step:23080 [D loss: 0.640618, acc.: 64.06%] [G loss: 1.233539]\n",
      "epoch:24 step:23081 [D loss: 0.578412, acc.: 70.31%] [G loss: 1.220467]\n",
      "epoch:24 step:23082 [D loss: 0.433856, acc.: 81.25%] [G loss: 1.409780]\n",
      "epoch:24 step:23083 [D loss: 0.676460, acc.: 64.84%] [G loss: 1.427994]\n",
      "epoch:24 step:23084 [D loss: 0.583122, acc.: 71.88%] [G loss: 1.233176]\n",
      "epoch:24 step:23085 [D loss: 0.619607, acc.: 67.19%] [G loss: 1.217343]\n",
      "epoch:24 step:23086 [D loss: 0.728747, acc.: 55.47%] [G loss: 1.276573]\n",
      "epoch:24 step:23087 [D loss: 0.353670, acc.: 94.53%] [G loss: 1.166730]\n",
      "epoch:24 step:23088 [D loss: 0.480516, acc.: 76.56%] [G loss: 1.749623]\n",
      "epoch:24 step:23089 [D loss: 0.724994, acc.: 57.81%] [G loss: 1.465931]\n",
      "epoch:24 step:23090 [D loss: 0.376885, acc.: 86.72%] [G loss: 1.652214]\n",
      "epoch:24 step:23091 [D loss: 0.589834, acc.: 62.50%] [G loss: 1.417475]\n",
      "epoch:24 step:23092 [D loss: 0.631228, acc.: 64.06%] [G loss: 1.222540]\n",
      "epoch:24 step:23093 [D loss: 0.539419, acc.: 73.44%] [G loss: 1.830314]\n",
      "epoch:24 step:23094 [D loss: 0.678538, acc.: 60.16%] [G loss: 1.249393]\n",
      "epoch:24 step:23095 [D loss: 0.543105, acc.: 74.22%] [G loss: 1.460384]\n",
      "epoch:24 step:23096 [D loss: 0.619398, acc.: 69.53%] [G loss: 1.213547]\n",
      "epoch:24 step:23097 [D loss: 0.578814, acc.: 69.53%] [G loss: 1.023736]\n",
      "epoch:24 step:23098 [D loss: 0.477152, acc.: 75.78%] [G loss: 1.448479]\n",
      "epoch:24 step:23099 [D loss: 0.693620, acc.: 62.50%] [G loss: 1.035321]\n",
      "epoch:24 step:23100 [D loss: 0.594683, acc.: 61.72%] [G loss: 1.262678]\n",
      "epoch:24 step:23101 [D loss: 0.519242, acc.: 74.22%] [G loss: 1.278859]\n",
      "epoch:24 step:23102 [D loss: 0.552705, acc.: 71.88%] [G loss: 1.362084]\n",
      "epoch:24 step:23103 [D loss: 0.650965, acc.: 64.84%] [G loss: 1.257558]\n",
      "epoch:24 step:23104 [D loss: 0.403239, acc.: 83.59%] [G loss: 1.650663]\n",
      "epoch:24 step:23105 [D loss: 0.492104, acc.: 78.91%] [G loss: 1.718100]\n",
      "epoch:24 step:23106 [D loss: 0.560728, acc.: 72.66%] [G loss: 1.281243]\n",
      "epoch:24 step:23107 [D loss: 0.615474, acc.: 69.53%] [G loss: 1.160444]\n",
      "epoch:24 step:23108 [D loss: 0.416448, acc.: 81.25%] [G loss: 1.348861]\n",
      "epoch:24 step:23109 [D loss: 0.559417, acc.: 71.09%] [G loss: 1.318202]\n",
      "epoch:24 step:23110 [D loss: 0.565767, acc.: 72.66%] [G loss: 1.105365]\n",
      "epoch:24 step:23111 [D loss: 0.658012, acc.: 64.06%] [G loss: 1.601566]\n",
      "epoch:24 step:23112 [D loss: 0.654884, acc.: 61.72%] [G loss: 1.517030]\n",
      "epoch:24 step:23113 [D loss: 0.510318, acc.: 73.44%] [G loss: 1.580189]\n",
      "epoch:24 step:23114 [D loss: 0.538233, acc.: 77.34%] [G loss: 1.300305]\n",
      "epoch:24 step:23115 [D loss: 0.559948, acc.: 73.44%] [G loss: 1.618205]\n",
      "epoch:24 step:23116 [D loss: 0.573132, acc.: 71.88%] [G loss: 0.980078]\n",
      "epoch:24 step:23117 [D loss: 0.631256, acc.: 69.53%] [G loss: 0.803677]\n",
      "epoch:24 step:23118 [D loss: 0.588792, acc.: 69.53%] [G loss: 1.329390]\n",
      "epoch:24 step:23119 [D loss: 0.510159, acc.: 78.12%] [G loss: 1.443263]\n",
      "epoch:24 step:23120 [D loss: 0.710883, acc.: 64.84%] [G loss: 1.499291]\n",
      "epoch:24 step:23121 [D loss: 0.500927, acc.: 75.00%] [G loss: 1.439732]\n",
      "epoch:24 step:23122 [D loss: 0.627819, acc.: 65.62%] [G loss: 1.206163]\n",
      "epoch:24 step:23123 [D loss: 0.624607, acc.: 63.28%] [G loss: 1.302063]\n",
      "epoch:24 step:23124 [D loss: 0.669616, acc.: 61.72%] [G loss: 1.266110]\n",
      "epoch:24 step:23125 [D loss: 0.545630, acc.: 75.00%] [G loss: 1.712555]\n",
      "epoch:24 step:23126 [D loss: 0.658529, acc.: 60.16%] [G loss: 1.379161]\n",
      "epoch:24 step:23127 [D loss: 0.687750, acc.: 58.59%] [G loss: 1.506918]\n",
      "epoch:24 step:23128 [D loss: 0.550612, acc.: 75.78%] [G loss: 1.463493]\n",
      "epoch:24 step:23129 [D loss: 0.544417, acc.: 72.66%] [G loss: 1.707378]\n",
      "epoch:24 step:23130 [D loss: 0.632795, acc.: 68.75%] [G loss: 1.364213]\n",
      "epoch:24 step:23131 [D loss: 0.731930, acc.: 57.03%] [G loss: 1.117796]\n",
      "epoch:24 step:23132 [D loss: 0.511451, acc.: 71.88%] [G loss: 1.541126]\n",
      "epoch:24 step:23133 [D loss: 0.543972, acc.: 75.78%] [G loss: 1.367586]\n",
      "epoch:24 step:23134 [D loss: 0.581701, acc.: 70.31%] [G loss: 1.659426]\n",
      "epoch:24 step:23135 [D loss: 0.524004, acc.: 74.22%] [G loss: 1.270246]\n",
      "epoch:24 step:23136 [D loss: 0.580489, acc.: 68.75%] [G loss: 1.150564]\n",
      "epoch:24 step:23137 [D loss: 0.434479, acc.: 78.12%] [G loss: 1.509593]\n",
      "epoch:24 step:23138 [D loss: 0.524289, acc.: 76.56%] [G loss: 1.661082]\n",
      "epoch:24 step:23139 [D loss: 0.369907, acc.: 87.50%] [G loss: 1.313460]\n",
      "epoch:24 step:23140 [D loss: 0.547543, acc.: 70.31%] [G loss: 1.841484]\n",
      "epoch:24 step:23141 [D loss: 0.440819, acc.: 82.03%] [G loss: 1.724393]\n",
      "epoch:24 step:23142 [D loss: 0.385698, acc.: 85.16%] [G loss: 1.437012]\n",
      "epoch:24 step:23143 [D loss: 0.537204, acc.: 75.00%] [G loss: 1.525806]\n",
      "epoch:24 step:23144 [D loss: 0.480817, acc.: 76.56%] [G loss: 1.329137]\n",
      "epoch:24 step:23145 [D loss: 0.704108, acc.: 56.25%] [G loss: 1.444217]\n",
      "epoch:24 step:23146 [D loss: 0.596001, acc.: 66.41%] [G loss: 0.819306]\n",
      "epoch:24 step:23147 [D loss: 0.651626, acc.: 64.06%] [G loss: 1.431380]\n",
      "epoch:24 step:23148 [D loss: 0.592540, acc.: 65.62%] [G loss: 1.048555]\n",
      "epoch:24 step:23149 [D loss: 0.709174, acc.: 61.72%] [G loss: 1.642899]\n",
      "epoch:24 step:23150 [D loss: 0.501673, acc.: 75.78%] [G loss: 1.429940]\n",
      "epoch:24 step:23151 [D loss: 0.551615, acc.: 66.41%] [G loss: 1.413704]\n",
      "epoch:24 step:23152 [D loss: 0.598744, acc.: 67.19%] [G loss: 1.119462]\n",
      "epoch:24 step:23153 [D loss: 0.506286, acc.: 75.00%] [G loss: 1.167991]\n",
      "epoch:24 step:23154 [D loss: 0.519051, acc.: 77.34%] [G loss: 1.132836]\n",
      "epoch:24 step:23155 [D loss: 0.517794, acc.: 75.78%] [G loss: 1.421346]\n",
      "epoch:24 step:23156 [D loss: 0.763097, acc.: 47.66%] [G loss: 1.041444]\n",
      "epoch:24 step:23157 [D loss: 0.490247, acc.: 78.12%] [G loss: 1.454182]\n",
      "epoch:24 step:23158 [D loss: 0.595614, acc.: 70.31%] [G loss: 1.498580]\n",
      "epoch:24 step:23159 [D loss: 0.545335, acc.: 73.44%] [G loss: 1.241796]\n",
      "epoch:24 step:23160 [D loss: 0.602113, acc.: 64.06%] [G loss: 1.253266]\n",
      "epoch:24 step:23161 [D loss: 0.609015, acc.: 67.97%] [G loss: 1.662577]\n",
      "epoch:24 step:23162 [D loss: 0.545854, acc.: 70.31%] [G loss: 1.016100]\n",
      "epoch:24 step:23163 [D loss: 0.549383, acc.: 71.09%] [G loss: 1.389117]\n",
      "epoch:24 step:23164 [D loss: 0.405253, acc.: 85.16%] [G loss: 1.404601]\n",
      "epoch:24 step:23165 [D loss: 0.515813, acc.: 76.56%] [G loss: 1.679391]\n",
      "epoch:24 step:23166 [D loss: 0.562797, acc.: 73.44%] [G loss: 1.469942]\n",
      "epoch:24 step:23167 [D loss: 0.470418, acc.: 79.69%] [G loss: 1.771907]\n",
      "epoch:24 step:23168 [D loss: 0.664415, acc.: 58.59%] [G loss: 1.333437]\n",
      "epoch:24 step:23169 [D loss: 0.411076, acc.: 84.38%] [G loss: 1.435419]\n",
      "epoch:24 step:23170 [D loss: 0.473007, acc.: 77.34%] [G loss: 1.379165]\n",
      "epoch:24 step:23171 [D loss: 0.712680, acc.: 60.16%] [G loss: 1.327823]\n",
      "epoch:24 step:23172 [D loss: 0.482733, acc.: 76.56%] [G loss: 1.354828]\n",
      "epoch:24 step:23173 [D loss: 0.615610, acc.: 64.06%] [G loss: 1.393131]\n",
      "epoch:24 step:23174 [D loss: 0.527573, acc.: 71.88%] [G loss: 1.493944]\n",
      "epoch:24 step:23175 [D loss: 0.565404, acc.: 68.75%] [G loss: 1.254507]\n",
      "epoch:24 step:23176 [D loss: 0.533035, acc.: 79.69%] [G loss: 1.361992]\n",
      "epoch:24 step:23177 [D loss: 0.662050, acc.: 60.16%] [G loss: 1.003077]\n",
      "epoch:24 step:23178 [D loss: 0.601894, acc.: 71.09%] [G loss: 1.012776]\n",
      "epoch:24 step:23179 [D loss: 0.640585, acc.: 64.06%] [G loss: 1.283049]\n",
      "epoch:24 step:23180 [D loss: 0.567531, acc.: 74.22%] [G loss: 1.305875]\n",
      "epoch:24 step:23181 [D loss: 0.645131, acc.: 61.72%] [G loss: 1.244675]\n",
      "epoch:24 step:23182 [D loss: 0.455579, acc.: 77.34%] [G loss: 1.457860]\n",
      "epoch:24 step:23183 [D loss: 0.539750, acc.: 68.75%] [G loss: 1.531927]\n",
      "epoch:24 step:23184 [D loss: 0.601559, acc.: 64.84%] [G loss: 1.406512]\n",
      "epoch:24 step:23185 [D loss: 0.438478, acc.: 84.38%] [G loss: 1.428355]\n",
      "epoch:24 step:23186 [D loss: 0.643632, acc.: 64.84%] [G loss: 1.445472]\n",
      "epoch:24 step:23187 [D loss: 0.485226, acc.: 79.69%] [G loss: 1.509042]\n",
      "epoch:24 step:23188 [D loss: 0.570432, acc.: 67.97%] [G loss: 1.299614]\n",
      "epoch:24 step:23189 [D loss: 0.404347, acc.: 83.59%] [G loss: 1.496386]\n",
      "epoch:24 step:23190 [D loss: 0.358597, acc.: 90.62%] [G loss: 1.584576]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:24 step:23191 [D loss: 0.660415, acc.: 61.72%] [G loss: 1.270325]\n",
      "epoch:24 step:23192 [D loss: 0.486623, acc.: 77.34%] [G loss: 1.330837]\n",
      "epoch:24 step:23193 [D loss: 0.692288, acc.: 60.16%] [G loss: 1.417016]\n",
      "epoch:24 step:23194 [D loss: 0.512384, acc.: 78.12%] [G loss: 1.263148]\n",
      "epoch:24 step:23195 [D loss: 0.314654, acc.: 89.06%] [G loss: 1.544343]\n",
      "epoch:24 step:23196 [D loss: 0.454884, acc.: 78.12%] [G loss: 1.135584]\n",
      "epoch:24 step:23197 [D loss: 0.580818, acc.: 67.97%] [G loss: 1.521464]\n",
      "epoch:24 step:23198 [D loss: 0.554843, acc.: 71.88%] [G loss: 1.203196]\n",
      "epoch:24 step:23199 [D loss: 0.522868, acc.: 72.66%] [G loss: 1.206677]\n",
      "epoch:24 step:23200 [D loss: 0.568227, acc.: 69.53%] [G loss: 1.456325]\n",
      "epoch:24 step:23201 [D loss: 0.609913, acc.: 66.41%] [G loss: 1.206315]\n",
      "epoch:24 step:23202 [D loss: 0.471538, acc.: 78.12%] [G loss: 1.481645]\n",
      "epoch:24 step:23203 [D loss: 0.664724, acc.: 60.16%] [G loss: 0.930852]\n",
      "epoch:24 step:23204 [D loss: 0.625741, acc.: 61.72%] [G loss: 1.118860]\n",
      "epoch:24 step:23205 [D loss: 0.539213, acc.: 72.66%] [G loss: 1.185964]\n",
      "epoch:24 step:23206 [D loss: 0.357669, acc.: 87.50%] [G loss: 1.469561]\n",
      "epoch:24 step:23207 [D loss: 0.694599, acc.: 60.94%] [G loss: 1.365711]\n",
      "epoch:24 step:23208 [D loss: 0.513057, acc.: 74.22%] [G loss: 1.564624]\n",
      "epoch:24 step:23209 [D loss: 0.536371, acc.: 72.66%] [G loss: 1.368311]\n",
      "epoch:24 step:23210 [D loss: 0.645883, acc.: 64.84%] [G loss: 1.549106]\n",
      "epoch:24 step:23211 [D loss: 0.438356, acc.: 80.47%] [G loss: 1.611369]\n",
      "epoch:24 step:23212 [D loss: 0.445123, acc.: 82.03%] [G loss: 1.296420]\n",
      "epoch:24 step:23213 [D loss: 0.545034, acc.: 69.53%] [G loss: 1.456129]\n",
      "epoch:24 step:23214 [D loss: 0.520797, acc.: 75.78%] [G loss: 1.322972]\n",
      "epoch:24 step:23215 [D loss: 0.379152, acc.: 89.84%] [G loss: 1.337186]\n",
      "epoch:24 step:23216 [D loss: 0.644708, acc.: 64.06%] [G loss: 1.167902]\n",
      "epoch:24 step:23217 [D loss: 0.580598, acc.: 67.19%] [G loss: 1.490434]\n",
      "epoch:24 step:23218 [D loss: 0.677279, acc.: 66.41%] [G loss: 1.103968]\n",
      "epoch:24 step:23219 [D loss: 0.642278, acc.: 63.28%] [G loss: 1.369766]\n",
      "epoch:24 step:23220 [D loss: 0.521048, acc.: 74.22%] [G loss: 1.041164]\n",
      "epoch:24 step:23221 [D loss: 0.420310, acc.: 82.03%] [G loss: 1.635305]\n",
      "epoch:24 step:23222 [D loss: 0.722051, acc.: 53.91%] [G loss: 1.257300]\n",
      "epoch:24 step:23223 [D loss: 0.431326, acc.: 85.94%] [G loss: 1.436289]\n",
      "epoch:24 step:23224 [D loss: 0.449460, acc.: 78.12%] [G loss: 1.651337]\n",
      "epoch:24 step:23225 [D loss: 0.672204, acc.: 60.16%] [G loss: 1.105376]\n",
      "epoch:24 step:23226 [D loss: 0.556366, acc.: 70.31%] [G loss: 1.428763]\n",
      "epoch:24 step:23227 [D loss: 0.478155, acc.: 76.56%] [G loss: 1.843505]\n",
      "epoch:24 step:23228 [D loss: 0.716127, acc.: 56.25%] [G loss: 1.090315]\n",
      "epoch:24 step:23229 [D loss: 0.553875, acc.: 74.22%] [G loss: 1.673227]\n",
      "epoch:24 step:23230 [D loss: 0.538457, acc.: 72.66%] [G loss: 1.482927]\n",
      "epoch:24 step:23231 [D loss: 0.564045, acc.: 71.88%] [G loss: 1.212235]\n",
      "epoch:24 step:23232 [D loss: 0.479457, acc.: 78.12%] [G loss: 1.580993]\n",
      "epoch:24 step:23233 [D loss: 0.438521, acc.: 80.47%] [G loss: 1.595730]\n",
      "epoch:24 step:23234 [D loss: 0.479794, acc.: 78.12%] [G loss: 1.553737]\n",
      "epoch:24 step:23235 [D loss: 0.515749, acc.: 76.56%] [G loss: 1.249662]\n",
      "epoch:24 step:23236 [D loss: 0.490854, acc.: 77.34%] [G loss: 1.164129]\n",
      "epoch:24 step:23237 [D loss: 0.720101, acc.: 54.69%] [G loss: 1.359242]\n",
      "epoch:24 step:23238 [D loss: 0.425996, acc.: 82.03%] [G loss: 1.227671]\n",
      "epoch:24 step:23239 [D loss: 0.572981, acc.: 74.22%] [G loss: 1.341731]\n",
      "epoch:24 step:23240 [D loss: 0.480961, acc.: 76.56%] [G loss: 1.502575]\n",
      "epoch:24 step:23241 [D loss: 0.549053, acc.: 73.44%] [G loss: 1.486462]\n",
      "epoch:24 step:23242 [D loss: 0.689717, acc.: 62.50%] [G loss: 1.087421]\n",
      "epoch:24 step:23243 [D loss: 0.612454, acc.: 71.09%] [G loss: 1.503451]\n",
      "epoch:24 step:23244 [D loss: 0.501869, acc.: 78.91%] [G loss: 1.735497]\n",
      "epoch:24 step:23245 [D loss: 0.643676, acc.: 56.25%] [G loss: 1.096983]\n",
      "epoch:24 step:23246 [D loss: 0.491030, acc.: 75.00%] [G loss: 1.534505]\n",
      "epoch:24 step:23247 [D loss: 0.498070, acc.: 79.69%] [G loss: 1.286904]\n",
      "epoch:24 step:23248 [D loss: 0.599923, acc.: 68.75%] [G loss: 1.053105]\n",
      "epoch:24 step:23249 [D loss: 0.606421, acc.: 66.41%] [G loss: 1.319134]\n",
      "epoch:24 step:23250 [D loss: 0.607345, acc.: 66.41%] [G loss: 1.062261]\n",
      "epoch:24 step:23251 [D loss: 0.451232, acc.: 78.12%] [G loss: 1.549430]\n",
      "epoch:24 step:23252 [D loss: 0.517750, acc.: 78.91%] [G loss: 1.311076]\n",
      "epoch:24 step:23253 [D loss: 0.514153, acc.: 73.44%] [G loss: 1.574699]\n",
      "epoch:24 step:23254 [D loss: 0.605606, acc.: 64.84%] [G loss: 1.287320]\n",
      "epoch:24 step:23255 [D loss: 0.582906, acc.: 67.97%] [G loss: 1.489182]\n",
      "epoch:24 step:23256 [D loss: 0.785207, acc.: 57.03%] [G loss: 1.350781]\n",
      "epoch:24 step:23257 [D loss: 0.620076, acc.: 67.97%] [G loss: 1.600405]\n",
      "epoch:24 step:23258 [D loss: 0.680891, acc.: 57.81%] [G loss: 1.227232]\n",
      "epoch:24 step:23259 [D loss: 0.456617, acc.: 78.91%] [G loss: 1.742449]\n",
      "epoch:24 step:23260 [D loss: 0.576024, acc.: 68.75%] [G loss: 1.168318]\n",
      "epoch:24 step:23261 [D loss: 0.684038, acc.: 56.25%] [G loss: 1.058685]\n",
      "epoch:24 step:23262 [D loss: 0.411933, acc.: 85.16%] [G loss: 1.694186]\n",
      "epoch:24 step:23263 [D loss: 0.447302, acc.: 80.47%] [G loss: 0.908722]\n",
      "epoch:24 step:23264 [D loss: 0.404872, acc.: 85.94%] [G loss: 1.448834]\n",
      "epoch:24 step:23265 [D loss: 0.445213, acc.: 82.81%] [G loss: 1.407319]\n",
      "epoch:24 step:23266 [D loss: 0.443411, acc.: 80.47%] [G loss: 1.481072]\n",
      "epoch:24 step:23267 [D loss: 0.677832, acc.: 62.50%] [G loss: 1.361371]\n",
      "epoch:24 step:23268 [D loss: 0.770038, acc.: 56.25%] [G loss: 1.311604]\n",
      "epoch:24 step:23269 [D loss: 0.454126, acc.: 83.59%] [G loss: 1.368414]\n",
      "epoch:24 step:23270 [D loss: 0.508576, acc.: 76.56%] [G loss: 1.449110]\n",
      "epoch:24 step:23271 [D loss: 0.463529, acc.: 83.59%] [G loss: 1.642147]\n",
      "epoch:24 step:23272 [D loss: 0.547761, acc.: 70.31%] [G loss: 1.290567]\n",
      "epoch:24 step:23273 [D loss: 0.346461, acc.: 89.06%] [G loss: 1.338069]\n",
      "epoch:24 step:23274 [D loss: 0.560387, acc.: 71.09%] [G loss: 1.534101]\n",
      "epoch:24 step:23275 [D loss: 0.548413, acc.: 71.09%] [G loss: 1.136690]\n",
      "epoch:24 step:23276 [D loss: 0.563967, acc.: 72.66%] [G loss: 1.197884]\n",
      "epoch:24 step:23277 [D loss: 0.593402, acc.: 72.66%] [G loss: 0.925693]\n",
      "epoch:24 step:23278 [D loss: 0.422431, acc.: 85.16%] [G loss: 1.341446]\n",
      "epoch:24 step:23279 [D loss: 0.655692, acc.: 59.38%] [G loss: 1.228179]\n",
      "epoch:24 step:23280 [D loss: 0.523254, acc.: 73.44%] [G loss: 1.460287]\n",
      "epoch:24 step:23281 [D loss: 0.544506, acc.: 70.31%] [G loss: 1.301329]\n",
      "epoch:24 step:23282 [D loss: 0.507135, acc.: 75.00%] [G loss: 1.534373]\n",
      "epoch:24 step:23283 [D loss: 0.530864, acc.: 75.78%] [G loss: 1.857894]\n",
      "epoch:24 step:23284 [D loss: 0.611943, acc.: 64.06%] [G loss: 1.018713]\n",
      "epoch:24 step:23285 [D loss: 0.592783, acc.: 66.41%] [G loss: 1.223253]\n",
      "epoch:24 step:23286 [D loss: 0.599130, acc.: 64.84%] [G loss: 1.550867]\n",
      "epoch:24 step:23287 [D loss: 0.457685, acc.: 82.03%] [G loss: 1.533811]\n",
      "epoch:24 step:23288 [D loss: 0.460233, acc.: 78.12%] [G loss: 1.130201]\n",
      "epoch:24 step:23289 [D loss: 0.420941, acc.: 83.59%] [G loss: 1.385820]\n",
      "epoch:24 step:23290 [D loss: 0.723327, acc.: 55.47%] [G loss: 0.921054]\n",
      "epoch:24 step:23291 [D loss: 0.615806, acc.: 67.97%] [G loss: 1.791423]\n",
      "epoch:24 step:23292 [D loss: 0.544326, acc.: 67.97%] [G loss: 1.575496]\n",
      "epoch:24 step:23293 [D loss: 0.566830, acc.: 71.09%] [G loss: 1.365847]\n",
      "epoch:24 step:23294 [D loss: 0.515802, acc.: 68.75%] [G loss: 1.384417]\n",
      "epoch:24 step:23295 [D loss: 0.485006, acc.: 75.78%] [G loss: 1.402097]\n",
      "epoch:24 step:23296 [D loss: 0.436279, acc.: 78.12%] [G loss: 1.346036]\n",
      "epoch:24 step:23297 [D loss: 0.640810, acc.: 62.50%] [G loss: 1.159097]\n",
      "epoch:24 step:23298 [D loss: 0.383358, acc.: 84.38%] [G loss: 1.190941]\n",
      "epoch:24 step:23299 [D loss: 0.659997, acc.: 63.28%] [G loss: 1.179995]\n",
      "epoch:24 step:23300 [D loss: 0.558653, acc.: 72.66%] [G loss: 1.331581]\n",
      "epoch:24 step:23301 [D loss: 0.642485, acc.: 63.28%] [G loss: 1.036874]\n",
      "epoch:24 step:23302 [D loss: 0.415025, acc.: 82.81%] [G loss: 1.106630]\n",
      "epoch:24 step:23303 [D loss: 0.562304, acc.: 73.44%] [G loss: 1.008491]\n",
      "epoch:24 step:23304 [D loss: 0.461071, acc.: 78.12%] [G loss: 1.499580]\n",
      "epoch:24 step:23305 [D loss: 0.529989, acc.: 71.09%] [G loss: 1.228991]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:24 step:23306 [D loss: 0.684702, acc.: 58.59%] [G loss: 1.110824]\n",
      "epoch:24 step:23307 [D loss: 0.535320, acc.: 72.66%] [G loss: 1.189545]\n",
      "epoch:24 step:23308 [D loss: 0.533144, acc.: 75.78%] [G loss: 1.239997]\n",
      "epoch:24 step:23309 [D loss: 0.524844, acc.: 76.56%] [G loss: 1.234598]\n",
      "epoch:24 step:23310 [D loss: 0.527565, acc.: 73.44%] [G loss: 1.189791]\n",
      "epoch:24 step:23311 [D loss: 0.580631, acc.: 67.19%] [G loss: 1.336788]\n",
      "epoch:24 step:23312 [D loss: 0.439556, acc.: 84.38%] [G loss: 1.356944]\n",
      "epoch:24 step:23313 [D loss: 0.589811, acc.: 66.41%] [G loss: 1.287937]\n",
      "epoch:24 step:23314 [D loss: 0.519764, acc.: 75.78%] [G loss: 1.293545]\n",
      "epoch:24 step:23315 [D loss: 0.491075, acc.: 76.56%] [G loss: 1.349970]\n",
      "epoch:24 step:23316 [D loss: 0.741297, acc.: 54.69%] [G loss: 1.322814]\n",
      "epoch:24 step:23317 [D loss: 0.532344, acc.: 71.88%] [G loss: 1.195347]\n",
      "epoch:24 step:23318 [D loss: 0.579093, acc.: 72.66%] [G loss: 1.225375]\n",
      "epoch:24 step:23319 [D loss: 0.639597, acc.: 64.06%] [G loss: 1.269279]\n",
      "epoch:24 step:23320 [D loss: 0.663988, acc.: 63.28%] [G loss: 1.178683]\n",
      "epoch:24 step:23321 [D loss: 0.505057, acc.: 76.56%] [G loss: 1.451919]\n",
      "epoch:24 step:23322 [D loss: 0.720428, acc.: 64.84%] [G loss: 1.288099]\n",
      "epoch:24 step:23323 [D loss: 0.434402, acc.: 82.03%] [G loss: 1.571819]\n",
      "epoch:24 step:23324 [D loss: 0.797078, acc.: 52.34%] [G loss: 1.218801]\n",
      "epoch:24 step:23325 [D loss: 0.478841, acc.: 79.69%] [G loss: 1.439739]\n",
      "epoch:24 step:23326 [D loss: 0.472284, acc.: 75.78%] [G loss: 1.578592]\n",
      "epoch:24 step:23327 [D loss: 0.404244, acc.: 84.38%] [G loss: 1.797803]\n",
      "epoch:24 step:23328 [D loss: 0.676919, acc.: 61.72%] [G loss: 1.160048]\n",
      "epoch:24 step:23329 [D loss: 0.502996, acc.: 76.56%] [G loss: 1.733198]\n",
      "epoch:24 step:23330 [D loss: 0.551499, acc.: 71.09%] [G loss: 1.338981]\n",
      "epoch:24 step:23331 [D loss: 0.630056, acc.: 63.28%] [G loss: 1.542239]\n",
      "epoch:24 step:23332 [D loss: 0.566241, acc.: 71.88%] [G loss: 1.281718]\n",
      "epoch:24 step:23333 [D loss: 0.622083, acc.: 61.72%] [G loss: 1.316563]\n",
      "epoch:24 step:23334 [D loss: 0.456513, acc.: 76.56%] [G loss: 1.764410]\n",
      "epoch:24 step:23335 [D loss: 0.663801, acc.: 59.38%] [G loss: 1.102339]\n",
      "epoch:24 step:23336 [D loss: 0.625603, acc.: 62.50%] [G loss: 1.420691]\n",
      "epoch:24 step:23337 [D loss: 0.400046, acc.: 86.72%] [G loss: 1.317497]\n",
      "epoch:24 step:23338 [D loss: 0.466817, acc.: 76.56%] [G loss: 1.823657]\n",
      "epoch:24 step:23339 [D loss: 0.584857, acc.: 67.97%] [G loss: 1.152198]\n",
      "epoch:24 step:23340 [D loss: 0.503192, acc.: 77.34%] [G loss: 1.223225]\n",
      "epoch:24 step:23341 [D loss: 0.663392, acc.: 60.94%] [G loss: 1.375903]\n",
      "epoch:24 step:23342 [D loss: 0.574860, acc.: 71.09%] [G loss: 1.236786]\n",
      "epoch:24 step:23343 [D loss: 0.592899, acc.: 71.88%] [G loss: 1.120362]\n",
      "epoch:24 step:23344 [D loss: 0.478715, acc.: 79.69%] [G loss: 1.057450]\n",
      "epoch:24 step:23345 [D loss: 0.603905, acc.: 67.97%] [G loss: 1.444741]\n",
      "epoch:24 step:23346 [D loss: 0.406633, acc.: 84.38%] [G loss: 1.134376]\n",
      "epoch:24 step:23347 [D loss: 0.635252, acc.: 62.50%] [G loss: 1.517522]\n",
      "epoch:24 step:23348 [D loss: 0.521164, acc.: 78.91%] [G loss: 0.942749]\n",
      "epoch:24 step:23349 [D loss: 0.433514, acc.: 82.81%] [G loss: 1.792819]\n",
      "epoch:24 step:23350 [D loss: 0.659941, acc.: 62.50%] [G loss: 1.244054]\n",
      "epoch:24 step:23351 [D loss: 0.491365, acc.: 78.91%] [G loss: 1.303106]\n",
      "epoch:24 step:23352 [D loss: 0.760287, acc.: 53.91%] [G loss: 1.038195]\n",
      "epoch:24 step:23353 [D loss: 0.668795, acc.: 66.41%] [G loss: 1.276626]\n",
      "epoch:24 step:23354 [D loss: 0.466327, acc.: 74.22%] [G loss: 1.580767]\n",
      "epoch:24 step:23355 [D loss: 0.607821, acc.: 64.06%] [G loss: 1.394228]\n",
      "epoch:24 step:23356 [D loss: 0.373361, acc.: 85.94%] [G loss: 1.439064]\n",
      "epoch:24 step:23357 [D loss: 0.499323, acc.: 75.00%] [G loss: 1.557624]\n",
      "epoch:24 step:23358 [D loss: 0.524484, acc.: 68.75%] [G loss: 1.036461]\n",
      "epoch:24 step:23359 [D loss: 0.346616, acc.: 89.06%] [G loss: 1.304506]\n",
      "epoch:24 step:23360 [D loss: 0.433171, acc.: 82.81%] [G loss: 1.246399]\n",
      "epoch:24 step:23361 [D loss: 0.318893, acc.: 90.62%] [G loss: 1.320734]\n",
      "epoch:24 step:23362 [D loss: 0.451804, acc.: 82.81%] [G loss: 1.160089]\n",
      "epoch:24 step:23363 [D loss: 0.545115, acc.: 74.22%] [G loss: 1.749176]\n",
      "epoch:24 step:23364 [D loss: 0.635644, acc.: 61.72%] [G loss: 1.109504]\n",
      "epoch:24 step:23365 [D loss: 0.632378, acc.: 65.62%] [G loss: 1.921388]\n",
      "epoch:24 step:23366 [D loss: 0.664710, acc.: 57.81%] [G loss: 1.220592]\n",
      "epoch:24 step:23367 [D loss: 0.623640, acc.: 66.41%] [G loss: 1.053524]\n",
      "epoch:24 step:23368 [D loss: 0.520136, acc.: 75.00%] [G loss: 1.265896]\n",
      "epoch:24 step:23369 [D loss: 0.477275, acc.: 80.47%] [G loss: 1.689032]\n",
      "epoch:24 step:23370 [D loss: 0.498371, acc.: 78.12%] [G loss: 1.251677]\n",
      "epoch:24 step:23371 [D loss: 0.638867, acc.: 68.75%] [G loss: 1.348136]\n",
      "epoch:24 step:23372 [D loss: 0.520008, acc.: 78.12%] [G loss: 1.666355]\n",
      "epoch:24 step:23373 [D loss: 0.365822, acc.: 92.19%] [G loss: 1.849347]\n",
      "epoch:24 step:23374 [D loss: 0.507823, acc.: 75.78%] [G loss: 1.195431]\n",
      "epoch:24 step:23375 [D loss: 0.666755, acc.: 60.16%] [G loss: 1.245661]\n",
      "epoch:24 step:23376 [D loss: 0.627140, acc.: 63.28%] [G loss: 1.021603]\n",
      "epoch:24 step:23377 [D loss: 0.608262, acc.: 67.97%] [G loss: 1.451494]\n",
      "epoch:24 step:23378 [D loss: 0.525888, acc.: 68.75%] [G loss: 1.274188]\n",
      "epoch:24 step:23379 [D loss: 0.708051, acc.: 55.47%] [G loss: 1.128462]\n",
      "epoch:24 step:23380 [D loss: 0.533837, acc.: 74.22%] [G loss: 1.259518]\n",
      "epoch:24 step:23381 [D loss: 0.692877, acc.: 60.16%] [G loss: 1.399297]\n",
      "epoch:24 step:23382 [D loss: 0.670041, acc.: 58.59%] [G loss: 1.144146]\n",
      "epoch:24 step:23383 [D loss: 0.536809, acc.: 74.22%] [G loss: 1.047513]\n",
      "epoch:24 step:23384 [D loss: 0.463351, acc.: 79.69%] [G loss: 1.159506]\n",
      "epoch:24 step:23385 [D loss: 0.582144, acc.: 69.53%] [G loss: 1.153934]\n",
      "epoch:24 step:23386 [D loss: 0.444137, acc.: 82.03%] [G loss: 1.357956]\n",
      "epoch:24 step:23387 [D loss: 0.547780, acc.: 66.41%] [G loss: 1.468166]\n",
      "epoch:24 step:23388 [D loss: 0.540774, acc.: 73.44%] [G loss: 1.136346]\n",
      "epoch:24 step:23389 [D loss: 0.537187, acc.: 75.00%] [G loss: 1.581999]\n",
      "epoch:24 step:23390 [D loss: 0.706537, acc.: 60.16%] [G loss: 1.391759]\n",
      "epoch:24 step:23391 [D loss: 0.705623, acc.: 59.38%] [G loss: 1.108386]\n",
      "epoch:24 step:23392 [D loss: 0.481211, acc.: 80.47%] [G loss: 2.119032]\n",
      "epoch:24 step:23393 [D loss: 0.549042, acc.: 74.22%] [G loss: 1.703389]\n",
      "epoch:24 step:23394 [D loss: 0.573657, acc.: 69.53%] [G loss: 1.306640]\n",
      "epoch:24 step:23395 [D loss: 0.619871, acc.: 64.06%] [G loss: 1.455789]\n",
      "epoch:24 step:23396 [D loss: 0.595776, acc.: 67.97%] [G loss: 0.968954]\n",
      "epoch:24 step:23397 [D loss: 0.554675, acc.: 70.31%] [G loss: 1.444407]\n",
      "epoch:24 step:23398 [D loss: 0.512118, acc.: 77.34%] [G loss: 1.655086]\n",
      "epoch:24 step:23399 [D loss: 0.582448, acc.: 71.88%] [G loss: 1.383476]\n",
      "epoch:24 step:23400 [D loss: 0.665106, acc.: 65.62%] [G loss: 1.338093]\n",
      "epoch:24 step:23401 [D loss: 0.452194, acc.: 79.69%] [G loss: 1.403919]\n",
      "epoch:24 step:23402 [D loss: 0.735257, acc.: 58.59%] [G loss: 1.317467]\n",
      "epoch:24 step:23403 [D loss: 0.628059, acc.: 66.41%] [G loss: 1.350204]\n",
      "epoch:24 step:23404 [D loss: 0.686643, acc.: 64.06%] [G loss: 1.046488]\n",
      "epoch:24 step:23405 [D loss: 0.650825, acc.: 61.72%] [G loss: 1.105585]\n",
      "epoch:24 step:23406 [D loss: 0.457863, acc.: 82.81%] [G loss: 1.363676]\n",
      "epoch:24 step:23407 [D loss: 0.537261, acc.: 72.66%] [G loss: 1.141284]\n",
      "epoch:24 step:23408 [D loss: 0.527925, acc.: 75.78%] [G loss: 1.402923]\n",
      "epoch:24 step:23409 [D loss: 0.669729, acc.: 60.16%] [G loss: 1.372384]\n",
      "epoch:24 step:23410 [D loss: 0.611223, acc.: 65.62%] [G loss: 1.142669]\n",
      "epoch:24 step:23411 [D loss: 0.528119, acc.: 74.22%] [G loss: 1.352770]\n",
      "epoch:24 step:23412 [D loss: 0.598179, acc.: 67.19%] [G loss: 1.655335]\n",
      "epoch:24 step:23413 [D loss: 0.545479, acc.: 74.22%] [G loss: 1.593531]\n",
      "epoch:24 step:23414 [D loss: 0.474948, acc.: 76.56%] [G loss: 1.561909]\n",
      "epoch:24 step:23415 [D loss: 0.639103, acc.: 68.75%] [G loss: 1.232511]\n",
      "epoch:24 step:23416 [D loss: 0.319001, acc.: 91.41%] [G loss: 1.440243]\n",
      "epoch:24 step:23417 [D loss: 0.601005, acc.: 62.50%] [G loss: 1.132114]\n",
      "epoch:24 step:23418 [D loss: 0.478587, acc.: 79.69%] [G loss: 1.624470]\n",
      "epoch:24 step:23419 [D loss: 0.667667, acc.: 61.72%] [G loss: 1.191658]\n",
      "epoch:24 step:23420 [D loss: 0.485718, acc.: 75.00%] [G loss: 1.789169]\n",
      "epoch:24 step:23421 [D loss: 0.577604, acc.: 67.97%] [G loss: 1.697526]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:24 step:23422 [D loss: 0.473330, acc.: 79.69%] [G loss: 1.159258]\n",
      "epoch:24 step:23423 [D loss: 0.517738, acc.: 75.00%] [G loss: 1.324206]\n",
      "epoch:24 step:23424 [D loss: 0.443097, acc.: 81.25%] [G loss: 1.636245]\n",
      "epoch:24 step:23425 [D loss: 0.457233, acc.: 81.25%] [G loss: 1.628942]\n",
      "epoch:25 step:23426 [D loss: 0.542528, acc.: 69.53%] [G loss: 1.346505]\n",
      "epoch:25 step:23427 [D loss: 0.518470, acc.: 76.56%] [G loss: 1.336952]\n",
      "epoch:25 step:23428 [D loss: 0.641734, acc.: 59.38%] [G loss: 1.286374]\n",
      "epoch:25 step:23429 [D loss: 0.599249, acc.: 66.41%] [G loss: 1.162170]\n",
      "epoch:25 step:23430 [D loss: 0.435520, acc.: 78.91%] [G loss: 1.556211]\n",
      "epoch:25 step:23431 [D loss: 0.525224, acc.: 77.34%] [G loss: 1.352674]\n",
      "epoch:25 step:23432 [D loss: 0.686757, acc.: 57.81%] [G loss: 1.357514]\n",
      "epoch:25 step:23433 [D loss: 0.576033, acc.: 71.09%] [G loss: 1.155781]\n",
      "epoch:25 step:23434 [D loss: 0.526021, acc.: 73.44%] [G loss: 1.389004]\n",
      "epoch:25 step:23435 [D loss: 0.728780, acc.: 58.59%] [G loss: 1.066130]\n",
      "epoch:25 step:23436 [D loss: 0.470682, acc.: 81.25%] [G loss: 1.555444]\n",
      "epoch:25 step:23437 [D loss: 0.580487, acc.: 66.41%] [G loss: 1.319278]\n",
      "epoch:25 step:23438 [D loss: 0.487116, acc.: 75.78%] [G loss: 1.434214]\n",
      "epoch:25 step:23439 [D loss: 0.527211, acc.: 71.88%] [G loss: 1.614881]\n",
      "epoch:25 step:23440 [D loss: 0.628335, acc.: 63.28%] [G loss: 1.026694]\n",
      "epoch:25 step:23441 [D loss: 0.505333, acc.: 75.00%] [G loss: 1.983184]\n",
      "epoch:25 step:23442 [D loss: 0.651951, acc.: 64.84%] [G loss: 1.264297]\n",
      "epoch:25 step:23443 [D loss: 0.626259, acc.: 65.62%] [G loss: 1.234131]\n",
      "epoch:25 step:23444 [D loss: 0.751559, acc.: 52.34%] [G loss: 0.979371]\n",
      "epoch:25 step:23445 [D loss: 0.510198, acc.: 72.66%] [G loss: 1.253357]\n",
      "epoch:25 step:23446 [D loss: 0.426508, acc.: 81.25%] [G loss: 1.554230]\n",
      "epoch:25 step:23447 [D loss: 0.642786, acc.: 64.84%] [G loss: 1.172796]\n",
      "epoch:25 step:23448 [D loss: 0.479899, acc.: 78.12%] [G loss: 1.343581]\n",
      "epoch:25 step:23449 [D loss: 0.399392, acc.: 85.94%] [G loss: 2.025418]\n",
      "epoch:25 step:23450 [D loss: 0.556847, acc.: 71.88%] [G loss: 1.153694]\n",
      "epoch:25 step:23451 [D loss: 0.574669, acc.: 68.75%] [G loss: 1.477959]\n",
      "epoch:25 step:23452 [D loss: 0.450064, acc.: 82.03%] [G loss: 1.231910]\n",
      "epoch:25 step:23453 [D loss: 0.528376, acc.: 74.22%] [G loss: 1.580077]\n",
      "epoch:25 step:23454 [D loss: 0.498388, acc.: 78.12%] [G loss: 1.220323]\n",
      "epoch:25 step:23455 [D loss: 0.540820, acc.: 72.66%] [G loss: 1.419968]\n",
      "epoch:25 step:23456 [D loss: 0.533746, acc.: 74.22%] [G loss: 1.009149]\n",
      "epoch:25 step:23457 [D loss: 0.475825, acc.: 78.91%] [G loss: 1.461013]\n",
      "epoch:25 step:23458 [D loss: 0.538580, acc.: 69.53%] [G loss: 1.461189]\n",
      "epoch:25 step:23459 [D loss: 0.555756, acc.: 71.88%] [G loss: 1.613981]\n",
      "epoch:25 step:23460 [D loss: 0.599577, acc.: 63.28%] [G loss: 1.757230]\n",
      "epoch:25 step:23461 [D loss: 0.511237, acc.: 78.91%] [G loss: 1.721577]\n",
      "epoch:25 step:23462 [D loss: 0.552388, acc.: 75.78%] [G loss: 1.660276]\n",
      "epoch:25 step:23463 [D loss: 0.545490, acc.: 69.53%] [G loss: 1.664119]\n",
      "epoch:25 step:23464 [D loss: 0.623282, acc.: 67.19%] [G loss: 1.405825]\n",
      "epoch:25 step:23465 [D loss: 0.683248, acc.: 61.72%] [G loss: 1.365136]\n",
      "epoch:25 step:23466 [D loss: 0.419952, acc.: 83.59%] [G loss: 1.500967]\n",
      "epoch:25 step:23467 [D loss: 0.451057, acc.: 79.69%] [G loss: 1.385436]\n",
      "epoch:25 step:23468 [D loss: 0.664753, acc.: 60.16%] [G loss: 1.197738]\n",
      "epoch:25 step:23469 [D loss: 0.546325, acc.: 75.78%] [G loss: 1.030697]\n",
      "epoch:25 step:23470 [D loss: 0.530532, acc.: 75.78%] [G loss: 1.613779]\n",
      "epoch:25 step:23471 [D loss: 0.619435, acc.: 66.41%] [G loss: 1.384802]\n",
      "epoch:25 step:23472 [D loss: 0.598999, acc.: 67.97%] [G loss: 1.394903]\n",
      "epoch:25 step:23473 [D loss: 0.638801, acc.: 68.75%] [G loss: 1.071677]\n",
      "epoch:25 step:23474 [D loss: 0.610709, acc.: 69.53%] [G loss: 1.300706]\n",
      "epoch:25 step:23475 [D loss: 0.608832, acc.: 67.97%] [G loss: 1.404927]\n",
      "epoch:25 step:23476 [D loss: 0.486492, acc.: 77.34%] [G loss: 1.620130]\n",
      "epoch:25 step:23477 [D loss: 0.483317, acc.: 79.69%] [G loss: 1.498979]\n",
      "epoch:25 step:23478 [D loss: 0.664671, acc.: 60.94%] [G loss: 1.517753]\n",
      "epoch:25 step:23479 [D loss: 0.665740, acc.: 59.38%] [G loss: 1.305992]\n",
      "epoch:25 step:23480 [D loss: 0.539947, acc.: 70.31%] [G loss: 1.490657]\n",
      "epoch:25 step:23481 [D loss: 0.620910, acc.: 67.97%] [G loss: 1.504420]\n",
      "epoch:25 step:23482 [D loss: 0.463224, acc.: 78.12%] [G loss: 1.638769]\n",
      "epoch:25 step:23483 [D loss: 0.474127, acc.: 76.56%] [G loss: 1.542503]\n",
      "epoch:25 step:23484 [D loss: 0.459732, acc.: 82.03%] [G loss: 1.471576]\n",
      "epoch:25 step:23485 [D loss: 0.557278, acc.: 75.00%] [G loss: 1.516957]\n",
      "epoch:25 step:23486 [D loss: 0.550165, acc.: 71.09%] [G loss: 1.538276]\n",
      "epoch:25 step:23487 [D loss: 0.680716, acc.: 58.59%] [G loss: 1.435727]\n",
      "epoch:25 step:23488 [D loss: 0.658201, acc.: 56.25%] [G loss: 1.344228]\n",
      "epoch:25 step:23489 [D loss: 0.533412, acc.: 72.66%] [G loss: 1.492302]\n",
      "epoch:25 step:23490 [D loss: 0.612561, acc.: 70.31%] [G loss: 1.840985]\n",
      "epoch:25 step:23491 [D loss: 0.491588, acc.: 75.78%] [G loss: 1.572151]\n",
      "epoch:25 step:23492 [D loss: 0.562219, acc.: 76.56%] [G loss: 1.516152]\n",
      "epoch:25 step:23493 [D loss: 0.544596, acc.: 72.66%] [G loss: 1.425248]\n",
      "epoch:25 step:23494 [D loss: 0.453791, acc.: 78.91%] [G loss: 1.719797]\n",
      "epoch:25 step:23495 [D loss: 0.616620, acc.: 68.75%] [G loss: 1.357834]\n",
      "epoch:25 step:23496 [D loss: 0.489037, acc.: 76.56%] [G loss: 1.435295]\n",
      "epoch:25 step:23497 [D loss: 0.536617, acc.: 71.09%] [G loss: 1.721321]\n",
      "epoch:25 step:23498 [D loss: 0.534368, acc.: 68.75%] [G loss: 1.474854]\n",
      "epoch:25 step:23499 [D loss: 0.628394, acc.: 66.41%] [G loss: 1.559212]\n",
      "epoch:25 step:23500 [D loss: 0.456055, acc.: 81.25%] [G loss: 1.435049]\n",
      "epoch:25 step:23501 [D loss: 0.431930, acc.: 82.03%] [G loss: 1.746291]\n",
      "epoch:25 step:23502 [D loss: 0.584915, acc.: 67.19%] [G loss: 1.504551]\n",
      "epoch:25 step:23503 [D loss: 0.670503, acc.: 64.84%] [G loss: 1.299949]\n",
      "epoch:25 step:23504 [D loss: 0.712523, acc.: 60.94%] [G loss: 1.363297]\n",
      "epoch:25 step:23505 [D loss: 0.522297, acc.: 77.34%] [G loss: 1.280130]\n",
      "epoch:25 step:23506 [D loss: 0.561125, acc.: 71.88%] [G loss: 1.259086]\n",
      "epoch:25 step:23507 [D loss: 0.477366, acc.: 76.56%] [G loss: 1.557590]\n",
      "epoch:25 step:23508 [D loss: 0.672159, acc.: 57.81%] [G loss: 1.223737]\n",
      "epoch:25 step:23509 [D loss: 0.586007, acc.: 67.97%] [G loss: 1.127677]\n",
      "epoch:25 step:23510 [D loss: 0.411785, acc.: 82.81%] [G loss: 1.224040]\n",
      "epoch:25 step:23511 [D loss: 0.462970, acc.: 78.91%] [G loss: 1.431541]\n",
      "epoch:25 step:23512 [D loss: 0.578570, acc.: 71.09%] [G loss: 1.303712]\n",
      "epoch:25 step:23513 [D loss: 0.587642, acc.: 68.75%] [G loss: 1.097898]\n",
      "epoch:25 step:23514 [D loss: 0.517950, acc.: 76.56%] [G loss: 1.319044]\n",
      "epoch:25 step:23515 [D loss: 0.552799, acc.: 69.53%] [G loss: 1.328008]\n",
      "epoch:25 step:23516 [D loss: 0.602536, acc.: 69.53%] [G loss: 1.436484]\n",
      "epoch:25 step:23517 [D loss: 0.586474, acc.: 69.53%] [G loss: 1.862443]\n",
      "epoch:25 step:23518 [D loss: 0.823366, acc.: 51.56%] [G loss: 1.696571]\n",
      "epoch:25 step:23519 [D loss: 0.522200, acc.: 75.78%] [G loss: 1.443112]\n",
      "epoch:25 step:23520 [D loss: 0.592387, acc.: 67.97%] [G loss: 1.649127]\n",
      "epoch:25 step:23521 [D loss: 0.509594, acc.: 72.66%] [G loss: 1.373123]\n",
      "epoch:25 step:23522 [D loss: 0.576669, acc.: 68.75%] [G loss: 1.513833]\n",
      "epoch:25 step:23523 [D loss: 0.449642, acc.: 82.81%] [G loss: 1.527107]\n",
      "epoch:25 step:23524 [D loss: 0.557236, acc.: 73.44%] [G loss: 1.661321]\n",
      "epoch:25 step:23525 [D loss: 0.610329, acc.: 67.97%] [G loss: 0.903174]\n",
      "epoch:25 step:23526 [D loss: 0.647359, acc.: 62.50%] [G loss: 1.374558]\n",
      "epoch:25 step:23527 [D loss: 0.622278, acc.: 67.19%] [G loss: 1.287584]\n",
      "epoch:25 step:23528 [D loss: 0.445181, acc.: 85.16%] [G loss: 1.386473]\n",
      "epoch:25 step:23529 [D loss: 0.467613, acc.: 78.91%] [G loss: 1.277627]\n",
      "epoch:25 step:23530 [D loss: 0.500995, acc.: 75.78%] [G loss: 1.613455]\n",
      "epoch:25 step:23531 [D loss: 0.603053, acc.: 69.53%] [G loss: 1.301447]\n",
      "epoch:25 step:23532 [D loss: 0.538092, acc.: 71.09%] [G loss: 1.400523]\n",
      "epoch:25 step:23533 [D loss: 0.567914, acc.: 70.31%] [G loss: 1.431664]\n",
      "epoch:25 step:23534 [D loss: 0.424131, acc.: 82.03%] [G loss: 1.500634]\n",
      "epoch:25 step:23535 [D loss: 0.484821, acc.: 80.47%] [G loss: 1.648062]\n",
      "epoch:25 step:23536 [D loss: 0.477110, acc.: 77.34%] [G loss: 1.548563]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:25 step:23537 [D loss: 0.742014, acc.: 56.25%] [G loss: 0.961548]\n",
      "epoch:25 step:23538 [D loss: 0.388549, acc.: 86.72%] [G loss: 1.691687]\n",
      "epoch:25 step:23539 [D loss: 0.448502, acc.: 79.69%] [G loss: 1.657473]\n",
      "epoch:25 step:23540 [D loss: 0.417925, acc.: 82.81%] [G loss: 1.227539]\n",
      "epoch:25 step:23541 [D loss: 0.440647, acc.: 79.69%] [G loss: 1.759389]\n",
      "epoch:25 step:23542 [D loss: 0.458565, acc.: 79.69%] [G loss: 1.307467]\n",
      "epoch:25 step:23543 [D loss: 0.594369, acc.: 67.97%] [G loss: 1.238176]\n",
      "epoch:25 step:23544 [D loss: 0.474407, acc.: 78.91%] [G loss: 1.753263]\n",
      "epoch:25 step:23545 [D loss: 0.673915, acc.: 57.81%] [G loss: 0.925478]\n",
      "epoch:25 step:23546 [D loss: 0.452133, acc.: 78.12%] [G loss: 1.256045]\n",
      "epoch:25 step:23547 [D loss: 0.723204, acc.: 53.12%] [G loss: 1.024166]\n",
      "epoch:25 step:23548 [D loss: 0.351178, acc.: 90.62%] [G loss: 1.578936]\n",
      "epoch:25 step:23549 [D loss: 0.581432, acc.: 67.19%] [G loss: 1.215035]\n",
      "epoch:25 step:23550 [D loss: 0.651675, acc.: 69.53%] [G loss: 1.543741]\n",
      "epoch:25 step:23551 [D loss: 0.480605, acc.: 75.78%] [G loss: 1.275127]\n",
      "epoch:25 step:23552 [D loss: 0.520727, acc.: 78.12%] [G loss: 1.225534]\n",
      "epoch:25 step:23553 [D loss: 0.428968, acc.: 80.47%] [G loss: 1.478639]\n",
      "epoch:25 step:23554 [D loss: 0.430657, acc.: 82.03%] [G loss: 1.462082]\n",
      "epoch:25 step:23555 [D loss: 0.591256, acc.: 72.66%] [G loss: 1.560691]\n",
      "epoch:25 step:23556 [D loss: 0.520660, acc.: 73.44%] [G loss: 1.459213]\n",
      "epoch:25 step:23557 [D loss: 0.454209, acc.: 81.25%] [G loss: 1.239137]\n",
      "epoch:25 step:23558 [D loss: 0.498998, acc.: 72.66%] [G loss: 1.531433]\n",
      "epoch:25 step:23559 [D loss: 0.629289, acc.: 68.75%] [G loss: 1.074291]\n",
      "epoch:25 step:23560 [D loss: 0.479267, acc.: 77.34%] [G loss: 1.542746]\n",
      "epoch:25 step:23561 [D loss: 0.663501, acc.: 61.72%] [G loss: 1.076183]\n",
      "epoch:25 step:23562 [D loss: 0.398485, acc.: 85.94%] [G loss: 1.426967]\n",
      "epoch:25 step:23563 [D loss: 0.559005, acc.: 70.31%] [G loss: 1.429608]\n",
      "epoch:25 step:23564 [D loss: 0.519067, acc.: 73.44%] [G loss: 1.004920]\n",
      "epoch:25 step:23565 [D loss: 0.711481, acc.: 52.34%] [G loss: 1.423236]\n",
      "epoch:25 step:23566 [D loss: 0.661747, acc.: 61.72%] [G loss: 1.131257]\n",
      "epoch:25 step:23567 [D loss: 0.462750, acc.: 81.25%] [G loss: 1.213173]\n",
      "epoch:25 step:23568 [D loss: 0.479436, acc.: 78.91%] [G loss: 1.397193]\n",
      "epoch:25 step:23569 [D loss: 0.587802, acc.: 65.62%] [G loss: 1.225910]\n",
      "epoch:25 step:23570 [D loss: 0.614025, acc.: 70.31%] [G loss: 1.490430]\n",
      "epoch:25 step:23571 [D loss: 0.380996, acc.: 85.94%] [G loss: 1.332342]\n",
      "epoch:25 step:23572 [D loss: 0.522432, acc.: 74.22%] [G loss: 1.248813]\n",
      "epoch:25 step:23573 [D loss: 0.673547, acc.: 66.41%] [G loss: 1.453852]\n",
      "epoch:25 step:23574 [D loss: 0.547491, acc.: 74.22%] [G loss: 1.307368]\n",
      "epoch:25 step:23575 [D loss: 0.594437, acc.: 68.75%] [G loss: 1.359654]\n",
      "epoch:25 step:23576 [D loss: 0.731824, acc.: 54.69%] [G loss: 1.181974]\n",
      "epoch:25 step:23577 [D loss: 0.530632, acc.: 70.31%] [G loss: 1.404029]\n",
      "epoch:25 step:23578 [D loss: 0.417784, acc.: 82.81%] [G loss: 1.737979]\n",
      "epoch:25 step:23579 [D loss: 0.636089, acc.: 63.28%] [G loss: 1.553594]\n",
      "epoch:25 step:23580 [D loss: 0.522176, acc.: 72.66%] [G loss: 1.235228]\n",
      "epoch:25 step:23581 [D loss: 0.603202, acc.: 64.84%] [G loss: 1.526547]\n",
      "epoch:25 step:23582 [D loss: 0.647445, acc.: 62.50%] [G loss: 1.296355]\n",
      "epoch:25 step:23583 [D loss: 0.502152, acc.: 77.34%] [G loss: 1.186241]\n",
      "epoch:25 step:23584 [D loss: 0.531916, acc.: 76.56%] [G loss: 1.178479]\n",
      "epoch:25 step:23585 [D loss: 0.634644, acc.: 63.28%] [G loss: 1.272273]\n",
      "epoch:25 step:23586 [D loss: 0.516723, acc.: 73.44%] [G loss: 1.215885]\n",
      "epoch:25 step:23587 [D loss: 0.512971, acc.: 75.00%] [G loss: 1.415480]\n",
      "epoch:25 step:23588 [D loss: 0.576550, acc.: 69.53%] [G loss: 1.118385]\n",
      "epoch:25 step:23589 [D loss: 0.546964, acc.: 73.44%] [G loss: 1.485448]\n",
      "epoch:25 step:23590 [D loss: 0.451282, acc.: 82.03%] [G loss: 1.436373]\n",
      "epoch:25 step:23591 [D loss: 0.720864, acc.: 59.38%] [G loss: 1.260272]\n",
      "epoch:25 step:23592 [D loss: 0.522278, acc.: 77.34%] [G loss: 1.478576]\n",
      "epoch:25 step:23593 [D loss: 0.609444, acc.: 64.84%] [G loss: 1.548892]\n",
      "epoch:25 step:23594 [D loss: 0.460641, acc.: 78.12%] [G loss: 1.499017]\n",
      "epoch:25 step:23595 [D loss: 0.449071, acc.: 79.69%] [G loss: 1.481423]\n",
      "epoch:25 step:23596 [D loss: 0.681685, acc.: 60.94%] [G loss: 1.135069]\n",
      "epoch:25 step:23597 [D loss: 0.396345, acc.: 82.03%] [G loss: 1.365852]\n",
      "epoch:25 step:23598 [D loss: 0.631099, acc.: 60.94%] [G loss: 1.225275]\n",
      "epoch:25 step:23599 [D loss: 0.429760, acc.: 88.28%] [G loss: 1.062541]\n",
      "epoch:25 step:23600 [D loss: 0.457161, acc.: 78.91%] [G loss: 1.475068]\n",
      "epoch:25 step:23601 [D loss: 0.582906, acc.: 70.31%] [G loss: 1.238101]\n",
      "epoch:25 step:23602 [D loss: 0.547020, acc.: 73.44%] [G loss: 1.093844]\n",
      "epoch:25 step:23603 [D loss: 0.515333, acc.: 75.00%] [G loss: 1.177157]\n",
      "epoch:25 step:23604 [D loss: 0.463028, acc.: 78.12%] [G loss: 1.309574]\n",
      "epoch:25 step:23605 [D loss: 0.558456, acc.: 72.66%] [G loss: 1.302360]\n",
      "epoch:25 step:23606 [D loss: 0.633871, acc.: 66.41%] [G loss: 1.611234]\n",
      "epoch:25 step:23607 [D loss: 0.481978, acc.: 79.69%] [G loss: 1.237393]\n",
      "epoch:25 step:23608 [D loss: 0.673471, acc.: 63.28%] [G loss: 1.382075]\n",
      "epoch:25 step:23609 [D loss: 0.745016, acc.: 55.47%] [G loss: 1.413124]\n",
      "epoch:25 step:23610 [D loss: 0.461825, acc.: 83.59%] [G loss: 1.619700]\n",
      "epoch:25 step:23611 [D loss: 0.408376, acc.: 85.16%] [G loss: 1.207073]\n",
      "epoch:25 step:23612 [D loss: 0.412171, acc.: 82.03%] [G loss: 1.457650]\n",
      "epoch:25 step:23613 [D loss: 0.568555, acc.: 72.66%] [G loss: 1.223915]\n",
      "epoch:25 step:23614 [D loss: 0.788430, acc.: 52.34%] [G loss: 1.164769]\n",
      "epoch:25 step:23615 [D loss: 0.612022, acc.: 70.31%] [G loss: 1.255869]\n",
      "epoch:25 step:23616 [D loss: 0.609949, acc.: 66.41%] [G loss: 1.415107]\n",
      "epoch:25 step:23617 [D loss: 0.553820, acc.: 69.53%] [G loss: 1.754981]\n",
      "epoch:25 step:23618 [D loss: 0.694691, acc.: 62.50%] [G loss: 1.326944]\n",
      "epoch:25 step:23619 [D loss: 0.672564, acc.: 63.28%] [G loss: 1.428402]\n",
      "epoch:25 step:23620 [D loss: 0.528892, acc.: 73.44%] [G loss: 1.311920]\n",
      "epoch:25 step:23621 [D loss: 0.546198, acc.: 71.88%] [G loss: 1.165567]\n",
      "epoch:25 step:23622 [D loss: 0.536620, acc.: 69.53%] [G loss: 1.334460]\n",
      "epoch:25 step:23623 [D loss: 0.546684, acc.: 73.44%] [G loss: 1.209868]\n",
      "epoch:25 step:23624 [D loss: 0.511508, acc.: 75.00%] [G loss: 1.190834]\n",
      "epoch:25 step:23625 [D loss: 0.496570, acc.: 78.91%] [G loss: 1.550204]\n",
      "epoch:25 step:23626 [D loss: 0.460046, acc.: 79.69%] [G loss: 1.786062]\n",
      "epoch:25 step:23627 [D loss: 0.508616, acc.: 73.44%] [G loss: 1.772248]\n",
      "epoch:25 step:23628 [D loss: 0.647197, acc.: 66.41%] [G loss: 1.153180]\n",
      "epoch:25 step:23629 [D loss: 0.262940, acc.: 94.53%] [G loss: 1.623189]\n",
      "epoch:25 step:23630 [D loss: 0.685139, acc.: 58.59%] [G loss: 1.279379]\n",
      "epoch:25 step:23631 [D loss: 0.517903, acc.: 75.00%] [G loss: 1.130809]\n",
      "epoch:25 step:23632 [D loss: 0.517300, acc.: 75.00%] [G loss: 1.397007]\n",
      "epoch:25 step:23633 [D loss: 0.466208, acc.: 80.47%] [G loss: 1.358103]\n",
      "epoch:25 step:23634 [D loss: 0.568863, acc.: 66.41%] [G loss: 1.330092]\n",
      "epoch:25 step:23635 [D loss: 0.620434, acc.: 67.19%] [G loss: 1.046694]\n",
      "epoch:25 step:23636 [D loss: 0.368877, acc.: 85.94%] [G loss: 1.725478]\n",
      "epoch:25 step:23637 [D loss: 0.618176, acc.: 67.19%] [G loss: 1.283319]\n",
      "epoch:25 step:23638 [D loss: 0.553788, acc.: 72.66%] [G loss: 1.487576]\n",
      "epoch:25 step:23639 [D loss: 0.611044, acc.: 65.62%] [G loss: 1.614630]\n",
      "epoch:25 step:23640 [D loss: 0.619940, acc.: 64.06%] [G loss: 1.102244]\n",
      "epoch:25 step:23641 [D loss: 0.488323, acc.: 71.88%] [G loss: 1.236971]\n",
      "epoch:25 step:23642 [D loss: 0.417600, acc.: 84.38%] [G loss: 1.733059]\n",
      "epoch:25 step:23643 [D loss: 0.629910, acc.: 61.72%] [G loss: 1.208620]\n",
      "epoch:25 step:23644 [D loss: 0.445989, acc.: 82.03%] [G loss: 1.535584]\n",
      "epoch:25 step:23645 [D loss: 0.530241, acc.: 69.53%] [G loss: 1.369409]\n",
      "epoch:25 step:23646 [D loss: 0.717026, acc.: 60.94%] [G loss: 1.408751]\n",
      "epoch:25 step:23647 [D loss: 0.602654, acc.: 61.72%] [G loss: 1.259987]\n",
      "epoch:25 step:23648 [D loss: 0.535277, acc.: 75.00%] [G loss: 1.202957]\n",
      "epoch:25 step:23649 [D loss: 0.577537, acc.: 71.88%] [G loss: 1.107763]\n",
      "epoch:25 step:23650 [D loss: 0.605776, acc.: 67.19%] [G loss: 1.363642]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:25 step:23651 [D loss: 0.475891, acc.: 77.34%] [G loss: 1.207101]\n",
      "epoch:25 step:23652 [D loss: 0.695692, acc.: 59.38%] [G loss: 1.300538]\n",
      "epoch:25 step:23653 [D loss: 0.690699, acc.: 61.72%] [G loss: 1.184663]\n",
      "epoch:25 step:23654 [D loss: 0.482340, acc.: 78.91%] [G loss: 1.298606]\n",
      "epoch:25 step:23655 [D loss: 0.515718, acc.: 75.78%] [G loss: 1.524396]\n",
      "epoch:25 step:23656 [D loss: 0.527624, acc.: 73.44%] [G loss: 1.250721]\n",
      "epoch:25 step:23657 [D loss: 0.729110, acc.: 57.81%] [G loss: 1.140484]\n",
      "epoch:25 step:23658 [D loss: 0.744638, acc.: 56.25%] [G loss: 1.180594]\n",
      "epoch:25 step:23659 [D loss: 0.581224, acc.: 70.31%] [G loss: 1.311805]\n",
      "epoch:25 step:23660 [D loss: 0.679790, acc.: 61.72%] [G loss: 1.119235]\n",
      "epoch:25 step:23661 [D loss: 0.572443, acc.: 71.09%] [G loss: 1.482758]\n",
      "epoch:25 step:23662 [D loss: 0.780146, acc.: 50.78%] [G loss: 1.493309]\n",
      "epoch:25 step:23663 [D loss: 0.690865, acc.: 57.03%] [G loss: 1.315780]\n",
      "epoch:25 step:23664 [D loss: 0.561618, acc.: 72.66%] [G loss: 0.899010]\n",
      "epoch:25 step:23665 [D loss: 0.685470, acc.: 60.94%] [G loss: 1.350877]\n",
      "epoch:25 step:23666 [D loss: 0.573359, acc.: 66.41%] [G loss: 1.152603]\n",
      "epoch:25 step:23667 [D loss: 0.590522, acc.: 69.53%] [G loss: 1.477433]\n",
      "epoch:25 step:23668 [D loss: 0.530792, acc.: 73.44%] [G loss: 1.434306]\n",
      "epoch:25 step:23669 [D loss: 0.612024, acc.: 68.75%] [G loss: 1.574499]\n",
      "epoch:25 step:23670 [D loss: 0.501318, acc.: 76.56%] [G loss: 1.302517]\n",
      "epoch:25 step:23671 [D loss: 0.511274, acc.: 80.47%] [G loss: 1.171012]\n",
      "epoch:25 step:23672 [D loss: 0.658856, acc.: 64.06%] [G loss: 1.298206]\n",
      "epoch:25 step:23673 [D loss: 0.542110, acc.: 75.00%] [G loss: 1.214574]\n",
      "epoch:25 step:23674 [D loss: 0.420831, acc.: 86.72%] [G loss: 1.417711]\n",
      "epoch:25 step:23675 [D loss: 0.595291, acc.: 71.09%] [G loss: 1.222304]\n",
      "epoch:25 step:23676 [D loss: 0.537155, acc.: 79.69%] [G loss: 1.501128]\n",
      "epoch:25 step:23677 [D loss: 0.421203, acc.: 82.81%] [G loss: 1.481670]\n",
      "epoch:25 step:23678 [D loss: 0.477541, acc.: 81.25%] [G loss: 1.512280]\n",
      "epoch:25 step:23679 [D loss: 0.600335, acc.: 65.62%] [G loss: 1.446842]\n",
      "epoch:25 step:23680 [D loss: 0.513059, acc.: 74.22%] [G loss: 0.891364]\n",
      "epoch:25 step:23681 [D loss: 0.604706, acc.: 64.84%] [G loss: 1.491058]\n",
      "epoch:25 step:23682 [D loss: 0.477043, acc.: 75.00%] [G loss: 1.212908]\n",
      "epoch:25 step:23683 [D loss: 0.572337, acc.: 67.19%] [G loss: 1.829798]\n",
      "epoch:25 step:23684 [D loss: 0.587910, acc.: 64.84%] [G loss: 1.375708]\n",
      "epoch:25 step:23685 [D loss: 0.647601, acc.: 63.28%] [G loss: 1.259552]\n",
      "epoch:25 step:23686 [D loss: 0.648120, acc.: 60.16%] [G loss: 1.211914]\n",
      "epoch:25 step:23687 [D loss: 0.467832, acc.: 78.12%] [G loss: 1.271492]\n",
      "epoch:25 step:23688 [D loss: 0.594694, acc.: 64.06%] [G loss: 0.989479]\n",
      "epoch:25 step:23689 [D loss: 0.423354, acc.: 84.38%] [G loss: 1.302480]\n",
      "epoch:25 step:23690 [D loss: 0.333495, acc.: 87.50%] [G loss: 1.592573]\n",
      "epoch:25 step:23691 [D loss: 0.375653, acc.: 84.38%] [G loss: 1.809173]\n",
      "epoch:25 step:23692 [D loss: 0.619462, acc.: 64.84%] [G loss: 1.580190]\n",
      "epoch:25 step:23693 [D loss: 0.547142, acc.: 67.19%] [G loss: 1.508642]\n",
      "epoch:25 step:23694 [D loss: 0.456930, acc.: 75.78%] [G loss: 1.429834]\n",
      "epoch:25 step:23695 [D loss: 0.521826, acc.: 73.44%] [G loss: 1.423250]\n",
      "epoch:25 step:23696 [D loss: 0.429331, acc.: 83.59%] [G loss: 1.539681]\n",
      "epoch:25 step:23697 [D loss: 0.710310, acc.: 60.94%] [G loss: 1.579274]\n",
      "epoch:25 step:23698 [D loss: 0.773994, acc.: 57.81%] [G loss: 1.554762]\n",
      "epoch:25 step:23699 [D loss: 0.647459, acc.: 62.50%] [G loss: 1.168279]\n",
      "epoch:25 step:23700 [D loss: 0.456203, acc.: 78.91%] [G loss: 1.106142]\n",
      "epoch:25 step:23701 [D loss: 0.701268, acc.: 62.50%] [G loss: 1.320726]\n",
      "epoch:25 step:23702 [D loss: 0.569983, acc.: 68.75%] [G loss: 1.213767]\n",
      "epoch:25 step:23703 [D loss: 0.573723, acc.: 69.53%] [G loss: 1.106877]\n",
      "epoch:25 step:23704 [D loss: 0.636939, acc.: 70.31%] [G loss: 1.195364]\n",
      "epoch:25 step:23705 [D loss: 0.637931, acc.: 63.28%] [G loss: 1.344558]\n",
      "epoch:25 step:23706 [D loss: 0.436815, acc.: 82.03%] [G loss: 1.565438]\n",
      "epoch:25 step:23707 [D loss: 0.503448, acc.: 74.22%] [G loss: 1.595619]\n",
      "epoch:25 step:23708 [D loss: 0.621770, acc.: 68.75%] [G loss: 1.335668]\n",
      "epoch:25 step:23709 [D loss: 0.469362, acc.: 82.03%] [G loss: 1.549665]\n",
      "epoch:25 step:23710 [D loss: 0.504463, acc.: 77.34%] [G loss: 1.332244]\n",
      "epoch:25 step:23711 [D loss: 0.512711, acc.: 75.78%] [G loss: 1.635850]\n",
      "epoch:25 step:23712 [D loss: 0.592014, acc.: 69.53%] [G loss: 1.399881]\n",
      "epoch:25 step:23713 [D loss: 0.688354, acc.: 61.72%] [G loss: 1.508122]\n",
      "epoch:25 step:23714 [D loss: 0.482630, acc.: 80.47%] [G loss: 1.554684]\n",
      "epoch:25 step:23715 [D loss: 0.440183, acc.: 77.34%] [G loss: 1.175147]\n",
      "epoch:25 step:23716 [D loss: 0.799445, acc.: 47.66%] [G loss: 1.518758]\n",
      "epoch:25 step:23717 [D loss: 0.499110, acc.: 75.00%] [G loss: 1.088891]\n",
      "epoch:25 step:23718 [D loss: 0.537905, acc.: 70.31%] [G loss: 1.678781]\n",
      "epoch:25 step:23719 [D loss: 0.430470, acc.: 82.03%] [G loss: 1.320858]\n",
      "epoch:25 step:23720 [D loss: 0.700563, acc.: 66.41%] [G loss: 1.396578]\n",
      "epoch:25 step:23721 [D loss: 0.419146, acc.: 82.03%] [G loss: 1.226227]\n",
      "epoch:25 step:23722 [D loss: 0.457652, acc.: 80.47%] [G loss: 1.333862]\n",
      "epoch:25 step:23723 [D loss: 0.591617, acc.: 68.75%] [G loss: 1.003561]\n",
      "epoch:25 step:23724 [D loss: 0.572927, acc.: 75.78%] [G loss: 1.175395]\n",
      "epoch:25 step:23725 [D loss: 0.549591, acc.: 74.22%] [G loss: 1.459030]\n",
      "epoch:25 step:23726 [D loss: 0.471758, acc.: 82.03%] [G loss: 1.606018]\n",
      "epoch:25 step:23727 [D loss: 0.535752, acc.: 74.22%] [G loss: 1.561049]\n",
      "epoch:25 step:23728 [D loss: 0.524086, acc.: 72.66%] [G loss: 1.220664]\n",
      "epoch:25 step:23729 [D loss: 0.602433, acc.: 69.53%] [G loss: 1.326352]\n",
      "epoch:25 step:23730 [D loss: 0.453891, acc.: 78.91%] [G loss: 1.228456]\n",
      "epoch:25 step:23731 [D loss: 0.525828, acc.: 71.88%] [G loss: 1.228251]\n",
      "epoch:25 step:23732 [D loss: 0.503883, acc.: 72.66%] [G loss: 1.398133]\n",
      "epoch:25 step:23733 [D loss: 0.482136, acc.: 81.25%] [G loss: 1.164442]\n",
      "epoch:25 step:23734 [D loss: 0.680560, acc.: 59.38%] [G loss: 1.009012]\n",
      "epoch:25 step:23735 [D loss: 0.567861, acc.: 75.00%] [G loss: 1.483466]\n",
      "epoch:25 step:23736 [D loss: 0.541588, acc.: 77.34%] [G loss: 1.355177]\n",
      "epoch:25 step:23737 [D loss: 0.676156, acc.: 56.25%] [G loss: 1.185017]\n",
      "epoch:25 step:23738 [D loss: 0.523178, acc.: 73.44%] [G loss: 1.524620]\n",
      "epoch:25 step:23739 [D loss: 0.457224, acc.: 82.81%] [G loss: 1.249043]\n",
      "epoch:25 step:23740 [D loss: 0.578081, acc.: 67.97%] [G loss: 1.307918]\n",
      "epoch:25 step:23741 [D loss: 0.480545, acc.: 80.47%] [G loss: 1.604327]\n",
      "epoch:25 step:23742 [D loss: 0.597983, acc.: 67.19%] [G loss: 1.348803]\n",
      "epoch:25 step:23743 [D loss: 0.623590, acc.: 65.62%] [G loss: 1.304553]\n",
      "epoch:25 step:23744 [D loss: 0.586363, acc.: 67.97%] [G loss: 1.112550]\n",
      "epoch:25 step:23745 [D loss: 0.569645, acc.: 71.09%] [G loss: 1.233059]\n",
      "epoch:25 step:23746 [D loss: 0.651669, acc.: 62.50%] [G loss: 1.336833]\n",
      "epoch:25 step:23747 [D loss: 0.646049, acc.: 66.41%] [G loss: 1.257048]\n",
      "epoch:25 step:23748 [D loss: 0.495962, acc.: 78.12%] [G loss: 1.333376]\n",
      "epoch:25 step:23749 [D loss: 0.527655, acc.: 71.88%] [G loss: 1.635848]\n",
      "epoch:25 step:23750 [D loss: 0.556549, acc.: 73.44%] [G loss: 1.271856]\n",
      "epoch:25 step:23751 [D loss: 0.468736, acc.: 78.12%] [G loss: 1.630167]\n",
      "epoch:25 step:23752 [D loss: 0.453867, acc.: 82.81%] [G loss: 2.268295]\n",
      "epoch:25 step:23753 [D loss: 0.475387, acc.: 78.12%] [G loss: 1.506509]\n",
      "epoch:25 step:23754 [D loss: 0.575538, acc.: 72.66%] [G loss: 1.300985]\n",
      "epoch:25 step:23755 [D loss: 0.491376, acc.: 75.78%] [G loss: 1.752537]\n",
      "epoch:25 step:23756 [D loss: 0.470015, acc.: 80.47%] [G loss: 1.360600]\n",
      "epoch:25 step:23757 [D loss: 0.491597, acc.: 77.34%] [G loss: 1.025071]\n",
      "epoch:25 step:23758 [D loss: 0.603304, acc.: 71.09%] [G loss: 1.196342]\n",
      "epoch:25 step:23759 [D loss: 0.392287, acc.: 85.94%] [G loss: 1.693140]\n",
      "epoch:25 step:23760 [D loss: 0.420636, acc.: 84.38%] [G loss: 1.389889]\n",
      "epoch:25 step:23761 [D loss: 0.343247, acc.: 87.50%] [G loss: 1.088732]\n",
      "epoch:25 step:23762 [D loss: 0.478879, acc.: 81.25%] [G loss: 1.396580]\n",
      "epoch:25 step:23763 [D loss: 0.592940, acc.: 75.00%] [G loss: 1.046824]\n",
      "epoch:25 step:23764 [D loss: 0.565001, acc.: 67.19%] [G loss: 1.189959]\n",
      "epoch:25 step:23765 [D loss: 0.477223, acc.: 76.56%] [G loss: 1.891701]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:25 step:23766 [D loss: 0.613194, acc.: 65.62%] [G loss: 1.580937]\n",
      "epoch:25 step:23767 [D loss: 0.517037, acc.: 76.56%] [G loss: 1.574707]\n",
      "epoch:25 step:23768 [D loss: 0.532921, acc.: 75.00%] [G loss: 1.535004]\n",
      "epoch:25 step:23769 [D loss: 0.505441, acc.: 78.12%] [G loss: 1.438367]\n",
      "epoch:25 step:23770 [D loss: 0.501939, acc.: 75.78%] [G loss: 1.298429]\n",
      "epoch:25 step:23771 [D loss: 0.631737, acc.: 64.84%] [G loss: 1.247154]\n",
      "epoch:25 step:23772 [D loss: 0.595934, acc.: 67.97%] [G loss: 1.219620]\n",
      "epoch:25 step:23773 [D loss: 0.731693, acc.: 53.91%] [G loss: 1.238724]\n",
      "epoch:25 step:23774 [D loss: 0.488852, acc.: 75.00%] [G loss: 1.326680]\n",
      "epoch:25 step:23775 [D loss: 0.581319, acc.: 71.88%] [G loss: 1.450540]\n",
      "epoch:25 step:23776 [D loss: 0.692470, acc.: 60.94%] [G loss: 1.088318]\n",
      "epoch:25 step:23777 [D loss: 0.518006, acc.: 73.44%] [G loss: 1.510412]\n",
      "epoch:25 step:23778 [D loss: 0.632421, acc.: 64.84%] [G loss: 1.370125]\n",
      "epoch:25 step:23779 [D loss: 0.553610, acc.: 75.78%] [G loss: 1.537079]\n",
      "epoch:25 step:23780 [D loss: 0.513385, acc.: 74.22%] [G loss: 1.463032]\n",
      "epoch:25 step:23781 [D loss: 0.643723, acc.: 64.84%] [G loss: 1.165889]\n",
      "epoch:25 step:23782 [D loss: 0.449237, acc.: 79.69%] [G loss: 1.667502]\n",
      "epoch:25 step:23783 [D loss: 0.661328, acc.: 63.28%] [G loss: 1.093520]\n",
      "epoch:25 step:23784 [D loss: 0.458527, acc.: 78.91%] [G loss: 1.558987]\n",
      "epoch:25 step:23785 [D loss: 0.457943, acc.: 82.81%] [G loss: 1.177165]\n",
      "epoch:25 step:23786 [D loss: 0.453237, acc.: 79.69%] [G loss: 1.303186]\n",
      "epoch:25 step:23787 [D loss: 0.405296, acc.: 85.94%] [G loss: 1.610757]\n",
      "epoch:25 step:23788 [D loss: 0.438962, acc.: 81.25%] [G loss: 1.023710]\n",
      "epoch:25 step:23789 [D loss: 0.471246, acc.: 78.91%] [G loss: 1.185292]\n",
      "epoch:25 step:23790 [D loss: 0.438300, acc.: 83.59%] [G loss: 1.329565]\n",
      "epoch:25 step:23791 [D loss: 0.469523, acc.: 80.47%] [G loss: 1.396264]\n",
      "epoch:25 step:23792 [D loss: 0.475784, acc.: 78.91%] [G loss: 1.236765]\n",
      "epoch:25 step:23793 [D loss: 0.498532, acc.: 73.44%] [G loss: 1.658889]\n",
      "epoch:25 step:23794 [D loss: 0.491473, acc.: 76.56%] [G loss: 1.174989]\n",
      "epoch:25 step:23795 [D loss: 0.578198, acc.: 71.88%] [G loss: 1.393517]\n",
      "epoch:25 step:23796 [D loss: 0.473214, acc.: 78.12%] [G loss: 1.517435]\n",
      "epoch:25 step:23797 [D loss: 0.561479, acc.: 68.75%] [G loss: 1.493222]\n",
      "epoch:25 step:23798 [D loss: 0.527270, acc.: 74.22%] [G loss: 1.368458]\n",
      "epoch:25 step:23799 [D loss: 0.691702, acc.: 56.25%] [G loss: 1.407885]\n",
      "epoch:25 step:23800 [D loss: 0.608696, acc.: 66.41%] [G loss: 0.918206]\n",
      "epoch:25 step:23801 [D loss: 0.670197, acc.: 66.41%] [G loss: 0.967624]\n",
      "epoch:25 step:23802 [D loss: 0.432337, acc.: 81.25%] [G loss: 1.591391]\n",
      "epoch:25 step:23803 [D loss: 0.582104, acc.: 67.19%] [G loss: 1.096614]\n",
      "epoch:25 step:23804 [D loss: 0.485345, acc.: 78.91%] [G loss: 1.523024]\n",
      "epoch:25 step:23805 [D loss: 0.547257, acc.: 72.66%] [G loss: 1.288258]\n",
      "epoch:25 step:23806 [D loss: 0.610925, acc.: 63.28%] [G loss: 1.479726]\n",
      "epoch:25 step:23807 [D loss: 0.460194, acc.: 77.34%] [G loss: 1.640410]\n",
      "epoch:25 step:23808 [D loss: 0.484008, acc.: 75.00%] [G loss: 1.451790]\n",
      "epoch:25 step:23809 [D loss: 0.564954, acc.: 70.31%] [G loss: 1.121445]\n",
      "epoch:25 step:23810 [D loss: 0.690026, acc.: 59.38%] [G loss: 1.303183]\n",
      "epoch:25 step:23811 [D loss: 0.449758, acc.: 79.69%] [G loss: 1.274957]\n",
      "epoch:25 step:23812 [D loss: 0.602939, acc.: 69.53%] [G loss: 1.270757]\n",
      "epoch:25 step:23813 [D loss: 0.735540, acc.: 57.03%] [G loss: 1.418851]\n",
      "epoch:25 step:23814 [D loss: 0.498479, acc.: 77.34%] [G loss: 1.360292]\n",
      "epoch:25 step:23815 [D loss: 0.645524, acc.: 65.62%] [G loss: 1.748437]\n",
      "epoch:25 step:23816 [D loss: 0.754079, acc.: 53.12%] [G loss: 1.452865]\n",
      "epoch:25 step:23817 [D loss: 0.539901, acc.: 76.56%] [G loss: 1.426245]\n",
      "epoch:25 step:23818 [D loss: 0.585168, acc.: 72.66%] [G loss: 1.107813]\n",
      "epoch:25 step:23819 [D loss: 0.561307, acc.: 70.31%] [G loss: 1.231709]\n",
      "epoch:25 step:23820 [D loss: 0.366531, acc.: 89.84%] [G loss: 1.995003]\n",
      "epoch:25 step:23821 [D loss: 0.493850, acc.: 81.25%] [G loss: 1.457059]\n",
      "epoch:25 step:23822 [D loss: 0.582918, acc.: 65.62%] [G loss: 1.235789]\n",
      "epoch:25 step:23823 [D loss: 0.571899, acc.: 64.84%] [G loss: 1.306170]\n",
      "epoch:25 step:23824 [D loss: 0.491227, acc.: 76.56%] [G loss: 1.279340]\n",
      "epoch:25 step:23825 [D loss: 0.609022, acc.: 68.75%] [G loss: 1.344676]\n",
      "epoch:25 step:23826 [D loss: 0.785016, acc.: 49.22%] [G loss: 1.348972]\n",
      "epoch:25 step:23827 [D loss: 0.470612, acc.: 78.12%] [G loss: 1.526776]\n",
      "epoch:25 step:23828 [D loss: 0.551251, acc.: 70.31%] [G loss: 1.076489]\n",
      "epoch:25 step:23829 [D loss: 0.580724, acc.: 67.97%] [G loss: 1.641887]\n",
      "epoch:25 step:23830 [D loss: 0.534136, acc.: 76.56%] [G loss: 1.913359]\n",
      "epoch:25 step:23831 [D loss: 0.515404, acc.: 74.22%] [G loss: 1.264042]\n",
      "epoch:25 step:23832 [D loss: 0.747692, acc.: 55.47%] [G loss: 1.440568]\n",
      "epoch:25 step:23833 [D loss: 0.420993, acc.: 87.50%] [G loss: 1.578703]\n",
      "epoch:25 step:23834 [D loss: 0.494737, acc.: 76.56%] [G loss: 1.418965]\n",
      "epoch:25 step:23835 [D loss: 0.534271, acc.: 73.44%] [G loss: 1.834444]\n",
      "epoch:25 step:23836 [D loss: 0.587479, acc.: 71.88%] [G loss: 1.387445]\n",
      "epoch:25 step:23837 [D loss: 0.811009, acc.: 47.66%] [G loss: 1.196281]\n",
      "epoch:25 step:23838 [D loss: 0.540254, acc.: 73.44%] [G loss: 1.741554]\n",
      "epoch:25 step:23839 [D loss: 0.450116, acc.: 84.38%] [G loss: 1.663581]\n",
      "epoch:25 step:23840 [D loss: 0.470028, acc.: 75.78%] [G loss: 1.259630]\n",
      "epoch:25 step:23841 [D loss: 0.692798, acc.: 63.28%] [G loss: 1.086521]\n",
      "epoch:25 step:23842 [D loss: 0.544778, acc.: 78.12%] [G loss: 1.395911]\n",
      "epoch:25 step:23843 [D loss: 0.625561, acc.: 62.50%] [G loss: 1.355021]\n",
      "epoch:25 step:23844 [D loss: 0.509939, acc.: 74.22%] [G loss: 1.723206]\n",
      "epoch:25 step:23845 [D loss: 0.582950, acc.: 67.19%] [G loss: 1.535005]\n",
      "epoch:25 step:23846 [D loss: 0.603840, acc.: 64.84%] [G loss: 1.326463]\n",
      "epoch:25 step:23847 [D loss: 0.722263, acc.: 59.38%] [G loss: 1.384851]\n",
      "epoch:25 step:23848 [D loss: 0.499244, acc.: 78.12%] [G loss: 1.413933]\n",
      "epoch:25 step:23849 [D loss: 0.555140, acc.: 67.97%] [G loss: 1.733692]\n",
      "epoch:25 step:23850 [D loss: 0.595173, acc.: 68.75%] [G loss: 1.224562]\n",
      "epoch:25 step:23851 [D loss: 0.566803, acc.: 71.09%] [G loss: 1.023901]\n",
      "epoch:25 step:23852 [D loss: 0.612575, acc.: 64.84%] [G loss: 1.270608]\n",
      "epoch:25 step:23853 [D loss: 0.708166, acc.: 55.47%] [G loss: 1.247994]\n",
      "epoch:25 step:23854 [D loss: 0.658310, acc.: 63.28%] [G loss: 0.896468]\n",
      "epoch:25 step:23855 [D loss: 0.527798, acc.: 73.44%] [G loss: 1.426240]\n",
      "epoch:25 step:23856 [D loss: 0.627179, acc.: 64.84%] [G loss: 1.283810]\n",
      "epoch:25 step:23857 [D loss: 0.405867, acc.: 85.16%] [G loss: 1.485114]\n",
      "epoch:25 step:23858 [D loss: 0.683066, acc.: 54.69%] [G loss: 1.319291]\n",
      "epoch:25 step:23859 [D loss: 0.543686, acc.: 73.44%] [G loss: 1.510146]\n",
      "epoch:25 step:23860 [D loss: 0.631473, acc.: 65.62%] [G loss: 1.414942]\n",
      "epoch:25 step:23861 [D loss: 0.403558, acc.: 82.81%] [G loss: 1.054106]\n",
      "epoch:25 step:23862 [D loss: 0.579684, acc.: 68.75%] [G loss: 1.380001]\n",
      "epoch:25 step:23863 [D loss: 0.583530, acc.: 73.44%] [G loss: 1.235040]\n",
      "epoch:25 step:23864 [D loss: 0.400152, acc.: 82.81%] [G loss: 1.675297]\n",
      "epoch:25 step:23865 [D loss: 0.359838, acc.: 89.06%] [G loss: 1.356473]\n",
      "epoch:25 step:23866 [D loss: 0.636421, acc.: 66.41%] [G loss: 1.578529]\n",
      "epoch:25 step:23867 [D loss: 0.461526, acc.: 82.81%] [G loss: 1.339751]\n",
      "epoch:25 step:23868 [D loss: 0.484031, acc.: 77.34%] [G loss: 1.405611]\n",
      "epoch:25 step:23869 [D loss: 0.704349, acc.: 67.19%] [G loss: 1.193353]\n",
      "epoch:25 step:23870 [D loss: 0.625961, acc.: 64.84%] [G loss: 1.506735]\n",
      "epoch:25 step:23871 [D loss: 0.781224, acc.: 57.03%] [G loss: 1.320723]\n",
      "epoch:25 step:23872 [D loss: 0.599011, acc.: 64.84%] [G loss: 1.536106]\n",
      "epoch:25 step:23873 [D loss: 0.550195, acc.: 72.66%] [G loss: 1.455528]\n",
      "epoch:25 step:23874 [D loss: 0.539170, acc.: 73.44%] [G loss: 1.568224]\n",
      "epoch:25 step:23875 [D loss: 0.672556, acc.: 60.16%] [G loss: 1.653135]\n",
      "epoch:25 step:23876 [D loss: 0.498948, acc.: 75.78%] [G loss: 1.352763]\n",
      "epoch:25 step:23877 [D loss: 0.529017, acc.: 73.44%] [G loss: 1.103538]\n",
      "epoch:25 step:23878 [D loss: 0.472638, acc.: 77.34%] [G loss: 1.536352]\n",
      "epoch:25 step:23879 [D loss: 0.496255, acc.: 76.56%] [G loss: 1.666459]\n",
      "epoch:25 step:23880 [D loss: 0.506454, acc.: 74.22%] [G loss: 1.175401]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:25 step:23881 [D loss: 0.519928, acc.: 78.91%] [G loss: 1.238055]\n",
      "epoch:25 step:23882 [D loss: 0.619027, acc.: 67.97%] [G loss: 1.412179]\n",
      "epoch:25 step:23883 [D loss: 0.422084, acc.: 81.25%] [G loss: 1.079809]\n",
      "epoch:25 step:23884 [D loss: 0.349355, acc.: 90.62%] [G loss: 1.731647]\n",
      "epoch:25 step:23885 [D loss: 0.613310, acc.: 72.66%] [G loss: 1.295498]\n",
      "epoch:25 step:23886 [D loss: 0.562342, acc.: 75.00%] [G loss: 1.434467]\n",
      "epoch:25 step:23887 [D loss: 0.641105, acc.: 65.62%] [G loss: 1.020660]\n",
      "epoch:25 step:23888 [D loss: 0.501126, acc.: 78.12%] [G loss: 1.509970]\n",
      "epoch:25 step:23889 [D loss: 0.589656, acc.: 69.53%] [G loss: 1.269720]\n",
      "epoch:25 step:23890 [D loss: 0.686391, acc.: 61.72%] [G loss: 1.004191]\n",
      "epoch:25 step:23891 [D loss: 0.456723, acc.: 78.91%] [G loss: 1.249944]\n",
      "epoch:25 step:23892 [D loss: 0.548858, acc.: 72.66%] [G loss: 1.374038]\n",
      "epoch:25 step:23893 [D loss: 0.681111, acc.: 60.94%] [G loss: 1.209834]\n",
      "epoch:25 step:23894 [D loss: 0.483686, acc.: 80.47%] [G loss: 1.492281]\n",
      "epoch:25 step:23895 [D loss: 0.753316, acc.: 58.59%] [G loss: 1.282514]\n",
      "epoch:25 step:23896 [D loss: 0.417072, acc.: 87.50%] [G loss: 1.451427]\n",
      "epoch:25 step:23897 [D loss: 0.543545, acc.: 73.44%] [G loss: 1.395099]\n",
      "epoch:25 step:23898 [D loss: 0.655054, acc.: 67.97%] [G loss: 1.184115]\n",
      "epoch:25 step:23899 [D loss: 0.551569, acc.: 73.44%] [G loss: 1.693848]\n",
      "epoch:25 step:23900 [D loss: 0.436691, acc.: 82.81%] [G loss: 1.283653]\n",
      "epoch:25 step:23901 [D loss: 0.634737, acc.: 62.50%] [G loss: 1.492954]\n",
      "epoch:25 step:23902 [D loss: 0.482066, acc.: 80.47%] [G loss: 1.942163]\n",
      "epoch:25 step:23903 [D loss: 0.500118, acc.: 75.00%] [G loss: 1.613498]\n",
      "epoch:25 step:23904 [D loss: 0.598596, acc.: 61.72%] [G loss: 1.311976]\n",
      "epoch:25 step:23905 [D loss: 0.532068, acc.: 72.66%] [G loss: 1.699342]\n",
      "epoch:25 step:23906 [D loss: 0.634940, acc.: 65.62%] [G loss: 0.993227]\n",
      "epoch:25 step:23907 [D loss: 0.649976, acc.: 57.03%] [G loss: 1.196469]\n",
      "epoch:25 step:23908 [D loss: 0.668423, acc.: 64.06%] [G loss: 1.242334]\n",
      "epoch:25 step:23909 [D loss: 0.596405, acc.: 67.97%] [G loss: 1.540386]\n",
      "epoch:25 step:23910 [D loss: 0.536992, acc.: 71.09%] [G loss: 1.478004]\n",
      "epoch:25 step:23911 [D loss: 0.512353, acc.: 75.78%] [G loss: 1.527120]\n",
      "epoch:25 step:23912 [D loss: 0.524506, acc.: 72.66%] [G loss: 1.136332]\n",
      "epoch:25 step:23913 [D loss: 0.487954, acc.: 75.00%] [G loss: 1.643417]\n",
      "epoch:25 step:23914 [D loss: 0.570302, acc.: 68.75%] [G loss: 1.671863]\n",
      "epoch:25 step:23915 [D loss: 0.575814, acc.: 75.00%] [G loss: 1.118339]\n",
      "epoch:25 step:23916 [D loss: 0.744116, acc.: 54.69%] [G loss: 1.178490]\n",
      "epoch:25 step:23917 [D loss: 0.539261, acc.: 78.12%] [G loss: 1.194503]\n",
      "epoch:25 step:23918 [D loss: 0.611731, acc.: 68.75%] [G loss: 1.415591]\n",
      "epoch:25 step:23919 [D loss: 0.464293, acc.: 81.25%] [G loss: 1.274635]\n",
      "epoch:25 step:23920 [D loss: 0.594510, acc.: 67.19%] [G loss: 1.357937]\n",
      "epoch:25 step:23921 [D loss: 0.641611, acc.: 65.62%] [G loss: 1.482623]\n",
      "epoch:25 step:23922 [D loss: 0.503249, acc.: 78.12%] [G loss: 1.474172]\n",
      "epoch:25 step:23923 [D loss: 0.463522, acc.: 79.69%] [G loss: 1.174400]\n",
      "epoch:25 step:23924 [D loss: 0.469906, acc.: 76.56%] [G loss: 1.500125]\n",
      "epoch:25 step:23925 [D loss: 0.558844, acc.: 69.53%] [G loss: 1.326609]\n",
      "epoch:25 step:23926 [D loss: 0.531019, acc.: 71.09%] [G loss: 1.710157]\n",
      "epoch:25 step:23927 [D loss: 0.630579, acc.: 64.84%] [G loss: 1.329439]\n",
      "epoch:25 step:23928 [D loss: 0.630734, acc.: 64.84%] [G loss: 1.321967]\n",
      "epoch:25 step:23929 [D loss: 0.540257, acc.: 73.44%] [G loss: 1.595895]\n",
      "epoch:25 step:23930 [D loss: 0.527214, acc.: 73.44%] [G loss: 1.522028]\n",
      "epoch:25 step:23931 [D loss: 0.541094, acc.: 75.00%] [G loss: 1.429097]\n",
      "epoch:25 step:23932 [D loss: 0.621087, acc.: 60.16%] [G loss: 1.231329]\n",
      "epoch:25 step:23933 [D loss: 0.645635, acc.: 60.94%] [G loss: 1.527860]\n",
      "epoch:25 step:23934 [D loss: 0.540106, acc.: 70.31%] [G loss: 1.707898]\n",
      "epoch:25 step:23935 [D loss: 0.601163, acc.: 64.06%] [G loss: 1.870466]\n",
      "epoch:25 step:23936 [D loss: 0.470953, acc.: 72.66%] [G loss: 1.614254]\n",
      "epoch:25 step:23937 [D loss: 0.385731, acc.: 84.38%] [G loss: 1.897854]\n",
      "epoch:25 step:23938 [D loss: 0.558857, acc.: 71.09%] [G loss: 1.374030]\n",
      "epoch:25 step:23939 [D loss: 0.581287, acc.: 72.66%] [G loss: 1.122375]\n",
      "epoch:25 step:23940 [D loss: 0.441760, acc.: 82.81%] [G loss: 1.467364]\n",
      "epoch:25 step:23941 [D loss: 0.649800, acc.: 61.72%] [G loss: 1.514339]\n",
      "epoch:25 step:23942 [D loss: 0.456175, acc.: 78.91%] [G loss: 1.936800]\n",
      "epoch:25 step:23943 [D loss: 0.539225, acc.: 74.22%] [G loss: 1.555352]\n",
      "epoch:25 step:23944 [D loss: 0.446640, acc.: 78.91%] [G loss: 1.623437]\n",
      "epoch:25 step:23945 [D loss: 0.696034, acc.: 59.38%] [G loss: 1.360155]\n",
      "epoch:25 step:23946 [D loss: 0.575489, acc.: 64.84%] [G loss: 1.752117]\n",
      "epoch:25 step:23947 [D loss: 0.543645, acc.: 71.09%] [G loss: 1.373366]\n",
      "epoch:25 step:23948 [D loss: 0.523178, acc.: 76.56%] [G loss: 1.540563]\n",
      "epoch:25 step:23949 [D loss: 0.755819, acc.: 50.78%] [G loss: 0.780752]\n",
      "epoch:25 step:23950 [D loss: 0.694395, acc.: 57.81%] [G loss: 1.499481]\n",
      "epoch:25 step:23951 [D loss: 0.416959, acc.: 84.38%] [G loss: 1.607339]\n",
      "epoch:25 step:23952 [D loss: 0.667158, acc.: 63.28%] [G loss: 0.959310]\n",
      "epoch:25 step:23953 [D loss: 0.957415, acc.: 32.81%] [G loss: 1.024882]\n",
      "epoch:25 step:23954 [D loss: 0.440772, acc.: 83.59%] [G loss: 1.432944]\n",
      "epoch:25 step:23955 [D loss: 0.637697, acc.: 63.28%] [G loss: 1.859736]\n",
      "epoch:25 step:23956 [D loss: 0.569494, acc.: 73.44%] [G loss: 1.305544]\n",
      "epoch:25 step:23957 [D loss: 0.670210, acc.: 64.06%] [G loss: 1.255378]\n",
      "epoch:25 step:23958 [D loss: 0.673862, acc.: 63.28%] [G loss: 1.063955]\n",
      "epoch:25 step:23959 [D loss: 0.675283, acc.: 60.94%] [G loss: 1.474719]\n",
      "epoch:25 step:23960 [D loss: 0.552506, acc.: 66.41%] [G loss: 1.485236]\n",
      "epoch:25 step:23961 [D loss: 0.493353, acc.: 77.34%] [G loss: 1.429807]\n",
      "epoch:25 step:23962 [D loss: 0.433508, acc.: 82.03%] [G loss: 1.427314]\n",
      "epoch:25 step:23963 [D loss: 0.751414, acc.: 57.03%] [G loss: 1.343954]\n",
      "epoch:25 step:23964 [D loss: 0.404464, acc.: 86.72%] [G loss: 1.493209]\n",
      "epoch:25 step:23965 [D loss: 0.480340, acc.: 79.69%] [G loss: 1.275827]\n",
      "epoch:25 step:23966 [D loss: 0.563762, acc.: 71.88%] [G loss: 1.283803]\n",
      "epoch:25 step:23967 [D loss: 0.343312, acc.: 86.72%] [G loss: 1.757339]\n",
      "epoch:25 step:23968 [D loss: 0.429337, acc.: 84.38%] [G loss: 1.183730]\n",
      "epoch:25 step:23969 [D loss: 0.562703, acc.: 73.44%] [G loss: 1.147761]\n",
      "epoch:25 step:23970 [D loss: 0.549660, acc.: 68.75%] [G loss: 1.746476]\n",
      "epoch:25 step:23971 [D loss: 0.645935, acc.: 67.19%] [G loss: 1.169495]\n",
      "epoch:25 step:23972 [D loss: 0.518745, acc.: 75.00%] [G loss: 1.609071]\n",
      "epoch:25 step:23973 [D loss: 0.829933, acc.: 48.44%] [G loss: 1.178715]\n",
      "epoch:25 step:23974 [D loss: 0.502212, acc.: 77.34%] [G loss: 1.537039]\n",
      "epoch:25 step:23975 [D loss: 0.468140, acc.: 80.47%] [G loss: 1.357783]\n",
      "epoch:25 step:23976 [D loss: 0.832903, acc.: 50.00%] [G loss: 1.180855]\n",
      "epoch:25 step:23977 [D loss: 0.608484, acc.: 70.31%] [G loss: 1.482533]\n",
      "epoch:25 step:23978 [D loss: 0.731644, acc.: 60.16%] [G loss: 1.519030]\n",
      "epoch:25 step:23979 [D loss: 0.631249, acc.: 62.50%] [G loss: 1.362892]\n",
      "epoch:25 step:23980 [D loss: 0.448314, acc.: 78.91%] [G loss: 1.476355]\n",
      "epoch:25 step:23981 [D loss: 0.686174, acc.: 56.25%] [G loss: 1.421274]\n",
      "epoch:25 step:23982 [D loss: 0.532116, acc.: 76.56%] [G loss: 1.492659]\n",
      "epoch:25 step:23983 [D loss: 0.622989, acc.: 63.28%] [G loss: 1.364331]\n",
      "epoch:25 step:23984 [D loss: 0.546595, acc.: 72.66%] [G loss: 1.453065]\n",
      "epoch:25 step:23985 [D loss: 0.387051, acc.: 84.38%] [G loss: 1.230646]\n",
      "epoch:25 step:23986 [D loss: 0.749963, acc.: 60.16%] [G loss: 1.190123]\n",
      "epoch:25 step:23987 [D loss: 0.483168, acc.: 82.81%] [G loss: 1.699909]\n",
      "epoch:25 step:23988 [D loss: 0.473473, acc.: 82.03%] [G loss: 1.285605]\n",
      "epoch:25 step:23989 [D loss: 0.450179, acc.: 76.56%] [G loss: 1.787112]\n",
      "epoch:25 step:23990 [D loss: 0.579261, acc.: 67.19%] [G loss: 1.210703]\n",
      "epoch:25 step:23991 [D loss: 0.478756, acc.: 80.47%] [G loss: 1.513378]\n",
      "epoch:25 step:23992 [D loss: 0.607420, acc.: 64.84%] [G loss: 1.447476]\n",
      "epoch:25 step:23993 [D loss: 0.585851, acc.: 69.53%] [G loss: 1.306240]\n",
      "epoch:25 step:23994 [D loss: 0.561899, acc.: 67.97%] [G loss: 1.439884]\n",
      "epoch:25 step:23995 [D loss: 0.572587, acc.: 67.97%] [G loss: 1.236014]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:25 step:23996 [D loss: 0.480809, acc.: 77.34%] [G loss: 1.805294]\n",
      "epoch:25 step:23997 [D loss: 0.479868, acc.: 76.56%] [G loss: 1.324913]\n",
      "epoch:25 step:23998 [D loss: 0.531519, acc.: 71.88%] [G loss: 1.545568]\n",
      "epoch:25 step:23999 [D loss: 0.632139, acc.: 69.53%] [G loss: 1.078349]\n",
      "epoch:25 step:24000 [D loss: 0.584214, acc.: 67.97%] [G loss: 1.271168]\n",
      "epoch:25 step:24001 [D loss: 0.439995, acc.: 83.59%] [G loss: 1.478033]\n",
      "epoch:25 step:24002 [D loss: 0.615895, acc.: 62.50%] [G loss: 1.314079]\n",
      "epoch:25 step:24003 [D loss: 0.492580, acc.: 77.34%] [G loss: 1.567063]\n",
      "epoch:25 step:24004 [D loss: 0.490520, acc.: 75.78%] [G loss: 1.589324]\n",
      "epoch:25 step:24005 [D loss: 0.475579, acc.: 78.12%] [G loss: 1.143651]\n",
      "epoch:25 step:24006 [D loss: 0.657244, acc.: 62.50%] [G loss: 1.083754]\n",
      "epoch:25 step:24007 [D loss: 0.521639, acc.: 73.44%] [G loss: 1.480973]\n",
      "epoch:25 step:24008 [D loss: 0.484896, acc.: 77.34%] [G loss: 1.443846]\n",
      "epoch:25 step:24009 [D loss: 0.572418, acc.: 67.97%] [G loss: 1.096105]\n",
      "epoch:25 step:24010 [D loss: 0.626647, acc.: 68.75%] [G loss: 1.928262]\n",
      "epoch:25 step:24011 [D loss: 0.454355, acc.: 75.78%] [G loss: 1.525546]\n",
      "epoch:25 step:24012 [D loss: 0.565995, acc.: 73.44%] [G loss: 1.284551]\n",
      "epoch:25 step:24013 [D loss: 0.865634, acc.: 42.19%] [G loss: 1.088274]\n",
      "epoch:25 step:24014 [D loss: 0.606621, acc.: 67.97%] [G loss: 1.168841]\n",
      "epoch:25 step:24015 [D loss: 0.452217, acc.: 83.59%] [G loss: 1.502686]\n",
      "epoch:25 step:24016 [D loss: 0.611183, acc.: 64.06%] [G loss: 1.369359]\n",
      "epoch:25 step:24017 [D loss: 0.492038, acc.: 77.34%] [G loss: 1.602349]\n",
      "epoch:25 step:24018 [D loss: 0.829552, acc.: 52.34%] [G loss: 1.233117]\n",
      "epoch:25 step:24019 [D loss: 0.451146, acc.: 79.69%] [G loss: 1.615689]\n",
      "epoch:25 step:24020 [D loss: 0.578741, acc.: 71.09%] [G loss: 1.393945]\n",
      "epoch:25 step:24021 [D loss: 0.590296, acc.: 67.97%] [G loss: 1.725206]\n",
      "epoch:25 step:24022 [D loss: 0.747370, acc.: 53.91%] [G loss: 1.165548]\n",
      "epoch:25 step:24023 [D loss: 0.619877, acc.: 63.28%] [G loss: 1.341770]\n",
      "epoch:25 step:24024 [D loss: 0.552188, acc.: 71.09%] [G loss: 1.506412]\n",
      "epoch:25 step:24025 [D loss: 0.440606, acc.: 79.69%] [G loss: 1.436762]\n",
      "epoch:25 step:24026 [D loss: 0.795006, acc.: 57.81%] [G loss: 1.303799]\n",
      "epoch:25 step:24027 [D loss: 0.447636, acc.: 80.47%] [G loss: 1.336107]\n",
      "epoch:25 step:24028 [D loss: 0.588991, acc.: 71.09%] [G loss: 1.226141]\n",
      "epoch:25 step:24029 [D loss: 0.445722, acc.: 80.47%] [G loss: 1.283149]\n",
      "epoch:25 step:24030 [D loss: 0.650962, acc.: 64.84%] [G loss: 1.096277]\n",
      "epoch:25 step:24031 [D loss: 0.617342, acc.: 68.75%] [G loss: 1.103254]\n",
      "epoch:25 step:24032 [D loss: 0.542120, acc.: 72.66%] [G loss: 1.373678]\n",
      "epoch:25 step:24033 [D loss: 0.537927, acc.: 75.78%] [G loss: 1.382328]\n",
      "epoch:25 step:24034 [D loss: 0.535757, acc.: 74.22%] [G loss: 1.503718]\n",
      "epoch:25 step:24035 [D loss: 0.636920, acc.: 65.62%] [G loss: 1.259685]\n",
      "epoch:25 step:24036 [D loss: 0.772311, acc.: 54.69%] [G loss: 1.064293]\n",
      "epoch:25 step:24037 [D loss: 0.669560, acc.: 60.16%] [G loss: 1.126941]\n",
      "epoch:25 step:24038 [D loss: 0.486788, acc.: 78.12%] [G loss: 1.095090]\n",
      "epoch:25 step:24039 [D loss: 0.571176, acc.: 62.50%] [G loss: 1.344274]\n",
      "epoch:25 step:24040 [D loss: 0.546471, acc.: 71.88%] [G loss: 1.700479]\n",
      "epoch:25 step:24041 [D loss: 0.545534, acc.: 69.53%] [G loss: 1.112947]\n",
      "epoch:25 step:24042 [D loss: 0.571905, acc.: 70.31%] [G loss: 1.493439]\n",
      "epoch:25 step:24043 [D loss: 0.426542, acc.: 83.59%] [G loss: 1.405006]\n",
      "epoch:25 step:24044 [D loss: 0.601139, acc.: 64.84%] [G loss: 1.482789]\n",
      "epoch:25 step:24045 [D loss: 0.667232, acc.: 67.19%] [G loss: 1.193507]\n",
      "epoch:25 step:24046 [D loss: 0.695246, acc.: 59.38%] [G loss: 1.051904]\n",
      "epoch:25 step:24047 [D loss: 0.669974, acc.: 61.72%] [G loss: 1.318191]\n",
      "epoch:25 step:24048 [D loss: 0.494723, acc.: 75.00%] [G loss: 1.606299]\n",
      "epoch:25 step:24049 [D loss: 0.508655, acc.: 76.56%] [G loss: 1.335599]\n",
      "epoch:25 step:24050 [D loss: 0.530787, acc.: 71.88%] [G loss: 1.133811]\n",
      "epoch:25 step:24051 [D loss: 0.434872, acc.: 79.69%] [G loss: 1.468506]\n",
      "epoch:25 step:24052 [D loss: 0.657059, acc.: 64.84%] [G loss: 1.296976]\n",
      "epoch:25 step:24053 [D loss: 0.626976, acc.: 64.06%] [G loss: 1.487910]\n",
      "epoch:25 step:24054 [D loss: 0.509119, acc.: 75.78%] [G loss: 1.626499]\n",
      "epoch:25 step:24055 [D loss: 0.676353, acc.: 59.38%] [G loss: 1.348676]\n",
      "epoch:25 step:24056 [D loss: 0.488744, acc.: 77.34%] [G loss: 1.315835]\n",
      "epoch:25 step:24057 [D loss: 0.516916, acc.: 71.88%] [G loss: 1.319334]\n",
      "epoch:25 step:24058 [D loss: 0.574692, acc.: 67.19%] [G loss: 1.151676]\n",
      "epoch:25 step:24059 [D loss: 0.430923, acc.: 82.03%] [G loss: 1.707548]\n",
      "epoch:25 step:24060 [D loss: 0.606175, acc.: 66.41%] [G loss: 1.193621]\n",
      "epoch:25 step:24061 [D loss: 0.577141, acc.: 67.97%] [G loss: 1.453173]\n",
      "epoch:25 step:24062 [D loss: 0.727239, acc.: 59.38%] [G loss: 1.330517]\n",
      "epoch:25 step:24063 [D loss: 0.546764, acc.: 71.88%] [G loss: 0.887267]\n",
      "epoch:25 step:24064 [D loss: 0.563922, acc.: 71.88%] [G loss: 1.287413]\n",
      "epoch:25 step:24065 [D loss: 0.434451, acc.: 80.47%] [G loss: 1.572815]\n",
      "epoch:25 step:24066 [D loss: 0.544196, acc.: 68.75%] [G loss: 1.245658]\n",
      "epoch:25 step:24067 [D loss: 0.594924, acc.: 73.44%] [G loss: 1.467464]\n",
      "epoch:25 step:24068 [D loss: 0.531615, acc.: 79.69%] [G loss: 1.294404]\n",
      "epoch:25 step:24069 [D loss: 0.636867, acc.: 65.62%] [G loss: 1.256313]\n",
      "epoch:25 step:24070 [D loss: 0.554471, acc.: 74.22%] [G loss: 1.532775]\n",
      "epoch:25 step:24071 [D loss: 0.460569, acc.: 80.47%] [G loss: 1.369716]\n",
      "epoch:25 step:24072 [D loss: 0.540760, acc.: 75.00%] [G loss: 1.307442]\n",
      "epoch:25 step:24073 [D loss: 0.348967, acc.: 89.84%] [G loss: 1.688609]\n",
      "epoch:25 step:24074 [D loss: 0.727899, acc.: 58.59%] [G loss: 1.264129]\n",
      "epoch:25 step:24075 [D loss: 0.477643, acc.: 75.78%] [G loss: 1.355435]\n",
      "epoch:25 step:24076 [D loss: 0.516935, acc.: 76.56%] [G loss: 1.548227]\n",
      "epoch:25 step:24077 [D loss: 0.509166, acc.: 75.78%] [G loss: 1.594057]\n",
      "epoch:25 step:24078 [D loss: 0.667383, acc.: 54.69%] [G loss: 1.434420]\n",
      "epoch:25 step:24079 [D loss: 0.746502, acc.: 58.59%] [G loss: 1.220195]\n",
      "epoch:25 step:24080 [D loss: 0.524228, acc.: 78.12%] [G loss: 1.418754]\n",
      "epoch:25 step:24081 [D loss: 0.447996, acc.: 80.47%] [G loss: 1.622741]\n",
      "epoch:25 step:24082 [D loss: 0.616644, acc.: 65.62%] [G loss: 0.791178]\n",
      "epoch:25 step:24083 [D loss: 0.443515, acc.: 81.25%] [G loss: 1.184862]\n",
      "epoch:25 step:24084 [D loss: 0.744376, acc.: 53.91%] [G loss: 1.520109]\n",
      "epoch:25 step:24085 [D loss: 0.736449, acc.: 56.25%] [G loss: 1.526709]\n",
      "epoch:25 step:24086 [D loss: 0.563497, acc.: 74.22%] [G loss: 1.862888]\n",
      "epoch:25 step:24087 [D loss: 0.736769, acc.: 54.69%] [G loss: 1.197291]\n",
      "epoch:25 step:24088 [D loss: 0.606268, acc.: 67.19%] [G loss: 1.549479]\n",
      "epoch:25 step:24089 [D loss: 0.688087, acc.: 59.38%] [G loss: 1.125554]\n",
      "epoch:25 step:24090 [D loss: 0.493801, acc.: 74.22%] [G loss: 1.048321]\n",
      "epoch:25 step:24091 [D loss: 0.468698, acc.: 74.22%] [G loss: 1.320404]\n",
      "epoch:25 step:24092 [D loss: 0.637043, acc.: 66.41%] [G loss: 1.256672]\n",
      "epoch:25 step:24093 [D loss: 0.728448, acc.: 57.03%] [G loss: 1.708668]\n",
      "epoch:25 step:24094 [D loss: 0.445646, acc.: 80.47%] [G loss: 1.521658]\n",
      "epoch:25 step:24095 [D loss: 0.804204, acc.: 52.34%] [G loss: 1.128391]\n",
      "epoch:25 step:24096 [D loss: 0.509878, acc.: 75.78%] [G loss: 1.205936]\n",
      "epoch:25 step:24097 [D loss: 0.525172, acc.: 71.09%] [G loss: 1.227429]\n",
      "epoch:25 step:24098 [D loss: 0.478699, acc.: 78.12%] [G loss: 1.136391]\n",
      "epoch:25 step:24099 [D loss: 0.410156, acc.: 84.38%] [G loss: 1.646890]\n",
      "epoch:25 step:24100 [D loss: 0.587893, acc.: 64.84%] [G loss: 1.140384]\n",
      "epoch:25 step:24101 [D loss: 0.570546, acc.: 70.31%] [G loss: 1.243251]\n",
      "epoch:25 step:24102 [D loss: 0.483559, acc.: 75.00%] [G loss: 1.099091]\n",
      "epoch:25 step:24103 [D loss: 0.531480, acc.: 76.56%] [G loss: 1.492789]\n",
      "epoch:25 step:24104 [D loss: 0.496330, acc.: 75.00%] [G loss: 1.684531]\n",
      "epoch:25 step:24105 [D loss: 0.627844, acc.: 68.75%] [G loss: 1.687094]\n",
      "epoch:25 step:24106 [D loss: 0.523191, acc.: 75.78%] [G loss: 1.480472]\n",
      "epoch:25 step:24107 [D loss: 0.557238, acc.: 70.31%] [G loss: 1.234222]\n",
      "epoch:25 step:24108 [D loss: 0.885810, acc.: 46.88%] [G loss: 1.438578]\n",
      "epoch:25 step:24109 [D loss: 0.555998, acc.: 76.56%] [G loss: 1.690339]\n",
      "epoch:25 step:24110 [D loss: 0.585224, acc.: 67.19%] [G loss: 1.346199]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:25 step:24111 [D loss: 0.516040, acc.: 75.78%] [G loss: 1.368311]\n",
      "epoch:25 step:24112 [D loss: 0.608004, acc.: 66.41%] [G loss: 1.364523]\n",
      "epoch:25 step:24113 [D loss: 0.421975, acc.: 79.69%] [G loss: 1.429970]\n",
      "epoch:25 step:24114 [D loss: 0.657834, acc.: 66.41%] [G loss: 1.102923]\n",
      "epoch:25 step:24115 [D loss: 0.585868, acc.: 66.41%] [G loss: 1.207326]\n",
      "epoch:25 step:24116 [D loss: 0.459534, acc.: 81.25%] [G loss: 0.928567]\n",
      "epoch:25 step:24117 [D loss: 0.687089, acc.: 61.72%] [G loss: 1.465360]\n",
      "epoch:25 step:24118 [D loss: 0.631682, acc.: 65.62%] [G loss: 1.311088]\n",
      "epoch:25 step:24119 [D loss: 0.451732, acc.: 78.12%] [G loss: 1.569081]\n",
      "epoch:25 step:24120 [D loss: 0.347430, acc.: 88.28%] [G loss: 1.242846]\n",
      "epoch:25 step:24121 [D loss: 0.579951, acc.: 73.44%] [G loss: 1.601320]\n",
      "epoch:25 step:24122 [D loss: 0.411949, acc.: 86.72%] [G loss: 1.427428]\n",
      "epoch:25 step:24123 [D loss: 0.592462, acc.: 67.97%] [G loss: 1.660818]\n",
      "epoch:25 step:24124 [D loss: 0.607762, acc.: 66.41%] [G loss: 1.406925]\n",
      "epoch:25 step:24125 [D loss: 0.560461, acc.: 71.09%] [G loss: 1.249398]\n",
      "epoch:25 step:24126 [D loss: 0.279846, acc.: 95.31%] [G loss: 1.378284]\n",
      "epoch:25 step:24127 [D loss: 0.413535, acc.: 82.03%] [G loss: 1.900288]\n",
      "epoch:25 step:24128 [D loss: 0.638880, acc.: 63.28%] [G loss: 1.971677]\n",
      "epoch:25 step:24129 [D loss: 0.658577, acc.: 65.62%] [G loss: 1.522017]\n",
      "epoch:25 step:24130 [D loss: 0.569793, acc.: 70.31%] [G loss: 1.196313]\n",
      "epoch:25 step:24131 [D loss: 0.561040, acc.: 69.53%] [G loss: 1.361510]\n",
      "epoch:25 step:24132 [D loss: 0.560309, acc.: 75.78%] [G loss: 1.339459]\n",
      "epoch:25 step:24133 [D loss: 0.499413, acc.: 72.66%] [G loss: 1.316037]\n",
      "epoch:25 step:24134 [D loss: 0.880588, acc.: 47.66%] [G loss: 1.405349]\n",
      "epoch:25 step:24135 [D loss: 0.572521, acc.: 74.22%] [G loss: 1.427288]\n",
      "epoch:25 step:24136 [D loss: 0.502816, acc.: 76.56%] [G loss: 1.343612]\n",
      "epoch:25 step:24137 [D loss: 0.448052, acc.: 79.69%] [G loss: 1.752835]\n",
      "epoch:25 step:24138 [D loss: 0.647060, acc.: 60.94%] [G loss: 1.032703]\n",
      "epoch:25 step:24139 [D loss: 0.585691, acc.: 72.66%] [G loss: 1.727798]\n",
      "epoch:25 step:24140 [D loss: 0.539630, acc.: 72.66%] [G loss: 1.431736]\n",
      "epoch:25 step:24141 [D loss: 0.554713, acc.: 72.66%] [G loss: 1.472212]\n",
      "epoch:25 step:24142 [D loss: 0.506059, acc.: 71.88%] [G loss: 1.541305]\n",
      "epoch:25 step:24143 [D loss: 0.420366, acc.: 83.59%] [G loss: 1.378988]\n",
      "epoch:25 step:24144 [D loss: 0.587855, acc.: 67.19%] [G loss: 1.404611]\n",
      "epoch:25 step:24145 [D loss: 0.561567, acc.: 69.53%] [G loss: 1.149508]\n",
      "epoch:25 step:24146 [D loss: 0.498584, acc.: 78.12%] [G loss: 1.167584]\n",
      "epoch:25 step:24147 [D loss: 0.436685, acc.: 85.94%] [G loss: 1.469072]\n",
      "epoch:25 step:24148 [D loss: 0.453877, acc.: 82.03%] [G loss: 1.524004]\n",
      "epoch:25 step:24149 [D loss: 0.477046, acc.: 81.25%] [G loss: 1.457605]\n",
      "epoch:25 step:24150 [D loss: 0.543961, acc.: 67.97%] [G loss: 1.540281]\n",
      "epoch:25 step:24151 [D loss: 0.704673, acc.: 53.91%] [G loss: 1.439801]\n",
      "epoch:25 step:24152 [D loss: 0.681524, acc.: 60.16%] [G loss: 1.355968]\n",
      "epoch:25 step:24153 [D loss: 0.540318, acc.: 71.09%] [G loss: 1.590937]\n",
      "epoch:25 step:24154 [D loss: 0.465598, acc.: 80.47%] [G loss: 1.616236]\n",
      "epoch:25 step:24155 [D loss: 0.711549, acc.: 60.16%] [G loss: 1.324992]\n",
      "epoch:25 step:24156 [D loss: 0.831013, acc.: 51.56%] [G loss: 1.208765]\n",
      "epoch:25 step:24157 [D loss: 0.671895, acc.: 62.50%] [G loss: 1.265276]\n",
      "epoch:25 step:24158 [D loss: 0.504661, acc.: 75.00%] [G loss: 1.247136]\n",
      "epoch:25 step:24159 [D loss: 0.483520, acc.: 75.78%] [G loss: 1.561821]\n",
      "epoch:25 step:24160 [D loss: 0.739826, acc.: 54.69%] [G loss: 1.333621]\n",
      "epoch:25 step:24161 [D loss: 0.505761, acc.: 75.00%] [G loss: 1.068581]\n",
      "epoch:25 step:24162 [D loss: 0.609663, acc.: 57.03%] [G loss: 1.481011]\n",
      "epoch:25 step:24163 [D loss: 0.641689, acc.: 65.62%] [G loss: 1.376110]\n",
      "epoch:25 step:24164 [D loss: 0.572890, acc.: 71.09%] [G loss: 1.446398]\n",
      "epoch:25 step:24165 [D loss: 0.678140, acc.: 57.81%] [G loss: 1.354533]\n",
      "epoch:25 step:24166 [D loss: 0.651018, acc.: 68.75%] [G loss: 1.207474]\n",
      "epoch:25 step:24167 [D loss: 0.548599, acc.: 74.22%] [G loss: 1.321671]\n",
      "epoch:25 step:24168 [D loss: 0.540411, acc.: 72.66%] [G loss: 1.448467]\n",
      "epoch:25 step:24169 [D loss: 0.578268, acc.: 72.66%] [G loss: 1.560251]\n",
      "epoch:25 step:24170 [D loss: 0.505144, acc.: 76.56%] [G loss: 1.588643]\n",
      "epoch:25 step:24171 [D loss: 0.646172, acc.: 67.19%] [G loss: 1.233671]\n",
      "epoch:25 step:24172 [D loss: 0.531040, acc.: 71.88%] [G loss: 1.470248]\n",
      "epoch:25 step:24173 [D loss: 0.429647, acc.: 79.69%] [G loss: 1.148069]\n",
      "epoch:25 step:24174 [D loss: 0.552087, acc.: 71.09%] [G loss: 1.232904]\n",
      "epoch:25 step:24175 [D loss: 0.626717, acc.: 68.75%] [G loss: 1.406569]\n",
      "epoch:25 step:24176 [D loss: 0.432055, acc.: 79.69%] [G loss: 1.555818]\n",
      "epoch:25 step:24177 [D loss: 0.566586, acc.: 70.31%] [G loss: 1.606317]\n",
      "epoch:25 step:24178 [D loss: 0.481227, acc.: 78.91%] [G loss: 1.141006]\n",
      "epoch:25 step:24179 [D loss: 0.545506, acc.: 69.53%] [G loss: 1.001709]\n",
      "epoch:25 step:24180 [D loss: 0.446122, acc.: 78.12%] [G loss: 1.204106]\n",
      "epoch:25 step:24181 [D loss: 0.551672, acc.: 72.66%] [G loss: 1.145834]\n",
      "epoch:25 step:24182 [D loss: 0.411896, acc.: 82.81%] [G loss: 1.924360]\n",
      "epoch:25 step:24183 [D loss: 0.453115, acc.: 81.25%] [G loss: 1.629137]\n",
      "epoch:25 step:24184 [D loss: 0.464201, acc.: 78.91%] [G loss: 1.246247]\n",
      "epoch:25 step:24185 [D loss: 0.566178, acc.: 72.66%] [G loss: 1.656440]\n",
      "epoch:25 step:24186 [D loss: 0.477607, acc.: 79.69%] [G loss: 1.460557]\n",
      "epoch:25 step:24187 [D loss: 0.696176, acc.: 61.72%] [G loss: 1.218107]\n",
      "epoch:25 step:24188 [D loss: 0.498727, acc.: 75.00%] [G loss: 1.482844]\n",
      "epoch:25 step:24189 [D loss: 0.450429, acc.: 77.34%] [G loss: 1.378565]\n",
      "epoch:25 step:24190 [D loss: 0.465806, acc.: 78.91%] [G loss: 1.229579]\n",
      "epoch:25 step:24191 [D loss: 0.500914, acc.: 77.34%] [G loss: 1.304338]\n",
      "epoch:25 step:24192 [D loss: 0.475483, acc.: 78.12%] [G loss: 0.898903]\n",
      "epoch:25 step:24193 [D loss: 0.505705, acc.: 77.34%] [G loss: 1.407276]\n",
      "epoch:25 step:24194 [D loss: 0.733342, acc.: 57.81%] [G loss: 1.660413]\n",
      "epoch:25 step:24195 [D loss: 0.685873, acc.: 62.50%] [G loss: 1.147861]\n",
      "epoch:25 step:24196 [D loss: 0.427257, acc.: 78.12%] [G loss: 1.577397]\n",
      "epoch:25 step:24197 [D loss: 0.651970, acc.: 66.41%] [G loss: 1.134441]\n",
      "epoch:25 step:24198 [D loss: 0.679969, acc.: 57.03%] [G loss: 1.510581]\n",
      "epoch:25 step:24199 [D loss: 0.551508, acc.: 70.31%] [G loss: 1.477391]\n",
      "epoch:25 step:24200 [D loss: 0.501382, acc.: 79.69%] [G loss: 1.557518]\n",
      "epoch:25 step:24201 [D loss: 0.332338, acc.: 89.84%] [G loss: 1.609024]\n",
      "epoch:25 step:24202 [D loss: 0.564757, acc.: 67.97%] [G loss: 1.435442]\n",
      "epoch:25 step:24203 [D loss: 0.444628, acc.: 82.81%] [G loss: 1.518117]\n",
      "epoch:25 step:24204 [D loss: 0.512452, acc.: 74.22%] [G loss: 1.420388]\n",
      "epoch:25 step:24205 [D loss: 0.802082, acc.: 44.53%] [G loss: 0.935827]\n",
      "epoch:25 step:24206 [D loss: 0.631459, acc.: 61.72%] [G loss: 1.404576]\n",
      "epoch:25 step:24207 [D loss: 0.495694, acc.: 75.00%] [G loss: 1.679353]\n",
      "epoch:25 step:24208 [D loss: 0.683763, acc.: 59.38%] [G loss: 1.154512]\n",
      "epoch:25 step:24209 [D loss: 0.579451, acc.: 67.97%] [G loss: 1.481656]\n",
      "epoch:25 step:24210 [D loss: 0.477182, acc.: 80.47%] [G loss: 1.076345]\n",
      "epoch:25 step:24211 [D loss: 0.596610, acc.: 68.75%] [G loss: 1.621294]\n",
      "epoch:25 step:24212 [D loss: 0.560199, acc.: 72.66%] [G loss: 1.643199]\n",
      "epoch:25 step:24213 [D loss: 0.503088, acc.: 73.44%] [G loss: 1.727659]\n",
      "epoch:25 step:24214 [D loss: 0.520201, acc.: 68.75%] [G loss: 1.435943]\n",
      "epoch:25 step:24215 [D loss: 0.640439, acc.: 66.41%] [G loss: 1.073520]\n",
      "epoch:25 step:24216 [D loss: 0.444645, acc.: 76.56%] [G loss: 1.479480]\n",
      "epoch:25 step:24217 [D loss: 0.426651, acc.: 83.59%] [G loss: 1.460600]\n",
      "epoch:25 step:24218 [D loss: 0.566048, acc.: 69.53%] [G loss: 1.410353]\n",
      "epoch:25 step:24219 [D loss: 0.459049, acc.: 78.91%] [G loss: 1.589832]\n",
      "epoch:25 step:24220 [D loss: 0.420380, acc.: 81.25%] [G loss: 1.946882]\n",
      "epoch:25 step:24221 [D loss: 0.539147, acc.: 72.66%] [G loss: 1.308487]\n",
      "epoch:25 step:24222 [D loss: 0.701741, acc.: 64.84%] [G loss: 1.247282]\n",
      "epoch:25 step:24223 [D loss: 0.400747, acc.: 85.94%] [G loss: 1.254827]\n",
      "epoch:25 step:24224 [D loss: 0.617248, acc.: 68.75%] [G loss: 1.569067]\n",
      "epoch:25 step:24225 [D loss: 0.495252, acc.: 76.56%] [G loss: 1.430694]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:25 step:24226 [D loss: 0.510894, acc.: 75.00%] [G loss: 1.173959]\n",
      "epoch:25 step:24227 [D loss: 0.693503, acc.: 59.38%] [G loss: 1.224457]\n",
      "epoch:25 step:24228 [D loss: 0.605706, acc.: 70.31%] [G loss: 1.489604]\n",
      "epoch:25 step:24229 [D loss: 0.522229, acc.: 75.78%] [G loss: 1.668440]\n",
      "epoch:25 step:24230 [D loss: 0.548789, acc.: 75.00%] [G loss: 1.675185]\n",
      "epoch:25 step:24231 [D loss: 0.484391, acc.: 72.66%] [G loss: 1.490316]\n",
      "epoch:25 step:24232 [D loss: 0.479256, acc.: 77.34%] [G loss: 1.540286]\n",
      "epoch:25 step:24233 [D loss: 0.501451, acc.: 74.22%] [G loss: 0.932837]\n",
      "epoch:25 step:24234 [D loss: 0.590497, acc.: 66.41%] [G loss: 1.376593]\n",
      "epoch:25 step:24235 [D loss: 0.518373, acc.: 73.44%] [G loss: 0.987027]\n",
      "epoch:25 step:24236 [D loss: 0.518647, acc.: 75.00%] [G loss: 1.354512]\n",
      "epoch:25 step:24237 [D loss: 0.608330, acc.: 70.31%] [G loss: 1.082054]\n",
      "epoch:25 step:24238 [D loss: 0.553284, acc.: 71.88%] [G loss: 1.359033]\n",
      "epoch:25 step:24239 [D loss: 0.523058, acc.: 71.88%] [G loss: 1.435691]\n",
      "epoch:25 step:24240 [D loss: 0.639768, acc.: 62.50%] [G loss: 1.070888]\n",
      "epoch:25 step:24241 [D loss: 0.502128, acc.: 77.34%] [G loss: 1.072959]\n",
      "epoch:25 step:24242 [D loss: 0.535902, acc.: 73.44%] [G loss: 1.374729]\n",
      "epoch:25 step:24243 [D loss: 0.423236, acc.: 85.16%] [G loss: 1.652288]\n",
      "epoch:25 step:24244 [D loss: 0.497934, acc.: 73.44%] [G loss: 1.626034]\n",
      "epoch:25 step:24245 [D loss: 0.636226, acc.: 61.72%] [G loss: 1.511522]\n",
      "epoch:25 step:24246 [D loss: 0.536156, acc.: 73.44%] [G loss: 1.493981]\n",
      "epoch:25 step:24247 [D loss: 0.601600, acc.: 68.75%] [G loss: 1.606737]\n",
      "epoch:25 step:24248 [D loss: 0.714115, acc.: 60.94%] [G loss: 1.238888]\n",
      "epoch:25 step:24249 [D loss: 0.660598, acc.: 64.06%] [G loss: 1.479357]\n",
      "epoch:25 step:24250 [D loss: 0.576671, acc.: 72.66%] [G loss: 1.369929]\n",
      "epoch:25 step:24251 [D loss: 0.585860, acc.: 66.41%] [G loss: 0.873205]\n",
      "epoch:25 step:24252 [D loss: 0.606914, acc.: 67.97%] [G loss: 1.053562]\n",
      "epoch:25 step:24253 [D loss: 0.638322, acc.: 64.84%] [G loss: 1.472319]\n",
      "epoch:25 step:24254 [D loss: 0.453107, acc.: 80.47%] [G loss: 1.164622]\n",
      "epoch:25 step:24255 [D loss: 0.583031, acc.: 65.62%] [G loss: 0.997917]\n",
      "epoch:25 step:24256 [D loss: 0.602733, acc.: 68.75%] [G loss: 1.409343]\n",
      "epoch:25 step:24257 [D loss: 0.466838, acc.: 75.78%] [G loss: 1.698451]\n",
      "epoch:25 step:24258 [D loss: 0.639447, acc.: 63.28%] [G loss: 1.491202]\n",
      "epoch:25 step:24259 [D loss: 0.676615, acc.: 57.81%] [G loss: 1.614689]\n",
      "epoch:25 step:24260 [D loss: 0.535429, acc.: 70.31%] [G loss: 1.116677]\n",
      "epoch:25 step:24261 [D loss: 0.611476, acc.: 69.53%] [G loss: 1.092125]\n",
      "epoch:25 step:24262 [D loss: 0.528054, acc.: 75.00%] [G loss: 1.278624]\n",
      "epoch:25 step:24263 [D loss: 0.442869, acc.: 77.34%] [G loss: 1.273762]\n",
      "epoch:25 step:24264 [D loss: 0.683998, acc.: 64.84%] [G loss: 1.514751]\n",
      "epoch:25 step:24265 [D loss: 0.324061, acc.: 89.06%] [G loss: 1.439932]\n",
      "epoch:25 step:24266 [D loss: 0.580165, acc.: 71.09%] [G loss: 1.616672]\n",
      "epoch:25 step:24267 [D loss: 0.597860, acc.: 67.19%] [G loss: 1.192119]\n",
      "epoch:25 step:24268 [D loss: 0.570623, acc.: 75.00%] [G loss: 0.980664]\n",
      "epoch:25 step:24269 [D loss: 0.689363, acc.: 59.38%] [G loss: 1.337144]\n",
      "epoch:25 step:24270 [D loss: 0.653901, acc.: 63.28%] [G loss: 1.179563]\n",
      "epoch:25 step:24271 [D loss: 0.557870, acc.: 71.09%] [G loss: 1.415714]\n",
      "epoch:25 step:24272 [D loss: 0.469266, acc.: 78.91%] [G loss: 1.533214]\n",
      "epoch:25 step:24273 [D loss: 0.499227, acc.: 75.78%] [G loss: 1.067554]\n",
      "epoch:25 step:24274 [D loss: 0.353607, acc.: 89.06%] [G loss: 1.661350]\n",
      "epoch:25 step:24275 [D loss: 0.629650, acc.: 67.19%] [G loss: 1.357929]\n",
      "epoch:25 step:24276 [D loss: 0.766360, acc.: 53.12%] [G loss: 1.014619]\n",
      "epoch:25 step:24277 [D loss: 0.491785, acc.: 77.34%] [G loss: 1.083963]\n",
      "epoch:25 step:24278 [D loss: 0.487097, acc.: 75.00%] [G loss: 1.464713]\n",
      "epoch:25 step:24279 [D loss: 0.718752, acc.: 57.81%] [G loss: 1.730025]\n",
      "epoch:25 step:24280 [D loss: 0.426880, acc.: 76.56%] [G loss: 1.371618]\n",
      "epoch:25 step:24281 [D loss: 0.767836, acc.: 53.91%] [G loss: 1.268237]\n",
      "epoch:25 step:24282 [D loss: 0.495095, acc.: 76.56%] [G loss: 1.362149]\n",
      "epoch:25 step:24283 [D loss: 0.539134, acc.: 70.31%] [G loss: 1.141219]\n",
      "epoch:25 step:24284 [D loss: 0.656827, acc.: 63.28%] [G loss: 1.354609]\n",
      "epoch:25 step:24285 [D loss: 0.749288, acc.: 62.50%] [G loss: 1.467179]\n",
      "epoch:25 step:24286 [D loss: 0.481683, acc.: 77.34%] [G loss: 2.050016]\n",
      "epoch:25 step:24287 [D loss: 0.648576, acc.: 61.72%] [G loss: 1.375070]\n",
      "epoch:25 step:24288 [D loss: 0.447253, acc.: 80.47%] [G loss: 1.428544]\n",
      "epoch:25 step:24289 [D loss: 0.566939, acc.: 72.66%] [G loss: 1.209863]\n",
      "epoch:25 step:24290 [D loss: 0.577107, acc.: 70.31%] [G loss: 1.342180]\n",
      "epoch:25 step:24291 [D loss: 0.568779, acc.: 66.41%] [G loss: 1.145229]\n",
      "epoch:25 step:24292 [D loss: 0.581200, acc.: 71.09%] [G loss: 1.482466]\n",
      "epoch:25 step:24293 [D loss: 0.414289, acc.: 85.94%] [G loss: 1.630311]\n",
      "epoch:25 step:24294 [D loss: 0.497142, acc.: 76.56%] [G loss: 1.432642]\n",
      "epoch:25 step:24295 [D loss: 0.459859, acc.: 81.25%] [G loss: 1.498750]\n",
      "epoch:25 step:24296 [D loss: 0.451634, acc.: 82.03%] [G loss: 1.542597]\n",
      "epoch:25 step:24297 [D loss: 0.590480, acc.: 71.09%] [G loss: 1.442513]\n",
      "epoch:25 step:24298 [D loss: 0.432455, acc.: 82.81%] [G loss: 1.617655]\n",
      "epoch:25 step:24299 [D loss: 0.591744, acc.: 65.62%] [G loss: 1.742501]\n",
      "epoch:25 step:24300 [D loss: 0.471413, acc.: 75.78%] [G loss: 1.830100]\n",
      "epoch:25 step:24301 [D loss: 0.705633, acc.: 60.16%] [G loss: 1.083925]\n",
      "epoch:25 step:24302 [D loss: 0.487002, acc.: 74.22%] [G loss: 1.613978]\n",
      "epoch:25 step:24303 [D loss: 0.554023, acc.: 69.53%] [G loss: 0.988062]\n",
      "epoch:25 step:24304 [D loss: 0.599901, acc.: 65.62%] [G loss: 1.515100]\n",
      "epoch:25 step:24305 [D loss: 0.490565, acc.: 77.34%] [G loss: 1.174234]\n",
      "epoch:25 step:24306 [D loss: 0.616628, acc.: 65.62%] [G loss: 1.309523]\n",
      "epoch:25 step:24307 [D loss: 0.480099, acc.: 77.34%] [G loss: 1.843372]\n",
      "epoch:25 step:24308 [D loss: 0.620539, acc.: 64.84%] [G loss: 1.322820]\n",
      "epoch:25 step:24309 [D loss: 0.576287, acc.: 77.34%] [G loss: 1.369307]\n",
      "epoch:25 step:24310 [D loss: 0.514790, acc.: 75.00%] [G loss: 1.185824]\n",
      "epoch:25 step:24311 [D loss: 0.406193, acc.: 84.38%] [G loss: 1.280467]\n",
      "epoch:25 step:24312 [D loss: 0.590333, acc.: 67.19%] [G loss: 1.421820]\n",
      "epoch:25 step:24313 [D loss: 0.516968, acc.: 70.31%] [G loss: 1.389862]\n",
      "epoch:25 step:24314 [D loss: 0.560706, acc.: 73.44%] [G loss: 1.407888]\n",
      "epoch:25 step:24315 [D loss: 0.570918, acc.: 70.31%] [G loss: 1.462229]\n",
      "epoch:25 step:24316 [D loss: 0.692055, acc.: 53.91%] [G loss: 1.204067]\n",
      "epoch:25 step:24317 [D loss: 0.414055, acc.: 85.94%] [G loss: 1.245876]\n",
      "epoch:25 step:24318 [D loss: 0.588094, acc.: 67.19%] [G loss: 1.172506]\n",
      "epoch:25 step:24319 [D loss: 0.647051, acc.: 66.41%] [G loss: 1.024984]\n",
      "epoch:25 step:24320 [D loss: 0.561855, acc.: 71.09%] [G loss: 1.357699]\n",
      "epoch:25 step:24321 [D loss: 0.615600, acc.: 66.41%] [G loss: 1.447299]\n",
      "epoch:25 step:24322 [D loss: 0.510494, acc.: 75.00%] [G loss: 1.844044]\n",
      "epoch:25 step:24323 [D loss: 0.569900, acc.: 72.66%] [G loss: 1.561841]\n",
      "epoch:25 step:24324 [D loss: 0.468077, acc.: 82.03%] [G loss: 1.609646]\n",
      "epoch:25 step:24325 [D loss: 0.569897, acc.: 70.31%] [G loss: 1.279734]\n",
      "epoch:25 step:24326 [D loss: 0.492283, acc.: 74.22%] [G loss: 1.459836]\n",
      "epoch:25 step:24327 [D loss: 0.588566, acc.: 70.31%] [G loss: 1.224573]\n",
      "epoch:25 step:24328 [D loss: 0.745195, acc.: 54.69%] [G loss: 1.260985]\n",
      "epoch:25 step:24329 [D loss: 0.467316, acc.: 72.66%] [G loss: 1.074038]\n",
      "epoch:25 step:24330 [D loss: 0.724379, acc.: 59.38%] [G loss: 1.207871]\n",
      "epoch:25 step:24331 [D loss: 0.514105, acc.: 78.12%] [G loss: 1.493204]\n",
      "epoch:25 step:24332 [D loss: 0.497785, acc.: 74.22%] [G loss: 1.268233]\n",
      "epoch:25 step:24333 [D loss: 0.611301, acc.: 67.97%] [G loss: 1.435558]\n",
      "epoch:25 step:24334 [D loss: 0.632894, acc.: 69.53%] [G loss: 1.439562]\n",
      "epoch:25 step:24335 [D loss: 0.628002, acc.: 67.19%] [G loss: 1.526882]\n",
      "epoch:25 step:24336 [D loss: 0.528275, acc.: 71.88%] [G loss: 1.661291]\n",
      "epoch:25 step:24337 [D loss: 0.565039, acc.: 70.31%] [G loss: 1.267618]\n",
      "epoch:25 step:24338 [D loss: 0.634401, acc.: 64.06%] [G loss: 1.457541]\n",
      "epoch:25 step:24339 [D loss: 0.412919, acc.: 85.94%] [G loss: 1.623541]\n",
      "epoch:25 step:24340 [D loss: 0.469135, acc.: 78.12%] [G loss: 1.543437]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:25 step:24341 [D loss: 0.534608, acc.: 76.56%] [G loss: 1.595196]\n",
      "epoch:25 step:24342 [D loss: 0.500380, acc.: 78.91%] [G loss: 1.202560]\n",
      "epoch:25 step:24343 [D loss: 0.516510, acc.: 72.66%] [G loss: 1.231202]\n",
      "epoch:25 step:24344 [D loss: 0.519111, acc.: 75.78%] [G loss: 1.513832]\n",
      "epoch:25 step:24345 [D loss: 0.546433, acc.: 70.31%] [G loss: 1.462427]\n",
      "epoch:25 step:24346 [D loss: 0.504057, acc.: 80.47%] [G loss: 1.242449]\n",
      "epoch:25 step:24347 [D loss: 0.532146, acc.: 71.09%] [G loss: 1.733574]\n",
      "epoch:25 step:24348 [D loss: 0.600655, acc.: 69.53%] [G loss: 1.300812]\n",
      "epoch:25 step:24349 [D loss: 0.519437, acc.: 71.88%] [G loss: 1.523952]\n",
      "epoch:25 step:24350 [D loss: 0.665778, acc.: 61.72%] [G loss: 1.633399]\n",
      "epoch:25 step:24351 [D loss: 0.637731, acc.: 63.28%] [G loss: 1.246745]\n",
      "epoch:25 step:24352 [D loss: 0.682685, acc.: 64.06%] [G loss: 1.142129]\n",
      "epoch:25 step:24353 [D loss: 0.416687, acc.: 83.59%] [G loss: 1.055032]\n",
      "epoch:25 step:24354 [D loss: 0.645082, acc.: 65.62%] [G loss: 0.979203]\n",
      "epoch:25 step:24355 [D loss: 0.498707, acc.: 74.22%] [G loss: 1.498995]\n",
      "epoch:25 step:24356 [D loss: 0.524708, acc.: 74.22%] [G loss: 1.502803]\n",
      "epoch:25 step:24357 [D loss: 0.394443, acc.: 85.16%] [G loss: 1.421448]\n",
      "epoch:25 step:24358 [D loss: 0.595408, acc.: 69.53%] [G loss: 1.302115]\n",
      "epoch:25 step:24359 [D loss: 0.895117, acc.: 47.66%] [G loss: 1.473147]\n",
      "epoch:25 step:24360 [D loss: 0.451400, acc.: 84.38%] [G loss: 1.406917]\n",
      "epoch:25 step:24361 [D loss: 0.458489, acc.: 78.91%] [G loss: 1.474706]\n",
      "epoch:25 step:24362 [D loss: 0.532438, acc.: 72.66%] [G loss: 1.981145]\n",
      "epoch:26 step:24363 [D loss: 0.602409, acc.: 65.62%] [G loss: 1.378482]\n",
      "epoch:26 step:24364 [D loss: 0.447379, acc.: 82.81%] [G loss: 1.107972]\n",
      "epoch:26 step:24365 [D loss: 0.597186, acc.: 69.53%] [G loss: 1.556821]\n",
      "epoch:26 step:24366 [D loss: 0.632372, acc.: 70.31%] [G loss: 1.162004]\n",
      "epoch:26 step:24367 [D loss: 0.548185, acc.: 73.44%] [G loss: 1.014834]\n",
      "epoch:26 step:24368 [D loss: 0.467833, acc.: 79.69%] [G loss: 1.058080]\n",
      "epoch:26 step:24369 [D loss: 0.534606, acc.: 73.44%] [G loss: 1.135566]\n",
      "epoch:26 step:24370 [D loss: 0.600998, acc.: 68.75%] [G loss: 1.678413]\n",
      "epoch:26 step:24371 [D loss: 0.630687, acc.: 69.53%] [G loss: 1.510950]\n",
      "epoch:26 step:24372 [D loss: 0.585596, acc.: 70.31%] [G loss: 1.322559]\n",
      "epoch:26 step:24373 [D loss: 0.481899, acc.: 77.34%] [G loss: 1.128254]\n",
      "epoch:26 step:24374 [D loss: 0.488767, acc.: 78.12%] [G loss: 1.494623]\n",
      "epoch:26 step:24375 [D loss: 0.696536, acc.: 58.59%] [G loss: 1.237070]\n",
      "epoch:26 step:24376 [D loss: 0.428878, acc.: 82.03%] [G loss: 1.435413]\n",
      "epoch:26 step:24377 [D loss: 0.482516, acc.: 82.81%] [G loss: 1.561279]\n",
      "epoch:26 step:24378 [D loss: 0.583989, acc.: 70.31%] [G loss: 1.531521]\n",
      "epoch:26 step:24379 [D loss: 0.650977, acc.: 61.72%] [G loss: 1.251621]\n",
      "epoch:26 step:24380 [D loss: 0.580911, acc.: 71.09%] [G loss: 1.361017]\n",
      "epoch:26 step:24381 [D loss: 0.561879, acc.: 67.19%] [G loss: 1.247140]\n",
      "epoch:26 step:24382 [D loss: 0.514850, acc.: 73.44%] [G loss: 1.702550]\n",
      "epoch:26 step:24383 [D loss: 0.563120, acc.: 67.97%] [G loss: 1.318522]\n",
      "epoch:26 step:24384 [D loss: 0.417920, acc.: 84.38%] [G loss: 1.390848]\n",
      "epoch:26 step:24385 [D loss: 0.420038, acc.: 82.81%] [G loss: 1.335263]\n",
      "epoch:26 step:24386 [D loss: 0.602253, acc.: 69.53%] [G loss: 1.267156]\n",
      "epoch:26 step:24387 [D loss: 0.526483, acc.: 77.34%] [G loss: 0.956789]\n",
      "epoch:26 step:24388 [D loss: 0.513194, acc.: 78.91%] [G loss: 1.840605]\n",
      "epoch:26 step:24389 [D loss: 0.694516, acc.: 60.94%] [G loss: 1.425364]\n",
      "epoch:26 step:24390 [D loss: 0.466792, acc.: 78.91%] [G loss: 1.450029]\n",
      "epoch:26 step:24391 [D loss: 0.603195, acc.: 67.19%] [G loss: 1.571789]\n",
      "epoch:26 step:24392 [D loss: 0.519630, acc.: 69.53%] [G loss: 1.329370]\n",
      "epoch:26 step:24393 [D loss: 0.574481, acc.: 67.97%] [G loss: 1.148503]\n",
      "epoch:26 step:24394 [D loss: 0.567188, acc.: 71.09%] [G loss: 1.149847]\n",
      "epoch:26 step:24395 [D loss: 0.555017, acc.: 74.22%] [G loss: 1.622732]\n",
      "epoch:26 step:24396 [D loss: 0.526120, acc.: 75.00%] [G loss: 1.621167]\n",
      "epoch:26 step:24397 [D loss: 0.551971, acc.: 72.66%] [G loss: 1.253975]\n",
      "epoch:26 step:24398 [D loss: 0.607282, acc.: 65.62%] [G loss: 1.303279]\n",
      "epoch:26 step:24399 [D loss: 0.517460, acc.: 78.12%] [G loss: 1.786018]\n",
      "epoch:26 step:24400 [D loss: 0.517373, acc.: 75.78%] [G loss: 1.912301]\n",
      "epoch:26 step:24401 [D loss: 0.558657, acc.: 71.88%] [G loss: 1.403222]\n",
      "epoch:26 step:24402 [D loss: 0.633616, acc.: 58.59%] [G loss: 1.769840]\n",
      "epoch:26 step:24403 [D loss: 0.424487, acc.: 81.25%] [G loss: 1.484060]\n",
      "epoch:26 step:24404 [D loss: 0.651268, acc.: 63.28%] [G loss: 1.097905]\n",
      "epoch:26 step:24405 [D loss: 0.552697, acc.: 67.19%] [G loss: 1.588839]\n",
      "epoch:26 step:24406 [D loss: 0.420591, acc.: 84.38%] [G loss: 1.281000]\n",
      "epoch:26 step:24407 [D loss: 0.580953, acc.: 68.75%] [G loss: 1.267031]\n",
      "epoch:26 step:24408 [D loss: 0.684115, acc.: 58.59%] [G loss: 1.106467]\n",
      "epoch:26 step:24409 [D loss: 0.577860, acc.: 68.75%] [G loss: 1.208935]\n",
      "epoch:26 step:24410 [D loss: 0.634766, acc.: 64.84%] [G loss: 1.436223]\n",
      "epoch:26 step:24411 [D loss: 0.604579, acc.: 70.31%] [G loss: 1.257046]\n",
      "epoch:26 step:24412 [D loss: 0.460836, acc.: 79.69%] [G loss: 1.416500]\n",
      "epoch:26 step:24413 [D loss: 0.611498, acc.: 69.53%] [G loss: 1.529922]\n",
      "epoch:26 step:24414 [D loss: 0.683446, acc.: 60.94%] [G loss: 1.426062]\n",
      "epoch:26 step:24415 [D loss: 0.622033, acc.: 64.06%] [G loss: 1.453127]\n",
      "epoch:26 step:24416 [D loss: 0.621334, acc.: 60.94%] [G loss: 1.139292]\n",
      "epoch:26 step:24417 [D loss: 0.476878, acc.: 75.78%] [G loss: 1.516703]\n",
      "epoch:26 step:24418 [D loss: 0.482361, acc.: 75.78%] [G loss: 1.292459]\n",
      "epoch:26 step:24419 [D loss: 0.386754, acc.: 87.50%] [G loss: 1.568246]\n",
      "epoch:26 step:24420 [D loss: 0.660552, acc.: 64.84%] [G loss: 1.185665]\n",
      "epoch:26 step:24421 [D loss: 0.405872, acc.: 84.38%] [G loss: 1.269581]\n",
      "epoch:26 step:24422 [D loss: 0.473603, acc.: 77.34%] [G loss: 1.363967]\n",
      "epoch:26 step:24423 [D loss: 0.676685, acc.: 63.28%] [G loss: 1.383049]\n",
      "epoch:26 step:24424 [D loss: 0.606778, acc.: 63.28%] [G loss: 1.400230]\n",
      "epoch:26 step:24425 [D loss: 0.697062, acc.: 59.38%] [G loss: 1.594917]\n",
      "epoch:26 step:24426 [D loss: 0.515842, acc.: 75.78%] [G loss: 1.647939]\n",
      "epoch:26 step:24427 [D loss: 0.507133, acc.: 73.44%] [G loss: 1.481554]\n",
      "epoch:26 step:24428 [D loss: 0.535134, acc.: 73.44%] [G loss: 1.309325]\n",
      "epoch:26 step:24429 [D loss: 0.616099, acc.: 71.09%] [G loss: 1.855575]\n",
      "epoch:26 step:24430 [D loss: 0.495925, acc.: 75.78%] [G loss: 1.345563]\n",
      "epoch:26 step:24431 [D loss: 0.574737, acc.: 66.41%] [G loss: 1.307012]\n",
      "epoch:26 step:24432 [D loss: 0.569008, acc.: 66.41%] [G loss: 1.443024]\n",
      "epoch:26 step:24433 [D loss: 0.561191, acc.: 73.44%] [G loss: 1.218755]\n",
      "epoch:26 step:24434 [D loss: 0.554620, acc.: 73.44%] [G loss: 1.402790]\n",
      "epoch:26 step:24435 [D loss: 0.457115, acc.: 79.69%] [G loss: 1.427637]\n",
      "epoch:26 step:24436 [D loss: 0.598029, acc.: 68.75%] [G loss: 1.713168]\n",
      "epoch:26 step:24437 [D loss: 0.475673, acc.: 82.81%] [G loss: 1.563420]\n",
      "epoch:26 step:24438 [D loss: 0.604511, acc.: 63.28%] [G loss: 1.137449]\n",
      "epoch:26 step:24439 [D loss: 0.610080, acc.: 57.03%] [G loss: 1.479278]\n",
      "epoch:26 step:24440 [D loss: 0.542042, acc.: 68.75%] [G loss: 1.391071]\n",
      "epoch:26 step:24441 [D loss: 0.604399, acc.: 66.41%] [G loss: 1.477977]\n",
      "epoch:26 step:24442 [D loss: 0.406936, acc.: 86.72%] [G loss: 1.069968]\n",
      "epoch:26 step:24443 [D loss: 0.671679, acc.: 60.94%] [G loss: 1.523295]\n",
      "epoch:26 step:24444 [D loss: 0.419656, acc.: 83.59%] [G loss: 1.408935]\n",
      "epoch:26 step:24445 [D loss: 0.541909, acc.: 78.12%] [G loss: 1.253976]\n",
      "epoch:26 step:24446 [D loss: 0.587861, acc.: 71.09%] [G loss: 1.519741]\n",
      "epoch:26 step:24447 [D loss: 0.494923, acc.: 74.22%] [G loss: 1.331778]\n",
      "epoch:26 step:24448 [D loss: 0.647627, acc.: 59.38%] [G loss: 1.689631]\n",
      "epoch:26 step:24449 [D loss: 0.605107, acc.: 68.75%] [G loss: 1.562646]\n",
      "epoch:26 step:24450 [D loss: 0.517759, acc.: 75.78%] [G loss: 1.444110]\n",
      "epoch:26 step:24451 [D loss: 0.542705, acc.: 73.44%] [G loss: 1.360882]\n",
      "epoch:26 step:24452 [D loss: 0.580599, acc.: 71.88%] [G loss: 1.414069]\n",
      "epoch:26 step:24453 [D loss: 0.529609, acc.: 74.22%] [G loss: 1.509785]\n",
      "epoch:26 step:24454 [D loss: 0.375034, acc.: 85.94%] [G loss: 1.617930]\n",
      "epoch:26 step:24455 [D loss: 0.446210, acc.: 81.25%] [G loss: 1.434284]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:26 step:24456 [D loss: 0.587717, acc.: 70.31%] [G loss: 1.643003]\n",
      "epoch:26 step:24457 [D loss: 0.785376, acc.: 53.12%] [G loss: 1.267774]\n",
      "epoch:26 step:24458 [D loss: 0.565697, acc.: 69.53%] [G loss: 1.858737]\n",
      "epoch:26 step:24459 [D loss: 0.637440, acc.: 67.19%] [G loss: 1.105570]\n",
      "epoch:26 step:24460 [D loss: 0.483155, acc.: 78.91%] [G loss: 1.301693]\n",
      "epoch:26 step:24461 [D loss: 0.533947, acc.: 71.09%] [G loss: 1.373644]\n",
      "epoch:26 step:24462 [D loss: 0.533866, acc.: 74.22%] [G loss: 1.181414]\n",
      "epoch:26 step:24463 [D loss: 0.446886, acc.: 74.22%] [G loss: 1.246009]\n",
      "epoch:26 step:24464 [D loss: 0.538212, acc.: 72.66%] [G loss: 1.380455]\n",
      "epoch:26 step:24465 [D loss: 0.520820, acc.: 76.56%] [G loss: 1.455380]\n",
      "epoch:26 step:24466 [D loss: 0.541544, acc.: 74.22%] [G loss: 1.437665]\n",
      "epoch:26 step:24467 [D loss: 0.515989, acc.: 78.12%] [G loss: 1.247020]\n",
      "epoch:26 step:24468 [D loss: 0.623243, acc.: 64.06%] [G loss: 1.242500]\n",
      "epoch:26 step:24469 [D loss: 0.497849, acc.: 78.91%] [G loss: 1.281271]\n",
      "epoch:26 step:24470 [D loss: 0.617687, acc.: 63.28%] [G loss: 0.981069]\n",
      "epoch:26 step:24471 [D loss: 0.623237, acc.: 62.50%] [G loss: 1.425502]\n",
      "epoch:26 step:24472 [D loss: 0.680710, acc.: 61.72%] [G loss: 1.407668]\n",
      "epoch:26 step:24473 [D loss: 0.758711, acc.: 55.47%] [G loss: 1.372304]\n",
      "epoch:26 step:24474 [D loss: 0.687590, acc.: 55.47%] [G loss: 1.536856]\n",
      "epoch:26 step:24475 [D loss: 0.469695, acc.: 79.69%] [G loss: 1.556583]\n",
      "epoch:26 step:24476 [D loss: 0.477095, acc.: 78.91%] [G loss: 1.310209]\n",
      "epoch:26 step:24477 [D loss: 0.323408, acc.: 85.94%] [G loss: 1.670232]\n",
      "epoch:26 step:24478 [D loss: 0.646779, acc.: 69.53%] [G loss: 1.200918]\n",
      "epoch:26 step:24479 [D loss: 0.567762, acc.: 72.66%] [G loss: 1.808298]\n",
      "epoch:26 step:24480 [D loss: 0.608318, acc.: 66.41%] [G loss: 1.455719]\n",
      "epoch:26 step:24481 [D loss: 0.499389, acc.: 75.00%] [G loss: 1.166368]\n",
      "epoch:26 step:24482 [D loss: 0.668995, acc.: 67.19%] [G loss: 1.475370]\n",
      "epoch:26 step:24483 [D loss: 0.463165, acc.: 80.47%] [G loss: 1.885623]\n",
      "epoch:26 step:24484 [D loss: 0.439442, acc.: 82.81%] [G loss: 1.417442]\n",
      "epoch:26 step:24485 [D loss: 0.537716, acc.: 71.88%] [G loss: 1.512188]\n",
      "epoch:26 step:24486 [D loss: 0.743548, acc.: 60.94%] [G loss: 1.506899]\n",
      "epoch:26 step:24487 [D loss: 0.599494, acc.: 67.19%] [G loss: 1.378765]\n",
      "epoch:26 step:24488 [D loss: 0.429865, acc.: 83.59%] [G loss: 1.149788]\n",
      "epoch:26 step:24489 [D loss: 0.614012, acc.: 62.50%] [G loss: 1.520576]\n",
      "epoch:26 step:24490 [D loss: 0.632820, acc.: 62.50%] [G loss: 1.177148]\n",
      "epoch:26 step:24491 [D loss: 0.491421, acc.: 79.69%] [G loss: 1.545187]\n",
      "epoch:26 step:24492 [D loss: 0.657544, acc.: 64.06%] [G loss: 1.211963]\n",
      "epoch:26 step:24493 [D loss: 0.551507, acc.: 73.44%] [G loss: 1.675469]\n",
      "epoch:26 step:24494 [D loss: 0.519142, acc.: 75.00%] [G loss: 1.273254]\n",
      "epoch:26 step:24495 [D loss: 0.389726, acc.: 88.28%] [G loss: 1.872717]\n",
      "epoch:26 step:24496 [D loss: 0.634376, acc.: 65.62%] [G loss: 1.329902]\n",
      "epoch:26 step:24497 [D loss: 0.603557, acc.: 65.62%] [G loss: 1.261029]\n",
      "epoch:26 step:24498 [D loss: 0.649472, acc.: 58.59%] [G loss: 1.471099]\n",
      "epoch:26 step:24499 [D loss: 0.611175, acc.: 64.06%] [G loss: 1.350785]\n",
      "epoch:26 step:24500 [D loss: 0.518884, acc.: 73.44%] [G loss: 1.417526]\n",
      "epoch:26 step:24501 [D loss: 0.614171, acc.: 61.72%] [G loss: 1.293700]\n",
      "epoch:26 step:24502 [D loss: 0.666640, acc.: 63.28%] [G loss: 1.200384]\n",
      "epoch:26 step:24503 [D loss: 0.627545, acc.: 63.28%] [G loss: 1.031792]\n",
      "epoch:26 step:24504 [D loss: 0.528108, acc.: 72.66%] [G loss: 1.182090]\n",
      "epoch:26 step:24505 [D loss: 0.531777, acc.: 71.09%] [G loss: 1.862866]\n",
      "epoch:26 step:24506 [D loss: 0.405261, acc.: 84.38%] [G loss: 1.288737]\n",
      "epoch:26 step:24507 [D loss: 0.556360, acc.: 69.53%] [G loss: 1.635331]\n",
      "epoch:26 step:24508 [D loss: 0.520063, acc.: 76.56%] [G loss: 1.369166]\n",
      "epoch:26 step:24509 [D loss: 0.459467, acc.: 78.91%] [G loss: 1.335864]\n",
      "epoch:26 step:24510 [D loss: 0.517668, acc.: 73.44%] [G loss: 1.357932]\n",
      "epoch:26 step:24511 [D loss: 0.637577, acc.: 68.75%] [G loss: 1.176479]\n",
      "epoch:26 step:24512 [D loss: 0.558847, acc.: 65.62%] [G loss: 1.413806]\n",
      "epoch:26 step:24513 [D loss: 0.520309, acc.: 76.56%] [G loss: 1.507244]\n",
      "epoch:26 step:24514 [D loss: 0.422833, acc.: 82.03%] [G loss: 1.577715]\n",
      "epoch:26 step:24515 [D loss: 0.530725, acc.: 75.00%] [G loss: 1.433894]\n",
      "epoch:26 step:24516 [D loss: 0.471178, acc.: 78.91%] [G loss: 1.132980]\n",
      "epoch:26 step:24517 [D loss: 0.606806, acc.: 69.53%] [G loss: 1.465452]\n",
      "epoch:26 step:24518 [D loss: 0.644962, acc.: 62.50%] [G loss: 1.290000]\n",
      "epoch:26 step:24519 [D loss: 0.692889, acc.: 57.03%] [G loss: 1.087273]\n",
      "epoch:26 step:24520 [D loss: 0.434534, acc.: 83.59%] [G loss: 0.913666]\n",
      "epoch:26 step:24521 [D loss: 0.437267, acc.: 82.03%] [G loss: 1.286836]\n",
      "epoch:26 step:24522 [D loss: 0.483848, acc.: 78.12%] [G loss: 1.392234]\n",
      "epoch:26 step:24523 [D loss: 0.428229, acc.: 83.59%] [G loss: 1.673489]\n",
      "epoch:26 step:24524 [D loss: 0.581887, acc.: 67.97%] [G loss: 1.254529]\n",
      "epoch:26 step:24525 [D loss: 0.812731, acc.: 54.69%] [G loss: 1.518836]\n",
      "epoch:26 step:24526 [D loss: 0.516190, acc.: 72.66%] [G loss: 1.390120]\n",
      "epoch:26 step:24527 [D loss: 0.508454, acc.: 77.34%] [G loss: 1.415599]\n",
      "epoch:26 step:24528 [D loss: 0.674054, acc.: 59.38%] [G loss: 1.445158]\n",
      "epoch:26 step:24529 [D loss: 0.712652, acc.: 59.38%] [G loss: 1.408546]\n",
      "epoch:26 step:24530 [D loss: 0.533397, acc.: 72.66%] [G loss: 1.258164]\n",
      "epoch:26 step:24531 [D loss: 0.663532, acc.: 62.50%] [G loss: 1.254304]\n",
      "epoch:26 step:24532 [D loss: 0.429270, acc.: 85.94%] [G loss: 1.603753]\n",
      "epoch:26 step:24533 [D loss: 0.781371, acc.: 49.22%] [G loss: 1.332216]\n",
      "epoch:26 step:24534 [D loss: 0.484838, acc.: 75.00%] [G loss: 1.369820]\n",
      "epoch:26 step:24535 [D loss: 0.645229, acc.: 61.72%] [G loss: 1.466204]\n",
      "epoch:26 step:24536 [D loss: 0.476231, acc.: 77.34%] [G loss: 1.913768]\n",
      "epoch:26 step:24537 [D loss: 0.670571, acc.: 62.50%] [G loss: 1.264282]\n",
      "epoch:26 step:24538 [D loss: 0.546287, acc.: 75.78%] [G loss: 1.586468]\n",
      "epoch:26 step:24539 [D loss: 0.418672, acc.: 82.81%] [G loss: 1.421528]\n",
      "epoch:26 step:24540 [D loss: 0.585276, acc.: 67.97%] [G loss: 1.115082]\n",
      "epoch:26 step:24541 [D loss: 0.389079, acc.: 85.94%] [G loss: 1.732620]\n",
      "epoch:26 step:24542 [D loss: 0.569327, acc.: 74.22%] [G loss: 1.188317]\n",
      "epoch:26 step:24543 [D loss: 0.376657, acc.: 85.94%] [G loss: 1.492843]\n",
      "epoch:26 step:24544 [D loss: 0.386743, acc.: 82.81%] [G loss: 1.773326]\n",
      "epoch:26 step:24545 [D loss: 0.574534, acc.: 71.09%] [G loss: 1.339320]\n",
      "epoch:26 step:24546 [D loss: 0.694435, acc.: 59.38%] [G loss: 1.214949]\n",
      "epoch:26 step:24547 [D loss: 0.452037, acc.: 84.38%] [G loss: 1.773060]\n",
      "epoch:26 step:24548 [D loss: 0.481403, acc.: 78.12%] [G loss: 1.520477]\n",
      "epoch:26 step:24549 [D loss: 0.437805, acc.: 78.91%] [G loss: 1.498682]\n",
      "epoch:26 step:24550 [D loss: 0.529855, acc.: 75.00%] [G loss: 1.110315]\n",
      "epoch:26 step:24551 [D loss: 0.628671, acc.: 64.06%] [G loss: 1.669009]\n",
      "epoch:26 step:24552 [D loss: 0.564607, acc.: 72.66%] [G loss: 1.252708]\n",
      "epoch:26 step:24553 [D loss: 0.636844, acc.: 67.19%] [G loss: 1.375587]\n",
      "epoch:26 step:24554 [D loss: 0.603897, acc.: 70.31%] [G loss: 1.616951]\n",
      "epoch:26 step:24555 [D loss: 0.650599, acc.: 63.28%] [G loss: 1.202971]\n",
      "epoch:26 step:24556 [D loss: 0.591519, acc.: 68.75%] [G loss: 1.600686]\n",
      "epoch:26 step:24557 [D loss: 0.684272, acc.: 67.19%] [G loss: 1.035475]\n",
      "epoch:26 step:24558 [D loss: 0.482257, acc.: 75.78%] [G loss: 1.431659]\n",
      "epoch:26 step:24559 [D loss: 0.482350, acc.: 77.34%] [G loss: 1.482467]\n",
      "epoch:26 step:24560 [D loss: 0.566631, acc.: 72.66%] [G loss: 1.767161]\n",
      "epoch:26 step:24561 [D loss: 0.462533, acc.: 83.59%] [G loss: 1.711056]\n",
      "epoch:26 step:24562 [D loss: 0.758020, acc.: 52.34%] [G loss: 1.379436]\n",
      "epoch:26 step:24563 [D loss: 0.332960, acc.: 89.06%] [G loss: 1.361726]\n",
      "epoch:26 step:24564 [D loss: 0.481356, acc.: 80.47%] [G loss: 1.383882]\n",
      "epoch:26 step:24565 [D loss: 0.418666, acc.: 82.03%] [G loss: 1.655179]\n",
      "epoch:26 step:24566 [D loss: 0.478247, acc.: 79.69%] [G loss: 1.579602]\n",
      "epoch:26 step:24567 [D loss: 0.604314, acc.: 65.62%] [G loss: 1.639204]\n",
      "epoch:26 step:24568 [D loss: 0.392775, acc.: 84.38%] [G loss: 1.328783]\n",
      "epoch:26 step:24569 [D loss: 0.648304, acc.: 61.72%] [G loss: 1.384427]\n",
      "epoch:26 step:24570 [D loss: 0.555019, acc.: 72.66%] [G loss: 1.393036]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:26 step:24571 [D loss: 0.612092, acc.: 64.06%] [G loss: 1.104382]\n",
      "epoch:26 step:24572 [D loss: 0.541411, acc.: 72.66%] [G loss: 1.380850]\n",
      "epoch:26 step:24573 [D loss: 0.469673, acc.: 82.81%] [G loss: 1.261269]\n",
      "epoch:26 step:24574 [D loss: 0.390279, acc.: 86.72%] [G loss: 1.369301]\n",
      "epoch:26 step:24575 [D loss: 0.591988, acc.: 72.66%] [G loss: 1.300800]\n",
      "epoch:26 step:24576 [D loss: 0.498974, acc.: 78.91%] [G loss: 1.345276]\n",
      "epoch:26 step:24577 [D loss: 0.628074, acc.: 64.84%] [G loss: 1.366193]\n",
      "epoch:26 step:24578 [D loss: 0.587897, acc.: 66.41%] [G loss: 1.425272]\n",
      "epoch:26 step:24579 [D loss: 0.434827, acc.: 82.81%] [G loss: 1.277420]\n",
      "epoch:26 step:24580 [D loss: 0.527524, acc.: 70.31%] [G loss: 1.402684]\n",
      "epoch:26 step:24581 [D loss: 0.574991, acc.: 69.53%] [G loss: 1.291311]\n",
      "epoch:26 step:24582 [D loss: 0.516141, acc.: 77.34%] [G loss: 1.358187]\n",
      "epoch:26 step:24583 [D loss: 0.569607, acc.: 71.09%] [G loss: 1.543151]\n",
      "epoch:26 step:24584 [D loss: 0.496106, acc.: 78.91%] [G loss: 1.379290]\n",
      "epoch:26 step:24585 [D loss: 0.540135, acc.: 71.09%] [G loss: 1.604318]\n",
      "epoch:26 step:24586 [D loss: 0.446451, acc.: 79.69%] [G loss: 1.600267]\n",
      "epoch:26 step:24587 [D loss: 0.479542, acc.: 80.47%] [G loss: 1.347507]\n",
      "epoch:26 step:24588 [D loss: 0.558830, acc.: 71.88%] [G loss: 1.997696]\n",
      "epoch:26 step:24589 [D loss: 0.502137, acc.: 75.78%] [G loss: 1.689703]\n",
      "epoch:26 step:24590 [D loss: 0.505162, acc.: 76.56%] [G loss: 1.937372]\n",
      "epoch:26 step:24591 [D loss: 0.456596, acc.: 81.25%] [G loss: 1.796266]\n",
      "epoch:26 step:24592 [D loss: 0.732139, acc.: 58.59%] [G loss: 1.321297]\n",
      "epoch:26 step:24593 [D loss: 0.526606, acc.: 72.66%] [G loss: 1.169210]\n",
      "epoch:26 step:24594 [D loss: 0.628380, acc.: 64.84%] [G loss: 1.506062]\n",
      "epoch:26 step:24595 [D loss: 0.627428, acc.: 66.41%] [G loss: 1.517991]\n",
      "epoch:26 step:24596 [D loss: 0.631069, acc.: 61.72%] [G loss: 1.328541]\n",
      "epoch:26 step:24597 [D loss: 0.588607, acc.: 67.19%] [G loss: 1.310746]\n",
      "epoch:26 step:24598 [D loss: 0.507042, acc.: 72.66%] [G loss: 1.280977]\n",
      "epoch:26 step:24599 [D loss: 0.577640, acc.: 71.88%] [G loss: 1.299504]\n",
      "epoch:26 step:24600 [D loss: 0.593337, acc.: 69.53%] [G loss: 1.620796]\n",
      "epoch:26 step:24601 [D loss: 0.643264, acc.: 67.19%] [G loss: 0.901199]\n",
      "epoch:26 step:24602 [D loss: 0.649897, acc.: 64.06%] [G loss: 1.436285]\n",
      "epoch:26 step:24603 [D loss: 0.538187, acc.: 71.09%] [G loss: 1.042194]\n",
      "epoch:26 step:24604 [D loss: 0.565439, acc.: 73.44%] [G loss: 1.047495]\n",
      "epoch:26 step:24605 [D loss: 0.614150, acc.: 69.53%] [G loss: 1.581605]\n",
      "epoch:26 step:24606 [D loss: 0.559503, acc.: 68.75%] [G loss: 1.206774]\n",
      "epoch:26 step:24607 [D loss: 0.475186, acc.: 76.56%] [G loss: 1.740481]\n",
      "epoch:26 step:24608 [D loss: 0.593760, acc.: 67.97%] [G loss: 1.787457]\n",
      "epoch:26 step:24609 [D loss: 0.705629, acc.: 58.59%] [G loss: 1.496773]\n",
      "epoch:26 step:24610 [D loss: 0.585119, acc.: 73.44%] [G loss: 1.377012]\n",
      "epoch:26 step:24611 [D loss: 0.407710, acc.: 85.94%] [G loss: 1.562570]\n",
      "epoch:26 step:24612 [D loss: 0.685055, acc.: 63.28%] [G loss: 1.261910]\n",
      "epoch:26 step:24613 [D loss: 0.566896, acc.: 67.97%] [G loss: 1.103620]\n",
      "epoch:26 step:24614 [D loss: 0.533525, acc.: 74.22%] [G loss: 1.398532]\n",
      "epoch:26 step:24615 [D loss: 0.686791, acc.: 61.72%] [G loss: 1.344675]\n",
      "epoch:26 step:24616 [D loss: 0.521958, acc.: 74.22%] [G loss: 1.536197]\n",
      "epoch:26 step:24617 [D loss: 0.559145, acc.: 71.09%] [G loss: 1.447305]\n",
      "epoch:26 step:24618 [D loss: 0.493734, acc.: 77.34%] [G loss: 1.488700]\n",
      "epoch:26 step:24619 [D loss: 0.510113, acc.: 78.91%] [G loss: 1.261724]\n",
      "epoch:26 step:24620 [D loss: 0.622239, acc.: 69.53%] [G loss: 1.430836]\n",
      "epoch:26 step:24621 [D loss: 0.455392, acc.: 82.03%] [G loss: 1.732046]\n",
      "epoch:26 step:24622 [D loss: 0.661671, acc.: 63.28%] [G loss: 1.235291]\n",
      "epoch:26 step:24623 [D loss: 0.430346, acc.: 85.94%] [G loss: 1.694036]\n",
      "epoch:26 step:24624 [D loss: 0.585679, acc.: 64.84%] [G loss: 1.319556]\n",
      "epoch:26 step:24625 [D loss: 0.622416, acc.: 64.84%] [G loss: 1.327536]\n",
      "epoch:26 step:24626 [D loss: 0.486812, acc.: 78.12%] [G loss: 1.511685]\n",
      "epoch:26 step:24627 [D loss: 0.320755, acc.: 89.84%] [G loss: 1.661437]\n",
      "epoch:26 step:24628 [D loss: 0.572435, acc.: 71.09%] [G loss: 1.114051]\n",
      "epoch:26 step:24629 [D loss: 0.498046, acc.: 75.00%] [G loss: 1.950837]\n",
      "epoch:26 step:24630 [D loss: 0.442659, acc.: 80.47%] [G loss: 1.447888]\n",
      "epoch:26 step:24631 [D loss: 0.408600, acc.: 80.47%] [G loss: 1.456232]\n",
      "epoch:26 step:24632 [D loss: 0.550968, acc.: 74.22%] [G loss: 1.757956]\n",
      "epoch:26 step:24633 [D loss: 0.460959, acc.: 78.91%] [G loss: 1.792952]\n",
      "epoch:26 step:24634 [D loss: 0.634865, acc.: 63.28%] [G loss: 1.430542]\n",
      "epoch:26 step:24635 [D loss: 0.466082, acc.: 81.25%] [G loss: 1.325778]\n",
      "epoch:26 step:24636 [D loss: 0.576499, acc.: 68.75%] [G loss: 1.277680]\n",
      "epoch:26 step:24637 [D loss: 0.692349, acc.: 61.72%] [G loss: 1.142876]\n",
      "epoch:26 step:24638 [D loss: 0.542107, acc.: 73.44%] [G loss: 1.425145]\n",
      "epoch:26 step:24639 [D loss: 0.541820, acc.: 68.75%] [G loss: 1.160176]\n",
      "epoch:26 step:24640 [D loss: 0.549339, acc.: 71.09%] [G loss: 1.012768]\n",
      "epoch:26 step:24641 [D loss: 0.465126, acc.: 78.91%] [G loss: 1.538746]\n",
      "epoch:26 step:24642 [D loss: 0.567828, acc.: 67.19%] [G loss: 1.182711]\n",
      "epoch:26 step:24643 [D loss: 0.432286, acc.: 76.56%] [G loss: 1.372057]\n",
      "epoch:26 step:24644 [D loss: 0.574027, acc.: 68.75%] [G loss: 1.160910]\n",
      "epoch:26 step:24645 [D loss: 0.436263, acc.: 78.12%] [G loss: 1.651229]\n",
      "epoch:26 step:24646 [D loss: 0.415868, acc.: 85.16%] [G loss: 1.441255]\n",
      "epoch:26 step:24647 [D loss: 0.537818, acc.: 73.44%] [G loss: 1.557456]\n",
      "epoch:26 step:24648 [D loss: 0.487316, acc.: 77.34%] [G loss: 1.338110]\n",
      "epoch:26 step:24649 [D loss: 0.643646, acc.: 64.84%] [G loss: 1.320142]\n",
      "epoch:26 step:24650 [D loss: 0.882528, acc.: 44.53%] [G loss: 0.976478]\n",
      "epoch:26 step:24651 [D loss: 0.421632, acc.: 85.16%] [G loss: 1.357913]\n",
      "epoch:26 step:24652 [D loss: 0.403805, acc.: 85.16%] [G loss: 1.216485]\n",
      "epoch:26 step:24653 [D loss: 0.496146, acc.: 76.56%] [G loss: 1.264300]\n",
      "epoch:26 step:24654 [D loss: 0.670308, acc.: 58.59%] [G loss: 1.328374]\n",
      "epoch:26 step:24655 [D loss: 0.537551, acc.: 72.66%] [G loss: 1.248800]\n",
      "epoch:26 step:24656 [D loss: 0.555774, acc.: 70.31%] [G loss: 1.415675]\n",
      "epoch:26 step:24657 [D loss: 0.589557, acc.: 69.53%] [G loss: 1.306531]\n",
      "epoch:26 step:24658 [D loss: 0.565051, acc.: 71.88%] [G loss: 1.588143]\n",
      "epoch:26 step:24659 [D loss: 0.819752, acc.: 50.78%] [G loss: 1.064463]\n",
      "epoch:26 step:24660 [D loss: 0.711496, acc.: 58.59%] [G loss: 1.619293]\n",
      "epoch:26 step:24661 [D loss: 0.654570, acc.: 59.38%] [G loss: 1.186886]\n",
      "epoch:26 step:24662 [D loss: 0.432350, acc.: 82.03%] [G loss: 1.796835]\n",
      "epoch:26 step:24663 [D loss: 0.733917, acc.: 57.81%] [G loss: 1.054712]\n",
      "epoch:26 step:24664 [D loss: 0.720367, acc.: 60.94%] [G loss: 1.217554]\n",
      "epoch:26 step:24665 [D loss: 0.641580, acc.: 62.50%] [G loss: 1.580606]\n",
      "epoch:26 step:24666 [D loss: 0.511065, acc.: 79.69%] [G loss: 1.311348]\n",
      "epoch:26 step:24667 [D loss: 0.557521, acc.: 69.53%] [G loss: 0.994349]\n",
      "epoch:26 step:24668 [D loss: 0.692593, acc.: 66.41%] [G loss: 1.386266]\n",
      "epoch:26 step:24669 [D loss: 0.629480, acc.: 63.28%] [G loss: 1.156985]\n",
      "epoch:26 step:24670 [D loss: 0.482208, acc.: 80.47%] [G loss: 1.435325]\n",
      "epoch:26 step:24671 [D loss: 0.498110, acc.: 79.69%] [G loss: 1.390886]\n",
      "epoch:26 step:24672 [D loss: 0.543731, acc.: 64.84%] [G loss: 1.737788]\n",
      "epoch:26 step:24673 [D loss: 0.581032, acc.: 67.97%] [G loss: 1.886187]\n",
      "epoch:26 step:24674 [D loss: 0.570238, acc.: 67.97%] [G loss: 1.226912]\n",
      "epoch:26 step:24675 [D loss: 0.697893, acc.: 59.38%] [G loss: 1.147974]\n",
      "epoch:26 step:24676 [D loss: 0.424773, acc.: 83.59%] [G loss: 1.602013]\n",
      "epoch:26 step:24677 [D loss: 0.653365, acc.: 60.94%] [G loss: 1.290240]\n",
      "epoch:26 step:24678 [D loss: 0.735247, acc.: 53.91%] [G loss: 1.165949]\n",
      "epoch:26 step:24679 [D loss: 0.537458, acc.: 74.22%] [G loss: 1.500219]\n",
      "epoch:26 step:24680 [D loss: 0.621897, acc.: 65.62%] [G loss: 1.571340]\n",
      "epoch:26 step:24681 [D loss: 0.632613, acc.: 60.16%] [G loss: 1.079044]\n",
      "epoch:26 step:24682 [D loss: 0.521711, acc.: 73.44%] [G loss: 1.311032]\n",
      "epoch:26 step:24683 [D loss: 0.601610, acc.: 66.41%] [G loss: 1.236275]\n",
      "epoch:26 step:24684 [D loss: 0.413655, acc.: 82.81%] [G loss: 1.611079]\n",
      "epoch:26 step:24685 [D loss: 0.513864, acc.: 70.31%] [G loss: 1.175141]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:26 step:24686 [D loss: 0.611532, acc.: 67.19%] [G loss: 1.233713]\n",
      "epoch:26 step:24687 [D loss: 0.494725, acc.: 71.88%] [G loss: 1.641631]\n",
      "epoch:26 step:24688 [D loss: 0.483010, acc.: 76.56%] [G loss: 1.270580]\n",
      "epoch:26 step:24689 [D loss: 0.541056, acc.: 75.00%] [G loss: 1.516077]\n",
      "epoch:26 step:24690 [D loss: 0.512026, acc.: 71.88%] [G loss: 1.411240]\n",
      "epoch:26 step:24691 [D loss: 0.570374, acc.: 68.75%] [G loss: 1.389075]\n",
      "epoch:26 step:24692 [D loss: 0.645789, acc.: 66.41%] [G loss: 1.336960]\n",
      "epoch:26 step:24693 [D loss: 0.512744, acc.: 76.56%] [G loss: 1.471299]\n",
      "epoch:26 step:24694 [D loss: 0.516719, acc.: 78.91%] [G loss: 1.176799]\n",
      "epoch:26 step:24695 [D loss: 0.562017, acc.: 74.22%] [G loss: 1.420904]\n",
      "epoch:26 step:24696 [D loss: 0.632959, acc.: 66.41%] [G loss: 1.285996]\n",
      "epoch:26 step:24697 [D loss: 0.566780, acc.: 76.56%] [G loss: 1.523290]\n",
      "epoch:26 step:24698 [D loss: 0.530250, acc.: 75.78%] [G loss: 1.279605]\n",
      "epoch:26 step:24699 [D loss: 0.501383, acc.: 77.34%] [G loss: 1.345063]\n",
      "epoch:26 step:24700 [D loss: 0.434186, acc.: 81.25%] [G loss: 1.280397]\n",
      "epoch:26 step:24701 [D loss: 0.584230, acc.: 69.53%] [G loss: 1.176708]\n",
      "epoch:26 step:24702 [D loss: 0.378920, acc.: 85.94%] [G loss: 1.257568]\n",
      "epoch:26 step:24703 [D loss: 0.782170, acc.: 51.56%] [G loss: 1.306120]\n",
      "epoch:26 step:24704 [D loss: 0.461264, acc.: 79.69%] [G loss: 1.787734]\n",
      "epoch:26 step:24705 [D loss: 0.593652, acc.: 69.53%] [G loss: 1.546683]\n",
      "epoch:26 step:24706 [D loss: 0.600954, acc.: 62.50%] [G loss: 1.252434]\n",
      "epoch:26 step:24707 [D loss: 0.500667, acc.: 75.78%] [G loss: 1.577806]\n",
      "epoch:26 step:24708 [D loss: 0.700285, acc.: 59.38%] [G loss: 1.309126]\n",
      "epoch:26 step:24709 [D loss: 0.613629, acc.: 61.72%] [G loss: 1.312851]\n",
      "epoch:26 step:24710 [D loss: 0.465404, acc.: 80.47%] [G loss: 1.023656]\n",
      "epoch:26 step:24711 [D loss: 0.661053, acc.: 64.84%] [G loss: 1.304547]\n",
      "epoch:26 step:24712 [D loss: 0.407429, acc.: 85.16%] [G loss: 1.621334]\n",
      "epoch:26 step:24713 [D loss: 0.492641, acc.: 73.44%] [G loss: 1.581528]\n",
      "epoch:26 step:24714 [D loss: 0.706571, acc.: 55.47%] [G loss: 1.118975]\n",
      "epoch:26 step:24715 [D loss: 0.694011, acc.: 61.72%] [G loss: 1.189417]\n",
      "epoch:26 step:24716 [D loss: 0.665998, acc.: 60.16%] [G loss: 1.374684]\n",
      "epoch:26 step:24717 [D loss: 0.532320, acc.: 75.78%] [G loss: 1.816305]\n",
      "epoch:26 step:24718 [D loss: 0.503549, acc.: 74.22%] [G loss: 1.277092]\n",
      "epoch:26 step:24719 [D loss: 0.512454, acc.: 75.78%] [G loss: 1.460915]\n",
      "epoch:26 step:24720 [D loss: 0.598527, acc.: 67.97%] [G loss: 1.472617]\n",
      "epoch:26 step:24721 [D loss: 0.557935, acc.: 71.09%] [G loss: 1.498041]\n",
      "epoch:26 step:24722 [D loss: 0.425300, acc.: 84.38%] [G loss: 1.222358]\n",
      "epoch:26 step:24723 [D loss: 0.596893, acc.: 61.72%] [G loss: 1.535881]\n",
      "epoch:26 step:24724 [D loss: 1.029249, acc.: 37.50%] [G loss: 0.972720]\n",
      "epoch:26 step:24725 [D loss: 0.519489, acc.: 71.09%] [G loss: 1.528260]\n",
      "epoch:26 step:24726 [D loss: 0.496788, acc.: 76.56%] [G loss: 1.326544]\n",
      "epoch:26 step:24727 [D loss: 0.595112, acc.: 66.41%] [G loss: 1.210593]\n",
      "epoch:26 step:24728 [D loss: 0.440864, acc.: 82.81%] [G loss: 1.541702]\n",
      "epoch:26 step:24729 [D loss: 0.574480, acc.: 71.09%] [G loss: 1.398185]\n",
      "epoch:26 step:24730 [D loss: 0.753043, acc.: 57.81%] [G loss: 1.401327]\n",
      "epoch:26 step:24731 [D loss: 0.499802, acc.: 75.78%] [G loss: 1.760584]\n",
      "epoch:26 step:24732 [D loss: 0.515444, acc.: 75.00%] [G loss: 1.668403]\n",
      "epoch:26 step:24733 [D loss: 0.444892, acc.: 81.25%] [G loss: 1.822325]\n",
      "epoch:26 step:24734 [D loss: 0.505548, acc.: 73.44%] [G loss: 1.667973]\n",
      "epoch:26 step:24735 [D loss: 0.620282, acc.: 67.97%] [G loss: 1.186222]\n",
      "epoch:26 step:24736 [D loss: 0.659863, acc.: 63.28%] [G loss: 1.198734]\n",
      "epoch:26 step:24737 [D loss: 0.533207, acc.: 76.56%] [G loss: 1.785085]\n",
      "epoch:26 step:24738 [D loss: 0.707750, acc.: 58.59%] [G loss: 1.221804]\n",
      "epoch:26 step:24739 [D loss: 0.325003, acc.: 89.06%] [G loss: 1.443241]\n",
      "epoch:26 step:24740 [D loss: 0.643451, acc.: 63.28%] [G loss: 1.420747]\n",
      "epoch:26 step:24741 [D loss: 0.563028, acc.: 70.31%] [G loss: 1.017120]\n",
      "epoch:26 step:24742 [D loss: 0.687913, acc.: 58.59%] [G loss: 1.006168]\n",
      "epoch:26 step:24743 [D loss: 0.558245, acc.: 72.66%] [G loss: 1.361332]\n",
      "epoch:26 step:24744 [D loss: 0.515805, acc.: 75.78%] [G loss: 0.900650]\n",
      "epoch:26 step:24745 [D loss: 0.696461, acc.: 60.16%] [G loss: 1.333869]\n",
      "epoch:26 step:24746 [D loss: 0.493925, acc.: 75.78%] [G loss: 1.478730]\n",
      "epoch:26 step:24747 [D loss: 0.324463, acc.: 90.62%] [G loss: 1.459009]\n",
      "epoch:26 step:24748 [D loss: 0.503927, acc.: 78.91%] [G loss: 1.406098]\n",
      "epoch:26 step:24749 [D loss: 0.647328, acc.: 67.97%] [G loss: 0.978314]\n",
      "epoch:26 step:24750 [D loss: 0.512258, acc.: 77.34%] [G loss: 1.269940]\n",
      "epoch:26 step:24751 [D loss: 0.677135, acc.: 64.06%] [G loss: 1.592905]\n",
      "epoch:26 step:24752 [D loss: 0.443006, acc.: 81.25%] [G loss: 1.806015]\n",
      "epoch:26 step:24753 [D loss: 0.528934, acc.: 71.88%] [G loss: 1.381527]\n",
      "epoch:26 step:24754 [D loss: 0.534942, acc.: 71.88%] [G loss: 1.385514]\n",
      "epoch:26 step:24755 [D loss: 0.566874, acc.: 67.97%] [G loss: 1.319975]\n",
      "epoch:26 step:24756 [D loss: 0.603824, acc.: 64.06%] [G loss: 1.116602]\n",
      "epoch:26 step:24757 [D loss: 0.533408, acc.: 75.78%] [G loss: 1.480109]\n",
      "epoch:26 step:24758 [D loss: 0.578430, acc.: 66.41%] [G loss: 1.061674]\n",
      "epoch:26 step:24759 [D loss: 0.662365, acc.: 66.41%] [G loss: 1.270086]\n",
      "epoch:26 step:24760 [D loss: 0.678064, acc.: 59.38%] [G loss: 1.579672]\n",
      "epoch:26 step:24761 [D loss: 0.655505, acc.: 60.94%] [G loss: 1.558821]\n",
      "epoch:26 step:24762 [D loss: 0.642951, acc.: 67.19%] [G loss: 1.348201]\n",
      "epoch:26 step:24763 [D loss: 0.512226, acc.: 72.66%] [G loss: 1.717074]\n",
      "epoch:26 step:24764 [D loss: 0.481019, acc.: 77.34%] [G loss: 1.682114]\n",
      "epoch:26 step:24765 [D loss: 0.663920, acc.: 60.94%] [G loss: 1.509062]\n",
      "epoch:26 step:24766 [D loss: 0.675574, acc.: 64.84%] [G loss: 1.227122]\n",
      "epoch:26 step:24767 [D loss: 0.462722, acc.: 81.25%] [G loss: 1.698015]\n",
      "epoch:26 step:24768 [D loss: 0.455091, acc.: 80.47%] [G loss: 1.606355]\n",
      "epoch:26 step:24769 [D loss: 0.718252, acc.: 57.03%] [G loss: 0.950209]\n",
      "epoch:26 step:24770 [D loss: 0.349351, acc.: 91.41%] [G loss: 1.742675]\n",
      "epoch:26 step:24771 [D loss: 0.527386, acc.: 71.88%] [G loss: 1.358510]\n",
      "epoch:26 step:24772 [D loss: 0.717739, acc.: 59.38%] [G loss: 1.130313]\n",
      "epoch:26 step:24773 [D loss: 0.463944, acc.: 78.91%] [G loss: 1.435448]\n",
      "epoch:26 step:24774 [D loss: 0.687416, acc.: 60.94%] [G loss: 1.193949]\n",
      "epoch:26 step:24775 [D loss: 0.719706, acc.: 57.03%] [G loss: 1.118527]\n",
      "epoch:26 step:24776 [D loss: 0.489395, acc.: 74.22%] [G loss: 1.020652]\n",
      "epoch:26 step:24777 [D loss: 0.468644, acc.: 83.59%] [G loss: 1.376530]\n",
      "epoch:26 step:24778 [D loss: 0.694300, acc.: 59.38%] [G loss: 1.260723]\n",
      "epoch:26 step:24779 [D loss: 0.728624, acc.: 55.47%] [G loss: 1.243874]\n",
      "epoch:26 step:24780 [D loss: 0.472881, acc.: 75.78%] [G loss: 1.512004]\n",
      "epoch:26 step:24781 [D loss: 0.593183, acc.: 71.09%] [G loss: 1.283038]\n",
      "epoch:26 step:24782 [D loss: 0.460402, acc.: 78.91%] [G loss: 1.793440]\n",
      "epoch:26 step:24783 [D loss: 0.430021, acc.: 78.91%] [G loss: 1.413429]\n",
      "epoch:26 step:24784 [D loss: 0.593681, acc.: 61.72%] [G loss: 1.017983]\n",
      "epoch:26 step:24785 [D loss: 0.477468, acc.: 77.34%] [G loss: 1.440033]\n",
      "epoch:26 step:24786 [D loss: 0.530135, acc.: 72.66%] [G loss: 1.495175]\n",
      "epoch:26 step:24787 [D loss: 0.501660, acc.: 75.00%] [G loss: 1.361289]\n",
      "epoch:26 step:24788 [D loss: 0.555449, acc.: 70.31%] [G loss: 1.492643]\n",
      "epoch:26 step:24789 [D loss: 0.751817, acc.: 57.81%] [G loss: 0.867065]\n",
      "epoch:26 step:24790 [D loss: 0.690366, acc.: 59.38%] [G loss: 1.119022]\n",
      "epoch:26 step:24791 [D loss: 0.596791, acc.: 67.19%] [G loss: 1.630205]\n",
      "epoch:26 step:24792 [D loss: 0.604177, acc.: 71.09%] [G loss: 1.471135]\n",
      "epoch:26 step:24793 [D loss: 0.551427, acc.: 70.31%] [G loss: 1.422997]\n",
      "epoch:26 step:24794 [D loss: 0.460445, acc.: 77.34%] [G loss: 1.609967]\n",
      "epoch:26 step:24795 [D loss: 0.699236, acc.: 55.47%] [G loss: 1.527378]\n",
      "epoch:26 step:24796 [D loss: 0.680014, acc.: 61.72%] [G loss: 1.221268]\n",
      "epoch:26 step:24797 [D loss: 0.561572, acc.: 75.00%] [G loss: 1.163829]\n",
      "epoch:26 step:24798 [D loss: 0.480794, acc.: 76.56%] [G loss: 1.567758]\n",
      "epoch:26 step:24799 [D loss: 0.703933, acc.: 59.38%] [G loss: 1.093004]\n",
      "epoch:26 step:24800 [D loss: 0.632129, acc.: 63.28%] [G loss: 1.399798]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:26 step:24801 [D loss: 0.651934, acc.: 63.28%] [G loss: 1.034331]\n",
      "epoch:26 step:24802 [D loss: 0.561668, acc.: 69.53%] [G loss: 1.310839]\n",
      "epoch:26 step:24803 [D loss: 0.442457, acc.: 85.16%] [G loss: 1.691865]\n",
      "epoch:26 step:24804 [D loss: 0.521946, acc.: 75.78%] [G loss: 1.188250]\n",
      "epoch:26 step:24805 [D loss: 0.515838, acc.: 75.00%] [G loss: 1.319792]\n",
      "epoch:26 step:24806 [D loss: 0.449310, acc.: 77.34%] [G loss: 1.435320]\n",
      "epoch:26 step:24807 [D loss: 0.499105, acc.: 77.34%] [G loss: 1.313199]\n",
      "epoch:26 step:24808 [D loss: 0.670627, acc.: 60.94%] [G loss: 1.190856]\n",
      "epoch:26 step:24809 [D loss: 0.391693, acc.: 85.16%] [G loss: 1.478864]\n",
      "epoch:26 step:24810 [D loss: 0.518495, acc.: 78.91%] [G loss: 1.370327]\n",
      "epoch:26 step:24811 [D loss: 0.411995, acc.: 82.81%] [G loss: 1.351947]\n",
      "epoch:26 step:24812 [D loss: 0.572718, acc.: 67.19%] [G loss: 1.249805]\n",
      "epoch:26 step:24813 [D loss: 0.450170, acc.: 80.47%] [G loss: 1.815371]\n",
      "epoch:26 step:24814 [D loss: 0.335725, acc.: 91.41%] [G loss: 1.958446]\n",
      "epoch:26 step:24815 [D loss: 0.611158, acc.: 63.28%] [G loss: 1.378000]\n",
      "epoch:26 step:24816 [D loss: 0.584124, acc.: 71.09%] [G loss: 2.023544]\n",
      "epoch:26 step:24817 [D loss: 0.546039, acc.: 71.88%] [G loss: 1.394992]\n",
      "epoch:26 step:24818 [D loss: 0.597176, acc.: 65.62%] [G loss: 1.333416]\n",
      "epoch:26 step:24819 [D loss: 0.748444, acc.: 52.34%] [G loss: 1.153992]\n",
      "epoch:26 step:24820 [D loss: 0.427547, acc.: 78.91%] [G loss: 1.562402]\n",
      "epoch:26 step:24821 [D loss: 0.393728, acc.: 84.38%] [G loss: 2.124371]\n",
      "epoch:26 step:24822 [D loss: 0.668483, acc.: 57.03%] [G loss: 1.309773]\n",
      "epoch:26 step:24823 [D loss: 0.461485, acc.: 78.12%] [G loss: 1.687139]\n",
      "epoch:26 step:24824 [D loss: 0.455420, acc.: 81.25%] [G loss: 1.085955]\n",
      "epoch:26 step:24825 [D loss: 0.481271, acc.: 77.34%] [G loss: 1.183460]\n",
      "epoch:26 step:24826 [D loss: 0.554223, acc.: 71.09%] [G loss: 1.063628]\n",
      "epoch:26 step:24827 [D loss: 0.620449, acc.: 65.62%] [G loss: 1.482408]\n",
      "epoch:26 step:24828 [D loss: 0.365575, acc.: 85.16%] [G loss: 1.955571]\n",
      "epoch:26 step:24829 [D loss: 0.521018, acc.: 75.78%] [G loss: 1.530819]\n",
      "epoch:26 step:24830 [D loss: 0.538486, acc.: 69.53%] [G loss: 1.464050]\n",
      "epoch:26 step:24831 [D loss: 0.540779, acc.: 71.09%] [G loss: 1.502169]\n",
      "epoch:26 step:24832 [D loss: 0.441263, acc.: 79.69%] [G loss: 2.095886]\n",
      "epoch:26 step:24833 [D loss: 0.535538, acc.: 74.22%] [G loss: 1.168925]\n",
      "epoch:26 step:24834 [D loss: 0.598807, acc.: 63.28%] [G loss: 1.121893]\n",
      "epoch:26 step:24835 [D loss: 0.309009, acc.: 93.75%] [G loss: 1.424224]\n",
      "epoch:26 step:24836 [D loss: 0.583131, acc.: 72.66%] [G loss: 1.507306]\n",
      "epoch:26 step:24837 [D loss: 0.358820, acc.: 87.50%] [G loss: 1.522934]\n",
      "epoch:26 step:24838 [D loss: 0.528286, acc.: 73.44%] [G loss: 1.238318]\n",
      "epoch:26 step:24839 [D loss: 0.573063, acc.: 71.09%] [G loss: 1.630335]\n",
      "epoch:26 step:24840 [D loss: 0.453230, acc.: 76.56%] [G loss: 1.406627]\n",
      "epoch:26 step:24841 [D loss: 0.514819, acc.: 75.00%] [G loss: 1.520861]\n",
      "epoch:26 step:24842 [D loss: 0.717567, acc.: 62.50%] [G loss: 1.269456]\n",
      "epoch:26 step:24843 [D loss: 0.459405, acc.: 80.47%] [G loss: 1.709668]\n",
      "epoch:26 step:24844 [D loss: 0.647196, acc.: 58.59%] [G loss: 1.688126]\n",
      "epoch:26 step:24845 [D loss: 0.637914, acc.: 64.06%] [G loss: 1.222699]\n",
      "epoch:26 step:24846 [D loss: 0.443697, acc.: 80.47%] [G loss: 1.007566]\n",
      "epoch:26 step:24847 [D loss: 0.758174, acc.: 55.47%] [G loss: 1.230746]\n",
      "epoch:26 step:24848 [D loss: 0.386341, acc.: 86.72%] [G loss: 1.511019]\n",
      "epoch:26 step:24849 [D loss: 0.507902, acc.: 71.88%] [G loss: 1.241213]\n",
      "epoch:26 step:24850 [D loss: 0.463150, acc.: 78.12%] [G loss: 1.579651]\n",
      "epoch:26 step:24851 [D loss: 0.530678, acc.: 72.66%] [G loss: 1.373170]\n",
      "epoch:26 step:24852 [D loss: 0.520404, acc.: 78.12%] [G loss: 1.145421]\n",
      "epoch:26 step:24853 [D loss: 0.427711, acc.: 84.38%] [G loss: 1.579194]\n",
      "epoch:26 step:24854 [D loss: 0.564972, acc.: 69.53%] [G loss: 1.439473]\n",
      "epoch:26 step:24855 [D loss: 0.527395, acc.: 71.09%] [G loss: 1.344290]\n",
      "epoch:26 step:24856 [D loss: 0.465645, acc.: 80.47%] [G loss: 1.219003]\n",
      "epoch:26 step:24857 [D loss: 0.466365, acc.: 82.03%] [G loss: 1.332992]\n",
      "epoch:26 step:24858 [D loss: 0.535214, acc.: 71.09%] [G loss: 1.237011]\n",
      "epoch:26 step:24859 [D loss: 0.667025, acc.: 63.28%] [G loss: 1.384662]\n",
      "epoch:26 step:24860 [D loss: 0.352823, acc.: 89.84%] [G loss: 1.718598]\n",
      "epoch:26 step:24861 [D loss: 0.459888, acc.: 79.69%] [G loss: 1.834048]\n",
      "epoch:26 step:24862 [D loss: 0.595741, acc.: 67.97%] [G loss: 1.376643]\n",
      "epoch:26 step:24863 [D loss: 0.493127, acc.: 72.66%] [G loss: 1.268503]\n",
      "epoch:26 step:24864 [D loss: 0.501089, acc.: 75.78%] [G loss: 1.243197]\n",
      "epoch:26 step:24865 [D loss: 0.754304, acc.: 57.81%] [G loss: 1.366854]\n",
      "epoch:26 step:24866 [D loss: 0.456435, acc.: 81.25%] [G loss: 1.305718]\n",
      "epoch:26 step:24867 [D loss: 0.626675, acc.: 66.41%] [G loss: 1.157791]\n",
      "epoch:26 step:24868 [D loss: 0.459785, acc.: 79.69%] [G loss: 1.372662]\n",
      "epoch:26 step:24869 [D loss: 0.452392, acc.: 78.91%] [G loss: 1.146143]\n",
      "epoch:26 step:24870 [D loss: 0.502010, acc.: 75.78%] [G loss: 1.457999]\n",
      "epoch:26 step:24871 [D loss: 0.565479, acc.: 71.09%] [G loss: 1.098484]\n",
      "epoch:26 step:24872 [D loss: 0.538738, acc.: 71.09%] [G loss: 1.246498]\n",
      "epoch:26 step:24873 [D loss: 0.464112, acc.: 76.56%] [G loss: 1.194855]\n",
      "epoch:26 step:24874 [D loss: 0.343785, acc.: 89.06%] [G loss: 1.660362]\n",
      "epoch:26 step:24875 [D loss: 0.462768, acc.: 77.34%] [G loss: 1.285400]\n",
      "epoch:26 step:24876 [D loss: 0.559403, acc.: 68.75%] [G loss: 1.328132]\n",
      "epoch:26 step:24877 [D loss: 0.660556, acc.: 63.28%] [G loss: 1.664095]\n",
      "epoch:26 step:24878 [D loss: 0.579527, acc.: 68.75%] [G loss: 1.431346]\n",
      "epoch:26 step:24879 [D loss: 0.381644, acc.: 85.94%] [G loss: 1.805971]\n",
      "epoch:26 step:24880 [D loss: 0.699790, acc.: 61.72%] [G loss: 1.311947]\n",
      "epoch:26 step:24881 [D loss: 0.519737, acc.: 76.56%] [G loss: 1.321964]\n",
      "epoch:26 step:24882 [D loss: 0.488657, acc.: 75.00%] [G loss: 1.343355]\n",
      "epoch:26 step:24883 [D loss: 0.494158, acc.: 77.34%] [G loss: 1.603051]\n",
      "epoch:26 step:24884 [D loss: 0.549313, acc.: 71.88%] [G loss: 1.746122]\n",
      "epoch:26 step:24885 [D loss: 0.313022, acc.: 90.62%] [G loss: 1.626045]\n",
      "epoch:26 step:24886 [D loss: 0.555750, acc.: 70.31%] [G loss: 1.299184]\n",
      "epoch:26 step:24887 [D loss: 0.579675, acc.: 70.31%] [G loss: 1.235295]\n",
      "epoch:26 step:24888 [D loss: 0.729494, acc.: 60.94%] [G loss: 1.168216]\n",
      "epoch:26 step:24889 [D loss: 0.683991, acc.: 57.81%] [G loss: 1.378103]\n",
      "epoch:26 step:24890 [D loss: 0.598517, acc.: 67.97%] [G loss: 1.142471]\n",
      "epoch:26 step:24891 [D loss: 0.477389, acc.: 78.12%] [G loss: 1.897649]\n",
      "epoch:26 step:24892 [D loss: 0.538786, acc.: 75.78%] [G loss: 1.588221]\n",
      "epoch:26 step:24893 [D loss: 0.709196, acc.: 54.69%] [G loss: 1.052637]\n",
      "epoch:26 step:24894 [D loss: 0.607153, acc.: 67.19%] [G loss: 1.360032]\n",
      "epoch:26 step:24895 [D loss: 0.728405, acc.: 57.81%] [G loss: 1.329515]\n",
      "epoch:26 step:24896 [D loss: 0.537906, acc.: 69.53%] [G loss: 1.480551]\n",
      "epoch:26 step:24897 [D loss: 0.593076, acc.: 68.75%] [G loss: 1.083963]\n",
      "epoch:26 step:24898 [D loss: 0.558905, acc.: 67.97%] [G loss: 1.140502]\n",
      "epoch:26 step:24899 [D loss: 0.486228, acc.: 76.56%] [G loss: 0.953886]\n",
      "epoch:26 step:24900 [D loss: 0.524377, acc.: 73.44%] [G loss: 1.425283]\n",
      "epoch:26 step:24901 [D loss: 0.448824, acc.: 75.00%] [G loss: 1.380916]\n",
      "epoch:26 step:24902 [D loss: 0.413910, acc.: 85.16%] [G loss: 1.250487]\n",
      "epoch:26 step:24903 [D loss: 0.592642, acc.: 69.53%] [G loss: 1.168463]\n",
      "epoch:26 step:24904 [D loss: 0.487695, acc.: 76.56%] [G loss: 1.306804]\n",
      "epoch:26 step:24905 [D loss: 0.611275, acc.: 70.31%] [G loss: 1.266958]\n",
      "epoch:26 step:24906 [D loss: 0.614579, acc.: 67.19%] [G loss: 1.475272]\n",
      "epoch:26 step:24907 [D loss: 0.608483, acc.: 71.09%] [G loss: 1.343709]\n",
      "epoch:26 step:24908 [D loss: 0.508053, acc.: 73.44%] [G loss: 1.336986]\n",
      "epoch:26 step:24909 [D loss: 0.574149, acc.: 71.88%] [G loss: 1.330552]\n",
      "epoch:26 step:24910 [D loss: 0.619853, acc.: 64.06%] [G loss: 1.353721]\n",
      "epoch:26 step:24911 [D loss: 0.490681, acc.: 78.91%] [G loss: 1.341722]\n",
      "epoch:26 step:24912 [D loss: 0.393348, acc.: 85.16%] [G loss: 2.142006]\n",
      "epoch:26 step:24913 [D loss: 0.678801, acc.: 60.94%] [G loss: 1.383026]\n",
      "epoch:26 step:24914 [D loss: 0.420497, acc.: 78.91%] [G loss: 1.771994]\n",
      "epoch:26 step:24915 [D loss: 0.539964, acc.: 77.34%] [G loss: 1.100933]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:26 step:24916 [D loss: 0.641207, acc.: 66.41%] [G loss: 1.095247]\n",
      "epoch:26 step:24917 [D loss: 0.606794, acc.: 66.41%] [G loss: 1.170338]\n",
      "epoch:26 step:24918 [D loss: 0.491772, acc.: 74.22%] [G loss: 1.414919]\n",
      "epoch:26 step:24919 [D loss: 0.392363, acc.: 82.81%] [G loss: 1.643792]\n",
      "epoch:26 step:24920 [D loss: 0.533088, acc.: 72.66%] [G loss: 1.456910]\n",
      "epoch:26 step:24921 [D loss: 0.492980, acc.: 78.91%] [G loss: 1.545842]\n",
      "epoch:26 step:24922 [D loss: 0.618650, acc.: 63.28%] [G loss: 1.189851]\n",
      "epoch:26 step:24923 [D loss: 0.609926, acc.: 64.06%] [G loss: 0.875441]\n",
      "epoch:26 step:24924 [D loss: 0.513990, acc.: 75.00%] [G loss: 1.028331]\n",
      "epoch:26 step:24925 [D loss: 0.454983, acc.: 80.47%] [G loss: 1.529080]\n",
      "epoch:26 step:24926 [D loss: 0.536912, acc.: 69.53%] [G loss: 1.360238]\n",
      "epoch:26 step:24927 [D loss: 0.586342, acc.: 69.53%] [G loss: 1.377343]\n",
      "epoch:26 step:24928 [D loss: 0.445929, acc.: 79.69%] [G loss: 1.761620]\n",
      "epoch:26 step:24929 [D loss: 0.543357, acc.: 75.00%] [G loss: 1.348897]\n",
      "epoch:26 step:24930 [D loss: 0.819422, acc.: 45.31%] [G loss: 1.418453]\n",
      "epoch:26 step:24931 [D loss: 0.537837, acc.: 71.09%] [G loss: 1.787205]\n",
      "epoch:26 step:24932 [D loss: 0.533260, acc.: 74.22%] [G loss: 1.166933]\n",
      "epoch:26 step:24933 [D loss: 0.394455, acc.: 82.03%] [G loss: 1.601965]\n",
      "epoch:26 step:24934 [D loss: 0.418867, acc.: 84.38%] [G loss: 1.194457]\n",
      "epoch:26 step:24935 [D loss: 0.699789, acc.: 60.16%] [G loss: 1.702995]\n",
      "epoch:26 step:24936 [D loss: 0.491458, acc.: 79.69%] [G loss: 1.583739]\n",
      "epoch:26 step:24937 [D loss: 0.571860, acc.: 72.66%] [G loss: 1.085620]\n",
      "epoch:26 step:24938 [D loss: 0.367421, acc.: 89.06%] [G loss: 1.593284]\n",
      "epoch:26 step:24939 [D loss: 0.676056, acc.: 60.94%] [G loss: 1.238533]\n",
      "epoch:26 step:24940 [D loss: 0.466937, acc.: 81.25%] [G loss: 1.909753]\n",
      "epoch:26 step:24941 [D loss: 0.540884, acc.: 75.00%] [G loss: 1.304549]\n",
      "epoch:26 step:24942 [D loss: 0.597610, acc.: 72.66%] [G loss: 1.321961]\n",
      "epoch:26 step:24943 [D loss: 0.620521, acc.: 67.19%] [G loss: 1.382275]\n",
      "epoch:26 step:24944 [D loss: 0.473027, acc.: 78.91%] [G loss: 1.785661]\n",
      "epoch:26 step:24945 [D loss: 0.485052, acc.: 74.22%] [G loss: 1.645058]\n",
      "epoch:26 step:24946 [D loss: 0.576287, acc.: 70.31%] [G loss: 1.402734]\n",
      "epoch:26 step:24947 [D loss: 0.481934, acc.: 80.47%] [G loss: 1.504521]\n",
      "epoch:26 step:24948 [D loss: 0.628278, acc.: 61.72%] [G loss: 1.596004]\n",
      "epoch:26 step:24949 [D loss: 0.525585, acc.: 72.66%] [G loss: 1.143251]\n",
      "epoch:26 step:24950 [D loss: 0.719095, acc.: 61.72%] [G loss: 1.134477]\n",
      "epoch:26 step:24951 [D loss: 0.545008, acc.: 74.22%] [G loss: 1.333662]\n",
      "epoch:26 step:24952 [D loss: 0.596539, acc.: 71.09%] [G loss: 1.380566]\n",
      "epoch:26 step:24953 [D loss: 0.481105, acc.: 76.56%] [G loss: 1.600454]\n",
      "epoch:26 step:24954 [D loss: 0.486159, acc.: 77.34%] [G loss: 1.580091]\n",
      "epoch:26 step:24955 [D loss: 0.479023, acc.: 75.78%] [G loss: 1.443581]\n",
      "epoch:26 step:24956 [D loss: 0.565182, acc.: 71.88%] [G loss: 1.302603]\n",
      "epoch:26 step:24957 [D loss: 0.559068, acc.: 72.66%] [G loss: 1.215490]\n",
      "epoch:26 step:24958 [D loss: 0.471770, acc.: 75.00%] [G loss: 1.683901]\n",
      "epoch:26 step:24959 [D loss: 0.424554, acc.: 86.72%] [G loss: 1.231195]\n",
      "epoch:26 step:24960 [D loss: 0.575996, acc.: 71.88%] [G loss: 0.909420]\n",
      "epoch:26 step:24961 [D loss: 0.392228, acc.: 81.25%] [G loss: 1.393731]\n",
      "epoch:26 step:24962 [D loss: 0.359793, acc.: 90.62%] [G loss: 1.283060]\n",
      "epoch:26 step:24963 [D loss: 0.899979, acc.: 48.44%] [G loss: 1.100865]\n",
      "epoch:26 step:24964 [D loss: 0.452514, acc.: 83.59%] [G loss: 1.512989]\n",
      "epoch:26 step:24965 [D loss: 0.547916, acc.: 76.56%] [G loss: 1.724484]\n",
      "epoch:26 step:24966 [D loss: 0.522320, acc.: 73.44%] [G loss: 1.383855]\n",
      "epoch:26 step:24967 [D loss: 0.563935, acc.: 69.53%] [G loss: 1.344590]\n",
      "epoch:26 step:24968 [D loss: 0.574256, acc.: 71.88%] [G loss: 1.562328]\n",
      "epoch:26 step:24969 [D loss: 0.561714, acc.: 67.19%] [G loss: 1.180359]\n",
      "epoch:26 step:24970 [D loss: 0.624810, acc.: 67.19%] [G loss: 1.786188]\n",
      "epoch:26 step:24971 [D loss: 0.420627, acc.: 85.16%] [G loss: 1.762183]\n",
      "epoch:26 step:24972 [D loss: 0.580787, acc.: 68.75%] [G loss: 1.386336]\n",
      "epoch:26 step:24973 [D loss: 0.758736, acc.: 53.12%] [G loss: 1.239288]\n",
      "epoch:26 step:24974 [D loss: 0.563388, acc.: 70.31%] [G loss: 1.803264]\n",
      "epoch:26 step:24975 [D loss: 0.519587, acc.: 77.34%] [G loss: 1.162818]\n",
      "epoch:26 step:24976 [D loss: 0.430272, acc.: 83.59%] [G loss: 1.511793]\n",
      "epoch:26 step:24977 [D loss: 0.567379, acc.: 71.88%] [G loss: 1.359993]\n",
      "epoch:26 step:24978 [D loss: 0.490851, acc.: 73.44%] [G loss: 1.832126]\n",
      "epoch:26 step:24979 [D loss: 0.531257, acc.: 74.22%] [G loss: 1.303272]\n",
      "epoch:26 step:24980 [D loss: 0.479535, acc.: 76.56%] [G loss: 1.723913]\n",
      "epoch:26 step:24981 [D loss: 0.759956, acc.: 57.81%] [G loss: 1.532495]\n",
      "epoch:26 step:24982 [D loss: 0.390684, acc.: 85.16%] [G loss: 1.452731]\n",
      "epoch:26 step:24983 [D loss: 0.499240, acc.: 78.12%] [G loss: 1.475281]\n",
      "epoch:26 step:24984 [D loss: 0.519238, acc.: 75.78%] [G loss: 1.094583]\n",
      "epoch:26 step:24985 [D loss: 0.429768, acc.: 83.59%] [G loss: 1.500572]\n",
      "epoch:26 step:24986 [D loss: 0.625875, acc.: 64.84%] [G loss: 1.219651]\n",
      "epoch:26 step:24987 [D loss: 0.584642, acc.: 69.53%] [G loss: 1.597412]\n",
      "epoch:26 step:24988 [D loss: 0.581903, acc.: 72.66%] [G loss: 1.396878]\n",
      "epoch:26 step:24989 [D loss: 0.460900, acc.: 78.12%] [G loss: 1.718952]\n",
      "epoch:26 step:24990 [D loss: 0.646957, acc.: 60.94%] [G loss: 1.560767]\n",
      "epoch:26 step:24991 [D loss: 0.516391, acc.: 75.00%] [G loss: 1.580381]\n",
      "epoch:26 step:24992 [D loss: 0.472059, acc.: 80.47%] [G loss: 1.271331]\n",
      "epoch:26 step:24993 [D loss: 0.412936, acc.: 83.59%] [G loss: 1.480332]\n",
      "epoch:26 step:24994 [D loss: 0.514543, acc.: 73.44%] [G loss: 1.109052]\n",
      "epoch:26 step:24995 [D loss: 0.413830, acc.: 78.91%] [G loss: 1.487451]\n",
      "epoch:26 step:24996 [D loss: 0.437286, acc.: 79.69%] [G loss: 1.546467]\n",
      "epoch:26 step:24997 [D loss: 0.667864, acc.: 65.62%] [G loss: 1.021878]\n",
      "epoch:26 step:24998 [D loss: 0.626400, acc.: 62.50%] [G loss: 1.479922]\n",
      "epoch:26 step:24999 [D loss: 0.659507, acc.: 60.16%] [G loss: 1.490171]\n",
      "epoch:26 step:25000 [D loss: 0.647249, acc.: 71.09%] [G loss: 1.193681]\n",
      "epoch:26 step:25001 [D loss: 0.708927, acc.: 52.34%] [G loss: 1.313222]\n",
      "epoch:26 step:25002 [D loss: 0.507720, acc.: 76.56%] [G loss: 1.495322]\n",
      "epoch:26 step:25003 [D loss: 0.551494, acc.: 69.53%] [G loss: 1.430898]\n",
      "epoch:26 step:25004 [D loss: 0.468340, acc.: 80.47%] [G loss: 1.321577]\n",
      "epoch:26 step:25005 [D loss: 0.690569, acc.: 56.25%] [G loss: 1.325756]\n",
      "epoch:26 step:25006 [D loss: 0.630588, acc.: 68.75%] [G loss: 1.198718]\n",
      "epoch:26 step:25007 [D loss: 0.497856, acc.: 78.91%] [G loss: 1.495794]\n",
      "epoch:26 step:25008 [D loss: 0.463083, acc.: 78.91%] [G loss: 1.453522]\n",
      "epoch:26 step:25009 [D loss: 0.789610, acc.: 53.91%] [G loss: 0.921425]\n",
      "epoch:26 step:25010 [D loss: 0.364657, acc.: 86.72%] [G loss: 1.061587]\n",
      "epoch:26 step:25011 [D loss: 0.580289, acc.: 67.19%] [G loss: 1.053061]\n",
      "epoch:26 step:25012 [D loss: 0.515402, acc.: 75.00%] [G loss: 1.277803]\n",
      "epoch:26 step:25013 [D loss: 0.423254, acc.: 78.91%] [G loss: 1.681258]\n",
      "epoch:26 step:25014 [D loss: 0.517074, acc.: 74.22%] [G loss: 1.240923]\n",
      "epoch:26 step:25015 [D loss: 0.584358, acc.: 67.19%] [G loss: 1.442554]\n",
      "epoch:26 step:25016 [D loss: 0.568048, acc.: 73.44%] [G loss: 1.200209]\n",
      "epoch:26 step:25017 [D loss: 0.467783, acc.: 76.56%] [G loss: 1.475776]\n",
      "epoch:26 step:25018 [D loss: 0.649319, acc.: 62.50%] [G loss: 1.705117]\n",
      "epoch:26 step:25019 [D loss: 0.610622, acc.: 71.09%] [G loss: 1.229961]\n",
      "epoch:26 step:25020 [D loss: 0.713224, acc.: 63.28%] [G loss: 1.386020]\n",
      "epoch:26 step:25021 [D loss: 0.613796, acc.: 67.19%] [G loss: 1.429653]\n",
      "epoch:26 step:25022 [D loss: 0.563828, acc.: 68.75%] [G loss: 1.522260]\n",
      "epoch:26 step:25023 [D loss: 0.509157, acc.: 75.78%] [G loss: 1.267719]\n",
      "epoch:26 step:25024 [D loss: 0.488118, acc.: 75.78%] [G loss: 1.719395]\n",
      "epoch:26 step:25025 [D loss: 0.451964, acc.: 78.91%] [G loss: 1.312151]\n",
      "epoch:26 step:25026 [D loss: 0.584702, acc.: 67.97%] [G loss: 1.164431]\n",
      "epoch:26 step:25027 [D loss: 0.482548, acc.: 79.69%] [G loss: 1.257435]\n",
      "epoch:26 step:25028 [D loss: 0.508051, acc.: 75.78%] [G loss: 0.893113]\n",
      "epoch:26 step:25029 [D loss: 0.509786, acc.: 70.31%] [G loss: 1.260864]\n",
      "epoch:26 step:25030 [D loss: 0.662711, acc.: 61.72%] [G loss: 1.020380]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:26 step:25031 [D loss: 0.464491, acc.: 80.47%] [G loss: 1.110365]\n",
      "epoch:26 step:25032 [D loss: 0.633368, acc.: 66.41%] [G loss: 1.447143]\n",
      "epoch:26 step:25033 [D loss: 0.600203, acc.: 68.75%] [G loss: 1.814744]\n",
      "epoch:26 step:25034 [D loss: 0.438149, acc.: 82.03%] [G loss: 1.388175]\n",
      "epoch:26 step:25035 [D loss: 0.651923, acc.: 58.59%] [G loss: 1.153797]\n",
      "epoch:26 step:25036 [D loss: 0.524813, acc.: 74.22%] [G loss: 1.548862]\n",
      "epoch:26 step:25037 [D loss: 0.712659, acc.: 59.38%] [G loss: 1.287181]\n",
      "epoch:26 step:25038 [D loss: 0.734920, acc.: 58.59%] [G loss: 1.159447]\n",
      "epoch:26 step:25039 [D loss: 0.515173, acc.: 76.56%] [G loss: 1.434890]\n",
      "epoch:26 step:25040 [D loss: 0.571439, acc.: 71.09%] [G loss: 1.291177]\n",
      "epoch:26 step:25041 [D loss: 0.475299, acc.: 81.25%] [G loss: 1.256283]\n",
      "epoch:26 step:25042 [D loss: 0.710845, acc.: 60.16%] [G loss: 1.511032]\n",
      "epoch:26 step:25043 [D loss: 0.591443, acc.: 70.31%] [G loss: 1.054548]\n",
      "epoch:26 step:25044 [D loss: 0.581255, acc.: 70.31%] [G loss: 1.290982]\n",
      "epoch:26 step:25045 [D loss: 0.724770, acc.: 60.16%] [G loss: 1.176111]\n",
      "epoch:26 step:25046 [D loss: 0.488303, acc.: 79.69%] [G loss: 1.263259]\n",
      "epoch:26 step:25047 [D loss: 0.696226, acc.: 59.38%] [G loss: 1.119275]\n",
      "epoch:26 step:25048 [D loss: 0.542011, acc.: 72.66%] [G loss: 1.302957]\n",
      "epoch:26 step:25049 [D loss: 0.496846, acc.: 76.56%] [G loss: 1.337878]\n",
      "epoch:26 step:25050 [D loss: 0.547329, acc.: 71.88%] [G loss: 1.112851]\n",
      "epoch:26 step:25051 [D loss: 0.866741, acc.: 46.09%] [G loss: 1.088987]\n",
      "epoch:26 step:25052 [D loss: 0.515520, acc.: 72.66%] [G loss: 1.547017]\n",
      "epoch:26 step:25053 [D loss: 0.594558, acc.: 70.31%] [G loss: 1.111025]\n",
      "epoch:26 step:25054 [D loss: 0.644346, acc.: 60.94%] [G loss: 1.557555]\n",
      "epoch:26 step:25055 [D loss: 0.430039, acc.: 83.59%] [G loss: 1.172086]\n",
      "epoch:26 step:25056 [D loss: 0.558201, acc.: 77.34%] [G loss: 1.395830]\n",
      "epoch:26 step:25057 [D loss: 0.515059, acc.: 77.34%] [G loss: 0.973050]\n",
      "epoch:26 step:25058 [D loss: 0.615547, acc.: 67.19%] [G loss: 1.291900]\n",
      "epoch:26 step:25059 [D loss: 0.446279, acc.: 82.03%] [G loss: 1.549268]\n",
      "epoch:26 step:25060 [D loss: 0.673405, acc.: 63.28%] [G loss: 1.660197]\n",
      "epoch:26 step:25061 [D loss: 0.498518, acc.: 79.69%] [G loss: 1.246799]\n",
      "epoch:26 step:25062 [D loss: 0.446924, acc.: 77.34%] [G loss: 1.478433]\n",
      "epoch:26 step:25063 [D loss: 0.411366, acc.: 83.59%] [G loss: 1.376968]\n",
      "epoch:26 step:25064 [D loss: 0.444188, acc.: 79.69%] [G loss: 1.785174]\n",
      "epoch:26 step:25065 [D loss: 0.714432, acc.: 57.81%] [G loss: 1.291809]\n",
      "epoch:26 step:25066 [D loss: 0.693566, acc.: 62.50%] [G loss: 1.030042]\n",
      "epoch:26 step:25067 [D loss: 0.562453, acc.: 71.88%] [G loss: 1.355861]\n",
      "epoch:26 step:25068 [D loss: 0.674843, acc.: 60.16%] [G loss: 1.517697]\n",
      "epoch:26 step:25069 [D loss: 0.505993, acc.: 75.00%] [G loss: 1.604535]\n",
      "epoch:26 step:25070 [D loss: 0.479849, acc.: 79.69%] [G loss: 1.476186]\n",
      "epoch:26 step:25071 [D loss: 0.640110, acc.: 66.41%] [G loss: 1.141608]\n",
      "epoch:26 step:25072 [D loss: 0.451946, acc.: 80.47%] [G loss: 1.563851]\n",
      "epoch:26 step:25073 [D loss: 0.595323, acc.: 71.88%] [G loss: 1.189780]\n",
      "epoch:26 step:25074 [D loss: 0.453190, acc.: 78.91%] [G loss: 1.486745]\n",
      "epoch:26 step:25075 [D loss: 0.821051, acc.: 49.22%] [G loss: 0.916789]\n",
      "epoch:26 step:25076 [D loss: 0.548061, acc.: 73.44%] [G loss: 1.182608]\n",
      "epoch:26 step:25077 [D loss: 0.670246, acc.: 63.28%] [G loss: 1.396579]\n",
      "epoch:26 step:25078 [D loss: 0.481944, acc.: 78.91%] [G loss: 1.191728]\n",
      "epoch:26 step:25079 [D loss: 0.490104, acc.: 76.56%] [G loss: 1.178018]\n",
      "epoch:26 step:25080 [D loss: 0.447309, acc.: 83.59%] [G loss: 1.838243]\n",
      "epoch:26 step:25081 [D loss: 0.674091, acc.: 57.03%] [G loss: 1.104537]\n",
      "epoch:26 step:25082 [D loss: 0.501864, acc.: 75.78%] [G loss: 1.571506]\n",
      "epoch:26 step:25083 [D loss: 0.688861, acc.: 60.16%] [G loss: 0.973502]\n",
      "epoch:26 step:25084 [D loss: 0.755314, acc.: 51.56%] [G loss: 1.638488]\n",
      "epoch:26 step:25085 [D loss: 0.513135, acc.: 76.56%] [G loss: 1.633002]\n",
      "epoch:26 step:25086 [D loss: 0.652822, acc.: 61.72%] [G loss: 1.105602]\n",
      "epoch:26 step:25087 [D loss: 0.488715, acc.: 72.66%] [G loss: 1.245722]\n",
      "epoch:26 step:25088 [D loss: 0.557096, acc.: 74.22%] [G loss: 1.257309]\n",
      "epoch:26 step:25089 [D loss: 0.617992, acc.: 65.62%] [G loss: 1.254202]\n",
      "epoch:26 step:25090 [D loss: 0.623228, acc.: 63.28%] [G loss: 1.279427]\n",
      "epoch:26 step:25091 [D loss: 0.518663, acc.: 74.22%] [G loss: 1.715190]\n",
      "epoch:26 step:25092 [D loss: 0.681567, acc.: 60.16%] [G loss: 1.112761]\n",
      "epoch:26 step:25093 [D loss: 0.557379, acc.: 67.97%] [G loss: 1.185405]\n",
      "epoch:26 step:25094 [D loss: 0.510152, acc.: 78.12%] [G loss: 1.469014]\n",
      "epoch:26 step:25095 [D loss: 0.557428, acc.: 64.84%] [G loss: 0.996379]\n",
      "epoch:26 step:25096 [D loss: 0.613719, acc.: 62.50%] [G loss: 1.348241]\n",
      "epoch:26 step:25097 [D loss: 0.624104, acc.: 69.53%] [G loss: 1.370591]\n",
      "epoch:26 step:25098 [D loss: 0.354832, acc.: 87.50%] [G loss: 1.680361]\n",
      "epoch:26 step:25099 [D loss: 0.443657, acc.: 77.34%] [G loss: 1.345925]\n",
      "epoch:26 step:25100 [D loss: 0.564105, acc.: 71.88%] [G loss: 1.396966]\n",
      "epoch:26 step:25101 [D loss: 0.695390, acc.: 54.69%] [G loss: 1.544837]\n",
      "epoch:26 step:25102 [D loss: 0.656088, acc.: 65.62%] [G loss: 1.335127]\n",
      "epoch:26 step:25103 [D loss: 0.532945, acc.: 75.00%] [G loss: 1.369607]\n",
      "epoch:26 step:25104 [D loss: 0.496739, acc.: 75.78%] [G loss: 1.347975]\n",
      "epoch:26 step:25105 [D loss: 0.695125, acc.: 63.28%] [G loss: 1.278340]\n",
      "epoch:26 step:25106 [D loss: 0.579512, acc.: 73.44%] [G loss: 1.126507]\n",
      "epoch:26 step:25107 [D loss: 0.593672, acc.: 65.62%] [G loss: 1.541972]\n",
      "epoch:26 step:25108 [D loss: 0.535484, acc.: 68.75%] [G loss: 1.355744]\n",
      "epoch:26 step:25109 [D loss: 0.478892, acc.: 78.12%] [G loss: 1.275045]\n",
      "epoch:26 step:25110 [D loss: 0.581151, acc.: 66.41%] [G loss: 1.971084]\n",
      "epoch:26 step:25111 [D loss: 0.707705, acc.: 54.69%] [G loss: 1.648901]\n",
      "epoch:26 step:25112 [D loss: 0.633577, acc.: 64.06%] [G loss: 0.884485]\n",
      "epoch:26 step:25113 [D loss: 0.557475, acc.: 74.22%] [G loss: 1.274807]\n",
      "epoch:26 step:25114 [D loss: 0.643536, acc.: 64.06%] [G loss: 1.011052]\n",
      "epoch:26 step:25115 [D loss: 0.557925, acc.: 71.09%] [G loss: 1.341645]\n",
      "epoch:26 step:25116 [D loss: 0.547966, acc.: 70.31%] [G loss: 1.248947]\n",
      "epoch:26 step:25117 [D loss: 0.400352, acc.: 84.38%] [G loss: 1.449859]\n",
      "epoch:26 step:25118 [D loss: 0.687302, acc.: 64.06%] [G loss: 1.383966]\n",
      "epoch:26 step:25119 [D loss: 0.441229, acc.: 82.03%] [G loss: 1.613334]\n",
      "epoch:26 step:25120 [D loss: 0.590230, acc.: 70.31%] [G loss: 1.389713]\n",
      "epoch:26 step:25121 [D loss: 0.533324, acc.: 73.44%] [G loss: 1.728045]\n",
      "epoch:26 step:25122 [D loss: 0.726265, acc.: 59.38%] [G loss: 1.734602]\n",
      "epoch:26 step:25123 [D loss: 0.646553, acc.: 61.72%] [G loss: 0.939589]\n",
      "epoch:26 step:25124 [D loss: 0.738857, acc.: 51.56%] [G loss: 0.843863]\n",
      "epoch:26 step:25125 [D loss: 0.496352, acc.: 78.12%] [G loss: 1.290142]\n",
      "epoch:26 step:25126 [D loss: 0.505761, acc.: 83.59%] [G loss: 1.606594]\n",
      "epoch:26 step:25127 [D loss: 0.687045, acc.: 61.72%] [G loss: 1.388666]\n",
      "epoch:26 step:25128 [D loss: 0.556548, acc.: 72.66%] [G loss: 1.253716]\n",
      "epoch:26 step:25129 [D loss: 0.425755, acc.: 81.25%] [G loss: 1.647812]\n",
      "epoch:26 step:25130 [D loss: 0.425504, acc.: 83.59%] [G loss: 1.787764]\n",
      "epoch:26 step:25131 [D loss: 0.553179, acc.: 74.22%] [G loss: 1.337286]\n",
      "epoch:26 step:25132 [D loss: 0.591516, acc.: 67.19%] [G loss: 1.329065]\n",
      "epoch:26 step:25133 [D loss: 0.686503, acc.: 53.91%] [G loss: 1.130986]\n",
      "epoch:26 step:25134 [D loss: 0.722906, acc.: 53.91%] [G loss: 1.679243]\n",
      "epoch:26 step:25135 [D loss: 0.795097, acc.: 49.22%] [G loss: 1.257025]\n",
      "epoch:26 step:25136 [D loss: 0.637231, acc.: 66.41%] [G loss: 1.310547]\n",
      "epoch:26 step:25137 [D loss: 0.601524, acc.: 67.19%] [G loss: 1.509537]\n",
      "epoch:26 step:25138 [D loss: 0.364845, acc.: 83.59%] [G loss: 1.519819]\n",
      "epoch:26 step:25139 [D loss: 0.640124, acc.: 59.38%] [G loss: 1.138163]\n",
      "epoch:26 step:25140 [D loss: 0.473894, acc.: 78.12%] [G loss: 1.508949]\n",
      "epoch:26 step:25141 [D loss: 0.501910, acc.: 72.66%] [G loss: 1.557075]\n",
      "epoch:26 step:25142 [D loss: 0.671017, acc.: 61.72%] [G loss: 1.427272]\n",
      "epoch:26 step:25143 [D loss: 0.500934, acc.: 78.91%] [G loss: 1.438597]\n",
      "epoch:26 step:25144 [D loss: 0.542331, acc.: 68.75%] [G loss: 1.631680]\n",
      "epoch:26 step:25145 [D loss: 0.586709, acc.: 70.31%] [G loss: 1.536981]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:26 step:25146 [D loss: 0.581425, acc.: 71.88%] [G loss: 1.354842]\n",
      "epoch:26 step:25147 [D loss: 0.358369, acc.: 88.28%] [G loss: 1.685197]\n",
      "epoch:26 step:25148 [D loss: 0.603900, acc.: 64.84%] [G loss: 1.443752]\n",
      "epoch:26 step:25149 [D loss: 0.524766, acc.: 75.78%] [G loss: 1.277208]\n",
      "epoch:26 step:25150 [D loss: 0.620932, acc.: 64.06%] [G loss: 1.699679]\n",
      "epoch:26 step:25151 [D loss: 0.733617, acc.: 53.91%] [G loss: 1.047683]\n",
      "epoch:26 step:25152 [D loss: 0.655604, acc.: 63.28%] [G loss: 1.190102]\n",
      "epoch:26 step:25153 [D loss: 0.477332, acc.: 75.00%] [G loss: 1.257689]\n",
      "epoch:26 step:25154 [D loss: 0.573060, acc.: 70.31%] [G loss: 1.807974]\n",
      "epoch:26 step:25155 [D loss: 0.451668, acc.: 78.91%] [G loss: 1.308409]\n",
      "epoch:26 step:25156 [D loss: 0.644647, acc.: 67.97%] [G loss: 1.306857]\n",
      "epoch:26 step:25157 [D loss: 0.413432, acc.: 84.38%] [G loss: 1.516363]\n",
      "epoch:26 step:25158 [D loss: 0.491912, acc.: 79.69%] [G loss: 1.197894]\n",
      "epoch:26 step:25159 [D loss: 0.534894, acc.: 71.09%] [G loss: 1.458188]\n",
      "epoch:26 step:25160 [D loss: 0.570826, acc.: 69.53%] [G loss: 1.505441]\n",
      "epoch:26 step:25161 [D loss: 0.593987, acc.: 68.75%] [G loss: 1.465366]\n",
      "epoch:26 step:25162 [D loss: 0.635494, acc.: 66.41%] [G loss: 1.367654]\n",
      "epoch:26 step:25163 [D loss: 0.738901, acc.: 53.12%] [G loss: 1.283319]\n",
      "epoch:26 step:25164 [D loss: 0.628433, acc.: 69.53%] [G loss: 1.376660]\n",
      "epoch:26 step:25165 [D loss: 0.605315, acc.: 73.44%] [G loss: 1.294716]\n",
      "epoch:26 step:25166 [D loss: 0.479078, acc.: 78.12%] [G loss: 1.090691]\n",
      "epoch:26 step:25167 [D loss: 0.559572, acc.: 71.88%] [G loss: 1.083825]\n",
      "epoch:26 step:25168 [D loss: 0.509741, acc.: 75.00%] [G loss: 1.390548]\n",
      "epoch:26 step:25169 [D loss: 0.584745, acc.: 70.31%] [G loss: 1.448128]\n",
      "epoch:26 step:25170 [D loss: 0.598145, acc.: 69.53%] [G loss: 1.435142]\n",
      "epoch:26 step:25171 [D loss: 0.348672, acc.: 92.19%] [G loss: 1.560441]\n",
      "epoch:26 step:25172 [D loss: 0.428082, acc.: 82.03%] [G loss: 1.282760]\n",
      "epoch:26 step:25173 [D loss: 0.585173, acc.: 71.88%] [G loss: 1.042754]\n",
      "epoch:26 step:25174 [D loss: 0.559992, acc.: 71.88%] [G loss: 1.475921]\n",
      "epoch:26 step:25175 [D loss: 0.668401, acc.: 63.28%] [G loss: 1.376349]\n",
      "epoch:26 step:25176 [D loss: 0.538340, acc.: 71.88%] [G loss: 2.120997]\n",
      "epoch:26 step:25177 [D loss: 0.668645, acc.: 63.28%] [G loss: 1.573132]\n",
      "epoch:26 step:25178 [D loss: 0.427093, acc.: 81.25%] [G loss: 1.388242]\n",
      "epoch:26 step:25179 [D loss: 0.621864, acc.: 64.06%] [G loss: 1.174476]\n",
      "epoch:26 step:25180 [D loss: 0.548135, acc.: 69.53%] [G loss: 1.513528]\n",
      "epoch:26 step:25181 [D loss: 0.617975, acc.: 63.28%] [G loss: 1.724885]\n",
      "epoch:26 step:25182 [D loss: 0.462120, acc.: 83.59%] [G loss: 1.480201]\n",
      "epoch:26 step:25183 [D loss: 0.592355, acc.: 67.97%] [G loss: 1.206192]\n",
      "epoch:26 step:25184 [D loss: 0.552397, acc.: 68.75%] [G loss: 1.409386]\n",
      "epoch:26 step:25185 [D loss: 0.552499, acc.: 71.09%] [G loss: 1.744385]\n",
      "epoch:26 step:25186 [D loss: 0.454073, acc.: 79.69%] [G loss: 1.471899]\n",
      "epoch:26 step:25187 [D loss: 0.432004, acc.: 79.69%] [G loss: 1.150517]\n",
      "epoch:26 step:25188 [D loss: 0.628226, acc.: 67.19%] [G loss: 1.248808]\n",
      "epoch:26 step:25189 [D loss: 0.542012, acc.: 76.56%] [G loss: 1.293029]\n",
      "epoch:26 step:25190 [D loss: 0.754545, acc.: 53.91%] [G loss: 1.520096]\n",
      "epoch:26 step:25191 [D loss: 0.523501, acc.: 74.22%] [G loss: 1.259281]\n",
      "epoch:26 step:25192 [D loss: 0.750677, acc.: 58.59%] [G loss: 1.213095]\n",
      "epoch:26 step:25193 [D loss: 0.574495, acc.: 70.31%] [G loss: 1.352913]\n",
      "epoch:26 step:25194 [D loss: 0.654616, acc.: 62.50%] [G loss: 0.895932]\n",
      "epoch:26 step:25195 [D loss: 0.543201, acc.: 71.88%] [G loss: 1.345798]\n",
      "epoch:26 step:25196 [D loss: 0.613618, acc.: 71.09%] [G loss: 1.389342]\n",
      "epoch:26 step:25197 [D loss: 0.525052, acc.: 70.31%] [G loss: 1.338940]\n",
      "epoch:26 step:25198 [D loss: 0.436376, acc.: 83.59%] [G loss: 1.186263]\n",
      "epoch:26 step:25199 [D loss: 0.588024, acc.: 62.50%] [G loss: 1.068456]\n",
      "epoch:26 step:25200 [D loss: 0.522941, acc.: 71.88%] [G loss: 1.191847]\n",
      "epoch:26 step:25201 [D loss: 0.562805, acc.: 72.66%] [G loss: 1.473581]\n",
      "epoch:26 step:25202 [D loss: 0.729963, acc.: 56.25%] [G loss: 1.560983]\n",
      "epoch:26 step:25203 [D loss: 0.494351, acc.: 76.56%] [G loss: 1.659710]\n",
      "epoch:26 step:25204 [D loss: 0.424175, acc.: 80.47%] [G loss: 1.274716]\n",
      "epoch:26 step:25205 [D loss: 0.589315, acc.: 71.88%] [G loss: 1.070490]\n",
      "epoch:26 step:25206 [D loss: 0.669768, acc.: 60.94%] [G loss: 1.169813]\n",
      "epoch:26 step:25207 [D loss: 0.644085, acc.: 67.19%] [G loss: 1.063535]\n",
      "epoch:26 step:25208 [D loss: 0.584037, acc.: 71.88%] [G loss: 1.589523]\n",
      "epoch:26 step:25209 [D loss: 0.686935, acc.: 54.69%] [G loss: 1.557350]\n",
      "epoch:26 step:25210 [D loss: 0.800909, acc.: 57.03%] [G loss: 1.467212]\n",
      "epoch:26 step:25211 [D loss: 0.413240, acc.: 82.03%] [G loss: 1.505133]\n",
      "epoch:26 step:25212 [D loss: 0.422227, acc.: 84.38%] [G loss: 1.546928]\n",
      "epoch:26 step:25213 [D loss: 0.594806, acc.: 71.88%] [G loss: 1.260229]\n",
      "epoch:26 step:25214 [D loss: 0.508610, acc.: 71.09%] [G loss: 1.808889]\n",
      "epoch:26 step:25215 [D loss: 0.604399, acc.: 62.50%] [G loss: 1.376425]\n",
      "epoch:26 step:25216 [D loss: 0.563698, acc.: 77.34%] [G loss: 1.183605]\n",
      "epoch:26 step:25217 [D loss: 0.542337, acc.: 74.22%] [G loss: 1.138904]\n",
      "epoch:26 step:25218 [D loss: 0.409951, acc.: 84.38%] [G loss: 1.438740]\n",
      "epoch:26 step:25219 [D loss: 0.638637, acc.: 67.97%] [G loss: 1.111747]\n",
      "epoch:26 step:25220 [D loss: 0.374740, acc.: 85.94%] [G loss: 1.619642]\n",
      "epoch:26 step:25221 [D loss: 0.523337, acc.: 75.00%] [G loss: 1.252746]\n",
      "epoch:26 step:25222 [D loss: 0.526829, acc.: 75.78%] [G loss: 1.468252]\n",
      "epoch:26 step:25223 [D loss: 0.472883, acc.: 82.81%] [G loss: 1.313723]\n",
      "epoch:26 step:25224 [D loss: 0.536386, acc.: 77.34%] [G loss: 1.166698]\n",
      "epoch:26 step:25225 [D loss: 0.593601, acc.: 67.97%] [G loss: 1.400556]\n",
      "epoch:26 step:25226 [D loss: 0.574857, acc.: 67.19%] [G loss: 0.804303]\n",
      "epoch:26 step:25227 [D loss: 0.571895, acc.: 65.62%] [G loss: 1.363731]\n",
      "epoch:26 step:25228 [D loss: 0.488146, acc.: 75.78%] [G loss: 1.319077]\n",
      "epoch:26 step:25229 [D loss: 0.447312, acc.: 79.69%] [G loss: 1.608443]\n",
      "epoch:26 step:25230 [D loss: 0.631158, acc.: 61.72%] [G loss: 1.674207]\n",
      "epoch:26 step:25231 [D loss: 0.455214, acc.: 80.47%] [G loss: 1.093941]\n",
      "epoch:26 step:25232 [D loss: 0.498031, acc.: 73.44%] [G loss: 1.236112]\n",
      "epoch:26 step:25233 [D loss: 0.705577, acc.: 55.47%] [G loss: 0.960367]\n",
      "epoch:26 step:25234 [D loss: 0.544911, acc.: 71.09%] [G loss: 1.335498]\n",
      "epoch:26 step:25235 [D loss: 0.440141, acc.: 84.38%] [G loss: 1.086742]\n",
      "epoch:26 step:25236 [D loss: 0.586196, acc.: 66.41%] [G loss: 1.304018]\n",
      "epoch:26 step:25237 [D loss: 0.527550, acc.: 72.66%] [G loss: 1.587415]\n",
      "epoch:26 step:25238 [D loss: 0.576818, acc.: 66.41%] [G loss: 1.214655]\n",
      "epoch:26 step:25239 [D loss: 0.632936, acc.: 64.84%] [G loss: 1.380086]\n",
      "epoch:26 step:25240 [D loss: 0.668587, acc.: 60.94%] [G loss: 1.385138]\n",
      "epoch:26 step:25241 [D loss: 0.632570, acc.: 61.72%] [G loss: 1.549770]\n",
      "epoch:26 step:25242 [D loss: 0.443224, acc.: 82.03%] [G loss: 1.463824]\n",
      "epoch:26 step:25243 [D loss: 0.555842, acc.: 77.34%] [G loss: 1.256798]\n",
      "epoch:26 step:25244 [D loss: 0.360258, acc.: 89.06%] [G loss: 1.371816]\n",
      "epoch:26 step:25245 [D loss: 0.683312, acc.: 63.28%] [G loss: 1.125830]\n",
      "epoch:26 step:25246 [D loss: 0.430536, acc.: 82.81%] [G loss: 1.634023]\n",
      "epoch:26 step:25247 [D loss: 0.599306, acc.: 65.62%] [G loss: 1.428576]\n",
      "epoch:26 step:25248 [D loss: 0.691962, acc.: 60.94%] [G loss: 1.467823]\n",
      "epoch:26 step:25249 [D loss: 0.330297, acc.: 91.41%] [G loss: 1.624446]\n",
      "epoch:26 step:25250 [D loss: 0.609203, acc.: 65.62%] [G loss: 1.282523]\n",
      "epoch:26 step:25251 [D loss: 0.648277, acc.: 59.38%] [G loss: 0.942736]\n",
      "epoch:26 step:25252 [D loss: 0.564415, acc.: 75.00%] [G loss: 1.535955]\n",
      "epoch:26 step:25253 [D loss: 0.702961, acc.: 58.59%] [G loss: 1.354798]\n",
      "epoch:26 step:25254 [D loss: 0.567368, acc.: 74.22%] [G loss: 1.722858]\n",
      "epoch:26 step:25255 [D loss: 0.564803, acc.: 71.09%] [G loss: 1.487394]\n",
      "epoch:26 step:25256 [D loss: 0.444414, acc.: 82.81%] [G loss: 1.531587]\n",
      "epoch:26 step:25257 [D loss: 0.464626, acc.: 79.69%] [G loss: 1.344109]\n",
      "epoch:26 step:25258 [D loss: 0.539794, acc.: 72.66%] [G loss: 1.659227]\n",
      "epoch:26 step:25259 [D loss: 0.676537, acc.: 60.16%] [G loss: 1.390242]\n",
      "epoch:26 step:25260 [D loss: 0.385601, acc.: 85.94%] [G loss: 1.753114]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:26 step:25261 [D loss: 0.530786, acc.: 78.91%] [G loss: 1.271144]\n",
      "epoch:26 step:25262 [D loss: 0.438125, acc.: 80.47%] [G loss: 1.196140]\n",
      "epoch:26 step:25263 [D loss: 0.644672, acc.: 64.84%] [G loss: 1.148219]\n",
      "epoch:26 step:25264 [D loss: 0.749649, acc.: 56.25%] [G loss: 1.444953]\n",
      "epoch:26 step:25265 [D loss: 0.537381, acc.: 73.44%] [G loss: 1.356876]\n",
      "epoch:26 step:25266 [D loss: 0.630188, acc.: 64.84%] [G loss: 1.186632]\n",
      "epoch:26 step:25267 [D loss: 0.543927, acc.: 71.88%] [G loss: 1.278013]\n",
      "epoch:26 step:25268 [D loss: 0.530812, acc.: 78.12%] [G loss: 1.406448]\n",
      "epoch:26 step:25269 [D loss: 0.599409, acc.: 67.97%] [G loss: 1.167997]\n",
      "epoch:26 step:25270 [D loss: 0.563208, acc.: 69.53%] [G loss: 1.311519]\n",
      "epoch:26 step:25271 [D loss: 0.541218, acc.: 72.66%] [G loss: 1.364011]\n",
      "epoch:26 step:25272 [D loss: 0.659440, acc.: 64.06%] [G loss: 1.256075]\n",
      "epoch:26 step:25273 [D loss: 0.532343, acc.: 77.34%] [G loss: 1.305757]\n",
      "epoch:26 step:25274 [D loss: 0.577061, acc.: 72.66%] [G loss: 1.226119]\n",
      "epoch:26 step:25275 [D loss: 0.575518, acc.: 69.53%] [G loss: 1.311800]\n",
      "epoch:26 step:25276 [D loss: 0.567979, acc.: 68.75%] [G loss: 1.434087]\n",
      "epoch:26 step:25277 [D loss: 0.566361, acc.: 71.09%] [G loss: 1.188780]\n",
      "epoch:26 step:25278 [D loss: 0.522071, acc.: 75.00%] [G loss: 1.309393]\n",
      "epoch:26 step:25279 [D loss: 0.568543, acc.: 74.22%] [G loss: 1.399668]\n",
      "epoch:26 step:25280 [D loss: 0.417618, acc.: 85.16%] [G loss: 1.426610]\n",
      "epoch:26 step:25281 [D loss: 0.422293, acc.: 82.03%] [G loss: 1.747753]\n",
      "epoch:26 step:25282 [D loss: 0.522718, acc.: 74.22%] [G loss: 1.527449]\n",
      "epoch:26 step:25283 [D loss: 0.493561, acc.: 75.78%] [G loss: 1.331892]\n",
      "epoch:26 step:25284 [D loss: 0.496310, acc.: 81.25%] [G loss: 1.312728]\n",
      "epoch:26 step:25285 [D loss: 0.639796, acc.: 62.50%] [G loss: 1.124272]\n",
      "epoch:26 step:25286 [D loss: 0.445598, acc.: 81.25%] [G loss: 1.526414]\n",
      "epoch:26 step:25287 [D loss: 0.615310, acc.: 69.53%] [G loss: 1.351033]\n",
      "epoch:26 step:25288 [D loss: 0.512427, acc.: 77.34%] [G loss: 1.075419]\n",
      "epoch:26 step:25289 [D loss: 0.662544, acc.: 60.94%] [G loss: 1.294968]\n",
      "epoch:26 step:25290 [D loss: 0.427218, acc.: 80.47%] [G loss: 1.193889]\n",
      "epoch:26 step:25291 [D loss: 0.544675, acc.: 74.22%] [G loss: 1.289084]\n",
      "epoch:26 step:25292 [D loss: 0.590942, acc.: 63.28%] [G loss: 1.513332]\n",
      "epoch:26 step:25293 [D loss: 0.575070, acc.: 67.97%] [G loss: 1.149052]\n",
      "epoch:26 step:25294 [D loss: 0.603461, acc.: 67.97%] [G loss: 1.060576]\n",
      "epoch:26 step:25295 [D loss: 0.500372, acc.: 76.56%] [G loss: 1.324569]\n",
      "epoch:26 step:25296 [D loss: 0.509370, acc.: 78.12%] [G loss: 1.136891]\n",
      "epoch:26 step:25297 [D loss: 0.347197, acc.: 87.50%] [G loss: 1.600811]\n",
      "epoch:26 step:25298 [D loss: 0.489974, acc.: 78.12%] [G loss: 1.476548]\n",
      "epoch:26 step:25299 [D loss: 0.572105, acc.: 67.19%] [G loss: 1.182164]\n",
      "epoch:27 step:25300 [D loss: 0.682809, acc.: 60.94%] [G loss: 1.570111]\n",
      "epoch:27 step:25301 [D loss: 0.523381, acc.: 76.56%] [G loss: 0.977654]\n",
      "epoch:27 step:25302 [D loss: 0.397110, acc.: 85.94%] [G loss: 1.361403]\n",
      "epoch:27 step:25303 [D loss: 0.481563, acc.: 81.25%] [G loss: 1.188847]\n",
      "epoch:27 step:25304 [D loss: 0.525734, acc.: 70.31%] [G loss: 1.418906]\n",
      "epoch:27 step:25305 [D loss: 0.587967, acc.: 66.41%] [G loss: 1.805976]\n",
      "epoch:27 step:25306 [D loss: 0.569876, acc.: 67.97%] [G loss: 1.338145]\n",
      "epoch:27 step:25307 [D loss: 0.675850, acc.: 63.28%] [G loss: 1.216450]\n",
      "epoch:27 step:25308 [D loss: 0.465657, acc.: 80.47%] [G loss: 1.495977]\n",
      "epoch:27 step:25309 [D loss: 0.689067, acc.: 57.03%] [G loss: 0.897637]\n",
      "epoch:27 step:25310 [D loss: 0.383824, acc.: 86.72%] [G loss: 1.308172]\n",
      "epoch:27 step:25311 [D loss: 0.438339, acc.: 85.16%] [G loss: 1.388645]\n",
      "epoch:27 step:25312 [D loss: 0.607856, acc.: 62.50%] [G loss: 1.387273]\n",
      "epoch:27 step:25313 [D loss: 0.571655, acc.: 69.53%] [G loss: 1.676646]\n",
      "epoch:27 step:25314 [D loss: 0.457532, acc.: 78.12%] [G loss: 1.161470]\n",
      "epoch:27 step:25315 [D loss: 0.615809, acc.: 65.62%] [G loss: 1.609203]\n",
      "epoch:27 step:25316 [D loss: 0.634196, acc.: 71.09%] [G loss: 1.533038]\n",
      "epoch:27 step:25317 [D loss: 0.439808, acc.: 82.03%] [G loss: 1.389891]\n",
      "epoch:27 step:25318 [D loss: 0.589749, acc.: 71.09%] [G loss: 1.384796]\n",
      "epoch:27 step:25319 [D loss: 0.652395, acc.: 57.03%] [G loss: 1.094240]\n",
      "epoch:27 step:25320 [D loss: 0.553499, acc.: 69.53%] [G loss: 1.161139]\n",
      "epoch:27 step:25321 [D loss: 0.595440, acc.: 67.97%] [G loss: 1.700843]\n",
      "epoch:27 step:25322 [D loss: 0.660734, acc.: 65.62%] [G loss: 1.284332]\n",
      "epoch:27 step:25323 [D loss: 0.480303, acc.: 78.12%] [G loss: 1.004340]\n",
      "epoch:27 step:25324 [D loss: 0.668063, acc.: 64.84%] [G loss: 0.802315]\n",
      "epoch:27 step:25325 [D loss: 0.531962, acc.: 71.88%] [G loss: 1.727223]\n",
      "epoch:27 step:25326 [D loss: 0.459582, acc.: 78.91%] [G loss: 1.353959]\n",
      "epoch:27 step:25327 [D loss: 0.799751, acc.: 53.91%] [G loss: 1.241867]\n",
      "epoch:27 step:25328 [D loss: 0.578945, acc.: 72.66%] [G loss: 1.479656]\n",
      "epoch:27 step:25329 [D loss: 0.470658, acc.: 79.69%] [G loss: 1.650949]\n",
      "epoch:27 step:25330 [D loss: 0.711973, acc.: 57.81%] [G loss: 1.329337]\n",
      "epoch:27 step:25331 [D loss: 0.442726, acc.: 81.25%] [G loss: 1.404200]\n",
      "epoch:27 step:25332 [D loss: 0.558668, acc.: 75.78%] [G loss: 1.319844]\n",
      "epoch:27 step:25333 [D loss: 0.423846, acc.: 82.03%] [G loss: 1.375590]\n",
      "epoch:27 step:25334 [D loss: 0.571770, acc.: 70.31%] [G loss: 1.891821]\n",
      "epoch:27 step:25335 [D loss: 0.378643, acc.: 82.81%] [G loss: 1.588192]\n",
      "epoch:27 step:25336 [D loss: 0.407216, acc.: 86.72%] [G loss: 1.558846]\n",
      "epoch:27 step:25337 [D loss: 0.509852, acc.: 76.56%] [G loss: 1.574172]\n",
      "epoch:27 step:25338 [D loss: 0.496369, acc.: 74.22%] [G loss: 1.550164]\n",
      "epoch:27 step:25339 [D loss: 0.659060, acc.: 61.72%] [G loss: 1.204655]\n",
      "epoch:27 step:25340 [D loss: 0.767798, acc.: 55.47%] [G loss: 1.419890]\n",
      "epoch:27 step:25341 [D loss: 0.554898, acc.: 69.53%] [G loss: 1.424185]\n",
      "epoch:27 step:25342 [D loss: 0.459322, acc.: 77.34%] [G loss: 1.580779]\n",
      "epoch:27 step:25343 [D loss: 0.625263, acc.: 64.84%] [G loss: 1.058351]\n",
      "epoch:27 step:25344 [D loss: 0.611601, acc.: 64.06%] [G loss: 1.196882]\n",
      "epoch:27 step:25345 [D loss: 0.671021, acc.: 64.06%] [G loss: 1.616821]\n",
      "epoch:27 step:25346 [D loss: 0.582881, acc.: 67.19%] [G loss: 1.068644]\n",
      "epoch:27 step:25347 [D loss: 0.659617, acc.: 62.50%] [G loss: 1.235347]\n",
      "epoch:27 step:25348 [D loss: 0.573129, acc.: 66.41%] [G loss: 1.360605]\n",
      "epoch:27 step:25349 [D loss: 0.385778, acc.: 84.38%] [G loss: 1.473913]\n",
      "epoch:27 step:25350 [D loss: 0.445337, acc.: 83.59%] [G loss: 1.460699]\n",
      "epoch:27 step:25351 [D loss: 0.644638, acc.: 58.59%] [G loss: 1.586531]\n",
      "epoch:27 step:25352 [D loss: 0.529762, acc.: 75.00%] [G loss: 1.766184]\n",
      "epoch:27 step:25353 [D loss: 0.555694, acc.: 69.53%] [G loss: 1.176558]\n",
      "epoch:27 step:25354 [D loss: 0.436239, acc.: 82.81%] [G loss: 1.730241]\n",
      "epoch:27 step:25355 [D loss: 0.673533, acc.: 61.72%] [G loss: 1.453004]\n",
      "epoch:27 step:25356 [D loss: 0.654187, acc.: 61.72%] [G loss: 1.277279]\n",
      "epoch:27 step:25357 [D loss: 0.798004, acc.: 50.78%] [G loss: 1.189569]\n",
      "epoch:27 step:25358 [D loss: 0.597239, acc.: 71.09%] [G loss: 1.429898]\n",
      "epoch:27 step:25359 [D loss: 0.438784, acc.: 82.81%] [G loss: 1.428682]\n",
      "epoch:27 step:25360 [D loss: 0.511852, acc.: 75.78%] [G loss: 1.701093]\n",
      "epoch:27 step:25361 [D loss: 0.668336, acc.: 63.28%] [G loss: 1.449784]\n",
      "epoch:27 step:25362 [D loss: 0.473940, acc.: 77.34%] [G loss: 1.513265]\n",
      "epoch:27 step:25363 [D loss: 0.575340, acc.: 70.31%] [G loss: 1.602892]\n",
      "epoch:27 step:25364 [D loss: 0.572322, acc.: 68.75%] [G loss: 1.275419]\n",
      "epoch:27 step:25365 [D loss: 0.594711, acc.: 70.31%] [G loss: 1.476622]\n",
      "epoch:27 step:25366 [D loss: 0.461078, acc.: 77.34%] [G loss: 1.647207]\n",
      "epoch:27 step:25367 [D loss: 0.628097, acc.: 64.06%] [G loss: 1.347504]\n",
      "epoch:27 step:25368 [D loss: 0.678862, acc.: 59.38%] [G loss: 1.429867]\n",
      "epoch:27 step:25369 [D loss: 0.437425, acc.: 85.16%] [G loss: 1.385908]\n",
      "epoch:27 step:25370 [D loss: 0.636339, acc.: 63.28%] [G loss: 1.187404]\n",
      "epoch:27 step:25371 [D loss: 0.470562, acc.: 75.78%] [G loss: 1.431874]\n",
      "epoch:27 step:25372 [D loss: 0.384317, acc.: 82.81%] [G loss: 1.808867]\n",
      "epoch:27 step:25373 [D loss: 0.529211, acc.: 75.00%] [G loss: 1.320983]\n",
      "epoch:27 step:25374 [D loss: 0.478884, acc.: 78.91%] [G loss: 1.539994]\n",
      "epoch:27 step:25375 [D loss: 0.681313, acc.: 63.28%] [G loss: 1.027969]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:27 step:25376 [D loss: 0.612923, acc.: 71.09%] [G loss: 1.139405]\n",
      "epoch:27 step:25377 [D loss: 0.602942, acc.: 65.62%] [G loss: 1.491857]\n",
      "epoch:27 step:25378 [D loss: 0.622019, acc.: 71.09%] [G loss: 1.253142]\n",
      "epoch:27 step:25379 [D loss: 0.484428, acc.: 74.22%] [G loss: 1.787901]\n",
      "epoch:27 step:25380 [D loss: 0.593061, acc.: 64.84%] [G loss: 1.369873]\n",
      "epoch:27 step:25381 [D loss: 0.445089, acc.: 78.12%] [G loss: 1.538558]\n",
      "epoch:27 step:25382 [D loss: 0.713810, acc.: 55.47%] [G loss: 1.612367]\n",
      "epoch:27 step:25383 [D loss: 0.651531, acc.: 63.28%] [G loss: 1.402928]\n",
      "epoch:27 step:25384 [D loss: 0.482697, acc.: 80.47%] [G loss: 1.532243]\n",
      "epoch:27 step:25385 [D loss: 0.425315, acc.: 79.69%] [G loss: 1.252217]\n",
      "epoch:27 step:25386 [D loss: 0.668456, acc.: 62.50%] [G loss: 1.433878]\n",
      "epoch:27 step:25387 [D loss: 0.607478, acc.: 70.31%] [G loss: 1.674053]\n",
      "epoch:27 step:25388 [D loss: 0.474044, acc.: 78.12%] [G loss: 1.466043]\n",
      "epoch:27 step:25389 [D loss: 0.428677, acc.: 83.59%] [G loss: 1.506606]\n",
      "epoch:27 step:25390 [D loss: 0.509688, acc.: 76.56%] [G loss: 1.697017]\n",
      "epoch:27 step:25391 [D loss: 0.450585, acc.: 80.47%] [G loss: 1.689939]\n",
      "epoch:27 step:25392 [D loss: 0.613665, acc.: 67.97%] [G loss: 1.280027]\n",
      "epoch:27 step:25393 [D loss: 0.478066, acc.: 77.34%] [G loss: 1.393727]\n",
      "epoch:27 step:25394 [D loss: 0.454606, acc.: 78.12%] [G loss: 1.675733]\n",
      "epoch:27 step:25395 [D loss: 0.462242, acc.: 80.47%] [G loss: 1.371495]\n",
      "epoch:27 step:25396 [D loss: 0.572510, acc.: 70.31%] [G loss: 1.371495]\n",
      "epoch:27 step:25397 [D loss: 0.484782, acc.: 78.91%] [G loss: 1.306369]\n",
      "epoch:27 step:25398 [D loss: 0.661978, acc.: 64.84%] [G loss: 1.102118]\n",
      "epoch:27 step:25399 [D loss: 0.477064, acc.: 76.56%] [G loss: 1.507812]\n",
      "epoch:27 step:25400 [D loss: 0.501498, acc.: 77.34%] [G loss: 1.344286]\n",
      "epoch:27 step:25401 [D loss: 0.735385, acc.: 59.38%] [G loss: 1.479879]\n",
      "epoch:27 step:25402 [D loss: 0.646715, acc.: 61.72%] [G loss: 1.938893]\n",
      "epoch:27 step:25403 [D loss: 0.395857, acc.: 85.16%] [G loss: 1.428576]\n",
      "epoch:27 step:25404 [D loss: 0.417967, acc.: 82.81%] [G loss: 1.811488]\n",
      "epoch:27 step:25405 [D loss: 0.544442, acc.: 73.44%] [G loss: 1.237725]\n",
      "epoch:27 step:25406 [D loss: 0.460217, acc.: 79.69%] [G loss: 1.580935]\n",
      "epoch:27 step:25407 [D loss: 0.431520, acc.: 80.47%] [G loss: 1.254168]\n",
      "epoch:27 step:25408 [D loss: 0.622152, acc.: 67.19%] [G loss: 1.801157]\n",
      "epoch:27 step:25409 [D loss: 0.730324, acc.: 53.91%] [G loss: 1.234082]\n",
      "epoch:27 step:25410 [D loss: 0.539261, acc.: 72.66%] [G loss: 1.481352]\n",
      "epoch:27 step:25411 [D loss: 0.468783, acc.: 78.12%] [G loss: 1.084653]\n",
      "epoch:27 step:25412 [D loss: 0.581154, acc.: 69.53%] [G loss: 1.142118]\n",
      "epoch:27 step:25413 [D loss: 0.665739, acc.: 60.94%] [G loss: 1.193802]\n",
      "epoch:27 step:25414 [D loss: 0.656719, acc.: 60.16%] [G loss: 1.584290]\n",
      "epoch:27 step:25415 [D loss: 0.684937, acc.: 59.38%] [G loss: 1.532813]\n",
      "epoch:27 step:25416 [D loss: 0.372442, acc.: 87.50%] [G loss: 1.615735]\n",
      "epoch:27 step:25417 [D loss: 0.520382, acc.: 75.00%] [G loss: 0.981386]\n",
      "epoch:27 step:25418 [D loss: 0.475648, acc.: 79.69%] [G loss: 1.283383]\n",
      "epoch:27 step:25419 [D loss: 0.653572, acc.: 59.38%] [G loss: 1.379719]\n",
      "epoch:27 step:25420 [D loss: 0.548191, acc.: 75.00%] [G loss: 1.578913]\n",
      "epoch:27 step:25421 [D loss: 0.724736, acc.: 58.59%] [G loss: 1.200129]\n",
      "epoch:27 step:25422 [D loss: 0.425893, acc.: 80.47%] [G loss: 1.235636]\n",
      "epoch:27 step:25423 [D loss: 0.595426, acc.: 71.09%] [G loss: 1.210107]\n",
      "epoch:27 step:25424 [D loss: 0.605643, acc.: 64.06%] [G loss: 1.036634]\n",
      "epoch:27 step:25425 [D loss: 0.546450, acc.: 74.22%] [G loss: 1.221034]\n",
      "epoch:27 step:25426 [D loss: 0.481185, acc.: 75.78%] [G loss: 1.592635]\n",
      "epoch:27 step:25427 [D loss: 0.514871, acc.: 75.00%] [G loss: 1.498570]\n",
      "epoch:27 step:25428 [D loss: 0.601084, acc.: 70.31%] [G loss: 1.239834]\n",
      "epoch:27 step:25429 [D loss: 0.595459, acc.: 69.53%] [G loss: 1.450647]\n",
      "epoch:27 step:25430 [D loss: 0.490187, acc.: 75.78%] [G loss: 1.511979]\n",
      "epoch:27 step:25431 [D loss: 0.566057, acc.: 67.97%] [G loss: 1.740335]\n",
      "epoch:27 step:25432 [D loss: 0.612160, acc.: 67.97%] [G loss: 0.973382]\n",
      "epoch:27 step:25433 [D loss: 0.611760, acc.: 65.62%] [G loss: 1.305816]\n",
      "epoch:27 step:25434 [D loss: 0.440353, acc.: 82.81%] [G loss: 1.514706]\n",
      "epoch:27 step:25435 [D loss: 0.638781, acc.: 64.84%] [G loss: 1.087442]\n",
      "epoch:27 step:25436 [D loss: 0.724712, acc.: 59.38%] [G loss: 1.292032]\n",
      "epoch:27 step:25437 [D loss: 0.521793, acc.: 69.53%] [G loss: 1.496550]\n",
      "epoch:27 step:25438 [D loss: 0.706540, acc.: 59.38%] [G loss: 1.167210]\n",
      "epoch:27 step:25439 [D loss: 0.667645, acc.: 63.28%] [G loss: 1.127005]\n",
      "epoch:27 step:25440 [D loss: 0.676834, acc.: 58.59%] [G loss: 1.521379]\n",
      "epoch:27 step:25441 [D loss: 0.585987, acc.: 68.75%] [G loss: 1.074507]\n",
      "epoch:27 step:25442 [D loss: 0.568178, acc.: 74.22%] [G loss: 1.069623]\n",
      "epoch:27 step:25443 [D loss: 0.502664, acc.: 73.44%] [G loss: 1.498782]\n",
      "epoch:27 step:25444 [D loss: 0.498323, acc.: 78.91%] [G loss: 1.332897]\n",
      "epoch:27 step:25445 [D loss: 0.546466, acc.: 73.44%] [G loss: 1.832798]\n",
      "epoch:27 step:25446 [D loss: 0.475113, acc.: 80.47%] [G loss: 1.253968]\n",
      "epoch:27 step:25447 [D loss: 0.429446, acc.: 79.69%] [G loss: 1.542560]\n",
      "epoch:27 step:25448 [D loss: 0.488312, acc.: 76.56%] [G loss: 1.645442]\n",
      "epoch:27 step:25449 [D loss: 0.491148, acc.: 78.12%] [G loss: 1.641972]\n",
      "epoch:27 step:25450 [D loss: 0.614455, acc.: 64.06%] [G loss: 1.368521]\n",
      "epoch:27 step:25451 [D loss: 0.504538, acc.: 72.66%] [G loss: 1.234040]\n",
      "epoch:27 step:25452 [D loss: 0.526417, acc.: 74.22%] [G loss: 1.348095]\n",
      "epoch:27 step:25453 [D loss: 0.414182, acc.: 82.81%] [G loss: 1.882062]\n",
      "epoch:27 step:25454 [D loss: 0.487978, acc.: 75.00%] [G loss: 1.422342]\n",
      "epoch:27 step:25455 [D loss: 0.426198, acc.: 80.47%] [G loss: 1.516334]\n",
      "epoch:27 step:25456 [D loss: 0.638140, acc.: 64.84%] [G loss: 1.092979]\n",
      "epoch:27 step:25457 [D loss: 0.685210, acc.: 59.38%] [G loss: 1.387616]\n",
      "epoch:27 step:25458 [D loss: 0.422669, acc.: 82.81%] [G loss: 1.691103]\n",
      "epoch:27 step:25459 [D loss: 0.327842, acc.: 90.62%] [G loss: 2.001423]\n",
      "epoch:27 step:25460 [D loss: 0.396496, acc.: 82.81%] [G loss: 1.655385]\n",
      "epoch:27 step:25461 [D loss: 0.709456, acc.: 55.47%] [G loss: 1.301951]\n",
      "epoch:27 step:25462 [D loss: 0.609385, acc.: 73.44%] [G loss: 1.268893]\n",
      "epoch:27 step:25463 [D loss: 0.381938, acc.: 85.16%] [G loss: 1.415451]\n",
      "epoch:27 step:25464 [D loss: 0.537396, acc.: 75.00%] [G loss: 1.543931]\n",
      "epoch:27 step:25465 [D loss: 0.470205, acc.: 81.25%] [G loss: 1.713207]\n",
      "epoch:27 step:25466 [D loss: 0.426706, acc.: 82.81%] [G loss: 1.763549]\n",
      "epoch:27 step:25467 [D loss: 0.742115, acc.: 54.69%] [G loss: 1.779483]\n",
      "epoch:27 step:25468 [D loss: 0.659456, acc.: 65.62%] [G loss: 1.169847]\n",
      "epoch:27 step:25469 [D loss: 0.417487, acc.: 81.25%] [G loss: 1.679872]\n",
      "epoch:27 step:25470 [D loss: 0.679795, acc.: 64.06%] [G loss: 1.396045]\n",
      "epoch:27 step:25471 [D loss: 0.453131, acc.: 83.59%] [G loss: 1.532193]\n",
      "epoch:27 step:25472 [D loss: 0.612415, acc.: 69.53%] [G loss: 1.495870]\n",
      "epoch:27 step:25473 [D loss: 0.576200, acc.: 71.09%] [G loss: 1.172475]\n",
      "epoch:27 step:25474 [D loss: 0.590080, acc.: 73.44%] [G loss: 1.374249]\n",
      "epoch:27 step:25475 [D loss: 0.476883, acc.: 81.25%] [G loss: 1.502266]\n",
      "epoch:27 step:25476 [D loss: 0.476671, acc.: 74.22%] [G loss: 1.650957]\n",
      "epoch:27 step:25477 [D loss: 0.505143, acc.: 75.78%] [G loss: 2.025814]\n",
      "epoch:27 step:25478 [D loss: 0.608886, acc.: 64.84%] [G loss: 1.309361]\n",
      "epoch:27 step:25479 [D loss: 0.641600, acc.: 65.62%] [G loss: 1.231468]\n",
      "epoch:27 step:25480 [D loss: 0.493793, acc.: 75.00%] [G loss: 1.309253]\n",
      "epoch:27 step:25481 [D loss: 0.530974, acc.: 77.34%] [G loss: 1.602393]\n",
      "epoch:27 step:25482 [D loss: 0.514544, acc.: 82.03%] [G loss: 1.537185]\n",
      "epoch:27 step:25483 [D loss: 0.485882, acc.: 78.12%] [G loss: 1.441889]\n",
      "epoch:27 step:25484 [D loss: 0.500617, acc.: 78.12%] [G loss: 1.430235]\n",
      "epoch:27 step:25485 [D loss: 0.727497, acc.: 57.81%] [G loss: 1.444644]\n",
      "epoch:27 step:25486 [D loss: 0.432019, acc.: 79.69%] [G loss: 1.935857]\n",
      "epoch:27 step:25487 [D loss: 0.469845, acc.: 78.12%] [G loss: 1.296932]\n",
      "epoch:27 step:25488 [D loss: 0.594877, acc.: 68.75%] [G loss: 0.985794]\n",
      "epoch:27 step:25489 [D loss: 0.543725, acc.: 72.66%] [G loss: 1.614086]\n",
      "epoch:27 step:25490 [D loss: 0.645716, acc.: 61.72%] [G loss: 1.496437]\n",
      "epoch:27 step:25491 [D loss: 0.526453, acc.: 74.22%] [G loss: 1.716771]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:27 step:25492 [D loss: 0.514266, acc.: 73.44%] [G loss: 1.328590]\n",
      "epoch:27 step:25493 [D loss: 0.415522, acc.: 82.03%] [G loss: 1.062129]\n",
      "epoch:27 step:25494 [D loss: 0.615382, acc.: 66.41%] [G loss: 1.760192]\n",
      "epoch:27 step:25495 [D loss: 0.418581, acc.: 82.81%] [G loss: 1.442491]\n",
      "epoch:27 step:25496 [D loss: 0.512524, acc.: 73.44%] [G loss: 1.453046]\n",
      "epoch:27 step:25497 [D loss: 0.576570, acc.: 70.31%] [G loss: 1.744635]\n",
      "epoch:27 step:25498 [D loss: 0.526102, acc.: 70.31%] [G loss: 1.808216]\n",
      "epoch:27 step:25499 [D loss: 0.629136, acc.: 65.62%] [G loss: 1.399628]\n",
      "epoch:27 step:25500 [D loss: 0.449329, acc.: 85.16%] [G loss: 1.664144]\n",
      "epoch:27 step:25501 [D loss: 0.489034, acc.: 78.12%] [G loss: 1.568980]\n",
      "epoch:27 step:25502 [D loss: 0.327502, acc.: 92.19%] [G loss: 1.366787]\n",
      "epoch:27 step:25503 [D loss: 0.385891, acc.: 85.94%] [G loss: 1.831840]\n",
      "epoch:27 step:25504 [D loss: 0.545177, acc.: 74.22%] [G loss: 1.396859]\n",
      "epoch:27 step:25505 [D loss: 0.546010, acc.: 70.31%] [G loss: 1.208524]\n",
      "epoch:27 step:25506 [D loss: 0.767133, acc.: 52.34%] [G loss: 1.218102]\n",
      "epoch:27 step:25507 [D loss: 0.453450, acc.: 82.03%] [G loss: 1.284521]\n",
      "epoch:27 step:25508 [D loss: 0.567417, acc.: 69.53%] [G loss: 1.334066]\n",
      "epoch:27 step:25509 [D loss: 0.644677, acc.: 67.97%] [G loss: 1.598375]\n",
      "epoch:27 step:25510 [D loss: 0.440101, acc.: 80.47%] [G loss: 1.952697]\n",
      "epoch:27 step:25511 [D loss: 0.499073, acc.: 78.91%] [G loss: 1.380815]\n",
      "epoch:27 step:25512 [D loss: 0.615877, acc.: 65.62%] [G loss: 1.361763]\n",
      "epoch:27 step:25513 [D loss: 0.562024, acc.: 69.53%] [G loss: 1.103892]\n",
      "epoch:27 step:25514 [D loss: 0.512595, acc.: 77.34%] [G loss: 1.554980]\n",
      "epoch:27 step:25515 [D loss: 0.562850, acc.: 75.78%] [G loss: 1.041234]\n",
      "epoch:27 step:25516 [D loss: 0.548122, acc.: 77.34%] [G loss: 1.160480]\n",
      "epoch:27 step:25517 [D loss: 0.407807, acc.: 82.81%] [G loss: 1.508420]\n",
      "epoch:27 step:25518 [D loss: 0.579248, acc.: 70.31%] [G loss: 1.694943]\n",
      "epoch:27 step:25519 [D loss: 0.431506, acc.: 83.59%] [G loss: 1.361530]\n",
      "epoch:27 step:25520 [D loss: 0.643000, acc.: 60.16%] [G loss: 1.225917]\n",
      "epoch:27 step:25521 [D loss: 0.471782, acc.: 82.03%] [G loss: 1.448859]\n",
      "epoch:27 step:25522 [D loss: 0.408198, acc.: 82.03%] [G loss: 1.392047]\n",
      "epoch:27 step:25523 [D loss: 0.727482, acc.: 55.47%] [G loss: 1.491987]\n",
      "epoch:27 step:25524 [D loss: 0.483981, acc.: 78.91%] [G loss: 1.446075]\n",
      "epoch:27 step:25525 [D loss: 0.552796, acc.: 70.31%] [G loss: 1.213231]\n",
      "epoch:27 step:25526 [D loss: 0.668248, acc.: 60.16%] [G loss: 1.347350]\n",
      "epoch:27 step:25527 [D loss: 0.478805, acc.: 77.34%] [G loss: 1.474914]\n",
      "epoch:27 step:25528 [D loss: 0.498658, acc.: 77.34%] [G loss: 1.518735]\n",
      "epoch:27 step:25529 [D loss: 0.419693, acc.: 82.81%] [G loss: 1.602311]\n",
      "epoch:27 step:25530 [D loss: 0.595516, acc.: 70.31%] [G loss: 1.367949]\n",
      "epoch:27 step:25531 [D loss: 0.530053, acc.: 70.31%] [G loss: 1.336563]\n",
      "epoch:27 step:25532 [D loss: 0.746673, acc.: 55.47%] [G loss: 1.093590]\n",
      "epoch:27 step:25533 [D loss: 0.531481, acc.: 72.66%] [G loss: 1.567884]\n",
      "epoch:27 step:25534 [D loss: 0.453810, acc.: 78.12%] [G loss: 1.188855]\n",
      "epoch:27 step:25535 [D loss: 0.646786, acc.: 66.41%] [G loss: 1.495881]\n",
      "epoch:27 step:25536 [D loss: 0.428434, acc.: 82.81%] [G loss: 1.353817]\n",
      "epoch:27 step:25537 [D loss: 0.596670, acc.: 70.31%] [G loss: 1.366907]\n",
      "epoch:27 step:25538 [D loss: 0.516818, acc.: 73.44%] [G loss: 1.317852]\n",
      "epoch:27 step:25539 [D loss: 0.508332, acc.: 73.44%] [G loss: 1.257383]\n",
      "epoch:27 step:25540 [D loss: 0.558035, acc.: 69.53%] [G loss: 1.404434]\n",
      "epoch:27 step:25541 [D loss: 0.568147, acc.: 67.19%] [G loss: 1.802724]\n",
      "epoch:27 step:25542 [D loss: 0.578490, acc.: 74.22%] [G loss: 1.577107]\n",
      "epoch:27 step:25543 [D loss: 0.515185, acc.: 75.78%] [G loss: 1.575506]\n",
      "epoch:27 step:25544 [D loss: 0.431160, acc.: 83.59%] [G loss: 1.805430]\n",
      "epoch:27 step:25545 [D loss: 0.429894, acc.: 82.03%] [G loss: 1.716531]\n",
      "epoch:27 step:25546 [D loss: 0.586670, acc.: 67.97%] [G loss: 1.472519]\n",
      "epoch:27 step:25547 [D loss: 0.398703, acc.: 84.38%] [G loss: 1.466873]\n",
      "epoch:27 step:25548 [D loss: 0.290491, acc.: 91.41%] [G loss: 1.858426]\n",
      "epoch:27 step:25549 [D loss: 0.486958, acc.: 74.22%] [G loss: 1.625797]\n",
      "epoch:27 step:25550 [D loss: 0.572658, acc.: 72.66%] [G loss: 1.228227]\n",
      "epoch:27 step:25551 [D loss: 0.496552, acc.: 77.34%] [G loss: 1.237401]\n",
      "epoch:27 step:25552 [D loss: 0.551769, acc.: 71.09%] [G loss: 1.425803]\n",
      "epoch:27 step:25553 [D loss: 0.439913, acc.: 82.03%] [G loss: 1.570073]\n",
      "epoch:27 step:25554 [D loss: 0.583198, acc.: 65.62%] [G loss: 1.214997]\n",
      "epoch:27 step:25555 [D loss: 0.609296, acc.: 69.53%] [G loss: 1.654660]\n",
      "epoch:27 step:25556 [D loss: 0.567414, acc.: 67.19%] [G loss: 1.232486]\n",
      "epoch:27 step:25557 [D loss: 0.553275, acc.: 68.75%] [G loss: 1.407629]\n",
      "epoch:27 step:25558 [D loss: 0.537355, acc.: 75.00%] [G loss: 1.669370]\n",
      "epoch:27 step:25559 [D loss: 0.617842, acc.: 60.94%] [G loss: 1.661042]\n",
      "epoch:27 step:25560 [D loss: 0.543289, acc.: 67.97%] [G loss: 1.257843]\n",
      "epoch:27 step:25561 [D loss: 0.717171, acc.: 59.38%] [G loss: 1.158479]\n",
      "epoch:27 step:25562 [D loss: 0.576988, acc.: 71.88%] [G loss: 1.678084]\n",
      "epoch:27 step:25563 [D loss: 0.619511, acc.: 63.28%] [G loss: 1.617722]\n",
      "epoch:27 step:25564 [D loss: 0.388141, acc.: 85.94%] [G loss: 1.608417]\n",
      "epoch:27 step:25565 [D loss: 0.367828, acc.: 89.06%] [G loss: 1.364083]\n",
      "epoch:27 step:25566 [D loss: 0.493146, acc.: 78.12%] [G loss: 1.452240]\n",
      "epoch:27 step:25567 [D loss: 0.493382, acc.: 77.34%] [G loss: 1.475256]\n",
      "epoch:27 step:25568 [D loss: 0.416687, acc.: 82.03%] [G loss: 1.586581]\n",
      "epoch:27 step:25569 [D loss: 0.462313, acc.: 78.12%] [G loss: 1.477701]\n",
      "epoch:27 step:25570 [D loss: 0.462902, acc.: 80.47%] [G loss: 1.706565]\n",
      "epoch:27 step:25571 [D loss: 0.446800, acc.: 81.25%] [G loss: 1.646896]\n",
      "epoch:27 step:25572 [D loss: 0.676192, acc.: 60.94%] [G loss: 1.232441]\n",
      "epoch:27 step:25573 [D loss: 0.516185, acc.: 78.12%] [G loss: 1.052915]\n",
      "epoch:27 step:25574 [D loss: 0.733212, acc.: 58.59%] [G loss: 0.928385]\n",
      "epoch:27 step:25575 [D loss: 0.546470, acc.: 72.66%] [G loss: 1.318817]\n",
      "epoch:27 step:25576 [D loss: 0.558851, acc.: 71.09%] [G loss: 1.169949]\n",
      "epoch:27 step:25577 [D loss: 0.552753, acc.: 71.88%] [G loss: 1.418519]\n",
      "epoch:27 step:25578 [D loss: 0.535374, acc.: 66.41%] [G loss: 1.213913]\n",
      "epoch:27 step:25579 [D loss: 0.778303, acc.: 51.56%] [G loss: 1.110340]\n",
      "epoch:27 step:25580 [D loss: 0.467022, acc.: 78.91%] [G loss: 1.766627]\n",
      "epoch:27 step:25581 [D loss: 0.495378, acc.: 78.91%] [G loss: 1.200587]\n",
      "epoch:27 step:25582 [D loss: 0.523570, acc.: 74.22%] [G loss: 1.136966]\n",
      "epoch:27 step:25583 [D loss: 0.402760, acc.: 83.59%] [G loss: 1.623508]\n",
      "epoch:27 step:25584 [D loss: 0.384049, acc.: 89.06%] [G loss: 1.167991]\n",
      "epoch:27 step:25585 [D loss: 0.533704, acc.: 73.44%] [G loss: 1.408273]\n",
      "epoch:27 step:25586 [D loss: 0.457334, acc.: 80.47%] [G loss: 1.850262]\n",
      "epoch:27 step:25587 [D loss: 0.521572, acc.: 72.66%] [G loss: 1.333295]\n",
      "epoch:27 step:25588 [D loss: 0.504320, acc.: 75.00%] [G loss: 1.196384]\n",
      "epoch:27 step:25589 [D loss: 0.606720, acc.: 65.62%] [G loss: 0.910689]\n",
      "epoch:27 step:25590 [D loss: 0.430312, acc.: 82.81%] [G loss: 1.796828]\n",
      "epoch:27 step:25591 [D loss: 0.395592, acc.: 88.28%] [G loss: 1.496027]\n",
      "epoch:27 step:25592 [D loss: 0.550774, acc.: 71.09%] [G loss: 1.151422]\n",
      "epoch:27 step:25593 [D loss: 0.698796, acc.: 54.69%] [G loss: 1.160370]\n",
      "epoch:27 step:25594 [D loss: 0.548972, acc.: 75.78%] [G loss: 1.663143]\n",
      "epoch:27 step:25595 [D loss: 0.402369, acc.: 86.72%] [G loss: 1.454903]\n",
      "epoch:27 step:25596 [D loss: 0.536764, acc.: 73.44%] [G loss: 1.475498]\n",
      "epoch:27 step:25597 [D loss: 0.417233, acc.: 82.81%] [G loss: 1.592058]\n",
      "epoch:27 step:25598 [D loss: 0.580180, acc.: 69.53%] [G loss: 1.102192]\n",
      "epoch:27 step:25599 [D loss: 0.608535, acc.: 67.19%] [G loss: 1.211536]\n",
      "epoch:27 step:25600 [D loss: 0.625230, acc.: 65.62%] [G loss: 1.218969]\n",
      "epoch:27 step:25601 [D loss: 0.491395, acc.: 74.22%] [G loss: 1.403125]\n",
      "epoch:27 step:25602 [D loss: 0.834666, acc.: 47.66%] [G loss: 0.939608]\n",
      "epoch:27 step:25603 [D loss: 0.545805, acc.: 71.09%] [G loss: 1.692098]\n",
      "epoch:27 step:25604 [D loss: 0.461090, acc.: 78.91%] [G loss: 1.944127]\n",
      "epoch:27 step:25605 [D loss: 0.523966, acc.: 71.88%] [G loss: 1.579827]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:27 step:25606 [D loss: 0.575497, acc.: 71.88%] [G loss: 1.100643]\n",
      "epoch:27 step:25607 [D loss: 0.487331, acc.: 77.34%] [G loss: 1.163118]\n",
      "epoch:27 step:25608 [D loss: 0.437691, acc.: 80.47%] [G loss: 1.692189]\n",
      "epoch:27 step:25609 [D loss: 0.550782, acc.: 75.78%] [G loss: 1.265344]\n",
      "epoch:27 step:25610 [D loss: 0.485229, acc.: 79.69%] [G loss: 1.390394]\n",
      "epoch:27 step:25611 [D loss: 0.710438, acc.: 57.81%] [G loss: 1.462010]\n",
      "epoch:27 step:25612 [D loss: 0.544921, acc.: 75.78%] [G loss: 1.066960]\n",
      "epoch:27 step:25613 [D loss: 0.565925, acc.: 67.19%] [G loss: 1.385082]\n",
      "epoch:27 step:25614 [D loss: 0.503454, acc.: 71.09%] [G loss: 1.201539]\n",
      "epoch:27 step:25615 [D loss: 0.656799, acc.: 61.72%] [G loss: 1.215850]\n",
      "epoch:27 step:25616 [D loss: 0.494754, acc.: 80.47%] [G loss: 1.041551]\n",
      "epoch:27 step:25617 [D loss: 0.731138, acc.: 54.69%] [G loss: 1.726066]\n",
      "epoch:27 step:25618 [D loss: 0.522750, acc.: 71.88%] [G loss: 1.224290]\n",
      "epoch:27 step:25619 [D loss: 0.462222, acc.: 81.25%] [G loss: 1.519941]\n",
      "epoch:27 step:25620 [D loss: 0.522588, acc.: 73.44%] [G loss: 1.575854]\n",
      "epoch:27 step:25621 [D loss: 0.585452, acc.: 71.88%] [G loss: 1.608583]\n",
      "epoch:27 step:25622 [D loss: 0.583613, acc.: 69.53%] [G loss: 1.456515]\n",
      "epoch:27 step:25623 [D loss: 0.652115, acc.: 60.94%] [G loss: 0.933091]\n",
      "epoch:27 step:25624 [D loss: 0.731705, acc.: 58.59%] [G loss: 1.327073]\n",
      "epoch:27 step:25625 [D loss: 0.701455, acc.: 57.03%] [G loss: 1.072790]\n",
      "epoch:27 step:25626 [D loss: 0.342695, acc.: 86.72%] [G loss: 1.466961]\n",
      "epoch:27 step:25627 [D loss: 0.505212, acc.: 73.44%] [G loss: 1.704770]\n",
      "epoch:27 step:25628 [D loss: 0.430013, acc.: 85.16%] [G loss: 1.674655]\n",
      "epoch:27 step:25629 [D loss: 0.565518, acc.: 69.53%] [G loss: 1.219125]\n",
      "epoch:27 step:25630 [D loss: 0.639030, acc.: 59.38%] [G loss: 1.235435]\n",
      "epoch:27 step:25631 [D loss: 0.653057, acc.: 67.97%] [G loss: 1.585964]\n",
      "epoch:27 step:25632 [D loss: 0.513321, acc.: 77.34%] [G loss: 1.628648]\n",
      "epoch:27 step:25633 [D loss: 0.476250, acc.: 80.47%] [G loss: 1.544943]\n",
      "epoch:27 step:25634 [D loss: 0.655266, acc.: 65.62%] [G loss: 1.495873]\n",
      "epoch:27 step:25635 [D loss: 0.540359, acc.: 75.00%] [G loss: 1.494940]\n",
      "epoch:27 step:25636 [D loss: 0.763569, acc.: 53.91%] [G loss: 1.205554]\n",
      "epoch:27 step:25637 [D loss: 0.422809, acc.: 83.59%] [G loss: 2.077955]\n",
      "epoch:27 step:25638 [D loss: 0.604362, acc.: 64.06%] [G loss: 1.616397]\n",
      "epoch:27 step:25639 [D loss: 0.462283, acc.: 78.12%] [G loss: 1.693343]\n",
      "epoch:27 step:25640 [D loss: 0.529192, acc.: 71.09%] [G loss: 1.420517]\n",
      "epoch:27 step:25641 [D loss: 0.633067, acc.: 62.50%] [G loss: 1.278936]\n",
      "epoch:27 step:25642 [D loss: 0.558128, acc.: 70.31%] [G loss: 1.554881]\n",
      "epoch:27 step:25643 [D loss: 0.483234, acc.: 70.31%] [G loss: 0.776137]\n",
      "epoch:27 step:25644 [D loss: 0.620282, acc.: 67.19%] [G loss: 1.391378]\n",
      "epoch:27 step:25645 [D loss: 0.774534, acc.: 53.12%] [G loss: 1.281442]\n",
      "epoch:27 step:25646 [D loss: 0.554083, acc.: 72.66%] [G loss: 1.460349]\n",
      "epoch:27 step:25647 [D loss: 0.604087, acc.: 66.41%] [G loss: 1.525494]\n",
      "epoch:27 step:25648 [D loss: 0.542243, acc.: 74.22%] [G loss: 1.430749]\n",
      "epoch:27 step:25649 [D loss: 0.468331, acc.: 79.69%] [G loss: 1.387398]\n",
      "epoch:27 step:25650 [D loss: 0.501644, acc.: 75.78%] [G loss: 1.410237]\n",
      "epoch:27 step:25651 [D loss: 0.759869, acc.: 57.81%] [G loss: 1.316430]\n",
      "epoch:27 step:25652 [D loss: 0.499208, acc.: 75.78%] [G loss: 1.490554]\n",
      "epoch:27 step:25653 [D loss: 0.536379, acc.: 71.09%] [G loss: 1.761910]\n",
      "epoch:27 step:25654 [D loss: 0.518489, acc.: 72.66%] [G loss: 1.551506]\n",
      "epoch:27 step:25655 [D loss: 0.462390, acc.: 81.25%] [G loss: 1.558877]\n",
      "epoch:27 step:25656 [D loss: 0.571390, acc.: 72.66%] [G loss: 1.504722]\n",
      "epoch:27 step:25657 [D loss: 0.622155, acc.: 65.62%] [G loss: 1.832553]\n",
      "epoch:27 step:25658 [D loss: 0.663901, acc.: 64.06%] [G loss: 1.508819]\n",
      "epoch:27 step:25659 [D loss: 0.556895, acc.: 73.44%] [G loss: 1.251281]\n",
      "epoch:27 step:25660 [D loss: 0.506574, acc.: 72.66%] [G loss: 1.388959]\n",
      "epoch:27 step:25661 [D loss: 0.560939, acc.: 71.88%] [G loss: 1.394409]\n",
      "epoch:27 step:25662 [D loss: 0.563947, acc.: 70.31%] [G loss: 1.129810]\n",
      "epoch:27 step:25663 [D loss: 0.481289, acc.: 78.91%] [G loss: 1.306605]\n",
      "epoch:27 step:25664 [D loss: 0.493459, acc.: 75.78%] [G loss: 1.337945]\n",
      "epoch:27 step:25665 [D loss: 0.455301, acc.: 79.69%] [G loss: 1.982349]\n",
      "epoch:27 step:25666 [D loss: 0.427570, acc.: 81.25%] [G loss: 1.417147]\n",
      "epoch:27 step:25667 [D loss: 0.606005, acc.: 63.28%] [G loss: 1.283220]\n",
      "epoch:27 step:25668 [D loss: 0.491106, acc.: 77.34%] [G loss: 1.875275]\n",
      "epoch:27 step:25669 [D loss: 0.442483, acc.: 82.81%] [G loss: 1.798438]\n",
      "epoch:27 step:25670 [D loss: 0.461320, acc.: 78.91%] [G loss: 1.208426]\n",
      "epoch:27 step:25671 [D loss: 0.679824, acc.: 62.50%] [G loss: 1.410359]\n",
      "epoch:27 step:25672 [D loss: 0.529782, acc.: 77.34%] [G loss: 1.828090]\n",
      "epoch:27 step:25673 [D loss: 0.633923, acc.: 64.84%] [G loss: 1.765047]\n",
      "epoch:27 step:25674 [D loss: 0.465465, acc.: 73.44%] [G loss: 1.373428]\n",
      "epoch:27 step:25675 [D loss: 0.627157, acc.: 61.72%] [G loss: 1.428820]\n",
      "epoch:27 step:25676 [D loss: 0.499979, acc.: 79.69%] [G loss: 1.133258]\n",
      "epoch:27 step:25677 [D loss: 0.663658, acc.: 61.72%] [G loss: 1.324623]\n",
      "epoch:27 step:25678 [D loss: 0.431341, acc.: 86.72%] [G loss: 1.410275]\n",
      "epoch:27 step:25679 [D loss: 0.542127, acc.: 71.09%] [G loss: 1.293595]\n",
      "epoch:27 step:25680 [D loss: 0.575336, acc.: 68.75%] [G loss: 1.253536]\n",
      "epoch:27 step:25681 [D loss: 0.728510, acc.: 57.03%] [G loss: 1.325540]\n",
      "epoch:27 step:25682 [D loss: 0.327837, acc.: 88.28%] [G loss: 1.712436]\n",
      "epoch:27 step:25683 [D loss: 0.445165, acc.: 84.38%] [G loss: 1.402715]\n",
      "epoch:27 step:25684 [D loss: 0.591224, acc.: 68.75%] [G loss: 2.040943]\n",
      "epoch:27 step:25685 [D loss: 0.725748, acc.: 54.69%] [G loss: 1.466841]\n",
      "epoch:27 step:25686 [D loss: 0.516507, acc.: 75.00%] [G loss: 1.430354]\n",
      "epoch:27 step:25687 [D loss: 0.465441, acc.: 79.69%] [G loss: 1.586697]\n",
      "epoch:27 step:25688 [D loss: 0.447971, acc.: 77.34%] [G loss: 1.702254]\n",
      "epoch:27 step:25689 [D loss: 0.480558, acc.: 80.47%] [G loss: 1.264357]\n",
      "epoch:27 step:25690 [D loss: 0.522861, acc.: 74.22%] [G loss: 1.542284]\n",
      "epoch:27 step:25691 [D loss: 0.554484, acc.: 71.09%] [G loss: 1.373945]\n",
      "epoch:27 step:25692 [D loss: 0.655233, acc.: 60.94%] [G loss: 1.276683]\n",
      "epoch:27 step:25693 [D loss: 0.530818, acc.: 72.66%] [G loss: 1.006189]\n",
      "epoch:27 step:25694 [D loss: 0.415110, acc.: 84.38%] [G loss: 1.643313]\n",
      "epoch:27 step:25695 [D loss: 0.582479, acc.: 71.09%] [G loss: 1.184271]\n",
      "epoch:27 step:25696 [D loss: 0.697849, acc.: 59.38%] [G loss: 1.242549]\n",
      "epoch:27 step:25697 [D loss: 0.324280, acc.: 92.97%] [G loss: 1.628335]\n",
      "epoch:27 step:25698 [D loss: 0.435010, acc.: 81.25%] [G loss: 1.272237]\n",
      "epoch:27 step:25699 [D loss: 0.522866, acc.: 68.75%] [G loss: 1.071172]\n",
      "epoch:27 step:25700 [D loss: 0.600790, acc.: 65.62%] [G loss: 1.090164]\n",
      "epoch:27 step:25701 [D loss: 0.477338, acc.: 78.12%] [G loss: 1.369403]\n",
      "epoch:27 step:25702 [D loss: 0.550179, acc.: 73.44%] [G loss: 1.618663]\n",
      "epoch:27 step:25703 [D loss: 0.670621, acc.: 60.16%] [G loss: 0.981359]\n",
      "epoch:27 step:25704 [D loss: 0.559333, acc.: 70.31%] [G loss: 1.082960]\n",
      "epoch:27 step:25705 [D loss: 0.602065, acc.: 68.75%] [G loss: 1.354381]\n",
      "epoch:27 step:25706 [D loss: 0.544836, acc.: 69.53%] [G loss: 2.214020]\n",
      "epoch:27 step:25707 [D loss: 0.460334, acc.: 82.03%] [G loss: 1.434660]\n",
      "epoch:27 step:25708 [D loss: 0.656790, acc.: 57.03%] [G loss: 1.143230]\n",
      "epoch:27 step:25709 [D loss: 0.596334, acc.: 68.75%] [G loss: 1.633230]\n",
      "epoch:27 step:25710 [D loss: 0.453885, acc.: 78.91%] [G loss: 1.387930]\n",
      "epoch:27 step:25711 [D loss: 0.614233, acc.: 67.19%] [G loss: 1.308372]\n",
      "epoch:27 step:25712 [D loss: 0.543465, acc.: 74.22%] [G loss: 1.250011]\n",
      "epoch:27 step:25713 [D loss: 0.547899, acc.: 67.97%] [G loss: 1.933616]\n",
      "epoch:27 step:25714 [D loss: 0.424121, acc.: 82.03%] [G loss: 1.427934]\n",
      "epoch:27 step:25715 [D loss: 0.570450, acc.: 74.22%] [G loss: 1.613937]\n",
      "epoch:27 step:25716 [D loss: 0.434172, acc.: 83.59%] [G loss: 1.456208]\n",
      "epoch:27 step:25717 [D loss: 0.554186, acc.: 71.09%] [G loss: 1.516071]\n",
      "epoch:27 step:25718 [D loss: 0.587619, acc.: 65.62%] [G loss: 1.660864]\n",
      "epoch:27 step:25719 [D loss: 0.503689, acc.: 78.12%] [G loss: 1.629654]\n",
      "epoch:27 step:25720 [D loss: 0.786081, acc.: 51.56%] [G loss: 1.367164]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:27 step:25721 [D loss: 0.437518, acc.: 82.81%] [G loss: 1.512043]\n",
      "epoch:27 step:25722 [D loss: 0.486036, acc.: 78.12%] [G loss: 1.504916]\n",
      "epoch:27 step:25723 [D loss: 0.393959, acc.: 84.38%] [G loss: 1.472327]\n",
      "epoch:27 step:25724 [D loss: 0.597950, acc.: 71.09%] [G loss: 1.399411]\n",
      "epoch:27 step:25725 [D loss: 0.527141, acc.: 74.22%] [G loss: 1.126288]\n",
      "epoch:27 step:25726 [D loss: 0.665927, acc.: 63.28%] [G loss: 1.334612]\n",
      "epoch:27 step:25727 [D loss: 0.570592, acc.: 65.62%] [G loss: 1.217226]\n",
      "epoch:27 step:25728 [D loss: 0.670316, acc.: 62.50%] [G loss: 0.831259]\n",
      "epoch:27 step:25729 [D loss: 0.516235, acc.: 78.12%] [G loss: 1.413457]\n",
      "epoch:27 step:25730 [D loss: 0.479377, acc.: 77.34%] [G loss: 1.400030]\n",
      "epoch:27 step:25731 [D loss: 0.680701, acc.: 60.94%] [G loss: 1.311917]\n",
      "epoch:27 step:25732 [D loss: 0.506503, acc.: 78.12%] [G loss: 1.454999]\n",
      "epoch:27 step:25733 [D loss: 0.595570, acc.: 69.53%] [G loss: 1.120411]\n",
      "epoch:27 step:25734 [D loss: 0.520110, acc.: 77.34%] [G loss: 1.195792]\n",
      "epoch:27 step:25735 [D loss: 0.443533, acc.: 83.59%] [G loss: 1.269128]\n",
      "epoch:27 step:25736 [D loss: 0.549738, acc.: 71.09%] [G loss: 1.474480]\n",
      "epoch:27 step:25737 [D loss: 0.669384, acc.: 60.16%] [G loss: 1.437355]\n",
      "epoch:27 step:25738 [D loss: 0.500082, acc.: 75.00%] [G loss: 1.092350]\n",
      "epoch:27 step:25739 [D loss: 0.507176, acc.: 75.78%] [G loss: 1.674288]\n",
      "epoch:27 step:25740 [D loss: 0.500342, acc.: 76.56%] [G loss: 1.419418]\n",
      "epoch:27 step:25741 [D loss: 0.455892, acc.: 79.69%] [G loss: 1.626313]\n",
      "epoch:27 step:25742 [D loss: 0.527979, acc.: 75.78%] [G loss: 1.110008]\n",
      "epoch:27 step:25743 [D loss: 0.414518, acc.: 82.81%] [G loss: 1.390748]\n",
      "epoch:27 step:25744 [D loss: 0.468718, acc.: 75.78%] [G loss: 1.837174]\n",
      "epoch:27 step:25745 [D loss: 0.595363, acc.: 70.31%] [G loss: 1.408240]\n",
      "epoch:27 step:25746 [D loss: 0.596839, acc.: 70.31%] [G loss: 1.384084]\n",
      "epoch:27 step:25747 [D loss: 0.614149, acc.: 67.19%] [G loss: 1.471540]\n",
      "epoch:27 step:25748 [D loss: 0.449731, acc.: 78.12%] [G loss: 2.081815]\n",
      "epoch:27 step:25749 [D loss: 0.558184, acc.: 73.44%] [G loss: 1.707973]\n",
      "epoch:27 step:25750 [D loss: 0.532104, acc.: 71.88%] [G loss: 1.406713]\n",
      "epoch:27 step:25751 [D loss: 0.632769, acc.: 63.28%] [G loss: 1.470947]\n",
      "epoch:27 step:25752 [D loss: 0.552049, acc.: 71.09%] [G loss: 1.379083]\n",
      "epoch:27 step:25753 [D loss: 0.457220, acc.: 77.34%] [G loss: 1.316579]\n",
      "epoch:27 step:25754 [D loss: 0.300574, acc.: 92.19%] [G loss: 1.398449]\n",
      "epoch:27 step:25755 [D loss: 0.672061, acc.: 59.38%] [G loss: 1.371921]\n",
      "epoch:27 step:25756 [D loss: 0.737297, acc.: 60.16%] [G loss: 1.202283]\n",
      "epoch:27 step:25757 [D loss: 0.403743, acc.: 85.16%] [G loss: 1.112152]\n",
      "epoch:27 step:25758 [D loss: 0.409047, acc.: 85.16%] [G loss: 1.947624]\n",
      "epoch:27 step:25759 [D loss: 0.533116, acc.: 75.00%] [G loss: 1.640919]\n",
      "epoch:27 step:25760 [D loss: 0.547676, acc.: 71.09%] [G loss: 1.559193]\n",
      "epoch:27 step:25761 [D loss: 0.642936, acc.: 64.06%] [G loss: 0.799534]\n",
      "epoch:27 step:25762 [D loss: 0.663998, acc.: 65.62%] [G loss: 1.400479]\n",
      "epoch:27 step:25763 [D loss: 0.539981, acc.: 72.66%] [G loss: 1.258934]\n",
      "epoch:27 step:25764 [D loss: 0.489996, acc.: 75.00%] [G loss: 1.683634]\n",
      "epoch:27 step:25765 [D loss: 0.474895, acc.: 78.12%] [G loss: 1.382056]\n",
      "epoch:27 step:25766 [D loss: 0.389628, acc.: 87.50%] [G loss: 1.363047]\n",
      "epoch:27 step:25767 [D loss: 0.511951, acc.: 78.91%] [G loss: 1.465185]\n",
      "epoch:27 step:25768 [D loss: 0.505056, acc.: 73.44%] [G loss: 1.705523]\n",
      "epoch:27 step:25769 [D loss: 0.548941, acc.: 70.31%] [G loss: 1.386140]\n",
      "epoch:27 step:25770 [D loss: 0.637099, acc.: 64.84%] [G loss: 1.481126]\n",
      "epoch:27 step:25771 [D loss: 0.680838, acc.: 65.62%] [G loss: 1.247583]\n",
      "epoch:27 step:25772 [D loss: 0.597118, acc.: 67.97%] [G loss: 1.597386]\n",
      "epoch:27 step:25773 [D loss: 0.478778, acc.: 78.91%] [G loss: 1.806980]\n",
      "epoch:27 step:25774 [D loss: 0.440484, acc.: 82.03%] [G loss: 1.592341]\n",
      "epoch:27 step:25775 [D loss: 0.407138, acc.: 85.16%] [G loss: 1.149670]\n",
      "epoch:27 step:25776 [D loss: 0.450686, acc.: 84.38%] [G loss: 2.266290]\n",
      "epoch:27 step:25777 [D loss: 0.557003, acc.: 73.44%] [G loss: 1.796337]\n",
      "epoch:27 step:25778 [D loss: 0.427587, acc.: 84.38%] [G loss: 1.305576]\n",
      "epoch:27 step:25779 [D loss: 0.520109, acc.: 74.22%] [G loss: 1.255898]\n",
      "epoch:27 step:25780 [D loss: 0.756668, acc.: 56.25%] [G loss: 1.241262]\n",
      "epoch:27 step:25781 [D loss: 0.759465, acc.: 53.12%] [G loss: 1.135552]\n",
      "epoch:27 step:25782 [D loss: 0.585022, acc.: 68.75%] [G loss: 1.416502]\n",
      "epoch:27 step:25783 [D loss: 0.701607, acc.: 57.03%] [G loss: 1.140515]\n",
      "epoch:27 step:25784 [D loss: 0.511918, acc.: 71.09%] [G loss: 2.010985]\n",
      "epoch:27 step:25785 [D loss: 0.341456, acc.: 88.28%] [G loss: 1.675617]\n",
      "epoch:27 step:25786 [D loss: 0.581635, acc.: 67.97%] [G loss: 1.233820]\n",
      "epoch:27 step:25787 [D loss: 0.573381, acc.: 71.88%] [G loss: 1.391001]\n",
      "epoch:27 step:25788 [D loss: 0.578033, acc.: 64.84%] [G loss: 1.673699]\n",
      "epoch:27 step:25789 [D loss: 0.545938, acc.: 78.12%] [G loss: 1.162507]\n",
      "epoch:27 step:25790 [D loss: 0.383631, acc.: 86.72%] [G loss: 1.761800]\n",
      "epoch:27 step:25791 [D loss: 0.676894, acc.: 60.94%] [G loss: 1.422803]\n",
      "epoch:27 step:25792 [D loss: 0.491856, acc.: 75.00%] [G loss: 1.024392]\n",
      "epoch:27 step:25793 [D loss: 0.644563, acc.: 68.75%] [G loss: 1.255825]\n",
      "epoch:27 step:25794 [D loss: 0.498098, acc.: 77.34%] [G loss: 1.134316]\n",
      "epoch:27 step:25795 [D loss: 0.620712, acc.: 64.06%] [G loss: 1.434612]\n",
      "epoch:27 step:25796 [D loss: 0.517462, acc.: 73.44%] [G loss: 1.278031]\n",
      "epoch:27 step:25797 [D loss: 0.593193, acc.: 72.66%] [G loss: 1.379642]\n",
      "epoch:27 step:25798 [D loss: 0.352449, acc.: 89.84%] [G loss: 1.648392]\n",
      "epoch:27 step:25799 [D loss: 0.545690, acc.: 74.22%] [G loss: 1.230652]\n",
      "epoch:27 step:25800 [D loss: 0.448939, acc.: 78.91%] [G loss: 1.657751]\n",
      "epoch:27 step:25801 [D loss: 0.465960, acc.: 79.69%] [G loss: 1.196557]\n",
      "epoch:27 step:25802 [D loss: 0.502429, acc.: 78.91%] [G loss: 1.328579]\n",
      "epoch:27 step:25803 [D loss: 0.586767, acc.: 67.19%] [G loss: 1.269634]\n",
      "epoch:27 step:25804 [D loss: 0.564870, acc.: 67.97%] [G loss: 1.173797]\n",
      "epoch:27 step:25805 [D loss: 0.379457, acc.: 91.41%] [G loss: 1.625552]\n",
      "epoch:27 step:25806 [D loss: 0.684926, acc.: 60.16%] [G loss: 0.977018]\n",
      "epoch:27 step:25807 [D loss: 0.421426, acc.: 85.94%] [G loss: 1.763840]\n",
      "epoch:27 step:25808 [D loss: 0.589983, acc.: 67.97%] [G loss: 1.289994]\n",
      "epoch:27 step:25809 [D loss: 0.377506, acc.: 86.72%] [G loss: 1.565651]\n",
      "epoch:27 step:25810 [D loss: 0.369720, acc.: 89.06%] [G loss: 1.279359]\n",
      "epoch:27 step:25811 [D loss: 0.542452, acc.: 73.44%] [G loss: 1.599353]\n",
      "epoch:27 step:25812 [D loss: 0.495627, acc.: 78.12%] [G loss: 1.890605]\n",
      "epoch:27 step:25813 [D loss: 0.498695, acc.: 75.78%] [G loss: 1.517559]\n",
      "epoch:27 step:25814 [D loss: 0.477383, acc.: 80.47%] [G loss: 1.339953]\n",
      "epoch:27 step:25815 [D loss: 0.710914, acc.: 60.16%] [G loss: 0.850069]\n",
      "epoch:27 step:25816 [D loss: 0.424775, acc.: 78.91%] [G loss: 1.438306]\n",
      "epoch:27 step:25817 [D loss: 0.468859, acc.: 80.47%] [G loss: 1.701780]\n",
      "epoch:27 step:25818 [D loss: 0.408779, acc.: 83.59%] [G loss: 1.586084]\n",
      "epoch:27 step:25819 [D loss: 0.468394, acc.: 79.69%] [G loss: 1.586596]\n",
      "epoch:27 step:25820 [D loss: 0.515211, acc.: 78.91%] [G loss: 1.860819]\n",
      "epoch:27 step:25821 [D loss: 0.751513, acc.: 51.56%] [G loss: 1.367179]\n",
      "epoch:27 step:25822 [D loss: 0.410264, acc.: 82.81%] [G loss: 1.461674]\n",
      "epoch:27 step:25823 [D loss: 0.581833, acc.: 74.22%] [G loss: 1.507948]\n",
      "epoch:27 step:25824 [D loss: 0.423488, acc.: 82.81%] [G loss: 1.622489]\n",
      "epoch:27 step:25825 [D loss: 0.641863, acc.: 65.62%] [G loss: 1.357571]\n",
      "epoch:27 step:25826 [D loss: 0.383993, acc.: 89.84%] [G loss: 1.546888]\n",
      "epoch:27 step:25827 [D loss: 0.601360, acc.: 64.06%] [G loss: 1.624580]\n",
      "epoch:27 step:25828 [D loss: 0.462387, acc.: 77.34%] [G loss: 1.651847]\n",
      "epoch:27 step:25829 [D loss: 0.509547, acc.: 78.91%] [G loss: 1.351540]\n",
      "epoch:27 step:25830 [D loss: 0.554203, acc.: 74.22%] [G loss: 1.942039]\n",
      "epoch:27 step:25831 [D loss: 0.635684, acc.: 67.97%] [G loss: 1.242492]\n",
      "epoch:27 step:25832 [D loss: 0.583986, acc.: 67.97%] [G loss: 1.432455]\n",
      "epoch:27 step:25833 [D loss: 0.497743, acc.: 78.12%] [G loss: 1.741311]\n",
      "epoch:27 step:25834 [D loss: 0.562428, acc.: 67.97%] [G loss: 1.126085]\n",
      "epoch:27 step:25835 [D loss: 0.539858, acc.: 73.44%] [G loss: 1.120499]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:27 step:25836 [D loss: 0.396729, acc.: 87.50%] [G loss: 1.553804]\n",
      "epoch:27 step:25837 [D loss: 0.555205, acc.: 71.88%] [G loss: 1.508706]\n",
      "epoch:27 step:25838 [D loss: 0.521490, acc.: 75.00%] [G loss: 1.045831]\n",
      "epoch:27 step:25839 [D loss: 0.542297, acc.: 70.31%] [G loss: 1.172668]\n",
      "epoch:27 step:25840 [D loss: 0.477084, acc.: 78.91%] [G loss: 1.270471]\n",
      "epoch:27 step:25841 [D loss: 0.590080, acc.: 67.19%] [G loss: 1.469146]\n",
      "epoch:27 step:25842 [D loss: 0.571269, acc.: 65.62%] [G loss: 1.181281]\n",
      "epoch:27 step:25843 [D loss: 0.543782, acc.: 71.88%] [G loss: 1.291824]\n",
      "epoch:27 step:25844 [D loss: 0.615416, acc.: 64.06%] [G loss: 1.152147]\n",
      "epoch:27 step:25845 [D loss: 0.413959, acc.: 82.81%] [G loss: 1.472811]\n",
      "epoch:27 step:25846 [D loss: 0.801940, acc.: 49.22%] [G loss: 1.121822]\n",
      "epoch:27 step:25847 [D loss: 0.567742, acc.: 70.31%] [G loss: 1.376402]\n",
      "epoch:27 step:25848 [D loss: 0.553376, acc.: 72.66%] [G loss: 1.282272]\n",
      "epoch:27 step:25849 [D loss: 0.503395, acc.: 78.12%] [G loss: 1.545355]\n",
      "epoch:27 step:25850 [D loss: 0.374668, acc.: 84.38%] [G loss: 1.160241]\n",
      "epoch:27 step:25851 [D loss: 0.474811, acc.: 76.56%] [G loss: 1.444187]\n",
      "epoch:27 step:25852 [D loss: 0.506567, acc.: 76.56%] [G loss: 1.476909]\n",
      "epoch:27 step:25853 [D loss: 0.486726, acc.: 75.78%] [G loss: 1.602710]\n",
      "epoch:27 step:25854 [D loss: 0.328335, acc.: 91.41%] [G loss: 1.424417]\n",
      "epoch:27 step:25855 [D loss: 0.650882, acc.: 66.41%] [G loss: 1.431614]\n",
      "epoch:27 step:25856 [D loss: 0.575896, acc.: 64.06%] [G loss: 1.239405]\n",
      "epoch:27 step:25857 [D loss: 0.702705, acc.: 60.16%] [G loss: 1.377994]\n",
      "epoch:27 step:25858 [D loss: 0.508100, acc.: 77.34%] [G loss: 1.237979]\n",
      "epoch:27 step:25859 [D loss: 0.541967, acc.: 70.31%] [G loss: 1.030542]\n",
      "epoch:27 step:25860 [D loss: 0.565809, acc.: 71.09%] [G loss: 1.263518]\n",
      "epoch:27 step:25861 [D loss: 0.618819, acc.: 67.97%] [G loss: 1.429696]\n",
      "epoch:27 step:25862 [D loss: 0.520219, acc.: 75.00%] [G loss: 1.629492]\n",
      "epoch:27 step:25863 [D loss: 0.515424, acc.: 74.22%] [G loss: 1.107425]\n",
      "epoch:27 step:25864 [D loss: 0.460964, acc.: 81.25%] [G loss: 1.377676]\n",
      "epoch:27 step:25865 [D loss: 0.598658, acc.: 66.41%] [G loss: 1.189098]\n",
      "epoch:27 step:25866 [D loss: 0.393002, acc.: 85.94%] [G loss: 1.852312]\n",
      "epoch:27 step:25867 [D loss: 0.558567, acc.: 69.53%] [G loss: 1.476229]\n",
      "epoch:27 step:25868 [D loss: 0.460106, acc.: 83.59%] [G loss: 1.753036]\n",
      "epoch:27 step:25869 [D loss: 0.601405, acc.: 67.97%] [G loss: 1.462971]\n",
      "epoch:27 step:25870 [D loss: 0.694082, acc.: 60.16%] [G loss: 1.236264]\n",
      "epoch:27 step:25871 [D loss: 0.485404, acc.: 78.91%] [G loss: 2.123069]\n",
      "epoch:27 step:25872 [D loss: 0.466601, acc.: 80.47%] [G loss: 1.702781]\n",
      "epoch:27 step:25873 [D loss: 0.550151, acc.: 71.09%] [G loss: 1.280128]\n",
      "epoch:27 step:25874 [D loss: 0.519844, acc.: 74.22%] [G loss: 1.381226]\n",
      "epoch:27 step:25875 [D loss: 0.495934, acc.: 76.56%] [G loss: 1.721047]\n",
      "epoch:27 step:25876 [D loss: 0.521461, acc.: 71.09%] [G loss: 1.463880]\n",
      "epoch:27 step:25877 [D loss: 0.567924, acc.: 71.09%] [G loss: 1.451002]\n",
      "epoch:27 step:25878 [D loss: 0.435946, acc.: 82.81%] [G loss: 1.061105]\n",
      "epoch:27 step:25879 [D loss: 0.578092, acc.: 68.75%] [G loss: 1.252110]\n",
      "epoch:27 step:25880 [D loss: 0.421772, acc.: 81.25%] [G loss: 1.475308]\n",
      "epoch:27 step:25881 [D loss: 0.482005, acc.: 81.25%] [G loss: 1.616052]\n",
      "epoch:27 step:25882 [D loss: 0.478006, acc.: 78.12%] [G loss: 1.557710]\n",
      "epoch:27 step:25883 [D loss: 0.533325, acc.: 75.00%] [G loss: 1.132694]\n",
      "epoch:27 step:25884 [D loss: 0.684618, acc.: 61.72%] [G loss: 1.298767]\n",
      "epoch:27 step:25885 [D loss: 0.536880, acc.: 73.44%] [G loss: 1.214834]\n",
      "epoch:27 step:25886 [D loss: 0.458961, acc.: 78.12%] [G loss: 1.381436]\n",
      "epoch:27 step:25887 [D loss: 0.452197, acc.: 78.91%] [G loss: 1.574541]\n",
      "epoch:27 step:25888 [D loss: 0.638573, acc.: 60.16%] [G loss: 1.028355]\n",
      "epoch:27 step:25889 [D loss: 0.516409, acc.: 78.12%] [G loss: 1.250034]\n",
      "epoch:27 step:25890 [D loss: 0.440594, acc.: 77.34%] [G loss: 1.342300]\n",
      "epoch:27 step:25891 [D loss: 0.699141, acc.: 60.94%] [G loss: 1.468745]\n",
      "epoch:27 step:25892 [D loss: 0.530100, acc.: 76.56%] [G loss: 1.503318]\n",
      "epoch:27 step:25893 [D loss: 0.441851, acc.: 79.69%] [G loss: 1.525975]\n",
      "epoch:27 step:25894 [D loss: 0.621913, acc.: 68.75%] [G loss: 1.269007]\n",
      "epoch:27 step:25895 [D loss: 0.683048, acc.: 60.16%] [G loss: 1.692258]\n",
      "epoch:27 step:25896 [D loss: 0.799709, acc.: 57.81%] [G loss: 1.817755]\n",
      "epoch:27 step:25897 [D loss: 0.542598, acc.: 75.78%] [G loss: 1.276052]\n",
      "epoch:27 step:25898 [D loss: 0.602059, acc.: 65.62%] [G loss: 1.132941]\n",
      "epoch:27 step:25899 [D loss: 0.319907, acc.: 88.28%] [G loss: 1.665695]\n",
      "epoch:27 step:25900 [D loss: 0.623399, acc.: 65.62%] [G loss: 1.433563]\n",
      "epoch:27 step:25901 [D loss: 0.452553, acc.: 81.25%] [G loss: 1.086424]\n",
      "epoch:27 step:25902 [D loss: 0.620240, acc.: 69.53%] [G loss: 1.404762]\n",
      "epoch:27 step:25903 [D loss: 0.503583, acc.: 76.56%] [G loss: 1.076707]\n",
      "epoch:27 step:25904 [D loss: 0.551855, acc.: 71.09%] [G loss: 1.213855]\n",
      "epoch:27 step:25905 [D loss: 0.453924, acc.: 84.38%] [G loss: 1.941009]\n",
      "epoch:27 step:25906 [D loss: 0.583600, acc.: 70.31%] [G loss: 1.318638]\n",
      "epoch:27 step:25907 [D loss: 0.485545, acc.: 77.34%] [G loss: 1.567074]\n",
      "epoch:27 step:25908 [D loss: 0.538424, acc.: 74.22%] [G loss: 1.242662]\n",
      "epoch:27 step:25909 [D loss: 0.425903, acc.: 83.59%] [G loss: 1.481864]\n",
      "epoch:27 step:25910 [D loss: 0.454885, acc.: 83.59%] [G loss: 1.266305]\n",
      "epoch:27 step:25911 [D loss: 0.542676, acc.: 72.66%] [G loss: 1.278570]\n",
      "epoch:27 step:25912 [D loss: 0.526887, acc.: 74.22%] [G loss: 1.475635]\n",
      "epoch:27 step:25913 [D loss: 0.610944, acc.: 68.75%] [G loss: 1.116962]\n",
      "epoch:27 step:25914 [D loss: 0.644529, acc.: 64.84%] [G loss: 1.287933]\n",
      "epoch:27 step:25915 [D loss: 0.600098, acc.: 67.19%] [G loss: 1.412951]\n",
      "epoch:27 step:25916 [D loss: 0.361981, acc.: 88.28%] [G loss: 1.737682]\n",
      "epoch:27 step:25917 [D loss: 0.470445, acc.: 74.22%] [G loss: 1.419471]\n",
      "epoch:27 step:25918 [D loss: 0.398826, acc.: 86.72%] [G loss: 1.665515]\n",
      "epoch:27 step:25919 [D loss: 0.638415, acc.: 63.28%] [G loss: 1.456586]\n",
      "epoch:27 step:25920 [D loss: 0.452693, acc.: 80.47%] [G loss: 1.387212]\n",
      "epoch:27 step:25921 [D loss: 0.554046, acc.: 72.66%] [G loss: 1.066797]\n",
      "epoch:27 step:25922 [D loss: 0.605812, acc.: 69.53%] [G loss: 1.043988]\n",
      "epoch:27 step:25923 [D loss: 0.553675, acc.: 75.00%] [G loss: 1.488893]\n",
      "epoch:27 step:25924 [D loss: 0.535887, acc.: 77.34%] [G loss: 1.283229]\n",
      "epoch:27 step:25925 [D loss: 0.405669, acc.: 83.59%] [G loss: 1.743460]\n",
      "epoch:27 step:25926 [D loss: 0.380366, acc.: 87.50%] [G loss: 1.597435]\n",
      "epoch:27 step:25927 [D loss: 0.606799, acc.: 68.75%] [G loss: 1.369154]\n",
      "epoch:27 step:25928 [D loss: 0.589644, acc.: 62.50%] [G loss: 1.767068]\n",
      "epoch:27 step:25929 [D loss: 0.579652, acc.: 70.31%] [G loss: 1.903113]\n",
      "epoch:27 step:25930 [D loss: 0.526781, acc.: 71.09%] [G loss: 1.097744]\n",
      "epoch:27 step:25931 [D loss: 0.620076, acc.: 67.97%] [G loss: 1.343190]\n",
      "epoch:27 step:25932 [D loss: 0.460437, acc.: 78.91%] [G loss: 1.392171]\n",
      "epoch:27 step:25933 [D loss: 0.621837, acc.: 57.03%] [G loss: 0.904645]\n",
      "epoch:27 step:25934 [D loss: 0.600059, acc.: 69.53%] [G loss: 1.539134]\n",
      "epoch:27 step:25935 [D loss: 0.658469, acc.: 64.84%] [G loss: 1.417741]\n",
      "epoch:27 step:25936 [D loss: 0.576696, acc.: 66.41%] [G loss: 1.451233]\n",
      "epoch:27 step:25937 [D loss: 0.502724, acc.: 76.56%] [G loss: 1.248793]\n",
      "epoch:27 step:25938 [D loss: 0.586288, acc.: 67.97%] [G loss: 1.620088]\n",
      "epoch:27 step:25939 [D loss: 0.576677, acc.: 72.66%] [G loss: 1.086666]\n",
      "epoch:27 step:25940 [D loss: 0.542787, acc.: 71.88%] [G loss: 1.145589]\n",
      "epoch:27 step:25941 [D loss: 0.471201, acc.: 81.25%] [G loss: 1.966874]\n",
      "epoch:27 step:25942 [D loss: 0.798944, acc.: 52.34%] [G loss: 1.064404]\n",
      "epoch:27 step:25943 [D loss: 0.434692, acc.: 78.91%] [G loss: 1.468166]\n",
      "epoch:27 step:25944 [D loss: 0.551365, acc.: 71.09%] [G loss: 1.221363]\n",
      "epoch:27 step:25945 [D loss: 0.443124, acc.: 81.25%] [G loss: 1.595773]\n",
      "epoch:27 step:25946 [D loss: 0.761817, acc.: 53.91%] [G loss: 1.157783]\n",
      "epoch:27 step:25947 [D loss: 0.416741, acc.: 83.59%] [G loss: 1.045283]\n",
      "epoch:27 step:25948 [D loss: 0.557084, acc.: 70.31%] [G loss: 1.456401]\n",
      "epoch:27 step:25949 [D loss: 0.574581, acc.: 75.78%] [G loss: 1.773321]\n",
      "epoch:27 step:25950 [D loss: 0.386824, acc.: 83.59%] [G loss: 1.346948]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:27 step:25951 [D loss: 0.516409, acc.: 74.22%] [G loss: 1.727895]\n",
      "epoch:27 step:25952 [D loss: 0.603822, acc.: 64.84%] [G loss: 1.177589]\n",
      "epoch:27 step:25953 [D loss: 0.580878, acc.: 68.75%] [G loss: 1.389321]\n",
      "epoch:27 step:25954 [D loss: 0.549158, acc.: 75.00%] [G loss: 1.297155]\n",
      "epoch:27 step:25955 [D loss: 0.496211, acc.: 79.69%] [G loss: 1.561503]\n",
      "epoch:27 step:25956 [D loss: 0.534837, acc.: 71.09%] [G loss: 1.767044]\n",
      "epoch:27 step:25957 [D loss: 0.637321, acc.: 64.84%] [G loss: 1.437938]\n",
      "epoch:27 step:25958 [D loss: 0.550500, acc.: 71.88%] [G loss: 1.398519]\n",
      "epoch:27 step:25959 [D loss: 0.473179, acc.: 75.78%] [G loss: 0.913547]\n",
      "epoch:27 step:25960 [D loss: 0.714966, acc.: 57.81%] [G loss: 1.341945]\n",
      "epoch:27 step:25961 [D loss: 0.647179, acc.: 59.38%] [G loss: 1.591252]\n",
      "epoch:27 step:25962 [D loss: 0.505749, acc.: 77.34%] [G loss: 1.206957]\n",
      "epoch:27 step:25963 [D loss: 0.585569, acc.: 72.66%] [G loss: 1.387513]\n",
      "epoch:27 step:25964 [D loss: 0.629466, acc.: 67.97%] [G loss: 1.160749]\n",
      "epoch:27 step:25965 [D loss: 0.516396, acc.: 75.78%] [G loss: 1.534750]\n",
      "epoch:27 step:25966 [D loss: 0.406634, acc.: 82.03%] [G loss: 1.778248]\n",
      "epoch:27 step:25967 [D loss: 0.639161, acc.: 67.19%] [G loss: 1.522945]\n",
      "epoch:27 step:25968 [D loss: 0.515240, acc.: 77.34%] [G loss: 1.637068]\n",
      "epoch:27 step:25969 [D loss: 0.682701, acc.: 60.94%] [G loss: 1.381072]\n",
      "epoch:27 step:25970 [D loss: 0.449832, acc.: 78.12%] [G loss: 1.748506]\n",
      "epoch:27 step:25971 [D loss: 0.538024, acc.: 68.75%] [G loss: 1.471271]\n",
      "epoch:27 step:25972 [D loss: 0.552877, acc.: 73.44%] [G loss: 1.869706]\n",
      "epoch:27 step:25973 [D loss: 0.545972, acc.: 76.56%] [G loss: 1.540195]\n",
      "epoch:27 step:25974 [D loss: 0.686417, acc.: 60.16%] [G loss: 0.948982]\n",
      "epoch:27 step:25975 [D loss: 0.467032, acc.: 78.91%] [G loss: 1.177397]\n",
      "epoch:27 step:25976 [D loss: 0.332759, acc.: 85.94%] [G loss: 1.979941]\n",
      "epoch:27 step:25977 [D loss: 0.477131, acc.: 79.69%] [G loss: 1.033477]\n",
      "epoch:27 step:25978 [D loss: 0.533073, acc.: 76.56%] [G loss: 1.306217]\n",
      "epoch:27 step:25979 [D loss: 0.563920, acc.: 68.75%] [G loss: 1.456924]\n",
      "epoch:27 step:25980 [D loss: 0.727484, acc.: 55.47%] [G loss: 1.013613]\n",
      "epoch:27 step:25981 [D loss: 0.511216, acc.: 78.12%] [G loss: 1.279664]\n",
      "epoch:27 step:25982 [D loss: 0.537165, acc.: 71.88%] [G loss: 1.385707]\n",
      "epoch:27 step:25983 [D loss: 0.574864, acc.: 71.09%] [G loss: 1.519202]\n",
      "epoch:27 step:25984 [D loss: 0.516533, acc.: 79.69%] [G loss: 1.048764]\n",
      "epoch:27 step:25985 [D loss: 0.458086, acc.: 78.12%] [G loss: 1.213684]\n",
      "epoch:27 step:25986 [D loss: 0.557471, acc.: 72.66%] [G loss: 1.273820]\n",
      "epoch:27 step:25987 [D loss: 0.506040, acc.: 75.78%] [G loss: 1.462404]\n",
      "epoch:27 step:25988 [D loss: 0.596070, acc.: 62.50%] [G loss: 1.089164]\n",
      "epoch:27 step:25989 [D loss: 0.589139, acc.: 67.97%] [G loss: 1.340985]\n",
      "epoch:27 step:25990 [D loss: 0.518224, acc.: 71.09%] [G loss: 1.288049]\n",
      "epoch:27 step:25991 [D loss: 0.584644, acc.: 70.31%] [G loss: 1.477562]\n",
      "epoch:27 step:25992 [D loss: 0.742608, acc.: 59.38%] [G loss: 1.183583]\n",
      "epoch:27 step:25993 [D loss: 0.651577, acc.: 68.75%] [G loss: 1.627531]\n",
      "epoch:27 step:25994 [D loss: 0.407579, acc.: 81.25%] [G loss: 1.738700]\n",
      "epoch:27 step:25995 [D loss: 0.596024, acc.: 71.88%] [G loss: 1.389837]\n",
      "epoch:27 step:25996 [D loss: 0.456938, acc.: 82.81%] [G loss: 1.222119]\n",
      "epoch:27 step:25997 [D loss: 0.618960, acc.: 69.53%] [G loss: 1.554662]\n",
      "epoch:27 step:25998 [D loss: 0.580826, acc.: 68.75%] [G loss: 1.310801]\n",
      "epoch:27 step:25999 [D loss: 0.635876, acc.: 60.94%] [G loss: 1.377394]\n",
      "epoch:27 step:26000 [D loss: 0.497808, acc.: 76.56%] [G loss: 1.577388]\n",
      "epoch:27 step:26001 [D loss: 0.427500, acc.: 82.03%] [G loss: 1.916182]\n",
      "epoch:27 step:26002 [D loss: 0.595016, acc.: 67.97%] [G loss: 1.116359]\n",
      "epoch:27 step:26003 [D loss: 0.655492, acc.: 60.16%] [G loss: 1.713306]\n",
      "epoch:27 step:26004 [D loss: 0.346437, acc.: 89.84%] [G loss: 1.392034]\n",
      "epoch:27 step:26005 [D loss: 0.522876, acc.: 75.78%] [G loss: 1.411449]\n",
      "epoch:27 step:26006 [D loss: 0.540381, acc.: 72.66%] [G loss: 1.156966]\n",
      "epoch:27 step:26007 [D loss: 0.372726, acc.: 88.28%] [G loss: 1.418214]\n",
      "epoch:27 step:26008 [D loss: 0.711104, acc.: 61.72%] [G loss: 1.766191]\n",
      "epoch:27 step:26009 [D loss: 0.488553, acc.: 80.47%] [G loss: 1.707224]\n",
      "epoch:27 step:26010 [D loss: 0.473961, acc.: 78.12%] [G loss: 1.375504]\n",
      "epoch:27 step:26011 [D loss: 0.551687, acc.: 66.41%] [G loss: 1.070064]\n",
      "epoch:27 step:26012 [D loss: 0.746293, acc.: 54.69%] [G loss: 1.102175]\n",
      "epoch:27 step:26013 [D loss: 0.618758, acc.: 66.41%] [G loss: 1.480334]\n",
      "epoch:27 step:26014 [D loss: 0.498854, acc.: 73.44%] [G loss: 1.764708]\n",
      "epoch:27 step:26015 [D loss: 0.602875, acc.: 67.97%] [G loss: 1.526402]\n",
      "epoch:27 step:26016 [D loss: 0.407716, acc.: 82.81%] [G loss: 1.425974]\n",
      "epoch:27 step:26017 [D loss: 0.396518, acc.: 81.25%] [G loss: 1.346174]\n",
      "epoch:27 step:26018 [D loss: 0.671422, acc.: 60.94%] [G loss: 1.384310]\n",
      "epoch:27 step:26019 [D loss: 0.477459, acc.: 77.34%] [G loss: 1.743156]\n",
      "epoch:27 step:26020 [D loss: 0.599249, acc.: 65.62%] [G loss: 1.866203]\n",
      "epoch:27 step:26021 [D loss: 0.582471, acc.: 68.75%] [G loss: 1.572620]\n",
      "epoch:27 step:26022 [D loss: 0.604612, acc.: 65.62%] [G loss: 1.445467]\n",
      "epoch:27 step:26023 [D loss: 0.491752, acc.: 75.00%] [G loss: 1.155928]\n",
      "epoch:27 step:26024 [D loss: 0.557088, acc.: 71.09%] [G loss: 1.123436]\n",
      "epoch:27 step:26025 [D loss: 0.482060, acc.: 81.25%] [G loss: 1.561814]\n",
      "epoch:27 step:26026 [D loss: 0.346699, acc.: 88.28%] [G loss: 1.597609]\n",
      "epoch:27 step:26027 [D loss: 0.583216, acc.: 71.88%] [G loss: 1.008390]\n",
      "epoch:27 step:26028 [D loss: 0.543681, acc.: 71.88%] [G loss: 1.525091]\n",
      "epoch:27 step:26029 [D loss: 0.503321, acc.: 75.78%] [G loss: 1.434927]\n",
      "epoch:27 step:26030 [D loss: 0.389802, acc.: 85.16%] [G loss: 1.714815]\n",
      "epoch:27 step:26031 [D loss: 0.595252, acc.: 68.75%] [G loss: 1.218210]\n",
      "epoch:27 step:26032 [D loss: 0.488458, acc.: 77.34%] [G loss: 1.738592]\n",
      "epoch:27 step:26033 [D loss: 0.686754, acc.: 62.50%] [G loss: 1.146271]\n",
      "epoch:27 step:26034 [D loss: 0.412190, acc.: 85.16%] [G loss: 1.928421]\n",
      "epoch:27 step:26035 [D loss: 0.476797, acc.: 80.47%] [G loss: 1.627327]\n",
      "epoch:27 step:26036 [D loss: 0.574615, acc.: 69.53%] [G loss: 2.004704]\n",
      "epoch:27 step:26037 [D loss: 0.685300, acc.: 59.38%] [G loss: 1.301579]\n",
      "epoch:27 step:26038 [D loss: 0.485709, acc.: 77.34%] [G loss: 1.251581]\n",
      "epoch:27 step:26039 [D loss: 0.525187, acc.: 75.00%] [G loss: 1.333518]\n",
      "epoch:27 step:26040 [D loss: 0.429871, acc.: 78.91%] [G loss: 1.610357]\n",
      "epoch:27 step:26041 [D loss: 0.473482, acc.: 75.78%] [G loss: 1.518960]\n",
      "epoch:27 step:26042 [D loss: 0.722297, acc.: 58.59%] [G loss: 0.934268]\n",
      "epoch:27 step:26043 [D loss: 0.521419, acc.: 69.53%] [G loss: 1.208383]\n",
      "epoch:27 step:26044 [D loss: 0.544276, acc.: 69.53%] [G loss: 1.280130]\n",
      "epoch:27 step:26045 [D loss: 0.552841, acc.: 71.88%] [G loss: 1.473147]\n",
      "epoch:27 step:26046 [D loss: 0.449318, acc.: 81.25%] [G loss: 1.663214]\n",
      "epoch:27 step:26047 [D loss: 0.534505, acc.: 74.22%] [G loss: 1.656422]\n",
      "epoch:27 step:26048 [D loss: 0.755285, acc.: 53.12%] [G loss: 1.303886]\n",
      "epoch:27 step:26049 [D loss: 0.638888, acc.: 64.84%] [G loss: 1.399922]\n",
      "epoch:27 step:26050 [D loss: 0.552701, acc.: 75.78%] [G loss: 1.246077]\n",
      "epoch:27 step:26051 [D loss: 0.540130, acc.: 71.09%] [G loss: 1.358875]\n",
      "epoch:27 step:26052 [D loss: 0.501826, acc.: 80.47%] [G loss: 1.302327]\n",
      "epoch:27 step:26053 [D loss: 0.482835, acc.: 75.00%] [G loss: 1.549616]\n",
      "epoch:27 step:26054 [D loss: 0.495602, acc.: 75.78%] [G loss: 1.343645]\n",
      "epoch:27 step:26055 [D loss: 0.481893, acc.: 77.34%] [G loss: 1.524021]\n",
      "epoch:27 step:26056 [D loss: 0.440386, acc.: 81.25%] [G loss: 1.776145]\n",
      "epoch:27 step:26057 [D loss: 0.504231, acc.: 72.66%] [G loss: 1.345851]\n",
      "epoch:27 step:26058 [D loss: 0.407734, acc.: 81.25%] [G loss: 1.345370]\n",
      "epoch:27 step:26059 [D loss: 0.589722, acc.: 64.84%] [G loss: 1.545727]\n",
      "epoch:27 step:26060 [D loss: 0.621075, acc.: 66.41%] [G loss: 1.294658]\n",
      "epoch:27 step:26061 [D loss: 0.741815, acc.: 60.16%] [G loss: 0.948063]\n",
      "epoch:27 step:26062 [D loss: 0.630680, acc.: 65.62%] [G loss: 1.828809]\n",
      "epoch:27 step:26063 [D loss: 0.506404, acc.: 78.12%] [G loss: 1.310252]\n",
      "epoch:27 step:26064 [D loss: 0.529338, acc.: 75.00%] [G loss: 0.996447]\n",
      "epoch:27 step:26065 [D loss: 0.383013, acc.: 85.16%] [G loss: 1.283945]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:27 step:26066 [D loss: 0.671919, acc.: 63.28%] [G loss: 1.111195]\n",
      "epoch:27 step:26067 [D loss: 0.571335, acc.: 73.44%] [G loss: 1.606294]\n",
      "epoch:27 step:26068 [D loss: 0.609816, acc.: 66.41%] [G loss: 1.886315]\n",
      "epoch:27 step:26069 [D loss: 0.643630, acc.: 66.41%] [G loss: 1.327913]\n",
      "epoch:27 step:26070 [D loss: 0.443933, acc.: 83.59%] [G loss: 1.449143]\n",
      "epoch:27 step:26071 [D loss: 0.495796, acc.: 71.88%] [G loss: 1.172413]\n",
      "epoch:27 step:26072 [D loss: 0.658840, acc.: 61.72%] [G loss: 1.197462]\n",
      "epoch:27 step:26073 [D loss: 0.456083, acc.: 79.69%] [G loss: 1.686519]\n",
      "epoch:27 step:26074 [D loss: 0.588399, acc.: 71.09%] [G loss: 1.227098]\n",
      "epoch:27 step:26075 [D loss: 0.544108, acc.: 69.53%] [G loss: 1.346097]\n",
      "epoch:27 step:26076 [D loss: 0.614697, acc.: 64.84%] [G loss: 1.098537]\n",
      "epoch:27 step:26077 [D loss: 0.537289, acc.: 71.09%] [G loss: 1.728710]\n",
      "epoch:27 step:26078 [D loss: 0.482554, acc.: 76.56%] [G loss: 1.682358]\n",
      "epoch:27 step:26079 [D loss: 0.510478, acc.: 77.34%] [G loss: 1.497524]\n",
      "epoch:27 step:26080 [D loss: 0.748614, acc.: 53.12%] [G loss: 1.274953]\n",
      "epoch:27 step:26081 [D loss: 0.566647, acc.: 67.19%] [G loss: 1.148294]\n",
      "epoch:27 step:26082 [D loss: 0.617502, acc.: 62.50%] [G loss: 1.244754]\n",
      "epoch:27 step:26083 [D loss: 0.626830, acc.: 64.84%] [G loss: 1.061505]\n",
      "epoch:27 step:26084 [D loss: 0.383353, acc.: 83.59%] [G loss: 1.818084]\n",
      "epoch:27 step:26085 [D loss: 0.547306, acc.: 73.44%] [G loss: 1.142309]\n",
      "epoch:27 step:26086 [D loss: 0.679810, acc.: 63.28%] [G loss: 1.996243]\n",
      "epoch:27 step:26087 [D loss: 0.816830, acc.: 50.00%] [G loss: 1.401906]\n",
      "epoch:27 step:26088 [D loss: 0.576012, acc.: 65.62%] [G loss: 1.069760]\n",
      "epoch:27 step:26089 [D loss: 0.399853, acc.: 82.81%] [G loss: 1.718175]\n",
      "epoch:27 step:26090 [D loss: 0.513692, acc.: 73.44%] [G loss: 1.631528]\n",
      "epoch:27 step:26091 [D loss: 0.612224, acc.: 67.19%] [G loss: 1.309853]\n",
      "epoch:27 step:26092 [D loss: 0.511626, acc.: 73.44%] [G loss: 1.417342]\n",
      "epoch:27 step:26093 [D loss: 0.626670, acc.: 63.28%] [G loss: 1.515172]\n",
      "epoch:27 step:26094 [D loss: 0.578005, acc.: 67.97%] [G loss: 1.580850]\n",
      "epoch:27 step:26095 [D loss: 0.467599, acc.: 75.78%] [G loss: 1.713079]\n",
      "epoch:27 step:26096 [D loss: 0.525983, acc.: 74.22%] [G loss: 1.316238]\n",
      "epoch:27 step:26097 [D loss: 0.603605, acc.: 62.50%] [G loss: 1.533917]\n",
      "epoch:27 step:26098 [D loss: 0.682863, acc.: 60.94%] [G loss: 1.747456]\n",
      "epoch:27 step:26099 [D loss: 0.607138, acc.: 69.53%] [G loss: 1.562795]\n",
      "epoch:27 step:26100 [D loss: 0.594357, acc.: 67.97%] [G loss: 1.506067]\n",
      "epoch:27 step:26101 [D loss: 0.614382, acc.: 67.19%] [G loss: 1.388539]\n",
      "epoch:27 step:26102 [D loss: 0.562309, acc.: 68.75%] [G loss: 1.664091]\n",
      "epoch:27 step:26103 [D loss: 0.608811, acc.: 67.97%] [G loss: 1.407358]\n",
      "epoch:27 step:26104 [D loss: 0.442239, acc.: 81.25%] [G loss: 1.494571]\n",
      "epoch:27 step:26105 [D loss: 0.473464, acc.: 75.78%] [G loss: 1.813980]\n",
      "epoch:27 step:26106 [D loss: 0.740762, acc.: 56.25%] [G loss: 1.383101]\n",
      "epoch:27 step:26107 [D loss: 0.622574, acc.: 69.53%] [G loss: 1.270917]\n",
      "epoch:27 step:26108 [D loss: 0.392696, acc.: 85.94%] [G loss: 1.571786]\n",
      "epoch:27 step:26109 [D loss: 0.433043, acc.: 80.47%] [G loss: 1.095041]\n",
      "epoch:27 step:26110 [D loss: 0.520444, acc.: 74.22%] [G loss: 1.467660]\n",
      "epoch:27 step:26111 [D loss: 0.531330, acc.: 74.22%] [G loss: 1.529558]\n",
      "epoch:27 step:26112 [D loss: 0.406734, acc.: 85.16%] [G loss: 1.442271]\n",
      "epoch:27 step:26113 [D loss: 0.837217, acc.: 52.34%] [G loss: 1.401372]\n",
      "epoch:27 step:26114 [D loss: 0.610863, acc.: 65.62%] [G loss: 1.591145]\n",
      "epoch:27 step:26115 [D loss: 0.371792, acc.: 84.38%] [G loss: 1.913214]\n",
      "epoch:27 step:26116 [D loss: 0.507469, acc.: 76.56%] [G loss: 1.383133]\n",
      "epoch:27 step:26117 [D loss: 0.471259, acc.: 82.81%] [G loss: 1.412924]\n",
      "epoch:27 step:26118 [D loss: 0.510067, acc.: 73.44%] [G loss: 1.290592]\n",
      "epoch:27 step:26119 [D loss: 0.480154, acc.: 77.34%] [G loss: 0.887136]\n",
      "epoch:27 step:26120 [D loss: 0.624294, acc.: 64.06%] [G loss: 1.031601]\n",
      "epoch:27 step:26121 [D loss: 0.581161, acc.: 65.62%] [G loss: 1.191491]\n",
      "epoch:27 step:26122 [D loss: 0.827919, acc.: 42.97%] [G loss: 1.097643]\n",
      "epoch:27 step:26123 [D loss: 0.540108, acc.: 74.22%] [G loss: 1.230721]\n",
      "epoch:27 step:26124 [D loss: 0.558865, acc.: 70.31%] [G loss: 1.717509]\n",
      "epoch:27 step:26125 [D loss: 0.476609, acc.: 78.91%] [G loss: 1.246506]\n",
      "epoch:27 step:26126 [D loss: 0.475100, acc.: 77.34%] [G loss: 1.787928]\n",
      "epoch:27 step:26127 [D loss: 0.644124, acc.: 61.72%] [G loss: 1.503546]\n",
      "epoch:27 step:26128 [D loss: 0.595031, acc.: 70.31%] [G loss: 1.262278]\n",
      "epoch:27 step:26129 [D loss: 0.376364, acc.: 88.28%] [G loss: 1.266246]\n",
      "epoch:27 step:26130 [D loss: 0.672018, acc.: 62.50%] [G loss: 1.237535]\n",
      "epoch:27 step:26131 [D loss: 0.410542, acc.: 82.81%] [G loss: 1.341379]\n",
      "epoch:27 step:26132 [D loss: 0.575084, acc.: 66.41%] [G loss: 1.430468]\n",
      "epoch:27 step:26133 [D loss: 0.563605, acc.: 72.66%] [G loss: 1.252470]\n",
      "epoch:27 step:26134 [D loss: 0.639218, acc.: 65.62%] [G loss: 1.574073]\n",
      "epoch:27 step:26135 [D loss: 0.628669, acc.: 67.97%] [G loss: 1.676660]\n",
      "epoch:27 step:26136 [D loss: 0.781652, acc.: 47.66%] [G loss: 1.273338]\n",
      "epoch:27 step:26137 [D loss: 0.418135, acc.: 82.81%] [G loss: 1.359762]\n",
      "epoch:27 step:26138 [D loss: 0.717755, acc.: 58.59%] [G loss: 1.283476]\n",
      "epoch:27 step:26139 [D loss: 0.570402, acc.: 67.97%] [G loss: 1.258647]\n",
      "epoch:27 step:26140 [D loss: 0.506098, acc.: 77.34%] [G loss: 1.799338]\n",
      "epoch:27 step:26141 [D loss: 0.490951, acc.: 79.69%] [G loss: 1.383954]\n",
      "epoch:27 step:26142 [D loss: 0.469973, acc.: 75.78%] [G loss: 1.462798]\n",
      "epoch:27 step:26143 [D loss: 0.502860, acc.: 74.22%] [G loss: 1.595537]\n",
      "epoch:27 step:26144 [D loss: 0.606175, acc.: 70.31%] [G loss: 1.652954]\n",
      "epoch:27 step:26145 [D loss: 0.875611, acc.: 44.53%] [G loss: 1.379923]\n",
      "epoch:27 step:26146 [D loss: 0.693716, acc.: 61.72%] [G loss: 1.164946]\n",
      "epoch:27 step:26147 [D loss: 0.598892, acc.: 63.28%] [G loss: 1.032220]\n",
      "epoch:27 step:26148 [D loss: 0.605144, acc.: 65.62%] [G loss: 1.036731]\n",
      "epoch:27 step:26149 [D loss: 0.348590, acc.: 90.62%] [G loss: 1.548046]\n",
      "epoch:27 step:26150 [D loss: 0.742765, acc.: 56.25%] [G loss: 1.409768]\n",
      "epoch:27 step:26151 [D loss: 0.440392, acc.: 80.47%] [G loss: 1.794348]\n",
      "epoch:27 step:26152 [D loss: 0.499962, acc.: 76.56%] [G loss: 1.522940]\n",
      "epoch:27 step:26153 [D loss: 0.684515, acc.: 62.50%] [G loss: 1.540325]\n",
      "epoch:27 step:26154 [D loss: 0.587345, acc.: 63.28%] [G loss: 1.369666]\n",
      "epoch:27 step:26155 [D loss: 0.360552, acc.: 85.94%] [G loss: 1.323925]\n",
      "epoch:27 step:26156 [D loss: 0.487572, acc.: 74.22%] [G loss: 1.396678]\n",
      "epoch:27 step:26157 [D loss: 0.467512, acc.: 75.78%] [G loss: 1.263278]\n",
      "epoch:27 step:26158 [D loss: 0.483643, acc.: 78.91%] [G loss: 1.023018]\n",
      "epoch:27 step:26159 [D loss: 0.686220, acc.: 64.84%] [G loss: 1.509945]\n",
      "epoch:27 step:26160 [D loss: 0.371135, acc.: 88.28%] [G loss: 1.693741]\n",
      "epoch:27 step:26161 [D loss: 0.534553, acc.: 74.22%] [G loss: 1.486157]\n",
      "epoch:27 step:26162 [D loss: 0.396147, acc.: 84.38%] [G loss: 1.694173]\n",
      "epoch:27 step:26163 [D loss: 0.590179, acc.: 70.31%] [G loss: 1.613639]\n",
      "epoch:27 step:26164 [D loss: 0.490294, acc.: 75.78%] [G loss: 1.366374]\n",
      "epoch:27 step:26165 [D loss: 0.489825, acc.: 77.34%] [G loss: 1.220554]\n",
      "epoch:27 step:26166 [D loss: 0.724362, acc.: 55.47%] [G loss: 1.548267]\n",
      "epoch:27 step:26167 [D loss: 0.506833, acc.: 75.00%] [G loss: 1.575726]\n",
      "epoch:27 step:26168 [D loss: 0.524100, acc.: 71.88%] [G loss: 1.782934]\n",
      "epoch:27 step:26169 [D loss: 0.374021, acc.: 89.84%] [G loss: 1.983822]\n",
      "epoch:27 step:26170 [D loss: 0.473971, acc.: 75.00%] [G loss: 1.385184]\n",
      "epoch:27 step:26171 [D loss: 0.659019, acc.: 62.50%] [G loss: 0.975986]\n",
      "epoch:27 step:26172 [D loss: 0.468941, acc.: 83.59%] [G loss: 1.588847]\n",
      "epoch:27 step:26173 [D loss: 0.433385, acc.: 77.34%] [G loss: 1.433118]\n",
      "epoch:27 step:26174 [D loss: 0.489577, acc.: 75.78%] [G loss: 1.486035]\n",
      "epoch:27 step:26175 [D loss: 0.587978, acc.: 68.75%] [G loss: 1.652624]\n",
      "epoch:27 step:26176 [D loss: 0.670527, acc.: 60.94%] [G loss: 1.513613]\n",
      "epoch:27 step:26177 [D loss: 0.497949, acc.: 75.78%] [G loss: 1.793714]\n",
      "epoch:27 step:26178 [D loss: 0.495750, acc.: 77.34%] [G loss: 1.129712]\n",
      "epoch:27 step:26179 [D loss: 0.529643, acc.: 72.66%] [G loss: 1.378470]\n",
      "epoch:27 step:26180 [D loss: 0.409150, acc.: 82.81%] [G loss: 1.885498]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:27 step:26181 [D loss: 0.442621, acc.: 82.03%] [G loss: 1.282695]\n",
      "epoch:27 step:26182 [D loss: 0.635986, acc.: 62.50%] [G loss: 1.460901]\n",
      "epoch:27 step:26183 [D loss: 0.591248, acc.: 66.41%] [G loss: 1.856381]\n",
      "epoch:27 step:26184 [D loss: 0.516255, acc.: 72.66%] [G loss: 1.349927]\n",
      "epoch:27 step:26185 [D loss: 0.522095, acc.: 71.88%] [G loss: 1.559529]\n",
      "epoch:27 step:26186 [D loss: 0.513675, acc.: 78.12%] [G loss: 1.864695]\n",
      "epoch:27 step:26187 [D loss: 0.652024, acc.: 59.38%] [G loss: 1.311883]\n",
      "epoch:27 step:26188 [D loss: 0.581197, acc.: 70.31%] [G loss: 1.116178]\n",
      "epoch:27 step:26189 [D loss: 0.512659, acc.: 75.78%] [G loss: 1.050841]\n",
      "epoch:27 step:26190 [D loss: 0.554776, acc.: 70.31%] [G loss: 1.166229]\n",
      "epoch:27 step:26191 [D loss: 0.708795, acc.: 60.16%] [G loss: 1.133026]\n",
      "epoch:27 step:26192 [D loss: 0.383497, acc.: 90.62%] [G loss: 1.237184]\n",
      "epoch:27 step:26193 [D loss: 0.635477, acc.: 67.97%] [G loss: 1.455579]\n",
      "epoch:27 step:26194 [D loss: 0.569623, acc.: 71.09%] [G loss: 1.333544]\n",
      "epoch:27 step:26195 [D loss: 0.604900, acc.: 69.53%] [G loss: 1.450827]\n",
      "epoch:27 step:26196 [D loss: 0.708015, acc.: 55.47%] [G loss: 1.153590]\n",
      "epoch:27 step:26197 [D loss: 0.571568, acc.: 74.22%] [G loss: 1.635222]\n",
      "epoch:27 step:26198 [D loss: 0.624559, acc.: 64.06%] [G loss: 1.459491]\n",
      "epoch:27 step:26199 [D loss: 0.395480, acc.: 85.94%] [G loss: 1.527607]\n",
      "epoch:27 step:26200 [D loss: 0.697925, acc.: 56.25%] [G loss: 1.286875]\n",
      "epoch:27 step:26201 [D loss: 0.552931, acc.: 71.88%] [G loss: 1.230031]\n",
      "epoch:27 step:26202 [D loss: 0.478862, acc.: 81.25%] [G loss: 1.703496]\n",
      "epoch:27 step:26203 [D loss: 0.503001, acc.: 78.12%] [G loss: 1.486369]\n",
      "epoch:27 step:26204 [D loss: 0.555728, acc.: 71.09%] [G loss: 0.917626]\n",
      "epoch:27 step:26205 [D loss: 0.502439, acc.: 78.12%] [G loss: 1.383756]\n",
      "epoch:27 step:26206 [D loss: 0.567955, acc.: 72.66%] [G loss: 1.364718]\n",
      "epoch:27 step:26207 [D loss: 0.619556, acc.: 66.41%] [G loss: 1.062605]\n",
      "epoch:27 step:26208 [D loss: 0.538457, acc.: 72.66%] [G loss: 1.165777]\n",
      "epoch:27 step:26209 [D loss: 0.494477, acc.: 74.22%] [G loss: 1.740784]\n",
      "epoch:27 step:26210 [D loss: 0.623940, acc.: 65.62%] [G loss: 1.263844]\n",
      "epoch:27 step:26211 [D loss: 0.532572, acc.: 74.22%] [G loss: 0.808723]\n",
      "epoch:27 step:26212 [D loss: 0.492969, acc.: 75.78%] [G loss: 1.477569]\n",
      "epoch:27 step:26213 [D loss: 0.509322, acc.: 76.56%] [G loss: 1.261115]\n",
      "epoch:27 step:26214 [D loss: 0.636798, acc.: 66.41%] [G loss: 1.327881]\n",
      "epoch:27 step:26215 [D loss: 0.559382, acc.: 72.66%] [G loss: 1.424401]\n",
      "epoch:27 step:26216 [D loss: 0.569302, acc.: 69.53%] [G loss: 1.534563]\n",
      "epoch:27 step:26217 [D loss: 0.658768, acc.: 64.06%] [G loss: 1.359308]\n",
      "epoch:27 step:26218 [D loss: 0.511106, acc.: 75.78%] [G loss: 1.194985]\n",
      "epoch:27 step:26219 [D loss: 0.560099, acc.: 66.41%] [G loss: 1.525973]\n",
      "epoch:27 step:26220 [D loss: 0.422147, acc.: 80.47%] [G loss: 1.721550]\n",
      "epoch:27 step:26221 [D loss: 0.607678, acc.: 68.75%] [G loss: 1.275497]\n",
      "epoch:27 step:26222 [D loss: 0.593054, acc.: 67.19%] [G loss: 0.899555]\n",
      "epoch:27 step:26223 [D loss: 0.514879, acc.: 73.44%] [G loss: 1.618567]\n",
      "epoch:27 step:26224 [D loss: 0.599363, acc.: 71.09%] [G loss: 1.761148]\n",
      "epoch:27 step:26225 [D loss: 0.540148, acc.: 71.88%] [G loss: 1.451942]\n",
      "epoch:27 step:26226 [D loss: 0.656320, acc.: 63.28%] [G loss: 1.310730]\n",
      "epoch:27 step:26227 [D loss: 0.411543, acc.: 85.16%] [G loss: 1.469702]\n",
      "epoch:27 step:26228 [D loss: 0.530587, acc.: 71.09%] [G loss: 1.603854]\n",
      "epoch:27 step:26229 [D loss: 0.446536, acc.: 79.69%] [G loss: 1.624066]\n",
      "epoch:27 step:26230 [D loss: 0.647861, acc.: 66.41%] [G loss: 1.414469]\n",
      "epoch:27 step:26231 [D loss: 0.381361, acc.: 85.94%] [G loss: 1.829063]\n",
      "epoch:27 step:26232 [D loss: 0.434716, acc.: 80.47%] [G loss: 1.379933]\n",
      "epoch:27 step:26233 [D loss: 0.610762, acc.: 70.31%] [G loss: 1.508415]\n",
      "epoch:27 step:26234 [D loss: 0.443312, acc.: 81.25%] [G loss: 1.757282]\n",
      "epoch:27 step:26235 [D loss: 0.524890, acc.: 76.56%] [G loss: 1.645996]\n",
      "epoch:27 step:26236 [D loss: 0.483248, acc.: 70.31%] [G loss: 1.316974]\n",
      "epoch:28 step:26237 [D loss: 0.632580, acc.: 67.19%] [G loss: 1.119786]\n",
      "epoch:28 step:26238 [D loss: 0.508995, acc.: 71.09%] [G loss: 1.708131]\n",
      "epoch:28 step:26239 [D loss: 0.474760, acc.: 79.69%] [G loss: 1.679443]\n",
      "epoch:28 step:26240 [D loss: 0.605113, acc.: 67.19%] [G loss: 1.397222]\n",
      "epoch:28 step:26241 [D loss: 0.439010, acc.: 83.59%] [G loss: 1.694499]\n",
      "epoch:28 step:26242 [D loss: 0.640473, acc.: 67.97%] [G loss: 1.536685]\n",
      "epoch:28 step:26243 [D loss: 0.559338, acc.: 69.53%] [G loss: 1.698197]\n",
      "epoch:28 step:26244 [D loss: 0.551791, acc.: 72.66%] [G loss: 1.173138]\n",
      "epoch:28 step:26245 [D loss: 0.635261, acc.: 64.06%] [G loss: 1.483545]\n",
      "epoch:28 step:26246 [D loss: 0.554217, acc.: 71.88%] [G loss: 1.368013]\n",
      "epoch:28 step:26247 [D loss: 0.582715, acc.: 66.41%] [G loss: 1.297103]\n",
      "epoch:28 step:26248 [D loss: 0.662486, acc.: 55.47%] [G loss: 1.563554]\n",
      "epoch:28 step:26249 [D loss: 0.432909, acc.: 84.38%] [G loss: 1.425311]\n",
      "epoch:28 step:26250 [D loss: 0.502596, acc.: 73.44%] [G loss: 1.550017]\n",
      "epoch:28 step:26251 [D loss: 0.417614, acc.: 83.59%] [G loss: 1.395989]\n",
      "epoch:28 step:26252 [D loss: 0.443047, acc.: 84.38%] [G loss: 1.859335]\n",
      "epoch:28 step:26253 [D loss: 0.478506, acc.: 76.56%] [G loss: 1.520822]\n",
      "epoch:28 step:26254 [D loss: 0.602518, acc.: 62.50%] [G loss: 1.965913]\n",
      "epoch:28 step:26255 [D loss: 0.681587, acc.: 60.16%] [G loss: 1.783047]\n",
      "epoch:28 step:26256 [D loss: 0.639440, acc.: 65.62%] [G loss: 1.306457]\n",
      "epoch:28 step:26257 [D loss: 0.651579, acc.: 65.62%] [G loss: 1.660731]\n",
      "epoch:28 step:26258 [D loss: 0.458159, acc.: 79.69%] [G loss: 1.234337]\n",
      "epoch:28 step:26259 [D loss: 0.675998, acc.: 58.59%] [G loss: 1.400961]\n",
      "epoch:28 step:26260 [D loss: 0.428971, acc.: 80.47%] [G loss: 1.399637]\n",
      "epoch:28 step:26261 [D loss: 0.644474, acc.: 64.84%] [G loss: 1.137669]\n",
      "epoch:28 step:26262 [D loss: 0.650604, acc.: 62.50%] [G loss: 1.124247]\n",
      "epoch:28 step:26263 [D loss: 0.423902, acc.: 78.91%] [G loss: 1.384303]\n",
      "epoch:28 step:26264 [D loss: 0.482220, acc.: 76.56%] [G loss: 1.701748]\n",
      "epoch:28 step:26265 [D loss: 0.645531, acc.: 62.50%] [G loss: 1.412765]\n",
      "epoch:28 step:26266 [D loss: 0.458911, acc.: 77.34%] [G loss: 1.777493]\n",
      "epoch:28 step:26267 [D loss: 0.740304, acc.: 57.81%] [G loss: 1.269173]\n",
      "epoch:28 step:26268 [D loss: 0.664858, acc.: 62.50%] [G loss: 1.062787]\n",
      "epoch:28 step:26269 [D loss: 0.396025, acc.: 88.28%] [G loss: 1.507314]\n",
      "epoch:28 step:26270 [D loss: 0.418588, acc.: 83.59%] [G loss: 1.878514]\n",
      "epoch:28 step:26271 [D loss: 0.537805, acc.: 77.34%] [G loss: 1.587147]\n",
      "epoch:28 step:26272 [D loss: 0.504991, acc.: 77.34%] [G loss: 1.308862]\n",
      "epoch:28 step:26273 [D loss: 0.513868, acc.: 74.22%] [G loss: 1.414865]\n",
      "epoch:28 step:26274 [D loss: 0.552997, acc.: 69.53%] [G loss: 1.190565]\n",
      "epoch:28 step:26275 [D loss: 0.687299, acc.: 60.94%] [G loss: 1.453926]\n",
      "epoch:28 step:26276 [D loss: 0.528366, acc.: 76.56%] [G loss: 1.136227]\n",
      "epoch:28 step:26277 [D loss: 0.544728, acc.: 69.53%] [G loss: 1.539031]\n",
      "epoch:28 step:26278 [D loss: 0.463439, acc.: 78.91%] [G loss: 1.461823]\n",
      "epoch:28 step:26279 [D loss: 0.682022, acc.: 61.72%] [G loss: 1.194825]\n",
      "epoch:28 step:26280 [D loss: 0.583568, acc.: 67.97%] [G loss: 1.369075]\n",
      "epoch:28 step:26281 [D loss: 0.442321, acc.: 82.03%] [G loss: 1.449869]\n",
      "epoch:28 step:26282 [D loss: 0.493890, acc.: 75.00%] [G loss: 1.570960]\n",
      "epoch:28 step:26283 [D loss: 0.478381, acc.: 77.34%] [G loss: 1.727507]\n",
      "epoch:28 step:26284 [D loss: 0.424623, acc.: 82.81%] [G loss: 1.255607]\n",
      "epoch:28 step:26285 [D loss: 0.574977, acc.: 68.75%] [G loss: 1.176332]\n",
      "epoch:28 step:26286 [D loss: 0.499735, acc.: 76.56%] [G loss: 1.234998]\n",
      "epoch:28 step:26287 [D loss: 0.562481, acc.: 71.09%] [G loss: 1.582211]\n",
      "epoch:28 step:26288 [D loss: 0.397131, acc.: 82.81%] [G loss: 1.742715]\n",
      "epoch:28 step:26289 [D loss: 0.352004, acc.: 87.50%] [G loss: 1.609802]\n",
      "epoch:28 step:26290 [D loss: 0.461465, acc.: 80.47%] [G loss: 1.575804]\n",
      "epoch:28 step:26291 [D loss: 0.596339, acc.: 65.62%] [G loss: 1.241833]\n",
      "epoch:28 step:26292 [D loss: 0.508264, acc.: 71.88%] [G loss: 1.863142]\n",
      "epoch:28 step:26293 [D loss: 0.493504, acc.: 75.00%] [G loss: 1.616080]\n",
      "epoch:28 step:26294 [D loss: 0.591218, acc.: 67.19%] [G loss: 1.464998]\n",
      "epoch:28 step:26295 [D loss: 0.314404, acc.: 89.84%] [G loss: 1.799906]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:28 step:26296 [D loss: 0.362364, acc.: 87.50%] [G loss: 1.743827]\n",
      "epoch:28 step:26297 [D loss: 0.478631, acc.: 80.47%] [G loss: 1.507483]\n",
      "epoch:28 step:26298 [D loss: 0.565134, acc.: 72.66%] [G loss: 1.222664]\n",
      "epoch:28 step:26299 [D loss: 0.465515, acc.: 78.91%] [G loss: 1.361391]\n",
      "epoch:28 step:26300 [D loss: 0.381814, acc.: 83.59%] [G loss: 1.289787]\n",
      "epoch:28 step:26301 [D loss: 0.423103, acc.: 85.94%] [G loss: 1.678278]\n",
      "epoch:28 step:26302 [D loss: 0.400790, acc.: 86.72%] [G loss: 1.925390]\n",
      "epoch:28 step:26303 [D loss: 0.624592, acc.: 65.62%] [G loss: 1.280108]\n",
      "epoch:28 step:26304 [D loss: 0.647396, acc.: 63.28%] [G loss: 1.725241]\n",
      "epoch:28 step:26305 [D loss: 0.367321, acc.: 89.06%] [G loss: 2.032821]\n",
      "epoch:28 step:26306 [D loss: 0.537459, acc.: 71.09%] [G loss: 1.444037]\n",
      "epoch:28 step:26307 [D loss: 0.550783, acc.: 73.44%] [G loss: 1.530859]\n",
      "epoch:28 step:26308 [D loss: 0.410067, acc.: 84.38%] [G loss: 1.303719]\n",
      "epoch:28 step:26309 [D loss: 0.480780, acc.: 75.78%] [G loss: 1.732441]\n",
      "epoch:28 step:26310 [D loss: 0.452218, acc.: 78.91%] [G loss: 1.605697]\n",
      "epoch:28 step:26311 [D loss: 0.522559, acc.: 75.00%] [G loss: 1.223496]\n",
      "epoch:28 step:26312 [D loss: 0.578932, acc.: 70.31%] [G loss: 1.164734]\n",
      "epoch:28 step:26313 [D loss: 0.654120, acc.: 64.84%] [G loss: 1.736190]\n",
      "epoch:28 step:26314 [D loss: 0.463893, acc.: 79.69%] [G loss: 1.805683]\n",
      "epoch:28 step:26315 [D loss: 0.620519, acc.: 65.62%] [G loss: 1.205634]\n",
      "epoch:28 step:26316 [D loss: 0.441084, acc.: 79.69%] [G loss: 1.238813]\n",
      "epoch:28 step:26317 [D loss: 0.486490, acc.: 78.12%] [G loss: 1.675802]\n",
      "epoch:28 step:26318 [D loss: 0.510156, acc.: 72.66%] [G loss: 1.131554]\n",
      "epoch:28 step:26319 [D loss: 0.563130, acc.: 75.00%] [G loss: 1.521869]\n",
      "epoch:28 step:26320 [D loss: 0.697206, acc.: 60.16%] [G loss: 1.652209]\n",
      "epoch:28 step:26321 [D loss: 0.522326, acc.: 72.66%] [G loss: 1.602172]\n",
      "epoch:28 step:26322 [D loss: 0.620305, acc.: 68.75%] [G loss: 1.219274]\n",
      "epoch:28 step:26323 [D loss: 0.610576, acc.: 65.62%] [G loss: 1.344687]\n",
      "epoch:28 step:26324 [D loss: 0.448139, acc.: 76.56%] [G loss: 1.412193]\n",
      "epoch:28 step:26325 [D loss: 0.480033, acc.: 78.91%] [G loss: 1.566256]\n",
      "epoch:28 step:26326 [D loss: 0.580791, acc.: 71.88%] [G loss: 0.838437]\n",
      "epoch:28 step:26327 [D loss: 0.440163, acc.: 80.47%] [G loss: 1.076485]\n",
      "epoch:28 step:26328 [D loss: 0.542360, acc.: 73.44%] [G loss: 1.628426]\n",
      "epoch:28 step:26329 [D loss: 0.473221, acc.: 82.03%] [G loss: 1.640976]\n",
      "epoch:28 step:26330 [D loss: 0.548089, acc.: 71.88%] [G loss: 1.263173]\n",
      "epoch:28 step:26331 [D loss: 0.714629, acc.: 60.94%] [G loss: 1.263541]\n",
      "epoch:28 step:26332 [D loss: 0.408537, acc.: 83.59%] [G loss: 1.619725]\n",
      "epoch:28 step:26333 [D loss: 0.611266, acc.: 68.75%] [G loss: 1.354900]\n",
      "epoch:28 step:26334 [D loss: 0.549145, acc.: 67.19%] [G loss: 1.803399]\n",
      "epoch:28 step:26335 [D loss: 0.742427, acc.: 57.03%] [G loss: 1.416502]\n",
      "epoch:28 step:26336 [D loss: 0.721423, acc.: 60.16%] [G loss: 1.452654]\n",
      "epoch:28 step:26337 [D loss: 0.693518, acc.: 57.81%] [G loss: 1.221595]\n",
      "epoch:28 step:26338 [D loss: 0.577155, acc.: 69.53%] [G loss: 1.208884]\n",
      "epoch:28 step:26339 [D loss: 0.692498, acc.: 60.94%] [G loss: 1.482298]\n",
      "epoch:28 step:26340 [D loss: 0.523297, acc.: 75.00%] [G loss: 1.312132]\n",
      "epoch:28 step:26341 [D loss: 0.343039, acc.: 89.06%] [G loss: 1.740836]\n",
      "epoch:28 step:26342 [D loss: 0.626695, acc.: 69.53%] [G loss: 1.134593]\n",
      "epoch:28 step:26343 [D loss: 0.621729, acc.: 61.72%] [G loss: 1.020653]\n",
      "epoch:28 step:26344 [D loss: 0.450682, acc.: 82.03%] [G loss: 1.634208]\n",
      "epoch:28 step:26345 [D loss: 0.489151, acc.: 78.91%] [G loss: 1.880992]\n",
      "epoch:28 step:26346 [D loss: 0.621344, acc.: 66.41%] [G loss: 1.280496]\n",
      "epoch:28 step:26347 [D loss: 0.694162, acc.: 59.38%] [G loss: 1.180227]\n",
      "epoch:28 step:26348 [D loss: 0.503058, acc.: 75.78%] [G loss: 1.453754]\n",
      "epoch:28 step:26349 [D loss: 0.331963, acc.: 89.06%] [G loss: 1.397816]\n",
      "epoch:28 step:26350 [D loss: 0.403057, acc.: 85.16%] [G loss: 1.538165]\n",
      "epoch:28 step:26351 [D loss: 0.325223, acc.: 86.72%] [G loss: 1.829672]\n",
      "epoch:28 step:26352 [D loss: 0.588944, acc.: 70.31%] [G loss: 1.461170]\n",
      "epoch:28 step:26353 [D loss: 0.564189, acc.: 70.31%] [G loss: 1.369508]\n",
      "epoch:28 step:26354 [D loss: 0.482063, acc.: 81.25%] [G loss: 1.609794]\n",
      "epoch:28 step:26355 [D loss: 0.404168, acc.: 87.50%] [G loss: 1.648052]\n",
      "epoch:28 step:26356 [D loss: 0.524917, acc.: 72.66%] [G loss: 1.312639]\n",
      "epoch:28 step:26357 [D loss: 0.532629, acc.: 73.44%] [G loss: 1.715868]\n",
      "epoch:28 step:26358 [D loss: 0.592430, acc.: 69.53%] [G loss: 1.409534]\n",
      "epoch:28 step:26359 [D loss: 0.341842, acc.: 88.28%] [G loss: 1.870623]\n",
      "epoch:28 step:26360 [D loss: 0.707170, acc.: 57.81%] [G loss: 1.305382]\n",
      "epoch:28 step:26361 [D loss: 0.482419, acc.: 79.69%] [G loss: 1.489785]\n",
      "epoch:28 step:26362 [D loss: 0.458922, acc.: 78.91%] [G loss: 1.462332]\n",
      "epoch:28 step:26363 [D loss: 0.638711, acc.: 64.84%] [G loss: 1.301318]\n",
      "epoch:28 step:26364 [D loss: 0.615146, acc.: 71.09%] [G loss: 1.403821]\n",
      "epoch:28 step:26365 [D loss: 0.500486, acc.: 82.03%] [G loss: 1.677280]\n",
      "epoch:28 step:26366 [D loss: 0.520184, acc.: 75.00%] [G loss: 1.437149]\n",
      "epoch:28 step:26367 [D loss: 0.547929, acc.: 72.66%] [G loss: 1.616558]\n",
      "epoch:28 step:26368 [D loss: 0.506283, acc.: 75.78%] [G loss: 1.959800]\n",
      "epoch:28 step:26369 [D loss: 0.674793, acc.: 60.94%] [G loss: 1.604134]\n",
      "epoch:28 step:26370 [D loss: 0.712930, acc.: 57.81%] [G loss: 1.133255]\n",
      "epoch:28 step:26371 [D loss: 0.429220, acc.: 85.94%] [G loss: 1.742573]\n",
      "epoch:28 step:26372 [D loss: 0.589075, acc.: 65.62%] [G loss: 1.362836]\n",
      "epoch:28 step:26373 [D loss: 0.567415, acc.: 71.09%] [G loss: 1.293847]\n",
      "epoch:28 step:26374 [D loss: 0.502411, acc.: 72.66%] [G loss: 1.298443]\n",
      "epoch:28 step:26375 [D loss: 0.580908, acc.: 68.75%] [G loss: 1.151108]\n",
      "epoch:28 step:26376 [D loss: 0.531103, acc.: 75.00%] [G loss: 1.611496]\n",
      "epoch:28 step:26377 [D loss: 0.745664, acc.: 55.47%] [G loss: 1.024817]\n",
      "epoch:28 step:26378 [D loss: 0.479904, acc.: 81.25%] [G loss: 1.510731]\n",
      "epoch:28 step:26379 [D loss: 0.571917, acc.: 69.53%] [G loss: 1.059801]\n",
      "epoch:28 step:26380 [D loss: 0.629280, acc.: 66.41%] [G loss: 1.207039]\n",
      "epoch:28 step:26381 [D loss: 0.519056, acc.: 74.22%] [G loss: 0.942329]\n",
      "epoch:28 step:26382 [D loss: 0.634881, acc.: 64.06%] [G loss: 0.927597]\n",
      "epoch:28 step:26383 [D loss: 0.583252, acc.: 67.19%] [G loss: 1.479547]\n",
      "epoch:28 step:26384 [D loss: 0.532617, acc.: 75.00%] [G loss: 1.450953]\n",
      "epoch:28 step:26385 [D loss: 0.556452, acc.: 71.09%] [G loss: 1.629186]\n",
      "epoch:28 step:26386 [D loss: 0.533490, acc.: 69.53%] [G loss: 1.798303]\n",
      "epoch:28 step:26387 [D loss: 0.567711, acc.: 67.97%] [G loss: 1.150751]\n",
      "epoch:28 step:26388 [D loss: 0.648733, acc.: 64.84%] [G loss: 1.070951]\n",
      "epoch:28 step:26389 [D loss: 0.410394, acc.: 86.72%] [G loss: 1.350241]\n",
      "epoch:28 step:26390 [D loss: 0.509172, acc.: 77.34%] [G loss: 1.485066]\n",
      "epoch:28 step:26391 [D loss: 0.548635, acc.: 69.53%] [G loss: 1.117350]\n",
      "epoch:28 step:26392 [D loss: 0.434508, acc.: 80.47%] [G loss: 1.476082]\n",
      "epoch:28 step:26393 [D loss: 0.607048, acc.: 65.62%] [G loss: 1.570369]\n",
      "epoch:28 step:26394 [D loss: 0.520213, acc.: 69.53%] [G loss: 1.412443]\n",
      "epoch:28 step:26395 [D loss: 0.756465, acc.: 59.38%] [G loss: 1.095257]\n",
      "epoch:28 step:26396 [D loss: 0.477310, acc.: 78.12%] [G loss: 1.573902]\n",
      "epoch:28 step:26397 [D loss: 0.339702, acc.: 88.28%] [G loss: 1.739303]\n",
      "epoch:28 step:26398 [D loss: 0.460041, acc.: 78.91%] [G loss: 1.396232]\n",
      "epoch:28 step:26399 [D loss: 0.601599, acc.: 65.62%] [G loss: 1.794542]\n",
      "epoch:28 step:26400 [D loss: 0.651270, acc.: 62.50%] [G loss: 1.394580]\n",
      "epoch:28 step:26401 [D loss: 0.398176, acc.: 87.50%] [G loss: 1.601597]\n",
      "epoch:28 step:26402 [D loss: 0.511941, acc.: 74.22%] [G loss: 1.864815]\n",
      "epoch:28 step:26403 [D loss: 0.571584, acc.: 70.31%] [G loss: 1.429643]\n",
      "epoch:28 step:26404 [D loss: 0.519266, acc.: 77.34%] [G loss: 1.004585]\n",
      "epoch:28 step:26405 [D loss: 0.641453, acc.: 64.06%] [G loss: 1.276355]\n",
      "epoch:28 step:26406 [D loss: 0.401381, acc.: 85.16%] [G loss: 1.455330]\n",
      "epoch:28 step:26407 [D loss: 0.565988, acc.: 69.53%] [G loss: 0.930179]\n",
      "epoch:28 step:26408 [D loss: 0.354369, acc.: 88.28%] [G loss: 1.862651]\n",
      "epoch:28 step:26409 [D loss: 0.467698, acc.: 79.69%] [G loss: 1.559313]\n",
      "epoch:28 step:26410 [D loss: 0.470586, acc.: 76.56%] [G loss: 1.246947]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:28 step:26411 [D loss: 0.538446, acc.: 74.22%] [G loss: 0.979648]\n",
      "epoch:28 step:26412 [D loss: 0.508478, acc.: 77.34%] [G loss: 1.644503]\n",
      "epoch:28 step:26413 [D loss: 0.351045, acc.: 87.50%] [G loss: 1.387928]\n",
      "epoch:28 step:26414 [D loss: 0.495781, acc.: 75.00%] [G loss: 0.911244]\n",
      "epoch:28 step:26415 [D loss: 0.861996, acc.: 47.66%] [G loss: 1.339392]\n",
      "epoch:28 step:26416 [D loss: 0.518227, acc.: 77.34%] [G loss: 1.220938]\n",
      "epoch:28 step:26417 [D loss: 0.604500, acc.: 67.97%] [G loss: 0.966571]\n",
      "epoch:28 step:26418 [D loss: 0.456688, acc.: 84.38%] [G loss: 1.368870]\n",
      "epoch:28 step:26419 [D loss: 0.587687, acc.: 70.31%] [G loss: 0.930638]\n",
      "epoch:28 step:26420 [D loss: 0.505190, acc.: 75.78%] [G loss: 1.536381]\n",
      "epoch:28 step:26421 [D loss: 0.437681, acc.: 78.91%] [G loss: 1.318988]\n",
      "epoch:28 step:26422 [D loss: 0.555872, acc.: 70.31%] [G loss: 1.655016]\n",
      "epoch:28 step:26423 [D loss: 0.452985, acc.: 78.91%] [G loss: 2.034189]\n",
      "epoch:28 step:26424 [D loss: 0.494177, acc.: 78.91%] [G loss: 1.244519]\n",
      "epoch:28 step:26425 [D loss: 0.575061, acc.: 71.88%] [G loss: 1.568107]\n",
      "epoch:28 step:26426 [D loss: 0.657167, acc.: 59.38%] [G loss: 1.338646]\n",
      "epoch:28 step:26427 [D loss: 0.476788, acc.: 75.78%] [G loss: 1.539620]\n",
      "epoch:28 step:26428 [D loss: 0.644681, acc.: 64.06%] [G loss: 1.086297]\n",
      "epoch:28 step:26429 [D loss: 0.715403, acc.: 56.25%] [G loss: 1.074264]\n",
      "epoch:28 step:26430 [D loss: 0.605471, acc.: 67.19%] [G loss: 1.444900]\n",
      "epoch:28 step:26431 [D loss: 0.648334, acc.: 69.53%] [G loss: 1.504461]\n",
      "epoch:28 step:26432 [D loss: 0.513484, acc.: 74.22%] [G loss: 1.155168]\n",
      "epoch:28 step:26433 [D loss: 0.620646, acc.: 69.53%] [G loss: 1.071708]\n",
      "epoch:28 step:26434 [D loss: 0.546992, acc.: 72.66%] [G loss: 1.681097]\n",
      "epoch:28 step:26435 [D loss: 0.536684, acc.: 73.44%] [G loss: 1.395763]\n",
      "epoch:28 step:26436 [D loss: 0.480759, acc.: 78.91%] [G loss: 1.326377]\n",
      "epoch:28 step:26437 [D loss: 0.438073, acc.: 79.69%] [G loss: 1.489542]\n",
      "epoch:28 step:26438 [D loss: 0.564896, acc.: 73.44%] [G loss: 1.551439]\n",
      "epoch:28 step:26439 [D loss: 0.555888, acc.: 67.19%] [G loss: 1.144485]\n",
      "epoch:28 step:26440 [D loss: 0.448838, acc.: 85.94%] [G loss: 1.756748]\n",
      "epoch:28 step:26441 [D loss: 0.756828, acc.: 57.03%] [G loss: 1.564717]\n",
      "epoch:28 step:26442 [D loss: 0.464556, acc.: 76.56%] [G loss: 1.764833]\n",
      "epoch:28 step:26443 [D loss: 0.728502, acc.: 56.25%] [G loss: 1.568794]\n",
      "epoch:28 step:26444 [D loss: 0.667531, acc.: 60.94%] [G loss: 0.876628]\n",
      "epoch:28 step:26445 [D loss: 0.655427, acc.: 59.38%] [G loss: 1.328535]\n",
      "epoch:28 step:26446 [D loss: 0.521410, acc.: 76.56%] [G loss: 1.423249]\n",
      "epoch:28 step:26447 [D loss: 0.571086, acc.: 75.78%] [G loss: 1.864661]\n",
      "epoch:28 step:26448 [D loss: 0.467011, acc.: 79.69%] [G loss: 1.949923]\n",
      "epoch:28 step:26449 [D loss: 0.422688, acc.: 82.81%] [G loss: 1.756129]\n",
      "epoch:28 step:26450 [D loss: 0.769816, acc.: 57.03%] [G loss: 1.442154]\n",
      "epoch:28 step:26451 [D loss: 0.607581, acc.: 69.53%] [G loss: 1.299681]\n",
      "epoch:28 step:26452 [D loss: 0.554605, acc.: 74.22%] [G loss: 1.175656]\n",
      "epoch:28 step:26453 [D loss: 0.375453, acc.: 85.16%] [G loss: 1.423959]\n",
      "epoch:28 step:26454 [D loss: 0.476554, acc.: 75.00%] [G loss: 1.384352]\n",
      "epoch:28 step:26455 [D loss: 0.523987, acc.: 72.66%] [G loss: 1.295832]\n",
      "epoch:28 step:26456 [D loss: 0.414630, acc.: 80.47%] [G loss: 1.457854]\n",
      "epoch:28 step:26457 [D loss: 0.759755, acc.: 52.34%] [G loss: 1.326747]\n",
      "epoch:28 step:26458 [D loss: 0.589678, acc.: 69.53%] [G loss: 1.990761]\n",
      "epoch:28 step:26459 [D loss: 0.402725, acc.: 82.81%] [G loss: 1.676070]\n",
      "epoch:28 step:26460 [D loss: 0.404111, acc.: 81.25%] [G loss: 1.663350]\n",
      "epoch:28 step:26461 [D loss: 0.526439, acc.: 70.31%] [G loss: 1.500102]\n",
      "epoch:28 step:26462 [D loss: 0.428079, acc.: 80.47%] [G loss: 1.527875]\n",
      "epoch:28 step:26463 [D loss: 0.509622, acc.: 77.34%] [G loss: 1.816078]\n",
      "epoch:28 step:26464 [D loss: 0.481377, acc.: 76.56%] [G loss: 0.975871]\n",
      "epoch:28 step:26465 [D loss: 0.476081, acc.: 78.12%] [G loss: 1.672588]\n",
      "epoch:28 step:26466 [D loss: 0.774972, acc.: 50.00%] [G loss: 1.136502]\n",
      "epoch:28 step:26467 [D loss: 0.585983, acc.: 67.97%] [G loss: 1.579265]\n",
      "epoch:28 step:26468 [D loss: 0.570329, acc.: 75.78%] [G loss: 1.405772]\n",
      "epoch:28 step:26469 [D loss: 0.520855, acc.: 71.88%] [G loss: 1.263416]\n",
      "epoch:28 step:26470 [D loss: 0.609396, acc.: 64.84%] [G loss: 1.190681]\n",
      "epoch:28 step:26471 [D loss: 0.420461, acc.: 82.81%] [G loss: 1.851840]\n",
      "epoch:28 step:26472 [D loss: 0.676226, acc.: 55.47%] [G loss: 1.424231]\n",
      "epoch:28 step:26473 [D loss: 0.515968, acc.: 78.12%] [G loss: 1.406982]\n",
      "epoch:28 step:26474 [D loss: 0.657354, acc.: 65.62%] [G loss: 1.289801]\n",
      "epoch:28 step:26475 [D loss: 0.449820, acc.: 78.12%] [G loss: 1.390619]\n",
      "epoch:28 step:26476 [D loss: 0.626732, acc.: 64.84%] [G loss: 1.471567]\n",
      "epoch:28 step:26477 [D loss: 0.439619, acc.: 82.03%] [G loss: 1.523750]\n",
      "epoch:28 step:26478 [D loss: 0.643976, acc.: 64.06%] [G loss: 1.661409]\n",
      "epoch:28 step:26479 [D loss: 0.525229, acc.: 71.88%] [G loss: 1.101490]\n",
      "epoch:28 step:26480 [D loss: 0.590093, acc.: 65.62%] [G loss: 1.236629]\n",
      "epoch:28 step:26481 [D loss: 0.518855, acc.: 75.00%] [G loss: 1.337491]\n",
      "epoch:28 step:26482 [D loss: 0.655475, acc.: 58.59%] [G loss: 1.430800]\n",
      "epoch:28 step:26483 [D loss: 0.600773, acc.: 66.41%] [G loss: 1.284661]\n",
      "epoch:28 step:26484 [D loss: 0.463729, acc.: 79.69%] [G loss: 1.568171]\n",
      "epoch:28 step:26485 [D loss: 0.531092, acc.: 74.22%] [G loss: 1.384924]\n",
      "epoch:28 step:26486 [D loss: 0.443641, acc.: 79.69%] [G loss: 1.812197]\n",
      "epoch:28 step:26487 [D loss: 0.406529, acc.: 81.25%] [G loss: 1.649161]\n",
      "epoch:28 step:26488 [D loss: 0.559110, acc.: 75.78%] [G loss: 1.189106]\n",
      "epoch:28 step:26489 [D loss: 0.490325, acc.: 77.34%] [G loss: 1.361619]\n",
      "epoch:28 step:26490 [D loss: 0.628356, acc.: 64.84%] [G loss: 1.059417]\n",
      "epoch:28 step:26491 [D loss: 0.658236, acc.: 66.41%] [G loss: 1.192140]\n",
      "epoch:28 step:26492 [D loss: 0.701236, acc.: 58.59%] [G loss: 1.179143]\n",
      "epoch:28 step:26493 [D loss: 0.580821, acc.: 66.41%] [G loss: 1.594053]\n",
      "epoch:28 step:26494 [D loss: 0.650171, acc.: 65.62%] [G loss: 1.457541]\n",
      "epoch:28 step:26495 [D loss: 0.581731, acc.: 64.06%] [G loss: 1.528404]\n",
      "epoch:28 step:26496 [D loss: 0.720739, acc.: 52.34%] [G loss: 1.278386]\n",
      "epoch:28 step:26497 [D loss: 0.625349, acc.: 67.19%] [G loss: 0.956101]\n",
      "epoch:28 step:26498 [D loss: 0.645058, acc.: 60.16%] [G loss: 1.130026]\n",
      "epoch:28 step:26499 [D loss: 0.549954, acc.: 71.88%] [G loss: 1.639104]\n",
      "epoch:28 step:26500 [D loss: 0.767062, acc.: 50.00%] [G loss: 1.328434]\n",
      "epoch:28 step:26501 [D loss: 0.365892, acc.: 89.06%] [G loss: 1.606601]\n",
      "epoch:28 step:26502 [D loss: 0.512204, acc.: 73.44%] [G loss: 1.270377]\n",
      "epoch:28 step:26503 [D loss: 0.637663, acc.: 65.62%] [G loss: 1.804746]\n",
      "epoch:28 step:26504 [D loss: 0.446408, acc.: 79.69%] [G loss: 1.813747]\n",
      "epoch:28 step:26505 [D loss: 0.515054, acc.: 78.91%] [G loss: 1.686609]\n",
      "epoch:28 step:26506 [D loss: 0.534509, acc.: 73.44%] [G loss: 1.843398]\n",
      "epoch:28 step:26507 [D loss: 0.431435, acc.: 78.12%] [G loss: 2.095733]\n",
      "epoch:28 step:26508 [D loss: 0.530044, acc.: 75.78%] [G loss: 1.164244]\n",
      "epoch:28 step:26509 [D loss: 0.605911, acc.: 64.06%] [G loss: 1.206279]\n",
      "epoch:28 step:26510 [D loss: 0.565441, acc.: 71.09%] [G loss: 1.174200]\n",
      "epoch:28 step:26511 [D loss: 0.787333, acc.: 50.78%] [G loss: 1.333322]\n",
      "epoch:28 step:26512 [D loss: 0.671778, acc.: 60.94%] [G loss: 1.437872]\n",
      "epoch:28 step:26513 [D loss: 0.513170, acc.: 73.44%] [G loss: 1.617565]\n",
      "epoch:28 step:26514 [D loss: 0.527471, acc.: 75.78%] [G loss: 1.462943]\n",
      "epoch:28 step:26515 [D loss: 0.590337, acc.: 70.31%] [G loss: 1.088996]\n",
      "epoch:28 step:26516 [D loss: 0.481833, acc.: 79.69%] [G loss: 1.368201]\n",
      "epoch:28 step:26517 [D loss: 0.627234, acc.: 68.75%] [G loss: 1.041514]\n",
      "epoch:28 step:26518 [D loss: 0.422653, acc.: 79.69%] [G loss: 1.215956]\n",
      "epoch:28 step:26519 [D loss: 0.427580, acc.: 81.25%] [G loss: 1.571006]\n",
      "epoch:28 step:26520 [D loss: 0.524065, acc.: 75.00%] [G loss: 1.635482]\n",
      "epoch:28 step:26521 [D loss: 0.503663, acc.: 78.12%] [G loss: 1.493523]\n",
      "epoch:28 step:26522 [D loss: 0.620500, acc.: 64.84%] [G loss: 1.349002]\n",
      "epoch:28 step:26523 [D loss: 0.460829, acc.: 82.81%] [G loss: 1.664999]\n",
      "epoch:28 step:26524 [D loss: 0.512511, acc.: 75.00%] [G loss: 1.396908]\n",
      "epoch:28 step:26525 [D loss: 0.369321, acc.: 86.72%] [G loss: 1.453385]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:28 step:26526 [D loss: 0.455871, acc.: 82.03%] [G loss: 1.331916]\n",
      "epoch:28 step:26527 [D loss: 0.439197, acc.: 79.69%] [G loss: 1.502098]\n",
      "epoch:28 step:26528 [D loss: 0.482476, acc.: 75.78%] [G loss: 1.205666]\n",
      "epoch:28 step:26529 [D loss: 0.409284, acc.: 80.47%] [G loss: 1.248331]\n",
      "epoch:28 step:26530 [D loss: 0.505185, acc.: 75.00%] [G loss: 1.693717]\n",
      "epoch:28 step:26531 [D loss: 0.446039, acc.: 80.47%] [G loss: 1.849090]\n",
      "epoch:28 step:26532 [D loss: 0.459831, acc.: 78.91%] [G loss: 1.567052]\n",
      "epoch:28 step:26533 [D loss: 0.581234, acc.: 69.53%] [G loss: 1.223660]\n",
      "epoch:28 step:26534 [D loss: 0.657602, acc.: 60.16%] [G loss: 1.088199]\n",
      "epoch:28 step:26535 [D loss: 0.486352, acc.: 78.12%] [G loss: 1.479399]\n",
      "epoch:28 step:26536 [D loss: 0.542450, acc.: 77.34%] [G loss: 1.768955]\n",
      "epoch:28 step:26537 [D loss: 0.513285, acc.: 77.34%] [G loss: 1.832434]\n",
      "epoch:28 step:26538 [D loss: 0.609909, acc.: 71.88%] [G loss: 1.444157]\n",
      "epoch:28 step:26539 [D loss: 0.561651, acc.: 70.31%] [G loss: 1.776687]\n",
      "epoch:28 step:26540 [D loss: 0.382659, acc.: 85.94%] [G loss: 1.309445]\n",
      "epoch:28 step:26541 [D loss: 0.567218, acc.: 70.31%] [G loss: 1.001256]\n",
      "epoch:28 step:26542 [D loss: 0.585438, acc.: 67.19%] [G loss: 1.371568]\n",
      "epoch:28 step:26543 [D loss: 0.447870, acc.: 82.81%] [G loss: 1.125413]\n",
      "epoch:28 step:26544 [D loss: 0.516791, acc.: 75.78%] [G loss: 1.368687]\n",
      "epoch:28 step:26545 [D loss: 0.632291, acc.: 61.72%] [G loss: 1.570336]\n",
      "epoch:28 step:26546 [D loss: 0.625403, acc.: 60.94%] [G loss: 1.759526]\n",
      "epoch:28 step:26547 [D loss: 0.452040, acc.: 78.12%] [G loss: 1.633260]\n",
      "epoch:28 step:26548 [D loss: 0.692475, acc.: 60.16%] [G loss: 1.621325]\n",
      "epoch:28 step:26549 [D loss: 0.567187, acc.: 71.09%] [G loss: 1.793726]\n",
      "epoch:28 step:26550 [D loss: 0.464020, acc.: 80.47%] [G loss: 1.942726]\n",
      "epoch:28 step:26551 [D loss: 0.577363, acc.: 68.75%] [G loss: 1.032704]\n",
      "epoch:28 step:26552 [D loss: 0.606638, acc.: 64.84%] [G loss: 1.725063]\n",
      "epoch:28 step:26553 [D loss: 0.600748, acc.: 70.31%] [G loss: 1.608511]\n",
      "epoch:28 step:26554 [D loss: 0.700278, acc.: 57.81%] [G loss: 0.961836]\n",
      "epoch:28 step:26555 [D loss: 0.442480, acc.: 79.69%] [G loss: 1.612834]\n",
      "epoch:28 step:26556 [D loss: 0.566323, acc.: 67.19%] [G loss: 1.252029]\n",
      "epoch:28 step:26557 [D loss: 0.665769, acc.: 64.06%] [G loss: 1.096327]\n",
      "epoch:28 step:26558 [D loss: 0.425394, acc.: 81.25%] [G loss: 1.178710]\n",
      "epoch:28 step:26559 [D loss: 0.542505, acc.: 73.44%] [G loss: 1.370270]\n",
      "epoch:28 step:26560 [D loss: 0.441429, acc.: 81.25%] [G loss: 1.617161]\n",
      "epoch:28 step:26561 [D loss: 0.464475, acc.: 73.44%] [G loss: 1.658626]\n",
      "epoch:28 step:26562 [D loss: 0.608345, acc.: 65.62%] [G loss: 1.331916]\n",
      "epoch:28 step:26563 [D loss: 0.515608, acc.: 75.00%] [G loss: 1.042133]\n",
      "epoch:28 step:26564 [D loss: 0.441431, acc.: 79.69%] [G loss: 1.440071]\n",
      "epoch:28 step:26565 [D loss: 0.516285, acc.: 74.22%] [G loss: 1.428751]\n",
      "epoch:28 step:26566 [D loss: 0.491762, acc.: 76.56%] [G loss: 1.267849]\n",
      "epoch:28 step:26567 [D loss: 0.495940, acc.: 78.91%] [G loss: 0.956135]\n",
      "epoch:28 step:26568 [D loss: 0.630624, acc.: 64.06%] [G loss: 1.147910]\n",
      "epoch:28 step:26569 [D loss: 0.461061, acc.: 80.47%] [G loss: 1.247154]\n",
      "epoch:28 step:26570 [D loss: 0.674767, acc.: 58.59%] [G loss: 1.340025]\n",
      "epoch:28 step:26571 [D loss: 0.582258, acc.: 67.97%] [G loss: 1.234440]\n",
      "epoch:28 step:26572 [D loss: 0.452069, acc.: 82.81%] [G loss: 1.432250]\n",
      "epoch:28 step:26573 [D loss: 0.669926, acc.: 60.94%] [G loss: 1.328536]\n",
      "epoch:28 step:26574 [D loss: 0.413386, acc.: 85.16%] [G loss: 1.513486]\n",
      "epoch:28 step:26575 [D loss: 0.641176, acc.: 61.72%] [G loss: 1.399386]\n",
      "epoch:28 step:26576 [D loss: 0.445623, acc.: 82.03%] [G loss: 1.830331]\n",
      "epoch:28 step:26577 [D loss: 0.574784, acc.: 65.62%] [G loss: 1.360216]\n",
      "epoch:28 step:26578 [D loss: 0.670266, acc.: 58.59%] [G loss: 1.321264]\n",
      "epoch:28 step:26579 [D loss: 0.554333, acc.: 74.22%] [G loss: 1.670738]\n",
      "epoch:28 step:26580 [D loss: 0.421810, acc.: 82.81%] [G loss: 1.546643]\n",
      "epoch:28 step:26581 [D loss: 0.466576, acc.: 77.34%] [G loss: 1.420092]\n",
      "epoch:28 step:26582 [D loss: 0.753254, acc.: 53.12%] [G loss: 1.242519]\n",
      "epoch:28 step:26583 [D loss: 0.474171, acc.: 77.34%] [G loss: 1.357396]\n",
      "epoch:28 step:26584 [D loss: 0.653159, acc.: 61.72%] [G loss: 1.020365]\n",
      "epoch:28 step:26585 [D loss: 0.378114, acc.: 84.38%] [G loss: 1.480408]\n",
      "epoch:28 step:26586 [D loss: 0.509928, acc.: 73.44%] [G loss: 1.370172]\n",
      "epoch:28 step:26587 [D loss: 0.471148, acc.: 74.22%] [G loss: 1.679373]\n",
      "epoch:28 step:26588 [D loss: 0.465915, acc.: 76.56%] [G loss: 1.762623]\n",
      "epoch:28 step:26589 [D loss: 0.516727, acc.: 72.66%] [G loss: 1.863657]\n",
      "epoch:28 step:26590 [D loss: 0.528898, acc.: 75.00%] [G loss: 1.734767]\n",
      "epoch:28 step:26591 [D loss: 0.378004, acc.: 85.16%] [G loss: 1.242767]\n",
      "epoch:28 step:26592 [D loss: 0.585342, acc.: 71.09%] [G loss: 1.498734]\n",
      "epoch:28 step:26593 [D loss: 0.407263, acc.: 82.81%] [G loss: 1.862624]\n",
      "epoch:28 step:26594 [D loss: 0.603300, acc.: 61.72%] [G loss: 1.291234]\n",
      "epoch:28 step:26595 [D loss: 0.581060, acc.: 68.75%] [G loss: 1.147899]\n",
      "epoch:28 step:26596 [D loss: 0.455372, acc.: 79.69%] [G loss: 1.320809]\n",
      "epoch:28 step:26597 [D loss: 0.459707, acc.: 82.03%] [G loss: 1.396490]\n",
      "epoch:28 step:26598 [D loss: 0.480923, acc.: 78.91%] [G loss: 1.514087]\n",
      "epoch:28 step:26599 [D loss: 0.476994, acc.: 74.22%] [G loss: 1.167415]\n",
      "epoch:28 step:26600 [D loss: 0.506986, acc.: 75.00%] [G loss: 1.477844]\n",
      "epoch:28 step:26601 [D loss: 0.672119, acc.: 59.38%] [G loss: 1.116805]\n",
      "epoch:28 step:26602 [D loss: 0.366511, acc.: 84.38%] [G loss: 2.056804]\n",
      "epoch:28 step:26603 [D loss: 0.556865, acc.: 71.88%] [G loss: 1.542844]\n",
      "epoch:28 step:26604 [D loss: 0.547675, acc.: 73.44%] [G loss: 1.180419]\n",
      "epoch:28 step:26605 [D loss: 0.449831, acc.: 77.34%] [G loss: 1.418431]\n",
      "epoch:28 step:26606 [D loss: 0.588981, acc.: 67.19%] [G loss: 1.697854]\n",
      "epoch:28 step:26607 [D loss: 0.517306, acc.: 72.66%] [G loss: 1.514831]\n",
      "epoch:28 step:26608 [D loss: 0.355292, acc.: 90.62%] [G loss: 1.689176]\n",
      "epoch:28 step:26609 [D loss: 0.543100, acc.: 75.00%] [G loss: 1.480665]\n",
      "epoch:28 step:26610 [D loss: 0.635813, acc.: 65.62%] [G loss: 1.366498]\n",
      "epoch:28 step:26611 [D loss: 0.651343, acc.: 63.28%] [G loss: 1.470283]\n",
      "epoch:28 step:26612 [D loss: 0.530792, acc.: 73.44%] [G loss: 1.263048]\n",
      "epoch:28 step:26613 [D loss: 0.443819, acc.: 85.94%] [G loss: 1.240548]\n",
      "epoch:28 step:26614 [D loss: 0.481203, acc.: 77.34%] [G loss: 1.412041]\n",
      "epoch:28 step:26615 [D loss: 0.529867, acc.: 71.88%] [G loss: 1.340193]\n",
      "epoch:28 step:26616 [D loss: 0.693463, acc.: 61.72%] [G loss: 1.291883]\n",
      "epoch:28 step:26617 [D loss: 0.528454, acc.: 76.56%] [G loss: 1.464144]\n",
      "epoch:28 step:26618 [D loss: 0.595450, acc.: 63.28%] [G loss: 1.298451]\n",
      "epoch:28 step:26619 [D loss: 0.490933, acc.: 75.00%] [G loss: 1.189307]\n",
      "epoch:28 step:26620 [D loss: 0.642981, acc.: 64.06%] [G loss: 1.976827]\n",
      "epoch:28 step:26621 [D loss: 0.476154, acc.: 76.56%] [G loss: 1.861403]\n",
      "epoch:28 step:26622 [D loss: 0.887993, acc.: 54.69%] [G loss: 0.958349]\n",
      "epoch:28 step:26623 [D loss: 0.602726, acc.: 68.75%] [G loss: 1.376400]\n",
      "epoch:28 step:26624 [D loss: 0.736164, acc.: 56.25%] [G loss: 1.018794]\n",
      "epoch:28 step:26625 [D loss: 0.611628, acc.: 72.66%] [G loss: 1.290688]\n",
      "epoch:28 step:26626 [D loss: 0.514323, acc.: 71.09%] [G loss: 1.630413]\n",
      "epoch:28 step:26627 [D loss: 0.536332, acc.: 71.88%] [G loss: 1.590308]\n",
      "epoch:28 step:26628 [D loss: 0.687205, acc.: 60.16%] [G loss: 1.265997]\n",
      "epoch:28 step:26629 [D loss: 0.741411, acc.: 58.59%] [G loss: 0.924523]\n",
      "epoch:28 step:26630 [D loss: 0.603617, acc.: 67.19%] [G loss: 1.281521]\n",
      "epoch:28 step:26631 [D loss: 0.501993, acc.: 76.56%] [G loss: 1.536211]\n",
      "epoch:28 step:26632 [D loss: 0.420561, acc.: 85.94%] [G loss: 1.662853]\n",
      "epoch:28 step:26633 [D loss: 0.618880, acc.: 66.41%] [G loss: 1.347111]\n",
      "epoch:28 step:26634 [D loss: 0.497872, acc.: 75.78%] [G loss: 1.218424]\n",
      "epoch:28 step:26635 [D loss: 0.342270, acc.: 89.84%] [G loss: 1.358459]\n",
      "epoch:28 step:26636 [D loss: 0.744872, acc.: 60.16%] [G loss: 1.322018]\n",
      "epoch:28 step:26637 [D loss: 0.457536, acc.: 78.91%] [G loss: 1.336984]\n",
      "epoch:28 step:26638 [D loss: 0.686573, acc.: 61.72%] [G loss: 1.231891]\n",
      "epoch:28 step:26639 [D loss: 0.651770, acc.: 62.50%] [G loss: 1.649716]\n",
      "epoch:28 step:26640 [D loss: 0.553258, acc.: 71.09%] [G loss: 1.699797]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:28 step:26641 [D loss: 0.366471, acc.: 85.94%] [G loss: 1.449869]\n",
      "epoch:28 step:26642 [D loss: 0.422517, acc.: 83.59%] [G loss: 1.708610]\n",
      "epoch:28 step:26643 [D loss: 0.534212, acc.: 72.66%] [G loss: 1.514181]\n",
      "epoch:28 step:26644 [D loss: 0.486161, acc.: 76.56%] [G loss: 1.767491]\n",
      "epoch:28 step:26645 [D loss: 0.492950, acc.: 75.78%] [G loss: 1.747101]\n",
      "epoch:28 step:26646 [D loss: 0.599071, acc.: 63.28%] [G loss: 0.945378]\n",
      "epoch:28 step:26647 [D loss: 0.434367, acc.: 82.03%] [G loss: 1.243845]\n",
      "epoch:28 step:26648 [D loss: 0.574564, acc.: 68.75%] [G loss: 1.268109]\n",
      "epoch:28 step:26649 [D loss: 0.576325, acc.: 73.44%] [G loss: 1.321076]\n",
      "epoch:28 step:26650 [D loss: 0.805648, acc.: 47.66%] [G loss: 1.232053]\n",
      "epoch:28 step:26651 [D loss: 0.590212, acc.: 70.31%] [G loss: 1.310241]\n",
      "epoch:28 step:26652 [D loss: 0.528891, acc.: 80.47%] [G loss: 1.196786]\n",
      "epoch:28 step:26653 [D loss: 0.591245, acc.: 67.97%] [G loss: 1.488516]\n",
      "epoch:28 step:26654 [D loss: 0.445104, acc.: 81.25%] [G loss: 1.592606]\n",
      "epoch:28 step:26655 [D loss: 0.547220, acc.: 71.88%] [G loss: 1.806335]\n",
      "epoch:28 step:26656 [D loss: 0.528615, acc.: 75.00%] [G loss: 1.888287]\n",
      "epoch:28 step:26657 [D loss: 0.522650, acc.: 74.22%] [G loss: 1.821236]\n",
      "epoch:28 step:26658 [D loss: 0.708183, acc.: 62.50%] [G loss: 1.413410]\n",
      "epoch:28 step:26659 [D loss: 0.518881, acc.: 75.00%] [G loss: 1.732394]\n",
      "epoch:28 step:26660 [D loss: 0.664872, acc.: 64.84%] [G loss: 1.127232]\n",
      "epoch:28 step:26661 [D loss: 0.847965, acc.: 46.88%] [G loss: 1.241476]\n",
      "epoch:28 step:26662 [D loss: 0.601144, acc.: 67.19%] [G loss: 1.332681]\n",
      "epoch:28 step:26663 [D loss: 0.510895, acc.: 77.34%] [G loss: 1.407050]\n",
      "epoch:28 step:26664 [D loss: 0.500076, acc.: 75.78%] [G loss: 1.103563]\n",
      "epoch:28 step:26665 [D loss: 0.787501, acc.: 52.34%] [G loss: 1.649023]\n",
      "epoch:28 step:26666 [D loss: 0.682660, acc.: 64.06%] [G loss: 1.514316]\n",
      "epoch:28 step:26667 [D loss: 0.674572, acc.: 62.50%] [G loss: 1.315651]\n",
      "epoch:28 step:26668 [D loss: 0.428179, acc.: 79.69%] [G loss: 1.358521]\n",
      "epoch:28 step:26669 [D loss: 0.574363, acc.: 71.09%] [G loss: 1.226575]\n",
      "epoch:28 step:26670 [D loss: 0.625030, acc.: 64.84%] [G loss: 1.434904]\n",
      "epoch:28 step:26671 [D loss: 0.582503, acc.: 66.41%] [G loss: 1.752003]\n",
      "epoch:28 step:26672 [D loss: 0.483350, acc.: 78.91%] [G loss: 1.148907]\n",
      "epoch:28 step:26673 [D loss: 0.598284, acc.: 66.41%] [G loss: 1.548982]\n",
      "epoch:28 step:26674 [D loss: 0.457587, acc.: 79.69%] [G loss: 1.371114]\n",
      "epoch:28 step:26675 [D loss: 0.752242, acc.: 55.47%] [G loss: 1.188500]\n",
      "epoch:28 step:26676 [D loss: 0.570365, acc.: 67.97%] [G loss: 1.250348]\n",
      "epoch:28 step:26677 [D loss: 0.525599, acc.: 77.34%] [G loss: 1.856185]\n",
      "epoch:28 step:26678 [D loss: 0.451468, acc.: 78.12%] [G loss: 1.334691]\n",
      "epoch:28 step:26679 [D loss: 0.453045, acc.: 78.91%] [G loss: 1.782830]\n",
      "epoch:28 step:26680 [D loss: 0.497351, acc.: 75.00%] [G loss: 1.490558]\n",
      "epoch:28 step:26681 [D loss: 0.492078, acc.: 78.12%] [G loss: 1.642484]\n",
      "epoch:28 step:26682 [D loss: 0.502809, acc.: 76.56%] [G loss: 1.376565]\n",
      "epoch:28 step:26683 [D loss: 0.514914, acc.: 75.78%] [G loss: 1.475985]\n",
      "epoch:28 step:26684 [D loss: 0.428787, acc.: 85.94%] [G loss: 1.349447]\n",
      "epoch:28 step:26685 [D loss: 0.476266, acc.: 78.91%] [G loss: 1.428503]\n",
      "epoch:28 step:26686 [D loss: 0.585288, acc.: 63.28%] [G loss: 1.188136]\n",
      "epoch:28 step:26687 [D loss: 0.598648, acc.: 66.41%] [G loss: 1.276073]\n",
      "epoch:28 step:26688 [D loss: 0.460294, acc.: 76.56%] [G loss: 1.567954]\n",
      "epoch:28 step:26689 [D loss: 0.550224, acc.: 73.44%] [G loss: 1.423918]\n",
      "epoch:28 step:26690 [D loss: 0.532175, acc.: 76.56%] [G loss: 1.081351]\n",
      "epoch:28 step:26691 [D loss: 0.565065, acc.: 70.31%] [G loss: 1.219564]\n",
      "epoch:28 step:26692 [D loss: 0.574801, acc.: 68.75%] [G loss: 1.006089]\n",
      "epoch:28 step:26693 [D loss: 0.615728, acc.: 66.41%] [G loss: 1.019480]\n",
      "epoch:28 step:26694 [D loss: 0.332372, acc.: 91.41%] [G loss: 1.927623]\n",
      "epoch:28 step:26695 [D loss: 0.449365, acc.: 81.25%] [G loss: 1.257900]\n",
      "epoch:28 step:26696 [D loss: 0.415683, acc.: 85.94%] [G loss: 1.482748]\n",
      "epoch:28 step:26697 [D loss: 0.571558, acc.: 71.88%] [G loss: 1.219881]\n",
      "epoch:28 step:26698 [D loss: 0.759085, acc.: 54.69%] [G loss: 1.426957]\n",
      "epoch:28 step:26699 [D loss: 0.738630, acc.: 60.16%] [G loss: 1.254240]\n",
      "epoch:28 step:26700 [D loss: 0.442657, acc.: 81.25%] [G loss: 1.513219]\n",
      "epoch:28 step:26701 [D loss: 0.736439, acc.: 53.12%] [G loss: 1.283026]\n",
      "epoch:28 step:26702 [D loss: 0.693875, acc.: 59.38%] [G loss: 1.045575]\n",
      "epoch:28 step:26703 [D loss: 0.573105, acc.: 69.53%] [G loss: 1.588262]\n",
      "epoch:28 step:26704 [D loss: 0.575178, acc.: 71.09%] [G loss: 1.527235]\n",
      "epoch:28 step:26705 [D loss: 0.411885, acc.: 81.25%] [G loss: 1.501774]\n",
      "epoch:28 step:26706 [D loss: 0.702738, acc.: 60.16%] [G loss: 1.551201]\n",
      "epoch:28 step:26707 [D loss: 0.590124, acc.: 71.09%] [G loss: 1.778981]\n",
      "epoch:28 step:26708 [D loss: 0.439320, acc.: 82.81%] [G loss: 1.425714]\n",
      "epoch:28 step:26709 [D loss: 0.583041, acc.: 66.41%] [G loss: 1.304978]\n",
      "epoch:28 step:26710 [D loss: 0.554431, acc.: 70.31%] [G loss: 1.652297]\n",
      "epoch:28 step:26711 [D loss: 0.506151, acc.: 72.66%] [G loss: 1.792718]\n",
      "epoch:28 step:26712 [D loss: 0.522801, acc.: 76.56%] [G loss: 1.427609]\n",
      "epoch:28 step:26713 [D loss: 0.570660, acc.: 75.00%] [G loss: 1.395599]\n",
      "epoch:28 step:26714 [D loss: 0.628902, acc.: 64.84%] [G loss: 1.382941]\n",
      "epoch:28 step:26715 [D loss: 0.474846, acc.: 76.56%] [G loss: 1.774763]\n",
      "epoch:28 step:26716 [D loss: 0.634982, acc.: 65.62%] [G loss: 1.410468]\n",
      "epoch:28 step:26717 [D loss: 0.595853, acc.: 66.41%] [G loss: 1.769281]\n",
      "epoch:28 step:26718 [D loss: 0.546166, acc.: 68.75%] [G loss: 1.368970]\n",
      "epoch:28 step:26719 [D loss: 0.640305, acc.: 66.41%] [G loss: 1.938928]\n",
      "epoch:28 step:26720 [D loss: 0.460812, acc.: 79.69%] [G loss: 1.711850]\n",
      "epoch:28 step:26721 [D loss: 0.471546, acc.: 78.91%] [G loss: 1.588864]\n",
      "epoch:28 step:26722 [D loss: 0.585112, acc.: 68.75%] [G loss: 1.345074]\n",
      "epoch:28 step:26723 [D loss: 0.461907, acc.: 81.25%] [G loss: 1.794818]\n",
      "epoch:28 step:26724 [D loss: 0.601225, acc.: 61.72%] [G loss: 1.395528]\n",
      "epoch:28 step:26725 [D loss: 0.596453, acc.: 65.62%] [G loss: 1.534993]\n",
      "epoch:28 step:26726 [D loss: 0.550286, acc.: 71.09%] [G loss: 1.713693]\n",
      "epoch:28 step:26727 [D loss: 0.521121, acc.: 72.66%] [G loss: 1.840612]\n",
      "epoch:28 step:26728 [D loss: 0.601300, acc.: 71.09%] [G loss: 1.298858]\n",
      "epoch:28 step:26729 [D loss: 0.686565, acc.: 60.16%] [G loss: 1.409362]\n",
      "epoch:28 step:26730 [D loss: 0.494302, acc.: 75.00%] [G loss: 1.427319]\n",
      "epoch:28 step:26731 [D loss: 0.642206, acc.: 64.84%] [G loss: 1.679219]\n",
      "epoch:28 step:26732 [D loss: 0.581954, acc.: 64.06%] [G loss: 1.504622]\n",
      "epoch:28 step:26733 [D loss: 0.552820, acc.: 67.19%] [G loss: 1.116643]\n",
      "epoch:28 step:26734 [D loss: 0.448987, acc.: 77.34%] [G loss: 1.116447]\n",
      "epoch:28 step:26735 [D loss: 0.450798, acc.: 79.69%] [G loss: 1.542889]\n",
      "epoch:28 step:26736 [D loss: 0.557733, acc.: 70.31%] [G loss: 1.338472]\n",
      "epoch:28 step:26737 [D loss: 0.374730, acc.: 85.94%] [G loss: 1.367579]\n",
      "epoch:28 step:26738 [D loss: 0.586586, acc.: 68.75%] [G loss: 1.326281]\n",
      "epoch:28 step:26739 [D loss: 0.569325, acc.: 71.88%] [G loss: 1.238168]\n",
      "epoch:28 step:26740 [D loss: 0.590273, acc.: 64.84%] [G loss: 1.647723]\n",
      "epoch:28 step:26741 [D loss: 0.489027, acc.: 75.78%] [G loss: 1.586612]\n",
      "epoch:28 step:26742 [D loss: 0.509247, acc.: 75.78%] [G loss: 1.517716]\n",
      "epoch:28 step:26743 [D loss: 0.653670, acc.: 62.50%] [G loss: 0.998533]\n",
      "epoch:28 step:26744 [D loss: 0.626084, acc.: 69.53%] [G loss: 1.673142]\n",
      "epoch:28 step:26745 [D loss: 0.626005, acc.: 67.97%] [G loss: 1.606423]\n",
      "epoch:28 step:26746 [D loss: 0.480920, acc.: 82.03%] [G loss: 1.551425]\n",
      "epoch:28 step:26747 [D loss: 0.609673, acc.: 63.28%] [G loss: 1.684800]\n",
      "epoch:28 step:26748 [D loss: 0.370711, acc.: 85.16%] [G loss: 1.348455]\n",
      "epoch:28 step:26749 [D loss: 0.576576, acc.: 69.53%] [G loss: 1.350700]\n",
      "epoch:28 step:26750 [D loss: 0.519356, acc.: 75.78%] [G loss: 1.339030]\n",
      "epoch:28 step:26751 [D loss: 0.619890, acc.: 64.06%] [G loss: 1.398071]\n",
      "epoch:28 step:26752 [D loss: 0.526636, acc.: 75.78%] [G loss: 1.545239]\n",
      "epoch:28 step:26753 [D loss: 0.563792, acc.: 74.22%] [G loss: 1.502412]\n",
      "epoch:28 step:26754 [D loss: 0.593345, acc.: 66.41%] [G loss: 1.458129]\n",
      "epoch:28 step:26755 [D loss: 0.414857, acc.: 82.81%] [G loss: 1.552676]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:28 step:26756 [D loss: 0.503186, acc.: 76.56%] [G loss: 1.371590]\n",
      "epoch:28 step:26757 [D loss: 0.774906, acc.: 55.47%] [G loss: 1.133457]\n",
      "epoch:28 step:26758 [D loss: 0.536552, acc.: 70.31%] [G loss: 1.382349]\n",
      "epoch:28 step:26759 [D loss: 0.507553, acc.: 78.12%] [G loss: 1.324458]\n",
      "epoch:28 step:26760 [D loss: 0.594947, acc.: 71.09%] [G loss: 1.665381]\n",
      "epoch:28 step:26761 [D loss: 0.600728, acc.: 68.75%] [G loss: 1.409553]\n",
      "epoch:28 step:26762 [D loss: 0.706691, acc.: 58.59%] [G loss: 1.333124]\n",
      "epoch:28 step:26763 [D loss: 0.410350, acc.: 82.81%] [G loss: 1.285128]\n",
      "epoch:28 step:26764 [D loss: 0.552724, acc.: 67.19%] [G loss: 1.616663]\n",
      "epoch:28 step:26765 [D loss: 0.375293, acc.: 88.28%] [G loss: 1.322654]\n",
      "epoch:28 step:26766 [D loss: 0.421871, acc.: 82.81%] [G loss: 1.347481]\n",
      "epoch:28 step:26767 [D loss: 0.655979, acc.: 64.06%] [G loss: 1.763373]\n",
      "epoch:28 step:26768 [D loss: 0.516580, acc.: 69.53%] [G loss: 1.519377]\n",
      "epoch:28 step:26769 [D loss: 0.607835, acc.: 66.41%] [G loss: 1.052176]\n",
      "epoch:28 step:26770 [D loss: 0.487746, acc.: 76.56%] [G loss: 1.352776]\n",
      "epoch:28 step:26771 [D loss: 0.406141, acc.: 82.81%] [G loss: 1.662670]\n",
      "epoch:28 step:26772 [D loss: 0.483996, acc.: 75.78%] [G loss: 1.245249]\n",
      "epoch:28 step:26773 [D loss: 0.557570, acc.: 67.19%] [G loss: 1.082834]\n",
      "epoch:28 step:26774 [D loss: 0.604806, acc.: 67.97%] [G loss: 1.467935]\n",
      "epoch:28 step:26775 [D loss: 0.554100, acc.: 69.53%] [G loss: 1.946842]\n",
      "epoch:28 step:26776 [D loss: 0.360064, acc.: 87.50%] [G loss: 1.568954]\n",
      "epoch:28 step:26777 [D loss: 0.495653, acc.: 75.00%] [G loss: 1.565173]\n",
      "epoch:28 step:26778 [D loss: 0.428017, acc.: 80.47%] [G loss: 1.502777]\n",
      "epoch:28 step:26779 [D loss: 0.812161, acc.: 50.78%] [G loss: 0.956369]\n",
      "epoch:28 step:26780 [D loss: 0.580473, acc.: 65.62%] [G loss: 1.633312]\n",
      "epoch:28 step:26781 [D loss: 0.470864, acc.: 79.69%] [G loss: 1.180567]\n",
      "epoch:28 step:26782 [D loss: 0.488568, acc.: 82.03%] [G loss: 1.177281]\n",
      "epoch:28 step:26783 [D loss: 0.559739, acc.: 71.88%] [G loss: 1.442302]\n",
      "epoch:28 step:26784 [D loss: 0.503804, acc.: 75.78%] [G loss: 1.485067]\n",
      "epoch:28 step:26785 [D loss: 0.591209, acc.: 67.19%] [G loss: 1.344355]\n",
      "epoch:28 step:26786 [D loss: 0.446452, acc.: 78.91%] [G loss: 1.487747]\n",
      "epoch:28 step:26787 [D loss: 0.607304, acc.: 64.06%] [G loss: 1.766879]\n",
      "epoch:28 step:26788 [D loss: 0.373434, acc.: 87.50%] [G loss: 1.062439]\n",
      "epoch:28 step:26789 [D loss: 0.705474, acc.: 54.69%] [G loss: 1.102702]\n",
      "epoch:28 step:26790 [D loss: 0.444268, acc.: 78.91%] [G loss: 1.867276]\n",
      "epoch:28 step:26791 [D loss: 0.459215, acc.: 81.25%] [G loss: 1.600038]\n",
      "epoch:28 step:26792 [D loss: 0.592224, acc.: 70.31%] [G loss: 1.237684]\n",
      "epoch:28 step:26793 [D loss: 0.473790, acc.: 78.91%] [G loss: 1.475263]\n",
      "epoch:28 step:26794 [D loss: 0.568128, acc.: 73.44%] [G loss: 1.326577]\n",
      "epoch:28 step:26795 [D loss: 0.676798, acc.: 55.47%] [G loss: 1.555310]\n",
      "epoch:28 step:26796 [D loss: 0.548243, acc.: 71.09%] [G loss: 1.567299]\n",
      "epoch:28 step:26797 [D loss: 0.693218, acc.: 57.03%] [G loss: 1.378935]\n",
      "epoch:28 step:26798 [D loss: 0.442858, acc.: 79.69%] [G loss: 1.861861]\n",
      "epoch:28 step:26799 [D loss: 0.478331, acc.: 74.22%] [G loss: 1.320338]\n",
      "epoch:28 step:26800 [D loss: 0.383589, acc.: 89.84%] [G loss: 1.478052]\n",
      "epoch:28 step:26801 [D loss: 0.496229, acc.: 78.91%] [G loss: 1.541183]\n",
      "epoch:28 step:26802 [D loss: 0.538493, acc.: 73.44%] [G loss: 1.131609]\n",
      "epoch:28 step:26803 [D loss: 0.566972, acc.: 69.53%] [G loss: 1.259821]\n",
      "epoch:28 step:26804 [D loss: 0.688030, acc.: 58.59%] [G loss: 1.295687]\n",
      "epoch:28 step:26805 [D loss: 0.444200, acc.: 77.34%] [G loss: 1.305204]\n",
      "epoch:28 step:26806 [D loss: 0.483330, acc.: 76.56%] [G loss: 1.328294]\n",
      "epoch:28 step:26807 [D loss: 0.410881, acc.: 83.59%] [G loss: 1.453841]\n",
      "epoch:28 step:26808 [D loss: 0.400391, acc.: 84.38%] [G loss: 1.899773]\n",
      "epoch:28 step:26809 [D loss: 0.784522, acc.: 58.59%] [G loss: 1.557657]\n",
      "epoch:28 step:26810 [D loss: 0.614577, acc.: 68.75%] [G loss: 1.334562]\n",
      "epoch:28 step:26811 [D loss: 0.577500, acc.: 70.31%] [G loss: 1.073817]\n",
      "epoch:28 step:26812 [D loss: 0.462603, acc.: 81.25%] [G loss: 1.720742]\n",
      "epoch:28 step:26813 [D loss: 0.488203, acc.: 74.22%] [G loss: 1.193722]\n",
      "epoch:28 step:26814 [D loss: 0.804633, acc.: 50.00%] [G loss: 1.172300]\n",
      "epoch:28 step:26815 [D loss: 0.588102, acc.: 72.66%] [G loss: 1.484794]\n",
      "epoch:28 step:26816 [D loss: 0.433127, acc.: 81.25%] [G loss: 2.055424]\n",
      "epoch:28 step:26817 [D loss: 0.545161, acc.: 74.22%] [G loss: 1.976565]\n",
      "epoch:28 step:26818 [D loss: 0.464664, acc.: 78.91%] [G loss: 1.248559]\n",
      "epoch:28 step:26819 [D loss: 0.591316, acc.: 67.19%] [G loss: 1.302180]\n",
      "epoch:28 step:26820 [D loss: 0.517044, acc.: 73.44%] [G loss: 1.722455]\n",
      "epoch:28 step:26821 [D loss: 0.574875, acc.: 73.44%] [G loss: 1.261663]\n",
      "epoch:28 step:26822 [D loss: 0.629734, acc.: 64.84%] [G loss: 1.376422]\n",
      "epoch:28 step:26823 [D loss: 0.524477, acc.: 75.00%] [G loss: 1.686080]\n",
      "epoch:28 step:26824 [D loss: 0.624788, acc.: 60.16%] [G loss: 1.341161]\n",
      "epoch:28 step:26825 [D loss: 0.370267, acc.: 89.06%] [G loss: 1.899492]\n",
      "epoch:28 step:26826 [D loss: 0.425209, acc.: 85.16%] [G loss: 1.644755]\n",
      "epoch:28 step:26827 [D loss: 0.638782, acc.: 64.06%] [G loss: 1.979746]\n",
      "epoch:28 step:26828 [D loss: 0.426156, acc.: 84.38%] [G loss: 1.643299]\n",
      "epoch:28 step:26829 [D loss: 0.528763, acc.: 72.66%] [G loss: 1.771334]\n",
      "epoch:28 step:26830 [D loss: 0.651312, acc.: 63.28%] [G loss: 1.299882]\n",
      "epoch:28 step:26831 [D loss: 0.476284, acc.: 76.56%] [G loss: 1.157082]\n",
      "epoch:28 step:26832 [D loss: 0.590753, acc.: 71.88%] [G loss: 1.730534]\n",
      "epoch:28 step:26833 [D loss: 0.700557, acc.: 61.72%] [G loss: 1.267089]\n",
      "epoch:28 step:26834 [D loss: 0.642842, acc.: 64.06%] [G loss: 1.195250]\n",
      "epoch:28 step:26835 [D loss: 0.389227, acc.: 86.72%] [G loss: 1.271783]\n",
      "epoch:28 step:26836 [D loss: 0.501114, acc.: 75.00%] [G loss: 1.600973]\n",
      "epoch:28 step:26837 [D loss: 0.758777, acc.: 54.69%] [G loss: 1.249279]\n",
      "epoch:28 step:26838 [D loss: 0.401802, acc.: 85.16%] [G loss: 1.734407]\n",
      "epoch:28 step:26839 [D loss: 0.487752, acc.: 75.78%] [G loss: 1.415968]\n",
      "epoch:28 step:26840 [D loss: 0.471134, acc.: 77.34%] [G loss: 1.561844]\n",
      "epoch:28 step:26841 [D loss: 0.536991, acc.: 76.56%] [G loss: 1.355323]\n",
      "epoch:28 step:26842 [D loss: 0.515755, acc.: 71.88%] [G loss: 1.282393]\n",
      "epoch:28 step:26843 [D loss: 0.435635, acc.: 84.38%] [G loss: 1.476576]\n",
      "epoch:28 step:26844 [D loss: 0.638317, acc.: 63.28%] [G loss: 1.669407]\n",
      "epoch:28 step:26845 [D loss: 0.614819, acc.: 64.84%] [G loss: 1.114046]\n",
      "epoch:28 step:26846 [D loss: 0.581972, acc.: 71.09%] [G loss: 1.483848]\n",
      "epoch:28 step:26847 [D loss: 0.575300, acc.: 67.97%] [G loss: 1.345379]\n",
      "epoch:28 step:26848 [D loss: 0.714047, acc.: 63.28%] [G loss: 1.376994]\n",
      "epoch:28 step:26849 [D loss: 0.521572, acc.: 75.00%] [G loss: 1.190075]\n",
      "epoch:28 step:26850 [D loss: 0.621833, acc.: 63.28%] [G loss: 1.200593]\n",
      "epoch:28 step:26851 [D loss: 0.432437, acc.: 82.81%] [G loss: 1.819525]\n",
      "epoch:28 step:26852 [D loss: 0.631144, acc.: 63.28%] [G loss: 1.188093]\n",
      "epoch:28 step:26853 [D loss: 0.624972, acc.: 68.75%] [G loss: 1.409313]\n",
      "epoch:28 step:26854 [D loss: 0.550099, acc.: 73.44%] [G loss: 1.334941]\n",
      "epoch:28 step:26855 [D loss: 0.688931, acc.: 65.62%] [G loss: 1.711081]\n",
      "epoch:28 step:26856 [D loss: 0.636748, acc.: 63.28%] [G loss: 1.383406]\n",
      "epoch:28 step:26857 [D loss: 0.561032, acc.: 70.31%] [G loss: 1.183349]\n",
      "epoch:28 step:26858 [D loss: 0.637151, acc.: 68.75%] [G loss: 1.095989]\n",
      "epoch:28 step:26859 [D loss: 0.583960, acc.: 71.88%] [G loss: 1.520492]\n",
      "epoch:28 step:26860 [D loss: 0.515359, acc.: 74.22%] [G loss: 1.438109]\n",
      "epoch:28 step:26861 [D loss: 0.546740, acc.: 72.66%] [G loss: 1.304813]\n",
      "epoch:28 step:26862 [D loss: 0.410187, acc.: 85.94%] [G loss: 1.488903]\n",
      "epoch:28 step:26863 [D loss: 0.534516, acc.: 73.44%] [G loss: 1.484396]\n",
      "epoch:28 step:26864 [D loss: 0.640168, acc.: 63.28%] [G loss: 1.541569]\n",
      "epoch:28 step:26865 [D loss: 0.694933, acc.: 59.38%] [G loss: 1.433815]\n",
      "epoch:28 step:26866 [D loss: 0.658073, acc.: 58.59%] [G loss: 1.355663]\n",
      "epoch:28 step:26867 [D loss: 0.544634, acc.: 73.44%] [G loss: 1.409739]\n",
      "epoch:28 step:26868 [D loss: 0.447630, acc.: 82.03%] [G loss: 1.611271]\n",
      "epoch:28 step:26869 [D loss: 0.528264, acc.: 71.88%] [G loss: 1.813347]\n",
      "epoch:28 step:26870 [D loss: 0.481564, acc.: 74.22%] [G loss: 1.687249]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:28 step:26871 [D loss: 0.563945, acc.: 75.78%] [G loss: 1.156901]\n",
      "epoch:28 step:26872 [D loss: 0.545834, acc.: 71.09%] [G loss: 1.519968]\n",
      "epoch:28 step:26873 [D loss: 0.775514, acc.: 53.12%] [G loss: 1.275711]\n",
      "epoch:28 step:26874 [D loss: 0.498368, acc.: 78.91%] [G loss: 1.675071]\n",
      "epoch:28 step:26875 [D loss: 0.620880, acc.: 65.62%] [G loss: 1.577543]\n",
      "epoch:28 step:26876 [D loss: 0.552202, acc.: 73.44%] [G loss: 1.337655]\n",
      "epoch:28 step:26877 [D loss: 0.551789, acc.: 66.41%] [G loss: 1.781188]\n",
      "epoch:28 step:26878 [D loss: 0.553554, acc.: 71.09%] [G loss: 1.201034]\n",
      "epoch:28 step:26879 [D loss: 0.661935, acc.: 64.06%] [G loss: 1.724621]\n",
      "epoch:28 step:26880 [D loss: 0.478461, acc.: 75.00%] [G loss: 1.455869]\n",
      "epoch:28 step:26881 [D loss: 0.425957, acc.: 85.16%] [G loss: 1.408854]\n",
      "epoch:28 step:26882 [D loss: 0.655260, acc.: 65.62%] [G loss: 1.320865]\n",
      "epoch:28 step:26883 [D loss: 0.614373, acc.: 70.31%] [G loss: 1.650646]\n",
      "epoch:28 step:26884 [D loss: 0.413624, acc.: 80.47%] [G loss: 1.287795]\n",
      "epoch:28 step:26885 [D loss: 0.538733, acc.: 71.88%] [G loss: 1.809083]\n",
      "epoch:28 step:26886 [D loss: 0.552365, acc.: 67.97%] [G loss: 1.895329]\n",
      "epoch:28 step:26887 [D loss: 0.527468, acc.: 75.78%] [G loss: 1.457419]\n",
      "epoch:28 step:26888 [D loss: 0.532591, acc.: 75.00%] [G loss: 1.235957]\n",
      "epoch:28 step:26889 [D loss: 0.632918, acc.: 63.28%] [G loss: 1.424841]\n",
      "epoch:28 step:26890 [D loss: 0.396453, acc.: 84.38%] [G loss: 1.513671]\n",
      "epoch:28 step:26891 [D loss: 0.483422, acc.: 74.22%] [G loss: 1.438457]\n",
      "epoch:28 step:26892 [D loss: 0.422426, acc.: 84.38%] [G loss: 1.237874]\n",
      "epoch:28 step:26893 [D loss: 0.479499, acc.: 83.59%] [G loss: 1.730130]\n",
      "epoch:28 step:26894 [D loss: 0.657129, acc.: 61.72%] [G loss: 1.040210]\n",
      "epoch:28 step:26895 [D loss: 0.620443, acc.: 64.84%] [G loss: 1.086343]\n",
      "epoch:28 step:26896 [D loss: 0.556004, acc.: 71.88%] [G loss: 1.335352]\n",
      "epoch:28 step:26897 [D loss: 0.599431, acc.: 65.62%] [G loss: 1.438553]\n",
      "epoch:28 step:26898 [D loss: 0.570124, acc.: 69.53%] [G loss: 1.416397]\n",
      "epoch:28 step:26899 [D loss: 0.615299, acc.: 71.88%] [G loss: 1.357773]\n",
      "epoch:28 step:26900 [D loss: 0.656855, acc.: 67.19%] [G loss: 1.767310]\n",
      "epoch:28 step:26901 [D loss: 0.544611, acc.: 72.66%] [G loss: 1.353208]\n",
      "epoch:28 step:26902 [D loss: 0.537636, acc.: 72.66%] [G loss: 1.538025]\n",
      "epoch:28 step:26903 [D loss: 0.562787, acc.: 68.75%] [G loss: 1.290926]\n",
      "epoch:28 step:26904 [D loss: 0.677452, acc.: 64.84%] [G loss: 1.581424]\n",
      "epoch:28 step:26905 [D loss: 0.512163, acc.: 76.56%] [G loss: 1.341798]\n",
      "epoch:28 step:26906 [D loss: 0.561253, acc.: 75.00%] [G loss: 1.616451]\n",
      "epoch:28 step:26907 [D loss: 0.493244, acc.: 74.22%] [G loss: 1.631627]\n",
      "epoch:28 step:26908 [D loss: 0.512145, acc.: 75.78%] [G loss: 1.786128]\n",
      "epoch:28 step:26909 [D loss: 0.568051, acc.: 72.66%] [G loss: 1.833119]\n",
      "epoch:28 step:26910 [D loss: 0.573456, acc.: 69.53%] [G loss: 1.563450]\n",
      "epoch:28 step:26911 [D loss: 0.535883, acc.: 78.12%] [G loss: 1.416738]\n",
      "epoch:28 step:26912 [D loss: 0.643081, acc.: 65.62%] [G loss: 1.368075]\n",
      "epoch:28 step:26913 [D loss: 0.511628, acc.: 77.34%] [G loss: 1.636580]\n",
      "epoch:28 step:26914 [D loss: 0.572315, acc.: 67.19%] [G loss: 1.267631]\n",
      "epoch:28 step:26915 [D loss: 0.432896, acc.: 82.81%] [G loss: 1.289881]\n",
      "epoch:28 step:26916 [D loss: 0.552591, acc.: 74.22%] [G loss: 1.446570]\n",
      "epoch:28 step:26917 [D loss: 0.538338, acc.: 71.88%] [G loss: 1.692415]\n",
      "epoch:28 step:26918 [D loss: 0.688797, acc.: 61.72%] [G loss: 1.567975]\n",
      "epoch:28 step:26919 [D loss: 0.480192, acc.: 77.34%] [G loss: 1.629647]\n",
      "epoch:28 step:26920 [D loss: 0.674891, acc.: 60.16%] [G loss: 1.158905]\n",
      "epoch:28 step:26921 [D loss: 0.581027, acc.: 71.88%] [G loss: 1.562867]\n",
      "epoch:28 step:26922 [D loss: 0.425855, acc.: 79.69%] [G loss: 1.350910]\n",
      "epoch:28 step:26923 [D loss: 0.467048, acc.: 80.47%] [G loss: 1.314667]\n",
      "epoch:28 step:26924 [D loss: 0.444304, acc.: 83.59%] [G loss: 1.315630]\n",
      "epoch:28 step:26925 [D loss: 0.480181, acc.: 79.69%] [G loss: 1.422226]\n",
      "epoch:28 step:26926 [D loss: 0.516049, acc.: 76.56%] [G loss: 1.475410]\n",
      "epoch:28 step:26927 [D loss: 0.460280, acc.: 77.34%] [G loss: 1.310930]\n",
      "epoch:28 step:26928 [D loss: 0.464574, acc.: 78.91%] [G loss: 1.931880]\n",
      "epoch:28 step:26929 [D loss: 0.637283, acc.: 61.72%] [G loss: 1.563148]\n",
      "epoch:28 step:26930 [D loss: 0.552471, acc.: 68.75%] [G loss: 1.519362]\n",
      "epoch:28 step:26931 [D loss: 0.472851, acc.: 72.66%] [G loss: 1.205259]\n",
      "epoch:28 step:26932 [D loss: 0.635226, acc.: 62.50%] [G loss: 1.322328]\n",
      "epoch:28 step:26933 [D loss: 0.526576, acc.: 73.44%] [G loss: 1.463956]\n",
      "epoch:28 step:26934 [D loss: 0.595443, acc.: 67.97%] [G loss: 1.782305]\n",
      "epoch:28 step:26935 [D loss: 0.485530, acc.: 78.12%] [G loss: 1.443573]\n",
      "epoch:28 step:26936 [D loss: 0.618160, acc.: 67.19%] [G loss: 1.697571]\n",
      "epoch:28 step:26937 [D loss: 0.465008, acc.: 76.56%] [G loss: 1.747637]\n",
      "epoch:28 step:26938 [D loss: 0.437691, acc.: 82.81%] [G loss: 1.265796]\n",
      "epoch:28 step:26939 [D loss: 0.566719, acc.: 69.53%] [G loss: 1.531008]\n",
      "epoch:28 step:26940 [D loss: 0.821209, acc.: 43.75%] [G loss: 1.171895]\n",
      "epoch:28 step:26941 [D loss: 0.452474, acc.: 85.16%] [G loss: 1.449632]\n",
      "epoch:28 step:26942 [D loss: 0.530871, acc.: 74.22%] [G loss: 1.013171]\n",
      "epoch:28 step:26943 [D loss: 0.415822, acc.: 81.25%] [G loss: 1.382132]\n",
      "epoch:28 step:26944 [D loss: 0.568733, acc.: 74.22%] [G loss: 1.567305]\n",
      "epoch:28 step:26945 [D loss: 0.775712, acc.: 56.25%] [G loss: 1.273837]\n",
      "epoch:28 step:26946 [D loss: 0.543744, acc.: 72.66%] [G loss: 1.446223]\n",
      "epoch:28 step:26947 [D loss: 0.563670, acc.: 75.00%] [G loss: 1.263447]\n",
      "epoch:28 step:26948 [D loss: 0.594042, acc.: 70.31%] [G loss: 1.104026]\n",
      "epoch:28 step:26949 [D loss: 0.465098, acc.: 78.91%] [G loss: 1.360209]\n",
      "epoch:28 step:26950 [D loss: 0.756084, acc.: 49.22%] [G loss: 1.081301]\n",
      "epoch:28 step:26951 [D loss: 0.702370, acc.: 61.72%] [G loss: 1.289190]\n",
      "epoch:28 step:26952 [D loss: 0.566909, acc.: 66.41%] [G loss: 1.622673]\n",
      "epoch:28 step:26953 [D loss: 0.611360, acc.: 60.16%] [G loss: 1.300265]\n",
      "epoch:28 step:26954 [D loss: 0.453681, acc.: 78.91%] [G loss: 1.514812]\n",
      "epoch:28 step:26955 [D loss: 0.497280, acc.: 73.44%] [G loss: 1.919518]\n",
      "epoch:28 step:26956 [D loss: 0.728315, acc.: 48.44%] [G loss: 1.756282]\n",
      "epoch:28 step:26957 [D loss: 0.561096, acc.: 70.31%] [G loss: 1.342600]\n",
      "epoch:28 step:26958 [D loss: 0.526555, acc.: 73.44%] [G loss: 1.027413]\n",
      "epoch:28 step:26959 [D loss: 0.645947, acc.: 63.28%] [G loss: 1.274801]\n",
      "epoch:28 step:26960 [D loss: 0.723805, acc.: 60.16%] [G loss: 1.227235]\n",
      "epoch:28 step:26961 [D loss: 0.466384, acc.: 77.34%] [G loss: 1.344356]\n",
      "epoch:28 step:26962 [D loss: 0.660880, acc.: 63.28%] [G loss: 1.513336]\n",
      "epoch:28 step:26963 [D loss: 0.392402, acc.: 81.25%] [G loss: 0.997386]\n",
      "epoch:28 step:26964 [D loss: 0.531515, acc.: 71.88%] [G loss: 1.459423]\n",
      "epoch:28 step:26965 [D loss: 0.644989, acc.: 67.19%] [G loss: 1.036234]\n",
      "epoch:28 step:26966 [D loss: 0.443722, acc.: 80.47%] [G loss: 1.678605]\n",
      "epoch:28 step:26967 [D loss: 0.708014, acc.: 57.03%] [G loss: 1.117449]\n",
      "epoch:28 step:26968 [D loss: 0.526726, acc.: 75.00%] [G loss: 1.363506]\n",
      "epoch:28 step:26969 [D loss: 0.674013, acc.: 62.50%] [G loss: 1.671783]\n",
      "epoch:28 step:26970 [D loss: 0.608587, acc.: 65.62%] [G loss: 1.479255]\n",
      "epoch:28 step:26971 [D loss: 0.620822, acc.: 67.19%] [G loss: 1.452759]\n",
      "epoch:28 step:26972 [D loss: 0.355082, acc.: 86.72%] [G loss: 1.153850]\n",
      "epoch:28 step:26973 [D loss: 0.513547, acc.: 75.78%] [G loss: 1.605915]\n",
      "epoch:28 step:26974 [D loss: 0.543930, acc.: 72.66%] [G loss: 1.048220]\n",
      "epoch:28 step:26975 [D loss: 0.585702, acc.: 71.88%] [G loss: 1.169200]\n",
      "epoch:28 step:26976 [D loss: 0.517699, acc.: 74.22%] [G loss: 1.185421]\n",
      "epoch:28 step:26977 [D loss: 0.618082, acc.: 67.97%] [G loss: 1.279260]\n",
      "epoch:28 step:26978 [D loss: 0.454351, acc.: 78.91%] [G loss: 1.332924]\n",
      "epoch:28 step:26979 [D loss: 0.576259, acc.: 67.97%] [G loss: 1.446315]\n",
      "epoch:28 step:26980 [D loss: 0.487746, acc.: 73.44%] [G loss: 1.597532]\n",
      "epoch:28 step:26981 [D loss: 0.412099, acc.: 83.59%] [G loss: 1.312036]\n",
      "epoch:28 step:26982 [D loss: 0.540950, acc.: 76.56%] [G loss: 1.402079]\n",
      "epoch:28 step:26983 [D loss: 0.431116, acc.: 84.38%] [G loss: 1.431600]\n",
      "epoch:28 step:26984 [D loss: 0.544082, acc.: 74.22%] [G loss: 1.102102]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:28 step:26985 [D loss: 0.650941, acc.: 63.28%] [G loss: 1.443196]\n",
      "epoch:28 step:26986 [D loss: 0.544779, acc.: 73.44%] [G loss: 1.324600]\n",
      "epoch:28 step:26987 [D loss: 0.433508, acc.: 82.03%] [G loss: 1.426552]\n",
      "epoch:28 step:26988 [D loss: 0.373051, acc.: 85.16%] [G loss: 1.464122]\n",
      "epoch:28 step:26989 [D loss: 0.467057, acc.: 79.69%] [G loss: 1.076540]\n",
      "epoch:28 step:26990 [D loss: 0.509912, acc.: 74.22%] [G loss: 1.197231]\n",
      "epoch:28 step:26991 [D loss: 0.442837, acc.: 82.81%] [G loss: 1.240456]\n",
      "epoch:28 step:26992 [D loss: 0.648866, acc.: 64.84%] [G loss: 1.070065]\n",
      "epoch:28 step:26993 [D loss: 0.579051, acc.: 67.19%] [G loss: 1.042082]\n",
      "epoch:28 step:26994 [D loss: 0.631936, acc.: 67.97%] [G loss: 1.936247]\n",
      "epoch:28 step:26995 [D loss: 0.414388, acc.: 85.16%] [G loss: 1.712124]\n",
      "epoch:28 step:26996 [D loss: 0.775026, acc.: 57.81%] [G loss: 1.423641]\n",
      "epoch:28 step:26997 [D loss: 0.693789, acc.: 60.16%] [G loss: 1.497845]\n",
      "epoch:28 step:26998 [D loss: 0.680532, acc.: 57.81%] [G loss: 0.901554]\n",
      "epoch:28 step:26999 [D loss: 0.454815, acc.: 82.03%] [G loss: 1.960370]\n",
      "epoch:28 step:27000 [D loss: 0.479133, acc.: 80.47%] [G loss: 1.553729]\n",
      "epoch:28 step:27001 [D loss: 0.414523, acc.: 86.72%] [G loss: 1.161350]\n",
      "epoch:28 step:27002 [D loss: 0.621308, acc.: 66.41%] [G loss: 1.251059]\n",
      "epoch:28 step:27003 [D loss: 0.381689, acc.: 86.72%] [G loss: 2.015707]\n",
      "epoch:28 step:27004 [D loss: 0.436298, acc.: 82.03%] [G loss: 2.295212]\n",
      "epoch:28 step:27005 [D loss: 0.442729, acc.: 81.25%] [G loss: 1.673759]\n",
      "epoch:28 step:27006 [D loss: 0.412098, acc.: 86.72%] [G loss: 1.722564]\n",
      "epoch:28 step:27007 [D loss: 0.433414, acc.: 82.03%] [G loss: 1.462083]\n",
      "epoch:28 step:27008 [D loss: 0.557324, acc.: 77.34%] [G loss: 1.223923]\n",
      "epoch:28 step:27009 [D loss: 0.564790, acc.: 69.53%] [G loss: 0.937791]\n",
      "epoch:28 step:27010 [D loss: 0.451327, acc.: 78.91%] [G loss: 1.423682]\n",
      "epoch:28 step:27011 [D loss: 0.516560, acc.: 75.00%] [G loss: 1.397180]\n",
      "epoch:28 step:27012 [D loss: 0.530360, acc.: 73.44%] [G loss: 1.308654]\n",
      "epoch:28 step:27013 [D loss: 0.735519, acc.: 57.81%] [G loss: 1.432208]\n",
      "epoch:28 step:27014 [D loss: 0.485280, acc.: 77.34%] [G loss: 1.474460]\n",
      "epoch:28 step:27015 [D loss: 0.764124, acc.: 53.91%] [G loss: 1.572992]\n",
      "epoch:28 step:27016 [D loss: 0.531706, acc.: 70.31%] [G loss: 0.958266]\n",
      "epoch:28 step:27017 [D loss: 0.462409, acc.: 82.03%] [G loss: 1.398378]\n",
      "epoch:28 step:27018 [D loss: 0.609228, acc.: 64.06%] [G loss: 1.459445]\n",
      "epoch:28 step:27019 [D loss: 0.580648, acc.: 65.62%] [G loss: 1.580065]\n",
      "epoch:28 step:27020 [D loss: 0.494344, acc.: 78.12%] [G loss: 1.822000]\n",
      "epoch:28 step:27021 [D loss: 0.440249, acc.: 80.47%] [G loss: 1.892365]\n",
      "epoch:28 step:27022 [D loss: 0.568139, acc.: 65.62%] [G loss: 1.716907]\n",
      "epoch:28 step:27023 [D loss: 0.475592, acc.: 78.12%] [G loss: 1.364110]\n",
      "epoch:28 step:27024 [D loss: 0.663043, acc.: 64.06%] [G loss: 1.159285]\n",
      "epoch:28 step:27025 [D loss: 0.559188, acc.: 73.44%] [G loss: 1.229647]\n",
      "epoch:28 step:27026 [D loss: 0.395377, acc.: 85.16%] [G loss: 1.846699]\n",
      "epoch:28 step:27027 [D loss: 0.542270, acc.: 71.88%] [G loss: 1.434473]\n",
      "epoch:28 step:27028 [D loss: 0.539032, acc.: 77.34%] [G loss: 1.447979]\n",
      "epoch:28 step:27029 [D loss: 0.553929, acc.: 71.09%] [G loss: 0.909741]\n",
      "epoch:28 step:27030 [D loss: 0.403260, acc.: 85.16%] [G loss: 1.912650]\n",
      "epoch:28 step:27031 [D loss: 0.527542, acc.: 75.78%] [G loss: 2.087706]\n",
      "epoch:28 step:27032 [D loss: 0.644918, acc.: 64.84%] [G loss: 1.507836]\n",
      "epoch:28 step:27033 [D loss: 0.445358, acc.: 80.47%] [G loss: 1.463321]\n",
      "epoch:28 step:27034 [D loss: 0.712157, acc.: 61.72%] [G loss: 0.928559]\n",
      "epoch:28 step:27035 [D loss: 0.448975, acc.: 82.81%] [G loss: 1.019861]\n",
      "epoch:28 step:27036 [D loss: 0.462051, acc.: 81.25%] [G loss: 1.140588]\n",
      "epoch:28 step:27037 [D loss: 0.556129, acc.: 71.09%] [G loss: 1.041998]\n",
      "epoch:28 step:27038 [D loss: 0.529984, acc.: 72.66%] [G loss: 1.135488]\n",
      "epoch:28 step:27039 [D loss: 0.610381, acc.: 71.09%] [G loss: 1.840775]\n",
      "epoch:28 step:27040 [D loss: 0.566324, acc.: 73.44%] [G loss: 1.638555]\n",
      "epoch:28 step:27041 [D loss: 0.582567, acc.: 68.75%] [G loss: 1.959859]\n",
      "epoch:28 step:27042 [D loss: 0.524012, acc.: 76.56%] [G loss: 1.563677]\n",
      "epoch:28 step:27043 [D loss: 0.624376, acc.: 63.28%] [G loss: 1.236006]\n",
      "epoch:28 step:27044 [D loss: 0.554353, acc.: 71.09%] [G loss: 1.044663]\n",
      "epoch:28 step:27045 [D loss: 0.608317, acc.: 65.62%] [G loss: 1.557406]\n",
      "epoch:28 step:27046 [D loss: 0.350975, acc.: 86.72%] [G loss: 1.352287]\n",
      "epoch:28 step:27047 [D loss: 0.664184, acc.: 63.28%] [G loss: 1.552551]\n",
      "epoch:28 step:27048 [D loss: 0.608027, acc.: 68.75%] [G loss: 1.361042]\n",
      "epoch:28 step:27049 [D loss: 0.535491, acc.: 75.78%] [G loss: 1.080403]\n",
      "epoch:28 step:27050 [D loss: 0.690320, acc.: 65.62%] [G loss: 1.297761]\n",
      "epoch:28 step:27051 [D loss: 0.572173, acc.: 70.31%] [G loss: 1.478605]\n",
      "epoch:28 step:27052 [D loss: 0.394837, acc.: 85.94%] [G loss: 1.258411]\n",
      "epoch:28 step:27053 [D loss: 0.469198, acc.: 80.47%] [G loss: 1.812390]\n",
      "epoch:28 step:27054 [D loss: 0.525819, acc.: 77.34%] [G loss: 1.435084]\n",
      "epoch:28 step:27055 [D loss: 0.355644, acc.: 89.06%] [G loss: 1.565828]\n",
      "epoch:28 step:27056 [D loss: 0.611133, acc.: 64.84%] [G loss: 1.075748]\n",
      "epoch:28 step:27057 [D loss: 0.553310, acc.: 69.53%] [G loss: 1.184635]\n",
      "epoch:28 step:27058 [D loss: 0.603269, acc.: 66.41%] [G loss: 1.326030]\n",
      "epoch:28 step:27059 [D loss: 0.445224, acc.: 79.69%] [G loss: 1.644943]\n",
      "epoch:28 step:27060 [D loss: 0.449615, acc.: 78.91%] [G loss: 1.371062]\n",
      "epoch:28 step:27061 [D loss: 0.492472, acc.: 74.22%] [G loss: 1.364688]\n",
      "epoch:28 step:27062 [D loss: 0.454218, acc.: 75.78%] [G loss: 1.736709]\n",
      "epoch:28 step:27063 [D loss: 0.524637, acc.: 74.22%] [G loss: 1.522778]\n",
      "epoch:28 step:27064 [D loss: 0.691462, acc.: 64.84%] [G loss: 0.899303]\n",
      "epoch:28 step:27065 [D loss: 0.756091, acc.: 58.59%] [G loss: 1.489338]\n",
      "epoch:28 step:27066 [D loss: 0.675001, acc.: 64.84%] [G loss: 1.191333]\n",
      "epoch:28 step:27067 [D loss: 0.459613, acc.: 79.69%] [G loss: 1.118038]\n",
      "epoch:28 step:27068 [D loss: 0.494407, acc.: 75.00%] [G loss: 1.037611]\n",
      "epoch:28 step:27069 [D loss: 0.700226, acc.: 62.50%] [G loss: 1.589987]\n",
      "epoch:28 step:27070 [D loss: 0.590639, acc.: 70.31%] [G loss: 1.835603]\n",
      "epoch:28 step:27071 [D loss: 0.675103, acc.: 60.94%] [G loss: 1.632699]\n",
      "epoch:28 step:27072 [D loss: 0.570384, acc.: 70.31%] [G loss: 1.062794]\n",
      "epoch:28 step:27073 [D loss: 0.547193, acc.: 70.31%] [G loss: 1.340537]\n",
      "epoch:28 step:27074 [D loss: 0.557855, acc.: 72.66%] [G loss: 1.517040]\n",
      "epoch:28 step:27075 [D loss: 0.453431, acc.: 78.12%] [G loss: 1.583938]\n",
      "epoch:28 step:27076 [D loss: 0.471698, acc.: 76.56%] [G loss: 1.682385]\n",
      "epoch:28 step:27077 [D loss: 0.599885, acc.: 69.53%] [G loss: 1.232980]\n",
      "epoch:28 step:27078 [D loss: 0.583240, acc.: 73.44%] [G loss: 0.880077]\n",
      "epoch:28 step:27079 [D loss: 0.617333, acc.: 62.50%] [G loss: 1.136693]\n",
      "epoch:28 step:27080 [D loss: 0.724052, acc.: 60.16%] [G loss: 1.356344]\n",
      "epoch:28 step:27081 [D loss: 0.481774, acc.: 80.47%] [G loss: 1.420127]\n",
      "epoch:28 step:27082 [D loss: 0.659314, acc.: 60.94%] [G loss: 1.294027]\n",
      "epoch:28 step:27083 [D loss: 0.564961, acc.: 76.56%] [G loss: 1.426023]\n",
      "epoch:28 step:27084 [D loss: 0.491946, acc.: 77.34%] [G loss: 1.464580]\n",
      "epoch:28 step:27085 [D loss: 0.517966, acc.: 71.88%] [G loss: 1.631835]\n",
      "epoch:28 step:27086 [D loss: 0.355980, acc.: 87.50%] [G loss: 1.579608]\n",
      "epoch:28 step:27087 [D loss: 0.592901, acc.: 70.31%] [G loss: 1.683683]\n",
      "epoch:28 step:27088 [D loss: 0.432385, acc.: 78.91%] [G loss: 1.630614]\n",
      "epoch:28 step:27089 [D loss: 0.420690, acc.: 84.38%] [G loss: 1.129170]\n",
      "epoch:28 step:27090 [D loss: 0.510424, acc.: 75.00%] [G loss: 1.402990]\n",
      "epoch:28 step:27091 [D loss: 0.614167, acc.: 64.84%] [G loss: 0.985565]\n",
      "epoch:28 step:27092 [D loss: 0.507619, acc.: 78.91%] [G loss: 1.131655]\n",
      "epoch:28 step:27093 [D loss: 0.819150, acc.: 53.91%] [G loss: 1.181954]\n",
      "epoch:28 step:27094 [D loss: 0.384453, acc.: 83.59%] [G loss: 2.089770]\n",
      "epoch:28 step:27095 [D loss: 0.415669, acc.: 84.38%] [G loss: 1.618085]\n",
      "epoch:28 step:27096 [D loss: 0.587031, acc.: 64.06%] [G loss: 1.449881]\n",
      "epoch:28 step:27097 [D loss: 0.587346, acc.: 66.41%] [G loss: 1.282153]\n",
      "epoch:28 step:27098 [D loss: 0.698847, acc.: 59.38%] [G loss: 1.601391]\n",
      "epoch:28 step:27099 [D loss: 0.588234, acc.: 71.09%] [G loss: 1.504642]\n",
      "epoch:28 step:27100 [D loss: 0.621491, acc.: 66.41%] [G loss: 0.994068]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:28 step:27101 [D loss: 0.577040, acc.: 71.09%] [G loss: 1.586428]\n",
      "epoch:28 step:27102 [D loss: 0.435393, acc.: 82.03%] [G loss: 1.352083]\n",
      "epoch:28 step:27103 [D loss: 0.575431, acc.: 72.66%] [G loss: 1.418145]\n",
      "epoch:28 step:27104 [D loss: 0.797423, acc.: 53.91%] [G loss: 1.452235]\n",
      "epoch:28 step:27105 [D loss: 0.420971, acc.: 81.25%] [G loss: 1.271359]\n",
      "epoch:28 step:27106 [D loss: 0.474320, acc.: 77.34%] [G loss: 1.722195]\n",
      "epoch:28 step:27107 [D loss: 0.671954, acc.: 64.84%] [G loss: 1.398844]\n",
      "epoch:28 step:27108 [D loss: 0.377831, acc.: 85.94%] [G loss: 1.803539]\n",
      "epoch:28 step:27109 [D loss: 0.461329, acc.: 78.12%] [G loss: 1.904419]\n",
      "epoch:28 step:27110 [D loss: 0.641573, acc.: 67.97%] [G loss: 1.153961]\n",
      "epoch:28 step:27111 [D loss: 0.416266, acc.: 85.16%] [G loss: 1.305691]\n",
      "epoch:28 step:27112 [D loss: 0.539095, acc.: 73.44%] [G loss: 1.286766]\n",
      "epoch:28 step:27113 [D loss: 0.571716, acc.: 68.75%] [G loss: 1.358861]\n",
      "epoch:28 step:27114 [D loss: 0.478623, acc.: 78.91%] [G loss: 1.181134]\n",
      "epoch:28 step:27115 [D loss: 0.652324, acc.: 66.41%] [G loss: 0.944191]\n",
      "epoch:28 step:27116 [D loss: 0.472021, acc.: 78.12%] [G loss: 1.251067]\n",
      "epoch:28 step:27117 [D loss: 0.626430, acc.: 65.62%] [G loss: 1.428075]\n",
      "epoch:28 step:27118 [D loss: 0.623695, acc.: 64.06%] [G loss: 1.297870]\n",
      "epoch:28 step:27119 [D loss: 0.636685, acc.: 67.97%] [G loss: 1.166506]\n",
      "epoch:28 step:27120 [D loss: 0.472529, acc.: 77.34%] [G loss: 1.511310]\n",
      "epoch:28 step:27121 [D loss: 0.509643, acc.: 77.34%] [G loss: 1.574860]\n",
      "epoch:28 step:27122 [D loss: 0.433677, acc.: 80.47%] [G loss: 1.221394]\n",
      "epoch:28 step:27123 [D loss: 0.663145, acc.: 62.50%] [G loss: 1.223575]\n",
      "epoch:28 step:27124 [D loss: 0.596710, acc.: 71.88%] [G loss: 1.520538]\n",
      "epoch:28 step:27125 [D loss: 0.630536, acc.: 64.06%] [G loss: 1.383885]\n",
      "epoch:28 step:27126 [D loss: 0.592581, acc.: 67.97%] [G loss: 1.176872]\n",
      "epoch:28 step:27127 [D loss: 0.591975, acc.: 71.09%] [G loss: 1.593230]\n",
      "epoch:28 step:27128 [D loss: 0.514404, acc.: 72.66%] [G loss: 1.183021]\n",
      "epoch:28 step:27129 [D loss: 0.634593, acc.: 64.84%] [G loss: 1.229719]\n",
      "epoch:28 step:27130 [D loss: 0.464212, acc.: 78.12%] [G loss: 1.243713]\n",
      "epoch:28 step:27131 [D loss: 0.418866, acc.: 83.59%] [G loss: 1.476311]\n",
      "epoch:28 step:27132 [D loss: 0.543555, acc.: 71.09%] [G loss: 1.492025]\n",
      "epoch:28 step:27133 [D loss: 0.415390, acc.: 80.47%] [G loss: 1.603484]\n",
      "epoch:28 step:27134 [D loss: 0.589624, acc.: 67.19%] [G loss: 1.463247]\n",
      "epoch:28 step:27135 [D loss: 0.515572, acc.: 75.00%] [G loss: 1.581676]\n",
      "epoch:28 step:27136 [D loss: 0.765230, acc.: 59.38%] [G loss: 1.229805]\n",
      "epoch:28 step:27137 [D loss: 0.672954, acc.: 58.59%] [G loss: 1.577076]\n",
      "epoch:28 step:27138 [D loss: 0.534050, acc.: 75.78%] [G loss: 1.554868]\n",
      "epoch:28 step:27139 [D loss: 0.454500, acc.: 83.59%] [G loss: 1.257520]\n",
      "epoch:28 step:27140 [D loss: 0.626179, acc.: 64.06%] [G loss: 1.308135]\n",
      "epoch:28 step:27141 [D loss: 0.701490, acc.: 59.38%] [G loss: 0.999337]\n",
      "epoch:28 step:27142 [D loss: 0.430969, acc.: 83.59%] [G loss: 1.740123]\n",
      "epoch:28 step:27143 [D loss: 0.749304, acc.: 58.59%] [G loss: 1.252265]\n",
      "epoch:28 step:27144 [D loss: 0.474923, acc.: 79.69%] [G loss: 1.368261]\n",
      "epoch:28 step:27145 [D loss: 0.551260, acc.: 69.53%] [G loss: 1.401953]\n",
      "epoch:28 step:27146 [D loss: 0.570192, acc.: 72.66%] [G loss: 1.305643]\n",
      "epoch:28 step:27147 [D loss: 0.644523, acc.: 64.06%] [G loss: 1.306629]\n",
      "epoch:28 step:27148 [D loss: 0.577711, acc.: 68.75%] [G loss: 1.271175]\n",
      "epoch:28 step:27149 [D loss: 0.461786, acc.: 82.03%] [G loss: 1.457459]\n",
      "epoch:28 step:27150 [D loss: 0.723317, acc.: 56.25%] [G loss: 1.231956]\n",
      "epoch:28 step:27151 [D loss: 0.554340, acc.: 76.56%] [G loss: 1.141455]\n",
      "epoch:28 step:27152 [D loss: 0.489950, acc.: 77.34%] [G loss: 1.305679]\n",
      "epoch:28 step:27153 [D loss: 0.528883, acc.: 74.22%] [G loss: 1.849542]\n",
      "epoch:28 step:27154 [D loss: 0.608431, acc.: 60.16%] [G loss: 1.554181]\n",
      "epoch:28 step:27155 [D loss: 0.528017, acc.: 72.66%] [G loss: 1.292067]\n",
      "epoch:28 step:27156 [D loss: 0.492140, acc.: 77.34%] [G loss: 1.558053]\n",
      "epoch:28 step:27157 [D loss: 0.610019, acc.: 64.84%] [G loss: 2.094138]\n",
      "epoch:28 step:27158 [D loss: 0.588186, acc.: 70.31%] [G loss: 1.225821]\n",
      "epoch:28 step:27159 [D loss: 0.657801, acc.: 65.62%] [G loss: 1.259783]\n",
      "epoch:28 step:27160 [D loss: 0.568211, acc.: 75.78%] [G loss: 1.032332]\n",
      "epoch:28 step:27161 [D loss: 0.494646, acc.: 77.34%] [G loss: 1.182653]\n",
      "epoch:28 step:27162 [D loss: 0.425507, acc.: 82.03%] [G loss: 1.467223]\n",
      "epoch:28 step:27163 [D loss: 0.650575, acc.: 66.41%] [G loss: 1.523842]\n",
      "epoch:28 step:27164 [D loss: 0.483066, acc.: 76.56%] [G loss: 1.606708]\n",
      "epoch:28 step:27165 [D loss: 0.518304, acc.: 76.56%] [G loss: 2.353269]\n",
      "epoch:28 step:27166 [D loss: 0.443489, acc.: 83.59%] [G loss: 1.383273]\n",
      "epoch:28 step:27167 [D loss: 0.834548, acc.: 51.56%] [G loss: 1.135309]\n",
      "epoch:28 step:27168 [D loss: 0.398795, acc.: 85.16%] [G loss: 1.368196]\n",
      "epoch:28 step:27169 [D loss: 0.626002, acc.: 64.06%] [G loss: 1.388579]\n",
      "epoch:28 step:27170 [D loss: 0.561722, acc.: 69.53%] [G loss: 1.335595]\n",
      "epoch:28 step:27171 [D loss: 0.447617, acc.: 77.34%] [G loss: 1.912632]\n",
      "epoch:28 step:27172 [D loss: 0.441878, acc.: 81.25%] [G loss: 1.673394]\n",
      "epoch:28 step:27173 [D loss: 0.598629, acc.: 68.75%] [G loss: 1.629849]\n",
      "epoch:29 step:27174 [D loss: 0.401728, acc.: 82.03%] [G loss: 1.491494]\n",
      "epoch:29 step:27175 [D loss: 0.515935, acc.: 73.44%] [G loss: 1.374531]\n",
      "epoch:29 step:27176 [D loss: 0.592337, acc.: 68.75%] [G loss: 1.202069]\n",
      "epoch:29 step:27177 [D loss: 0.616614, acc.: 69.53%] [G loss: 1.048027]\n",
      "epoch:29 step:27178 [D loss: 0.549402, acc.: 70.31%] [G loss: 1.460658]\n",
      "epoch:29 step:27179 [D loss: 0.634162, acc.: 68.75%] [G loss: 1.238999]\n",
      "epoch:29 step:27180 [D loss: 0.706383, acc.: 59.38%] [G loss: 1.469595]\n",
      "epoch:29 step:27181 [D loss: 0.459274, acc.: 75.00%] [G loss: 1.163221]\n",
      "epoch:29 step:27182 [D loss: 0.503941, acc.: 75.78%] [G loss: 1.478536]\n",
      "epoch:29 step:27183 [D loss: 0.738371, acc.: 53.91%] [G loss: 1.539148]\n",
      "epoch:29 step:27184 [D loss: 0.479898, acc.: 77.34%] [G loss: 1.260663]\n",
      "epoch:29 step:27185 [D loss: 0.566456, acc.: 72.66%] [G loss: 1.777400]\n",
      "epoch:29 step:27186 [D loss: 0.693553, acc.: 57.03%] [G loss: 1.665091]\n",
      "epoch:29 step:27187 [D loss: 0.436672, acc.: 80.47%] [G loss: 1.248184]\n",
      "epoch:29 step:27188 [D loss: 0.606068, acc.: 68.75%] [G loss: 1.328601]\n",
      "epoch:29 step:27189 [D loss: 0.430666, acc.: 78.91%] [G loss: 2.075018]\n",
      "epoch:29 step:27190 [D loss: 0.573606, acc.: 69.53%] [G loss: 1.627387]\n",
      "epoch:29 step:27191 [D loss: 0.628702, acc.: 67.97%] [G loss: 1.391099]\n",
      "epoch:29 step:27192 [D loss: 0.695150, acc.: 57.03%] [G loss: 1.237462]\n",
      "epoch:29 step:27193 [D loss: 0.593533, acc.: 67.97%] [G loss: 1.285950]\n",
      "epoch:29 step:27194 [D loss: 0.532248, acc.: 71.88%] [G loss: 1.683142]\n",
      "epoch:29 step:27195 [D loss: 0.681664, acc.: 59.38%] [G loss: 1.296551]\n",
      "epoch:29 step:27196 [D loss: 0.376712, acc.: 86.72%] [G loss: 1.464512]\n",
      "epoch:29 step:27197 [D loss: 0.576120, acc.: 73.44%] [G loss: 1.622123]\n",
      "epoch:29 step:27198 [D loss: 0.568756, acc.: 71.09%] [G loss: 1.643460]\n",
      "epoch:29 step:27199 [D loss: 0.430157, acc.: 81.25%] [G loss: 1.823871]\n",
      "epoch:29 step:27200 [D loss: 0.537867, acc.: 70.31%] [G loss: 1.316599]\n",
      "epoch:29 step:27201 [D loss: 0.639494, acc.: 65.62%] [G loss: 1.290341]\n",
      "epoch:29 step:27202 [D loss: 0.528979, acc.: 69.53%] [G loss: 1.888531]\n",
      "epoch:29 step:27203 [D loss: 0.648886, acc.: 63.28%] [G loss: 0.954028]\n",
      "epoch:29 step:27204 [D loss: 0.436552, acc.: 84.38%] [G loss: 1.054146]\n",
      "epoch:29 step:27205 [D loss: 0.484603, acc.: 77.34%] [G loss: 1.496830]\n",
      "epoch:29 step:27206 [D loss: 0.507003, acc.: 74.22%] [G loss: 1.319854]\n",
      "epoch:29 step:27207 [D loss: 0.524519, acc.: 79.69%] [G loss: 1.601905]\n",
      "epoch:29 step:27208 [D loss: 0.440356, acc.: 78.91%] [G loss: 1.357940]\n",
      "epoch:29 step:27209 [D loss: 0.380847, acc.: 83.59%] [G loss: 1.451927]\n",
      "epoch:29 step:27210 [D loss: 0.503642, acc.: 74.22%] [G loss: 1.463108]\n",
      "epoch:29 step:27211 [D loss: 0.502651, acc.: 75.78%] [G loss: 1.958154]\n",
      "epoch:29 step:27212 [D loss: 0.374283, acc.: 86.72%] [G loss: 1.439611]\n",
      "epoch:29 step:27213 [D loss: 0.760922, acc.: 53.91%] [G loss: 1.382306]\n",
      "epoch:29 step:27214 [D loss: 0.502644, acc.: 75.78%] [G loss: 1.526570]\n",
      "epoch:29 step:27215 [D loss: 0.464419, acc.: 78.91%] [G loss: 1.524327]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:29 step:27216 [D loss: 0.553288, acc.: 69.53%] [G loss: 1.710453]\n",
      "epoch:29 step:27217 [D loss: 0.555355, acc.: 72.66%] [G loss: 1.496861]\n",
      "epoch:29 step:27218 [D loss: 0.532721, acc.: 74.22%] [G loss: 1.430683]\n",
      "epoch:29 step:27219 [D loss: 0.675155, acc.: 58.59%] [G loss: 1.219753]\n",
      "epoch:29 step:27220 [D loss: 0.468543, acc.: 79.69%] [G loss: 1.384831]\n",
      "epoch:29 step:27221 [D loss: 0.457797, acc.: 80.47%] [G loss: 1.264124]\n",
      "epoch:29 step:27222 [D loss: 0.549216, acc.: 70.31%] [G loss: 1.245280]\n",
      "epoch:29 step:27223 [D loss: 0.375215, acc.: 87.50%] [G loss: 1.292041]\n",
      "epoch:29 step:27224 [D loss: 0.562046, acc.: 70.31%] [G loss: 1.175476]\n",
      "epoch:29 step:27225 [D loss: 0.386500, acc.: 85.16%] [G loss: 1.429746]\n",
      "epoch:29 step:27226 [D loss: 0.376977, acc.: 86.72%] [G loss: 1.367305]\n",
      "epoch:29 step:27227 [D loss: 0.477011, acc.: 78.91%] [G loss: 1.334367]\n",
      "epoch:29 step:27228 [D loss: 0.697329, acc.: 61.72%] [G loss: 1.104380]\n",
      "epoch:29 step:27229 [D loss: 0.654228, acc.: 60.94%] [G loss: 1.323198]\n",
      "epoch:29 step:27230 [D loss: 0.501992, acc.: 73.44%] [G loss: 1.329654]\n",
      "epoch:29 step:27231 [D loss: 0.714951, acc.: 63.28%] [G loss: 0.852605]\n",
      "epoch:29 step:27232 [D loss: 0.544091, acc.: 72.66%] [G loss: 1.495641]\n",
      "epoch:29 step:27233 [D loss: 0.504294, acc.: 77.34%] [G loss: 1.232059]\n",
      "epoch:29 step:27234 [D loss: 0.387334, acc.: 85.94%] [G loss: 1.600657]\n",
      "epoch:29 step:27235 [D loss: 0.505878, acc.: 78.12%] [G loss: 1.672108]\n",
      "epoch:29 step:27236 [D loss: 0.508573, acc.: 73.44%] [G loss: 1.332331]\n",
      "epoch:29 step:27237 [D loss: 0.707089, acc.: 55.47%] [G loss: 1.065284]\n",
      "epoch:29 step:27238 [D loss: 0.638716, acc.: 64.06%] [G loss: 1.649248]\n",
      "epoch:29 step:27239 [D loss: 0.596930, acc.: 65.62%] [G loss: 1.068544]\n",
      "epoch:29 step:27240 [D loss: 0.495583, acc.: 78.91%] [G loss: 1.471821]\n",
      "epoch:29 step:27241 [D loss: 0.655807, acc.: 69.53%] [G loss: 1.144160]\n",
      "epoch:29 step:27242 [D loss: 0.588674, acc.: 72.66%] [G loss: 1.430503]\n",
      "epoch:29 step:27243 [D loss: 0.532164, acc.: 71.09%] [G loss: 1.686137]\n",
      "epoch:29 step:27244 [D loss: 0.475280, acc.: 77.34%] [G loss: 1.279626]\n",
      "epoch:29 step:27245 [D loss: 0.529929, acc.: 70.31%] [G loss: 1.747270]\n",
      "epoch:29 step:27246 [D loss: 0.408112, acc.: 85.16%] [G loss: 1.348468]\n",
      "epoch:29 step:27247 [D loss: 0.444948, acc.: 84.38%] [G loss: 1.556360]\n",
      "epoch:29 step:27248 [D loss: 0.459913, acc.: 75.00%] [G loss: 1.613745]\n",
      "epoch:29 step:27249 [D loss: 0.606844, acc.: 67.19%] [G loss: 1.574388]\n",
      "epoch:29 step:27250 [D loss: 0.632631, acc.: 64.84%] [G loss: 1.335487]\n",
      "epoch:29 step:27251 [D loss: 0.686593, acc.: 60.16%] [G loss: 0.768541]\n",
      "epoch:29 step:27252 [D loss: 0.527424, acc.: 67.97%] [G loss: 2.132771]\n",
      "epoch:29 step:27253 [D loss: 0.573925, acc.: 68.75%] [G loss: 1.291901]\n",
      "epoch:29 step:27254 [D loss: 0.531772, acc.: 73.44%] [G loss: 1.296093]\n",
      "epoch:29 step:27255 [D loss: 0.483442, acc.: 76.56%] [G loss: 1.546003]\n",
      "epoch:29 step:27256 [D loss: 0.756896, acc.: 54.69%] [G loss: 1.477723]\n",
      "epoch:29 step:27257 [D loss: 0.636663, acc.: 66.41%] [G loss: 1.657778]\n",
      "epoch:29 step:27258 [D loss: 0.444081, acc.: 82.03%] [G loss: 1.484260]\n",
      "epoch:29 step:27259 [D loss: 0.665461, acc.: 65.62%] [G loss: 1.606920]\n",
      "epoch:29 step:27260 [D loss: 0.584076, acc.: 68.75%] [G loss: 1.248018]\n",
      "epoch:29 step:27261 [D loss: 0.535731, acc.: 77.34%] [G loss: 1.491674]\n",
      "epoch:29 step:27262 [D loss: 0.608518, acc.: 65.62%] [G loss: 1.138004]\n",
      "epoch:29 step:27263 [D loss: 0.586476, acc.: 66.41%] [G loss: 0.975842]\n",
      "epoch:29 step:27264 [D loss: 0.400489, acc.: 79.69%] [G loss: 0.922404]\n",
      "epoch:29 step:27265 [D loss: 0.464465, acc.: 78.91%] [G loss: 1.497330]\n",
      "epoch:29 step:27266 [D loss: 0.573737, acc.: 66.41%] [G loss: 1.225734]\n",
      "epoch:29 step:27267 [D loss: 0.422399, acc.: 84.38%] [G loss: 1.696174]\n",
      "epoch:29 step:27268 [D loss: 0.539918, acc.: 71.88%] [G loss: 1.575971]\n",
      "epoch:29 step:27269 [D loss: 0.424885, acc.: 78.91%] [G loss: 1.481023]\n",
      "epoch:29 step:27270 [D loss: 0.582157, acc.: 71.88%] [G loss: 1.111736]\n",
      "epoch:29 step:27271 [D loss: 0.402140, acc.: 87.50%] [G loss: 1.811299]\n",
      "epoch:29 step:27272 [D loss: 0.680504, acc.: 64.06%] [G loss: 1.649900]\n",
      "epoch:29 step:27273 [D loss: 0.541083, acc.: 68.75%] [G loss: 1.196261]\n",
      "epoch:29 step:27274 [D loss: 0.522746, acc.: 75.00%] [G loss: 1.350216]\n",
      "epoch:29 step:27275 [D loss: 0.542469, acc.: 75.78%] [G loss: 2.190496]\n",
      "epoch:29 step:27276 [D loss: 0.415800, acc.: 82.81%] [G loss: 1.493614]\n",
      "epoch:29 step:27277 [D loss: 0.494486, acc.: 75.78%] [G loss: 1.406727]\n",
      "epoch:29 step:27278 [D loss: 0.578304, acc.: 71.88%] [G loss: 1.483908]\n",
      "epoch:29 step:27279 [D loss: 0.516606, acc.: 75.00%] [G loss: 1.356308]\n",
      "epoch:29 step:27280 [D loss: 0.541015, acc.: 74.22%] [G loss: 1.010231]\n",
      "epoch:29 step:27281 [D loss: 0.474568, acc.: 78.12%] [G loss: 1.137276]\n",
      "epoch:29 step:27282 [D loss: 0.515360, acc.: 71.09%] [G loss: 1.275708]\n",
      "epoch:29 step:27283 [D loss: 0.411322, acc.: 82.81%] [G loss: 1.539247]\n",
      "epoch:29 step:27284 [D loss: 0.443658, acc.: 80.47%] [G loss: 1.611484]\n",
      "epoch:29 step:27285 [D loss: 0.552605, acc.: 71.88%] [G loss: 1.338813]\n",
      "epoch:29 step:27286 [D loss: 0.611258, acc.: 69.53%] [G loss: 1.044712]\n",
      "epoch:29 step:27287 [D loss: 0.330841, acc.: 92.19%] [G loss: 1.573170]\n",
      "epoch:29 step:27288 [D loss: 0.480006, acc.: 77.34%] [G loss: 1.640155]\n",
      "epoch:29 step:27289 [D loss: 0.543205, acc.: 73.44%] [G loss: 1.276034]\n",
      "epoch:29 step:27290 [D loss: 0.474466, acc.: 80.47%] [G loss: 1.474554]\n",
      "epoch:29 step:27291 [D loss: 0.561175, acc.: 70.31%] [G loss: 1.381102]\n",
      "epoch:29 step:27292 [D loss: 0.504188, acc.: 76.56%] [G loss: 1.606487]\n",
      "epoch:29 step:27293 [D loss: 0.562131, acc.: 72.66%] [G loss: 1.277181]\n",
      "epoch:29 step:27294 [D loss: 0.514886, acc.: 76.56%] [G loss: 1.474339]\n",
      "epoch:29 step:27295 [D loss: 0.827642, acc.: 52.34%] [G loss: 1.318461]\n",
      "epoch:29 step:27296 [D loss: 0.617382, acc.: 70.31%] [G loss: 1.399916]\n",
      "epoch:29 step:27297 [D loss: 0.413983, acc.: 80.47%] [G loss: 1.715706]\n",
      "epoch:29 step:27298 [D loss: 0.593886, acc.: 66.41%] [G loss: 1.039535]\n",
      "epoch:29 step:27299 [D loss: 0.552191, acc.: 81.25%] [G loss: 1.081391]\n",
      "epoch:29 step:27300 [D loss: 0.522553, acc.: 72.66%] [G loss: 1.172300]\n",
      "epoch:29 step:27301 [D loss: 0.618600, acc.: 61.72%] [G loss: 1.434493]\n",
      "epoch:29 step:27302 [D loss: 0.566476, acc.: 73.44%] [G loss: 1.510402]\n",
      "epoch:29 step:27303 [D loss: 0.582485, acc.: 70.31%] [G loss: 1.598502]\n",
      "epoch:29 step:27304 [D loss: 0.460161, acc.: 82.03%] [G loss: 1.663370]\n",
      "epoch:29 step:27305 [D loss: 0.433194, acc.: 82.81%] [G loss: 1.340878]\n",
      "epoch:29 step:27306 [D loss: 0.393950, acc.: 84.38%] [G loss: 1.399098]\n",
      "epoch:29 step:27307 [D loss: 0.657257, acc.: 60.94%] [G loss: 1.276315]\n",
      "epoch:29 step:27308 [D loss: 0.489445, acc.: 81.25%] [G loss: 1.512913]\n",
      "epoch:29 step:27309 [D loss: 0.686974, acc.: 58.59%] [G loss: 1.075426]\n",
      "epoch:29 step:27310 [D loss: 0.458464, acc.: 83.59%] [G loss: 1.612738]\n",
      "epoch:29 step:27311 [D loss: 0.562445, acc.: 68.75%] [G loss: 1.213997]\n",
      "epoch:29 step:27312 [D loss: 0.474095, acc.: 79.69%] [G loss: 1.435548]\n",
      "epoch:29 step:27313 [D loss: 0.501330, acc.: 75.78%] [G loss: 1.362218]\n",
      "epoch:29 step:27314 [D loss: 0.637323, acc.: 64.84%] [G loss: 1.068175]\n",
      "epoch:29 step:27315 [D loss: 0.420838, acc.: 81.25%] [G loss: 1.264241]\n",
      "epoch:29 step:27316 [D loss: 0.684667, acc.: 58.59%] [G loss: 1.280067]\n",
      "epoch:29 step:27317 [D loss: 0.691956, acc.: 60.94%] [G loss: 1.294069]\n",
      "epoch:29 step:27318 [D loss: 0.572915, acc.: 74.22%] [G loss: 1.452993]\n",
      "epoch:29 step:27319 [D loss: 0.637796, acc.: 67.97%] [G loss: 1.541512]\n",
      "epoch:29 step:27320 [D loss: 0.469376, acc.: 83.59%] [G loss: 1.771552]\n",
      "epoch:29 step:27321 [D loss: 0.642095, acc.: 67.97%] [G loss: 1.209238]\n",
      "epoch:29 step:27322 [D loss: 0.564237, acc.: 73.44%] [G loss: 1.828822]\n",
      "epoch:29 step:27323 [D loss: 0.695067, acc.: 58.59%] [G loss: 1.246637]\n",
      "epoch:29 step:27324 [D loss: 0.520858, acc.: 75.00%] [G loss: 1.168865]\n",
      "epoch:29 step:27325 [D loss: 0.584266, acc.: 70.31%] [G loss: 1.431581]\n",
      "epoch:29 step:27326 [D loss: 0.520480, acc.: 71.88%] [G loss: 1.462874]\n",
      "epoch:29 step:27327 [D loss: 0.539685, acc.: 75.78%] [G loss: 1.300131]\n",
      "epoch:29 step:27328 [D loss: 0.422789, acc.: 81.25%] [G loss: 1.668330]\n",
      "epoch:29 step:27329 [D loss: 0.761868, acc.: 57.03%] [G loss: 1.174062]\n",
      "epoch:29 step:27330 [D loss: 0.633347, acc.: 67.97%] [G loss: 1.356381]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:29 step:27331 [D loss: 0.573923, acc.: 67.97%] [G loss: 1.507185]\n",
      "epoch:29 step:27332 [D loss: 0.442547, acc.: 76.56%] [G loss: 1.497479]\n",
      "epoch:29 step:27333 [D loss: 0.582161, acc.: 71.88%] [G loss: 1.486867]\n",
      "epoch:29 step:27334 [D loss: 0.495521, acc.: 76.56%] [G loss: 1.281420]\n",
      "epoch:29 step:27335 [D loss: 0.611290, acc.: 64.06%] [G loss: 0.984442]\n",
      "epoch:29 step:27336 [D loss: 0.583500, acc.: 70.31%] [G loss: 1.042381]\n",
      "epoch:29 step:27337 [D loss: 0.496734, acc.: 74.22%] [G loss: 1.965449]\n",
      "epoch:29 step:27338 [D loss: 0.518768, acc.: 75.78%] [G loss: 1.567176]\n",
      "epoch:29 step:27339 [D loss: 0.660294, acc.: 62.50%] [G loss: 1.205777]\n",
      "epoch:29 step:27340 [D loss: 0.600910, acc.: 67.97%] [G loss: 1.435848]\n",
      "epoch:29 step:27341 [D loss: 0.548764, acc.: 71.88%] [G loss: 1.344813]\n",
      "epoch:29 step:27342 [D loss: 0.494950, acc.: 75.78%] [G loss: 1.439457]\n",
      "epoch:29 step:27343 [D loss: 0.520766, acc.: 75.78%] [G loss: 1.453225]\n",
      "epoch:29 step:27344 [D loss: 0.628839, acc.: 66.41%] [G loss: 1.056902]\n",
      "epoch:29 step:27345 [D loss: 0.582781, acc.: 67.19%] [G loss: 1.275833]\n",
      "epoch:29 step:27346 [D loss: 0.484749, acc.: 73.44%] [G loss: 1.675687]\n",
      "epoch:29 step:27347 [D loss: 0.461110, acc.: 80.47%] [G loss: 1.997224]\n",
      "epoch:29 step:27348 [D loss: 0.648662, acc.: 63.28%] [G loss: 1.102478]\n",
      "epoch:29 step:27349 [D loss: 0.495252, acc.: 75.00%] [G loss: 1.101350]\n",
      "epoch:29 step:27350 [D loss: 0.625416, acc.: 66.41%] [G loss: 1.296434]\n",
      "epoch:29 step:27351 [D loss: 0.464703, acc.: 79.69%] [G loss: 1.859443]\n",
      "epoch:29 step:27352 [D loss: 0.365305, acc.: 82.03%] [G loss: 1.634697]\n",
      "epoch:29 step:27353 [D loss: 0.436668, acc.: 76.56%] [G loss: 1.809827]\n",
      "epoch:29 step:27354 [D loss: 0.532307, acc.: 78.12%] [G loss: 1.586765]\n",
      "epoch:29 step:27355 [D loss: 0.508990, acc.: 75.78%] [G loss: 1.802397]\n",
      "epoch:29 step:27356 [D loss: 0.512248, acc.: 73.44%] [G loss: 1.642070]\n",
      "epoch:29 step:27357 [D loss: 0.725540, acc.: 59.38%] [G loss: 1.047687]\n",
      "epoch:29 step:27358 [D loss: 0.405816, acc.: 81.25%] [G loss: 1.621206]\n",
      "epoch:29 step:27359 [D loss: 0.491328, acc.: 75.78%] [G loss: 1.447474]\n",
      "epoch:29 step:27360 [D loss: 0.495633, acc.: 78.91%] [G loss: 1.284104]\n",
      "epoch:29 step:27361 [D loss: 0.507329, acc.: 75.00%] [G loss: 1.369827]\n",
      "epoch:29 step:27362 [D loss: 0.555216, acc.: 74.22%] [G loss: 1.064996]\n",
      "epoch:29 step:27363 [D loss: 0.706364, acc.: 59.38%] [G loss: 1.359663]\n",
      "epoch:29 step:27364 [D loss: 0.539561, acc.: 78.12%] [G loss: 1.655944]\n",
      "epoch:29 step:27365 [D loss: 0.564619, acc.: 73.44%] [G loss: 1.521271]\n",
      "epoch:29 step:27366 [D loss: 0.357107, acc.: 85.16%] [G loss: 1.789707]\n",
      "epoch:29 step:27367 [D loss: 0.853894, acc.: 47.66%] [G loss: 1.416108]\n",
      "epoch:29 step:27368 [D loss: 0.532984, acc.: 73.44%] [G loss: 1.692058]\n",
      "epoch:29 step:27369 [D loss: 0.554083, acc.: 71.09%] [G loss: 1.364950]\n",
      "epoch:29 step:27370 [D loss: 0.711175, acc.: 60.16%] [G loss: 1.474911]\n",
      "epoch:29 step:27371 [D loss: 0.567165, acc.: 71.09%] [G loss: 1.355343]\n",
      "epoch:29 step:27372 [D loss: 0.528199, acc.: 71.88%] [G loss: 1.585778]\n",
      "epoch:29 step:27373 [D loss: 0.518570, acc.: 74.22%] [G loss: 1.105733]\n",
      "epoch:29 step:27374 [D loss: 0.535803, acc.: 75.78%] [G loss: 1.681293]\n",
      "epoch:29 step:27375 [D loss: 0.568772, acc.: 75.00%] [G loss: 1.403035]\n",
      "epoch:29 step:27376 [D loss: 0.400592, acc.: 84.38%] [G loss: 1.903822]\n",
      "epoch:29 step:27377 [D loss: 0.306272, acc.: 92.19%] [G loss: 1.548738]\n",
      "epoch:29 step:27378 [D loss: 0.531981, acc.: 70.31%] [G loss: 1.495517]\n",
      "epoch:29 step:27379 [D loss: 0.498780, acc.: 72.66%] [G loss: 1.348990]\n",
      "epoch:29 step:27380 [D loss: 0.449839, acc.: 81.25%] [G loss: 1.478231]\n",
      "epoch:29 step:27381 [D loss: 0.405154, acc.: 83.59%] [G loss: 1.470411]\n",
      "epoch:29 step:27382 [D loss: 0.555554, acc.: 74.22%] [G loss: 1.728376]\n",
      "epoch:29 step:27383 [D loss: 0.437713, acc.: 80.47%] [G loss: 1.669147]\n",
      "epoch:29 step:27384 [D loss: 0.632864, acc.: 68.75%] [G loss: 1.647503]\n",
      "epoch:29 step:27385 [D loss: 0.470392, acc.: 76.56%] [G loss: 1.733669]\n",
      "epoch:29 step:27386 [D loss: 0.735291, acc.: 60.16%] [G loss: 1.404464]\n",
      "epoch:29 step:27387 [D loss: 0.579374, acc.: 72.66%] [G loss: 1.787796]\n",
      "epoch:29 step:27388 [D loss: 0.592966, acc.: 67.97%] [G loss: 1.591722]\n",
      "epoch:29 step:27389 [D loss: 0.721028, acc.: 58.59%] [G loss: 0.886493]\n",
      "epoch:29 step:27390 [D loss: 0.535319, acc.: 71.09%] [G loss: 1.073300]\n",
      "epoch:29 step:27391 [D loss: 0.494379, acc.: 78.12%] [G loss: 1.304797]\n",
      "epoch:29 step:27392 [D loss: 0.576985, acc.: 67.97%] [G loss: 1.585535]\n",
      "epoch:29 step:27393 [D loss: 0.573605, acc.: 67.19%] [G loss: 1.872267]\n",
      "epoch:29 step:27394 [D loss: 0.698737, acc.: 64.06%] [G loss: 1.482451]\n",
      "epoch:29 step:27395 [D loss: 0.519550, acc.: 79.69%] [G loss: 1.206611]\n",
      "epoch:29 step:27396 [D loss: 0.545363, acc.: 72.66%] [G loss: 1.369981]\n",
      "epoch:29 step:27397 [D loss: 0.584854, acc.: 74.22%] [G loss: 1.181555]\n",
      "epoch:29 step:27398 [D loss: 0.808717, acc.: 53.12%] [G loss: 1.285722]\n",
      "epoch:29 step:27399 [D loss: 0.606340, acc.: 65.62%] [G loss: 1.255159]\n",
      "epoch:29 step:27400 [D loss: 0.533950, acc.: 71.88%] [G loss: 1.484475]\n",
      "epoch:29 step:27401 [D loss: 0.643124, acc.: 67.19%] [G loss: 1.516600]\n",
      "epoch:29 step:27402 [D loss: 0.548142, acc.: 70.31%] [G loss: 1.545567]\n",
      "epoch:29 step:27403 [D loss: 0.495474, acc.: 73.44%] [G loss: 1.457746]\n",
      "epoch:29 step:27404 [D loss: 0.532052, acc.: 72.66%] [G loss: 1.599684]\n",
      "epoch:29 step:27405 [D loss: 0.636334, acc.: 62.50%] [G loss: 1.662090]\n",
      "epoch:29 step:27406 [D loss: 0.697834, acc.: 64.84%] [G loss: 1.430289]\n",
      "epoch:29 step:27407 [D loss: 0.588288, acc.: 71.09%] [G loss: 1.342515]\n",
      "epoch:29 step:27408 [D loss: 0.702055, acc.: 65.62%] [G loss: 1.146805]\n",
      "epoch:29 step:27409 [D loss: 0.426567, acc.: 85.16%] [G loss: 0.941572]\n",
      "epoch:29 step:27410 [D loss: 0.627571, acc.: 66.41%] [G loss: 1.084293]\n",
      "epoch:29 step:27411 [D loss: 0.663044, acc.: 62.50%] [G loss: 1.058149]\n",
      "epoch:29 step:27412 [D loss: 0.645684, acc.: 63.28%] [G loss: 1.565037]\n",
      "epoch:29 step:27413 [D loss: 0.495848, acc.: 75.78%] [G loss: 1.500783]\n",
      "epoch:29 step:27414 [D loss: 0.624549, acc.: 64.84%] [G loss: 1.674175]\n",
      "epoch:29 step:27415 [D loss: 0.906684, acc.: 43.75%] [G loss: 1.195540]\n",
      "epoch:29 step:27416 [D loss: 0.642791, acc.: 57.81%] [G loss: 1.136136]\n",
      "epoch:29 step:27417 [D loss: 0.520649, acc.: 72.66%] [G loss: 1.642820]\n",
      "epoch:29 step:27418 [D loss: 0.454031, acc.: 80.47%] [G loss: 1.587211]\n",
      "epoch:29 step:27419 [D loss: 0.576401, acc.: 67.19%] [G loss: 1.036700]\n",
      "epoch:29 step:27420 [D loss: 0.600345, acc.: 68.75%] [G loss: 1.341611]\n",
      "epoch:29 step:27421 [D loss: 0.524739, acc.: 75.78%] [G loss: 1.638022]\n",
      "epoch:29 step:27422 [D loss: 0.600769, acc.: 69.53%] [G loss: 1.451418]\n",
      "epoch:29 step:27423 [D loss: 0.602622, acc.: 67.97%] [G loss: 1.102869]\n",
      "epoch:29 step:27424 [D loss: 0.594138, acc.: 68.75%] [G loss: 1.463704]\n",
      "epoch:29 step:27425 [D loss: 0.412774, acc.: 83.59%] [G loss: 1.371689]\n",
      "epoch:29 step:27426 [D loss: 0.626012, acc.: 70.31%] [G loss: 1.427968]\n",
      "epoch:29 step:27427 [D loss: 0.466055, acc.: 79.69%] [G loss: 1.866812]\n",
      "epoch:29 step:27428 [D loss: 0.550390, acc.: 67.19%] [G loss: 1.344113]\n",
      "epoch:29 step:27429 [D loss: 0.453897, acc.: 78.91%] [G loss: 1.897707]\n",
      "epoch:29 step:27430 [D loss: 0.492423, acc.: 78.12%] [G loss: 1.362840]\n",
      "epoch:29 step:27431 [D loss: 0.728634, acc.: 60.16%] [G loss: 1.548956]\n",
      "epoch:29 step:27432 [D loss: 0.705898, acc.: 57.03%] [G loss: 1.714944]\n",
      "epoch:29 step:27433 [D loss: 0.545153, acc.: 72.66%] [G loss: 1.267521]\n",
      "epoch:29 step:27434 [D loss: 0.468035, acc.: 83.59%] [G loss: 1.417346]\n",
      "epoch:29 step:27435 [D loss: 0.678392, acc.: 61.72%] [G loss: 1.542020]\n",
      "epoch:29 step:27436 [D loss: 0.558781, acc.: 68.75%] [G loss: 1.278109]\n",
      "epoch:29 step:27437 [D loss: 0.593873, acc.: 68.75%] [G loss: 1.439948]\n",
      "epoch:29 step:27438 [D loss: 0.505894, acc.: 76.56%] [G loss: 1.601092]\n",
      "epoch:29 step:27439 [D loss: 0.372575, acc.: 88.28%] [G loss: 1.646870]\n",
      "epoch:29 step:27440 [D loss: 0.576830, acc.: 72.66%] [G loss: 1.324896]\n",
      "epoch:29 step:27441 [D loss: 0.576290, acc.: 67.97%] [G loss: 1.368736]\n",
      "epoch:29 step:27442 [D loss: 0.633561, acc.: 67.97%] [G loss: 1.421432]\n",
      "epoch:29 step:27443 [D loss: 0.306716, acc.: 89.84%] [G loss: 1.788960]\n",
      "epoch:29 step:27444 [D loss: 0.648533, acc.: 66.41%] [G loss: 1.325930]\n",
      "epoch:29 step:27445 [D loss: 0.558580, acc.: 76.56%] [G loss: 1.453860]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:29 step:27446 [D loss: 0.644422, acc.: 62.50%] [G loss: 0.980454]\n",
      "epoch:29 step:27447 [D loss: 0.712848, acc.: 58.59%] [G loss: 1.667732]\n",
      "epoch:29 step:27448 [D loss: 0.699289, acc.: 57.03%] [G loss: 2.069222]\n",
      "epoch:29 step:27449 [D loss: 0.855520, acc.: 46.88%] [G loss: 1.189364]\n",
      "epoch:29 step:27450 [D loss: 0.632913, acc.: 66.41%] [G loss: 1.225383]\n",
      "epoch:29 step:27451 [D loss: 0.595858, acc.: 67.19%] [G loss: 1.323633]\n",
      "epoch:29 step:27452 [D loss: 0.434859, acc.: 79.69%] [G loss: 1.520606]\n",
      "epoch:29 step:27453 [D loss: 0.521111, acc.: 71.88%] [G loss: 1.096090]\n",
      "epoch:29 step:27454 [D loss: 0.462753, acc.: 82.03%] [G loss: 1.273724]\n",
      "epoch:29 step:27455 [D loss: 0.617915, acc.: 70.31%] [G loss: 1.257402]\n",
      "epoch:29 step:27456 [D loss: 0.396126, acc.: 85.16%] [G loss: 1.409021]\n",
      "epoch:29 step:27457 [D loss: 0.522453, acc.: 74.22%] [G loss: 1.556693]\n",
      "epoch:29 step:27458 [D loss: 0.393552, acc.: 86.72%] [G loss: 1.849485]\n",
      "epoch:29 step:27459 [D loss: 0.623110, acc.: 64.84%] [G loss: 1.484591]\n",
      "epoch:29 step:27460 [D loss: 0.533041, acc.: 73.44%] [G loss: 1.790418]\n",
      "epoch:29 step:27461 [D loss: 0.728068, acc.: 57.03%] [G loss: 0.902689]\n",
      "epoch:29 step:27462 [D loss: 0.400065, acc.: 84.38%] [G loss: 1.517309]\n",
      "epoch:29 step:27463 [D loss: 0.369838, acc.: 88.28%] [G loss: 1.584539]\n",
      "epoch:29 step:27464 [D loss: 0.399637, acc.: 83.59%] [G loss: 1.525584]\n",
      "epoch:29 step:27465 [D loss: 0.486336, acc.: 78.12%] [G loss: 2.128500]\n",
      "epoch:29 step:27466 [D loss: 0.593289, acc.: 71.09%] [G loss: 1.397815]\n",
      "epoch:29 step:27467 [D loss: 0.576413, acc.: 67.97%] [G loss: 1.664522]\n",
      "epoch:29 step:27468 [D loss: 0.383301, acc.: 89.06%] [G loss: 1.432098]\n",
      "epoch:29 step:27469 [D loss: 0.511767, acc.: 76.56%] [G loss: 1.069332]\n",
      "epoch:29 step:27470 [D loss: 0.501342, acc.: 71.09%] [G loss: 1.318131]\n",
      "epoch:29 step:27471 [D loss: 0.752518, acc.: 57.03%] [G loss: 1.327199]\n",
      "epoch:29 step:27472 [D loss: 0.702704, acc.: 60.94%] [G loss: 1.145304]\n",
      "epoch:29 step:27473 [D loss: 0.595610, acc.: 70.31%] [G loss: 1.200722]\n",
      "epoch:29 step:27474 [D loss: 0.420795, acc.: 85.16%] [G loss: 1.472401]\n",
      "epoch:29 step:27475 [D loss: 0.752946, acc.: 59.38%] [G loss: 1.128231]\n",
      "epoch:29 step:27476 [D loss: 0.548570, acc.: 69.53%] [G loss: 1.277200]\n",
      "epoch:29 step:27477 [D loss: 0.668500, acc.: 62.50%] [G loss: 1.660663]\n",
      "epoch:29 step:27478 [D loss: 0.365592, acc.: 86.72%] [G loss: 1.824238]\n",
      "epoch:29 step:27479 [D loss: 0.431149, acc.: 82.03%] [G loss: 1.293858]\n",
      "epoch:29 step:27480 [D loss: 0.572776, acc.: 69.53%] [G loss: 1.401367]\n",
      "epoch:29 step:27481 [D loss: 0.501522, acc.: 76.56%] [G loss: 1.252735]\n",
      "epoch:29 step:27482 [D loss: 0.506745, acc.: 78.91%] [G loss: 1.545503]\n",
      "epoch:29 step:27483 [D loss: 0.604180, acc.: 67.97%] [G loss: 1.586840]\n",
      "epoch:29 step:27484 [D loss: 0.428454, acc.: 82.03%] [G loss: 1.699940]\n",
      "epoch:29 step:27485 [D loss: 0.731391, acc.: 54.69%] [G loss: 1.505087]\n",
      "epoch:29 step:27486 [D loss: 0.554732, acc.: 70.31%] [G loss: 1.105626]\n",
      "epoch:29 step:27487 [D loss: 0.413198, acc.: 78.12%] [G loss: 1.963200]\n",
      "epoch:29 step:27488 [D loss: 0.561432, acc.: 72.66%] [G loss: 1.071588]\n",
      "epoch:29 step:27489 [D loss: 0.685686, acc.: 62.50%] [G loss: 1.234430]\n",
      "epoch:29 step:27490 [D loss: 0.537904, acc.: 73.44%] [G loss: 1.226702]\n",
      "epoch:29 step:27491 [D loss: 0.543459, acc.: 68.75%] [G loss: 0.855643]\n",
      "epoch:29 step:27492 [D loss: 0.487929, acc.: 74.22%] [G loss: 1.620801]\n",
      "epoch:29 step:27493 [D loss: 0.568241, acc.: 71.09%] [G loss: 1.372592]\n",
      "epoch:29 step:27494 [D loss: 0.630506, acc.: 63.28%] [G loss: 1.675783]\n",
      "epoch:29 step:27495 [D loss: 0.568593, acc.: 67.97%] [G loss: 1.730153]\n",
      "epoch:29 step:27496 [D loss: 0.543567, acc.: 72.66%] [G loss: 1.607287]\n",
      "epoch:29 step:27497 [D loss: 0.502876, acc.: 73.44%] [G loss: 1.568576]\n",
      "epoch:29 step:27498 [D loss: 0.684335, acc.: 60.94%] [G loss: 1.286952]\n",
      "epoch:29 step:27499 [D loss: 0.680824, acc.: 64.06%] [G loss: 1.511200]\n",
      "epoch:29 step:27500 [D loss: 0.392051, acc.: 87.50%] [G loss: 1.203122]\n",
      "epoch:29 step:27501 [D loss: 0.423757, acc.: 82.81%] [G loss: 1.706800]\n",
      "epoch:29 step:27502 [D loss: 0.581693, acc.: 65.62%] [G loss: 1.348937]\n",
      "epoch:29 step:27503 [D loss: 0.387924, acc.: 85.94%] [G loss: 1.729524]\n",
      "epoch:29 step:27504 [D loss: 0.444481, acc.: 78.91%] [G loss: 1.553527]\n",
      "epoch:29 step:27505 [D loss: 0.696355, acc.: 60.16%] [G loss: 1.020946]\n",
      "epoch:29 step:27506 [D loss: 0.679449, acc.: 61.72%] [G loss: 1.394949]\n",
      "epoch:29 step:27507 [D loss: 0.677972, acc.: 62.50%] [G loss: 1.295436]\n",
      "epoch:29 step:27508 [D loss: 0.424093, acc.: 82.03%] [G loss: 1.706456]\n",
      "epoch:29 step:27509 [D loss: 0.381716, acc.: 85.94%] [G loss: 1.036621]\n",
      "epoch:29 step:27510 [D loss: 0.580673, acc.: 67.97%] [G loss: 1.411841]\n",
      "epoch:29 step:27511 [D loss: 0.405019, acc.: 84.38%] [G loss: 1.799943]\n",
      "epoch:29 step:27512 [D loss: 0.461121, acc.: 82.81%] [G loss: 1.308966]\n",
      "epoch:29 step:27513 [D loss: 0.529445, acc.: 75.00%] [G loss: 1.369986]\n",
      "epoch:29 step:27514 [D loss: 0.850957, acc.: 45.31%] [G loss: 1.264251]\n",
      "epoch:29 step:27515 [D loss: 0.484982, acc.: 79.69%] [G loss: 2.204950]\n",
      "epoch:29 step:27516 [D loss: 0.416631, acc.: 85.94%] [G loss: 1.263728]\n",
      "epoch:29 step:27517 [D loss: 0.543930, acc.: 71.09%] [G loss: 1.337729]\n",
      "epoch:29 step:27518 [D loss: 0.564783, acc.: 72.66%] [G loss: 1.449303]\n",
      "epoch:29 step:27519 [D loss: 0.494064, acc.: 78.91%] [G loss: 1.615225]\n",
      "epoch:29 step:27520 [D loss: 0.730772, acc.: 55.47%] [G loss: 1.493543]\n",
      "epoch:29 step:27521 [D loss: 0.478538, acc.: 78.91%] [G loss: 1.140685]\n",
      "epoch:29 step:27522 [D loss: 0.486887, acc.: 78.91%] [G loss: 1.375297]\n",
      "epoch:29 step:27523 [D loss: 0.426028, acc.: 82.81%] [G loss: 1.335515]\n",
      "epoch:29 step:27524 [D loss: 0.673936, acc.: 62.50%] [G loss: 1.006683]\n",
      "epoch:29 step:27525 [D loss: 0.775003, acc.: 53.12%] [G loss: 1.124755]\n",
      "epoch:29 step:27526 [D loss: 0.541927, acc.: 67.97%] [G loss: 1.365524]\n",
      "epoch:29 step:27527 [D loss: 0.450428, acc.: 84.38%] [G loss: 1.662434]\n",
      "epoch:29 step:27528 [D loss: 0.547555, acc.: 72.66%] [G loss: 1.427395]\n",
      "epoch:29 step:27529 [D loss: 0.476478, acc.: 81.25%] [G loss: 1.459440]\n",
      "epoch:29 step:27530 [D loss: 0.486387, acc.: 75.78%] [G loss: 1.653742]\n",
      "epoch:29 step:27531 [D loss: 0.729840, acc.: 54.69%] [G loss: 1.407516]\n",
      "epoch:29 step:27532 [D loss: 0.574695, acc.: 71.09%] [G loss: 1.686276]\n",
      "epoch:29 step:27533 [D loss: 0.666652, acc.: 61.72%] [G loss: 0.721383]\n",
      "epoch:29 step:27534 [D loss: 0.357818, acc.: 89.06%] [G loss: 1.389366]\n",
      "epoch:29 step:27535 [D loss: 0.659470, acc.: 63.28%] [G loss: 1.190443]\n",
      "epoch:29 step:27536 [D loss: 0.551349, acc.: 69.53%] [G loss: 1.083113]\n",
      "epoch:29 step:27537 [D loss: 0.455006, acc.: 79.69%] [G loss: 1.502042]\n",
      "epoch:29 step:27538 [D loss: 0.428963, acc.: 81.25%] [G loss: 1.381740]\n",
      "epoch:29 step:27539 [D loss: 0.442587, acc.: 82.03%] [G loss: 1.727470]\n",
      "epoch:29 step:27540 [D loss: 0.644704, acc.: 61.72%] [G loss: 1.331669]\n",
      "epoch:29 step:27541 [D loss: 0.311571, acc.: 89.84%] [G loss: 2.114550]\n",
      "epoch:29 step:27542 [D loss: 0.541280, acc.: 71.09%] [G loss: 1.415701]\n",
      "epoch:29 step:27543 [D loss: 0.467041, acc.: 80.47%] [G loss: 1.422933]\n",
      "epoch:29 step:27544 [D loss: 0.397692, acc.: 82.81%] [G loss: 1.527082]\n",
      "epoch:29 step:27545 [D loss: 0.507648, acc.: 75.78%] [G loss: 1.285574]\n",
      "epoch:29 step:27546 [D loss: 0.494079, acc.: 74.22%] [G loss: 1.037645]\n",
      "epoch:29 step:27547 [D loss: 0.602577, acc.: 64.84%] [G loss: 1.506409]\n",
      "epoch:29 step:27548 [D loss: 0.505434, acc.: 75.78%] [G loss: 1.161106]\n",
      "epoch:29 step:27549 [D loss: 0.746623, acc.: 50.78%] [G loss: 0.891534]\n",
      "epoch:29 step:27550 [D loss: 0.448594, acc.: 82.03%] [G loss: 1.316029]\n",
      "epoch:29 step:27551 [D loss: 0.614416, acc.: 68.75%] [G loss: 1.425061]\n",
      "epoch:29 step:27552 [D loss: 0.682174, acc.: 59.38%] [G loss: 1.621613]\n",
      "epoch:29 step:27553 [D loss: 0.361445, acc.: 89.84%] [G loss: 1.740985]\n",
      "epoch:29 step:27554 [D loss: 0.536036, acc.: 75.00%] [G loss: 1.382773]\n",
      "epoch:29 step:27555 [D loss: 0.560908, acc.: 71.88%] [G loss: 1.337080]\n",
      "epoch:29 step:27556 [D loss: 0.404260, acc.: 85.94%] [G loss: 1.251420]\n",
      "epoch:29 step:27557 [D loss: 0.537672, acc.: 75.00%] [G loss: 1.493311]\n",
      "epoch:29 step:27558 [D loss: 0.554928, acc.: 69.53%] [G loss: 1.408484]\n",
      "epoch:29 step:27559 [D loss: 0.596751, acc.: 71.88%] [G loss: 1.276399]\n",
      "epoch:29 step:27560 [D loss: 0.493200, acc.: 76.56%] [G loss: 1.400366]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:29 step:27561 [D loss: 0.732075, acc.: 59.38%] [G loss: 1.361914]\n",
      "epoch:29 step:27562 [D loss: 0.524931, acc.: 76.56%] [G loss: 1.575802]\n",
      "epoch:29 step:27563 [D loss: 0.432029, acc.: 80.47%] [G loss: 1.396988]\n",
      "epoch:29 step:27564 [D loss: 0.486407, acc.: 75.78%] [G loss: 1.575447]\n",
      "epoch:29 step:27565 [D loss: 0.501510, acc.: 74.22%] [G loss: 1.423785]\n",
      "epoch:29 step:27566 [D loss: 0.662964, acc.: 64.84%] [G loss: 0.987452]\n",
      "epoch:29 step:27567 [D loss: 0.646016, acc.: 62.50%] [G loss: 0.942094]\n",
      "epoch:29 step:27568 [D loss: 0.478598, acc.: 83.59%] [G loss: 1.383141]\n",
      "epoch:29 step:27569 [D loss: 0.433919, acc.: 81.25%] [G loss: 1.443733]\n",
      "epoch:29 step:27570 [D loss: 0.606696, acc.: 70.31%] [G loss: 1.488301]\n",
      "epoch:29 step:27571 [D loss: 0.634761, acc.: 62.50%] [G loss: 1.312299]\n",
      "epoch:29 step:27572 [D loss: 0.377743, acc.: 84.38%] [G loss: 1.636496]\n",
      "epoch:29 step:27573 [D loss: 0.533583, acc.: 75.00%] [G loss: 1.181053]\n",
      "epoch:29 step:27574 [D loss: 0.522516, acc.: 70.31%] [G loss: 1.316803]\n",
      "epoch:29 step:27575 [D loss: 0.576118, acc.: 66.41%] [G loss: 1.765232]\n",
      "epoch:29 step:27576 [D loss: 0.532911, acc.: 75.78%] [G loss: 1.738447]\n",
      "epoch:29 step:27577 [D loss: 0.592643, acc.: 72.66%] [G loss: 1.317095]\n",
      "epoch:29 step:27578 [D loss: 0.575426, acc.: 68.75%] [G loss: 1.445325]\n",
      "epoch:29 step:27579 [D loss: 0.623718, acc.: 60.94%] [G loss: 1.320249]\n",
      "epoch:29 step:27580 [D loss: 0.488651, acc.: 76.56%] [G loss: 1.601292]\n",
      "epoch:29 step:27581 [D loss: 0.534063, acc.: 71.88%] [G loss: 1.484555]\n",
      "epoch:29 step:27582 [D loss: 0.578963, acc.: 70.31%] [G loss: 1.673854]\n",
      "epoch:29 step:27583 [D loss: 0.600072, acc.: 65.62%] [G loss: 1.192052]\n",
      "epoch:29 step:27584 [D loss: 0.588503, acc.: 70.31%] [G loss: 1.272243]\n",
      "epoch:29 step:27585 [D loss: 0.573682, acc.: 71.09%] [G loss: 1.322512]\n",
      "epoch:29 step:27586 [D loss: 0.721444, acc.: 55.47%] [G loss: 1.300915]\n",
      "epoch:29 step:27587 [D loss: 0.602287, acc.: 66.41%] [G loss: 1.494341]\n",
      "epoch:29 step:27588 [D loss: 0.483898, acc.: 76.56%] [G loss: 1.326989]\n",
      "epoch:29 step:27589 [D loss: 0.574089, acc.: 69.53%] [G loss: 1.403470]\n",
      "epoch:29 step:27590 [D loss: 0.531756, acc.: 71.09%] [G loss: 2.083486]\n",
      "epoch:29 step:27591 [D loss: 0.689720, acc.: 60.94%] [G loss: 1.447160]\n",
      "epoch:29 step:27592 [D loss: 0.548713, acc.: 69.53%] [G loss: 1.315902]\n",
      "epoch:29 step:27593 [D loss: 0.326915, acc.: 90.62%] [G loss: 1.573017]\n",
      "epoch:29 step:27594 [D loss: 0.564646, acc.: 66.41%] [G loss: 1.054122]\n",
      "epoch:29 step:27595 [D loss: 0.547675, acc.: 72.66%] [G loss: 1.322978]\n",
      "epoch:29 step:27596 [D loss: 0.451128, acc.: 82.81%] [G loss: 1.540538]\n",
      "epoch:29 step:27597 [D loss: 0.553109, acc.: 71.09%] [G loss: 1.383885]\n",
      "epoch:29 step:27598 [D loss: 0.631356, acc.: 66.41%] [G loss: 0.931475]\n",
      "epoch:29 step:27599 [D loss: 0.615298, acc.: 64.84%] [G loss: 1.363276]\n",
      "epoch:29 step:27600 [D loss: 0.519369, acc.: 76.56%] [G loss: 1.235897]\n",
      "epoch:29 step:27601 [D loss: 0.622194, acc.: 68.75%] [G loss: 1.495869]\n",
      "epoch:29 step:27602 [D loss: 0.698704, acc.: 61.72%] [G loss: 1.249887]\n",
      "epoch:29 step:27603 [D loss: 0.530543, acc.: 75.00%] [G loss: 1.404160]\n",
      "epoch:29 step:27604 [D loss: 0.351623, acc.: 85.94%] [G loss: 1.431947]\n",
      "epoch:29 step:27605 [D loss: 0.613549, acc.: 65.62%] [G loss: 1.477489]\n",
      "epoch:29 step:27606 [D loss: 0.624310, acc.: 64.06%] [G loss: 1.521675]\n",
      "epoch:29 step:27607 [D loss: 0.649378, acc.: 67.19%] [G loss: 1.409965]\n",
      "epoch:29 step:27608 [D loss: 0.464514, acc.: 79.69%] [G loss: 1.715958]\n",
      "epoch:29 step:27609 [D loss: 0.493229, acc.: 76.56%] [G loss: 1.426817]\n",
      "epoch:29 step:27610 [D loss: 0.617337, acc.: 66.41%] [G loss: 1.397748]\n",
      "epoch:29 step:27611 [D loss: 0.495819, acc.: 73.44%] [G loss: 1.549087]\n",
      "epoch:29 step:27612 [D loss: 0.570941, acc.: 74.22%] [G loss: 1.011044]\n",
      "epoch:29 step:27613 [D loss: 0.426357, acc.: 82.03%] [G loss: 1.856454]\n",
      "epoch:29 step:27614 [D loss: 0.433772, acc.: 84.38%] [G loss: 1.330217]\n",
      "epoch:29 step:27615 [D loss: 0.785544, acc.: 55.47%] [G loss: 1.552903]\n",
      "epoch:29 step:27616 [D loss: 0.489625, acc.: 76.56%] [G loss: 1.702271]\n",
      "epoch:29 step:27617 [D loss: 0.492519, acc.: 78.12%] [G loss: 1.355809]\n",
      "epoch:29 step:27618 [D loss: 0.362318, acc.: 87.50%] [G loss: 1.463962]\n",
      "epoch:29 step:27619 [D loss: 0.623591, acc.: 67.97%] [G loss: 1.576046]\n",
      "epoch:29 step:27620 [D loss: 0.596345, acc.: 67.97%] [G loss: 1.675179]\n",
      "epoch:29 step:27621 [D loss: 0.585986, acc.: 74.22%] [G loss: 1.545635]\n",
      "epoch:29 step:27622 [D loss: 0.498351, acc.: 77.34%] [G loss: 1.433024]\n",
      "epoch:29 step:27623 [D loss: 0.455154, acc.: 80.47%] [G loss: 1.247434]\n",
      "epoch:29 step:27624 [D loss: 0.500785, acc.: 75.00%] [G loss: 1.188842]\n",
      "epoch:29 step:27625 [D loss: 0.595366, acc.: 71.88%] [G loss: 1.586818]\n",
      "epoch:29 step:27626 [D loss: 0.405957, acc.: 83.59%] [G loss: 1.313084]\n",
      "epoch:29 step:27627 [D loss: 0.460129, acc.: 79.69%] [G loss: 1.302018]\n",
      "epoch:29 step:27628 [D loss: 0.576707, acc.: 71.09%] [G loss: 0.954433]\n",
      "epoch:29 step:27629 [D loss: 0.713033, acc.: 60.16%] [G loss: 1.357323]\n",
      "epoch:29 step:27630 [D loss: 0.643928, acc.: 63.28%] [G loss: 1.307470]\n",
      "epoch:29 step:27631 [D loss: 0.328235, acc.: 90.62%] [G loss: 1.645071]\n",
      "epoch:29 step:27632 [D loss: 0.550641, acc.: 74.22%] [G loss: 1.745609]\n",
      "epoch:29 step:27633 [D loss: 0.574121, acc.: 67.97%] [G loss: 1.583328]\n",
      "epoch:29 step:27634 [D loss: 0.546945, acc.: 72.66%] [G loss: 1.394417]\n",
      "epoch:29 step:27635 [D loss: 0.422151, acc.: 82.81%] [G loss: 1.026087]\n",
      "epoch:29 step:27636 [D loss: 0.614033, acc.: 70.31%] [G loss: 1.452742]\n",
      "epoch:29 step:27637 [D loss: 0.590557, acc.: 65.62%] [G loss: 1.780601]\n",
      "epoch:29 step:27638 [D loss: 0.427108, acc.: 79.69%] [G loss: 1.389510]\n",
      "epoch:29 step:27639 [D loss: 0.495465, acc.: 77.34%] [G loss: 1.298791]\n",
      "epoch:29 step:27640 [D loss: 0.368982, acc.: 88.28%] [G loss: 1.355761]\n",
      "epoch:29 step:27641 [D loss: 0.569975, acc.: 67.19%] [G loss: 1.550237]\n",
      "epoch:29 step:27642 [D loss: 0.430445, acc.: 83.59%] [G loss: 1.895308]\n",
      "epoch:29 step:27643 [D loss: 0.904997, acc.: 43.75%] [G loss: 1.520568]\n",
      "epoch:29 step:27644 [D loss: 0.667485, acc.: 58.59%] [G loss: 1.077596]\n",
      "epoch:29 step:27645 [D loss: 0.546118, acc.: 68.75%] [G loss: 1.219981]\n",
      "epoch:29 step:27646 [D loss: 0.437118, acc.: 78.91%] [G loss: 1.553340]\n",
      "epoch:29 step:27647 [D loss: 0.446068, acc.: 81.25%] [G loss: 1.911973]\n",
      "epoch:29 step:27648 [D loss: 0.476574, acc.: 76.56%] [G loss: 1.330719]\n",
      "epoch:29 step:27649 [D loss: 0.334650, acc.: 89.84%] [G loss: 1.525527]\n",
      "epoch:29 step:27650 [D loss: 0.408616, acc.: 85.16%] [G loss: 1.524847]\n",
      "epoch:29 step:27651 [D loss: 0.712266, acc.: 53.91%] [G loss: 1.077648]\n",
      "epoch:29 step:27652 [D loss: 0.616421, acc.: 71.09%] [G loss: 1.244027]\n",
      "epoch:29 step:27653 [D loss: 0.550568, acc.: 74.22%] [G loss: 1.505417]\n",
      "epoch:29 step:27654 [D loss: 0.609074, acc.: 64.06%] [G loss: 1.693326]\n",
      "epoch:29 step:27655 [D loss: 0.451209, acc.: 78.91%] [G loss: 1.407144]\n",
      "epoch:29 step:27656 [D loss: 0.953873, acc.: 41.41%] [G loss: 1.368332]\n",
      "epoch:29 step:27657 [D loss: 0.435379, acc.: 82.03%] [G loss: 1.403664]\n",
      "epoch:29 step:27658 [D loss: 0.527948, acc.: 72.66%] [G loss: 1.662093]\n",
      "epoch:29 step:27659 [D loss: 0.449261, acc.: 77.34%] [G loss: 1.599018]\n",
      "epoch:29 step:27660 [D loss: 0.408584, acc.: 84.38%] [G loss: 1.621801]\n",
      "epoch:29 step:27661 [D loss: 0.430363, acc.: 82.03%] [G loss: 1.314510]\n",
      "epoch:29 step:27662 [D loss: 0.626512, acc.: 67.19%] [G loss: 1.235078]\n",
      "epoch:29 step:27663 [D loss: 0.408463, acc.: 82.03%] [G loss: 1.724773]\n",
      "epoch:29 step:27664 [D loss: 0.443766, acc.: 78.91%] [G loss: 1.279716]\n",
      "epoch:29 step:27665 [D loss: 0.603688, acc.: 71.09%] [G loss: 1.217112]\n",
      "epoch:29 step:27666 [D loss: 0.546442, acc.: 75.00%] [G loss: 1.860476]\n",
      "epoch:29 step:27667 [D loss: 0.399277, acc.: 84.38%] [G loss: 1.387680]\n",
      "epoch:29 step:27668 [D loss: 0.598041, acc.: 67.97%] [G loss: 1.273819]\n",
      "epoch:29 step:27669 [D loss: 0.581528, acc.: 65.62%] [G loss: 1.970319]\n",
      "epoch:29 step:27670 [D loss: 0.532416, acc.: 71.88%] [G loss: 1.606313]\n",
      "epoch:29 step:27671 [D loss: 0.572702, acc.: 68.75%] [G loss: 1.076223]\n",
      "epoch:29 step:27672 [D loss: 0.524504, acc.: 75.00%] [G loss: 1.590169]\n",
      "epoch:29 step:27673 [D loss: 0.490485, acc.: 73.44%] [G loss: 1.512380]\n",
      "epoch:29 step:27674 [D loss: 0.505531, acc.: 78.91%] [G loss: 1.702440]\n",
      "epoch:29 step:27675 [D loss: 0.662760, acc.: 58.59%] [G loss: 1.247861]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:29 step:27676 [D loss: 0.376160, acc.: 86.72%] [G loss: 2.304799]\n",
      "epoch:29 step:27677 [D loss: 0.783704, acc.: 47.66%] [G loss: 1.825119]\n",
      "epoch:29 step:27678 [D loss: 0.535282, acc.: 73.44%] [G loss: 1.967943]\n",
      "epoch:29 step:27679 [D loss: 0.403936, acc.: 84.38%] [G loss: 1.594113]\n",
      "epoch:29 step:27680 [D loss: 0.597876, acc.: 66.41%] [G loss: 1.693205]\n",
      "epoch:29 step:27681 [D loss: 0.671092, acc.: 62.50%] [G loss: 1.408925]\n",
      "epoch:29 step:27682 [D loss: 0.519039, acc.: 75.78%] [G loss: 1.175775]\n",
      "epoch:29 step:27683 [D loss: 0.365946, acc.: 82.81%] [G loss: 1.655351]\n",
      "epoch:29 step:27684 [D loss: 0.634178, acc.: 65.62%] [G loss: 1.544724]\n",
      "epoch:29 step:27685 [D loss: 0.590743, acc.: 72.66%] [G loss: 1.475263]\n",
      "epoch:29 step:27686 [D loss: 0.583703, acc.: 66.41%] [G loss: 1.343887]\n",
      "epoch:29 step:27687 [D loss: 0.550088, acc.: 70.31%] [G loss: 1.694357]\n",
      "epoch:29 step:27688 [D loss: 0.384917, acc.: 86.72%] [G loss: 1.823087]\n",
      "epoch:29 step:27689 [D loss: 0.504983, acc.: 77.34%] [G loss: 1.613551]\n",
      "epoch:29 step:27690 [D loss: 0.562622, acc.: 71.88%] [G loss: 1.127279]\n",
      "epoch:29 step:27691 [D loss: 0.504624, acc.: 71.88%] [G loss: 1.322768]\n",
      "epoch:29 step:27692 [D loss: 0.431185, acc.: 85.94%] [G loss: 1.635239]\n",
      "epoch:29 step:27693 [D loss: 0.685625, acc.: 60.16%] [G loss: 1.738655]\n",
      "epoch:29 step:27694 [D loss: 0.480984, acc.: 75.78%] [G loss: 1.696424]\n",
      "epoch:29 step:27695 [D loss: 0.504298, acc.: 69.53%] [G loss: 1.339456]\n",
      "epoch:29 step:27696 [D loss: 0.601686, acc.: 65.62%] [G loss: 1.062801]\n",
      "epoch:29 step:27697 [D loss: 0.487958, acc.: 77.34%] [G loss: 1.277846]\n",
      "epoch:29 step:27698 [D loss: 0.722721, acc.: 63.28%] [G loss: 1.259934]\n",
      "epoch:29 step:27699 [D loss: 0.452621, acc.: 77.34%] [G loss: 1.327873]\n",
      "epoch:29 step:27700 [D loss: 0.464665, acc.: 78.91%] [G loss: 1.747955]\n",
      "epoch:29 step:27701 [D loss: 0.510765, acc.: 79.69%] [G loss: 1.529514]\n",
      "epoch:29 step:27702 [D loss: 0.360225, acc.: 89.84%] [G loss: 2.061067]\n",
      "epoch:29 step:27703 [D loss: 0.644672, acc.: 61.72%] [G loss: 1.407074]\n",
      "epoch:29 step:27704 [D loss: 0.500967, acc.: 79.69%] [G loss: 1.191830]\n",
      "epoch:29 step:27705 [D loss: 0.609470, acc.: 66.41%] [G loss: 1.487114]\n",
      "epoch:29 step:27706 [D loss: 0.686221, acc.: 62.50%] [G loss: 1.243222]\n",
      "epoch:29 step:27707 [D loss: 0.787926, acc.: 48.44%] [G loss: 1.248581]\n",
      "epoch:29 step:27708 [D loss: 0.406031, acc.: 86.72%] [G loss: 1.949302]\n",
      "epoch:29 step:27709 [D loss: 0.596762, acc.: 70.31%] [G loss: 1.368713]\n",
      "epoch:29 step:27710 [D loss: 0.576199, acc.: 70.31%] [G loss: 1.552622]\n",
      "epoch:29 step:27711 [D loss: 0.745997, acc.: 57.81%] [G loss: 1.120528]\n",
      "epoch:29 step:27712 [D loss: 0.443609, acc.: 81.25%] [G loss: 1.570399]\n",
      "epoch:29 step:27713 [D loss: 0.713800, acc.: 55.47%] [G loss: 1.476460]\n",
      "epoch:29 step:27714 [D loss: 0.462006, acc.: 81.25%] [G loss: 1.449866]\n",
      "epoch:29 step:27715 [D loss: 0.513922, acc.: 78.12%] [G loss: 1.535837]\n",
      "epoch:29 step:27716 [D loss: 0.411157, acc.: 84.38%] [G loss: 1.432805]\n",
      "epoch:29 step:27717 [D loss: 0.519329, acc.: 79.69%] [G loss: 1.307040]\n",
      "epoch:29 step:27718 [D loss: 0.430783, acc.: 80.47%] [G loss: 1.773533]\n",
      "epoch:29 step:27719 [D loss: 0.467824, acc.: 75.00%] [G loss: 1.507361]\n",
      "epoch:29 step:27720 [D loss: 0.389609, acc.: 85.16%] [G loss: 1.730340]\n",
      "epoch:29 step:27721 [D loss: 0.565588, acc.: 71.88%] [G loss: 1.292239]\n",
      "epoch:29 step:27722 [D loss: 0.438780, acc.: 79.69%] [G loss: 1.595567]\n",
      "epoch:29 step:27723 [D loss: 0.356314, acc.: 89.06%] [G loss: 2.157272]\n",
      "epoch:29 step:27724 [D loss: 0.483085, acc.: 75.00%] [G loss: 1.463965]\n",
      "epoch:29 step:27725 [D loss: 0.468543, acc.: 79.69%] [G loss: 1.378798]\n",
      "epoch:29 step:27726 [D loss: 0.513431, acc.: 75.78%] [G loss: 1.347583]\n",
      "epoch:29 step:27727 [D loss: 0.824784, acc.: 52.34%] [G loss: 1.290505]\n",
      "epoch:29 step:27728 [D loss: 0.369074, acc.: 87.50%] [G loss: 1.438487]\n",
      "epoch:29 step:27729 [D loss: 0.498355, acc.: 77.34%] [G loss: 1.635365]\n",
      "epoch:29 step:27730 [D loss: 0.560212, acc.: 74.22%] [G loss: 1.198545]\n",
      "epoch:29 step:27731 [D loss: 0.492739, acc.: 77.34%] [G loss: 1.979363]\n",
      "epoch:29 step:27732 [D loss: 0.515773, acc.: 75.78%] [G loss: 1.076949]\n",
      "epoch:29 step:27733 [D loss: 0.593190, acc.: 61.72%] [G loss: 1.372868]\n",
      "epoch:29 step:27734 [D loss: 0.575802, acc.: 74.22%] [G loss: 1.481661]\n",
      "epoch:29 step:27735 [D loss: 0.494497, acc.: 75.00%] [G loss: 1.052748]\n",
      "epoch:29 step:27736 [D loss: 0.515054, acc.: 73.44%] [G loss: 1.452190]\n",
      "epoch:29 step:27737 [D loss: 0.491885, acc.: 80.47%] [G loss: 1.079008]\n",
      "epoch:29 step:27738 [D loss: 0.407468, acc.: 82.03%] [G loss: 1.688574]\n",
      "epoch:29 step:27739 [D loss: 0.567513, acc.: 70.31%] [G loss: 1.559515]\n",
      "epoch:29 step:27740 [D loss: 0.503830, acc.: 75.00%] [G loss: 1.406368]\n",
      "epoch:29 step:27741 [D loss: 0.534856, acc.: 69.53%] [G loss: 1.591974]\n",
      "epoch:29 step:27742 [D loss: 0.650358, acc.: 63.28%] [G loss: 1.270555]\n",
      "epoch:29 step:27743 [D loss: 0.489628, acc.: 79.69%] [G loss: 1.513996]\n",
      "epoch:29 step:27744 [D loss: 0.435794, acc.: 82.81%] [G loss: 1.186542]\n",
      "epoch:29 step:27745 [D loss: 0.475373, acc.: 80.47%] [G loss: 1.418369]\n",
      "epoch:29 step:27746 [D loss: 0.502003, acc.: 75.00%] [G loss: 1.661953]\n",
      "epoch:29 step:27747 [D loss: 0.525458, acc.: 75.00%] [G loss: 1.301642]\n",
      "epoch:29 step:27748 [D loss: 0.528810, acc.: 73.44%] [G loss: 1.094871]\n",
      "epoch:29 step:27749 [D loss: 0.437215, acc.: 81.25%] [G loss: 1.479831]\n",
      "epoch:29 step:27750 [D loss: 0.644383, acc.: 67.97%] [G loss: 1.080222]\n",
      "epoch:29 step:27751 [D loss: 0.755766, acc.: 55.47%] [G loss: 1.026898]\n",
      "epoch:29 step:27752 [D loss: 0.744019, acc.: 56.25%] [G loss: 1.449799]\n",
      "epoch:29 step:27753 [D loss: 0.556158, acc.: 72.66%] [G loss: 1.580176]\n",
      "epoch:29 step:27754 [D loss: 0.472769, acc.: 77.34%] [G loss: 1.998299]\n",
      "epoch:29 step:27755 [D loss: 0.680012, acc.: 60.16%] [G loss: 1.238206]\n",
      "epoch:29 step:27756 [D loss: 0.461798, acc.: 78.12%] [G loss: 2.161626]\n",
      "epoch:29 step:27757 [D loss: 0.407898, acc.: 85.94%] [G loss: 1.188928]\n",
      "epoch:29 step:27758 [D loss: 0.519614, acc.: 80.47%] [G loss: 1.444505]\n",
      "epoch:29 step:27759 [D loss: 0.504557, acc.: 74.22%] [G loss: 1.415192]\n",
      "epoch:29 step:27760 [D loss: 0.545133, acc.: 70.31%] [G loss: 1.385223]\n",
      "epoch:29 step:27761 [D loss: 0.943196, acc.: 42.19%] [G loss: 0.722975]\n",
      "epoch:29 step:27762 [D loss: 0.568132, acc.: 69.53%] [G loss: 1.482298]\n",
      "epoch:29 step:27763 [D loss: 0.657904, acc.: 67.19%] [G loss: 1.228914]\n",
      "epoch:29 step:27764 [D loss: 0.670657, acc.: 67.19%] [G loss: 1.303548]\n",
      "epoch:29 step:27765 [D loss: 0.397560, acc.: 84.38%] [G loss: 1.863615]\n",
      "epoch:29 step:27766 [D loss: 0.516523, acc.: 74.22%] [G loss: 1.108105]\n",
      "epoch:29 step:27767 [D loss: 0.500024, acc.: 78.12%] [G loss: 1.599749]\n",
      "epoch:29 step:27768 [D loss: 0.737534, acc.: 56.25%] [G loss: 1.359063]\n",
      "epoch:29 step:27769 [D loss: 0.568949, acc.: 72.66%] [G loss: 1.306840]\n",
      "epoch:29 step:27770 [D loss: 0.536117, acc.: 75.78%] [G loss: 0.901253]\n",
      "epoch:29 step:27771 [D loss: 0.517105, acc.: 69.53%] [G loss: 1.472195]\n",
      "epoch:29 step:27772 [D loss: 0.495550, acc.: 75.00%] [G loss: 1.233746]\n",
      "epoch:29 step:27773 [D loss: 0.310980, acc.: 90.62%] [G loss: 1.653248]\n",
      "epoch:29 step:27774 [D loss: 0.819365, acc.: 48.44%] [G loss: 1.173245]\n",
      "epoch:29 step:27775 [D loss: 0.503000, acc.: 71.88%] [G loss: 1.290135]\n",
      "epoch:29 step:27776 [D loss: 0.723239, acc.: 61.72%] [G loss: 1.798777]\n",
      "epoch:29 step:27777 [D loss: 0.724212, acc.: 58.59%] [G loss: 1.446941]\n",
      "epoch:29 step:27778 [D loss: 0.496617, acc.: 78.12%] [G loss: 1.183478]\n",
      "epoch:29 step:27779 [D loss: 0.600731, acc.: 66.41%] [G loss: 1.565349]\n",
      "epoch:29 step:27780 [D loss: 0.518525, acc.: 72.66%] [G loss: 1.422949]\n",
      "epoch:29 step:27781 [D loss: 0.410554, acc.: 86.72%] [G loss: 1.424340]\n",
      "epoch:29 step:27782 [D loss: 0.665906, acc.: 64.06%] [G loss: 1.458409]\n",
      "epoch:29 step:27783 [D loss: 0.601782, acc.: 69.53%] [G loss: 1.400613]\n",
      "epoch:29 step:27784 [D loss: 0.676744, acc.: 65.62%] [G loss: 1.833768]\n",
      "epoch:29 step:27785 [D loss: 0.618411, acc.: 69.53%] [G loss: 1.353642]\n",
      "epoch:29 step:27786 [D loss: 0.592997, acc.: 70.31%] [G loss: 1.147470]\n",
      "epoch:29 step:27787 [D loss: 0.584217, acc.: 67.19%] [G loss: 1.138772]\n",
      "epoch:29 step:27788 [D loss: 0.482043, acc.: 73.44%] [G loss: 1.516191]\n",
      "epoch:29 step:27789 [D loss: 0.758571, acc.: 56.25%] [G loss: 1.368555]\n",
      "epoch:29 step:27790 [D loss: 0.658351, acc.: 62.50%] [G loss: 1.261709]\n",
      "epoch:29 step:27791 [D loss: 0.654752, acc.: 64.06%] [G loss: 1.338621]\n",
      "epoch:29 step:27792 [D loss: 0.735033, acc.: 53.91%] [G loss: 1.449002]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:29 step:27793 [D loss: 0.621143, acc.: 63.28%] [G loss: 1.322258]\n",
      "epoch:29 step:27794 [D loss: 0.508172, acc.: 74.22%] [G loss: 1.041203]\n",
      "epoch:29 step:27795 [D loss: 0.479653, acc.: 76.56%] [G loss: 1.136920]\n",
      "epoch:29 step:27796 [D loss: 0.452759, acc.: 77.34%] [G loss: 1.520451]\n",
      "epoch:29 step:27797 [D loss: 0.759968, acc.: 50.78%] [G loss: 1.447033]\n",
      "epoch:29 step:27798 [D loss: 0.583272, acc.: 71.09%] [G loss: 1.151460]\n",
      "epoch:29 step:27799 [D loss: 0.481489, acc.: 78.91%] [G loss: 1.572857]\n",
      "epoch:29 step:27800 [D loss: 0.453111, acc.: 81.25%] [G loss: 1.367513]\n",
      "epoch:29 step:27801 [D loss: 0.598046, acc.: 70.31%] [G loss: 1.488011]\n",
      "epoch:29 step:27802 [D loss: 0.551686, acc.: 68.75%] [G loss: 1.701245]\n",
      "epoch:29 step:27803 [D loss: 0.678407, acc.: 60.94%] [G loss: 1.271911]\n",
      "epoch:29 step:27804 [D loss: 0.514838, acc.: 73.44%] [G loss: 1.327743]\n",
      "epoch:29 step:27805 [D loss: 0.559720, acc.: 73.44%] [G loss: 1.883933]\n",
      "epoch:29 step:27806 [D loss: 0.407230, acc.: 84.38%] [G loss: 1.803635]\n",
      "epoch:29 step:27807 [D loss: 0.431057, acc.: 80.47%] [G loss: 1.486540]\n",
      "epoch:29 step:27808 [D loss: 0.624076, acc.: 61.72%] [G loss: 1.323075]\n",
      "epoch:29 step:27809 [D loss: 0.371408, acc.: 87.50%] [G loss: 1.380192]\n",
      "epoch:29 step:27810 [D loss: 0.393310, acc.: 82.03%] [G loss: 1.036412]\n",
      "epoch:29 step:27811 [D loss: 0.477648, acc.: 75.78%] [G loss: 1.217887]\n",
      "epoch:29 step:27812 [D loss: 0.542496, acc.: 70.31%] [G loss: 1.227434]\n",
      "epoch:29 step:27813 [D loss: 0.616117, acc.: 66.41%] [G loss: 1.260888]\n",
      "epoch:29 step:27814 [D loss: 0.582856, acc.: 67.97%] [G loss: 1.131150]\n",
      "epoch:29 step:27815 [D loss: 0.502801, acc.: 75.00%] [G loss: 1.479153]\n",
      "epoch:29 step:27816 [D loss: 0.763663, acc.: 56.25%] [G loss: 1.407076]\n",
      "epoch:29 step:27817 [D loss: 0.496975, acc.: 75.00%] [G loss: 1.560411]\n",
      "epoch:29 step:27818 [D loss: 0.481420, acc.: 79.69%] [G loss: 1.262324]\n",
      "epoch:29 step:27819 [D loss: 0.605754, acc.: 70.31%] [G loss: 1.207788]\n",
      "epoch:29 step:27820 [D loss: 0.701703, acc.: 67.19%] [G loss: 1.463991]\n",
      "epoch:29 step:27821 [D loss: 0.463816, acc.: 80.47%] [G loss: 1.806041]\n",
      "epoch:29 step:27822 [D loss: 0.648955, acc.: 61.72%] [G loss: 1.460964]\n",
      "epoch:29 step:27823 [D loss: 0.455810, acc.: 77.34%] [G loss: 1.953785]\n",
      "epoch:29 step:27824 [D loss: 0.573767, acc.: 67.97%] [G loss: 1.411857]\n",
      "epoch:29 step:27825 [D loss: 0.609318, acc.: 64.84%] [G loss: 1.414615]\n",
      "epoch:29 step:27826 [D loss: 0.572806, acc.: 69.53%] [G loss: 1.164476]\n",
      "epoch:29 step:27827 [D loss: 0.595673, acc.: 61.72%] [G loss: 1.125810]\n",
      "epoch:29 step:27828 [D loss: 0.669860, acc.: 59.38%] [G loss: 1.579523]\n",
      "epoch:29 step:27829 [D loss: 0.577479, acc.: 68.75%] [G loss: 1.109738]\n",
      "epoch:29 step:27830 [D loss: 0.575074, acc.: 67.97%] [G loss: 1.719427]\n",
      "epoch:29 step:27831 [D loss: 0.582182, acc.: 69.53%] [G loss: 1.201080]\n",
      "epoch:29 step:27832 [D loss: 0.703302, acc.: 57.03%] [G loss: 1.357861]\n",
      "epoch:29 step:27833 [D loss: 0.494671, acc.: 76.56%] [G loss: 1.595927]\n",
      "epoch:29 step:27834 [D loss: 0.641629, acc.: 67.97%] [G loss: 1.493449]\n",
      "epoch:29 step:27835 [D loss: 0.596427, acc.: 69.53%] [G loss: 1.674324]\n",
      "epoch:29 step:27836 [D loss: 0.495468, acc.: 75.78%] [G loss: 1.681400]\n",
      "epoch:29 step:27837 [D loss: 0.829638, acc.: 46.88%] [G loss: 1.638963]\n",
      "epoch:29 step:27838 [D loss: 0.440348, acc.: 82.81%] [G loss: 1.564926]\n",
      "epoch:29 step:27839 [D loss: 0.427070, acc.: 82.03%] [G loss: 1.279035]\n",
      "epoch:29 step:27840 [D loss: 0.440264, acc.: 83.59%] [G loss: 1.371874]\n",
      "epoch:29 step:27841 [D loss: 0.755085, acc.: 53.12%] [G loss: 1.123946]\n",
      "epoch:29 step:27842 [D loss: 0.588560, acc.: 70.31%] [G loss: 1.514148]\n",
      "epoch:29 step:27843 [D loss: 0.468894, acc.: 80.47%] [G loss: 1.310366]\n",
      "epoch:29 step:27844 [D loss: 0.657811, acc.: 64.84%] [G loss: 1.408497]\n",
      "epoch:29 step:27845 [D loss: 0.484350, acc.: 77.34%] [G loss: 1.297866]\n",
      "epoch:29 step:27846 [D loss: 0.649871, acc.: 62.50%] [G loss: 1.619742]\n",
      "epoch:29 step:27847 [D loss: 0.643744, acc.: 67.97%] [G loss: 1.463402]\n",
      "epoch:29 step:27848 [D loss: 0.555804, acc.: 71.09%] [G loss: 1.490374]\n",
      "epoch:29 step:27849 [D loss: 0.623976, acc.: 64.84%] [G loss: 1.417917]\n",
      "epoch:29 step:27850 [D loss: 0.606845, acc.: 67.97%] [G loss: 1.848006]\n",
      "epoch:29 step:27851 [D loss: 0.497539, acc.: 78.12%] [G loss: 1.705454]\n",
      "epoch:29 step:27852 [D loss: 0.480030, acc.: 78.12%] [G loss: 1.346261]\n",
      "epoch:29 step:27853 [D loss: 0.578267, acc.: 73.44%] [G loss: 1.454383]\n",
      "epoch:29 step:27854 [D loss: 0.533184, acc.: 75.00%] [G loss: 1.480293]\n",
      "epoch:29 step:27855 [D loss: 0.326271, acc.: 89.06%] [G loss: 1.517024]\n",
      "epoch:29 step:27856 [D loss: 0.783987, acc.: 47.66%] [G loss: 1.423194]\n",
      "epoch:29 step:27857 [D loss: 0.767643, acc.: 54.69%] [G loss: 1.413421]\n",
      "epoch:29 step:27858 [D loss: 0.505668, acc.: 76.56%] [G loss: 1.445005]\n",
      "epoch:29 step:27859 [D loss: 0.405839, acc.: 86.72%] [G loss: 1.709180]\n",
      "epoch:29 step:27860 [D loss: 0.525502, acc.: 75.78%] [G loss: 1.845275]\n",
      "epoch:29 step:27861 [D loss: 0.583694, acc.: 68.75%] [G loss: 1.112657]\n",
      "epoch:29 step:27862 [D loss: 0.561328, acc.: 71.88%] [G loss: 1.601093]\n",
      "epoch:29 step:27863 [D loss: 0.453499, acc.: 78.12%] [G loss: 1.702479]\n",
      "epoch:29 step:27864 [D loss: 0.446028, acc.: 78.91%] [G loss: 1.628906]\n",
      "epoch:29 step:27865 [D loss: 0.663649, acc.: 60.94%] [G loss: 1.199499]\n",
      "epoch:29 step:27866 [D loss: 0.664357, acc.: 54.69%] [G loss: 1.032420]\n",
      "epoch:29 step:27867 [D loss: 0.510735, acc.: 75.00%] [G loss: 0.960216]\n",
      "epoch:29 step:27868 [D loss: 0.531629, acc.: 73.44%] [G loss: 1.486587]\n",
      "epoch:29 step:27869 [D loss: 0.543110, acc.: 71.09%] [G loss: 1.435716]\n",
      "epoch:29 step:27870 [D loss: 0.419529, acc.: 78.12%] [G loss: 1.523173]\n",
      "epoch:29 step:27871 [D loss: 0.710887, acc.: 56.25%] [G loss: 1.146335]\n",
      "epoch:29 step:27872 [D loss: 0.487329, acc.: 78.12%] [G loss: 1.731622]\n",
      "epoch:29 step:27873 [D loss: 0.510193, acc.: 76.56%] [G loss: 1.290729]\n",
      "epoch:29 step:27874 [D loss: 0.412419, acc.: 82.81%] [G loss: 1.785171]\n",
      "epoch:29 step:27875 [D loss: 0.276606, acc.: 92.19%] [G loss: 1.524791]\n",
      "epoch:29 step:27876 [D loss: 0.519899, acc.: 69.53%] [G loss: 1.411518]\n",
      "epoch:29 step:27877 [D loss: 0.547974, acc.: 75.00%] [G loss: 1.585900]\n",
      "epoch:29 step:27878 [D loss: 0.486801, acc.: 78.91%] [G loss: 1.215297]\n",
      "epoch:29 step:27879 [D loss: 0.616769, acc.: 65.62%] [G loss: 1.140917]\n",
      "epoch:29 step:27880 [D loss: 0.628451, acc.: 64.06%] [G loss: 1.272000]\n",
      "epoch:29 step:27881 [D loss: 0.443337, acc.: 81.25%] [G loss: 1.269502]\n",
      "epoch:29 step:27882 [D loss: 0.453015, acc.: 83.59%] [G loss: 1.150000]\n",
      "epoch:29 step:27883 [D loss: 0.620364, acc.: 64.84%] [G loss: 1.331201]\n",
      "epoch:29 step:27884 [D loss: 0.380817, acc.: 85.16%] [G loss: 1.374807]\n",
      "epoch:29 step:27885 [D loss: 0.589595, acc.: 66.41%] [G loss: 1.313956]\n",
      "epoch:29 step:27886 [D loss: 0.544100, acc.: 74.22%] [G loss: 1.535971]\n",
      "epoch:29 step:27887 [D loss: 0.701135, acc.: 58.59%] [G loss: 1.036500]\n",
      "epoch:29 step:27888 [D loss: 0.751792, acc.: 52.34%] [G loss: 1.418555]\n",
      "epoch:29 step:27889 [D loss: 0.437830, acc.: 79.69%] [G loss: 1.760642]\n",
      "epoch:29 step:27890 [D loss: 0.633096, acc.: 64.84%] [G loss: 1.294389]\n",
      "epoch:29 step:27891 [D loss: 0.473336, acc.: 80.47%] [G loss: 1.322716]\n",
      "epoch:29 step:27892 [D loss: 0.646680, acc.: 62.50%] [G loss: 1.196182]\n",
      "epoch:29 step:27893 [D loss: 0.655642, acc.: 66.41%] [G loss: 1.062598]\n",
      "epoch:29 step:27894 [D loss: 0.398355, acc.: 83.59%] [G loss: 1.627303]\n",
      "epoch:29 step:27895 [D loss: 0.714032, acc.: 58.59%] [G loss: 1.153324]\n",
      "epoch:29 step:27896 [D loss: 0.610413, acc.: 63.28%] [G loss: 1.163583]\n",
      "epoch:29 step:27897 [D loss: 0.483423, acc.: 78.12%] [G loss: 1.674931]\n",
      "epoch:29 step:27898 [D loss: 0.400514, acc.: 81.25%] [G loss: 1.831498]\n",
      "epoch:29 step:27899 [D loss: 0.540150, acc.: 75.00%] [G loss: 1.934087]\n",
      "epoch:29 step:27900 [D loss: 0.566019, acc.: 71.09%] [G loss: 1.048906]\n",
      "epoch:29 step:27901 [D loss: 0.591833, acc.: 67.97%] [G loss: 1.429155]\n",
      "epoch:29 step:27902 [D loss: 0.701335, acc.: 59.38%] [G loss: 1.266570]\n",
      "epoch:29 step:27903 [D loss: 0.588022, acc.: 71.09%] [G loss: 1.383140]\n",
      "epoch:29 step:27904 [D loss: 0.531611, acc.: 74.22%] [G loss: 1.415907]\n",
      "epoch:29 step:27905 [D loss: 0.545224, acc.: 72.66%] [G loss: 1.773306]\n",
      "epoch:29 step:27906 [D loss: 0.548902, acc.: 71.09%] [G loss: 1.249044]\n",
      "epoch:29 step:27907 [D loss: 0.511843, acc.: 73.44%] [G loss: 1.408755]\n",
      "epoch:29 step:27908 [D loss: 0.502210, acc.: 71.88%] [G loss: 1.174665]\n",
      "epoch:29 step:27909 [D loss: 0.584061, acc.: 64.06%] [G loss: 1.402175]\n",
      "epoch:29 step:27910 [D loss: 0.613073, acc.: 62.50%] [G loss: 1.656547]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:29 step:27911 [D loss: 0.534122, acc.: 75.78%] [G loss: 1.442832]\n",
      "epoch:29 step:27912 [D loss: 0.580839, acc.: 72.66%] [G loss: 1.269887]\n",
      "epoch:29 step:27913 [D loss: 0.611602, acc.: 60.94%] [G loss: 1.197076]\n",
      "epoch:29 step:27914 [D loss: 0.489551, acc.: 74.22%] [G loss: 1.547084]\n",
      "epoch:29 step:27915 [D loss: 0.470936, acc.: 82.81%] [G loss: 1.248369]\n",
      "epoch:29 step:27916 [D loss: 0.535679, acc.: 71.88%] [G loss: 1.707741]\n",
      "epoch:29 step:27917 [D loss: 0.382978, acc.: 86.72%] [G loss: 1.361559]\n",
      "epoch:29 step:27918 [D loss: 0.651152, acc.: 62.50%] [G loss: 1.375376]\n",
      "epoch:29 step:27919 [D loss: 0.380153, acc.: 87.50%] [G loss: 1.246580]\n",
      "epoch:29 step:27920 [D loss: 0.444139, acc.: 76.56%] [G loss: 1.756488]\n",
      "epoch:29 step:27921 [D loss: 0.665978, acc.: 66.41%] [G loss: 1.285517]\n",
      "epoch:29 step:27922 [D loss: 0.477004, acc.: 78.12%] [G loss: 1.317745]\n",
      "epoch:29 step:27923 [D loss: 0.439050, acc.: 82.03%] [G loss: 1.058272]\n",
      "epoch:29 step:27924 [D loss: 0.430043, acc.: 80.47%] [G loss: 1.607564]\n",
      "epoch:29 step:27925 [D loss: 0.789120, acc.: 49.22%] [G loss: 1.583175]\n",
      "epoch:29 step:27926 [D loss: 0.464817, acc.: 81.25%] [G loss: 1.506221]\n",
      "epoch:29 step:27927 [D loss: 0.613844, acc.: 68.75%] [G loss: 1.400403]\n",
      "epoch:29 step:27928 [D loss: 0.479773, acc.: 81.25%] [G loss: 1.690328]\n",
      "epoch:29 step:27929 [D loss: 0.706247, acc.: 58.59%] [G loss: 1.257483]\n",
      "epoch:29 step:27930 [D loss: 0.543841, acc.: 74.22%] [G loss: 1.615741]\n",
      "epoch:29 step:27931 [D loss: 0.600495, acc.: 67.19%] [G loss: 0.986229]\n",
      "epoch:29 step:27932 [D loss: 0.454166, acc.: 83.59%] [G loss: 1.843540]\n",
      "epoch:29 step:27933 [D loss: 0.432170, acc.: 79.69%] [G loss: 1.758420]\n",
      "epoch:29 step:27934 [D loss: 0.750653, acc.: 56.25%] [G loss: 1.225440]\n",
      "epoch:29 step:27935 [D loss: 0.613925, acc.: 71.09%] [G loss: 1.514539]\n",
      "epoch:29 step:27936 [D loss: 0.563411, acc.: 70.31%] [G loss: 1.460969]\n",
      "epoch:29 step:27937 [D loss: 0.552014, acc.: 70.31%] [G loss: 1.349902]\n",
      "epoch:29 step:27938 [D loss: 0.490779, acc.: 77.34%] [G loss: 1.664132]\n",
      "epoch:29 step:27939 [D loss: 0.591011, acc.: 69.53%] [G loss: 1.442710]\n",
      "epoch:29 step:27940 [D loss: 0.399752, acc.: 83.59%] [G loss: 1.803073]\n",
      "epoch:29 step:27941 [D loss: 0.515009, acc.: 71.88%] [G loss: 1.645835]\n",
      "epoch:29 step:27942 [D loss: 0.449199, acc.: 83.59%] [G loss: 1.622684]\n",
      "epoch:29 step:27943 [D loss: 0.540192, acc.: 74.22%] [G loss: 1.284225]\n",
      "epoch:29 step:27944 [D loss: 0.473131, acc.: 77.34%] [G loss: 1.384247]\n",
      "epoch:29 step:27945 [D loss: 0.413063, acc.: 80.47%] [G loss: 1.300898]\n",
      "epoch:29 step:27946 [D loss: 0.685550, acc.: 66.41%] [G loss: 1.536200]\n",
      "epoch:29 step:27947 [D loss: 0.480444, acc.: 76.56%] [G loss: 1.270963]\n",
      "epoch:29 step:27948 [D loss: 0.579949, acc.: 66.41%] [G loss: 1.477543]\n",
      "epoch:29 step:27949 [D loss: 0.501940, acc.: 75.78%] [G loss: 1.191661]\n",
      "epoch:29 step:27950 [D loss: 0.723500, acc.: 60.16%] [G loss: 1.073254]\n",
      "epoch:29 step:27951 [D loss: 0.431098, acc.: 78.12%] [G loss: 1.831470]\n",
      "epoch:29 step:27952 [D loss: 0.673136, acc.: 58.59%] [G loss: 1.556782]\n",
      "epoch:29 step:27953 [D loss: 0.783518, acc.: 51.56%] [G loss: 1.320410]\n",
      "epoch:29 step:27954 [D loss: 0.390077, acc.: 85.16%] [G loss: 1.706592]\n",
      "epoch:29 step:27955 [D loss: 0.560083, acc.: 74.22%] [G loss: 1.711415]\n",
      "epoch:29 step:27956 [D loss: 0.626126, acc.: 62.50%] [G loss: 1.996518]\n",
      "epoch:29 step:27957 [D loss: 0.507541, acc.: 73.44%] [G loss: 1.757086]\n",
      "epoch:29 step:27958 [D loss: 0.374058, acc.: 87.50%] [G loss: 1.859904]\n",
      "epoch:29 step:27959 [D loss: 0.742237, acc.: 56.25%] [G loss: 1.465753]\n",
      "epoch:29 step:27960 [D loss: 0.606048, acc.: 68.75%] [G loss: 1.123125]\n",
      "epoch:29 step:27961 [D loss: 0.508040, acc.: 75.78%] [G loss: 1.309312]\n",
      "epoch:29 step:27962 [D loss: 0.634494, acc.: 67.19%] [G loss: 1.433314]\n",
      "epoch:29 step:27963 [D loss: 0.544747, acc.: 75.00%] [G loss: 1.582450]\n",
      "epoch:29 step:27964 [D loss: 0.583079, acc.: 67.97%] [G loss: 1.755336]\n",
      "epoch:29 step:27965 [D loss: 0.659842, acc.: 62.50%] [G loss: 1.451046]\n",
      "epoch:29 step:27966 [D loss: 0.462058, acc.: 74.22%] [G loss: 1.682069]\n",
      "epoch:29 step:27967 [D loss: 0.537471, acc.: 74.22%] [G loss: 1.830083]\n",
      "epoch:29 step:27968 [D loss: 0.615793, acc.: 64.84%] [G loss: 1.356676]\n",
      "epoch:29 step:27969 [D loss: 0.523572, acc.: 75.78%] [G loss: 1.303152]\n",
      "epoch:29 step:27970 [D loss: 0.575628, acc.: 71.88%] [G loss: 1.208777]\n",
      "epoch:29 step:27971 [D loss: 0.497301, acc.: 73.44%] [G loss: 1.325578]\n",
      "epoch:29 step:27972 [D loss: 0.479214, acc.: 78.91%] [G loss: 1.455228]\n",
      "epoch:29 step:27973 [D loss: 0.556540, acc.: 71.88%] [G loss: 1.237372]\n",
      "epoch:29 step:27974 [D loss: 0.675475, acc.: 60.94%] [G loss: 1.487815]\n",
      "epoch:29 step:27975 [D loss: 0.748117, acc.: 53.12%] [G loss: 1.361249]\n",
      "epoch:29 step:27976 [D loss: 0.671577, acc.: 61.72%] [G loss: 1.556867]\n",
      "epoch:29 step:27977 [D loss: 0.339354, acc.: 88.28%] [G loss: 1.862581]\n",
      "epoch:29 step:27978 [D loss: 0.634373, acc.: 67.97%] [G loss: 1.555388]\n",
      "epoch:29 step:27979 [D loss: 0.425461, acc.: 84.38%] [G loss: 1.610339]\n",
      "epoch:29 step:27980 [D loss: 0.430277, acc.: 79.69%] [G loss: 1.091273]\n",
      "epoch:29 step:27981 [D loss: 0.426890, acc.: 83.59%] [G loss: 1.737461]\n",
      "epoch:29 step:27982 [D loss: 0.397135, acc.: 86.72%] [G loss: 1.186560]\n",
      "epoch:29 step:27983 [D loss: 0.334719, acc.: 87.50%] [G loss: 1.693129]\n",
      "epoch:29 step:27984 [D loss: 0.628288, acc.: 71.88%] [G loss: 1.529261]\n",
      "epoch:29 step:27985 [D loss: 0.503046, acc.: 76.56%] [G loss: 1.445165]\n",
      "epoch:29 step:27986 [D loss: 0.483965, acc.: 79.69%] [G loss: 1.622307]\n",
      "epoch:29 step:27987 [D loss: 0.465623, acc.: 80.47%] [G loss: 1.246664]\n",
      "epoch:29 step:27988 [D loss: 0.516541, acc.: 76.56%] [G loss: 1.749673]\n",
      "epoch:29 step:27989 [D loss: 0.558720, acc.: 70.31%] [G loss: 1.190414]\n",
      "epoch:29 step:27990 [D loss: 0.516268, acc.: 80.47%] [G loss: 1.485124]\n",
      "epoch:29 step:27991 [D loss: 0.655217, acc.: 64.06%] [G loss: 1.244017]\n",
      "epoch:29 step:27992 [D loss: 0.527184, acc.: 73.44%] [G loss: 1.671065]\n",
      "epoch:29 step:27993 [D loss: 0.483883, acc.: 77.34%] [G loss: 1.610133]\n",
      "epoch:29 step:27994 [D loss: 0.655777, acc.: 59.38%] [G loss: 1.472866]\n",
      "epoch:29 step:27995 [D loss: 0.658007, acc.: 63.28%] [G loss: 1.478855]\n",
      "epoch:29 step:27996 [D loss: 0.515727, acc.: 70.31%] [G loss: 1.790806]\n",
      "epoch:29 step:27997 [D loss: 0.402631, acc.: 82.81%] [G loss: 1.590516]\n",
      "epoch:29 step:27998 [D loss: 0.344183, acc.: 87.50%] [G loss: 1.649534]\n",
      "epoch:29 step:27999 [D loss: 0.654010, acc.: 62.50%] [G loss: 0.998402]\n",
      "epoch:29 step:28000 [D loss: 0.581707, acc.: 72.66%] [G loss: 1.236557]\n",
      "epoch:29 step:28001 [D loss: 0.533952, acc.: 70.31%] [G loss: 0.821839]\n",
      "epoch:29 step:28002 [D loss: 0.551456, acc.: 75.78%] [G loss: 1.568024]\n",
      "epoch:29 step:28003 [D loss: 0.504324, acc.: 77.34%] [G loss: 1.303517]\n",
      "epoch:29 step:28004 [D loss: 0.650322, acc.: 68.75%] [G loss: 1.364295]\n",
      "epoch:29 step:28005 [D loss: 0.499403, acc.: 77.34%] [G loss: 1.183070]\n",
      "epoch:29 step:28006 [D loss: 0.431301, acc.: 78.91%] [G loss: 1.541029]\n",
      "epoch:29 step:28007 [D loss: 0.494111, acc.: 78.12%] [G loss: 1.131193]\n",
      "epoch:29 step:28008 [D loss: 0.616109, acc.: 67.97%] [G loss: 1.333874]\n",
      "epoch:29 step:28009 [D loss: 0.480980, acc.: 78.91%] [G loss: 1.564778]\n",
      "epoch:29 step:28010 [D loss: 0.566316, acc.: 69.53%] [G loss: 1.588128]\n",
      "epoch:29 step:28011 [D loss: 0.519267, acc.: 75.78%] [G loss: 1.756100]\n",
      "epoch:29 step:28012 [D loss: 0.486848, acc.: 79.69%] [G loss: 1.422921]\n",
      "epoch:29 step:28013 [D loss: 0.554639, acc.: 70.31%] [G loss: 1.173932]\n",
      "epoch:29 step:28014 [D loss: 0.494284, acc.: 75.00%] [G loss: 1.235147]\n",
      "epoch:29 step:28015 [D loss: 0.515085, acc.: 74.22%] [G loss: 1.762691]\n",
      "epoch:29 step:28016 [D loss: 0.510231, acc.: 75.00%] [G loss: 1.406818]\n",
      "epoch:29 step:28017 [D loss: 0.624359, acc.: 64.84%] [G loss: 1.033964]\n",
      "epoch:29 step:28018 [D loss: 0.594002, acc.: 70.31%] [G loss: 1.465713]\n",
      "epoch:29 step:28019 [D loss: 0.414170, acc.: 85.94%] [G loss: 1.559270]\n",
      "epoch:29 step:28020 [D loss: 0.504548, acc.: 74.22%] [G loss: 1.617973]\n",
      "epoch:29 step:28021 [D loss: 0.643946, acc.: 63.28%] [G loss: 1.384181]\n",
      "epoch:29 step:28022 [D loss: 0.337185, acc.: 92.19%] [G loss: 1.725854]\n",
      "epoch:29 step:28023 [D loss: 0.558701, acc.: 66.41%] [G loss: 1.756132]\n",
      "epoch:29 step:28024 [D loss: 0.723741, acc.: 57.81%] [G loss: 1.481586]\n",
      "epoch:29 step:28025 [D loss: 0.565837, acc.: 70.31%] [G loss: 1.370005]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:29 step:28026 [D loss: 0.494821, acc.: 77.34%] [G loss: 1.752655]\n",
      "epoch:29 step:28027 [D loss: 0.461846, acc.: 77.34%] [G loss: 1.536392]\n",
      "epoch:29 step:28028 [D loss: 0.580404, acc.: 70.31%] [G loss: 1.618600]\n",
      "epoch:29 step:28029 [D loss: 0.438634, acc.: 81.25%] [G loss: 1.430184]\n",
      "epoch:29 step:28030 [D loss: 0.667868, acc.: 64.06%] [G loss: 1.233868]\n",
      "epoch:29 step:28031 [D loss: 0.432525, acc.: 81.25%] [G loss: 1.555959]\n",
      "epoch:29 step:28032 [D loss: 0.507024, acc.: 77.34%] [G loss: 1.348228]\n",
      "epoch:29 step:28033 [D loss: 0.636042, acc.: 61.72%] [G loss: 1.448402]\n",
      "epoch:29 step:28034 [D loss: 0.477478, acc.: 75.78%] [G loss: 1.797863]\n",
      "epoch:29 step:28035 [D loss: 0.597196, acc.: 67.19%] [G loss: 1.235590]\n",
      "epoch:29 step:28036 [D loss: 0.494725, acc.: 78.91%] [G loss: 1.339862]\n",
      "epoch:29 step:28037 [D loss: 0.545929, acc.: 69.53%] [G loss: 1.352900]\n",
      "epoch:29 step:28038 [D loss: 0.735131, acc.: 50.78%] [G loss: 1.485537]\n",
      "epoch:29 step:28039 [D loss: 0.355502, acc.: 89.06%] [G loss: 1.455058]\n",
      "epoch:29 step:28040 [D loss: 0.703877, acc.: 57.81%] [G loss: 1.294055]\n",
      "epoch:29 step:28041 [D loss: 0.591079, acc.: 63.28%] [G loss: 1.547734]\n",
      "epoch:29 step:28042 [D loss: 0.620554, acc.: 68.75%] [G loss: 1.137892]\n",
      "epoch:29 step:28043 [D loss: 0.600720, acc.: 67.19%] [G loss: 1.200843]\n",
      "epoch:29 step:28044 [D loss: 0.524332, acc.: 74.22%] [G loss: 1.558927]\n",
      "epoch:29 step:28045 [D loss: 0.513516, acc.: 76.56%] [G loss: 1.297979]\n",
      "epoch:29 step:28046 [D loss: 0.347421, acc.: 85.94%] [G loss: 1.429526]\n",
      "epoch:29 step:28047 [D loss: 0.667243, acc.: 64.84%] [G loss: 1.624367]\n",
      "epoch:29 step:28048 [D loss: 0.541597, acc.: 70.31%] [G loss: 1.398968]\n",
      "epoch:29 step:28049 [D loss: 0.526040, acc.: 75.00%] [G loss: 1.577169]\n",
      "epoch:29 step:28050 [D loss: 0.564710, acc.: 75.78%] [G loss: 1.900225]\n",
      "epoch:29 step:28051 [D loss: 0.573887, acc.: 71.09%] [G loss: 1.213116]\n",
      "epoch:29 step:28052 [D loss: 0.423752, acc.: 82.03%] [G loss: 1.412239]\n",
      "epoch:29 step:28053 [D loss: 0.477574, acc.: 79.69%] [G loss: 1.592327]\n",
      "epoch:29 step:28054 [D loss: 0.502520, acc.: 73.44%] [G loss: 1.247292]\n",
      "epoch:29 step:28055 [D loss: 0.528997, acc.: 72.66%] [G loss: 1.228542]\n",
      "epoch:29 step:28056 [D loss: 0.594089, acc.: 73.44%] [G loss: 1.578139]\n",
      "epoch:29 step:28057 [D loss: 0.483846, acc.: 78.12%] [G loss: 1.220618]\n",
      "epoch:29 step:28058 [D loss: 0.467379, acc.: 73.44%] [G loss: 1.430634]\n",
      "epoch:29 step:28059 [D loss: 0.390443, acc.: 84.38%] [G loss: 1.751766]\n",
      "epoch:29 step:28060 [D loss: 0.498125, acc.: 76.56%] [G loss: 1.061649]\n",
      "epoch:29 step:28061 [D loss: 0.536191, acc.: 75.00%] [G loss: 1.368344]\n",
      "epoch:29 step:28062 [D loss: 0.550339, acc.: 72.66%] [G loss: 1.828799]\n",
      "epoch:29 step:28063 [D loss: 0.484308, acc.: 75.78%] [G loss: 1.343594]\n",
      "epoch:29 step:28064 [D loss: 0.623322, acc.: 66.41%] [G loss: 1.151394]\n",
      "epoch:29 step:28065 [D loss: 0.496623, acc.: 82.81%] [G loss: 1.235920]\n",
      "epoch:29 step:28066 [D loss: 0.421701, acc.: 82.81%] [G loss: 1.580301]\n",
      "epoch:29 step:28067 [D loss: 0.645815, acc.: 63.28%] [G loss: 1.403687]\n",
      "epoch:29 step:28068 [D loss: 0.548841, acc.: 71.09%] [G loss: 1.299190]\n",
      "epoch:29 step:28069 [D loss: 0.471242, acc.: 78.91%] [G loss: 1.688280]\n",
      "epoch:29 step:28070 [D loss: 0.785827, acc.: 58.59%] [G loss: 0.882371]\n",
      "epoch:29 step:28071 [D loss: 0.555425, acc.: 73.44%] [G loss: 1.002439]\n",
      "epoch:29 step:28072 [D loss: 0.507015, acc.: 78.91%] [G loss: 1.431942]\n",
      "epoch:29 step:28073 [D loss: 0.528456, acc.: 77.34%] [G loss: 1.312589]\n",
      "epoch:29 step:28074 [D loss: 0.564779, acc.: 75.00%] [G loss: 1.476635]\n",
      "epoch:29 step:28075 [D loss: 0.464247, acc.: 78.91%] [G loss: 1.678320]\n",
      "epoch:29 step:28076 [D loss: 0.656701, acc.: 66.41%] [G loss: 1.221509]\n",
      "epoch:29 step:28077 [D loss: 0.654555, acc.: 67.19%] [G loss: 1.359865]\n",
      "epoch:29 step:28078 [D loss: 0.792582, acc.: 53.12%] [G loss: 1.390027]\n",
      "epoch:29 step:28079 [D loss: 0.565807, acc.: 67.97%] [G loss: 1.129007]\n",
      "epoch:29 step:28080 [D loss: 0.731376, acc.: 57.81%] [G loss: 1.296215]\n",
      "epoch:29 step:28081 [D loss: 0.662204, acc.: 62.50%] [G loss: 1.591137]\n",
      "epoch:29 step:28082 [D loss: 0.483361, acc.: 79.69%] [G loss: 1.709671]\n",
      "epoch:29 step:28083 [D loss: 0.619801, acc.: 67.19%] [G loss: 1.242009]\n",
      "epoch:29 step:28084 [D loss: 0.743335, acc.: 53.12%] [G loss: 1.456306]\n",
      "epoch:29 step:28085 [D loss: 0.487406, acc.: 78.12%] [G loss: 1.417522]\n",
      "epoch:29 step:28086 [D loss: 0.611976, acc.: 63.28%] [G loss: 1.422651]\n",
      "epoch:29 step:28087 [D loss: 0.564656, acc.: 72.66%] [G loss: 1.696262]\n",
      "epoch:29 step:28088 [D loss: 0.522605, acc.: 71.88%] [G loss: 1.449593]\n",
      "epoch:29 step:28089 [D loss: 0.438988, acc.: 80.47%] [G loss: 1.618394]\n",
      "epoch:29 step:28090 [D loss: 0.520795, acc.: 72.66%] [G loss: 1.352617]\n",
      "epoch:29 step:28091 [D loss: 0.516321, acc.: 75.00%] [G loss: 1.002956]\n",
      "epoch:29 step:28092 [D loss: 0.509224, acc.: 77.34%] [G loss: 1.345999]\n",
      "epoch:29 step:28093 [D loss: 0.673645, acc.: 65.62%] [G loss: 1.330444]\n",
      "epoch:29 step:28094 [D loss: 0.486280, acc.: 74.22%] [G loss: 1.567504]\n",
      "epoch:29 step:28095 [D loss: 0.598720, acc.: 67.19%] [G loss: 1.299055]\n",
      "epoch:29 step:28096 [D loss: 0.634768, acc.: 66.41%] [G loss: 1.045464]\n",
      "epoch:29 step:28097 [D loss: 0.504214, acc.: 78.91%] [G loss: 1.667417]\n",
      "epoch:29 step:28098 [D loss: 0.708564, acc.: 60.16%] [G loss: 1.105823]\n",
      "epoch:29 step:28099 [D loss: 0.514913, acc.: 75.00%] [G loss: 1.562382]\n",
      "epoch:29 step:28100 [D loss: 0.700020, acc.: 55.47%] [G loss: 1.909680]\n",
      "epoch:29 step:28101 [D loss: 0.461639, acc.: 80.47%] [G loss: 1.469919]\n",
      "epoch:29 step:28102 [D loss: 0.443416, acc.: 81.25%] [G loss: 1.338037]\n",
      "epoch:29 step:28103 [D loss: 0.502659, acc.: 82.03%] [G loss: 1.283969]\n",
      "epoch:29 step:28104 [D loss: 0.493780, acc.: 71.88%] [G loss: 1.890980]\n",
      "epoch:29 step:28105 [D loss: 0.507393, acc.: 80.47%] [G loss: 1.616966]\n",
      "epoch:29 step:28106 [D loss: 0.598941, acc.: 64.06%] [G loss: 1.150687]\n",
      "epoch:29 step:28107 [D loss: 0.392721, acc.: 85.16%] [G loss: 1.180731]\n",
      "epoch:29 step:28108 [D loss: 0.608257, acc.: 68.75%] [G loss: 1.306945]\n",
      "epoch:29 step:28109 [D loss: 0.518455, acc.: 72.66%] [G loss: 1.525708]\n",
      "epoch:29 step:28110 [D loss: 0.654357, acc.: 60.94%] [G loss: 0.967099]\n",
      "epoch:30 step:28111 [D loss: 0.597745, acc.: 63.28%] [G loss: 1.560706]\n",
      "epoch:30 step:28112 [D loss: 0.578958, acc.: 64.84%] [G loss: 1.480207]\n",
      "epoch:30 step:28113 [D loss: 0.469764, acc.: 78.91%] [G loss: 1.901958]\n",
      "epoch:30 step:28114 [D loss: 0.462412, acc.: 82.03%] [G loss: 1.542413]\n",
      "epoch:30 step:28115 [D loss: 0.664435, acc.: 64.06%] [G loss: 1.099091]\n",
      "epoch:30 step:28116 [D loss: 0.723251, acc.: 60.94%] [G loss: 1.357923]\n",
      "epoch:30 step:28117 [D loss: 0.528701, acc.: 71.09%] [G loss: 1.688123]\n",
      "epoch:30 step:28118 [D loss: 0.603667, acc.: 67.19%] [G loss: 1.533991]\n",
      "epoch:30 step:28119 [D loss: 0.399600, acc.: 86.72%] [G loss: 1.535888]\n",
      "epoch:30 step:28120 [D loss: 0.603213, acc.: 72.66%] [G loss: 1.693935]\n",
      "epoch:30 step:28121 [D loss: 0.513267, acc.: 71.09%] [G loss: 1.393696]\n",
      "epoch:30 step:28122 [D loss: 0.554246, acc.: 64.84%] [G loss: 1.585210]\n",
      "epoch:30 step:28123 [D loss: 0.782667, acc.: 52.34%] [G loss: 1.431227]\n",
      "epoch:30 step:28124 [D loss: 0.602455, acc.: 71.09%] [G loss: 1.134584]\n",
      "epoch:30 step:28125 [D loss: 0.419207, acc.: 82.03%] [G loss: 1.503837]\n",
      "epoch:30 step:28126 [D loss: 0.545675, acc.: 71.88%] [G loss: 1.615213]\n",
      "epoch:30 step:28127 [D loss: 0.570846, acc.: 70.31%] [G loss: 1.628802]\n",
      "epoch:30 step:28128 [D loss: 0.720292, acc.: 59.38%] [G loss: 1.380851]\n",
      "epoch:30 step:28129 [D loss: 0.580392, acc.: 72.66%] [G loss: 1.592010]\n",
      "epoch:30 step:28130 [D loss: 0.522162, acc.: 75.78%] [G loss: 1.450555]\n",
      "epoch:30 step:28131 [D loss: 0.473588, acc.: 80.47%] [G loss: 1.517473]\n",
      "epoch:30 step:28132 [D loss: 0.554579, acc.: 68.75%] [G loss: 1.342104]\n",
      "epoch:30 step:28133 [D loss: 0.475373, acc.: 77.34%] [G loss: 1.528795]\n",
      "epoch:30 step:28134 [D loss: 0.547355, acc.: 71.88%] [G loss: 1.301806]\n",
      "epoch:30 step:28135 [D loss: 0.683405, acc.: 59.38%] [G loss: 1.804989]\n",
      "epoch:30 step:28136 [D loss: 0.520633, acc.: 73.44%] [G loss: 2.024139]\n",
      "epoch:30 step:28137 [D loss: 0.607901, acc.: 67.19%] [G loss: 1.427445]\n",
      "epoch:30 step:28138 [D loss: 0.453188, acc.: 83.59%] [G loss: 1.923532]\n",
      "epoch:30 step:28139 [D loss: 0.384501, acc.: 85.16%] [G loss: 1.974405]\n",
      "epoch:30 step:28140 [D loss: 0.521516, acc.: 77.34%] [G loss: 1.414845]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:30 step:28141 [D loss: 0.805986, acc.: 51.56%] [G loss: 1.295074]\n",
      "epoch:30 step:28142 [D loss: 0.471021, acc.: 82.81%] [G loss: 1.235746]\n",
      "epoch:30 step:28143 [D loss: 0.419831, acc.: 78.91%] [G loss: 1.811742]\n",
      "epoch:30 step:28144 [D loss: 0.488699, acc.: 78.12%] [G loss: 1.299495]\n",
      "epoch:30 step:28145 [D loss: 0.579763, acc.: 71.88%] [G loss: 1.586489]\n",
      "epoch:30 step:28146 [D loss: 0.512156, acc.: 75.00%] [G loss: 1.576710]\n",
      "epoch:30 step:28147 [D loss: 0.443925, acc.: 82.03%] [G loss: 1.338756]\n",
      "epoch:30 step:28148 [D loss: 0.391194, acc.: 87.50%] [G loss: 1.697526]\n",
      "epoch:30 step:28149 [D loss: 0.526875, acc.: 69.53%] [G loss: 1.535792]\n",
      "epoch:30 step:28150 [D loss: 0.637667, acc.: 64.06%] [G loss: 0.948306]\n",
      "epoch:30 step:28151 [D loss: 0.470190, acc.: 83.59%] [G loss: 1.419581]\n",
      "epoch:30 step:28152 [D loss: 0.603940, acc.: 67.19%] [G loss: 1.846060]\n",
      "epoch:30 step:28153 [D loss: 0.441143, acc.: 80.47%] [G loss: 1.551421]\n",
      "epoch:30 step:28154 [D loss: 0.546536, acc.: 71.09%] [G loss: 1.387328]\n",
      "epoch:30 step:28155 [D loss: 0.476659, acc.: 74.22%] [G loss: 1.082332]\n",
      "epoch:30 step:28156 [D loss: 0.610299, acc.: 71.09%] [G loss: 1.754654]\n",
      "epoch:30 step:28157 [D loss: 0.669517, acc.: 59.38%] [G loss: 1.228067]\n",
      "epoch:30 step:28158 [D loss: 0.563875, acc.: 68.75%] [G loss: 1.090828]\n",
      "epoch:30 step:28159 [D loss: 0.558443, acc.: 68.75%] [G loss: 1.595876]\n",
      "epoch:30 step:28160 [D loss: 0.568807, acc.: 74.22%] [G loss: 1.030764]\n",
      "epoch:30 step:28161 [D loss: 0.446879, acc.: 80.47%] [G loss: 1.588750]\n",
      "epoch:30 step:28162 [D loss: 0.517448, acc.: 72.66%] [G loss: 1.497797]\n",
      "epoch:30 step:28163 [D loss: 0.409570, acc.: 82.81%] [G loss: 1.491319]\n",
      "epoch:30 step:28164 [D loss: 0.617842, acc.: 67.97%] [G loss: 1.526364]\n",
      "epoch:30 step:28165 [D loss: 0.700664, acc.: 54.69%] [G loss: 1.038459]\n",
      "epoch:30 step:28166 [D loss: 0.639476, acc.: 65.62%] [G loss: 1.614319]\n",
      "epoch:30 step:28167 [D loss: 0.532751, acc.: 73.44%] [G loss: 1.412509]\n",
      "epoch:30 step:28168 [D loss: 0.612075, acc.: 71.88%] [G loss: 1.087667]\n",
      "epoch:30 step:28169 [D loss: 0.521162, acc.: 74.22%] [G loss: 1.170119]\n",
      "epoch:30 step:28170 [D loss: 0.553904, acc.: 74.22%] [G loss: 1.063059]\n",
      "epoch:30 step:28171 [D loss: 0.638117, acc.: 64.84%] [G loss: 1.274871]\n",
      "epoch:30 step:28172 [D loss: 0.699673, acc.: 60.94%] [G loss: 1.206954]\n",
      "epoch:30 step:28173 [D loss: 0.582926, acc.: 65.62%] [G loss: 1.265175]\n",
      "epoch:30 step:28174 [D loss: 0.565362, acc.: 70.31%] [G loss: 1.042056]\n",
      "epoch:30 step:28175 [D loss: 0.541001, acc.: 75.00%] [G loss: 1.168326]\n",
      "epoch:30 step:28176 [D loss: 0.690004, acc.: 57.03%] [G loss: 1.051982]\n",
      "epoch:30 step:28177 [D loss: 0.462177, acc.: 80.47%] [G loss: 1.329294]\n",
      "epoch:30 step:28178 [D loss: 0.673235, acc.: 63.28%] [G loss: 0.990123]\n",
      "epoch:30 step:28179 [D loss: 0.273071, acc.: 93.75%] [G loss: 1.504915]\n",
      "epoch:30 step:28180 [D loss: 0.647991, acc.: 71.09%] [G loss: 1.348664]\n",
      "epoch:30 step:28181 [D loss: 0.628724, acc.: 60.16%] [G loss: 1.495658]\n",
      "epoch:30 step:28182 [D loss: 0.572612, acc.: 68.75%] [G loss: 1.320391]\n",
      "epoch:30 step:28183 [D loss: 0.529336, acc.: 70.31%] [G loss: 1.624500]\n",
      "epoch:30 step:28184 [D loss: 0.377862, acc.: 87.50%] [G loss: 1.915610]\n",
      "epoch:30 step:28185 [D loss: 0.591267, acc.: 71.88%] [G loss: 1.366326]\n",
      "epoch:30 step:28186 [D loss: 0.437635, acc.: 80.47%] [G loss: 1.141079]\n",
      "epoch:30 step:28187 [D loss: 0.414160, acc.: 84.38%] [G loss: 1.328221]\n",
      "epoch:30 step:28188 [D loss: 0.484473, acc.: 76.56%] [G loss: 1.928253]\n",
      "epoch:30 step:28189 [D loss: 0.597496, acc.: 67.97%] [G loss: 1.398007]\n",
      "epoch:30 step:28190 [D loss: 0.489348, acc.: 75.00%] [G loss: 1.240126]\n",
      "epoch:30 step:28191 [D loss: 0.656334, acc.: 61.72%] [G loss: 1.576639]\n",
      "epoch:30 step:28192 [D loss: 0.645721, acc.: 57.81%] [G loss: 0.949251]\n",
      "epoch:30 step:28193 [D loss: 0.523821, acc.: 72.66%] [G loss: 1.469131]\n",
      "epoch:30 step:28194 [D loss: 0.658702, acc.: 63.28%] [G loss: 1.351620]\n",
      "epoch:30 step:28195 [D loss: 0.453511, acc.: 78.91%] [G loss: 1.574133]\n",
      "epoch:30 step:28196 [D loss: 0.596864, acc.: 73.44%] [G loss: 1.458542]\n",
      "epoch:30 step:28197 [D loss: 0.536076, acc.: 72.66%] [G loss: 1.310790]\n",
      "epoch:30 step:28198 [D loss: 0.527301, acc.: 72.66%] [G loss: 1.269581]\n",
      "epoch:30 step:28199 [D loss: 0.490120, acc.: 79.69%] [G loss: 1.179986]\n",
      "epoch:30 step:28200 [D loss: 0.406878, acc.: 82.81%] [G loss: 1.683456]\n",
      "epoch:30 step:28201 [D loss: 0.658330, acc.: 59.38%] [G loss: 1.548458]\n",
      "epoch:30 step:28202 [D loss: 0.340927, acc.: 88.28%] [G loss: 1.511299]\n",
      "epoch:30 step:28203 [D loss: 0.697388, acc.: 60.16%] [G loss: 1.357454]\n",
      "epoch:30 step:28204 [D loss: 0.437007, acc.: 78.91%] [G loss: 1.267156]\n",
      "epoch:30 step:28205 [D loss: 0.544865, acc.: 71.88%] [G loss: 2.021398]\n",
      "epoch:30 step:28206 [D loss: 0.352993, acc.: 89.06%] [G loss: 1.532592]\n",
      "epoch:30 step:28207 [D loss: 0.424021, acc.: 78.91%] [G loss: 1.479975]\n",
      "epoch:30 step:28208 [D loss: 0.465817, acc.: 77.34%] [G loss: 1.185097]\n",
      "epoch:30 step:28209 [D loss: 0.639019, acc.: 65.62%] [G loss: 1.542478]\n",
      "epoch:30 step:28210 [D loss: 0.481249, acc.: 78.91%] [G loss: 1.863253]\n",
      "epoch:30 step:28211 [D loss: 0.426097, acc.: 82.03%] [G loss: 2.137374]\n",
      "epoch:30 step:28212 [D loss: 0.632107, acc.: 66.41%] [G loss: 1.020144]\n",
      "epoch:30 step:28213 [D loss: 0.563232, acc.: 69.53%] [G loss: 1.236792]\n",
      "epoch:30 step:28214 [D loss: 0.522434, acc.: 77.34%] [G loss: 1.871693]\n",
      "epoch:30 step:28215 [D loss: 0.508363, acc.: 76.56%] [G loss: 1.441618]\n",
      "epoch:30 step:28216 [D loss: 0.629285, acc.: 66.41%] [G loss: 1.534085]\n",
      "epoch:30 step:28217 [D loss: 0.582735, acc.: 71.09%] [G loss: 1.177583]\n",
      "epoch:30 step:28218 [D loss: 0.494272, acc.: 75.78%] [G loss: 1.430765]\n",
      "epoch:30 step:28219 [D loss: 0.483299, acc.: 78.12%] [G loss: 1.374310]\n",
      "epoch:30 step:28220 [D loss: 0.635655, acc.: 67.97%] [G loss: 1.512999]\n",
      "epoch:30 step:28221 [D loss: 0.765483, acc.: 60.16%] [G loss: 1.132625]\n",
      "epoch:30 step:28222 [D loss: 0.541833, acc.: 74.22%] [G loss: 1.491271]\n",
      "epoch:30 step:28223 [D loss: 0.507845, acc.: 74.22%] [G loss: 1.069492]\n",
      "epoch:30 step:28224 [D loss: 0.371464, acc.: 86.72%] [G loss: 1.368019]\n",
      "epoch:30 step:28225 [D loss: 0.372474, acc.: 85.16%] [G loss: 2.054456]\n",
      "epoch:30 step:28226 [D loss: 0.480152, acc.: 78.91%] [G loss: 1.788425]\n",
      "epoch:30 step:28227 [D loss: 0.447250, acc.: 82.81%] [G loss: 1.677379]\n",
      "epoch:30 step:28228 [D loss: 0.603045, acc.: 71.88%] [G loss: 1.442263]\n",
      "epoch:30 step:28229 [D loss: 0.542314, acc.: 71.09%] [G loss: 1.386734]\n",
      "epoch:30 step:28230 [D loss: 0.660816, acc.: 64.06%] [G loss: 1.608327]\n",
      "epoch:30 step:28231 [D loss: 0.609587, acc.: 66.41%] [G loss: 1.810733]\n",
      "epoch:30 step:28232 [D loss: 0.622459, acc.: 71.09%] [G loss: 1.226982]\n",
      "epoch:30 step:28233 [D loss: 0.354760, acc.: 85.94%] [G loss: 1.607675]\n",
      "epoch:30 step:28234 [D loss: 0.570438, acc.: 67.19%] [G loss: 1.705646]\n",
      "epoch:30 step:28235 [D loss: 0.346251, acc.: 87.50%] [G loss: 1.870282]\n",
      "epoch:30 step:28236 [D loss: 0.550848, acc.: 72.66%] [G loss: 1.702620]\n",
      "epoch:30 step:28237 [D loss: 0.487691, acc.: 75.78%] [G loss: 1.093946]\n",
      "epoch:30 step:28238 [D loss: 0.517935, acc.: 71.09%] [G loss: 1.364281]\n",
      "epoch:30 step:28239 [D loss: 0.508796, acc.: 75.00%] [G loss: 1.639704]\n",
      "epoch:30 step:28240 [D loss: 0.552765, acc.: 68.75%] [G loss: 1.806339]\n",
      "epoch:30 step:28241 [D loss: 0.574941, acc.: 74.22%] [G loss: 1.520709]\n",
      "epoch:30 step:28242 [D loss: 0.563398, acc.: 66.41%] [G loss: 1.095477]\n",
      "epoch:30 step:28243 [D loss: 0.421354, acc.: 78.91%] [G loss: 1.555912]\n",
      "epoch:30 step:28244 [D loss: 0.434169, acc.: 82.03%] [G loss: 1.434856]\n",
      "epoch:30 step:28245 [D loss: 0.574871, acc.: 70.31%] [G loss: 1.210836]\n",
      "epoch:30 step:28246 [D loss: 0.665534, acc.: 62.50%] [G loss: 1.194512]\n",
      "epoch:30 step:28247 [D loss: 0.463407, acc.: 79.69%] [G loss: 1.575104]\n",
      "epoch:30 step:28248 [D loss: 0.546702, acc.: 71.88%] [G loss: 1.205349]\n",
      "epoch:30 step:28249 [D loss: 0.520542, acc.: 73.44%] [G loss: 1.159934]\n",
      "epoch:30 step:28250 [D loss: 0.715310, acc.: 57.03%] [G loss: 1.249382]\n",
      "epoch:30 step:28251 [D loss: 0.490909, acc.: 78.12%] [G loss: 1.634681]\n",
      "epoch:30 step:28252 [D loss: 0.575540, acc.: 71.09%] [G loss: 1.329834]\n",
      "epoch:30 step:28253 [D loss: 0.397394, acc.: 84.38%] [G loss: 1.836918]\n",
      "epoch:30 step:28254 [D loss: 0.610403, acc.: 67.97%] [G loss: 1.214997]\n",
      "epoch:30 step:28255 [D loss: 0.556125, acc.: 71.88%] [G loss: 1.373867]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:30 step:28256 [D loss: 0.549100, acc.: 71.09%] [G loss: 1.179496]\n",
      "epoch:30 step:28257 [D loss: 0.673624, acc.: 60.94%] [G loss: 1.338959]\n",
      "epoch:30 step:28258 [D loss: 0.420398, acc.: 80.47%] [G loss: 1.567071]\n",
      "epoch:30 step:28259 [D loss: 0.523896, acc.: 75.00%] [G loss: 1.589889]\n",
      "epoch:30 step:28260 [D loss: 0.570308, acc.: 67.97%] [G loss: 1.574331]\n",
      "epoch:30 step:28261 [D loss: 0.402014, acc.: 85.16%] [G loss: 1.760299]\n",
      "epoch:30 step:28262 [D loss: 0.513283, acc.: 69.53%] [G loss: 1.709484]\n",
      "epoch:30 step:28263 [D loss: 0.695661, acc.: 60.94%] [G loss: 1.388895]\n",
      "epoch:30 step:28264 [D loss: 0.588391, acc.: 71.88%] [G loss: 1.709896]\n",
      "epoch:30 step:28265 [D loss: 0.709450, acc.: 57.81%] [G loss: 0.882255]\n",
      "epoch:30 step:28266 [D loss: 0.719502, acc.: 57.81%] [G loss: 1.081825]\n",
      "epoch:30 step:28267 [D loss: 0.606208, acc.: 65.62%] [G loss: 1.542365]\n",
      "epoch:30 step:28268 [D loss: 0.683984, acc.: 62.50%] [G loss: 2.188632]\n",
      "epoch:30 step:28269 [D loss: 0.590166, acc.: 68.75%] [G loss: 1.291951]\n",
      "epoch:30 step:28270 [D loss: 0.349149, acc.: 90.62%] [G loss: 1.472554]\n",
      "epoch:30 step:28271 [D loss: 0.517423, acc.: 71.09%] [G loss: 2.237663]\n",
      "epoch:30 step:28272 [D loss: 0.413666, acc.: 88.28%] [G loss: 1.679136]\n",
      "epoch:30 step:28273 [D loss: 0.456886, acc.: 79.69%] [G loss: 1.383492]\n",
      "epoch:30 step:28274 [D loss: 0.539448, acc.: 74.22%] [G loss: 1.409460]\n",
      "epoch:30 step:28275 [D loss: 0.485062, acc.: 78.12%] [G loss: 1.450714]\n",
      "epoch:30 step:28276 [D loss: 0.471647, acc.: 78.91%] [G loss: 1.600285]\n",
      "epoch:30 step:28277 [D loss: 0.456384, acc.: 76.56%] [G loss: 2.031561]\n",
      "epoch:30 step:28278 [D loss: 0.760342, acc.: 53.91%] [G loss: 1.320767]\n",
      "epoch:30 step:28279 [D loss: 0.563988, acc.: 69.53%] [G loss: 1.136284]\n",
      "epoch:30 step:28280 [D loss: 0.381929, acc.: 85.94%] [G loss: 1.735555]\n",
      "epoch:30 step:28281 [D loss: 0.587283, acc.: 64.84%] [G loss: 1.573718]\n",
      "epoch:30 step:28282 [D loss: 0.565439, acc.: 72.66%] [G loss: 1.744521]\n",
      "epoch:30 step:28283 [D loss: 0.595446, acc.: 69.53%] [G loss: 1.324920]\n",
      "epoch:30 step:28284 [D loss: 0.560098, acc.: 69.53%] [G loss: 1.384522]\n",
      "epoch:30 step:28285 [D loss: 0.667513, acc.: 63.28%] [G loss: 1.275657]\n",
      "epoch:30 step:28286 [D loss: 0.585757, acc.: 70.31%] [G loss: 1.681515]\n",
      "epoch:30 step:28287 [D loss: 0.540801, acc.: 75.00%] [G loss: 1.907491]\n",
      "epoch:30 step:28288 [D loss: 0.652024, acc.: 64.06%] [G loss: 1.023085]\n",
      "epoch:30 step:28289 [D loss: 0.480865, acc.: 75.00%] [G loss: 1.171176]\n",
      "epoch:30 step:28290 [D loss: 0.415664, acc.: 85.94%] [G loss: 2.014388]\n",
      "epoch:30 step:28291 [D loss: 0.541559, acc.: 72.66%] [G loss: 1.559118]\n",
      "epoch:30 step:28292 [D loss: 0.540955, acc.: 71.88%] [G loss: 1.502229]\n",
      "epoch:30 step:28293 [D loss: 0.475947, acc.: 75.00%] [G loss: 2.172076]\n",
      "epoch:30 step:28294 [D loss: 0.488961, acc.: 77.34%] [G loss: 1.498209]\n",
      "epoch:30 step:28295 [D loss: 0.391927, acc.: 84.38%] [G loss: 1.598237]\n",
      "epoch:30 step:28296 [D loss: 0.580317, acc.: 72.66%] [G loss: 1.260174]\n",
      "epoch:30 step:28297 [D loss: 0.764166, acc.: 57.81%] [G loss: 1.297910]\n",
      "epoch:30 step:28298 [D loss: 0.471874, acc.: 75.78%] [G loss: 1.628734]\n",
      "epoch:30 step:28299 [D loss: 0.539026, acc.: 71.88%] [G loss: 1.555792]\n",
      "epoch:30 step:28300 [D loss: 0.649610, acc.: 64.84%] [G loss: 1.193743]\n",
      "epoch:30 step:28301 [D loss: 0.691151, acc.: 61.72%] [G loss: 1.774378]\n",
      "epoch:30 step:28302 [D loss: 0.727031, acc.: 55.47%] [G loss: 1.170235]\n",
      "epoch:30 step:28303 [D loss: 0.790854, acc.: 51.56%] [G loss: 1.072783]\n",
      "epoch:30 step:28304 [D loss: 0.511947, acc.: 74.22%] [G loss: 1.138769]\n",
      "epoch:30 step:28305 [D loss: 0.449862, acc.: 83.59%] [G loss: 1.412884]\n",
      "epoch:30 step:28306 [D loss: 0.505535, acc.: 75.78%] [G loss: 1.341273]\n",
      "epoch:30 step:28307 [D loss: 0.545022, acc.: 71.09%] [G loss: 1.774516]\n",
      "epoch:30 step:28308 [D loss: 0.477709, acc.: 81.25%] [G loss: 1.395052]\n",
      "epoch:30 step:28309 [D loss: 0.367548, acc.: 85.94%] [G loss: 1.682989]\n",
      "epoch:30 step:28310 [D loss: 0.575030, acc.: 74.22%] [G loss: 1.544363]\n",
      "epoch:30 step:28311 [D loss: 0.421712, acc.: 81.25%] [G loss: 1.751093]\n",
      "epoch:30 step:28312 [D loss: 0.488249, acc.: 75.00%] [G loss: 1.688184]\n",
      "epoch:30 step:28313 [D loss: 0.495814, acc.: 76.56%] [G loss: 0.971658]\n",
      "epoch:30 step:28314 [D loss: 0.387904, acc.: 84.38%] [G loss: 1.633460]\n",
      "epoch:30 step:28315 [D loss: 0.476968, acc.: 82.03%] [G loss: 1.556734]\n",
      "epoch:30 step:28316 [D loss: 0.488522, acc.: 78.12%] [G loss: 1.668406]\n",
      "epoch:30 step:28317 [D loss: 0.599866, acc.: 66.41%] [G loss: 1.311695]\n",
      "epoch:30 step:28318 [D loss: 0.597020, acc.: 68.75%] [G loss: 1.412067]\n",
      "epoch:30 step:28319 [D loss: 0.503588, acc.: 74.22%] [G loss: 1.332892]\n",
      "epoch:30 step:28320 [D loss: 0.563178, acc.: 69.53%] [G loss: 1.107084]\n",
      "epoch:30 step:28321 [D loss: 0.446950, acc.: 81.25%] [G loss: 2.045643]\n",
      "epoch:30 step:28322 [D loss: 0.560014, acc.: 72.66%] [G loss: 1.699273]\n",
      "epoch:30 step:28323 [D loss: 0.500062, acc.: 76.56%] [G loss: 1.343671]\n",
      "epoch:30 step:28324 [D loss: 0.614305, acc.: 67.97%] [G loss: 1.154287]\n",
      "epoch:30 step:28325 [D loss: 0.612339, acc.: 64.84%] [G loss: 1.356987]\n",
      "epoch:30 step:28326 [D loss: 0.588923, acc.: 67.19%] [G loss: 1.217934]\n",
      "epoch:30 step:28327 [D loss: 0.620286, acc.: 66.41%] [G loss: 1.508783]\n",
      "epoch:30 step:28328 [D loss: 0.484104, acc.: 75.78%] [G loss: 1.548400]\n",
      "epoch:30 step:28329 [D loss: 0.451580, acc.: 76.56%] [G loss: 1.520601]\n",
      "epoch:30 step:28330 [D loss: 0.523424, acc.: 71.88%] [G loss: 1.406760]\n",
      "epoch:30 step:28331 [D loss: 0.721501, acc.: 60.94%] [G loss: 1.224595]\n",
      "epoch:30 step:28332 [D loss: 0.607105, acc.: 69.53%] [G loss: 1.354773]\n",
      "epoch:30 step:28333 [D loss: 0.455267, acc.: 79.69%] [G loss: 1.567243]\n",
      "epoch:30 step:28334 [D loss: 0.639391, acc.: 60.94%] [G loss: 1.236892]\n",
      "epoch:30 step:28335 [D loss: 0.478380, acc.: 78.91%] [G loss: 1.732320]\n",
      "epoch:30 step:28336 [D loss: 0.398623, acc.: 80.47%] [G loss: 1.992644]\n",
      "epoch:30 step:28337 [D loss: 0.574060, acc.: 71.88%] [G loss: 1.229318]\n",
      "epoch:30 step:28338 [D loss: 0.494161, acc.: 77.34%] [G loss: 1.273304]\n",
      "epoch:30 step:28339 [D loss: 0.546453, acc.: 70.31%] [G loss: 1.253563]\n",
      "epoch:30 step:28340 [D loss: 0.528810, acc.: 75.00%] [G loss: 1.789735]\n",
      "epoch:30 step:28341 [D loss: 0.481835, acc.: 77.34%] [G loss: 1.066073]\n",
      "epoch:30 step:28342 [D loss: 0.506459, acc.: 74.22%] [G loss: 1.219925]\n",
      "epoch:30 step:28343 [D loss: 0.817023, acc.: 49.22%] [G loss: 0.916539]\n",
      "epoch:30 step:28344 [D loss: 0.574388, acc.: 70.31%] [G loss: 1.363198]\n",
      "epoch:30 step:28345 [D loss: 0.621463, acc.: 69.53%] [G loss: 1.227151]\n",
      "epoch:30 step:28346 [D loss: 0.473103, acc.: 79.69%] [G loss: 1.086506]\n",
      "epoch:30 step:28347 [D loss: 0.602846, acc.: 67.97%] [G loss: 1.098992]\n",
      "epoch:30 step:28348 [D loss: 0.591546, acc.: 66.41%] [G loss: 1.811149]\n",
      "epoch:30 step:28349 [D loss: 0.528941, acc.: 70.31%] [G loss: 1.585091]\n",
      "epoch:30 step:28350 [D loss: 0.536522, acc.: 71.09%] [G loss: 1.943617]\n",
      "epoch:30 step:28351 [D loss: 0.494791, acc.: 75.00%] [G loss: 1.395133]\n",
      "epoch:30 step:28352 [D loss: 0.515515, acc.: 75.78%] [G loss: 1.071403]\n",
      "epoch:30 step:28353 [D loss: 0.623497, acc.: 64.06%] [G loss: 1.401876]\n",
      "epoch:30 step:28354 [D loss: 0.427615, acc.: 82.81%] [G loss: 1.564589]\n",
      "epoch:30 step:28355 [D loss: 0.641355, acc.: 66.41%] [G loss: 1.393642]\n",
      "epoch:30 step:28356 [D loss: 0.483234, acc.: 75.78%] [G loss: 1.382170]\n",
      "epoch:30 step:28357 [D loss: 0.490549, acc.: 75.78%] [G loss: 1.436179]\n",
      "epoch:30 step:28358 [D loss: 0.572722, acc.: 71.88%] [G loss: 1.120219]\n",
      "epoch:30 step:28359 [D loss: 0.612045, acc.: 68.75%] [G loss: 0.889742]\n",
      "epoch:30 step:28360 [D loss: 0.575455, acc.: 65.62%] [G loss: 1.339454]\n",
      "epoch:30 step:28361 [D loss: 0.738608, acc.: 51.56%] [G loss: 1.169845]\n",
      "epoch:30 step:28362 [D loss: 0.366808, acc.: 85.16%] [G loss: 1.722334]\n",
      "epoch:30 step:28363 [D loss: 0.625989, acc.: 66.41%] [G loss: 1.441297]\n",
      "epoch:30 step:28364 [D loss: 0.528760, acc.: 75.78%] [G loss: 1.747235]\n",
      "epoch:30 step:28365 [D loss: 0.583675, acc.: 71.09%] [G loss: 1.379909]\n",
      "epoch:30 step:28366 [D loss: 0.652556, acc.: 64.06%] [G loss: 1.493053]\n",
      "epoch:30 step:28367 [D loss: 0.408094, acc.: 83.59%] [G loss: 1.434515]\n",
      "epoch:30 step:28368 [D loss: 0.728426, acc.: 57.03%] [G loss: 1.365516]\n",
      "epoch:30 step:28369 [D loss: 0.576218, acc.: 72.66%] [G loss: 1.893794]\n",
      "epoch:30 step:28370 [D loss: 0.600265, acc.: 62.50%] [G loss: 1.067200]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:30 step:28371 [D loss: 0.494216, acc.: 75.00%] [G loss: 1.549627]\n",
      "epoch:30 step:28372 [D loss: 0.564573, acc.: 71.09%] [G loss: 1.443569]\n",
      "epoch:30 step:28373 [D loss: 0.507710, acc.: 75.78%] [G loss: 1.841297]\n",
      "epoch:30 step:28374 [D loss: 0.465489, acc.: 79.69%] [G loss: 1.547898]\n",
      "epoch:30 step:28375 [D loss: 0.339935, acc.: 89.84%] [G loss: 1.629363]\n",
      "epoch:30 step:28376 [D loss: 0.562835, acc.: 64.06%] [G loss: 1.461286]\n",
      "epoch:30 step:28377 [D loss: 0.444105, acc.: 77.34%] [G loss: 1.802490]\n",
      "epoch:30 step:28378 [D loss: 0.404687, acc.: 82.81%] [G loss: 1.633114]\n",
      "epoch:30 step:28379 [D loss: 0.484234, acc.: 81.25%] [G loss: 1.689283]\n",
      "epoch:30 step:28380 [D loss: 0.415114, acc.: 82.81%] [G loss: 1.203635]\n",
      "epoch:30 step:28381 [D loss: 0.504011, acc.: 75.78%] [G loss: 1.430614]\n",
      "epoch:30 step:28382 [D loss: 0.508359, acc.: 78.12%] [G loss: 1.562399]\n",
      "epoch:30 step:28383 [D loss: 0.598122, acc.: 67.19%] [G loss: 1.969803]\n",
      "epoch:30 step:28384 [D loss: 0.442287, acc.: 80.47%] [G loss: 1.732626]\n",
      "epoch:30 step:28385 [D loss: 0.820926, acc.: 53.91%] [G loss: 1.373515]\n",
      "epoch:30 step:28386 [D loss: 0.636060, acc.: 65.62%] [G loss: 1.144462]\n",
      "epoch:30 step:28387 [D loss: 0.572682, acc.: 68.75%] [G loss: 1.441272]\n",
      "epoch:30 step:28388 [D loss: 0.499932, acc.: 77.34%] [G loss: 1.503191]\n",
      "epoch:30 step:28389 [D loss: 0.423934, acc.: 82.81%] [G loss: 1.637793]\n",
      "epoch:30 step:28390 [D loss: 0.590055, acc.: 64.84%] [G loss: 0.931811]\n",
      "epoch:30 step:28391 [D loss: 0.509924, acc.: 75.78%] [G loss: 1.238022]\n",
      "epoch:30 step:28392 [D loss: 0.469341, acc.: 77.34%] [G loss: 2.010419]\n",
      "epoch:30 step:28393 [D loss: 0.477204, acc.: 77.34%] [G loss: 1.626379]\n",
      "epoch:30 step:28394 [D loss: 0.549437, acc.: 71.09%] [G loss: 1.425065]\n",
      "epoch:30 step:28395 [D loss: 0.426917, acc.: 82.03%] [G loss: 1.078508]\n",
      "epoch:30 step:28396 [D loss: 0.591536, acc.: 68.75%] [G loss: 1.255115]\n",
      "epoch:30 step:28397 [D loss: 0.406531, acc.: 82.81%] [G loss: 1.901489]\n",
      "epoch:30 step:28398 [D loss: 0.531134, acc.: 75.78%] [G loss: 1.518885]\n",
      "epoch:30 step:28399 [D loss: 0.600518, acc.: 69.53%] [G loss: 1.585547]\n",
      "epoch:30 step:28400 [D loss: 0.387610, acc.: 83.59%] [G loss: 1.562970]\n",
      "epoch:30 step:28401 [D loss: 0.753810, acc.: 54.69%] [G loss: 1.234167]\n",
      "epoch:30 step:28402 [D loss: 0.521097, acc.: 76.56%] [G loss: 1.356291]\n",
      "epoch:30 step:28403 [D loss: 0.740611, acc.: 57.81%] [G loss: 1.333403]\n",
      "epoch:30 step:28404 [D loss: 0.620791, acc.: 65.62%] [G loss: 1.158754]\n",
      "epoch:30 step:28405 [D loss: 0.507168, acc.: 74.22%] [G loss: 1.869440]\n",
      "epoch:30 step:28406 [D loss: 0.548511, acc.: 72.66%] [G loss: 1.302879]\n",
      "epoch:30 step:28407 [D loss: 0.686991, acc.: 64.84%] [G loss: 1.696578]\n",
      "epoch:30 step:28408 [D loss: 0.945729, acc.: 41.41%] [G loss: 1.630844]\n",
      "epoch:30 step:28409 [D loss: 0.598146, acc.: 72.66%] [G loss: 1.091515]\n",
      "epoch:30 step:28410 [D loss: 0.549619, acc.: 74.22%] [G loss: 1.302932]\n",
      "epoch:30 step:28411 [D loss: 0.781531, acc.: 54.69%] [G loss: 1.774773]\n",
      "epoch:30 step:28412 [D loss: 0.676735, acc.: 60.94%] [G loss: 1.179397]\n",
      "epoch:30 step:28413 [D loss: 0.609443, acc.: 67.19%] [G loss: 1.475638]\n",
      "epoch:30 step:28414 [D loss: 0.621566, acc.: 65.62%] [G loss: 1.511122]\n",
      "epoch:30 step:28415 [D loss: 0.624133, acc.: 67.97%] [G loss: 1.268196]\n",
      "epoch:30 step:28416 [D loss: 0.602887, acc.: 66.41%] [G loss: 1.611503]\n",
      "epoch:30 step:28417 [D loss: 0.686844, acc.: 66.41%] [G loss: 1.595386]\n",
      "epoch:30 step:28418 [D loss: 0.511616, acc.: 81.25%] [G loss: 1.484684]\n",
      "epoch:30 step:28419 [D loss: 0.467974, acc.: 76.56%] [G loss: 1.468737]\n",
      "epoch:30 step:28420 [D loss: 0.675717, acc.: 64.06%] [G loss: 1.251092]\n",
      "epoch:30 step:28421 [D loss: 0.473431, acc.: 78.91%] [G loss: 1.365285]\n",
      "epoch:30 step:28422 [D loss: 0.800579, acc.: 55.47%] [G loss: 1.214387]\n",
      "epoch:30 step:28423 [D loss: 0.474965, acc.: 78.91%] [G loss: 1.740006]\n",
      "epoch:30 step:28424 [D loss: 0.470788, acc.: 81.25%] [G loss: 1.828883]\n",
      "epoch:30 step:28425 [D loss: 0.672384, acc.: 64.84%] [G loss: 1.107264]\n",
      "epoch:30 step:28426 [D loss: 0.505181, acc.: 75.78%] [G loss: 1.810098]\n",
      "epoch:30 step:28427 [D loss: 0.633973, acc.: 64.06%] [G loss: 1.481642]\n",
      "epoch:30 step:28428 [D loss: 0.433391, acc.: 84.38%] [G loss: 1.550408]\n",
      "epoch:30 step:28429 [D loss: 0.459096, acc.: 81.25%] [G loss: 1.752630]\n",
      "epoch:30 step:28430 [D loss: 0.585706, acc.: 66.41%] [G loss: 1.340931]\n",
      "epoch:30 step:28431 [D loss: 0.451984, acc.: 79.69%] [G loss: 1.413239]\n",
      "epoch:30 step:28432 [D loss: 0.511514, acc.: 75.00%] [G loss: 1.389003]\n",
      "epoch:30 step:28433 [D loss: 0.652945, acc.: 66.41%] [G loss: 1.070397]\n",
      "epoch:30 step:28434 [D loss: 0.457537, acc.: 74.22%] [G loss: 1.405611]\n",
      "epoch:30 step:28435 [D loss: 0.603271, acc.: 68.75%] [G loss: 0.993845]\n",
      "epoch:30 step:28436 [D loss: 0.487762, acc.: 78.91%] [G loss: 1.252922]\n",
      "epoch:30 step:28437 [D loss: 0.558184, acc.: 72.66%] [G loss: 1.380057]\n",
      "epoch:30 step:28438 [D loss: 0.421632, acc.: 82.81%] [G loss: 1.327977]\n",
      "epoch:30 step:28439 [D loss: 0.475213, acc.: 75.00%] [G loss: 1.636545]\n",
      "epoch:30 step:28440 [D loss: 0.681702, acc.: 60.16%] [G loss: 1.138754]\n",
      "epoch:30 step:28441 [D loss: 0.554614, acc.: 71.88%] [G loss: 1.807056]\n",
      "epoch:30 step:28442 [D loss: 0.466845, acc.: 79.69%] [G loss: 1.502041]\n",
      "epoch:30 step:28443 [D loss: 0.465507, acc.: 76.56%] [G loss: 1.043240]\n",
      "epoch:30 step:28444 [D loss: 0.604947, acc.: 68.75%] [G loss: 1.344816]\n",
      "epoch:30 step:28445 [D loss: 0.420061, acc.: 82.81%] [G loss: 1.869895]\n",
      "epoch:30 step:28446 [D loss: 0.485552, acc.: 77.34%] [G loss: 1.647143]\n",
      "epoch:30 step:28447 [D loss: 0.605001, acc.: 64.06%] [G loss: 1.177287]\n",
      "epoch:30 step:28448 [D loss: 0.361710, acc.: 86.72%] [G loss: 1.604412]\n",
      "epoch:30 step:28449 [D loss: 0.513340, acc.: 73.44%] [G loss: 1.796355]\n",
      "epoch:30 step:28450 [D loss: 0.552417, acc.: 73.44%] [G loss: 1.384028]\n",
      "epoch:30 step:28451 [D loss: 0.537094, acc.: 76.56%] [G loss: 1.704145]\n",
      "epoch:30 step:28452 [D loss: 0.645918, acc.: 64.84%] [G loss: 1.383309]\n",
      "epoch:30 step:28453 [D loss: 0.677767, acc.: 64.06%] [G loss: 1.609123]\n",
      "epoch:30 step:28454 [D loss: 0.540305, acc.: 75.78%] [G loss: 1.569998]\n",
      "epoch:30 step:28455 [D loss: 0.434274, acc.: 82.03%] [G loss: 1.315448]\n",
      "epoch:30 step:28456 [D loss: 0.552418, acc.: 70.31%] [G loss: 1.238624]\n",
      "epoch:30 step:28457 [D loss: 0.542030, acc.: 72.66%] [G loss: 1.295061]\n",
      "epoch:30 step:28458 [D loss: 0.609025, acc.: 69.53%] [G loss: 1.538396]\n",
      "epoch:30 step:28459 [D loss: 0.468988, acc.: 82.03%] [G loss: 1.275892]\n",
      "epoch:30 step:28460 [D loss: 0.610066, acc.: 67.97%] [G loss: 1.101941]\n",
      "epoch:30 step:28461 [D loss: 0.631427, acc.: 67.19%] [G loss: 1.246896]\n",
      "epoch:30 step:28462 [D loss: 0.601079, acc.: 69.53%] [G loss: 1.520195]\n",
      "epoch:30 step:28463 [D loss: 0.616702, acc.: 60.16%] [G loss: 1.717707]\n",
      "epoch:30 step:28464 [D loss: 0.495307, acc.: 77.34%] [G loss: 1.340440]\n",
      "epoch:30 step:28465 [D loss: 0.406262, acc.: 84.38%] [G loss: 1.625543]\n",
      "epoch:30 step:28466 [D loss: 0.647852, acc.: 63.28%] [G loss: 1.403524]\n",
      "epoch:30 step:28467 [D loss: 0.637388, acc.: 63.28%] [G loss: 1.243734]\n",
      "epoch:30 step:28468 [D loss: 0.773229, acc.: 49.22%] [G loss: 1.241306]\n",
      "epoch:30 step:28469 [D loss: 0.730665, acc.: 53.12%] [G loss: 1.371963]\n",
      "epoch:30 step:28470 [D loss: 0.481676, acc.: 75.78%] [G loss: 1.491465]\n",
      "epoch:30 step:28471 [D loss: 0.461796, acc.: 79.69%] [G loss: 1.334846]\n",
      "epoch:30 step:28472 [D loss: 0.484041, acc.: 78.12%] [G loss: 1.286938]\n",
      "epoch:30 step:28473 [D loss: 0.645303, acc.: 62.50%] [G loss: 1.053995]\n",
      "epoch:30 step:28474 [D loss: 0.635378, acc.: 64.06%] [G loss: 1.327548]\n",
      "epoch:30 step:28475 [D loss: 0.511297, acc.: 72.66%] [G loss: 1.240436]\n",
      "epoch:30 step:28476 [D loss: 0.477593, acc.: 77.34%] [G loss: 1.529842]\n",
      "epoch:30 step:28477 [D loss: 0.502844, acc.: 75.78%] [G loss: 1.959097]\n",
      "epoch:30 step:28478 [D loss: 0.494854, acc.: 80.47%] [G loss: 1.255527]\n",
      "epoch:30 step:28479 [D loss: 0.406106, acc.: 82.81%] [G loss: 2.063081]\n",
      "epoch:30 step:28480 [D loss: 0.586368, acc.: 65.62%] [G loss: 1.505126]\n",
      "epoch:30 step:28481 [D loss: 0.355185, acc.: 87.50%] [G loss: 1.729405]\n",
      "epoch:30 step:28482 [D loss: 0.582785, acc.: 67.97%] [G loss: 1.480419]\n",
      "epoch:30 step:28483 [D loss: 0.689711, acc.: 59.38%] [G loss: 1.805585]\n",
      "epoch:30 step:28484 [D loss: 0.643564, acc.: 67.19%] [G loss: 1.623042]\n",
      "epoch:30 step:28485 [D loss: 0.523410, acc.: 73.44%] [G loss: 1.687700]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:30 step:28486 [D loss: 0.708796, acc.: 58.59%] [G loss: 1.360994]\n",
      "epoch:30 step:28487 [D loss: 0.447104, acc.: 78.91%] [G loss: 1.237404]\n",
      "epoch:30 step:28488 [D loss: 0.545407, acc.: 71.88%] [G loss: 1.955061]\n",
      "epoch:30 step:28489 [D loss: 0.588734, acc.: 68.75%] [G loss: 1.566646]\n",
      "epoch:30 step:28490 [D loss: 0.406167, acc.: 81.25%] [G loss: 1.222993]\n",
      "epoch:30 step:28491 [D loss: 0.465551, acc.: 79.69%] [G loss: 1.753579]\n",
      "epoch:30 step:28492 [D loss: 0.557455, acc.: 75.00%] [G loss: 1.292299]\n",
      "epoch:30 step:28493 [D loss: 0.459857, acc.: 78.12%] [G loss: 1.918840]\n",
      "epoch:30 step:28494 [D loss: 0.609876, acc.: 62.50%] [G loss: 1.334483]\n",
      "epoch:30 step:28495 [D loss: 0.501236, acc.: 71.09%] [G loss: 1.483244]\n",
      "epoch:30 step:28496 [D loss: 0.548654, acc.: 74.22%] [G loss: 1.341982]\n",
      "epoch:30 step:28497 [D loss: 0.432070, acc.: 81.25%] [G loss: 1.082191]\n",
      "epoch:30 step:28498 [D loss: 0.688798, acc.: 66.41%] [G loss: 1.216598]\n",
      "epoch:30 step:28499 [D loss: 0.506943, acc.: 74.22%] [G loss: 1.104035]\n",
      "epoch:30 step:28500 [D loss: 0.583488, acc.: 71.09%] [G loss: 1.430739]\n",
      "epoch:30 step:28501 [D loss: 0.479797, acc.: 80.47%] [G loss: 1.327289]\n",
      "epoch:30 step:28502 [D loss: 0.533534, acc.: 74.22%] [G loss: 1.440660]\n",
      "epoch:30 step:28503 [D loss: 0.615842, acc.: 69.53%] [G loss: 1.499121]\n",
      "epoch:30 step:28504 [D loss: 0.438016, acc.: 83.59%] [G loss: 1.619956]\n",
      "epoch:30 step:28505 [D loss: 0.439240, acc.: 79.69%] [G loss: 1.371684]\n",
      "epoch:30 step:28506 [D loss: 0.634210, acc.: 65.62%] [G loss: 1.254189]\n",
      "epoch:30 step:28507 [D loss: 0.463880, acc.: 79.69%] [G loss: 1.447019]\n",
      "epoch:30 step:28508 [D loss: 0.460075, acc.: 78.12%] [G loss: 1.922208]\n",
      "epoch:30 step:28509 [D loss: 0.498408, acc.: 71.88%] [G loss: 1.331675]\n",
      "epoch:30 step:28510 [D loss: 0.387241, acc.: 87.50%] [G loss: 1.360353]\n",
      "epoch:30 step:28511 [D loss: 0.624995, acc.: 63.28%] [G loss: 1.333898]\n",
      "epoch:30 step:28512 [D loss: 0.404033, acc.: 83.59%] [G loss: 1.609967]\n",
      "epoch:30 step:28513 [D loss: 0.651407, acc.: 64.06%] [G loss: 1.272413]\n",
      "epoch:30 step:28514 [D loss: 0.486335, acc.: 78.12%] [G loss: 1.161990]\n",
      "epoch:30 step:28515 [D loss: 0.452096, acc.: 78.91%] [G loss: 1.605836]\n",
      "epoch:30 step:28516 [D loss: 0.445823, acc.: 79.69%] [G loss: 1.079071]\n",
      "epoch:30 step:28517 [D loss: 0.718785, acc.: 58.59%] [G loss: 1.026454]\n",
      "epoch:30 step:28518 [D loss: 0.399909, acc.: 80.47%] [G loss: 1.412094]\n",
      "epoch:30 step:28519 [D loss: 0.486118, acc.: 78.12%] [G loss: 1.377449]\n",
      "epoch:30 step:28520 [D loss: 0.545268, acc.: 75.78%] [G loss: 1.019251]\n",
      "epoch:30 step:28521 [D loss: 0.441906, acc.: 77.34%] [G loss: 2.040403]\n",
      "epoch:30 step:28522 [D loss: 0.830068, acc.: 53.12%] [G loss: 1.376686]\n",
      "epoch:30 step:28523 [D loss: 0.590792, acc.: 70.31%] [G loss: 1.405161]\n",
      "epoch:30 step:28524 [D loss: 0.622613, acc.: 66.41%] [G loss: 1.437002]\n",
      "epoch:30 step:28525 [D loss: 0.527264, acc.: 75.00%] [G loss: 1.344012]\n",
      "epoch:30 step:28526 [D loss: 0.499216, acc.: 76.56%] [G loss: 1.421097]\n",
      "epoch:30 step:28527 [D loss: 0.540407, acc.: 69.53%] [G loss: 1.725696]\n",
      "epoch:30 step:28528 [D loss: 0.587261, acc.: 67.97%] [G loss: 1.590207]\n",
      "epoch:30 step:28529 [D loss: 0.417932, acc.: 81.25%] [G loss: 1.560297]\n",
      "epoch:30 step:28530 [D loss: 0.565237, acc.: 72.66%] [G loss: 1.327382]\n",
      "epoch:30 step:28531 [D loss: 0.765144, acc.: 51.56%] [G loss: 1.151408]\n",
      "epoch:30 step:28532 [D loss: 0.577055, acc.: 69.53%] [G loss: 1.615389]\n",
      "epoch:30 step:28533 [D loss: 0.535863, acc.: 73.44%] [G loss: 1.664324]\n",
      "epoch:30 step:28534 [D loss: 0.492976, acc.: 75.78%] [G loss: 1.582887]\n",
      "epoch:30 step:28535 [D loss: 0.650784, acc.: 61.72%] [G loss: 1.108462]\n",
      "epoch:30 step:28536 [D loss: 0.707567, acc.: 64.06%] [G loss: 1.643156]\n",
      "epoch:30 step:28537 [D loss: 0.637913, acc.: 64.84%] [G loss: 1.308098]\n",
      "epoch:30 step:28538 [D loss: 0.671886, acc.: 64.06%] [G loss: 1.610132]\n",
      "epoch:30 step:28539 [D loss: 0.500974, acc.: 72.66%] [G loss: 1.872410]\n",
      "epoch:30 step:28540 [D loss: 0.507996, acc.: 77.34%] [G loss: 1.463610]\n",
      "epoch:30 step:28541 [D loss: 0.482960, acc.: 74.22%] [G loss: 1.501176]\n",
      "epoch:30 step:28542 [D loss: 0.690427, acc.: 60.16%] [G loss: 1.299713]\n",
      "epoch:30 step:28543 [D loss: 0.440406, acc.: 80.47%] [G loss: 1.360670]\n",
      "epoch:30 step:28544 [D loss: 0.531980, acc.: 73.44%] [G loss: 1.416550]\n",
      "epoch:30 step:28545 [D loss: 0.554119, acc.: 74.22%] [G loss: 1.176142]\n",
      "epoch:30 step:28546 [D loss: 0.548130, acc.: 70.31%] [G loss: 1.614651]\n",
      "epoch:30 step:28547 [D loss: 0.632723, acc.: 63.28%] [G loss: 1.112350]\n",
      "epoch:30 step:28548 [D loss: 0.623090, acc.: 70.31%] [G loss: 1.096393]\n",
      "epoch:30 step:28549 [D loss: 0.685337, acc.: 63.28%] [G loss: 1.349234]\n",
      "epoch:30 step:28550 [D loss: 0.406423, acc.: 85.16%] [G loss: 1.764382]\n",
      "epoch:30 step:28551 [D loss: 0.381008, acc.: 86.72%] [G loss: 1.720520]\n",
      "epoch:30 step:28552 [D loss: 0.668366, acc.: 66.41%] [G loss: 0.925906]\n",
      "epoch:30 step:28553 [D loss: 0.491597, acc.: 72.66%] [G loss: 1.302555]\n",
      "epoch:30 step:28554 [D loss: 0.590441, acc.: 63.28%] [G loss: 0.942739]\n",
      "epoch:30 step:28555 [D loss: 0.562022, acc.: 69.53%] [G loss: 1.500687]\n",
      "epoch:30 step:28556 [D loss: 0.456309, acc.: 81.25%] [G loss: 1.433519]\n",
      "epoch:30 step:28557 [D loss: 0.472237, acc.: 74.22%] [G loss: 1.277714]\n",
      "epoch:30 step:28558 [D loss: 0.428810, acc.: 82.81%] [G loss: 1.491428]\n",
      "epoch:30 step:28559 [D loss: 0.503834, acc.: 77.34%] [G loss: 1.401940]\n",
      "epoch:30 step:28560 [D loss: 0.593345, acc.: 67.19%] [G loss: 1.563549]\n",
      "epoch:30 step:28561 [D loss: 0.456393, acc.: 82.03%] [G loss: 1.812778]\n",
      "epoch:30 step:28562 [D loss: 0.542710, acc.: 68.75%] [G loss: 1.364040]\n",
      "epoch:30 step:28563 [D loss: 0.538415, acc.: 75.00%] [G loss: 2.292801]\n",
      "epoch:30 step:28564 [D loss: 0.515862, acc.: 76.56%] [G loss: 1.408754]\n",
      "epoch:30 step:28565 [D loss: 0.493426, acc.: 77.34%] [G loss: 1.421879]\n",
      "epoch:30 step:28566 [D loss: 0.629670, acc.: 67.97%] [G loss: 1.009094]\n",
      "epoch:30 step:28567 [D loss: 0.345304, acc.: 93.75%] [G loss: 1.155054]\n",
      "epoch:30 step:28568 [D loss: 0.358144, acc.: 86.72%] [G loss: 1.791486]\n",
      "epoch:30 step:28569 [D loss: 0.367802, acc.: 87.50%] [G loss: 1.601470]\n",
      "epoch:30 step:28570 [D loss: 0.532827, acc.: 67.19%] [G loss: 1.757024]\n",
      "epoch:30 step:28571 [D loss: 0.660484, acc.: 67.97%] [G loss: 1.443831]\n",
      "epoch:30 step:28572 [D loss: 0.650434, acc.: 60.16%] [G loss: 1.463349]\n",
      "epoch:30 step:28573 [D loss: 0.751961, acc.: 57.03%] [G loss: 1.512842]\n",
      "epoch:30 step:28574 [D loss: 0.514039, acc.: 78.12%] [G loss: 1.176146]\n",
      "epoch:30 step:28575 [D loss: 0.463720, acc.: 78.12%] [G loss: 1.492468]\n",
      "epoch:30 step:28576 [D loss: 0.531169, acc.: 75.78%] [G loss: 1.467280]\n",
      "epoch:30 step:28577 [D loss: 0.659855, acc.: 64.84%] [G loss: 1.164625]\n",
      "epoch:30 step:28578 [D loss: 0.457701, acc.: 76.56%] [G loss: 1.774719]\n",
      "epoch:30 step:28579 [D loss: 0.480424, acc.: 76.56%] [G loss: 1.575606]\n",
      "epoch:30 step:28580 [D loss: 0.770035, acc.: 55.47%] [G loss: 1.011555]\n",
      "epoch:30 step:28581 [D loss: 0.679760, acc.: 63.28%] [G loss: 1.193612]\n",
      "epoch:30 step:28582 [D loss: 0.540464, acc.: 74.22%] [G loss: 1.605784]\n",
      "epoch:30 step:28583 [D loss: 0.494659, acc.: 74.22%] [G loss: 1.506091]\n",
      "epoch:30 step:28584 [D loss: 0.640936, acc.: 60.94%] [G loss: 0.947157]\n",
      "epoch:30 step:28585 [D loss: 0.495501, acc.: 79.69%] [G loss: 1.544141]\n",
      "epoch:30 step:28586 [D loss: 0.491166, acc.: 74.22%] [G loss: 1.304430]\n",
      "epoch:30 step:28587 [D loss: 0.517267, acc.: 78.91%] [G loss: 1.673269]\n",
      "epoch:30 step:28588 [D loss: 0.461405, acc.: 77.34%] [G loss: 1.604435]\n",
      "epoch:30 step:28589 [D loss: 0.547268, acc.: 71.88%] [G loss: 1.348325]\n",
      "epoch:30 step:28590 [D loss: 0.482317, acc.: 79.69%] [G loss: 1.142846]\n",
      "epoch:30 step:28591 [D loss: 0.503505, acc.: 78.91%] [G loss: 1.368729]\n",
      "epoch:30 step:28592 [D loss: 0.504452, acc.: 74.22%] [G loss: 1.072679]\n",
      "epoch:30 step:28593 [D loss: 0.791428, acc.: 53.91%] [G loss: 1.412634]\n",
      "epoch:30 step:28594 [D loss: 0.448190, acc.: 78.91%] [G loss: 1.692778]\n",
      "epoch:30 step:28595 [D loss: 0.439248, acc.: 78.91%] [G loss: 1.613995]\n",
      "epoch:30 step:28596 [D loss: 0.499380, acc.: 79.69%] [G loss: 1.221895]\n",
      "epoch:30 step:28597 [D loss: 0.684946, acc.: 65.62%] [G loss: 1.740234]\n",
      "epoch:30 step:28598 [D loss: 0.525592, acc.: 74.22%] [G loss: 1.199644]\n",
      "epoch:30 step:28599 [D loss: 0.470859, acc.: 74.22%] [G loss: 1.524438]\n",
      "epoch:30 step:28600 [D loss: 0.422198, acc.: 83.59%] [G loss: 2.009804]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:30 step:28601 [D loss: 0.679995, acc.: 62.50%] [G loss: 1.719322]\n",
      "epoch:30 step:28602 [D loss: 0.566451, acc.: 72.66%] [G loss: 1.563164]\n",
      "epoch:30 step:28603 [D loss: 0.432048, acc.: 78.12%] [G loss: 1.671305]\n",
      "epoch:30 step:28604 [D loss: 0.801128, acc.: 50.00%] [G loss: 0.877154]\n",
      "epoch:30 step:28605 [D loss: 0.600381, acc.: 66.41%] [G loss: 0.938472]\n",
      "epoch:30 step:28606 [D loss: 0.518944, acc.: 75.00%] [G loss: 1.251594]\n",
      "epoch:30 step:28607 [D loss: 0.680732, acc.: 62.50%] [G loss: 1.369785]\n",
      "epoch:30 step:28608 [D loss: 0.514109, acc.: 75.78%] [G loss: 1.499469]\n",
      "epoch:30 step:28609 [D loss: 0.616965, acc.: 67.19%] [G loss: 1.466579]\n",
      "epoch:30 step:28610 [D loss: 0.507999, acc.: 75.78%] [G loss: 1.654026]\n",
      "epoch:30 step:28611 [D loss: 0.538058, acc.: 73.44%] [G loss: 1.680550]\n",
      "epoch:30 step:28612 [D loss: 0.490046, acc.: 83.59%] [G loss: 1.638385]\n",
      "epoch:30 step:28613 [D loss: 0.357393, acc.: 91.41%] [G loss: 1.703464]\n",
      "epoch:30 step:28614 [D loss: 0.506343, acc.: 74.22%] [G loss: 1.271849]\n",
      "epoch:30 step:28615 [D loss: 0.554384, acc.: 72.66%] [G loss: 1.577198]\n",
      "epoch:30 step:28616 [D loss: 0.474619, acc.: 78.12%] [G loss: 1.585997]\n",
      "epoch:30 step:28617 [D loss: 0.626079, acc.: 66.41%] [G loss: 1.778715]\n",
      "epoch:30 step:28618 [D loss: 0.400991, acc.: 83.59%] [G loss: 1.880698]\n",
      "epoch:30 step:28619 [D loss: 0.535537, acc.: 73.44%] [G loss: 1.192214]\n",
      "epoch:30 step:28620 [D loss: 0.649801, acc.: 67.19%] [G loss: 1.199229]\n",
      "epoch:30 step:28621 [D loss: 0.532986, acc.: 75.00%] [G loss: 1.818300]\n",
      "epoch:30 step:28622 [D loss: 0.489457, acc.: 73.44%] [G loss: 1.348217]\n",
      "epoch:30 step:28623 [D loss: 0.385518, acc.: 86.72%] [G loss: 1.537723]\n",
      "epoch:30 step:28624 [D loss: 0.474596, acc.: 74.22%] [G loss: 1.479446]\n",
      "epoch:30 step:28625 [D loss: 0.439480, acc.: 81.25%] [G loss: 1.419778]\n",
      "epoch:30 step:28626 [D loss: 0.426497, acc.: 84.38%] [G loss: 1.405901]\n",
      "epoch:30 step:28627 [D loss: 0.433965, acc.: 82.03%] [G loss: 1.455317]\n",
      "epoch:30 step:28628 [D loss: 0.545905, acc.: 75.00%] [G loss: 1.796535]\n",
      "epoch:30 step:28629 [D loss: 0.513072, acc.: 74.22%] [G loss: 1.967802]\n",
      "epoch:30 step:28630 [D loss: 0.533612, acc.: 71.88%] [G loss: 1.395940]\n",
      "epoch:30 step:28631 [D loss: 0.594553, acc.: 68.75%] [G loss: 1.340589]\n",
      "epoch:30 step:28632 [D loss: 0.766210, acc.: 55.47%] [G loss: 1.464217]\n",
      "epoch:30 step:28633 [D loss: 0.452887, acc.: 81.25%] [G loss: 1.604574]\n",
      "epoch:30 step:28634 [D loss: 0.453999, acc.: 77.34%] [G loss: 1.702480]\n",
      "epoch:30 step:28635 [D loss: 0.512884, acc.: 75.00%] [G loss: 1.444110]\n",
      "epoch:30 step:28636 [D loss: 0.676929, acc.: 61.72%] [G loss: 1.177135]\n",
      "epoch:30 step:28637 [D loss: 0.581711, acc.: 68.75%] [G loss: 1.346813]\n",
      "epoch:30 step:28638 [D loss: 0.600995, acc.: 71.09%] [G loss: 1.234812]\n",
      "epoch:30 step:28639 [D loss: 0.426654, acc.: 85.16%] [G loss: 1.923628]\n",
      "epoch:30 step:28640 [D loss: 0.517537, acc.: 71.88%] [G loss: 1.441917]\n",
      "epoch:30 step:28641 [D loss: 0.533310, acc.: 75.00%] [G loss: 1.756738]\n",
      "epoch:30 step:28642 [D loss: 0.483569, acc.: 78.12%] [G loss: 1.704268]\n",
      "epoch:30 step:28643 [D loss: 0.597793, acc.: 63.28%] [G loss: 1.577156]\n",
      "epoch:30 step:28644 [D loss: 0.551642, acc.: 66.41%] [G loss: 1.834320]\n",
      "epoch:30 step:28645 [D loss: 0.455709, acc.: 80.47%] [G loss: 1.388348]\n",
      "epoch:30 step:28646 [D loss: 0.487561, acc.: 80.47%] [G loss: 1.352383]\n",
      "epoch:30 step:28647 [D loss: 0.531910, acc.: 75.00%] [G loss: 1.258414]\n",
      "epoch:30 step:28648 [D loss: 0.552776, acc.: 70.31%] [G loss: 1.399890]\n",
      "epoch:30 step:28649 [D loss: 0.654474, acc.: 64.84%] [G loss: 1.534902]\n",
      "epoch:30 step:28650 [D loss: 0.557974, acc.: 71.88%] [G loss: 1.214137]\n",
      "epoch:30 step:28651 [D loss: 0.448057, acc.: 78.91%] [G loss: 1.658741]\n",
      "epoch:30 step:28652 [D loss: 0.433340, acc.: 84.38%] [G loss: 1.380441]\n",
      "epoch:30 step:28653 [D loss: 0.544736, acc.: 71.09%] [G loss: 1.692803]\n",
      "epoch:30 step:28654 [D loss: 0.622218, acc.: 65.62%] [G loss: 1.689959]\n",
      "epoch:30 step:28655 [D loss: 0.487584, acc.: 73.44%] [G loss: 1.584540]\n",
      "epoch:30 step:28656 [D loss: 0.523162, acc.: 72.66%] [G loss: 1.486351]\n",
      "epoch:30 step:28657 [D loss: 0.668880, acc.: 58.59%] [G loss: 1.341615]\n",
      "epoch:30 step:28658 [D loss: 0.853928, acc.: 50.00%] [G loss: 1.156465]\n",
      "epoch:30 step:28659 [D loss: 0.416965, acc.: 84.38%] [G loss: 1.081280]\n",
      "epoch:30 step:28660 [D loss: 0.516209, acc.: 70.31%] [G loss: 1.198432]\n",
      "epoch:30 step:28661 [D loss: 0.688372, acc.: 64.84%] [G loss: 1.437836]\n",
      "epoch:30 step:28662 [D loss: 0.454133, acc.: 79.69%] [G loss: 2.058432]\n",
      "epoch:30 step:28663 [D loss: 0.609341, acc.: 68.75%] [G loss: 1.383128]\n",
      "epoch:30 step:28664 [D loss: 0.724817, acc.: 53.91%] [G loss: 1.465265]\n",
      "epoch:30 step:28665 [D loss: 0.498563, acc.: 73.44%] [G loss: 1.138523]\n",
      "epoch:30 step:28666 [D loss: 0.531373, acc.: 71.88%] [G loss: 1.191125]\n",
      "epoch:30 step:28667 [D loss: 0.522946, acc.: 71.09%] [G loss: 1.270027]\n",
      "epoch:30 step:28668 [D loss: 0.592242, acc.: 66.41%] [G loss: 1.676800]\n",
      "epoch:30 step:28669 [D loss: 0.411883, acc.: 82.81%] [G loss: 1.701660]\n",
      "epoch:30 step:28670 [D loss: 0.445766, acc.: 81.25%] [G loss: 1.429239]\n",
      "epoch:30 step:28671 [D loss: 0.558971, acc.: 67.97%] [G loss: 1.537464]\n",
      "epoch:30 step:28672 [D loss: 0.620533, acc.: 66.41%] [G loss: 1.191859]\n",
      "epoch:30 step:28673 [D loss: 0.519434, acc.: 75.78%] [G loss: 1.662173]\n",
      "epoch:30 step:28674 [D loss: 0.451450, acc.: 81.25%] [G loss: 1.751470]\n",
      "epoch:30 step:28675 [D loss: 0.458369, acc.: 82.81%] [G loss: 1.655455]\n",
      "epoch:30 step:28676 [D loss: 0.751247, acc.: 56.25%] [G loss: 1.384649]\n",
      "epoch:30 step:28677 [D loss: 0.445121, acc.: 77.34%] [G loss: 1.458302]\n",
      "epoch:30 step:28678 [D loss: 0.591855, acc.: 66.41%] [G loss: 1.553287]\n",
      "epoch:30 step:28679 [D loss: 0.675469, acc.: 67.97%] [G loss: 1.303936]\n",
      "epoch:30 step:28680 [D loss: 0.491887, acc.: 76.56%] [G loss: 1.287439]\n",
      "epoch:30 step:28681 [D loss: 0.486020, acc.: 76.56%] [G loss: 1.540591]\n",
      "epoch:30 step:28682 [D loss: 0.427931, acc.: 82.03%] [G loss: 1.525178]\n",
      "epoch:30 step:28683 [D loss: 0.423795, acc.: 81.25%] [G loss: 1.583473]\n",
      "epoch:30 step:28684 [D loss: 0.781395, acc.: 54.69%] [G loss: 1.418016]\n",
      "epoch:30 step:28685 [D loss: 0.524707, acc.: 71.88%] [G loss: 1.185601]\n",
      "epoch:30 step:28686 [D loss: 0.347695, acc.: 86.72%] [G loss: 1.846910]\n",
      "epoch:30 step:28687 [D loss: 0.622861, acc.: 70.31%] [G loss: 1.527702]\n",
      "epoch:30 step:28688 [D loss: 0.557671, acc.: 70.31%] [G loss: 1.020436]\n",
      "epoch:30 step:28689 [D loss: 0.577309, acc.: 69.53%] [G loss: 1.150438]\n",
      "epoch:30 step:28690 [D loss: 0.654691, acc.: 63.28%] [G loss: 1.079609]\n",
      "epoch:30 step:28691 [D loss: 0.711204, acc.: 58.59%] [G loss: 1.435727]\n",
      "epoch:30 step:28692 [D loss: 0.514522, acc.: 71.09%] [G loss: 1.676841]\n",
      "epoch:30 step:28693 [D loss: 0.498748, acc.: 75.00%] [G loss: 1.213079]\n",
      "epoch:30 step:28694 [D loss: 0.549444, acc.: 74.22%] [G loss: 1.400368]\n",
      "epoch:30 step:28695 [D loss: 0.549934, acc.: 71.09%] [G loss: 1.353189]\n",
      "epoch:30 step:28696 [D loss: 0.573032, acc.: 68.75%] [G loss: 1.451075]\n",
      "epoch:30 step:28697 [D loss: 0.499767, acc.: 75.78%] [G loss: 1.424440]\n",
      "epoch:30 step:28698 [D loss: 0.695548, acc.: 61.72%] [G loss: 1.559702]\n",
      "epoch:30 step:28699 [D loss: 0.531133, acc.: 71.88%] [G loss: 1.644933]\n",
      "epoch:30 step:28700 [D loss: 0.571580, acc.: 72.66%] [G loss: 1.565966]\n",
      "epoch:30 step:28701 [D loss: 0.505092, acc.: 78.91%] [G loss: 1.646373]\n",
      "epoch:30 step:28702 [D loss: 0.535957, acc.: 71.09%] [G loss: 1.564624]\n",
      "epoch:30 step:28703 [D loss: 0.630832, acc.: 60.94%] [G loss: 1.416603]\n",
      "epoch:30 step:28704 [D loss: 0.385590, acc.: 85.16%] [G loss: 1.618806]\n",
      "epoch:30 step:28705 [D loss: 0.438083, acc.: 82.81%] [G loss: 1.650825]\n",
      "epoch:30 step:28706 [D loss: 0.668042, acc.: 64.06%] [G loss: 1.027351]\n",
      "epoch:30 step:28707 [D loss: 0.689094, acc.: 54.69%] [G loss: 1.598888]\n",
      "epoch:30 step:28708 [D loss: 0.594066, acc.: 69.53%] [G loss: 1.270847]\n",
      "epoch:30 step:28709 [D loss: 0.521207, acc.: 76.56%] [G loss: 1.369170]\n",
      "epoch:30 step:28710 [D loss: 0.529112, acc.: 71.88%] [G loss: 1.700592]\n",
      "epoch:30 step:28711 [D loss: 0.696385, acc.: 62.50%] [G loss: 1.661161]\n",
      "epoch:30 step:28712 [D loss: 0.428265, acc.: 80.47%] [G loss: 1.239097]\n",
      "epoch:30 step:28713 [D loss: 0.362453, acc.: 88.28%] [G loss: 1.570105]\n",
      "epoch:30 step:28714 [D loss: 0.558121, acc.: 74.22%] [G loss: 1.329867]\n",
      "epoch:30 step:28715 [D loss: 0.489427, acc.: 77.34%] [G loss: 1.198949]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:30 step:28716 [D loss: 0.414519, acc.: 82.81%] [G loss: 1.493679]\n",
      "epoch:30 step:28717 [D loss: 0.483070, acc.: 79.69%] [G loss: 1.677859]\n",
      "epoch:30 step:28718 [D loss: 0.621335, acc.: 64.84%] [G loss: 1.030673]\n",
      "epoch:30 step:28719 [D loss: 0.567057, acc.: 71.09%] [G loss: 1.296629]\n",
      "epoch:30 step:28720 [D loss: 0.432127, acc.: 82.81%] [G loss: 1.680591]\n",
      "epoch:30 step:28721 [D loss: 0.598812, acc.: 62.50%] [G loss: 0.789020]\n",
      "epoch:30 step:28722 [D loss: 0.537167, acc.: 73.44%] [G loss: 1.393677]\n",
      "epoch:30 step:28723 [D loss: 0.554995, acc.: 74.22%] [G loss: 1.039239]\n",
      "epoch:30 step:28724 [D loss: 0.516184, acc.: 75.78%] [G loss: 1.617401]\n",
      "epoch:30 step:28725 [D loss: 0.715518, acc.: 59.38%] [G loss: 1.029041]\n",
      "epoch:30 step:28726 [D loss: 0.506165, acc.: 74.22%] [G loss: 1.474145]\n",
      "epoch:30 step:28727 [D loss: 0.488868, acc.: 80.47%] [G loss: 1.631771]\n",
      "epoch:30 step:28728 [D loss: 0.502848, acc.: 75.00%] [G loss: 1.388805]\n",
      "epoch:30 step:28729 [D loss: 0.498553, acc.: 78.12%] [G loss: 1.302456]\n",
      "epoch:30 step:28730 [D loss: 0.592307, acc.: 69.53%] [G loss: 1.480745]\n",
      "epoch:30 step:28731 [D loss: 0.701136, acc.: 58.59%] [G loss: 1.125856]\n",
      "epoch:30 step:28732 [D loss: 0.766527, acc.: 50.78%] [G loss: 1.292662]\n",
      "epoch:30 step:28733 [D loss: 0.461931, acc.: 82.03%] [G loss: 1.058727]\n",
      "epoch:30 step:28734 [D loss: 0.676920, acc.: 59.38%] [G loss: 1.122876]\n",
      "epoch:30 step:28735 [D loss: 0.470051, acc.: 77.34%] [G loss: 1.311287]\n",
      "epoch:30 step:28736 [D loss: 0.498170, acc.: 75.78%] [G loss: 1.694968]\n",
      "epoch:30 step:28737 [D loss: 0.552589, acc.: 73.44%] [G loss: 1.489403]\n",
      "epoch:30 step:28738 [D loss: 0.573050, acc.: 66.41%] [G loss: 1.407684]\n",
      "epoch:30 step:28739 [D loss: 0.593160, acc.: 67.97%] [G loss: 1.280507]\n",
      "epoch:30 step:28740 [D loss: 0.485553, acc.: 79.69%] [G loss: 1.694711]\n",
      "epoch:30 step:28741 [D loss: 0.431692, acc.: 82.81%] [G loss: 1.323737]\n",
      "epoch:30 step:28742 [D loss: 0.568040, acc.: 67.97%] [G loss: 1.567217]\n",
      "epoch:30 step:28743 [D loss: 0.386496, acc.: 82.81%] [G loss: 1.280044]\n",
      "epoch:30 step:28744 [D loss: 0.552059, acc.: 71.88%] [G loss: 1.874908]\n",
      "epoch:30 step:28745 [D loss: 0.539193, acc.: 69.53%] [G loss: 1.567010]\n",
      "epoch:30 step:28746 [D loss: 0.477683, acc.: 78.91%] [G loss: 1.718839]\n",
      "epoch:30 step:28747 [D loss: 0.556661, acc.: 67.19%] [G loss: 1.378414]\n",
      "epoch:30 step:28748 [D loss: 0.508600, acc.: 75.00%] [G loss: 1.310158]\n",
      "epoch:30 step:28749 [D loss: 0.784814, acc.: 53.91%] [G loss: 1.178598]\n",
      "epoch:30 step:28750 [D loss: 0.490685, acc.: 78.12%] [G loss: 1.684548]\n",
      "epoch:30 step:28751 [D loss: 0.436994, acc.: 82.03%] [G loss: 1.502668]\n",
      "epoch:30 step:28752 [D loss: 0.449770, acc.: 77.34%] [G loss: 1.676004]\n",
      "epoch:30 step:28753 [D loss: 0.756790, acc.: 54.69%] [G loss: 1.081295]\n",
      "epoch:30 step:28754 [D loss: 0.565492, acc.: 72.66%] [G loss: 1.339187]\n",
      "epoch:30 step:28755 [D loss: 0.526870, acc.: 74.22%] [G loss: 1.720027]\n",
      "epoch:30 step:28756 [D loss: 0.466488, acc.: 79.69%] [G loss: 1.006023]\n",
      "epoch:30 step:28757 [D loss: 0.604504, acc.: 65.62%] [G loss: 1.416763]\n",
      "epoch:30 step:28758 [D loss: 0.469388, acc.: 81.25%] [G loss: 1.356836]\n",
      "epoch:30 step:28759 [D loss: 0.349785, acc.: 88.28%] [G loss: 1.590119]\n",
      "epoch:30 step:28760 [D loss: 0.661369, acc.: 63.28%] [G loss: 1.341618]\n",
      "epoch:30 step:28761 [D loss: 0.368812, acc.: 85.94%] [G loss: 1.805406]\n",
      "epoch:30 step:28762 [D loss: 0.569247, acc.: 71.09%] [G loss: 1.831439]\n",
      "epoch:30 step:28763 [D loss: 0.609375, acc.: 67.19%] [G loss: 1.418461]\n",
      "epoch:30 step:28764 [D loss: 0.543451, acc.: 71.09%] [G loss: 1.668922]\n",
      "epoch:30 step:28765 [D loss: 0.464011, acc.: 79.69%] [G loss: 1.660236]\n",
      "epoch:30 step:28766 [D loss: 0.445486, acc.: 79.69%] [G loss: 1.705390]\n",
      "epoch:30 step:28767 [D loss: 0.453007, acc.: 78.12%] [G loss: 1.662726]\n",
      "epoch:30 step:28768 [D loss: 0.559448, acc.: 72.66%] [G loss: 1.605443]\n",
      "epoch:30 step:28769 [D loss: 0.573949, acc.: 65.62%] [G loss: 1.362643]\n",
      "epoch:30 step:28770 [D loss: 0.399205, acc.: 85.16%] [G loss: 1.662670]\n",
      "epoch:30 step:28771 [D loss: 0.632156, acc.: 64.84%] [G loss: 1.274534]\n",
      "epoch:30 step:28772 [D loss: 0.626269, acc.: 68.75%] [G loss: 1.339746]\n",
      "epoch:30 step:28773 [D loss: 0.638425, acc.: 64.84%] [G loss: 0.956851]\n",
      "epoch:30 step:28774 [D loss: 0.558754, acc.: 74.22%] [G loss: 1.242948]\n",
      "epoch:30 step:28775 [D loss: 0.440775, acc.: 78.91%] [G loss: 1.180090]\n",
      "epoch:30 step:28776 [D loss: 0.471494, acc.: 78.12%] [G loss: 1.356090]\n",
      "epoch:30 step:28777 [D loss: 0.447140, acc.: 79.69%] [G loss: 1.663540]\n",
      "epoch:30 step:28778 [D loss: 0.683459, acc.: 58.59%] [G loss: 1.282847]\n",
      "epoch:30 step:28779 [D loss: 0.557213, acc.: 71.09%] [G loss: 1.445252]\n",
      "epoch:30 step:28780 [D loss: 0.426240, acc.: 84.38%] [G loss: 1.535275]\n",
      "epoch:30 step:28781 [D loss: 0.404624, acc.: 85.16%] [G loss: 1.650579]\n",
      "epoch:30 step:28782 [D loss: 0.633767, acc.: 62.50%] [G loss: 1.258698]\n",
      "epoch:30 step:28783 [D loss: 0.606879, acc.: 63.28%] [G loss: 1.650953]\n",
      "epoch:30 step:28784 [D loss: 0.440429, acc.: 81.25%] [G loss: 1.750186]\n",
      "epoch:30 step:28785 [D loss: 0.540348, acc.: 74.22%] [G loss: 1.414356]\n",
      "epoch:30 step:28786 [D loss: 0.501510, acc.: 71.09%] [G loss: 1.522630]\n",
      "epoch:30 step:28787 [D loss: 0.546844, acc.: 70.31%] [G loss: 1.601977]\n",
      "epoch:30 step:28788 [D loss: 0.651835, acc.: 65.62%] [G loss: 1.042988]\n",
      "epoch:30 step:28789 [D loss: 0.580282, acc.: 67.97%] [G loss: 1.609102]\n",
      "epoch:30 step:28790 [D loss: 0.509522, acc.: 77.34%] [G loss: 1.349041]\n",
      "epoch:30 step:28791 [D loss: 0.733539, acc.: 55.47%] [G loss: 0.879389]\n",
      "epoch:30 step:28792 [D loss: 0.561558, acc.: 73.44%] [G loss: 1.471818]\n",
      "epoch:30 step:28793 [D loss: 0.611908, acc.: 67.19%] [G loss: 1.409292]\n",
      "epoch:30 step:28794 [D loss: 0.665761, acc.: 64.84%] [G loss: 1.294119]\n",
      "epoch:30 step:28795 [D loss: 0.460687, acc.: 77.34%] [G loss: 1.665173]\n",
      "epoch:30 step:28796 [D loss: 0.397258, acc.: 84.38%] [G loss: 1.640053]\n",
      "epoch:30 step:28797 [D loss: 0.503725, acc.: 75.00%] [G loss: 1.758831]\n",
      "epoch:30 step:28798 [D loss: 0.501880, acc.: 78.91%] [G loss: 1.303802]\n",
      "epoch:30 step:28799 [D loss: 0.666259, acc.: 62.50%] [G loss: 1.144546]\n",
      "epoch:30 step:28800 [D loss: 0.428829, acc.: 83.59%] [G loss: 1.310013]\n",
      "epoch:30 step:28801 [D loss: 0.606591, acc.: 66.41%] [G loss: 1.707548]\n",
      "epoch:30 step:28802 [D loss: 0.488375, acc.: 78.12%] [G loss: 1.581461]\n",
      "epoch:30 step:28803 [D loss: 0.755127, acc.: 54.69%] [G loss: 1.475550]\n",
      "epoch:30 step:28804 [D loss: 0.514340, acc.: 79.69%] [G loss: 1.309521]\n",
      "epoch:30 step:28805 [D loss: 0.523901, acc.: 76.56%] [G loss: 1.077236]\n",
      "epoch:30 step:28806 [D loss: 0.522676, acc.: 76.56%] [G loss: 1.000818]\n",
      "epoch:30 step:28807 [D loss: 0.584457, acc.: 68.75%] [G loss: 1.428039]\n",
      "epoch:30 step:28808 [D loss: 0.472502, acc.: 81.25%] [G loss: 1.729134]\n",
      "epoch:30 step:28809 [D loss: 0.627740, acc.: 64.84%] [G loss: 1.426006]\n",
      "epoch:30 step:28810 [D loss: 0.541649, acc.: 71.09%] [G loss: 1.127776]\n",
      "epoch:30 step:28811 [D loss: 0.446928, acc.: 82.03%] [G loss: 1.218797]\n",
      "epoch:30 step:28812 [D loss: 0.592891, acc.: 69.53%] [G loss: 1.639918]\n",
      "epoch:30 step:28813 [D loss: 0.641657, acc.: 62.50%] [G loss: 1.511706]\n",
      "epoch:30 step:28814 [D loss: 0.727071, acc.: 58.59%] [G loss: 1.610472]\n",
      "epoch:30 step:28815 [D loss: 0.410533, acc.: 82.03%] [G loss: 1.491994]\n",
      "epoch:30 step:28816 [D loss: 0.498671, acc.: 77.34%] [G loss: 1.440264]\n",
      "epoch:30 step:28817 [D loss: 0.540787, acc.: 75.78%] [G loss: 1.669782]\n",
      "epoch:30 step:28818 [D loss: 0.571679, acc.: 71.88%] [G loss: 1.658057]\n",
      "epoch:30 step:28819 [D loss: 0.715004, acc.: 56.25%] [G loss: 1.556233]\n",
      "epoch:30 step:28820 [D loss: 0.564485, acc.: 72.66%] [G loss: 1.952496]\n",
      "epoch:30 step:28821 [D loss: 0.469986, acc.: 81.25%] [G loss: 1.515879]\n",
      "epoch:30 step:28822 [D loss: 0.476203, acc.: 76.56%] [G loss: 1.913822]\n",
      "epoch:30 step:28823 [D loss: 0.497045, acc.: 78.12%] [G loss: 1.278976]\n",
      "epoch:30 step:28824 [D loss: 0.654288, acc.: 66.41%] [G loss: 1.585621]\n",
      "epoch:30 step:28825 [D loss: 0.604989, acc.: 64.84%] [G loss: 1.198218]\n",
      "epoch:30 step:28826 [D loss: 0.414792, acc.: 82.03%] [G loss: 1.565325]\n",
      "epoch:30 step:28827 [D loss: 0.582768, acc.: 67.19%] [G loss: 1.256692]\n",
      "epoch:30 step:28828 [D loss: 0.652696, acc.: 65.62%] [G loss: 1.497808]\n",
      "epoch:30 step:28829 [D loss: 0.635797, acc.: 64.84%] [G loss: 1.128999]\n",
      "epoch:30 step:28830 [D loss: 0.476264, acc.: 84.38%] [G loss: 1.558096]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:30 step:28831 [D loss: 0.625136, acc.: 66.41%] [G loss: 1.734938]\n",
      "epoch:30 step:28832 [D loss: 0.464753, acc.: 79.69%] [G loss: 1.400438]\n",
      "epoch:30 step:28833 [D loss: 0.584525, acc.: 65.62%] [G loss: 1.509928]\n",
      "epoch:30 step:28834 [D loss: 0.584012, acc.: 70.31%] [G loss: 1.066392]\n",
      "epoch:30 step:28835 [D loss: 0.414087, acc.: 80.47%] [G loss: 1.715205]\n",
      "epoch:30 step:28836 [D loss: 0.647745, acc.: 63.28%] [G loss: 1.408879]\n",
      "epoch:30 step:28837 [D loss: 0.481018, acc.: 75.00%] [G loss: 0.885301]\n",
      "epoch:30 step:28838 [D loss: 0.574989, acc.: 69.53%] [G loss: 1.244588]\n",
      "epoch:30 step:28839 [D loss: 0.523565, acc.: 77.34%] [G loss: 1.439982]\n",
      "epoch:30 step:28840 [D loss: 0.454664, acc.: 80.47%] [G loss: 1.624983]\n",
      "epoch:30 step:28841 [D loss: 0.744492, acc.: 52.34%] [G loss: 1.248658]\n",
      "epoch:30 step:28842 [D loss: 0.549117, acc.: 71.88%] [G loss: 1.269195]\n",
      "epoch:30 step:28843 [D loss: 0.389934, acc.: 80.47%] [G loss: 1.462349]\n",
      "epoch:30 step:28844 [D loss: 0.459305, acc.: 79.69%] [G loss: 1.878061]\n",
      "epoch:30 step:28845 [D loss: 0.462848, acc.: 78.91%] [G loss: 1.852068]\n",
      "epoch:30 step:28846 [D loss: 0.384186, acc.: 88.28%] [G loss: 1.611836]\n",
      "epoch:30 step:28847 [D loss: 0.696300, acc.: 63.28%] [G loss: 1.535535]\n",
      "epoch:30 step:28848 [D loss: 0.574203, acc.: 70.31%] [G loss: 1.739265]\n",
      "epoch:30 step:28849 [D loss: 0.484958, acc.: 81.25%] [G loss: 1.362293]\n",
      "epoch:30 step:28850 [D loss: 0.734563, acc.: 55.47%] [G loss: 1.247240]\n",
      "epoch:30 step:28851 [D loss: 0.714856, acc.: 61.72%] [G loss: 1.172077]\n",
      "epoch:30 step:28852 [D loss: 0.489966, acc.: 72.66%] [G loss: 1.474947]\n",
      "epoch:30 step:28853 [D loss: 0.612525, acc.: 67.19%] [G loss: 1.480725]\n",
      "epoch:30 step:28854 [D loss: 0.551095, acc.: 70.31%] [G loss: 1.700125]\n",
      "epoch:30 step:28855 [D loss: 0.479396, acc.: 77.34%] [G loss: 1.587518]\n",
      "epoch:30 step:28856 [D loss: 0.432481, acc.: 83.59%] [G loss: 2.013546]\n",
      "epoch:30 step:28857 [D loss: 0.453216, acc.: 82.03%] [G loss: 1.335251]\n",
      "epoch:30 step:28858 [D loss: 0.485366, acc.: 72.66%] [G loss: 1.286499]\n",
      "epoch:30 step:28859 [D loss: 0.550677, acc.: 66.41%] [G loss: 1.356177]\n",
      "epoch:30 step:28860 [D loss: 0.617575, acc.: 63.28%] [G loss: 1.341473]\n",
      "epoch:30 step:28861 [D loss: 0.460985, acc.: 78.91%] [G loss: 1.454872]\n",
      "epoch:30 step:28862 [D loss: 0.419172, acc.: 81.25%] [G loss: 1.778118]\n",
      "epoch:30 step:28863 [D loss: 0.613639, acc.: 71.09%] [G loss: 0.892632]\n",
      "epoch:30 step:28864 [D loss: 0.526377, acc.: 74.22%] [G loss: 1.627476]\n",
      "epoch:30 step:28865 [D loss: 0.557334, acc.: 71.09%] [G loss: 1.333547]\n",
      "epoch:30 step:28866 [D loss: 0.577673, acc.: 68.75%] [G loss: 1.205497]\n",
      "epoch:30 step:28867 [D loss: 0.425815, acc.: 82.03%] [G loss: 1.636241]\n",
      "epoch:30 step:28868 [D loss: 0.605727, acc.: 71.09%] [G loss: 1.426217]\n",
      "epoch:30 step:28869 [D loss: 0.416246, acc.: 79.69%] [G loss: 1.877076]\n",
      "epoch:30 step:28870 [D loss: 0.502352, acc.: 75.00%] [G loss: 1.727292]\n",
      "epoch:30 step:28871 [D loss: 0.465822, acc.: 76.56%] [G loss: 1.380565]\n",
      "epoch:30 step:28872 [D loss: 0.475254, acc.: 80.47%] [G loss: 1.078955]\n",
      "epoch:30 step:28873 [D loss: 0.352304, acc.: 85.16%] [G loss: 1.261124]\n",
      "epoch:30 step:28874 [D loss: 0.468221, acc.: 82.81%] [G loss: 1.498934]\n",
      "epoch:30 step:28875 [D loss: 0.574093, acc.: 70.31%] [G loss: 1.810485]\n",
      "epoch:30 step:28876 [D loss: 0.671257, acc.: 57.03%] [G loss: 1.549856]\n",
      "epoch:30 step:28877 [D loss: 0.329884, acc.: 88.28%] [G loss: 1.704232]\n",
      "epoch:30 step:28878 [D loss: 0.497060, acc.: 76.56%] [G loss: 1.855408]\n",
      "epoch:30 step:28879 [D loss: 0.417375, acc.: 82.81%] [G loss: 1.461235]\n",
      "epoch:30 step:28880 [D loss: 0.618459, acc.: 64.84%] [G loss: 1.155929]\n",
      "epoch:30 step:28881 [D loss: 0.496776, acc.: 78.91%] [G loss: 1.353940]\n",
      "epoch:30 step:28882 [D loss: 0.426300, acc.: 85.94%] [G loss: 1.291604]\n",
      "epoch:30 step:28883 [D loss: 0.658805, acc.: 66.41%] [G loss: 1.431112]\n",
      "epoch:30 step:28884 [D loss: 0.544367, acc.: 76.56%] [G loss: 1.480121]\n",
      "epoch:30 step:28885 [D loss: 0.531217, acc.: 74.22%] [G loss: 1.434848]\n",
      "epoch:30 step:28886 [D loss: 0.550397, acc.: 71.88%] [G loss: 1.513121]\n",
      "epoch:30 step:28887 [D loss: 0.574830, acc.: 72.66%] [G loss: 1.397987]\n",
      "epoch:30 step:28888 [D loss: 0.419888, acc.: 85.16%] [G loss: 1.583423]\n",
      "epoch:30 step:28889 [D loss: 0.589463, acc.: 71.88%] [G loss: 1.302957]\n",
      "epoch:30 step:28890 [D loss: 0.876365, acc.: 50.00%] [G loss: 1.441226]\n",
      "epoch:30 step:28891 [D loss: 0.546726, acc.: 71.09%] [G loss: 1.681313]\n",
      "epoch:30 step:28892 [D loss: 0.483574, acc.: 75.78%] [G loss: 1.722937]\n",
      "epoch:30 step:28893 [D loss: 0.636841, acc.: 62.50%] [G loss: 1.641210]\n",
      "epoch:30 step:28894 [D loss: 0.789484, acc.: 54.69%] [G loss: 1.512544]\n",
      "epoch:30 step:28895 [D loss: 0.447804, acc.: 81.25%] [G loss: 1.695519]\n",
      "epoch:30 step:28896 [D loss: 0.710285, acc.: 55.47%] [G loss: 1.390546]\n",
      "epoch:30 step:28897 [D loss: 0.518219, acc.: 75.00%] [G loss: 1.537449]\n",
      "epoch:30 step:28898 [D loss: 0.575283, acc.: 71.09%] [G loss: 1.248101]\n",
      "epoch:30 step:28899 [D loss: 0.484072, acc.: 78.91%] [G loss: 1.332726]\n",
      "epoch:30 step:28900 [D loss: 0.513339, acc.: 74.22%] [G loss: 1.557119]\n",
      "epoch:30 step:28901 [D loss: 0.480167, acc.: 73.44%] [G loss: 2.130308]\n",
      "epoch:30 step:28902 [D loss: 0.527406, acc.: 76.56%] [G loss: 1.742606]\n",
      "epoch:30 step:28903 [D loss: 0.644032, acc.: 64.06%] [G loss: 1.632328]\n",
      "epoch:30 step:28904 [D loss: 0.501883, acc.: 81.25%] [G loss: 2.050403]\n",
      "epoch:30 step:28905 [D loss: 0.463533, acc.: 78.12%] [G loss: 1.845353]\n",
      "epoch:30 step:28906 [D loss: 0.477626, acc.: 79.69%] [G loss: 1.460582]\n",
      "epoch:30 step:28907 [D loss: 0.460230, acc.: 75.00%] [G loss: 1.744601]\n",
      "epoch:30 step:28908 [D loss: 0.589856, acc.: 69.53%] [G loss: 1.517140]\n",
      "epoch:30 step:28909 [D loss: 0.544737, acc.: 71.88%] [G loss: 1.518888]\n",
      "epoch:30 step:28910 [D loss: 0.416571, acc.: 85.16%] [G loss: 1.339615]\n",
      "epoch:30 step:28911 [D loss: 0.541409, acc.: 76.56%] [G loss: 1.237002]\n",
      "epoch:30 step:28912 [D loss: 0.764683, acc.: 57.81%] [G loss: 1.455014]\n",
      "epoch:30 step:28913 [D loss: 0.630419, acc.: 67.19%] [G loss: 1.115165]\n",
      "epoch:30 step:28914 [D loss: 0.330700, acc.: 88.28%] [G loss: 1.845107]\n",
      "epoch:30 step:28915 [D loss: 0.472754, acc.: 80.47%] [G loss: 1.431026]\n",
      "epoch:30 step:28916 [D loss: 0.497576, acc.: 75.00%] [G loss: 1.584941]\n",
      "epoch:30 step:28917 [D loss: 0.631925, acc.: 64.06%] [G loss: 1.385725]\n",
      "epoch:30 step:28918 [D loss: 0.601214, acc.: 67.97%] [G loss: 1.396308]\n",
      "epoch:30 step:28919 [D loss: 0.465305, acc.: 76.56%] [G loss: 1.546534]\n",
      "epoch:30 step:28920 [D loss: 0.335865, acc.: 89.84%] [G loss: 1.502745]\n",
      "epoch:30 step:28921 [D loss: 0.589199, acc.: 68.75%] [G loss: 1.359563]\n",
      "epoch:30 step:28922 [D loss: 0.402736, acc.: 85.16%] [G loss: 1.556735]\n",
      "epoch:30 step:28923 [D loss: 0.440857, acc.: 84.38%] [G loss: 1.558146]\n",
      "epoch:30 step:28924 [D loss: 0.562128, acc.: 71.09%] [G loss: 1.719360]\n",
      "epoch:30 step:28925 [D loss: 0.433620, acc.: 82.81%] [G loss: 1.976982]\n",
      "epoch:30 step:28926 [D loss: 0.505902, acc.: 74.22%] [G loss: 1.498303]\n",
      "epoch:30 step:28927 [D loss: 0.512496, acc.: 75.00%] [G loss: 1.245343]\n",
      "epoch:30 step:28928 [D loss: 0.360007, acc.: 83.59%] [G loss: 1.615037]\n",
      "epoch:30 step:28929 [D loss: 0.532290, acc.: 71.88%] [G loss: 1.247079]\n",
      "epoch:30 step:28930 [D loss: 0.438420, acc.: 80.47%] [G loss: 1.465478]\n",
      "epoch:30 step:28931 [D loss: 0.525859, acc.: 75.00%] [G loss: 1.601640]\n",
      "epoch:30 step:28932 [D loss: 0.631218, acc.: 66.41%] [G loss: 1.159314]\n",
      "epoch:30 step:28933 [D loss: 0.414492, acc.: 85.94%] [G loss: 1.711343]\n",
      "epoch:30 step:28934 [D loss: 0.510381, acc.: 75.78%] [G loss: 1.352141]\n",
      "epoch:30 step:28935 [D loss: 0.499949, acc.: 76.56%] [G loss: 1.444268]\n",
      "epoch:30 step:28936 [D loss: 0.669832, acc.: 63.28%] [G loss: 1.680451]\n",
      "epoch:30 step:28937 [D loss: 1.056122, acc.: 42.19%] [G loss: 0.937629]\n",
      "epoch:30 step:28938 [D loss: 0.592884, acc.: 69.53%] [G loss: 1.429593]\n",
      "epoch:30 step:28939 [D loss: 0.903636, acc.: 45.31%] [G loss: 1.278621]\n",
      "epoch:30 step:28940 [D loss: 0.555036, acc.: 69.53%] [G loss: 1.700271]\n",
      "epoch:30 step:28941 [D loss: 0.621718, acc.: 67.97%] [G loss: 1.445176]\n",
      "epoch:30 step:28942 [D loss: 0.573926, acc.: 72.66%] [G loss: 1.799351]\n",
      "epoch:30 step:28943 [D loss: 0.493147, acc.: 79.69%] [G loss: 1.304672]\n",
      "epoch:30 step:28944 [D loss: 0.543298, acc.: 73.44%] [G loss: 0.912414]\n",
      "epoch:30 step:28945 [D loss: 0.666945, acc.: 56.25%] [G loss: 1.315301]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:30 step:28946 [D loss: 0.620043, acc.: 67.97%] [G loss: 1.250144]\n",
      "epoch:30 step:28947 [D loss: 0.639358, acc.: 69.53%] [G loss: 1.032868]\n",
      "epoch:30 step:28948 [D loss: 0.426209, acc.: 81.25%] [G loss: 1.285315]\n",
      "epoch:30 step:28949 [D loss: 0.395859, acc.: 81.25%] [G loss: 1.847623]\n",
      "epoch:30 step:28950 [D loss: 0.441807, acc.: 83.59%] [G loss: 1.466086]\n",
      "epoch:30 step:28951 [D loss: 0.619269, acc.: 67.97%] [G loss: 1.675813]\n",
      "epoch:30 step:28952 [D loss: 0.645371, acc.: 60.16%] [G loss: 1.296222]\n",
      "epoch:30 step:28953 [D loss: 0.725197, acc.: 56.25%] [G loss: 1.439463]\n",
      "epoch:30 step:28954 [D loss: 0.646852, acc.: 63.28%] [G loss: 1.470056]\n",
      "epoch:30 step:28955 [D loss: 0.423931, acc.: 82.81%] [G loss: 1.428341]\n",
      "epoch:30 step:28956 [D loss: 0.513572, acc.: 78.91%] [G loss: 1.484750]\n",
      "epoch:30 step:28957 [D loss: 0.536093, acc.: 71.09%] [G loss: 1.322886]\n",
      "epoch:30 step:28958 [D loss: 0.537998, acc.: 73.44%] [G loss: 1.425885]\n",
      "epoch:30 step:28959 [D loss: 0.385993, acc.: 86.72%] [G loss: 1.617850]\n",
      "epoch:30 step:28960 [D loss: 0.539493, acc.: 71.09%] [G loss: 1.974975]\n",
      "epoch:30 step:28961 [D loss: 0.702570, acc.: 64.06%] [G loss: 1.653977]\n",
      "epoch:30 step:28962 [D loss: 0.322589, acc.: 91.41%] [G loss: 1.711146]\n",
      "epoch:30 step:28963 [D loss: 0.631834, acc.: 60.94%] [G loss: 2.019803]\n",
      "epoch:30 step:28964 [D loss: 0.529022, acc.: 74.22%] [G loss: 1.806761]\n",
      "epoch:30 step:28965 [D loss: 0.575982, acc.: 71.09%] [G loss: 1.726752]\n",
      "epoch:30 step:28966 [D loss: 0.441365, acc.: 85.16%] [G loss: 1.588946]\n",
      "epoch:30 step:28967 [D loss: 0.493573, acc.: 78.12%] [G loss: 1.355619]\n",
      "epoch:30 step:28968 [D loss: 0.402755, acc.: 85.16%] [G loss: 1.158376]\n",
      "epoch:30 step:28969 [D loss: 0.520728, acc.: 74.22%] [G loss: 1.502206]\n",
      "epoch:30 step:28970 [D loss: 0.496540, acc.: 76.56%] [G loss: 1.595363]\n",
      "epoch:30 step:28971 [D loss: 0.481431, acc.: 75.00%] [G loss: 1.100125]\n",
      "epoch:30 step:28972 [D loss: 0.630322, acc.: 66.41%] [G loss: 1.013109]\n",
      "epoch:30 step:28973 [D loss: 0.581461, acc.: 72.66%] [G loss: 1.080765]\n",
      "epoch:30 step:28974 [D loss: 0.592818, acc.: 71.09%] [G loss: 1.545581]\n",
      "epoch:30 step:28975 [D loss: 0.476403, acc.: 76.56%] [G loss: 1.576210]\n",
      "epoch:30 step:28976 [D loss: 0.386532, acc.: 81.25%] [G loss: 2.166542]\n",
      "epoch:30 step:28977 [D loss: 0.605018, acc.: 72.66%] [G loss: 1.941771]\n",
      "epoch:30 step:28978 [D loss: 0.613739, acc.: 67.97%] [G loss: 1.570580]\n",
      "epoch:30 step:28979 [D loss: 0.477144, acc.: 81.25%] [G loss: 1.639064]\n",
      "epoch:30 step:28980 [D loss: 0.433233, acc.: 81.25%] [G loss: 1.441480]\n",
      "epoch:30 step:28981 [D loss: 0.461528, acc.: 80.47%] [G loss: 1.627623]\n",
      "epoch:30 step:28982 [D loss: 0.588695, acc.: 66.41%] [G loss: 1.049939]\n",
      "epoch:30 step:28983 [D loss: 0.417928, acc.: 80.47%] [G loss: 0.940494]\n",
      "epoch:30 step:28984 [D loss: 0.619529, acc.: 64.84%] [G loss: 1.409700]\n",
      "epoch:30 step:28985 [D loss: 0.383798, acc.: 87.50%] [G loss: 1.415829]\n",
      "epoch:30 step:28986 [D loss: 0.591376, acc.: 67.19%] [G loss: 1.074693]\n",
      "epoch:30 step:28987 [D loss: 0.512576, acc.: 75.78%] [G loss: 1.597739]\n",
      "epoch:30 step:28988 [D loss: 0.548773, acc.: 74.22%] [G loss: 1.670273]\n",
      "epoch:30 step:28989 [D loss: 0.710481, acc.: 59.38%] [G loss: 1.643096]\n",
      "epoch:30 step:28990 [D loss: 0.490408, acc.: 77.34%] [G loss: 1.427711]\n",
      "epoch:30 step:28991 [D loss: 0.503655, acc.: 77.34%] [G loss: 1.507526]\n",
      "epoch:30 step:28992 [D loss: 0.389746, acc.: 85.16%] [G loss: 1.931196]\n",
      "epoch:30 step:28993 [D loss: 0.704911, acc.: 57.81%] [G loss: 1.472225]\n",
      "epoch:30 step:28994 [D loss: 0.561618, acc.: 71.09%] [G loss: 1.499453]\n",
      "epoch:30 step:28995 [D loss: 0.508007, acc.: 77.34%] [G loss: 1.551289]\n",
      "epoch:30 step:28996 [D loss: 0.601123, acc.: 71.88%] [G loss: 1.775144]\n",
      "epoch:30 step:28997 [D loss: 0.684761, acc.: 60.94%] [G loss: 1.577600]\n",
      "epoch:30 step:28998 [D loss: 0.622086, acc.: 66.41%] [G loss: 1.156767]\n",
      "epoch:30 step:28999 [D loss: 0.598481, acc.: 66.41%] [G loss: 1.237490]\n",
      "epoch:30 step:29000 [D loss: 0.551309, acc.: 75.78%] [G loss: 1.586605]\n",
      "epoch:30 step:29001 [D loss: 0.640347, acc.: 66.41%] [G loss: 1.274557]\n",
      "epoch:30 step:29002 [D loss: 0.494214, acc.: 76.56%] [G loss: 1.491569]\n",
      "epoch:30 step:29003 [D loss: 0.426761, acc.: 82.81%] [G loss: 1.940894]\n",
      "epoch:30 step:29004 [D loss: 0.805056, acc.: 51.56%] [G loss: 1.574444]\n",
      "epoch:30 step:29005 [D loss: 0.442909, acc.: 82.03%] [G loss: 1.588740]\n",
      "epoch:30 step:29006 [D loss: 0.532321, acc.: 71.88%] [G loss: 1.359710]\n",
      "epoch:30 step:29007 [D loss: 0.565306, acc.: 71.09%] [G loss: 1.234500]\n",
      "epoch:30 step:29008 [D loss: 0.463388, acc.: 80.47%] [G loss: 1.332180]\n",
      "epoch:30 step:29009 [D loss: 0.454712, acc.: 81.25%] [G loss: 1.856157]\n",
      "epoch:30 step:29010 [D loss: 0.478216, acc.: 75.00%] [G loss: 1.976989]\n",
      "epoch:30 step:29011 [D loss: 0.475188, acc.: 78.91%] [G loss: 1.803841]\n",
      "epoch:30 step:29012 [D loss: 0.460154, acc.: 80.47%] [G loss: 1.835960]\n",
      "epoch:30 step:29013 [D loss: 0.324730, acc.: 91.41%] [G loss: 1.995616]\n",
      "epoch:30 step:29014 [D loss: 0.340315, acc.: 89.06%] [G loss: 1.829077]\n",
      "epoch:30 step:29015 [D loss: 0.494377, acc.: 75.00%] [G loss: 1.737414]\n",
      "epoch:30 step:29016 [D loss: 0.404522, acc.: 83.59%] [G loss: 1.505114]\n",
      "epoch:30 step:29017 [D loss: 0.420860, acc.: 84.38%] [G loss: 1.364622]\n",
      "epoch:30 step:29018 [D loss: 0.580806, acc.: 70.31%] [G loss: 1.279180]\n",
      "epoch:30 step:29019 [D loss: 0.590899, acc.: 69.53%] [G loss: 1.387081]\n",
      "epoch:30 step:29020 [D loss: 0.362500, acc.: 82.81%] [G loss: 1.492004]\n",
      "epoch:30 step:29021 [D loss: 0.353920, acc.: 83.59%] [G loss: 1.546000]\n",
      "epoch:30 step:29022 [D loss: 0.525528, acc.: 74.22%] [G loss: 1.160382]\n",
      "epoch:30 step:29023 [D loss: 0.423283, acc.: 82.03%] [G loss: 1.028695]\n",
      "epoch:30 step:29024 [D loss: 0.419627, acc.: 83.59%] [G loss: 1.430912]\n",
      "epoch:30 step:29025 [D loss: 0.477287, acc.: 75.78%] [G loss: 1.417091]\n",
      "epoch:30 step:29026 [D loss: 0.469341, acc.: 79.69%] [G loss: 1.338281]\n",
      "epoch:30 step:29027 [D loss: 0.516855, acc.: 76.56%] [G loss: 1.285126]\n",
      "epoch:30 step:29028 [D loss: 0.631181, acc.: 62.50%] [G loss: 1.078177]\n",
      "epoch:30 step:29029 [D loss: 0.428794, acc.: 81.25%] [G loss: 1.962127]\n",
      "epoch:30 step:29030 [D loss: 0.553259, acc.: 71.09%] [G loss: 1.569416]\n",
      "epoch:30 step:29031 [D loss: 0.470372, acc.: 79.69%] [G loss: 1.229060]\n",
      "epoch:30 step:29032 [D loss: 0.528847, acc.: 75.00%] [G loss: 1.307180]\n",
      "epoch:30 step:29033 [D loss: 0.452639, acc.: 79.69%] [G loss: 1.656213]\n",
      "epoch:30 step:29034 [D loss: 0.733658, acc.: 55.47%] [G loss: 1.121908]\n",
      "epoch:30 step:29035 [D loss: 0.524312, acc.: 77.34%] [G loss: 1.107299]\n",
      "epoch:30 step:29036 [D loss: 0.633176, acc.: 64.84%] [G loss: 1.569644]\n",
      "epoch:30 step:29037 [D loss: 0.651534, acc.: 66.41%] [G loss: 1.340950]\n",
      "epoch:30 step:29038 [D loss: 0.355092, acc.: 84.38%] [G loss: 2.120223]\n",
      "epoch:30 step:29039 [D loss: 0.607178, acc.: 65.62%] [G loss: 1.510645]\n",
      "epoch:30 step:29040 [D loss: 0.500587, acc.: 78.12%] [G loss: 2.030978]\n",
      "epoch:30 step:29041 [D loss: 0.711030, acc.: 53.91%] [G loss: 1.421974]\n",
      "epoch:30 step:29042 [D loss: 0.532943, acc.: 75.78%] [G loss: 1.461414]\n",
      "epoch:30 step:29043 [D loss: 0.658567, acc.: 62.50%] [G loss: 1.432177]\n",
      "epoch:30 step:29044 [D loss: 0.728402, acc.: 58.59%] [G loss: 1.512780]\n",
      "epoch:30 step:29045 [D loss: 0.595331, acc.: 67.19%] [G loss: 1.129212]\n",
      "epoch:30 step:29046 [D loss: 0.546905, acc.: 71.09%] [G loss: 1.272053]\n",
      "epoch:30 step:29047 [D loss: 0.611406, acc.: 65.62%] [G loss: 1.508753]\n",
      "epoch:31 step:29048 [D loss: 0.490451, acc.: 79.69%] [G loss: 1.444879]\n",
      "epoch:31 step:29049 [D loss: 0.491195, acc.: 80.47%] [G loss: 1.396601]\n",
      "epoch:31 step:29050 [D loss: 0.523148, acc.: 71.88%] [G loss: 1.367442]\n",
      "epoch:31 step:29051 [D loss: 0.632757, acc.: 64.06%] [G loss: 1.262563]\n",
      "epoch:31 step:29052 [D loss: 0.697850, acc.: 60.16%] [G loss: 1.092976]\n",
      "epoch:31 step:29053 [D loss: 0.568137, acc.: 68.75%] [G loss: 1.060869]\n",
      "epoch:31 step:29054 [D loss: 0.713989, acc.: 56.25%] [G loss: 1.623537]\n",
      "epoch:31 step:29055 [D loss: 0.482681, acc.: 75.00%] [G loss: 1.598338]\n",
      "epoch:31 step:29056 [D loss: 0.475961, acc.: 75.78%] [G loss: 1.237207]\n",
      "epoch:31 step:29057 [D loss: 0.616660, acc.: 64.06%] [G loss: 1.199758]\n",
      "epoch:31 step:29058 [D loss: 0.649301, acc.: 66.41%] [G loss: 1.229363]\n",
      "epoch:31 step:29059 [D loss: 0.614678, acc.: 68.75%] [G loss: 1.458261]\n",
      "epoch:31 step:29060 [D loss: 0.408800, acc.: 82.03%] [G loss: 1.645379]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:31 step:29061 [D loss: 0.674646, acc.: 63.28%] [G loss: 1.008810]\n",
      "epoch:31 step:29062 [D loss: 0.589801, acc.: 67.19%] [G loss: 1.553046]\n",
      "epoch:31 step:29063 [D loss: 0.490451, acc.: 73.44%] [G loss: 1.689765]\n",
      "epoch:31 step:29064 [D loss: 0.518122, acc.: 75.00%] [G loss: 1.361812]\n",
      "epoch:31 step:29065 [D loss: 0.490598, acc.: 72.66%] [G loss: 1.105326]\n",
      "epoch:31 step:29066 [D loss: 0.598610, acc.: 70.31%] [G loss: 1.151347]\n",
      "epoch:31 step:29067 [D loss: 0.550077, acc.: 67.97%] [G loss: 1.107431]\n",
      "epoch:31 step:29068 [D loss: 0.548083, acc.: 75.00%] [G loss: 1.566264]\n",
      "epoch:31 step:29069 [D loss: 0.567017, acc.: 71.09%] [G loss: 1.300506]\n",
      "epoch:31 step:29070 [D loss: 0.465360, acc.: 78.12%] [G loss: 1.438942]\n",
      "epoch:31 step:29071 [D loss: 0.594348, acc.: 65.62%] [G loss: 1.136416]\n",
      "epoch:31 step:29072 [D loss: 0.490162, acc.: 78.91%] [G loss: 1.559112]\n",
      "epoch:31 step:29073 [D loss: 0.468949, acc.: 76.56%] [G loss: 1.516463]\n",
      "epoch:31 step:29074 [D loss: 0.588549, acc.: 64.84%] [G loss: 1.585418]\n",
      "epoch:31 step:29075 [D loss: 0.560833, acc.: 70.31%] [G loss: 1.402006]\n",
      "epoch:31 step:29076 [D loss: 0.618416, acc.: 64.06%] [G loss: 1.433590]\n",
      "epoch:31 step:29077 [D loss: 0.558401, acc.: 71.88%] [G loss: 1.831672]\n",
      "epoch:31 step:29078 [D loss: 0.614446, acc.: 67.19%] [G loss: 1.490260]\n",
      "epoch:31 step:29079 [D loss: 0.481282, acc.: 82.03%] [G loss: 1.117366]\n",
      "epoch:31 step:29080 [D loss: 0.522653, acc.: 68.75%] [G loss: 1.197549]\n",
      "epoch:31 step:29081 [D loss: 0.441388, acc.: 77.34%] [G loss: 1.787961]\n",
      "epoch:31 step:29082 [D loss: 0.540877, acc.: 75.00%] [G loss: 1.203402]\n",
      "epoch:31 step:29083 [D loss: 0.415058, acc.: 84.38%] [G loss: 1.751881]\n",
      "epoch:31 step:29084 [D loss: 0.409409, acc.: 83.59%] [G loss: 1.666758]\n",
      "epoch:31 step:29085 [D loss: 0.491976, acc.: 76.56%] [G loss: 1.451612]\n",
      "epoch:31 step:29086 [D loss: 0.503395, acc.: 75.00%] [G loss: 1.391187]\n",
      "epoch:31 step:29087 [D loss: 0.665540, acc.: 64.06%] [G loss: 1.282282]\n",
      "epoch:31 step:29088 [D loss: 0.476018, acc.: 81.25%] [G loss: 1.540126]\n",
      "epoch:31 step:29089 [D loss: 0.557772, acc.: 72.66%] [G loss: 1.355603]\n",
      "epoch:31 step:29090 [D loss: 0.641041, acc.: 67.19%] [G loss: 1.102556]\n",
      "epoch:31 step:29091 [D loss: 0.560616, acc.: 68.75%] [G loss: 1.333053]\n",
      "epoch:31 step:29092 [D loss: 0.688050, acc.: 58.59%] [G loss: 0.975059]\n",
      "epoch:31 step:29093 [D loss: 0.614428, acc.: 65.62%] [G loss: 1.686861]\n",
      "epoch:31 step:29094 [D loss: 0.542710, acc.: 71.09%] [G loss: 1.498385]\n",
      "epoch:31 step:29095 [D loss: 0.562413, acc.: 70.31%] [G loss: 1.260979]\n",
      "epoch:31 step:29096 [D loss: 0.618013, acc.: 66.41%] [G loss: 1.626921]\n",
      "epoch:31 step:29097 [D loss: 0.399767, acc.: 88.28%] [G loss: 1.367038]\n",
      "epoch:31 step:29098 [D loss: 0.423081, acc.: 80.47%] [G loss: 1.487676]\n",
      "epoch:31 step:29099 [D loss: 0.563358, acc.: 71.09%] [G loss: 1.295990]\n",
      "epoch:31 step:29100 [D loss: 0.476744, acc.: 75.78%] [G loss: 1.549997]\n",
      "epoch:31 step:29101 [D loss: 0.425926, acc.: 82.03%] [G loss: 1.287771]\n",
      "epoch:31 step:29102 [D loss: 0.710138, acc.: 53.91%] [G loss: 1.165159]\n",
      "epoch:31 step:29103 [D loss: 0.488648, acc.: 78.12%] [G loss: 1.601542]\n",
      "epoch:31 step:29104 [D loss: 0.499010, acc.: 76.56%] [G loss: 1.268225]\n",
      "epoch:31 step:29105 [D loss: 0.694870, acc.: 59.38%] [G loss: 1.495782]\n",
      "epoch:31 step:29106 [D loss: 0.501944, acc.: 71.88%] [G loss: 1.295041]\n",
      "epoch:31 step:29107 [D loss: 0.446664, acc.: 76.56%] [G loss: 1.771106]\n",
      "epoch:31 step:29108 [D loss: 0.679530, acc.: 67.19%] [G loss: 1.093423]\n",
      "epoch:31 step:29109 [D loss: 0.433557, acc.: 83.59%] [G loss: 1.334678]\n",
      "epoch:31 step:29110 [D loss: 0.414675, acc.: 80.47%] [G loss: 1.249831]\n",
      "epoch:31 step:29111 [D loss: 0.480991, acc.: 76.56%] [G loss: 1.454618]\n",
      "epoch:31 step:29112 [D loss: 0.457212, acc.: 79.69%] [G loss: 1.458926]\n",
      "epoch:31 step:29113 [D loss: 0.589193, acc.: 68.75%] [G loss: 0.989306]\n",
      "epoch:31 step:29114 [D loss: 0.567021, acc.: 67.97%] [G loss: 1.144949]\n",
      "epoch:31 step:29115 [D loss: 0.464836, acc.: 75.78%] [G loss: 1.507907]\n",
      "epoch:31 step:29116 [D loss: 0.340393, acc.: 88.28%] [G loss: 1.844027]\n",
      "epoch:31 step:29117 [D loss: 0.479520, acc.: 79.69%] [G loss: 1.637079]\n",
      "epoch:31 step:29118 [D loss: 0.662660, acc.: 64.06%] [G loss: 1.156023]\n",
      "epoch:31 step:29119 [D loss: 0.883363, acc.: 41.41%] [G loss: 1.131770]\n",
      "epoch:31 step:29120 [D loss: 0.375303, acc.: 85.94%] [G loss: 1.598421]\n",
      "epoch:31 step:29121 [D loss: 0.564530, acc.: 74.22%] [G loss: 1.661628]\n",
      "epoch:31 step:29122 [D loss: 0.583499, acc.: 71.88%] [G loss: 1.582555]\n",
      "epoch:31 step:29123 [D loss: 0.504008, acc.: 76.56%] [G loss: 1.599094]\n",
      "epoch:31 step:29124 [D loss: 0.502702, acc.: 73.44%] [G loss: 1.582421]\n",
      "epoch:31 step:29125 [D loss: 0.557674, acc.: 72.66%] [G loss: 1.084576]\n",
      "epoch:31 step:29126 [D loss: 0.550184, acc.: 72.66%] [G loss: 1.134048]\n",
      "epoch:31 step:29127 [D loss: 0.537782, acc.: 71.88%] [G loss: 1.693864]\n",
      "epoch:31 step:29128 [D loss: 0.556503, acc.: 67.97%] [G loss: 1.258090]\n",
      "epoch:31 step:29129 [D loss: 0.417738, acc.: 83.59%] [G loss: 1.439616]\n",
      "epoch:31 step:29130 [D loss: 0.489548, acc.: 79.69%] [G loss: 1.205071]\n",
      "epoch:31 step:29131 [D loss: 0.421896, acc.: 84.38%] [G loss: 1.203745]\n",
      "epoch:31 step:29132 [D loss: 0.503764, acc.: 75.78%] [G loss: 1.326921]\n",
      "epoch:31 step:29133 [D loss: 0.670352, acc.: 60.94%] [G loss: 1.214391]\n",
      "epoch:31 step:29134 [D loss: 0.571016, acc.: 73.44%] [G loss: 1.116959]\n",
      "epoch:31 step:29135 [D loss: 0.479970, acc.: 78.12%] [G loss: 1.624005]\n",
      "epoch:31 step:29136 [D loss: 0.554062, acc.: 66.41%] [G loss: 1.792308]\n",
      "epoch:31 step:29137 [D loss: 0.666685, acc.: 61.72%] [G loss: 1.373232]\n",
      "epoch:31 step:29138 [D loss: 0.401906, acc.: 82.03%] [G loss: 1.609548]\n",
      "epoch:31 step:29139 [D loss: 0.495636, acc.: 74.22%] [G loss: 1.602198]\n",
      "epoch:31 step:29140 [D loss: 0.511311, acc.: 75.00%] [G loss: 1.826106]\n",
      "epoch:31 step:29141 [D loss: 0.641097, acc.: 59.38%] [G loss: 1.336126]\n",
      "epoch:31 step:29142 [D loss: 0.701152, acc.: 57.81%] [G loss: 1.290886]\n",
      "epoch:31 step:29143 [D loss: 0.631022, acc.: 67.19%] [G loss: 1.830085]\n",
      "epoch:31 step:29144 [D loss: 0.509564, acc.: 72.66%] [G loss: 1.334739]\n",
      "epoch:31 step:29145 [D loss: 0.641442, acc.: 65.62%] [G loss: 1.157744]\n",
      "epoch:31 step:29146 [D loss: 0.475245, acc.: 77.34%] [G loss: 1.257489]\n",
      "epoch:31 step:29147 [D loss: 0.529799, acc.: 72.66%] [G loss: 1.305929]\n",
      "epoch:31 step:29148 [D loss: 0.730893, acc.: 61.72%] [G loss: 1.026125]\n",
      "epoch:31 step:29149 [D loss: 0.656995, acc.: 64.84%] [G loss: 1.936381]\n",
      "epoch:31 step:29150 [D loss: 0.524095, acc.: 77.34%] [G loss: 1.498457]\n",
      "epoch:31 step:29151 [D loss: 0.664014, acc.: 62.50%] [G loss: 1.324990]\n",
      "epoch:31 step:29152 [D loss: 0.346847, acc.: 85.94%] [G loss: 1.587400]\n",
      "epoch:31 step:29153 [D loss: 0.558791, acc.: 71.88%] [G loss: 0.994037]\n",
      "epoch:31 step:29154 [D loss: 0.529442, acc.: 75.00%] [G loss: 1.388538]\n",
      "epoch:31 step:29155 [D loss: 0.447833, acc.: 82.03%] [G loss: 1.730119]\n",
      "epoch:31 step:29156 [D loss: 0.454295, acc.: 83.59%] [G loss: 1.126376]\n",
      "epoch:31 step:29157 [D loss: 0.485608, acc.: 79.69%] [G loss: 1.894087]\n",
      "epoch:31 step:29158 [D loss: 0.533899, acc.: 71.09%] [G loss: 1.304870]\n",
      "epoch:31 step:29159 [D loss: 0.553408, acc.: 68.75%] [G loss: 1.665393]\n",
      "epoch:31 step:29160 [D loss: 0.580238, acc.: 71.88%] [G loss: 1.168815]\n",
      "epoch:31 step:29161 [D loss: 0.655411, acc.: 63.28%] [G loss: 1.493242]\n",
      "epoch:31 step:29162 [D loss: 0.570332, acc.: 71.09%] [G loss: 1.404629]\n",
      "epoch:31 step:29163 [D loss: 0.606631, acc.: 69.53%] [G loss: 1.383058]\n",
      "epoch:31 step:29164 [D loss: 0.322541, acc.: 88.28%] [G loss: 1.987608]\n",
      "epoch:31 step:29165 [D loss: 0.608360, acc.: 71.88%] [G loss: 1.670992]\n",
      "epoch:31 step:29166 [D loss: 0.417311, acc.: 82.03%] [G loss: 1.529714]\n",
      "epoch:31 step:29167 [D loss: 0.648101, acc.: 64.84%] [G loss: 1.344828]\n",
      "epoch:31 step:29168 [D loss: 0.464543, acc.: 79.69%] [G loss: 1.286753]\n",
      "epoch:31 step:29169 [D loss: 0.415111, acc.: 83.59%] [G loss: 1.534337]\n",
      "epoch:31 step:29170 [D loss: 0.613386, acc.: 68.75%] [G loss: 1.418751]\n",
      "epoch:31 step:29171 [D loss: 0.729792, acc.: 57.03%] [G loss: 1.015207]\n",
      "epoch:31 step:29172 [D loss: 0.817476, acc.: 49.22%] [G loss: 1.244554]\n",
      "epoch:31 step:29173 [D loss: 0.591165, acc.: 68.75%] [G loss: 1.557167]\n",
      "epoch:31 step:29174 [D loss: 0.593435, acc.: 68.75%] [G loss: 1.072237]\n",
      "epoch:31 step:29175 [D loss: 0.454709, acc.: 81.25%] [G loss: 1.673667]\n",
      "epoch:31 step:29176 [D loss: 0.602543, acc.: 66.41%] [G loss: 1.139269]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:31 step:29177 [D loss: 0.551450, acc.: 74.22%] [G loss: 1.096988]\n",
      "epoch:31 step:29178 [D loss: 0.570891, acc.: 71.09%] [G loss: 1.683844]\n",
      "epoch:31 step:29179 [D loss: 0.591908, acc.: 67.97%] [G loss: 1.738681]\n",
      "epoch:31 step:29180 [D loss: 0.445649, acc.: 85.94%] [G loss: 1.704885]\n",
      "epoch:31 step:29181 [D loss: 0.597616, acc.: 70.31%] [G loss: 1.057061]\n",
      "epoch:31 step:29182 [D loss: 0.602724, acc.: 64.84%] [G loss: 1.141725]\n",
      "epoch:31 step:29183 [D loss: 0.779787, acc.: 50.00%] [G loss: 1.289958]\n",
      "epoch:31 step:29184 [D loss: 0.602844, acc.: 64.84%] [G loss: 1.588243]\n",
      "epoch:31 step:29185 [D loss: 0.414423, acc.: 84.38%] [G loss: 1.758017]\n",
      "epoch:31 step:29186 [D loss: 0.517767, acc.: 74.22%] [G loss: 1.487911]\n",
      "epoch:31 step:29187 [D loss: 0.508484, acc.: 75.78%] [G loss: 1.291238]\n",
      "epoch:31 step:29188 [D loss: 0.450236, acc.: 81.25%] [G loss: 1.360883]\n",
      "epoch:31 step:29189 [D loss: 0.403305, acc.: 78.91%] [G loss: 1.561672]\n",
      "epoch:31 step:29190 [D loss: 0.414700, acc.: 85.16%] [G loss: 1.840591]\n",
      "epoch:31 step:29191 [D loss: 0.701620, acc.: 58.59%] [G loss: 1.311722]\n",
      "epoch:31 step:29192 [D loss: 0.346398, acc.: 89.84%] [G loss: 1.904671]\n",
      "epoch:31 step:29193 [D loss: 0.704147, acc.: 55.47%] [G loss: 1.267583]\n",
      "epoch:31 step:29194 [D loss: 0.483460, acc.: 76.56%] [G loss: 1.775198]\n",
      "epoch:31 step:29195 [D loss: 0.290601, acc.: 91.41%] [G loss: 2.158168]\n",
      "epoch:31 step:29196 [D loss: 0.480053, acc.: 78.12%] [G loss: 1.787358]\n",
      "epoch:31 step:29197 [D loss: 0.700727, acc.: 59.38%] [G loss: 1.099047]\n",
      "epoch:31 step:29198 [D loss: 0.788743, acc.: 51.56%] [G loss: 1.334722]\n",
      "epoch:31 step:29199 [D loss: 0.662100, acc.: 64.06%] [G loss: 1.343478]\n",
      "epoch:31 step:29200 [D loss: 0.308977, acc.: 89.84%] [G loss: 1.685924]\n",
      "epoch:31 step:29201 [D loss: 0.445927, acc.: 78.91%] [G loss: 1.676681]\n",
      "epoch:31 step:29202 [D loss: 0.623859, acc.: 61.72%] [G loss: 0.998239]\n",
      "epoch:31 step:29203 [D loss: 0.449615, acc.: 79.69%] [G loss: 1.254327]\n",
      "epoch:31 step:29204 [D loss: 0.761264, acc.: 57.81%] [G loss: 1.257886]\n",
      "epoch:31 step:29205 [D loss: 0.441385, acc.: 83.59%] [G loss: 1.823361]\n",
      "epoch:31 step:29206 [D loss: 0.465816, acc.: 81.25%] [G loss: 1.521122]\n",
      "epoch:31 step:29207 [D loss: 0.604772, acc.: 65.62%] [G loss: 1.527976]\n",
      "epoch:31 step:29208 [D loss: 0.380804, acc.: 85.94%] [G loss: 1.215447]\n",
      "epoch:31 step:29209 [D loss: 0.568990, acc.: 67.97%] [G loss: 1.243801]\n",
      "epoch:31 step:29210 [D loss: 0.694674, acc.: 61.72%] [G loss: 1.443471]\n",
      "epoch:31 step:29211 [D loss: 0.322049, acc.: 91.41%] [G loss: 1.534982]\n",
      "epoch:31 step:29212 [D loss: 0.489480, acc.: 75.00%] [G loss: 1.114371]\n",
      "epoch:31 step:29213 [D loss: 0.434577, acc.: 80.47%] [G loss: 1.753576]\n",
      "epoch:31 step:29214 [D loss: 0.444554, acc.: 81.25%] [G loss: 1.468542]\n",
      "epoch:31 step:29215 [D loss: 0.565722, acc.: 69.53%] [G loss: 1.450531]\n",
      "epoch:31 step:29216 [D loss: 0.573395, acc.: 67.19%] [G loss: 1.560224]\n",
      "epoch:31 step:29217 [D loss: 0.435564, acc.: 87.50%] [G loss: 1.453664]\n",
      "epoch:31 step:29218 [D loss: 0.438944, acc.: 80.47%] [G loss: 1.464086]\n",
      "epoch:31 step:29219 [D loss: 0.396026, acc.: 85.94%] [G loss: 1.246497]\n",
      "epoch:31 step:29220 [D loss: 0.583579, acc.: 70.31%] [G loss: 1.058906]\n",
      "epoch:31 step:29221 [D loss: 0.530208, acc.: 75.00%] [G loss: 1.844429]\n",
      "epoch:31 step:29222 [D loss: 0.550642, acc.: 71.09%] [G loss: 1.795857]\n",
      "epoch:31 step:29223 [D loss: 0.456901, acc.: 81.25%] [G loss: 1.732618]\n",
      "epoch:31 step:29224 [D loss: 0.496908, acc.: 75.78%] [G loss: 1.534246]\n",
      "epoch:31 step:29225 [D loss: 0.368834, acc.: 86.72%] [G loss: 1.260664]\n",
      "epoch:31 step:29226 [D loss: 0.414476, acc.: 85.16%] [G loss: 1.742493]\n",
      "epoch:31 step:29227 [D loss: 0.635031, acc.: 65.62%] [G loss: 0.975531]\n",
      "epoch:31 step:29228 [D loss: 0.562433, acc.: 74.22%] [G loss: 1.584789]\n",
      "epoch:31 step:29229 [D loss: 0.522517, acc.: 75.00%] [G loss: 1.709877]\n",
      "epoch:31 step:29230 [D loss: 0.718758, acc.: 57.81%] [G loss: 1.445650]\n",
      "epoch:31 step:29231 [D loss: 0.541742, acc.: 75.78%] [G loss: 1.775092]\n",
      "epoch:31 step:29232 [D loss: 0.509257, acc.: 72.66%] [G loss: 1.442045]\n",
      "epoch:31 step:29233 [D loss: 0.486837, acc.: 77.34%] [G loss: 1.753489]\n",
      "epoch:31 step:29234 [D loss: 0.486600, acc.: 78.91%] [G loss: 1.634678]\n",
      "epoch:31 step:29235 [D loss: 0.483327, acc.: 78.91%] [G loss: 1.512926]\n",
      "epoch:31 step:29236 [D loss: 0.606316, acc.: 70.31%] [G loss: 1.659871]\n",
      "epoch:31 step:29237 [D loss: 0.573125, acc.: 68.75%] [G loss: 1.594558]\n",
      "epoch:31 step:29238 [D loss: 0.755849, acc.: 57.03%] [G loss: 1.193883]\n",
      "epoch:31 step:29239 [D loss: 0.468515, acc.: 78.91%] [G loss: 1.310173]\n",
      "epoch:31 step:29240 [D loss: 0.281354, acc.: 91.41%] [G loss: 1.752449]\n",
      "epoch:31 step:29241 [D loss: 0.735698, acc.: 57.81%] [G loss: 1.545104]\n",
      "epoch:31 step:29242 [D loss: 0.632756, acc.: 64.84%] [G loss: 1.420071]\n",
      "epoch:31 step:29243 [D loss: 0.490285, acc.: 79.69%] [G loss: 1.014224]\n",
      "epoch:31 step:29244 [D loss: 0.419290, acc.: 84.38%] [G loss: 1.101170]\n",
      "epoch:31 step:29245 [D loss: 0.491806, acc.: 76.56%] [G loss: 1.896294]\n",
      "epoch:31 step:29246 [D loss: 0.609428, acc.: 67.19%] [G loss: 1.223170]\n",
      "epoch:31 step:29247 [D loss: 0.490631, acc.: 75.78%] [G loss: 1.697140]\n",
      "epoch:31 step:29248 [D loss: 0.514118, acc.: 74.22%] [G loss: 1.173627]\n",
      "epoch:31 step:29249 [D loss: 0.554681, acc.: 72.66%] [G loss: 1.545833]\n",
      "epoch:31 step:29250 [D loss: 0.509387, acc.: 74.22%] [G loss: 1.353661]\n",
      "epoch:31 step:29251 [D loss: 0.512309, acc.: 74.22%] [G loss: 1.046097]\n",
      "epoch:31 step:29252 [D loss: 0.765577, acc.: 57.81%] [G loss: 1.512989]\n",
      "epoch:31 step:29253 [D loss: 0.626932, acc.: 65.62%] [G loss: 1.894709]\n",
      "epoch:31 step:29254 [D loss: 0.609859, acc.: 63.28%] [G loss: 1.573122]\n",
      "epoch:31 step:29255 [D loss: 0.575095, acc.: 72.66%] [G loss: 1.714982]\n",
      "epoch:31 step:29256 [D loss: 0.770324, acc.: 55.47%] [G loss: 1.596620]\n",
      "epoch:31 step:29257 [D loss: 0.591310, acc.: 70.31%] [G loss: 1.597723]\n",
      "epoch:31 step:29258 [D loss: 0.534172, acc.: 76.56%] [G loss: 0.984498]\n",
      "epoch:31 step:29259 [D loss: 0.444963, acc.: 80.47%] [G loss: 1.605890]\n",
      "epoch:31 step:29260 [D loss: 0.608760, acc.: 71.09%] [G loss: 1.373062]\n",
      "epoch:31 step:29261 [D loss: 0.687810, acc.: 64.84%] [G loss: 1.299582]\n",
      "epoch:31 step:29262 [D loss: 0.511738, acc.: 71.88%] [G loss: 1.388217]\n",
      "epoch:31 step:29263 [D loss: 0.748978, acc.: 57.81%] [G loss: 1.037698]\n",
      "epoch:31 step:29264 [D loss: 0.417071, acc.: 78.91%] [G loss: 1.687352]\n",
      "epoch:31 step:29265 [D loss: 0.444339, acc.: 81.25%] [G loss: 1.736768]\n",
      "epoch:31 step:29266 [D loss: 0.656299, acc.: 64.84%] [G loss: 1.912895]\n",
      "epoch:31 step:29267 [D loss: 0.464750, acc.: 81.25%] [G loss: 1.468377]\n",
      "epoch:31 step:29268 [D loss: 0.652332, acc.: 62.50%] [G loss: 1.035617]\n",
      "epoch:31 step:29269 [D loss: 0.537792, acc.: 71.88%] [G loss: 2.000044]\n",
      "epoch:31 step:29270 [D loss: 0.486521, acc.: 78.12%] [G loss: 1.376956]\n",
      "epoch:31 step:29271 [D loss: 0.449996, acc.: 78.91%] [G loss: 1.707024]\n",
      "epoch:31 step:29272 [D loss: 0.795269, acc.: 55.47%] [G loss: 1.132559]\n",
      "epoch:31 step:29273 [D loss: 0.557126, acc.: 74.22%] [G loss: 1.464155]\n",
      "epoch:31 step:29274 [D loss: 0.656530, acc.: 65.62%] [G loss: 1.166006]\n",
      "epoch:31 step:29275 [D loss: 0.395455, acc.: 83.59%] [G loss: 1.381804]\n",
      "epoch:31 step:29276 [D loss: 0.509436, acc.: 73.44%] [G loss: 1.570200]\n",
      "epoch:31 step:29277 [D loss: 0.612833, acc.: 66.41%] [G loss: 1.447777]\n",
      "epoch:31 step:29278 [D loss: 0.428658, acc.: 82.81%] [G loss: 1.406221]\n",
      "epoch:31 step:29279 [D loss: 0.584863, acc.: 69.53%] [G loss: 1.290051]\n",
      "epoch:31 step:29280 [D loss: 0.532777, acc.: 66.41%] [G loss: 1.743178]\n",
      "epoch:31 step:29281 [D loss: 0.529266, acc.: 74.22%] [G loss: 1.367607]\n",
      "epoch:31 step:29282 [D loss: 0.701651, acc.: 58.59%] [G loss: 1.409093]\n",
      "epoch:31 step:29283 [D loss: 0.591270, acc.: 71.09%] [G loss: 1.293835]\n",
      "epoch:31 step:29284 [D loss: 0.616246, acc.: 68.75%] [G loss: 1.194041]\n",
      "epoch:31 step:29285 [D loss: 0.575784, acc.: 67.19%] [G loss: 1.655832]\n",
      "epoch:31 step:29286 [D loss: 0.529343, acc.: 77.34%] [G loss: 1.493334]\n",
      "epoch:31 step:29287 [D loss: 0.610282, acc.: 67.19%] [G loss: 1.530902]\n",
      "epoch:31 step:29288 [D loss: 0.416687, acc.: 81.25%] [G loss: 1.078387]\n",
      "epoch:31 step:29289 [D loss: 0.439615, acc.: 82.03%] [G loss: 1.284801]\n",
      "epoch:31 step:29290 [D loss: 0.548963, acc.: 75.00%] [G loss: 1.199283]\n",
      "epoch:31 step:29291 [D loss: 0.549740, acc.: 72.66%] [G loss: 1.184064]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:31 step:29292 [D loss: 0.514510, acc.: 73.44%] [G loss: 1.683399]\n",
      "epoch:31 step:29293 [D loss: 0.607382, acc.: 70.31%] [G loss: 1.322046]\n",
      "epoch:31 step:29294 [D loss: 0.567473, acc.: 69.53%] [G loss: 1.403799]\n",
      "epoch:31 step:29295 [D loss: 0.489521, acc.: 72.66%] [G loss: 1.914109]\n",
      "epoch:31 step:29296 [D loss: 0.478369, acc.: 77.34%] [G loss: 1.414003]\n",
      "epoch:31 step:29297 [D loss: 0.511598, acc.: 75.78%] [G loss: 1.588417]\n",
      "epoch:31 step:29298 [D loss: 0.601685, acc.: 67.97%] [G loss: 1.584541]\n",
      "epoch:31 step:29299 [D loss: 0.346362, acc.: 87.50%] [G loss: 1.808851]\n",
      "epoch:31 step:29300 [D loss: 0.483195, acc.: 79.69%] [G loss: 1.069928]\n",
      "epoch:31 step:29301 [D loss: 0.525924, acc.: 77.34%] [G loss: 1.669222]\n",
      "epoch:31 step:29302 [D loss: 0.543957, acc.: 75.00%] [G loss: 1.822016]\n",
      "epoch:31 step:29303 [D loss: 0.747354, acc.: 57.81%] [G loss: 1.003074]\n",
      "epoch:31 step:29304 [D loss: 0.567460, acc.: 67.19%] [G loss: 1.881957]\n",
      "epoch:31 step:29305 [D loss: 0.555000, acc.: 74.22%] [G loss: 1.642626]\n",
      "epoch:31 step:29306 [D loss: 0.623371, acc.: 67.97%] [G loss: 1.696419]\n",
      "epoch:31 step:29307 [D loss: 0.538379, acc.: 71.09%] [G loss: 1.444404]\n",
      "epoch:31 step:29308 [D loss: 0.686705, acc.: 65.62%] [G loss: 1.335607]\n",
      "epoch:31 step:29309 [D loss: 0.667011, acc.: 56.25%] [G loss: 1.337129]\n",
      "epoch:31 step:29310 [D loss: 0.534982, acc.: 71.88%] [G loss: 1.362603]\n",
      "epoch:31 step:29311 [D loss: 0.577575, acc.: 65.62%] [G loss: 1.549024]\n",
      "epoch:31 step:29312 [D loss: 0.342130, acc.: 88.28%] [G loss: 2.052950]\n",
      "epoch:31 step:29313 [D loss: 0.640760, acc.: 64.84%] [G loss: 1.570648]\n",
      "epoch:31 step:29314 [D loss: 0.674296, acc.: 62.50%] [G loss: 0.980059]\n",
      "epoch:31 step:29315 [D loss: 0.642749, acc.: 68.75%] [G loss: 1.065233]\n",
      "epoch:31 step:29316 [D loss: 0.522868, acc.: 78.12%] [G loss: 1.163963]\n",
      "epoch:31 step:29317 [D loss: 0.450474, acc.: 79.69%] [G loss: 1.483247]\n",
      "epoch:31 step:29318 [D loss: 0.478653, acc.: 82.81%] [G loss: 1.651299]\n",
      "epoch:31 step:29319 [D loss: 0.534761, acc.: 71.09%] [G loss: 1.533106]\n",
      "epoch:31 step:29320 [D loss: 0.605919, acc.: 67.19%] [G loss: 1.059961]\n",
      "epoch:31 step:29321 [D loss: 0.457635, acc.: 84.38%] [G loss: 1.620894]\n",
      "epoch:31 step:29322 [D loss: 0.649487, acc.: 59.38%] [G loss: 1.349790]\n",
      "epoch:31 step:29323 [D loss: 0.732704, acc.: 56.25%] [G loss: 1.125783]\n",
      "epoch:31 step:29324 [D loss: 0.570167, acc.: 65.62%] [G loss: 1.157652]\n",
      "epoch:31 step:29325 [D loss: 0.463831, acc.: 78.12%] [G loss: 1.938100]\n",
      "epoch:31 step:29326 [D loss: 0.553089, acc.: 76.56%] [G loss: 1.572018]\n",
      "epoch:31 step:29327 [D loss: 0.447275, acc.: 81.25%] [G loss: 1.278900]\n",
      "epoch:31 step:29328 [D loss: 0.469962, acc.: 77.34%] [G loss: 1.934032]\n",
      "epoch:31 step:29329 [D loss: 0.493025, acc.: 75.00%] [G loss: 2.012415]\n",
      "epoch:31 step:29330 [D loss: 0.434525, acc.: 84.38%] [G loss: 1.193728]\n",
      "epoch:31 step:29331 [D loss: 0.662171, acc.: 64.06%] [G loss: 1.135561]\n",
      "epoch:31 step:29332 [D loss: 0.626736, acc.: 67.97%] [G loss: 1.325028]\n",
      "epoch:31 step:29333 [D loss: 0.651364, acc.: 64.06%] [G loss: 1.541907]\n",
      "epoch:31 step:29334 [D loss: 0.480731, acc.: 77.34%] [G loss: 1.573494]\n",
      "epoch:31 step:29335 [D loss: 0.555747, acc.: 74.22%] [G loss: 1.567277]\n",
      "epoch:31 step:29336 [D loss: 0.536413, acc.: 70.31%] [G loss: 1.428646]\n",
      "epoch:31 step:29337 [D loss: 0.403420, acc.: 83.59%] [G loss: 1.517931]\n",
      "epoch:31 step:29338 [D loss: 0.492315, acc.: 79.69%] [G loss: 1.429243]\n",
      "epoch:31 step:29339 [D loss: 0.439420, acc.: 81.25%] [G loss: 1.164608]\n",
      "epoch:31 step:29340 [D loss: 0.654547, acc.: 67.19%] [G loss: 1.774947]\n",
      "epoch:31 step:29341 [D loss: 0.485071, acc.: 78.91%] [G loss: 1.605133]\n",
      "epoch:31 step:29342 [D loss: 0.459803, acc.: 83.59%] [G loss: 1.080795]\n",
      "epoch:31 step:29343 [D loss: 0.335469, acc.: 89.06%] [G loss: 1.929846]\n",
      "epoch:31 step:29344 [D loss: 0.474670, acc.: 74.22%] [G loss: 1.874259]\n",
      "epoch:31 step:29345 [D loss: 0.740704, acc.: 57.03%] [G loss: 0.885864]\n",
      "epoch:31 step:29346 [D loss: 0.547453, acc.: 73.44%] [G loss: 1.148664]\n",
      "epoch:31 step:29347 [D loss: 0.403566, acc.: 86.72%] [G loss: 1.471696]\n",
      "epoch:31 step:29348 [D loss: 0.681377, acc.: 57.81%] [G loss: 0.988404]\n",
      "epoch:31 step:29349 [D loss: 0.517704, acc.: 76.56%] [G loss: 1.446344]\n",
      "epoch:31 step:29350 [D loss: 0.557521, acc.: 71.09%] [G loss: 0.998726]\n",
      "epoch:31 step:29351 [D loss: 0.536947, acc.: 75.00%] [G loss: 1.325558]\n",
      "epoch:31 step:29352 [D loss: 0.517333, acc.: 71.88%] [G loss: 1.719501]\n",
      "epoch:31 step:29353 [D loss: 0.504831, acc.: 75.78%] [G loss: 1.718403]\n",
      "epoch:31 step:29354 [D loss: 0.437283, acc.: 78.91%] [G loss: 1.095174]\n",
      "epoch:31 step:29355 [D loss: 0.504341, acc.: 75.00%] [G loss: 1.864231]\n",
      "epoch:31 step:29356 [D loss: 0.446947, acc.: 79.69%] [G loss: 1.573045]\n",
      "epoch:31 step:29357 [D loss: 0.641983, acc.: 69.53%] [G loss: 1.137810]\n",
      "epoch:31 step:29358 [D loss: 0.472375, acc.: 81.25%] [G loss: 1.301565]\n",
      "epoch:31 step:29359 [D loss: 0.689641, acc.: 62.50%] [G loss: 1.033193]\n",
      "epoch:31 step:29360 [D loss: 0.751708, acc.: 56.25%] [G loss: 1.369913]\n",
      "epoch:31 step:29361 [D loss: 0.523039, acc.: 75.00%] [G loss: 1.162290]\n",
      "epoch:31 step:29362 [D loss: 0.526764, acc.: 76.56%] [G loss: 1.700400]\n",
      "epoch:31 step:29363 [D loss: 0.822107, acc.: 50.78%] [G loss: 1.218689]\n",
      "epoch:31 step:29364 [D loss: 0.570390, acc.: 71.88%] [G loss: 1.455068]\n",
      "epoch:31 step:29365 [D loss: 0.601518, acc.: 61.72%] [G loss: 1.554205]\n",
      "epoch:31 step:29366 [D loss: 0.464858, acc.: 78.91%] [G loss: 0.969751]\n",
      "epoch:31 step:29367 [D loss: 0.563355, acc.: 71.09%] [G loss: 1.767009]\n",
      "epoch:31 step:29368 [D loss: 0.700653, acc.: 60.16%] [G loss: 1.359474]\n",
      "epoch:31 step:29369 [D loss: 0.523750, acc.: 75.00%] [G loss: 1.532753]\n",
      "epoch:31 step:29370 [D loss: 0.721072, acc.: 55.47%] [G loss: 1.225218]\n",
      "epoch:31 step:29371 [D loss: 0.690796, acc.: 64.06%] [G loss: 1.343707]\n",
      "epoch:31 step:29372 [D loss: 0.477797, acc.: 78.12%] [G loss: 1.428519]\n",
      "epoch:31 step:29373 [D loss: 0.537606, acc.: 78.12%] [G loss: 1.351702]\n",
      "epoch:31 step:29374 [D loss: 0.477717, acc.: 75.78%] [G loss: 1.786059]\n",
      "epoch:31 step:29375 [D loss: 0.447323, acc.: 79.69%] [G loss: 1.580546]\n",
      "epoch:31 step:29376 [D loss: 0.538216, acc.: 75.00%] [G loss: 1.471817]\n",
      "epoch:31 step:29377 [D loss: 0.634286, acc.: 64.06%] [G loss: 1.673027]\n",
      "epoch:31 step:29378 [D loss: 0.393292, acc.: 82.81%] [G loss: 1.690585]\n",
      "epoch:31 step:29379 [D loss: 0.462735, acc.: 81.25%] [G loss: 1.655984]\n",
      "epoch:31 step:29380 [D loss: 0.583874, acc.: 68.75%] [G loss: 1.378801]\n",
      "epoch:31 step:29381 [D loss: 0.494701, acc.: 75.78%] [G loss: 1.761310]\n",
      "epoch:31 step:29382 [D loss: 0.592460, acc.: 68.75%] [G loss: 1.381575]\n",
      "epoch:31 step:29383 [D loss: 0.508202, acc.: 75.78%] [G loss: 1.632626]\n",
      "epoch:31 step:29384 [D loss: 0.474761, acc.: 80.47%] [G loss: 1.212956]\n",
      "epoch:31 step:29385 [D loss: 0.533503, acc.: 77.34%] [G loss: 1.675514]\n",
      "epoch:31 step:29386 [D loss: 0.452464, acc.: 82.81%] [G loss: 1.720434]\n",
      "epoch:31 step:29387 [D loss: 0.315032, acc.: 90.62%] [G loss: 1.853482]\n",
      "epoch:31 step:29388 [D loss: 0.675577, acc.: 61.72%] [G loss: 1.518725]\n",
      "epoch:31 step:29389 [D loss: 0.612365, acc.: 70.31%] [G loss: 1.135441]\n",
      "epoch:31 step:29390 [D loss: 0.542005, acc.: 73.44%] [G loss: 1.381017]\n",
      "epoch:31 step:29391 [D loss: 0.365027, acc.: 86.72%] [G loss: 1.509900]\n",
      "epoch:31 step:29392 [D loss: 0.484793, acc.: 79.69%] [G loss: 1.241256]\n",
      "epoch:31 step:29393 [D loss: 0.550341, acc.: 73.44%] [G loss: 1.490641]\n",
      "epoch:31 step:29394 [D loss: 0.449628, acc.: 85.94%] [G loss: 1.494031]\n",
      "epoch:31 step:29395 [D loss: 0.528498, acc.: 74.22%] [G loss: 1.321384]\n",
      "epoch:31 step:29396 [D loss: 0.635827, acc.: 64.06%] [G loss: 1.477122]\n",
      "epoch:31 step:29397 [D loss: 0.522935, acc.: 75.78%] [G loss: 1.474959]\n",
      "epoch:31 step:29398 [D loss: 0.763889, acc.: 52.34%] [G loss: 1.331193]\n",
      "epoch:31 step:29399 [D loss: 0.636388, acc.: 64.06%] [G loss: 1.598428]\n",
      "epoch:31 step:29400 [D loss: 0.560452, acc.: 67.97%] [G loss: 1.322240]\n",
      "epoch:31 step:29401 [D loss: 0.548187, acc.: 74.22%] [G loss: 1.405699]\n",
      "epoch:31 step:29402 [D loss: 0.613832, acc.: 64.06%] [G loss: 1.148598]\n",
      "epoch:31 step:29403 [D loss: 0.523596, acc.: 76.56%] [G loss: 1.357783]\n",
      "epoch:31 step:29404 [D loss: 0.431378, acc.: 83.59%] [G loss: 1.590594]\n",
      "epoch:31 step:29405 [D loss: 0.571676, acc.: 67.97%] [G loss: 1.335104]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:31 step:29406 [D loss: 0.681342, acc.: 61.72%] [G loss: 1.194040]\n",
      "epoch:31 step:29407 [D loss: 0.348199, acc.: 89.06%] [G loss: 1.347998]\n",
      "epoch:31 step:29408 [D loss: 0.568175, acc.: 75.78%] [G loss: 1.617322]\n",
      "epoch:31 step:29409 [D loss: 0.448628, acc.: 81.25%] [G loss: 1.770977]\n",
      "epoch:31 step:29410 [D loss: 0.676031, acc.: 63.28%] [G loss: 1.534362]\n",
      "epoch:31 step:29411 [D loss: 0.438856, acc.: 77.34%] [G loss: 1.825464]\n",
      "epoch:31 step:29412 [D loss: 0.506191, acc.: 79.69%] [G loss: 2.304153]\n",
      "epoch:31 step:29413 [D loss: 0.400841, acc.: 87.50%] [G loss: 1.372342]\n",
      "epoch:31 step:29414 [D loss: 0.555389, acc.: 71.09%] [G loss: 1.370192]\n",
      "epoch:31 step:29415 [D loss: 0.522097, acc.: 74.22%] [G loss: 1.535822]\n",
      "epoch:31 step:29416 [D loss: 0.535789, acc.: 71.09%] [G loss: 1.360797]\n",
      "epoch:31 step:29417 [D loss: 0.353541, acc.: 86.72%] [G loss: 1.509031]\n",
      "epoch:31 step:29418 [D loss: 0.541203, acc.: 72.66%] [G loss: 1.838116]\n",
      "epoch:31 step:29419 [D loss: 0.419843, acc.: 85.16%] [G loss: 1.468945]\n",
      "epoch:31 step:29420 [D loss: 0.528150, acc.: 73.44%] [G loss: 1.189636]\n",
      "epoch:31 step:29421 [D loss: 0.694496, acc.: 57.03%] [G loss: 1.053702]\n",
      "epoch:31 step:29422 [D loss: 0.543904, acc.: 71.88%] [G loss: 1.463179]\n",
      "epoch:31 step:29423 [D loss: 0.731977, acc.: 54.69%] [G loss: 1.530543]\n",
      "epoch:31 step:29424 [D loss: 0.368851, acc.: 85.94%] [G loss: 1.256222]\n",
      "epoch:31 step:29425 [D loss: 0.547131, acc.: 72.66%] [G loss: 1.136392]\n",
      "epoch:31 step:29426 [D loss: 0.693890, acc.: 53.12%] [G loss: 1.754149]\n",
      "epoch:31 step:29427 [D loss: 0.587518, acc.: 66.41%] [G loss: 1.950936]\n",
      "epoch:31 step:29428 [D loss: 0.649839, acc.: 66.41%] [G loss: 1.500090]\n",
      "epoch:31 step:29429 [D loss: 0.621417, acc.: 64.84%] [G loss: 2.169481]\n",
      "epoch:31 step:29430 [D loss: 0.556789, acc.: 71.09%] [G loss: 1.889163]\n",
      "epoch:31 step:29431 [D loss: 0.554459, acc.: 71.88%] [G loss: 1.666602]\n",
      "epoch:31 step:29432 [D loss: 0.583767, acc.: 63.28%] [G loss: 1.185039]\n",
      "epoch:31 step:29433 [D loss: 0.499807, acc.: 80.47%] [G loss: 1.669283]\n",
      "epoch:31 step:29434 [D loss: 0.517352, acc.: 78.91%] [G loss: 1.367726]\n",
      "epoch:31 step:29435 [D loss: 0.517420, acc.: 73.44%] [G loss: 1.679180]\n",
      "epoch:31 step:29436 [D loss: 0.545630, acc.: 77.34%] [G loss: 1.092546]\n",
      "epoch:31 step:29437 [D loss: 0.384911, acc.: 89.06%] [G loss: 1.368772]\n",
      "epoch:31 step:29438 [D loss: 0.692183, acc.: 60.16%] [G loss: 1.860127]\n",
      "epoch:31 step:29439 [D loss: 0.474878, acc.: 76.56%] [G loss: 1.969014]\n",
      "epoch:31 step:29440 [D loss: 0.695812, acc.: 60.94%] [G loss: 1.597180]\n",
      "epoch:31 step:29441 [D loss: 0.451684, acc.: 81.25%] [G loss: 0.930960]\n",
      "epoch:31 step:29442 [D loss: 0.477218, acc.: 78.91%] [G loss: 1.622155]\n",
      "epoch:31 step:29443 [D loss: 0.485853, acc.: 80.47%] [G loss: 1.606426]\n",
      "epoch:31 step:29444 [D loss: 0.597688, acc.: 70.31%] [G loss: 1.360975]\n",
      "epoch:31 step:29445 [D loss: 0.534991, acc.: 71.88%] [G loss: 1.300421]\n",
      "epoch:31 step:29446 [D loss: 0.469449, acc.: 79.69%] [G loss: 1.515007]\n",
      "epoch:31 step:29447 [D loss: 0.595312, acc.: 67.97%] [G loss: 1.165542]\n",
      "epoch:31 step:29448 [D loss: 0.775230, acc.: 49.22%] [G loss: 1.483706]\n",
      "epoch:31 step:29449 [D loss: 0.630354, acc.: 64.84%] [G loss: 1.161822]\n",
      "epoch:31 step:29450 [D loss: 0.364640, acc.: 87.50%] [G loss: 1.770033]\n",
      "epoch:31 step:29451 [D loss: 0.644680, acc.: 65.62%] [G loss: 1.600800]\n",
      "epoch:31 step:29452 [D loss: 0.385851, acc.: 88.28%] [G loss: 1.455649]\n",
      "epoch:31 step:29453 [D loss: 0.438748, acc.: 82.81%] [G loss: 1.819150]\n",
      "epoch:31 step:29454 [D loss: 0.727038, acc.: 53.12%] [G loss: 1.484128]\n",
      "epoch:31 step:29455 [D loss: 0.500831, acc.: 76.56%] [G loss: 1.748812]\n",
      "epoch:31 step:29456 [D loss: 0.566472, acc.: 71.88%] [G loss: 1.127589]\n",
      "epoch:31 step:29457 [D loss: 0.540904, acc.: 73.44%] [G loss: 1.572970]\n",
      "epoch:31 step:29458 [D loss: 0.463132, acc.: 79.69%] [G loss: 2.166339]\n",
      "epoch:31 step:29459 [D loss: 0.638552, acc.: 64.84%] [G loss: 1.149162]\n",
      "epoch:31 step:29460 [D loss: 0.450357, acc.: 82.03%] [G loss: 1.318189]\n",
      "epoch:31 step:29461 [D loss: 0.514978, acc.: 76.56%] [G loss: 1.720963]\n",
      "epoch:31 step:29462 [D loss: 0.312383, acc.: 92.97%] [G loss: 1.647189]\n",
      "epoch:31 step:29463 [D loss: 0.583310, acc.: 68.75%] [G loss: 1.338300]\n",
      "epoch:31 step:29464 [D loss: 0.473002, acc.: 85.16%] [G loss: 1.154164]\n",
      "epoch:31 step:29465 [D loss: 0.435151, acc.: 83.59%] [G loss: 1.606079]\n",
      "epoch:31 step:29466 [D loss: 0.563432, acc.: 71.88%] [G loss: 1.204340]\n",
      "epoch:31 step:29467 [D loss: 0.597007, acc.: 70.31%] [G loss: 1.387168]\n",
      "epoch:31 step:29468 [D loss: 0.693085, acc.: 58.59%] [G loss: 1.532344]\n",
      "epoch:31 step:29469 [D loss: 0.707818, acc.: 59.38%] [G loss: 1.491452]\n",
      "epoch:31 step:29470 [D loss: 0.541783, acc.: 75.00%] [G loss: 1.636129]\n",
      "epoch:31 step:29471 [D loss: 0.478923, acc.: 79.69%] [G loss: 1.434434]\n",
      "epoch:31 step:29472 [D loss: 0.404406, acc.: 83.59%] [G loss: 1.408475]\n",
      "epoch:31 step:29473 [D loss: 0.681012, acc.: 57.81%] [G loss: 1.225763]\n",
      "epoch:31 step:29474 [D loss: 0.630720, acc.: 62.50%] [G loss: 1.156145]\n",
      "epoch:31 step:29475 [D loss: 0.633999, acc.: 64.06%] [G loss: 1.545794]\n",
      "epoch:31 step:29476 [D loss: 0.501013, acc.: 75.00%] [G loss: 1.005457]\n",
      "epoch:31 step:29477 [D loss: 0.629387, acc.: 67.97%] [G loss: 1.217432]\n",
      "epoch:31 step:29478 [D loss: 0.428479, acc.: 82.03%] [G loss: 1.248495]\n",
      "epoch:31 step:29479 [D loss: 0.535711, acc.: 71.09%] [G loss: 1.500245]\n",
      "epoch:31 step:29480 [D loss: 0.519998, acc.: 73.44%] [G loss: 1.279131]\n",
      "epoch:31 step:29481 [D loss: 0.565934, acc.: 67.97%] [G loss: 1.203314]\n",
      "epoch:31 step:29482 [D loss: 0.500340, acc.: 75.78%] [G loss: 1.652634]\n",
      "epoch:31 step:29483 [D loss: 0.605932, acc.: 65.62%] [G loss: 1.501302]\n",
      "epoch:31 step:29484 [D loss: 0.594407, acc.: 64.06%] [G loss: 1.498916]\n",
      "epoch:31 step:29485 [D loss: 0.581546, acc.: 70.31%] [G loss: 1.379865]\n",
      "epoch:31 step:29486 [D loss: 0.658564, acc.: 63.28%] [G loss: 1.661342]\n",
      "epoch:31 step:29487 [D loss: 0.453679, acc.: 79.69%] [G loss: 1.750934]\n",
      "epoch:31 step:29488 [D loss: 0.471834, acc.: 80.47%] [G loss: 1.614580]\n",
      "epoch:31 step:29489 [D loss: 0.615870, acc.: 64.84%] [G loss: 1.485728]\n",
      "epoch:31 step:29490 [D loss: 0.606142, acc.: 65.62%] [G loss: 1.221839]\n",
      "epoch:31 step:29491 [D loss: 0.684447, acc.: 57.81%] [G loss: 1.473222]\n",
      "epoch:31 step:29492 [D loss: 0.412980, acc.: 85.94%] [G loss: 1.510094]\n",
      "epoch:31 step:29493 [D loss: 0.611848, acc.: 68.75%] [G loss: 1.407327]\n",
      "epoch:31 step:29494 [D loss: 0.416216, acc.: 82.81%] [G loss: 1.818003]\n",
      "epoch:31 step:29495 [D loss: 0.421504, acc.: 82.03%] [G loss: 1.448582]\n",
      "epoch:31 step:29496 [D loss: 0.447705, acc.: 78.12%] [G loss: 1.241210]\n",
      "epoch:31 step:29497 [D loss: 0.470584, acc.: 79.69%] [G loss: 1.732877]\n",
      "epoch:31 step:29498 [D loss: 0.437057, acc.: 82.81%] [G loss: 1.442975]\n",
      "epoch:31 step:29499 [D loss: 0.391410, acc.: 87.50%] [G loss: 1.923553]\n",
      "epoch:31 step:29500 [D loss: 0.439950, acc.: 77.34%] [G loss: 1.595963]\n",
      "epoch:31 step:29501 [D loss: 0.378007, acc.: 87.50%] [G loss: 1.701554]\n",
      "epoch:31 step:29502 [D loss: 0.772569, acc.: 49.22%] [G loss: 1.528100]\n",
      "epoch:31 step:29503 [D loss: 0.769754, acc.: 50.78%] [G loss: 0.887512]\n",
      "epoch:31 step:29504 [D loss: 0.649791, acc.: 63.28%] [G loss: 1.037311]\n",
      "epoch:31 step:29505 [D loss: 0.457780, acc.: 78.91%] [G loss: 1.177304]\n",
      "epoch:31 step:29506 [D loss: 0.447317, acc.: 84.38%] [G loss: 1.718491]\n",
      "epoch:31 step:29507 [D loss: 0.682763, acc.: 60.16%] [G loss: 1.275758]\n",
      "epoch:31 step:29508 [D loss: 0.455195, acc.: 78.12%] [G loss: 1.529916]\n",
      "epoch:31 step:29509 [D loss: 0.512758, acc.: 77.34%] [G loss: 1.528805]\n",
      "epoch:31 step:29510 [D loss: 0.557161, acc.: 69.53%] [G loss: 1.247936]\n",
      "epoch:31 step:29511 [D loss: 0.645334, acc.: 63.28%] [G loss: 1.299138]\n",
      "epoch:31 step:29512 [D loss: 0.426477, acc.: 80.47%] [G loss: 1.471358]\n",
      "epoch:31 step:29513 [D loss: 0.595888, acc.: 68.75%] [G loss: 1.405428]\n",
      "epoch:31 step:29514 [D loss: 0.502497, acc.: 78.91%] [G loss: 1.477270]\n",
      "epoch:31 step:29515 [D loss: 0.372868, acc.: 85.16%] [G loss: 1.070808]\n",
      "epoch:31 step:29516 [D loss: 0.504023, acc.: 79.69%] [G loss: 1.191107]\n",
      "epoch:31 step:29517 [D loss: 0.599573, acc.: 67.97%] [G loss: 1.296950]\n",
      "epoch:31 step:29518 [D loss: 0.531846, acc.: 75.00%] [G loss: 0.902800]\n",
      "epoch:31 step:29519 [D loss: 0.676476, acc.: 63.28%] [G loss: 1.219402]\n",
      "epoch:31 step:29520 [D loss: 0.580180, acc.: 66.41%] [G loss: 1.616709]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:31 step:29521 [D loss: 0.493497, acc.: 77.34%] [G loss: 1.798919]\n",
      "epoch:31 step:29522 [D loss: 0.635857, acc.: 67.97%] [G loss: 1.708387]\n",
      "epoch:31 step:29523 [D loss: 0.508601, acc.: 71.88%] [G loss: 1.711534]\n",
      "epoch:31 step:29524 [D loss: 0.609173, acc.: 71.88%] [G loss: 1.751212]\n",
      "epoch:31 step:29525 [D loss: 0.511683, acc.: 77.34%] [G loss: 1.753326]\n",
      "epoch:31 step:29526 [D loss: 0.619437, acc.: 65.62%] [G loss: 1.090142]\n",
      "epoch:31 step:29527 [D loss: 0.579165, acc.: 70.31%] [G loss: 1.216323]\n",
      "epoch:31 step:29528 [D loss: 0.633823, acc.: 67.97%] [G loss: 1.232950]\n",
      "epoch:31 step:29529 [D loss: 0.553485, acc.: 67.97%] [G loss: 1.394048]\n",
      "epoch:31 step:29530 [D loss: 0.703987, acc.: 63.28%] [G loss: 1.016322]\n",
      "epoch:31 step:29531 [D loss: 0.372303, acc.: 88.28%] [G loss: 1.730863]\n",
      "epoch:31 step:29532 [D loss: 0.569119, acc.: 70.31%] [G loss: 1.398577]\n",
      "epoch:31 step:29533 [D loss: 0.457675, acc.: 78.91%] [G loss: 1.736160]\n",
      "epoch:31 step:29534 [D loss: 0.369590, acc.: 86.72%] [G loss: 1.820434]\n",
      "epoch:31 step:29535 [D loss: 0.542770, acc.: 74.22%] [G loss: 1.528689]\n",
      "epoch:31 step:29536 [D loss: 0.598556, acc.: 67.19%] [G loss: 1.590099]\n",
      "epoch:31 step:29537 [D loss: 0.645483, acc.: 60.16%] [G loss: 1.315491]\n",
      "epoch:31 step:29538 [D loss: 0.555231, acc.: 67.19%] [G loss: 1.422203]\n",
      "epoch:31 step:29539 [D loss: 0.483873, acc.: 81.25%] [G loss: 2.042751]\n",
      "epoch:31 step:29540 [D loss: 0.579700, acc.: 66.41%] [G loss: 1.537212]\n",
      "epoch:31 step:29541 [D loss: 0.590444, acc.: 68.75%] [G loss: 1.262012]\n",
      "epoch:31 step:29542 [D loss: 0.625376, acc.: 66.41%] [G loss: 1.129634]\n",
      "epoch:31 step:29543 [D loss: 0.619607, acc.: 66.41%] [G loss: 1.454543]\n",
      "epoch:31 step:29544 [D loss: 0.509751, acc.: 71.88%] [G loss: 1.868606]\n",
      "epoch:31 step:29545 [D loss: 0.520142, acc.: 74.22%] [G loss: 1.266033]\n",
      "epoch:31 step:29546 [D loss: 0.494048, acc.: 73.44%] [G loss: 1.377232]\n",
      "epoch:31 step:29547 [D loss: 0.692430, acc.: 60.16%] [G loss: 1.174683]\n",
      "epoch:31 step:29548 [D loss: 0.501210, acc.: 78.12%] [G loss: 1.252821]\n",
      "epoch:31 step:29549 [D loss: 0.423533, acc.: 82.81%] [G loss: 1.397808]\n",
      "epoch:31 step:29550 [D loss: 0.454597, acc.: 82.03%] [G loss: 1.363634]\n",
      "epoch:31 step:29551 [D loss: 0.462094, acc.: 81.25%] [G loss: 1.441963]\n",
      "epoch:31 step:29552 [D loss: 0.439230, acc.: 78.91%] [G loss: 1.397935]\n",
      "epoch:31 step:29553 [D loss: 0.446781, acc.: 85.16%] [G loss: 1.649268]\n",
      "epoch:31 step:29554 [D loss: 0.697276, acc.: 64.06%] [G loss: 1.334126]\n",
      "epoch:31 step:29555 [D loss: 0.722662, acc.: 57.03%] [G loss: 1.176972]\n",
      "epoch:31 step:29556 [D loss: 0.509227, acc.: 73.44%] [G loss: 1.775407]\n",
      "epoch:31 step:29557 [D loss: 0.476513, acc.: 78.12%] [G loss: 1.342240]\n",
      "epoch:31 step:29558 [D loss: 0.500625, acc.: 76.56%] [G loss: 1.096235]\n",
      "epoch:31 step:29559 [D loss: 0.483967, acc.: 82.03%] [G loss: 1.204263]\n",
      "epoch:31 step:29560 [D loss: 0.477475, acc.: 82.81%] [G loss: 1.775011]\n",
      "epoch:31 step:29561 [D loss: 0.402579, acc.: 86.72%] [G loss: 1.580253]\n",
      "epoch:31 step:29562 [D loss: 0.435850, acc.: 82.03%] [G loss: 1.599576]\n",
      "epoch:31 step:29563 [D loss: 0.639492, acc.: 63.28%] [G loss: 1.852706]\n",
      "epoch:31 step:29564 [D loss: 0.497932, acc.: 82.81%] [G loss: 1.550409]\n",
      "epoch:31 step:29565 [D loss: 0.566604, acc.: 70.31%] [G loss: 1.195647]\n",
      "epoch:31 step:29566 [D loss: 0.513920, acc.: 71.88%] [G loss: 1.189788]\n",
      "epoch:31 step:29567 [D loss: 0.553507, acc.: 69.53%] [G loss: 1.465796]\n",
      "epoch:31 step:29568 [D loss: 0.753388, acc.: 51.56%] [G loss: 1.220389]\n",
      "epoch:31 step:29569 [D loss: 0.719331, acc.: 53.12%] [G loss: 1.430969]\n",
      "epoch:31 step:29570 [D loss: 0.518522, acc.: 66.41%] [G loss: 1.805908]\n",
      "epoch:31 step:29571 [D loss: 0.498412, acc.: 76.56%] [G loss: 2.014529]\n",
      "epoch:31 step:29572 [D loss: 0.635854, acc.: 63.28%] [G loss: 1.785568]\n",
      "epoch:31 step:29573 [D loss: 0.450787, acc.: 81.25%] [G loss: 1.608010]\n",
      "epoch:31 step:29574 [D loss: 0.594684, acc.: 68.75%] [G loss: 1.209869]\n",
      "epoch:31 step:29575 [D loss: 0.470780, acc.: 79.69%] [G loss: 1.530233]\n",
      "epoch:31 step:29576 [D loss: 0.530510, acc.: 74.22%] [G loss: 1.398422]\n",
      "epoch:31 step:29577 [D loss: 0.490786, acc.: 82.81%] [G loss: 1.323375]\n",
      "epoch:31 step:29578 [D loss: 0.409427, acc.: 85.94%] [G loss: 1.568551]\n",
      "epoch:31 step:29579 [D loss: 0.683980, acc.: 61.72%] [G loss: 1.425678]\n",
      "epoch:31 step:29580 [D loss: 0.566206, acc.: 67.97%] [G loss: 1.724868]\n",
      "epoch:31 step:29581 [D loss: 0.491993, acc.: 73.44%] [G loss: 1.677553]\n",
      "epoch:31 step:29582 [D loss: 0.424116, acc.: 82.81%] [G loss: 1.396858]\n",
      "epoch:31 step:29583 [D loss: 0.770353, acc.: 53.91%] [G loss: 1.536257]\n",
      "epoch:31 step:29584 [D loss: 0.537407, acc.: 75.78%] [G loss: 1.715929]\n",
      "epoch:31 step:29585 [D loss: 0.513449, acc.: 74.22%] [G loss: 1.577900]\n",
      "epoch:31 step:29586 [D loss: 0.510508, acc.: 82.03%] [G loss: 1.311930]\n",
      "epoch:31 step:29587 [D loss: 0.487303, acc.: 77.34%] [G loss: 1.482208]\n",
      "epoch:31 step:29588 [D loss: 0.509769, acc.: 74.22%] [G loss: 1.327451]\n",
      "epoch:31 step:29589 [D loss: 0.660884, acc.: 62.50%] [G loss: 1.793771]\n",
      "epoch:31 step:29590 [D loss: 0.499979, acc.: 74.22%] [G loss: 1.356726]\n",
      "epoch:31 step:29591 [D loss: 0.560983, acc.: 72.66%] [G loss: 1.161896]\n",
      "epoch:31 step:29592 [D loss: 0.680130, acc.: 57.81%] [G loss: 1.090880]\n",
      "epoch:31 step:29593 [D loss: 0.473407, acc.: 78.91%] [G loss: 1.411025]\n",
      "epoch:31 step:29594 [D loss: 0.687170, acc.: 57.81%] [G loss: 1.408561]\n",
      "epoch:31 step:29595 [D loss: 0.486631, acc.: 75.00%] [G loss: 1.540381]\n",
      "epoch:31 step:29596 [D loss: 0.460471, acc.: 75.78%] [G loss: 1.757311]\n",
      "epoch:31 step:29597 [D loss: 0.396847, acc.: 83.59%] [G loss: 1.487474]\n",
      "epoch:31 step:29598 [D loss: 0.534272, acc.: 74.22%] [G loss: 1.648629]\n",
      "epoch:31 step:29599 [D loss: 0.293208, acc.: 92.19%] [G loss: 1.621631]\n",
      "epoch:31 step:29600 [D loss: 0.687100, acc.: 61.72%] [G loss: 1.051708]\n",
      "epoch:31 step:29601 [D loss: 0.487986, acc.: 78.12%] [G loss: 1.312876]\n",
      "epoch:31 step:29602 [D loss: 0.577535, acc.: 69.53%] [G loss: 1.479266]\n",
      "epoch:31 step:29603 [D loss: 0.468651, acc.: 76.56%] [G loss: 1.558892]\n",
      "epoch:31 step:29604 [D loss: 0.543615, acc.: 78.12%] [G loss: 1.298817]\n",
      "epoch:31 step:29605 [D loss: 0.614553, acc.: 67.97%] [G loss: 1.194758]\n",
      "epoch:31 step:29606 [D loss: 0.511439, acc.: 78.12%] [G loss: 1.619424]\n",
      "epoch:31 step:29607 [D loss: 0.717537, acc.: 63.28%] [G loss: 1.390110]\n",
      "epoch:31 step:29608 [D loss: 0.551920, acc.: 71.88%] [G loss: 1.544673]\n",
      "epoch:31 step:29609 [D loss: 0.499108, acc.: 79.69%] [G loss: 1.709940]\n",
      "epoch:31 step:29610 [D loss: 0.485447, acc.: 76.56%] [G loss: 1.998111]\n",
      "epoch:31 step:29611 [D loss: 0.567968, acc.: 67.19%] [G loss: 1.578564]\n",
      "epoch:31 step:29612 [D loss: 0.394786, acc.: 82.81%] [G loss: 1.456507]\n",
      "epoch:31 step:29613 [D loss: 0.444599, acc.: 80.47%] [G loss: 1.087059]\n",
      "epoch:31 step:29614 [D loss: 0.623512, acc.: 67.97%] [G loss: 1.762540]\n",
      "epoch:31 step:29615 [D loss: 0.562399, acc.: 71.09%] [G loss: 1.589768]\n",
      "epoch:31 step:29616 [D loss: 0.466494, acc.: 80.47%] [G loss: 1.513006]\n",
      "epoch:31 step:29617 [D loss: 0.497022, acc.: 75.00%] [G loss: 1.861865]\n",
      "epoch:31 step:29618 [D loss: 0.561716, acc.: 66.41%] [G loss: 1.505740]\n",
      "epoch:31 step:29619 [D loss: 0.571588, acc.: 67.19%] [G loss: 1.695384]\n",
      "epoch:31 step:29620 [D loss: 0.527213, acc.: 72.66%] [G loss: 1.387159]\n",
      "epoch:31 step:29621 [D loss: 0.560844, acc.: 67.97%] [G loss: 1.541158]\n",
      "epoch:31 step:29622 [D loss: 0.590504, acc.: 64.84%] [G loss: 1.704538]\n",
      "epoch:31 step:29623 [D loss: 0.434933, acc.: 80.47%] [G loss: 1.987717]\n",
      "epoch:31 step:29624 [D loss: 0.531754, acc.: 75.78%] [G loss: 1.580352]\n",
      "epoch:31 step:29625 [D loss: 0.609814, acc.: 64.06%] [G loss: 1.059768]\n",
      "epoch:31 step:29626 [D loss: 0.347389, acc.: 88.28%] [G loss: 1.437615]\n",
      "epoch:31 step:29627 [D loss: 0.464621, acc.: 76.56%] [G loss: 1.323058]\n",
      "epoch:31 step:29628 [D loss: 0.568525, acc.: 67.97%] [G loss: 1.318192]\n",
      "epoch:31 step:29629 [D loss: 0.402441, acc.: 84.38%] [G loss: 1.392652]\n",
      "epoch:31 step:29630 [D loss: 0.377731, acc.: 82.81%] [G loss: 1.360718]\n",
      "epoch:31 step:29631 [D loss: 0.536939, acc.: 73.44%] [G loss: 1.479101]\n",
      "epoch:31 step:29632 [D loss: 0.474189, acc.: 82.81%] [G loss: 1.269579]\n",
      "epoch:31 step:29633 [D loss: 0.520230, acc.: 73.44%] [G loss: 1.543771]\n",
      "epoch:31 step:29634 [D loss: 0.586283, acc.: 67.97%] [G loss: 1.537310]\n",
      "epoch:31 step:29635 [D loss: 0.544673, acc.: 72.66%] [G loss: 1.401075]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:31 step:29636 [D loss: 0.541952, acc.: 73.44%] [G loss: 1.531726]\n",
      "epoch:31 step:29637 [D loss: 0.455957, acc.: 77.34%] [G loss: 1.636671]\n",
      "epoch:31 step:29638 [D loss: 0.439242, acc.: 79.69%] [G loss: 1.740325]\n",
      "epoch:31 step:29639 [D loss: 0.526253, acc.: 76.56%] [G loss: 1.192761]\n",
      "epoch:31 step:29640 [D loss: 0.723228, acc.: 57.03%] [G loss: 1.908281]\n",
      "epoch:31 step:29641 [D loss: 0.367407, acc.: 85.94%] [G loss: 1.351470]\n",
      "epoch:31 step:29642 [D loss: 0.539319, acc.: 75.78%] [G loss: 1.308677]\n",
      "epoch:31 step:29643 [D loss: 0.499582, acc.: 79.69%] [G loss: 1.572541]\n",
      "epoch:31 step:29644 [D loss: 0.467499, acc.: 77.34%] [G loss: 1.590332]\n",
      "epoch:31 step:29645 [D loss: 0.518150, acc.: 73.44%] [G loss: 1.247492]\n",
      "epoch:31 step:29646 [D loss: 0.643190, acc.: 67.19%] [G loss: 1.277076]\n",
      "epoch:31 step:29647 [D loss: 0.477404, acc.: 78.12%] [G loss: 1.597915]\n",
      "epoch:31 step:29648 [D loss: 0.783857, acc.: 52.34%] [G loss: 1.627265]\n",
      "epoch:31 step:29649 [D loss: 0.526052, acc.: 78.91%] [G loss: 1.326032]\n",
      "epoch:31 step:29650 [D loss: 0.433534, acc.: 80.47%] [G loss: 1.736453]\n",
      "epoch:31 step:29651 [D loss: 0.351221, acc.: 89.06%] [G loss: 1.380389]\n",
      "epoch:31 step:29652 [D loss: 0.672934, acc.: 61.72%] [G loss: 1.091817]\n",
      "epoch:31 step:29653 [D loss: 0.537272, acc.: 75.78%] [G loss: 1.503893]\n",
      "epoch:31 step:29654 [D loss: 0.488186, acc.: 76.56%] [G loss: 1.677186]\n",
      "epoch:31 step:29655 [D loss: 0.450890, acc.: 85.94%] [G loss: 1.586353]\n",
      "epoch:31 step:29656 [D loss: 0.565524, acc.: 67.97%] [G loss: 1.143501]\n",
      "epoch:31 step:29657 [D loss: 0.542877, acc.: 71.09%] [G loss: 1.500808]\n",
      "epoch:31 step:29658 [D loss: 0.651041, acc.: 63.28%] [G loss: 1.281061]\n",
      "epoch:31 step:29659 [D loss: 0.510784, acc.: 75.00%] [G loss: 1.293411]\n",
      "epoch:31 step:29660 [D loss: 0.421058, acc.: 83.59%] [G loss: 1.484447]\n",
      "epoch:31 step:29661 [D loss: 0.624906, acc.: 68.75%] [G loss: 1.474087]\n",
      "epoch:31 step:29662 [D loss: 0.401963, acc.: 85.94%] [G loss: 1.295246]\n",
      "epoch:31 step:29663 [D loss: 0.532241, acc.: 76.56%] [G loss: 1.149111]\n",
      "epoch:31 step:29664 [D loss: 0.451438, acc.: 78.91%] [G loss: 1.328748]\n",
      "epoch:31 step:29665 [D loss: 0.640677, acc.: 70.31%] [G loss: 1.431670]\n",
      "epoch:31 step:29666 [D loss: 0.504242, acc.: 74.22%] [G loss: 1.233812]\n",
      "epoch:31 step:29667 [D loss: 0.474298, acc.: 80.47%] [G loss: 1.673200]\n",
      "epoch:31 step:29668 [D loss: 0.546643, acc.: 71.88%] [G loss: 1.777251]\n",
      "epoch:31 step:29669 [D loss: 0.521528, acc.: 75.00%] [G loss: 1.564510]\n",
      "epoch:31 step:29670 [D loss: 0.431152, acc.: 80.47%] [G loss: 1.748691]\n",
      "epoch:31 step:29671 [D loss: 0.718545, acc.: 57.03%] [G loss: 1.251555]\n",
      "epoch:31 step:29672 [D loss: 0.641073, acc.: 64.84%] [G loss: 1.353808]\n",
      "epoch:31 step:29673 [D loss: 0.536041, acc.: 72.66%] [G loss: 1.461874]\n",
      "epoch:31 step:29674 [D loss: 0.579698, acc.: 71.09%] [G loss: 1.661477]\n",
      "epoch:31 step:29675 [D loss: 0.627837, acc.: 67.97%] [G loss: 1.628416]\n",
      "epoch:31 step:29676 [D loss: 0.619724, acc.: 66.41%] [G loss: 1.658454]\n",
      "epoch:31 step:29677 [D loss: 0.515187, acc.: 71.88%] [G loss: 2.030851]\n",
      "epoch:31 step:29678 [D loss: 0.348289, acc.: 88.28%] [G loss: 1.502742]\n",
      "epoch:31 step:29679 [D loss: 0.755116, acc.: 60.16%] [G loss: 1.244297]\n",
      "epoch:31 step:29680 [D loss: 0.510445, acc.: 67.97%] [G loss: 1.365501]\n",
      "epoch:31 step:29681 [D loss: 0.462926, acc.: 77.34%] [G loss: 1.332993]\n",
      "epoch:31 step:29682 [D loss: 0.881510, acc.: 46.88%] [G loss: 1.089627]\n",
      "epoch:31 step:29683 [D loss: 0.424628, acc.: 83.59%] [G loss: 1.451037]\n",
      "epoch:31 step:29684 [D loss: 0.579683, acc.: 64.06%] [G loss: 1.337352]\n",
      "epoch:31 step:29685 [D loss: 0.564168, acc.: 68.75%] [G loss: 1.374583]\n",
      "epoch:31 step:29686 [D loss: 0.790568, acc.: 52.34%] [G loss: 1.124444]\n",
      "epoch:31 step:29687 [D loss: 0.687845, acc.: 61.72%] [G loss: 1.135562]\n",
      "epoch:31 step:29688 [D loss: 0.673186, acc.: 58.59%] [G loss: 1.199328]\n",
      "epoch:31 step:29689 [D loss: 0.502468, acc.: 74.22%] [G loss: 1.584694]\n",
      "epoch:31 step:29690 [D loss: 0.682442, acc.: 60.16%] [G loss: 1.311246]\n",
      "epoch:31 step:29691 [D loss: 0.379433, acc.: 86.72%] [G loss: 1.474336]\n",
      "epoch:31 step:29692 [D loss: 0.471323, acc.: 80.47%] [G loss: 1.321021]\n",
      "epoch:31 step:29693 [D loss: 0.578193, acc.: 72.66%] [G loss: 1.385576]\n",
      "epoch:31 step:29694 [D loss: 0.585182, acc.: 67.19%] [G loss: 1.620446]\n",
      "epoch:31 step:29695 [D loss: 0.328216, acc.: 88.28%] [G loss: 1.511627]\n",
      "epoch:31 step:29696 [D loss: 0.497406, acc.: 77.34%] [G loss: 1.687787]\n",
      "epoch:31 step:29697 [D loss: 0.468177, acc.: 82.81%] [G loss: 1.282385]\n",
      "epoch:31 step:29698 [D loss: 0.541727, acc.: 67.97%] [G loss: 1.811906]\n",
      "epoch:31 step:29699 [D loss: 0.399599, acc.: 82.03%] [G loss: 1.799449]\n",
      "epoch:31 step:29700 [D loss: 0.559983, acc.: 70.31%] [G loss: 1.376023]\n",
      "epoch:31 step:29701 [D loss: 0.503818, acc.: 76.56%] [G loss: 1.204345]\n",
      "epoch:31 step:29702 [D loss: 0.312933, acc.: 92.19%] [G loss: 1.751190]\n",
      "epoch:31 step:29703 [D loss: 0.532219, acc.: 74.22%] [G loss: 1.182662]\n",
      "epoch:31 step:29704 [D loss: 0.568702, acc.: 69.53%] [G loss: 1.214799]\n",
      "epoch:31 step:29705 [D loss: 0.452151, acc.: 82.03%] [G loss: 1.473152]\n",
      "epoch:31 step:29706 [D loss: 0.736262, acc.: 54.69%] [G loss: 1.303979]\n",
      "epoch:31 step:29707 [D loss: 0.623962, acc.: 65.62%] [G loss: 1.849738]\n",
      "epoch:31 step:29708 [D loss: 0.399621, acc.: 85.16%] [G loss: 1.703667]\n",
      "epoch:31 step:29709 [D loss: 0.462043, acc.: 78.12%] [G loss: 2.125742]\n",
      "epoch:31 step:29710 [D loss: 0.442676, acc.: 77.34%] [G loss: 1.991997]\n",
      "epoch:31 step:29711 [D loss: 0.741960, acc.: 60.16%] [G loss: 1.242282]\n",
      "epoch:31 step:29712 [D loss: 0.446264, acc.: 79.69%] [G loss: 1.079569]\n",
      "epoch:31 step:29713 [D loss: 0.355523, acc.: 89.06%] [G loss: 1.935957]\n",
      "epoch:31 step:29714 [D loss: 0.471324, acc.: 78.12%] [G loss: 1.466091]\n",
      "epoch:31 step:29715 [D loss: 0.688384, acc.: 60.16%] [G loss: 1.543181]\n",
      "epoch:31 step:29716 [D loss: 0.475738, acc.: 76.56%] [G loss: 1.616562]\n",
      "epoch:31 step:29717 [D loss: 0.494772, acc.: 78.12%] [G loss: 1.438581]\n",
      "epoch:31 step:29718 [D loss: 0.645597, acc.: 63.28%] [G loss: 1.371380]\n",
      "epoch:31 step:29719 [D loss: 0.501043, acc.: 74.22%] [G loss: 1.532769]\n",
      "epoch:31 step:29720 [D loss: 0.822147, acc.: 46.09%] [G loss: 1.497715]\n",
      "epoch:31 step:29721 [D loss: 0.494028, acc.: 77.34%] [G loss: 1.472555]\n",
      "epoch:31 step:29722 [D loss: 0.579615, acc.: 72.66%] [G loss: 1.747920]\n",
      "epoch:31 step:29723 [D loss: 0.625948, acc.: 68.75%] [G loss: 1.013828]\n",
      "epoch:31 step:29724 [D loss: 0.502130, acc.: 74.22%] [G loss: 1.589088]\n",
      "epoch:31 step:29725 [D loss: 0.493644, acc.: 75.00%] [G loss: 1.792657]\n",
      "epoch:31 step:29726 [D loss: 0.510604, acc.: 79.69%] [G loss: 1.484531]\n",
      "epoch:31 step:29727 [D loss: 0.470894, acc.: 73.44%] [G loss: 1.449695]\n",
      "epoch:31 step:29728 [D loss: 0.400112, acc.: 86.72%] [G loss: 0.954650]\n",
      "epoch:31 step:29729 [D loss: 0.389431, acc.: 82.81%] [G loss: 1.079996]\n",
      "epoch:31 step:29730 [D loss: 0.691067, acc.: 57.81%] [G loss: 1.364534]\n",
      "epoch:31 step:29731 [D loss: 0.553493, acc.: 69.53%] [G loss: 1.621551]\n",
      "epoch:31 step:29732 [D loss: 0.456299, acc.: 80.47%] [G loss: 1.521946]\n",
      "epoch:31 step:29733 [D loss: 0.352328, acc.: 86.72%] [G loss: 1.385343]\n",
      "epoch:31 step:29734 [D loss: 0.668244, acc.: 62.50%] [G loss: 1.198723]\n",
      "epoch:31 step:29735 [D loss: 0.618145, acc.: 67.97%] [G loss: 1.097952]\n",
      "epoch:31 step:29736 [D loss: 0.598018, acc.: 71.09%] [G loss: 1.813555]\n",
      "epoch:31 step:29737 [D loss: 0.685421, acc.: 61.72%] [G loss: 1.359460]\n",
      "epoch:31 step:29738 [D loss: 0.610334, acc.: 64.06%] [G loss: 1.310017]\n",
      "epoch:31 step:29739 [D loss: 0.554663, acc.: 71.09%] [G loss: 1.321826]\n",
      "epoch:31 step:29740 [D loss: 0.620971, acc.: 67.19%] [G loss: 1.481565]\n",
      "epoch:31 step:29741 [D loss: 0.494619, acc.: 73.44%] [G loss: 1.750284]\n",
      "epoch:31 step:29742 [D loss: 0.579659, acc.: 71.88%] [G loss: 1.050363]\n",
      "epoch:31 step:29743 [D loss: 0.532395, acc.: 73.44%] [G loss: 1.375790]\n",
      "epoch:31 step:29744 [D loss: 0.567923, acc.: 71.09%] [G loss: 1.391969]\n",
      "epoch:31 step:29745 [D loss: 0.534618, acc.: 72.66%] [G loss: 1.401237]\n",
      "epoch:31 step:29746 [D loss: 0.639587, acc.: 64.84%] [G loss: 1.024534]\n",
      "epoch:31 step:29747 [D loss: 0.522810, acc.: 75.00%] [G loss: 1.522167]\n",
      "epoch:31 step:29748 [D loss: 0.577230, acc.: 71.09%] [G loss: 1.661889]\n",
      "epoch:31 step:29749 [D loss: 0.575812, acc.: 71.09%] [G loss: 1.189587]\n",
      "epoch:31 step:29750 [D loss: 0.542826, acc.: 72.66%] [G loss: 1.296561]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:31 step:29751 [D loss: 1.005932, acc.: 42.19%] [G loss: 0.959572]\n",
      "epoch:31 step:29752 [D loss: 0.520730, acc.: 69.53%] [G loss: 1.261893]\n",
      "epoch:31 step:29753 [D loss: 0.477475, acc.: 78.12%] [G loss: 1.423970]\n",
      "epoch:31 step:29754 [D loss: 0.536620, acc.: 75.78%] [G loss: 1.612556]\n",
      "epoch:31 step:29755 [D loss: 0.489457, acc.: 78.91%] [G loss: 1.872794]\n",
      "epoch:31 step:29756 [D loss: 0.749243, acc.: 56.25%] [G loss: 1.539507]\n",
      "epoch:31 step:29757 [D loss: 0.501520, acc.: 78.91%] [G loss: 1.141593]\n",
      "epoch:31 step:29758 [D loss: 0.427440, acc.: 81.25%] [G loss: 1.788029]\n",
      "epoch:31 step:29759 [D loss: 0.436704, acc.: 82.81%] [G loss: 1.581341]\n",
      "epoch:31 step:29760 [D loss: 0.395288, acc.: 85.94%] [G loss: 1.467188]\n",
      "epoch:31 step:29761 [D loss: 0.789355, acc.: 52.34%] [G loss: 1.249485]\n",
      "epoch:31 step:29762 [D loss: 0.583269, acc.: 68.75%] [G loss: 1.103360]\n",
      "epoch:31 step:29763 [D loss: 0.603597, acc.: 67.19%] [G loss: 1.390234]\n",
      "epoch:31 step:29764 [D loss: 0.478617, acc.: 78.12%] [G loss: 1.369443]\n",
      "epoch:31 step:29765 [D loss: 0.560374, acc.: 68.75%] [G loss: 1.646409]\n",
      "epoch:31 step:29766 [D loss: 0.748089, acc.: 53.12%] [G loss: 1.624376]\n",
      "epoch:31 step:29767 [D loss: 0.520041, acc.: 73.44%] [G loss: 1.476087]\n",
      "epoch:31 step:29768 [D loss: 0.746863, acc.: 54.69%] [G loss: 1.320877]\n",
      "epoch:31 step:29769 [D loss: 0.462578, acc.: 78.12%] [G loss: 1.748545]\n",
      "epoch:31 step:29770 [D loss: 0.588922, acc.: 66.41%] [G loss: 1.349628]\n",
      "epoch:31 step:29771 [D loss: 0.624798, acc.: 65.62%] [G loss: 1.475597]\n",
      "epoch:31 step:29772 [D loss: 0.502331, acc.: 76.56%] [G loss: 1.502342]\n",
      "epoch:31 step:29773 [D loss: 0.578316, acc.: 74.22%] [G loss: 1.286486]\n",
      "epoch:31 step:29774 [D loss: 0.548698, acc.: 75.00%] [G loss: 1.708504]\n",
      "epoch:31 step:29775 [D loss: 0.598561, acc.: 71.88%] [G loss: 1.544504]\n",
      "epoch:31 step:29776 [D loss: 0.542138, acc.: 71.88%] [G loss: 1.088243]\n",
      "epoch:31 step:29777 [D loss: 0.553063, acc.: 71.88%] [G loss: 1.814334]\n",
      "epoch:31 step:29778 [D loss: 0.511806, acc.: 75.00%] [G loss: 1.290334]\n",
      "epoch:31 step:29779 [D loss: 0.450324, acc.: 82.81%] [G loss: 1.168265]\n",
      "epoch:31 step:29780 [D loss: 0.467582, acc.: 75.00%] [G loss: 1.483825]\n",
      "epoch:31 step:29781 [D loss: 0.671730, acc.: 63.28%] [G loss: 1.282852]\n",
      "epoch:31 step:29782 [D loss: 0.379504, acc.: 89.06%] [G loss: 1.224990]\n",
      "epoch:31 step:29783 [D loss: 0.443564, acc.: 82.81%] [G loss: 1.698256]\n",
      "epoch:31 step:29784 [D loss: 0.397625, acc.: 83.59%] [G loss: 1.544692]\n",
      "epoch:31 step:29785 [D loss: 0.610518, acc.: 67.97%] [G loss: 1.788038]\n",
      "epoch:31 step:29786 [D loss: 0.439777, acc.: 82.03%] [G loss: 1.199081]\n",
      "epoch:31 step:29787 [D loss: 0.488129, acc.: 75.78%] [G loss: 1.100127]\n",
      "epoch:31 step:29788 [D loss: 0.555572, acc.: 72.66%] [G loss: 1.194059]\n",
      "epoch:31 step:29789 [D loss: 0.465293, acc.: 77.34%] [G loss: 1.584397]\n",
      "epoch:31 step:29790 [D loss: 0.567289, acc.: 72.66%] [G loss: 1.415658]\n",
      "epoch:31 step:29791 [D loss: 0.619658, acc.: 66.41%] [G loss: 1.260595]\n",
      "epoch:31 step:29792 [D loss: 0.434429, acc.: 83.59%] [G loss: 1.527184]\n",
      "epoch:31 step:29793 [D loss: 0.460947, acc.: 80.47%] [G loss: 1.455897]\n",
      "epoch:31 step:29794 [D loss: 0.561217, acc.: 66.41%] [G loss: 1.482327]\n",
      "epoch:31 step:29795 [D loss: 0.584472, acc.: 66.41%] [G loss: 1.435044]\n",
      "epoch:31 step:29796 [D loss: 0.580986, acc.: 72.66%] [G loss: 1.490198]\n",
      "epoch:31 step:29797 [D loss: 0.458291, acc.: 82.03%] [G loss: 1.845332]\n",
      "epoch:31 step:29798 [D loss: 0.583434, acc.: 69.53%] [G loss: 1.308888]\n",
      "epoch:31 step:29799 [D loss: 0.460213, acc.: 79.69%] [G loss: 1.420453]\n",
      "epoch:31 step:29800 [D loss: 0.404523, acc.: 88.28%] [G loss: 1.440982]\n",
      "epoch:31 step:29801 [D loss: 0.472180, acc.: 78.91%] [G loss: 1.477618]\n",
      "epoch:31 step:29802 [D loss: 0.460858, acc.: 77.34%] [G loss: 1.758160]\n",
      "epoch:31 step:29803 [D loss: 0.691245, acc.: 60.94%] [G loss: 1.167696]\n",
      "epoch:31 step:29804 [D loss: 0.394113, acc.: 83.59%] [G loss: 1.455357]\n",
      "epoch:31 step:29805 [D loss: 0.725995, acc.: 59.38%] [G loss: 1.254390]\n",
      "epoch:31 step:29806 [D loss: 0.518554, acc.: 74.22%] [G loss: 1.206938]\n",
      "epoch:31 step:29807 [D loss: 0.568324, acc.: 67.97%] [G loss: 1.778164]\n",
      "epoch:31 step:29808 [D loss: 0.690786, acc.: 60.16%] [G loss: 1.272408]\n",
      "epoch:31 step:29809 [D loss: 0.687723, acc.: 60.94%] [G loss: 1.377192]\n",
      "epoch:31 step:29810 [D loss: 0.543627, acc.: 73.44%] [G loss: 1.720358]\n",
      "epoch:31 step:29811 [D loss: 0.439329, acc.: 78.91%] [G loss: 1.494063]\n",
      "epoch:31 step:29812 [D loss: 0.450779, acc.: 76.56%] [G loss: 1.836020]\n",
      "epoch:31 step:29813 [D loss: 0.557287, acc.: 73.44%] [G loss: 1.507608]\n",
      "epoch:31 step:29814 [D loss: 0.425007, acc.: 82.81%] [G loss: 1.554426]\n",
      "epoch:31 step:29815 [D loss: 0.591295, acc.: 66.41%] [G loss: 1.600862]\n",
      "epoch:31 step:29816 [D loss: 0.499893, acc.: 73.44%] [G loss: 1.479690]\n",
      "epoch:31 step:29817 [D loss: 0.457108, acc.: 82.03%] [G loss: 1.463316]\n",
      "epoch:31 step:29818 [D loss: 0.483448, acc.: 80.47%] [G loss: 1.790480]\n",
      "epoch:31 step:29819 [D loss: 0.515119, acc.: 78.12%] [G loss: 1.095575]\n",
      "epoch:31 step:29820 [D loss: 0.580935, acc.: 71.88%] [G loss: 1.342440]\n",
      "epoch:31 step:29821 [D loss: 0.402697, acc.: 84.38%] [G loss: 1.178432]\n",
      "epoch:31 step:29822 [D loss: 0.533526, acc.: 72.66%] [G loss: 1.728984]\n",
      "epoch:31 step:29823 [D loss: 0.533959, acc.: 75.00%] [G loss: 1.282588]\n",
      "epoch:31 step:29824 [D loss: 0.694705, acc.: 64.06%] [G loss: 1.195466]\n",
      "epoch:31 step:29825 [D loss: 0.590813, acc.: 71.88%] [G loss: 1.218763]\n",
      "epoch:31 step:29826 [D loss: 0.513021, acc.: 71.88%] [G loss: 1.782434]\n",
      "epoch:31 step:29827 [D loss: 0.681135, acc.: 60.94%] [G loss: 1.201432]\n",
      "epoch:31 step:29828 [D loss: 0.433656, acc.: 80.47%] [G loss: 1.371979]\n",
      "epoch:31 step:29829 [D loss: 0.465322, acc.: 79.69%] [G loss: 1.486518]\n",
      "epoch:31 step:29830 [D loss: 0.635957, acc.: 65.62%] [G loss: 1.560829]\n",
      "epoch:31 step:29831 [D loss: 0.408967, acc.: 85.16%] [G loss: 1.761509]\n",
      "epoch:31 step:29832 [D loss: 0.455845, acc.: 80.47%] [G loss: 1.667936]\n",
      "epoch:31 step:29833 [D loss: 0.637112, acc.: 67.97%] [G loss: 1.378953]\n",
      "epoch:31 step:29834 [D loss: 0.599094, acc.: 65.62%] [G loss: 1.422989]\n",
      "epoch:31 step:29835 [D loss: 0.594263, acc.: 67.97%] [G loss: 1.424103]\n",
      "epoch:31 step:29836 [D loss: 0.694913, acc.: 59.38%] [G loss: 1.613928]\n",
      "epoch:31 step:29837 [D loss: 0.459448, acc.: 79.69%] [G loss: 1.357845]\n",
      "epoch:31 step:29838 [D loss: 0.497748, acc.: 76.56%] [G loss: 1.464322]\n",
      "epoch:31 step:29839 [D loss: 0.695227, acc.: 60.16%] [G loss: 1.261594]\n",
      "epoch:31 step:29840 [D loss: 0.564209, acc.: 71.88%] [G loss: 2.250336]\n",
      "epoch:31 step:29841 [D loss: 0.369414, acc.: 86.72%] [G loss: 1.714888]\n",
      "epoch:31 step:29842 [D loss: 0.562842, acc.: 71.88%] [G loss: 1.468017]\n",
      "epoch:31 step:29843 [D loss: 0.562503, acc.: 65.62%] [G loss: 1.606065]\n",
      "epoch:31 step:29844 [D loss: 0.437512, acc.: 79.69%] [G loss: 1.652083]\n",
      "epoch:31 step:29845 [D loss: 0.521120, acc.: 75.00%] [G loss: 1.733056]\n",
      "epoch:31 step:29846 [D loss: 0.552803, acc.: 74.22%] [G loss: 1.390463]\n",
      "epoch:31 step:29847 [D loss: 0.455302, acc.: 78.91%] [G loss: 1.718456]\n",
      "epoch:31 step:29848 [D loss: 0.602236, acc.: 69.53%] [G loss: 1.114939]\n",
      "epoch:31 step:29849 [D loss: 0.758914, acc.: 56.25%] [G loss: 1.188131]\n",
      "epoch:31 step:29850 [D loss: 0.599293, acc.: 67.19%] [G loss: 1.244939]\n",
      "epoch:31 step:29851 [D loss: 0.415490, acc.: 80.47%] [G loss: 1.849857]\n",
      "epoch:31 step:29852 [D loss: 0.360444, acc.: 89.06%] [G loss: 1.613399]\n",
      "epoch:31 step:29853 [D loss: 0.652779, acc.: 62.50%] [G loss: 1.482833]\n",
      "epoch:31 step:29854 [D loss: 0.583402, acc.: 72.66%] [G loss: 1.361878]\n",
      "epoch:31 step:29855 [D loss: 0.652415, acc.: 67.19%] [G loss: 1.623456]\n",
      "epoch:31 step:29856 [D loss: 0.552918, acc.: 71.88%] [G loss: 1.502343]\n",
      "epoch:31 step:29857 [D loss: 0.309724, acc.: 92.97%] [G loss: 1.461609]\n",
      "epoch:31 step:29858 [D loss: 0.673935, acc.: 60.16%] [G loss: 1.146125]\n",
      "epoch:31 step:29859 [D loss: 0.602890, acc.: 67.19%] [G loss: 1.226076]\n",
      "epoch:31 step:29860 [D loss: 0.659110, acc.: 62.50%] [G loss: 1.673005]\n",
      "epoch:31 step:29861 [D loss: 0.684505, acc.: 60.16%] [G loss: 1.860021]\n",
      "epoch:31 step:29862 [D loss: 0.592622, acc.: 71.09%] [G loss: 1.304672]\n",
      "epoch:31 step:29863 [D loss: 0.453461, acc.: 76.56%] [G loss: 1.341672]\n",
      "epoch:31 step:29864 [D loss: 0.472096, acc.: 78.91%] [G loss: 1.650482]\n",
      "epoch:31 step:29865 [D loss: 0.657088, acc.: 58.59%] [G loss: 1.322276]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:31 step:29866 [D loss: 0.455686, acc.: 80.47%] [G loss: 1.457209]\n",
      "epoch:31 step:29867 [D loss: 0.590950, acc.: 67.19%] [G loss: 1.446055]\n",
      "epoch:31 step:29868 [D loss: 0.592426, acc.: 65.62%] [G loss: 1.270399]\n",
      "epoch:31 step:29869 [D loss: 0.608501, acc.: 67.19%] [G loss: 1.293385]\n",
      "epoch:31 step:29870 [D loss: 0.446144, acc.: 77.34%] [G loss: 1.406748]\n",
      "epoch:31 step:29871 [D loss: 0.595278, acc.: 67.97%] [G loss: 1.203701]\n",
      "epoch:31 step:29872 [D loss: 0.455762, acc.: 81.25%] [G loss: 1.897778]\n",
      "epoch:31 step:29873 [D loss: 0.541405, acc.: 72.66%] [G loss: 1.633564]\n",
      "epoch:31 step:29874 [D loss: 0.544073, acc.: 75.00%] [G loss: 1.144484]\n",
      "epoch:31 step:29875 [D loss: 0.587313, acc.: 64.84%] [G loss: 1.377052]\n",
      "epoch:31 step:29876 [D loss: 0.717199, acc.: 62.50%] [G loss: 1.234710]\n",
      "epoch:31 step:29877 [D loss: 0.424114, acc.: 75.78%] [G loss: 1.503960]\n",
      "epoch:31 step:29878 [D loss: 0.637960, acc.: 59.38%] [G loss: 1.574165]\n",
      "epoch:31 step:29879 [D loss: 0.525517, acc.: 72.66%] [G loss: 1.190171]\n",
      "epoch:31 step:29880 [D loss: 0.591265, acc.: 68.75%] [G loss: 1.332753]\n",
      "epoch:31 step:29881 [D loss: 0.561758, acc.: 71.09%] [G loss: 1.647572]\n",
      "epoch:31 step:29882 [D loss: 0.473749, acc.: 76.56%] [G loss: 1.743644]\n",
      "epoch:31 step:29883 [D loss: 0.607931, acc.: 62.50%] [G loss: 1.691269]\n",
      "epoch:31 step:29884 [D loss: 0.568850, acc.: 74.22%] [G loss: 1.217324]\n",
      "epoch:31 step:29885 [D loss: 0.382796, acc.: 85.16%] [G loss: 1.595300]\n",
      "epoch:31 step:29886 [D loss: 0.455881, acc.: 79.69%] [G loss: 1.537889]\n",
      "epoch:31 step:29887 [D loss: 0.446625, acc.: 79.69%] [G loss: 1.182678]\n",
      "epoch:31 step:29888 [D loss: 0.815558, acc.: 52.34%] [G loss: 1.299966]\n",
      "epoch:31 step:29889 [D loss: 0.505239, acc.: 75.78%] [G loss: 1.642827]\n",
      "epoch:31 step:29890 [D loss: 0.425889, acc.: 83.59%] [G loss: 1.609396]\n",
      "epoch:31 step:29891 [D loss: 0.661313, acc.: 63.28%] [G loss: 1.365013]\n",
      "epoch:31 step:29892 [D loss: 0.713419, acc.: 61.72%] [G loss: 1.703030]\n",
      "epoch:31 step:29893 [D loss: 0.445394, acc.: 75.00%] [G loss: 1.613716]\n",
      "epoch:31 step:29894 [D loss: 0.702723, acc.: 63.28%] [G loss: 1.072855]\n",
      "epoch:31 step:29895 [D loss: 0.489899, acc.: 76.56%] [G loss: 1.655988]\n",
      "epoch:31 step:29896 [D loss: 0.518578, acc.: 74.22%] [G loss: 1.244768]\n",
      "epoch:31 step:29897 [D loss: 0.378107, acc.: 86.72%] [G loss: 1.537055]\n",
      "epoch:31 step:29898 [D loss: 0.565863, acc.: 71.09%] [G loss: 1.284347]\n",
      "epoch:31 step:29899 [D loss: 0.476094, acc.: 78.91%] [G loss: 1.696331]\n",
      "epoch:31 step:29900 [D loss: 0.420397, acc.: 84.38%] [G loss: 1.694396]\n",
      "epoch:31 step:29901 [D loss: 0.488522, acc.: 74.22%] [G loss: 1.797559]\n",
      "epoch:31 step:29902 [D loss: 0.605311, acc.: 64.84%] [G loss: 1.002416]\n",
      "epoch:31 step:29903 [D loss: 0.420639, acc.: 85.94%] [G loss: 1.555765]\n",
      "epoch:31 step:29904 [D loss: 0.402146, acc.: 81.25%] [G loss: 1.509431]\n",
      "epoch:31 step:29905 [D loss: 0.487393, acc.: 78.12%] [G loss: 1.658143]\n",
      "epoch:31 step:29906 [D loss: 0.537060, acc.: 71.88%] [G loss: 1.110651]\n",
      "epoch:31 step:29907 [D loss: 0.506912, acc.: 73.44%] [G loss: 1.628534]\n",
      "epoch:31 step:29908 [D loss: 0.478653, acc.: 75.78%] [G loss: 1.376878]\n",
      "epoch:31 step:29909 [D loss: 0.610479, acc.: 67.97%] [G loss: 1.005342]\n",
      "epoch:31 step:29910 [D loss: 0.538768, acc.: 73.44%] [G loss: 1.738650]\n",
      "epoch:31 step:29911 [D loss: 0.544810, acc.: 70.31%] [G loss: 1.417565]\n",
      "epoch:31 step:29912 [D loss: 0.535172, acc.: 74.22%] [G loss: 1.841258]\n",
      "epoch:31 step:29913 [D loss: 0.501162, acc.: 74.22%] [G loss: 1.496925]\n",
      "epoch:31 step:29914 [D loss: 0.384880, acc.: 84.38%] [G loss: 1.579470]\n",
      "epoch:31 step:29915 [D loss: 0.476069, acc.: 82.81%] [G loss: 1.854766]\n",
      "epoch:31 step:29916 [D loss: 0.554433, acc.: 70.31%] [G loss: 1.581520]\n",
      "epoch:31 step:29917 [D loss: 0.541611, acc.: 71.88%] [G loss: 1.373694]\n",
      "epoch:31 step:29918 [D loss: 0.617149, acc.: 64.84%] [G loss: 1.239503]\n",
      "epoch:31 step:29919 [D loss: 0.546181, acc.: 74.22%] [G loss: 1.330265]\n",
      "epoch:31 step:29920 [D loss: 0.361850, acc.: 88.28%] [G loss: 1.317893]\n",
      "epoch:31 step:29921 [D loss: 0.752535, acc.: 60.16%] [G loss: 1.184972]\n",
      "epoch:31 step:29922 [D loss: 0.524519, acc.: 71.09%] [G loss: 1.419641]\n",
      "epoch:31 step:29923 [D loss: 0.573881, acc.: 66.41%] [G loss: 1.936453]\n",
      "epoch:31 step:29924 [D loss: 0.495100, acc.: 76.56%] [G loss: 1.816593]\n",
      "epoch:31 step:29925 [D loss: 0.481247, acc.: 78.12%] [G loss: 1.669183]\n",
      "epoch:31 step:29926 [D loss: 0.556855, acc.: 67.19%] [G loss: 1.442796]\n",
      "epoch:31 step:29927 [D loss: 0.513171, acc.: 76.56%] [G loss: 1.177463]\n",
      "epoch:31 step:29928 [D loss: 0.607189, acc.: 64.06%] [G loss: 1.598355]\n",
      "epoch:31 step:29929 [D loss: 0.542875, acc.: 73.44%] [G loss: 1.335780]\n",
      "epoch:31 step:29930 [D loss: 0.529007, acc.: 75.00%] [G loss: 1.722193]\n",
      "epoch:31 step:29931 [D loss: 0.436829, acc.: 82.03%] [G loss: 1.531948]\n",
      "epoch:31 step:29932 [D loss: 0.499270, acc.: 78.12%] [G loss: 1.752938]\n",
      "epoch:31 step:29933 [D loss: 0.563477, acc.: 69.53%] [G loss: 1.478708]\n",
      "epoch:31 step:29934 [D loss: 0.395952, acc.: 84.38%] [G loss: 1.578454]\n",
      "epoch:31 step:29935 [D loss: 0.625145, acc.: 67.97%] [G loss: 1.361842]\n",
      "epoch:31 step:29936 [D loss: 0.548909, acc.: 73.44%] [G loss: 1.263496]\n",
      "epoch:31 step:29937 [D loss: 0.557219, acc.: 71.88%] [G loss: 0.988148]\n",
      "epoch:31 step:29938 [D loss: 0.534749, acc.: 72.66%] [G loss: 1.132554]\n",
      "epoch:31 step:29939 [D loss: 0.566715, acc.: 72.66%] [G loss: 1.150002]\n",
      "epoch:31 step:29940 [D loss: 0.411698, acc.: 82.81%] [G loss: 1.635260]\n",
      "epoch:31 step:29941 [D loss: 0.502871, acc.: 72.66%] [G loss: 1.335553]\n",
      "epoch:31 step:29942 [D loss: 0.601295, acc.: 70.31%] [G loss: 1.271471]\n",
      "epoch:31 step:29943 [D loss: 0.587531, acc.: 71.09%] [G loss: 1.243327]\n",
      "epoch:31 step:29944 [D loss: 0.459336, acc.: 80.47%] [G loss: 1.633944]\n",
      "epoch:31 step:29945 [D loss: 0.558676, acc.: 67.19%] [G loss: 1.008360]\n",
      "epoch:31 step:29946 [D loss: 0.400212, acc.: 85.16%] [G loss: 1.414463]\n",
      "epoch:31 step:29947 [D loss: 0.359283, acc.: 87.50%] [G loss: 1.853591]\n",
      "epoch:31 step:29948 [D loss: 0.622371, acc.: 66.41%] [G loss: 1.430648]\n",
      "epoch:31 step:29949 [D loss: 0.580278, acc.: 68.75%] [G loss: 1.130064]\n",
      "epoch:31 step:29950 [D loss: 0.660746, acc.: 64.06%] [G loss: 1.329729]\n",
      "epoch:31 step:29951 [D loss: 0.505700, acc.: 77.34%] [G loss: 1.690355]\n",
      "epoch:31 step:29952 [D loss: 0.563241, acc.: 71.09%] [G loss: 1.430646]\n",
      "epoch:31 step:29953 [D loss: 0.672976, acc.: 61.72%] [G loss: 1.240141]\n",
      "epoch:31 step:29954 [D loss: 0.471898, acc.: 78.91%] [G loss: 1.826540]\n",
      "epoch:31 step:29955 [D loss: 0.477748, acc.: 79.69%] [G loss: 1.695552]\n",
      "epoch:31 step:29956 [D loss: 0.558695, acc.: 67.19%] [G loss: 1.550256]\n",
      "epoch:31 step:29957 [D loss: 0.512963, acc.: 71.88%] [G loss: 1.418411]\n",
      "epoch:31 step:29958 [D loss: 0.585340, acc.: 68.75%] [G loss: 1.460157]\n",
      "epoch:31 step:29959 [D loss: 0.665374, acc.: 58.59%] [G loss: 0.785432]\n",
      "epoch:31 step:29960 [D loss: 0.608710, acc.: 70.31%] [G loss: 1.528013]\n",
      "epoch:31 step:29961 [D loss: 0.427745, acc.: 80.47%] [G loss: 1.639629]\n",
      "epoch:31 step:29962 [D loss: 0.581726, acc.: 68.75%] [G loss: 1.616711]\n",
      "epoch:31 step:29963 [D loss: 0.692300, acc.: 64.06%] [G loss: 1.683936]\n",
      "epoch:31 step:29964 [D loss: 0.533376, acc.: 73.44%] [G loss: 1.643317]\n",
      "epoch:31 step:29965 [D loss: 0.573627, acc.: 71.09%] [G loss: 1.345060]\n",
      "epoch:31 step:29966 [D loss: 0.488917, acc.: 75.78%] [G loss: 1.386058]\n",
      "epoch:31 step:29967 [D loss: 0.612807, acc.: 72.66%] [G loss: 1.525119]\n",
      "epoch:31 step:29968 [D loss: 0.685808, acc.: 57.81%] [G loss: 1.333951]\n",
      "epoch:31 step:29969 [D loss: 0.557431, acc.: 73.44%] [G loss: 1.839819]\n",
      "epoch:31 step:29970 [D loss: 0.512638, acc.: 71.09%] [G loss: 1.509926]\n",
      "epoch:31 step:29971 [D loss: 0.494799, acc.: 78.12%] [G loss: 1.488683]\n",
      "epoch:31 step:29972 [D loss: 0.446551, acc.: 78.91%] [G loss: 1.867792]\n",
      "epoch:31 step:29973 [D loss: 0.485569, acc.: 76.56%] [G loss: 1.287906]\n",
      "epoch:31 step:29974 [D loss: 0.585216, acc.: 67.19%] [G loss: 1.402321]\n",
      "epoch:31 step:29975 [D loss: 0.304733, acc.: 90.62%] [G loss: 1.673953]\n",
      "epoch:31 step:29976 [D loss: 0.586376, acc.: 67.97%] [G loss: 1.768753]\n",
      "epoch:31 step:29977 [D loss: 0.470521, acc.: 78.12%] [G loss: 1.627477]\n",
      "epoch:31 step:29978 [D loss: 0.605021, acc.: 66.41%] [G loss: 1.214081]\n",
      "epoch:31 step:29979 [D loss: 0.527455, acc.: 73.44%] [G loss: 1.301045]\n",
      "epoch:31 step:29980 [D loss: 0.556625, acc.: 73.44%] [G loss: 1.265095]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:31 step:29981 [D loss: 0.730092, acc.: 58.59%] [G loss: 1.653246]\n",
      "epoch:31 step:29982 [D loss: 0.332803, acc.: 92.97%] [G loss: 1.680557]\n",
      "epoch:31 step:29983 [D loss: 0.458897, acc.: 77.34%] [G loss: 1.313007]\n",
      "epoch:31 step:29984 [D loss: 0.684909, acc.: 57.81%] [G loss: 1.737520]\n",
      "epoch:32 step:29985 [D loss: 0.580741, acc.: 71.88%] [G loss: 1.509876]\n",
      "epoch:32 step:29986 [D loss: 0.530795, acc.: 76.56%] [G loss: 1.514537]\n",
      "epoch:32 step:29987 [D loss: 0.570864, acc.: 68.75%] [G loss: 1.610267]\n",
      "epoch:32 step:29988 [D loss: 0.562146, acc.: 69.53%] [G loss: 1.271594]\n",
      "epoch:32 step:29989 [D loss: 0.555311, acc.: 72.66%] [G loss: 1.361825]\n",
      "epoch:32 step:29990 [D loss: 0.525157, acc.: 70.31%] [G loss: 1.616594]\n",
      "epoch:32 step:29991 [D loss: 0.384022, acc.: 84.38%] [G loss: 1.941687]\n",
      "epoch:32 step:29992 [D loss: 0.771277, acc.: 49.22%] [G loss: 1.407904]\n",
      "epoch:32 step:29993 [D loss: 0.423312, acc.: 82.03%] [G loss: 1.716397]\n",
      "epoch:32 step:29994 [D loss: 0.897795, acc.: 46.88%] [G loss: 1.395130]\n",
      "epoch:32 step:29995 [D loss: 0.506361, acc.: 78.12%] [G loss: 2.016212]\n",
      "epoch:32 step:29996 [D loss: 0.668166, acc.: 64.06%] [G loss: 1.435965]\n",
      "epoch:32 step:29997 [D loss: 0.476952, acc.: 76.56%] [G loss: 1.792810]\n",
      "epoch:32 step:29998 [D loss: 0.363454, acc.: 85.94%] [G loss: 1.702844]\n",
      "epoch:32 step:29999 [D loss: 0.537920, acc.: 75.78%] [G loss: 1.466853]\n",
      "epoch:32 step:30000 [D loss: 0.342544, acc.: 87.50%] [G loss: 1.608569]\n",
      "epoch:32 step:30001 [D loss: 0.503069, acc.: 75.00%] [G loss: 1.703804]\n",
      "epoch:32 step:30002 [D loss: 0.580710, acc.: 64.06%] [G loss: 1.404894]\n",
      "epoch:32 step:30003 [D loss: 0.777817, acc.: 52.34%] [G loss: 1.103410]\n",
      "epoch:32 step:30004 [D loss: 0.497880, acc.: 72.66%] [G loss: 1.799769]\n",
      "epoch:32 step:30005 [D loss: 0.605681, acc.: 66.41%] [G loss: 1.883455]\n",
      "epoch:32 step:30006 [D loss: 0.640846, acc.: 59.38%] [G loss: 1.402688]\n",
      "epoch:32 step:30007 [D loss: 0.499736, acc.: 77.34%] [G loss: 1.522857]\n",
      "epoch:32 step:30008 [D loss: 0.482081, acc.: 78.12%] [G loss: 1.510336]\n",
      "epoch:32 step:30009 [D loss: 0.618543, acc.: 67.97%] [G loss: 1.118176]\n",
      "epoch:32 step:30010 [D loss: 0.510318, acc.: 77.34%] [G loss: 1.355948]\n",
      "epoch:32 step:30011 [D loss: 0.554580, acc.: 71.09%] [G loss: 1.706303]\n",
      "epoch:32 step:30012 [D loss: 0.447281, acc.: 81.25%] [G loss: 1.399127]\n",
      "epoch:32 step:30013 [D loss: 0.554258, acc.: 67.97%] [G loss: 1.830478]\n",
      "epoch:32 step:30014 [D loss: 0.673139, acc.: 64.06%] [G loss: 1.285993]\n",
      "epoch:32 step:30015 [D loss: 0.650412, acc.: 62.50%] [G loss: 1.250235]\n",
      "epoch:32 step:30016 [D loss: 0.440294, acc.: 82.03%] [G loss: 1.223785]\n",
      "epoch:32 step:30017 [D loss: 0.613337, acc.: 65.62%] [G loss: 1.314752]\n",
      "epoch:32 step:30018 [D loss: 0.449523, acc.: 78.91%] [G loss: 1.703374]\n",
      "epoch:32 step:30019 [D loss: 0.392717, acc.: 86.72%] [G loss: 1.963701]\n",
      "epoch:32 step:30020 [D loss: 0.412189, acc.: 82.03%] [G loss: 1.433140]\n",
      "epoch:32 step:30021 [D loss: 0.454052, acc.: 82.81%] [G loss: 1.815493]\n",
      "epoch:32 step:30022 [D loss: 0.441964, acc.: 82.81%] [G loss: 1.184738]\n",
      "epoch:32 step:30023 [D loss: 0.532643, acc.: 72.66%] [G loss: 1.010482]\n",
      "epoch:32 step:30024 [D loss: 0.603317, acc.: 68.75%] [G loss: 1.147473]\n",
      "epoch:32 step:30025 [D loss: 0.576191, acc.: 73.44%] [G loss: 1.450915]\n",
      "epoch:32 step:30026 [D loss: 0.588339, acc.: 69.53%] [G loss: 1.380662]\n",
      "epoch:32 step:30027 [D loss: 0.465572, acc.: 75.78%] [G loss: 1.219512]\n",
      "epoch:32 step:30028 [D loss: 0.657338, acc.: 59.38%] [G loss: 0.996127]\n",
      "epoch:32 step:30029 [D loss: 0.554822, acc.: 72.66%] [G loss: 1.752089]\n",
      "epoch:32 step:30030 [D loss: 0.606305, acc.: 68.75%] [G loss: 1.303924]\n",
      "epoch:32 step:30031 [D loss: 0.635900, acc.: 62.50%] [G loss: 1.138895]\n",
      "epoch:32 step:30032 [D loss: 0.511534, acc.: 74.22%] [G loss: 1.378789]\n",
      "epoch:32 step:30033 [D loss: 0.517471, acc.: 78.12%] [G loss: 0.973887]\n",
      "epoch:32 step:30034 [D loss: 0.399477, acc.: 82.03%] [G loss: 1.451703]\n",
      "epoch:32 step:30035 [D loss: 0.640467, acc.: 64.06%] [G loss: 1.502779]\n",
      "epoch:32 step:30036 [D loss: 0.666114, acc.: 60.16%] [G loss: 1.615070]\n",
      "epoch:32 step:30037 [D loss: 0.485474, acc.: 79.69%] [G loss: 1.955115]\n",
      "epoch:32 step:30038 [D loss: 0.378418, acc.: 87.50%] [G loss: 1.556953]\n",
      "epoch:32 step:30039 [D loss: 0.519670, acc.: 71.88%] [G loss: 1.016564]\n",
      "epoch:32 step:30040 [D loss: 0.518811, acc.: 71.09%] [G loss: 1.752128]\n",
      "epoch:32 step:30041 [D loss: 0.598322, acc.: 69.53%] [G loss: 1.752898]\n",
      "epoch:32 step:30042 [D loss: 0.314418, acc.: 89.84%] [G loss: 1.640996]\n",
      "epoch:32 step:30043 [D loss: 0.508954, acc.: 74.22%] [G loss: 1.545345]\n",
      "epoch:32 step:30044 [D loss: 0.565281, acc.: 67.97%] [G loss: 1.883256]\n",
      "epoch:32 step:30045 [D loss: 0.573575, acc.: 66.41%] [G loss: 1.196029]\n",
      "epoch:32 step:30046 [D loss: 0.594389, acc.: 64.06%] [G loss: 1.434925]\n",
      "epoch:32 step:30047 [D loss: 0.598863, acc.: 71.88%] [G loss: 1.777952]\n",
      "epoch:32 step:30048 [D loss: 0.438800, acc.: 84.38%] [G loss: 1.563490]\n",
      "epoch:32 step:30049 [D loss: 0.406008, acc.: 82.81%] [G loss: 1.515282]\n",
      "epoch:32 step:30050 [D loss: 0.564591, acc.: 68.75%] [G loss: 1.373093]\n",
      "epoch:32 step:30051 [D loss: 0.437195, acc.: 82.03%] [G loss: 1.231635]\n",
      "epoch:32 step:30052 [D loss: 0.574192, acc.: 71.88%] [G loss: 1.160004]\n",
      "epoch:32 step:30053 [D loss: 0.469061, acc.: 73.44%] [G loss: 1.774598]\n",
      "epoch:32 step:30054 [D loss: 0.585185, acc.: 67.19%] [G loss: 1.701113]\n",
      "epoch:32 step:30055 [D loss: 0.565928, acc.: 67.97%] [G loss: 1.145731]\n",
      "epoch:32 step:30056 [D loss: 0.693380, acc.: 60.16%] [G loss: 1.426590]\n",
      "epoch:32 step:30057 [D loss: 0.497662, acc.: 78.12%] [G loss: 1.762008]\n",
      "epoch:32 step:30058 [D loss: 0.524530, acc.: 71.88%] [G loss: 1.504319]\n",
      "epoch:32 step:30059 [D loss: 0.481477, acc.: 79.69%] [G loss: 1.477559]\n",
      "epoch:32 step:30060 [D loss: 0.475608, acc.: 80.47%] [G loss: 1.404032]\n",
      "epoch:32 step:30061 [D loss: 0.774480, acc.: 53.91%] [G loss: 1.157829]\n",
      "epoch:32 step:30062 [D loss: 0.447411, acc.: 83.59%] [G loss: 1.339906]\n",
      "epoch:32 step:30063 [D loss: 0.466734, acc.: 82.03%] [G loss: 1.241525]\n",
      "epoch:32 step:30064 [D loss: 0.621321, acc.: 67.19%] [G loss: 0.955680]\n",
      "epoch:32 step:30065 [D loss: 0.520458, acc.: 78.12%] [G loss: 1.214460]\n",
      "epoch:32 step:30066 [D loss: 0.394673, acc.: 85.16%] [G loss: 1.734430]\n",
      "epoch:32 step:30067 [D loss: 0.510047, acc.: 75.00%] [G loss: 1.629588]\n",
      "epoch:32 step:30068 [D loss: 0.803514, acc.: 47.66%] [G loss: 0.735531]\n",
      "epoch:32 step:30069 [D loss: 0.612464, acc.: 68.75%] [G loss: 1.216597]\n",
      "epoch:32 step:30070 [D loss: 0.519069, acc.: 72.66%] [G loss: 1.486642]\n",
      "epoch:32 step:30071 [D loss: 0.412159, acc.: 85.94%] [G loss: 1.376343]\n",
      "epoch:32 step:30072 [D loss: 0.490203, acc.: 75.78%] [G loss: 1.160826]\n",
      "epoch:32 step:30073 [D loss: 0.481804, acc.: 76.56%] [G loss: 1.293392]\n",
      "epoch:32 step:30074 [D loss: 0.583496, acc.: 66.41%] [G loss: 1.555230]\n",
      "epoch:32 step:30075 [D loss: 0.533717, acc.: 75.00%] [G loss: 1.323146]\n",
      "epoch:32 step:30076 [D loss: 0.546364, acc.: 75.78%] [G loss: 1.850261]\n",
      "epoch:32 step:30077 [D loss: 0.459496, acc.: 80.47%] [G loss: 1.306369]\n",
      "epoch:32 step:30078 [D loss: 0.347421, acc.: 88.28%] [G loss: 1.548181]\n",
      "epoch:32 step:30079 [D loss: 0.554717, acc.: 71.88%] [G loss: 1.756924]\n",
      "epoch:32 step:30080 [D loss: 0.428180, acc.: 85.16%] [G loss: 1.374047]\n",
      "epoch:32 step:30081 [D loss: 0.564650, acc.: 71.88%] [G loss: 1.248738]\n",
      "epoch:32 step:30082 [D loss: 0.512529, acc.: 76.56%] [G loss: 1.105546]\n",
      "epoch:32 step:30083 [D loss: 0.673675, acc.: 63.28%] [G loss: 0.941562]\n",
      "epoch:32 step:30084 [D loss: 0.453612, acc.: 79.69%] [G loss: 2.114881]\n",
      "epoch:32 step:30085 [D loss: 0.620082, acc.: 64.06%] [G loss: 1.834415]\n",
      "epoch:32 step:30086 [D loss: 0.515039, acc.: 72.66%] [G loss: 1.338706]\n",
      "epoch:32 step:30087 [D loss: 0.617609, acc.: 67.97%] [G loss: 1.248229]\n",
      "epoch:32 step:30088 [D loss: 0.511980, acc.: 76.56%] [G loss: 1.349770]\n",
      "epoch:32 step:30089 [D loss: 0.397330, acc.: 81.25%] [G loss: 1.437116]\n",
      "epoch:32 step:30090 [D loss: 0.590505, acc.: 68.75%] [G loss: 1.350059]\n",
      "epoch:32 step:30091 [D loss: 0.501213, acc.: 79.69%] [G loss: 1.424889]\n",
      "epoch:32 step:30092 [D loss: 0.388535, acc.: 85.94%] [G loss: 1.711029]\n",
      "epoch:32 step:30093 [D loss: 0.586002, acc.: 68.75%] [G loss: 1.402032]\n",
      "epoch:32 step:30094 [D loss: 0.691000, acc.: 59.38%] [G loss: 1.005012]\n",
      "epoch:32 step:30095 [D loss: 0.617509, acc.: 62.50%] [G loss: 1.001100]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:32 step:30096 [D loss: 0.666377, acc.: 65.62%] [G loss: 1.218767]\n",
      "epoch:32 step:30097 [D loss: 0.472982, acc.: 80.47%] [G loss: 1.148817]\n",
      "epoch:32 step:30098 [D loss: 0.592950, acc.: 64.84%] [G loss: 1.585552]\n",
      "epoch:32 step:30099 [D loss: 0.377757, acc.: 90.62%] [G loss: 1.393454]\n",
      "epoch:32 step:30100 [D loss: 0.687647, acc.: 53.91%] [G loss: 1.773208]\n",
      "epoch:32 step:30101 [D loss: 0.554145, acc.: 68.75%] [G loss: 1.288123]\n",
      "epoch:32 step:30102 [D loss: 0.563652, acc.: 71.09%] [G loss: 1.311550]\n",
      "epoch:32 step:30103 [D loss: 0.406421, acc.: 79.69%] [G loss: 1.658527]\n",
      "epoch:32 step:30104 [D loss: 0.718866, acc.: 60.94%] [G loss: 1.719308]\n",
      "epoch:32 step:30105 [D loss: 0.486579, acc.: 78.12%] [G loss: 1.626657]\n",
      "epoch:32 step:30106 [D loss: 0.777449, acc.: 49.22%] [G loss: 1.136347]\n",
      "epoch:32 step:30107 [D loss: 0.344175, acc.: 89.84%] [G loss: 1.846920]\n",
      "epoch:32 step:30108 [D loss: 0.401421, acc.: 84.38%] [G loss: 1.270358]\n",
      "epoch:32 step:30109 [D loss: 0.497144, acc.: 74.22%] [G loss: 1.653759]\n",
      "epoch:32 step:30110 [D loss: 0.512164, acc.: 74.22%] [G loss: 2.024261]\n",
      "epoch:32 step:30111 [D loss: 0.642410, acc.: 65.62%] [G loss: 1.317861]\n",
      "epoch:32 step:30112 [D loss: 0.706443, acc.: 64.06%] [G loss: 1.442499]\n",
      "epoch:32 step:30113 [D loss: 0.485796, acc.: 75.78%] [G loss: 1.682603]\n",
      "epoch:32 step:30114 [D loss: 0.427133, acc.: 82.81%] [G loss: 1.236696]\n",
      "epoch:32 step:30115 [D loss: 0.571242, acc.: 67.97%] [G loss: 1.208344]\n",
      "epoch:32 step:30116 [D loss: 0.593254, acc.: 68.75%] [G loss: 1.354009]\n",
      "epoch:32 step:30117 [D loss: 0.336604, acc.: 86.72%] [G loss: 1.701079]\n",
      "epoch:32 step:30118 [D loss: 0.526578, acc.: 79.69%] [G loss: 1.792065]\n",
      "epoch:32 step:30119 [D loss: 0.597925, acc.: 71.88%] [G loss: 1.568209]\n",
      "epoch:32 step:30120 [D loss: 0.700832, acc.: 57.81%] [G loss: 1.081025]\n",
      "epoch:32 step:30121 [D loss: 0.621851, acc.: 62.50%] [G loss: 0.937236]\n",
      "epoch:32 step:30122 [D loss: 0.612676, acc.: 71.09%] [G loss: 1.235035]\n",
      "epoch:32 step:30123 [D loss: 0.570193, acc.: 73.44%] [G loss: 1.460990]\n",
      "epoch:32 step:30124 [D loss: 0.468818, acc.: 83.59%] [G loss: 1.561982]\n",
      "epoch:32 step:30125 [D loss: 0.611385, acc.: 70.31%] [G loss: 1.428702]\n",
      "epoch:32 step:30126 [D loss: 0.522200, acc.: 75.78%] [G loss: 1.611004]\n",
      "epoch:32 step:30127 [D loss: 0.438010, acc.: 83.59%] [G loss: 2.004075]\n",
      "epoch:32 step:30128 [D loss: 0.618899, acc.: 67.19%] [G loss: 1.953033]\n",
      "epoch:32 step:30129 [D loss: 0.452602, acc.: 78.12%] [G loss: 1.821757]\n",
      "epoch:32 step:30130 [D loss: 0.443787, acc.: 79.69%] [G loss: 1.606884]\n",
      "epoch:32 step:30131 [D loss: 0.530782, acc.: 77.34%] [G loss: 1.139734]\n",
      "epoch:32 step:30132 [D loss: 0.599858, acc.: 65.62%] [G loss: 1.369897]\n",
      "epoch:32 step:30133 [D loss: 0.632053, acc.: 64.84%] [G loss: 1.788857]\n",
      "epoch:32 step:30134 [D loss: 0.585636, acc.: 64.84%] [G loss: 1.527226]\n",
      "epoch:32 step:30135 [D loss: 0.584367, acc.: 72.66%] [G loss: 1.569107]\n",
      "epoch:32 step:30136 [D loss: 0.610133, acc.: 67.97%] [G loss: 1.621402]\n",
      "epoch:32 step:30137 [D loss: 0.568268, acc.: 71.88%] [G loss: 1.505901]\n",
      "epoch:32 step:30138 [D loss: 0.560650, acc.: 71.09%] [G loss: 1.365439]\n",
      "epoch:32 step:30139 [D loss: 0.467306, acc.: 78.12%] [G loss: 1.621282]\n",
      "epoch:32 step:30140 [D loss: 0.526340, acc.: 74.22%] [G loss: 1.501647]\n",
      "epoch:32 step:30141 [D loss: 0.524922, acc.: 75.00%] [G loss: 1.463059]\n",
      "epoch:32 step:30142 [D loss: 0.611814, acc.: 64.06%] [G loss: 0.863403]\n",
      "epoch:32 step:30143 [D loss: 0.490342, acc.: 76.56%] [G loss: 1.184941]\n",
      "epoch:32 step:30144 [D loss: 0.591033, acc.: 71.09%] [G loss: 1.134022]\n",
      "epoch:32 step:30145 [D loss: 0.457058, acc.: 78.91%] [G loss: 1.637815]\n",
      "epoch:32 step:30146 [D loss: 0.614867, acc.: 61.72%] [G loss: 1.576331]\n",
      "epoch:32 step:30147 [D loss: 0.575871, acc.: 73.44%] [G loss: 1.616037]\n",
      "epoch:32 step:30148 [D loss: 0.472317, acc.: 76.56%] [G loss: 1.841150]\n",
      "epoch:32 step:30149 [D loss: 0.513233, acc.: 73.44%] [G loss: 1.619213]\n",
      "epoch:32 step:30150 [D loss: 0.664576, acc.: 59.38%] [G loss: 0.928770]\n",
      "epoch:32 step:30151 [D loss: 0.630888, acc.: 67.19%] [G loss: 1.389220]\n",
      "epoch:32 step:30152 [D loss: 0.520885, acc.: 72.66%] [G loss: 1.263209]\n",
      "epoch:32 step:30153 [D loss: 0.593465, acc.: 66.41%] [G loss: 1.302517]\n",
      "epoch:32 step:30154 [D loss: 0.531145, acc.: 75.00%] [G loss: 1.745966]\n",
      "epoch:32 step:30155 [D loss: 0.486314, acc.: 78.12%] [G loss: 1.503689]\n",
      "epoch:32 step:30156 [D loss: 0.314639, acc.: 89.84%] [G loss: 1.407493]\n",
      "epoch:32 step:30157 [D loss: 0.638197, acc.: 66.41%] [G loss: 1.490495]\n",
      "epoch:32 step:30158 [D loss: 0.632167, acc.: 62.50%] [G loss: 1.482045]\n",
      "epoch:32 step:30159 [D loss: 0.464201, acc.: 78.12%] [G loss: 1.362941]\n",
      "epoch:32 step:30160 [D loss: 0.504677, acc.: 75.00%] [G loss: 1.100864]\n",
      "epoch:32 step:30161 [D loss: 0.454516, acc.: 82.03%] [G loss: 1.215952]\n",
      "epoch:32 step:30162 [D loss: 0.521947, acc.: 73.44%] [G loss: 0.874296]\n",
      "epoch:32 step:30163 [D loss: 0.497698, acc.: 78.91%] [G loss: 2.072049]\n",
      "epoch:32 step:30164 [D loss: 0.444709, acc.: 78.12%] [G loss: 1.841179]\n",
      "epoch:32 step:30165 [D loss: 0.513644, acc.: 73.44%] [G loss: 1.305929]\n",
      "epoch:32 step:30166 [D loss: 0.484107, acc.: 77.34%] [G loss: 1.983163]\n",
      "epoch:32 step:30167 [D loss: 0.391818, acc.: 86.72%] [G loss: 1.696236]\n",
      "epoch:32 step:30168 [D loss: 0.631690, acc.: 62.50%] [G loss: 1.597276]\n",
      "epoch:32 step:30169 [D loss: 0.508604, acc.: 77.34%] [G loss: 1.111730]\n",
      "epoch:32 step:30170 [D loss: 0.635242, acc.: 67.97%] [G loss: 1.074993]\n",
      "epoch:32 step:30171 [D loss: 0.375163, acc.: 84.38%] [G loss: 1.726255]\n",
      "epoch:32 step:30172 [D loss: 0.542576, acc.: 74.22%] [G loss: 1.467017]\n",
      "epoch:32 step:30173 [D loss: 0.506968, acc.: 81.25%] [G loss: 1.509915]\n",
      "epoch:32 step:30174 [D loss: 0.543536, acc.: 73.44%] [G loss: 2.062764]\n",
      "epoch:32 step:30175 [D loss: 0.458746, acc.: 78.91%] [G loss: 0.951270]\n",
      "epoch:32 step:30176 [D loss: 0.728761, acc.: 54.69%] [G loss: 1.268840]\n",
      "epoch:32 step:30177 [D loss: 0.563572, acc.: 73.44%] [G loss: 1.512089]\n",
      "epoch:32 step:30178 [D loss: 0.460864, acc.: 75.78%] [G loss: 1.415661]\n",
      "epoch:32 step:30179 [D loss: 0.596942, acc.: 71.09%] [G loss: 1.141995]\n",
      "epoch:32 step:30180 [D loss: 0.353655, acc.: 89.06%] [G loss: 1.565327]\n",
      "epoch:32 step:30181 [D loss: 0.427112, acc.: 83.59%] [G loss: 1.801902]\n",
      "epoch:32 step:30182 [D loss: 0.542743, acc.: 69.53%] [G loss: 1.360783]\n",
      "epoch:32 step:30183 [D loss: 0.331219, acc.: 92.19%] [G loss: 1.494287]\n",
      "epoch:32 step:30184 [D loss: 0.678131, acc.: 60.16%] [G loss: 1.239919]\n",
      "epoch:32 step:30185 [D loss: 0.437797, acc.: 79.69%] [G loss: 1.560208]\n",
      "epoch:32 step:30186 [D loss: 0.461480, acc.: 82.03%] [G loss: 1.331666]\n",
      "epoch:32 step:30187 [D loss: 0.394932, acc.: 85.16%] [G loss: 1.620289]\n",
      "epoch:32 step:30188 [D loss: 0.443834, acc.: 80.47%] [G loss: 1.532910]\n",
      "epoch:32 step:30189 [D loss: 0.613036, acc.: 65.62%] [G loss: 1.338600]\n",
      "epoch:32 step:30190 [D loss: 0.413555, acc.: 83.59%] [G loss: 1.251189]\n",
      "epoch:32 step:30191 [D loss: 0.646617, acc.: 66.41%] [G loss: 1.767814]\n",
      "epoch:32 step:30192 [D loss: 0.379509, acc.: 85.16%] [G loss: 1.419363]\n",
      "epoch:32 step:30193 [D loss: 0.457926, acc.: 78.91%] [G loss: 1.428124]\n",
      "epoch:32 step:30194 [D loss: 0.481672, acc.: 75.78%] [G loss: 1.604229]\n",
      "epoch:32 step:30195 [D loss: 0.611939, acc.: 68.75%] [G loss: 1.308424]\n",
      "epoch:32 step:30196 [D loss: 0.486279, acc.: 73.44%] [G loss: 1.404039]\n",
      "epoch:32 step:30197 [D loss: 0.665961, acc.: 63.28%] [G loss: 1.185918]\n",
      "epoch:32 step:30198 [D loss: 0.529641, acc.: 75.78%] [G loss: 1.243214]\n",
      "epoch:32 step:30199 [D loss: 0.668190, acc.: 59.38%] [G loss: 0.984622]\n",
      "epoch:32 step:30200 [D loss: 0.691093, acc.: 62.50%] [G loss: 1.414425]\n",
      "epoch:32 step:30201 [D loss: 0.442322, acc.: 75.78%] [G loss: 1.063509]\n",
      "epoch:32 step:30202 [D loss: 0.710132, acc.: 56.25%] [G loss: 1.510616]\n",
      "epoch:32 step:30203 [D loss: 0.617664, acc.: 64.84%] [G loss: 1.727804]\n",
      "epoch:32 step:30204 [D loss: 0.546999, acc.: 71.88%] [G loss: 1.457023]\n",
      "epoch:32 step:30205 [D loss: 0.526250, acc.: 77.34%] [G loss: 1.714856]\n",
      "epoch:32 step:30206 [D loss: 0.576095, acc.: 67.19%] [G loss: 1.521991]\n",
      "epoch:32 step:30207 [D loss: 0.485211, acc.: 79.69%] [G loss: 1.887954]\n",
      "epoch:32 step:30208 [D loss: 0.511654, acc.: 74.22%] [G loss: 1.132941]\n",
      "epoch:32 step:30209 [D loss: 0.598641, acc.: 64.06%] [G loss: 1.942220]\n",
      "epoch:32 step:30210 [D loss: 0.493871, acc.: 79.69%] [G loss: 2.022234]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:32 step:30211 [D loss: 0.523107, acc.: 73.44%] [G loss: 1.586055]\n",
      "epoch:32 step:30212 [D loss: 0.637342, acc.: 64.84%] [G loss: 1.250015]\n",
      "epoch:32 step:30213 [D loss: 0.444363, acc.: 79.69%] [G loss: 1.299107]\n",
      "epoch:32 step:30214 [D loss: 0.587409, acc.: 71.09%] [G loss: 1.607679]\n",
      "epoch:32 step:30215 [D loss: 0.548967, acc.: 66.41%] [G loss: 1.285794]\n",
      "epoch:32 step:30216 [D loss: 0.592649, acc.: 69.53%] [G loss: 1.300717]\n",
      "epoch:32 step:30217 [D loss: 0.443684, acc.: 80.47%] [G loss: 1.885383]\n",
      "epoch:32 step:30218 [D loss: 0.519176, acc.: 73.44%] [G loss: 1.445646]\n",
      "epoch:32 step:30219 [D loss: 0.367980, acc.: 87.50%] [G loss: 1.638256]\n",
      "epoch:32 step:30220 [D loss: 0.563271, acc.: 67.97%] [G loss: 1.202066]\n",
      "epoch:32 step:30221 [D loss: 0.501134, acc.: 76.56%] [G loss: 1.405861]\n",
      "epoch:32 step:30222 [D loss: 0.636856, acc.: 69.53%] [G loss: 1.768112]\n",
      "epoch:32 step:30223 [D loss: 0.410845, acc.: 82.81%] [G loss: 1.797652]\n",
      "epoch:32 step:30224 [D loss: 0.457838, acc.: 78.12%] [G loss: 2.225317]\n",
      "epoch:32 step:30225 [D loss: 0.532743, acc.: 72.66%] [G loss: 1.393899]\n",
      "epoch:32 step:30226 [D loss: 0.458879, acc.: 78.91%] [G loss: 0.997836]\n",
      "epoch:32 step:30227 [D loss: 0.316965, acc.: 91.41%] [G loss: 1.422378]\n",
      "epoch:32 step:30228 [D loss: 0.442510, acc.: 77.34%] [G loss: 1.125819]\n",
      "epoch:32 step:30229 [D loss: 0.512295, acc.: 75.78%] [G loss: 1.467817]\n",
      "epoch:32 step:30230 [D loss: 0.441016, acc.: 80.47%] [G loss: 1.622878]\n",
      "epoch:32 step:30231 [D loss: 0.707240, acc.: 60.16%] [G loss: 1.332597]\n",
      "epoch:32 step:30232 [D loss: 0.592312, acc.: 70.31%] [G loss: 1.176029]\n",
      "epoch:32 step:30233 [D loss: 0.333627, acc.: 91.41%] [G loss: 1.652134]\n",
      "epoch:32 step:30234 [D loss: 0.441993, acc.: 85.16%] [G loss: 1.652847]\n",
      "epoch:32 step:30235 [D loss: 0.462899, acc.: 82.03%] [G loss: 1.402788]\n",
      "epoch:32 step:30236 [D loss: 0.514019, acc.: 77.34%] [G loss: 1.227994]\n",
      "epoch:32 step:30237 [D loss: 0.553688, acc.: 70.31%] [G loss: 1.370224]\n",
      "epoch:32 step:30238 [D loss: 0.648957, acc.: 61.72%] [G loss: 0.958884]\n",
      "epoch:32 step:30239 [D loss: 0.461369, acc.: 78.91%] [G loss: 1.300528]\n",
      "epoch:32 step:30240 [D loss: 0.575379, acc.: 74.22%] [G loss: 1.567799]\n",
      "epoch:32 step:30241 [D loss: 0.335688, acc.: 87.50%] [G loss: 1.730872]\n",
      "epoch:32 step:30242 [D loss: 0.647796, acc.: 64.06%] [G loss: 1.262752]\n",
      "epoch:32 step:30243 [D loss: 0.674417, acc.: 66.41%] [G loss: 1.519411]\n",
      "epoch:32 step:30244 [D loss: 0.539765, acc.: 71.09%] [G loss: 1.488985]\n",
      "epoch:32 step:30245 [D loss: 0.453610, acc.: 82.03%] [G loss: 0.994502]\n",
      "epoch:32 step:30246 [D loss: 0.705120, acc.: 64.84%] [G loss: 1.168062]\n",
      "epoch:32 step:30247 [D loss: 0.563262, acc.: 69.53%] [G loss: 1.165628]\n",
      "epoch:32 step:30248 [D loss: 0.603603, acc.: 70.31%] [G loss: 1.654218]\n",
      "epoch:32 step:30249 [D loss: 0.402120, acc.: 84.38%] [G loss: 1.864091]\n",
      "epoch:32 step:30250 [D loss: 0.504544, acc.: 75.00%] [G loss: 1.718332]\n",
      "epoch:32 step:30251 [D loss: 0.450690, acc.: 81.25%] [G loss: 0.969538]\n",
      "epoch:32 step:30252 [D loss: 0.385914, acc.: 83.59%] [G loss: 2.007226]\n",
      "epoch:32 step:30253 [D loss: 0.369500, acc.: 82.03%] [G loss: 1.463648]\n",
      "epoch:32 step:30254 [D loss: 0.501754, acc.: 75.78%] [G loss: 1.865614]\n",
      "epoch:32 step:30255 [D loss: 0.408732, acc.: 83.59%] [G loss: 2.112838]\n",
      "epoch:32 step:30256 [D loss: 0.334583, acc.: 87.50%] [G loss: 1.845802]\n",
      "epoch:32 step:30257 [D loss: 0.731131, acc.: 57.03%] [G loss: 1.221901]\n",
      "epoch:32 step:30258 [D loss: 0.497977, acc.: 77.34%] [G loss: 1.127316]\n",
      "epoch:32 step:30259 [D loss: 0.689858, acc.: 58.59%] [G loss: 1.524927]\n",
      "epoch:32 step:30260 [D loss: 0.749845, acc.: 59.38%] [G loss: 1.857817]\n",
      "epoch:32 step:30261 [D loss: 0.499330, acc.: 75.00%] [G loss: 1.410463]\n",
      "epoch:32 step:30262 [D loss: 0.658664, acc.: 57.81%] [G loss: 1.001603]\n",
      "epoch:32 step:30263 [D loss: 0.580693, acc.: 68.75%] [G loss: 1.569206]\n",
      "epoch:32 step:30264 [D loss: 0.626351, acc.: 67.19%] [G loss: 0.874910]\n",
      "epoch:32 step:30265 [D loss: 0.545702, acc.: 72.66%] [G loss: 1.073576]\n",
      "epoch:32 step:30266 [D loss: 0.533697, acc.: 71.88%] [G loss: 1.424385]\n",
      "epoch:32 step:30267 [D loss: 0.394203, acc.: 84.38%] [G loss: 1.506987]\n",
      "epoch:32 step:30268 [D loss: 0.681170, acc.: 63.28%] [G loss: 1.293445]\n",
      "epoch:32 step:30269 [D loss: 0.460911, acc.: 80.47%] [G loss: 1.377571]\n",
      "epoch:32 step:30270 [D loss: 0.583195, acc.: 70.31%] [G loss: 1.091333]\n",
      "epoch:32 step:30271 [D loss: 0.571768, acc.: 70.31%] [G loss: 1.599545]\n",
      "epoch:32 step:30272 [D loss: 0.526294, acc.: 76.56%] [G loss: 1.244286]\n",
      "epoch:32 step:30273 [D loss: 0.630268, acc.: 64.06%] [G loss: 1.477370]\n",
      "epoch:32 step:30274 [D loss: 0.444912, acc.: 81.25%] [G loss: 1.445480]\n",
      "epoch:32 step:30275 [D loss: 0.645368, acc.: 61.72%] [G loss: 1.397244]\n",
      "epoch:32 step:30276 [D loss: 0.674495, acc.: 59.38%] [G loss: 1.643736]\n",
      "epoch:32 step:30277 [D loss: 0.635449, acc.: 65.62%] [G loss: 1.710437]\n",
      "epoch:32 step:30278 [D loss: 0.729728, acc.: 53.12%] [G loss: 1.236275]\n",
      "epoch:32 step:30279 [D loss: 0.717171, acc.: 57.03%] [G loss: 1.338488]\n",
      "epoch:32 step:30280 [D loss: 0.528932, acc.: 74.22%] [G loss: 1.191655]\n",
      "epoch:32 step:30281 [D loss: 0.610348, acc.: 65.62%] [G loss: 1.459551]\n",
      "epoch:32 step:30282 [D loss: 0.556831, acc.: 70.31%] [G loss: 1.196740]\n",
      "epoch:32 step:30283 [D loss: 0.528104, acc.: 75.00%] [G loss: 1.534585]\n",
      "epoch:32 step:30284 [D loss: 0.354079, acc.: 89.06%] [G loss: 1.545798]\n",
      "epoch:32 step:30285 [D loss: 0.629531, acc.: 64.06%] [G loss: 1.319412]\n",
      "epoch:32 step:30286 [D loss: 0.538148, acc.: 72.66%] [G loss: 1.789100]\n",
      "epoch:32 step:30287 [D loss: 0.750671, acc.: 58.59%] [G loss: 1.559160]\n",
      "epoch:32 step:30288 [D loss: 0.561619, acc.: 67.19%] [G loss: 1.720094]\n",
      "epoch:32 step:30289 [D loss: 0.638622, acc.: 65.62%] [G loss: 1.286131]\n",
      "epoch:32 step:30290 [D loss: 0.546190, acc.: 73.44%] [G loss: 1.862848]\n",
      "epoch:32 step:30291 [D loss: 0.545260, acc.: 75.78%] [G loss: 0.948612]\n",
      "epoch:32 step:30292 [D loss: 0.553862, acc.: 69.53%] [G loss: 0.905494]\n",
      "epoch:32 step:30293 [D loss: 0.443296, acc.: 79.69%] [G loss: 1.802981]\n",
      "epoch:32 step:30294 [D loss: 0.722756, acc.: 57.81%] [G loss: 1.683775]\n",
      "epoch:32 step:30295 [D loss: 0.391086, acc.: 85.94%] [G loss: 2.000534]\n",
      "epoch:32 step:30296 [D loss: 0.390116, acc.: 86.72%] [G loss: 1.970950]\n",
      "epoch:32 step:30297 [D loss: 0.608087, acc.: 70.31%] [G loss: 1.307180]\n",
      "epoch:32 step:30298 [D loss: 0.541820, acc.: 65.62%] [G loss: 1.732359]\n",
      "epoch:32 step:30299 [D loss: 0.603538, acc.: 65.62%] [G loss: 1.037662]\n",
      "epoch:32 step:30300 [D loss: 0.610307, acc.: 67.97%] [G loss: 1.359600]\n",
      "epoch:32 step:30301 [D loss: 0.396740, acc.: 85.94%] [G loss: 1.505644]\n",
      "epoch:32 step:30302 [D loss: 0.511928, acc.: 71.09%] [G loss: 1.329193]\n",
      "epoch:32 step:30303 [D loss: 0.422676, acc.: 81.25%] [G loss: 0.947443]\n",
      "epoch:32 step:30304 [D loss: 0.449787, acc.: 78.91%] [G loss: 1.440497]\n",
      "epoch:32 step:30305 [D loss: 0.539309, acc.: 75.00%] [G loss: 1.682955]\n",
      "epoch:32 step:30306 [D loss: 0.742559, acc.: 57.03%] [G loss: 1.991328]\n",
      "epoch:32 step:30307 [D loss: 0.553313, acc.: 75.00%] [G loss: 1.278934]\n",
      "epoch:32 step:30308 [D loss: 0.481651, acc.: 78.12%] [G loss: 1.552432]\n",
      "epoch:32 step:30309 [D loss: 0.524117, acc.: 70.31%] [G loss: 1.358147]\n",
      "epoch:32 step:30310 [D loss: 0.469685, acc.: 80.47%] [G loss: 1.199184]\n",
      "epoch:32 step:30311 [D loss: 0.450543, acc.: 79.69%] [G loss: 1.341733]\n",
      "epoch:32 step:30312 [D loss: 0.612318, acc.: 67.19%] [G loss: 1.378499]\n",
      "epoch:32 step:30313 [D loss: 0.453551, acc.: 75.78%] [G loss: 1.665112]\n",
      "epoch:32 step:30314 [D loss: 0.452217, acc.: 81.25%] [G loss: 1.637845]\n",
      "epoch:32 step:30315 [D loss: 0.500877, acc.: 75.78%] [G loss: 1.129690]\n",
      "epoch:32 step:30316 [D loss: 0.610551, acc.: 64.84%] [G loss: 1.542754]\n",
      "epoch:32 step:30317 [D loss: 0.608589, acc.: 63.28%] [G loss: 1.303420]\n",
      "epoch:32 step:30318 [D loss: 0.601712, acc.: 66.41%] [G loss: 1.333619]\n",
      "epoch:32 step:30319 [D loss: 0.686546, acc.: 62.50%] [G loss: 1.758173]\n",
      "epoch:32 step:30320 [D loss: 0.410060, acc.: 83.59%] [G loss: 1.982651]\n",
      "epoch:32 step:30321 [D loss: 0.692364, acc.: 57.03%] [G loss: 1.336448]\n",
      "epoch:32 step:30322 [D loss: 0.367186, acc.: 89.06%] [G loss: 1.421258]\n",
      "epoch:32 step:30323 [D loss: 0.574912, acc.: 69.53%] [G loss: 1.310580]\n",
      "epoch:32 step:30324 [D loss: 0.490340, acc.: 73.44%] [G loss: 1.870530]\n",
      "epoch:32 step:30325 [D loss: 0.556823, acc.: 74.22%] [G loss: 1.667204]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:32 step:30326 [D loss: 0.564110, acc.: 66.41%] [G loss: 1.523892]\n",
      "epoch:32 step:30327 [D loss: 0.595954, acc.: 69.53%] [G loss: 1.193590]\n",
      "epoch:32 step:30328 [D loss: 0.504135, acc.: 68.75%] [G loss: 1.723382]\n",
      "epoch:32 step:30329 [D loss: 0.441402, acc.: 82.03%] [G loss: 1.309629]\n",
      "epoch:32 step:30330 [D loss: 0.618414, acc.: 66.41%] [G loss: 1.777897]\n",
      "epoch:32 step:30331 [D loss: 0.499795, acc.: 74.22%] [G loss: 1.482138]\n",
      "epoch:32 step:30332 [D loss: 0.497861, acc.: 71.09%] [G loss: 1.152661]\n",
      "epoch:32 step:30333 [D loss: 0.523816, acc.: 77.34%] [G loss: 1.597778]\n",
      "epoch:32 step:30334 [D loss: 0.402784, acc.: 81.25%] [G loss: 2.220741]\n",
      "epoch:32 step:30335 [D loss: 0.401395, acc.: 83.59%] [G loss: 1.420072]\n",
      "epoch:32 step:30336 [D loss: 0.694357, acc.: 58.59%] [G loss: 1.098653]\n",
      "epoch:32 step:30337 [D loss: 0.524511, acc.: 71.88%] [G loss: 1.565233]\n",
      "epoch:32 step:30338 [D loss: 0.502327, acc.: 74.22%] [G loss: 1.355981]\n",
      "epoch:32 step:30339 [D loss: 0.529936, acc.: 74.22%] [G loss: 1.753926]\n",
      "epoch:32 step:30340 [D loss: 0.512202, acc.: 75.00%] [G loss: 1.157205]\n",
      "epoch:32 step:30341 [D loss: 0.425948, acc.: 80.47%] [G loss: 1.490969]\n",
      "epoch:32 step:30342 [D loss: 0.717561, acc.: 57.03%] [G loss: 1.781467]\n",
      "epoch:32 step:30343 [D loss: 0.667220, acc.: 62.50%] [G loss: 1.338276]\n",
      "epoch:32 step:30344 [D loss: 0.414841, acc.: 80.47%] [G loss: 1.851595]\n",
      "epoch:32 step:30345 [D loss: 0.495598, acc.: 75.78%] [G loss: 1.511052]\n",
      "epoch:32 step:30346 [D loss: 0.461645, acc.: 78.91%] [G loss: 1.788094]\n",
      "epoch:32 step:30347 [D loss: 0.508819, acc.: 75.78%] [G loss: 1.430168]\n",
      "epoch:32 step:30348 [D loss: 0.456066, acc.: 80.47%] [G loss: 1.892079]\n",
      "epoch:32 step:30349 [D loss: 0.483819, acc.: 78.12%] [G loss: 1.364467]\n",
      "epoch:32 step:30350 [D loss: 0.467107, acc.: 78.12%] [G loss: 1.487159]\n",
      "epoch:32 step:30351 [D loss: 0.462789, acc.: 82.81%] [G loss: 1.336818]\n",
      "epoch:32 step:30352 [D loss: 0.510389, acc.: 78.91%] [G loss: 1.539760]\n",
      "epoch:32 step:30353 [D loss: 0.573876, acc.: 67.19%] [G loss: 1.614126]\n",
      "epoch:32 step:30354 [D loss: 0.493667, acc.: 75.78%] [G loss: 1.647660]\n",
      "epoch:32 step:30355 [D loss: 0.542788, acc.: 72.66%] [G loss: 1.493593]\n",
      "epoch:32 step:30356 [D loss: 0.645126, acc.: 63.28%] [G loss: 1.215639]\n",
      "epoch:32 step:30357 [D loss: 0.693937, acc.: 60.94%] [G loss: 1.712715]\n",
      "epoch:32 step:30358 [D loss: 0.629749, acc.: 67.97%] [G loss: 1.591635]\n",
      "epoch:32 step:30359 [D loss: 0.717210, acc.: 60.94%] [G loss: 1.182649]\n",
      "epoch:32 step:30360 [D loss: 0.376561, acc.: 85.16%] [G loss: 1.711906]\n",
      "epoch:32 step:30361 [D loss: 0.472019, acc.: 78.12%] [G loss: 1.567408]\n",
      "epoch:32 step:30362 [D loss: 0.547529, acc.: 70.31%] [G loss: 1.143620]\n",
      "epoch:32 step:30363 [D loss: 0.360106, acc.: 92.97%] [G loss: 1.529940]\n",
      "epoch:32 step:30364 [D loss: 0.570940, acc.: 69.53%] [G loss: 1.168112]\n",
      "epoch:32 step:30365 [D loss: 0.530522, acc.: 75.00%] [G loss: 1.540030]\n",
      "epoch:32 step:30366 [D loss: 0.502714, acc.: 75.78%] [G loss: 1.451789]\n",
      "epoch:32 step:30367 [D loss: 0.534615, acc.: 76.56%] [G loss: 1.808779]\n",
      "epoch:32 step:30368 [D loss: 0.671773, acc.: 64.84%] [G loss: 1.250761]\n",
      "epoch:32 step:30369 [D loss: 0.698180, acc.: 62.50%] [G loss: 1.417166]\n",
      "epoch:32 step:30370 [D loss: 0.568266, acc.: 75.00%] [G loss: 1.677681]\n",
      "epoch:32 step:30371 [D loss: 0.319248, acc.: 89.06%] [G loss: 1.567111]\n",
      "epoch:32 step:30372 [D loss: 0.524808, acc.: 67.97%] [G loss: 1.982207]\n",
      "epoch:32 step:30373 [D loss: 0.820343, acc.: 53.91%] [G loss: 1.368150]\n",
      "epoch:32 step:30374 [D loss: 0.441174, acc.: 79.69%] [G loss: 1.304929]\n",
      "epoch:32 step:30375 [D loss: 0.730171, acc.: 60.16%] [G loss: 1.231398]\n",
      "epoch:32 step:30376 [D loss: 0.623779, acc.: 64.84%] [G loss: 1.907032]\n",
      "epoch:32 step:30377 [D loss: 0.684722, acc.: 60.94%] [G loss: 1.078676]\n",
      "epoch:32 step:30378 [D loss: 0.532782, acc.: 75.00%] [G loss: 1.472700]\n",
      "epoch:32 step:30379 [D loss: 0.560284, acc.: 73.44%] [G loss: 1.464181]\n",
      "epoch:32 step:30380 [D loss: 0.585625, acc.: 68.75%] [G loss: 1.443355]\n",
      "epoch:32 step:30381 [D loss: 0.591616, acc.: 68.75%] [G loss: 1.327542]\n",
      "epoch:32 step:30382 [D loss: 0.536585, acc.: 72.66%] [G loss: 1.099025]\n",
      "epoch:32 step:30383 [D loss: 0.837817, acc.: 47.66%] [G loss: 1.441867]\n",
      "epoch:32 step:30384 [D loss: 0.540211, acc.: 74.22%] [G loss: 1.919424]\n",
      "epoch:32 step:30385 [D loss: 0.753529, acc.: 57.81%] [G loss: 0.963126]\n",
      "epoch:32 step:30386 [D loss: 0.314613, acc.: 92.19%] [G loss: 2.245302]\n",
      "epoch:32 step:30387 [D loss: 0.523740, acc.: 74.22%] [G loss: 0.993057]\n",
      "epoch:32 step:30388 [D loss: 0.493043, acc.: 73.44%] [G loss: 1.195947]\n",
      "epoch:32 step:30389 [D loss: 0.499119, acc.: 77.34%] [G loss: 1.385642]\n",
      "epoch:32 step:30390 [D loss: 0.471553, acc.: 80.47%] [G loss: 1.367020]\n",
      "epoch:32 step:30391 [D loss: 0.470317, acc.: 75.00%] [G loss: 1.441316]\n",
      "epoch:32 step:30392 [D loss: 0.517861, acc.: 74.22%] [G loss: 1.256024]\n",
      "epoch:32 step:30393 [D loss: 0.854693, acc.: 47.66%] [G loss: 1.401889]\n",
      "epoch:32 step:30394 [D loss: 0.456654, acc.: 78.12%] [G loss: 1.148729]\n",
      "epoch:32 step:30395 [D loss: 0.611948, acc.: 66.41%] [G loss: 1.113236]\n",
      "epoch:32 step:30396 [D loss: 0.692075, acc.: 60.16%] [G loss: 1.240010]\n",
      "epoch:32 step:30397 [D loss: 0.521955, acc.: 73.44%] [G loss: 1.385017]\n",
      "epoch:32 step:30398 [D loss: 0.642165, acc.: 62.50%] [G loss: 1.446374]\n",
      "epoch:32 step:30399 [D loss: 0.493252, acc.: 76.56%] [G loss: 1.372586]\n",
      "epoch:32 step:30400 [D loss: 0.574521, acc.: 62.50%] [G loss: 1.372624]\n",
      "epoch:32 step:30401 [D loss: 0.469316, acc.: 79.69%] [G loss: 1.688380]\n",
      "epoch:32 step:30402 [D loss: 0.534769, acc.: 71.09%] [G loss: 1.618300]\n",
      "epoch:32 step:30403 [D loss: 0.533837, acc.: 75.00%] [G loss: 2.020626]\n",
      "epoch:32 step:30404 [D loss: 0.516025, acc.: 77.34%] [G loss: 1.193509]\n",
      "epoch:32 step:30405 [D loss: 0.454310, acc.: 80.47%] [G loss: 1.808721]\n",
      "epoch:32 step:30406 [D loss: 0.439196, acc.: 81.25%] [G loss: 1.523141]\n",
      "epoch:32 step:30407 [D loss: 0.476162, acc.: 78.12%] [G loss: 1.818229]\n",
      "epoch:32 step:30408 [D loss: 0.579580, acc.: 69.53%] [G loss: 1.073237]\n",
      "epoch:32 step:30409 [D loss: 0.382431, acc.: 85.94%] [G loss: 1.634748]\n",
      "epoch:32 step:30410 [D loss: 0.471891, acc.: 76.56%] [G loss: 1.568000]\n",
      "epoch:32 step:30411 [D loss: 0.692150, acc.: 62.50%] [G loss: 1.184216]\n",
      "epoch:32 step:30412 [D loss: 0.656094, acc.: 66.41%] [G loss: 1.683428]\n",
      "epoch:32 step:30413 [D loss: 0.536934, acc.: 72.66%] [G loss: 1.451584]\n",
      "epoch:32 step:30414 [D loss: 0.536293, acc.: 73.44%] [G loss: 1.448604]\n",
      "epoch:32 step:30415 [D loss: 0.579371, acc.: 68.75%] [G loss: 1.450945]\n",
      "epoch:32 step:30416 [D loss: 0.352965, acc.: 84.38%] [G loss: 1.746686]\n",
      "epoch:32 step:30417 [D loss: 0.447560, acc.: 79.69%] [G loss: 1.745977]\n",
      "epoch:32 step:30418 [D loss: 0.447938, acc.: 78.12%] [G loss: 1.499497]\n",
      "epoch:32 step:30419 [D loss: 0.565475, acc.: 71.88%] [G loss: 1.544180]\n",
      "epoch:32 step:30420 [D loss: 0.423328, acc.: 82.81%] [G loss: 1.861958]\n",
      "epoch:32 step:30421 [D loss: 0.616280, acc.: 65.62%] [G loss: 1.663492]\n",
      "epoch:32 step:30422 [D loss: 0.457513, acc.: 79.69%] [G loss: 1.018061]\n",
      "epoch:32 step:30423 [D loss: 0.515722, acc.: 72.66%] [G loss: 1.369948]\n",
      "epoch:32 step:30424 [D loss: 0.529658, acc.: 76.56%] [G loss: 1.272477]\n",
      "epoch:32 step:30425 [D loss: 0.552592, acc.: 72.66%] [G loss: 1.745900]\n",
      "epoch:32 step:30426 [D loss: 0.599690, acc.: 63.28%] [G loss: 1.310050]\n",
      "epoch:32 step:30427 [D loss: 0.708113, acc.: 60.94%] [G loss: 1.167239]\n",
      "epoch:32 step:30428 [D loss: 0.461499, acc.: 85.16%] [G loss: 1.566195]\n",
      "epoch:32 step:30429 [D loss: 0.373429, acc.: 86.72%] [G loss: 1.718870]\n",
      "epoch:32 step:30430 [D loss: 0.752794, acc.: 56.25%] [G loss: 1.377821]\n",
      "epoch:32 step:30431 [D loss: 0.396603, acc.: 84.38%] [G loss: 1.862162]\n",
      "epoch:32 step:30432 [D loss: 0.410409, acc.: 82.03%] [G loss: 1.616720]\n",
      "epoch:32 step:30433 [D loss: 0.515583, acc.: 77.34%] [G loss: 1.518832]\n",
      "epoch:32 step:30434 [D loss: 0.812747, acc.: 51.56%] [G loss: 0.946788]\n",
      "epoch:32 step:30435 [D loss: 0.320212, acc.: 92.19%] [G loss: 1.349875]\n",
      "epoch:32 step:30436 [D loss: 0.362732, acc.: 83.59%] [G loss: 1.743192]\n",
      "epoch:32 step:30437 [D loss: 0.406083, acc.: 84.38%] [G loss: 1.243474]\n",
      "epoch:32 step:30438 [D loss: 0.449561, acc.: 79.69%] [G loss: 1.942319]\n",
      "epoch:32 step:30439 [D loss: 0.569343, acc.: 70.31%] [G loss: 1.707851]\n",
      "epoch:32 step:30440 [D loss: 0.768220, acc.: 53.12%] [G loss: 1.332753]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:32 step:30441 [D loss: 0.680181, acc.: 57.81%] [G loss: 1.456641]\n",
      "epoch:32 step:30442 [D loss: 0.516446, acc.: 77.34%] [G loss: 1.448344]\n",
      "epoch:32 step:30443 [D loss: 0.590370, acc.: 67.19%] [G loss: 1.041683]\n",
      "epoch:32 step:30444 [D loss: 0.489504, acc.: 79.69%] [G loss: 1.244609]\n",
      "epoch:32 step:30445 [D loss: 0.539148, acc.: 69.53%] [G loss: 1.345381]\n",
      "epoch:32 step:30446 [D loss: 0.748857, acc.: 55.47%] [G loss: 0.922412]\n",
      "epoch:32 step:30447 [D loss: 0.487220, acc.: 79.69%] [G loss: 1.757585]\n",
      "epoch:32 step:30448 [D loss: 0.531154, acc.: 71.88%] [G loss: 1.444754]\n",
      "epoch:32 step:30449 [D loss: 0.628368, acc.: 61.72%] [G loss: 1.485087]\n",
      "epoch:32 step:30450 [D loss: 0.419185, acc.: 82.81%] [G loss: 1.759586]\n",
      "epoch:32 step:30451 [D loss: 0.306868, acc.: 91.41%] [G loss: 1.462003]\n",
      "epoch:32 step:30452 [D loss: 0.481656, acc.: 77.34%] [G loss: 1.508793]\n",
      "epoch:32 step:30453 [D loss: 0.377069, acc.: 85.16%] [G loss: 1.420694]\n",
      "epoch:32 step:30454 [D loss: 0.648999, acc.: 66.41%] [G loss: 1.065114]\n",
      "epoch:32 step:30455 [D loss: 0.527252, acc.: 73.44%] [G loss: 1.224738]\n",
      "epoch:32 step:30456 [D loss: 0.498548, acc.: 75.00%] [G loss: 1.682738]\n",
      "epoch:32 step:30457 [D loss: 0.324448, acc.: 90.62%] [G loss: 1.821277]\n",
      "epoch:32 step:30458 [D loss: 0.520318, acc.: 74.22%] [G loss: 1.172471]\n",
      "epoch:32 step:30459 [D loss: 0.589889, acc.: 70.31%] [G loss: 1.736468]\n",
      "epoch:32 step:30460 [D loss: 0.767953, acc.: 56.25%] [G loss: 1.786704]\n",
      "epoch:32 step:30461 [D loss: 0.505782, acc.: 75.00%] [G loss: 1.770871]\n",
      "epoch:32 step:30462 [D loss: 0.471169, acc.: 76.56%] [G loss: 1.426006]\n",
      "epoch:32 step:30463 [D loss: 0.498726, acc.: 70.31%] [G loss: 1.217232]\n",
      "epoch:32 step:30464 [D loss: 0.448099, acc.: 80.47%] [G loss: 1.659218]\n",
      "epoch:32 step:30465 [D loss: 0.574527, acc.: 67.19%] [G loss: 1.365963]\n",
      "epoch:32 step:30466 [D loss: 0.489424, acc.: 78.12%] [G loss: 1.359597]\n",
      "epoch:32 step:30467 [D loss: 0.474849, acc.: 80.47%] [G loss: 1.490914]\n",
      "epoch:32 step:30468 [D loss: 0.721326, acc.: 60.16%] [G loss: 1.400037]\n",
      "epoch:32 step:30469 [D loss: 0.557868, acc.: 74.22%] [G loss: 1.209784]\n",
      "epoch:32 step:30470 [D loss: 0.620281, acc.: 67.97%] [G loss: 1.503215]\n",
      "epoch:32 step:30471 [D loss: 0.559773, acc.: 72.66%] [G loss: 1.439039]\n",
      "epoch:32 step:30472 [D loss: 0.486444, acc.: 78.91%] [G loss: 1.504328]\n",
      "epoch:32 step:30473 [D loss: 0.595094, acc.: 71.88%] [G loss: 1.314834]\n",
      "epoch:32 step:30474 [D loss: 0.445215, acc.: 78.12%] [G loss: 1.396062]\n",
      "epoch:32 step:30475 [D loss: 0.427776, acc.: 82.03%] [G loss: 1.571399]\n",
      "epoch:32 step:30476 [D loss: 0.425961, acc.: 78.12%] [G loss: 1.369378]\n",
      "epoch:32 step:30477 [D loss: 0.541855, acc.: 73.44%] [G loss: 1.536045]\n",
      "epoch:32 step:30478 [D loss: 0.629500, acc.: 63.28%] [G loss: 1.141946]\n",
      "epoch:32 step:30479 [D loss: 0.442067, acc.: 82.03%] [G loss: 1.250634]\n",
      "epoch:32 step:30480 [D loss: 0.590705, acc.: 67.19%] [G loss: 1.654159]\n",
      "epoch:32 step:30481 [D loss: 0.602683, acc.: 69.53%] [G loss: 1.216131]\n",
      "epoch:32 step:30482 [D loss: 0.497821, acc.: 78.12%] [G loss: 1.268126]\n",
      "epoch:32 step:30483 [D loss: 0.483821, acc.: 76.56%] [G loss: 1.432949]\n",
      "epoch:32 step:30484 [D loss: 0.589837, acc.: 68.75%] [G loss: 1.151683]\n",
      "epoch:32 step:30485 [D loss: 0.391172, acc.: 85.94%] [G loss: 1.746200]\n",
      "epoch:32 step:30486 [D loss: 0.306498, acc.: 90.62%] [G loss: 1.397125]\n",
      "epoch:32 step:30487 [D loss: 0.361357, acc.: 89.06%] [G loss: 1.613930]\n",
      "epoch:32 step:30488 [D loss: 0.557553, acc.: 74.22%] [G loss: 1.274327]\n",
      "epoch:32 step:30489 [D loss: 0.374090, acc.: 88.28%] [G loss: 1.769846]\n",
      "epoch:32 step:30490 [D loss: 0.551109, acc.: 72.66%] [G loss: 1.614857]\n",
      "epoch:32 step:30491 [D loss: 0.613120, acc.: 66.41%] [G loss: 1.071993]\n",
      "epoch:32 step:30492 [D loss: 0.542106, acc.: 73.44%] [G loss: 1.224104]\n",
      "epoch:32 step:30493 [D loss: 0.636256, acc.: 65.62%] [G loss: 1.522826]\n",
      "epoch:32 step:30494 [D loss: 0.514064, acc.: 76.56%] [G loss: 1.772597]\n",
      "epoch:32 step:30495 [D loss: 0.434338, acc.: 81.25%] [G loss: 1.723401]\n",
      "epoch:32 step:30496 [D loss: 0.445538, acc.: 80.47%] [G loss: 1.761109]\n",
      "epoch:32 step:30497 [D loss: 0.372454, acc.: 87.50%] [G loss: 1.441105]\n",
      "epoch:32 step:30498 [D loss: 0.340038, acc.: 89.84%] [G loss: 1.692306]\n",
      "epoch:32 step:30499 [D loss: 0.524761, acc.: 66.41%] [G loss: 1.597015]\n",
      "epoch:32 step:30500 [D loss: 0.496531, acc.: 79.69%] [G loss: 1.170906]\n",
      "epoch:32 step:30501 [D loss: 0.521405, acc.: 75.78%] [G loss: 1.461975]\n",
      "epoch:32 step:30502 [D loss: 0.563204, acc.: 77.34%] [G loss: 1.408906]\n",
      "epoch:32 step:30503 [D loss: 0.481453, acc.: 79.69%] [G loss: 1.331624]\n",
      "epoch:32 step:30504 [D loss: 0.459591, acc.: 77.34%] [G loss: 1.560913]\n",
      "epoch:32 step:30505 [D loss: 0.532375, acc.: 75.78%] [G loss: 1.130964]\n",
      "epoch:32 step:30506 [D loss: 0.670254, acc.: 67.19%] [G loss: 1.238523]\n",
      "epoch:32 step:30507 [D loss: 0.651472, acc.: 64.06%] [G loss: 1.365939]\n",
      "epoch:32 step:30508 [D loss: 0.624143, acc.: 69.53%] [G loss: 2.087566]\n",
      "epoch:32 step:30509 [D loss: 0.563437, acc.: 72.66%] [G loss: 1.347718]\n",
      "epoch:32 step:30510 [D loss: 0.554626, acc.: 69.53%] [G loss: 1.144893]\n",
      "epoch:32 step:30511 [D loss: 0.732688, acc.: 59.38%] [G loss: 1.023229]\n",
      "epoch:32 step:30512 [D loss: 0.612349, acc.: 66.41%] [G loss: 1.647812]\n",
      "epoch:32 step:30513 [D loss: 0.536557, acc.: 71.09%] [G loss: 1.377916]\n",
      "epoch:32 step:30514 [D loss: 0.455666, acc.: 78.12%] [G loss: 1.400620]\n",
      "epoch:32 step:30515 [D loss: 0.409145, acc.: 79.69%] [G loss: 1.438890]\n",
      "epoch:32 step:30516 [D loss: 0.683392, acc.: 59.38%] [G loss: 1.648293]\n",
      "epoch:32 step:30517 [D loss: 0.431777, acc.: 81.25%] [G loss: 1.292821]\n",
      "epoch:32 step:30518 [D loss: 0.619307, acc.: 64.06%] [G loss: 1.330277]\n",
      "epoch:32 step:30519 [D loss: 0.675475, acc.: 64.84%] [G loss: 1.128978]\n",
      "epoch:32 step:30520 [D loss: 0.745531, acc.: 54.69%] [G loss: 1.596333]\n",
      "epoch:32 step:30521 [D loss: 0.554837, acc.: 71.88%] [G loss: 1.401469]\n",
      "epoch:32 step:30522 [D loss: 0.705721, acc.: 60.16%] [G loss: 1.262344]\n",
      "epoch:32 step:30523 [D loss: 0.451515, acc.: 81.25%] [G loss: 1.555196]\n",
      "epoch:32 step:30524 [D loss: 0.483428, acc.: 78.91%] [G loss: 1.616882]\n",
      "epoch:32 step:30525 [D loss: 0.478485, acc.: 78.12%] [G loss: 1.329906]\n",
      "epoch:32 step:30526 [D loss: 0.416182, acc.: 83.59%] [G loss: 1.880107]\n",
      "epoch:32 step:30527 [D loss: 0.527342, acc.: 71.09%] [G loss: 1.764057]\n",
      "epoch:32 step:30528 [D loss: 0.500164, acc.: 77.34%] [G loss: 1.465057]\n",
      "epoch:32 step:30529 [D loss: 0.348331, acc.: 86.72%] [G loss: 1.519628]\n",
      "epoch:32 step:30530 [D loss: 0.384281, acc.: 85.94%] [G loss: 1.647920]\n",
      "epoch:32 step:30531 [D loss: 0.520375, acc.: 74.22%] [G loss: 1.602621]\n",
      "epoch:32 step:30532 [D loss: 0.628347, acc.: 65.62%] [G loss: 1.078329]\n",
      "epoch:32 step:30533 [D loss: 0.631864, acc.: 67.97%] [G loss: 1.689414]\n",
      "epoch:32 step:30534 [D loss: 0.428502, acc.: 84.38%] [G loss: 1.558040]\n",
      "epoch:32 step:30535 [D loss: 0.491753, acc.: 75.00%] [G loss: 1.400059]\n",
      "epoch:32 step:30536 [D loss: 0.466151, acc.: 78.91%] [G loss: 2.095840]\n",
      "epoch:32 step:30537 [D loss: 0.416481, acc.: 82.81%] [G loss: 1.316628]\n",
      "epoch:32 step:30538 [D loss: 0.561121, acc.: 70.31%] [G loss: 1.214908]\n",
      "epoch:32 step:30539 [D loss: 0.528149, acc.: 75.00%] [G loss: 1.353859]\n",
      "epoch:32 step:30540 [D loss: 0.486671, acc.: 80.47%] [G loss: 1.764121]\n",
      "epoch:32 step:30541 [D loss: 0.554760, acc.: 74.22%] [G loss: 1.790613]\n",
      "epoch:32 step:30542 [D loss: 0.578170, acc.: 67.19%] [G loss: 1.514426]\n",
      "epoch:32 step:30543 [D loss: 0.809321, acc.: 49.22%] [G loss: 2.022997]\n",
      "epoch:32 step:30544 [D loss: 0.407188, acc.: 80.47%] [G loss: 1.500935]\n",
      "epoch:32 step:30545 [D loss: 0.419647, acc.: 85.94%] [G loss: 1.363801]\n",
      "epoch:32 step:30546 [D loss: 0.528795, acc.: 74.22%] [G loss: 1.507845]\n",
      "epoch:32 step:30547 [D loss: 0.404269, acc.: 85.94%] [G loss: 1.411944]\n",
      "epoch:32 step:30548 [D loss: 0.578836, acc.: 68.75%] [G loss: 1.889559]\n",
      "epoch:32 step:30549 [D loss: 0.473979, acc.: 81.25%] [G loss: 1.512382]\n",
      "epoch:32 step:30550 [D loss: 0.645580, acc.: 61.72%] [G loss: 1.270404]\n",
      "epoch:32 step:30551 [D loss: 0.616988, acc.: 67.19%] [G loss: 1.399662]\n",
      "epoch:32 step:30552 [D loss: 0.450931, acc.: 78.91%] [G loss: 1.604152]\n",
      "epoch:32 step:30553 [D loss: 0.452894, acc.: 82.03%] [G loss: 1.714466]\n",
      "epoch:32 step:30554 [D loss: 0.428342, acc.: 80.47%] [G loss: 1.765437]\n",
      "epoch:32 step:30555 [D loss: 0.491898, acc.: 72.66%] [G loss: 1.264154]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:32 step:30556 [D loss: 0.351736, acc.: 91.41%] [G loss: 1.580486]\n",
      "epoch:32 step:30557 [D loss: 0.626020, acc.: 67.97%] [G loss: 1.433305]\n",
      "epoch:32 step:30558 [D loss: 0.559072, acc.: 70.31%] [G loss: 1.468770]\n",
      "epoch:32 step:30559 [D loss: 0.674121, acc.: 59.38%] [G loss: 1.403641]\n",
      "epoch:32 step:30560 [D loss: 0.444394, acc.: 82.03%] [G loss: 1.475290]\n",
      "epoch:32 step:30561 [D loss: 0.610623, acc.: 67.97%] [G loss: 1.311215]\n",
      "epoch:32 step:30562 [D loss: 0.390425, acc.: 87.50%] [G loss: 1.446422]\n",
      "epoch:32 step:30563 [D loss: 0.540355, acc.: 67.97%] [G loss: 1.615163]\n",
      "epoch:32 step:30564 [D loss: 0.734039, acc.: 61.72%] [G loss: 0.987002]\n",
      "epoch:32 step:30565 [D loss: 0.494132, acc.: 74.22%] [G loss: 1.735257]\n",
      "epoch:32 step:30566 [D loss: 0.527846, acc.: 77.34%] [G loss: 1.216161]\n",
      "epoch:32 step:30567 [D loss: 0.573003, acc.: 70.31%] [G loss: 1.083674]\n",
      "epoch:32 step:30568 [D loss: 0.522714, acc.: 73.44%] [G loss: 1.081612]\n",
      "epoch:32 step:30569 [D loss: 0.405263, acc.: 82.81%] [G loss: 0.949912]\n",
      "epoch:32 step:30570 [D loss: 0.343326, acc.: 86.72%] [G loss: 1.629831]\n",
      "epoch:32 step:30571 [D loss: 0.462658, acc.: 80.47%] [G loss: 1.209832]\n",
      "epoch:32 step:30572 [D loss: 0.592461, acc.: 72.66%] [G loss: 1.068755]\n",
      "epoch:32 step:30573 [D loss: 0.538943, acc.: 71.88%] [G loss: 1.023980]\n",
      "epoch:32 step:30574 [D loss: 0.427971, acc.: 82.81%] [G loss: 1.362920]\n",
      "epoch:32 step:30575 [D loss: 0.406517, acc.: 81.25%] [G loss: 1.905189]\n",
      "epoch:32 step:30576 [D loss: 0.519030, acc.: 76.56%] [G loss: 1.696387]\n",
      "epoch:32 step:30577 [D loss: 0.570340, acc.: 71.88%] [G loss: 1.491302]\n",
      "epoch:32 step:30578 [D loss: 0.509782, acc.: 71.09%] [G loss: 1.603476]\n",
      "epoch:32 step:30579 [D loss: 0.490937, acc.: 77.34%] [G loss: 1.534093]\n",
      "epoch:32 step:30580 [D loss: 0.561526, acc.: 69.53%] [G loss: 1.260811]\n",
      "epoch:32 step:30581 [D loss: 0.642634, acc.: 60.16%] [G loss: 1.544342]\n",
      "epoch:32 step:30582 [D loss: 0.541740, acc.: 73.44%] [G loss: 1.488416]\n",
      "epoch:32 step:30583 [D loss: 0.411610, acc.: 84.38%] [G loss: 1.668157]\n",
      "epoch:32 step:30584 [D loss: 0.350648, acc.: 88.28%] [G loss: 1.293178]\n",
      "epoch:32 step:30585 [D loss: 0.651928, acc.: 69.53%] [G loss: 1.818338]\n",
      "epoch:32 step:30586 [D loss: 0.544809, acc.: 71.88%] [G loss: 0.816597]\n",
      "epoch:32 step:30587 [D loss: 0.629154, acc.: 67.97%] [G loss: 1.406781]\n",
      "epoch:32 step:30588 [D loss: 0.555407, acc.: 72.66%] [G loss: 1.544911]\n",
      "epoch:32 step:30589 [D loss: 0.586321, acc.: 68.75%] [G loss: 1.132377]\n",
      "epoch:32 step:30590 [D loss: 0.616550, acc.: 64.84%] [G loss: 1.729068]\n",
      "epoch:32 step:30591 [D loss: 0.418082, acc.: 82.81%] [G loss: 1.574466]\n",
      "epoch:32 step:30592 [D loss: 0.689489, acc.: 61.72%] [G loss: 0.923947]\n",
      "epoch:32 step:30593 [D loss: 0.356578, acc.: 86.72%] [G loss: 1.638806]\n",
      "epoch:32 step:30594 [D loss: 0.686294, acc.: 62.50%] [G loss: 1.310510]\n",
      "epoch:32 step:30595 [D loss: 0.522571, acc.: 76.56%] [G loss: 1.649770]\n",
      "epoch:32 step:30596 [D loss: 0.731856, acc.: 57.03%] [G loss: 1.542207]\n",
      "epoch:32 step:30597 [D loss: 0.532709, acc.: 71.09%] [G loss: 1.173020]\n",
      "epoch:32 step:30598 [D loss: 0.669759, acc.: 64.06%] [G loss: 1.204995]\n",
      "epoch:32 step:30599 [D loss: 0.375686, acc.: 87.50%] [G loss: 1.791258]\n",
      "epoch:32 step:30600 [D loss: 0.523035, acc.: 74.22%] [G loss: 1.088447]\n",
      "epoch:32 step:30601 [D loss: 0.498419, acc.: 78.91%] [G loss: 1.429605]\n",
      "epoch:32 step:30602 [D loss: 0.550205, acc.: 71.09%] [G loss: 1.714594]\n",
      "epoch:32 step:30603 [D loss: 0.800767, acc.: 52.34%] [G loss: 1.276267]\n",
      "epoch:32 step:30604 [D loss: 0.750151, acc.: 53.12%] [G loss: 1.240040]\n",
      "epoch:32 step:30605 [D loss: 0.518398, acc.: 75.00%] [G loss: 1.289512]\n",
      "epoch:32 step:30606 [D loss: 0.543266, acc.: 73.44%] [G loss: 1.939677]\n",
      "epoch:32 step:30607 [D loss: 0.415194, acc.: 80.47%] [G loss: 1.236286]\n",
      "epoch:32 step:30608 [D loss: 0.525724, acc.: 76.56%] [G loss: 1.444106]\n",
      "epoch:32 step:30609 [D loss: 0.352307, acc.: 88.28%] [G loss: 1.954915]\n",
      "epoch:32 step:30610 [D loss: 0.404898, acc.: 85.16%] [G loss: 1.329094]\n",
      "epoch:32 step:30611 [D loss: 0.408220, acc.: 79.69%] [G loss: 2.005575]\n",
      "epoch:32 step:30612 [D loss: 0.568253, acc.: 74.22%] [G loss: 1.015671]\n",
      "epoch:32 step:30613 [D loss: 0.449469, acc.: 77.34%] [G loss: 1.591725]\n",
      "epoch:32 step:30614 [D loss: 0.479356, acc.: 79.69%] [G loss: 1.527998]\n",
      "epoch:32 step:30615 [D loss: 0.605136, acc.: 64.84%] [G loss: 2.029334]\n",
      "epoch:32 step:30616 [D loss: 0.617807, acc.: 64.06%] [G loss: 1.558951]\n",
      "epoch:32 step:30617 [D loss: 0.369229, acc.: 87.50%] [G loss: 2.018013]\n",
      "epoch:32 step:30618 [D loss: 0.431220, acc.: 80.47%] [G loss: 1.567987]\n",
      "epoch:32 step:30619 [D loss: 0.491933, acc.: 71.88%] [G loss: 1.514616]\n",
      "epoch:32 step:30620 [D loss: 0.565188, acc.: 71.88%] [G loss: 0.945044]\n",
      "epoch:32 step:30621 [D loss: 0.571713, acc.: 70.31%] [G loss: 1.339833]\n",
      "epoch:32 step:30622 [D loss: 0.460213, acc.: 78.91%] [G loss: 1.731444]\n",
      "epoch:32 step:30623 [D loss: 0.656338, acc.: 61.72%] [G loss: 1.077296]\n",
      "epoch:32 step:30624 [D loss: 0.451565, acc.: 79.69%] [G loss: 1.081220]\n",
      "epoch:32 step:30625 [D loss: 0.608282, acc.: 66.41%] [G loss: 1.466982]\n",
      "epoch:32 step:30626 [D loss: 0.540677, acc.: 71.09%] [G loss: 1.408965]\n",
      "epoch:32 step:30627 [D loss: 0.544368, acc.: 75.78%] [G loss: 1.435143]\n",
      "epoch:32 step:30628 [D loss: 0.509351, acc.: 73.44%] [G loss: 1.737408]\n",
      "epoch:32 step:30629 [D loss: 0.483201, acc.: 78.91%] [G loss: 1.846711]\n",
      "epoch:32 step:30630 [D loss: 0.561667, acc.: 73.44%] [G loss: 1.667994]\n",
      "epoch:32 step:30631 [D loss: 0.424043, acc.: 83.59%] [G loss: 1.534425]\n",
      "epoch:32 step:30632 [D loss: 0.340609, acc.: 89.06%] [G loss: 1.313783]\n",
      "epoch:32 step:30633 [D loss: 0.581364, acc.: 72.66%] [G loss: 1.712637]\n",
      "epoch:32 step:30634 [D loss: 0.577861, acc.: 71.88%] [G loss: 1.186307]\n",
      "epoch:32 step:30635 [D loss: 0.501763, acc.: 77.34%] [G loss: 1.572693]\n",
      "epoch:32 step:30636 [D loss: 0.422966, acc.: 86.72%] [G loss: 1.436717]\n",
      "epoch:32 step:30637 [D loss: 0.586540, acc.: 67.19%] [G loss: 1.392744]\n",
      "epoch:32 step:30638 [D loss: 0.533036, acc.: 75.78%] [G loss: 1.255338]\n",
      "epoch:32 step:30639 [D loss: 0.393421, acc.: 82.81%] [G loss: 1.132585]\n",
      "epoch:32 step:30640 [D loss: 0.600853, acc.: 64.84%] [G loss: 1.116651]\n",
      "epoch:32 step:30641 [D loss: 0.443979, acc.: 78.91%] [G loss: 1.691261]\n",
      "epoch:32 step:30642 [D loss: 0.741146, acc.: 56.25%] [G loss: 1.785991]\n",
      "epoch:32 step:30643 [D loss: 0.513600, acc.: 73.44%] [G loss: 1.590724]\n",
      "epoch:32 step:30644 [D loss: 0.693595, acc.: 62.50%] [G loss: 1.426930]\n",
      "epoch:32 step:30645 [D loss: 0.530114, acc.: 75.78%] [G loss: 1.565168]\n",
      "epoch:32 step:30646 [D loss: 0.437163, acc.: 83.59%] [G loss: 1.975171]\n",
      "epoch:32 step:30647 [D loss: 0.640806, acc.: 64.84%] [G loss: 1.025090]\n",
      "epoch:32 step:30648 [D loss: 0.593503, acc.: 70.31%] [G loss: 0.847108]\n",
      "epoch:32 step:30649 [D loss: 0.457422, acc.: 78.12%] [G loss: 1.609914]\n",
      "epoch:32 step:30650 [D loss: 0.267209, acc.: 92.97%] [G loss: 1.619358]\n",
      "epoch:32 step:30651 [D loss: 0.560154, acc.: 74.22%] [G loss: 1.370954]\n",
      "epoch:32 step:30652 [D loss: 0.678966, acc.: 62.50%] [G loss: 1.374822]\n",
      "epoch:32 step:30653 [D loss: 0.366633, acc.: 87.50%] [G loss: 1.825116]\n",
      "epoch:32 step:30654 [D loss: 0.446415, acc.: 78.12%] [G loss: 1.531906]\n",
      "epoch:32 step:30655 [D loss: 0.579668, acc.: 73.44%] [G loss: 1.349261]\n",
      "epoch:32 step:30656 [D loss: 0.500356, acc.: 75.78%] [G loss: 1.681118]\n",
      "epoch:32 step:30657 [D loss: 0.683942, acc.: 60.94%] [G loss: 1.405830]\n",
      "epoch:32 step:30658 [D loss: 0.611536, acc.: 62.50%] [G loss: 1.649100]\n",
      "epoch:32 step:30659 [D loss: 0.631208, acc.: 67.19%] [G loss: 1.156487]\n",
      "epoch:32 step:30660 [D loss: 0.491907, acc.: 76.56%] [G loss: 1.729797]\n",
      "epoch:32 step:30661 [D loss: 0.509494, acc.: 76.56%] [G loss: 1.716716]\n",
      "epoch:32 step:30662 [D loss: 0.492028, acc.: 77.34%] [G loss: 1.397666]\n",
      "epoch:32 step:30663 [D loss: 0.377234, acc.: 83.59%] [G loss: 1.751865]\n",
      "epoch:32 step:30664 [D loss: 0.457269, acc.: 78.91%] [G loss: 1.392419]\n",
      "epoch:32 step:30665 [D loss: 0.494634, acc.: 76.56%] [G loss: 1.395286]\n",
      "epoch:32 step:30666 [D loss: 0.510349, acc.: 75.78%] [G loss: 1.677998]\n",
      "epoch:32 step:30667 [D loss: 0.734147, acc.: 53.91%] [G loss: 1.374898]\n",
      "epoch:32 step:30668 [D loss: 0.441941, acc.: 80.47%] [G loss: 1.572121]\n",
      "epoch:32 step:30669 [D loss: 0.499621, acc.: 78.12%] [G loss: 1.340933]\n",
      "epoch:32 step:30670 [D loss: 0.747650, acc.: 57.81%] [G loss: 1.033722]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:32 step:30671 [D loss: 0.531942, acc.: 72.66%] [G loss: 1.668447]\n",
      "epoch:32 step:30672 [D loss: 0.473176, acc.: 81.25%] [G loss: 1.578836]\n",
      "epoch:32 step:30673 [D loss: 0.656227, acc.: 60.94%] [G loss: 1.689433]\n",
      "epoch:32 step:30674 [D loss: 0.400567, acc.: 81.25%] [G loss: 1.215220]\n",
      "epoch:32 step:30675 [D loss: 0.560633, acc.: 71.88%] [G loss: 0.945399]\n",
      "epoch:32 step:30676 [D loss: 0.548437, acc.: 71.09%] [G loss: 1.500488]\n",
      "epoch:32 step:30677 [D loss: 0.578644, acc.: 67.97%] [G loss: 1.229027]\n",
      "epoch:32 step:30678 [D loss: 0.672960, acc.: 63.28%] [G loss: 1.393886]\n",
      "epoch:32 step:30679 [D loss: 0.515989, acc.: 78.91%] [G loss: 2.274920]\n",
      "epoch:32 step:30680 [D loss: 0.531194, acc.: 71.09%] [G loss: 1.992130]\n",
      "epoch:32 step:30681 [D loss: 0.515793, acc.: 76.56%] [G loss: 1.696609]\n",
      "epoch:32 step:30682 [D loss: 0.580570, acc.: 67.97%] [G loss: 1.210225]\n",
      "epoch:32 step:30683 [D loss: 0.666351, acc.: 64.84%] [G loss: 0.914603]\n",
      "epoch:32 step:30684 [D loss: 0.364708, acc.: 87.50%] [G loss: 1.750682]\n",
      "epoch:32 step:30685 [D loss: 0.507739, acc.: 73.44%] [G loss: 1.404037]\n",
      "epoch:32 step:30686 [D loss: 0.395373, acc.: 83.59%] [G loss: 2.052301]\n",
      "epoch:32 step:30687 [D loss: 0.514071, acc.: 78.12%] [G loss: 1.449563]\n",
      "epoch:32 step:30688 [D loss: 0.588852, acc.: 75.78%] [G loss: 1.234526]\n",
      "epoch:32 step:30689 [D loss: 0.449921, acc.: 81.25%] [G loss: 1.421480]\n",
      "epoch:32 step:30690 [D loss: 0.555317, acc.: 68.75%] [G loss: 1.248620]\n",
      "epoch:32 step:30691 [D loss: 0.487205, acc.: 78.12%] [G loss: 1.488252]\n",
      "epoch:32 step:30692 [D loss: 0.518359, acc.: 71.88%] [G loss: 1.316082]\n",
      "epoch:32 step:30693 [D loss: 0.711143, acc.: 57.81%] [G loss: 1.882819]\n",
      "epoch:32 step:30694 [D loss: 0.446587, acc.: 78.12%] [G loss: 1.617189]\n",
      "epoch:32 step:30695 [D loss: 0.549173, acc.: 74.22%] [G loss: 1.196929]\n",
      "epoch:32 step:30696 [D loss: 0.513974, acc.: 75.00%] [G loss: 1.254633]\n",
      "epoch:32 step:30697 [D loss: 0.685940, acc.: 61.72%] [G loss: 1.277699]\n",
      "epoch:32 step:30698 [D loss: 0.715917, acc.: 62.50%] [G loss: 1.718504]\n",
      "epoch:32 step:30699 [D loss: 0.650032, acc.: 64.06%] [G loss: 1.989751]\n",
      "epoch:32 step:30700 [D loss: 0.737686, acc.: 57.03%] [G loss: 1.319809]\n",
      "epoch:32 step:30701 [D loss: 0.657906, acc.: 66.41%] [G loss: 1.024297]\n",
      "epoch:32 step:30702 [D loss: 0.556251, acc.: 73.44%] [G loss: 1.429488]\n",
      "epoch:32 step:30703 [D loss: 0.651639, acc.: 62.50%] [G loss: 1.875934]\n",
      "epoch:32 step:30704 [D loss: 0.722904, acc.: 60.16%] [G loss: 1.616490]\n",
      "epoch:32 step:30705 [D loss: 0.348545, acc.: 83.59%] [G loss: 1.753155]\n",
      "epoch:32 step:30706 [D loss: 0.518208, acc.: 72.66%] [G loss: 1.643762]\n",
      "epoch:32 step:30707 [D loss: 0.456730, acc.: 81.25%] [G loss: 1.658338]\n",
      "epoch:32 step:30708 [D loss: 0.395355, acc.: 82.03%] [G loss: 1.257505]\n",
      "epoch:32 step:30709 [D loss: 0.526018, acc.: 72.66%] [G loss: 1.880581]\n",
      "epoch:32 step:30710 [D loss: 0.626431, acc.: 60.94%] [G loss: 1.636267]\n",
      "epoch:32 step:30711 [D loss: 0.440955, acc.: 79.69%] [G loss: 1.237305]\n",
      "epoch:32 step:30712 [D loss: 0.626606, acc.: 61.72%] [G loss: 1.418263]\n",
      "epoch:32 step:30713 [D loss: 0.495609, acc.: 78.12%] [G loss: 1.434364]\n",
      "epoch:32 step:30714 [D loss: 0.553221, acc.: 74.22%] [G loss: 1.489953]\n",
      "epoch:32 step:30715 [D loss: 0.606531, acc.: 67.97%] [G loss: 1.329410]\n",
      "epoch:32 step:30716 [D loss: 0.473749, acc.: 78.91%] [G loss: 1.583911]\n",
      "epoch:32 step:30717 [D loss: 0.607714, acc.: 69.53%] [G loss: 1.042498]\n",
      "epoch:32 step:30718 [D loss: 0.513889, acc.: 73.44%] [G loss: 1.475733]\n",
      "epoch:32 step:30719 [D loss: 0.547513, acc.: 71.88%] [G loss: 1.578104]\n",
      "epoch:32 step:30720 [D loss: 0.499299, acc.: 78.12%] [G loss: 1.557955]\n",
      "epoch:32 step:30721 [D loss: 0.546210, acc.: 71.88%] [G loss: 1.519742]\n",
      "epoch:32 step:30722 [D loss: 0.709432, acc.: 59.38%] [G loss: 1.293236]\n",
      "epoch:32 step:30723 [D loss: 0.657698, acc.: 66.41%] [G loss: 1.295304]\n",
      "epoch:32 step:30724 [D loss: 0.483849, acc.: 78.12%] [G loss: 1.973492]\n",
      "epoch:32 step:30725 [D loss: 0.414326, acc.: 83.59%] [G loss: 1.864451]\n",
      "epoch:32 step:30726 [D loss: 0.380334, acc.: 88.28%] [G loss: 1.549236]\n",
      "epoch:32 step:30727 [D loss: 0.430563, acc.: 78.12%] [G loss: 1.735853]\n",
      "epoch:32 step:30728 [D loss: 0.354276, acc.: 88.28%] [G loss: 2.091957]\n",
      "epoch:32 step:30729 [D loss: 0.486939, acc.: 72.66%] [G loss: 1.304466]\n",
      "epoch:32 step:30730 [D loss: 0.461581, acc.: 78.91%] [G loss: 1.363025]\n",
      "epoch:32 step:30731 [D loss: 0.457711, acc.: 78.91%] [G loss: 1.480614]\n",
      "epoch:32 step:30732 [D loss: 0.571336, acc.: 69.53%] [G loss: 1.427584]\n",
      "epoch:32 step:30733 [D loss: 0.579157, acc.: 69.53%] [G loss: 1.575637]\n",
      "epoch:32 step:30734 [D loss: 0.441513, acc.: 78.12%] [G loss: 1.606745]\n",
      "epoch:32 step:30735 [D loss: 0.554974, acc.: 74.22%] [G loss: 1.481056]\n",
      "epoch:32 step:30736 [D loss: 0.470760, acc.: 72.66%] [G loss: 1.581711]\n",
      "epoch:32 step:30737 [D loss: 0.507808, acc.: 75.00%] [G loss: 1.320231]\n",
      "epoch:32 step:30738 [D loss: 0.687671, acc.: 64.06%] [G loss: 1.732995]\n",
      "epoch:32 step:30739 [D loss: 0.433051, acc.: 81.25%] [G loss: 1.472577]\n",
      "epoch:32 step:30740 [D loss: 0.717111, acc.: 54.69%] [G loss: 1.319312]\n",
      "epoch:32 step:30741 [D loss: 0.509993, acc.: 76.56%] [G loss: 1.027728]\n",
      "epoch:32 step:30742 [D loss: 0.661778, acc.: 62.50%] [G loss: 1.277850]\n",
      "epoch:32 step:30743 [D loss: 0.521855, acc.: 71.09%] [G loss: 1.300516]\n",
      "epoch:32 step:30744 [D loss: 0.512120, acc.: 73.44%] [G loss: 1.524203]\n",
      "epoch:32 step:30745 [D loss: 0.772304, acc.: 50.78%] [G loss: 1.232144]\n",
      "epoch:32 step:30746 [D loss: 0.691915, acc.: 57.81%] [G loss: 1.328981]\n",
      "epoch:32 step:30747 [D loss: 0.488725, acc.: 76.56%] [G loss: 1.195102]\n",
      "epoch:32 step:30748 [D loss: 0.454108, acc.: 81.25%] [G loss: 1.806694]\n",
      "epoch:32 step:30749 [D loss: 0.486655, acc.: 76.56%] [G loss: 1.423059]\n",
      "epoch:32 step:30750 [D loss: 0.600025, acc.: 67.19%] [G loss: 1.475347]\n",
      "epoch:32 step:30751 [D loss: 0.345879, acc.: 89.84%] [G loss: 1.969974]\n",
      "epoch:32 step:30752 [D loss: 0.642025, acc.: 63.28%] [G loss: 1.911398]\n",
      "epoch:32 step:30753 [D loss: 0.606763, acc.: 66.41%] [G loss: 1.812814]\n",
      "epoch:32 step:30754 [D loss: 0.456921, acc.: 79.69%] [G loss: 2.278413]\n",
      "epoch:32 step:30755 [D loss: 0.530760, acc.: 73.44%] [G loss: 1.435808]\n",
      "epoch:32 step:30756 [D loss: 0.422959, acc.: 80.47%] [G loss: 1.857569]\n",
      "epoch:32 step:30757 [D loss: 0.481905, acc.: 78.12%] [G loss: 1.266892]\n",
      "epoch:32 step:30758 [D loss: 0.507034, acc.: 75.00%] [G loss: 1.322990]\n",
      "epoch:32 step:30759 [D loss: 0.657072, acc.: 62.50%] [G loss: 1.325739]\n",
      "epoch:32 step:30760 [D loss: 0.412185, acc.: 86.72%] [G loss: 1.275264]\n",
      "epoch:32 step:30761 [D loss: 0.467335, acc.: 78.91%] [G loss: 1.186113]\n",
      "epoch:32 step:30762 [D loss: 0.514716, acc.: 73.44%] [G loss: 1.582185]\n",
      "epoch:32 step:30763 [D loss: 0.507591, acc.: 71.88%] [G loss: 1.350066]\n",
      "epoch:32 step:30764 [D loss: 0.574322, acc.: 75.00%] [G loss: 1.452271]\n",
      "epoch:32 step:30765 [D loss: 0.622361, acc.: 70.31%] [G loss: 1.398118]\n",
      "epoch:32 step:30766 [D loss: 0.374416, acc.: 85.94%] [G loss: 1.389476]\n",
      "epoch:32 step:30767 [D loss: 0.435215, acc.: 80.47%] [G loss: 1.466364]\n",
      "epoch:32 step:30768 [D loss: 0.585614, acc.: 67.19%] [G loss: 1.176954]\n",
      "epoch:32 step:30769 [D loss: 0.297852, acc.: 92.19%] [G loss: 1.695973]\n",
      "epoch:32 step:30770 [D loss: 0.729697, acc.: 63.28%] [G loss: 1.113882]\n",
      "epoch:32 step:30771 [D loss: 0.672993, acc.: 57.81%] [G loss: 1.447041]\n",
      "epoch:32 step:30772 [D loss: 0.724132, acc.: 60.16%] [G loss: 0.969044]\n",
      "epoch:32 step:30773 [D loss: 0.585059, acc.: 66.41%] [G loss: 1.614726]\n",
      "epoch:32 step:30774 [D loss: 0.582782, acc.: 69.53%] [G loss: 1.645411]\n",
      "epoch:32 step:30775 [D loss: 0.416964, acc.: 85.94%] [G loss: 1.279544]\n",
      "epoch:32 step:30776 [D loss: 0.452881, acc.: 78.12%] [G loss: 1.745976]\n",
      "epoch:32 step:30777 [D loss: 0.476328, acc.: 78.91%] [G loss: 1.468984]\n",
      "epoch:32 step:30778 [D loss: 0.596728, acc.: 68.75%] [G loss: 1.606458]\n",
      "epoch:32 step:30779 [D loss: 0.536236, acc.: 71.88%] [G loss: 1.194011]\n",
      "epoch:32 step:30780 [D loss: 0.574099, acc.: 67.97%] [G loss: 0.893165]\n",
      "epoch:32 step:30781 [D loss: 0.726566, acc.: 63.28%] [G loss: 1.271661]\n",
      "epoch:32 step:30782 [D loss: 0.382332, acc.: 85.94%] [G loss: 1.474875]\n",
      "epoch:32 step:30783 [D loss: 0.628031, acc.: 67.19%] [G loss: 1.410871]\n",
      "epoch:32 step:30784 [D loss: 0.573067, acc.: 69.53%] [G loss: 1.688784]\n",
      "epoch:32 step:30785 [D loss: 0.594790, acc.: 71.88%] [G loss: 1.283097]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:32 step:30786 [D loss: 0.535557, acc.: 74.22%] [G loss: 1.385376]\n",
      "epoch:32 step:30787 [D loss: 0.679184, acc.: 61.72%] [G loss: 1.118227]\n",
      "epoch:32 step:30788 [D loss: 0.413722, acc.: 87.50%] [G loss: 1.520095]\n",
      "epoch:32 step:30789 [D loss: 0.403083, acc.: 85.94%] [G loss: 1.629638]\n",
      "epoch:32 step:30790 [D loss: 0.341862, acc.: 85.16%] [G loss: 1.581113]\n",
      "epoch:32 step:30791 [D loss: 0.523892, acc.: 73.44%] [G loss: 1.696054]\n",
      "epoch:32 step:30792 [D loss: 0.483866, acc.: 75.00%] [G loss: 1.361030]\n",
      "epoch:32 step:30793 [D loss: 0.439054, acc.: 79.69%] [G loss: 0.950158]\n",
      "epoch:32 step:30794 [D loss: 0.362625, acc.: 87.50%] [G loss: 1.580750]\n",
      "epoch:32 step:30795 [D loss: 0.451288, acc.: 80.47%] [G loss: 1.500266]\n",
      "epoch:32 step:30796 [D loss: 0.374730, acc.: 84.38%] [G loss: 1.721230]\n",
      "epoch:32 step:30797 [D loss: 0.584841, acc.: 68.75%] [G loss: 1.389370]\n",
      "epoch:32 step:30798 [D loss: 0.476917, acc.: 79.69%] [G loss: 1.464399]\n",
      "epoch:32 step:30799 [D loss: 0.404558, acc.: 85.16%] [G loss: 2.234780]\n",
      "epoch:32 step:30800 [D loss: 0.447497, acc.: 81.25%] [G loss: 1.050617]\n",
      "epoch:32 step:30801 [D loss: 0.552273, acc.: 68.75%] [G loss: 1.420271]\n",
      "epoch:32 step:30802 [D loss: 0.566468, acc.: 71.88%] [G loss: 1.085326]\n",
      "epoch:32 step:30803 [D loss: 0.398497, acc.: 83.59%] [G loss: 1.383194]\n",
      "epoch:32 step:30804 [D loss: 0.894583, acc.: 44.53%] [G loss: 1.209307]\n",
      "epoch:32 step:30805 [D loss: 0.485276, acc.: 78.12%] [G loss: 1.902757]\n",
      "epoch:32 step:30806 [D loss: 0.465970, acc.: 78.91%] [G loss: 1.337904]\n",
      "epoch:32 step:30807 [D loss: 0.507247, acc.: 71.88%] [G loss: 1.131009]\n",
      "epoch:32 step:30808 [D loss: 0.672577, acc.: 58.59%] [G loss: 1.140629]\n",
      "epoch:32 step:30809 [D loss: 0.436947, acc.: 79.69%] [G loss: 1.340505]\n",
      "epoch:32 step:30810 [D loss: 0.532768, acc.: 77.34%] [G loss: 1.345656]\n",
      "epoch:32 step:30811 [D loss: 0.504690, acc.: 73.44%] [G loss: 1.374201]\n",
      "epoch:32 step:30812 [D loss: 0.663469, acc.: 59.38%] [G loss: 1.165416]\n",
      "epoch:32 step:30813 [D loss: 0.633595, acc.: 57.81%] [G loss: 1.319573]\n",
      "epoch:32 step:30814 [D loss: 0.507362, acc.: 72.66%] [G loss: 1.799453]\n",
      "epoch:32 step:30815 [D loss: 0.575707, acc.: 71.09%] [G loss: 1.357983]\n",
      "epoch:32 step:30816 [D loss: 0.506946, acc.: 74.22%] [G loss: 1.718232]\n",
      "epoch:32 step:30817 [D loss: 0.775660, acc.: 53.91%] [G loss: 1.220468]\n",
      "epoch:32 step:30818 [D loss: 0.640403, acc.: 65.62%] [G loss: 1.268889]\n",
      "epoch:32 step:30819 [D loss: 0.401380, acc.: 88.28%] [G loss: 1.725621]\n",
      "epoch:32 step:30820 [D loss: 0.585921, acc.: 70.31%] [G loss: 1.253784]\n",
      "epoch:32 step:30821 [D loss: 0.400773, acc.: 83.59%] [G loss: 1.545386]\n",
      "epoch:32 step:30822 [D loss: 0.507589, acc.: 78.12%] [G loss: 1.677121]\n",
      "epoch:32 step:30823 [D loss: 0.491519, acc.: 75.00%] [G loss: 2.055276]\n",
      "epoch:32 step:30824 [D loss: 0.429632, acc.: 79.69%] [G loss: 1.702962]\n",
      "epoch:32 step:30825 [D loss: 0.529685, acc.: 73.44%] [G loss: 1.879932]\n",
      "epoch:32 step:30826 [D loss: 0.535492, acc.: 73.44%] [G loss: 1.697774]\n",
      "epoch:32 step:30827 [D loss: 0.560954, acc.: 68.75%] [G loss: 1.554958]\n",
      "epoch:32 step:30828 [D loss: 0.618445, acc.: 64.84%] [G loss: 1.225540]\n",
      "epoch:32 step:30829 [D loss: 0.538179, acc.: 72.66%] [G loss: 1.562631]\n",
      "epoch:32 step:30830 [D loss: 0.518117, acc.: 72.66%] [G loss: 1.338038]\n",
      "epoch:32 step:30831 [D loss: 0.417627, acc.: 82.03%] [G loss: 1.556672]\n",
      "epoch:32 step:30832 [D loss: 0.729548, acc.: 57.03%] [G loss: 1.497790]\n",
      "epoch:32 step:30833 [D loss: 0.426019, acc.: 81.25%] [G loss: 1.718938]\n",
      "epoch:32 step:30834 [D loss: 0.378890, acc.: 85.16%] [G loss: 2.081723]\n",
      "epoch:32 step:30835 [D loss: 0.716729, acc.: 62.50%] [G loss: 1.323247]\n",
      "epoch:32 step:30836 [D loss: 0.340370, acc.: 89.84%] [G loss: 2.264744]\n",
      "epoch:32 step:30837 [D loss: 0.693121, acc.: 64.06%] [G loss: 1.090249]\n",
      "epoch:32 step:30838 [D loss: 0.490575, acc.: 74.22%] [G loss: 1.242867]\n",
      "epoch:32 step:30839 [D loss: 0.467667, acc.: 79.69%] [G loss: 1.870601]\n",
      "epoch:32 step:30840 [D loss: 0.395801, acc.: 82.81%] [G loss: 1.908901]\n",
      "epoch:32 step:30841 [D loss: 0.548391, acc.: 73.44%] [G loss: 1.664740]\n",
      "epoch:32 step:30842 [D loss: 0.398398, acc.: 80.47%] [G loss: 1.441590]\n",
      "epoch:32 step:30843 [D loss: 0.542234, acc.: 74.22%] [G loss: 1.755963]\n",
      "epoch:32 step:30844 [D loss: 0.574214, acc.: 67.97%] [G loss: 1.506711]\n",
      "epoch:32 step:30845 [D loss: 0.530951, acc.: 75.00%] [G loss: 1.181734]\n",
      "epoch:32 step:30846 [D loss: 0.566147, acc.: 71.09%] [G loss: 1.763603]\n",
      "epoch:32 step:30847 [D loss: 0.580285, acc.: 67.97%] [G loss: 1.298791]\n",
      "epoch:32 step:30848 [D loss: 0.731053, acc.: 57.03%] [G loss: 1.731959]\n",
      "epoch:32 step:30849 [D loss: 0.483204, acc.: 75.78%] [G loss: 1.495826]\n",
      "epoch:32 step:30850 [D loss: 0.353528, acc.: 89.84%] [G loss: 1.160612]\n",
      "epoch:32 step:30851 [D loss: 0.654091, acc.: 61.72%] [G loss: 1.497275]\n",
      "epoch:32 step:30852 [D loss: 0.507122, acc.: 77.34%] [G loss: 1.448748]\n",
      "epoch:32 step:30853 [D loss: 0.425449, acc.: 78.12%] [G loss: 1.802949]\n",
      "epoch:32 step:30854 [D loss: 0.549428, acc.: 68.75%] [G loss: 1.602206]\n",
      "epoch:32 step:30855 [D loss: 0.451697, acc.: 81.25%] [G loss: 1.665937]\n",
      "epoch:32 step:30856 [D loss: 0.426616, acc.: 78.12%] [G loss: 1.740007]\n",
      "epoch:32 step:30857 [D loss: 0.305481, acc.: 89.84%] [G loss: 1.540964]\n",
      "epoch:32 step:30858 [D loss: 0.469061, acc.: 80.47%] [G loss: 1.580665]\n",
      "epoch:32 step:30859 [D loss: 0.666331, acc.: 60.94%] [G loss: 1.698134]\n",
      "epoch:32 step:30860 [D loss: 0.584951, acc.: 71.09%] [G loss: 1.219337]\n",
      "epoch:32 step:30861 [D loss: 0.508424, acc.: 69.53%] [G loss: 0.852282]\n",
      "epoch:32 step:30862 [D loss: 0.436372, acc.: 85.16%] [G loss: 1.655051]\n",
      "epoch:32 step:30863 [D loss: 0.561728, acc.: 68.75%] [G loss: 1.387435]\n",
      "epoch:32 step:30864 [D loss: 0.405439, acc.: 85.16%] [G loss: 1.317922]\n",
      "epoch:32 step:30865 [D loss: 0.621869, acc.: 64.06%] [G loss: 1.500311]\n",
      "epoch:32 step:30866 [D loss: 0.349181, acc.: 83.59%] [G loss: 1.354278]\n",
      "epoch:32 step:30867 [D loss: 0.640433, acc.: 67.19%] [G loss: 1.227488]\n",
      "epoch:32 step:30868 [D loss: 0.427691, acc.: 79.69%] [G loss: 1.253361]\n",
      "epoch:32 step:30869 [D loss: 0.478526, acc.: 75.00%] [G loss: 1.443875]\n",
      "epoch:32 step:30870 [D loss: 0.515143, acc.: 74.22%] [G loss: 1.606570]\n",
      "epoch:32 step:30871 [D loss: 0.953188, acc.: 43.75%] [G loss: 1.528925]\n",
      "epoch:32 step:30872 [D loss: 0.501672, acc.: 75.78%] [G loss: 1.589348]\n",
      "epoch:32 step:30873 [D loss: 0.582818, acc.: 70.31%] [G loss: 1.500539]\n",
      "epoch:32 step:30874 [D loss: 0.477178, acc.: 77.34%] [G loss: 1.310893]\n",
      "epoch:32 step:30875 [D loss: 0.675034, acc.: 58.59%] [G loss: 1.295992]\n",
      "epoch:32 step:30876 [D loss: 0.750404, acc.: 54.69%] [G loss: 1.338805]\n",
      "epoch:32 step:30877 [D loss: 0.620366, acc.: 68.75%] [G loss: 1.222990]\n",
      "epoch:32 step:30878 [D loss: 0.577232, acc.: 67.97%] [G loss: 1.293278]\n",
      "epoch:32 step:30879 [D loss: 0.398501, acc.: 84.38%] [G loss: 1.348871]\n",
      "epoch:32 step:30880 [D loss: 0.517333, acc.: 71.88%] [G loss: 1.463993]\n",
      "epoch:32 step:30881 [D loss: 0.512946, acc.: 77.34%] [G loss: 1.227833]\n",
      "epoch:32 step:30882 [D loss: 0.380498, acc.: 86.72%] [G loss: 2.011179]\n",
      "epoch:32 step:30883 [D loss: 0.579481, acc.: 73.44%] [G loss: 1.625065]\n",
      "epoch:32 step:30884 [D loss: 0.438527, acc.: 82.81%] [G loss: 1.119160]\n",
      "epoch:32 step:30885 [D loss: 0.406447, acc.: 83.59%] [G loss: 1.620906]\n",
      "epoch:32 step:30886 [D loss: 0.648303, acc.: 65.62%] [G loss: 1.422391]\n",
      "epoch:32 step:30887 [D loss: 0.392438, acc.: 83.59%] [G loss: 2.310751]\n",
      "epoch:32 step:30888 [D loss: 0.710034, acc.: 60.94%] [G loss: 1.670011]\n",
      "epoch:32 step:30889 [D loss: 0.661095, acc.: 69.53%] [G loss: 1.342483]\n",
      "epoch:32 step:30890 [D loss: 0.440053, acc.: 78.12%] [G loss: 1.515531]\n",
      "epoch:32 step:30891 [D loss: 0.560574, acc.: 69.53%] [G loss: 1.578943]\n",
      "epoch:32 step:30892 [D loss: 0.586210, acc.: 67.97%] [G loss: 1.456584]\n",
      "epoch:32 step:30893 [D loss: 0.567764, acc.: 72.66%] [G loss: 1.301762]\n",
      "epoch:32 step:30894 [D loss: 0.538142, acc.: 71.88%] [G loss: 1.540783]\n",
      "epoch:32 step:30895 [D loss: 0.619301, acc.: 67.19%] [G loss: 1.503305]\n",
      "epoch:32 step:30896 [D loss: 0.741803, acc.: 60.16%] [G loss: 1.651977]\n",
      "epoch:32 step:30897 [D loss: 0.612672, acc.: 64.84%] [G loss: 1.176973]\n",
      "epoch:32 step:30898 [D loss: 0.507001, acc.: 75.78%] [G loss: 1.716797]\n",
      "epoch:32 step:30899 [D loss: 0.346205, acc.: 92.19%] [G loss: 1.328038]\n",
      "epoch:32 step:30900 [D loss: 0.548041, acc.: 68.75%] [G loss: 1.923638]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:32 step:30901 [D loss: 0.496327, acc.: 75.78%] [G loss: 1.552694]\n",
      "epoch:32 step:30902 [D loss: 0.584524, acc.: 71.88%] [G loss: 1.828981]\n",
      "epoch:32 step:30903 [D loss: 0.379517, acc.: 86.72%] [G loss: 2.033760]\n",
      "epoch:32 step:30904 [D loss: 0.607684, acc.: 67.97%] [G loss: 1.446882]\n",
      "epoch:32 step:30905 [D loss: 0.491864, acc.: 78.12%] [G loss: 1.684929]\n",
      "epoch:32 step:30906 [D loss: 0.615046, acc.: 63.28%] [G loss: 1.335254]\n",
      "epoch:32 step:30907 [D loss: 0.371105, acc.: 83.59%] [G loss: 1.354366]\n",
      "epoch:32 step:30908 [D loss: 0.470143, acc.: 78.12%] [G loss: 1.624648]\n",
      "epoch:32 step:30909 [D loss: 0.720566, acc.: 60.16%] [G loss: 0.997890]\n",
      "epoch:32 step:30910 [D loss: 0.441947, acc.: 79.69%] [G loss: 1.361418]\n",
      "epoch:32 step:30911 [D loss: 0.739564, acc.: 56.25%] [G loss: 0.823997]\n",
      "epoch:32 step:30912 [D loss: 0.417967, acc.: 81.25%] [G loss: 1.336567]\n",
      "epoch:32 step:30913 [D loss: 0.424444, acc.: 83.59%] [G loss: 1.075318]\n",
      "epoch:32 step:30914 [D loss: 0.440925, acc.: 82.03%] [G loss: 1.875929]\n",
      "epoch:32 step:30915 [D loss: 0.625032, acc.: 60.94%] [G loss: 1.459680]\n",
      "epoch:32 step:30916 [D loss: 0.606302, acc.: 67.19%] [G loss: 1.678934]\n",
      "epoch:32 step:30917 [D loss: 0.504705, acc.: 79.69%] [G loss: 1.306982]\n",
      "epoch:32 step:30918 [D loss: 0.742404, acc.: 55.47%] [G loss: 1.885272]\n",
      "epoch:32 step:30919 [D loss: 0.470489, acc.: 81.25%] [G loss: 1.743741]\n",
      "epoch:32 step:30920 [D loss: 0.649086, acc.: 62.50%] [G loss: 1.326262]\n",
      "epoch:32 step:30921 [D loss: 0.463439, acc.: 82.03%] [G loss: 1.740654]\n",
      "epoch:33 step:30922 [D loss: 0.610628, acc.: 65.62%] [G loss: 1.024367]\n",
      "epoch:33 step:30923 [D loss: 0.430441, acc.: 82.81%] [G loss: 1.561982]\n",
      "epoch:33 step:30924 [D loss: 0.563616, acc.: 71.09%] [G loss: 1.448418]\n",
      "epoch:33 step:30925 [D loss: 0.634896, acc.: 63.28%] [G loss: 1.277073]\n",
      "epoch:33 step:30926 [D loss: 0.735005, acc.: 57.03%] [G loss: 1.719836]\n",
      "epoch:33 step:30927 [D loss: 0.771521, acc.: 51.56%] [G loss: 1.744657]\n",
      "epoch:33 step:30928 [D loss: 0.486349, acc.: 75.00%] [G loss: 1.399882]\n",
      "epoch:33 step:30929 [D loss: 0.323588, acc.: 91.41%] [G loss: 1.649124]\n",
      "epoch:33 step:30930 [D loss: 0.699030, acc.: 60.16%] [G loss: 1.648501]\n",
      "epoch:33 step:30931 [D loss: 0.608468, acc.: 64.06%] [G loss: 1.272538]\n",
      "epoch:33 step:30932 [D loss: 0.423467, acc.: 80.47%] [G loss: 1.389404]\n",
      "epoch:33 step:30933 [D loss: 0.498481, acc.: 71.88%] [G loss: 1.531552]\n",
      "epoch:33 step:30934 [D loss: 0.570955, acc.: 64.06%] [G loss: 1.322722]\n",
      "epoch:33 step:30935 [D loss: 0.639676, acc.: 68.75%] [G loss: 1.202603]\n",
      "epoch:33 step:30936 [D loss: 0.379250, acc.: 85.16%] [G loss: 1.335883]\n",
      "epoch:33 step:30937 [D loss: 0.572710, acc.: 74.22%] [G loss: 1.697379]\n",
      "epoch:33 step:30938 [D loss: 0.598912, acc.: 69.53%] [G loss: 1.471573]\n",
      "epoch:33 step:30939 [D loss: 0.670111, acc.: 60.94%] [G loss: 1.239498]\n",
      "epoch:33 step:30940 [D loss: 0.589300, acc.: 68.75%] [G loss: 1.587810]\n",
      "epoch:33 step:30941 [D loss: 0.529673, acc.: 76.56%] [G loss: 1.376830]\n",
      "epoch:33 step:30942 [D loss: 0.683230, acc.: 60.94%] [G loss: 1.542742]\n",
      "epoch:33 step:30943 [D loss: 0.638823, acc.: 64.84%] [G loss: 1.747807]\n",
      "epoch:33 step:30944 [D loss: 0.577060, acc.: 71.09%] [G loss: 2.002148]\n",
      "epoch:33 step:30945 [D loss: 0.458518, acc.: 79.69%] [G loss: 1.834871]\n",
      "epoch:33 step:30946 [D loss: 0.540255, acc.: 71.09%] [G loss: 1.636478]\n",
      "epoch:33 step:30947 [D loss: 0.572425, acc.: 71.88%] [G loss: 1.615356]\n",
      "epoch:33 step:30948 [D loss: 0.449674, acc.: 80.47%] [G loss: 1.065071]\n",
      "epoch:33 step:30949 [D loss: 0.325227, acc.: 89.84%] [G loss: 1.669104]\n",
      "epoch:33 step:30950 [D loss: 0.640125, acc.: 59.38%] [G loss: 1.084179]\n",
      "epoch:33 step:30951 [D loss: 0.473581, acc.: 82.03%] [G loss: 1.715055]\n",
      "epoch:33 step:30952 [D loss: 0.521957, acc.: 77.34%] [G loss: 1.436275]\n",
      "epoch:33 step:30953 [D loss: 0.423020, acc.: 80.47%] [G loss: 1.174806]\n",
      "epoch:33 step:30954 [D loss: 0.551025, acc.: 72.66%] [G loss: 1.466659]\n",
      "epoch:33 step:30955 [D loss: 0.371854, acc.: 82.03%] [G loss: 1.469852]\n",
      "epoch:33 step:30956 [D loss: 0.549860, acc.: 69.53%] [G loss: 1.168770]\n",
      "epoch:33 step:30957 [D loss: 0.479997, acc.: 76.56%] [G loss: 1.828301]\n",
      "epoch:33 step:30958 [D loss: 0.592014, acc.: 67.97%] [G loss: 1.575838]\n",
      "epoch:33 step:30959 [D loss: 0.601597, acc.: 79.69%] [G loss: 2.021532]\n",
      "epoch:33 step:30960 [D loss: 0.525376, acc.: 69.53%] [G loss: 1.939253]\n",
      "epoch:33 step:30961 [D loss: 0.469656, acc.: 79.69%] [G loss: 1.253357]\n",
      "epoch:33 step:30962 [D loss: 0.319748, acc.: 88.28%] [G loss: 1.565654]\n",
      "epoch:33 step:30963 [D loss: 0.482600, acc.: 75.00%] [G loss: 1.219869]\n",
      "epoch:33 step:30964 [D loss: 0.508495, acc.: 75.78%] [G loss: 1.248816]\n",
      "epoch:33 step:30965 [D loss: 0.609699, acc.: 70.31%] [G loss: 1.749871]\n",
      "epoch:33 step:30966 [D loss: 0.360615, acc.: 82.81%] [G loss: 1.709526]\n",
      "epoch:33 step:30967 [D loss: 0.728050, acc.: 56.25%] [G loss: 1.724088]\n",
      "epoch:33 step:30968 [D loss: 0.604852, acc.: 68.75%] [G loss: 1.296313]\n",
      "epoch:33 step:30969 [D loss: 0.378004, acc.: 83.59%] [G loss: 2.115062]\n",
      "epoch:33 step:30970 [D loss: 0.413386, acc.: 87.50%] [G loss: 1.212849]\n",
      "epoch:33 step:30971 [D loss: 0.347165, acc.: 90.62%] [G loss: 1.605983]\n",
      "epoch:33 step:30972 [D loss: 0.494739, acc.: 77.34%] [G loss: 1.652912]\n",
      "epoch:33 step:30973 [D loss: 0.607879, acc.: 67.19%] [G loss: 1.906394]\n",
      "epoch:33 step:30974 [D loss: 0.421208, acc.: 84.38%] [G loss: 1.782902]\n",
      "epoch:33 step:30975 [D loss: 0.832141, acc.: 47.66%] [G loss: 1.117442]\n",
      "epoch:33 step:30976 [D loss: 0.503698, acc.: 73.44%] [G loss: 2.197749]\n",
      "epoch:33 step:30977 [D loss: 0.522141, acc.: 72.66%] [G loss: 1.316256]\n",
      "epoch:33 step:30978 [D loss: 0.462804, acc.: 78.91%] [G loss: 1.449767]\n",
      "epoch:33 step:30979 [D loss: 0.540529, acc.: 72.66%] [G loss: 1.828781]\n",
      "epoch:33 step:30980 [D loss: 0.478269, acc.: 78.12%] [G loss: 1.766281]\n",
      "epoch:33 step:30981 [D loss: 0.564506, acc.: 70.31%] [G loss: 1.378892]\n",
      "epoch:33 step:30982 [D loss: 0.605876, acc.: 71.09%] [G loss: 1.537970]\n",
      "epoch:33 step:30983 [D loss: 0.647076, acc.: 62.50%] [G loss: 1.171776]\n",
      "epoch:33 step:30984 [D loss: 0.736487, acc.: 57.81%] [G loss: 1.223918]\n",
      "epoch:33 step:30985 [D loss: 0.679340, acc.: 63.28%] [G loss: 1.252837]\n",
      "epoch:33 step:30986 [D loss: 0.724122, acc.: 60.94%] [G loss: 1.364020]\n",
      "epoch:33 step:30987 [D loss: 0.588836, acc.: 70.31%] [G loss: 1.490080]\n",
      "epoch:33 step:30988 [D loss: 0.449913, acc.: 82.03%] [G loss: 1.502867]\n",
      "epoch:33 step:30989 [D loss: 0.500664, acc.: 73.44%] [G loss: 1.177547]\n",
      "epoch:33 step:30990 [D loss: 0.617588, acc.: 70.31%] [G loss: 1.327653]\n",
      "epoch:33 step:30991 [D loss: 0.634220, acc.: 67.97%] [G loss: 1.722607]\n",
      "epoch:33 step:30992 [D loss: 0.544210, acc.: 71.88%] [G loss: 1.275185]\n",
      "epoch:33 step:30993 [D loss: 0.405878, acc.: 87.50%] [G loss: 1.849247]\n",
      "epoch:33 step:30994 [D loss: 0.385077, acc.: 82.03%] [G loss: 1.495393]\n",
      "epoch:33 step:30995 [D loss: 0.362811, acc.: 86.72%] [G loss: 1.820433]\n",
      "epoch:33 step:30996 [D loss: 0.490148, acc.: 78.91%] [G loss: 1.255859]\n",
      "epoch:33 step:30997 [D loss: 0.519426, acc.: 73.44%] [G loss: 1.429546]\n",
      "epoch:33 step:30998 [D loss: 0.489549, acc.: 75.78%] [G loss: 1.545452]\n",
      "epoch:33 step:30999 [D loss: 0.629363, acc.: 65.62%] [G loss: 0.974787]\n",
      "epoch:33 step:31000 [D loss: 0.590160, acc.: 68.75%] [G loss: 1.136322]\n",
      "epoch:33 step:31001 [D loss: 0.503340, acc.: 75.78%] [G loss: 1.288971]\n",
      "epoch:33 step:31002 [D loss: 0.489513, acc.: 77.34%] [G loss: 1.381865]\n",
      "epoch:33 step:31003 [D loss: 0.559554, acc.: 71.09%] [G loss: 1.022622]\n",
      "epoch:33 step:31004 [D loss: 0.494698, acc.: 74.22%] [G loss: 1.210118]\n",
      "epoch:33 step:31005 [D loss: 0.728114, acc.: 53.91%] [G loss: 1.361063]\n",
      "epoch:33 step:31006 [D loss: 0.592921, acc.: 68.75%] [G loss: 1.238875]\n",
      "epoch:33 step:31007 [D loss: 0.614905, acc.: 65.62%] [G loss: 1.379397]\n",
      "epoch:33 step:31008 [D loss: 0.462041, acc.: 79.69%] [G loss: 1.233180]\n",
      "epoch:33 step:31009 [D loss: 0.414236, acc.: 82.81%] [G loss: 1.187276]\n",
      "epoch:33 step:31010 [D loss: 0.542168, acc.: 69.53%] [G loss: 1.242153]\n",
      "epoch:33 step:31011 [D loss: 0.673172, acc.: 64.06%] [G loss: 1.196404]\n",
      "epoch:33 step:31012 [D loss: 0.471392, acc.: 78.12%] [G loss: 1.777608]\n",
      "epoch:33 step:31013 [D loss: 0.431455, acc.: 80.47%] [G loss: 1.693452]\n",
      "epoch:33 step:31014 [D loss: 0.582213, acc.: 70.31%] [G loss: 1.326134]\n",
      "epoch:33 step:31015 [D loss: 0.648444, acc.: 70.31%] [G loss: 1.209371]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:33 step:31016 [D loss: 0.556093, acc.: 71.88%] [G loss: 1.569023]\n",
      "epoch:33 step:31017 [D loss: 0.653966, acc.: 64.84%] [G loss: 1.322318]\n",
      "epoch:33 step:31018 [D loss: 0.547511, acc.: 75.00%] [G loss: 1.594825]\n",
      "epoch:33 step:31019 [D loss: 0.434618, acc.: 80.47%] [G loss: 1.369897]\n",
      "epoch:33 step:31020 [D loss: 0.575856, acc.: 67.97%] [G loss: 1.383043]\n",
      "epoch:33 step:31021 [D loss: 0.534483, acc.: 71.09%] [G loss: 1.222745]\n",
      "epoch:33 step:31022 [D loss: 0.343644, acc.: 89.06%] [G loss: 1.347501]\n",
      "epoch:33 step:31023 [D loss: 0.607966, acc.: 64.06%] [G loss: 1.214478]\n",
      "epoch:33 step:31024 [D loss: 0.473780, acc.: 76.56%] [G loss: 2.013933]\n",
      "epoch:33 step:31025 [D loss: 0.418440, acc.: 83.59%] [G loss: 1.537243]\n",
      "epoch:33 step:31026 [D loss: 0.477003, acc.: 75.00%] [G loss: 1.811716]\n",
      "epoch:33 step:31027 [D loss: 0.560367, acc.: 67.97%] [G loss: 1.567628]\n",
      "epoch:33 step:31028 [D loss: 0.633528, acc.: 64.84%] [G loss: 1.524463]\n",
      "epoch:33 step:31029 [D loss: 0.398819, acc.: 82.81%] [G loss: 1.390681]\n",
      "epoch:33 step:31030 [D loss: 0.709275, acc.: 62.50%] [G loss: 1.155253]\n",
      "epoch:33 step:31031 [D loss: 0.566954, acc.: 68.75%] [G loss: 1.392494]\n",
      "epoch:33 step:31032 [D loss: 0.667813, acc.: 62.50%] [G loss: 1.762182]\n",
      "epoch:33 step:31033 [D loss: 0.392070, acc.: 83.59%] [G loss: 2.006187]\n",
      "epoch:33 step:31034 [D loss: 0.491712, acc.: 77.34%] [G loss: 1.457728]\n",
      "epoch:33 step:31035 [D loss: 0.363251, acc.: 85.94%] [G loss: 1.656043]\n",
      "epoch:33 step:31036 [D loss: 0.661473, acc.: 64.84%] [G loss: 1.332653]\n",
      "epoch:33 step:31037 [D loss: 0.578022, acc.: 73.44%] [G loss: 1.708708]\n",
      "epoch:33 step:31038 [D loss: 0.495224, acc.: 77.34%] [G loss: 1.346462]\n",
      "epoch:33 step:31039 [D loss: 0.785546, acc.: 56.25%] [G loss: 1.129222]\n",
      "epoch:33 step:31040 [D loss: 0.516168, acc.: 75.00%] [G loss: 1.543674]\n",
      "epoch:33 step:31041 [D loss: 0.761976, acc.: 50.78%] [G loss: 1.379271]\n",
      "epoch:33 step:31042 [D loss: 0.428947, acc.: 78.91%] [G loss: 1.572927]\n",
      "epoch:33 step:31043 [D loss: 0.549261, acc.: 71.88%] [G loss: 1.562696]\n",
      "epoch:33 step:31044 [D loss: 0.337461, acc.: 87.50%] [G loss: 1.410122]\n",
      "epoch:33 step:31045 [D loss: 0.569544, acc.: 71.88%] [G loss: 1.453984]\n",
      "epoch:33 step:31046 [D loss: 0.326817, acc.: 91.41%] [G loss: 1.771411]\n",
      "epoch:33 step:31047 [D loss: 0.637389, acc.: 60.16%] [G loss: 1.538142]\n",
      "epoch:33 step:31048 [D loss: 0.583670, acc.: 69.53%] [G loss: 1.340265]\n",
      "epoch:33 step:31049 [D loss: 0.479482, acc.: 76.56%] [G loss: 1.353438]\n",
      "epoch:33 step:31050 [D loss: 0.505970, acc.: 76.56%] [G loss: 2.017772]\n",
      "epoch:33 step:31051 [D loss: 0.431765, acc.: 82.81%] [G loss: 1.609769]\n",
      "epoch:33 step:31052 [D loss: 0.443394, acc.: 82.03%] [G loss: 1.666191]\n",
      "epoch:33 step:31053 [D loss: 0.336640, acc.: 93.75%] [G loss: 1.201758]\n",
      "epoch:33 step:31054 [D loss: 0.577066, acc.: 74.22%] [G loss: 1.200249]\n",
      "epoch:33 step:31055 [D loss: 0.766780, acc.: 57.81%] [G loss: 1.511053]\n",
      "epoch:33 step:31056 [D loss: 0.406095, acc.: 82.03%] [G loss: 1.454213]\n",
      "epoch:33 step:31057 [D loss: 0.969718, acc.: 43.75%] [G loss: 1.217972]\n",
      "epoch:33 step:31058 [D loss: 0.449557, acc.: 82.81%] [G loss: 1.157774]\n",
      "epoch:33 step:31059 [D loss: 0.708128, acc.: 57.03%] [G loss: 1.223162]\n",
      "epoch:33 step:31060 [D loss: 0.630480, acc.: 65.62%] [G loss: 1.304260]\n",
      "epoch:33 step:31061 [D loss: 0.439951, acc.: 81.25%] [G loss: 1.574622]\n",
      "epoch:33 step:31062 [D loss: 0.603515, acc.: 64.84%] [G loss: 1.836576]\n",
      "epoch:33 step:31063 [D loss: 0.416439, acc.: 79.69%] [G loss: 1.418890]\n",
      "epoch:33 step:31064 [D loss: 0.490155, acc.: 74.22%] [G loss: 1.515935]\n",
      "epoch:33 step:31065 [D loss: 0.538077, acc.: 71.09%] [G loss: 1.724912]\n",
      "epoch:33 step:31066 [D loss: 0.523097, acc.: 71.88%] [G loss: 1.830423]\n",
      "epoch:33 step:31067 [D loss: 0.370962, acc.: 86.72%] [G loss: 1.935326]\n",
      "epoch:33 step:31068 [D loss: 0.415018, acc.: 82.81%] [G loss: 2.153847]\n",
      "epoch:33 step:31069 [D loss: 0.560973, acc.: 73.44%] [G loss: 1.638287]\n",
      "epoch:33 step:31070 [D loss: 0.695279, acc.: 61.72%] [G loss: 1.523916]\n",
      "epoch:33 step:31071 [D loss: 0.529636, acc.: 71.09%] [G loss: 1.707319]\n",
      "epoch:33 step:31072 [D loss: 0.499834, acc.: 71.88%] [G loss: 1.165288]\n",
      "epoch:33 step:31073 [D loss: 0.529244, acc.: 71.88%] [G loss: 1.435148]\n",
      "epoch:33 step:31074 [D loss: 0.432269, acc.: 78.91%] [G loss: 1.037184]\n",
      "epoch:33 step:31075 [D loss: 0.413922, acc.: 82.81%] [G loss: 1.255988]\n",
      "epoch:33 step:31076 [D loss: 0.485780, acc.: 80.47%] [G loss: 1.080923]\n",
      "epoch:33 step:31077 [D loss: 0.457526, acc.: 82.03%] [G loss: 1.324654]\n",
      "epoch:33 step:31078 [D loss: 0.762119, acc.: 60.16%] [G loss: 1.378232]\n",
      "epoch:33 step:31079 [D loss: 0.661277, acc.: 63.28%] [G loss: 1.583153]\n",
      "epoch:33 step:31080 [D loss: 0.495903, acc.: 78.91%] [G loss: 1.395176]\n",
      "epoch:33 step:31081 [D loss: 0.416211, acc.: 82.03%] [G loss: 1.987307]\n",
      "epoch:33 step:31082 [D loss: 0.459868, acc.: 78.12%] [G loss: 1.295105]\n",
      "epoch:33 step:31083 [D loss: 0.661094, acc.: 64.84%] [G loss: 1.606687]\n",
      "epoch:33 step:31084 [D loss: 0.644376, acc.: 62.50%] [G loss: 1.222501]\n",
      "epoch:33 step:31085 [D loss: 0.564205, acc.: 70.31%] [G loss: 1.025358]\n",
      "epoch:33 step:31086 [D loss: 0.621512, acc.: 66.41%] [G loss: 1.165585]\n",
      "epoch:33 step:31087 [D loss: 0.498672, acc.: 75.78%] [G loss: 1.085461]\n",
      "epoch:33 step:31088 [D loss: 0.391710, acc.: 82.03%] [G loss: 1.558411]\n",
      "epoch:33 step:31089 [D loss: 0.816194, acc.: 53.12%] [G loss: 1.468117]\n",
      "epoch:33 step:31090 [D loss: 0.672373, acc.: 62.50%] [G loss: 1.159460]\n",
      "epoch:33 step:31091 [D loss: 0.497586, acc.: 80.47%] [G loss: 1.238431]\n",
      "epoch:33 step:31092 [D loss: 0.606776, acc.: 69.53%] [G loss: 1.076059]\n",
      "epoch:33 step:31093 [D loss: 0.452030, acc.: 82.81%] [G loss: 1.164492]\n",
      "epoch:33 step:31094 [D loss: 0.542049, acc.: 75.78%] [G loss: 1.645773]\n",
      "epoch:33 step:31095 [D loss: 0.447707, acc.: 80.47%] [G loss: 1.561561]\n",
      "epoch:33 step:31096 [D loss: 0.363199, acc.: 86.72%] [G loss: 1.471163]\n",
      "epoch:33 step:31097 [D loss: 0.495901, acc.: 76.56%] [G loss: 1.521734]\n",
      "epoch:33 step:31098 [D loss: 0.523201, acc.: 75.78%] [G loss: 1.404333]\n",
      "epoch:33 step:31099 [D loss: 0.396229, acc.: 82.03%] [G loss: 1.443515]\n",
      "epoch:33 step:31100 [D loss: 0.505237, acc.: 74.22%] [G loss: 1.278764]\n",
      "epoch:33 step:31101 [D loss: 0.512129, acc.: 78.12%] [G loss: 1.857600]\n",
      "epoch:33 step:31102 [D loss: 0.600716, acc.: 65.62%] [G loss: 1.358529]\n",
      "epoch:33 step:31103 [D loss: 0.414352, acc.: 82.03%] [G loss: 1.343342]\n",
      "epoch:33 step:31104 [D loss: 0.537564, acc.: 71.88%] [G loss: 1.631347]\n",
      "epoch:33 step:31105 [D loss: 0.733426, acc.: 57.81%] [G loss: 1.480412]\n",
      "epoch:33 step:31106 [D loss: 0.463647, acc.: 81.25%] [G loss: 1.578443]\n",
      "epoch:33 step:31107 [D loss: 0.459403, acc.: 76.56%] [G loss: 1.278372]\n",
      "epoch:33 step:31108 [D loss: 0.396268, acc.: 85.16%] [G loss: 1.460451]\n",
      "epoch:33 step:31109 [D loss: 0.326642, acc.: 88.28%] [G loss: 2.038162]\n",
      "epoch:33 step:31110 [D loss: 0.409270, acc.: 81.25%] [G loss: 1.542252]\n",
      "epoch:33 step:31111 [D loss: 0.428552, acc.: 82.81%] [G loss: 1.348246]\n",
      "epoch:33 step:31112 [D loss: 0.427802, acc.: 85.16%] [G loss: 1.321459]\n",
      "epoch:33 step:31113 [D loss: 0.533616, acc.: 71.88%] [G loss: 1.130998]\n",
      "epoch:33 step:31114 [D loss: 0.596595, acc.: 69.53%] [G loss: 0.967295]\n",
      "epoch:33 step:31115 [D loss: 0.469395, acc.: 75.78%] [G loss: 1.249961]\n",
      "epoch:33 step:31116 [D loss: 0.619757, acc.: 69.53%] [G loss: 1.349034]\n",
      "epoch:33 step:31117 [D loss: 0.328478, acc.: 89.06%] [G loss: 1.807849]\n",
      "epoch:33 step:31118 [D loss: 0.510438, acc.: 78.12%] [G loss: 1.616398]\n",
      "epoch:33 step:31119 [D loss: 0.569703, acc.: 70.31%] [G loss: 1.279935]\n",
      "epoch:33 step:31120 [D loss: 0.442351, acc.: 81.25%] [G loss: 1.132174]\n",
      "epoch:33 step:31121 [D loss: 0.859838, acc.: 40.62%] [G loss: 1.217674]\n",
      "epoch:33 step:31122 [D loss: 0.358387, acc.: 87.50%] [G loss: 1.372250]\n",
      "epoch:33 step:31123 [D loss: 0.543616, acc.: 71.88%] [G loss: 1.824029]\n",
      "epoch:33 step:31124 [D loss: 0.305926, acc.: 93.75%] [G loss: 1.505774]\n",
      "epoch:33 step:31125 [D loss: 0.494037, acc.: 78.12%] [G loss: 1.404798]\n",
      "epoch:33 step:31126 [D loss: 0.556416, acc.: 68.75%] [G loss: 1.132749]\n",
      "epoch:33 step:31127 [D loss: 0.543567, acc.: 68.75%] [G loss: 1.872170]\n",
      "epoch:33 step:31128 [D loss: 0.571682, acc.: 71.09%] [G loss: 1.554163]\n",
      "epoch:33 step:31129 [D loss: 0.519538, acc.: 74.22%] [G loss: 1.231803]\n",
      "epoch:33 step:31130 [D loss: 0.742024, acc.: 57.81%] [G loss: 1.443421]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:33 step:31131 [D loss: 0.482288, acc.: 75.78%] [G loss: 1.435591]\n",
      "epoch:33 step:31132 [D loss: 0.642720, acc.: 67.19%] [G loss: 1.188756]\n",
      "epoch:33 step:31133 [D loss: 0.457180, acc.: 81.25%] [G loss: 1.510842]\n",
      "epoch:33 step:31134 [D loss: 0.531734, acc.: 74.22%] [G loss: 1.507114]\n",
      "epoch:33 step:31135 [D loss: 0.734008, acc.: 54.69%] [G loss: 1.263531]\n",
      "epoch:33 step:31136 [D loss: 0.557004, acc.: 67.19%] [G loss: 1.486840]\n",
      "epoch:33 step:31137 [D loss: 0.454891, acc.: 82.03%] [G loss: 1.862393]\n",
      "epoch:33 step:31138 [D loss: 0.476095, acc.: 75.78%] [G loss: 1.097241]\n",
      "epoch:33 step:31139 [D loss: 0.415748, acc.: 83.59%] [G loss: 1.694469]\n",
      "epoch:33 step:31140 [D loss: 0.645485, acc.: 60.16%] [G loss: 0.853442]\n",
      "epoch:33 step:31141 [D loss: 0.672587, acc.: 62.50%] [G loss: 0.959443]\n",
      "epoch:33 step:31142 [D loss: 0.508751, acc.: 74.22%] [G loss: 1.659157]\n",
      "epoch:33 step:31143 [D loss: 0.434450, acc.: 78.12%] [G loss: 1.446914]\n",
      "epoch:33 step:31144 [D loss: 0.598141, acc.: 67.19%] [G loss: 0.774395]\n",
      "epoch:33 step:31145 [D loss: 0.561954, acc.: 72.66%] [G loss: 1.433585]\n",
      "epoch:33 step:31146 [D loss: 0.642237, acc.: 66.41%] [G loss: 1.177645]\n",
      "epoch:33 step:31147 [D loss: 0.581509, acc.: 67.97%] [G loss: 1.942618]\n",
      "epoch:33 step:31148 [D loss: 0.539310, acc.: 73.44%] [G loss: 2.202377]\n",
      "epoch:33 step:31149 [D loss: 0.704248, acc.: 60.16%] [G loss: 0.913552]\n",
      "epoch:33 step:31150 [D loss: 0.618883, acc.: 69.53%] [G loss: 1.460699]\n",
      "epoch:33 step:31151 [D loss: 0.589359, acc.: 71.09%] [G loss: 1.582900]\n",
      "epoch:33 step:31152 [D loss: 0.411555, acc.: 81.25%] [G loss: 1.409356]\n",
      "epoch:33 step:31153 [D loss: 0.595387, acc.: 64.06%] [G loss: 1.151865]\n",
      "epoch:33 step:31154 [D loss: 0.399683, acc.: 82.81%] [G loss: 2.135363]\n",
      "epoch:33 step:31155 [D loss: 0.784339, acc.: 51.56%] [G loss: 1.132277]\n",
      "epoch:33 step:31156 [D loss: 0.568905, acc.: 75.00%] [G loss: 1.343548]\n",
      "epoch:33 step:31157 [D loss: 0.555077, acc.: 70.31%] [G loss: 0.934518]\n",
      "epoch:33 step:31158 [D loss: 0.519016, acc.: 72.66%] [G loss: 1.440893]\n",
      "epoch:33 step:31159 [D loss: 0.729697, acc.: 58.59%] [G loss: 1.464223]\n",
      "epoch:33 step:31160 [D loss: 0.292613, acc.: 90.62%] [G loss: 1.940650]\n",
      "epoch:33 step:31161 [D loss: 0.453579, acc.: 78.91%] [G loss: 1.381302]\n",
      "epoch:33 step:31162 [D loss: 0.546240, acc.: 67.19%] [G loss: 1.542339]\n",
      "epoch:33 step:31163 [D loss: 0.675479, acc.: 60.16%] [G loss: 1.209910]\n",
      "epoch:33 step:31164 [D loss: 0.540971, acc.: 72.66%] [G loss: 1.120206]\n",
      "epoch:33 step:31165 [D loss: 0.750955, acc.: 54.69%] [G loss: 1.406943]\n",
      "epoch:33 step:31166 [D loss: 0.408383, acc.: 82.03%] [G loss: 1.788720]\n",
      "epoch:33 step:31167 [D loss: 0.538635, acc.: 75.00%] [G loss: 1.253869]\n",
      "epoch:33 step:31168 [D loss: 0.491227, acc.: 72.66%] [G loss: 1.870028]\n",
      "epoch:33 step:31169 [D loss: 0.507867, acc.: 72.66%] [G loss: 1.441554]\n",
      "epoch:33 step:31170 [D loss: 0.288867, acc.: 92.97%] [G loss: 1.610980]\n",
      "epoch:33 step:31171 [D loss: 0.495270, acc.: 75.78%] [G loss: 1.490430]\n",
      "epoch:33 step:31172 [D loss: 0.458475, acc.: 77.34%] [G loss: 1.556425]\n",
      "epoch:33 step:31173 [D loss: 0.391909, acc.: 85.16%] [G loss: 1.682096]\n",
      "epoch:33 step:31174 [D loss: 0.625726, acc.: 67.97%] [G loss: 1.649109]\n",
      "epoch:33 step:31175 [D loss: 0.476099, acc.: 74.22%] [G loss: 1.829803]\n",
      "epoch:33 step:31176 [D loss: 0.635030, acc.: 60.94%] [G loss: 1.281302]\n",
      "epoch:33 step:31177 [D loss: 0.403439, acc.: 81.25%] [G loss: 1.582036]\n",
      "epoch:33 step:31178 [D loss: 0.520650, acc.: 78.91%] [G loss: 1.379795]\n",
      "epoch:33 step:31179 [D loss: 0.439089, acc.: 82.03%] [G loss: 1.977152]\n",
      "epoch:33 step:31180 [D loss: 0.595067, acc.: 69.53%] [G loss: 1.387443]\n",
      "epoch:33 step:31181 [D loss: 0.490163, acc.: 74.22%] [G loss: 1.497368]\n",
      "epoch:33 step:31182 [D loss: 0.648248, acc.: 64.84%] [G loss: 1.608383]\n",
      "epoch:33 step:31183 [D loss: 0.613915, acc.: 61.72%] [G loss: 0.899353]\n",
      "epoch:33 step:31184 [D loss: 0.552549, acc.: 69.53%] [G loss: 1.443618]\n",
      "epoch:33 step:31185 [D loss: 0.475372, acc.: 78.91%] [G loss: 1.477687]\n",
      "epoch:33 step:31186 [D loss: 0.332739, acc.: 89.84%] [G loss: 1.624841]\n",
      "epoch:33 step:31187 [D loss: 0.452159, acc.: 78.91%] [G loss: 1.360305]\n",
      "epoch:33 step:31188 [D loss: 0.719989, acc.: 59.38%] [G loss: 1.126445]\n",
      "epoch:33 step:31189 [D loss: 0.539052, acc.: 69.53%] [G loss: 1.688194]\n",
      "epoch:33 step:31190 [D loss: 0.349044, acc.: 85.94%] [G loss: 2.098474]\n",
      "epoch:33 step:31191 [D loss: 0.527439, acc.: 77.34%] [G loss: 1.389166]\n",
      "epoch:33 step:31192 [D loss: 0.405885, acc.: 82.81%] [G loss: 1.771003]\n",
      "epoch:33 step:31193 [D loss: 0.452680, acc.: 78.12%] [G loss: 1.608456]\n",
      "epoch:33 step:31194 [D loss: 0.743092, acc.: 53.12%] [G loss: 1.176865]\n",
      "epoch:33 step:31195 [D loss: 0.580619, acc.: 67.19%] [G loss: 1.257964]\n",
      "epoch:33 step:31196 [D loss: 0.804874, acc.: 47.66%] [G loss: 1.232485]\n",
      "epoch:33 step:31197 [D loss: 0.727895, acc.: 56.25%] [G loss: 1.551020]\n",
      "epoch:33 step:31198 [D loss: 0.596841, acc.: 67.97%] [G loss: 1.486669]\n",
      "epoch:33 step:31199 [D loss: 0.620438, acc.: 64.06%] [G loss: 1.449112]\n",
      "epoch:33 step:31200 [D loss: 0.448119, acc.: 80.47%] [G loss: 1.439210]\n",
      "epoch:33 step:31201 [D loss: 0.503852, acc.: 76.56%] [G loss: 1.675727]\n",
      "epoch:33 step:31202 [D loss: 0.689184, acc.: 66.41%] [G loss: 1.621041]\n",
      "epoch:33 step:31203 [D loss: 0.434269, acc.: 78.12%] [G loss: 1.238457]\n",
      "epoch:33 step:31204 [D loss: 0.590035, acc.: 70.31%] [G loss: 1.467656]\n",
      "epoch:33 step:31205 [D loss: 0.541695, acc.: 73.44%] [G loss: 1.002136]\n",
      "epoch:33 step:31206 [D loss: 0.381283, acc.: 84.38%] [G loss: 1.785652]\n",
      "epoch:33 step:31207 [D loss: 0.492359, acc.: 75.00%] [G loss: 1.870126]\n",
      "epoch:33 step:31208 [D loss: 0.457885, acc.: 78.91%] [G loss: 0.995230]\n",
      "epoch:33 step:31209 [D loss: 0.467939, acc.: 78.12%] [G loss: 1.140967]\n",
      "epoch:33 step:31210 [D loss: 0.594735, acc.: 71.09%] [G loss: 1.589082]\n",
      "epoch:33 step:31211 [D loss: 0.407109, acc.: 83.59%] [G loss: 1.625554]\n",
      "epoch:33 step:31212 [D loss: 0.555628, acc.: 71.88%] [G loss: 1.771701]\n",
      "epoch:33 step:31213 [D loss: 0.584604, acc.: 67.19%] [G loss: 1.454268]\n",
      "epoch:33 step:31214 [D loss: 0.591231, acc.: 66.41%] [G loss: 2.013755]\n",
      "epoch:33 step:31215 [D loss: 0.392889, acc.: 85.16%] [G loss: 2.235000]\n",
      "epoch:33 step:31216 [D loss: 0.646494, acc.: 64.06%] [G loss: 1.350528]\n",
      "epoch:33 step:31217 [D loss: 0.418885, acc.: 80.47%] [G loss: 1.558663]\n",
      "epoch:33 step:31218 [D loss: 0.453542, acc.: 81.25%] [G loss: 1.361656]\n",
      "epoch:33 step:31219 [D loss: 0.802228, acc.: 57.81%] [G loss: 1.164158]\n",
      "epoch:33 step:31220 [D loss: 0.519968, acc.: 72.66%] [G loss: 1.941813]\n",
      "epoch:33 step:31221 [D loss: 0.675346, acc.: 60.16%] [G loss: 1.838931]\n",
      "epoch:33 step:31222 [D loss: 0.567935, acc.: 71.09%] [G loss: 1.424623]\n",
      "epoch:33 step:31223 [D loss: 0.790250, acc.: 45.31%] [G loss: 1.275037]\n",
      "epoch:33 step:31224 [D loss: 0.479753, acc.: 75.78%] [G loss: 1.622450]\n",
      "epoch:33 step:31225 [D loss: 0.537494, acc.: 76.56%] [G loss: 1.708601]\n",
      "epoch:33 step:31226 [D loss: 0.587865, acc.: 68.75%] [G loss: 0.899179]\n",
      "epoch:33 step:31227 [D loss: 0.458417, acc.: 80.47%] [G loss: 1.402174]\n",
      "epoch:33 step:31228 [D loss: 0.507822, acc.: 76.56%] [G loss: 1.652773]\n",
      "epoch:33 step:31229 [D loss: 0.431942, acc.: 80.47%] [G loss: 2.105400]\n",
      "epoch:33 step:31230 [D loss: 0.504920, acc.: 79.69%] [G loss: 1.945173]\n",
      "epoch:33 step:31231 [D loss: 0.536130, acc.: 71.88%] [G loss: 1.593410]\n",
      "epoch:33 step:31232 [D loss: 0.373911, acc.: 89.06%] [G loss: 1.345819]\n",
      "epoch:33 step:31233 [D loss: 0.671120, acc.: 60.94%] [G loss: 1.335359]\n",
      "epoch:33 step:31234 [D loss: 0.647316, acc.: 63.28%] [G loss: 1.291631]\n",
      "epoch:33 step:31235 [D loss: 0.378826, acc.: 82.03%] [G loss: 1.738571]\n",
      "epoch:33 step:31236 [D loss: 0.487056, acc.: 75.00%] [G loss: 2.159675]\n",
      "epoch:33 step:31237 [D loss: 0.666921, acc.: 61.72%] [G loss: 1.698853]\n",
      "epoch:33 step:31238 [D loss: 0.607606, acc.: 61.72%] [G loss: 1.632181]\n",
      "epoch:33 step:31239 [D loss: 0.543569, acc.: 75.78%] [G loss: 1.707107]\n",
      "epoch:33 step:31240 [D loss: 0.522244, acc.: 76.56%] [G loss: 1.397264]\n",
      "epoch:33 step:31241 [D loss: 0.564634, acc.: 70.31%] [G loss: 1.256739]\n",
      "epoch:33 step:31242 [D loss: 0.689797, acc.: 57.81%] [G loss: 1.946147]\n",
      "epoch:33 step:31243 [D loss: 0.469332, acc.: 79.69%] [G loss: 1.393129]\n",
      "epoch:33 step:31244 [D loss: 0.561517, acc.: 66.41%] [G loss: 1.299693]\n",
      "epoch:33 step:31245 [D loss: 0.391993, acc.: 82.03%] [G loss: 1.482998]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:33 step:31246 [D loss: 0.377160, acc.: 85.94%] [G loss: 1.750945]\n",
      "epoch:33 step:31247 [D loss: 0.523239, acc.: 71.88%] [G loss: 1.589226]\n",
      "epoch:33 step:31248 [D loss: 0.452647, acc.: 81.25%] [G loss: 1.435343]\n",
      "epoch:33 step:31249 [D loss: 0.488379, acc.: 78.91%] [G loss: 1.755773]\n",
      "epoch:33 step:31250 [D loss: 0.454139, acc.: 81.25%] [G loss: 1.861473]\n",
      "epoch:33 step:31251 [D loss: 0.505751, acc.: 74.22%] [G loss: 1.757005]\n",
      "epoch:33 step:31252 [D loss: 0.621388, acc.: 67.97%] [G loss: 1.799855]\n",
      "epoch:33 step:31253 [D loss: 0.547833, acc.: 71.88%] [G loss: 1.229743]\n",
      "epoch:33 step:31254 [D loss: 0.550342, acc.: 71.09%] [G loss: 1.302497]\n",
      "epoch:33 step:31255 [D loss: 0.740419, acc.: 56.25%] [G loss: 1.183722]\n",
      "epoch:33 step:31256 [D loss: 0.492877, acc.: 74.22%] [G loss: 1.898225]\n",
      "epoch:33 step:31257 [D loss: 0.582150, acc.: 71.88%] [G loss: 1.552513]\n",
      "epoch:33 step:31258 [D loss: 0.450953, acc.: 81.25%] [G loss: 1.718458]\n",
      "epoch:33 step:31259 [D loss: 0.451050, acc.: 78.91%] [G loss: 1.189512]\n",
      "epoch:33 step:31260 [D loss: 0.434601, acc.: 81.25%] [G loss: 1.455606]\n",
      "epoch:33 step:31261 [D loss: 0.513441, acc.: 73.44%] [G loss: 2.130755]\n",
      "epoch:33 step:31262 [D loss: 0.556316, acc.: 72.66%] [G loss: 1.508097]\n",
      "epoch:33 step:31263 [D loss: 0.613081, acc.: 64.84%] [G loss: 1.445513]\n",
      "epoch:33 step:31264 [D loss: 0.743533, acc.: 51.56%] [G loss: 1.255465]\n",
      "epoch:33 step:31265 [D loss: 0.476539, acc.: 74.22%] [G loss: 1.457366]\n",
      "epoch:33 step:31266 [D loss: 0.530828, acc.: 70.31%] [G loss: 1.704043]\n",
      "epoch:33 step:31267 [D loss: 0.801323, acc.: 57.81%] [G loss: 1.145160]\n",
      "epoch:33 step:31268 [D loss: 0.461408, acc.: 79.69%] [G loss: 1.219455]\n",
      "epoch:33 step:31269 [D loss: 0.516049, acc.: 74.22%] [G loss: 1.089283]\n",
      "epoch:33 step:31270 [D loss: 0.407493, acc.: 82.03%] [G loss: 1.633567]\n",
      "epoch:33 step:31271 [D loss: 0.714652, acc.: 59.38%] [G loss: 1.672429]\n",
      "epoch:33 step:31272 [D loss: 0.478691, acc.: 80.47%] [G loss: 1.446781]\n",
      "epoch:33 step:31273 [D loss: 0.678450, acc.: 61.72%] [G loss: 1.781283]\n",
      "epoch:33 step:31274 [D loss: 0.536128, acc.: 72.66%] [G loss: 1.399978]\n",
      "epoch:33 step:31275 [D loss: 0.450992, acc.: 80.47%] [G loss: 1.314337]\n",
      "epoch:33 step:31276 [D loss: 0.577120, acc.: 71.88%] [G loss: 1.331223]\n",
      "epoch:33 step:31277 [D loss: 0.431690, acc.: 81.25%] [G loss: 1.320175]\n",
      "epoch:33 step:31278 [D loss: 0.475767, acc.: 78.12%] [G loss: 1.647543]\n",
      "epoch:33 step:31279 [D loss: 0.617015, acc.: 67.97%] [G loss: 1.512422]\n",
      "epoch:33 step:31280 [D loss: 0.480945, acc.: 77.34%] [G loss: 1.200288]\n",
      "epoch:33 step:31281 [D loss: 0.480255, acc.: 71.88%] [G loss: 1.367630]\n",
      "epoch:33 step:31282 [D loss: 0.622153, acc.: 66.41%] [G loss: 1.589695]\n",
      "epoch:33 step:31283 [D loss: 0.405608, acc.: 84.38%] [G loss: 1.413772]\n",
      "epoch:33 step:31284 [D loss: 0.472573, acc.: 81.25%] [G loss: 1.423056]\n",
      "epoch:33 step:31285 [D loss: 0.387025, acc.: 86.72%] [G loss: 1.978233]\n",
      "epoch:33 step:31286 [D loss: 0.559536, acc.: 72.66%] [G loss: 1.188403]\n",
      "epoch:33 step:31287 [D loss: 0.559125, acc.: 69.53%] [G loss: 1.333201]\n",
      "epoch:33 step:31288 [D loss: 0.494440, acc.: 76.56%] [G loss: 1.110986]\n",
      "epoch:33 step:31289 [D loss: 0.494663, acc.: 76.56%] [G loss: 1.068905]\n",
      "epoch:33 step:31290 [D loss: 0.485743, acc.: 75.78%] [G loss: 1.546603]\n",
      "epoch:33 step:31291 [D loss: 0.317396, acc.: 89.06%] [G loss: 2.014983]\n",
      "epoch:33 step:31292 [D loss: 0.383351, acc.: 89.06%] [G loss: 1.411149]\n",
      "epoch:33 step:31293 [D loss: 0.460252, acc.: 75.78%] [G loss: 1.092176]\n",
      "epoch:33 step:31294 [D loss: 0.509540, acc.: 77.34%] [G loss: 1.283994]\n",
      "epoch:33 step:31295 [D loss: 0.761694, acc.: 50.78%] [G loss: 1.208261]\n",
      "epoch:33 step:31296 [D loss: 0.531350, acc.: 72.66%] [G loss: 1.109893]\n",
      "epoch:33 step:31297 [D loss: 0.510880, acc.: 72.66%] [G loss: 1.164217]\n",
      "epoch:33 step:31298 [D loss: 0.631367, acc.: 65.62%] [G loss: 1.079820]\n",
      "epoch:33 step:31299 [D loss: 0.380181, acc.: 82.81%] [G loss: 2.057080]\n",
      "epoch:33 step:31300 [D loss: 0.703651, acc.: 58.59%] [G loss: 1.322291]\n",
      "epoch:33 step:31301 [D loss: 0.541502, acc.: 73.44%] [G loss: 1.429697]\n",
      "epoch:33 step:31302 [D loss: 0.464507, acc.: 77.34%] [G loss: 1.664316]\n",
      "epoch:33 step:31303 [D loss: 0.489368, acc.: 76.56%] [G loss: 1.886323]\n",
      "epoch:33 step:31304 [D loss: 0.468452, acc.: 78.91%] [G loss: 1.317682]\n",
      "epoch:33 step:31305 [D loss: 0.529820, acc.: 68.75%] [G loss: 1.441089]\n",
      "epoch:33 step:31306 [D loss: 0.676150, acc.: 61.72%] [G loss: 1.418661]\n",
      "epoch:33 step:31307 [D loss: 0.557691, acc.: 72.66%] [G loss: 1.487426]\n",
      "epoch:33 step:31308 [D loss: 0.417658, acc.: 82.03%] [G loss: 1.485089]\n",
      "epoch:33 step:31309 [D loss: 0.560167, acc.: 67.97%] [G loss: 1.486354]\n",
      "epoch:33 step:31310 [D loss: 0.700347, acc.: 54.69%] [G loss: 1.176599]\n",
      "epoch:33 step:31311 [D loss: 0.631687, acc.: 66.41%] [G loss: 1.048648]\n",
      "epoch:33 step:31312 [D loss: 0.645460, acc.: 64.06%] [G loss: 1.422487]\n",
      "epoch:33 step:31313 [D loss: 0.445735, acc.: 81.25%] [G loss: 1.386000]\n",
      "epoch:33 step:31314 [D loss: 0.610810, acc.: 65.62%] [G loss: 1.717335]\n",
      "epoch:33 step:31315 [D loss: 0.589990, acc.: 65.62%] [G loss: 1.315097]\n",
      "epoch:33 step:31316 [D loss: 0.482239, acc.: 77.34%] [G loss: 1.810483]\n",
      "epoch:33 step:31317 [D loss: 0.402560, acc.: 85.94%] [G loss: 1.213143]\n",
      "epoch:33 step:31318 [D loss: 0.618537, acc.: 65.62%] [G loss: 1.621770]\n",
      "epoch:33 step:31319 [D loss: 0.410976, acc.: 83.59%] [G loss: 1.331592]\n",
      "epoch:33 step:31320 [D loss: 0.460300, acc.: 79.69%] [G loss: 1.786319]\n",
      "epoch:33 step:31321 [D loss: 0.593154, acc.: 67.19%] [G loss: 1.124136]\n",
      "epoch:33 step:31322 [D loss: 0.610020, acc.: 60.94%] [G loss: 1.971740]\n",
      "epoch:33 step:31323 [D loss: 0.503976, acc.: 75.78%] [G loss: 1.364236]\n",
      "epoch:33 step:31324 [D loss: 0.619703, acc.: 67.97%] [G loss: 1.321374]\n",
      "epoch:33 step:31325 [D loss: 0.518272, acc.: 75.78%] [G loss: 1.542674]\n",
      "epoch:33 step:31326 [D loss: 0.589559, acc.: 67.19%] [G loss: 1.601139]\n",
      "epoch:33 step:31327 [D loss: 0.563086, acc.: 71.88%] [G loss: 1.458373]\n",
      "epoch:33 step:31328 [D loss: 0.586911, acc.: 71.09%] [G loss: 1.348705]\n",
      "epoch:33 step:31329 [D loss: 0.534561, acc.: 68.75%] [G loss: 1.684901]\n",
      "epoch:33 step:31330 [D loss: 0.449377, acc.: 81.25%] [G loss: 1.344909]\n",
      "epoch:33 step:31331 [D loss: 0.492832, acc.: 75.78%] [G loss: 1.631483]\n",
      "epoch:33 step:31332 [D loss: 0.594196, acc.: 68.75%] [G loss: 1.115533]\n",
      "epoch:33 step:31333 [D loss: 0.573110, acc.: 71.09%] [G loss: 1.514404]\n",
      "epoch:33 step:31334 [D loss: 0.685793, acc.: 58.59%] [G loss: 1.630603]\n",
      "epoch:33 step:31335 [D loss: 0.772079, acc.: 54.69%] [G loss: 1.605716]\n",
      "epoch:33 step:31336 [D loss: 0.468946, acc.: 80.47%] [G loss: 1.763899]\n",
      "epoch:33 step:31337 [D loss: 0.632498, acc.: 66.41%] [G loss: 0.909877]\n",
      "epoch:33 step:31338 [D loss: 0.648135, acc.: 65.62%] [G loss: 1.296582]\n",
      "epoch:33 step:31339 [D loss: 0.438211, acc.: 82.81%] [G loss: 2.276418]\n",
      "epoch:33 step:31340 [D loss: 0.481801, acc.: 71.88%] [G loss: 1.753063]\n",
      "epoch:33 step:31341 [D loss: 0.421257, acc.: 83.59%] [G loss: 1.306158]\n",
      "epoch:33 step:31342 [D loss: 0.499611, acc.: 72.66%] [G loss: 1.543223]\n",
      "epoch:33 step:31343 [D loss: 0.534591, acc.: 76.56%] [G loss: 1.710321]\n",
      "epoch:33 step:31344 [D loss: 0.579165, acc.: 69.53%] [G loss: 1.232209]\n",
      "epoch:33 step:31345 [D loss: 0.481461, acc.: 82.03%] [G loss: 1.400550]\n",
      "epoch:33 step:31346 [D loss: 0.799092, acc.: 48.44%] [G loss: 1.628245]\n",
      "epoch:33 step:31347 [D loss: 0.383598, acc.: 86.72%] [G loss: 1.630458]\n",
      "epoch:33 step:31348 [D loss: 0.867369, acc.: 49.22%] [G loss: 1.388642]\n",
      "epoch:33 step:31349 [D loss: 0.417230, acc.: 83.59%] [G loss: 0.970904]\n",
      "epoch:33 step:31350 [D loss: 0.587274, acc.: 71.09%] [G loss: 0.942327]\n",
      "epoch:33 step:31351 [D loss: 0.608902, acc.: 70.31%] [G loss: 1.329197]\n",
      "epoch:33 step:31352 [D loss: 0.704972, acc.: 57.81%] [G loss: 1.494230]\n",
      "epoch:33 step:31353 [D loss: 0.380609, acc.: 85.16%] [G loss: 1.526487]\n",
      "epoch:33 step:31354 [D loss: 0.331566, acc.: 88.28%] [G loss: 1.909891]\n",
      "epoch:33 step:31355 [D loss: 0.628559, acc.: 62.50%] [G loss: 1.754297]\n",
      "epoch:33 step:31356 [D loss: 0.495616, acc.: 75.00%] [G loss: 2.105336]\n",
      "epoch:33 step:31357 [D loss: 0.641704, acc.: 66.41%] [G loss: 1.164990]\n",
      "epoch:33 step:31358 [D loss: 0.438751, acc.: 81.25%] [G loss: 1.483943]\n",
      "epoch:33 step:31359 [D loss: 0.539074, acc.: 72.66%] [G loss: 1.740230]\n",
      "epoch:33 step:31360 [D loss: 0.497072, acc.: 71.88%] [G loss: 0.982419]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:33 step:31361 [D loss: 0.663140, acc.: 63.28%] [G loss: 1.352662]\n",
      "epoch:33 step:31362 [D loss: 0.529035, acc.: 76.56%] [G loss: 1.702962]\n",
      "epoch:33 step:31363 [D loss: 0.553809, acc.: 76.56%] [G loss: 1.938397]\n",
      "epoch:33 step:31364 [D loss: 0.609483, acc.: 64.06%] [G loss: 1.123437]\n",
      "epoch:33 step:31365 [D loss: 0.480277, acc.: 75.78%] [G loss: 1.420391]\n",
      "epoch:33 step:31366 [D loss: 0.368676, acc.: 89.06%] [G loss: 1.267888]\n",
      "epoch:33 step:31367 [D loss: 0.779052, acc.: 57.81%] [G loss: 1.077940]\n",
      "epoch:33 step:31368 [D loss: 0.500674, acc.: 76.56%] [G loss: 1.270894]\n",
      "epoch:33 step:31369 [D loss: 0.466195, acc.: 78.91%] [G loss: 2.225679]\n",
      "epoch:33 step:31370 [D loss: 0.505956, acc.: 76.56%] [G loss: 1.577964]\n",
      "epoch:33 step:31371 [D loss: 0.390694, acc.: 81.25%] [G loss: 1.403671]\n",
      "epoch:33 step:31372 [D loss: 0.476501, acc.: 76.56%] [G loss: 1.462243]\n",
      "epoch:33 step:31373 [D loss: 0.582402, acc.: 71.88%] [G loss: 1.394573]\n",
      "epoch:33 step:31374 [D loss: 0.598500, acc.: 63.28%] [G loss: 0.838721]\n",
      "epoch:33 step:31375 [D loss: 0.409584, acc.: 84.38%] [G loss: 1.478037]\n",
      "epoch:33 step:31376 [D loss: 0.429596, acc.: 84.38%] [G loss: 1.333829]\n",
      "epoch:33 step:31377 [D loss: 0.547104, acc.: 72.66%] [G loss: 1.633611]\n",
      "epoch:33 step:31378 [D loss: 0.732767, acc.: 55.47%] [G loss: 1.340386]\n",
      "epoch:33 step:31379 [D loss: 0.390857, acc.: 85.16%] [G loss: 1.374133]\n",
      "epoch:33 step:31380 [D loss: 0.392303, acc.: 85.16%] [G loss: 1.447499]\n",
      "epoch:33 step:31381 [D loss: 0.449699, acc.: 75.78%] [G loss: 1.693020]\n",
      "epoch:33 step:31382 [D loss: 0.454492, acc.: 78.91%] [G loss: 1.395299]\n",
      "epoch:33 step:31383 [D loss: 0.977818, acc.: 35.94%] [G loss: 1.240039]\n",
      "epoch:33 step:31384 [D loss: 0.530691, acc.: 75.78%] [G loss: 1.442372]\n",
      "epoch:33 step:31385 [D loss: 0.700858, acc.: 58.59%] [G loss: 1.037694]\n",
      "epoch:33 step:31386 [D loss: 0.418453, acc.: 80.47%] [G loss: 2.089997]\n",
      "epoch:33 step:31387 [D loss: 0.557248, acc.: 69.53%] [G loss: 1.438433]\n",
      "epoch:33 step:31388 [D loss: 0.556511, acc.: 73.44%] [G loss: 1.367689]\n",
      "epoch:33 step:31389 [D loss: 0.523656, acc.: 70.31%] [G loss: 1.212626]\n",
      "epoch:33 step:31390 [D loss: 0.421022, acc.: 82.03%] [G loss: 1.121517]\n",
      "epoch:33 step:31391 [D loss: 0.610673, acc.: 67.19%] [G loss: 1.752975]\n",
      "epoch:33 step:31392 [D loss: 0.443604, acc.: 79.69%] [G loss: 1.334177]\n",
      "epoch:33 step:31393 [D loss: 0.768134, acc.: 51.56%] [G loss: 1.706739]\n",
      "epoch:33 step:31394 [D loss: 0.412688, acc.: 84.38%] [G loss: 1.351541]\n",
      "epoch:33 step:31395 [D loss: 0.543885, acc.: 71.88%] [G loss: 2.229400]\n",
      "epoch:33 step:31396 [D loss: 0.493949, acc.: 74.22%] [G loss: 1.383586]\n",
      "epoch:33 step:31397 [D loss: 0.475909, acc.: 75.00%] [G loss: 1.667962]\n",
      "epoch:33 step:31398 [D loss: 0.520351, acc.: 75.78%] [G loss: 1.594108]\n",
      "epoch:33 step:31399 [D loss: 0.671273, acc.: 64.06%] [G loss: 1.204479]\n",
      "epoch:33 step:31400 [D loss: 0.668833, acc.: 61.72%] [G loss: 1.359560]\n",
      "epoch:33 step:31401 [D loss: 0.494197, acc.: 75.78%] [G loss: 1.449879]\n",
      "epoch:33 step:31402 [D loss: 0.543683, acc.: 72.66%] [G loss: 1.731051]\n",
      "epoch:33 step:31403 [D loss: 0.702534, acc.: 61.72%] [G loss: 1.552901]\n",
      "epoch:33 step:31404 [D loss: 0.879410, acc.: 48.44%] [G loss: 1.563005]\n",
      "epoch:33 step:31405 [D loss: 0.458217, acc.: 82.03%] [G loss: 1.386220]\n",
      "epoch:33 step:31406 [D loss: 0.391481, acc.: 85.94%] [G loss: 1.760998]\n",
      "epoch:33 step:31407 [D loss: 0.442749, acc.: 78.91%] [G loss: 1.937168]\n",
      "epoch:33 step:31408 [D loss: 0.380605, acc.: 85.16%] [G loss: 2.034757]\n",
      "epoch:33 step:31409 [D loss: 0.501375, acc.: 74.22%] [G loss: 1.545724]\n",
      "epoch:33 step:31410 [D loss: 0.412196, acc.: 82.81%] [G loss: 1.734174]\n",
      "epoch:33 step:31411 [D loss: 0.430350, acc.: 82.03%] [G loss: 1.273185]\n",
      "epoch:33 step:31412 [D loss: 0.480710, acc.: 78.12%] [G loss: 1.693635]\n",
      "epoch:33 step:31413 [D loss: 0.564374, acc.: 71.88%] [G loss: 1.706460]\n",
      "epoch:33 step:31414 [D loss: 0.599845, acc.: 65.62%] [G loss: 1.174901]\n",
      "epoch:33 step:31415 [D loss: 0.456959, acc.: 77.34%] [G loss: 1.300168]\n",
      "epoch:33 step:31416 [D loss: 0.570732, acc.: 68.75%] [G loss: 1.995698]\n",
      "epoch:33 step:31417 [D loss: 0.475569, acc.: 73.44%] [G loss: 1.501482]\n",
      "epoch:33 step:31418 [D loss: 0.504068, acc.: 73.44%] [G loss: 1.800884]\n",
      "epoch:33 step:31419 [D loss: 0.438839, acc.: 79.69%] [G loss: 1.344298]\n",
      "epoch:33 step:31420 [D loss: 0.521222, acc.: 73.44%] [G loss: 1.235661]\n",
      "epoch:33 step:31421 [D loss: 0.508428, acc.: 78.12%] [G loss: 1.509662]\n",
      "epoch:33 step:31422 [D loss: 0.428605, acc.: 80.47%] [G loss: 1.733955]\n",
      "epoch:33 step:31423 [D loss: 0.536495, acc.: 72.66%] [G loss: 1.596801]\n",
      "epoch:33 step:31424 [D loss: 0.531561, acc.: 71.88%] [G loss: 1.455211]\n",
      "epoch:33 step:31425 [D loss: 0.725073, acc.: 61.72%] [G loss: 1.534571]\n",
      "epoch:33 step:31426 [D loss: 0.376342, acc.: 86.72%] [G loss: 1.446349]\n",
      "epoch:33 step:31427 [D loss: 0.464738, acc.: 82.81%] [G loss: 1.814943]\n",
      "epoch:33 step:31428 [D loss: 0.683810, acc.: 59.38%] [G loss: 1.213104]\n",
      "epoch:33 step:31429 [D loss: 0.339370, acc.: 86.72%] [G loss: 1.854742]\n",
      "epoch:33 step:31430 [D loss: 0.436430, acc.: 82.03%] [G loss: 1.213095]\n",
      "epoch:33 step:31431 [D loss: 0.670253, acc.: 60.94%] [G loss: 1.389509]\n",
      "epoch:33 step:31432 [D loss: 0.451423, acc.: 83.59%] [G loss: 1.558903]\n",
      "epoch:33 step:31433 [D loss: 0.427671, acc.: 82.03%] [G loss: 1.905104]\n",
      "epoch:33 step:31434 [D loss: 0.490857, acc.: 75.78%] [G loss: 1.699759]\n",
      "epoch:33 step:31435 [D loss: 0.410987, acc.: 79.69%] [G loss: 1.473589]\n",
      "epoch:33 step:31436 [D loss: 0.662770, acc.: 61.72%] [G loss: 1.106722]\n",
      "epoch:33 step:31437 [D loss: 0.630683, acc.: 68.75%] [G loss: 1.161350]\n",
      "epoch:33 step:31438 [D loss: 0.412917, acc.: 82.81%] [G loss: 1.714810]\n",
      "epoch:33 step:31439 [D loss: 0.567675, acc.: 74.22%] [G loss: 1.753771]\n",
      "epoch:33 step:31440 [D loss: 0.361857, acc.: 85.16%] [G loss: 0.963671]\n",
      "epoch:33 step:31441 [D loss: 0.455247, acc.: 75.78%] [G loss: 1.614067]\n",
      "epoch:33 step:31442 [D loss: 0.675398, acc.: 61.72%] [G loss: 1.370474]\n",
      "epoch:33 step:31443 [D loss: 0.708912, acc.: 59.38%] [G loss: 1.928852]\n",
      "epoch:33 step:31444 [D loss: 0.563731, acc.: 69.53%] [G loss: 1.709684]\n",
      "epoch:33 step:31445 [D loss: 0.778460, acc.: 51.56%] [G loss: 1.792697]\n",
      "epoch:33 step:31446 [D loss: 0.595558, acc.: 69.53%] [G loss: 1.672733]\n",
      "epoch:33 step:31447 [D loss: 0.554984, acc.: 71.88%] [G loss: 1.252738]\n",
      "epoch:33 step:31448 [D loss: 0.625222, acc.: 62.50%] [G loss: 1.792833]\n",
      "epoch:33 step:31449 [D loss: 0.835274, acc.: 51.56%] [G loss: 1.419009]\n",
      "epoch:33 step:31450 [D loss: 0.725052, acc.: 58.59%] [G loss: 1.182940]\n",
      "epoch:33 step:31451 [D loss: 0.720813, acc.: 59.38%] [G loss: 1.694680]\n",
      "epoch:33 step:31452 [D loss: 0.629581, acc.: 69.53%] [G loss: 1.192337]\n",
      "epoch:33 step:31453 [D loss: 0.586646, acc.: 68.75%] [G loss: 1.284496]\n",
      "epoch:33 step:31454 [D loss: 0.511242, acc.: 70.31%] [G loss: 1.651572]\n",
      "epoch:33 step:31455 [D loss: 0.628944, acc.: 65.62%] [G loss: 1.580572]\n",
      "epoch:33 step:31456 [D loss: 0.561560, acc.: 70.31%] [G loss: 0.954130]\n",
      "epoch:33 step:31457 [D loss: 0.536366, acc.: 77.34%] [G loss: 1.221392]\n",
      "epoch:33 step:31458 [D loss: 0.461314, acc.: 82.03%] [G loss: 2.116918]\n",
      "epoch:33 step:31459 [D loss: 0.625712, acc.: 69.53%] [G loss: 1.071336]\n",
      "epoch:33 step:31460 [D loss: 0.285677, acc.: 92.19%] [G loss: 1.696224]\n",
      "epoch:33 step:31461 [D loss: 0.495403, acc.: 77.34%] [G loss: 1.360970]\n",
      "epoch:33 step:31462 [D loss: 0.456285, acc.: 81.25%] [G loss: 1.573498]\n",
      "epoch:33 step:31463 [D loss: 0.338758, acc.: 87.50%] [G loss: 2.087683]\n",
      "epoch:33 step:31464 [D loss: 0.420875, acc.: 84.38%] [G loss: 1.749983]\n",
      "epoch:33 step:31465 [D loss: 0.543656, acc.: 71.09%] [G loss: 1.694025]\n",
      "epoch:33 step:31466 [D loss: 0.506741, acc.: 78.12%] [G loss: 1.401113]\n",
      "epoch:33 step:31467 [D loss: 0.479192, acc.: 76.56%] [G loss: 1.616157]\n",
      "epoch:33 step:31468 [D loss: 0.588726, acc.: 67.97%] [G loss: 1.345437]\n",
      "epoch:33 step:31469 [D loss: 0.704951, acc.: 59.38%] [G loss: 1.075419]\n",
      "epoch:33 step:31470 [D loss: 0.374933, acc.: 86.72%] [G loss: 1.336052]\n",
      "epoch:33 step:31471 [D loss: 0.619728, acc.: 67.19%] [G loss: 1.546273]\n",
      "epoch:33 step:31472 [D loss: 0.630860, acc.: 67.97%] [G loss: 1.473081]\n",
      "epoch:33 step:31473 [D loss: 0.334367, acc.: 89.84%] [G loss: 1.690495]\n",
      "epoch:33 step:31474 [D loss: 0.706224, acc.: 59.38%] [G loss: 1.762112]\n",
      "epoch:33 step:31475 [D loss: 0.539178, acc.: 68.75%] [G loss: 1.493637]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:33 step:31476 [D loss: 0.578951, acc.: 68.75%] [G loss: 1.437058]\n",
      "epoch:33 step:31477 [D loss: 0.458632, acc.: 78.91%] [G loss: 1.775430]\n",
      "epoch:33 step:31478 [D loss: 0.860176, acc.: 53.12%] [G loss: 1.089095]\n",
      "epoch:33 step:31479 [D loss: 0.363518, acc.: 88.28%] [G loss: 1.557373]\n",
      "epoch:33 step:31480 [D loss: 0.417372, acc.: 80.47%] [G loss: 1.496797]\n",
      "epoch:33 step:31481 [D loss: 0.473968, acc.: 80.47%] [G loss: 1.462403]\n",
      "epoch:33 step:31482 [D loss: 0.455849, acc.: 78.91%] [G loss: 1.389737]\n",
      "epoch:33 step:31483 [D loss: 0.434242, acc.: 81.25%] [G loss: 1.465447]\n",
      "epoch:33 step:31484 [D loss: 0.476479, acc.: 76.56%] [G loss: 1.922185]\n",
      "epoch:33 step:31485 [D loss: 0.555523, acc.: 72.66%] [G loss: 1.425322]\n",
      "epoch:33 step:31486 [D loss: 0.470945, acc.: 80.47%] [G loss: 1.740863]\n",
      "epoch:33 step:31487 [D loss: 0.382764, acc.: 83.59%] [G loss: 1.557506]\n",
      "epoch:33 step:31488 [D loss: 0.410802, acc.: 80.47%] [G loss: 1.573249]\n",
      "epoch:33 step:31489 [D loss: 0.502035, acc.: 76.56%] [G loss: 1.242099]\n",
      "epoch:33 step:31490 [D loss: 0.329348, acc.: 89.06%] [G loss: 1.676801]\n",
      "epoch:33 step:31491 [D loss: 0.532696, acc.: 69.53%] [G loss: 1.548289]\n",
      "epoch:33 step:31492 [D loss: 0.612141, acc.: 60.94%] [G loss: 1.257538]\n",
      "epoch:33 step:31493 [D loss: 0.518613, acc.: 78.12%] [G loss: 1.289457]\n",
      "epoch:33 step:31494 [D loss: 0.707742, acc.: 61.72%] [G loss: 1.998734]\n",
      "epoch:33 step:31495 [D loss: 0.587342, acc.: 69.53%] [G loss: 1.383345]\n",
      "epoch:33 step:31496 [D loss: 0.438623, acc.: 79.69%] [G loss: 1.472450]\n",
      "epoch:33 step:31497 [D loss: 0.537984, acc.: 68.75%] [G loss: 1.370218]\n",
      "epoch:33 step:31498 [D loss: 0.726187, acc.: 58.59%] [G loss: 1.498112]\n",
      "epoch:33 step:31499 [D loss: 0.626890, acc.: 69.53%] [G loss: 1.277623]\n",
      "epoch:33 step:31500 [D loss: 0.430477, acc.: 79.69%] [G loss: 1.615746]\n",
      "epoch:33 step:31501 [D loss: 0.511949, acc.: 73.44%] [G loss: 1.267027]\n",
      "epoch:33 step:31502 [D loss: 0.669227, acc.: 61.72%] [G loss: 1.670621]\n",
      "epoch:33 step:31503 [D loss: 0.413111, acc.: 84.38%] [G loss: 1.655775]\n",
      "epoch:33 step:31504 [D loss: 0.374974, acc.: 85.94%] [G loss: 1.183333]\n",
      "epoch:33 step:31505 [D loss: 0.476943, acc.: 79.69%] [G loss: 1.697604]\n",
      "epoch:33 step:31506 [D loss: 0.717164, acc.: 61.72%] [G loss: 1.461055]\n",
      "epoch:33 step:31507 [D loss: 0.521520, acc.: 74.22%] [G loss: 1.479774]\n",
      "epoch:33 step:31508 [D loss: 0.707422, acc.: 55.47%] [G loss: 1.237587]\n",
      "epoch:33 step:31509 [D loss: 0.656462, acc.: 60.16%] [G loss: 1.381742]\n",
      "epoch:33 step:31510 [D loss: 0.626743, acc.: 64.06%] [G loss: 1.348770]\n",
      "epoch:33 step:31511 [D loss: 0.620398, acc.: 63.28%] [G loss: 1.134551]\n",
      "epoch:33 step:31512 [D loss: 0.439974, acc.: 79.69%] [G loss: 1.608135]\n",
      "epoch:33 step:31513 [D loss: 0.497028, acc.: 74.22%] [G loss: 1.008740]\n",
      "epoch:33 step:31514 [D loss: 0.441311, acc.: 81.25%] [G loss: 1.423123]\n",
      "epoch:33 step:31515 [D loss: 0.546145, acc.: 76.56%] [G loss: 1.177625]\n",
      "epoch:33 step:31516 [D loss: 0.326015, acc.: 90.62%] [G loss: 1.361557]\n",
      "epoch:33 step:31517 [D loss: 0.569786, acc.: 75.00%] [G loss: 2.064939]\n",
      "epoch:33 step:31518 [D loss: 0.432917, acc.: 77.34%] [G loss: 2.023131]\n",
      "epoch:33 step:31519 [D loss: 0.594151, acc.: 64.84%] [G loss: 1.197541]\n",
      "epoch:33 step:31520 [D loss: 0.476176, acc.: 79.69%] [G loss: 1.605875]\n",
      "epoch:33 step:31521 [D loss: 0.499454, acc.: 74.22%] [G loss: 1.523628]\n",
      "epoch:33 step:31522 [D loss: 0.828224, acc.: 50.00%] [G loss: 1.379093]\n",
      "epoch:33 step:31523 [D loss: 0.331513, acc.: 90.62%] [G loss: 1.326976]\n",
      "epoch:33 step:31524 [D loss: 0.506176, acc.: 74.22%] [G loss: 1.462064]\n",
      "epoch:33 step:31525 [D loss: 0.455395, acc.: 74.22%] [G loss: 1.563611]\n",
      "epoch:33 step:31526 [D loss: 0.850174, acc.: 47.66%] [G loss: 1.206561]\n",
      "epoch:33 step:31527 [D loss: 0.496606, acc.: 78.91%] [G loss: 1.415753]\n",
      "epoch:33 step:31528 [D loss: 0.425350, acc.: 80.47%] [G loss: 1.761256]\n",
      "epoch:33 step:31529 [D loss: 0.535695, acc.: 73.44%] [G loss: 1.210596]\n",
      "epoch:33 step:31530 [D loss: 0.542307, acc.: 71.09%] [G loss: 1.485475]\n",
      "epoch:33 step:31531 [D loss: 0.485763, acc.: 79.69%] [G loss: 1.573628]\n",
      "epoch:33 step:31532 [D loss: 0.627290, acc.: 64.06%] [G loss: 1.413524]\n",
      "epoch:33 step:31533 [D loss: 0.674921, acc.: 61.72%] [G loss: 0.920605]\n",
      "epoch:33 step:31534 [D loss: 0.454812, acc.: 78.12%] [G loss: 1.702907]\n",
      "epoch:33 step:31535 [D loss: 0.429332, acc.: 80.47%] [G loss: 1.360622]\n",
      "epoch:33 step:31536 [D loss: 0.478692, acc.: 77.34%] [G loss: 1.764865]\n",
      "epoch:33 step:31537 [D loss: 0.339043, acc.: 86.72%] [G loss: 1.663083]\n",
      "epoch:33 step:31538 [D loss: 0.406233, acc.: 82.81%] [G loss: 1.356559]\n",
      "epoch:33 step:31539 [D loss: 0.545175, acc.: 74.22%] [G loss: 1.450448]\n",
      "epoch:33 step:31540 [D loss: 0.485028, acc.: 75.00%] [G loss: 1.558736]\n",
      "epoch:33 step:31541 [D loss: 0.490185, acc.: 76.56%] [G loss: 1.096086]\n",
      "epoch:33 step:31542 [D loss: 0.610987, acc.: 71.09%] [G loss: 1.568433]\n",
      "epoch:33 step:31543 [D loss: 0.601344, acc.: 66.41%] [G loss: 2.013128]\n",
      "epoch:33 step:31544 [D loss: 0.434490, acc.: 81.25%] [G loss: 1.282502]\n",
      "epoch:33 step:31545 [D loss: 0.729394, acc.: 57.81%] [G loss: 0.999076]\n",
      "epoch:33 step:31546 [D loss: 0.562228, acc.: 70.31%] [G loss: 0.960122]\n",
      "epoch:33 step:31547 [D loss: 0.490799, acc.: 78.91%] [G loss: 1.557915]\n",
      "epoch:33 step:31548 [D loss: 0.551239, acc.: 69.53%] [G loss: 1.702197]\n",
      "epoch:33 step:31549 [D loss: 0.482850, acc.: 77.34%] [G loss: 1.598598]\n",
      "epoch:33 step:31550 [D loss: 0.393393, acc.: 85.16%] [G loss: 1.397274]\n",
      "epoch:33 step:31551 [D loss: 0.484277, acc.: 78.91%] [G loss: 2.443052]\n",
      "epoch:33 step:31552 [D loss: 0.463802, acc.: 78.12%] [G loss: 1.486460]\n",
      "epoch:33 step:31553 [D loss: 0.406799, acc.: 83.59%] [G loss: 1.144634]\n",
      "epoch:33 step:31554 [D loss: 0.608354, acc.: 68.75%] [G loss: 1.288587]\n",
      "epoch:33 step:31555 [D loss: 0.562734, acc.: 68.75%] [G loss: 1.700105]\n",
      "epoch:33 step:31556 [D loss: 0.735797, acc.: 55.47%] [G loss: 1.546968]\n",
      "epoch:33 step:31557 [D loss: 0.480819, acc.: 78.91%] [G loss: 1.438673]\n",
      "epoch:33 step:31558 [D loss: 0.591743, acc.: 68.75%] [G loss: 1.717365]\n",
      "epoch:33 step:31559 [D loss: 0.676878, acc.: 57.03%] [G loss: 1.511303]\n",
      "epoch:33 step:31560 [D loss: 0.801940, acc.: 52.34%] [G loss: 0.856524]\n",
      "epoch:33 step:31561 [D loss: 0.514396, acc.: 77.34%] [G loss: 1.450828]\n",
      "epoch:33 step:31562 [D loss: 0.772989, acc.: 51.56%] [G loss: 1.544652]\n",
      "epoch:33 step:31563 [D loss: 0.614456, acc.: 66.41%] [G loss: 1.333652]\n",
      "epoch:33 step:31564 [D loss: 0.736668, acc.: 55.47%] [G loss: 1.262893]\n",
      "epoch:33 step:31565 [D loss: 0.555087, acc.: 68.75%] [G loss: 1.236527]\n",
      "epoch:33 step:31566 [D loss: 0.649016, acc.: 65.62%] [G loss: 1.249178]\n",
      "epoch:33 step:31567 [D loss: 0.628538, acc.: 67.19%] [G loss: 1.216139]\n",
      "epoch:33 step:31568 [D loss: 0.880242, acc.: 42.97%] [G loss: 1.233449]\n",
      "epoch:33 step:31569 [D loss: 0.515538, acc.: 74.22%] [G loss: 1.547616]\n",
      "epoch:33 step:31570 [D loss: 0.416209, acc.: 86.72%] [G loss: 2.064549]\n",
      "epoch:33 step:31571 [D loss: 0.516406, acc.: 73.44%] [G loss: 1.717529]\n",
      "epoch:33 step:31572 [D loss: 0.538023, acc.: 70.31%] [G loss: 1.799214]\n",
      "epoch:33 step:31573 [D loss: 0.383845, acc.: 84.38%] [G loss: 2.013791]\n",
      "epoch:33 step:31574 [D loss: 0.573997, acc.: 71.09%] [G loss: 1.406014]\n",
      "epoch:33 step:31575 [D loss: 0.580267, acc.: 71.09%] [G loss: 1.308621]\n",
      "epoch:33 step:31576 [D loss: 0.659383, acc.: 61.72%] [G loss: 1.059061]\n",
      "epoch:33 step:31577 [D loss: 0.399768, acc.: 81.25%] [G loss: 1.568229]\n",
      "epoch:33 step:31578 [D loss: 0.444021, acc.: 80.47%] [G loss: 1.821137]\n",
      "epoch:33 step:31579 [D loss: 0.505133, acc.: 75.78%] [G loss: 1.717935]\n",
      "epoch:33 step:31580 [D loss: 0.551768, acc.: 69.53%] [G loss: 1.357329]\n",
      "epoch:33 step:31581 [D loss: 0.518705, acc.: 76.56%] [G loss: 1.957725]\n",
      "epoch:33 step:31582 [D loss: 0.445785, acc.: 82.03%] [G loss: 1.563171]\n",
      "epoch:33 step:31583 [D loss: 0.607071, acc.: 68.75%] [G loss: 1.332824]\n",
      "epoch:33 step:31584 [D loss: 0.608739, acc.: 67.19%] [G loss: 1.268945]\n",
      "epoch:33 step:31585 [D loss: 0.458721, acc.: 79.69%] [G loss: 1.578787]\n",
      "epoch:33 step:31586 [D loss: 0.449789, acc.: 78.91%] [G loss: 1.143567]\n",
      "epoch:33 step:31587 [D loss: 0.428201, acc.: 82.81%] [G loss: 1.071898]\n",
      "epoch:33 step:31588 [D loss: 0.621647, acc.: 68.75%] [G loss: 1.702198]\n",
      "epoch:33 step:31589 [D loss: 0.595338, acc.: 70.31%] [G loss: 1.435797]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:33 step:31590 [D loss: 0.380294, acc.: 86.72%] [G loss: 1.560735]\n",
      "epoch:33 step:31591 [D loss: 0.507591, acc.: 78.12%] [G loss: 1.678078]\n",
      "epoch:33 step:31592 [D loss: 0.403496, acc.: 80.47%] [G loss: 1.931411]\n",
      "epoch:33 step:31593 [D loss: 0.528256, acc.: 74.22%] [G loss: 1.875566]\n",
      "epoch:33 step:31594 [D loss: 0.579204, acc.: 69.53%] [G loss: 1.665605]\n",
      "epoch:33 step:31595 [D loss: 0.650733, acc.: 61.72%] [G loss: 1.382200]\n",
      "epoch:33 step:31596 [D loss: 0.510626, acc.: 77.34%] [G loss: 1.308690]\n",
      "epoch:33 step:31597 [D loss: 0.391153, acc.: 87.50%] [G loss: 1.800940]\n",
      "epoch:33 step:31598 [D loss: 0.515719, acc.: 75.00%] [G loss: 1.549856]\n",
      "epoch:33 step:31599 [D loss: 0.662797, acc.: 61.72%] [G loss: 1.507711]\n",
      "epoch:33 step:31600 [D loss: 0.622869, acc.: 66.41%] [G loss: 1.004674]\n",
      "epoch:33 step:31601 [D loss: 0.683713, acc.: 61.72%] [G loss: 1.339283]\n",
      "epoch:33 step:31602 [D loss: 0.491640, acc.: 78.91%] [G loss: 1.552444]\n",
      "epoch:33 step:31603 [D loss: 0.358166, acc.: 83.59%] [G loss: 1.274561]\n",
      "epoch:33 step:31604 [D loss: 0.616310, acc.: 67.19%] [G loss: 1.349227]\n",
      "epoch:33 step:31605 [D loss: 0.542531, acc.: 71.88%] [G loss: 1.486457]\n",
      "epoch:33 step:31606 [D loss: 0.586627, acc.: 71.88%] [G loss: 1.565473]\n",
      "epoch:33 step:31607 [D loss: 0.621679, acc.: 67.19%] [G loss: 1.626893]\n",
      "epoch:33 step:31608 [D loss: 0.534149, acc.: 74.22%] [G loss: 1.557929]\n",
      "epoch:33 step:31609 [D loss: 0.563629, acc.: 68.75%] [G loss: 1.694693]\n",
      "epoch:33 step:31610 [D loss: 0.436379, acc.: 82.03%] [G loss: 1.962580]\n",
      "epoch:33 step:31611 [D loss: 0.598704, acc.: 65.62%] [G loss: 1.407692]\n",
      "epoch:33 step:31612 [D loss: 0.446488, acc.: 83.59%] [G loss: 1.923197]\n",
      "epoch:33 step:31613 [D loss: 0.468692, acc.: 78.91%] [G loss: 1.906169]\n",
      "epoch:33 step:31614 [D loss: 0.569319, acc.: 72.66%] [G loss: 2.067078]\n",
      "epoch:33 step:31615 [D loss: 0.632112, acc.: 67.97%] [G loss: 1.192891]\n",
      "epoch:33 step:31616 [D loss: 0.569656, acc.: 71.88%] [G loss: 1.431066]\n",
      "epoch:33 step:31617 [D loss: 0.538177, acc.: 72.66%] [G loss: 1.553595]\n",
      "epoch:33 step:31618 [D loss: 0.440239, acc.: 82.03%] [G loss: 1.658702]\n",
      "epoch:33 step:31619 [D loss: 0.539332, acc.: 71.09%] [G loss: 1.311300]\n",
      "epoch:33 step:31620 [D loss: 0.413724, acc.: 85.94%] [G loss: 1.808609]\n",
      "epoch:33 step:31621 [D loss: 0.327482, acc.: 89.06%] [G loss: 1.190607]\n",
      "epoch:33 step:31622 [D loss: 0.463999, acc.: 80.47%] [G loss: 1.455460]\n",
      "epoch:33 step:31623 [D loss: 0.391164, acc.: 84.38%] [G loss: 1.679597]\n",
      "epoch:33 step:31624 [D loss: 0.478516, acc.: 79.69%] [G loss: 1.244858]\n",
      "epoch:33 step:31625 [D loss: 0.677132, acc.: 63.28%] [G loss: 1.635664]\n",
      "epoch:33 step:31626 [D loss: 0.775099, acc.: 57.81%] [G loss: 1.059224]\n",
      "epoch:33 step:31627 [D loss: 0.749725, acc.: 57.03%] [G loss: 1.433389]\n",
      "epoch:33 step:31628 [D loss: 0.575856, acc.: 70.31%] [G loss: 1.273234]\n",
      "epoch:33 step:31629 [D loss: 0.482251, acc.: 77.34%] [G loss: 1.089382]\n",
      "epoch:33 step:31630 [D loss: 0.518431, acc.: 75.00%] [G loss: 1.504176]\n",
      "epoch:33 step:31631 [D loss: 0.481288, acc.: 76.56%] [G loss: 1.466790]\n",
      "epoch:33 step:31632 [D loss: 0.530101, acc.: 73.44%] [G loss: 1.039239]\n",
      "epoch:33 step:31633 [D loss: 0.430509, acc.: 84.38%] [G loss: 1.285496]\n",
      "epoch:33 step:31634 [D loss: 0.688174, acc.: 63.28%] [G loss: 1.452269]\n",
      "epoch:33 step:31635 [D loss: 0.619614, acc.: 64.84%] [G loss: 0.709462]\n",
      "epoch:33 step:31636 [D loss: 0.586620, acc.: 71.88%] [G loss: 1.669453]\n",
      "epoch:33 step:31637 [D loss: 0.578513, acc.: 70.31%] [G loss: 1.272670]\n",
      "epoch:33 step:31638 [D loss: 0.559409, acc.: 71.09%] [G loss: 0.790682]\n",
      "epoch:33 step:31639 [D loss: 0.592116, acc.: 71.88%] [G loss: 1.103949]\n",
      "epoch:33 step:31640 [D loss: 0.632365, acc.: 68.75%] [G loss: 1.578145]\n",
      "epoch:33 step:31641 [D loss: 0.474319, acc.: 77.34%] [G loss: 1.636417]\n",
      "epoch:33 step:31642 [D loss: 0.463804, acc.: 76.56%] [G loss: 1.393919]\n",
      "epoch:33 step:31643 [D loss: 0.482302, acc.: 75.00%] [G loss: 1.360577]\n",
      "epoch:33 step:31644 [D loss: 0.522980, acc.: 75.78%] [G loss: 1.668702]\n",
      "epoch:33 step:31645 [D loss: 0.551447, acc.: 71.88%] [G loss: 1.559176]\n",
      "epoch:33 step:31646 [D loss: 0.528619, acc.: 74.22%] [G loss: 2.049528]\n",
      "epoch:33 step:31647 [D loss: 0.583233, acc.: 67.97%] [G loss: 1.607583]\n",
      "epoch:33 step:31648 [D loss: 0.445952, acc.: 80.47%] [G loss: 1.308944]\n",
      "epoch:33 step:31649 [D loss: 0.526319, acc.: 72.66%] [G loss: 1.901930]\n",
      "epoch:33 step:31650 [D loss: 0.466547, acc.: 77.34%] [G loss: 1.272468]\n",
      "epoch:33 step:31651 [D loss: 0.635586, acc.: 67.19%] [G loss: 1.324115]\n",
      "epoch:33 step:31652 [D loss: 0.509987, acc.: 74.22%] [G loss: 1.229208]\n",
      "epoch:33 step:31653 [D loss: 0.422989, acc.: 85.94%] [G loss: 1.512592]\n",
      "epoch:33 step:31654 [D loss: 0.718258, acc.: 60.94%] [G loss: 1.211890]\n",
      "epoch:33 step:31655 [D loss: 0.596868, acc.: 65.62%] [G loss: 2.033414]\n",
      "epoch:33 step:31656 [D loss: 0.600328, acc.: 64.84%] [G loss: 1.539432]\n",
      "epoch:33 step:31657 [D loss: 0.418419, acc.: 82.81%] [G loss: 1.304079]\n",
      "epoch:33 step:31658 [D loss: 0.586731, acc.: 70.31%] [G loss: 1.228185]\n",
      "epoch:33 step:31659 [D loss: 0.567015, acc.: 69.53%] [G loss: 1.024498]\n",
      "epoch:33 step:31660 [D loss: 0.365678, acc.: 87.50%] [G loss: 1.858952]\n",
      "epoch:33 step:31661 [D loss: 0.727828, acc.: 57.03%] [G loss: 1.870956]\n",
      "epoch:33 step:31662 [D loss: 0.538976, acc.: 73.44%] [G loss: 1.364951]\n",
      "epoch:33 step:31663 [D loss: 0.472241, acc.: 82.81%] [G loss: 1.566210]\n",
      "epoch:33 step:31664 [D loss: 0.784622, acc.: 49.22%] [G loss: 1.330974]\n",
      "epoch:33 step:31665 [D loss: 0.562109, acc.: 67.19%] [G loss: 1.464607]\n",
      "epoch:33 step:31666 [D loss: 0.495468, acc.: 80.47%] [G loss: 1.390058]\n",
      "epoch:33 step:31667 [D loss: 0.415977, acc.: 85.16%] [G loss: 1.814042]\n",
      "epoch:33 step:31668 [D loss: 0.372830, acc.: 88.28%] [G loss: 1.396654]\n",
      "epoch:33 step:31669 [D loss: 0.427527, acc.: 82.03%] [G loss: 1.382068]\n",
      "epoch:33 step:31670 [D loss: 0.711188, acc.: 59.38%] [G loss: 1.561836]\n",
      "epoch:33 step:31671 [D loss: 0.464803, acc.: 80.47%] [G loss: 1.756849]\n",
      "epoch:33 step:31672 [D loss: 0.591175, acc.: 70.31%] [G loss: 1.574072]\n",
      "epoch:33 step:31673 [D loss: 0.654005, acc.: 67.19%] [G loss: 1.220555]\n",
      "epoch:33 step:31674 [D loss: 0.399824, acc.: 81.25%] [G loss: 1.407026]\n",
      "epoch:33 step:31675 [D loss: 0.732594, acc.: 57.81%] [G loss: 1.712919]\n",
      "epoch:33 step:31676 [D loss: 0.462638, acc.: 78.12%] [G loss: 1.722813]\n",
      "epoch:33 step:31677 [D loss: 0.530355, acc.: 77.34%] [G loss: 1.644442]\n",
      "epoch:33 step:31678 [D loss: 0.524234, acc.: 75.00%] [G loss: 1.334123]\n",
      "epoch:33 step:31679 [D loss: 0.589148, acc.: 72.66%] [G loss: 1.443814]\n",
      "epoch:33 step:31680 [D loss: 0.376857, acc.: 87.50%] [G loss: 1.673682]\n",
      "epoch:33 step:31681 [D loss: 0.475327, acc.: 74.22%] [G loss: 1.632981]\n",
      "epoch:33 step:31682 [D loss: 0.850676, acc.: 46.09%] [G loss: 1.330970]\n",
      "epoch:33 step:31683 [D loss: 0.773226, acc.: 57.03%] [G loss: 1.015907]\n",
      "epoch:33 step:31684 [D loss: 0.495986, acc.: 76.56%] [G loss: 1.521620]\n",
      "epoch:33 step:31685 [D loss: 0.585668, acc.: 70.31%] [G loss: 1.096325]\n",
      "epoch:33 step:31686 [D loss: 0.499250, acc.: 77.34%] [G loss: 1.399401]\n",
      "epoch:33 step:31687 [D loss: 0.509827, acc.: 71.88%] [G loss: 1.556716]\n",
      "epoch:33 step:31688 [D loss: 0.374887, acc.: 84.38%] [G loss: 1.899938]\n",
      "epoch:33 step:31689 [D loss: 0.466048, acc.: 81.25%] [G loss: 1.499136]\n",
      "epoch:33 step:31690 [D loss: 0.504989, acc.: 72.66%] [G loss: 1.692947]\n",
      "epoch:33 step:31691 [D loss: 0.544624, acc.: 68.75%] [G loss: 1.955304]\n",
      "epoch:33 step:31692 [D loss: 0.701325, acc.: 60.94%] [G loss: 1.188900]\n",
      "epoch:33 step:31693 [D loss: 0.549781, acc.: 71.88%] [G loss: 1.202634]\n",
      "epoch:33 step:31694 [D loss: 0.824670, acc.: 47.66%] [G loss: 1.314222]\n",
      "epoch:33 step:31695 [D loss: 0.416425, acc.: 87.50%] [G loss: 1.502897]\n",
      "epoch:33 step:31696 [D loss: 0.499797, acc.: 73.44%] [G loss: 1.135345]\n",
      "epoch:33 step:31697 [D loss: 0.485649, acc.: 77.34%] [G loss: 1.416222]\n",
      "epoch:33 step:31698 [D loss: 0.559528, acc.: 67.97%] [G loss: 1.899698]\n",
      "epoch:33 step:31699 [D loss: 0.442650, acc.: 84.38%] [G loss: 1.500595]\n",
      "epoch:33 step:31700 [D loss: 0.465000, acc.: 74.22%] [G loss: 1.381800]\n",
      "epoch:33 step:31701 [D loss: 0.666547, acc.: 63.28%] [G loss: 1.500613]\n",
      "epoch:33 step:31702 [D loss: 0.509985, acc.: 78.12%] [G loss: 1.170981]\n",
      "epoch:33 step:31703 [D loss: 0.427737, acc.: 83.59%] [G loss: 1.738878]\n",
      "epoch:33 step:31704 [D loss: 0.570024, acc.: 68.75%] [G loss: 1.639308]\n",
      "epoch:33 step:31705 [D loss: 0.320031, acc.: 88.28%] [G loss: 1.876043]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:33 step:31706 [D loss: 0.668697, acc.: 65.62%] [G loss: 1.292915]\n",
      "epoch:33 step:31707 [D loss: 0.447541, acc.: 77.34%] [G loss: 1.576868]\n",
      "epoch:33 step:31708 [D loss: 0.609996, acc.: 61.72%] [G loss: 1.316289]\n",
      "epoch:33 step:31709 [D loss: 0.660394, acc.: 61.72%] [G loss: 1.568601]\n",
      "epoch:33 step:31710 [D loss: 0.714766, acc.: 56.25%] [G loss: 1.738124]\n",
      "epoch:33 step:31711 [D loss: 0.570386, acc.: 69.53%] [G loss: 0.828718]\n",
      "epoch:33 step:31712 [D loss: 0.509268, acc.: 77.34%] [G loss: 1.166636]\n",
      "epoch:33 step:31713 [D loss: 0.404446, acc.: 83.59%] [G loss: 1.157067]\n",
      "epoch:33 step:31714 [D loss: 0.477844, acc.: 75.00%] [G loss: 1.608728]\n",
      "epoch:33 step:31715 [D loss: 0.616451, acc.: 66.41%] [G loss: 1.222910]\n",
      "epoch:33 step:31716 [D loss: 0.453909, acc.: 78.91%] [G loss: 1.421793]\n",
      "epoch:33 step:31717 [D loss: 0.673193, acc.: 60.94%] [G loss: 1.258463]\n",
      "epoch:33 step:31718 [D loss: 0.571181, acc.: 67.97%] [G loss: 1.508616]\n",
      "epoch:33 step:31719 [D loss: 0.570539, acc.: 72.66%] [G loss: 1.581132]\n",
      "epoch:33 step:31720 [D loss: 0.422191, acc.: 82.03%] [G loss: 1.716142]\n",
      "epoch:33 step:31721 [D loss: 0.720628, acc.: 62.50%] [G loss: 1.406212]\n",
      "epoch:33 step:31722 [D loss: 0.566324, acc.: 73.44%] [G loss: 1.324318]\n",
      "epoch:33 step:31723 [D loss: 0.930698, acc.: 39.06%] [G loss: 0.665032]\n",
      "epoch:33 step:31724 [D loss: 0.680258, acc.: 57.03%] [G loss: 1.245150]\n",
      "epoch:33 step:31725 [D loss: 0.337806, acc.: 90.62%] [G loss: 1.722092]\n",
      "epoch:33 step:31726 [D loss: 0.518635, acc.: 77.34%] [G loss: 1.328029]\n",
      "epoch:33 step:31727 [D loss: 0.514506, acc.: 75.78%] [G loss: 1.641586]\n",
      "epoch:33 step:31728 [D loss: 0.418393, acc.: 82.03%] [G loss: 1.334688]\n",
      "epoch:33 step:31729 [D loss: 0.562939, acc.: 67.97%] [G loss: 0.988315]\n",
      "epoch:33 step:31730 [D loss: 0.474533, acc.: 79.69%] [G loss: 1.057682]\n",
      "epoch:33 step:31731 [D loss: 0.385892, acc.: 82.81%] [G loss: 1.918112]\n",
      "epoch:33 step:31732 [D loss: 0.574978, acc.: 64.06%] [G loss: 1.687380]\n",
      "epoch:33 step:31733 [D loss: 0.599521, acc.: 70.31%] [G loss: 1.583929]\n",
      "epoch:33 step:31734 [D loss: 0.559018, acc.: 73.44%] [G loss: 1.642691]\n",
      "epoch:33 step:31735 [D loss: 0.556117, acc.: 73.44%] [G loss: 1.404772]\n",
      "epoch:33 step:31736 [D loss: 0.532472, acc.: 75.00%] [G loss: 1.539742]\n",
      "epoch:33 step:31737 [D loss: 0.445947, acc.: 83.59%] [G loss: 1.670337]\n",
      "epoch:33 step:31738 [D loss: 0.502010, acc.: 76.56%] [G loss: 1.483766]\n",
      "epoch:33 step:31739 [D loss: 0.520162, acc.: 74.22%] [G loss: 1.498255]\n",
      "epoch:33 step:31740 [D loss: 0.504747, acc.: 75.78%] [G loss: 1.488778]\n",
      "epoch:33 step:31741 [D loss: 0.459007, acc.: 81.25%] [G loss: 1.483566]\n",
      "epoch:33 step:31742 [D loss: 0.465767, acc.: 80.47%] [G loss: 1.381826]\n",
      "epoch:33 step:31743 [D loss: 0.521091, acc.: 71.88%] [G loss: 1.416886]\n",
      "epoch:33 step:31744 [D loss: 0.481229, acc.: 75.78%] [G loss: 0.935954]\n",
      "epoch:33 step:31745 [D loss: 0.411486, acc.: 78.91%] [G loss: 2.030361]\n",
      "epoch:33 step:31746 [D loss: 0.414834, acc.: 85.16%] [G loss: 1.402959]\n",
      "epoch:33 step:31747 [D loss: 0.734115, acc.: 56.25%] [G loss: 0.997805]\n",
      "epoch:33 step:31748 [D loss: 0.601960, acc.: 67.19%] [G loss: 1.492682]\n",
      "epoch:33 step:31749 [D loss: 0.546128, acc.: 73.44%] [G loss: 1.846542]\n",
      "epoch:33 step:31750 [D loss: 0.555821, acc.: 71.88%] [G loss: 1.324029]\n",
      "epoch:33 step:31751 [D loss: 0.490806, acc.: 77.34%] [G loss: 1.511987]\n",
      "epoch:33 step:31752 [D loss: 0.788206, acc.: 50.78%] [G loss: 1.378814]\n",
      "epoch:33 step:31753 [D loss: 0.582174, acc.: 71.09%] [G loss: 1.608075]\n",
      "epoch:33 step:31754 [D loss: 0.594144, acc.: 70.31%] [G loss: 1.808826]\n",
      "epoch:33 step:31755 [D loss: 0.572015, acc.: 69.53%] [G loss: 1.353927]\n",
      "epoch:33 step:31756 [D loss: 0.413115, acc.: 81.25%] [G loss: 1.530484]\n",
      "epoch:33 step:31757 [D loss: 0.651227, acc.: 64.06%] [G loss: 1.836602]\n",
      "epoch:33 step:31758 [D loss: 0.720380, acc.: 61.72%] [G loss: 1.397063]\n",
      "epoch:33 step:31759 [D loss: 0.511286, acc.: 71.88%] [G loss: 1.370232]\n",
      "epoch:33 step:31760 [D loss: 0.444147, acc.: 78.12%] [G loss: 1.780666]\n",
      "epoch:33 step:31761 [D loss: 0.564853, acc.: 71.88%] [G loss: 1.679126]\n",
      "epoch:33 step:31762 [D loss: 0.426671, acc.: 79.69%] [G loss: 1.563255]\n",
      "epoch:33 step:31763 [D loss: 0.509155, acc.: 73.44%] [G loss: 0.966009]\n",
      "epoch:33 step:31764 [D loss: 0.423669, acc.: 80.47%] [G loss: 1.342855]\n",
      "epoch:33 step:31765 [D loss: 0.728363, acc.: 52.34%] [G loss: 0.980279]\n",
      "epoch:33 step:31766 [D loss: 0.815814, acc.: 51.56%] [G loss: 0.948986]\n",
      "epoch:33 step:31767 [D loss: 0.844783, acc.: 53.12%] [G loss: 0.669583]\n",
      "epoch:33 step:31768 [D loss: 0.661736, acc.: 66.41%] [G loss: 1.269262]\n",
      "epoch:33 step:31769 [D loss: 0.632615, acc.: 62.50%] [G loss: 1.448062]\n",
      "epoch:33 step:31770 [D loss: 0.441269, acc.: 85.94%] [G loss: 2.431118]\n",
      "epoch:33 step:31771 [D loss: 0.582645, acc.: 64.84%] [G loss: 2.097868]\n",
      "epoch:33 step:31772 [D loss: 0.657318, acc.: 64.84%] [G loss: 1.808445]\n",
      "epoch:33 step:31773 [D loss: 0.571396, acc.: 74.22%] [G loss: 1.249641]\n",
      "epoch:33 step:31774 [D loss: 0.622379, acc.: 61.72%] [G loss: 1.088621]\n",
      "epoch:33 step:31775 [D loss: 0.554260, acc.: 69.53%] [G loss: 1.869787]\n",
      "epoch:33 step:31776 [D loss: 0.464638, acc.: 80.47%] [G loss: 1.418652]\n",
      "epoch:33 step:31777 [D loss: 0.438106, acc.: 82.03%] [G loss: 2.171116]\n",
      "epoch:33 step:31778 [D loss: 0.736420, acc.: 60.16%] [G loss: 1.504692]\n",
      "epoch:33 step:31779 [D loss: 0.398290, acc.: 84.38%] [G loss: 1.669980]\n",
      "epoch:33 step:31780 [D loss: 0.586237, acc.: 71.88%] [G loss: 1.495732]\n",
      "epoch:33 step:31781 [D loss: 0.560564, acc.: 70.31%] [G loss: 1.212107]\n",
      "epoch:33 step:31782 [D loss: 0.594818, acc.: 71.88%] [G loss: 1.645557]\n",
      "epoch:33 step:31783 [D loss: 0.809290, acc.: 54.69%] [G loss: 1.613255]\n",
      "epoch:33 step:31784 [D loss: 0.655759, acc.: 63.28%] [G loss: 1.659820]\n",
      "epoch:33 step:31785 [D loss: 0.366217, acc.: 81.25%] [G loss: 1.704857]\n",
      "epoch:33 step:31786 [D loss: 0.657944, acc.: 67.19%] [G loss: 1.214766]\n",
      "epoch:33 step:31787 [D loss: 0.459007, acc.: 77.34%] [G loss: 1.799431]\n",
      "epoch:33 step:31788 [D loss: 0.725493, acc.: 50.00%] [G loss: 1.071064]\n",
      "epoch:33 step:31789 [D loss: 0.409397, acc.: 82.81%] [G loss: 1.477290]\n",
      "epoch:33 step:31790 [D loss: 0.384622, acc.: 85.94%] [G loss: 1.481344]\n",
      "epoch:33 step:31791 [D loss: 0.502273, acc.: 78.91%] [G loss: 1.599587]\n",
      "epoch:33 step:31792 [D loss: 0.645292, acc.: 65.62%] [G loss: 1.201524]\n",
      "epoch:33 step:31793 [D loss: 0.452231, acc.: 81.25%] [G loss: 1.515881]\n",
      "epoch:33 step:31794 [D loss: 0.316230, acc.: 89.84%] [G loss: 2.045729]\n",
      "epoch:33 step:31795 [D loss: 0.385819, acc.: 84.38%] [G loss: 1.679969]\n",
      "epoch:33 step:31796 [D loss: 0.641637, acc.: 67.19%] [G loss: 1.481230]\n",
      "epoch:33 step:31797 [D loss: 0.577126, acc.: 70.31%] [G loss: 1.840802]\n",
      "epoch:33 step:31798 [D loss: 0.374071, acc.: 88.28%] [G loss: 1.356276]\n",
      "epoch:33 step:31799 [D loss: 0.551324, acc.: 69.53%] [G loss: 2.537817]\n",
      "epoch:33 step:31800 [D loss: 0.611514, acc.: 63.28%] [G loss: 1.560321]\n",
      "epoch:33 step:31801 [D loss: 0.413281, acc.: 80.47%] [G loss: 1.708914]\n",
      "epoch:33 step:31802 [D loss: 0.502006, acc.: 76.56%] [G loss: 1.575253]\n",
      "epoch:33 step:31803 [D loss: 0.396349, acc.: 83.59%] [G loss: 1.180034]\n",
      "epoch:33 step:31804 [D loss: 0.606649, acc.: 67.97%] [G loss: 1.489915]\n",
      "epoch:33 step:31805 [D loss: 0.508058, acc.: 73.44%] [G loss: 1.892017]\n",
      "epoch:33 step:31806 [D loss: 0.486103, acc.: 74.22%] [G loss: 1.137487]\n",
      "epoch:33 step:31807 [D loss: 0.574314, acc.: 71.88%] [G loss: 1.179434]\n",
      "epoch:33 step:31808 [D loss: 0.468581, acc.: 75.00%] [G loss: 1.611824]\n",
      "epoch:33 step:31809 [D loss: 0.667773, acc.: 64.84%] [G loss: 1.397177]\n",
      "epoch:33 step:31810 [D loss: 0.650675, acc.: 63.28%] [G loss: 1.095893]\n",
      "epoch:33 step:31811 [D loss: 0.628264, acc.: 69.53%] [G loss: 1.527645]\n",
      "epoch:33 step:31812 [D loss: 0.620278, acc.: 63.28%] [G loss: 1.469060]\n",
      "epoch:33 step:31813 [D loss: 0.490364, acc.: 74.22%] [G loss: 1.714473]\n",
      "epoch:33 step:31814 [D loss: 0.559682, acc.: 73.44%] [G loss: 1.921422]\n",
      "epoch:33 step:31815 [D loss: 0.650010, acc.: 64.06%] [G loss: 1.357781]\n",
      "epoch:33 step:31816 [D loss: 0.479674, acc.: 75.78%] [G loss: 1.590465]\n",
      "epoch:33 step:31817 [D loss: 0.519470, acc.: 75.78%] [G loss: 0.961864]\n",
      "epoch:33 step:31818 [D loss: 0.536864, acc.: 72.66%] [G loss: 2.098930]\n",
      "epoch:33 step:31819 [D loss: 0.508936, acc.: 75.78%] [G loss: 1.333405]\n",
      "epoch:33 step:31820 [D loss: 0.582151, acc.: 71.88%] [G loss: 1.668108]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:33 step:31821 [D loss: 0.517451, acc.: 75.78%] [G loss: 1.703117]\n",
      "epoch:33 step:31822 [D loss: 0.610084, acc.: 66.41%] [G loss: 1.144125]\n",
      "epoch:33 step:31823 [D loss: 0.534246, acc.: 72.66%] [G loss: 1.100501]\n",
      "epoch:33 step:31824 [D loss: 0.706035, acc.: 62.50%] [G loss: 0.942308]\n",
      "epoch:33 step:31825 [D loss: 0.448601, acc.: 82.03%] [G loss: 1.011468]\n",
      "epoch:33 step:31826 [D loss: 0.462004, acc.: 78.91%] [G loss: 1.196606]\n",
      "epoch:33 step:31827 [D loss: 0.613456, acc.: 65.62%] [G loss: 1.546879]\n",
      "epoch:33 step:31828 [D loss: 0.540876, acc.: 72.66%] [G loss: 1.454325]\n",
      "epoch:33 step:31829 [D loss: 0.478245, acc.: 78.12%] [G loss: 1.880884]\n",
      "epoch:33 step:31830 [D loss: 0.511316, acc.: 74.22%] [G loss: 1.085541]\n",
      "epoch:33 step:31831 [D loss: 0.375231, acc.: 83.59%] [G loss: 1.372197]\n",
      "epoch:33 step:31832 [D loss: 0.496339, acc.: 78.91%] [G loss: 1.347902]\n",
      "epoch:33 step:31833 [D loss: 0.523981, acc.: 78.91%] [G loss: 1.485671]\n",
      "epoch:33 step:31834 [D loss: 0.860275, acc.: 48.44%] [G loss: 1.345645]\n",
      "epoch:33 step:31835 [D loss: 0.726744, acc.: 57.81%] [G loss: 1.473476]\n",
      "epoch:33 step:31836 [D loss: 0.561768, acc.: 72.66%] [G loss: 1.157247]\n",
      "epoch:33 step:31837 [D loss: 0.448701, acc.: 79.69%] [G loss: 1.513775]\n",
      "epoch:33 step:31838 [D loss: 0.693414, acc.: 67.97%] [G loss: 1.568401]\n",
      "epoch:33 step:31839 [D loss: 0.457586, acc.: 79.69%] [G loss: 1.719224]\n",
      "epoch:33 step:31840 [D loss: 0.498980, acc.: 78.12%] [G loss: 1.531308]\n",
      "epoch:33 step:31841 [D loss: 0.453963, acc.: 81.25%] [G loss: 1.247145]\n",
      "epoch:33 step:31842 [D loss: 0.687262, acc.: 60.16%] [G loss: 1.403452]\n",
      "epoch:33 step:31843 [D loss: 0.598111, acc.: 69.53%] [G loss: 1.317395]\n",
      "epoch:33 step:31844 [D loss: 0.962979, acc.: 39.06%] [G loss: 1.520442]\n",
      "epoch:33 step:31845 [D loss: 0.540439, acc.: 75.00%] [G loss: 1.719900]\n",
      "epoch:33 step:31846 [D loss: 0.508263, acc.: 79.69%] [G loss: 1.467094]\n",
      "epoch:33 step:31847 [D loss: 0.481756, acc.: 75.00%] [G loss: 1.188903]\n",
      "epoch:33 step:31848 [D loss: 0.651286, acc.: 61.72%] [G loss: 1.496345]\n",
      "epoch:33 step:31849 [D loss: 0.516931, acc.: 73.44%] [G loss: 1.728981]\n",
      "epoch:33 step:31850 [D loss: 0.489985, acc.: 73.44%] [G loss: 1.390561]\n",
      "epoch:33 step:31851 [D loss: 0.614984, acc.: 68.75%] [G loss: 1.439310]\n",
      "epoch:33 step:31852 [D loss: 0.652477, acc.: 61.72%] [G loss: 1.284213]\n",
      "epoch:33 step:31853 [D loss: 0.310470, acc.: 93.75%] [G loss: 1.427203]\n",
      "epoch:33 step:31854 [D loss: 0.517226, acc.: 75.78%] [G loss: 1.586929]\n",
      "epoch:33 step:31855 [D loss: 0.576400, acc.: 70.31%] [G loss: 1.824115]\n",
      "epoch:33 step:31856 [D loss: 0.573068, acc.: 67.97%] [G loss: 1.134071]\n",
      "epoch:33 step:31857 [D loss: 0.490550, acc.: 75.78%] [G loss: 1.529698]\n",
      "epoch:33 step:31858 [D loss: 0.482177, acc.: 78.91%] [G loss: 1.527020]\n",
      "epoch:34 step:31859 [D loss: 0.530262, acc.: 71.09%] [G loss: 1.385534]\n",
      "epoch:34 step:31860 [D loss: 0.457651, acc.: 77.34%] [G loss: 1.522101]\n",
      "epoch:34 step:31861 [D loss: 0.653443, acc.: 64.06%] [G loss: 1.330175]\n",
      "epoch:34 step:31862 [D loss: 0.559960, acc.: 75.78%] [G loss: 1.582604]\n",
      "epoch:34 step:31863 [D loss: 0.568489, acc.: 71.88%] [G loss: 1.295583]\n",
      "epoch:34 step:31864 [D loss: 0.519670, acc.: 75.00%] [G loss: 1.487752]\n",
      "epoch:34 step:31865 [D loss: 0.564364, acc.: 72.66%] [G loss: 1.300021]\n",
      "epoch:34 step:31866 [D loss: 0.393587, acc.: 83.59%] [G loss: 1.109547]\n",
      "epoch:34 step:31867 [D loss: 0.631375, acc.: 67.97%] [G loss: 1.298661]\n",
      "epoch:34 step:31868 [D loss: 0.554618, acc.: 74.22%] [G loss: 1.476940]\n",
      "epoch:34 step:31869 [D loss: 0.476853, acc.: 79.69%] [G loss: 1.544906]\n",
      "epoch:34 step:31870 [D loss: 0.478551, acc.: 76.56%] [G loss: 1.595255]\n",
      "epoch:34 step:31871 [D loss: 0.532928, acc.: 72.66%] [G loss: 1.627682]\n",
      "epoch:34 step:31872 [D loss: 0.495349, acc.: 74.22%] [G loss: 1.731819]\n",
      "epoch:34 step:31873 [D loss: 0.413903, acc.: 83.59%] [G loss: 1.319951]\n",
      "epoch:34 step:31874 [D loss: 0.556299, acc.: 71.88%] [G loss: 1.980039]\n",
      "epoch:34 step:31875 [D loss: 0.593153, acc.: 71.88%] [G loss: 1.512889]\n",
      "epoch:34 step:31876 [D loss: 0.633522, acc.: 65.62%] [G loss: 2.069352]\n",
      "epoch:34 step:31877 [D loss: 0.532010, acc.: 71.09%] [G loss: 0.968749]\n",
      "epoch:34 step:31878 [D loss: 0.560131, acc.: 75.00%] [G loss: 1.332460]\n",
      "epoch:34 step:31879 [D loss: 0.659411, acc.: 55.47%] [G loss: 1.129314]\n",
      "epoch:34 step:31880 [D loss: 0.400494, acc.: 83.59%] [G loss: 1.687147]\n",
      "epoch:34 step:31881 [D loss: 0.500082, acc.: 76.56%] [G loss: 1.555904]\n",
      "epoch:34 step:31882 [D loss: 0.476088, acc.: 78.91%] [G loss: 1.455340]\n",
      "epoch:34 step:31883 [D loss: 0.708475, acc.: 57.81%] [G loss: 1.532223]\n",
      "epoch:34 step:31884 [D loss: 0.519415, acc.: 75.00%] [G loss: 1.323575]\n",
      "epoch:34 step:31885 [D loss: 0.586815, acc.: 70.31%] [G loss: 1.351052]\n",
      "epoch:34 step:31886 [D loss: 0.406239, acc.: 85.94%] [G loss: 1.417009]\n",
      "epoch:34 step:31887 [D loss: 0.578526, acc.: 71.88%] [G loss: 1.414103]\n",
      "epoch:34 step:31888 [D loss: 0.568824, acc.: 71.09%] [G loss: 1.156460]\n",
      "epoch:34 step:31889 [D loss: 0.453269, acc.: 79.69%] [G loss: 1.931573]\n",
      "epoch:34 step:31890 [D loss: 0.478699, acc.: 76.56%] [G loss: 1.012650]\n",
      "epoch:34 step:31891 [D loss: 0.494374, acc.: 73.44%] [G loss: 1.310269]\n",
      "epoch:34 step:31892 [D loss: 0.393504, acc.: 85.94%] [G loss: 1.507487]\n",
      "epoch:34 step:31893 [D loss: 0.634358, acc.: 65.62%] [G loss: 1.351968]\n",
      "epoch:34 step:31894 [D loss: 0.517444, acc.: 75.78%] [G loss: 1.665250]\n",
      "epoch:34 step:31895 [D loss: 0.442199, acc.: 77.34%] [G loss: 1.891068]\n",
      "epoch:34 step:31896 [D loss: 0.610438, acc.: 67.19%] [G loss: 1.744076]\n",
      "epoch:34 step:31897 [D loss: 0.677349, acc.: 60.94%] [G loss: 1.067769]\n",
      "epoch:34 step:31898 [D loss: 0.601209, acc.: 69.53%] [G loss: 1.424695]\n",
      "epoch:34 step:31899 [D loss: 0.559780, acc.: 74.22%] [G loss: 1.751086]\n",
      "epoch:34 step:31900 [D loss: 0.630526, acc.: 67.97%] [G loss: 1.982421]\n",
      "epoch:34 step:31901 [D loss: 0.752479, acc.: 53.91%] [G loss: 1.145172]\n",
      "epoch:34 step:31902 [D loss: 0.664646, acc.: 64.06%] [G loss: 1.049316]\n",
      "epoch:34 step:31903 [D loss: 0.539213, acc.: 76.56%] [G loss: 1.082349]\n",
      "epoch:34 step:31904 [D loss: 0.706936, acc.: 59.38%] [G loss: 1.262646]\n",
      "epoch:34 step:31905 [D loss: 0.417125, acc.: 84.38%] [G loss: 1.517945]\n",
      "epoch:34 step:31906 [D loss: 0.534782, acc.: 71.88%] [G loss: 1.272535]\n",
      "epoch:34 step:31907 [D loss: 0.430915, acc.: 81.25%] [G loss: 1.329909]\n",
      "epoch:34 step:31908 [D loss: 0.365481, acc.: 89.84%] [G loss: 1.422841]\n",
      "epoch:34 step:31909 [D loss: 0.463225, acc.: 79.69%] [G loss: 1.599500]\n",
      "epoch:34 step:31910 [D loss: 0.550291, acc.: 70.31%] [G loss: 1.233441]\n",
      "epoch:34 step:31911 [D loss: 0.365690, acc.: 84.38%] [G loss: 1.574531]\n",
      "epoch:34 step:31912 [D loss: 0.457571, acc.: 79.69%] [G loss: 1.651242]\n",
      "epoch:34 step:31913 [D loss: 0.735925, acc.: 55.47%] [G loss: 1.165895]\n",
      "epoch:34 step:31914 [D loss: 0.548026, acc.: 67.97%] [G loss: 1.672327]\n",
      "epoch:34 step:31915 [D loss: 0.607263, acc.: 67.19%] [G loss: 1.557832]\n",
      "epoch:34 step:31916 [D loss: 0.568191, acc.: 72.66%] [G loss: 1.311717]\n",
      "epoch:34 step:31917 [D loss: 0.364499, acc.: 87.50%] [G loss: 1.498163]\n",
      "epoch:34 step:31918 [D loss: 0.535203, acc.: 70.31%] [G loss: 1.459730]\n",
      "epoch:34 step:31919 [D loss: 0.460343, acc.: 77.34%] [G loss: 1.803854]\n",
      "epoch:34 step:31920 [D loss: 0.653294, acc.: 61.72%] [G loss: 1.186864]\n",
      "epoch:34 step:31921 [D loss: 0.655880, acc.: 62.50%] [G loss: 1.600232]\n",
      "epoch:34 step:31922 [D loss: 0.668645, acc.: 65.62%] [G loss: 1.401938]\n",
      "epoch:34 step:31923 [D loss: 0.366633, acc.: 87.50%] [G loss: 1.576280]\n",
      "epoch:34 step:31924 [D loss: 0.510369, acc.: 75.78%] [G loss: 1.444841]\n",
      "epoch:34 step:31925 [D loss: 0.314221, acc.: 90.62%] [G loss: 2.104963]\n",
      "epoch:34 step:31926 [D loss: 0.549802, acc.: 71.88%] [G loss: 1.956545]\n",
      "epoch:34 step:31927 [D loss: 0.370849, acc.: 85.94%] [G loss: 1.439902]\n",
      "epoch:34 step:31928 [D loss: 0.619641, acc.: 67.97%] [G loss: 1.427790]\n",
      "epoch:34 step:31929 [D loss: 0.536977, acc.: 74.22%] [G loss: 1.392364]\n",
      "epoch:34 step:31930 [D loss: 0.377702, acc.: 86.72%] [G loss: 1.551550]\n",
      "epoch:34 step:31931 [D loss: 0.395219, acc.: 81.25%] [G loss: 1.551028]\n",
      "epoch:34 step:31932 [D loss: 0.399675, acc.: 84.38%] [G loss: 1.724148]\n",
      "epoch:34 step:31933 [D loss: 0.633431, acc.: 68.75%] [G loss: 1.213011]\n",
      "epoch:34 step:31934 [D loss: 0.576529, acc.: 75.78%] [G loss: 1.260020]\n",
      "epoch:34 step:31935 [D loss: 0.502661, acc.: 74.22%] [G loss: 1.423126]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:34 step:31936 [D loss: 0.583966, acc.: 69.53%] [G loss: 1.301408]\n",
      "epoch:34 step:31937 [D loss: 0.801427, acc.: 51.56%] [G loss: 1.337587]\n",
      "epoch:34 step:31938 [D loss: 0.463476, acc.: 75.78%] [G loss: 1.090876]\n",
      "epoch:34 step:31939 [D loss: 0.634443, acc.: 64.84%] [G loss: 1.729625]\n",
      "epoch:34 step:31940 [D loss: 0.373250, acc.: 83.59%] [G loss: 1.739654]\n",
      "epoch:34 step:31941 [D loss: 0.756918, acc.: 57.03%] [G loss: 1.004920]\n",
      "epoch:34 step:31942 [D loss: 0.758657, acc.: 57.03%] [G loss: 1.477910]\n",
      "epoch:34 step:31943 [D loss: 0.374528, acc.: 88.28%] [G loss: 1.874196]\n",
      "epoch:34 step:31944 [D loss: 0.498081, acc.: 75.00%] [G loss: 1.206142]\n",
      "epoch:34 step:31945 [D loss: 0.701348, acc.: 56.25%] [G loss: 1.570588]\n",
      "epoch:34 step:31946 [D loss: 0.590153, acc.: 66.41%] [G loss: 1.892120]\n",
      "epoch:34 step:31947 [D loss: 0.455377, acc.: 79.69%] [G loss: 1.240824]\n",
      "epoch:34 step:31948 [D loss: 0.490281, acc.: 79.69%] [G loss: 1.612973]\n",
      "epoch:34 step:31949 [D loss: 0.507382, acc.: 74.22%] [G loss: 1.243843]\n",
      "epoch:34 step:31950 [D loss: 0.492933, acc.: 77.34%] [G loss: 1.740230]\n",
      "epoch:34 step:31951 [D loss: 0.450173, acc.: 79.69%] [G loss: 1.105822]\n",
      "epoch:34 step:31952 [D loss: 0.467454, acc.: 82.81%] [G loss: 1.780771]\n",
      "epoch:34 step:31953 [D loss: 0.504993, acc.: 74.22%] [G loss: 1.887449]\n",
      "epoch:34 step:31954 [D loss: 0.584082, acc.: 64.84%] [G loss: 1.287327]\n",
      "epoch:34 step:31955 [D loss: 0.622308, acc.: 68.75%] [G loss: 1.421989]\n",
      "epoch:34 step:31956 [D loss: 0.451476, acc.: 80.47%] [G loss: 1.237244]\n",
      "epoch:34 step:31957 [D loss: 0.581482, acc.: 69.53%] [G loss: 1.563231]\n",
      "epoch:34 step:31958 [D loss: 0.308603, acc.: 91.41%] [G loss: 1.460314]\n",
      "epoch:34 step:31959 [D loss: 0.452498, acc.: 79.69%] [G loss: 1.226789]\n",
      "epoch:34 step:31960 [D loss: 0.560683, acc.: 68.75%] [G loss: 0.992628]\n",
      "epoch:34 step:31961 [D loss: 0.550900, acc.: 70.31%] [G loss: 1.237578]\n",
      "epoch:34 step:31962 [D loss: 0.435199, acc.: 79.69%] [G loss: 1.610212]\n",
      "epoch:34 step:31963 [D loss: 0.655551, acc.: 61.72%] [G loss: 1.256021]\n",
      "epoch:34 step:31964 [D loss: 0.787434, acc.: 55.47%] [G loss: 0.968088]\n",
      "epoch:34 step:31965 [D loss: 0.501753, acc.: 75.78%] [G loss: 1.347671]\n",
      "epoch:34 step:31966 [D loss: 0.516676, acc.: 76.56%] [G loss: 1.618663]\n",
      "epoch:34 step:31967 [D loss: 0.454314, acc.: 78.91%] [G loss: 1.286993]\n",
      "epoch:34 step:31968 [D loss: 0.518946, acc.: 75.78%] [G loss: 1.323887]\n",
      "epoch:34 step:31969 [D loss: 0.555910, acc.: 67.19%] [G loss: 1.965155]\n",
      "epoch:34 step:31970 [D loss: 0.426444, acc.: 80.47%] [G loss: 1.721804]\n",
      "epoch:34 step:31971 [D loss: 0.442142, acc.: 79.69%] [G loss: 1.581939]\n",
      "epoch:34 step:31972 [D loss: 0.346965, acc.: 85.94%] [G loss: 1.600893]\n",
      "epoch:34 step:31973 [D loss: 0.435672, acc.: 80.47%] [G loss: 1.815343]\n",
      "epoch:34 step:31974 [D loss: 0.437042, acc.: 78.91%] [G loss: 1.968437]\n",
      "epoch:34 step:31975 [D loss: 0.420378, acc.: 81.25%] [G loss: 1.150256]\n",
      "epoch:34 step:31976 [D loss: 0.644754, acc.: 62.50%] [G loss: 1.149777]\n",
      "epoch:34 step:31977 [D loss: 0.360491, acc.: 87.50%] [G loss: 1.679329]\n",
      "epoch:34 step:31978 [D loss: 0.541101, acc.: 71.09%] [G loss: 1.216108]\n",
      "epoch:34 step:31979 [D loss: 0.426686, acc.: 82.81%] [G loss: 1.332435]\n",
      "epoch:34 step:31980 [D loss: 0.710391, acc.: 60.16%] [G loss: 1.325544]\n",
      "epoch:34 step:31981 [D loss: 0.409718, acc.: 84.38%] [G loss: 1.695516]\n",
      "epoch:34 step:31982 [D loss: 0.636101, acc.: 60.94%] [G loss: 1.145419]\n",
      "epoch:34 step:31983 [D loss: 0.447359, acc.: 79.69%] [G loss: 1.665830]\n",
      "epoch:34 step:31984 [D loss: 0.501695, acc.: 75.78%] [G loss: 1.753058]\n",
      "epoch:34 step:31985 [D loss: 0.678369, acc.: 65.62%] [G loss: 1.507090]\n",
      "epoch:34 step:31986 [D loss: 0.374931, acc.: 87.50%] [G loss: 1.138067]\n",
      "epoch:34 step:31987 [D loss: 0.346277, acc.: 88.28%] [G loss: 1.831737]\n",
      "epoch:34 step:31988 [D loss: 0.663413, acc.: 62.50%] [G loss: 1.190688]\n",
      "epoch:34 step:31989 [D loss: 0.532179, acc.: 75.78%] [G loss: 1.641278]\n",
      "epoch:34 step:31990 [D loss: 0.575904, acc.: 71.88%] [G loss: 1.858782]\n",
      "epoch:34 step:31991 [D loss: 0.476404, acc.: 78.12%] [G loss: 1.607014]\n",
      "epoch:34 step:31992 [D loss: 0.502385, acc.: 76.56%] [G loss: 1.109292]\n",
      "epoch:34 step:31993 [D loss: 0.423425, acc.: 78.91%] [G loss: 1.342005]\n",
      "epoch:34 step:31994 [D loss: 0.654329, acc.: 67.97%] [G loss: 1.380728]\n",
      "epoch:34 step:31995 [D loss: 0.467165, acc.: 79.69%] [G loss: 1.455865]\n",
      "epoch:34 step:31996 [D loss: 0.525809, acc.: 75.78%] [G loss: 1.466396]\n",
      "epoch:34 step:31997 [D loss: 0.541686, acc.: 73.44%] [G loss: 1.588858]\n",
      "epoch:34 step:31998 [D loss: 0.633635, acc.: 65.62%] [G loss: 1.246286]\n",
      "epoch:34 step:31999 [D loss: 0.601226, acc.: 68.75%] [G loss: 1.630218]\n",
      "epoch:34 step:32000 [D loss: 0.417503, acc.: 84.38%] [G loss: 1.424073]\n",
      "epoch:34 step:32001 [D loss: 0.517941, acc.: 71.88%] [G loss: 1.613938]\n",
      "epoch:34 step:32002 [D loss: 0.713579, acc.: 64.84%] [G loss: 1.375421]\n",
      "epoch:34 step:32003 [D loss: 0.391939, acc.: 84.38%] [G loss: 1.918383]\n",
      "epoch:34 step:32004 [D loss: 0.434606, acc.: 84.38%] [G loss: 1.364901]\n",
      "epoch:34 step:32005 [D loss: 0.545838, acc.: 67.19%] [G loss: 1.718322]\n",
      "epoch:34 step:32006 [D loss: 0.610312, acc.: 64.84%] [G loss: 1.203904]\n",
      "epoch:34 step:32007 [D loss: 0.588781, acc.: 69.53%] [G loss: 1.293311]\n",
      "epoch:34 step:32008 [D loss: 0.596763, acc.: 73.44%] [G loss: 1.573632]\n",
      "epoch:34 step:32009 [D loss: 0.482780, acc.: 78.91%] [G loss: 1.649294]\n",
      "epoch:34 step:32010 [D loss: 0.414783, acc.: 78.91%] [G loss: 1.702439]\n",
      "epoch:34 step:32011 [D loss: 0.493500, acc.: 78.91%] [G loss: 1.200961]\n",
      "epoch:34 step:32012 [D loss: 0.574949, acc.: 68.75%] [G loss: 1.271637]\n",
      "epoch:34 step:32013 [D loss: 0.501692, acc.: 75.00%] [G loss: 1.726565]\n",
      "epoch:34 step:32014 [D loss: 0.644992, acc.: 66.41%] [G loss: 1.598011]\n",
      "epoch:34 step:32015 [D loss: 0.457814, acc.: 78.91%] [G loss: 1.435755]\n",
      "epoch:34 step:32016 [D loss: 0.670574, acc.: 60.16%] [G loss: 1.215399]\n",
      "epoch:34 step:32017 [D loss: 0.430203, acc.: 84.38%] [G loss: 1.017538]\n",
      "epoch:34 step:32018 [D loss: 0.475515, acc.: 76.56%] [G loss: 1.132536]\n",
      "epoch:34 step:32019 [D loss: 0.465314, acc.: 80.47%] [G loss: 1.924138]\n",
      "epoch:34 step:32020 [D loss: 0.782329, acc.: 53.91%] [G loss: 1.588393]\n",
      "epoch:34 step:32021 [D loss: 0.808917, acc.: 44.53%] [G loss: 1.239267]\n",
      "epoch:34 step:32022 [D loss: 0.464705, acc.: 80.47%] [G loss: 1.145105]\n",
      "epoch:34 step:32023 [D loss: 0.483296, acc.: 75.00%] [G loss: 1.178371]\n",
      "epoch:34 step:32024 [D loss: 0.530400, acc.: 72.66%] [G loss: 1.453638]\n",
      "epoch:34 step:32025 [D loss: 0.446019, acc.: 79.69%] [G loss: 1.587570]\n",
      "epoch:34 step:32026 [D loss: 0.689682, acc.: 62.50%] [G loss: 1.283705]\n",
      "epoch:34 step:32027 [D loss: 0.608300, acc.: 69.53%] [G loss: 1.410363]\n",
      "epoch:34 step:32028 [D loss: 0.575256, acc.: 75.00%] [G loss: 1.656327]\n",
      "epoch:34 step:32029 [D loss: 0.806873, acc.: 50.78%] [G loss: 1.845771]\n",
      "epoch:34 step:32030 [D loss: 0.388472, acc.: 85.94%] [G loss: 1.272840]\n",
      "epoch:34 step:32031 [D loss: 0.618369, acc.: 67.19%] [G loss: 1.614637]\n",
      "epoch:34 step:32032 [D loss: 0.490132, acc.: 80.47%] [G loss: 1.763143]\n",
      "epoch:34 step:32033 [D loss: 0.527764, acc.: 72.66%] [G loss: 1.300220]\n",
      "epoch:34 step:32034 [D loss: 0.453706, acc.: 81.25%] [G loss: 1.530926]\n",
      "epoch:34 step:32035 [D loss: 0.429948, acc.: 82.81%] [G loss: 1.899242]\n",
      "epoch:34 step:32036 [D loss: 0.449941, acc.: 78.91%] [G loss: 1.808943]\n",
      "epoch:34 step:32037 [D loss: 0.659090, acc.: 71.09%] [G loss: 1.333418]\n",
      "epoch:34 step:32038 [D loss: 0.672631, acc.: 67.19%] [G loss: 1.181528]\n",
      "epoch:34 step:32039 [D loss: 0.488975, acc.: 78.12%] [G loss: 1.895470]\n",
      "epoch:34 step:32040 [D loss: 0.676397, acc.: 60.94%] [G loss: 1.593946]\n",
      "epoch:34 step:32041 [D loss: 0.532481, acc.: 75.00%] [G loss: 1.247683]\n",
      "epoch:34 step:32042 [D loss: 0.533527, acc.: 77.34%] [G loss: 1.727489]\n",
      "epoch:34 step:32043 [D loss: 0.447540, acc.: 83.59%] [G loss: 1.852824]\n",
      "epoch:34 step:32044 [D loss: 0.434431, acc.: 82.81%] [G loss: 1.562412]\n",
      "epoch:34 step:32045 [D loss: 0.563478, acc.: 70.31%] [G loss: 2.138656]\n",
      "epoch:34 step:32046 [D loss: 0.363841, acc.: 87.50%] [G loss: 1.845293]\n",
      "epoch:34 step:32047 [D loss: 0.600879, acc.: 67.97%] [G loss: 1.201156]\n",
      "epoch:34 step:32048 [D loss: 0.590682, acc.: 68.75%] [G loss: 1.558495]\n",
      "epoch:34 step:32049 [D loss: 0.456524, acc.: 76.56%] [G loss: 1.376122]\n",
      "epoch:34 step:32050 [D loss: 0.560863, acc.: 77.34%] [G loss: 1.363611]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:34 step:32051 [D loss: 0.742321, acc.: 58.59%] [G loss: 1.850009]\n",
      "epoch:34 step:32052 [D loss: 0.453545, acc.: 76.56%] [G loss: 2.259544]\n",
      "epoch:34 step:32053 [D loss: 0.565957, acc.: 67.19%] [G loss: 1.252207]\n",
      "epoch:34 step:32054 [D loss: 0.519842, acc.: 67.97%] [G loss: 1.627382]\n",
      "epoch:34 step:32055 [D loss: 0.397596, acc.: 85.94%] [G loss: 1.332064]\n",
      "epoch:34 step:32056 [D loss: 0.361944, acc.: 91.41%] [G loss: 1.786534]\n",
      "epoch:34 step:32057 [D loss: 0.370832, acc.: 85.16%] [G loss: 2.070873]\n",
      "epoch:34 step:32058 [D loss: 0.865086, acc.: 51.56%] [G loss: 1.486982]\n",
      "epoch:34 step:32059 [D loss: 0.500854, acc.: 75.78%] [G loss: 1.473141]\n",
      "epoch:34 step:32060 [D loss: 0.557996, acc.: 67.97%] [G loss: 1.319430]\n",
      "epoch:34 step:32061 [D loss: 0.597736, acc.: 68.75%] [G loss: 1.281337]\n",
      "epoch:34 step:32062 [D loss: 0.457995, acc.: 80.47%] [G loss: 1.371339]\n",
      "epoch:34 step:32063 [D loss: 0.686176, acc.: 56.25%] [G loss: 1.446175]\n",
      "epoch:34 step:32064 [D loss: 0.574207, acc.: 69.53%] [G loss: 1.277227]\n",
      "epoch:34 step:32065 [D loss: 0.646809, acc.: 63.28%] [G loss: 1.366092]\n",
      "epoch:34 step:32066 [D loss: 0.568384, acc.: 68.75%] [G loss: 1.249186]\n",
      "epoch:34 step:32067 [D loss: 0.568066, acc.: 72.66%] [G loss: 1.280860]\n",
      "epoch:34 step:32068 [D loss: 0.599097, acc.: 65.62%] [G loss: 0.986990]\n",
      "epoch:34 step:32069 [D loss: 0.493488, acc.: 79.69%] [G loss: 1.998251]\n",
      "epoch:34 step:32070 [D loss: 0.411181, acc.: 80.47%] [G loss: 1.479119]\n",
      "epoch:34 step:32071 [D loss: 0.557959, acc.: 72.66%] [G loss: 1.517171]\n",
      "epoch:34 step:32072 [D loss: 0.582042, acc.: 66.41%] [G loss: 1.562900]\n",
      "epoch:34 step:32073 [D loss: 0.646543, acc.: 58.59%] [G loss: 0.998170]\n",
      "epoch:34 step:32074 [D loss: 0.444284, acc.: 77.34%] [G loss: 1.564767]\n",
      "epoch:34 step:32075 [D loss: 0.348977, acc.: 88.28%] [G loss: 1.731666]\n",
      "epoch:34 step:32076 [D loss: 0.731285, acc.: 60.94%] [G loss: 1.501155]\n",
      "epoch:34 step:32077 [D loss: 0.635228, acc.: 71.09%] [G loss: 1.122410]\n",
      "epoch:34 step:32078 [D loss: 0.393310, acc.: 87.50%] [G loss: 1.564669]\n",
      "epoch:34 step:32079 [D loss: 0.506543, acc.: 74.22%] [G loss: 1.028860]\n",
      "epoch:34 step:32080 [D loss: 0.568231, acc.: 68.75%] [G loss: 1.941904]\n",
      "epoch:34 step:32081 [D loss: 0.476750, acc.: 78.12%] [G loss: 1.590025]\n",
      "epoch:34 step:32082 [D loss: 0.677280, acc.: 60.16%] [G loss: 1.153570]\n",
      "epoch:34 step:32083 [D loss: 0.627453, acc.: 64.06%] [G loss: 1.089441]\n",
      "epoch:34 step:32084 [D loss: 0.349353, acc.: 88.28%] [G loss: 1.096273]\n",
      "epoch:34 step:32085 [D loss: 0.709804, acc.: 55.47%] [G loss: 1.527429]\n",
      "epoch:34 step:32086 [D loss: 0.522779, acc.: 73.44%] [G loss: 1.749652]\n",
      "epoch:34 step:32087 [D loss: 0.457330, acc.: 78.91%] [G loss: 1.801734]\n",
      "epoch:34 step:32088 [D loss: 0.654286, acc.: 67.97%] [G loss: 1.495114]\n",
      "epoch:34 step:32089 [D loss: 0.583695, acc.: 72.66%] [G loss: 1.794502]\n",
      "epoch:34 step:32090 [D loss: 0.498970, acc.: 76.56%] [G loss: 2.145029]\n",
      "epoch:34 step:32091 [D loss: 0.604089, acc.: 69.53%] [G loss: 1.540534]\n",
      "epoch:34 step:32092 [D loss: 0.650394, acc.: 62.50%] [G loss: 1.430929]\n",
      "epoch:34 step:32093 [D loss: 0.490107, acc.: 72.66%] [G loss: 1.587930]\n",
      "epoch:34 step:32094 [D loss: 0.626766, acc.: 67.97%] [G loss: 1.439946]\n",
      "epoch:34 step:32095 [D loss: 0.648670, acc.: 63.28%] [G loss: 1.525649]\n",
      "epoch:34 step:32096 [D loss: 0.577728, acc.: 64.84%] [G loss: 1.366374]\n",
      "epoch:34 step:32097 [D loss: 0.600728, acc.: 69.53%] [G loss: 1.561152]\n",
      "epoch:34 step:32098 [D loss: 0.550976, acc.: 72.66%] [G loss: 1.567131]\n",
      "epoch:34 step:32099 [D loss: 0.472258, acc.: 77.34%] [G loss: 1.425866]\n",
      "epoch:34 step:32100 [D loss: 0.675073, acc.: 60.94%] [G loss: 1.267313]\n",
      "epoch:34 step:32101 [D loss: 0.590023, acc.: 64.06%] [G loss: 1.506839]\n",
      "epoch:34 step:32102 [D loss: 0.564679, acc.: 70.31%] [G loss: 1.626152]\n",
      "epoch:34 step:32103 [D loss: 0.572863, acc.: 71.09%] [G loss: 1.632445]\n",
      "epoch:34 step:32104 [D loss: 0.440208, acc.: 80.47%] [G loss: 1.504868]\n",
      "epoch:34 step:32105 [D loss: 0.576932, acc.: 71.88%] [G loss: 1.310580]\n",
      "epoch:34 step:32106 [D loss: 0.483744, acc.: 78.12%] [G loss: 1.216126]\n",
      "epoch:34 step:32107 [D loss: 0.382568, acc.: 83.59%] [G loss: 1.615315]\n",
      "epoch:34 step:32108 [D loss: 0.610559, acc.: 67.97%] [G loss: 1.493608]\n",
      "epoch:34 step:32109 [D loss: 0.492991, acc.: 78.12%] [G loss: 1.348147]\n",
      "epoch:34 step:32110 [D loss: 0.615669, acc.: 64.06%] [G loss: 1.306032]\n",
      "epoch:34 step:32111 [D loss: 0.454158, acc.: 78.12%] [G loss: 1.420094]\n",
      "epoch:34 step:32112 [D loss: 0.583146, acc.: 72.66%] [G loss: 1.420418]\n",
      "epoch:34 step:32113 [D loss: 0.566025, acc.: 71.09%] [G loss: 2.119242]\n",
      "epoch:34 step:32114 [D loss: 0.422602, acc.: 78.91%] [G loss: 1.207176]\n",
      "epoch:34 step:32115 [D loss: 0.388201, acc.: 85.94%] [G loss: 1.878593]\n",
      "epoch:34 step:32116 [D loss: 0.385649, acc.: 85.16%] [G loss: 1.650840]\n",
      "epoch:34 step:32117 [D loss: 0.484043, acc.: 78.12%] [G loss: 1.537138]\n",
      "epoch:34 step:32118 [D loss: 0.449944, acc.: 79.69%] [G loss: 1.224766]\n",
      "epoch:34 step:32119 [D loss: 0.865467, acc.: 52.34%] [G loss: 0.747352]\n",
      "epoch:34 step:32120 [D loss: 0.613816, acc.: 66.41%] [G loss: 1.286786]\n",
      "epoch:34 step:32121 [D loss: 0.742109, acc.: 59.38%] [G loss: 1.566029]\n",
      "epoch:34 step:32122 [D loss: 0.404830, acc.: 82.03%] [G loss: 1.813114]\n",
      "epoch:34 step:32123 [D loss: 0.243495, acc.: 96.09%] [G loss: 2.118023]\n",
      "epoch:34 step:32124 [D loss: 0.585367, acc.: 64.06%] [G loss: 1.533878]\n",
      "epoch:34 step:32125 [D loss: 0.549401, acc.: 72.66%] [G loss: 1.349366]\n",
      "epoch:34 step:32126 [D loss: 0.474720, acc.: 77.34%] [G loss: 1.214509]\n",
      "epoch:34 step:32127 [D loss: 0.628342, acc.: 61.72%] [G loss: 1.392908]\n",
      "epoch:34 step:32128 [D loss: 0.486610, acc.: 77.34%] [G loss: 1.275450]\n",
      "epoch:34 step:32129 [D loss: 0.707160, acc.: 57.03%] [G loss: 1.405514]\n",
      "epoch:34 step:32130 [D loss: 0.571222, acc.: 73.44%] [G loss: 1.341911]\n",
      "epoch:34 step:32131 [D loss: 0.639899, acc.: 66.41%] [G loss: 1.707388]\n",
      "epoch:34 step:32132 [D loss: 0.349909, acc.: 87.50%] [G loss: 1.373147]\n",
      "epoch:34 step:32133 [D loss: 0.638111, acc.: 65.62%] [G loss: 1.393280]\n",
      "epoch:34 step:32134 [D loss: 0.743519, acc.: 57.03%] [G loss: 1.336092]\n",
      "epoch:34 step:32135 [D loss: 0.624443, acc.: 68.75%] [G loss: 1.161781]\n",
      "epoch:34 step:32136 [D loss: 0.503824, acc.: 78.91%] [G loss: 1.472501]\n",
      "epoch:34 step:32137 [D loss: 0.383892, acc.: 89.06%] [G loss: 1.641987]\n",
      "epoch:34 step:32138 [D loss: 0.528484, acc.: 71.09%] [G loss: 1.380015]\n",
      "epoch:34 step:32139 [D loss: 0.546906, acc.: 71.09%] [G loss: 1.369238]\n",
      "epoch:34 step:32140 [D loss: 0.760307, acc.: 55.47%] [G loss: 1.493841]\n",
      "epoch:34 step:32141 [D loss: 0.543442, acc.: 74.22%] [G loss: 1.658254]\n",
      "epoch:34 step:32142 [D loss: 0.541723, acc.: 74.22%] [G loss: 1.432675]\n",
      "epoch:34 step:32143 [D loss: 0.590091, acc.: 73.44%] [G loss: 1.743633]\n",
      "epoch:34 step:32144 [D loss: 0.587905, acc.: 72.66%] [G loss: 1.409545]\n",
      "epoch:34 step:32145 [D loss: 0.416206, acc.: 85.94%] [G loss: 2.003689]\n",
      "epoch:34 step:32146 [D loss: 0.730370, acc.: 58.59%] [G loss: 1.544645]\n",
      "epoch:34 step:32147 [D loss: 0.409260, acc.: 85.94%] [G loss: 1.535856]\n",
      "epoch:34 step:32148 [D loss: 0.424854, acc.: 79.69%] [G loss: 1.688065]\n",
      "epoch:34 step:32149 [D loss: 0.570329, acc.: 71.09%] [G loss: 1.214288]\n",
      "epoch:34 step:32150 [D loss: 0.510808, acc.: 77.34%] [G loss: 1.192679]\n",
      "epoch:34 step:32151 [D loss: 0.435989, acc.: 83.59%] [G loss: 1.627417]\n",
      "epoch:34 step:32152 [D loss: 0.554774, acc.: 69.53%] [G loss: 1.288362]\n",
      "epoch:34 step:32153 [D loss: 0.635341, acc.: 67.97%] [G loss: 2.078908]\n",
      "epoch:34 step:32154 [D loss: 0.520737, acc.: 75.00%] [G loss: 1.795446]\n",
      "epoch:34 step:32155 [D loss: 0.561350, acc.: 71.09%] [G loss: 1.639584]\n",
      "epoch:34 step:32156 [D loss: 0.653728, acc.: 65.62%] [G loss: 1.613862]\n",
      "epoch:34 step:32157 [D loss: 0.585308, acc.: 68.75%] [G loss: 1.175146]\n",
      "epoch:34 step:32158 [D loss: 0.685910, acc.: 58.59%] [G loss: 1.300977]\n",
      "epoch:34 step:32159 [D loss: 0.611686, acc.: 67.97%] [G loss: 1.423707]\n",
      "epoch:34 step:32160 [D loss: 0.492531, acc.: 75.00%] [G loss: 1.392706]\n",
      "epoch:34 step:32161 [D loss: 0.433803, acc.: 78.91%] [G loss: 1.806095]\n",
      "epoch:34 step:32162 [D loss: 0.536986, acc.: 72.66%] [G loss: 1.014663]\n",
      "epoch:34 step:32163 [D loss: 0.622528, acc.: 63.28%] [G loss: 1.337579]\n",
      "epoch:34 step:32164 [D loss: 0.580462, acc.: 71.88%] [G loss: 1.317683]\n",
      "epoch:34 step:32165 [D loss: 0.567351, acc.: 76.56%] [G loss: 1.041146]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:34 step:32166 [D loss: 0.518602, acc.: 77.34%] [G loss: 1.541189]\n",
      "epoch:34 step:32167 [D loss: 0.480901, acc.: 75.78%] [G loss: 1.175652]\n",
      "epoch:34 step:32168 [D loss: 0.541068, acc.: 70.31%] [G loss: 1.218052]\n",
      "epoch:34 step:32169 [D loss: 0.547697, acc.: 76.56%] [G loss: 1.464466]\n",
      "epoch:34 step:32170 [D loss: 0.573331, acc.: 67.97%] [G loss: 1.292097]\n",
      "epoch:34 step:32171 [D loss: 0.569546, acc.: 71.88%] [G loss: 1.474820]\n",
      "epoch:34 step:32172 [D loss: 0.417179, acc.: 85.94%] [G loss: 1.539426]\n",
      "epoch:34 step:32173 [D loss: 0.518976, acc.: 75.00%] [G loss: 1.439002]\n",
      "epoch:34 step:32174 [D loss: 0.622985, acc.: 71.88%] [G loss: 1.460561]\n",
      "epoch:34 step:32175 [D loss: 0.619695, acc.: 69.53%] [G loss: 1.649786]\n",
      "epoch:34 step:32176 [D loss: 0.799018, acc.: 53.91%] [G loss: 1.436889]\n",
      "epoch:34 step:32177 [D loss: 0.641493, acc.: 61.72%] [G loss: 1.069621]\n",
      "epoch:34 step:32178 [D loss: 0.549916, acc.: 69.53%] [G loss: 1.365811]\n",
      "epoch:34 step:32179 [D loss: 0.502894, acc.: 73.44%] [G loss: 1.484518]\n",
      "epoch:34 step:32180 [D loss: 0.537430, acc.: 72.66%] [G loss: 1.323250]\n",
      "epoch:34 step:32181 [D loss: 0.487374, acc.: 76.56%] [G loss: 1.290953]\n",
      "epoch:34 step:32182 [D loss: 0.503702, acc.: 78.12%] [G loss: 1.416507]\n",
      "epoch:34 step:32183 [D loss: 0.585031, acc.: 69.53%] [G loss: 1.118791]\n",
      "epoch:34 step:32184 [D loss: 0.549299, acc.: 69.53%] [G loss: 1.430049]\n",
      "epoch:34 step:32185 [D loss: 0.587401, acc.: 66.41%] [G loss: 1.330472]\n",
      "epoch:34 step:32186 [D loss: 0.602869, acc.: 68.75%] [G loss: 1.705878]\n",
      "epoch:34 step:32187 [D loss: 0.443958, acc.: 78.12%] [G loss: 1.412025]\n",
      "epoch:34 step:32188 [D loss: 0.591323, acc.: 68.75%] [G loss: 1.706640]\n",
      "epoch:34 step:32189 [D loss: 0.562112, acc.: 73.44%] [G loss: 1.649226]\n",
      "epoch:34 step:32190 [D loss: 0.576721, acc.: 70.31%] [G loss: 1.547036]\n",
      "epoch:34 step:32191 [D loss: 0.537129, acc.: 75.00%] [G loss: 1.595088]\n",
      "epoch:34 step:32192 [D loss: 0.548351, acc.: 75.00%] [G loss: 1.761676]\n",
      "epoch:34 step:32193 [D loss: 0.410551, acc.: 82.81%] [G loss: 1.521834]\n",
      "epoch:34 step:32194 [D loss: 0.389323, acc.: 85.94%] [G loss: 1.682763]\n",
      "epoch:34 step:32195 [D loss: 0.556565, acc.: 71.09%] [G loss: 1.335374]\n",
      "epoch:34 step:32196 [D loss: 0.476083, acc.: 82.81%] [G loss: 2.044887]\n",
      "epoch:34 step:32197 [D loss: 0.437929, acc.: 83.59%] [G loss: 1.429265]\n",
      "epoch:34 step:32198 [D loss: 0.409517, acc.: 85.16%] [G loss: 1.270639]\n",
      "epoch:34 step:32199 [D loss: 0.525861, acc.: 78.91%] [G loss: 1.579558]\n",
      "epoch:34 step:32200 [D loss: 0.610492, acc.: 64.84%] [G loss: 1.339279]\n",
      "epoch:34 step:32201 [D loss: 0.446423, acc.: 79.69%] [G loss: 1.464535]\n",
      "epoch:34 step:32202 [D loss: 0.473503, acc.: 78.12%] [G loss: 1.394599]\n",
      "epoch:34 step:32203 [D loss: 0.520312, acc.: 75.00%] [G loss: 1.507537]\n",
      "epoch:34 step:32204 [D loss: 0.443956, acc.: 82.03%] [G loss: 1.498918]\n",
      "epoch:34 step:32205 [D loss: 0.438014, acc.: 85.16%] [G loss: 1.857346]\n",
      "epoch:34 step:32206 [D loss: 0.615670, acc.: 65.62%] [G loss: 1.691083]\n",
      "epoch:34 step:32207 [D loss: 0.391145, acc.: 85.94%] [G loss: 2.168725]\n",
      "epoch:34 step:32208 [D loss: 0.365747, acc.: 86.72%] [G loss: 1.879528]\n",
      "epoch:34 step:32209 [D loss: 0.567385, acc.: 71.88%] [G loss: 1.353579]\n",
      "epoch:34 step:32210 [D loss: 0.789157, acc.: 50.78%] [G loss: 1.192840]\n",
      "epoch:34 step:32211 [D loss: 0.522320, acc.: 71.88%] [G loss: 1.112720]\n",
      "epoch:34 step:32212 [D loss: 0.460796, acc.: 81.25%] [G loss: 1.661870]\n",
      "epoch:34 step:32213 [D loss: 0.531032, acc.: 73.44%] [G loss: 1.542645]\n",
      "epoch:34 step:32214 [D loss: 0.549603, acc.: 72.66%] [G loss: 1.622686]\n",
      "epoch:34 step:32215 [D loss: 0.455342, acc.: 78.12%] [G loss: 1.616209]\n",
      "epoch:34 step:32216 [D loss: 0.596009, acc.: 68.75%] [G loss: 1.610655]\n",
      "epoch:34 step:32217 [D loss: 0.421457, acc.: 82.81%] [G loss: 1.590897]\n",
      "epoch:34 step:32218 [D loss: 0.525312, acc.: 72.66%] [G loss: 1.075613]\n",
      "epoch:34 step:32219 [D loss: 0.409376, acc.: 82.03%] [G loss: 1.920286]\n",
      "epoch:34 step:32220 [D loss: 0.411702, acc.: 83.59%] [G loss: 1.206527]\n",
      "epoch:34 step:32221 [D loss: 0.596578, acc.: 70.31%] [G loss: 1.226763]\n",
      "epoch:34 step:32222 [D loss: 0.418646, acc.: 78.91%] [G loss: 1.689291]\n",
      "epoch:34 step:32223 [D loss: 0.764140, acc.: 57.81%] [G loss: 1.367231]\n",
      "epoch:34 step:32224 [D loss: 0.566730, acc.: 73.44%] [G loss: 1.405260]\n",
      "epoch:34 step:32225 [D loss: 0.557043, acc.: 75.00%] [G loss: 1.650979]\n",
      "epoch:34 step:32226 [D loss: 0.460160, acc.: 78.12%] [G loss: 1.592180]\n",
      "epoch:34 step:32227 [D loss: 0.695355, acc.: 61.72%] [G loss: 1.320198]\n",
      "epoch:34 step:32228 [D loss: 0.423783, acc.: 82.81%] [G loss: 1.818109]\n",
      "epoch:34 step:32229 [D loss: 0.501633, acc.: 76.56%] [G loss: 1.485231]\n",
      "epoch:34 step:32230 [D loss: 0.458251, acc.: 78.91%] [G loss: 1.343429]\n",
      "epoch:34 step:32231 [D loss: 0.480543, acc.: 74.22%] [G loss: 1.434207]\n",
      "epoch:34 step:32232 [D loss: 0.618972, acc.: 69.53%] [G loss: 1.850240]\n",
      "epoch:34 step:32233 [D loss: 0.565749, acc.: 71.88%] [G loss: 1.125048]\n",
      "epoch:34 step:32234 [D loss: 0.560631, acc.: 67.97%] [G loss: 1.368624]\n",
      "epoch:34 step:32235 [D loss: 0.493900, acc.: 75.78%] [G loss: 1.625833]\n",
      "epoch:34 step:32236 [D loss: 0.370027, acc.: 86.72%] [G loss: 1.888245]\n",
      "epoch:34 step:32237 [D loss: 0.473515, acc.: 75.00%] [G loss: 1.462649]\n",
      "epoch:34 step:32238 [D loss: 0.650459, acc.: 69.53%] [G loss: 1.806611]\n",
      "epoch:34 step:32239 [D loss: 0.630885, acc.: 63.28%] [G loss: 1.338237]\n",
      "epoch:34 step:32240 [D loss: 0.464753, acc.: 80.47%] [G loss: 1.709849]\n",
      "epoch:34 step:32241 [D loss: 0.498686, acc.: 78.91%] [G loss: 1.818883]\n",
      "epoch:34 step:32242 [D loss: 0.507794, acc.: 72.66%] [G loss: 1.409250]\n",
      "epoch:34 step:32243 [D loss: 0.354115, acc.: 84.38%] [G loss: 2.196834]\n",
      "epoch:34 step:32244 [D loss: 0.676401, acc.: 57.81%] [G loss: 1.301756]\n",
      "epoch:34 step:32245 [D loss: 0.325558, acc.: 89.06%] [G loss: 1.656394]\n",
      "epoch:34 step:32246 [D loss: 0.645735, acc.: 65.62%] [G loss: 1.556168]\n",
      "epoch:34 step:32247 [D loss: 0.475607, acc.: 78.12%] [G loss: 1.290540]\n",
      "epoch:34 step:32248 [D loss: 0.571297, acc.: 71.09%] [G loss: 1.200614]\n",
      "epoch:34 step:32249 [D loss: 0.576179, acc.: 71.09%] [G loss: 1.677828]\n",
      "epoch:34 step:32250 [D loss: 0.595245, acc.: 68.75%] [G loss: 1.394093]\n",
      "epoch:34 step:32251 [D loss: 0.665017, acc.: 60.94%] [G loss: 1.538013]\n",
      "epoch:34 step:32252 [D loss: 0.633154, acc.: 64.06%] [G loss: 1.046267]\n",
      "epoch:34 step:32253 [D loss: 0.452076, acc.: 82.81%] [G loss: 1.770840]\n",
      "epoch:34 step:32254 [D loss: 0.479888, acc.: 75.00%] [G loss: 1.471198]\n",
      "epoch:34 step:32255 [D loss: 0.644820, acc.: 63.28%] [G loss: 0.973611]\n",
      "epoch:34 step:32256 [D loss: 0.607320, acc.: 67.97%] [G loss: 1.382740]\n",
      "epoch:34 step:32257 [D loss: 0.473729, acc.: 79.69%] [G loss: 1.858979]\n",
      "epoch:34 step:32258 [D loss: 0.608994, acc.: 69.53%] [G loss: 1.132362]\n",
      "epoch:34 step:32259 [D loss: 0.563277, acc.: 74.22%] [G loss: 1.400255]\n",
      "epoch:34 step:32260 [D loss: 0.543453, acc.: 73.44%] [G loss: 1.332263]\n",
      "epoch:34 step:32261 [D loss: 0.459074, acc.: 75.78%] [G loss: 1.986021]\n",
      "epoch:34 step:32262 [D loss: 0.435120, acc.: 78.91%] [G loss: 1.161351]\n",
      "epoch:34 step:32263 [D loss: 0.581629, acc.: 71.88%] [G loss: 1.346388]\n",
      "epoch:34 step:32264 [D loss: 0.325047, acc.: 88.28%] [G loss: 2.023752]\n",
      "epoch:34 step:32265 [D loss: 0.929098, acc.: 41.41%] [G loss: 1.340615]\n",
      "epoch:34 step:32266 [D loss: 0.542596, acc.: 74.22%] [G loss: 1.465333]\n",
      "epoch:34 step:32267 [D loss: 0.605792, acc.: 71.88%] [G loss: 1.183066]\n",
      "epoch:34 step:32268 [D loss: 0.494870, acc.: 75.00%] [G loss: 1.274939]\n",
      "epoch:34 step:32269 [D loss: 0.675778, acc.: 62.50%] [G loss: 1.579185]\n",
      "epoch:34 step:32270 [D loss: 0.698438, acc.: 57.03%] [G loss: 0.920868]\n",
      "epoch:34 step:32271 [D loss: 0.456856, acc.: 80.47%] [G loss: 1.790299]\n",
      "epoch:34 step:32272 [D loss: 0.565791, acc.: 69.53%] [G loss: 1.342358]\n",
      "epoch:34 step:32273 [D loss: 0.665366, acc.: 66.41%] [G loss: 1.389698]\n",
      "epoch:34 step:32274 [D loss: 0.652224, acc.: 64.06%] [G loss: 1.249259]\n",
      "epoch:34 step:32275 [D loss: 0.606903, acc.: 64.84%] [G loss: 0.908450]\n",
      "epoch:34 step:32276 [D loss: 0.556539, acc.: 69.53%] [G loss: 1.606882]\n",
      "epoch:34 step:32277 [D loss: 0.653743, acc.: 62.50%] [G loss: 1.495615]\n",
      "epoch:34 step:32278 [D loss: 0.533614, acc.: 76.56%] [G loss: 1.540132]\n",
      "epoch:34 step:32279 [D loss: 0.610330, acc.: 70.31%] [G loss: 1.081223]\n",
      "epoch:34 step:32280 [D loss: 0.407735, acc.: 85.16%] [G loss: 1.776474]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:34 step:32281 [D loss: 0.512650, acc.: 77.34%] [G loss: 2.324024]\n",
      "epoch:34 step:32282 [D loss: 0.459149, acc.: 79.69%] [G loss: 1.450942]\n",
      "epoch:34 step:32283 [D loss: 0.513502, acc.: 74.22%] [G loss: 1.266596]\n",
      "epoch:34 step:32284 [D loss: 0.667120, acc.: 61.72%] [G loss: 1.121438]\n",
      "epoch:34 step:32285 [D loss: 0.577109, acc.: 68.75%] [G loss: 1.428819]\n",
      "epoch:34 step:32286 [D loss: 0.629591, acc.: 67.97%] [G loss: 1.216628]\n",
      "epoch:34 step:32287 [D loss: 0.807032, acc.: 50.00%] [G loss: 1.475002]\n",
      "epoch:34 step:32288 [D loss: 0.400885, acc.: 82.81%] [G loss: 1.600291]\n",
      "epoch:34 step:32289 [D loss: 0.590924, acc.: 68.75%] [G loss: 1.343958]\n",
      "epoch:34 step:32290 [D loss: 0.375778, acc.: 84.38%] [G loss: 1.747479]\n",
      "epoch:34 step:32291 [D loss: 0.417446, acc.: 80.47%] [G loss: 1.532150]\n",
      "epoch:34 step:32292 [D loss: 0.642893, acc.: 61.72%] [G loss: 1.516514]\n",
      "epoch:34 step:32293 [D loss: 0.494402, acc.: 76.56%] [G loss: 1.423443]\n",
      "epoch:34 step:32294 [D loss: 0.650883, acc.: 61.72%] [G loss: 2.087070]\n",
      "epoch:34 step:32295 [D loss: 0.581068, acc.: 70.31%] [G loss: 2.120779]\n",
      "epoch:34 step:32296 [D loss: 0.580321, acc.: 69.53%] [G loss: 1.635091]\n",
      "epoch:34 step:32297 [D loss: 0.541143, acc.: 71.88%] [G loss: 1.562152]\n",
      "epoch:34 step:32298 [D loss: 0.785752, acc.: 51.56%] [G loss: 1.527962]\n",
      "epoch:34 step:32299 [D loss: 0.481945, acc.: 79.69%] [G loss: 1.645052]\n",
      "epoch:34 step:32300 [D loss: 0.619959, acc.: 63.28%] [G loss: 1.560995]\n",
      "epoch:34 step:32301 [D loss: 0.489066, acc.: 76.56%] [G loss: 1.413293]\n",
      "epoch:34 step:32302 [D loss: 0.600812, acc.: 71.09%] [G loss: 1.263441]\n",
      "epoch:34 step:32303 [D loss: 0.449015, acc.: 77.34%] [G loss: 2.011651]\n",
      "epoch:34 step:32304 [D loss: 0.618213, acc.: 67.97%] [G loss: 1.676250]\n",
      "epoch:34 step:32305 [D loss: 0.585453, acc.: 65.62%] [G loss: 1.219846]\n",
      "epoch:34 step:32306 [D loss: 0.438461, acc.: 83.59%] [G loss: 1.414813]\n",
      "epoch:34 step:32307 [D loss: 0.540273, acc.: 71.09%] [G loss: 1.555196]\n",
      "epoch:34 step:32308 [D loss: 0.673679, acc.: 60.16%] [G loss: 1.410146]\n",
      "epoch:34 step:32309 [D loss: 0.492972, acc.: 79.69%] [G loss: 1.664454]\n",
      "epoch:34 step:32310 [D loss: 0.468529, acc.: 78.12%] [G loss: 1.635199]\n",
      "epoch:34 step:32311 [D loss: 0.504353, acc.: 77.34%] [G loss: 1.224038]\n",
      "epoch:34 step:32312 [D loss: 0.520814, acc.: 74.22%] [G loss: 1.245145]\n",
      "epoch:34 step:32313 [D loss: 0.410165, acc.: 84.38%] [G loss: 1.226614]\n",
      "epoch:34 step:32314 [D loss: 0.728037, acc.: 52.34%] [G loss: 1.712735]\n",
      "epoch:34 step:32315 [D loss: 0.518085, acc.: 73.44%] [G loss: 1.342795]\n",
      "epoch:34 step:32316 [D loss: 0.363265, acc.: 88.28%] [G loss: 1.804549]\n",
      "epoch:34 step:32317 [D loss: 0.407324, acc.: 85.16%] [G loss: 1.268022]\n",
      "epoch:34 step:32318 [D loss: 0.601765, acc.: 64.06%] [G loss: 1.241646]\n",
      "epoch:34 step:32319 [D loss: 0.549217, acc.: 75.00%] [G loss: 1.276973]\n",
      "epoch:34 step:32320 [D loss: 0.635526, acc.: 64.06%] [G loss: 1.540888]\n",
      "epoch:34 step:32321 [D loss: 0.420820, acc.: 82.81%] [G loss: 1.559360]\n",
      "epoch:34 step:32322 [D loss: 0.556531, acc.: 72.66%] [G loss: 1.627133]\n",
      "epoch:34 step:32323 [D loss: 0.635867, acc.: 63.28%] [G loss: 1.248060]\n",
      "epoch:34 step:32324 [D loss: 0.609861, acc.: 67.19%] [G loss: 1.247948]\n",
      "epoch:34 step:32325 [D loss: 0.512622, acc.: 73.44%] [G loss: 1.571676]\n",
      "epoch:34 step:32326 [D loss: 0.525175, acc.: 73.44%] [G loss: 1.106244]\n",
      "epoch:34 step:32327 [D loss: 0.503178, acc.: 75.78%] [G loss: 1.542570]\n",
      "epoch:34 step:32328 [D loss: 0.681268, acc.: 60.94%] [G loss: 1.483502]\n",
      "epoch:34 step:32329 [D loss: 0.553760, acc.: 75.00%] [G loss: 0.881588]\n",
      "epoch:34 step:32330 [D loss: 0.506914, acc.: 75.00%] [G loss: 1.425792]\n",
      "epoch:34 step:32331 [D loss: 0.439011, acc.: 82.03%] [G loss: 1.424088]\n",
      "epoch:34 step:32332 [D loss: 0.539036, acc.: 72.66%] [G loss: 1.648507]\n",
      "epoch:34 step:32333 [D loss: 0.417266, acc.: 83.59%] [G loss: 1.775386]\n",
      "epoch:34 step:32334 [D loss: 0.688491, acc.: 64.06%] [G loss: 1.365988]\n",
      "epoch:34 step:32335 [D loss: 0.803975, acc.: 57.03%] [G loss: 1.153652]\n",
      "epoch:34 step:32336 [D loss: 0.508843, acc.: 77.34%] [G loss: 1.591809]\n",
      "epoch:34 step:32337 [D loss: 0.429867, acc.: 79.69%] [G loss: 1.213818]\n",
      "epoch:34 step:32338 [D loss: 0.529355, acc.: 72.66%] [G loss: 1.347924]\n",
      "epoch:34 step:32339 [D loss: 0.543845, acc.: 75.00%] [G loss: 1.052114]\n",
      "epoch:34 step:32340 [D loss: 0.539770, acc.: 71.09%] [G loss: 1.486426]\n",
      "epoch:34 step:32341 [D loss: 0.637482, acc.: 60.16%] [G loss: 1.443678]\n",
      "epoch:34 step:32342 [D loss: 0.479499, acc.: 78.12%] [G loss: 1.814860]\n",
      "epoch:34 step:32343 [D loss: 0.553094, acc.: 68.75%] [G loss: 1.562304]\n",
      "epoch:34 step:32344 [D loss: 0.504495, acc.: 75.00%] [G loss: 2.005879]\n",
      "epoch:34 step:32345 [D loss: 0.642640, acc.: 63.28%] [G loss: 1.224716]\n",
      "epoch:34 step:32346 [D loss: 0.402434, acc.: 85.94%] [G loss: 1.524593]\n",
      "epoch:34 step:32347 [D loss: 0.648170, acc.: 59.38%] [G loss: 1.667594]\n",
      "epoch:34 step:32348 [D loss: 0.453742, acc.: 81.25%] [G loss: 1.513192]\n",
      "epoch:34 step:32349 [D loss: 0.533263, acc.: 77.34%] [G loss: 1.466259]\n",
      "epoch:34 step:32350 [D loss: 0.612001, acc.: 69.53%] [G loss: 1.155977]\n",
      "epoch:34 step:32351 [D loss: 0.426432, acc.: 80.47%] [G loss: 1.590545]\n",
      "epoch:34 step:32352 [D loss: 0.533276, acc.: 75.00%] [G loss: 1.166282]\n",
      "epoch:34 step:32353 [D loss: 0.591484, acc.: 70.31%] [G loss: 1.702306]\n",
      "epoch:34 step:32354 [D loss: 0.570273, acc.: 74.22%] [G loss: 0.909547]\n",
      "epoch:34 step:32355 [D loss: 0.632505, acc.: 64.06%] [G loss: 1.476855]\n",
      "epoch:34 step:32356 [D loss: 0.578726, acc.: 73.44%] [G loss: 1.511624]\n",
      "epoch:34 step:32357 [D loss: 0.787334, acc.: 51.56%] [G loss: 1.383932]\n",
      "epoch:34 step:32358 [D loss: 0.824146, acc.: 53.91%] [G loss: 1.617220]\n",
      "epoch:34 step:32359 [D loss: 0.581238, acc.: 73.44%] [G loss: 1.755302]\n",
      "epoch:34 step:32360 [D loss: 0.495031, acc.: 77.34%] [G loss: 1.530195]\n",
      "epoch:34 step:32361 [D loss: 0.689890, acc.: 57.81%] [G loss: 1.317455]\n",
      "epoch:34 step:32362 [D loss: 0.567302, acc.: 70.31%] [G loss: 1.128453]\n",
      "epoch:34 step:32363 [D loss: 0.363200, acc.: 84.38%] [G loss: 1.245122]\n",
      "epoch:34 step:32364 [D loss: 0.556847, acc.: 68.75%] [G loss: 1.424243]\n",
      "epoch:34 step:32365 [D loss: 0.528014, acc.: 75.00%] [G loss: 1.318578]\n",
      "epoch:34 step:32366 [D loss: 0.593686, acc.: 67.19%] [G loss: 1.510982]\n",
      "epoch:34 step:32367 [D loss: 0.546802, acc.: 75.78%] [G loss: 1.124960]\n",
      "epoch:34 step:32368 [D loss: 0.455108, acc.: 76.56%] [G loss: 1.222287]\n",
      "epoch:34 step:32369 [D loss: 0.701439, acc.: 63.28%] [G loss: 1.123278]\n",
      "epoch:34 step:32370 [D loss: 0.507580, acc.: 76.56%] [G loss: 1.736143]\n",
      "epoch:34 step:32371 [D loss: 0.448874, acc.: 79.69%] [G loss: 1.597808]\n",
      "epoch:34 step:32372 [D loss: 0.402540, acc.: 84.38%] [G loss: 1.321518]\n",
      "epoch:34 step:32373 [D loss: 0.460986, acc.: 82.03%] [G loss: 1.113429]\n",
      "epoch:34 step:32374 [D loss: 0.521378, acc.: 71.09%] [G loss: 1.574273]\n",
      "epoch:34 step:32375 [D loss: 0.398317, acc.: 84.38%] [G loss: 1.178329]\n",
      "epoch:34 step:32376 [D loss: 0.546336, acc.: 75.00%] [G loss: 1.160794]\n",
      "epoch:34 step:32377 [D loss: 0.322800, acc.: 91.41%] [G loss: 1.204187]\n",
      "epoch:34 step:32378 [D loss: 0.680388, acc.: 57.81%] [G loss: 1.272861]\n",
      "epoch:34 step:32379 [D loss: 0.394839, acc.: 85.16%] [G loss: 1.370453]\n",
      "epoch:34 step:32380 [D loss: 0.604138, acc.: 66.41%] [G loss: 1.287090]\n",
      "epoch:34 step:32381 [D loss: 0.464878, acc.: 78.91%] [G loss: 1.900182]\n",
      "epoch:34 step:32382 [D loss: 0.546457, acc.: 71.88%] [G loss: 1.086977]\n",
      "epoch:34 step:32383 [D loss: 0.526748, acc.: 72.66%] [G loss: 1.106802]\n",
      "epoch:34 step:32384 [D loss: 0.546824, acc.: 67.19%] [G loss: 1.775140]\n",
      "epoch:34 step:32385 [D loss: 0.594666, acc.: 70.31%] [G loss: 1.595853]\n",
      "epoch:34 step:32386 [D loss: 0.630651, acc.: 60.16%] [G loss: 0.907855]\n",
      "epoch:34 step:32387 [D loss: 0.556795, acc.: 70.31%] [G loss: 1.030208]\n",
      "epoch:34 step:32388 [D loss: 0.387714, acc.: 85.94%] [G loss: 1.619339]\n",
      "epoch:34 step:32389 [D loss: 0.527154, acc.: 76.56%] [G loss: 1.676740]\n",
      "epoch:34 step:32390 [D loss: 0.674858, acc.: 60.16%] [G loss: 1.388507]\n",
      "epoch:34 step:32391 [D loss: 0.604202, acc.: 68.75%] [G loss: 1.025804]\n",
      "epoch:34 step:32392 [D loss: 0.590205, acc.: 67.97%] [G loss: 2.027925]\n",
      "epoch:34 step:32393 [D loss: 0.682825, acc.: 59.38%] [G loss: 1.503787]\n",
      "epoch:34 step:32394 [D loss: 0.522506, acc.: 78.12%] [G loss: 1.775709]\n",
      "epoch:34 step:32395 [D loss: 0.408827, acc.: 82.81%] [G loss: 1.381690]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:34 step:32396 [D loss: 0.739543, acc.: 57.81%] [G loss: 1.186750]\n",
      "epoch:34 step:32397 [D loss: 0.532955, acc.: 71.88%] [G loss: 1.455577]\n",
      "epoch:34 step:32398 [D loss: 0.467888, acc.: 78.12%] [G loss: 1.925299]\n",
      "epoch:34 step:32399 [D loss: 0.475196, acc.: 80.47%] [G loss: 1.156464]\n",
      "epoch:34 step:32400 [D loss: 0.704029, acc.: 62.50%] [G loss: 1.804416]\n",
      "epoch:34 step:32401 [D loss: 0.585123, acc.: 67.97%] [G loss: 1.446290]\n",
      "epoch:34 step:32402 [D loss: 0.602813, acc.: 67.97%] [G loss: 1.501696]\n",
      "epoch:34 step:32403 [D loss: 0.487428, acc.: 76.56%] [G loss: 1.741728]\n",
      "epoch:34 step:32404 [D loss: 0.563682, acc.: 71.88%] [G loss: 1.620737]\n",
      "epoch:34 step:32405 [D loss: 0.506169, acc.: 76.56%] [G loss: 1.405817]\n",
      "epoch:34 step:32406 [D loss: 0.463885, acc.: 79.69%] [G loss: 1.637795]\n",
      "epoch:34 step:32407 [D loss: 0.592008, acc.: 68.75%] [G loss: 1.267313]\n",
      "epoch:34 step:32408 [D loss: 0.512430, acc.: 74.22%] [G loss: 1.227232]\n",
      "epoch:34 step:32409 [D loss: 0.561134, acc.: 68.75%] [G loss: 1.120435]\n",
      "epoch:34 step:32410 [D loss: 0.325190, acc.: 88.28%] [G loss: 1.635270]\n",
      "epoch:34 step:32411 [D loss: 0.388925, acc.: 87.50%] [G loss: 1.477412]\n",
      "epoch:34 step:32412 [D loss: 0.567873, acc.: 71.09%] [G loss: 0.923620]\n",
      "epoch:34 step:32413 [D loss: 0.501699, acc.: 75.00%] [G loss: 1.737254]\n",
      "epoch:34 step:32414 [D loss: 0.600076, acc.: 71.88%] [G loss: 1.251282]\n",
      "epoch:34 step:32415 [D loss: 0.486564, acc.: 79.69%] [G loss: 1.437417]\n",
      "epoch:34 step:32416 [D loss: 0.534018, acc.: 73.44%] [G loss: 1.496173]\n",
      "epoch:34 step:32417 [D loss: 0.575744, acc.: 71.09%] [G loss: 1.394161]\n",
      "epoch:34 step:32418 [D loss: 0.443429, acc.: 84.38%] [G loss: 1.928191]\n",
      "epoch:34 step:32419 [D loss: 0.548813, acc.: 73.44%] [G loss: 1.508539]\n",
      "epoch:34 step:32420 [D loss: 0.625941, acc.: 63.28%] [G loss: 1.281505]\n",
      "epoch:34 step:32421 [D loss: 0.269573, acc.: 93.75%] [G loss: 1.759846]\n",
      "epoch:34 step:32422 [D loss: 0.411772, acc.: 83.59%] [G loss: 1.968598]\n",
      "epoch:34 step:32423 [D loss: 0.322093, acc.: 89.06%] [G loss: 1.687136]\n",
      "epoch:34 step:32424 [D loss: 0.301865, acc.: 91.41%] [G loss: 1.508796]\n",
      "epoch:34 step:32425 [D loss: 0.497672, acc.: 76.56%] [G loss: 1.274027]\n",
      "epoch:34 step:32426 [D loss: 0.560580, acc.: 75.00%] [G loss: 1.819497]\n",
      "epoch:34 step:32427 [D loss: 0.627554, acc.: 59.38%] [G loss: 1.834709]\n",
      "epoch:34 step:32428 [D loss: 0.675412, acc.: 60.16%] [G loss: 1.363586]\n",
      "epoch:34 step:32429 [D loss: 0.537097, acc.: 75.78%] [G loss: 1.503348]\n",
      "epoch:34 step:32430 [D loss: 0.369313, acc.: 86.72%] [G loss: 1.746636]\n",
      "epoch:34 step:32431 [D loss: 0.350927, acc.: 88.28%] [G loss: 1.633924]\n",
      "epoch:34 step:32432 [D loss: 0.392747, acc.: 82.81%] [G loss: 1.563194]\n",
      "epoch:34 step:32433 [D loss: 0.443654, acc.: 78.91%] [G loss: 1.799417]\n",
      "epoch:34 step:32434 [D loss: 0.434083, acc.: 88.28%] [G loss: 1.211305]\n",
      "epoch:34 step:32435 [D loss: 0.671669, acc.: 60.94%] [G loss: 1.622013]\n",
      "epoch:34 step:32436 [D loss: 0.547478, acc.: 75.00%] [G loss: 1.626098]\n",
      "epoch:34 step:32437 [D loss: 0.597031, acc.: 71.88%] [G loss: 1.700682]\n",
      "epoch:34 step:32438 [D loss: 0.625619, acc.: 68.75%] [G loss: 1.533807]\n",
      "epoch:34 step:32439 [D loss: 0.465681, acc.: 78.12%] [G loss: 1.390697]\n",
      "epoch:34 step:32440 [D loss: 0.495055, acc.: 81.25%] [G loss: 1.474041]\n",
      "epoch:34 step:32441 [D loss: 0.509933, acc.: 78.12%] [G loss: 1.792436]\n",
      "epoch:34 step:32442 [D loss: 0.504843, acc.: 75.78%] [G loss: 1.696702]\n",
      "epoch:34 step:32443 [D loss: 0.512432, acc.: 75.78%] [G loss: 2.187880]\n",
      "epoch:34 step:32444 [D loss: 0.440895, acc.: 82.81%] [G loss: 1.793204]\n",
      "epoch:34 step:32445 [D loss: 0.498518, acc.: 75.00%] [G loss: 1.066764]\n",
      "epoch:34 step:32446 [D loss: 0.673614, acc.: 62.50%] [G loss: 1.291425]\n",
      "epoch:34 step:32447 [D loss: 0.469255, acc.: 77.34%] [G loss: 1.720008]\n",
      "epoch:34 step:32448 [D loss: 0.464240, acc.: 82.81%] [G loss: 1.702426]\n",
      "epoch:34 step:32449 [D loss: 0.570008, acc.: 69.53%] [G loss: 1.378835]\n",
      "epoch:34 step:32450 [D loss: 0.535171, acc.: 70.31%] [G loss: 1.756750]\n",
      "epoch:34 step:32451 [D loss: 0.612224, acc.: 70.31%] [G loss: 1.367483]\n",
      "epoch:34 step:32452 [D loss: 0.581164, acc.: 67.97%] [G loss: 1.556118]\n",
      "epoch:34 step:32453 [D loss: 0.484765, acc.: 78.91%] [G loss: 1.068776]\n",
      "epoch:34 step:32454 [D loss: 0.514452, acc.: 74.22%] [G loss: 1.313018]\n",
      "epoch:34 step:32455 [D loss: 0.492562, acc.: 74.22%] [G loss: 1.463179]\n",
      "epoch:34 step:32456 [D loss: 0.633337, acc.: 61.72%] [G loss: 1.582011]\n",
      "epoch:34 step:32457 [D loss: 0.558452, acc.: 73.44%] [G loss: 1.627063]\n",
      "epoch:34 step:32458 [D loss: 0.297935, acc.: 90.62%] [G loss: 2.070024]\n",
      "epoch:34 step:32459 [D loss: 0.830628, acc.: 50.00%] [G loss: 1.373972]\n",
      "epoch:34 step:32460 [D loss: 0.345432, acc.: 89.06%] [G loss: 1.501065]\n",
      "epoch:34 step:32461 [D loss: 0.372772, acc.: 88.28%] [G loss: 2.015891]\n",
      "epoch:34 step:32462 [D loss: 0.750592, acc.: 54.69%] [G loss: 1.176558]\n",
      "epoch:34 step:32463 [D loss: 0.509213, acc.: 72.66%] [G loss: 1.881589]\n",
      "epoch:34 step:32464 [D loss: 0.620708, acc.: 60.94%] [G loss: 1.383899]\n",
      "epoch:34 step:32465 [D loss: 0.578894, acc.: 68.75%] [G loss: 1.670373]\n",
      "epoch:34 step:32466 [D loss: 0.508425, acc.: 80.47%] [G loss: 2.034685]\n",
      "epoch:34 step:32467 [D loss: 0.627671, acc.: 64.84%] [G loss: 1.444626]\n",
      "epoch:34 step:32468 [D loss: 0.634543, acc.: 60.94%] [G loss: 1.389637]\n",
      "epoch:34 step:32469 [D loss: 0.419601, acc.: 82.03%] [G loss: 1.685003]\n",
      "epoch:34 step:32470 [D loss: 0.473481, acc.: 78.12%] [G loss: 1.684498]\n",
      "epoch:34 step:32471 [D loss: 0.567233, acc.: 69.53%] [G loss: 1.258084]\n",
      "epoch:34 step:32472 [D loss: 0.576404, acc.: 68.75%] [G loss: 1.123865]\n",
      "epoch:34 step:32473 [D loss: 0.653510, acc.: 67.19%] [G loss: 1.245535]\n",
      "epoch:34 step:32474 [D loss: 0.382453, acc.: 87.50%] [G loss: 1.282731]\n",
      "epoch:34 step:32475 [D loss: 0.535284, acc.: 76.56%] [G loss: 1.313370]\n",
      "epoch:34 step:32476 [D loss: 0.564994, acc.: 69.53%] [G loss: 1.362211]\n",
      "epoch:34 step:32477 [D loss: 0.471337, acc.: 80.47%] [G loss: 2.040315]\n",
      "epoch:34 step:32478 [D loss: 0.504220, acc.: 81.25%] [G loss: 1.228049]\n",
      "epoch:34 step:32479 [D loss: 0.623802, acc.: 65.62%] [G loss: 0.973836]\n",
      "epoch:34 step:32480 [D loss: 0.546385, acc.: 72.66%] [G loss: 1.258449]\n",
      "epoch:34 step:32481 [D loss: 0.497636, acc.: 75.78%] [G loss: 1.686646]\n",
      "epoch:34 step:32482 [D loss: 0.600871, acc.: 67.19%] [G loss: 1.589721]\n",
      "epoch:34 step:32483 [D loss: 0.556174, acc.: 67.97%] [G loss: 1.458860]\n",
      "epoch:34 step:32484 [D loss: 0.550761, acc.: 71.88%] [G loss: 1.438158]\n",
      "epoch:34 step:32485 [D loss: 0.421381, acc.: 84.38%] [G loss: 1.539421]\n",
      "epoch:34 step:32486 [D loss: 0.416337, acc.: 84.38%] [G loss: 1.872692]\n",
      "epoch:34 step:32487 [D loss: 0.487891, acc.: 77.34%] [G loss: 1.766098]\n",
      "epoch:34 step:32488 [D loss: 0.487486, acc.: 78.91%] [G loss: 1.619413]\n",
      "epoch:34 step:32489 [D loss: 0.378052, acc.: 83.59%] [G loss: 1.003682]\n",
      "epoch:34 step:32490 [D loss: 0.440569, acc.: 78.12%] [G loss: 1.093097]\n",
      "epoch:34 step:32491 [D loss: 0.622573, acc.: 66.41%] [G loss: 1.638806]\n",
      "epoch:34 step:32492 [D loss: 0.488231, acc.: 71.88%] [G loss: 2.118866]\n",
      "epoch:34 step:32493 [D loss: 0.848244, acc.: 47.66%] [G loss: 1.354927]\n",
      "epoch:34 step:32494 [D loss: 0.428547, acc.: 79.69%] [G loss: 2.053174]\n",
      "epoch:34 step:32495 [D loss: 0.634112, acc.: 61.72%] [G loss: 1.658771]\n",
      "epoch:34 step:32496 [D loss: 0.516372, acc.: 75.78%] [G loss: 1.247171]\n",
      "epoch:34 step:32497 [D loss: 0.561493, acc.: 70.31%] [G loss: 2.041833]\n",
      "epoch:34 step:32498 [D loss: 0.356750, acc.: 87.50%] [G loss: 1.681412]\n",
      "epoch:34 step:32499 [D loss: 0.413422, acc.: 84.38%] [G loss: 1.837122]\n",
      "epoch:34 step:32500 [D loss: 0.541582, acc.: 75.78%] [G loss: 1.523462]\n",
      "epoch:34 step:32501 [D loss: 0.708620, acc.: 57.03%] [G loss: 1.611169]\n",
      "epoch:34 step:32502 [D loss: 0.466083, acc.: 79.69%] [G loss: 1.297309]\n",
      "epoch:34 step:32503 [D loss: 0.445344, acc.: 78.12%] [G loss: 1.795722]\n",
      "epoch:34 step:32504 [D loss: 0.521308, acc.: 71.09%] [G loss: 1.280207]\n",
      "epoch:34 step:32505 [D loss: 0.661301, acc.: 60.94%] [G loss: 0.960083]\n",
      "epoch:34 step:32506 [D loss: 0.567179, acc.: 73.44%] [G loss: 1.018727]\n",
      "epoch:34 step:32507 [D loss: 0.557852, acc.: 70.31%] [G loss: 1.940536]\n",
      "epoch:34 step:32508 [D loss: 0.559218, acc.: 70.31%] [G loss: 1.687042]\n",
      "epoch:34 step:32509 [D loss: 0.371291, acc.: 87.50%] [G loss: 1.379417]\n",
      "epoch:34 step:32510 [D loss: 0.497323, acc.: 79.69%] [G loss: 1.204699]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:34 step:32511 [D loss: 0.428482, acc.: 78.91%] [G loss: 1.750014]\n",
      "epoch:34 step:32512 [D loss: 0.456290, acc.: 80.47%] [G loss: 1.495826]\n",
      "epoch:34 step:32513 [D loss: 0.500411, acc.: 77.34%] [G loss: 1.523452]\n",
      "epoch:34 step:32514 [D loss: 0.474157, acc.: 79.69%] [G loss: 1.904454]\n",
      "epoch:34 step:32515 [D loss: 0.924574, acc.: 41.41%] [G loss: 1.311142]\n",
      "epoch:34 step:32516 [D loss: 0.694431, acc.: 66.41%] [G loss: 1.360566]\n",
      "epoch:34 step:32517 [D loss: 0.627696, acc.: 60.94%] [G loss: 1.613326]\n",
      "epoch:34 step:32518 [D loss: 0.483819, acc.: 79.69%] [G loss: 1.639713]\n",
      "epoch:34 step:32519 [D loss: 0.597480, acc.: 67.97%] [G loss: 0.989685]\n",
      "epoch:34 step:32520 [D loss: 0.548964, acc.: 74.22%] [G loss: 1.488371]\n",
      "epoch:34 step:32521 [D loss: 0.672336, acc.: 64.06%] [G loss: 1.786756]\n",
      "epoch:34 step:32522 [D loss: 0.435540, acc.: 82.81%] [G loss: 1.433586]\n",
      "epoch:34 step:32523 [D loss: 0.447949, acc.: 82.81%] [G loss: 1.047412]\n",
      "epoch:34 step:32524 [D loss: 0.474304, acc.: 77.34%] [G loss: 1.578763]\n",
      "epoch:34 step:32525 [D loss: 0.295080, acc.: 92.19%] [G loss: 1.991253]\n",
      "epoch:34 step:32526 [D loss: 0.765404, acc.: 59.38%] [G loss: 1.210622]\n",
      "epoch:34 step:32527 [D loss: 0.519994, acc.: 80.47%] [G loss: 1.396131]\n",
      "epoch:34 step:32528 [D loss: 0.421327, acc.: 82.03%] [G loss: 1.308705]\n",
      "epoch:34 step:32529 [D loss: 0.594925, acc.: 66.41%] [G loss: 0.936372]\n",
      "epoch:34 step:32530 [D loss: 0.539678, acc.: 71.09%] [G loss: 1.702665]\n",
      "epoch:34 step:32531 [D loss: 0.683545, acc.: 60.94%] [G loss: 1.520166]\n",
      "epoch:34 step:32532 [D loss: 0.475105, acc.: 78.12%] [G loss: 1.901739]\n",
      "epoch:34 step:32533 [D loss: 0.565756, acc.: 66.41%] [G loss: 1.554577]\n",
      "epoch:34 step:32534 [D loss: 0.465879, acc.: 78.12%] [G loss: 1.562575]\n",
      "epoch:34 step:32535 [D loss: 0.398161, acc.: 85.16%] [G loss: 1.653276]\n",
      "epoch:34 step:32536 [D loss: 0.634264, acc.: 64.84%] [G loss: 1.630731]\n",
      "epoch:34 step:32537 [D loss: 0.518427, acc.: 72.66%] [G loss: 1.506803]\n",
      "epoch:34 step:32538 [D loss: 0.684530, acc.: 57.03%] [G loss: 1.165104]\n",
      "epoch:34 step:32539 [D loss: 0.499675, acc.: 75.78%] [G loss: 1.405626]\n",
      "epoch:34 step:32540 [D loss: 0.576644, acc.: 66.41%] [G loss: 1.747525]\n",
      "epoch:34 step:32541 [D loss: 0.576388, acc.: 70.31%] [G loss: 1.773557]\n",
      "epoch:34 step:32542 [D loss: 0.437251, acc.: 85.16%] [G loss: 1.447206]\n",
      "epoch:34 step:32543 [D loss: 0.454558, acc.: 82.03%] [G loss: 1.584087]\n",
      "epoch:34 step:32544 [D loss: 0.467196, acc.: 76.56%] [G loss: 1.377269]\n",
      "epoch:34 step:32545 [D loss: 0.465452, acc.: 79.69%] [G loss: 1.812848]\n",
      "epoch:34 step:32546 [D loss: 0.516264, acc.: 75.00%] [G loss: 1.436762]\n",
      "epoch:34 step:32547 [D loss: 0.583327, acc.: 74.22%] [G loss: 1.567679]\n",
      "epoch:34 step:32548 [D loss: 0.450943, acc.: 78.91%] [G loss: 1.408786]\n",
      "epoch:34 step:32549 [D loss: 0.421555, acc.: 84.38%] [G loss: 1.421512]\n",
      "epoch:34 step:32550 [D loss: 0.460369, acc.: 79.69%] [G loss: 1.852764]\n",
      "epoch:34 step:32551 [D loss: 0.449883, acc.: 82.81%] [G loss: 1.298367]\n",
      "epoch:34 step:32552 [D loss: 0.575287, acc.: 67.97%] [G loss: 1.297228]\n",
      "epoch:34 step:32553 [D loss: 0.403860, acc.: 85.16%] [G loss: 1.761307]\n",
      "epoch:34 step:32554 [D loss: 0.569213, acc.: 73.44%] [G loss: 1.428416]\n",
      "epoch:34 step:32555 [D loss: 0.558970, acc.: 70.31%] [G loss: 1.203917]\n",
      "epoch:34 step:32556 [D loss: 0.428499, acc.: 78.91%] [G loss: 1.395625]\n",
      "epoch:34 step:32557 [D loss: 0.324084, acc.: 91.41%] [G loss: 2.001548]\n",
      "epoch:34 step:32558 [D loss: 0.512176, acc.: 78.91%] [G loss: 1.437879]\n",
      "epoch:34 step:32559 [D loss: 0.288813, acc.: 92.97%] [G loss: 2.166692]\n",
      "epoch:34 step:32560 [D loss: 0.438408, acc.: 79.69%] [G loss: 2.238635]\n",
      "epoch:34 step:32561 [D loss: 0.676118, acc.: 65.62%] [G loss: 1.517671]\n",
      "epoch:34 step:32562 [D loss: 0.546357, acc.: 71.09%] [G loss: 1.706821]\n",
      "epoch:34 step:32563 [D loss: 0.531596, acc.: 74.22%] [G loss: 1.352491]\n",
      "epoch:34 step:32564 [D loss: 0.523403, acc.: 72.66%] [G loss: 1.588609]\n",
      "epoch:34 step:32565 [D loss: 0.428493, acc.: 86.72%] [G loss: 2.256121]\n",
      "epoch:34 step:32566 [D loss: 0.454098, acc.: 78.12%] [G loss: 1.903974]\n",
      "epoch:34 step:32567 [D loss: 0.715757, acc.: 62.50%] [G loss: 1.550172]\n",
      "epoch:34 step:32568 [D loss: 0.518101, acc.: 75.00%] [G loss: 1.266028]\n",
      "epoch:34 step:32569 [D loss: 0.431748, acc.: 81.25%] [G loss: 1.352990]\n",
      "epoch:34 step:32570 [D loss: 0.396777, acc.: 82.81%] [G loss: 1.702991]\n",
      "epoch:34 step:32571 [D loss: 0.331841, acc.: 89.06%] [G loss: 0.979400]\n",
      "epoch:34 step:32572 [D loss: 0.551763, acc.: 70.31%] [G loss: 1.634953]\n",
      "epoch:34 step:32573 [D loss: 0.566099, acc.: 71.88%] [G loss: 1.267077]\n",
      "epoch:34 step:32574 [D loss: 0.464102, acc.: 78.91%] [G loss: 1.585618]\n",
      "epoch:34 step:32575 [D loss: 0.326495, acc.: 89.06%] [G loss: 1.816233]\n",
      "epoch:34 step:32576 [D loss: 0.414971, acc.: 82.81%] [G loss: 1.739228]\n",
      "epoch:34 step:32577 [D loss: 0.549907, acc.: 71.88%] [G loss: 1.448848]\n",
      "epoch:34 step:32578 [D loss: 0.622821, acc.: 62.50%] [G loss: 1.555867]\n",
      "epoch:34 step:32579 [D loss: 0.427322, acc.: 84.38%] [G loss: 1.213484]\n",
      "epoch:34 step:32580 [D loss: 0.605973, acc.: 70.31%] [G loss: 1.368734]\n",
      "epoch:34 step:32581 [D loss: 0.608258, acc.: 71.09%] [G loss: 1.223848]\n",
      "epoch:34 step:32582 [D loss: 0.417917, acc.: 83.59%] [G loss: 1.240229]\n",
      "epoch:34 step:32583 [D loss: 0.452355, acc.: 84.38%] [G loss: 1.605585]\n",
      "epoch:34 step:32584 [D loss: 0.740917, acc.: 52.34%] [G loss: 2.085757]\n",
      "epoch:34 step:32585 [D loss: 0.355657, acc.: 84.38%] [G loss: 2.265971]\n",
      "epoch:34 step:32586 [D loss: 0.718811, acc.: 57.81%] [G loss: 1.638988]\n",
      "epoch:34 step:32587 [D loss: 0.713404, acc.: 62.50%] [G loss: 1.052356]\n",
      "epoch:34 step:32588 [D loss: 0.620399, acc.: 67.19%] [G loss: 1.766858]\n",
      "epoch:34 step:32589 [D loss: 0.672539, acc.: 60.94%] [G loss: 1.452532]\n",
      "epoch:34 step:32590 [D loss: 0.509021, acc.: 74.22%] [G loss: 1.616937]\n",
      "epoch:34 step:32591 [D loss: 0.466207, acc.: 78.91%] [G loss: 1.397963]\n",
      "epoch:34 step:32592 [D loss: 0.484765, acc.: 75.78%] [G loss: 0.938457]\n",
      "epoch:34 step:32593 [D loss: 0.607221, acc.: 68.75%] [G loss: 1.474458]\n",
      "epoch:34 step:32594 [D loss: 0.544124, acc.: 71.09%] [G loss: 1.294314]\n",
      "epoch:34 step:32595 [D loss: 0.507253, acc.: 75.00%] [G loss: 1.507464]\n",
      "epoch:34 step:32596 [D loss: 0.643204, acc.: 68.75%] [G loss: 1.540961]\n",
      "epoch:34 step:32597 [D loss: 0.727325, acc.: 58.59%] [G loss: 1.522459]\n",
      "epoch:34 step:32598 [D loss: 0.680292, acc.: 60.94%] [G loss: 1.186495]\n",
      "epoch:34 step:32599 [D loss: 0.655478, acc.: 63.28%] [G loss: 1.672693]\n",
      "epoch:34 step:32600 [D loss: 0.440745, acc.: 84.38%] [G loss: 1.001741]\n",
      "epoch:34 step:32601 [D loss: 0.515262, acc.: 74.22%] [G loss: 1.422206]\n",
      "epoch:34 step:32602 [D loss: 0.584878, acc.: 66.41%] [G loss: 1.140572]\n",
      "epoch:34 step:32603 [D loss: 0.468519, acc.: 79.69%] [G loss: 1.948965]\n",
      "epoch:34 step:32604 [D loss: 0.540979, acc.: 77.34%] [G loss: 2.361856]\n",
      "epoch:34 step:32605 [D loss: 0.414074, acc.: 83.59%] [G loss: 1.607033]\n",
      "epoch:34 step:32606 [D loss: 0.550189, acc.: 75.00%] [G loss: 1.630044]\n",
      "epoch:34 step:32607 [D loss: 0.506133, acc.: 73.44%] [G loss: 1.461326]\n",
      "epoch:34 step:32608 [D loss: 0.718543, acc.: 60.94%] [G loss: 1.353964]\n",
      "epoch:34 step:32609 [D loss: 0.557148, acc.: 71.88%] [G loss: 2.316334]\n",
      "epoch:34 step:32610 [D loss: 0.688053, acc.: 64.06%] [G loss: 1.765222]\n",
      "epoch:34 step:32611 [D loss: 0.340837, acc.: 86.72%] [G loss: 1.886595]\n",
      "epoch:34 step:32612 [D loss: 0.508625, acc.: 76.56%] [G loss: 1.216529]\n",
      "epoch:34 step:32613 [D loss: 0.513456, acc.: 78.12%] [G loss: 1.587036]\n",
      "epoch:34 step:32614 [D loss: 0.576458, acc.: 73.44%] [G loss: 1.677689]\n",
      "epoch:34 step:32615 [D loss: 0.551675, acc.: 68.75%] [G loss: 1.780115]\n",
      "epoch:34 step:32616 [D loss: 0.453953, acc.: 79.69%] [G loss: 1.958960]\n",
      "epoch:34 step:32617 [D loss: 0.525732, acc.: 74.22%] [G loss: 1.362717]\n",
      "epoch:34 step:32618 [D loss: 0.479778, acc.: 81.25%] [G loss: 1.629109]\n",
      "epoch:34 step:32619 [D loss: 0.621252, acc.: 66.41%] [G loss: 1.122425]\n",
      "epoch:34 step:32620 [D loss: 0.719697, acc.: 57.81%] [G loss: 1.444973]\n",
      "epoch:34 step:32621 [D loss: 0.477055, acc.: 75.78%] [G loss: 1.501887]\n",
      "epoch:34 step:32622 [D loss: 0.476766, acc.: 78.91%] [G loss: 1.630936]\n",
      "epoch:34 step:32623 [D loss: 0.537747, acc.: 68.75%] [G loss: 1.618809]\n",
      "epoch:34 step:32624 [D loss: 0.503193, acc.: 76.56%] [G loss: 1.413007]\n",
      "epoch:34 step:32625 [D loss: 0.573823, acc.: 68.75%] [G loss: 1.281523]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:34 step:32626 [D loss: 0.565075, acc.: 70.31%] [G loss: 1.537055]\n",
      "epoch:34 step:32627 [D loss: 0.576534, acc.: 71.88%] [G loss: 1.390725]\n",
      "epoch:34 step:32628 [D loss: 0.761334, acc.: 60.94%] [G loss: 1.399534]\n",
      "epoch:34 step:32629 [D loss: 0.627262, acc.: 68.75%] [G loss: 1.165123]\n",
      "epoch:34 step:32630 [D loss: 0.570095, acc.: 66.41%] [G loss: 1.347382]\n",
      "epoch:34 step:32631 [D loss: 0.759618, acc.: 53.12%] [G loss: 0.906974]\n",
      "epoch:34 step:32632 [D loss: 0.389033, acc.: 86.72%] [G loss: 1.776755]\n",
      "epoch:34 step:32633 [D loss: 0.479734, acc.: 77.34%] [G loss: 1.760415]\n",
      "epoch:34 step:32634 [D loss: 0.438516, acc.: 78.91%] [G loss: 2.064529]\n",
      "epoch:34 step:32635 [D loss: 0.675164, acc.: 64.06%] [G loss: 1.763027]\n",
      "epoch:34 step:32636 [D loss: 0.624513, acc.: 61.72%] [G loss: 1.812760]\n",
      "epoch:34 step:32637 [D loss: 0.665830, acc.: 62.50%] [G loss: 1.329019]\n",
      "epoch:34 step:32638 [D loss: 0.599522, acc.: 69.53%] [G loss: 1.664849]\n",
      "epoch:34 step:32639 [D loss: 0.600019, acc.: 74.22%] [G loss: 1.582540]\n",
      "epoch:34 step:32640 [D loss: 0.501518, acc.: 77.34%] [G loss: 1.479714]\n",
      "epoch:34 step:32641 [D loss: 0.460176, acc.: 81.25%] [G loss: 1.707869]\n",
      "epoch:34 step:32642 [D loss: 0.627098, acc.: 64.84%] [G loss: 1.404279]\n",
      "epoch:34 step:32643 [D loss: 0.403667, acc.: 85.16%] [G loss: 1.568011]\n",
      "epoch:34 step:32644 [D loss: 0.649002, acc.: 63.28%] [G loss: 1.563587]\n",
      "epoch:34 step:32645 [D loss: 0.561707, acc.: 72.66%] [G loss: 0.942467]\n",
      "epoch:34 step:32646 [D loss: 0.773640, acc.: 55.47%] [G loss: 1.360307]\n",
      "epoch:34 step:32647 [D loss: 0.461139, acc.: 82.03%] [G loss: 1.324718]\n",
      "epoch:34 step:32648 [D loss: 0.635266, acc.: 63.28%] [G loss: 1.090080]\n",
      "epoch:34 step:32649 [D loss: 0.460860, acc.: 78.12%] [G loss: 1.405566]\n",
      "epoch:34 step:32650 [D loss: 0.552124, acc.: 70.31%] [G loss: 1.733130]\n",
      "epoch:34 step:32651 [D loss: 0.455848, acc.: 80.47%] [G loss: 2.217327]\n",
      "epoch:34 step:32652 [D loss: 0.734147, acc.: 55.47%] [G loss: 1.374034]\n",
      "epoch:34 step:32653 [D loss: 0.477331, acc.: 76.56%] [G loss: 1.531873]\n",
      "epoch:34 step:32654 [D loss: 0.681714, acc.: 58.59%] [G loss: 1.034894]\n",
      "epoch:34 step:32655 [D loss: 0.448256, acc.: 78.91%] [G loss: 1.722558]\n",
      "epoch:34 step:32656 [D loss: 0.621971, acc.: 63.28%] [G loss: 1.792302]\n",
      "epoch:34 step:32657 [D loss: 0.418909, acc.: 78.91%] [G loss: 1.813636]\n",
      "epoch:34 step:32658 [D loss: 0.673595, acc.: 60.16%] [G loss: 1.273186]\n",
      "epoch:34 step:32659 [D loss: 0.581754, acc.: 73.44%] [G loss: 1.398951]\n",
      "epoch:34 step:32660 [D loss: 0.608328, acc.: 68.75%] [G loss: 1.509670]\n",
      "epoch:34 step:32661 [D loss: 0.689710, acc.: 59.38%] [G loss: 1.471102]\n",
      "epoch:34 step:32662 [D loss: 0.549067, acc.: 73.44%] [G loss: 1.578367]\n",
      "epoch:34 step:32663 [D loss: 0.688862, acc.: 62.50%] [G loss: 1.816828]\n",
      "epoch:34 step:32664 [D loss: 0.433996, acc.: 82.03%] [G loss: 1.696113]\n",
      "epoch:34 step:32665 [D loss: 0.627754, acc.: 63.28%] [G loss: 1.465392]\n",
      "epoch:34 step:32666 [D loss: 0.351744, acc.: 86.72%] [G loss: 1.361140]\n",
      "epoch:34 step:32667 [D loss: 0.609311, acc.: 67.19%] [G loss: 1.554452]\n",
      "epoch:34 step:32668 [D loss: 0.435974, acc.: 78.12%] [G loss: 1.898684]\n",
      "epoch:34 step:32669 [D loss: 0.486049, acc.: 76.56%] [G loss: 1.909516]\n",
      "epoch:34 step:32670 [D loss: 0.487836, acc.: 78.12%] [G loss: 1.396920]\n",
      "epoch:34 step:32671 [D loss: 0.740809, acc.: 59.38%] [G loss: 1.594470]\n",
      "epoch:34 step:32672 [D loss: 0.596950, acc.: 66.41%] [G loss: 1.183440]\n",
      "epoch:34 step:32673 [D loss: 0.617755, acc.: 65.62%] [G loss: 1.721957]\n",
      "epoch:34 step:32674 [D loss: 0.299471, acc.: 91.41%] [G loss: 1.448809]\n",
      "epoch:34 step:32675 [D loss: 0.635630, acc.: 67.19%] [G loss: 1.350980]\n",
      "epoch:34 step:32676 [D loss: 0.490564, acc.: 77.34%] [G loss: 1.090900]\n",
      "epoch:34 step:32677 [D loss: 0.491609, acc.: 78.12%] [G loss: 1.499922]\n",
      "epoch:34 step:32678 [D loss: 0.508233, acc.: 75.78%] [G loss: 1.298182]\n",
      "epoch:34 step:32679 [D loss: 0.581837, acc.: 68.75%] [G loss: 1.524856]\n",
      "epoch:34 step:32680 [D loss: 0.589292, acc.: 72.66%] [G loss: 1.239126]\n",
      "epoch:34 step:32681 [D loss: 0.611298, acc.: 66.41%] [G loss: 1.363665]\n",
      "epoch:34 step:32682 [D loss: 0.565416, acc.: 71.88%] [G loss: 1.062532]\n",
      "epoch:34 step:32683 [D loss: 0.499028, acc.: 75.78%] [G loss: 1.210449]\n",
      "epoch:34 step:32684 [D loss: 0.546479, acc.: 74.22%] [G loss: 1.491103]\n",
      "epoch:34 step:32685 [D loss: 0.694971, acc.: 63.28%] [G loss: 1.898864]\n",
      "epoch:34 step:32686 [D loss: 0.613651, acc.: 67.19%] [G loss: 1.559833]\n",
      "epoch:34 step:32687 [D loss: 0.521279, acc.: 71.88%] [G loss: 1.359358]\n",
      "epoch:34 step:32688 [D loss: 0.395680, acc.: 85.16%] [G loss: 1.636349]\n",
      "epoch:34 step:32689 [D loss: 0.635755, acc.: 64.84%] [G loss: 1.120200]\n",
      "epoch:34 step:32690 [D loss: 0.467354, acc.: 80.47%] [G loss: 1.475349]\n",
      "epoch:34 step:32691 [D loss: 0.419903, acc.: 82.03%] [G loss: 1.485345]\n",
      "epoch:34 step:32692 [D loss: 0.720823, acc.: 59.38%] [G loss: 1.467845]\n",
      "epoch:34 step:32693 [D loss: 0.544037, acc.: 74.22%] [G loss: 1.238366]\n",
      "epoch:34 step:32694 [D loss: 0.717475, acc.: 57.81%] [G loss: 1.079783]\n",
      "epoch:34 step:32695 [D loss: 0.560615, acc.: 66.41%] [G loss: 1.464077]\n",
      "epoch:34 step:32696 [D loss: 0.606252, acc.: 65.62%] [G loss: 1.591537]\n",
      "epoch:34 step:32697 [D loss: 0.512468, acc.: 75.00%] [G loss: 1.471494]\n",
      "epoch:34 step:32698 [D loss: 0.454904, acc.: 78.12%] [G loss: 1.402112]\n",
      "epoch:34 step:32699 [D loss: 0.527133, acc.: 72.66%] [G loss: 1.916597]\n",
      "epoch:34 step:32700 [D loss: 0.489071, acc.: 72.66%] [G loss: 1.166885]\n",
      "epoch:34 step:32701 [D loss: 0.557955, acc.: 67.19%] [G loss: 1.133451]\n",
      "epoch:34 step:32702 [D loss: 0.722879, acc.: 58.59%] [G loss: 1.591042]\n",
      "epoch:34 step:32703 [D loss: 0.508329, acc.: 78.12%] [G loss: 1.746190]\n",
      "epoch:34 step:32704 [D loss: 0.486370, acc.: 77.34%] [G loss: 1.815845]\n",
      "epoch:34 step:32705 [D loss: 0.574862, acc.: 71.88%] [G loss: 1.664398]\n",
      "epoch:34 step:32706 [D loss: 0.796325, acc.: 48.44%] [G loss: 1.127437]\n",
      "epoch:34 step:32707 [D loss: 0.506258, acc.: 75.00%] [G loss: 1.613656]\n",
      "epoch:34 step:32708 [D loss: 0.351132, acc.: 90.62%] [G loss: 1.195578]\n",
      "epoch:34 step:32709 [D loss: 0.445265, acc.: 78.12%] [G loss: 1.321849]\n",
      "epoch:34 step:32710 [D loss: 0.555161, acc.: 76.56%] [G loss: 1.285237]\n",
      "epoch:34 step:32711 [D loss: 0.659220, acc.: 61.72%] [G loss: 1.556489]\n",
      "epoch:34 step:32712 [D loss: 0.562690, acc.: 66.41%] [G loss: 1.149288]\n",
      "epoch:34 step:32713 [D loss: 0.491205, acc.: 74.22%] [G loss: 1.413187]\n",
      "epoch:34 step:32714 [D loss: 0.420949, acc.: 85.16%] [G loss: 1.273503]\n",
      "epoch:34 step:32715 [D loss: 0.371088, acc.: 82.03%] [G loss: 1.378389]\n",
      "epoch:34 step:32716 [D loss: 0.406462, acc.: 81.25%] [G loss: 1.434235]\n",
      "epoch:34 step:32717 [D loss: 0.548718, acc.: 71.88%] [G loss: 1.742486]\n",
      "epoch:34 step:32718 [D loss: 0.752785, acc.: 55.47%] [G loss: 1.095528]\n",
      "epoch:34 step:32719 [D loss: 0.379500, acc.: 84.38%] [G loss: 1.932834]\n",
      "epoch:34 step:32720 [D loss: 0.507225, acc.: 70.31%] [G loss: 1.294640]\n",
      "epoch:34 step:32721 [D loss: 0.451783, acc.: 77.34%] [G loss: 1.607351]\n",
      "epoch:34 step:32722 [D loss: 0.569516, acc.: 66.41%] [G loss: 1.822866]\n",
      "epoch:34 step:32723 [D loss: 0.371025, acc.: 85.94%] [G loss: 1.361667]\n",
      "epoch:34 step:32724 [D loss: 0.493615, acc.: 78.91%] [G loss: 1.077803]\n",
      "epoch:34 step:32725 [D loss: 0.486076, acc.: 82.03%] [G loss: 1.485286]\n",
      "epoch:34 step:32726 [D loss: 0.543030, acc.: 67.97%] [G loss: 1.762921]\n",
      "epoch:34 step:32727 [D loss: 0.594927, acc.: 72.66%] [G loss: 1.512085]\n",
      "epoch:34 step:32728 [D loss: 0.434973, acc.: 85.94%] [G loss: 1.493202]\n",
      "epoch:34 step:32729 [D loss: 0.654401, acc.: 63.28%] [G loss: 1.338365]\n",
      "epoch:34 step:32730 [D loss: 0.703765, acc.: 54.69%] [G loss: 1.431938]\n",
      "epoch:34 step:32731 [D loss: 0.415439, acc.: 86.72%] [G loss: 1.562252]\n",
      "epoch:34 step:32732 [D loss: 0.509278, acc.: 75.00%] [G loss: 1.958511]\n",
      "epoch:34 step:32733 [D loss: 0.490853, acc.: 78.91%] [G loss: 1.634278]\n",
      "epoch:34 step:32734 [D loss: 0.624168, acc.: 70.31%] [G loss: 1.226534]\n",
      "epoch:34 step:32735 [D loss: 0.551302, acc.: 67.97%] [G loss: 1.280696]\n",
      "epoch:34 step:32736 [D loss: 0.537605, acc.: 74.22%] [G loss: 1.299592]\n",
      "epoch:34 step:32737 [D loss: 0.529039, acc.: 74.22%] [G loss: 1.014044]\n",
      "epoch:34 step:32738 [D loss: 0.475916, acc.: 78.12%] [G loss: 1.309486]\n",
      "epoch:34 step:32739 [D loss: 0.430931, acc.: 82.03%] [G loss: 1.429002]\n",
      "epoch:34 step:32740 [D loss: 0.377360, acc.: 85.16%] [G loss: 1.574606]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:34 step:32741 [D loss: 0.551625, acc.: 72.66%] [G loss: 1.695859]\n",
      "epoch:34 step:32742 [D loss: 0.567529, acc.: 70.31%] [G loss: 1.377103]\n",
      "epoch:34 step:32743 [D loss: 0.480761, acc.: 76.56%] [G loss: 1.761870]\n",
      "epoch:34 step:32744 [D loss: 0.370094, acc.: 85.16%] [G loss: 1.128011]\n",
      "epoch:34 step:32745 [D loss: 0.395541, acc.: 85.16%] [G loss: 1.493578]\n",
      "epoch:34 step:32746 [D loss: 0.512687, acc.: 71.09%] [G loss: 1.102886]\n",
      "epoch:34 step:32747 [D loss: 0.559939, acc.: 71.09%] [G loss: 1.239851]\n",
      "epoch:34 step:32748 [D loss: 0.843737, acc.: 49.22%] [G loss: 0.875067]\n",
      "epoch:34 step:32749 [D loss: 0.613020, acc.: 65.62%] [G loss: 1.201389]\n",
      "epoch:34 step:32750 [D loss: 0.556204, acc.: 73.44%] [G loss: 1.554290]\n",
      "epoch:34 step:32751 [D loss: 0.480331, acc.: 79.69%] [G loss: 1.614016]\n",
      "epoch:34 step:32752 [D loss: 0.536676, acc.: 71.88%] [G loss: 1.330442]\n",
      "epoch:34 step:32753 [D loss: 0.396183, acc.: 85.16%] [G loss: 2.214462]\n",
      "epoch:34 step:32754 [D loss: 0.441510, acc.: 80.47%] [G loss: 2.027162]\n",
      "epoch:34 step:32755 [D loss: 0.715541, acc.: 50.00%] [G loss: 1.691881]\n",
      "epoch:34 step:32756 [D loss: 0.361780, acc.: 86.72%] [G loss: 1.514167]\n",
      "epoch:34 step:32757 [D loss: 0.512732, acc.: 78.91%] [G loss: 2.028035]\n",
      "epoch:34 step:32758 [D loss: 0.388895, acc.: 85.94%] [G loss: 2.020650]\n",
      "epoch:34 step:32759 [D loss: 0.529016, acc.: 73.44%] [G loss: 1.267195]\n",
      "epoch:34 step:32760 [D loss: 0.524899, acc.: 72.66%] [G loss: 1.444729]\n",
      "epoch:34 step:32761 [D loss: 0.626930, acc.: 67.19%] [G loss: 1.329031]\n",
      "epoch:34 step:32762 [D loss: 0.485496, acc.: 75.00%] [G loss: 1.547409]\n",
      "epoch:34 step:32763 [D loss: 0.649079, acc.: 64.06%] [G loss: 1.141921]\n",
      "epoch:34 step:32764 [D loss: 0.587591, acc.: 68.75%] [G loss: 1.763100]\n",
      "epoch:34 step:32765 [D loss: 0.301350, acc.: 89.06%] [G loss: 1.707211]\n",
      "epoch:34 step:32766 [D loss: 0.591590, acc.: 67.19%] [G loss: 1.528314]\n",
      "epoch:34 step:32767 [D loss: 0.521492, acc.: 75.00%] [G loss: 1.782324]\n",
      "epoch:34 step:32768 [D loss: 0.320953, acc.: 89.06%] [G loss: 2.093836]\n",
      "epoch:34 step:32769 [D loss: 0.364060, acc.: 83.59%] [G loss: 2.009957]\n",
      "epoch:34 step:32770 [D loss: 0.544810, acc.: 75.78%] [G loss: 1.356051]\n",
      "epoch:34 step:32771 [D loss: 0.493707, acc.: 75.78%] [G loss: 1.689402]\n",
      "epoch:34 step:32772 [D loss: 0.668162, acc.: 66.41%] [G loss: 1.867999]\n",
      "epoch:34 step:32773 [D loss: 0.547536, acc.: 72.66%] [G loss: 1.481470]\n",
      "epoch:34 step:32774 [D loss: 0.663818, acc.: 62.50%] [G loss: 1.569160]\n",
      "epoch:34 step:32775 [D loss: 0.390678, acc.: 88.28%] [G loss: 1.462344]\n",
      "epoch:34 step:32776 [D loss: 0.514627, acc.: 80.47%] [G loss: 1.922395]\n",
      "epoch:34 step:32777 [D loss: 0.482661, acc.: 74.22%] [G loss: 1.705288]\n",
      "epoch:34 step:32778 [D loss: 0.487111, acc.: 73.44%] [G loss: 1.316381]\n",
      "epoch:34 step:32779 [D loss: 0.346894, acc.: 89.06%] [G loss: 1.237469]\n",
      "epoch:34 step:32780 [D loss: 0.382487, acc.: 83.59%] [G loss: 1.622926]\n",
      "epoch:34 step:32781 [D loss: 0.570453, acc.: 71.09%] [G loss: 1.140421]\n",
      "epoch:34 step:32782 [D loss: 0.513081, acc.: 73.44%] [G loss: 1.530951]\n",
      "epoch:34 step:32783 [D loss: 0.481942, acc.: 75.00%] [G loss: 1.845883]\n",
      "epoch:34 step:32784 [D loss: 0.603230, acc.: 66.41%] [G loss: 1.600550]\n",
      "epoch:34 step:32785 [D loss: 0.540074, acc.: 74.22%] [G loss: 1.793844]\n",
      "epoch:34 step:32786 [D loss: 0.290824, acc.: 88.28%] [G loss: 1.651470]\n",
      "epoch:34 step:32787 [D loss: 0.494960, acc.: 76.56%] [G loss: 1.584558]\n",
      "epoch:34 step:32788 [D loss: 0.448483, acc.: 78.91%] [G loss: 1.809179]\n",
      "epoch:34 step:32789 [D loss: 0.488698, acc.: 78.12%] [G loss: 1.637110]\n",
      "epoch:34 step:32790 [D loss: 0.485917, acc.: 79.69%] [G loss: 2.160897]\n",
      "epoch:34 step:32791 [D loss: 0.588956, acc.: 70.31%] [G loss: 1.078242]\n",
      "epoch:34 step:32792 [D loss: 0.539259, acc.: 69.53%] [G loss: 1.335320]\n",
      "epoch:34 step:32793 [D loss: 0.453123, acc.: 79.69%] [G loss: 2.015623]\n",
      "epoch:34 step:32794 [D loss: 0.429585, acc.: 81.25%] [G loss: 1.394406]\n",
      "epoch:34 step:32795 [D loss: 0.550035, acc.: 71.09%] [G loss: 1.629855]\n",
      "epoch:35 step:32796 [D loss: 0.448461, acc.: 79.69%] [G loss: 1.407194]\n",
      "epoch:35 step:32797 [D loss: 0.399993, acc.: 81.25%] [G loss: 1.480162]\n",
      "epoch:35 step:32798 [D loss: 0.628712, acc.: 67.19%] [G loss: 1.111123]\n",
      "epoch:35 step:32799 [D loss: 0.279585, acc.: 94.53%] [G loss: 1.592896]\n",
      "epoch:35 step:32800 [D loss: 0.599332, acc.: 67.19%] [G loss: 1.642485]\n",
      "epoch:35 step:32801 [D loss: 0.565528, acc.: 70.31%] [G loss: 1.274008]\n",
      "epoch:35 step:32802 [D loss: 0.658930, acc.: 63.28%] [G loss: 1.647388]\n",
      "epoch:35 step:32803 [D loss: 0.636937, acc.: 67.19%] [G loss: 0.725479]\n",
      "epoch:35 step:32804 [D loss: 0.417607, acc.: 85.16%] [G loss: 1.321750]\n",
      "epoch:35 step:32805 [D loss: 0.571017, acc.: 69.53%] [G loss: 1.449383]\n",
      "epoch:35 step:32806 [D loss: 0.422989, acc.: 80.47%] [G loss: 1.543445]\n",
      "epoch:35 step:32807 [D loss: 0.424387, acc.: 84.38%] [G loss: 1.303789]\n",
      "epoch:35 step:32808 [D loss: 0.521057, acc.: 74.22%] [G loss: 1.792777]\n",
      "epoch:35 step:32809 [D loss: 0.754058, acc.: 57.81%] [G loss: 1.217646]\n",
      "epoch:35 step:32810 [D loss: 0.383252, acc.: 82.81%] [G loss: 1.352149]\n",
      "epoch:35 step:32811 [D loss: 0.409092, acc.: 82.81%] [G loss: 1.377766]\n",
      "epoch:35 step:32812 [D loss: 0.510855, acc.: 76.56%] [G loss: 1.525871]\n",
      "epoch:35 step:32813 [D loss: 0.533462, acc.: 73.44%] [G loss: 1.268589]\n",
      "epoch:35 step:32814 [D loss: 0.616639, acc.: 69.53%] [G loss: 1.437159]\n",
      "epoch:35 step:32815 [D loss: 0.483055, acc.: 78.91%] [G loss: 1.400529]\n",
      "epoch:35 step:32816 [D loss: 0.629175, acc.: 69.53%] [G loss: 1.577262]\n",
      "epoch:35 step:32817 [D loss: 0.552951, acc.: 73.44%] [G loss: 1.324475]\n",
      "epoch:35 step:32818 [D loss: 0.438445, acc.: 82.03%] [G loss: 1.119680]\n",
      "epoch:35 step:32819 [D loss: 0.407920, acc.: 83.59%] [G loss: 1.768849]\n",
      "epoch:35 step:32820 [D loss: 0.431661, acc.: 84.38%] [G loss: 1.958039]\n",
      "epoch:35 step:32821 [D loss: 0.764416, acc.: 50.78%] [G loss: 1.672512]\n",
      "epoch:35 step:32822 [D loss: 0.528724, acc.: 69.53%] [G loss: 1.399737]\n",
      "epoch:35 step:32823 [D loss: 0.566893, acc.: 73.44%] [G loss: 2.067537]\n",
      "epoch:35 step:32824 [D loss: 0.724579, acc.: 55.47%] [G loss: 1.232107]\n",
      "epoch:35 step:32825 [D loss: 0.617587, acc.: 70.31%] [G loss: 1.749593]\n",
      "epoch:35 step:32826 [D loss: 0.493172, acc.: 78.12%] [G loss: 1.964619]\n",
      "epoch:35 step:32827 [D loss: 0.541592, acc.: 71.88%] [G loss: 1.085183]\n",
      "epoch:35 step:32828 [D loss: 0.545911, acc.: 71.88%] [G loss: 1.575752]\n",
      "epoch:35 step:32829 [D loss: 0.607572, acc.: 64.06%] [G loss: 1.418231]\n",
      "epoch:35 step:32830 [D loss: 0.501785, acc.: 72.66%] [G loss: 2.147409]\n",
      "epoch:35 step:32831 [D loss: 0.360275, acc.: 88.28%] [G loss: 1.893480]\n",
      "epoch:35 step:32832 [D loss: 0.484494, acc.: 75.78%] [G loss: 1.962344]\n",
      "epoch:35 step:32833 [D loss: 0.526205, acc.: 72.66%] [G loss: 1.246890]\n",
      "epoch:35 step:32834 [D loss: 0.607082, acc.: 69.53%] [G loss: 1.568199]\n",
      "epoch:35 step:32835 [D loss: 0.742300, acc.: 54.69%] [G loss: 1.424727]\n",
      "epoch:35 step:32836 [D loss: 0.781674, acc.: 56.25%] [G loss: 1.277685]\n",
      "epoch:35 step:32837 [D loss: 0.919632, acc.: 43.75%] [G loss: 1.675149]\n",
      "epoch:35 step:32838 [D loss: 0.578777, acc.: 67.19%] [G loss: 1.857219]\n",
      "epoch:35 step:32839 [D loss: 0.466922, acc.: 78.91%] [G loss: 1.562860]\n",
      "epoch:35 step:32840 [D loss: 0.438951, acc.: 82.03%] [G loss: 1.259870]\n",
      "epoch:35 step:32841 [D loss: 0.475807, acc.: 77.34%] [G loss: 1.491020]\n",
      "epoch:35 step:32842 [D loss: 0.441723, acc.: 79.69%] [G loss: 1.791135]\n",
      "epoch:35 step:32843 [D loss: 0.554505, acc.: 67.97%] [G loss: 1.486181]\n",
      "epoch:35 step:32844 [D loss: 0.596145, acc.: 68.75%] [G loss: 1.264952]\n",
      "epoch:35 step:32845 [D loss: 0.495623, acc.: 75.00%] [G loss: 1.498886]\n",
      "epoch:35 step:32846 [D loss: 0.522838, acc.: 71.09%] [G loss: 1.562396]\n",
      "epoch:35 step:32847 [D loss: 0.601852, acc.: 67.97%] [G loss: 1.306433]\n",
      "epoch:35 step:32848 [D loss: 0.542622, acc.: 69.53%] [G loss: 1.109780]\n",
      "epoch:35 step:32849 [D loss: 0.551746, acc.: 71.88%] [G loss: 2.012164]\n",
      "epoch:35 step:32850 [D loss: 0.574524, acc.: 65.62%] [G loss: 2.315484]\n",
      "epoch:35 step:32851 [D loss: 0.802140, acc.: 60.16%] [G loss: 1.426302]\n",
      "epoch:35 step:32852 [D loss: 0.560805, acc.: 67.97%] [G loss: 1.543010]\n",
      "epoch:35 step:32853 [D loss: 0.523660, acc.: 72.66%] [G loss: 1.091547]\n",
      "epoch:35 step:32854 [D loss: 0.446378, acc.: 81.25%] [G loss: 1.345601]\n",
      "epoch:35 step:32855 [D loss: 0.699811, acc.: 60.16%] [G loss: 1.256075]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:35 step:32856 [D loss: 0.416606, acc.: 81.25%] [G loss: 1.580559]\n",
      "epoch:35 step:32857 [D loss: 0.561837, acc.: 69.53%] [G loss: 1.346444]\n",
      "epoch:35 step:32858 [D loss: 0.662636, acc.: 60.94%] [G loss: 1.077900]\n",
      "epoch:35 step:32859 [D loss: 0.611862, acc.: 61.72%] [G loss: 1.208645]\n",
      "epoch:35 step:32860 [D loss: 0.427012, acc.: 84.38%] [G loss: 1.912315]\n",
      "epoch:35 step:32861 [D loss: 0.653393, acc.: 66.41%] [G loss: 1.557346]\n",
      "epoch:35 step:32862 [D loss: 0.436092, acc.: 81.25%] [G loss: 1.475465]\n",
      "epoch:35 step:32863 [D loss: 0.442258, acc.: 79.69%] [G loss: 2.029136]\n",
      "epoch:35 step:32864 [D loss: 0.351631, acc.: 89.84%] [G loss: 1.781927]\n",
      "epoch:35 step:32865 [D loss: 0.493569, acc.: 78.91%] [G loss: 1.440661]\n",
      "epoch:35 step:32866 [D loss: 0.534649, acc.: 71.09%] [G loss: 1.530318]\n",
      "epoch:35 step:32867 [D loss: 0.543112, acc.: 70.31%] [G loss: 1.260983]\n",
      "epoch:35 step:32868 [D loss: 0.362488, acc.: 84.38%] [G loss: 1.832749]\n",
      "epoch:35 step:32869 [D loss: 0.295257, acc.: 93.75%] [G loss: 1.850563]\n",
      "epoch:35 step:32870 [D loss: 0.468079, acc.: 78.91%] [G loss: 1.787721]\n",
      "epoch:35 step:32871 [D loss: 0.763107, acc.: 48.44%] [G loss: 1.362310]\n",
      "epoch:35 step:32872 [D loss: 0.539069, acc.: 71.09%] [G loss: 1.221773]\n",
      "epoch:35 step:32873 [D loss: 0.665687, acc.: 59.38%] [G loss: 1.045186]\n",
      "epoch:35 step:32874 [D loss: 0.743542, acc.: 60.94%] [G loss: 1.139888]\n",
      "epoch:35 step:32875 [D loss: 0.453567, acc.: 79.69%] [G loss: 1.309639]\n",
      "epoch:35 step:32876 [D loss: 0.649847, acc.: 64.84%] [G loss: 1.518159]\n",
      "epoch:35 step:32877 [D loss: 0.433818, acc.: 79.69%] [G loss: 1.550610]\n",
      "epoch:35 step:32878 [D loss: 0.398516, acc.: 85.94%] [G loss: 1.461284]\n",
      "epoch:35 step:32879 [D loss: 0.732020, acc.: 57.03%] [G loss: 1.579889]\n",
      "epoch:35 step:32880 [D loss: 0.414696, acc.: 84.38%] [G loss: 2.044716]\n",
      "epoch:35 step:32881 [D loss: 0.555405, acc.: 69.53%] [G loss: 1.119789]\n",
      "epoch:35 step:32882 [D loss: 0.414360, acc.: 85.16%] [G loss: 1.408585]\n",
      "epoch:35 step:32883 [D loss: 0.425939, acc.: 81.25%] [G loss: 1.388204]\n",
      "epoch:35 step:32884 [D loss: 0.494772, acc.: 75.00%] [G loss: 1.164965]\n",
      "epoch:35 step:32885 [D loss: 0.508322, acc.: 73.44%] [G loss: 1.601954]\n",
      "epoch:35 step:32886 [D loss: 0.459746, acc.: 78.12%] [G loss: 1.392203]\n",
      "epoch:35 step:32887 [D loss: 0.350364, acc.: 87.50%] [G loss: 1.360018]\n",
      "epoch:35 step:32888 [D loss: 0.387693, acc.: 86.72%] [G loss: 1.670240]\n",
      "epoch:35 step:32889 [D loss: 0.498945, acc.: 80.47%] [G loss: 1.318776]\n",
      "epoch:35 step:32890 [D loss: 0.566382, acc.: 67.97%] [G loss: 1.359335]\n",
      "epoch:35 step:32891 [D loss: 0.446827, acc.: 80.47%] [G loss: 1.768774]\n",
      "epoch:35 step:32892 [D loss: 0.625083, acc.: 60.16%] [G loss: 1.168051]\n",
      "epoch:35 step:32893 [D loss: 0.751333, acc.: 55.47%] [G loss: 1.280571]\n",
      "epoch:35 step:32894 [D loss: 0.609162, acc.: 69.53%] [G loss: 1.550108]\n",
      "epoch:35 step:32895 [D loss: 0.468359, acc.: 79.69%] [G loss: 1.187969]\n",
      "epoch:35 step:32896 [D loss: 0.587908, acc.: 66.41%] [G loss: 1.492617]\n",
      "epoch:35 step:32897 [D loss: 0.622584, acc.: 61.72%] [G loss: 1.639606]\n",
      "epoch:35 step:32898 [D loss: 0.431968, acc.: 81.25%] [G loss: 1.413309]\n",
      "epoch:35 step:32899 [D loss: 0.285272, acc.: 89.84%] [G loss: 1.896037]\n",
      "epoch:35 step:32900 [D loss: 0.502516, acc.: 79.69%] [G loss: 1.648346]\n",
      "epoch:35 step:32901 [D loss: 0.597206, acc.: 67.97%] [G loss: 1.764040]\n",
      "epoch:35 step:32902 [D loss: 0.452828, acc.: 86.72%] [G loss: 1.504593]\n",
      "epoch:35 step:32903 [D loss: 0.533480, acc.: 74.22%] [G loss: 1.893910]\n",
      "epoch:35 step:32904 [D loss: 0.381200, acc.: 86.72%] [G loss: 1.618690]\n",
      "epoch:35 step:32905 [D loss: 0.572717, acc.: 69.53%] [G loss: 1.026827]\n",
      "epoch:35 step:32906 [D loss: 0.716030, acc.: 58.59%] [G loss: 1.790186]\n",
      "epoch:35 step:32907 [D loss: 0.427903, acc.: 83.59%] [G loss: 1.841733]\n",
      "epoch:35 step:32908 [D loss: 0.345530, acc.: 89.84%] [G loss: 1.295075]\n",
      "epoch:35 step:32909 [D loss: 0.465304, acc.: 78.91%] [G loss: 1.641750]\n",
      "epoch:35 step:32910 [D loss: 0.522348, acc.: 74.22%] [G loss: 1.130595]\n",
      "epoch:35 step:32911 [D loss: 0.422595, acc.: 83.59%] [G loss: 1.349158]\n",
      "epoch:35 step:32912 [D loss: 0.488009, acc.: 76.56%] [G loss: 2.093886]\n",
      "epoch:35 step:32913 [D loss: 0.586363, acc.: 73.44%] [G loss: 1.047462]\n",
      "epoch:35 step:32914 [D loss: 0.511301, acc.: 78.12%] [G loss: 1.698991]\n",
      "epoch:35 step:32915 [D loss: 0.687330, acc.: 60.16%] [G loss: 1.429705]\n",
      "epoch:35 step:32916 [D loss: 0.475546, acc.: 79.69%] [G loss: 1.588607]\n",
      "epoch:35 step:32917 [D loss: 0.538487, acc.: 75.78%] [G loss: 1.394100]\n",
      "epoch:35 step:32918 [D loss: 0.398240, acc.: 82.81%] [G loss: 1.760118]\n",
      "epoch:35 step:32919 [D loss: 0.527762, acc.: 74.22%] [G loss: 1.745483]\n",
      "epoch:35 step:32920 [D loss: 0.641327, acc.: 64.84%] [G loss: 1.797746]\n",
      "epoch:35 step:32921 [D loss: 0.652306, acc.: 66.41%] [G loss: 1.324704]\n",
      "epoch:35 step:32922 [D loss: 0.609059, acc.: 67.97%] [G loss: 0.980772]\n",
      "epoch:35 step:32923 [D loss: 0.713855, acc.: 58.59%] [G loss: 1.747660]\n",
      "epoch:35 step:32924 [D loss: 0.536389, acc.: 72.66%] [G loss: 1.532996]\n",
      "epoch:35 step:32925 [D loss: 0.608994, acc.: 72.66%] [G loss: 1.491038]\n",
      "epoch:35 step:32926 [D loss: 0.529185, acc.: 71.88%] [G loss: 1.686794]\n",
      "epoch:35 step:32927 [D loss: 0.489495, acc.: 77.34%] [G loss: 1.152639]\n",
      "epoch:35 step:32928 [D loss: 0.394194, acc.: 83.59%] [G loss: 1.471302]\n",
      "epoch:35 step:32929 [D loss: 0.564219, acc.: 74.22%] [G loss: 1.186214]\n",
      "epoch:35 step:32930 [D loss: 0.421577, acc.: 84.38%] [G loss: 0.911639]\n",
      "epoch:35 step:32931 [D loss: 0.798594, acc.: 48.44%] [G loss: 1.501277]\n",
      "epoch:35 step:32932 [D loss: 0.774356, acc.: 54.69%] [G loss: 1.104949]\n",
      "epoch:35 step:32933 [D loss: 0.314730, acc.: 90.62%] [G loss: 2.370663]\n",
      "epoch:35 step:32934 [D loss: 0.398524, acc.: 82.81%] [G loss: 1.767632]\n",
      "epoch:35 step:32935 [D loss: 0.424439, acc.: 83.59%] [G loss: 1.675923]\n",
      "epoch:35 step:32936 [D loss: 0.525361, acc.: 73.44%] [G loss: 1.450217]\n",
      "epoch:35 step:32937 [D loss: 0.519601, acc.: 73.44%] [G loss: 1.094489]\n",
      "epoch:35 step:32938 [D loss: 0.616321, acc.: 63.28%] [G loss: 1.399887]\n",
      "epoch:35 step:32939 [D loss: 0.558261, acc.: 69.53%] [G loss: 1.456722]\n",
      "epoch:35 step:32940 [D loss: 0.359787, acc.: 87.50%] [G loss: 1.562809]\n",
      "epoch:35 step:32941 [D loss: 0.564805, acc.: 68.75%] [G loss: 1.492768]\n",
      "epoch:35 step:32942 [D loss: 0.762607, acc.: 53.91%] [G loss: 1.223887]\n",
      "epoch:35 step:32943 [D loss: 0.389813, acc.: 84.38%] [G loss: 1.336057]\n",
      "epoch:35 step:32944 [D loss: 0.621856, acc.: 67.97%] [G loss: 1.527326]\n",
      "epoch:35 step:32945 [D loss: 0.444385, acc.: 82.03%] [G loss: 1.517239]\n",
      "epoch:35 step:32946 [D loss: 0.511995, acc.: 74.22%] [G loss: 2.117620]\n",
      "epoch:35 step:32947 [D loss: 0.558841, acc.: 70.31%] [G loss: 1.463104]\n",
      "epoch:35 step:32948 [D loss: 0.602940, acc.: 64.06%] [G loss: 1.300840]\n",
      "epoch:35 step:32949 [D loss: 0.575177, acc.: 70.31%] [G loss: 1.326635]\n",
      "epoch:35 step:32950 [D loss: 0.511576, acc.: 78.91%] [G loss: 1.697512]\n",
      "epoch:35 step:32951 [D loss: 0.499239, acc.: 75.00%] [G loss: 1.656792]\n",
      "epoch:35 step:32952 [D loss: 0.511249, acc.: 76.56%] [G loss: 1.664001]\n",
      "epoch:35 step:32953 [D loss: 0.559090, acc.: 71.09%] [G loss: 1.436242]\n",
      "epoch:35 step:32954 [D loss: 0.433469, acc.: 78.12%] [G loss: 1.334453]\n",
      "epoch:35 step:32955 [D loss: 0.701376, acc.: 61.72%] [G loss: 1.233393]\n",
      "epoch:35 step:32956 [D loss: 0.584664, acc.: 70.31%] [G loss: 1.382154]\n",
      "epoch:35 step:32957 [D loss: 0.392444, acc.: 87.50%] [G loss: 1.459957]\n",
      "epoch:35 step:32958 [D loss: 0.519189, acc.: 76.56%] [G loss: 1.360531]\n",
      "epoch:35 step:32959 [D loss: 0.468515, acc.: 79.69%] [G loss: 1.425892]\n",
      "epoch:35 step:32960 [D loss: 0.389906, acc.: 84.38%] [G loss: 1.319196]\n",
      "epoch:35 step:32961 [D loss: 0.444154, acc.: 82.03%] [G loss: 1.654069]\n",
      "epoch:35 step:32962 [D loss: 0.457304, acc.: 79.69%] [G loss: 1.505552]\n",
      "epoch:35 step:32963 [D loss: 0.616672, acc.: 66.41%] [G loss: 1.225302]\n",
      "epoch:35 step:32964 [D loss: 0.566983, acc.: 67.19%] [G loss: 1.597304]\n",
      "epoch:35 step:32965 [D loss: 0.469551, acc.: 80.47%] [G loss: 1.092845]\n",
      "epoch:35 step:32966 [D loss: 0.663674, acc.: 62.50%] [G loss: 1.478429]\n",
      "epoch:35 step:32967 [D loss: 0.504519, acc.: 72.66%] [G loss: 1.528119]\n",
      "epoch:35 step:32968 [D loss: 0.505228, acc.: 75.00%] [G loss: 1.314888]\n",
      "epoch:35 step:32969 [D loss: 0.563607, acc.: 71.09%] [G loss: 1.226099]\n",
      "epoch:35 step:32970 [D loss: 0.471388, acc.: 78.12%] [G loss: 1.573106]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:35 step:32971 [D loss: 0.388632, acc.: 85.16%] [G loss: 1.819014]\n",
      "epoch:35 step:32972 [D loss: 0.509037, acc.: 73.44%] [G loss: 1.779358]\n",
      "epoch:35 step:32973 [D loss: 0.699760, acc.: 62.50%] [G loss: 1.213850]\n",
      "epoch:35 step:32974 [D loss: 0.655884, acc.: 60.94%] [G loss: 2.054574]\n",
      "epoch:35 step:32975 [D loss: 0.545098, acc.: 69.53%] [G loss: 1.498450]\n",
      "epoch:35 step:32976 [D loss: 0.298731, acc.: 92.19%] [G loss: 1.402589]\n",
      "epoch:35 step:32977 [D loss: 0.400936, acc.: 81.25%] [G loss: 1.450555]\n",
      "epoch:35 step:32978 [D loss: 0.638512, acc.: 67.19%] [G loss: 1.309936]\n",
      "epoch:35 step:32979 [D loss: 0.609129, acc.: 60.94%] [G loss: 1.155589]\n",
      "epoch:35 step:32980 [D loss: 0.445825, acc.: 82.03%] [G loss: 1.866685]\n",
      "epoch:35 step:32981 [D loss: 0.486128, acc.: 78.12%] [G loss: 1.539307]\n",
      "epoch:35 step:32982 [D loss: 0.688059, acc.: 63.28%] [G loss: 0.882541]\n",
      "epoch:35 step:32983 [D loss: 0.402054, acc.: 82.81%] [G loss: 1.557503]\n",
      "epoch:35 step:32984 [D loss: 0.608399, acc.: 65.62%] [G loss: 1.595404]\n",
      "epoch:35 step:32985 [D loss: 0.479996, acc.: 78.12%] [G loss: 1.640930]\n",
      "epoch:35 step:32986 [D loss: 0.619911, acc.: 67.19%] [G loss: 1.166632]\n",
      "epoch:35 step:32987 [D loss: 0.410145, acc.: 81.25%] [G loss: 1.618338]\n",
      "epoch:35 step:32988 [D loss: 0.534727, acc.: 74.22%] [G loss: 1.720737]\n",
      "epoch:35 step:32989 [D loss: 0.502202, acc.: 77.34%] [G loss: 1.455184]\n",
      "epoch:35 step:32990 [D loss: 0.703747, acc.: 57.03%] [G loss: 1.350031]\n",
      "epoch:35 step:32991 [D loss: 0.473981, acc.: 74.22%] [G loss: 1.197212]\n",
      "epoch:35 step:32992 [D loss: 0.574047, acc.: 71.09%] [G loss: 1.195279]\n",
      "epoch:35 step:32993 [D loss: 0.526589, acc.: 70.31%] [G loss: 1.515914]\n",
      "epoch:35 step:32994 [D loss: 0.472207, acc.: 78.12%] [G loss: 1.473174]\n",
      "epoch:35 step:32995 [D loss: 0.618615, acc.: 64.06%] [G loss: 1.673401]\n",
      "epoch:35 step:32996 [D loss: 0.426780, acc.: 78.12%] [G loss: 1.817027]\n",
      "epoch:35 step:32997 [D loss: 0.476438, acc.: 79.69%] [G loss: 1.408904]\n",
      "epoch:35 step:32998 [D loss: 0.705904, acc.: 60.16%] [G loss: 1.989789]\n",
      "epoch:35 step:32999 [D loss: 0.415102, acc.: 80.47%] [G loss: 2.224670]\n",
      "epoch:35 step:33000 [D loss: 0.770484, acc.: 57.03%] [G loss: 2.019349]\n",
      "epoch:35 step:33001 [D loss: 0.812596, acc.: 52.34%] [G loss: 1.099738]\n",
      "epoch:35 step:33002 [D loss: 0.734948, acc.: 53.91%] [G loss: 1.494123]\n",
      "epoch:35 step:33003 [D loss: 0.470803, acc.: 77.34%] [G loss: 1.636540]\n",
      "epoch:35 step:33004 [D loss: 0.485893, acc.: 76.56%] [G loss: 1.612905]\n",
      "epoch:35 step:33005 [D loss: 0.418910, acc.: 79.69%] [G loss: 1.824290]\n",
      "epoch:35 step:33006 [D loss: 0.559878, acc.: 69.53%] [G loss: 1.110146]\n",
      "epoch:35 step:33007 [D loss: 0.548464, acc.: 71.09%] [G loss: 1.819792]\n",
      "epoch:35 step:33008 [D loss: 0.692138, acc.: 59.38%] [G loss: 1.507605]\n",
      "epoch:35 step:33009 [D loss: 0.453392, acc.: 78.12%] [G loss: 1.409993]\n",
      "epoch:35 step:33010 [D loss: 0.593061, acc.: 67.97%] [G loss: 1.154019]\n",
      "epoch:35 step:33011 [D loss: 0.359015, acc.: 88.28%] [G loss: 1.746282]\n",
      "epoch:35 step:33012 [D loss: 0.392486, acc.: 85.94%] [G loss: 1.614168]\n",
      "epoch:35 step:33013 [D loss: 0.608048, acc.: 68.75%] [G loss: 1.334897]\n",
      "epoch:35 step:33014 [D loss: 0.409849, acc.: 83.59%] [G loss: 1.587360]\n",
      "epoch:35 step:33015 [D loss: 0.467482, acc.: 74.22%] [G loss: 1.351275]\n",
      "epoch:35 step:33016 [D loss: 0.751305, acc.: 57.03%] [G loss: 1.833879]\n",
      "epoch:35 step:33017 [D loss: 0.714148, acc.: 56.25%] [G loss: 1.377683]\n",
      "epoch:35 step:33018 [D loss: 0.481091, acc.: 80.47%] [G loss: 1.494537]\n",
      "epoch:35 step:33019 [D loss: 0.617980, acc.: 64.84%] [G loss: 1.150190]\n",
      "epoch:35 step:33020 [D loss: 0.574066, acc.: 69.53%] [G loss: 1.301584]\n",
      "epoch:35 step:33021 [D loss: 0.398532, acc.: 86.72%] [G loss: 1.896389]\n",
      "epoch:35 step:33022 [D loss: 0.614018, acc.: 67.19%] [G loss: 1.628601]\n",
      "epoch:35 step:33023 [D loss: 0.780434, acc.: 54.69%] [G loss: 1.704289]\n",
      "epoch:35 step:33024 [D loss: 0.465181, acc.: 81.25%] [G loss: 1.511843]\n",
      "epoch:35 step:33025 [D loss: 0.466307, acc.: 78.91%] [G loss: 1.302784]\n",
      "epoch:35 step:33026 [D loss: 0.467516, acc.: 77.34%] [G loss: 1.309572]\n",
      "epoch:35 step:33027 [D loss: 0.673425, acc.: 64.84%] [G loss: 1.285670]\n",
      "epoch:35 step:33028 [D loss: 0.453553, acc.: 78.91%] [G loss: 1.497642]\n",
      "epoch:35 step:33029 [D loss: 0.535096, acc.: 69.53%] [G loss: 1.223877]\n",
      "epoch:35 step:33030 [D loss: 0.672333, acc.: 58.59%] [G loss: 1.106918]\n",
      "epoch:35 step:33031 [D loss: 0.523943, acc.: 71.88%] [G loss: 1.412052]\n",
      "epoch:35 step:33032 [D loss: 0.502105, acc.: 78.12%] [G loss: 1.478366]\n",
      "epoch:35 step:33033 [D loss: 0.696675, acc.: 57.81%] [G loss: 1.029241]\n",
      "epoch:35 step:33034 [D loss: 0.631991, acc.: 67.97%] [G loss: 1.506267]\n",
      "epoch:35 step:33035 [D loss: 0.565075, acc.: 69.53%] [G loss: 1.550056]\n",
      "epoch:35 step:33036 [D loss: 0.617692, acc.: 69.53%] [G loss: 1.276332]\n",
      "epoch:35 step:33037 [D loss: 0.634642, acc.: 71.09%] [G loss: 1.122961]\n",
      "epoch:35 step:33038 [D loss: 0.433553, acc.: 82.03%] [G loss: 1.684481]\n",
      "epoch:35 step:33039 [D loss: 0.566181, acc.: 68.75%] [G loss: 1.406111]\n",
      "epoch:35 step:33040 [D loss: 0.393417, acc.: 89.06%] [G loss: 1.253722]\n",
      "epoch:35 step:33041 [D loss: 0.558989, acc.: 70.31%] [G loss: 1.215872]\n",
      "epoch:35 step:33042 [D loss: 0.391765, acc.: 83.59%] [G loss: 1.787329]\n",
      "epoch:35 step:33043 [D loss: 0.408189, acc.: 82.81%] [G loss: 1.638580]\n",
      "epoch:35 step:33044 [D loss: 0.401980, acc.: 84.38%] [G loss: 1.708973]\n",
      "epoch:35 step:33045 [D loss: 0.412149, acc.: 82.03%] [G loss: 1.601344]\n",
      "epoch:35 step:33046 [D loss: 0.427380, acc.: 82.81%] [G loss: 1.493911]\n",
      "epoch:35 step:33047 [D loss: 0.530196, acc.: 72.66%] [G loss: 1.411021]\n",
      "epoch:35 step:33048 [D loss: 0.557165, acc.: 72.66%] [G loss: 2.107379]\n",
      "epoch:35 step:33049 [D loss: 0.513849, acc.: 75.78%] [G loss: 1.406375]\n",
      "epoch:35 step:33050 [D loss: 0.591627, acc.: 68.75%] [G loss: 1.329471]\n",
      "epoch:35 step:33051 [D loss: 0.560214, acc.: 64.84%] [G loss: 1.383060]\n",
      "epoch:35 step:33052 [D loss: 0.499143, acc.: 77.34%] [G loss: 1.441015]\n",
      "epoch:35 step:33053 [D loss: 0.525732, acc.: 76.56%] [G loss: 1.119104]\n",
      "epoch:35 step:33054 [D loss: 0.558391, acc.: 69.53%] [G loss: 1.699106]\n",
      "epoch:35 step:33055 [D loss: 0.513162, acc.: 75.78%] [G loss: 1.380326]\n",
      "epoch:35 step:33056 [D loss: 0.382079, acc.: 86.72%] [G loss: 1.701788]\n",
      "epoch:35 step:33057 [D loss: 0.587493, acc.: 70.31%] [G loss: 1.308973]\n",
      "epoch:35 step:33058 [D loss: 0.463820, acc.: 77.34%] [G loss: 1.461824]\n",
      "epoch:35 step:33059 [D loss: 0.643572, acc.: 67.97%] [G loss: 1.384201]\n",
      "epoch:35 step:33060 [D loss: 0.432047, acc.: 82.81%] [G loss: 1.624938]\n",
      "epoch:35 step:33061 [D loss: 0.294028, acc.: 95.31%] [G loss: 1.384983]\n",
      "epoch:35 step:33062 [D loss: 0.718271, acc.: 59.38%] [G loss: 1.585857]\n",
      "epoch:35 step:33063 [D loss: 0.466459, acc.: 77.34%] [G loss: 1.194402]\n",
      "epoch:35 step:33064 [D loss: 0.501172, acc.: 77.34%] [G loss: 1.337728]\n",
      "epoch:35 step:33065 [D loss: 0.493939, acc.: 79.69%] [G loss: 1.778424]\n",
      "epoch:35 step:33066 [D loss: 0.517269, acc.: 71.09%] [G loss: 1.615423]\n",
      "epoch:35 step:33067 [D loss: 0.595277, acc.: 65.62%] [G loss: 1.732639]\n",
      "epoch:35 step:33068 [D loss: 0.516790, acc.: 72.66%] [G loss: 1.753196]\n",
      "epoch:35 step:33069 [D loss: 0.398154, acc.: 83.59%] [G loss: 1.583484]\n",
      "epoch:35 step:33070 [D loss: 0.760022, acc.: 59.38%] [G loss: 1.067427]\n",
      "epoch:35 step:33071 [D loss: 0.671245, acc.: 60.16%] [G loss: 1.340972]\n",
      "epoch:35 step:33072 [D loss: 0.438527, acc.: 79.69%] [G loss: 1.751956]\n",
      "epoch:35 step:33073 [D loss: 0.618256, acc.: 68.75%] [G loss: 1.307721]\n",
      "epoch:35 step:33074 [D loss: 0.652282, acc.: 64.84%] [G loss: 1.937759]\n",
      "epoch:35 step:33075 [D loss: 0.672875, acc.: 60.16%] [G loss: 1.526318]\n",
      "epoch:35 step:33076 [D loss: 0.695021, acc.: 61.72%] [G loss: 1.530313]\n",
      "epoch:35 step:33077 [D loss: 0.666248, acc.: 64.06%] [G loss: 1.088600]\n",
      "epoch:35 step:33078 [D loss: 0.320143, acc.: 89.06%] [G loss: 1.797382]\n",
      "epoch:35 step:33079 [D loss: 0.595138, acc.: 70.31%] [G loss: 1.641733]\n",
      "epoch:35 step:33080 [D loss: 0.490727, acc.: 72.66%] [G loss: 1.161599]\n",
      "epoch:35 step:33081 [D loss: 0.560116, acc.: 70.31%] [G loss: 1.393922]\n",
      "epoch:35 step:33082 [D loss: 0.420689, acc.: 81.25%] [G loss: 1.358952]\n",
      "epoch:35 step:33083 [D loss: 0.631682, acc.: 65.62%] [G loss: 1.492509]\n",
      "epoch:35 step:33084 [D loss: 0.240149, acc.: 95.31%] [G loss: 1.729063]\n",
      "epoch:35 step:33085 [D loss: 0.454198, acc.: 78.12%] [G loss: 1.947110]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:35 step:33086 [D loss: 0.520900, acc.: 71.88%] [G loss: 1.412437]\n",
      "epoch:35 step:33087 [D loss: 0.650493, acc.: 58.59%] [G loss: 1.585982]\n",
      "epoch:35 step:33088 [D loss: 0.811288, acc.: 48.44%] [G loss: 1.195515]\n",
      "epoch:35 step:33089 [D loss: 0.523453, acc.: 78.12%] [G loss: 1.394731]\n",
      "epoch:35 step:33090 [D loss: 0.602853, acc.: 69.53%] [G loss: 2.287338]\n",
      "epoch:35 step:33091 [D loss: 0.446897, acc.: 81.25%] [G loss: 1.680811]\n",
      "epoch:35 step:33092 [D loss: 0.399766, acc.: 82.81%] [G loss: 1.487420]\n",
      "epoch:35 step:33093 [D loss: 0.583830, acc.: 68.75%] [G loss: 1.390010]\n",
      "epoch:35 step:33094 [D loss: 0.578763, acc.: 71.09%] [G loss: 1.224070]\n",
      "epoch:35 step:33095 [D loss: 0.518867, acc.: 72.66%] [G loss: 1.106793]\n",
      "epoch:35 step:33096 [D loss: 0.514185, acc.: 78.12%] [G loss: 1.224444]\n",
      "epoch:35 step:33097 [D loss: 0.642773, acc.: 65.62%] [G loss: 1.523908]\n",
      "epoch:35 step:33098 [D loss: 0.399414, acc.: 85.94%] [G loss: 0.882143]\n",
      "epoch:35 step:33099 [D loss: 0.498505, acc.: 75.00%] [G loss: 1.405807]\n",
      "epoch:35 step:33100 [D loss: 0.443151, acc.: 80.47%] [G loss: 1.394806]\n",
      "epoch:35 step:33101 [D loss: 0.493869, acc.: 77.34%] [G loss: 1.640991]\n",
      "epoch:35 step:33102 [D loss: 0.562897, acc.: 71.09%] [G loss: 1.403652]\n",
      "epoch:35 step:33103 [D loss: 0.520838, acc.: 75.00%] [G loss: 1.681389]\n",
      "epoch:35 step:33104 [D loss: 0.416865, acc.: 83.59%] [G loss: 1.349335]\n",
      "epoch:35 step:33105 [D loss: 0.533121, acc.: 71.88%] [G loss: 1.625934]\n",
      "epoch:35 step:33106 [D loss: 0.441976, acc.: 79.69%] [G loss: 1.728413]\n",
      "epoch:35 step:33107 [D loss: 0.468120, acc.: 79.69%] [G loss: 1.077510]\n",
      "epoch:35 step:33108 [D loss: 0.451539, acc.: 82.81%] [G loss: 1.503884]\n",
      "epoch:35 step:33109 [D loss: 0.614257, acc.: 67.19%] [G loss: 1.329727]\n",
      "epoch:35 step:33110 [D loss: 0.568440, acc.: 70.31%] [G loss: 1.193635]\n",
      "epoch:35 step:33111 [D loss: 0.503052, acc.: 76.56%] [G loss: 1.410685]\n",
      "epoch:35 step:33112 [D loss: 0.636068, acc.: 62.50%] [G loss: 1.228148]\n",
      "epoch:35 step:33113 [D loss: 0.351830, acc.: 88.28%] [G loss: 1.736454]\n",
      "epoch:35 step:33114 [D loss: 0.588298, acc.: 69.53%] [G loss: 1.690156]\n",
      "epoch:35 step:33115 [D loss: 0.517236, acc.: 71.09%] [G loss: 0.965072]\n",
      "epoch:35 step:33116 [D loss: 0.599669, acc.: 68.75%] [G loss: 1.488864]\n",
      "epoch:35 step:33117 [D loss: 0.433786, acc.: 78.91%] [G loss: 1.689689]\n",
      "epoch:35 step:33118 [D loss: 0.725876, acc.: 56.25%] [G loss: 1.065852]\n",
      "epoch:35 step:33119 [D loss: 0.296651, acc.: 90.62%] [G loss: 1.591323]\n",
      "epoch:35 step:33120 [D loss: 0.517259, acc.: 68.75%] [G loss: 1.220445]\n",
      "epoch:35 step:33121 [D loss: 0.524076, acc.: 71.88%] [G loss: 1.312196]\n",
      "epoch:35 step:33122 [D loss: 0.380100, acc.: 86.72%] [G loss: 1.334971]\n",
      "epoch:35 step:33123 [D loss: 0.455020, acc.: 73.44%] [G loss: 1.191863]\n",
      "epoch:35 step:33124 [D loss: 0.727983, acc.: 60.16%] [G loss: 1.409575]\n",
      "epoch:35 step:33125 [D loss: 0.712502, acc.: 59.38%] [G loss: 1.468150]\n",
      "epoch:35 step:33126 [D loss: 0.374804, acc.: 80.47%] [G loss: 1.939000]\n",
      "epoch:35 step:33127 [D loss: 0.897595, acc.: 42.19%] [G loss: 1.185583]\n",
      "epoch:35 step:33128 [D loss: 0.502210, acc.: 75.78%] [G loss: 1.901202]\n",
      "epoch:35 step:33129 [D loss: 0.413812, acc.: 81.25%] [G loss: 1.558318]\n",
      "epoch:35 step:33130 [D loss: 0.799183, acc.: 50.78%] [G loss: 1.560089]\n",
      "epoch:35 step:33131 [D loss: 0.282964, acc.: 92.97%] [G loss: 1.750405]\n",
      "epoch:35 step:33132 [D loss: 0.647409, acc.: 64.06%] [G loss: 1.095249]\n",
      "epoch:35 step:33133 [D loss: 0.567782, acc.: 71.88%] [G loss: 1.350044]\n",
      "epoch:35 step:33134 [D loss: 0.527836, acc.: 74.22%] [G loss: 1.493260]\n",
      "epoch:35 step:33135 [D loss: 0.476224, acc.: 75.00%] [G loss: 1.833982]\n",
      "epoch:35 step:33136 [D loss: 0.393844, acc.: 85.16%] [G loss: 2.035609]\n",
      "epoch:35 step:33137 [D loss: 0.468433, acc.: 77.34%] [G loss: 1.092189]\n",
      "epoch:35 step:33138 [D loss: 0.403217, acc.: 84.38%] [G loss: 1.753528]\n",
      "epoch:35 step:33139 [D loss: 0.540346, acc.: 68.75%] [G loss: 1.535038]\n",
      "epoch:35 step:33140 [D loss: 0.456282, acc.: 80.47%] [G loss: 1.497259]\n",
      "epoch:35 step:33141 [D loss: 0.689993, acc.: 60.94%] [G loss: 1.555487]\n",
      "epoch:35 step:33142 [D loss: 0.480890, acc.: 78.91%] [G loss: 1.581321]\n",
      "epoch:35 step:33143 [D loss: 0.582384, acc.: 71.88%] [G loss: 1.633045]\n",
      "epoch:35 step:33144 [D loss: 0.535141, acc.: 69.53%] [G loss: 1.178261]\n",
      "epoch:35 step:33145 [D loss: 0.536165, acc.: 71.09%] [G loss: 1.936323]\n",
      "epoch:35 step:33146 [D loss: 0.596699, acc.: 71.09%] [G loss: 1.080033]\n",
      "epoch:35 step:33147 [D loss: 0.433274, acc.: 83.59%] [G loss: 1.209293]\n",
      "epoch:35 step:33148 [D loss: 0.450000, acc.: 82.03%] [G loss: 1.519328]\n",
      "epoch:35 step:33149 [D loss: 0.686813, acc.: 61.72%] [G loss: 1.351560]\n",
      "epoch:35 step:33150 [D loss: 0.533940, acc.: 75.00%] [G loss: 1.715946]\n",
      "epoch:35 step:33151 [D loss: 0.520081, acc.: 78.12%] [G loss: 1.299973]\n",
      "epoch:35 step:33152 [D loss: 0.525115, acc.: 71.09%] [G loss: 1.352956]\n",
      "epoch:35 step:33153 [D loss: 0.814358, acc.: 50.00%] [G loss: 1.212204]\n",
      "epoch:35 step:33154 [D loss: 0.701571, acc.: 61.72%] [G loss: 1.598892]\n",
      "epoch:35 step:33155 [D loss: 0.528944, acc.: 69.53%] [G loss: 1.828171]\n",
      "epoch:35 step:33156 [D loss: 0.402733, acc.: 82.03%] [G loss: 1.422687]\n",
      "epoch:35 step:33157 [D loss: 0.487961, acc.: 75.78%] [G loss: 1.326799]\n",
      "epoch:35 step:33158 [D loss: 0.413100, acc.: 80.47%] [G loss: 1.737674]\n",
      "epoch:35 step:33159 [D loss: 0.445699, acc.: 78.12%] [G loss: 1.157655]\n",
      "epoch:35 step:33160 [D loss: 0.598696, acc.: 67.19%] [G loss: 1.786150]\n",
      "epoch:35 step:33161 [D loss: 0.510819, acc.: 75.78%] [G loss: 1.136838]\n",
      "epoch:35 step:33162 [D loss: 0.474011, acc.: 79.69%] [G loss: 1.694934]\n",
      "epoch:35 step:33163 [D loss: 0.516582, acc.: 68.75%] [G loss: 1.505115]\n",
      "epoch:35 step:33164 [D loss: 0.537341, acc.: 71.88%] [G loss: 1.499786]\n",
      "epoch:35 step:33165 [D loss: 0.496781, acc.: 74.22%] [G loss: 1.607626]\n",
      "epoch:35 step:33166 [D loss: 0.435820, acc.: 78.12%] [G loss: 1.251648]\n",
      "epoch:35 step:33167 [D loss: 0.488740, acc.: 76.56%] [G loss: 1.323047]\n",
      "epoch:35 step:33168 [D loss: 0.440760, acc.: 80.47%] [G loss: 1.241491]\n",
      "epoch:35 step:33169 [D loss: 0.541905, acc.: 75.78%] [G loss: 1.160336]\n",
      "epoch:35 step:33170 [D loss: 0.450539, acc.: 79.69%] [G loss: 1.472512]\n",
      "epoch:35 step:33171 [D loss: 0.664875, acc.: 64.06%] [G loss: 1.258821]\n",
      "epoch:35 step:33172 [D loss: 0.612831, acc.: 68.75%] [G loss: 1.681534]\n",
      "epoch:35 step:33173 [D loss: 0.585936, acc.: 69.53%] [G loss: 2.131495]\n",
      "epoch:35 step:33174 [D loss: 0.488372, acc.: 75.78%] [G loss: 1.629343]\n",
      "epoch:35 step:33175 [D loss: 0.603858, acc.: 64.84%] [G loss: 1.710214]\n",
      "epoch:35 step:33176 [D loss: 0.573141, acc.: 71.09%] [G loss: 1.892223]\n",
      "epoch:35 step:33177 [D loss: 0.777318, acc.: 57.03%] [G loss: 1.534243]\n",
      "epoch:35 step:33178 [D loss: 0.420248, acc.: 82.81%] [G loss: 1.941624]\n",
      "epoch:35 step:33179 [D loss: 0.388832, acc.: 87.50%] [G loss: 1.750542]\n",
      "epoch:35 step:33180 [D loss: 0.632488, acc.: 67.19%] [G loss: 1.528028]\n",
      "epoch:35 step:33181 [D loss: 0.556330, acc.: 69.53%] [G loss: 1.363212]\n",
      "epoch:35 step:33182 [D loss: 0.369583, acc.: 89.06%] [G loss: 2.275303]\n",
      "epoch:35 step:33183 [D loss: 0.636657, acc.: 64.84%] [G loss: 1.535742]\n",
      "epoch:35 step:33184 [D loss: 0.471702, acc.: 80.47%] [G loss: 1.290389]\n",
      "epoch:35 step:33185 [D loss: 0.585830, acc.: 71.09%] [G loss: 1.235669]\n",
      "epoch:35 step:33186 [D loss: 0.734050, acc.: 58.59%] [G loss: 1.704327]\n",
      "epoch:35 step:33187 [D loss: 0.488271, acc.: 78.91%] [G loss: 1.222359]\n",
      "epoch:35 step:33188 [D loss: 0.730584, acc.: 57.81%] [G loss: 1.727651]\n",
      "epoch:35 step:33189 [D loss: 0.491920, acc.: 79.69%] [G loss: 1.811394]\n",
      "epoch:35 step:33190 [D loss: 0.454767, acc.: 78.12%] [G loss: 1.306583]\n",
      "epoch:35 step:33191 [D loss: 0.503870, acc.: 75.00%] [G loss: 1.423221]\n",
      "epoch:35 step:33192 [D loss: 0.633879, acc.: 70.31%] [G loss: 1.167522]\n",
      "epoch:35 step:33193 [D loss: 0.628828, acc.: 64.84%] [G loss: 1.734660]\n",
      "epoch:35 step:33194 [D loss: 0.532203, acc.: 73.44%] [G loss: 1.769065]\n",
      "epoch:35 step:33195 [D loss: 0.552605, acc.: 75.00%] [G loss: 1.725148]\n",
      "epoch:35 step:33196 [D loss: 0.580478, acc.: 71.88%] [G loss: 1.478050]\n",
      "epoch:35 step:33197 [D loss: 0.641452, acc.: 64.84%] [G loss: 1.337189]\n",
      "epoch:35 step:33198 [D loss: 0.523209, acc.: 78.12%] [G loss: 1.845015]\n",
      "epoch:35 step:33199 [D loss: 0.567279, acc.: 69.53%] [G loss: 1.536773]\n",
      "epoch:35 step:33200 [D loss: 0.432919, acc.: 84.38%] [G loss: 1.512979]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:35 step:33201 [D loss: 0.540177, acc.: 75.78%] [G loss: 1.717247]\n",
      "epoch:35 step:33202 [D loss: 0.569550, acc.: 75.00%] [G loss: 1.409677]\n",
      "epoch:35 step:33203 [D loss: 0.486026, acc.: 74.22%] [G loss: 1.502558]\n",
      "epoch:35 step:33204 [D loss: 0.668880, acc.: 65.62%] [G loss: 1.193523]\n",
      "epoch:35 step:33205 [D loss: 0.666307, acc.: 65.62%] [G loss: 1.755972]\n",
      "epoch:35 step:33206 [D loss: 0.457992, acc.: 77.34%] [G loss: 1.815222]\n",
      "epoch:35 step:33207 [D loss: 0.921693, acc.: 44.53%] [G loss: 1.303389]\n",
      "epoch:35 step:33208 [D loss: 0.519010, acc.: 75.00%] [G loss: 1.540249]\n",
      "epoch:35 step:33209 [D loss: 0.532630, acc.: 75.00%] [G loss: 1.721587]\n",
      "epoch:35 step:33210 [D loss: 0.427724, acc.: 81.25%] [G loss: 1.485802]\n",
      "epoch:35 step:33211 [D loss: 0.465944, acc.: 82.81%] [G loss: 1.986989]\n",
      "epoch:35 step:33212 [D loss: 0.686406, acc.: 63.28%] [G loss: 1.620616]\n",
      "epoch:35 step:33213 [D loss: 0.567193, acc.: 70.31%] [G loss: 1.483384]\n",
      "epoch:35 step:33214 [D loss: 0.850766, acc.: 45.31%] [G loss: 1.209285]\n",
      "epoch:35 step:33215 [D loss: 0.482941, acc.: 80.47%] [G loss: 1.177525]\n",
      "epoch:35 step:33216 [D loss: 0.495994, acc.: 75.78%] [G loss: 1.886789]\n",
      "epoch:35 step:33217 [D loss: 0.611450, acc.: 64.06%] [G loss: 1.725065]\n",
      "epoch:35 step:33218 [D loss: 0.556296, acc.: 71.09%] [G loss: 1.248183]\n",
      "epoch:35 step:33219 [D loss: 0.597656, acc.: 68.75%] [G loss: 1.660602]\n",
      "epoch:35 step:33220 [D loss: 0.575508, acc.: 75.00%] [G loss: 1.286873]\n",
      "epoch:35 step:33221 [D loss: 0.464701, acc.: 78.12%] [G loss: 1.745151]\n",
      "epoch:35 step:33222 [D loss: 0.676653, acc.: 64.84%] [G loss: 1.709943]\n",
      "epoch:35 step:33223 [D loss: 0.570198, acc.: 71.88%] [G loss: 1.429389]\n",
      "epoch:35 step:33224 [D loss: 0.730561, acc.: 60.16%] [G loss: 1.623769]\n",
      "epoch:35 step:33225 [D loss: 0.461167, acc.: 81.25%] [G loss: 1.670443]\n",
      "epoch:35 step:33226 [D loss: 0.508219, acc.: 74.22%] [G loss: 1.176395]\n",
      "epoch:35 step:33227 [D loss: 0.465202, acc.: 77.34%] [G loss: 1.352413]\n",
      "epoch:35 step:33228 [D loss: 0.465990, acc.: 75.00%] [G loss: 1.227094]\n",
      "epoch:35 step:33229 [D loss: 0.615580, acc.: 71.09%] [G loss: 1.543730]\n",
      "epoch:35 step:33230 [D loss: 0.768640, acc.: 52.34%] [G loss: 1.473397]\n",
      "epoch:35 step:33231 [D loss: 0.352071, acc.: 84.38%] [G loss: 1.894395]\n",
      "epoch:35 step:33232 [D loss: 0.729348, acc.: 57.03%] [G loss: 0.843948]\n",
      "epoch:35 step:33233 [D loss: 0.459773, acc.: 78.12%] [G loss: 1.120218]\n",
      "epoch:35 step:33234 [D loss: 0.486475, acc.: 77.34%] [G loss: 1.705645]\n",
      "epoch:35 step:33235 [D loss: 0.798678, acc.: 54.69%] [G loss: 1.350380]\n",
      "epoch:35 step:33236 [D loss: 0.398838, acc.: 85.16%] [G loss: 1.528075]\n",
      "epoch:35 step:33237 [D loss: 0.557202, acc.: 71.88%] [G loss: 1.786179]\n",
      "epoch:35 step:33238 [D loss: 0.466808, acc.: 77.34%] [G loss: 1.152629]\n",
      "epoch:35 step:33239 [D loss: 0.572924, acc.: 69.53%] [G loss: 1.615589]\n",
      "epoch:35 step:33240 [D loss: 0.364577, acc.: 85.16%] [G loss: 1.654663]\n",
      "epoch:35 step:33241 [D loss: 0.493816, acc.: 76.56%] [G loss: 1.426791]\n",
      "epoch:35 step:33242 [D loss: 0.494153, acc.: 72.66%] [G loss: 1.368439]\n",
      "epoch:35 step:33243 [D loss: 0.583147, acc.: 68.75%] [G loss: 1.475241]\n",
      "epoch:35 step:33244 [D loss: 0.402600, acc.: 83.59%] [G loss: 1.956488]\n",
      "epoch:35 step:33245 [D loss: 0.753513, acc.: 58.59%] [G loss: 1.439093]\n",
      "epoch:35 step:33246 [D loss: 0.448967, acc.: 79.69%] [G loss: 1.500467]\n",
      "epoch:35 step:33247 [D loss: 0.490341, acc.: 75.78%] [G loss: 2.017763]\n",
      "epoch:35 step:33248 [D loss: 0.632587, acc.: 64.84%] [G loss: 0.982536]\n",
      "epoch:35 step:33249 [D loss: 0.431445, acc.: 78.12%] [G loss: 1.560445]\n",
      "epoch:35 step:33250 [D loss: 0.411190, acc.: 78.12%] [G loss: 1.442789]\n",
      "epoch:35 step:33251 [D loss: 0.502839, acc.: 77.34%] [G loss: 1.838944]\n",
      "epoch:35 step:33252 [D loss: 0.566174, acc.: 72.66%] [G loss: 1.349355]\n",
      "epoch:35 step:33253 [D loss: 0.539389, acc.: 74.22%] [G loss: 1.495515]\n",
      "epoch:35 step:33254 [D loss: 0.477568, acc.: 82.03%] [G loss: 1.674309]\n",
      "epoch:35 step:33255 [D loss: 0.446485, acc.: 81.25%] [G loss: 2.146816]\n",
      "epoch:35 step:33256 [D loss: 0.547313, acc.: 71.88%] [G loss: 1.639699]\n",
      "epoch:35 step:33257 [D loss: 0.634878, acc.: 64.06%] [G loss: 1.287343]\n",
      "epoch:35 step:33258 [D loss: 0.452367, acc.: 78.12%] [G loss: 1.047045]\n",
      "epoch:35 step:33259 [D loss: 0.397631, acc.: 84.38%] [G loss: 1.630033]\n",
      "epoch:35 step:33260 [D loss: 0.570062, acc.: 70.31%] [G loss: 1.179753]\n",
      "epoch:35 step:33261 [D loss: 0.309903, acc.: 89.06%] [G loss: 1.963592]\n",
      "epoch:35 step:33262 [D loss: 0.410926, acc.: 84.38%] [G loss: 1.650934]\n",
      "epoch:35 step:33263 [D loss: 0.348159, acc.: 86.72%] [G loss: 1.376028]\n",
      "epoch:35 step:33264 [D loss: 0.710245, acc.: 60.94%] [G loss: 1.188098]\n",
      "epoch:35 step:33265 [D loss: 0.611242, acc.: 64.84%] [G loss: 1.438146]\n",
      "epoch:35 step:33266 [D loss: 0.653065, acc.: 63.28%] [G loss: 1.120395]\n",
      "epoch:35 step:33267 [D loss: 0.480378, acc.: 76.56%] [G loss: 1.890350]\n",
      "epoch:35 step:33268 [D loss: 0.523001, acc.: 72.66%] [G loss: 1.540155]\n",
      "epoch:35 step:33269 [D loss: 0.473666, acc.: 78.91%] [G loss: 1.888428]\n",
      "epoch:35 step:33270 [D loss: 0.389691, acc.: 87.50%] [G loss: 2.756488]\n",
      "epoch:35 step:33271 [D loss: 0.358342, acc.: 88.28%] [G loss: 2.132894]\n",
      "epoch:35 step:33272 [D loss: 0.410819, acc.: 81.25%] [G loss: 1.679279]\n",
      "epoch:35 step:33273 [D loss: 0.249030, acc.: 92.19%] [G loss: 1.673784]\n",
      "epoch:35 step:33274 [D loss: 0.501276, acc.: 78.12%] [G loss: 1.237256]\n",
      "epoch:35 step:33275 [D loss: 0.338210, acc.: 89.06%] [G loss: 1.890451]\n",
      "epoch:35 step:33276 [D loss: 0.528286, acc.: 75.00%] [G loss: 1.219317]\n",
      "epoch:35 step:33277 [D loss: 0.547554, acc.: 74.22%] [G loss: 1.799906]\n",
      "epoch:35 step:33278 [D loss: 0.661121, acc.: 58.59%] [G loss: 1.090890]\n",
      "epoch:35 step:33279 [D loss: 0.413924, acc.: 82.81%] [G loss: 1.605470]\n",
      "epoch:35 step:33280 [D loss: 0.910174, acc.: 50.00%] [G loss: 1.047980]\n",
      "epoch:35 step:33281 [D loss: 0.398179, acc.: 82.81%] [G loss: 1.431266]\n",
      "epoch:35 step:33282 [D loss: 0.286654, acc.: 92.19%] [G loss: 1.464032]\n",
      "epoch:35 step:33283 [D loss: 0.461727, acc.: 77.34%] [G loss: 1.464189]\n",
      "epoch:35 step:33284 [D loss: 0.672763, acc.: 67.19%] [G loss: 1.023221]\n",
      "epoch:35 step:33285 [D loss: 0.572472, acc.: 71.88%] [G loss: 1.416639]\n",
      "epoch:35 step:33286 [D loss: 0.371801, acc.: 84.38%] [G loss: 1.532010]\n",
      "epoch:35 step:33287 [D loss: 0.508686, acc.: 71.09%] [G loss: 1.781052]\n",
      "epoch:35 step:33288 [D loss: 0.475329, acc.: 78.12%] [G loss: 1.435170]\n",
      "epoch:35 step:33289 [D loss: 0.745410, acc.: 60.16%] [G loss: 1.477118]\n",
      "epoch:35 step:33290 [D loss: 0.449021, acc.: 75.78%] [G loss: 1.589219]\n",
      "epoch:35 step:33291 [D loss: 0.590178, acc.: 68.75%] [G loss: 1.987875]\n",
      "epoch:35 step:33292 [D loss: 0.595351, acc.: 68.75%] [G loss: 1.490677]\n",
      "epoch:35 step:33293 [D loss: 0.419876, acc.: 85.16%] [G loss: 1.693945]\n",
      "epoch:35 step:33294 [D loss: 0.377794, acc.: 85.94%] [G loss: 1.537552]\n",
      "epoch:35 step:33295 [D loss: 0.757290, acc.: 57.81%] [G loss: 1.245257]\n",
      "epoch:35 step:33296 [D loss: 0.398487, acc.: 83.59%] [G loss: 1.601326]\n",
      "epoch:35 step:33297 [D loss: 0.524939, acc.: 73.44%] [G loss: 1.472411]\n",
      "epoch:35 step:33298 [D loss: 0.542967, acc.: 73.44%] [G loss: 1.497756]\n",
      "epoch:35 step:33299 [D loss: 0.557609, acc.: 74.22%] [G loss: 1.811053]\n",
      "epoch:35 step:33300 [D loss: 0.401774, acc.: 83.59%] [G loss: 1.135513]\n",
      "epoch:35 step:33301 [D loss: 0.351586, acc.: 89.06%] [G loss: 1.724675]\n",
      "epoch:35 step:33302 [D loss: 0.688557, acc.: 58.59%] [G loss: 1.287268]\n",
      "epoch:35 step:33303 [D loss: 0.574170, acc.: 68.75%] [G loss: 1.245129]\n",
      "epoch:35 step:33304 [D loss: 0.759141, acc.: 53.91%] [G loss: 1.258288]\n",
      "epoch:35 step:33305 [D loss: 0.505126, acc.: 75.78%] [G loss: 1.503175]\n",
      "epoch:35 step:33306 [D loss: 0.457062, acc.: 79.69%] [G loss: 1.529615]\n",
      "epoch:35 step:33307 [D loss: 0.419627, acc.: 85.16%] [G loss: 1.691715]\n",
      "epoch:35 step:33308 [D loss: 0.586611, acc.: 75.00%] [G loss: 1.346052]\n",
      "epoch:35 step:33309 [D loss: 0.415604, acc.: 84.38%] [G loss: 1.269419]\n",
      "epoch:35 step:33310 [D loss: 0.527789, acc.: 72.66%] [G loss: 1.504223]\n",
      "epoch:35 step:33311 [D loss: 0.409058, acc.: 82.03%] [G loss: 1.246207]\n",
      "epoch:35 step:33312 [D loss: 0.402903, acc.: 87.50%] [G loss: 1.613104]\n",
      "epoch:35 step:33313 [D loss: 0.433823, acc.: 76.56%] [G loss: 1.984410]\n",
      "epoch:35 step:33314 [D loss: 0.632996, acc.: 66.41%] [G loss: 1.752088]\n",
      "epoch:35 step:33315 [D loss: 0.521839, acc.: 73.44%] [G loss: 1.639102]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:35 step:33316 [D loss: 0.417263, acc.: 82.81%] [G loss: 1.855838]\n",
      "epoch:35 step:33317 [D loss: 0.639011, acc.: 62.50%] [G loss: 1.255073]\n",
      "epoch:35 step:33318 [D loss: 0.602830, acc.: 66.41%] [G loss: 1.538268]\n",
      "epoch:35 step:33319 [D loss: 0.576723, acc.: 68.75%] [G loss: 1.321222]\n",
      "epoch:35 step:33320 [D loss: 0.433035, acc.: 80.47%] [G loss: 1.354527]\n",
      "epoch:35 step:33321 [D loss: 0.463066, acc.: 81.25%] [G loss: 1.695454]\n",
      "epoch:35 step:33322 [D loss: 0.564939, acc.: 69.53%] [G loss: 1.487288]\n",
      "epoch:35 step:33323 [D loss: 0.353096, acc.: 86.72%] [G loss: 2.347051]\n",
      "epoch:35 step:33324 [D loss: 0.569786, acc.: 71.09%] [G loss: 1.412875]\n",
      "epoch:35 step:33325 [D loss: 0.490495, acc.: 74.22%] [G loss: 1.720086]\n",
      "epoch:35 step:33326 [D loss: 0.581786, acc.: 72.66%] [G loss: 1.379762]\n",
      "epoch:35 step:33327 [D loss: 0.581731, acc.: 75.78%] [G loss: 0.936669]\n",
      "epoch:35 step:33328 [D loss: 0.653805, acc.: 63.28%] [G loss: 1.191422]\n",
      "epoch:35 step:33329 [D loss: 0.897109, acc.: 46.88%] [G loss: 1.327300]\n",
      "epoch:35 step:33330 [D loss: 0.450576, acc.: 78.12%] [G loss: 1.727016]\n",
      "epoch:35 step:33331 [D loss: 0.645463, acc.: 65.62%] [G loss: 1.531650]\n",
      "epoch:35 step:33332 [D loss: 0.615319, acc.: 71.09%] [G loss: 1.246203]\n",
      "epoch:35 step:33333 [D loss: 0.670773, acc.: 60.94%] [G loss: 1.390802]\n",
      "epoch:35 step:33334 [D loss: 0.644164, acc.: 66.41%] [G loss: 1.553048]\n",
      "epoch:35 step:33335 [D loss: 0.406435, acc.: 80.47%] [G loss: 1.380532]\n",
      "epoch:35 step:33336 [D loss: 0.603347, acc.: 64.06%] [G loss: 1.345021]\n",
      "epoch:35 step:33337 [D loss: 0.524476, acc.: 69.53%] [G loss: 1.302951]\n",
      "epoch:35 step:33338 [D loss: 0.544618, acc.: 76.56%] [G loss: 1.600783]\n",
      "epoch:35 step:33339 [D loss: 0.783098, acc.: 57.03%] [G loss: 1.644672]\n",
      "epoch:35 step:33340 [D loss: 0.676394, acc.: 63.28%] [G loss: 1.371408]\n",
      "epoch:35 step:33341 [D loss: 0.463507, acc.: 77.34%] [G loss: 1.366216]\n",
      "epoch:35 step:33342 [D loss: 0.756392, acc.: 50.78%] [G loss: 1.582248]\n",
      "epoch:35 step:33343 [D loss: 0.648228, acc.: 64.06%] [G loss: 1.278037]\n",
      "epoch:35 step:33344 [D loss: 0.477414, acc.: 77.34%] [G loss: 1.276448]\n",
      "epoch:35 step:33345 [D loss: 0.577556, acc.: 71.09%] [G loss: 1.546089]\n",
      "epoch:35 step:33346 [D loss: 0.713531, acc.: 56.25%] [G loss: 1.825985]\n",
      "epoch:35 step:33347 [D loss: 0.416913, acc.: 81.25%] [G loss: 1.511484]\n",
      "epoch:35 step:33348 [D loss: 0.548651, acc.: 70.31%] [G loss: 1.641638]\n",
      "epoch:35 step:33349 [D loss: 0.804889, acc.: 50.00%] [G loss: 0.882009]\n",
      "epoch:35 step:33350 [D loss: 0.313995, acc.: 93.75%] [G loss: 1.814269]\n",
      "epoch:35 step:33351 [D loss: 0.457310, acc.: 77.34%] [G loss: 1.969707]\n",
      "epoch:35 step:33352 [D loss: 0.637848, acc.: 64.06%] [G loss: 1.712090]\n",
      "epoch:35 step:33353 [D loss: 0.534638, acc.: 72.66%] [G loss: 1.485424]\n",
      "epoch:35 step:33354 [D loss: 0.560515, acc.: 71.88%] [G loss: 1.619656]\n",
      "epoch:35 step:33355 [D loss: 0.368835, acc.: 82.81%] [G loss: 1.271412]\n",
      "epoch:35 step:33356 [D loss: 0.441121, acc.: 79.69%] [G loss: 1.616536]\n",
      "epoch:35 step:33357 [D loss: 0.410043, acc.: 83.59%] [G loss: 1.822856]\n",
      "epoch:35 step:33358 [D loss: 0.473657, acc.: 77.34%] [G loss: 1.763215]\n",
      "epoch:35 step:33359 [D loss: 0.366967, acc.: 85.16%] [G loss: 1.357538]\n",
      "epoch:35 step:33360 [D loss: 0.492699, acc.: 80.47%] [G loss: 1.488019]\n",
      "epoch:35 step:33361 [D loss: 0.494515, acc.: 78.12%] [G loss: 1.684785]\n",
      "epoch:35 step:33362 [D loss: 0.595182, acc.: 70.31%] [G loss: 0.986501]\n",
      "epoch:35 step:33363 [D loss: 0.644651, acc.: 60.16%] [G loss: 1.434364]\n",
      "epoch:35 step:33364 [D loss: 0.497533, acc.: 78.12%] [G loss: 1.303826]\n",
      "epoch:35 step:33365 [D loss: 0.643785, acc.: 67.19%] [G loss: 1.170871]\n",
      "epoch:35 step:33366 [D loss: 0.386750, acc.: 81.25%] [G loss: 1.699367]\n",
      "epoch:35 step:33367 [D loss: 0.514472, acc.: 74.22%] [G loss: 1.805532]\n",
      "epoch:35 step:33368 [D loss: 0.666393, acc.: 63.28%] [G loss: 1.639200]\n",
      "epoch:35 step:33369 [D loss: 0.587067, acc.: 72.66%] [G loss: 1.363142]\n",
      "epoch:35 step:33370 [D loss: 0.471656, acc.: 78.91%] [G loss: 1.807287]\n",
      "epoch:35 step:33371 [D loss: 0.493937, acc.: 76.56%] [G loss: 1.303273]\n",
      "epoch:35 step:33372 [D loss: 0.561602, acc.: 74.22%] [G loss: 1.456302]\n",
      "epoch:35 step:33373 [D loss: 0.440218, acc.: 83.59%] [G loss: 1.675275]\n",
      "epoch:35 step:33374 [D loss: 0.613673, acc.: 62.50%] [G loss: 1.376050]\n",
      "epoch:35 step:33375 [D loss: 0.482641, acc.: 75.78%] [G loss: 1.374190]\n",
      "epoch:35 step:33376 [D loss: 0.647613, acc.: 70.31%] [G loss: 1.308710]\n",
      "epoch:35 step:33377 [D loss: 0.590100, acc.: 69.53%] [G loss: 1.338741]\n",
      "epoch:35 step:33378 [D loss: 0.577234, acc.: 67.19%] [G loss: 1.820570]\n",
      "epoch:35 step:33379 [D loss: 0.567505, acc.: 66.41%] [G loss: 1.654381]\n",
      "epoch:35 step:33380 [D loss: 0.409998, acc.: 80.47%] [G loss: 1.611744]\n",
      "epoch:35 step:33381 [D loss: 0.515045, acc.: 78.91%] [G loss: 1.449354]\n",
      "epoch:35 step:33382 [D loss: 0.416715, acc.: 84.38%] [G loss: 0.986062]\n",
      "epoch:35 step:33383 [D loss: 0.672994, acc.: 66.41%] [G loss: 1.462095]\n",
      "epoch:35 step:33384 [D loss: 0.534417, acc.: 72.66%] [G loss: 1.786734]\n",
      "epoch:35 step:33385 [D loss: 0.367227, acc.: 89.06%] [G loss: 1.758929]\n",
      "epoch:35 step:33386 [D loss: 0.464548, acc.: 78.12%] [G loss: 1.246657]\n",
      "epoch:35 step:33387 [D loss: 0.363558, acc.: 86.72%] [G loss: 1.846318]\n",
      "epoch:35 step:33388 [D loss: 0.803276, acc.: 53.91%] [G loss: 1.102165]\n",
      "epoch:35 step:33389 [D loss: 0.570411, acc.: 67.97%] [G loss: 1.067446]\n",
      "epoch:35 step:33390 [D loss: 0.493533, acc.: 77.34%] [G loss: 1.404210]\n",
      "epoch:35 step:33391 [D loss: 0.650258, acc.: 65.62%] [G loss: 1.028199]\n",
      "epoch:35 step:33392 [D loss: 0.648787, acc.: 65.62%] [G loss: 1.648350]\n",
      "epoch:35 step:33393 [D loss: 0.449597, acc.: 82.03%] [G loss: 1.450812]\n",
      "epoch:35 step:33394 [D loss: 0.522796, acc.: 75.00%] [G loss: 1.489690]\n",
      "epoch:35 step:33395 [D loss: 0.529534, acc.: 71.09%] [G loss: 1.399471]\n",
      "epoch:35 step:33396 [D loss: 0.604549, acc.: 68.75%] [G loss: 1.478596]\n",
      "epoch:35 step:33397 [D loss: 0.478401, acc.: 73.44%] [G loss: 1.571066]\n",
      "epoch:35 step:33398 [D loss: 0.524514, acc.: 75.00%] [G loss: 1.642449]\n",
      "epoch:35 step:33399 [D loss: 0.611947, acc.: 69.53%] [G loss: 1.161345]\n",
      "epoch:35 step:33400 [D loss: 0.440145, acc.: 81.25%] [G loss: 1.235717]\n",
      "epoch:35 step:33401 [D loss: 0.787468, acc.: 53.12%] [G loss: 1.265084]\n",
      "epoch:35 step:33402 [D loss: 0.437282, acc.: 83.59%] [G loss: 1.468101]\n",
      "epoch:35 step:33403 [D loss: 0.528075, acc.: 75.00%] [G loss: 1.403516]\n",
      "epoch:35 step:33404 [D loss: 0.586942, acc.: 70.31%] [G loss: 1.118713]\n",
      "epoch:35 step:33405 [D loss: 0.522385, acc.: 74.22%] [G loss: 1.344252]\n",
      "epoch:35 step:33406 [D loss: 0.608753, acc.: 66.41%] [G loss: 1.425107]\n",
      "epoch:35 step:33407 [D loss: 0.522621, acc.: 75.78%] [G loss: 1.337157]\n",
      "epoch:35 step:33408 [D loss: 0.651961, acc.: 61.72%] [G loss: 1.498497]\n",
      "epoch:35 step:33409 [D loss: 0.810571, acc.: 50.00%] [G loss: 1.773697]\n",
      "epoch:35 step:33410 [D loss: 0.403843, acc.: 84.38%] [G loss: 1.884356]\n",
      "epoch:35 step:33411 [D loss: 0.531930, acc.: 73.44%] [G loss: 1.913282]\n",
      "epoch:35 step:33412 [D loss: 0.505662, acc.: 74.22%] [G loss: 2.378971]\n",
      "epoch:35 step:33413 [D loss: 0.471455, acc.: 78.12%] [G loss: 1.504442]\n",
      "epoch:35 step:33414 [D loss: 0.685033, acc.: 58.59%] [G loss: 1.330742]\n",
      "epoch:35 step:33415 [D loss: 0.514880, acc.: 75.78%] [G loss: 1.487893]\n",
      "epoch:35 step:33416 [D loss: 0.583840, acc.: 67.97%] [G loss: 1.423339]\n",
      "epoch:35 step:33417 [D loss: 0.580375, acc.: 71.88%] [G loss: 1.231447]\n",
      "epoch:35 step:33418 [D loss: 0.417517, acc.: 83.59%] [G loss: 1.564263]\n",
      "epoch:35 step:33419 [D loss: 0.470788, acc.: 77.34%] [G loss: 1.308193]\n",
      "epoch:35 step:33420 [D loss: 0.443141, acc.: 81.25%] [G loss: 1.702225]\n",
      "epoch:35 step:33421 [D loss: 0.566509, acc.: 76.56%] [G loss: 1.369344]\n",
      "epoch:35 step:33422 [D loss: 0.379327, acc.: 81.25%] [G loss: 1.422194]\n",
      "epoch:35 step:33423 [D loss: 0.593554, acc.: 67.19%] [G loss: 1.637240]\n",
      "epoch:35 step:33424 [D loss: 0.567488, acc.: 69.53%] [G loss: 1.593425]\n",
      "epoch:35 step:33425 [D loss: 0.479544, acc.: 80.47%] [G loss: 1.446677]\n",
      "epoch:35 step:33426 [D loss: 0.489651, acc.: 75.00%] [G loss: 1.233435]\n",
      "epoch:35 step:33427 [D loss: 0.555530, acc.: 73.44%] [G loss: 1.609073]\n",
      "epoch:35 step:33428 [D loss: 0.721789, acc.: 60.16%] [G loss: 1.649750]\n",
      "epoch:35 step:33429 [D loss: 0.574175, acc.: 71.09%] [G loss: 1.336557]\n",
      "epoch:35 step:33430 [D loss: 0.712055, acc.: 62.50%] [G loss: 1.292629]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:35 step:33431 [D loss: 0.434840, acc.: 76.56%] [G loss: 1.876675]\n",
      "epoch:35 step:33432 [D loss: 0.452231, acc.: 78.12%] [G loss: 1.956968]\n",
      "epoch:35 step:33433 [D loss: 0.610374, acc.: 67.97%] [G loss: 1.383626]\n",
      "epoch:35 step:33434 [D loss: 0.623160, acc.: 64.06%] [G loss: 1.185559]\n",
      "epoch:35 step:33435 [D loss: 0.444192, acc.: 82.03%] [G loss: 1.080875]\n",
      "epoch:35 step:33436 [D loss: 0.556484, acc.: 68.75%] [G loss: 1.168394]\n",
      "epoch:35 step:33437 [D loss: 0.449142, acc.: 80.47%] [G loss: 1.258519]\n",
      "epoch:35 step:33438 [D loss: 0.840251, acc.: 53.91%] [G loss: 1.076220]\n",
      "epoch:35 step:33439 [D loss: 0.472647, acc.: 76.56%] [G loss: 1.341808]\n",
      "epoch:35 step:33440 [D loss: 0.509019, acc.: 71.09%] [G loss: 1.162580]\n",
      "epoch:35 step:33441 [D loss: 0.611240, acc.: 71.88%] [G loss: 1.247807]\n",
      "epoch:35 step:33442 [D loss: 0.557468, acc.: 72.66%] [G loss: 1.469204]\n",
      "epoch:35 step:33443 [D loss: 0.379534, acc.: 83.59%] [G loss: 1.624169]\n",
      "epoch:35 step:33444 [D loss: 0.450465, acc.: 79.69%] [G loss: 1.332597]\n",
      "epoch:35 step:33445 [D loss: 0.312346, acc.: 89.84%] [G loss: 1.701024]\n",
      "epoch:35 step:33446 [D loss: 0.211407, acc.: 96.09%] [G loss: 1.591213]\n",
      "epoch:35 step:33447 [D loss: 0.433376, acc.: 84.38%] [G loss: 1.210478]\n",
      "epoch:35 step:33448 [D loss: 0.527772, acc.: 74.22%] [G loss: 1.839026]\n",
      "epoch:35 step:33449 [D loss: 0.566144, acc.: 67.19%] [G loss: 1.553959]\n",
      "epoch:35 step:33450 [D loss: 0.650301, acc.: 61.72%] [G loss: 1.653600]\n",
      "epoch:35 step:33451 [D loss: 0.307122, acc.: 92.19%] [G loss: 1.413405]\n",
      "epoch:35 step:33452 [D loss: 0.619370, acc.: 70.31%] [G loss: 1.834556]\n",
      "epoch:35 step:33453 [D loss: 0.613059, acc.: 64.06%] [G loss: 0.808036]\n",
      "epoch:35 step:33454 [D loss: 0.671275, acc.: 61.72%] [G loss: 1.208786]\n",
      "epoch:35 step:33455 [D loss: 0.712746, acc.: 57.03%] [G loss: 1.287438]\n",
      "epoch:35 step:33456 [D loss: 0.483235, acc.: 79.69%] [G loss: 1.590645]\n",
      "epoch:35 step:33457 [D loss: 0.536553, acc.: 72.66%] [G loss: 1.109274]\n",
      "epoch:35 step:33458 [D loss: 0.490407, acc.: 76.56%] [G loss: 1.378719]\n",
      "epoch:35 step:33459 [D loss: 0.482982, acc.: 77.34%] [G loss: 1.474530]\n",
      "epoch:35 step:33460 [D loss: 0.476251, acc.: 81.25%] [G loss: 1.671232]\n",
      "epoch:35 step:33461 [D loss: 0.325535, acc.: 88.28%] [G loss: 1.403125]\n",
      "epoch:35 step:33462 [D loss: 0.478274, acc.: 77.34%] [G loss: 1.325547]\n",
      "epoch:35 step:33463 [D loss: 0.603327, acc.: 69.53%] [G loss: 1.584804]\n",
      "epoch:35 step:33464 [D loss: 0.306363, acc.: 92.97%] [G loss: 1.919001]\n",
      "epoch:35 step:33465 [D loss: 0.576568, acc.: 67.19%] [G loss: 1.039295]\n",
      "epoch:35 step:33466 [D loss: 0.586787, acc.: 71.88%] [G loss: 0.890079]\n",
      "epoch:35 step:33467 [D loss: 0.450524, acc.: 80.47%] [G loss: 2.053417]\n",
      "epoch:35 step:33468 [D loss: 0.603988, acc.: 74.22%] [G loss: 1.527302]\n",
      "epoch:35 step:33469 [D loss: 0.461727, acc.: 82.03%] [G loss: 1.676594]\n",
      "epoch:35 step:33470 [D loss: 0.673980, acc.: 61.72%] [G loss: 1.533479]\n",
      "epoch:35 step:33471 [D loss: 0.612259, acc.: 71.88%] [G loss: 1.416344]\n",
      "epoch:35 step:33472 [D loss: 0.493374, acc.: 77.34%] [G loss: 1.799241]\n",
      "epoch:35 step:33473 [D loss: 0.598050, acc.: 66.41%] [G loss: 1.230687]\n",
      "epoch:35 step:33474 [D loss: 0.721835, acc.: 59.38%] [G loss: 1.375617]\n",
      "epoch:35 step:33475 [D loss: 0.480609, acc.: 78.12%] [G loss: 1.492837]\n",
      "epoch:35 step:33476 [D loss: 0.575911, acc.: 67.97%] [G loss: 1.348044]\n",
      "epoch:35 step:33477 [D loss: 0.571508, acc.: 73.44%] [G loss: 1.817343]\n",
      "epoch:35 step:33478 [D loss: 0.645805, acc.: 60.16%] [G loss: 1.460211]\n",
      "epoch:35 step:33479 [D loss: 0.600672, acc.: 62.50%] [G loss: 1.520169]\n",
      "epoch:35 step:33480 [D loss: 0.593684, acc.: 68.75%] [G loss: 1.711112]\n",
      "epoch:35 step:33481 [D loss: 0.401456, acc.: 81.25%] [G loss: 1.463113]\n",
      "epoch:35 step:33482 [D loss: 0.442391, acc.: 82.03%] [G loss: 1.675670]\n",
      "epoch:35 step:33483 [D loss: 0.607206, acc.: 69.53%] [G loss: 1.197670]\n",
      "epoch:35 step:33484 [D loss: 0.532341, acc.: 71.88%] [G loss: 1.500926]\n",
      "epoch:35 step:33485 [D loss: 0.691438, acc.: 61.72%] [G loss: 2.037352]\n",
      "epoch:35 step:33486 [D loss: 0.541997, acc.: 71.09%] [G loss: 1.883026]\n",
      "epoch:35 step:33487 [D loss: 0.817641, acc.: 50.78%] [G loss: 1.291720]\n",
      "epoch:35 step:33488 [D loss: 0.542855, acc.: 72.66%] [G loss: 1.822990]\n",
      "epoch:35 step:33489 [D loss: 0.524392, acc.: 78.12%] [G loss: 1.406568]\n",
      "epoch:35 step:33490 [D loss: 0.650130, acc.: 61.72%] [G loss: 1.339888]\n",
      "epoch:35 step:33491 [D loss: 0.648896, acc.: 66.41%] [G loss: 1.673875]\n",
      "epoch:35 step:33492 [D loss: 0.508852, acc.: 80.47%] [G loss: 1.061091]\n",
      "epoch:35 step:33493 [D loss: 0.474160, acc.: 78.12%] [G loss: 1.280466]\n",
      "epoch:35 step:33494 [D loss: 0.612816, acc.: 67.19%] [G loss: 1.500348]\n",
      "epoch:35 step:33495 [D loss: 0.424529, acc.: 83.59%] [G loss: 1.693200]\n",
      "epoch:35 step:33496 [D loss: 0.535345, acc.: 72.66%] [G loss: 1.429104]\n",
      "epoch:35 step:33497 [D loss: 0.456140, acc.: 81.25%] [G loss: 1.307161]\n",
      "epoch:35 step:33498 [D loss: 0.591178, acc.: 67.97%] [G loss: 1.398614]\n",
      "epoch:35 step:33499 [D loss: 0.595300, acc.: 64.84%] [G loss: 1.501395]\n",
      "epoch:35 step:33500 [D loss: 0.417107, acc.: 82.03%] [G loss: 1.184635]\n",
      "epoch:35 step:33501 [D loss: 0.529705, acc.: 75.78%] [G loss: 0.896190]\n",
      "epoch:35 step:33502 [D loss: 0.714237, acc.: 57.03%] [G loss: 1.418103]\n",
      "epoch:35 step:33503 [D loss: 0.361974, acc.: 87.50%] [G loss: 1.820538]\n",
      "epoch:35 step:33504 [D loss: 0.673238, acc.: 60.94%] [G loss: 1.363651]\n",
      "epoch:35 step:33505 [D loss: 0.533331, acc.: 74.22%] [G loss: 1.183360]\n",
      "epoch:35 step:33506 [D loss: 0.453344, acc.: 80.47%] [G loss: 1.627392]\n",
      "epoch:35 step:33507 [D loss: 0.528431, acc.: 74.22%] [G loss: 1.908493]\n",
      "epoch:35 step:33508 [D loss: 0.453277, acc.: 77.34%] [G loss: 1.242062]\n",
      "epoch:35 step:33509 [D loss: 0.665763, acc.: 64.84%] [G loss: 1.492215]\n",
      "epoch:35 step:33510 [D loss: 0.505867, acc.: 75.78%] [G loss: 1.328815]\n",
      "epoch:35 step:33511 [D loss: 0.474453, acc.: 80.47%] [G loss: 1.497538]\n",
      "epoch:35 step:33512 [D loss: 0.495682, acc.: 76.56%] [G loss: 1.686200]\n",
      "epoch:35 step:33513 [D loss: 0.459458, acc.: 76.56%] [G loss: 1.109633]\n",
      "epoch:35 step:33514 [D loss: 0.529002, acc.: 68.75%] [G loss: 1.405690]\n",
      "epoch:35 step:33515 [D loss: 0.550968, acc.: 68.75%] [G loss: 1.229417]\n",
      "epoch:35 step:33516 [D loss: 0.476750, acc.: 78.91%] [G loss: 1.430269]\n",
      "epoch:35 step:33517 [D loss: 0.636534, acc.: 61.72%] [G loss: 1.509768]\n",
      "epoch:35 step:33518 [D loss: 0.469861, acc.: 77.34%] [G loss: 1.645338]\n",
      "epoch:35 step:33519 [D loss: 0.495292, acc.: 75.78%] [G loss: 1.493454]\n",
      "epoch:35 step:33520 [D loss: 0.528995, acc.: 71.88%] [G loss: 1.788856]\n",
      "epoch:35 step:33521 [D loss: 0.801988, acc.: 51.56%] [G loss: 1.624745]\n",
      "epoch:35 step:33522 [D loss: 0.483132, acc.: 78.12%] [G loss: 1.393988]\n",
      "epoch:35 step:33523 [D loss: 0.690983, acc.: 57.81%] [G loss: 1.586190]\n",
      "epoch:35 step:33524 [D loss: 0.471584, acc.: 75.78%] [G loss: 1.125229]\n",
      "epoch:35 step:33525 [D loss: 0.846041, acc.: 41.41%] [G loss: 1.282690]\n",
      "epoch:35 step:33526 [D loss: 0.662932, acc.: 64.84%] [G loss: 1.508548]\n",
      "epoch:35 step:33527 [D loss: 0.603006, acc.: 72.66%] [G loss: 1.862363]\n",
      "epoch:35 step:33528 [D loss: 0.291367, acc.: 91.41%] [G loss: 1.830325]\n",
      "epoch:35 step:33529 [D loss: 0.449436, acc.: 78.91%] [G loss: 2.061147]\n",
      "epoch:35 step:33530 [D loss: 0.529169, acc.: 72.66%] [G loss: 1.604311]\n",
      "epoch:35 step:33531 [D loss: 0.594623, acc.: 65.62%] [G loss: 1.400616]\n",
      "epoch:35 step:33532 [D loss: 0.388810, acc.: 81.25%] [G loss: 1.939149]\n",
      "epoch:35 step:33533 [D loss: 0.466180, acc.: 79.69%] [G loss: 1.457815]\n",
      "epoch:35 step:33534 [D loss: 0.778424, acc.: 48.44%] [G loss: 1.047068]\n",
      "epoch:35 step:33535 [D loss: 0.576409, acc.: 70.31%] [G loss: 1.406071]\n",
      "epoch:35 step:33536 [D loss: 0.552929, acc.: 71.09%] [G loss: 1.199373]\n",
      "epoch:35 step:33537 [D loss: 0.434084, acc.: 82.81%] [G loss: 1.209957]\n",
      "epoch:35 step:33538 [D loss: 0.527563, acc.: 74.22%] [G loss: 1.358533]\n",
      "epoch:35 step:33539 [D loss: 0.526154, acc.: 74.22%] [G loss: 1.348728]\n",
      "epoch:35 step:33540 [D loss: 0.441294, acc.: 82.81%] [G loss: 1.810707]\n",
      "epoch:35 step:33541 [D loss: 0.389092, acc.: 85.16%] [G loss: 1.708157]\n",
      "epoch:35 step:33542 [D loss: 0.689456, acc.: 59.38%] [G loss: 1.943658]\n",
      "epoch:35 step:33543 [D loss: 0.596158, acc.: 67.19%] [G loss: 1.287968]\n",
      "epoch:35 step:33544 [D loss: 0.579913, acc.: 70.31%] [G loss: 1.345454]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:35 step:33545 [D loss: 0.465605, acc.: 75.78%] [G loss: 1.259542]\n",
      "epoch:35 step:33546 [D loss: 0.494009, acc.: 75.78%] [G loss: 1.118584]\n",
      "epoch:35 step:33547 [D loss: 0.418742, acc.: 82.81%] [G loss: 2.088393]\n",
      "epoch:35 step:33548 [D loss: 0.625642, acc.: 64.84%] [G loss: 1.492858]\n",
      "epoch:35 step:33549 [D loss: 0.470316, acc.: 78.91%] [G loss: 1.126315]\n",
      "epoch:35 step:33550 [D loss: 0.410630, acc.: 83.59%] [G loss: 1.228270]\n",
      "epoch:35 step:33551 [D loss: 0.449397, acc.: 79.69%] [G loss: 1.725803]\n",
      "epoch:35 step:33552 [D loss: 0.441113, acc.: 82.81%] [G loss: 1.883326]\n",
      "epoch:35 step:33553 [D loss: 0.582978, acc.: 72.66%] [G loss: 1.329539]\n",
      "epoch:35 step:33554 [D loss: 0.365812, acc.: 88.28%] [G loss: 1.707837]\n",
      "epoch:35 step:33555 [D loss: 0.568507, acc.: 72.66%] [G loss: 1.505972]\n",
      "epoch:35 step:33556 [D loss: 0.455275, acc.: 82.03%] [G loss: 1.268768]\n",
      "epoch:35 step:33557 [D loss: 0.594917, acc.: 69.53%] [G loss: 0.855242]\n",
      "epoch:35 step:33558 [D loss: 0.546378, acc.: 74.22%] [G loss: 1.342029]\n",
      "epoch:35 step:33559 [D loss: 0.364954, acc.: 87.50%] [G loss: 2.047470]\n",
      "epoch:35 step:33560 [D loss: 0.606958, acc.: 71.88%] [G loss: 1.344832]\n",
      "epoch:35 step:33561 [D loss: 0.400872, acc.: 87.50%] [G loss: 1.517687]\n",
      "epoch:35 step:33562 [D loss: 0.443358, acc.: 77.34%] [G loss: 2.042598]\n",
      "epoch:35 step:33563 [D loss: 0.547793, acc.: 72.66%] [G loss: 1.537787]\n",
      "epoch:35 step:33564 [D loss: 0.789352, acc.: 52.34%] [G loss: 1.253393]\n",
      "epoch:35 step:33565 [D loss: 0.794438, acc.: 53.12%] [G loss: 1.439831]\n",
      "epoch:35 step:33566 [D loss: 0.441828, acc.: 80.47%] [G loss: 2.065498]\n",
      "epoch:35 step:33567 [D loss: 0.438231, acc.: 82.03%] [G loss: 1.299789]\n",
      "epoch:35 step:33568 [D loss: 0.611054, acc.: 67.19%] [G loss: 1.469895]\n",
      "epoch:35 step:33569 [D loss: 0.548978, acc.: 74.22%] [G loss: 1.522858]\n",
      "epoch:35 step:33570 [D loss: 0.483654, acc.: 77.34%] [G loss: 1.682455]\n",
      "epoch:35 step:33571 [D loss: 0.353607, acc.: 85.94%] [G loss: 1.458961]\n",
      "epoch:35 step:33572 [D loss: 0.435198, acc.: 78.12%] [G loss: 1.640124]\n",
      "epoch:35 step:33573 [D loss: 0.518807, acc.: 71.88%] [G loss: 1.940748]\n",
      "epoch:35 step:33574 [D loss: 0.508330, acc.: 73.44%] [G loss: 1.390997]\n",
      "epoch:35 step:33575 [D loss: 0.639912, acc.: 64.06%] [G loss: 1.910699]\n",
      "epoch:35 step:33576 [D loss: 0.573366, acc.: 71.88%] [G loss: 2.027456]\n",
      "epoch:35 step:33577 [D loss: 0.447419, acc.: 80.47%] [G loss: 1.673071]\n",
      "epoch:35 step:33578 [D loss: 0.463386, acc.: 80.47%] [G loss: 1.281265]\n",
      "epoch:35 step:33579 [D loss: 0.656387, acc.: 63.28%] [G loss: 1.220869]\n",
      "epoch:35 step:33580 [D loss: 0.636203, acc.: 67.19%] [G loss: 1.517868]\n",
      "epoch:35 step:33581 [D loss: 0.503884, acc.: 73.44%] [G loss: 1.495624]\n",
      "epoch:35 step:33582 [D loss: 0.450605, acc.: 83.59%] [G loss: 1.613195]\n",
      "epoch:35 step:33583 [D loss: 0.519172, acc.: 68.75%] [G loss: 1.491556]\n",
      "epoch:35 step:33584 [D loss: 0.515844, acc.: 75.78%] [G loss: 1.229186]\n",
      "epoch:35 step:33585 [D loss: 0.679316, acc.: 64.84%] [G loss: 1.439163]\n",
      "epoch:35 step:33586 [D loss: 0.598964, acc.: 67.19%] [G loss: 1.084225]\n",
      "epoch:35 step:33587 [D loss: 0.559009, acc.: 70.31%] [G loss: 1.132354]\n",
      "epoch:35 step:33588 [D loss: 0.524628, acc.: 75.00%] [G loss: 1.965670]\n",
      "epoch:35 step:33589 [D loss: 0.564193, acc.: 70.31%] [G loss: 1.319866]\n",
      "epoch:35 step:33590 [D loss: 0.534593, acc.: 72.66%] [G loss: 1.646109]\n",
      "epoch:35 step:33591 [D loss: 0.532262, acc.: 77.34%] [G loss: 1.653954]\n",
      "epoch:35 step:33592 [D loss: 0.299052, acc.: 89.84%] [G loss: 2.374374]\n",
      "epoch:35 step:33593 [D loss: 0.815062, acc.: 55.47%] [G loss: 1.506966]\n",
      "epoch:35 step:33594 [D loss: 0.445176, acc.: 78.12%] [G loss: 1.418243]\n",
      "epoch:35 step:33595 [D loss: 0.342431, acc.: 87.50%] [G loss: 1.438780]\n",
      "epoch:35 step:33596 [D loss: 0.594482, acc.: 67.97%] [G loss: 1.475128]\n",
      "epoch:35 step:33597 [D loss: 0.949164, acc.: 41.41%] [G loss: 0.768378]\n",
      "epoch:35 step:33598 [D loss: 0.423858, acc.: 82.03%] [G loss: 1.403164]\n",
      "epoch:35 step:33599 [D loss: 0.438079, acc.: 81.25%] [G loss: 1.440867]\n",
      "epoch:35 step:33600 [D loss: 0.548724, acc.: 71.09%] [G loss: 1.283849]\n",
      "epoch:35 step:33601 [D loss: 0.493542, acc.: 77.34%] [G loss: 0.913397]\n",
      "epoch:35 step:33602 [D loss: 0.339129, acc.: 87.50%] [G loss: 2.275609]\n",
      "epoch:35 step:33603 [D loss: 0.481905, acc.: 77.34%] [G loss: 1.373498]\n",
      "epoch:35 step:33604 [D loss: 0.289504, acc.: 92.19%] [G loss: 2.208024]\n",
      "epoch:35 step:33605 [D loss: 0.372395, acc.: 85.94%] [G loss: 1.609368]\n",
      "epoch:35 step:33606 [D loss: 0.667444, acc.: 63.28%] [G loss: 1.736874]\n",
      "epoch:35 step:33607 [D loss: 0.443376, acc.: 79.69%] [G loss: 1.424032]\n",
      "epoch:35 step:33608 [D loss: 0.550247, acc.: 68.75%] [G loss: 1.422340]\n",
      "epoch:35 step:33609 [D loss: 0.386845, acc.: 87.50%] [G loss: 1.303721]\n",
      "epoch:35 step:33610 [D loss: 0.734668, acc.: 57.03%] [G loss: 1.719802]\n",
      "epoch:35 step:33611 [D loss: 0.526504, acc.: 71.88%] [G loss: 1.200005]\n",
      "epoch:35 step:33612 [D loss: 0.602640, acc.: 67.97%] [G loss: 2.012226]\n",
      "epoch:35 step:33613 [D loss: 0.445333, acc.: 81.25%] [G loss: 1.451235]\n",
      "epoch:35 step:33614 [D loss: 0.558593, acc.: 69.53%] [G loss: 1.475334]\n",
      "epoch:35 step:33615 [D loss: 0.486757, acc.: 75.78%] [G loss: 1.496523]\n",
      "epoch:35 step:33616 [D loss: 0.589016, acc.: 69.53%] [G loss: 1.712838]\n",
      "epoch:35 step:33617 [D loss: 0.511806, acc.: 77.34%] [G loss: 1.922625]\n",
      "epoch:35 step:33618 [D loss: 0.621203, acc.: 64.06%] [G loss: 2.005159]\n",
      "epoch:35 step:33619 [D loss: 0.566659, acc.: 71.88%] [G loss: 1.193879]\n",
      "epoch:35 step:33620 [D loss: 0.647631, acc.: 64.84%] [G loss: 1.237348]\n",
      "epoch:35 step:33621 [D loss: 0.483292, acc.: 77.34%] [G loss: 1.992388]\n",
      "epoch:35 step:33622 [D loss: 0.513699, acc.: 75.00%] [G loss: 1.417724]\n",
      "epoch:35 step:33623 [D loss: 0.723822, acc.: 57.81%] [G loss: 1.364306]\n",
      "epoch:35 step:33624 [D loss: 0.818169, acc.: 46.09%] [G loss: 1.295083]\n",
      "epoch:35 step:33625 [D loss: 0.535444, acc.: 69.53%] [G loss: 1.649164]\n",
      "epoch:35 step:33626 [D loss: 0.560014, acc.: 68.75%] [G loss: 0.818312]\n",
      "epoch:35 step:33627 [D loss: 0.588559, acc.: 70.31%] [G loss: 1.102850]\n",
      "epoch:35 step:33628 [D loss: 0.613294, acc.: 65.62%] [G loss: 1.186539]\n",
      "epoch:35 step:33629 [D loss: 0.499989, acc.: 71.88%] [G loss: 1.321820]\n",
      "epoch:35 step:33630 [D loss: 0.469311, acc.: 75.00%] [G loss: 1.765128]\n",
      "epoch:35 step:33631 [D loss: 0.568342, acc.: 71.88%] [G loss: 1.488767]\n",
      "epoch:35 step:33632 [D loss: 0.538193, acc.: 75.00%] [G loss: 1.184862]\n",
      "epoch:35 step:33633 [D loss: 0.440448, acc.: 80.47%] [G loss: 1.019076]\n",
      "epoch:35 step:33634 [D loss: 0.438357, acc.: 82.03%] [G loss: 2.012563]\n",
      "epoch:35 step:33635 [D loss: 0.797287, acc.: 50.00%] [G loss: 1.048753]\n",
      "epoch:35 step:33636 [D loss: 0.543306, acc.: 71.88%] [G loss: 1.201033]\n",
      "epoch:35 step:33637 [D loss: 0.516080, acc.: 73.44%] [G loss: 1.779239]\n",
      "epoch:35 step:33638 [D loss: 0.414862, acc.: 82.81%] [G loss: 1.159563]\n",
      "epoch:35 step:33639 [D loss: 0.722039, acc.: 57.81%] [G loss: 1.499226]\n",
      "epoch:35 step:33640 [D loss: 0.600989, acc.: 67.97%] [G loss: 1.401201]\n",
      "epoch:35 step:33641 [D loss: 0.364117, acc.: 86.72%] [G loss: 1.440137]\n",
      "epoch:35 step:33642 [D loss: 0.574398, acc.: 65.62%] [G loss: 1.933951]\n",
      "epoch:35 step:33643 [D loss: 0.429875, acc.: 79.69%] [G loss: 1.893722]\n",
      "epoch:35 step:33644 [D loss: 0.437361, acc.: 84.38%] [G loss: 1.389107]\n",
      "epoch:35 step:33645 [D loss: 0.287267, acc.: 92.97%] [G loss: 1.673594]\n",
      "epoch:35 step:33646 [D loss: 0.975242, acc.: 39.84%] [G loss: 1.049706]\n",
      "epoch:35 step:33647 [D loss: 0.554602, acc.: 68.75%] [G loss: 1.831970]\n",
      "epoch:35 step:33648 [D loss: 0.637066, acc.: 67.97%] [G loss: 1.790258]\n",
      "epoch:35 step:33649 [D loss: 0.609123, acc.: 67.19%] [G loss: 1.614374]\n",
      "epoch:35 step:33650 [D loss: 0.585806, acc.: 70.31%] [G loss: 1.346504]\n",
      "epoch:35 step:33651 [D loss: 0.548232, acc.: 68.75%] [G loss: 1.244477]\n",
      "epoch:35 step:33652 [D loss: 0.501054, acc.: 76.56%] [G loss: 1.311827]\n",
      "epoch:35 step:33653 [D loss: 0.477216, acc.: 78.91%] [G loss: 1.139567]\n",
      "epoch:35 step:33654 [D loss: 0.442867, acc.: 80.47%] [G loss: 1.057238]\n",
      "epoch:35 step:33655 [D loss: 0.565493, acc.: 71.88%] [G loss: 1.682672]\n",
      "epoch:35 step:33656 [D loss: 0.490740, acc.: 78.91%] [G loss: 0.938111]\n",
      "epoch:35 step:33657 [D loss: 0.630825, acc.: 67.97%] [G loss: 1.363238]\n",
      "epoch:35 step:33658 [D loss: 0.685944, acc.: 66.41%] [G loss: 1.391157]\n",
      "epoch:35 step:33659 [D loss: 0.523975, acc.: 76.56%] [G loss: 1.405741]\n",
      "epoch:35 step:33660 [D loss: 0.559260, acc.: 71.09%] [G loss: 1.528528]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:35 step:33661 [D loss: 0.402448, acc.: 82.03%] [G loss: 1.187880]\n",
      "epoch:35 step:33662 [D loss: 0.523021, acc.: 72.66%] [G loss: 1.458530]\n",
      "epoch:35 step:33663 [D loss: 0.502224, acc.: 75.00%] [G loss: 1.137433]\n",
      "epoch:35 step:33664 [D loss: 0.564529, acc.: 71.09%] [G loss: 1.219913]\n",
      "epoch:35 step:33665 [D loss: 0.515434, acc.: 71.88%] [G loss: 2.351753]\n",
      "epoch:35 step:33666 [D loss: 0.671564, acc.: 59.38%] [G loss: 1.729742]\n",
      "epoch:35 step:33667 [D loss: 0.427930, acc.: 79.69%] [G loss: 1.590037]\n",
      "epoch:35 step:33668 [D loss: 0.446245, acc.: 75.78%] [G loss: 1.740044]\n",
      "epoch:35 step:33669 [D loss: 0.599784, acc.: 67.97%] [G loss: 1.188094]\n",
      "epoch:35 step:33670 [D loss: 0.472641, acc.: 76.56%] [G loss: 1.477204]\n",
      "epoch:35 step:33671 [D loss: 0.490615, acc.: 75.00%] [G loss: 1.350758]\n",
      "epoch:35 step:33672 [D loss: 0.425363, acc.: 83.59%] [G loss: 1.511562]\n",
      "epoch:35 step:33673 [D loss: 0.540759, acc.: 71.09%] [G loss: 1.155563]\n",
      "epoch:35 step:33674 [D loss: 0.431402, acc.: 82.03%] [G loss: 1.553414]\n",
      "epoch:35 step:33675 [D loss: 0.324602, acc.: 89.06%] [G loss: 1.887294]\n",
      "epoch:35 step:33676 [D loss: 0.549673, acc.: 72.66%] [G loss: 1.560610]\n",
      "epoch:35 step:33677 [D loss: 0.406370, acc.: 84.38%] [G loss: 2.016171]\n",
      "epoch:35 step:33678 [D loss: 0.651506, acc.: 66.41%] [G loss: 1.515225]\n",
      "epoch:35 step:33679 [D loss: 0.462985, acc.: 78.12%] [G loss: 1.139952]\n",
      "epoch:35 step:33680 [D loss: 0.530717, acc.: 78.12%] [G loss: 1.476948]\n",
      "epoch:35 step:33681 [D loss: 0.308955, acc.: 91.41%] [G loss: 1.788021]\n",
      "epoch:35 step:33682 [D loss: 0.582370, acc.: 72.66%] [G loss: 1.456367]\n",
      "epoch:35 step:33683 [D loss: 0.759790, acc.: 53.12%] [G loss: 1.215064]\n",
      "epoch:35 step:33684 [D loss: 0.588506, acc.: 71.09%] [G loss: 1.243431]\n",
      "epoch:35 step:33685 [D loss: 0.517531, acc.: 71.88%] [G loss: 1.620165]\n",
      "epoch:35 step:33686 [D loss: 0.594852, acc.: 65.62%] [G loss: 1.653786]\n",
      "epoch:35 step:33687 [D loss: 0.686684, acc.: 61.72%] [G loss: 1.589999]\n",
      "epoch:35 step:33688 [D loss: 0.807095, acc.: 51.56%] [G loss: 1.501032]\n",
      "epoch:35 step:33689 [D loss: 0.475409, acc.: 74.22%] [G loss: 1.461443]\n",
      "epoch:35 step:33690 [D loss: 0.311280, acc.: 90.62%] [G loss: 1.474923]\n",
      "epoch:35 step:33691 [D loss: 0.556438, acc.: 72.66%] [G loss: 1.136705]\n",
      "epoch:35 step:33692 [D loss: 0.495261, acc.: 77.34%] [G loss: 1.491894]\n",
      "epoch:35 step:33693 [D loss: 0.371672, acc.: 87.50%] [G loss: 1.375143]\n",
      "epoch:35 step:33694 [D loss: 0.568942, acc.: 69.53%] [G loss: 1.546392]\n",
      "epoch:35 step:33695 [D loss: 0.374118, acc.: 85.16%] [G loss: 1.189738]\n",
      "epoch:35 step:33696 [D loss: 0.758891, acc.: 61.72%] [G loss: 1.126324]\n",
      "epoch:35 step:33697 [D loss: 0.524238, acc.: 71.88%] [G loss: 1.554138]\n",
      "epoch:35 step:33698 [D loss: 0.542783, acc.: 75.78%] [G loss: 1.099106]\n",
      "epoch:35 step:33699 [D loss: 0.373069, acc.: 85.16%] [G loss: 1.626486]\n",
      "epoch:35 step:33700 [D loss: 0.394778, acc.: 83.59%] [G loss: 1.037154]\n",
      "epoch:35 step:33701 [D loss: 0.650365, acc.: 63.28%] [G loss: 1.443671]\n",
      "epoch:35 step:33702 [D loss: 0.333504, acc.: 89.84%] [G loss: 1.593383]\n",
      "epoch:35 step:33703 [D loss: 0.587879, acc.: 67.19%] [G loss: 1.732596]\n",
      "epoch:35 step:33704 [D loss: 0.334273, acc.: 88.28%] [G loss: 1.823837]\n",
      "epoch:35 step:33705 [D loss: 0.339623, acc.: 89.06%] [G loss: 1.281703]\n",
      "epoch:35 step:33706 [D loss: 0.527941, acc.: 75.00%] [G loss: 1.360124]\n",
      "epoch:35 step:33707 [D loss: 0.590094, acc.: 65.62%] [G loss: 1.338268]\n",
      "epoch:35 step:33708 [D loss: 0.544766, acc.: 71.88%] [G loss: 1.317561]\n",
      "epoch:35 step:33709 [D loss: 0.503399, acc.: 76.56%] [G loss: 1.695729]\n",
      "epoch:35 step:33710 [D loss: 0.494934, acc.: 75.00%] [G loss: 1.389202]\n",
      "epoch:35 step:33711 [D loss: 0.475911, acc.: 79.69%] [G loss: 1.453489]\n",
      "epoch:35 step:33712 [D loss: 0.633364, acc.: 71.09%] [G loss: 1.542258]\n",
      "epoch:35 step:33713 [D loss: 0.394520, acc.: 84.38%] [G loss: 1.397431]\n",
      "epoch:35 step:33714 [D loss: 0.584287, acc.: 68.75%] [G loss: 2.039795]\n",
      "epoch:35 step:33715 [D loss: 0.603730, acc.: 62.50%] [G loss: 1.691543]\n",
      "epoch:35 step:33716 [D loss: 0.511980, acc.: 75.00%] [G loss: 2.005471]\n",
      "epoch:35 step:33717 [D loss: 0.452132, acc.: 79.69%] [G loss: 1.350053]\n",
      "epoch:35 step:33718 [D loss: 0.513265, acc.: 71.88%] [G loss: 1.733946]\n",
      "epoch:35 step:33719 [D loss: 0.445921, acc.: 77.34%] [G loss: 1.626400]\n",
      "epoch:35 step:33720 [D loss: 0.455200, acc.: 78.91%] [G loss: 1.330573]\n",
      "epoch:35 step:33721 [D loss: 0.472936, acc.: 75.00%] [G loss: 1.454297]\n",
      "epoch:35 step:33722 [D loss: 0.739029, acc.: 57.81%] [G loss: 1.448742]\n",
      "epoch:35 step:33723 [D loss: 0.464260, acc.: 78.91%] [G loss: 1.462627]\n",
      "epoch:35 step:33724 [D loss: 0.790436, acc.: 52.34%] [G loss: 1.360758]\n",
      "epoch:35 step:33725 [D loss: 0.581196, acc.: 68.75%] [G loss: 1.487261]\n",
      "epoch:35 step:33726 [D loss: 0.665552, acc.: 60.16%] [G loss: 1.392831]\n",
      "epoch:35 step:33727 [D loss: 0.386758, acc.: 86.72%] [G loss: 1.626783]\n",
      "epoch:35 step:33728 [D loss: 0.597995, acc.: 70.31%] [G loss: 1.063985]\n",
      "epoch:35 step:33729 [D loss: 0.527363, acc.: 73.44%] [G loss: 1.175090]\n",
      "epoch:35 step:33730 [D loss: 0.470950, acc.: 80.47%] [G loss: 1.713124]\n",
      "epoch:35 step:33731 [D loss: 0.482866, acc.: 77.34%] [G loss: 1.577413]\n",
      "epoch:35 step:33732 [D loss: 0.533193, acc.: 70.31%] [G loss: 1.201638]\n",
      "epoch:36 step:33733 [D loss: 0.456137, acc.: 81.25%] [G loss: 1.602307]\n",
      "epoch:36 step:33734 [D loss: 0.328922, acc.: 85.16%] [G loss: 1.383748]\n",
      "epoch:36 step:33735 [D loss: 0.594333, acc.: 73.44%] [G loss: 1.191124]\n",
      "epoch:36 step:33736 [D loss: 0.507702, acc.: 75.00%] [G loss: 0.818585]\n",
      "epoch:36 step:33737 [D loss: 0.425355, acc.: 85.94%] [G loss: 1.539908]\n",
      "epoch:36 step:33738 [D loss: 0.501676, acc.: 75.00%] [G loss: 1.392430]\n",
      "epoch:36 step:33739 [D loss: 0.456052, acc.: 80.47%] [G loss: 1.575892]\n",
      "epoch:36 step:33740 [D loss: 0.336028, acc.: 86.72%] [G loss: 1.630080]\n",
      "epoch:36 step:33741 [D loss: 0.473743, acc.: 78.12%] [G loss: 1.605824]\n",
      "epoch:36 step:33742 [D loss: 0.638514, acc.: 66.41%] [G loss: 1.502582]\n",
      "epoch:36 step:33743 [D loss: 0.430241, acc.: 82.81%] [G loss: 1.601007]\n",
      "epoch:36 step:33744 [D loss: 0.553323, acc.: 67.97%] [G loss: 1.716336]\n",
      "epoch:36 step:33745 [D loss: 0.547867, acc.: 70.31%] [G loss: 1.328032]\n",
      "epoch:36 step:33746 [D loss: 0.608647, acc.: 70.31%] [G loss: 1.712343]\n",
      "epoch:36 step:33747 [D loss: 0.368599, acc.: 89.06%] [G loss: 1.525619]\n",
      "epoch:36 step:33748 [D loss: 0.497639, acc.: 78.91%] [G loss: 1.696835]\n",
      "epoch:36 step:33749 [D loss: 0.434641, acc.: 82.81%] [G loss: 1.493216]\n",
      "epoch:36 step:33750 [D loss: 0.547334, acc.: 67.19%] [G loss: 1.608529]\n",
      "epoch:36 step:33751 [D loss: 0.591410, acc.: 67.97%] [G loss: 1.335897]\n",
      "epoch:36 step:33752 [D loss: 0.417617, acc.: 84.38%] [G loss: 1.812803]\n",
      "epoch:36 step:33753 [D loss: 0.800179, acc.: 54.69%] [G loss: 1.226108]\n",
      "epoch:36 step:33754 [D loss: 0.404650, acc.: 81.25%] [G loss: 1.341472]\n",
      "epoch:36 step:33755 [D loss: 0.424052, acc.: 84.38%] [G loss: 1.364067]\n",
      "epoch:36 step:33756 [D loss: 0.400841, acc.: 82.81%] [G loss: 1.459379]\n",
      "epoch:36 step:33757 [D loss: 0.749187, acc.: 59.38%] [G loss: 1.478029]\n",
      "epoch:36 step:33758 [D loss: 0.641780, acc.: 64.84%] [G loss: 1.250238]\n",
      "epoch:36 step:33759 [D loss: 0.459400, acc.: 80.47%] [G loss: 1.390546]\n",
      "epoch:36 step:33760 [D loss: 0.703530, acc.: 55.47%] [G loss: 1.465815]\n",
      "epoch:36 step:33761 [D loss: 0.510980, acc.: 75.00%] [G loss: 1.599971]\n",
      "epoch:36 step:33762 [D loss: 0.510335, acc.: 76.56%] [G loss: 1.187488]\n",
      "epoch:36 step:33763 [D loss: 0.666391, acc.: 61.72%] [G loss: 1.369783]\n",
      "epoch:36 step:33764 [D loss: 0.512675, acc.: 75.00%] [G loss: 1.635436]\n",
      "epoch:36 step:33765 [D loss: 0.480764, acc.: 76.56%] [G loss: 1.280247]\n",
      "epoch:36 step:33766 [D loss: 0.517434, acc.: 79.69%] [G loss: 2.056947]\n",
      "epoch:36 step:33767 [D loss: 0.388891, acc.: 86.72%] [G loss: 1.903592]\n",
      "epoch:36 step:33768 [D loss: 0.498217, acc.: 81.25%] [G loss: 1.399393]\n",
      "epoch:36 step:33769 [D loss: 0.431473, acc.: 79.69%] [G loss: 1.524859]\n",
      "epoch:36 step:33770 [D loss: 0.427940, acc.: 82.81%] [G loss: 1.654094]\n",
      "epoch:36 step:33771 [D loss: 0.523486, acc.: 72.66%] [G loss: 1.542665]\n",
      "epoch:36 step:33772 [D loss: 0.418492, acc.: 81.25%] [G loss: 1.472279]\n",
      "epoch:36 step:33773 [D loss: 0.504852, acc.: 78.12%] [G loss: 1.643055]\n",
      "epoch:36 step:33774 [D loss: 0.520648, acc.: 74.22%] [G loss: 1.401954]\n",
      "epoch:36 step:33775 [D loss: 0.355726, acc.: 88.28%] [G loss: 1.750088]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:36 step:33776 [D loss: 0.534568, acc.: 70.31%] [G loss: 1.183909]\n",
      "epoch:36 step:33777 [D loss: 0.572413, acc.: 67.19%] [G loss: 1.045594]\n",
      "epoch:36 step:33778 [D loss: 0.473853, acc.: 79.69%] [G loss: 1.474828]\n",
      "epoch:36 step:33779 [D loss: 0.650296, acc.: 64.06%] [G loss: 1.128876]\n",
      "epoch:36 step:33780 [D loss: 0.890884, acc.: 43.75%] [G loss: 1.133777]\n",
      "epoch:36 step:33781 [D loss: 0.406995, acc.: 82.81%] [G loss: 1.231940]\n",
      "epoch:36 step:33782 [D loss: 0.585006, acc.: 71.09%] [G loss: 1.663569]\n",
      "epoch:36 step:33783 [D loss: 0.392922, acc.: 81.25%] [G loss: 1.636212]\n",
      "epoch:36 step:33784 [D loss: 0.560000, acc.: 72.66%] [G loss: 1.670991]\n",
      "epoch:36 step:33785 [D loss: 0.599035, acc.: 69.53%] [G loss: 1.090998]\n",
      "epoch:36 step:33786 [D loss: 0.628787, acc.: 69.53%] [G loss: 1.529763]\n",
      "epoch:36 step:33787 [D loss: 0.406719, acc.: 81.25%] [G loss: 1.881836]\n",
      "epoch:36 step:33788 [D loss: 0.436887, acc.: 84.38%] [G loss: 0.954026]\n",
      "epoch:36 step:33789 [D loss: 0.463400, acc.: 78.12%] [G loss: 1.587167]\n",
      "epoch:36 step:33790 [D loss: 0.482645, acc.: 80.47%] [G loss: 1.700296]\n",
      "epoch:36 step:33791 [D loss: 0.359735, acc.: 85.16%] [G loss: 1.465425]\n",
      "epoch:36 step:33792 [D loss: 0.586351, acc.: 64.06%] [G loss: 1.102589]\n",
      "epoch:36 step:33793 [D loss: 0.517217, acc.: 71.09%] [G loss: 1.571007]\n",
      "epoch:36 step:33794 [D loss: 0.450377, acc.: 81.25%] [G loss: 1.435929]\n",
      "epoch:36 step:33795 [D loss: 0.533328, acc.: 76.56%] [G loss: 1.116807]\n",
      "epoch:36 step:33796 [D loss: 0.439177, acc.: 77.34%] [G loss: 1.653811]\n",
      "epoch:36 step:33797 [D loss: 0.527292, acc.: 72.66%] [G loss: 1.253052]\n",
      "epoch:36 step:33798 [D loss: 0.646242, acc.: 60.94%] [G loss: 1.473284]\n",
      "epoch:36 step:33799 [D loss: 0.433587, acc.: 83.59%] [G loss: 1.576015]\n",
      "epoch:36 step:33800 [D loss: 0.383273, acc.: 81.25%] [G loss: 1.810830]\n",
      "epoch:36 step:33801 [D loss: 0.604079, acc.: 68.75%] [G loss: 1.096307]\n",
      "epoch:36 step:33802 [D loss: 0.488742, acc.: 75.00%] [G loss: 1.572980]\n",
      "epoch:36 step:33803 [D loss: 0.661712, acc.: 63.28%] [G loss: 1.116334]\n",
      "epoch:36 step:33804 [D loss: 0.601440, acc.: 65.62%] [G loss: 1.015686]\n",
      "epoch:36 step:33805 [D loss: 0.454852, acc.: 78.12%] [G loss: 1.435725]\n",
      "epoch:36 step:33806 [D loss: 0.360773, acc.: 89.84%] [G loss: 1.709337]\n",
      "epoch:36 step:33807 [D loss: 0.438536, acc.: 80.47%] [G loss: 2.209550]\n",
      "epoch:36 step:33808 [D loss: 0.825615, acc.: 50.78%] [G loss: 1.339604]\n",
      "epoch:36 step:33809 [D loss: 0.602209, acc.: 67.19%] [G loss: 1.595760]\n",
      "epoch:36 step:33810 [D loss: 0.462525, acc.: 82.81%] [G loss: 1.572100]\n",
      "epoch:36 step:33811 [D loss: 0.704607, acc.: 60.16%] [G loss: 1.252788]\n",
      "epoch:36 step:33812 [D loss: 0.500078, acc.: 75.78%] [G loss: 2.006133]\n",
      "epoch:36 step:33813 [D loss: 0.488766, acc.: 77.34%] [G loss: 1.886084]\n",
      "epoch:36 step:33814 [D loss: 0.426272, acc.: 82.81%] [G loss: 1.444548]\n",
      "epoch:36 step:33815 [D loss: 0.603104, acc.: 67.97%] [G loss: 1.431903]\n",
      "epoch:36 step:33816 [D loss: 0.606031, acc.: 69.53%] [G loss: 1.069348]\n",
      "epoch:36 step:33817 [D loss: 0.402234, acc.: 85.94%] [G loss: 1.562055]\n",
      "epoch:36 step:33818 [D loss: 0.430826, acc.: 82.03%] [G loss: 1.456819]\n",
      "epoch:36 step:33819 [D loss: 0.695868, acc.: 58.59%] [G loss: 1.660255]\n",
      "epoch:36 step:33820 [D loss: 0.695949, acc.: 60.94%] [G loss: 1.313790]\n",
      "epoch:36 step:33821 [D loss: 0.399090, acc.: 81.25%] [G loss: 1.682338]\n",
      "epoch:36 step:33822 [D loss: 0.629662, acc.: 71.09%] [G loss: 1.181715]\n",
      "epoch:36 step:33823 [D loss: 0.530551, acc.: 74.22%] [G loss: 1.137113]\n",
      "epoch:36 step:33824 [D loss: 0.437461, acc.: 80.47%] [G loss: 1.679931]\n",
      "epoch:36 step:33825 [D loss: 0.606585, acc.: 66.41%] [G loss: 1.289665]\n",
      "epoch:36 step:33826 [D loss: 0.498946, acc.: 76.56%] [G loss: 1.644135]\n",
      "epoch:36 step:33827 [D loss: 0.386632, acc.: 85.16%] [G loss: 1.268596]\n",
      "epoch:36 step:33828 [D loss: 0.836467, acc.: 43.75%] [G loss: 1.099514]\n",
      "epoch:36 step:33829 [D loss: 0.445182, acc.: 79.69%] [G loss: 1.179854]\n",
      "epoch:36 step:33830 [D loss: 0.497127, acc.: 75.00%] [G loss: 1.310143]\n",
      "epoch:36 step:33831 [D loss: 0.438416, acc.: 78.91%] [G loss: 1.047316]\n",
      "epoch:36 step:33832 [D loss: 0.356966, acc.: 90.62%] [G loss: 1.368548]\n",
      "epoch:36 step:33833 [D loss: 0.700247, acc.: 57.81%] [G loss: 1.292588]\n",
      "epoch:36 step:33834 [D loss: 0.355009, acc.: 87.50%] [G loss: 1.751785]\n",
      "epoch:36 step:33835 [D loss: 0.341431, acc.: 90.62%] [G loss: 1.714913]\n",
      "epoch:36 step:33836 [D loss: 0.328491, acc.: 90.62%] [G loss: 1.351038]\n",
      "epoch:36 step:33837 [D loss: 0.419305, acc.: 85.94%] [G loss: 1.543563]\n",
      "epoch:36 step:33838 [D loss: 0.530995, acc.: 75.78%] [G loss: 1.673006]\n",
      "epoch:36 step:33839 [D loss: 0.558166, acc.: 67.97%] [G loss: 1.274438]\n",
      "epoch:36 step:33840 [D loss: 0.489881, acc.: 73.44%] [G loss: 1.290442]\n",
      "epoch:36 step:33841 [D loss: 0.668133, acc.: 58.59%] [G loss: 1.080920]\n",
      "epoch:36 step:33842 [D loss: 0.504052, acc.: 74.22%] [G loss: 2.032200]\n",
      "epoch:36 step:33843 [D loss: 0.494483, acc.: 75.78%] [G loss: 2.028854]\n",
      "epoch:36 step:33844 [D loss: 0.401870, acc.: 84.38%] [G loss: 1.512486]\n",
      "epoch:36 step:33845 [D loss: 0.465482, acc.: 78.91%] [G loss: 1.882469]\n",
      "epoch:36 step:33846 [D loss: 0.401137, acc.: 84.38%] [G loss: 1.528953]\n",
      "epoch:36 step:33847 [D loss: 0.537549, acc.: 72.66%] [G loss: 1.186277]\n",
      "epoch:36 step:33848 [D loss: 0.554974, acc.: 67.97%] [G loss: 1.164068]\n",
      "epoch:36 step:33849 [D loss: 0.410499, acc.: 81.25%] [G loss: 1.340078]\n",
      "epoch:36 step:33850 [D loss: 0.503147, acc.: 72.66%] [G loss: 1.775191]\n",
      "epoch:36 step:33851 [D loss: 0.349805, acc.: 85.94%] [G loss: 1.816547]\n",
      "epoch:36 step:33852 [D loss: 0.750301, acc.: 53.91%] [G loss: 1.478987]\n",
      "epoch:36 step:33853 [D loss: 0.567336, acc.: 69.53%] [G loss: 1.660385]\n",
      "epoch:36 step:33854 [D loss: 0.605146, acc.: 66.41%] [G loss: 1.166880]\n",
      "epoch:36 step:33855 [D loss: 0.431454, acc.: 80.47%] [G loss: 1.430617]\n",
      "epoch:36 step:33856 [D loss: 0.485914, acc.: 78.91%] [G loss: 2.111144]\n",
      "epoch:36 step:33857 [D loss: 0.611308, acc.: 64.06%] [G loss: 1.382502]\n",
      "epoch:36 step:33858 [D loss: 0.452343, acc.: 77.34%] [G loss: 2.220301]\n",
      "epoch:36 step:33859 [D loss: 0.599798, acc.: 66.41%] [G loss: 1.432663]\n",
      "epoch:36 step:33860 [D loss: 0.494818, acc.: 72.66%] [G loss: 1.350613]\n",
      "epoch:36 step:33861 [D loss: 0.365985, acc.: 83.59%] [G loss: 1.247422]\n",
      "epoch:36 step:33862 [D loss: 0.492599, acc.: 78.12%] [G loss: 1.214085]\n",
      "epoch:36 step:33863 [D loss: 0.686374, acc.: 61.72%] [G loss: 1.695998]\n",
      "epoch:36 step:33864 [D loss: 0.507004, acc.: 73.44%] [G loss: 2.100058]\n",
      "epoch:36 step:33865 [D loss: 0.288905, acc.: 89.84%] [G loss: 1.879660]\n",
      "epoch:36 step:33866 [D loss: 0.574170, acc.: 70.31%] [G loss: 1.556200]\n",
      "epoch:36 step:33867 [D loss: 0.407204, acc.: 82.81%] [G loss: 0.977645]\n",
      "epoch:36 step:33868 [D loss: 0.612902, acc.: 66.41%] [G loss: 1.026141]\n",
      "epoch:36 step:33869 [D loss: 0.668099, acc.: 65.62%] [G loss: 1.460719]\n",
      "epoch:36 step:33870 [D loss: 0.458221, acc.: 78.91%] [G loss: 1.863449]\n",
      "epoch:36 step:33871 [D loss: 0.553924, acc.: 71.88%] [G loss: 1.824458]\n",
      "epoch:36 step:33872 [D loss: 0.677542, acc.: 59.38%] [G loss: 1.288724]\n",
      "epoch:36 step:33873 [D loss: 0.935312, acc.: 50.00%] [G loss: 1.813521]\n",
      "epoch:36 step:33874 [D loss: 0.645043, acc.: 61.72%] [G loss: 1.507496]\n",
      "epoch:36 step:33875 [D loss: 0.411175, acc.: 86.72%] [G loss: 1.767745]\n",
      "epoch:36 step:33876 [D loss: 0.485024, acc.: 78.12%] [G loss: 1.294111]\n",
      "epoch:36 step:33877 [D loss: 0.505699, acc.: 71.88%] [G loss: 1.473633]\n",
      "epoch:36 step:33878 [D loss: 0.595130, acc.: 69.53%] [G loss: 1.871499]\n",
      "epoch:36 step:33879 [D loss: 0.461363, acc.: 78.12%] [G loss: 1.554984]\n",
      "epoch:36 step:33880 [D loss: 0.487940, acc.: 78.91%] [G loss: 1.322111]\n",
      "epoch:36 step:33881 [D loss: 0.601337, acc.: 64.84%] [G loss: 1.411371]\n",
      "epoch:36 step:33882 [D loss: 0.618844, acc.: 65.62%] [G loss: 1.084435]\n",
      "epoch:36 step:33883 [D loss: 0.496845, acc.: 78.91%] [G loss: 1.187398]\n",
      "epoch:36 step:33884 [D loss: 0.348060, acc.: 85.94%] [G loss: 1.526528]\n",
      "epoch:36 step:33885 [D loss: 0.406293, acc.: 82.81%] [G loss: 1.661767]\n",
      "epoch:36 step:33886 [D loss: 0.509100, acc.: 71.09%] [G loss: 1.498907]\n",
      "epoch:36 step:33887 [D loss: 0.530880, acc.: 75.00%] [G loss: 1.585443]\n",
      "epoch:36 step:33888 [D loss: 0.420554, acc.: 81.25%] [G loss: 1.725124]\n",
      "epoch:36 step:33889 [D loss: 0.521310, acc.: 71.09%] [G loss: 1.709992]\n",
      "epoch:36 step:33890 [D loss: 0.416906, acc.: 85.94%] [G loss: 2.071361]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:36 step:33891 [D loss: 0.538042, acc.: 71.09%] [G loss: 1.777661]\n",
      "epoch:36 step:33892 [D loss: 0.467557, acc.: 76.56%] [G loss: 1.852469]\n",
      "epoch:36 step:33893 [D loss: 0.508857, acc.: 79.69%] [G loss: 1.559595]\n",
      "epoch:36 step:33894 [D loss: 0.696521, acc.: 58.59%] [G loss: 1.914863]\n",
      "epoch:36 step:33895 [D loss: 0.485821, acc.: 76.56%] [G loss: 1.461127]\n",
      "epoch:36 step:33896 [D loss: 0.537293, acc.: 72.66%] [G loss: 0.968718]\n",
      "epoch:36 step:33897 [D loss: 0.568052, acc.: 73.44%] [G loss: 1.510772]\n",
      "epoch:36 step:33898 [D loss: 0.522196, acc.: 71.09%] [G loss: 1.731038]\n",
      "epoch:36 step:33899 [D loss: 0.392219, acc.: 85.94%] [G loss: 2.290763]\n",
      "epoch:36 step:33900 [D loss: 0.706429, acc.: 57.03%] [G loss: 1.308574]\n",
      "epoch:36 step:33901 [D loss: 0.516177, acc.: 73.44%] [G loss: 1.127691]\n",
      "epoch:36 step:33902 [D loss: 0.430354, acc.: 80.47%] [G loss: 1.706120]\n",
      "epoch:36 step:33903 [D loss: 0.814526, acc.: 51.56%] [G loss: 1.299608]\n",
      "epoch:36 step:33904 [D loss: 0.542082, acc.: 71.88%] [G loss: 1.491486]\n",
      "epoch:36 step:33905 [D loss: 0.795208, acc.: 53.91%] [G loss: 1.023205]\n",
      "epoch:36 step:33906 [D loss: 0.522280, acc.: 74.22%] [G loss: 1.925273]\n",
      "epoch:36 step:33907 [D loss: 0.682015, acc.: 62.50%] [G loss: 1.835351]\n",
      "epoch:36 step:33908 [D loss: 0.334703, acc.: 89.84%] [G loss: 1.861554]\n",
      "epoch:36 step:33909 [D loss: 0.519331, acc.: 76.56%] [G loss: 1.592958]\n",
      "epoch:36 step:33910 [D loss: 0.410923, acc.: 81.25%] [G loss: 1.468725]\n",
      "epoch:36 step:33911 [D loss: 0.520463, acc.: 71.88%] [G loss: 1.497157]\n",
      "epoch:36 step:33912 [D loss: 0.471827, acc.: 78.91%] [G loss: 2.143699]\n",
      "epoch:36 step:33913 [D loss: 0.499137, acc.: 75.00%] [G loss: 1.475531]\n",
      "epoch:36 step:33914 [D loss: 0.626908, acc.: 62.50%] [G loss: 2.004080]\n",
      "epoch:36 step:33915 [D loss: 0.452874, acc.: 82.03%] [G loss: 1.827943]\n",
      "epoch:36 step:33916 [D loss: 0.753913, acc.: 54.69%] [G loss: 1.694881]\n",
      "epoch:36 step:33917 [D loss: 0.443293, acc.: 79.69%] [G loss: 1.294620]\n",
      "epoch:36 step:33918 [D loss: 0.453896, acc.: 82.03%] [G loss: 1.644346]\n",
      "epoch:36 step:33919 [D loss: 0.623010, acc.: 65.62%] [G loss: 1.557993]\n",
      "epoch:36 step:33920 [D loss: 0.528925, acc.: 74.22%] [G loss: 1.117616]\n",
      "epoch:36 step:33921 [D loss: 0.768536, acc.: 59.38%] [G loss: 0.803779]\n",
      "epoch:36 step:33922 [D loss: 0.530433, acc.: 74.22%] [G loss: 0.985652]\n",
      "epoch:36 step:33923 [D loss: 0.636448, acc.: 64.06%] [G loss: 1.581350]\n",
      "epoch:36 step:33924 [D loss: 0.625089, acc.: 59.38%] [G loss: 1.057280]\n",
      "epoch:36 step:33925 [D loss: 0.591449, acc.: 63.28%] [G loss: 1.432848]\n",
      "epoch:36 step:33926 [D loss: 0.536196, acc.: 76.56%] [G loss: 1.518254]\n",
      "epoch:36 step:33927 [D loss: 0.589466, acc.: 64.06%] [G loss: 1.598034]\n",
      "epoch:36 step:33928 [D loss: 0.477772, acc.: 78.12%] [G loss: 1.599920]\n",
      "epoch:36 step:33929 [D loss: 0.364851, acc.: 89.06%] [G loss: 1.644430]\n",
      "epoch:36 step:33930 [D loss: 0.552278, acc.: 67.19%] [G loss: 1.510093]\n",
      "epoch:36 step:33931 [D loss: 0.491632, acc.: 75.78%] [G loss: 1.623786]\n",
      "epoch:36 step:33932 [D loss: 0.408307, acc.: 81.25%] [G loss: 1.147582]\n",
      "epoch:36 step:33933 [D loss: 0.331928, acc.: 87.50%] [G loss: 1.287927]\n",
      "epoch:36 step:33934 [D loss: 0.625575, acc.: 66.41%] [G loss: 1.584498]\n",
      "epoch:36 step:33935 [D loss: 0.400069, acc.: 84.38%] [G loss: 1.792233]\n",
      "epoch:36 step:33936 [D loss: 0.462112, acc.: 78.12%] [G loss: 1.593117]\n",
      "epoch:36 step:33937 [D loss: 0.549975, acc.: 73.44%] [G loss: 1.686240]\n",
      "epoch:36 step:33938 [D loss: 0.493016, acc.: 78.12%] [G loss: 1.997605]\n",
      "epoch:36 step:33939 [D loss: 0.634379, acc.: 71.09%] [G loss: 1.426146]\n",
      "epoch:36 step:33940 [D loss: 0.392878, acc.: 82.03%] [G loss: 1.481439]\n",
      "epoch:36 step:33941 [D loss: 0.457002, acc.: 79.69%] [G loss: 1.298429]\n",
      "epoch:36 step:33942 [D loss: 0.478380, acc.: 81.25%] [G loss: 1.459045]\n",
      "epoch:36 step:33943 [D loss: 0.452392, acc.: 80.47%] [G loss: 1.291370]\n",
      "epoch:36 step:33944 [D loss: 0.537690, acc.: 74.22%] [G loss: 1.399259]\n",
      "epoch:36 step:33945 [D loss: 0.570709, acc.: 68.75%] [G loss: 1.735985]\n",
      "epoch:36 step:33946 [D loss: 0.684151, acc.: 58.59%] [G loss: 1.393869]\n",
      "epoch:36 step:33947 [D loss: 0.627415, acc.: 65.62%] [G loss: 1.355694]\n",
      "epoch:36 step:33948 [D loss: 0.641760, acc.: 67.19%] [G loss: 1.573945]\n",
      "epoch:36 step:33949 [D loss: 0.551909, acc.: 76.56%] [G loss: 1.137852]\n",
      "epoch:36 step:33950 [D loss: 0.439603, acc.: 82.81%] [G loss: 1.701234]\n",
      "epoch:36 step:33951 [D loss: 0.605075, acc.: 68.75%] [G loss: 1.240887]\n",
      "epoch:36 step:33952 [D loss: 0.610930, acc.: 62.50%] [G loss: 1.313740]\n",
      "epoch:36 step:33953 [D loss: 0.544267, acc.: 73.44%] [G loss: 1.402929]\n",
      "epoch:36 step:33954 [D loss: 0.359258, acc.: 89.84%] [G loss: 1.423434]\n",
      "epoch:36 step:33955 [D loss: 0.484073, acc.: 78.91%] [G loss: 1.452117]\n",
      "epoch:36 step:33956 [D loss: 0.590354, acc.: 70.31%] [G loss: 1.440706]\n",
      "epoch:36 step:33957 [D loss: 0.564073, acc.: 69.53%] [G loss: 1.433657]\n",
      "epoch:36 step:33958 [D loss: 0.398099, acc.: 85.16%] [G loss: 1.856489]\n",
      "epoch:36 step:33959 [D loss: 0.476824, acc.: 78.91%] [G loss: 1.408359]\n",
      "epoch:36 step:33960 [D loss: 0.413506, acc.: 84.38%] [G loss: 0.857619]\n",
      "epoch:36 step:33961 [D loss: 0.568115, acc.: 67.19%] [G loss: 0.851820]\n",
      "epoch:36 step:33962 [D loss: 0.387088, acc.: 85.16%] [G loss: 1.508938]\n",
      "epoch:36 step:33963 [D loss: 0.580795, acc.: 74.22%] [G loss: 1.402739]\n",
      "epoch:36 step:33964 [D loss: 0.652644, acc.: 64.06%] [G loss: 1.152841]\n",
      "epoch:36 step:33965 [D loss: 0.593134, acc.: 67.97%] [G loss: 1.126525]\n",
      "epoch:36 step:33966 [D loss: 0.617029, acc.: 66.41%] [G loss: 1.763774]\n",
      "epoch:36 step:33967 [D loss: 0.486679, acc.: 75.00%] [G loss: 1.103320]\n",
      "epoch:36 step:33968 [D loss: 0.348188, acc.: 89.06%] [G loss: 1.921658]\n",
      "epoch:36 step:33969 [D loss: 0.564825, acc.: 68.75%] [G loss: 1.349205]\n",
      "epoch:36 step:33970 [D loss: 0.420363, acc.: 82.81%] [G loss: 2.022989]\n",
      "epoch:36 step:33971 [D loss: 0.517776, acc.: 73.44%] [G loss: 1.322449]\n",
      "epoch:36 step:33972 [D loss: 0.623424, acc.: 68.75%] [G loss: 1.142667]\n",
      "epoch:36 step:33973 [D loss: 0.430614, acc.: 83.59%] [G loss: 1.788819]\n",
      "epoch:36 step:33974 [D loss: 0.681174, acc.: 61.72%] [G loss: 1.123006]\n",
      "epoch:36 step:33975 [D loss: 0.442950, acc.: 72.66%] [G loss: 1.685182]\n",
      "epoch:36 step:33976 [D loss: 0.581103, acc.: 68.75%] [G loss: 1.302732]\n",
      "epoch:36 step:33977 [D loss: 0.479173, acc.: 80.47%] [G loss: 1.240634]\n",
      "epoch:36 step:33978 [D loss: 0.385659, acc.: 85.94%] [G loss: 1.037759]\n",
      "epoch:36 step:33979 [D loss: 0.420851, acc.: 78.91%] [G loss: 1.666851]\n",
      "epoch:36 step:33980 [D loss: 0.313681, acc.: 88.28%] [G loss: 1.204184]\n",
      "epoch:36 step:33981 [D loss: 0.373753, acc.: 88.28%] [G loss: 1.730686]\n",
      "epoch:36 step:33982 [D loss: 0.582918, acc.: 69.53%] [G loss: 1.877115]\n",
      "epoch:36 step:33983 [D loss: 0.444375, acc.: 76.56%] [G loss: 1.937126]\n",
      "epoch:36 step:33984 [D loss: 0.375956, acc.: 82.81%] [G loss: 1.696225]\n",
      "epoch:36 step:33985 [D loss: 0.444286, acc.: 77.34%] [G loss: 1.374128]\n",
      "epoch:36 step:33986 [D loss: 0.434873, acc.: 80.47%] [G loss: 1.246280]\n",
      "epoch:36 step:33987 [D loss: 0.471914, acc.: 81.25%] [G loss: 1.615823]\n",
      "epoch:36 step:33988 [D loss: 0.527732, acc.: 72.66%] [G loss: 1.744236]\n",
      "epoch:36 step:33989 [D loss: 0.460907, acc.: 78.12%] [G loss: 1.326684]\n",
      "epoch:36 step:33990 [D loss: 0.470071, acc.: 78.12%] [G loss: 1.484327]\n",
      "epoch:36 step:33991 [D loss: 0.491618, acc.: 75.00%] [G loss: 1.753928]\n",
      "epoch:36 step:33992 [D loss: 0.568421, acc.: 69.53%] [G loss: 1.497074]\n",
      "epoch:36 step:33993 [D loss: 0.595332, acc.: 67.19%] [G loss: 1.279483]\n",
      "epoch:36 step:33994 [D loss: 0.716513, acc.: 57.81%] [G loss: 1.096623]\n",
      "epoch:36 step:33995 [D loss: 0.467440, acc.: 76.56%] [G loss: 1.466949]\n",
      "epoch:36 step:33996 [D loss: 0.588837, acc.: 72.66%] [G loss: 1.576072]\n",
      "epoch:36 step:33997 [D loss: 0.616190, acc.: 70.31%] [G loss: 1.203678]\n",
      "epoch:36 step:33998 [D loss: 0.438608, acc.: 80.47%] [G loss: 2.029961]\n",
      "epoch:36 step:33999 [D loss: 0.529607, acc.: 69.53%] [G loss: 1.168745]\n",
      "epoch:36 step:34000 [D loss: 0.509262, acc.: 75.00%] [G loss: 1.366224]\n",
      "epoch:36 step:34001 [D loss: 0.474059, acc.: 78.12%] [G loss: 1.488177]\n",
      "epoch:36 step:34002 [D loss: 0.622186, acc.: 64.06%] [G loss: 1.408829]\n",
      "epoch:36 step:34003 [D loss: 0.352931, acc.: 87.50%] [G loss: 2.307194]\n",
      "epoch:36 step:34004 [D loss: 0.404234, acc.: 83.59%] [G loss: 2.051161]\n",
      "epoch:36 step:34005 [D loss: 0.668952, acc.: 65.62%] [G loss: 1.496277]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:36 step:34006 [D loss: 0.492881, acc.: 73.44%] [G loss: 1.271933]\n",
      "epoch:36 step:34007 [D loss: 0.486535, acc.: 78.12%] [G loss: 1.819396]\n",
      "epoch:36 step:34008 [D loss: 0.550202, acc.: 70.31%] [G loss: 1.463034]\n",
      "epoch:36 step:34009 [D loss: 0.462255, acc.: 78.91%] [G loss: 1.548124]\n",
      "epoch:36 step:34010 [D loss: 0.795296, acc.: 53.91%] [G loss: 1.643231]\n",
      "epoch:36 step:34011 [D loss: 0.631910, acc.: 69.53%] [G loss: 1.307549]\n",
      "epoch:36 step:34012 [D loss: 0.533278, acc.: 75.00%] [G loss: 1.675223]\n",
      "epoch:36 step:34013 [D loss: 0.629016, acc.: 67.97%] [G loss: 1.443063]\n",
      "epoch:36 step:34014 [D loss: 0.406091, acc.: 86.72%] [G loss: 1.822443]\n",
      "epoch:36 step:34015 [D loss: 0.541275, acc.: 71.88%] [G loss: 1.404695]\n",
      "epoch:36 step:34016 [D loss: 0.585704, acc.: 74.22%] [G loss: 1.658060]\n",
      "epoch:36 step:34017 [D loss: 0.586024, acc.: 64.06%] [G loss: 1.122098]\n",
      "epoch:36 step:34018 [D loss: 0.546735, acc.: 71.09%] [G loss: 1.412629]\n",
      "epoch:36 step:34019 [D loss: 0.459291, acc.: 79.69%] [G loss: 1.209979]\n",
      "epoch:36 step:34020 [D loss: 0.725047, acc.: 63.28%] [G loss: 1.116343]\n",
      "epoch:36 step:34021 [D loss: 0.400765, acc.: 86.72%] [G loss: 1.738545]\n",
      "epoch:36 step:34022 [D loss: 0.499482, acc.: 71.88%] [G loss: 1.390160]\n",
      "epoch:36 step:34023 [D loss: 0.716072, acc.: 57.81%] [G loss: 1.649608]\n",
      "epoch:36 step:34024 [D loss: 0.638000, acc.: 62.50%] [G loss: 1.630757]\n",
      "epoch:36 step:34025 [D loss: 0.529243, acc.: 75.00%] [G loss: 1.490206]\n",
      "epoch:36 step:34026 [D loss: 0.285609, acc.: 95.31%] [G loss: 1.877578]\n",
      "epoch:36 step:34027 [D loss: 0.597528, acc.: 69.53%] [G loss: 1.383507]\n",
      "epoch:36 step:34028 [D loss: 0.490658, acc.: 77.34%] [G loss: 1.251251]\n",
      "epoch:36 step:34029 [D loss: 0.537872, acc.: 78.91%] [G loss: 1.593006]\n",
      "epoch:36 step:34030 [D loss: 0.544667, acc.: 74.22%] [G loss: 1.130428]\n",
      "epoch:36 step:34031 [D loss: 0.624668, acc.: 64.06%] [G loss: 1.601891]\n",
      "epoch:36 step:34032 [D loss: 0.318613, acc.: 89.84%] [G loss: 1.802473]\n",
      "epoch:36 step:34033 [D loss: 0.693503, acc.: 61.72%] [G loss: 1.213475]\n",
      "epoch:36 step:34034 [D loss: 0.604833, acc.: 66.41%] [G loss: 1.349855]\n",
      "epoch:36 step:34035 [D loss: 0.736108, acc.: 57.81%] [G loss: 1.517543]\n",
      "epoch:36 step:34036 [D loss: 0.624570, acc.: 65.62%] [G loss: 1.563503]\n",
      "epoch:36 step:34037 [D loss: 0.630292, acc.: 66.41%] [G loss: 1.190477]\n",
      "epoch:36 step:34038 [D loss: 0.464214, acc.: 82.03%] [G loss: 1.685310]\n",
      "epoch:36 step:34039 [D loss: 0.575597, acc.: 72.66%] [G loss: 1.793983]\n",
      "epoch:36 step:34040 [D loss: 0.628661, acc.: 67.19%] [G loss: 1.476944]\n",
      "epoch:36 step:34041 [D loss: 0.505247, acc.: 76.56%] [G loss: 1.335344]\n",
      "epoch:36 step:34042 [D loss: 0.427437, acc.: 80.47%] [G loss: 1.172733]\n",
      "epoch:36 step:34043 [D loss: 0.602396, acc.: 64.84%] [G loss: 1.496402]\n",
      "epoch:36 step:34044 [D loss: 0.279274, acc.: 91.41%] [G loss: 2.317942]\n",
      "epoch:36 step:34045 [D loss: 0.433814, acc.: 82.81%] [G loss: 1.268418]\n",
      "epoch:36 step:34046 [D loss: 0.679301, acc.: 57.81%] [G loss: 1.527695]\n",
      "epoch:36 step:34047 [D loss: 0.423063, acc.: 79.69%] [G loss: 1.547136]\n",
      "epoch:36 step:34048 [D loss: 0.788963, acc.: 50.78%] [G loss: 1.096946]\n",
      "epoch:36 step:34049 [D loss: 0.537737, acc.: 71.09%] [G loss: 1.452872]\n",
      "epoch:36 step:34050 [D loss: 0.658289, acc.: 64.06%] [G loss: 1.229460]\n",
      "epoch:36 step:34051 [D loss: 0.493021, acc.: 78.12%] [G loss: 1.051916]\n",
      "epoch:36 step:34052 [D loss: 0.325136, acc.: 88.28%] [G loss: 1.801364]\n",
      "epoch:36 step:34053 [D loss: 0.623567, acc.: 67.97%] [G loss: 1.554615]\n",
      "epoch:36 step:34054 [D loss: 0.530793, acc.: 71.88%] [G loss: 1.776943]\n",
      "epoch:36 step:34055 [D loss: 0.400396, acc.: 82.03%] [G loss: 1.361321]\n",
      "epoch:36 step:34056 [D loss: 0.500120, acc.: 77.34%] [G loss: 1.109484]\n",
      "epoch:36 step:34057 [D loss: 0.413088, acc.: 80.47%] [G loss: 1.468427]\n",
      "epoch:36 step:34058 [D loss: 0.451872, acc.: 79.69%] [G loss: 1.617055]\n",
      "epoch:36 step:34059 [D loss: 0.471424, acc.: 79.69%] [G loss: 1.723527]\n",
      "epoch:36 step:34060 [D loss: 0.461892, acc.: 78.12%] [G loss: 1.868679]\n",
      "epoch:36 step:34061 [D loss: 0.390392, acc.: 85.94%] [G loss: 1.501444]\n",
      "epoch:36 step:34062 [D loss: 0.452996, acc.: 80.47%] [G loss: 1.362612]\n",
      "epoch:36 step:34063 [D loss: 0.540189, acc.: 72.66%] [G loss: 1.307503]\n",
      "epoch:36 step:34064 [D loss: 0.484001, acc.: 75.78%] [G loss: 1.451152]\n",
      "epoch:36 step:34065 [D loss: 0.580853, acc.: 73.44%] [G loss: 1.630013]\n",
      "epoch:36 step:34066 [D loss: 0.553828, acc.: 72.66%] [G loss: 1.183987]\n",
      "epoch:36 step:34067 [D loss: 0.440889, acc.: 80.47%] [G loss: 1.234257]\n",
      "epoch:36 step:34068 [D loss: 0.619641, acc.: 66.41%] [G loss: 2.028074]\n",
      "epoch:36 step:34069 [D loss: 0.644329, acc.: 67.97%] [G loss: 1.197492]\n",
      "epoch:36 step:34070 [D loss: 0.488238, acc.: 77.34%] [G loss: 1.101256]\n",
      "epoch:36 step:34071 [D loss: 0.602707, acc.: 70.31%] [G loss: 1.952119]\n",
      "epoch:36 step:34072 [D loss: 0.553426, acc.: 71.88%] [G loss: 1.366345]\n",
      "epoch:36 step:34073 [D loss: 0.732974, acc.: 53.91%] [G loss: 1.960271]\n",
      "epoch:36 step:34074 [D loss: 0.350103, acc.: 87.50%] [G loss: 1.765344]\n",
      "epoch:36 step:34075 [D loss: 0.784359, acc.: 55.47%] [G loss: 1.270629]\n",
      "epoch:36 step:34076 [D loss: 0.582898, acc.: 65.62%] [G loss: 1.536166]\n",
      "epoch:36 step:34077 [D loss: 0.528377, acc.: 70.31%] [G loss: 1.825513]\n",
      "epoch:36 step:34078 [D loss: 0.586671, acc.: 72.66%] [G loss: 1.691243]\n",
      "epoch:36 step:34079 [D loss: 0.480880, acc.: 77.34%] [G loss: 1.528372]\n",
      "epoch:36 step:34080 [D loss: 0.603395, acc.: 70.31%] [G loss: 1.443737]\n",
      "epoch:36 step:34081 [D loss: 0.395009, acc.: 82.81%] [G loss: 1.725428]\n",
      "epoch:36 step:34082 [D loss: 0.522667, acc.: 75.00%] [G loss: 1.523686]\n",
      "epoch:36 step:34083 [D loss: 0.537934, acc.: 73.44%] [G loss: 1.092067]\n",
      "epoch:36 step:34084 [D loss: 0.529345, acc.: 66.41%] [G loss: 1.439725]\n",
      "epoch:36 step:34085 [D loss: 0.405562, acc.: 85.94%] [G loss: 1.825531]\n",
      "epoch:36 step:34086 [D loss: 0.313870, acc.: 92.19%] [G loss: 2.155947]\n",
      "epoch:36 step:34087 [D loss: 0.527872, acc.: 71.09%] [G loss: 1.370324]\n",
      "epoch:36 step:34088 [D loss: 0.369415, acc.: 82.03%] [G loss: 1.767164]\n",
      "epoch:36 step:34089 [D loss: 0.648704, acc.: 59.38%] [G loss: 1.395947]\n",
      "epoch:36 step:34090 [D loss: 0.575954, acc.: 70.31%] [G loss: 1.145912]\n",
      "epoch:36 step:34091 [D loss: 0.479864, acc.: 78.12%] [G loss: 1.352851]\n",
      "epoch:36 step:34092 [D loss: 0.490035, acc.: 78.12%] [G loss: 1.417942]\n",
      "epoch:36 step:34093 [D loss: 0.516479, acc.: 75.78%] [G loss: 1.680568]\n",
      "epoch:36 step:34094 [D loss: 0.375286, acc.: 82.03%] [G loss: 2.271924]\n",
      "epoch:36 step:34095 [D loss: 0.765385, acc.: 57.03%] [G loss: 1.278059]\n",
      "epoch:36 step:34096 [D loss: 0.532444, acc.: 70.31%] [G loss: 1.542398]\n",
      "epoch:36 step:34097 [D loss: 0.607479, acc.: 72.66%] [G loss: 1.468446]\n",
      "epoch:36 step:34098 [D loss: 0.443900, acc.: 81.25%] [G loss: 1.093317]\n",
      "epoch:36 step:34099 [D loss: 0.472937, acc.: 80.47%] [G loss: 1.586036]\n",
      "epoch:36 step:34100 [D loss: 0.375569, acc.: 84.38%] [G loss: 1.016765]\n",
      "epoch:36 step:34101 [D loss: 0.502965, acc.: 73.44%] [G loss: 1.757646]\n",
      "epoch:36 step:34102 [D loss: 0.848122, acc.: 53.91%] [G loss: 1.400374]\n",
      "epoch:36 step:34103 [D loss: 0.671214, acc.: 63.28%] [G loss: 1.944007]\n",
      "epoch:36 step:34104 [D loss: 0.485531, acc.: 75.00%] [G loss: 1.808663]\n",
      "epoch:36 step:34105 [D loss: 0.541598, acc.: 74.22%] [G loss: 1.336410]\n",
      "epoch:36 step:34106 [D loss: 0.566117, acc.: 72.66%] [G loss: 1.127440]\n",
      "epoch:36 step:34107 [D loss: 0.589825, acc.: 69.53%] [G loss: 1.193542]\n",
      "epoch:36 step:34108 [D loss: 0.578148, acc.: 70.31%] [G loss: 1.325312]\n",
      "epoch:36 step:34109 [D loss: 0.367110, acc.: 89.06%] [G loss: 1.106250]\n",
      "epoch:36 step:34110 [D loss: 0.389932, acc.: 82.81%] [G loss: 1.651481]\n",
      "epoch:36 step:34111 [D loss: 0.664580, acc.: 70.31%] [G loss: 1.816042]\n",
      "epoch:36 step:34112 [D loss: 0.508257, acc.: 74.22%] [G loss: 1.673679]\n",
      "epoch:36 step:34113 [D loss: 0.412437, acc.: 80.47%] [G loss: 1.482913]\n",
      "epoch:36 step:34114 [D loss: 0.418643, acc.: 80.47%] [G loss: 1.716783]\n",
      "epoch:36 step:34115 [D loss: 0.611572, acc.: 65.62%] [G loss: 2.064207]\n",
      "epoch:36 step:34116 [D loss: 0.539953, acc.: 73.44%] [G loss: 1.786621]\n",
      "epoch:36 step:34117 [D loss: 0.500917, acc.: 76.56%] [G loss: 1.772491]\n",
      "epoch:36 step:34118 [D loss: 0.587013, acc.: 71.88%] [G loss: 1.234169]\n",
      "epoch:36 step:34119 [D loss: 0.467768, acc.: 75.78%] [G loss: 1.376818]\n",
      "epoch:36 step:34120 [D loss: 0.643194, acc.: 64.84%] [G loss: 1.387307]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:36 step:34121 [D loss: 0.420993, acc.: 79.69%] [G loss: 1.643533]\n",
      "epoch:36 step:34122 [D loss: 0.585677, acc.: 69.53%] [G loss: 1.444004]\n",
      "epoch:36 step:34123 [D loss: 0.778129, acc.: 54.69%] [G loss: 1.563345]\n",
      "epoch:36 step:34124 [D loss: 0.459293, acc.: 81.25%] [G loss: 1.672655]\n",
      "epoch:36 step:34125 [D loss: 0.522404, acc.: 77.34%] [G loss: 1.580329]\n",
      "epoch:36 step:34126 [D loss: 0.598362, acc.: 75.78%] [G loss: 1.566151]\n",
      "epoch:36 step:34127 [D loss: 0.537637, acc.: 74.22%] [G loss: 1.486635]\n",
      "epoch:36 step:34128 [D loss: 0.669089, acc.: 64.06%] [G loss: 1.724994]\n",
      "epoch:36 step:34129 [D loss: 0.642932, acc.: 63.28%] [G loss: 1.536825]\n",
      "epoch:36 step:34130 [D loss: 0.452120, acc.: 82.81%] [G loss: 1.731175]\n",
      "epoch:36 step:34131 [D loss: 0.555677, acc.: 71.88%] [G loss: 1.448460]\n",
      "epoch:36 step:34132 [D loss: 0.640754, acc.: 62.50%] [G loss: 1.510000]\n",
      "epoch:36 step:34133 [D loss: 0.595588, acc.: 70.31%] [G loss: 1.597278]\n",
      "epoch:36 step:34134 [D loss: 0.805535, acc.: 51.56%] [G loss: 1.612516]\n",
      "epoch:36 step:34135 [D loss: 0.516995, acc.: 75.00%] [G loss: 1.287117]\n",
      "epoch:36 step:34136 [D loss: 0.564343, acc.: 74.22%] [G loss: 1.636986]\n",
      "epoch:36 step:34137 [D loss: 0.471242, acc.: 78.91%] [G loss: 1.351463]\n",
      "epoch:36 step:34138 [D loss: 0.529207, acc.: 76.56%] [G loss: 1.753501]\n",
      "epoch:36 step:34139 [D loss: 0.572841, acc.: 71.09%] [G loss: 1.695861]\n",
      "epoch:36 step:34140 [D loss: 0.628432, acc.: 64.06%] [G loss: 1.173534]\n",
      "epoch:36 step:34141 [D loss: 0.540470, acc.: 74.22%] [G loss: 1.813917]\n",
      "epoch:36 step:34142 [D loss: 0.624067, acc.: 68.75%] [G loss: 1.366449]\n",
      "epoch:36 step:34143 [D loss: 0.427927, acc.: 80.47%] [G loss: 2.240292]\n",
      "epoch:36 step:34144 [D loss: 0.694222, acc.: 56.25%] [G loss: 1.538270]\n",
      "epoch:36 step:34145 [D loss: 0.660298, acc.: 64.84%] [G loss: 1.579887]\n",
      "epoch:36 step:34146 [D loss: 0.630894, acc.: 70.31%] [G loss: 1.606972]\n",
      "epoch:36 step:34147 [D loss: 0.432906, acc.: 79.69%] [G loss: 1.070205]\n",
      "epoch:36 step:34148 [D loss: 0.422788, acc.: 81.25%] [G loss: 1.705932]\n",
      "epoch:36 step:34149 [D loss: 0.528465, acc.: 76.56%] [G loss: 1.555804]\n",
      "epoch:36 step:34150 [D loss: 0.647435, acc.: 67.19%] [G loss: 1.513607]\n",
      "epoch:36 step:34151 [D loss: 0.538121, acc.: 70.31%] [G loss: 1.611748]\n",
      "epoch:36 step:34152 [D loss: 0.431155, acc.: 78.12%] [G loss: 1.141124]\n",
      "epoch:36 step:34153 [D loss: 0.617339, acc.: 67.97%] [G loss: 0.836656]\n",
      "epoch:36 step:34154 [D loss: 0.397775, acc.: 85.94%] [G loss: 1.983642]\n",
      "epoch:36 step:34155 [D loss: 0.538260, acc.: 70.31%] [G loss: 2.138006]\n",
      "epoch:36 step:34156 [D loss: 0.543228, acc.: 75.00%] [G loss: 1.130760]\n",
      "epoch:36 step:34157 [D loss: 0.701204, acc.: 57.03%] [G loss: 1.327266]\n",
      "epoch:36 step:34158 [D loss: 0.430112, acc.: 82.03%] [G loss: 1.900873]\n",
      "epoch:36 step:34159 [D loss: 0.750568, acc.: 55.47%] [G loss: 1.586933]\n",
      "epoch:36 step:34160 [D loss: 0.644458, acc.: 60.16%] [G loss: 1.832912]\n",
      "epoch:36 step:34161 [D loss: 0.462229, acc.: 78.91%] [G loss: 1.584777]\n",
      "epoch:36 step:34162 [D loss: 0.576055, acc.: 70.31%] [G loss: 1.350827]\n",
      "epoch:36 step:34163 [D loss: 0.573398, acc.: 68.75%] [G loss: 1.092142]\n",
      "epoch:36 step:34164 [D loss: 0.478362, acc.: 78.12%] [G loss: 1.516411]\n",
      "epoch:36 step:34165 [D loss: 0.511055, acc.: 70.31%] [G loss: 1.697867]\n",
      "epoch:36 step:34166 [D loss: 0.704013, acc.: 58.59%] [G loss: 1.645042]\n",
      "epoch:36 step:34167 [D loss: 0.568722, acc.: 66.41%] [G loss: 1.622307]\n",
      "epoch:36 step:34168 [D loss: 0.637611, acc.: 68.75%] [G loss: 1.610846]\n",
      "epoch:36 step:34169 [D loss: 0.413280, acc.: 82.03%] [G loss: 1.279295]\n",
      "epoch:36 step:34170 [D loss: 0.666358, acc.: 55.47%] [G loss: 1.349978]\n",
      "epoch:36 step:34171 [D loss: 0.573043, acc.: 68.75%] [G loss: 1.666519]\n",
      "epoch:36 step:34172 [D loss: 0.448492, acc.: 81.25%] [G loss: 1.063068]\n",
      "epoch:36 step:34173 [D loss: 0.327760, acc.: 88.28%] [G loss: 2.084581]\n",
      "epoch:36 step:34174 [D loss: 0.482832, acc.: 78.91%] [G loss: 0.935968]\n",
      "epoch:36 step:34175 [D loss: 0.528470, acc.: 75.78%] [G loss: 1.429475]\n",
      "epoch:36 step:34176 [D loss: 0.364992, acc.: 83.59%] [G loss: 2.004669]\n",
      "epoch:36 step:34177 [D loss: 0.348822, acc.: 89.06%] [G loss: 1.677366]\n",
      "epoch:36 step:34178 [D loss: 0.539349, acc.: 78.12%] [G loss: 1.740181]\n",
      "epoch:36 step:34179 [D loss: 0.562752, acc.: 73.44%] [G loss: 1.619631]\n",
      "epoch:36 step:34180 [D loss: 0.632205, acc.: 67.97%] [G loss: 1.223485]\n",
      "epoch:36 step:34181 [D loss: 0.450667, acc.: 81.25%] [G loss: 1.280971]\n",
      "epoch:36 step:34182 [D loss: 0.501603, acc.: 79.69%] [G loss: 1.385648]\n",
      "epoch:36 step:34183 [D loss: 0.325210, acc.: 89.84%] [G loss: 2.110690]\n",
      "epoch:36 step:34184 [D loss: 0.534225, acc.: 72.66%] [G loss: 1.504601]\n",
      "epoch:36 step:34185 [D loss: 0.468529, acc.: 81.25%] [G loss: 1.678066]\n",
      "epoch:36 step:34186 [D loss: 0.521863, acc.: 74.22%] [G loss: 1.411760]\n",
      "epoch:36 step:34187 [D loss: 0.411308, acc.: 80.47%] [G loss: 2.370783]\n",
      "epoch:36 step:34188 [D loss: 0.481875, acc.: 75.00%] [G loss: 2.249574]\n",
      "epoch:36 step:34189 [D loss: 0.544243, acc.: 78.91%] [G loss: 1.024432]\n",
      "epoch:36 step:34190 [D loss: 0.498488, acc.: 75.00%] [G loss: 2.276981]\n",
      "epoch:36 step:34191 [D loss: 0.401938, acc.: 82.03%] [G loss: 1.980229]\n",
      "epoch:36 step:34192 [D loss: 0.734010, acc.: 57.81%] [G loss: 1.394781]\n",
      "epoch:36 step:34193 [D loss: 0.561347, acc.: 72.66%] [G loss: 1.487038]\n",
      "epoch:36 step:34194 [D loss: 0.422812, acc.: 78.91%] [G loss: 1.719029]\n",
      "epoch:36 step:34195 [D loss: 0.499815, acc.: 75.00%] [G loss: 2.027353]\n",
      "epoch:36 step:34196 [D loss: 0.372281, acc.: 89.06%] [G loss: 1.490079]\n",
      "epoch:36 step:34197 [D loss: 0.611528, acc.: 63.28%] [G loss: 1.654633]\n",
      "epoch:36 step:34198 [D loss: 0.558906, acc.: 72.66%] [G loss: 1.612198]\n",
      "epoch:36 step:34199 [D loss: 0.378736, acc.: 88.28%] [G loss: 2.394719]\n",
      "epoch:36 step:34200 [D loss: 0.433618, acc.: 79.69%] [G loss: 1.956215]\n",
      "epoch:36 step:34201 [D loss: 0.374198, acc.: 87.50%] [G loss: 1.847910]\n",
      "epoch:36 step:34202 [D loss: 0.539698, acc.: 74.22%] [G loss: 1.726578]\n",
      "epoch:36 step:34203 [D loss: 0.433336, acc.: 78.91%] [G loss: 1.129459]\n",
      "epoch:36 step:34204 [D loss: 0.454898, acc.: 85.94%] [G loss: 1.649933]\n",
      "epoch:36 step:34205 [D loss: 0.449156, acc.: 74.22%] [G loss: 1.142989]\n",
      "epoch:36 step:34206 [D loss: 0.482676, acc.: 79.69%] [G loss: 1.556804]\n",
      "epoch:36 step:34207 [D loss: 0.558350, acc.: 71.09%] [G loss: 1.389838]\n",
      "epoch:36 step:34208 [D loss: 0.370531, acc.: 86.72%] [G loss: 1.452790]\n",
      "epoch:36 step:34209 [D loss: 0.605099, acc.: 67.19%] [G loss: 1.673474]\n",
      "epoch:36 step:34210 [D loss: 0.567354, acc.: 70.31%] [G loss: 2.482985]\n",
      "epoch:36 step:34211 [D loss: 0.524188, acc.: 75.00%] [G loss: 1.210762]\n",
      "epoch:36 step:34212 [D loss: 0.655275, acc.: 67.97%] [G loss: 1.130764]\n",
      "epoch:36 step:34213 [D loss: 0.581025, acc.: 74.22%] [G loss: 1.691659]\n",
      "epoch:36 step:34214 [D loss: 0.481481, acc.: 77.34%] [G loss: 1.816551]\n",
      "epoch:36 step:34215 [D loss: 0.526221, acc.: 71.09%] [G loss: 1.835801]\n",
      "epoch:36 step:34216 [D loss: 0.480316, acc.: 79.69%] [G loss: 1.436140]\n",
      "epoch:36 step:34217 [D loss: 0.568560, acc.: 70.31%] [G loss: 1.348131]\n",
      "epoch:36 step:34218 [D loss: 0.367767, acc.: 86.72%] [G loss: 1.784378]\n",
      "epoch:36 step:34219 [D loss: 0.597405, acc.: 67.97%] [G loss: 1.543642]\n",
      "epoch:36 step:34220 [D loss: 0.388853, acc.: 85.16%] [G loss: 1.754268]\n",
      "epoch:36 step:34221 [D loss: 0.604908, acc.: 66.41%] [G loss: 1.103322]\n",
      "epoch:36 step:34222 [D loss: 0.504765, acc.: 73.44%] [G loss: 1.531920]\n",
      "epoch:36 step:34223 [D loss: 0.654483, acc.: 58.59%] [G loss: 1.159573]\n",
      "epoch:36 step:34224 [D loss: 0.600503, acc.: 69.53%] [G loss: 1.703300]\n",
      "epoch:36 step:34225 [D loss: 0.537438, acc.: 75.78%] [G loss: 1.752057]\n",
      "epoch:36 step:34226 [D loss: 0.639142, acc.: 60.94%] [G loss: 1.915231]\n",
      "epoch:36 step:34227 [D loss: 0.648962, acc.: 64.06%] [G loss: 1.212152]\n",
      "epoch:36 step:34228 [D loss: 0.657321, acc.: 64.06%] [G loss: 1.593385]\n",
      "epoch:36 step:34229 [D loss: 0.715242, acc.: 64.06%] [G loss: 1.358331]\n",
      "epoch:36 step:34230 [D loss: 0.517951, acc.: 71.09%] [G loss: 1.472042]\n",
      "epoch:36 step:34231 [D loss: 0.458555, acc.: 82.03%] [G loss: 1.830518]\n",
      "epoch:36 step:34232 [D loss: 0.628330, acc.: 66.41%] [G loss: 1.963131]\n",
      "epoch:36 step:34233 [D loss: 0.517733, acc.: 78.12%] [G loss: 1.443649]\n",
      "epoch:36 step:34234 [D loss: 0.528995, acc.: 72.66%] [G loss: 1.348846]\n",
      "epoch:36 step:34235 [D loss: 0.555084, acc.: 70.31%] [G loss: 1.577483]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:36 step:34236 [D loss: 0.393809, acc.: 85.94%] [G loss: 1.858439]\n",
      "epoch:36 step:34237 [D loss: 0.463709, acc.: 82.81%] [G loss: 1.457419]\n",
      "epoch:36 step:34238 [D loss: 0.331533, acc.: 90.62%] [G loss: 1.526292]\n",
      "epoch:36 step:34239 [D loss: 0.651967, acc.: 62.50%] [G loss: 1.795197]\n",
      "epoch:36 step:34240 [D loss: 0.431616, acc.: 82.81%] [G loss: 2.410994]\n",
      "epoch:36 step:34241 [D loss: 0.355779, acc.: 85.94%] [G loss: 1.839009]\n",
      "epoch:36 step:34242 [D loss: 0.485352, acc.: 77.34%] [G loss: 1.233044]\n",
      "epoch:36 step:34243 [D loss: 0.659137, acc.: 68.75%] [G loss: 1.654004]\n",
      "epoch:36 step:34244 [D loss: 0.371646, acc.: 89.06%] [G loss: 1.251470]\n",
      "epoch:36 step:34245 [D loss: 0.404779, acc.: 84.38%] [G loss: 2.003971]\n",
      "epoch:36 step:34246 [D loss: 0.357108, acc.: 82.81%] [G loss: 1.593710]\n",
      "epoch:36 step:34247 [D loss: 0.577202, acc.: 71.09%] [G loss: 1.407115]\n",
      "epoch:36 step:34248 [D loss: 0.423592, acc.: 82.03%] [G loss: 1.613251]\n",
      "epoch:36 step:34249 [D loss: 0.480655, acc.: 79.69%] [G loss: 1.194355]\n",
      "epoch:36 step:34250 [D loss: 0.514162, acc.: 75.78%] [G loss: 1.687126]\n",
      "epoch:36 step:34251 [D loss: 0.553055, acc.: 69.53%] [G loss: 1.314836]\n",
      "epoch:36 step:34252 [D loss: 0.600119, acc.: 67.19%] [G loss: 1.405799]\n",
      "epoch:36 step:34253 [D loss: 0.377055, acc.: 84.38%] [G loss: 1.737409]\n",
      "epoch:36 step:34254 [D loss: 0.604605, acc.: 69.53%] [G loss: 1.757749]\n",
      "epoch:36 step:34255 [D loss: 0.571074, acc.: 67.19%] [G loss: 0.870230]\n",
      "epoch:36 step:34256 [D loss: 0.447740, acc.: 82.03%] [G loss: 1.288169]\n",
      "epoch:36 step:34257 [D loss: 0.478602, acc.: 80.47%] [G loss: 1.762592]\n",
      "epoch:36 step:34258 [D loss: 0.527811, acc.: 71.88%] [G loss: 1.459239]\n",
      "epoch:36 step:34259 [D loss: 0.664359, acc.: 65.62%] [G loss: 1.898345]\n",
      "epoch:36 step:34260 [D loss: 0.477988, acc.: 77.34%] [G loss: 1.288561]\n",
      "epoch:36 step:34261 [D loss: 0.512060, acc.: 76.56%] [G loss: 1.309875]\n",
      "epoch:36 step:34262 [D loss: 0.418875, acc.: 82.03%] [G loss: 1.358191]\n",
      "epoch:36 step:34263 [D loss: 0.653976, acc.: 60.94%] [G loss: 1.235301]\n",
      "epoch:36 step:34264 [D loss: 0.497450, acc.: 74.22%] [G loss: 1.638482]\n",
      "epoch:36 step:34265 [D loss: 0.432832, acc.: 84.38%] [G loss: 1.716329]\n",
      "epoch:36 step:34266 [D loss: 0.622581, acc.: 69.53%] [G loss: 1.117961]\n",
      "epoch:36 step:34267 [D loss: 0.573757, acc.: 73.44%] [G loss: 1.378647]\n",
      "epoch:36 step:34268 [D loss: 0.421968, acc.: 82.03%] [G loss: 1.690386]\n",
      "epoch:36 step:34269 [D loss: 0.423445, acc.: 81.25%] [G loss: 1.441082]\n",
      "epoch:36 step:34270 [D loss: 0.633518, acc.: 67.19%] [G loss: 1.298850]\n",
      "epoch:36 step:34271 [D loss: 0.524212, acc.: 73.44%] [G loss: 1.373211]\n",
      "epoch:36 step:34272 [D loss: 0.567087, acc.: 70.31%] [G loss: 1.448263]\n",
      "epoch:36 step:34273 [D loss: 0.442323, acc.: 78.12%] [G loss: 1.494985]\n",
      "epoch:36 step:34274 [D loss: 0.460113, acc.: 76.56%] [G loss: 1.241595]\n",
      "epoch:36 step:34275 [D loss: 0.490354, acc.: 78.91%] [G loss: 1.784096]\n",
      "epoch:36 step:34276 [D loss: 0.493601, acc.: 70.31%] [G loss: 1.685382]\n",
      "epoch:36 step:34277 [D loss: 0.671695, acc.: 67.19%] [G loss: 1.229394]\n",
      "epoch:36 step:34278 [D loss: 0.491961, acc.: 78.12%] [G loss: 1.492348]\n",
      "epoch:36 step:34279 [D loss: 0.522719, acc.: 73.44%] [G loss: 1.741581]\n",
      "epoch:36 step:34280 [D loss: 0.667180, acc.: 65.62%] [G loss: 1.169419]\n",
      "epoch:36 step:34281 [D loss: 0.531258, acc.: 77.34%] [G loss: 1.123831]\n",
      "epoch:36 step:34282 [D loss: 0.498147, acc.: 77.34%] [G loss: 1.089527]\n",
      "epoch:36 step:34283 [D loss: 0.560178, acc.: 75.78%] [G loss: 1.340811]\n",
      "epoch:36 step:34284 [D loss: 0.493075, acc.: 80.47%] [G loss: 1.933347]\n",
      "epoch:36 step:34285 [D loss: 0.565987, acc.: 65.62%] [G loss: 1.054905]\n",
      "epoch:36 step:34286 [D loss: 0.457231, acc.: 80.47%] [G loss: 1.487680]\n",
      "epoch:36 step:34287 [D loss: 0.378247, acc.: 89.06%] [G loss: 1.110642]\n",
      "epoch:36 step:34288 [D loss: 0.543486, acc.: 67.19%] [G loss: 1.586240]\n",
      "epoch:36 step:34289 [D loss: 0.648429, acc.: 62.50%] [G loss: 1.518559]\n",
      "epoch:36 step:34290 [D loss: 0.642377, acc.: 62.50%] [G loss: 1.859953]\n",
      "epoch:36 step:34291 [D loss: 0.527229, acc.: 73.44%] [G loss: 1.409027]\n",
      "epoch:36 step:34292 [D loss: 0.579318, acc.: 70.31%] [G loss: 1.203242]\n",
      "epoch:36 step:34293 [D loss: 0.736631, acc.: 55.47%] [G loss: 1.194698]\n",
      "epoch:36 step:34294 [D loss: 0.281993, acc.: 92.19%] [G loss: 2.028325]\n",
      "epoch:36 step:34295 [D loss: 0.425488, acc.: 82.81%] [G loss: 1.588065]\n",
      "epoch:36 step:34296 [D loss: 0.504488, acc.: 75.00%] [G loss: 1.515999]\n",
      "epoch:36 step:34297 [D loss: 0.505075, acc.: 78.12%] [G loss: 1.575723]\n",
      "epoch:36 step:34298 [D loss: 0.270385, acc.: 94.53%] [G loss: 1.287580]\n",
      "epoch:36 step:34299 [D loss: 0.705260, acc.: 60.94%] [G loss: 1.103779]\n",
      "epoch:36 step:34300 [D loss: 0.529942, acc.: 68.75%] [G loss: 1.586215]\n",
      "epoch:36 step:34301 [D loss: 0.485632, acc.: 77.34%] [G loss: 1.395839]\n",
      "epoch:36 step:34302 [D loss: 0.593643, acc.: 71.88%] [G loss: 1.771919]\n",
      "epoch:36 step:34303 [D loss: 0.572626, acc.: 69.53%] [G loss: 1.671352]\n",
      "epoch:36 step:34304 [D loss: 0.597389, acc.: 65.62%] [G loss: 1.223027]\n",
      "epoch:36 step:34305 [D loss: 0.385143, acc.: 85.94%] [G loss: 1.283171]\n",
      "epoch:36 step:34306 [D loss: 0.573009, acc.: 69.53%] [G loss: 1.644974]\n",
      "epoch:36 step:34307 [D loss: 0.374968, acc.: 83.59%] [G loss: 1.467086]\n",
      "epoch:36 step:34308 [D loss: 0.353552, acc.: 85.94%] [G loss: 1.747558]\n",
      "epoch:36 step:34309 [D loss: 0.542319, acc.: 72.66%] [G loss: 1.208502]\n",
      "epoch:36 step:34310 [D loss: 0.427075, acc.: 79.69%] [G loss: 1.660845]\n",
      "epoch:36 step:34311 [D loss: 0.553818, acc.: 71.88%] [G loss: 1.498840]\n",
      "epoch:36 step:34312 [D loss: 0.312385, acc.: 92.19%] [G loss: 1.830563]\n",
      "epoch:36 step:34313 [D loss: 0.495115, acc.: 76.56%] [G loss: 1.235184]\n",
      "epoch:36 step:34314 [D loss: 0.448888, acc.: 79.69%] [G loss: 1.607458]\n",
      "epoch:36 step:34315 [D loss: 0.586360, acc.: 68.75%] [G loss: 1.596524]\n",
      "epoch:36 step:34316 [D loss: 0.485083, acc.: 76.56%] [G loss: 1.471595]\n",
      "epoch:36 step:34317 [D loss: 0.548081, acc.: 71.88%] [G loss: 1.393546]\n",
      "epoch:36 step:34318 [D loss: 0.491155, acc.: 75.78%] [G loss: 1.452176]\n",
      "epoch:36 step:34319 [D loss: 0.599959, acc.: 68.75%] [G loss: 1.783908]\n",
      "epoch:36 step:34320 [D loss: 0.424762, acc.: 85.16%] [G loss: 2.019005]\n",
      "epoch:36 step:34321 [D loss: 0.544445, acc.: 72.66%] [G loss: 1.296170]\n",
      "epoch:36 step:34322 [D loss: 0.346502, acc.: 90.62%] [G loss: 1.702279]\n",
      "epoch:36 step:34323 [D loss: 0.545975, acc.: 71.09%] [G loss: 1.305344]\n",
      "epoch:36 step:34324 [D loss: 0.304079, acc.: 91.41%] [G loss: 2.247238]\n",
      "epoch:36 step:34325 [D loss: 0.522859, acc.: 74.22%] [G loss: 1.377936]\n",
      "epoch:36 step:34326 [D loss: 0.462517, acc.: 79.69%] [G loss: 1.498201]\n",
      "epoch:36 step:34327 [D loss: 0.630512, acc.: 62.50%] [G loss: 1.134654]\n",
      "epoch:36 step:34328 [D loss: 0.569596, acc.: 73.44%] [G loss: 1.714626]\n",
      "epoch:36 step:34329 [D loss: 0.508294, acc.: 76.56%] [G loss: 1.339023]\n",
      "epoch:36 step:34330 [D loss: 0.597807, acc.: 71.09%] [G loss: 1.949448]\n",
      "epoch:36 step:34331 [D loss: 0.445589, acc.: 83.59%] [G loss: 1.600809]\n",
      "epoch:36 step:34332 [D loss: 0.417091, acc.: 85.16%] [G loss: 1.586726]\n",
      "epoch:36 step:34333 [D loss: 0.711699, acc.: 59.38%] [G loss: 1.510690]\n",
      "epoch:36 step:34334 [D loss: 0.334086, acc.: 88.28%] [G loss: 1.339327]\n",
      "epoch:36 step:34335 [D loss: 0.611601, acc.: 63.28%] [G loss: 1.365081]\n",
      "epoch:36 step:34336 [D loss: 0.564379, acc.: 69.53%] [G loss: 1.347198]\n",
      "epoch:36 step:34337 [D loss: 0.492335, acc.: 75.00%] [G loss: 1.429995]\n",
      "epoch:36 step:34338 [D loss: 0.718723, acc.: 55.47%] [G loss: 1.318603]\n",
      "epoch:36 step:34339 [D loss: 0.437351, acc.: 75.00%] [G loss: 1.287125]\n",
      "epoch:36 step:34340 [D loss: 0.485089, acc.: 75.78%] [G loss: 1.396471]\n",
      "epoch:36 step:34341 [D loss: 0.635446, acc.: 60.94%] [G loss: 1.518811]\n",
      "epoch:36 step:34342 [D loss: 0.559074, acc.: 72.66%] [G loss: 1.264816]\n",
      "epoch:36 step:34343 [D loss: 0.487536, acc.: 76.56%] [G loss: 1.306627]\n",
      "epoch:36 step:34344 [D loss: 0.763445, acc.: 51.56%] [G loss: 1.287358]\n",
      "epoch:36 step:34345 [D loss: 0.425840, acc.: 78.12%] [G loss: 1.721624]\n",
      "epoch:36 step:34346 [D loss: 0.651082, acc.: 67.97%] [G loss: 1.763132]\n",
      "epoch:36 step:34347 [D loss: 0.504492, acc.: 76.56%] [G loss: 1.486211]\n",
      "epoch:36 step:34348 [D loss: 0.467877, acc.: 78.12%] [G loss: 1.353903]\n",
      "epoch:36 step:34349 [D loss: 0.666894, acc.: 65.62%] [G loss: 1.809201]\n",
      "epoch:36 step:34350 [D loss: 0.465265, acc.: 78.91%] [G loss: 1.479017]\n",
      "epoch:36 step:34351 [D loss: 0.500445, acc.: 74.22%] [G loss: 1.504392]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:36 step:34352 [D loss: 0.545334, acc.: 71.88%] [G loss: 1.176849]\n",
      "epoch:36 step:34353 [D loss: 0.411567, acc.: 83.59%] [G loss: 1.439525]\n",
      "epoch:36 step:34354 [D loss: 0.677581, acc.: 60.16%] [G loss: 1.362425]\n",
      "epoch:36 step:34355 [D loss: 0.548273, acc.: 71.09%] [G loss: 1.635473]\n",
      "epoch:36 step:34356 [D loss: 0.567970, acc.: 74.22%] [G loss: 1.115760]\n",
      "epoch:36 step:34357 [D loss: 0.657441, acc.: 61.72%] [G loss: 1.407182]\n",
      "epoch:36 step:34358 [D loss: 0.456762, acc.: 78.91%] [G loss: 1.298782]\n",
      "epoch:36 step:34359 [D loss: 0.400746, acc.: 83.59%] [G loss: 2.107980]\n",
      "epoch:36 step:34360 [D loss: 0.668894, acc.: 58.59%] [G loss: 1.242023]\n",
      "epoch:36 step:34361 [D loss: 0.426630, acc.: 83.59%] [G loss: 1.843017]\n",
      "epoch:36 step:34362 [D loss: 0.537105, acc.: 73.44%] [G loss: 1.281018]\n",
      "epoch:36 step:34363 [D loss: 0.455505, acc.: 79.69%] [G loss: 1.385632]\n",
      "epoch:36 step:34364 [D loss: 0.468326, acc.: 79.69%] [G loss: 1.432792]\n",
      "epoch:36 step:34365 [D loss: 0.328857, acc.: 89.84%] [G loss: 1.257136]\n",
      "epoch:36 step:34366 [D loss: 0.594429, acc.: 69.53%] [G loss: 1.360190]\n",
      "epoch:36 step:34367 [D loss: 0.572245, acc.: 67.97%] [G loss: 1.555201]\n",
      "epoch:36 step:34368 [D loss: 0.547135, acc.: 71.88%] [G loss: 1.009703]\n",
      "epoch:36 step:34369 [D loss: 0.591003, acc.: 71.88%] [G loss: 1.016269]\n",
      "epoch:36 step:34370 [D loss: 0.695230, acc.: 54.69%] [G loss: 1.426771]\n",
      "epoch:36 step:34371 [D loss: 0.571104, acc.: 71.09%] [G loss: 2.177729]\n",
      "epoch:36 step:34372 [D loss: 0.741291, acc.: 56.25%] [G loss: 1.577361]\n",
      "epoch:36 step:34373 [D loss: 0.547486, acc.: 73.44%] [G loss: 1.543756]\n",
      "epoch:36 step:34374 [D loss: 0.503810, acc.: 75.78%] [G loss: 1.188851]\n",
      "epoch:36 step:34375 [D loss: 0.835272, acc.: 53.91%] [G loss: 0.982958]\n",
      "epoch:36 step:34376 [D loss: 0.364496, acc.: 88.28%] [G loss: 1.469277]\n",
      "epoch:36 step:34377 [D loss: 0.506307, acc.: 78.12%] [G loss: 1.621233]\n",
      "epoch:36 step:34378 [D loss: 0.564762, acc.: 73.44%] [G loss: 1.212033]\n",
      "epoch:36 step:34379 [D loss: 0.483688, acc.: 77.34%] [G loss: 1.702653]\n",
      "epoch:36 step:34380 [D loss: 0.395698, acc.: 82.03%] [G loss: 1.610553]\n",
      "epoch:36 step:34381 [D loss: 0.521971, acc.: 73.44%] [G loss: 1.483712]\n",
      "epoch:36 step:34382 [D loss: 0.551519, acc.: 77.34%] [G loss: 1.457768]\n",
      "epoch:36 step:34383 [D loss: 0.380596, acc.: 87.50%] [G loss: 1.469866]\n",
      "epoch:36 step:34384 [D loss: 0.617424, acc.: 67.19%] [G loss: 1.045484]\n",
      "epoch:36 step:34385 [D loss: 0.468460, acc.: 78.91%] [G loss: 1.793863]\n",
      "epoch:36 step:34386 [D loss: 0.599658, acc.: 67.97%] [G loss: 1.490232]\n",
      "epoch:36 step:34387 [D loss: 0.391311, acc.: 85.16%] [G loss: 2.085134]\n",
      "epoch:36 step:34388 [D loss: 0.545342, acc.: 75.00%] [G loss: 2.130516]\n",
      "epoch:36 step:34389 [D loss: 0.508468, acc.: 81.25%] [G loss: 1.200510]\n",
      "epoch:36 step:34390 [D loss: 0.655054, acc.: 64.06%] [G loss: 1.047714]\n",
      "epoch:36 step:34391 [D loss: 0.479577, acc.: 80.47%] [G loss: 1.472537]\n",
      "epoch:36 step:34392 [D loss: 0.564677, acc.: 69.53%] [G loss: 1.755847]\n",
      "epoch:36 step:34393 [D loss: 0.408885, acc.: 85.16%] [G loss: 1.418138]\n",
      "epoch:36 step:34394 [D loss: 0.588091, acc.: 67.19%] [G loss: 1.463959]\n",
      "epoch:36 step:34395 [D loss: 0.484595, acc.: 78.12%] [G loss: 1.361676]\n",
      "epoch:36 step:34396 [D loss: 0.781105, acc.: 56.25%] [G loss: 1.193249]\n",
      "epoch:36 step:34397 [D loss: 0.380270, acc.: 82.81%] [G loss: 1.848631]\n",
      "epoch:36 step:34398 [D loss: 0.342765, acc.: 87.50%] [G loss: 2.427858]\n",
      "epoch:36 step:34399 [D loss: 0.480438, acc.: 75.00%] [G loss: 1.555305]\n",
      "epoch:36 step:34400 [D loss: 0.697291, acc.: 57.81%] [G loss: 1.809419]\n",
      "epoch:36 step:34401 [D loss: 0.326731, acc.: 89.84%] [G loss: 1.063435]\n",
      "epoch:36 step:34402 [D loss: 0.490507, acc.: 78.91%] [G loss: 1.222072]\n",
      "epoch:36 step:34403 [D loss: 0.507100, acc.: 73.44%] [G loss: 1.349512]\n",
      "epoch:36 step:34404 [D loss: 0.358536, acc.: 87.50%] [G loss: 1.978411]\n",
      "epoch:36 step:34405 [D loss: 0.672540, acc.: 62.50%] [G loss: 1.207586]\n",
      "epoch:36 step:34406 [D loss: 0.449830, acc.: 76.56%] [G loss: 1.324216]\n",
      "epoch:36 step:34407 [D loss: 0.665382, acc.: 59.38%] [G loss: 1.395010]\n",
      "epoch:36 step:34408 [D loss: 0.489238, acc.: 78.12%] [G loss: 1.789769]\n",
      "epoch:36 step:34409 [D loss: 0.479236, acc.: 81.25%] [G loss: 1.500766]\n",
      "epoch:36 step:34410 [D loss: 0.519145, acc.: 75.00%] [G loss: 1.264872]\n",
      "epoch:36 step:34411 [D loss: 0.427047, acc.: 81.25%] [G loss: 1.635287]\n",
      "epoch:36 step:34412 [D loss: 0.637912, acc.: 62.50%] [G loss: 1.733404]\n",
      "epoch:36 step:34413 [D loss: 0.319273, acc.: 89.06%] [G loss: 1.659897]\n",
      "epoch:36 step:34414 [D loss: 0.443674, acc.: 78.91%] [G loss: 1.407820]\n",
      "epoch:36 step:34415 [D loss: 0.764056, acc.: 53.12%] [G loss: 1.263533]\n",
      "epoch:36 step:34416 [D loss: 0.471621, acc.: 74.22%] [G loss: 1.331664]\n",
      "epoch:36 step:34417 [D loss: 0.566012, acc.: 68.75%] [G loss: 1.610542]\n",
      "epoch:36 step:34418 [D loss: 0.469178, acc.: 77.34%] [G loss: 1.450110]\n",
      "epoch:36 step:34419 [D loss: 0.605819, acc.: 62.50%] [G loss: 1.539495]\n",
      "epoch:36 step:34420 [D loss: 0.421328, acc.: 81.25%] [G loss: 2.365763]\n",
      "epoch:36 step:34421 [D loss: 0.538709, acc.: 71.88%] [G loss: 1.826422]\n",
      "epoch:36 step:34422 [D loss: 0.393749, acc.: 84.38%] [G loss: 1.995662]\n",
      "epoch:36 step:34423 [D loss: 0.394605, acc.: 85.94%] [G loss: 1.572857]\n",
      "epoch:36 step:34424 [D loss: 0.406842, acc.: 82.03%] [G loss: 1.497615]\n",
      "epoch:36 step:34425 [D loss: 0.414145, acc.: 80.47%] [G loss: 1.106683]\n",
      "epoch:36 step:34426 [D loss: 0.579205, acc.: 68.75%] [G loss: 1.150973]\n",
      "epoch:36 step:34427 [D loss: 0.293890, acc.: 90.62%] [G loss: 1.776240]\n",
      "epoch:36 step:34428 [D loss: 0.697392, acc.: 61.72%] [G loss: 1.716363]\n",
      "epoch:36 step:34429 [D loss: 0.497081, acc.: 73.44%] [G loss: 1.592330]\n",
      "epoch:36 step:34430 [D loss: 0.562835, acc.: 71.88%] [G loss: 1.734330]\n",
      "epoch:36 step:34431 [D loss: 0.708852, acc.: 59.38%] [G loss: 1.375398]\n",
      "epoch:36 step:34432 [D loss: 0.554910, acc.: 72.66%] [G loss: 1.899257]\n",
      "epoch:36 step:34433 [D loss: 0.556122, acc.: 74.22%] [G loss: 1.102004]\n",
      "epoch:36 step:34434 [D loss: 0.538817, acc.: 73.44%] [G loss: 1.381392]\n",
      "epoch:36 step:34435 [D loss: 0.729948, acc.: 59.38%] [G loss: 1.455039]\n",
      "epoch:36 step:34436 [D loss: 0.706885, acc.: 57.03%] [G loss: 1.290407]\n",
      "epoch:36 step:34437 [D loss: 0.441470, acc.: 79.69%] [G loss: 1.536299]\n",
      "epoch:36 step:34438 [D loss: 0.409351, acc.: 82.03%] [G loss: 1.505688]\n",
      "epoch:36 step:34439 [D loss: 0.464779, acc.: 79.69%] [G loss: 1.946858]\n",
      "epoch:36 step:34440 [D loss: 0.526100, acc.: 74.22%] [G loss: 1.295049]\n",
      "epoch:36 step:34441 [D loss: 0.724716, acc.: 65.62%] [G loss: 1.454508]\n",
      "epoch:36 step:34442 [D loss: 0.593537, acc.: 68.75%] [G loss: 1.282538]\n",
      "epoch:36 step:34443 [D loss: 0.624881, acc.: 65.62%] [G loss: 1.878397]\n",
      "epoch:36 step:34444 [D loss: 0.618343, acc.: 67.19%] [G loss: 1.424322]\n",
      "epoch:36 step:34445 [D loss: 0.590670, acc.: 69.53%] [G loss: 1.426387]\n",
      "epoch:36 step:34446 [D loss: 0.593727, acc.: 66.41%] [G loss: 1.608749]\n",
      "epoch:36 step:34447 [D loss: 0.669267, acc.: 59.38%] [G loss: 1.369157]\n",
      "epoch:36 step:34448 [D loss: 0.386508, acc.: 82.03%] [G loss: 2.014634]\n",
      "epoch:36 step:34449 [D loss: 0.834052, acc.: 47.66%] [G loss: 1.288144]\n",
      "epoch:36 step:34450 [D loss: 0.340366, acc.: 86.72%] [G loss: 1.289434]\n",
      "epoch:36 step:34451 [D loss: 0.698236, acc.: 61.72%] [G loss: 1.279251]\n",
      "epoch:36 step:34452 [D loss: 0.461168, acc.: 78.91%] [G loss: 1.897775]\n",
      "epoch:36 step:34453 [D loss: 0.580611, acc.: 67.19%] [G loss: 1.462062]\n",
      "epoch:36 step:34454 [D loss: 0.537011, acc.: 71.88%] [G loss: 0.978728]\n",
      "epoch:36 step:34455 [D loss: 0.565279, acc.: 68.75%] [G loss: 1.887434]\n",
      "epoch:36 step:34456 [D loss: 0.427950, acc.: 81.25%] [G loss: 1.645333]\n",
      "epoch:36 step:34457 [D loss: 0.357418, acc.: 84.38%] [G loss: 1.306940]\n",
      "epoch:36 step:34458 [D loss: 0.648620, acc.: 64.84%] [G loss: 1.487364]\n",
      "epoch:36 step:34459 [D loss: 0.427595, acc.: 78.91%] [G loss: 1.590419]\n",
      "epoch:36 step:34460 [D loss: 0.437943, acc.: 80.47%] [G loss: 1.857924]\n",
      "epoch:36 step:34461 [D loss: 0.641217, acc.: 70.31%] [G loss: 1.138186]\n",
      "epoch:36 step:34462 [D loss: 0.660132, acc.: 63.28%] [G loss: 1.569943]\n",
      "epoch:36 step:34463 [D loss: 0.621445, acc.: 67.19%] [G loss: 1.113515]\n",
      "epoch:36 step:34464 [D loss: 0.460140, acc.: 77.34%] [G loss: 1.341308]\n",
      "epoch:36 step:34465 [D loss: 0.459475, acc.: 77.34%] [G loss: 1.813658]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:36 step:34466 [D loss: 0.494587, acc.: 76.56%] [G loss: 1.316241]\n",
      "epoch:36 step:34467 [D loss: 0.626550, acc.: 67.97%] [G loss: 1.505344]\n",
      "epoch:36 step:34468 [D loss: 0.543292, acc.: 68.75%] [G loss: 1.474472]\n",
      "epoch:36 step:34469 [D loss: 0.392601, acc.: 89.84%] [G loss: 1.490416]\n",
      "epoch:36 step:34470 [D loss: 0.604814, acc.: 65.62%] [G loss: 1.045760]\n",
      "epoch:36 step:34471 [D loss: 0.507397, acc.: 76.56%] [G loss: 1.011761]\n",
      "epoch:36 step:34472 [D loss: 0.477278, acc.: 78.91%] [G loss: 1.589810]\n",
      "epoch:36 step:34473 [D loss: 0.519233, acc.: 72.66%] [G loss: 1.025610]\n",
      "epoch:36 step:34474 [D loss: 0.608698, acc.: 67.19%] [G loss: 1.682327]\n",
      "epoch:36 step:34475 [D loss: 0.558161, acc.: 71.09%] [G loss: 2.101117]\n",
      "epoch:36 step:34476 [D loss: 0.635085, acc.: 61.72%] [G loss: 1.529273]\n",
      "epoch:36 step:34477 [D loss: 0.511872, acc.: 75.78%] [G loss: 1.353818]\n",
      "epoch:36 step:34478 [D loss: 0.678409, acc.: 67.97%] [G loss: 1.125868]\n",
      "epoch:36 step:34479 [D loss: 0.389841, acc.: 89.06%] [G loss: 1.825417]\n",
      "epoch:36 step:34480 [D loss: 0.515194, acc.: 71.88%] [G loss: 1.990555]\n",
      "epoch:36 step:34481 [D loss: 0.593043, acc.: 70.31%] [G loss: 2.118287]\n",
      "epoch:36 step:34482 [D loss: 0.650286, acc.: 67.97%] [G loss: 1.468372]\n",
      "epoch:36 step:34483 [D loss: 0.573982, acc.: 69.53%] [G loss: 1.623914]\n",
      "epoch:36 step:34484 [D loss: 0.562156, acc.: 71.88%] [G loss: 1.641019]\n",
      "epoch:36 step:34485 [D loss: 0.497257, acc.: 77.34%] [G loss: 1.438414]\n",
      "epoch:36 step:34486 [D loss: 0.619293, acc.: 66.41%] [G loss: 1.389641]\n",
      "epoch:36 step:34487 [D loss: 0.369966, acc.: 86.72%] [G loss: 2.030817]\n",
      "epoch:36 step:34488 [D loss: 0.449111, acc.: 81.25%] [G loss: 1.627669]\n",
      "epoch:36 step:34489 [D loss: 0.554606, acc.: 71.09%] [G loss: 1.821644]\n",
      "epoch:36 step:34490 [D loss: 0.921603, acc.: 42.19%] [G loss: 1.404369]\n",
      "epoch:36 step:34491 [D loss: 0.549664, acc.: 76.56%] [G loss: 1.537205]\n",
      "epoch:36 step:34492 [D loss: 0.549078, acc.: 72.66%] [G loss: 1.586897]\n",
      "epoch:36 step:34493 [D loss: 0.635265, acc.: 63.28%] [G loss: 1.523793]\n",
      "epoch:36 step:34494 [D loss: 0.681930, acc.: 59.38%] [G loss: 1.443303]\n",
      "epoch:36 step:34495 [D loss: 0.474247, acc.: 76.56%] [G loss: 1.288492]\n",
      "epoch:36 step:34496 [D loss: 0.500614, acc.: 73.44%] [G loss: 1.764648]\n",
      "epoch:36 step:34497 [D loss: 0.421637, acc.: 82.03%] [G loss: 1.196198]\n",
      "epoch:36 step:34498 [D loss: 0.406962, acc.: 84.38%] [G loss: 1.281032]\n",
      "epoch:36 step:34499 [D loss: 0.476466, acc.: 75.78%] [G loss: 1.126598]\n",
      "epoch:36 step:34500 [D loss: 0.719226, acc.: 53.12%] [G loss: 1.140437]\n",
      "epoch:36 step:34501 [D loss: 0.324236, acc.: 89.06%] [G loss: 1.321960]\n",
      "epoch:36 step:34502 [D loss: 0.829230, acc.: 49.22%] [G loss: 1.598529]\n",
      "epoch:36 step:34503 [D loss: 0.297483, acc.: 88.28%] [G loss: 1.662952]\n",
      "epoch:36 step:34504 [D loss: 0.509319, acc.: 75.00%] [G loss: 1.684254]\n",
      "epoch:36 step:34505 [D loss: 0.586038, acc.: 70.31%] [G loss: 1.351292]\n",
      "epoch:36 step:34506 [D loss: 0.619411, acc.: 64.84%] [G loss: 1.415484]\n",
      "epoch:36 step:34507 [D loss: 0.446893, acc.: 82.81%] [G loss: 1.173962]\n",
      "epoch:36 step:34508 [D loss: 0.594399, acc.: 68.75%] [G loss: 1.054090]\n",
      "epoch:36 step:34509 [D loss: 0.606822, acc.: 67.97%] [G loss: 1.538426]\n",
      "epoch:36 step:34510 [D loss: 0.523966, acc.: 75.78%] [G loss: 1.553309]\n",
      "epoch:36 step:34511 [D loss: 0.584603, acc.: 68.75%] [G loss: 1.565632]\n",
      "epoch:36 step:34512 [D loss: 0.459267, acc.: 81.25%] [G loss: 1.779146]\n",
      "epoch:36 step:34513 [D loss: 0.616329, acc.: 65.62%] [G loss: 1.440501]\n",
      "epoch:36 step:34514 [D loss: 0.352917, acc.: 88.28%] [G loss: 1.646761]\n",
      "epoch:36 step:34515 [D loss: 0.325004, acc.: 89.84%] [G loss: 2.251453]\n",
      "epoch:36 step:34516 [D loss: 0.412192, acc.: 82.81%] [G loss: 1.877509]\n",
      "epoch:36 step:34517 [D loss: 0.250660, acc.: 94.53%] [G loss: 1.768612]\n",
      "epoch:36 step:34518 [D loss: 0.640143, acc.: 65.62%] [G loss: 1.241899]\n",
      "epoch:36 step:34519 [D loss: 0.600335, acc.: 63.28%] [G loss: 1.542483]\n",
      "epoch:36 step:34520 [D loss: 0.435390, acc.: 82.03%] [G loss: 1.796119]\n",
      "epoch:36 step:34521 [D loss: 0.421669, acc.: 79.69%] [G loss: 1.432909]\n",
      "epoch:36 step:34522 [D loss: 0.560929, acc.: 71.88%] [G loss: 1.767820]\n",
      "epoch:36 step:34523 [D loss: 0.348493, acc.: 90.62%] [G loss: 2.572282]\n",
      "epoch:36 step:34524 [D loss: 0.531714, acc.: 71.88%] [G loss: 1.566029]\n",
      "epoch:36 step:34525 [D loss: 0.359433, acc.: 85.16%] [G loss: 2.365330]\n",
      "epoch:36 step:34526 [D loss: 0.440001, acc.: 79.69%] [G loss: 2.220313]\n",
      "epoch:36 step:34527 [D loss: 0.458004, acc.: 80.47%] [G loss: 1.760909]\n",
      "epoch:36 step:34528 [D loss: 0.547752, acc.: 74.22%] [G loss: 1.924523]\n",
      "epoch:36 step:34529 [D loss: 0.352374, acc.: 89.84%] [G loss: 1.378477]\n",
      "epoch:36 step:34530 [D loss: 0.624724, acc.: 70.31%] [G loss: 1.585311]\n",
      "epoch:36 step:34531 [D loss: 0.601824, acc.: 67.19%] [G loss: 1.634326]\n",
      "epoch:36 step:34532 [D loss: 0.707459, acc.: 57.03%] [G loss: 1.087103]\n",
      "epoch:36 step:34533 [D loss: 0.503052, acc.: 77.34%] [G loss: 1.120848]\n",
      "epoch:36 step:34534 [D loss: 0.458116, acc.: 79.69%] [G loss: 1.864476]\n",
      "epoch:36 step:34535 [D loss: 0.684092, acc.: 58.59%] [G loss: 0.874276]\n",
      "epoch:36 step:34536 [D loss: 0.485473, acc.: 71.88%] [G loss: 1.422903]\n",
      "epoch:36 step:34537 [D loss: 0.377661, acc.: 85.94%] [G loss: 1.412863]\n",
      "epoch:36 step:34538 [D loss: 0.387500, acc.: 83.59%] [G loss: 2.420218]\n",
      "epoch:36 step:34539 [D loss: 0.701181, acc.: 58.59%] [G loss: 1.687572]\n",
      "epoch:36 step:34540 [D loss: 0.275406, acc.: 92.97%] [G loss: 2.226769]\n",
      "epoch:36 step:34541 [D loss: 0.385484, acc.: 85.16%] [G loss: 1.822633]\n",
      "epoch:36 step:34542 [D loss: 0.274590, acc.: 95.31%] [G loss: 2.068424]\n",
      "epoch:36 step:34543 [D loss: 0.526162, acc.: 72.66%] [G loss: 1.387649]\n",
      "epoch:36 step:34544 [D loss: 0.499288, acc.: 74.22%] [G loss: 1.164852]\n",
      "epoch:36 step:34545 [D loss: 0.373338, acc.: 86.72%] [G loss: 1.859952]\n",
      "epoch:36 step:34546 [D loss: 0.455871, acc.: 76.56%] [G loss: 1.475606]\n",
      "epoch:36 step:34547 [D loss: 0.713038, acc.: 57.81%] [G loss: 1.862605]\n",
      "epoch:36 step:34548 [D loss: 0.474513, acc.: 82.81%] [G loss: 2.174729]\n",
      "epoch:36 step:34549 [D loss: 0.845985, acc.: 51.56%] [G loss: 1.248829]\n",
      "epoch:36 step:34550 [D loss: 0.518684, acc.: 73.44%] [G loss: 1.658826]\n",
      "epoch:36 step:34551 [D loss: 0.498476, acc.: 76.56%] [G loss: 1.190123]\n",
      "epoch:36 step:34552 [D loss: 0.612364, acc.: 67.97%] [G loss: 1.608223]\n",
      "epoch:36 step:34553 [D loss: 0.631877, acc.: 68.75%] [G loss: 1.459683]\n",
      "epoch:36 step:34554 [D loss: 0.499634, acc.: 76.56%] [G loss: 1.347548]\n",
      "epoch:36 step:34555 [D loss: 0.430051, acc.: 80.47%] [G loss: 1.744248]\n",
      "epoch:36 step:34556 [D loss: 0.544562, acc.: 71.09%] [G loss: 1.466550]\n",
      "epoch:36 step:34557 [D loss: 0.433047, acc.: 84.38%] [G loss: 1.460881]\n",
      "epoch:36 step:34558 [D loss: 0.431041, acc.: 85.16%] [G loss: 1.505557]\n",
      "epoch:36 step:34559 [D loss: 0.537749, acc.: 71.09%] [G loss: 1.993763]\n",
      "epoch:36 step:34560 [D loss: 0.693697, acc.: 58.59%] [G loss: 0.873294]\n",
      "epoch:36 step:34561 [D loss: 0.547983, acc.: 71.88%] [G loss: 1.700189]\n",
      "epoch:36 step:34562 [D loss: 0.674123, acc.: 64.06%] [G loss: 1.067642]\n",
      "epoch:36 step:34563 [D loss: 0.425036, acc.: 82.81%] [G loss: 1.120477]\n",
      "epoch:36 step:34564 [D loss: 0.575472, acc.: 71.09%] [G loss: 0.860691]\n",
      "epoch:36 step:34565 [D loss: 0.466660, acc.: 82.81%] [G loss: 1.713755]\n",
      "epoch:36 step:34566 [D loss: 0.766911, acc.: 50.00%] [G loss: 1.342553]\n",
      "epoch:36 step:34567 [D loss: 0.593970, acc.: 68.75%] [G loss: 1.348966]\n",
      "epoch:36 step:34568 [D loss: 0.586294, acc.: 68.75%] [G loss: 0.986266]\n",
      "epoch:36 step:34569 [D loss: 0.666940, acc.: 64.06%] [G loss: 0.966702]\n",
      "epoch:36 step:34570 [D loss: 0.306712, acc.: 90.62%] [G loss: 1.908191]\n",
      "epoch:36 step:34571 [D loss: 0.370207, acc.: 86.72%] [G loss: 1.824127]\n",
      "epoch:36 step:34572 [D loss: 0.507337, acc.: 79.69%] [G loss: 2.076371]\n",
      "epoch:36 step:34573 [D loss: 0.580717, acc.: 69.53%] [G loss: 1.874370]\n",
      "epoch:36 step:34574 [D loss: 0.717277, acc.: 61.72%] [G loss: 1.304891]\n",
      "epoch:36 step:34575 [D loss: 0.418627, acc.: 83.59%] [G loss: 1.452933]\n",
      "epoch:36 step:34576 [D loss: 0.466018, acc.: 78.12%] [G loss: 1.751385]\n",
      "epoch:36 step:34577 [D loss: 0.541160, acc.: 73.44%] [G loss: 1.508510]\n",
      "epoch:36 step:34578 [D loss: 0.440439, acc.: 83.59%] [G loss: 1.695059]\n",
      "epoch:36 step:34579 [D loss: 0.575829, acc.: 71.88%] [G loss: 2.108960]\n",
      "epoch:36 step:34580 [D loss: 0.593745, acc.: 69.53%] [G loss: 1.843222]\n",
      "epoch:36 step:34581 [D loss: 0.336053, acc.: 85.16%] [G loss: 1.991377]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:36 step:34582 [D loss: 0.419337, acc.: 83.59%] [G loss: 0.958968]\n",
      "epoch:36 step:34583 [D loss: 0.599402, acc.: 69.53%] [G loss: 1.728871]\n",
      "epoch:36 step:34584 [D loss: 0.375027, acc.: 86.72%] [G loss: 1.226136]\n",
      "epoch:36 step:34585 [D loss: 0.673936, acc.: 64.06%] [G loss: 1.720422]\n",
      "epoch:36 step:34586 [D loss: 0.521099, acc.: 75.78%] [G loss: 1.755860]\n",
      "epoch:36 step:34587 [D loss: 0.730809, acc.: 58.59%] [G loss: 1.755924]\n",
      "epoch:36 step:34588 [D loss: 0.396436, acc.: 86.72%] [G loss: 1.647065]\n",
      "epoch:36 step:34589 [D loss: 0.489539, acc.: 73.44%] [G loss: 1.426091]\n",
      "epoch:36 step:34590 [D loss: 0.596324, acc.: 70.31%] [G loss: 1.276936]\n",
      "epoch:36 step:34591 [D loss: 0.608963, acc.: 64.06%] [G loss: 1.081291]\n",
      "epoch:36 step:34592 [D loss: 0.381281, acc.: 85.16%] [G loss: 1.481174]\n",
      "epoch:36 step:34593 [D loss: 0.471047, acc.: 77.34%] [G loss: 1.236160]\n",
      "epoch:36 step:34594 [D loss: 0.551511, acc.: 70.31%] [G loss: 2.166095]\n",
      "epoch:36 step:34595 [D loss: 0.745454, acc.: 60.94%] [G loss: 1.400781]\n",
      "epoch:36 step:34596 [D loss: 0.631120, acc.: 71.88%] [G loss: 1.676421]\n",
      "epoch:36 step:34597 [D loss: 0.589868, acc.: 64.84%] [G loss: 1.349228]\n",
      "epoch:36 step:34598 [D loss: 0.529976, acc.: 74.22%] [G loss: 0.977949]\n",
      "epoch:36 step:34599 [D loss: 0.544752, acc.: 72.66%] [G loss: 1.329215]\n",
      "epoch:36 step:34600 [D loss: 0.432829, acc.: 82.03%] [G loss: 1.774957]\n",
      "epoch:36 step:34601 [D loss: 0.506580, acc.: 75.78%] [G loss: 1.726020]\n",
      "epoch:36 step:34602 [D loss: 0.432506, acc.: 78.12%] [G loss: 1.753068]\n",
      "epoch:36 step:34603 [D loss: 0.468314, acc.: 76.56%] [G loss: 1.370487]\n",
      "epoch:36 step:34604 [D loss: 0.718083, acc.: 57.81%] [G loss: 1.855711]\n",
      "epoch:36 step:34605 [D loss: 0.331808, acc.: 88.28%] [G loss: 1.828589]\n",
      "epoch:36 step:34606 [D loss: 0.545717, acc.: 72.66%] [G loss: 1.424091]\n",
      "epoch:36 step:34607 [D loss: 0.514876, acc.: 75.78%] [G loss: 1.313864]\n",
      "epoch:36 step:34608 [D loss: 0.784928, acc.: 54.69%] [G loss: 1.162457]\n",
      "epoch:36 step:34609 [D loss: 0.563734, acc.: 71.09%] [G loss: 1.112039]\n",
      "epoch:36 step:34610 [D loss: 0.444303, acc.: 82.03%] [G loss: 1.463470]\n",
      "epoch:36 step:34611 [D loss: 0.521193, acc.: 71.88%] [G loss: 1.652533]\n",
      "epoch:36 step:34612 [D loss: 0.524235, acc.: 74.22%] [G loss: 2.011017]\n",
      "epoch:36 step:34613 [D loss: 0.642022, acc.: 65.62%] [G loss: 1.784858]\n",
      "epoch:36 step:34614 [D loss: 0.501424, acc.: 77.34%] [G loss: 1.403632]\n",
      "epoch:36 step:34615 [D loss: 0.422162, acc.: 80.47%] [G loss: 1.486974]\n",
      "epoch:36 step:34616 [D loss: 0.449023, acc.: 80.47%] [G loss: 1.446962]\n",
      "epoch:36 step:34617 [D loss: 0.570034, acc.: 68.75%] [G loss: 1.232288]\n",
      "epoch:36 step:34618 [D loss: 0.418184, acc.: 81.25%] [G loss: 1.967060]\n",
      "epoch:36 step:34619 [D loss: 0.444589, acc.: 81.25%] [G loss: 1.034765]\n",
      "epoch:36 step:34620 [D loss: 0.614941, acc.: 64.06%] [G loss: 1.330228]\n",
      "epoch:36 step:34621 [D loss: 0.548721, acc.: 74.22%] [G loss: 1.621057]\n",
      "epoch:36 step:34622 [D loss: 0.418218, acc.: 82.03%] [G loss: 1.456687]\n",
      "epoch:36 step:34623 [D loss: 0.539141, acc.: 72.66%] [G loss: 1.202145]\n",
      "epoch:36 step:34624 [D loss: 0.697703, acc.: 59.38%] [G loss: 1.216216]\n",
      "epoch:36 step:34625 [D loss: 0.504125, acc.: 75.78%] [G loss: 1.816704]\n",
      "epoch:36 step:34626 [D loss: 0.560497, acc.: 67.97%] [G loss: 1.679234]\n",
      "epoch:36 step:34627 [D loss: 0.350351, acc.: 89.06%] [G loss: 2.205421]\n",
      "epoch:36 step:34628 [D loss: 0.566845, acc.: 68.75%] [G loss: 1.303329]\n",
      "epoch:36 step:34629 [D loss: 0.610802, acc.: 66.41%] [G loss: 1.516383]\n",
      "epoch:36 step:34630 [D loss: 0.626962, acc.: 65.62%] [G loss: 0.932253]\n",
      "epoch:36 step:34631 [D loss: 0.461152, acc.: 77.34%] [G loss: 1.523697]\n",
      "epoch:36 step:34632 [D loss: 0.453616, acc.: 82.03%] [G loss: 1.606222]\n",
      "epoch:36 step:34633 [D loss: 0.706772, acc.: 57.03%] [G loss: 2.021389]\n",
      "epoch:36 step:34634 [D loss: 0.444445, acc.: 84.38%] [G loss: 1.143449]\n",
      "epoch:36 step:34635 [D loss: 0.439247, acc.: 87.50%] [G loss: 1.786703]\n",
      "epoch:36 step:34636 [D loss: 0.597666, acc.: 68.75%] [G loss: 1.315163]\n",
      "epoch:36 step:34637 [D loss: 0.477414, acc.: 75.78%] [G loss: 1.345636]\n",
      "epoch:36 step:34638 [D loss: 0.560181, acc.: 75.00%] [G loss: 1.450135]\n",
      "epoch:36 step:34639 [D loss: 0.502694, acc.: 76.56%] [G loss: 2.014747]\n",
      "epoch:36 step:34640 [D loss: 0.502864, acc.: 77.34%] [G loss: 1.934464]\n",
      "epoch:36 step:34641 [D loss: 0.572389, acc.: 69.53%] [G loss: 1.595154]\n",
      "epoch:36 step:34642 [D loss: 0.538451, acc.: 73.44%] [G loss: 1.756742]\n",
      "epoch:36 step:34643 [D loss: 0.437548, acc.: 82.81%] [G loss: 1.695021]\n",
      "epoch:36 step:34644 [D loss: 0.647555, acc.: 64.84%] [G loss: 1.236924]\n",
      "epoch:36 step:34645 [D loss: 0.397199, acc.: 87.50%] [G loss: 1.759710]\n",
      "epoch:36 step:34646 [D loss: 0.659791, acc.: 62.50%] [G loss: 1.459491]\n",
      "epoch:36 step:34647 [D loss: 0.622472, acc.: 67.19%] [G loss: 1.574666]\n",
      "epoch:36 step:34648 [D loss: 0.375084, acc.: 85.16%] [G loss: 1.363023]\n",
      "epoch:36 step:34649 [D loss: 0.762859, acc.: 53.91%] [G loss: 1.159632]\n",
      "epoch:36 step:34650 [D loss: 0.458601, acc.: 80.47%] [G loss: 1.288597]\n",
      "epoch:36 step:34651 [D loss: 0.661564, acc.: 63.28%] [G loss: 1.503542]\n",
      "epoch:36 step:34652 [D loss: 0.670924, acc.: 64.84%] [G loss: 2.064827]\n",
      "epoch:36 step:34653 [D loss: 0.437837, acc.: 83.59%] [G loss: 1.725005]\n",
      "epoch:36 step:34654 [D loss: 0.646625, acc.: 72.66%] [G loss: 1.464069]\n",
      "epoch:36 step:34655 [D loss: 0.356916, acc.: 88.28%] [G loss: 1.218074]\n",
      "epoch:36 step:34656 [D loss: 0.536270, acc.: 73.44%] [G loss: 1.733782]\n",
      "epoch:36 step:34657 [D loss: 0.426530, acc.: 79.69%] [G loss: 1.622888]\n",
      "epoch:36 step:34658 [D loss: 0.597734, acc.: 67.97%] [G loss: 1.131288]\n",
      "epoch:36 step:34659 [D loss: 0.591630, acc.: 67.19%] [G loss: 1.684913]\n",
      "epoch:36 step:34660 [D loss: 0.485644, acc.: 77.34%] [G loss: 1.352085]\n",
      "epoch:36 step:34661 [D loss: 0.611279, acc.: 64.06%] [G loss: 2.075113]\n",
      "epoch:36 step:34662 [D loss: 0.495911, acc.: 78.12%] [G loss: 1.562774]\n",
      "epoch:36 step:34663 [D loss: 0.444936, acc.: 81.25%] [G loss: 1.609288]\n",
      "epoch:36 step:34664 [D loss: 0.476115, acc.: 77.34%] [G loss: 1.986812]\n",
      "epoch:36 step:34665 [D loss: 0.666764, acc.: 62.50%] [G loss: 0.834942]\n",
      "epoch:36 step:34666 [D loss: 0.523317, acc.: 74.22%] [G loss: 1.117932]\n",
      "epoch:36 step:34667 [D loss: 0.432968, acc.: 82.03%] [G loss: 1.430074]\n",
      "epoch:36 step:34668 [D loss: 0.596215, acc.: 67.19%] [G loss: 1.803512]\n",
      "epoch:36 step:34669 [D loss: 0.463040, acc.: 80.47%] [G loss: 1.331035]\n",
      "epoch:37 step:34670 [D loss: 0.560758, acc.: 71.88%] [G loss: 1.333335]\n",
      "epoch:37 step:34671 [D loss: 0.559565, acc.: 69.53%] [G loss: 1.376860]\n",
      "epoch:37 step:34672 [D loss: 0.541618, acc.: 75.78%] [G loss: 1.374684]\n",
      "epoch:37 step:34673 [D loss: 0.500340, acc.: 77.34%] [G loss: 1.446986]\n",
      "epoch:37 step:34674 [D loss: 0.496229, acc.: 75.00%] [G loss: 1.573999]\n",
      "epoch:37 step:34675 [D loss: 0.518617, acc.: 73.44%] [G loss: 1.647547]\n",
      "epoch:37 step:34676 [D loss: 0.645390, acc.: 66.41%] [G loss: 1.497055]\n",
      "epoch:37 step:34677 [D loss: 0.387880, acc.: 85.94%] [G loss: 1.487256]\n",
      "epoch:37 step:34678 [D loss: 0.735901, acc.: 56.25%] [G loss: 1.343405]\n",
      "epoch:37 step:34679 [D loss: 0.498306, acc.: 74.22%] [G loss: 1.371994]\n",
      "epoch:37 step:34680 [D loss: 0.798547, acc.: 56.25%] [G loss: 1.230674]\n",
      "epoch:37 step:34681 [D loss: 0.493261, acc.: 75.00%] [G loss: 1.024184]\n",
      "epoch:37 step:34682 [D loss: 0.538690, acc.: 75.00%] [G loss: 1.860295]\n",
      "epoch:37 step:34683 [D loss: 0.450641, acc.: 82.03%] [G loss: 1.287147]\n",
      "epoch:37 step:34684 [D loss: 0.444187, acc.: 80.47%] [G loss: 1.618523]\n",
      "epoch:37 step:34685 [D loss: 0.839606, acc.: 52.34%] [G loss: 1.322560]\n",
      "epoch:37 step:34686 [D loss: 0.461183, acc.: 78.91%] [G loss: 1.894798]\n",
      "epoch:37 step:34687 [D loss: 0.665294, acc.: 62.50%] [G loss: 1.686338]\n",
      "epoch:37 step:34688 [D loss: 0.714622, acc.: 60.16%] [G loss: 1.514741]\n",
      "epoch:37 step:34689 [D loss: 0.327754, acc.: 85.94%] [G loss: 1.654582]\n",
      "epoch:37 step:34690 [D loss: 0.588043, acc.: 67.19%] [G loss: 1.771194]\n",
      "epoch:37 step:34691 [D loss: 0.392399, acc.: 82.03%] [G loss: 1.498630]\n",
      "epoch:37 step:34692 [D loss: 0.477175, acc.: 77.34%] [G loss: 1.869819]\n",
      "epoch:37 step:34693 [D loss: 0.423022, acc.: 85.94%] [G loss: 1.529827]\n",
      "epoch:37 step:34694 [D loss: 0.743473, acc.: 56.25%] [G loss: 1.491220]\n",
      "epoch:37 step:34695 [D loss: 0.692985, acc.: 64.84%] [G loss: 1.162496]\n",
      "epoch:37 step:34696 [D loss: 0.427278, acc.: 80.47%] [G loss: 1.679603]\n",
      "epoch:37 step:34697 [D loss: 0.423677, acc.: 82.03%] [G loss: 1.388959]\n",
      "epoch:37 step:34698 [D loss: 0.568116, acc.: 67.97%] [G loss: 1.322351]\n",
      "epoch:37 step:34699 [D loss: 0.406893, acc.: 82.81%] [G loss: 1.664717]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:37 step:34700 [D loss: 0.410800, acc.: 82.81%] [G loss: 1.617702]\n",
      "epoch:37 step:34701 [D loss: 0.479279, acc.: 78.12%] [G loss: 1.341795]\n",
      "epoch:37 step:34702 [D loss: 0.462391, acc.: 80.47%] [G loss: 1.508567]\n",
      "epoch:37 step:34703 [D loss: 0.338616, acc.: 87.50%] [G loss: 1.998164]\n",
      "epoch:37 step:34704 [D loss: 0.542528, acc.: 71.88%] [G loss: 1.451810]\n",
      "epoch:37 step:34705 [D loss: 0.444776, acc.: 80.47%] [G loss: 1.183230]\n",
      "epoch:37 step:34706 [D loss: 0.359363, acc.: 85.94%] [G loss: 2.242351]\n",
      "epoch:37 step:34707 [D loss: 0.602878, acc.: 68.75%] [G loss: 1.636787]\n",
      "epoch:37 step:34708 [D loss: 0.865574, acc.: 42.97%] [G loss: 1.460144]\n",
      "epoch:37 step:34709 [D loss: 0.455203, acc.: 78.91%] [G loss: 1.390094]\n",
      "epoch:37 step:34710 [D loss: 0.620756, acc.: 60.94%] [G loss: 1.600216]\n",
      "epoch:37 step:34711 [D loss: 0.611582, acc.: 68.75%] [G loss: 1.539877]\n",
      "epoch:37 step:34712 [D loss: 0.736648, acc.: 60.16%] [G loss: 1.227717]\n",
      "epoch:37 step:34713 [D loss: 0.657541, acc.: 64.84%] [G loss: 1.512568]\n",
      "epoch:37 step:34714 [D loss: 0.622344, acc.: 64.06%] [G loss: 1.330143]\n",
      "epoch:37 step:34715 [D loss: 0.567928, acc.: 68.75%] [G loss: 1.272444]\n",
      "epoch:37 step:34716 [D loss: 0.556503, acc.: 69.53%] [G loss: 1.275844]\n",
      "epoch:37 step:34717 [D loss: 0.449420, acc.: 82.81%] [G loss: 1.763625]\n",
      "epoch:37 step:34718 [D loss: 0.368712, acc.: 86.72%] [G loss: 1.873638]\n",
      "epoch:37 step:34719 [D loss: 0.337327, acc.: 86.72%] [G loss: 2.282393]\n",
      "epoch:37 step:34720 [D loss: 0.610605, acc.: 68.75%] [G loss: 1.709926]\n",
      "epoch:37 step:34721 [D loss: 0.636531, acc.: 62.50%] [G loss: 1.148632]\n",
      "epoch:37 step:34722 [D loss: 0.504081, acc.: 73.44%] [G loss: 1.379778]\n",
      "epoch:37 step:34723 [D loss: 0.474575, acc.: 75.78%] [G loss: 1.793974]\n",
      "epoch:37 step:34724 [D loss: 0.510689, acc.: 71.88%] [G loss: 1.490278]\n",
      "epoch:37 step:34725 [D loss: 0.595635, acc.: 70.31%] [G loss: 1.065502]\n",
      "epoch:37 step:34726 [D loss: 0.394843, acc.: 84.38%] [G loss: 1.341332]\n",
      "epoch:37 step:34727 [D loss: 0.392871, acc.: 83.59%] [G loss: 1.765461]\n",
      "epoch:37 step:34728 [D loss: 0.586533, acc.: 67.97%] [G loss: 1.250948]\n",
      "epoch:37 step:34729 [D loss: 0.492832, acc.: 78.12%] [G loss: 1.128542]\n",
      "epoch:37 step:34730 [D loss: 0.510343, acc.: 70.31%] [G loss: 1.056266]\n",
      "epoch:37 step:34731 [D loss: 0.557167, acc.: 69.53%] [G loss: 1.412481]\n",
      "epoch:37 step:34732 [D loss: 0.416649, acc.: 82.03%] [G loss: 1.854815]\n",
      "epoch:37 step:34733 [D loss: 0.519572, acc.: 77.34%] [G loss: 1.435780]\n",
      "epoch:37 step:34734 [D loss: 0.632661, acc.: 68.75%] [G loss: 1.524599]\n",
      "epoch:37 step:34735 [D loss: 0.409218, acc.: 88.28%] [G loss: 1.577904]\n",
      "epoch:37 step:34736 [D loss: 0.552817, acc.: 71.88%] [G loss: 1.654877]\n",
      "epoch:37 step:34737 [D loss: 0.676749, acc.: 60.94%] [G loss: 1.628358]\n",
      "epoch:37 step:34738 [D loss: 0.482798, acc.: 75.00%] [G loss: 1.481979]\n",
      "epoch:37 step:34739 [D loss: 0.744818, acc.: 60.16%] [G loss: 1.625715]\n",
      "epoch:37 step:34740 [D loss: 0.487137, acc.: 77.34%] [G loss: 1.978781]\n",
      "epoch:37 step:34741 [D loss: 0.534108, acc.: 75.78%] [G loss: 1.319142]\n",
      "epoch:37 step:34742 [D loss: 0.451180, acc.: 75.78%] [G loss: 1.899047]\n",
      "epoch:37 step:34743 [D loss: 0.581614, acc.: 70.31%] [G loss: 1.242737]\n",
      "epoch:37 step:34744 [D loss: 0.795197, acc.: 51.56%] [G loss: 1.979271]\n",
      "epoch:37 step:34745 [D loss: 0.645893, acc.: 67.19%] [G loss: 1.226461]\n",
      "epoch:37 step:34746 [D loss: 0.591418, acc.: 64.84%] [G loss: 1.583638]\n",
      "epoch:37 step:34747 [D loss: 0.534010, acc.: 71.88%] [G loss: 1.573478]\n",
      "epoch:37 step:34748 [D loss: 0.744160, acc.: 54.69%] [G loss: 1.539284]\n",
      "epoch:37 step:34749 [D loss: 0.468542, acc.: 79.69%] [G loss: 1.716143]\n",
      "epoch:37 step:34750 [D loss: 0.615781, acc.: 66.41%] [G loss: 1.731774]\n",
      "epoch:37 step:34751 [D loss: 0.544882, acc.: 69.53%] [G loss: 1.632895]\n",
      "epoch:37 step:34752 [D loss: 0.740102, acc.: 56.25%] [G loss: 1.519670]\n",
      "epoch:37 step:34753 [D loss: 0.660895, acc.: 64.84%] [G loss: 1.496161]\n",
      "epoch:37 step:34754 [D loss: 0.369874, acc.: 88.28%] [G loss: 1.433855]\n",
      "epoch:37 step:34755 [D loss: 0.715707, acc.: 60.94%] [G loss: 1.273566]\n",
      "epoch:37 step:34756 [D loss: 0.372881, acc.: 85.94%] [G loss: 1.456620]\n",
      "epoch:37 step:34757 [D loss: 0.651450, acc.: 62.50%] [G loss: 1.460477]\n",
      "epoch:37 step:34758 [D loss: 0.503256, acc.: 77.34%] [G loss: 1.136635]\n",
      "epoch:37 step:34759 [D loss: 0.643548, acc.: 64.06%] [G loss: 1.174983]\n",
      "epoch:37 step:34760 [D loss: 0.443018, acc.: 79.69%] [G loss: 1.666425]\n",
      "epoch:37 step:34761 [D loss: 0.455436, acc.: 78.91%] [G loss: 1.598617]\n",
      "epoch:37 step:34762 [D loss: 0.476559, acc.: 75.78%] [G loss: 1.730145]\n",
      "epoch:37 step:34763 [D loss: 0.474439, acc.: 78.12%] [G loss: 1.283587]\n",
      "epoch:37 step:34764 [D loss: 0.582710, acc.: 71.09%] [G loss: 1.581033]\n",
      "epoch:37 step:34765 [D loss: 0.458582, acc.: 82.03%] [G loss: 1.442888]\n",
      "epoch:37 step:34766 [D loss: 0.608067, acc.: 67.19%] [G loss: 1.691095]\n",
      "epoch:37 step:34767 [D loss: 0.318758, acc.: 86.72%] [G loss: 2.011493]\n",
      "epoch:37 step:34768 [D loss: 0.639736, acc.: 67.97%] [G loss: 1.734112]\n",
      "epoch:37 step:34769 [D loss: 0.403820, acc.: 79.69%] [G loss: 1.578369]\n",
      "epoch:37 step:34770 [D loss: 0.612492, acc.: 70.31%] [G loss: 1.782938]\n",
      "epoch:37 step:34771 [D loss: 0.477841, acc.: 78.12%] [G loss: 1.737613]\n",
      "epoch:37 step:34772 [D loss: 0.390918, acc.: 84.38%] [G loss: 2.134876]\n",
      "epoch:37 step:34773 [D loss: 0.556163, acc.: 71.09%] [G loss: 1.224723]\n",
      "epoch:37 step:34774 [D loss: 0.359946, acc.: 87.50%] [G loss: 1.821971]\n",
      "epoch:37 step:34775 [D loss: 0.560225, acc.: 70.31%] [G loss: 1.304586]\n",
      "epoch:37 step:34776 [D loss: 0.605693, acc.: 67.19%] [G loss: 1.459219]\n",
      "epoch:37 step:34777 [D loss: 0.466950, acc.: 78.12%] [G loss: 1.351935]\n",
      "epoch:37 step:34778 [D loss: 0.403427, acc.: 83.59%] [G loss: 1.659472]\n",
      "epoch:37 step:34779 [D loss: 0.805425, acc.: 54.69%] [G loss: 1.635966]\n",
      "epoch:37 step:34780 [D loss: 0.472236, acc.: 73.44%] [G loss: 2.006748]\n",
      "epoch:37 step:34781 [D loss: 0.490418, acc.: 77.34%] [G loss: 2.162554]\n",
      "epoch:37 step:34782 [D loss: 0.379921, acc.: 82.03%] [G loss: 1.049852]\n",
      "epoch:37 step:34783 [D loss: 0.313372, acc.: 87.50%] [G loss: 1.399157]\n",
      "epoch:37 step:34784 [D loss: 0.305747, acc.: 86.72%] [G loss: 1.552864]\n",
      "epoch:37 step:34785 [D loss: 0.467533, acc.: 76.56%] [G loss: 1.640398]\n",
      "epoch:37 step:34786 [D loss: 0.427977, acc.: 82.81%] [G loss: 1.391973]\n",
      "epoch:37 step:34787 [D loss: 0.757178, acc.: 50.00%] [G loss: 1.102835]\n",
      "epoch:37 step:34788 [D loss: 0.311339, acc.: 87.50%] [G loss: 1.416637]\n",
      "epoch:37 step:34789 [D loss: 0.527969, acc.: 74.22%] [G loss: 1.828045]\n",
      "epoch:37 step:34790 [D loss: 0.580589, acc.: 67.97%] [G loss: 1.416590]\n",
      "epoch:37 step:34791 [D loss: 0.492084, acc.: 78.91%] [G loss: 1.001368]\n",
      "epoch:37 step:34792 [D loss: 0.443164, acc.: 82.03%] [G loss: 1.505764]\n",
      "epoch:37 step:34793 [D loss: 0.691200, acc.: 61.72%] [G loss: 1.281392]\n",
      "epoch:37 step:34794 [D loss: 0.398060, acc.: 82.81%] [G loss: 1.836255]\n",
      "epoch:37 step:34795 [D loss: 0.505727, acc.: 78.91%] [G loss: 1.419120]\n",
      "epoch:37 step:34796 [D loss: 0.418253, acc.: 83.59%] [G loss: 1.386259]\n",
      "epoch:37 step:34797 [D loss: 0.538812, acc.: 70.31%] [G loss: 1.334089]\n",
      "epoch:37 step:34798 [D loss: 0.372691, acc.: 85.94%] [G loss: 1.726045]\n",
      "epoch:37 step:34799 [D loss: 0.444519, acc.: 78.91%] [G loss: 1.824045]\n",
      "epoch:37 step:34800 [D loss: 0.390135, acc.: 83.59%] [G loss: 1.672603]\n",
      "epoch:37 step:34801 [D loss: 0.583568, acc.: 69.53%] [G loss: 1.392072]\n",
      "epoch:37 step:34802 [D loss: 0.424279, acc.: 79.69%] [G loss: 1.154469]\n",
      "epoch:37 step:34803 [D loss: 0.538717, acc.: 71.09%] [G loss: 1.529298]\n",
      "epoch:37 step:34804 [D loss: 0.390762, acc.: 84.38%] [G loss: 1.659638]\n",
      "epoch:37 step:34805 [D loss: 0.615231, acc.: 67.19%] [G loss: 1.376589]\n",
      "epoch:37 step:34806 [D loss: 0.776524, acc.: 50.78%] [G loss: 1.003408]\n",
      "epoch:37 step:34807 [D loss: 0.467243, acc.: 77.34%] [G loss: 1.941377]\n",
      "epoch:37 step:34808 [D loss: 0.626038, acc.: 67.97%] [G loss: 1.452239]\n",
      "epoch:37 step:34809 [D loss: 0.613685, acc.: 66.41%] [G loss: 1.245752]\n",
      "epoch:37 step:34810 [D loss: 0.748273, acc.: 57.03%] [G loss: 1.474661]\n",
      "epoch:37 step:34811 [D loss: 0.512965, acc.: 73.44%] [G loss: 1.796731]\n",
      "epoch:37 step:34812 [D loss: 0.538948, acc.: 75.78%] [G loss: 1.810073]\n",
      "epoch:37 step:34813 [D loss: 0.419036, acc.: 83.59%] [G loss: 0.880544]\n",
      "epoch:37 step:34814 [D loss: 0.419011, acc.: 82.81%] [G loss: 1.495640]\n",
      "epoch:37 step:34815 [D loss: 0.322292, acc.: 89.84%] [G loss: 1.719156]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:37 step:34816 [D loss: 0.564797, acc.: 68.75%] [G loss: 1.783603]\n",
      "epoch:37 step:34817 [D loss: 0.349809, acc.: 89.06%] [G loss: 1.719295]\n",
      "epoch:37 step:34818 [D loss: 0.546418, acc.: 69.53%] [G loss: 1.455695]\n",
      "epoch:37 step:34819 [D loss: 0.554223, acc.: 74.22%] [G loss: 1.804726]\n",
      "epoch:37 step:34820 [D loss: 0.629179, acc.: 64.84%] [G loss: 1.604666]\n",
      "epoch:37 step:34821 [D loss: 0.687187, acc.: 59.38%] [G loss: 1.521386]\n",
      "epoch:37 step:34822 [D loss: 0.490928, acc.: 75.00%] [G loss: 1.302563]\n",
      "epoch:37 step:34823 [D loss: 0.443303, acc.: 81.25%] [G loss: 1.329698]\n",
      "epoch:37 step:34824 [D loss: 0.471062, acc.: 77.34%] [G loss: 1.191637]\n",
      "epoch:37 step:34825 [D loss: 0.402700, acc.: 81.25%] [G loss: 1.116321]\n",
      "epoch:37 step:34826 [D loss: 0.503690, acc.: 75.00%] [G loss: 1.541105]\n",
      "epoch:37 step:34827 [D loss: 0.388337, acc.: 86.72%] [G loss: 1.483302]\n",
      "epoch:37 step:34828 [D loss: 0.518174, acc.: 72.66%] [G loss: 1.263868]\n",
      "epoch:37 step:34829 [D loss: 0.756884, acc.: 52.34%] [G loss: 1.360683]\n",
      "epoch:37 step:34830 [D loss: 0.499456, acc.: 73.44%] [G loss: 1.038898]\n",
      "epoch:37 step:34831 [D loss: 0.624318, acc.: 69.53%] [G loss: 1.676498]\n",
      "epoch:37 step:34832 [D loss: 0.421209, acc.: 82.03%] [G loss: 1.844022]\n",
      "epoch:37 step:34833 [D loss: 0.504504, acc.: 77.34%] [G loss: 1.626807]\n",
      "epoch:37 step:34834 [D loss: 0.691654, acc.: 61.72%] [G loss: 1.600510]\n",
      "epoch:37 step:34835 [D loss: 0.718800, acc.: 57.81%] [G loss: 1.432720]\n",
      "epoch:37 step:34836 [D loss: 0.446180, acc.: 75.00%] [G loss: 1.890392]\n",
      "epoch:37 step:34837 [D loss: 0.595460, acc.: 67.19%] [G loss: 1.359791]\n",
      "epoch:37 step:34838 [D loss: 0.649245, acc.: 64.84%] [G loss: 1.201226]\n",
      "epoch:37 step:34839 [D loss: 0.443943, acc.: 82.03%] [G loss: 1.864901]\n",
      "epoch:37 step:34840 [D loss: 0.608453, acc.: 67.19%] [G loss: 1.390598]\n",
      "epoch:37 step:34841 [D loss: 0.396899, acc.: 84.38%] [G loss: 2.273221]\n",
      "epoch:37 step:34842 [D loss: 0.486136, acc.: 77.34%] [G loss: 1.224432]\n",
      "epoch:37 step:34843 [D loss: 0.472105, acc.: 81.25%] [G loss: 2.230844]\n",
      "epoch:37 step:34844 [D loss: 0.502831, acc.: 73.44%] [G loss: 1.854925]\n",
      "epoch:37 step:34845 [D loss: 0.627126, acc.: 67.19%] [G loss: 1.579462]\n",
      "epoch:37 step:34846 [D loss: 0.502321, acc.: 75.78%] [G loss: 1.295605]\n",
      "epoch:37 step:34847 [D loss: 0.488295, acc.: 78.91%] [G loss: 1.358575]\n",
      "epoch:37 step:34848 [D loss: 0.465336, acc.: 74.22%] [G loss: 1.480186]\n",
      "epoch:37 step:34849 [D loss: 0.439842, acc.: 79.69%] [G loss: 1.643925]\n",
      "epoch:37 step:34850 [D loss: 0.529242, acc.: 75.00%] [G loss: 1.202467]\n",
      "epoch:37 step:34851 [D loss: 0.431965, acc.: 82.03%] [G loss: 2.117054]\n",
      "epoch:37 step:34852 [D loss: 0.598494, acc.: 64.84%] [G loss: 1.051166]\n",
      "epoch:37 step:34853 [D loss: 0.612387, acc.: 71.09%] [G loss: 1.813585]\n",
      "epoch:37 step:34854 [D loss: 0.567975, acc.: 71.88%] [G loss: 1.623122]\n",
      "epoch:37 step:34855 [D loss: 0.553982, acc.: 72.66%] [G loss: 0.908358]\n",
      "epoch:37 step:34856 [D loss: 0.413017, acc.: 82.81%] [G loss: 1.644487]\n",
      "epoch:37 step:34857 [D loss: 0.463211, acc.: 82.03%] [G loss: 1.706289]\n",
      "epoch:37 step:34858 [D loss: 0.560036, acc.: 71.88%] [G loss: 1.350811]\n",
      "epoch:37 step:34859 [D loss: 0.573978, acc.: 69.53%] [G loss: 1.211663]\n",
      "epoch:37 step:34860 [D loss: 0.799759, acc.: 53.12%] [G loss: 1.590238]\n",
      "epoch:37 step:34861 [D loss: 0.629637, acc.: 61.72%] [G loss: 1.153438]\n",
      "epoch:37 step:34862 [D loss: 0.452843, acc.: 76.56%] [G loss: 1.650241]\n",
      "epoch:37 step:34863 [D loss: 0.454528, acc.: 74.22%] [G loss: 1.521191]\n",
      "epoch:37 step:34864 [D loss: 0.559112, acc.: 73.44%] [G loss: 2.024529]\n",
      "epoch:37 step:34865 [D loss: 0.493917, acc.: 79.69%] [G loss: 1.805830]\n",
      "epoch:37 step:34866 [D loss: 0.461455, acc.: 82.81%] [G loss: 1.136251]\n",
      "epoch:37 step:34867 [D loss: 0.873161, acc.: 48.44%] [G loss: 1.289438]\n",
      "epoch:37 step:34868 [D loss: 0.617131, acc.: 69.53%] [G loss: 1.157386]\n",
      "epoch:37 step:34869 [D loss: 0.575580, acc.: 68.75%] [G loss: 1.845002]\n",
      "epoch:37 step:34870 [D loss: 0.377933, acc.: 88.28%] [G loss: 1.867120]\n",
      "epoch:37 step:34871 [D loss: 0.501657, acc.: 75.00%] [G loss: 0.962287]\n",
      "epoch:37 step:34872 [D loss: 0.396960, acc.: 85.16%] [G loss: 1.868148]\n",
      "epoch:37 step:34873 [D loss: 0.438153, acc.: 75.78%] [G loss: 1.512874]\n",
      "epoch:37 step:34874 [D loss: 0.585263, acc.: 67.97%] [G loss: 1.328279]\n",
      "epoch:37 step:34875 [D loss: 0.568947, acc.: 71.88%] [G loss: 1.716159]\n",
      "epoch:37 step:34876 [D loss: 0.847399, acc.: 50.00%] [G loss: 1.416548]\n",
      "epoch:37 step:34877 [D loss: 0.618218, acc.: 70.31%] [G loss: 1.582824]\n",
      "epoch:37 step:34878 [D loss: 0.568455, acc.: 74.22%] [G loss: 1.433223]\n",
      "epoch:37 step:34879 [D loss: 0.524316, acc.: 73.44%] [G loss: 1.345528]\n",
      "epoch:37 step:34880 [D loss: 0.438597, acc.: 82.03%] [G loss: 1.743154]\n",
      "epoch:37 step:34881 [D loss: 0.664287, acc.: 61.72%] [G loss: 1.264682]\n",
      "epoch:37 step:34882 [D loss: 0.595171, acc.: 67.97%] [G loss: 1.866351]\n",
      "epoch:37 step:34883 [D loss: 0.699239, acc.: 62.50%] [G loss: 1.764567]\n",
      "epoch:37 step:34884 [D loss: 0.459994, acc.: 78.91%] [G loss: 2.342946]\n",
      "epoch:37 step:34885 [D loss: 0.555199, acc.: 71.09%] [G loss: 0.896039]\n",
      "epoch:37 step:34886 [D loss: 0.484190, acc.: 76.56%] [G loss: 1.299375]\n",
      "epoch:37 step:34887 [D loss: 0.628640, acc.: 62.50%] [G loss: 1.198126]\n",
      "epoch:37 step:34888 [D loss: 0.579475, acc.: 66.41%] [G loss: 1.490144]\n",
      "epoch:37 step:34889 [D loss: 0.523314, acc.: 72.66%] [G loss: 1.475594]\n",
      "epoch:37 step:34890 [D loss: 0.444099, acc.: 81.25%] [G loss: 1.935762]\n",
      "epoch:37 step:34891 [D loss: 0.794458, acc.: 57.03%] [G loss: 1.365770]\n",
      "epoch:37 step:34892 [D loss: 0.480376, acc.: 78.12%] [G loss: 1.424582]\n",
      "epoch:37 step:34893 [D loss: 0.421310, acc.: 81.25%] [G loss: 2.227095]\n",
      "epoch:37 step:34894 [D loss: 0.553973, acc.: 69.53%] [G loss: 1.394065]\n",
      "epoch:37 step:34895 [D loss: 0.555002, acc.: 69.53%] [G loss: 1.464029]\n",
      "epoch:37 step:34896 [D loss: 0.436624, acc.: 78.12%] [G loss: 2.135751]\n",
      "epoch:37 step:34897 [D loss: 0.477157, acc.: 76.56%] [G loss: 2.022830]\n",
      "epoch:37 step:34898 [D loss: 0.368532, acc.: 83.59%] [G loss: 1.734428]\n",
      "epoch:37 step:34899 [D loss: 0.433947, acc.: 79.69%] [G loss: 1.984628]\n",
      "epoch:37 step:34900 [D loss: 0.527174, acc.: 76.56%] [G loss: 1.622878]\n",
      "epoch:37 step:34901 [D loss: 0.589699, acc.: 66.41%] [G loss: 1.004941]\n",
      "epoch:37 step:34902 [D loss: 0.624335, acc.: 69.53%] [G loss: 2.055552]\n",
      "epoch:37 step:34903 [D loss: 0.677187, acc.: 57.81%] [G loss: 1.504865]\n",
      "epoch:37 step:34904 [D loss: 0.403178, acc.: 83.59%] [G loss: 1.772518]\n",
      "epoch:37 step:34905 [D loss: 0.654428, acc.: 60.16%] [G loss: 1.747149]\n",
      "epoch:37 step:34906 [D loss: 0.629847, acc.: 72.66%] [G loss: 1.644404]\n",
      "epoch:37 step:34907 [D loss: 0.600257, acc.: 75.00%] [G loss: 1.440541]\n",
      "epoch:37 step:34908 [D loss: 0.348147, acc.: 86.72%] [G loss: 1.162384]\n",
      "epoch:37 step:34909 [D loss: 0.649387, acc.: 60.16%] [G loss: 1.678031]\n",
      "epoch:37 step:34910 [D loss: 0.394291, acc.: 83.59%] [G loss: 1.224671]\n",
      "epoch:37 step:34911 [D loss: 0.553902, acc.: 75.00%] [G loss: 1.568528]\n",
      "epoch:37 step:34912 [D loss: 0.472032, acc.: 80.47%] [G loss: 1.548086]\n",
      "epoch:37 step:34913 [D loss: 0.593183, acc.: 66.41%] [G loss: 1.427335]\n",
      "epoch:37 step:34914 [D loss: 0.518949, acc.: 76.56%] [G loss: 1.204925]\n",
      "epoch:37 step:34915 [D loss: 0.605169, acc.: 67.19%] [G loss: 1.546243]\n",
      "epoch:37 step:34916 [D loss: 0.600482, acc.: 67.97%] [G loss: 1.255464]\n",
      "epoch:37 step:34917 [D loss: 0.602739, acc.: 68.75%] [G loss: 1.341469]\n",
      "epoch:37 step:34918 [D loss: 0.479229, acc.: 78.91%] [G loss: 1.503744]\n",
      "epoch:37 step:34919 [D loss: 0.572419, acc.: 67.97%] [G loss: 1.595790]\n",
      "epoch:37 step:34920 [D loss: 0.586977, acc.: 67.19%] [G loss: 1.043711]\n",
      "epoch:37 step:34921 [D loss: 0.492267, acc.: 75.78%] [G loss: 1.497571]\n",
      "epoch:37 step:34922 [D loss: 0.462067, acc.: 77.34%] [G loss: 1.438048]\n",
      "epoch:37 step:34923 [D loss: 0.507305, acc.: 76.56%] [G loss: 1.432715]\n",
      "epoch:37 step:34924 [D loss: 0.894072, acc.: 45.31%] [G loss: 1.616633]\n",
      "epoch:37 step:34925 [D loss: 0.610357, acc.: 66.41%] [G loss: 1.737086]\n",
      "epoch:37 step:34926 [D loss: 0.589406, acc.: 75.00%] [G loss: 1.538619]\n",
      "epoch:37 step:34927 [D loss: 0.516742, acc.: 73.44%] [G loss: 1.416012]\n",
      "epoch:37 step:34928 [D loss: 0.491526, acc.: 78.91%] [G loss: 1.400180]\n",
      "epoch:37 step:34929 [D loss: 0.625615, acc.: 66.41%] [G loss: 1.074862]\n",
      "epoch:37 step:34930 [D loss: 0.585953, acc.: 67.19%] [G loss: 1.367849]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:37 step:34931 [D loss: 0.491738, acc.: 78.12%] [G loss: 1.824715]\n",
      "epoch:37 step:34932 [D loss: 0.550721, acc.: 70.31%] [G loss: 2.024718]\n",
      "epoch:37 step:34933 [D loss: 0.394306, acc.: 85.94%] [G loss: 1.523362]\n",
      "epoch:37 step:34934 [D loss: 0.493749, acc.: 70.31%] [G loss: 1.637476]\n",
      "epoch:37 step:34935 [D loss: 0.471895, acc.: 78.91%] [G loss: 2.017069]\n",
      "epoch:37 step:34936 [D loss: 0.596167, acc.: 67.97%] [G loss: 1.349155]\n",
      "epoch:37 step:34937 [D loss: 0.527733, acc.: 75.00%] [G loss: 1.919162]\n",
      "epoch:37 step:34938 [D loss: 0.363156, acc.: 83.59%] [G loss: 1.675885]\n",
      "epoch:37 step:34939 [D loss: 0.629433, acc.: 63.28%] [G loss: 1.731870]\n",
      "epoch:37 step:34940 [D loss: 0.441523, acc.: 76.56%] [G loss: 2.384974]\n",
      "epoch:37 step:34941 [D loss: 0.571967, acc.: 72.66%] [G loss: 1.441041]\n",
      "epoch:37 step:34942 [D loss: 0.658673, acc.: 63.28%] [G loss: 1.513474]\n",
      "epoch:37 step:34943 [D loss: 0.444396, acc.: 82.03%] [G loss: 1.564805]\n",
      "epoch:37 step:34944 [D loss: 0.558635, acc.: 75.00%] [G loss: 1.004638]\n",
      "epoch:37 step:34945 [D loss: 0.732456, acc.: 54.69%] [G loss: 1.089568]\n",
      "epoch:37 step:34946 [D loss: 0.545124, acc.: 72.66%] [G loss: 1.608803]\n",
      "epoch:37 step:34947 [D loss: 0.606590, acc.: 64.84%] [G loss: 1.755748]\n",
      "epoch:37 step:34948 [D loss: 0.441133, acc.: 81.25%] [G loss: 1.753491]\n",
      "epoch:37 step:34949 [D loss: 0.676548, acc.: 57.03%] [G loss: 1.295368]\n",
      "epoch:37 step:34950 [D loss: 0.435097, acc.: 82.03%] [G loss: 1.729687]\n",
      "epoch:37 step:34951 [D loss: 0.538362, acc.: 71.09%] [G loss: 1.272939]\n",
      "epoch:37 step:34952 [D loss: 0.427824, acc.: 82.03%] [G loss: 1.338306]\n",
      "epoch:37 step:34953 [D loss: 0.726613, acc.: 58.59%] [G loss: 1.799656]\n",
      "epoch:37 step:34954 [D loss: 0.551231, acc.: 68.75%] [G loss: 1.456195]\n",
      "epoch:37 step:34955 [D loss: 0.523807, acc.: 74.22%] [G loss: 1.569739]\n",
      "epoch:37 step:34956 [D loss: 0.372492, acc.: 89.06%] [G loss: 1.868310]\n",
      "epoch:37 step:34957 [D loss: 0.541068, acc.: 72.66%] [G loss: 2.092039]\n",
      "epoch:37 step:34958 [D loss: 0.487964, acc.: 76.56%] [G loss: 1.408558]\n",
      "epoch:37 step:34959 [D loss: 0.530506, acc.: 78.91%] [G loss: 1.439040]\n",
      "epoch:37 step:34960 [D loss: 0.761706, acc.: 57.81%] [G loss: 0.717604]\n",
      "epoch:37 step:34961 [D loss: 0.435275, acc.: 80.47%] [G loss: 1.403735]\n",
      "epoch:37 step:34962 [D loss: 0.644311, acc.: 60.16%] [G loss: 1.637183]\n",
      "epoch:37 step:34963 [D loss: 0.389180, acc.: 84.38%] [G loss: 1.620224]\n",
      "epoch:37 step:34964 [D loss: 0.484288, acc.: 76.56%] [G loss: 1.649287]\n",
      "epoch:37 step:34965 [D loss: 0.447106, acc.: 79.69%] [G loss: 2.277406]\n",
      "epoch:37 step:34966 [D loss: 0.559861, acc.: 71.09%] [G loss: 1.141456]\n",
      "epoch:37 step:34967 [D loss: 0.712918, acc.: 57.03%] [G loss: 1.625673]\n",
      "epoch:37 step:34968 [D loss: 0.595430, acc.: 66.41%] [G loss: 1.655860]\n",
      "epoch:37 step:34969 [D loss: 0.629632, acc.: 65.62%] [G loss: 1.114998]\n",
      "epoch:37 step:34970 [D loss: 0.697643, acc.: 57.81%] [G loss: 1.526615]\n",
      "epoch:37 step:34971 [D loss: 0.594368, acc.: 67.97%] [G loss: 1.653748]\n",
      "epoch:37 step:34972 [D loss: 0.728341, acc.: 60.16%] [G loss: 1.047534]\n",
      "epoch:37 step:34973 [D loss: 0.603013, acc.: 65.62%] [G loss: 1.716208]\n",
      "epoch:37 step:34974 [D loss: 0.430024, acc.: 78.12%] [G loss: 1.235699]\n",
      "epoch:37 step:34975 [D loss: 0.585632, acc.: 67.97%] [G loss: 1.008702]\n",
      "epoch:37 step:34976 [D loss: 0.596997, acc.: 68.75%] [G loss: 1.733688]\n",
      "epoch:37 step:34977 [D loss: 0.545138, acc.: 73.44%] [G loss: 1.478533]\n",
      "epoch:37 step:34978 [D loss: 0.384920, acc.: 83.59%] [G loss: 1.696005]\n",
      "epoch:37 step:34979 [D loss: 0.467979, acc.: 77.34%] [G loss: 1.725982]\n",
      "epoch:37 step:34980 [D loss: 0.533675, acc.: 73.44%] [G loss: 1.508882]\n",
      "epoch:37 step:34981 [D loss: 0.520024, acc.: 73.44%] [G loss: 1.301465]\n",
      "epoch:37 step:34982 [D loss: 0.436927, acc.: 78.12%] [G loss: 1.700922]\n",
      "epoch:37 step:34983 [D loss: 0.482896, acc.: 75.00%] [G loss: 1.320819]\n",
      "epoch:37 step:34984 [D loss: 0.418218, acc.: 82.81%] [G loss: 1.335089]\n",
      "epoch:37 step:34985 [D loss: 0.799912, acc.: 46.09%] [G loss: 1.045111]\n",
      "epoch:37 step:34986 [D loss: 0.496156, acc.: 78.91%] [G loss: 1.397746]\n",
      "epoch:37 step:34987 [D loss: 0.771605, acc.: 49.22%] [G loss: 1.241255]\n",
      "epoch:37 step:34988 [D loss: 0.793216, acc.: 52.34%] [G loss: 1.084379]\n",
      "epoch:37 step:34989 [D loss: 0.418276, acc.: 84.38%] [G loss: 1.546295]\n",
      "epoch:37 step:34990 [D loss: 0.613309, acc.: 67.97%] [G loss: 2.193650]\n",
      "epoch:37 step:34991 [D loss: 0.638632, acc.: 67.19%] [G loss: 1.248708]\n",
      "epoch:37 step:34992 [D loss: 0.654901, acc.: 66.41%] [G loss: 1.426524]\n",
      "epoch:37 step:34993 [D loss: 0.461356, acc.: 77.34%] [G loss: 1.562900]\n",
      "epoch:37 step:34994 [D loss: 0.481023, acc.: 78.12%] [G loss: 1.664029]\n",
      "epoch:37 step:34995 [D loss: 0.396933, acc.: 84.38%] [G loss: 1.664939]\n",
      "epoch:37 step:34996 [D loss: 0.398235, acc.: 82.81%] [G loss: 1.774003]\n",
      "epoch:37 step:34997 [D loss: 0.476466, acc.: 81.25%] [G loss: 1.221587]\n",
      "epoch:37 step:34998 [D loss: 0.569956, acc.: 70.31%] [G loss: 1.577093]\n",
      "epoch:37 step:34999 [D loss: 0.526653, acc.: 71.88%] [G loss: 1.843776]\n",
      "epoch:37 step:35000 [D loss: 0.413870, acc.: 82.81%] [G loss: 1.371957]\n",
      "epoch:37 step:35001 [D loss: 0.454220, acc.: 78.12%] [G loss: 1.162506]\n",
      "epoch:37 step:35002 [D loss: 0.491414, acc.: 79.69%] [G loss: 1.898578]\n",
      "epoch:37 step:35003 [D loss: 0.453994, acc.: 80.47%] [G loss: 1.416537]\n",
      "epoch:37 step:35004 [D loss: 0.796507, acc.: 56.25%] [G loss: 0.916726]\n",
      "epoch:37 step:35005 [D loss: 0.489589, acc.: 75.00%] [G loss: 1.905672]\n",
      "epoch:37 step:35006 [D loss: 0.532332, acc.: 74.22%] [G loss: 1.031320]\n",
      "epoch:37 step:35007 [D loss: 0.420520, acc.: 79.69%] [G loss: 1.691817]\n",
      "epoch:37 step:35008 [D loss: 0.522777, acc.: 74.22%] [G loss: 2.125482]\n",
      "epoch:37 step:35009 [D loss: 0.649151, acc.: 67.19%] [G loss: 1.543751]\n",
      "epoch:37 step:35010 [D loss: 0.491734, acc.: 81.25%] [G loss: 1.602283]\n",
      "epoch:37 step:35011 [D loss: 0.653634, acc.: 67.19%] [G loss: 1.289869]\n",
      "epoch:37 step:35012 [D loss: 0.587601, acc.: 63.28%] [G loss: 0.986858]\n",
      "epoch:37 step:35013 [D loss: 0.412180, acc.: 84.38%] [G loss: 1.527000]\n",
      "epoch:37 step:35014 [D loss: 0.526476, acc.: 75.00%] [G loss: 1.371496]\n",
      "epoch:37 step:35015 [D loss: 0.513733, acc.: 74.22%] [G loss: 1.549242]\n",
      "epoch:37 step:35016 [D loss: 0.562309, acc.: 72.66%] [G loss: 1.684847]\n",
      "epoch:37 step:35017 [D loss: 0.447109, acc.: 80.47%] [G loss: 1.370152]\n",
      "epoch:37 step:35018 [D loss: 0.447440, acc.: 80.47%] [G loss: 1.548601]\n",
      "epoch:37 step:35019 [D loss: 0.535214, acc.: 72.66%] [G loss: 1.550277]\n",
      "epoch:37 step:35020 [D loss: 0.658840, acc.: 67.19%] [G loss: 1.885801]\n",
      "epoch:37 step:35021 [D loss: 0.508391, acc.: 72.66%] [G loss: 1.322019]\n",
      "epoch:37 step:35022 [D loss: 0.499774, acc.: 75.00%] [G loss: 1.214181]\n",
      "epoch:37 step:35023 [D loss: 0.553489, acc.: 75.78%] [G loss: 1.341936]\n",
      "epoch:37 step:35024 [D loss: 0.435745, acc.: 82.03%] [G loss: 1.874016]\n",
      "epoch:37 step:35025 [D loss: 0.492477, acc.: 78.91%] [G loss: 1.698555]\n",
      "epoch:37 step:35026 [D loss: 0.466271, acc.: 79.69%] [G loss: 1.861258]\n",
      "epoch:37 step:35027 [D loss: 0.503223, acc.: 75.00%] [G loss: 1.802596]\n",
      "epoch:37 step:35028 [D loss: 0.565951, acc.: 67.97%] [G loss: 1.450905]\n",
      "epoch:37 step:35029 [D loss: 0.390086, acc.: 86.72%] [G loss: 1.506265]\n",
      "epoch:37 step:35030 [D loss: 0.512048, acc.: 75.00%] [G loss: 1.227205]\n",
      "epoch:37 step:35031 [D loss: 0.429545, acc.: 83.59%] [G loss: 1.215354]\n",
      "epoch:37 step:35032 [D loss: 0.389579, acc.: 86.72%] [G loss: 1.676576]\n",
      "epoch:37 step:35033 [D loss: 0.611509, acc.: 64.06%] [G loss: 1.797548]\n",
      "epoch:37 step:35034 [D loss: 0.532010, acc.: 71.88%] [G loss: 1.566638]\n",
      "epoch:37 step:35035 [D loss: 0.415078, acc.: 82.81%] [G loss: 1.384464]\n",
      "epoch:37 step:35036 [D loss: 0.534443, acc.: 72.66%] [G loss: 1.753871]\n",
      "epoch:37 step:35037 [D loss: 0.536919, acc.: 70.31%] [G loss: 1.630955]\n",
      "epoch:37 step:35038 [D loss: 0.530728, acc.: 72.66%] [G loss: 1.622696]\n",
      "epoch:37 step:35039 [D loss: 0.514256, acc.: 78.12%] [G loss: 1.601333]\n",
      "epoch:37 step:35040 [D loss: 0.350714, acc.: 88.28%] [G loss: 1.722469]\n",
      "epoch:37 step:35041 [D loss: 0.468422, acc.: 78.91%] [G loss: 1.732998]\n",
      "epoch:37 step:35042 [D loss: 0.484747, acc.: 81.25%] [G loss: 1.887688]\n",
      "epoch:37 step:35043 [D loss: 0.871476, acc.: 50.78%] [G loss: 2.054398]\n",
      "epoch:37 step:35044 [D loss: 0.606428, acc.: 68.75%] [G loss: 1.890794]\n",
      "epoch:37 step:35045 [D loss: 0.798988, acc.: 53.12%] [G loss: 0.994293]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:37 step:35046 [D loss: 0.362588, acc.: 85.16%] [G loss: 1.157073]\n",
      "epoch:37 step:35047 [D loss: 0.453149, acc.: 78.12%] [G loss: 1.788350]\n",
      "epoch:37 step:35048 [D loss: 0.398262, acc.: 86.72%] [G loss: 1.306670]\n",
      "epoch:37 step:35049 [D loss: 0.506317, acc.: 75.00%] [G loss: 2.064641]\n",
      "epoch:37 step:35050 [D loss: 0.499794, acc.: 74.22%] [G loss: 1.856298]\n",
      "epoch:37 step:35051 [D loss: 0.605551, acc.: 64.84%] [G loss: 1.687012]\n",
      "epoch:37 step:35052 [D loss: 0.437957, acc.: 78.91%] [G loss: 1.100999]\n",
      "epoch:37 step:35053 [D loss: 0.618893, acc.: 60.94%] [G loss: 1.124494]\n",
      "epoch:37 step:35054 [D loss: 0.438513, acc.: 82.03%] [G loss: 1.148686]\n",
      "epoch:37 step:35055 [D loss: 0.506818, acc.: 73.44%] [G loss: 1.650321]\n",
      "epoch:37 step:35056 [D loss: 0.402754, acc.: 82.81%] [G loss: 1.194442]\n",
      "epoch:37 step:35057 [D loss: 0.462085, acc.: 74.22%] [G loss: 1.426738]\n",
      "epoch:37 step:35058 [D loss: 0.458149, acc.: 77.34%] [G loss: 1.600415]\n",
      "epoch:37 step:35059 [D loss: 0.519356, acc.: 72.66%] [G loss: 1.585589]\n",
      "epoch:37 step:35060 [D loss: 0.573574, acc.: 70.31%] [G loss: 1.550248]\n",
      "epoch:37 step:35061 [D loss: 0.633316, acc.: 64.06%] [G loss: 1.109351]\n",
      "epoch:37 step:35062 [D loss: 0.678225, acc.: 60.16%] [G loss: 1.315482]\n",
      "epoch:37 step:35063 [D loss: 0.638345, acc.: 64.84%] [G loss: 1.378282]\n",
      "epoch:37 step:35064 [D loss: 0.491412, acc.: 80.47%] [G loss: 2.080812]\n",
      "epoch:37 step:35065 [D loss: 0.670354, acc.: 63.28%] [G loss: 1.969808]\n",
      "epoch:37 step:35066 [D loss: 0.522411, acc.: 68.75%] [G loss: 1.352386]\n",
      "epoch:37 step:35067 [D loss: 0.519381, acc.: 73.44%] [G loss: 1.477656]\n",
      "epoch:37 step:35068 [D loss: 0.452968, acc.: 84.38%] [G loss: 1.292291]\n",
      "epoch:37 step:35069 [D loss: 0.651271, acc.: 61.72%] [G loss: 1.624460]\n",
      "epoch:37 step:35070 [D loss: 0.456427, acc.: 77.34%] [G loss: 1.853456]\n",
      "epoch:37 step:35071 [D loss: 0.328927, acc.: 89.06%] [G loss: 1.926106]\n",
      "epoch:37 step:35072 [D loss: 0.498661, acc.: 76.56%] [G loss: 1.667878]\n",
      "epoch:37 step:35073 [D loss: 0.722825, acc.: 63.28%] [G loss: 1.321206]\n",
      "epoch:37 step:35074 [D loss: 0.343561, acc.: 89.06%] [G loss: 1.848006]\n",
      "epoch:37 step:35075 [D loss: 0.663743, acc.: 64.84%] [G loss: 1.993902]\n",
      "epoch:37 step:35076 [D loss: 0.548016, acc.: 68.75%] [G loss: 1.585470]\n",
      "epoch:37 step:35077 [D loss: 0.454117, acc.: 78.91%] [G loss: 1.410897]\n",
      "epoch:37 step:35078 [D loss: 0.688096, acc.: 61.72%] [G loss: 1.773540]\n",
      "epoch:37 step:35079 [D loss: 0.449221, acc.: 82.81%] [G loss: 1.945321]\n",
      "epoch:37 step:35080 [D loss: 0.728698, acc.: 58.59%] [G loss: 1.239101]\n",
      "epoch:37 step:35081 [D loss: 0.510642, acc.: 76.56%] [G loss: 1.842183]\n",
      "epoch:37 step:35082 [D loss: 0.542692, acc.: 71.88%] [G loss: 1.087976]\n",
      "epoch:37 step:35083 [D loss: 0.588042, acc.: 64.06%] [G loss: 1.478447]\n",
      "epoch:37 step:35084 [D loss: 0.423745, acc.: 78.12%] [G loss: 1.364970]\n",
      "epoch:37 step:35085 [D loss: 0.610494, acc.: 69.53%] [G loss: 1.728217]\n",
      "epoch:37 step:35086 [D loss: 0.503233, acc.: 77.34%] [G loss: 1.645595]\n",
      "epoch:37 step:35087 [D loss: 0.481188, acc.: 76.56%] [G loss: 1.633927]\n",
      "epoch:37 step:35088 [D loss: 0.299227, acc.: 95.31%] [G loss: 2.005385]\n",
      "epoch:37 step:35089 [D loss: 0.930158, acc.: 43.75%] [G loss: 1.046116]\n",
      "epoch:37 step:35090 [D loss: 0.467949, acc.: 75.78%] [G loss: 1.750207]\n",
      "epoch:37 step:35091 [D loss: 0.564569, acc.: 70.31%] [G loss: 1.469858]\n",
      "epoch:37 step:35092 [D loss: 0.332273, acc.: 89.06%] [G loss: 1.417136]\n",
      "epoch:37 step:35093 [D loss: 0.408608, acc.: 81.25%] [G loss: 1.974773]\n",
      "epoch:37 step:35094 [D loss: 0.558463, acc.: 71.09%] [G loss: 1.785535]\n",
      "epoch:37 step:35095 [D loss: 0.713547, acc.: 60.16%] [G loss: 1.377543]\n",
      "epoch:37 step:35096 [D loss: 0.606982, acc.: 70.31%] [G loss: 1.585451]\n",
      "epoch:37 step:35097 [D loss: 0.636728, acc.: 67.19%] [G loss: 0.985004]\n",
      "epoch:37 step:35098 [D loss: 0.472437, acc.: 76.56%] [G loss: 1.665541]\n",
      "epoch:37 step:35099 [D loss: 0.461922, acc.: 77.34%] [G loss: 1.481660]\n",
      "epoch:37 step:35100 [D loss: 0.506777, acc.: 75.00%] [G loss: 1.613034]\n",
      "epoch:37 step:35101 [D loss: 0.465290, acc.: 79.69%] [G loss: 1.812206]\n",
      "epoch:37 step:35102 [D loss: 0.516192, acc.: 73.44%] [G loss: 1.351855]\n",
      "epoch:37 step:35103 [D loss: 0.589619, acc.: 67.97%] [G loss: 1.729475]\n",
      "epoch:37 step:35104 [D loss: 0.612754, acc.: 66.41%] [G loss: 1.266094]\n",
      "epoch:37 step:35105 [D loss: 0.530938, acc.: 70.31%] [G loss: 1.442280]\n",
      "epoch:37 step:35106 [D loss: 0.550379, acc.: 72.66%] [G loss: 1.496899]\n",
      "epoch:37 step:35107 [D loss: 0.570449, acc.: 73.44%] [G loss: 1.163608]\n",
      "epoch:37 step:35108 [D loss: 0.703454, acc.: 61.72%] [G loss: 1.468270]\n",
      "epoch:37 step:35109 [D loss: 0.606261, acc.: 68.75%] [G loss: 1.942157]\n",
      "epoch:37 step:35110 [D loss: 0.651552, acc.: 64.06%] [G loss: 1.480743]\n",
      "epoch:37 step:35111 [D loss: 0.561850, acc.: 72.66%] [G loss: 1.515592]\n",
      "epoch:37 step:35112 [D loss: 0.414683, acc.: 83.59%] [G loss: 1.457222]\n",
      "epoch:37 step:35113 [D loss: 0.503012, acc.: 75.78%] [G loss: 1.342301]\n",
      "epoch:37 step:35114 [D loss: 0.456159, acc.: 79.69%] [G loss: 1.490080]\n",
      "epoch:37 step:35115 [D loss: 0.340789, acc.: 86.72%] [G loss: 1.492947]\n",
      "epoch:37 step:35116 [D loss: 0.385966, acc.: 83.59%] [G loss: 1.142273]\n",
      "epoch:37 step:35117 [D loss: 0.610234, acc.: 67.97%] [G loss: 1.409598]\n",
      "epoch:37 step:35118 [D loss: 0.443873, acc.: 80.47%] [G loss: 1.644160]\n",
      "epoch:37 step:35119 [D loss: 0.617417, acc.: 66.41%] [G loss: 1.542440]\n",
      "epoch:37 step:35120 [D loss: 0.492811, acc.: 74.22%] [G loss: 1.617813]\n",
      "epoch:37 step:35121 [D loss: 0.524921, acc.: 73.44%] [G loss: 1.301848]\n",
      "epoch:37 step:35122 [D loss: 0.405783, acc.: 82.81%] [G loss: 1.860324]\n",
      "epoch:37 step:35123 [D loss: 0.484808, acc.: 75.00%] [G loss: 1.758533]\n",
      "epoch:37 step:35124 [D loss: 0.623080, acc.: 63.28%] [G loss: 2.277776]\n",
      "epoch:37 step:35125 [D loss: 0.691479, acc.: 59.38%] [G loss: 1.286630]\n",
      "epoch:37 step:35126 [D loss: 0.684639, acc.: 59.38%] [G loss: 0.874359]\n",
      "epoch:37 step:35127 [D loss: 0.564618, acc.: 70.31%] [G loss: 1.502504]\n",
      "epoch:37 step:35128 [D loss: 0.328564, acc.: 88.28%] [G loss: 2.271912]\n",
      "epoch:37 step:35129 [D loss: 0.797038, acc.: 56.25%] [G loss: 1.903344]\n",
      "epoch:37 step:35130 [D loss: 0.700410, acc.: 62.50%] [G loss: 1.908582]\n",
      "epoch:37 step:35131 [D loss: 0.531640, acc.: 72.66%] [G loss: 1.406659]\n",
      "epoch:37 step:35132 [D loss: 0.508133, acc.: 71.88%] [G loss: 1.346054]\n",
      "epoch:37 step:35133 [D loss: 0.436782, acc.: 80.47%] [G loss: 1.907459]\n",
      "epoch:37 step:35134 [D loss: 0.528333, acc.: 75.78%] [G loss: 1.340692]\n",
      "epoch:37 step:35135 [D loss: 0.504692, acc.: 75.78%] [G loss: 1.398298]\n",
      "epoch:37 step:35136 [D loss: 0.470784, acc.: 79.69%] [G loss: 2.066640]\n",
      "epoch:37 step:35137 [D loss: 0.504188, acc.: 69.53%] [G loss: 1.973866]\n",
      "epoch:37 step:35138 [D loss: 0.459332, acc.: 80.47%] [G loss: 1.979933]\n",
      "epoch:37 step:35139 [D loss: 0.659900, acc.: 65.62%] [G loss: 1.562533]\n",
      "epoch:37 step:35140 [D loss: 0.518778, acc.: 75.78%] [G loss: 1.434473]\n",
      "epoch:37 step:35141 [D loss: 0.631355, acc.: 62.50%] [G loss: 0.921361]\n",
      "epoch:37 step:35142 [D loss: 0.485396, acc.: 75.78%] [G loss: 1.699019]\n",
      "epoch:37 step:35143 [D loss: 0.448251, acc.: 79.69%] [G loss: 1.260104]\n",
      "epoch:37 step:35144 [D loss: 0.325612, acc.: 89.84%] [G loss: 1.062573]\n",
      "epoch:37 step:35145 [D loss: 0.439768, acc.: 82.03%] [G loss: 1.305306]\n",
      "epoch:37 step:35146 [D loss: 0.420173, acc.: 82.81%] [G loss: 1.372706]\n",
      "epoch:37 step:35147 [D loss: 0.555465, acc.: 71.09%] [G loss: 1.280247]\n",
      "epoch:37 step:35148 [D loss: 0.391675, acc.: 84.38%] [G loss: 1.467736]\n",
      "epoch:37 step:35149 [D loss: 0.565656, acc.: 69.53%] [G loss: 1.022920]\n",
      "epoch:37 step:35150 [D loss: 0.536284, acc.: 75.78%] [G loss: 1.552308]\n",
      "epoch:37 step:35151 [D loss: 0.363750, acc.: 88.28%] [G loss: 1.834140]\n",
      "epoch:37 step:35152 [D loss: 0.566217, acc.: 72.66%] [G loss: 2.135980]\n",
      "epoch:37 step:35153 [D loss: 0.455544, acc.: 77.34%] [G loss: 1.759009]\n",
      "epoch:37 step:35154 [D loss: 0.492661, acc.: 80.47%] [G loss: 1.475804]\n",
      "epoch:37 step:35155 [D loss: 0.465697, acc.: 76.56%] [G loss: 1.690808]\n",
      "epoch:37 step:35156 [D loss: 0.360279, acc.: 86.72%] [G loss: 1.543956]\n",
      "epoch:37 step:35157 [D loss: 0.583728, acc.: 69.53%] [G loss: 1.461627]\n",
      "epoch:37 step:35158 [D loss: 0.385437, acc.: 83.59%] [G loss: 2.015722]\n",
      "epoch:37 step:35159 [D loss: 0.525026, acc.: 78.12%] [G loss: 0.693694]\n",
      "epoch:37 step:35160 [D loss: 0.356404, acc.: 88.28%] [G loss: 1.643875]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:37 step:35161 [D loss: 0.565094, acc.: 71.88%] [G loss: 1.626385]\n",
      "epoch:37 step:35162 [D loss: 0.466346, acc.: 81.25%] [G loss: 1.574034]\n",
      "epoch:37 step:35163 [D loss: 0.706826, acc.: 58.59%] [G loss: 1.100148]\n",
      "epoch:37 step:35164 [D loss: 0.619963, acc.: 64.06%] [G loss: 0.987300]\n",
      "epoch:37 step:35165 [D loss: 0.761972, acc.: 57.81%] [G loss: 1.545660]\n",
      "epoch:37 step:35166 [D loss: 0.655068, acc.: 67.97%] [G loss: 1.398443]\n",
      "epoch:37 step:35167 [D loss: 0.459696, acc.: 76.56%] [G loss: 1.836722]\n",
      "epoch:37 step:35168 [D loss: 0.557618, acc.: 71.88%] [G loss: 1.413855]\n",
      "epoch:37 step:35169 [D loss: 0.577296, acc.: 73.44%] [G loss: 1.653405]\n",
      "epoch:37 step:35170 [D loss: 0.390499, acc.: 82.81%] [G loss: 1.775147]\n",
      "epoch:37 step:35171 [D loss: 0.544741, acc.: 71.88%] [G loss: 1.763950]\n",
      "epoch:37 step:35172 [D loss: 0.715717, acc.: 57.03%] [G loss: 1.541306]\n",
      "epoch:37 step:35173 [D loss: 0.573694, acc.: 67.97%] [G loss: 1.440392]\n",
      "epoch:37 step:35174 [D loss: 0.579273, acc.: 67.97%] [G loss: 1.486101]\n",
      "epoch:37 step:35175 [D loss: 0.280739, acc.: 89.84%] [G loss: 1.776398]\n",
      "epoch:37 step:35176 [D loss: 0.517502, acc.: 76.56%] [G loss: 1.468048]\n",
      "epoch:37 step:35177 [D loss: 0.472157, acc.: 77.34%] [G loss: 1.629651]\n",
      "epoch:37 step:35178 [D loss: 0.404690, acc.: 83.59%] [G loss: 1.462668]\n",
      "epoch:37 step:35179 [D loss: 0.403352, acc.: 84.38%] [G loss: 1.587590]\n",
      "epoch:37 step:35180 [D loss: 0.346498, acc.: 89.84%] [G loss: 1.483775]\n",
      "epoch:37 step:35181 [D loss: 0.566929, acc.: 73.44%] [G loss: 2.049444]\n",
      "epoch:37 step:35182 [D loss: 0.391404, acc.: 85.16%] [G loss: 1.461504]\n",
      "epoch:37 step:35183 [D loss: 0.480047, acc.: 80.47%] [G loss: 1.598875]\n",
      "epoch:37 step:35184 [D loss: 0.457931, acc.: 80.47%] [G loss: 1.804971]\n",
      "epoch:37 step:35185 [D loss: 0.646397, acc.: 63.28%] [G loss: 1.214455]\n",
      "epoch:37 step:35186 [D loss: 0.437851, acc.: 78.91%] [G loss: 2.154019]\n",
      "epoch:37 step:35187 [D loss: 0.650935, acc.: 67.19%] [G loss: 1.881396]\n",
      "epoch:37 step:35188 [D loss: 0.507692, acc.: 72.66%] [G loss: 1.203540]\n",
      "epoch:37 step:35189 [D loss: 0.610677, acc.: 69.53%] [G loss: 1.412045]\n",
      "epoch:37 step:35190 [D loss: 0.581482, acc.: 67.19%] [G loss: 1.407394]\n",
      "epoch:37 step:35191 [D loss: 0.616345, acc.: 69.53%] [G loss: 1.720461]\n",
      "epoch:37 step:35192 [D loss: 0.388520, acc.: 82.81%] [G loss: 1.633782]\n",
      "epoch:37 step:35193 [D loss: 0.456055, acc.: 84.38%] [G loss: 1.230828]\n",
      "epoch:37 step:35194 [D loss: 0.519414, acc.: 76.56%] [G loss: 2.101321]\n",
      "epoch:37 step:35195 [D loss: 0.580423, acc.: 67.97%] [G loss: 1.467221]\n",
      "epoch:37 step:35196 [D loss: 0.639286, acc.: 64.06%] [G loss: 1.440514]\n",
      "epoch:37 step:35197 [D loss: 0.637735, acc.: 64.06%] [G loss: 1.913471]\n",
      "epoch:37 step:35198 [D loss: 0.392196, acc.: 81.25%] [G loss: 1.093830]\n",
      "epoch:37 step:35199 [D loss: 0.578792, acc.: 71.09%] [G loss: 1.558954]\n",
      "epoch:37 step:35200 [D loss: 0.468415, acc.: 75.78%] [G loss: 1.528639]\n",
      "epoch:37 step:35201 [D loss: 0.607629, acc.: 68.75%] [G loss: 1.525883]\n",
      "epoch:37 step:35202 [D loss: 0.411038, acc.: 82.81%] [G loss: 2.226498]\n",
      "epoch:37 step:35203 [D loss: 0.612509, acc.: 66.41%] [G loss: 1.655699]\n",
      "epoch:37 step:35204 [D loss: 0.561819, acc.: 72.66%] [G loss: 1.392044]\n",
      "epoch:37 step:35205 [D loss: 0.541144, acc.: 68.75%] [G loss: 1.261430]\n",
      "epoch:37 step:35206 [D loss: 0.607275, acc.: 67.97%] [G loss: 1.519916]\n",
      "epoch:37 step:35207 [D loss: 0.822131, acc.: 58.59%] [G loss: 1.468126]\n",
      "epoch:37 step:35208 [D loss: 0.378000, acc.: 80.47%] [G loss: 1.785801]\n",
      "epoch:37 step:35209 [D loss: 0.327255, acc.: 89.84%] [G loss: 1.436359]\n",
      "epoch:37 step:35210 [D loss: 0.434663, acc.: 85.16%] [G loss: 1.342142]\n",
      "epoch:37 step:35211 [D loss: 0.456934, acc.: 78.12%] [G loss: 1.859654]\n",
      "epoch:37 step:35212 [D loss: 0.811256, acc.: 49.22%] [G loss: 1.552737]\n",
      "epoch:37 step:35213 [D loss: 0.614528, acc.: 66.41%] [G loss: 1.514013]\n",
      "epoch:37 step:35214 [D loss: 0.391822, acc.: 86.72%] [G loss: 1.439506]\n",
      "epoch:37 step:35215 [D loss: 0.425968, acc.: 80.47%] [G loss: 2.380530]\n",
      "epoch:37 step:35216 [D loss: 0.604318, acc.: 66.41%] [G loss: 1.655911]\n",
      "epoch:37 step:35217 [D loss: 0.591665, acc.: 67.19%] [G loss: 1.626055]\n",
      "epoch:37 step:35218 [D loss: 0.478299, acc.: 77.34%] [G loss: 1.497934]\n",
      "epoch:37 step:35219 [D loss: 0.410781, acc.: 85.16%] [G loss: 1.765760]\n",
      "epoch:37 step:35220 [D loss: 0.653834, acc.: 66.41%] [G loss: 2.254982]\n",
      "epoch:37 step:35221 [D loss: 0.411149, acc.: 82.03%] [G loss: 1.331910]\n",
      "epoch:37 step:35222 [D loss: 0.434686, acc.: 79.69%] [G loss: 1.691641]\n",
      "epoch:37 step:35223 [D loss: 0.501220, acc.: 75.00%] [G loss: 1.815482]\n",
      "epoch:37 step:35224 [D loss: 0.592668, acc.: 68.75%] [G loss: 1.378555]\n",
      "epoch:37 step:35225 [D loss: 0.652419, acc.: 64.06%] [G loss: 1.628428]\n",
      "epoch:37 step:35226 [D loss: 0.590020, acc.: 68.75%] [G loss: 1.616875]\n",
      "epoch:37 step:35227 [D loss: 0.617055, acc.: 69.53%] [G loss: 1.416331]\n",
      "epoch:37 step:35228 [D loss: 0.565347, acc.: 72.66%] [G loss: 1.806643]\n",
      "epoch:37 step:35229 [D loss: 0.478117, acc.: 78.91%] [G loss: 1.145805]\n",
      "epoch:37 step:35230 [D loss: 0.489208, acc.: 81.25%] [G loss: 1.650532]\n",
      "epoch:37 step:35231 [D loss: 0.474244, acc.: 75.00%] [G loss: 1.582035]\n",
      "epoch:37 step:35232 [D loss: 0.561854, acc.: 75.00%] [G loss: 1.537613]\n",
      "epoch:37 step:35233 [D loss: 0.417674, acc.: 81.25%] [G loss: 1.208403]\n",
      "epoch:37 step:35234 [D loss: 0.517933, acc.: 75.78%] [G loss: 2.382719]\n",
      "epoch:37 step:35235 [D loss: 0.291921, acc.: 90.62%] [G loss: 1.522173]\n",
      "epoch:37 step:35236 [D loss: 0.501408, acc.: 75.78%] [G loss: 1.541808]\n",
      "epoch:37 step:35237 [D loss: 0.494869, acc.: 78.12%] [G loss: 1.356474]\n",
      "epoch:37 step:35238 [D loss: 0.491567, acc.: 78.91%] [G loss: 1.826210]\n",
      "epoch:37 step:35239 [D loss: 0.538021, acc.: 75.00%] [G loss: 1.247010]\n",
      "epoch:37 step:35240 [D loss: 0.555316, acc.: 71.09%] [G loss: 1.525550]\n",
      "epoch:37 step:35241 [D loss: 0.434735, acc.: 82.03%] [G loss: 1.484350]\n",
      "epoch:37 step:35242 [D loss: 0.679007, acc.: 61.72%] [G loss: 1.147284]\n",
      "epoch:37 step:35243 [D loss: 0.681849, acc.: 60.94%] [G loss: 1.645960]\n",
      "epoch:37 step:35244 [D loss: 0.605888, acc.: 66.41%] [G loss: 1.714710]\n",
      "epoch:37 step:35245 [D loss: 0.353830, acc.: 89.06%] [G loss: 1.832640]\n",
      "epoch:37 step:35246 [D loss: 0.488785, acc.: 74.22%] [G loss: 1.425381]\n",
      "epoch:37 step:35247 [D loss: 0.299413, acc.: 89.84%] [G loss: 1.465478]\n",
      "epoch:37 step:35248 [D loss: 0.487844, acc.: 77.34%] [G loss: 1.498779]\n",
      "epoch:37 step:35249 [D loss: 0.889725, acc.: 44.53%] [G loss: 1.094551]\n",
      "epoch:37 step:35250 [D loss: 0.541385, acc.: 75.78%] [G loss: 1.473112]\n",
      "epoch:37 step:35251 [D loss: 0.428336, acc.: 80.47%] [G loss: 1.226736]\n",
      "epoch:37 step:35252 [D loss: 0.712060, acc.: 55.47%] [G loss: 1.391235]\n",
      "epoch:37 step:35253 [D loss: 0.591056, acc.: 67.97%] [G loss: 1.243436]\n",
      "epoch:37 step:35254 [D loss: 0.590539, acc.: 66.41%] [G loss: 1.735036]\n",
      "epoch:37 step:35255 [D loss: 0.361713, acc.: 87.50%] [G loss: 1.802664]\n",
      "epoch:37 step:35256 [D loss: 0.569915, acc.: 67.97%] [G loss: 1.136697]\n",
      "epoch:37 step:35257 [D loss: 0.505765, acc.: 73.44%] [G loss: 0.947072]\n",
      "epoch:37 step:35258 [D loss: 0.516805, acc.: 75.00%] [G loss: 1.335290]\n",
      "epoch:37 step:35259 [D loss: 0.328696, acc.: 89.06%] [G loss: 1.570210]\n",
      "epoch:37 step:35260 [D loss: 0.511286, acc.: 74.22%] [G loss: 1.309980]\n",
      "epoch:37 step:35261 [D loss: 0.330261, acc.: 89.06%] [G loss: 1.412858]\n",
      "epoch:37 step:35262 [D loss: 0.503541, acc.: 76.56%] [G loss: 1.621269]\n",
      "epoch:37 step:35263 [D loss: 0.833872, acc.: 57.81%] [G loss: 1.169568]\n",
      "epoch:37 step:35264 [D loss: 0.481180, acc.: 78.91%] [G loss: 1.365242]\n",
      "epoch:37 step:35265 [D loss: 0.412666, acc.: 84.38%] [G loss: 1.698212]\n",
      "epoch:37 step:35266 [D loss: 0.700889, acc.: 57.81%] [G loss: 1.666008]\n",
      "epoch:37 step:35267 [D loss: 0.756606, acc.: 53.91%] [G loss: 1.405768]\n",
      "epoch:37 step:35268 [D loss: 0.474563, acc.: 77.34%] [G loss: 1.548856]\n",
      "epoch:37 step:35269 [D loss: 0.400477, acc.: 82.81%] [G loss: 1.670162]\n",
      "epoch:37 step:35270 [D loss: 0.690490, acc.: 56.25%] [G loss: 1.451626]\n",
      "epoch:37 step:35271 [D loss: 0.653936, acc.: 67.19%] [G loss: 1.420504]\n",
      "epoch:37 step:35272 [D loss: 0.559270, acc.: 72.66%] [G loss: 1.684559]\n",
      "epoch:37 step:35273 [D loss: 0.723238, acc.: 57.03%] [G loss: 1.169061]\n",
      "epoch:37 step:35274 [D loss: 0.459024, acc.: 80.47%] [G loss: 1.877791]\n",
      "epoch:37 step:35275 [D loss: 0.527936, acc.: 71.09%] [G loss: 1.782227]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:37 step:35276 [D loss: 0.497749, acc.: 76.56%] [G loss: 1.402908]\n",
      "epoch:37 step:35277 [D loss: 0.355779, acc.: 89.06%] [G loss: 1.475009]\n",
      "epoch:37 step:35278 [D loss: 0.559539, acc.: 71.09%] [G loss: 1.414618]\n",
      "epoch:37 step:35279 [D loss: 0.462018, acc.: 82.03%] [G loss: 1.702490]\n",
      "epoch:37 step:35280 [D loss: 0.481970, acc.: 76.56%] [G loss: 1.385898]\n",
      "epoch:37 step:35281 [D loss: 0.782428, acc.: 53.91%] [G loss: 2.130099]\n",
      "epoch:37 step:35282 [D loss: 0.489073, acc.: 78.12%] [G loss: 1.542347]\n",
      "epoch:37 step:35283 [D loss: 0.568245, acc.: 72.66%] [G loss: 1.726384]\n",
      "epoch:37 step:35284 [D loss: 0.715795, acc.: 64.06%] [G loss: 0.885745]\n",
      "epoch:37 step:35285 [D loss: 0.561595, acc.: 71.88%] [G loss: 1.672682]\n",
      "epoch:37 step:35286 [D loss: 0.301432, acc.: 91.41%] [G loss: 1.902243]\n",
      "epoch:37 step:35287 [D loss: 0.457353, acc.: 78.12%] [G loss: 1.634002]\n",
      "epoch:37 step:35288 [D loss: 0.503148, acc.: 77.34%] [G loss: 1.284449]\n",
      "epoch:37 step:35289 [D loss: 0.619023, acc.: 64.06%] [G loss: 1.266160]\n",
      "epoch:37 step:35290 [D loss: 0.586345, acc.: 67.19%] [G loss: 1.778800]\n",
      "epoch:37 step:35291 [D loss: 0.610109, acc.: 65.62%] [G loss: 1.323434]\n",
      "epoch:37 step:35292 [D loss: 0.367449, acc.: 84.38%] [G loss: 1.862289]\n",
      "epoch:37 step:35293 [D loss: 0.464532, acc.: 82.03%] [G loss: 1.147395]\n",
      "epoch:37 step:35294 [D loss: 0.513837, acc.: 76.56%] [G loss: 1.522441]\n",
      "epoch:37 step:35295 [D loss: 0.432521, acc.: 79.69%] [G loss: 1.985862]\n",
      "epoch:37 step:35296 [D loss: 0.381030, acc.: 84.38%] [G loss: 1.860640]\n",
      "epoch:37 step:35297 [D loss: 0.446909, acc.: 77.34%] [G loss: 1.995091]\n",
      "epoch:37 step:35298 [D loss: 0.675319, acc.: 63.28%] [G loss: 1.716681]\n",
      "epoch:37 step:35299 [D loss: 0.557783, acc.: 69.53%] [G loss: 1.192709]\n",
      "epoch:37 step:35300 [D loss: 0.500751, acc.: 78.12%] [G loss: 1.438761]\n",
      "epoch:37 step:35301 [D loss: 0.547230, acc.: 74.22%] [G loss: 1.482655]\n",
      "epoch:37 step:35302 [D loss: 0.656577, acc.: 64.84%] [G loss: 1.747125]\n",
      "epoch:37 step:35303 [D loss: 0.562083, acc.: 73.44%] [G loss: 1.521304]\n",
      "epoch:37 step:35304 [D loss: 0.644262, acc.: 63.28%] [G loss: 1.402254]\n",
      "epoch:37 step:35305 [D loss: 0.549398, acc.: 71.09%] [G loss: 1.750299]\n",
      "epoch:37 step:35306 [D loss: 0.416340, acc.: 85.94%] [G loss: 1.682096]\n",
      "epoch:37 step:35307 [D loss: 0.609270, acc.: 72.66%] [G loss: 1.645870]\n",
      "epoch:37 step:35308 [D loss: 0.491745, acc.: 73.44%] [G loss: 1.606935]\n",
      "epoch:37 step:35309 [D loss: 0.280598, acc.: 92.97%] [G loss: 2.217954]\n",
      "epoch:37 step:35310 [D loss: 0.744063, acc.: 53.91%] [G loss: 1.117308]\n",
      "epoch:37 step:35311 [D loss: 0.700486, acc.: 64.06%] [G loss: 1.660006]\n",
      "epoch:37 step:35312 [D loss: 0.744326, acc.: 57.81%] [G loss: 1.361860]\n",
      "epoch:37 step:35313 [D loss: 0.565933, acc.: 73.44%] [G loss: 1.207514]\n",
      "epoch:37 step:35314 [D loss: 0.465566, acc.: 80.47%] [G loss: 1.596094]\n",
      "epoch:37 step:35315 [D loss: 0.584631, acc.: 75.78%] [G loss: 1.882249]\n",
      "epoch:37 step:35316 [D loss: 0.630051, acc.: 67.19%] [G loss: 1.794917]\n",
      "epoch:37 step:35317 [D loss: 0.343926, acc.: 87.50%] [G loss: 1.959351]\n",
      "epoch:37 step:35318 [D loss: 0.637661, acc.: 65.62%] [G loss: 1.205399]\n",
      "epoch:37 step:35319 [D loss: 0.580775, acc.: 69.53%] [G loss: 1.533798]\n",
      "epoch:37 step:35320 [D loss: 0.560748, acc.: 71.09%] [G loss: 1.047388]\n",
      "epoch:37 step:35321 [D loss: 0.500337, acc.: 77.34%] [G loss: 1.996967]\n",
      "epoch:37 step:35322 [D loss: 0.495342, acc.: 79.69%] [G loss: 1.799394]\n",
      "epoch:37 step:35323 [D loss: 0.543733, acc.: 70.31%] [G loss: 1.768236]\n",
      "epoch:37 step:35324 [D loss: 0.487776, acc.: 76.56%] [G loss: 1.833214]\n",
      "epoch:37 step:35325 [D loss: 0.527847, acc.: 77.34%] [G loss: 1.308697]\n",
      "epoch:37 step:35326 [D loss: 0.573188, acc.: 67.19%] [G loss: 1.391872]\n",
      "epoch:37 step:35327 [D loss: 0.469383, acc.: 72.66%] [G loss: 1.543988]\n",
      "epoch:37 step:35328 [D loss: 0.670349, acc.: 63.28%] [G loss: 1.029635]\n",
      "epoch:37 step:35329 [D loss: 0.475330, acc.: 77.34%] [G loss: 1.651529]\n",
      "epoch:37 step:35330 [D loss: 0.554497, acc.: 68.75%] [G loss: 1.873753]\n",
      "epoch:37 step:35331 [D loss: 0.603685, acc.: 64.06%] [G loss: 1.993340]\n",
      "epoch:37 step:35332 [D loss: 0.720988, acc.: 58.59%] [G loss: 1.793226]\n",
      "epoch:37 step:35333 [D loss: 0.962982, acc.: 42.19%] [G loss: 1.345831]\n",
      "epoch:37 step:35334 [D loss: 0.592645, acc.: 67.19%] [G loss: 1.509247]\n",
      "epoch:37 step:35335 [D loss: 0.277328, acc.: 91.41%] [G loss: 2.061345]\n",
      "epoch:37 step:35336 [D loss: 0.502062, acc.: 75.00%] [G loss: 1.781821]\n",
      "epoch:37 step:35337 [D loss: 0.641803, acc.: 61.72%] [G loss: 1.226771]\n",
      "epoch:37 step:35338 [D loss: 0.563416, acc.: 64.84%] [G loss: 1.154037]\n",
      "epoch:37 step:35339 [D loss: 0.532057, acc.: 74.22%] [G loss: 1.641213]\n",
      "epoch:37 step:35340 [D loss: 0.513800, acc.: 76.56%] [G loss: 1.793591]\n",
      "epoch:37 step:35341 [D loss: 0.730739, acc.: 57.81%] [G loss: 1.528609]\n",
      "epoch:37 step:35342 [D loss: 0.653022, acc.: 67.97%] [G loss: 1.334255]\n",
      "epoch:37 step:35343 [D loss: 0.656556, acc.: 63.28%] [G loss: 1.358928]\n",
      "epoch:37 step:35344 [D loss: 0.535525, acc.: 73.44%] [G loss: 1.973561]\n",
      "epoch:37 step:35345 [D loss: 0.438987, acc.: 81.25%] [G loss: 1.288606]\n",
      "epoch:37 step:35346 [D loss: 0.403296, acc.: 85.94%] [G loss: 1.909840]\n",
      "epoch:37 step:35347 [D loss: 0.526517, acc.: 71.88%] [G loss: 1.444227]\n",
      "epoch:37 step:35348 [D loss: 0.440699, acc.: 81.25%] [G loss: 2.048150]\n",
      "epoch:37 step:35349 [D loss: 0.715370, acc.: 59.38%] [G loss: 1.212385]\n",
      "epoch:37 step:35350 [D loss: 0.419754, acc.: 81.25%] [G loss: 1.195971]\n",
      "epoch:37 step:35351 [D loss: 0.387888, acc.: 87.50%] [G loss: 1.802826]\n",
      "epoch:37 step:35352 [D loss: 0.735597, acc.: 57.81%] [G loss: 1.084304]\n",
      "epoch:37 step:35353 [D loss: 0.368790, acc.: 85.16%] [G loss: 1.641209]\n",
      "epoch:37 step:35354 [D loss: 0.659238, acc.: 64.84%] [G loss: 1.405478]\n",
      "epoch:37 step:35355 [D loss: 0.475731, acc.: 74.22%] [G loss: 1.496285]\n",
      "epoch:37 step:35356 [D loss: 0.509226, acc.: 73.44%] [G loss: 1.612838]\n",
      "epoch:37 step:35357 [D loss: 0.638516, acc.: 66.41%] [G loss: 1.819528]\n",
      "epoch:37 step:35358 [D loss: 0.609004, acc.: 70.31%] [G loss: 2.169472]\n",
      "epoch:37 step:35359 [D loss: 0.462721, acc.: 78.12%] [G loss: 1.426956]\n",
      "epoch:37 step:35360 [D loss: 0.553153, acc.: 73.44%] [G loss: 1.251261]\n",
      "epoch:37 step:35361 [D loss: 0.373909, acc.: 87.50%] [G loss: 1.488564]\n",
      "epoch:37 step:35362 [D loss: 0.923343, acc.: 43.75%] [G loss: 1.158531]\n",
      "epoch:37 step:35363 [D loss: 0.418834, acc.: 85.16%] [G loss: 1.863982]\n",
      "epoch:37 step:35364 [D loss: 0.609232, acc.: 67.97%] [G loss: 1.555910]\n",
      "epoch:37 step:35365 [D loss: 0.604537, acc.: 67.19%] [G loss: 1.471046]\n",
      "epoch:37 step:35366 [D loss: 0.396570, acc.: 79.69%] [G loss: 1.693346]\n",
      "epoch:37 step:35367 [D loss: 0.432487, acc.: 78.91%] [G loss: 1.375768]\n",
      "epoch:37 step:35368 [D loss: 0.550712, acc.: 68.75%] [G loss: 1.225734]\n",
      "epoch:37 step:35369 [D loss: 0.458540, acc.: 82.03%] [G loss: 1.705951]\n",
      "epoch:37 step:35370 [D loss: 0.384291, acc.: 86.72%] [G loss: 1.858391]\n",
      "epoch:37 step:35371 [D loss: 0.723289, acc.: 55.47%] [G loss: 1.461747]\n",
      "epoch:37 step:35372 [D loss: 0.542477, acc.: 67.19%] [G loss: 1.391188]\n",
      "epoch:37 step:35373 [D loss: 0.496462, acc.: 75.78%] [G loss: 1.131117]\n",
      "epoch:37 step:35374 [D loss: 0.366679, acc.: 84.38%] [G loss: 1.231753]\n",
      "epoch:37 step:35375 [D loss: 0.553777, acc.: 73.44%] [G loss: 1.572620]\n",
      "epoch:37 step:35376 [D loss: 0.479344, acc.: 77.34%] [G loss: 1.771820]\n",
      "epoch:37 step:35377 [D loss: 0.347827, acc.: 88.28%] [G loss: 1.411532]\n",
      "epoch:37 step:35378 [D loss: 0.577248, acc.: 67.97%] [G loss: 0.933888]\n",
      "epoch:37 step:35379 [D loss: 0.459474, acc.: 78.12%] [G loss: 2.090246]\n",
      "epoch:37 step:35380 [D loss: 0.608586, acc.: 66.41%] [G loss: 1.355472]\n",
      "epoch:37 step:35381 [D loss: 0.462690, acc.: 76.56%] [G loss: 1.460356]\n",
      "epoch:37 step:35382 [D loss: 0.408004, acc.: 80.47%] [G loss: 1.998093]\n",
      "epoch:37 step:35383 [D loss: 0.671375, acc.: 63.28%] [G loss: 1.275874]\n",
      "epoch:37 step:35384 [D loss: 0.378956, acc.: 85.94%] [G loss: 1.662284]\n",
      "epoch:37 step:35385 [D loss: 0.362748, acc.: 89.06%] [G loss: 1.707551]\n",
      "epoch:37 step:35386 [D loss: 0.461356, acc.: 81.25%] [G loss: 1.419803]\n",
      "epoch:37 step:35387 [D loss: 0.346096, acc.: 88.28%] [G loss: 1.405957]\n",
      "epoch:37 step:35388 [D loss: 0.561590, acc.: 69.53%] [G loss: 1.225850]\n",
      "epoch:37 step:35389 [D loss: 0.439460, acc.: 83.59%] [G loss: 1.480801]\n",
      "epoch:37 step:35390 [D loss: 0.559335, acc.: 69.53%] [G loss: 1.246326]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:37 step:35391 [D loss: 0.674013, acc.: 61.72%] [G loss: 1.152123]\n",
      "epoch:37 step:35392 [D loss: 0.568284, acc.: 78.12%] [G loss: 1.695751]\n",
      "epoch:37 step:35393 [D loss: 0.453736, acc.: 80.47%] [G loss: 2.071783]\n",
      "epoch:37 step:35394 [D loss: 0.506278, acc.: 75.00%] [G loss: 1.410009]\n",
      "epoch:37 step:35395 [D loss: 0.601825, acc.: 71.88%] [G loss: 1.370703]\n",
      "epoch:37 step:35396 [D loss: 0.278581, acc.: 93.75%] [G loss: 1.524632]\n",
      "epoch:37 step:35397 [D loss: 0.622951, acc.: 64.84%] [G loss: 1.939156]\n",
      "epoch:37 step:35398 [D loss: 0.655964, acc.: 66.41%] [G loss: 1.005501]\n",
      "epoch:37 step:35399 [D loss: 0.553648, acc.: 69.53%] [G loss: 1.397452]\n",
      "epoch:37 step:35400 [D loss: 0.838496, acc.: 46.88%] [G loss: 1.323312]\n",
      "epoch:37 step:35401 [D loss: 0.593253, acc.: 68.75%] [G loss: 1.663644]\n",
      "epoch:37 step:35402 [D loss: 0.378373, acc.: 84.38%] [G loss: 2.099726]\n",
      "epoch:37 step:35403 [D loss: 0.559729, acc.: 75.00%] [G loss: 1.816903]\n",
      "epoch:37 step:35404 [D loss: 0.584905, acc.: 68.75%] [G loss: 1.146090]\n",
      "epoch:37 step:35405 [D loss: 0.420908, acc.: 82.03%] [G loss: 1.456192]\n",
      "epoch:37 step:35406 [D loss: 0.313412, acc.: 89.84%] [G loss: 1.385890]\n",
      "epoch:37 step:35407 [D loss: 0.643301, acc.: 67.19%] [G loss: 1.647463]\n",
      "epoch:37 step:35408 [D loss: 0.441275, acc.: 77.34%] [G loss: 1.296034]\n",
      "epoch:37 step:35409 [D loss: 0.525173, acc.: 70.31%] [G loss: 1.575143]\n",
      "epoch:37 step:35410 [D loss: 0.447659, acc.: 78.91%] [G loss: 1.177852]\n",
      "epoch:37 step:35411 [D loss: 0.446020, acc.: 85.16%] [G loss: 1.848987]\n",
      "epoch:37 step:35412 [D loss: 0.513332, acc.: 76.56%] [G loss: 2.092115]\n",
      "epoch:37 step:35413 [D loss: 0.437243, acc.: 83.59%] [G loss: 1.345080]\n",
      "epoch:37 step:35414 [D loss: 0.621115, acc.: 64.84%] [G loss: 1.514156]\n",
      "epoch:37 step:35415 [D loss: 0.308707, acc.: 89.06%] [G loss: 2.122924]\n",
      "epoch:37 step:35416 [D loss: 0.605022, acc.: 69.53%] [G loss: 1.445819]\n",
      "epoch:37 step:35417 [D loss: 0.438545, acc.: 78.12%] [G loss: 1.507033]\n",
      "epoch:37 step:35418 [D loss: 0.625950, acc.: 60.94%] [G loss: 1.334836]\n",
      "epoch:37 step:35419 [D loss: 0.557943, acc.: 71.88%] [G loss: 1.938289]\n",
      "epoch:37 step:35420 [D loss: 0.538703, acc.: 72.66%] [G loss: 2.042657]\n",
      "epoch:37 step:35421 [D loss: 0.691000, acc.: 57.81%] [G loss: 1.090973]\n",
      "epoch:37 step:35422 [D loss: 0.411024, acc.: 82.81%] [G loss: 1.890992]\n",
      "epoch:37 step:35423 [D loss: 0.745136, acc.: 57.81%] [G loss: 1.574128]\n",
      "epoch:37 step:35424 [D loss: 0.419108, acc.: 83.59%] [G loss: 1.251211]\n",
      "epoch:37 step:35425 [D loss: 0.487637, acc.: 75.78%] [G loss: 1.605733]\n",
      "epoch:37 step:35426 [D loss: 0.497225, acc.: 73.44%] [G loss: 1.172988]\n",
      "epoch:37 step:35427 [D loss: 0.596901, acc.: 70.31%] [G loss: 1.205845]\n",
      "epoch:37 step:35428 [D loss: 0.327988, acc.: 85.94%] [G loss: 1.767907]\n",
      "epoch:37 step:35429 [D loss: 0.449602, acc.: 80.47%] [G loss: 1.967245]\n",
      "epoch:37 step:35430 [D loss: 0.780677, acc.: 56.25%] [G loss: 1.469065]\n",
      "epoch:37 step:35431 [D loss: 0.591210, acc.: 61.72%] [G loss: 1.314738]\n",
      "epoch:37 step:35432 [D loss: 0.583671, acc.: 68.75%] [G loss: 1.251303]\n",
      "epoch:37 step:35433 [D loss: 0.494692, acc.: 76.56%] [G loss: 1.774115]\n",
      "epoch:37 step:35434 [D loss: 0.525845, acc.: 72.66%] [G loss: 2.123653]\n",
      "epoch:37 step:35435 [D loss: 0.606825, acc.: 68.75%] [G loss: 1.792625]\n",
      "epoch:37 step:35436 [D loss: 0.399668, acc.: 82.03%] [G loss: 1.867153]\n",
      "epoch:37 step:35437 [D loss: 0.677934, acc.: 64.06%] [G loss: 1.090792]\n",
      "epoch:37 step:35438 [D loss: 0.485849, acc.: 78.91%] [G loss: 1.230548]\n",
      "epoch:37 step:35439 [D loss: 0.619591, acc.: 64.84%] [G loss: 1.717883]\n",
      "epoch:37 step:35440 [D loss: 0.478898, acc.: 76.56%] [G loss: 1.630633]\n",
      "epoch:37 step:35441 [D loss: 0.523547, acc.: 69.53%] [G loss: 1.547135]\n",
      "epoch:37 step:35442 [D loss: 0.871663, acc.: 47.66%] [G loss: 1.343846]\n",
      "epoch:37 step:35443 [D loss: 0.577396, acc.: 69.53%] [G loss: 1.222960]\n",
      "epoch:37 step:35444 [D loss: 0.505578, acc.: 73.44%] [G loss: 1.688650]\n",
      "epoch:37 step:35445 [D loss: 0.320141, acc.: 88.28%] [G loss: 1.471679]\n",
      "epoch:37 step:35446 [D loss: 0.561603, acc.: 70.31%] [G loss: 1.416324]\n",
      "epoch:37 step:35447 [D loss: 0.567466, acc.: 71.09%] [G loss: 1.665351]\n",
      "epoch:37 step:35448 [D loss: 0.442089, acc.: 81.25%] [G loss: 1.521823]\n",
      "epoch:37 step:35449 [D loss: 0.647704, acc.: 64.06%] [G loss: 1.241385]\n",
      "epoch:37 step:35450 [D loss: 0.560089, acc.: 71.88%] [G loss: 1.090968]\n",
      "epoch:37 step:35451 [D loss: 0.541165, acc.: 72.66%] [G loss: 1.458528]\n",
      "epoch:37 step:35452 [D loss: 0.523798, acc.: 75.78%] [G loss: 1.876214]\n",
      "epoch:37 step:35453 [D loss: 0.537347, acc.: 71.09%] [G loss: 1.410232]\n",
      "epoch:37 step:35454 [D loss: 0.543645, acc.: 75.78%] [G loss: 2.036855]\n",
      "epoch:37 step:35455 [D loss: 0.737186, acc.: 55.47%] [G loss: 1.952190]\n",
      "epoch:37 step:35456 [D loss: 0.626504, acc.: 67.19%] [G loss: 1.488945]\n",
      "epoch:37 step:35457 [D loss: 0.606957, acc.: 67.97%] [G loss: 1.316385]\n",
      "epoch:37 step:35458 [D loss: 0.735275, acc.: 57.03%] [G loss: 1.056239]\n",
      "epoch:37 step:35459 [D loss: 0.506196, acc.: 74.22%] [G loss: 1.782960]\n",
      "epoch:37 step:35460 [D loss: 0.583087, acc.: 71.09%] [G loss: 1.722149]\n",
      "epoch:37 step:35461 [D loss: 0.317110, acc.: 90.62%] [G loss: 1.650645]\n",
      "epoch:37 step:35462 [D loss: 0.327777, acc.: 91.41%] [G loss: 1.867463]\n",
      "epoch:37 step:35463 [D loss: 0.539546, acc.: 77.34%] [G loss: 1.162841]\n",
      "epoch:37 step:35464 [D loss: 0.501932, acc.: 74.22%] [G loss: 1.187374]\n",
      "epoch:37 step:35465 [D loss: 0.399970, acc.: 83.59%] [G loss: 1.496555]\n",
      "epoch:37 step:35466 [D loss: 0.522646, acc.: 73.44%] [G loss: 1.461755]\n",
      "epoch:37 step:35467 [D loss: 0.643669, acc.: 61.72%] [G loss: 1.712187]\n",
      "epoch:37 step:35468 [D loss: 0.474742, acc.: 78.12%] [G loss: 1.526915]\n",
      "epoch:37 step:35469 [D loss: 0.522503, acc.: 77.34%] [G loss: 2.056077]\n",
      "epoch:37 step:35470 [D loss: 0.571414, acc.: 73.44%] [G loss: 1.280063]\n",
      "epoch:37 step:35471 [D loss: 0.730370, acc.: 57.81%] [G loss: 1.049343]\n",
      "epoch:37 step:35472 [D loss: 0.591208, acc.: 67.97%] [G loss: 1.761596]\n",
      "epoch:37 step:35473 [D loss: 0.551115, acc.: 73.44%] [G loss: 1.587594]\n",
      "epoch:37 step:35474 [D loss: 0.371650, acc.: 89.06%] [G loss: 1.779627]\n",
      "epoch:37 step:35475 [D loss: 0.541669, acc.: 71.09%] [G loss: 1.438902]\n",
      "epoch:37 step:35476 [D loss: 0.563373, acc.: 71.88%] [G loss: 2.092868]\n",
      "epoch:37 step:35477 [D loss: 0.539280, acc.: 71.09%] [G loss: 1.490876]\n",
      "epoch:37 step:35478 [D loss: 0.470272, acc.: 75.78%] [G loss: 1.619051]\n",
      "epoch:37 step:35479 [D loss: 0.470307, acc.: 80.47%] [G loss: 1.651119]\n",
      "epoch:37 step:35480 [D loss: 0.493848, acc.: 78.12%] [G loss: 1.615551]\n",
      "epoch:37 step:35481 [D loss: 0.521501, acc.: 73.44%] [G loss: 1.363274]\n",
      "epoch:37 step:35482 [D loss: 0.381880, acc.: 89.84%] [G loss: 1.246474]\n",
      "epoch:37 step:35483 [D loss: 0.345160, acc.: 90.62%] [G loss: 1.573478]\n",
      "epoch:37 step:35484 [D loss: 0.589738, acc.: 65.62%] [G loss: 1.579839]\n",
      "epoch:37 step:35485 [D loss: 0.430601, acc.: 79.69%] [G loss: 2.061858]\n",
      "epoch:37 step:35486 [D loss: 0.700688, acc.: 61.72%] [G loss: 1.330293]\n",
      "epoch:37 step:35487 [D loss: 0.586280, acc.: 73.44%] [G loss: 1.555217]\n",
      "epoch:37 step:35488 [D loss: 0.400458, acc.: 84.38%] [G loss: 1.433440]\n",
      "epoch:37 step:35489 [D loss: 0.571265, acc.: 72.66%] [G loss: 1.898801]\n",
      "epoch:37 step:35490 [D loss: 0.540846, acc.: 74.22%] [G loss: 1.361092]\n",
      "epoch:37 step:35491 [D loss: 0.475638, acc.: 78.91%] [G loss: 1.600385]\n",
      "epoch:37 step:35492 [D loss: 0.566363, acc.: 73.44%] [G loss: 1.667295]\n",
      "epoch:37 step:35493 [D loss: 0.545960, acc.: 71.88%] [G loss: 1.696576]\n",
      "epoch:37 step:35494 [D loss: 0.505294, acc.: 76.56%] [G loss: 1.529382]\n",
      "epoch:37 step:35495 [D loss: 0.550975, acc.: 76.56%] [G loss: 1.594255]\n",
      "epoch:37 step:35496 [D loss: 0.477494, acc.: 85.16%] [G loss: 1.521450]\n",
      "epoch:37 step:35497 [D loss: 0.543339, acc.: 76.56%] [G loss: 1.368368]\n",
      "epoch:37 step:35498 [D loss: 0.721487, acc.: 57.03%] [G loss: 0.915128]\n",
      "epoch:37 step:35499 [D loss: 0.530200, acc.: 74.22%] [G loss: 1.523087]\n",
      "epoch:37 step:35500 [D loss: 0.632563, acc.: 69.53%] [G loss: 2.419603]\n",
      "epoch:37 step:35501 [D loss: 0.367268, acc.: 82.03%] [G loss: 1.560874]\n",
      "epoch:37 step:35502 [D loss: 0.463907, acc.: 78.12%] [G loss: 1.404737]\n",
      "epoch:37 step:35503 [D loss: 0.585112, acc.: 68.75%] [G loss: 2.204874]\n",
      "epoch:37 step:35504 [D loss: 0.639506, acc.: 62.50%] [G loss: 1.241222]\n",
      "epoch:37 step:35505 [D loss: 0.428834, acc.: 80.47%] [G loss: 1.554392]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:37 step:35506 [D loss: 0.787377, acc.: 58.59%] [G loss: 1.597621]\n",
      "epoch:37 step:35507 [D loss: 0.468523, acc.: 80.47%] [G loss: 1.578753]\n",
      "epoch:37 step:35508 [D loss: 0.469467, acc.: 78.91%] [G loss: 1.618159]\n",
      "epoch:37 step:35509 [D loss: 0.375026, acc.: 85.94%] [G loss: 1.541978]\n",
      "epoch:37 step:35510 [D loss: 0.660131, acc.: 65.62%] [G loss: 1.367573]\n",
      "epoch:37 step:35511 [D loss: 0.383224, acc.: 85.16%] [G loss: 1.608573]\n",
      "epoch:37 step:35512 [D loss: 0.531538, acc.: 73.44%] [G loss: 1.076240]\n",
      "epoch:37 step:35513 [D loss: 0.429190, acc.: 82.03%] [G loss: 1.439162]\n",
      "epoch:37 step:35514 [D loss: 0.539183, acc.: 70.31%] [G loss: 1.632725]\n",
      "epoch:37 step:35515 [D loss: 0.408735, acc.: 83.59%] [G loss: 1.119538]\n",
      "epoch:37 step:35516 [D loss: 0.611608, acc.: 64.06%] [G loss: 1.275041]\n",
      "epoch:37 step:35517 [D loss: 0.424291, acc.: 80.47%] [G loss: 1.802112]\n",
      "epoch:37 step:35518 [D loss: 0.567204, acc.: 68.75%] [G loss: 1.409333]\n",
      "epoch:37 step:35519 [D loss: 0.474307, acc.: 79.69%] [G loss: 1.251170]\n",
      "epoch:37 step:35520 [D loss: 0.651892, acc.: 64.06%] [G loss: 1.552034]\n",
      "epoch:37 step:35521 [D loss: 0.498913, acc.: 75.78%] [G loss: 1.455523]\n",
      "epoch:37 step:35522 [D loss: 0.412512, acc.: 81.25%] [G loss: 1.629864]\n",
      "epoch:37 step:35523 [D loss: 0.729179, acc.: 63.28%] [G loss: 1.315560]\n",
      "epoch:37 step:35524 [D loss: 0.633250, acc.: 64.84%] [G loss: 1.130155]\n",
      "epoch:37 step:35525 [D loss: 0.619830, acc.: 68.75%] [G loss: 1.250919]\n",
      "epoch:37 step:35526 [D loss: 0.627912, acc.: 71.88%] [G loss: 1.290464]\n",
      "epoch:37 step:35527 [D loss: 0.395576, acc.: 85.94%] [G loss: 1.800510]\n",
      "epoch:37 step:35528 [D loss: 0.872287, acc.: 49.22%] [G loss: 1.453951]\n",
      "epoch:37 step:35529 [D loss: 0.441318, acc.: 81.25%] [G loss: 1.564215]\n",
      "epoch:37 step:35530 [D loss: 0.386787, acc.: 84.38%] [G loss: 1.405206]\n",
      "epoch:37 step:35531 [D loss: 0.507063, acc.: 78.91%] [G loss: 1.246808]\n",
      "epoch:37 step:35532 [D loss: 0.828218, acc.: 47.66%] [G loss: 1.415292]\n",
      "epoch:37 step:35533 [D loss: 0.700006, acc.: 53.91%] [G loss: 1.188132]\n",
      "epoch:37 step:35534 [D loss: 0.449220, acc.: 82.81%] [G loss: 1.712266]\n",
      "epoch:37 step:35535 [D loss: 0.367898, acc.: 85.94%] [G loss: 1.771762]\n",
      "epoch:37 step:35536 [D loss: 0.702184, acc.: 58.59%] [G loss: 1.533144]\n",
      "epoch:37 step:35537 [D loss: 0.528897, acc.: 71.88%] [G loss: 1.337569]\n",
      "epoch:37 step:35538 [D loss: 0.646664, acc.: 64.84%] [G loss: 1.051543]\n",
      "epoch:37 step:35539 [D loss: 0.449465, acc.: 80.47%] [G loss: 1.535296]\n",
      "epoch:37 step:35540 [D loss: 0.658102, acc.: 60.16%] [G loss: 1.931393]\n",
      "epoch:37 step:35541 [D loss: 0.477389, acc.: 75.78%] [G loss: 1.587128]\n",
      "epoch:37 step:35542 [D loss: 0.311129, acc.: 92.97%] [G loss: 1.831572]\n",
      "epoch:37 step:35543 [D loss: 0.514381, acc.: 78.12%] [G loss: 1.525681]\n",
      "epoch:37 step:35544 [D loss: 0.407514, acc.: 81.25%] [G loss: 1.746898]\n",
      "epoch:37 step:35545 [D loss: 0.692778, acc.: 57.81%] [G loss: 1.170414]\n",
      "epoch:37 step:35546 [D loss: 0.598451, acc.: 67.97%] [G loss: 1.364399]\n",
      "epoch:37 step:35547 [D loss: 0.478268, acc.: 79.69%] [G loss: 1.025701]\n",
      "epoch:37 step:35548 [D loss: 0.641437, acc.: 60.16%] [G loss: 1.103077]\n",
      "epoch:37 step:35549 [D loss: 0.655214, acc.: 61.72%] [G loss: 1.042653]\n",
      "epoch:37 step:35550 [D loss: 0.510908, acc.: 77.34%] [G loss: 1.490324]\n",
      "epoch:37 step:35551 [D loss: 0.407126, acc.: 86.72%] [G loss: 1.862997]\n",
      "epoch:37 step:35552 [D loss: 0.604150, acc.: 67.19%] [G loss: 1.575486]\n",
      "epoch:37 step:35553 [D loss: 0.394177, acc.: 85.16%] [G loss: 1.652626]\n",
      "epoch:37 step:35554 [D loss: 0.628008, acc.: 67.97%] [G loss: 1.503718]\n",
      "epoch:37 step:35555 [D loss: 0.366222, acc.: 89.06%] [G loss: 1.851613]\n",
      "epoch:37 step:35556 [D loss: 0.720153, acc.: 54.69%] [G loss: 1.321310]\n",
      "epoch:37 step:35557 [D loss: 0.537675, acc.: 73.44%] [G loss: 1.285596]\n",
      "epoch:37 step:35558 [D loss: 0.622734, acc.: 67.19%] [G loss: 1.538177]\n",
      "epoch:37 step:35559 [D loss: 0.468768, acc.: 77.34%] [G loss: 1.766248]\n",
      "epoch:37 step:35560 [D loss: 0.619204, acc.: 64.06%] [G loss: 1.022546]\n",
      "epoch:37 step:35561 [D loss: 0.690380, acc.: 58.59%] [G loss: 1.265366]\n",
      "epoch:37 step:35562 [D loss: 0.532772, acc.: 75.00%] [G loss: 1.566095]\n",
      "epoch:37 step:35563 [D loss: 0.453991, acc.: 81.25%] [G loss: 1.870942]\n",
      "epoch:37 step:35564 [D loss: 0.382820, acc.: 88.28%] [G loss: 1.552776]\n",
      "epoch:37 step:35565 [D loss: 0.704463, acc.: 60.16%] [G loss: 1.478318]\n",
      "epoch:37 step:35566 [D loss: 0.426662, acc.: 81.25%] [G loss: 1.452729]\n",
      "epoch:37 step:35567 [D loss: 0.537185, acc.: 70.31%] [G loss: 1.276014]\n",
      "epoch:37 step:35568 [D loss: 0.454253, acc.: 79.69%] [G loss: 1.076421]\n",
      "epoch:37 step:35569 [D loss: 0.642965, acc.: 64.06%] [G loss: 1.564980]\n",
      "epoch:37 step:35570 [D loss: 0.711518, acc.: 58.59%] [G loss: 1.181246]\n",
      "epoch:37 step:35571 [D loss: 0.521747, acc.: 70.31%] [G loss: 1.692930]\n",
      "epoch:37 step:35572 [D loss: 0.460136, acc.: 75.00%] [G loss: 1.155939]\n",
      "epoch:37 step:35573 [D loss: 0.697951, acc.: 58.59%] [G loss: 1.070015]\n",
      "epoch:37 step:35574 [D loss: 0.549134, acc.: 74.22%] [G loss: 1.552698]\n",
      "epoch:37 step:35575 [D loss: 0.585369, acc.: 68.75%] [G loss: 1.789252]\n",
      "epoch:37 step:35576 [D loss: 0.497090, acc.: 74.22%] [G loss: 1.552261]\n",
      "epoch:37 step:35577 [D loss: 0.402892, acc.: 81.25%] [G loss: 1.649957]\n",
      "epoch:37 step:35578 [D loss: 0.603541, acc.: 67.97%] [G loss: 1.416672]\n",
      "epoch:37 step:35579 [D loss: 0.302599, acc.: 91.41%] [G loss: 1.696288]\n",
      "epoch:37 step:35580 [D loss: 0.504365, acc.: 73.44%] [G loss: 1.304401]\n",
      "epoch:37 step:35581 [D loss: 0.407388, acc.: 82.03%] [G loss: 1.488637]\n",
      "epoch:37 step:35582 [D loss: 0.447256, acc.: 78.91%] [G loss: 1.593875]\n",
      "epoch:37 step:35583 [D loss: 0.633649, acc.: 60.94%] [G loss: 1.356329]\n",
      "epoch:37 step:35584 [D loss: 0.489256, acc.: 78.91%] [G loss: 1.553411]\n",
      "epoch:37 step:35585 [D loss: 0.536845, acc.: 71.09%] [G loss: 1.560165]\n",
      "epoch:37 step:35586 [D loss: 0.504924, acc.: 78.91%] [G loss: 1.711039]\n",
      "epoch:37 step:35587 [D loss: 0.404752, acc.: 82.81%] [G loss: 1.811619]\n",
      "epoch:37 step:35588 [D loss: 0.500596, acc.: 74.22%] [G loss: 1.668668]\n",
      "epoch:37 step:35589 [D loss: 0.548683, acc.: 74.22%] [G loss: 1.841510]\n",
      "epoch:37 step:35590 [D loss: 0.697696, acc.: 60.94%] [G loss: 1.344732]\n",
      "epoch:37 step:35591 [D loss: 0.620335, acc.: 66.41%] [G loss: 1.162534]\n",
      "epoch:37 step:35592 [D loss: 0.506812, acc.: 77.34%] [G loss: 1.523645]\n",
      "epoch:37 step:35593 [D loss: 0.441457, acc.: 79.69%] [G loss: 1.175420]\n",
      "epoch:37 step:35594 [D loss: 0.423204, acc.: 81.25%] [G loss: 1.371120]\n",
      "epoch:37 step:35595 [D loss: 0.479846, acc.: 77.34%] [G loss: 1.532285]\n",
      "epoch:37 step:35596 [D loss: 0.507480, acc.: 74.22%] [G loss: 1.384296]\n",
      "epoch:37 step:35597 [D loss: 0.686579, acc.: 60.16%] [G loss: 1.511675]\n",
      "epoch:37 step:35598 [D loss: 0.556046, acc.: 69.53%] [G loss: 1.130311]\n",
      "epoch:37 step:35599 [D loss: 0.454193, acc.: 82.03%] [G loss: 2.028277]\n",
      "epoch:37 step:35600 [D loss: 0.668755, acc.: 64.84%] [G loss: 1.809048]\n",
      "epoch:37 step:35601 [D loss: 0.365715, acc.: 89.06%] [G loss: 1.516251]\n",
      "epoch:37 step:35602 [D loss: 0.802613, acc.: 52.34%] [G loss: 1.228882]\n",
      "epoch:37 step:35603 [D loss: 0.531965, acc.: 73.44%] [G loss: 1.761809]\n",
      "epoch:37 step:35604 [D loss: 0.419731, acc.: 84.38%] [G loss: 1.532986]\n",
      "epoch:37 step:35605 [D loss: 0.499273, acc.: 73.44%] [G loss: 2.000696]\n",
      "epoch:37 step:35606 [D loss: 0.588127, acc.: 67.97%] [G loss: 1.590606]\n",
      "epoch:38 step:35607 [D loss: 0.927427, acc.: 41.41%] [G loss: 1.435023]\n",
      "epoch:38 step:35608 [D loss: 0.545329, acc.: 74.22%] [G loss: 1.112204]\n",
      "epoch:38 step:35609 [D loss: 0.765444, acc.: 53.12%] [G loss: 1.650369]\n",
      "epoch:38 step:35610 [D loss: 0.414632, acc.: 81.25%] [G loss: 1.759693]\n",
      "epoch:38 step:35611 [D loss: 0.602220, acc.: 67.97%] [G loss: 1.540888]\n",
      "epoch:38 step:35612 [D loss: 0.454139, acc.: 75.00%] [G loss: 1.528425]\n",
      "epoch:38 step:35613 [D loss: 0.532652, acc.: 75.00%] [G loss: 1.231175]\n",
      "epoch:38 step:35614 [D loss: 0.311421, acc.: 89.06%] [G loss: 2.247426]\n",
      "epoch:38 step:35615 [D loss: 0.546703, acc.: 71.88%] [G loss: 1.273432]\n",
      "epoch:38 step:35616 [D loss: 0.793701, acc.: 53.12%] [G loss: 1.443703]\n",
      "epoch:38 step:35617 [D loss: 0.400764, acc.: 82.03%] [G loss: 2.047818]\n",
      "epoch:38 step:35618 [D loss: 0.544750, acc.: 69.53%] [G loss: 1.321964]\n",
      "epoch:38 step:35619 [D loss: 0.581085, acc.: 69.53%] [G loss: 1.199586]\n",
      "epoch:38 step:35620 [D loss: 0.384220, acc.: 85.94%] [G loss: 1.737952]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:38 step:35621 [D loss: 0.428128, acc.: 78.91%] [G loss: 1.560560]\n",
      "epoch:38 step:35622 [D loss: 0.382301, acc.: 84.38%] [G loss: 1.966925]\n",
      "epoch:38 step:35623 [D loss: 0.636316, acc.: 61.72%] [G loss: 1.474422]\n",
      "epoch:38 step:35624 [D loss: 0.634880, acc.: 71.09%] [G loss: 1.389998]\n",
      "epoch:38 step:35625 [D loss: 0.505552, acc.: 75.78%] [G loss: 1.477155]\n",
      "epoch:38 step:35626 [D loss: 0.368246, acc.: 87.50%] [G loss: 1.792464]\n",
      "epoch:38 step:35627 [D loss: 0.688473, acc.: 60.16%] [G loss: 1.574517]\n",
      "epoch:38 step:35628 [D loss: 0.559137, acc.: 67.19%] [G loss: 1.586498]\n",
      "epoch:38 step:35629 [D loss: 0.626638, acc.: 63.28%] [G loss: 1.352570]\n",
      "epoch:38 step:35630 [D loss: 0.395061, acc.: 86.72%] [G loss: 2.138006]\n",
      "epoch:38 step:35631 [D loss: 0.444441, acc.: 82.81%] [G loss: 2.395459]\n",
      "epoch:38 step:35632 [D loss: 0.552478, acc.: 69.53%] [G loss: 1.351540]\n",
      "epoch:38 step:35633 [D loss: 0.513988, acc.: 72.66%] [G loss: 1.398531]\n",
      "epoch:38 step:35634 [D loss: 0.491795, acc.: 75.78%] [G loss: 1.350759]\n",
      "epoch:38 step:35635 [D loss: 0.304355, acc.: 90.62%] [G loss: 1.426860]\n",
      "epoch:38 step:35636 [D loss: 0.529812, acc.: 75.00%] [G loss: 1.407154]\n",
      "epoch:38 step:35637 [D loss: 0.688304, acc.: 59.38%] [G loss: 1.644413]\n",
      "epoch:38 step:35638 [D loss: 0.360646, acc.: 85.94%] [G loss: 1.223993]\n",
      "epoch:38 step:35639 [D loss: 0.526417, acc.: 68.75%] [G loss: 1.518570]\n",
      "epoch:38 step:35640 [D loss: 0.379296, acc.: 86.72%] [G loss: 1.575686]\n",
      "epoch:38 step:35641 [D loss: 0.518450, acc.: 72.66%] [G loss: 1.314788]\n",
      "epoch:38 step:35642 [D loss: 0.538430, acc.: 77.34%] [G loss: 1.168703]\n",
      "epoch:38 step:35643 [D loss: 0.427419, acc.: 82.81%] [G loss: 1.566429]\n",
      "epoch:38 step:35644 [D loss: 0.358972, acc.: 87.50%] [G loss: 1.547474]\n",
      "epoch:38 step:35645 [D loss: 0.741448, acc.: 54.69%] [G loss: 1.234011]\n",
      "epoch:38 step:35646 [D loss: 0.525950, acc.: 73.44%] [G loss: 1.150652]\n",
      "epoch:38 step:35647 [D loss: 0.339438, acc.: 91.41%] [G loss: 1.869671]\n",
      "epoch:38 step:35648 [D loss: 0.739925, acc.: 53.91%] [G loss: 1.385909]\n",
      "epoch:38 step:35649 [D loss: 0.479702, acc.: 77.34%] [G loss: 1.025462]\n",
      "epoch:38 step:35650 [D loss: 0.601658, acc.: 64.84%] [G loss: 1.421098]\n",
      "epoch:38 step:35651 [D loss: 0.616017, acc.: 66.41%] [G loss: 1.630499]\n",
      "epoch:38 step:35652 [D loss: 0.678784, acc.: 64.06%] [G loss: 1.088487]\n",
      "epoch:38 step:35653 [D loss: 0.452418, acc.: 79.69%] [G loss: 1.447166]\n",
      "epoch:38 step:35654 [D loss: 0.446494, acc.: 82.03%] [G loss: 1.689053]\n",
      "epoch:38 step:35655 [D loss: 0.434591, acc.: 85.16%] [G loss: 1.571758]\n",
      "epoch:38 step:35656 [D loss: 0.644653, acc.: 64.06%] [G loss: 1.765811]\n",
      "epoch:38 step:35657 [D loss: 0.412568, acc.: 85.16%] [G loss: 1.934714]\n",
      "epoch:38 step:35658 [D loss: 0.671706, acc.: 62.50%] [G loss: 1.144467]\n",
      "epoch:38 step:35659 [D loss: 0.434829, acc.: 79.69%] [G loss: 1.343012]\n",
      "epoch:38 step:35660 [D loss: 0.554810, acc.: 73.44%] [G loss: 1.197735]\n",
      "epoch:38 step:35661 [D loss: 0.390458, acc.: 82.81%] [G loss: 1.154152]\n",
      "epoch:38 step:35662 [D loss: 0.470188, acc.: 76.56%] [G loss: 1.764586]\n",
      "epoch:38 step:35663 [D loss: 0.537521, acc.: 73.44%] [G loss: 2.026017]\n",
      "epoch:38 step:35664 [D loss: 0.639613, acc.: 62.50%] [G loss: 1.772806]\n",
      "epoch:38 step:35665 [D loss: 0.700182, acc.: 59.38%] [G loss: 1.621639]\n",
      "epoch:38 step:35666 [D loss: 0.602691, acc.: 71.09%] [G loss: 1.530374]\n",
      "epoch:38 step:35667 [D loss: 0.450660, acc.: 76.56%] [G loss: 1.612189]\n",
      "epoch:38 step:35668 [D loss: 0.890335, acc.: 50.00%] [G loss: 1.686594]\n",
      "epoch:38 step:35669 [D loss: 0.655394, acc.: 66.41%] [G loss: 1.634462]\n",
      "epoch:38 step:35670 [D loss: 0.505660, acc.: 79.69%] [G loss: 1.386801]\n",
      "epoch:38 step:35671 [D loss: 0.426161, acc.: 81.25%] [G loss: 1.351042]\n",
      "epoch:38 step:35672 [D loss: 0.494330, acc.: 78.91%] [G loss: 1.837029]\n",
      "epoch:38 step:35673 [D loss: 0.552634, acc.: 71.09%] [G loss: 1.797116]\n",
      "epoch:38 step:35674 [D loss: 0.531967, acc.: 72.66%] [G loss: 1.713321]\n",
      "epoch:38 step:35675 [D loss: 0.441678, acc.: 82.81%] [G loss: 1.757110]\n",
      "epoch:38 step:35676 [D loss: 0.603352, acc.: 69.53%] [G loss: 1.063649]\n",
      "epoch:38 step:35677 [D loss: 0.433300, acc.: 82.03%] [G loss: 1.158868]\n",
      "epoch:38 step:35678 [D loss: 0.553790, acc.: 67.19%] [G loss: 1.618077]\n",
      "epoch:38 step:35679 [D loss: 0.418973, acc.: 84.38%] [G loss: 2.008688]\n",
      "epoch:38 step:35680 [D loss: 0.325734, acc.: 89.84%] [G loss: 1.763876]\n",
      "epoch:38 step:35681 [D loss: 0.423337, acc.: 83.59%] [G loss: 1.963989]\n",
      "epoch:38 step:35682 [D loss: 0.624001, acc.: 64.06%] [G loss: 1.438004]\n",
      "epoch:38 step:35683 [D loss: 0.510222, acc.: 77.34%] [G loss: 1.467866]\n",
      "epoch:38 step:35684 [D loss: 0.601511, acc.: 67.97%] [G loss: 1.305178]\n",
      "epoch:38 step:35685 [D loss: 0.652820, acc.: 62.50%] [G loss: 1.155285]\n",
      "epoch:38 step:35686 [D loss: 0.454212, acc.: 80.47%] [G loss: 1.718513]\n",
      "epoch:38 step:35687 [D loss: 0.696119, acc.: 56.25%] [G loss: 1.736737]\n",
      "epoch:38 step:35688 [D loss: 0.987068, acc.: 43.75%] [G loss: 1.286189]\n",
      "epoch:38 step:35689 [D loss: 0.662974, acc.: 66.41%] [G loss: 2.130862]\n",
      "epoch:38 step:35690 [D loss: 0.847875, acc.: 48.44%] [G loss: 1.213140]\n",
      "epoch:38 step:35691 [D loss: 0.533993, acc.: 71.09%] [G loss: 1.439577]\n",
      "epoch:38 step:35692 [D loss: 0.550072, acc.: 71.09%] [G loss: 1.469774]\n",
      "epoch:38 step:35693 [D loss: 0.578466, acc.: 71.09%] [G loss: 1.937350]\n",
      "epoch:38 step:35694 [D loss: 0.817511, acc.: 53.91%] [G loss: 1.530388]\n",
      "epoch:38 step:35695 [D loss: 0.448379, acc.: 83.59%] [G loss: 1.276353]\n",
      "epoch:38 step:35696 [D loss: 0.602450, acc.: 66.41%] [G loss: 1.599616]\n",
      "epoch:38 step:35697 [D loss: 0.318869, acc.: 88.28%] [G loss: 1.608996]\n",
      "epoch:38 step:35698 [D loss: 0.334397, acc.: 82.03%] [G loss: 1.492133]\n",
      "epoch:38 step:35699 [D loss: 0.557305, acc.: 71.09%] [G loss: 1.199132]\n",
      "epoch:38 step:35700 [D loss: 0.342599, acc.: 84.38%] [G loss: 0.955298]\n",
      "epoch:38 step:35701 [D loss: 0.418570, acc.: 78.91%] [G loss: 1.731646]\n",
      "epoch:38 step:35702 [D loss: 0.635650, acc.: 71.09%] [G loss: 1.229445]\n",
      "epoch:38 step:35703 [D loss: 0.542308, acc.: 71.88%] [G loss: 1.917258]\n",
      "epoch:38 step:35704 [D loss: 0.531323, acc.: 74.22%] [G loss: 1.274508]\n",
      "epoch:38 step:35705 [D loss: 0.662347, acc.: 64.84%] [G loss: 1.345305]\n",
      "epoch:38 step:35706 [D loss: 0.485420, acc.: 78.91%] [G loss: 1.152304]\n",
      "epoch:38 step:35707 [D loss: 0.513270, acc.: 76.56%] [G loss: 1.960012]\n",
      "epoch:38 step:35708 [D loss: 0.541960, acc.: 74.22%] [G loss: 1.910903]\n",
      "epoch:38 step:35709 [D loss: 0.505839, acc.: 76.56%] [G loss: 2.096751]\n",
      "epoch:38 step:35710 [D loss: 0.424829, acc.: 85.16%] [G loss: 1.676016]\n",
      "epoch:38 step:35711 [D loss: 0.698591, acc.: 63.28%] [G loss: 1.501560]\n",
      "epoch:38 step:35712 [D loss: 0.495402, acc.: 77.34%] [G loss: 1.709658]\n",
      "epoch:38 step:35713 [D loss: 0.602705, acc.: 68.75%] [G loss: 2.050373]\n",
      "epoch:38 step:35714 [D loss: 0.511906, acc.: 77.34%] [G loss: 1.844842]\n",
      "epoch:38 step:35715 [D loss: 0.423222, acc.: 83.59%] [G loss: 1.338064]\n",
      "epoch:38 step:35716 [D loss: 0.482507, acc.: 78.12%] [G loss: 1.576579]\n",
      "epoch:38 step:35717 [D loss: 0.419541, acc.: 81.25%] [G loss: 1.660154]\n",
      "epoch:38 step:35718 [D loss: 0.572350, acc.: 71.88%] [G loss: 1.807724]\n",
      "epoch:38 step:35719 [D loss: 0.434828, acc.: 80.47%] [G loss: 1.490320]\n",
      "epoch:38 step:35720 [D loss: 0.539877, acc.: 75.00%] [G loss: 1.913079]\n",
      "epoch:38 step:35721 [D loss: 0.685251, acc.: 60.16%] [G loss: 1.489754]\n",
      "epoch:38 step:35722 [D loss: 0.504454, acc.: 80.47%] [G loss: 1.475491]\n",
      "epoch:38 step:35723 [D loss: 0.456394, acc.: 80.47%] [G loss: 1.348527]\n",
      "epoch:38 step:35724 [D loss: 0.730196, acc.: 58.59%] [G loss: 1.295864]\n",
      "epoch:38 step:35725 [D loss: 0.572268, acc.: 70.31%] [G loss: 1.303165]\n",
      "epoch:38 step:35726 [D loss: 0.529267, acc.: 78.12%] [G loss: 1.196281]\n",
      "epoch:38 step:35727 [D loss: 0.476997, acc.: 75.00%] [G loss: 1.744086]\n",
      "epoch:38 step:35728 [D loss: 0.621627, acc.: 64.06%] [G loss: 1.590240]\n",
      "epoch:38 step:35729 [D loss: 0.434368, acc.: 81.25%] [G loss: 1.612457]\n",
      "epoch:38 step:35730 [D loss: 0.503051, acc.: 75.78%] [G loss: 0.956900]\n",
      "epoch:38 step:35731 [D loss: 0.443177, acc.: 78.91%] [G loss: 1.138850]\n",
      "epoch:38 step:35732 [D loss: 0.586816, acc.: 72.66%] [G loss: 1.397004]\n",
      "epoch:38 step:35733 [D loss: 0.665253, acc.: 62.50%] [G loss: 1.645856]\n",
      "epoch:38 step:35734 [D loss: 0.491724, acc.: 78.91%] [G loss: 1.282408]\n",
      "epoch:38 step:35735 [D loss: 0.405930, acc.: 85.16%] [G loss: 1.514101]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:38 step:35736 [D loss: 0.409635, acc.: 85.16%] [G loss: 1.834414]\n",
      "epoch:38 step:35737 [D loss: 0.423658, acc.: 78.91%] [G loss: 1.396432]\n",
      "epoch:38 step:35738 [D loss: 0.465925, acc.: 80.47%] [G loss: 1.380325]\n",
      "epoch:38 step:35739 [D loss: 0.323137, acc.: 87.50%] [G loss: 1.613540]\n",
      "epoch:38 step:35740 [D loss: 0.548956, acc.: 73.44%] [G loss: 1.391424]\n",
      "epoch:38 step:35741 [D loss: 0.462320, acc.: 80.47%] [G loss: 1.306365]\n",
      "epoch:38 step:35742 [D loss: 0.903122, acc.: 44.53%] [G loss: 1.525235]\n",
      "epoch:38 step:35743 [D loss: 0.451728, acc.: 75.78%] [G loss: 0.869887]\n",
      "epoch:38 step:35744 [D loss: 0.536833, acc.: 72.66%] [G loss: 1.691894]\n",
      "epoch:38 step:35745 [D loss: 0.591752, acc.: 66.41%] [G loss: 1.748513]\n",
      "epoch:38 step:35746 [D loss: 0.557678, acc.: 71.88%] [G loss: 1.272265]\n",
      "epoch:38 step:35747 [D loss: 0.652224, acc.: 67.19%] [G loss: 1.549469]\n",
      "epoch:38 step:35748 [D loss: 0.417300, acc.: 78.91%] [G loss: 1.885713]\n",
      "epoch:38 step:35749 [D loss: 0.658800, acc.: 62.50%] [G loss: 1.758112]\n",
      "epoch:38 step:35750 [D loss: 0.685884, acc.: 58.59%] [G loss: 1.405629]\n",
      "epoch:38 step:35751 [D loss: 0.396104, acc.: 85.16%] [G loss: 1.885662]\n",
      "epoch:38 step:35752 [D loss: 0.326412, acc.: 90.62%] [G loss: 2.074766]\n",
      "epoch:38 step:35753 [D loss: 0.543287, acc.: 72.66%] [G loss: 1.632327]\n",
      "epoch:38 step:35754 [D loss: 0.464173, acc.: 79.69%] [G loss: 1.978069]\n",
      "epoch:38 step:35755 [D loss: 0.437577, acc.: 81.25%] [G loss: 1.363934]\n",
      "epoch:38 step:35756 [D loss: 0.486306, acc.: 75.00%] [G loss: 1.316936]\n",
      "epoch:38 step:35757 [D loss: 0.607979, acc.: 67.97%] [G loss: 1.442320]\n",
      "epoch:38 step:35758 [D loss: 0.744249, acc.: 55.47%] [G loss: 0.922367]\n",
      "epoch:38 step:35759 [D loss: 0.365929, acc.: 88.28%] [G loss: 1.858174]\n",
      "epoch:38 step:35760 [D loss: 0.536350, acc.: 71.09%] [G loss: 2.096936]\n",
      "epoch:38 step:35761 [D loss: 0.589422, acc.: 71.88%] [G loss: 1.330042]\n",
      "epoch:38 step:35762 [D loss: 0.631934, acc.: 71.88%] [G loss: 0.865296]\n",
      "epoch:38 step:35763 [D loss: 0.500997, acc.: 75.78%] [G loss: 1.286908]\n",
      "epoch:38 step:35764 [D loss: 0.540293, acc.: 71.88%] [G loss: 1.826152]\n",
      "epoch:38 step:35765 [D loss: 0.348937, acc.: 87.50%] [G loss: 1.432371]\n",
      "epoch:38 step:35766 [D loss: 0.415317, acc.: 82.03%] [G loss: 1.517588]\n",
      "epoch:38 step:35767 [D loss: 0.503013, acc.: 75.78%] [G loss: 1.432048]\n",
      "epoch:38 step:35768 [D loss: 0.808372, acc.: 51.56%] [G loss: 1.343352]\n",
      "epoch:38 step:35769 [D loss: 0.524225, acc.: 71.09%] [G loss: 1.678442]\n",
      "epoch:38 step:35770 [D loss: 0.486697, acc.: 78.12%] [G loss: 2.280834]\n",
      "epoch:38 step:35771 [D loss: 0.547385, acc.: 66.41%] [G loss: 1.212344]\n",
      "epoch:38 step:35772 [D loss: 0.498024, acc.: 76.56%] [G loss: 0.806141]\n",
      "epoch:38 step:35773 [D loss: 0.493755, acc.: 74.22%] [G loss: 1.400543]\n",
      "epoch:38 step:35774 [D loss: 0.721814, acc.: 55.47%] [G loss: 1.535719]\n",
      "epoch:38 step:35775 [D loss: 0.677893, acc.: 62.50%] [G loss: 2.018195]\n",
      "epoch:38 step:35776 [D loss: 0.504967, acc.: 69.53%] [G loss: 1.619411]\n",
      "epoch:38 step:35777 [D loss: 0.535255, acc.: 75.78%] [G loss: 1.505837]\n",
      "epoch:38 step:35778 [D loss: 0.546206, acc.: 75.00%] [G loss: 1.956167]\n",
      "epoch:38 step:35779 [D loss: 0.526250, acc.: 73.44%] [G loss: 2.057195]\n",
      "epoch:38 step:35780 [D loss: 0.444844, acc.: 83.59%] [G loss: 1.346804]\n",
      "epoch:38 step:35781 [D loss: 0.519171, acc.: 75.00%] [G loss: 1.442625]\n",
      "epoch:38 step:35782 [D loss: 0.572927, acc.: 65.62%] [G loss: 1.633326]\n",
      "epoch:38 step:35783 [D loss: 0.331949, acc.: 88.28%] [G loss: 1.985659]\n",
      "epoch:38 step:35784 [D loss: 0.516684, acc.: 75.00%] [G loss: 1.252136]\n",
      "epoch:38 step:35785 [D loss: 0.421306, acc.: 79.69%] [G loss: 1.896829]\n",
      "epoch:38 step:35786 [D loss: 0.542453, acc.: 71.88%] [G loss: 1.007767]\n",
      "epoch:38 step:35787 [D loss: 0.445861, acc.: 81.25%] [G loss: 2.020706]\n",
      "epoch:38 step:35788 [D loss: 0.598588, acc.: 67.19%] [G loss: 1.546622]\n",
      "epoch:38 step:35789 [D loss: 0.464772, acc.: 79.69%] [G loss: 1.464472]\n",
      "epoch:38 step:35790 [D loss: 0.618710, acc.: 66.41%] [G loss: 1.399939]\n",
      "epoch:38 step:35791 [D loss: 0.481719, acc.: 76.56%] [G loss: 1.112281]\n",
      "epoch:38 step:35792 [D loss: 0.463979, acc.: 79.69%] [G loss: 1.221324]\n",
      "epoch:38 step:35793 [D loss: 0.537466, acc.: 74.22%] [G loss: 1.645045]\n",
      "epoch:38 step:35794 [D loss: 0.423098, acc.: 80.47%] [G loss: 1.356518]\n",
      "epoch:38 step:35795 [D loss: 0.669940, acc.: 62.50%] [G loss: 1.739913]\n",
      "epoch:38 step:35796 [D loss: 0.622222, acc.: 63.28%] [G loss: 1.060504]\n",
      "epoch:38 step:35797 [D loss: 0.630071, acc.: 64.06%] [G loss: 1.931309]\n",
      "epoch:38 step:35798 [D loss: 0.574202, acc.: 72.66%] [G loss: 1.325793]\n",
      "epoch:38 step:35799 [D loss: 0.528662, acc.: 71.88%] [G loss: 2.156209]\n",
      "epoch:38 step:35800 [D loss: 0.688891, acc.: 57.03%] [G loss: 1.645008]\n",
      "epoch:38 step:35801 [D loss: 0.393396, acc.: 85.16%] [G loss: 1.612009]\n",
      "epoch:38 step:35802 [D loss: 0.501492, acc.: 74.22%] [G loss: 1.255645]\n",
      "epoch:38 step:35803 [D loss: 0.479522, acc.: 82.81%] [G loss: 1.968260]\n",
      "epoch:38 step:35804 [D loss: 0.407818, acc.: 84.38%] [G loss: 1.291739]\n",
      "epoch:38 step:35805 [D loss: 0.396254, acc.: 83.59%] [G loss: 1.503948]\n",
      "epoch:38 step:35806 [D loss: 0.574514, acc.: 71.09%] [G loss: 1.336038]\n",
      "epoch:38 step:35807 [D loss: 0.336653, acc.: 86.72%] [G loss: 1.509819]\n",
      "epoch:38 step:35808 [D loss: 0.434737, acc.: 82.03%] [G loss: 1.648978]\n",
      "epoch:38 step:35809 [D loss: 0.535558, acc.: 75.00%] [G loss: 1.567862]\n",
      "epoch:38 step:35810 [D loss: 0.436170, acc.: 80.47%] [G loss: 2.000082]\n",
      "epoch:38 step:35811 [D loss: 0.648138, acc.: 65.62%] [G loss: 1.173278]\n",
      "epoch:38 step:35812 [D loss: 0.602562, acc.: 65.62%] [G loss: 1.504267]\n",
      "epoch:38 step:35813 [D loss: 0.775903, acc.: 61.72%] [G loss: 1.044005]\n",
      "epoch:38 step:35814 [D loss: 0.581367, acc.: 63.28%] [G loss: 1.016156]\n",
      "epoch:38 step:35815 [D loss: 0.658778, acc.: 57.81%] [G loss: 1.060553]\n",
      "epoch:38 step:35816 [D loss: 0.554972, acc.: 67.19%] [G loss: 1.620765]\n",
      "epoch:38 step:35817 [D loss: 0.576857, acc.: 69.53%] [G loss: 1.647747]\n",
      "epoch:38 step:35818 [D loss: 0.559515, acc.: 67.97%] [G loss: 1.664369]\n",
      "epoch:38 step:35819 [D loss: 0.789569, acc.: 54.69%] [G loss: 1.655794]\n",
      "epoch:38 step:35820 [D loss: 0.559918, acc.: 73.44%] [G loss: 1.297813]\n",
      "epoch:38 step:35821 [D loss: 0.481857, acc.: 78.12%] [G loss: 1.170272]\n",
      "epoch:38 step:35822 [D loss: 0.512322, acc.: 75.00%] [G loss: 1.419242]\n",
      "epoch:38 step:35823 [D loss: 0.582548, acc.: 69.53%] [G loss: 1.694002]\n",
      "epoch:38 step:35824 [D loss: 0.487237, acc.: 75.78%] [G loss: 1.578202]\n",
      "epoch:38 step:35825 [D loss: 0.463853, acc.: 80.47%] [G loss: 1.385469]\n",
      "epoch:38 step:35826 [D loss: 0.352364, acc.: 87.50%] [G loss: 1.369143]\n",
      "epoch:38 step:35827 [D loss: 0.805864, acc.: 54.69%] [G loss: 1.276151]\n",
      "epoch:38 step:35828 [D loss: 0.712553, acc.: 60.94%] [G loss: 1.284924]\n",
      "epoch:38 step:35829 [D loss: 0.494300, acc.: 72.66%] [G loss: 0.883166]\n",
      "epoch:38 step:35830 [D loss: 0.478248, acc.: 79.69%] [G loss: 1.772963]\n",
      "epoch:38 step:35831 [D loss: 0.487927, acc.: 79.69%] [G loss: 0.891256]\n",
      "epoch:38 step:35832 [D loss: 0.703088, acc.: 60.16%] [G loss: 1.323079]\n",
      "epoch:38 step:35833 [D loss: 0.523353, acc.: 75.00%] [G loss: 1.457301]\n",
      "epoch:38 step:35834 [D loss: 0.605894, acc.: 64.84%] [G loss: 1.826237]\n",
      "epoch:38 step:35835 [D loss: 0.321438, acc.: 88.28%] [G loss: 1.728604]\n",
      "epoch:38 step:35836 [D loss: 0.635174, acc.: 59.38%] [G loss: 1.138590]\n",
      "epoch:38 step:35837 [D loss: 0.537101, acc.: 71.88%] [G loss: 1.276546]\n",
      "epoch:38 step:35838 [D loss: 0.572278, acc.: 71.09%] [G loss: 1.372399]\n",
      "epoch:38 step:35839 [D loss: 0.657474, acc.: 63.28%] [G loss: 1.309743]\n",
      "epoch:38 step:35840 [D loss: 0.437850, acc.: 78.12%] [G loss: 1.665314]\n",
      "epoch:38 step:35841 [D loss: 0.422634, acc.: 83.59%] [G loss: 1.601965]\n",
      "epoch:38 step:35842 [D loss: 0.398701, acc.: 82.03%] [G loss: 1.594439]\n",
      "epoch:38 step:35843 [D loss: 0.507801, acc.: 77.34%] [G loss: 1.216672]\n",
      "epoch:38 step:35844 [D loss: 0.580311, acc.: 67.19%] [G loss: 0.926508]\n",
      "epoch:38 step:35845 [D loss: 0.343286, acc.: 85.94%] [G loss: 1.004595]\n",
      "epoch:38 step:35846 [D loss: 0.590084, acc.: 67.19%] [G loss: 1.217827]\n",
      "epoch:38 step:35847 [D loss: 0.500999, acc.: 71.09%] [G loss: 1.317153]\n",
      "epoch:38 step:35848 [D loss: 0.732059, acc.: 61.72%] [G loss: 1.419635]\n",
      "epoch:38 step:35849 [D loss: 0.588669, acc.: 68.75%] [G loss: 1.551037]\n",
      "epoch:38 step:35850 [D loss: 0.533800, acc.: 74.22%] [G loss: 1.264498]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:38 step:35851 [D loss: 0.441934, acc.: 78.12%] [G loss: 1.900183]\n",
      "epoch:38 step:35852 [D loss: 0.525248, acc.: 75.78%] [G loss: 1.849098]\n",
      "epoch:38 step:35853 [D loss: 0.684645, acc.: 63.28%] [G loss: 1.660892]\n",
      "epoch:38 step:35854 [D loss: 0.478294, acc.: 80.47%] [G loss: 2.000880]\n",
      "epoch:38 step:35855 [D loss: 0.413705, acc.: 82.03%] [G loss: 2.255993]\n",
      "epoch:38 step:35856 [D loss: 0.364164, acc.: 87.50%] [G loss: 1.601263]\n",
      "epoch:38 step:35857 [D loss: 0.497622, acc.: 71.88%] [G loss: 1.714170]\n",
      "epoch:38 step:35858 [D loss: 0.401569, acc.: 85.94%] [G loss: 1.734587]\n",
      "epoch:38 step:35859 [D loss: 0.540256, acc.: 73.44%] [G loss: 1.612472]\n",
      "epoch:38 step:35860 [D loss: 0.352163, acc.: 87.50%] [G loss: 1.812562]\n",
      "epoch:38 step:35861 [D loss: 0.536577, acc.: 73.44%] [G loss: 1.722691]\n",
      "epoch:38 step:35862 [D loss: 0.431362, acc.: 82.03%] [G loss: 1.987007]\n",
      "epoch:38 step:35863 [D loss: 0.521362, acc.: 71.88%] [G loss: 1.341990]\n",
      "epoch:38 step:35864 [D loss: 0.502426, acc.: 77.34%] [G loss: 1.629831]\n",
      "epoch:38 step:35865 [D loss: 0.457605, acc.: 79.69%] [G loss: 1.573570]\n",
      "epoch:38 step:35866 [D loss: 0.467007, acc.: 76.56%] [G loss: 1.552453]\n",
      "epoch:38 step:35867 [D loss: 0.436926, acc.: 82.03%] [G loss: 1.368831]\n",
      "epoch:38 step:35868 [D loss: 0.636272, acc.: 65.62%] [G loss: 1.752310]\n",
      "epoch:38 step:35869 [D loss: 0.577494, acc.: 70.31%] [G loss: 1.291428]\n",
      "epoch:38 step:35870 [D loss: 0.576071, acc.: 70.31%] [G loss: 1.288554]\n",
      "epoch:38 step:35871 [D loss: 0.409407, acc.: 83.59%] [G loss: 1.812085]\n",
      "epoch:38 step:35872 [D loss: 0.574607, acc.: 71.09%] [G loss: 1.950832]\n",
      "epoch:38 step:35873 [D loss: 0.600432, acc.: 66.41%] [G loss: 1.530957]\n",
      "epoch:38 step:35874 [D loss: 0.431996, acc.: 80.47%] [G loss: 1.688836]\n",
      "epoch:38 step:35875 [D loss: 0.539628, acc.: 72.66%] [G loss: 1.603806]\n",
      "epoch:38 step:35876 [D loss: 0.412261, acc.: 82.81%] [G loss: 1.822017]\n",
      "epoch:38 step:35877 [D loss: 0.378346, acc.: 84.38%] [G loss: 1.887639]\n",
      "epoch:38 step:35878 [D loss: 0.428871, acc.: 82.81%] [G loss: 1.950948]\n",
      "epoch:38 step:35879 [D loss: 0.502407, acc.: 77.34%] [G loss: 1.613554]\n",
      "epoch:38 step:35880 [D loss: 0.475100, acc.: 76.56%] [G loss: 1.278300]\n",
      "epoch:38 step:35881 [D loss: 0.600986, acc.: 70.31%] [G loss: 1.945366]\n",
      "epoch:38 step:35882 [D loss: 0.794961, acc.: 52.34%] [G loss: 0.878223]\n",
      "epoch:38 step:35883 [D loss: 0.430809, acc.: 78.91%] [G loss: 1.396997]\n",
      "epoch:38 step:35884 [D loss: 0.622317, acc.: 66.41%] [G loss: 1.335619]\n",
      "epoch:38 step:35885 [D loss: 0.546197, acc.: 67.97%] [G loss: 1.353694]\n",
      "epoch:38 step:35886 [D loss: 0.578251, acc.: 71.09%] [G loss: 2.210445]\n",
      "epoch:38 step:35887 [D loss: 0.579843, acc.: 71.88%] [G loss: 1.288189]\n",
      "epoch:38 step:35888 [D loss: 0.512754, acc.: 74.22%] [G loss: 1.540962]\n",
      "epoch:38 step:35889 [D loss: 0.469165, acc.: 79.69%] [G loss: 1.996671]\n",
      "epoch:38 step:35890 [D loss: 0.695638, acc.: 60.94%] [G loss: 1.384529]\n",
      "epoch:38 step:35891 [D loss: 0.536920, acc.: 75.78%] [G loss: 1.261834]\n",
      "epoch:38 step:35892 [D loss: 0.635570, acc.: 68.75%] [G loss: 1.456014]\n",
      "epoch:38 step:35893 [D loss: 0.375515, acc.: 85.16%] [G loss: 1.784649]\n",
      "epoch:38 step:35894 [D loss: 0.665664, acc.: 62.50%] [G loss: 1.492622]\n",
      "epoch:38 step:35895 [D loss: 0.430456, acc.: 84.38%] [G loss: 1.391023]\n",
      "epoch:38 step:35896 [D loss: 0.600020, acc.: 70.31%] [G loss: 1.249286]\n",
      "epoch:38 step:35897 [D loss: 0.656606, acc.: 64.06%] [G loss: 1.135875]\n",
      "epoch:38 step:35898 [D loss: 0.590274, acc.: 67.97%] [G loss: 1.203579]\n",
      "epoch:38 step:35899 [D loss: 0.499609, acc.: 78.12%] [G loss: 1.431466]\n",
      "epoch:38 step:35900 [D loss: 0.389688, acc.: 85.16%] [G loss: 1.384250]\n",
      "epoch:38 step:35901 [D loss: 0.646625, acc.: 64.06%] [G loss: 1.632011]\n",
      "epoch:38 step:35902 [D loss: 0.523590, acc.: 75.78%] [G loss: 1.780364]\n",
      "epoch:38 step:35903 [D loss: 0.523388, acc.: 73.44%] [G loss: 1.622706]\n",
      "epoch:38 step:35904 [D loss: 0.690491, acc.: 61.72%] [G loss: 2.038120]\n",
      "epoch:38 step:35905 [D loss: 0.609617, acc.: 67.19%] [G loss: 1.509356]\n",
      "epoch:38 step:35906 [D loss: 0.581041, acc.: 62.50%] [G loss: 1.344115]\n",
      "epoch:38 step:35907 [D loss: 0.608969, acc.: 63.28%] [G loss: 1.805055]\n",
      "epoch:38 step:35908 [D loss: 0.431646, acc.: 79.69%] [G loss: 1.914334]\n",
      "epoch:38 step:35909 [D loss: 0.598132, acc.: 67.19%] [G loss: 1.591673]\n",
      "epoch:38 step:35910 [D loss: 0.616204, acc.: 68.75%] [G loss: 1.289099]\n",
      "epoch:38 step:35911 [D loss: 0.672063, acc.: 60.16%] [G loss: 1.542403]\n",
      "epoch:38 step:35912 [D loss: 0.397571, acc.: 83.59%] [G loss: 2.105763]\n",
      "epoch:38 step:35913 [D loss: 0.786880, acc.: 50.00%] [G loss: 1.394718]\n",
      "epoch:38 step:35914 [D loss: 0.601563, acc.: 65.62%] [G loss: 1.245154]\n",
      "epoch:38 step:35915 [D loss: 0.385267, acc.: 86.72%] [G loss: 1.505960]\n",
      "epoch:38 step:35916 [D loss: 0.441782, acc.: 82.03%] [G loss: 1.053655]\n",
      "epoch:38 step:35917 [D loss: 0.843052, acc.: 52.34%] [G loss: 1.320497]\n",
      "epoch:38 step:35918 [D loss: 0.554311, acc.: 74.22%] [G loss: 1.785110]\n",
      "epoch:38 step:35919 [D loss: 0.400989, acc.: 83.59%] [G loss: 1.764606]\n",
      "epoch:38 step:35920 [D loss: 0.353176, acc.: 86.72%] [G loss: 1.275197]\n",
      "epoch:38 step:35921 [D loss: 0.535724, acc.: 76.56%] [G loss: 1.381494]\n",
      "epoch:38 step:35922 [D loss: 0.547042, acc.: 72.66%] [G loss: 1.859179]\n",
      "epoch:38 step:35923 [D loss: 0.566586, acc.: 74.22%] [G loss: 0.928689]\n",
      "epoch:38 step:35924 [D loss: 0.648941, acc.: 61.72%] [G loss: 1.665607]\n",
      "epoch:38 step:35925 [D loss: 0.611641, acc.: 66.41%] [G loss: 1.302003]\n",
      "epoch:38 step:35926 [D loss: 0.513248, acc.: 75.00%] [G loss: 2.043568]\n",
      "epoch:38 step:35927 [D loss: 0.661987, acc.: 65.62%] [G loss: 1.616497]\n",
      "epoch:38 step:35928 [D loss: 0.573288, acc.: 67.19%] [G loss: 1.566474]\n",
      "epoch:38 step:35929 [D loss: 0.489417, acc.: 79.69%] [G loss: 1.868973]\n",
      "epoch:38 step:35930 [D loss: 0.459906, acc.: 78.91%] [G loss: 1.354531]\n",
      "epoch:38 step:35931 [D loss: 0.390375, acc.: 87.50%] [G loss: 1.460239]\n",
      "epoch:38 step:35932 [D loss: 0.574558, acc.: 71.88%] [G loss: 1.504390]\n",
      "epoch:38 step:35933 [D loss: 0.495168, acc.: 73.44%] [G loss: 0.935093]\n",
      "epoch:38 step:35934 [D loss: 0.491782, acc.: 75.00%] [G loss: 1.524129]\n",
      "epoch:38 step:35935 [D loss: 0.382687, acc.: 85.94%] [G loss: 1.800428]\n",
      "epoch:38 step:35936 [D loss: 0.465085, acc.: 80.47%] [G loss: 1.744045]\n",
      "epoch:38 step:35937 [D loss: 0.488121, acc.: 74.22%] [G loss: 1.449845]\n",
      "epoch:38 step:35938 [D loss: 0.565411, acc.: 72.66%] [G loss: 1.273684]\n",
      "epoch:38 step:35939 [D loss: 0.698161, acc.: 59.38%] [G loss: 1.155919]\n",
      "epoch:38 step:35940 [D loss: 0.497355, acc.: 78.91%] [G loss: 0.939631]\n",
      "epoch:38 step:35941 [D loss: 0.514990, acc.: 78.12%] [G loss: 1.264611]\n",
      "epoch:38 step:35942 [D loss: 0.526859, acc.: 71.09%] [G loss: 1.606326]\n",
      "epoch:38 step:35943 [D loss: 0.489515, acc.: 78.91%] [G loss: 2.013208]\n",
      "epoch:38 step:35944 [D loss: 0.344367, acc.: 85.16%] [G loss: 2.128391]\n",
      "epoch:38 step:35945 [D loss: 0.504919, acc.: 78.12%] [G loss: 1.401193]\n",
      "epoch:38 step:35946 [D loss: 0.533421, acc.: 72.66%] [G loss: 1.453773]\n",
      "epoch:38 step:35947 [D loss: 0.537563, acc.: 75.78%] [G loss: 1.586265]\n",
      "epoch:38 step:35948 [D loss: 0.721366, acc.: 60.16%] [G loss: 1.625357]\n",
      "epoch:38 step:35949 [D loss: 0.457401, acc.: 76.56%] [G loss: 1.339871]\n",
      "epoch:38 step:35950 [D loss: 0.555963, acc.: 71.09%] [G loss: 1.007267]\n",
      "epoch:38 step:35951 [D loss: 0.634203, acc.: 66.41%] [G loss: 1.563680]\n",
      "epoch:38 step:35952 [D loss: 0.571185, acc.: 74.22%] [G loss: 1.696159]\n",
      "epoch:38 step:35953 [D loss: 0.494848, acc.: 77.34%] [G loss: 1.389433]\n",
      "epoch:38 step:35954 [D loss: 0.374505, acc.: 89.06%] [G loss: 1.685708]\n",
      "epoch:38 step:35955 [D loss: 0.577906, acc.: 65.62%] [G loss: 1.629472]\n",
      "epoch:38 step:35956 [D loss: 0.595617, acc.: 66.41%] [G loss: 1.197293]\n",
      "epoch:38 step:35957 [D loss: 0.780648, acc.: 53.91%] [G loss: 1.818623]\n",
      "epoch:38 step:35958 [D loss: 0.514353, acc.: 76.56%] [G loss: 1.550061]\n",
      "epoch:38 step:35959 [D loss: 0.465443, acc.: 78.91%] [G loss: 1.598863]\n",
      "epoch:38 step:35960 [D loss: 0.258866, acc.: 95.31%] [G loss: 1.003406]\n",
      "epoch:38 step:35961 [D loss: 0.476673, acc.: 74.22%] [G loss: 1.467648]\n",
      "epoch:38 step:35962 [D loss: 0.378877, acc.: 86.72%] [G loss: 1.685617]\n",
      "epoch:38 step:35963 [D loss: 0.421476, acc.: 82.81%] [G loss: 1.758709]\n",
      "epoch:38 step:35964 [D loss: 0.592904, acc.: 67.97%] [G loss: 2.251968]\n",
      "epoch:38 step:35965 [D loss: 0.586969, acc.: 70.31%] [G loss: 1.671807]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:38 step:35966 [D loss: 0.442203, acc.: 80.47%] [G loss: 1.186385]\n",
      "epoch:38 step:35967 [D loss: 0.508395, acc.: 75.78%] [G loss: 1.762302]\n",
      "epoch:38 step:35968 [D loss: 0.535221, acc.: 73.44%] [G loss: 1.715286]\n",
      "epoch:38 step:35969 [D loss: 0.431297, acc.: 81.25%] [G loss: 1.260132]\n",
      "epoch:38 step:35970 [D loss: 0.477470, acc.: 78.91%] [G loss: 1.110667]\n",
      "epoch:38 step:35971 [D loss: 0.478973, acc.: 78.12%] [G loss: 1.779722]\n",
      "epoch:38 step:35972 [D loss: 0.405933, acc.: 85.94%] [G loss: 1.274972]\n",
      "epoch:38 step:35973 [D loss: 0.550679, acc.: 74.22%] [G loss: 2.051591]\n",
      "epoch:38 step:35974 [D loss: 0.418307, acc.: 78.12%] [G loss: 1.594503]\n",
      "epoch:38 step:35975 [D loss: 0.520386, acc.: 68.75%] [G loss: 2.036080]\n",
      "epoch:38 step:35976 [D loss: 0.688245, acc.: 67.19%] [G loss: 1.325416]\n",
      "epoch:38 step:35977 [D loss: 0.533988, acc.: 70.31%] [G loss: 1.441624]\n",
      "epoch:38 step:35978 [D loss: 0.460714, acc.: 77.34%] [G loss: 1.653077]\n",
      "epoch:38 step:35979 [D loss: 0.557603, acc.: 67.97%] [G loss: 2.242949]\n",
      "epoch:38 step:35980 [D loss: 0.980976, acc.: 42.97%] [G loss: 1.019884]\n",
      "epoch:38 step:35981 [D loss: 0.558932, acc.: 69.53%] [G loss: 1.523676]\n",
      "epoch:38 step:35982 [D loss: 0.599776, acc.: 69.53%] [G loss: 2.017410]\n",
      "epoch:38 step:35983 [D loss: 0.612444, acc.: 66.41%] [G loss: 1.506852]\n",
      "epoch:38 step:35984 [D loss: 0.551970, acc.: 67.97%] [G loss: 1.392365]\n",
      "epoch:38 step:35985 [D loss: 0.544430, acc.: 71.09%] [G loss: 1.611840]\n",
      "epoch:38 step:35986 [D loss: 0.540028, acc.: 71.88%] [G loss: 1.328030]\n",
      "epoch:38 step:35987 [D loss: 0.629467, acc.: 64.06%] [G loss: 1.400663]\n",
      "epoch:38 step:35988 [D loss: 0.385561, acc.: 85.94%] [G loss: 1.967038]\n",
      "epoch:38 step:35989 [D loss: 0.521182, acc.: 73.44%] [G loss: 1.416378]\n",
      "epoch:38 step:35990 [D loss: 0.340600, acc.: 88.28%] [G loss: 1.988985]\n",
      "epoch:38 step:35991 [D loss: 0.627399, acc.: 67.97%] [G loss: 1.468867]\n",
      "epoch:38 step:35992 [D loss: 0.539706, acc.: 73.44%] [G loss: 2.309211]\n",
      "epoch:38 step:35993 [D loss: 0.440132, acc.: 82.81%] [G loss: 1.249344]\n",
      "epoch:38 step:35994 [D loss: 0.521842, acc.: 71.09%] [G loss: 1.477314]\n",
      "epoch:38 step:35995 [D loss: 0.493412, acc.: 73.44%] [G loss: 1.365842]\n",
      "epoch:38 step:35996 [D loss: 0.498175, acc.: 75.00%] [G loss: 1.273693]\n",
      "epoch:38 step:35997 [D loss: 0.816848, acc.: 52.34%] [G loss: 1.570142]\n",
      "epoch:38 step:35998 [D loss: 0.336743, acc.: 88.28%] [G loss: 1.791521]\n",
      "epoch:38 step:35999 [D loss: 0.678947, acc.: 64.06%] [G loss: 1.343201]\n",
      "epoch:38 step:36000 [D loss: 0.371100, acc.: 89.06%] [G loss: 1.386092]\n",
      "epoch:38 step:36001 [D loss: 0.495478, acc.: 76.56%] [G loss: 1.560335]\n",
      "epoch:38 step:36002 [D loss: 0.303143, acc.: 89.06%] [G loss: 1.792666]\n",
      "epoch:38 step:36003 [D loss: 0.501892, acc.: 76.56%] [G loss: 1.699366]\n",
      "epoch:38 step:36004 [D loss: 0.571596, acc.: 75.78%] [G loss: 1.796402]\n",
      "epoch:38 step:36005 [D loss: 0.336640, acc.: 89.84%] [G loss: 1.868194]\n",
      "epoch:38 step:36006 [D loss: 0.671589, acc.: 62.50%] [G loss: 1.138821]\n",
      "epoch:38 step:36007 [D loss: 0.659237, acc.: 62.50%] [G loss: 1.472868]\n",
      "epoch:38 step:36008 [D loss: 0.553245, acc.: 74.22%] [G loss: 1.666073]\n",
      "epoch:38 step:36009 [D loss: 0.400244, acc.: 84.38%] [G loss: 2.212264]\n",
      "epoch:38 step:36010 [D loss: 0.764207, acc.: 54.69%] [G loss: 1.381452]\n",
      "epoch:38 step:36011 [D loss: 0.607339, acc.: 67.19%] [G loss: 1.365420]\n",
      "epoch:38 step:36012 [D loss: 0.375821, acc.: 87.50%] [G loss: 1.843486]\n",
      "epoch:38 step:36013 [D loss: 0.728025, acc.: 55.47%] [G loss: 1.223725]\n",
      "epoch:38 step:36014 [D loss: 0.436856, acc.: 75.78%] [G loss: 1.385955]\n",
      "epoch:38 step:36015 [D loss: 0.718917, acc.: 57.81%] [G loss: 1.450839]\n",
      "epoch:38 step:36016 [D loss: 0.751502, acc.: 55.47%] [G loss: 0.929144]\n",
      "epoch:38 step:36017 [D loss: 0.466018, acc.: 78.91%] [G loss: 1.546418]\n",
      "epoch:38 step:36018 [D loss: 0.653821, acc.: 63.28%] [G loss: 1.323807]\n",
      "epoch:38 step:36019 [D loss: 0.863930, acc.: 46.88%] [G loss: 0.826152]\n",
      "epoch:38 step:36020 [D loss: 0.627584, acc.: 72.66%] [G loss: 1.538646]\n",
      "epoch:38 step:36021 [D loss: 0.449408, acc.: 84.38%] [G loss: 1.610880]\n",
      "epoch:38 step:36022 [D loss: 0.332967, acc.: 88.28%] [G loss: 1.219688]\n",
      "epoch:38 step:36023 [D loss: 0.471571, acc.: 75.78%] [G loss: 1.661927]\n",
      "epoch:38 step:36024 [D loss: 0.665002, acc.: 60.94%] [G loss: 1.114173]\n",
      "epoch:38 step:36025 [D loss: 0.522381, acc.: 78.12%] [G loss: 1.464548]\n",
      "epoch:38 step:36026 [D loss: 0.432677, acc.: 82.81%] [G loss: 1.586096]\n",
      "epoch:38 step:36027 [D loss: 0.398961, acc.: 84.38%] [G loss: 1.228456]\n",
      "epoch:38 step:36028 [D loss: 0.699000, acc.: 57.03%] [G loss: 1.514070]\n",
      "epoch:38 step:36029 [D loss: 0.605242, acc.: 69.53%] [G loss: 1.440855]\n",
      "epoch:38 step:36030 [D loss: 0.427103, acc.: 81.25%] [G loss: 1.586484]\n",
      "epoch:38 step:36031 [D loss: 0.467889, acc.: 78.12%] [G loss: 1.223142]\n",
      "epoch:38 step:36032 [D loss: 0.616657, acc.: 67.97%] [G loss: 1.431112]\n",
      "epoch:38 step:36033 [D loss: 0.703219, acc.: 60.16%] [G loss: 1.187084]\n",
      "epoch:38 step:36034 [D loss: 0.669594, acc.: 61.72%] [G loss: 1.638807]\n",
      "epoch:38 step:36035 [D loss: 0.478003, acc.: 81.25%] [G loss: 1.441676]\n",
      "epoch:38 step:36036 [D loss: 0.630820, acc.: 67.19%] [G loss: 1.393347]\n",
      "epoch:38 step:36037 [D loss: 0.631337, acc.: 65.62%] [G loss: 2.323157]\n",
      "epoch:38 step:36038 [D loss: 0.353306, acc.: 88.28%] [G loss: 1.940309]\n",
      "epoch:38 step:36039 [D loss: 0.466998, acc.: 75.78%] [G loss: 1.456032]\n",
      "epoch:38 step:36040 [D loss: 0.603275, acc.: 67.97%] [G loss: 1.535242]\n",
      "epoch:38 step:36041 [D loss: 0.436544, acc.: 83.59%] [G loss: 1.450086]\n",
      "epoch:38 step:36042 [D loss: 0.638623, acc.: 64.84%] [G loss: 1.418123]\n",
      "epoch:38 step:36043 [D loss: 0.539090, acc.: 75.00%] [G loss: 1.393058]\n",
      "epoch:38 step:36044 [D loss: 0.425996, acc.: 79.69%] [G loss: 1.381921]\n",
      "epoch:38 step:36045 [D loss: 0.502762, acc.: 74.22%] [G loss: 1.602963]\n",
      "epoch:38 step:36046 [D loss: 0.576637, acc.: 68.75%] [G loss: 1.763761]\n",
      "epoch:38 step:36047 [D loss: 0.377563, acc.: 84.38%] [G loss: 1.369091]\n",
      "epoch:38 step:36048 [D loss: 0.489366, acc.: 78.91%] [G loss: 2.061123]\n",
      "epoch:38 step:36049 [D loss: 0.573724, acc.: 69.53%] [G loss: 1.802902]\n",
      "epoch:38 step:36050 [D loss: 0.479518, acc.: 75.78%] [G loss: 1.615134]\n",
      "epoch:38 step:36051 [D loss: 0.459635, acc.: 78.91%] [G loss: 1.808567]\n",
      "epoch:38 step:36052 [D loss: 0.622579, acc.: 67.19%] [G loss: 1.241840]\n",
      "epoch:38 step:36053 [D loss: 0.479804, acc.: 77.34%] [G loss: 1.829460]\n",
      "epoch:38 step:36054 [D loss: 0.461424, acc.: 79.69%] [G loss: 1.573570]\n",
      "epoch:38 step:36055 [D loss: 0.487432, acc.: 78.12%] [G loss: 1.311869]\n",
      "epoch:38 step:36056 [D loss: 0.670584, acc.: 59.38%] [G loss: 1.381252]\n",
      "epoch:38 step:36057 [D loss: 0.432517, acc.: 77.34%] [G loss: 1.420241]\n",
      "epoch:38 step:36058 [D loss: 0.684573, acc.: 64.06%] [G loss: 1.130650]\n",
      "epoch:38 step:36059 [D loss: 0.391008, acc.: 82.81%] [G loss: 1.906399]\n",
      "epoch:38 step:36060 [D loss: 0.532106, acc.: 75.00%] [G loss: 1.469012]\n",
      "epoch:38 step:36061 [D loss: 0.586485, acc.: 70.31%] [G loss: 1.437134]\n",
      "epoch:38 step:36062 [D loss: 0.954857, acc.: 47.66%] [G loss: 1.543447]\n",
      "epoch:38 step:36063 [D loss: 0.539629, acc.: 71.09%] [G loss: 1.130261]\n",
      "epoch:38 step:36064 [D loss: 0.350708, acc.: 87.50%] [G loss: 1.694548]\n",
      "epoch:38 step:36065 [D loss: 0.535145, acc.: 72.66%] [G loss: 1.541317]\n",
      "epoch:38 step:36066 [D loss: 0.458667, acc.: 78.91%] [G loss: 1.631347]\n",
      "epoch:38 step:36067 [D loss: 0.742011, acc.: 56.25%] [G loss: 1.217189]\n",
      "epoch:38 step:36068 [D loss: 0.729612, acc.: 58.59%] [G loss: 1.217633]\n",
      "epoch:38 step:36069 [D loss: 0.724516, acc.: 59.38%] [G loss: 1.475658]\n",
      "epoch:38 step:36070 [D loss: 0.445322, acc.: 82.03%] [G loss: 1.359605]\n",
      "epoch:38 step:36071 [D loss: 0.588763, acc.: 71.09%] [G loss: 1.359775]\n",
      "epoch:38 step:36072 [D loss: 0.436259, acc.: 80.47%] [G loss: 2.334486]\n",
      "epoch:38 step:36073 [D loss: 0.555020, acc.: 66.41%] [G loss: 2.099539]\n",
      "epoch:38 step:36074 [D loss: 0.562749, acc.: 70.31%] [G loss: 1.561064]\n",
      "epoch:38 step:36075 [D loss: 0.452618, acc.: 83.59%] [G loss: 1.980460]\n",
      "epoch:38 step:36076 [D loss: 0.682152, acc.: 60.94%] [G loss: 1.645750]\n",
      "epoch:38 step:36077 [D loss: 0.613761, acc.: 68.75%] [G loss: 2.044671]\n",
      "epoch:38 step:36078 [D loss: 0.635274, acc.: 64.84%] [G loss: 1.734179]\n",
      "epoch:38 step:36079 [D loss: 0.584646, acc.: 67.97%] [G loss: 1.490960]\n",
      "epoch:38 step:36080 [D loss: 0.581445, acc.: 69.53%] [G loss: 1.461975]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:38 step:36081 [D loss: 0.570920, acc.: 71.88%] [G loss: 1.538431]\n",
      "epoch:38 step:36082 [D loss: 0.411690, acc.: 81.25%] [G loss: 1.903857]\n",
      "epoch:38 step:36083 [D loss: 0.596636, acc.: 67.97%] [G loss: 1.541394]\n",
      "epoch:38 step:36084 [D loss: 0.462725, acc.: 81.25%] [G loss: 1.183866]\n",
      "epoch:38 step:36085 [D loss: 0.545221, acc.: 76.56%] [G loss: 1.076496]\n",
      "epoch:38 step:36086 [D loss: 0.483026, acc.: 78.12%] [G loss: 1.866345]\n",
      "epoch:38 step:36087 [D loss: 0.645827, acc.: 65.62%] [G loss: 1.995379]\n",
      "epoch:38 step:36088 [D loss: 0.550105, acc.: 72.66%] [G loss: 0.896445]\n",
      "epoch:38 step:36089 [D loss: 0.472935, acc.: 75.78%] [G loss: 1.932735]\n",
      "epoch:38 step:36090 [D loss: 0.436135, acc.: 81.25%] [G loss: 1.308612]\n",
      "epoch:38 step:36091 [D loss: 0.646199, acc.: 60.94%] [G loss: 1.313250]\n",
      "epoch:38 step:36092 [D loss: 0.563402, acc.: 73.44%] [G loss: 1.653988]\n",
      "epoch:38 step:36093 [D loss: 0.392683, acc.: 85.16%] [G loss: 1.466276]\n",
      "epoch:38 step:36094 [D loss: 0.393947, acc.: 84.38%] [G loss: 1.470407]\n",
      "epoch:38 step:36095 [D loss: 0.710314, acc.: 60.16%] [G loss: 0.951994]\n",
      "epoch:38 step:36096 [D loss: 0.468995, acc.: 82.03%] [G loss: 2.254545]\n",
      "epoch:38 step:36097 [D loss: 0.379144, acc.: 83.59%] [G loss: 1.400727]\n",
      "epoch:38 step:36098 [D loss: 0.601052, acc.: 65.62%] [G loss: 1.463273]\n",
      "epoch:38 step:36099 [D loss: 0.624160, acc.: 64.06%] [G loss: 1.425069]\n",
      "epoch:38 step:36100 [D loss: 0.480379, acc.: 77.34%] [G loss: 1.886404]\n",
      "epoch:38 step:36101 [D loss: 0.381614, acc.: 85.94%] [G loss: 1.562403]\n",
      "epoch:38 step:36102 [D loss: 0.678096, acc.: 60.16%] [G loss: 1.354488]\n",
      "epoch:38 step:36103 [D loss: 0.520301, acc.: 75.00%] [G loss: 1.351558]\n",
      "epoch:38 step:36104 [D loss: 0.625953, acc.: 66.41%] [G loss: 1.174108]\n",
      "epoch:38 step:36105 [D loss: 0.427315, acc.: 83.59%] [G loss: 2.007222]\n",
      "epoch:38 step:36106 [D loss: 0.672879, acc.: 65.62%] [G loss: 1.356851]\n",
      "epoch:38 step:36107 [D loss: 0.670800, acc.: 67.19%] [G loss: 2.022332]\n",
      "epoch:38 step:36108 [D loss: 0.517326, acc.: 76.56%] [G loss: 1.341005]\n",
      "epoch:38 step:36109 [D loss: 0.489801, acc.: 78.12%] [G loss: 0.992756]\n",
      "epoch:38 step:36110 [D loss: 0.461721, acc.: 75.78%] [G loss: 1.797031]\n",
      "epoch:38 step:36111 [D loss: 0.521276, acc.: 75.78%] [G loss: 1.560028]\n",
      "epoch:38 step:36112 [D loss: 0.534231, acc.: 70.31%] [G loss: 1.419098]\n",
      "epoch:38 step:36113 [D loss: 0.581787, acc.: 71.88%] [G loss: 1.857823]\n",
      "epoch:38 step:36114 [D loss: 0.523827, acc.: 77.34%] [G loss: 1.122546]\n",
      "epoch:38 step:36115 [D loss: 0.429676, acc.: 80.47%] [G loss: 1.251053]\n",
      "epoch:38 step:36116 [D loss: 0.430801, acc.: 82.81%] [G loss: 1.543902]\n",
      "epoch:38 step:36117 [D loss: 0.670098, acc.: 60.16%] [G loss: 1.004357]\n",
      "epoch:38 step:36118 [D loss: 0.474560, acc.: 76.56%] [G loss: 1.784376]\n",
      "epoch:38 step:36119 [D loss: 0.486452, acc.: 71.88%] [G loss: 1.800121]\n",
      "epoch:38 step:36120 [D loss: 0.612652, acc.: 69.53%] [G loss: 1.426124]\n",
      "epoch:38 step:36121 [D loss: 0.367452, acc.: 87.50%] [G loss: 1.788881]\n",
      "epoch:38 step:36122 [D loss: 0.547739, acc.: 74.22%] [G loss: 1.563860]\n",
      "epoch:38 step:36123 [D loss: 0.640459, acc.: 62.50%] [G loss: 2.048216]\n",
      "epoch:38 step:36124 [D loss: 0.622414, acc.: 68.75%] [G loss: 2.182425]\n",
      "epoch:38 step:36125 [D loss: 0.413685, acc.: 84.38%] [G loss: 1.594582]\n",
      "epoch:38 step:36126 [D loss: 0.468764, acc.: 82.03%] [G loss: 1.799216]\n",
      "epoch:38 step:36127 [D loss: 0.562179, acc.: 74.22%] [G loss: 1.206334]\n",
      "epoch:38 step:36128 [D loss: 0.519088, acc.: 68.75%] [G loss: 1.746471]\n",
      "epoch:38 step:36129 [D loss: 0.524723, acc.: 76.56%] [G loss: 1.374628]\n",
      "epoch:38 step:36130 [D loss: 0.370036, acc.: 87.50%] [G loss: 1.025707]\n",
      "epoch:38 step:36131 [D loss: 0.546952, acc.: 71.88%] [G loss: 1.759902]\n",
      "epoch:38 step:36132 [D loss: 0.351333, acc.: 89.06%] [G loss: 1.964113]\n",
      "epoch:38 step:36133 [D loss: 0.587909, acc.: 75.00%] [G loss: 1.296200]\n",
      "epoch:38 step:36134 [D loss: 0.667351, acc.: 65.62%] [G loss: 1.481473]\n",
      "epoch:38 step:36135 [D loss: 0.503840, acc.: 74.22%] [G loss: 1.462509]\n",
      "epoch:38 step:36136 [D loss: 0.417359, acc.: 83.59%] [G loss: 1.714644]\n",
      "epoch:38 step:36137 [D loss: 0.539040, acc.: 71.88%] [G loss: 1.628204]\n",
      "epoch:38 step:36138 [D loss: 0.493861, acc.: 75.00%] [G loss: 1.983509]\n",
      "epoch:38 step:36139 [D loss: 0.419696, acc.: 84.38%] [G loss: 1.905656]\n",
      "epoch:38 step:36140 [D loss: 0.545913, acc.: 75.00%] [G loss: 1.630892]\n",
      "epoch:38 step:36141 [D loss: 0.405154, acc.: 84.38%] [G loss: 2.214700]\n",
      "epoch:38 step:36142 [D loss: 0.406474, acc.: 84.38%] [G loss: 1.404080]\n",
      "epoch:38 step:36143 [D loss: 0.581012, acc.: 62.50%] [G loss: 1.456576]\n",
      "epoch:38 step:36144 [D loss: 0.526870, acc.: 69.53%] [G loss: 1.259582]\n",
      "epoch:38 step:36145 [D loss: 0.544985, acc.: 72.66%] [G loss: 1.499890]\n",
      "epoch:38 step:36146 [D loss: 0.274397, acc.: 92.19%] [G loss: 1.775524]\n",
      "epoch:38 step:36147 [D loss: 0.502720, acc.: 76.56%] [G loss: 1.540671]\n",
      "epoch:38 step:36148 [D loss: 0.466191, acc.: 79.69%] [G loss: 1.368761]\n",
      "epoch:38 step:36149 [D loss: 0.364734, acc.: 87.50%] [G loss: 1.535509]\n",
      "epoch:38 step:36150 [D loss: 0.488797, acc.: 76.56%] [G loss: 1.761471]\n",
      "epoch:38 step:36151 [D loss: 0.457721, acc.: 76.56%] [G loss: 1.532797]\n",
      "epoch:38 step:36152 [D loss: 0.355762, acc.: 87.50%] [G loss: 1.511077]\n",
      "epoch:38 step:36153 [D loss: 0.649626, acc.: 66.41%] [G loss: 1.085282]\n",
      "epoch:38 step:36154 [D loss: 0.679106, acc.: 59.38%] [G loss: 1.236641]\n",
      "epoch:38 step:36155 [D loss: 0.730172, acc.: 63.28%] [G loss: 1.160272]\n",
      "epoch:38 step:36156 [D loss: 0.527331, acc.: 75.00%] [G loss: 1.246052]\n",
      "epoch:38 step:36157 [D loss: 0.553384, acc.: 71.88%] [G loss: 1.338292]\n",
      "epoch:38 step:36158 [D loss: 0.456714, acc.: 79.69%] [G loss: 2.449797]\n",
      "epoch:38 step:36159 [D loss: 0.745776, acc.: 52.34%] [G loss: 1.841612]\n",
      "epoch:38 step:36160 [D loss: 0.746262, acc.: 54.69%] [G loss: 1.207580]\n",
      "epoch:38 step:36161 [D loss: 0.390551, acc.: 84.38%] [G loss: 1.481899]\n",
      "epoch:38 step:36162 [D loss: 0.568903, acc.: 71.09%] [G loss: 1.563364]\n",
      "epoch:38 step:36163 [D loss: 0.378911, acc.: 80.47%] [G loss: 1.239080]\n",
      "epoch:38 step:36164 [D loss: 0.627909, acc.: 65.62%] [G loss: 1.932898]\n",
      "epoch:38 step:36165 [D loss: 0.429836, acc.: 83.59%] [G loss: 1.704014]\n",
      "epoch:38 step:36166 [D loss: 0.535249, acc.: 73.44%] [G loss: 1.373272]\n",
      "epoch:38 step:36167 [D loss: 0.462721, acc.: 79.69%] [G loss: 1.767778]\n",
      "epoch:38 step:36168 [D loss: 0.691541, acc.: 65.62%] [G loss: 1.586917]\n",
      "epoch:38 step:36169 [D loss: 0.455179, acc.: 80.47%] [G loss: 1.333296]\n",
      "epoch:38 step:36170 [D loss: 0.602491, acc.: 61.72%] [G loss: 1.522756]\n",
      "epoch:38 step:36171 [D loss: 0.506993, acc.: 75.00%] [G loss: 1.544575]\n",
      "epoch:38 step:36172 [D loss: 0.361916, acc.: 88.28%] [G loss: 2.400124]\n",
      "epoch:38 step:36173 [D loss: 0.442811, acc.: 82.81%] [G loss: 1.335958]\n",
      "epoch:38 step:36174 [D loss: 0.785564, acc.: 54.69%] [G loss: 1.178263]\n",
      "epoch:38 step:36175 [D loss: 0.385611, acc.: 85.94%] [G loss: 1.556753]\n",
      "epoch:38 step:36176 [D loss: 0.457958, acc.: 77.34%] [G loss: 1.267206]\n",
      "epoch:38 step:36177 [D loss: 0.436533, acc.: 82.81%] [G loss: 1.452972]\n",
      "epoch:38 step:36178 [D loss: 0.427030, acc.: 78.91%] [G loss: 1.452157]\n",
      "epoch:38 step:36179 [D loss: 0.467280, acc.: 78.12%] [G loss: 1.399330]\n",
      "epoch:38 step:36180 [D loss: 0.498745, acc.: 74.22%] [G loss: 1.819392]\n",
      "epoch:38 step:36181 [D loss: 0.652307, acc.: 63.28%] [G loss: 0.902854]\n",
      "epoch:38 step:36182 [D loss: 0.420552, acc.: 78.91%] [G loss: 1.321686]\n",
      "epoch:38 step:36183 [D loss: 0.723374, acc.: 57.81%] [G loss: 1.447375]\n",
      "epoch:38 step:36184 [D loss: 0.514096, acc.: 75.78%] [G loss: 1.320804]\n",
      "epoch:38 step:36185 [D loss: 0.515886, acc.: 79.69%] [G loss: 1.499147]\n",
      "epoch:38 step:36186 [D loss: 0.692911, acc.: 60.94%] [G loss: 1.468853]\n",
      "epoch:38 step:36187 [D loss: 0.483029, acc.: 76.56%] [G loss: 1.398883]\n",
      "epoch:38 step:36188 [D loss: 0.443656, acc.: 82.81%] [G loss: 2.466930]\n",
      "epoch:38 step:36189 [D loss: 0.441840, acc.: 77.34%] [G loss: 2.100924]\n",
      "epoch:38 step:36190 [D loss: 0.490265, acc.: 79.69%] [G loss: 0.890703]\n",
      "epoch:38 step:36191 [D loss: 0.426477, acc.: 81.25%] [G loss: 1.707478]\n",
      "epoch:38 step:36192 [D loss: 0.481191, acc.: 74.22%] [G loss: 1.278197]\n",
      "epoch:38 step:36193 [D loss: 0.463256, acc.: 78.12%] [G loss: 1.659600]\n",
      "epoch:38 step:36194 [D loss: 0.799940, acc.: 53.91%] [G loss: 1.083310]\n",
      "epoch:38 step:36195 [D loss: 0.492982, acc.: 74.22%] [G loss: 1.197587]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:38 step:36196 [D loss: 0.508932, acc.: 77.34%] [G loss: 1.905421]\n",
      "epoch:38 step:36197 [D loss: 0.399510, acc.: 85.16%] [G loss: 2.206887]\n",
      "epoch:38 step:36198 [D loss: 0.484978, acc.: 82.03%] [G loss: 1.678572]\n",
      "epoch:38 step:36199 [D loss: 0.446255, acc.: 79.69%] [G loss: 1.114227]\n",
      "epoch:38 step:36200 [D loss: 0.573500, acc.: 72.66%] [G loss: 1.156874]\n",
      "epoch:38 step:36201 [D loss: 0.523441, acc.: 71.09%] [G loss: 1.370942]\n",
      "epoch:38 step:36202 [D loss: 0.494898, acc.: 74.22%] [G loss: 1.277917]\n",
      "epoch:38 step:36203 [D loss: 0.753001, acc.: 57.81%] [G loss: 1.688728]\n",
      "epoch:38 step:36204 [D loss: 0.431621, acc.: 78.91%] [G loss: 1.402412]\n",
      "epoch:38 step:36205 [D loss: 0.476443, acc.: 78.12%] [G loss: 1.804063]\n",
      "epoch:38 step:36206 [D loss: 0.375973, acc.: 86.72%] [G loss: 1.467076]\n",
      "epoch:38 step:36207 [D loss: 0.515020, acc.: 71.88%] [G loss: 1.507792]\n",
      "epoch:38 step:36208 [D loss: 0.521185, acc.: 74.22%] [G loss: 1.082446]\n",
      "epoch:38 step:36209 [D loss: 0.466918, acc.: 78.91%] [G loss: 1.818486]\n",
      "epoch:38 step:36210 [D loss: 0.501829, acc.: 73.44%] [G loss: 1.742554]\n",
      "epoch:38 step:36211 [D loss: 0.551357, acc.: 73.44%] [G loss: 1.306427]\n",
      "epoch:38 step:36212 [D loss: 0.576393, acc.: 72.66%] [G loss: 1.956615]\n",
      "epoch:38 step:36213 [D loss: 0.444761, acc.: 83.59%] [G loss: 1.326669]\n",
      "epoch:38 step:36214 [D loss: 0.526284, acc.: 72.66%] [G loss: 1.462932]\n",
      "epoch:38 step:36215 [D loss: 0.629425, acc.: 67.19%] [G loss: 1.749155]\n",
      "epoch:38 step:36216 [D loss: 0.628838, acc.: 71.88%] [G loss: 1.250428]\n",
      "epoch:38 step:36217 [D loss: 0.522210, acc.: 77.34%] [G loss: 2.031607]\n",
      "epoch:38 step:36218 [D loss: 0.526514, acc.: 73.44%] [G loss: 1.645866]\n",
      "epoch:38 step:36219 [D loss: 0.583580, acc.: 67.19%] [G loss: 1.933262]\n",
      "epoch:38 step:36220 [D loss: 0.649478, acc.: 61.72%] [G loss: 1.398778]\n",
      "epoch:38 step:36221 [D loss: 0.807332, acc.: 54.69%] [G loss: 1.473753]\n",
      "epoch:38 step:36222 [D loss: 0.456228, acc.: 78.91%] [G loss: 1.547266]\n",
      "epoch:38 step:36223 [D loss: 0.467031, acc.: 81.25%] [G loss: 2.002836]\n",
      "epoch:38 step:36224 [D loss: 0.232467, acc.: 94.53%] [G loss: 1.721406]\n",
      "epoch:38 step:36225 [D loss: 0.503595, acc.: 76.56%] [G loss: 1.836050]\n",
      "epoch:38 step:36226 [D loss: 0.530128, acc.: 72.66%] [G loss: 1.783029]\n",
      "epoch:38 step:36227 [D loss: 0.564650, acc.: 72.66%] [G loss: 1.457776]\n",
      "epoch:38 step:36228 [D loss: 0.532796, acc.: 69.53%] [G loss: 1.718994]\n",
      "epoch:38 step:36229 [D loss: 0.375365, acc.: 87.50%] [G loss: 1.774185]\n",
      "epoch:38 step:36230 [D loss: 0.514401, acc.: 75.00%] [G loss: 1.877879]\n",
      "epoch:38 step:36231 [D loss: 0.424277, acc.: 81.25%] [G loss: 1.342471]\n",
      "epoch:38 step:36232 [D loss: 0.478780, acc.: 78.12%] [G loss: 1.658011]\n",
      "epoch:38 step:36233 [D loss: 0.375430, acc.: 83.59%] [G loss: 1.928473]\n",
      "epoch:38 step:36234 [D loss: 0.385262, acc.: 84.38%] [G loss: 1.823079]\n",
      "epoch:38 step:36235 [D loss: 0.583392, acc.: 71.09%] [G loss: 1.282956]\n",
      "epoch:38 step:36236 [D loss: 0.474776, acc.: 77.34%] [G loss: 1.467579]\n",
      "epoch:38 step:36237 [D loss: 0.664470, acc.: 64.06%] [G loss: 1.464388]\n",
      "epoch:38 step:36238 [D loss: 0.386060, acc.: 85.94%] [G loss: 1.381773]\n",
      "epoch:38 step:36239 [D loss: 0.408835, acc.: 82.03%] [G loss: 1.382553]\n",
      "epoch:38 step:36240 [D loss: 0.510471, acc.: 78.12%] [G loss: 1.437454]\n",
      "epoch:38 step:36241 [D loss: 0.706840, acc.: 62.50%] [G loss: 1.662076]\n",
      "epoch:38 step:36242 [D loss: 0.472028, acc.: 81.25%] [G loss: 1.185471]\n",
      "epoch:38 step:36243 [D loss: 0.398908, acc.: 84.38%] [G loss: 1.560231]\n",
      "epoch:38 step:36244 [D loss: 0.410201, acc.: 79.69%] [G loss: 2.045998]\n",
      "epoch:38 step:36245 [D loss: 0.506841, acc.: 71.09%] [G loss: 1.676196]\n",
      "epoch:38 step:36246 [D loss: 0.391424, acc.: 85.16%] [G loss: 1.732313]\n",
      "epoch:38 step:36247 [D loss: 0.558674, acc.: 75.78%] [G loss: 1.839018]\n",
      "epoch:38 step:36248 [D loss: 0.452690, acc.: 83.59%] [G loss: 1.469275]\n",
      "epoch:38 step:36249 [D loss: 0.861172, acc.: 46.09%] [G loss: 1.426135]\n",
      "epoch:38 step:36250 [D loss: 0.498891, acc.: 78.91%] [G loss: 1.685598]\n",
      "epoch:38 step:36251 [D loss: 0.631554, acc.: 67.19%] [G loss: 1.745412]\n",
      "epoch:38 step:36252 [D loss: 0.522049, acc.: 75.78%] [G loss: 1.751210]\n",
      "epoch:38 step:36253 [D loss: 0.555464, acc.: 73.44%] [G loss: 1.264175]\n",
      "epoch:38 step:36254 [D loss: 0.525365, acc.: 75.00%] [G loss: 1.226804]\n",
      "epoch:38 step:36255 [D loss: 0.548068, acc.: 75.78%] [G loss: 1.610936]\n",
      "epoch:38 step:36256 [D loss: 0.577628, acc.: 71.09%] [G loss: 1.746084]\n",
      "epoch:38 step:36257 [D loss: 0.400681, acc.: 83.59%] [G loss: 1.479270]\n",
      "epoch:38 step:36258 [D loss: 0.394763, acc.: 81.25%] [G loss: 1.773802]\n",
      "epoch:38 step:36259 [D loss: 0.394564, acc.: 86.72%] [G loss: 1.839478]\n",
      "epoch:38 step:36260 [D loss: 0.476585, acc.: 75.78%] [G loss: 1.746320]\n",
      "epoch:38 step:36261 [D loss: 0.539245, acc.: 70.31%] [G loss: 1.310376]\n",
      "epoch:38 step:36262 [D loss: 0.697575, acc.: 58.59%] [G loss: 1.472492]\n",
      "epoch:38 step:36263 [D loss: 0.536090, acc.: 67.19%] [G loss: 1.501236]\n",
      "epoch:38 step:36264 [D loss: 0.461507, acc.: 82.03%] [G loss: 2.144749]\n",
      "epoch:38 step:36265 [D loss: 0.467932, acc.: 77.34%] [G loss: 1.499702]\n",
      "epoch:38 step:36266 [D loss: 0.556360, acc.: 70.31%] [G loss: 1.158708]\n",
      "epoch:38 step:36267 [D loss: 0.527869, acc.: 71.09%] [G loss: 1.808584]\n",
      "epoch:38 step:36268 [D loss: 0.578001, acc.: 66.41%] [G loss: 1.663419]\n",
      "epoch:38 step:36269 [D loss: 0.737068, acc.: 60.16%] [G loss: 1.443986]\n",
      "epoch:38 step:36270 [D loss: 0.439109, acc.: 80.47%] [G loss: 1.185264]\n",
      "epoch:38 step:36271 [D loss: 0.555691, acc.: 75.00%] [G loss: 1.197513]\n",
      "epoch:38 step:36272 [D loss: 0.391800, acc.: 85.16%] [G loss: 1.379629]\n",
      "epoch:38 step:36273 [D loss: 0.618261, acc.: 66.41%] [G loss: 1.438603]\n",
      "epoch:38 step:36274 [D loss: 0.814255, acc.: 52.34%] [G loss: 1.541697]\n",
      "epoch:38 step:36275 [D loss: 0.437397, acc.: 79.69%] [G loss: 1.479718]\n",
      "epoch:38 step:36276 [D loss: 0.361036, acc.: 85.16%] [G loss: 1.832730]\n",
      "epoch:38 step:36277 [D loss: 0.500035, acc.: 76.56%] [G loss: 1.807940]\n",
      "epoch:38 step:36278 [D loss: 0.599252, acc.: 66.41%] [G loss: 1.416638]\n",
      "epoch:38 step:36279 [D loss: 0.728283, acc.: 54.69%] [G loss: 1.241339]\n",
      "epoch:38 step:36280 [D loss: 0.480894, acc.: 77.34%] [G loss: 1.269090]\n",
      "epoch:38 step:36281 [D loss: 0.475827, acc.: 76.56%] [G loss: 1.450168]\n",
      "epoch:38 step:36282 [D loss: 0.352501, acc.: 89.84%] [G loss: 1.576077]\n",
      "epoch:38 step:36283 [D loss: 0.452338, acc.: 78.91%] [G loss: 1.274550]\n",
      "epoch:38 step:36284 [D loss: 0.662423, acc.: 65.62%] [G loss: 1.124460]\n",
      "epoch:38 step:36285 [D loss: 0.688277, acc.: 54.69%] [G loss: 1.259957]\n",
      "epoch:38 step:36286 [D loss: 0.606516, acc.: 67.97%] [G loss: 1.537531]\n",
      "epoch:38 step:36287 [D loss: 0.486966, acc.: 78.91%] [G loss: 1.256476]\n",
      "epoch:38 step:36288 [D loss: 0.468530, acc.: 80.47%] [G loss: 1.135559]\n",
      "epoch:38 step:36289 [D loss: 0.620126, acc.: 67.19%] [G loss: 1.467107]\n",
      "epoch:38 step:36290 [D loss: 0.498316, acc.: 73.44%] [G loss: 1.534924]\n",
      "epoch:38 step:36291 [D loss: 0.491845, acc.: 75.00%] [G loss: 1.711711]\n",
      "epoch:38 step:36292 [D loss: 0.391714, acc.: 85.94%] [G loss: 1.476868]\n",
      "epoch:38 step:36293 [D loss: 0.343695, acc.: 84.38%] [G loss: 2.067025]\n",
      "epoch:38 step:36294 [D loss: 0.419810, acc.: 82.03%] [G loss: 1.358893]\n",
      "epoch:38 step:36295 [D loss: 0.706364, acc.: 61.72%] [G loss: 1.232012]\n",
      "epoch:38 step:36296 [D loss: 0.591079, acc.: 71.09%] [G loss: 1.883236]\n",
      "epoch:38 step:36297 [D loss: 0.500216, acc.: 74.22%] [G loss: 1.797320]\n",
      "epoch:38 step:36298 [D loss: 0.398787, acc.: 84.38%] [G loss: 1.526503]\n",
      "epoch:38 step:36299 [D loss: 0.618875, acc.: 67.97%] [G loss: 1.745748]\n",
      "epoch:38 step:36300 [D loss: 0.496905, acc.: 78.91%] [G loss: 1.077770]\n",
      "epoch:38 step:36301 [D loss: 0.474404, acc.: 78.91%] [G loss: 1.738964]\n",
      "epoch:38 step:36302 [D loss: 0.659609, acc.: 64.84%] [G loss: 1.345706]\n",
      "epoch:38 step:36303 [D loss: 0.522930, acc.: 75.00%] [G loss: 1.495064]\n",
      "epoch:38 step:36304 [D loss: 0.472010, acc.: 76.56%] [G loss: 2.032773]\n",
      "epoch:38 step:36305 [D loss: 0.310570, acc.: 90.62%] [G loss: 1.527349]\n",
      "epoch:38 step:36306 [D loss: 0.499648, acc.: 78.91%] [G loss: 1.553137]\n",
      "epoch:38 step:36307 [D loss: 0.485582, acc.: 76.56%] [G loss: 1.366998]\n",
      "epoch:38 step:36308 [D loss: 0.561642, acc.: 71.88%] [G loss: 1.266955]\n",
      "epoch:38 step:36309 [D loss: 0.494320, acc.: 76.56%] [G loss: 2.003600]\n",
      "epoch:38 step:36310 [D loss: 0.575082, acc.: 72.66%] [G loss: 1.524939]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:38 step:36311 [D loss: 0.554351, acc.: 69.53%] [G loss: 1.238679]\n",
      "epoch:38 step:36312 [D loss: 0.469556, acc.: 77.34%] [G loss: 1.634755]\n",
      "epoch:38 step:36313 [D loss: 0.501103, acc.: 79.69%] [G loss: 1.731190]\n",
      "epoch:38 step:36314 [D loss: 0.536217, acc.: 76.56%] [G loss: 1.096461]\n",
      "epoch:38 step:36315 [D loss: 0.750160, acc.: 58.59%] [G loss: 1.266912]\n",
      "epoch:38 step:36316 [D loss: 0.608543, acc.: 66.41%] [G loss: 1.500812]\n",
      "epoch:38 step:36317 [D loss: 0.484158, acc.: 72.66%] [G loss: 1.534684]\n",
      "epoch:38 step:36318 [D loss: 0.461581, acc.: 82.81%] [G loss: 1.507377]\n",
      "epoch:38 step:36319 [D loss: 0.665165, acc.: 62.50%] [G loss: 1.676812]\n",
      "epoch:38 step:36320 [D loss: 0.473078, acc.: 78.91%] [G loss: 1.856024]\n",
      "epoch:38 step:36321 [D loss: 0.535387, acc.: 70.31%] [G loss: 1.756710]\n",
      "epoch:38 step:36322 [D loss: 0.295253, acc.: 90.62%] [G loss: 2.157308]\n",
      "epoch:38 step:36323 [D loss: 0.423577, acc.: 82.81%] [G loss: 1.667864]\n",
      "epoch:38 step:36324 [D loss: 0.506202, acc.: 76.56%] [G loss: 1.619003]\n",
      "epoch:38 step:36325 [D loss: 0.728913, acc.: 61.72%] [G loss: 1.560711]\n",
      "epoch:38 step:36326 [D loss: 0.495990, acc.: 79.69%] [G loss: 1.490268]\n",
      "epoch:38 step:36327 [D loss: 0.704831, acc.: 64.84%] [G loss: 1.284917]\n",
      "epoch:38 step:36328 [D loss: 0.448859, acc.: 78.91%] [G loss: 2.370932]\n",
      "epoch:38 step:36329 [D loss: 0.440980, acc.: 78.91%] [G loss: 1.194397]\n",
      "epoch:38 step:36330 [D loss: 0.421615, acc.: 83.59%] [G loss: 1.346318]\n",
      "epoch:38 step:36331 [D loss: 0.404298, acc.: 85.16%] [G loss: 1.565710]\n",
      "epoch:38 step:36332 [D loss: 0.696178, acc.: 57.03%] [G loss: 1.093436]\n",
      "epoch:38 step:36333 [D loss: 0.421787, acc.: 81.25%] [G loss: 1.299636]\n",
      "epoch:38 step:36334 [D loss: 0.624163, acc.: 69.53%] [G loss: 1.620863]\n",
      "epoch:38 step:36335 [D loss: 0.497133, acc.: 77.34%] [G loss: 1.557780]\n",
      "epoch:38 step:36336 [D loss: 0.685169, acc.: 62.50%] [G loss: 1.878590]\n",
      "epoch:38 step:36337 [D loss: 0.499629, acc.: 75.00%] [G loss: 1.426849]\n",
      "epoch:38 step:36338 [D loss: 0.384478, acc.: 86.72%] [G loss: 1.455105]\n",
      "epoch:38 step:36339 [D loss: 0.531658, acc.: 79.69%] [G loss: 1.306336]\n",
      "epoch:38 step:36340 [D loss: 0.509486, acc.: 71.88%] [G loss: 1.465733]\n",
      "epoch:38 step:36341 [D loss: 0.552763, acc.: 73.44%] [G loss: 1.481629]\n",
      "epoch:38 step:36342 [D loss: 0.472886, acc.: 72.66%] [G loss: 1.682087]\n",
      "epoch:38 step:36343 [D loss: 0.500672, acc.: 77.34%] [G loss: 1.989514]\n",
      "epoch:38 step:36344 [D loss: 0.666307, acc.: 62.50%] [G loss: 1.199192]\n",
      "epoch:38 step:36345 [D loss: 0.794460, acc.: 50.00%] [G loss: 1.293902]\n",
      "epoch:38 step:36346 [D loss: 0.578162, acc.: 68.75%] [G loss: 1.243201]\n",
      "epoch:38 step:36347 [D loss: 0.715823, acc.: 56.25%] [G loss: 1.623875]\n",
      "epoch:38 step:36348 [D loss: 0.655667, acc.: 66.41%] [G loss: 1.485398]\n",
      "epoch:38 step:36349 [D loss: 0.724462, acc.: 55.47%] [G loss: 1.210327]\n",
      "epoch:38 step:36350 [D loss: 0.539932, acc.: 71.88%] [G loss: 1.192613]\n",
      "epoch:38 step:36351 [D loss: 0.519115, acc.: 75.00%] [G loss: 2.056931]\n",
      "epoch:38 step:36352 [D loss: 0.553154, acc.: 78.12%] [G loss: 2.079768]\n",
      "epoch:38 step:36353 [D loss: 0.506152, acc.: 75.00%] [G loss: 1.056042]\n",
      "epoch:38 step:36354 [D loss: 0.310582, acc.: 89.06%] [G loss: 2.308236]\n",
      "epoch:38 step:36355 [D loss: 0.626570, acc.: 67.19%] [G loss: 1.790606]\n",
      "epoch:38 step:36356 [D loss: 0.346471, acc.: 84.38%] [G loss: 1.482807]\n",
      "epoch:38 step:36357 [D loss: 0.600907, acc.: 63.28%] [G loss: 1.228396]\n",
      "epoch:38 step:36358 [D loss: 0.550587, acc.: 73.44%] [G loss: 1.459297]\n",
      "epoch:38 step:36359 [D loss: 0.527601, acc.: 76.56%] [G loss: 1.186712]\n",
      "epoch:38 step:36360 [D loss: 0.471215, acc.: 75.78%] [G loss: 1.970693]\n",
      "epoch:38 step:36361 [D loss: 0.478950, acc.: 75.00%] [G loss: 1.466596]\n",
      "epoch:38 step:36362 [D loss: 0.537001, acc.: 76.56%] [G loss: 0.987982]\n",
      "epoch:38 step:36363 [D loss: 0.613270, acc.: 65.62%] [G loss: 1.777453]\n",
      "epoch:38 step:36364 [D loss: 0.539203, acc.: 74.22%] [G loss: 1.544509]\n",
      "epoch:38 step:36365 [D loss: 0.493950, acc.: 76.56%] [G loss: 1.557430]\n",
      "epoch:38 step:36366 [D loss: 0.347149, acc.: 89.06%] [G loss: 1.630502]\n",
      "epoch:38 step:36367 [D loss: 0.624027, acc.: 68.75%] [G loss: 1.696529]\n",
      "epoch:38 step:36368 [D loss: 0.536200, acc.: 70.31%] [G loss: 1.942343]\n",
      "epoch:38 step:36369 [D loss: 0.524252, acc.: 71.09%] [G loss: 1.402175]\n",
      "epoch:38 step:36370 [D loss: 0.693518, acc.: 58.59%] [G loss: 1.732356]\n",
      "epoch:38 step:36371 [D loss: 0.433644, acc.: 83.59%] [G loss: 2.232955]\n",
      "epoch:38 step:36372 [D loss: 0.429585, acc.: 78.91%] [G loss: 1.791621]\n",
      "epoch:38 step:36373 [D loss: 0.447807, acc.: 75.78%] [G loss: 1.206914]\n",
      "epoch:38 step:36374 [D loss: 0.847858, acc.: 49.22%] [G loss: 0.823156]\n",
      "epoch:38 step:36375 [D loss: 0.683043, acc.: 59.38%] [G loss: 1.598403]\n",
      "epoch:38 step:36376 [D loss: 0.562595, acc.: 66.41%] [G loss: 1.656982]\n",
      "epoch:38 step:36377 [D loss: 0.431527, acc.: 82.03%] [G loss: 1.363789]\n",
      "epoch:38 step:36378 [D loss: 0.398837, acc.: 85.94%] [G loss: 1.620932]\n",
      "epoch:38 step:36379 [D loss: 0.505661, acc.: 75.00%] [G loss: 1.247923]\n",
      "epoch:38 step:36380 [D loss: 0.421759, acc.: 84.38%] [G loss: 1.574912]\n",
      "epoch:38 step:36381 [D loss: 0.495724, acc.: 78.91%] [G loss: 1.637154]\n",
      "epoch:38 step:36382 [D loss: 0.466448, acc.: 81.25%] [G loss: 1.362090]\n",
      "epoch:38 step:36383 [D loss: 0.670354, acc.: 60.94%] [G loss: 1.502272]\n",
      "epoch:38 step:36384 [D loss: 0.589687, acc.: 68.75%] [G loss: 1.326703]\n",
      "epoch:38 step:36385 [D loss: 0.463824, acc.: 81.25%] [G loss: 1.861912]\n",
      "epoch:38 step:36386 [D loss: 0.551559, acc.: 76.56%] [G loss: 1.858235]\n",
      "epoch:38 step:36387 [D loss: 0.369104, acc.: 87.50%] [G loss: 1.317324]\n",
      "epoch:38 step:36388 [D loss: 0.777061, acc.: 53.91%] [G loss: 1.368326]\n",
      "epoch:38 step:36389 [D loss: 0.365023, acc.: 84.38%] [G loss: 1.780775]\n",
      "epoch:38 step:36390 [D loss: 0.324558, acc.: 89.06%] [G loss: 2.247215]\n",
      "epoch:38 step:36391 [D loss: 0.367705, acc.: 89.84%] [G loss: 1.912936]\n",
      "epoch:38 step:36392 [D loss: 0.633272, acc.: 65.62%] [G loss: 2.211122]\n",
      "epoch:38 step:36393 [D loss: 0.486037, acc.: 80.47%] [G loss: 1.611138]\n",
      "epoch:38 step:36394 [D loss: 0.519052, acc.: 75.00%] [G loss: 1.348321]\n",
      "epoch:38 step:36395 [D loss: 0.482370, acc.: 77.34%] [G loss: 1.154008]\n",
      "epoch:38 step:36396 [D loss: 0.452766, acc.: 78.12%] [G loss: 1.300311]\n",
      "epoch:38 step:36397 [D loss: 0.430090, acc.: 82.03%] [G loss: 1.600534]\n",
      "epoch:38 step:36398 [D loss: 0.423348, acc.: 82.03%] [G loss: 1.576041]\n",
      "epoch:38 step:36399 [D loss: 0.472291, acc.: 76.56%] [G loss: 1.189601]\n",
      "epoch:38 step:36400 [D loss: 0.600150, acc.: 68.75%] [G loss: 1.092080]\n",
      "epoch:38 step:36401 [D loss: 0.628537, acc.: 68.75%] [G loss: 1.088829]\n",
      "epoch:38 step:36402 [D loss: 0.500786, acc.: 79.69%] [G loss: 1.386507]\n",
      "epoch:38 step:36403 [D loss: 0.387282, acc.: 85.16%] [G loss: 1.758429]\n",
      "epoch:38 step:36404 [D loss: 0.591318, acc.: 70.31%] [G loss: 1.779557]\n",
      "epoch:38 step:36405 [D loss: 0.369653, acc.: 85.94%] [G loss: 2.000460]\n",
      "epoch:38 step:36406 [D loss: 0.483880, acc.: 80.47%] [G loss: 1.435593]\n",
      "epoch:38 step:36407 [D loss: 0.541694, acc.: 71.88%] [G loss: 1.248600]\n",
      "epoch:38 step:36408 [D loss: 0.447054, acc.: 79.69%] [G loss: 1.748014]\n",
      "epoch:38 step:36409 [D loss: 0.696273, acc.: 58.59%] [G loss: 1.610466]\n",
      "epoch:38 step:36410 [D loss: 0.520250, acc.: 74.22%] [G loss: 1.707120]\n",
      "epoch:38 step:36411 [D loss: 0.532611, acc.: 75.00%] [G loss: 1.294003]\n",
      "epoch:38 step:36412 [D loss: 0.474227, acc.: 78.12%] [G loss: 1.316703]\n",
      "epoch:38 step:36413 [D loss: 0.488415, acc.: 77.34%] [G loss: 1.332599]\n",
      "epoch:38 step:36414 [D loss: 0.479618, acc.: 75.78%] [G loss: 1.360924]\n",
      "epoch:38 step:36415 [D loss: 0.538674, acc.: 71.09%] [G loss: 0.986942]\n",
      "epoch:38 step:36416 [D loss: 0.404024, acc.: 85.16%] [G loss: 1.620457]\n",
      "epoch:38 step:36417 [D loss: 0.574562, acc.: 70.31%] [G loss: 1.293111]\n",
      "epoch:38 step:36418 [D loss: 0.648437, acc.: 64.84%] [G loss: 1.361999]\n",
      "epoch:38 step:36419 [D loss: 0.822878, acc.: 50.00%] [G loss: 1.732289]\n",
      "epoch:38 step:36420 [D loss: 0.550218, acc.: 76.56%] [G loss: 1.451167]\n",
      "epoch:38 step:36421 [D loss: 0.616622, acc.: 64.06%] [G loss: 2.186971]\n",
      "epoch:38 step:36422 [D loss: 0.473476, acc.: 77.34%] [G loss: 1.094588]\n",
      "epoch:38 step:36423 [D loss: 0.606017, acc.: 68.75%] [G loss: 2.030437]\n",
      "epoch:38 step:36424 [D loss: 0.591102, acc.: 71.88%] [G loss: 1.869730]\n",
      "epoch:38 step:36425 [D loss: 0.617294, acc.: 64.06%] [G loss: 1.479221]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:38 step:36426 [D loss: 0.606760, acc.: 68.75%] [G loss: 1.572477]\n",
      "epoch:38 step:36427 [D loss: 0.744240, acc.: 57.81%] [G loss: 1.229481]\n",
      "epoch:38 step:36428 [D loss: 0.563669, acc.: 72.66%] [G loss: 1.453307]\n",
      "epoch:38 step:36429 [D loss: 0.582604, acc.: 69.53%] [G loss: 2.079547]\n",
      "epoch:38 step:36430 [D loss: 0.491157, acc.: 71.88%] [G loss: 1.593235]\n",
      "epoch:38 step:36431 [D loss: 0.544636, acc.: 74.22%] [G loss: 1.569185]\n",
      "epoch:38 step:36432 [D loss: 0.620179, acc.: 67.19%] [G loss: 1.142638]\n",
      "epoch:38 step:36433 [D loss: 0.449398, acc.: 77.34%] [G loss: 1.908456]\n",
      "epoch:38 step:36434 [D loss: 0.524537, acc.: 73.44%] [G loss: 1.646538]\n",
      "epoch:38 step:36435 [D loss: 0.457878, acc.: 78.91%] [G loss: 1.136303]\n",
      "epoch:38 step:36436 [D loss: 0.604100, acc.: 67.97%] [G loss: 1.268779]\n",
      "epoch:38 step:36437 [D loss: 0.646933, acc.: 66.41%] [G loss: 1.669190]\n",
      "epoch:38 step:36438 [D loss: 0.396522, acc.: 89.84%] [G loss: 2.317817]\n",
      "epoch:38 step:36439 [D loss: 0.788002, acc.: 51.56%] [G loss: 1.330034]\n",
      "epoch:38 step:36440 [D loss: 0.707161, acc.: 61.72%] [G loss: 1.464698]\n",
      "epoch:38 step:36441 [D loss: 0.561630, acc.: 74.22%] [G loss: 0.864306]\n",
      "epoch:38 step:36442 [D loss: 0.652575, acc.: 64.84%] [G loss: 1.231354]\n",
      "epoch:38 step:36443 [D loss: 0.551835, acc.: 72.66%] [G loss: 1.663345]\n",
      "epoch:38 step:36444 [D loss: 0.449679, acc.: 82.03%] [G loss: 1.328616]\n",
      "epoch:38 step:36445 [D loss: 0.594116, acc.: 67.19%] [G loss: 1.582572]\n",
      "epoch:38 step:36446 [D loss: 0.338432, acc.: 87.50%] [G loss: 1.726921]\n",
      "epoch:38 step:36447 [D loss: 0.462055, acc.: 79.69%] [G loss: 1.369957]\n",
      "epoch:38 step:36448 [D loss: 0.551273, acc.: 71.88%] [G loss: 1.664263]\n",
      "epoch:38 step:36449 [D loss: 0.687189, acc.: 58.59%] [G loss: 1.353061]\n",
      "epoch:38 step:36450 [D loss: 0.559546, acc.: 71.88%] [G loss: 1.416348]\n",
      "epoch:38 step:36451 [D loss: 0.621751, acc.: 68.75%] [G loss: 0.858606]\n",
      "epoch:38 step:36452 [D loss: 0.570671, acc.: 69.53%] [G loss: 1.374574]\n",
      "epoch:38 step:36453 [D loss: 0.566935, acc.: 67.97%] [G loss: 1.164428]\n",
      "epoch:38 step:36454 [D loss: 0.439037, acc.: 81.25%] [G loss: 1.481667]\n",
      "epoch:38 step:36455 [D loss: 0.473357, acc.: 79.69%] [G loss: 1.819396]\n",
      "epoch:38 step:36456 [D loss: 0.531851, acc.: 71.09%] [G loss: 1.554372]\n",
      "epoch:38 step:36457 [D loss: 0.574713, acc.: 69.53%] [G loss: 1.672544]\n",
      "epoch:38 step:36458 [D loss: 0.590223, acc.: 68.75%] [G loss: 1.547753]\n",
      "epoch:38 step:36459 [D loss: 0.407480, acc.: 82.81%] [G loss: 1.012014]\n",
      "epoch:38 step:36460 [D loss: 0.510486, acc.: 73.44%] [G loss: 1.317528]\n",
      "epoch:38 step:36461 [D loss: 0.565213, acc.: 66.41%] [G loss: 1.364378]\n",
      "epoch:38 step:36462 [D loss: 0.612294, acc.: 69.53%] [G loss: 1.318084]\n",
      "epoch:38 step:36463 [D loss: 0.700459, acc.: 57.03%] [G loss: 1.483783]\n",
      "epoch:38 step:36464 [D loss: 0.472133, acc.: 78.91%] [G loss: 1.451103]\n",
      "epoch:38 step:36465 [D loss: 0.631323, acc.: 67.97%] [G loss: 1.390245]\n",
      "epoch:38 step:36466 [D loss: 0.428881, acc.: 85.16%] [G loss: 2.286673]\n",
      "epoch:38 step:36467 [D loss: 0.591901, acc.: 67.19%] [G loss: 1.224359]\n",
      "epoch:38 step:36468 [D loss: 0.645896, acc.: 62.50%] [G loss: 1.538641]\n",
      "epoch:38 step:36469 [D loss: 0.561157, acc.: 71.09%] [G loss: 1.624462]\n",
      "epoch:38 step:36470 [D loss: 0.922279, acc.: 51.56%] [G loss: 0.927517]\n",
      "epoch:38 step:36471 [D loss: 0.771195, acc.: 53.91%] [G loss: 1.937908]\n",
      "epoch:38 step:36472 [D loss: 0.429398, acc.: 79.69%] [G loss: 1.554851]\n",
      "epoch:38 step:36473 [D loss: 0.516962, acc.: 72.66%] [G loss: 1.481547]\n",
      "epoch:38 step:36474 [D loss: 0.358021, acc.: 89.84%] [G loss: 1.545806]\n",
      "epoch:38 step:36475 [D loss: 0.354103, acc.: 84.38%] [G loss: 1.960712]\n",
      "epoch:38 step:36476 [D loss: 0.525964, acc.: 75.78%] [G loss: 1.213941]\n",
      "epoch:38 step:36477 [D loss: 0.527094, acc.: 78.12%] [G loss: 1.782884]\n",
      "epoch:38 step:36478 [D loss: 0.665391, acc.: 60.94%] [G loss: 1.309597]\n",
      "epoch:38 step:36479 [D loss: 0.301554, acc.: 92.97%] [G loss: 2.122980]\n",
      "epoch:38 step:36480 [D loss: 0.623821, acc.: 66.41%] [G loss: 1.568961]\n",
      "epoch:38 step:36481 [D loss: 0.572150, acc.: 71.88%] [G loss: 1.707185]\n",
      "epoch:38 step:36482 [D loss: 0.532750, acc.: 72.66%] [G loss: 2.271960]\n",
      "epoch:38 step:36483 [D loss: 0.447036, acc.: 77.34%] [G loss: 1.392548]\n",
      "epoch:38 step:36484 [D loss: 0.472239, acc.: 77.34%] [G loss: 1.417713]\n",
      "epoch:38 step:36485 [D loss: 0.593972, acc.: 71.09%] [G loss: 1.857178]\n",
      "epoch:38 step:36486 [D loss: 0.535170, acc.: 72.66%] [G loss: 1.524600]\n",
      "epoch:38 step:36487 [D loss: 0.713919, acc.: 57.03%] [G loss: 1.456335]\n",
      "epoch:38 step:36488 [D loss: 0.265273, acc.: 92.19%] [G loss: 2.225583]\n",
      "epoch:38 step:36489 [D loss: 0.814095, acc.: 53.12%] [G loss: 1.173736]\n",
      "epoch:38 step:36490 [D loss: 0.379847, acc.: 86.72%] [G loss: 1.379359]\n",
      "epoch:38 step:36491 [D loss: 0.480955, acc.: 78.12%] [G loss: 1.343095]\n",
      "epoch:38 step:36492 [D loss: 0.346080, acc.: 89.06%] [G loss: 1.464013]\n",
      "epoch:38 step:36493 [D loss: 0.438454, acc.: 76.56%] [G loss: 1.928620]\n",
      "epoch:38 step:36494 [D loss: 0.686017, acc.: 63.28%] [G loss: 1.827186]\n",
      "epoch:38 step:36495 [D loss: 0.612824, acc.: 65.62%] [G loss: 1.580233]\n",
      "epoch:38 step:36496 [D loss: 0.616345, acc.: 60.94%] [G loss: 1.348554]\n",
      "epoch:38 step:36497 [D loss: 0.675518, acc.: 63.28%] [G loss: 1.518396]\n",
      "epoch:38 step:36498 [D loss: 0.519385, acc.: 77.34%] [G loss: 1.859326]\n",
      "epoch:38 step:36499 [D loss: 0.510672, acc.: 71.88%] [G loss: 1.982241]\n",
      "epoch:38 step:36500 [D loss: 0.680861, acc.: 58.59%] [G loss: 1.519191]\n",
      "epoch:38 step:36501 [D loss: 0.399943, acc.: 83.59%] [G loss: 1.355152]\n",
      "epoch:38 step:36502 [D loss: 0.629176, acc.: 64.06%] [G loss: 1.262090]\n",
      "epoch:38 step:36503 [D loss: 0.463238, acc.: 78.12%] [G loss: 1.647784]\n",
      "epoch:38 step:36504 [D loss: 0.529416, acc.: 73.44%] [G loss: 1.809207]\n",
      "epoch:38 step:36505 [D loss: 0.472022, acc.: 78.91%] [G loss: 2.098844]\n",
      "epoch:38 step:36506 [D loss: 0.435012, acc.: 83.59%] [G loss: 1.758588]\n",
      "epoch:38 step:36507 [D loss: 0.614003, acc.: 68.75%] [G loss: 1.199911]\n",
      "epoch:38 step:36508 [D loss: 0.511091, acc.: 71.88%] [G loss: 1.278670]\n",
      "epoch:38 step:36509 [D loss: 0.620081, acc.: 71.09%] [G loss: 1.288081]\n",
      "epoch:38 step:36510 [D loss: 0.550384, acc.: 70.31%] [G loss: 1.659263]\n",
      "epoch:38 step:36511 [D loss: 0.672822, acc.: 60.94%] [G loss: 2.035624]\n",
      "epoch:38 step:36512 [D loss: 0.557548, acc.: 75.78%] [G loss: 1.912862]\n",
      "epoch:38 step:36513 [D loss: 0.624725, acc.: 67.97%] [G loss: 1.142663]\n",
      "epoch:38 step:36514 [D loss: 0.651985, acc.: 67.19%] [G loss: 1.532228]\n",
      "epoch:38 step:36515 [D loss: 0.391774, acc.: 86.72%] [G loss: 1.641537]\n",
      "epoch:38 step:36516 [D loss: 0.372295, acc.: 85.16%] [G loss: 1.846507]\n",
      "epoch:38 step:36517 [D loss: 0.425182, acc.: 80.47%] [G loss: 1.731434]\n",
      "epoch:38 step:36518 [D loss: 0.556891, acc.: 71.88%] [G loss: 1.868337]\n",
      "epoch:38 step:36519 [D loss: 0.566945, acc.: 72.66%] [G loss: 1.315100]\n",
      "epoch:38 step:36520 [D loss: 0.429839, acc.: 80.47%] [G loss: 1.279599]\n",
      "epoch:38 step:36521 [D loss: 0.553335, acc.: 71.09%] [G loss: 2.160589]\n",
      "epoch:38 step:36522 [D loss: 0.521366, acc.: 72.66%] [G loss: 1.639701]\n",
      "epoch:38 step:36523 [D loss: 0.527111, acc.: 74.22%] [G loss: 1.593003]\n",
      "epoch:38 step:36524 [D loss: 0.371412, acc.: 83.59%] [G loss: 1.828986]\n",
      "epoch:38 step:36525 [D loss: 0.510967, acc.: 74.22%] [G loss: 1.743056]\n",
      "epoch:38 step:36526 [D loss: 0.650243, acc.: 66.41%] [G loss: 2.020773]\n",
      "epoch:38 step:36527 [D loss: 0.510491, acc.: 72.66%] [G loss: 1.702232]\n",
      "epoch:38 step:36528 [D loss: 0.513373, acc.: 74.22%] [G loss: 1.262224]\n",
      "epoch:38 step:36529 [D loss: 0.546157, acc.: 74.22%] [G loss: 1.766711]\n",
      "epoch:38 step:36530 [D loss: 0.463444, acc.: 77.34%] [G loss: 1.313354]\n",
      "epoch:38 step:36531 [D loss: 0.566231, acc.: 69.53%] [G loss: 1.505900]\n",
      "epoch:38 step:36532 [D loss: 0.605343, acc.: 61.72%] [G loss: 1.419756]\n",
      "epoch:38 step:36533 [D loss: 0.604690, acc.: 68.75%] [G loss: 1.243115]\n",
      "epoch:38 step:36534 [D loss: 0.365163, acc.: 87.50%] [G loss: 1.485018]\n",
      "epoch:38 step:36535 [D loss: 0.511147, acc.: 73.44%] [G loss: 1.941428]\n",
      "epoch:38 step:36536 [D loss: 0.574742, acc.: 67.97%] [G loss: 1.655284]\n",
      "epoch:38 step:36537 [D loss: 0.445735, acc.: 78.12%] [G loss: 1.156226]\n",
      "epoch:38 step:36538 [D loss: 0.323734, acc.: 87.50%] [G loss: 1.321372]\n",
      "epoch:38 step:36539 [D loss: 0.511368, acc.: 74.22%] [G loss: 1.313008]\n",
      "epoch:38 step:36540 [D loss: 0.609094, acc.: 65.62%] [G loss: 1.528774]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:38 step:36541 [D loss: 0.521650, acc.: 71.88%] [G loss: 1.829289]\n",
      "epoch:38 step:36542 [D loss: 0.490867, acc.: 76.56%] [G loss: 1.711274]\n",
      "epoch:38 step:36543 [D loss: 0.670650, acc.: 60.94%] [G loss: 1.199412]\n",
      "epoch:39 step:36544 [D loss: 0.305975, acc.: 91.41%] [G loss: 2.176980]\n",
      "epoch:39 step:36545 [D loss: 0.921749, acc.: 45.31%] [G loss: 1.692390]\n",
      "epoch:39 step:36546 [D loss: 0.485522, acc.: 78.91%] [G loss: 1.879806]\n",
      "epoch:39 step:36547 [D loss: 0.585964, acc.: 67.97%] [G loss: 1.436974]\n",
      "epoch:39 step:36548 [D loss: 0.652975, acc.: 65.62%] [G loss: 1.071603]\n",
      "epoch:39 step:36549 [D loss: 0.526678, acc.: 75.78%] [G loss: 1.509831]\n",
      "epoch:39 step:36550 [D loss: 0.797017, acc.: 51.56%] [G loss: 1.660956]\n",
      "epoch:39 step:36551 [D loss: 0.560823, acc.: 71.88%] [G loss: 1.945148]\n",
      "epoch:39 step:36552 [D loss: 0.442965, acc.: 79.69%] [G loss: 1.468088]\n",
      "epoch:39 step:36553 [D loss: 0.596835, acc.: 65.62%] [G loss: 1.484897]\n",
      "epoch:39 step:36554 [D loss: 0.639577, acc.: 67.19%] [G loss: 1.374790]\n",
      "epoch:39 step:36555 [D loss: 0.575206, acc.: 71.09%] [G loss: 1.476596]\n",
      "epoch:39 step:36556 [D loss: 0.482706, acc.: 81.25%] [G loss: 1.783233]\n",
      "epoch:39 step:36557 [D loss: 0.492834, acc.: 78.91%] [G loss: 0.853178]\n",
      "epoch:39 step:36558 [D loss: 0.569049, acc.: 67.19%] [G loss: 0.803143]\n",
      "epoch:39 step:36559 [D loss: 0.364056, acc.: 89.06%] [G loss: 1.148863]\n",
      "epoch:39 step:36560 [D loss: 0.408395, acc.: 84.38%] [G loss: 1.485495]\n",
      "epoch:39 step:36561 [D loss: 0.534392, acc.: 71.88%] [G loss: 1.760754]\n",
      "epoch:39 step:36562 [D loss: 0.603472, acc.: 66.41%] [G loss: 0.905687]\n",
      "epoch:39 step:36563 [D loss: 0.589538, acc.: 68.75%] [G loss: 1.232921]\n",
      "epoch:39 step:36564 [D loss: 0.524073, acc.: 74.22%] [G loss: 1.623925]\n",
      "epoch:39 step:36565 [D loss: 0.436002, acc.: 81.25%] [G loss: 1.724297]\n",
      "epoch:39 step:36566 [D loss: 0.488413, acc.: 76.56%] [G loss: 1.165783]\n",
      "epoch:39 step:36567 [D loss: 0.528606, acc.: 72.66%] [G loss: 1.681924]\n",
      "epoch:39 step:36568 [D loss: 0.475655, acc.: 79.69%] [G loss: 1.333046]\n",
      "epoch:39 step:36569 [D loss: 0.583040, acc.: 71.88%] [G loss: 1.360672]\n",
      "epoch:39 step:36570 [D loss: 0.361560, acc.: 86.72%] [G loss: 1.220948]\n",
      "epoch:39 step:36571 [D loss: 0.445114, acc.: 80.47%] [G loss: 1.509660]\n",
      "epoch:39 step:36572 [D loss: 0.521959, acc.: 76.56%] [G loss: 1.131692]\n",
      "epoch:39 step:36573 [D loss: 0.640734, acc.: 61.72%] [G loss: 1.333504]\n",
      "epoch:39 step:36574 [D loss: 0.550643, acc.: 71.09%] [G loss: 1.689284]\n",
      "epoch:39 step:36575 [D loss: 0.565111, acc.: 70.31%] [G loss: 1.830994]\n",
      "epoch:39 step:36576 [D loss: 0.582748, acc.: 68.75%] [G loss: 1.893757]\n",
      "epoch:39 step:36577 [D loss: 0.530998, acc.: 69.53%] [G loss: 1.460327]\n",
      "epoch:39 step:36578 [D loss: 0.787362, acc.: 49.22%] [G loss: 1.112795]\n",
      "epoch:39 step:36579 [D loss: 0.482010, acc.: 75.00%] [G loss: 1.505535]\n",
      "epoch:39 step:36580 [D loss: 0.415005, acc.: 83.59%] [G loss: 1.348679]\n",
      "epoch:39 step:36581 [D loss: 0.270187, acc.: 92.97%] [G loss: 1.405947]\n",
      "epoch:39 step:36582 [D loss: 0.456894, acc.: 79.69%] [G loss: 2.126600]\n",
      "epoch:39 step:36583 [D loss: 0.495707, acc.: 71.88%] [G loss: 1.152099]\n",
      "epoch:39 step:36584 [D loss: 0.544404, acc.: 70.31%] [G loss: 0.852233]\n",
      "epoch:39 step:36585 [D loss: 0.851991, acc.: 50.78%] [G loss: 1.487105]\n",
      "epoch:39 step:36586 [D loss: 0.730929, acc.: 53.12%] [G loss: 1.560461]\n",
      "epoch:39 step:36587 [D loss: 0.468530, acc.: 82.81%] [G loss: 1.911093]\n",
      "epoch:39 step:36588 [D loss: 0.338981, acc.: 86.72%] [G loss: 2.287481]\n",
      "epoch:39 step:36589 [D loss: 0.525442, acc.: 75.78%] [G loss: 1.321778]\n",
      "epoch:39 step:36590 [D loss: 0.554254, acc.: 67.97%] [G loss: 1.510137]\n",
      "epoch:39 step:36591 [D loss: 0.499152, acc.: 71.88%] [G loss: 1.503979]\n",
      "epoch:39 step:36592 [D loss: 0.567945, acc.: 71.09%] [G loss: 1.203125]\n",
      "epoch:39 step:36593 [D loss: 0.310968, acc.: 90.62%] [G loss: 1.632404]\n",
      "epoch:39 step:36594 [D loss: 0.400771, acc.: 85.94%] [G loss: 1.609771]\n",
      "epoch:39 step:36595 [D loss: 0.530806, acc.: 75.78%] [G loss: 1.832667]\n",
      "epoch:39 step:36596 [D loss: 0.672045, acc.: 62.50%] [G loss: 1.312584]\n",
      "epoch:39 step:36597 [D loss: 0.498899, acc.: 72.66%] [G loss: 1.629206]\n",
      "epoch:39 step:36598 [D loss: 0.377441, acc.: 85.94%] [G loss: 1.530064]\n",
      "epoch:39 step:36599 [D loss: 0.575973, acc.: 71.09%] [G loss: 1.388429]\n",
      "epoch:39 step:36600 [D loss: 0.688691, acc.: 59.38%] [G loss: 1.461475]\n",
      "epoch:39 step:36601 [D loss: 0.406781, acc.: 84.38%] [G loss: 1.982797]\n",
      "epoch:39 step:36602 [D loss: 0.482129, acc.: 81.25%] [G loss: 1.759937]\n",
      "epoch:39 step:36603 [D loss: 0.516410, acc.: 72.66%] [G loss: 0.904463]\n",
      "epoch:39 step:36604 [D loss: 0.483600, acc.: 75.00%] [G loss: 1.699841]\n",
      "epoch:39 step:36605 [D loss: 0.606785, acc.: 67.19%] [G loss: 1.470614]\n",
      "epoch:39 step:36606 [D loss: 0.342221, acc.: 87.50%] [G loss: 1.804696]\n",
      "epoch:39 step:36607 [D loss: 0.655465, acc.: 63.28%] [G loss: 1.710501]\n",
      "epoch:39 step:36608 [D loss: 0.451060, acc.: 79.69%] [G loss: 1.802763]\n",
      "epoch:39 step:36609 [D loss: 0.430011, acc.: 79.69%] [G loss: 1.639464]\n",
      "epoch:39 step:36610 [D loss: 0.479604, acc.: 78.12%] [G loss: 1.688069]\n",
      "epoch:39 step:36611 [D loss: 0.415568, acc.: 86.72%] [G loss: 1.525428]\n",
      "epoch:39 step:36612 [D loss: 0.410057, acc.: 87.50%] [G loss: 1.891192]\n",
      "epoch:39 step:36613 [D loss: 0.625781, acc.: 67.19%] [G loss: 1.516269]\n",
      "epoch:39 step:36614 [D loss: 0.707702, acc.: 64.84%] [G loss: 1.383625]\n",
      "epoch:39 step:36615 [D loss: 0.651142, acc.: 64.84%] [G loss: 1.610486]\n",
      "epoch:39 step:36616 [D loss: 0.553205, acc.: 71.88%] [G loss: 1.470900]\n",
      "epoch:39 step:36617 [D loss: 0.512182, acc.: 75.00%] [G loss: 1.896643]\n",
      "epoch:39 step:36618 [D loss: 0.492476, acc.: 77.34%] [G loss: 1.909737]\n",
      "epoch:39 step:36619 [D loss: 0.747658, acc.: 53.12%] [G loss: 1.782099]\n",
      "epoch:39 step:36620 [D loss: 0.429341, acc.: 78.12%] [G loss: 1.302965]\n",
      "epoch:39 step:36621 [D loss: 0.700368, acc.: 64.84%] [G loss: 1.204139]\n",
      "epoch:39 step:36622 [D loss: 0.415593, acc.: 85.16%] [G loss: 1.401877]\n",
      "epoch:39 step:36623 [D loss: 0.591847, acc.: 72.66%] [G loss: 1.652149]\n",
      "epoch:39 step:36624 [D loss: 0.581499, acc.: 67.97%] [G loss: 1.516996]\n",
      "epoch:39 step:36625 [D loss: 0.380668, acc.: 82.81%] [G loss: 1.694161]\n",
      "epoch:39 step:36626 [D loss: 0.458494, acc.: 74.22%] [G loss: 2.094921]\n",
      "epoch:39 step:36627 [D loss: 0.549140, acc.: 74.22%] [G loss: 1.023881]\n",
      "epoch:39 step:36628 [D loss: 0.829329, acc.: 53.12%] [G loss: 1.463826]\n",
      "epoch:39 step:36629 [D loss: 0.531013, acc.: 69.53%] [G loss: 1.935031]\n",
      "epoch:39 step:36630 [D loss: 0.481185, acc.: 82.03%] [G loss: 1.655865]\n",
      "epoch:39 step:36631 [D loss: 0.533764, acc.: 77.34%] [G loss: 1.465093]\n",
      "epoch:39 step:36632 [D loss: 0.617202, acc.: 67.19%] [G loss: 1.467586]\n",
      "epoch:39 step:36633 [D loss: 0.390952, acc.: 85.94%] [G loss: 2.195696]\n",
      "epoch:39 step:36634 [D loss: 0.505013, acc.: 75.00%] [G loss: 1.480356]\n",
      "epoch:39 step:36635 [D loss: 0.406272, acc.: 84.38%] [G loss: 1.847414]\n",
      "epoch:39 step:36636 [D loss: 0.439175, acc.: 78.91%] [G loss: 1.451142]\n",
      "epoch:39 step:36637 [D loss: 0.469412, acc.: 79.69%] [G loss: 1.250878]\n",
      "epoch:39 step:36638 [D loss: 0.571902, acc.: 71.09%] [G loss: 1.252443]\n",
      "epoch:39 step:36639 [D loss: 0.499273, acc.: 77.34%] [G loss: 1.584425]\n",
      "epoch:39 step:36640 [D loss: 0.648779, acc.: 60.94%] [G loss: 1.689983]\n",
      "epoch:39 step:36641 [D loss: 0.627927, acc.: 64.06%] [G loss: 0.852209]\n",
      "epoch:39 step:36642 [D loss: 0.546209, acc.: 67.97%] [G loss: 1.837806]\n",
      "epoch:39 step:36643 [D loss: 0.465248, acc.: 78.12%] [G loss: 2.267789]\n",
      "epoch:39 step:36644 [D loss: 0.612504, acc.: 67.97%] [G loss: 1.204745]\n",
      "epoch:39 step:36645 [D loss: 0.567645, acc.: 67.97%] [G loss: 1.669531]\n",
      "epoch:39 step:36646 [D loss: 0.406463, acc.: 84.38%] [G loss: 1.956497]\n",
      "epoch:39 step:36647 [D loss: 0.464596, acc.: 82.03%] [G loss: 1.661308]\n",
      "epoch:39 step:36648 [D loss: 0.642477, acc.: 59.38%] [G loss: 1.494758]\n",
      "epoch:39 step:36649 [D loss: 0.430784, acc.: 81.25%] [G loss: 1.162535]\n",
      "epoch:39 step:36650 [D loss: 0.594382, acc.: 67.97%] [G loss: 1.134860]\n",
      "epoch:39 step:36651 [D loss: 0.304349, acc.: 89.84%] [G loss: 1.328969]\n",
      "epoch:39 step:36652 [D loss: 0.337302, acc.: 88.28%] [G loss: 1.659312]\n",
      "epoch:39 step:36653 [D loss: 0.552314, acc.: 71.09%] [G loss: 1.764562]\n",
      "epoch:39 step:36654 [D loss: 0.598827, acc.: 67.19%] [G loss: 1.088588]\n",
      "epoch:39 step:36655 [D loss: 0.515126, acc.: 74.22%] [G loss: 1.867924]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:39 step:36656 [D loss: 0.394536, acc.: 82.81%] [G loss: 1.925282]\n",
      "epoch:39 step:36657 [D loss: 0.474368, acc.: 79.69%] [G loss: 1.578020]\n",
      "epoch:39 step:36658 [D loss: 0.418651, acc.: 82.03%] [G loss: 1.514293]\n",
      "epoch:39 step:36659 [D loss: 0.518966, acc.: 78.12%] [G loss: 1.053174]\n",
      "epoch:39 step:36660 [D loss: 0.479627, acc.: 75.00%] [G loss: 1.414194]\n",
      "epoch:39 step:36661 [D loss: 0.840004, acc.: 53.91%] [G loss: 1.246233]\n",
      "epoch:39 step:36662 [D loss: 0.519892, acc.: 71.88%] [G loss: 1.088423]\n",
      "epoch:39 step:36663 [D loss: 0.677386, acc.: 63.28%] [G loss: 1.476910]\n",
      "epoch:39 step:36664 [D loss: 0.646614, acc.: 62.50%] [G loss: 1.357757]\n",
      "epoch:39 step:36665 [D loss: 0.608479, acc.: 68.75%] [G loss: 1.282602]\n",
      "epoch:39 step:36666 [D loss: 0.687310, acc.: 58.59%] [G loss: 1.464940]\n",
      "epoch:39 step:36667 [D loss: 0.702637, acc.: 63.28%] [G loss: 1.696700]\n",
      "epoch:39 step:36668 [D loss: 0.687613, acc.: 61.72%] [G loss: 1.277856]\n",
      "epoch:39 step:36669 [D loss: 0.582816, acc.: 64.84%] [G loss: 2.325824]\n",
      "epoch:39 step:36670 [D loss: 0.501457, acc.: 75.78%] [G loss: 0.872306]\n",
      "epoch:39 step:36671 [D loss: 0.450017, acc.: 81.25%] [G loss: 1.430145]\n",
      "epoch:39 step:36672 [D loss: 0.510037, acc.: 81.25%] [G loss: 1.656689]\n",
      "epoch:39 step:36673 [D loss: 0.475766, acc.: 79.69%] [G loss: 1.335467]\n",
      "epoch:39 step:36674 [D loss: 0.349290, acc.: 85.94%] [G loss: 1.565827]\n",
      "epoch:39 step:36675 [D loss: 0.409248, acc.: 85.16%] [G loss: 1.679074]\n",
      "epoch:39 step:36676 [D loss: 0.464281, acc.: 76.56%] [G loss: 1.642530]\n",
      "epoch:39 step:36677 [D loss: 0.381937, acc.: 83.59%] [G loss: 1.409024]\n",
      "epoch:39 step:36678 [D loss: 0.541969, acc.: 71.88%] [G loss: 1.522676]\n",
      "epoch:39 step:36679 [D loss: 0.675480, acc.: 60.94%] [G loss: 1.951413]\n",
      "epoch:39 step:36680 [D loss: 0.588674, acc.: 71.09%] [G loss: 1.478575]\n",
      "epoch:39 step:36681 [D loss: 0.753384, acc.: 60.16%] [G loss: 1.294185]\n",
      "epoch:39 step:36682 [D loss: 0.889258, acc.: 42.97%] [G loss: 1.117722]\n",
      "epoch:39 step:36683 [D loss: 0.739912, acc.: 58.59%] [G loss: 0.987693]\n",
      "epoch:39 step:36684 [D loss: 0.785295, acc.: 52.34%] [G loss: 1.341705]\n",
      "epoch:39 step:36685 [D loss: 0.453583, acc.: 79.69%] [G loss: 1.792131]\n",
      "epoch:39 step:36686 [D loss: 0.396574, acc.: 82.81%] [G loss: 1.927812]\n",
      "epoch:39 step:36687 [D loss: 0.508566, acc.: 75.00%] [G loss: 1.228925]\n",
      "epoch:39 step:36688 [D loss: 0.560328, acc.: 67.19%] [G loss: 1.489494]\n",
      "epoch:39 step:36689 [D loss: 0.632801, acc.: 57.81%] [G loss: 1.121114]\n",
      "epoch:39 step:36690 [D loss: 0.423755, acc.: 80.47%] [G loss: 2.340976]\n",
      "epoch:39 step:36691 [D loss: 0.398154, acc.: 84.38%] [G loss: 1.679937]\n",
      "epoch:39 step:36692 [D loss: 0.579289, acc.: 66.41%] [G loss: 1.227121]\n",
      "epoch:39 step:36693 [D loss: 0.359589, acc.: 85.94%] [G loss: 1.467912]\n",
      "epoch:39 step:36694 [D loss: 0.594904, acc.: 71.88%] [G loss: 1.878153]\n",
      "epoch:39 step:36695 [D loss: 0.475695, acc.: 78.12%] [G loss: 1.667799]\n",
      "epoch:39 step:36696 [D loss: 0.447515, acc.: 82.81%] [G loss: 1.525542]\n",
      "epoch:39 step:36697 [D loss: 0.532564, acc.: 71.88%] [G loss: 1.797523]\n",
      "epoch:39 step:36698 [D loss: 0.713223, acc.: 56.25%] [G loss: 0.911117]\n",
      "epoch:39 step:36699 [D loss: 0.400137, acc.: 86.72%] [G loss: 1.369192]\n",
      "epoch:39 step:36700 [D loss: 0.507985, acc.: 77.34%] [G loss: 1.513310]\n",
      "epoch:39 step:36701 [D loss: 0.495161, acc.: 77.34%] [G loss: 1.611737]\n",
      "epoch:39 step:36702 [D loss: 0.429644, acc.: 80.47%] [G loss: 1.814976]\n",
      "epoch:39 step:36703 [D loss: 0.464708, acc.: 76.56%] [G loss: 1.910552]\n",
      "epoch:39 step:36704 [D loss: 0.500325, acc.: 78.91%] [G loss: 1.689581]\n",
      "epoch:39 step:36705 [D loss: 0.590853, acc.: 69.53%] [G loss: 1.641669]\n",
      "epoch:39 step:36706 [D loss: 0.467781, acc.: 80.47%] [G loss: 1.037434]\n",
      "epoch:39 step:36707 [D loss: 0.369996, acc.: 84.38%] [G loss: 1.686858]\n",
      "epoch:39 step:36708 [D loss: 0.460283, acc.: 79.69%] [G loss: 1.283959]\n",
      "epoch:39 step:36709 [D loss: 0.540459, acc.: 75.00%] [G loss: 1.189657]\n",
      "epoch:39 step:36710 [D loss: 0.432137, acc.: 84.38%] [G loss: 1.820379]\n",
      "epoch:39 step:36711 [D loss: 0.453162, acc.: 77.34%] [G loss: 2.095785]\n",
      "epoch:39 step:36712 [D loss: 0.487154, acc.: 78.12%] [G loss: 1.842086]\n",
      "epoch:39 step:36713 [D loss: 0.430629, acc.: 85.16%] [G loss: 1.406048]\n",
      "epoch:39 step:36714 [D loss: 0.488340, acc.: 75.78%] [G loss: 1.885391]\n",
      "epoch:39 step:36715 [D loss: 0.593564, acc.: 66.41%] [G loss: 1.560813]\n",
      "epoch:39 step:36716 [D loss: 0.711303, acc.: 52.34%] [G loss: 1.845175]\n",
      "epoch:39 step:36717 [D loss: 0.579157, acc.: 70.31%] [G loss: 1.594055]\n",
      "epoch:39 step:36718 [D loss: 0.317241, acc.: 85.16%] [G loss: 2.204659]\n",
      "epoch:39 step:36719 [D loss: 0.676263, acc.: 61.72%] [G loss: 1.671275]\n",
      "epoch:39 step:36720 [D loss: 0.440832, acc.: 81.25%] [G loss: 2.184767]\n",
      "epoch:39 step:36721 [D loss: 0.594486, acc.: 66.41%] [G loss: 1.971720]\n",
      "epoch:39 step:36722 [D loss: 0.544246, acc.: 75.78%] [G loss: 1.241085]\n",
      "epoch:39 step:36723 [D loss: 0.450332, acc.: 78.12%] [G loss: 1.721564]\n",
      "epoch:39 step:36724 [D loss: 0.502512, acc.: 74.22%] [G loss: 1.196211]\n",
      "epoch:39 step:36725 [D loss: 0.582322, acc.: 70.31%] [G loss: 1.878490]\n",
      "epoch:39 step:36726 [D loss: 0.703133, acc.: 64.84%] [G loss: 1.376365]\n",
      "epoch:39 step:36727 [D loss: 0.624823, acc.: 67.97%] [G loss: 1.488912]\n",
      "epoch:39 step:36728 [D loss: 0.461954, acc.: 76.56%] [G loss: 1.809574]\n",
      "epoch:39 step:36729 [D loss: 0.758803, acc.: 55.47%] [G loss: 2.032058]\n",
      "epoch:39 step:36730 [D loss: 0.536333, acc.: 68.75%] [G loss: 1.302721]\n",
      "epoch:39 step:36731 [D loss: 0.527311, acc.: 78.12%] [G loss: 1.282827]\n",
      "epoch:39 step:36732 [D loss: 0.527446, acc.: 71.88%] [G loss: 1.506710]\n",
      "epoch:39 step:36733 [D loss: 0.758316, acc.: 58.59%] [G loss: 1.274308]\n",
      "epoch:39 step:36734 [D loss: 0.438663, acc.: 80.47%] [G loss: 1.662758]\n",
      "epoch:39 step:36735 [D loss: 0.568774, acc.: 67.97%] [G loss: 1.481879]\n",
      "epoch:39 step:36736 [D loss: 0.711777, acc.: 63.28%] [G loss: 1.650655]\n",
      "epoch:39 step:36737 [D loss: 0.481667, acc.: 76.56%] [G loss: 1.388201]\n",
      "epoch:39 step:36738 [D loss: 0.499874, acc.: 75.00%] [G loss: 1.088084]\n",
      "epoch:39 step:36739 [D loss: 0.891905, acc.: 47.66%] [G loss: 1.034163]\n",
      "epoch:39 step:36740 [D loss: 0.516466, acc.: 72.66%] [G loss: 1.999349]\n",
      "epoch:39 step:36741 [D loss: 0.415703, acc.: 82.03%] [G loss: 2.019285]\n",
      "epoch:39 step:36742 [D loss: 0.599101, acc.: 64.84%] [G loss: 1.293722]\n",
      "epoch:39 step:36743 [D loss: 0.638098, acc.: 63.28%] [G loss: 1.331897]\n",
      "epoch:39 step:36744 [D loss: 0.665606, acc.: 62.50%] [G loss: 1.210589]\n",
      "epoch:39 step:36745 [D loss: 0.671077, acc.: 62.50%] [G loss: 1.286384]\n",
      "epoch:39 step:36746 [D loss: 0.355604, acc.: 87.50%] [G loss: 1.660132]\n",
      "epoch:39 step:36747 [D loss: 0.387284, acc.: 82.81%] [G loss: 1.929130]\n",
      "epoch:39 step:36748 [D loss: 0.618631, acc.: 70.31%] [G loss: 1.624388]\n",
      "epoch:39 step:36749 [D loss: 0.641649, acc.: 62.50%] [G loss: 1.874054]\n",
      "epoch:39 step:36750 [D loss: 0.618873, acc.: 60.94%] [G loss: 1.203695]\n",
      "epoch:39 step:36751 [D loss: 0.656770, acc.: 67.97%] [G loss: 1.724342]\n",
      "epoch:39 step:36752 [D loss: 0.485338, acc.: 76.56%] [G loss: 1.203332]\n",
      "epoch:39 step:36753 [D loss: 0.388162, acc.: 86.72%] [G loss: 2.073187]\n",
      "epoch:39 step:36754 [D loss: 0.524356, acc.: 74.22%] [G loss: 1.771193]\n",
      "epoch:39 step:36755 [D loss: 0.503884, acc.: 74.22%] [G loss: 1.683393]\n",
      "epoch:39 step:36756 [D loss: 0.543986, acc.: 75.00%] [G loss: 1.304096]\n",
      "epoch:39 step:36757 [D loss: 0.559195, acc.: 73.44%] [G loss: 1.364098]\n",
      "epoch:39 step:36758 [D loss: 0.678367, acc.: 64.06%] [G loss: 1.096412]\n",
      "epoch:39 step:36759 [D loss: 0.522930, acc.: 73.44%] [G loss: 1.764423]\n",
      "epoch:39 step:36760 [D loss: 0.410613, acc.: 81.25%] [G loss: 1.941500]\n",
      "epoch:39 step:36761 [D loss: 0.447273, acc.: 81.25%] [G loss: 0.916170]\n",
      "epoch:39 step:36762 [D loss: 0.706291, acc.: 63.28%] [G loss: 0.755641]\n",
      "epoch:39 step:36763 [D loss: 0.356793, acc.: 88.28%] [G loss: 1.760463]\n",
      "epoch:39 step:36764 [D loss: 0.591453, acc.: 70.31%] [G loss: 1.893694]\n",
      "epoch:39 step:36765 [D loss: 0.509319, acc.: 78.91%] [G loss: 1.941960]\n",
      "epoch:39 step:36766 [D loss: 0.366289, acc.: 83.59%] [G loss: 1.687327]\n",
      "epoch:39 step:36767 [D loss: 0.585468, acc.: 67.97%] [G loss: 1.243651]\n",
      "epoch:39 step:36768 [D loss: 0.693042, acc.: 57.81%] [G loss: 1.169490]\n",
      "epoch:39 step:36769 [D loss: 0.624480, acc.: 68.75%] [G loss: 1.896232]\n",
      "epoch:39 step:36770 [D loss: 0.655745, acc.: 68.75%] [G loss: 1.391141]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:39 step:36771 [D loss: 0.404587, acc.: 85.94%] [G loss: 1.349500]\n",
      "epoch:39 step:36772 [D loss: 0.385149, acc.: 84.38%] [G loss: 1.467733]\n",
      "epoch:39 step:36773 [D loss: 0.487845, acc.: 78.12%] [G loss: 1.879232]\n",
      "epoch:39 step:36774 [D loss: 0.429726, acc.: 81.25%] [G loss: 1.765416]\n",
      "epoch:39 step:36775 [D loss: 0.481989, acc.: 76.56%] [G loss: 1.526384]\n",
      "epoch:39 step:36776 [D loss: 0.555431, acc.: 73.44%] [G loss: 1.147018]\n",
      "epoch:39 step:36777 [D loss: 0.400590, acc.: 79.69%] [G loss: 1.514984]\n",
      "epoch:39 step:36778 [D loss: 0.483351, acc.: 75.78%] [G loss: 1.265948]\n",
      "epoch:39 step:36779 [D loss: 0.470364, acc.: 78.91%] [G loss: 1.328373]\n",
      "epoch:39 step:36780 [D loss: 0.417883, acc.: 79.69%] [G loss: 1.478174]\n",
      "epoch:39 step:36781 [D loss: 0.469803, acc.: 80.47%] [G loss: 1.282011]\n",
      "epoch:39 step:36782 [D loss: 0.684817, acc.: 60.94%] [G loss: 1.269563]\n",
      "epoch:39 step:36783 [D loss: 0.478304, acc.: 74.22%] [G loss: 1.736391]\n",
      "epoch:39 step:36784 [D loss: 0.517897, acc.: 72.66%] [G loss: 2.085596]\n",
      "epoch:39 step:36785 [D loss: 0.719324, acc.: 58.59%] [G loss: 1.763592]\n",
      "epoch:39 step:36786 [D loss: 0.549200, acc.: 71.09%] [G loss: 1.276742]\n",
      "epoch:39 step:36787 [D loss: 0.540503, acc.: 69.53%] [G loss: 0.961013]\n",
      "epoch:39 step:36788 [D loss: 0.380632, acc.: 85.16%] [G loss: 1.967671]\n",
      "epoch:39 step:36789 [D loss: 0.478373, acc.: 77.34%] [G loss: 1.960157]\n",
      "epoch:39 step:36790 [D loss: 0.482526, acc.: 74.22%] [G loss: 1.897141]\n",
      "epoch:39 step:36791 [D loss: 0.481882, acc.: 77.34%] [G loss: 1.058004]\n",
      "epoch:39 step:36792 [D loss: 0.401162, acc.: 83.59%] [G loss: 2.049934]\n",
      "epoch:39 step:36793 [D loss: 0.258834, acc.: 95.31%] [G loss: 1.986541]\n",
      "epoch:39 step:36794 [D loss: 0.537876, acc.: 69.53%] [G loss: 2.151884]\n",
      "epoch:39 step:36795 [D loss: 0.327886, acc.: 87.50%] [G loss: 2.049808]\n",
      "epoch:39 step:36796 [D loss: 0.393092, acc.: 83.59%] [G loss: 1.485721]\n",
      "epoch:39 step:36797 [D loss: 0.456264, acc.: 79.69%] [G loss: 1.336800]\n",
      "epoch:39 step:36798 [D loss: 0.538288, acc.: 70.31%] [G loss: 0.974062]\n",
      "epoch:39 step:36799 [D loss: 0.311089, acc.: 90.62%] [G loss: 1.645934]\n",
      "epoch:39 step:36800 [D loss: 0.437927, acc.: 82.03%] [G loss: 1.701620]\n",
      "epoch:39 step:36801 [D loss: 0.446620, acc.: 79.69%] [G loss: 1.714456]\n",
      "epoch:39 step:36802 [D loss: 0.554281, acc.: 69.53%] [G loss: 1.377800]\n",
      "epoch:39 step:36803 [D loss: 0.416938, acc.: 82.81%] [G loss: 1.704866]\n",
      "epoch:39 step:36804 [D loss: 0.718846, acc.: 57.81%] [G loss: 1.277659]\n",
      "epoch:39 step:36805 [D loss: 0.611618, acc.: 67.19%] [G loss: 1.248477]\n",
      "epoch:39 step:36806 [D loss: 0.579336, acc.: 68.75%] [G loss: 1.245810]\n",
      "epoch:39 step:36807 [D loss: 0.574269, acc.: 70.31%] [G loss: 0.860724]\n",
      "epoch:39 step:36808 [D loss: 0.458692, acc.: 81.25%] [G loss: 1.296918]\n",
      "epoch:39 step:36809 [D loss: 0.514592, acc.: 75.78%] [G loss: 1.614542]\n",
      "epoch:39 step:36810 [D loss: 0.736580, acc.: 59.38%] [G loss: 1.634451]\n",
      "epoch:39 step:36811 [D loss: 0.470250, acc.: 79.69%] [G loss: 1.583144]\n",
      "epoch:39 step:36812 [D loss: 0.257380, acc.: 92.19%] [G loss: 1.883611]\n",
      "epoch:39 step:36813 [D loss: 0.501864, acc.: 76.56%] [G loss: 2.518782]\n",
      "epoch:39 step:36814 [D loss: 0.527789, acc.: 75.00%] [G loss: 1.125647]\n",
      "epoch:39 step:36815 [D loss: 0.634779, acc.: 64.06%] [G loss: 1.213591]\n",
      "epoch:39 step:36816 [D loss: 0.569355, acc.: 71.09%] [G loss: 1.501445]\n",
      "epoch:39 step:36817 [D loss: 0.747930, acc.: 61.72%] [G loss: 1.242364]\n",
      "epoch:39 step:36818 [D loss: 0.545888, acc.: 74.22%] [G loss: 1.934286]\n",
      "epoch:39 step:36819 [D loss: 0.745610, acc.: 63.28%] [G loss: 1.491192]\n",
      "epoch:39 step:36820 [D loss: 0.525316, acc.: 71.88%] [G loss: 1.208896]\n",
      "epoch:39 step:36821 [D loss: 0.654854, acc.: 65.62%] [G loss: 1.532820]\n",
      "epoch:39 step:36822 [D loss: 0.545299, acc.: 75.00%] [G loss: 1.253524]\n",
      "epoch:39 step:36823 [D loss: 0.419501, acc.: 85.16%] [G loss: 1.614765]\n",
      "epoch:39 step:36824 [D loss: 0.534138, acc.: 72.66%] [G loss: 1.542883]\n",
      "epoch:39 step:36825 [D loss: 0.555156, acc.: 73.44%] [G loss: 1.615127]\n",
      "epoch:39 step:36826 [D loss: 0.334507, acc.: 87.50%] [G loss: 1.524819]\n",
      "epoch:39 step:36827 [D loss: 0.550249, acc.: 67.97%] [G loss: 1.615143]\n",
      "epoch:39 step:36828 [D loss: 0.350056, acc.: 85.16%] [G loss: 2.279076]\n",
      "epoch:39 step:36829 [D loss: 0.345130, acc.: 89.06%] [G loss: 1.326500]\n",
      "epoch:39 step:36830 [D loss: 0.419919, acc.: 83.59%] [G loss: 1.755387]\n",
      "epoch:39 step:36831 [D loss: 0.610440, acc.: 66.41%] [G loss: 1.508302]\n",
      "epoch:39 step:36832 [D loss: 0.493834, acc.: 77.34%] [G loss: 1.329164]\n",
      "epoch:39 step:36833 [D loss: 0.397346, acc.: 86.72%] [G loss: 1.587375]\n",
      "epoch:39 step:36834 [D loss: 0.586586, acc.: 71.09%] [G loss: 1.344792]\n",
      "epoch:39 step:36835 [D loss: 0.620513, acc.: 64.84%] [G loss: 1.004745]\n",
      "epoch:39 step:36836 [D loss: 0.728376, acc.: 54.69%] [G loss: 1.324255]\n",
      "epoch:39 step:36837 [D loss: 0.368189, acc.: 83.59%] [G loss: 1.606867]\n",
      "epoch:39 step:36838 [D loss: 0.694814, acc.: 63.28%] [G loss: 1.261462]\n",
      "epoch:39 step:36839 [D loss: 0.437904, acc.: 80.47%] [G loss: 1.472172]\n",
      "epoch:39 step:36840 [D loss: 0.437729, acc.: 82.03%] [G loss: 1.566133]\n",
      "epoch:39 step:36841 [D loss: 0.646649, acc.: 69.53%] [G loss: 0.886390]\n",
      "epoch:39 step:36842 [D loss: 0.692486, acc.: 57.81%] [G loss: 0.803311]\n",
      "epoch:39 step:36843 [D loss: 0.508471, acc.: 74.22%] [G loss: 1.960332]\n",
      "epoch:39 step:36844 [D loss: 0.639107, acc.: 67.19%] [G loss: 1.353724]\n",
      "epoch:39 step:36845 [D loss: 0.531122, acc.: 77.34%] [G loss: 1.638319]\n",
      "epoch:39 step:36846 [D loss: 0.710332, acc.: 61.72%] [G loss: 1.471819]\n",
      "epoch:39 step:36847 [D loss: 0.508771, acc.: 76.56%] [G loss: 1.522676]\n",
      "epoch:39 step:36848 [D loss: 0.522000, acc.: 75.00%] [G loss: 1.418015]\n",
      "epoch:39 step:36849 [D loss: 0.563990, acc.: 67.97%] [G loss: 1.361937]\n",
      "epoch:39 step:36850 [D loss: 0.464063, acc.: 78.91%] [G loss: 1.324043]\n",
      "epoch:39 step:36851 [D loss: 0.453007, acc.: 80.47%] [G loss: 1.815800]\n",
      "epoch:39 step:36852 [D loss: 0.457765, acc.: 82.81%] [G loss: 1.509617]\n",
      "epoch:39 step:36853 [D loss: 0.554160, acc.: 72.66%] [G loss: 1.237271]\n",
      "epoch:39 step:36854 [D loss: 0.418582, acc.: 81.25%] [G loss: 2.171026]\n",
      "epoch:39 step:36855 [D loss: 0.427217, acc.: 78.91%] [G loss: 1.975341]\n",
      "epoch:39 step:36856 [D loss: 0.299697, acc.: 92.97%] [G loss: 1.784117]\n",
      "epoch:39 step:36857 [D loss: 0.479453, acc.: 78.91%] [G loss: 1.710370]\n",
      "epoch:39 step:36858 [D loss: 0.495651, acc.: 78.12%] [G loss: 1.686265]\n",
      "epoch:39 step:36859 [D loss: 0.380448, acc.: 82.81%] [G loss: 1.431029]\n",
      "epoch:39 step:36860 [D loss: 0.518821, acc.: 76.56%] [G loss: 1.328610]\n",
      "epoch:39 step:36861 [D loss: 0.528182, acc.: 71.88%] [G loss: 1.391079]\n",
      "epoch:39 step:36862 [D loss: 0.374717, acc.: 86.72%] [G loss: 1.599595]\n",
      "epoch:39 step:36863 [D loss: 0.406757, acc.: 82.03%] [G loss: 1.472684]\n",
      "epoch:39 step:36864 [D loss: 0.647891, acc.: 64.06%] [G loss: 1.388527]\n",
      "epoch:39 step:36865 [D loss: 0.522926, acc.: 75.78%] [G loss: 1.380460]\n",
      "epoch:39 step:36866 [D loss: 0.527480, acc.: 70.31%] [G loss: 1.402067]\n",
      "epoch:39 step:36867 [D loss: 0.510791, acc.: 79.69%] [G loss: 1.791882]\n",
      "epoch:39 step:36868 [D loss: 0.675429, acc.: 61.72%] [G loss: 1.922359]\n",
      "epoch:39 step:36869 [D loss: 0.342569, acc.: 85.16%] [G loss: 2.167262]\n",
      "epoch:39 step:36870 [D loss: 0.491147, acc.: 78.91%] [G loss: 1.376250]\n",
      "epoch:39 step:36871 [D loss: 0.539626, acc.: 72.66%] [G loss: 1.767452]\n",
      "epoch:39 step:36872 [D loss: 0.613194, acc.: 69.53%] [G loss: 0.876376]\n",
      "epoch:39 step:36873 [D loss: 0.587923, acc.: 70.31%] [G loss: 1.773381]\n",
      "epoch:39 step:36874 [D loss: 0.504658, acc.: 75.78%] [G loss: 1.657290]\n",
      "epoch:39 step:36875 [D loss: 0.562351, acc.: 74.22%] [G loss: 1.952715]\n",
      "epoch:39 step:36876 [D loss: 0.616128, acc.: 65.62%] [G loss: 1.742348]\n",
      "epoch:39 step:36877 [D loss: 0.556652, acc.: 68.75%] [G loss: 1.645256]\n",
      "epoch:39 step:36878 [D loss: 0.602761, acc.: 68.75%] [G loss: 1.008382]\n",
      "epoch:39 step:36879 [D loss: 0.548504, acc.: 73.44%] [G loss: 1.777099]\n",
      "epoch:39 step:36880 [D loss: 0.516413, acc.: 75.00%] [G loss: 1.634955]\n",
      "epoch:39 step:36881 [D loss: 0.472597, acc.: 78.91%] [G loss: 1.894950]\n",
      "epoch:39 step:36882 [D loss: 0.332440, acc.: 85.94%] [G loss: 2.434567]\n",
      "epoch:39 step:36883 [D loss: 0.495919, acc.: 80.47%] [G loss: 1.315494]\n",
      "epoch:39 step:36884 [D loss: 0.436082, acc.: 80.47%] [G loss: 2.158600]\n",
      "epoch:39 step:36885 [D loss: 0.451898, acc.: 78.91%] [G loss: 1.907314]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:39 step:36886 [D loss: 0.608664, acc.: 71.88%] [G loss: 1.444543]\n",
      "epoch:39 step:36887 [D loss: 0.664288, acc.: 64.84%] [G loss: 1.628865]\n",
      "epoch:39 step:36888 [D loss: 0.452847, acc.: 76.56%] [G loss: 1.352320]\n",
      "epoch:39 step:36889 [D loss: 0.789910, acc.: 50.78%] [G loss: 0.934119]\n",
      "epoch:39 step:36890 [D loss: 0.567943, acc.: 71.09%] [G loss: 1.816489]\n",
      "epoch:39 step:36891 [D loss: 0.690375, acc.: 61.72%] [G loss: 0.960529]\n",
      "epoch:39 step:36892 [D loss: 0.540181, acc.: 71.09%] [G loss: 1.568163]\n",
      "epoch:39 step:36893 [D loss: 0.540469, acc.: 74.22%] [G loss: 1.509617]\n",
      "epoch:39 step:36894 [D loss: 0.426227, acc.: 82.03%] [G loss: 1.398395]\n",
      "epoch:39 step:36895 [D loss: 0.765152, acc.: 57.03%] [G loss: 1.814301]\n",
      "epoch:39 step:36896 [D loss: 0.544325, acc.: 74.22%] [G loss: 1.109069]\n",
      "epoch:39 step:36897 [D loss: 0.393903, acc.: 85.94%] [G loss: 1.360685]\n",
      "epoch:39 step:36898 [D loss: 0.480189, acc.: 80.47%] [G loss: 1.416008]\n",
      "epoch:39 step:36899 [D loss: 0.625097, acc.: 70.31%] [G loss: 1.394633]\n",
      "epoch:39 step:36900 [D loss: 0.507285, acc.: 77.34%] [G loss: 1.023647]\n",
      "epoch:39 step:36901 [D loss: 0.545873, acc.: 70.31%] [G loss: 1.020944]\n",
      "epoch:39 step:36902 [D loss: 0.355053, acc.: 86.72%] [G loss: 1.692343]\n",
      "epoch:39 step:36903 [D loss: 0.496876, acc.: 75.78%] [G loss: 1.356667]\n",
      "epoch:39 step:36904 [D loss: 0.567166, acc.: 67.97%] [G loss: 1.356741]\n",
      "epoch:39 step:36905 [D loss: 0.672325, acc.: 62.50%] [G loss: 1.187435]\n",
      "epoch:39 step:36906 [D loss: 0.418652, acc.: 81.25%] [G loss: 1.827058]\n",
      "epoch:39 step:36907 [D loss: 0.446122, acc.: 78.12%] [G loss: 1.285059]\n",
      "epoch:39 step:36908 [D loss: 0.463756, acc.: 78.91%] [G loss: 1.949384]\n",
      "epoch:39 step:36909 [D loss: 0.525880, acc.: 71.88%] [G loss: 1.601870]\n",
      "epoch:39 step:36910 [D loss: 0.594576, acc.: 67.19%] [G loss: 1.446011]\n",
      "epoch:39 step:36911 [D loss: 0.565864, acc.: 72.66%] [G loss: 1.768059]\n",
      "epoch:39 step:36912 [D loss: 0.451788, acc.: 82.03%] [G loss: 1.498518]\n",
      "epoch:39 step:36913 [D loss: 0.677382, acc.: 60.94%] [G loss: 1.377159]\n",
      "epoch:39 step:36914 [D loss: 0.591004, acc.: 67.97%] [G loss: 2.056013]\n",
      "epoch:39 step:36915 [D loss: 0.453087, acc.: 78.12%] [G loss: 1.895829]\n",
      "epoch:39 step:36916 [D loss: 0.539348, acc.: 74.22%] [G loss: 1.455930]\n",
      "epoch:39 step:36917 [D loss: 0.614042, acc.: 61.72%] [G loss: 1.657844]\n",
      "epoch:39 step:36918 [D loss: 0.352795, acc.: 87.50%] [G loss: 1.278904]\n",
      "epoch:39 step:36919 [D loss: 0.520103, acc.: 71.88%] [G loss: 1.240194]\n",
      "epoch:39 step:36920 [D loss: 0.476708, acc.: 77.34%] [G loss: 2.012965]\n",
      "epoch:39 step:36921 [D loss: 0.485521, acc.: 76.56%] [G loss: 1.563934]\n",
      "epoch:39 step:36922 [D loss: 0.465678, acc.: 78.91%] [G loss: 2.044674]\n",
      "epoch:39 step:36923 [D loss: 0.350984, acc.: 84.38%] [G loss: 1.932118]\n",
      "epoch:39 step:36924 [D loss: 0.530413, acc.: 71.88%] [G loss: 0.802071]\n",
      "epoch:39 step:36925 [D loss: 0.565868, acc.: 68.75%] [G loss: 1.447371]\n",
      "epoch:39 step:36926 [D loss: 0.364868, acc.: 84.38%] [G loss: 1.416589]\n",
      "epoch:39 step:36927 [D loss: 0.588557, acc.: 67.97%] [G loss: 1.615120]\n",
      "epoch:39 step:36928 [D loss: 0.636674, acc.: 67.19%] [G loss: 1.469208]\n",
      "epoch:39 step:36929 [D loss: 0.658932, acc.: 67.97%] [G loss: 1.418680]\n",
      "epoch:39 step:36930 [D loss: 0.504728, acc.: 78.12%] [G loss: 1.452628]\n",
      "epoch:39 step:36931 [D loss: 0.827585, acc.: 51.56%] [G loss: 1.584306]\n",
      "epoch:39 step:36932 [D loss: 0.575880, acc.: 69.53%] [G loss: 1.322345]\n",
      "epoch:39 step:36933 [D loss: 0.509766, acc.: 71.88%] [G loss: 1.121841]\n",
      "epoch:39 step:36934 [D loss: 0.889891, acc.: 46.88%] [G loss: 1.491541]\n",
      "epoch:39 step:36935 [D loss: 0.398287, acc.: 83.59%] [G loss: 1.333128]\n",
      "epoch:39 step:36936 [D loss: 0.505608, acc.: 75.78%] [G loss: 1.399711]\n",
      "epoch:39 step:36937 [D loss: 0.623007, acc.: 67.19%] [G loss: 1.078292]\n",
      "epoch:39 step:36938 [D loss: 0.415018, acc.: 81.25%] [G loss: 1.466311]\n",
      "epoch:39 step:36939 [D loss: 0.387287, acc.: 85.94%] [G loss: 1.964100]\n",
      "epoch:39 step:36940 [D loss: 0.687411, acc.: 60.16%] [G loss: 1.392669]\n",
      "epoch:39 step:36941 [D loss: 0.583806, acc.: 67.19%] [G loss: 1.624499]\n",
      "epoch:39 step:36942 [D loss: 0.361854, acc.: 83.59%] [G loss: 1.217974]\n",
      "epoch:39 step:36943 [D loss: 0.660532, acc.: 63.28%] [G loss: 1.567075]\n",
      "epoch:39 step:36944 [D loss: 0.682411, acc.: 58.59%] [G loss: 1.127494]\n",
      "epoch:39 step:36945 [D loss: 0.505360, acc.: 73.44%] [G loss: 1.198691]\n",
      "epoch:39 step:36946 [D loss: 0.390753, acc.: 85.94%] [G loss: 1.603961]\n",
      "epoch:39 step:36947 [D loss: 0.504614, acc.: 75.78%] [G loss: 1.475517]\n",
      "epoch:39 step:36948 [D loss: 0.608182, acc.: 67.19%] [G loss: 1.469843]\n",
      "epoch:39 step:36949 [D loss: 0.459243, acc.: 80.47%] [G loss: 1.812655]\n",
      "epoch:39 step:36950 [D loss: 0.634943, acc.: 60.16%] [G loss: 1.048096]\n",
      "epoch:39 step:36951 [D loss: 0.523346, acc.: 71.09%] [G loss: 1.640449]\n",
      "epoch:39 step:36952 [D loss: 0.566682, acc.: 71.88%] [G loss: 1.492444]\n",
      "epoch:39 step:36953 [D loss: 0.511899, acc.: 75.78%] [G loss: 1.468827]\n",
      "epoch:39 step:36954 [D loss: 0.554884, acc.: 75.00%] [G loss: 0.773742]\n",
      "epoch:39 step:36955 [D loss: 0.622954, acc.: 67.97%] [G loss: 1.168013]\n",
      "epoch:39 step:36956 [D loss: 0.451866, acc.: 76.56%] [G loss: 1.307516]\n",
      "epoch:39 step:36957 [D loss: 0.548437, acc.: 71.09%] [G loss: 1.074794]\n",
      "epoch:39 step:36958 [D loss: 0.567184, acc.: 70.31%] [G loss: 1.557058]\n",
      "epoch:39 step:36959 [D loss: 0.811298, acc.: 50.78%] [G loss: 1.798110]\n",
      "epoch:39 step:36960 [D loss: 0.744120, acc.: 60.16%] [G loss: 1.657438]\n",
      "epoch:39 step:36961 [D loss: 0.406486, acc.: 82.81%] [G loss: 1.625061]\n",
      "epoch:39 step:36962 [D loss: 0.602595, acc.: 73.44%] [G loss: 0.911739]\n",
      "epoch:39 step:36963 [D loss: 0.471028, acc.: 77.34%] [G loss: 1.583169]\n",
      "epoch:39 step:36964 [D loss: 0.497758, acc.: 73.44%] [G loss: 1.409118]\n",
      "epoch:39 step:36965 [D loss: 0.511152, acc.: 72.66%] [G loss: 1.266105]\n",
      "epoch:39 step:36966 [D loss: 0.563611, acc.: 67.97%] [G loss: 1.320978]\n",
      "epoch:39 step:36967 [D loss: 0.295209, acc.: 91.41%] [G loss: 1.484809]\n",
      "epoch:39 step:36968 [D loss: 0.483699, acc.: 75.78%] [G loss: 2.048586]\n",
      "epoch:39 step:36969 [D loss: 0.471986, acc.: 78.91%] [G loss: 1.535356]\n",
      "epoch:39 step:36970 [D loss: 0.836617, acc.: 49.22%] [G loss: 1.117940]\n",
      "epoch:39 step:36971 [D loss: 0.677080, acc.: 61.72%] [G loss: 1.375466]\n",
      "epoch:39 step:36972 [D loss: 0.593283, acc.: 69.53%] [G loss: 1.223714]\n",
      "epoch:39 step:36973 [D loss: 0.595543, acc.: 68.75%] [G loss: 1.633776]\n",
      "epoch:39 step:36974 [D loss: 0.629872, acc.: 67.19%] [G loss: 1.813973]\n",
      "epoch:39 step:36975 [D loss: 0.496869, acc.: 75.78%] [G loss: 2.120550]\n",
      "epoch:39 step:36976 [D loss: 0.429380, acc.: 71.09%] [G loss: 1.885569]\n",
      "epoch:39 step:36977 [D loss: 0.604028, acc.: 69.53%] [G loss: 1.599376]\n",
      "epoch:39 step:36978 [D loss: 0.551379, acc.: 71.09%] [G loss: 1.293728]\n",
      "epoch:39 step:36979 [D loss: 0.541447, acc.: 73.44%] [G loss: 1.740244]\n",
      "epoch:39 step:36980 [D loss: 0.493074, acc.: 76.56%] [G loss: 1.373740]\n",
      "epoch:39 step:36981 [D loss: 0.514160, acc.: 77.34%] [G loss: 1.789161]\n",
      "epoch:39 step:36982 [D loss: 0.642676, acc.: 64.84%] [G loss: 1.399819]\n",
      "epoch:39 step:36983 [D loss: 0.450349, acc.: 80.47%] [G loss: 1.850710]\n",
      "epoch:39 step:36984 [D loss: 0.602648, acc.: 71.09%] [G loss: 1.356569]\n",
      "epoch:39 step:36985 [D loss: 0.590164, acc.: 68.75%] [G loss: 2.238134]\n",
      "epoch:39 step:36986 [D loss: 0.472760, acc.: 77.34%] [G loss: 1.681073]\n",
      "epoch:39 step:36987 [D loss: 0.558168, acc.: 72.66%] [G loss: 1.190392]\n",
      "epoch:39 step:36988 [D loss: 0.422128, acc.: 78.91%] [G loss: 1.889920]\n",
      "epoch:39 step:36989 [D loss: 0.472455, acc.: 78.12%] [G loss: 2.090544]\n",
      "epoch:39 step:36990 [D loss: 0.438118, acc.: 78.91%] [G loss: 1.206819]\n",
      "epoch:39 step:36991 [D loss: 0.516088, acc.: 76.56%] [G loss: 1.466380]\n",
      "epoch:39 step:36992 [D loss: 0.739097, acc.: 64.06%] [G loss: 1.621302]\n",
      "epoch:39 step:36993 [D loss: 0.481206, acc.: 80.47%] [G loss: 1.294122]\n",
      "epoch:39 step:36994 [D loss: 0.388809, acc.: 82.81%] [G loss: 1.638915]\n",
      "epoch:39 step:36995 [D loss: 0.681169, acc.: 61.72%] [G loss: 1.012108]\n",
      "epoch:39 step:36996 [D loss: 0.480938, acc.: 78.12%] [G loss: 1.630224]\n",
      "epoch:39 step:36997 [D loss: 0.643269, acc.: 67.97%] [G loss: 1.238863]\n",
      "epoch:39 step:36998 [D loss: 0.557753, acc.: 69.53%] [G loss: 1.343585]\n",
      "epoch:39 step:36999 [D loss: 0.655136, acc.: 63.28%] [G loss: 1.235814]\n",
      "epoch:39 step:37000 [D loss: 0.689809, acc.: 64.84%] [G loss: 1.523059]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:39 step:37001 [D loss: 0.441726, acc.: 78.91%] [G loss: 1.444735]\n",
      "epoch:39 step:37002 [D loss: 0.512050, acc.: 73.44%] [G loss: 1.624398]\n",
      "epoch:39 step:37003 [D loss: 0.656588, acc.: 60.94%] [G loss: 1.672837]\n",
      "epoch:39 step:37004 [D loss: 0.802401, acc.: 52.34%] [G loss: 1.829042]\n",
      "epoch:39 step:37005 [D loss: 0.421984, acc.: 82.81%] [G loss: 1.963761]\n",
      "epoch:39 step:37006 [D loss: 0.555894, acc.: 74.22%] [G loss: 1.799433]\n",
      "epoch:39 step:37007 [D loss: 0.694801, acc.: 58.59%] [G loss: 1.210439]\n",
      "epoch:39 step:37008 [D loss: 0.512552, acc.: 78.12%] [G loss: 1.284373]\n",
      "epoch:39 step:37009 [D loss: 0.497359, acc.: 82.03%] [G loss: 1.620774]\n",
      "epoch:39 step:37010 [D loss: 0.262752, acc.: 94.53%] [G loss: 1.695931]\n",
      "epoch:39 step:37011 [D loss: 0.557161, acc.: 71.88%] [G loss: 1.595615]\n",
      "epoch:39 step:37012 [D loss: 0.476878, acc.: 77.34%] [G loss: 1.562918]\n",
      "epoch:39 step:37013 [D loss: 0.817231, acc.: 54.69%] [G loss: 1.308623]\n",
      "epoch:39 step:37014 [D loss: 0.644730, acc.: 65.62%] [G loss: 1.206292]\n",
      "epoch:39 step:37015 [D loss: 0.538643, acc.: 74.22%] [G loss: 1.384657]\n",
      "epoch:39 step:37016 [D loss: 0.307150, acc.: 89.06%] [G loss: 2.103138]\n",
      "epoch:39 step:37017 [D loss: 0.452420, acc.: 75.00%] [G loss: 1.948508]\n",
      "epoch:39 step:37018 [D loss: 0.938414, acc.: 45.31%] [G loss: 1.305545]\n",
      "epoch:39 step:37019 [D loss: 0.558087, acc.: 73.44%] [G loss: 1.698617]\n",
      "epoch:39 step:37020 [D loss: 0.703807, acc.: 55.47%] [G loss: 1.479722]\n",
      "epoch:39 step:37021 [D loss: 0.427990, acc.: 81.25%] [G loss: 1.736839]\n",
      "epoch:39 step:37022 [D loss: 0.349572, acc.: 84.38%] [G loss: 1.339189]\n",
      "epoch:39 step:37023 [D loss: 0.494980, acc.: 78.12%] [G loss: 1.439739]\n",
      "epoch:39 step:37024 [D loss: 0.586170, acc.: 69.53%] [G loss: 1.877984]\n",
      "epoch:39 step:37025 [D loss: 0.540626, acc.: 71.88%] [G loss: 1.054446]\n",
      "epoch:39 step:37026 [D loss: 0.650642, acc.: 62.50%] [G loss: 1.410589]\n",
      "epoch:39 step:37027 [D loss: 0.473398, acc.: 78.91%] [G loss: 1.846583]\n",
      "epoch:39 step:37028 [D loss: 0.560432, acc.: 73.44%] [G loss: 1.776930]\n",
      "epoch:39 step:37029 [D loss: 0.659883, acc.: 62.50%] [G loss: 1.107336]\n",
      "epoch:39 step:37030 [D loss: 0.664947, acc.: 64.84%] [G loss: 1.148135]\n",
      "epoch:39 step:37031 [D loss: 0.314779, acc.: 91.41%] [G loss: 1.420582]\n",
      "epoch:39 step:37032 [D loss: 0.456702, acc.: 83.59%] [G loss: 1.380921]\n",
      "epoch:39 step:37033 [D loss: 0.556387, acc.: 71.09%] [G loss: 1.306787]\n",
      "epoch:39 step:37034 [D loss: 0.514862, acc.: 73.44%] [G loss: 1.211452]\n",
      "epoch:39 step:37035 [D loss: 0.930495, acc.: 41.41%] [G loss: 2.067845]\n",
      "epoch:39 step:37036 [D loss: 0.593601, acc.: 71.09%] [G loss: 1.049077]\n",
      "epoch:39 step:37037 [D loss: 0.568133, acc.: 66.41%] [G loss: 1.432209]\n",
      "epoch:39 step:37038 [D loss: 0.466470, acc.: 78.12%] [G loss: 1.623173]\n",
      "epoch:39 step:37039 [D loss: 0.529090, acc.: 72.66%] [G loss: 1.298889]\n",
      "epoch:39 step:37040 [D loss: 0.548934, acc.: 73.44%] [G loss: 1.916694]\n",
      "epoch:39 step:37041 [D loss: 0.597444, acc.: 66.41%] [G loss: 1.020248]\n",
      "epoch:39 step:37042 [D loss: 0.851663, acc.: 49.22%] [G loss: 1.523193]\n",
      "epoch:39 step:37043 [D loss: 0.420004, acc.: 82.81%] [G loss: 1.792150]\n",
      "epoch:39 step:37044 [D loss: 0.379213, acc.: 85.16%] [G loss: 2.176640]\n",
      "epoch:39 step:37045 [D loss: 0.575705, acc.: 72.66%] [G loss: 1.276724]\n",
      "epoch:39 step:37046 [D loss: 0.605812, acc.: 69.53%] [G loss: 1.456944]\n",
      "epoch:39 step:37047 [D loss: 0.586554, acc.: 67.19%] [G loss: 1.474394]\n",
      "epoch:39 step:37048 [D loss: 0.419195, acc.: 82.03%] [G loss: 1.524278]\n",
      "epoch:39 step:37049 [D loss: 0.391457, acc.: 88.28%] [G loss: 2.314564]\n",
      "epoch:39 step:37050 [D loss: 0.441642, acc.: 76.56%] [G loss: 1.357839]\n",
      "epoch:39 step:37051 [D loss: 0.391218, acc.: 82.81%] [G loss: 1.845966]\n",
      "epoch:39 step:37052 [D loss: 0.702754, acc.: 61.72%] [G loss: 1.580105]\n",
      "epoch:39 step:37053 [D loss: 0.427589, acc.: 80.47%] [G loss: 2.604623]\n",
      "epoch:39 step:37054 [D loss: 0.689884, acc.: 59.38%] [G loss: 2.028332]\n",
      "epoch:39 step:37055 [D loss: 0.357537, acc.: 85.94%] [G loss: 1.553221]\n",
      "epoch:39 step:37056 [D loss: 0.461996, acc.: 78.12%] [G loss: 1.176582]\n",
      "epoch:39 step:37057 [D loss: 0.473660, acc.: 79.69%] [G loss: 1.771735]\n",
      "epoch:39 step:37058 [D loss: 0.541709, acc.: 69.53%] [G loss: 1.239384]\n",
      "epoch:39 step:37059 [D loss: 0.345575, acc.: 84.38%] [G loss: 1.852700]\n",
      "epoch:39 step:37060 [D loss: 0.372150, acc.: 86.72%] [G loss: 1.658792]\n",
      "epoch:39 step:37061 [D loss: 0.444857, acc.: 80.47%] [G loss: 1.976624]\n",
      "epoch:39 step:37062 [D loss: 0.427735, acc.: 84.38%] [G loss: 1.917079]\n",
      "epoch:39 step:37063 [D loss: 0.537545, acc.: 70.31%] [G loss: 1.392872]\n",
      "epoch:39 step:37064 [D loss: 0.331080, acc.: 85.16%] [G loss: 2.259305]\n",
      "epoch:39 step:37065 [D loss: 0.811792, acc.: 52.34%] [G loss: 1.109069]\n",
      "epoch:39 step:37066 [D loss: 0.353024, acc.: 86.72%] [G loss: 1.555588]\n",
      "epoch:39 step:37067 [D loss: 0.365620, acc.: 83.59%] [G loss: 1.567738]\n",
      "epoch:39 step:37068 [D loss: 0.487347, acc.: 75.00%] [G loss: 1.060681]\n",
      "epoch:39 step:37069 [D loss: 0.574046, acc.: 71.09%] [G loss: 1.210046]\n",
      "epoch:39 step:37070 [D loss: 0.928321, acc.: 44.53%] [G loss: 1.553165]\n",
      "epoch:39 step:37071 [D loss: 0.518416, acc.: 75.78%] [G loss: 1.583142]\n",
      "epoch:39 step:37072 [D loss: 0.707051, acc.: 55.47%] [G loss: 1.441487]\n",
      "epoch:39 step:37073 [D loss: 0.473855, acc.: 78.12%] [G loss: 1.406730]\n",
      "epoch:39 step:37074 [D loss: 0.390609, acc.: 85.16%] [G loss: 1.514327]\n",
      "epoch:39 step:37075 [D loss: 0.540312, acc.: 71.09%] [G loss: 1.494206]\n",
      "epoch:39 step:37076 [D loss: 0.380119, acc.: 85.94%] [G loss: 1.877416]\n",
      "epoch:39 step:37077 [D loss: 0.566728, acc.: 71.88%] [G loss: 1.278960]\n",
      "epoch:39 step:37078 [D loss: 0.533063, acc.: 73.44%] [G loss: 1.727053]\n",
      "epoch:39 step:37079 [D loss: 0.541400, acc.: 70.31%] [G loss: 1.814670]\n",
      "epoch:39 step:37080 [D loss: 0.531627, acc.: 74.22%] [G loss: 1.843157]\n",
      "epoch:39 step:37081 [D loss: 0.655488, acc.: 62.50%] [G loss: 1.279987]\n",
      "epoch:39 step:37082 [D loss: 0.296898, acc.: 90.62%] [G loss: 1.781150]\n",
      "epoch:39 step:37083 [D loss: 0.491449, acc.: 80.47%] [G loss: 1.171712]\n",
      "epoch:39 step:37084 [D loss: 0.568551, acc.: 68.75%] [G loss: 1.669790]\n",
      "epoch:39 step:37085 [D loss: 0.397286, acc.: 85.94%] [G loss: 2.155512]\n",
      "epoch:39 step:37086 [D loss: 0.490172, acc.: 74.22%] [G loss: 1.521264]\n",
      "epoch:39 step:37087 [D loss: 0.476799, acc.: 76.56%] [G loss: 1.070892]\n",
      "epoch:39 step:37088 [D loss: 0.368364, acc.: 91.41%] [G loss: 1.373885]\n",
      "epoch:39 step:37089 [D loss: 0.470524, acc.: 78.12%] [G loss: 1.246984]\n",
      "epoch:39 step:37090 [D loss: 0.691540, acc.: 57.81%] [G loss: 1.007429]\n",
      "epoch:39 step:37091 [D loss: 0.491506, acc.: 75.00%] [G loss: 0.938488]\n",
      "epoch:39 step:37092 [D loss: 0.547305, acc.: 71.09%] [G loss: 1.836753]\n",
      "epoch:39 step:37093 [D loss: 0.458420, acc.: 79.69%] [G loss: 1.543692]\n",
      "epoch:39 step:37094 [D loss: 0.640283, acc.: 67.19%] [G loss: 1.382144]\n",
      "epoch:39 step:37095 [D loss: 0.636016, acc.: 64.84%] [G loss: 2.411849]\n",
      "epoch:39 step:37096 [D loss: 0.356977, acc.: 85.94%] [G loss: 1.876685]\n",
      "epoch:39 step:37097 [D loss: 0.418758, acc.: 83.59%] [G loss: 1.837054]\n",
      "epoch:39 step:37098 [D loss: 0.568598, acc.: 70.31%] [G loss: 1.241799]\n",
      "epoch:39 step:37099 [D loss: 0.384040, acc.: 84.38%] [G loss: 1.831733]\n",
      "epoch:39 step:37100 [D loss: 0.657967, acc.: 66.41%] [G loss: 1.304993]\n",
      "epoch:39 step:37101 [D loss: 0.574108, acc.: 71.88%] [G loss: 1.201440]\n",
      "epoch:39 step:37102 [D loss: 0.403849, acc.: 84.38%] [G loss: 1.542268]\n",
      "epoch:39 step:37103 [D loss: 0.489197, acc.: 72.66%] [G loss: 1.619345]\n",
      "epoch:39 step:37104 [D loss: 0.642998, acc.: 66.41%] [G loss: 1.307727]\n",
      "epoch:39 step:37105 [D loss: 0.781205, acc.: 58.59%] [G loss: 1.115239]\n",
      "epoch:39 step:37106 [D loss: 0.466759, acc.: 78.12%] [G loss: 1.348069]\n",
      "epoch:39 step:37107 [D loss: 0.418445, acc.: 85.16%] [G loss: 1.667988]\n",
      "epoch:39 step:37108 [D loss: 0.428958, acc.: 82.03%] [G loss: 2.040167]\n",
      "epoch:39 step:37109 [D loss: 0.446464, acc.: 79.69%] [G loss: 1.442225]\n",
      "epoch:39 step:37110 [D loss: 0.619500, acc.: 69.53%] [G loss: 1.553990]\n",
      "epoch:39 step:37111 [D loss: 0.576278, acc.: 67.97%] [G loss: 1.160387]\n",
      "epoch:39 step:37112 [D loss: 0.474070, acc.: 77.34%] [G loss: 1.522000]\n",
      "epoch:39 step:37113 [D loss: 0.794400, acc.: 57.03%] [G loss: 1.331207]\n",
      "epoch:39 step:37114 [D loss: 0.473874, acc.: 78.12%] [G loss: 1.323396]\n",
      "epoch:39 step:37115 [D loss: 0.642342, acc.: 59.38%] [G loss: 1.489958]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:39 step:37116 [D loss: 0.588284, acc.: 71.09%] [G loss: 1.400137]\n",
      "epoch:39 step:37117 [D loss: 0.549016, acc.: 68.75%] [G loss: 1.564304]\n",
      "epoch:39 step:37118 [D loss: 0.621899, acc.: 60.16%] [G loss: 1.847567]\n",
      "epoch:39 step:37119 [D loss: 0.530718, acc.: 77.34%] [G loss: 1.541503]\n",
      "epoch:39 step:37120 [D loss: 0.406718, acc.: 82.03%] [G loss: 1.654928]\n",
      "epoch:39 step:37121 [D loss: 0.643065, acc.: 64.06%] [G loss: 1.282339]\n",
      "epoch:39 step:37122 [D loss: 0.630184, acc.: 67.97%] [G loss: 1.776597]\n",
      "epoch:39 step:37123 [D loss: 0.420835, acc.: 78.91%] [G loss: 2.110442]\n",
      "epoch:39 step:37124 [D loss: 0.626780, acc.: 65.62%] [G loss: 1.630700]\n",
      "epoch:39 step:37125 [D loss: 0.415929, acc.: 82.03%] [G loss: 1.284189]\n",
      "epoch:39 step:37126 [D loss: 0.522410, acc.: 73.44%] [G loss: 1.425661]\n",
      "epoch:39 step:37127 [D loss: 0.471805, acc.: 82.03%] [G loss: 1.549665]\n",
      "epoch:39 step:37128 [D loss: 0.729196, acc.: 49.22%] [G loss: 1.278283]\n",
      "epoch:39 step:37129 [D loss: 0.335351, acc.: 91.41%] [G loss: 1.505293]\n",
      "epoch:39 step:37130 [D loss: 0.747158, acc.: 53.12%] [G loss: 1.233374]\n",
      "epoch:39 step:37131 [D loss: 0.675721, acc.: 61.72%] [G loss: 1.704454]\n",
      "epoch:39 step:37132 [D loss: 0.613349, acc.: 65.62%] [G loss: 0.979392]\n",
      "epoch:39 step:37133 [D loss: 0.568437, acc.: 71.88%] [G loss: 1.707085]\n",
      "epoch:39 step:37134 [D loss: 0.443632, acc.: 83.59%] [G loss: 1.930664]\n",
      "epoch:39 step:37135 [D loss: 0.586537, acc.: 68.75%] [G loss: 1.525684]\n",
      "epoch:39 step:37136 [D loss: 0.543399, acc.: 70.31%] [G loss: 1.675213]\n",
      "epoch:39 step:37137 [D loss: 0.532223, acc.: 75.78%] [G loss: 1.576493]\n",
      "epoch:39 step:37138 [D loss: 0.437758, acc.: 80.47%] [G loss: 1.901988]\n",
      "epoch:39 step:37139 [D loss: 0.694963, acc.: 57.03%] [G loss: 1.076691]\n",
      "epoch:39 step:37140 [D loss: 0.443140, acc.: 81.25%] [G loss: 1.624861]\n",
      "epoch:39 step:37141 [D loss: 0.544670, acc.: 75.00%] [G loss: 1.346523]\n",
      "epoch:39 step:37142 [D loss: 0.390949, acc.: 85.16%] [G loss: 1.822007]\n",
      "epoch:39 step:37143 [D loss: 0.420096, acc.: 86.72%] [G loss: 1.933543]\n",
      "epoch:39 step:37144 [D loss: 0.729440, acc.: 57.81%] [G loss: 1.593990]\n",
      "epoch:39 step:37145 [D loss: 0.676248, acc.: 60.16%] [G loss: 1.101034]\n",
      "epoch:39 step:37146 [D loss: 0.613464, acc.: 68.75%] [G loss: 1.438331]\n",
      "epoch:39 step:37147 [D loss: 0.544944, acc.: 78.12%] [G loss: 2.042744]\n",
      "epoch:39 step:37148 [D loss: 0.553427, acc.: 67.97%] [G loss: 1.715113]\n",
      "epoch:39 step:37149 [D loss: 0.662320, acc.: 63.28%] [G loss: 1.386860]\n",
      "epoch:39 step:37150 [D loss: 0.486495, acc.: 77.34%] [G loss: 1.972911]\n",
      "epoch:39 step:37151 [D loss: 0.662140, acc.: 64.06%] [G loss: 1.456876]\n",
      "epoch:39 step:37152 [D loss: 0.574080, acc.: 67.97%] [G loss: 1.397394]\n",
      "epoch:39 step:37153 [D loss: 0.440405, acc.: 83.59%] [G loss: 0.907446]\n",
      "epoch:39 step:37154 [D loss: 0.506102, acc.: 75.78%] [G loss: 1.147196]\n",
      "epoch:39 step:37155 [D loss: 0.474721, acc.: 76.56%] [G loss: 0.988054]\n",
      "epoch:39 step:37156 [D loss: 0.514218, acc.: 75.00%] [G loss: 1.243607]\n",
      "epoch:39 step:37157 [D loss: 0.511114, acc.: 77.34%] [G loss: 1.848636]\n",
      "epoch:39 step:37158 [D loss: 0.361854, acc.: 85.16%] [G loss: 2.319272]\n",
      "epoch:39 step:37159 [D loss: 0.488090, acc.: 75.78%] [G loss: 1.332977]\n",
      "epoch:39 step:37160 [D loss: 0.521047, acc.: 78.91%] [G loss: 1.165151]\n",
      "epoch:39 step:37161 [D loss: 0.638986, acc.: 65.62%] [G loss: 1.783926]\n",
      "epoch:39 step:37162 [D loss: 0.397524, acc.: 87.50%] [G loss: 1.820713]\n",
      "epoch:39 step:37163 [D loss: 0.576172, acc.: 78.12%] [G loss: 1.737278]\n",
      "epoch:39 step:37164 [D loss: 0.595192, acc.: 70.31%] [G loss: 0.938209]\n",
      "epoch:39 step:37165 [D loss: 0.516756, acc.: 73.44%] [G loss: 1.111448]\n",
      "epoch:39 step:37166 [D loss: 0.512439, acc.: 75.00%] [G loss: 1.672631]\n",
      "epoch:39 step:37167 [D loss: 0.576749, acc.: 68.75%] [G loss: 1.222939]\n",
      "epoch:39 step:37168 [D loss: 0.521213, acc.: 72.66%] [G loss: 1.519530]\n",
      "epoch:39 step:37169 [D loss: 0.344820, acc.: 86.72%] [G loss: 1.543053]\n",
      "epoch:39 step:37170 [D loss: 0.679648, acc.: 62.50%] [G loss: 1.322460]\n",
      "epoch:39 step:37171 [D loss: 0.357378, acc.: 87.50%] [G loss: 1.911377]\n",
      "epoch:39 step:37172 [D loss: 0.506582, acc.: 71.88%] [G loss: 1.563169]\n",
      "epoch:39 step:37173 [D loss: 0.470246, acc.: 73.44%] [G loss: 1.726541]\n",
      "epoch:39 step:37174 [D loss: 0.513697, acc.: 75.78%] [G loss: 2.235859]\n",
      "epoch:39 step:37175 [D loss: 0.713340, acc.: 61.72%] [G loss: 1.462987]\n",
      "epoch:39 step:37176 [D loss: 0.536620, acc.: 71.88%] [G loss: 1.340637]\n",
      "epoch:39 step:37177 [D loss: 0.297467, acc.: 87.50%] [G loss: 1.474043]\n",
      "epoch:39 step:37178 [D loss: 0.607647, acc.: 70.31%] [G loss: 1.121544]\n",
      "epoch:39 step:37179 [D loss: 0.464094, acc.: 76.56%] [G loss: 1.648075]\n",
      "epoch:39 step:37180 [D loss: 0.593381, acc.: 72.66%] [G loss: 1.623425]\n",
      "epoch:39 step:37181 [D loss: 0.491990, acc.: 75.78%] [G loss: 1.319556]\n",
      "epoch:39 step:37182 [D loss: 0.567811, acc.: 72.66%] [G loss: 1.330017]\n",
      "epoch:39 step:37183 [D loss: 0.376309, acc.: 86.72%] [G loss: 1.906870]\n",
      "epoch:39 step:37184 [D loss: 0.451165, acc.: 75.00%] [G loss: 1.903486]\n",
      "epoch:39 step:37185 [D loss: 0.396520, acc.: 86.72%] [G loss: 1.588984]\n",
      "epoch:39 step:37186 [D loss: 0.642267, acc.: 60.16%] [G loss: 1.742706]\n",
      "epoch:39 step:37187 [D loss: 0.359202, acc.: 90.62%] [G loss: 1.984268]\n",
      "epoch:39 step:37188 [D loss: 0.422820, acc.: 80.47%] [G loss: 1.396908]\n",
      "epoch:39 step:37189 [D loss: 0.414965, acc.: 85.94%] [G loss: 1.522918]\n",
      "epoch:39 step:37190 [D loss: 0.684403, acc.: 58.59%] [G loss: 1.150871]\n",
      "epoch:39 step:37191 [D loss: 0.545052, acc.: 71.09%] [G loss: 1.020910]\n",
      "epoch:39 step:37192 [D loss: 0.512188, acc.: 75.78%] [G loss: 1.539933]\n",
      "epoch:39 step:37193 [D loss: 0.490236, acc.: 77.34%] [G loss: 2.285915]\n",
      "epoch:39 step:37194 [D loss: 0.352584, acc.: 86.72%] [G loss: 1.977196]\n",
      "epoch:39 step:37195 [D loss: 0.480669, acc.: 78.12%] [G loss: 1.966122]\n",
      "epoch:39 step:37196 [D loss: 0.603542, acc.: 70.31%] [G loss: 1.463831]\n",
      "epoch:39 step:37197 [D loss: 0.663177, acc.: 64.06%] [G loss: 1.567692]\n",
      "epoch:39 step:37198 [D loss: 0.732181, acc.: 59.38%] [G loss: 1.420140]\n",
      "epoch:39 step:37199 [D loss: 0.589600, acc.: 69.53%] [G loss: 1.560504]\n",
      "epoch:39 step:37200 [D loss: 0.660032, acc.: 63.28%] [G loss: 1.526535]\n",
      "epoch:39 step:37201 [D loss: 0.518618, acc.: 72.66%] [G loss: 1.556187]\n",
      "epoch:39 step:37202 [D loss: 0.750787, acc.: 58.59%] [G loss: 0.979782]\n",
      "epoch:39 step:37203 [D loss: 0.452078, acc.: 75.00%] [G loss: 1.391798]\n",
      "epoch:39 step:37204 [D loss: 0.513265, acc.: 80.47%] [G loss: 1.807235]\n",
      "epoch:39 step:37205 [D loss: 0.732953, acc.: 53.12%] [G loss: 1.912637]\n",
      "epoch:39 step:37206 [D loss: 0.616428, acc.: 71.88%] [G loss: 1.027386]\n",
      "epoch:39 step:37207 [D loss: 0.558716, acc.: 67.19%] [G loss: 1.801354]\n",
      "epoch:39 step:37208 [D loss: 0.482777, acc.: 78.12%] [G loss: 1.600721]\n",
      "epoch:39 step:37209 [D loss: 0.336501, acc.: 86.72%] [G loss: 1.804720]\n",
      "epoch:39 step:37210 [D loss: 0.538333, acc.: 70.31%] [G loss: 1.309464]\n",
      "epoch:39 step:37211 [D loss: 0.848780, acc.: 48.44%] [G loss: 1.390988]\n",
      "epoch:39 step:37212 [D loss: 0.344119, acc.: 87.50%] [G loss: 1.923495]\n",
      "epoch:39 step:37213 [D loss: 0.459574, acc.: 79.69%] [G loss: 1.609111]\n",
      "epoch:39 step:37214 [D loss: 0.498491, acc.: 80.47%] [G loss: 1.284944]\n",
      "epoch:39 step:37215 [D loss: 0.611310, acc.: 67.19%] [G loss: 1.110084]\n",
      "epoch:39 step:37216 [D loss: 0.605186, acc.: 64.06%] [G loss: 1.667970]\n",
      "epoch:39 step:37217 [D loss: 0.441432, acc.: 80.47%] [G loss: 1.940085]\n",
      "epoch:39 step:37218 [D loss: 0.485231, acc.: 71.88%] [G loss: 1.302182]\n",
      "epoch:39 step:37219 [D loss: 0.563093, acc.: 73.44%] [G loss: 1.527996]\n",
      "epoch:39 step:37220 [D loss: 0.555120, acc.: 68.75%] [G loss: 1.535397]\n",
      "epoch:39 step:37221 [D loss: 0.629532, acc.: 64.84%] [G loss: 2.219334]\n",
      "epoch:39 step:37222 [D loss: 0.526433, acc.: 72.66%] [G loss: 1.612745]\n",
      "epoch:39 step:37223 [D loss: 0.472695, acc.: 81.25%] [G loss: 1.678546]\n",
      "epoch:39 step:37224 [D loss: 0.618430, acc.: 62.50%] [G loss: 0.944408]\n",
      "epoch:39 step:37225 [D loss: 0.397976, acc.: 85.16%] [G loss: 1.204896]\n",
      "epoch:39 step:37226 [D loss: 0.575712, acc.: 68.75%] [G loss: 1.213763]\n",
      "epoch:39 step:37227 [D loss: 0.700871, acc.: 63.28%] [G loss: 1.752415]\n",
      "epoch:39 step:37228 [D loss: 0.530632, acc.: 71.88%] [G loss: 1.263294]\n",
      "epoch:39 step:37229 [D loss: 0.475622, acc.: 76.56%] [G loss: 1.598448]\n",
      "epoch:39 step:37230 [D loss: 0.607171, acc.: 65.62%] [G loss: 2.257720]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:39 step:37231 [D loss: 0.627104, acc.: 65.62%] [G loss: 1.851865]\n",
      "epoch:39 step:37232 [D loss: 0.605644, acc.: 64.06%] [G loss: 1.525447]\n",
      "epoch:39 step:37233 [D loss: 0.428133, acc.: 85.16%] [G loss: 1.567205]\n",
      "epoch:39 step:37234 [D loss: 0.508339, acc.: 74.22%] [G loss: 2.199122]\n",
      "epoch:39 step:37235 [D loss: 0.581085, acc.: 75.00%] [G loss: 1.448476]\n",
      "epoch:39 step:37236 [D loss: 0.588172, acc.: 68.75%] [G loss: 1.143348]\n",
      "epoch:39 step:37237 [D loss: 0.638150, acc.: 72.66%] [G loss: 1.601812]\n",
      "epoch:39 step:37238 [D loss: 0.582552, acc.: 69.53%] [G loss: 1.854965]\n",
      "epoch:39 step:37239 [D loss: 0.684250, acc.: 62.50%] [G loss: 1.722899]\n",
      "epoch:39 step:37240 [D loss: 0.576179, acc.: 73.44%] [G loss: 1.319005]\n",
      "epoch:39 step:37241 [D loss: 0.679353, acc.: 60.94%] [G loss: 1.491600]\n",
      "epoch:39 step:37242 [D loss: 0.540792, acc.: 67.97%] [G loss: 1.611903]\n",
      "epoch:39 step:37243 [D loss: 0.378597, acc.: 85.94%] [G loss: 2.246260]\n",
      "epoch:39 step:37244 [D loss: 0.324755, acc.: 85.16%] [G loss: 1.788379]\n",
      "epoch:39 step:37245 [D loss: 0.424537, acc.: 82.03%] [G loss: 1.615836]\n",
      "epoch:39 step:37246 [D loss: 0.514753, acc.: 75.00%] [G loss: 1.208009]\n",
      "epoch:39 step:37247 [D loss: 0.806515, acc.: 44.53%] [G loss: 1.100256]\n",
      "epoch:39 step:37248 [D loss: 0.568540, acc.: 72.66%] [G loss: 1.218494]\n",
      "epoch:39 step:37249 [D loss: 0.371194, acc.: 89.06%] [G loss: 1.763633]\n",
      "epoch:39 step:37250 [D loss: 0.859653, acc.: 47.66%] [G loss: 1.790038]\n",
      "epoch:39 step:37251 [D loss: 0.566192, acc.: 68.75%] [G loss: 2.219708]\n",
      "epoch:39 step:37252 [D loss: 0.714043, acc.: 60.94%] [G loss: 2.010274]\n",
      "epoch:39 step:37253 [D loss: 0.299265, acc.: 92.19%] [G loss: 1.884838]\n",
      "epoch:39 step:37254 [D loss: 0.619532, acc.: 65.62%] [G loss: 1.396008]\n",
      "epoch:39 step:37255 [D loss: 0.485330, acc.: 78.12%] [G loss: 1.592808]\n",
      "epoch:39 step:37256 [D loss: 0.612888, acc.: 67.19%] [G loss: 1.511518]\n",
      "epoch:39 step:37257 [D loss: 0.464438, acc.: 77.34%] [G loss: 1.434829]\n",
      "epoch:39 step:37258 [D loss: 0.465365, acc.: 78.12%] [G loss: 1.949037]\n",
      "epoch:39 step:37259 [D loss: 0.537139, acc.: 71.09%] [G loss: 2.107319]\n",
      "epoch:39 step:37260 [D loss: 0.586311, acc.: 67.97%] [G loss: 1.106672]\n",
      "epoch:39 step:37261 [D loss: 0.430009, acc.: 83.59%] [G loss: 1.782045]\n",
      "epoch:39 step:37262 [D loss: 0.385490, acc.: 82.03%] [G loss: 1.902116]\n",
      "epoch:39 step:37263 [D loss: 0.435164, acc.: 79.69%] [G loss: 2.228746]\n",
      "epoch:39 step:37264 [D loss: 0.547803, acc.: 72.66%] [G loss: 1.769825]\n",
      "epoch:39 step:37265 [D loss: 0.598256, acc.: 66.41%] [G loss: 0.933876]\n",
      "epoch:39 step:37266 [D loss: 0.677580, acc.: 60.94%] [G loss: 1.168641]\n",
      "epoch:39 step:37267 [D loss: 0.540927, acc.: 75.78%] [G loss: 1.405591]\n",
      "epoch:39 step:37268 [D loss: 0.487398, acc.: 71.88%] [G loss: 1.764972]\n",
      "epoch:39 step:37269 [D loss: 0.756767, acc.: 55.47%] [G loss: 1.030543]\n",
      "epoch:39 step:37270 [D loss: 0.472633, acc.: 78.12%] [G loss: 1.432771]\n",
      "epoch:39 step:37271 [D loss: 0.496480, acc.: 74.22%] [G loss: 1.858763]\n",
      "epoch:39 step:37272 [D loss: 0.594474, acc.: 70.31%] [G loss: 1.338892]\n",
      "epoch:39 step:37273 [D loss: 0.674952, acc.: 57.81%] [G loss: 1.162578]\n",
      "epoch:39 step:37274 [D loss: 0.487631, acc.: 76.56%] [G loss: 1.397708]\n",
      "epoch:39 step:37275 [D loss: 0.369519, acc.: 88.28%] [G loss: 1.796144]\n",
      "epoch:39 step:37276 [D loss: 0.522533, acc.: 74.22%] [G loss: 0.911211]\n",
      "epoch:39 step:37277 [D loss: 0.503109, acc.: 75.78%] [G loss: 1.681315]\n",
      "epoch:39 step:37278 [D loss: 0.595080, acc.: 69.53%] [G loss: 1.112811]\n",
      "epoch:39 step:37279 [D loss: 0.528024, acc.: 71.09%] [G loss: 1.161718]\n",
      "epoch:39 step:37280 [D loss: 0.469305, acc.: 78.91%] [G loss: 1.984035]\n",
      "epoch:39 step:37281 [D loss: 0.711932, acc.: 57.81%] [G loss: 1.409095]\n",
      "epoch:39 step:37282 [D loss: 0.499101, acc.: 78.91%] [G loss: 1.647849]\n",
      "epoch:39 step:37283 [D loss: 0.488347, acc.: 72.66%] [G loss: 1.356563]\n",
      "epoch:39 step:37284 [D loss: 0.495717, acc.: 75.00%] [G loss: 1.692898]\n",
      "epoch:39 step:37285 [D loss: 0.482485, acc.: 75.78%] [G loss: 1.324293]\n",
      "epoch:39 step:37286 [D loss: 0.681838, acc.: 60.94%] [G loss: 1.636864]\n",
      "epoch:39 step:37287 [D loss: 0.505709, acc.: 79.69%] [G loss: 2.078200]\n",
      "epoch:39 step:37288 [D loss: 0.590106, acc.: 71.09%] [G loss: 1.447389]\n",
      "epoch:39 step:37289 [D loss: 0.344213, acc.: 86.72%] [G loss: 2.689085]\n",
      "epoch:39 step:37290 [D loss: 0.445513, acc.: 78.91%] [G loss: 1.570638]\n",
      "epoch:39 step:37291 [D loss: 0.385411, acc.: 85.94%] [G loss: 1.894718]\n",
      "epoch:39 step:37292 [D loss: 0.586188, acc.: 71.09%] [G loss: 1.477385]\n",
      "epoch:39 step:37293 [D loss: 0.732182, acc.: 60.16%] [G loss: 1.407588]\n",
      "epoch:39 step:37294 [D loss: 0.420755, acc.: 81.25%] [G loss: 1.099090]\n",
      "epoch:39 step:37295 [D loss: 0.563266, acc.: 74.22%] [G loss: 1.251321]\n",
      "epoch:39 step:37296 [D loss: 0.352205, acc.: 83.59%] [G loss: 1.746735]\n",
      "epoch:39 step:37297 [D loss: 0.566203, acc.: 71.09%] [G loss: 1.450946]\n",
      "epoch:39 step:37298 [D loss: 0.446402, acc.: 78.91%] [G loss: 1.237885]\n",
      "epoch:39 step:37299 [D loss: 0.596696, acc.: 68.75%] [G loss: 1.234479]\n",
      "epoch:39 step:37300 [D loss: 0.530889, acc.: 71.09%] [G loss: 0.997222]\n",
      "epoch:39 step:37301 [D loss: 0.569819, acc.: 71.09%] [G loss: 1.677681]\n",
      "epoch:39 step:37302 [D loss: 0.311644, acc.: 92.19%] [G loss: 1.817835]\n",
      "epoch:39 step:37303 [D loss: 0.658703, acc.: 58.59%] [G loss: 1.496583]\n",
      "epoch:39 step:37304 [D loss: 0.539578, acc.: 73.44%] [G loss: 1.329415]\n",
      "epoch:39 step:37305 [D loss: 0.625005, acc.: 65.62%] [G loss: 0.981623]\n",
      "epoch:39 step:37306 [D loss: 0.470030, acc.: 79.69%] [G loss: 1.343128]\n",
      "epoch:39 step:37307 [D loss: 0.766910, acc.: 55.47%] [G loss: 1.601548]\n",
      "epoch:39 step:37308 [D loss: 0.568203, acc.: 69.53%] [G loss: 1.492564]\n",
      "epoch:39 step:37309 [D loss: 0.506497, acc.: 74.22%] [G loss: 1.819813]\n",
      "epoch:39 step:37310 [D loss: 0.345750, acc.: 89.84%] [G loss: 1.770485]\n",
      "epoch:39 step:37311 [D loss: 0.608116, acc.: 71.09%] [G loss: 1.902755]\n",
      "epoch:39 step:37312 [D loss: 0.453813, acc.: 80.47%] [G loss: 1.467936]\n",
      "epoch:39 step:37313 [D loss: 0.701389, acc.: 62.50%] [G loss: 1.535050]\n",
      "epoch:39 step:37314 [D loss: 0.681869, acc.: 63.28%] [G loss: 1.345557]\n",
      "epoch:39 step:37315 [D loss: 0.484053, acc.: 78.12%] [G loss: 2.206028]\n",
      "epoch:39 step:37316 [D loss: 0.718888, acc.: 56.25%] [G loss: 1.578179]\n",
      "epoch:39 step:37317 [D loss: 0.419419, acc.: 80.47%] [G loss: 1.472181]\n",
      "epoch:39 step:37318 [D loss: 0.547386, acc.: 74.22%] [G loss: 1.296216]\n",
      "epoch:39 step:37319 [D loss: 0.521492, acc.: 67.19%] [G loss: 1.468043]\n",
      "epoch:39 step:37320 [D loss: 0.582054, acc.: 71.09%] [G loss: 1.456763]\n",
      "epoch:39 step:37321 [D loss: 0.366334, acc.: 86.72%] [G loss: 1.451679]\n",
      "epoch:39 step:37322 [D loss: 0.478692, acc.: 76.56%] [G loss: 1.571022]\n",
      "epoch:39 step:37323 [D loss: 0.684534, acc.: 63.28%] [G loss: 1.256199]\n",
      "epoch:39 step:37324 [D loss: 0.603010, acc.: 67.19%] [G loss: 1.284107]\n",
      "epoch:39 step:37325 [D loss: 0.514333, acc.: 75.00%] [G loss: 2.110298]\n",
      "epoch:39 step:37326 [D loss: 0.637686, acc.: 68.75%] [G loss: 1.579107]\n",
      "epoch:39 step:37327 [D loss: 0.490776, acc.: 73.44%] [G loss: 1.373565]\n",
      "epoch:39 step:37328 [D loss: 0.486752, acc.: 74.22%] [G loss: 1.696831]\n",
      "epoch:39 step:37329 [D loss: 0.659802, acc.: 68.75%] [G loss: 1.027619]\n",
      "epoch:39 step:37330 [D loss: 0.751451, acc.: 58.59%] [G loss: 1.640970]\n",
      "epoch:39 step:37331 [D loss: 0.426394, acc.: 80.47%] [G loss: 1.719543]\n",
      "epoch:39 step:37332 [D loss: 0.449288, acc.: 79.69%] [G loss: 1.495746]\n",
      "epoch:39 step:37333 [D loss: 0.361049, acc.: 85.94%] [G loss: 1.645416]\n",
      "epoch:39 step:37334 [D loss: 0.504076, acc.: 75.00%] [G loss: 1.658737]\n",
      "epoch:39 step:37335 [D loss: 0.539072, acc.: 75.00%] [G loss: 1.581303]\n",
      "epoch:39 step:37336 [D loss: 0.419797, acc.: 82.81%] [G loss: 1.991269]\n",
      "epoch:39 step:37337 [D loss: 0.691328, acc.: 66.41%] [G loss: 1.200036]\n",
      "epoch:39 step:37338 [D loss: 0.461110, acc.: 77.34%] [G loss: 1.358726]\n",
      "epoch:39 step:37339 [D loss: 0.461148, acc.: 81.25%] [G loss: 1.442319]\n",
      "epoch:39 step:37340 [D loss: 0.491905, acc.: 81.25%] [G loss: 1.283412]\n",
      "epoch:39 step:37341 [D loss: 0.537716, acc.: 70.31%] [G loss: 1.562832]\n",
      "epoch:39 step:37342 [D loss: 0.458959, acc.: 78.91%] [G loss: 1.790415]\n",
      "epoch:39 step:37343 [D loss: 0.651244, acc.: 65.62%] [G loss: 1.577897]\n",
      "epoch:39 step:37344 [D loss: 0.709966, acc.: 63.28%] [G loss: 1.409726]\n",
      "epoch:39 step:37345 [D loss: 0.558301, acc.: 71.09%] [G loss: 1.227039]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:39 step:37346 [D loss: 0.560347, acc.: 71.88%] [G loss: 1.416011]\n",
      "epoch:39 step:37347 [D loss: 0.458682, acc.: 76.56%] [G loss: 1.790535]\n",
      "epoch:39 step:37348 [D loss: 0.590114, acc.: 68.75%] [G loss: 1.385464]\n",
      "epoch:39 step:37349 [D loss: 0.817984, acc.: 57.03%] [G loss: 2.037214]\n",
      "epoch:39 step:37350 [D loss: 0.632149, acc.: 68.75%] [G loss: 1.400572]\n",
      "epoch:39 step:37351 [D loss: 0.347501, acc.: 86.72%] [G loss: 1.726753]\n",
      "epoch:39 step:37352 [D loss: 0.471568, acc.: 78.12%] [G loss: 1.537224]\n",
      "epoch:39 step:37353 [D loss: 0.520833, acc.: 74.22%] [G loss: 0.897506]\n",
      "epoch:39 step:37354 [D loss: 0.435373, acc.: 82.81%] [G loss: 1.846293]\n",
      "epoch:39 step:37355 [D loss: 0.401537, acc.: 80.47%] [G loss: 1.172756]\n",
      "epoch:39 step:37356 [D loss: 0.515017, acc.: 76.56%] [G loss: 1.620640]\n",
      "epoch:39 step:37357 [D loss: 0.409567, acc.: 85.16%] [G loss: 1.732549]\n",
      "epoch:39 step:37358 [D loss: 0.652946, acc.: 64.06%] [G loss: 1.253320]\n",
      "epoch:39 step:37359 [D loss: 0.351415, acc.: 88.28%] [G loss: 1.786824]\n",
      "epoch:39 step:37360 [D loss: 0.506990, acc.: 78.12%] [G loss: 1.899635]\n",
      "epoch:39 step:37361 [D loss: 0.371238, acc.: 84.38%] [G loss: 1.352722]\n",
      "epoch:39 step:37362 [D loss: 0.566754, acc.: 74.22%] [G loss: 1.417631]\n",
      "epoch:39 step:37363 [D loss: 0.592329, acc.: 69.53%] [G loss: 1.383044]\n",
      "epoch:39 step:37364 [D loss: 0.476614, acc.: 72.66%] [G loss: 1.366130]\n",
      "epoch:39 step:37365 [D loss: 0.768222, acc.: 55.47%] [G loss: 1.537784]\n",
      "epoch:39 step:37366 [D loss: 0.541703, acc.: 71.88%] [G loss: 1.183495]\n",
      "epoch:39 step:37367 [D loss: 0.508325, acc.: 72.66%] [G loss: 1.493558]\n",
      "epoch:39 step:37368 [D loss: 0.630863, acc.: 62.50%] [G loss: 1.406176]\n",
      "epoch:39 step:37369 [D loss: 0.532099, acc.: 72.66%] [G loss: 1.586397]\n",
      "epoch:39 step:37370 [D loss: 0.476764, acc.: 81.25%] [G loss: 1.293024]\n",
      "epoch:39 step:37371 [D loss: 0.678708, acc.: 60.16%] [G loss: 1.581287]\n",
      "epoch:39 step:37372 [D loss: 0.459134, acc.: 78.91%] [G loss: 1.375420]\n",
      "epoch:39 step:37373 [D loss: 0.564798, acc.: 71.88%] [G loss: 2.038517]\n",
      "epoch:39 step:37374 [D loss: 0.517565, acc.: 73.44%] [G loss: 1.289242]\n",
      "epoch:39 step:37375 [D loss: 0.427367, acc.: 80.47%] [G loss: 1.745802]\n",
      "epoch:39 step:37376 [D loss: 0.502005, acc.: 77.34%] [G loss: 1.695895]\n",
      "epoch:39 step:37377 [D loss: 0.526214, acc.: 71.88%] [G loss: 1.720773]\n",
      "epoch:39 step:37378 [D loss: 0.612784, acc.: 67.97%] [G loss: 1.417521]\n",
      "epoch:39 step:37379 [D loss: 0.828253, acc.: 49.22%] [G loss: 1.208991]\n",
      "epoch:39 step:37380 [D loss: 0.662102, acc.: 62.50%] [G loss: 1.292030]\n",
      "epoch:39 step:37381 [D loss: 0.387879, acc.: 85.94%] [G loss: 1.701556]\n",
      "epoch:39 step:37382 [D loss: 0.457092, acc.: 76.56%] [G loss: 1.724899]\n",
      "epoch:39 step:37383 [D loss: 0.602098, acc.: 71.88%] [G loss: 1.517512]\n",
      "epoch:39 step:37384 [D loss: 0.681465, acc.: 53.91%] [G loss: 1.635149]\n",
      "epoch:39 step:37385 [D loss: 0.536185, acc.: 72.66%] [G loss: 1.446166]\n",
      "epoch:39 step:37386 [D loss: 0.592028, acc.: 68.75%] [G loss: 1.361431]\n",
      "epoch:39 step:37387 [D loss: 0.517050, acc.: 74.22%] [G loss: 1.394860]\n",
      "epoch:39 step:37388 [D loss: 0.503101, acc.: 75.00%] [G loss: 1.231323]\n",
      "epoch:39 step:37389 [D loss: 0.747780, acc.: 53.91%] [G loss: 1.051182]\n",
      "epoch:39 step:37390 [D loss: 0.521645, acc.: 75.00%] [G loss: 1.767248]\n",
      "epoch:39 step:37391 [D loss: 0.553538, acc.: 73.44%] [G loss: 1.637908]\n",
      "epoch:39 step:37392 [D loss: 0.443484, acc.: 78.12%] [G loss: 1.340275]\n",
      "epoch:39 step:37393 [D loss: 0.500978, acc.: 75.00%] [G loss: 1.909442]\n",
      "epoch:39 step:37394 [D loss: 0.738795, acc.: 60.16%] [G loss: 1.207119]\n",
      "epoch:39 step:37395 [D loss: 0.283708, acc.: 94.53%] [G loss: 2.088781]\n",
      "epoch:39 step:37396 [D loss: 0.387123, acc.: 85.94%] [G loss: 1.483020]\n",
      "epoch:39 step:37397 [D loss: 0.473645, acc.: 75.78%] [G loss: 1.628088]\n",
      "epoch:39 step:37398 [D loss: 0.488459, acc.: 71.09%] [G loss: 1.378869]\n",
      "epoch:39 step:37399 [D loss: 0.433030, acc.: 77.34%] [G loss: 1.427376]\n",
      "epoch:39 step:37400 [D loss: 0.440948, acc.: 82.03%] [G loss: 1.421165]\n",
      "epoch:39 step:37401 [D loss: 0.440293, acc.: 78.91%] [G loss: 1.417385]\n",
      "epoch:39 step:37402 [D loss: 0.884870, acc.: 39.84%] [G loss: 0.835067]\n",
      "epoch:39 step:37403 [D loss: 0.718764, acc.: 60.16%] [G loss: 1.929523]\n",
      "epoch:39 step:37404 [D loss: 0.337573, acc.: 91.41%] [G loss: 1.579829]\n",
      "epoch:39 step:37405 [D loss: 0.651302, acc.: 62.50%] [G loss: 1.533995]\n",
      "epoch:39 step:37406 [D loss: 0.439523, acc.: 82.81%] [G loss: 1.393134]\n",
      "epoch:39 step:37407 [D loss: 0.614845, acc.: 64.84%] [G loss: 1.108669]\n",
      "epoch:39 step:37408 [D loss: 0.451556, acc.: 76.56%] [G loss: 1.435366]\n",
      "epoch:39 step:37409 [D loss: 0.270870, acc.: 91.41%] [G loss: 1.875322]\n",
      "epoch:39 step:37410 [D loss: 0.621621, acc.: 64.06%] [G loss: 1.575831]\n",
      "epoch:39 step:37411 [D loss: 0.716805, acc.: 57.03%] [G loss: 1.319594]\n",
      "epoch:39 step:37412 [D loss: 0.426659, acc.: 85.16%] [G loss: 1.587584]\n",
      "epoch:39 step:37413 [D loss: 0.351116, acc.: 88.28%] [G loss: 1.981699]\n",
      "epoch:39 step:37414 [D loss: 0.520640, acc.: 68.75%] [G loss: 1.470282]\n",
      "epoch:39 step:37415 [D loss: 0.371630, acc.: 84.38%] [G loss: 1.408314]\n",
      "epoch:39 step:37416 [D loss: 0.323757, acc.: 92.97%] [G loss: 1.332010]\n",
      "epoch:39 step:37417 [D loss: 0.483659, acc.: 78.91%] [G loss: 1.409943]\n",
      "epoch:39 step:37418 [D loss: 0.393502, acc.: 85.16%] [G loss: 1.732029]\n",
      "epoch:39 step:37419 [D loss: 0.534306, acc.: 74.22%] [G loss: 1.347737]\n",
      "epoch:39 step:37420 [D loss: 0.771372, acc.: 57.81%] [G loss: 1.720136]\n",
      "epoch:39 step:37421 [D loss: 0.418780, acc.: 85.16%] [G loss: 1.547477]\n",
      "epoch:39 step:37422 [D loss: 0.627164, acc.: 62.50%] [G loss: 1.204198]\n",
      "epoch:39 step:37423 [D loss: 0.410551, acc.: 85.94%] [G loss: 1.417757]\n",
      "epoch:39 step:37424 [D loss: 0.503554, acc.: 77.34%] [G loss: 1.719429]\n",
      "epoch:39 step:37425 [D loss: 0.444011, acc.: 81.25%] [G loss: 1.360533]\n",
      "epoch:39 step:37426 [D loss: 0.477382, acc.: 78.12%] [G loss: 1.734700]\n",
      "epoch:39 step:37427 [D loss: 0.501049, acc.: 75.78%] [G loss: 1.479074]\n",
      "epoch:39 step:37428 [D loss: 0.491949, acc.: 76.56%] [G loss: 1.085570]\n",
      "epoch:39 step:37429 [D loss: 0.607643, acc.: 69.53%] [G loss: 1.467923]\n",
      "epoch:39 step:37430 [D loss: 0.709569, acc.: 62.50%] [G loss: 1.225871]\n",
      "epoch:39 step:37431 [D loss: 0.586424, acc.: 69.53%] [G loss: 1.359796]\n",
      "epoch:39 step:37432 [D loss: 0.649284, acc.: 67.19%] [G loss: 1.533267]\n",
      "epoch:39 step:37433 [D loss: 0.547649, acc.: 71.88%] [G loss: 1.503302]\n",
      "epoch:39 step:37434 [D loss: 0.542583, acc.: 74.22%] [G loss: 1.607329]\n",
      "epoch:39 step:37435 [D loss: 0.547964, acc.: 67.19%] [G loss: 1.375803]\n",
      "epoch:39 step:37436 [D loss: 0.556495, acc.: 67.97%] [G loss: 1.895636]\n",
      "epoch:39 step:37437 [D loss: 0.457095, acc.: 80.47%] [G loss: 1.613565]\n",
      "epoch:39 step:37438 [D loss: 0.564384, acc.: 69.53%] [G loss: 1.670739]\n",
      "epoch:39 step:37439 [D loss: 0.641673, acc.: 62.50%] [G loss: 1.916584]\n",
      "epoch:39 step:37440 [D loss: 0.785100, acc.: 50.00%] [G loss: 1.711349]\n",
      "epoch:39 step:37441 [D loss: 0.753967, acc.: 64.06%] [G loss: 1.475737]\n",
      "epoch:39 step:37442 [D loss: 0.622283, acc.: 66.41%] [G loss: 2.044654]\n",
      "epoch:39 step:37443 [D loss: 0.509539, acc.: 75.00%] [G loss: 1.422691]\n",
      "epoch:39 step:37444 [D loss: 0.611383, acc.: 68.75%] [G loss: 1.091942]\n",
      "epoch:39 step:37445 [D loss: 0.445332, acc.: 78.12%] [G loss: 1.058160]\n",
      "epoch:39 step:37446 [D loss: 0.641465, acc.: 66.41%] [G loss: 1.726767]\n",
      "epoch:39 step:37447 [D loss: 0.580802, acc.: 70.31%] [G loss: 1.783762]\n",
      "epoch:39 step:37448 [D loss: 0.696702, acc.: 59.38%] [G loss: 1.479727]\n",
      "epoch:39 step:37449 [D loss: 0.678751, acc.: 64.06%] [G loss: 1.566923]\n",
      "epoch:39 step:37450 [D loss: 0.617800, acc.: 66.41%] [G loss: 1.203260]\n",
      "epoch:39 step:37451 [D loss: 0.535481, acc.: 71.88%] [G loss: 1.231318]\n",
      "epoch:39 step:37452 [D loss: 0.535619, acc.: 70.31%] [G loss: 1.877511]\n",
      "epoch:39 step:37453 [D loss: 0.533398, acc.: 73.44%] [G loss: 1.587341]\n",
      "epoch:39 step:37454 [D loss: 0.388180, acc.: 85.94%] [G loss: 1.435685]\n",
      "epoch:39 step:37455 [D loss: 0.680798, acc.: 61.72%] [G loss: 1.209945]\n",
      "epoch:39 step:37456 [D loss: 0.525183, acc.: 75.00%] [G loss: 1.852815]\n",
      "epoch:39 step:37457 [D loss: 0.398069, acc.: 84.38%] [G loss: 1.400455]\n",
      "epoch:39 step:37458 [D loss: 0.514913, acc.: 73.44%] [G loss: 1.294538]\n",
      "epoch:39 step:37459 [D loss: 0.405256, acc.: 83.59%] [G loss: 1.170501]\n",
      "epoch:39 step:37460 [D loss: 0.578560, acc.: 70.31%] [G loss: 1.322549]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:39 step:37461 [D loss: 0.587288, acc.: 71.88%] [G loss: 1.165016]\n",
      "epoch:39 step:37462 [D loss: 0.322861, acc.: 88.28%] [G loss: 1.694633]\n",
      "epoch:39 step:37463 [D loss: 0.512190, acc.: 71.09%] [G loss: 2.003757]\n",
      "epoch:39 step:37464 [D loss: 0.602923, acc.: 72.66%] [G loss: 1.150062]\n",
      "epoch:39 step:37465 [D loss: 0.727918, acc.: 53.12%] [G loss: 1.358097]\n",
      "epoch:39 step:37466 [D loss: 0.707430, acc.: 62.50%] [G loss: 1.983932]\n",
      "epoch:39 step:37467 [D loss: 0.477298, acc.: 76.56%] [G loss: 1.469891]\n",
      "epoch:39 step:37468 [D loss: 0.679826, acc.: 64.06%] [G loss: 0.930553]\n",
      "epoch:39 step:37469 [D loss: 0.464617, acc.: 84.38%] [G loss: 1.559571]\n",
      "epoch:39 step:37470 [D loss: 0.669093, acc.: 64.84%] [G loss: 1.249963]\n",
      "epoch:39 step:37471 [D loss: 0.558440, acc.: 71.09%] [G loss: 1.282879]\n",
      "epoch:39 step:37472 [D loss: 0.343345, acc.: 88.28%] [G loss: 1.636791]\n",
      "epoch:39 step:37473 [D loss: 0.714859, acc.: 62.50%] [G loss: 1.454905]\n",
      "epoch:39 step:37474 [D loss: 0.476055, acc.: 78.91%] [G loss: 1.617906]\n",
      "epoch:39 step:37475 [D loss: 0.306169, acc.: 91.41%] [G loss: 1.570773]\n",
      "epoch:39 step:37476 [D loss: 0.657948, acc.: 63.28%] [G loss: 1.547578]\n",
      "epoch:39 step:37477 [D loss: 0.538380, acc.: 65.62%] [G loss: 0.912470]\n",
      "epoch:39 step:37478 [D loss: 0.443271, acc.: 81.25%] [G loss: 1.394028]\n",
      "epoch:39 step:37479 [D loss: 0.706831, acc.: 62.50%] [G loss: 1.292679]\n",
      "epoch:39 step:37480 [D loss: 0.541855, acc.: 72.66%] [G loss: 1.506427]\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function, division\n",
    "\n",
    "from keras.datasets import mnist,fashion_mnist\n",
    "from keras.layers import Input, Dense, Reshape, Flatten, Dropout\n",
    "from keras.layers import BatchNormalization, Activation, ZeroPadding2D\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "from keras.layers.convolutional import UpSampling2D, Conv2D\n",
    "from keras.models import Sequential, Model\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import sys\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "class DCGAN():\n",
    "    def __init__(self):\n",
    "        # Input shape\n",
    "        self.img_rows = 28\n",
    "        self.img_cols = 28\n",
    "        self.channels = 1\n",
    "        self.img_shape = (self.img_rows, self.img_cols, self.channels)\n",
    "        self.latent_dim = 100\n",
    "\n",
    "        optimizer = Adam(0.0002, 0.5)\n",
    "\n",
    "        # Build and compile the discriminator\n",
    "        self.discriminator = self.build_discriminator()\n",
    "        self.discriminator.compile(loss='binary_crossentropy',\n",
    "            optimizer=optimizer,\n",
    "            metrics=['accuracy'])\n",
    "\n",
    "        # Build the generator\n",
    "        self.generator = self.build_generator()\n",
    "\n",
    "        # The generator takes noise as input and generates imgs\n",
    "        z = Input(shape=(self.latent_dim,))\n",
    "        img = self.generator(z)\n",
    "\n",
    "        # For the combined model we will only train the generator\n",
    "        self.discriminator.trainable = False\n",
    "\n",
    "        # The discriminator takes generated images as input and determines validity\n",
    "        valid = self.discriminator(img)\n",
    "\n",
    "        # The combined model  (stacked generator and discriminator)\n",
    "        # Trains the generator to fool the discriminator\n",
    "        self.combined = Model(z, valid)\n",
    "        self.combined.compile(loss='binary_crossentropy', optimizer=optimizer)\n",
    "\n",
    "    def build_generator(self):\n",
    "\n",
    "        model = Sequential()\n",
    "\n",
    "        model.add(Dense(128 * 7 * 7, activation=\"relu\", input_dim=self.latent_dim))\n",
    "        model.add(Reshape((7, 7, 128)))\n",
    "        model.add(UpSampling2D())\n",
    "        model.add(Conv2D(128, kernel_size=3, padding=\"same\"))\n",
    "        model.add(BatchNormalization(momentum=0.8))\n",
    "        model.add(Activation(\"relu\"))\n",
    "        model.add(UpSampling2D())\n",
    "        model.add(Conv2D(64, kernel_size=3, padding=\"same\"))\n",
    "        model.add(BatchNormalization(momentum=0.8))\n",
    "        model.add(Activation(\"relu\"))\n",
    "        model.add(Conv2D(self.channels, kernel_size=3, padding=\"same\"))\n",
    "        model.add(Activation(\"tanh\"))\n",
    "\n",
    "        model.summary()\n",
    "\n",
    "        noise = Input(shape=(self.latent_dim,))\n",
    "        img = model(noise)\n",
    "\n",
    "        return Model(noise, img)\n",
    "\n",
    "    def build_discriminator(self):\n",
    "\n",
    "        model = Sequential()\n",
    "\n",
    "        model.add(Conv2D(32, kernel_size=3, strides=2, input_shape=self.img_shape, padding=\"same\"))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(Dropout(0.25))\n",
    "        model.add(Conv2D(64, kernel_size=3, strides=2, padding=\"same\"))\n",
    "        model.add(ZeroPadding2D(padding=((0,1),(0,1))))\n",
    "        model.add(BatchNormalization(momentum=0.8))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(Dropout(0.25))\n",
    "        model.add(Conv2D(128, kernel_size=3, strides=2, padding=\"same\"))\n",
    "        model.add(BatchNormalization(momentum=0.8))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(Dropout(0.25))\n",
    "        model.add(Conv2D(256, kernel_size=3, strides=1, padding=\"same\"))\n",
    "        model.add(BatchNormalization(momentum=0.8))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(Dropout(0.25))\n",
    "        model.add(Flatten())\n",
    "        model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "        model.summary()\n",
    "\n",
    "        img = Input(shape=self.img_shape)\n",
    "        validity = model(img)\n",
    "\n",
    "        return Model(img, validity)\n",
    "\n",
    "    def train(self, epochs, batch_size=128, save_interval=50):\n",
    "\n",
    "        # Load the dataset\n",
    "        (X_train, _), (_, _) = fashion_mnist.load_data()\n",
    "\n",
    "        # Rescale -1 to 1\n",
    "        X_train = X_train / 127.5 - 1.\n",
    "        X_train = np.expand_dims(X_train, axis=3)\n",
    "\n",
    "        # Adversarial ground truths\n",
    "        valid = np.ones((batch_size, 1))\n",
    "        fake = np.zeros((batch_size, 1))\n",
    "\n",
    "        nb_batches = int(X_train.shape[0] / batch_size)\n",
    "        global_step = 0\n",
    "\n",
    "        for epoch in range(epochs):\n",
    "\n",
    "            for index in range(nb_batches):\n",
    "                global_step += 1\n",
    "                imgs = X_train[index * batch_size:(index + 1) * batch_size]\n",
    "                # labels = y_train[index * batch_size:(index + 1) * batch_size]\n",
    "                # Sample noise and generate a batch of new images\n",
    "                noise = np.random.normal(0, 1, (batch_size, self.latent_dim))\n",
    "                gen_imgs = self.generator.predict(noise)\n",
    "\n",
    "                # Train the discriminator (real classified as ones and generated as zeros)\n",
    "                d_loss_real = self.discriminator.train_on_batch(imgs, valid)\n",
    "                d_loss_fake = self.discriminator.train_on_batch(gen_imgs, fake)\n",
    "                d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)\n",
    "\n",
    "                # ---------------------\n",
    "                #  Train Generator\n",
    "                # ---------------------\n",
    "\n",
    "                # Train the generator (wants discriminator to mistake images as real)\n",
    "                g_loss = self.combined.train_on_batch(noise, valid)\n",
    "\n",
    "                # Plot the progress\n",
    "                print(\"epoch:%d step:%d [D loss: %f, acc.: %.2f%%] [G loss: %f]\" % (\n",
    "                epoch, global_step, d_loss[0], 100 * d_loss[1], g_loss))\n",
    "\n",
    "                # If at save interval => save generated image samples\n",
    "                if global_step % save_interval == 0:\n",
    "                    self.save_imgs(epoch, global_step)\n",
    "\n",
    "    def save_imgs(self, epoch, global_step):\n",
    "        r, c = 10, 10\n",
    "        noise = np.random.normal(0, 1, (r * c, self.latent_dim))\n",
    "        gen_imgs = self.generator.predict(noise)\n",
    "\n",
    "        # Rescale images 0 - 1\n",
    "        gen_imgs = 0.5 * gen_imgs + 0.5\n",
    "\n",
    "        fig, axs = plt.subplots(r, c)\n",
    "        cnt = 0\n",
    "        for i in range(r):\n",
    "            for j in range(c):\n",
    "                axs[i, j].imshow(gen_imgs[cnt, :, :, 0], cmap='gray')\n",
    "                axs[i, j].axis('off')\n",
    "                cnt += 1\n",
    "        if not os.path.isdir('images_dcgan_fashion_mnist'):\n",
    "            os.mkdir('images_dcgan_fashion_mnist')\n",
    "        fig.savefig(\"images_dcgan_fashion_mnist/epoch_%d_step_%d.png\" % (epoch, global_step))\n",
    "        plt.close()\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    dcgan = DCGAN()\n",
    "    dcgan.train(epochs=40, batch_size=64, save_interval=200)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pppppppp [conda env:root] *",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
