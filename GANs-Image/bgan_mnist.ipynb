{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_1 (Flatten)          (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 512)               401920    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_1 (LeakyReLU)    (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_2 (LeakyReLU)    (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 257       \n",
      "=================================================================\n",
      "Total params: 533,505\n",
      "Trainable params: 533,505\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_4 (Dense)              (None, 256)               25856     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_3 (LeakyReLU)    (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 512)               131584    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_4 (LeakyReLU)    (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 512)               2048      \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 1024)              525312    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_5 (LeakyReLU)    (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 1024)              4096      \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 784)               803600    \n",
      "_________________________________________________________________\n",
      "reshape_1 (Reshape)          (None, 28, 28, 1)         0         \n",
      "=================================================================\n",
      "Total params: 1,493,520\n",
      "Trainable params: 1,489,936\n",
      "Non-trainable params: 3,584\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/imi432_006/anaconda3/envs/tf/lib/python3.5/site-packages/keras/engine/training.py:490: UserWarning: Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?\n",
      "  'Discrepancy between trainable weights and collected trainable'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0 step:1 [D loss: 0.986237, acc.: 3.12%] [G loss: 0.146112]\n",
      "epoch:0 step:2 [D loss: 0.472062, acc.: 69.53%] [G loss: 0.074949]\n",
      "epoch:0 step:3 [D loss: 0.348500, acc.: 81.25%] [G loss: 0.131366]\n",
      "epoch:0 step:4 [D loss: 0.322515, acc.: 85.16%] [G loss: 0.248839]\n",
      "epoch:0 step:5 [D loss: 0.241025, acc.: 98.44%] [G loss: 0.366994]\n",
      "epoch:0 step:6 [D loss: 0.215772, acc.: 99.22%] [G loss: 0.523038]\n",
      "epoch:0 step:7 [D loss: 0.190584, acc.: 99.22%] [G loss: 0.674367]\n",
      "epoch:0 step:8 [D loss: 0.168803, acc.: 99.22%] [G loss: 0.726735]\n",
      "epoch:0 step:9 [D loss: 0.155547, acc.: 99.22%] [G loss: 0.941902]\n",
      "epoch:0 step:10 [D loss: 0.151439, acc.: 100.00%] [G loss: 0.992103]\n",
      "epoch:0 step:11 [D loss: 0.134715, acc.: 100.00%] [G loss: 1.214959]\n",
      "epoch:0 step:12 [D loss: 0.138540, acc.: 100.00%] [G loss: 1.314952]\n",
      "epoch:0 step:13 [D loss: 0.118236, acc.: 100.00%] [G loss: 1.465600]\n",
      "epoch:0 step:14 [D loss: 0.114718, acc.: 100.00%] [G loss: 1.557668]\n",
      "epoch:0 step:15 [D loss: 0.112591, acc.: 100.00%] [G loss: 1.620037]\n",
      "epoch:0 step:16 [D loss: 0.091699, acc.: 100.00%] [G loss: 1.891257]\n",
      "epoch:0 step:17 [D loss: 0.092880, acc.: 100.00%] [G loss: 1.930997]\n",
      "epoch:0 step:18 [D loss: 0.085476, acc.: 100.00%] [G loss: 2.204501]\n",
      "epoch:0 step:19 [D loss: 0.081630, acc.: 100.00%] [G loss: 2.148076]\n",
      "epoch:0 step:20 [D loss: 0.088149, acc.: 100.00%] [G loss: 2.352849]\n",
      "epoch:0 step:21 [D loss: 0.068330, acc.: 100.00%] [G loss: 2.682514]\n",
      "epoch:0 step:22 [D loss: 0.066650, acc.: 100.00%] [G loss: 2.675416]\n",
      "epoch:0 step:23 [D loss: 0.061778, acc.: 100.00%] [G loss: 3.030265]\n",
      "epoch:0 step:24 [D loss: 0.056730, acc.: 100.00%] [G loss: 3.136083]\n",
      "epoch:0 step:25 [D loss: 0.056464, acc.: 100.00%] [G loss: 3.001372]\n",
      "epoch:0 step:26 [D loss: 0.057115, acc.: 100.00%] [G loss: 3.238011]\n",
      "epoch:0 step:27 [D loss: 0.056244, acc.: 100.00%] [G loss: 3.316236]\n",
      "epoch:0 step:28 [D loss: 0.046802, acc.: 100.00%] [G loss: 3.443832]\n",
      "epoch:0 step:29 [D loss: 0.046280, acc.: 100.00%] [G loss: 3.603018]\n",
      "epoch:0 step:30 [D loss: 0.043250, acc.: 100.00%] [G loss: 3.764125]\n",
      "epoch:0 step:31 [D loss: 0.045620, acc.: 100.00%] [G loss: 3.805314]\n",
      "epoch:0 step:32 [D loss: 0.038844, acc.: 100.00%] [G loss: 4.014724]\n",
      "epoch:0 step:33 [D loss: 0.048686, acc.: 100.00%] [G loss: 4.144382]\n",
      "epoch:0 step:34 [D loss: 0.044134, acc.: 100.00%] [G loss: 4.346238]\n",
      "epoch:0 step:35 [D loss: 0.033917, acc.: 100.00%] [G loss: 4.757872]\n",
      "epoch:0 step:36 [D loss: 0.033166, acc.: 100.00%] [G loss: 4.391522]\n",
      "epoch:0 step:37 [D loss: 0.035172, acc.: 100.00%] [G loss: 4.656454]\n",
      "epoch:0 step:38 [D loss: 0.027012, acc.: 100.00%] [G loss: 5.227425]\n",
      "epoch:0 step:39 [D loss: 0.030423, acc.: 100.00%] [G loss: 5.120149]\n",
      "epoch:0 step:40 [D loss: 0.036948, acc.: 100.00%] [G loss: 5.005644]\n",
      "epoch:0 step:41 [D loss: 0.031069, acc.: 100.00%] [G loss: 5.343441]\n",
      "epoch:0 step:42 [D loss: 0.027668, acc.: 100.00%] [G loss: 5.548327]\n",
      "epoch:0 step:43 [D loss: 0.034388, acc.: 100.00%] [G loss: 5.604106]\n",
      "epoch:0 step:44 [D loss: 0.024702, acc.: 100.00%] [G loss: 5.592728]\n",
      "epoch:0 step:45 [D loss: 0.025576, acc.: 100.00%] [G loss: 5.582313]\n",
      "epoch:0 step:46 [D loss: 0.027607, acc.: 100.00%] [G loss: 6.051411]\n",
      "epoch:0 step:47 [D loss: 0.027310, acc.: 100.00%] [G loss: 5.939385]\n",
      "epoch:0 step:48 [D loss: 0.027028, acc.: 100.00%] [G loss: 6.041370]\n",
      "epoch:0 step:49 [D loss: 0.025200, acc.: 100.00%] [G loss: 6.072308]\n",
      "epoch:0 step:50 [D loss: 0.021559, acc.: 100.00%] [G loss: 5.855586]\n",
      "epoch:0 step:51 [D loss: 0.027451, acc.: 100.00%] [G loss: 6.128963]\n",
      "epoch:0 step:52 [D loss: 0.024189, acc.: 100.00%] [G loss: 6.222016]\n",
      "epoch:0 step:53 [D loss: 0.023781, acc.: 100.00%] [G loss: 6.018984]\n",
      "epoch:0 step:54 [D loss: 0.025734, acc.: 100.00%] [G loss: 6.177486]\n",
      "epoch:0 step:55 [D loss: 0.024215, acc.: 100.00%] [G loss: 6.262676]\n",
      "epoch:0 step:56 [D loss: 0.026805, acc.: 100.00%] [G loss: 6.281439]\n",
      "epoch:0 step:57 [D loss: 0.024620, acc.: 100.00%] [G loss: 5.987556]\n",
      "epoch:0 step:58 [D loss: 0.028655, acc.: 100.00%] [G loss: 6.467237]\n",
      "epoch:0 step:59 [D loss: 0.025139, acc.: 100.00%] [G loss: 6.447758]\n",
      "epoch:0 step:60 [D loss: 0.022749, acc.: 100.00%] [G loss: 6.626892]\n",
      "epoch:0 step:61 [D loss: 0.020094, acc.: 100.00%] [G loss: 6.778515]\n",
      "epoch:0 step:62 [D loss: 0.021483, acc.: 100.00%] [G loss: 6.630483]\n",
      "epoch:0 step:63 [D loss: 0.024022, acc.: 100.00%] [G loss: 6.648287]\n",
      "epoch:0 step:64 [D loss: 0.026942, acc.: 100.00%] [G loss: 6.740635]\n",
      "epoch:0 step:65 [D loss: 0.025951, acc.: 100.00%] [G loss: 6.884770]\n",
      "epoch:0 step:66 [D loss: 0.021876, acc.: 100.00%] [G loss: 6.891817]\n",
      "epoch:0 step:67 [D loss: 0.025662, acc.: 100.00%] [G loss: 6.789513]\n",
      "epoch:0 step:68 [D loss: 0.018629, acc.: 100.00%] [G loss: 7.121820]\n",
      "epoch:0 step:69 [D loss: 0.027903, acc.: 100.00%] [G loss: 6.941483]\n",
      "epoch:0 step:70 [D loss: 0.026878, acc.: 100.00%] [G loss: 7.281404]\n",
      "epoch:0 step:71 [D loss: 0.025819, acc.: 100.00%] [G loss: 7.338793]\n",
      "epoch:0 step:72 [D loss: 0.024825, acc.: 100.00%] [G loss: 7.344434]\n",
      "epoch:0 step:73 [D loss: 0.020991, acc.: 100.00%] [G loss: 7.564557]\n",
      "epoch:0 step:74 [D loss: 0.030581, acc.: 100.00%] [G loss: 7.120166]\n",
      "epoch:0 step:75 [D loss: 0.026184, acc.: 100.00%] [G loss: 7.227164]\n",
      "epoch:0 step:76 [D loss: 0.022340, acc.: 100.00%] [G loss: 7.656167]\n",
      "epoch:0 step:77 [D loss: 0.025733, acc.: 100.00%] [G loss: 7.619732]\n",
      "epoch:0 step:78 [D loss: 0.016488, acc.: 100.00%] [G loss: 7.784806]\n",
      "epoch:0 step:79 [D loss: 0.025621, acc.: 100.00%] [G loss: 8.155611]\n",
      "epoch:0 step:80 [D loss: 0.024182, acc.: 100.00%] [G loss: 7.746270]\n",
      "epoch:0 step:81 [D loss: 0.026151, acc.: 100.00%] [G loss: 7.691331]\n",
      "epoch:0 step:82 [D loss: 0.027316, acc.: 100.00%] [G loss: 7.772807]\n",
      "epoch:0 step:83 [D loss: 0.024971, acc.: 100.00%] [G loss: 8.058819]\n",
      "epoch:0 step:84 [D loss: 0.040506, acc.: 100.00%] [G loss: 7.823916]\n",
      "epoch:0 step:85 [D loss: 0.030238, acc.: 100.00%] [G loss: 7.666943]\n",
      "epoch:0 step:86 [D loss: 0.034442, acc.: 100.00%] [G loss: 8.421246]\n",
      "epoch:0 step:87 [D loss: 0.027131, acc.: 100.00%] [G loss: 8.172501]\n",
      "epoch:0 step:88 [D loss: 0.033984, acc.: 100.00%] [G loss: 8.527022]\n",
      "epoch:0 step:89 [D loss: 0.073195, acc.: 100.00%] [G loss: 7.797439]\n",
      "epoch:0 step:90 [D loss: 0.035489, acc.: 100.00%] [G loss: 8.461927]\n",
      "epoch:0 step:91 [D loss: 0.033647, acc.: 100.00%] [G loss: 8.190996]\n",
      "epoch:0 step:92 [D loss: 0.094778, acc.: 97.66%] [G loss: 14.365627]\n",
      "epoch:0 step:93 [D loss: 0.986150, acc.: 71.09%] [G loss: 36.663132]\n",
      "epoch:0 step:94 [D loss: 0.654552, acc.: 77.34%] [G loss: 15.115840]\n",
      "epoch:0 step:95 [D loss: 0.219682, acc.: 85.94%] [G loss: 9.739923]\n",
      "epoch:0 step:96 [D loss: 0.112461, acc.: 94.53%] [G loss: 8.670740]\n",
      "epoch:0 step:97 [D loss: 0.043088, acc.: 100.00%] [G loss: 9.085892]\n",
      "epoch:0 step:98 [D loss: 0.032646, acc.: 99.22%] [G loss: 9.553932]\n",
      "epoch:0 step:99 [D loss: 0.032688, acc.: 100.00%] [G loss: 8.793379]\n",
      "epoch:0 step:100 [D loss: 0.029633, acc.: 100.00%] [G loss: 8.297665]\n",
      "epoch:0 step:101 [D loss: 0.029668, acc.: 100.00%] [G loss: 8.415222]\n",
      "epoch:0 step:102 [D loss: 0.034226, acc.: 100.00%] [G loss: 8.533182]\n",
      "epoch:0 step:103 [D loss: 0.028703, acc.: 100.00%] [G loss: 8.192656]\n",
      "epoch:0 step:104 [D loss: 0.041699, acc.: 99.22%] [G loss: 7.479038]\n",
      "epoch:0 step:105 [D loss: 0.040240, acc.: 100.00%] [G loss: 7.189888]\n",
      "epoch:0 step:106 [D loss: 0.028477, acc.: 100.00%] [G loss: 7.260683]\n",
      "epoch:0 step:107 [D loss: 0.031685, acc.: 100.00%] [G loss: 7.425709]\n",
      "epoch:0 step:108 [D loss: 0.079350, acc.: 99.22%] [G loss: 5.319743]\n",
      "epoch:0 step:109 [D loss: 0.039441, acc.: 100.00%] [G loss: 5.882218]\n",
      "epoch:0 step:110 [D loss: 0.056926, acc.: 100.00%] [G loss: 7.086331]\n",
      "epoch:0 step:111 [D loss: 0.042120, acc.: 100.00%] [G loss: 6.456428]\n",
      "epoch:0 step:112 [D loss: 0.066365, acc.: 98.44%] [G loss: 5.717963]\n",
      "epoch:0 step:113 [D loss: 0.095585, acc.: 97.66%] [G loss: 6.837775]\n",
      "epoch:0 step:114 [D loss: 0.082849, acc.: 98.44%] [G loss: 5.880758]\n",
      "epoch:0 step:115 [D loss: 0.052442, acc.: 100.00%] [G loss: 5.806874]\n",
      "epoch:0 step:116 [D loss: 0.090095, acc.: 98.44%] [G loss: 7.357125]\n",
      "epoch:0 step:117 [D loss: 0.188103, acc.: 93.75%] [G loss: 5.451127]\n",
      "epoch:0 step:118 [D loss: 0.060836, acc.: 100.00%] [G loss: 6.887030]\n",
      "epoch:0 step:119 [D loss: 0.129540, acc.: 97.66%] [G loss: 6.124113]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0 step:120 [D loss: 0.440543, acc.: 74.22%] [G loss: 6.337528]\n",
      "epoch:0 step:121 [D loss: 0.051268, acc.: 100.00%] [G loss: 9.072118]\n",
      "epoch:0 step:122 [D loss: 0.934221, acc.: 68.75%] [G loss: 7.722188]\n",
      "epoch:0 step:123 [D loss: 0.221105, acc.: 91.41%] [G loss: 5.233693]\n",
      "epoch:0 step:124 [D loss: 0.090721, acc.: 98.44%] [G loss: 6.306021]\n",
      "epoch:0 step:125 [D loss: 0.091072, acc.: 99.22%] [G loss: 6.348392]\n",
      "epoch:0 step:126 [D loss: 0.095613, acc.: 99.22%] [G loss: 6.517221]\n",
      "epoch:0 step:127 [D loss: 0.111776, acc.: 98.44%] [G loss: 5.727079]\n",
      "epoch:0 step:128 [D loss: 0.101437, acc.: 97.66%] [G loss: 6.290627]\n",
      "epoch:0 step:129 [D loss: 0.107292, acc.: 98.44%] [G loss: 6.048798]\n",
      "epoch:0 step:130 [D loss: 0.131319, acc.: 97.66%] [G loss: 6.135802]\n",
      "epoch:0 step:131 [D loss: 0.110547, acc.: 97.66%] [G loss: 7.130000]\n",
      "epoch:0 step:132 [D loss: 0.190573, acc.: 94.53%] [G loss: 3.173328]\n",
      "epoch:0 step:133 [D loss: 0.104270, acc.: 98.44%] [G loss: 5.165356]\n",
      "epoch:0 step:134 [D loss: 0.072561, acc.: 99.22%] [G loss: 5.263409]\n",
      "epoch:0 step:135 [D loss: 0.179320, acc.: 93.75%] [G loss: 5.447257]\n",
      "epoch:0 step:136 [D loss: 0.128731, acc.: 99.22%] [G loss: 6.132913]\n",
      "epoch:0 step:137 [D loss: 0.159847, acc.: 96.88%] [G loss: 3.996771]\n",
      "epoch:0 step:138 [D loss: 0.080348, acc.: 99.22%] [G loss: 6.479149]\n",
      "epoch:0 step:139 [D loss: 0.120137, acc.: 96.88%] [G loss: 5.942329]\n",
      "epoch:0 step:140 [D loss: 0.194689, acc.: 93.75%] [G loss: 6.473207]\n",
      "epoch:0 step:141 [D loss: 0.408432, acc.: 82.81%] [G loss: 6.746037]\n",
      "epoch:0 step:142 [D loss: 0.200979, acc.: 96.09%] [G loss: 4.670732]\n",
      "epoch:0 step:143 [D loss: 0.085428, acc.: 99.22%] [G loss: 6.269629]\n",
      "epoch:0 step:144 [D loss: 0.297383, acc.: 87.50%] [G loss: 4.093188]\n",
      "epoch:0 step:145 [D loss: 0.092016, acc.: 100.00%] [G loss: 6.490310]\n",
      "epoch:0 step:146 [D loss: 0.729516, acc.: 64.84%] [G loss: 3.198641]\n",
      "epoch:0 step:147 [D loss: 0.131661, acc.: 93.75%] [G loss: 6.511996]\n",
      "epoch:0 step:148 [D loss: 0.112374, acc.: 100.00%] [G loss: 7.083848]\n",
      "epoch:0 step:149 [D loss: 0.270668, acc.: 89.84%] [G loss: 4.714262]\n",
      "epoch:0 step:150 [D loss: 0.083392, acc.: 100.00%] [G loss: 8.361282]\n",
      "epoch:0 step:151 [D loss: 0.213375, acc.: 95.31%] [G loss: 5.303937]\n",
      "epoch:0 step:152 [D loss: 0.132118, acc.: 96.88%] [G loss: 8.727616]\n",
      "epoch:0 step:153 [D loss: 1.141562, acc.: 60.94%] [G loss: 4.856427]\n",
      "epoch:0 step:154 [D loss: 0.307284, acc.: 82.81%] [G loss: 7.665034]\n",
      "epoch:0 step:155 [D loss: 0.100229, acc.: 98.44%] [G loss: 9.042561]\n",
      "epoch:0 step:156 [D loss: 0.225447, acc.: 89.06%] [G loss: 5.592302]\n",
      "epoch:0 step:157 [D loss: 0.135900, acc.: 96.88%] [G loss: 6.501049]\n",
      "epoch:0 step:158 [D loss: 0.122368, acc.: 96.88%] [G loss: 6.703147]\n",
      "epoch:0 step:159 [D loss: 0.242581, acc.: 90.62%] [G loss: 4.047472]\n",
      "epoch:0 step:160 [D loss: 0.214949, acc.: 95.31%] [G loss: 4.270777]\n",
      "epoch:0 step:161 [D loss: 0.105313, acc.: 100.00%] [G loss: 5.892515]\n",
      "epoch:0 step:162 [D loss: 0.443900, acc.: 78.91%] [G loss: 3.765097]\n",
      "epoch:0 step:163 [D loss: 0.136077, acc.: 99.22%] [G loss: 6.075897]\n",
      "epoch:0 step:164 [D loss: 0.367573, acc.: 85.94%] [G loss: 5.204265]\n",
      "epoch:0 step:165 [D loss: 0.209513, acc.: 95.31%] [G loss: 5.228574]\n",
      "epoch:0 step:166 [D loss: 0.295246, acc.: 85.94%] [G loss: 4.621746]\n",
      "epoch:0 step:167 [D loss: 0.253882, acc.: 92.97%] [G loss: 4.991400]\n",
      "epoch:0 step:168 [D loss: 0.294583, acc.: 90.62%] [G loss: 4.632679]\n",
      "epoch:0 step:169 [D loss: 0.244083, acc.: 90.62%] [G loss: 4.122079]\n",
      "epoch:0 step:170 [D loss: 0.252184, acc.: 89.84%] [G loss: 5.856791]\n",
      "epoch:0 step:171 [D loss: 0.506315, acc.: 75.78%] [G loss: 5.794874]\n",
      "epoch:0 step:172 [D loss: 0.321360, acc.: 82.03%] [G loss: 4.816897]\n",
      "epoch:0 step:173 [D loss: 0.494960, acc.: 75.00%] [G loss: 4.004466]\n",
      "epoch:0 step:174 [D loss: 0.242008, acc.: 94.53%] [G loss: 5.653010]\n",
      "epoch:0 step:175 [D loss: 0.424332, acc.: 78.91%] [G loss: 3.972178]\n",
      "epoch:0 step:176 [D loss: 0.150750, acc.: 99.22%] [G loss: 6.343401]\n",
      "epoch:0 step:177 [D loss: 0.684148, acc.: 65.62%] [G loss: 2.213538]\n",
      "epoch:0 step:178 [D loss: 0.248386, acc.: 85.94%] [G loss: 8.269983]\n",
      "epoch:0 step:179 [D loss: 0.629811, acc.: 67.19%] [G loss: 4.087519]\n",
      "epoch:0 step:180 [D loss: 0.126059, acc.: 97.66%] [G loss: 6.891519]\n",
      "epoch:0 step:181 [D loss: 0.300910, acc.: 88.28%] [G loss: 5.200014]\n",
      "epoch:0 step:182 [D loss: 0.337343, acc.: 83.59%] [G loss: 5.832295]\n",
      "epoch:0 step:183 [D loss: 0.439576, acc.: 78.91%] [G loss: 3.672992]\n",
      "epoch:0 step:184 [D loss: 0.151210, acc.: 99.22%] [G loss: 5.753239]\n",
      "epoch:0 step:185 [D loss: 0.820165, acc.: 63.28%] [G loss: 2.620839]\n",
      "epoch:0 step:186 [D loss: 0.255675, acc.: 87.50%] [G loss: 6.053729]\n",
      "epoch:0 step:187 [D loss: 0.164848, acc.: 97.66%] [G loss: 5.336053]\n",
      "epoch:0 step:188 [D loss: 0.343416, acc.: 82.81%] [G loss: 3.388080]\n",
      "epoch:0 step:189 [D loss: 0.145088, acc.: 97.66%] [G loss: 5.178573]\n",
      "epoch:0 step:190 [D loss: 0.474690, acc.: 76.56%] [G loss: 4.438225]\n",
      "epoch:0 step:191 [D loss: 0.305426, acc.: 89.06%] [G loss: 4.085917]\n",
      "epoch:0 step:192 [D loss: 0.477339, acc.: 72.66%] [G loss: 4.082069]\n",
      "epoch:0 step:193 [D loss: 0.537295, acc.: 66.41%] [G loss: 2.983788]\n",
      "epoch:0 step:194 [D loss: 0.346752, acc.: 89.84%] [G loss: 5.315731]\n",
      "epoch:0 step:195 [D loss: 0.957004, acc.: 51.56%] [G loss: 1.496106]\n",
      "epoch:0 step:196 [D loss: 0.254229, acc.: 91.41%] [G loss: 4.154580]\n",
      "epoch:0 step:197 [D loss: 0.791138, acc.: 54.69%] [G loss: 1.641335]\n",
      "epoch:0 step:198 [D loss: 0.246469, acc.: 96.09%] [G loss: 5.429891]\n",
      "epoch:0 step:199 [D loss: 0.972717, acc.: 46.88%] [G loss: 0.926268]\n",
      "epoch:0 step:200 [D loss: 0.344735, acc.: 79.69%] [G loss: 4.119770]\n",
      "epoch:0 step:201 [D loss: 0.215389, acc.: 96.09%] [G loss: 4.591592]\n",
      "epoch:0 step:202 [D loss: 0.652909, acc.: 56.25%] [G loss: 1.385163]\n",
      "epoch:0 step:203 [D loss: 0.284813, acc.: 92.19%] [G loss: 4.005421]\n",
      "epoch:0 step:204 [D loss: 0.332056, acc.: 90.62%] [G loss: 3.477044]\n",
      "epoch:0 step:205 [D loss: 0.429404, acc.: 82.81%] [G loss: 2.809267]\n",
      "epoch:0 step:206 [D loss: 0.272334, acc.: 96.88%] [G loss: 4.620870]\n",
      "epoch:0 step:207 [D loss: 0.963912, acc.: 50.00%] [G loss: 0.674338]\n",
      "epoch:0 step:208 [D loss: 0.381651, acc.: 71.88%] [G loss: 4.514810]\n",
      "epoch:0 step:209 [D loss: 0.760490, acc.: 50.00%] [G loss: 1.202749]\n",
      "epoch:0 step:210 [D loss: 0.384837, acc.: 82.03%] [G loss: 3.745607]\n",
      "epoch:0 step:211 [D loss: 0.673509, acc.: 59.38%] [G loss: 1.215405]\n",
      "epoch:0 step:212 [D loss: 0.387807, acc.: 86.72%] [G loss: 3.040601]\n",
      "epoch:0 step:213 [D loss: 0.510875, acc.: 75.00%] [G loss: 2.397411]\n",
      "epoch:0 step:214 [D loss: 0.502710, acc.: 73.44%] [G loss: 2.249859]\n",
      "epoch:0 step:215 [D loss: 0.351399, acc.: 88.28%] [G loss: 3.949871]\n",
      "epoch:0 step:216 [D loss: 1.070299, acc.: 34.38%] [G loss: 0.381897]\n",
      "epoch:0 step:217 [D loss: 0.375273, acc.: 78.91%] [G loss: 2.956270]\n",
      "epoch:0 step:218 [D loss: 0.861008, acc.: 39.06%] [G loss: 0.455122]\n",
      "epoch:0 step:219 [D loss: 0.374057, acc.: 80.47%] [G loss: 2.366851]\n",
      "epoch:0 step:220 [D loss: 1.367464, acc.: 19.53%] [G loss: 0.300096]\n",
      "epoch:0 step:221 [D loss: 0.565760, acc.: 53.91%] [G loss: 0.805629]\n",
      "epoch:0 step:222 [D loss: 0.389143, acc.: 87.50%] [G loss: 2.062025]\n",
      "epoch:0 step:223 [D loss: 0.602286, acc.: 67.97%] [G loss: 0.797662]\n",
      "epoch:0 step:224 [D loss: 0.605822, acc.: 60.94%] [G loss: 0.716323]\n",
      "epoch:0 step:225 [D loss: 0.682363, acc.: 53.91%] [G loss: 0.438883]\n",
      "epoch:0 step:226 [D loss: 0.442128, acc.: 82.81%] [G loss: 1.283710]\n",
      "epoch:0 step:227 [D loss: 0.742846, acc.: 47.66%] [G loss: 0.337117]\n",
      "epoch:0 step:228 [D loss: 0.416953, acc.: 81.25%] [G loss: 1.788803]\n",
      "epoch:0 step:229 [D loss: 0.767909, acc.: 51.56%] [G loss: 0.431110]\n",
      "epoch:0 step:230 [D loss: 0.484229, acc.: 71.09%] [G loss: 1.627306]\n",
      "epoch:0 step:231 [D loss: 0.523145, acc.: 79.69%] [G loss: 1.558549]\n",
      "epoch:0 step:232 [D loss: 0.578959, acc.: 64.84%] [G loss: 0.854999]\n",
      "epoch:0 step:233 [D loss: 0.877923, acc.: 35.16%] [G loss: 0.180311]\n",
      "epoch:0 step:234 [D loss: 0.552070, acc.: 60.16%] [G loss: 1.043213]\n",
      "epoch:0 step:235 [D loss: 0.703556, acc.: 51.56%] [G loss: 0.318895]\n",
      "epoch:0 step:236 [D loss: 0.634689, acc.: 50.78%] [G loss: 0.487761]\n",
      "epoch:0 step:237 [D loss: 0.617268, acc.: 60.94%] [G loss: 0.547208]\n",
      "epoch:0 step:238 [D loss: 0.602080, acc.: 57.81%] [G loss: 0.647606]\n",
      "epoch:0 step:239 [D loss: 0.619336, acc.: 63.28%] [G loss: 0.345990]\n",
      "epoch:0 step:240 [D loss: 0.488832, acc.: 76.56%] [G loss: 1.127967]\n",
      "epoch:0 step:241 [D loss: 0.704137, acc.: 51.56%] [G loss: 0.292499]\n",
      "epoch:0 step:242 [D loss: 0.576361, acc.: 57.03%] [G loss: 0.618475]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0 step:243 [D loss: 0.761367, acc.: 42.19%] [G loss: 0.295940]\n",
      "epoch:0 step:244 [D loss: 0.587936, acc.: 57.81%] [G loss: 0.642323]\n",
      "epoch:0 step:245 [D loss: 0.676699, acc.: 53.12%] [G loss: 0.326925]\n",
      "epoch:0 step:246 [D loss: 0.746635, acc.: 42.97%] [G loss: 0.203251]\n",
      "epoch:0 step:247 [D loss: 0.591071, acc.: 59.38%] [G loss: 0.477070]\n",
      "epoch:0 step:248 [D loss: 0.707941, acc.: 48.44%] [G loss: 0.330718]\n",
      "epoch:0 step:249 [D loss: 0.622773, acc.: 54.69%] [G loss: 0.333793]\n",
      "epoch:0 step:250 [D loss: 0.539138, acc.: 64.84%] [G loss: 0.654703]\n",
      "epoch:0 step:251 [D loss: 0.761494, acc.: 42.97%] [G loss: 0.216259]\n",
      "epoch:0 step:252 [D loss: 0.651323, acc.: 51.56%] [G loss: 0.429284]\n",
      "epoch:0 step:253 [D loss: 0.642000, acc.: 55.47%] [G loss: 0.384121]\n",
      "epoch:0 step:254 [D loss: 0.637835, acc.: 58.59%] [G loss: 0.407935]\n",
      "epoch:0 step:255 [D loss: 0.648569, acc.: 53.12%] [G loss: 0.290283]\n",
      "epoch:0 step:256 [D loss: 0.660820, acc.: 48.44%] [G loss: 0.275954]\n",
      "epoch:0 step:257 [D loss: 0.535932, acc.: 65.62%] [G loss: 0.729976]\n",
      "epoch:0 step:258 [D loss: 0.683446, acc.: 46.88%] [G loss: 0.238293]\n",
      "epoch:0 step:259 [D loss: 0.664638, acc.: 49.22%] [G loss: 0.314405]\n",
      "epoch:0 step:260 [D loss: 0.664520, acc.: 50.00%] [G loss: 0.340646]\n",
      "epoch:0 step:261 [D loss: 0.639706, acc.: 56.25%] [G loss: 0.306119]\n",
      "epoch:0 step:262 [D loss: 0.648044, acc.: 52.34%] [G loss: 0.301314]\n",
      "epoch:0 step:263 [D loss: 0.914440, acc.: 32.03%] [G loss: 0.052251]\n",
      "epoch:0 step:264 [D loss: 0.629849, acc.: 46.88%] [G loss: 0.121305]\n",
      "epoch:0 step:265 [D loss: 0.619983, acc.: 58.59%] [G loss: 0.301750]\n",
      "epoch:0 step:266 [D loss: 0.664990, acc.: 50.78%] [G loss: 0.152737]\n",
      "epoch:0 step:267 [D loss: 0.596454, acc.: 53.91%] [G loss: 0.304479]\n",
      "epoch:0 step:268 [D loss: 0.677511, acc.: 50.78%] [G loss: 0.176929]\n",
      "epoch:0 step:269 [D loss: 0.790534, acc.: 34.38%] [G loss: 0.051835]\n",
      "epoch:0 step:270 [D loss: 0.625808, acc.: 53.12%] [G loss: 0.213734]\n",
      "epoch:0 step:271 [D loss: 0.662179, acc.: 45.31%] [G loss: 0.196963]\n",
      "epoch:0 step:272 [D loss: 0.630801, acc.: 54.69%] [G loss: 0.174084]\n",
      "epoch:0 step:273 [D loss: 0.614104, acc.: 55.47%] [G loss: 0.238369]\n",
      "epoch:0 step:274 [D loss: 0.705265, acc.: 47.66%] [G loss: 0.158850]\n",
      "epoch:0 step:275 [D loss: 0.683295, acc.: 48.44%] [G loss: 0.136936]\n",
      "epoch:0 step:276 [D loss: 0.669201, acc.: 47.66%] [G loss: 0.178979]\n",
      "epoch:0 step:277 [D loss: 0.649382, acc.: 49.22%] [G loss: 0.128039]\n",
      "epoch:0 step:278 [D loss: 0.611467, acc.: 59.38%] [G loss: 0.209056]\n",
      "epoch:0 step:279 [D loss: 0.615154, acc.: 61.72%] [G loss: 0.172903]\n",
      "epoch:0 step:280 [D loss: 0.588024, acc.: 63.28%] [G loss: 0.218510]\n",
      "epoch:0 step:281 [D loss: 0.667754, acc.: 44.53%] [G loss: 0.214056]\n",
      "epoch:0 step:282 [D loss: 0.635594, acc.: 53.91%] [G loss: 0.161267]\n",
      "epoch:0 step:283 [D loss: 0.603940, acc.: 55.47%] [G loss: 0.227812]\n",
      "epoch:0 step:284 [D loss: 0.603918, acc.: 57.81%] [G loss: 0.231683]\n",
      "epoch:0 step:285 [D loss: 0.603781, acc.: 60.94%] [G loss: 0.210985]\n",
      "epoch:0 step:286 [D loss: 0.584036, acc.: 64.84%] [G loss: 0.202750]\n",
      "epoch:0 step:287 [D loss: 0.594639, acc.: 59.38%] [G loss: 0.212422]\n",
      "epoch:0 step:288 [D loss: 0.656672, acc.: 51.56%] [G loss: 0.162288]\n",
      "epoch:0 step:289 [D loss: 0.581281, acc.: 60.16%] [G loss: 0.300525]\n",
      "epoch:0 step:290 [D loss: 0.717102, acc.: 45.31%] [G loss: 0.123650]\n",
      "epoch:0 step:291 [D loss: 0.756438, acc.: 38.28%] [G loss: 0.044938]\n",
      "epoch:0 step:292 [D loss: 0.690670, acc.: 39.84%] [G loss: 0.069896]\n",
      "epoch:0 step:293 [D loss: 0.668272, acc.: 41.41%] [G loss: 0.105717]\n",
      "epoch:0 step:294 [D loss: 0.601190, acc.: 63.28%] [G loss: 0.120482]\n",
      "epoch:0 step:295 [D loss: 0.687308, acc.: 45.31%] [G loss: 0.078920]\n",
      "epoch:0 step:296 [D loss: 0.607850, acc.: 53.12%] [G loss: 0.118673]\n",
      "epoch:0 step:297 [D loss: 0.623877, acc.: 57.81%] [G loss: 0.108429]\n",
      "epoch:0 step:298 [D loss: 0.695813, acc.: 45.31%] [G loss: 0.081561]\n",
      "epoch:0 step:299 [D loss: 0.613974, acc.: 55.47%] [G loss: 0.144169]\n",
      "epoch:0 step:300 [D loss: 0.625095, acc.: 61.72%] [G loss: 0.165783]\n",
      "epoch:0 step:301 [D loss: 0.710649, acc.: 43.75%] [G loss: 0.078670]\n",
      "epoch:0 step:302 [D loss: 0.631203, acc.: 54.69%] [G loss: 0.108020]\n",
      "epoch:0 step:303 [D loss: 0.689163, acc.: 39.06%] [G loss: 0.076152]\n",
      "epoch:0 step:304 [D loss: 0.640247, acc.: 51.56%] [G loss: 0.163092]\n",
      "epoch:0 step:305 [D loss: 0.596021, acc.: 61.72%] [G loss: 0.183554]\n",
      "epoch:0 step:306 [D loss: 0.618389, acc.: 53.91%] [G loss: 0.162939]\n",
      "epoch:0 step:307 [D loss: 0.581552, acc.: 65.62%] [G loss: 0.225096]\n",
      "epoch:0 step:308 [D loss: 0.658659, acc.: 57.03%] [G loss: 0.142776]\n",
      "epoch:0 step:309 [D loss: 0.668045, acc.: 47.66%] [G loss: 0.092578]\n",
      "epoch:0 step:310 [D loss: 0.609260, acc.: 57.81%] [G loss: 0.157246]\n",
      "epoch:0 step:311 [D loss: 0.641727, acc.: 58.59%] [G loss: 0.121325]\n",
      "epoch:0 step:312 [D loss: 0.792773, acc.: 28.91%] [G loss: 0.018235]\n",
      "epoch:0 step:313 [D loss: 0.667024, acc.: 46.09%] [G loss: 0.037687]\n",
      "epoch:0 step:314 [D loss: 0.618565, acc.: 51.56%] [G loss: 0.122204]\n",
      "epoch:0 step:315 [D loss: 0.618359, acc.: 60.94%] [G loss: 0.109094]\n",
      "epoch:0 step:316 [D loss: 0.742224, acc.: 36.72%] [G loss: 0.029953]\n",
      "epoch:0 step:317 [D loss: 0.643530, acc.: 49.22%] [G loss: 0.029051]\n",
      "epoch:0 step:318 [D loss: 0.624605, acc.: 52.34%] [G loss: 0.033933]\n",
      "epoch:0 step:319 [D loss: 0.601912, acc.: 57.81%] [G loss: 0.071310]\n",
      "epoch:0 step:320 [D loss: 0.598943, acc.: 60.16%] [G loss: 0.072234]\n",
      "epoch:0 step:321 [D loss: 0.673446, acc.: 49.22%] [G loss: 0.044673]\n",
      "epoch:0 step:322 [D loss: 0.598815, acc.: 62.50%] [G loss: 0.077689]\n",
      "epoch:0 step:323 [D loss: 0.590679, acc.: 62.50%] [G loss: 0.134490]\n",
      "epoch:0 step:324 [D loss: 0.587031, acc.: 63.28%] [G loss: 0.148038]\n",
      "epoch:0 step:325 [D loss: 0.593951, acc.: 65.62%] [G loss: 0.117342]\n",
      "epoch:0 step:326 [D loss: 0.639273, acc.: 48.44%] [G loss: 0.085100]\n",
      "epoch:0 step:327 [D loss: 0.607332, acc.: 54.69%] [G loss: 0.081722]\n",
      "epoch:0 step:328 [D loss: 0.663891, acc.: 54.69%] [G loss: 0.062789]\n",
      "epoch:0 step:329 [D loss: 0.583179, acc.: 61.72%] [G loss: 0.087421]\n",
      "epoch:0 step:330 [D loss: 0.637210, acc.: 53.12%] [G loss: 0.067085]\n",
      "epoch:0 step:331 [D loss: 0.605562, acc.: 55.47%] [G loss: 0.079843]\n",
      "epoch:0 step:332 [D loss: 0.618587, acc.: 55.47%] [G loss: 0.086708]\n",
      "epoch:0 step:333 [D loss: 0.628798, acc.: 53.91%] [G loss: 0.079926]\n",
      "epoch:0 step:334 [D loss: 0.642087, acc.: 53.91%] [G loss: 0.058450]\n",
      "epoch:0 step:335 [D loss: 0.592406, acc.: 60.94%] [G loss: 0.074122]\n",
      "epoch:0 step:336 [D loss: 0.573286, acc.: 66.41%] [G loss: 0.120406]\n",
      "epoch:0 step:337 [D loss: 0.589201, acc.: 67.19%] [G loss: 0.134925]\n",
      "epoch:0 step:338 [D loss: 0.558262, acc.: 74.22%] [G loss: 0.112089]\n",
      "epoch:0 step:339 [D loss: 0.584451, acc.: 57.81%] [G loss: 0.095194]\n",
      "epoch:0 step:340 [D loss: 0.591027, acc.: 60.94%] [G loss: 0.139584]\n",
      "epoch:0 step:341 [D loss: 0.640750, acc.: 57.03%] [G loss: 0.077586]\n",
      "epoch:0 step:342 [D loss: 0.609610, acc.: 55.47%] [G loss: 0.100479]\n",
      "epoch:0 step:343 [D loss: 0.572332, acc.: 71.09%] [G loss: 0.182144]\n",
      "epoch:0 step:344 [D loss: 0.537890, acc.: 85.16%] [G loss: 0.237829]\n",
      "epoch:0 step:345 [D loss: 0.747538, acc.: 39.84%] [G loss: 0.031551]\n",
      "epoch:0 step:346 [D loss: 0.641524, acc.: 49.22%] [G loss: 0.021270]\n",
      "epoch:0 step:347 [D loss: 0.585851, acc.: 61.72%] [G loss: 0.066766]\n",
      "epoch:0 step:348 [D loss: 0.610698, acc.: 59.38%] [G loss: 0.065498]\n",
      "epoch:0 step:349 [D loss: 0.636293, acc.: 49.22%] [G loss: 0.043242]\n",
      "epoch:0 step:350 [D loss: 0.621071, acc.: 51.56%] [G loss: 0.045364]\n",
      "epoch:0 step:351 [D loss: 0.611994, acc.: 57.81%] [G loss: 0.056678]\n",
      "epoch:0 step:352 [D loss: 0.635464, acc.: 50.00%] [G loss: 0.057334]\n",
      "epoch:0 step:353 [D loss: 0.589932, acc.: 60.94%] [G loss: 0.069419]\n",
      "epoch:0 step:354 [D loss: 0.591815, acc.: 64.84%] [G loss: 0.100207]\n",
      "epoch:0 step:355 [D loss: 0.603002, acc.: 63.28%] [G loss: 0.105951]\n",
      "epoch:0 step:356 [D loss: 0.586266, acc.: 71.09%] [G loss: 0.182873]\n",
      "epoch:0 step:357 [D loss: 0.581436, acc.: 64.06%] [G loss: 0.104491]\n",
      "epoch:0 step:358 [D loss: 0.554265, acc.: 77.34%] [G loss: 0.131707]\n",
      "epoch:0 step:359 [D loss: 0.611303, acc.: 66.41%] [G loss: 0.087664]\n",
      "epoch:0 step:360 [D loss: 0.621302, acc.: 59.38%] [G loss: 0.072233]\n",
      "epoch:0 step:361 [D loss: 0.590029, acc.: 61.72%] [G loss: 0.090157]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0 step:362 [D loss: 0.604960, acc.: 60.94%] [G loss: 0.085388]\n",
      "epoch:0 step:363 [D loss: 0.569621, acc.: 67.19%] [G loss: 0.076041]\n",
      "epoch:0 step:364 [D loss: 0.569897, acc.: 65.62%] [G loss: 0.097910]\n",
      "epoch:0 step:365 [D loss: 0.591366, acc.: 69.53%] [G loss: 0.086179]\n",
      "epoch:0 step:366 [D loss: 0.593048, acc.: 58.59%] [G loss: 0.098476]\n",
      "epoch:0 step:367 [D loss: 0.588891, acc.: 67.19%] [G loss: 0.107858]\n",
      "epoch:0 step:368 [D loss: 0.608480, acc.: 57.81%] [G loss: 0.057985]\n",
      "epoch:0 step:369 [D loss: 0.640524, acc.: 52.34%] [G loss: 0.041246]\n",
      "epoch:0 step:370 [D loss: 0.609260, acc.: 57.81%] [G loss: 0.055283]\n",
      "epoch:0 step:371 [D loss: 0.650775, acc.: 50.00%] [G loss: 0.049778]\n",
      "epoch:0 step:372 [D loss: 0.618915, acc.: 57.81%] [G loss: 0.056298]\n",
      "epoch:0 step:373 [D loss: 0.600205, acc.: 65.62%] [G loss: 0.052464]\n",
      "epoch:0 step:374 [D loss: 0.634947, acc.: 60.16%] [G loss: 0.027164]\n",
      "epoch:0 step:375 [D loss: 0.570859, acc.: 60.94%] [G loss: 0.069919]\n",
      "epoch:0 step:376 [D loss: 0.561083, acc.: 70.31%] [G loss: 0.078938]\n",
      "epoch:0 step:377 [D loss: 0.544550, acc.: 75.78%] [G loss: 0.133215]\n",
      "epoch:0 step:378 [D loss: 0.521207, acc.: 85.16%] [G loss: 0.145828]\n",
      "epoch:0 step:379 [D loss: 0.581644, acc.: 73.44%] [G loss: 0.094413]\n",
      "epoch:0 step:380 [D loss: 0.628509, acc.: 56.25%] [G loss: 0.065821]\n",
      "epoch:0 step:381 [D loss: 0.555866, acc.: 73.44%] [G loss: 0.106481]\n",
      "epoch:0 step:382 [D loss: 0.610543, acc.: 64.06%] [G loss: 0.086277]\n",
      "epoch:0 step:383 [D loss: 0.609805, acc.: 66.41%] [G loss: 0.064907]\n",
      "epoch:0 step:384 [D loss: 0.607354, acc.: 63.28%] [G loss: 0.069184]\n",
      "epoch:0 step:385 [D loss: 0.623033, acc.: 60.16%] [G loss: 0.071709]\n",
      "epoch:0 step:386 [D loss: 0.557474, acc.: 71.88%] [G loss: 0.087430]\n",
      "epoch:0 step:387 [D loss: 0.549521, acc.: 78.12%] [G loss: 0.138539]\n",
      "epoch:0 step:388 [D loss: 0.520323, acc.: 80.47%] [G loss: 0.149949]\n",
      "epoch:0 step:389 [D loss: 0.578800, acc.: 73.44%] [G loss: 0.090992]\n",
      "epoch:0 step:390 [D loss: 0.565741, acc.: 62.50%] [G loss: 0.090804]\n",
      "epoch:0 step:391 [D loss: 0.585000, acc.: 65.62%] [G loss: 0.088820]\n",
      "epoch:0 step:392 [D loss: 0.552592, acc.: 74.22%] [G loss: 0.086349]\n",
      "epoch:0 step:393 [D loss: 0.646413, acc.: 55.47%] [G loss: 0.050941]\n",
      "epoch:0 step:394 [D loss: 0.620569, acc.: 57.81%] [G loss: 0.052180]\n",
      "epoch:0 step:395 [D loss: 0.598653, acc.: 68.75%] [G loss: 0.054809]\n",
      "epoch:0 step:396 [D loss: 0.582699, acc.: 67.19%] [G loss: 0.101223]\n",
      "epoch:0 step:397 [D loss: 0.559146, acc.: 75.78%] [G loss: 0.132772]\n",
      "epoch:0 step:398 [D loss: 0.551056, acc.: 77.34%] [G loss: 0.101102]\n",
      "epoch:0 step:399 [D loss: 0.545849, acc.: 81.25%] [G loss: 0.115921]\n",
      "epoch:0 step:400 [D loss: 0.613715, acc.: 64.84%] [G loss: 0.068687]\n",
      "epoch:0 step:401 [D loss: 0.598226, acc.: 63.28%] [G loss: 0.075032]\n",
      "epoch:0 step:402 [D loss: 0.582684, acc.: 66.41%] [G loss: 0.100777]\n",
      "epoch:0 step:403 [D loss: 0.565720, acc.: 75.78%] [G loss: 0.112765]\n",
      "epoch:0 step:404 [D loss: 0.628260, acc.: 57.81%] [G loss: 0.068130]\n",
      "epoch:0 step:405 [D loss: 0.553599, acc.: 70.31%] [G loss: 0.082143]\n",
      "epoch:0 step:406 [D loss: 0.601063, acc.: 63.28%] [G loss: 0.090050]\n",
      "epoch:0 step:407 [D loss: 0.580916, acc.: 71.09%] [G loss: 0.085912]\n",
      "epoch:0 step:408 [D loss: 0.561587, acc.: 75.00%] [G loss: 0.143788]\n",
      "epoch:0 step:409 [D loss: 0.555223, acc.: 76.56%] [G loss: 0.094325]\n",
      "epoch:0 step:410 [D loss: 0.572236, acc.: 68.75%] [G loss: 0.099182]\n",
      "epoch:0 step:411 [D loss: 0.588899, acc.: 67.19%] [G loss: 0.095748]\n",
      "epoch:0 step:412 [D loss: 0.601885, acc.: 70.31%] [G loss: 0.084873]\n",
      "epoch:0 step:413 [D loss: 0.584330, acc.: 66.41%] [G loss: 0.097536]\n",
      "epoch:0 step:414 [D loss: 0.596739, acc.: 71.09%] [G loss: 0.080783]\n",
      "epoch:0 step:415 [D loss: 0.594550, acc.: 62.50%] [G loss: 0.101344]\n",
      "epoch:0 step:416 [D loss: 0.597228, acc.: 65.62%] [G loss: 0.086675]\n",
      "epoch:0 step:417 [D loss: 0.602589, acc.: 69.53%] [G loss: 0.113295]\n",
      "epoch:0 step:418 [D loss: 0.558018, acc.: 73.44%] [G loss: 0.106987]\n",
      "epoch:0 step:419 [D loss: 0.573765, acc.: 71.09%] [G loss: 0.155020]\n",
      "epoch:0 step:420 [D loss: 0.574170, acc.: 74.22%] [G loss: 0.093590]\n",
      "epoch:0 step:421 [D loss: 0.648216, acc.: 57.81%] [G loss: 0.055218]\n",
      "epoch:0 step:422 [D loss: 0.607917, acc.: 67.97%] [G loss: 0.047039]\n",
      "epoch:0 step:423 [D loss: 0.623030, acc.: 57.03%] [G loss: 0.055664]\n",
      "epoch:0 step:424 [D loss: 0.598961, acc.: 64.06%] [G loss: 0.067639]\n",
      "epoch:0 step:425 [D loss: 0.621101, acc.: 67.19%] [G loss: 0.064838]\n",
      "epoch:0 step:426 [D loss: 0.575553, acc.: 71.88%] [G loss: 0.096473]\n",
      "epoch:0 step:427 [D loss: 0.601631, acc.: 68.75%] [G loss: 0.111754]\n",
      "epoch:0 step:428 [D loss: 0.613778, acc.: 62.50%] [G loss: 0.096119]\n",
      "epoch:0 step:429 [D loss: 0.586545, acc.: 75.00%] [G loss: 0.079528]\n",
      "epoch:0 step:430 [D loss: 0.602342, acc.: 65.62%] [G loss: 0.066659]\n",
      "epoch:0 step:431 [D loss: 0.587251, acc.: 67.19%] [G loss: 0.057886]\n",
      "epoch:0 step:432 [D loss: 0.640013, acc.: 59.38%] [G loss: 0.045069]\n",
      "epoch:0 step:433 [D loss: 0.577717, acc.: 66.41%] [G loss: 0.050577]\n",
      "epoch:0 step:434 [D loss: 0.622289, acc.: 62.50%] [G loss: 0.062772]\n",
      "epoch:0 step:435 [D loss: 0.594334, acc.: 73.44%] [G loss: 0.083811]\n",
      "epoch:0 step:436 [D loss: 0.607634, acc.: 65.62%] [G loss: 0.077942]\n",
      "epoch:0 step:437 [D loss: 0.632319, acc.: 61.72%] [G loss: 0.065919]\n",
      "epoch:0 step:438 [D loss: 0.565154, acc.: 75.00%] [G loss: 0.072851]\n",
      "epoch:0 step:439 [D loss: 0.589127, acc.: 75.00%] [G loss: 0.083877]\n",
      "epoch:0 step:440 [D loss: 0.574140, acc.: 72.66%] [G loss: 0.075626]\n",
      "epoch:0 step:441 [D loss: 0.605641, acc.: 60.94%] [G loss: 0.068059]\n",
      "epoch:0 step:442 [D loss: 0.579637, acc.: 73.44%] [G loss: 0.068761]\n",
      "epoch:0 step:443 [D loss: 0.627268, acc.: 60.16%] [G loss: 0.056422]\n",
      "epoch:0 step:444 [D loss: 0.610173, acc.: 60.16%] [G loss: 0.072570]\n",
      "epoch:0 step:445 [D loss: 0.595943, acc.: 71.09%] [G loss: 0.067394]\n",
      "epoch:0 step:446 [D loss: 0.567752, acc.: 74.22%] [G loss: 0.087061]\n",
      "epoch:0 step:447 [D loss: 0.552584, acc.: 75.00%] [G loss: 0.102057]\n",
      "epoch:0 step:448 [D loss: 0.700671, acc.: 49.22%] [G loss: 0.045297]\n",
      "epoch:0 step:449 [D loss: 0.662236, acc.: 51.56%] [G loss: 0.046964]\n",
      "epoch:0 step:450 [D loss: 0.594892, acc.: 67.97%] [G loss: 0.040037]\n",
      "epoch:0 step:451 [D loss: 0.604446, acc.: 64.84%] [G loss: 0.048617]\n",
      "epoch:0 step:452 [D loss: 0.626451, acc.: 62.50%] [G loss: 0.040241]\n",
      "epoch:0 step:453 [D loss: 0.646126, acc.: 56.25%] [G loss: 0.049286]\n",
      "epoch:0 step:454 [D loss: 0.614112, acc.: 65.62%] [G loss: 0.041525]\n",
      "epoch:0 step:455 [D loss: 0.615000, acc.: 61.72%] [G loss: 0.040005]\n",
      "epoch:0 step:456 [D loss: 0.622833, acc.: 64.84%] [G loss: 0.034559]\n",
      "epoch:0 step:457 [D loss: 0.630941, acc.: 56.25%] [G loss: 0.035258]\n",
      "epoch:0 step:458 [D loss: 0.563755, acc.: 67.97%] [G loss: 0.060338]\n",
      "epoch:0 step:459 [D loss: 0.577182, acc.: 75.00%] [G loss: 0.073247]\n",
      "epoch:0 step:460 [D loss: 0.579184, acc.: 80.47%] [G loss: 0.103607]\n",
      "epoch:0 step:461 [D loss: 0.566589, acc.: 74.22%] [G loss: 0.080218]\n",
      "epoch:0 step:462 [D loss: 0.583861, acc.: 74.22%] [G loss: 0.051255]\n",
      "epoch:0 step:463 [D loss: 0.599035, acc.: 67.19%] [G loss: 0.031674]\n",
      "epoch:0 step:464 [D loss: 0.575335, acc.: 70.31%] [G loss: 0.046022]\n",
      "epoch:0 step:465 [D loss: 0.599520, acc.: 67.97%] [G loss: 0.051858]\n",
      "epoch:0 step:466 [D loss: 0.553788, acc.: 78.12%] [G loss: 0.069816]\n",
      "epoch:0 step:467 [D loss: 0.595628, acc.: 70.31%] [G loss: 0.058940]\n",
      "epoch:0 step:468 [D loss: 0.594336, acc.: 66.41%] [G loss: 0.051818]\n",
      "epoch:0 step:469 [D loss: 0.590948, acc.: 71.09%] [G loss: 0.073022]\n",
      "epoch:0 step:470 [D loss: 0.588375, acc.: 76.56%] [G loss: 0.052046]\n",
      "epoch:0 step:471 [D loss: 0.571847, acc.: 76.56%] [G loss: 0.081569]\n",
      "epoch:0 step:472 [D loss: 0.580869, acc.: 75.00%] [G loss: 0.078435]\n",
      "epoch:0 step:473 [D loss: 0.580274, acc.: 76.56%] [G loss: 0.070115]\n",
      "epoch:0 step:474 [D loss: 0.583008, acc.: 69.53%] [G loss: 0.055227]\n",
      "epoch:0 step:475 [D loss: 0.566821, acc.: 77.34%] [G loss: 0.078655]\n",
      "epoch:0 step:476 [D loss: 0.586929, acc.: 75.78%] [G loss: 0.078636]\n",
      "epoch:0 step:477 [D loss: 0.592523, acc.: 75.00%] [G loss: 0.069659]\n",
      "epoch:0 step:478 [D loss: 0.599776, acc.: 72.66%] [G loss: 0.052653]\n",
      "epoch:0 step:479 [D loss: 0.576552, acc.: 75.00%] [G loss: 0.081433]\n",
      "epoch:0 step:480 [D loss: 0.563897, acc.: 80.47%] [G loss: 0.066186]\n",
      "epoch:0 step:481 [D loss: 0.556513, acc.: 74.22%] [G loss: 0.079377]\n",
      "epoch:0 step:482 [D loss: 0.590989, acc.: 75.00%] [G loss: 0.071483]\n",
      "epoch:0 step:483 [D loss: 0.569298, acc.: 75.00%] [G loss: 0.060868]\n",
      "epoch:0 step:484 [D loss: 0.565385, acc.: 71.09%] [G loss: 0.075680]\n",
      "epoch:0 step:485 [D loss: 0.540515, acc.: 81.25%] [G loss: 0.084142]\n",
      "epoch:0 step:486 [D loss: 0.587240, acc.: 67.97%] [G loss: 0.073151]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0 step:487 [D loss: 0.561480, acc.: 75.78%] [G loss: 0.077810]\n",
      "epoch:0 step:488 [D loss: 0.590209, acc.: 69.53%] [G loss: 0.063098]\n",
      "epoch:0 step:489 [D loss: 0.579141, acc.: 74.22%] [G loss: 0.070310]\n",
      "epoch:0 step:490 [D loss: 0.558720, acc.: 75.78%] [G loss: 0.074443]\n",
      "epoch:0 step:491 [D loss: 0.559952, acc.: 78.12%] [G loss: 0.073831]\n",
      "epoch:0 step:492 [D loss: 0.571553, acc.: 81.25%] [G loss: 0.070621]\n",
      "epoch:0 step:493 [D loss: 0.554464, acc.: 72.66%] [G loss: 0.078145]\n",
      "epoch:0 step:494 [D loss: 0.569419, acc.: 75.00%] [G loss: 0.079822]\n",
      "epoch:0 step:495 [D loss: 0.590821, acc.: 67.97%] [G loss: 0.083810]\n",
      "epoch:0 step:496 [D loss: 0.586726, acc.: 72.66%] [G loss: 0.078227]\n",
      "epoch:0 step:497 [D loss: 0.557874, acc.: 76.56%] [G loss: 0.084465]\n",
      "epoch:0 step:498 [D loss: 0.531439, acc.: 83.59%] [G loss: 0.104656]\n",
      "epoch:0 step:499 [D loss: 0.523112, acc.: 81.25%] [G loss: 0.089597]\n",
      "epoch:0 step:500 [D loss: 0.580136, acc.: 71.09%] [G loss: 0.097279]\n",
      "epoch:0 step:501 [D loss: 0.604158, acc.: 63.28%] [G loss: 0.082822]\n",
      "epoch:0 step:502 [D loss: 0.568061, acc.: 78.91%] [G loss: 0.092370]\n",
      "epoch:0 step:503 [D loss: 0.566939, acc.: 82.03%] [G loss: 0.113833]\n",
      "epoch:0 step:504 [D loss: 0.554025, acc.: 82.03%] [G loss: 0.104448]\n",
      "epoch:0 step:505 [D loss: 0.565393, acc.: 78.12%] [G loss: 0.097006]\n",
      "epoch:0 step:506 [D loss: 0.553855, acc.: 80.47%] [G loss: 0.118266]\n",
      "epoch:0 step:507 [D loss: 0.575153, acc.: 81.25%] [G loss: 0.072083]\n",
      "epoch:0 step:508 [D loss: 0.525198, acc.: 82.81%] [G loss: 0.085011]\n",
      "epoch:0 step:509 [D loss: 0.604418, acc.: 67.19%] [G loss: 0.073635]\n",
      "epoch:0 step:510 [D loss: 0.586969, acc.: 75.78%] [G loss: 0.053705]\n",
      "epoch:0 step:511 [D loss: 0.589177, acc.: 69.53%] [G loss: 0.067329]\n",
      "epoch:0 step:512 [D loss: 0.531276, acc.: 78.91%] [G loss: 0.089625]\n",
      "epoch:0 step:513 [D loss: 0.547823, acc.: 82.03%] [G loss: 0.089867]\n",
      "epoch:0 step:514 [D loss: 0.546492, acc.: 71.88%] [G loss: 0.080657]\n",
      "epoch:0 step:515 [D loss: 0.546047, acc.: 79.69%] [G loss: 0.115564]\n",
      "epoch:0 step:516 [D loss: 0.556639, acc.: 76.56%] [G loss: 0.106425]\n",
      "epoch:0 step:517 [D loss: 0.608048, acc.: 70.31%] [G loss: 0.060887]\n",
      "epoch:0 step:518 [D loss: 0.530234, acc.: 81.25%] [G loss: 0.083216]\n",
      "epoch:0 step:519 [D loss: 0.530980, acc.: 86.72%] [G loss: 0.100055]\n",
      "epoch:0 step:520 [D loss: 0.548809, acc.: 84.38%] [G loss: 0.101478]\n",
      "epoch:0 step:521 [D loss: 0.565954, acc.: 80.47%] [G loss: 0.101462]\n",
      "epoch:0 step:522 [D loss: 0.580165, acc.: 73.44%] [G loss: 0.084052]\n",
      "epoch:0 step:523 [D loss: 0.573011, acc.: 70.31%] [G loss: 0.059582]\n",
      "epoch:0 step:524 [D loss: 0.584440, acc.: 71.88%] [G loss: 0.051371]\n",
      "epoch:0 step:525 [D loss: 0.543902, acc.: 78.12%] [G loss: 0.079075]\n",
      "epoch:0 step:526 [D loss: 0.530051, acc.: 75.00%] [G loss: 0.099878]\n",
      "epoch:0 step:527 [D loss: 0.522102, acc.: 86.72%] [G loss: 0.148656]\n",
      "epoch:0 step:528 [D loss: 0.533624, acc.: 85.94%] [G loss: 0.114797]\n",
      "epoch:0 step:529 [D loss: 0.539441, acc.: 81.25%] [G loss: 0.097787]\n",
      "epoch:0 step:530 [D loss: 0.493658, acc.: 90.62%] [G loss: 0.160677]\n",
      "epoch:0 step:531 [D loss: 0.563171, acc.: 81.25%] [G loss: 0.148994]\n",
      "epoch:0 step:532 [D loss: 0.542388, acc.: 83.59%] [G loss: 0.095094]\n",
      "epoch:0 step:533 [D loss: 0.539195, acc.: 84.38%] [G loss: 0.098872]\n",
      "epoch:0 step:534 [D loss: 0.543590, acc.: 76.56%] [G loss: 0.119808]\n",
      "epoch:0 step:535 [D loss: 0.575023, acc.: 71.09%] [G loss: 0.101098]\n",
      "epoch:0 step:536 [D loss: 0.561841, acc.: 76.56%] [G loss: 0.103430]\n",
      "epoch:0 step:537 [D loss: 0.562423, acc.: 73.44%] [G loss: 0.099604]\n",
      "epoch:0 step:538 [D loss: 0.551881, acc.: 75.78%] [G loss: 0.132935]\n",
      "epoch:0 step:539 [D loss: 0.575535, acc.: 76.56%] [G loss: 0.122862]\n",
      "epoch:0 step:540 [D loss: 0.560415, acc.: 77.34%] [G loss: 0.122471]\n",
      "epoch:0 step:541 [D loss: 0.508276, acc.: 82.81%] [G loss: 0.134847]\n",
      "epoch:0 step:542 [D loss: 0.588868, acc.: 75.00%] [G loss: 0.107810]\n",
      "epoch:0 step:543 [D loss: 0.584410, acc.: 73.44%] [G loss: 0.105574]\n",
      "epoch:0 step:544 [D loss: 0.535650, acc.: 82.81%] [G loss: 0.106245]\n",
      "epoch:0 step:545 [D loss: 0.563613, acc.: 70.31%] [G loss: 0.133183]\n",
      "epoch:0 step:546 [D loss: 0.516283, acc.: 83.59%] [G loss: 0.123757]\n",
      "epoch:0 step:547 [D loss: 0.480524, acc.: 86.72%] [G loss: 0.161943]\n",
      "epoch:0 step:548 [D loss: 0.545445, acc.: 78.91%] [G loss: 0.170839]\n",
      "epoch:0 step:549 [D loss: 0.560866, acc.: 69.53%] [G loss: 0.165025]\n",
      "epoch:0 step:550 [D loss: 0.598323, acc.: 64.06%] [G loss: 0.117037]\n",
      "epoch:0 step:551 [D loss: 0.553884, acc.: 75.78%] [G loss: 0.146262]\n",
      "epoch:0 step:552 [D loss: 0.563420, acc.: 78.12%] [G loss: 0.133545]\n",
      "epoch:0 step:553 [D loss: 0.548561, acc.: 75.00%] [G loss: 0.147340]\n",
      "epoch:0 step:554 [D loss: 0.560696, acc.: 74.22%] [G loss: 0.155783]\n",
      "epoch:0 step:555 [D loss: 0.556580, acc.: 73.44%] [G loss: 0.176131]\n",
      "epoch:0 step:556 [D loss: 0.526411, acc.: 79.69%] [G loss: 0.192854]\n",
      "epoch:0 step:557 [D loss: 0.551138, acc.: 71.09%] [G loss: 0.195701]\n",
      "epoch:0 step:558 [D loss: 0.575036, acc.: 70.31%] [G loss: 0.158677]\n",
      "epoch:0 step:559 [D loss: 0.571387, acc.: 71.88%] [G loss: 0.164716]\n",
      "epoch:0 step:560 [D loss: 0.543162, acc.: 78.91%] [G loss: 0.197259]\n",
      "epoch:0 step:561 [D loss: 0.572740, acc.: 66.41%] [G loss: 0.227221]\n",
      "epoch:0 step:562 [D loss: 0.624229, acc.: 61.72%] [G loss: 0.170265]\n",
      "epoch:0 step:563 [D loss: 0.533786, acc.: 85.16%] [G loss: 0.182153]\n",
      "epoch:0 step:564 [D loss: 0.518776, acc.: 82.81%] [G loss: 0.186307]\n",
      "epoch:0 step:565 [D loss: 0.628091, acc.: 69.53%] [G loss: 0.133960]\n",
      "epoch:0 step:566 [D loss: 0.719642, acc.: 50.78%] [G loss: 0.099010]\n",
      "epoch:0 step:567 [D loss: 0.577332, acc.: 70.31%] [G loss: 0.132396]\n",
      "epoch:0 step:568 [D loss: 0.626485, acc.: 66.41%] [G loss: 0.114122]\n",
      "epoch:0 step:569 [D loss: 0.659590, acc.: 53.12%] [G loss: 0.084754]\n",
      "epoch:0 step:570 [D loss: 0.590302, acc.: 62.50%] [G loss: 0.125226]\n",
      "epoch:0 step:571 [D loss: 0.585290, acc.: 62.50%] [G loss: 0.157040]\n",
      "epoch:0 step:572 [D loss: 0.594154, acc.: 71.09%] [G loss: 0.154218]\n",
      "epoch:0 step:573 [D loss: 0.578173, acc.: 73.44%] [G loss: 0.109394]\n",
      "epoch:0 step:574 [D loss: 0.578739, acc.: 67.19%] [G loss: 0.145571]\n",
      "epoch:0 step:575 [D loss: 0.567669, acc.: 73.44%] [G loss: 0.181227]\n",
      "epoch:0 step:576 [D loss: 0.609219, acc.: 70.31%] [G loss: 0.106751]\n",
      "epoch:0 step:577 [D loss: 0.595389, acc.: 63.28%] [G loss: 0.126579]\n",
      "epoch:0 step:578 [D loss: 0.566425, acc.: 71.09%] [G loss: 0.164794]\n",
      "epoch:0 step:579 [D loss: 0.563705, acc.: 76.56%] [G loss: 0.140318]\n",
      "epoch:0 step:580 [D loss: 0.596705, acc.: 71.09%] [G loss: 0.169387]\n",
      "epoch:0 step:581 [D loss: 0.585210, acc.: 67.19%] [G loss: 0.180671]\n",
      "epoch:0 step:582 [D loss: 0.602634, acc.: 70.31%] [G loss: 0.188932]\n",
      "epoch:0 step:583 [D loss: 0.640872, acc.: 60.94%] [G loss: 0.101047]\n",
      "epoch:0 step:584 [D loss: 0.658522, acc.: 58.59%] [G loss: 0.059324]\n",
      "epoch:0 step:585 [D loss: 0.630494, acc.: 67.19%] [G loss: 0.088157]\n",
      "epoch:0 step:586 [D loss: 0.633095, acc.: 61.72%] [G loss: 0.102717]\n",
      "epoch:0 step:587 [D loss: 0.650382, acc.: 59.38%] [G loss: 0.093676]\n",
      "epoch:0 step:588 [D loss: 0.602806, acc.: 69.53%] [G loss: 0.084665]\n",
      "epoch:0 step:589 [D loss: 0.658587, acc.: 55.47%] [G loss: 0.100334]\n",
      "epoch:0 step:590 [D loss: 0.636158, acc.: 67.19%] [G loss: 0.103409]\n",
      "epoch:0 step:591 [D loss: 0.619338, acc.: 67.19%] [G loss: 0.112800]\n",
      "epoch:0 step:592 [D loss: 0.643757, acc.: 54.69%] [G loss: 0.055987]\n",
      "epoch:0 step:593 [D loss: 0.605123, acc.: 62.50%] [G loss: 0.068121]\n",
      "epoch:0 step:594 [D loss: 0.630793, acc.: 61.72%] [G loss: 0.076828]\n",
      "epoch:0 step:595 [D loss: 0.585936, acc.: 71.09%] [G loss: 0.114423]\n",
      "epoch:0 step:596 [D loss: 0.586892, acc.: 67.19%] [G loss: 0.132140]\n",
      "epoch:0 step:597 [D loss: 0.634771, acc.: 63.28%] [G loss: 0.089354]\n",
      "epoch:0 step:598 [D loss: 0.592114, acc.: 59.38%] [G loss: 0.129345]\n",
      "epoch:0 step:599 [D loss: 0.620943, acc.: 67.19%] [G loss: 0.089770]\n",
      "epoch:0 step:600 [D loss: 0.637272, acc.: 61.72%] [G loss: 0.086914]\n",
      "epoch:0 step:601 [D loss: 0.588515, acc.: 63.28%] [G loss: 0.121010]\n",
      "epoch:0 step:602 [D loss: 0.607550, acc.: 64.06%] [G loss: 0.112911]\n",
      "epoch:0 step:603 [D loss: 0.565948, acc.: 78.91%] [G loss: 0.125846]\n",
      "epoch:0 step:604 [D loss: 0.597466, acc.: 69.53%] [G loss: 0.113231]\n",
      "epoch:0 step:605 [D loss: 0.611804, acc.: 62.50%] [G loss: 0.085024]\n",
      "epoch:0 step:606 [D loss: 0.560074, acc.: 72.66%] [G loss: 0.109362]\n",
      "epoch:0 step:607 [D loss: 0.595384, acc.: 66.41%] [G loss: 0.109912]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0 step:608 [D loss: 0.591797, acc.: 70.31%] [G loss: 0.096302]\n",
      "epoch:0 step:609 [D loss: 0.613248, acc.: 66.41%] [G loss: 0.071527]\n",
      "epoch:0 step:610 [D loss: 0.574316, acc.: 65.62%] [G loss: 0.089282]\n",
      "epoch:0 step:611 [D loss: 0.571912, acc.: 75.00%] [G loss: 0.111294]\n",
      "epoch:0 step:612 [D loss: 0.579309, acc.: 69.53%] [G loss: 0.103642]\n",
      "epoch:0 step:613 [D loss: 0.544945, acc.: 84.38%] [G loss: 0.137065]\n",
      "epoch:0 step:614 [D loss: 0.552467, acc.: 79.69%] [G loss: 0.132724]\n",
      "epoch:0 step:615 [D loss: 0.602507, acc.: 67.19%] [G loss: 0.073870]\n",
      "epoch:0 step:616 [D loss: 0.565748, acc.: 63.28%] [G loss: 0.089246]\n",
      "epoch:0 step:617 [D loss: 0.567240, acc.: 71.88%] [G loss: 0.106997]\n",
      "epoch:0 step:618 [D loss: 0.540482, acc.: 80.47%] [G loss: 0.114612]\n",
      "epoch:0 step:619 [D loss: 0.523854, acc.: 85.94%] [G loss: 0.124198]\n",
      "epoch:0 step:620 [D loss: 0.574825, acc.: 74.22%] [G loss: 0.112118]\n",
      "epoch:0 step:621 [D loss: 0.608141, acc.: 63.28%] [G loss: 0.072415]\n",
      "epoch:0 step:622 [D loss: 0.571534, acc.: 71.88%] [G loss: 0.073957]\n",
      "epoch:0 step:623 [D loss: 0.544486, acc.: 72.66%] [G loss: 0.096203]\n",
      "epoch:0 step:624 [D loss: 0.537697, acc.: 78.91%] [G loss: 0.117831]\n",
      "epoch:0 step:625 [D loss: 0.516643, acc.: 88.28%] [G loss: 0.148993]\n",
      "epoch:0 step:626 [D loss: 0.546245, acc.: 84.38%] [G loss: 0.118327]\n",
      "epoch:0 step:627 [D loss: 0.559689, acc.: 82.81%] [G loss: 0.109389]\n",
      "epoch:0 step:628 [D loss: 0.541987, acc.: 85.16%] [G loss: 0.109722]\n",
      "epoch:0 step:629 [D loss: 0.516192, acc.: 82.03%] [G loss: 0.133317]\n",
      "epoch:0 step:630 [D loss: 0.503782, acc.: 87.50%] [G loss: 0.142783]\n",
      "epoch:0 step:631 [D loss: 0.570887, acc.: 77.34%] [G loss: 0.101068]\n",
      "epoch:0 step:632 [D loss: 0.551511, acc.: 77.34%] [G loss: 0.122266]\n",
      "epoch:0 step:633 [D loss: 0.540166, acc.: 82.03%] [G loss: 0.116272]\n",
      "epoch:0 step:634 [D loss: 0.554405, acc.: 76.56%] [G loss: 0.104855]\n",
      "epoch:0 step:635 [D loss: 0.537732, acc.: 78.12%] [G loss: 0.104572]\n",
      "epoch:0 step:636 [D loss: 0.518961, acc.: 88.28%] [G loss: 0.137740]\n",
      "epoch:0 step:637 [D loss: 0.551241, acc.: 79.69%] [G loss: 0.123158]\n",
      "epoch:0 step:638 [D loss: 0.484054, acc.: 90.62%] [G loss: 0.181804]\n",
      "epoch:0 step:639 [D loss: 0.540197, acc.: 82.03%] [G loss: 0.173096]\n",
      "epoch:0 step:640 [D loss: 0.545016, acc.: 78.12%] [G loss: 0.149987]\n",
      "epoch:0 step:641 [D loss: 0.525151, acc.: 78.91%] [G loss: 0.150561]\n",
      "epoch:0 step:642 [D loss: 0.544607, acc.: 76.56%] [G loss: 0.164630]\n",
      "epoch:0 step:643 [D loss: 0.568953, acc.: 75.00%] [G loss: 0.133891]\n",
      "epoch:0 step:644 [D loss: 0.596712, acc.: 67.97%] [G loss: 0.084264]\n",
      "epoch:0 step:645 [D loss: 0.597483, acc.: 66.41%] [G loss: 0.094465]\n",
      "epoch:0 step:646 [D loss: 0.549004, acc.: 78.12%] [G loss: 0.125189]\n",
      "epoch:0 step:647 [D loss: 0.496212, acc.: 85.16%] [G loss: 0.190319]\n",
      "epoch:0 step:648 [D loss: 0.542689, acc.: 82.03%] [G loss: 0.164852]\n",
      "epoch:0 step:649 [D loss: 0.514763, acc.: 79.69%] [G loss: 0.169301]\n",
      "epoch:0 step:650 [D loss: 0.512559, acc.: 78.12%] [G loss: 0.246161]\n",
      "epoch:0 step:651 [D loss: 0.550858, acc.: 78.91%] [G loss: 0.182321]\n",
      "epoch:0 step:652 [D loss: 0.570754, acc.: 70.31%] [G loss: 0.123632]\n",
      "epoch:0 step:653 [D loss: 0.546107, acc.: 68.75%] [G loss: 0.136642]\n",
      "epoch:0 step:654 [D loss: 0.563593, acc.: 75.78%] [G loss: 0.131909]\n",
      "epoch:0 step:655 [D loss: 0.625710, acc.: 64.84%] [G loss: 0.140675]\n",
      "epoch:0 step:656 [D loss: 0.578723, acc.: 74.22%] [G loss: 0.154932]\n",
      "epoch:0 step:657 [D loss: 0.610916, acc.: 64.06%] [G loss: 0.145161]\n",
      "epoch:0 step:658 [D loss: 0.577863, acc.: 69.53%] [G loss: 0.143395]\n",
      "epoch:0 step:659 [D loss: 0.618738, acc.: 60.16%] [G loss: 0.113623]\n",
      "epoch:0 step:660 [D loss: 0.577231, acc.: 70.31%] [G loss: 0.134095]\n",
      "epoch:0 step:661 [D loss: 0.564668, acc.: 71.88%] [G loss: 0.153896]\n",
      "epoch:0 step:662 [D loss: 0.629220, acc.: 61.72%] [G loss: 0.101148]\n",
      "epoch:0 step:663 [D loss: 0.632468, acc.: 58.59%] [G loss: 0.092255]\n",
      "epoch:0 step:664 [D loss: 0.589993, acc.: 64.84%] [G loss: 0.149243]\n",
      "epoch:0 step:665 [D loss: 0.556087, acc.: 75.00%] [G loss: 0.194061]\n",
      "epoch:0 step:666 [D loss: 0.605621, acc.: 67.19%] [G loss: 0.221357]\n",
      "epoch:0 step:667 [D loss: 0.575419, acc.: 77.34%] [G loss: 0.213222]\n",
      "epoch:0 step:668 [D loss: 0.647390, acc.: 60.94%] [G loss: 0.101142]\n",
      "epoch:0 step:669 [D loss: 0.576073, acc.: 62.50%] [G loss: 0.130725]\n",
      "epoch:0 step:670 [D loss: 0.591217, acc.: 73.44%] [G loss: 0.139782]\n",
      "epoch:0 step:671 [D loss: 0.626963, acc.: 62.50%] [G loss: 0.074669]\n",
      "epoch:0 step:672 [D loss: 0.624074, acc.: 61.72%] [G loss: 0.083145]\n",
      "epoch:0 step:673 [D loss: 0.621589, acc.: 64.06%] [G loss: 0.097671]\n",
      "epoch:0 step:674 [D loss: 0.558975, acc.: 75.00%] [G loss: 0.160155]\n",
      "epoch:0 step:675 [D loss: 0.551979, acc.: 72.66%] [G loss: 0.211701]\n",
      "epoch:0 step:676 [D loss: 0.611347, acc.: 68.75%] [G loss: 0.177422]\n",
      "epoch:0 step:677 [D loss: 0.551154, acc.: 78.91%] [G loss: 0.160278]\n",
      "epoch:0 step:678 [D loss: 0.619910, acc.: 64.84%] [G loss: 0.112591]\n",
      "epoch:0 step:679 [D loss: 0.585944, acc.: 70.31%] [G loss: 0.120230]\n",
      "epoch:0 step:680 [D loss: 0.603962, acc.: 64.84%] [G loss: 0.110935]\n",
      "epoch:0 step:681 [D loss: 0.624936, acc.: 60.94%] [G loss: 0.090979]\n",
      "epoch:0 step:682 [D loss: 0.585290, acc.: 70.31%] [G loss: 0.133449]\n",
      "epoch:0 step:683 [D loss: 0.559760, acc.: 73.44%] [G loss: 0.159598]\n",
      "epoch:0 step:684 [D loss: 0.610145, acc.: 69.53%] [G loss: 0.125738]\n",
      "epoch:0 step:685 [D loss: 0.640566, acc.: 62.50%] [G loss: 0.109560]\n",
      "epoch:0 step:686 [D loss: 0.587638, acc.: 71.09%] [G loss: 0.118756]\n",
      "epoch:0 step:687 [D loss: 0.591021, acc.: 68.75%] [G loss: 0.140144]\n",
      "epoch:0 step:688 [D loss: 0.594440, acc.: 71.88%] [G loss: 0.116736]\n",
      "epoch:0 step:689 [D loss: 0.623247, acc.: 63.28%] [G loss: 0.091784]\n",
      "epoch:0 step:690 [D loss: 0.634820, acc.: 60.94%] [G loss: 0.092812]\n",
      "epoch:0 step:691 [D loss: 0.591562, acc.: 71.88%] [G loss: 0.091788]\n",
      "epoch:0 step:692 [D loss: 0.594916, acc.: 66.41%] [G loss: 0.124134]\n",
      "epoch:0 step:693 [D loss: 0.606862, acc.: 71.09%] [G loss: 0.124787]\n",
      "epoch:0 step:694 [D loss: 0.537395, acc.: 84.38%] [G loss: 0.139502]\n",
      "epoch:0 step:695 [D loss: 0.581650, acc.: 77.34%] [G loss: 0.139210]\n",
      "epoch:0 step:696 [D loss: 0.618775, acc.: 71.88%] [G loss: 0.133958]\n",
      "epoch:0 step:697 [D loss: 0.644513, acc.: 65.62%] [G loss: 0.106064]\n",
      "epoch:0 step:698 [D loss: 0.569724, acc.: 78.91%] [G loss: 0.129927]\n",
      "epoch:0 step:699 [D loss: 0.586473, acc.: 75.78%] [G loss: 0.109738]\n",
      "epoch:0 step:700 [D loss: 0.599300, acc.: 68.75%] [G loss: 0.106583]\n",
      "epoch:0 step:701 [D loss: 0.612499, acc.: 67.97%] [G loss: 0.106531]\n",
      "epoch:0 step:702 [D loss: 0.585511, acc.: 67.97%] [G loss: 0.121122]\n",
      "epoch:0 step:703 [D loss: 0.593460, acc.: 70.31%] [G loss: 0.096055]\n",
      "epoch:0 step:704 [D loss: 0.594050, acc.: 69.53%] [G loss: 0.098801]\n",
      "epoch:0 step:705 [D loss: 0.589054, acc.: 71.09%] [G loss: 0.116129]\n",
      "epoch:0 step:706 [D loss: 0.575530, acc.: 80.47%] [G loss: 0.122924]\n",
      "epoch:0 step:707 [D loss: 0.571498, acc.: 83.59%] [G loss: 0.097699]\n",
      "epoch:0 step:708 [D loss: 0.553749, acc.: 75.78%] [G loss: 0.149860]\n",
      "epoch:0 step:709 [D loss: 0.555502, acc.: 72.66%] [G loss: 0.163059]\n",
      "epoch:0 step:710 [D loss: 0.597714, acc.: 72.66%] [G loss: 0.087978]\n",
      "epoch:0 step:711 [D loss: 0.576616, acc.: 71.09%] [G loss: 0.093979]\n",
      "epoch:0 step:712 [D loss: 0.533519, acc.: 81.25%] [G loss: 0.141621]\n",
      "epoch:0 step:713 [D loss: 0.531668, acc.: 90.62%] [G loss: 0.164985]\n",
      "epoch:0 step:714 [D loss: 0.562840, acc.: 79.69%] [G loss: 0.133894]\n",
      "epoch:0 step:715 [D loss: 0.609205, acc.: 68.75%] [G loss: 0.088985]\n",
      "epoch:0 step:716 [D loss: 0.589647, acc.: 67.97%] [G loss: 0.091650]\n",
      "epoch:0 step:717 [D loss: 0.577122, acc.: 67.19%] [G loss: 0.120632]\n",
      "epoch:0 step:718 [D loss: 0.557772, acc.: 75.00%] [G loss: 0.128577]\n",
      "epoch:0 step:719 [D loss: 0.590014, acc.: 69.53%] [G loss: 0.110322]\n",
      "epoch:0 step:720 [D loss: 0.598614, acc.: 67.19%] [G loss: 0.087867]\n",
      "epoch:0 step:721 [D loss: 0.548703, acc.: 75.78%] [G loss: 0.123829]\n",
      "epoch:0 step:722 [D loss: 0.550562, acc.: 78.12%] [G loss: 0.157887]\n",
      "epoch:0 step:723 [D loss: 0.562501, acc.: 76.56%] [G loss: 0.135075]\n",
      "epoch:0 step:724 [D loss: 0.580314, acc.: 64.06%] [G loss: 0.140786]\n",
      "epoch:0 step:725 [D loss: 0.587120, acc.: 82.03%] [G loss: 0.129484]\n",
      "epoch:0 step:726 [D loss: 0.590478, acc.: 72.66%] [G loss: 0.123386]\n",
      "epoch:0 step:727 [D loss: 0.580992, acc.: 72.66%] [G loss: 0.098020]\n",
      "epoch:0 step:728 [D loss: 0.545246, acc.: 81.25%] [G loss: 0.132780]\n",
      "epoch:0 step:729 [D loss: 0.571910, acc.: 82.81%] [G loss: 0.117702]\n",
      "epoch:0 step:730 [D loss: 0.556171, acc.: 85.16%] [G loss: 0.122477]\n",
      "epoch:0 step:731 [D loss: 0.519334, acc.: 85.94%] [G loss: 0.162231]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0 step:732 [D loss: 0.545414, acc.: 83.59%] [G loss: 0.161437]\n",
      "epoch:0 step:733 [D loss: 0.529044, acc.: 85.94%] [G loss: 0.185577]\n",
      "epoch:0 step:734 [D loss: 0.582235, acc.: 75.78%] [G loss: 0.129176]\n",
      "epoch:0 step:735 [D loss: 0.572564, acc.: 74.22%] [G loss: 0.108340]\n",
      "epoch:0 step:736 [D loss: 0.542499, acc.: 81.25%] [G loss: 0.110330]\n",
      "epoch:0 step:737 [D loss: 0.555538, acc.: 71.09%] [G loss: 0.130585]\n",
      "epoch:0 step:738 [D loss: 0.564141, acc.: 78.12%] [G loss: 0.116468]\n",
      "epoch:0 step:739 [D loss: 0.544862, acc.: 80.47%] [G loss: 0.118215]\n",
      "epoch:0 step:740 [D loss: 0.554715, acc.: 82.03%] [G loss: 0.117978]\n",
      "epoch:0 step:741 [D loss: 0.534408, acc.: 82.03%] [G loss: 0.133658]\n",
      "epoch:0 step:742 [D loss: 0.542259, acc.: 78.12%] [G loss: 0.124488]\n",
      "epoch:0 step:743 [D loss: 0.513317, acc.: 85.94%] [G loss: 0.171039]\n",
      "epoch:0 step:744 [D loss: 0.565649, acc.: 79.69%] [G loss: 0.145062]\n",
      "epoch:0 step:745 [D loss: 0.524589, acc.: 88.28%] [G loss: 0.147811]\n",
      "epoch:0 step:746 [D loss: 0.530487, acc.: 88.28%] [G loss: 0.174774]\n",
      "epoch:0 step:747 [D loss: 0.540614, acc.: 82.03%] [G loss: 0.154201]\n",
      "epoch:0 step:748 [D loss: 0.513559, acc.: 91.41%] [G loss: 0.174331]\n",
      "epoch:0 step:749 [D loss: 0.519590, acc.: 85.16%] [G loss: 0.183570]\n",
      "epoch:0 step:750 [D loss: 0.529319, acc.: 87.50%] [G loss: 0.150730]\n",
      "epoch:0 step:751 [D loss: 0.513911, acc.: 89.84%] [G loss: 0.178871]\n",
      "epoch:0 step:752 [D loss: 0.502547, acc.: 82.81%] [G loss: 0.172485]\n",
      "epoch:0 step:753 [D loss: 0.513179, acc.: 81.25%] [G loss: 0.204952]\n",
      "epoch:0 step:754 [D loss: 0.534413, acc.: 85.16%] [G loss: 0.179762]\n",
      "epoch:0 step:755 [D loss: 0.541344, acc.: 83.59%] [G loss: 0.179182]\n",
      "epoch:0 step:756 [D loss: 0.543215, acc.: 82.81%] [G loss: 0.149182]\n",
      "epoch:0 step:757 [D loss: 0.523436, acc.: 85.16%] [G loss: 0.186856]\n",
      "epoch:0 step:758 [D loss: 0.565431, acc.: 73.44%] [G loss: 0.168163]\n",
      "epoch:0 step:759 [D loss: 0.552705, acc.: 75.00%] [G loss: 0.139898]\n",
      "epoch:0 step:760 [D loss: 0.591049, acc.: 70.31%] [G loss: 0.134891]\n",
      "epoch:0 step:761 [D loss: 0.531113, acc.: 78.12%] [G loss: 0.164861]\n",
      "epoch:0 step:762 [D loss: 0.535599, acc.: 82.03%] [G loss: 0.187014]\n",
      "epoch:0 step:763 [D loss: 0.518384, acc.: 84.38%] [G loss: 0.198219]\n",
      "epoch:0 step:764 [D loss: 0.557860, acc.: 73.44%] [G loss: 0.199067]\n",
      "epoch:0 step:765 [D loss: 0.648984, acc.: 62.50%] [G loss: 0.093918]\n",
      "epoch:0 step:766 [D loss: 0.544575, acc.: 72.66%] [G loss: 0.129010]\n",
      "epoch:0 step:767 [D loss: 0.552903, acc.: 71.88%] [G loss: 0.190763]\n",
      "epoch:0 step:768 [D loss: 0.526568, acc.: 78.12%] [G loss: 0.208429]\n",
      "epoch:0 step:769 [D loss: 0.573225, acc.: 75.00%] [G loss: 0.218643]\n",
      "epoch:0 step:770 [D loss: 0.532511, acc.: 78.12%] [G loss: 0.218346]\n",
      "epoch:0 step:771 [D loss: 0.607037, acc.: 66.41%] [G loss: 0.179664]\n",
      "epoch:0 step:772 [D loss: 0.570039, acc.: 74.22%] [G loss: 0.165067]\n",
      "epoch:0 step:773 [D loss: 0.616500, acc.: 67.97%] [G loss: 0.122823]\n",
      "epoch:0 step:774 [D loss: 0.571193, acc.: 67.97%] [G loss: 0.190951]\n",
      "epoch:0 step:775 [D loss: 0.553784, acc.: 77.34%] [G loss: 0.231393]\n",
      "epoch:0 step:776 [D loss: 0.621935, acc.: 62.50%] [G loss: 0.172358]\n",
      "epoch:0 step:777 [D loss: 0.587269, acc.: 66.41%] [G loss: 0.151329]\n",
      "epoch:0 step:778 [D loss: 0.662467, acc.: 59.38%] [G loss: 0.113633]\n",
      "epoch:0 step:779 [D loss: 0.649398, acc.: 58.59%] [G loss: 0.086538]\n",
      "epoch:0 step:780 [D loss: 0.621233, acc.: 67.19%] [G loss: 0.092209]\n",
      "epoch:0 step:781 [D loss: 0.584428, acc.: 71.88%] [G loss: 0.129116]\n",
      "epoch:0 step:782 [D loss: 0.538711, acc.: 76.56%] [G loss: 0.181072]\n",
      "epoch:0 step:783 [D loss: 0.618474, acc.: 57.81%] [G loss: 0.159317]\n",
      "epoch:0 step:784 [D loss: 0.573098, acc.: 74.22%] [G loss: 0.168051]\n",
      "epoch:0 step:785 [D loss: 0.575725, acc.: 78.91%] [G loss: 0.154615]\n",
      "epoch:0 step:786 [D loss: 0.582905, acc.: 71.09%] [G loss: 0.131840]\n",
      "epoch:0 step:787 [D loss: 0.628261, acc.: 59.38%] [G loss: 0.107899]\n",
      "epoch:0 step:788 [D loss: 0.569665, acc.: 78.12%] [G loss: 0.154453]\n",
      "epoch:0 step:789 [D loss: 0.567382, acc.: 71.09%] [G loss: 0.166103]\n",
      "epoch:0 step:790 [D loss: 0.567864, acc.: 75.00%] [G loss: 0.189940]\n",
      "epoch:0 step:791 [D loss: 0.582729, acc.: 75.00%] [G loss: 0.135917]\n",
      "epoch:0 step:792 [D loss: 0.550736, acc.: 75.00%] [G loss: 0.192062]\n",
      "epoch:0 step:793 [D loss: 0.614195, acc.: 63.28%] [G loss: 0.189893]\n",
      "epoch:0 step:794 [D loss: 0.597578, acc.: 71.88%] [G loss: 0.194107]\n",
      "epoch:0 step:795 [D loss: 0.514250, acc.: 83.59%] [G loss: 0.198284]\n",
      "epoch:0 step:796 [D loss: 0.540421, acc.: 80.47%] [G loss: 0.192125]\n",
      "epoch:0 step:797 [D loss: 0.581767, acc.: 75.78%] [G loss: 0.149756]\n",
      "epoch:0 step:798 [D loss: 0.510506, acc.: 82.81%] [G loss: 0.178943]\n",
      "epoch:0 step:799 [D loss: 0.575964, acc.: 71.88%] [G loss: 0.167181]\n",
      "epoch:0 step:800 [D loss: 0.589126, acc.: 69.53%] [G loss: 0.137198]\n",
      "epoch:0 step:801 [D loss: 0.536089, acc.: 79.69%] [G loss: 0.208341]\n",
      "epoch:0 step:802 [D loss: 0.492321, acc.: 90.62%] [G loss: 0.272643]\n",
      "epoch:0 step:803 [D loss: 0.577197, acc.: 76.56%] [G loss: 0.171626]\n",
      "epoch:0 step:804 [D loss: 0.637570, acc.: 57.81%] [G loss: 0.095123]\n",
      "epoch:0 step:805 [D loss: 0.606231, acc.: 65.62%] [G loss: 0.110993]\n",
      "epoch:0 step:806 [D loss: 0.530814, acc.: 74.22%] [G loss: 0.195196]\n",
      "epoch:0 step:807 [D loss: 0.569426, acc.: 72.66%] [G loss: 0.187132]\n",
      "epoch:0 step:808 [D loss: 0.551416, acc.: 83.59%] [G loss: 0.146270]\n",
      "epoch:0 step:809 [D loss: 0.558985, acc.: 77.34%] [G loss: 0.136039]\n",
      "epoch:0 step:810 [D loss: 0.556252, acc.: 75.00%] [G loss: 0.151785]\n",
      "epoch:0 step:811 [D loss: 0.547856, acc.: 80.47%] [G loss: 0.181214]\n",
      "epoch:0 step:812 [D loss: 0.610285, acc.: 66.41%] [G loss: 0.124828]\n",
      "epoch:0 step:813 [D loss: 0.578431, acc.: 75.78%] [G loss: 0.120117]\n",
      "epoch:0 step:814 [D loss: 0.531691, acc.: 79.69%] [G loss: 0.143395]\n",
      "epoch:0 step:815 [D loss: 0.523599, acc.: 86.72%] [G loss: 0.170070]\n",
      "epoch:0 step:816 [D loss: 0.512646, acc.: 80.47%] [G loss: 0.192237]\n",
      "epoch:0 step:817 [D loss: 0.518414, acc.: 83.59%] [G loss: 0.224907]\n",
      "epoch:0 step:818 [D loss: 0.522647, acc.: 82.03%] [G loss: 0.204392]\n",
      "epoch:0 step:819 [D loss: 0.558855, acc.: 69.53%] [G loss: 0.182599]\n",
      "epoch:0 step:820 [D loss: 0.589897, acc.: 78.91%] [G loss: 0.155482]\n",
      "epoch:0 step:821 [D loss: 0.550598, acc.: 82.03%] [G loss: 0.143516]\n",
      "epoch:0 step:822 [D loss: 0.549516, acc.: 75.78%] [G loss: 0.167717]\n",
      "epoch:0 step:823 [D loss: 0.551270, acc.: 77.34%] [G loss: 0.147201]\n",
      "epoch:0 step:824 [D loss: 0.569139, acc.: 72.66%] [G loss: 0.149456]\n",
      "epoch:0 step:825 [D loss: 0.528120, acc.: 83.59%] [G loss: 0.161199]\n",
      "epoch:0 step:826 [D loss: 0.525801, acc.: 85.94%] [G loss: 0.175952]\n",
      "epoch:0 step:827 [D loss: 0.544889, acc.: 78.12%] [G loss: 0.179452]\n",
      "epoch:0 step:828 [D loss: 0.535386, acc.: 79.69%] [G loss: 0.204047]\n",
      "epoch:0 step:829 [D loss: 0.553277, acc.: 78.12%] [G loss: 0.203997]\n",
      "epoch:0 step:830 [D loss: 0.512199, acc.: 91.41%] [G loss: 0.203297]\n",
      "epoch:0 step:831 [D loss: 0.550610, acc.: 81.25%] [G loss: 0.158227]\n",
      "epoch:0 step:832 [D loss: 0.542634, acc.: 80.47%] [G loss: 0.153251]\n",
      "epoch:0 step:833 [D loss: 0.559698, acc.: 71.88%] [G loss: 0.147738]\n",
      "epoch:0 step:834 [D loss: 0.572680, acc.: 75.78%] [G loss: 0.145571]\n",
      "epoch:0 step:835 [D loss: 0.561126, acc.: 74.22%] [G loss: 0.138896]\n",
      "epoch:0 step:836 [D loss: 0.547672, acc.: 81.25%] [G loss: 0.143598]\n",
      "epoch:0 step:837 [D loss: 0.552535, acc.: 82.03%] [G loss: 0.146284]\n",
      "epoch:0 step:838 [D loss: 0.526701, acc.: 89.06%] [G loss: 0.158812]\n",
      "epoch:0 step:839 [D loss: 0.578248, acc.: 73.44%] [G loss: 0.140066]\n",
      "epoch:0 step:840 [D loss: 0.548727, acc.: 76.56%] [G loss: 0.193009]\n",
      "epoch:0 step:841 [D loss: 0.514260, acc.: 86.72%] [G loss: 0.233625]\n",
      "epoch:0 step:842 [D loss: 0.546752, acc.: 82.81%] [G loss: 0.218834]\n",
      "epoch:0 step:843 [D loss: 0.566800, acc.: 76.56%] [G loss: 0.193094]\n",
      "epoch:0 step:844 [D loss: 0.564014, acc.: 85.94%] [G loss: 0.179314]\n",
      "epoch:0 step:845 [D loss: 0.553971, acc.: 80.47%] [G loss: 0.187951]\n",
      "epoch:0 step:846 [D loss: 0.530034, acc.: 78.91%] [G loss: 0.162064]\n",
      "epoch:0 step:847 [D loss: 0.562215, acc.: 77.34%] [G loss: 0.157547]\n",
      "epoch:0 step:848 [D loss: 0.543726, acc.: 78.91%] [G loss: 0.167196]\n",
      "epoch:0 step:849 [D loss: 0.573639, acc.: 75.78%] [G loss: 0.142845]\n",
      "epoch:0 step:850 [D loss: 0.552545, acc.: 78.91%] [G loss: 0.175741]\n",
      "epoch:0 step:851 [D loss: 0.540287, acc.: 78.12%] [G loss: 0.215671]\n",
      "epoch:0 step:852 [D loss: 0.526182, acc.: 86.72%] [G loss: 0.241802]\n",
      "epoch:0 step:853 [D loss: 0.536644, acc.: 80.47%] [G loss: 0.209463]\n",
      "epoch:0 step:854 [D loss: 0.494493, acc.: 87.50%] [G loss: 0.237546]\n",
      "epoch:0 step:855 [D loss: 0.526582, acc.: 83.59%] [G loss: 0.218244]\n",
      "epoch:0 step:856 [D loss: 0.567189, acc.: 75.78%] [G loss: 0.172062]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0 step:857 [D loss: 0.563747, acc.: 72.66%] [G loss: 0.160815]\n",
      "epoch:0 step:858 [D loss: 0.672013, acc.: 49.22%] [G loss: 0.072257]\n",
      "epoch:0 step:859 [D loss: 0.570635, acc.: 71.09%] [G loss: 0.130052]\n",
      "epoch:0 step:860 [D loss: 0.532416, acc.: 80.47%] [G loss: 0.173666]\n",
      "epoch:0 step:861 [D loss: 0.542810, acc.: 82.81%] [G loss: 0.172084]\n",
      "epoch:0 step:862 [D loss: 0.570704, acc.: 74.22%] [G loss: 0.159587]\n",
      "epoch:0 step:863 [D loss: 0.524087, acc.: 82.03%] [G loss: 0.204990]\n",
      "epoch:0 step:864 [D loss: 0.492532, acc.: 88.28%] [G loss: 0.228410]\n",
      "epoch:0 step:865 [D loss: 0.591303, acc.: 74.22%] [G loss: 0.147847]\n",
      "epoch:0 step:866 [D loss: 0.507245, acc.: 90.62%] [G loss: 0.189599]\n",
      "epoch:0 step:867 [D loss: 0.562687, acc.: 74.22%] [G loss: 0.162971]\n",
      "epoch:0 step:868 [D loss: 0.571522, acc.: 78.12%] [G loss: 0.137117]\n",
      "epoch:0 step:869 [D loss: 0.530584, acc.: 80.47%] [G loss: 0.182478]\n",
      "epoch:0 step:870 [D loss: 0.562082, acc.: 81.25%] [G loss: 0.183370]\n",
      "epoch:0 step:871 [D loss: 0.530060, acc.: 82.81%] [G loss: 0.197334]\n",
      "epoch:0 step:872 [D loss: 0.515595, acc.: 88.28%] [G loss: 0.210046]\n",
      "epoch:0 step:873 [D loss: 0.521495, acc.: 84.38%] [G loss: 0.197159]\n",
      "epoch:0 step:874 [D loss: 0.577443, acc.: 80.47%] [G loss: 0.147775]\n",
      "epoch:0 step:875 [D loss: 0.566563, acc.: 68.75%] [G loss: 0.155915]\n",
      "epoch:0 step:876 [D loss: 0.554293, acc.: 78.12%] [G loss: 0.152678]\n",
      "epoch:0 step:877 [D loss: 0.565391, acc.: 71.88%] [G loss: 0.158655]\n",
      "epoch:0 step:878 [D loss: 0.553185, acc.: 75.78%] [G loss: 0.167779]\n",
      "epoch:0 step:879 [D loss: 0.621146, acc.: 66.41%] [G loss: 0.140384]\n",
      "epoch:0 step:880 [D loss: 0.557285, acc.: 82.03%] [G loss: 0.156553]\n",
      "epoch:0 step:881 [D loss: 0.564719, acc.: 72.66%] [G loss: 0.157558]\n",
      "epoch:0 step:882 [D loss: 0.576035, acc.: 71.09%] [G loss: 0.177778]\n",
      "epoch:0 step:883 [D loss: 0.561680, acc.: 80.47%] [G loss: 0.171687]\n",
      "epoch:0 step:884 [D loss: 0.591066, acc.: 69.53%] [G loss: 0.175357]\n",
      "epoch:0 step:885 [D loss: 0.506436, acc.: 82.03%] [G loss: 0.253953]\n",
      "epoch:0 step:886 [D loss: 0.536879, acc.: 74.22%] [G loss: 0.349086]\n",
      "epoch:0 step:887 [D loss: 0.520693, acc.: 82.81%] [G loss: 0.270692]\n",
      "epoch:0 step:888 [D loss: 0.550864, acc.: 69.53%] [G loss: 0.263190]\n",
      "epoch:0 step:889 [D loss: 0.557493, acc.: 74.22%] [G loss: 0.252677]\n",
      "epoch:0 step:890 [D loss: 0.566049, acc.: 76.56%] [G loss: 0.176389]\n",
      "epoch:0 step:891 [D loss: 0.641017, acc.: 66.41%] [G loss: 0.115934]\n",
      "epoch:0 step:892 [D loss: 0.621786, acc.: 67.19%] [G loss: 0.121289]\n",
      "epoch:0 step:893 [D loss: 0.531495, acc.: 76.56%] [G loss: 0.197792]\n",
      "epoch:0 step:894 [D loss: 0.576819, acc.: 75.00%] [G loss: 0.180919]\n",
      "epoch:0 step:895 [D loss: 0.608968, acc.: 69.53%] [G loss: 0.168790]\n",
      "epoch:0 step:896 [D loss: 0.571064, acc.: 74.22%] [G loss: 0.187206]\n",
      "epoch:0 step:897 [D loss: 0.528322, acc.: 78.91%] [G loss: 0.228572]\n",
      "epoch:0 step:898 [D loss: 0.520075, acc.: 84.38%] [G loss: 0.184193]\n",
      "epoch:0 step:899 [D loss: 0.543492, acc.: 78.91%] [G loss: 0.184247]\n",
      "epoch:0 step:900 [D loss: 0.541572, acc.: 75.78%] [G loss: 0.224721]\n",
      "epoch:0 step:901 [D loss: 0.517913, acc.: 84.38%] [G loss: 0.232245]\n",
      "epoch:0 step:902 [D loss: 0.569395, acc.: 74.22%] [G loss: 0.169119]\n",
      "epoch:0 step:903 [D loss: 0.559575, acc.: 71.88%] [G loss: 0.164434]\n",
      "epoch:0 step:904 [D loss: 0.616487, acc.: 67.97%] [G loss: 0.172899]\n",
      "epoch:0 step:905 [D loss: 0.554490, acc.: 79.69%] [G loss: 0.228903]\n",
      "epoch:0 step:906 [D loss: 0.520199, acc.: 85.16%] [G loss: 0.215858]\n",
      "epoch:0 step:907 [D loss: 0.532619, acc.: 85.16%] [G loss: 0.241694]\n",
      "epoch:0 step:908 [D loss: 0.539764, acc.: 76.56%] [G loss: 0.235022]\n",
      "epoch:0 step:909 [D loss: 0.552810, acc.: 74.22%] [G loss: 0.271505]\n",
      "epoch:0 step:910 [D loss: 0.508398, acc.: 86.72%] [G loss: 0.296975]\n",
      "epoch:0 step:911 [D loss: 0.624000, acc.: 67.19%] [G loss: 0.176287]\n",
      "epoch:0 step:912 [D loss: 0.533639, acc.: 78.91%] [G loss: 0.191981]\n",
      "epoch:0 step:913 [D loss: 0.587664, acc.: 72.66%] [G loss: 0.153393]\n",
      "epoch:0 step:914 [D loss: 0.524463, acc.: 76.56%] [G loss: 0.266728]\n",
      "epoch:0 step:915 [D loss: 0.563131, acc.: 82.81%] [G loss: 0.169235]\n",
      "epoch:0 step:916 [D loss: 0.555111, acc.: 75.00%] [G loss: 0.165942]\n",
      "epoch:0 step:917 [D loss: 0.519641, acc.: 78.91%] [G loss: 0.205521]\n",
      "epoch:0 step:918 [D loss: 0.484045, acc.: 85.16%] [G loss: 0.281949]\n",
      "epoch:0 step:919 [D loss: 0.503291, acc.: 85.94%] [G loss: 0.273347]\n",
      "epoch:0 step:920 [D loss: 0.639497, acc.: 64.84%] [G loss: 0.129566]\n",
      "epoch:0 step:921 [D loss: 0.513806, acc.: 75.00%] [G loss: 0.206012]\n",
      "epoch:0 step:922 [D loss: 0.514458, acc.: 76.56%] [G loss: 0.210964]\n",
      "epoch:0 step:923 [D loss: 0.523750, acc.: 81.25%] [G loss: 0.221709]\n",
      "epoch:0 step:924 [D loss: 0.506198, acc.: 83.59%] [G loss: 0.257665]\n",
      "epoch:0 step:925 [D loss: 0.444913, acc.: 95.31%] [G loss: 0.313799]\n",
      "epoch:0 step:926 [D loss: 0.453552, acc.: 88.28%] [G loss: 0.350775]\n",
      "epoch:0 step:927 [D loss: 0.522359, acc.: 78.91%] [G loss: 0.309834]\n",
      "epoch:0 step:928 [D loss: 0.765231, acc.: 57.81%] [G loss: 0.134281]\n",
      "epoch:0 step:929 [D loss: 0.545092, acc.: 74.22%] [G loss: 0.185796]\n",
      "epoch:0 step:930 [D loss: 0.432207, acc.: 91.41%] [G loss: 0.341476]\n",
      "epoch:0 step:931 [D loss: 0.523500, acc.: 85.16%] [G loss: 0.200403]\n",
      "epoch:0 step:932 [D loss: 0.538358, acc.: 82.03%] [G loss: 0.160689]\n",
      "epoch:0 step:933 [D loss: 0.525176, acc.: 79.69%] [G loss: 0.207941]\n",
      "epoch:0 step:934 [D loss: 0.541962, acc.: 78.91%] [G loss: 0.194446]\n",
      "epoch:0 step:935 [D loss: 0.413300, acc.: 93.75%] [G loss: 0.296667]\n",
      "epoch:0 step:936 [D loss: 0.368806, acc.: 94.53%] [G loss: 0.458823]\n",
      "epoch:0 step:937 [D loss: 0.618621, acc.: 67.97%] [G loss: 0.289110]\n",
      "epoch:1 step:938 [D loss: 0.564648, acc.: 77.34%] [G loss: 0.204891]\n",
      "epoch:1 step:939 [D loss: 0.512571, acc.: 78.91%] [G loss: 0.220664]\n",
      "epoch:1 step:940 [D loss: 0.611936, acc.: 64.06%] [G loss: 0.196197]\n",
      "epoch:1 step:941 [D loss: 0.516277, acc.: 78.91%] [G loss: 0.258156]\n",
      "epoch:1 step:942 [D loss: 0.549542, acc.: 79.69%] [G loss: 0.231886]\n",
      "epoch:1 step:943 [D loss: 0.513182, acc.: 81.25%] [G loss: 0.216357]\n",
      "epoch:1 step:944 [D loss: 0.527063, acc.: 82.81%] [G loss: 0.203377]\n",
      "epoch:1 step:945 [D loss: 0.547766, acc.: 78.12%] [G loss: 0.174255]\n",
      "epoch:1 step:946 [D loss: 0.524081, acc.: 81.25%] [G loss: 0.202443]\n",
      "epoch:1 step:947 [D loss: 0.530167, acc.: 82.81%] [G loss: 0.197367]\n",
      "epoch:1 step:948 [D loss: 0.518777, acc.: 76.56%] [G loss: 0.244917]\n",
      "epoch:1 step:949 [D loss: 0.525827, acc.: 76.56%] [G loss: 0.280042]\n",
      "epoch:1 step:950 [D loss: 0.498775, acc.: 86.72%] [G loss: 0.263258]\n",
      "epoch:1 step:951 [D loss: 0.483394, acc.: 89.84%] [G loss: 0.276256]\n",
      "epoch:1 step:952 [D loss: 0.558457, acc.: 72.66%] [G loss: 0.178119]\n",
      "epoch:1 step:953 [D loss: 0.541795, acc.: 72.66%] [G loss: 0.212716]\n",
      "epoch:1 step:954 [D loss: 0.580695, acc.: 67.19%] [G loss: 0.157758]\n",
      "epoch:1 step:955 [D loss: 0.538242, acc.: 77.34%] [G loss: 0.215270]\n",
      "epoch:1 step:956 [D loss: 0.503791, acc.: 82.81%] [G loss: 0.242941]\n",
      "epoch:1 step:957 [D loss: 0.555604, acc.: 76.56%] [G loss: 0.233121]\n",
      "epoch:1 step:958 [D loss: 0.499005, acc.: 84.38%] [G loss: 0.267209]\n",
      "epoch:1 step:959 [D loss: 0.504534, acc.: 80.47%] [G loss: 0.274109]\n",
      "epoch:1 step:960 [D loss: 0.552354, acc.: 80.47%] [G loss: 0.174145]\n",
      "epoch:1 step:961 [D loss: 0.567210, acc.: 71.88%] [G loss: 0.160742]\n",
      "epoch:1 step:962 [D loss: 0.542812, acc.: 75.78%] [G loss: 0.200910]\n",
      "epoch:1 step:963 [D loss: 0.529301, acc.: 82.81%] [G loss: 0.212788]\n",
      "epoch:1 step:964 [D loss: 0.536479, acc.: 80.47%] [G loss: 0.181083]\n",
      "epoch:1 step:965 [D loss: 0.545854, acc.: 75.00%] [G loss: 0.198503]\n",
      "epoch:1 step:966 [D loss: 0.532276, acc.: 76.56%] [G loss: 0.199600]\n",
      "epoch:1 step:967 [D loss: 0.503413, acc.: 84.38%] [G loss: 0.250810]\n",
      "epoch:1 step:968 [D loss: 0.527464, acc.: 83.59%] [G loss: 0.273700]\n",
      "epoch:1 step:969 [D loss: 0.497742, acc.: 86.72%] [G loss: 0.278919]\n",
      "epoch:1 step:970 [D loss: 0.482940, acc.: 89.84%] [G loss: 0.288382]\n",
      "epoch:1 step:971 [D loss: 0.508504, acc.: 81.25%] [G loss: 0.268995]\n",
      "epoch:1 step:972 [D loss: 0.514498, acc.: 83.59%] [G loss: 0.258857]\n",
      "epoch:1 step:973 [D loss: 0.492716, acc.: 91.41%] [G loss: 0.309317]\n",
      "epoch:1 step:974 [D loss: 0.515034, acc.: 81.25%] [G loss: 0.282757]\n",
      "epoch:1 step:975 [D loss: 0.587634, acc.: 70.31%] [G loss: 0.153134]\n",
      "epoch:1 step:976 [D loss: 0.506165, acc.: 78.91%] [G loss: 0.237749]\n",
      "epoch:1 step:977 [D loss: 0.440843, acc.: 86.72%] [G loss: 0.355785]\n",
      "epoch:1 step:978 [D loss: 0.496404, acc.: 85.16%] [G loss: 0.333665]\n",
      "epoch:1 step:979 [D loss: 0.573520, acc.: 73.44%] [G loss: 0.255343]\n",
      "epoch:1 step:980 [D loss: 0.509887, acc.: 82.81%] [G loss: 0.236082]\n",
      "epoch:1 step:981 [D loss: 0.521540, acc.: 80.47%] [G loss: 0.250757]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:1 step:982 [D loss: 0.534927, acc.: 76.56%] [G loss: 0.258114]\n",
      "epoch:1 step:983 [D loss: 0.546611, acc.: 76.56%] [G loss: 0.257929]\n",
      "epoch:1 step:984 [D loss: 0.532223, acc.: 78.91%] [G loss: 0.184590]\n",
      "epoch:1 step:985 [D loss: 0.510202, acc.: 85.16%] [G loss: 0.197505]\n",
      "epoch:1 step:986 [D loss: 0.479295, acc.: 85.16%] [G loss: 0.292651]\n",
      "epoch:1 step:987 [D loss: 0.531772, acc.: 74.22%] [G loss: 0.298315]\n",
      "epoch:1 step:988 [D loss: 0.505423, acc.: 85.16%] [G loss: 0.263790]\n",
      "epoch:1 step:989 [D loss: 0.513966, acc.: 81.25%] [G loss: 0.216182]\n",
      "epoch:1 step:990 [D loss: 0.524193, acc.: 78.12%] [G loss: 0.269981]\n",
      "epoch:1 step:991 [D loss: 0.573357, acc.: 66.41%] [G loss: 0.263030]\n",
      "epoch:1 step:992 [D loss: 0.578734, acc.: 68.75%] [G loss: 0.248677]\n",
      "epoch:1 step:993 [D loss: 0.557902, acc.: 75.00%] [G loss: 0.251963]\n",
      "epoch:1 step:994 [D loss: 0.590073, acc.: 67.19%] [G loss: 0.300866]\n",
      "epoch:1 step:995 [D loss: 0.593780, acc.: 71.09%] [G loss: 0.307779]\n",
      "epoch:1 step:996 [D loss: 0.520867, acc.: 75.78%] [G loss: 0.366522]\n",
      "epoch:1 step:997 [D loss: 0.533963, acc.: 78.12%] [G loss: 0.324224]\n",
      "epoch:1 step:998 [D loss: 0.562368, acc.: 69.53%] [G loss: 0.290446]\n",
      "epoch:1 step:999 [D loss: 0.580116, acc.: 71.88%] [G loss: 0.248452]\n",
      "epoch:1 step:1000 [D loss: 0.532203, acc.: 70.31%] [G loss: 0.241082]\n",
      "epoch:1 step:1001 [D loss: 0.588975, acc.: 67.19%] [G loss: 0.236112]\n",
      "epoch:1 step:1002 [D loss: 0.565239, acc.: 66.41%] [G loss: 0.222643]\n",
      "epoch:1 step:1003 [D loss: 0.553131, acc.: 71.88%] [G loss: 0.260765]\n",
      "epoch:1 step:1004 [D loss: 0.552083, acc.: 70.31%] [G loss: 0.220038]\n",
      "epoch:1 step:1005 [D loss: 0.513881, acc.: 76.56%] [G loss: 0.298117]\n",
      "epoch:1 step:1006 [D loss: 0.533716, acc.: 80.47%] [G loss: 0.285396]\n",
      "epoch:1 step:1007 [D loss: 0.535530, acc.: 79.69%] [G loss: 0.338510]\n",
      "epoch:1 step:1008 [D loss: 0.582710, acc.: 78.12%] [G loss: 0.221308]\n",
      "epoch:1 step:1009 [D loss: 0.558333, acc.: 67.19%] [G loss: 0.239791]\n",
      "epoch:1 step:1010 [D loss: 0.529297, acc.: 75.00%] [G loss: 0.288189]\n",
      "epoch:1 step:1011 [D loss: 0.547806, acc.: 76.56%] [G loss: 0.276302]\n",
      "epoch:1 step:1012 [D loss: 0.543735, acc.: 71.88%] [G loss: 0.270293]\n",
      "epoch:1 step:1013 [D loss: 0.523774, acc.: 75.00%] [G loss: 0.270699]\n",
      "epoch:1 step:1014 [D loss: 0.477012, acc.: 83.59%] [G loss: 0.299870]\n",
      "epoch:1 step:1015 [D loss: 0.608226, acc.: 61.72%] [G loss: 0.172811]\n",
      "epoch:1 step:1016 [D loss: 0.564368, acc.: 73.44%] [G loss: 0.215153]\n",
      "epoch:1 step:1017 [D loss: 0.587378, acc.: 67.19%] [G loss: 0.200742]\n",
      "epoch:1 step:1018 [D loss: 0.513067, acc.: 85.16%] [G loss: 0.241101]\n",
      "epoch:1 step:1019 [D loss: 0.538391, acc.: 75.78%] [G loss: 0.251568]\n",
      "epoch:1 step:1020 [D loss: 0.532746, acc.: 79.69%] [G loss: 0.248107]\n",
      "epoch:1 step:1021 [D loss: 0.512101, acc.: 82.81%] [G loss: 0.231972]\n",
      "epoch:1 step:1022 [D loss: 0.573704, acc.: 71.09%] [G loss: 0.162804]\n",
      "epoch:1 step:1023 [D loss: 0.526563, acc.: 71.88%] [G loss: 0.243681]\n",
      "epoch:1 step:1024 [D loss: 0.485195, acc.: 87.50%] [G loss: 0.281994]\n",
      "epoch:1 step:1025 [D loss: 0.493385, acc.: 85.16%] [G loss: 0.282872]\n",
      "epoch:1 step:1026 [D loss: 0.556289, acc.: 74.22%] [G loss: 0.216914]\n",
      "epoch:1 step:1027 [D loss: 0.558478, acc.: 70.31%] [G loss: 0.217274]\n",
      "epoch:1 step:1028 [D loss: 0.572124, acc.: 71.09%] [G loss: 0.222115]\n",
      "epoch:1 step:1029 [D loss: 0.559976, acc.: 74.22%] [G loss: 0.211880]\n",
      "epoch:1 step:1030 [D loss: 0.545837, acc.: 75.00%] [G loss: 0.215014]\n",
      "epoch:1 step:1031 [D loss: 0.532777, acc.: 78.91%] [G loss: 0.247972]\n",
      "epoch:1 step:1032 [D loss: 0.551285, acc.: 75.00%] [G loss: 0.244061]\n",
      "epoch:1 step:1033 [D loss: 0.533185, acc.: 82.81%] [G loss: 0.219551]\n",
      "epoch:1 step:1034 [D loss: 0.564720, acc.: 71.09%] [G loss: 0.217088]\n",
      "epoch:1 step:1035 [D loss: 0.551448, acc.: 82.03%] [G loss: 0.232214]\n",
      "epoch:1 step:1036 [D loss: 0.605511, acc.: 67.19%] [G loss: 0.178233]\n",
      "epoch:1 step:1037 [D loss: 0.562961, acc.: 72.66%] [G loss: 0.232604]\n",
      "epoch:1 step:1038 [D loss: 0.577200, acc.: 73.44%] [G loss: 0.238572]\n",
      "epoch:1 step:1039 [D loss: 0.640065, acc.: 60.94%] [G loss: 0.145126]\n",
      "epoch:1 step:1040 [D loss: 0.495895, acc.: 85.16%] [G loss: 0.249595]\n",
      "epoch:1 step:1041 [D loss: 0.542365, acc.: 78.12%] [G loss: 0.244703]\n",
      "epoch:1 step:1042 [D loss: 0.625348, acc.: 64.06%] [G loss: 0.183621]\n",
      "epoch:1 step:1043 [D loss: 0.581254, acc.: 69.53%] [G loss: 0.192548]\n",
      "epoch:1 step:1044 [D loss: 0.563017, acc.: 71.09%] [G loss: 0.287642]\n",
      "epoch:1 step:1045 [D loss: 0.547642, acc.: 77.34%] [G loss: 0.311323]\n",
      "epoch:1 step:1046 [D loss: 0.605235, acc.: 68.75%] [G loss: 0.166902]\n",
      "epoch:1 step:1047 [D loss: 0.556556, acc.: 74.22%] [G loss: 0.216205]\n",
      "epoch:1 step:1048 [D loss: 0.536247, acc.: 78.12%] [G loss: 0.215912]\n",
      "epoch:1 step:1049 [D loss: 0.548408, acc.: 78.91%] [G loss: 0.207603]\n",
      "epoch:1 step:1050 [D loss: 0.524012, acc.: 77.34%] [G loss: 0.241734]\n",
      "epoch:1 step:1051 [D loss: 0.530642, acc.: 79.69%] [G loss: 0.249949]\n",
      "epoch:1 step:1052 [D loss: 0.491697, acc.: 85.94%] [G loss: 0.350238]\n",
      "epoch:1 step:1053 [D loss: 0.526725, acc.: 79.69%] [G loss: 0.292511]\n",
      "epoch:1 step:1054 [D loss: 0.542900, acc.: 77.34%] [G loss: 0.294563]\n",
      "epoch:1 step:1055 [D loss: 0.502625, acc.: 83.59%] [G loss: 0.307148]\n",
      "epoch:1 step:1056 [D loss: 0.509957, acc.: 76.56%] [G loss: 0.325453]\n",
      "epoch:1 step:1057 [D loss: 0.625535, acc.: 69.53%] [G loss: 0.196159]\n",
      "epoch:1 step:1058 [D loss: 0.606851, acc.: 67.97%] [G loss: 0.193388]\n",
      "epoch:1 step:1059 [D loss: 0.538553, acc.: 76.56%] [G loss: 0.247957]\n",
      "epoch:1 step:1060 [D loss: 0.553598, acc.: 76.56%] [G loss: 0.260291]\n",
      "epoch:1 step:1061 [D loss: 0.528233, acc.: 88.28%] [G loss: 0.183961]\n",
      "epoch:1 step:1062 [D loss: 0.516586, acc.: 85.16%] [G loss: 0.231214]\n",
      "epoch:1 step:1063 [D loss: 0.535202, acc.: 80.47%] [G loss: 0.222939]\n",
      "epoch:1 step:1064 [D loss: 0.524477, acc.: 82.03%] [G loss: 0.208110]\n",
      "epoch:1 step:1065 [D loss: 0.535794, acc.: 83.59%] [G loss: 0.211071]\n",
      "epoch:1 step:1066 [D loss: 0.522843, acc.: 82.81%] [G loss: 0.185664]\n",
      "epoch:1 step:1067 [D loss: 0.505462, acc.: 83.59%] [G loss: 0.236798]\n",
      "epoch:1 step:1068 [D loss: 0.483337, acc.: 82.03%] [G loss: 0.267642]\n",
      "epoch:1 step:1069 [D loss: 0.529081, acc.: 83.59%] [G loss: 0.227011]\n",
      "epoch:1 step:1070 [D loss: 0.500619, acc.: 82.81%] [G loss: 0.217939]\n",
      "epoch:1 step:1071 [D loss: 0.506641, acc.: 85.16%] [G loss: 0.227546]\n",
      "epoch:1 step:1072 [D loss: 0.507376, acc.: 87.50%] [G loss: 0.212118]\n",
      "epoch:1 step:1073 [D loss: 0.473320, acc.: 89.84%] [G loss: 0.255411]\n",
      "epoch:1 step:1074 [D loss: 0.559233, acc.: 79.69%] [G loss: 0.163144]\n",
      "epoch:1 step:1075 [D loss: 0.489892, acc.: 85.94%] [G loss: 0.216585]\n",
      "epoch:1 step:1076 [D loss: 0.559055, acc.: 75.78%] [G loss: 0.232690]\n",
      "epoch:1 step:1077 [D loss: 0.541433, acc.: 78.91%] [G loss: 0.199999]\n",
      "epoch:1 step:1078 [D loss: 0.517584, acc.: 76.56%] [G loss: 0.235841]\n",
      "epoch:1 step:1079 [D loss: 0.540556, acc.: 75.00%] [G loss: 0.226643]\n",
      "epoch:1 step:1080 [D loss: 0.520819, acc.: 81.25%] [G loss: 0.240728]\n",
      "epoch:1 step:1081 [D loss: 0.526513, acc.: 74.22%] [G loss: 0.189014]\n",
      "epoch:1 step:1082 [D loss: 0.501756, acc.: 82.81%] [G loss: 0.239012]\n",
      "epoch:1 step:1083 [D loss: 0.499872, acc.: 82.81%] [G loss: 0.290763]\n",
      "epoch:1 step:1084 [D loss: 0.514861, acc.: 82.81%] [G loss: 0.249147]\n",
      "epoch:1 step:1085 [D loss: 0.497047, acc.: 85.94%] [G loss: 0.259592]\n",
      "epoch:1 step:1086 [D loss: 0.501162, acc.: 82.03%] [G loss: 0.280259]\n",
      "epoch:1 step:1087 [D loss: 0.500841, acc.: 81.25%] [G loss: 0.293391]\n",
      "epoch:1 step:1088 [D loss: 0.443401, acc.: 89.84%] [G loss: 0.338854]\n",
      "epoch:1 step:1089 [D loss: 0.476672, acc.: 85.16%] [G loss: 0.449313]\n",
      "epoch:1 step:1090 [D loss: 0.561648, acc.: 72.66%] [G loss: 0.276316]\n",
      "epoch:1 step:1091 [D loss: 0.555201, acc.: 75.78%] [G loss: 0.161322]\n",
      "epoch:1 step:1092 [D loss: 0.473098, acc.: 88.28%] [G loss: 0.236383]\n",
      "epoch:1 step:1093 [D loss: 0.505814, acc.: 82.03%] [G loss: 0.276979]\n",
      "epoch:1 step:1094 [D loss: 0.513794, acc.: 85.94%] [G loss: 0.261779]\n",
      "epoch:1 step:1095 [D loss: 0.534601, acc.: 76.56%] [G loss: 0.240384]\n",
      "epoch:1 step:1096 [D loss: 0.513966, acc.: 80.47%] [G loss: 0.252534]\n",
      "epoch:1 step:1097 [D loss: 0.573974, acc.: 74.22%] [G loss: 0.240709]\n",
      "epoch:1 step:1098 [D loss: 0.503913, acc.: 78.91%] [G loss: 0.295398]\n",
      "epoch:1 step:1099 [D loss: 0.470998, acc.: 87.50%] [G loss: 0.348613]\n",
      "epoch:1 step:1100 [D loss: 0.486476, acc.: 85.16%] [G loss: 0.307888]\n",
      "epoch:1 step:1101 [D loss: 0.491464, acc.: 82.81%] [G loss: 0.301632]\n",
      "epoch:1 step:1102 [D loss: 0.536510, acc.: 78.12%] [G loss: 0.284981]\n",
      "epoch:1 step:1103 [D loss: 0.551442, acc.: 75.00%] [G loss: 0.237209]\n",
      "epoch:1 step:1104 [D loss: 0.558820, acc.: 76.56%] [G loss: 0.218458]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:1 step:1105 [D loss: 0.523683, acc.: 78.91%] [G loss: 0.269283]\n",
      "epoch:1 step:1106 [D loss: 0.537664, acc.: 75.00%] [G loss: 0.292976]\n",
      "epoch:1 step:1107 [D loss: 0.486080, acc.: 86.72%] [G loss: 0.319921]\n",
      "epoch:1 step:1108 [D loss: 0.482703, acc.: 87.50%] [G loss: 0.281702]\n",
      "epoch:1 step:1109 [D loss: 0.511547, acc.: 78.91%] [G loss: 0.292745]\n",
      "epoch:1 step:1110 [D loss: 0.507601, acc.: 83.59%] [G loss: 0.322950]\n",
      "epoch:1 step:1111 [D loss: 0.533665, acc.: 82.03%] [G loss: 0.260375]\n",
      "epoch:1 step:1112 [D loss: 0.549988, acc.: 73.44%] [G loss: 0.244863]\n",
      "epoch:1 step:1113 [D loss: 0.537106, acc.: 75.78%] [G loss: 0.254349]\n",
      "epoch:1 step:1114 [D loss: 0.524657, acc.: 75.78%] [G loss: 0.290442]\n",
      "epoch:1 step:1115 [D loss: 0.477227, acc.: 83.59%] [G loss: 0.359757]\n",
      "epoch:1 step:1116 [D loss: 0.522493, acc.: 78.12%] [G loss: 0.337570]\n",
      "epoch:1 step:1117 [D loss: 0.534951, acc.: 81.25%] [G loss: 0.284702]\n",
      "epoch:1 step:1118 [D loss: 0.560271, acc.: 74.22%] [G loss: 0.280580]\n",
      "epoch:1 step:1119 [D loss: 0.526111, acc.: 78.91%] [G loss: 0.304503]\n",
      "epoch:1 step:1120 [D loss: 0.579854, acc.: 72.66%] [G loss: 0.232709]\n",
      "epoch:1 step:1121 [D loss: 0.530168, acc.: 75.00%] [G loss: 0.301928]\n",
      "epoch:1 step:1122 [D loss: 0.569654, acc.: 74.22%] [G loss: 0.290000]\n",
      "epoch:1 step:1123 [D loss: 0.495057, acc.: 84.38%] [G loss: 0.327345]\n",
      "epoch:1 step:1124 [D loss: 0.555040, acc.: 75.00%] [G loss: 0.257552]\n",
      "epoch:1 step:1125 [D loss: 0.544773, acc.: 78.12%] [G loss: 0.303566]\n",
      "epoch:1 step:1126 [D loss: 0.553637, acc.: 69.53%] [G loss: 0.301942]\n",
      "epoch:1 step:1127 [D loss: 0.509093, acc.: 85.94%] [G loss: 0.274753]\n",
      "epoch:1 step:1128 [D loss: 0.536060, acc.: 75.00%] [G loss: 0.254148]\n",
      "epoch:1 step:1129 [D loss: 0.518309, acc.: 78.91%] [G loss: 0.338697]\n",
      "epoch:1 step:1130 [D loss: 0.568212, acc.: 74.22%] [G loss: 0.232464]\n",
      "epoch:1 step:1131 [D loss: 0.497615, acc.: 76.56%] [G loss: 0.328897]\n",
      "epoch:1 step:1132 [D loss: 0.483663, acc.: 87.50%] [G loss: 0.409125]\n",
      "epoch:1 step:1133 [D loss: 0.511334, acc.: 85.16%] [G loss: 0.358806]\n",
      "epoch:1 step:1134 [D loss: 0.555506, acc.: 80.47%] [G loss: 0.232292]\n",
      "epoch:1 step:1135 [D loss: 0.473623, acc.: 89.84%] [G loss: 0.357210]\n",
      "epoch:1 step:1136 [D loss: 0.555609, acc.: 76.56%] [G loss: 0.272853]\n",
      "epoch:1 step:1137 [D loss: 0.550491, acc.: 75.78%] [G loss: 0.259244]\n",
      "epoch:1 step:1138 [D loss: 0.548368, acc.: 74.22%] [G loss: 0.264104]\n",
      "epoch:1 step:1139 [D loss: 0.488478, acc.: 83.59%] [G loss: 0.338913]\n",
      "epoch:1 step:1140 [D loss: 0.542318, acc.: 80.47%] [G loss: 0.321464]\n",
      "epoch:1 step:1141 [D loss: 0.512651, acc.: 81.25%] [G loss: 0.315494]\n",
      "epoch:1 step:1142 [D loss: 0.481970, acc.: 87.50%] [G loss: 0.400349]\n",
      "epoch:1 step:1143 [D loss: 0.475928, acc.: 90.62%] [G loss: 0.392843]\n",
      "epoch:1 step:1144 [D loss: 0.459047, acc.: 86.72%] [G loss: 0.462570]\n",
      "epoch:1 step:1145 [D loss: 0.469996, acc.: 86.72%] [G loss: 0.371880]\n",
      "epoch:1 step:1146 [D loss: 0.454317, acc.: 85.94%] [G loss: 0.447985]\n",
      "epoch:1 step:1147 [D loss: 0.582827, acc.: 67.97%] [G loss: 0.253988]\n",
      "epoch:1 step:1148 [D loss: 0.530192, acc.: 80.47%] [G loss: 0.244535]\n",
      "epoch:1 step:1149 [D loss: 0.485323, acc.: 81.25%] [G loss: 0.333253]\n",
      "epoch:1 step:1150 [D loss: 0.475982, acc.: 86.72%] [G loss: 0.376153]\n",
      "epoch:1 step:1151 [D loss: 0.578354, acc.: 76.56%] [G loss: 0.241629]\n",
      "epoch:1 step:1152 [D loss: 0.548634, acc.: 78.91%] [G loss: 0.212867]\n",
      "epoch:1 step:1153 [D loss: 0.538695, acc.: 74.22%] [G loss: 0.235022]\n",
      "epoch:1 step:1154 [D loss: 0.451194, acc.: 92.97%] [G loss: 0.390807]\n",
      "epoch:1 step:1155 [D loss: 0.465882, acc.: 89.84%] [G loss: 0.413689]\n",
      "epoch:1 step:1156 [D loss: 0.492815, acc.: 83.59%] [G loss: 0.398743]\n",
      "epoch:1 step:1157 [D loss: 0.556256, acc.: 75.78%] [G loss: 0.254503]\n",
      "epoch:1 step:1158 [D loss: 0.479559, acc.: 85.94%] [G loss: 0.392941]\n",
      "epoch:1 step:1159 [D loss: 0.484795, acc.: 79.69%] [G loss: 0.472325]\n",
      "epoch:1 step:1160 [D loss: 0.507633, acc.: 82.03%] [G loss: 0.412627]\n",
      "epoch:1 step:1161 [D loss: 0.512444, acc.: 85.94%] [G loss: 0.289529]\n",
      "epoch:1 step:1162 [D loss: 0.526609, acc.: 81.25%] [G loss: 0.262642]\n",
      "epoch:1 step:1163 [D loss: 0.509891, acc.: 82.81%] [G loss: 0.252503]\n",
      "epoch:1 step:1164 [D loss: 0.559381, acc.: 75.00%] [G loss: 0.246019]\n",
      "epoch:1 step:1165 [D loss: 0.489263, acc.: 84.38%] [G loss: 0.321831]\n",
      "epoch:1 step:1166 [D loss: 0.503700, acc.: 78.12%] [G loss: 0.420948]\n",
      "epoch:1 step:1167 [D loss: 0.454290, acc.: 91.41%] [G loss: 0.516828]\n",
      "epoch:1 step:1168 [D loss: 0.465959, acc.: 85.94%] [G loss: 0.526646]\n",
      "epoch:1 step:1169 [D loss: 0.418747, acc.: 86.72%] [G loss: 0.639680]\n",
      "epoch:1 step:1170 [D loss: 0.584331, acc.: 75.78%] [G loss: 0.285094]\n",
      "epoch:1 step:1171 [D loss: 0.513477, acc.: 78.12%] [G loss: 0.272466]\n",
      "epoch:1 step:1172 [D loss: 0.524962, acc.: 82.03%] [G loss: 0.252372]\n",
      "epoch:1 step:1173 [D loss: 0.526498, acc.: 80.47%] [G loss: 0.234120]\n",
      "epoch:1 step:1174 [D loss: 0.516199, acc.: 78.91%] [G loss: 0.318484]\n",
      "epoch:1 step:1175 [D loss: 0.522438, acc.: 78.12%] [G loss: 0.320572]\n",
      "epoch:1 step:1176 [D loss: 0.504104, acc.: 80.47%] [G loss: 0.342976]\n",
      "epoch:1 step:1177 [D loss: 0.534899, acc.: 73.44%] [G loss: 0.317649]\n",
      "epoch:1 step:1178 [D loss: 0.501883, acc.: 85.16%] [G loss: 0.308560]\n",
      "epoch:1 step:1179 [D loss: 0.553996, acc.: 78.91%] [G loss: 0.257878]\n",
      "epoch:1 step:1180 [D loss: 0.524047, acc.: 79.69%] [G loss: 0.236275]\n",
      "epoch:1 step:1181 [D loss: 0.468496, acc.: 83.59%] [G loss: 0.325507]\n",
      "epoch:1 step:1182 [D loss: 0.476873, acc.: 87.50%] [G loss: 0.410037]\n",
      "epoch:1 step:1183 [D loss: 0.473550, acc.: 89.84%] [G loss: 0.365440]\n",
      "epoch:1 step:1184 [D loss: 0.513931, acc.: 86.72%] [G loss: 0.334392]\n",
      "epoch:1 step:1185 [D loss: 0.535941, acc.: 78.12%] [G loss: 0.333195]\n",
      "epoch:1 step:1186 [D loss: 0.485112, acc.: 85.94%] [G loss: 0.442944]\n",
      "epoch:1 step:1187 [D loss: 0.529236, acc.: 78.91%] [G loss: 0.278026]\n",
      "epoch:1 step:1188 [D loss: 0.488659, acc.: 86.72%] [G loss: 0.331401]\n",
      "epoch:1 step:1189 [D loss: 0.522133, acc.: 76.56%] [G loss: 0.328490]\n",
      "epoch:1 step:1190 [D loss: 0.502177, acc.: 82.03%] [G loss: 0.416114]\n",
      "epoch:1 step:1191 [D loss: 0.503366, acc.: 83.59%] [G loss: 0.362041]\n",
      "epoch:1 step:1192 [D loss: 0.492813, acc.: 87.50%] [G loss: 0.366349]\n",
      "epoch:1 step:1193 [D loss: 0.487520, acc.: 87.50%] [G loss: 0.342157]\n",
      "epoch:1 step:1194 [D loss: 0.493602, acc.: 84.38%] [G loss: 0.328890]\n",
      "epoch:1 step:1195 [D loss: 0.471636, acc.: 86.72%] [G loss: 0.364112]\n",
      "epoch:1 step:1196 [D loss: 0.488559, acc.: 85.94%] [G loss: 0.401003]\n",
      "epoch:1 step:1197 [D loss: 0.507486, acc.: 78.91%] [G loss: 0.381823]\n",
      "epoch:1 step:1198 [D loss: 0.513048, acc.: 78.91%] [G loss: 0.356663]\n",
      "epoch:1 step:1199 [D loss: 0.480462, acc.: 81.25%] [G loss: 0.347331]\n",
      "epoch:1 step:1200 [D loss: 0.664380, acc.: 60.94%] [G loss: 0.163430]\n",
      "epoch:1 step:1201 [D loss: 0.580830, acc.: 67.97%] [G loss: 0.238231]\n",
      "epoch:1 step:1202 [D loss: 0.458549, acc.: 87.50%] [G loss: 0.431520]\n",
      "epoch:1 step:1203 [D loss: 0.513286, acc.: 82.03%] [G loss: 0.369838]\n",
      "epoch:1 step:1204 [D loss: 0.499801, acc.: 81.25%] [G loss: 0.332327]\n",
      "epoch:1 step:1205 [D loss: 0.555830, acc.: 75.78%] [G loss: 0.240759]\n",
      "epoch:1 step:1206 [D loss: 0.611273, acc.: 65.62%] [G loss: 0.251084]\n",
      "epoch:1 step:1207 [D loss: 0.494134, acc.: 82.81%] [G loss: 0.360941]\n",
      "epoch:1 step:1208 [D loss: 0.503317, acc.: 89.06%] [G loss: 0.339224]\n",
      "epoch:1 step:1209 [D loss: 0.518924, acc.: 85.94%] [G loss: 0.289749]\n",
      "epoch:1 step:1210 [D loss: 0.516066, acc.: 78.91%] [G loss: 0.281657]\n",
      "epoch:1 step:1211 [D loss: 0.575378, acc.: 71.88%] [G loss: 0.232594]\n",
      "epoch:1 step:1212 [D loss: 0.577847, acc.: 70.31%] [G loss: 0.201968]\n",
      "epoch:1 step:1213 [D loss: 0.528468, acc.: 74.22%] [G loss: 0.288302]\n",
      "epoch:1 step:1214 [D loss: 0.554201, acc.: 74.22%] [G loss: 0.281302]\n",
      "epoch:1 step:1215 [D loss: 0.540272, acc.: 71.88%] [G loss: 0.281209]\n",
      "epoch:1 step:1216 [D loss: 0.474589, acc.: 85.16%] [G loss: 0.411836]\n",
      "epoch:1 step:1217 [D loss: 0.518181, acc.: 85.94%] [G loss: 0.346400]\n",
      "epoch:1 step:1218 [D loss: 0.539704, acc.: 76.56%] [G loss: 0.279596]\n",
      "epoch:1 step:1219 [D loss: 0.534683, acc.: 77.34%] [G loss: 0.248524]\n",
      "epoch:1 step:1220 [D loss: 0.514923, acc.: 80.47%] [G loss: 0.223761]\n",
      "epoch:1 step:1221 [D loss: 0.509003, acc.: 76.56%] [G loss: 0.347461]\n",
      "epoch:1 step:1222 [D loss: 0.506930, acc.: 82.81%] [G loss: 0.348172]\n",
      "epoch:1 step:1223 [D loss: 0.475391, acc.: 86.72%] [G loss: 0.324965]\n",
      "epoch:1 step:1224 [D loss: 0.547365, acc.: 70.31%] [G loss: 0.267495]\n",
      "epoch:1 step:1225 [D loss: 0.536201, acc.: 73.44%] [G loss: 0.312980]\n",
      "epoch:1 step:1226 [D loss: 0.521211, acc.: 73.44%] [G loss: 0.401696]\n",
      "epoch:1 step:1227 [D loss: 0.562038, acc.: 71.09%] [G loss: 0.311924]\n",
      "epoch:1 step:1228 [D loss: 0.600057, acc.: 66.41%] [G loss: 0.246062]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:1 step:1229 [D loss: 0.527825, acc.: 76.56%] [G loss: 0.337190]\n",
      "epoch:1 step:1230 [D loss: 0.549858, acc.: 75.78%] [G loss: 0.338133]\n",
      "epoch:1 step:1231 [D loss: 0.540135, acc.: 75.78%] [G loss: 0.304844]\n",
      "epoch:1 step:1232 [D loss: 0.559137, acc.: 71.09%] [G loss: 0.292832]\n",
      "epoch:1 step:1233 [D loss: 0.492129, acc.: 81.25%] [G loss: 0.393768]\n",
      "epoch:1 step:1234 [D loss: 0.489773, acc.: 89.06%] [G loss: 0.393069]\n",
      "epoch:1 step:1235 [D loss: 0.547236, acc.: 76.56%] [G loss: 0.327368]\n",
      "epoch:1 step:1236 [D loss: 0.530611, acc.: 74.22%] [G loss: 0.461576]\n",
      "epoch:1 step:1237 [D loss: 0.529670, acc.: 78.91%] [G loss: 0.344607]\n",
      "epoch:1 step:1238 [D loss: 0.528001, acc.: 81.25%] [G loss: 0.337951]\n",
      "epoch:1 step:1239 [D loss: 0.482803, acc.: 86.72%] [G loss: 0.349316]\n",
      "epoch:1 step:1240 [D loss: 0.485909, acc.: 89.06%] [G loss: 0.395686]\n",
      "epoch:1 step:1241 [D loss: 0.469210, acc.: 89.84%] [G loss: 0.340426]\n",
      "epoch:1 step:1242 [D loss: 0.477697, acc.: 85.16%] [G loss: 0.359809]\n",
      "epoch:1 step:1243 [D loss: 0.514776, acc.: 83.59%] [G loss: 0.358700]\n",
      "epoch:1 step:1244 [D loss: 0.490255, acc.: 82.03%] [G loss: 0.380912]\n",
      "epoch:1 step:1245 [D loss: 0.499452, acc.: 82.81%] [G loss: 0.380901]\n",
      "epoch:1 step:1246 [D loss: 0.467148, acc.: 85.94%] [G loss: 0.419253]\n",
      "epoch:1 step:1247 [D loss: 0.488041, acc.: 82.03%] [G loss: 0.353974]\n",
      "epoch:1 step:1248 [D loss: 0.489550, acc.: 81.25%] [G loss: 0.399121]\n",
      "epoch:1 step:1249 [D loss: 0.488327, acc.: 78.91%] [G loss: 0.465547]\n",
      "epoch:1 step:1250 [D loss: 0.504070, acc.: 76.56%] [G loss: 0.435531]\n",
      "epoch:1 step:1251 [D loss: 0.488397, acc.: 84.38%] [G loss: 0.419160]\n",
      "epoch:1 step:1252 [D loss: 0.426270, acc.: 88.28%] [G loss: 0.434697]\n",
      "epoch:1 step:1253 [D loss: 0.697927, acc.: 62.50%] [G loss: 0.141111]\n",
      "epoch:1 step:1254 [D loss: 0.542471, acc.: 69.53%] [G loss: 0.171910]\n",
      "epoch:1 step:1255 [D loss: 0.542323, acc.: 72.66%] [G loss: 0.217553]\n",
      "epoch:1 step:1256 [D loss: 0.477368, acc.: 83.59%] [G loss: 0.301012]\n",
      "epoch:1 step:1257 [D loss: 0.530708, acc.: 81.25%] [G loss: 0.261128]\n",
      "epoch:1 step:1258 [D loss: 0.514438, acc.: 79.69%] [G loss: 0.259899]\n",
      "epoch:1 step:1259 [D loss: 0.475685, acc.: 85.16%] [G loss: 0.290766]\n",
      "epoch:1 step:1260 [D loss: 0.461917, acc.: 85.16%] [G loss: 0.294105]\n",
      "epoch:1 step:1261 [D loss: 0.455203, acc.: 88.28%] [G loss: 0.328913]\n",
      "epoch:1 step:1262 [D loss: 0.507857, acc.: 84.38%] [G loss: 0.311960]\n",
      "epoch:1 step:1263 [D loss: 0.494860, acc.: 80.47%] [G loss: 0.334502]\n",
      "epoch:1 step:1264 [D loss: 0.535379, acc.: 73.44%] [G loss: 0.310276]\n",
      "epoch:1 step:1265 [D loss: 0.539239, acc.: 75.00%] [G loss: 0.344860]\n",
      "epoch:1 step:1266 [D loss: 0.497338, acc.: 78.12%] [G loss: 0.372523]\n",
      "epoch:1 step:1267 [D loss: 0.576892, acc.: 68.75%] [G loss: 0.297806]\n",
      "epoch:1 step:1268 [D loss: 0.502892, acc.: 83.59%] [G loss: 0.304179]\n",
      "epoch:1 step:1269 [D loss: 0.504933, acc.: 81.25%] [G loss: 0.304836]\n",
      "epoch:1 step:1270 [D loss: 0.495056, acc.: 79.69%] [G loss: 0.346423]\n",
      "epoch:1 step:1271 [D loss: 0.489748, acc.: 78.12%] [G loss: 0.392397]\n",
      "epoch:1 step:1272 [D loss: 0.460194, acc.: 83.59%] [G loss: 0.419881]\n",
      "epoch:1 step:1273 [D loss: 0.504846, acc.: 81.25%] [G loss: 0.318183]\n",
      "epoch:1 step:1274 [D loss: 0.483823, acc.: 78.12%] [G loss: 0.352780]\n",
      "epoch:1 step:1275 [D loss: 0.561947, acc.: 71.88%] [G loss: 0.282610]\n",
      "epoch:1 step:1276 [D loss: 0.522183, acc.: 78.91%] [G loss: 0.296887]\n",
      "epoch:1 step:1277 [D loss: 0.512174, acc.: 77.34%] [G loss: 0.279423]\n",
      "epoch:1 step:1278 [D loss: 0.471770, acc.: 82.03%] [G loss: 0.313691]\n",
      "epoch:1 step:1279 [D loss: 0.534843, acc.: 79.69%] [G loss: 0.279588]\n",
      "epoch:1 step:1280 [D loss: 0.493594, acc.: 78.91%] [G loss: 0.386433]\n",
      "epoch:1 step:1281 [D loss: 0.431780, acc.: 85.94%] [G loss: 0.523745]\n",
      "epoch:1 step:1282 [D loss: 0.507920, acc.: 78.91%] [G loss: 0.432053]\n",
      "epoch:1 step:1283 [D loss: 0.509400, acc.: 79.69%] [G loss: 0.453192]\n",
      "epoch:1 step:1284 [D loss: 0.459474, acc.: 82.81%] [G loss: 0.587758]\n",
      "epoch:1 step:1285 [D loss: 0.588673, acc.: 65.62%] [G loss: 0.249364]\n",
      "epoch:1 step:1286 [D loss: 0.742189, acc.: 42.97%] [G loss: 0.107123]\n",
      "epoch:1 step:1287 [D loss: 0.478389, acc.: 85.94%] [G loss: 0.276213]\n",
      "epoch:1 step:1288 [D loss: 0.549372, acc.: 74.22%] [G loss: 0.352455]\n",
      "epoch:1 step:1289 [D loss: 0.599240, acc.: 65.62%] [G loss: 0.267830]\n",
      "epoch:1 step:1290 [D loss: 0.523782, acc.: 77.34%] [G loss: 0.326658]\n",
      "epoch:1 step:1291 [D loss: 0.445833, acc.: 85.16%] [G loss: 0.391160]\n",
      "epoch:1 step:1292 [D loss: 0.474589, acc.: 80.47%] [G loss: 0.418559]\n",
      "epoch:1 step:1293 [D loss: 0.493781, acc.: 85.16%] [G loss: 0.360175]\n",
      "epoch:1 step:1294 [D loss: 0.463355, acc.: 82.81%] [G loss: 0.398590]\n",
      "epoch:1 step:1295 [D loss: 0.440726, acc.: 89.84%] [G loss: 0.389805]\n",
      "epoch:1 step:1296 [D loss: 0.465781, acc.: 82.81%] [G loss: 0.421105]\n",
      "epoch:1 step:1297 [D loss: 0.530407, acc.: 78.12%] [G loss: 0.340735]\n",
      "epoch:1 step:1298 [D loss: 0.445630, acc.: 86.72%] [G loss: 0.340729]\n",
      "epoch:1 step:1299 [D loss: 0.552518, acc.: 74.22%] [G loss: 0.320887]\n",
      "epoch:1 step:1300 [D loss: 0.500741, acc.: 85.94%] [G loss: 0.306637]\n",
      "epoch:1 step:1301 [D loss: 0.454011, acc.: 91.41%] [G loss: 0.340154]\n",
      "epoch:1 step:1302 [D loss: 0.547088, acc.: 71.09%] [G loss: 0.289665]\n",
      "epoch:1 step:1303 [D loss: 0.492373, acc.: 82.81%] [G loss: 0.321580]\n",
      "epoch:1 step:1304 [D loss: 0.545785, acc.: 69.53%] [G loss: 0.376763]\n",
      "epoch:1 step:1305 [D loss: 0.467308, acc.: 84.38%] [G loss: 0.354374]\n",
      "epoch:1 step:1306 [D loss: 0.531504, acc.: 78.12%] [G loss: 0.300282]\n",
      "epoch:1 step:1307 [D loss: 0.548810, acc.: 76.56%] [G loss: 0.327022]\n",
      "epoch:1 step:1308 [D loss: 0.526739, acc.: 79.69%] [G loss: 0.382765]\n",
      "epoch:1 step:1309 [D loss: 0.534868, acc.: 78.91%] [G loss: 0.384959]\n",
      "epoch:1 step:1310 [D loss: 0.571347, acc.: 72.66%] [G loss: 0.298411]\n",
      "epoch:1 step:1311 [D loss: 0.517096, acc.: 81.25%] [G loss: 0.261678]\n",
      "epoch:1 step:1312 [D loss: 0.508915, acc.: 79.69%] [G loss: 0.320752]\n",
      "epoch:1 step:1313 [D loss: 0.610685, acc.: 66.41%] [G loss: 0.269236]\n",
      "epoch:1 step:1314 [D loss: 0.561219, acc.: 72.66%] [G loss: 0.297494]\n",
      "epoch:1 step:1315 [D loss: 0.466689, acc.: 85.16%] [G loss: 0.432385]\n",
      "epoch:1 step:1316 [D loss: 0.558904, acc.: 71.88%] [G loss: 0.303440]\n",
      "epoch:1 step:1317 [D loss: 0.530847, acc.: 81.25%] [G loss: 0.282769]\n",
      "epoch:1 step:1318 [D loss: 0.487742, acc.: 82.03%] [G loss: 0.362618]\n",
      "epoch:1 step:1319 [D loss: 0.551641, acc.: 80.47%] [G loss: 0.311654]\n",
      "epoch:1 step:1320 [D loss: 0.647046, acc.: 59.38%] [G loss: 0.333703]\n",
      "epoch:1 step:1321 [D loss: 0.606971, acc.: 67.97%] [G loss: 0.297128]\n",
      "epoch:1 step:1322 [D loss: 0.576964, acc.: 71.09%] [G loss: 0.273565]\n",
      "epoch:1 step:1323 [D loss: 0.565655, acc.: 70.31%] [G loss: 0.259043]\n",
      "epoch:1 step:1324 [D loss: 0.524221, acc.: 78.91%] [G loss: 0.345440]\n",
      "epoch:1 step:1325 [D loss: 0.514498, acc.: 75.78%] [G loss: 0.395670]\n",
      "epoch:1 step:1326 [D loss: 0.527266, acc.: 76.56%] [G loss: 0.317199]\n",
      "epoch:1 step:1327 [D loss: 0.570688, acc.: 76.56%] [G loss: 0.270577]\n",
      "epoch:1 step:1328 [D loss: 0.537729, acc.: 80.47%] [G loss: 0.267033]\n",
      "epoch:1 step:1329 [D loss: 0.455046, acc.: 84.38%] [G loss: 0.400312]\n",
      "epoch:1 step:1330 [D loss: 0.537912, acc.: 75.78%] [G loss: 0.293282]\n",
      "epoch:1 step:1331 [D loss: 0.498611, acc.: 85.94%] [G loss: 0.308952]\n",
      "epoch:1 step:1332 [D loss: 0.508383, acc.: 76.56%] [G loss: 0.310554]\n",
      "epoch:1 step:1333 [D loss: 0.520089, acc.: 83.59%] [G loss: 0.366690]\n",
      "epoch:1 step:1334 [D loss: 0.395192, acc.: 89.84%] [G loss: 0.489002]\n",
      "epoch:1 step:1335 [D loss: 0.457083, acc.: 80.47%] [G loss: 0.506659]\n",
      "epoch:1 step:1336 [D loss: 0.429487, acc.: 89.06%] [G loss: 0.514384]\n",
      "epoch:1 step:1337 [D loss: 0.532042, acc.: 78.12%] [G loss: 0.303581]\n",
      "epoch:1 step:1338 [D loss: 0.517172, acc.: 79.69%] [G loss: 0.254837]\n",
      "epoch:1 step:1339 [D loss: 0.431243, acc.: 83.59%] [G loss: 0.399978]\n",
      "epoch:1 step:1340 [D loss: 0.468145, acc.: 80.47%] [G loss: 0.430046]\n",
      "epoch:1 step:1341 [D loss: 0.560794, acc.: 74.22%] [G loss: 0.257687]\n",
      "epoch:1 step:1342 [D loss: 0.521909, acc.: 75.78%] [G loss: 0.329022]\n",
      "epoch:1 step:1343 [D loss: 0.507728, acc.: 77.34%] [G loss: 0.371669]\n",
      "epoch:1 step:1344 [D loss: 0.454055, acc.: 88.28%] [G loss: 0.435524]\n",
      "epoch:1 step:1345 [D loss: 0.518415, acc.: 78.91%] [G loss: 0.324783]\n",
      "epoch:1 step:1346 [D loss: 0.460138, acc.: 82.81%] [G loss: 0.356948]\n",
      "epoch:1 step:1347 [D loss: 0.534908, acc.: 78.12%] [G loss: 0.346057]\n",
      "epoch:1 step:1348 [D loss: 0.535449, acc.: 76.56%] [G loss: 0.284914]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:1 step:1349 [D loss: 0.464623, acc.: 92.97%] [G loss: 0.359669]\n",
      "epoch:1 step:1350 [D loss: 0.529342, acc.: 83.59%] [G loss: 0.272040]\n",
      "epoch:1 step:1351 [D loss: 0.509714, acc.: 80.47%] [G loss: 0.275802]\n",
      "epoch:1 step:1352 [D loss: 0.499794, acc.: 76.56%] [G loss: 0.342516]\n",
      "epoch:1 step:1353 [D loss: 0.464991, acc.: 87.50%] [G loss: 0.478977]\n",
      "epoch:1 step:1354 [D loss: 0.544651, acc.: 76.56%] [G loss: 0.305655]\n",
      "epoch:1 step:1355 [D loss: 0.484531, acc.: 79.69%] [G loss: 0.347066]\n",
      "epoch:1 step:1356 [D loss: 0.461955, acc.: 88.28%] [G loss: 0.362395]\n",
      "epoch:1 step:1357 [D loss: 0.490164, acc.: 82.03%] [G loss: 0.355005]\n",
      "epoch:1 step:1358 [D loss: 0.532244, acc.: 78.12%] [G loss: 0.298177]\n",
      "epoch:1 step:1359 [D loss: 0.523635, acc.: 84.38%] [G loss: 0.296552]\n",
      "epoch:1 step:1360 [D loss: 0.474285, acc.: 84.38%] [G loss: 0.348839]\n",
      "epoch:1 step:1361 [D loss: 0.524707, acc.: 78.12%] [G loss: 0.374628]\n",
      "epoch:1 step:1362 [D loss: 0.473017, acc.: 82.81%] [G loss: 0.391527]\n",
      "epoch:1 step:1363 [D loss: 0.498644, acc.: 79.69%] [G loss: 0.447804]\n",
      "epoch:1 step:1364 [D loss: 0.505456, acc.: 79.69%] [G loss: 0.401070]\n",
      "epoch:1 step:1365 [D loss: 0.477204, acc.: 87.50%] [G loss: 0.383612]\n",
      "epoch:1 step:1366 [D loss: 0.467111, acc.: 86.72%] [G loss: 0.401002]\n",
      "epoch:1 step:1367 [D loss: 0.505113, acc.: 78.12%] [G loss: 0.347228]\n",
      "epoch:1 step:1368 [D loss: 0.448771, acc.: 89.84%] [G loss: 0.364721]\n",
      "epoch:1 step:1369 [D loss: 0.540586, acc.: 81.25%] [G loss: 0.353549]\n",
      "epoch:1 step:1370 [D loss: 0.515917, acc.: 78.91%] [G loss: 0.311736]\n",
      "epoch:1 step:1371 [D loss: 0.548190, acc.: 76.56%] [G loss: 0.271237]\n",
      "epoch:1 step:1372 [D loss: 0.503258, acc.: 85.16%] [G loss: 0.279495]\n",
      "epoch:1 step:1373 [D loss: 0.491666, acc.: 85.94%] [G loss: 0.378327]\n",
      "epoch:1 step:1374 [D loss: 0.556687, acc.: 77.34%] [G loss: 0.265407]\n",
      "epoch:1 step:1375 [D loss: 0.495756, acc.: 82.03%] [G loss: 0.265991]\n",
      "epoch:1 step:1376 [D loss: 0.471431, acc.: 85.94%] [G loss: 0.307580]\n",
      "epoch:1 step:1377 [D loss: 0.485357, acc.: 88.28%] [G loss: 0.344523]\n",
      "epoch:1 step:1378 [D loss: 0.471663, acc.: 85.16%] [G loss: 0.362338]\n",
      "epoch:1 step:1379 [D loss: 0.476044, acc.: 84.38%] [G loss: 0.373010]\n",
      "epoch:1 step:1380 [D loss: 0.456835, acc.: 85.94%] [G loss: 0.325765]\n",
      "epoch:1 step:1381 [D loss: 0.535855, acc.: 69.53%] [G loss: 0.304456]\n",
      "epoch:1 step:1382 [D loss: 0.495339, acc.: 78.91%] [G loss: 0.411225]\n",
      "epoch:1 step:1383 [D loss: 0.530220, acc.: 75.00%] [G loss: 0.437507]\n",
      "epoch:1 step:1384 [D loss: 0.419438, acc.: 88.28%] [G loss: 0.488001]\n",
      "epoch:1 step:1385 [D loss: 0.496475, acc.: 79.69%] [G loss: 0.458487]\n",
      "epoch:1 step:1386 [D loss: 0.504145, acc.: 81.25%] [G loss: 0.427114]\n",
      "epoch:1 step:1387 [D loss: 0.409836, acc.: 91.41%] [G loss: 0.445014]\n",
      "epoch:1 step:1388 [D loss: 0.497619, acc.: 81.25%] [G loss: 0.406344]\n",
      "epoch:1 step:1389 [D loss: 0.484853, acc.: 78.12%] [G loss: 0.431294]\n",
      "epoch:1 step:1390 [D loss: 0.520504, acc.: 76.56%] [G loss: 0.386827]\n",
      "epoch:1 step:1391 [D loss: 0.553382, acc.: 78.12%] [G loss: 0.385288]\n",
      "epoch:1 step:1392 [D loss: 0.504233, acc.: 78.12%] [G loss: 0.322366]\n",
      "epoch:1 step:1393 [D loss: 0.565232, acc.: 71.88%] [G loss: 0.362155]\n",
      "epoch:1 step:1394 [D loss: 0.492582, acc.: 79.69%] [G loss: 0.428718]\n",
      "epoch:1 step:1395 [D loss: 0.479596, acc.: 80.47%] [G loss: 0.417856]\n",
      "epoch:1 step:1396 [D loss: 0.502169, acc.: 76.56%] [G loss: 0.444887]\n",
      "epoch:1 step:1397 [D loss: 0.522678, acc.: 74.22%] [G loss: 0.472531]\n",
      "epoch:1 step:1398 [D loss: 0.492159, acc.: 82.81%] [G loss: 0.514929]\n",
      "epoch:1 step:1399 [D loss: 0.602041, acc.: 71.88%] [G loss: 0.277960]\n",
      "epoch:1 step:1400 [D loss: 0.588900, acc.: 70.31%] [G loss: 0.297903]\n",
      "epoch:1 step:1401 [D loss: 0.517268, acc.: 78.12%] [G loss: 0.321315]\n",
      "epoch:1 step:1402 [D loss: 0.601259, acc.: 69.53%] [G loss: 0.292477]\n",
      "epoch:1 step:1403 [D loss: 0.565521, acc.: 67.19%] [G loss: 0.360768]\n",
      "epoch:1 step:1404 [D loss: 0.546944, acc.: 76.56%] [G loss: 0.400329]\n",
      "epoch:1 step:1405 [D loss: 0.599982, acc.: 65.62%] [G loss: 0.343389]\n",
      "epoch:1 step:1406 [D loss: 0.549286, acc.: 67.19%] [G loss: 0.445711]\n",
      "epoch:1 step:1407 [D loss: 0.534225, acc.: 75.78%] [G loss: 0.384217]\n",
      "epoch:1 step:1408 [D loss: 0.555716, acc.: 71.88%] [G loss: 0.414303]\n",
      "epoch:1 step:1409 [D loss: 0.514705, acc.: 83.59%] [G loss: 0.515218]\n",
      "epoch:1 step:1410 [D loss: 0.702931, acc.: 58.59%] [G loss: 0.302811]\n",
      "epoch:1 step:1411 [D loss: 0.538665, acc.: 75.00%] [G loss: 0.415734]\n",
      "epoch:1 step:1412 [D loss: 0.491204, acc.: 84.38%] [G loss: 0.568193]\n",
      "epoch:1 step:1413 [D loss: 0.587805, acc.: 71.09%] [G loss: 0.409941]\n",
      "epoch:1 step:1414 [D loss: 0.603256, acc.: 71.09%] [G loss: 0.261376]\n",
      "epoch:1 step:1415 [D loss: 0.615989, acc.: 69.53%] [G loss: 0.260591]\n",
      "epoch:1 step:1416 [D loss: 0.592527, acc.: 73.44%] [G loss: 0.269222]\n",
      "epoch:1 step:1417 [D loss: 0.516347, acc.: 85.16%] [G loss: 0.367128]\n",
      "epoch:1 step:1418 [D loss: 0.504126, acc.: 79.69%] [G loss: 0.409904]\n",
      "epoch:1 step:1419 [D loss: 0.576925, acc.: 71.88%] [G loss: 0.244695]\n",
      "epoch:1 step:1420 [D loss: 0.507806, acc.: 82.03%] [G loss: 0.291090]\n",
      "epoch:1 step:1421 [D loss: 0.510251, acc.: 80.47%] [G loss: 0.366546]\n",
      "epoch:1 step:1422 [D loss: 0.525966, acc.: 77.34%] [G loss: 0.310439]\n",
      "epoch:1 step:1423 [D loss: 0.552663, acc.: 77.34%] [G loss: 0.280822]\n",
      "epoch:1 step:1424 [D loss: 0.508551, acc.: 87.50%] [G loss: 0.316313]\n",
      "epoch:1 step:1425 [D loss: 0.458444, acc.: 88.28%] [G loss: 0.391588]\n",
      "epoch:1 step:1426 [D loss: 0.548648, acc.: 73.44%] [G loss: 0.275021]\n",
      "epoch:1 step:1427 [D loss: 0.511003, acc.: 82.03%] [G loss: 0.317149]\n",
      "epoch:1 step:1428 [D loss: 0.484529, acc.: 78.12%] [G loss: 0.410886]\n",
      "epoch:1 step:1429 [D loss: 0.478053, acc.: 86.72%] [G loss: 0.373033]\n",
      "epoch:1 step:1430 [D loss: 0.511060, acc.: 80.47%] [G loss: 0.354188]\n",
      "epoch:1 step:1431 [D loss: 0.459987, acc.: 89.06%] [G loss: 0.376776]\n",
      "epoch:1 step:1432 [D loss: 0.504960, acc.: 85.16%] [G loss: 0.335584]\n",
      "epoch:1 step:1433 [D loss: 0.548098, acc.: 76.56%] [G loss: 0.320537]\n",
      "epoch:1 step:1434 [D loss: 0.486892, acc.: 82.81%] [G loss: 0.364555]\n",
      "epoch:1 step:1435 [D loss: 0.467779, acc.: 82.03%] [G loss: 0.522224]\n",
      "epoch:1 step:1436 [D loss: 0.470301, acc.: 84.38%] [G loss: 0.463587]\n",
      "epoch:1 step:1437 [D loss: 0.585375, acc.: 75.78%] [G loss: 0.208117]\n",
      "epoch:1 step:1438 [D loss: 0.570046, acc.: 73.44%] [G loss: 0.181379]\n",
      "epoch:1 step:1439 [D loss: 0.534235, acc.: 73.44%] [G loss: 0.211587]\n",
      "epoch:1 step:1440 [D loss: 0.432889, acc.: 89.06%] [G loss: 0.355187]\n",
      "epoch:1 step:1441 [D loss: 0.454276, acc.: 85.16%] [G loss: 0.429069]\n",
      "epoch:1 step:1442 [D loss: 0.483661, acc.: 82.81%] [G loss: 0.401442]\n",
      "epoch:1 step:1443 [D loss: 0.482344, acc.: 82.03%] [G loss: 0.375635]\n",
      "epoch:1 step:1444 [D loss: 0.442569, acc.: 84.38%] [G loss: 0.436126]\n",
      "epoch:1 step:1445 [D loss: 0.443743, acc.: 79.69%] [G loss: 0.503758]\n",
      "epoch:1 step:1446 [D loss: 0.481813, acc.: 85.16%] [G loss: 0.426455]\n",
      "epoch:1 step:1447 [D loss: 0.498726, acc.: 81.25%] [G loss: 0.325710]\n",
      "epoch:1 step:1448 [D loss: 0.554971, acc.: 71.88%] [G loss: 0.252455]\n",
      "epoch:1 step:1449 [D loss: 0.544280, acc.: 78.12%] [G loss: 0.240381]\n",
      "epoch:1 step:1450 [D loss: 0.462500, acc.: 83.59%] [G loss: 0.324182]\n",
      "epoch:1 step:1451 [D loss: 0.486921, acc.: 77.34%] [G loss: 0.347829]\n",
      "epoch:1 step:1452 [D loss: 0.453037, acc.: 82.03%] [G loss: 0.444329]\n",
      "epoch:1 step:1453 [D loss: 0.478394, acc.: 86.72%] [G loss: 0.431827]\n",
      "epoch:1 step:1454 [D loss: 0.490291, acc.: 83.59%] [G loss: 0.372143]\n",
      "epoch:1 step:1455 [D loss: 0.473543, acc.: 82.81%] [G loss: 0.353125]\n",
      "epoch:1 step:1456 [D loss: 0.447807, acc.: 83.59%] [G loss: 0.497486]\n",
      "epoch:1 step:1457 [D loss: 0.462076, acc.: 82.81%] [G loss: 0.439193]\n",
      "epoch:1 step:1458 [D loss: 0.462522, acc.: 86.72%] [G loss: 0.413824]\n",
      "epoch:1 step:1459 [D loss: 0.467804, acc.: 82.03%] [G loss: 0.384634]\n",
      "epoch:1 step:1460 [D loss: 0.456860, acc.: 84.38%] [G loss: 0.405918]\n",
      "epoch:1 step:1461 [D loss: 0.474234, acc.: 81.25%] [G loss: 0.390968]\n",
      "epoch:1 step:1462 [D loss: 0.519274, acc.: 78.91%] [G loss: 0.364733]\n",
      "epoch:1 step:1463 [D loss: 0.455564, acc.: 88.28%] [G loss: 0.485182]\n",
      "epoch:1 step:1464 [D loss: 0.541380, acc.: 77.34%] [G loss: 0.281434]\n",
      "epoch:1 step:1465 [D loss: 0.503455, acc.: 83.59%] [G loss: 0.254244]\n",
      "epoch:1 step:1466 [D loss: 0.461529, acc.: 85.16%] [G loss: 0.425763]\n",
      "epoch:1 step:1467 [D loss: 0.439689, acc.: 89.06%] [G loss: 0.426828]\n",
      "epoch:1 step:1468 [D loss: 0.506160, acc.: 82.03%] [G loss: 0.385641]\n",
      "epoch:1 step:1469 [D loss: 0.467878, acc.: 85.16%] [G loss: 0.446581]\n",
      "epoch:1 step:1470 [D loss: 0.453579, acc.: 83.59%] [G loss: 0.472830]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:1 step:1471 [D loss: 0.435341, acc.: 89.06%] [G loss: 0.591017]\n",
      "epoch:1 step:1472 [D loss: 0.555165, acc.: 69.53%] [G loss: 0.364432]\n",
      "epoch:1 step:1473 [D loss: 0.506284, acc.: 81.25%] [G loss: 0.418216]\n",
      "epoch:1 step:1474 [D loss: 0.502668, acc.: 82.81%] [G loss: 0.441597]\n",
      "epoch:1 step:1475 [D loss: 0.520850, acc.: 78.12%] [G loss: 0.423369]\n",
      "epoch:1 step:1476 [D loss: 0.553049, acc.: 76.56%] [G loss: 0.416412]\n",
      "epoch:1 step:1477 [D loss: 0.512365, acc.: 76.56%] [G loss: 0.479349]\n",
      "epoch:1 step:1478 [D loss: 0.492585, acc.: 82.81%] [G loss: 0.483128]\n",
      "epoch:1 step:1479 [D loss: 0.527039, acc.: 75.78%] [G loss: 0.334834]\n",
      "epoch:1 step:1480 [D loss: 0.558729, acc.: 69.53%] [G loss: 0.335030]\n",
      "epoch:1 step:1481 [D loss: 0.487850, acc.: 82.03%] [G loss: 0.436940]\n",
      "epoch:1 step:1482 [D loss: 0.504620, acc.: 79.69%] [G loss: 0.448651]\n",
      "epoch:1 step:1483 [D loss: 0.461851, acc.: 82.81%] [G loss: 0.463108]\n",
      "epoch:1 step:1484 [D loss: 0.450669, acc.: 87.50%] [G loss: 0.537247]\n",
      "epoch:1 step:1485 [D loss: 0.507528, acc.: 81.25%] [G loss: 0.441919]\n",
      "epoch:1 step:1486 [D loss: 0.505647, acc.: 75.00%] [G loss: 0.475913]\n",
      "epoch:1 step:1487 [D loss: 0.526375, acc.: 75.78%] [G loss: 0.371425]\n",
      "epoch:1 step:1488 [D loss: 0.488972, acc.: 85.16%] [G loss: 0.389719]\n",
      "epoch:1 step:1489 [D loss: 0.479272, acc.: 83.59%] [G loss: 0.467989]\n",
      "epoch:1 step:1490 [D loss: 0.544275, acc.: 76.56%] [G loss: 0.328095]\n",
      "epoch:1 step:1491 [D loss: 0.500957, acc.: 82.03%] [G loss: 0.425300]\n",
      "epoch:1 step:1492 [D loss: 0.460981, acc.: 79.69%] [G loss: 0.479014]\n",
      "epoch:1 step:1493 [D loss: 0.476457, acc.: 80.47%] [G loss: 0.573350]\n",
      "epoch:1 step:1494 [D loss: 0.504265, acc.: 77.34%] [G loss: 0.494776]\n",
      "epoch:1 step:1495 [D loss: 0.488741, acc.: 75.00%] [G loss: 0.499720]\n",
      "epoch:1 step:1496 [D loss: 0.559893, acc.: 71.88%] [G loss: 0.392558]\n",
      "epoch:1 step:1497 [D loss: 0.508933, acc.: 79.69%] [G loss: 0.411503]\n",
      "epoch:1 step:1498 [D loss: 0.446527, acc.: 89.06%] [G loss: 0.436789]\n",
      "epoch:1 step:1499 [D loss: 0.544675, acc.: 77.34%] [G loss: 0.349014]\n",
      "epoch:1 step:1500 [D loss: 0.537660, acc.: 75.00%] [G loss: 0.399665]\n",
      "epoch:1 step:1501 [D loss: 0.500629, acc.: 78.91%] [G loss: 0.537418]\n",
      "epoch:1 step:1502 [D loss: 0.495834, acc.: 82.81%] [G loss: 0.464384]\n",
      "epoch:1 step:1503 [D loss: 0.516603, acc.: 78.12%] [G loss: 0.366323]\n",
      "epoch:1 step:1504 [D loss: 0.456752, acc.: 82.03%] [G loss: 0.443317]\n",
      "epoch:1 step:1505 [D loss: 0.520739, acc.: 78.12%] [G loss: 0.424915]\n",
      "epoch:1 step:1506 [D loss: 0.553541, acc.: 78.12%] [G loss: 0.320656]\n",
      "epoch:1 step:1507 [D loss: 0.517692, acc.: 77.34%] [G loss: 0.353987]\n",
      "epoch:1 step:1508 [D loss: 0.484715, acc.: 78.91%] [G loss: 0.438913]\n",
      "epoch:1 step:1509 [D loss: 0.533368, acc.: 75.78%] [G loss: 0.364567]\n",
      "epoch:1 step:1510 [D loss: 0.458059, acc.: 85.16%] [G loss: 0.457325]\n",
      "epoch:1 step:1511 [D loss: 0.439894, acc.: 84.38%] [G loss: 0.555124]\n",
      "epoch:1 step:1512 [D loss: 0.410170, acc.: 89.06%] [G loss: 0.622540]\n",
      "epoch:1 step:1513 [D loss: 0.481237, acc.: 78.12%] [G loss: 0.564998]\n",
      "epoch:1 step:1514 [D loss: 0.495228, acc.: 78.12%] [G loss: 0.441078]\n",
      "epoch:1 step:1515 [D loss: 0.490790, acc.: 75.00%] [G loss: 0.418889]\n",
      "epoch:1 step:1516 [D loss: 0.485320, acc.: 86.72%] [G loss: 0.530736]\n",
      "epoch:1 step:1517 [D loss: 0.535088, acc.: 75.00%] [G loss: 0.391007]\n",
      "epoch:1 step:1518 [D loss: 0.480165, acc.: 78.91%] [G loss: 0.446622]\n",
      "epoch:1 step:1519 [D loss: 0.416755, acc.: 82.81%] [G loss: 0.732549]\n",
      "epoch:1 step:1520 [D loss: 0.525985, acc.: 75.78%] [G loss: 0.545149]\n",
      "epoch:1 step:1521 [D loss: 0.578949, acc.: 69.53%] [G loss: 0.489829]\n",
      "epoch:1 step:1522 [D loss: 0.562732, acc.: 75.00%] [G loss: 0.364351]\n",
      "epoch:1 step:1523 [D loss: 0.580281, acc.: 71.88%] [G loss: 0.360113]\n",
      "epoch:1 step:1524 [D loss: 0.631209, acc.: 67.97%] [G loss: 0.277814]\n",
      "epoch:1 step:1525 [D loss: 0.565141, acc.: 73.44%] [G loss: 0.408734]\n",
      "epoch:1 step:1526 [D loss: 0.540293, acc.: 73.44%] [G loss: 0.411282]\n",
      "epoch:1 step:1527 [D loss: 0.563019, acc.: 73.44%] [G loss: 0.454448]\n",
      "epoch:1 step:1528 [D loss: 0.572219, acc.: 74.22%] [G loss: 0.443984]\n",
      "epoch:1 step:1529 [D loss: 0.474855, acc.: 82.81%] [G loss: 0.541180]\n",
      "epoch:1 step:1530 [D loss: 0.543456, acc.: 76.56%] [G loss: 0.431845]\n",
      "epoch:1 step:1531 [D loss: 0.522300, acc.: 73.44%] [G loss: 0.396583]\n",
      "epoch:1 step:1532 [D loss: 0.518367, acc.: 81.25%] [G loss: 0.382181]\n",
      "epoch:1 step:1533 [D loss: 0.487287, acc.: 78.12%] [G loss: 0.537709]\n",
      "epoch:1 step:1534 [D loss: 0.485516, acc.: 82.81%] [G loss: 0.479287]\n",
      "epoch:1 step:1535 [D loss: 0.464749, acc.: 84.38%] [G loss: 0.619299]\n",
      "epoch:1 step:1536 [D loss: 0.591279, acc.: 71.88%] [G loss: 0.421409]\n",
      "epoch:1 step:1537 [D loss: 0.642197, acc.: 61.72%] [G loss: 0.276485]\n",
      "epoch:1 step:1538 [D loss: 0.535640, acc.: 77.34%] [G loss: 0.301896]\n",
      "epoch:1 step:1539 [D loss: 0.451954, acc.: 88.28%] [G loss: 0.545171]\n",
      "epoch:1 step:1540 [D loss: 0.489655, acc.: 79.69%] [G loss: 0.461936]\n",
      "epoch:1 step:1541 [D loss: 0.555151, acc.: 79.69%] [G loss: 0.370449]\n",
      "epoch:1 step:1542 [D loss: 0.468883, acc.: 80.47%] [G loss: 0.493879]\n",
      "epoch:1 step:1543 [D loss: 0.505850, acc.: 75.00%] [G loss: 0.475711]\n",
      "epoch:1 step:1544 [D loss: 0.533258, acc.: 68.75%] [G loss: 0.441755]\n",
      "epoch:1 step:1545 [D loss: 0.507290, acc.: 78.12%] [G loss: 0.422447]\n",
      "epoch:1 step:1546 [D loss: 0.503785, acc.: 78.12%] [G loss: 0.421730]\n",
      "epoch:1 step:1547 [D loss: 0.557522, acc.: 75.00%] [G loss: 0.324754]\n",
      "epoch:1 step:1548 [D loss: 0.478976, acc.: 78.12%] [G loss: 0.485443]\n",
      "epoch:1 step:1549 [D loss: 0.527234, acc.: 76.56%] [G loss: 0.430453]\n",
      "epoch:1 step:1550 [D loss: 0.475037, acc.: 80.47%] [G loss: 0.530083]\n",
      "epoch:1 step:1551 [D loss: 0.536871, acc.: 75.00%] [G loss: 0.395110]\n",
      "epoch:1 step:1552 [D loss: 0.550972, acc.: 79.69%] [G loss: 0.400764]\n",
      "epoch:1 step:1553 [D loss: 0.551417, acc.: 72.66%] [G loss: 0.438588]\n",
      "epoch:1 step:1554 [D loss: 0.505196, acc.: 75.00%] [G loss: 0.428581]\n",
      "epoch:1 step:1555 [D loss: 0.505549, acc.: 78.12%] [G loss: 0.457124]\n",
      "epoch:1 step:1556 [D loss: 0.458852, acc.: 85.16%] [G loss: 0.490456]\n",
      "epoch:1 step:1557 [D loss: 0.536492, acc.: 75.78%] [G loss: 0.410745]\n",
      "epoch:1 step:1558 [D loss: 0.575032, acc.: 71.88%] [G loss: 0.341248]\n",
      "epoch:1 step:1559 [D loss: 0.607188, acc.: 69.53%] [G loss: 0.302947]\n",
      "epoch:1 step:1560 [D loss: 0.522235, acc.: 72.66%] [G loss: 0.411045]\n",
      "epoch:1 step:1561 [D loss: 0.524116, acc.: 74.22%] [G loss: 0.507156]\n",
      "epoch:1 step:1562 [D loss: 0.579351, acc.: 68.75%] [G loss: 0.360730]\n",
      "epoch:1 step:1563 [D loss: 0.548078, acc.: 71.88%] [G loss: 0.307438]\n",
      "epoch:1 step:1564 [D loss: 0.475426, acc.: 82.03%] [G loss: 0.412211]\n",
      "epoch:1 step:1565 [D loss: 0.468067, acc.: 83.59%] [G loss: 0.445616]\n",
      "epoch:1 step:1566 [D loss: 0.468554, acc.: 84.38%] [G loss: 0.438568]\n",
      "epoch:1 step:1567 [D loss: 0.499233, acc.: 82.03%] [G loss: 0.391926]\n",
      "epoch:1 step:1568 [D loss: 0.479071, acc.: 85.16%] [G loss: 0.389343]\n",
      "epoch:1 step:1569 [D loss: 0.453247, acc.: 85.16%] [G loss: 0.458248]\n",
      "epoch:1 step:1570 [D loss: 0.452622, acc.: 80.47%] [G loss: 0.491295]\n",
      "epoch:1 step:1571 [D loss: 0.452756, acc.: 82.03%] [G loss: 0.451560]\n",
      "epoch:1 step:1572 [D loss: 0.510648, acc.: 81.25%] [G loss: 0.372578]\n",
      "epoch:1 step:1573 [D loss: 0.608122, acc.: 67.97%] [G loss: 0.338771]\n",
      "epoch:1 step:1574 [D loss: 0.491564, acc.: 84.38%] [G loss: 0.318461]\n",
      "epoch:1 step:1575 [D loss: 0.492911, acc.: 81.25%] [G loss: 0.349714]\n",
      "epoch:1 step:1576 [D loss: 0.440814, acc.: 86.72%] [G loss: 0.465876]\n",
      "epoch:1 step:1577 [D loss: 0.479798, acc.: 82.81%] [G loss: 0.390572]\n",
      "epoch:1 step:1578 [D loss: 0.474048, acc.: 84.38%] [G loss: 0.367318]\n",
      "epoch:1 step:1579 [D loss: 0.459813, acc.: 87.50%] [G loss: 0.425673]\n",
      "epoch:1 step:1580 [D loss: 0.510835, acc.: 82.81%] [G loss: 0.335053]\n",
      "epoch:1 step:1581 [D loss: 0.480971, acc.: 86.72%] [G loss: 0.350750]\n",
      "epoch:1 step:1582 [D loss: 0.503073, acc.: 82.03%] [G loss: 0.374690]\n",
      "epoch:1 step:1583 [D loss: 0.523900, acc.: 76.56%] [G loss: 0.403157]\n",
      "epoch:1 step:1584 [D loss: 0.466633, acc.: 84.38%] [G loss: 0.449157]\n",
      "epoch:1 step:1585 [D loss: 0.416753, acc.: 85.16%] [G loss: 0.557162]\n",
      "epoch:1 step:1586 [D loss: 0.434929, acc.: 88.28%] [G loss: 0.544914]\n",
      "epoch:1 step:1587 [D loss: 0.452847, acc.: 83.59%] [G loss: 0.434925]\n",
      "epoch:1 step:1588 [D loss: 0.431690, acc.: 82.81%] [G loss: 0.492382]\n",
      "epoch:1 step:1589 [D loss: 0.548778, acc.: 72.66%] [G loss: 0.344889]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:1 step:1590 [D loss: 0.543793, acc.: 81.25%] [G loss: 0.284924]\n",
      "epoch:1 step:1591 [D loss: 0.446886, acc.: 90.62%] [G loss: 0.352881]\n",
      "epoch:1 step:1592 [D loss: 0.510862, acc.: 79.69%] [G loss: 0.340360]\n",
      "epoch:1 step:1593 [D loss: 0.506852, acc.: 79.69%] [G loss: 0.342409]\n",
      "epoch:1 step:1594 [D loss: 0.442411, acc.: 89.06%] [G loss: 0.414992]\n",
      "epoch:1 step:1595 [D loss: 0.474076, acc.: 81.25%] [G loss: 0.401079]\n",
      "epoch:1 step:1596 [D loss: 0.489022, acc.: 77.34%] [G loss: 0.434721]\n",
      "epoch:1 step:1597 [D loss: 0.459261, acc.: 82.03%] [G loss: 0.444608]\n",
      "epoch:1 step:1598 [D loss: 0.424904, acc.: 85.94%] [G loss: 0.483444]\n",
      "epoch:1 step:1599 [D loss: 0.536504, acc.: 78.12%] [G loss: 0.336372]\n",
      "epoch:1 step:1600 [D loss: 0.478056, acc.: 78.91%] [G loss: 0.400126]\n",
      "epoch:1 step:1601 [D loss: 0.452725, acc.: 83.59%] [G loss: 0.460320]\n",
      "epoch:1 step:1602 [D loss: 0.487450, acc.: 81.25%] [G loss: 0.465899]\n",
      "epoch:1 step:1603 [D loss: 0.436553, acc.: 87.50%] [G loss: 0.416793]\n",
      "epoch:1 step:1604 [D loss: 0.440642, acc.: 88.28%] [G loss: 0.564318]\n",
      "epoch:1 step:1605 [D loss: 0.508540, acc.: 80.47%] [G loss: 0.496525]\n",
      "epoch:1 step:1606 [D loss: 0.441219, acc.: 88.28%] [G loss: 0.473319]\n",
      "epoch:1 step:1607 [D loss: 0.462201, acc.: 85.16%] [G loss: 0.528816]\n",
      "epoch:1 step:1608 [D loss: 0.443076, acc.: 84.38%] [G loss: 0.553687]\n",
      "epoch:1 step:1609 [D loss: 0.578673, acc.: 71.09%] [G loss: 0.437852]\n",
      "epoch:1 step:1610 [D loss: 0.508941, acc.: 78.12%] [G loss: 0.427788]\n",
      "epoch:1 step:1611 [D loss: 0.494010, acc.: 80.47%] [G loss: 0.452023]\n",
      "epoch:1 step:1612 [D loss: 0.440511, acc.: 85.16%] [G loss: 0.519574]\n",
      "epoch:1 step:1613 [D loss: 0.449845, acc.: 84.38%] [G loss: 0.583756]\n",
      "epoch:1 step:1614 [D loss: 0.423418, acc.: 87.50%] [G loss: 0.634311]\n",
      "epoch:1 step:1615 [D loss: 0.436276, acc.: 85.94%] [G loss: 0.572457]\n",
      "epoch:1 step:1616 [D loss: 0.461405, acc.: 84.38%] [G loss: 0.534311]\n",
      "epoch:1 step:1617 [D loss: 0.405475, acc.: 86.72%] [G loss: 0.562751]\n",
      "epoch:1 step:1618 [D loss: 0.455044, acc.: 86.72%] [G loss: 0.532889]\n",
      "epoch:1 step:1619 [D loss: 0.478256, acc.: 74.22%] [G loss: 0.500006]\n",
      "epoch:1 step:1620 [D loss: 0.478000, acc.: 80.47%] [G loss: 0.459904]\n",
      "epoch:1 step:1621 [D loss: 0.460991, acc.: 82.81%] [G loss: 0.443182]\n",
      "epoch:1 step:1622 [D loss: 0.512166, acc.: 77.34%] [G loss: 0.466040]\n",
      "epoch:1 step:1623 [D loss: 0.491039, acc.: 81.25%] [G loss: 0.372840]\n",
      "epoch:1 step:1624 [D loss: 0.437280, acc.: 85.94%] [G loss: 0.425405]\n",
      "epoch:1 step:1625 [D loss: 0.496676, acc.: 80.47%] [G loss: 0.392408]\n",
      "epoch:1 step:1626 [D loss: 0.441098, acc.: 83.59%] [G loss: 0.528489]\n",
      "epoch:1 step:1627 [D loss: 0.456824, acc.: 83.59%] [G loss: 0.527456]\n",
      "epoch:1 step:1628 [D loss: 0.480418, acc.: 79.69%] [G loss: 0.538822]\n",
      "epoch:1 step:1629 [D loss: 0.488164, acc.: 80.47%] [G loss: 0.517506]\n",
      "epoch:1 step:1630 [D loss: 0.424764, acc.: 83.59%] [G loss: 0.588155]\n",
      "epoch:1 step:1631 [D loss: 0.418358, acc.: 82.81%] [G loss: 0.726702]\n",
      "epoch:1 step:1632 [D loss: 0.433099, acc.: 82.03%] [G loss: 0.711527]\n",
      "epoch:1 step:1633 [D loss: 0.498233, acc.: 78.91%] [G loss: 0.553610]\n",
      "epoch:1 step:1634 [D loss: 0.496813, acc.: 80.47%] [G loss: 0.562473]\n",
      "epoch:1 step:1635 [D loss: 0.466853, acc.: 81.25%] [G loss: 0.573162]\n",
      "epoch:1 step:1636 [D loss: 0.490613, acc.: 76.56%] [G loss: 0.494979]\n",
      "epoch:1 step:1637 [D loss: 0.441013, acc.: 84.38%] [G loss: 0.641208]\n",
      "epoch:1 step:1638 [D loss: 0.467606, acc.: 85.94%] [G loss: 0.509565]\n",
      "epoch:1 step:1639 [D loss: 0.489420, acc.: 76.56%] [G loss: 0.427590]\n",
      "epoch:1 step:1640 [D loss: 0.475481, acc.: 82.81%] [G loss: 0.493180]\n",
      "epoch:1 step:1641 [D loss: 0.502230, acc.: 82.81%] [G loss: 0.483510]\n",
      "epoch:1 step:1642 [D loss: 0.467122, acc.: 82.81%] [G loss: 0.505764]\n",
      "epoch:1 step:1643 [D loss: 0.514171, acc.: 77.34%] [G loss: 0.403027]\n",
      "epoch:1 step:1644 [D loss: 0.415368, acc.: 89.06%] [G loss: 0.596832]\n",
      "epoch:1 step:1645 [D loss: 0.387472, acc.: 92.19%] [G loss: 0.643872]\n",
      "epoch:1 step:1646 [D loss: 0.465159, acc.: 81.25%] [G loss: 0.599228]\n",
      "epoch:1 step:1647 [D loss: 0.620091, acc.: 69.53%] [G loss: 0.357190]\n",
      "epoch:1 step:1648 [D loss: 0.550576, acc.: 71.09%] [G loss: 0.358716]\n",
      "epoch:1 step:1649 [D loss: 0.455836, acc.: 81.25%] [G loss: 0.433123]\n",
      "epoch:1 step:1650 [D loss: 0.457157, acc.: 83.59%] [G loss: 0.549147]\n",
      "epoch:1 step:1651 [D loss: 0.481871, acc.: 78.12%] [G loss: 0.515692]\n",
      "epoch:1 step:1652 [D loss: 0.481679, acc.: 80.47%] [G loss: 0.481695]\n",
      "epoch:1 step:1653 [D loss: 0.548334, acc.: 71.88%] [G loss: 0.339390]\n",
      "epoch:1 step:1654 [D loss: 0.502296, acc.: 78.91%] [G loss: 0.367889]\n",
      "epoch:1 step:1655 [D loss: 0.547058, acc.: 75.78%] [G loss: 0.434556]\n",
      "epoch:1 step:1656 [D loss: 0.500935, acc.: 79.69%] [G loss: 0.603886]\n",
      "epoch:1 step:1657 [D loss: 0.530859, acc.: 73.44%] [G loss: 0.493789]\n",
      "epoch:1 step:1658 [D loss: 0.547089, acc.: 75.00%] [G loss: 0.363347]\n",
      "epoch:1 step:1659 [D loss: 0.499321, acc.: 78.12%] [G loss: 0.411735]\n",
      "epoch:1 step:1660 [D loss: 0.554707, acc.: 75.00%] [G loss: 0.328508]\n",
      "epoch:1 step:1661 [D loss: 0.513968, acc.: 75.78%] [G loss: 0.327689]\n",
      "epoch:1 step:1662 [D loss: 0.506719, acc.: 77.34%] [G loss: 0.439241]\n",
      "epoch:1 step:1663 [D loss: 0.464212, acc.: 82.81%] [G loss: 0.483826]\n",
      "epoch:1 step:1664 [D loss: 0.518939, acc.: 76.56%] [G loss: 0.403354]\n",
      "epoch:1 step:1665 [D loss: 0.498843, acc.: 80.47%] [G loss: 0.486595]\n",
      "epoch:1 step:1666 [D loss: 0.453046, acc.: 82.81%] [G loss: 0.499045]\n",
      "epoch:1 step:1667 [D loss: 0.503448, acc.: 79.69%] [G loss: 0.464563]\n",
      "epoch:1 step:1668 [D loss: 0.476648, acc.: 87.50%] [G loss: 0.472365]\n",
      "epoch:1 step:1669 [D loss: 0.449635, acc.: 82.81%] [G loss: 0.584324]\n",
      "epoch:1 step:1670 [D loss: 0.443662, acc.: 89.06%] [G loss: 0.555288]\n",
      "epoch:1 step:1671 [D loss: 0.445636, acc.: 89.06%] [G loss: 0.543109]\n",
      "epoch:1 step:1672 [D loss: 0.548692, acc.: 74.22%] [G loss: 0.443537]\n",
      "epoch:1 step:1673 [D loss: 0.479715, acc.: 78.91%] [G loss: 0.482292]\n",
      "epoch:1 step:1674 [D loss: 0.452809, acc.: 87.50%] [G loss: 0.511792]\n",
      "epoch:1 step:1675 [D loss: 0.484224, acc.: 77.34%] [G loss: 0.577217]\n",
      "epoch:1 step:1676 [D loss: 0.541751, acc.: 74.22%] [G loss: 0.463419]\n",
      "epoch:1 step:1677 [D loss: 0.539428, acc.: 76.56%] [G loss: 0.325038]\n",
      "epoch:1 step:1678 [D loss: 0.461662, acc.: 83.59%] [G loss: 0.436092]\n",
      "epoch:1 step:1679 [D loss: 0.494183, acc.: 80.47%] [G loss: 0.403261]\n",
      "epoch:1 step:1680 [D loss: 0.482791, acc.: 82.03%] [G loss: 0.425902]\n",
      "epoch:1 step:1681 [D loss: 0.509622, acc.: 75.00%] [G loss: 0.480425]\n",
      "epoch:1 step:1682 [D loss: 0.474950, acc.: 83.59%] [G loss: 0.424018]\n",
      "epoch:1 step:1683 [D loss: 0.422347, acc.: 88.28%] [G loss: 0.556931]\n",
      "epoch:1 step:1684 [D loss: 0.392249, acc.: 89.84%] [G loss: 0.695540]\n",
      "epoch:1 step:1685 [D loss: 0.442210, acc.: 82.81%] [G loss: 0.605441]\n",
      "epoch:1 step:1686 [D loss: 0.531584, acc.: 75.78%] [G loss: 0.465912]\n",
      "epoch:1 step:1687 [D loss: 0.496737, acc.: 79.69%] [G loss: 0.461749]\n",
      "epoch:1 step:1688 [D loss: 0.435116, acc.: 85.94%] [G loss: 0.485006]\n",
      "epoch:1 step:1689 [D loss: 0.463114, acc.: 83.59%] [G loss: 0.528329]\n",
      "epoch:1 step:1690 [D loss: 0.425108, acc.: 88.28%] [G loss: 0.589888]\n",
      "epoch:1 step:1691 [D loss: 0.454037, acc.: 84.38%] [G loss: 0.570829]\n",
      "epoch:1 step:1692 [D loss: 0.498748, acc.: 79.69%] [G loss: 0.462959]\n",
      "epoch:1 step:1693 [D loss: 0.485812, acc.: 82.81%] [G loss: 0.455150]\n",
      "epoch:1 step:1694 [D loss: 0.466621, acc.: 82.03%] [G loss: 0.518716]\n",
      "epoch:1 step:1695 [D loss: 0.543458, acc.: 73.44%] [G loss: 0.469192]\n",
      "epoch:1 step:1696 [D loss: 0.521750, acc.: 76.56%] [G loss: 0.388915]\n",
      "epoch:1 step:1697 [D loss: 0.527519, acc.: 74.22%] [G loss: 0.453766]\n",
      "epoch:1 step:1698 [D loss: 0.460513, acc.: 79.69%] [G loss: 0.586707]\n",
      "epoch:1 step:1699 [D loss: 0.505227, acc.: 75.00%] [G loss: 0.519038]\n",
      "epoch:1 step:1700 [D loss: 0.452032, acc.: 82.03%] [G loss: 0.608410]\n",
      "epoch:1 step:1701 [D loss: 0.483796, acc.: 80.47%] [G loss: 0.564608]\n",
      "epoch:1 step:1702 [D loss: 0.591714, acc.: 70.31%] [G loss: 0.339760]\n",
      "epoch:1 step:1703 [D loss: 0.578895, acc.: 71.09%] [G loss: 0.343103]\n",
      "epoch:1 step:1704 [D loss: 0.506299, acc.: 80.47%] [G loss: 0.426171]\n",
      "epoch:1 step:1705 [D loss: 0.476578, acc.: 81.25%] [G loss: 0.551109]\n",
      "epoch:1 step:1706 [D loss: 0.485510, acc.: 81.25%] [G loss: 0.536721]\n",
      "epoch:1 step:1707 [D loss: 0.517973, acc.: 76.56%] [G loss: 0.529703]\n",
      "epoch:1 step:1708 [D loss: 0.454671, acc.: 85.16%] [G loss: 0.640283]\n",
      "epoch:1 step:1709 [D loss: 0.445075, acc.: 85.16%] [G loss: 0.640350]\n",
      "epoch:1 step:1710 [D loss: 0.464736, acc.: 83.59%] [G loss: 0.474345]\n",
      "epoch:1 step:1711 [D loss: 0.554642, acc.: 72.66%] [G loss: 0.360055]\n",
      "epoch:1 step:1712 [D loss: 0.478708, acc.: 79.69%] [G loss: 0.450126]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:1 step:1713 [D loss: 0.492024, acc.: 78.91%] [G loss: 0.544372]\n",
      "epoch:1 step:1714 [D loss: 0.497759, acc.: 76.56%] [G loss: 0.560655]\n",
      "epoch:1 step:1715 [D loss: 0.483417, acc.: 80.47%] [G loss: 0.548616]\n",
      "epoch:1 step:1716 [D loss: 0.511551, acc.: 83.59%] [G loss: 0.477756]\n",
      "epoch:1 step:1717 [D loss: 0.503748, acc.: 75.78%] [G loss: 0.558077]\n",
      "epoch:1 step:1718 [D loss: 0.492605, acc.: 80.47%] [G loss: 0.670818]\n",
      "epoch:1 step:1719 [D loss: 0.476308, acc.: 80.47%] [G loss: 0.619889]\n",
      "epoch:1 step:1720 [D loss: 0.537142, acc.: 71.88%] [G loss: 0.460454]\n",
      "epoch:1 step:1721 [D loss: 0.500442, acc.: 77.34%] [G loss: 0.364578]\n",
      "epoch:1 step:1722 [D loss: 0.504083, acc.: 77.34%] [G loss: 0.477485]\n",
      "epoch:1 step:1723 [D loss: 0.428772, acc.: 85.16%] [G loss: 0.548534]\n",
      "epoch:1 step:1724 [D loss: 0.573818, acc.: 78.12%] [G loss: 0.401893]\n",
      "epoch:1 step:1725 [D loss: 0.549147, acc.: 78.12%] [G loss: 0.440464]\n",
      "epoch:1 step:1726 [D loss: 0.485871, acc.: 80.47%] [G loss: 0.416921]\n",
      "epoch:1 step:1727 [D loss: 0.447282, acc.: 87.50%] [G loss: 0.499679]\n",
      "epoch:1 step:1728 [D loss: 0.573347, acc.: 67.19%] [G loss: 0.473152]\n",
      "epoch:1 step:1729 [D loss: 0.478304, acc.: 81.25%] [G loss: 0.504905]\n",
      "epoch:1 step:1730 [D loss: 0.519971, acc.: 81.25%] [G loss: 0.485650]\n",
      "epoch:1 step:1731 [D loss: 0.597396, acc.: 67.97%] [G loss: 0.301519]\n",
      "epoch:1 step:1732 [D loss: 0.494590, acc.: 74.22%] [G loss: 0.387726]\n",
      "epoch:1 step:1733 [D loss: 0.404217, acc.: 89.84%] [G loss: 0.666060]\n",
      "epoch:1 step:1734 [D loss: 0.542587, acc.: 71.09%] [G loss: 0.460173]\n",
      "epoch:1 step:1735 [D loss: 0.447447, acc.: 82.81%] [G loss: 0.555971]\n",
      "epoch:1 step:1736 [D loss: 0.508821, acc.: 81.25%] [G loss: 0.502148]\n",
      "epoch:1 step:1737 [D loss: 0.584817, acc.: 71.09%] [G loss: 0.418888]\n",
      "epoch:1 step:1738 [D loss: 0.479081, acc.: 78.12%] [G loss: 0.545484]\n",
      "epoch:1 step:1739 [D loss: 0.432740, acc.: 82.03%] [G loss: 0.582002]\n",
      "epoch:1 step:1740 [D loss: 0.469093, acc.: 78.12%] [G loss: 0.645025]\n",
      "epoch:1 step:1741 [D loss: 0.454317, acc.: 87.50%] [G loss: 0.620294]\n",
      "epoch:1 step:1742 [D loss: 0.485388, acc.: 77.34%] [G loss: 0.553055]\n",
      "epoch:1 step:1743 [D loss: 0.475078, acc.: 80.47%] [G loss: 0.545601]\n",
      "epoch:1 step:1744 [D loss: 0.456199, acc.: 81.25%] [G loss: 0.551094]\n",
      "epoch:1 step:1745 [D loss: 0.545188, acc.: 76.56%] [G loss: 0.420034]\n",
      "epoch:1 step:1746 [D loss: 0.513777, acc.: 75.78%] [G loss: 0.485236]\n",
      "epoch:1 step:1747 [D loss: 0.488174, acc.: 78.12%] [G loss: 0.531928]\n",
      "epoch:1 step:1748 [D loss: 0.524720, acc.: 75.00%] [G loss: 0.553593]\n",
      "epoch:1 step:1749 [D loss: 0.474814, acc.: 87.50%] [G loss: 0.491190]\n",
      "epoch:1 step:1750 [D loss: 0.470436, acc.: 81.25%] [G loss: 0.494721]\n",
      "epoch:1 step:1751 [D loss: 0.450420, acc.: 81.25%] [G loss: 0.641033]\n",
      "epoch:1 step:1752 [D loss: 0.503412, acc.: 76.56%] [G loss: 0.647407]\n",
      "epoch:1 step:1753 [D loss: 0.466568, acc.: 82.81%] [G loss: 0.634449]\n",
      "epoch:1 step:1754 [D loss: 0.491230, acc.: 82.03%] [G loss: 0.486835]\n",
      "epoch:1 step:1755 [D loss: 0.502984, acc.: 75.78%] [G loss: 0.497785]\n",
      "epoch:1 step:1756 [D loss: 0.482630, acc.: 79.69%] [G loss: 0.537375]\n",
      "epoch:1 step:1757 [D loss: 0.533589, acc.: 81.25%] [G loss: 0.541094]\n",
      "epoch:1 step:1758 [D loss: 0.493690, acc.: 80.47%] [G loss: 0.479758]\n",
      "epoch:1 step:1759 [D loss: 0.390392, acc.: 89.84%] [G loss: 0.611534]\n",
      "epoch:1 step:1760 [D loss: 0.480702, acc.: 79.69%] [G loss: 0.529615]\n",
      "epoch:1 step:1761 [D loss: 0.564104, acc.: 68.75%] [G loss: 0.591882]\n",
      "epoch:1 step:1762 [D loss: 0.436669, acc.: 85.16%] [G loss: 0.394199]\n",
      "epoch:1 step:1763 [D loss: 0.497606, acc.: 76.56%] [G loss: 0.509599]\n",
      "epoch:1 step:1764 [D loss: 0.530016, acc.: 74.22%] [G loss: 0.456918]\n",
      "epoch:1 step:1765 [D loss: 0.523377, acc.: 77.34%] [G loss: 0.384798]\n",
      "epoch:1 step:1766 [D loss: 0.474110, acc.: 79.69%] [G loss: 0.516023]\n",
      "epoch:1 step:1767 [D loss: 0.473807, acc.: 78.91%] [G loss: 0.628179]\n",
      "epoch:1 step:1768 [D loss: 0.483223, acc.: 81.25%] [G loss: 0.644603]\n",
      "epoch:1 step:1769 [D loss: 0.473103, acc.: 82.03%] [G loss: 0.473365]\n",
      "epoch:1 step:1770 [D loss: 0.439898, acc.: 84.38%] [G loss: 0.548177]\n",
      "epoch:1 step:1771 [D loss: 0.496845, acc.: 78.12%] [G loss: 0.449358]\n",
      "epoch:1 step:1772 [D loss: 0.475671, acc.: 82.03%] [G loss: 0.541380]\n",
      "epoch:1 step:1773 [D loss: 0.511677, acc.: 80.47%] [G loss: 0.438241]\n",
      "epoch:1 step:1774 [D loss: 0.483579, acc.: 82.81%] [G loss: 0.418057]\n",
      "epoch:1 step:1775 [D loss: 0.497451, acc.: 75.00%] [G loss: 0.434977]\n",
      "epoch:1 step:1776 [D loss: 0.492042, acc.: 78.12%] [G loss: 0.458601]\n",
      "epoch:1 step:1777 [D loss: 0.492904, acc.: 80.47%] [G loss: 0.456819]\n",
      "epoch:1 step:1778 [D loss: 0.438795, acc.: 85.16%] [G loss: 0.532871]\n",
      "epoch:1 step:1779 [D loss: 0.470179, acc.: 85.16%] [G loss: 0.590612]\n",
      "epoch:1 step:1780 [D loss: 0.459766, acc.: 85.16%] [G loss: 0.597913]\n",
      "epoch:1 step:1781 [D loss: 0.541693, acc.: 74.22%] [G loss: 0.443628]\n",
      "epoch:1 step:1782 [D loss: 0.477141, acc.: 77.34%] [G loss: 0.456528]\n",
      "epoch:1 step:1783 [D loss: 0.467907, acc.: 82.81%] [G loss: 0.500181]\n",
      "epoch:1 step:1784 [D loss: 0.501735, acc.: 79.69%] [G loss: 0.375656]\n",
      "epoch:1 step:1785 [D loss: 0.440667, acc.: 89.06%] [G loss: 0.420155]\n",
      "epoch:1 step:1786 [D loss: 0.497402, acc.: 78.91%] [G loss: 0.485768]\n",
      "epoch:1 step:1787 [D loss: 0.485565, acc.: 80.47%] [G loss: 0.467270]\n",
      "epoch:1 step:1788 [D loss: 0.463150, acc.: 82.81%] [G loss: 0.433765]\n",
      "epoch:1 step:1789 [D loss: 0.420987, acc.: 85.94%] [G loss: 0.580875]\n",
      "epoch:1 step:1790 [D loss: 0.445816, acc.: 81.25%] [G loss: 0.569973]\n",
      "epoch:1 step:1791 [D loss: 0.374345, acc.: 89.06%] [G loss: 0.688205]\n",
      "epoch:1 step:1792 [D loss: 0.423166, acc.: 82.81%] [G loss: 0.686355]\n",
      "epoch:1 step:1793 [D loss: 0.460474, acc.: 87.50%] [G loss: 0.545165]\n",
      "epoch:1 step:1794 [D loss: 0.394221, acc.: 85.94%] [G loss: 0.563515]\n",
      "epoch:1 step:1795 [D loss: 0.624062, acc.: 64.84%] [G loss: 0.472291]\n",
      "epoch:1 step:1796 [D loss: 0.462041, acc.: 80.47%] [G loss: 0.523808]\n",
      "epoch:1 step:1797 [D loss: 0.450401, acc.: 83.59%] [G loss: 0.686940]\n",
      "epoch:1 step:1798 [D loss: 0.541450, acc.: 73.44%] [G loss: 0.459360]\n",
      "epoch:1 step:1799 [D loss: 0.436092, acc.: 85.16%] [G loss: 0.493264]\n",
      "epoch:1 step:1800 [D loss: 0.425501, acc.: 85.16%] [G loss: 0.656204]\n",
      "epoch:1 step:1801 [D loss: 0.474996, acc.: 78.12%] [G loss: 0.627196]\n",
      "epoch:1 step:1802 [D loss: 0.514510, acc.: 78.12%] [G loss: 0.520540]\n",
      "epoch:1 step:1803 [D loss: 0.401333, acc.: 89.84%] [G loss: 0.677658]\n",
      "epoch:1 step:1804 [D loss: 0.532243, acc.: 78.12%] [G loss: 0.498231]\n",
      "epoch:1 step:1805 [D loss: 0.541329, acc.: 72.66%] [G loss: 0.401090]\n",
      "epoch:1 step:1806 [D loss: 0.493536, acc.: 77.34%] [G loss: 0.405651]\n",
      "epoch:1 step:1807 [D loss: 0.442865, acc.: 81.25%] [G loss: 0.585086]\n",
      "epoch:1 step:1808 [D loss: 0.413110, acc.: 86.72%] [G loss: 0.668219]\n",
      "epoch:1 step:1809 [D loss: 0.434625, acc.: 82.81%] [G loss: 0.629855]\n",
      "epoch:1 step:1810 [D loss: 0.464442, acc.: 78.91%] [G loss: 0.589322]\n",
      "epoch:1 step:1811 [D loss: 0.461373, acc.: 82.03%] [G loss: 0.696682]\n",
      "epoch:1 step:1812 [D loss: 0.417878, acc.: 85.94%] [G loss: 0.686515]\n",
      "epoch:1 step:1813 [D loss: 0.474558, acc.: 88.28%] [G loss: 0.571877]\n",
      "epoch:1 step:1814 [D loss: 0.487953, acc.: 79.69%] [G loss: 0.493767]\n",
      "epoch:1 step:1815 [D loss: 0.519236, acc.: 76.56%] [G loss: 0.450141]\n",
      "epoch:1 step:1816 [D loss: 0.531470, acc.: 76.56%] [G loss: 0.450875]\n",
      "epoch:1 step:1817 [D loss: 0.591423, acc.: 71.88%] [G loss: 0.451021]\n",
      "epoch:1 step:1818 [D loss: 0.492176, acc.: 82.03%] [G loss: 0.589282]\n",
      "epoch:1 step:1819 [D loss: 0.494725, acc.: 79.69%] [G loss: 0.609728]\n",
      "epoch:1 step:1820 [D loss: 0.508012, acc.: 76.56%] [G loss: 0.552531]\n",
      "epoch:1 step:1821 [D loss: 0.488505, acc.: 80.47%] [G loss: 0.483191]\n",
      "epoch:1 step:1822 [D loss: 0.434403, acc.: 86.72%] [G loss: 0.613571]\n",
      "epoch:1 step:1823 [D loss: 0.431314, acc.: 86.72%] [G loss: 0.694874]\n",
      "epoch:1 step:1824 [D loss: 0.427987, acc.: 85.16%] [G loss: 0.726131]\n",
      "epoch:1 step:1825 [D loss: 0.452529, acc.: 80.47%] [G loss: 0.651821]\n",
      "epoch:1 step:1826 [D loss: 0.476706, acc.: 78.91%] [G loss: 0.727185]\n",
      "epoch:1 step:1827 [D loss: 0.435788, acc.: 83.59%] [G loss: 0.713898]\n",
      "epoch:1 step:1828 [D loss: 0.516335, acc.: 76.56%] [G loss: 0.524706]\n",
      "epoch:1 step:1829 [D loss: 0.611302, acc.: 70.31%] [G loss: 0.387476]\n",
      "epoch:1 step:1830 [D loss: 0.517979, acc.: 71.88%] [G loss: 0.522009]\n",
      "epoch:1 step:1831 [D loss: 0.489485, acc.: 77.34%] [G loss: 0.542365]\n",
      "epoch:1 step:1832 [D loss: 0.487739, acc.: 78.12%] [G loss: 0.603133]\n",
      "epoch:1 step:1833 [D loss: 0.474455, acc.: 78.12%] [G loss: 0.692953]\n",
      "epoch:1 step:1834 [D loss: 0.451085, acc.: 85.94%] [G loss: 0.655658]\n",
      "epoch:1 step:1835 [D loss: 0.459399, acc.: 80.47%] [G loss: 0.603959]\n",
      "epoch:1 step:1836 [D loss: 0.474328, acc.: 82.03%] [G loss: 0.601418]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:1 step:1837 [D loss: 0.457269, acc.: 82.81%] [G loss: 0.656736]\n",
      "epoch:1 step:1838 [D loss: 0.485314, acc.: 79.69%] [G loss: 0.557320]\n",
      "epoch:1 step:1839 [D loss: 0.531610, acc.: 78.12%] [G loss: 0.396590]\n",
      "epoch:1 step:1840 [D loss: 0.534922, acc.: 75.00%] [G loss: 0.457610]\n",
      "epoch:1 step:1841 [D loss: 0.456148, acc.: 82.81%] [G loss: 0.585184]\n",
      "epoch:1 step:1842 [D loss: 0.552944, acc.: 76.56%] [G loss: 0.495389]\n",
      "epoch:1 step:1843 [D loss: 0.515490, acc.: 75.00%] [G loss: 0.496651]\n",
      "epoch:1 step:1844 [D loss: 0.495549, acc.: 80.47%] [G loss: 0.498743]\n",
      "epoch:1 step:1845 [D loss: 0.464848, acc.: 79.69%] [G loss: 0.547644]\n",
      "epoch:1 step:1846 [D loss: 0.456621, acc.: 83.59%] [G loss: 0.615131]\n",
      "epoch:1 step:1847 [D loss: 0.397410, acc.: 90.62%] [G loss: 0.630649]\n",
      "epoch:1 step:1848 [D loss: 0.435841, acc.: 85.94%] [G loss: 0.666941]\n",
      "epoch:1 step:1849 [D loss: 0.451932, acc.: 79.69%] [G loss: 0.676913]\n",
      "epoch:1 step:1850 [D loss: 0.539377, acc.: 71.88%] [G loss: 0.500939]\n",
      "epoch:1 step:1851 [D loss: 0.447251, acc.: 81.25%] [G loss: 0.577498]\n",
      "epoch:1 step:1852 [D loss: 0.546944, acc.: 73.44%] [G loss: 0.504041]\n",
      "epoch:1 step:1853 [D loss: 0.495774, acc.: 79.69%] [G loss: 0.521962]\n",
      "epoch:1 step:1854 [D loss: 0.501663, acc.: 74.22%] [G loss: 0.427899]\n",
      "epoch:1 step:1855 [D loss: 0.392411, acc.: 91.41%] [G loss: 0.570390]\n",
      "epoch:1 step:1856 [D loss: 0.482123, acc.: 77.34%] [G loss: 0.556409]\n",
      "epoch:1 step:1857 [D loss: 0.620837, acc.: 63.28%] [G loss: 0.400292]\n",
      "epoch:1 step:1858 [D loss: 0.368778, acc.: 92.19%] [G loss: 0.712968]\n",
      "epoch:1 step:1859 [D loss: 0.476935, acc.: 80.47%] [G loss: 0.503760]\n",
      "epoch:1 step:1860 [D loss: 0.418902, acc.: 82.81%] [G loss: 0.544602]\n",
      "epoch:1 step:1861 [D loss: 0.418444, acc.: 84.38%] [G loss: 0.669819]\n",
      "epoch:1 step:1862 [D loss: 0.400482, acc.: 87.50%] [G loss: 0.744009]\n",
      "epoch:1 step:1863 [D loss: 0.367335, acc.: 89.06%] [G loss: 1.061508]\n",
      "epoch:1 step:1864 [D loss: 0.479435, acc.: 74.22%] [G loss: 0.967734]\n",
      "epoch:1 step:1865 [D loss: 0.833803, acc.: 56.25%] [G loss: 0.497197]\n",
      "epoch:1 step:1866 [D loss: 0.499451, acc.: 78.12%] [G loss: 0.621669]\n",
      "epoch:1 step:1867 [D loss: 0.353603, acc.: 89.84%] [G loss: 0.927060]\n",
      "epoch:1 step:1868 [D loss: 0.486128, acc.: 75.78%] [G loss: 0.657657]\n",
      "epoch:1 step:1869 [D loss: 0.521867, acc.: 75.00%] [G loss: 0.501458]\n",
      "epoch:1 step:1870 [D loss: 0.449681, acc.: 82.03%] [G loss: 0.526716]\n",
      "epoch:1 step:1871 [D loss: 0.443416, acc.: 81.25%] [G loss: 0.668922]\n",
      "epoch:1 step:1872 [D loss: 0.380146, acc.: 85.94%] [G loss: 0.693844]\n",
      "epoch:1 step:1873 [D loss: 0.327554, acc.: 87.50%] [G loss: 0.912648]\n",
      "epoch:1 step:1874 [D loss: 0.546284, acc.: 72.66%] [G loss: 0.757065]\n",
      "epoch:2 step:1875 [D loss: 0.497317, acc.: 74.22%] [G loss: 0.689741]\n",
      "epoch:2 step:1876 [D loss: 0.459211, acc.: 79.69%] [G loss: 0.744904]\n",
      "epoch:2 step:1877 [D loss: 0.537202, acc.: 75.78%] [G loss: 0.580033]\n",
      "epoch:2 step:1878 [D loss: 0.454064, acc.: 82.81%] [G loss: 0.678507]\n",
      "epoch:2 step:1879 [D loss: 0.451213, acc.: 85.16%] [G loss: 0.594351]\n",
      "epoch:2 step:1880 [D loss: 0.449933, acc.: 81.25%] [G loss: 0.551232]\n",
      "epoch:2 step:1881 [D loss: 0.456778, acc.: 81.25%] [G loss: 0.659945]\n",
      "epoch:2 step:1882 [D loss: 0.544168, acc.: 68.75%] [G loss: 0.588326]\n",
      "epoch:2 step:1883 [D loss: 0.514904, acc.: 81.25%] [G loss: 0.541279]\n",
      "epoch:2 step:1884 [D loss: 0.495862, acc.: 78.91%] [G loss: 0.517707]\n",
      "epoch:2 step:1885 [D loss: 0.490752, acc.: 75.78%] [G loss: 0.505740]\n",
      "epoch:2 step:1886 [D loss: 0.482512, acc.: 79.69%] [G loss: 0.532842]\n",
      "epoch:2 step:1887 [D loss: 0.459345, acc.: 82.03%] [G loss: 0.624791]\n",
      "epoch:2 step:1888 [D loss: 0.518684, acc.: 77.34%] [G loss: 0.522100]\n",
      "epoch:2 step:1889 [D loss: 0.473325, acc.: 82.81%] [G loss: 0.594193]\n",
      "epoch:2 step:1890 [D loss: 0.505318, acc.: 77.34%] [G loss: 0.526891]\n",
      "epoch:2 step:1891 [D loss: 0.517458, acc.: 78.91%] [G loss: 0.513640]\n",
      "epoch:2 step:1892 [D loss: 0.461999, acc.: 81.25%] [G loss: 0.541580]\n",
      "epoch:2 step:1893 [D loss: 0.455280, acc.: 82.03%] [G loss: 0.470799]\n",
      "epoch:2 step:1894 [D loss: 0.522398, acc.: 76.56%] [G loss: 0.454401]\n",
      "epoch:2 step:1895 [D loss: 0.421218, acc.: 86.72%] [G loss: 0.558260]\n",
      "epoch:2 step:1896 [D loss: 0.433982, acc.: 83.59%] [G loss: 0.691838]\n",
      "epoch:2 step:1897 [D loss: 0.449497, acc.: 87.50%] [G loss: 0.655839]\n",
      "epoch:2 step:1898 [D loss: 0.503416, acc.: 76.56%] [G loss: 0.623058]\n",
      "epoch:2 step:1899 [D loss: 0.465763, acc.: 85.16%] [G loss: 0.548730]\n",
      "epoch:2 step:1900 [D loss: 0.485898, acc.: 77.34%] [G loss: 0.548962]\n",
      "epoch:2 step:1901 [D loss: 0.403973, acc.: 88.28%] [G loss: 0.687255]\n",
      "epoch:2 step:1902 [D loss: 0.461773, acc.: 82.03%] [G loss: 0.570777]\n",
      "epoch:2 step:1903 [D loss: 0.461046, acc.: 85.94%] [G loss: 0.519691]\n",
      "epoch:2 step:1904 [D loss: 0.490901, acc.: 82.81%] [G loss: 0.419637]\n",
      "epoch:2 step:1905 [D loss: 0.470836, acc.: 80.47%] [G loss: 0.505952]\n",
      "epoch:2 step:1906 [D loss: 0.444263, acc.: 82.03%] [G loss: 0.544282]\n",
      "epoch:2 step:1907 [D loss: 0.451541, acc.: 78.91%] [G loss: 0.578317]\n",
      "epoch:2 step:1908 [D loss: 0.425776, acc.: 86.72%] [G loss: 0.642797]\n",
      "epoch:2 step:1909 [D loss: 0.426491, acc.: 88.28%] [G loss: 0.654412]\n",
      "epoch:2 step:1910 [D loss: 0.417395, acc.: 85.16%] [G loss: 0.668385]\n",
      "epoch:2 step:1911 [D loss: 0.492218, acc.: 80.47%] [G loss: 0.563792]\n",
      "epoch:2 step:1912 [D loss: 0.549385, acc.: 69.53%] [G loss: 0.613718]\n",
      "epoch:2 step:1913 [D loss: 0.444410, acc.: 84.38%] [G loss: 0.598031]\n",
      "epoch:2 step:1914 [D loss: 0.440482, acc.: 83.59%] [G loss: 0.729960]\n",
      "epoch:2 step:1915 [D loss: 0.496936, acc.: 74.22%] [G loss: 0.595695]\n",
      "epoch:2 step:1916 [D loss: 0.449377, acc.: 81.25%] [G loss: 0.613257]\n",
      "epoch:2 step:1917 [D loss: 0.471780, acc.: 77.34%] [G loss: 0.624224]\n",
      "epoch:2 step:1918 [D loss: 0.518198, acc.: 75.00%] [G loss: 0.491320]\n",
      "epoch:2 step:1919 [D loss: 0.421605, acc.: 87.50%] [G loss: 0.523038]\n",
      "epoch:2 step:1920 [D loss: 0.457112, acc.: 80.47%] [G loss: 0.543782]\n",
      "epoch:2 step:1921 [D loss: 0.490967, acc.: 80.47%] [G loss: 0.503045]\n",
      "epoch:2 step:1922 [D loss: 0.486045, acc.: 80.47%] [G loss: 0.518827]\n",
      "epoch:2 step:1923 [D loss: 0.458670, acc.: 81.25%] [G loss: 0.593285]\n",
      "epoch:2 step:1924 [D loss: 0.494089, acc.: 81.25%] [G loss: 0.493320]\n",
      "epoch:2 step:1925 [D loss: 0.434225, acc.: 85.94%] [G loss: 0.451630]\n",
      "epoch:2 step:1926 [D loss: 0.489704, acc.: 80.47%] [G loss: 0.607676]\n",
      "epoch:2 step:1927 [D loss: 0.464205, acc.: 78.12%] [G loss: 0.719353]\n",
      "epoch:2 step:1928 [D loss: 0.531060, acc.: 73.44%] [G loss: 0.671379]\n",
      "epoch:2 step:1929 [D loss: 0.451849, acc.: 82.81%] [G loss: 0.660451]\n",
      "epoch:2 step:1930 [D loss: 0.496089, acc.: 82.03%] [G loss: 0.406782]\n",
      "epoch:2 step:1931 [D loss: 0.443839, acc.: 85.16%] [G loss: 0.615233]\n",
      "epoch:2 step:1932 [D loss: 0.486525, acc.: 79.69%] [G loss: 0.519091]\n",
      "epoch:2 step:1933 [D loss: 0.421140, acc.: 83.59%] [G loss: 0.636269]\n",
      "epoch:2 step:1934 [D loss: 0.471746, acc.: 81.25%] [G loss: 0.622308]\n",
      "epoch:2 step:1935 [D loss: 0.437181, acc.: 83.59%] [G loss: 0.596681]\n",
      "epoch:2 step:1936 [D loss: 0.474515, acc.: 78.12%] [G loss: 0.536102]\n",
      "epoch:2 step:1937 [D loss: 0.457253, acc.: 81.25%] [G loss: 0.585015]\n",
      "epoch:2 step:1938 [D loss: 0.520613, acc.: 77.34%] [G loss: 0.491161]\n",
      "epoch:2 step:1939 [D loss: 0.509179, acc.: 77.34%] [G loss: 0.476993]\n",
      "epoch:2 step:1940 [D loss: 0.504689, acc.: 78.12%] [G loss: 0.595278]\n",
      "epoch:2 step:1941 [D loss: 0.488791, acc.: 81.25%] [G loss: 0.496489]\n",
      "epoch:2 step:1942 [D loss: 0.528184, acc.: 73.44%] [G loss: 0.456610]\n",
      "epoch:2 step:1943 [D loss: 0.459500, acc.: 84.38%] [G loss: 0.487617]\n",
      "epoch:2 step:1944 [D loss: 0.501511, acc.: 74.22%] [G loss: 0.495482]\n",
      "epoch:2 step:1945 [D loss: 0.488765, acc.: 78.12%] [G loss: 0.622914]\n",
      "epoch:2 step:1946 [D loss: 0.410355, acc.: 83.59%] [G loss: 0.659609]\n",
      "epoch:2 step:1947 [D loss: 0.523229, acc.: 75.78%] [G loss: 0.484314]\n",
      "epoch:2 step:1948 [D loss: 0.421970, acc.: 85.94%] [G loss: 0.565063]\n",
      "epoch:2 step:1949 [D loss: 0.437230, acc.: 82.81%] [G loss: 0.544928]\n",
      "epoch:2 step:1950 [D loss: 0.483057, acc.: 75.78%] [G loss: 0.759285]\n",
      "epoch:2 step:1951 [D loss: 0.418112, acc.: 82.03%] [G loss: 0.818915]\n",
      "epoch:2 step:1952 [D loss: 0.555293, acc.: 75.00%] [G loss: 0.537494]\n",
      "epoch:2 step:1953 [D loss: 0.545555, acc.: 71.88%] [G loss: 0.419186]\n",
      "epoch:2 step:1954 [D loss: 0.510016, acc.: 73.44%] [G loss: 0.515670]\n",
      "epoch:2 step:1955 [D loss: 0.510642, acc.: 75.00%] [G loss: 0.491576]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:2 step:1956 [D loss: 0.429494, acc.: 84.38%] [G loss: 0.634514]\n",
      "epoch:2 step:1957 [D loss: 0.519231, acc.: 76.56%] [G loss: 0.716939]\n",
      "epoch:2 step:1958 [D loss: 0.491479, acc.: 80.47%] [G loss: 0.592174]\n",
      "epoch:2 step:1959 [D loss: 0.476090, acc.: 78.12%] [G loss: 0.654111]\n",
      "epoch:2 step:1960 [D loss: 0.462743, acc.: 82.03%] [G loss: 0.653751]\n",
      "epoch:2 step:1961 [D loss: 0.420685, acc.: 86.72%] [G loss: 0.611173]\n",
      "epoch:2 step:1962 [D loss: 0.475716, acc.: 82.03%] [G loss: 0.519567]\n",
      "epoch:2 step:1963 [D loss: 0.486487, acc.: 80.47%] [G loss: 0.681584]\n",
      "epoch:2 step:1964 [D loss: 0.447026, acc.: 81.25%] [G loss: 0.671409]\n",
      "epoch:2 step:1965 [D loss: 0.436062, acc.: 85.94%] [G loss: 0.588101]\n",
      "epoch:2 step:1966 [D loss: 0.488687, acc.: 78.12%] [G loss: 0.605412]\n",
      "epoch:2 step:1967 [D loss: 0.454137, acc.: 82.03%] [G loss: 0.559628]\n",
      "epoch:2 step:1968 [D loss: 0.482064, acc.: 80.47%] [G loss: 0.531488]\n",
      "epoch:2 step:1969 [D loss: 0.464142, acc.: 78.91%] [G loss: 0.534976]\n",
      "epoch:2 step:1970 [D loss: 0.409618, acc.: 87.50%] [G loss: 0.670788]\n",
      "epoch:2 step:1971 [D loss: 0.473694, acc.: 80.47%] [G loss: 0.635702]\n",
      "epoch:2 step:1972 [D loss: 0.461942, acc.: 82.81%] [G loss: 0.647822]\n",
      "epoch:2 step:1973 [D loss: 0.479552, acc.: 79.69%] [G loss: 0.625382]\n",
      "epoch:2 step:1974 [D loss: 0.446654, acc.: 82.81%] [G loss: 0.598614]\n",
      "epoch:2 step:1975 [D loss: 0.434380, acc.: 84.38%] [G loss: 0.678758]\n",
      "epoch:2 step:1976 [D loss: 0.549938, acc.: 74.22%] [G loss: 0.496518]\n",
      "epoch:2 step:1977 [D loss: 0.452248, acc.: 82.03%] [G loss: 0.527674]\n",
      "epoch:2 step:1978 [D loss: 0.444482, acc.: 78.12%] [G loss: 0.588929]\n",
      "epoch:2 step:1979 [D loss: 0.509342, acc.: 75.00%] [G loss: 0.595034]\n",
      "epoch:2 step:1980 [D loss: 0.566485, acc.: 73.44%] [G loss: 0.500625]\n",
      "epoch:2 step:1981 [D loss: 0.627623, acc.: 67.19%] [G loss: 0.460254]\n",
      "epoch:2 step:1982 [D loss: 0.486960, acc.: 82.03%] [G loss: 0.604049]\n",
      "epoch:2 step:1983 [D loss: 0.506320, acc.: 79.69%] [G loss: 0.503125]\n",
      "epoch:2 step:1984 [D loss: 0.477095, acc.: 78.12%] [G loss: 0.558985]\n",
      "epoch:2 step:1985 [D loss: 0.491143, acc.: 81.25%] [G loss: 0.475956]\n",
      "epoch:2 step:1986 [D loss: 0.502687, acc.: 76.56%] [G loss: 0.540496]\n",
      "epoch:2 step:1987 [D loss: 0.547399, acc.: 76.56%] [G loss: 0.546248]\n",
      "epoch:2 step:1988 [D loss: 0.564995, acc.: 73.44%] [G loss: 0.468136]\n",
      "epoch:2 step:1989 [D loss: 0.563961, acc.: 71.88%] [G loss: 0.598614]\n",
      "epoch:2 step:1990 [D loss: 0.495146, acc.: 82.81%] [G loss: 0.558751]\n",
      "epoch:2 step:1991 [D loss: 0.495372, acc.: 80.47%] [G loss: 0.588300]\n",
      "epoch:2 step:1992 [D loss: 0.404087, acc.: 90.62%] [G loss: 0.647304]\n",
      "epoch:2 step:1993 [D loss: 0.417902, acc.: 84.38%] [G loss: 0.724672]\n",
      "epoch:2 step:1994 [D loss: 0.547105, acc.: 74.22%] [G loss: 0.529768]\n",
      "epoch:2 step:1995 [D loss: 0.499180, acc.: 78.12%] [G loss: 0.437287]\n",
      "epoch:2 step:1996 [D loss: 0.524404, acc.: 70.31%] [G loss: 0.683962]\n",
      "epoch:2 step:1997 [D loss: 0.536027, acc.: 70.31%] [G loss: 0.545246]\n",
      "epoch:2 step:1998 [D loss: 0.513371, acc.: 76.56%] [G loss: 0.601515]\n",
      "epoch:2 step:1999 [D loss: 0.487839, acc.: 78.12%] [G loss: 0.517729]\n",
      "epoch:2 step:2000 [D loss: 0.475969, acc.: 78.91%] [G loss: 0.489650]\n",
      "epoch:2 step:2001 [D loss: 0.484755, acc.: 78.91%] [G loss: 0.508002]\n",
      "epoch:2 step:2002 [D loss: 0.439742, acc.: 81.25%] [G loss: 0.558818]\n",
      "epoch:2 step:2003 [D loss: 0.520088, acc.: 77.34%] [G loss: 0.530785]\n",
      "epoch:2 step:2004 [D loss: 0.453125, acc.: 80.47%] [G loss: 0.584256]\n",
      "epoch:2 step:2005 [D loss: 0.422913, acc.: 82.81%] [G loss: 0.688333]\n",
      "epoch:2 step:2006 [D loss: 0.474040, acc.: 79.69%] [G loss: 0.677716]\n",
      "epoch:2 step:2007 [D loss: 0.555416, acc.: 75.00%] [G loss: 0.511081]\n",
      "epoch:2 step:2008 [D loss: 0.430573, acc.: 79.69%] [G loss: 0.561753]\n",
      "epoch:2 step:2009 [D loss: 0.443417, acc.: 86.72%] [G loss: 0.651378]\n",
      "epoch:2 step:2010 [D loss: 0.515648, acc.: 73.44%] [G loss: 0.683118]\n",
      "epoch:2 step:2011 [D loss: 0.552668, acc.: 72.66%] [G loss: 0.474933]\n",
      "epoch:2 step:2012 [D loss: 0.460614, acc.: 81.25%] [G loss: 0.569489]\n",
      "epoch:2 step:2013 [D loss: 0.548866, acc.: 71.88%] [G loss: 0.641272]\n",
      "epoch:2 step:2014 [D loss: 0.477195, acc.: 82.03%] [G loss: 0.578957]\n",
      "epoch:2 step:2015 [D loss: 0.433292, acc.: 82.03%] [G loss: 0.712932]\n",
      "epoch:2 step:2016 [D loss: 0.425317, acc.: 82.81%] [G loss: 0.654910]\n",
      "epoch:2 step:2017 [D loss: 0.482866, acc.: 78.12%] [G loss: 0.569313]\n",
      "epoch:2 step:2018 [D loss: 0.468437, acc.: 79.69%] [G loss: 0.489506]\n",
      "epoch:2 step:2019 [D loss: 0.469459, acc.: 80.47%] [G loss: 0.573468]\n",
      "epoch:2 step:2020 [D loss: 0.485768, acc.: 81.25%] [G loss: 0.464993]\n",
      "epoch:2 step:2021 [D loss: 0.499102, acc.: 79.69%] [G loss: 0.518162]\n",
      "epoch:2 step:2022 [D loss: 0.444060, acc.: 82.81%] [G loss: 0.501714]\n",
      "epoch:2 step:2023 [D loss: 0.431536, acc.: 79.69%] [G loss: 0.599563]\n",
      "epoch:2 step:2024 [D loss: 0.523281, acc.: 75.00%] [G loss: 0.626506]\n",
      "epoch:2 step:2025 [D loss: 0.495097, acc.: 81.25%] [G loss: 0.454131]\n",
      "epoch:2 step:2026 [D loss: 0.438177, acc.: 82.81%] [G loss: 0.712123]\n",
      "epoch:2 step:2027 [D loss: 0.546791, acc.: 78.12%] [G loss: 0.470802]\n",
      "epoch:2 step:2028 [D loss: 0.472651, acc.: 79.69%] [G loss: 0.465413]\n",
      "epoch:2 step:2029 [D loss: 0.454126, acc.: 78.91%] [G loss: 0.656555]\n",
      "epoch:2 step:2030 [D loss: 0.512927, acc.: 75.00%] [G loss: 0.576423]\n",
      "epoch:2 step:2031 [D loss: 0.489929, acc.: 78.12%] [G loss: 0.622746]\n",
      "epoch:2 step:2032 [D loss: 0.508349, acc.: 75.78%] [G loss: 0.484941]\n",
      "epoch:2 step:2033 [D loss: 0.465936, acc.: 77.34%] [G loss: 0.580725]\n",
      "epoch:2 step:2034 [D loss: 0.501124, acc.: 74.22%] [G loss: 0.506498]\n",
      "epoch:2 step:2035 [D loss: 0.546316, acc.: 71.88%] [G loss: 0.441574]\n",
      "epoch:2 step:2036 [D loss: 0.438713, acc.: 83.59%] [G loss: 0.602616]\n",
      "epoch:2 step:2037 [D loss: 0.439438, acc.: 79.69%] [G loss: 0.609228]\n",
      "epoch:2 step:2038 [D loss: 0.494585, acc.: 77.34%] [G loss: 0.737033]\n",
      "epoch:2 step:2039 [D loss: 0.495590, acc.: 78.91%] [G loss: 0.649098]\n",
      "epoch:2 step:2040 [D loss: 0.443979, acc.: 82.81%] [G loss: 0.660252]\n",
      "epoch:2 step:2041 [D loss: 0.552064, acc.: 74.22%] [G loss: 0.470823]\n",
      "epoch:2 step:2042 [D loss: 0.500778, acc.: 78.12%] [G loss: 0.557700]\n",
      "epoch:2 step:2043 [D loss: 0.509187, acc.: 75.00%] [G loss: 0.544512]\n",
      "epoch:2 step:2044 [D loss: 0.422657, acc.: 85.16%] [G loss: 0.603593]\n",
      "epoch:2 step:2045 [D loss: 0.472000, acc.: 83.59%] [G loss: 0.500117]\n",
      "epoch:2 step:2046 [D loss: 0.453682, acc.: 82.03%] [G loss: 0.691953]\n",
      "epoch:2 step:2047 [D loss: 0.466442, acc.: 78.91%] [G loss: 0.667584]\n",
      "epoch:2 step:2048 [D loss: 0.456068, acc.: 80.47%] [G loss: 0.739771]\n",
      "epoch:2 step:2049 [D loss: 0.447465, acc.: 82.81%] [G loss: 0.682707]\n",
      "epoch:2 step:2050 [D loss: 0.460225, acc.: 79.69%] [G loss: 0.704959]\n",
      "epoch:2 step:2051 [D loss: 0.468436, acc.: 78.91%] [G loss: 0.639002]\n",
      "epoch:2 step:2052 [D loss: 0.429260, acc.: 84.38%] [G loss: 0.653141]\n",
      "epoch:2 step:2053 [D loss: 0.512667, acc.: 80.47%] [G loss: 0.720603]\n",
      "epoch:2 step:2054 [D loss: 0.475522, acc.: 79.69%] [G loss: 0.591367]\n",
      "epoch:2 step:2055 [D loss: 0.453272, acc.: 85.16%] [G loss: 0.591398]\n",
      "epoch:2 step:2056 [D loss: 0.463382, acc.: 80.47%] [G loss: 0.686566]\n",
      "epoch:2 step:2057 [D loss: 0.541587, acc.: 71.88%] [G loss: 0.619794]\n",
      "epoch:2 step:2058 [D loss: 0.480389, acc.: 78.12%] [G loss: 0.672221]\n",
      "epoch:2 step:2059 [D loss: 0.478965, acc.: 77.34%] [G loss: 0.659733]\n",
      "epoch:2 step:2060 [D loss: 0.479621, acc.: 81.25%] [G loss: 0.515531]\n",
      "epoch:2 step:2061 [D loss: 0.524605, acc.: 75.78%] [G loss: 0.507528]\n",
      "epoch:2 step:2062 [D loss: 0.461598, acc.: 78.91%] [G loss: 0.692410]\n",
      "epoch:2 step:2063 [D loss: 0.479477, acc.: 78.91%] [G loss: 0.675164]\n",
      "epoch:2 step:2064 [D loss: 0.411390, acc.: 81.25%] [G loss: 0.817822]\n",
      "epoch:2 step:2065 [D loss: 0.489964, acc.: 77.34%] [G loss: 0.580103]\n",
      "epoch:2 step:2066 [D loss: 0.550159, acc.: 74.22%] [G loss: 0.632662]\n",
      "epoch:2 step:2067 [D loss: 0.511721, acc.: 77.34%] [G loss: 0.543024]\n",
      "epoch:2 step:2068 [D loss: 0.427214, acc.: 84.38%] [G loss: 0.712089]\n",
      "epoch:2 step:2069 [D loss: 0.498288, acc.: 80.47%] [G loss: 0.587265]\n",
      "epoch:2 step:2070 [D loss: 0.564455, acc.: 70.31%] [G loss: 0.534331]\n",
      "epoch:2 step:2071 [D loss: 0.478378, acc.: 78.12%] [G loss: 0.569639]\n",
      "epoch:2 step:2072 [D loss: 0.454943, acc.: 82.03%] [G loss: 0.693056]\n",
      "epoch:2 step:2073 [D loss: 0.468741, acc.: 79.69%] [G loss: 0.662674]\n",
      "epoch:2 step:2074 [D loss: 0.503287, acc.: 75.78%] [G loss: 0.563041]\n",
      "epoch:2 step:2075 [D loss: 0.476315, acc.: 83.59%] [G loss: 0.487205]\n",
      "epoch:2 step:2076 [D loss: 0.477190, acc.: 84.38%] [G loss: 0.579456]\n",
      "epoch:2 step:2077 [D loss: 0.548660, acc.: 71.88%] [G loss: 0.547395]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:2 step:2078 [D loss: 0.395903, acc.: 85.16%] [G loss: 0.747147]\n",
      "epoch:2 step:2079 [D loss: 0.463899, acc.: 80.47%] [G loss: 0.813988]\n",
      "epoch:2 step:2080 [D loss: 0.453892, acc.: 82.81%] [G loss: 0.685181]\n",
      "epoch:2 step:2081 [D loss: 0.437906, acc.: 83.59%] [G loss: 0.717450]\n",
      "epoch:2 step:2082 [D loss: 0.489550, acc.: 77.34%] [G loss: 0.764606]\n",
      "epoch:2 step:2083 [D loss: 0.488106, acc.: 80.47%] [G loss: 0.668001]\n",
      "epoch:2 step:2084 [D loss: 0.498895, acc.: 73.44%] [G loss: 0.510306]\n",
      "epoch:2 step:2085 [D loss: 0.451674, acc.: 82.81%] [G loss: 0.570670]\n",
      "epoch:2 step:2086 [D loss: 0.437981, acc.: 80.47%] [G loss: 0.672053]\n",
      "epoch:2 step:2087 [D loss: 0.489608, acc.: 74.22%] [G loss: 0.602041]\n",
      "epoch:2 step:2088 [D loss: 0.567830, acc.: 67.19%] [G loss: 0.454838]\n",
      "epoch:2 step:2089 [D loss: 0.549781, acc.: 74.22%] [G loss: 0.497962]\n",
      "epoch:2 step:2090 [D loss: 0.530288, acc.: 77.34%] [G loss: 0.454932]\n",
      "epoch:2 step:2091 [D loss: 0.451071, acc.: 84.38%] [G loss: 0.511071]\n",
      "epoch:2 step:2092 [D loss: 0.497089, acc.: 77.34%] [G loss: 0.543373]\n",
      "epoch:2 step:2093 [D loss: 0.505414, acc.: 76.56%] [G loss: 0.518970]\n",
      "epoch:2 step:2094 [D loss: 0.481976, acc.: 78.91%] [G loss: 0.512373]\n",
      "epoch:2 step:2095 [D loss: 0.419447, acc.: 86.72%] [G loss: 0.593583]\n",
      "epoch:2 step:2096 [D loss: 0.491064, acc.: 75.00%] [G loss: 0.554469]\n",
      "epoch:2 step:2097 [D loss: 0.407901, acc.: 86.72%] [G loss: 0.737358]\n",
      "epoch:2 step:2098 [D loss: 0.530364, acc.: 71.88%] [G loss: 0.561102]\n",
      "epoch:2 step:2099 [D loss: 0.532066, acc.: 74.22%] [G loss: 0.437454]\n",
      "epoch:2 step:2100 [D loss: 0.470272, acc.: 82.81%] [G loss: 0.541052]\n",
      "epoch:2 step:2101 [D loss: 0.500402, acc.: 75.78%] [G loss: 0.507600]\n",
      "epoch:2 step:2102 [D loss: 0.453023, acc.: 83.59%] [G loss: 0.571482]\n",
      "epoch:2 step:2103 [D loss: 0.521124, acc.: 78.91%] [G loss: 0.565364]\n",
      "epoch:2 step:2104 [D loss: 0.457189, acc.: 83.59%] [G loss: 0.543705]\n",
      "epoch:2 step:2105 [D loss: 0.472707, acc.: 76.56%] [G loss: 0.565709]\n",
      "epoch:2 step:2106 [D loss: 0.386027, acc.: 88.28%] [G loss: 1.048489]\n",
      "epoch:2 step:2107 [D loss: 0.532485, acc.: 78.12%] [G loss: 0.619439]\n",
      "epoch:2 step:2108 [D loss: 0.440272, acc.: 83.59%] [G loss: 0.613086]\n",
      "epoch:2 step:2109 [D loss: 0.487228, acc.: 75.78%] [G loss: 0.649949]\n",
      "epoch:2 step:2110 [D loss: 0.464686, acc.: 78.91%] [G loss: 0.599044]\n",
      "epoch:2 step:2111 [D loss: 0.526377, acc.: 75.00%] [G loss: 0.557486]\n",
      "epoch:2 step:2112 [D loss: 0.447917, acc.: 80.47%] [G loss: 0.627606]\n",
      "epoch:2 step:2113 [D loss: 0.511783, acc.: 73.44%] [G loss: 0.586534]\n",
      "epoch:2 step:2114 [D loss: 0.457263, acc.: 80.47%] [G loss: 0.636674]\n",
      "epoch:2 step:2115 [D loss: 0.494521, acc.: 78.12%] [G loss: 0.431667]\n",
      "epoch:2 step:2116 [D loss: 0.464275, acc.: 81.25%] [G loss: 0.521944]\n",
      "epoch:2 step:2117 [D loss: 0.463198, acc.: 79.69%] [G loss: 0.545663]\n",
      "epoch:2 step:2118 [D loss: 0.434539, acc.: 85.16%] [G loss: 0.545914]\n",
      "epoch:2 step:2119 [D loss: 0.499310, acc.: 79.69%] [G loss: 0.483643]\n",
      "epoch:2 step:2120 [D loss: 0.509876, acc.: 78.12%] [G loss: 0.499829]\n",
      "epoch:2 step:2121 [D loss: 0.490900, acc.: 78.91%] [G loss: 0.573030]\n",
      "epoch:2 step:2122 [D loss: 0.504959, acc.: 81.25%] [G loss: 0.571561]\n",
      "epoch:2 step:2123 [D loss: 0.499558, acc.: 71.09%] [G loss: 0.473588]\n",
      "epoch:2 step:2124 [D loss: 0.517106, acc.: 76.56%] [G loss: 0.460430]\n",
      "epoch:2 step:2125 [D loss: 0.512897, acc.: 73.44%] [G loss: 0.559813]\n",
      "epoch:2 step:2126 [D loss: 0.490110, acc.: 76.56%] [G loss: 0.692559]\n",
      "epoch:2 step:2127 [D loss: 0.464110, acc.: 79.69%] [G loss: 0.546673]\n",
      "epoch:2 step:2128 [D loss: 0.428489, acc.: 83.59%] [G loss: 0.648839]\n",
      "epoch:2 step:2129 [D loss: 0.474197, acc.: 77.34%] [G loss: 0.620217]\n",
      "epoch:2 step:2130 [D loss: 0.464620, acc.: 78.12%] [G loss: 0.608057]\n",
      "epoch:2 step:2131 [D loss: 0.466837, acc.: 77.34%] [G loss: 0.714130]\n",
      "epoch:2 step:2132 [D loss: 0.412835, acc.: 85.94%] [G loss: 0.660014]\n",
      "epoch:2 step:2133 [D loss: 0.446538, acc.: 81.25%] [G loss: 0.662217]\n",
      "epoch:2 step:2134 [D loss: 0.428134, acc.: 86.72%] [G loss: 0.626046]\n",
      "epoch:2 step:2135 [D loss: 0.484885, acc.: 79.69%] [G loss: 0.609260]\n",
      "epoch:2 step:2136 [D loss: 0.464931, acc.: 84.38%] [G loss: 0.588601]\n",
      "epoch:2 step:2137 [D loss: 0.604536, acc.: 67.97%] [G loss: 0.528644]\n",
      "epoch:2 step:2138 [D loss: 0.518241, acc.: 78.91%] [G loss: 0.586684]\n",
      "epoch:2 step:2139 [D loss: 0.569396, acc.: 71.09%] [G loss: 0.474339]\n",
      "epoch:2 step:2140 [D loss: 0.462061, acc.: 82.81%] [G loss: 0.497478]\n",
      "epoch:2 step:2141 [D loss: 0.538325, acc.: 69.53%] [G loss: 0.555331]\n",
      "epoch:2 step:2142 [D loss: 0.477136, acc.: 79.69%] [G loss: 0.456099]\n",
      "epoch:2 step:2143 [D loss: 0.557451, acc.: 72.66%] [G loss: 0.474160]\n",
      "epoch:2 step:2144 [D loss: 0.486427, acc.: 77.34%] [G loss: 0.478340]\n",
      "epoch:2 step:2145 [D loss: 0.426506, acc.: 82.81%] [G loss: 0.677053]\n",
      "epoch:2 step:2146 [D loss: 0.499621, acc.: 78.91%] [G loss: 0.581917]\n",
      "epoch:2 step:2147 [D loss: 0.461041, acc.: 79.69%] [G loss: 0.662947]\n",
      "epoch:2 step:2148 [D loss: 0.505019, acc.: 72.66%] [G loss: 0.683537]\n",
      "epoch:2 step:2149 [D loss: 0.523452, acc.: 76.56%] [G loss: 0.481028]\n",
      "epoch:2 step:2150 [D loss: 0.525243, acc.: 74.22%] [G loss: 0.555315]\n",
      "epoch:2 step:2151 [D loss: 0.585816, acc.: 67.19%] [G loss: 0.425091]\n",
      "epoch:2 step:2152 [D loss: 0.536234, acc.: 76.56%] [G loss: 0.514983]\n",
      "epoch:2 step:2153 [D loss: 0.458454, acc.: 78.12%] [G loss: 0.752814]\n",
      "epoch:2 step:2154 [D loss: 0.480729, acc.: 80.47%] [G loss: 0.737550]\n",
      "epoch:2 step:2155 [D loss: 0.556975, acc.: 71.88%] [G loss: 0.406054]\n",
      "epoch:2 step:2156 [D loss: 0.515803, acc.: 75.78%] [G loss: 0.405039]\n",
      "epoch:2 step:2157 [D loss: 0.418759, acc.: 86.72%] [G loss: 0.569270]\n",
      "epoch:2 step:2158 [D loss: 0.425706, acc.: 82.81%] [G loss: 0.605858]\n",
      "epoch:2 step:2159 [D loss: 0.450020, acc.: 78.12%] [G loss: 0.684078]\n",
      "epoch:2 step:2160 [D loss: 0.408734, acc.: 88.28%] [G loss: 0.670316]\n",
      "epoch:2 step:2161 [D loss: 0.511781, acc.: 78.12%] [G loss: 0.563540]\n",
      "epoch:2 step:2162 [D loss: 0.519616, acc.: 76.56%] [G loss: 0.527907]\n",
      "epoch:2 step:2163 [D loss: 0.453795, acc.: 86.72%] [G loss: 0.573949]\n",
      "epoch:2 step:2164 [D loss: 0.569866, acc.: 68.75%] [G loss: 0.529856]\n",
      "epoch:2 step:2165 [D loss: 0.495168, acc.: 82.81%] [G loss: 0.576803]\n",
      "epoch:2 step:2166 [D loss: 0.569768, acc.: 72.66%] [G loss: 0.475224]\n",
      "epoch:2 step:2167 [D loss: 0.487486, acc.: 79.69%] [G loss: 0.540986]\n",
      "epoch:2 step:2168 [D loss: 0.474433, acc.: 82.03%] [G loss: 0.512485]\n",
      "epoch:2 step:2169 [D loss: 0.468107, acc.: 82.03%] [G loss: 0.655952]\n",
      "epoch:2 step:2170 [D loss: 0.414618, acc.: 83.59%] [G loss: 0.668221]\n",
      "epoch:2 step:2171 [D loss: 0.482627, acc.: 78.91%] [G loss: 0.668224]\n",
      "epoch:2 step:2172 [D loss: 0.542116, acc.: 72.66%] [G loss: 0.534040]\n",
      "epoch:2 step:2173 [D loss: 0.486263, acc.: 80.47%] [G loss: 0.605609]\n",
      "epoch:2 step:2174 [D loss: 0.467405, acc.: 83.59%] [G loss: 0.671299]\n",
      "epoch:2 step:2175 [D loss: 0.553719, acc.: 71.88%] [G loss: 0.425071]\n",
      "epoch:2 step:2176 [D loss: 0.455233, acc.: 82.03%] [G loss: 0.518372]\n",
      "epoch:2 step:2177 [D loss: 0.529087, acc.: 75.00%] [G loss: 0.430504]\n",
      "epoch:2 step:2178 [D loss: 0.429746, acc.: 82.81%] [G loss: 0.599964]\n",
      "epoch:2 step:2179 [D loss: 0.418031, acc.: 85.16%] [G loss: 0.719873]\n",
      "epoch:2 step:2180 [D loss: 0.484920, acc.: 80.47%] [G loss: 0.628185]\n",
      "epoch:2 step:2181 [D loss: 0.411335, acc.: 88.28%] [G loss: 0.622651]\n",
      "epoch:2 step:2182 [D loss: 0.413653, acc.: 85.16%] [G loss: 0.754243]\n",
      "epoch:2 step:2183 [D loss: 0.371096, acc.: 87.50%] [G loss: 0.773571]\n",
      "epoch:2 step:2184 [D loss: 0.438121, acc.: 83.59%] [G loss: 0.748077]\n",
      "epoch:2 step:2185 [D loss: 0.429862, acc.: 83.59%] [G loss: 0.701450]\n",
      "epoch:2 step:2186 [D loss: 0.461554, acc.: 84.38%] [G loss: 0.767807]\n",
      "epoch:2 step:2187 [D loss: 0.444178, acc.: 85.16%] [G loss: 0.733675]\n",
      "epoch:2 step:2188 [D loss: 0.394492, acc.: 87.50%] [G loss: 0.839134]\n",
      "epoch:2 step:2189 [D loss: 0.439727, acc.: 83.59%] [G loss: 0.887494]\n",
      "epoch:2 step:2190 [D loss: 0.604893, acc.: 75.00%] [G loss: 0.554025]\n",
      "epoch:2 step:2191 [D loss: 0.486955, acc.: 78.91%] [G loss: 0.609225]\n",
      "epoch:2 step:2192 [D loss: 0.465772, acc.: 85.16%] [G loss: 0.654114]\n",
      "epoch:2 step:2193 [D loss: 0.462508, acc.: 78.91%] [G loss: 0.631423]\n",
      "epoch:2 step:2194 [D loss: 0.454945, acc.: 82.81%] [G loss: 0.754673]\n",
      "epoch:2 step:2195 [D loss: 0.418647, acc.: 85.94%] [G loss: 0.828160]\n",
      "epoch:2 step:2196 [D loss: 0.454200, acc.: 82.81%] [G loss: 0.782669]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:2 step:2197 [D loss: 0.454475, acc.: 80.47%] [G loss: 0.630567]\n",
      "epoch:2 step:2198 [D loss: 0.439114, acc.: 82.03%] [G loss: 0.739908]\n",
      "epoch:2 step:2199 [D loss: 0.463655, acc.: 78.91%] [G loss: 0.627963]\n",
      "epoch:2 step:2200 [D loss: 0.459643, acc.: 78.91%] [G loss: 0.673889]\n",
      "epoch:2 step:2201 [D loss: 0.487542, acc.: 81.25%] [G loss: 0.680657]\n",
      "epoch:2 step:2202 [D loss: 0.499190, acc.: 80.47%] [G loss: 0.592189]\n",
      "epoch:2 step:2203 [D loss: 0.471891, acc.: 82.03%] [G loss: 0.610095]\n",
      "epoch:2 step:2204 [D loss: 0.450316, acc.: 84.38%] [G loss: 0.627464]\n",
      "epoch:2 step:2205 [D loss: 0.451867, acc.: 82.81%] [G loss: 0.628227]\n",
      "epoch:2 step:2206 [D loss: 0.456874, acc.: 81.25%] [G loss: 0.689635]\n",
      "epoch:2 step:2207 [D loss: 0.456904, acc.: 83.59%] [G loss: 0.527224]\n",
      "epoch:2 step:2208 [D loss: 0.502465, acc.: 75.00%] [G loss: 0.727810]\n",
      "epoch:2 step:2209 [D loss: 0.466032, acc.: 82.03%] [G loss: 0.769620]\n",
      "epoch:2 step:2210 [D loss: 0.533489, acc.: 74.22%] [G loss: 0.638419]\n",
      "epoch:2 step:2211 [D loss: 0.441451, acc.: 79.69%] [G loss: 0.761266]\n",
      "epoch:2 step:2212 [D loss: 0.489090, acc.: 77.34%] [G loss: 0.711824]\n",
      "epoch:2 step:2213 [D loss: 0.476631, acc.: 75.78%] [G loss: 0.613233]\n",
      "epoch:2 step:2214 [D loss: 0.446963, acc.: 78.91%] [G loss: 0.778082]\n",
      "epoch:2 step:2215 [D loss: 0.490387, acc.: 78.12%] [G loss: 0.643193]\n",
      "epoch:2 step:2216 [D loss: 0.467525, acc.: 82.81%] [G loss: 0.627752]\n",
      "epoch:2 step:2217 [D loss: 0.387879, acc.: 88.28%] [G loss: 0.768010]\n",
      "epoch:2 step:2218 [D loss: 0.413620, acc.: 82.81%] [G loss: 0.848119]\n",
      "epoch:2 step:2219 [D loss: 0.499065, acc.: 73.44%] [G loss: 0.772403]\n",
      "epoch:2 step:2220 [D loss: 0.471735, acc.: 76.56%] [G loss: 0.775595]\n",
      "epoch:2 step:2221 [D loss: 0.495606, acc.: 78.12%] [G loss: 0.941501]\n",
      "epoch:2 step:2222 [D loss: 0.548517, acc.: 78.12%] [G loss: 0.534441]\n",
      "epoch:2 step:2223 [D loss: 0.549954, acc.: 75.00%] [G loss: 0.522744]\n",
      "epoch:2 step:2224 [D loss: 0.420155, acc.: 85.94%] [G loss: 0.572626]\n",
      "epoch:2 step:2225 [D loss: 0.475937, acc.: 80.47%] [G loss: 0.599035]\n",
      "epoch:2 step:2226 [D loss: 0.589162, acc.: 70.31%] [G loss: 0.540863]\n",
      "epoch:2 step:2227 [D loss: 0.523555, acc.: 71.88%] [G loss: 0.619241]\n",
      "epoch:2 step:2228 [D loss: 0.399467, acc.: 85.94%] [G loss: 0.945972]\n",
      "epoch:2 step:2229 [D loss: 0.437783, acc.: 81.25%] [G loss: 0.794368]\n",
      "epoch:2 step:2230 [D loss: 0.468806, acc.: 75.00%] [G loss: 0.574741]\n",
      "epoch:2 step:2231 [D loss: 0.460163, acc.: 79.69%] [G loss: 0.633959]\n",
      "epoch:2 step:2232 [D loss: 0.377644, acc.: 88.28%] [G loss: 0.808129]\n",
      "epoch:2 step:2233 [D loss: 0.434130, acc.: 81.25%] [G loss: 0.870883]\n",
      "epoch:2 step:2234 [D loss: 0.461781, acc.: 85.16%] [G loss: 0.711335]\n",
      "epoch:2 step:2235 [D loss: 0.441720, acc.: 82.03%] [G loss: 0.628899]\n",
      "epoch:2 step:2236 [D loss: 0.502849, acc.: 78.12%] [G loss: 0.573120]\n",
      "epoch:2 step:2237 [D loss: 0.472411, acc.: 79.69%] [G loss: 0.648725]\n",
      "epoch:2 step:2238 [D loss: 0.451857, acc.: 82.81%] [G loss: 0.643238]\n",
      "epoch:2 step:2239 [D loss: 0.466653, acc.: 84.38%] [G loss: 0.573630]\n",
      "epoch:2 step:2240 [D loss: 0.434931, acc.: 82.03%] [G loss: 0.715050]\n",
      "epoch:2 step:2241 [D loss: 0.515240, acc.: 78.12%] [G loss: 0.623389]\n",
      "epoch:2 step:2242 [D loss: 0.444871, acc.: 82.81%] [G loss: 0.637996]\n",
      "epoch:2 step:2243 [D loss: 0.463309, acc.: 82.03%] [G loss: 0.676387]\n",
      "epoch:2 step:2244 [D loss: 0.465398, acc.: 80.47%] [G loss: 0.685246]\n",
      "epoch:2 step:2245 [D loss: 0.443932, acc.: 83.59%] [G loss: 0.651521]\n",
      "epoch:2 step:2246 [D loss: 0.427105, acc.: 85.16%] [G loss: 0.563994]\n",
      "epoch:2 step:2247 [D loss: 0.491816, acc.: 82.03%] [G loss: 0.749959]\n",
      "epoch:2 step:2248 [D loss: 0.432902, acc.: 82.81%] [G loss: 0.734605]\n",
      "epoch:2 step:2249 [D loss: 0.449104, acc.: 82.03%] [G loss: 0.687092]\n",
      "epoch:2 step:2250 [D loss: 0.494936, acc.: 78.91%] [G loss: 0.563093]\n",
      "epoch:2 step:2251 [D loss: 0.501507, acc.: 78.91%] [G loss: 0.598491]\n",
      "epoch:2 step:2252 [D loss: 0.431417, acc.: 84.38%] [G loss: 0.697091]\n",
      "epoch:2 step:2253 [D loss: 0.475716, acc.: 82.81%] [G loss: 0.802528]\n",
      "epoch:2 step:2254 [D loss: 0.508820, acc.: 78.12%] [G loss: 0.663256]\n",
      "epoch:2 step:2255 [D loss: 0.372480, acc.: 85.16%] [G loss: 0.792537]\n",
      "epoch:2 step:2256 [D loss: 0.485559, acc.: 82.03%] [G loss: 0.711802]\n",
      "epoch:2 step:2257 [D loss: 0.459685, acc.: 80.47%] [G loss: 0.713215]\n",
      "epoch:2 step:2258 [D loss: 0.464449, acc.: 78.12%] [G loss: 0.570126]\n",
      "epoch:2 step:2259 [D loss: 0.491378, acc.: 78.12%] [G loss: 0.579060]\n",
      "epoch:2 step:2260 [D loss: 0.497712, acc.: 76.56%] [G loss: 0.484527]\n",
      "epoch:2 step:2261 [D loss: 0.508634, acc.: 78.12%] [G loss: 0.581310]\n",
      "epoch:2 step:2262 [D loss: 0.514673, acc.: 75.00%] [G loss: 0.638327]\n",
      "epoch:2 step:2263 [D loss: 0.463379, acc.: 78.12%] [G loss: 0.591665]\n",
      "epoch:2 step:2264 [D loss: 0.509716, acc.: 75.00%] [G loss: 0.526993]\n",
      "epoch:2 step:2265 [D loss: 0.446326, acc.: 79.69%] [G loss: 0.712784]\n",
      "epoch:2 step:2266 [D loss: 0.355497, acc.: 88.28%] [G loss: 0.755318]\n",
      "epoch:2 step:2267 [D loss: 0.493854, acc.: 75.78%] [G loss: 0.539060]\n",
      "epoch:2 step:2268 [D loss: 0.466559, acc.: 78.91%] [G loss: 0.643493]\n",
      "epoch:2 step:2269 [D loss: 0.422170, acc.: 85.94%] [G loss: 0.789320]\n",
      "epoch:2 step:2270 [D loss: 0.576518, acc.: 71.09%] [G loss: 0.599978]\n",
      "epoch:2 step:2271 [D loss: 0.436807, acc.: 85.94%] [G loss: 0.570477]\n",
      "epoch:2 step:2272 [D loss: 0.416282, acc.: 85.16%] [G loss: 0.758416]\n",
      "epoch:2 step:2273 [D loss: 0.401826, acc.: 86.72%] [G loss: 0.787950]\n",
      "epoch:2 step:2274 [D loss: 0.567110, acc.: 73.44%] [G loss: 0.558434]\n",
      "epoch:2 step:2275 [D loss: 0.450844, acc.: 77.34%] [G loss: 0.666343]\n",
      "epoch:2 step:2276 [D loss: 0.386500, acc.: 85.94%] [G loss: 0.691725]\n",
      "epoch:2 step:2277 [D loss: 0.469837, acc.: 77.34%] [G loss: 0.910210]\n",
      "epoch:2 step:2278 [D loss: 0.513295, acc.: 74.22%] [G loss: 0.830017]\n",
      "epoch:2 step:2279 [D loss: 0.485130, acc.: 76.56%] [G loss: 0.698409]\n",
      "epoch:2 step:2280 [D loss: 0.472571, acc.: 80.47%] [G loss: 0.611032]\n",
      "epoch:2 step:2281 [D loss: 0.438144, acc.: 79.69%] [G loss: 0.684754]\n",
      "epoch:2 step:2282 [D loss: 0.461332, acc.: 77.34%] [G loss: 0.646490]\n",
      "epoch:2 step:2283 [D loss: 0.452505, acc.: 78.12%] [G loss: 0.777321]\n",
      "epoch:2 step:2284 [D loss: 0.473211, acc.: 80.47%] [G loss: 0.700685]\n",
      "epoch:2 step:2285 [D loss: 0.481794, acc.: 81.25%] [G loss: 0.653991]\n",
      "epoch:2 step:2286 [D loss: 0.494532, acc.: 76.56%] [G loss: 0.664308]\n",
      "epoch:2 step:2287 [D loss: 0.465533, acc.: 79.69%] [G loss: 0.723186]\n",
      "epoch:2 step:2288 [D loss: 0.483347, acc.: 77.34%] [G loss: 0.564821]\n",
      "epoch:2 step:2289 [D loss: 0.526283, acc.: 78.12%] [G loss: 0.677346]\n",
      "epoch:2 step:2290 [D loss: 0.440303, acc.: 83.59%] [G loss: 0.736374]\n",
      "epoch:2 step:2291 [D loss: 0.521912, acc.: 73.44%] [G loss: 0.634364]\n",
      "epoch:2 step:2292 [D loss: 0.508389, acc.: 75.00%] [G loss: 0.567858]\n",
      "epoch:2 step:2293 [D loss: 0.456166, acc.: 80.47%] [G loss: 0.688456]\n",
      "epoch:2 step:2294 [D loss: 0.466977, acc.: 82.03%] [G loss: 0.705912]\n",
      "epoch:2 step:2295 [D loss: 0.506967, acc.: 79.69%] [G loss: 0.610487]\n",
      "epoch:2 step:2296 [D loss: 0.422491, acc.: 83.59%] [G loss: 0.608328]\n",
      "epoch:2 step:2297 [D loss: 0.473143, acc.: 78.91%] [G loss: 0.586328]\n",
      "epoch:2 step:2298 [D loss: 0.515818, acc.: 72.66%] [G loss: 0.721780]\n",
      "epoch:2 step:2299 [D loss: 0.448224, acc.: 85.16%] [G loss: 0.659537]\n",
      "epoch:2 step:2300 [D loss: 0.419159, acc.: 81.25%] [G loss: 0.735982]\n",
      "epoch:2 step:2301 [D loss: 0.429943, acc.: 84.38%] [G loss: 0.891804]\n",
      "epoch:2 step:2302 [D loss: 0.434743, acc.: 84.38%] [G loss: 0.849234]\n",
      "epoch:2 step:2303 [D loss: 0.449117, acc.: 82.81%] [G loss: 0.697665]\n",
      "epoch:2 step:2304 [D loss: 0.491581, acc.: 72.66%] [G loss: 0.692517]\n",
      "epoch:2 step:2305 [D loss: 0.438673, acc.: 85.94%] [G loss: 0.720130]\n",
      "epoch:2 step:2306 [D loss: 0.470087, acc.: 82.81%] [G loss: 0.763972]\n",
      "epoch:2 step:2307 [D loss: 0.513673, acc.: 75.00%] [G loss: 0.610951]\n",
      "epoch:2 step:2308 [D loss: 0.487052, acc.: 82.81%] [G loss: 0.651464]\n",
      "epoch:2 step:2309 [D loss: 0.521174, acc.: 78.12%] [G loss: 0.614969]\n",
      "epoch:2 step:2310 [D loss: 0.453850, acc.: 82.03%] [G loss: 0.658468]\n",
      "epoch:2 step:2311 [D loss: 0.531134, acc.: 73.44%] [G loss: 0.506814]\n",
      "epoch:2 step:2312 [D loss: 0.451436, acc.: 82.03%] [G loss: 0.610452]\n",
      "epoch:2 step:2313 [D loss: 0.420024, acc.: 87.50%] [G loss: 0.680860]\n",
      "epoch:2 step:2314 [D loss: 0.418211, acc.: 86.72%] [G loss: 0.672706]\n",
      "epoch:2 step:2315 [D loss: 0.535841, acc.: 80.47%] [G loss: 0.586872]\n",
      "epoch:2 step:2316 [D loss: 0.468969, acc.: 80.47%] [G loss: 0.666095]\n",
      "epoch:2 step:2317 [D loss: 0.494863, acc.: 77.34%] [G loss: 0.644979]\n",
      "epoch:2 step:2318 [D loss: 0.559555, acc.: 67.19%] [G loss: 0.568098]\n",
      "epoch:2 step:2319 [D loss: 0.449908, acc.: 82.81%] [G loss: 0.631836]\n",
      "epoch:2 step:2320 [D loss: 0.479306, acc.: 78.91%] [G loss: 0.675189]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:2 step:2321 [D loss: 0.395029, acc.: 86.72%] [G loss: 0.808174]\n",
      "epoch:2 step:2322 [D loss: 0.516052, acc.: 76.56%] [G loss: 0.666846]\n",
      "epoch:2 step:2323 [D loss: 0.518156, acc.: 74.22%] [G loss: 0.704360]\n",
      "epoch:2 step:2324 [D loss: 0.392082, acc.: 88.28%] [G loss: 0.821519]\n",
      "epoch:2 step:2325 [D loss: 0.463343, acc.: 76.56%] [G loss: 0.666232]\n",
      "epoch:2 step:2326 [D loss: 0.498486, acc.: 76.56%] [G loss: 0.699505]\n",
      "epoch:2 step:2327 [D loss: 0.487496, acc.: 75.78%] [G loss: 0.600988]\n",
      "epoch:2 step:2328 [D loss: 0.524485, acc.: 75.78%] [G loss: 0.559487]\n",
      "epoch:2 step:2329 [D loss: 0.471992, acc.: 82.03%] [G loss: 0.611157]\n",
      "epoch:2 step:2330 [D loss: 0.511841, acc.: 77.34%] [G loss: 0.565567]\n",
      "epoch:2 step:2331 [D loss: 0.447028, acc.: 82.81%] [G loss: 0.729573]\n",
      "epoch:2 step:2332 [D loss: 0.552802, acc.: 69.53%] [G loss: 0.625888]\n",
      "epoch:2 step:2333 [D loss: 0.504320, acc.: 72.66%] [G loss: 0.560219]\n",
      "epoch:2 step:2334 [D loss: 0.440131, acc.: 83.59%] [G loss: 0.848452]\n",
      "epoch:2 step:2335 [D loss: 0.431457, acc.: 85.16%] [G loss: 0.647714]\n",
      "epoch:2 step:2336 [D loss: 0.499261, acc.: 73.44%] [G loss: 0.795369]\n",
      "epoch:2 step:2337 [D loss: 0.520051, acc.: 75.78%] [G loss: 0.559179]\n",
      "epoch:2 step:2338 [D loss: 0.488094, acc.: 81.25%] [G loss: 0.518272]\n",
      "epoch:2 step:2339 [D loss: 0.604801, acc.: 65.62%] [G loss: 0.420137]\n",
      "epoch:2 step:2340 [D loss: 0.427967, acc.: 79.69%] [G loss: 0.643491]\n",
      "epoch:2 step:2341 [D loss: 0.508680, acc.: 75.00%] [G loss: 0.866016]\n",
      "epoch:2 step:2342 [D loss: 0.563652, acc.: 72.66%] [G loss: 0.590055]\n",
      "epoch:2 step:2343 [D loss: 0.486642, acc.: 78.91%] [G loss: 0.668105]\n",
      "epoch:2 step:2344 [D loss: 0.524922, acc.: 78.12%] [G loss: 0.486218]\n",
      "epoch:2 step:2345 [D loss: 0.459776, acc.: 83.59%] [G loss: 0.676673]\n",
      "epoch:2 step:2346 [D loss: 0.482791, acc.: 78.12%] [G loss: 0.879965]\n",
      "epoch:2 step:2347 [D loss: 0.557210, acc.: 79.69%] [G loss: 0.707707]\n",
      "epoch:2 step:2348 [D loss: 0.392727, acc.: 82.81%] [G loss: 1.015496]\n",
      "epoch:2 step:2349 [D loss: 0.456427, acc.: 79.69%] [G loss: 0.850230]\n",
      "epoch:2 step:2350 [D loss: 0.537217, acc.: 71.88%] [G loss: 0.541904]\n",
      "epoch:2 step:2351 [D loss: 0.567379, acc.: 64.06%] [G loss: 0.475175]\n",
      "epoch:2 step:2352 [D loss: 0.502190, acc.: 76.56%] [G loss: 0.586175]\n",
      "epoch:2 step:2353 [D loss: 0.496929, acc.: 81.25%] [G loss: 0.639748]\n",
      "epoch:2 step:2354 [D loss: 0.514329, acc.: 77.34%] [G loss: 0.556714]\n",
      "epoch:2 step:2355 [D loss: 0.510563, acc.: 80.47%] [G loss: 0.730229]\n",
      "epoch:2 step:2356 [D loss: 0.468808, acc.: 81.25%] [G loss: 0.595528]\n",
      "epoch:2 step:2357 [D loss: 0.521489, acc.: 74.22%] [G loss: 0.576512]\n",
      "epoch:2 step:2358 [D loss: 0.402792, acc.: 87.50%] [G loss: 0.721412]\n",
      "epoch:2 step:2359 [D loss: 0.473726, acc.: 81.25%] [G loss: 0.693059]\n",
      "epoch:2 step:2360 [D loss: 0.482004, acc.: 76.56%] [G loss: 0.651790]\n",
      "epoch:2 step:2361 [D loss: 0.442709, acc.: 83.59%] [G loss: 0.642316]\n",
      "epoch:2 step:2362 [D loss: 0.419052, acc.: 86.72%] [G loss: 0.866343]\n",
      "epoch:2 step:2363 [D loss: 0.536102, acc.: 74.22%] [G loss: 0.583576]\n",
      "epoch:2 step:2364 [D loss: 0.508868, acc.: 75.78%] [G loss: 0.664816]\n",
      "epoch:2 step:2365 [D loss: 0.473119, acc.: 76.56%] [G loss: 0.708942]\n",
      "epoch:2 step:2366 [D loss: 0.545980, acc.: 75.78%] [G loss: 0.574591]\n",
      "epoch:2 step:2367 [D loss: 0.491055, acc.: 76.56%] [G loss: 0.639705]\n",
      "epoch:2 step:2368 [D loss: 0.461697, acc.: 81.25%] [G loss: 0.656743]\n",
      "epoch:2 step:2369 [D loss: 0.493605, acc.: 77.34%] [G loss: 0.632161]\n",
      "epoch:2 step:2370 [D loss: 0.545493, acc.: 71.88%] [G loss: 0.607639]\n",
      "epoch:2 step:2371 [D loss: 0.486630, acc.: 78.12%] [G loss: 0.684328]\n",
      "epoch:2 step:2372 [D loss: 0.419617, acc.: 83.59%] [G loss: 0.794275]\n",
      "epoch:2 step:2373 [D loss: 0.395621, acc.: 87.50%] [G loss: 0.834549]\n",
      "epoch:2 step:2374 [D loss: 0.625404, acc.: 65.62%] [G loss: 0.442240]\n",
      "epoch:2 step:2375 [D loss: 0.568838, acc.: 71.09%] [G loss: 0.410860]\n",
      "epoch:2 step:2376 [D loss: 0.478082, acc.: 78.12%] [G loss: 0.513297]\n",
      "epoch:2 step:2377 [D loss: 0.471575, acc.: 78.12%] [G loss: 0.599019]\n",
      "epoch:2 step:2378 [D loss: 0.450117, acc.: 83.59%] [G loss: 0.701220]\n",
      "epoch:2 step:2379 [D loss: 0.540415, acc.: 73.44%] [G loss: 0.632875]\n",
      "epoch:2 step:2380 [D loss: 0.390550, acc.: 85.16%] [G loss: 0.740571]\n",
      "epoch:2 step:2381 [D loss: 0.467903, acc.: 79.69%] [G loss: 0.675800]\n",
      "epoch:2 step:2382 [D loss: 0.417813, acc.: 82.03%] [G loss: 0.741731]\n",
      "epoch:2 step:2383 [D loss: 0.489193, acc.: 77.34%] [G loss: 0.870467]\n",
      "epoch:2 step:2384 [D loss: 0.477098, acc.: 78.91%] [G loss: 0.857777]\n",
      "epoch:2 step:2385 [D loss: 0.532630, acc.: 71.09%] [G loss: 0.553715]\n",
      "epoch:2 step:2386 [D loss: 0.525693, acc.: 75.00%] [G loss: 0.613411]\n",
      "epoch:2 step:2387 [D loss: 0.431411, acc.: 82.81%] [G loss: 0.787663]\n",
      "epoch:2 step:2388 [D loss: 0.411233, acc.: 82.81%] [G loss: 0.845414]\n",
      "epoch:2 step:2389 [D loss: 0.364384, acc.: 89.06%] [G loss: 0.984350]\n",
      "epoch:2 step:2390 [D loss: 0.468148, acc.: 78.91%] [G loss: 0.644510]\n",
      "epoch:2 step:2391 [D loss: 0.520794, acc.: 75.78%] [G loss: 0.536927]\n",
      "epoch:2 step:2392 [D loss: 0.452708, acc.: 80.47%] [G loss: 0.656884]\n",
      "epoch:2 step:2393 [D loss: 0.511187, acc.: 72.66%] [G loss: 0.623619]\n",
      "epoch:2 step:2394 [D loss: 0.436306, acc.: 84.38%] [G loss: 0.745769]\n",
      "epoch:2 step:2395 [D loss: 0.468810, acc.: 82.03%] [G loss: 0.669802]\n",
      "epoch:2 step:2396 [D loss: 0.476264, acc.: 78.91%] [G loss: 0.640048]\n",
      "epoch:2 step:2397 [D loss: 0.412418, acc.: 82.81%] [G loss: 0.779509]\n",
      "epoch:2 step:2398 [D loss: 0.484250, acc.: 76.56%] [G loss: 0.621357]\n",
      "epoch:2 step:2399 [D loss: 0.505923, acc.: 75.78%] [G loss: 0.575065]\n",
      "epoch:2 step:2400 [D loss: 0.391797, acc.: 88.28%] [G loss: 0.727941]\n",
      "epoch:2 step:2401 [D loss: 0.533734, acc.: 72.66%] [G loss: 0.600734]\n",
      "epoch:2 step:2402 [D loss: 0.510201, acc.: 77.34%] [G loss: 0.517628]\n",
      "epoch:2 step:2403 [D loss: 0.440584, acc.: 81.25%] [G loss: 0.681441]\n",
      "epoch:2 step:2404 [D loss: 0.434439, acc.: 80.47%] [G loss: 0.696749]\n",
      "epoch:2 step:2405 [D loss: 0.511361, acc.: 79.69%] [G loss: 0.614787]\n",
      "epoch:2 step:2406 [D loss: 0.480403, acc.: 78.12%] [G loss: 0.598319]\n",
      "epoch:2 step:2407 [D loss: 0.512760, acc.: 77.34%] [G loss: 0.553766]\n",
      "epoch:2 step:2408 [D loss: 0.486348, acc.: 76.56%] [G loss: 0.707032]\n",
      "epoch:2 step:2409 [D loss: 0.478767, acc.: 81.25%] [G loss: 0.690476]\n",
      "epoch:2 step:2410 [D loss: 0.396013, acc.: 85.94%] [G loss: 0.897177]\n",
      "epoch:2 step:2411 [D loss: 0.556611, acc.: 71.88%] [G loss: 0.617942]\n",
      "epoch:2 step:2412 [D loss: 0.543004, acc.: 72.66%] [G loss: 0.591990]\n",
      "epoch:2 step:2413 [D loss: 0.508060, acc.: 77.34%] [G loss: 0.537196]\n",
      "epoch:2 step:2414 [D loss: 0.487385, acc.: 78.12%] [G loss: 0.562012]\n",
      "epoch:2 step:2415 [D loss: 0.423103, acc.: 87.50%] [G loss: 0.716155]\n",
      "epoch:2 step:2416 [D loss: 0.527683, acc.: 73.44%] [G loss: 0.623905]\n",
      "epoch:2 step:2417 [D loss: 0.556204, acc.: 72.66%] [G loss: 0.493268]\n",
      "epoch:2 step:2418 [D loss: 0.472866, acc.: 80.47%] [G loss: 0.622787]\n",
      "epoch:2 step:2419 [D loss: 0.474099, acc.: 79.69%] [G loss: 0.801045]\n",
      "epoch:2 step:2420 [D loss: 0.398904, acc.: 85.16%] [G loss: 0.852985]\n",
      "epoch:2 step:2421 [D loss: 0.389596, acc.: 87.50%] [G loss: 1.035590]\n",
      "epoch:2 step:2422 [D loss: 0.472353, acc.: 78.12%] [G loss: 0.776372]\n",
      "epoch:2 step:2423 [D loss: 0.454855, acc.: 78.91%] [G loss: 0.693720]\n",
      "epoch:2 step:2424 [D loss: 0.459557, acc.: 82.03%] [G loss: 0.745862]\n",
      "epoch:2 step:2425 [D loss: 0.460925, acc.: 81.25%] [G loss: 0.710074]\n",
      "epoch:2 step:2426 [D loss: 0.452193, acc.: 79.69%] [G loss: 0.714305]\n",
      "epoch:2 step:2427 [D loss: 0.440857, acc.: 85.16%] [G loss: 0.649866]\n",
      "epoch:2 step:2428 [D loss: 0.403859, acc.: 84.38%] [G loss: 0.829712]\n",
      "epoch:2 step:2429 [D loss: 0.432950, acc.: 82.81%] [G loss: 0.679813]\n",
      "epoch:2 step:2430 [D loss: 0.387831, acc.: 86.72%] [G loss: 0.859480]\n",
      "epoch:2 step:2431 [D loss: 0.435071, acc.: 82.81%] [G loss: 0.777779]\n",
      "epoch:2 step:2432 [D loss: 0.438053, acc.: 80.47%] [G loss: 0.684955]\n",
      "epoch:2 step:2433 [D loss: 0.521073, acc.: 80.47%] [G loss: 0.610131]\n",
      "epoch:2 step:2434 [D loss: 0.488949, acc.: 81.25%] [G loss: 0.652796]\n",
      "epoch:2 step:2435 [D loss: 0.453861, acc.: 84.38%] [G loss: 0.692401]\n",
      "epoch:2 step:2436 [D loss: 0.508252, acc.: 81.25%] [G loss: 0.643074]\n",
      "epoch:2 step:2437 [D loss: 0.445857, acc.: 84.38%] [G loss: 0.632367]\n",
      "epoch:2 step:2438 [D loss: 0.522124, acc.: 75.78%] [G loss: 0.680467]\n",
      "epoch:2 step:2439 [D loss: 0.426689, acc.: 85.16%] [G loss: 0.648419]\n",
      "epoch:2 step:2440 [D loss: 0.440223, acc.: 82.81%] [G loss: 0.721511]\n",
      "epoch:2 step:2441 [D loss: 0.398681, acc.: 88.28%] [G loss: 0.689446]\n",
      "epoch:2 step:2442 [D loss: 0.462902, acc.: 81.25%] [G loss: 0.631755]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:2 step:2443 [D loss: 0.455213, acc.: 78.91%] [G loss: 0.650190]\n",
      "epoch:2 step:2444 [D loss: 0.416286, acc.: 83.59%] [G loss: 0.703385]\n",
      "epoch:2 step:2445 [D loss: 0.456724, acc.: 78.91%] [G loss: 0.731945]\n",
      "epoch:2 step:2446 [D loss: 0.450394, acc.: 77.34%] [G loss: 0.716654]\n",
      "epoch:2 step:2447 [D loss: 0.408988, acc.: 86.72%] [G loss: 0.771559]\n",
      "epoch:2 step:2448 [D loss: 0.418427, acc.: 83.59%] [G loss: 0.799550]\n",
      "epoch:2 step:2449 [D loss: 0.388609, acc.: 82.81%] [G loss: 0.892072]\n",
      "epoch:2 step:2450 [D loss: 0.471752, acc.: 81.25%] [G loss: 0.773406]\n",
      "epoch:2 step:2451 [D loss: 0.435595, acc.: 78.91%] [G loss: 0.795658]\n",
      "epoch:2 step:2452 [D loss: 0.413898, acc.: 85.16%] [G loss: 0.825050]\n",
      "epoch:2 step:2453 [D loss: 0.444364, acc.: 80.47%] [G loss: 0.743494]\n",
      "epoch:2 step:2454 [D loss: 0.481272, acc.: 79.69%] [G loss: 0.790810]\n",
      "epoch:2 step:2455 [D loss: 0.485515, acc.: 79.69%] [G loss: 0.823249]\n",
      "epoch:2 step:2456 [D loss: 0.362545, acc.: 87.50%] [G loss: 1.036980]\n",
      "epoch:2 step:2457 [D loss: 0.489160, acc.: 78.12%] [G loss: 0.747519]\n",
      "epoch:2 step:2458 [D loss: 0.520603, acc.: 75.78%] [G loss: 0.648104]\n",
      "epoch:2 step:2459 [D loss: 0.513546, acc.: 71.09%] [G loss: 0.547127]\n",
      "epoch:2 step:2460 [D loss: 0.507487, acc.: 78.91%] [G loss: 0.633295]\n",
      "epoch:2 step:2461 [D loss: 0.504511, acc.: 76.56%] [G loss: 0.529862]\n",
      "epoch:2 step:2462 [D loss: 0.503848, acc.: 77.34%] [G loss: 0.642009]\n",
      "epoch:2 step:2463 [D loss: 0.441944, acc.: 83.59%] [G loss: 0.729630]\n",
      "epoch:2 step:2464 [D loss: 0.470168, acc.: 81.25%] [G loss: 0.725055]\n",
      "epoch:2 step:2465 [D loss: 0.482863, acc.: 82.03%] [G loss: 0.624983]\n",
      "epoch:2 step:2466 [D loss: 0.447202, acc.: 82.03%] [G loss: 0.777109]\n",
      "epoch:2 step:2467 [D loss: 0.508353, acc.: 78.91%] [G loss: 0.649763]\n",
      "epoch:2 step:2468 [D loss: 0.451381, acc.: 78.91%] [G loss: 0.759121]\n",
      "epoch:2 step:2469 [D loss: 0.461048, acc.: 82.03%] [G loss: 0.737531]\n",
      "epoch:2 step:2470 [D loss: 0.464433, acc.: 82.81%] [G loss: 0.658468]\n",
      "epoch:2 step:2471 [D loss: 0.466502, acc.: 80.47%] [G loss: 0.599008]\n",
      "epoch:2 step:2472 [D loss: 0.464436, acc.: 76.56%] [G loss: 0.724556]\n",
      "epoch:2 step:2473 [D loss: 0.487011, acc.: 76.56%] [G loss: 0.745630]\n",
      "epoch:2 step:2474 [D loss: 0.469279, acc.: 81.25%] [G loss: 0.655478]\n",
      "epoch:2 step:2475 [D loss: 0.468439, acc.: 83.59%] [G loss: 0.591383]\n",
      "epoch:2 step:2476 [D loss: 0.412055, acc.: 87.50%] [G loss: 0.751398]\n",
      "epoch:2 step:2477 [D loss: 0.417735, acc.: 85.16%] [G loss: 0.668407]\n",
      "epoch:2 step:2478 [D loss: 0.508932, acc.: 78.91%] [G loss: 0.645173]\n",
      "epoch:2 step:2479 [D loss: 0.514453, acc.: 80.47%] [G loss: 0.629102]\n",
      "epoch:2 step:2480 [D loss: 0.445422, acc.: 80.47%] [G loss: 0.724180]\n",
      "epoch:2 step:2481 [D loss: 0.487327, acc.: 79.69%] [G loss: 0.662110]\n",
      "epoch:2 step:2482 [D loss: 0.454054, acc.: 82.81%] [G loss: 0.621149]\n",
      "epoch:2 step:2483 [D loss: 0.413083, acc.: 84.38%] [G loss: 0.780992]\n",
      "epoch:2 step:2484 [D loss: 0.491413, acc.: 77.34%] [G loss: 0.706334]\n",
      "epoch:2 step:2485 [D loss: 0.398302, acc.: 84.38%] [G loss: 0.720454]\n",
      "epoch:2 step:2486 [D loss: 0.444295, acc.: 82.81%] [G loss: 0.714083]\n",
      "epoch:2 step:2487 [D loss: 0.440076, acc.: 82.81%] [G loss: 0.715016]\n",
      "epoch:2 step:2488 [D loss: 0.429457, acc.: 84.38%] [G loss: 0.964466]\n",
      "epoch:2 step:2489 [D loss: 0.525491, acc.: 74.22%] [G loss: 0.578600]\n",
      "epoch:2 step:2490 [D loss: 0.510808, acc.: 75.78%] [G loss: 0.864739]\n",
      "epoch:2 step:2491 [D loss: 0.541147, acc.: 74.22%] [G loss: 0.786139]\n",
      "epoch:2 step:2492 [D loss: 0.490908, acc.: 76.56%] [G loss: 0.639465]\n",
      "epoch:2 step:2493 [D loss: 0.460559, acc.: 81.25%] [G loss: 0.668542]\n",
      "epoch:2 step:2494 [D loss: 0.457687, acc.: 80.47%] [G loss: 0.694479]\n",
      "epoch:2 step:2495 [D loss: 0.477259, acc.: 79.69%] [G loss: 0.560356]\n",
      "epoch:2 step:2496 [D loss: 0.629198, acc.: 63.28%] [G loss: 0.434509]\n",
      "epoch:2 step:2497 [D loss: 0.494842, acc.: 78.91%] [G loss: 0.715129]\n",
      "epoch:2 step:2498 [D loss: 0.433574, acc.: 80.47%] [G loss: 0.917475]\n",
      "epoch:2 step:2499 [D loss: 0.528412, acc.: 71.09%] [G loss: 0.618548]\n",
      "epoch:2 step:2500 [D loss: 0.492432, acc.: 76.56%] [G loss: 0.643261]\n",
      "epoch:2 step:2501 [D loss: 0.444456, acc.: 78.91%] [G loss: 0.768708]\n",
      "epoch:2 step:2502 [D loss: 0.448551, acc.: 78.12%] [G loss: 0.838300]\n",
      "epoch:2 step:2503 [D loss: 0.468089, acc.: 80.47%] [G loss: 0.720818]\n",
      "epoch:2 step:2504 [D loss: 0.470656, acc.: 78.12%] [G loss: 0.821550]\n",
      "epoch:2 step:2505 [D loss: 0.432295, acc.: 81.25%] [G loss: 0.744093]\n",
      "epoch:2 step:2506 [D loss: 0.445831, acc.: 81.25%] [G loss: 0.822611]\n",
      "epoch:2 step:2507 [D loss: 0.438163, acc.: 84.38%] [G loss: 0.829175]\n",
      "epoch:2 step:2508 [D loss: 0.466776, acc.: 79.69%] [G loss: 0.717342]\n",
      "epoch:2 step:2509 [D loss: 0.477464, acc.: 79.69%] [G loss: 0.747657]\n",
      "epoch:2 step:2510 [D loss: 0.563025, acc.: 75.78%] [G loss: 0.671889]\n",
      "epoch:2 step:2511 [D loss: 0.543146, acc.: 75.00%] [G loss: 0.529709]\n",
      "epoch:2 step:2512 [D loss: 0.440442, acc.: 83.59%] [G loss: 0.690767]\n",
      "epoch:2 step:2513 [D loss: 0.374747, acc.: 84.38%] [G loss: 0.911152]\n",
      "epoch:2 step:2514 [D loss: 0.421927, acc.: 88.28%] [G loss: 0.766433]\n",
      "epoch:2 step:2515 [D loss: 0.410939, acc.: 82.81%] [G loss: 0.694076]\n",
      "epoch:2 step:2516 [D loss: 0.412929, acc.: 82.81%] [G loss: 0.818195]\n",
      "epoch:2 step:2517 [D loss: 0.508762, acc.: 75.78%] [G loss: 0.597860]\n",
      "epoch:2 step:2518 [D loss: 0.485171, acc.: 79.69%] [G loss: 0.587934]\n",
      "epoch:2 step:2519 [D loss: 0.507264, acc.: 75.00%] [G loss: 0.701659]\n",
      "epoch:2 step:2520 [D loss: 0.505188, acc.: 76.56%] [G loss: 0.825653]\n",
      "epoch:2 step:2521 [D loss: 0.543123, acc.: 75.00%] [G loss: 0.657601]\n",
      "epoch:2 step:2522 [D loss: 0.430069, acc.: 81.25%] [G loss: 0.859861]\n",
      "epoch:2 step:2523 [D loss: 0.399796, acc.: 87.50%] [G loss: 0.827674]\n",
      "epoch:2 step:2524 [D loss: 0.460097, acc.: 78.91%] [G loss: 0.769778]\n",
      "epoch:2 step:2525 [D loss: 0.492530, acc.: 74.22%] [G loss: 0.929034]\n",
      "epoch:2 step:2526 [D loss: 0.518915, acc.: 75.78%] [G loss: 0.661585]\n",
      "epoch:2 step:2527 [D loss: 0.575870, acc.: 67.19%] [G loss: 0.458838]\n",
      "epoch:2 step:2528 [D loss: 0.476065, acc.: 77.34%] [G loss: 0.632794]\n",
      "epoch:2 step:2529 [D loss: 0.463385, acc.: 82.81%] [G loss: 0.652477]\n",
      "epoch:2 step:2530 [D loss: 0.502294, acc.: 76.56%] [G loss: 0.647223]\n",
      "epoch:2 step:2531 [D loss: 0.462471, acc.: 78.91%] [G loss: 0.661353]\n",
      "epoch:2 step:2532 [D loss: 0.482953, acc.: 82.03%] [G loss: 0.658344]\n",
      "epoch:2 step:2533 [D loss: 0.451497, acc.: 80.47%] [G loss: 0.741509]\n",
      "epoch:2 step:2534 [D loss: 0.516551, acc.: 77.34%] [G loss: 0.640095]\n",
      "epoch:2 step:2535 [D loss: 0.413435, acc.: 82.03%] [G loss: 0.711552]\n",
      "epoch:2 step:2536 [D loss: 0.652166, acc.: 64.06%] [G loss: 0.524200]\n",
      "epoch:2 step:2537 [D loss: 0.499391, acc.: 72.66%] [G loss: 0.644931]\n",
      "epoch:2 step:2538 [D loss: 0.517875, acc.: 75.00%] [G loss: 0.754249]\n",
      "epoch:2 step:2539 [D loss: 0.424316, acc.: 84.38%] [G loss: 0.869630]\n",
      "epoch:2 step:2540 [D loss: 0.532649, acc.: 73.44%] [G loss: 0.836983]\n",
      "epoch:2 step:2541 [D loss: 0.479647, acc.: 81.25%] [G loss: 0.744354]\n",
      "epoch:2 step:2542 [D loss: 0.516816, acc.: 73.44%] [G loss: 0.666143]\n",
      "epoch:2 step:2543 [D loss: 0.429139, acc.: 85.94%] [G loss: 0.660384]\n",
      "epoch:2 step:2544 [D loss: 0.411709, acc.: 83.59%] [G loss: 0.804222]\n",
      "epoch:2 step:2545 [D loss: 0.499199, acc.: 77.34%] [G loss: 0.671176]\n",
      "epoch:2 step:2546 [D loss: 0.575466, acc.: 71.88%] [G loss: 0.627870]\n",
      "epoch:2 step:2547 [D loss: 0.537502, acc.: 74.22%] [G loss: 0.563493]\n",
      "epoch:2 step:2548 [D loss: 0.569613, acc.: 71.88%] [G loss: 0.563142]\n",
      "epoch:2 step:2549 [D loss: 0.456986, acc.: 80.47%] [G loss: 0.692726]\n",
      "epoch:2 step:2550 [D loss: 0.512941, acc.: 75.00%] [G loss: 0.623674]\n",
      "epoch:2 step:2551 [D loss: 0.381931, acc.: 88.28%] [G loss: 0.827805]\n",
      "epoch:2 step:2552 [D loss: 0.432816, acc.: 84.38%] [G loss: 0.827960]\n",
      "epoch:2 step:2553 [D loss: 0.479425, acc.: 82.81%] [G loss: 0.700212]\n",
      "epoch:2 step:2554 [D loss: 0.432458, acc.: 85.16%] [G loss: 0.618331]\n",
      "epoch:2 step:2555 [D loss: 0.444236, acc.: 84.38%] [G loss: 0.613373]\n",
      "epoch:2 step:2556 [D loss: 0.456581, acc.: 85.94%] [G loss: 0.735967]\n",
      "epoch:2 step:2557 [D loss: 0.512679, acc.: 77.34%] [G loss: 0.652239]\n",
      "epoch:2 step:2558 [D loss: 0.488439, acc.: 78.12%] [G loss: 0.584622]\n",
      "epoch:2 step:2559 [D loss: 0.503459, acc.: 79.69%] [G loss: 0.597521]\n",
      "epoch:2 step:2560 [D loss: 0.464241, acc.: 80.47%] [G loss: 0.695795]\n",
      "epoch:2 step:2561 [D loss: 0.476598, acc.: 77.34%] [G loss: 0.602814]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:2 step:2562 [D loss: 0.533504, acc.: 72.66%] [G loss: 0.657856]\n",
      "epoch:2 step:2563 [D loss: 0.504670, acc.: 78.91%] [G loss: 0.722698]\n",
      "epoch:2 step:2564 [D loss: 0.480235, acc.: 81.25%] [G loss: 0.697078]\n",
      "epoch:2 step:2565 [D loss: 0.477743, acc.: 79.69%] [G loss: 0.685529]\n",
      "epoch:2 step:2566 [D loss: 0.482894, acc.: 81.25%] [G loss: 0.670655]\n",
      "epoch:2 step:2567 [D loss: 0.491384, acc.: 79.69%] [G loss: 0.579474]\n",
      "epoch:2 step:2568 [D loss: 0.433096, acc.: 82.03%] [G loss: 0.691750]\n",
      "epoch:2 step:2569 [D loss: 0.438393, acc.: 84.38%] [G loss: 0.914057]\n",
      "epoch:2 step:2570 [D loss: 0.542521, acc.: 77.34%] [G loss: 0.514098]\n",
      "epoch:2 step:2571 [D loss: 0.486873, acc.: 78.12%] [G loss: 0.573776]\n",
      "epoch:2 step:2572 [D loss: 0.524418, acc.: 70.31%] [G loss: 0.631630]\n",
      "epoch:2 step:2573 [D loss: 0.520342, acc.: 75.78%] [G loss: 0.644020]\n",
      "epoch:2 step:2574 [D loss: 0.513648, acc.: 73.44%] [G loss: 0.697020]\n",
      "epoch:2 step:2575 [D loss: 0.513090, acc.: 75.78%] [G loss: 0.665218]\n",
      "epoch:2 step:2576 [D loss: 0.470809, acc.: 79.69%] [G loss: 0.719014]\n",
      "epoch:2 step:2577 [D loss: 0.427385, acc.: 89.06%] [G loss: 0.595354]\n",
      "epoch:2 step:2578 [D loss: 0.515730, acc.: 73.44%] [G loss: 0.603339]\n",
      "epoch:2 step:2579 [D loss: 0.486245, acc.: 73.44%] [G loss: 0.665152]\n",
      "epoch:2 step:2580 [D loss: 0.469460, acc.: 78.12%] [G loss: 0.837515]\n",
      "epoch:2 step:2581 [D loss: 0.361892, acc.: 90.62%] [G loss: 0.873787]\n",
      "epoch:2 step:2582 [D loss: 0.364518, acc.: 88.28%] [G loss: 1.062394]\n",
      "epoch:2 step:2583 [D loss: 0.407761, acc.: 82.81%] [G loss: 0.912412]\n",
      "epoch:2 step:2584 [D loss: 0.646388, acc.: 69.53%] [G loss: 0.593202]\n",
      "epoch:2 step:2585 [D loss: 0.631169, acc.: 59.38%] [G loss: 0.572608]\n",
      "epoch:2 step:2586 [D loss: 0.466863, acc.: 77.34%] [G loss: 0.882501]\n",
      "epoch:2 step:2587 [D loss: 0.518280, acc.: 75.00%] [G loss: 0.492204]\n",
      "epoch:2 step:2588 [D loss: 0.460690, acc.: 79.69%] [G loss: 0.589859]\n",
      "epoch:2 step:2589 [D loss: 0.467211, acc.: 77.34%] [G loss: 0.741850]\n",
      "epoch:2 step:2590 [D loss: 0.518410, acc.: 78.12%] [G loss: 0.634291]\n",
      "epoch:2 step:2591 [D loss: 0.581252, acc.: 67.19%] [G loss: 0.443648]\n",
      "epoch:2 step:2592 [D loss: 0.493702, acc.: 77.34%] [G loss: 0.597082]\n",
      "epoch:2 step:2593 [D loss: 0.483831, acc.: 80.47%] [G loss: 0.612669]\n",
      "epoch:2 step:2594 [D loss: 0.503198, acc.: 77.34%] [G loss: 0.598875]\n",
      "epoch:2 step:2595 [D loss: 0.482910, acc.: 75.78%] [G loss: 0.707267]\n",
      "epoch:2 step:2596 [D loss: 0.476688, acc.: 79.69%] [G loss: 0.653776]\n",
      "epoch:2 step:2597 [D loss: 0.525261, acc.: 75.78%] [G loss: 0.491397]\n",
      "epoch:2 step:2598 [D loss: 0.550119, acc.: 73.44%] [G loss: 0.446850]\n",
      "epoch:2 step:2599 [D loss: 0.449820, acc.: 85.16%] [G loss: 0.699158]\n",
      "epoch:2 step:2600 [D loss: 0.481517, acc.: 77.34%] [G loss: 0.697698]\n",
      "epoch:2 step:2601 [D loss: 0.526085, acc.: 75.00%] [G loss: 0.506404]\n",
      "epoch:2 step:2602 [D loss: 0.536031, acc.: 70.31%] [G loss: 0.565929]\n",
      "epoch:2 step:2603 [D loss: 0.458278, acc.: 82.03%] [G loss: 0.614696]\n",
      "epoch:2 step:2604 [D loss: 0.478917, acc.: 80.47%] [G loss: 0.678574]\n",
      "epoch:2 step:2605 [D loss: 0.456840, acc.: 78.12%] [G loss: 0.673891]\n",
      "epoch:2 step:2606 [D loss: 0.411400, acc.: 87.50%] [G loss: 0.680163]\n",
      "epoch:2 step:2607 [D loss: 0.446838, acc.: 82.81%] [G loss: 0.692027]\n",
      "epoch:2 step:2608 [D loss: 0.422957, acc.: 82.81%] [G loss: 0.786102]\n",
      "epoch:2 step:2609 [D loss: 0.548994, acc.: 74.22%] [G loss: 0.712592]\n",
      "epoch:2 step:2610 [D loss: 0.475547, acc.: 77.34%] [G loss: 0.693865]\n",
      "epoch:2 step:2611 [D loss: 0.471742, acc.: 77.34%] [G loss: 0.743886]\n",
      "epoch:2 step:2612 [D loss: 0.511326, acc.: 77.34%] [G loss: 0.540887]\n",
      "epoch:2 step:2613 [D loss: 0.532944, acc.: 70.31%] [G loss: 0.541681]\n",
      "epoch:2 step:2614 [D loss: 0.490623, acc.: 78.12%] [G loss: 0.595581]\n",
      "epoch:2 step:2615 [D loss: 0.543007, acc.: 67.97%] [G loss: 0.585754]\n",
      "epoch:2 step:2616 [D loss: 0.605902, acc.: 67.19%] [G loss: 0.566145]\n",
      "epoch:2 step:2617 [D loss: 0.511440, acc.: 75.78%] [G loss: 0.574290]\n",
      "epoch:2 step:2618 [D loss: 0.486028, acc.: 76.56%] [G loss: 0.653895]\n",
      "epoch:2 step:2619 [D loss: 0.527663, acc.: 71.88%] [G loss: 0.517604]\n",
      "epoch:2 step:2620 [D loss: 0.380223, acc.: 86.72%] [G loss: 0.856807]\n",
      "epoch:2 step:2621 [D loss: 0.356935, acc.: 86.72%] [G loss: 0.894925]\n",
      "epoch:2 step:2622 [D loss: 0.400802, acc.: 84.38%] [G loss: 0.880229]\n",
      "epoch:2 step:2623 [D loss: 0.527558, acc.: 72.66%] [G loss: 0.659015]\n",
      "epoch:2 step:2624 [D loss: 0.458469, acc.: 78.12%] [G loss: 0.641615]\n",
      "epoch:2 step:2625 [D loss: 0.462073, acc.: 81.25%] [G loss: 0.653850]\n",
      "epoch:2 step:2626 [D loss: 0.439437, acc.: 81.25%] [G loss: 0.649777]\n",
      "epoch:2 step:2627 [D loss: 0.427645, acc.: 82.81%] [G loss: 0.737204]\n",
      "epoch:2 step:2628 [D loss: 0.437472, acc.: 80.47%] [G loss: 0.844873]\n",
      "epoch:2 step:2629 [D loss: 0.402187, acc.: 87.50%] [G loss: 0.831783]\n",
      "epoch:2 step:2630 [D loss: 0.471886, acc.: 78.12%] [G loss: 0.797166]\n",
      "epoch:2 step:2631 [D loss: 0.420956, acc.: 85.16%] [G loss: 0.765428]\n",
      "epoch:2 step:2632 [D loss: 0.507206, acc.: 75.00%] [G loss: 0.771235]\n",
      "epoch:2 step:2633 [D loss: 0.473469, acc.: 78.91%] [G loss: 0.676125]\n",
      "epoch:2 step:2634 [D loss: 0.455464, acc.: 78.12%] [G loss: 0.699430]\n",
      "epoch:2 step:2635 [D loss: 0.485040, acc.: 77.34%] [G loss: 0.688525]\n",
      "epoch:2 step:2636 [D loss: 0.420935, acc.: 82.03%] [G loss: 0.784880]\n",
      "epoch:2 step:2637 [D loss: 0.488002, acc.: 76.56%] [G loss: 0.643383]\n",
      "epoch:2 step:2638 [D loss: 0.461235, acc.: 80.47%] [G loss: 0.744456]\n",
      "epoch:2 step:2639 [D loss: 0.597567, acc.: 71.09%] [G loss: 0.616110]\n",
      "epoch:2 step:2640 [D loss: 0.565390, acc.: 70.31%] [G loss: 0.615630]\n",
      "epoch:2 step:2641 [D loss: 0.563256, acc.: 68.75%] [G loss: 0.540463]\n",
      "epoch:2 step:2642 [D loss: 0.501455, acc.: 79.69%] [G loss: 0.782411]\n",
      "epoch:2 step:2643 [D loss: 0.447348, acc.: 79.69%] [G loss: 0.830666]\n",
      "epoch:2 step:2644 [D loss: 0.481197, acc.: 76.56%] [G loss: 0.766628]\n",
      "epoch:2 step:2645 [D loss: 0.512159, acc.: 75.00%] [G loss: 0.661220]\n",
      "epoch:2 step:2646 [D loss: 0.449707, acc.: 82.03%] [G loss: 0.699691]\n",
      "epoch:2 step:2647 [D loss: 0.463300, acc.: 82.81%] [G loss: 0.844836]\n",
      "epoch:2 step:2648 [D loss: 0.569924, acc.: 71.09%] [G loss: 0.546909]\n",
      "epoch:2 step:2649 [D loss: 0.430898, acc.: 84.38%] [G loss: 0.599996]\n",
      "epoch:2 step:2650 [D loss: 0.495270, acc.: 78.91%] [G loss: 0.565880]\n",
      "epoch:2 step:2651 [D loss: 0.413945, acc.: 86.72%] [G loss: 0.775947]\n",
      "epoch:2 step:2652 [D loss: 0.527085, acc.: 71.88%] [G loss: 0.610396]\n",
      "epoch:2 step:2653 [D loss: 0.484587, acc.: 78.12%] [G loss: 0.716034]\n",
      "epoch:2 step:2654 [D loss: 0.448471, acc.: 81.25%] [G loss: 1.018932]\n",
      "epoch:2 step:2655 [D loss: 0.413449, acc.: 82.03%] [G loss: 1.015508]\n",
      "epoch:2 step:2656 [D loss: 0.461937, acc.: 82.03%] [G loss: 0.998787]\n",
      "epoch:2 step:2657 [D loss: 0.491667, acc.: 74.22%] [G loss: 0.605083]\n",
      "epoch:2 step:2658 [D loss: 0.453806, acc.: 80.47%] [G loss: 0.689110]\n",
      "epoch:2 step:2659 [D loss: 0.479383, acc.: 78.91%] [G loss: 0.771010]\n",
      "epoch:2 step:2660 [D loss: 0.455320, acc.: 79.69%] [G loss: 0.754563]\n",
      "epoch:2 step:2661 [D loss: 0.529827, acc.: 73.44%] [G loss: 0.685775]\n",
      "epoch:2 step:2662 [D loss: 0.588574, acc.: 67.97%] [G loss: 0.592607]\n",
      "epoch:2 step:2663 [D loss: 0.434528, acc.: 86.72%] [G loss: 0.695609]\n",
      "epoch:2 step:2664 [D loss: 0.437654, acc.: 80.47%] [G loss: 0.841068]\n",
      "epoch:2 step:2665 [D loss: 0.452279, acc.: 83.59%] [G loss: 0.686331]\n",
      "epoch:2 step:2666 [D loss: 0.410021, acc.: 85.94%] [G loss: 0.732168]\n",
      "epoch:2 step:2667 [D loss: 0.506228, acc.: 78.91%] [G loss: 0.545269]\n",
      "epoch:2 step:2668 [D loss: 0.531307, acc.: 73.44%] [G loss: 0.575224]\n",
      "epoch:2 step:2669 [D loss: 0.425508, acc.: 82.03%] [G loss: 0.692236]\n",
      "epoch:2 step:2670 [D loss: 0.425572, acc.: 85.16%] [G loss: 0.740536]\n",
      "epoch:2 step:2671 [D loss: 0.466018, acc.: 81.25%] [G loss: 0.595113]\n",
      "epoch:2 step:2672 [D loss: 0.397508, acc.: 85.94%] [G loss: 0.862736]\n",
      "epoch:2 step:2673 [D loss: 0.474605, acc.: 79.69%] [G loss: 0.776000]\n",
      "epoch:2 step:2674 [D loss: 0.456501, acc.: 83.59%] [G loss: 0.707826]\n",
      "epoch:2 step:2675 [D loss: 0.441516, acc.: 81.25%] [G loss: 0.758561]\n",
      "epoch:2 step:2676 [D loss: 0.408600, acc.: 78.91%] [G loss: 1.114940]\n",
      "epoch:2 step:2677 [D loss: 0.432315, acc.: 82.03%] [G loss: 0.933605]\n",
      "epoch:2 step:2678 [D loss: 0.484926, acc.: 79.69%] [G loss: 0.797124]\n",
      "epoch:2 step:2679 [D loss: 0.474220, acc.: 80.47%] [G loss: 0.685644]\n",
      "epoch:2 step:2680 [D loss: 0.439755, acc.: 82.03%] [G loss: 0.709537]\n",
      "epoch:2 step:2681 [D loss: 0.470177, acc.: 78.91%] [G loss: 0.843741]\n",
      "epoch:2 step:2682 [D loss: 0.563964, acc.: 69.53%] [G loss: 0.524528]\n",
      "epoch:2 step:2683 [D loss: 0.518330, acc.: 76.56%] [G loss: 0.486387]\n",
      "epoch:2 step:2684 [D loss: 0.429968, acc.: 85.94%] [G loss: 0.714117]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:2 step:2685 [D loss: 0.456773, acc.: 82.03%] [G loss: 0.683974]\n",
      "epoch:2 step:2686 [D loss: 0.498494, acc.: 77.34%] [G loss: 0.744726]\n",
      "epoch:2 step:2687 [D loss: 0.511484, acc.: 72.66%] [G loss: 0.697322]\n",
      "epoch:2 step:2688 [D loss: 0.494027, acc.: 77.34%] [G loss: 0.682841]\n",
      "epoch:2 step:2689 [D loss: 0.514083, acc.: 73.44%] [G loss: 0.581993]\n",
      "epoch:2 step:2690 [D loss: 0.468358, acc.: 82.03%] [G loss: 0.626120]\n",
      "epoch:2 step:2691 [D loss: 0.497422, acc.: 75.00%] [G loss: 0.816659]\n",
      "epoch:2 step:2692 [D loss: 0.524364, acc.: 71.09%] [G loss: 0.595433]\n",
      "epoch:2 step:2693 [D loss: 0.467490, acc.: 78.12%] [G loss: 0.888789]\n",
      "epoch:2 step:2694 [D loss: 0.474241, acc.: 78.91%] [G loss: 0.862894]\n",
      "epoch:2 step:2695 [D loss: 0.473510, acc.: 78.91%] [G loss: 0.706589]\n",
      "epoch:2 step:2696 [D loss: 0.361617, acc.: 89.84%] [G loss: 0.996957]\n",
      "epoch:2 step:2697 [D loss: 0.399078, acc.: 84.38%] [G loss: 0.846938]\n",
      "epoch:2 step:2698 [D loss: 0.603054, acc.: 70.31%] [G loss: 0.579238]\n",
      "epoch:2 step:2699 [D loss: 0.508655, acc.: 76.56%] [G loss: 0.559209]\n",
      "epoch:2 step:2700 [D loss: 0.523513, acc.: 76.56%] [G loss: 0.654468]\n",
      "epoch:2 step:2701 [D loss: 0.534693, acc.: 74.22%] [G loss: 0.569373]\n",
      "epoch:2 step:2702 [D loss: 0.526418, acc.: 73.44%] [G loss: 0.611911]\n",
      "epoch:2 step:2703 [D loss: 0.437561, acc.: 82.03%] [G loss: 0.795524]\n",
      "epoch:2 step:2704 [D loss: 0.443251, acc.: 80.47%] [G loss: 0.741526]\n",
      "epoch:2 step:2705 [D loss: 0.502697, acc.: 73.44%] [G loss: 0.650220]\n",
      "epoch:2 step:2706 [D loss: 0.436471, acc.: 81.25%] [G loss: 0.823186]\n",
      "epoch:2 step:2707 [D loss: 0.415944, acc.: 86.72%] [G loss: 0.816858]\n",
      "epoch:2 step:2708 [D loss: 0.434180, acc.: 81.25%] [G loss: 0.790173]\n",
      "epoch:2 step:2709 [D loss: 0.504998, acc.: 76.56%] [G loss: 0.679259]\n",
      "epoch:2 step:2710 [D loss: 0.489232, acc.: 79.69%] [G loss: 0.675896]\n",
      "epoch:2 step:2711 [D loss: 0.495817, acc.: 76.56%] [G loss: 0.673046]\n",
      "epoch:2 step:2712 [D loss: 0.473573, acc.: 78.12%] [G loss: 0.652843]\n",
      "epoch:2 step:2713 [D loss: 0.488478, acc.: 77.34%] [G loss: 0.712236]\n",
      "epoch:2 step:2714 [D loss: 0.536900, acc.: 68.75%] [G loss: 0.565102]\n",
      "epoch:2 step:2715 [D loss: 0.398457, acc.: 85.16%] [G loss: 0.836568]\n",
      "epoch:2 step:2716 [D loss: 0.413839, acc.: 85.16%] [G loss: 0.841170]\n",
      "epoch:2 step:2717 [D loss: 0.529038, acc.: 75.78%] [G loss: 0.671666]\n",
      "epoch:2 step:2718 [D loss: 0.587976, acc.: 71.88%] [G loss: 0.433321]\n",
      "epoch:2 step:2719 [D loss: 0.529476, acc.: 73.44%] [G loss: 0.562918]\n",
      "epoch:2 step:2720 [D loss: 0.443910, acc.: 79.69%] [G loss: 0.715558]\n",
      "epoch:2 step:2721 [D loss: 0.493181, acc.: 75.00%] [G loss: 0.792060]\n",
      "epoch:2 step:2722 [D loss: 0.413434, acc.: 85.94%] [G loss: 0.788828]\n",
      "epoch:2 step:2723 [D loss: 0.526533, acc.: 78.12%] [G loss: 0.550893]\n",
      "epoch:2 step:2724 [D loss: 0.487188, acc.: 78.91%] [G loss: 0.590724]\n",
      "epoch:2 step:2725 [D loss: 0.523730, acc.: 71.88%] [G loss: 0.636773]\n",
      "epoch:2 step:2726 [D loss: 0.440097, acc.: 81.25%] [G loss: 0.740047]\n",
      "epoch:2 step:2727 [D loss: 0.477705, acc.: 77.34%] [G loss: 0.811183]\n",
      "epoch:2 step:2728 [D loss: 0.392045, acc.: 85.16%] [G loss: 0.921311]\n",
      "epoch:2 step:2729 [D loss: 0.447018, acc.: 83.59%] [G loss: 0.727730]\n",
      "epoch:2 step:2730 [D loss: 0.470095, acc.: 81.25%] [G loss: 0.858295]\n",
      "epoch:2 step:2731 [D loss: 0.459335, acc.: 78.91%] [G loss: 0.806669]\n",
      "epoch:2 step:2732 [D loss: 0.643857, acc.: 64.84%] [G loss: 0.713489]\n",
      "epoch:2 step:2733 [D loss: 0.515144, acc.: 76.56%] [G loss: 0.700187]\n",
      "epoch:2 step:2734 [D loss: 0.444159, acc.: 82.81%] [G loss: 0.762716]\n",
      "epoch:2 step:2735 [D loss: 0.522425, acc.: 75.78%] [G loss: 0.731701]\n",
      "epoch:2 step:2736 [D loss: 0.418841, acc.: 85.94%] [G loss: 0.738924]\n",
      "epoch:2 step:2737 [D loss: 0.485563, acc.: 76.56%] [G loss: 0.632023]\n",
      "epoch:2 step:2738 [D loss: 0.466417, acc.: 78.91%] [G loss: 0.622696]\n",
      "epoch:2 step:2739 [D loss: 0.447300, acc.: 76.56%] [G loss: 0.668150]\n",
      "epoch:2 step:2740 [D loss: 0.395476, acc.: 89.06%] [G loss: 0.687614]\n",
      "epoch:2 step:2741 [D loss: 0.484569, acc.: 78.91%] [G loss: 0.694031]\n",
      "epoch:2 step:2742 [D loss: 0.487396, acc.: 80.47%] [G loss: 0.596828]\n",
      "epoch:2 step:2743 [D loss: 0.471041, acc.: 76.56%] [G loss: 0.852986]\n",
      "epoch:2 step:2744 [D loss: 0.497276, acc.: 76.56%] [G loss: 0.735665]\n",
      "epoch:2 step:2745 [D loss: 0.405195, acc.: 83.59%] [G loss: 0.878117]\n",
      "epoch:2 step:2746 [D loss: 0.455511, acc.: 80.47%] [G loss: 0.802719]\n",
      "epoch:2 step:2747 [D loss: 0.477245, acc.: 78.12%] [G loss: 0.821686]\n",
      "epoch:2 step:2748 [D loss: 0.458287, acc.: 80.47%] [G loss: 0.789389]\n",
      "epoch:2 step:2749 [D loss: 0.390031, acc.: 88.28%] [G loss: 0.905537]\n",
      "epoch:2 step:2750 [D loss: 0.459891, acc.: 82.81%] [G loss: 0.996808]\n",
      "epoch:2 step:2751 [D loss: 0.416756, acc.: 87.50%] [G loss: 0.927350]\n",
      "epoch:2 step:2752 [D loss: 0.549979, acc.: 72.66%] [G loss: 0.547855]\n",
      "epoch:2 step:2753 [D loss: 0.480350, acc.: 78.12%] [G loss: 0.678595]\n",
      "epoch:2 step:2754 [D loss: 0.591496, acc.: 67.97%] [G loss: 0.690357]\n",
      "epoch:2 step:2755 [D loss: 0.545919, acc.: 73.44%] [G loss: 0.723793]\n",
      "epoch:2 step:2756 [D loss: 0.563392, acc.: 69.53%] [G loss: 0.560268]\n",
      "epoch:2 step:2757 [D loss: 0.547908, acc.: 69.53%] [G loss: 0.763445]\n",
      "epoch:2 step:2758 [D loss: 0.456574, acc.: 80.47%] [G loss: 0.606439]\n",
      "epoch:2 step:2759 [D loss: 0.431977, acc.: 82.03%] [G loss: 0.756533]\n",
      "epoch:2 step:2760 [D loss: 0.419160, acc.: 85.16%] [G loss: 0.861303]\n",
      "epoch:2 step:2761 [D loss: 0.454179, acc.: 79.69%] [G loss: 0.836254]\n",
      "epoch:2 step:2762 [D loss: 0.411872, acc.: 85.16%] [G loss: 0.907847]\n",
      "epoch:2 step:2763 [D loss: 0.446791, acc.: 82.81%] [G loss: 0.770977]\n",
      "epoch:2 step:2764 [D loss: 0.381629, acc.: 86.72%] [G loss: 0.803986]\n",
      "epoch:2 step:2765 [D loss: 0.511611, acc.: 75.78%] [G loss: 0.595778]\n",
      "epoch:2 step:2766 [D loss: 0.585456, acc.: 74.22%] [G loss: 0.654750]\n",
      "epoch:2 step:2767 [D loss: 0.464038, acc.: 82.03%] [G loss: 0.637690]\n",
      "epoch:2 step:2768 [D loss: 0.475983, acc.: 77.34%] [G loss: 0.690615]\n",
      "epoch:2 step:2769 [D loss: 0.507602, acc.: 73.44%] [G loss: 0.736390]\n",
      "epoch:2 step:2770 [D loss: 0.476225, acc.: 79.69%] [G loss: 0.669556]\n",
      "epoch:2 step:2771 [D loss: 0.428455, acc.: 82.03%] [G loss: 0.923014]\n",
      "epoch:2 step:2772 [D loss: 0.448217, acc.: 82.03%] [G loss: 0.745982]\n",
      "epoch:2 step:2773 [D loss: 0.470065, acc.: 84.38%] [G loss: 0.699286]\n",
      "epoch:2 step:2774 [D loss: 0.423003, acc.: 84.38%] [G loss: 0.740310]\n",
      "epoch:2 step:2775 [D loss: 0.440360, acc.: 81.25%] [G loss: 0.688329]\n",
      "epoch:2 step:2776 [D loss: 0.482692, acc.: 80.47%] [G loss: 0.683685]\n",
      "epoch:2 step:2777 [D loss: 0.527974, acc.: 75.00%] [G loss: 0.528395]\n",
      "epoch:2 step:2778 [D loss: 0.472959, acc.: 78.12%] [G loss: 0.559563]\n",
      "epoch:2 step:2779 [D loss: 0.447841, acc.: 81.25%] [G loss: 0.763842]\n",
      "epoch:2 step:2780 [D loss: 0.445320, acc.: 83.59%] [G loss: 0.817096]\n",
      "epoch:2 step:2781 [D loss: 0.478368, acc.: 81.25%] [G loss: 0.869864]\n",
      "epoch:2 step:2782 [D loss: 0.436391, acc.: 85.16%] [G loss: 0.786291]\n",
      "epoch:2 step:2783 [D loss: 0.434969, acc.: 82.03%] [G loss: 0.759880]\n",
      "epoch:2 step:2784 [D loss: 0.391296, acc.: 89.06%] [G loss: 0.845302]\n",
      "epoch:2 step:2785 [D loss: 0.414887, acc.: 85.94%] [G loss: 0.930833]\n",
      "epoch:2 step:2786 [D loss: 0.451980, acc.: 80.47%] [G loss: 0.772534]\n",
      "epoch:2 step:2787 [D loss: 0.559328, acc.: 67.97%] [G loss: 0.720786]\n",
      "epoch:2 step:2788 [D loss: 0.441449, acc.: 78.12%] [G loss: 0.916565]\n",
      "epoch:2 step:2789 [D loss: 0.546648, acc.: 75.00%] [G loss: 0.685445]\n",
      "epoch:2 step:2790 [D loss: 0.494113, acc.: 75.78%] [G loss: 0.672081]\n",
      "epoch:2 step:2791 [D loss: 0.480601, acc.: 80.47%] [G loss: 0.642352]\n",
      "epoch:2 step:2792 [D loss: 0.400353, acc.: 82.81%] [G loss: 0.860039]\n",
      "epoch:2 step:2793 [D loss: 0.574877, acc.: 73.44%] [G loss: 0.627363]\n",
      "epoch:2 step:2794 [D loss: 0.577929, acc.: 69.53%] [G loss: 0.570940]\n",
      "epoch:2 step:2795 [D loss: 0.348267, acc.: 89.06%] [G loss: 0.936031]\n",
      "epoch:2 step:2796 [D loss: 0.461311, acc.: 78.91%] [G loss: 0.708922]\n",
      "epoch:2 step:2797 [D loss: 0.385386, acc.: 86.72%] [G loss: 0.786149]\n",
      "epoch:2 step:2798 [D loss: 0.375903, acc.: 83.59%] [G loss: 0.926264]\n",
      "epoch:2 step:2799 [D loss: 0.413575, acc.: 80.47%] [G loss: 1.036639]\n",
      "epoch:2 step:2800 [D loss: 0.406989, acc.: 83.59%] [G loss: 1.067874]\n",
      "epoch:2 step:2801 [D loss: 0.487359, acc.: 77.34%] [G loss: 1.037442]\n",
      "epoch:2 step:2802 [D loss: 0.788211, acc.: 64.84%] [G loss: 0.653041]\n",
      "epoch:2 step:2803 [D loss: 0.507694, acc.: 79.69%] [G loss: 0.845473]\n",
      "epoch:2 step:2804 [D loss: 0.371553, acc.: 84.38%] [G loss: 1.099302]\n",
      "epoch:2 step:2805 [D loss: 0.512979, acc.: 71.88%] [G loss: 0.939598]\n",
      "epoch:2 step:2806 [D loss: 0.514977, acc.: 75.78%] [G loss: 0.632196]\n",
      "epoch:2 step:2807 [D loss: 0.461191, acc.: 79.69%] [G loss: 0.723335]\n",
      "epoch:2 step:2808 [D loss: 0.531831, acc.: 76.56%] [G loss: 0.775687]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:2 step:2809 [D loss: 0.380935, acc.: 83.59%] [G loss: 1.022866]\n",
      "epoch:2 step:2810 [D loss: 0.308882, acc.: 93.75%] [G loss: 1.111900]\n",
      "epoch:2 step:2811 [D loss: 0.528279, acc.: 75.78%] [G loss: 1.044111]\n",
      "epoch:3 step:2812 [D loss: 0.480748, acc.: 77.34%] [G loss: 0.934905]\n",
      "epoch:3 step:2813 [D loss: 0.426718, acc.: 80.47%] [G loss: 0.778332]\n",
      "epoch:3 step:2814 [D loss: 0.529426, acc.: 76.56%] [G loss: 0.707122]\n",
      "epoch:3 step:2815 [D loss: 0.488741, acc.: 73.44%] [G loss: 0.678428]\n",
      "epoch:3 step:2816 [D loss: 0.465622, acc.: 79.69%] [G loss: 0.695205]\n",
      "epoch:3 step:2817 [D loss: 0.430315, acc.: 85.16%] [G loss: 0.951641]\n",
      "epoch:3 step:2818 [D loss: 0.449180, acc.: 80.47%] [G loss: 0.893995]\n",
      "epoch:3 step:2819 [D loss: 0.517785, acc.: 75.00%] [G loss: 0.807689]\n",
      "epoch:3 step:2820 [D loss: 0.449821, acc.: 81.25%] [G loss: 0.774646]\n",
      "epoch:3 step:2821 [D loss: 0.523969, acc.: 75.00%] [G loss: 0.732048]\n",
      "epoch:3 step:2822 [D loss: 0.567193, acc.: 66.41%] [G loss: 0.726584]\n",
      "epoch:3 step:2823 [D loss: 0.476961, acc.: 77.34%] [G loss: 0.714481]\n",
      "epoch:3 step:2824 [D loss: 0.508335, acc.: 75.00%] [G loss: 0.752197]\n",
      "epoch:3 step:2825 [D loss: 0.573674, acc.: 69.53%] [G loss: 0.548198]\n",
      "epoch:3 step:2826 [D loss: 0.408947, acc.: 83.59%] [G loss: 0.689121]\n",
      "epoch:3 step:2827 [D loss: 0.473712, acc.: 78.12%] [G loss: 0.753606]\n",
      "epoch:3 step:2828 [D loss: 0.559128, acc.: 70.31%] [G loss: 0.689650]\n",
      "epoch:3 step:2829 [D loss: 0.503692, acc.: 80.47%] [G loss: 0.661459]\n",
      "epoch:3 step:2830 [D loss: 0.555158, acc.: 69.53%] [G loss: 0.504354]\n",
      "epoch:3 step:2831 [D loss: 0.597196, acc.: 71.09%] [G loss: 0.562226]\n",
      "epoch:3 step:2832 [D loss: 0.533171, acc.: 72.66%] [G loss: 0.472473]\n",
      "epoch:3 step:2833 [D loss: 0.394584, acc.: 82.03%] [G loss: 0.956062]\n",
      "epoch:3 step:2834 [D loss: 0.478427, acc.: 79.69%] [G loss: 0.759547]\n",
      "epoch:3 step:2835 [D loss: 0.495430, acc.: 71.09%] [G loss: 0.599584]\n",
      "epoch:3 step:2836 [D loss: 0.499125, acc.: 75.00%] [G loss: 0.602992]\n",
      "epoch:3 step:2837 [D loss: 0.512651, acc.: 77.34%] [G loss: 0.783243]\n",
      "epoch:3 step:2838 [D loss: 0.438890, acc.: 80.47%] [G loss: 0.774781]\n",
      "epoch:3 step:2839 [D loss: 0.485602, acc.: 80.47%] [G loss: 0.762819]\n",
      "epoch:3 step:2840 [D loss: 0.445802, acc.: 82.81%] [G loss: 0.798143]\n",
      "epoch:3 step:2841 [D loss: 0.501890, acc.: 79.69%] [G loss: 0.724582]\n",
      "epoch:3 step:2842 [D loss: 0.484417, acc.: 77.34%] [G loss: 0.670834]\n",
      "epoch:3 step:2843 [D loss: 0.539394, acc.: 71.88%] [G loss: 0.611528]\n",
      "epoch:3 step:2844 [D loss: 0.486274, acc.: 76.56%] [G loss: 0.687084]\n",
      "epoch:3 step:2845 [D loss: 0.435576, acc.: 82.03%] [G loss: 0.881527]\n",
      "epoch:3 step:2846 [D loss: 0.426900, acc.: 80.47%] [G loss: 0.815730]\n",
      "epoch:3 step:2847 [D loss: 0.464945, acc.: 77.34%] [G loss: 0.670141]\n",
      "epoch:3 step:2848 [D loss: 0.520965, acc.: 75.78%] [G loss: 0.580253]\n",
      "epoch:3 step:2849 [D loss: 0.581704, acc.: 71.09%] [G loss: 0.711557]\n",
      "epoch:3 step:2850 [D loss: 0.525707, acc.: 71.88%] [G loss: 0.693831]\n",
      "epoch:3 step:2851 [D loss: 0.390821, acc.: 85.16%] [G loss: 0.727258]\n",
      "epoch:3 step:2852 [D loss: 0.478959, acc.: 81.25%] [G loss: 0.668013]\n",
      "epoch:3 step:2853 [D loss: 0.455526, acc.: 78.12%] [G loss: 0.736216]\n",
      "epoch:3 step:2854 [D loss: 0.437237, acc.: 82.03%] [G loss: 0.636407]\n",
      "epoch:3 step:2855 [D loss: 0.531793, acc.: 74.22%] [G loss: 0.546610]\n",
      "epoch:3 step:2856 [D loss: 0.458231, acc.: 80.47%] [G loss: 0.578463]\n",
      "epoch:3 step:2857 [D loss: 0.505758, acc.: 75.00%] [G loss: 0.622206]\n",
      "epoch:3 step:2858 [D loss: 0.509630, acc.: 77.34%] [G loss: 0.679876]\n",
      "epoch:3 step:2859 [D loss: 0.504945, acc.: 78.12%] [G loss: 0.670869]\n",
      "epoch:3 step:2860 [D loss: 0.550813, acc.: 72.66%] [G loss: 0.565107]\n",
      "epoch:3 step:2861 [D loss: 0.470561, acc.: 80.47%] [G loss: 0.745115]\n",
      "epoch:3 step:2862 [D loss: 0.479258, acc.: 78.91%] [G loss: 0.669375]\n",
      "epoch:3 step:2863 [D loss: 0.507885, acc.: 76.56%] [G loss: 0.749678]\n",
      "epoch:3 step:2864 [D loss: 0.462676, acc.: 79.69%] [G loss: 0.778619]\n",
      "epoch:3 step:2865 [D loss: 0.460305, acc.: 79.69%] [G loss: 0.671980]\n",
      "epoch:3 step:2866 [D loss: 0.455296, acc.: 86.72%] [G loss: 0.760515]\n",
      "epoch:3 step:2867 [D loss: 0.485994, acc.: 79.69%] [G loss: 0.647814]\n",
      "epoch:3 step:2868 [D loss: 0.453363, acc.: 81.25%] [G loss: 0.770377]\n",
      "epoch:3 step:2869 [D loss: 0.482181, acc.: 82.03%] [G loss: 0.659595]\n",
      "epoch:3 step:2870 [D loss: 0.485408, acc.: 77.34%] [G loss: 0.767549]\n",
      "epoch:3 step:2871 [D loss: 0.505245, acc.: 75.78%] [G loss: 0.712341]\n",
      "epoch:3 step:2872 [D loss: 0.494431, acc.: 78.91%] [G loss: 0.681080]\n",
      "epoch:3 step:2873 [D loss: 0.524369, acc.: 76.56%] [G loss: 0.634200]\n",
      "epoch:3 step:2874 [D loss: 0.491803, acc.: 82.03%] [G loss: 0.594023]\n",
      "epoch:3 step:2875 [D loss: 0.534360, acc.: 75.00%] [G loss: 0.556373]\n",
      "epoch:3 step:2876 [D loss: 0.505114, acc.: 76.56%] [G loss: 0.581140]\n",
      "epoch:3 step:2877 [D loss: 0.474487, acc.: 76.56%] [G loss: 0.596260]\n",
      "epoch:3 step:2878 [D loss: 0.514942, acc.: 73.44%] [G loss: 0.592573]\n",
      "epoch:3 step:2879 [D loss: 0.495531, acc.: 75.00%] [G loss: 0.664835]\n",
      "epoch:3 step:2880 [D loss: 0.453945, acc.: 82.81%] [G loss: 0.723750]\n",
      "epoch:3 step:2881 [D loss: 0.449232, acc.: 79.69%] [G loss: 0.778767]\n",
      "epoch:3 step:2882 [D loss: 0.455924, acc.: 76.56%] [G loss: 0.736571]\n",
      "epoch:3 step:2883 [D loss: 0.374493, acc.: 85.94%] [G loss: 0.934144]\n",
      "epoch:3 step:2884 [D loss: 0.434257, acc.: 85.16%] [G loss: 0.935835]\n",
      "epoch:3 step:2885 [D loss: 0.475516, acc.: 78.91%] [G loss: 0.717085]\n",
      "epoch:3 step:2886 [D loss: 0.497988, acc.: 75.00%] [G loss: 0.762215]\n",
      "epoch:3 step:2887 [D loss: 0.464926, acc.: 75.00%] [G loss: 0.941026]\n",
      "epoch:3 step:2888 [D loss: 0.430325, acc.: 79.69%] [G loss: 0.956338]\n",
      "epoch:3 step:2889 [D loss: 0.563923, acc.: 76.56%] [G loss: 0.618250]\n",
      "epoch:3 step:2890 [D loss: 0.511377, acc.: 74.22%] [G loss: 0.501511]\n",
      "epoch:3 step:2891 [D loss: 0.521640, acc.: 73.44%] [G loss: 0.643234]\n",
      "epoch:3 step:2892 [D loss: 0.520882, acc.: 75.00%] [G loss: 0.574180]\n",
      "epoch:3 step:2893 [D loss: 0.465565, acc.: 82.81%] [G loss: 0.643209]\n",
      "epoch:3 step:2894 [D loss: 0.468733, acc.: 78.12%] [G loss: 0.751835]\n",
      "epoch:3 step:2895 [D loss: 0.437525, acc.: 83.59%] [G loss: 0.797897]\n",
      "epoch:3 step:2896 [D loss: 0.447126, acc.: 82.03%] [G loss: 0.599791]\n",
      "epoch:3 step:2897 [D loss: 0.450376, acc.: 82.81%] [G loss: 0.720250]\n",
      "epoch:3 step:2898 [D loss: 0.433022, acc.: 81.25%] [G loss: 0.760801]\n",
      "epoch:3 step:2899 [D loss: 0.449083, acc.: 80.47%] [G loss: 0.840255]\n",
      "epoch:3 step:2900 [D loss: 0.478134, acc.: 77.34%] [G loss: 0.733636]\n",
      "epoch:3 step:2901 [D loss: 0.426618, acc.: 84.38%] [G loss: 0.679324]\n",
      "epoch:3 step:2902 [D loss: 0.377292, acc.: 88.28%] [G loss: 0.884048]\n",
      "epoch:3 step:2903 [D loss: 0.453700, acc.: 82.81%] [G loss: 0.646281]\n",
      "epoch:3 step:2904 [D loss: 0.455652, acc.: 83.59%] [G loss: 0.590261]\n",
      "epoch:3 step:2905 [D loss: 0.459712, acc.: 82.03%] [G loss: 0.673037]\n",
      "epoch:3 step:2906 [D loss: 0.464983, acc.: 79.69%] [G loss: 0.661723]\n",
      "epoch:3 step:2907 [D loss: 0.371542, acc.: 87.50%] [G loss: 0.795234]\n",
      "epoch:3 step:2908 [D loss: 0.515676, acc.: 75.78%] [G loss: 0.759626]\n",
      "epoch:3 step:2909 [D loss: 0.448027, acc.: 76.56%] [G loss: 0.659110]\n",
      "epoch:3 step:2910 [D loss: 0.435129, acc.: 82.81%] [G loss: 0.858037]\n",
      "epoch:3 step:2911 [D loss: 0.424401, acc.: 82.03%] [G loss: 0.749941]\n",
      "epoch:3 step:2912 [D loss: 0.473563, acc.: 78.91%] [G loss: 0.692887]\n",
      "epoch:3 step:2913 [D loss: 0.473877, acc.: 77.34%] [G loss: 0.701698]\n",
      "epoch:3 step:2914 [D loss: 0.374071, acc.: 89.06%] [G loss: 0.802088]\n",
      "epoch:3 step:2915 [D loss: 0.455797, acc.: 78.12%] [G loss: 0.908440]\n",
      "epoch:3 step:2916 [D loss: 0.459780, acc.: 82.03%] [G loss: 0.783904]\n",
      "epoch:3 step:2917 [D loss: 0.497668, acc.: 82.03%] [G loss: 0.609752]\n",
      "epoch:3 step:2918 [D loss: 0.569702, acc.: 75.00%] [G loss: 0.660932]\n",
      "epoch:3 step:2919 [D loss: 0.516666, acc.: 78.12%] [G loss: 0.675179]\n",
      "epoch:3 step:2920 [D loss: 0.546680, acc.: 71.09%] [G loss: 0.777691]\n",
      "epoch:3 step:2921 [D loss: 0.502625, acc.: 74.22%] [G loss: 0.787083]\n",
      "epoch:3 step:2922 [D loss: 0.452506, acc.: 79.69%] [G loss: 0.790946]\n",
      "epoch:3 step:2923 [D loss: 0.453781, acc.: 82.03%] [G loss: 0.738558]\n",
      "epoch:3 step:2924 [D loss: 0.566898, acc.: 71.88%] [G loss: 0.576231]\n",
      "epoch:3 step:2925 [D loss: 0.541112, acc.: 75.78%] [G loss: 0.509440]\n",
      "epoch:3 step:2926 [D loss: 0.542825, acc.: 74.22%] [G loss: 0.770520]\n",
      "epoch:3 step:2927 [D loss: 0.477360, acc.: 79.69%] [G loss: 0.764707]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:3 step:2928 [D loss: 0.403522, acc.: 90.62%] [G loss: 0.823681]\n",
      "epoch:3 step:2929 [D loss: 0.434931, acc.: 83.59%] [G loss: 0.795580]\n",
      "epoch:3 step:2930 [D loss: 0.391759, acc.: 85.94%] [G loss: 1.013198]\n",
      "epoch:3 step:2931 [D loss: 0.646163, acc.: 60.16%] [G loss: 0.508182]\n",
      "epoch:3 step:2932 [D loss: 0.527153, acc.: 75.00%] [G loss: 0.596965]\n",
      "epoch:3 step:2933 [D loss: 0.468246, acc.: 79.69%] [G loss: 0.880478]\n",
      "epoch:3 step:2934 [D loss: 0.539272, acc.: 72.66%] [G loss: 0.796615]\n",
      "epoch:3 step:2935 [D loss: 0.492372, acc.: 77.34%] [G loss: 0.739174]\n",
      "epoch:3 step:2936 [D loss: 0.491162, acc.: 78.12%] [G loss: 0.569708]\n",
      "epoch:3 step:2937 [D loss: 0.504441, acc.: 71.88%] [G loss: 0.666255]\n",
      "epoch:3 step:2938 [D loss: 0.539576, acc.: 67.19%] [G loss: 0.521696]\n",
      "epoch:3 step:2939 [D loss: 0.491189, acc.: 75.78%] [G loss: 0.714678]\n",
      "epoch:3 step:2940 [D loss: 0.512716, acc.: 78.12%] [G loss: 0.584454]\n",
      "epoch:3 step:2941 [D loss: 0.529731, acc.: 75.00%] [G loss: 0.564390]\n",
      "epoch:3 step:2942 [D loss: 0.421331, acc.: 85.16%] [G loss: 0.775298]\n",
      "epoch:3 step:2943 [D loss: 0.500666, acc.: 75.00%] [G loss: 0.775906]\n",
      "epoch:3 step:2944 [D loss: 0.552867, acc.: 67.97%] [G loss: 0.673228]\n",
      "epoch:3 step:2945 [D loss: 0.451169, acc.: 84.38%] [G loss: 0.697677]\n",
      "epoch:3 step:2946 [D loss: 0.387797, acc.: 88.28%] [G loss: 0.838757]\n",
      "epoch:3 step:2947 [D loss: 0.496128, acc.: 80.47%] [G loss: 0.757483]\n",
      "epoch:3 step:2948 [D loss: 0.548412, acc.: 75.78%] [G loss: 0.569986]\n",
      "epoch:3 step:2949 [D loss: 0.460288, acc.: 80.47%] [G loss: 0.622120]\n",
      "epoch:3 step:2950 [D loss: 0.506468, acc.: 81.25%] [G loss: 0.697721]\n",
      "epoch:3 step:2951 [D loss: 0.481428, acc.: 75.78%] [G loss: 0.658539]\n",
      "epoch:3 step:2952 [D loss: 0.418186, acc.: 83.59%] [G loss: 0.668536]\n",
      "epoch:3 step:2953 [D loss: 0.450262, acc.: 79.69%] [G loss: 0.738208]\n",
      "epoch:3 step:2954 [D loss: 0.487968, acc.: 79.69%] [G loss: 0.744118]\n",
      "epoch:3 step:2955 [D loss: 0.445409, acc.: 77.34%] [G loss: 0.732501]\n",
      "epoch:3 step:2956 [D loss: 0.472318, acc.: 78.91%] [G loss: 0.778726]\n",
      "epoch:3 step:2957 [D loss: 0.509623, acc.: 78.12%] [G loss: 0.654922]\n",
      "epoch:3 step:2958 [D loss: 0.487756, acc.: 78.12%] [G loss: 0.554746]\n",
      "epoch:3 step:2959 [D loss: 0.446402, acc.: 82.81%] [G loss: 0.632577]\n",
      "epoch:3 step:2960 [D loss: 0.417722, acc.: 84.38%] [G loss: 0.724290]\n",
      "epoch:3 step:2961 [D loss: 0.474249, acc.: 81.25%] [G loss: 0.855334]\n",
      "epoch:3 step:2962 [D loss: 0.473916, acc.: 85.16%] [G loss: 0.671775]\n",
      "epoch:3 step:2963 [D loss: 0.421059, acc.: 82.03%] [G loss: 0.795861]\n",
      "epoch:3 step:2964 [D loss: 0.459217, acc.: 82.03%] [G loss: 0.787686]\n",
      "epoch:3 step:2965 [D loss: 0.416514, acc.: 86.72%] [G loss: 0.637415]\n",
      "epoch:3 step:2966 [D loss: 0.398488, acc.: 84.38%] [G loss: 0.832046]\n",
      "epoch:3 step:2967 [D loss: 0.455470, acc.: 80.47%] [G loss: 0.691431]\n",
      "epoch:3 step:2968 [D loss: 0.483295, acc.: 79.69%] [G loss: 0.755297]\n",
      "epoch:3 step:2969 [D loss: 0.484790, acc.: 78.91%] [G loss: 0.663839]\n",
      "epoch:3 step:2970 [D loss: 0.454188, acc.: 82.03%] [G loss: 0.711989]\n",
      "epoch:3 step:2971 [D loss: 0.519587, acc.: 72.66%] [G loss: 0.666546]\n",
      "epoch:3 step:2972 [D loss: 0.472697, acc.: 80.47%] [G loss: 0.668648]\n",
      "epoch:3 step:2973 [D loss: 0.371704, acc.: 84.38%] [G loss: 0.953354]\n",
      "epoch:3 step:2974 [D loss: 0.401605, acc.: 85.16%] [G loss: 0.985690]\n",
      "epoch:3 step:2975 [D loss: 0.455793, acc.: 79.69%] [G loss: 0.965617]\n",
      "epoch:3 step:2976 [D loss: 0.472720, acc.: 78.91%] [G loss: 0.934949]\n",
      "epoch:3 step:2977 [D loss: 0.495527, acc.: 78.12%] [G loss: 0.916446]\n",
      "epoch:3 step:2978 [D loss: 0.468845, acc.: 80.47%] [G loss: 0.868301]\n",
      "epoch:3 step:2979 [D loss: 0.491186, acc.: 78.12%] [G loss: 0.647250]\n",
      "epoch:3 step:2980 [D loss: 0.447475, acc.: 80.47%] [G loss: 0.694865]\n",
      "epoch:3 step:2981 [D loss: 0.450694, acc.: 80.47%] [G loss: 0.765738]\n",
      "epoch:3 step:2982 [D loss: 0.434379, acc.: 82.03%] [G loss: 0.874819]\n",
      "epoch:3 step:2983 [D loss: 0.473516, acc.: 76.56%] [G loss: 0.815098]\n",
      "epoch:3 step:2984 [D loss: 0.470544, acc.: 78.12%] [G loss: 0.757819]\n",
      "epoch:3 step:2985 [D loss: 0.424989, acc.: 86.72%] [G loss: 0.799277]\n",
      "epoch:3 step:2986 [D loss: 0.428800, acc.: 82.81%] [G loss: 0.753589]\n",
      "epoch:3 step:2987 [D loss: 0.466870, acc.: 77.34%] [G loss: 0.881584]\n",
      "epoch:3 step:2988 [D loss: 0.424700, acc.: 83.59%] [G loss: 0.958058]\n",
      "epoch:3 step:2989 [D loss: 0.490826, acc.: 75.78%] [G loss: 0.724727]\n",
      "epoch:3 step:2990 [D loss: 0.497375, acc.: 80.47%] [G loss: 0.655778]\n",
      "epoch:3 step:2991 [D loss: 0.490267, acc.: 77.34%] [G loss: 0.747776]\n",
      "epoch:3 step:2992 [D loss: 0.511169, acc.: 75.78%] [G loss: 0.569345]\n",
      "epoch:3 step:2993 [D loss: 0.567168, acc.: 71.09%] [G loss: 0.615509]\n",
      "epoch:3 step:2994 [D loss: 0.511146, acc.: 75.78%] [G loss: 0.575801]\n",
      "epoch:3 step:2995 [D loss: 0.551894, acc.: 70.31%] [G loss: 0.644607]\n",
      "epoch:3 step:2996 [D loss: 0.507191, acc.: 75.78%] [G loss: 0.545653]\n",
      "epoch:3 step:2997 [D loss: 0.503863, acc.: 75.00%] [G loss: 0.788317]\n",
      "epoch:3 step:2998 [D loss: 0.514129, acc.: 78.12%] [G loss: 0.749320]\n",
      "epoch:3 step:2999 [D loss: 0.504819, acc.: 75.78%] [G loss: 0.537550]\n",
      "epoch:3 step:3000 [D loss: 0.437266, acc.: 84.38%] [G loss: 0.866268]\n",
      "epoch:3 step:3001 [D loss: 0.446035, acc.: 79.69%] [G loss: 0.751882]\n",
      "epoch:3 step:3002 [D loss: 0.402095, acc.: 87.50%] [G loss: 0.863690]\n",
      "epoch:3 step:3003 [D loss: 0.520761, acc.: 77.34%] [G loss: 0.688217]\n",
      "epoch:3 step:3004 [D loss: 0.525196, acc.: 75.00%] [G loss: 0.556941]\n",
      "epoch:3 step:3005 [D loss: 0.457985, acc.: 82.81%] [G loss: 0.666761]\n",
      "epoch:3 step:3006 [D loss: 0.473615, acc.: 81.25%] [G loss: 0.817784]\n",
      "epoch:3 step:3007 [D loss: 0.528946, acc.: 74.22%] [G loss: 0.674800]\n",
      "epoch:3 step:3008 [D loss: 0.532476, acc.: 79.69%] [G loss: 0.512570]\n",
      "epoch:3 step:3009 [D loss: 0.446204, acc.: 79.69%] [G loss: 0.702826]\n",
      "epoch:3 step:3010 [D loss: 0.515872, acc.: 75.78%] [G loss: 0.718876]\n",
      "epoch:3 step:3011 [D loss: 0.565928, acc.: 65.62%] [G loss: 0.623825]\n",
      "epoch:3 step:3012 [D loss: 0.515318, acc.: 71.88%] [G loss: 0.700314]\n",
      "epoch:3 step:3013 [D loss: 0.491716, acc.: 76.56%] [G loss: 0.734212]\n",
      "epoch:3 step:3014 [D loss: 0.571870, acc.: 68.75%] [G loss: 0.646346]\n",
      "epoch:3 step:3015 [D loss: 0.386578, acc.: 87.50%] [G loss: 0.854173]\n",
      "epoch:3 step:3016 [D loss: 0.458305, acc.: 79.69%] [G loss: 0.822607]\n",
      "epoch:3 step:3017 [D loss: 0.510518, acc.: 75.78%] [G loss: 0.711656]\n",
      "epoch:3 step:3018 [D loss: 0.439967, acc.: 82.81%] [G loss: 0.821578]\n",
      "epoch:3 step:3019 [D loss: 0.424962, acc.: 82.03%] [G loss: 0.841857]\n",
      "epoch:3 step:3020 [D loss: 0.516827, acc.: 76.56%] [G loss: 0.743538]\n",
      "epoch:3 step:3021 [D loss: 0.496520, acc.: 75.78%] [G loss: 0.752253]\n",
      "epoch:3 step:3022 [D loss: 0.469782, acc.: 78.91%] [G loss: 0.536892]\n",
      "epoch:3 step:3023 [D loss: 0.466854, acc.: 77.34%] [G loss: 0.661811]\n",
      "epoch:3 step:3024 [D loss: 0.439279, acc.: 81.25%] [G loss: 0.732748]\n",
      "epoch:3 step:3025 [D loss: 0.605126, acc.: 64.06%] [G loss: 0.526575]\n",
      "epoch:3 step:3026 [D loss: 0.520414, acc.: 75.78%] [G loss: 0.646336]\n",
      "epoch:3 step:3027 [D loss: 0.531602, acc.: 75.00%] [G loss: 0.509870]\n",
      "epoch:3 step:3028 [D loss: 0.458343, acc.: 81.25%] [G loss: 0.591536]\n",
      "epoch:3 step:3029 [D loss: 0.484680, acc.: 78.91%] [G loss: 0.681683]\n",
      "epoch:3 step:3030 [D loss: 0.540033, acc.: 70.31%] [G loss: 0.676836]\n",
      "epoch:3 step:3031 [D loss: 0.597491, acc.: 69.53%] [G loss: 0.595077]\n",
      "epoch:3 step:3032 [D loss: 0.469067, acc.: 75.78%] [G loss: 0.779251]\n",
      "epoch:3 step:3033 [D loss: 0.451351, acc.: 80.47%] [G loss: 0.876733]\n",
      "epoch:3 step:3034 [D loss: 0.422991, acc.: 81.25%] [G loss: 1.056906]\n",
      "epoch:3 step:3035 [D loss: 0.558827, acc.: 72.66%] [G loss: 0.670467]\n",
      "epoch:3 step:3036 [D loss: 0.573410, acc.: 69.53%] [G loss: 0.556945]\n",
      "epoch:3 step:3037 [D loss: 0.454669, acc.: 82.81%] [G loss: 0.635544]\n",
      "epoch:3 step:3038 [D loss: 0.486733, acc.: 77.34%] [G loss: 0.583250]\n",
      "epoch:3 step:3039 [D loss: 0.519342, acc.: 71.88%] [G loss: 0.479138]\n",
      "epoch:3 step:3040 [D loss: 0.440528, acc.: 80.47%] [G loss: 0.743648]\n",
      "epoch:3 step:3041 [D loss: 0.373692, acc.: 88.28%] [G loss: 0.844846]\n",
      "epoch:3 step:3042 [D loss: 0.444871, acc.: 83.59%] [G loss: 0.908841]\n",
      "epoch:3 step:3043 [D loss: 0.365112, acc.: 85.94%] [G loss: 0.965304]\n",
      "epoch:3 step:3044 [D loss: 0.556809, acc.: 72.66%] [G loss: 0.705662]\n",
      "epoch:3 step:3045 [D loss: 0.485891, acc.: 75.78%] [G loss: 0.723218]\n",
      "epoch:3 step:3046 [D loss: 0.423575, acc.: 82.03%] [G loss: 0.810109]\n",
      "epoch:3 step:3047 [D loss: 0.443993, acc.: 84.38%] [G loss: 0.641352]\n",
      "epoch:3 step:3048 [D loss: 0.507768, acc.: 76.56%] [G loss: 0.705603]\n",
      "epoch:3 step:3049 [D loss: 0.460450, acc.: 82.03%] [G loss: 0.637641]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:3 step:3050 [D loss: 0.510452, acc.: 81.25%] [G loss: 0.503642]\n",
      "epoch:3 step:3051 [D loss: 0.449406, acc.: 81.25%] [G loss: 0.613804]\n",
      "epoch:3 step:3052 [D loss: 0.452558, acc.: 81.25%] [G loss: 0.699374]\n",
      "epoch:3 step:3053 [D loss: 0.464331, acc.: 82.03%] [G loss: 0.679883]\n",
      "epoch:3 step:3054 [D loss: 0.501052, acc.: 76.56%] [G loss: 0.603447]\n",
      "epoch:3 step:3055 [D loss: 0.490877, acc.: 76.56%] [G loss: 0.846572]\n",
      "epoch:3 step:3056 [D loss: 0.475675, acc.: 81.25%] [G loss: 0.887191]\n",
      "epoch:3 step:3057 [D loss: 0.531379, acc.: 75.78%] [G loss: 0.817953]\n",
      "epoch:3 step:3058 [D loss: 0.586875, acc.: 66.41%] [G loss: 0.659299]\n",
      "epoch:3 step:3059 [D loss: 0.534542, acc.: 72.66%] [G loss: 0.509964]\n",
      "epoch:3 step:3060 [D loss: 0.479255, acc.: 78.12%] [G loss: 0.622895]\n",
      "epoch:3 step:3061 [D loss: 0.532992, acc.: 75.78%] [G loss: 0.583282]\n",
      "epoch:3 step:3062 [D loss: 0.480341, acc.: 78.12%] [G loss: 0.865220]\n",
      "epoch:3 step:3063 [D loss: 0.478957, acc.: 77.34%] [G loss: 0.688537]\n",
      "epoch:3 step:3064 [D loss: 0.459250, acc.: 81.25%] [G loss: 0.757536]\n",
      "epoch:3 step:3065 [D loss: 0.444517, acc.: 82.03%] [G loss: 0.739969]\n",
      "epoch:3 step:3066 [D loss: 0.440530, acc.: 83.59%] [G loss: 0.785555]\n",
      "epoch:3 step:3067 [D loss: 0.414715, acc.: 83.59%] [G loss: 0.673113]\n",
      "epoch:3 step:3068 [D loss: 0.448352, acc.: 78.91%] [G loss: 0.756273]\n",
      "epoch:3 step:3069 [D loss: 0.466221, acc.: 82.03%] [G loss: 0.804714]\n",
      "epoch:3 step:3070 [D loss: 0.425157, acc.: 81.25%] [G loss: 0.936886]\n",
      "epoch:3 step:3071 [D loss: 0.475120, acc.: 80.47%] [G loss: 0.659703]\n",
      "epoch:3 step:3072 [D loss: 0.500026, acc.: 72.66%] [G loss: 0.886179]\n",
      "epoch:3 step:3073 [D loss: 0.486279, acc.: 77.34%] [G loss: 0.910952]\n",
      "epoch:3 step:3074 [D loss: 0.618288, acc.: 64.06%] [G loss: 0.706016]\n",
      "epoch:3 step:3075 [D loss: 0.462311, acc.: 78.91%] [G loss: 0.731228]\n",
      "epoch:3 step:3076 [D loss: 0.520779, acc.: 69.53%] [G loss: 0.563041]\n",
      "epoch:3 step:3077 [D loss: 0.476240, acc.: 78.12%] [G loss: 0.718881]\n",
      "epoch:3 step:3078 [D loss: 0.512119, acc.: 77.34%] [G loss: 0.763935]\n",
      "epoch:3 step:3079 [D loss: 0.535571, acc.: 67.19%] [G loss: 0.573979]\n",
      "epoch:3 step:3080 [D loss: 0.552275, acc.: 69.53%] [G loss: 0.694441]\n",
      "epoch:3 step:3081 [D loss: 0.490016, acc.: 76.56%] [G loss: 0.573051]\n",
      "epoch:3 step:3082 [D loss: 0.441522, acc.: 82.81%] [G loss: 0.764422]\n",
      "epoch:3 step:3083 [D loss: 0.572127, acc.: 72.66%] [G loss: 0.629586]\n",
      "epoch:3 step:3084 [D loss: 0.476476, acc.: 75.00%] [G loss: 0.707381]\n",
      "epoch:3 step:3085 [D loss: 0.520193, acc.: 74.22%] [G loss: 0.688394]\n",
      "epoch:3 step:3086 [D loss: 0.572142, acc.: 70.31%] [G loss: 0.669604]\n",
      "epoch:3 step:3087 [D loss: 0.504484, acc.: 75.78%] [G loss: 0.640284]\n",
      "epoch:3 step:3088 [D loss: 0.556750, acc.: 70.31%] [G loss: 0.646591]\n",
      "epoch:3 step:3089 [D loss: 0.504771, acc.: 81.25%] [G loss: 0.790252]\n",
      "epoch:3 step:3090 [D loss: 0.469634, acc.: 78.12%] [G loss: 0.865628]\n",
      "epoch:3 step:3091 [D loss: 0.487704, acc.: 77.34%] [G loss: 0.694863]\n",
      "epoch:3 step:3092 [D loss: 0.542242, acc.: 74.22%] [G loss: 0.535356]\n",
      "epoch:3 step:3093 [D loss: 0.524509, acc.: 74.22%] [G loss: 0.520716]\n",
      "epoch:3 step:3094 [D loss: 0.468171, acc.: 81.25%] [G loss: 0.665003]\n",
      "epoch:3 step:3095 [D loss: 0.429647, acc.: 79.69%] [G loss: 0.830107]\n",
      "epoch:3 step:3096 [D loss: 0.414349, acc.: 83.59%] [G loss: 0.790398]\n",
      "epoch:3 step:3097 [D loss: 0.402476, acc.: 82.03%] [G loss: 0.960272]\n",
      "epoch:3 step:3098 [D loss: 0.492413, acc.: 77.34%] [G loss: 0.741066]\n",
      "epoch:3 step:3099 [D loss: 0.530476, acc.: 74.22%] [G loss: 0.727324]\n",
      "epoch:3 step:3100 [D loss: 0.500391, acc.: 78.91%] [G loss: 0.653020]\n",
      "epoch:3 step:3101 [D loss: 0.469618, acc.: 79.69%] [G loss: 0.712210]\n",
      "epoch:3 step:3102 [D loss: 0.439009, acc.: 85.94%] [G loss: 0.813900]\n",
      "epoch:3 step:3103 [D loss: 0.528329, acc.: 77.34%] [G loss: 0.568384]\n",
      "epoch:3 step:3104 [D loss: 0.483211, acc.: 77.34%] [G loss: 0.566810]\n",
      "epoch:3 step:3105 [D loss: 0.505335, acc.: 78.12%] [G loss: 0.548110]\n",
      "epoch:3 step:3106 [D loss: 0.501604, acc.: 79.69%] [G loss: 0.637577]\n",
      "epoch:3 step:3107 [D loss: 0.450837, acc.: 85.94%] [G loss: 0.710681]\n",
      "epoch:3 step:3108 [D loss: 0.488481, acc.: 75.00%] [G loss: 0.690152]\n",
      "epoch:3 step:3109 [D loss: 0.507783, acc.: 72.66%] [G loss: 0.619149]\n",
      "epoch:3 step:3110 [D loss: 0.459679, acc.: 78.91%] [G loss: 0.689210]\n",
      "epoch:3 step:3111 [D loss: 0.456549, acc.: 81.25%] [G loss: 0.642352]\n",
      "epoch:3 step:3112 [D loss: 0.576254, acc.: 72.66%] [G loss: 0.602242]\n",
      "epoch:3 step:3113 [D loss: 0.436366, acc.: 82.81%] [G loss: 0.644479]\n",
      "epoch:3 step:3114 [D loss: 0.500098, acc.: 75.78%] [G loss: 0.637075]\n",
      "epoch:3 step:3115 [D loss: 0.433941, acc.: 79.69%] [G loss: 0.869515]\n",
      "epoch:3 step:3116 [D loss: 0.460826, acc.: 77.34%] [G loss: 0.825196]\n",
      "epoch:3 step:3117 [D loss: 0.568796, acc.: 69.53%] [G loss: 0.655225]\n",
      "epoch:3 step:3118 [D loss: 0.480343, acc.: 78.12%] [G loss: 0.770822]\n",
      "epoch:3 step:3119 [D loss: 0.467510, acc.: 78.12%] [G loss: 0.744844]\n",
      "epoch:3 step:3120 [D loss: 0.403826, acc.: 85.16%] [G loss: 0.831024]\n",
      "epoch:3 step:3121 [D loss: 0.449211, acc.: 84.38%] [G loss: 0.794310]\n",
      "epoch:3 step:3122 [D loss: 0.462361, acc.: 78.91%] [G loss: 0.727064]\n",
      "epoch:3 step:3123 [D loss: 0.399121, acc.: 79.69%] [G loss: 0.875859]\n",
      "epoch:3 step:3124 [D loss: 0.457869, acc.: 78.91%] [G loss: 0.801462]\n",
      "epoch:3 step:3125 [D loss: 0.427404, acc.: 81.25%] [G loss: 1.111955]\n",
      "epoch:3 step:3126 [D loss: 0.375312, acc.: 85.94%] [G loss: 1.025715]\n",
      "epoch:3 step:3127 [D loss: 0.684579, acc.: 61.72%] [G loss: 0.633876]\n",
      "epoch:3 step:3128 [D loss: 0.488301, acc.: 80.47%] [G loss: 0.698432]\n",
      "epoch:3 step:3129 [D loss: 0.522391, acc.: 73.44%] [G loss: 0.626991]\n",
      "epoch:3 step:3130 [D loss: 0.491476, acc.: 71.88%] [G loss: 0.566161]\n",
      "epoch:3 step:3131 [D loss: 0.451767, acc.: 76.56%] [G loss: 0.724324]\n",
      "epoch:3 step:3132 [D loss: 0.397149, acc.: 85.94%] [G loss: 0.687129]\n",
      "epoch:3 step:3133 [D loss: 0.466154, acc.: 76.56%] [G loss: 0.692938]\n",
      "epoch:3 step:3134 [D loss: 0.550128, acc.: 70.31%] [G loss: 0.545684]\n",
      "epoch:3 step:3135 [D loss: 0.462039, acc.: 78.91%] [G loss: 0.724260]\n",
      "epoch:3 step:3136 [D loss: 0.437155, acc.: 82.03%] [G loss: 0.805509]\n",
      "epoch:3 step:3137 [D loss: 0.458788, acc.: 82.03%] [G loss: 0.731553]\n",
      "epoch:3 step:3138 [D loss: 0.522032, acc.: 74.22%] [G loss: 0.599562]\n",
      "epoch:3 step:3139 [D loss: 0.443592, acc.: 84.38%] [G loss: 0.736198]\n",
      "epoch:3 step:3140 [D loss: 0.421563, acc.: 82.81%] [G loss: 0.721823]\n",
      "epoch:3 step:3141 [D loss: 0.478688, acc.: 77.34%] [G loss: 0.787646]\n",
      "epoch:3 step:3142 [D loss: 0.466914, acc.: 74.22%] [G loss: 0.818327]\n",
      "epoch:3 step:3143 [D loss: 0.457758, acc.: 78.12%] [G loss: 0.735942]\n",
      "epoch:3 step:3144 [D loss: 0.393910, acc.: 86.72%] [G loss: 0.868263]\n",
      "epoch:3 step:3145 [D loss: 0.524112, acc.: 75.78%] [G loss: 0.587728]\n",
      "epoch:3 step:3146 [D loss: 0.471462, acc.: 82.03%] [G loss: 0.819371]\n",
      "epoch:3 step:3147 [D loss: 0.481283, acc.: 77.34%] [G loss: 0.705992]\n",
      "epoch:3 step:3148 [D loss: 0.442003, acc.: 82.03%] [G loss: 0.719965]\n",
      "epoch:3 step:3149 [D loss: 0.472425, acc.: 78.91%] [G loss: 0.838640]\n",
      "epoch:3 step:3150 [D loss: 0.454323, acc.: 81.25%] [G loss: 0.724747]\n",
      "epoch:3 step:3151 [D loss: 0.461483, acc.: 81.25%] [G loss: 0.743763]\n",
      "epoch:3 step:3152 [D loss: 0.430008, acc.: 85.16%] [G loss: 0.745401]\n",
      "epoch:3 step:3153 [D loss: 0.522513, acc.: 71.88%] [G loss: 0.605225]\n",
      "epoch:3 step:3154 [D loss: 0.500134, acc.: 77.34%] [G loss: 0.863610]\n",
      "epoch:3 step:3155 [D loss: 0.412999, acc.: 83.59%] [G loss: 0.994623]\n",
      "epoch:3 step:3156 [D loss: 0.517092, acc.: 76.56%] [G loss: 0.738516]\n",
      "epoch:3 step:3157 [D loss: 0.446736, acc.: 80.47%] [G loss: 1.025521]\n",
      "epoch:3 step:3158 [D loss: 0.487746, acc.: 72.66%] [G loss: 1.050506]\n",
      "epoch:3 step:3159 [D loss: 0.558504, acc.: 71.88%] [G loss: 0.741657]\n",
      "epoch:3 step:3160 [D loss: 0.675497, acc.: 65.62%] [G loss: 0.657311]\n",
      "epoch:3 step:3161 [D loss: 0.429934, acc.: 86.72%] [G loss: 0.825865]\n",
      "epoch:3 step:3162 [D loss: 0.478236, acc.: 78.91%] [G loss: 0.683551]\n",
      "epoch:3 step:3163 [D loss: 0.550390, acc.: 72.66%] [G loss: 0.677131]\n",
      "epoch:3 step:3164 [D loss: 0.501296, acc.: 78.12%] [G loss: 0.605456]\n",
      "epoch:3 step:3165 [D loss: 0.449934, acc.: 80.47%] [G loss: 0.704874]\n",
      "epoch:3 step:3166 [D loss: 0.454073, acc.: 80.47%] [G loss: 0.767885]\n",
      "epoch:3 step:3167 [D loss: 0.494907, acc.: 78.12%] [G loss: 0.826396]\n",
      "epoch:3 step:3168 [D loss: 0.465713, acc.: 79.69%] [G loss: 0.659187]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:3 step:3169 [D loss: 0.402715, acc.: 84.38%] [G loss: 0.721296]\n",
      "epoch:3 step:3170 [D loss: 0.433534, acc.: 82.81%] [G loss: 0.722224]\n",
      "epoch:3 step:3171 [D loss: 0.456543, acc.: 77.34%] [G loss: 0.797616]\n",
      "epoch:3 step:3172 [D loss: 0.462290, acc.: 82.03%] [G loss: 0.663250]\n",
      "epoch:3 step:3173 [D loss: 0.511536, acc.: 75.78%] [G loss: 0.623470]\n",
      "epoch:3 step:3174 [D loss: 0.434845, acc.: 83.59%] [G loss: 0.716260]\n",
      "epoch:3 step:3175 [D loss: 0.511181, acc.: 74.22%] [G loss: 0.536801]\n",
      "epoch:3 step:3176 [D loss: 0.422210, acc.: 85.16%] [G loss: 0.656583]\n",
      "epoch:3 step:3177 [D loss: 0.495355, acc.: 75.78%] [G loss: 0.641813]\n",
      "epoch:3 step:3178 [D loss: 0.523393, acc.: 72.66%] [G loss: 0.670777]\n",
      "epoch:3 step:3179 [D loss: 0.459816, acc.: 78.91%] [G loss: 0.654722]\n",
      "epoch:3 step:3180 [D loss: 0.529518, acc.: 78.12%] [G loss: 0.537023]\n",
      "epoch:3 step:3181 [D loss: 0.486747, acc.: 80.47%] [G loss: 0.662557]\n",
      "epoch:3 step:3182 [D loss: 0.453337, acc.: 83.59%] [G loss: 0.751163]\n",
      "epoch:3 step:3183 [D loss: 0.472880, acc.: 79.69%] [G loss: 0.709872]\n",
      "epoch:3 step:3184 [D loss: 0.509641, acc.: 74.22%] [G loss: 0.611767]\n",
      "epoch:3 step:3185 [D loss: 0.504369, acc.: 76.56%] [G loss: 0.623291]\n",
      "epoch:3 step:3186 [D loss: 0.519452, acc.: 72.66%] [G loss: 0.669129]\n",
      "epoch:3 step:3187 [D loss: 0.565839, acc.: 67.97%] [G loss: 0.699785]\n",
      "epoch:3 step:3188 [D loss: 0.563696, acc.: 73.44%] [G loss: 0.658471]\n",
      "epoch:3 step:3189 [D loss: 0.449039, acc.: 80.47%] [G loss: 0.781489]\n",
      "epoch:3 step:3190 [D loss: 0.530690, acc.: 75.00%] [G loss: 0.647132]\n",
      "epoch:3 step:3191 [D loss: 0.585775, acc.: 68.75%] [G loss: 0.552965]\n",
      "epoch:3 step:3192 [D loss: 0.455697, acc.: 77.34%] [G loss: 0.732830]\n",
      "epoch:3 step:3193 [D loss: 0.469325, acc.: 82.81%] [G loss: 0.779970]\n",
      "epoch:3 step:3194 [D loss: 0.519311, acc.: 75.78%] [G loss: 0.619378]\n",
      "epoch:3 step:3195 [D loss: 0.482273, acc.: 76.56%] [G loss: 0.628892]\n",
      "epoch:3 step:3196 [D loss: 0.513279, acc.: 77.34%] [G loss: 0.763967]\n",
      "epoch:3 step:3197 [D loss: 0.547508, acc.: 71.88%] [G loss: 0.496112]\n",
      "epoch:3 step:3198 [D loss: 0.543520, acc.: 70.31%] [G loss: 0.529851]\n",
      "epoch:3 step:3199 [D loss: 0.498015, acc.: 75.00%] [G loss: 0.621402]\n",
      "epoch:3 step:3200 [D loss: 0.495182, acc.: 78.12%] [G loss: 0.670351]\n",
      "epoch:3 step:3201 [D loss: 0.524865, acc.: 77.34%] [G loss: 0.501665]\n",
      "epoch:3 step:3202 [D loss: 0.455322, acc.: 78.12%] [G loss: 0.727576]\n",
      "epoch:3 step:3203 [D loss: 0.404126, acc.: 85.16%] [G loss: 0.967604]\n",
      "epoch:3 step:3204 [D loss: 0.528192, acc.: 75.00%] [G loss: 0.687160]\n",
      "epoch:3 step:3205 [D loss: 0.490162, acc.: 75.78%] [G loss: 0.553495]\n",
      "epoch:3 step:3206 [D loss: 0.444301, acc.: 80.47%] [G loss: 0.696602]\n",
      "epoch:3 step:3207 [D loss: 0.526848, acc.: 74.22%] [G loss: 0.676830]\n",
      "epoch:3 step:3208 [D loss: 0.431220, acc.: 82.81%] [G loss: 0.695605]\n",
      "epoch:3 step:3209 [D loss: 0.413648, acc.: 82.81%] [G loss: 0.708390]\n",
      "epoch:3 step:3210 [D loss: 0.424568, acc.: 82.03%] [G loss: 0.853137]\n",
      "epoch:3 step:3211 [D loss: 0.592741, acc.: 69.53%] [G loss: 0.590039]\n",
      "epoch:3 step:3212 [D loss: 0.541653, acc.: 73.44%] [G loss: 0.566667]\n",
      "epoch:3 step:3213 [D loss: 0.405853, acc.: 85.16%] [G loss: 0.861616]\n",
      "epoch:3 step:3214 [D loss: 0.455737, acc.: 81.25%] [G loss: 0.769691]\n",
      "epoch:3 step:3215 [D loss: 0.558828, acc.: 71.09%] [G loss: 0.646494]\n",
      "epoch:3 step:3216 [D loss: 0.509102, acc.: 75.00%] [G loss: 0.621952]\n",
      "epoch:3 step:3217 [D loss: 0.487296, acc.: 77.34%] [G loss: 0.815771]\n",
      "epoch:3 step:3218 [D loss: 0.475029, acc.: 77.34%] [G loss: 0.768801]\n",
      "epoch:3 step:3219 [D loss: 0.450561, acc.: 78.91%] [G loss: 0.645986]\n",
      "epoch:3 step:3220 [D loss: 0.477094, acc.: 77.34%] [G loss: 0.571965]\n",
      "epoch:3 step:3221 [D loss: 0.519854, acc.: 73.44%] [G loss: 0.538697]\n",
      "epoch:3 step:3222 [D loss: 0.439769, acc.: 87.50%] [G loss: 0.740101]\n",
      "epoch:3 step:3223 [D loss: 0.524741, acc.: 75.78%] [G loss: 0.615506]\n",
      "epoch:3 step:3224 [D loss: 0.451335, acc.: 79.69%] [G loss: 0.700058]\n",
      "epoch:3 step:3225 [D loss: 0.487888, acc.: 75.78%] [G loss: 0.784666]\n",
      "epoch:3 step:3226 [D loss: 0.541455, acc.: 73.44%] [G loss: 0.532317]\n",
      "epoch:3 step:3227 [D loss: 0.514029, acc.: 69.53%] [G loss: 0.555901]\n",
      "epoch:3 step:3228 [D loss: 0.548638, acc.: 75.00%] [G loss: 0.642102]\n",
      "epoch:3 step:3229 [D loss: 0.526938, acc.: 78.12%] [G loss: 0.657946]\n",
      "epoch:3 step:3230 [D loss: 0.494883, acc.: 75.00%] [G loss: 0.588312]\n",
      "epoch:3 step:3231 [D loss: 0.477174, acc.: 77.34%] [G loss: 0.711297]\n",
      "epoch:3 step:3232 [D loss: 0.508160, acc.: 73.44%] [G loss: 0.640378]\n",
      "epoch:3 step:3233 [D loss: 0.498191, acc.: 76.56%] [G loss: 0.573549]\n",
      "epoch:3 step:3234 [D loss: 0.553572, acc.: 73.44%] [G loss: 0.597293]\n",
      "epoch:3 step:3235 [D loss: 0.498592, acc.: 78.91%] [G loss: 0.638659]\n",
      "epoch:3 step:3236 [D loss: 0.457667, acc.: 84.38%] [G loss: 0.541172]\n",
      "epoch:3 step:3237 [D loss: 0.478197, acc.: 75.78%] [G loss: 0.753063]\n",
      "epoch:3 step:3238 [D loss: 0.445372, acc.: 81.25%] [G loss: 0.878868]\n",
      "epoch:3 step:3239 [D loss: 0.442243, acc.: 84.38%] [G loss: 0.793263]\n",
      "epoch:3 step:3240 [D loss: 0.424997, acc.: 85.94%] [G loss: 0.968871]\n",
      "epoch:3 step:3241 [D loss: 0.462501, acc.: 83.59%] [G loss: 0.820384]\n",
      "epoch:3 step:3242 [D loss: 0.508074, acc.: 75.00%] [G loss: 0.710944]\n",
      "epoch:3 step:3243 [D loss: 0.528957, acc.: 71.88%] [G loss: 0.604690]\n",
      "epoch:3 step:3244 [D loss: 0.536137, acc.: 71.09%] [G loss: 0.561406]\n",
      "epoch:3 step:3245 [D loss: 0.545354, acc.: 71.09%] [G loss: 0.574589]\n",
      "epoch:3 step:3246 [D loss: 0.503149, acc.: 78.91%] [G loss: 0.601201]\n",
      "epoch:3 step:3247 [D loss: 0.479605, acc.: 76.56%] [G loss: 0.600331]\n",
      "epoch:3 step:3248 [D loss: 0.591871, acc.: 64.06%] [G loss: 0.622667]\n",
      "epoch:3 step:3249 [D loss: 0.560210, acc.: 69.53%] [G loss: 0.642566]\n",
      "epoch:3 step:3250 [D loss: 0.473885, acc.: 77.34%] [G loss: 0.662171]\n",
      "epoch:3 step:3251 [D loss: 0.501011, acc.: 76.56%] [G loss: 0.674876]\n",
      "epoch:3 step:3252 [D loss: 0.523539, acc.: 73.44%] [G loss: 0.591869]\n",
      "epoch:3 step:3253 [D loss: 0.499623, acc.: 71.88%] [G loss: 0.527443]\n",
      "epoch:3 step:3254 [D loss: 0.526312, acc.: 72.66%] [G loss: 0.570310]\n",
      "epoch:3 step:3255 [D loss: 0.512141, acc.: 75.00%] [G loss: 0.644320]\n",
      "epoch:3 step:3256 [D loss: 0.493146, acc.: 77.34%] [G loss: 0.647506]\n",
      "epoch:3 step:3257 [D loss: 0.509711, acc.: 75.00%] [G loss: 0.642107]\n",
      "epoch:3 step:3258 [D loss: 0.400376, acc.: 84.38%] [G loss: 0.782354]\n",
      "epoch:3 step:3259 [D loss: 0.508788, acc.: 75.00%] [G loss: 0.690166]\n",
      "epoch:3 step:3260 [D loss: 0.500398, acc.: 77.34%] [G loss: 0.748694]\n",
      "epoch:3 step:3261 [D loss: 0.467105, acc.: 85.16%] [G loss: 0.531972]\n",
      "epoch:3 step:3262 [D loss: 0.437245, acc.: 80.47%] [G loss: 0.867095]\n",
      "epoch:3 step:3263 [D loss: 0.482604, acc.: 75.78%] [G loss: 0.977024]\n",
      "epoch:3 step:3264 [D loss: 0.545541, acc.: 68.75%] [G loss: 0.699149]\n",
      "epoch:3 step:3265 [D loss: 0.544896, acc.: 70.31%] [G loss: 0.596759]\n",
      "epoch:3 step:3266 [D loss: 0.525629, acc.: 71.88%] [G loss: 0.618707]\n",
      "epoch:3 step:3267 [D loss: 0.545628, acc.: 75.00%] [G loss: 0.592797]\n",
      "epoch:3 step:3268 [D loss: 0.488159, acc.: 77.34%] [G loss: 0.682597]\n",
      "epoch:3 step:3269 [D loss: 0.537393, acc.: 72.66%] [G loss: 0.526995]\n",
      "epoch:3 step:3270 [D loss: 0.513405, acc.: 74.22%] [G loss: 0.623329]\n",
      "epoch:3 step:3271 [D loss: 0.475051, acc.: 73.44%] [G loss: 0.555052]\n",
      "epoch:3 step:3272 [D loss: 0.431673, acc.: 80.47%] [G loss: 0.706989]\n",
      "epoch:3 step:3273 [D loss: 0.523488, acc.: 73.44%] [G loss: 0.592530]\n",
      "epoch:3 step:3274 [D loss: 0.482717, acc.: 75.00%] [G loss: 0.704501]\n",
      "epoch:3 step:3275 [D loss: 0.451931, acc.: 82.03%] [G loss: 0.635552]\n",
      "epoch:3 step:3276 [D loss: 0.525622, acc.: 71.88%] [G loss: 0.545834]\n",
      "epoch:3 step:3277 [D loss: 0.486361, acc.: 77.34%] [G loss: 0.540051]\n",
      "epoch:3 step:3278 [D loss: 0.492624, acc.: 76.56%] [G loss: 0.755433]\n",
      "epoch:3 step:3279 [D loss: 0.513332, acc.: 76.56%] [G loss: 0.667073]\n",
      "epoch:3 step:3280 [D loss: 0.514403, acc.: 77.34%] [G loss: 0.614375]\n",
      "epoch:3 step:3281 [D loss: 0.469080, acc.: 78.12%] [G loss: 0.661246]\n",
      "epoch:3 step:3282 [D loss: 0.427413, acc.: 86.72%] [G loss: 0.796674]\n",
      "epoch:3 step:3283 [D loss: 0.416157, acc.: 85.16%] [G loss: 0.958639]\n",
      "epoch:3 step:3284 [D loss: 0.590891, acc.: 72.66%] [G loss: 0.657361]\n",
      "epoch:3 step:3285 [D loss: 0.432934, acc.: 82.81%] [G loss: 0.709106]\n",
      "epoch:3 step:3286 [D loss: 0.465724, acc.: 78.91%] [G loss: 0.734934]\n",
      "epoch:3 step:3287 [D loss: 0.589135, acc.: 72.66%] [G loss: 0.604535]\n",
      "epoch:3 step:3288 [D loss: 0.642898, acc.: 65.62%] [G loss: 0.432544]\n",
      "epoch:3 step:3289 [D loss: 0.534197, acc.: 74.22%] [G loss: 0.437293]\n",
      "epoch:3 step:3290 [D loss: 0.522986, acc.: 76.56%] [G loss: 0.583160]\n",
      "epoch:3 step:3291 [D loss: 0.502733, acc.: 75.00%] [G loss: 0.534250]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:3 step:3292 [D loss: 0.508147, acc.: 81.25%] [G loss: 0.506887]\n",
      "epoch:3 step:3293 [D loss: 0.499276, acc.: 75.78%] [G loss: 0.575732]\n",
      "epoch:3 step:3294 [D loss: 0.565067, acc.: 66.41%] [G loss: 0.570374]\n",
      "epoch:3 step:3295 [D loss: 0.489195, acc.: 77.34%] [G loss: 0.774970]\n",
      "epoch:3 step:3296 [D loss: 0.458520, acc.: 81.25%] [G loss: 0.703929]\n",
      "epoch:3 step:3297 [D loss: 0.609791, acc.: 65.62%] [G loss: 0.472248]\n",
      "epoch:3 step:3298 [D loss: 0.490630, acc.: 80.47%] [G loss: 0.636734]\n",
      "epoch:3 step:3299 [D loss: 0.440293, acc.: 82.03%] [G loss: 0.771984]\n",
      "epoch:3 step:3300 [D loss: 0.610738, acc.: 66.41%] [G loss: 0.544258]\n",
      "epoch:3 step:3301 [D loss: 0.527248, acc.: 75.00%] [G loss: 0.525930]\n",
      "epoch:3 step:3302 [D loss: 0.488973, acc.: 73.44%] [G loss: 0.614195]\n",
      "epoch:3 step:3303 [D loss: 0.495908, acc.: 78.12%] [G loss: 0.572601]\n",
      "epoch:3 step:3304 [D loss: 0.531504, acc.: 73.44%] [G loss: 0.531033]\n",
      "epoch:3 step:3305 [D loss: 0.450342, acc.: 82.81%] [G loss: 0.603639]\n",
      "epoch:3 step:3306 [D loss: 0.500032, acc.: 77.34%] [G loss: 0.597936]\n",
      "epoch:3 step:3307 [D loss: 0.521405, acc.: 72.66%] [G loss: 0.640891]\n",
      "epoch:3 step:3308 [D loss: 0.483294, acc.: 74.22%] [G loss: 0.619130]\n",
      "epoch:3 step:3309 [D loss: 0.448482, acc.: 79.69%] [G loss: 0.754124]\n",
      "epoch:3 step:3310 [D loss: 0.407973, acc.: 85.16%] [G loss: 0.973965]\n",
      "epoch:3 step:3311 [D loss: 0.628942, acc.: 71.09%] [G loss: 0.637002]\n",
      "epoch:3 step:3312 [D loss: 0.615749, acc.: 68.75%] [G loss: 0.441233]\n",
      "epoch:3 step:3313 [D loss: 0.568496, acc.: 70.31%] [G loss: 0.377100]\n",
      "epoch:3 step:3314 [D loss: 0.452074, acc.: 78.12%] [G loss: 0.608959]\n",
      "epoch:3 step:3315 [D loss: 0.409382, acc.: 88.28%] [G loss: 0.662091]\n",
      "epoch:3 step:3316 [D loss: 0.544453, acc.: 71.88%] [G loss: 0.611010]\n",
      "epoch:3 step:3317 [D loss: 0.537789, acc.: 72.66%] [G loss: 0.573602]\n",
      "epoch:3 step:3318 [D loss: 0.510772, acc.: 74.22%] [G loss: 0.632155]\n",
      "epoch:3 step:3319 [D loss: 0.451341, acc.: 80.47%] [G loss: 0.574743]\n",
      "epoch:3 step:3320 [D loss: 0.458563, acc.: 79.69%] [G loss: 0.787097]\n",
      "epoch:3 step:3321 [D loss: 0.497476, acc.: 75.78%] [G loss: 0.734024]\n",
      "epoch:3 step:3322 [D loss: 0.537859, acc.: 74.22%] [G loss: 0.689757]\n",
      "epoch:3 step:3323 [D loss: 0.468836, acc.: 82.81%] [G loss: 0.679899]\n",
      "epoch:3 step:3324 [D loss: 0.459830, acc.: 79.69%] [G loss: 0.580825]\n",
      "epoch:3 step:3325 [D loss: 0.431842, acc.: 84.38%] [G loss: 0.621503]\n",
      "epoch:3 step:3326 [D loss: 0.418726, acc.: 85.16%] [G loss: 0.790107]\n",
      "epoch:3 step:3327 [D loss: 0.462783, acc.: 79.69%] [G loss: 0.654403]\n",
      "epoch:3 step:3328 [D loss: 0.526546, acc.: 76.56%] [G loss: 0.588674]\n",
      "epoch:3 step:3329 [D loss: 0.438841, acc.: 78.12%] [G loss: 0.555000]\n",
      "epoch:3 step:3330 [D loss: 0.443490, acc.: 81.25%] [G loss: 0.600331]\n",
      "epoch:3 step:3331 [D loss: 0.430941, acc.: 79.69%] [G loss: 0.613494]\n",
      "epoch:3 step:3332 [D loss: 0.422385, acc.: 84.38%] [G loss: 0.756086]\n",
      "epoch:3 step:3333 [D loss: 0.435848, acc.: 80.47%] [G loss: 0.757631]\n",
      "epoch:3 step:3334 [D loss: 0.452694, acc.: 82.03%] [G loss: 0.738019]\n",
      "epoch:3 step:3335 [D loss: 0.447148, acc.: 82.81%] [G loss: 0.686746]\n",
      "epoch:3 step:3336 [D loss: 0.473660, acc.: 79.69%] [G loss: 0.655034]\n",
      "epoch:3 step:3337 [D loss: 0.405804, acc.: 85.94%] [G loss: 0.751645]\n",
      "epoch:3 step:3338 [D loss: 0.509592, acc.: 76.56%] [G loss: 0.664370]\n",
      "epoch:3 step:3339 [D loss: 0.596933, acc.: 65.62%] [G loss: 0.492345]\n",
      "epoch:3 step:3340 [D loss: 0.493832, acc.: 80.47%] [G loss: 0.782263]\n",
      "epoch:3 step:3341 [D loss: 0.467838, acc.: 80.47%] [G loss: 0.634451]\n",
      "epoch:3 step:3342 [D loss: 0.528335, acc.: 71.09%] [G loss: 0.640263]\n",
      "epoch:3 step:3343 [D loss: 0.458182, acc.: 80.47%] [G loss: 0.659469]\n",
      "epoch:3 step:3344 [D loss: 0.502633, acc.: 78.91%] [G loss: 0.638503]\n",
      "epoch:3 step:3345 [D loss: 0.453841, acc.: 82.03%] [G loss: 0.690391]\n",
      "epoch:3 step:3346 [D loss: 0.521941, acc.: 75.78%] [G loss: 0.597928]\n",
      "epoch:3 step:3347 [D loss: 0.440636, acc.: 82.03%] [G loss: 0.747392]\n",
      "epoch:3 step:3348 [D loss: 0.531292, acc.: 77.34%] [G loss: 0.671646]\n",
      "epoch:3 step:3349 [D loss: 0.550666, acc.: 72.66%] [G loss: 0.535883]\n",
      "epoch:3 step:3350 [D loss: 0.515846, acc.: 70.31%] [G loss: 0.543639]\n",
      "epoch:3 step:3351 [D loss: 0.523238, acc.: 76.56%] [G loss: 0.658108]\n",
      "epoch:3 step:3352 [D loss: 0.507263, acc.: 74.22%] [G loss: 0.552200]\n",
      "epoch:3 step:3353 [D loss: 0.510459, acc.: 78.12%] [G loss: 0.634388]\n",
      "epoch:3 step:3354 [D loss: 0.557794, acc.: 73.44%] [G loss: 0.623455]\n",
      "epoch:3 step:3355 [D loss: 0.483820, acc.: 75.00%] [G loss: 0.717416]\n",
      "epoch:3 step:3356 [D loss: 0.465044, acc.: 80.47%] [G loss: 0.778008]\n",
      "epoch:3 step:3357 [D loss: 0.443000, acc.: 78.12%] [G loss: 0.828151]\n",
      "epoch:3 step:3358 [D loss: 0.474827, acc.: 75.00%] [G loss: 0.934226]\n",
      "epoch:3 step:3359 [D loss: 0.448315, acc.: 77.34%] [G loss: 0.837241]\n",
      "epoch:3 step:3360 [D loss: 0.503882, acc.: 76.56%] [G loss: 0.500165]\n",
      "epoch:3 step:3361 [D loss: 0.516536, acc.: 72.66%] [G loss: 0.593322]\n",
      "epoch:3 step:3362 [D loss: 0.509690, acc.: 75.00%] [G loss: 0.785281]\n",
      "epoch:3 step:3363 [D loss: 0.441003, acc.: 82.81%] [G loss: 0.684696]\n",
      "epoch:3 step:3364 [D loss: 0.515087, acc.: 72.66%] [G loss: 0.598888]\n",
      "epoch:3 step:3365 [D loss: 0.431887, acc.: 82.81%] [G loss: 0.660740]\n",
      "epoch:3 step:3366 [D loss: 0.427017, acc.: 82.81%] [G loss: 0.718938]\n",
      "epoch:3 step:3367 [D loss: 0.416200, acc.: 85.94%] [G loss: 0.790684]\n",
      "epoch:3 step:3368 [D loss: 0.480913, acc.: 78.91%] [G loss: 0.704087]\n",
      "epoch:3 step:3369 [D loss: 0.431151, acc.: 81.25%] [G loss: 0.646164]\n",
      "epoch:3 step:3370 [D loss: 0.557889, acc.: 69.53%] [G loss: 0.517900]\n",
      "epoch:3 step:3371 [D loss: 0.554110, acc.: 74.22%] [G loss: 0.580308]\n",
      "epoch:3 step:3372 [D loss: 0.529058, acc.: 73.44%] [G loss: 0.602122]\n",
      "epoch:3 step:3373 [D loss: 0.516801, acc.: 75.78%] [G loss: 0.721952]\n",
      "epoch:3 step:3374 [D loss: 0.495153, acc.: 78.91%] [G loss: 0.619704]\n",
      "epoch:3 step:3375 [D loss: 0.513916, acc.: 77.34%] [G loss: 0.551989]\n",
      "epoch:3 step:3376 [D loss: 0.520495, acc.: 78.12%] [G loss: 0.618004]\n",
      "epoch:3 step:3377 [D loss: 0.646821, acc.: 64.84%] [G loss: 0.552055]\n",
      "epoch:3 step:3378 [D loss: 0.482199, acc.: 75.78%] [G loss: 0.653986]\n",
      "epoch:3 step:3379 [D loss: 0.527671, acc.: 82.03%] [G loss: 0.581775]\n",
      "epoch:3 step:3380 [D loss: 0.513185, acc.: 78.12%] [G loss: 0.525927]\n",
      "epoch:3 step:3381 [D loss: 0.498520, acc.: 75.78%] [G loss: 0.446228]\n",
      "epoch:3 step:3382 [D loss: 0.477842, acc.: 78.91%] [G loss: 0.611536]\n",
      "epoch:3 step:3383 [D loss: 0.514866, acc.: 73.44%] [G loss: 0.617992]\n",
      "epoch:3 step:3384 [D loss: 0.468608, acc.: 78.91%] [G loss: 0.670570]\n",
      "epoch:3 step:3385 [D loss: 0.490224, acc.: 80.47%] [G loss: 0.556482]\n",
      "epoch:3 step:3386 [D loss: 0.413392, acc.: 85.16%] [G loss: 0.752759]\n",
      "epoch:3 step:3387 [D loss: 0.545780, acc.: 69.53%] [G loss: 0.718872]\n",
      "epoch:3 step:3388 [D loss: 0.507509, acc.: 77.34%] [G loss: 0.591171]\n",
      "epoch:3 step:3389 [D loss: 0.487441, acc.: 74.22%] [G loss: 0.705003]\n",
      "epoch:3 step:3390 [D loss: 0.516755, acc.: 74.22%] [G loss: 0.516052]\n",
      "epoch:3 step:3391 [D loss: 0.522268, acc.: 77.34%] [G loss: 0.641514]\n",
      "epoch:3 step:3392 [D loss: 0.474492, acc.: 75.78%] [G loss: 0.722815]\n",
      "epoch:3 step:3393 [D loss: 0.424405, acc.: 82.03%] [G loss: 0.810785]\n",
      "epoch:3 step:3394 [D loss: 0.488631, acc.: 74.22%] [G loss: 0.742528]\n",
      "epoch:3 step:3395 [D loss: 0.586346, acc.: 67.19%] [G loss: 0.622489]\n",
      "epoch:3 step:3396 [D loss: 0.540835, acc.: 70.31%] [G loss: 0.540983]\n",
      "epoch:3 step:3397 [D loss: 0.544313, acc.: 71.88%] [G loss: 0.703310]\n",
      "epoch:3 step:3398 [D loss: 0.511047, acc.: 75.78%] [G loss: 0.663480]\n",
      "epoch:3 step:3399 [D loss: 0.552892, acc.: 71.88%] [G loss: 0.561887]\n",
      "epoch:3 step:3400 [D loss: 0.496006, acc.: 77.34%] [G loss: 0.634866]\n",
      "epoch:3 step:3401 [D loss: 0.563112, acc.: 71.88%] [G loss: 0.617996]\n",
      "epoch:3 step:3402 [D loss: 0.519707, acc.: 73.44%] [G loss: 0.621363]\n",
      "epoch:3 step:3403 [D loss: 0.436615, acc.: 82.81%] [G loss: 0.748696]\n",
      "epoch:3 step:3404 [D loss: 0.527849, acc.: 75.00%] [G loss: 0.605469]\n",
      "epoch:3 step:3405 [D loss: 0.508256, acc.: 72.66%] [G loss: 0.597832]\n",
      "epoch:3 step:3406 [D loss: 0.481351, acc.: 77.34%] [G loss: 0.597036]\n",
      "epoch:3 step:3407 [D loss: 0.486258, acc.: 78.12%] [G loss: 0.644956]\n",
      "epoch:3 step:3408 [D loss: 0.497835, acc.: 74.22%] [G loss: 0.582484]\n",
      "epoch:3 step:3409 [D loss: 0.440564, acc.: 83.59%] [G loss: 0.704527]\n",
      "epoch:3 step:3410 [D loss: 0.506782, acc.: 76.56%] [G loss: 0.644832]\n",
      "epoch:3 step:3411 [D loss: 0.571256, acc.: 65.62%] [G loss: 0.457540]\n",
      "epoch:3 step:3412 [D loss: 0.508656, acc.: 75.00%] [G loss: 0.573799]\n",
      "epoch:3 step:3413 [D loss: 0.467094, acc.: 75.00%] [G loss: 0.709938]\n",
      "epoch:3 step:3414 [D loss: 0.444996, acc.: 81.25%] [G loss: 0.665103]\n",
      "epoch:3 step:3415 [D loss: 0.523730, acc.: 71.88%] [G loss: 0.720971]\n",
      "epoch:3 step:3416 [D loss: 0.385980, acc.: 85.94%] [G loss: 0.659567]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:3 step:3417 [D loss: 0.531295, acc.: 71.09%] [G loss: 0.567750]\n",
      "epoch:3 step:3418 [D loss: 0.514869, acc.: 74.22%] [G loss: 0.618346]\n",
      "epoch:3 step:3419 [D loss: 0.513527, acc.: 71.88%] [G loss: 0.654631]\n",
      "epoch:3 step:3420 [D loss: 0.431355, acc.: 78.91%] [G loss: 0.665726]\n",
      "epoch:3 step:3421 [D loss: 0.466797, acc.: 77.34%] [G loss: 0.582514]\n",
      "epoch:3 step:3422 [D loss: 0.442017, acc.: 82.03%] [G loss: 0.771838]\n",
      "epoch:3 step:3423 [D loss: 0.462845, acc.: 78.12%] [G loss: 0.730426]\n",
      "epoch:3 step:3424 [D loss: 0.425036, acc.: 82.81%] [G loss: 0.707147]\n",
      "epoch:3 step:3425 [D loss: 0.509549, acc.: 75.78%] [G loss: 0.669513]\n",
      "epoch:3 step:3426 [D loss: 0.528912, acc.: 75.78%] [G loss: 0.749054]\n",
      "epoch:3 step:3427 [D loss: 0.511362, acc.: 74.22%] [G loss: 0.528610]\n",
      "epoch:3 step:3428 [D loss: 0.590118, acc.: 64.06%] [G loss: 0.530947]\n",
      "epoch:3 step:3429 [D loss: 0.541261, acc.: 75.78%] [G loss: 0.691405]\n",
      "epoch:3 step:3430 [D loss: 0.436273, acc.: 82.81%] [G loss: 0.863639]\n",
      "epoch:3 step:3431 [D loss: 0.556383, acc.: 69.53%] [G loss: 0.742601]\n",
      "epoch:3 step:3432 [D loss: 0.477573, acc.: 79.69%] [G loss: 0.813534]\n",
      "epoch:3 step:3433 [D loss: 0.563400, acc.: 68.75%] [G loss: 0.575267]\n",
      "epoch:3 step:3434 [D loss: 0.451251, acc.: 83.59%] [G loss: 0.624178]\n",
      "epoch:3 step:3435 [D loss: 0.513117, acc.: 72.66%] [G loss: 0.704692]\n",
      "epoch:3 step:3436 [D loss: 0.503091, acc.: 74.22%] [G loss: 0.629110]\n",
      "epoch:3 step:3437 [D loss: 0.426106, acc.: 84.38%] [G loss: 0.681119]\n",
      "epoch:3 step:3438 [D loss: 0.480011, acc.: 77.34%] [G loss: 0.701133]\n",
      "epoch:3 step:3439 [D loss: 0.484891, acc.: 73.44%] [G loss: 0.696000]\n",
      "epoch:3 step:3440 [D loss: 0.476266, acc.: 79.69%] [G loss: 0.667221]\n",
      "epoch:3 step:3441 [D loss: 0.462900, acc.: 74.22%] [G loss: 0.718018]\n",
      "epoch:3 step:3442 [D loss: 0.434399, acc.: 81.25%] [G loss: 0.947204]\n",
      "epoch:3 step:3443 [D loss: 0.466476, acc.: 79.69%] [G loss: 0.725064]\n",
      "epoch:3 step:3444 [D loss: 0.481313, acc.: 80.47%] [G loss: 0.664237]\n",
      "epoch:3 step:3445 [D loss: 0.490883, acc.: 76.56%] [G loss: 0.744847]\n",
      "epoch:3 step:3446 [D loss: 0.496606, acc.: 74.22%] [G loss: 0.933057]\n",
      "epoch:3 step:3447 [D loss: 0.517091, acc.: 77.34%] [G loss: 0.621655]\n",
      "epoch:3 step:3448 [D loss: 0.533826, acc.: 68.75%] [G loss: 0.641413]\n",
      "epoch:3 step:3449 [D loss: 0.451852, acc.: 80.47%] [G loss: 0.675309]\n",
      "epoch:3 step:3450 [D loss: 0.439098, acc.: 81.25%] [G loss: 0.886652]\n",
      "epoch:3 step:3451 [D loss: 0.491612, acc.: 76.56%] [G loss: 0.729248]\n",
      "epoch:3 step:3452 [D loss: 0.439005, acc.: 79.69%] [G loss: 0.844308]\n",
      "epoch:3 step:3453 [D loss: 0.431908, acc.: 82.81%] [G loss: 0.976930]\n",
      "epoch:3 step:3454 [D loss: 0.545566, acc.: 77.34%] [G loss: 0.579249]\n",
      "epoch:3 step:3455 [D loss: 0.465435, acc.: 78.12%] [G loss: 0.546039]\n",
      "epoch:3 step:3456 [D loss: 0.489901, acc.: 76.56%] [G loss: 0.709663]\n",
      "epoch:3 step:3457 [D loss: 0.521628, acc.: 74.22%] [G loss: 0.621717]\n",
      "epoch:3 step:3458 [D loss: 0.468439, acc.: 78.91%] [G loss: 0.694913]\n",
      "epoch:3 step:3459 [D loss: 0.451034, acc.: 80.47%] [G loss: 0.673792]\n",
      "epoch:3 step:3460 [D loss: 0.470845, acc.: 79.69%] [G loss: 0.799087]\n",
      "epoch:3 step:3461 [D loss: 0.523510, acc.: 75.00%] [G loss: 0.697450]\n",
      "epoch:3 step:3462 [D loss: 0.551611, acc.: 72.66%] [G loss: 0.692689]\n",
      "epoch:3 step:3463 [D loss: 0.580488, acc.: 64.84%] [G loss: 0.560592]\n",
      "epoch:3 step:3464 [D loss: 0.569498, acc.: 71.09%] [G loss: 0.525429]\n",
      "epoch:3 step:3465 [D loss: 0.490834, acc.: 77.34%] [G loss: 0.547753]\n",
      "epoch:3 step:3466 [D loss: 0.544693, acc.: 76.56%] [G loss: 0.482994]\n",
      "epoch:3 step:3467 [D loss: 0.525389, acc.: 74.22%] [G loss: 0.509105]\n",
      "epoch:3 step:3468 [D loss: 0.491885, acc.: 75.00%] [G loss: 0.555994]\n",
      "epoch:3 step:3469 [D loss: 0.491773, acc.: 78.12%] [G loss: 0.683939]\n",
      "epoch:3 step:3470 [D loss: 0.501196, acc.: 79.69%] [G loss: 0.695965]\n",
      "epoch:3 step:3471 [D loss: 0.499297, acc.: 77.34%] [G loss: 0.674971]\n",
      "epoch:3 step:3472 [D loss: 0.511890, acc.: 72.66%] [G loss: 0.696957]\n",
      "epoch:3 step:3473 [D loss: 0.557652, acc.: 76.56%] [G loss: 0.603280]\n",
      "epoch:3 step:3474 [D loss: 0.483931, acc.: 75.00%] [G loss: 0.673893]\n",
      "epoch:3 step:3475 [D loss: 0.529872, acc.: 73.44%] [G loss: 0.715304]\n",
      "epoch:3 step:3476 [D loss: 0.487536, acc.: 75.00%] [G loss: 0.744016]\n",
      "epoch:3 step:3477 [D loss: 0.530769, acc.: 75.00%] [G loss: 0.680780]\n",
      "epoch:3 step:3478 [D loss: 0.533007, acc.: 76.56%] [G loss: 0.613100]\n",
      "epoch:3 step:3479 [D loss: 0.539520, acc.: 71.88%] [G loss: 0.650595]\n",
      "epoch:3 step:3480 [D loss: 0.431820, acc.: 82.03%] [G loss: 0.776218]\n",
      "epoch:3 step:3481 [D loss: 0.440173, acc.: 81.25%] [G loss: 0.633227]\n",
      "epoch:3 step:3482 [D loss: 0.570862, acc.: 71.88%] [G loss: 0.542094]\n",
      "epoch:3 step:3483 [D loss: 0.534034, acc.: 74.22%] [G loss: 0.677341]\n",
      "epoch:3 step:3484 [D loss: 0.554327, acc.: 71.88%] [G loss: 0.692706]\n",
      "epoch:3 step:3485 [D loss: 0.531126, acc.: 75.78%] [G loss: 0.629662]\n",
      "epoch:3 step:3486 [D loss: 0.501229, acc.: 76.56%] [G loss: 0.643892]\n",
      "epoch:3 step:3487 [D loss: 0.586316, acc.: 66.41%] [G loss: 0.561760]\n",
      "epoch:3 step:3488 [D loss: 0.401942, acc.: 85.16%] [G loss: 0.835510]\n",
      "epoch:3 step:3489 [D loss: 0.458536, acc.: 82.03%] [G loss: 0.979868]\n",
      "epoch:3 step:3490 [D loss: 0.456318, acc.: 81.25%] [G loss: 0.621874]\n",
      "epoch:3 step:3491 [D loss: 0.452954, acc.: 82.81%] [G loss: 0.623645]\n",
      "epoch:3 step:3492 [D loss: 0.447412, acc.: 82.81%] [G loss: 0.622449]\n",
      "epoch:3 step:3493 [D loss: 0.467000, acc.: 78.12%] [G loss: 0.816731]\n",
      "epoch:3 step:3494 [D loss: 0.518591, acc.: 73.44%] [G loss: 0.636302]\n",
      "epoch:3 step:3495 [D loss: 0.518913, acc.: 75.00%] [G loss: 0.592626]\n",
      "epoch:3 step:3496 [D loss: 0.512725, acc.: 73.44%] [G loss: 0.695800]\n",
      "epoch:3 step:3497 [D loss: 0.497950, acc.: 78.12%] [G loss: 0.639302]\n",
      "epoch:3 step:3498 [D loss: 0.552439, acc.: 70.31%] [G loss: 0.621252]\n",
      "epoch:3 step:3499 [D loss: 0.504645, acc.: 76.56%] [G loss: 0.748116]\n",
      "epoch:3 step:3500 [D loss: 0.494979, acc.: 77.34%] [G loss: 0.754912]\n",
      "epoch:3 step:3501 [D loss: 0.516822, acc.: 75.00%] [G loss: 0.668100]\n",
      "epoch:3 step:3502 [D loss: 0.461213, acc.: 81.25%] [G loss: 0.694161]\n",
      "epoch:3 step:3503 [D loss: 0.456460, acc.: 83.59%] [G loss: 0.643487]\n",
      "epoch:3 step:3504 [D loss: 0.455829, acc.: 78.91%] [G loss: 0.717005]\n",
      "epoch:3 step:3505 [D loss: 0.463344, acc.: 79.69%] [G loss: 0.801798]\n",
      "epoch:3 step:3506 [D loss: 0.494201, acc.: 76.56%] [G loss: 0.815065]\n",
      "epoch:3 step:3507 [D loss: 0.617356, acc.: 66.41%] [G loss: 0.681228]\n",
      "epoch:3 step:3508 [D loss: 0.520386, acc.: 75.78%] [G loss: 0.603019]\n",
      "epoch:3 step:3509 [D loss: 0.505484, acc.: 76.56%] [G loss: 0.654055]\n",
      "epoch:3 step:3510 [D loss: 0.529674, acc.: 72.66%] [G loss: 0.597953]\n",
      "epoch:3 step:3511 [D loss: 0.529676, acc.: 72.66%] [G loss: 0.912902]\n",
      "epoch:3 step:3512 [D loss: 0.488775, acc.: 76.56%] [G loss: 0.826001]\n",
      "epoch:3 step:3513 [D loss: 0.601870, acc.: 67.97%] [G loss: 0.666802]\n",
      "epoch:3 step:3514 [D loss: 0.544981, acc.: 70.31%] [G loss: 0.673641]\n",
      "epoch:3 step:3515 [D loss: 0.585167, acc.: 71.88%] [G loss: 0.555895]\n",
      "epoch:3 step:3516 [D loss: 0.556779, acc.: 70.31%] [G loss: 0.513756]\n",
      "epoch:3 step:3517 [D loss: 0.485645, acc.: 77.34%] [G loss: 0.509195]\n",
      "epoch:3 step:3518 [D loss: 0.478810, acc.: 76.56%] [G loss: 0.779022]\n",
      "epoch:3 step:3519 [D loss: 0.417047, acc.: 79.69%] [G loss: 0.878597]\n",
      "epoch:3 step:3520 [D loss: 0.459995, acc.: 78.91%] [G loss: 0.787777]\n",
      "epoch:3 step:3521 [D loss: 0.613335, acc.: 65.62%] [G loss: 0.623086]\n",
      "epoch:3 step:3522 [D loss: 0.593064, acc.: 67.97%] [G loss: 0.568183]\n",
      "epoch:3 step:3523 [D loss: 0.527394, acc.: 67.19%] [G loss: 0.591878]\n",
      "epoch:3 step:3524 [D loss: 0.557059, acc.: 71.88%] [G loss: 0.565610]\n",
      "epoch:3 step:3525 [D loss: 0.473701, acc.: 79.69%] [G loss: 0.641971]\n",
      "epoch:3 step:3526 [D loss: 0.518276, acc.: 75.00%] [G loss: 0.550281]\n",
      "epoch:3 step:3527 [D loss: 0.527851, acc.: 78.91%] [G loss: 0.581974]\n",
      "epoch:3 step:3528 [D loss: 0.561567, acc.: 73.44%] [G loss: 0.489955]\n",
      "epoch:3 step:3529 [D loss: 0.555577, acc.: 73.44%] [G loss: 0.462991]\n",
      "epoch:3 step:3530 [D loss: 0.498549, acc.: 77.34%] [G loss: 0.640602]\n",
      "epoch:3 step:3531 [D loss: 0.553589, acc.: 70.31%] [G loss: 0.594269]\n",
      "epoch:3 step:3532 [D loss: 0.532056, acc.: 71.09%] [G loss: 0.534812]\n",
      "epoch:3 step:3533 [D loss: 0.475681, acc.: 78.91%] [G loss: 0.678756]\n",
      "epoch:3 step:3534 [D loss: 0.572358, acc.: 67.19%] [G loss: 0.497573]\n",
      "epoch:3 step:3535 [D loss: 0.545696, acc.: 71.09%] [G loss: 0.457064]\n",
      "epoch:3 step:3536 [D loss: 0.509786, acc.: 75.00%] [G loss: 0.726136]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:3 step:3537 [D loss: 0.538910, acc.: 77.34%] [G loss: 0.677950]\n",
      "epoch:3 step:3538 [D loss: 0.580024, acc.: 67.97%] [G loss: 0.512262]\n",
      "epoch:3 step:3539 [D loss: 0.514003, acc.: 70.31%] [G loss: 0.531057]\n",
      "epoch:3 step:3540 [D loss: 0.553833, acc.: 69.53%] [G loss: 0.391650]\n",
      "epoch:3 step:3541 [D loss: 0.515066, acc.: 78.12%] [G loss: 0.484583]\n",
      "epoch:3 step:3542 [D loss: 0.525311, acc.: 75.78%] [G loss: 0.569562]\n",
      "epoch:3 step:3543 [D loss: 0.440991, acc.: 82.03%] [G loss: 0.649160]\n",
      "epoch:3 step:3544 [D loss: 0.481320, acc.: 75.78%] [G loss: 0.728009]\n",
      "epoch:3 step:3545 [D loss: 0.474375, acc.: 78.91%] [G loss: 0.648610]\n",
      "epoch:3 step:3546 [D loss: 0.515170, acc.: 78.91%] [G loss: 0.532353]\n",
      "epoch:3 step:3547 [D loss: 0.442172, acc.: 81.25%] [G loss: 0.596479]\n",
      "epoch:3 step:3548 [D loss: 0.513190, acc.: 74.22%] [G loss: 0.709143]\n",
      "epoch:3 step:3549 [D loss: 0.531296, acc.: 71.09%] [G loss: 0.527575]\n",
      "epoch:3 step:3550 [D loss: 0.550418, acc.: 70.31%] [G loss: 0.429205]\n",
      "epoch:3 step:3551 [D loss: 0.583697, acc.: 63.28%] [G loss: 0.469336]\n",
      "epoch:3 step:3552 [D loss: 0.537511, acc.: 74.22%] [G loss: 0.472169]\n",
      "epoch:3 step:3553 [D loss: 0.529299, acc.: 75.00%] [G loss: 0.579388]\n",
      "epoch:3 step:3554 [D loss: 0.450430, acc.: 81.25%] [G loss: 0.690473]\n",
      "epoch:3 step:3555 [D loss: 0.444943, acc.: 81.25%] [G loss: 0.761912]\n",
      "epoch:3 step:3556 [D loss: 0.552907, acc.: 73.44%] [G loss: 0.553538]\n",
      "epoch:3 step:3557 [D loss: 0.430702, acc.: 79.69%] [G loss: 0.650716]\n",
      "epoch:3 step:3558 [D loss: 0.460073, acc.: 75.78%] [G loss: 0.876864]\n",
      "epoch:3 step:3559 [D loss: 0.470327, acc.: 74.22%] [G loss: 0.820156]\n",
      "epoch:3 step:3560 [D loss: 0.490185, acc.: 75.00%] [G loss: 0.756511]\n",
      "epoch:3 step:3561 [D loss: 0.513007, acc.: 76.56%] [G loss: 0.550588]\n",
      "epoch:3 step:3562 [D loss: 0.519458, acc.: 78.12%] [G loss: 0.616211]\n",
      "epoch:3 step:3563 [D loss: 0.481690, acc.: 82.03%] [G loss: 0.673811]\n",
      "epoch:3 step:3564 [D loss: 0.440704, acc.: 82.81%] [G loss: 0.726066]\n",
      "epoch:3 step:3565 [D loss: 0.475993, acc.: 75.78%] [G loss: 0.911227]\n",
      "epoch:3 step:3566 [D loss: 0.435118, acc.: 84.38%] [G loss: 0.715409]\n",
      "epoch:3 step:3567 [D loss: 0.490903, acc.: 80.47%] [G loss: 0.749941]\n",
      "epoch:3 step:3568 [D loss: 0.482362, acc.: 78.91%] [G loss: 0.640777]\n",
      "epoch:3 step:3569 [D loss: 0.509736, acc.: 77.34%] [G loss: 0.613662]\n",
      "epoch:3 step:3570 [D loss: 0.529742, acc.: 75.00%] [G loss: 0.595927]\n",
      "epoch:3 step:3571 [D loss: 0.494928, acc.: 80.47%] [G loss: 0.694228]\n",
      "epoch:3 step:3572 [D loss: 0.453956, acc.: 80.47%] [G loss: 0.678130]\n",
      "epoch:3 step:3573 [D loss: 0.539237, acc.: 71.88%] [G loss: 0.637810]\n",
      "epoch:3 step:3574 [D loss: 0.515937, acc.: 73.44%] [G loss: 0.589791]\n",
      "epoch:3 step:3575 [D loss: 0.504070, acc.: 73.44%] [G loss: 0.634589]\n",
      "epoch:3 step:3576 [D loss: 0.621792, acc.: 64.06%] [G loss: 0.582430]\n",
      "epoch:3 step:3577 [D loss: 0.620869, acc.: 67.19%] [G loss: 0.474513]\n",
      "epoch:3 step:3578 [D loss: 0.552526, acc.: 72.66%] [G loss: 0.478128]\n",
      "epoch:3 step:3579 [D loss: 0.559653, acc.: 71.09%] [G loss: 0.499955]\n",
      "epoch:3 step:3580 [D loss: 0.396774, acc.: 84.38%] [G loss: 0.749213]\n",
      "epoch:3 step:3581 [D loss: 0.510074, acc.: 73.44%] [G loss: 0.856978]\n",
      "epoch:3 step:3582 [D loss: 0.443149, acc.: 84.38%] [G loss: 0.728333]\n",
      "epoch:3 step:3583 [D loss: 0.483331, acc.: 78.91%] [G loss: 0.540713]\n",
      "epoch:3 step:3584 [D loss: 0.480103, acc.: 78.91%] [G loss: 0.611044]\n",
      "epoch:3 step:3585 [D loss: 0.562971, acc.: 73.44%] [G loss: 0.613759]\n",
      "epoch:3 step:3586 [D loss: 0.449656, acc.: 81.25%] [G loss: 0.828806]\n",
      "epoch:3 step:3587 [D loss: 0.592918, acc.: 66.41%] [G loss: 0.510934]\n",
      "epoch:3 step:3588 [D loss: 0.474242, acc.: 78.12%] [G loss: 0.554716]\n",
      "epoch:3 step:3589 [D loss: 0.525190, acc.: 71.88%] [G loss: 0.480885]\n",
      "epoch:3 step:3590 [D loss: 0.445233, acc.: 80.47%] [G loss: 0.675561]\n",
      "epoch:3 step:3591 [D loss: 0.509163, acc.: 75.78%] [G loss: 0.605895]\n",
      "epoch:3 step:3592 [D loss: 0.449489, acc.: 78.91%] [G loss: 0.719245]\n",
      "epoch:3 step:3593 [D loss: 0.482814, acc.: 78.12%] [G loss: 0.745837]\n",
      "epoch:3 step:3594 [D loss: 0.556957, acc.: 72.66%] [G loss: 0.612943]\n",
      "epoch:3 step:3595 [D loss: 0.503210, acc.: 72.66%] [G loss: 0.634599]\n",
      "epoch:3 step:3596 [D loss: 0.536676, acc.: 73.44%] [G loss: 0.472834]\n",
      "epoch:3 step:3597 [D loss: 0.485199, acc.: 75.78%] [G loss: 0.675476]\n",
      "epoch:3 step:3598 [D loss: 0.539892, acc.: 75.00%] [G loss: 0.694401]\n",
      "epoch:3 step:3599 [D loss: 0.602698, acc.: 65.62%] [G loss: 0.553138]\n",
      "epoch:3 step:3600 [D loss: 0.476947, acc.: 78.91%] [G loss: 0.573534]\n",
      "epoch:3 step:3601 [D loss: 0.501738, acc.: 76.56%] [G loss: 0.553715]\n",
      "epoch:3 step:3602 [D loss: 0.480883, acc.: 78.91%] [G loss: 0.654465]\n",
      "epoch:3 step:3603 [D loss: 0.402426, acc.: 83.59%] [G loss: 0.837594]\n",
      "epoch:3 step:3604 [D loss: 0.514739, acc.: 75.00%] [G loss: 0.769454]\n",
      "epoch:3 step:3605 [D loss: 0.531309, acc.: 73.44%] [G loss: 0.683727]\n",
      "epoch:3 step:3606 [D loss: 0.456466, acc.: 78.91%] [G loss: 0.678280]\n",
      "epoch:3 step:3607 [D loss: 0.482288, acc.: 75.00%] [G loss: 0.693234]\n",
      "epoch:3 step:3608 [D loss: 0.536499, acc.: 74.22%] [G loss: 0.563251]\n",
      "epoch:3 step:3609 [D loss: 0.559547, acc.: 71.88%] [G loss: 0.550554]\n",
      "epoch:3 step:3610 [D loss: 0.559219, acc.: 72.66%] [G loss: 0.653117]\n",
      "epoch:3 step:3611 [D loss: 0.570079, acc.: 67.19%] [G loss: 0.528682]\n",
      "epoch:3 step:3612 [D loss: 0.519217, acc.: 75.00%] [G loss: 0.757518]\n",
      "epoch:3 step:3613 [D loss: 0.479558, acc.: 76.56%] [G loss: 0.817556]\n",
      "epoch:3 step:3614 [D loss: 0.408757, acc.: 82.03%] [G loss: 0.924272]\n",
      "epoch:3 step:3615 [D loss: 0.485297, acc.: 77.34%] [G loss: 0.688648]\n",
      "epoch:3 step:3616 [D loss: 0.454597, acc.: 78.91%] [G loss: 0.662511]\n",
      "epoch:3 step:3617 [D loss: 0.479979, acc.: 81.25%] [G loss: 0.606198]\n",
      "epoch:3 step:3618 [D loss: 0.483837, acc.: 75.78%] [G loss: 0.636764]\n",
      "epoch:3 step:3619 [D loss: 0.550659, acc.: 70.31%] [G loss: 0.604492]\n",
      "epoch:3 step:3620 [D loss: 0.518932, acc.: 72.66%] [G loss: 0.618052]\n",
      "epoch:3 step:3621 [D loss: 0.433265, acc.: 82.03%] [G loss: 0.547938]\n",
      "epoch:3 step:3622 [D loss: 0.502693, acc.: 78.12%] [G loss: 0.599503]\n",
      "epoch:3 step:3623 [D loss: 0.547558, acc.: 75.78%] [G loss: 0.533756]\n",
      "epoch:3 step:3624 [D loss: 0.474871, acc.: 77.34%] [G loss: 0.633786]\n",
      "epoch:3 step:3625 [D loss: 0.463893, acc.: 79.69%] [G loss: 0.597194]\n",
      "epoch:3 step:3626 [D loss: 0.485648, acc.: 78.12%] [G loss: 0.635548]\n",
      "epoch:3 step:3627 [D loss: 0.480982, acc.: 78.91%] [G loss: 0.521361]\n",
      "epoch:3 step:3628 [D loss: 0.542996, acc.: 71.09%] [G loss: 0.569978]\n",
      "epoch:3 step:3629 [D loss: 0.514373, acc.: 76.56%] [G loss: 0.605823]\n",
      "epoch:3 step:3630 [D loss: 0.505957, acc.: 73.44%] [G loss: 0.652436]\n",
      "epoch:3 step:3631 [D loss: 0.504991, acc.: 75.00%] [G loss: 0.700411]\n",
      "epoch:3 step:3632 [D loss: 0.471317, acc.: 77.34%] [G loss: 0.572115]\n",
      "epoch:3 step:3633 [D loss: 0.444099, acc.: 82.81%] [G loss: 0.575864]\n",
      "epoch:3 step:3634 [D loss: 0.467455, acc.: 74.22%] [G loss: 0.691538]\n",
      "epoch:3 step:3635 [D loss: 0.649926, acc.: 71.09%] [G loss: 0.538250]\n",
      "epoch:3 step:3636 [D loss: 0.560537, acc.: 70.31%] [G loss: 0.660330]\n",
      "epoch:3 step:3637 [D loss: 0.541741, acc.: 71.88%] [G loss: 0.611411]\n",
      "epoch:3 step:3638 [D loss: 0.539582, acc.: 75.78%] [G loss: 0.534496]\n",
      "epoch:3 step:3639 [D loss: 0.571472, acc.: 68.75%] [G loss: 0.599776]\n",
      "epoch:3 step:3640 [D loss: 0.438892, acc.: 82.03%] [G loss: 0.652262]\n",
      "epoch:3 step:3641 [D loss: 0.482485, acc.: 77.34%] [G loss: 0.714349]\n",
      "epoch:3 step:3642 [D loss: 0.505666, acc.: 76.56%] [G loss: 0.589585]\n",
      "epoch:3 step:3643 [D loss: 0.457662, acc.: 83.59%] [G loss: 0.627419]\n",
      "epoch:3 step:3644 [D loss: 0.495591, acc.: 76.56%] [G loss: 0.706226]\n",
      "epoch:3 step:3645 [D loss: 0.468102, acc.: 78.12%] [G loss: 0.668152]\n",
      "epoch:3 step:3646 [D loss: 0.480076, acc.: 78.91%] [G loss: 0.566529]\n",
      "epoch:3 step:3647 [D loss: 0.573613, acc.: 71.09%] [G loss: 0.567807]\n",
      "epoch:3 step:3648 [D loss: 0.507359, acc.: 72.66%] [G loss: 0.637903]\n",
      "epoch:3 step:3649 [D loss: 0.465205, acc.: 83.59%] [G loss: 0.746779]\n",
      "epoch:3 step:3650 [D loss: 0.499471, acc.: 75.78%] [G loss: 0.628471]\n",
      "epoch:3 step:3651 [D loss: 0.548539, acc.: 73.44%] [G loss: 0.611128]\n",
      "epoch:3 step:3652 [D loss: 0.495627, acc.: 78.12%] [G loss: 0.594347]\n",
      "epoch:3 step:3653 [D loss: 0.462850, acc.: 78.12%] [G loss: 0.718335]\n",
      "epoch:3 step:3654 [D loss: 0.484582, acc.: 80.47%] [G loss: 0.723723]\n",
      "epoch:3 step:3655 [D loss: 0.534466, acc.: 73.44%] [G loss: 0.629432]\n",
      "epoch:3 step:3656 [D loss: 0.539130, acc.: 74.22%] [G loss: 0.548002]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:3 step:3657 [D loss: 0.507625, acc.: 76.56%] [G loss: 0.461609]\n",
      "epoch:3 step:3658 [D loss: 0.534454, acc.: 73.44%] [G loss: 0.477790]\n",
      "epoch:3 step:3659 [D loss: 0.468370, acc.: 81.25%] [G loss: 0.598347]\n",
      "epoch:3 step:3660 [D loss: 0.559144, acc.: 69.53%] [G loss: 0.584833]\n",
      "epoch:3 step:3661 [D loss: 0.511832, acc.: 75.00%] [G loss: 0.522688]\n",
      "epoch:3 step:3662 [D loss: 0.564911, acc.: 71.09%] [G loss: 0.576768]\n",
      "epoch:3 step:3663 [D loss: 0.453227, acc.: 81.25%] [G loss: 0.628348]\n",
      "epoch:3 step:3664 [D loss: 0.503316, acc.: 76.56%] [G loss: 0.800556]\n",
      "epoch:3 step:3665 [D loss: 0.398148, acc.: 87.50%] [G loss: 0.859943]\n",
      "epoch:3 step:3666 [D loss: 0.529946, acc.: 75.00%] [G loss: 0.799348]\n",
      "epoch:3 step:3667 [D loss: 0.584826, acc.: 70.31%] [G loss: 0.544974]\n",
      "epoch:3 step:3668 [D loss: 0.470025, acc.: 77.34%] [G loss: 0.698250]\n",
      "epoch:3 step:3669 [D loss: 0.595033, acc.: 65.62%] [G loss: 0.634494]\n",
      "epoch:3 step:3670 [D loss: 0.483045, acc.: 78.12%] [G loss: 0.715802]\n",
      "epoch:3 step:3671 [D loss: 0.482709, acc.: 75.78%] [G loss: 0.761218]\n",
      "epoch:3 step:3672 [D loss: 0.588476, acc.: 62.50%] [G loss: 0.544380]\n",
      "epoch:3 step:3673 [D loss: 0.499843, acc.: 76.56%] [G loss: 0.627200]\n",
      "epoch:3 step:3674 [D loss: 0.552192, acc.: 72.66%] [G loss: 0.479487]\n",
      "epoch:3 step:3675 [D loss: 0.438980, acc.: 84.38%] [G loss: 0.770117]\n",
      "epoch:3 step:3676 [D loss: 0.511105, acc.: 73.44%] [G loss: 0.649081]\n",
      "epoch:3 step:3677 [D loss: 0.470558, acc.: 78.12%] [G loss: 0.619443]\n",
      "epoch:3 step:3678 [D loss: 0.551115, acc.: 67.19%] [G loss: 0.578484]\n",
      "epoch:3 step:3679 [D loss: 0.523295, acc.: 71.88%] [G loss: 0.541718]\n",
      "epoch:3 step:3680 [D loss: 0.537691, acc.: 72.66%] [G loss: 0.532534]\n",
      "epoch:3 step:3681 [D loss: 0.491747, acc.: 75.78%] [G loss: 0.662321]\n",
      "epoch:3 step:3682 [D loss: 0.484767, acc.: 81.25%] [G loss: 0.616326]\n",
      "epoch:3 step:3683 [D loss: 0.521842, acc.: 73.44%] [G loss: 0.558285]\n",
      "epoch:3 step:3684 [D loss: 0.515068, acc.: 75.78%] [G loss: 0.589876]\n",
      "epoch:3 step:3685 [D loss: 0.533710, acc.: 70.31%] [G loss: 0.658452]\n",
      "epoch:3 step:3686 [D loss: 0.454233, acc.: 81.25%] [G loss: 0.750510]\n",
      "epoch:3 step:3687 [D loss: 0.561848, acc.: 71.09%] [G loss: 0.688967]\n",
      "epoch:3 step:3688 [D loss: 0.542608, acc.: 75.00%] [G loss: 0.513690]\n",
      "epoch:3 step:3689 [D loss: 0.511821, acc.: 74.22%] [G loss: 0.588017]\n",
      "epoch:3 step:3690 [D loss: 0.506090, acc.: 75.78%] [G loss: 0.543644]\n",
      "epoch:3 step:3691 [D loss: 0.590787, acc.: 71.09%] [G loss: 0.491616]\n",
      "epoch:3 step:3692 [D loss: 0.516873, acc.: 75.00%] [G loss: 0.663419]\n",
      "epoch:3 step:3693 [D loss: 0.570605, acc.: 64.06%] [G loss: 0.514432]\n",
      "epoch:3 step:3694 [D loss: 0.525527, acc.: 75.78%] [G loss: 0.550943]\n",
      "epoch:3 step:3695 [D loss: 0.418834, acc.: 86.72%] [G loss: 0.614004]\n",
      "epoch:3 step:3696 [D loss: 0.454656, acc.: 78.91%] [G loss: 0.804541]\n",
      "epoch:3 step:3697 [D loss: 0.471152, acc.: 78.12%] [G loss: 0.809596]\n",
      "epoch:3 step:3698 [D loss: 0.456010, acc.: 78.12%] [G loss: 0.846515]\n",
      "epoch:3 step:3699 [D loss: 0.467030, acc.: 77.34%] [G loss: 0.786698]\n",
      "epoch:3 step:3700 [D loss: 0.532720, acc.: 71.09%] [G loss: 0.632085]\n",
      "epoch:3 step:3701 [D loss: 0.395219, acc.: 85.94%] [G loss: 0.719505]\n",
      "epoch:3 step:3702 [D loss: 0.486668, acc.: 78.91%] [G loss: 0.819962]\n",
      "epoch:3 step:3703 [D loss: 0.579665, acc.: 69.53%] [G loss: 0.610492]\n",
      "epoch:3 step:3704 [D loss: 0.470151, acc.: 82.81%] [G loss: 0.570322]\n",
      "epoch:3 step:3705 [D loss: 0.449444, acc.: 81.25%] [G loss: 0.633692]\n",
      "epoch:3 step:3706 [D loss: 0.448863, acc.: 83.59%] [G loss: 0.674314]\n",
      "epoch:3 step:3707 [D loss: 0.507263, acc.: 74.22%] [G loss: 0.579021]\n",
      "epoch:3 step:3708 [D loss: 0.461242, acc.: 78.12%] [G loss: 0.713123]\n",
      "epoch:3 step:3709 [D loss: 0.446880, acc.: 78.91%] [G loss: 0.774614]\n",
      "epoch:3 step:3710 [D loss: 0.480771, acc.: 78.12%] [G loss: 0.785666]\n",
      "epoch:3 step:3711 [D loss: 0.478558, acc.: 80.47%] [G loss: 0.748530]\n",
      "epoch:3 step:3712 [D loss: 0.487681, acc.: 76.56%] [G loss: 0.673426]\n",
      "epoch:3 step:3713 [D loss: 0.519867, acc.: 78.12%] [G loss: 0.523463]\n",
      "epoch:3 step:3714 [D loss: 0.505718, acc.: 76.56%] [G loss: 0.603953]\n",
      "epoch:3 step:3715 [D loss: 0.419498, acc.: 83.59%] [G loss: 0.732652]\n",
      "epoch:3 step:3716 [D loss: 0.489799, acc.: 75.00%] [G loss: 0.677757]\n",
      "epoch:3 step:3717 [D loss: 0.494570, acc.: 76.56%] [G loss: 0.794344]\n",
      "epoch:3 step:3718 [D loss: 0.544722, acc.: 72.66%] [G loss: 0.603628]\n",
      "epoch:3 step:3719 [D loss: 0.511751, acc.: 78.12%] [G loss: 0.692043]\n",
      "epoch:3 step:3720 [D loss: 0.462156, acc.: 80.47%] [G loss: 0.564730]\n",
      "epoch:3 step:3721 [D loss: 0.481997, acc.: 82.03%] [G loss: 0.679719]\n",
      "epoch:3 step:3722 [D loss: 0.444063, acc.: 78.12%] [G loss: 0.861499]\n",
      "epoch:3 step:3723 [D loss: 0.404686, acc.: 85.94%] [G loss: 1.023684]\n",
      "epoch:3 step:3724 [D loss: 0.596775, acc.: 68.75%] [G loss: 0.875192]\n",
      "epoch:3 step:3725 [D loss: 0.512723, acc.: 70.31%] [G loss: 0.754138]\n",
      "epoch:3 step:3726 [D loss: 0.536043, acc.: 74.22%] [G loss: 0.721090]\n",
      "epoch:3 step:3727 [D loss: 0.544238, acc.: 69.53%] [G loss: 0.527912]\n",
      "epoch:3 step:3728 [D loss: 0.464146, acc.: 82.03%] [G loss: 0.832732]\n",
      "epoch:3 step:3729 [D loss: 0.451312, acc.: 85.16%] [G loss: 0.585677]\n",
      "epoch:3 step:3730 [D loss: 0.503230, acc.: 75.78%] [G loss: 0.744833]\n",
      "epoch:3 step:3731 [D loss: 0.630213, acc.: 72.66%] [G loss: 0.641687]\n",
      "epoch:3 step:3732 [D loss: 0.467256, acc.: 85.16%] [G loss: 0.642574]\n",
      "epoch:3 step:3733 [D loss: 0.531983, acc.: 76.56%] [G loss: 0.543652]\n",
      "epoch:3 step:3734 [D loss: 0.440558, acc.: 84.38%] [G loss: 0.585407]\n",
      "epoch:3 step:3735 [D loss: 0.383755, acc.: 86.72%] [G loss: 0.795114]\n",
      "epoch:3 step:3736 [D loss: 0.411873, acc.: 85.94%] [G loss: 0.931227]\n",
      "epoch:3 step:3737 [D loss: 0.413399, acc.: 82.81%] [G loss: 0.978579]\n",
      "epoch:3 step:3738 [D loss: 0.474653, acc.: 75.00%] [G loss: 0.920217]\n",
      "epoch:3 step:3739 [D loss: 0.784441, acc.: 63.28%] [G loss: 0.861862]\n",
      "epoch:3 step:3740 [D loss: 0.457251, acc.: 75.00%] [G loss: 1.052182]\n",
      "epoch:3 step:3741 [D loss: 0.387155, acc.: 82.81%] [G loss: 1.156368]\n",
      "epoch:3 step:3742 [D loss: 0.572414, acc.: 67.19%] [G loss: 0.803931]\n",
      "epoch:3 step:3743 [D loss: 0.537651, acc.: 70.31%] [G loss: 0.569631]\n",
      "epoch:3 step:3744 [D loss: 0.433957, acc.: 82.03%] [G loss: 0.671552]\n",
      "epoch:3 step:3745 [D loss: 0.543310, acc.: 74.22%] [G loss: 0.637839]\n",
      "epoch:3 step:3746 [D loss: 0.452443, acc.: 78.12%] [G loss: 0.750777]\n",
      "epoch:3 step:3747 [D loss: 0.334361, acc.: 87.50%] [G loss: 1.138755]\n",
      "epoch:3 step:3748 [D loss: 0.392649, acc.: 85.94%] [G loss: 1.223899]\n",
      "epoch:4 step:3749 [D loss: 0.574129, acc.: 70.31%] [G loss: 0.991638]\n",
      "epoch:4 step:3750 [D loss: 0.458913, acc.: 80.47%] [G loss: 0.870762]\n",
      "epoch:4 step:3751 [D loss: 0.595007, acc.: 69.53%] [G loss: 0.721155]\n",
      "epoch:4 step:3752 [D loss: 0.485102, acc.: 78.12%] [G loss: 0.755659]\n",
      "epoch:4 step:3753 [D loss: 0.502986, acc.: 76.56%] [G loss: 0.745306]\n",
      "epoch:4 step:3754 [D loss: 0.515095, acc.: 72.66%] [G loss: 0.695132]\n",
      "epoch:4 step:3755 [D loss: 0.463993, acc.: 78.12%] [G loss: 0.802918]\n",
      "epoch:4 step:3756 [D loss: 0.502191, acc.: 73.44%] [G loss: 0.671847]\n",
      "epoch:4 step:3757 [D loss: 0.511754, acc.: 75.00%] [G loss: 0.735160]\n",
      "epoch:4 step:3758 [D loss: 0.510767, acc.: 75.00%] [G loss: 0.633832]\n",
      "epoch:4 step:3759 [D loss: 0.395584, acc.: 85.94%] [G loss: 0.725762]\n",
      "epoch:4 step:3760 [D loss: 0.496616, acc.: 75.78%] [G loss: 0.546631]\n",
      "epoch:4 step:3761 [D loss: 0.503284, acc.: 75.00%] [G loss: 0.574783]\n",
      "epoch:4 step:3762 [D loss: 0.501604, acc.: 72.66%] [G loss: 0.642436]\n",
      "epoch:4 step:3763 [D loss: 0.414176, acc.: 85.94%] [G loss: 0.791690]\n",
      "epoch:4 step:3764 [D loss: 0.426610, acc.: 84.38%] [G loss: 0.741782]\n",
      "epoch:4 step:3765 [D loss: 0.507205, acc.: 75.78%] [G loss: 0.724972]\n",
      "epoch:4 step:3766 [D loss: 0.528680, acc.: 72.66%] [G loss: 0.582357]\n",
      "epoch:4 step:3767 [D loss: 0.477969, acc.: 78.12%] [G loss: 0.616614]\n",
      "epoch:4 step:3768 [D loss: 0.541854, acc.: 71.09%] [G loss: 0.653790]\n",
      "epoch:4 step:3769 [D loss: 0.525418, acc.: 77.34%] [G loss: 0.803856]\n",
      "epoch:4 step:3770 [D loss: 0.440837, acc.: 84.38%] [G loss: 0.668227]\n",
      "epoch:4 step:3771 [D loss: 0.501016, acc.: 75.00%] [G loss: 0.683312]\n",
      "epoch:4 step:3772 [D loss: 0.488401, acc.: 75.78%] [G loss: 0.645672]\n",
      "epoch:4 step:3773 [D loss: 0.466020, acc.: 83.59%] [G loss: 0.698257]\n",
      "epoch:4 step:3774 [D loss: 0.506479, acc.: 73.44%] [G loss: 0.629608]\n",
      "epoch:4 step:3775 [D loss: 0.443134, acc.: 82.03%] [G loss: 0.670876]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:4 step:3776 [D loss: 0.486155, acc.: 77.34%] [G loss: 0.688424]\n",
      "epoch:4 step:3777 [D loss: 0.436127, acc.: 81.25%] [G loss: 0.680537]\n",
      "epoch:4 step:3778 [D loss: 0.549193, acc.: 69.53%] [G loss: 0.570365]\n",
      "epoch:4 step:3779 [D loss: 0.527007, acc.: 77.34%] [G loss: 0.632243]\n",
      "epoch:4 step:3780 [D loss: 0.512264, acc.: 74.22%] [G loss: 0.719812]\n",
      "epoch:4 step:3781 [D loss: 0.504203, acc.: 77.34%] [G loss: 0.685316]\n",
      "epoch:4 step:3782 [D loss: 0.510256, acc.: 75.78%] [G loss: 0.577198]\n",
      "epoch:4 step:3783 [D loss: 0.552865, acc.: 68.75%] [G loss: 0.541734]\n",
      "epoch:4 step:3784 [D loss: 0.431516, acc.: 82.81%] [G loss: 0.783511]\n",
      "epoch:4 step:3785 [D loss: 0.423831, acc.: 83.59%] [G loss: 0.706822]\n",
      "epoch:4 step:3786 [D loss: 0.556455, acc.: 74.22%] [G loss: 0.698984]\n",
      "epoch:4 step:3787 [D loss: 0.493879, acc.: 75.78%] [G loss: 0.694235]\n",
      "epoch:4 step:3788 [D loss: 0.399524, acc.: 85.94%] [G loss: 0.742717]\n",
      "epoch:4 step:3789 [D loss: 0.569403, acc.: 71.88%] [G loss: 0.580884]\n",
      "epoch:4 step:3790 [D loss: 0.490646, acc.: 74.22%] [G loss: 0.627443]\n",
      "epoch:4 step:3791 [D loss: 0.485008, acc.: 73.44%] [G loss: 0.544288]\n",
      "epoch:4 step:3792 [D loss: 0.527901, acc.: 77.34%] [G loss: 0.565368]\n",
      "epoch:4 step:3793 [D loss: 0.490160, acc.: 78.12%] [G loss: 0.612345]\n",
      "epoch:4 step:3794 [D loss: 0.469797, acc.: 79.69%] [G loss: 0.624470]\n",
      "epoch:4 step:3795 [D loss: 0.502505, acc.: 77.34%] [G loss: 0.588894]\n",
      "epoch:4 step:3796 [D loss: 0.506195, acc.: 78.91%] [G loss: 0.579945]\n",
      "epoch:4 step:3797 [D loss: 0.518298, acc.: 75.00%] [G loss: 0.620441]\n",
      "epoch:4 step:3798 [D loss: 0.503683, acc.: 73.44%] [G loss: 0.657482]\n",
      "epoch:4 step:3799 [D loss: 0.520293, acc.: 71.88%] [G loss: 0.541726]\n",
      "epoch:4 step:3800 [D loss: 0.523347, acc.: 73.44%] [G loss: 0.561997]\n",
      "epoch:4 step:3801 [D loss: 0.452589, acc.: 80.47%] [G loss: 0.642047]\n",
      "epoch:4 step:3802 [D loss: 0.467556, acc.: 78.12%] [G loss: 0.877961]\n",
      "epoch:4 step:3803 [D loss: 0.530728, acc.: 77.34%] [G loss: 0.627800]\n",
      "epoch:4 step:3804 [D loss: 0.457059, acc.: 78.12%] [G loss: 0.680810]\n",
      "epoch:4 step:3805 [D loss: 0.448001, acc.: 81.25%] [G loss: 0.708403]\n",
      "epoch:4 step:3806 [D loss: 0.444486, acc.: 83.59%] [G loss: 0.854612]\n",
      "epoch:4 step:3807 [D loss: 0.482834, acc.: 75.00%] [G loss: 0.687154]\n",
      "epoch:4 step:3808 [D loss: 0.539422, acc.: 72.66%] [G loss: 0.688050]\n",
      "epoch:4 step:3809 [D loss: 0.497287, acc.: 77.34%] [G loss: 0.567941]\n",
      "epoch:4 step:3810 [D loss: 0.530255, acc.: 75.00%] [G loss: 0.615131]\n",
      "epoch:4 step:3811 [D loss: 0.474940, acc.: 81.25%] [G loss: 0.623553]\n",
      "epoch:4 step:3812 [D loss: 0.500354, acc.: 75.78%] [G loss: 0.596621]\n",
      "epoch:4 step:3813 [D loss: 0.519366, acc.: 78.91%] [G loss: 0.469015]\n",
      "epoch:4 step:3814 [D loss: 0.485255, acc.: 75.00%] [G loss: 0.637601]\n",
      "epoch:4 step:3815 [D loss: 0.530321, acc.: 76.56%] [G loss: 0.612847]\n",
      "epoch:4 step:3816 [D loss: 0.506509, acc.: 76.56%] [G loss: 0.580774]\n",
      "epoch:4 step:3817 [D loss: 0.528817, acc.: 78.12%] [G loss: 0.695481]\n",
      "epoch:4 step:3818 [D loss: 0.474164, acc.: 78.91%] [G loss: 0.681725]\n",
      "epoch:4 step:3819 [D loss: 0.476346, acc.: 77.34%] [G loss: 0.657689]\n",
      "epoch:4 step:3820 [D loss: 0.460350, acc.: 79.69%] [G loss: 0.828845]\n",
      "epoch:4 step:3821 [D loss: 0.482714, acc.: 76.56%] [G loss: 0.747093]\n",
      "epoch:4 step:3822 [D loss: 0.451759, acc.: 79.69%] [G loss: 0.816367]\n",
      "epoch:4 step:3823 [D loss: 0.482953, acc.: 78.91%] [G loss: 0.741927]\n",
      "epoch:4 step:3824 [D loss: 0.465718, acc.: 79.69%] [G loss: 0.813218]\n",
      "epoch:4 step:3825 [D loss: 0.416226, acc.: 83.59%] [G loss: 0.860219]\n",
      "epoch:4 step:3826 [D loss: 0.585510, acc.: 66.41%] [G loss: 0.603919]\n",
      "epoch:4 step:3827 [D loss: 0.506700, acc.: 76.56%] [G loss: 0.625605]\n",
      "epoch:4 step:3828 [D loss: 0.577799, acc.: 68.75%] [G loss: 0.617327]\n",
      "epoch:4 step:3829 [D loss: 0.574153, acc.: 67.19%] [G loss: 0.506507]\n",
      "epoch:4 step:3830 [D loss: 0.461036, acc.: 80.47%] [G loss: 0.557059]\n",
      "epoch:4 step:3831 [D loss: 0.457180, acc.: 78.12%] [G loss: 0.585047]\n",
      "epoch:4 step:3832 [D loss: 0.492954, acc.: 77.34%] [G loss: 0.517631]\n",
      "epoch:4 step:3833 [D loss: 0.539607, acc.: 72.66%] [G loss: 0.445073]\n",
      "epoch:4 step:3834 [D loss: 0.464565, acc.: 79.69%] [G loss: 0.638804]\n",
      "epoch:4 step:3835 [D loss: 0.465358, acc.: 80.47%] [G loss: 0.629096]\n",
      "epoch:4 step:3836 [D loss: 0.430393, acc.: 81.25%] [G loss: 0.688568]\n",
      "epoch:4 step:3837 [D loss: 0.425824, acc.: 82.03%] [G loss: 0.693793]\n",
      "epoch:4 step:3838 [D loss: 0.491523, acc.: 73.44%] [G loss: 0.744427]\n",
      "epoch:4 step:3839 [D loss: 0.507331, acc.: 76.56%] [G loss: 0.714421]\n",
      "epoch:4 step:3840 [D loss: 0.445702, acc.: 80.47%] [G loss: 0.727442]\n",
      "epoch:4 step:3841 [D loss: 0.470864, acc.: 79.69%] [G loss: 0.812838]\n",
      "epoch:4 step:3842 [D loss: 0.443908, acc.: 79.69%] [G loss: 0.716897]\n",
      "epoch:4 step:3843 [D loss: 0.548398, acc.: 66.41%] [G loss: 0.710903]\n",
      "epoch:4 step:3844 [D loss: 0.453957, acc.: 76.56%] [G loss: 0.702850]\n",
      "epoch:4 step:3845 [D loss: 0.489583, acc.: 78.91%] [G loss: 0.804545]\n",
      "epoch:4 step:3846 [D loss: 0.504915, acc.: 73.44%] [G loss: 0.669885]\n",
      "epoch:4 step:3847 [D loss: 0.473990, acc.: 78.91%] [G loss: 0.821583]\n",
      "epoch:4 step:3848 [D loss: 0.436484, acc.: 79.69%] [G loss: 0.653083]\n",
      "epoch:4 step:3849 [D loss: 0.471395, acc.: 79.69%] [G loss: 0.706195]\n",
      "epoch:4 step:3850 [D loss: 0.505177, acc.: 71.88%] [G loss: 0.898890]\n",
      "epoch:4 step:3851 [D loss: 0.406100, acc.: 84.38%] [G loss: 0.625934]\n",
      "epoch:4 step:3852 [D loss: 0.535934, acc.: 70.31%] [G loss: 0.636199]\n",
      "epoch:4 step:3853 [D loss: 0.523440, acc.: 69.53%] [G loss: 0.662563]\n",
      "epoch:4 step:3854 [D loss: 0.563529, acc.: 71.88%] [G loss: 0.532845]\n",
      "epoch:4 step:3855 [D loss: 0.569889, acc.: 73.44%] [G loss: 0.569355]\n",
      "epoch:4 step:3856 [D loss: 0.562589, acc.: 70.31%] [G loss: 0.645644]\n",
      "epoch:4 step:3857 [D loss: 0.560281, acc.: 66.41%] [G loss: 0.616513]\n",
      "epoch:4 step:3858 [D loss: 0.587325, acc.: 63.28%] [G loss: 0.596182]\n",
      "epoch:4 step:3859 [D loss: 0.507367, acc.: 75.78%] [G loss: 0.624608]\n",
      "epoch:4 step:3860 [D loss: 0.473968, acc.: 78.91%] [G loss: 0.653314]\n",
      "epoch:4 step:3861 [D loss: 0.622459, acc.: 67.19%] [G loss: 0.640875]\n",
      "epoch:4 step:3862 [D loss: 0.564658, acc.: 73.44%] [G loss: 0.515450]\n",
      "epoch:4 step:3863 [D loss: 0.525026, acc.: 71.88%] [G loss: 0.713268]\n",
      "epoch:4 step:3864 [D loss: 0.507742, acc.: 72.66%] [G loss: 0.692188]\n",
      "epoch:4 step:3865 [D loss: 0.460990, acc.: 81.25%] [G loss: 0.624953]\n",
      "epoch:4 step:3866 [D loss: 0.494889, acc.: 78.12%] [G loss: 0.698914]\n",
      "epoch:4 step:3867 [D loss: 0.429442, acc.: 82.81%] [G loss: 0.837205]\n",
      "epoch:4 step:3868 [D loss: 0.571253, acc.: 71.88%] [G loss: 0.714778]\n",
      "epoch:4 step:3869 [D loss: 0.569077, acc.: 73.44%] [G loss: 0.630247]\n",
      "epoch:4 step:3870 [D loss: 0.509183, acc.: 78.91%] [G loss: 0.664527]\n",
      "epoch:4 step:3871 [D loss: 0.536613, acc.: 72.66%] [G loss: 0.626844]\n",
      "epoch:4 step:3872 [D loss: 0.489396, acc.: 79.69%] [G loss: 0.613544]\n",
      "epoch:4 step:3873 [D loss: 0.504229, acc.: 76.56%] [G loss: 0.654827]\n",
      "epoch:4 step:3874 [D loss: 0.478485, acc.: 80.47%] [G loss: 0.598491]\n",
      "epoch:4 step:3875 [D loss: 0.471359, acc.: 79.69%] [G loss: 0.699489]\n",
      "epoch:4 step:3876 [D loss: 0.461266, acc.: 78.91%] [G loss: 0.573295]\n",
      "epoch:4 step:3877 [D loss: 0.549014, acc.: 69.53%] [G loss: 0.543992]\n",
      "epoch:4 step:3878 [D loss: 0.510836, acc.: 78.91%] [G loss: 0.512899]\n",
      "epoch:4 step:3879 [D loss: 0.474258, acc.: 78.12%] [G loss: 0.456740]\n",
      "epoch:4 step:3880 [D loss: 0.551767, acc.: 71.88%] [G loss: 0.626630]\n",
      "epoch:4 step:3881 [D loss: 0.535215, acc.: 67.19%] [G loss: 0.636110]\n",
      "epoch:4 step:3882 [D loss: 0.571515, acc.: 67.97%] [G loss: 0.629964]\n",
      "epoch:4 step:3883 [D loss: 0.488426, acc.: 79.69%] [G loss: 0.701845]\n",
      "epoch:4 step:3884 [D loss: 0.612567, acc.: 66.41%] [G loss: 0.599218]\n",
      "epoch:4 step:3885 [D loss: 0.608430, acc.: 66.41%] [G loss: 0.534760]\n",
      "epoch:4 step:3886 [D loss: 0.488368, acc.: 79.69%] [G loss: 0.658904]\n",
      "epoch:4 step:3887 [D loss: 0.528804, acc.: 75.00%] [G loss: 0.631732]\n",
      "epoch:4 step:3888 [D loss: 0.538477, acc.: 70.31%] [G loss: 0.523648]\n",
      "epoch:4 step:3889 [D loss: 0.488639, acc.: 76.56%] [G loss: 0.673768]\n",
      "epoch:4 step:3890 [D loss: 0.514234, acc.: 71.88%] [G loss: 0.647050]\n",
      "epoch:4 step:3891 [D loss: 0.539732, acc.: 76.56%] [G loss: 0.544289]\n",
      "epoch:4 step:3892 [D loss: 0.462539, acc.: 78.91%] [G loss: 0.570017]\n",
      "epoch:4 step:3893 [D loss: 0.505386, acc.: 73.44%] [G loss: 0.532495]\n",
      "epoch:4 step:3894 [D loss: 0.481304, acc.: 77.34%] [G loss: 0.583134]\n",
      "epoch:4 step:3895 [D loss: 0.524384, acc.: 72.66%] [G loss: 0.662275]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:4 step:3896 [D loss: 0.501137, acc.: 76.56%] [G loss: 0.550627]\n",
      "epoch:4 step:3897 [D loss: 0.426497, acc.: 84.38%] [G loss: 0.631942]\n",
      "epoch:4 step:3898 [D loss: 0.584670, acc.: 69.53%] [G loss: 0.525027]\n",
      "epoch:4 step:3899 [D loss: 0.509009, acc.: 73.44%] [G loss: 0.654711]\n",
      "epoch:4 step:3900 [D loss: 0.430127, acc.: 84.38%] [G loss: 0.843227]\n",
      "epoch:4 step:3901 [D loss: 0.585777, acc.: 68.75%] [G loss: 0.642979]\n",
      "epoch:4 step:3902 [D loss: 0.423303, acc.: 83.59%] [G loss: 0.710225]\n",
      "epoch:4 step:3903 [D loss: 0.422089, acc.: 82.03%] [G loss: 0.753985]\n",
      "epoch:4 step:3904 [D loss: 0.497827, acc.: 78.91%] [G loss: 0.666700]\n",
      "epoch:4 step:3905 [D loss: 0.532066, acc.: 72.66%] [G loss: 0.516945]\n",
      "epoch:4 step:3906 [D loss: 0.513921, acc.: 75.00%] [G loss: 0.594155]\n",
      "epoch:4 step:3907 [D loss: 0.516800, acc.: 73.44%] [G loss: 0.542474]\n",
      "epoch:4 step:3908 [D loss: 0.558880, acc.: 70.31%] [G loss: 0.658381]\n",
      "epoch:4 step:3909 [D loss: 0.474675, acc.: 79.69%] [G loss: 0.570100]\n",
      "epoch:4 step:3910 [D loss: 0.457165, acc.: 84.38%] [G loss: 0.686737]\n",
      "epoch:4 step:3911 [D loss: 0.463398, acc.: 78.91%] [G loss: 0.855153]\n",
      "epoch:4 step:3912 [D loss: 0.543311, acc.: 72.66%] [G loss: 0.751328]\n",
      "epoch:4 step:3913 [D loss: 0.484420, acc.: 78.12%] [G loss: 0.787808]\n",
      "epoch:4 step:3914 [D loss: 0.492070, acc.: 78.12%] [G loss: 0.697341]\n",
      "epoch:4 step:3915 [D loss: 0.522050, acc.: 71.88%] [G loss: 0.607615]\n",
      "epoch:4 step:3916 [D loss: 0.530010, acc.: 71.88%] [G loss: 0.446601]\n",
      "epoch:4 step:3917 [D loss: 0.560267, acc.: 70.31%] [G loss: 0.583809]\n",
      "epoch:4 step:3918 [D loss: 0.487629, acc.: 78.91%] [G loss: 0.647253]\n",
      "epoch:4 step:3919 [D loss: 0.464055, acc.: 77.34%] [G loss: 0.669372]\n",
      "epoch:4 step:3920 [D loss: 0.516944, acc.: 76.56%] [G loss: 0.589477]\n",
      "epoch:4 step:3921 [D loss: 0.475709, acc.: 78.91%] [G loss: 0.604841]\n",
      "epoch:4 step:3922 [D loss: 0.533869, acc.: 71.88%] [G loss: 0.480173]\n",
      "epoch:4 step:3923 [D loss: 0.485541, acc.: 75.00%] [G loss: 0.561878]\n",
      "epoch:4 step:3924 [D loss: 0.502754, acc.: 73.44%] [G loss: 0.647147]\n",
      "epoch:4 step:3925 [D loss: 0.485464, acc.: 78.91%] [G loss: 0.620356]\n",
      "epoch:4 step:3926 [D loss: 0.518413, acc.: 76.56%] [G loss: 0.672991]\n",
      "epoch:4 step:3927 [D loss: 0.528722, acc.: 70.31%] [G loss: 0.600551]\n",
      "epoch:4 step:3928 [D loss: 0.492408, acc.: 75.78%] [G loss: 0.665663]\n",
      "epoch:4 step:3929 [D loss: 0.452368, acc.: 78.12%] [G loss: 0.717581]\n",
      "epoch:4 step:3930 [D loss: 0.517712, acc.: 74.22%] [G loss: 0.657449]\n",
      "epoch:4 step:3931 [D loss: 0.511153, acc.: 75.78%] [G loss: 0.540043]\n",
      "epoch:4 step:3932 [D loss: 0.576202, acc.: 74.22%] [G loss: 0.475050]\n",
      "epoch:4 step:3933 [D loss: 0.502838, acc.: 78.91%] [G loss: 0.618876]\n",
      "epoch:4 step:3934 [D loss: 0.498882, acc.: 76.56%] [G loss: 0.615202]\n",
      "epoch:4 step:3935 [D loss: 0.550070, acc.: 71.88%] [G loss: 0.624132]\n",
      "epoch:4 step:3936 [D loss: 0.541118, acc.: 75.78%] [G loss: 0.651710]\n",
      "epoch:4 step:3937 [D loss: 0.492731, acc.: 74.22%] [G loss: 0.411076]\n",
      "epoch:4 step:3938 [D loss: 0.473425, acc.: 77.34%] [G loss: 0.515758]\n",
      "epoch:4 step:3939 [D loss: 0.456355, acc.: 86.72%] [G loss: 0.754894]\n",
      "epoch:4 step:3940 [D loss: 0.523384, acc.: 72.66%] [G loss: 0.577460]\n",
      "epoch:4 step:3941 [D loss: 0.512153, acc.: 71.88%] [G loss: 0.712948]\n",
      "epoch:4 step:3942 [D loss: 0.482212, acc.: 75.78%] [G loss: 0.758153]\n",
      "epoch:4 step:3943 [D loss: 0.514341, acc.: 72.66%] [G loss: 0.656375]\n",
      "epoch:4 step:3944 [D loss: 0.563766, acc.: 69.53%] [G loss: 0.554719]\n",
      "epoch:4 step:3945 [D loss: 0.496969, acc.: 78.12%] [G loss: 0.633205]\n",
      "epoch:4 step:3946 [D loss: 0.470084, acc.: 75.78%] [G loss: 0.826652]\n",
      "epoch:4 step:3947 [D loss: 0.473829, acc.: 77.34%] [G loss: 0.691300]\n",
      "epoch:4 step:3948 [D loss: 0.559411, acc.: 69.53%] [G loss: 0.640695]\n",
      "epoch:4 step:3949 [D loss: 0.464858, acc.: 82.03%] [G loss: 0.730485]\n",
      "epoch:4 step:3950 [D loss: 0.508977, acc.: 76.56%] [G loss: 0.627108]\n",
      "epoch:4 step:3951 [D loss: 0.624285, acc.: 62.50%] [G loss: 0.470710]\n",
      "epoch:4 step:3952 [D loss: 0.513799, acc.: 75.78%] [G loss: 0.559519]\n",
      "epoch:4 step:3953 [D loss: 0.477944, acc.: 77.34%] [G loss: 0.566804]\n",
      "epoch:4 step:3954 [D loss: 0.555107, acc.: 64.06%] [G loss: 0.665561]\n",
      "epoch:4 step:3955 [D loss: 0.344678, acc.: 88.28%] [G loss: 0.863556]\n",
      "epoch:4 step:3956 [D loss: 0.453175, acc.: 78.12%] [G loss: 0.755224]\n",
      "epoch:4 step:3957 [D loss: 0.480989, acc.: 78.91%] [G loss: 0.658721]\n",
      "epoch:4 step:3958 [D loss: 0.602978, acc.: 67.19%] [G loss: 0.565560]\n",
      "epoch:4 step:3959 [D loss: 0.517293, acc.: 72.66%] [G loss: 0.477490]\n",
      "epoch:4 step:3960 [D loss: 0.499501, acc.: 75.00%] [G loss: 0.536126]\n",
      "epoch:4 step:3961 [D loss: 0.472965, acc.: 78.12%] [G loss: 0.638440]\n",
      "epoch:4 step:3962 [D loss: 0.608239, acc.: 64.84%] [G loss: 0.462869]\n",
      "epoch:4 step:3963 [D loss: 0.575887, acc.: 67.97%] [G loss: 0.486216]\n",
      "epoch:4 step:3964 [D loss: 0.557613, acc.: 66.41%] [G loss: 0.461549]\n",
      "epoch:4 step:3965 [D loss: 0.437885, acc.: 83.59%] [G loss: 0.583660]\n",
      "epoch:4 step:3966 [D loss: 0.517595, acc.: 78.91%] [G loss: 0.547696]\n",
      "epoch:4 step:3967 [D loss: 0.504696, acc.: 78.12%] [G loss: 0.652207]\n",
      "epoch:4 step:3968 [D loss: 0.647800, acc.: 64.84%] [G loss: 0.476590]\n",
      "epoch:4 step:3969 [D loss: 0.456762, acc.: 78.12%] [G loss: 0.738937]\n",
      "epoch:4 step:3970 [D loss: 0.479097, acc.: 75.00%] [G loss: 0.691295]\n",
      "epoch:4 step:3971 [D loss: 0.450759, acc.: 83.59%] [G loss: 0.688955]\n",
      "epoch:4 step:3972 [D loss: 0.555509, acc.: 72.66%] [G loss: 0.665350]\n",
      "epoch:4 step:3973 [D loss: 0.588507, acc.: 70.31%] [G loss: 0.515869]\n",
      "epoch:4 step:3974 [D loss: 0.540032, acc.: 74.22%] [G loss: 0.495628]\n",
      "epoch:4 step:3975 [D loss: 0.524446, acc.: 75.00%] [G loss: 0.486402]\n",
      "epoch:4 step:3976 [D loss: 0.548275, acc.: 75.00%] [G loss: 0.497857]\n",
      "epoch:4 step:3977 [D loss: 0.506995, acc.: 74.22%] [G loss: 0.592144]\n",
      "epoch:4 step:3978 [D loss: 0.455271, acc.: 80.47%] [G loss: 0.700700]\n",
      "epoch:4 step:3979 [D loss: 0.426501, acc.: 82.81%] [G loss: 0.801952]\n",
      "epoch:4 step:3980 [D loss: 0.458879, acc.: 82.03%] [G loss: 0.626824]\n",
      "epoch:4 step:3981 [D loss: 0.572305, acc.: 71.88%] [G loss: 0.675359]\n",
      "epoch:4 step:3982 [D loss: 0.541203, acc.: 71.88%] [G loss: 0.559333]\n",
      "epoch:4 step:3983 [D loss: 0.573112, acc.: 65.62%] [G loss: 0.610079]\n",
      "epoch:4 step:3984 [D loss: 0.516887, acc.: 73.44%] [G loss: 0.548014]\n",
      "epoch:4 step:3985 [D loss: 0.521091, acc.: 73.44%] [G loss: 0.531070]\n",
      "epoch:4 step:3986 [D loss: 0.543175, acc.: 71.09%] [G loss: 0.495328]\n",
      "epoch:4 step:3987 [D loss: 0.523021, acc.: 72.66%] [G loss: 0.519660]\n",
      "epoch:4 step:3988 [D loss: 0.499545, acc.: 76.56%] [G loss: 0.635411]\n",
      "epoch:4 step:3989 [D loss: 0.514321, acc.: 77.34%] [G loss: 0.518956]\n",
      "epoch:4 step:3990 [D loss: 0.529137, acc.: 74.22%] [G loss: 0.591396]\n",
      "epoch:4 step:3991 [D loss: 0.527489, acc.: 71.88%] [G loss: 0.579575]\n",
      "epoch:4 step:3992 [D loss: 0.483885, acc.: 76.56%] [G loss: 0.522377]\n",
      "epoch:4 step:3993 [D loss: 0.446965, acc.: 85.94%] [G loss: 0.613094]\n",
      "epoch:4 step:3994 [D loss: 0.497717, acc.: 78.91%] [G loss: 0.644535]\n",
      "epoch:4 step:3995 [D loss: 0.520476, acc.: 75.00%] [G loss: 0.652382]\n",
      "epoch:4 step:3996 [D loss: 0.574944, acc.: 71.88%] [G loss: 0.727421]\n",
      "epoch:4 step:3997 [D loss: 0.487365, acc.: 75.78%] [G loss: 0.690443]\n",
      "epoch:4 step:3998 [D loss: 0.547782, acc.: 69.53%] [G loss: 0.631048]\n",
      "epoch:4 step:3999 [D loss: 0.585122, acc.: 66.41%] [G loss: 0.653741]\n",
      "epoch:4 step:4000 [D loss: 0.508022, acc.: 73.44%] [G loss: 0.582851]\n",
      "epoch:4 step:4001 [D loss: 0.470268, acc.: 78.91%] [G loss: 0.501859]\n",
      "epoch:4 step:4002 [D loss: 0.529143, acc.: 75.00%] [G loss: 0.544123]\n",
      "epoch:4 step:4003 [D loss: 0.458114, acc.: 78.91%] [G loss: 0.752014]\n",
      "epoch:4 step:4004 [D loss: 0.461594, acc.: 79.69%] [G loss: 0.629577]\n",
      "epoch:4 step:4005 [D loss: 0.556222, acc.: 70.31%] [G loss: 0.663110]\n",
      "epoch:4 step:4006 [D loss: 0.470661, acc.: 82.81%] [G loss: 0.603381]\n",
      "epoch:4 step:4007 [D loss: 0.458117, acc.: 79.69%] [G loss: 0.763775]\n",
      "epoch:4 step:4008 [D loss: 0.508794, acc.: 77.34%] [G loss: 0.536278]\n",
      "epoch:4 step:4009 [D loss: 0.478953, acc.: 78.12%] [G loss: 0.593210]\n",
      "epoch:4 step:4010 [D loss: 0.506496, acc.: 78.91%] [G loss: 0.592439]\n",
      "epoch:4 step:4011 [D loss: 0.666340, acc.: 57.81%] [G loss: 0.368970]\n",
      "epoch:4 step:4012 [D loss: 0.491756, acc.: 78.91%] [G loss: 0.621881]\n",
      "epoch:4 step:4013 [D loss: 0.516890, acc.: 73.44%] [G loss: 0.609486]\n",
      "epoch:4 step:4014 [D loss: 0.510666, acc.: 76.56%] [G loss: 0.544400]\n",
      "epoch:4 step:4015 [D loss: 0.537268, acc.: 73.44%] [G loss: 0.532316]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:4 step:4016 [D loss: 0.547733, acc.: 73.44%] [G loss: 0.458492]\n",
      "epoch:4 step:4017 [D loss: 0.487383, acc.: 77.34%] [G loss: 0.677931]\n",
      "epoch:4 step:4018 [D loss: 0.493925, acc.: 74.22%] [G loss: 0.509572]\n",
      "epoch:4 step:4019 [D loss: 0.459940, acc.: 81.25%] [G loss: 0.579212]\n",
      "epoch:4 step:4020 [D loss: 0.567251, acc.: 67.97%] [G loss: 0.516764]\n",
      "epoch:4 step:4021 [D loss: 0.479876, acc.: 78.91%] [G loss: 0.631128]\n",
      "epoch:4 step:4022 [D loss: 0.537320, acc.: 75.00%] [G loss: 0.510253]\n",
      "epoch:4 step:4023 [D loss: 0.600071, acc.: 67.19%] [G loss: 0.542643]\n",
      "epoch:4 step:4024 [D loss: 0.465097, acc.: 83.59%] [G loss: 0.647769]\n",
      "epoch:4 step:4025 [D loss: 0.636920, acc.: 64.06%] [G loss: 0.494087]\n",
      "epoch:4 step:4026 [D loss: 0.593919, acc.: 69.53%] [G loss: 0.417969]\n",
      "epoch:4 step:4027 [D loss: 0.484384, acc.: 77.34%] [G loss: 0.598516]\n",
      "epoch:4 step:4028 [D loss: 0.493832, acc.: 73.44%] [G loss: 0.675328]\n",
      "epoch:4 step:4029 [D loss: 0.536813, acc.: 75.78%] [G loss: 0.496797]\n",
      "epoch:4 step:4030 [D loss: 0.529956, acc.: 75.00%] [G loss: 0.503059]\n",
      "epoch:4 step:4031 [D loss: 0.477145, acc.: 74.22%] [G loss: 0.490254]\n",
      "epoch:4 step:4032 [D loss: 0.468139, acc.: 77.34%] [G loss: 0.574828]\n",
      "epoch:4 step:4033 [D loss: 0.488349, acc.: 74.22%] [G loss: 0.782036]\n",
      "epoch:4 step:4034 [D loss: 0.419480, acc.: 85.16%] [G loss: 0.683903]\n",
      "epoch:4 step:4035 [D loss: 0.544248, acc.: 75.00%] [G loss: 0.567716]\n",
      "epoch:4 step:4036 [D loss: 0.545596, acc.: 67.97%] [G loss: 0.469192]\n",
      "epoch:4 step:4037 [D loss: 0.532278, acc.: 73.44%] [G loss: 0.527583]\n",
      "epoch:4 step:4038 [D loss: 0.479140, acc.: 79.69%] [G loss: 0.659928]\n",
      "epoch:4 step:4039 [D loss: 0.534646, acc.: 74.22%] [G loss: 0.475180]\n",
      "epoch:4 step:4040 [D loss: 0.569630, acc.: 69.53%] [G loss: 0.432208]\n",
      "epoch:4 step:4041 [D loss: 0.482233, acc.: 77.34%] [G loss: 0.631606]\n",
      "epoch:4 step:4042 [D loss: 0.525208, acc.: 72.66%] [G loss: 0.571676]\n",
      "epoch:4 step:4043 [D loss: 0.491842, acc.: 70.31%] [G loss: 0.615263]\n",
      "epoch:4 step:4044 [D loss: 0.471936, acc.: 79.69%] [G loss: 0.489369]\n",
      "epoch:4 step:4045 [D loss: 0.506114, acc.: 75.00%] [G loss: 0.657497]\n",
      "epoch:4 step:4046 [D loss: 0.531596, acc.: 69.53%] [G loss: 0.645159]\n",
      "epoch:4 step:4047 [D loss: 0.513829, acc.: 74.22%] [G loss: 0.669890]\n",
      "epoch:4 step:4048 [D loss: 0.465326, acc.: 80.47%] [G loss: 0.614295]\n",
      "epoch:4 step:4049 [D loss: 0.609968, acc.: 64.06%] [G loss: 0.489070]\n",
      "epoch:4 step:4050 [D loss: 0.476281, acc.: 81.25%] [G loss: 0.584962]\n",
      "epoch:4 step:4051 [D loss: 0.493877, acc.: 73.44%] [G loss: 0.650601]\n",
      "epoch:4 step:4052 [D loss: 0.447026, acc.: 78.12%] [G loss: 0.607488]\n",
      "epoch:4 step:4053 [D loss: 0.431044, acc.: 78.12%] [G loss: 0.731639]\n",
      "epoch:4 step:4054 [D loss: 0.538355, acc.: 70.31%] [G loss: 0.708343]\n",
      "epoch:4 step:4055 [D loss: 0.439474, acc.: 79.69%] [G loss: 0.665386]\n",
      "epoch:4 step:4056 [D loss: 0.527799, acc.: 73.44%] [G loss: 0.545783]\n",
      "epoch:4 step:4057 [D loss: 0.435525, acc.: 79.69%] [G loss: 0.739305]\n",
      "epoch:4 step:4058 [D loss: 0.475765, acc.: 77.34%] [G loss: 0.805151]\n",
      "epoch:4 step:4059 [D loss: 0.428000, acc.: 80.47%] [G loss: 0.797230]\n",
      "epoch:4 step:4060 [D loss: 0.368994, acc.: 87.50%] [G loss: 0.917849]\n",
      "epoch:4 step:4061 [D loss: 0.424058, acc.: 83.59%] [G loss: 0.948373]\n",
      "epoch:4 step:4062 [D loss: 0.410384, acc.: 84.38%] [G loss: 0.970285]\n",
      "epoch:4 step:4063 [D loss: 0.429046, acc.: 82.81%] [G loss: 1.009642]\n",
      "epoch:4 step:4064 [D loss: 0.707405, acc.: 64.06%] [G loss: 0.501830]\n",
      "epoch:4 step:4065 [D loss: 0.575005, acc.: 65.62%] [G loss: 0.633060]\n",
      "epoch:4 step:4066 [D loss: 0.497069, acc.: 79.69%] [G loss: 0.612603]\n",
      "epoch:4 step:4067 [D loss: 0.505237, acc.: 79.69%] [G loss: 0.685582]\n",
      "epoch:4 step:4068 [D loss: 0.451772, acc.: 78.91%] [G loss: 0.854097]\n",
      "epoch:4 step:4069 [D loss: 0.388114, acc.: 82.81%] [G loss: 0.936886]\n",
      "epoch:4 step:4070 [D loss: 0.553397, acc.: 70.31%] [G loss: 0.653105]\n",
      "epoch:4 step:4071 [D loss: 0.534245, acc.: 75.78%] [G loss: 0.751674]\n",
      "epoch:4 step:4072 [D loss: 0.534979, acc.: 75.78%] [G loss: 0.569963]\n",
      "epoch:4 step:4073 [D loss: 0.506617, acc.: 77.34%] [G loss: 0.488103]\n",
      "epoch:4 step:4074 [D loss: 0.494097, acc.: 76.56%] [G loss: 0.603668]\n",
      "epoch:4 step:4075 [D loss: 0.519177, acc.: 75.78%] [G loss: 0.648949]\n",
      "epoch:4 step:4076 [D loss: 0.529441, acc.: 74.22%] [G loss: 0.584071]\n",
      "epoch:4 step:4077 [D loss: 0.517597, acc.: 70.31%] [G loss: 0.702753]\n",
      "epoch:4 step:4078 [D loss: 0.487752, acc.: 75.00%] [G loss: 0.743558]\n",
      "epoch:4 step:4079 [D loss: 0.494087, acc.: 80.47%] [G loss: 0.645182]\n",
      "epoch:4 step:4080 [D loss: 0.495191, acc.: 76.56%] [G loss: 0.512361]\n",
      "epoch:4 step:4081 [D loss: 0.410419, acc.: 86.72%] [G loss: 0.740185]\n",
      "epoch:4 step:4082 [D loss: 0.514411, acc.: 74.22%] [G loss: 0.633342]\n",
      "epoch:4 step:4083 [D loss: 0.503784, acc.: 73.44%] [G loss: 0.777401]\n",
      "epoch:4 step:4084 [D loss: 0.487598, acc.: 75.78%] [G loss: 0.778861]\n",
      "epoch:4 step:4085 [D loss: 0.464381, acc.: 78.12%] [G loss: 0.682866]\n",
      "epoch:4 step:4086 [D loss: 0.563821, acc.: 69.53%] [G loss: 0.646521]\n",
      "epoch:4 step:4087 [D loss: 0.476231, acc.: 83.59%] [G loss: 0.627746]\n",
      "epoch:4 step:4088 [D loss: 0.492215, acc.: 76.56%] [G loss: 0.606468]\n",
      "epoch:4 step:4089 [D loss: 0.574842, acc.: 71.88%] [G loss: 0.504213]\n",
      "epoch:4 step:4090 [D loss: 0.567048, acc.: 71.88%] [G loss: 0.545556]\n",
      "epoch:4 step:4091 [D loss: 0.442845, acc.: 82.03%] [G loss: 0.702155]\n",
      "epoch:4 step:4092 [D loss: 0.441472, acc.: 81.25%] [G loss: 0.986053]\n",
      "epoch:4 step:4093 [D loss: 0.515097, acc.: 71.88%] [G loss: 0.844170]\n",
      "epoch:4 step:4094 [D loss: 0.539526, acc.: 67.19%] [G loss: 0.978804]\n",
      "epoch:4 step:4095 [D loss: 0.449260, acc.: 77.34%] [G loss: 0.977704]\n",
      "epoch:4 step:4096 [D loss: 0.637345, acc.: 67.19%] [G loss: 0.581757]\n",
      "epoch:4 step:4097 [D loss: 0.688180, acc.: 57.81%] [G loss: 0.493127]\n",
      "epoch:4 step:4098 [D loss: 0.459150, acc.: 80.47%] [G loss: 0.686412]\n",
      "epoch:4 step:4099 [D loss: 0.420008, acc.: 82.03%] [G loss: 0.761119]\n",
      "epoch:4 step:4100 [D loss: 0.638794, acc.: 64.06%] [G loss: 0.585327]\n",
      "epoch:4 step:4101 [D loss: 0.509183, acc.: 74.22%] [G loss: 0.656697]\n",
      "epoch:4 step:4102 [D loss: 0.444902, acc.: 80.47%] [G loss: 0.665793]\n",
      "epoch:4 step:4103 [D loss: 0.498255, acc.: 73.44%] [G loss: 0.903482]\n",
      "epoch:4 step:4104 [D loss: 0.567648, acc.: 71.88%] [G loss: 0.556098]\n",
      "epoch:4 step:4105 [D loss: 0.464000, acc.: 75.78%] [G loss: 0.779649]\n",
      "epoch:4 step:4106 [D loss: 0.421964, acc.: 81.25%] [G loss: 0.789649]\n",
      "epoch:4 step:4107 [D loss: 0.429302, acc.: 79.69%] [G loss: 0.836437]\n",
      "epoch:4 step:4108 [D loss: 0.486214, acc.: 77.34%] [G loss: 0.692156]\n",
      "epoch:4 step:4109 [D loss: 0.471842, acc.: 82.03%] [G loss: 0.704271]\n",
      "epoch:4 step:4110 [D loss: 0.541486, acc.: 74.22%] [G loss: 0.587527]\n",
      "epoch:4 step:4111 [D loss: 0.447887, acc.: 77.34%] [G loss: 0.830846]\n",
      "epoch:4 step:4112 [D loss: 0.459206, acc.: 77.34%] [G loss: 0.656887]\n",
      "epoch:4 step:4113 [D loss: 0.462708, acc.: 75.78%] [G loss: 0.690989]\n",
      "epoch:4 step:4114 [D loss: 0.443595, acc.: 79.69%] [G loss: 0.760420]\n",
      "epoch:4 step:4115 [D loss: 0.490064, acc.: 78.91%] [G loss: 0.731860]\n",
      "epoch:4 step:4116 [D loss: 0.486768, acc.: 70.31%] [G loss: 0.712494]\n",
      "epoch:4 step:4117 [D loss: 0.521153, acc.: 72.66%] [G loss: 0.642961]\n",
      "epoch:4 step:4118 [D loss: 0.498358, acc.: 78.91%] [G loss: 0.684628]\n",
      "epoch:4 step:4119 [D loss: 0.504282, acc.: 73.44%] [G loss: 0.666948]\n",
      "epoch:4 step:4120 [D loss: 0.481705, acc.: 71.88%] [G loss: 0.723335]\n",
      "epoch:4 step:4121 [D loss: 0.587448, acc.: 69.53%] [G loss: 0.673740]\n",
      "epoch:4 step:4122 [D loss: 0.446399, acc.: 79.69%] [G loss: 0.676595]\n",
      "epoch:4 step:4123 [D loss: 0.533709, acc.: 69.53%] [G loss: 0.577314]\n",
      "epoch:4 step:4124 [D loss: 0.602911, acc.: 69.53%] [G loss: 0.490429]\n",
      "epoch:4 step:4125 [D loss: 0.525579, acc.: 73.44%] [G loss: 0.557302]\n",
      "epoch:4 step:4126 [D loss: 0.464742, acc.: 79.69%] [G loss: 0.837375]\n",
      "epoch:4 step:4127 [D loss: 0.525465, acc.: 76.56%] [G loss: 0.647669]\n",
      "epoch:4 step:4128 [D loss: 0.498520, acc.: 78.12%] [G loss: 0.665528]\n",
      "epoch:4 step:4129 [D loss: 0.434465, acc.: 84.38%] [G loss: 0.648407]\n",
      "epoch:4 step:4130 [D loss: 0.503750, acc.: 79.69%] [G loss: 0.734901]\n",
      "epoch:4 step:4131 [D loss: 0.529786, acc.: 67.97%] [G loss: 0.673491]\n",
      "epoch:4 step:4132 [D loss: 0.516746, acc.: 71.88%] [G loss: 0.584914]\n",
      "epoch:4 step:4133 [D loss: 0.500262, acc.: 72.66%] [G loss: 0.722808]\n",
      "epoch:4 step:4134 [D loss: 0.594066, acc.: 65.62%] [G loss: 0.570567]\n",
      "epoch:4 step:4135 [D loss: 0.502007, acc.: 75.00%] [G loss: 0.512464]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:4 step:4136 [D loss: 0.490722, acc.: 76.56%] [G loss: 0.760366]\n",
      "epoch:4 step:4137 [D loss: 0.508821, acc.: 75.78%] [G loss: 0.605818]\n",
      "epoch:4 step:4138 [D loss: 0.536674, acc.: 71.88%] [G loss: 0.766724]\n",
      "epoch:4 step:4139 [D loss: 0.547362, acc.: 73.44%] [G loss: 0.680213]\n",
      "epoch:4 step:4140 [D loss: 0.435544, acc.: 80.47%] [G loss: 0.653771]\n",
      "epoch:4 step:4141 [D loss: 0.522497, acc.: 68.75%] [G loss: 0.704692]\n",
      "epoch:4 step:4142 [D loss: 0.499797, acc.: 72.66%] [G loss: 0.525168]\n",
      "epoch:4 step:4143 [D loss: 0.547689, acc.: 70.31%] [G loss: 0.530600]\n",
      "epoch:4 step:4144 [D loss: 0.573321, acc.: 71.09%] [G loss: 0.568745]\n",
      "epoch:4 step:4145 [D loss: 0.467386, acc.: 79.69%] [G loss: 0.764006]\n",
      "epoch:4 step:4146 [D loss: 0.426436, acc.: 83.59%] [G loss: 0.713088]\n",
      "epoch:4 step:4147 [D loss: 0.477674, acc.: 80.47%] [G loss: 0.672387]\n",
      "epoch:4 step:4148 [D loss: 0.613923, acc.: 62.50%] [G loss: 0.558360]\n",
      "epoch:4 step:4149 [D loss: 0.521442, acc.: 71.88%] [G loss: 0.668833]\n",
      "epoch:4 step:4150 [D loss: 0.459981, acc.: 77.34%] [G loss: 0.724537]\n",
      "epoch:4 step:4151 [D loss: 0.483688, acc.: 76.56%] [G loss: 0.669934]\n",
      "epoch:4 step:4152 [D loss: 0.573201, acc.: 67.19%] [G loss: 0.598358]\n",
      "epoch:4 step:4153 [D loss: 0.503394, acc.: 77.34%] [G loss: 0.580204]\n",
      "epoch:4 step:4154 [D loss: 0.500987, acc.: 80.47%] [G loss: 0.677397]\n",
      "epoch:4 step:4155 [D loss: 0.554271, acc.: 68.75%] [G loss: 0.606510]\n",
      "epoch:4 step:4156 [D loss: 0.501172, acc.: 75.00%] [G loss: 0.692731]\n",
      "epoch:4 step:4157 [D loss: 0.536202, acc.: 75.00%] [G loss: 0.647263]\n",
      "epoch:4 step:4158 [D loss: 0.563378, acc.: 67.19%] [G loss: 0.565506]\n",
      "epoch:4 step:4159 [D loss: 0.567809, acc.: 70.31%] [G loss: 0.655004]\n",
      "epoch:4 step:4160 [D loss: 0.569046, acc.: 65.62%] [G loss: 0.570232]\n",
      "epoch:4 step:4161 [D loss: 0.499784, acc.: 78.91%] [G loss: 0.665177]\n",
      "epoch:4 step:4162 [D loss: 0.519827, acc.: 73.44%] [G loss: 0.594142]\n",
      "epoch:4 step:4163 [D loss: 0.499858, acc.: 74.22%] [G loss: 0.687767]\n",
      "epoch:4 step:4164 [D loss: 0.520894, acc.: 73.44%] [G loss: 0.667697]\n",
      "epoch:4 step:4165 [D loss: 0.625490, acc.: 69.53%] [G loss: 0.553397]\n",
      "epoch:4 step:4166 [D loss: 0.552822, acc.: 72.66%] [G loss: 0.527474]\n",
      "epoch:4 step:4167 [D loss: 0.603901, acc.: 66.41%] [G loss: 0.546163]\n",
      "epoch:4 step:4168 [D loss: 0.557325, acc.: 71.09%] [G loss: 0.605994]\n",
      "epoch:4 step:4169 [D loss: 0.524570, acc.: 73.44%] [G loss: 0.523226]\n",
      "epoch:4 step:4170 [D loss: 0.517121, acc.: 75.00%] [G loss: 0.599849]\n",
      "epoch:4 step:4171 [D loss: 0.526922, acc.: 71.09%] [G loss: 0.541133]\n",
      "epoch:4 step:4172 [D loss: 0.566103, acc.: 67.19%] [G loss: 0.625426]\n",
      "epoch:4 step:4173 [D loss: 0.478801, acc.: 78.12%] [G loss: 0.611292]\n",
      "epoch:4 step:4174 [D loss: 0.444246, acc.: 80.47%] [G loss: 0.710712]\n",
      "epoch:4 step:4175 [D loss: 0.434175, acc.: 82.81%] [G loss: 0.916605]\n",
      "epoch:4 step:4176 [D loss: 0.560304, acc.: 71.09%] [G loss: 0.668096]\n",
      "epoch:4 step:4177 [D loss: 0.444681, acc.: 83.59%] [G loss: 0.813815]\n",
      "epoch:4 step:4178 [D loss: 0.468996, acc.: 80.47%] [G loss: 0.767418]\n",
      "epoch:4 step:4179 [D loss: 0.528358, acc.: 75.78%] [G loss: 0.545824]\n",
      "epoch:4 step:4180 [D loss: 0.533699, acc.: 75.78%] [G loss: 0.582194]\n",
      "epoch:4 step:4181 [D loss: 0.507781, acc.: 74.22%] [G loss: 0.561867]\n",
      "epoch:4 step:4182 [D loss: 0.531047, acc.: 72.66%] [G loss: 0.470366]\n",
      "epoch:4 step:4183 [D loss: 0.524028, acc.: 72.66%] [G loss: 0.626203]\n",
      "epoch:4 step:4184 [D loss: 0.484003, acc.: 77.34%] [G loss: 0.664099]\n",
      "epoch:4 step:4185 [D loss: 0.571368, acc.: 72.66%] [G loss: 0.573814]\n",
      "epoch:4 step:4186 [D loss: 0.518596, acc.: 75.00%] [G loss: 0.620042]\n",
      "epoch:4 step:4187 [D loss: 0.499091, acc.: 75.00%] [G loss: 0.770559]\n",
      "epoch:4 step:4188 [D loss: 0.480131, acc.: 75.00%] [G loss: 0.770583]\n",
      "epoch:4 step:4189 [D loss: 0.510026, acc.: 78.12%] [G loss: 0.692954]\n",
      "epoch:4 step:4190 [D loss: 0.538530, acc.: 68.75%] [G loss: 0.508728]\n",
      "epoch:4 step:4191 [D loss: 0.446616, acc.: 78.91%] [G loss: 0.696589]\n",
      "epoch:4 step:4192 [D loss: 0.477192, acc.: 78.91%] [G loss: 0.640088]\n",
      "epoch:4 step:4193 [D loss: 0.459387, acc.: 74.22%] [G loss: 0.735777]\n",
      "epoch:4 step:4194 [D loss: 0.487916, acc.: 78.91%] [G loss: 0.702405]\n",
      "epoch:4 step:4195 [D loss: 0.427386, acc.: 82.81%] [G loss: 0.692356]\n",
      "epoch:4 step:4196 [D loss: 0.506770, acc.: 72.66%] [G loss: 0.660378]\n",
      "epoch:4 step:4197 [D loss: 0.555345, acc.: 71.09%] [G loss: 0.533183]\n",
      "epoch:4 step:4198 [D loss: 0.444398, acc.: 82.81%] [G loss: 0.735466]\n",
      "epoch:4 step:4199 [D loss: 0.402113, acc.: 85.94%] [G loss: 0.920912]\n",
      "epoch:4 step:4200 [D loss: 0.490614, acc.: 71.88%] [G loss: 0.879969]\n",
      "epoch:4 step:4201 [D loss: 0.548068, acc.: 71.09%] [G loss: 0.783135]\n",
      "epoch:4 step:4202 [D loss: 0.510307, acc.: 78.91%] [G loss: 0.600076]\n",
      "epoch:4 step:4203 [D loss: 0.532338, acc.: 71.09%] [G loss: 0.562493]\n",
      "epoch:4 step:4204 [D loss: 0.588102, acc.: 68.75%] [G loss: 0.569039]\n",
      "epoch:4 step:4205 [D loss: 0.465855, acc.: 81.25%] [G loss: 0.586990]\n",
      "epoch:4 step:4206 [D loss: 0.516234, acc.: 75.00%] [G loss: 0.538728]\n",
      "epoch:4 step:4207 [D loss: 0.534834, acc.: 71.09%] [G loss: 0.728395]\n",
      "epoch:4 step:4208 [D loss: 0.494056, acc.: 70.31%] [G loss: 0.771327]\n",
      "epoch:4 step:4209 [D loss: 0.495224, acc.: 78.12%] [G loss: 0.587795]\n",
      "epoch:4 step:4210 [D loss: 0.521941, acc.: 73.44%] [G loss: 0.568032]\n",
      "epoch:4 step:4211 [D loss: 0.507059, acc.: 76.56%] [G loss: 0.692661]\n",
      "epoch:4 step:4212 [D loss: 0.461542, acc.: 76.56%] [G loss: 0.685453]\n",
      "epoch:4 step:4213 [D loss: 0.570106, acc.: 71.88%] [G loss: 0.553324]\n",
      "epoch:4 step:4214 [D loss: 0.538601, acc.: 71.09%] [G loss: 0.531235]\n",
      "epoch:4 step:4215 [D loss: 0.488936, acc.: 78.91%] [G loss: 0.650787]\n",
      "epoch:4 step:4216 [D loss: 0.542455, acc.: 71.88%] [G loss: 0.697518]\n",
      "epoch:4 step:4217 [D loss: 0.558271, acc.: 71.88%] [G loss: 0.684184]\n",
      "epoch:4 step:4218 [D loss: 0.457131, acc.: 83.59%] [G loss: 0.708636]\n",
      "epoch:4 step:4219 [D loss: 0.492867, acc.: 78.12%] [G loss: 0.749539]\n",
      "epoch:4 step:4220 [D loss: 0.429858, acc.: 82.81%] [G loss: 0.795524]\n",
      "epoch:4 step:4221 [D loss: 0.585788, acc.: 72.66%] [G loss: 0.542437]\n",
      "epoch:4 step:4222 [D loss: 0.468620, acc.: 78.12%] [G loss: 0.867095]\n",
      "epoch:4 step:4223 [D loss: 0.461396, acc.: 82.03%] [G loss: 0.703186]\n",
      "epoch:4 step:4224 [D loss: 0.564316, acc.: 74.22%] [G loss: 0.541398]\n",
      "epoch:4 step:4225 [D loss: 0.615007, acc.: 65.62%] [G loss: 0.461027]\n",
      "epoch:4 step:4226 [D loss: 0.610767, acc.: 66.41%] [G loss: 0.466610]\n",
      "epoch:4 step:4227 [D loss: 0.532754, acc.: 71.09%] [G loss: 0.605358]\n",
      "epoch:4 step:4228 [D loss: 0.568287, acc.: 70.31%] [G loss: 0.525394]\n",
      "epoch:4 step:4229 [D loss: 0.513770, acc.: 75.00%] [G loss: 0.502156]\n",
      "epoch:4 step:4230 [D loss: 0.555154, acc.: 67.97%] [G loss: 0.444434]\n",
      "epoch:4 step:4231 [D loss: 0.594873, acc.: 64.84%] [G loss: 0.404698]\n",
      "epoch:4 step:4232 [D loss: 0.510599, acc.: 74.22%] [G loss: 0.510947]\n",
      "epoch:4 step:4233 [D loss: 0.449504, acc.: 84.38%] [G loss: 0.663257]\n",
      "epoch:4 step:4234 [D loss: 0.532827, acc.: 76.56%] [G loss: 0.513599]\n",
      "epoch:4 step:4235 [D loss: 0.452520, acc.: 82.81%] [G loss: 0.791458]\n",
      "epoch:4 step:4236 [D loss: 0.486283, acc.: 76.56%] [G loss: 0.644794]\n",
      "epoch:4 step:4237 [D loss: 0.589648, acc.: 64.06%] [G loss: 0.699217]\n",
      "epoch:4 step:4238 [D loss: 0.592129, acc.: 65.62%] [G loss: 0.628379]\n",
      "epoch:4 step:4239 [D loss: 0.485106, acc.: 78.12%] [G loss: 0.695331]\n",
      "epoch:4 step:4240 [D loss: 0.481408, acc.: 75.00%] [G loss: 0.548615]\n",
      "epoch:4 step:4241 [D loss: 0.576324, acc.: 67.97%] [G loss: 0.623778]\n",
      "epoch:4 step:4242 [D loss: 0.510354, acc.: 78.91%] [G loss: 0.707234]\n",
      "epoch:4 step:4243 [D loss: 0.453236, acc.: 82.81%] [G loss: 0.745991]\n",
      "epoch:4 step:4244 [D loss: 0.541378, acc.: 71.88%] [G loss: 0.612975]\n",
      "epoch:4 step:4245 [D loss: 0.500794, acc.: 79.69%] [G loss: 0.612167]\n",
      "epoch:4 step:4246 [D loss: 0.454782, acc.: 75.78%] [G loss: 0.937142]\n",
      "epoch:4 step:4247 [D loss: 0.426928, acc.: 85.94%] [G loss: 0.919994]\n",
      "epoch:4 step:4248 [D loss: 0.645663, acc.: 64.06%] [G loss: 0.501464]\n",
      "epoch:4 step:4249 [D loss: 0.632504, acc.: 67.19%] [G loss: 0.412461]\n",
      "epoch:4 step:4250 [D loss: 0.550445, acc.: 76.56%] [G loss: 0.519634]\n",
      "epoch:4 step:4251 [D loss: 0.443222, acc.: 77.34%] [G loss: 0.584763]\n",
      "epoch:4 step:4252 [D loss: 0.458391, acc.: 80.47%] [G loss: 0.764867]\n",
      "epoch:4 step:4253 [D loss: 0.567433, acc.: 73.44%] [G loss: 0.645442]\n",
      "epoch:4 step:4254 [D loss: 0.535416, acc.: 71.09%] [G loss: 0.603057]\n",
      "epoch:4 step:4255 [D loss: 0.564756, acc.: 68.75%] [G loss: 0.581573]\n",
      "epoch:4 step:4256 [D loss: 0.444491, acc.: 82.03%] [G loss: 0.705976]\n",
      "epoch:4 step:4257 [D loss: 0.477657, acc.: 75.00%] [G loss: 0.761463]\n",
      "epoch:4 step:4258 [D loss: 0.549187, acc.: 67.19%] [G loss: 0.654000]\n",
      "epoch:4 step:4259 [D loss: 0.622370, acc.: 65.62%] [G loss: 0.605407]\n",
      "epoch:4 step:4260 [D loss: 0.508619, acc.: 71.09%] [G loss: 0.539815]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:4 step:4261 [D loss: 0.458034, acc.: 78.12%] [G loss: 0.626042]\n",
      "epoch:4 step:4262 [D loss: 0.464343, acc.: 78.91%] [G loss: 0.513917]\n",
      "epoch:4 step:4263 [D loss: 0.493319, acc.: 72.66%] [G loss: 0.732866]\n",
      "epoch:4 step:4264 [D loss: 0.458716, acc.: 79.69%] [G loss: 0.779341]\n",
      "epoch:4 step:4265 [D loss: 0.538030, acc.: 76.56%] [G loss: 0.621107]\n",
      "epoch:4 step:4266 [D loss: 0.460331, acc.: 77.34%] [G loss: 0.655180]\n",
      "epoch:4 step:4267 [D loss: 0.511519, acc.: 75.78%] [G loss: 0.642658]\n",
      "epoch:4 step:4268 [D loss: 0.432297, acc.: 82.03%] [G loss: 0.752827]\n",
      "epoch:4 step:4269 [D loss: 0.515534, acc.: 75.00%] [G loss: 0.667420]\n",
      "epoch:4 step:4270 [D loss: 0.489020, acc.: 78.12%] [G loss: 0.657948]\n",
      "epoch:4 step:4271 [D loss: 0.519240, acc.: 75.78%] [G loss: 0.669205]\n",
      "epoch:4 step:4272 [D loss: 0.453084, acc.: 82.03%] [G loss: 0.768669]\n",
      "epoch:4 step:4273 [D loss: 0.546948, acc.: 78.12%] [G loss: 0.663341]\n",
      "epoch:4 step:4274 [D loss: 0.447492, acc.: 82.03%] [G loss: 0.784089]\n",
      "epoch:4 step:4275 [D loss: 0.507567, acc.: 71.88%] [G loss: 0.809357]\n",
      "epoch:4 step:4276 [D loss: 0.590627, acc.: 62.50%] [G loss: 0.637885]\n",
      "epoch:4 step:4277 [D loss: 0.538945, acc.: 73.44%] [G loss: 0.560166]\n",
      "epoch:4 step:4278 [D loss: 0.460631, acc.: 75.78%] [G loss: 0.738171]\n",
      "epoch:4 step:4279 [D loss: 0.569965, acc.: 70.31%] [G loss: 0.577538]\n",
      "epoch:4 step:4280 [D loss: 0.552847, acc.: 72.66%] [G loss: 0.447894]\n",
      "epoch:4 step:4281 [D loss: 0.525503, acc.: 79.69%] [G loss: 0.548435]\n",
      "epoch:4 step:4282 [D loss: 0.477424, acc.: 80.47%] [G loss: 0.572086]\n",
      "epoch:4 step:4283 [D loss: 0.584805, acc.: 60.16%] [G loss: 0.479222]\n",
      "epoch:4 step:4284 [D loss: 0.445678, acc.: 84.38%] [G loss: 0.552439]\n",
      "epoch:4 step:4285 [D loss: 0.536338, acc.: 77.34%] [G loss: 0.536364]\n",
      "epoch:4 step:4286 [D loss: 0.575308, acc.: 70.31%] [G loss: 0.550962]\n",
      "epoch:4 step:4287 [D loss: 0.545649, acc.: 71.09%] [G loss: 0.540974]\n",
      "epoch:4 step:4288 [D loss: 0.534508, acc.: 73.44%] [G loss: 0.469307]\n",
      "epoch:4 step:4289 [D loss: 0.500887, acc.: 73.44%] [G loss: 0.613770]\n",
      "epoch:4 step:4290 [D loss: 0.556682, acc.: 75.00%] [G loss: 0.504274]\n",
      "epoch:4 step:4291 [D loss: 0.575762, acc.: 66.41%] [G loss: 0.517745]\n",
      "epoch:4 step:4292 [D loss: 0.537756, acc.: 73.44%] [G loss: 0.564215]\n",
      "epoch:4 step:4293 [D loss: 0.481408, acc.: 76.56%] [G loss: 0.674467]\n",
      "epoch:4 step:4294 [D loss: 0.453412, acc.: 77.34%] [G loss: 0.689442]\n",
      "epoch:4 step:4295 [D loss: 0.469285, acc.: 75.78%] [G loss: 0.670815]\n",
      "epoch:4 step:4296 [D loss: 0.444561, acc.: 78.12%] [G loss: 0.666136]\n",
      "epoch:4 step:4297 [D loss: 0.473475, acc.: 78.12%] [G loss: 0.620808]\n",
      "epoch:4 step:4298 [D loss: 0.471249, acc.: 82.03%] [G loss: 0.571901]\n",
      "epoch:4 step:4299 [D loss: 0.534239, acc.: 74.22%] [G loss: 0.543300]\n",
      "epoch:4 step:4300 [D loss: 0.465142, acc.: 79.69%] [G loss: 0.631175]\n",
      "epoch:4 step:4301 [D loss: 0.544078, acc.: 75.00%] [G loss: 0.583305]\n",
      "epoch:4 step:4302 [D loss: 0.420257, acc.: 82.81%] [G loss: 0.663044]\n",
      "epoch:4 step:4303 [D loss: 0.461180, acc.: 78.91%] [G loss: 0.525429]\n",
      "epoch:4 step:4304 [D loss: 0.500186, acc.: 78.91%] [G loss: 0.525378]\n",
      "epoch:4 step:4305 [D loss: 0.493614, acc.: 78.91%] [G loss: 0.601944]\n",
      "epoch:4 step:4306 [D loss: 0.431914, acc.: 82.81%] [G loss: 0.578864]\n",
      "epoch:4 step:4307 [D loss: 0.524106, acc.: 75.00%] [G loss: 0.611912]\n",
      "epoch:4 step:4308 [D loss: 0.511931, acc.: 78.12%] [G loss: 0.536214]\n",
      "epoch:4 step:4309 [D loss: 0.521490, acc.: 75.00%] [G loss: 0.549253]\n",
      "epoch:4 step:4310 [D loss: 0.530562, acc.: 78.91%] [G loss: 0.558806]\n",
      "epoch:4 step:4311 [D loss: 0.544858, acc.: 74.22%] [G loss: 0.509156]\n",
      "epoch:4 step:4312 [D loss: 0.497664, acc.: 74.22%] [G loss: 0.621067]\n",
      "epoch:4 step:4313 [D loss: 0.579841, acc.: 68.75%] [G loss: 0.541823]\n",
      "epoch:4 step:4314 [D loss: 0.633086, acc.: 68.75%] [G loss: 0.557105]\n",
      "epoch:4 step:4315 [D loss: 0.504014, acc.: 75.00%] [G loss: 0.647869]\n",
      "epoch:4 step:4316 [D loss: 0.492729, acc.: 76.56%] [G loss: 0.694651]\n",
      "epoch:4 step:4317 [D loss: 0.478097, acc.: 75.00%] [G loss: 0.660814]\n",
      "epoch:4 step:4318 [D loss: 0.519678, acc.: 74.22%] [G loss: 0.579061]\n",
      "epoch:4 step:4319 [D loss: 0.490421, acc.: 75.00%] [G loss: 0.673527]\n",
      "epoch:4 step:4320 [D loss: 0.563101, acc.: 68.75%] [G loss: 0.550909]\n",
      "epoch:4 step:4321 [D loss: 0.525303, acc.: 73.44%] [G loss: 0.592907]\n",
      "epoch:4 step:4322 [D loss: 0.510061, acc.: 74.22%] [G loss: 0.740401]\n",
      "epoch:4 step:4323 [D loss: 0.498054, acc.: 75.78%] [G loss: 0.582564]\n",
      "epoch:4 step:4324 [D loss: 0.566576, acc.: 68.75%] [G loss: 0.678133]\n",
      "epoch:4 step:4325 [D loss: 0.542076, acc.: 72.66%] [G loss: 0.693802]\n",
      "epoch:4 step:4326 [D loss: 0.530053, acc.: 70.31%] [G loss: 0.620199]\n",
      "epoch:4 step:4327 [D loss: 0.493685, acc.: 75.00%] [G loss: 0.549887]\n",
      "epoch:4 step:4328 [D loss: 0.541120, acc.: 72.66%] [G loss: 0.517629]\n",
      "epoch:4 step:4329 [D loss: 0.505224, acc.: 74.22%] [G loss: 0.697756]\n",
      "epoch:4 step:4330 [D loss: 0.382528, acc.: 89.84%] [G loss: 0.765976]\n",
      "epoch:4 step:4331 [D loss: 0.564918, acc.: 71.09%] [G loss: 0.563564]\n",
      "epoch:4 step:4332 [D loss: 0.580090, acc.: 67.97%] [G loss: 0.543817]\n",
      "epoch:4 step:4333 [D loss: 0.488901, acc.: 74.22%] [G loss: 0.611413]\n",
      "epoch:4 step:4334 [D loss: 0.536242, acc.: 71.88%] [G loss: 0.596153]\n",
      "epoch:4 step:4335 [D loss: 0.531457, acc.: 71.09%] [G loss: 0.646250]\n",
      "epoch:4 step:4336 [D loss: 0.555537, acc.: 71.88%] [G loss: 0.650750]\n",
      "epoch:4 step:4337 [D loss: 0.464626, acc.: 79.69%] [G loss: 0.725339]\n",
      "epoch:4 step:4338 [D loss: 0.544522, acc.: 75.78%] [G loss: 0.647332]\n",
      "epoch:4 step:4339 [D loss: 0.585313, acc.: 70.31%] [G loss: 0.612898]\n",
      "epoch:4 step:4340 [D loss: 0.440271, acc.: 83.59%] [G loss: 0.656916]\n",
      "epoch:4 step:4341 [D loss: 0.500366, acc.: 75.78%] [G loss: 0.546196]\n",
      "epoch:4 step:4342 [D loss: 0.514537, acc.: 71.88%] [G loss: 0.509238]\n",
      "epoch:4 step:4343 [D loss: 0.507253, acc.: 75.78%] [G loss: 0.558589]\n",
      "epoch:4 step:4344 [D loss: 0.502252, acc.: 79.69%] [G loss: 0.592834]\n",
      "epoch:4 step:4345 [D loss: 0.477706, acc.: 76.56%] [G loss: 0.653509]\n",
      "epoch:4 step:4346 [D loss: 0.475158, acc.: 75.78%] [G loss: 0.576417]\n",
      "epoch:4 step:4347 [D loss: 0.497289, acc.: 75.00%] [G loss: 0.693686]\n",
      "epoch:4 step:4348 [D loss: 0.548997, acc.: 67.97%] [G loss: 0.499984]\n",
      "epoch:4 step:4349 [D loss: 0.499401, acc.: 72.66%] [G loss: 0.503529]\n",
      "epoch:4 step:4350 [D loss: 0.489557, acc.: 75.00%] [G loss: 0.649529]\n",
      "epoch:4 step:4351 [D loss: 0.460738, acc.: 80.47%] [G loss: 0.629119]\n",
      "epoch:4 step:4352 [D loss: 0.532093, acc.: 72.66%] [G loss: 0.474806]\n",
      "epoch:4 step:4353 [D loss: 0.480836, acc.: 75.00%] [G loss: 0.673743]\n",
      "epoch:4 step:4354 [D loss: 0.520352, acc.: 72.66%] [G loss: 0.647282]\n",
      "epoch:4 step:4355 [D loss: 0.538282, acc.: 74.22%] [G loss: 0.553916]\n",
      "epoch:4 step:4356 [D loss: 0.490924, acc.: 76.56%] [G loss: 0.589280]\n",
      "epoch:4 step:4357 [D loss: 0.531482, acc.: 73.44%] [G loss: 0.437063]\n",
      "epoch:4 step:4358 [D loss: 0.498975, acc.: 78.12%] [G loss: 0.580308]\n",
      "epoch:4 step:4359 [D loss: 0.431267, acc.: 87.50%] [G loss: 0.763654]\n",
      "epoch:4 step:4360 [D loss: 0.534804, acc.: 74.22%] [G loss: 0.624367]\n",
      "epoch:4 step:4361 [D loss: 0.474801, acc.: 82.03%] [G loss: 0.484566]\n",
      "epoch:4 step:4362 [D loss: 0.536557, acc.: 72.66%] [G loss: 0.720011]\n",
      "epoch:4 step:4363 [D loss: 0.572690, acc.: 68.75%] [G loss: 0.686905]\n",
      "epoch:4 step:4364 [D loss: 0.514833, acc.: 75.00%] [G loss: 0.654219]\n",
      "epoch:4 step:4365 [D loss: 0.528906, acc.: 71.88%] [G loss: 0.513850]\n",
      "epoch:4 step:4366 [D loss: 0.537424, acc.: 68.75%] [G loss: 0.618611]\n",
      "epoch:4 step:4367 [D loss: 0.534218, acc.: 69.53%] [G loss: 0.610071]\n",
      "epoch:4 step:4368 [D loss: 0.513228, acc.: 75.78%] [G loss: 0.681930]\n",
      "epoch:4 step:4369 [D loss: 0.555550, acc.: 70.31%] [G loss: 0.550894]\n",
      "epoch:4 step:4370 [D loss: 0.616146, acc.: 69.53%] [G loss: 0.417173]\n",
      "epoch:4 step:4371 [D loss: 0.495455, acc.: 72.66%] [G loss: 0.555115]\n",
      "epoch:4 step:4372 [D loss: 0.518139, acc.: 75.00%] [G loss: 0.528433]\n",
      "epoch:4 step:4373 [D loss: 0.537235, acc.: 70.31%] [G loss: 0.611788]\n",
      "epoch:4 step:4374 [D loss: 0.534829, acc.: 72.66%] [G loss: 0.670910]\n",
      "epoch:4 step:4375 [D loss: 0.492175, acc.: 76.56%] [G loss: 0.591180]\n",
      "epoch:4 step:4376 [D loss: 0.498505, acc.: 75.78%] [G loss: 0.590968]\n",
      "epoch:4 step:4377 [D loss: 0.500650, acc.: 75.78%] [G loss: 0.685158]\n",
      "epoch:4 step:4378 [D loss: 0.495258, acc.: 75.00%] [G loss: 0.542701]\n",
      "epoch:4 step:4379 [D loss: 0.505311, acc.: 77.34%] [G loss: 0.561759]\n",
      "epoch:4 step:4380 [D loss: 0.520164, acc.: 75.00%] [G loss: 0.634113]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:4 step:4381 [D loss: 0.504398, acc.: 76.56%] [G loss: 0.645200]\n",
      "epoch:4 step:4382 [D loss: 0.508830, acc.: 77.34%] [G loss: 0.608416]\n",
      "epoch:4 step:4383 [D loss: 0.473536, acc.: 78.12%] [G loss: 0.730603]\n",
      "epoch:4 step:4384 [D loss: 0.581967, acc.: 71.09%] [G loss: 0.594174]\n",
      "epoch:4 step:4385 [D loss: 0.491173, acc.: 78.91%] [G loss: 0.541396]\n",
      "epoch:4 step:4386 [D loss: 0.446201, acc.: 82.03%] [G loss: 0.624792]\n",
      "epoch:4 step:4387 [D loss: 0.438782, acc.: 86.72%] [G loss: 0.633667]\n",
      "epoch:4 step:4388 [D loss: 0.465802, acc.: 78.91%] [G loss: 0.681565]\n",
      "epoch:4 step:4389 [D loss: 0.442385, acc.: 76.56%] [G loss: 0.839100]\n",
      "epoch:4 step:4390 [D loss: 0.474168, acc.: 78.12%] [G loss: 0.830340]\n",
      "epoch:4 step:4391 [D loss: 0.551756, acc.: 75.78%] [G loss: 0.669684]\n",
      "epoch:4 step:4392 [D loss: 0.542056, acc.: 72.66%] [G loss: 0.529672]\n",
      "epoch:4 step:4393 [D loss: 0.509903, acc.: 79.69%] [G loss: 0.557901]\n",
      "epoch:4 step:4394 [D loss: 0.544901, acc.: 67.97%] [G loss: 0.529260]\n",
      "epoch:4 step:4395 [D loss: 0.447302, acc.: 78.91%] [G loss: 0.733287]\n",
      "epoch:4 step:4396 [D loss: 0.390888, acc.: 84.38%] [G loss: 0.836593]\n",
      "epoch:4 step:4397 [D loss: 0.453406, acc.: 79.69%] [G loss: 0.843431]\n",
      "epoch:4 step:4398 [D loss: 0.464147, acc.: 79.69%] [G loss: 0.776057]\n",
      "epoch:4 step:4399 [D loss: 0.450062, acc.: 81.25%] [G loss: 0.770509]\n",
      "epoch:4 step:4400 [D loss: 0.576344, acc.: 67.97%] [G loss: 0.573033]\n",
      "epoch:4 step:4401 [D loss: 0.582617, acc.: 63.28%] [G loss: 0.431641]\n",
      "epoch:4 step:4402 [D loss: 0.482928, acc.: 77.34%] [G loss: 0.614073]\n",
      "epoch:4 step:4403 [D loss: 0.562275, acc.: 73.44%] [G loss: 0.622136]\n",
      "epoch:4 step:4404 [D loss: 0.505442, acc.: 75.78%] [G loss: 0.633381]\n",
      "epoch:4 step:4405 [D loss: 0.501363, acc.: 73.44%] [G loss: 0.597170]\n",
      "epoch:4 step:4406 [D loss: 0.606845, acc.: 64.84%] [G loss: 0.537442]\n",
      "epoch:4 step:4407 [D loss: 0.567855, acc.: 67.19%] [G loss: 0.487856]\n",
      "epoch:4 step:4408 [D loss: 0.479413, acc.: 77.34%] [G loss: 0.558315]\n",
      "epoch:4 step:4409 [D loss: 0.477116, acc.: 78.91%] [G loss: 0.655373]\n",
      "epoch:4 step:4410 [D loss: 0.550517, acc.: 72.66%] [G loss: 0.674475]\n",
      "epoch:4 step:4411 [D loss: 0.527306, acc.: 72.66%] [G loss: 0.690750]\n",
      "epoch:4 step:4412 [D loss: 0.528055, acc.: 73.44%] [G loss: 0.671357]\n",
      "epoch:4 step:4413 [D loss: 0.506237, acc.: 72.66%] [G loss: 0.750058]\n",
      "epoch:4 step:4414 [D loss: 0.531330, acc.: 75.78%] [G loss: 0.558332]\n",
      "epoch:4 step:4415 [D loss: 0.550358, acc.: 65.62%] [G loss: 0.609789]\n",
      "epoch:4 step:4416 [D loss: 0.527974, acc.: 77.34%] [G loss: 0.598145]\n",
      "epoch:4 step:4417 [D loss: 0.432625, acc.: 84.38%] [G loss: 0.634258]\n",
      "epoch:4 step:4418 [D loss: 0.494079, acc.: 77.34%] [G loss: 0.566750]\n",
      "epoch:4 step:4419 [D loss: 0.567003, acc.: 72.66%] [G loss: 0.635403]\n",
      "epoch:4 step:4420 [D loss: 0.586009, acc.: 67.97%] [G loss: 0.570832]\n",
      "epoch:4 step:4421 [D loss: 0.564621, acc.: 76.56%] [G loss: 0.547331]\n",
      "epoch:4 step:4422 [D loss: 0.514069, acc.: 78.12%] [G loss: 0.648438]\n",
      "epoch:4 step:4423 [D loss: 0.501200, acc.: 79.69%] [G loss: 0.590477]\n",
      "epoch:4 step:4424 [D loss: 0.489647, acc.: 74.22%] [G loss: 0.681385]\n",
      "epoch:4 step:4425 [D loss: 0.472410, acc.: 82.03%] [G loss: 0.727153]\n",
      "epoch:4 step:4426 [D loss: 0.487037, acc.: 79.69%] [G loss: 0.605806]\n",
      "epoch:4 step:4427 [D loss: 0.490468, acc.: 77.34%] [G loss: 0.544673]\n",
      "epoch:4 step:4428 [D loss: 0.428023, acc.: 88.28%] [G loss: 0.582015]\n",
      "epoch:4 step:4429 [D loss: 0.469935, acc.: 78.12%] [G loss: 0.635722]\n",
      "epoch:4 step:4430 [D loss: 0.467710, acc.: 78.91%] [G loss: 0.581377]\n",
      "epoch:4 step:4431 [D loss: 0.546063, acc.: 70.31%] [G loss: 0.585185]\n",
      "epoch:4 step:4432 [D loss: 0.509408, acc.: 76.56%] [G loss: 0.579638]\n",
      "epoch:4 step:4433 [D loss: 0.501017, acc.: 75.00%] [G loss: 0.488265]\n",
      "epoch:4 step:4434 [D loss: 0.544805, acc.: 77.34%] [G loss: 0.452768]\n",
      "epoch:4 step:4435 [D loss: 0.512892, acc.: 71.09%] [G loss: 0.541719]\n",
      "epoch:4 step:4436 [D loss: 0.523700, acc.: 77.34%] [G loss: 0.619056]\n",
      "epoch:4 step:4437 [D loss: 0.576581, acc.: 65.62%] [G loss: 0.600312]\n",
      "epoch:4 step:4438 [D loss: 0.498308, acc.: 75.00%] [G loss: 0.665476]\n",
      "epoch:4 step:4439 [D loss: 0.504648, acc.: 77.34%] [G loss: 0.746502]\n",
      "epoch:4 step:4440 [D loss: 0.517923, acc.: 75.00%] [G loss: 0.596425]\n",
      "epoch:4 step:4441 [D loss: 0.476210, acc.: 77.34%] [G loss: 0.696174]\n",
      "epoch:4 step:4442 [D loss: 0.513599, acc.: 75.00%] [G loss: 0.574550]\n",
      "epoch:4 step:4443 [D loss: 0.464825, acc.: 76.56%] [G loss: 0.585095]\n",
      "epoch:4 step:4444 [D loss: 0.621102, acc.: 56.25%] [G loss: 0.486937]\n",
      "epoch:4 step:4445 [D loss: 0.500932, acc.: 76.56%] [G loss: 0.515968]\n",
      "epoch:4 step:4446 [D loss: 0.534665, acc.: 73.44%] [G loss: 0.573264]\n",
      "epoch:4 step:4447 [D loss: 0.483568, acc.: 74.22%] [G loss: 0.611266]\n",
      "epoch:4 step:4448 [D loss: 0.513178, acc.: 75.00%] [G loss: 0.672126]\n",
      "epoch:4 step:4449 [D loss: 0.506872, acc.: 77.34%] [G loss: 0.666361]\n",
      "epoch:4 step:4450 [D loss: 0.576533, acc.: 62.50%] [G loss: 0.526711]\n",
      "epoch:4 step:4451 [D loss: 0.527566, acc.: 73.44%] [G loss: 0.521049]\n",
      "epoch:4 step:4452 [D loss: 0.585717, acc.: 66.41%] [G loss: 0.537126]\n",
      "epoch:4 step:4453 [D loss: 0.494491, acc.: 78.12%] [G loss: 0.537518]\n",
      "epoch:4 step:4454 [D loss: 0.539531, acc.: 71.09%] [G loss: 0.488409]\n",
      "epoch:4 step:4455 [D loss: 0.467584, acc.: 80.47%] [G loss: 0.664254]\n",
      "epoch:4 step:4456 [D loss: 0.459518, acc.: 78.12%] [G loss: 0.740587]\n",
      "epoch:4 step:4457 [D loss: 0.499145, acc.: 78.12%] [G loss: 0.598499]\n",
      "epoch:4 step:4458 [D loss: 0.585290, acc.: 71.88%] [G loss: 0.528437]\n",
      "epoch:4 step:4459 [D loss: 0.554596, acc.: 67.97%] [G loss: 0.523457]\n",
      "epoch:4 step:4460 [D loss: 0.472399, acc.: 80.47%] [G loss: 0.561460]\n",
      "epoch:4 step:4461 [D loss: 0.533021, acc.: 71.88%] [G loss: 0.620128]\n",
      "epoch:4 step:4462 [D loss: 0.483054, acc.: 75.78%] [G loss: 0.597007]\n",
      "epoch:4 step:4463 [D loss: 0.507360, acc.: 73.44%] [G loss: 0.458719]\n",
      "epoch:4 step:4464 [D loss: 0.540896, acc.: 69.53%] [G loss: 0.567714]\n",
      "epoch:4 step:4465 [D loss: 0.530187, acc.: 75.78%] [G loss: 0.630859]\n",
      "epoch:4 step:4466 [D loss: 0.543190, acc.: 73.44%] [G loss: 0.576172]\n",
      "epoch:4 step:4467 [D loss: 0.482062, acc.: 78.12%] [G loss: 0.627474]\n",
      "epoch:4 step:4468 [D loss: 0.580194, acc.: 73.44%] [G loss: 0.540527]\n",
      "epoch:4 step:4469 [D loss: 0.529339, acc.: 76.56%] [G loss: 0.602689]\n",
      "epoch:4 step:4470 [D loss: 0.514202, acc.: 75.00%] [G loss: 0.682682]\n",
      "epoch:4 step:4471 [D loss: 0.567519, acc.: 76.56%] [G loss: 0.581975]\n",
      "epoch:4 step:4472 [D loss: 0.480383, acc.: 76.56%] [G loss: 0.643135]\n",
      "epoch:4 step:4473 [D loss: 0.442207, acc.: 82.03%] [G loss: 0.664207]\n",
      "epoch:4 step:4474 [D loss: 0.497685, acc.: 76.56%] [G loss: 0.751812]\n",
      "epoch:4 step:4475 [D loss: 0.508727, acc.: 72.66%] [G loss: 0.628119]\n",
      "epoch:4 step:4476 [D loss: 0.544944, acc.: 70.31%] [G loss: 0.579900]\n",
      "epoch:4 step:4477 [D loss: 0.562844, acc.: 69.53%] [G loss: 0.428836]\n",
      "epoch:4 step:4478 [D loss: 0.550239, acc.: 69.53%] [G loss: 0.502066]\n",
      "epoch:4 step:4479 [D loss: 0.546141, acc.: 69.53%] [G loss: 0.596269]\n",
      "epoch:4 step:4480 [D loss: 0.499966, acc.: 77.34%] [G loss: 0.641730]\n",
      "epoch:4 step:4481 [D loss: 0.483864, acc.: 80.47%] [G loss: 0.600733]\n",
      "epoch:4 step:4482 [D loss: 0.592989, acc.: 65.62%] [G loss: 0.536910]\n",
      "epoch:4 step:4483 [D loss: 0.555041, acc.: 75.00%] [G loss: 0.521794]\n",
      "epoch:4 step:4484 [D loss: 0.458679, acc.: 80.47%] [G loss: 0.570891]\n",
      "epoch:4 step:4485 [D loss: 0.516786, acc.: 76.56%] [G loss: 0.612113]\n",
      "epoch:4 step:4486 [D loss: 0.587158, acc.: 67.19%] [G loss: 0.602019]\n",
      "epoch:4 step:4487 [D loss: 0.608411, acc.: 65.62%] [G loss: 0.538975]\n",
      "epoch:4 step:4488 [D loss: 0.524038, acc.: 78.12%] [G loss: 0.470073]\n",
      "epoch:4 step:4489 [D loss: 0.519598, acc.: 75.00%] [G loss: 0.467682]\n",
      "epoch:4 step:4490 [D loss: 0.506473, acc.: 75.78%] [G loss: 0.581294]\n",
      "epoch:4 step:4491 [D loss: 0.563603, acc.: 71.09%] [G loss: 0.596084]\n",
      "epoch:4 step:4492 [D loss: 0.554518, acc.: 74.22%] [G loss: 0.532184]\n",
      "epoch:4 step:4493 [D loss: 0.541959, acc.: 74.22%] [G loss: 0.621172]\n",
      "epoch:4 step:4494 [D loss: 0.438005, acc.: 79.69%] [G loss: 0.735540]\n",
      "epoch:4 step:4495 [D loss: 0.423105, acc.: 85.94%] [G loss: 0.716967]\n",
      "epoch:4 step:4496 [D loss: 0.524195, acc.: 70.31%] [G loss: 0.633169]\n",
      "epoch:4 step:4497 [D loss: 0.509876, acc.: 78.91%] [G loss: 0.640207]\n",
      "epoch:4 step:4498 [D loss: 0.581354, acc.: 65.62%] [G loss: 0.487855]\n",
      "epoch:4 step:4499 [D loss: 0.539500, acc.: 72.66%] [G loss: 0.603938]\n",
      "epoch:4 step:4500 [D loss: 0.454525, acc.: 78.12%] [G loss: 0.631462]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:4 step:4501 [D loss: 0.437519, acc.: 81.25%] [G loss: 1.037027]\n",
      "epoch:4 step:4502 [D loss: 0.524720, acc.: 71.09%] [G loss: 0.677196]\n",
      "epoch:4 step:4503 [D loss: 0.500976, acc.: 77.34%] [G loss: 0.651205]\n",
      "epoch:4 step:4504 [D loss: 0.511244, acc.: 71.88%] [G loss: 0.701226]\n",
      "epoch:4 step:4505 [D loss: 0.529222, acc.: 74.22%] [G loss: 0.714503]\n",
      "epoch:4 step:4506 [D loss: 0.485899, acc.: 79.69%] [G loss: 0.579571]\n",
      "epoch:4 step:4507 [D loss: 0.592776, acc.: 67.19%] [G loss: 0.408545]\n",
      "epoch:4 step:4508 [D loss: 0.463616, acc.: 80.47%] [G loss: 0.657326]\n",
      "epoch:4 step:4509 [D loss: 0.492703, acc.: 75.78%] [G loss: 0.698853]\n",
      "epoch:4 step:4510 [D loss: 0.551822, acc.: 71.09%] [G loss: 0.641891]\n",
      "epoch:4 step:4511 [D loss: 0.489446, acc.: 75.78%] [G loss: 0.709546]\n",
      "epoch:4 step:4512 [D loss: 0.489822, acc.: 76.56%] [G loss: 0.588013]\n",
      "epoch:4 step:4513 [D loss: 0.593583, acc.: 69.53%] [G loss: 0.493215]\n",
      "epoch:4 step:4514 [D loss: 0.621302, acc.: 67.97%] [G loss: 0.538227]\n",
      "epoch:4 step:4515 [D loss: 0.488539, acc.: 76.56%] [G loss: 0.490199]\n",
      "epoch:4 step:4516 [D loss: 0.600848, acc.: 68.75%] [G loss: 0.534622]\n",
      "epoch:4 step:4517 [D loss: 0.490575, acc.: 78.91%] [G loss: 0.775124]\n",
      "epoch:4 step:4518 [D loss: 0.501077, acc.: 74.22%] [G loss: 0.653971]\n",
      "epoch:4 step:4519 [D loss: 0.495836, acc.: 76.56%] [G loss: 0.580096]\n",
      "epoch:4 step:4520 [D loss: 0.491719, acc.: 73.44%] [G loss: 0.649194]\n",
      "epoch:4 step:4521 [D loss: 0.515821, acc.: 76.56%] [G loss: 0.625515]\n",
      "epoch:4 step:4522 [D loss: 0.578777, acc.: 68.75%] [G loss: 0.497915]\n",
      "epoch:4 step:4523 [D loss: 0.492736, acc.: 75.00%] [G loss: 0.611715]\n",
      "epoch:4 step:4524 [D loss: 0.559830, acc.: 71.09%] [G loss: 0.483771]\n",
      "epoch:4 step:4525 [D loss: 0.550774, acc.: 71.88%] [G loss: 0.500539]\n",
      "epoch:4 step:4526 [D loss: 0.512837, acc.: 73.44%] [G loss: 0.657709]\n",
      "epoch:4 step:4527 [D loss: 0.558938, acc.: 67.19%] [G loss: 0.564040]\n",
      "epoch:4 step:4528 [D loss: 0.484081, acc.: 79.69%] [G loss: 0.612988]\n",
      "epoch:4 step:4529 [D loss: 0.451673, acc.: 78.91%] [G loss: 0.929275]\n",
      "epoch:4 step:4530 [D loss: 0.472332, acc.: 78.12%] [G loss: 0.810986]\n",
      "epoch:4 step:4531 [D loss: 0.555508, acc.: 71.09%] [G loss: 0.690369]\n",
      "epoch:4 step:4532 [D loss: 0.580297, acc.: 64.84%] [G loss: 0.585164]\n",
      "epoch:4 step:4533 [D loss: 0.521550, acc.: 74.22%] [G loss: 0.564299]\n",
      "epoch:4 step:4534 [D loss: 0.427744, acc.: 81.25%] [G loss: 0.651491]\n",
      "epoch:4 step:4535 [D loss: 0.553085, acc.: 64.06%] [G loss: 0.587244]\n",
      "epoch:4 step:4536 [D loss: 0.580154, acc.: 69.53%] [G loss: 0.563277]\n",
      "epoch:4 step:4537 [D loss: 0.574673, acc.: 72.66%] [G loss: 0.493471]\n",
      "epoch:4 step:4538 [D loss: 0.513554, acc.: 77.34%] [G loss: 0.451314]\n",
      "epoch:4 step:4539 [D loss: 0.494810, acc.: 82.03%] [G loss: 0.616636]\n",
      "epoch:4 step:4540 [D loss: 0.444828, acc.: 83.59%] [G loss: 0.576645]\n",
      "epoch:4 step:4541 [D loss: 0.588750, acc.: 68.75%] [G loss: 0.556267]\n",
      "epoch:4 step:4542 [D loss: 0.589995, acc.: 67.19%] [G loss: 0.533407]\n",
      "epoch:4 step:4543 [D loss: 0.545577, acc.: 71.88%] [G loss: 0.579230]\n",
      "epoch:4 step:4544 [D loss: 0.490020, acc.: 78.91%] [G loss: 0.694872]\n",
      "epoch:4 step:4545 [D loss: 0.539372, acc.: 71.09%] [G loss: 0.629579]\n",
      "epoch:4 step:4546 [D loss: 0.476148, acc.: 77.34%] [G loss: 0.691217]\n",
      "epoch:4 step:4547 [D loss: 0.537881, acc.: 71.09%] [G loss: 0.621816]\n",
      "epoch:4 step:4548 [D loss: 0.522285, acc.: 70.31%] [G loss: 0.598009]\n",
      "epoch:4 step:4549 [D loss: 0.530464, acc.: 71.88%] [G loss: 0.554672]\n",
      "epoch:4 step:4550 [D loss: 0.457818, acc.: 76.56%] [G loss: 0.722791]\n",
      "epoch:4 step:4551 [D loss: 0.454997, acc.: 74.22%] [G loss: 0.875693]\n",
      "epoch:4 step:4552 [D loss: 0.576535, acc.: 64.06%] [G loss: 0.580075]\n",
      "epoch:4 step:4553 [D loss: 0.463361, acc.: 79.69%] [G loss: 0.696161]\n",
      "epoch:4 step:4554 [D loss: 0.514461, acc.: 71.88%] [G loss: 0.596339]\n",
      "epoch:4 step:4555 [D loss: 0.464366, acc.: 80.47%] [G loss: 0.774514]\n",
      "epoch:4 step:4556 [D loss: 0.569970, acc.: 72.66%] [G loss: 0.660365]\n",
      "epoch:4 step:4557 [D loss: 0.480044, acc.: 79.69%] [G loss: 0.637290]\n",
      "epoch:4 step:4558 [D loss: 0.493822, acc.: 75.78%] [G loss: 0.568947]\n",
      "epoch:4 step:4559 [D loss: 0.492111, acc.: 78.12%] [G loss: 0.584585]\n",
      "epoch:4 step:4560 [D loss: 0.566553, acc.: 71.09%] [G loss: 0.468047]\n",
      "epoch:4 step:4561 [D loss: 0.575860, acc.: 68.75%] [G loss: 0.531033]\n",
      "epoch:4 step:4562 [D loss: 0.445188, acc.: 81.25%] [G loss: 0.834281]\n",
      "epoch:4 step:4563 [D loss: 0.561688, acc.: 73.44%] [G loss: 0.666151]\n",
      "epoch:4 step:4564 [D loss: 0.490745, acc.: 82.03%] [G loss: 0.683505]\n",
      "epoch:4 step:4565 [D loss: 0.554411, acc.: 74.22%] [G loss: 0.645904]\n",
      "epoch:4 step:4566 [D loss: 0.560091, acc.: 70.31%] [G loss: 0.525988]\n",
      "epoch:4 step:4567 [D loss: 0.491953, acc.: 75.00%] [G loss: 0.610167]\n",
      "epoch:4 step:4568 [D loss: 0.520608, acc.: 71.88%] [G loss: 0.548024]\n",
      "epoch:4 step:4569 [D loss: 0.460621, acc.: 78.12%] [G loss: 0.577067]\n",
      "epoch:4 step:4570 [D loss: 0.472676, acc.: 82.03%] [G loss: 0.593754]\n",
      "epoch:4 step:4571 [D loss: 0.481348, acc.: 77.34%] [G loss: 0.775663]\n",
      "epoch:4 step:4572 [D loss: 0.641283, acc.: 68.75%] [G loss: 0.630998]\n",
      "epoch:4 step:4573 [D loss: 0.515407, acc.: 75.78%] [G loss: 0.505278]\n",
      "epoch:4 step:4574 [D loss: 0.562497, acc.: 67.97%] [G loss: 0.633260]\n",
      "epoch:4 step:4575 [D loss: 0.563387, acc.: 70.31%] [G loss: 0.588378]\n",
      "epoch:4 step:4576 [D loss: 0.595126, acc.: 65.62%] [G loss: 0.522863]\n",
      "epoch:4 step:4577 [D loss: 0.505416, acc.: 74.22%] [G loss: 0.650536]\n",
      "epoch:4 step:4578 [D loss: 0.483586, acc.: 74.22%] [G loss: 0.606457]\n",
      "epoch:4 step:4579 [D loss: 0.564932, acc.: 74.22%] [G loss: 0.630162]\n",
      "epoch:4 step:4580 [D loss: 0.495745, acc.: 77.34%] [G loss: 0.558706]\n",
      "epoch:4 step:4581 [D loss: 0.466822, acc.: 80.47%] [G loss: 0.675774]\n",
      "epoch:4 step:4582 [D loss: 0.437762, acc.: 82.03%] [G loss: 0.703950]\n",
      "epoch:4 step:4583 [D loss: 0.439216, acc.: 84.38%] [G loss: 0.672737]\n",
      "epoch:4 step:4584 [D loss: 0.490170, acc.: 79.69%] [G loss: 0.591708]\n",
      "epoch:4 step:4585 [D loss: 0.521335, acc.: 71.09%] [G loss: 0.720039]\n",
      "epoch:4 step:4586 [D loss: 0.432341, acc.: 78.91%] [G loss: 0.713073]\n",
      "epoch:4 step:4587 [D loss: 0.538228, acc.: 69.53%] [G loss: 0.601622]\n",
      "epoch:4 step:4588 [D loss: 0.594067, acc.: 64.84%] [G loss: 0.425691]\n",
      "epoch:4 step:4589 [D loss: 0.478351, acc.: 80.47%] [G loss: 0.542622]\n",
      "epoch:4 step:4590 [D loss: 0.485063, acc.: 75.78%] [G loss: 0.667271]\n",
      "epoch:4 step:4591 [D loss: 0.490505, acc.: 77.34%] [G loss: 0.670092]\n",
      "epoch:4 step:4592 [D loss: 0.536460, acc.: 75.00%] [G loss: 0.718429]\n",
      "epoch:4 step:4593 [D loss: 0.546012, acc.: 68.75%] [G loss: 0.582338]\n",
      "epoch:4 step:4594 [D loss: 0.517360, acc.: 71.88%] [G loss: 0.657094]\n",
      "epoch:4 step:4595 [D loss: 0.534026, acc.: 72.66%] [G loss: 0.416839]\n",
      "epoch:4 step:4596 [D loss: 0.485469, acc.: 76.56%] [G loss: 0.440076]\n",
      "epoch:4 step:4597 [D loss: 0.536274, acc.: 71.88%] [G loss: 0.500154]\n",
      "epoch:4 step:4598 [D loss: 0.568773, acc.: 67.19%] [G loss: 0.521715]\n",
      "epoch:4 step:4599 [D loss: 0.578771, acc.: 64.06%] [G loss: 0.586440]\n",
      "epoch:4 step:4600 [D loss: 0.478671, acc.: 80.47%] [G loss: 0.741402]\n",
      "epoch:4 step:4601 [D loss: 0.493823, acc.: 79.69%] [G loss: 0.683011]\n",
      "epoch:4 step:4602 [D loss: 0.449588, acc.: 79.69%] [G loss: 0.788656]\n",
      "epoch:4 step:4603 [D loss: 0.536949, acc.: 72.66%] [G loss: 0.794330]\n",
      "epoch:4 step:4604 [D loss: 0.551548, acc.: 71.88%] [G loss: 0.678297]\n",
      "epoch:4 step:4605 [D loss: 0.477149, acc.: 77.34%] [G loss: 0.598820]\n",
      "epoch:4 step:4606 [D loss: 0.683292, acc.: 62.50%] [G loss: 0.655145]\n",
      "epoch:4 step:4607 [D loss: 0.520941, acc.: 77.34%] [G loss: 0.727437]\n",
      "epoch:4 step:4608 [D loss: 0.445409, acc.: 79.69%] [G loss: 0.792921]\n",
      "epoch:4 step:4609 [D loss: 0.590344, acc.: 68.75%] [G loss: 0.540488]\n",
      "epoch:4 step:4610 [D loss: 0.539458, acc.: 72.66%] [G loss: 0.497201]\n",
      "epoch:4 step:4611 [D loss: 0.523949, acc.: 75.00%] [G loss: 0.453033]\n",
      "epoch:4 step:4612 [D loss: 0.485439, acc.: 73.44%] [G loss: 0.638500]\n",
      "epoch:4 step:4613 [D loss: 0.491026, acc.: 73.44%] [G loss: 0.719720]\n",
      "epoch:4 step:4614 [D loss: 0.557932, acc.: 70.31%] [G loss: 0.592808]\n",
      "epoch:4 step:4615 [D loss: 0.591647, acc.: 68.75%] [G loss: 0.556528]\n",
      "epoch:4 step:4616 [D loss: 0.493431, acc.: 74.22%] [G loss: 0.591344]\n",
      "epoch:4 step:4617 [D loss: 0.488942, acc.: 79.69%] [G loss: 0.648368]\n",
      "epoch:4 step:4618 [D loss: 0.483307, acc.: 78.91%] [G loss: 0.610252]\n",
      "epoch:4 step:4619 [D loss: 0.500800, acc.: 74.22%] [G loss: 0.739097]\n",
      "epoch:4 step:4620 [D loss: 0.511941, acc.: 80.47%] [G loss: 0.726359]\n",
      "epoch:4 step:4621 [D loss: 0.590725, acc.: 67.19%] [G loss: 0.757213]\n",
      "epoch:4 step:4622 [D loss: 0.507887, acc.: 76.56%] [G loss: 0.683872]\n",
      "epoch:4 step:4623 [D loss: 0.435792, acc.: 82.81%] [G loss: 0.835725]\n",
      "epoch:4 step:4624 [D loss: 0.555725, acc.: 72.66%] [G loss: 0.621139]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:4 step:4625 [D loss: 0.530160, acc.: 76.56%] [G loss: 0.460006]\n",
      "epoch:4 step:4626 [D loss: 0.569363, acc.: 70.31%] [G loss: 0.451410]\n",
      "epoch:4 step:4627 [D loss: 0.589958, acc.: 67.19%] [G loss: 0.539518]\n",
      "epoch:4 step:4628 [D loss: 0.591594, acc.: 67.97%] [G loss: 0.431044]\n",
      "epoch:4 step:4629 [D loss: 0.563903, acc.: 71.09%] [G loss: 0.511820]\n",
      "epoch:4 step:4630 [D loss: 0.552767, acc.: 74.22%] [G loss: 0.506652]\n",
      "epoch:4 step:4631 [D loss: 0.568277, acc.: 69.53%] [G loss: 0.561215]\n",
      "epoch:4 step:4632 [D loss: 0.453273, acc.: 78.12%] [G loss: 0.569983]\n",
      "epoch:4 step:4633 [D loss: 0.476774, acc.: 72.66%] [G loss: 0.740991]\n",
      "epoch:4 step:4634 [D loss: 0.435288, acc.: 81.25%] [G loss: 0.795153]\n",
      "epoch:4 step:4635 [D loss: 0.487993, acc.: 74.22%] [G loss: 0.811604]\n",
      "epoch:4 step:4636 [D loss: 0.489532, acc.: 76.56%] [G loss: 0.877811]\n",
      "epoch:4 step:4637 [D loss: 0.479034, acc.: 78.12%] [G loss: 0.695711]\n",
      "epoch:4 step:4638 [D loss: 0.412085, acc.: 79.69%] [G loss: 0.867006]\n",
      "epoch:4 step:4639 [D loss: 0.530242, acc.: 71.09%] [G loss: 0.727392]\n",
      "epoch:4 step:4640 [D loss: 0.640300, acc.: 64.84%] [G loss: 0.619455]\n",
      "epoch:4 step:4641 [D loss: 0.487188, acc.: 82.03%] [G loss: 0.581794]\n",
      "epoch:4 step:4642 [D loss: 0.472635, acc.: 80.47%] [G loss: 0.641135]\n",
      "epoch:4 step:4643 [D loss: 0.519477, acc.: 76.56%] [G loss: 0.661039]\n",
      "epoch:4 step:4644 [D loss: 0.542178, acc.: 67.97%] [G loss: 0.695475]\n",
      "epoch:4 step:4645 [D loss: 0.435423, acc.: 83.59%] [G loss: 0.793662]\n",
      "epoch:4 step:4646 [D loss: 0.427557, acc.: 81.25%] [G loss: 0.714900]\n",
      "epoch:4 step:4647 [D loss: 0.492682, acc.: 78.12%] [G loss: 0.786690]\n",
      "epoch:4 step:4648 [D loss: 0.515163, acc.: 75.78%] [G loss: 0.695032]\n",
      "epoch:4 step:4649 [D loss: 0.491690, acc.: 76.56%] [G loss: 0.700275]\n",
      "epoch:4 step:4650 [D loss: 0.516527, acc.: 71.09%] [G loss: 0.502358]\n",
      "epoch:4 step:4651 [D loss: 0.577861, acc.: 68.75%] [G loss: 0.550861]\n",
      "epoch:4 step:4652 [D loss: 0.484262, acc.: 72.66%] [G loss: 0.686656]\n",
      "epoch:4 step:4653 [D loss: 0.510225, acc.: 78.12%] [G loss: 0.760949]\n",
      "epoch:4 step:4654 [D loss: 0.493042, acc.: 76.56%] [G loss: 0.680485]\n",
      "epoch:4 step:4655 [D loss: 0.500156, acc.: 73.44%] [G loss: 0.705990]\n",
      "epoch:4 step:4656 [D loss: 0.471119, acc.: 78.12%] [G loss: 0.632650]\n",
      "epoch:4 step:4657 [D loss: 0.490989, acc.: 77.34%] [G loss: 0.754915]\n",
      "epoch:4 step:4658 [D loss: 0.387757, acc.: 84.38%] [G loss: 0.823317]\n",
      "epoch:4 step:4659 [D loss: 0.436707, acc.: 81.25%] [G loss: 0.871754]\n",
      "epoch:4 step:4660 [D loss: 0.488628, acc.: 81.25%] [G loss: 0.769400]\n",
      "epoch:4 step:4661 [D loss: 0.578906, acc.: 68.75%] [G loss: 0.776539]\n",
      "epoch:4 step:4662 [D loss: 0.428921, acc.: 82.81%] [G loss: 0.814329]\n",
      "epoch:4 step:4663 [D loss: 0.582299, acc.: 65.62%] [G loss: 0.574621]\n",
      "epoch:4 step:4664 [D loss: 0.511909, acc.: 75.00%] [G loss: 0.772262]\n",
      "epoch:4 step:4665 [D loss: 0.544071, acc.: 72.66%] [G loss: 0.627785]\n",
      "epoch:4 step:4666 [D loss: 0.437459, acc.: 86.72%] [G loss: 0.687947]\n",
      "epoch:4 step:4667 [D loss: 0.447869, acc.: 82.03%] [G loss: 0.797197]\n",
      "epoch:4 step:4668 [D loss: 0.631084, acc.: 66.41%] [G loss: 0.634276]\n",
      "epoch:4 step:4669 [D loss: 0.466920, acc.: 79.69%] [G loss: 0.783192]\n",
      "epoch:4 step:4670 [D loss: 0.512904, acc.: 73.44%] [G loss: 0.718438]\n",
      "epoch:4 step:4671 [D loss: 0.446285, acc.: 82.03%] [G loss: 0.784668]\n",
      "epoch:4 step:4672 [D loss: 0.438295, acc.: 75.00%] [G loss: 0.719472]\n",
      "epoch:4 step:4673 [D loss: 0.390988, acc.: 83.59%] [G loss: 0.943830]\n",
      "epoch:4 step:4674 [D loss: 0.405104, acc.: 83.59%] [G loss: 1.041628]\n",
      "epoch:4 step:4675 [D loss: 0.442767, acc.: 80.47%] [G loss: 1.177199]\n",
      "epoch:4 step:4676 [D loss: 0.708562, acc.: 64.84%] [G loss: 1.048458]\n",
      "epoch:4 step:4677 [D loss: 0.410979, acc.: 80.47%] [G loss: 1.230422]\n",
      "epoch:4 step:4678 [D loss: 0.465876, acc.: 74.22%] [G loss: 1.097305]\n",
      "epoch:4 step:4679 [D loss: 0.442932, acc.: 79.69%] [G loss: 0.869965]\n",
      "epoch:4 step:4680 [D loss: 0.551581, acc.: 71.88%] [G loss: 0.737078]\n",
      "epoch:4 step:4681 [D loss: 0.447026, acc.: 77.34%] [G loss: 0.754271]\n",
      "epoch:4 step:4682 [D loss: 0.510565, acc.: 77.34%] [G loss: 0.936979]\n",
      "epoch:4 step:4683 [D loss: 0.469296, acc.: 78.91%] [G loss: 0.939151]\n",
      "epoch:4 step:4684 [D loss: 0.394998, acc.: 82.03%] [G loss: 1.139181]\n",
      "epoch:4 step:4685 [D loss: 0.486937, acc.: 78.91%] [G loss: 1.292981]\n",
      "epoch:5 step:4686 [D loss: 0.552537, acc.: 75.00%] [G loss: 0.931180]\n",
      "epoch:5 step:4687 [D loss: 0.457326, acc.: 81.25%] [G loss: 0.749127]\n",
      "epoch:5 step:4688 [D loss: 0.566361, acc.: 75.78%] [G loss: 0.750894]\n",
      "epoch:5 step:4689 [D loss: 0.486521, acc.: 78.91%] [G loss: 0.675063]\n",
      "epoch:5 step:4690 [D loss: 0.498723, acc.: 78.12%] [G loss: 0.818579]\n",
      "epoch:5 step:4691 [D loss: 0.440300, acc.: 79.69%] [G loss: 0.899581]\n",
      "epoch:5 step:4692 [D loss: 0.501799, acc.: 74.22%] [G loss: 0.735371]\n",
      "epoch:5 step:4693 [D loss: 0.527775, acc.: 71.09%] [G loss: 0.661450]\n",
      "epoch:5 step:4694 [D loss: 0.525649, acc.: 72.66%] [G loss: 0.814545]\n",
      "epoch:5 step:4695 [D loss: 0.529428, acc.: 71.09%] [G loss: 0.630085]\n",
      "epoch:5 step:4696 [D loss: 0.476928, acc.: 77.34%] [G loss: 0.600767]\n",
      "epoch:5 step:4697 [D loss: 0.510775, acc.: 77.34%] [G loss: 0.770994]\n",
      "epoch:5 step:4698 [D loss: 0.478782, acc.: 78.12%] [G loss: 0.682512]\n",
      "epoch:5 step:4699 [D loss: 0.497501, acc.: 78.91%] [G loss: 0.548707]\n",
      "epoch:5 step:4700 [D loss: 0.432099, acc.: 85.16%] [G loss: 0.644148]\n",
      "epoch:5 step:4701 [D loss: 0.443165, acc.: 82.03%] [G loss: 0.804580]\n",
      "epoch:5 step:4702 [D loss: 0.518701, acc.: 75.00%] [G loss: 0.801084]\n",
      "epoch:5 step:4703 [D loss: 0.527068, acc.: 75.78%] [G loss: 0.672003]\n",
      "epoch:5 step:4704 [D loss: 0.525780, acc.: 70.31%] [G loss: 0.736061]\n",
      "epoch:5 step:4705 [D loss: 0.555853, acc.: 67.97%] [G loss: 0.664874]\n",
      "epoch:5 step:4706 [D loss: 0.557041, acc.: 75.00%] [G loss: 0.624371]\n",
      "epoch:5 step:4707 [D loss: 0.393762, acc.: 85.94%] [G loss: 0.950705]\n",
      "epoch:5 step:4708 [D loss: 0.505991, acc.: 73.44%] [G loss: 0.740036]\n",
      "epoch:5 step:4709 [D loss: 0.519841, acc.: 68.75%] [G loss: 0.776683]\n",
      "epoch:5 step:4710 [D loss: 0.543068, acc.: 75.78%] [G loss: 0.755533]\n",
      "epoch:5 step:4711 [D loss: 0.541837, acc.: 71.09%] [G loss: 0.632571]\n",
      "epoch:5 step:4712 [D loss: 0.425035, acc.: 81.25%] [G loss: 0.840658]\n",
      "epoch:5 step:4713 [D loss: 0.501636, acc.: 74.22%] [G loss: 0.759080]\n",
      "epoch:5 step:4714 [D loss: 0.469799, acc.: 77.34%] [G loss: 0.660802]\n",
      "epoch:5 step:4715 [D loss: 0.542782, acc.: 74.22%] [G loss: 0.660944]\n",
      "epoch:5 step:4716 [D loss: 0.543606, acc.: 71.09%] [G loss: 0.695841]\n",
      "epoch:5 step:4717 [D loss: 0.502348, acc.: 71.09%] [G loss: 0.629137]\n",
      "epoch:5 step:4718 [D loss: 0.501825, acc.: 78.12%] [G loss: 0.611850]\n",
      "epoch:5 step:4719 [D loss: 0.447760, acc.: 81.25%] [G loss: 0.761810]\n",
      "epoch:5 step:4720 [D loss: 0.463972, acc.: 76.56%] [G loss: 0.845338]\n",
      "epoch:5 step:4721 [D loss: 0.479469, acc.: 79.69%] [G loss: 0.794630]\n",
      "epoch:5 step:4722 [D loss: 0.422681, acc.: 85.94%] [G loss: 0.956704]\n",
      "epoch:5 step:4723 [D loss: 0.603929, acc.: 69.53%] [G loss: 0.635133]\n",
      "epoch:5 step:4724 [D loss: 0.518454, acc.: 76.56%] [G loss: 0.672601]\n",
      "epoch:5 step:4725 [D loss: 0.383464, acc.: 84.38%] [G loss: 1.004196]\n",
      "epoch:5 step:4726 [D loss: 0.555586, acc.: 69.53%] [G loss: 0.642400]\n",
      "epoch:5 step:4727 [D loss: 0.491629, acc.: 78.12%] [G loss: 0.658387]\n",
      "epoch:5 step:4728 [D loss: 0.513388, acc.: 74.22%] [G loss: 0.600745]\n",
      "epoch:5 step:4729 [D loss: 0.594965, acc.: 65.62%] [G loss: 0.647644]\n",
      "epoch:5 step:4730 [D loss: 0.484551, acc.: 78.12%] [G loss: 0.573540]\n",
      "epoch:5 step:4731 [D loss: 0.482043, acc.: 78.12%] [G loss: 0.664141]\n",
      "epoch:5 step:4732 [D loss: 0.492592, acc.: 75.00%] [G loss: 0.842941]\n",
      "epoch:5 step:4733 [D loss: 0.503221, acc.: 75.78%] [G loss: 0.657771]\n",
      "epoch:5 step:4734 [D loss: 0.482890, acc.: 78.91%] [G loss: 0.666192]\n",
      "epoch:5 step:4735 [D loss: 0.494619, acc.: 80.47%] [G loss: 0.656129]\n",
      "epoch:5 step:4736 [D loss: 0.573670, acc.: 63.28%] [G loss: 0.533297]\n",
      "epoch:5 step:4737 [D loss: 0.521583, acc.: 72.66%] [G loss: 0.591518]\n",
      "epoch:5 step:4738 [D loss: 0.454335, acc.: 81.25%] [G loss: 0.628861]\n",
      "epoch:5 step:4739 [D loss: 0.492311, acc.: 75.00%] [G loss: 0.839580]\n",
      "epoch:5 step:4740 [D loss: 0.492260, acc.: 75.78%] [G loss: 0.695510]\n",
      "epoch:5 step:4741 [D loss: 0.437008, acc.: 83.59%] [G loss: 0.754884]\n",
      "epoch:5 step:4742 [D loss: 0.561560, acc.: 65.62%] [G loss: 0.671243]\n",
      "epoch:5 step:4743 [D loss: 0.471774, acc.: 79.69%] [G loss: 0.811020]\n",
      "epoch:5 step:4744 [D loss: 0.438461, acc.: 80.47%] [G loss: 0.881066]\n",
      "epoch:5 step:4745 [D loss: 0.559305, acc.: 67.97%] [G loss: 0.725759]\n",
      "epoch:5 step:4746 [D loss: 0.552221, acc.: 72.66%] [G loss: 0.575565]\n",
      "epoch:5 step:4747 [D loss: 0.586606, acc.: 68.75%] [G loss: 0.572991]\n",
      "epoch:5 step:4748 [D loss: 0.539279, acc.: 73.44%] [G loss: 0.666546]\n",
      "epoch:5 step:4749 [D loss: 0.531500, acc.: 71.88%] [G loss: 0.641024]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:5 step:4750 [D loss: 0.481208, acc.: 78.12%] [G loss: 0.569914]\n",
      "epoch:5 step:4751 [D loss: 0.479667, acc.: 81.25%] [G loss: 0.638983]\n",
      "epoch:5 step:4752 [D loss: 0.537562, acc.: 72.66%] [G loss: 0.579495]\n",
      "epoch:5 step:4753 [D loss: 0.484858, acc.: 73.44%] [G loss: 0.584464]\n",
      "epoch:5 step:4754 [D loss: 0.503599, acc.: 78.91%] [G loss: 0.710409]\n",
      "epoch:5 step:4755 [D loss: 0.534615, acc.: 74.22%] [G loss: 0.717661]\n",
      "epoch:5 step:4756 [D loss: 0.554909, acc.: 71.09%] [G loss: 0.515134]\n",
      "epoch:5 step:4757 [D loss: 0.479751, acc.: 80.47%] [G loss: 0.686838]\n",
      "epoch:5 step:4758 [D loss: 0.497161, acc.: 74.22%] [G loss: 0.824431]\n",
      "epoch:5 step:4759 [D loss: 0.428920, acc.: 84.38%] [G loss: 0.755659]\n",
      "epoch:5 step:4760 [D loss: 0.533988, acc.: 75.78%] [G loss: 0.740551]\n",
      "epoch:5 step:4761 [D loss: 0.498245, acc.: 76.56%] [G loss: 0.719173]\n",
      "epoch:5 step:4762 [D loss: 0.432415, acc.: 78.12%] [G loss: 0.873237]\n",
      "epoch:5 step:4763 [D loss: 0.584618, acc.: 68.75%] [G loss: 0.565031]\n",
      "epoch:5 step:4764 [D loss: 0.488965, acc.: 77.34%] [G loss: 0.597369]\n",
      "epoch:5 step:4765 [D loss: 0.485197, acc.: 75.00%] [G loss: 0.563005]\n",
      "epoch:5 step:4766 [D loss: 0.541816, acc.: 72.66%] [G loss: 0.503351]\n",
      "epoch:5 step:4767 [D loss: 0.491148, acc.: 75.00%] [G loss: 0.689444]\n",
      "epoch:5 step:4768 [D loss: 0.495902, acc.: 74.22%] [G loss: 0.756776]\n",
      "epoch:5 step:4769 [D loss: 0.522887, acc.: 73.44%] [G loss: 0.771653]\n",
      "epoch:5 step:4770 [D loss: 0.523780, acc.: 74.22%] [G loss: 0.601654]\n",
      "epoch:5 step:4771 [D loss: 0.529934, acc.: 77.34%] [G loss: 0.470635]\n",
      "epoch:5 step:4772 [D loss: 0.466090, acc.: 78.91%] [G loss: 0.616121]\n",
      "epoch:5 step:4773 [D loss: 0.460232, acc.: 82.03%] [G loss: 0.583234]\n",
      "epoch:5 step:4774 [D loss: 0.446529, acc.: 81.25%] [G loss: 0.760004]\n",
      "epoch:5 step:4775 [D loss: 0.508017, acc.: 74.22%] [G loss: 0.640687]\n",
      "epoch:5 step:4776 [D loss: 0.505868, acc.: 76.56%] [G loss: 0.760500]\n",
      "epoch:5 step:4777 [D loss: 0.484739, acc.: 78.12%] [G loss: 0.985498]\n",
      "epoch:5 step:4778 [D loss: 0.507490, acc.: 75.78%] [G loss: 0.705810]\n",
      "epoch:5 step:4779 [D loss: 0.474914, acc.: 77.34%] [G loss: 0.893164]\n",
      "epoch:5 step:4780 [D loss: 0.554175, acc.: 67.97%] [G loss: 0.728596]\n",
      "epoch:5 step:4781 [D loss: 0.439563, acc.: 84.38%] [G loss: 0.769247]\n",
      "epoch:5 step:4782 [D loss: 0.542277, acc.: 72.66%] [G loss: 0.687442]\n",
      "epoch:5 step:4783 [D loss: 0.490219, acc.: 77.34%] [G loss: 0.670589]\n",
      "epoch:5 step:4784 [D loss: 0.529154, acc.: 70.31%] [G loss: 0.748686]\n",
      "epoch:5 step:4785 [D loss: 0.463533, acc.: 76.56%] [G loss: 0.542318]\n",
      "epoch:5 step:4786 [D loss: 0.425054, acc.: 86.72%] [G loss: 0.758750]\n",
      "epoch:5 step:4787 [D loss: 0.554479, acc.: 72.66%] [G loss: 0.527189]\n",
      "epoch:5 step:4788 [D loss: 0.477635, acc.: 76.56%] [G loss: 0.592594]\n",
      "epoch:5 step:4789 [D loss: 0.507656, acc.: 72.66%] [G loss: 0.537332]\n",
      "epoch:5 step:4790 [D loss: 0.567960, acc.: 63.28%] [G loss: 0.583835]\n",
      "epoch:5 step:4791 [D loss: 0.523954, acc.: 75.00%] [G loss: 0.609571]\n",
      "epoch:5 step:4792 [D loss: 0.571419, acc.: 73.44%] [G loss: 0.631193]\n",
      "epoch:5 step:4793 [D loss: 0.547415, acc.: 71.09%] [G loss: 0.707379]\n",
      "epoch:5 step:4794 [D loss: 0.564902, acc.: 68.75%] [G loss: 0.620689]\n",
      "epoch:5 step:4795 [D loss: 0.548632, acc.: 69.53%] [G loss: 0.594599]\n",
      "epoch:5 step:4796 [D loss: 0.508290, acc.: 72.66%] [G loss: 0.652504]\n",
      "epoch:5 step:4797 [D loss: 0.533838, acc.: 75.78%] [G loss: 0.686309]\n",
      "epoch:5 step:4798 [D loss: 0.553710, acc.: 67.97%] [G loss: 0.659710]\n",
      "epoch:5 step:4799 [D loss: 0.566783, acc.: 71.09%] [G loss: 0.579485]\n",
      "epoch:5 step:4800 [D loss: 0.543231, acc.: 74.22%] [G loss: 0.638113]\n",
      "epoch:5 step:4801 [D loss: 0.514650, acc.: 74.22%] [G loss: 0.726006]\n",
      "epoch:5 step:4802 [D loss: 0.487757, acc.: 74.22%] [G loss: 0.704240]\n",
      "epoch:5 step:4803 [D loss: 0.495188, acc.: 78.91%] [G loss: 0.786830]\n",
      "epoch:5 step:4804 [D loss: 0.459465, acc.: 81.25%] [G loss: 0.834889]\n",
      "epoch:5 step:4805 [D loss: 0.685909, acc.: 59.38%] [G loss: 0.707560]\n",
      "epoch:5 step:4806 [D loss: 0.542512, acc.: 71.09%] [G loss: 0.659471]\n",
      "epoch:5 step:4807 [D loss: 0.512180, acc.: 75.00%] [G loss: 0.761791]\n",
      "epoch:5 step:4808 [D loss: 0.545931, acc.: 71.88%] [G loss: 0.599384]\n",
      "epoch:5 step:4809 [D loss: 0.530293, acc.: 71.09%] [G loss: 0.590248]\n",
      "epoch:5 step:4810 [D loss: 0.526072, acc.: 75.78%] [G loss: 0.622957]\n",
      "epoch:5 step:4811 [D loss: 0.469984, acc.: 80.47%] [G loss: 0.573512]\n",
      "epoch:5 step:4812 [D loss: 0.474567, acc.: 78.91%] [G loss: 0.458957]\n",
      "epoch:5 step:4813 [D loss: 0.459474, acc.: 80.47%] [G loss: 0.547563]\n",
      "epoch:5 step:4814 [D loss: 0.622165, acc.: 71.88%] [G loss: 0.530639]\n",
      "epoch:5 step:4815 [D loss: 0.540935, acc.: 71.88%] [G loss: 0.556720]\n",
      "epoch:5 step:4816 [D loss: 0.511515, acc.: 78.91%] [G loss: 0.686131]\n",
      "epoch:5 step:4817 [D loss: 0.564050, acc.: 63.28%] [G loss: 0.638533]\n",
      "epoch:5 step:4818 [D loss: 0.524734, acc.: 71.88%] [G loss: 0.695845]\n",
      "epoch:5 step:4819 [D loss: 0.498227, acc.: 71.88%] [G loss: 0.701225]\n",
      "epoch:5 step:4820 [D loss: 0.487724, acc.: 76.56%] [G loss: 0.695626]\n",
      "epoch:5 step:4821 [D loss: 0.488685, acc.: 75.78%] [G loss: 0.711737]\n",
      "epoch:5 step:4822 [D loss: 0.554737, acc.: 69.53%] [G loss: 0.595073]\n",
      "epoch:5 step:4823 [D loss: 0.543312, acc.: 71.88%] [G loss: 0.597502]\n",
      "epoch:5 step:4824 [D loss: 0.646548, acc.: 59.38%] [G loss: 0.547754]\n",
      "epoch:5 step:4825 [D loss: 0.506076, acc.: 67.19%] [G loss: 0.672016]\n",
      "epoch:5 step:4826 [D loss: 0.465387, acc.: 78.12%] [G loss: 0.544829]\n",
      "epoch:5 step:4827 [D loss: 0.511237, acc.: 73.44%] [G loss: 0.667768]\n",
      "epoch:5 step:4828 [D loss: 0.596948, acc.: 61.72%] [G loss: 0.530513]\n",
      "epoch:5 step:4829 [D loss: 0.477687, acc.: 75.78%] [G loss: 0.540040]\n",
      "epoch:5 step:4830 [D loss: 0.509819, acc.: 73.44%] [G loss: 0.709361]\n",
      "epoch:5 step:4831 [D loss: 0.518406, acc.: 72.66%] [G loss: 0.701830]\n",
      "epoch:5 step:4832 [D loss: 0.546656, acc.: 71.88%] [G loss: 0.530535]\n",
      "epoch:5 step:4833 [D loss: 0.495450, acc.: 78.91%] [G loss: 0.663294]\n",
      "epoch:5 step:4834 [D loss: 0.523310, acc.: 71.09%] [G loss: 0.681441]\n",
      "epoch:5 step:4835 [D loss: 0.559884, acc.: 72.66%] [G loss: 0.706660]\n",
      "epoch:5 step:4836 [D loss: 0.542906, acc.: 70.31%] [G loss: 0.603315]\n",
      "epoch:5 step:4837 [D loss: 0.466668, acc.: 77.34%] [G loss: 0.754401]\n",
      "epoch:5 step:4838 [D loss: 0.542239, acc.: 71.09%] [G loss: 0.555225]\n",
      "epoch:5 step:4839 [D loss: 0.513565, acc.: 75.00%] [G loss: 0.631974]\n",
      "epoch:5 step:4840 [D loss: 0.389502, acc.: 85.16%] [G loss: 0.738709]\n",
      "epoch:5 step:4841 [D loss: 0.522360, acc.: 76.56%] [G loss: 0.732706]\n",
      "epoch:5 step:4842 [D loss: 0.585107, acc.: 71.09%] [G loss: 0.723519]\n",
      "epoch:5 step:4843 [D loss: 0.549237, acc.: 74.22%] [G loss: 0.536687]\n",
      "epoch:5 step:4844 [D loss: 0.525197, acc.: 67.97%] [G loss: 0.594883]\n",
      "epoch:5 step:4845 [D loss: 0.526726, acc.: 72.66%] [G loss: 0.600550]\n",
      "epoch:5 step:4846 [D loss: 0.490836, acc.: 76.56%] [G loss: 0.558638]\n",
      "epoch:5 step:4847 [D loss: 0.465614, acc.: 78.91%] [G loss: 0.607615]\n",
      "epoch:5 step:4848 [D loss: 0.502937, acc.: 73.44%] [G loss: 0.695285]\n",
      "epoch:5 step:4849 [D loss: 0.521565, acc.: 69.53%] [G loss: 0.769280]\n",
      "epoch:5 step:4850 [D loss: 0.571167, acc.: 71.88%] [G loss: 0.645163]\n",
      "epoch:5 step:4851 [D loss: 0.502389, acc.: 72.66%] [G loss: 0.603981]\n",
      "epoch:5 step:4852 [D loss: 0.492364, acc.: 78.12%] [G loss: 0.567551]\n",
      "epoch:5 step:4853 [D loss: 0.540477, acc.: 72.66%] [G loss: 0.587945]\n",
      "epoch:5 step:4854 [D loss: 0.595708, acc.: 67.19%] [G loss: 0.603861]\n",
      "epoch:5 step:4855 [D loss: 0.465954, acc.: 78.12%] [G loss: 0.612635]\n",
      "epoch:5 step:4856 [D loss: 0.517467, acc.: 70.31%] [G loss: 0.431182]\n",
      "epoch:5 step:4857 [D loss: 0.541312, acc.: 70.31%] [G loss: 0.448526]\n",
      "epoch:5 step:4858 [D loss: 0.484604, acc.: 80.47%] [G loss: 0.605549]\n",
      "epoch:5 step:4859 [D loss: 0.575930, acc.: 70.31%] [G loss: 0.517225]\n",
      "epoch:5 step:4860 [D loss: 0.521177, acc.: 77.34%] [G loss: 0.695058]\n",
      "epoch:5 step:4861 [D loss: 0.502888, acc.: 77.34%] [G loss: 0.825892]\n",
      "epoch:5 step:4862 [D loss: 0.477544, acc.: 79.69%] [G loss: 0.722897]\n",
      "epoch:5 step:4863 [D loss: 0.607035, acc.: 63.28%] [G loss: 0.488567]\n",
      "epoch:5 step:4864 [D loss: 0.502832, acc.: 76.56%] [G loss: 0.542969]\n",
      "epoch:5 step:4865 [D loss: 0.539838, acc.: 71.88%] [G loss: 0.463950]\n",
      "epoch:5 step:4866 [D loss: 0.513441, acc.: 74.22%] [G loss: 0.560528]\n",
      "epoch:5 step:4867 [D loss: 0.549879, acc.: 73.44%] [G loss: 0.528757]\n",
      "epoch:5 step:4868 [D loss: 0.559892, acc.: 70.31%] [G loss: 0.519251]\n",
      "epoch:5 step:4869 [D loss: 0.539963, acc.: 71.09%] [G loss: 0.612881]\n",
      "epoch:5 step:4870 [D loss: 0.561212, acc.: 67.97%] [G loss: 0.602429]\n",
      "epoch:5 step:4871 [D loss: 0.514797, acc.: 77.34%] [G loss: 0.677668]\n",
      "epoch:5 step:4872 [D loss: 0.595225, acc.: 71.09%] [G loss: 0.647055]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:5 step:4873 [D loss: 0.556305, acc.: 68.75%] [G loss: 0.531098]\n",
      "epoch:5 step:4874 [D loss: 0.564098, acc.: 68.75%] [G loss: 0.509374]\n",
      "epoch:5 step:4875 [D loss: 0.477232, acc.: 77.34%] [G loss: 0.636140]\n",
      "epoch:5 step:4876 [D loss: 0.516702, acc.: 73.44%] [G loss: 0.597599]\n",
      "epoch:5 step:4877 [D loss: 0.534788, acc.: 73.44%] [G loss: 0.652768]\n",
      "epoch:5 step:4878 [D loss: 0.514243, acc.: 77.34%] [G loss: 0.678243]\n",
      "epoch:5 step:4879 [D loss: 0.457085, acc.: 80.47%] [G loss: 0.724628]\n",
      "epoch:5 step:4880 [D loss: 0.546500, acc.: 72.66%] [G loss: 0.587027]\n",
      "epoch:5 step:4881 [D loss: 0.524198, acc.: 72.66%] [G loss: 0.590238]\n",
      "epoch:5 step:4882 [D loss: 0.521850, acc.: 72.66%] [G loss: 0.601547]\n",
      "epoch:5 step:4883 [D loss: 0.430068, acc.: 82.81%] [G loss: 0.596344]\n",
      "epoch:5 step:4884 [D loss: 0.517299, acc.: 74.22%] [G loss: 0.588918]\n",
      "epoch:5 step:4885 [D loss: 0.603639, acc.: 67.97%] [G loss: 0.439576]\n",
      "epoch:5 step:4886 [D loss: 0.552601, acc.: 72.66%] [G loss: 0.477157]\n",
      "epoch:5 step:4887 [D loss: 0.512822, acc.: 76.56%] [G loss: 0.518456]\n",
      "epoch:5 step:4888 [D loss: 0.566163, acc.: 72.66%] [G loss: 0.515854]\n",
      "epoch:5 step:4889 [D loss: 0.523411, acc.: 74.22%] [G loss: 0.527129]\n",
      "epoch:5 step:4890 [D loss: 0.540509, acc.: 75.00%] [G loss: 0.606499]\n",
      "epoch:5 step:4891 [D loss: 0.509306, acc.: 75.78%] [G loss: 0.675454]\n",
      "epoch:5 step:4892 [D loss: 0.437817, acc.: 77.34%] [G loss: 0.763091]\n",
      "epoch:5 step:4893 [D loss: 0.434667, acc.: 82.03%] [G loss: 0.801962]\n",
      "epoch:5 step:4894 [D loss: 0.507567, acc.: 76.56%] [G loss: 0.833951]\n",
      "epoch:5 step:4895 [D loss: 0.596302, acc.: 67.19%] [G loss: 0.571663]\n",
      "epoch:5 step:4896 [D loss: 0.581249, acc.: 67.97%] [G loss: 0.447651]\n",
      "epoch:5 step:4897 [D loss: 0.496986, acc.: 76.56%] [G loss: 0.495493]\n",
      "epoch:5 step:4898 [D loss: 0.462534, acc.: 77.34%] [G loss: 0.630898]\n",
      "epoch:5 step:4899 [D loss: 0.618428, acc.: 64.06%] [G loss: 0.467420]\n",
      "epoch:5 step:4900 [D loss: 0.553215, acc.: 69.53%] [G loss: 0.560837]\n",
      "epoch:5 step:4901 [D loss: 0.527502, acc.: 74.22%] [G loss: 0.528788]\n",
      "epoch:5 step:4902 [D loss: 0.473029, acc.: 82.81%] [G loss: 0.534347]\n",
      "epoch:5 step:4903 [D loss: 0.520433, acc.: 75.00%] [G loss: 0.654271]\n",
      "epoch:5 step:4904 [D loss: 0.483159, acc.: 78.91%] [G loss: 0.609861]\n",
      "epoch:5 step:4905 [D loss: 0.643315, acc.: 64.06%] [G loss: 0.554563]\n",
      "epoch:5 step:4906 [D loss: 0.491288, acc.: 78.12%] [G loss: 0.748002]\n",
      "epoch:5 step:4907 [D loss: 0.486958, acc.: 78.12%] [G loss: 0.713363]\n",
      "epoch:5 step:4908 [D loss: 0.490316, acc.: 77.34%] [G loss: 0.708643]\n",
      "epoch:5 step:4909 [D loss: 0.582371, acc.: 75.78%] [G loss: 0.522038]\n",
      "epoch:5 step:4910 [D loss: 0.531009, acc.: 73.44%] [G loss: 0.633110]\n",
      "epoch:5 step:4911 [D loss: 0.517708, acc.: 72.66%] [G loss: 0.520736]\n",
      "epoch:5 step:4912 [D loss: 0.562145, acc.: 74.22%] [G loss: 0.468500]\n",
      "epoch:5 step:4913 [D loss: 0.543958, acc.: 73.44%] [G loss: 0.450303]\n",
      "epoch:5 step:4914 [D loss: 0.552902, acc.: 69.53%] [G loss: 0.579318]\n",
      "epoch:5 step:4915 [D loss: 0.507794, acc.: 75.00%] [G loss: 0.707800]\n",
      "epoch:5 step:4916 [D loss: 0.434979, acc.: 78.91%] [G loss: 0.880111]\n",
      "epoch:5 step:4917 [D loss: 0.456334, acc.: 75.78%] [G loss: 0.923149]\n",
      "epoch:5 step:4918 [D loss: 0.623970, acc.: 66.41%] [G loss: 0.681432]\n",
      "epoch:5 step:4919 [D loss: 0.580331, acc.: 65.62%] [G loss: 0.636142]\n",
      "epoch:5 step:4920 [D loss: 0.500998, acc.: 74.22%] [G loss: 0.723241]\n",
      "epoch:5 step:4921 [D loss: 0.513071, acc.: 77.34%] [G loss: 0.496560]\n",
      "epoch:5 step:4922 [D loss: 0.496814, acc.: 77.34%] [G loss: 0.535494]\n",
      "epoch:5 step:4923 [D loss: 0.484946, acc.: 75.00%] [G loss: 0.665644]\n",
      "epoch:5 step:4924 [D loss: 0.492527, acc.: 79.69%] [G loss: 0.442834]\n",
      "epoch:5 step:4925 [D loss: 0.471670, acc.: 78.12%] [G loss: 0.556432]\n",
      "epoch:5 step:4926 [D loss: 0.562061, acc.: 63.28%] [G loss: 0.481993]\n",
      "epoch:5 step:4927 [D loss: 0.547773, acc.: 68.75%] [G loss: 0.614162]\n",
      "epoch:5 step:4928 [D loss: 0.569530, acc.: 71.09%] [G loss: 0.485324]\n",
      "epoch:5 step:4929 [D loss: 0.503039, acc.: 73.44%] [G loss: 0.507304]\n",
      "epoch:5 step:4930 [D loss: 0.426051, acc.: 83.59%] [G loss: 0.646117]\n",
      "epoch:5 step:4931 [D loss: 0.553289, acc.: 70.31%] [G loss: 0.521889]\n",
      "epoch:5 step:4932 [D loss: 0.618569, acc.: 65.62%] [G loss: 0.747659]\n",
      "epoch:5 step:4933 [D loss: 0.520397, acc.: 74.22%] [G loss: 0.741379]\n",
      "epoch:5 step:4934 [D loss: 0.520139, acc.: 76.56%] [G loss: 0.661827]\n",
      "epoch:5 step:4935 [D loss: 0.566926, acc.: 67.19%] [G loss: 0.461546]\n",
      "epoch:5 step:4936 [D loss: 0.544230, acc.: 70.31%] [G loss: 0.610941]\n",
      "epoch:5 step:4937 [D loss: 0.535304, acc.: 74.22%] [G loss: 0.608348]\n",
      "epoch:5 step:4938 [D loss: 0.479993, acc.: 78.91%] [G loss: 0.588341]\n",
      "epoch:5 step:4939 [D loss: 0.511893, acc.: 74.22%] [G loss: 0.502010]\n",
      "epoch:5 step:4940 [D loss: 0.513336, acc.: 72.66%] [G loss: 0.584120]\n",
      "epoch:5 step:4941 [D loss: 0.469585, acc.: 77.34%] [G loss: 0.638783]\n",
      "epoch:5 step:4942 [D loss: 0.535974, acc.: 70.31%] [G loss: 0.551218]\n",
      "epoch:5 step:4943 [D loss: 0.472423, acc.: 78.91%] [G loss: 0.763505]\n",
      "epoch:5 step:4944 [D loss: 0.485447, acc.: 76.56%] [G loss: 0.696597]\n",
      "epoch:5 step:4945 [D loss: 0.552810, acc.: 71.09%] [G loss: 0.647983]\n",
      "epoch:5 step:4946 [D loss: 0.496554, acc.: 74.22%] [G loss: 0.667185]\n",
      "epoch:5 step:4947 [D loss: 0.534952, acc.: 69.53%] [G loss: 0.591385]\n",
      "epoch:5 step:4948 [D loss: 0.639711, acc.: 66.41%] [G loss: 0.558632]\n",
      "epoch:5 step:4949 [D loss: 0.502949, acc.: 75.00%] [G loss: 0.592629]\n",
      "epoch:5 step:4950 [D loss: 0.580379, acc.: 65.62%] [G loss: 0.507545]\n",
      "epoch:5 step:4951 [D loss: 0.507927, acc.: 73.44%] [G loss: 0.679706]\n",
      "epoch:5 step:4952 [D loss: 0.537839, acc.: 73.44%] [G loss: 0.605308]\n",
      "epoch:5 step:4953 [D loss: 0.540682, acc.: 72.66%] [G loss: 0.504820]\n",
      "epoch:5 step:4954 [D loss: 0.514230, acc.: 72.66%] [G loss: 0.700729]\n",
      "epoch:5 step:4955 [D loss: 0.465221, acc.: 78.12%] [G loss: 0.621427]\n",
      "epoch:5 step:4956 [D loss: 0.475488, acc.: 76.56%] [G loss: 0.776762]\n",
      "epoch:5 step:4957 [D loss: 0.563488, acc.: 70.31%] [G loss: 0.658327]\n",
      "epoch:5 step:4958 [D loss: 0.487727, acc.: 74.22%] [G loss: 0.704257]\n",
      "epoch:5 step:4959 [D loss: 0.551123, acc.: 73.44%] [G loss: 0.548375]\n",
      "epoch:5 step:4960 [D loss: 0.576746, acc.: 71.88%] [G loss: 0.498502]\n",
      "epoch:5 step:4961 [D loss: 0.463122, acc.: 78.12%] [G loss: 0.773099]\n",
      "epoch:5 step:4962 [D loss: 0.584757, acc.: 67.97%] [G loss: 0.499500]\n",
      "epoch:5 step:4963 [D loss: 0.541005, acc.: 73.44%] [G loss: 0.666930]\n",
      "epoch:5 step:4964 [D loss: 0.464686, acc.: 81.25%] [G loss: 0.645844]\n",
      "epoch:5 step:4965 [D loss: 0.551970, acc.: 72.66%] [G loss: 0.639540]\n",
      "epoch:5 step:4966 [D loss: 0.603982, acc.: 71.09%] [G loss: 0.577123]\n",
      "epoch:5 step:4967 [D loss: 0.553729, acc.: 69.53%] [G loss: 0.524841]\n",
      "epoch:5 step:4968 [D loss: 0.437894, acc.: 85.16%] [G loss: 0.609688]\n",
      "epoch:5 step:4969 [D loss: 0.475002, acc.: 78.12%] [G loss: 0.630903]\n",
      "epoch:5 step:4970 [D loss: 0.487061, acc.: 75.78%] [G loss: 0.668887]\n",
      "epoch:5 step:4971 [D loss: 0.422811, acc.: 82.03%] [G loss: 0.697319]\n",
      "epoch:5 step:4972 [D loss: 0.551767, acc.: 68.75%] [G loss: 0.684178]\n",
      "epoch:5 step:4973 [D loss: 0.550492, acc.: 67.97%] [G loss: 0.494509]\n",
      "epoch:5 step:4974 [D loss: 0.534620, acc.: 73.44%] [G loss: 0.551293]\n",
      "epoch:5 step:4975 [D loss: 0.505006, acc.: 73.44%] [G loss: 0.645241]\n",
      "epoch:5 step:4976 [D loss: 0.500139, acc.: 78.12%] [G loss: 0.605498]\n",
      "epoch:5 step:4977 [D loss: 0.528196, acc.: 75.00%] [G loss: 0.651709]\n",
      "epoch:5 step:4978 [D loss: 0.493671, acc.: 74.22%] [G loss: 0.630373]\n",
      "epoch:5 step:4979 [D loss: 0.599172, acc.: 67.19%] [G loss: 0.521894]\n",
      "epoch:5 step:4980 [D loss: 0.557821, acc.: 67.19%] [G loss: 0.468765]\n",
      "epoch:5 step:4981 [D loss: 0.456066, acc.: 80.47%] [G loss: 0.681198]\n",
      "epoch:5 step:4982 [D loss: 0.524718, acc.: 77.34%] [G loss: 0.578240]\n",
      "epoch:5 step:4983 [D loss: 0.556646, acc.: 68.75%] [G loss: 0.632199]\n",
      "epoch:5 step:4984 [D loss: 0.491905, acc.: 73.44%] [G loss: 0.663029]\n",
      "epoch:5 step:4985 [D loss: 0.478523, acc.: 77.34%] [G loss: 0.650645]\n",
      "epoch:5 step:4986 [D loss: 0.591878, acc.: 71.88%] [G loss: 0.638943]\n",
      "epoch:5 step:4987 [D loss: 0.520063, acc.: 71.09%] [G loss: 0.582599]\n",
      "epoch:5 step:4988 [D loss: 0.505335, acc.: 74.22%] [G loss: 0.655277]\n",
      "epoch:5 step:4989 [D loss: 0.525381, acc.: 71.88%] [G loss: 0.616383]\n",
      "epoch:5 step:4990 [D loss: 0.482322, acc.: 74.22%] [G loss: 0.629516]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:5 step:4991 [D loss: 0.534726, acc.: 72.66%] [G loss: 0.638621]\n",
      "epoch:5 step:4992 [D loss: 0.489072, acc.: 75.78%] [G loss: 0.584173]\n",
      "epoch:5 step:4993 [D loss: 0.521692, acc.: 73.44%] [G loss: 0.658727]\n",
      "epoch:5 step:4994 [D loss: 0.471135, acc.: 76.56%] [G loss: 0.598252]\n",
      "epoch:5 step:4995 [D loss: 0.528002, acc.: 75.00%] [G loss: 0.644668]\n",
      "epoch:5 step:4996 [D loss: 0.453240, acc.: 80.47%] [G loss: 0.726118]\n",
      "epoch:5 step:4997 [D loss: 0.415055, acc.: 81.25%] [G loss: 0.917436]\n",
      "epoch:5 step:4998 [D loss: 0.504971, acc.: 72.66%] [G loss: 0.809562]\n",
      "epoch:5 step:4999 [D loss: 0.400365, acc.: 82.81%] [G loss: 1.053550]\n",
      "epoch:5 step:5000 [D loss: 0.427028, acc.: 81.25%] [G loss: 1.012398]\n",
      "epoch:5 step:5001 [D loss: 0.646314, acc.: 66.41%] [G loss: 0.668940]\n",
      "epoch:5 step:5002 [D loss: 0.542376, acc.: 71.09%] [G loss: 0.574293]\n",
      "epoch:5 step:5003 [D loss: 0.502163, acc.: 77.34%] [G loss: 0.577127]\n",
      "epoch:5 step:5004 [D loss: 0.525369, acc.: 74.22%] [G loss: 0.631881]\n",
      "epoch:5 step:5005 [D loss: 0.521399, acc.: 75.00%] [G loss: 0.604643]\n",
      "epoch:5 step:5006 [D loss: 0.492290, acc.: 74.22%] [G loss: 0.744080]\n",
      "epoch:5 step:5007 [D loss: 0.556250, acc.: 67.97%] [G loss: 0.636571]\n",
      "epoch:5 step:5008 [D loss: 0.588400, acc.: 68.75%] [G loss: 0.509584]\n",
      "epoch:5 step:5009 [D loss: 0.580378, acc.: 64.06%] [G loss: 0.413668]\n",
      "epoch:5 step:5010 [D loss: 0.475475, acc.: 81.25%] [G loss: 0.601975]\n",
      "epoch:5 step:5011 [D loss: 0.512616, acc.: 76.56%] [G loss: 0.713399]\n",
      "epoch:5 step:5012 [D loss: 0.503541, acc.: 76.56%] [G loss: 0.657389]\n",
      "epoch:5 step:5013 [D loss: 0.513754, acc.: 73.44%] [G loss: 0.671869]\n",
      "epoch:5 step:5014 [D loss: 0.533034, acc.: 72.66%] [G loss: 0.548774]\n",
      "epoch:5 step:5015 [D loss: 0.509086, acc.: 70.31%] [G loss: 0.601989]\n",
      "epoch:5 step:5016 [D loss: 0.501490, acc.: 77.34%] [G loss: 0.564269]\n",
      "epoch:5 step:5017 [D loss: 0.454820, acc.: 79.69%] [G loss: 0.611713]\n",
      "epoch:5 step:5018 [D loss: 0.471014, acc.: 75.78%] [G loss: 0.637393]\n",
      "epoch:5 step:5019 [D loss: 0.508872, acc.: 75.00%] [G loss: 0.660248]\n",
      "epoch:5 step:5020 [D loss: 0.443101, acc.: 80.47%] [G loss: 0.737241]\n",
      "epoch:5 step:5021 [D loss: 0.483609, acc.: 75.78%] [G loss: 0.860220]\n",
      "epoch:5 step:5022 [D loss: 0.519183, acc.: 70.31%] [G loss: 0.634335]\n",
      "epoch:5 step:5023 [D loss: 0.478106, acc.: 76.56%] [G loss: 0.676545]\n",
      "epoch:5 step:5024 [D loss: 0.466246, acc.: 79.69%] [G loss: 0.719085]\n",
      "epoch:5 step:5025 [D loss: 0.444110, acc.: 76.56%] [G loss: 0.877556]\n",
      "epoch:5 step:5026 [D loss: 0.606046, acc.: 63.28%] [G loss: 0.662377]\n",
      "epoch:5 step:5027 [D loss: 0.565340, acc.: 67.97%] [G loss: 0.717914]\n",
      "epoch:5 step:5028 [D loss: 0.455329, acc.: 80.47%] [G loss: 0.882638]\n",
      "epoch:5 step:5029 [D loss: 0.428125, acc.: 78.12%] [G loss: 0.988071]\n",
      "epoch:5 step:5030 [D loss: 0.492993, acc.: 75.78%] [G loss: 1.067253]\n",
      "epoch:5 step:5031 [D loss: 0.486707, acc.: 75.00%] [G loss: 0.967071]\n",
      "epoch:5 step:5032 [D loss: 0.431545, acc.: 82.03%] [G loss: 1.167550]\n",
      "epoch:5 step:5033 [D loss: 0.620075, acc.: 68.75%] [G loss: 0.772691]\n",
      "epoch:5 step:5034 [D loss: 0.728372, acc.: 56.25%] [G loss: 0.600956]\n",
      "epoch:5 step:5035 [D loss: 0.516006, acc.: 74.22%] [G loss: 0.720909]\n",
      "epoch:5 step:5036 [D loss: 0.476828, acc.: 78.91%] [G loss: 0.668987]\n",
      "epoch:5 step:5037 [D loss: 0.619658, acc.: 67.19%] [G loss: 0.669704]\n",
      "epoch:5 step:5038 [D loss: 0.544020, acc.: 72.66%] [G loss: 0.676895]\n",
      "epoch:5 step:5039 [D loss: 0.400451, acc.: 86.72%] [G loss: 0.831590]\n",
      "epoch:5 step:5040 [D loss: 0.531471, acc.: 75.00%] [G loss: 0.839169]\n",
      "epoch:5 step:5041 [D loss: 0.543063, acc.: 72.66%] [G loss: 0.626489]\n",
      "epoch:5 step:5042 [D loss: 0.482358, acc.: 75.78%] [G loss: 0.692926]\n",
      "epoch:5 step:5043 [D loss: 0.445586, acc.: 78.91%] [G loss: 0.730661]\n",
      "epoch:5 step:5044 [D loss: 0.465793, acc.: 75.78%] [G loss: 0.762596]\n",
      "epoch:5 step:5045 [D loss: 0.566534, acc.: 69.53%] [G loss: 0.774664]\n",
      "epoch:5 step:5046 [D loss: 0.482106, acc.: 78.12%] [G loss: 0.800542]\n",
      "epoch:5 step:5047 [D loss: 0.516855, acc.: 74.22%] [G loss: 0.701564]\n",
      "epoch:5 step:5048 [D loss: 0.533662, acc.: 71.88%] [G loss: 0.513053]\n",
      "epoch:5 step:5049 [D loss: 0.462470, acc.: 78.91%] [G loss: 0.642818]\n",
      "epoch:5 step:5050 [D loss: 0.471161, acc.: 79.69%] [G loss: 0.520768]\n",
      "epoch:5 step:5051 [D loss: 0.438325, acc.: 81.25%] [G loss: 0.547670]\n",
      "epoch:5 step:5052 [D loss: 0.558064, acc.: 74.22%] [G loss: 0.643444]\n",
      "epoch:5 step:5053 [D loss: 0.513906, acc.: 75.00%] [G loss: 0.705154]\n",
      "epoch:5 step:5054 [D loss: 0.628121, acc.: 60.16%] [G loss: 0.622412]\n",
      "epoch:5 step:5055 [D loss: 0.538558, acc.: 71.09%] [G loss: 0.760877]\n",
      "epoch:5 step:5056 [D loss: 0.499219, acc.: 73.44%] [G loss: 0.860736]\n",
      "epoch:5 step:5057 [D loss: 0.537425, acc.: 75.78%] [G loss: 0.532540]\n",
      "epoch:5 step:5058 [D loss: 0.588581, acc.: 68.75%] [G loss: 0.612938]\n",
      "epoch:5 step:5059 [D loss: 0.461738, acc.: 81.25%] [G loss: 0.751774]\n",
      "epoch:5 step:5060 [D loss: 0.540628, acc.: 67.97%] [G loss: 0.607806]\n",
      "epoch:5 step:5061 [D loss: 0.687665, acc.: 57.81%] [G loss: 0.494225]\n",
      "epoch:5 step:5062 [D loss: 0.555678, acc.: 69.53%] [G loss: 0.519939]\n",
      "epoch:5 step:5063 [D loss: 0.511307, acc.: 72.66%] [G loss: 0.672839]\n",
      "epoch:5 step:5064 [D loss: 0.599352, acc.: 63.28%] [G loss: 0.488622]\n",
      "epoch:5 step:5065 [D loss: 0.562511, acc.: 72.66%] [G loss: 0.533980]\n",
      "epoch:5 step:5066 [D loss: 0.457982, acc.: 79.69%] [G loss: 0.595653]\n",
      "epoch:5 step:5067 [D loss: 0.534477, acc.: 73.44%] [G loss: 0.680317]\n",
      "epoch:5 step:5068 [D loss: 0.543557, acc.: 68.75%] [G loss: 0.575462]\n",
      "epoch:5 step:5069 [D loss: 0.494803, acc.: 78.91%] [G loss: 0.559687]\n",
      "epoch:5 step:5070 [D loss: 0.521058, acc.: 75.00%] [G loss: 0.528407]\n",
      "epoch:5 step:5071 [D loss: 0.536524, acc.: 72.66%] [G loss: 0.509856]\n",
      "epoch:5 step:5072 [D loss: 0.511104, acc.: 75.78%] [G loss: 0.524969]\n",
      "epoch:5 step:5073 [D loss: 0.511594, acc.: 75.00%] [G loss: 0.633578]\n",
      "epoch:5 step:5074 [D loss: 0.526184, acc.: 73.44%] [G loss: 0.501840]\n",
      "epoch:5 step:5075 [D loss: 0.499381, acc.: 78.12%] [G loss: 0.700834]\n",
      "epoch:5 step:5076 [D loss: 0.563363, acc.: 69.53%] [G loss: 0.732589]\n",
      "epoch:5 step:5077 [D loss: 0.492335, acc.: 73.44%] [G loss: 0.888244]\n",
      "epoch:5 step:5078 [D loss: 0.527393, acc.: 70.31%] [G loss: 0.536756]\n",
      "epoch:5 step:5079 [D loss: 0.486612, acc.: 76.56%] [G loss: 0.628851]\n",
      "epoch:5 step:5080 [D loss: 0.492889, acc.: 75.78%] [G loss: 0.518970]\n",
      "epoch:5 step:5081 [D loss: 0.621580, acc.: 65.62%] [G loss: 0.534516]\n",
      "epoch:5 step:5082 [D loss: 0.513189, acc.: 74.22%] [G loss: 0.470193]\n",
      "epoch:5 step:5083 [D loss: 0.466723, acc.: 74.22%] [G loss: 0.673247]\n",
      "epoch:5 step:5084 [D loss: 0.475354, acc.: 79.69%] [G loss: 0.779665]\n",
      "epoch:5 step:5085 [D loss: 0.651700, acc.: 60.16%] [G loss: 0.513469]\n",
      "epoch:5 step:5086 [D loss: 0.561536, acc.: 67.19%] [G loss: 0.515402]\n",
      "epoch:5 step:5087 [D loss: 0.453879, acc.: 80.47%] [G loss: 0.485699]\n",
      "epoch:5 step:5088 [D loss: 0.527729, acc.: 75.00%] [G loss: 0.552802]\n",
      "epoch:5 step:5089 [D loss: 0.561028, acc.: 66.41%] [G loss: 0.551059]\n",
      "epoch:5 step:5090 [D loss: 0.537349, acc.: 74.22%] [G loss: 0.566252]\n",
      "epoch:5 step:5091 [D loss: 0.393508, acc.: 82.81%] [G loss: 0.734276]\n",
      "epoch:5 step:5092 [D loss: 0.568946, acc.: 68.75%] [G loss: 0.740683]\n",
      "epoch:5 step:5093 [D loss: 0.518824, acc.: 75.00%] [G loss: 0.570755]\n",
      "epoch:5 step:5094 [D loss: 0.573196, acc.: 67.97%] [G loss: 0.486632]\n",
      "epoch:5 step:5095 [D loss: 0.520545, acc.: 71.88%] [G loss: 0.631860]\n",
      "epoch:5 step:5096 [D loss: 0.543878, acc.: 74.22%] [G loss: 0.581741]\n",
      "epoch:5 step:5097 [D loss: 0.532080, acc.: 74.22%] [G loss: 0.482805]\n",
      "epoch:5 step:5098 [D loss: 0.504483, acc.: 73.44%] [G loss: 0.582251]\n",
      "epoch:5 step:5099 [D loss: 0.513128, acc.: 76.56%] [G loss: 0.622279]\n",
      "epoch:5 step:5100 [D loss: 0.536937, acc.: 74.22%] [G loss: 0.539268]\n",
      "epoch:5 step:5101 [D loss: 0.488173, acc.: 81.25%] [G loss: 0.675559]\n",
      "epoch:5 step:5102 [D loss: 0.561104, acc.: 71.88%] [G loss: 0.589081]\n",
      "epoch:5 step:5103 [D loss: 0.615101, acc.: 66.41%] [G loss: 0.559147]\n",
      "epoch:5 step:5104 [D loss: 0.508226, acc.: 75.00%] [G loss: 0.547476]\n",
      "epoch:5 step:5105 [D loss: 0.597522, acc.: 64.06%] [G loss: 0.773852]\n",
      "epoch:5 step:5106 [D loss: 0.541839, acc.: 77.34%] [G loss: 0.558149]\n",
      "epoch:5 step:5107 [D loss: 0.577359, acc.: 67.97%] [G loss: 0.505321]\n",
      "epoch:5 step:5108 [D loss: 0.520671, acc.: 74.22%] [G loss: 0.606947]\n",
      "epoch:5 step:5109 [D loss: 0.539748, acc.: 70.31%] [G loss: 0.531030]\n",
      "epoch:5 step:5110 [D loss: 0.478420, acc.: 81.25%] [G loss: 0.799006]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:5 step:5111 [D loss: 0.471235, acc.: 77.34%] [G loss: 0.735291]\n",
      "epoch:5 step:5112 [D loss: 0.463408, acc.: 76.56%] [G loss: 0.758498]\n",
      "epoch:5 step:5113 [D loss: 0.515313, acc.: 77.34%] [G loss: 0.636838]\n",
      "epoch:5 step:5114 [D loss: 0.429623, acc.: 80.47%] [G loss: 0.864653]\n",
      "epoch:5 step:5115 [D loss: 0.508498, acc.: 75.78%] [G loss: 0.699129]\n",
      "epoch:5 step:5116 [D loss: 0.508103, acc.: 78.91%] [G loss: 0.556819]\n",
      "epoch:5 step:5117 [D loss: 0.594521, acc.: 66.41%] [G loss: 0.546489]\n",
      "epoch:5 step:5118 [D loss: 0.553754, acc.: 66.41%] [G loss: 0.411331]\n",
      "epoch:5 step:5119 [D loss: 0.499849, acc.: 78.91%] [G loss: 0.602921]\n",
      "epoch:5 step:5120 [D loss: 0.536966, acc.: 75.00%] [G loss: 0.542842]\n",
      "epoch:5 step:5121 [D loss: 0.487312, acc.: 76.56%] [G loss: 0.545125]\n",
      "epoch:5 step:5122 [D loss: 0.726720, acc.: 55.47%] [G loss: 0.476474]\n",
      "epoch:5 step:5123 [D loss: 0.506216, acc.: 76.56%] [G loss: 0.591069]\n",
      "epoch:5 step:5124 [D loss: 0.516560, acc.: 73.44%] [G loss: 0.783579]\n",
      "epoch:5 step:5125 [D loss: 0.469743, acc.: 77.34%] [G loss: 0.706746]\n",
      "epoch:5 step:5126 [D loss: 0.551336, acc.: 74.22%] [G loss: 0.701955]\n",
      "epoch:5 step:5127 [D loss: 0.553579, acc.: 68.75%] [G loss: 0.579975]\n",
      "epoch:5 step:5128 [D loss: 0.472372, acc.: 77.34%] [G loss: 0.707123]\n",
      "epoch:5 step:5129 [D loss: 0.473108, acc.: 75.78%] [G loss: 0.687073]\n",
      "epoch:5 step:5130 [D loss: 0.523594, acc.: 71.88%] [G loss: 0.618348]\n",
      "epoch:5 step:5131 [D loss: 0.535012, acc.: 74.22%] [G loss: 0.773929]\n",
      "epoch:5 step:5132 [D loss: 0.480536, acc.: 72.66%] [G loss: 0.673192]\n",
      "epoch:5 step:5133 [D loss: 0.526921, acc.: 70.31%] [G loss: 0.767926]\n",
      "epoch:5 step:5134 [D loss: 0.532434, acc.: 75.00%] [G loss: 0.718856]\n",
      "epoch:5 step:5135 [D loss: 0.435206, acc.: 82.03%] [G loss: 0.670132]\n",
      "epoch:5 step:5136 [D loss: 0.408800, acc.: 83.59%] [G loss: 0.859882]\n",
      "epoch:5 step:5137 [D loss: 0.517052, acc.: 75.00%] [G loss: 0.820639]\n",
      "epoch:5 step:5138 [D loss: 0.507418, acc.: 77.34%] [G loss: 0.630085]\n",
      "epoch:5 step:5139 [D loss: 0.600920, acc.: 67.19%] [G loss: 0.594145]\n",
      "epoch:5 step:5140 [D loss: 0.572216, acc.: 70.31%] [G loss: 0.573537]\n",
      "epoch:5 step:5141 [D loss: 0.602046, acc.: 67.19%] [G loss: 0.564864]\n",
      "epoch:5 step:5142 [D loss: 0.444751, acc.: 81.25%] [G loss: 0.672739]\n",
      "epoch:5 step:5143 [D loss: 0.586362, acc.: 69.53%] [G loss: 0.561515]\n",
      "epoch:5 step:5144 [D loss: 0.531099, acc.: 70.31%] [G loss: 0.589328]\n",
      "epoch:5 step:5145 [D loss: 0.510162, acc.: 75.78%] [G loss: 0.764036]\n",
      "epoch:5 step:5146 [D loss: 0.552562, acc.: 69.53%] [G loss: 0.710846]\n",
      "epoch:5 step:5147 [D loss: 0.550257, acc.: 70.31%] [G loss: 0.657097]\n",
      "epoch:5 step:5148 [D loss: 0.547190, acc.: 70.31%] [G loss: 0.612066]\n",
      "epoch:5 step:5149 [D loss: 0.537185, acc.: 67.97%] [G loss: 0.546143]\n",
      "epoch:5 step:5150 [D loss: 0.569731, acc.: 73.44%] [G loss: 0.479480]\n",
      "epoch:5 step:5151 [D loss: 0.552189, acc.: 67.97%] [G loss: 0.580062]\n",
      "epoch:5 step:5152 [D loss: 0.572564, acc.: 65.62%] [G loss: 0.579326]\n",
      "epoch:5 step:5153 [D loss: 0.504456, acc.: 76.56%] [G loss: 0.722649]\n",
      "epoch:5 step:5154 [D loss: 0.533170, acc.: 68.75%] [G loss: 0.700832]\n",
      "epoch:5 step:5155 [D loss: 0.492251, acc.: 74.22%] [G loss: 0.768413]\n",
      "epoch:5 step:5156 [D loss: 0.449968, acc.: 80.47%] [G loss: 0.867826]\n",
      "epoch:5 step:5157 [D loss: 0.433132, acc.: 82.03%] [G loss: 0.844429]\n",
      "epoch:5 step:5158 [D loss: 0.592785, acc.: 68.75%] [G loss: 0.904178]\n",
      "epoch:5 step:5159 [D loss: 0.492321, acc.: 75.78%] [G loss: 0.659100]\n",
      "epoch:5 step:5160 [D loss: 0.433303, acc.: 85.16%] [G loss: 0.774227]\n",
      "epoch:5 step:5161 [D loss: 0.569263, acc.: 73.44%] [G loss: 0.520232]\n",
      "epoch:5 step:5162 [D loss: 0.602526, acc.: 66.41%] [G loss: 0.480073]\n",
      "epoch:5 step:5163 [D loss: 0.617953, acc.: 66.41%] [G loss: 0.388316]\n",
      "epoch:5 step:5164 [D loss: 0.521326, acc.: 75.00%] [G loss: 0.468616]\n",
      "epoch:5 step:5165 [D loss: 0.536331, acc.: 71.88%] [G loss: 0.583640]\n",
      "epoch:5 step:5166 [D loss: 0.502790, acc.: 79.69%] [G loss: 0.634860]\n",
      "epoch:5 step:5167 [D loss: 0.547619, acc.: 68.75%] [G loss: 0.475383]\n",
      "epoch:5 step:5168 [D loss: 0.530962, acc.: 71.09%] [G loss: 0.526703]\n",
      "epoch:5 step:5169 [D loss: 0.452873, acc.: 85.16%] [G loss: 0.601703]\n",
      "epoch:5 step:5170 [D loss: 0.482837, acc.: 78.91%] [G loss: 0.760801]\n",
      "epoch:5 step:5171 [D loss: 0.549123, acc.: 73.44%] [G loss: 0.564859]\n",
      "epoch:5 step:5172 [D loss: 0.538400, acc.: 73.44%] [G loss: 0.492104]\n",
      "epoch:5 step:5173 [D loss: 0.484250, acc.: 75.78%] [G loss: 0.622253]\n",
      "epoch:5 step:5174 [D loss: 0.581512, acc.: 64.84%] [G loss: 0.529379]\n",
      "epoch:5 step:5175 [D loss: 0.553333, acc.: 71.88%] [G loss: 0.461932]\n",
      "epoch:5 step:5176 [D loss: 0.563493, acc.: 68.75%] [G loss: 0.542507]\n",
      "epoch:5 step:5177 [D loss: 0.515760, acc.: 73.44%] [G loss: 0.588498]\n",
      "epoch:5 step:5178 [D loss: 0.536004, acc.: 71.09%] [G loss: 0.543417]\n",
      "epoch:5 step:5179 [D loss: 0.502986, acc.: 78.91%] [G loss: 0.601973]\n",
      "epoch:5 step:5180 [D loss: 0.498328, acc.: 74.22%] [G loss: 0.753910]\n",
      "epoch:5 step:5181 [D loss: 0.502601, acc.: 74.22%] [G loss: 0.600014]\n",
      "epoch:5 step:5182 [D loss: 0.519973, acc.: 72.66%] [G loss: 0.541010]\n",
      "epoch:5 step:5183 [D loss: 0.540103, acc.: 71.09%] [G loss: 0.644937]\n",
      "epoch:5 step:5184 [D loss: 0.448884, acc.: 83.59%] [G loss: 0.907996]\n",
      "epoch:5 step:5185 [D loss: 0.619398, acc.: 65.62%] [G loss: 0.666875]\n",
      "epoch:5 step:5186 [D loss: 0.653256, acc.: 64.06%] [G loss: 0.534643]\n",
      "epoch:5 step:5187 [D loss: 0.599034, acc.: 64.84%] [G loss: 0.488785]\n",
      "epoch:5 step:5188 [D loss: 0.496234, acc.: 77.34%] [G loss: 0.665606]\n",
      "epoch:5 step:5189 [D loss: 0.476233, acc.: 79.69%] [G loss: 0.794507]\n",
      "epoch:5 step:5190 [D loss: 0.557010, acc.: 71.09%] [G loss: 0.713094]\n",
      "epoch:5 step:5191 [D loss: 0.512696, acc.: 75.78%] [G loss: 0.670678]\n",
      "epoch:5 step:5192 [D loss: 0.569854, acc.: 69.53%] [G loss: 0.585183]\n",
      "epoch:5 step:5193 [D loss: 0.464433, acc.: 77.34%] [G loss: 0.653113]\n",
      "epoch:5 step:5194 [D loss: 0.466588, acc.: 74.22%] [G loss: 0.727153]\n",
      "epoch:5 step:5195 [D loss: 0.556477, acc.: 67.19%] [G loss: 0.526620]\n",
      "epoch:5 step:5196 [D loss: 0.641755, acc.: 60.16%] [G loss: 0.418698]\n",
      "epoch:5 step:5197 [D loss: 0.548433, acc.: 67.97%] [G loss: 0.572615]\n",
      "epoch:5 step:5198 [D loss: 0.485649, acc.: 74.22%] [G loss: 0.682551]\n",
      "epoch:5 step:5199 [D loss: 0.486224, acc.: 76.56%] [G loss: 0.634993]\n",
      "epoch:5 step:5200 [D loss: 0.530630, acc.: 73.44%] [G loss: 0.680282]\n",
      "epoch:5 step:5201 [D loss: 0.485161, acc.: 75.00%] [G loss: 0.823229]\n",
      "epoch:5 step:5202 [D loss: 0.524899, acc.: 71.88%] [G loss: 0.703057]\n",
      "epoch:5 step:5203 [D loss: 0.438828, acc.: 82.03%] [G loss: 0.784132]\n",
      "epoch:5 step:5204 [D loss: 0.555956, acc.: 66.41%] [G loss: 0.611623]\n",
      "epoch:5 step:5205 [D loss: 0.460435, acc.: 80.47%] [G loss: 0.669311]\n",
      "epoch:5 step:5206 [D loss: 0.482216, acc.: 82.03%] [G loss: 0.654363]\n",
      "epoch:5 step:5207 [D loss: 0.510086, acc.: 75.00%] [G loss: 0.718087]\n",
      "epoch:5 step:5208 [D loss: 0.476534, acc.: 76.56%] [G loss: 0.755351]\n",
      "epoch:5 step:5209 [D loss: 0.517537, acc.: 74.22%] [G loss: 0.678504]\n",
      "epoch:5 step:5210 [D loss: 0.611859, acc.: 63.28%] [G loss: 0.489497]\n",
      "epoch:5 step:5211 [D loss: 0.532554, acc.: 73.44%] [G loss: 0.529627]\n",
      "epoch:5 step:5212 [D loss: 0.525682, acc.: 71.09%] [G loss: 0.646017]\n",
      "epoch:5 step:5213 [D loss: 0.566546, acc.: 72.66%] [G loss: 0.504904]\n",
      "epoch:5 step:5214 [D loss: 0.555807, acc.: 71.88%] [G loss: 0.506023]\n",
      "epoch:5 step:5215 [D loss: 0.469150, acc.: 79.69%] [G loss: 0.689801]\n",
      "epoch:5 step:5216 [D loss: 0.613894, acc.: 64.84%] [G loss: 0.572188]\n",
      "epoch:5 step:5217 [D loss: 0.515131, acc.: 75.78%] [G loss: 0.488632]\n",
      "epoch:5 step:5218 [D loss: 0.541517, acc.: 71.88%] [G loss: 0.597586]\n",
      "epoch:5 step:5219 [D loss: 0.469594, acc.: 77.34%] [G loss: 0.663245]\n",
      "epoch:5 step:5220 [D loss: 0.548754, acc.: 69.53%] [G loss: 0.576573]\n",
      "epoch:5 step:5221 [D loss: 0.490887, acc.: 70.31%] [G loss: 0.531321]\n",
      "epoch:5 step:5222 [D loss: 0.526134, acc.: 73.44%] [G loss: 0.516309]\n",
      "epoch:5 step:5223 [D loss: 0.565066, acc.: 70.31%] [G loss: 0.432765]\n",
      "epoch:5 step:5224 [D loss: 0.518242, acc.: 73.44%] [G loss: 0.509155]\n",
      "epoch:5 step:5225 [D loss: 0.532418, acc.: 68.75%] [G loss: 0.497141]\n",
      "epoch:5 step:5226 [D loss: 0.540699, acc.: 73.44%] [G loss: 0.540837]\n",
      "epoch:5 step:5227 [D loss: 0.531116, acc.: 71.88%] [G loss: 0.562838]\n",
      "epoch:5 step:5228 [D loss: 0.525511, acc.: 74.22%] [G loss: 0.550668]\n",
      "epoch:5 step:5229 [D loss: 0.560402, acc.: 71.88%] [G loss: 0.517773]\n",
      "epoch:5 step:5230 [D loss: 0.553488, acc.: 71.09%] [G loss: 0.665364]\n",
      "epoch:5 step:5231 [D loss: 0.486608, acc.: 75.00%] [G loss: 0.638123]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:5 step:5232 [D loss: 0.509746, acc.: 78.91%] [G loss: 0.786159]\n",
      "epoch:5 step:5233 [D loss: 0.512714, acc.: 74.22%] [G loss: 0.657903]\n",
      "epoch:5 step:5234 [D loss: 0.518791, acc.: 77.34%] [G loss: 0.576944]\n",
      "epoch:5 step:5235 [D loss: 0.518579, acc.: 78.12%] [G loss: 0.583936]\n",
      "epoch:5 step:5236 [D loss: 0.519657, acc.: 73.44%] [G loss: 0.684773]\n",
      "epoch:5 step:5237 [D loss: 0.452869, acc.: 81.25%] [G loss: 0.560285]\n",
      "epoch:5 step:5238 [D loss: 0.509753, acc.: 75.00%] [G loss: 0.585016]\n",
      "epoch:5 step:5239 [D loss: 0.469144, acc.: 75.00%] [G loss: 0.629136]\n",
      "epoch:5 step:5240 [D loss: 0.467457, acc.: 82.03%] [G loss: 0.604305]\n",
      "epoch:5 step:5241 [D loss: 0.482166, acc.: 81.25%] [G loss: 0.591435]\n",
      "epoch:5 step:5242 [D loss: 0.507108, acc.: 75.78%] [G loss: 0.567174]\n",
      "epoch:5 step:5243 [D loss: 0.472313, acc.: 79.69%] [G loss: 0.584094]\n",
      "epoch:5 step:5244 [D loss: 0.547681, acc.: 73.44%] [G loss: 0.569733]\n",
      "epoch:5 step:5245 [D loss: 0.546469, acc.: 73.44%] [G loss: 0.512634]\n",
      "epoch:5 step:5246 [D loss: 0.522112, acc.: 75.00%] [G loss: 0.550430]\n",
      "epoch:5 step:5247 [D loss: 0.564619, acc.: 74.22%] [G loss: 0.548116]\n",
      "epoch:5 step:5248 [D loss: 0.538788, acc.: 72.66%] [G loss: 0.699691]\n",
      "epoch:5 step:5249 [D loss: 0.491260, acc.: 75.78%] [G loss: 0.710882]\n",
      "epoch:5 step:5250 [D loss: 0.568865, acc.: 71.09%] [G loss: 0.564703]\n",
      "epoch:5 step:5251 [D loss: 0.651468, acc.: 63.28%] [G loss: 0.522187]\n",
      "epoch:5 step:5252 [D loss: 0.480875, acc.: 78.12%] [G loss: 0.657238]\n",
      "epoch:5 step:5253 [D loss: 0.475655, acc.: 76.56%] [G loss: 0.691788]\n",
      "epoch:5 step:5254 [D loss: 0.564382, acc.: 71.09%] [G loss: 0.488960]\n",
      "epoch:5 step:5255 [D loss: 0.492559, acc.: 78.12%] [G loss: 0.598383]\n",
      "epoch:5 step:5256 [D loss: 0.465399, acc.: 81.25%] [G loss: 0.571958]\n",
      "epoch:5 step:5257 [D loss: 0.521234, acc.: 71.09%] [G loss: 0.564345]\n",
      "epoch:5 step:5258 [D loss: 0.546059, acc.: 68.75%] [G loss: 0.688774]\n",
      "epoch:5 step:5259 [D loss: 0.492850, acc.: 76.56%] [G loss: 0.694668]\n",
      "epoch:5 step:5260 [D loss: 0.417533, acc.: 83.59%] [G loss: 0.803770]\n",
      "epoch:5 step:5261 [D loss: 0.498669, acc.: 74.22%] [G loss: 0.781443]\n",
      "epoch:5 step:5262 [D loss: 0.610592, acc.: 65.62%] [G loss: 0.589933]\n",
      "epoch:5 step:5263 [D loss: 0.564970, acc.: 69.53%] [G loss: 0.566715]\n",
      "epoch:5 step:5264 [D loss: 0.529209, acc.: 68.75%] [G loss: 0.719139]\n",
      "epoch:5 step:5265 [D loss: 0.537493, acc.: 72.66%] [G loss: 0.529535]\n",
      "epoch:5 step:5266 [D loss: 0.518412, acc.: 72.66%] [G loss: 0.792627]\n",
      "epoch:5 step:5267 [D loss: 0.416940, acc.: 83.59%] [G loss: 0.776732]\n",
      "epoch:5 step:5268 [D loss: 0.554578, acc.: 68.75%] [G loss: 0.761207]\n",
      "epoch:5 step:5269 [D loss: 0.535441, acc.: 70.31%] [G loss: 0.747919]\n",
      "epoch:5 step:5270 [D loss: 0.521714, acc.: 76.56%] [G loss: 0.821045]\n",
      "epoch:5 step:5271 [D loss: 0.575275, acc.: 70.31%] [G loss: 0.572734]\n",
      "epoch:5 step:5272 [D loss: 0.512497, acc.: 70.31%] [G loss: 0.642216]\n",
      "epoch:5 step:5273 [D loss: 0.560042, acc.: 68.75%] [G loss: 0.633029]\n",
      "epoch:5 step:5274 [D loss: 0.498236, acc.: 75.78%] [G loss: 0.789873]\n",
      "epoch:5 step:5275 [D loss: 0.636205, acc.: 66.41%] [G loss: 0.505891]\n",
      "epoch:5 step:5276 [D loss: 0.668827, acc.: 61.72%] [G loss: 0.495491]\n",
      "epoch:5 step:5277 [D loss: 0.512617, acc.: 75.00%] [G loss: 0.530977]\n",
      "epoch:5 step:5278 [D loss: 0.600820, acc.: 70.31%] [G loss: 0.532161]\n",
      "epoch:5 step:5279 [D loss: 0.524552, acc.: 74.22%] [G loss: 0.599122]\n",
      "epoch:5 step:5280 [D loss: 0.525199, acc.: 71.09%] [G loss: 0.631641]\n",
      "epoch:5 step:5281 [D loss: 0.528880, acc.: 71.88%] [G loss: 0.576188]\n",
      "epoch:5 step:5282 [D loss: 0.498772, acc.: 75.78%] [G loss: 0.539970]\n",
      "epoch:5 step:5283 [D loss: 0.537421, acc.: 73.44%] [G loss: 0.608212]\n",
      "epoch:5 step:5284 [D loss: 0.593004, acc.: 69.53%] [G loss: 0.647295]\n",
      "epoch:5 step:5285 [D loss: 0.568727, acc.: 68.75%] [G loss: 0.640002]\n",
      "epoch:5 step:5286 [D loss: 0.520810, acc.: 71.09%] [G loss: 0.545191]\n",
      "epoch:5 step:5287 [D loss: 0.482398, acc.: 75.78%] [G loss: 0.459746]\n",
      "epoch:5 step:5288 [D loss: 0.543706, acc.: 71.09%] [G loss: 0.511981]\n",
      "epoch:5 step:5289 [D loss: 0.579042, acc.: 70.31%] [G loss: 0.501995]\n",
      "epoch:5 step:5290 [D loss: 0.458940, acc.: 75.78%] [G loss: 0.701414]\n",
      "epoch:5 step:5291 [D loss: 0.551806, acc.: 68.75%] [G loss: 0.494372]\n",
      "epoch:5 step:5292 [D loss: 0.534973, acc.: 69.53%] [G loss: 0.634902]\n",
      "epoch:5 step:5293 [D loss: 0.490124, acc.: 78.12%] [G loss: 0.639271]\n",
      "epoch:5 step:5294 [D loss: 0.502481, acc.: 75.00%] [G loss: 0.415661]\n",
      "epoch:5 step:5295 [D loss: 0.511199, acc.: 74.22%] [G loss: 0.581444]\n",
      "epoch:5 step:5296 [D loss: 0.482142, acc.: 73.44%] [G loss: 0.507677]\n",
      "epoch:5 step:5297 [D loss: 0.530691, acc.: 68.75%] [G loss: 0.538524]\n",
      "epoch:5 step:5298 [D loss: 0.473572, acc.: 74.22%] [G loss: 0.611101]\n",
      "epoch:5 step:5299 [D loss: 0.581148, acc.: 64.84%] [G loss: 0.572472]\n",
      "epoch:5 step:5300 [D loss: 0.600582, acc.: 62.50%] [G loss: 0.560305]\n",
      "epoch:5 step:5301 [D loss: 0.537901, acc.: 66.41%] [G loss: 0.664176]\n",
      "epoch:5 step:5302 [D loss: 0.528839, acc.: 73.44%] [G loss: 0.633607]\n",
      "epoch:5 step:5303 [D loss: 0.530591, acc.: 71.88%] [G loss: 0.553605]\n",
      "epoch:5 step:5304 [D loss: 0.530568, acc.: 71.88%] [G loss: 0.607884]\n",
      "epoch:5 step:5305 [D loss: 0.513295, acc.: 72.66%] [G loss: 0.611252]\n",
      "epoch:5 step:5306 [D loss: 0.545739, acc.: 73.44%] [G loss: 0.489430]\n",
      "epoch:5 step:5307 [D loss: 0.566539, acc.: 70.31%] [G loss: 0.533190]\n",
      "epoch:5 step:5308 [D loss: 0.483280, acc.: 76.56%] [G loss: 0.592728]\n",
      "epoch:5 step:5309 [D loss: 0.521036, acc.: 67.19%] [G loss: 0.652220]\n",
      "epoch:5 step:5310 [D loss: 0.567084, acc.: 69.53%] [G loss: 0.575669]\n",
      "epoch:5 step:5311 [D loss: 0.518409, acc.: 72.66%] [G loss: 0.583868]\n",
      "epoch:5 step:5312 [D loss: 0.494926, acc.: 75.00%] [G loss: 0.594149]\n",
      "epoch:5 step:5313 [D loss: 0.530113, acc.: 71.09%] [G loss: 0.495464]\n",
      "epoch:5 step:5314 [D loss: 0.527765, acc.: 71.09%] [G loss: 0.523245]\n",
      "epoch:5 step:5315 [D loss: 0.525190, acc.: 74.22%] [G loss: 0.539043]\n",
      "epoch:5 step:5316 [D loss: 0.493223, acc.: 76.56%] [G loss: 0.653931]\n",
      "epoch:5 step:5317 [D loss: 0.482139, acc.: 78.12%] [G loss: 0.621779]\n",
      "epoch:5 step:5318 [D loss: 0.508872, acc.: 74.22%] [G loss: 0.501705]\n",
      "epoch:5 step:5319 [D loss: 0.536896, acc.: 74.22%] [G loss: 0.586522]\n",
      "epoch:5 step:5320 [D loss: 0.546563, acc.: 71.88%] [G loss: 0.616857]\n",
      "epoch:5 step:5321 [D loss: 0.581577, acc.: 69.53%] [G loss: 0.577307]\n",
      "epoch:5 step:5322 [D loss: 0.551987, acc.: 72.66%] [G loss: 0.563392]\n",
      "epoch:5 step:5323 [D loss: 0.505375, acc.: 75.00%] [G loss: 0.574782]\n",
      "epoch:5 step:5324 [D loss: 0.487876, acc.: 77.34%] [G loss: 0.559309]\n",
      "epoch:5 step:5325 [D loss: 0.484351, acc.: 78.91%] [G loss: 0.610703]\n",
      "epoch:5 step:5326 [D loss: 0.474968, acc.: 74.22%] [G loss: 0.805464]\n",
      "epoch:5 step:5327 [D loss: 0.490819, acc.: 73.44%] [G loss: 0.947288]\n",
      "epoch:5 step:5328 [D loss: 0.494469, acc.: 77.34%] [G loss: 0.821843]\n",
      "epoch:5 step:5329 [D loss: 0.603687, acc.: 64.84%] [G loss: 0.500874]\n",
      "epoch:5 step:5330 [D loss: 0.545804, acc.: 75.00%] [G loss: 0.511534]\n",
      "epoch:5 step:5331 [D loss: 0.643868, acc.: 61.72%] [G loss: 0.440414]\n",
      "epoch:5 step:5332 [D loss: 0.514491, acc.: 77.34%] [G loss: 0.640072]\n",
      "epoch:5 step:5333 [D loss: 0.430315, acc.: 84.38%] [G loss: 0.864938]\n",
      "epoch:5 step:5334 [D loss: 0.445540, acc.: 82.03%] [G loss: 0.821048]\n",
      "epoch:5 step:5335 [D loss: 0.531815, acc.: 71.09%] [G loss: 0.713704]\n",
      "epoch:5 step:5336 [D loss: 0.472479, acc.: 78.12%] [G loss: 0.737581]\n",
      "epoch:5 step:5337 [D loss: 0.593507, acc.: 68.75%] [G loss: 0.485868]\n",
      "epoch:5 step:5338 [D loss: 0.574885, acc.: 64.84%] [G loss: 0.453449]\n",
      "epoch:5 step:5339 [D loss: 0.523791, acc.: 69.53%] [G loss: 0.610590]\n",
      "epoch:5 step:5340 [D loss: 0.543951, acc.: 73.44%] [G loss: 0.528746]\n",
      "epoch:5 step:5341 [D loss: 0.533771, acc.: 77.34%] [G loss: 0.451502]\n",
      "epoch:5 step:5342 [D loss: 0.564814, acc.: 71.09%] [G loss: 0.543284]\n",
      "epoch:5 step:5343 [D loss: 0.604164, acc.: 67.19%] [G loss: 0.527596]\n",
      "epoch:5 step:5344 [D loss: 0.526994, acc.: 72.66%] [G loss: 0.570691]\n",
      "epoch:5 step:5345 [D loss: 0.507252, acc.: 71.09%] [G loss: 0.643179]\n",
      "epoch:5 step:5346 [D loss: 0.494528, acc.: 75.00%] [G loss: 0.581381]\n",
      "epoch:5 step:5347 [D loss: 0.578426, acc.: 68.75%] [G loss: 0.686139]\n",
      "epoch:5 step:5348 [D loss: 0.488423, acc.: 79.69%] [G loss: 0.810720]\n",
      "epoch:5 step:5349 [D loss: 0.523707, acc.: 72.66%] [G loss: 0.802382]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:5 step:5350 [D loss: 0.527650, acc.: 70.31%] [G loss: 0.771832]\n",
      "epoch:5 step:5351 [D loss: 0.558909, acc.: 76.56%] [G loss: 0.568057]\n",
      "epoch:5 step:5352 [D loss: 0.564838, acc.: 69.53%] [G loss: 0.625972]\n",
      "epoch:5 step:5353 [D loss: 0.507476, acc.: 78.91%] [G loss: 0.782946]\n",
      "epoch:5 step:5354 [D loss: 0.538023, acc.: 71.88%] [G loss: 0.495684]\n",
      "epoch:5 step:5355 [D loss: 0.531570, acc.: 69.53%] [G loss: 0.530855]\n",
      "epoch:5 step:5356 [D loss: 0.554723, acc.: 67.97%] [G loss: 0.497322]\n",
      "epoch:5 step:5357 [D loss: 0.617453, acc.: 63.28%] [G loss: 0.603995]\n",
      "epoch:5 step:5358 [D loss: 0.533045, acc.: 73.44%] [G loss: 0.588756]\n",
      "epoch:5 step:5359 [D loss: 0.540406, acc.: 71.88%] [G loss: 0.547668]\n",
      "epoch:5 step:5360 [D loss: 0.532205, acc.: 71.88%] [G loss: 0.576163]\n",
      "epoch:5 step:5361 [D loss: 0.596969, acc.: 64.06%] [G loss: 0.581179]\n",
      "epoch:5 step:5362 [D loss: 0.474669, acc.: 78.91%] [G loss: 0.597695]\n",
      "epoch:5 step:5363 [D loss: 0.504266, acc.: 78.12%] [G loss: 0.715647]\n",
      "epoch:5 step:5364 [D loss: 0.569539, acc.: 64.06%] [G loss: 0.555097]\n",
      "epoch:5 step:5365 [D loss: 0.458518, acc.: 81.25%] [G loss: 0.664467]\n",
      "epoch:5 step:5366 [D loss: 0.472750, acc.: 78.91%] [G loss: 0.682945]\n",
      "epoch:5 step:5367 [D loss: 0.510616, acc.: 77.34%] [G loss: 0.617926]\n",
      "epoch:5 step:5368 [D loss: 0.579599, acc.: 68.75%] [G loss: 0.534908]\n",
      "epoch:5 step:5369 [D loss: 0.542121, acc.: 72.66%] [G loss: 0.440942]\n",
      "epoch:5 step:5370 [D loss: 0.553577, acc.: 73.44%] [G loss: 0.495217]\n",
      "epoch:5 step:5371 [D loss: 0.514948, acc.: 78.12%] [G loss: 0.584045]\n",
      "epoch:5 step:5372 [D loss: 0.529567, acc.: 74.22%] [G loss: 0.469039]\n",
      "epoch:5 step:5373 [D loss: 0.546432, acc.: 71.09%] [G loss: 0.520791]\n",
      "epoch:5 step:5374 [D loss: 0.551792, acc.: 70.31%] [G loss: 0.728446]\n",
      "epoch:5 step:5375 [D loss: 0.526455, acc.: 71.88%] [G loss: 0.761514]\n",
      "epoch:5 step:5376 [D loss: 0.474479, acc.: 78.91%] [G loss: 0.649617]\n",
      "epoch:5 step:5377 [D loss: 0.510186, acc.: 79.69%] [G loss: 0.732893]\n",
      "epoch:5 step:5378 [D loss: 0.503784, acc.: 73.44%] [G loss: 0.635413]\n",
      "epoch:5 step:5379 [D loss: 0.481350, acc.: 78.12%] [G loss: 0.640114]\n",
      "epoch:5 step:5380 [D loss: 0.505915, acc.: 75.78%] [G loss: 0.513834]\n",
      "epoch:5 step:5381 [D loss: 0.572533, acc.: 67.97%] [G loss: 0.598317]\n",
      "epoch:5 step:5382 [D loss: 0.567325, acc.: 72.66%] [G loss: 0.552729]\n",
      "epoch:5 step:5383 [D loss: 0.523399, acc.: 73.44%] [G loss: 0.525288]\n",
      "epoch:5 step:5384 [D loss: 0.505420, acc.: 77.34%] [G loss: 0.712953]\n",
      "epoch:5 step:5385 [D loss: 0.520689, acc.: 75.78%] [G loss: 0.825059]\n",
      "epoch:5 step:5386 [D loss: 0.490393, acc.: 78.91%] [G loss: 0.740981]\n",
      "epoch:5 step:5387 [D loss: 0.548984, acc.: 69.53%] [G loss: 0.713425]\n",
      "epoch:5 step:5388 [D loss: 0.562593, acc.: 70.31%] [G loss: 0.592897]\n",
      "epoch:5 step:5389 [D loss: 0.597775, acc.: 67.97%] [G loss: 0.383804]\n",
      "epoch:5 step:5390 [D loss: 0.510987, acc.: 73.44%] [G loss: 0.420283]\n",
      "epoch:5 step:5391 [D loss: 0.472538, acc.: 79.69%] [G loss: 0.569719]\n",
      "epoch:5 step:5392 [D loss: 0.454941, acc.: 77.34%] [G loss: 0.607063]\n",
      "epoch:5 step:5393 [D loss: 0.422606, acc.: 83.59%] [G loss: 0.820781]\n",
      "epoch:5 step:5394 [D loss: 0.529815, acc.: 75.00%] [G loss: 0.760183]\n",
      "epoch:5 step:5395 [D loss: 0.658709, acc.: 61.72%] [G loss: 0.463886]\n",
      "epoch:5 step:5396 [D loss: 0.603161, acc.: 64.84%] [G loss: 0.609673]\n",
      "epoch:5 step:5397 [D loss: 0.543678, acc.: 71.88%] [G loss: 0.491126]\n",
      "epoch:5 step:5398 [D loss: 0.548290, acc.: 68.75%] [G loss: 0.595013]\n",
      "epoch:5 step:5399 [D loss: 0.477609, acc.: 82.03%] [G loss: 0.524074]\n",
      "epoch:5 step:5400 [D loss: 0.539166, acc.: 72.66%] [G loss: 0.566957]\n",
      "epoch:5 step:5401 [D loss: 0.607038, acc.: 67.19%] [G loss: 0.587272]\n",
      "epoch:5 step:5402 [D loss: 0.638726, acc.: 63.28%] [G loss: 0.474604]\n",
      "epoch:5 step:5403 [D loss: 0.586079, acc.: 66.41%] [G loss: 0.526099]\n",
      "epoch:5 step:5404 [D loss: 0.519220, acc.: 72.66%] [G loss: 0.637005]\n",
      "epoch:5 step:5405 [D loss: 0.600531, acc.: 67.19%] [G loss: 0.516816]\n",
      "epoch:5 step:5406 [D loss: 0.562596, acc.: 71.88%] [G loss: 0.466448]\n",
      "epoch:5 step:5407 [D loss: 0.504873, acc.: 75.78%] [G loss: 0.527121]\n",
      "epoch:5 step:5408 [D loss: 0.569377, acc.: 69.53%] [G loss: 0.598284]\n",
      "epoch:5 step:5409 [D loss: 0.480452, acc.: 78.12%] [G loss: 0.551327]\n",
      "epoch:5 step:5410 [D loss: 0.480621, acc.: 78.12%] [G loss: 0.707757]\n",
      "epoch:5 step:5411 [D loss: 0.517179, acc.: 72.66%] [G loss: 0.598639]\n",
      "epoch:5 step:5412 [D loss: 0.525541, acc.: 71.88%] [G loss: 0.538239]\n",
      "epoch:5 step:5413 [D loss: 0.505988, acc.: 75.78%] [G loss: 0.517168]\n",
      "epoch:5 step:5414 [D loss: 0.571884, acc.: 68.75%] [G loss: 0.490200]\n",
      "epoch:5 step:5415 [D loss: 0.495622, acc.: 73.44%] [G loss: 0.517516]\n",
      "epoch:5 step:5416 [D loss: 0.497379, acc.: 75.78%] [G loss: 0.714945]\n",
      "epoch:5 step:5417 [D loss: 0.511647, acc.: 72.66%] [G loss: 0.590968]\n",
      "epoch:5 step:5418 [D loss: 0.481607, acc.: 82.81%] [G loss: 0.654051]\n",
      "epoch:5 step:5419 [D loss: 0.548105, acc.: 70.31%] [G loss: 0.508115]\n",
      "epoch:5 step:5420 [D loss: 0.561754, acc.: 74.22%] [G loss: 0.599696]\n",
      "epoch:5 step:5421 [D loss: 0.488650, acc.: 78.91%] [G loss: 0.608656]\n",
      "epoch:5 step:5422 [D loss: 0.502665, acc.: 74.22%] [G loss: 0.582819]\n",
      "epoch:5 step:5423 [D loss: 0.552244, acc.: 72.66%] [G loss: 0.524830]\n",
      "epoch:5 step:5424 [D loss: 0.582917, acc.: 64.84%] [G loss: 0.447155]\n",
      "epoch:5 step:5425 [D loss: 0.547714, acc.: 67.97%] [G loss: 0.339541]\n",
      "epoch:5 step:5426 [D loss: 0.506602, acc.: 75.78%] [G loss: 0.477813]\n",
      "epoch:5 step:5427 [D loss: 0.561167, acc.: 66.41%] [G loss: 0.492389]\n",
      "epoch:5 step:5428 [D loss: 0.482641, acc.: 79.69%] [G loss: 0.463027]\n",
      "epoch:5 step:5429 [D loss: 0.547782, acc.: 71.88%] [G loss: 0.511941]\n",
      "epoch:5 step:5430 [D loss: 0.551632, acc.: 71.09%] [G loss: 0.572128]\n",
      "epoch:5 step:5431 [D loss: 0.500282, acc.: 74.22%] [G loss: 0.572161]\n",
      "epoch:5 step:5432 [D loss: 0.401750, acc.: 80.47%] [G loss: 0.709191]\n",
      "epoch:5 step:5433 [D loss: 0.545813, acc.: 67.97%] [G loss: 0.687890]\n",
      "epoch:5 step:5434 [D loss: 0.535250, acc.: 68.75%] [G loss: 0.631120]\n",
      "epoch:5 step:5435 [D loss: 0.551376, acc.: 69.53%] [G loss: 0.596498]\n",
      "epoch:5 step:5436 [D loss: 0.500547, acc.: 77.34%] [G loss: 0.580143]\n",
      "epoch:5 step:5437 [D loss: 0.522051, acc.: 71.88%] [G loss: 0.579370]\n",
      "epoch:5 step:5438 [D loss: 0.474347, acc.: 73.44%] [G loss: 0.726524]\n",
      "epoch:5 step:5439 [D loss: 0.430774, acc.: 83.59%] [G loss: 0.729972]\n",
      "epoch:5 step:5440 [D loss: 0.477707, acc.: 77.34%] [G loss: 0.655527]\n",
      "epoch:5 step:5441 [D loss: 0.541193, acc.: 67.97%] [G loss: 0.689951]\n",
      "epoch:5 step:5442 [D loss: 0.571373, acc.: 66.41%] [G loss: 0.598794]\n",
      "epoch:5 step:5443 [D loss: 0.484298, acc.: 78.12%] [G loss: 0.667363]\n",
      "epoch:5 step:5444 [D loss: 0.531969, acc.: 74.22%] [G loss: 0.492382]\n",
      "epoch:5 step:5445 [D loss: 0.517626, acc.: 72.66%] [G loss: 0.552490]\n",
      "epoch:5 step:5446 [D loss: 0.488792, acc.: 77.34%] [G loss: 0.649888]\n",
      "epoch:5 step:5447 [D loss: 0.560355, acc.: 71.09%] [G loss: 0.566118]\n",
      "epoch:5 step:5448 [D loss: 0.527774, acc.: 71.09%] [G loss: 0.515079]\n",
      "epoch:5 step:5449 [D loss: 0.468313, acc.: 80.47%] [G loss: 0.636646]\n",
      "epoch:5 step:5450 [D loss: 0.645131, acc.: 64.06%] [G loss: 0.617068]\n",
      "epoch:5 step:5451 [D loss: 0.579507, acc.: 71.88%] [G loss: 0.531860]\n",
      "epoch:5 step:5452 [D loss: 0.480922, acc.: 79.69%] [G loss: 0.651123]\n",
      "epoch:5 step:5453 [D loss: 0.529802, acc.: 75.78%] [G loss: 0.677031]\n",
      "epoch:5 step:5454 [D loss: 0.514180, acc.: 74.22%] [G loss: 0.820144]\n",
      "epoch:5 step:5455 [D loss: 0.594603, acc.: 74.22%] [G loss: 0.871696]\n",
      "epoch:5 step:5456 [D loss: 0.495862, acc.: 75.78%] [G loss: 0.626689]\n",
      "epoch:5 step:5457 [D loss: 0.523362, acc.: 72.66%] [G loss: 0.789476]\n",
      "epoch:5 step:5458 [D loss: 0.529767, acc.: 72.66%] [G loss: 0.549814]\n",
      "epoch:5 step:5459 [D loss: 0.645093, acc.: 60.16%] [G loss: 0.531156]\n",
      "epoch:5 step:5460 [D loss: 0.508824, acc.: 77.34%] [G loss: 0.651946]\n",
      "epoch:5 step:5461 [D loss: 0.502766, acc.: 73.44%] [G loss: 0.673481]\n",
      "epoch:5 step:5462 [D loss: 0.563900, acc.: 70.31%] [G loss: 0.492540]\n",
      "epoch:5 step:5463 [D loss: 0.560451, acc.: 72.66%] [G loss: 0.524244]\n",
      "epoch:5 step:5464 [D loss: 0.560160, acc.: 67.97%] [G loss: 0.507020]\n",
      "epoch:5 step:5465 [D loss: 0.501033, acc.: 74.22%] [G loss: 0.638173]\n",
      "epoch:5 step:5466 [D loss: 0.478478, acc.: 77.34%] [G loss: 0.858330]\n",
      "epoch:5 step:5467 [D loss: 0.512566, acc.: 70.31%] [G loss: 0.841267]\n",
      "epoch:5 step:5468 [D loss: 0.566517, acc.: 71.09%] [G loss: 0.631525]\n",
      "epoch:5 step:5469 [D loss: 0.568108, acc.: 71.88%] [G loss: 0.517973]\n",
      "epoch:5 step:5470 [D loss: 0.499693, acc.: 78.12%] [G loss: 0.556321]\n",
      "epoch:5 step:5471 [D loss: 0.482075, acc.: 75.78%] [G loss: 0.577975]\n",
      "epoch:5 step:5472 [D loss: 0.596320, acc.: 72.66%] [G loss: 0.505540]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:5 step:5473 [D loss: 0.639467, acc.: 63.28%] [G loss: 0.414329]\n",
      "epoch:5 step:5474 [D loss: 0.493076, acc.: 81.25%] [G loss: 0.541216]\n",
      "epoch:5 step:5475 [D loss: 0.539781, acc.: 71.09%] [G loss: 0.559223]\n",
      "epoch:5 step:5476 [D loss: 0.489300, acc.: 80.47%] [G loss: 0.508498]\n",
      "epoch:5 step:5477 [D loss: 0.426307, acc.: 83.59%] [G loss: 0.646352]\n",
      "epoch:5 step:5478 [D loss: 0.572246, acc.: 67.19%] [G loss: 0.576359]\n",
      "epoch:5 step:5479 [D loss: 0.587711, acc.: 65.62%] [G loss: 0.575299]\n",
      "epoch:5 step:5480 [D loss: 0.498334, acc.: 77.34%] [G loss: 0.618006]\n",
      "epoch:5 step:5481 [D loss: 0.466569, acc.: 79.69%] [G loss: 0.667264]\n",
      "epoch:5 step:5482 [D loss: 0.517701, acc.: 78.12%] [G loss: 0.634934]\n",
      "epoch:5 step:5483 [D loss: 0.485265, acc.: 75.78%] [G loss: 0.740940]\n",
      "epoch:5 step:5484 [D loss: 0.578517, acc.: 66.41%] [G loss: 0.631813]\n",
      "epoch:5 step:5485 [D loss: 0.493288, acc.: 77.34%] [G loss: 0.586181]\n",
      "epoch:5 step:5486 [D loss: 0.506305, acc.: 76.56%] [G loss: 0.776689]\n",
      "epoch:5 step:5487 [D loss: 0.465655, acc.: 78.91%] [G loss: 0.775304]\n",
      "epoch:5 step:5488 [D loss: 0.460586, acc.: 78.12%] [G loss: 0.849052]\n",
      "epoch:5 step:5489 [D loss: 0.557414, acc.: 67.19%] [G loss: 0.571417]\n",
      "epoch:5 step:5490 [D loss: 0.516118, acc.: 71.88%] [G loss: 0.465512]\n",
      "epoch:5 step:5491 [D loss: 0.470350, acc.: 78.91%] [G loss: 0.616199]\n",
      "epoch:5 step:5492 [D loss: 0.442947, acc.: 83.59%] [G loss: 0.635869]\n",
      "epoch:5 step:5493 [D loss: 0.589541, acc.: 64.06%] [G loss: 0.453179]\n",
      "epoch:5 step:5494 [D loss: 0.571908, acc.: 71.88%] [G loss: 0.673936]\n",
      "epoch:5 step:5495 [D loss: 0.514778, acc.: 75.00%] [G loss: 0.634552]\n",
      "epoch:5 step:5496 [D loss: 0.496994, acc.: 74.22%] [G loss: 0.628321]\n",
      "epoch:5 step:5497 [D loss: 0.580217, acc.: 68.75%] [G loss: 0.578721]\n",
      "epoch:5 step:5498 [D loss: 0.564422, acc.: 69.53%] [G loss: 0.455493]\n",
      "epoch:5 step:5499 [D loss: 0.484266, acc.: 76.56%] [G loss: 0.667146]\n",
      "epoch:5 step:5500 [D loss: 0.564877, acc.: 71.88%] [G loss: 0.701832]\n",
      "epoch:5 step:5501 [D loss: 0.534551, acc.: 71.88%] [G loss: 0.697156]\n",
      "epoch:5 step:5502 [D loss: 0.528137, acc.: 72.66%] [G loss: 0.620026]\n",
      "epoch:5 step:5503 [D loss: 0.566228, acc.: 68.75%] [G loss: 0.498627]\n",
      "epoch:5 step:5504 [D loss: 0.544444, acc.: 74.22%] [G loss: 0.428840]\n",
      "epoch:5 step:5505 [D loss: 0.592285, acc.: 64.84%] [G loss: 0.445943]\n",
      "epoch:5 step:5506 [D loss: 0.495275, acc.: 78.91%] [G loss: 0.428543]\n",
      "epoch:5 step:5507 [D loss: 0.473733, acc.: 78.91%] [G loss: 0.611121]\n",
      "epoch:5 step:5508 [D loss: 0.478476, acc.: 75.78%] [G loss: 0.656910]\n",
      "epoch:5 step:5509 [D loss: 0.656350, acc.: 59.38%] [G loss: 0.488642]\n",
      "epoch:5 step:5510 [D loss: 0.489339, acc.: 77.34%] [G loss: 0.655711]\n",
      "epoch:5 step:5511 [D loss: 0.505440, acc.: 75.00%] [G loss: 0.601854]\n",
      "epoch:5 step:5512 [D loss: 0.563827, acc.: 71.88%] [G loss: 0.613526]\n",
      "epoch:5 step:5513 [D loss: 0.622965, acc.: 57.81%] [G loss: 0.470573]\n",
      "epoch:5 step:5514 [D loss: 0.545193, acc.: 68.75%] [G loss: 0.562164]\n",
      "epoch:5 step:5515 [D loss: 0.497059, acc.: 78.91%] [G loss: 0.642293]\n",
      "epoch:5 step:5516 [D loss: 0.604581, acc.: 68.75%] [G loss: 0.544929]\n",
      "epoch:5 step:5517 [D loss: 0.537792, acc.: 71.88%] [G loss: 0.571417]\n",
      "epoch:5 step:5518 [D loss: 0.506669, acc.: 75.00%] [G loss: 0.551844]\n",
      "epoch:5 step:5519 [D loss: 0.502895, acc.: 71.88%] [G loss: 0.549445]\n",
      "epoch:5 step:5520 [D loss: 0.492563, acc.: 75.78%] [G loss: 0.580610]\n",
      "epoch:5 step:5521 [D loss: 0.569498, acc.: 65.62%] [G loss: 0.517066]\n",
      "epoch:5 step:5522 [D loss: 0.490638, acc.: 75.00%] [G loss: 0.562311]\n",
      "epoch:5 step:5523 [D loss: 0.521544, acc.: 69.53%] [G loss: 0.673894]\n",
      "epoch:5 step:5524 [D loss: 0.575552, acc.: 69.53%] [G loss: 0.549285]\n",
      "epoch:5 step:5525 [D loss: 0.603670, acc.: 63.28%] [G loss: 0.471979]\n",
      "epoch:5 step:5526 [D loss: 0.500386, acc.: 73.44%] [G loss: 0.374434]\n",
      "epoch:5 step:5527 [D loss: 0.514484, acc.: 71.88%] [G loss: 0.649578]\n",
      "epoch:5 step:5528 [D loss: 0.584765, acc.: 67.97%] [G loss: 0.511024]\n",
      "epoch:5 step:5529 [D loss: 0.563111, acc.: 72.66%] [G loss: 0.558680]\n",
      "epoch:5 step:5530 [D loss: 0.563052, acc.: 71.09%] [G loss: 0.560958]\n",
      "epoch:5 step:5531 [D loss: 0.519977, acc.: 71.88%] [G loss: 0.561722]\n",
      "epoch:5 step:5532 [D loss: 0.526618, acc.: 75.78%] [G loss: 0.514356]\n",
      "epoch:5 step:5533 [D loss: 0.525105, acc.: 72.66%] [G loss: 0.519458]\n",
      "epoch:5 step:5534 [D loss: 0.547560, acc.: 71.88%] [G loss: 0.511445]\n",
      "epoch:5 step:5535 [D loss: 0.567030, acc.: 71.09%] [G loss: 0.575917]\n",
      "epoch:5 step:5536 [D loss: 0.572605, acc.: 66.41%] [G loss: 0.487980]\n",
      "epoch:5 step:5537 [D loss: 0.514369, acc.: 75.00%] [G loss: 0.559795]\n",
      "epoch:5 step:5538 [D loss: 0.513909, acc.: 74.22%] [G loss: 0.573367]\n",
      "epoch:5 step:5539 [D loss: 0.435987, acc.: 80.47%] [G loss: 0.693600]\n",
      "epoch:5 step:5540 [D loss: 0.472914, acc.: 82.03%] [G loss: 0.664176]\n",
      "epoch:5 step:5541 [D loss: 0.566486, acc.: 71.88%] [G loss: 0.614912]\n",
      "epoch:5 step:5542 [D loss: 0.501486, acc.: 75.78%] [G loss: 0.644083]\n",
      "epoch:5 step:5543 [D loss: 0.664629, acc.: 69.53%] [G loss: 0.622366]\n",
      "epoch:5 step:5544 [D loss: 0.510907, acc.: 76.56%] [G loss: 0.483165]\n",
      "epoch:5 step:5545 [D loss: 0.430370, acc.: 80.47%] [G loss: 0.720922]\n",
      "epoch:5 step:5546 [D loss: 0.632376, acc.: 65.62%] [G loss: 0.589295]\n",
      "epoch:5 step:5547 [D loss: 0.579180, acc.: 67.97%] [G loss: 0.529944]\n",
      "epoch:5 step:5548 [D loss: 0.527964, acc.: 72.66%] [G loss: 0.486347]\n",
      "epoch:5 step:5549 [D loss: 0.508906, acc.: 75.78%] [G loss: 0.515660]\n",
      "epoch:5 step:5550 [D loss: 0.520072, acc.: 71.09%] [G loss: 0.580654]\n",
      "epoch:5 step:5551 [D loss: 0.543012, acc.: 71.09%] [G loss: 0.603726]\n",
      "epoch:5 step:5552 [D loss: 0.605944, acc.: 70.31%] [G loss: 0.578350]\n",
      "epoch:5 step:5553 [D loss: 0.561785, acc.: 68.75%] [G loss: 0.629989]\n",
      "epoch:5 step:5554 [D loss: 0.525896, acc.: 68.75%] [G loss: 0.680256]\n",
      "epoch:5 step:5555 [D loss: 0.464351, acc.: 78.91%] [G loss: 0.754233]\n",
      "epoch:5 step:5556 [D loss: 0.477257, acc.: 77.34%] [G loss: 0.614910]\n",
      "epoch:5 step:5557 [D loss: 0.492356, acc.: 71.09%] [G loss: 0.472141]\n",
      "epoch:5 step:5558 [D loss: 0.590098, acc.: 68.75%] [G loss: 0.485325]\n",
      "epoch:5 step:5559 [D loss: 0.542847, acc.: 66.41%] [G loss: 0.538734]\n",
      "epoch:5 step:5560 [D loss: 0.459547, acc.: 80.47%] [G loss: 0.614149]\n",
      "epoch:5 step:5561 [D loss: 0.559528, acc.: 67.19%] [G loss: 0.577922]\n",
      "epoch:5 step:5562 [D loss: 0.459483, acc.: 81.25%] [G loss: 0.621504]\n",
      "epoch:5 step:5563 [D loss: 0.521637, acc.: 70.31%] [G loss: 0.447085]\n",
      "epoch:5 step:5564 [D loss: 0.532643, acc.: 68.75%] [G loss: 0.473547]\n",
      "epoch:5 step:5565 [D loss: 0.630443, acc.: 64.06%] [G loss: 0.432124]\n",
      "epoch:5 step:5566 [D loss: 0.531298, acc.: 71.09%] [G loss: 0.515592]\n",
      "epoch:5 step:5567 [D loss: 0.517336, acc.: 78.91%] [G loss: 0.425969]\n",
      "epoch:5 step:5568 [D loss: 0.565801, acc.: 66.41%] [G loss: 0.465164]\n",
      "epoch:5 step:5569 [D loss: 0.414977, acc.: 85.16%] [G loss: 0.606522]\n",
      "epoch:5 step:5570 [D loss: 0.472398, acc.: 76.56%] [G loss: 0.600690]\n",
      "epoch:5 step:5571 [D loss: 0.475590, acc.: 74.22%] [G loss: 0.771186]\n",
      "epoch:5 step:5572 [D loss: 0.479068, acc.: 78.91%] [G loss: 0.850697]\n",
      "epoch:5 step:5573 [D loss: 0.501270, acc.: 73.44%] [G loss: 0.819076]\n",
      "epoch:5 step:5574 [D loss: 0.512144, acc.: 73.44%] [G loss: 0.622507]\n",
      "epoch:5 step:5575 [D loss: 0.403243, acc.: 85.16%] [G loss: 0.874924]\n",
      "epoch:5 step:5576 [D loss: 0.520897, acc.: 75.00%] [G loss: 0.748770]\n",
      "epoch:5 step:5577 [D loss: 0.625267, acc.: 67.97%] [G loss: 0.550410]\n",
      "epoch:5 step:5578 [D loss: 0.552012, acc.: 68.75%] [G loss: 0.513791]\n",
      "epoch:5 step:5579 [D loss: 0.464973, acc.: 82.81%] [G loss: 0.848836]\n",
      "epoch:5 step:5580 [D loss: 0.492937, acc.: 75.00%] [G loss: 0.967507]\n",
      "epoch:5 step:5581 [D loss: 0.512012, acc.: 75.00%] [G loss: 0.660829]\n",
      "epoch:5 step:5582 [D loss: 0.480602, acc.: 76.56%] [G loss: 0.599385]\n",
      "epoch:5 step:5583 [D loss: 0.408223, acc.: 85.16%] [G loss: 0.687304]\n",
      "epoch:5 step:5584 [D loss: 0.487737, acc.: 78.91%] [G loss: 0.622309]\n",
      "epoch:5 step:5585 [D loss: 0.471258, acc.: 78.12%] [G loss: 0.678375]\n",
      "epoch:5 step:5586 [D loss: 0.556830, acc.: 69.53%] [G loss: 0.585088]\n",
      "epoch:5 step:5587 [D loss: 0.520302, acc.: 73.44%] [G loss: 0.624450]\n",
      "epoch:5 step:5588 [D loss: 0.567222, acc.: 67.97%] [G loss: 0.649546]\n",
      "epoch:5 step:5589 [D loss: 0.512981, acc.: 77.34%] [G loss: 0.629673]\n",
      "epoch:5 step:5590 [D loss: 0.546957, acc.: 70.31%] [G loss: 0.578116]\n",
      "epoch:5 step:5591 [D loss: 0.462710, acc.: 85.16%] [G loss: 0.684531]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:5 step:5592 [D loss: 0.552051, acc.: 70.31%] [G loss: 0.539912]\n",
      "epoch:5 step:5593 [D loss: 0.499328, acc.: 73.44%] [G loss: 0.677694]\n",
      "epoch:5 step:5594 [D loss: 0.510552, acc.: 72.66%] [G loss: 0.713410]\n",
      "epoch:5 step:5595 [D loss: 0.482880, acc.: 74.22%] [G loss: 0.648870]\n",
      "epoch:5 step:5596 [D loss: 0.418961, acc.: 80.47%] [G loss: 0.812656]\n",
      "epoch:5 step:5597 [D loss: 0.430680, acc.: 85.16%] [G loss: 0.692183]\n",
      "epoch:5 step:5598 [D loss: 0.555920, acc.: 71.09%] [G loss: 0.827064]\n",
      "epoch:5 step:5599 [D loss: 0.494273, acc.: 75.00%] [G loss: 0.847053]\n",
      "epoch:5 step:5600 [D loss: 0.560317, acc.: 71.88%] [G loss: 0.759126]\n",
      "epoch:5 step:5601 [D loss: 0.498804, acc.: 78.91%] [G loss: 0.734443]\n",
      "epoch:5 step:5602 [D loss: 0.570473, acc.: 63.28%] [G loss: 0.639009]\n",
      "epoch:5 step:5603 [D loss: 0.490080, acc.: 77.34%] [G loss: 0.805633]\n",
      "epoch:5 step:5604 [D loss: 0.466885, acc.: 78.12%] [G loss: 0.858287]\n",
      "epoch:5 step:5605 [D loss: 0.590669, acc.: 68.75%] [G loss: 0.653889]\n",
      "epoch:5 step:5606 [D loss: 0.446287, acc.: 81.25%] [G loss: 0.859952]\n",
      "epoch:5 step:5607 [D loss: 0.562845, acc.: 76.56%] [G loss: 0.503354]\n",
      "epoch:5 step:5608 [D loss: 0.466494, acc.: 76.56%] [G loss: 0.686019]\n",
      "epoch:5 step:5609 [D loss: 0.446831, acc.: 79.69%] [G loss: 0.802149]\n",
      "epoch:5 step:5610 [D loss: 0.417242, acc.: 82.81%] [G loss: 0.914058]\n",
      "epoch:5 step:5611 [D loss: 0.425326, acc.: 83.59%] [G loss: 1.010042]\n",
      "epoch:5 step:5612 [D loss: 0.510055, acc.: 75.00%] [G loss: 1.009866]\n",
      "epoch:5 step:5613 [D loss: 0.665854, acc.: 63.28%] [G loss: 0.839406]\n",
      "epoch:5 step:5614 [D loss: 0.507196, acc.: 76.56%] [G loss: 1.053742]\n",
      "epoch:5 step:5615 [D loss: 0.438735, acc.: 80.47%] [G loss: 0.970711]\n",
      "epoch:5 step:5616 [D loss: 0.431797, acc.: 79.69%] [G loss: 0.954673]\n",
      "epoch:5 step:5617 [D loss: 0.574397, acc.: 67.97%] [G loss: 0.907274]\n",
      "epoch:5 step:5618 [D loss: 0.472302, acc.: 76.56%] [G loss: 0.823033]\n",
      "epoch:5 step:5619 [D loss: 0.528522, acc.: 72.66%] [G loss: 0.729301]\n",
      "epoch:5 step:5620 [D loss: 0.519115, acc.: 71.88%] [G loss: 0.964417]\n",
      "epoch:5 step:5621 [D loss: 0.395088, acc.: 83.59%] [G loss: 1.002064]\n",
      "epoch:5 step:5622 [D loss: 0.465031, acc.: 83.59%] [G loss: 1.091843]\n",
      "epoch:6 step:5623 [D loss: 0.542549, acc.: 75.00%] [G loss: 0.972906]\n",
      "epoch:6 step:5624 [D loss: 0.491659, acc.: 80.47%] [G loss: 1.067718]\n",
      "epoch:6 step:5625 [D loss: 0.617825, acc.: 67.97%] [G loss: 0.772908]\n",
      "epoch:6 step:5626 [D loss: 0.484124, acc.: 74.22%] [G loss: 0.835211]\n",
      "epoch:6 step:5627 [D loss: 0.525462, acc.: 71.09%] [G loss: 0.814550]\n",
      "epoch:6 step:5628 [D loss: 0.498793, acc.: 71.88%] [G loss: 0.924144]\n",
      "epoch:6 step:5629 [D loss: 0.519786, acc.: 74.22%] [G loss: 0.834499]\n",
      "epoch:6 step:5630 [D loss: 0.515461, acc.: 73.44%] [G loss: 0.717191]\n",
      "epoch:6 step:5631 [D loss: 0.573968, acc.: 70.31%] [G loss: 0.572834]\n",
      "epoch:6 step:5632 [D loss: 0.528275, acc.: 71.88%] [G loss: 0.647873]\n",
      "epoch:6 step:5633 [D loss: 0.472957, acc.: 81.25%] [G loss: 0.721882]\n",
      "epoch:6 step:5634 [D loss: 0.492789, acc.: 74.22%] [G loss: 0.653877]\n",
      "epoch:6 step:5635 [D loss: 0.584527, acc.: 60.94%] [G loss: 0.468767]\n",
      "epoch:6 step:5636 [D loss: 0.528137, acc.: 74.22%] [G loss: 0.563990]\n",
      "epoch:6 step:5637 [D loss: 0.463408, acc.: 80.47%] [G loss: 0.743555]\n",
      "epoch:6 step:5638 [D loss: 0.499208, acc.: 75.00%] [G loss: 0.703074]\n",
      "epoch:6 step:5639 [D loss: 0.564729, acc.: 68.75%] [G loss: 0.575734]\n",
      "epoch:6 step:5640 [D loss: 0.582129, acc.: 71.88%] [G loss: 0.668063]\n",
      "epoch:6 step:5641 [D loss: 0.534271, acc.: 71.88%] [G loss: 0.746927]\n",
      "epoch:6 step:5642 [D loss: 0.560723, acc.: 70.31%] [G loss: 0.669261]\n",
      "epoch:6 step:5643 [D loss: 0.492439, acc.: 78.91%] [G loss: 0.630262]\n",
      "epoch:6 step:5644 [D loss: 0.523530, acc.: 71.09%] [G loss: 0.592855]\n",
      "epoch:6 step:5645 [D loss: 0.498591, acc.: 72.66%] [G loss: 0.715428]\n",
      "epoch:6 step:5646 [D loss: 0.529909, acc.: 71.88%] [G loss: 0.528759]\n",
      "epoch:6 step:5647 [D loss: 0.544688, acc.: 71.88%] [G loss: 0.689417]\n",
      "epoch:6 step:5648 [D loss: 0.507865, acc.: 74.22%] [G loss: 0.688248]\n",
      "epoch:6 step:5649 [D loss: 0.421348, acc.: 80.47%] [G loss: 0.783903]\n",
      "epoch:6 step:5650 [D loss: 0.494410, acc.: 74.22%] [G loss: 0.738913]\n",
      "epoch:6 step:5651 [D loss: 0.560175, acc.: 62.50%] [G loss: 0.550648]\n",
      "epoch:6 step:5652 [D loss: 0.530786, acc.: 72.66%] [G loss: 0.608462]\n",
      "epoch:6 step:5653 [D loss: 0.594999, acc.: 62.50%] [G loss: 0.599840]\n",
      "epoch:6 step:5654 [D loss: 0.539508, acc.: 70.31%] [G loss: 0.647916]\n",
      "epoch:6 step:5655 [D loss: 0.491430, acc.: 80.47%] [G loss: 0.617227]\n",
      "epoch:6 step:5656 [D loss: 0.479345, acc.: 75.78%] [G loss: 0.655266]\n",
      "epoch:6 step:5657 [D loss: 0.456250, acc.: 81.25%] [G loss: 0.676443]\n",
      "epoch:6 step:5658 [D loss: 0.468559, acc.: 76.56%] [G loss: 0.865674]\n",
      "epoch:6 step:5659 [D loss: 0.459690, acc.: 80.47%] [G loss: 0.725683]\n",
      "epoch:6 step:5660 [D loss: 0.620683, acc.: 65.62%] [G loss: 0.600833]\n",
      "epoch:6 step:5661 [D loss: 0.508243, acc.: 75.78%] [G loss: 0.642777]\n",
      "epoch:6 step:5662 [D loss: 0.430001, acc.: 82.03%] [G loss: 0.786027]\n",
      "epoch:6 step:5663 [D loss: 0.535463, acc.: 67.19%] [G loss: 0.692317]\n",
      "epoch:6 step:5664 [D loss: 0.519801, acc.: 75.78%] [G loss: 0.612547]\n",
      "epoch:6 step:5665 [D loss: 0.473067, acc.: 79.69%] [G loss: 0.620521]\n",
      "epoch:6 step:5666 [D loss: 0.543548, acc.: 70.31%] [G loss: 0.594007]\n",
      "epoch:6 step:5667 [D loss: 0.520201, acc.: 72.66%] [G loss: 0.633879]\n",
      "epoch:6 step:5668 [D loss: 0.457745, acc.: 82.81%] [G loss: 0.613424]\n",
      "epoch:6 step:5669 [D loss: 0.512573, acc.: 74.22%] [G loss: 0.743109]\n",
      "epoch:6 step:5670 [D loss: 0.530269, acc.: 72.66%] [G loss: 0.698141]\n",
      "epoch:6 step:5671 [D loss: 0.464079, acc.: 83.59%] [G loss: 0.749109]\n",
      "epoch:6 step:5672 [D loss: 0.538189, acc.: 75.78%] [G loss: 0.627400]\n",
      "epoch:6 step:5673 [D loss: 0.571824, acc.: 69.53%] [G loss: 0.428206]\n",
      "epoch:6 step:5674 [D loss: 0.561068, acc.: 70.31%] [G loss: 0.481068]\n",
      "epoch:6 step:5675 [D loss: 0.455608, acc.: 78.91%] [G loss: 0.623914]\n",
      "epoch:6 step:5676 [D loss: 0.452367, acc.: 79.69%] [G loss: 0.878033]\n",
      "epoch:6 step:5677 [D loss: 0.478309, acc.: 78.12%] [G loss: 0.744698]\n",
      "epoch:6 step:5678 [D loss: 0.573870, acc.: 65.62%] [G loss: 0.611650]\n",
      "epoch:6 step:5679 [D loss: 0.508947, acc.: 72.66%] [G loss: 0.831376]\n",
      "epoch:6 step:5680 [D loss: 0.459815, acc.: 78.91%] [G loss: 0.812627]\n",
      "epoch:6 step:5681 [D loss: 0.430721, acc.: 82.81%] [G loss: 0.777246]\n",
      "epoch:6 step:5682 [D loss: 0.540944, acc.: 74.22%] [G loss: 0.785555]\n",
      "epoch:6 step:5683 [D loss: 0.532921, acc.: 69.53%] [G loss: 0.735280]\n",
      "epoch:6 step:5684 [D loss: 0.546158, acc.: 71.09%] [G loss: 0.707637]\n",
      "epoch:6 step:5685 [D loss: 0.513070, acc.: 76.56%] [G loss: 0.458937]\n",
      "epoch:6 step:5686 [D loss: 0.558763, acc.: 70.31%] [G loss: 0.517769]\n",
      "epoch:6 step:5687 [D loss: 0.528144, acc.: 76.56%] [G loss: 0.544972]\n",
      "epoch:6 step:5688 [D loss: 0.516289, acc.: 74.22%] [G loss: 0.488806]\n",
      "epoch:6 step:5689 [D loss: 0.542428, acc.: 71.09%] [G loss: 0.577615]\n",
      "epoch:6 step:5690 [D loss: 0.505304, acc.: 75.00%] [G loss: 0.615914]\n",
      "epoch:6 step:5691 [D loss: 0.492991, acc.: 75.78%] [G loss: 0.664603]\n",
      "epoch:6 step:5692 [D loss: 0.588223, acc.: 70.31%] [G loss: 0.572164]\n",
      "epoch:6 step:5693 [D loss: 0.534634, acc.: 71.09%] [G loss: 0.617966]\n",
      "epoch:6 step:5694 [D loss: 0.452924, acc.: 81.25%] [G loss: 0.700541]\n",
      "epoch:6 step:5695 [D loss: 0.517120, acc.: 76.56%] [G loss: 0.595391]\n",
      "epoch:6 step:5696 [D loss: 0.449987, acc.: 80.47%] [G loss: 0.731709]\n",
      "epoch:6 step:5697 [D loss: 0.500599, acc.: 77.34%] [G loss: 0.692805]\n",
      "epoch:6 step:5698 [D loss: 0.490000, acc.: 73.44%] [G loss: 0.647528]\n",
      "epoch:6 step:5699 [D loss: 0.392400, acc.: 82.81%] [G loss: 0.854554]\n",
      "epoch:6 step:5700 [D loss: 0.583347, acc.: 67.97%] [G loss: 0.604657]\n",
      "epoch:6 step:5701 [D loss: 0.506163, acc.: 74.22%] [G loss: 0.559686]\n",
      "epoch:6 step:5702 [D loss: 0.499328, acc.: 75.78%] [G loss: 0.623926]\n",
      "epoch:6 step:5703 [D loss: 0.581590, acc.: 67.19%] [G loss: 0.544788]\n",
      "epoch:6 step:5704 [D loss: 0.532345, acc.: 70.31%] [G loss: 0.694964]\n",
      "epoch:6 step:5705 [D loss: 0.464062, acc.: 77.34%] [G loss: 0.796671]\n",
      "epoch:6 step:5706 [D loss: 0.537624, acc.: 67.19%] [G loss: 0.634432]\n",
      "epoch:6 step:5707 [D loss: 0.521976, acc.: 74.22%] [G loss: 0.707655]\n",
      "epoch:6 step:5708 [D loss: 0.500145, acc.: 75.00%] [G loss: 0.555971]\n",
      "epoch:6 step:5709 [D loss: 0.500876, acc.: 74.22%] [G loss: 0.546277]\n",
      "epoch:6 step:5710 [D loss: 0.467640, acc.: 78.12%] [G loss: 0.738293]\n",
      "epoch:6 step:5711 [D loss: 0.507194, acc.: 77.34%] [G loss: 0.776678]\n",
      "epoch:6 step:5712 [D loss: 0.510976, acc.: 71.09%] [G loss: 0.697355]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:6 step:5713 [D loss: 0.525063, acc.: 75.00%] [G loss: 0.751288]\n",
      "epoch:6 step:5714 [D loss: 0.466845, acc.: 78.91%] [G loss: 0.700399]\n",
      "epoch:6 step:5715 [D loss: 0.494717, acc.: 76.56%] [G loss: 0.876324]\n",
      "epoch:6 step:5716 [D loss: 0.502096, acc.: 76.56%] [G loss: 0.643810]\n",
      "epoch:6 step:5717 [D loss: 0.484517, acc.: 76.56%] [G loss: 0.675448]\n",
      "epoch:6 step:5718 [D loss: 0.467411, acc.: 78.12%] [G loss: 0.586171]\n",
      "epoch:6 step:5719 [D loss: 0.487806, acc.: 76.56%] [G loss: 0.710419]\n",
      "epoch:6 step:5720 [D loss: 0.560661, acc.: 66.41%] [G loss: 0.666296]\n",
      "epoch:6 step:5721 [D loss: 0.505151, acc.: 82.03%] [G loss: 0.759447]\n",
      "epoch:6 step:5722 [D loss: 0.476342, acc.: 74.22%] [G loss: 0.821460]\n",
      "epoch:6 step:5723 [D loss: 0.468328, acc.: 82.03%] [G loss: 0.745964]\n",
      "epoch:6 step:5724 [D loss: 0.690644, acc.: 58.59%] [G loss: 0.554443]\n",
      "epoch:6 step:5725 [D loss: 0.488444, acc.: 73.44%] [G loss: 0.600908]\n",
      "epoch:6 step:5726 [D loss: 0.510864, acc.: 71.09%] [G loss: 0.651105]\n",
      "epoch:6 step:5727 [D loss: 0.560700, acc.: 66.41%] [G loss: 0.688149]\n",
      "epoch:6 step:5728 [D loss: 0.532039, acc.: 73.44%] [G loss: 0.626004]\n",
      "epoch:6 step:5729 [D loss: 0.571020, acc.: 66.41%] [G loss: 0.613955]\n",
      "epoch:6 step:5730 [D loss: 0.568465, acc.: 67.19%] [G loss: 0.667124]\n",
      "epoch:6 step:5731 [D loss: 0.571518, acc.: 69.53%] [G loss: 0.605346]\n",
      "epoch:6 step:5732 [D loss: 0.502540, acc.: 71.09%] [G loss: 0.632415]\n",
      "epoch:6 step:5733 [D loss: 0.490815, acc.: 74.22%] [G loss: 0.710831]\n",
      "epoch:6 step:5734 [D loss: 0.552609, acc.: 72.66%] [G loss: 0.692589]\n",
      "epoch:6 step:5735 [D loss: 0.576194, acc.: 71.09%] [G loss: 0.682109]\n",
      "epoch:6 step:5736 [D loss: 0.578186, acc.: 66.41%] [G loss: 0.600681]\n",
      "epoch:6 step:5737 [D loss: 0.543083, acc.: 72.66%] [G loss: 0.654389]\n",
      "epoch:6 step:5738 [D loss: 0.494100, acc.: 76.56%] [G loss: 0.664721]\n",
      "epoch:6 step:5739 [D loss: 0.471769, acc.: 76.56%] [G loss: 0.687302]\n",
      "epoch:6 step:5740 [D loss: 0.495571, acc.: 72.66%] [G loss: 0.882903]\n",
      "epoch:6 step:5741 [D loss: 0.445275, acc.: 82.03%] [G loss: 0.833341]\n",
      "epoch:6 step:5742 [D loss: 0.657309, acc.: 63.28%] [G loss: 0.635046]\n",
      "epoch:6 step:5743 [D loss: 0.548275, acc.: 68.75%] [G loss: 0.576993]\n",
      "epoch:6 step:5744 [D loss: 0.549125, acc.: 70.31%] [G loss: 0.682981]\n",
      "epoch:6 step:5745 [D loss: 0.573443, acc.: 71.09%] [G loss: 0.631956]\n",
      "epoch:6 step:5746 [D loss: 0.495938, acc.: 78.12%] [G loss: 0.723721]\n",
      "epoch:6 step:5747 [D loss: 0.521528, acc.: 75.00%] [G loss: 0.786571]\n",
      "epoch:6 step:5748 [D loss: 0.540341, acc.: 71.88%] [G loss: 0.624327]\n",
      "epoch:6 step:5749 [D loss: 0.488222, acc.: 77.34%] [G loss: 0.595283]\n",
      "epoch:6 step:5750 [D loss: 0.514861, acc.: 71.88%] [G loss: 0.562739]\n",
      "epoch:6 step:5751 [D loss: 0.576677, acc.: 70.31%] [G loss: 0.519846]\n",
      "epoch:6 step:5752 [D loss: 0.503841, acc.: 75.78%] [G loss: 0.525862]\n",
      "epoch:6 step:5753 [D loss: 0.486953, acc.: 80.47%] [G loss: 0.651448]\n",
      "epoch:6 step:5754 [D loss: 0.517493, acc.: 74.22%] [G loss: 0.629109]\n",
      "epoch:6 step:5755 [D loss: 0.535989, acc.: 71.88%] [G loss: 0.624193]\n",
      "epoch:6 step:5756 [D loss: 0.503791, acc.: 71.09%] [G loss: 0.530502]\n",
      "epoch:6 step:5757 [D loss: 0.531793, acc.: 75.00%] [G loss: 0.624865]\n",
      "epoch:6 step:5758 [D loss: 0.528219, acc.: 78.12%] [G loss: 0.646615]\n",
      "epoch:6 step:5759 [D loss: 0.587638, acc.: 68.75%] [G loss: 0.595749]\n",
      "epoch:6 step:5760 [D loss: 0.576484, acc.: 63.28%] [G loss: 0.549499]\n",
      "epoch:6 step:5761 [D loss: 0.522256, acc.: 75.00%] [G loss: 0.768974]\n",
      "epoch:6 step:5762 [D loss: 0.607300, acc.: 64.06%] [G loss: 0.529971]\n",
      "epoch:6 step:5763 [D loss: 0.480456, acc.: 75.00%] [G loss: 0.517263]\n",
      "epoch:6 step:5764 [D loss: 0.488756, acc.: 75.78%] [G loss: 0.674045]\n",
      "epoch:6 step:5765 [D loss: 0.618262, acc.: 66.41%] [G loss: 0.518004]\n",
      "epoch:6 step:5766 [D loss: 0.507506, acc.: 75.78%] [G loss: 0.725011]\n",
      "epoch:6 step:5767 [D loss: 0.525108, acc.: 75.00%] [G loss: 0.856583]\n",
      "epoch:6 step:5768 [D loss: 0.485806, acc.: 75.00%] [G loss: 0.791322]\n",
      "epoch:6 step:5769 [D loss: 0.564037, acc.: 72.66%] [G loss: 0.661677]\n",
      "epoch:6 step:5770 [D loss: 0.498124, acc.: 75.00%] [G loss: 0.664605]\n",
      "epoch:6 step:5771 [D loss: 0.476722, acc.: 78.91%] [G loss: 0.835918]\n",
      "epoch:6 step:5772 [D loss: 0.562311, acc.: 73.44%] [G loss: 0.542262]\n",
      "epoch:6 step:5773 [D loss: 0.523143, acc.: 71.09%] [G loss: 0.685215]\n",
      "epoch:6 step:5774 [D loss: 0.500033, acc.: 76.56%] [G loss: 0.664629]\n",
      "epoch:6 step:5775 [D loss: 0.568094, acc.: 69.53%] [G loss: 0.588247]\n",
      "epoch:6 step:5776 [D loss: 0.523011, acc.: 71.09%] [G loss: 0.678054]\n",
      "epoch:6 step:5777 [D loss: 0.472336, acc.: 79.69%] [G loss: 0.757107]\n",
      "epoch:6 step:5778 [D loss: 0.519206, acc.: 74.22%] [G loss: 0.869455]\n",
      "epoch:6 step:5779 [D loss: 0.527129, acc.: 73.44%] [G loss: 0.757442]\n",
      "epoch:6 step:5780 [D loss: 0.563643, acc.: 64.84%] [G loss: 0.529575]\n",
      "epoch:6 step:5781 [D loss: 0.524124, acc.: 73.44%] [G loss: 0.600272]\n",
      "epoch:6 step:5782 [D loss: 0.566497, acc.: 71.09%] [G loss: 0.743415]\n",
      "epoch:6 step:5783 [D loss: 0.445425, acc.: 77.34%] [G loss: 0.688313]\n",
      "epoch:6 step:5784 [D loss: 0.441107, acc.: 79.69%] [G loss: 0.893566]\n",
      "epoch:6 step:5785 [D loss: 0.554728, acc.: 67.97%] [G loss: 0.634266]\n",
      "epoch:6 step:5786 [D loss: 0.511601, acc.: 70.31%] [G loss: 0.649193]\n",
      "epoch:6 step:5787 [D loss: 0.529299, acc.: 77.34%] [G loss: 0.543003]\n",
      "epoch:6 step:5788 [D loss: 0.548316, acc.: 69.53%] [G loss: 0.547240]\n",
      "epoch:6 step:5789 [D loss: 0.493254, acc.: 78.12%] [G loss: 0.675235]\n",
      "epoch:6 step:5790 [D loss: 0.580826, acc.: 68.75%] [G loss: 0.706025]\n",
      "epoch:6 step:5791 [D loss: 0.589501, acc.: 67.97%] [G loss: 0.612190]\n",
      "epoch:6 step:5792 [D loss: 0.545729, acc.: 73.44%] [G loss: 0.460689]\n",
      "epoch:6 step:5793 [D loss: 0.545521, acc.: 69.53%] [G loss: 0.614346]\n",
      "epoch:6 step:5794 [D loss: 0.497029, acc.: 75.00%] [G loss: 0.799803]\n",
      "epoch:6 step:5795 [D loss: 0.513809, acc.: 73.44%] [G loss: 0.607397]\n",
      "epoch:6 step:5796 [D loss: 0.569839, acc.: 67.19%] [G loss: 0.557335]\n",
      "epoch:6 step:5797 [D loss: 0.552810, acc.: 70.31%] [G loss: 0.630759]\n",
      "epoch:6 step:5798 [D loss: 0.551017, acc.: 69.53%] [G loss: 0.636142]\n",
      "epoch:6 step:5799 [D loss: 0.481995, acc.: 76.56%] [G loss: 0.654309]\n",
      "epoch:6 step:5800 [D loss: 0.582869, acc.: 71.09%] [G loss: 0.485027]\n",
      "epoch:6 step:5801 [D loss: 0.518610, acc.: 73.44%] [G loss: 0.548071]\n",
      "epoch:6 step:5802 [D loss: 0.569784, acc.: 71.09%] [G loss: 0.561301]\n",
      "epoch:6 step:5803 [D loss: 0.571905, acc.: 67.97%] [G loss: 0.533120]\n",
      "epoch:6 step:5804 [D loss: 0.560243, acc.: 70.31%] [G loss: 0.595542]\n",
      "epoch:6 step:5805 [D loss: 0.557705, acc.: 70.31%] [G loss: 0.573478]\n",
      "epoch:6 step:5806 [D loss: 0.579633, acc.: 66.41%] [G loss: 0.612387]\n",
      "epoch:6 step:5807 [D loss: 0.614627, acc.: 64.84%] [G loss: 0.567767]\n",
      "epoch:6 step:5808 [D loss: 0.610487, acc.: 60.94%] [G loss: 0.482247]\n",
      "epoch:6 step:5809 [D loss: 0.546629, acc.: 71.09%] [G loss: 0.657841]\n",
      "epoch:6 step:5810 [D loss: 0.544965, acc.: 71.09%] [G loss: 0.669620]\n",
      "epoch:6 step:5811 [D loss: 0.575872, acc.: 68.75%] [G loss: 0.401191]\n",
      "epoch:6 step:5812 [D loss: 0.508114, acc.: 76.56%] [G loss: 0.599280]\n",
      "epoch:6 step:5813 [D loss: 0.521093, acc.: 77.34%] [G loss: 0.759277]\n",
      "epoch:6 step:5814 [D loss: 0.489382, acc.: 77.34%] [G loss: 0.737426]\n",
      "epoch:6 step:5815 [D loss: 0.567151, acc.: 70.31%] [G loss: 0.683429]\n",
      "epoch:6 step:5816 [D loss: 0.432756, acc.: 83.59%] [G loss: 0.731399]\n",
      "epoch:6 step:5817 [D loss: 0.518936, acc.: 71.88%] [G loss: 0.816821]\n",
      "epoch:6 step:5818 [D loss: 0.606198, acc.: 66.41%] [G loss: 0.631939]\n",
      "epoch:6 step:5819 [D loss: 0.501715, acc.: 78.91%] [G loss: 0.769836]\n",
      "epoch:6 step:5820 [D loss: 0.497352, acc.: 76.56%] [G loss: 0.749797]\n",
      "epoch:6 step:5821 [D loss: 0.521438, acc.: 76.56%] [G loss: 0.726007]\n",
      "epoch:6 step:5822 [D loss: 0.561719, acc.: 66.41%] [G loss: 0.666721]\n",
      "epoch:6 step:5823 [D loss: 0.576599, acc.: 67.97%] [G loss: 0.671113]\n",
      "epoch:6 step:5824 [D loss: 0.540513, acc.: 70.31%] [G loss: 0.715459]\n",
      "epoch:6 step:5825 [D loss: 0.595967, acc.: 72.66%] [G loss: 0.475669]\n",
      "epoch:6 step:5826 [D loss: 0.518979, acc.: 73.44%] [G loss: 0.537113]\n",
      "epoch:6 step:5827 [D loss: 0.580650, acc.: 68.75%] [G loss: 0.625813]\n",
      "epoch:6 step:5828 [D loss: 0.545997, acc.: 70.31%] [G loss: 0.626547]\n",
      "epoch:6 step:5829 [D loss: 0.448643, acc.: 81.25%] [G loss: 0.763084]\n",
      "epoch:6 step:5830 [D loss: 0.414490, acc.: 85.16%] [G loss: 0.736678]\n",
      "epoch:6 step:5831 [D loss: 0.481280, acc.: 81.25%] [G loss: 0.627749]\n",
      "epoch:6 step:5832 [D loss: 0.595971, acc.: 66.41%] [G loss: 0.584876]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:6 step:5833 [D loss: 0.581579, acc.: 71.09%] [G loss: 0.390972]\n",
      "epoch:6 step:5834 [D loss: 0.499641, acc.: 78.91%] [G loss: 0.522882]\n",
      "epoch:6 step:5835 [D loss: 0.503715, acc.: 75.78%] [G loss: 0.528717]\n",
      "epoch:6 step:5836 [D loss: 0.621660, acc.: 66.41%] [G loss: 0.426632]\n",
      "epoch:6 step:5837 [D loss: 0.569551, acc.: 68.75%] [G loss: 0.521633]\n",
      "epoch:6 step:5838 [D loss: 0.538092, acc.: 71.88%] [G loss: 0.524455]\n",
      "epoch:6 step:5839 [D loss: 0.496165, acc.: 71.09%] [G loss: 0.650178]\n",
      "epoch:6 step:5840 [D loss: 0.482755, acc.: 78.91%] [G loss: 0.621982]\n",
      "epoch:6 step:5841 [D loss: 0.474372, acc.: 75.78%] [G loss: 0.765319]\n",
      "epoch:6 step:5842 [D loss: 0.696195, acc.: 64.84%] [G loss: 0.558133]\n",
      "epoch:6 step:5843 [D loss: 0.496782, acc.: 78.12%] [G loss: 0.722998]\n",
      "epoch:6 step:5844 [D loss: 0.430988, acc.: 78.91%] [G loss: 0.918718]\n",
      "epoch:6 step:5845 [D loss: 0.473108, acc.: 76.56%] [G loss: 0.911761]\n",
      "epoch:6 step:5846 [D loss: 0.643052, acc.: 68.75%] [G loss: 0.622986]\n",
      "epoch:6 step:5847 [D loss: 0.579181, acc.: 67.97%] [G loss: 0.547007]\n",
      "epoch:6 step:5848 [D loss: 0.590241, acc.: 64.84%] [G loss: 0.463608]\n",
      "epoch:6 step:5849 [D loss: 0.522766, acc.: 73.44%] [G loss: 0.555452]\n",
      "epoch:6 step:5850 [D loss: 0.539035, acc.: 69.53%] [G loss: 0.562635]\n",
      "epoch:6 step:5851 [D loss: 0.484957, acc.: 77.34%] [G loss: 0.514765]\n",
      "epoch:6 step:5852 [D loss: 0.434015, acc.: 79.69%] [G loss: 0.769606]\n",
      "epoch:6 step:5853 [D loss: 0.490385, acc.: 78.91%] [G loss: 0.728462]\n",
      "epoch:6 step:5854 [D loss: 0.436932, acc.: 83.59%] [G loss: 0.920619]\n",
      "epoch:6 step:5855 [D loss: 0.565895, acc.: 74.22%] [G loss: 0.730132]\n",
      "epoch:6 step:5856 [D loss: 0.528714, acc.: 73.44%] [G loss: 0.579865]\n",
      "epoch:6 step:5857 [D loss: 0.494517, acc.: 75.78%] [G loss: 0.750745]\n",
      "epoch:6 step:5858 [D loss: 0.527770, acc.: 67.97%] [G loss: 0.621944]\n",
      "epoch:6 step:5859 [D loss: 0.520880, acc.: 76.56%] [G loss: 0.669695]\n",
      "epoch:6 step:5860 [D loss: 0.528408, acc.: 75.00%] [G loss: 0.646731]\n",
      "epoch:6 step:5861 [D loss: 0.514616, acc.: 69.53%] [G loss: 0.631972]\n",
      "epoch:6 step:5862 [D loss: 0.525020, acc.: 74.22%] [G loss: 0.612471]\n",
      "epoch:6 step:5863 [D loss: 0.535955, acc.: 74.22%] [G loss: 0.524682]\n",
      "epoch:6 step:5864 [D loss: 0.497149, acc.: 73.44%] [G loss: 0.725593]\n",
      "epoch:6 step:5865 [D loss: 0.569164, acc.: 67.97%] [G loss: 0.577396]\n",
      "epoch:6 step:5866 [D loss: 0.492091, acc.: 72.66%] [G loss: 0.549914]\n",
      "epoch:6 step:5867 [D loss: 0.536043, acc.: 71.09%] [G loss: 0.571379]\n",
      "epoch:6 step:5868 [D loss: 0.499875, acc.: 75.78%] [G loss: 0.701594]\n",
      "epoch:6 step:5869 [D loss: 0.562651, acc.: 67.97%] [G loss: 0.724977]\n",
      "epoch:6 step:5870 [D loss: 0.539770, acc.: 69.53%] [G loss: 0.685709]\n",
      "epoch:6 step:5871 [D loss: 0.547527, acc.: 67.97%] [G loss: 0.579480]\n",
      "epoch:6 step:5872 [D loss: 0.628006, acc.: 60.16%] [G loss: 0.475697]\n",
      "epoch:6 step:5873 [D loss: 0.567717, acc.: 71.88%] [G loss: 0.497717]\n",
      "epoch:6 step:5874 [D loss: 0.561312, acc.: 74.22%] [G loss: 0.609867]\n",
      "epoch:6 step:5875 [D loss: 0.496860, acc.: 76.56%] [G loss: 0.568949]\n",
      "epoch:6 step:5876 [D loss: 0.449420, acc.: 77.34%] [G loss: 0.714432]\n",
      "epoch:6 step:5877 [D loss: 0.496566, acc.: 71.88%] [G loss: 0.709683]\n",
      "epoch:6 step:5878 [D loss: 0.472749, acc.: 77.34%] [G loss: 0.692246]\n",
      "epoch:6 step:5879 [D loss: 0.567806, acc.: 69.53%] [G loss: 0.668608]\n",
      "epoch:6 step:5880 [D loss: 0.467092, acc.: 79.69%] [G loss: 0.599752]\n",
      "epoch:6 step:5881 [D loss: 0.518459, acc.: 71.09%] [G loss: 0.581402]\n",
      "epoch:6 step:5882 [D loss: 0.492135, acc.: 75.78%] [G loss: 0.692094]\n",
      "epoch:6 step:5883 [D loss: 0.492107, acc.: 76.56%] [G loss: 0.645734]\n",
      "epoch:6 step:5884 [D loss: 0.495984, acc.: 75.00%] [G loss: 0.702269]\n",
      "epoch:6 step:5885 [D loss: 0.626729, acc.: 61.72%] [G loss: 0.489991]\n",
      "epoch:6 step:5886 [D loss: 0.472463, acc.: 78.12%] [G loss: 0.635863]\n",
      "epoch:6 step:5887 [D loss: 0.565699, acc.: 71.09%] [G loss: 0.582806]\n",
      "epoch:6 step:5888 [D loss: 0.523380, acc.: 74.22%] [G loss: 0.497650]\n",
      "epoch:6 step:5889 [D loss: 0.549682, acc.: 70.31%] [G loss: 0.441541]\n",
      "epoch:6 step:5890 [D loss: 0.574033, acc.: 72.66%] [G loss: 0.537919]\n",
      "epoch:6 step:5891 [D loss: 0.522934, acc.: 75.78%] [G loss: 0.513602]\n",
      "epoch:6 step:5892 [D loss: 0.502602, acc.: 77.34%] [G loss: 0.676287]\n",
      "epoch:6 step:5893 [D loss: 0.456944, acc.: 80.47%] [G loss: 0.743319]\n",
      "epoch:6 step:5894 [D loss: 0.557965, acc.: 73.44%] [G loss: 0.586962]\n",
      "epoch:6 step:5895 [D loss: 0.510665, acc.: 71.09%] [G loss: 0.548201]\n",
      "epoch:6 step:5896 [D loss: 0.563342, acc.: 68.75%] [G loss: 0.589805]\n",
      "epoch:6 step:5897 [D loss: 0.559321, acc.: 74.22%] [G loss: 0.572384]\n",
      "epoch:6 step:5898 [D loss: 0.533755, acc.: 75.78%] [G loss: 0.747278]\n",
      "epoch:6 step:5899 [D loss: 0.607439, acc.: 69.53%] [G loss: 0.469101]\n",
      "epoch:6 step:5900 [D loss: 0.546522, acc.: 70.31%] [G loss: 0.541510]\n",
      "epoch:6 step:5901 [D loss: 0.489005, acc.: 79.69%] [G loss: 0.576444]\n",
      "epoch:6 step:5902 [D loss: 0.469920, acc.: 79.69%] [G loss: 0.704383]\n",
      "epoch:6 step:5903 [D loss: 0.599576, acc.: 65.62%] [G loss: 0.479923]\n",
      "epoch:6 step:5904 [D loss: 0.530849, acc.: 68.75%] [G loss: 0.549194]\n",
      "epoch:6 step:5905 [D loss: 0.440259, acc.: 82.03%] [G loss: 0.663457]\n",
      "epoch:6 step:5906 [D loss: 0.466986, acc.: 72.66%] [G loss: 0.768073]\n",
      "epoch:6 step:5907 [D loss: 0.457147, acc.: 78.91%] [G loss: 0.688158]\n",
      "epoch:6 step:5908 [D loss: 0.423329, acc.: 85.94%] [G loss: 0.735539]\n",
      "epoch:6 step:5909 [D loss: 0.586061, acc.: 67.97%] [G loss: 0.640222]\n",
      "epoch:6 step:5910 [D loss: 0.641777, acc.: 63.28%] [G loss: 0.595880]\n",
      "epoch:6 step:5911 [D loss: 0.600835, acc.: 67.19%] [G loss: 0.525470]\n",
      "epoch:6 step:5912 [D loss: 0.538112, acc.: 67.19%] [G loss: 0.678649]\n",
      "epoch:6 step:5913 [D loss: 0.552602, acc.: 69.53%] [G loss: 0.595900]\n",
      "epoch:6 step:5914 [D loss: 0.539806, acc.: 72.66%] [G loss: 0.565363]\n",
      "epoch:6 step:5915 [D loss: 0.551164, acc.: 67.19%] [G loss: 0.534286]\n",
      "epoch:6 step:5916 [D loss: 0.581832, acc.: 67.97%] [G loss: 0.354410]\n",
      "epoch:6 step:5917 [D loss: 0.567623, acc.: 63.28%] [G loss: 0.428702]\n",
      "epoch:6 step:5918 [D loss: 0.532074, acc.: 73.44%] [G loss: 0.476135]\n",
      "epoch:6 step:5919 [D loss: 0.538723, acc.: 75.78%] [G loss: 0.534158]\n",
      "epoch:6 step:5920 [D loss: 0.513793, acc.: 77.34%] [G loss: 0.648191]\n",
      "epoch:6 step:5921 [D loss: 0.492889, acc.: 74.22%] [G loss: 0.591494]\n",
      "epoch:6 step:5922 [D loss: 0.476133, acc.: 76.56%] [G loss: 0.704511]\n",
      "epoch:6 step:5923 [D loss: 0.597134, acc.: 69.53%] [G loss: 0.591402]\n",
      "epoch:6 step:5924 [D loss: 0.483195, acc.: 74.22%] [G loss: 0.547173]\n",
      "epoch:6 step:5925 [D loss: 0.493463, acc.: 76.56%] [G loss: 0.554258]\n",
      "epoch:6 step:5926 [D loss: 0.508938, acc.: 75.00%] [G loss: 0.695874]\n",
      "epoch:6 step:5927 [D loss: 0.440964, acc.: 82.03%] [G loss: 0.670071]\n",
      "epoch:6 step:5928 [D loss: 0.550392, acc.: 70.31%] [G loss: 0.665134]\n",
      "epoch:6 step:5929 [D loss: 0.487861, acc.: 80.47%] [G loss: 0.756323]\n",
      "epoch:6 step:5930 [D loss: 0.520935, acc.: 73.44%] [G loss: 0.536645]\n",
      "epoch:6 step:5931 [D loss: 0.478747, acc.: 71.09%] [G loss: 0.588198]\n",
      "epoch:6 step:5932 [D loss: 0.550034, acc.: 71.09%] [G loss: 0.669499]\n",
      "epoch:6 step:5933 [D loss: 0.452024, acc.: 74.22%] [G loss: 0.832010]\n",
      "epoch:6 step:5934 [D loss: 0.449812, acc.: 79.69%] [G loss: 0.645896]\n",
      "epoch:6 step:5935 [D loss: 0.486412, acc.: 75.00%] [G loss: 0.999904]\n",
      "epoch:6 step:5936 [D loss: 0.428036, acc.: 78.91%] [G loss: 0.717549]\n",
      "epoch:6 step:5937 [D loss: 0.424051, acc.: 82.81%] [G loss: 0.955000]\n",
      "epoch:6 step:5938 [D loss: 0.640021, acc.: 64.84%] [G loss: 0.616986]\n",
      "epoch:6 step:5939 [D loss: 0.551782, acc.: 72.66%] [G loss: 0.565238]\n",
      "epoch:6 step:5940 [D loss: 0.542254, acc.: 67.97%] [G loss: 0.656503]\n",
      "epoch:6 step:5941 [D loss: 0.553887, acc.: 72.66%] [G loss: 0.537397]\n",
      "epoch:6 step:5942 [D loss: 0.528021, acc.: 73.44%] [G loss: 0.631967]\n",
      "epoch:6 step:5943 [D loss: 0.463604, acc.: 81.25%] [G loss: 0.667629]\n",
      "epoch:6 step:5944 [D loss: 0.562692, acc.: 66.41%] [G loss: 0.539139]\n",
      "epoch:6 step:5945 [D loss: 0.614329, acc.: 64.06%] [G loss: 0.476387]\n",
      "epoch:6 step:5946 [D loss: 0.521035, acc.: 70.31%] [G loss: 0.486203]\n",
      "epoch:6 step:5947 [D loss: 0.548030, acc.: 71.88%] [G loss: 0.449525]\n",
      "epoch:6 step:5948 [D loss: 0.527404, acc.: 70.31%] [G loss: 0.607734]\n",
      "epoch:6 step:5949 [D loss: 0.553661, acc.: 70.31%] [G loss: 0.664304]\n",
      "epoch:6 step:5950 [D loss: 0.518272, acc.: 71.88%] [G loss: 0.596186]\n",
      "epoch:6 step:5951 [D loss: 0.523749, acc.: 73.44%] [G loss: 0.546966]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:6 step:5952 [D loss: 0.546660, acc.: 71.09%] [G loss: 0.572503]\n",
      "epoch:6 step:5953 [D loss: 0.499224, acc.: 78.91%] [G loss: 0.606187]\n",
      "epoch:6 step:5954 [D loss: 0.508764, acc.: 75.78%] [G loss: 0.546287]\n",
      "epoch:6 step:5955 [D loss: 0.441359, acc.: 82.03%] [G loss: 0.534934]\n",
      "epoch:6 step:5956 [D loss: 0.551831, acc.: 66.41%] [G loss: 0.725276]\n",
      "epoch:6 step:5957 [D loss: 0.489976, acc.: 71.88%] [G loss: 0.763701]\n",
      "epoch:6 step:5958 [D loss: 0.492326, acc.: 75.00%] [G loss: 0.694652]\n",
      "epoch:6 step:5959 [D loss: 0.540721, acc.: 70.31%] [G loss: 0.728586]\n",
      "epoch:6 step:5960 [D loss: 0.515359, acc.: 73.44%] [G loss: 0.767942]\n",
      "epoch:6 step:5961 [D loss: 0.476292, acc.: 76.56%] [G loss: 0.682448]\n",
      "epoch:6 step:5962 [D loss: 0.534534, acc.: 73.44%] [G loss: 0.679600]\n",
      "epoch:6 step:5963 [D loss: 0.647101, acc.: 66.41%] [G loss: 0.561763]\n",
      "epoch:6 step:5964 [D loss: 0.619013, acc.: 63.28%] [G loss: 0.678267]\n",
      "epoch:6 step:5965 [D loss: 0.484427, acc.: 72.66%] [G loss: 0.552053]\n",
      "epoch:6 step:5966 [D loss: 0.465252, acc.: 75.78%] [G loss: 0.772989]\n",
      "epoch:6 step:5967 [D loss: 0.505133, acc.: 75.00%] [G loss: 0.656097]\n",
      "epoch:6 step:5968 [D loss: 0.506282, acc.: 74.22%] [G loss: 0.875945]\n",
      "epoch:6 step:5969 [D loss: 0.464715, acc.: 83.59%] [G loss: 0.814104]\n",
      "epoch:6 step:5970 [D loss: 0.600404, acc.: 67.19%] [G loss: 0.554008]\n",
      "epoch:6 step:5971 [D loss: 0.678303, acc.: 62.50%] [G loss: 0.462367]\n",
      "epoch:6 step:5972 [D loss: 0.492658, acc.: 75.00%] [G loss: 0.497075]\n",
      "epoch:6 step:5973 [D loss: 0.520655, acc.: 73.44%] [G loss: 0.642004]\n",
      "epoch:6 step:5974 [D loss: 0.616027, acc.: 60.16%] [G loss: 0.589799]\n",
      "epoch:6 step:5975 [D loss: 0.539829, acc.: 74.22%] [G loss: 0.611065]\n",
      "epoch:6 step:5976 [D loss: 0.432175, acc.: 80.47%] [G loss: 0.613371]\n",
      "epoch:6 step:5977 [D loss: 0.512572, acc.: 75.78%] [G loss: 0.753388]\n",
      "epoch:6 step:5978 [D loss: 0.566348, acc.: 70.31%] [G loss: 0.562729]\n",
      "epoch:6 step:5979 [D loss: 0.492112, acc.: 71.09%] [G loss: 0.571168]\n",
      "epoch:6 step:5980 [D loss: 0.433072, acc.: 79.69%] [G loss: 0.767502]\n",
      "epoch:6 step:5981 [D loss: 0.442231, acc.: 79.69%] [G loss: 0.770714]\n",
      "epoch:6 step:5982 [D loss: 0.468134, acc.: 78.91%] [G loss: 0.747643]\n",
      "epoch:6 step:5983 [D loss: 0.505554, acc.: 75.00%] [G loss: 0.684397]\n",
      "epoch:6 step:5984 [D loss: 0.554006, acc.: 71.88%] [G loss: 0.596469]\n",
      "epoch:6 step:5985 [D loss: 0.504190, acc.: 80.47%] [G loss: 0.524907]\n",
      "epoch:6 step:5986 [D loss: 0.421497, acc.: 81.25%] [G loss: 0.611385]\n",
      "epoch:6 step:5987 [D loss: 0.524767, acc.: 67.97%] [G loss: 0.607142]\n",
      "epoch:6 step:5988 [D loss: 0.433873, acc.: 78.12%] [G loss: 0.817824]\n",
      "epoch:6 step:5989 [D loss: 0.559556, acc.: 67.97%] [G loss: 0.721224]\n",
      "epoch:6 step:5990 [D loss: 0.502930, acc.: 71.88%] [G loss: 0.674775]\n",
      "epoch:6 step:5991 [D loss: 0.521688, acc.: 67.97%] [G loss: 0.590058]\n",
      "epoch:6 step:5992 [D loss: 0.530015, acc.: 73.44%] [G loss: 0.633977]\n",
      "epoch:6 step:5993 [D loss: 0.457380, acc.: 78.12%] [G loss: 0.736574]\n",
      "epoch:6 step:5994 [D loss: 0.505106, acc.: 72.66%] [G loss: 0.582079]\n",
      "epoch:6 step:5995 [D loss: 0.574544, acc.: 64.84%] [G loss: 0.571323]\n",
      "epoch:6 step:5996 [D loss: 0.438069, acc.: 80.47%] [G loss: 0.761145]\n",
      "epoch:6 step:5997 [D loss: 0.541582, acc.: 72.66%] [G loss: 0.682703]\n",
      "epoch:6 step:5998 [D loss: 0.659341, acc.: 64.06%] [G loss: 0.582593]\n",
      "epoch:6 step:5999 [D loss: 0.566033, acc.: 66.41%] [G loss: 0.444371]\n",
      "epoch:6 step:6000 [D loss: 0.504993, acc.: 73.44%] [G loss: 0.597770]\n",
      "epoch:6 step:6001 [D loss: 0.609688, acc.: 67.19%] [G loss: 0.506117]\n",
      "epoch:6 step:6002 [D loss: 0.576969, acc.: 70.31%] [G loss: 0.475289]\n",
      "epoch:6 step:6003 [D loss: 0.445781, acc.: 78.91%] [G loss: 0.640280]\n",
      "epoch:6 step:6004 [D loss: 0.513530, acc.: 76.56%] [G loss: 0.657091]\n",
      "epoch:6 step:6005 [D loss: 0.554873, acc.: 69.53%] [G loss: 0.615221]\n",
      "epoch:6 step:6006 [D loss: 0.525101, acc.: 71.09%] [G loss: 0.519547]\n",
      "epoch:6 step:6007 [D loss: 0.447081, acc.: 82.03%] [G loss: 0.603288]\n",
      "epoch:6 step:6008 [D loss: 0.567776, acc.: 72.66%] [G loss: 0.544262]\n",
      "epoch:6 step:6009 [D loss: 0.565688, acc.: 68.75%] [G loss: 0.508971]\n",
      "epoch:6 step:6010 [D loss: 0.504131, acc.: 76.56%] [G loss: 0.550881]\n",
      "epoch:6 step:6011 [D loss: 0.471773, acc.: 78.91%] [G loss: 0.616336]\n",
      "epoch:6 step:6012 [D loss: 0.574841, acc.: 68.75%] [G loss: 0.609562]\n",
      "epoch:6 step:6013 [D loss: 0.493070, acc.: 75.78%] [G loss: 0.687173]\n",
      "epoch:6 step:6014 [D loss: 0.467686, acc.: 78.91%] [G loss: 0.557964]\n",
      "epoch:6 step:6015 [D loss: 0.499244, acc.: 74.22%] [G loss: 0.640907]\n",
      "epoch:6 step:6016 [D loss: 0.515508, acc.: 74.22%] [G loss: 0.727965]\n",
      "epoch:6 step:6017 [D loss: 0.547968, acc.: 70.31%] [G loss: 0.593331]\n",
      "epoch:6 step:6018 [D loss: 0.572071, acc.: 67.19%] [G loss: 0.790973]\n",
      "epoch:6 step:6019 [D loss: 0.526620, acc.: 74.22%] [G loss: 0.645063]\n",
      "epoch:6 step:6020 [D loss: 0.483626, acc.: 73.44%] [G loss: 0.753284]\n",
      "epoch:6 step:6021 [D loss: 0.543623, acc.: 73.44%] [G loss: 0.672661]\n",
      "epoch:6 step:6022 [D loss: 0.645206, acc.: 61.72%] [G loss: 0.548740]\n",
      "epoch:6 step:6023 [D loss: 0.553571, acc.: 67.19%] [G loss: 0.556830]\n",
      "epoch:6 step:6024 [D loss: 0.546173, acc.: 69.53%] [G loss: 0.536295]\n",
      "epoch:6 step:6025 [D loss: 0.471258, acc.: 75.78%] [G loss: 0.855759]\n",
      "epoch:6 step:6026 [D loss: 0.577956, acc.: 67.97%] [G loss: 0.814344]\n",
      "epoch:6 step:6027 [D loss: 0.533090, acc.: 72.66%] [G loss: 0.681153]\n",
      "epoch:6 step:6028 [D loss: 0.495884, acc.: 81.25%] [G loss: 0.821985]\n",
      "epoch:6 step:6029 [D loss: 0.581566, acc.: 67.19%] [G loss: 0.768907]\n",
      "epoch:6 step:6030 [D loss: 0.562130, acc.: 68.75%] [G loss: 0.661816]\n",
      "epoch:6 step:6031 [D loss: 0.556020, acc.: 71.88%] [G loss: 0.753085]\n",
      "epoch:6 step:6032 [D loss: 0.559284, acc.: 68.75%] [G loss: 0.521150]\n",
      "epoch:6 step:6033 [D loss: 0.543932, acc.: 71.09%] [G loss: 0.552561]\n",
      "epoch:6 step:6034 [D loss: 0.586701, acc.: 64.84%] [G loss: 0.575488]\n",
      "epoch:6 step:6035 [D loss: 0.567823, acc.: 65.62%] [G loss: 0.517538]\n",
      "epoch:6 step:6036 [D loss: 0.546546, acc.: 72.66%] [G loss: 0.619300]\n",
      "epoch:6 step:6037 [D loss: 0.578450, acc.: 65.62%] [G loss: 0.651856]\n",
      "epoch:6 step:6038 [D loss: 0.508724, acc.: 77.34%] [G loss: 0.739509]\n",
      "epoch:6 step:6039 [D loss: 0.609522, acc.: 65.62%] [G loss: 0.556014]\n",
      "epoch:6 step:6040 [D loss: 0.640437, acc.: 59.38%] [G loss: 0.541462]\n",
      "epoch:6 step:6041 [D loss: 0.541343, acc.: 71.09%] [G loss: 0.486847]\n",
      "epoch:6 step:6042 [D loss: 0.597495, acc.: 62.50%] [G loss: 0.538857]\n",
      "epoch:6 step:6043 [D loss: 0.548434, acc.: 70.31%] [G loss: 0.531673]\n",
      "epoch:6 step:6044 [D loss: 0.526854, acc.: 72.66%] [G loss: 0.705795]\n",
      "epoch:6 step:6045 [D loss: 0.524946, acc.: 71.09%] [G loss: 0.677259]\n",
      "epoch:6 step:6046 [D loss: 0.519483, acc.: 74.22%] [G loss: 0.712005]\n",
      "epoch:6 step:6047 [D loss: 0.524415, acc.: 71.88%] [G loss: 0.654632]\n",
      "epoch:6 step:6048 [D loss: 0.532420, acc.: 72.66%] [G loss: 0.524151]\n",
      "epoch:6 step:6049 [D loss: 0.464075, acc.: 80.47%] [G loss: 0.672468]\n",
      "epoch:6 step:6050 [D loss: 0.491160, acc.: 78.91%] [G loss: 0.640250]\n",
      "epoch:6 step:6051 [D loss: 0.470095, acc.: 80.47%] [G loss: 0.743673]\n",
      "epoch:6 step:6052 [D loss: 0.527146, acc.: 73.44%] [G loss: 0.643095]\n",
      "epoch:6 step:6053 [D loss: 0.530799, acc.: 75.00%] [G loss: 0.596581]\n",
      "epoch:6 step:6054 [D loss: 0.548125, acc.: 63.28%] [G loss: 0.595111]\n",
      "epoch:6 step:6055 [D loss: 0.562105, acc.: 68.75%] [G loss: 0.550638]\n",
      "epoch:6 step:6056 [D loss: 0.547537, acc.: 64.84%] [G loss: 0.426194]\n",
      "epoch:6 step:6057 [D loss: 0.581273, acc.: 71.88%] [G loss: 0.559759]\n",
      "epoch:6 step:6058 [D loss: 0.503897, acc.: 75.78%] [G loss: 0.561927]\n",
      "epoch:6 step:6059 [D loss: 0.643174, acc.: 66.41%] [G loss: 0.456323]\n",
      "epoch:6 step:6060 [D loss: 0.544301, acc.: 68.75%] [G loss: 0.558135]\n",
      "epoch:6 step:6061 [D loss: 0.512175, acc.: 75.78%] [G loss: 0.612501]\n",
      "epoch:6 step:6062 [D loss: 0.522005, acc.: 70.31%] [G loss: 0.676881]\n",
      "epoch:6 step:6063 [D loss: 0.509189, acc.: 74.22%] [G loss: 0.761941]\n",
      "epoch:6 step:6064 [D loss: 0.527033, acc.: 72.66%] [G loss: 0.597631]\n",
      "epoch:6 step:6065 [D loss: 0.513883, acc.: 77.34%] [G loss: 0.571148]\n",
      "epoch:6 step:6066 [D loss: 0.541149, acc.: 74.22%] [G loss: 0.667037]\n",
      "epoch:6 step:6067 [D loss: 0.499270, acc.: 75.78%] [G loss: 0.656079]\n",
      "epoch:6 step:6068 [D loss: 0.507819, acc.: 76.56%] [G loss: 0.711818]\n",
      "epoch:6 step:6069 [D loss: 0.487836, acc.: 78.91%] [G loss: 0.523819]\n",
      "epoch:6 step:6070 [D loss: 0.556377, acc.: 68.75%] [G loss: 0.673340]\n",
      "epoch:6 step:6071 [D loss: 0.526978, acc.: 71.88%] [G loss: 0.709361]\n",
      "epoch:6 step:6072 [D loss: 0.454960, acc.: 82.81%] [G loss: 0.716497]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:6 step:6073 [D loss: 0.419555, acc.: 80.47%] [G loss: 0.795454]\n",
      "epoch:6 step:6074 [D loss: 0.481708, acc.: 76.56%] [G loss: 0.809954]\n",
      "epoch:6 step:6075 [D loss: 0.525542, acc.: 70.31%] [G loss: 0.688575]\n",
      "epoch:6 step:6076 [D loss: 0.564085, acc.: 69.53%] [G loss: 0.567939]\n",
      "epoch:6 step:6077 [D loss: 0.530152, acc.: 72.66%] [G loss: 0.559356]\n",
      "epoch:6 step:6078 [D loss: 0.566433, acc.: 70.31%] [G loss: 0.665799]\n",
      "epoch:6 step:6079 [D loss: 0.469207, acc.: 78.12%] [G loss: 0.659697]\n",
      "epoch:6 step:6080 [D loss: 0.612925, acc.: 66.41%] [G loss: 0.505223]\n",
      "epoch:6 step:6081 [D loss: 0.555380, acc.: 73.44%] [G loss: 0.593428]\n",
      "epoch:6 step:6082 [D loss: 0.544815, acc.: 71.88%] [G loss: 0.529957]\n",
      "epoch:6 step:6083 [D loss: 0.574220, acc.: 66.41%] [G loss: 0.675335]\n",
      "epoch:6 step:6084 [D loss: 0.536667, acc.: 71.09%] [G loss: 0.661095]\n",
      "epoch:6 step:6085 [D loss: 0.567894, acc.: 70.31%] [G loss: 0.514264]\n",
      "epoch:6 step:6086 [D loss: 0.519384, acc.: 74.22%] [G loss: 0.505685]\n",
      "epoch:6 step:6087 [D loss: 0.616812, acc.: 64.06%] [G loss: 0.567903]\n",
      "epoch:6 step:6088 [D loss: 0.556261, acc.: 71.09%] [G loss: 0.513950]\n",
      "epoch:6 step:6089 [D loss: 0.589961, acc.: 67.97%] [G loss: 0.515863]\n",
      "epoch:6 step:6090 [D loss: 0.542124, acc.: 71.88%] [G loss: 0.686188]\n",
      "epoch:6 step:6091 [D loss: 0.550288, acc.: 71.09%] [G loss: 0.564605]\n",
      "epoch:6 step:6092 [D loss: 0.525851, acc.: 74.22%] [G loss: 0.517878]\n",
      "epoch:6 step:6093 [D loss: 0.451158, acc.: 82.03%] [G loss: 0.732016]\n",
      "epoch:6 step:6094 [D loss: 0.461471, acc.: 80.47%] [G loss: 0.822105]\n",
      "epoch:6 step:6095 [D loss: 0.632470, acc.: 67.19%] [G loss: 0.764564]\n",
      "epoch:6 step:6096 [D loss: 0.520645, acc.: 71.88%] [G loss: 0.622537]\n",
      "epoch:6 step:6097 [D loss: 0.466173, acc.: 85.94%] [G loss: 0.724407]\n",
      "epoch:6 step:6098 [D loss: 0.551549, acc.: 78.12%] [G loss: 0.697833]\n",
      "epoch:6 step:6099 [D loss: 0.615991, acc.: 67.19%] [G loss: 0.485735]\n",
      "epoch:6 step:6100 [D loss: 0.544449, acc.: 73.44%] [G loss: 0.503217]\n",
      "epoch:6 step:6101 [D loss: 0.546407, acc.: 70.31%] [G loss: 0.525274]\n",
      "epoch:6 step:6102 [D loss: 0.556530, acc.: 70.31%] [G loss: 0.556789]\n",
      "epoch:6 step:6103 [D loss: 0.529182, acc.: 73.44%] [G loss: 0.529608]\n",
      "epoch:6 step:6104 [D loss: 0.602153, acc.: 63.28%] [G loss: 0.565768]\n",
      "epoch:6 step:6105 [D loss: 0.576164, acc.: 61.72%] [G loss: 0.670492]\n",
      "epoch:6 step:6106 [D loss: 0.466129, acc.: 80.47%] [G loss: 0.750355]\n",
      "epoch:6 step:6107 [D loss: 0.526237, acc.: 73.44%] [G loss: 0.748509]\n",
      "epoch:6 step:6108 [D loss: 0.543113, acc.: 71.88%] [G loss: 0.632672]\n",
      "epoch:6 step:6109 [D loss: 0.563596, acc.: 73.44%] [G loss: 0.540576]\n",
      "epoch:6 step:6110 [D loss: 0.468080, acc.: 79.69%] [G loss: 0.700915]\n",
      "epoch:6 step:6111 [D loss: 0.619820, acc.: 64.84%] [G loss: 0.498990]\n",
      "epoch:6 step:6112 [D loss: 0.603583, acc.: 59.38%] [G loss: 0.625806]\n",
      "epoch:6 step:6113 [D loss: 0.527404, acc.: 73.44%] [G loss: 0.540759]\n",
      "epoch:6 step:6114 [D loss: 0.530460, acc.: 74.22%] [G loss: 0.508364]\n",
      "epoch:6 step:6115 [D loss: 0.568341, acc.: 67.19%] [G loss: 0.527151]\n",
      "epoch:6 step:6116 [D loss: 0.516405, acc.: 78.91%] [G loss: 0.535052]\n",
      "epoch:6 step:6117 [D loss: 0.485648, acc.: 77.34%] [G loss: 0.733242]\n",
      "epoch:6 step:6118 [D loss: 0.577958, acc.: 63.28%] [G loss: 0.598223]\n",
      "epoch:6 step:6119 [D loss: 0.545971, acc.: 68.75%] [G loss: 0.682829]\n",
      "epoch:6 step:6120 [D loss: 0.486122, acc.: 74.22%] [G loss: 0.751512]\n",
      "epoch:6 step:6121 [D loss: 0.449612, acc.: 78.91%] [G loss: 0.731578]\n",
      "epoch:6 step:6122 [D loss: 0.658945, acc.: 58.59%] [G loss: 0.539370]\n",
      "epoch:6 step:6123 [D loss: 0.681782, acc.: 59.38%] [G loss: 0.484983]\n",
      "epoch:6 step:6124 [D loss: 0.599654, acc.: 60.16%] [G loss: 0.415746]\n",
      "epoch:6 step:6125 [D loss: 0.485412, acc.: 77.34%] [G loss: 0.499686]\n",
      "epoch:6 step:6126 [D loss: 0.457016, acc.: 78.91%] [G loss: 0.790609]\n",
      "epoch:6 step:6127 [D loss: 0.546887, acc.: 67.97%] [G loss: 0.668716]\n",
      "epoch:6 step:6128 [D loss: 0.490162, acc.: 79.69%] [G loss: 0.654966]\n",
      "epoch:6 step:6129 [D loss: 0.551463, acc.: 71.88%] [G loss: 0.736935]\n",
      "epoch:6 step:6130 [D loss: 0.411461, acc.: 83.59%] [G loss: 0.839481]\n",
      "epoch:6 step:6131 [D loss: 0.517643, acc.: 76.56%] [G loss: 0.696166]\n",
      "epoch:6 step:6132 [D loss: 0.563775, acc.: 67.97%] [G loss: 0.615998]\n",
      "epoch:6 step:6133 [D loss: 0.627361, acc.: 63.28%] [G loss: 0.558706]\n",
      "epoch:6 step:6134 [D loss: 0.571525, acc.: 69.53%] [G loss: 0.500690]\n",
      "epoch:6 step:6135 [D loss: 0.520650, acc.: 78.12%] [G loss: 0.504324]\n",
      "epoch:6 step:6136 [D loss: 0.511876, acc.: 70.31%] [G loss: 0.609043]\n",
      "epoch:6 step:6137 [D loss: 0.472335, acc.: 76.56%] [G loss: 0.774366]\n",
      "epoch:6 step:6138 [D loss: 0.453565, acc.: 79.69%] [G loss: 0.726132]\n",
      "epoch:6 step:6139 [D loss: 0.515534, acc.: 76.56%] [G loss: 0.590504]\n",
      "epoch:6 step:6140 [D loss: 0.489700, acc.: 77.34%] [G loss: 0.593250]\n",
      "epoch:6 step:6141 [D loss: 0.492044, acc.: 78.12%] [G loss: 0.562362]\n",
      "epoch:6 step:6142 [D loss: 0.467883, acc.: 78.12%] [G loss: 0.724266]\n",
      "epoch:6 step:6143 [D loss: 0.479767, acc.: 81.25%] [G loss: 0.760495]\n",
      "epoch:6 step:6144 [D loss: 0.524553, acc.: 73.44%] [G loss: 0.793281]\n",
      "epoch:6 step:6145 [D loss: 0.451582, acc.: 80.47%] [G loss: 0.874032]\n",
      "epoch:6 step:6146 [D loss: 0.512125, acc.: 72.66%] [G loss: 0.658816]\n",
      "epoch:6 step:6147 [D loss: 0.553409, acc.: 72.66%] [G loss: 0.681484]\n",
      "epoch:6 step:6148 [D loss: 0.519875, acc.: 75.78%] [G loss: 0.550315]\n",
      "epoch:6 step:6149 [D loss: 0.519789, acc.: 72.66%] [G loss: 0.626861]\n",
      "epoch:6 step:6150 [D loss: 0.625215, acc.: 67.19%] [G loss: 0.713227]\n",
      "epoch:6 step:6151 [D loss: 0.584840, acc.: 67.97%] [G loss: 0.468214]\n",
      "epoch:6 step:6152 [D loss: 0.491687, acc.: 73.44%] [G loss: 0.733681]\n",
      "epoch:6 step:6153 [D loss: 0.586456, acc.: 67.97%] [G loss: 0.621317]\n",
      "epoch:6 step:6154 [D loss: 0.564901, acc.: 68.75%] [G loss: 0.500230]\n",
      "epoch:6 step:6155 [D loss: 0.602084, acc.: 63.28%] [G loss: 0.511408]\n",
      "epoch:6 step:6156 [D loss: 0.452319, acc.: 78.91%] [G loss: 0.722538]\n",
      "epoch:6 step:6157 [D loss: 0.569320, acc.: 70.31%] [G loss: 0.523402]\n",
      "epoch:6 step:6158 [D loss: 0.440872, acc.: 83.59%] [G loss: 0.681978]\n",
      "epoch:6 step:6159 [D loss: 0.519128, acc.: 73.44%] [G loss: 0.688374]\n",
      "epoch:6 step:6160 [D loss: 0.524104, acc.: 75.00%] [G loss: 0.601793]\n",
      "epoch:6 step:6161 [D loss: 0.548325, acc.: 71.09%] [G loss: 0.605460]\n",
      "epoch:6 step:6162 [D loss: 0.536495, acc.: 71.88%] [G loss: 0.548391]\n",
      "epoch:6 step:6163 [D loss: 0.529995, acc.: 73.44%] [G loss: 0.440199]\n",
      "epoch:6 step:6164 [D loss: 0.593401, acc.: 69.53%] [G loss: 0.538499]\n",
      "epoch:6 step:6165 [D loss: 0.554674, acc.: 70.31%] [G loss: 0.629630]\n",
      "epoch:6 step:6166 [D loss: 0.532524, acc.: 74.22%] [G loss: 0.596112]\n",
      "epoch:6 step:6167 [D loss: 0.555689, acc.: 73.44%] [G loss: 0.610828]\n",
      "epoch:6 step:6168 [D loss: 0.467860, acc.: 74.22%] [G loss: 0.628482]\n",
      "epoch:6 step:6169 [D loss: 0.482926, acc.: 78.91%] [G loss: 0.844377]\n",
      "epoch:6 step:6170 [D loss: 0.534689, acc.: 67.97%] [G loss: 0.556642]\n",
      "epoch:6 step:6171 [D loss: 0.490397, acc.: 78.12%] [G loss: 0.736177]\n",
      "epoch:6 step:6172 [D loss: 0.560488, acc.: 68.75%] [G loss: 0.718160]\n",
      "epoch:6 step:6173 [D loss: 0.561805, acc.: 68.75%] [G loss: 0.625902]\n",
      "epoch:6 step:6174 [D loss: 0.459987, acc.: 82.03%] [G loss: 0.637291]\n",
      "epoch:6 step:6175 [D loss: 0.581060, acc.: 65.62%] [G loss: 0.597073]\n",
      "epoch:6 step:6176 [D loss: 0.471915, acc.: 77.34%] [G loss: 0.573320]\n",
      "epoch:6 step:6177 [D loss: 0.459722, acc.: 77.34%] [G loss: 0.656928]\n",
      "epoch:6 step:6178 [D loss: 0.463741, acc.: 82.81%] [G loss: 0.550550]\n",
      "epoch:6 step:6179 [D loss: 0.522718, acc.: 72.66%] [G loss: 0.588140]\n",
      "epoch:6 step:6180 [D loss: 0.494464, acc.: 73.44%] [G loss: 0.755595]\n",
      "epoch:6 step:6181 [D loss: 0.560024, acc.: 67.97%] [G loss: 0.778949]\n",
      "epoch:6 step:6182 [D loss: 0.559405, acc.: 65.62%] [G loss: 0.449884]\n",
      "epoch:6 step:6183 [D loss: 0.450869, acc.: 82.81%] [G loss: 0.609606]\n",
      "epoch:6 step:6184 [D loss: 0.621558, acc.: 64.06%] [G loss: 0.656252]\n",
      "epoch:6 step:6185 [D loss: 0.551681, acc.: 72.66%] [G loss: 0.620169]\n",
      "epoch:6 step:6186 [D loss: 0.523798, acc.: 73.44%] [G loss: 0.737393]\n",
      "epoch:6 step:6187 [D loss: 0.595382, acc.: 68.75%] [G loss: 0.615443]\n",
      "epoch:6 step:6188 [D loss: 0.645266, acc.: 62.50%] [G loss: 0.527881]\n",
      "epoch:6 step:6189 [D loss: 0.506281, acc.: 72.66%] [G loss: 0.585678]\n",
      "epoch:6 step:6190 [D loss: 0.500356, acc.: 75.00%] [G loss: 0.658018]\n",
      "epoch:6 step:6191 [D loss: 0.518016, acc.: 74.22%] [G loss: 0.561276]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:6 step:6192 [D loss: 0.520939, acc.: 76.56%] [G loss: 0.635725]\n",
      "epoch:6 step:6193 [D loss: 0.518020, acc.: 74.22%] [G loss: 0.647428]\n",
      "epoch:6 step:6194 [D loss: 0.535007, acc.: 72.66%] [G loss: 0.617005]\n",
      "epoch:6 step:6195 [D loss: 0.522041, acc.: 77.34%] [G loss: 0.524765]\n",
      "epoch:6 step:6196 [D loss: 0.477943, acc.: 74.22%] [G loss: 0.633744]\n",
      "epoch:6 step:6197 [D loss: 0.444305, acc.: 80.47%] [G loss: 0.617133]\n",
      "epoch:6 step:6198 [D loss: 0.570430, acc.: 67.19%] [G loss: 0.589672]\n",
      "epoch:6 step:6199 [D loss: 0.593354, acc.: 69.53%] [G loss: 0.541551]\n",
      "epoch:6 step:6200 [D loss: 0.539722, acc.: 74.22%] [G loss: 0.636657]\n",
      "epoch:6 step:6201 [D loss: 0.532000, acc.: 72.66%] [G loss: 0.528527]\n",
      "epoch:6 step:6202 [D loss: 0.535235, acc.: 72.66%] [G loss: 0.593446]\n",
      "epoch:6 step:6203 [D loss: 0.547628, acc.: 74.22%] [G loss: 0.527048]\n",
      "epoch:6 step:6204 [D loss: 0.427317, acc.: 80.47%] [G loss: 0.712800]\n",
      "epoch:6 step:6205 [D loss: 0.589117, acc.: 71.09%] [G loss: 0.766448]\n",
      "epoch:6 step:6206 [D loss: 0.546338, acc.: 67.19%] [G loss: 0.554161]\n",
      "epoch:6 step:6207 [D loss: 0.584609, acc.: 66.41%] [G loss: 0.527790]\n",
      "epoch:6 step:6208 [D loss: 0.549596, acc.: 74.22%] [G loss: 0.508491]\n",
      "epoch:6 step:6209 [D loss: 0.583090, acc.: 63.28%] [G loss: 0.489389]\n",
      "epoch:6 step:6210 [D loss: 0.528987, acc.: 74.22%] [G loss: 0.643297]\n",
      "epoch:6 step:6211 [D loss: 0.528781, acc.: 71.88%] [G loss: 0.696093]\n",
      "epoch:6 step:6212 [D loss: 0.591868, acc.: 64.84%] [G loss: 0.642966]\n",
      "epoch:6 step:6213 [D loss: 0.601433, acc.: 68.75%] [G loss: 0.664909]\n",
      "epoch:6 step:6214 [D loss: 0.488073, acc.: 77.34%] [G loss: 0.704653]\n",
      "epoch:6 step:6215 [D loss: 0.534215, acc.: 71.09%] [G loss: 0.734748]\n",
      "epoch:6 step:6216 [D loss: 0.579815, acc.: 70.31%] [G loss: 0.528422]\n",
      "epoch:6 step:6217 [D loss: 0.485402, acc.: 78.12%] [G loss: 0.570549]\n",
      "epoch:6 step:6218 [D loss: 0.551589, acc.: 72.66%] [G loss: 0.535580]\n",
      "epoch:6 step:6219 [D loss: 0.494789, acc.: 78.12%] [G loss: 0.643725]\n",
      "epoch:6 step:6220 [D loss: 0.524291, acc.: 74.22%] [G loss: 0.661389]\n",
      "epoch:6 step:6221 [D loss: 0.547686, acc.: 64.84%] [G loss: 0.513943]\n",
      "epoch:6 step:6222 [D loss: 0.606267, acc.: 64.06%] [G loss: 0.594236]\n",
      "epoch:6 step:6223 [D loss: 0.528617, acc.: 71.88%] [G loss: 0.559988]\n",
      "epoch:6 step:6224 [D loss: 0.493045, acc.: 73.44%] [G loss: 0.781785]\n",
      "epoch:6 step:6225 [D loss: 0.482640, acc.: 78.12%] [G loss: 0.705631]\n",
      "epoch:6 step:6226 [D loss: 0.608772, acc.: 71.09%] [G loss: 0.554165]\n",
      "epoch:6 step:6227 [D loss: 0.467993, acc.: 80.47%] [G loss: 0.607126]\n",
      "epoch:6 step:6228 [D loss: 0.597286, acc.: 65.62%] [G loss: 0.505437]\n",
      "epoch:6 step:6229 [D loss: 0.535921, acc.: 68.75%] [G loss: 0.448756]\n",
      "epoch:6 step:6230 [D loss: 0.536902, acc.: 71.09%] [G loss: 0.515549]\n",
      "epoch:6 step:6231 [D loss: 0.477207, acc.: 79.69%] [G loss: 0.483531]\n",
      "epoch:6 step:6232 [D loss: 0.580147, acc.: 66.41%] [G loss: 0.510622]\n",
      "epoch:6 step:6233 [D loss: 0.477328, acc.: 75.00%] [G loss: 0.646872]\n",
      "epoch:6 step:6234 [D loss: 0.532515, acc.: 73.44%] [G loss: 0.478130]\n",
      "epoch:6 step:6235 [D loss: 0.505026, acc.: 74.22%] [G loss: 0.552644]\n",
      "epoch:6 step:6236 [D loss: 0.615799, acc.: 66.41%] [G loss: 0.481668]\n",
      "epoch:6 step:6237 [D loss: 0.586785, acc.: 64.84%] [G loss: 0.620132]\n",
      "epoch:6 step:6238 [D loss: 0.562434, acc.: 71.09%] [G loss: 0.465167]\n",
      "epoch:6 step:6239 [D loss: 0.522133, acc.: 72.66%] [G loss: 0.551071]\n",
      "epoch:6 step:6240 [D loss: 0.498825, acc.: 75.00%] [G loss: 0.646526]\n",
      "epoch:6 step:6241 [D loss: 0.570458, acc.: 68.75%] [G loss: 0.713023]\n",
      "epoch:6 step:6242 [D loss: 0.553469, acc.: 71.88%] [G loss: 0.659431]\n",
      "epoch:6 step:6243 [D loss: 0.564862, acc.: 69.53%] [G loss: 0.498708]\n",
      "epoch:6 step:6244 [D loss: 0.626983, acc.: 63.28%] [G loss: 0.471039]\n",
      "epoch:6 step:6245 [D loss: 0.465995, acc.: 78.91%] [G loss: 0.593212]\n",
      "epoch:6 step:6246 [D loss: 0.490532, acc.: 76.56%] [G loss: 0.782316]\n",
      "epoch:6 step:6247 [D loss: 0.569409, acc.: 64.84%] [G loss: 0.487514]\n",
      "epoch:6 step:6248 [D loss: 0.486465, acc.: 76.56%] [G loss: 0.616939]\n",
      "epoch:6 step:6249 [D loss: 0.502708, acc.: 75.78%] [G loss: 0.573163]\n",
      "epoch:6 step:6250 [D loss: 0.552329, acc.: 64.84%] [G loss: 0.454801]\n",
      "epoch:6 step:6251 [D loss: 0.493204, acc.: 76.56%] [G loss: 0.575862]\n",
      "epoch:6 step:6252 [D loss: 0.518243, acc.: 76.56%] [G loss: 0.476165]\n",
      "epoch:6 step:6253 [D loss: 0.473195, acc.: 78.91%] [G loss: 0.653567]\n",
      "epoch:6 step:6254 [D loss: 0.493589, acc.: 76.56%] [G loss: 0.598595]\n",
      "epoch:6 step:6255 [D loss: 0.478272, acc.: 78.91%] [G loss: 0.556491]\n",
      "epoch:6 step:6256 [D loss: 0.484474, acc.: 78.91%] [G loss: 0.663688]\n",
      "epoch:6 step:6257 [D loss: 0.527127, acc.: 71.88%] [G loss: 0.628439]\n",
      "epoch:6 step:6258 [D loss: 0.557522, acc.: 68.75%] [G loss: 0.573740]\n",
      "epoch:6 step:6259 [D loss: 0.513206, acc.: 73.44%] [G loss: 0.574185]\n",
      "epoch:6 step:6260 [D loss: 0.529273, acc.: 72.66%] [G loss: 0.517420]\n",
      "epoch:6 step:6261 [D loss: 0.485422, acc.: 77.34%] [G loss: 0.535488]\n",
      "epoch:6 step:6262 [D loss: 0.476101, acc.: 80.47%] [G loss: 0.659724]\n",
      "epoch:6 step:6263 [D loss: 0.435256, acc.: 78.12%] [G loss: 0.805744]\n",
      "epoch:6 step:6264 [D loss: 0.515530, acc.: 71.88%] [G loss: 0.760186]\n",
      "epoch:6 step:6265 [D loss: 0.513486, acc.: 71.88%] [G loss: 0.704980]\n",
      "epoch:6 step:6266 [D loss: 0.608878, acc.: 64.06%] [G loss: 0.563967]\n",
      "epoch:6 step:6267 [D loss: 0.551331, acc.: 75.78%] [G loss: 0.631069]\n",
      "epoch:6 step:6268 [D loss: 0.615216, acc.: 65.62%] [G loss: 0.593257]\n",
      "epoch:6 step:6269 [D loss: 0.500066, acc.: 77.34%] [G loss: 0.765385]\n",
      "epoch:6 step:6270 [D loss: 0.441692, acc.: 81.25%] [G loss: 0.731214]\n",
      "epoch:6 step:6271 [D loss: 0.456201, acc.: 78.91%] [G loss: 0.850370]\n",
      "epoch:6 step:6272 [D loss: 0.482558, acc.: 77.34%] [G loss: 0.720109]\n",
      "epoch:6 step:6273 [D loss: 0.478848, acc.: 78.91%] [G loss: 0.841528]\n",
      "epoch:6 step:6274 [D loss: 0.649235, acc.: 64.06%] [G loss: 0.712531]\n",
      "epoch:6 step:6275 [D loss: 0.558302, acc.: 68.75%] [G loss: 0.539141]\n",
      "epoch:6 step:6276 [D loss: 0.511486, acc.: 72.66%] [G loss: 0.516529]\n",
      "epoch:6 step:6277 [D loss: 0.560601, acc.: 74.22%] [G loss: 0.584661]\n",
      "epoch:6 step:6278 [D loss: 0.532595, acc.: 76.56%] [G loss: 0.602125]\n",
      "epoch:6 step:6279 [D loss: 0.501908, acc.: 71.88%] [G loss: 0.628274]\n",
      "epoch:6 step:6280 [D loss: 0.601515, acc.: 62.50%] [G loss: 0.597423]\n",
      "epoch:6 step:6281 [D loss: 0.572671, acc.: 70.31%] [G loss: 0.530736]\n",
      "epoch:6 step:6282 [D loss: 0.482829, acc.: 74.22%] [G loss: 0.730174]\n",
      "epoch:6 step:6283 [D loss: 0.457444, acc.: 81.25%] [G loss: 0.670237]\n",
      "epoch:6 step:6284 [D loss: 0.573966, acc.: 71.09%] [G loss: 0.610299]\n",
      "epoch:6 step:6285 [D loss: 0.509456, acc.: 72.66%] [G loss: 0.547330]\n",
      "epoch:6 step:6286 [D loss: 0.547541, acc.: 71.88%] [G loss: 0.638227]\n",
      "epoch:6 step:6287 [D loss: 0.518271, acc.: 72.66%] [G loss: 0.798447]\n",
      "epoch:6 step:6288 [D loss: 0.503229, acc.: 78.91%] [G loss: 0.636047]\n",
      "epoch:6 step:6289 [D loss: 0.560903, acc.: 67.97%] [G loss: 0.638807]\n",
      "epoch:6 step:6290 [D loss: 0.533828, acc.: 73.44%] [G loss: 0.539986]\n",
      "epoch:6 step:6291 [D loss: 0.502850, acc.: 71.88%] [G loss: 0.625836]\n",
      "epoch:6 step:6292 [D loss: 0.564384, acc.: 67.97%] [G loss: 0.575479]\n",
      "epoch:6 step:6293 [D loss: 0.569172, acc.: 70.31%] [G loss: 0.566580]\n",
      "epoch:6 step:6294 [D loss: 0.580894, acc.: 71.88%] [G loss: 0.616327]\n",
      "epoch:6 step:6295 [D loss: 0.601222, acc.: 67.97%] [G loss: 0.546042]\n",
      "epoch:6 step:6296 [D loss: 0.537491, acc.: 72.66%] [G loss: 0.721250]\n",
      "epoch:6 step:6297 [D loss: 0.492455, acc.: 76.56%] [G loss: 0.797679]\n",
      "epoch:6 step:6298 [D loss: 0.574929, acc.: 68.75%] [G loss: 0.555808]\n",
      "epoch:6 step:6299 [D loss: 0.450485, acc.: 78.91%] [G loss: 0.733038]\n",
      "epoch:6 step:6300 [D loss: 0.563805, acc.: 67.97%] [G loss: 0.687348]\n",
      "epoch:6 step:6301 [D loss: 0.487163, acc.: 75.00%] [G loss: 0.796407]\n",
      "epoch:6 step:6302 [D loss: 0.506629, acc.: 76.56%] [G loss: 0.733627]\n",
      "epoch:6 step:6303 [D loss: 0.465871, acc.: 80.47%] [G loss: 0.755422]\n",
      "epoch:6 step:6304 [D loss: 0.511448, acc.: 76.56%] [G loss: 0.604076]\n",
      "epoch:6 step:6305 [D loss: 0.562885, acc.: 71.09%] [G loss: 0.532753]\n",
      "epoch:6 step:6306 [D loss: 0.516441, acc.: 71.09%] [G loss: 0.483775]\n",
      "epoch:6 step:6307 [D loss: 0.549000, acc.: 69.53%] [G loss: 0.443567]\n",
      "epoch:6 step:6308 [D loss: 0.504052, acc.: 81.25%] [G loss: 0.567874]\n",
      "epoch:6 step:6309 [D loss: 0.506182, acc.: 76.56%] [G loss: 0.599692]\n",
      "epoch:6 step:6310 [D loss: 0.517332, acc.: 73.44%] [G loss: 0.591178]\n",
      "epoch:6 step:6311 [D loss: 0.478886, acc.: 78.12%] [G loss: 0.752925]\n",
      "epoch:6 step:6312 [D loss: 0.552053, acc.: 67.97%] [G loss: 0.600749]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:6 step:6313 [D loss: 0.558923, acc.: 73.44%] [G loss: 0.737149]\n",
      "epoch:6 step:6314 [D loss: 0.550979, acc.: 73.44%] [G loss: 0.615700]\n",
      "epoch:6 step:6315 [D loss: 0.484001, acc.: 78.12%] [G loss: 0.604109]\n",
      "epoch:6 step:6316 [D loss: 0.533394, acc.: 72.66%] [G loss: 0.700778]\n",
      "epoch:6 step:6317 [D loss: 0.549441, acc.: 72.66%] [G loss: 0.623450]\n",
      "epoch:6 step:6318 [D loss: 0.589176, acc.: 68.75%] [G loss: 0.576008]\n",
      "epoch:6 step:6319 [D loss: 0.574573, acc.: 72.66%] [G loss: 0.421484]\n",
      "epoch:6 step:6320 [D loss: 0.524921, acc.: 71.88%] [G loss: 0.545053]\n",
      "epoch:6 step:6321 [D loss: 0.458797, acc.: 82.81%] [G loss: 0.683417]\n",
      "epoch:6 step:6322 [D loss: 0.512795, acc.: 75.00%] [G loss: 0.572207]\n",
      "epoch:6 step:6323 [D loss: 0.517611, acc.: 75.78%] [G loss: 0.646746]\n",
      "epoch:6 step:6324 [D loss: 0.599506, acc.: 70.31%] [G loss: 0.642828]\n",
      "epoch:6 step:6325 [D loss: 0.582107, acc.: 68.75%] [G loss: 0.689431]\n",
      "epoch:6 step:6326 [D loss: 0.627353, acc.: 64.84%] [G loss: 0.578374]\n",
      "epoch:6 step:6327 [D loss: 0.503084, acc.: 75.78%] [G loss: 0.496469]\n",
      "epoch:6 step:6328 [D loss: 0.560129, acc.: 69.53%] [G loss: 0.587232]\n",
      "epoch:6 step:6329 [D loss: 0.485735, acc.: 77.34%] [G loss: 0.578445]\n",
      "epoch:6 step:6330 [D loss: 0.455922, acc.: 78.91%] [G loss: 0.672532]\n",
      "epoch:6 step:6331 [D loss: 0.511753, acc.: 72.66%] [G loss: 0.637093]\n",
      "epoch:6 step:6332 [D loss: 0.618578, acc.: 67.97%] [G loss: 0.619493]\n",
      "epoch:6 step:6333 [D loss: 0.589790, acc.: 64.84%] [G loss: 0.553325]\n",
      "epoch:6 step:6334 [D loss: 0.532737, acc.: 72.66%] [G loss: 0.609540]\n",
      "epoch:6 step:6335 [D loss: 0.590344, acc.: 67.97%] [G loss: 0.652219]\n",
      "epoch:6 step:6336 [D loss: 0.519422, acc.: 79.69%] [G loss: 0.625082]\n",
      "epoch:6 step:6337 [D loss: 0.558594, acc.: 69.53%] [G loss: 0.512710]\n",
      "epoch:6 step:6338 [D loss: 0.617004, acc.: 66.41%] [G loss: 0.623963]\n",
      "epoch:6 step:6339 [D loss: 0.607348, acc.: 63.28%] [G loss: 0.510891]\n",
      "epoch:6 step:6340 [D loss: 0.567791, acc.: 73.44%] [G loss: 0.510533]\n",
      "epoch:6 step:6341 [D loss: 0.474225, acc.: 81.25%] [G loss: 0.542167]\n",
      "epoch:6 step:6342 [D loss: 0.651157, acc.: 65.62%] [G loss: 0.551412]\n",
      "epoch:6 step:6343 [D loss: 0.596254, acc.: 64.84%] [G loss: 0.578258]\n",
      "epoch:6 step:6344 [D loss: 0.541566, acc.: 65.62%] [G loss: 0.628539]\n",
      "epoch:6 step:6345 [D loss: 0.530030, acc.: 71.09%] [G loss: 0.528362]\n",
      "epoch:6 step:6346 [D loss: 0.573054, acc.: 71.88%] [G loss: 0.571589]\n",
      "epoch:6 step:6347 [D loss: 0.459058, acc.: 82.03%] [G loss: 0.694032]\n",
      "epoch:6 step:6348 [D loss: 0.567743, acc.: 71.88%] [G loss: 0.716581]\n",
      "epoch:6 step:6349 [D loss: 0.560593, acc.: 70.31%] [G loss: 0.642490]\n",
      "epoch:6 step:6350 [D loss: 0.513129, acc.: 71.09%] [G loss: 0.534773]\n",
      "epoch:6 step:6351 [D loss: 0.534752, acc.: 74.22%] [G loss: 0.591199]\n",
      "epoch:6 step:6352 [D loss: 0.525101, acc.: 78.12%] [G loss: 0.527802]\n",
      "epoch:6 step:6353 [D loss: 0.559461, acc.: 67.19%] [G loss: 0.559785]\n",
      "epoch:6 step:6354 [D loss: 0.467729, acc.: 78.12%] [G loss: 0.678521]\n",
      "epoch:6 step:6355 [D loss: 0.537512, acc.: 69.53%] [G loss: 0.599354]\n",
      "epoch:6 step:6356 [D loss: 0.527496, acc.: 69.53%] [G loss: 0.565363]\n",
      "epoch:6 step:6357 [D loss: 0.490404, acc.: 76.56%] [G loss: 0.558505]\n",
      "epoch:6 step:6358 [D loss: 0.497028, acc.: 75.78%] [G loss: 0.556314]\n",
      "epoch:6 step:6359 [D loss: 0.555981, acc.: 67.97%] [G loss: 0.732913]\n",
      "epoch:6 step:6360 [D loss: 0.525622, acc.: 68.75%] [G loss: 0.616717]\n",
      "epoch:6 step:6361 [D loss: 0.579577, acc.: 66.41%] [G loss: 0.544253]\n",
      "epoch:6 step:6362 [D loss: 0.597746, acc.: 67.19%] [G loss: 0.493933]\n",
      "epoch:6 step:6363 [D loss: 0.519138, acc.: 75.78%] [G loss: 0.533974]\n",
      "epoch:6 step:6364 [D loss: 0.535671, acc.: 72.66%] [G loss: 0.561543]\n",
      "epoch:6 step:6365 [D loss: 0.483450, acc.: 74.22%] [G loss: 0.648959]\n",
      "epoch:6 step:6366 [D loss: 0.553106, acc.: 73.44%] [G loss: 0.554174]\n",
      "epoch:6 step:6367 [D loss: 0.574725, acc.: 69.53%] [G loss: 0.672826]\n",
      "epoch:6 step:6368 [D loss: 0.517051, acc.: 76.56%] [G loss: 0.730491]\n",
      "epoch:6 step:6369 [D loss: 0.428147, acc.: 78.12%] [G loss: 0.682747]\n",
      "epoch:6 step:6370 [D loss: 0.562030, acc.: 69.53%] [G loss: 0.649133]\n",
      "epoch:6 step:6371 [D loss: 0.541658, acc.: 71.09%] [G loss: 0.605446]\n",
      "epoch:6 step:6372 [D loss: 0.580840, acc.: 71.88%] [G loss: 0.563004]\n",
      "epoch:6 step:6373 [D loss: 0.483774, acc.: 79.69%] [G loss: 0.684657]\n",
      "epoch:6 step:6374 [D loss: 0.516320, acc.: 75.78%] [G loss: 0.795444]\n",
      "epoch:6 step:6375 [D loss: 0.515244, acc.: 71.88%] [G loss: 0.793867]\n",
      "epoch:6 step:6376 [D loss: 0.522680, acc.: 70.31%] [G loss: 0.579284]\n",
      "epoch:6 step:6377 [D loss: 0.521707, acc.: 76.56%] [G loss: 0.674533]\n",
      "epoch:6 step:6378 [D loss: 0.546012, acc.: 72.66%] [G loss: 0.590584]\n",
      "epoch:6 step:6379 [D loss: 0.561259, acc.: 67.97%] [G loss: 0.517880]\n",
      "epoch:6 step:6380 [D loss: 0.520718, acc.: 75.00%] [G loss: 0.618610]\n",
      "epoch:6 step:6381 [D loss: 0.519320, acc.: 74.22%] [G loss: 0.646248]\n",
      "epoch:6 step:6382 [D loss: 0.513656, acc.: 68.75%] [G loss: 0.542354]\n",
      "epoch:6 step:6383 [D loss: 0.533404, acc.: 73.44%] [G loss: 0.479055]\n",
      "epoch:6 step:6384 [D loss: 0.565237, acc.: 67.19%] [G loss: 0.561675]\n",
      "epoch:6 step:6385 [D loss: 0.532089, acc.: 72.66%] [G loss: 0.616239]\n",
      "epoch:6 step:6386 [D loss: 0.538058, acc.: 71.88%] [G loss: 0.551348]\n",
      "epoch:6 step:6387 [D loss: 0.654041, acc.: 64.84%] [G loss: 0.532004]\n",
      "epoch:6 step:6388 [D loss: 0.721079, acc.: 58.59%] [G loss: 0.524172]\n",
      "epoch:6 step:6389 [D loss: 0.490344, acc.: 77.34%] [G loss: 0.589160]\n",
      "epoch:6 step:6390 [D loss: 0.513677, acc.: 76.56%] [G loss: 0.588523]\n",
      "epoch:6 step:6391 [D loss: 0.475355, acc.: 78.91%] [G loss: 0.796749]\n",
      "epoch:6 step:6392 [D loss: 0.453837, acc.: 79.69%] [G loss: 0.727554]\n",
      "epoch:6 step:6393 [D loss: 0.469544, acc.: 81.25%] [G loss: 0.703837]\n",
      "epoch:6 step:6394 [D loss: 0.494951, acc.: 75.78%] [G loss: 0.704430]\n",
      "epoch:6 step:6395 [D loss: 0.531416, acc.: 75.00%] [G loss: 0.541407]\n",
      "epoch:6 step:6396 [D loss: 0.601800, acc.: 69.53%] [G loss: 0.411765]\n",
      "epoch:6 step:6397 [D loss: 0.577150, acc.: 68.75%] [G loss: 0.539994]\n",
      "epoch:6 step:6398 [D loss: 0.579788, acc.: 69.53%] [G loss: 0.564209]\n",
      "epoch:6 step:6399 [D loss: 0.521349, acc.: 71.09%] [G loss: 0.644193]\n",
      "epoch:6 step:6400 [D loss: 0.528800, acc.: 69.53%] [G loss: 0.606927]\n",
      "epoch:6 step:6401 [D loss: 0.516596, acc.: 74.22%] [G loss: 0.695789]\n",
      "epoch:6 step:6402 [D loss: 0.503767, acc.: 77.34%] [G loss: 0.610438]\n",
      "epoch:6 step:6403 [D loss: 0.550011, acc.: 69.53%] [G loss: 0.801101]\n",
      "epoch:6 step:6404 [D loss: 0.462754, acc.: 81.25%] [G loss: 0.998132]\n",
      "epoch:6 step:6405 [D loss: 0.553371, acc.: 65.62%] [G loss: 0.830854]\n",
      "epoch:6 step:6406 [D loss: 0.649986, acc.: 58.59%] [G loss: 0.565500]\n",
      "epoch:6 step:6407 [D loss: 0.520898, acc.: 75.00%] [G loss: 0.602108]\n",
      "epoch:6 step:6408 [D loss: 0.481799, acc.: 75.78%] [G loss: 0.719937]\n",
      "epoch:6 step:6409 [D loss: 0.608781, acc.: 69.53%] [G loss: 0.684042]\n",
      "epoch:6 step:6410 [D loss: 0.701778, acc.: 56.25%] [G loss: 0.531931]\n",
      "epoch:6 step:6411 [D loss: 0.560473, acc.: 73.44%] [G loss: 0.616377]\n",
      "epoch:6 step:6412 [D loss: 0.512763, acc.: 74.22%] [G loss: 0.535629]\n",
      "epoch:6 step:6413 [D loss: 0.540274, acc.: 71.09%] [G loss: 0.512349]\n",
      "epoch:6 step:6414 [D loss: 0.476869, acc.: 79.69%] [G loss: 0.517400]\n",
      "epoch:6 step:6415 [D loss: 0.579232, acc.: 65.62%] [G loss: 0.624856]\n",
      "epoch:6 step:6416 [D loss: 0.570274, acc.: 67.19%] [G loss: 0.552443]\n",
      "epoch:6 step:6417 [D loss: 0.482055, acc.: 78.12%] [G loss: 0.701997]\n",
      "epoch:6 step:6418 [D loss: 0.456273, acc.: 78.12%] [G loss: 0.758362]\n",
      "epoch:6 step:6419 [D loss: 0.572062, acc.: 67.97%] [G loss: 0.700947]\n",
      "epoch:6 step:6420 [D loss: 0.492245, acc.: 70.31%] [G loss: 0.631690]\n",
      "epoch:6 step:6421 [D loss: 0.512844, acc.: 71.88%] [G loss: 0.724610]\n",
      "epoch:6 step:6422 [D loss: 0.540332, acc.: 71.88%] [G loss: 0.750153]\n",
      "epoch:6 step:6423 [D loss: 0.513858, acc.: 74.22%] [G loss: 0.521999]\n",
      "epoch:6 step:6424 [D loss: 0.453946, acc.: 80.47%] [G loss: 0.670840]\n",
      "epoch:6 step:6425 [D loss: 0.515198, acc.: 77.34%] [G loss: 0.854222]\n",
      "epoch:6 step:6426 [D loss: 0.606638, acc.: 64.84%] [G loss: 0.552548]\n",
      "epoch:6 step:6427 [D loss: 0.520307, acc.: 71.09%] [G loss: 0.654992]\n",
      "epoch:6 step:6428 [D loss: 0.544449, acc.: 71.88%] [G loss: 0.582105]\n",
      "epoch:6 step:6429 [D loss: 0.513033, acc.: 73.44%] [G loss: 0.630008]\n",
      "epoch:6 step:6430 [D loss: 0.550722, acc.: 74.22%] [G loss: 0.648594]\n",
      "epoch:6 step:6431 [D loss: 0.544372, acc.: 67.97%] [G loss: 0.583161]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:6 step:6432 [D loss: 0.496087, acc.: 78.12%] [G loss: 0.657448]\n",
      "epoch:6 step:6433 [D loss: 0.552353, acc.: 71.09%] [G loss: 0.525495]\n",
      "epoch:6 step:6434 [D loss: 0.639153, acc.: 66.41%] [G loss: 0.430354]\n",
      "epoch:6 step:6435 [D loss: 0.489556, acc.: 77.34%] [G loss: 0.624706]\n",
      "epoch:6 step:6436 [D loss: 0.562310, acc.: 67.19%] [G loss: 0.545115]\n",
      "epoch:6 step:6437 [D loss: 0.532565, acc.: 75.00%] [G loss: 0.526108]\n",
      "epoch:6 step:6438 [D loss: 0.580262, acc.: 67.19%] [G loss: 0.644258]\n",
      "epoch:6 step:6439 [D loss: 0.568507, acc.: 70.31%] [G loss: 0.512527]\n",
      "epoch:6 step:6440 [D loss: 0.551624, acc.: 67.97%] [G loss: 0.602101]\n",
      "epoch:6 step:6441 [D loss: 0.538011, acc.: 67.19%] [G loss: 0.549781]\n",
      "epoch:6 step:6442 [D loss: 0.557579, acc.: 70.31%] [G loss: 0.642384]\n",
      "epoch:6 step:6443 [D loss: 0.557253, acc.: 73.44%] [G loss: 0.617854]\n",
      "epoch:6 step:6444 [D loss: 0.472726, acc.: 79.69%] [G loss: 0.703878]\n",
      "epoch:6 step:6445 [D loss: 0.483403, acc.: 74.22%] [G loss: 0.502061]\n",
      "epoch:6 step:6446 [D loss: 0.648142, acc.: 64.84%] [G loss: 0.559177]\n",
      "epoch:6 step:6447 [D loss: 0.577969, acc.: 65.62%] [G loss: 0.429698]\n",
      "epoch:6 step:6448 [D loss: 0.544216, acc.: 71.88%] [G loss: 0.603987]\n",
      "epoch:6 step:6449 [D loss: 0.605742, acc.: 65.62%] [G loss: 0.525554]\n",
      "epoch:6 step:6450 [D loss: 0.668296, acc.: 60.16%] [G loss: 0.656202]\n",
      "epoch:6 step:6451 [D loss: 0.534293, acc.: 70.31%] [G loss: 0.772382]\n",
      "epoch:6 step:6452 [D loss: 0.555000, acc.: 67.19%] [G loss: 0.664154]\n",
      "epoch:6 step:6453 [D loss: 0.594418, acc.: 66.41%] [G loss: 0.588412]\n",
      "epoch:6 step:6454 [D loss: 0.490013, acc.: 77.34%] [G loss: 0.526057]\n",
      "epoch:6 step:6455 [D loss: 0.519520, acc.: 71.88%] [G loss: 0.552556]\n",
      "epoch:6 step:6456 [D loss: 0.465315, acc.: 82.03%] [G loss: 0.559474]\n",
      "epoch:6 step:6457 [D loss: 0.473692, acc.: 76.56%] [G loss: 0.602903]\n",
      "epoch:6 step:6458 [D loss: 0.525165, acc.: 68.75%] [G loss: 0.548191]\n",
      "epoch:6 step:6459 [D loss: 0.543191, acc.: 71.09%] [G loss: 0.509461]\n",
      "epoch:6 step:6460 [D loss: 0.487371, acc.: 73.44%] [G loss: 0.629571]\n",
      "epoch:6 step:6461 [D loss: 0.569365, acc.: 68.75%] [G loss: 0.451851]\n",
      "epoch:6 step:6462 [D loss: 0.609274, acc.: 64.84%] [G loss: 0.520046]\n",
      "epoch:6 step:6463 [D loss: 0.483303, acc.: 78.12%] [G loss: 0.540326]\n",
      "epoch:6 step:6464 [D loss: 0.517981, acc.: 74.22%] [G loss: 0.539809]\n",
      "epoch:6 step:6465 [D loss: 0.555610, acc.: 74.22%] [G loss: 0.528011]\n",
      "epoch:6 step:6466 [D loss: 0.529875, acc.: 71.09%] [G loss: 0.704596]\n",
      "epoch:6 step:6467 [D loss: 0.549954, acc.: 72.66%] [G loss: 0.593407]\n",
      "epoch:6 step:6468 [D loss: 0.535636, acc.: 75.78%] [G loss: 0.526831]\n",
      "epoch:6 step:6469 [D loss: 0.592013, acc.: 61.72%] [G loss: 0.473277]\n",
      "epoch:6 step:6470 [D loss: 0.520109, acc.: 69.53%] [G loss: 0.611394]\n",
      "epoch:6 step:6471 [D loss: 0.574876, acc.: 70.31%] [G loss: 0.590330]\n",
      "epoch:6 step:6472 [D loss: 0.520511, acc.: 73.44%] [G loss: 0.458521]\n",
      "epoch:6 step:6473 [D loss: 0.578623, acc.: 69.53%] [G loss: 0.450869]\n",
      "epoch:6 step:6474 [D loss: 0.476299, acc.: 78.12%] [G loss: 0.498126]\n",
      "epoch:6 step:6475 [D loss: 0.516621, acc.: 72.66%] [G loss: 0.579059]\n",
      "epoch:6 step:6476 [D loss: 0.508905, acc.: 72.66%] [G loss: 0.778960]\n",
      "epoch:6 step:6477 [D loss: 0.498970, acc.: 75.78%] [G loss: 0.669433]\n",
      "epoch:6 step:6478 [D loss: 0.583337, acc.: 67.19%] [G loss: 0.599416]\n",
      "epoch:6 step:6479 [D loss: 0.473335, acc.: 79.69%] [G loss: 0.553092]\n",
      "epoch:6 step:6480 [D loss: 0.624593, acc.: 66.41%] [G loss: 0.634970]\n",
      "epoch:6 step:6481 [D loss: 0.517304, acc.: 73.44%] [G loss: 0.542342]\n",
      "epoch:6 step:6482 [D loss: 0.485374, acc.: 77.34%] [G loss: 0.546067]\n",
      "epoch:6 step:6483 [D loss: 0.604027, acc.: 66.41%] [G loss: 0.484399]\n",
      "epoch:6 step:6484 [D loss: 0.500168, acc.: 76.56%] [G loss: 0.509592]\n",
      "epoch:6 step:6485 [D loss: 0.575123, acc.: 69.53%] [G loss: 0.446200]\n",
      "epoch:6 step:6486 [D loss: 0.480550, acc.: 78.12%] [G loss: 0.631014]\n",
      "epoch:6 step:6487 [D loss: 0.573607, acc.: 66.41%] [G loss: 0.565074]\n",
      "epoch:6 step:6488 [D loss: 0.544605, acc.: 67.19%] [G loss: 0.586881]\n",
      "epoch:6 step:6489 [D loss: 0.666847, acc.: 64.06%] [G loss: 0.512512]\n",
      "epoch:6 step:6490 [D loss: 0.537581, acc.: 72.66%] [G loss: 0.395150]\n",
      "epoch:6 step:6491 [D loss: 0.525385, acc.: 72.66%] [G loss: 0.565397]\n",
      "epoch:6 step:6492 [D loss: 0.479743, acc.: 80.47%] [G loss: 0.592316]\n",
      "epoch:6 step:6493 [D loss: 0.545319, acc.: 71.09%] [G loss: 0.631518]\n",
      "epoch:6 step:6494 [D loss: 0.542548, acc.: 71.88%] [G loss: 0.665343]\n",
      "epoch:6 step:6495 [D loss: 0.542800, acc.: 71.09%] [G loss: 0.577816]\n",
      "epoch:6 step:6496 [D loss: 0.539826, acc.: 70.31%] [G loss: 0.591590]\n",
      "epoch:6 step:6497 [D loss: 0.470727, acc.: 76.56%] [G loss: 0.632298]\n",
      "epoch:6 step:6498 [D loss: 0.588776, acc.: 68.75%] [G loss: 0.555261]\n",
      "epoch:6 step:6499 [D loss: 0.512633, acc.: 78.12%] [G loss: 0.492434]\n",
      "epoch:6 step:6500 [D loss: 0.581678, acc.: 71.88%] [G loss: 0.533294]\n",
      "epoch:6 step:6501 [D loss: 0.554021, acc.: 70.31%] [G loss: 0.437420]\n",
      "epoch:6 step:6502 [D loss: 0.630278, acc.: 61.72%] [G loss: 0.521765]\n",
      "epoch:6 step:6503 [D loss: 0.577498, acc.: 71.88%] [G loss: 0.470324]\n",
      "epoch:6 step:6504 [D loss: 0.550788, acc.: 71.88%] [G loss: 0.453628]\n",
      "epoch:6 step:6505 [D loss: 0.557719, acc.: 68.75%] [G loss: 0.464456]\n",
      "epoch:6 step:6506 [D loss: 0.445552, acc.: 83.59%] [G loss: 0.657149]\n",
      "epoch:6 step:6507 [D loss: 0.506049, acc.: 77.34%] [G loss: 0.677282]\n",
      "epoch:6 step:6508 [D loss: 0.511356, acc.: 75.78%] [G loss: 0.756004]\n",
      "epoch:6 step:6509 [D loss: 0.519645, acc.: 72.66%] [G loss: 0.753303]\n",
      "epoch:6 step:6510 [D loss: 0.559304, acc.: 68.75%] [G loss: 0.622215]\n",
      "epoch:6 step:6511 [D loss: 0.550710, acc.: 72.66%] [G loss: 0.548110]\n",
      "epoch:6 step:6512 [D loss: 0.435050, acc.: 82.81%] [G loss: 0.685314]\n",
      "epoch:6 step:6513 [D loss: 0.559484, acc.: 68.75%] [G loss: 0.539385]\n",
      "epoch:6 step:6514 [D loss: 0.623084, acc.: 61.72%] [G loss: 0.506607]\n",
      "epoch:6 step:6515 [D loss: 0.547769, acc.: 77.34%] [G loss: 0.508504]\n",
      "epoch:6 step:6516 [D loss: 0.460386, acc.: 81.25%] [G loss: 0.612113]\n",
      "epoch:6 step:6517 [D loss: 0.531231, acc.: 74.22%] [G loss: 0.873891]\n",
      "epoch:6 step:6518 [D loss: 0.536393, acc.: 75.00%] [G loss: 0.617998]\n",
      "epoch:6 step:6519 [D loss: 0.490559, acc.: 75.78%] [G loss: 0.708444]\n",
      "epoch:6 step:6520 [D loss: 0.451094, acc.: 78.12%] [G loss: 0.619483]\n",
      "epoch:6 step:6521 [D loss: 0.517587, acc.: 75.00%] [G loss: 0.587153]\n",
      "epoch:6 step:6522 [D loss: 0.538044, acc.: 77.34%] [G loss: 0.645589]\n",
      "epoch:6 step:6523 [D loss: 0.548778, acc.: 68.75%] [G loss: 0.725157]\n",
      "epoch:6 step:6524 [D loss: 0.566041, acc.: 66.41%] [G loss: 0.696433]\n",
      "epoch:6 step:6525 [D loss: 0.560845, acc.: 71.88%] [G loss: 0.565971]\n",
      "epoch:6 step:6526 [D loss: 0.519507, acc.: 71.88%] [G loss: 0.564541]\n",
      "epoch:6 step:6527 [D loss: 0.574402, acc.: 68.75%] [G loss: 0.540977]\n",
      "epoch:6 step:6528 [D loss: 0.502632, acc.: 77.34%] [G loss: 0.605630]\n",
      "epoch:6 step:6529 [D loss: 0.536867, acc.: 70.31%] [G loss: 0.630233]\n",
      "epoch:6 step:6530 [D loss: 0.563724, acc.: 63.28%] [G loss: 0.598009]\n",
      "epoch:6 step:6531 [D loss: 0.493882, acc.: 77.34%] [G loss: 0.582179]\n",
      "epoch:6 step:6532 [D loss: 0.486043, acc.: 72.66%] [G loss: 0.721442]\n",
      "epoch:6 step:6533 [D loss: 0.461181, acc.: 79.69%] [G loss: 0.712536]\n",
      "epoch:6 step:6534 [D loss: 0.417761, acc.: 81.25%] [G loss: 0.854694]\n",
      "epoch:6 step:6535 [D loss: 0.645244, acc.: 59.38%] [G loss: 0.765812]\n",
      "epoch:6 step:6536 [D loss: 0.521939, acc.: 71.88%] [G loss: 0.770686]\n",
      "epoch:6 step:6537 [D loss: 0.588522, acc.: 65.62%] [G loss: 0.843684]\n",
      "epoch:6 step:6538 [D loss: 0.491709, acc.: 78.91%] [G loss: 0.585433]\n",
      "epoch:6 step:6539 [D loss: 0.567729, acc.: 67.97%] [G loss: 0.538303]\n",
      "epoch:6 step:6540 [D loss: 0.536005, acc.: 71.88%] [G loss: 0.644393]\n",
      "epoch:6 step:6541 [D loss: 0.489338, acc.: 77.34%] [G loss: 0.778381]\n",
      "epoch:6 step:6542 [D loss: 0.689065, acc.: 64.06%] [G loss: 0.590885]\n",
      "epoch:6 step:6543 [D loss: 0.478311, acc.: 77.34%] [G loss: 0.728809]\n",
      "epoch:6 step:6544 [D loss: 0.567536, acc.: 66.41%] [G loss: 0.609875]\n",
      "epoch:6 step:6545 [D loss: 0.441181, acc.: 78.12%] [G loss: 0.707639]\n",
      "epoch:6 step:6546 [D loss: 0.492699, acc.: 77.34%] [G loss: 0.582687]\n",
      "epoch:6 step:6547 [D loss: 0.419175, acc.: 80.47%] [G loss: 0.935985]\n",
      "epoch:6 step:6548 [D loss: 0.513512, acc.: 78.91%] [G loss: 0.956838]\n",
      "epoch:6 step:6549 [D loss: 0.434182, acc.: 85.16%] [G loss: 1.095349]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:6 step:6550 [D loss: 0.793719, acc.: 64.06%] [G loss: 0.949020]\n",
      "epoch:6 step:6551 [D loss: 0.463492, acc.: 82.81%] [G loss: 1.170202]\n",
      "epoch:6 step:6552 [D loss: 0.506248, acc.: 71.09%] [G loss: 1.070569]\n",
      "epoch:6 step:6553 [D loss: 0.577014, acc.: 67.97%] [G loss: 0.726261]\n",
      "epoch:6 step:6554 [D loss: 0.617918, acc.: 67.19%] [G loss: 0.685602]\n",
      "epoch:6 step:6555 [D loss: 0.524294, acc.: 69.53%] [G loss: 0.588476]\n",
      "epoch:6 step:6556 [D loss: 0.540926, acc.: 73.44%] [G loss: 0.869286]\n",
      "epoch:6 step:6557 [D loss: 0.443577, acc.: 79.69%] [G loss: 0.784293]\n",
      "epoch:6 step:6558 [D loss: 0.451046, acc.: 74.22%] [G loss: 0.999201]\n",
      "epoch:6 step:6559 [D loss: 0.415098, acc.: 82.03%] [G loss: 1.096051]\n",
      "epoch:7 step:6560 [D loss: 0.615301, acc.: 69.53%] [G loss: 0.963155]\n",
      "epoch:7 step:6561 [D loss: 0.492868, acc.: 76.56%] [G loss: 0.918959]\n",
      "epoch:7 step:6562 [D loss: 0.556594, acc.: 71.09%] [G loss: 0.607835]\n",
      "epoch:7 step:6563 [D loss: 0.472204, acc.: 77.34%] [G loss: 0.617136]\n",
      "epoch:7 step:6564 [D loss: 0.572419, acc.: 66.41%] [G loss: 0.619511]\n",
      "epoch:7 step:6565 [D loss: 0.567573, acc.: 71.88%] [G loss: 0.560782]\n",
      "epoch:7 step:6566 [D loss: 0.499177, acc.: 77.34%] [G loss: 0.690308]\n",
      "epoch:7 step:6567 [D loss: 0.474920, acc.: 80.47%] [G loss: 0.660480]\n",
      "epoch:7 step:6568 [D loss: 0.534637, acc.: 71.09%] [G loss: 0.617605]\n",
      "epoch:7 step:6569 [D loss: 0.549855, acc.: 71.09%] [G loss: 0.575675]\n",
      "epoch:7 step:6570 [D loss: 0.450222, acc.: 79.69%] [G loss: 0.751669]\n",
      "epoch:7 step:6571 [D loss: 0.546921, acc.: 78.12%] [G loss: 0.578796]\n",
      "epoch:7 step:6572 [D loss: 0.555950, acc.: 71.09%] [G loss: 0.498099]\n",
      "epoch:7 step:6573 [D loss: 0.575704, acc.: 70.31%] [G loss: 0.550304]\n",
      "epoch:7 step:6574 [D loss: 0.483381, acc.: 75.78%] [G loss: 0.673972]\n",
      "epoch:7 step:6575 [D loss: 0.493154, acc.: 74.22%] [G loss: 0.661986]\n",
      "epoch:7 step:6576 [D loss: 0.579078, acc.: 67.19%] [G loss: 0.521179]\n",
      "epoch:7 step:6577 [D loss: 0.581358, acc.: 68.75%] [G loss: 0.528659]\n",
      "epoch:7 step:6578 [D loss: 0.615988, acc.: 68.75%] [G loss: 0.504495]\n",
      "epoch:7 step:6579 [D loss: 0.605846, acc.: 60.16%] [G loss: 0.635021]\n",
      "epoch:7 step:6580 [D loss: 0.526579, acc.: 75.00%] [G loss: 0.629189]\n",
      "epoch:7 step:6581 [D loss: 0.453896, acc.: 79.69%] [G loss: 0.837327]\n",
      "epoch:7 step:6582 [D loss: 0.546486, acc.: 69.53%] [G loss: 0.638915]\n",
      "epoch:7 step:6583 [D loss: 0.526806, acc.: 70.31%] [G loss: 0.532034]\n",
      "epoch:7 step:6584 [D loss: 0.468246, acc.: 78.91%] [G loss: 0.584473]\n",
      "epoch:7 step:6585 [D loss: 0.528629, acc.: 75.78%] [G loss: 0.540460]\n",
      "epoch:7 step:6586 [D loss: 0.427366, acc.: 78.91%] [G loss: 0.679508]\n",
      "epoch:7 step:6587 [D loss: 0.520650, acc.: 75.00%] [G loss: 0.478869]\n",
      "epoch:7 step:6588 [D loss: 0.486574, acc.: 75.78%] [G loss: 0.568988]\n",
      "epoch:7 step:6589 [D loss: 0.530692, acc.: 69.53%] [G loss: 0.520142]\n",
      "epoch:7 step:6590 [D loss: 0.590815, acc.: 66.41%] [G loss: 0.421271]\n",
      "epoch:7 step:6591 [D loss: 0.544142, acc.: 71.09%] [G loss: 0.549518]\n",
      "epoch:7 step:6592 [D loss: 0.471088, acc.: 78.12%] [G loss: 0.557826]\n",
      "epoch:7 step:6593 [D loss: 0.481926, acc.: 76.56%] [G loss: 0.639711]\n",
      "epoch:7 step:6594 [D loss: 0.541179, acc.: 73.44%] [G loss: 0.596692]\n",
      "epoch:7 step:6595 [D loss: 0.497325, acc.: 77.34%] [G loss: 0.652726]\n",
      "epoch:7 step:6596 [D loss: 0.456563, acc.: 80.47%] [G loss: 0.681631]\n",
      "epoch:7 step:6597 [D loss: 0.557900, acc.: 71.88%] [G loss: 0.602397]\n",
      "epoch:7 step:6598 [D loss: 0.529585, acc.: 75.78%] [G loss: 0.435646]\n",
      "epoch:7 step:6599 [D loss: 0.443062, acc.: 81.25%] [G loss: 0.612134]\n",
      "epoch:7 step:6600 [D loss: 0.494967, acc.: 74.22%] [G loss: 0.784290]\n",
      "epoch:7 step:6601 [D loss: 0.504862, acc.: 69.53%] [G loss: 0.679569]\n",
      "epoch:7 step:6602 [D loss: 0.584429, acc.: 67.97%] [G loss: 0.658588]\n",
      "epoch:7 step:6603 [D loss: 0.592398, acc.: 65.62%] [G loss: 0.485628]\n",
      "epoch:7 step:6604 [D loss: 0.496503, acc.: 78.91%] [G loss: 0.603829]\n",
      "epoch:7 step:6605 [D loss: 0.493438, acc.: 75.78%] [G loss: 0.699684]\n",
      "epoch:7 step:6606 [D loss: 0.585912, acc.: 71.88%] [G loss: 0.587511]\n",
      "epoch:7 step:6607 [D loss: 0.556003, acc.: 70.31%] [G loss: 0.628093]\n",
      "epoch:7 step:6608 [D loss: 0.507610, acc.: 75.00%] [G loss: 0.611767]\n",
      "epoch:7 step:6609 [D loss: 0.536857, acc.: 71.88%] [G loss: 0.640107]\n",
      "epoch:7 step:6610 [D loss: 0.616263, acc.: 64.84%] [G loss: 0.467631]\n",
      "epoch:7 step:6611 [D loss: 0.565988, acc.: 66.41%] [G loss: 0.510724]\n",
      "epoch:7 step:6612 [D loss: 0.508741, acc.: 75.78%] [G loss: 0.545404]\n",
      "epoch:7 step:6613 [D loss: 0.467617, acc.: 80.47%] [G loss: 0.707915]\n",
      "epoch:7 step:6614 [D loss: 0.565798, acc.: 69.53%] [G loss: 0.583883]\n",
      "epoch:7 step:6615 [D loss: 0.531103, acc.: 76.56%] [G loss: 0.584191]\n",
      "epoch:7 step:6616 [D loss: 0.520870, acc.: 72.66%] [G loss: 0.675540]\n",
      "epoch:7 step:6617 [D loss: 0.579780, acc.: 65.62%] [G loss: 0.497117]\n",
      "epoch:7 step:6618 [D loss: 0.479174, acc.: 80.47%] [G loss: 0.647064]\n",
      "epoch:7 step:6619 [D loss: 0.561143, acc.: 68.75%] [G loss: 0.573794]\n",
      "epoch:7 step:6620 [D loss: 0.545825, acc.: 73.44%] [G loss: 0.554900]\n",
      "epoch:7 step:6621 [D loss: 0.529193, acc.: 73.44%] [G loss: 0.569331]\n",
      "epoch:7 step:6622 [D loss: 0.535570, acc.: 73.44%] [G loss: 0.545979]\n",
      "epoch:7 step:6623 [D loss: 0.521303, acc.: 73.44%] [G loss: 0.470329]\n",
      "epoch:7 step:6624 [D loss: 0.550120, acc.: 71.09%] [G loss: 0.505401]\n",
      "epoch:7 step:6625 [D loss: 0.507364, acc.: 75.00%] [G loss: 0.562304]\n",
      "epoch:7 step:6626 [D loss: 0.518929, acc.: 75.78%] [G loss: 0.456283]\n",
      "epoch:7 step:6627 [D loss: 0.499696, acc.: 75.78%] [G loss: 0.664136]\n",
      "epoch:7 step:6628 [D loss: 0.498387, acc.: 80.47%] [G loss: 0.624990]\n",
      "epoch:7 step:6629 [D loss: 0.548575, acc.: 75.00%] [G loss: 0.569550]\n",
      "epoch:7 step:6630 [D loss: 0.546699, acc.: 68.75%] [G loss: 0.548601]\n",
      "epoch:7 step:6631 [D loss: 0.515820, acc.: 76.56%] [G loss: 0.501328]\n",
      "epoch:7 step:6632 [D loss: 0.533914, acc.: 75.00%] [G loss: 0.507851]\n",
      "epoch:7 step:6633 [D loss: 0.515787, acc.: 75.00%] [G loss: 0.461376]\n",
      "epoch:7 step:6634 [D loss: 0.530751, acc.: 70.31%] [G loss: 0.639526]\n",
      "epoch:7 step:6635 [D loss: 0.498310, acc.: 73.44%] [G loss: 0.713077]\n",
      "epoch:7 step:6636 [D loss: 0.458865, acc.: 78.91%] [G loss: 0.744907]\n",
      "epoch:7 step:6637 [D loss: 0.572601, acc.: 71.88%] [G loss: 0.562098]\n",
      "epoch:7 step:6638 [D loss: 0.538369, acc.: 75.78%] [G loss: 0.462685]\n",
      "epoch:7 step:6639 [D loss: 0.496839, acc.: 76.56%] [G loss: 0.533018]\n",
      "epoch:7 step:6640 [D loss: 0.540367, acc.: 74.22%] [G loss: 0.586016]\n",
      "epoch:7 step:6641 [D loss: 0.532268, acc.: 69.53%] [G loss: 0.582927]\n",
      "epoch:7 step:6642 [D loss: 0.493126, acc.: 74.22%] [G loss: 0.573231]\n",
      "epoch:7 step:6643 [D loss: 0.490302, acc.: 75.00%] [G loss: 0.629690]\n",
      "epoch:7 step:6644 [D loss: 0.576727, acc.: 68.75%] [G loss: 0.591246]\n",
      "epoch:7 step:6645 [D loss: 0.568301, acc.: 71.09%] [G loss: 0.518438]\n",
      "epoch:7 step:6646 [D loss: 0.449150, acc.: 83.59%] [G loss: 0.639686]\n",
      "epoch:7 step:6647 [D loss: 0.480208, acc.: 78.12%] [G loss: 0.615838]\n",
      "epoch:7 step:6648 [D loss: 0.520712, acc.: 75.00%] [G loss: 0.651001]\n",
      "epoch:7 step:6649 [D loss: 0.522610, acc.: 75.00%] [G loss: 0.616080]\n",
      "epoch:7 step:6650 [D loss: 0.573316, acc.: 67.97%] [G loss: 0.684866]\n",
      "epoch:7 step:6651 [D loss: 0.467589, acc.: 79.69%] [G loss: 0.678068]\n",
      "epoch:7 step:6652 [D loss: 0.516304, acc.: 74.22%] [G loss: 0.616380]\n",
      "epoch:7 step:6653 [D loss: 0.482582, acc.: 72.66%] [G loss: 0.675077]\n",
      "epoch:7 step:6654 [D loss: 0.527209, acc.: 75.78%] [G loss: 0.537647]\n",
      "epoch:7 step:6655 [D loss: 0.517651, acc.: 75.78%] [G loss: 0.557168]\n",
      "epoch:7 step:6656 [D loss: 0.501864, acc.: 74.22%] [G loss: 0.683209]\n",
      "epoch:7 step:6657 [D loss: 0.523590, acc.: 74.22%] [G loss: 0.574566]\n",
      "epoch:7 step:6658 [D loss: 0.514140, acc.: 77.34%] [G loss: 0.628005]\n",
      "epoch:7 step:6659 [D loss: 0.465745, acc.: 78.12%] [G loss: 0.768037]\n",
      "epoch:7 step:6660 [D loss: 0.513574, acc.: 71.88%] [G loss: 0.621090]\n",
      "epoch:7 step:6661 [D loss: 0.588341, acc.: 67.97%] [G loss: 0.484856]\n",
      "epoch:7 step:6662 [D loss: 0.527273, acc.: 68.75%] [G loss: 0.500074]\n",
      "epoch:7 step:6663 [D loss: 0.531635, acc.: 71.09%] [G loss: 0.536746]\n",
      "epoch:7 step:6664 [D loss: 0.605081, acc.: 62.50%] [G loss: 0.652779]\n",
      "epoch:7 step:6665 [D loss: 0.566864, acc.: 73.44%] [G loss: 0.550299]\n",
      "epoch:7 step:6666 [D loss: 0.594823, acc.: 67.97%] [G loss: 0.597718]\n",
      "epoch:7 step:6667 [D loss: 0.588456, acc.: 67.97%] [G loss: 0.507077]\n",
      "epoch:7 step:6668 [D loss: 0.544523, acc.: 71.09%] [G loss: 0.475404]\n",
      "epoch:7 step:6669 [D loss: 0.525996, acc.: 77.34%] [G loss: 0.560564]\n",
      "epoch:7 step:6670 [D loss: 0.491388, acc.: 72.66%] [G loss: 0.691360]\n",
      "epoch:7 step:6671 [D loss: 0.538469, acc.: 65.62%] [G loss: 0.697190]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:7 step:6672 [D loss: 0.586760, acc.: 67.97%] [G loss: 0.564020]\n",
      "epoch:7 step:6673 [D loss: 0.614608, acc.: 66.41%] [G loss: 0.511683]\n",
      "epoch:7 step:6674 [D loss: 0.592070, acc.: 67.19%] [G loss: 0.580331]\n",
      "epoch:7 step:6675 [D loss: 0.516659, acc.: 78.12%] [G loss: 0.638793]\n",
      "epoch:7 step:6676 [D loss: 0.521289, acc.: 71.88%] [G loss: 0.626318]\n",
      "epoch:7 step:6677 [D loss: 0.544858, acc.: 74.22%] [G loss: 0.780613]\n",
      "epoch:7 step:6678 [D loss: 0.418360, acc.: 82.81%] [G loss: 0.857104]\n",
      "epoch:7 step:6679 [D loss: 0.608868, acc.: 67.97%] [G loss: 0.626539]\n",
      "epoch:7 step:6680 [D loss: 0.582022, acc.: 67.19%] [G loss: 0.702655]\n",
      "epoch:7 step:6681 [D loss: 0.511697, acc.: 75.78%] [G loss: 0.696097]\n",
      "epoch:7 step:6682 [D loss: 0.482665, acc.: 75.00%] [G loss: 0.748215]\n",
      "epoch:7 step:6683 [D loss: 0.536994, acc.: 74.22%] [G loss: 0.663981]\n",
      "epoch:7 step:6684 [D loss: 0.576198, acc.: 65.62%] [G loss: 0.622394]\n",
      "epoch:7 step:6685 [D loss: 0.534373, acc.: 72.66%] [G loss: 0.505395]\n",
      "epoch:7 step:6686 [D loss: 0.476493, acc.: 77.34%] [G loss: 0.582557]\n",
      "epoch:7 step:6687 [D loss: 0.497455, acc.: 72.66%] [G loss: 0.573178]\n",
      "epoch:7 step:6688 [D loss: 0.596777, acc.: 71.09%] [G loss: 0.553636]\n",
      "epoch:7 step:6689 [D loss: 0.513359, acc.: 75.00%] [G loss: 0.677578]\n",
      "epoch:7 step:6690 [D loss: 0.503716, acc.: 72.66%] [G loss: 0.549026]\n",
      "epoch:7 step:6691 [D loss: 0.600058, acc.: 67.97%] [G loss: 0.564146]\n",
      "epoch:7 step:6692 [D loss: 0.558393, acc.: 71.09%] [G loss: 0.484768]\n",
      "epoch:7 step:6693 [D loss: 0.489827, acc.: 74.22%] [G loss: 0.844063]\n",
      "epoch:7 step:6694 [D loss: 0.546738, acc.: 72.66%] [G loss: 0.718395]\n",
      "epoch:7 step:6695 [D loss: 0.525010, acc.: 71.88%] [G loss: 0.636621]\n",
      "epoch:7 step:6696 [D loss: 0.576930, acc.: 69.53%] [G loss: 0.623722]\n",
      "epoch:7 step:6697 [D loss: 0.564260, acc.: 68.75%] [G loss: 0.576936]\n",
      "epoch:7 step:6698 [D loss: 0.563989, acc.: 70.31%] [G loss: 0.683213]\n",
      "epoch:7 step:6699 [D loss: 0.537293, acc.: 69.53%] [G loss: 0.549921]\n",
      "epoch:7 step:6700 [D loss: 0.484540, acc.: 78.12%] [G loss: 0.582885]\n",
      "epoch:7 step:6701 [D loss: 0.592295, acc.: 67.97%] [G loss: 0.619494]\n",
      "epoch:7 step:6702 [D loss: 0.578350, acc.: 67.97%] [G loss: 0.562719]\n",
      "epoch:7 step:6703 [D loss: 0.518885, acc.: 74.22%] [G loss: 0.590073]\n",
      "epoch:7 step:6704 [D loss: 0.532557, acc.: 71.88%] [G loss: 0.611692]\n",
      "epoch:7 step:6705 [D loss: 0.439703, acc.: 83.59%] [G loss: 0.735140]\n",
      "epoch:7 step:6706 [D loss: 0.577240, acc.: 75.00%] [G loss: 0.528827]\n",
      "epoch:7 step:6707 [D loss: 0.552973, acc.: 73.44%] [G loss: 0.608990]\n",
      "epoch:7 step:6708 [D loss: 0.498669, acc.: 76.56%] [G loss: 0.568671]\n",
      "epoch:7 step:6709 [D loss: 0.617181, acc.: 67.19%] [G loss: 0.578871]\n",
      "epoch:7 step:6710 [D loss: 0.592490, acc.: 71.88%] [G loss: 0.481603]\n",
      "epoch:7 step:6711 [D loss: 0.493799, acc.: 78.12%] [G loss: 0.640684]\n",
      "epoch:7 step:6712 [D loss: 0.555552, acc.: 71.09%] [G loss: 0.513961]\n",
      "epoch:7 step:6713 [D loss: 0.498773, acc.: 75.78%] [G loss: 0.549362]\n",
      "epoch:7 step:6714 [D loss: 0.433411, acc.: 82.81%] [G loss: 0.550059]\n",
      "epoch:7 step:6715 [D loss: 0.480588, acc.: 78.12%] [G loss: 0.657740]\n",
      "epoch:7 step:6716 [D loss: 0.527129, acc.: 73.44%] [G loss: 0.563050]\n",
      "epoch:7 step:6717 [D loss: 0.554403, acc.: 72.66%] [G loss: 0.534412]\n",
      "epoch:7 step:6718 [D loss: 0.553390, acc.: 70.31%] [G loss: 0.654022]\n",
      "epoch:7 step:6719 [D loss: 0.570138, acc.: 73.44%] [G loss: 0.588242]\n",
      "epoch:7 step:6720 [D loss: 0.470930, acc.: 77.34%] [G loss: 0.626614]\n",
      "epoch:7 step:6721 [D loss: 0.520300, acc.: 74.22%] [G loss: 0.848002]\n",
      "epoch:7 step:6722 [D loss: 0.571862, acc.: 69.53%] [G loss: 0.733178]\n",
      "epoch:7 step:6723 [D loss: 0.555729, acc.: 65.62%] [G loss: 0.726746]\n",
      "epoch:7 step:6724 [D loss: 0.499765, acc.: 74.22%] [G loss: 0.590918]\n",
      "epoch:7 step:6725 [D loss: 0.531838, acc.: 71.88%] [G loss: 0.526283]\n",
      "epoch:7 step:6726 [D loss: 0.523904, acc.: 71.88%] [G loss: 0.637652]\n",
      "epoch:7 step:6727 [D loss: 0.561012, acc.: 70.31%] [G loss: 0.469951]\n",
      "epoch:7 step:6728 [D loss: 0.551241, acc.: 67.97%] [G loss: 0.413997]\n",
      "epoch:7 step:6729 [D loss: 0.528405, acc.: 71.09%] [G loss: 0.438989]\n",
      "epoch:7 step:6730 [D loss: 0.468273, acc.: 78.91%] [G loss: 0.566073]\n",
      "epoch:7 step:6731 [D loss: 0.490982, acc.: 75.00%] [G loss: 0.683016]\n",
      "epoch:7 step:6732 [D loss: 0.499247, acc.: 74.22%] [G loss: 0.605862]\n",
      "epoch:7 step:6733 [D loss: 0.527664, acc.: 68.75%] [G loss: 0.523010]\n",
      "epoch:7 step:6734 [D loss: 0.536357, acc.: 69.53%] [G loss: 0.506919]\n",
      "epoch:7 step:6735 [D loss: 0.515040, acc.: 71.09%] [G loss: 0.592142]\n",
      "epoch:7 step:6736 [D loss: 0.484412, acc.: 72.66%] [G loss: 0.722820]\n",
      "epoch:7 step:6737 [D loss: 0.580910, acc.: 65.62%] [G loss: 0.562557]\n",
      "epoch:7 step:6738 [D loss: 0.532122, acc.: 69.53%] [G loss: 0.541152]\n",
      "epoch:7 step:6739 [D loss: 0.578994, acc.: 74.22%] [G loss: 0.596416]\n",
      "epoch:7 step:6740 [D loss: 0.516593, acc.: 73.44%] [G loss: 0.575387]\n",
      "epoch:7 step:6741 [D loss: 0.538390, acc.: 71.09%] [G loss: 0.495714]\n",
      "epoch:7 step:6742 [D loss: 0.584785, acc.: 68.75%] [G loss: 0.603127]\n",
      "epoch:7 step:6743 [D loss: 0.568608, acc.: 69.53%] [G loss: 0.714227]\n",
      "epoch:7 step:6744 [D loss: 0.574808, acc.: 68.75%] [G loss: 0.583852]\n",
      "epoch:7 step:6745 [D loss: 0.528076, acc.: 73.44%] [G loss: 0.574436]\n",
      "epoch:7 step:6746 [D loss: 0.597988, acc.: 66.41%] [G loss: 0.525453]\n",
      "epoch:7 step:6747 [D loss: 0.554841, acc.: 70.31%] [G loss: 0.509180]\n",
      "epoch:7 step:6748 [D loss: 0.606142, acc.: 61.72%] [G loss: 0.520019]\n",
      "epoch:7 step:6749 [D loss: 0.473850, acc.: 76.56%] [G loss: 0.517340]\n",
      "epoch:7 step:6750 [D loss: 0.519198, acc.: 74.22%] [G loss: 0.615080]\n",
      "epoch:7 step:6751 [D loss: 0.517266, acc.: 69.53%] [G loss: 0.706399]\n",
      "epoch:7 step:6752 [D loss: 0.596828, acc.: 67.19%] [G loss: 0.636880]\n",
      "epoch:7 step:6753 [D loss: 0.451830, acc.: 81.25%] [G loss: 0.790230]\n",
      "epoch:7 step:6754 [D loss: 0.545974, acc.: 73.44%] [G loss: 0.694063]\n",
      "epoch:7 step:6755 [D loss: 0.538597, acc.: 70.31%] [G loss: 0.602474]\n",
      "epoch:7 step:6756 [D loss: 0.515123, acc.: 76.56%] [G loss: 0.568947]\n",
      "epoch:7 step:6757 [D loss: 0.492199, acc.: 76.56%] [G loss: 0.731449]\n",
      "epoch:7 step:6758 [D loss: 0.478559, acc.: 73.44%] [G loss: 0.759187]\n",
      "epoch:7 step:6759 [D loss: 0.592639, acc.: 68.75%] [G loss: 0.614580]\n",
      "epoch:7 step:6760 [D loss: 0.556619, acc.: 67.19%] [G loss: 0.622536]\n",
      "epoch:7 step:6761 [D loss: 0.553216, acc.: 71.09%] [G loss: 0.655137]\n",
      "epoch:7 step:6762 [D loss: 0.574492, acc.: 71.88%] [G loss: 0.510807]\n",
      "epoch:7 step:6763 [D loss: 0.567039, acc.: 73.44%] [G loss: 0.605063]\n",
      "epoch:7 step:6764 [D loss: 0.473042, acc.: 77.34%] [G loss: 0.761146]\n",
      "epoch:7 step:6765 [D loss: 0.516059, acc.: 75.00%] [G loss: 0.664465]\n",
      "epoch:7 step:6766 [D loss: 0.484891, acc.: 76.56%] [G loss: 0.775560]\n",
      "epoch:7 step:6767 [D loss: 0.438337, acc.: 81.25%] [G loss: 0.646226]\n",
      "epoch:7 step:6768 [D loss: 0.544734, acc.: 75.78%] [G loss: 0.734106]\n",
      "epoch:7 step:6769 [D loss: 0.610748, acc.: 66.41%] [G loss: 0.595069]\n",
      "epoch:7 step:6770 [D loss: 0.613242, acc.: 64.06%] [G loss: 0.542277]\n",
      "epoch:7 step:6771 [D loss: 0.522280, acc.: 72.66%] [G loss: 0.556127]\n",
      "epoch:7 step:6772 [D loss: 0.481489, acc.: 76.56%] [G loss: 0.587146]\n",
      "epoch:7 step:6773 [D loss: 0.646235, acc.: 58.59%] [G loss: 0.435411]\n",
      "epoch:7 step:6774 [D loss: 0.564870, acc.: 70.31%] [G loss: 0.579497]\n",
      "epoch:7 step:6775 [D loss: 0.524929, acc.: 74.22%] [G loss: 0.621055]\n",
      "epoch:7 step:6776 [D loss: 0.575587, acc.: 70.31%] [G loss: 0.643565]\n",
      "epoch:7 step:6777 [D loss: 0.505574, acc.: 76.56%] [G loss: 0.634409]\n",
      "epoch:7 step:6778 [D loss: 0.479017, acc.: 81.25%] [G loss: 0.661620]\n",
      "epoch:7 step:6779 [D loss: 0.660693, acc.: 62.50%] [G loss: 0.536049]\n",
      "epoch:7 step:6780 [D loss: 0.529562, acc.: 70.31%] [G loss: 0.670651]\n",
      "epoch:7 step:6781 [D loss: 0.470427, acc.: 78.91%] [G loss: 0.835201]\n",
      "epoch:7 step:6782 [D loss: 0.501234, acc.: 73.44%] [G loss: 0.666173]\n",
      "epoch:7 step:6783 [D loss: 0.610397, acc.: 67.97%] [G loss: 0.500303]\n",
      "epoch:7 step:6784 [D loss: 0.570574, acc.: 69.53%] [G loss: 0.710275]\n",
      "epoch:7 step:6785 [D loss: 0.593317, acc.: 64.06%] [G loss: 0.541358]\n",
      "epoch:7 step:6786 [D loss: 0.588725, acc.: 70.31%] [G loss: 0.442709]\n",
      "epoch:7 step:6787 [D loss: 0.580524, acc.: 71.09%] [G loss: 0.513328]\n",
      "epoch:7 step:6788 [D loss: 0.555446, acc.: 77.34%] [G loss: 0.537918]\n",
      "epoch:7 step:6789 [D loss: 0.502265, acc.: 73.44%] [G loss: 0.696414]\n",
      "epoch:7 step:6790 [D loss: 0.465959, acc.: 82.81%] [G loss: 0.748593]\n",
      "epoch:7 step:6791 [D loss: 0.423500, acc.: 82.03%] [G loss: 0.733791]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:7 step:6792 [D loss: 0.644138, acc.: 69.53%] [G loss: 0.640122]\n",
      "epoch:7 step:6793 [D loss: 0.551029, acc.: 70.31%] [G loss: 0.671711]\n",
      "epoch:7 step:6794 [D loss: 0.556623, acc.: 67.19%] [G loss: 0.754220]\n",
      "epoch:7 step:6795 [D loss: 0.518859, acc.: 75.78%] [G loss: 0.632643]\n",
      "epoch:7 step:6796 [D loss: 0.572558, acc.: 67.19%] [G loss: 0.554158]\n",
      "epoch:7 step:6797 [D loss: 0.510561, acc.: 75.00%] [G loss: 0.599809]\n",
      "epoch:7 step:6798 [D loss: 0.572191, acc.: 67.19%] [G loss: 0.525241]\n",
      "epoch:7 step:6799 [D loss: 0.526543, acc.: 71.09%] [G loss: 0.575191]\n",
      "epoch:7 step:6800 [D loss: 0.539453, acc.: 67.97%] [G loss: 0.510221]\n",
      "epoch:7 step:6801 [D loss: 0.512370, acc.: 77.34%] [G loss: 0.599604]\n",
      "epoch:7 step:6802 [D loss: 0.517319, acc.: 76.56%] [G loss: 0.637989]\n",
      "epoch:7 step:6803 [D loss: 0.491978, acc.: 75.78%] [G loss: 0.599459]\n",
      "epoch:7 step:6804 [D loss: 0.509237, acc.: 73.44%] [G loss: 0.624408]\n",
      "epoch:7 step:6805 [D loss: 0.521882, acc.: 75.00%] [G loss: 0.640529]\n",
      "epoch:7 step:6806 [D loss: 0.548462, acc.: 67.19%] [G loss: 0.672696]\n",
      "epoch:7 step:6807 [D loss: 0.518278, acc.: 76.56%] [G loss: 0.628721]\n",
      "epoch:7 step:6808 [D loss: 0.534673, acc.: 74.22%] [G loss: 0.537617]\n",
      "epoch:7 step:6809 [D loss: 0.600600, acc.: 63.28%] [G loss: 0.542631]\n",
      "epoch:7 step:6810 [D loss: 0.631176, acc.: 66.41%] [G loss: 0.461916]\n",
      "epoch:7 step:6811 [D loss: 0.559004, acc.: 68.75%] [G loss: 0.491892]\n",
      "epoch:7 step:6812 [D loss: 0.536463, acc.: 71.88%] [G loss: 0.491058]\n",
      "epoch:7 step:6813 [D loss: 0.476691, acc.: 78.91%] [G loss: 0.562029]\n",
      "epoch:7 step:6814 [D loss: 0.594180, acc.: 68.75%] [G loss: 0.628951]\n",
      "epoch:7 step:6815 [D loss: 0.537932, acc.: 71.09%] [G loss: 0.655856]\n",
      "epoch:7 step:6816 [D loss: 0.586626, acc.: 65.62%] [G loss: 0.504309]\n",
      "epoch:7 step:6817 [D loss: 0.492518, acc.: 79.69%] [G loss: 0.529090]\n",
      "epoch:7 step:6818 [D loss: 0.501093, acc.: 73.44%] [G loss: 0.670251]\n",
      "epoch:7 step:6819 [D loss: 0.515592, acc.: 75.00%] [G loss: 0.664722]\n",
      "epoch:7 step:6820 [D loss: 0.497692, acc.: 77.34%] [G loss: 0.661602]\n",
      "epoch:7 step:6821 [D loss: 0.513607, acc.: 75.78%] [G loss: 0.648347]\n",
      "epoch:7 step:6822 [D loss: 0.640130, acc.: 63.28%] [G loss: 0.501626]\n",
      "epoch:7 step:6823 [D loss: 0.490517, acc.: 75.78%] [G loss: 0.674926]\n",
      "epoch:7 step:6824 [D loss: 0.571142, acc.: 69.53%] [G loss: 0.558579]\n",
      "epoch:7 step:6825 [D loss: 0.520955, acc.: 71.88%] [G loss: 0.539166]\n",
      "epoch:7 step:6826 [D loss: 0.574154, acc.: 66.41%] [G loss: 0.528358]\n",
      "epoch:7 step:6827 [D loss: 0.575798, acc.: 71.88%] [G loss: 0.495178]\n",
      "epoch:7 step:6828 [D loss: 0.547718, acc.: 67.19%] [G loss: 0.441786]\n",
      "epoch:7 step:6829 [D loss: 0.527461, acc.: 74.22%] [G loss: 0.549650]\n",
      "epoch:7 step:6830 [D loss: 0.479969, acc.: 82.81%] [G loss: 0.716596]\n",
      "epoch:7 step:6831 [D loss: 0.530122, acc.: 76.56%] [G loss: 0.576249]\n",
      "epoch:7 step:6832 [D loss: 0.503914, acc.: 72.66%] [G loss: 0.578852]\n",
      "epoch:7 step:6833 [D loss: 0.574510, acc.: 66.41%] [G loss: 0.531271]\n",
      "epoch:7 step:6834 [D loss: 0.584769, acc.: 67.19%] [G loss: 0.469131]\n",
      "epoch:7 step:6835 [D loss: 0.513447, acc.: 78.12%] [G loss: 0.547766]\n",
      "epoch:7 step:6836 [D loss: 0.572860, acc.: 71.88%] [G loss: 0.493006]\n",
      "epoch:7 step:6837 [D loss: 0.554160, acc.: 72.66%] [G loss: 0.499359]\n",
      "epoch:7 step:6838 [D loss: 0.572300, acc.: 64.84%] [G loss: 0.470206]\n",
      "epoch:7 step:6839 [D loss: 0.517908, acc.: 76.56%] [G loss: 0.549223]\n",
      "epoch:7 step:6840 [D loss: 0.535208, acc.: 71.88%] [G loss: 0.405368]\n",
      "epoch:7 step:6841 [D loss: 0.550602, acc.: 72.66%] [G loss: 0.538450]\n",
      "epoch:7 step:6842 [D loss: 0.473831, acc.: 79.69%] [G loss: 0.634680]\n",
      "epoch:7 step:6843 [D loss: 0.499186, acc.: 78.91%] [G loss: 0.603259]\n",
      "epoch:7 step:6844 [D loss: 0.536458, acc.: 69.53%] [G loss: 0.568877]\n",
      "epoch:7 step:6845 [D loss: 0.474054, acc.: 77.34%] [G loss: 0.813766]\n",
      "epoch:7 step:6846 [D loss: 0.595438, acc.: 67.19%] [G loss: 0.625782]\n",
      "epoch:7 step:6847 [D loss: 0.577167, acc.: 65.62%] [G loss: 0.612246]\n",
      "epoch:7 step:6848 [D loss: 0.558527, acc.: 66.41%] [G loss: 0.592056]\n",
      "epoch:7 step:6849 [D loss: 0.530733, acc.: 67.19%] [G loss: 0.490589]\n",
      "epoch:7 step:6850 [D loss: 0.520902, acc.: 74.22%] [G loss: 0.506048]\n",
      "epoch:7 step:6851 [D loss: 0.544748, acc.: 69.53%] [G loss: 0.532636]\n",
      "epoch:7 step:6852 [D loss: 0.524028, acc.: 71.88%] [G loss: 0.480448]\n",
      "epoch:7 step:6853 [D loss: 0.534436, acc.: 70.31%] [G loss: 0.536727]\n",
      "epoch:7 step:6854 [D loss: 0.579937, acc.: 66.41%] [G loss: 0.513030]\n",
      "epoch:7 step:6855 [D loss: 0.478863, acc.: 82.03%] [G loss: 0.625127]\n",
      "epoch:7 step:6856 [D loss: 0.565851, acc.: 68.75%] [G loss: 0.530992]\n",
      "epoch:7 step:6857 [D loss: 0.538874, acc.: 74.22%] [G loss: 0.610781]\n",
      "epoch:7 step:6858 [D loss: 0.458082, acc.: 78.91%] [G loss: 0.606224]\n",
      "epoch:7 step:6859 [D loss: 0.521078, acc.: 75.78%] [G loss: 0.647611]\n",
      "epoch:7 step:6860 [D loss: 0.604768, acc.: 67.19%] [G loss: 0.559189]\n",
      "epoch:7 step:6861 [D loss: 0.490793, acc.: 73.44%] [G loss: 0.589000]\n",
      "epoch:7 step:6862 [D loss: 0.510020, acc.: 75.78%] [G loss: 0.657200]\n",
      "epoch:7 step:6863 [D loss: 0.509386, acc.: 73.44%] [G loss: 0.670057]\n",
      "epoch:7 step:6864 [D loss: 0.521599, acc.: 75.00%] [G loss: 0.521238]\n",
      "epoch:7 step:6865 [D loss: 0.552058, acc.: 71.09%] [G loss: 0.704820]\n",
      "epoch:7 step:6866 [D loss: 0.516741, acc.: 73.44%] [G loss: 0.577474]\n",
      "epoch:7 step:6867 [D loss: 0.560086, acc.: 67.19%] [G loss: 0.509238]\n",
      "epoch:7 step:6868 [D loss: 0.430110, acc.: 77.34%] [G loss: 0.828859]\n",
      "epoch:7 step:6869 [D loss: 0.594713, acc.: 64.06%] [G loss: 0.628503]\n",
      "epoch:7 step:6870 [D loss: 0.466762, acc.: 79.69%] [G loss: 0.632499]\n",
      "epoch:7 step:6871 [D loss: 0.391465, acc.: 87.50%] [G loss: 0.775330]\n",
      "epoch:7 step:6872 [D loss: 0.493828, acc.: 75.78%] [G loss: 0.819850]\n",
      "epoch:7 step:6873 [D loss: 0.423287, acc.: 81.25%] [G loss: 0.808129]\n",
      "epoch:7 step:6874 [D loss: 0.441490, acc.: 78.12%] [G loss: 0.862927]\n",
      "epoch:7 step:6875 [D loss: 0.716891, acc.: 60.94%] [G loss: 0.684655]\n",
      "epoch:7 step:6876 [D loss: 0.598913, acc.: 62.50%] [G loss: 0.537473]\n",
      "epoch:7 step:6877 [D loss: 0.548162, acc.: 70.31%] [G loss: 0.615211]\n",
      "epoch:7 step:6878 [D loss: 0.578187, acc.: 73.44%] [G loss: 0.586983]\n",
      "epoch:7 step:6879 [D loss: 0.550082, acc.: 71.09%] [G loss: 0.553671]\n",
      "epoch:7 step:6880 [D loss: 0.462613, acc.: 78.91%] [G loss: 0.641023]\n",
      "epoch:7 step:6881 [D loss: 0.547674, acc.: 72.66%] [G loss: 0.700092]\n",
      "epoch:7 step:6882 [D loss: 0.574943, acc.: 68.75%] [G loss: 0.619062]\n",
      "epoch:7 step:6883 [D loss: 0.539160, acc.: 71.88%] [G loss: 0.594159]\n",
      "epoch:7 step:6884 [D loss: 0.550027, acc.: 67.97%] [G loss: 0.445732]\n",
      "epoch:7 step:6885 [D loss: 0.524246, acc.: 70.31%] [G loss: 0.535189]\n",
      "epoch:7 step:6886 [D loss: 0.517518, acc.: 75.78%] [G loss: 0.592684]\n",
      "epoch:7 step:6887 [D loss: 0.509706, acc.: 72.66%] [G loss: 0.669713]\n",
      "epoch:7 step:6888 [D loss: 0.511306, acc.: 75.00%] [G loss: 0.778818]\n",
      "epoch:7 step:6889 [D loss: 0.528751, acc.: 71.88%] [G loss: 0.540432]\n",
      "epoch:7 step:6890 [D loss: 0.534413, acc.: 75.78%] [G loss: 0.555558]\n",
      "epoch:7 step:6891 [D loss: 0.470973, acc.: 75.78%] [G loss: 0.693618]\n",
      "epoch:7 step:6892 [D loss: 0.441643, acc.: 79.69%] [G loss: 0.680543]\n",
      "epoch:7 step:6893 [D loss: 0.501601, acc.: 71.88%] [G loss: 0.692580]\n",
      "epoch:7 step:6894 [D loss: 0.472635, acc.: 75.00%] [G loss: 0.937942]\n",
      "epoch:7 step:6895 [D loss: 0.520235, acc.: 73.44%] [G loss: 0.791866]\n",
      "epoch:7 step:6896 [D loss: 0.498378, acc.: 76.56%] [G loss: 0.684172]\n",
      "epoch:7 step:6897 [D loss: 0.535751, acc.: 68.75%] [G loss: 0.634058]\n",
      "epoch:7 step:6898 [D loss: 0.485555, acc.: 77.34%] [G loss: 0.639243]\n",
      "epoch:7 step:6899 [D loss: 0.455782, acc.: 75.78%] [G loss: 0.765688]\n",
      "epoch:7 step:6900 [D loss: 0.625127, acc.: 64.84%] [G loss: 0.495706]\n",
      "epoch:7 step:6901 [D loss: 0.622877, acc.: 64.84%] [G loss: 0.514180]\n",
      "epoch:7 step:6902 [D loss: 0.482262, acc.: 78.91%] [G loss: 0.738090]\n",
      "epoch:7 step:6903 [D loss: 0.489066, acc.: 75.00%] [G loss: 0.820333]\n",
      "epoch:7 step:6904 [D loss: 0.513737, acc.: 75.00%] [G loss: 0.811342]\n",
      "epoch:7 step:6905 [D loss: 0.514279, acc.: 77.34%] [G loss: 0.842356]\n",
      "epoch:7 step:6906 [D loss: 0.421686, acc.: 83.59%] [G loss: 0.893108]\n",
      "epoch:7 step:6907 [D loss: 0.706376, acc.: 63.28%] [G loss: 0.630958]\n",
      "epoch:7 step:6908 [D loss: 0.725561, acc.: 51.56%] [G loss: 0.385261]\n",
      "epoch:7 step:6909 [D loss: 0.482733, acc.: 77.34%] [G loss: 0.615605]\n",
      "epoch:7 step:6910 [D loss: 0.525352, acc.: 73.44%] [G loss: 0.637838]\n",
      "epoch:7 step:6911 [D loss: 0.582415, acc.: 66.41%] [G loss: 0.638657]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:7 step:6912 [D loss: 0.566566, acc.: 69.53%] [G loss: 0.785808]\n",
      "epoch:7 step:6913 [D loss: 0.416947, acc.: 82.03%] [G loss: 0.827750]\n",
      "epoch:7 step:6914 [D loss: 0.513361, acc.: 75.78%] [G loss: 0.597949]\n",
      "epoch:7 step:6915 [D loss: 0.573037, acc.: 66.41%] [G loss: 0.508647]\n",
      "epoch:7 step:6916 [D loss: 0.432913, acc.: 78.91%] [G loss: 0.549286]\n",
      "epoch:7 step:6917 [D loss: 0.451708, acc.: 75.78%] [G loss: 0.650475]\n",
      "epoch:7 step:6918 [D loss: 0.508925, acc.: 74.22%] [G loss: 0.704959]\n",
      "epoch:7 step:6919 [D loss: 0.497099, acc.: 73.44%] [G loss: 0.696178]\n",
      "epoch:7 step:6920 [D loss: 0.471745, acc.: 78.91%] [G loss: 0.839365]\n",
      "epoch:7 step:6921 [D loss: 0.596601, acc.: 67.19%] [G loss: 0.721701]\n",
      "epoch:7 step:6922 [D loss: 0.488508, acc.: 75.78%] [G loss: 0.653541]\n",
      "epoch:7 step:6923 [D loss: 0.476024, acc.: 75.78%] [G loss: 0.616528]\n",
      "epoch:7 step:6924 [D loss: 0.575883, acc.: 69.53%] [G loss: 0.700357]\n",
      "epoch:7 step:6925 [D loss: 0.469335, acc.: 75.78%] [G loss: 0.707289]\n",
      "epoch:7 step:6926 [D loss: 0.583892, acc.: 67.19%] [G loss: 0.753269]\n",
      "epoch:7 step:6927 [D loss: 0.569148, acc.: 71.09%] [G loss: 0.636302]\n",
      "epoch:7 step:6928 [D loss: 0.564531, acc.: 69.53%] [G loss: 0.754563]\n",
      "epoch:7 step:6929 [D loss: 0.525591, acc.: 75.78%] [G loss: 0.747102]\n",
      "epoch:7 step:6930 [D loss: 0.494341, acc.: 76.56%] [G loss: 0.606274]\n",
      "epoch:7 step:6931 [D loss: 0.560043, acc.: 76.56%] [G loss: 0.686234]\n",
      "epoch:7 step:6932 [D loss: 0.569435, acc.: 67.97%] [G loss: 0.654613]\n",
      "epoch:7 step:6933 [D loss: 0.483357, acc.: 75.78%] [G loss: 0.644298]\n",
      "epoch:7 step:6934 [D loss: 0.576642, acc.: 68.75%] [G loss: 0.628740]\n",
      "epoch:7 step:6935 [D loss: 0.715178, acc.: 59.38%] [G loss: 0.473088]\n",
      "epoch:7 step:6936 [D loss: 0.589130, acc.: 64.06%] [G loss: 0.517683]\n",
      "epoch:7 step:6937 [D loss: 0.504868, acc.: 71.09%] [G loss: 0.650828]\n",
      "epoch:7 step:6938 [D loss: 0.566482, acc.: 68.75%] [G loss: 0.589610]\n",
      "epoch:7 step:6939 [D loss: 0.624223, acc.: 64.84%] [G loss: 0.437706]\n",
      "epoch:7 step:6940 [D loss: 0.479561, acc.: 76.56%] [G loss: 0.565923]\n",
      "epoch:7 step:6941 [D loss: 0.526876, acc.: 73.44%] [G loss: 0.469126]\n",
      "epoch:7 step:6942 [D loss: 0.578229, acc.: 67.19%] [G loss: 0.561473]\n",
      "epoch:7 step:6943 [D loss: 0.543829, acc.: 71.09%] [G loss: 0.660491]\n",
      "epoch:7 step:6944 [D loss: 0.503362, acc.: 71.88%] [G loss: 0.672859]\n",
      "epoch:7 step:6945 [D loss: 0.558359, acc.: 72.66%] [G loss: 0.610718]\n",
      "epoch:7 step:6946 [D loss: 0.585827, acc.: 67.97%] [G loss: 0.609539]\n",
      "epoch:7 step:6947 [D loss: 0.544378, acc.: 75.00%] [G loss: 0.619841]\n",
      "epoch:7 step:6948 [D loss: 0.523505, acc.: 72.66%] [G loss: 0.658617]\n",
      "epoch:7 step:6949 [D loss: 0.556732, acc.: 73.44%] [G loss: 0.481030]\n",
      "epoch:7 step:6950 [D loss: 0.550245, acc.: 70.31%] [G loss: 0.620570]\n",
      "epoch:7 step:6951 [D loss: 0.462953, acc.: 78.91%] [G loss: 0.574610]\n",
      "epoch:7 step:6952 [D loss: 0.558495, acc.: 70.31%] [G loss: 0.634450]\n",
      "epoch:7 step:6953 [D loss: 0.564668, acc.: 68.75%] [G loss: 0.572694]\n",
      "epoch:7 step:6954 [D loss: 0.495912, acc.: 75.00%] [G loss: 0.508041]\n",
      "epoch:7 step:6955 [D loss: 0.619866, acc.: 64.06%] [G loss: 0.576316]\n",
      "epoch:7 step:6956 [D loss: 0.541584, acc.: 68.75%] [G loss: 0.701396]\n",
      "epoch:7 step:6957 [D loss: 0.513606, acc.: 72.66%] [G loss: 0.565254]\n",
      "epoch:7 step:6958 [D loss: 0.443631, acc.: 85.94%] [G loss: 0.676194]\n",
      "epoch:7 step:6959 [D loss: 0.718922, acc.: 60.94%] [G loss: 0.560361]\n",
      "epoch:7 step:6960 [D loss: 0.590381, acc.: 64.84%] [G loss: 0.500265]\n",
      "epoch:7 step:6961 [D loss: 0.466131, acc.: 82.03%] [G loss: 0.576217]\n",
      "epoch:7 step:6962 [D loss: 0.467179, acc.: 75.78%] [G loss: 0.692932]\n",
      "epoch:7 step:6963 [D loss: 0.566746, acc.: 67.97%] [G loss: 0.582327]\n",
      "epoch:7 step:6964 [D loss: 0.572049, acc.: 67.19%] [G loss: 0.556800]\n",
      "epoch:7 step:6965 [D loss: 0.512424, acc.: 73.44%] [G loss: 0.638142]\n",
      "epoch:7 step:6966 [D loss: 0.604636, acc.: 62.50%] [G loss: 0.677166]\n",
      "epoch:7 step:6967 [D loss: 0.546783, acc.: 67.97%] [G loss: 0.595996]\n",
      "epoch:7 step:6968 [D loss: 0.574739, acc.: 63.28%] [G loss: 0.507653]\n",
      "epoch:7 step:6969 [D loss: 0.601497, acc.: 70.31%] [G loss: 0.461159]\n",
      "epoch:7 step:6970 [D loss: 0.528893, acc.: 68.75%] [G loss: 0.758316]\n",
      "epoch:7 step:6971 [D loss: 0.636639, acc.: 62.50%] [G loss: 0.442725]\n",
      "epoch:7 step:6972 [D loss: 0.508768, acc.: 77.34%] [G loss: 0.683084]\n",
      "epoch:7 step:6973 [D loss: 0.580048, acc.: 69.53%] [G loss: 0.633417]\n",
      "epoch:7 step:6974 [D loss: 0.549742, acc.: 69.53%] [G loss: 0.631263]\n",
      "epoch:7 step:6975 [D loss: 0.487141, acc.: 78.12%] [G loss: 0.648778]\n",
      "epoch:7 step:6976 [D loss: 0.587727, acc.: 71.09%] [G loss: 0.700698]\n",
      "epoch:7 step:6977 [D loss: 0.642716, acc.: 62.50%] [G loss: 0.447061]\n",
      "epoch:7 step:6978 [D loss: 0.547918, acc.: 69.53%] [G loss: 0.495959]\n",
      "epoch:7 step:6979 [D loss: 0.593346, acc.: 65.62%] [G loss: 0.539057]\n",
      "epoch:7 step:6980 [D loss: 0.572821, acc.: 69.53%] [G loss: 0.587246]\n",
      "epoch:7 step:6981 [D loss: 0.608503, acc.: 67.19%] [G loss: 0.574301]\n",
      "epoch:7 step:6982 [D loss: 0.578415, acc.: 68.75%] [G loss: 0.567907]\n",
      "epoch:7 step:6983 [D loss: 0.584985, acc.: 67.97%] [G loss: 0.599497]\n",
      "epoch:7 step:6984 [D loss: 0.543177, acc.: 74.22%] [G loss: 0.525292]\n",
      "epoch:7 step:6985 [D loss: 0.458991, acc.: 79.69%] [G loss: 0.634058]\n",
      "epoch:7 step:6986 [D loss: 0.457723, acc.: 82.03%] [G loss: 0.880313]\n",
      "epoch:7 step:6987 [D loss: 0.536623, acc.: 75.78%] [G loss: 0.673508]\n",
      "epoch:7 step:6988 [D loss: 0.449473, acc.: 81.25%] [G loss: 0.766030]\n",
      "epoch:7 step:6989 [D loss: 0.474783, acc.: 76.56%] [G loss: 0.730090]\n",
      "epoch:7 step:6990 [D loss: 0.550944, acc.: 70.31%] [G loss: 0.695284]\n",
      "epoch:7 step:6991 [D loss: 0.580656, acc.: 64.06%] [G loss: 0.622877]\n",
      "epoch:7 step:6992 [D loss: 0.607718, acc.: 64.84%] [G loss: 0.508690]\n",
      "epoch:7 step:6993 [D loss: 0.563876, acc.: 68.75%] [G loss: 0.645796]\n",
      "epoch:7 step:6994 [D loss: 0.550740, acc.: 73.44%] [G loss: 0.576315]\n",
      "epoch:7 step:6995 [D loss: 0.515601, acc.: 70.31%] [G loss: 0.753731]\n",
      "epoch:7 step:6996 [D loss: 0.712076, acc.: 65.62%] [G loss: 0.584959]\n",
      "epoch:7 step:6997 [D loss: 0.537943, acc.: 69.53%] [G loss: 0.625260]\n",
      "epoch:7 step:6998 [D loss: 0.477360, acc.: 78.91%] [G loss: 0.775174]\n",
      "epoch:7 step:6999 [D loss: 0.498847, acc.: 74.22%] [G loss: 0.637304]\n",
      "epoch:7 step:7000 [D loss: 0.527719, acc.: 70.31%] [G loss: 0.662252]\n",
      "epoch:7 step:7001 [D loss: 0.578333, acc.: 68.75%] [G loss: 0.599923]\n",
      "epoch:7 step:7002 [D loss: 0.499738, acc.: 78.12%] [G loss: 0.614672]\n",
      "epoch:7 step:7003 [D loss: 0.538293, acc.: 71.88%] [G loss: 0.682048]\n",
      "epoch:7 step:7004 [D loss: 0.505771, acc.: 74.22%] [G loss: 0.620914]\n",
      "epoch:7 step:7005 [D loss: 0.542811, acc.: 71.88%] [G loss: 0.527678]\n",
      "epoch:7 step:7006 [D loss: 0.550332, acc.: 71.09%] [G loss: 0.625834]\n",
      "epoch:7 step:7007 [D loss: 0.512439, acc.: 75.00%] [G loss: 0.570524]\n",
      "epoch:7 step:7008 [D loss: 0.477472, acc.: 77.34%] [G loss: 0.675870]\n",
      "epoch:7 step:7009 [D loss: 0.491853, acc.: 80.47%] [G loss: 0.644130]\n",
      "epoch:7 step:7010 [D loss: 0.440743, acc.: 81.25%] [G loss: 0.716795]\n",
      "epoch:7 step:7011 [D loss: 0.489100, acc.: 78.91%] [G loss: 0.764088]\n",
      "epoch:7 step:7012 [D loss: 0.538633, acc.: 73.44%] [G loss: 0.703677]\n",
      "epoch:7 step:7013 [D loss: 0.574796, acc.: 69.53%] [G loss: 0.608074]\n",
      "epoch:7 step:7014 [D loss: 0.568456, acc.: 67.97%] [G loss: 0.597860]\n",
      "epoch:7 step:7015 [D loss: 0.621920, acc.: 64.06%] [G loss: 0.565083]\n",
      "epoch:7 step:7016 [D loss: 0.549370, acc.: 73.44%] [G loss: 0.639911]\n",
      "epoch:7 step:7017 [D loss: 0.593756, acc.: 68.75%] [G loss: 0.487579]\n",
      "epoch:7 step:7018 [D loss: 0.578017, acc.: 67.19%] [G loss: 0.607442]\n",
      "epoch:7 step:7019 [D loss: 0.461442, acc.: 80.47%] [G loss: 0.631135]\n",
      "epoch:7 step:7020 [D loss: 0.483832, acc.: 75.00%] [G loss: 0.637983]\n",
      "epoch:7 step:7021 [D loss: 0.568900, acc.: 70.31%] [G loss: 0.598813]\n",
      "epoch:7 step:7022 [D loss: 0.562362, acc.: 65.62%] [G loss: 0.549457]\n",
      "epoch:7 step:7023 [D loss: 0.570275, acc.: 69.53%] [G loss: 0.590777]\n",
      "epoch:7 step:7024 [D loss: 0.638023, acc.: 59.38%] [G loss: 0.475491]\n",
      "epoch:7 step:7025 [D loss: 0.521369, acc.: 71.09%] [G loss: 0.649914]\n",
      "epoch:7 step:7026 [D loss: 0.591801, acc.: 69.53%] [G loss: 0.724244]\n",
      "epoch:7 step:7027 [D loss: 0.529955, acc.: 75.00%] [G loss: 0.644709]\n",
      "epoch:7 step:7028 [D loss: 0.595069, acc.: 66.41%] [G loss: 0.581878]\n",
      "epoch:7 step:7029 [D loss: 0.527122, acc.: 74.22%] [G loss: 0.757798]\n",
      "epoch:7 step:7030 [D loss: 0.419533, acc.: 83.59%] [G loss: 0.697114]\n",
      "epoch:7 step:7031 [D loss: 0.487171, acc.: 76.56%] [G loss: 0.821029]\n",
      "epoch:7 step:7032 [D loss: 0.589170, acc.: 70.31%] [G loss: 0.653461]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:7 step:7033 [D loss: 0.530470, acc.: 71.88%] [G loss: 0.639715]\n",
      "epoch:7 step:7034 [D loss: 0.511766, acc.: 71.88%] [G loss: 0.721194]\n",
      "epoch:7 step:7035 [D loss: 0.585966, acc.: 69.53%] [G loss: 0.583891]\n",
      "epoch:7 step:7036 [D loss: 0.623418, acc.: 67.97%] [G loss: 0.494991]\n",
      "epoch:7 step:7037 [D loss: 0.564194, acc.: 67.97%] [G loss: 0.537069]\n",
      "epoch:7 step:7038 [D loss: 0.568335, acc.: 72.66%] [G loss: 0.555514]\n",
      "epoch:7 step:7039 [D loss: 0.526699, acc.: 75.00%] [G loss: 0.561117]\n",
      "epoch:7 step:7040 [D loss: 0.546974, acc.: 72.66%] [G loss: 0.545867]\n",
      "epoch:7 step:7041 [D loss: 0.622951, acc.: 59.38%] [G loss: 0.431829]\n",
      "epoch:7 step:7042 [D loss: 0.557931, acc.: 64.84%] [G loss: 0.525120]\n",
      "epoch:7 step:7043 [D loss: 0.504865, acc.: 79.69%] [G loss: 0.626523]\n",
      "epoch:7 step:7044 [D loss: 0.520235, acc.: 76.56%] [G loss: 0.646152]\n",
      "epoch:7 step:7045 [D loss: 0.561284, acc.: 71.09%] [G loss: 0.462135]\n",
      "epoch:7 step:7046 [D loss: 0.513401, acc.: 71.09%] [G loss: 0.587130]\n",
      "epoch:7 step:7047 [D loss: 0.553940, acc.: 69.53%] [G loss: 0.548488]\n",
      "epoch:7 step:7048 [D loss: 0.603880, acc.: 64.06%] [G loss: 0.587931]\n",
      "epoch:7 step:7049 [D loss: 0.552899, acc.: 68.75%] [G loss: 0.614442]\n",
      "epoch:7 step:7050 [D loss: 0.516583, acc.: 78.91%] [G loss: 0.556053]\n",
      "epoch:7 step:7051 [D loss: 0.585262, acc.: 66.41%] [G loss: 0.599491]\n",
      "epoch:7 step:7052 [D loss: 0.548447, acc.: 68.75%] [G loss: 0.552215]\n",
      "epoch:7 step:7053 [D loss: 0.540434, acc.: 72.66%] [G loss: 0.575047]\n",
      "epoch:7 step:7054 [D loss: 0.544167, acc.: 70.31%] [G loss: 0.586340]\n",
      "epoch:7 step:7055 [D loss: 0.607304, acc.: 67.19%] [G loss: 0.497229]\n",
      "epoch:7 step:7056 [D loss: 0.523415, acc.: 74.22%] [G loss: 0.640360]\n",
      "epoch:7 step:7057 [D loss: 0.535616, acc.: 67.97%] [G loss: 0.637409]\n",
      "epoch:7 step:7058 [D loss: 0.458014, acc.: 78.91%] [G loss: 0.741147]\n",
      "epoch:7 step:7059 [D loss: 0.630859, acc.: 63.28%] [G loss: 0.505228]\n",
      "epoch:7 step:7060 [D loss: 0.627073, acc.: 67.97%] [G loss: 0.446497]\n",
      "epoch:7 step:7061 [D loss: 0.606615, acc.: 64.84%] [G loss: 0.477701]\n",
      "epoch:7 step:7062 [D loss: 0.524633, acc.: 67.97%] [G loss: 0.457777]\n",
      "epoch:7 step:7063 [D loss: 0.477286, acc.: 75.78%] [G loss: 0.634663]\n",
      "epoch:7 step:7064 [D loss: 0.513176, acc.: 75.00%] [G loss: 0.733923]\n",
      "epoch:7 step:7065 [D loss: 0.535635, acc.: 70.31%] [G loss: 0.591890]\n",
      "epoch:7 step:7066 [D loss: 0.510358, acc.: 70.31%] [G loss: 0.700460]\n",
      "epoch:7 step:7067 [D loss: 0.462199, acc.: 78.91%] [G loss: 0.816601]\n",
      "epoch:7 step:7068 [D loss: 0.543560, acc.: 72.66%] [G loss: 0.615152]\n",
      "epoch:7 step:7069 [D loss: 0.573547, acc.: 69.53%] [G loss: 0.553072]\n",
      "epoch:7 step:7070 [D loss: 0.587129, acc.: 67.97%] [G loss: 0.447530]\n",
      "epoch:7 step:7071 [D loss: 0.553186, acc.: 66.41%] [G loss: 0.484771]\n",
      "epoch:7 step:7072 [D loss: 0.502193, acc.: 77.34%] [G loss: 0.542912]\n",
      "epoch:7 step:7073 [D loss: 0.470111, acc.: 78.12%] [G loss: 0.651882]\n",
      "epoch:7 step:7074 [D loss: 0.505320, acc.: 76.56%] [G loss: 0.547834]\n",
      "epoch:7 step:7075 [D loss: 0.473502, acc.: 81.25%] [G loss: 0.587443]\n",
      "epoch:7 step:7076 [D loss: 0.502542, acc.: 78.91%] [G loss: 0.724305]\n",
      "epoch:7 step:7077 [D loss: 0.509346, acc.: 73.44%] [G loss: 0.736083]\n",
      "epoch:7 step:7078 [D loss: 0.463399, acc.: 79.69%] [G loss: 0.631528]\n",
      "epoch:7 step:7079 [D loss: 0.480343, acc.: 76.56%] [G loss: 0.718883]\n",
      "epoch:7 step:7080 [D loss: 0.533053, acc.: 73.44%] [G loss: 0.603352]\n",
      "epoch:7 step:7081 [D loss: 0.513461, acc.: 73.44%] [G loss: 0.628607]\n",
      "epoch:7 step:7082 [D loss: 0.520414, acc.: 76.56%] [G loss: 0.718366]\n",
      "epoch:7 step:7083 [D loss: 0.493930, acc.: 76.56%] [G loss: 0.698726]\n",
      "epoch:7 step:7084 [D loss: 0.575935, acc.: 69.53%] [G loss: 0.608297]\n",
      "epoch:7 step:7085 [D loss: 0.521198, acc.: 75.00%] [G loss: 0.628428]\n",
      "epoch:7 step:7086 [D loss: 0.556911, acc.: 70.31%] [G loss: 0.614455]\n",
      "epoch:7 step:7087 [D loss: 0.690859, acc.: 60.16%] [G loss: 0.746420]\n",
      "epoch:7 step:7088 [D loss: 0.581609, acc.: 68.75%] [G loss: 0.583479]\n",
      "epoch:7 step:7089 [D loss: 0.553075, acc.: 69.53%] [G loss: 0.694930]\n",
      "epoch:7 step:7090 [D loss: 0.556207, acc.: 67.97%] [G loss: 0.567191]\n",
      "epoch:7 step:7091 [D loss: 0.564532, acc.: 70.31%] [G loss: 0.603514]\n",
      "epoch:7 step:7092 [D loss: 0.592689, acc.: 65.62%] [G loss: 0.463089]\n",
      "epoch:7 step:7093 [D loss: 0.526814, acc.: 72.66%] [G loss: 0.584304]\n",
      "epoch:7 step:7094 [D loss: 0.618994, acc.: 61.72%] [G loss: 0.541964]\n",
      "epoch:7 step:7095 [D loss: 0.499629, acc.: 73.44%] [G loss: 0.531360]\n",
      "epoch:7 step:7096 [D loss: 0.576950, acc.: 67.19%] [G loss: 0.504848]\n",
      "epoch:7 step:7097 [D loss: 0.579795, acc.: 63.28%] [G loss: 0.495844]\n",
      "epoch:7 step:7098 [D loss: 0.596676, acc.: 65.62%] [G loss: 0.551452]\n",
      "epoch:7 step:7099 [D loss: 0.577893, acc.: 68.75%] [G loss: 0.637065]\n",
      "epoch:7 step:7100 [D loss: 0.575834, acc.: 73.44%] [G loss: 0.512799]\n",
      "epoch:7 step:7101 [D loss: 0.619714, acc.: 65.62%] [G loss: 0.417665]\n",
      "epoch:7 step:7102 [D loss: 0.584813, acc.: 66.41%] [G loss: 0.652650]\n",
      "epoch:7 step:7103 [D loss: 0.482441, acc.: 75.78%] [G loss: 0.538177]\n",
      "epoch:7 step:7104 [D loss: 0.553228, acc.: 72.66%] [G loss: 0.547576]\n",
      "epoch:7 step:7105 [D loss: 0.500457, acc.: 76.56%] [G loss: 0.691103]\n",
      "epoch:7 step:7106 [D loss: 0.493053, acc.: 75.00%] [G loss: 0.586730]\n",
      "epoch:7 step:7107 [D loss: 0.479951, acc.: 71.09%] [G loss: 0.700635]\n",
      "epoch:7 step:7108 [D loss: 0.529640, acc.: 73.44%] [G loss: 0.642914]\n",
      "epoch:7 step:7109 [D loss: 0.560433, acc.: 72.66%] [G loss: 0.600389]\n",
      "epoch:7 step:7110 [D loss: 0.508430, acc.: 73.44%] [G loss: 0.629866]\n",
      "epoch:7 step:7111 [D loss: 0.475678, acc.: 76.56%] [G loss: 0.499588]\n",
      "epoch:7 step:7112 [D loss: 0.595682, acc.: 71.09%] [G loss: 0.645044]\n",
      "epoch:7 step:7113 [D loss: 0.487205, acc.: 80.47%] [G loss: 0.610708]\n",
      "epoch:7 step:7114 [D loss: 0.509921, acc.: 78.12%] [G loss: 0.777984]\n",
      "epoch:7 step:7115 [D loss: 0.550216, acc.: 70.31%] [G loss: 0.531941]\n",
      "epoch:7 step:7116 [D loss: 0.490245, acc.: 76.56%] [G loss: 0.631534]\n",
      "epoch:7 step:7117 [D loss: 0.518070, acc.: 74.22%] [G loss: 0.564267]\n",
      "epoch:7 step:7118 [D loss: 0.540024, acc.: 71.09%] [G loss: 0.681180]\n",
      "epoch:7 step:7119 [D loss: 0.593619, acc.: 65.62%] [G loss: 0.670179]\n",
      "epoch:7 step:7120 [D loss: 0.560441, acc.: 71.09%] [G loss: 0.534648]\n",
      "epoch:7 step:7121 [D loss: 0.559926, acc.: 73.44%] [G loss: 0.549231]\n",
      "epoch:7 step:7122 [D loss: 0.532815, acc.: 75.00%] [G loss: 0.556153]\n",
      "epoch:7 step:7123 [D loss: 0.535983, acc.: 72.66%] [G loss: 0.595910]\n",
      "epoch:7 step:7124 [D loss: 0.559830, acc.: 67.19%] [G loss: 0.628461]\n",
      "epoch:7 step:7125 [D loss: 0.615513, acc.: 68.75%] [G loss: 0.546169]\n",
      "epoch:7 step:7126 [D loss: 0.493768, acc.: 75.78%] [G loss: 0.484287]\n",
      "epoch:7 step:7127 [D loss: 0.535149, acc.: 70.31%] [G loss: 0.586057]\n",
      "epoch:7 step:7128 [D loss: 0.553296, acc.: 67.97%] [G loss: 0.453802]\n",
      "epoch:7 step:7129 [D loss: 0.560633, acc.: 75.78%] [G loss: 0.539692]\n",
      "epoch:7 step:7130 [D loss: 0.541255, acc.: 71.09%] [G loss: 0.481705]\n",
      "epoch:7 step:7131 [D loss: 0.535070, acc.: 76.56%] [G loss: 0.597060]\n",
      "epoch:7 step:7132 [D loss: 0.554201, acc.: 70.31%] [G loss: 0.676352]\n",
      "epoch:7 step:7133 [D loss: 0.463885, acc.: 78.12%] [G loss: 0.665255]\n",
      "epoch:7 step:7134 [D loss: 0.460017, acc.: 79.69%] [G loss: 0.753499]\n",
      "epoch:7 step:7135 [D loss: 0.623547, acc.: 69.53%] [G loss: 0.569008]\n",
      "epoch:7 step:7136 [D loss: 0.593594, acc.: 67.97%] [G loss: 0.489361]\n",
      "epoch:7 step:7137 [D loss: 0.588151, acc.: 68.75%] [G loss: 0.533282]\n",
      "epoch:7 step:7138 [D loss: 0.557799, acc.: 71.09%] [G loss: 0.557655]\n",
      "epoch:7 step:7139 [D loss: 0.551393, acc.: 72.66%] [G loss: 0.492589]\n",
      "epoch:7 step:7140 [D loss: 0.482257, acc.: 78.12%] [G loss: 0.719860]\n",
      "epoch:7 step:7141 [D loss: 0.421818, acc.: 81.25%] [G loss: 0.680436]\n",
      "epoch:7 step:7142 [D loss: 0.581383, acc.: 68.75%] [G loss: 0.625275]\n",
      "epoch:7 step:7143 [D loss: 0.631074, acc.: 60.94%] [G loss: 0.598090]\n",
      "epoch:7 step:7144 [D loss: 0.539605, acc.: 71.88%] [G loss: 0.564840]\n",
      "epoch:7 step:7145 [D loss: 0.557692, acc.: 69.53%] [G loss: 0.670795]\n",
      "epoch:7 step:7146 [D loss: 0.623978, acc.: 58.59%] [G loss: 0.488067]\n",
      "epoch:7 step:7147 [D loss: 0.587019, acc.: 64.84%] [G loss: 0.659458]\n",
      "epoch:7 step:7148 [D loss: 0.540552, acc.: 67.19%] [G loss: 0.678056]\n",
      "epoch:7 step:7149 [D loss: 0.541375, acc.: 73.44%] [G loss: 0.713701]\n",
      "epoch:7 step:7150 [D loss: 0.607967, acc.: 67.19%] [G loss: 0.510040]\n",
      "epoch:7 step:7151 [D loss: 0.537030, acc.: 69.53%] [G loss: 0.513763]\n",
      "epoch:7 step:7152 [D loss: 0.538173, acc.: 75.00%] [G loss: 0.690401]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:7 step:7153 [D loss: 0.559636, acc.: 68.75%] [G loss: 0.502176]\n",
      "epoch:7 step:7154 [D loss: 0.536838, acc.: 71.88%] [G loss: 0.591595]\n",
      "epoch:7 step:7155 [D loss: 0.506723, acc.: 72.66%] [G loss: 0.602781]\n",
      "epoch:7 step:7156 [D loss: 0.535918, acc.: 76.56%] [G loss: 0.541029]\n",
      "epoch:7 step:7157 [D loss: 0.504387, acc.: 75.78%] [G loss: 0.628614]\n",
      "epoch:7 step:7158 [D loss: 0.543086, acc.: 68.75%] [G loss: 0.555220]\n",
      "epoch:7 step:7159 [D loss: 0.635974, acc.: 63.28%] [G loss: 0.516698]\n",
      "epoch:7 step:7160 [D loss: 0.605562, acc.: 61.72%] [G loss: 0.489543]\n",
      "epoch:7 step:7161 [D loss: 0.514121, acc.: 75.00%] [G loss: 0.644218]\n",
      "epoch:7 step:7162 [D loss: 0.488268, acc.: 78.12%] [G loss: 0.684650]\n",
      "epoch:7 step:7163 [D loss: 0.573864, acc.: 71.88%] [G loss: 0.702919]\n",
      "epoch:7 step:7164 [D loss: 0.477415, acc.: 75.78%] [G loss: 0.579939]\n",
      "epoch:7 step:7165 [D loss: 0.546559, acc.: 71.88%] [G loss: 0.630715]\n",
      "epoch:7 step:7166 [D loss: 0.502856, acc.: 75.78%] [G loss: 0.604415]\n",
      "epoch:7 step:7167 [D loss: 0.518160, acc.: 71.09%] [G loss: 0.582025]\n",
      "epoch:7 step:7168 [D loss: 0.539795, acc.: 70.31%] [G loss: 0.499041]\n",
      "epoch:7 step:7169 [D loss: 0.553126, acc.: 71.88%] [G loss: 0.520974]\n",
      "epoch:7 step:7170 [D loss: 0.526394, acc.: 72.66%] [G loss: 0.533916]\n",
      "epoch:7 step:7171 [D loss: 0.541786, acc.: 72.66%] [G loss: 0.503658]\n",
      "epoch:7 step:7172 [D loss: 0.516450, acc.: 77.34%] [G loss: 0.519833]\n",
      "epoch:7 step:7173 [D loss: 0.546469, acc.: 69.53%] [G loss: 0.550036]\n",
      "epoch:7 step:7174 [D loss: 0.584226, acc.: 68.75%] [G loss: 0.571885]\n",
      "epoch:7 step:7175 [D loss: 0.655531, acc.: 64.06%] [G loss: 0.678143]\n",
      "epoch:7 step:7176 [D loss: 0.508124, acc.: 76.56%] [G loss: 0.645020]\n",
      "epoch:7 step:7177 [D loss: 0.551065, acc.: 72.66%] [G loss: 0.554306]\n",
      "epoch:7 step:7178 [D loss: 0.564106, acc.: 68.75%] [G loss: 0.667301]\n",
      "epoch:7 step:7179 [D loss: 0.543926, acc.: 71.09%] [G loss: 0.646334]\n",
      "epoch:7 step:7180 [D loss: 0.582230, acc.: 67.19%] [G loss: 0.578298]\n",
      "epoch:7 step:7181 [D loss: 0.648255, acc.: 61.72%] [G loss: 0.473372]\n",
      "epoch:7 step:7182 [D loss: 0.490813, acc.: 71.88%] [G loss: 0.699941]\n",
      "epoch:7 step:7183 [D loss: 0.493134, acc.: 76.56%] [G loss: 0.657287]\n",
      "epoch:7 step:7184 [D loss: 0.613403, acc.: 64.84%] [G loss: 0.482653]\n",
      "epoch:7 step:7185 [D loss: 0.507724, acc.: 76.56%] [G loss: 0.660138]\n",
      "epoch:7 step:7186 [D loss: 0.532457, acc.: 69.53%] [G loss: 0.578803]\n",
      "epoch:7 step:7187 [D loss: 0.576834, acc.: 67.97%] [G loss: 0.548661]\n",
      "epoch:7 step:7188 [D loss: 0.509610, acc.: 75.78%] [G loss: 0.610535]\n",
      "epoch:7 step:7189 [D loss: 0.532353, acc.: 70.31%] [G loss: 0.609192]\n",
      "epoch:7 step:7190 [D loss: 0.468755, acc.: 80.47%] [G loss: 0.572749]\n",
      "epoch:7 step:7191 [D loss: 0.519639, acc.: 73.44%] [G loss: 0.624978]\n",
      "epoch:7 step:7192 [D loss: 0.530674, acc.: 74.22%] [G loss: 0.593593]\n",
      "epoch:7 step:7193 [D loss: 0.468841, acc.: 78.12%] [G loss: 0.565355]\n",
      "epoch:7 step:7194 [D loss: 0.529332, acc.: 68.75%] [G loss: 0.633526]\n",
      "epoch:7 step:7195 [D loss: 0.515382, acc.: 75.00%] [G loss: 0.597843]\n",
      "epoch:7 step:7196 [D loss: 0.585616, acc.: 66.41%] [G loss: 0.468307]\n",
      "epoch:7 step:7197 [D loss: 0.549952, acc.: 71.88%] [G loss: 0.557607]\n",
      "epoch:7 step:7198 [D loss: 0.543187, acc.: 72.66%] [G loss: 0.504428]\n",
      "epoch:7 step:7199 [D loss: 0.507309, acc.: 72.66%] [G loss: 0.678960]\n",
      "epoch:7 step:7200 [D loss: 0.470971, acc.: 77.34%] [G loss: 0.746006]\n",
      "epoch:7 step:7201 [D loss: 0.525025, acc.: 79.69%] [G loss: 0.783072]\n",
      "epoch:7 step:7202 [D loss: 0.570858, acc.: 67.19%] [G loss: 0.673913]\n",
      "epoch:7 step:7203 [D loss: 0.551358, acc.: 71.09%] [G loss: 0.621453]\n",
      "epoch:7 step:7204 [D loss: 0.584441, acc.: 67.19%] [G loss: 0.610191]\n",
      "epoch:7 step:7205 [D loss: 0.554950, acc.: 70.31%] [G loss: 0.621294]\n",
      "epoch:7 step:7206 [D loss: 0.490593, acc.: 77.34%] [G loss: 0.733225]\n",
      "epoch:7 step:7207 [D loss: 0.340281, acc.: 85.94%] [G loss: 0.905191]\n",
      "epoch:7 step:7208 [D loss: 0.489649, acc.: 78.91%] [G loss: 0.860718]\n",
      "epoch:7 step:7209 [D loss: 0.494397, acc.: 77.34%] [G loss: 0.837021]\n",
      "epoch:7 step:7210 [D loss: 0.545914, acc.: 69.53%] [G loss: 0.714373]\n",
      "epoch:7 step:7211 [D loss: 0.578086, acc.: 66.41%] [G loss: 0.616030]\n",
      "epoch:7 step:7212 [D loss: 0.602834, acc.: 63.28%] [G loss: 0.423831]\n",
      "epoch:7 step:7213 [D loss: 0.525537, acc.: 70.31%] [G loss: 0.550191]\n",
      "epoch:7 step:7214 [D loss: 0.541199, acc.: 75.78%] [G loss: 0.704009]\n",
      "epoch:7 step:7215 [D loss: 0.505280, acc.: 75.00%] [G loss: 0.655931]\n",
      "epoch:7 step:7216 [D loss: 0.575775, acc.: 67.19%] [G loss: 0.537047]\n",
      "epoch:7 step:7217 [D loss: 0.612425, acc.: 60.94%] [G loss: 0.506682]\n",
      "epoch:7 step:7218 [D loss: 0.523037, acc.: 71.09%] [G loss: 0.629607]\n",
      "epoch:7 step:7219 [D loss: 0.527273, acc.: 70.31%] [G loss: 0.582590]\n",
      "epoch:7 step:7220 [D loss: 0.480013, acc.: 78.12%] [G loss: 0.651114]\n",
      "epoch:7 step:7221 [D loss: 0.550896, acc.: 70.31%] [G loss: 0.723289]\n",
      "epoch:7 step:7222 [D loss: 0.504271, acc.: 75.00%] [G loss: 0.581975]\n",
      "epoch:7 step:7223 [D loss: 0.560769, acc.: 69.53%] [G loss: 0.656201]\n",
      "epoch:7 step:7224 [D loss: 0.485000, acc.: 76.56%] [G loss: 0.834888]\n",
      "epoch:7 step:7225 [D loss: 0.552912, acc.: 67.19%] [G loss: 0.695205]\n",
      "epoch:7 step:7226 [D loss: 0.561976, acc.: 71.09%] [G loss: 0.589353]\n",
      "epoch:7 step:7227 [D loss: 0.532530, acc.: 74.22%] [G loss: 0.550422]\n",
      "epoch:7 step:7228 [D loss: 0.545319, acc.: 75.00%] [G loss: 0.496318]\n",
      "epoch:7 step:7229 [D loss: 0.561052, acc.: 68.75%] [G loss: 0.538540]\n",
      "epoch:7 step:7230 [D loss: 0.600924, acc.: 66.41%] [G loss: 0.738276]\n",
      "epoch:7 step:7231 [D loss: 0.595149, acc.: 70.31%] [G loss: 0.621853]\n",
      "epoch:7 step:7232 [D loss: 0.604435, acc.: 71.09%] [G loss: 0.603689]\n",
      "epoch:7 step:7233 [D loss: 0.563047, acc.: 70.31%] [G loss: 0.799647]\n",
      "epoch:7 step:7234 [D loss: 0.547050, acc.: 75.78%] [G loss: 0.738228]\n",
      "epoch:7 step:7235 [D loss: 0.570238, acc.: 70.31%] [G loss: 0.807341]\n",
      "epoch:7 step:7236 [D loss: 0.508206, acc.: 75.00%] [G loss: 0.596250]\n",
      "epoch:7 step:7237 [D loss: 0.542293, acc.: 71.09%] [G loss: 0.581358]\n",
      "epoch:7 step:7238 [D loss: 0.553064, acc.: 68.75%] [G loss: 0.624919]\n",
      "epoch:7 step:7239 [D loss: 0.500215, acc.: 78.12%] [G loss: 0.619281]\n",
      "epoch:7 step:7240 [D loss: 0.505095, acc.: 75.00%] [G loss: 0.612873]\n",
      "epoch:7 step:7241 [D loss: 0.533278, acc.: 71.09%] [G loss: 0.631712]\n",
      "epoch:7 step:7242 [D loss: 0.600127, acc.: 66.41%] [G loss: 0.555546]\n",
      "epoch:7 step:7243 [D loss: 0.568451, acc.: 66.41%] [G loss: 0.535634]\n",
      "epoch:7 step:7244 [D loss: 0.535517, acc.: 76.56%] [G loss: 0.410447]\n",
      "epoch:7 step:7245 [D loss: 0.592939, acc.: 66.41%] [G loss: 0.446852]\n",
      "epoch:7 step:7246 [D loss: 0.544291, acc.: 72.66%] [G loss: 0.485282]\n",
      "epoch:7 step:7247 [D loss: 0.542277, acc.: 67.97%] [G loss: 0.525861]\n",
      "epoch:7 step:7248 [D loss: 0.577894, acc.: 65.62%] [G loss: 0.520025]\n",
      "epoch:7 step:7249 [D loss: 0.550535, acc.: 71.88%] [G loss: 0.520848]\n",
      "epoch:7 step:7250 [D loss: 0.482486, acc.: 76.56%] [G loss: 0.837572]\n",
      "epoch:7 step:7251 [D loss: 0.515746, acc.: 77.34%] [G loss: 0.654487]\n",
      "epoch:7 step:7252 [D loss: 0.490707, acc.: 76.56%] [G loss: 0.689503]\n",
      "epoch:7 step:7253 [D loss: 0.480632, acc.: 77.34%] [G loss: 0.687492]\n",
      "epoch:7 step:7254 [D loss: 0.531148, acc.: 72.66%] [G loss: 0.484283]\n",
      "epoch:7 step:7255 [D loss: 0.588371, acc.: 66.41%] [G loss: 0.627971]\n",
      "epoch:7 step:7256 [D loss: 0.522182, acc.: 73.44%] [G loss: 0.468461]\n",
      "epoch:7 step:7257 [D loss: 0.562453, acc.: 71.88%] [G loss: 0.469681]\n",
      "epoch:7 step:7258 [D loss: 0.509756, acc.: 75.00%] [G loss: 0.532609]\n",
      "epoch:7 step:7259 [D loss: 0.518433, acc.: 75.00%] [G loss: 0.634204]\n",
      "epoch:7 step:7260 [D loss: 0.485254, acc.: 75.78%] [G loss: 0.792487]\n",
      "epoch:7 step:7261 [D loss: 0.561246, acc.: 68.75%] [G loss: 0.786119]\n",
      "epoch:7 step:7262 [D loss: 0.571465, acc.: 67.19%] [G loss: 0.515515]\n",
      "epoch:7 step:7263 [D loss: 0.579085, acc.: 65.62%] [G loss: 0.539366]\n",
      "epoch:7 step:7264 [D loss: 0.556861, acc.: 71.88%] [G loss: 0.524512]\n",
      "epoch:7 step:7265 [D loss: 0.535265, acc.: 72.66%] [G loss: 0.540655]\n",
      "epoch:7 step:7266 [D loss: 0.484042, acc.: 75.78%] [G loss: 0.732119]\n",
      "epoch:7 step:7267 [D loss: 0.462472, acc.: 75.00%] [G loss: 0.625852]\n",
      "epoch:7 step:7268 [D loss: 0.527063, acc.: 74.22%] [G loss: 0.636771]\n",
      "epoch:7 step:7269 [D loss: 0.574075, acc.: 70.31%] [G loss: 0.458219]\n",
      "epoch:7 step:7270 [D loss: 0.571013, acc.: 69.53%] [G loss: 0.524118]\n",
      "epoch:7 step:7271 [D loss: 0.522634, acc.: 70.31%] [G loss: 0.571577]\n",
      "epoch:7 step:7272 [D loss: 0.562865, acc.: 71.88%] [G loss: 0.633250]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:7 step:7273 [D loss: 0.492037, acc.: 75.00%] [G loss: 0.682696]\n",
      "epoch:7 step:7274 [D loss: 0.572795, acc.: 67.19%] [G loss: 0.468370]\n",
      "epoch:7 step:7275 [D loss: 0.565360, acc.: 72.66%] [G loss: 0.587875]\n",
      "epoch:7 step:7276 [D loss: 0.618415, acc.: 67.97%] [G loss: 0.552394]\n",
      "epoch:7 step:7277 [D loss: 0.533610, acc.: 73.44%] [G loss: 0.528447]\n",
      "epoch:7 step:7278 [D loss: 0.523550, acc.: 75.00%] [G loss: 0.649238]\n",
      "epoch:7 step:7279 [D loss: 0.565907, acc.: 72.66%] [G loss: 0.564240]\n",
      "epoch:7 step:7280 [D loss: 0.602186, acc.: 63.28%] [G loss: 0.490474]\n",
      "epoch:7 step:7281 [D loss: 0.564205, acc.: 69.53%] [G loss: 0.420919]\n",
      "epoch:7 step:7282 [D loss: 0.571803, acc.: 71.88%] [G loss: 0.588606]\n",
      "epoch:7 step:7283 [D loss: 0.496735, acc.: 75.00%] [G loss: 0.603321]\n",
      "epoch:7 step:7284 [D loss: 0.487465, acc.: 75.78%] [G loss: 0.651141]\n",
      "epoch:7 step:7285 [D loss: 0.562541, acc.: 71.88%] [G loss: 0.510261]\n",
      "epoch:7 step:7286 [D loss: 0.544843, acc.: 69.53%] [G loss: 0.602338]\n",
      "epoch:7 step:7287 [D loss: 0.527768, acc.: 69.53%] [G loss: 0.660836]\n",
      "epoch:7 step:7288 [D loss: 0.540654, acc.: 71.09%] [G loss: 0.538883]\n",
      "epoch:7 step:7289 [D loss: 0.543744, acc.: 74.22%] [G loss: 0.559652]\n",
      "epoch:7 step:7290 [D loss: 0.601303, acc.: 63.28%] [G loss: 0.568123]\n",
      "epoch:7 step:7291 [D loss: 0.481083, acc.: 76.56%] [G loss: 0.735143]\n",
      "epoch:7 step:7292 [D loss: 0.529856, acc.: 72.66%] [G loss: 0.666360]\n",
      "epoch:7 step:7293 [D loss: 0.551077, acc.: 71.09%] [G loss: 0.652004]\n",
      "epoch:7 step:7294 [D loss: 0.532812, acc.: 70.31%] [G loss: 0.600086]\n",
      "epoch:7 step:7295 [D loss: 0.481827, acc.: 79.69%] [G loss: 0.559123]\n",
      "epoch:7 step:7296 [D loss: 0.508650, acc.: 71.88%] [G loss: 0.662575]\n",
      "epoch:7 step:7297 [D loss: 0.575935, acc.: 68.75%] [G loss: 0.486312]\n",
      "epoch:7 step:7298 [D loss: 0.604706, acc.: 67.19%] [G loss: 0.485357]\n",
      "epoch:7 step:7299 [D loss: 0.600148, acc.: 60.16%] [G loss: 0.507551]\n",
      "epoch:7 step:7300 [D loss: 0.456215, acc.: 78.12%] [G loss: 0.547927]\n",
      "epoch:7 step:7301 [D loss: 0.606735, acc.: 69.53%] [G loss: 0.634841]\n",
      "epoch:7 step:7302 [D loss: 0.493106, acc.: 79.69%] [G loss: 0.721080]\n",
      "epoch:7 step:7303 [D loss: 0.527849, acc.: 77.34%] [G loss: 0.570858]\n",
      "epoch:7 step:7304 [D loss: 0.563730, acc.: 64.84%] [G loss: 0.628254]\n",
      "epoch:7 step:7305 [D loss: 0.459424, acc.: 78.12%] [G loss: 0.592649]\n",
      "epoch:7 step:7306 [D loss: 0.491506, acc.: 71.88%] [G loss: 0.700594]\n",
      "epoch:7 step:7307 [D loss: 0.558893, acc.: 70.31%] [G loss: 0.625533]\n",
      "epoch:7 step:7308 [D loss: 0.587595, acc.: 66.41%] [G loss: 0.574996]\n",
      "epoch:7 step:7309 [D loss: 0.571348, acc.: 66.41%] [G loss: 0.507794]\n",
      "epoch:7 step:7310 [D loss: 0.524152, acc.: 75.78%] [G loss: 0.682928]\n",
      "epoch:7 step:7311 [D loss: 0.525135, acc.: 70.31%] [G loss: 0.727845]\n",
      "epoch:7 step:7312 [D loss: 0.501971, acc.: 71.88%] [G loss: 0.739974]\n",
      "epoch:7 step:7313 [D loss: 0.552360, acc.: 67.19%] [G loss: 0.709677]\n",
      "epoch:7 step:7314 [D loss: 0.512608, acc.: 75.78%] [G loss: 0.607630]\n",
      "epoch:7 step:7315 [D loss: 0.588389, acc.: 67.19%] [G loss: 0.638351]\n",
      "epoch:7 step:7316 [D loss: 0.515971, acc.: 75.00%] [G loss: 0.632643]\n",
      "epoch:7 step:7317 [D loss: 0.519055, acc.: 74.22%] [G loss: 0.692770]\n",
      "epoch:7 step:7318 [D loss: 0.581956, acc.: 66.41%] [G loss: 0.550132]\n",
      "epoch:7 step:7319 [D loss: 0.537184, acc.: 71.88%] [G loss: 0.551513]\n",
      "epoch:7 step:7320 [D loss: 0.521341, acc.: 71.88%] [G loss: 0.558430]\n",
      "epoch:7 step:7321 [D loss: 0.593192, acc.: 66.41%] [G loss: 0.589481]\n",
      "epoch:7 step:7322 [D loss: 0.533696, acc.: 75.78%] [G loss: 0.524445]\n",
      "epoch:7 step:7323 [D loss: 0.534712, acc.: 71.88%] [G loss: 0.569160]\n",
      "epoch:7 step:7324 [D loss: 0.616903, acc.: 59.38%] [G loss: 0.510157]\n",
      "epoch:7 step:7325 [D loss: 0.645928, acc.: 60.94%] [G loss: 0.440307]\n",
      "epoch:7 step:7326 [D loss: 0.533449, acc.: 73.44%] [G loss: 0.464222]\n",
      "epoch:7 step:7327 [D loss: 0.535503, acc.: 75.00%] [G loss: 0.661593]\n",
      "epoch:7 step:7328 [D loss: 0.483035, acc.: 78.91%] [G loss: 0.776233]\n",
      "epoch:7 step:7329 [D loss: 0.549945, acc.: 68.75%] [G loss: 0.729140]\n",
      "epoch:7 step:7330 [D loss: 0.565307, acc.: 65.62%] [G loss: 0.836040]\n",
      "epoch:7 step:7331 [D loss: 0.540321, acc.: 73.44%] [G loss: 0.580537]\n",
      "epoch:7 step:7332 [D loss: 0.516957, acc.: 72.66%] [G loss: 0.569811]\n",
      "epoch:7 step:7333 [D loss: 0.559306, acc.: 72.66%] [G loss: 0.645586]\n",
      "epoch:7 step:7334 [D loss: 0.555686, acc.: 71.88%] [G loss: 0.665242]\n",
      "epoch:7 step:7335 [D loss: 0.606926, acc.: 67.19%] [G loss: 0.670075]\n",
      "epoch:7 step:7336 [D loss: 0.583565, acc.: 71.09%] [G loss: 0.617099]\n",
      "epoch:7 step:7337 [D loss: 0.566020, acc.: 68.75%] [G loss: 0.513515]\n",
      "epoch:7 step:7338 [D loss: 0.550775, acc.: 71.88%] [G loss: 0.557566]\n",
      "epoch:7 step:7339 [D loss: 0.552864, acc.: 71.09%] [G loss: 0.622696]\n",
      "epoch:7 step:7340 [D loss: 0.474574, acc.: 77.34%] [G loss: 0.720893]\n",
      "epoch:7 step:7341 [D loss: 0.473486, acc.: 78.12%] [G loss: 0.831450]\n",
      "epoch:7 step:7342 [D loss: 0.636756, acc.: 59.38%] [G loss: 0.598085]\n",
      "epoch:7 step:7343 [D loss: 0.604190, acc.: 64.06%] [G loss: 0.545726]\n",
      "epoch:7 step:7344 [D loss: 0.543487, acc.: 71.88%] [G loss: 0.572154]\n",
      "epoch:7 step:7345 [D loss: 0.465426, acc.: 80.47%] [G loss: 0.639197]\n",
      "epoch:7 step:7346 [D loss: 0.616147, acc.: 63.28%] [G loss: 0.541327]\n",
      "epoch:7 step:7347 [D loss: 0.647501, acc.: 62.50%] [G loss: 0.434060]\n",
      "epoch:7 step:7348 [D loss: 0.556168, acc.: 71.88%] [G loss: 0.481363]\n",
      "epoch:7 step:7349 [D loss: 0.567712, acc.: 72.66%] [G loss: 0.434531]\n",
      "epoch:7 step:7350 [D loss: 0.537911, acc.: 74.22%] [G loss: 0.565456]\n",
      "epoch:7 step:7351 [D loss: 0.485077, acc.: 75.00%] [G loss: 0.675078]\n",
      "epoch:7 step:7352 [D loss: 0.584879, acc.: 65.62%] [G loss: 0.463950]\n",
      "epoch:7 step:7353 [D loss: 0.617320, acc.: 60.16%] [G loss: 0.597548]\n",
      "epoch:7 step:7354 [D loss: 0.543174, acc.: 71.09%] [G loss: 0.528034]\n",
      "epoch:7 step:7355 [D loss: 0.510641, acc.: 78.12%] [G loss: 0.818679]\n",
      "epoch:7 step:7356 [D loss: 0.563352, acc.: 68.75%] [G loss: 0.592299]\n",
      "epoch:7 step:7357 [D loss: 0.535057, acc.: 69.53%] [G loss: 0.535012]\n",
      "epoch:7 step:7358 [D loss: 0.551450, acc.: 71.09%] [G loss: 0.590198]\n",
      "epoch:7 step:7359 [D loss: 0.568442, acc.: 73.44%] [G loss: 0.610582]\n",
      "epoch:7 step:7360 [D loss: 0.479524, acc.: 76.56%] [G loss: 0.764430]\n",
      "epoch:7 step:7361 [D loss: 0.483923, acc.: 76.56%] [G loss: 0.625021]\n",
      "epoch:7 step:7362 [D loss: 0.478700, acc.: 76.56%] [G loss: 0.665350]\n",
      "epoch:7 step:7363 [D loss: 0.547288, acc.: 69.53%] [G loss: 0.550907]\n",
      "epoch:7 step:7364 [D loss: 0.506632, acc.: 78.91%] [G loss: 0.546029]\n",
      "epoch:7 step:7365 [D loss: 0.540336, acc.: 68.75%] [G loss: 0.512400]\n",
      "epoch:7 step:7366 [D loss: 0.503012, acc.: 71.88%] [G loss: 0.669690]\n",
      "epoch:7 step:7367 [D loss: 0.548568, acc.: 72.66%] [G loss: 0.576917]\n",
      "epoch:7 step:7368 [D loss: 0.546077, acc.: 69.53%] [G loss: 0.488569]\n",
      "epoch:7 step:7369 [D loss: 0.523315, acc.: 67.97%] [G loss: 0.562417]\n",
      "epoch:7 step:7370 [D loss: 0.491467, acc.: 78.12%] [G loss: 0.641193]\n",
      "epoch:7 step:7371 [D loss: 0.650694, acc.: 65.62%] [G loss: 0.420363]\n",
      "epoch:7 step:7372 [D loss: 0.542935, acc.: 68.75%] [G loss: 0.630015]\n",
      "epoch:7 step:7373 [D loss: 0.509026, acc.: 75.00%] [G loss: 0.702871]\n",
      "epoch:7 step:7374 [D loss: 0.531656, acc.: 75.00%] [G loss: 0.645214]\n",
      "epoch:7 step:7375 [D loss: 0.583422, acc.: 67.97%] [G loss: 0.762559]\n",
      "epoch:7 step:7376 [D loss: 0.590406, acc.: 68.75%] [G loss: 0.663935]\n",
      "epoch:7 step:7377 [D loss: 0.590363, acc.: 67.19%] [G loss: 0.590110]\n",
      "epoch:7 step:7378 [D loss: 0.535978, acc.: 74.22%] [G loss: 0.493197]\n",
      "epoch:7 step:7379 [D loss: 0.600040, acc.: 63.28%] [G loss: 0.482975]\n",
      "epoch:7 step:7380 [D loss: 0.486093, acc.: 75.78%] [G loss: 0.624983]\n",
      "epoch:7 step:7381 [D loss: 0.550427, acc.: 67.19%] [G loss: 0.567083]\n",
      "epoch:7 step:7382 [D loss: 0.497284, acc.: 68.75%] [G loss: 0.582207]\n",
      "epoch:7 step:7383 [D loss: 0.653081, acc.: 64.06%] [G loss: 0.531831]\n",
      "epoch:7 step:7384 [D loss: 0.551199, acc.: 71.88%] [G loss: 0.575694]\n",
      "epoch:7 step:7385 [D loss: 0.576948, acc.: 71.88%] [G loss: 0.548555]\n",
      "epoch:7 step:7386 [D loss: 0.610640, acc.: 66.41%] [G loss: 0.586465]\n",
      "epoch:7 step:7387 [D loss: 0.653329, acc.: 59.38%] [G loss: 0.449713]\n",
      "epoch:7 step:7388 [D loss: 0.546709, acc.: 69.53%] [G loss: 0.469469]\n",
      "epoch:7 step:7389 [D loss: 0.539803, acc.: 72.66%] [G loss: 0.531932]\n",
      "epoch:7 step:7390 [D loss: 0.541718, acc.: 67.19%] [G loss: 0.543681]\n",
      "epoch:7 step:7391 [D loss: 0.521393, acc.: 73.44%] [G loss: 0.491637]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:7 step:7392 [D loss: 0.494792, acc.: 74.22%] [G loss: 0.644401]\n",
      "epoch:7 step:7393 [D loss: 0.539637, acc.: 68.75%] [G loss: 0.463649]\n",
      "epoch:7 step:7394 [D loss: 0.553667, acc.: 71.88%] [G loss: 0.504989]\n",
      "epoch:7 step:7395 [D loss: 0.539756, acc.: 67.97%] [G loss: 0.574589]\n",
      "epoch:7 step:7396 [D loss: 0.546865, acc.: 72.66%] [G loss: 0.613289]\n",
      "epoch:7 step:7397 [D loss: 0.514503, acc.: 74.22%] [G loss: 0.627555]\n",
      "epoch:7 step:7398 [D loss: 0.591198, acc.: 60.94%] [G loss: 0.537303]\n",
      "epoch:7 step:7399 [D loss: 0.592582, acc.: 67.19%] [G loss: 0.503997]\n",
      "epoch:7 step:7400 [D loss: 0.504444, acc.: 72.66%] [G loss: 0.459729]\n",
      "epoch:7 step:7401 [D loss: 0.494696, acc.: 75.00%] [G loss: 0.569629]\n",
      "epoch:7 step:7402 [D loss: 0.494922, acc.: 78.91%] [G loss: 0.515711]\n",
      "epoch:7 step:7403 [D loss: 0.571604, acc.: 67.97%] [G loss: 0.555511]\n",
      "epoch:7 step:7404 [D loss: 0.610065, acc.: 63.28%] [G loss: 0.571657]\n",
      "epoch:7 step:7405 [D loss: 0.519790, acc.: 73.44%] [G loss: 0.558046]\n",
      "epoch:7 step:7406 [D loss: 0.652807, acc.: 57.81%] [G loss: 0.417065]\n",
      "epoch:7 step:7407 [D loss: 0.551103, acc.: 67.19%] [G loss: 0.435052]\n",
      "epoch:7 step:7408 [D loss: 0.567273, acc.: 73.44%] [G loss: 0.354336]\n",
      "epoch:7 step:7409 [D loss: 0.506222, acc.: 72.66%] [G loss: 0.481708]\n",
      "epoch:7 step:7410 [D loss: 0.535061, acc.: 69.53%] [G loss: 0.564152]\n",
      "epoch:7 step:7411 [D loss: 0.525082, acc.: 71.09%] [G loss: 0.588862]\n",
      "epoch:7 step:7412 [D loss: 0.529006, acc.: 69.53%] [G loss: 0.741379]\n",
      "epoch:7 step:7413 [D loss: 0.458025, acc.: 78.12%] [G loss: 0.679047]\n",
      "epoch:7 step:7414 [D loss: 0.524053, acc.: 74.22%] [G loss: 0.721812]\n",
      "epoch:7 step:7415 [D loss: 0.607672, acc.: 64.06%] [G loss: 0.588934]\n",
      "epoch:7 step:7416 [D loss: 0.507181, acc.: 71.09%] [G loss: 0.553918]\n",
      "epoch:7 step:7417 [D loss: 0.582374, acc.: 71.88%] [G loss: 0.633379]\n",
      "epoch:7 step:7418 [D loss: 0.554964, acc.: 70.31%] [G loss: 0.582123]\n",
      "epoch:7 step:7419 [D loss: 0.447355, acc.: 79.69%] [G loss: 0.607152]\n",
      "epoch:7 step:7420 [D loss: 0.576791, acc.: 71.09%] [G loss: 0.544945]\n",
      "epoch:7 step:7421 [D loss: 0.564643, acc.: 67.97%] [G loss: 0.538325]\n",
      "epoch:7 step:7422 [D loss: 0.595331, acc.: 65.62%] [G loss: 0.548105]\n",
      "epoch:7 step:7423 [D loss: 0.517009, acc.: 72.66%] [G loss: 0.519548]\n",
      "epoch:7 step:7424 [D loss: 0.570127, acc.: 66.41%] [G loss: 0.457597]\n",
      "epoch:7 step:7425 [D loss: 0.535413, acc.: 72.66%] [G loss: 0.485635]\n",
      "epoch:7 step:7426 [D loss: 0.616557, acc.: 64.84%] [G loss: 0.434138]\n",
      "epoch:7 step:7427 [D loss: 0.520874, acc.: 76.56%] [G loss: 0.620697]\n",
      "epoch:7 step:7428 [D loss: 0.537206, acc.: 72.66%] [G loss: 0.405818]\n",
      "epoch:7 step:7429 [D loss: 0.506354, acc.: 75.00%] [G loss: 0.693824]\n",
      "epoch:7 step:7430 [D loss: 0.478481, acc.: 77.34%] [G loss: 0.747793]\n",
      "epoch:7 step:7431 [D loss: 0.519128, acc.: 67.19%] [G loss: 0.669609]\n",
      "epoch:7 step:7432 [D loss: 0.579177, acc.: 67.97%] [G loss: 0.586046]\n",
      "epoch:7 step:7433 [D loss: 0.561323, acc.: 68.75%] [G loss: 0.591362]\n",
      "epoch:7 step:7434 [D loss: 0.474016, acc.: 75.78%] [G loss: 0.544435]\n",
      "epoch:7 step:7435 [D loss: 0.569505, acc.: 68.75%] [G loss: 0.696937]\n",
      "epoch:7 step:7436 [D loss: 0.556698, acc.: 69.53%] [G loss: 0.512989]\n",
      "epoch:7 step:7437 [D loss: 0.566441, acc.: 67.97%] [G loss: 0.523397]\n",
      "epoch:7 step:7438 [D loss: 0.548270, acc.: 71.09%] [G loss: 0.595276]\n",
      "epoch:7 step:7439 [D loss: 0.662903, acc.: 58.59%] [G loss: 0.447840]\n",
      "epoch:7 step:7440 [D loss: 0.547797, acc.: 71.09%] [G loss: 0.469753]\n",
      "epoch:7 step:7441 [D loss: 0.550946, acc.: 72.66%] [G loss: 0.556731]\n",
      "epoch:7 step:7442 [D loss: 0.581450, acc.: 67.19%] [G loss: 0.441969]\n",
      "epoch:7 step:7443 [D loss: 0.427028, acc.: 82.03%] [G loss: 0.640891]\n",
      "epoch:7 step:7444 [D loss: 0.488710, acc.: 74.22%] [G loss: 0.690290]\n",
      "epoch:7 step:7445 [D loss: 0.470960, acc.: 79.69%] [G loss: 0.787604]\n",
      "epoch:7 step:7446 [D loss: 0.538380, acc.: 72.66%] [G loss: 0.624242]\n",
      "epoch:7 step:7447 [D loss: 0.595628, acc.: 66.41%] [G loss: 0.635486]\n",
      "epoch:7 step:7448 [D loss: 0.526571, acc.: 71.88%] [G loss: 0.616177]\n",
      "epoch:7 step:7449 [D loss: 0.450451, acc.: 82.03%] [G loss: 0.640387]\n",
      "epoch:7 step:7450 [D loss: 0.539017, acc.: 71.88%] [G loss: 0.700111]\n",
      "epoch:7 step:7451 [D loss: 0.632695, acc.: 64.84%] [G loss: 0.447451]\n",
      "epoch:7 step:7452 [D loss: 0.532651, acc.: 73.44%] [G loss: 0.594650]\n",
      "epoch:7 step:7453 [D loss: 0.492821, acc.: 76.56%] [G loss: 0.731116]\n",
      "epoch:7 step:7454 [D loss: 0.485087, acc.: 76.56%] [G loss: 0.904515]\n",
      "epoch:7 step:7455 [D loss: 0.489808, acc.: 76.56%] [G loss: 0.756680]\n",
      "epoch:7 step:7456 [D loss: 0.515562, acc.: 75.00%] [G loss: 0.760999]\n",
      "epoch:7 step:7457 [D loss: 0.500793, acc.: 75.00%] [G loss: 0.661600]\n",
      "epoch:7 step:7458 [D loss: 0.497457, acc.: 73.44%] [G loss: 0.674122]\n",
      "epoch:7 step:7459 [D loss: 0.477784, acc.: 78.91%] [G loss: 0.729413]\n",
      "epoch:7 step:7460 [D loss: 0.536403, acc.: 68.75%] [G loss: 0.655608]\n",
      "epoch:7 step:7461 [D loss: 0.570629, acc.: 67.97%] [G loss: 0.473106]\n",
      "epoch:7 step:7462 [D loss: 0.554405, acc.: 71.09%] [G loss: 0.518042]\n",
      "epoch:7 step:7463 [D loss: 0.561765, acc.: 67.97%] [G loss: 0.460275]\n",
      "epoch:7 step:7464 [D loss: 0.583864, acc.: 65.62%] [G loss: 0.549060]\n",
      "epoch:7 step:7465 [D loss: 0.498134, acc.: 78.12%] [G loss: 0.584188]\n",
      "epoch:7 step:7466 [D loss: 0.551896, acc.: 68.75%] [G loss: 0.614997]\n",
      "epoch:7 step:7467 [D loss: 0.578063, acc.: 65.62%] [G loss: 0.570430]\n",
      "epoch:7 step:7468 [D loss: 0.545305, acc.: 71.09%] [G loss: 0.612039]\n",
      "epoch:7 step:7469 [D loss: 0.501297, acc.: 75.78%] [G loss: 0.580039]\n",
      "epoch:7 step:7470 [D loss: 0.504218, acc.: 74.22%] [G loss: 0.619597]\n",
      "epoch:7 step:7471 [D loss: 0.458828, acc.: 78.12%] [G loss: 0.819204]\n",
      "epoch:7 step:7472 [D loss: 0.556204, acc.: 70.31%] [G loss: 0.677866]\n",
      "epoch:7 step:7473 [D loss: 0.509966, acc.: 78.91%] [G loss: 0.666158]\n",
      "epoch:7 step:7474 [D loss: 0.670509, acc.: 63.28%] [G loss: 0.682618]\n",
      "epoch:7 step:7475 [D loss: 0.564446, acc.: 72.66%] [G loss: 0.535355]\n",
      "epoch:7 step:7476 [D loss: 0.612019, acc.: 60.16%] [G loss: 0.571768]\n",
      "epoch:7 step:7477 [D loss: 0.548225, acc.: 73.44%] [G loss: 0.681190]\n",
      "epoch:7 step:7478 [D loss: 0.434843, acc.: 84.38%] [G loss: 0.693744]\n",
      "epoch:7 step:7479 [D loss: 0.706027, acc.: 60.16%] [G loss: 0.442062]\n",
      "epoch:7 step:7480 [D loss: 0.470596, acc.: 75.00%] [G loss: 0.630111]\n",
      "epoch:7 step:7481 [D loss: 0.478056, acc.: 77.34%] [G loss: 0.617150]\n",
      "epoch:7 step:7482 [D loss: 0.461581, acc.: 78.12%] [G loss: 0.630612]\n",
      "epoch:7 step:7483 [D loss: 0.477050, acc.: 75.00%] [G loss: 0.754494]\n",
      "epoch:7 step:7484 [D loss: 0.411758, acc.: 81.25%] [G loss: 0.809502]\n",
      "epoch:7 step:7485 [D loss: 0.425527, acc.: 81.25%] [G loss: 0.992601]\n",
      "epoch:7 step:7486 [D loss: 0.451879, acc.: 78.91%] [G loss: 0.869811]\n",
      "epoch:7 step:7487 [D loss: 0.692898, acc.: 67.19%] [G loss: 1.145918]\n",
      "epoch:7 step:7488 [D loss: 0.469891, acc.: 77.34%] [G loss: 0.948010]\n",
      "epoch:7 step:7489 [D loss: 0.513135, acc.: 71.88%] [G loss: 0.710596]\n",
      "epoch:7 step:7490 [D loss: 0.576217, acc.: 65.62%] [G loss: 0.707991]\n",
      "epoch:7 step:7491 [D loss: 0.642556, acc.: 64.84%] [G loss: 0.792658]\n",
      "epoch:7 step:7492 [D loss: 0.485807, acc.: 74.22%] [G loss: 0.688499]\n",
      "epoch:7 step:7493 [D loss: 0.562151, acc.: 72.66%] [G loss: 0.643809]\n",
      "epoch:7 step:7494 [D loss: 0.490244, acc.: 75.00%] [G loss: 0.862629]\n",
      "epoch:7 step:7495 [D loss: 0.446285, acc.: 80.47%] [G loss: 0.854417]\n",
      "epoch:7 step:7496 [D loss: 0.434708, acc.: 85.16%] [G loss: 1.249721]\n",
      "epoch:8 step:7497 [D loss: 0.598366, acc.: 66.41%] [G loss: 1.005477]\n",
      "epoch:8 step:7498 [D loss: 0.560648, acc.: 68.75%] [G loss: 0.812008]\n",
      "epoch:8 step:7499 [D loss: 0.588891, acc.: 68.75%] [G loss: 0.762002]\n",
      "epoch:8 step:7500 [D loss: 0.541966, acc.: 72.66%] [G loss: 0.593587]\n",
      "epoch:8 step:7501 [D loss: 0.531390, acc.: 75.00%] [G loss: 0.567083]\n",
      "epoch:8 step:7502 [D loss: 0.566591, acc.: 71.88%] [G loss: 0.640808]\n",
      "epoch:8 step:7503 [D loss: 0.461682, acc.: 75.78%] [G loss: 0.871072]\n",
      "epoch:8 step:7504 [D loss: 0.518943, acc.: 74.22%] [G loss: 0.646730]\n",
      "epoch:8 step:7505 [D loss: 0.517038, acc.: 71.09%] [G loss: 0.714640]\n",
      "epoch:8 step:7506 [D loss: 0.500478, acc.: 79.69%] [G loss: 0.668158]\n",
      "epoch:8 step:7507 [D loss: 0.431972, acc.: 78.91%] [G loss: 0.734736]\n",
      "epoch:8 step:7508 [D loss: 0.587443, acc.: 71.09%] [G loss: 0.617790]\n",
      "epoch:8 step:7509 [D loss: 0.518765, acc.: 71.88%] [G loss: 0.533128]\n",
      "epoch:8 step:7510 [D loss: 0.575506, acc.: 71.88%] [G loss: 0.514634]\n",
      "epoch:8 step:7511 [D loss: 0.457113, acc.: 82.81%] [G loss: 0.485587]\n",
      "epoch:8 step:7512 [D loss: 0.448488, acc.: 80.47%] [G loss: 0.584107]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:8 step:7513 [D loss: 0.538493, acc.: 71.88%] [G loss: 0.630118]\n",
      "epoch:8 step:7514 [D loss: 0.547224, acc.: 74.22%] [G loss: 0.687054]\n",
      "epoch:8 step:7515 [D loss: 0.611784, acc.: 69.53%] [G loss: 0.593727]\n",
      "epoch:8 step:7516 [D loss: 0.652244, acc.: 58.59%] [G loss: 0.514812]\n",
      "epoch:8 step:7517 [D loss: 0.543263, acc.: 74.22%] [G loss: 0.567536]\n",
      "epoch:8 step:7518 [D loss: 0.482812, acc.: 78.12%] [G loss: 0.890584]\n",
      "epoch:8 step:7519 [D loss: 0.516023, acc.: 72.66%] [G loss: 0.635417]\n",
      "epoch:8 step:7520 [D loss: 0.511043, acc.: 77.34%] [G loss: 0.677965]\n",
      "epoch:8 step:7521 [D loss: 0.485316, acc.: 76.56%] [G loss: 0.588409]\n",
      "epoch:8 step:7522 [D loss: 0.574555, acc.: 72.66%] [G loss: 0.515691]\n",
      "epoch:8 step:7523 [D loss: 0.548160, acc.: 70.31%] [G loss: 0.567683]\n",
      "epoch:8 step:7524 [D loss: 0.577097, acc.: 69.53%] [G loss: 0.529274]\n",
      "epoch:8 step:7525 [D loss: 0.510000, acc.: 74.22%] [G loss: 0.720195]\n",
      "epoch:8 step:7526 [D loss: 0.570279, acc.: 66.41%] [G loss: 0.522888]\n",
      "epoch:8 step:7527 [D loss: 0.626085, acc.: 66.41%] [G loss: 0.364870]\n",
      "epoch:8 step:7528 [D loss: 0.582924, acc.: 67.19%] [G loss: 0.554868]\n",
      "epoch:8 step:7529 [D loss: 0.526578, acc.: 73.44%] [G loss: 0.644228]\n",
      "epoch:8 step:7530 [D loss: 0.507104, acc.: 75.00%] [G loss: 0.588894]\n",
      "epoch:8 step:7531 [D loss: 0.576909, acc.: 64.84%] [G loss: 0.497657]\n",
      "epoch:8 step:7532 [D loss: 0.474452, acc.: 78.12%] [G loss: 0.699024]\n",
      "epoch:8 step:7533 [D loss: 0.458273, acc.: 78.91%] [G loss: 0.673555]\n",
      "epoch:8 step:7534 [D loss: 0.559346, acc.: 73.44%] [G loss: 0.461318]\n",
      "epoch:8 step:7535 [D loss: 0.502867, acc.: 75.78%] [G loss: 0.517870]\n",
      "epoch:8 step:7536 [D loss: 0.421288, acc.: 82.03%] [G loss: 0.472081]\n",
      "epoch:8 step:7537 [D loss: 0.544798, acc.: 70.31%] [G loss: 0.502773]\n",
      "epoch:8 step:7538 [D loss: 0.533333, acc.: 73.44%] [G loss: 0.627022]\n",
      "epoch:8 step:7539 [D loss: 0.482916, acc.: 78.12%] [G loss: 0.660020]\n",
      "epoch:8 step:7540 [D loss: 0.597467, acc.: 62.50%] [G loss: 0.522263]\n",
      "epoch:8 step:7541 [D loss: 0.540751, acc.: 67.97%] [G loss: 0.565579]\n",
      "epoch:8 step:7542 [D loss: 0.447129, acc.: 83.59%] [G loss: 0.605550]\n",
      "epoch:8 step:7543 [D loss: 0.545848, acc.: 72.66%] [G loss: 0.626295]\n",
      "epoch:8 step:7544 [D loss: 0.529006, acc.: 70.31%] [G loss: 0.582100]\n",
      "epoch:8 step:7545 [D loss: 0.504862, acc.: 77.34%] [G loss: 0.524714]\n",
      "epoch:8 step:7546 [D loss: 0.519287, acc.: 74.22%] [G loss: 0.633975]\n",
      "epoch:8 step:7547 [D loss: 0.685804, acc.: 58.59%] [G loss: 0.490684]\n",
      "epoch:8 step:7548 [D loss: 0.498830, acc.: 75.00%] [G loss: 0.631189]\n",
      "epoch:8 step:7549 [D loss: 0.514672, acc.: 75.00%] [G loss: 0.564037]\n",
      "epoch:8 step:7550 [D loss: 0.487126, acc.: 75.00%] [G loss: 0.788806]\n",
      "epoch:8 step:7551 [D loss: 0.559842, acc.: 69.53%] [G loss: 0.774272]\n",
      "epoch:8 step:7552 [D loss: 0.525245, acc.: 74.22%] [G loss: 0.663667]\n",
      "epoch:8 step:7553 [D loss: 0.585006, acc.: 63.28%] [G loss: 0.603231]\n",
      "epoch:8 step:7554 [D loss: 0.513088, acc.: 72.66%] [G loss: 0.707228]\n",
      "epoch:8 step:7555 [D loss: 0.497258, acc.: 76.56%] [G loss: 0.667783]\n",
      "epoch:8 step:7556 [D loss: 0.524598, acc.: 74.22%] [G loss: 0.673700]\n",
      "epoch:8 step:7557 [D loss: 0.565959, acc.: 71.88%] [G loss: 0.491160]\n",
      "epoch:8 step:7558 [D loss: 0.569629, acc.: 67.19%] [G loss: 0.578292]\n",
      "epoch:8 step:7559 [D loss: 0.529141, acc.: 72.66%] [G loss: 0.487448]\n",
      "epoch:8 step:7560 [D loss: 0.535032, acc.: 72.66%] [G loss: 0.601623]\n",
      "epoch:8 step:7561 [D loss: 0.548752, acc.: 71.09%] [G loss: 0.568766]\n",
      "epoch:8 step:7562 [D loss: 0.553341, acc.: 71.88%] [G loss: 0.549265]\n",
      "epoch:8 step:7563 [D loss: 0.589578, acc.: 72.66%] [G loss: 0.504620]\n",
      "epoch:8 step:7564 [D loss: 0.469396, acc.: 75.78%] [G loss: 0.547341]\n",
      "epoch:8 step:7565 [D loss: 0.520023, acc.: 71.09%] [G loss: 0.550988]\n",
      "epoch:8 step:7566 [D loss: 0.520707, acc.: 75.78%] [G loss: 0.588791]\n",
      "epoch:8 step:7567 [D loss: 0.541510, acc.: 67.97%] [G loss: 0.546437]\n",
      "epoch:8 step:7568 [D loss: 0.493917, acc.: 73.44%] [G loss: 0.592423]\n",
      "epoch:8 step:7569 [D loss: 0.575955, acc.: 68.75%] [G loss: 0.493781]\n",
      "epoch:8 step:7570 [D loss: 0.479070, acc.: 75.78%] [G loss: 0.701750]\n",
      "epoch:8 step:7571 [D loss: 0.534727, acc.: 73.44%] [G loss: 0.669403]\n",
      "epoch:8 step:7572 [D loss: 0.546206, acc.: 70.31%] [G loss: 0.640655]\n",
      "epoch:8 step:7573 [D loss: 0.467513, acc.: 75.00%] [G loss: 1.133299]\n",
      "epoch:8 step:7574 [D loss: 0.596807, acc.: 69.53%] [G loss: 0.610308]\n",
      "epoch:8 step:7575 [D loss: 0.532813, acc.: 71.88%] [G loss: 0.613996]\n",
      "epoch:8 step:7576 [D loss: 0.502556, acc.: 75.78%] [G loss: 0.638520]\n",
      "epoch:8 step:7577 [D loss: 0.562610, acc.: 67.19%] [G loss: 0.568639]\n",
      "epoch:8 step:7578 [D loss: 0.478987, acc.: 76.56%] [G loss: 0.690008]\n",
      "epoch:8 step:7579 [D loss: 0.525600, acc.: 75.78%] [G loss: 0.761691]\n",
      "epoch:8 step:7580 [D loss: 0.508957, acc.: 72.66%] [G loss: 0.780000]\n",
      "epoch:8 step:7581 [D loss: 0.616594, acc.: 66.41%] [G loss: 0.569503]\n",
      "epoch:8 step:7582 [D loss: 0.559187, acc.: 71.09%] [G loss: 0.518139]\n",
      "epoch:8 step:7583 [D loss: 0.491064, acc.: 77.34%] [G loss: 0.525680]\n",
      "epoch:8 step:7584 [D loss: 0.501539, acc.: 75.00%] [G loss: 0.649925]\n",
      "epoch:8 step:7585 [D loss: 0.474531, acc.: 78.91%] [G loss: 0.757725]\n",
      "epoch:8 step:7586 [D loss: 0.512366, acc.: 71.09%] [G loss: 0.764281]\n",
      "epoch:8 step:7587 [D loss: 0.512513, acc.: 72.66%] [G loss: 0.788809]\n",
      "epoch:8 step:7588 [D loss: 0.478017, acc.: 79.69%] [G loss: 0.743155]\n",
      "epoch:8 step:7589 [D loss: 0.536406, acc.: 74.22%] [G loss: 0.813900]\n",
      "epoch:8 step:7590 [D loss: 0.459482, acc.: 79.69%] [G loss: 0.710199]\n",
      "epoch:8 step:7591 [D loss: 0.497321, acc.: 76.56%] [G loss: 0.655420]\n",
      "epoch:8 step:7592 [D loss: 0.516234, acc.: 75.00%] [G loss: 0.575119]\n",
      "epoch:8 step:7593 [D loss: 0.483110, acc.: 72.66%] [G loss: 0.722398]\n",
      "epoch:8 step:7594 [D loss: 0.595618, acc.: 65.62%] [G loss: 0.596970]\n",
      "epoch:8 step:7595 [D loss: 0.526194, acc.: 74.22%] [G loss: 0.751895]\n",
      "epoch:8 step:7596 [D loss: 0.446013, acc.: 76.56%] [G loss: 0.817984]\n",
      "epoch:8 step:7597 [D loss: 0.510993, acc.: 75.78%] [G loss: 0.666317]\n",
      "epoch:8 step:7598 [D loss: 0.628932, acc.: 61.72%] [G loss: 0.577282]\n",
      "epoch:8 step:7599 [D loss: 0.497383, acc.: 75.78%] [G loss: 0.663882]\n",
      "epoch:8 step:7600 [D loss: 0.562589, acc.: 67.97%] [G loss: 0.417910]\n",
      "epoch:8 step:7601 [D loss: 0.585997, acc.: 69.53%] [G loss: 0.588894]\n",
      "epoch:8 step:7602 [D loss: 0.539854, acc.: 71.09%] [G loss: 0.569101]\n",
      "epoch:8 step:7603 [D loss: 0.636778, acc.: 63.28%] [G loss: 0.625937]\n",
      "epoch:8 step:7604 [D loss: 0.585612, acc.: 66.41%] [G loss: 0.598043]\n",
      "epoch:8 step:7605 [D loss: 0.531146, acc.: 72.66%] [G loss: 0.616171]\n",
      "epoch:8 step:7606 [D loss: 0.542800, acc.: 73.44%] [G loss: 0.666177]\n",
      "epoch:8 step:7607 [D loss: 0.512825, acc.: 71.88%] [G loss: 0.660859]\n",
      "epoch:8 step:7608 [D loss: 0.521629, acc.: 72.66%] [G loss: 0.555818]\n",
      "epoch:8 step:7609 [D loss: 0.572235, acc.: 65.62%] [G loss: 0.541151]\n",
      "epoch:8 step:7610 [D loss: 0.554299, acc.: 69.53%] [G loss: 0.534133]\n",
      "epoch:8 step:7611 [D loss: 0.553885, acc.: 72.66%] [G loss: 0.475757]\n",
      "epoch:8 step:7612 [D loss: 0.523034, acc.: 71.09%] [G loss: 0.644501]\n",
      "epoch:8 step:7613 [D loss: 0.545333, acc.: 67.97%] [G loss: 0.723281]\n",
      "epoch:8 step:7614 [D loss: 0.556037, acc.: 70.31%] [G loss: 0.856466]\n",
      "epoch:8 step:7615 [D loss: 0.453736, acc.: 78.91%] [G loss: 0.896483]\n",
      "epoch:8 step:7616 [D loss: 0.577901, acc.: 67.19%] [G loss: 0.730648]\n",
      "epoch:8 step:7617 [D loss: 0.572464, acc.: 70.31%] [G loss: 0.638955]\n",
      "epoch:8 step:7618 [D loss: 0.509210, acc.: 75.78%] [G loss: 0.694213]\n",
      "epoch:8 step:7619 [D loss: 0.544884, acc.: 66.41%] [G loss: 0.725943]\n",
      "epoch:8 step:7620 [D loss: 0.549288, acc.: 69.53%] [G loss: 0.685762]\n",
      "epoch:8 step:7621 [D loss: 0.569360, acc.: 69.53%] [G loss: 0.682506]\n",
      "epoch:8 step:7622 [D loss: 0.518688, acc.: 74.22%] [G loss: 0.532732]\n",
      "epoch:8 step:7623 [D loss: 0.496110, acc.: 77.34%] [G loss: 0.460877]\n",
      "epoch:8 step:7624 [D loss: 0.495875, acc.: 76.56%] [G loss: 0.599231]\n",
      "epoch:8 step:7625 [D loss: 0.561462, acc.: 71.09%] [G loss: 0.570057]\n",
      "epoch:8 step:7626 [D loss: 0.514078, acc.: 74.22%] [G loss: 0.523135]\n",
      "epoch:8 step:7627 [D loss: 0.540055, acc.: 71.09%] [G loss: 0.538366]\n",
      "epoch:8 step:7628 [D loss: 0.597524, acc.: 65.62%] [G loss: 0.652527]\n",
      "epoch:8 step:7629 [D loss: 0.534400, acc.: 67.97%] [G loss: 0.534113]\n",
      "epoch:8 step:7630 [D loss: 0.566816, acc.: 68.75%] [G loss: 0.540101]\n",
      "epoch:8 step:7631 [D loss: 0.555263, acc.: 64.84%] [G loss: 0.499660]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:8 step:7632 [D loss: 0.489596, acc.: 74.22%] [G loss: 0.706774]\n",
      "epoch:8 step:7633 [D loss: 0.615012, acc.: 62.50%] [G loss: 0.593067]\n",
      "epoch:8 step:7634 [D loss: 0.606954, acc.: 63.28%] [G loss: 0.590856]\n",
      "epoch:8 step:7635 [D loss: 0.567612, acc.: 71.09%] [G loss: 0.574780]\n",
      "epoch:8 step:7636 [D loss: 0.544181, acc.: 68.75%] [G loss: 0.521502]\n",
      "epoch:8 step:7637 [D loss: 0.515466, acc.: 75.78%] [G loss: 0.537846]\n",
      "epoch:8 step:7638 [D loss: 0.586234, acc.: 67.97%] [G loss: 0.530915]\n",
      "epoch:8 step:7639 [D loss: 0.583089, acc.: 64.84%] [G loss: 0.508693]\n",
      "epoch:8 step:7640 [D loss: 0.452920, acc.: 77.34%] [G loss: 0.570885]\n",
      "epoch:8 step:7641 [D loss: 0.663702, acc.: 57.03%] [G loss: 0.661372]\n",
      "epoch:8 step:7642 [D loss: 0.469976, acc.: 76.56%] [G loss: 0.624148]\n",
      "epoch:8 step:7643 [D loss: 0.581956, acc.: 69.53%] [G loss: 0.560923]\n",
      "epoch:8 step:7644 [D loss: 0.515895, acc.: 69.53%] [G loss: 0.552818]\n",
      "epoch:8 step:7645 [D loss: 0.546905, acc.: 67.97%] [G loss: 0.595838]\n",
      "epoch:8 step:7646 [D loss: 0.607181, acc.: 67.97%] [G loss: 0.513621]\n",
      "epoch:8 step:7647 [D loss: 0.528945, acc.: 71.88%] [G loss: 0.557917]\n",
      "epoch:8 step:7648 [D loss: 0.484999, acc.: 78.91%] [G loss: 0.700321]\n",
      "epoch:8 step:7649 [D loss: 0.550619, acc.: 67.97%] [G loss: 0.642273]\n",
      "epoch:8 step:7650 [D loss: 0.545544, acc.: 70.31%] [G loss: 0.559501]\n",
      "epoch:8 step:7651 [D loss: 0.432787, acc.: 83.59%] [G loss: 0.664165]\n",
      "epoch:8 step:7652 [D loss: 0.485435, acc.: 75.78%] [G loss: 0.651756]\n",
      "epoch:8 step:7653 [D loss: 0.559468, acc.: 67.19%] [G loss: 0.567981]\n",
      "epoch:8 step:7654 [D loss: 0.578848, acc.: 68.75%] [G loss: 0.571248]\n",
      "epoch:8 step:7655 [D loss: 0.511727, acc.: 74.22%] [G loss: 0.465516]\n",
      "epoch:8 step:7656 [D loss: 0.608619, acc.: 65.62%] [G loss: 0.576354]\n",
      "epoch:8 step:7657 [D loss: 0.481837, acc.: 79.69%] [G loss: 0.605660]\n",
      "epoch:8 step:7658 [D loss: 0.466813, acc.: 76.56%] [G loss: 0.810684]\n",
      "epoch:8 step:7659 [D loss: 0.571217, acc.: 67.19%] [G loss: 0.609783]\n",
      "epoch:8 step:7660 [D loss: 0.577364, acc.: 67.97%] [G loss: 0.653687]\n",
      "epoch:8 step:7661 [D loss: 0.473205, acc.: 78.91%] [G loss: 0.735720]\n",
      "epoch:8 step:7662 [D loss: 0.534788, acc.: 73.44%] [G loss: 0.568436]\n",
      "epoch:8 step:7663 [D loss: 0.542033, acc.: 71.09%] [G loss: 0.486343]\n",
      "epoch:8 step:7664 [D loss: 0.500955, acc.: 78.12%] [G loss: 0.641559]\n",
      "epoch:8 step:7665 [D loss: 0.575808, acc.: 67.97%] [G loss: 0.462185]\n",
      "epoch:8 step:7666 [D loss: 0.468998, acc.: 74.22%] [G loss: 0.566501]\n",
      "epoch:8 step:7667 [D loss: 0.513295, acc.: 71.88%] [G loss: 0.493912]\n",
      "epoch:8 step:7668 [D loss: 0.496731, acc.: 75.78%] [G loss: 0.705483]\n",
      "epoch:8 step:7669 [D loss: 0.536690, acc.: 70.31%] [G loss: 0.678829]\n",
      "epoch:8 step:7670 [D loss: 0.615762, acc.: 66.41%] [G loss: 0.486337]\n",
      "epoch:8 step:7671 [D loss: 0.608697, acc.: 60.94%] [G loss: 0.508429]\n",
      "epoch:8 step:7672 [D loss: 0.475901, acc.: 79.69%] [G loss: 0.567324]\n",
      "epoch:8 step:7673 [D loss: 0.505528, acc.: 74.22%] [G loss: 0.591181]\n",
      "epoch:8 step:7674 [D loss: 0.594546, acc.: 69.53%] [G loss: 0.568585]\n",
      "epoch:8 step:7675 [D loss: 0.558378, acc.: 71.09%] [G loss: 0.531148]\n",
      "epoch:8 step:7676 [D loss: 0.627342, acc.: 62.50%] [G loss: 0.436751]\n",
      "epoch:8 step:7677 [D loss: 0.563300, acc.: 71.09%] [G loss: 0.593040]\n",
      "epoch:8 step:7678 [D loss: 0.574366, acc.: 74.22%] [G loss: 0.541679]\n",
      "epoch:8 step:7679 [D loss: 0.595302, acc.: 64.06%] [G loss: 0.482057]\n",
      "epoch:8 step:7680 [D loss: 0.572293, acc.: 68.75%] [G loss: 0.497386]\n",
      "epoch:8 step:7681 [D loss: 0.527525, acc.: 71.88%] [G loss: 0.550167]\n",
      "epoch:8 step:7682 [D loss: 0.541356, acc.: 69.53%] [G loss: 0.540133]\n",
      "epoch:8 step:7683 [D loss: 0.614797, acc.: 67.19%] [G loss: 0.581533]\n",
      "epoch:8 step:7684 [D loss: 0.574596, acc.: 67.19%] [G loss: 0.451818]\n",
      "epoch:8 step:7685 [D loss: 0.584370, acc.: 64.84%] [G loss: 0.508865]\n",
      "epoch:8 step:7686 [D loss: 0.497546, acc.: 75.78%] [G loss: 0.738253]\n",
      "epoch:8 step:7687 [D loss: 0.539780, acc.: 73.44%] [G loss: 0.605898]\n",
      "epoch:8 step:7688 [D loss: 0.519558, acc.: 71.09%] [G loss: 0.661424]\n",
      "epoch:8 step:7689 [D loss: 0.577452, acc.: 73.44%] [G loss: 0.600341]\n",
      "epoch:8 step:7690 [D loss: 0.440450, acc.: 79.69%] [G loss: 0.735333]\n",
      "epoch:8 step:7691 [D loss: 0.624780, acc.: 66.41%] [G loss: 0.676171]\n",
      "epoch:8 step:7692 [D loss: 0.543079, acc.: 70.31%] [G loss: 0.648175]\n",
      "epoch:8 step:7693 [D loss: 0.514701, acc.: 73.44%] [G loss: 0.638344]\n",
      "epoch:8 step:7694 [D loss: 0.502261, acc.: 71.88%] [G loss: 0.446367]\n",
      "epoch:8 step:7695 [D loss: 0.508023, acc.: 73.44%] [G loss: 0.714693]\n",
      "epoch:8 step:7696 [D loss: 0.624106, acc.: 61.72%] [G loss: 0.618865]\n",
      "epoch:8 step:7697 [D loss: 0.552468, acc.: 69.53%] [G loss: 0.482220]\n",
      "epoch:8 step:7698 [D loss: 0.546812, acc.: 70.31%] [G loss: 0.625903]\n",
      "epoch:8 step:7699 [D loss: 0.602496, acc.: 67.19%] [G loss: 0.496121]\n",
      "epoch:8 step:7700 [D loss: 0.552327, acc.: 65.62%] [G loss: 0.533238]\n",
      "epoch:8 step:7701 [D loss: 0.515540, acc.: 73.44%] [G loss: 0.613530]\n",
      "epoch:8 step:7702 [D loss: 0.507401, acc.: 75.78%] [G loss: 0.703104]\n",
      "epoch:8 step:7703 [D loss: 0.478095, acc.: 80.47%] [G loss: 0.702361]\n",
      "epoch:8 step:7704 [D loss: 0.445792, acc.: 78.12%] [G loss: 0.657669]\n",
      "epoch:8 step:7705 [D loss: 0.519330, acc.: 71.88%] [G loss: 0.801812]\n",
      "epoch:8 step:7706 [D loss: 0.629774, acc.: 63.28%] [G loss: 0.574791]\n",
      "epoch:8 step:7707 [D loss: 0.639036, acc.: 60.94%] [G loss: 0.545281]\n",
      "epoch:8 step:7708 [D loss: 0.518927, acc.: 75.78%] [G loss: 0.524221]\n",
      "epoch:8 step:7709 [D loss: 0.482327, acc.: 70.31%] [G loss: 0.512775]\n",
      "epoch:8 step:7710 [D loss: 0.624550, acc.: 67.19%] [G loss: 0.577214]\n",
      "epoch:8 step:7711 [D loss: 0.587168, acc.: 64.84%] [G loss: 0.460169]\n",
      "epoch:8 step:7712 [D loss: 0.530414, acc.: 75.78%] [G loss: 0.541097]\n",
      "epoch:8 step:7713 [D loss: 0.516576, acc.: 74.22%] [G loss: 0.582873]\n",
      "epoch:8 step:7714 [D loss: 0.537534, acc.: 77.34%] [G loss: 0.562133]\n",
      "epoch:8 step:7715 [D loss: 0.496489, acc.: 76.56%] [G loss: 0.574556]\n",
      "epoch:8 step:7716 [D loss: 0.684222, acc.: 61.72%] [G loss: 0.502809]\n",
      "epoch:8 step:7717 [D loss: 0.510011, acc.: 76.56%] [G loss: 0.579407]\n",
      "epoch:8 step:7718 [D loss: 0.481976, acc.: 78.12%] [G loss: 0.692924]\n",
      "epoch:8 step:7719 [D loss: 0.493683, acc.: 76.56%] [G loss: 0.501821]\n",
      "epoch:8 step:7720 [D loss: 0.551618, acc.: 67.97%] [G loss: 0.595684]\n",
      "epoch:8 step:7721 [D loss: 0.573829, acc.: 68.75%] [G loss: 0.572163]\n",
      "epoch:8 step:7722 [D loss: 0.584272, acc.: 68.75%] [G loss: 0.615213]\n",
      "epoch:8 step:7723 [D loss: 0.527094, acc.: 71.88%] [G loss: 0.530442]\n",
      "epoch:8 step:7724 [D loss: 0.561429, acc.: 64.06%] [G loss: 0.531258]\n",
      "epoch:8 step:7725 [D loss: 0.530625, acc.: 77.34%] [G loss: 0.506040]\n",
      "epoch:8 step:7726 [D loss: 0.483908, acc.: 81.25%] [G loss: 0.684190]\n",
      "epoch:8 step:7727 [D loss: 0.447901, acc.: 79.69%] [G loss: 0.650100]\n",
      "epoch:8 step:7728 [D loss: 0.512131, acc.: 77.34%] [G loss: 0.913420]\n",
      "epoch:8 step:7729 [D loss: 0.588756, acc.: 71.09%] [G loss: 0.733220]\n",
      "epoch:8 step:7730 [D loss: 0.553969, acc.: 70.31%] [G loss: 0.765409]\n",
      "epoch:8 step:7731 [D loss: 0.581896, acc.: 61.72%] [G loss: 0.821561]\n",
      "epoch:8 step:7732 [D loss: 0.525537, acc.: 73.44%] [G loss: 0.551244]\n",
      "epoch:8 step:7733 [D loss: 0.559148, acc.: 67.19%] [G loss: 0.720385]\n",
      "epoch:8 step:7734 [D loss: 0.545739, acc.: 69.53%] [G loss: 0.538454]\n",
      "epoch:8 step:7735 [D loss: 0.566037, acc.: 66.41%] [G loss: 0.415809]\n",
      "epoch:8 step:7736 [D loss: 0.507379, acc.: 73.44%] [G loss: 0.506030]\n",
      "epoch:8 step:7737 [D loss: 0.550441, acc.: 70.31%] [G loss: 0.534503]\n",
      "epoch:8 step:7738 [D loss: 0.533498, acc.: 71.09%] [G loss: 0.545838]\n",
      "epoch:8 step:7739 [D loss: 0.501856, acc.: 77.34%] [G loss: 0.668811]\n",
      "epoch:8 step:7740 [D loss: 0.521174, acc.: 70.31%] [G loss: 0.570911]\n",
      "epoch:8 step:7741 [D loss: 0.530006, acc.: 70.31%] [G loss: 0.626628]\n",
      "epoch:8 step:7742 [D loss: 0.535979, acc.: 71.88%] [G loss: 0.657622]\n",
      "epoch:8 step:7743 [D loss: 0.563807, acc.: 69.53%] [G loss: 0.658900]\n",
      "epoch:8 step:7744 [D loss: 0.478923, acc.: 75.78%] [G loss: 0.702997]\n",
      "epoch:8 step:7745 [D loss: 0.607975, acc.: 66.41%] [G loss: 0.600753]\n",
      "epoch:8 step:7746 [D loss: 0.585555, acc.: 61.72%] [G loss: 0.508027]\n",
      "epoch:8 step:7747 [D loss: 0.618368, acc.: 64.84%] [G loss: 0.582963]\n",
      "epoch:8 step:7748 [D loss: 0.590964, acc.: 68.75%] [G loss: 0.661031]\n",
      "epoch:8 step:7749 [D loss: 0.571773, acc.: 67.19%] [G loss: 0.648738]\n",
      "epoch:8 step:7750 [D loss: 0.470965, acc.: 75.00%] [G loss: 0.623744]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:8 step:7751 [D loss: 0.545897, acc.: 70.31%] [G loss: 0.498481]\n",
      "epoch:8 step:7752 [D loss: 0.527403, acc.: 69.53%] [G loss: 0.641859]\n",
      "epoch:8 step:7753 [D loss: 0.558165, acc.: 64.84%] [G loss: 0.555459]\n",
      "epoch:8 step:7754 [D loss: 0.539963, acc.: 67.19%] [G loss: 0.551910]\n",
      "epoch:8 step:7755 [D loss: 0.510936, acc.: 71.88%] [G loss: 0.624875]\n",
      "epoch:8 step:7756 [D loss: 0.504018, acc.: 78.12%] [G loss: 0.623087]\n",
      "epoch:8 step:7757 [D loss: 0.528870, acc.: 74.22%] [G loss: 0.542341]\n",
      "epoch:8 step:7758 [D loss: 0.536870, acc.: 69.53%] [G loss: 0.710749]\n",
      "epoch:8 step:7759 [D loss: 0.605827, acc.: 66.41%] [G loss: 0.505213]\n",
      "epoch:8 step:7760 [D loss: 0.503106, acc.: 77.34%] [G loss: 0.701163]\n",
      "epoch:8 step:7761 [D loss: 0.591115, acc.: 68.75%] [G loss: 0.545187]\n",
      "epoch:8 step:7762 [D loss: 0.508321, acc.: 73.44%] [G loss: 0.636783]\n",
      "epoch:8 step:7763 [D loss: 0.596530, acc.: 64.06%] [G loss: 0.456446]\n",
      "epoch:8 step:7764 [D loss: 0.565828, acc.: 70.31%] [G loss: 0.446807]\n",
      "epoch:8 step:7765 [D loss: 0.524062, acc.: 74.22%] [G loss: 0.525330]\n",
      "epoch:8 step:7766 [D loss: 0.524141, acc.: 71.88%] [G loss: 0.556444]\n",
      "epoch:8 step:7767 [D loss: 0.472059, acc.: 78.91%] [G loss: 0.729160]\n",
      "epoch:8 step:7768 [D loss: 0.620481, acc.: 67.19%] [G loss: 0.533220]\n",
      "epoch:8 step:7769 [D loss: 0.525718, acc.: 67.19%] [G loss: 0.676374]\n",
      "epoch:8 step:7770 [D loss: 0.547385, acc.: 74.22%] [G loss: 0.637123]\n",
      "epoch:8 step:7771 [D loss: 0.586011, acc.: 67.97%] [G loss: 0.407519]\n",
      "epoch:8 step:7772 [D loss: 0.504115, acc.: 77.34%] [G loss: 0.487938]\n",
      "epoch:8 step:7773 [D loss: 0.658091, acc.: 62.50%] [G loss: 0.475021]\n",
      "epoch:8 step:7774 [D loss: 0.567806, acc.: 65.62%] [G loss: 0.479614]\n",
      "epoch:8 step:7775 [D loss: 0.507596, acc.: 68.75%] [G loss: 0.638391]\n",
      "epoch:8 step:7776 [D loss: 0.557031, acc.: 67.97%] [G loss: 0.636973]\n",
      "epoch:8 step:7777 [D loss: 0.615785, acc.: 67.97%] [G loss: 0.469489]\n",
      "epoch:8 step:7778 [D loss: 0.593894, acc.: 63.28%] [G loss: 0.494760]\n",
      "epoch:8 step:7779 [D loss: 0.499707, acc.: 78.91%] [G loss: 0.803728]\n",
      "epoch:8 step:7780 [D loss: 0.536953, acc.: 72.66%] [G loss: 0.585052]\n",
      "epoch:8 step:7781 [D loss: 0.524859, acc.: 69.53%] [G loss: 0.570826]\n",
      "epoch:8 step:7782 [D loss: 0.453736, acc.: 78.91%] [G loss: 0.738835]\n",
      "epoch:8 step:7783 [D loss: 0.622919, acc.: 63.28%] [G loss: 0.623194]\n",
      "epoch:8 step:7784 [D loss: 0.606346, acc.: 64.84%] [G loss: 0.497971]\n",
      "epoch:8 step:7785 [D loss: 0.563346, acc.: 71.09%] [G loss: 0.509789]\n",
      "epoch:8 step:7786 [D loss: 0.556362, acc.: 67.19%] [G loss: 0.455442]\n",
      "epoch:8 step:7787 [D loss: 0.552571, acc.: 71.88%] [G loss: 0.510441]\n",
      "epoch:8 step:7788 [D loss: 0.520073, acc.: 75.78%] [G loss: 0.607103]\n",
      "epoch:8 step:7789 [D loss: 0.569268, acc.: 68.75%] [G loss: 0.476514]\n",
      "epoch:8 step:7790 [D loss: 0.578510, acc.: 66.41%] [G loss: 0.520144]\n",
      "epoch:8 step:7791 [D loss: 0.520041, acc.: 75.00%] [G loss: 0.512032]\n",
      "epoch:8 step:7792 [D loss: 0.476620, acc.: 76.56%] [G loss: 0.651370]\n",
      "epoch:8 step:7793 [D loss: 0.531209, acc.: 72.66%] [G loss: 0.621870]\n",
      "epoch:8 step:7794 [D loss: 0.523490, acc.: 74.22%] [G loss: 0.658961]\n",
      "epoch:8 step:7795 [D loss: 0.534290, acc.: 73.44%] [G loss: 0.751690]\n",
      "epoch:8 step:7796 [D loss: 0.502175, acc.: 76.56%] [G loss: 0.644754]\n",
      "epoch:8 step:7797 [D loss: 0.616470, acc.: 64.84%] [G loss: 0.609345]\n",
      "epoch:8 step:7798 [D loss: 0.531875, acc.: 75.00%] [G loss: 0.503093]\n",
      "epoch:8 step:7799 [D loss: 0.519674, acc.: 74.22%] [G loss: 0.599403]\n",
      "epoch:8 step:7800 [D loss: 0.451936, acc.: 82.81%] [G loss: 0.720985]\n",
      "epoch:8 step:7801 [D loss: 0.531391, acc.: 75.00%] [G loss: 0.685724]\n",
      "epoch:8 step:7802 [D loss: 0.545600, acc.: 71.09%] [G loss: 0.668257]\n",
      "epoch:8 step:7803 [D loss: 0.499161, acc.: 73.44%] [G loss: 0.518609]\n",
      "epoch:8 step:7804 [D loss: 0.543828, acc.: 65.62%] [G loss: 0.650077]\n",
      "epoch:8 step:7805 [D loss: 0.460457, acc.: 77.34%] [G loss: 0.607824]\n",
      "epoch:8 step:7806 [D loss: 0.485086, acc.: 76.56%] [G loss: 0.718904]\n",
      "epoch:8 step:7807 [D loss: 0.473703, acc.: 75.78%] [G loss: 0.580596]\n",
      "epoch:8 step:7808 [D loss: 0.521360, acc.: 73.44%] [G loss: 0.905608]\n",
      "epoch:8 step:7809 [D loss: 0.508459, acc.: 73.44%] [G loss: 0.946712]\n",
      "epoch:8 step:7810 [D loss: 0.510259, acc.: 76.56%] [G loss: 0.834561]\n",
      "epoch:8 step:7811 [D loss: 0.460293, acc.: 81.25%] [G loss: 0.865210]\n",
      "epoch:8 step:7812 [D loss: 0.657531, acc.: 63.28%] [G loss: 0.651415]\n",
      "epoch:8 step:7813 [D loss: 0.581963, acc.: 71.88%] [G loss: 0.460644]\n",
      "epoch:8 step:7814 [D loss: 0.530595, acc.: 67.19%] [G loss: 0.543272]\n",
      "epoch:8 step:7815 [D loss: 0.633372, acc.: 64.06%] [G loss: 0.605123]\n",
      "epoch:8 step:7816 [D loss: 0.539904, acc.: 68.75%] [G loss: 0.579400]\n",
      "epoch:8 step:7817 [D loss: 0.476079, acc.: 81.25%] [G loss: 0.569093]\n",
      "epoch:8 step:7818 [D loss: 0.571034, acc.: 70.31%] [G loss: 0.578563]\n",
      "epoch:8 step:7819 [D loss: 0.651615, acc.: 64.84%] [G loss: 0.495287]\n",
      "epoch:8 step:7820 [D loss: 0.558819, acc.: 69.53%] [G loss: 0.419828]\n",
      "epoch:8 step:7821 [D loss: 0.570156, acc.: 70.31%] [G loss: 0.519340]\n",
      "epoch:8 step:7822 [D loss: 0.507676, acc.: 71.88%] [G loss: 0.626753]\n",
      "epoch:8 step:7823 [D loss: 0.558886, acc.: 71.88%] [G loss: 0.612925]\n",
      "epoch:8 step:7824 [D loss: 0.503326, acc.: 75.78%] [G loss: 0.768584]\n",
      "epoch:8 step:7825 [D loss: 0.501048, acc.: 74.22%] [G loss: 0.669094]\n",
      "epoch:8 step:7826 [D loss: 0.533721, acc.: 71.09%] [G loss: 0.618570]\n",
      "epoch:8 step:7827 [D loss: 0.558255, acc.: 71.09%] [G loss: 0.448912]\n",
      "epoch:8 step:7828 [D loss: 0.467363, acc.: 78.12%] [G loss: 0.504783]\n",
      "epoch:8 step:7829 [D loss: 0.519692, acc.: 75.00%] [G loss: 0.680683]\n",
      "epoch:8 step:7830 [D loss: 0.527097, acc.: 72.66%] [G loss: 0.582637]\n",
      "epoch:8 step:7831 [D loss: 0.518321, acc.: 74.22%] [G loss: 0.640820]\n",
      "epoch:8 step:7832 [D loss: 0.506351, acc.: 73.44%] [G loss: 0.712509]\n",
      "epoch:8 step:7833 [D loss: 0.526648, acc.: 72.66%] [G loss: 0.562630]\n",
      "epoch:8 step:7834 [D loss: 0.511896, acc.: 72.66%] [G loss: 0.607368]\n",
      "epoch:8 step:7835 [D loss: 0.511461, acc.: 74.22%] [G loss: 0.610994]\n",
      "epoch:8 step:7836 [D loss: 0.487346, acc.: 76.56%] [G loss: 0.720159]\n",
      "epoch:8 step:7837 [D loss: 0.554994, acc.: 74.22%] [G loss: 0.615504]\n",
      "epoch:8 step:7838 [D loss: 0.623149, acc.: 64.06%] [G loss: 0.611934]\n",
      "epoch:8 step:7839 [D loss: 0.477945, acc.: 74.22%] [G loss: 0.698400]\n",
      "epoch:8 step:7840 [D loss: 0.463991, acc.: 80.47%] [G loss: 0.831576]\n",
      "epoch:8 step:7841 [D loss: 0.577127, acc.: 67.19%] [G loss: 0.761326]\n",
      "epoch:8 step:7842 [D loss: 0.518590, acc.: 72.66%] [G loss: 0.853770]\n",
      "epoch:8 step:7843 [D loss: 0.477566, acc.: 77.34%] [G loss: 0.809893]\n",
      "epoch:8 step:7844 [D loss: 0.589646, acc.: 75.78%] [G loss: 0.651093]\n",
      "epoch:8 step:7845 [D loss: 0.684001, acc.: 58.59%] [G loss: 0.502949]\n",
      "epoch:8 step:7846 [D loss: 0.500485, acc.: 77.34%] [G loss: 0.638968]\n",
      "epoch:8 step:7847 [D loss: 0.522246, acc.: 72.66%] [G loss: 0.682636]\n",
      "epoch:8 step:7848 [D loss: 0.571048, acc.: 67.97%] [G loss: 0.658097]\n",
      "epoch:8 step:7849 [D loss: 0.544134, acc.: 71.09%] [G loss: 0.649180]\n",
      "epoch:8 step:7850 [D loss: 0.417172, acc.: 83.59%] [G loss: 0.750505]\n",
      "epoch:8 step:7851 [D loss: 0.532636, acc.: 71.88%] [G loss: 0.772010]\n",
      "epoch:8 step:7852 [D loss: 0.555450, acc.: 71.09%] [G loss: 0.744641]\n",
      "epoch:8 step:7853 [D loss: 0.455974, acc.: 75.00%] [G loss: 0.696902]\n",
      "epoch:8 step:7854 [D loss: 0.405784, acc.: 82.81%] [G loss: 0.772423]\n",
      "epoch:8 step:7855 [D loss: 0.481196, acc.: 77.34%] [G loss: 0.639876]\n",
      "epoch:8 step:7856 [D loss: 0.532004, acc.: 69.53%] [G loss: 0.823504]\n",
      "epoch:8 step:7857 [D loss: 0.509563, acc.: 72.66%] [G loss: 0.787052]\n",
      "epoch:8 step:7858 [D loss: 0.568564, acc.: 64.84%] [G loss: 0.496966]\n",
      "epoch:8 step:7859 [D loss: 0.508685, acc.: 75.78%] [G loss: 0.522627]\n",
      "epoch:8 step:7860 [D loss: 0.495901, acc.: 78.12%] [G loss: 0.530605]\n",
      "epoch:8 step:7861 [D loss: 0.549639, acc.: 70.31%] [G loss: 0.581548]\n",
      "epoch:8 step:7862 [D loss: 0.473675, acc.: 78.12%] [G loss: 0.616381]\n",
      "epoch:8 step:7863 [D loss: 0.569489, acc.: 66.41%] [G loss: 0.632732]\n",
      "epoch:8 step:7864 [D loss: 0.502689, acc.: 73.44%] [G loss: 0.602835]\n",
      "epoch:8 step:7865 [D loss: 0.538763, acc.: 70.31%] [G loss: 0.622720]\n",
      "epoch:8 step:7866 [D loss: 0.498964, acc.: 79.69%] [G loss: 0.647065]\n",
      "epoch:8 step:7867 [D loss: 0.470681, acc.: 79.69%] [G loss: 0.735627]\n",
      "epoch:8 step:7868 [D loss: 0.565291, acc.: 70.31%] [G loss: 0.639285]\n",
      "epoch:8 step:7869 [D loss: 0.617271, acc.: 64.06%] [G loss: 0.716024]\n",
      "epoch:8 step:7870 [D loss: 0.497077, acc.: 73.44%] [G loss: 0.628109]\n",
      "epoch:8 step:7871 [D loss: 0.579118, acc.: 70.31%] [G loss: 0.711849]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:8 step:7872 [D loss: 0.758977, acc.: 56.25%] [G loss: 0.357280]\n",
      "epoch:8 step:7873 [D loss: 0.637885, acc.: 57.81%] [G loss: 0.430293]\n",
      "epoch:8 step:7874 [D loss: 0.519045, acc.: 74.22%] [G loss: 0.527338]\n",
      "epoch:8 step:7875 [D loss: 0.591234, acc.: 68.75%] [G loss: 0.531918]\n",
      "epoch:8 step:7876 [D loss: 0.585090, acc.: 70.31%] [G loss: 0.574023]\n",
      "epoch:8 step:7877 [D loss: 0.484358, acc.: 75.78%] [G loss: 0.557215]\n",
      "epoch:8 step:7878 [D loss: 0.574125, acc.: 66.41%] [G loss: 0.530687]\n",
      "epoch:8 step:7879 [D loss: 0.565803, acc.: 70.31%] [G loss: 0.502535]\n",
      "epoch:8 step:7880 [D loss: 0.552701, acc.: 68.75%] [G loss: 0.624764]\n",
      "epoch:8 step:7881 [D loss: 0.494622, acc.: 72.66%] [G loss: 0.681238]\n",
      "epoch:8 step:7882 [D loss: 0.583576, acc.: 67.19%] [G loss: 0.588356]\n",
      "epoch:8 step:7883 [D loss: 0.618795, acc.: 67.19%] [G loss: 0.480308]\n",
      "epoch:8 step:7884 [D loss: 0.557349, acc.: 73.44%] [G loss: 0.643039]\n",
      "epoch:8 step:7885 [D loss: 0.579902, acc.: 64.84%] [G loss: 0.646256]\n",
      "epoch:8 step:7886 [D loss: 0.548368, acc.: 71.88%] [G loss: 0.485457]\n",
      "epoch:8 step:7887 [D loss: 0.538519, acc.: 75.00%] [G loss: 0.481102]\n",
      "epoch:8 step:7888 [D loss: 0.490676, acc.: 78.12%] [G loss: 0.691560]\n",
      "epoch:8 step:7889 [D loss: 0.594921, acc.: 67.19%] [G loss: 0.556247]\n",
      "epoch:8 step:7890 [D loss: 0.600668, acc.: 63.28%] [G loss: 0.595076]\n",
      "epoch:8 step:7891 [D loss: 0.481664, acc.: 78.91%] [G loss: 0.556857]\n",
      "epoch:8 step:7892 [D loss: 0.564054, acc.: 67.97%] [G loss: 0.557506]\n",
      "epoch:8 step:7893 [D loss: 0.591159, acc.: 62.50%] [G loss: 0.525497]\n",
      "epoch:8 step:7894 [D loss: 0.430187, acc.: 81.25%] [G loss: 0.663012]\n",
      "epoch:8 step:7895 [D loss: 0.504153, acc.: 76.56%] [G loss: 0.620109]\n",
      "epoch:8 step:7896 [D loss: 0.642920, acc.: 61.72%] [G loss: 0.550655]\n",
      "epoch:8 step:7897 [D loss: 0.647207, acc.: 58.59%] [G loss: 0.435348]\n",
      "epoch:8 step:7898 [D loss: 0.482200, acc.: 79.69%] [G loss: 0.619136]\n",
      "epoch:8 step:7899 [D loss: 0.495715, acc.: 74.22%] [G loss: 0.804681]\n",
      "epoch:8 step:7900 [D loss: 0.585135, acc.: 69.53%] [G loss: 0.614823]\n",
      "epoch:8 step:7901 [D loss: 0.521429, acc.: 74.22%] [G loss: 0.689930]\n",
      "epoch:8 step:7902 [D loss: 0.464370, acc.: 80.47%] [G loss: 0.809142]\n",
      "epoch:8 step:7903 [D loss: 0.591310, acc.: 67.19%] [G loss: 0.560060]\n",
      "epoch:8 step:7904 [D loss: 0.589406, acc.: 63.28%] [G loss: 0.617548]\n",
      "epoch:8 step:7905 [D loss: 0.547484, acc.: 67.19%] [G loss: 0.618294]\n",
      "epoch:8 step:7906 [D loss: 0.568494, acc.: 67.97%] [G loss: 0.524643]\n",
      "epoch:8 step:7907 [D loss: 0.567656, acc.: 67.19%] [G loss: 0.511549]\n",
      "epoch:8 step:7908 [D loss: 0.545482, acc.: 71.09%] [G loss: 0.514251]\n",
      "epoch:8 step:7909 [D loss: 0.555568, acc.: 72.66%] [G loss: 0.460098]\n",
      "epoch:8 step:7910 [D loss: 0.524728, acc.: 73.44%] [G loss: 0.556069]\n",
      "epoch:8 step:7911 [D loss: 0.599278, acc.: 63.28%] [G loss: 0.571080]\n",
      "epoch:8 step:7912 [D loss: 0.482126, acc.: 77.34%] [G loss: 0.828513]\n",
      "epoch:8 step:7913 [D loss: 0.643245, acc.: 67.19%] [G loss: 0.613556]\n",
      "epoch:8 step:7914 [D loss: 0.660047, acc.: 61.72%] [G loss: 0.463758]\n",
      "epoch:8 step:7915 [D loss: 0.543690, acc.: 71.09%] [G loss: 0.518059]\n",
      "epoch:8 step:7916 [D loss: 0.614028, acc.: 64.84%] [G loss: 0.521683]\n",
      "epoch:8 step:7917 [D loss: 0.551095, acc.: 71.88%] [G loss: 0.525333]\n",
      "epoch:8 step:7918 [D loss: 0.560099, acc.: 71.09%] [G loss: 0.501431]\n",
      "epoch:8 step:7919 [D loss: 0.506201, acc.: 74.22%] [G loss: 0.535821]\n",
      "epoch:8 step:7920 [D loss: 0.553518, acc.: 75.00%] [G loss: 0.660057]\n",
      "epoch:8 step:7921 [D loss: 0.467918, acc.: 79.69%] [G loss: 0.725127]\n",
      "epoch:8 step:7922 [D loss: 0.456675, acc.: 75.00%] [G loss: 0.746761]\n",
      "epoch:8 step:7923 [D loss: 0.477755, acc.: 74.22%] [G loss: 0.707095]\n",
      "epoch:8 step:7924 [D loss: 0.500463, acc.: 75.78%] [G loss: 0.715263]\n",
      "epoch:8 step:7925 [D loss: 0.532720, acc.: 72.66%] [G loss: 0.928426]\n",
      "epoch:8 step:7926 [D loss: 0.507156, acc.: 75.78%] [G loss: 0.885328]\n",
      "epoch:8 step:7927 [D loss: 0.511714, acc.: 72.66%] [G loss: 0.719797]\n",
      "epoch:8 step:7928 [D loss: 0.577575, acc.: 67.19%] [G loss: 0.686820]\n",
      "epoch:8 step:7929 [D loss: 0.603331, acc.: 65.62%] [G loss: 0.442317]\n",
      "epoch:8 step:7930 [D loss: 0.524441, acc.: 71.88%] [G loss: 0.593543]\n",
      "epoch:8 step:7931 [D loss: 0.551337, acc.: 73.44%] [G loss: 0.526910]\n",
      "epoch:8 step:7932 [D loss: 0.496541, acc.: 75.78%] [G loss: 0.671527]\n",
      "epoch:8 step:7933 [D loss: 0.695419, acc.: 67.19%] [G loss: 0.630304]\n",
      "epoch:8 step:7934 [D loss: 0.617086, acc.: 61.72%] [G loss: 0.484318]\n",
      "epoch:8 step:7935 [D loss: 0.517807, acc.: 71.88%] [G loss: 0.606574]\n",
      "epoch:8 step:7936 [D loss: 0.496170, acc.: 70.31%] [G loss: 0.801225]\n",
      "epoch:8 step:7937 [D loss: 0.507790, acc.: 68.75%] [G loss: 0.750420]\n",
      "epoch:8 step:7938 [D loss: 0.515643, acc.: 75.00%] [G loss: 0.698351]\n",
      "epoch:8 step:7939 [D loss: 0.480307, acc.: 78.91%] [G loss: 0.651562]\n",
      "epoch:8 step:7940 [D loss: 0.528523, acc.: 75.00%] [G loss: 0.588345]\n",
      "epoch:8 step:7941 [D loss: 0.570787, acc.: 69.53%] [G loss: 0.661035]\n",
      "epoch:8 step:7942 [D loss: 0.566767, acc.: 68.75%] [G loss: 0.589483]\n",
      "epoch:8 step:7943 [D loss: 0.496454, acc.: 73.44%] [G loss: 0.722793]\n",
      "epoch:8 step:7944 [D loss: 0.569471, acc.: 69.53%] [G loss: 0.655507]\n",
      "epoch:8 step:7945 [D loss: 0.467665, acc.: 77.34%] [G loss: 0.673326]\n",
      "epoch:8 step:7946 [D loss: 0.505306, acc.: 72.66%] [G loss: 0.783716]\n",
      "epoch:8 step:7947 [D loss: 0.398167, acc.: 87.50%] [G loss: 0.803649]\n",
      "epoch:8 step:7948 [D loss: 0.478261, acc.: 78.91%] [G loss: 0.700490]\n",
      "epoch:8 step:7949 [D loss: 0.535912, acc.: 75.00%] [G loss: 0.624757]\n",
      "epoch:8 step:7950 [D loss: 0.579663, acc.: 68.75%] [G loss: 0.593086]\n",
      "epoch:8 step:7951 [D loss: 0.542150, acc.: 71.09%] [G loss: 0.555810]\n",
      "epoch:8 step:7952 [D loss: 0.644576, acc.: 60.16%] [G loss: 0.490647]\n",
      "epoch:8 step:7953 [D loss: 0.509387, acc.: 76.56%] [G loss: 0.609893]\n",
      "epoch:8 step:7954 [D loss: 0.644834, acc.: 64.06%] [G loss: 0.498961]\n",
      "epoch:8 step:7955 [D loss: 0.567671, acc.: 71.09%] [G loss: 0.525647]\n",
      "epoch:8 step:7956 [D loss: 0.530600, acc.: 69.53%] [G loss: 0.554799]\n",
      "epoch:8 step:7957 [D loss: 0.533076, acc.: 69.53%] [G loss: 0.698573]\n",
      "epoch:8 step:7958 [D loss: 0.625083, acc.: 57.81%] [G loss: 0.576088]\n",
      "epoch:8 step:7959 [D loss: 0.550187, acc.: 66.41%] [G loss: 0.526196]\n",
      "epoch:8 step:7960 [D loss: 0.565092, acc.: 67.19%] [G loss: 0.548756]\n",
      "epoch:8 step:7961 [D loss: 0.667742, acc.: 58.59%] [G loss: 0.519814]\n",
      "epoch:8 step:7962 [D loss: 0.497313, acc.: 75.00%] [G loss: 0.677942]\n",
      "epoch:8 step:7963 [D loss: 0.536973, acc.: 68.75%] [G loss: 0.544300]\n",
      "epoch:8 step:7964 [D loss: 0.586236, acc.: 63.28%] [G loss: 0.613513]\n",
      "epoch:8 step:7965 [D loss: 0.538654, acc.: 71.09%] [G loss: 0.593806]\n",
      "epoch:8 step:7966 [D loss: 0.502745, acc.: 77.34%] [G loss: 0.682234]\n",
      "epoch:8 step:7967 [D loss: 0.456313, acc.: 82.03%] [G loss: 0.696841]\n",
      "epoch:8 step:7968 [D loss: 0.416026, acc.: 82.03%] [G loss: 0.955800]\n",
      "epoch:8 step:7969 [D loss: 0.645043, acc.: 62.50%] [G loss: 0.502221]\n",
      "epoch:8 step:7970 [D loss: 0.560449, acc.: 70.31%] [G loss: 0.564703]\n",
      "epoch:8 step:7971 [D loss: 0.465656, acc.: 78.91%] [G loss: 0.607271]\n",
      "epoch:8 step:7972 [D loss: 0.576419, acc.: 74.22%] [G loss: 0.557060]\n",
      "epoch:8 step:7973 [D loss: 0.671327, acc.: 62.50%] [G loss: 0.424212]\n",
      "epoch:8 step:7974 [D loss: 0.585821, acc.: 67.19%] [G loss: 0.429318]\n",
      "epoch:8 step:7975 [D loss: 0.499908, acc.: 75.00%] [G loss: 0.544207]\n",
      "epoch:8 step:7976 [D loss: 0.634325, acc.: 64.84%] [G loss: 0.465767]\n",
      "epoch:8 step:7977 [D loss: 0.524597, acc.: 78.91%] [G loss: 0.565029]\n",
      "epoch:8 step:7978 [D loss: 0.616465, acc.: 65.62%] [G loss: 0.451919]\n",
      "epoch:8 step:7979 [D loss: 0.537874, acc.: 67.19%] [G loss: 0.653429]\n",
      "epoch:8 step:7980 [D loss: 0.495346, acc.: 77.34%] [G loss: 0.609969]\n",
      "epoch:8 step:7981 [D loss: 0.532068, acc.: 72.66%] [G loss: 0.689754]\n",
      "epoch:8 step:7982 [D loss: 0.553097, acc.: 70.31%] [G loss: 0.564394]\n",
      "epoch:8 step:7983 [D loss: 0.540303, acc.: 70.31%] [G loss: 0.604300]\n",
      "epoch:8 step:7984 [D loss: 0.464057, acc.: 75.00%] [G loss: 0.663336]\n",
      "epoch:8 step:7985 [D loss: 0.596401, acc.: 68.75%] [G loss: 0.466556]\n",
      "epoch:8 step:7986 [D loss: 0.527820, acc.: 75.78%] [G loss: 0.551123]\n",
      "epoch:8 step:7987 [D loss: 0.577909, acc.: 70.31%] [G loss: 0.590821]\n",
      "epoch:8 step:7988 [D loss: 0.577944, acc.: 67.97%] [G loss: 0.567728]\n",
      "epoch:8 step:7989 [D loss: 0.518851, acc.: 75.78%] [G loss: 0.664386]\n",
      "epoch:8 step:7990 [D loss: 0.562123, acc.: 64.84%] [G loss: 0.535208]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:8 step:7991 [D loss: 0.512020, acc.: 75.78%] [G loss: 0.510938]\n",
      "epoch:8 step:7992 [D loss: 0.536122, acc.: 75.78%] [G loss: 0.606639]\n",
      "epoch:8 step:7993 [D loss: 0.568355, acc.: 66.41%] [G loss: 0.643748]\n",
      "epoch:8 step:7994 [D loss: 0.518299, acc.: 76.56%] [G loss: 0.710163]\n",
      "epoch:8 step:7995 [D loss: 0.457211, acc.: 83.59%] [G loss: 0.888364]\n",
      "epoch:8 step:7996 [D loss: 0.579336, acc.: 67.97%] [G loss: 0.630363]\n",
      "epoch:8 step:7997 [D loss: 0.660558, acc.: 64.84%] [G loss: 0.474586]\n",
      "epoch:8 step:7998 [D loss: 0.592274, acc.: 62.50%] [G loss: 0.470233]\n",
      "epoch:8 step:7999 [D loss: 0.507140, acc.: 70.31%] [G loss: 0.571905]\n",
      "epoch:8 step:8000 [D loss: 0.473783, acc.: 78.91%] [G loss: 0.594805]\n",
      "epoch:8 step:8001 [D loss: 0.516875, acc.: 80.47%] [G loss: 0.543333]\n",
      "epoch:8 step:8002 [D loss: 0.519711, acc.: 71.09%] [G loss: 0.720627]\n",
      "epoch:8 step:8003 [D loss: 0.541469, acc.: 77.34%] [G loss: 0.739730]\n",
      "epoch:8 step:8004 [D loss: 0.489943, acc.: 75.78%] [G loss: 0.713271]\n",
      "epoch:8 step:8005 [D loss: 0.513539, acc.: 73.44%] [G loss: 0.610654]\n",
      "epoch:8 step:8006 [D loss: 0.572073, acc.: 67.19%] [G loss: 0.557541]\n",
      "epoch:8 step:8007 [D loss: 0.650323, acc.: 58.59%] [G loss: 0.566828]\n",
      "epoch:8 step:8008 [D loss: 0.556237, acc.: 68.75%] [G loss: 0.518158]\n",
      "epoch:8 step:8009 [D loss: 0.566753, acc.: 68.75%] [G loss: 0.687683]\n",
      "epoch:8 step:8010 [D loss: 0.499604, acc.: 73.44%] [G loss: 0.591958]\n",
      "epoch:8 step:8011 [D loss: 0.538744, acc.: 71.88%] [G loss: 0.696745]\n",
      "epoch:8 step:8012 [D loss: 0.493318, acc.: 78.91%] [G loss: 0.924839]\n",
      "epoch:8 step:8013 [D loss: 0.594398, acc.: 67.19%] [G loss: 0.572469]\n",
      "epoch:8 step:8014 [D loss: 0.493578, acc.: 75.00%] [G loss: 0.660460]\n",
      "epoch:8 step:8015 [D loss: 0.455150, acc.: 78.91%] [G loss: 0.665990]\n",
      "epoch:8 step:8016 [D loss: 0.472524, acc.: 76.56%] [G loss: 0.698050]\n",
      "epoch:8 step:8017 [D loss: 0.493045, acc.: 82.03%] [G loss: 0.728616]\n",
      "epoch:8 step:8018 [D loss: 0.533615, acc.: 67.97%] [G loss: 0.642256]\n",
      "epoch:8 step:8019 [D loss: 0.519727, acc.: 75.78%] [G loss: 0.684755]\n",
      "epoch:8 step:8020 [D loss: 0.575575, acc.: 67.97%] [G loss: 0.651211]\n",
      "epoch:8 step:8021 [D loss: 0.577831, acc.: 64.06%] [G loss: 0.663586]\n",
      "epoch:8 step:8022 [D loss: 0.504787, acc.: 75.00%] [G loss: 0.812405]\n",
      "epoch:8 step:8023 [D loss: 0.588965, acc.: 64.84%] [G loss: 0.613880]\n",
      "epoch:8 step:8024 [D loss: 0.643063, acc.: 60.16%] [G loss: 0.627558]\n",
      "epoch:8 step:8025 [D loss: 0.600880, acc.: 64.84%] [G loss: 0.498928]\n",
      "epoch:8 step:8026 [D loss: 0.527376, acc.: 75.78%] [G loss: 0.595300]\n",
      "epoch:8 step:8027 [D loss: 0.516414, acc.: 75.78%] [G loss: 0.672967]\n",
      "epoch:8 step:8028 [D loss: 0.626351, acc.: 63.28%] [G loss: 0.507212]\n",
      "epoch:8 step:8029 [D loss: 0.532816, acc.: 70.31%] [G loss: 0.509388]\n",
      "epoch:8 step:8030 [D loss: 0.538549, acc.: 75.00%] [G loss: 0.586282]\n",
      "epoch:8 step:8031 [D loss: 0.612108, acc.: 64.06%] [G loss: 0.445274]\n",
      "epoch:8 step:8032 [D loss: 0.470993, acc.: 79.69%] [G loss: 0.512457]\n",
      "epoch:8 step:8033 [D loss: 0.559089, acc.: 72.66%] [G loss: 0.633731]\n",
      "epoch:8 step:8034 [D loss: 0.625050, acc.: 62.50%] [G loss: 0.457548]\n",
      "epoch:8 step:8035 [D loss: 0.626490, acc.: 62.50%] [G loss: 0.571757]\n",
      "epoch:8 step:8036 [D loss: 0.568947, acc.: 64.84%] [G loss: 0.478615]\n",
      "epoch:8 step:8037 [D loss: 0.538924, acc.: 68.75%] [G loss: 0.508231]\n",
      "epoch:8 step:8038 [D loss: 0.589215, acc.: 70.31%] [G loss: 0.466598]\n",
      "epoch:8 step:8039 [D loss: 0.557610, acc.: 67.97%] [G loss: 0.633993]\n",
      "epoch:8 step:8040 [D loss: 0.573434, acc.: 70.31%] [G loss: 0.563770]\n",
      "epoch:8 step:8041 [D loss: 0.514734, acc.: 74.22%] [G loss: 0.646286]\n",
      "epoch:8 step:8042 [D loss: 0.511932, acc.: 71.88%] [G loss: 0.634377]\n",
      "epoch:8 step:8043 [D loss: 0.498727, acc.: 76.56%] [G loss: 0.653846]\n",
      "epoch:8 step:8044 [D loss: 0.478071, acc.: 75.00%] [G loss: 0.716079]\n",
      "epoch:8 step:8045 [D loss: 0.517141, acc.: 71.88%] [G loss: 0.651496]\n",
      "epoch:8 step:8046 [D loss: 0.552895, acc.: 70.31%] [G loss: 0.573403]\n",
      "epoch:8 step:8047 [D loss: 0.525017, acc.: 73.44%] [G loss: 0.548847]\n",
      "epoch:8 step:8048 [D loss: 0.456575, acc.: 80.47%] [G loss: 0.591557]\n",
      "epoch:8 step:8049 [D loss: 0.538646, acc.: 71.09%] [G loss: 0.517565]\n",
      "epoch:8 step:8050 [D loss: 0.484161, acc.: 74.22%] [G loss: 0.699188]\n",
      "epoch:8 step:8051 [D loss: 0.472300, acc.: 78.91%] [G loss: 0.743561]\n",
      "epoch:8 step:8052 [D loss: 0.526511, acc.: 72.66%] [G loss: 0.790253]\n",
      "epoch:8 step:8053 [D loss: 0.508906, acc.: 75.78%] [G loss: 0.664448]\n",
      "epoch:8 step:8054 [D loss: 0.492866, acc.: 76.56%] [G loss: 0.658278]\n",
      "epoch:8 step:8055 [D loss: 0.593243, acc.: 67.97%] [G loss: 0.736319]\n",
      "epoch:8 step:8056 [D loss: 0.588789, acc.: 64.84%] [G loss: 0.538433]\n",
      "epoch:8 step:8057 [D loss: 0.492774, acc.: 78.12%] [G loss: 0.557794]\n",
      "epoch:8 step:8058 [D loss: 0.567549, acc.: 67.97%] [G loss: 0.496328]\n",
      "epoch:8 step:8059 [D loss: 0.539806, acc.: 69.53%] [G loss: 0.549950]\n",
      "epoch:8 step:8060 [D loss: 0.514381, acc.: 69.53%] [G loss: 0.756687]\n",
      "epoch:8 step:8061 [D loss: 0.616767, acc.: 68.75%] [G loss: 0.694278]\n",
      "epoch:8 step:8062 [D loss: 0.676257, acc.: 64.06%] [G loss: 0.651503]\n",
      "epoch:8 step:8063 [D loss: 0.500228, acc.: 75.78%] [G loss: 0.584804]\n",
      "epoch:8 step:8064 [D loss: 0.509136, acc.: 68.75%] [G loss: 0.561550]\n",
      "epoch:8 step:8065 [D loss: 0.505958, acc.: 77.34%] [G loss: 0.543751]\n",
      "epoch:8 step:8066 [D loss: 0.604860, acc.: 62.50%] [G loss: 0.528972]\n",
      "epoch:8 step:8067 [D loss: 0.602123, acc.: 67.97%] [G loss: 0.525159]\n",
      "epoch:8 step:8068 [D loss: 0.573667, acc.: 67.19%] [G loss: 0.682422]\n",
      "epoch:8 step:8069 [D loss: 0.523660, acc.: 74.22%] [G loss: 0.606193]\n",
      "epoch:8 step:8070 [D loss: 0.502782, acc.: 75.78%] [G loss: 0.634238]\n",
      "epoch:8 step:8071 [D loss: 0.524989, acc.: 73.44%] [G loss: 0.884560]\n",
      "epoch:8 step:8072 [D loss: 0.583655, acc.: 67.97%] [G loss: 0.619777]\n",
      "epoch:8 step:8073 [D loss: 0.565157, acc.: 71.88%] [G loss: 0.556286]\n",
      "epoch:8 step:8074 [D loss: 0.572926, acc.: 65.62%] [G loss: 0.637251]\n",
      "epoch:8 step:8075 [D loss: 0.486454, acc.: 71.09%] [G loss: 0.689772]\n",
      "epoch:8 step:8076 [D loss: 0.541814, acc.: 71.88%] [G loss: 0.636709]\n",
      "epoch:8 step:8077 [D loss: 0.553529, acc.: 72.66%] [G loss: 0.520286]\n",
      "epoch:8 step:8078 [D loss: 0.441501, acc.: 78.91%] [G loss: 0.734095]\n",
      "epoch:8 step:8079 [D loss: 0.560929, acc.: 72.66%] [G loss: 0.742637]\n",
      "epoch:8 step:8080 [D loss: 0.698778, acc.: 56.25%] [G loss: 0.490638]\n",
      "epoch:8 step:8081 [D loss: 0.586224, acc.: 67.19%] [G loss: 0.513712]\n",
      "epoch:8 step:8082 [D loss: 0.587216, acc.: 67.19%] [G loss: 0.594644]\n",
      "epoch:8 step:8083 [D loss: 0.592215, acc.: 63.28%] [G loss: 0.517417]\n",
      "epoch:8 step:8084 [D loss: 0.587824, acc.: 67.97%] [G loss: 0.655149]\n",
      "epoch:8 step:8085 [D loss: 0.515680, acc.: 67.97%] [G loss: 0.685155]\n",
      "epoch:8 step:8086 [D loss: 0.627214, acc.: 63.28%] [G loss: 0.616816]\n",
      "epoch:8 step:8087 [D loss: 0.611137, acc.: 61.72%] [G loss: 0.550576]\n",
      "epoch:8 step:8088 [D loss: 0.530426, acc.: 69.53%] [G loss: 0.489997]\n",
      "epoch:8 step:8089 [D loss: 0.519800, acc.: 78.91%] [G loss: 0.556994]\n",
      "epoch:8 step:8090 [D loss: 0.548082, acc.: 75.00%] [G loss: 0.460781]\n",
      "epoch:8 step:8091 [D loss: 0.537802, acc.: 71.09%] [G loss: 0.429470]\n",
      "epoch:8 step:8092 [D loss: 0.498890, acc.: 75.78%] [G loss: 0.627871]\n",
      "epoch:8 step:8093 [D loss: 0.531443, acc.: 72.66%] [G loss: 0.614322]\n",
      "epoch:8 step:8094 [D loss: 0.487797, acc.: 76.56%] [G loss: 0.596070]\n",
      "epoch:8 step:8095 [D loss: 0.529133, acc.: 74.22%] [G loss: 0.671811]\n",
      "epoch:8 step:8096 [D loss: 0.627297, acc.: 61.72%] [G loss: 0.521184]\n",
      "epoch:8 step:8097 [D loss: 0.498872, acc.: 75.00%] [G loss: 0.675009]\n",
      "epoch:8 step:8098 [D loss: 0.497751, acc.: 75.00%] [G loss: 0.598096]\n",
      "epoch:8 step:8099 [D loss: 0.486862, acc.: 75.78%] [G loss: 0.613481]\n",
      "epoch:8 step:8100 [D loss: 0.594931, acc.: 66.41%] [G loss: 0.702081]\n",
      "epoch:8 step:8101 [D loss: 0.474587, acc.: 77.34%] [G loss: 0.609800]\n",
      "epoch:8 step:8102 [D loss: 0.593255, acc.: 67.97%] [G loss: 0.467365]\n",
      "epoch:8 step:8103 [D loss: 0.525386, acc.: 71.09%] [G loss: 0.656784]\n",
      "epoch:8 step:8104 [D loss: 0.595021, acc.: 67.97%] [G loss: 0.473438]\n",
      "epoch:8 step:8105 [D loss: 0.528653, acc.: 70.31%] [G loss: 0.475643]\n",
      "epoch:8 step:8106 [D loss: 0.535361, acc.: 67.19%] [G loss: 0.537433]\n",
      "epoch:8 step:8107 [D loss: 0.512584, acc.: 75.78%] [G loss: 0.474152]\n",
      "epoch:8 step:8108 [D loss: 0.608647, acc.: 67.19%] [G loss: 0.546499]\n",
      "epoch:8 step:8109 [D loss: 0.538433, acc.: 70.31%] [G loss: 0.579056]\n",
      "epoch:8 step:8110 [D loss: 0.549965, acc.: 66.41%] [G loss: 0.483992]\n",
      "epoch:8 step:8111 [D loss: 0.643942, acc.: 60.94%] [G loss: 0.409089]\n",
      "epoch:8 step:8112 [D loss: 0.555932, acc.: 64.84%] [G loss: 0.644938]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:8 step:8113 [D loss: 0.492369, acc.: 79.69%] [G loss: 0.559603]\n",
      "epoch:8 step:8114 [D loss: 0.547335, acc.: 72.66%] [G loss: 0.550693]\n",
      "epoch:8 step:8115 [D loss: 0.588924, acc.: 67.19%] [G loss: 0.542005]\n",
      "epoch:8 step:8116 [D loss: 0.510356, acc.: 73.44%] [G loss: 0.660498]\n",
      "epoch:8 step:8117 [D loss: 0.591558, acc.: 67.19%] [G loss: 0.584719]\n",
      "epoch:8 step:8118 [D loss: 0.634035, acc.: 64.84%] [G loss: 0.503008]\n",
      "epoch:8 step:8119 [D loss: 0.484864, acc.: 77.34%] [G loss: 0.662695]\n",
      "epoch:8 step:8120 [D loss: 0.462900, acc.: 78.91%] [G loss: 0.763330]\n",
      "epoch:8 step:8121 [D loss: 0.594423, acc.: 65.62%] [G loss: 0.660760]\n",
      "epoch:8 step:8122 [D loss: 0.543379, acc.: 71.09%] [G loss: 0.577542]\n",
      "epoch:8 step:8123 [D loss: 0.601585, acc.: 65.62%] [G loss: 0.562678]\n",
      "epoch:8 step:8124 [D loss: 0.583247, acc.: 62.50%] [G loss: 0.624984]\n",
      "epoch:8 step:8125 [D loss: 0.499466, acc.: 78.91%] [G loss: 0.493287]\n",
      "epoch:8 step:8126 [D loss: 0.528392, acc.: 71.09%] [G loss: 0.614791]\n",
      "epoch:8 step:8127 [D loss: 0.482093, acc.: 76.56%] [G loss: 0.594738]\n",
      "epoch:8 step:8128 [D loss: 0.525031, acc.: 75.00%] [G loss: 0.558057]\n",
      "epoch:8 step:8129 [D loss: 0.525486, acc.: 72.66%] [G loss: 0.602078]\n",
      "epoch:8 step:8130 [D loss: 0.501349, acc.: 78.91%] [G loss: 0.623324]\n",
      "epoch:8 step:8131 [D loss: 0.514546, acc.: 72.66%] [G loss: 0.524699]\n",
      "epoch:8 step:8132 [D loss: 0.588836, acc.: 67.19%] [G loss: 0.596638]\n",
      "epoch:8 step:8133 [D loss: 0.537998, acc.: 68.75%] [G loss: 0.505826]\n",
      "epoch:8 step:8134 [D loss: 0.552679, acc.: 67.19%] [G loss: 0.489469]\n",
      "epoch:8 step:8135 [D loss: 0.471097, acc.: 78.91%] [G loss: 0.546776]\n",
      "epoch:8 step:8136 [D loss: 0.518415, acc.: 75.78%] [G loss: 0.567340]\n",
      "epoch:8 step:8137 [D loss: 0.487579, acc.: 77.34%] [G loss: 0.719449]\n",
      "epoch:8 step:8138 [D loss: 0.488043, acc.: 78.12%] [G loss: 0.748417]\n",
      "epoch:8 step:8139 [D loss: 0.562908, acc.: 66.41%] [G loss: 0.599214]\n",
      "epoch:8 step:8140 [D loss: 0.612504, acc.: 65.62%] [G loss: 0.610642]\n",
      "epoch:8 step:8141 [D loss: 0.507030, acc.: 73.44%] [G loss: 0.574562]\n",
      "epoch:8 step:8142 [D loss: 0.573135, acc.: 70.31%] [G loss: 0.556723]\n",
      "epoch:8 step:8143 [D loss: 0.424337, acc.: 83.59%] [G loss: 0.752690]\n",
      "epoch:8 step:8144 [D loss: 0.428352, acc.: 78.91%] [G loss: 1.006483]\n",
      "epoch:8 step:8145 [D loss: 0.483842, acc.: 77.34%] [G loss: 0.993945]\n",
      "epoch:8 step:8146 [D loss: 0.521815, acc.: 75.78%] [G loss: 0.963261]\n",
      "epoch:8 step:8147 [D loss: 0.508281, acc.: 73.44%] [G loss: 0.904269]\n",
      "epoch:8 step:8148 [D loss: 0.691961, acc.: 57.03%] [G loss: 0.648943]\n",
      "epoch:8 step:8149 [D loss: 0.608624, acc.: 69.53%] [G loss: 0.502800]\n",
      "epoch:8 step:8150 [D loss: 0.519372, acc.: 71.88%] [G loss: 0.517819]\n",
      "epoch:8 step:8151 [D loss: 0.535984, acc.: 71.09%] [G loss: 0.594938]\n",
      "epoch:8 step:8152 [D loss: 0.534525, acc.: 75.00%] [G loss: 0.624190]\n",
      "epoch:8 step:8153 [D loss: 0.559049, acc.: 71.09%] [G loss: 0.562349]\n",
      "epoch:8 step:8154 [D loss: 0.582033, acc.: 67.97%] [G loss: 0.644349]\n",
      "epoch:8 step:8155 [D loss: 0.507978, acc.: 75.00%] [G loss: 0.485961]\n",
      "epoch:8 step:8156 [D loss: 0.523947, acc.: 69.53%] [G loss: 0.584740]\n",
      "epoch:8 step:8157 [D loss: 0.472512, acc.: 76.56%] [G loss: 0.728521]\n",
      "epoch:8 step:8158 [D loss: 0.641768, acc.: 64.84%] [G loss: 0.618354]\n",
      "epoch:8 step:8159 [D loss: 0.552348, acc.: 70.31%] [G loss: 0.527684]\n",
      "epoch:8 step:8160 [D loss: 0.586233, acc.: 66.41%] [G loss: 0.651056]\n",
      "epoch:8 step:8161 [D loss: 0.542255, acc.: 66.41%] [G loss: 0.769785]\n",
      "epoch:8 step:8162 [D loss: 0.518334, acc.: 72.66%] [G loss: 0.486597]\n",
      "epoch:8 step:8163 [D loss: 0.534941, acc.: 75.78%] [G loss: 0.607490]\n",
      "epoch:8 step:8164 [D loss: 0.577160, acc.: 67.19%] [G loss: 0.490587]\n",
      "epoch:8 step:8165 [D loss: 0.542250, acc.: 71.09%] [G loss: 0.588609]\n",
      "epoch:8 step:8166 [D loss: 0.508448, acc.: 71.88%] [G loss: 0.596504]\n",
      "epoch:8 step:8167 [D loss: 0.576147, acc.: 65.62%] [G loss: 0.523193]\n",
      "epoch:8 step:8168 [D loss: 0.526077, acc.: 74.22%] [G loss: 0.600981]\n",
      "epoch:8 step:8169 [D loss: 0.574776, acc.: 69.53%] [G loss: 0.548207]\n",
      "epoch:8 step:8170 [D loss: 0.532379, acc.: 74.22%] [G loss: 0.712737]\n",
      "epoch:8 step:8171 [D loss: 0.586564, acc.: 68.75%] [G loss: 0.517244]\n",
      "epoch:8 step:8172 [D loss: 0.561313, acc.: 65.62%] [G loss: 0.645826]\n",
      "epoch:8 step:8173 [D loss: 0.520161, acc.: 75.00%] [G loss: 0.602566]\n",
      "epoch:8 step:8174 [D loss: 0.599213, acc.: 67.97%] [G loss: 0.659195]\n",
      "epoch:8 step:8175 [D loss: 0.548074, acc.: 72.66%] [G loss: 0.583580]\n",
      "epoch:8 step:8176 [D loss: 0.482683, acc.: 77.34%] [G loss: 0.690356]\n",
      "epoch:8 step:8177 [D loss: 0.475606, acc.: 78.91%] [G loss: 0.632202]\n",
      "epoch:8 step:8178 [D loss: 0.522693, acc.: 73.44%] [G loss: 0.578049]\n",
      "epoch:8 step:8179 [D loss: 0.557523, acc.: 72.66%] [G loss: 0.562256]\n",
      "epoch:8 step:8180 [D loss: 0.553338, acc.: 71.88%] [G loss: 0.547952]\n",
      "epoch:8 step:8181 [D loss: 0.514826, acc.: 73.44%] [G loss: 0.641803]\n",
      "epoch:8 step:8182 [D loss: 0.552458, acc.: 69.53%] [G loss: 0.459366]\n",
      "epoch:8 step:8183 [D loss: 0.547899, acc.: 67.97%] [G loss: 0.541993]\n",
      "epoch:8 step:8184 [D loss: 0.500053, acc.: 77.34%] [G loss: 0.616975]\n",
      "epoch:8 step:8185 [D loss: 0.609451, acc.: 62.50%] [G loss: 0.537488]\n",
      "epoch:8 step:8186 [D loss: 0.531008, acc.: 73.44%] [G loss: 0.610061]\n",
      "epoch:8 step:8187 [D loss: 0.493419, acc.: 78.12%] [G loss: 0.745485]\n",
      "epoch:8 step:8188 [D loss: 0.514365, acc.: 75.00%] [G loss: 0.600653]\n",
      "epoch:8 step:8189 [D loss: 0.514976, acc.: 74.22%] [G loss: 0.775974]\n",
      "epoch:8 step:8190 [D loss: 0.473887, acc.: 77.34%] [G loss: 0.798508]\n",
      "epoch:8 step:8191 [D loss: 0.559089, acc.: 67.19%] [G loss: 0.695938]\n",
      "epoch:8 step:8192 [D loss: 0.615741, acc.: 63.28%] [G loss: 0.590784]\n",
      "epoch:8 step:8193 [D loss: 0.590471, acc.: 63.28%] [G loss: 0.327632]\n",
      "epoch:8 step:8194 [D loss: 0.566077, acc.: 72.66%] [G loss: 0.433486]\n",
      "epoch:8 step:8195 [D loss: 0.536566, acc.: 71.09%] [G loss: 0.611068]\n",
      "epoch:8 step:8196 [D loss: 0.543343, acc.: 65.62%] [G loss: 0.627622]\n",
      "epoch:8 step:8197 [D loss: 0.515462, acc.: 75.00%] [G loss: 0.591078]\n",
      "epoch:8 step:8198 [D loss: 0.623669, acc.: 64.84%] [G loss: 0.642261]\n",
      "epoch:8 step:8199 [D loss: 0.561669, acc.: 70.31%] [G loss: 0.558524]\n",
      "epoch:8 step:8200 [D loss: 0.555815, acc.: 68.75%] [G loss: 0.562127]\n",
      "epoch:8 step:8201 [D loss: 0.517705, acc.: 73.44%] [G loss: 0.575471]\n",
      "epoch:8 step:8202 [D loss: 0.583096, acc.: 70.31%] [G loss: 0.460114]\n",
      "epoch:8 step:8203 [D loss: 0.541819, acc.: 70.31%] [G loss: 0.567191]\n",
      "epoch:8 step:8204 [D loss: 0.515230, acc.: 75.00%] [G loss: 0.696800]\n",
      "epoch:8 step:8205 [D loss: 0.550839, acc.: 71.88%] [G loss: 0.642375]\n",
      "epoch:8 step:8206 [D loss: 0.608565, acc.: 68.75%] [G loss: 0.515490]\n",
      "epoch:8 step:8207 [D loss: 0.606644, acc.: 64.06%] [G loss: 0.495212]\n",
      "epoch:8 step:8208 [D loss: 0.488344, acc.: 76.56%] [G loss: 0.495447]\n",
      "epoch:8 step:8209 [D loss: 0.558060, acc.: 66.41%] [G loss: 0.507982]\n",
      "epoch:8 step:8210 [D loss: 0.527936, acc.: 71.88%] [G loss: 0.568379]\n",
      "epoch:8 step:8211 [D loss: 0.556653, acc.: 70.31%] [G loss: 0.533557]\n",
      "epoch:8 step:8212 [D loss: 0.621110, acc.: 63.28%] [G loss: 0.587352]\n",
      "epoch:8 step:8213 [D loss: 0.628268, acc.: 67.19%] [G loss: 0.613387]\n",
      "epoch:8 step:8214 [D loss: 0.556527, acc.: 71.09%] [G loss: 0.629869]\n",
      "epoch:8 step:8215 [D loss: 0.493398, acc.: 76.56%] [G loss: 0.795759]\n",
      "epoch:8 step:8216 [D loss: 0.590717, acc.: 67.97%] [G loss: 0.610051]\n",
      "epoch:8 step:8217 [D loss: 0.607184, acc.: 65.62%] [G loss: 0.402844]\n",
      "epoch:8 step:8218 [D loss: 0.588711, acc.: 64.06%] [G loss: 0.576267]\n",
      "epoch:8 step:8219 [D loss: 0.566931, acc.: 71.09%] [G loss: 0.485409]\n",
      "epoch:8 step:8220 [D loss: 0.528156, acc.: 76.56%] [G loss: 0.526671]\n",
      "epoch:8 step:8221 [D loss: 0.482365, acc.: 75.78%] [G loss: 0.808654]\n",
      "epoch:8 step:8222 [D loss: 0.568846, acc.: 72.66%] [G loss: 0.632413]\n",
      "epoch:8 step:8223 [D loss: 0.590439, acc.: 66.41%] [G loss: 0.707557]\n",
      "epoch:8 step:8224 [D loss: 0.522583, acc.: 75.00%] [G loss: 0.597681]\n",
      "epoch:8 step:8225 [D loss: 0.607493, acc.: 64.06%] [G loss: 0.465199]\n",
      "epoch:8 step:8226 [D loss: 0.518039, acc.: 71.88%] [G loss: 0.485358]\n",
      "epoch:8 step:8227 [D loss: 0.601830, acc.: 64.06%] [G loss: 0.614411]\n",
      "epoch:8 step:8228 [D loss: 0.478817, acc.: 75.00%] [G loss: 0.787821]\n",
      "epoch:8 step:8229 [D loss: 0.555880, acc.: 65.62%] [G loss: 0.759871]\n",
      "epoch:8 step:8230 [D loss: 0.541126, acc.: 67.97%] [G loss: 0.634795]\n",
      "epoch:8 step:8231 [D loss: 0.582667, acc.: 67.19%] [G loss: 0.506122]\n",
      "epoch:8 step:8232 [D loss: 0.513833, acc.: 73.44%] [G loss: 0.585696]\n",
      "epoch:8 step:8233 [D loss: 0.522620, acc.: 69.53%] [G loss: 0.765624]\n",
      "epoch:8 step:8234 [D loss: 0.531653, acc.: 71.88%] [G loss: 0.654098]\n",
      "epoch:8 step:8235 [D loss: 0.532809, acc.: 74.22%] [G loss: 0.609411]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:8 step:8236 [D loss: 0.648216, acc.: 58.59%] [G loss: 0.442084]\n",
      "epoch:8 step:8237 [D loss: 0.530320, acc.: 73.44%] [G loss: 0.646324]\n",
      "epoch:8 step:8238 [D loss: 0.553407, acc.: 68.75%] [G loss: 0.569212]\n",
      "epoch:8 step:8239 [D loss: 0.459458, acc.: 78.91%] [G loss: 0.828018]\n",
      "epoch:8 step:8240 [D loss: 0.592445, acc.: 70.31%] [G loss: 0.587292]\n",
      "epoch:8 step:8241 [D loss: 0.677762, acc.: 59.38%] [G loss: 0.539299]\n",
      "epoch:8 step:8242 [D loss: 0.465410, acc.: 76.56%] [G loss: 0.581395]\n",
      "epoch:8 step:8243 [D loss: 0.444813, acc.: 78.91%] [G loss: 0.804863]\n",
      "epoch:8 step:8244 [D loss: 0.564976, acc.: 67.97%] [G loss: 0.645021]\n",
      "epoch:8 step:8245 [D loss: 0.560410, acc.: 71.09%] [G loss: 0.542334]\n",
      "epoch:8 step:8246 [D loss: 0.549315, acc.: 72.66%] [G loss: 0.603383]\n",
      "epoch:8 step:8247 [D loss: 0.516461, acc.: 75.78%] [G loss: 0.569503]\n",
      "epoch:8 step:8248 [D loss: 0.580895, acc.: 67.19%] [G loss: 0.594373]\n",
      "epoch:8 step:8249 [D loss: 0.509647, acc.: 74.22%] [G loss: 0.633981]\n",
      "epoch:8 step:8250 [D loss: 0.545471, acc.: 68.75%] [G loss: 0.558338]\n",
      "epoch:8 step:8251 [D loss: 0.529402, acc.: 70.31%] [G loss: 0.721475]\n",
      "epoch:8 step:8252 [D loss: 0.609004, acc.: 64.84%] [G loss: 0.629248]\n",
      "epoch:8 step:8253 [D loss: 0.569001, acc.: 70.31%] [G loss: 0.540561]\n",
      "epoch:8 step:8254 [D loss: 0.527219, acc.: 72.66%] [G loss: 0.684092]\n",
      "epoch:8 step:8255 [D loss: 0.539016, acc.: 69.53%] [G loss: 0.596943]\n",
      "epoch:8 step:8256 [D loss: 0.528073, acc.: 72.66%] [G loss: 0.453658]\n",
      "epoch:8 step:8257 [D loss: 0.526820, acc.: 75.00%] [G loss: 0.636865]\n",
      "epoch:8 step:8258 [D loss: 0.564397, acc.: 71.88%] [G loss: 0.415236]\n",
      "epoch:8 step:8259 [D loss: 0.561417, acc.: 67.97%] [G loss: 0.535632]\n",
      "epoch:8 step:8260 [D loss: 0.580342, acc.: 68.75%] [G loss: 0.538399]\n",
      "epoch:8 step:8261 [D loss: 0.629232, acc.: 67.97%] [G loss: 0.656448]\n",
      "epoch:8 step:8262 [D loss: 0.695161, acc.: 58.59%] [G loss: 0.518163]\n",
      "epoch:8 step:8263 [D loss: 0.555721, acc.: 71.09%] [G loss: 0.581524]\n",
      "epoch:8 step:8264 [D loss: 0.556916, acc.: 72.66%] [G loss: 0.574257]\n",
      "epoch:8 step:8265 [D loss: 0.508978, acc.: 75.00%] [G loss: 0.654428]\n",
      "epoch:8 step:8266 [D loss: 0.537452, acc.: 69.53%] [G loss: 0.748066]\n",
      "epoch:8 step:8267 [D loss: 0.516697, acc.: 76.56%] [G loss: 0.672906]\n",
      "epoch:8 step:8268 [D loss: 0.528862, acc.: 73.44%] [G loss: 0.671777]\n",
      "epoch:8 step:8269 [D loss: 0.533547, acc.: 71.09%] [G loss: 0.569413]\n",
      "epoch:8 step:8270 [D loss: 0.584362, acc.: 68.75%] [G loss: 0.583401]\n",
      "epoch:8 step:8271 [D loss: 0.510782, acc.: 74.22%] [G loss: 0.746104]\n",
      "epoch:8 step:8272 [D loss: 0.590220, acc.: 70.31%] [G loss: 0.654548]\n",
      "epoch:8 step:8273 [D loss: 0.556661, acc.: 71.09%] [G loss: 0.629485]\n",
      "epoch:8 step:8274 [D loss: 0.562200, acc.: 68.75%] [G loss: 0.609153]\n",
      "epoch:8 step:8275 [D loss: 0.628065, acc.: 67.19%] [G loss: 0.551496]\n",
      "epoch:8 step:8276 [D loss: 0.561604, acc.: 71.88%] [G loss: 0.630978]\n",
      "epoch:8 step:8277 [D loss: 0.528280, acc.: 69.53%] [G loss: 0.703199]\n",
      "epoch:8 step:8278 [D loss: 0.504665, acc.: 74.22%] [G loss: 0.904683]\n",
      "epoch:8 step:8279 [D loss: 0.612968, acc.: 63.28%] [G loss: 0.798297]\n",
      "epoch:8 step:8280 [D loss: 0.655851, acc.: 55.47%] [G loss: 0.624370]\n",
      "epoch:8 step:8281 [D loss: 0.541654, acc.: 73.44%] [G loss: 0.525739]\n",
      "epoch:8 step:8282 [D loss: 0.516769, acc.: 73.44%] [G loss: 0.530474]\n",
      "epoch:8 step:8283 [D loss: 0.579159, acc.: 68.75%] [G loss: 0.474186]\n",
      "epoch:8 step:8284 [D loss: 0.608611, acc.: 64.06%] [G loss: 0.439935]\n",
      "epoch:8 step:8285 [D loss: 0.532546, acc.: 69.53%] [G loss: 0.437430]\n",
      "epoch:8 step:8286 [D loss: 0.536395, acc.: 70.31%] [G loss: 0.507799]\n",
      "epoch:8 step:8287 [D loss: 0.579759, acc.: 64.06%] [G loss: 0.411129]\n",
      "epoch:8 step:8288 [D loss: 0.452428, acc.: 79.69%] [G loss: 0.552640]\n",
      "epoch:8 step:8289 [D loss: 0.604680, acc.: 67.97%] [G loss: 0.498645]\n",
      "epoch:8 step:8290 [D loss: 0.649015, acc.: 60.94%] [G loss: 0.578847]\n",
      "epoch:8 step:8291 [D loss: 0.547874, acc.: 67.19%] [G loss: 0.466897]\n",
      "epoch:8 step:8292 [D loss: 0.570242, acc.: 67.19%] [G loss: 0.609224]\n",
      "epoch:8 step:8293 [D loss: 0.576823, acc.: 64.84%] [G loss: 0.662202]\n",
      "epoch:8 step:8294 [D loss: 0.492365, acc.: 71.09%] [G loss: 0.746535]\n",
      "epoch:8 step:8295 [D loss: 0.571118, acc.: 71.88%] [G loss: 0.622597]\n",
      "epoch:8 step:8296 [D loss: 0.605376, acc.: 62.50%] [G loss: 0.586378]\n",
      "epoch:8 step:8297 [D loss: 0.451612, acc.: 80.47%] [G loss: 0.626976]\n",
      "epoch:8 step:8298 [D loss: 0.510542, acc.: 71.88%] [G loss: 0.600102]\n",
      "epoch:8 step:8299 [D loss: 0.566950, acc.: 69.53%] [G loss: 0.591135]\n",
      "epoch:8 step:8300 [D loss: 0.508971, acc.: 71.88%] [G loss: 0.582091]\n",
      "epoch:8 step:8301 [D loss: 0.545912, acc.: 71.88%] [G loss: 0.562380]\n",
      "epoch:8 step:8302 [D loss: 0.511859, acc.: 74.22%] [G loss: 0.609998]\n",
      "epoch:8 step:8303 [D loss: 0.506886, acc.: 72.66%] [G loss: 0.668332]\n",
      "epoch:8 step:8304 [D loss: 0.596373, acc.: 64.84%] [G loss: 0.556674]\n",
      "epoch:8 step:8305 [D loss: 0.561240, acc.: 67.97%] [G loss: 0.630953]\n",
      "epoch:8 step:8306 [D loss: 0.507440, acc.: 74.22%] [G loss: 0.515696]\n",
      "epoch:8 step:8307 [D loss: 0.507128, acc.: 74.22%] [G loss: 0.651878]\n",
      "epoch:8 step:8308 [D loss: 0.662077, acc.: 61.72%] [G loss: 0.370891]\n",
      "epoch:8 step:8309 [D loss: 0.525020, acc.: 71.88%] [G loss: 0.529930]\n",
      "epoch:8 step:8310 [D loss: 0.515912, acc.: 75.00%] [G loss: 0.685460]\n",
      "epoch:8 step:8311 [D loss: 0.572729, acc.: 69.53%] [G loss: 0.544708]\n",
      "epoch:8 step:8312 [D loss: 0.511496, acc.: 75.78%] [G loss: 0.822789]\n",
      "epoch:8 step:8313 [D loss: 0.568751, acc.: 71.09%] [G loss: 0.585441]\n",
      "epoch:8 step:8314 [D loss: 0.616415, acc.: 66.41%] [G loss: 0.492352]\n",
      "epoch:8 step:8315 [D loss: 0.502272, acc.: 76.56%] [G loss: 0.603104]\n",
      "epoch:8 step:8316 [D loss: 0.604332, acc.: 67.19%] [G loss: 0.639007]\n",
      "epoch:8 step:8317 [D loss: 0.539447, acc.: 71.09%] [G loss: 0.490551]\n",
      "epoch:8 step:8318 [D loss: 0.503987, acc.: 74.22%] [G loss: 0.594617]\n",
      "epoch:8 step:8319 [D loss: 0.477712, acc.: 77.34%] [G loss: 0.476808]\n",
      "epoch:8 step:8320 [D loss: 0.607939, acc.: 67.19%] [G loss: 0.480833]\n",
      "epoch:8 step:8321 [D loss: 0.572565, acc.: 73.44%] [G loss: 0.550659]\n",
      "epoch:8 step:8322 [D loss: 0.525082, acc.: 73.44%] [G loss: 0.609085]\n",
      "epoch:8 step:8323 [D loss: 0.571241, acc.: 68.75%] [G loss: 0.551086]\n",
      "epoch:8 step:8324 [D loss: 0.558739, acc.: 71.09%] [G loss: 0.571474]\n",
      "epoch:8 step:8325 [D loss: 0.551847, acc.: 73.44%] [G loss: 0.556262]\n",
      "epoch:8 step:8326 [D loss: 0.569616, acc.: 64.84%] [G loss: 0.574038]\n",
      "epoch:8 step:8327 [D loss: 0.541415, acc.: 73.44%] [G loss: 0.521325]\n",
      "epoch:8 step:8328 [D loss: 0.569641, acc.: 68.75%] [G loss: 0.522653]\n",
      "epoch:8 step:8329 [D loss: 0.534287, acc.: 72.66%] [G loss: 0.563430]\n",
      "epoch:8 step:8330 [D loss: 0.519189, acc.: 73.44%] [G loss: 0.524468]\n",
      "epoch:8 step:8331 [D loss: 0.540631, acc.: 71.88%] [G loss: 0.507865]\n",
      "epoch:8 step:8332 [D loss: 0.516999, acc.: 72.66%] [G loss: 0.524611]\n",
      "epoch:8 step:8333 [D loss: 0.519263, acc.: 78.12%] [G loss: 0.438358]\n",
      "epoch:8 step:8334 [D loss: 0.533698, acc.: 71.09%] [G loss: 0.663758]\n",
      "epoch:8 step:8335 [D loss: 0.579750, acc.: 68.75%] [G loss: 0.441985]\n",
      "epoch:8 step:8336 [D loss: 0.593161, acc.: 67.19%] [G loss: 0.462749]\n",
      "epoch:8 step:8337 [D loss: 0.516288, acc.: 71.09%] [G loss: 0.511920]\n",
      "epoch:8 step:8338 [D loss: 0.536607, acc.: 71.88%] [G loss: 0.476915]\n",
      "epoch:8 step:8339 [D loss: 0.509021, acc.: 74.22%] [G loss: 0.557594]\n",
      "epoch:8 step:8340 [D loss: 0.571000, acc.: 68.75%] [G loss: 0.569844]\n",
      "epoch:8 step:8341 [D loss: 0.585456, acc.: 67.19%] [G loss: 0.664300]\n",
      "epoch:8 step:8342 [D loss: 0.531881, acc.: 74.22%] [G loss: 0.561497]\n",
      "epoch:8 step:8343 [D loss: 0.609027, acc.: 66.41%] [G loss: 0.416407]\n",
      "epoch:8 step:8344 [D loss: 0.546959, acc.: 67.19%] [G loss: 0.479106]\n",
      "epoch:8 step:8345 [D loss: 0.575778, acc.: 64.84%] [G loss: 0.349733]\n",
      "epoch:8 step:8346 [D loss: 0.555504, acc.: 68.75%] [G loss: 0.487773]\n",
      "epoch:8 step:8347 [D loss: 0.582196, acc.: 63.28%] [G loss: 0.484052]\n",
      "epoch:8 step:8348 [D loss: 0.524549, acc.: 73.44%] [G loss: 0.544260]\n",
      "epoch:8 step:8349 [D loss: 0.508448, acc.: 73.44%] [G loss: 0.503764]\n",
      "epoch:8 step:8350 [D loss: 0.520475, acc.: 71.09%] [G loss: 0.599112]\n",
      "epoch:8 step:8351 [D loss: 0.574471, acc.: 71.09%] [G loss: 0.718425]\n",
      "epoch:8 step:8352 [D loss: 0.594523, acc.: 67.19%] [G loss: 0.485363]\n",
      "epoch:8 step:8353 [D loss: 0.496718, acc.: 74.22%] [G loss: 0.573837]\n",
      "epoch:8 step:8354 [D loss: 0.684757, acc.: 55.47%] [G loss: 0.595221]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:8 step:8355 [D loss: 0.541340, acc.: 71.88%] [G loss: 0.627853]\n",
      "epoch:8 step:8356 [D loss: 0.478741, acc.: 75.78%] [G loss: 0.647260]\n",
      "epoch:8 step:8357 [D loss: 0.640914, acc.: 64.84%] [G loss: 0.576588]\n",
      "epoch:8 step:8358 [D loss: 0.579464, acc.: 64.06%] [G loss: 0.383893]\n",
      "epoch:8 step:8359 [D loss: 0.609333, acc.: 65.62%] [G loss: 0.452998]\n",
      "epoch:8 step:8360 [D loss: 0.522250, acc.: 69.53%] [G loss: 0.478875]\n",
      "epoch:8 step:8361 [D loss: 0.535276, acc.: 71.09%] [G loss: 0.549345]\n",
      "epoch:8 step:8362 [D loss: 0.564331, acc.: 64.84%] [G loss: 0.516693]\n",
      "epoch:8 step:8363 [D loss: 0.687801, acc.: 58.59%] [G loss: 0.394221]\n",
      "epoch:8 step:8364 [D loss: 0.534114, acc.: 67.97%] [G loss: 0.519382]\n",
      "epoch:8 step:8365 [D loss: 0.546184, acc.: 66.41%] [G loss: 0.549634]\n",
      "epoch:8 step:8366 [D loss: 0.472271, acc.: 78.91%] [G loss: 0.698347]\n",
      "epoch:8 step:8367 [D loss: 0.538135, acc.: 69.53%] [G loss: 0.582067]\n",
      "epoch:8 step:8368 [D loss: 0.554107, acc.: 67.97%] [G loss: 0.503349]\n",
      "epoch:8 step:8369 [D loss: 0.575696, acc.: 67.19%] [G loss: 0.482595]\n",
      "epoch:8 step:8370 [D loss: 0.554474, acc.: 71.88%] [G loss: 0.517389]\n",
      "epoch:8 step:8371 [D loss: 0.512609, acc.: 75.78%] [G loss: 0.552967]\n",
      "epoch:8 step:8372 [D loss: 0.550444, acc.: 71.09%] [G loss: 0.537299]\n",
      "epoch:8 step:8373 [D loss: 0.595563, acc.: 64.84%] [G loss: 0.531260]\n",
      "epoch:8 step:8374 [D loss: 0.566814, acc.: 69.53%] [G loss: 0.484569]\n",
      "epoch:8 step:8375 [D loss: 0.533997, acc.: 72.66%] [G loss: 0.649735]\n",
      "epoch:8 step:8376 [D loss: 0.644260, acc.: 53.91%] [G loss: 0.383712]\n",
      "epoch:8 step:8377 [D loss: 0.644334, acc.: 64.06%] [G loss: 0.476397]\n",
      "epoch:8 step:8378 [D loss: 0.581604, acc.: 68.75%] [G loss: 0.429211]\n",
      "epoch:8 step:8379 [D loss: 0.593433, acc.: 67.97%] [G loss: 0.457171]\n",
      "epoch:8 step:8380 [D loss: 0.515685, acc.: 71.88%] [G loss: 0.421313]\n",
      "epoch:8 step:8381 [D loss: 0.545518, acc.: 67.97%] [G loss: 0.471243]\n",
      "epoch:8 step:8382 [D loss: 0.537961, acc.: 69.53%] [G loss: 0.861733]\n",
      "epoch:8 step:8383 [D loss: 0.521556, acc.: 73.44%] [G loss: 0.663464]\n",
      "epoch:8 step:8384 [D loss: 0.537868, acc.: 68.75%] [G loss: 0.591729]\n",
      "epoch:8 step:8385 [D loss: 0.556018, acc.: 67.19%] [G loss: 0.478168]\n",
      "epoch:8 step:8386 [D loss: 0.490785, acc.: 78.91%] [G loss: 0.663153]\n",
      "epoch:8 step:8387 [D loss: 0.576017, acc.: 69.53%] [G loss: 0.622345]\n",
      "epoch:8 step:8388 [D loss: 0.682905, acc.: 60.94%] [G loss: 0.388796]\n",
      "epoch:8 step:8389 [D loss: 0.538758, acc.: 74.22%] [G loss: 0.514687]\n",
      "epoch:8 step:8390 [D loss: 0.479793, acc.: 75.78%] [G loss: 0.587131]\n",
      "epoch:8 step:8391 [D loss: 0.532777, acc.: 71.88%] [G loss: 0.662442]\n",
      "epoch:8 step:8392 [D loss: 0.535226, acc.: 74.22%] [G loss: 0.733885]\n",
      "epoch:8 step:8393 [D loss: 0.477896, acc.: 73.44%] [G loss: 0.786324]\n",
      "epoch:8 step:8394 [D loss: 0.483697, acc.: 74.22%] [G loss: 0.624933]\n",
      "epoch:8 step:8395 [D loss: 0.547006, acc.: 75.78%] [G loss: 0.808875]\n",
      "epoch:8 step:8396 [D loss: 0.498041, acc.: 76.56%] [G loss: 0.743100]\n",
      "epoch:8 step:8397 [D loss: 0.561665, acc.: 67.19%] [G loss: 0.585209]\n",
      "epoch:8 step:8398 [D loss: 0.575844, acc.: 67.19%] [G loss: 0.438238]\n",
      "epoch:8 step:8399 [D loss: 0.559250, acc.: 71.09%] [G loss: 0.580063]\n",
      "epoch:8 step:8400 [D loss: 0.582415, acc.: 66.41%] [G loss: 0.509838]\n",
      "epoch:8 step:8401 [D loss: 0.547541, acc.: 71.88%] [G loss: 0.440281]\n",
      "epoch:8 step:8402 [D loss: 0.468332, acc.: 78.91%] [G loss: 0.517824]\n",
      "epoch:8 step:8403 [D loss: 0.544991, acc.: 70.31%] [G loss: 0.586142]\n",
      "epoch:8 step:8404 [D loss: 0.563099, acc.: 71.09%] [G loss: 0.565200]\n",
      "epoch:8 step:8405 [D loss: 0.512397, acc.: 74.22%] [G loss: 0.537067]\n",
      "epoch:8 step:8406 [D loss: 0.511962, acc.: 73.44%] [G loss: 0.891567]\n",
      "epoch:8 step:8407 [D loss: 0.481554, acc.: 78.12%] [G loss: 0.787469]\n",
      "epoch:8 step:8408 [D loss: 0.487154, acc.: 75.00%] [G loss: 1.068725]\n",
      "epoch:8 step:8409 [D loss: 0.557015, acc.: 70.31%] [G loss: 0.757483]\n",
      "epoch:8 step:8410 [D loss: 0.494921, acc.: 77.34%] [G loss: 0.771695]\n",
      "epoch:8 step:8411 [D loss: 0.646089, acc.: 63.28%] [G loss: 0.525324]\n",
      "epoch:8 step:8412 [D loss: 0.557405, acc.: 71.09%] [G loss: 0.596425]\n",
      "epoch:8 step:8413 [D loss: 0.599196, acc.: 62.50%] [G loss: 0.505787]\n",
      "epoch:8 step:8414 [D loss: 0.490320, acc.: 77.34%] [G loss: 0.655127]\n",
      "epoch:8 step:8415 [D loss: 0.455534, acc.: 82.81%] [G loss: 0.723969]\n",
      "epoch:8 step:8416 [D loss: 0.734363, acc.: 59.38%] [G loss: 0.551656]\n",
      "epoch:8 step:8417 [D loss: 0.492196, acc.: 75.78%] [G loss: 0.678375]\n",
      "epoch:8 step:8418 [D loss: 0.486349, acc.: 75.78%] [G loss: 0.734125]\n",
      "epoch:8 step:8419 [D loss: 0.499329, acc.: 75.78%] [G loss: 0.622063]\n",
      "epoch:8 step:8420 [D loss: 0.466562, acc.: 74.22%] [G loss: 0.698548]\n",
      "epoch:8 step:8421 [D loss: 0.430760, acc.: 81.25%] [G loss: 0.900649]\n",
      "epoch:8 step:8422 [D loss: 0.465430, acc.: 77.34%] [G loss: 0.891782]\n",
      "epoch:8 step:8423 [D loss: 0.535753, acc.: 71.09%] [G loss: 1.005121]\n",
      "epoch:8 step:8424 [D loss: 0.793829, acc.: 62.50%] [G loss: 0.944579]\n",
      "epoch:8 step:8425 [D loss: 0.454965, acc.: 75.78%] [G loss: 1.519352]\n",
      "epoch:8 step:8426 [D loss: 0.504158, acc.: 73.44%] [G loss: 0.988227]\n",
      "epoch:8 step:8427 [D loss: 0.552881, acc.: 69.53%] [G loss: 0.831598]\n",
      "epoch:8 step:8428 [D loss: 0.580763, acc.: 72.66%] [G loss: 0.746208]\n",
      "epoch:8 step:8429 [D loss: 0.506984, acc.: 77.34%] [G loss: 0.802756]\n",
      "epoch:8 step:8430 [D loss: 0.506809, acc.: 75.78%] [G loss: 0.766411]\n",
      "epoch:8 step:8431 [D loss: 0.490256, acc.: 70.31%] [G loss: 0.817316]\n",
      "epoch:8 step:8432 [D loss: 0.438059, acc.: 78.91%] [G loss: 1.190132]\n",
      "epoch:8 step:8433 [D loss: 0.502328, acc.: 73.44%] [G loss: 1.088269]\n",
      "epoch:9 step:8434 [D loss: 0.627493, acc.: 66.41%] [G loss: 1.066308]\n",
      "epoch:9 step:8435 [D loss: 0.525787, acc.: 71.09%] [G loss: 1.128317]\n",
      "epoch:9 step:8436 [D loss: 0.567017, acc.: 72.66%] [G loss: 0.813838]\n",
      "epoch:9 step:8437 [D loss: 0.502538, acc.: 71.88%] [G loss: 0.763862]\n",
      "epoch:9 step:8438 [D loss: 0.578035, acc.: 68.75%] [G loss: 0.701259]\n",
      "epoch:9 step:8439 [D loss: 0.525509, acc.: 73.44%] [G loss: 0.830652]\n",
      "epoch:9 step:8440 [D loss: 0.517725, acc.: 73.44%] [G loss: 0.699537]\n",
      "epoch:9 step:8441 [D loss: 0.495875, acc.: 75.78%] [G loss: 0.788453]\n",
      "epoch:9 step:8442 [D loss: 0.511086, acc.: 71.88%] [G loss: 0.712452]\n",
      "epoch:9 step:8443 [D loss: 0.555225, acc.: 68.75%] [G loss: 0.461755]\n",
      "epoch:9 step:8444 [D loss: 0.493370, acc.: 75.00%] [G loss: 0.596806]\n",
      "epoch:9 step:8445 [D loss: 0.577247, acc.: 69.53%] [G loss: 0.552546]\n",
      "epoch:9 step:8446 [D loss: 0.565604, acc.: 67.19%] [G loss: 0.561884]\n",
      "epoch:9 step:8447 [D loss: 0.562599, acc.: 67.19%] [G loss: 0.611355]\n",
      "epoch:9 step:8448 [D loss: 0.493078, acc.: 75.00%] [G loss: 0.583752]\n",
      "epoch:9 step:8449 [D loss: 0.517220, acc.: 69.53%] [G loss: 0.584429]\n",
      "epoch:9 step:8450 [D loss: 0.567562, acc.: 68.75%] [G loss: 0.648743]\n",
      "epoch:9 step:8451 [D loss: 0.542876, acc.: 74.22%] [G loss: 0.692816]\n",
      "epoch:9 step:8452 [D loss: 0.578456, acc.: 70.31%] [G loss: 0.517827]\n",
      "epoch:9 step:8453 [D loss: 0.650420, acc.: 58.59%] [G loss: 0.560677]\n",
      "epoch:9 step:8454 [D loss: 0.518265, acc.: 73.44%] [G loss: 0.553771]\n",
      "epoch:9 step:8455 [D loss: 0.432026, acc.: 78.12%] [G loss: 0.801668]\n",
      "epoch:9 step:8456 [D loss: 0.550593, acc.: 69.53%] [G loss: 0.655115]\n",
      "epoch:9 step:8457 [D loss: 0.519959, acc.: 75.78%] [G loss: 0.610532]\n",
      "epoch:9 step:8458 [D loss: 0.497726, acc.: 78.12%] [G loss: 0.585674]\n",
      "epoch:9 step:8459 [D loss: 0.618545, acc.: 64.84%] [G loss: 0.498741]\n",
      "epoch:9 step:8460 [D loss: 0.481715, acc.: 74.22%] [G loss: 0.597658]\n",
      "epoch:9 step:8461 [D loss: 0.604030, acc.: 62.50%] [G loss: 0.440853]\n",
      "epoch:9 step:8462 [D loss: 0.522506, acc.: 70.31%] [G loss: 0.486109]\n",
      "epoch:9 step:8463 [D loss: 0.530953, acc.: 68.75%] [G loss: 0.538081]\n",
      "epoch:9 step:8464 [D loss: 0.608234, acc.: 63.28%] [G loss: 0.454753]\n",
      "epoch:9 step:8465 [D loss: 0.516236, acc.: 71.09%] [G loss: 0.662214]\n",
      "epoch:9 step:8466 [D loss: 0.554327, acc.: 69.53%] [G loss: 0.449662]\n",
      "epoch:9 step:8467 [D loss: 0.532650, acc.: 70.31%] [G loss: 0.623013]\n",
      "epoch:9 step:8468 [D loss: 0.539814, acc.: 71.09%] [G loss: 0.792261]\n",
      "epoch:9 step:8469 [D loss: 0.536620, acc.: 72.66%] [G loss: 0.641970]\n",
      "epoch:9 step:8470 [D loss: 0.535985, acc.: 68.75%] [G loss: 0.616223]\n",
      "epoch:9 step:8471 [D loss: 0.620037, acc.: 69.53%] [G loss: 0.606668]\n",
      "epoch:9 step:8472 [D loss: 0.556509, acc.: 70.31%] [G loss: 0.526603]\n",
      "epoch:9 step:8473 [D loss: 0.414329, acc.: 81.25%] [G loss: 0.691006]\n",
      "epoch:9 step:8474 [D loss: 0.528169, acc.: 71.09%] [G loss: 0.688988]\n",
      "epoch:9 step:8475 [D loss: 0.505947, acc.: 71.88%] [G loss: 0.657589]\n",
      "epoch:9 step:8476 [D loss: 0.504599, acc.: 75.78%] [G loss: 0.731041]\n",
      "epoch:9 step:8477 [D loss: 0.582439, acc.: 65.62%] [G loss: 0.573649]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:9 step:8478 [D loss: 0.474452, acc.: 76.56%] [G loss: 0.607076]\n",
      "epoch:9 step:8479 [D loss: 0.561520, acc.: 71.09%] [G loss: 0.551260]\n",
      "epoch:9 step:8480 [D loss: 0.549024, acc.: 68.75%] [G loss: 0.685409]\n",
      "epoch:9 step:8481 [D loss: 0.560671, acc.: 69.53%] [G loss: 0.548426]\n",
      "epoch:9 step:8482 [D loss: 0.498868, acc.: 78.12%] [G loss: 0.681960]\n",
      "epoch:9 step:8483 [D loss: 0.547062, acc.: 67.97%] [G loss: 0.602405]\n",
      "epoch:9 step:8484 [D loss: 0.655070, acc.: 60.16%] [G loss: 0.406505]\n",
      "epoch:9 step:8485 [D loss: 0.564876, acc.: 68.75%] [G loss: 0.521332]\n",
      "epoch:9 step:8486 [D loss: 0.542333, acc.: 67.19%] [G loss: 0.510327]\n",
      "epoch:9 step:8487 [D loss: 0.461042, acc.: 78.12%] [G loss: 0.664240]\n",
      "epoch:9 step:8488 [D loss: 0.534664, acc.: 71.88%] [G loss: 0.531548]\n",
      "epoch:9 step:8489 [D loss: 0.569089, acc.: 75.00%] [G loss: 0.500628]\n",
      "epoch:9 step:8490 [D loss: 0.537393, acc.: 72.66%] [G loss: 0.581633]\n",
      "epoch:9 step:8491 [D loss: 0.539916, acc.: 71.09%] [G loss: 0.626312]\n",
      "epoch:9 step:8492 [D loss: 0.504039, acc.: 72.66%] [G loss: 0.650528]\n",
      "epoch:9 step:8493 [D loss: 0.571712, acc.: 67.19%] [G loss: 0.622968]\n",
      "epoch:9 step:8494 [D loss: 0.522977, acc.: 75.78%] [G loss: 0.601322]\n",
      "epoch:9 step:8495 [D loss: 0.597977, acc.: 71.09%] [G loss: 0.604920]\n",
      "epoch:9 step:8496 [D loss: 0.535765, acc.: 70.31%] [G loss: 0.579133]\n",
      "epoch:9 step:8497 [D loss: 0.576587, acc.: 67.97%] [G loss: 0.565813]\n",
      "epoch:9 step:8498 [D loss: 0.550534, acc.: 74.22%] [G loss: 0.563984]\n",
      "epoch:9 step:8499 [D loss: 0.538289, acc.: 68.75%] [G loss: 0.508736]\n",
      "epoch:9 step:8500 [D loss: 0.551974, acc.: 67.19%] [G loss: 0.522855]\n",
      "epoch:9 step:8501 [D loss: 0.535790, acc.: 75.00%] [G loss: 0.579272]\n",
      "epoch:9 step:8502 [D loss: 0.506623, acc.: 77.34%] [G loss: 0.678841]\n",
      "epoch:9 step:8503 [D loss: 0.500975, acc.: 78.91%] [G loss: 0.652103]\n",
      "epoch:9 step:8504 [D loss: 0.542044, acc.: 73.44%] [G loss: 0.599559]\n",
      "epoch:9 step:8505 [D loss: 0.503973, acc.: 74.22%] [G loss: 0.519695]\n",
      "epoch:9 step:8506 [D loss: 0.551598, acc.: 70.31%] [G loss: 0.571108]\n",
      "epoch:9 step:8507 [D loss: 0.505340, acc.: 76.56%] [G loss: 0.520170]\n",
      "epoch:9 step:8508 [D loss: 0.502881, acc.: 71.09%] [G loss: 0.736847]\n",
      "epoch:9 step:8509 [D loss: 0.530268, acc.: 69.53%] [G loss: 0.867088]\n",
      "epoch:9 step:8510 [D loss: 0.457508, acc.: 78.12%] [G loss: 0.929633]\n",
      "epoch:9 step:8511 [D loss: 0.629576, acc.: 66.41%] [G loss: 0.575626]\n",
      "epoch:9 step:8512 [D loss: 0.564189, acc.: 67.19%] [G loss: 0.548492]\n",
      "epoch:9 step:8513 [D loss: 0.567068, acc.: 67.97%] [G loss: 0.696988]\n",
      "epoch:9 step:8514 [D loss: 0.537058, acc.: 74.22%] [G loss: 0.662390]\n",
      "epoch:9 step:8515 [D loss: 0.523380, acc.: 67.19%] [G loss: 0.701621]\n",
      "epoch:9 step:8516 [D loss: 0.524257, acc.: 75.00%] [G loss: 0.735810]\n",
      "epoch:9 step:8517 [D loss: 0.567132, acc.: 67.97%] [G loss: 0.694359]\n",
      "epoch:9 step:8518 [D loss: 0.592170, acc.: 63.28%] [G loss: 0.609774]\n",
      "epoch:9 step:8519 [D loss: 0.541938, acc.: 71.88%] [G loss: 0.628411]\n",
      "epoch:9 step:8520 [D loss: 0.479668, acc.: 76.56%] [G loss: 0.537688]\n",
      "epoch:9 step:8521 [D loss: 0.512589, acc.: 75.00%] [G loss: 0.652557]\n",
      "epoch:9 step:8522 [D loss: 0.482972, acc.: 73.44%] [G loss: 0.705824]\n",
      "epoch:9 step:8523 [D loss: 0.508355, acc.: 71.88%] [G loss: 0.679051]\n",
      "epoch:9 step:8524 [D loss: 0.566305, acc.: 67.19%] [G loss: 0.561604]\n",
      "epoch:9 step:8525 [D loss: 0.449213, acc.: 80.47%] [G loss: 0.691517]\n",
      "epoch:9 step:8526 [D loss: 0.484759, acc.: 75.00%] [G loss: 0.734696]\n",
      "epoch:9 step:8527 [D loss: 0.434765, acc.: 80.47%] [G loss: 0.597258]\n",
      "epoch:9 step:8528 [D loss: 0.517431, acc.: 75.78%] [G loss: 0.685430]\n",
      "epoch:9 step:8529 [D loss: 0.559612, acc.: 69.53%] [G loss: 0.730532]\n",
      "epoch:9 step:8530 [D loss: 0.531315, acc.: 73.44%] [G loss: 0.615700]\n",
      "epoch:9 step:8531 [D loss: 0.563145, acc.: 68.75%] [G loss: 0.567761]\n",
      "epoch:9 step:8532 [D loss: 0.589708, acc.: 64.06%] [G loss: 0.736253]\n",
      "epoch:9 step:8533 [D loss: 0.446982, acc.: 77.34%] [G loss: 0.828974]\n",
      "epoch:9 step:8534 [D loss: 0.492063, acc.: 71.09%] [G loss: 0.662736]\n",
      "epoch:9 step:8535 [D loss: 0.598260, acc.: 68.75%] [G loss: 0.526545]\n",
      "epoch:9 step:8536 [D loss: 0.502173, acc.: 72.66%] [G loss: 0.545717]\n",
      "epoch:9 step:8537 [D loss: 0.550832, acc.: 70.31%] [G loss: 0.582656]\n",
      "epoch:9 step:8538 [D loss: 0.561064, acc.: 71.09%] [G loss: 0.560230]\n",
      "epoch:9 step:8539 [D loss: 0.550043, acc.: 70.31%] [G loss: 0.478450]\n",
      "epoch:9 step:8540 [D loss: 0.594662, acc.: 66.41%] [G loss: 0.494846]\n",
      "epoch:9 step:8541 [D loss: 0.668327, acc.: 53.12%] [G loss: 0.572964]\n",
      "epoch:9 step:8542 [D loss: 0.559430, acc.: 71.09%] [G loss: 0.580366]\n",
      "epoch:9 step:8543 [D loss: 0.558501, acc.: 71.88%] [G loss: 0.687412]\n",
      "epoch:9 step:8544 [D loss: 0.507775, acc.: 76.56%] [G loss: 0.539025]\n",
      "epoch:9 step:8545 [D loss: 0.486671, acc.: 78.12%] [G loss: 0.752708]\n",
      "epoch:9 step:8546 [D loss: 0.596528, acc.: 67.19%] [G loss: 0.529064]\n",
      "epoch:9 step:8547 [D loss: 0.605553, acc.: 66.41%] [G loss: 0.536250]\n",
      "epoch:9 step:8548 [D loss: 0.553982, acc.: 71.09%] [G loss: 0.473385]\n",
      "epoch:9 step:8549 [D loss: 0.546154, acc.: 69.53%] [G loss: 0.652856]\n",
      "epoch:9 step:8550 [D loss: 0.518569, acc.: 71.09%] [G loss: 0.804090]\n",
      "epoch:9 step:8551 [D loss: 0.608175, acc.: 64.84%] [G loss: 0.870071]\n",
      "epoch:9 step:8552 [D loss: 0.470296, acc.: 79.69%] [G loss: 0.806481]\n",
      "epoch:9 step:8553 [D loss: 0.601202, acc.: 67.19%] [G loss: 0.566275]\n",
      "epoch:9 step:8554 [D loss: 0.548842, acc.: 74.22%] [G loss: 0.581474]\n",
      "epoch:9 step:8555 [D loss: 0.513328, acc.: 75.78%] [G loss: 0.750488]\n",
      "epoch:9 step:8556 [D loss: 0.539788, acc.: 71.09%] [G loss: 0.822070]\n",
      "epoch:9 step:8557 [D loss: 0.580110, acc.: 67.19%] [G loss: 0.635755]\n",
      "epoch:9 step:8558 [D loss: 0.561114, acc.: 67.19%] [G loss: 0.604390]\n",
      "epoch:9 step:8559 [D loss: 0.538558, acc.: 77.34%] [G loss: 0.691015]\n",
      "epoch:9 step:8560 [D loss: 0.499022, acc.: 74.22%] [G loss: 0.532965]\n",
      "epoch:9 step:8561 [D loss: 0.501294, acc.: 77.34%] [G loss: 0.747875]\n",
      "epoch:9 step:8562 [D loss: 0.545386, acc.: 70.31%] [G loss: 0.565978]\n",
      "epoch:9 step:8563 [D loss: 0.489458, acc.: 75.00%] [G loss: 0.615129]\n",
      "epoch:9 step:8564 [D loss: 0.516477, acc.: 74.22%] [G loss: 0.620975]\n",
      "epoch:9 step:8565 [D loss: 0.552968, acc.: 70.31%] [G loss: 0.590665]\n",
      "epoch:9 step:8566 [D loss: 0.537929, acc.: 69.53%] [G loss: 0.730999]\n",
      "epoch:9 step:8567 [D loss: 0.527015, acc.: 73.44%] [G loss: 0.752306]\n",
      "epoch:9 step:8568 [D loss: 0.524831, acc.: 72.66%] [G loss: 0.518326]\n",
      "epoch:9 step:8569 [D loss: 0.512090, acc.: 73.44%] [G loss: 0.613250]\n",
      "epoch:9 step:8570 [D loss: 0.596836, acc.: 68.75%] [G loss: 0.548739]\n",
      "epoch:9 step:8571 [D loss: 0.586425, acc.: 63.28%] [G loss: 0.417844]\n",
      "epoch:9 step:8572 [D loss: 0.561720, acc.: 77.34%] [G loss: 0.553083]\n",
      "epoch:9 step:8573 [D loss: 0.564517, acc.: 69.53%] [G loss: 0.480389]\n",
      "epoch:9 step:8574 [D loss: 0.487269, acc.: 71.88%] [G loss: 0.551889]\n",
      "epoch:9 step:8575 [D loss: 0.572168, acc.: 65.62%] [G loss: 0.508684]\n",
      "epoch:9 step:8576 [D loss: 0.545191, acc.: 68.75%] [G loss: 0.571864]\n",
      "epoch:9 step:8577 [D loss: 0.507703, acc.: 75.78%] [G loss: 0.582853]\n",
      "epoch:9 step:8578 [D loss: 0.586460, acc.: 62.50%] [G loss: 0.639849]\n",
      "epoch:9 step:8579 [D loss: 0.478339, acc.: 78.12%] [G loss: 0.727938]\n",
      "epoch:9 step:8580 [D loss: 0.575418, acc.: 71.88%] [G loss: 0.590250]\n",
      "epoch:9 step:8581 [D loss: 0.568809, acc.: 70.31%] [G loss: 0.534399]\n",
      "epoch:9 step:8582 [D loss: 0.558910, acc.: 67.97%] [G loss: 0.631079]\n",
      "epoch:9 step:8583 [D loss: 0.613898, acc.: 62.50%] [G loss: 0.543348]\n",
      "epoch:9 step:8584 [D loss: 0.585343, acc.: 69.53%] [G loss: 0.516825]\n",
      "epoch:9 step:8585 [D loss: 0.486504, acc.: 76.56%] [G loss: 0.793010]\n",
      "epoch:9 step:8586 [D loss: 0.592861, acc.: 64.06%] [G loss: 0.585653]\n",
      "epoch:9 step:8587 [D loss: 0.509344, acc.: 71.09%] [G loss: 0.780682]\n",
      "epoch:9 step:8588 [D loss: 0.462417, acc.: 77.34%] [G loss: 0.664361]\n",
      "epoch:9 step:8589 [D loss: 0.535837, acc.: 67.19%] [G loss: 0.585376]\n",
      "epoch:9 step:8590 [D loss: 0.614891, acc.: 64.84%] [G loss: 0.469103]\n",
      "epoch:9 step:8591 [D loss: 0.579936, acc.: 66.41%] [G loss: 0.592703]\n",
      "epoch:9 step:8592 [D loss: 0.548128, acc.: 71.09%] [G loss: 0.560633]\n",
      "epoch:9 step:8593 [D loss: 0.587743, acc.: 67.19%] [G loss: 0.540203]\n",
      "epoch:9 step:8594 [D loss: 0.522416, acc.: 71.88%] [G loss: 0.596107]\n",
      "epoch:9 step:8595 [D loss: 0.457041, acc.: 74.22%] [G loss: 0.755901]\n",
      "epoch:9 step:8596 [D loss: 0.599997, acc.: 68.75%] [G loss: 0.809452]\n",
      "epoch:9 step:8597 [D loss: 0.588134, acc.: 65.62%] [G loss: 0.681582]\n",
      "epoch:9 step:8598 [D loss: 0.451195, acc.: 78.91%] [G loss: 0.687962]\n",
      "epoch:9 step:8599 [D loss: 0.540059, acc.: 72.66%] [G loss: 0.491992]\n",
      "epoch:9 step:8600 [D loss: 0.539866, acc.: 67.19%] [G loss: 0.446943]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:9 step:8601 [D loss: 0.532887, acc.: 71.88%] [G loss: 0.618659]\n",
      "epoch:9 step:8602 [D loss: 0.594780, acc.: 68.75%] [G loss: 0.407095]\n",
      "epoch:9 step:8603 [D loss: 0.466350, acc.: 77.34%] [G loss: 0.452951]\n",
      "epoch:9 step:8604 [D loss: 0.473046, acc.: 78.91%] [G loss: 0.528867]\n",
      "epoch:9 step:8605 [D loss: 0.516367, acc.: 65.62%] [G loss: 0.519670]\n",
      "epoch:9 step:8606 [D loss: 0.513277, acc.: 71.09%] [G loss: 0.548265]\n",
      "epoch:9 step:8607 [D loss: 0.584475, acc.: 62.50%] [G loss: 0.504082]\n",
      "epoch:9 step:8608 [D loss: 0.572626, acc.: 68.75%] [G loss: 0.568468]\n",
      "epoch:9 step:8609 [D loss: 0.519676, acc.: 68.75%] [G loss: 0.541626]\n",
      "epoch:9 step:8610 [D loss: 0.488874, acc.: 74.22%] [G loss: 0.552977]\n",
      "epoch:9 step:8611 [D loss: 0.561090, acc.: 70.31%] [G loss: 0.412301]\n",
      "epoch:9 step:8612 [D loss: 0.505588, acc.: 72.66%] [G loss: 0.508407]\n",
      "epoch:9 step:8613 [D loss: 0.605506, acc.: 64.06%] [G loss: 0.340732]\n",
      "epoch:9 step:8614 [D loss: 0.591905, acc.: 68.75%] [G loss: 0.483984]\n",
      "epoch:9 step:8615 [D loss: 0.561881, acc.: 69.53%] [G loss: 0.630176]\n",
      "epoch:9 step:8616 [D loss: 0.555489, acc.: 71.88%] [G loss: 0.616838]\n",
      "epoch:9 step:8617 [D loss: 0.547035, acc.: 73.44%] [G loss: 0.574594]\n",
      "epoch:9 step:8618 [D loss: 0.622990, acc.: 58.59%] [G loss: 0.496927]\n",
      "epoch:9 step:8619 [D loss: 0.567351, acc.: 66.41%] [G loss: 0.568260]\n",
      "epoch:9 step:8620 [D loss: 0.605695, acc.: 63.28%] [G loss: 0.463451]\n",
      "epoch:9 step:8621 [D loss: 0.565272, acc.: 67.19%] [G loss: 0.518761]\n",
      "epoch:9 step:8622 [D loss: 0.555214, acc.: 68.75%] [G loss: 0.461985]\n",
      "epoch:9 step:8623 [D loss: 0.494050, acc.: 77.34%] [G loss: 0.579039]\n",
      "epoch:9 step:8624 [D loss: 0.499462, acc.: 71.09%] [G loss: 0.640235]\n",
      "epoch:9 step:8625 [D loss: 0.554528, acc.: 67.97%] [G loss: 0.612772]\n",
      "epoch:9 step:8626 [D loss: 0.555371, acc.: 70.31%] [G loss: 0.542555]\n",
      "epoch:9 step:8627 [D loss: 0.435228, acc.: 82.81%] [G loss: 0.683472]\n",
      "epoch:9 step:8628 [D loss: 0.590294, acc.: 67.97%] [G loss: 0.719614]\n",
      "epoch:9 step:8629 [D loss: 0.586601, acc.: 66.41%] [G loss: 0.593996]\n",
      "epoch:9 step:8630 [D loss: 0.584442, acc.: 71.09%] [G loss: 0.595461]\n",
      "epoch:9 step:8631 [D loss: 0.496786, acc.: 74.22%] [G loss: 0.677033]\n",
      "epoch:9 step:8632 [D loss: 0.510147, acc.: 74.22%] [G loss: 0.765826]\n",
      "epoch:9 step:8633 [D loss: 0.585591, acc.: 65.62%] [G loss: 0.672370]\n",
      "epoch:9 step:8634 [D loss: 0.580919, acc.: 70.31%] [G loss: 0.670233]\n",
      "epoch:9 step:8635 [D loss: 0.541405, acc.: 71.88%] [G loss: 0.642454]\n",
      "epoch:9 step:8636 [D loss: 0.653578, acc.: 62.50%] [G loss: 0.514095]\n",
      "epoch:9 step:8637 [D loss: 0.556651, acc.: 68.75%] [G loss: 0.537805]\n",
      "epoch:9 step:8638 [D loss: 0.480236, acc.: 75.78%] [G loss: 0.765859]\n",
      "epoch:9 step:8639 [D loss: 0.512803, acc.: 71.88%] [G loss: 0.554064]\n",
      "epoch:9 step:8640 [D loss: 0.464035, acc.: 79.69%] [G loss: 0.627564]\n",
      "epoch:9 step:8641 [D loss: 0.468169, acc.: 77.34%] [G loss: 0.714272]\n",
      "epoch:9 step:8642 [D loss: 0.512594, acc.: 76.56%] [G loss: 0.614460]\n",
      "epoch:9 step:8643 [D loss: 0.636831, acc.: 66.41%] [G loss: 0.471797]\n",
      "epoch:9 step:8644 [D loss: 0.581918, acc.: 64.06%] [G loss: 0.464898]\n",
      "epoch:9 step:8645 [D loss: 0.552531, acc.: 75.00%] [G loss: 0.577266]\n",
      "epoch:9 step:8646 [D loss: 0.497307, acc.: 75.00%] [G loss: 0.523350]\n",
      "epoch:9 step:8647 [D loss: 0.638535, acc.: 63.28%] [G loss: 0.418746]\n",
      "epoch:9 step:8648 [D loss: 0.571626, acc.: 63.28%] [G loss: 0.521389]\n",
      "epoch:9 step:8649 [D loss: 0.592162, acc.: 65.62%] [G loss: 0.518296]\n",
      "epoch:9 step:8650 [D loss: 0.519948, acc.: 75.00%] [G loss: 0.611355]\n",
      "epoch:9 step:8651 [D loss: 0.507232, acc.: 77.34%] [G loss: 0.640953]\n",
      "epoch:9 step:8652 [D loss: 0.551157, acc.: 73.44%] [G loss: 0.566668]\n",
      "epoch:9 step:8653 [D loss: 0.676849, acc.: 67.97%] [G loss: 0.547530]\n",
      "epoch:9 step:8654 [D loss: 0.508380, acc.: 72.66%] [G loss: 0.636556]\n",
      "epoch:9 step:8655 [D loss: 0.516299, acc.: 70.31%] [G loss: 0.560606]\n",
      "epoch:9 step:8656 [D loss: 0.506263, acc.: 76.56%] [G loss: 0.656426]\n",
      "epoch:9 step:8657 [D loss: 0.595112, acc.: 64.06%] [G loss: 0.575589]\n",
      "epoch:9 step:8658 [D loss: 0.561549, acc.: 66.41%] [G loss: 0.533508]\n",
      "epoch:9 step:8659 [D loss: 0.618001, acc.: 62.50%] [G loss: 0.436567]\n",
      "epoch:9 step:8660 [D loss: 0.611542, acc.: 61.72%] [G loss: 0.487399]\n",
      "epoch:9 step:8661 [D loss: 0.551039, acc.: 71.88%] [G loss: 0.584849]\n",
      "epoch:9 step:8662 [D loss: 0.544938, acc.: 78.91%] [G loss: 0.440360]\n",
      "epoch:9 step:8663 [D loss: 0.481289, acc.: 75.00%] [G loss: 0.571514]\n",
      "epoch:9 step:8664 [D loss: 0.431151, acc.: 80.47%] [G loss: 0.783381]\n",
      "epoch:9 step:8665 [D loss: 0.475970, acc.: 80.47%] [G loss: 0.765373]\n",
      "epoch:9 step:8666 [D loss: 0.529178, acc.: 70.31%] [G loss: 0.724918]\n",
      "epoch:9 step:8667 [D loss: 0.591471, acc.: 66.41%] [G loss: 0.585530]\n",
      "epoch:9 step:8668 [D loss: 0.566392, acc.: 69.53%] [G loss: 0.586094]\n",
      "epoch:9 step:8669 [D loss: 0.533423, acc.: 71.88%] [G loss: 0.521455]\n",
      "epoch:9 step:8670 [D loss: 0.614091, acc.: 64.84%] [G loss: 0.533361]\n",
      "epoch:9 step:8671 [D loss: 0.565296, acc.: 65.62%] [G loss: 0.498640]\n",
      "epoch:9 step:8672 [D loss: 0.531815, acc.: 70.31%] [G loss: 0.478075]\n",
      "epoch:9 step:8673 [D loss: 0.525466, acc.: 71.09%] [G loss: 0.463598]\n",
      "epoch:9 step:8674 [D loss: 0.580913, acc.: 66.41%] [G loss: 0.544490]\n",
      "epoch:9 step:8675 [D loss: 0.525507, acc.: 71.09%] [G loss: 0.672286]\n",
      "epoch:9 step:8676 [D loss: 0.508326, acc.: 71.88%] [G loss: 0.661821]\n",
      "epoch:9 step:8677 [D loss: 0.480736, acc.: 78.12%] [G loss: 0.619309]\n",
      "epoch:9 step:8678 [D loss: 0.578139, acc.: 67.19%] [G loss: 0.508595]\n",
      "epoch:9 step:8679 [D loss: 0.566709, acc.: 67.97%] [G loss: 0.670393]\n",
      "epoch:9 step:8680 [D loss: 0.528920, acc.: 72.66%] [G loss: 0.627591]\n",
      "epoch:9 step:8681 [D loss: 0.515792, acc.: 76.56%] [G loss: 0.735817]\n",
      "epoch:9 step:8682 [D loss: 0.530903, acc.: 72.66%] [G loss: 0.609415]\n",
      "epoch:9 step:8683 [D loss: 0.625256, acc.: 63.28%] [G loss: 0.558059]\n",
      "epoch:9 step:8684 [D loss: 0.591275, acc.: 67.19%] [G loss: 0.628224]\n",
      "epoch:9 step:8685 [D loss: 0.556323, acc.: 72.66%] [G loss: 0.631319]\n",
      "epoch:9 step:8686 [D loss: 0.551636, acc.: 71.88%] [G loss: 0.522526]\n",
      "epoch:9 step:8687 [D loss: 0.534134, acc.: 72.66%] [G loss: 0.538044]\n",
      "epoch:9 step:8688 [D loss: 0.532066, acc.: 71.88%] [G loss: 0.674250]\n",
      "epoch:9 step:8689 [D loss: 0.508284, acc.: 74.22%] [G loss: 0.739923]\n",
      "epoch:9 step:8690 [D loss: 0.539139, acc.: 72.66%] [G loss: 0.606257]\n",
      "epoch:9 step:8691 [D loss: 0.495324, acc.: 74.22%] [G loss: 0.608075]\n",
      "epoch:9 step:8692 [D loss: 0.503534, acc.: 76.56%] [G loss: 0.600683]\n",
      "epoch:9 step:8693 [D loss: 0.558699, acc.: 67.97%] [G loss: 0.530145]\n",
      "epoch:9 step:8694 [D loss: 0.518933, acc.: 73.44%] [G loss: 0.505491]\n",
      "epoch:9 step:8695 [D loss: 0.539573, acc.: 74.22%] [G loss: 0.634464]\n",
      "epoch:9 step:8696 [D loss: 0.597417, acc.: 71.88%] [G loss: 0.525563]\n",
      "epoch:9 step:8697 [D loss: 0.534057, acc.: 71.88%] [G loss: 0.550552]\n",
      "epoch:9 step:8698 [D loss: 0.556970, acc.: 69.53%] [G loss: 0.535273]\n",
      "epoch:9 step:8699 [D loss: 0.523831, acc.: 69.53%] [G loss: 0.655810]\n",
      "epoch:9 step:8700 [D loss: 0.607157, acc.: 64.84%] [G loss: 0.602461]\n",
      "epoch:9 step:8701 [D loss: 0.517187, acc.: 71.88%] [G loss: 0.573456]\n",
      "epoch:9 step:8702 [D loss: 0.581311, acc.: 70.31%] [G loss: 0.526550]\n",
      "epoch:9 step:8703 [D loss: 0.460127, acc.: 80.47%] [G loss: 0.652079]\n",
      "epoch:9 step:8704 [D loss: 0.470847, acc.: 78.12%] [G loss: 0.724125]\n",
      "epoch:9 step:8705 [D loss: 0.541456, acc.: 70.31%] [G loss: 0.733801]\n",
      "epoch:9 step:8706 [D loss: 0.510398, acc.: 75.78%] [G loss: 0.667917]\n",
      "epoch:9 step:8707 [D loss: 0.557001, acc.: 71.88%] [G loss: 0.628170]\n",
      "epoch:9 step:8708 [D loss: 0.556214, acc.: 74.22%] [G loss: 0.487874]\n",
      "epoch:9 step:8709 [D loss: 0.512598, acc.: 74.22%] [G loss: 0.654305]\n",
      "epoch:9 step:8710 [D loss: 0.588145, acc.: 70.31%] [G loss: 0.465524]\n",
      "epoch:9 step:8711 [D loss: 0.608137, acc.: 64.84%] [G loss: 0.365207]\n",
      "epoch:9 step:8712 [D loss: 0.599723, acc.: 60.94%] [G loss: 0.517251]\n",
      "epoch:9 step:8713 [D loss: 0.557895, acc.: 67.19%] [G loss: 0.451261]\n",
      "epoch:9 step:8714 [D loss: 0.594967, acc.: 71.09%] [G loss: 0.504660]\n",
      "epoch:9 step:8715 [D loss: 0.541553, acc.: 75.78%] [G loss: 0.532258]\n",
      "epoch:9 step:8716 [D loss: 0.493350, acc.: 76.56%] [G loss: 0.625507]\n",
      "epoch:9 step:8717 [D loss: 0.554219, acc.: 67.97%] [G loss: 0.482006]\n",
      "epoch:9 step:8718 [D loss: 0.513218, acc.: 69.53%] [G loss: 0.628687]\n",
      "epoch:9 step:8719 [D loss: 0.480340, acc.: 74.22%] [G loss: 0.645864]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:9 step:8720 [D loss: 0.586932, acc.: 69.53%] [G loss: 0.644350]\n",
      "epoch:9 step:8721 [D loss: 0.567639, acc.: 68.75%] [G loss: 0.617067]\n",
      "epoch:9 step:8722 [D loss: 0.537351, acc.: 71.09%] [G loss: 0.600562]\n",
      "epoch:9 step:8723 [D loss: 0.544422, acc.: 69.53%] [G loss: 0.623406]\n",
      "epoch:9 step:8724 [D loss: 0.595829, acc.: 64.84%] [G loss: 0.594618]\n",
      "epoch:9 step:8725 [D loss: 0.514792, acc.: 73.44%] [G loss: 0.607651]\n",
      "epoch:9 step:8726 [D loss: 0.577472, acc.: 67.19%] [G loss: 0.472008]\n",
      "epoch:9 step:8727 [D loss: 0.541882, acc.: 71.09%] [G loss: 0.577823]\n",
      "epoch:9 step:8728 [D loss: 0.548234, acc.: 70.31%] [G loss: 0.433354]\n",
      "epoch:9 step:8729 [D loss: 0.482098, acc.: 80.47%] [G loss: 0.548734]\n",
      "epoch:9 step:8730 [D loss: 0.579188, acc.: 67.97%] [G loss: 0.571966]\n",
      "epoch:9 step:8731 [D loss: 0.511663, acc.: 71.88%] [G loss: 0.652362]\n",
      "epoch:9 step:8732 [D loss: 0.493925, acc.: 77.34%] [G loss: 0.665592]\n",
      "epoch:9 step:8733 [D loss: 0.477545, acc.: 79.69%] [G loss: 0.607031]\n",
      "epoch:9 step:8734 [D loss: 0.591017, acc.: 66.41%] [G loss: 0.544728]\n",
      "epoch:9 step:8735 [D loss: 0.515212, acc.: 72.66%] [G loss: 0.535606]\n",
      "epoch:9 step:8736 [D loss: 0.530086, acc.: 71.88%] [G loss: 0.614315]\n",
      "epoch:9 step:8737 [D loss: 0.483250, acc.: 75.00%] [G loss: 0.548681]\n",
      "epoch:9 step:8738 [D loss: 0.533058, acc.: 72.66%] [G loss: 0.582159]\n",
      "epoch:9 step:8739 [D loss: 0.580528, acc.: 71.09%] [G loss: 0.618088]\n",
      "epoch:9 step:8740 [D loss: 0.510111, acc.: 72.66%] [G loss: 0.674819]\n",
      "epoch:9 step:8741 [D loss: 0.555055, acc.: 71.09%] [G loss: 0.479383]\n",
      "epoch:9 step:8742 [D loss: 0.508846, acc.: 74.22%] [G loss: 0.632040]\n",
      "epoch:9 step:8743 [D loss: 0.556103, acc.: 71.88%] [G loss: 0.662723]\n",
      "epoch:9 step:8744 [D loss: 0.436475, acc.: 80.47%] [G loss: 0.737733]\n",
      "epoch:9 step:8745 [D loss: 0.445293, acc.: 82.81%] [G loss: 0.622376]\n",
      "epoch:9 step:8746 [D loss: 0.518568, acc.: 72.66%] [G loss: 0.755399]\n",
      "epoch:9 step:8747 [D loss: 0.419276, acc.: 83.59%] [G loss: 0.740379]\n",
      "epoch:9 step:8748 [D loss: 0.451193, acc.: 80.47%] [G loss: 0.929023]\n",
      "epoch:9 step:8749 [D loss: 0.662937, acc.: 64.06%] [G loss: 0.612285]\n",
      "epoch:9 step:8750 [D loss: 0.593073, acc.: 63.28%] [G loss: 0.514428]\n",
      "epoch:9 step:8751 [D loss: 0.597120, acc.: 62.50%] [G loss: 0.499519]\n",
      "epoch:9 step:8752 [D loss: 0.569896, acc.: 71.88%] [G loss: 0.602840]\n",
      "epoch:9 step:8753 [D loss: 0.567147, acc.: 67.19%] [G loss: 0.550615]\n",
      "epoch:9 step:8754 [D loss: 0.442490, acc.: 81.25%] [G loss: 0.707901]\n",
      "epoch:9 step:8755 [D loss: 0.605559, acc.: 65.62%] [G loss: 0.619857]\n",
      "epoch:9 step:8756 [D loss: 0.542399, acc.: 71.09%] [G loss: 0.477816]\n",
      "epoch:9 step:8757 [D loss: 0.545005, acc.: 72.66%] [G loss: 0.467427]\n",
      "epoch:9 step:8758 [D loss: 0.546743, acc.: 69.53%] [G loss: 0.582705]\n",
      "epoch:9 step:8759 [D loss: 0.506109, acc.: 67.97%] [G loss: 0.673580]\n",
      "epoch:9 step:8760 [D loss: 0.477160, acc.: 78.91%] [G loss: 0.678183]\n",
      "epoch:9 step:8761 [D loss: 0.493570, acc.: 77.34%] [G loss: 0.630479]\n",
      "epoch:9 step:8762 [D loss: 0.491799, acc.: 78.91%] [G loss: 0.568900]\n",
      "epoch:9 step:8763 [D loss: 0.559047, acc.: 70.31%] [G loss: 0.614550]\n",
      "epoch:9 step:8764 [D loss: 0.522701, acc.: 79.69%] [G loss: 0.708143]\n",
      "epoch:9 step:8765 [D loss: 0.515639, acc.: 71.88%] [G loss: 0.593014]\n",
      "epoch:9 step:8766 [D loss: 0.471388, acc.: 76.56%] [G loss: 0.539254]\n",
      "epoch:9 step:8767 [D loss: 0.527309, acc.: 71.88%] [G loss: 0.561333]\n",
      "epoch:9 step:8768 [D loss: 0.484277, acc.: 75.00%] [G loss: 0.738030]\n",
      "epoch:9 step:8769 [D loss: 0.488210, acc.: 73.44%] [G loss: 0.655749]\n",
      "epoch:9 step:8770 [D loss: 0.529150, acc.: 71.09%] [G loss: 0.727691]\n",
      "epoch:9 step:8771 [D loss: 0.539695, acc.: 68.75%] [G loss: 0.586021]\n",
      "epoch:9 step:8772 [D loss: 0.513800, acc.: 73.44%] [G loss: 0.598103]\n",
      "epoch:9 step:8773 [D loss: 0.498250, acc.: 72.66%] [G loss: 0.775472]\n",
      "epoch:9 step:8774 [D loss: 0.597810, acc.: 67.19%] [G loss: 0.805856]\n",
      "epoch:9 step:8775 [D loss: 0.663570, acc.: 57.03%] [G loss: 0.603972]\n",
      "epoch:9 step:8776 [D loss: 0.481387, acc.: 77.34%] [G loss: 0.596428]\n",
      "epoch:9 step:8777 [D loss: 0.464215, acc.: 75.78%] [G loss: 0.688235]\n",
      "epoch:9 step:8778 [D loss: 0.570101, acc.: 67.97%] [G loss: 0.662626]\n",
      "epoch:9 step:8779 [D loss: 0.566102, acc.: 67.97%] [G loss: 0.657110]\n",
      "epoch:9 step:8780 [D loss: 0.457692, acc.: 79.69%] [G loss: 0.770278]\n",
      "epoch:9 step:8781 [D loss: 0.641464, acc.: 62.50%] [G loss: 0.579542]\n",
      "epoch:9 step:8782 [D loss: 0.725584, acc.: 57.03%] [G loss: 0.487005]\n",
      "epoch:9 step:8783 [D loss: 0.501800, acc.: 72.66%] [G loss: 0.503870]\n",
      "epoch:9 step:8784 [D loss: 0.541746, acc.: 71.88%] [G loss: 0.660220]\n",
      "epoch:9 step:8785 [D loss: 0.571851, acc.: 71.09%] [G loss: 0.762676]\n",
      "epoch:9 step:8786 [D loss: 0.534716, acc.: 71.88%] [G loss: 0.670776]\n",
      "epoch:9 step:8787 [D loss: 0.367868, acc.: 81.25%] [G loss: 0.838208]\n",
      "epoch:9 step:8788 [D loss: 0.559766, acc.: 69.53%] [G loss: 0.629718]\n",
      "epoch:9 step:8789 [D loss: 0.553172, acc.: 68.75%] [G loss: 0.633163]\n",
      "epoch:9 step:8790 [D loss: 0.484209, acc.: 73.44%] [G loss: 0.612275]\n",
      "epoch:9 step:8791 [D loss: 0.437315, acc.: 78.91%] [G loss: 0.624900]\n",
      "epoch:9 step:8792 [D loss: 0.449556, acc.: 78.91%] [G loss: 0.806383]\n",
      "epoch:9 step:8793 [D loss: 0.503951, acc.: 71.88%] [G loss: 0.685723]\n",
      "epoch:9 step:8794 [D loss: 0.520991, acc.: 73.44%] [G loss: 0.660779]\n",
      "epoch:9 step:8795 [D loss: 0.587140, acc.: 67.97%] [G loss: 0.683322]\n",
      "epoch:9 step:8796 [D loss: 0.565766, acc.: 71.09%] [G loss: 0.599420]\n",
      "epoch:9 step:8797 [D loss: 0.489257, acc.: 76.56%] [G loss: 0.530928]\n",
      "epoch:9 step:8798 [D loss: 0.548119, acc.: 71.09%] [G loss: 0.627966]\n",
      "epoch:9 step:8799 [D loss: 0.491968, acc.: 72.66%] [G loss: 0.636350]\n",
      "epoch:9 step:8800 [D loss: 0.495836, acc.: 76.56%] [G loss: 0.557101]\n",
      "epoch:9 step:8801 [D loss: 0.493981, acc.: 75.78%] [G loss: 0.447538]\n",
      "epoch:9 step:8802 [D loss: 0.553990, acc.: 68.75%] [G loss: 0.494023]\n",
      "epoch:9 step:8803 [D loss: 0.483408, acc.: 78.91%] [G loss: 0.641166]\n",
      "epoch:9 step:8804 [D loss: 0.492623, acc.: 75.78%] [G loss: 0.792241]\n",
      "epoch:9 step:8805 [D loss: 0.545359, acc.: 70.31%] [G loss: 0.705668]\n",
      "epoch:9 step:8806 [D loss: 0.556659, acc.: 73.44%] [G loss: 0.651159]\n",
      "epoch:9 step:8807 [D loss: 0.451023, acc.: 78.12%] [G loss: 0.786700]\n",
      "epoch:9 step:8808 [D loss: 0.549848, acc.: 71.88%] [G loss: 0.591498]\n",
      "epoch:9 step:8809 [D loss: 0.711467, acc.: 55.47%] [G loss: 0.418868]\n",
      "epoch:9 step:8810 [D loss: 0.569186, acc.: 64.06%] [G loss: 0.598480]\n",
      "epoch:9 step:8811 [D loss: 0.522823, acc.: 75.78%] [G loss: 0.612556]\n",
      "epoch:9 step:8812 [D loss: 0.565812, acc.: 67.97%] [G loss: 0.706467]\n",
      "epoch:9 step:8813 [D loss: 0.636180, acc.: 66.41%] [G loss: 0.479820]\n",
      "epoch:9 step:8814 [D loss: 0.459131, acc.: 78.12%] [G loss: 0.515061]\n",
      "epoch:9 step:8815 [D loss: 0.583351, acc.: 71.09%] [G loss: 0.592996]\n",
      "epoch:9 step:8816 [D loss: 0.545027, acc.: 71.88%] [G loss: 0.600381]\n",
      "epoch:9 step:8817 [D loss: 0.564251, acc.: 67.19%] [G loss: 0.613335]\n",
      "epoch:9 step:8818 [D loss: 0.494013, acc.: 73.44%] [G loss: 0.641672]\n",
      "epoch:9 step:8819 [D loss: 0.659876, acc.: 58.59%] [G loss: 0.522906]\n",
      "epoch:9 step:8820 [D loss: 0.590633, acc.: 66.41%] [G loss: 0.592356]\n",
      "epoch:9 step:8821 [D loss: 0.502974, acc.: 77.34%] [G loss: 0.622297]\n",
      "epoch:9 step:8822 [D loss: 0.523252, acc.: 72.66%] [G loss: 0.621454]\n",
      "epoch:9 step:8823 [D loss: 0.614335, acc.: 66.41%] [G loss: 0.506933]\n",
      "epoch:9 step:8824 [D loss: 0.489687, acc.: 75.00%] [G loss: 0.607048]\n",
      "epoch:9 step:8825 [D loss: 0.512127, acc.: 74.22%] [G loss: 0.682608]\n",
      "epoch:9 step:8826 [D loss: 0.546123, acc.: 70.31%] [G loss: 0.462277]\n",
      "epoch:9 step:8827 [D loss: 0.611150, acc.: 65.62%] [G loss: 0.580837]\n",
      "epoch:9 step:8828 [D loss: 0.536512, acc.: 71.09%] [G loss: 0.410181]\n",
      "epoch:9 step:8829 [D loss: 0.529588, acc.: 68.75%] [G loss: 0.575439]\n",
      "epoch:9 step:8830 [D loss: 0.558658, acc.: 70.31%] [G loss: 0.563931]\n",
      "epoch:9 step:8831 [D loss: 0.455375, acc.: 80.47%] [G loss: 0.801135]\n",
      "epoch:9 step:8832 [D loss: 0.519224, acc.: 74.22%] [G loss: 0.770127]\n",
      "epoch:9 step:8833 [D loss: 0.627604, acc.: 61.72%] [G loss: 0.692711]\n",
      "epoch:9 step:8834 [D loss: 0.639921, acc.: 61.72%] [G loss: 0.453459]\n",
      "epoch:9 step:8835 [D loss: 0.450435, acc.: 78.91%] [G loss: 0.660378]\n",
      "epoch:9 step:8836 [D loss: 0.499264, acc.: 75.78%] [G loss: 0.712276]\n",
      "epoch:9 step:8837 [D loss: 0.606993, acc.: 63.28%] [G loss: 0.576854]\n",
      "epoch:9 step:8838 [D loss: 0.598989, acc.: 66.41%] [G loss: 0.667524]\n",
      "epoch:9 step:8839 [D loss: 0.496389, acc.: 75.00%] [G loss: 0.614292]\n",
      "epoch:9 step:8840 [D loss: 0.568064, acc.: 64.06%] [G loss: 0.712933]\n",
      "epoch:9 step:8841 [D loss: 0.605480, acc.: 66.41%] [G loss: 0.598949]\n",
      "epoch:9 step:8842 [D loss: 0.585231, acc.: 63.28%] [G loss: 0.587353]\n",
      "epoch:9 step:8843 [D loss: 0.580676, acc.: 63.28%] [G loss: 0.430144]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:9 step:8844 [D loss: 0.537572, acc.: 71.88%] [G loss: 0.524275]\n",
      "epoch:9 step:8845 [D loss: 0.603693, acc.: 64.06%] [G loss: 0.433266]\n",
      "epoch:9 step:8846 [D loss: 0.554127, acc.: 70.31%] [G loss: 0.419821]\n",
      "epoch:9 step:8847 [D loss: 0.522874, acc.: 68.75%] [G loss: 0.604268]\n",
      "epoch:9 step:8848 [D loss: 0.614469, acc.: 64.84%] [G loss: 0.549052]\n",
      "epoch:9 step:8849 [D loss: 0.495169, acc.: 77.34%] [G loss: 0.645377]\n",
      "epoch:9 step:8850 [D loss: 0.616622, acc.: 64.06%] [G loss: 0.611052]\n",
      "epoch:9 step:8851 [D loss: 0.607797, acc.: 62.50%] [G loss: 0.468767]\n",
      "epoch:9 step:8852 [D loss: 0.540565, acc.: 71.09%] [G loss: 0.546644]\n",
      "epoch:9 step:8853 [D loss: 0.647994, acc.: 62.50%] [G loss: 0.481583]\n",
      "epoch:9 step:8854 [D loss: 0.544145, acc.: 69.53%] [G loss: 0.611050]\n",
      "epoch:9 step:8855 [D loss: 0.562434, acc.: 64.84%] [G loss: 0.661804]\n",
      "epoch:9 step:8856 [D loss: 0.539552, acc.: 67.19%] [G loss: 0.533490]\n",
      "epoch:9 step:8857 [D loss: 0.574933, acc.: 67.19%] [G loss: 0.488374]\n",
      "epoch:9 step:8858 [D loss: 0.529723, acc.: 71.09%] [G loss: 0.633269]\n",
      "epoch:9 step:8859 [D loss: 0.465165, acc.: 74.22%] [G loss: 0.939183]\n",
      "epoch:9 step:8860 [D loss: 0.534915, acc.: 72.66%] [G loss: 0.837007]\n",
      "epoch:9 step:8861 [D loss: 0.490721, acc.: 79.69%] [G loss: 0.728144]\n",
      "epoch:9 step:8862 [D loss: 0.471172, acc.: 76.56%] [G loss: 0.768898]\n",
      "epoch:9 step:8863 [D loss: 0.508347, acc.: 73.44%] [G loss: 0.658880]\n",
      "epoch:9 step:8864 [D loss: 0.538285, acc.: 70.31%] [G loss: 0.639233]\n",
      "epoch:9 step:8865 [D loss: 0.554850, acc.: 68.75%] [G loss: 0.628191]\n",
      "epoch:9 step:8866 [D loss: 0.565578, acc.: 63.28%] [G loss: 0.463611]\n",
      "epoch:9 step:8867 [D loss: 0.504048, acc.: 74.22%] [G loss: 0.581044]\n",
      "epoch:9 step:8868 [D loss: 0.537643, acc.: 69.53%] [G loss: 0.421286]\n",
      "epoch:9 step:8869 [D loss: 0.435696, acc.: 79.69%] [G loss: 0.801523]\n",
      "epoch:9 step:8870 [D loss: 0.706284, acc.: 60.16%] [G loss: 0.503864]\n",
      "epoch:9 step:8871 [D loss: 0.579415, acc.: 66.41%] [G loss: 0.435815]\n",
      "epoch:9 step:8872 [D loss: 0.517647, acc.: 78.12%] [G loss: 0.728387]\n",
      "epoch:9 step:8873 [D loss: 0.515912, acc.: 71.09%] [G loss: 0.732036]\n",
      "epoch:9 step:8874 [D loss: 0.549582, acc.: 70.31%] [G loss: 0.784729]\n",
      "epoch:9 step:8875 [D loss: 0.519967, acc.: 68.75%] [G loss: 0.567456]\n",
      "epoch:9 step:8876 [D loss: 0.516160, acc.: 72.66%] [G loss: 0.560382]\n",
      "epoch:9 step:8877 [D loss: 0.522845, acc.: 72.66%] [G loss: 0.627702]\n",
      "epoch:9 step:8878 [D loss: 0.563854, acc.: 67.97%] [G loss: 0.549138]\n",
      "epoch:9 step:8879 [D loss: 0.540882, acc.: 67.97%] [G loss: 0.542961]\n",
      "epoch:9 step:8880 [D loss: 0.506150, acc.: 71.09%] [G loss: 0.702311]\n",
      "epoch:9 step:8881 [D loss: 0.531632, acc.: 70.31%] [G loss: 0.680075]\n",
      "epoch:9 step:8882 [D loss: 0.461020, acc.: 71.88%] [G loss: 0.637322]\n",
      "epoch:9 step:8883 [D loss: 0.508138, acc.: 72.66%] [G loss: 0.574989]\n",
      "epoch:9 step:8884 [D loss: 0.465155, acc.: 75.78%] [G loss: 0.680088]\n",
      "epoch:9 step:8885 [D loss: 0.503995, acc.: 73.44%] [G loss: 0.781230]\n",
      "epoch:9 step:8886 [D loss: 0.502000, acc.: 76.56%] [G loss: 0.679269]\n",
      "epoch:9 step:8887 [D loss: 0.583839, acc.: 71.88%] [G loss: 0.459750]\n",
      "epoch:9 step:8888 [D loss: 0.533059, acc.: 74.22%] [G loss: 0.608853]\n",
      "epoch:9 step:8889 [D loss: 0.556687, acc.: 69.53%] [G loss: 0.634948]\n",
      "epoch:9 step:8890 [D loss: 0.497636, acc.: 73.44%] [G loss: 0.645965]\n",
      "epoch:9 step:8891 [D loss: 0.621175, acc.: 65.62%] [G loss: 0.578379]\n",
      "epoch:9 step:8892 [D loss: 0.573878, acc.: 67.19%] [G loss: 0.454363]\n",
      "epoch:9 step:8893 [D loss: 0.523389, acc.: 71.88%] [G loss: 0.714982]\n",
      "epoch:9 step:8894 [D loss: 0.511448, acc.: 75.00%] [G loss: 0.696890]\n",
      "epoch:9 step:8895 [D loss: 0.597614, acc.: 66.41%] [G loss: 0.683127]\n",
      "epoch:9 step:8896 [D loss: 0.566027, acc.: 67.19%] [G loss: 0.548034]\n",
      "epoch:9 step:8897 [D loss: 0.527754, acc.: 72.66%] [G loss: 0.640335]\n",
      "epoch:9 step:8898 [D loss: 0.560521, acc.: 70.31%] [G loss: 0.571083]\n",
      "epoch:9 step:8899 [D loss: 0.553131, acc.: 70.31%] [G loss: 0.604893]\n",
      "epoch:9 step:8900 [D loss: 0.624170, acc.: 69.53%] [G loss: 0.682415]\n",
      "epoch:9 step:8901 [D loss: 0.521412, acc.: 72.66%] [G loss: 0.695628]\n",
      "epoch:9 step:8902 [D loss: 0.556872, acc.: 71.09%] [G loss: 0.553845]\n",
      "epoch:9 step:8903 [D loss: 0.559959, acc.: 67.97%] [G loss: 0.449878]\n",
      "epoch:9 step:8904 [D loss: 0.473866, acc.: 77.34%] [G loss: 0.661038]\n",
      "epoch:9 step:8905 [D loss: 0.478598, acc.: 75.78%] [G loss: 0.864567]\n",
      "epoch:9 step:8906 [D loss: 0.640662, acc.: 62.50%] [G loss: 0.578267]\n",
      "epoch:9 step:8907 [D loss: 0.558098, acc.: 70.31%] [G loss: 0.701328]\n",
      "epoch:9 step:8908 [D loss: 0.482960, acc.: 75.00%] [G loss: 0.691022]\n",
      "epoch:9 step:8909 [D loss: 0.567533, acc.: 67.19%] [G loss: 0.521106]\n",
      "epoch:9 step:8910 [D loss: 0.643561, acc.: 60.94%] [G loss: 0.527065]\n",
      "epoch:9 step:8911 [D loss: 0.562204, acc.: 71.09%] [G loss: 0.419941]\n",
      "epoch:9 step:8912 [D loss: 0.552505, acc.: 72.66%] [G loss: 0.456761]\n",
      "epoch:9 step:8913 [D loss: 0.623047, acc.: 64.84%] [G loss: 0.542434]\n",
      "epoch:9 step:8914 [D loss: 0.512215, acc.: 79.69%] [G loss: 0.524694]\n",
      "epoch:9 step:8915 [D loss: 0.597503, acc.: 67.19%] [G loss: 0.426640]\n",
      "epoch:9 step:8916 [D loss: 0.557215, acc.: 67.97%] [G loss: 0.627221]\n",
      "epoch:9 step:8917 [D loss: 0.527292, acc.: 72.66%] [G loss: 0.695583]\n",
      "epoch:9 step:8918 [D loss: 0.565165, acc.: 71.09%] [G loss: 0.841631]\n",
      "epoch:9 step:8919 [D loss: 0.540568, acc.: 75.00%] [G loss: 0.607291]\n",
      "epoch:9 step:8920 [D loss: 0.494899, acc.: 79.69%] [G loss: 0.582305]\n",
      "epoch:9 step:8921 [D loss: 0.520555, acc.: 66.41%] [G loss: 0.570855]\n",
      "epoch:9 step:8922 [D loss: 0.535602, acc.: 72.66%] [G loss: 0.581585]\n",
      "epoch:9 step:8923 [D loss: 0.574854, acc.: 71.09%] [G loss: 0.614148]\n",
      "epoch:9 step:8924 [D loss: 0.566865, acc.: 69.53%] [G loss: 0.623851]\n",
      "epoch:9 step:8925 [D loss: 0.532219, acc.: 75.78%] [G loss: 0.595081]\n",
      "epoch:9 step:8926 [D loss: 0.566670, acc.: 67.19%] [G loss: 0.461769]\n",
      "epoch:9 step:8927 [D loss: 0.577522, acc.: 66.41%] [G loss: 0.568965]\n",
      "epoch:9 step:8928 [D loss: 0.516782, acc.: 74.22%] [G loss: 0.597633]\n",
      "epoch:9 step:8929 [D loss: 0.555941, acc.: 69.53%] [G loss: 0.581906]\n",
      "epoch:9 step:8930 [D loss: 0.543755, acc.: 71.09%] [G loss: 0.613194]\n",
      "epoch:9 step:8931 [D loss: 0.485687, acc.: 76.56%] [G loss: 0.716848]\n",
      "epoch:9 step:8932 [D loss: 0.523140, acc.: 71.88%] [G loss: 0.585392]\n",
      "epoch:9 step:8933 [D loss: 0.624691, acc.: 66.41%] [G loss: 0.558192]\n",
      "epoch:9 step:8934 [D loss: 0.688022, acc.: 64.06%] [G loss: 0.435902]\n",
      "epoch:9 step:8935 [D loss: 0.620478, acc.: 62.50%] [G loss: 0.468017]\n",
      "epoch:9 step:8936 [D loss: 0.447022, acc.: 77.34%] [G loss: 0.545234]\n",
      "epoch:9 step:8937 [D loss: 0.425292, acc.: 78.12%] [G loss: 0.772734]\n",
      "epoch:9 step:8938 [D loss: 0.520064, acc.: 77.34%] [G loss: 0.545078]\n",
      "epoch:9 step:8939 [D loss: 0.564292, acc.: 71.09%] [G loss: 0.661604]\n",
      "epoch:9 step:8940 [D loss: 0.545950, acc.: 67.19%] [G loss: 0.644269]\n",
      "epoch:9 step:8941 [D loss: 0.473996, acc.: 78.91%] [G loss: 0.785723]\n",
      "epoch:9 step:8942 [D loss: 0.510249, acc.: 72.66%] [G loss: 0.802720]\n",
      "epoch:9 step:8943 [D loss: 0.634964, acc.: 59.38%] [G loss: 0.633867]\n",
      "epoch:9 step:8944 [D loss: 0.600775, acc.: 68.75%] [G loss: 0.617633]\n",
      "epoch:9 step:8945 [D loss: 0.532281, acc.: 71.09%] [G loss: 0.481737]\n",
      "epoch:9 step:8946 [D loss: 0.562186, acc.: 68.75%] [G loss: 0.675747]\n",
      "epoch:9 step:8947 [D loss: 0.523433, acc.: 69.53%] [G loss: 0.582198]\n",
      "epoch:9 step:8948 [D loss: 0.574855, acc.: 70.31%] [G loss: 0.566038]\n",
      "epoch:9 step:8949 [D loss: 0.446910, acc.: 80.47%] [G loss: 0.678606]\n",
      "epoch:9 step:8950 [D loss: 0.549232, acc.: 69.53%] [G loss: 0.571742]\n",
      "epoch:9 step:8951 [D loss: 0.523453, acc.: 71.88%] [G loss: 0.611019]\n",
      "epoch:9 step:8952 [D loss: 0.508194, acc.: 75.00%] [G loss: 0.790149]\n",
      "epoch:9 step:8953 [D loss: 0.506261, acc.: 76.56%] [G loss: 0.780069]\n",
      "epoch:9 step:8954 [D loss: 0.549808, acc.: 71.09%] [G loss: 0.665349]\n",
      "epoch:9 step:8955 [D loss: 0.592167, acc.: 69.53%] [G loss: 0.565619]\n",
      "epoch:9 step:8956 [D loss: 0.490473, acc.: 74.22%] [G loss: 0.774067]\n",
      "epoch:9 step:8957 [D loss: 0.554063, acc.: 69.53%] [G loss: 0.630700]\n",
      "epoch:9 step:8958 [D loss: 0.609741, acc.: 64.06%] [G loss: 0.654832]\n",
      "epoch:9 step:8959 [D loss: 0.523072, acc.: 71.88%] [G loss: 0.587733]\n",
      "epoch:9 step:8960 [D loss: 0.547980, acc.: 74.22%] [G loss: 0.601995]\n",
      "epoch:9 step:8961 [D loss: 0.658982, acc.: 57.81%] [G loss: 0.536282]\n",
      "epoch:9 step:8962 [D loss: 0.648329, acc.: 63.28%] [G loss: 0.494227]\n",
      "epoch:9 step:8963 [D loss: 0.532917, acc.: 67.97%] [G loss: 0.613480]\n",
      "epoch:9 step:8964 [D loss: 0.539498, acc.: 72.66%] [G loss: 0.417631]\n",
      "epoch:9 step:8965 [D loss: 0.627128, acc.: 64.06%] [G loss: 0.508739]\n",
      "epoch:9 step:8966 [D loss: 0.569698, acc.: 67.19%] [G loss: 0.629713]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:9 step:8967 [D loss: 0.478651, acc.: 76.56%] [G loss: 0.709597]\n",
      "epoch:9 step:8968 [D loss: 0.633017, acc.: 63.28%] [G loss: 0.546156]\n",
      "epoch:9 step:8969 [D loss: 0.528986, acc.: 64.84%] [G loss: 0.503547]\n",
      "epoch:9 step:8970 [D loss: 0.597264, acc.: 67.97%] [G loss: 0.588028]\n",
      "epoch:9 step:8971 [D loss: 0.572901, acc.: 67.19%] [G loss: 0.596914]\n",
      "epoch:9 step:8972 [D loss: 0.549568, acc.: 71.88%] [G loss: 0.494352]\n",
      "epoch:9 step:8973 [D loss: 0.578829, acc.: 64.06%] [G loss: 0.584836]\n",
      "epoch:9 step:8974 [D loss: 0.634011, acc.: 60.16%] [G loss: 0.513291]\n",
      "epoch:9 step:8975 [D loss: 0.626711, acc.: 67.19%] [G loss: 0.541666]\n",
      "epoch:9 step:8976 [D loss: 0.647844, acc.: 60.94%] [G loss: 0.529049]\n",
      "epoch:9 step:8977 [D loss: 0.498356, acc.: 75.78%] [G loss: 0.531129]\n",
      "epoch:9 step:8978 [D loss: 0.548176, acc.: 72.66%] [G loss: 0.463298]\n",
      "epoch:9 step:8979 [D loss: 0.480575, acc.: 78.12%] [G loss: 0.666625]\n",
      "epoch:9 step:8980 [D loss: 0.494088, acc.: 75.00%] [G loss: 0.644373]\n",
      "epoch:9 step:8981 [D loss: 0.471879, acc.: 76.56%] [G loss: 0.760210]\n",
      "epoch:9 step:8982 [D loss: 0.513728, acc.: 74.22%] [G loss: 0.654122]\n",
      "epoch:9 step:8983 [D loss: 0.546669, acc.: 71.09%] [G loss: 0.632036]\n",
      "epoch:9 step:8984 [D loss: 0.536722, acc.: 71.88%] [G loss: 0.553680]\n",
      "epoch:9 step:8985 [D loss: 0.458510, acc.: 78.91%] [G loss: 0.608948]\n",
      "epoch:9 step:8986 [D loss: 0.579417, acc.: 68.75%] [G loss: 0.567485]\n",
      "epoch:9 step:8987 [D loss: 0.444192, acc.: 78.91%] [G loss: 0.653723]\n",
      "epoch:9 step:8988 [D loss: 0.449803, acc.: 82.81%] [G loss: 0.747748]\n",
      "epoch:9 step:8989 [D loss: 0.507093, acc.: 75.78%] [G loss: 0.539106]\n",
      "epoch:9 step:8990 [D loss: 0.519462, acc.: 73.44%] [G loss: 0.529575]\n",
      "epoch:9 step:8991 [D loss: 0.567430, acc.: 64.84%] [G loss: 0.610511]\n",
      "epoch:9 step:8992 [D loss: 0.566556, acc.: 67.97%] [G loss: 0.765049]\n",
      "epoch:9 step:8993 [D loss: 0.529719, acc.: 74.22%] [G loss: 0.617849]\n",
      "epoch:9 step:8994 [D loss: 0.570299, acc.: 71.88%] [G loss: 0.553365]\n",
      "epoch:9 step:8995 [D loss: 0.618852, acc.: 63.28%] [G loss: 0.617519]\n",
      "epoch:9 step:8996 [D loss: 0.530487, acc.: 75.00%] [G loss: 0.541350]\n",
      "epoch:9 step:8997 [D loss: 0.495832, acc.: 72.66%] [G loss: 0.638346]\n",
      "epoch:9 step:8998 [D loss: 0.606382, acc.: 68.75%] [G loss: 0.605024]\n",
      "epoch:9 step:8999 [D loss: 0.644395, acc.: 61.72%] [G loss: 0.554781]\n",
      "epoch:9 step:9000 [D loss: 0.530413, acc.: 69.53%] [G loss: 0.483837]\n",
      "epoch:9 step:9001 [D loss: 0.493840, acc.: 75.78%] [G loss: 0.599390]\n",
      "epoch:9 step:9002 [D loss: 0.557148, acc.: 70.31%] [G loss: 0.657096]\n",
      "epoch:9 step:9003 [D loss: 0.526182, acc.: 71.88%] [G loss: 0.627356]\n",
      "epoch:9 step:9004 [D loss: 0.577690, acc.: 67.19%] [G loss: 0.612288]\n",
      "epoch:9 step:9005 [D loss: 0.612499, acc.: 71.09%] [G loss: 0.482671]\n",
      "epoch:9 step:9006 [D loss: 0.524229, acc.: 71.88%] [G loss: 0.554300]\n",
      "epoch:9 step:9007 [D loss: 0.487428, acc.: 78.91%] [G loss: 0.703934]\n",
      "epoch:9 step:9008 [D loss: 0.500631, acc.: 71.88%] [G loss: 0.883840]\n",
      "epoch:9 step:9009 [D loss: 0.586480, acc.: 74.22%] [G loss: 0.562595]\n",
      "epoch:9 step:9010 [D loss: 0.574327, acc.: 72.66%] [G loss: 0.691576]\n",
      "epoch:9 step:9011 [D loss: 0.566225, acc.: 68.75%] [G loss: 0.573936]\n",
      "epoch:9 step:9012 [D loss: 0.520928, acc.: 71.88%] [G loss: 0.641490]\n",
      "epoch:9 step:9013 [D loss: 0.585019, acc.: 69.53%] [G loss: 0.786727]\n",
      "epoch:9 step:9014 [D loss: 0.557289, acc.: 66.41%] [G loss: 0.641444]\n",
      "epoch:9 step:9015 [D loss: 0.463341, acc.: 78.12%] [G loss: 0.760758]\n",
      "epoch:9 step:9016 [D loss: 0.596542, acc.: 67.97%] [G loss: 0.685910]\n",
      "epoch:9 step:9017 [D loss: 0.592269, acc.: 65.62%] [G loss: 0.727872]\n",
      "epoch:9 step:9018 [D loss: 0.549011, acc.: 75.00%] [G loss: 0.642713]\n",
      "epoch:9 step:9019 [D loss: 0.620465, acc.: 64.06%] [G loss: 0.616796]\n",
      "epoch:9 step:9020 [D loss: 0.594815, acc.: 60.94%] [G loss: 0.474322]\n",
      "epoch:9 step:9021 [D loss: 0.629638, acc.: 64.06%] [G loss: 0.604198]\n",
      "epoch:9 step:9022 [D loss: 0.536848, acc.: 69.53%] [G loss: 0.680913]\n",
      "epoch:9 step:9023 [D loss: 0.591638, acc.: 69.53%] [G loss: 0.625534]\n",
      "epoch:9 step:9024 [D loss: 0.588973, acc.: 67.19%] [G loss: 0.585147]\n",
      "epoch:9 step:9025 [D loss: 0.481093, acc.: 78.12%] [G loss: 0.532927]\n",
      "epoch:9 step:9026 [D loss: 0.536893, acc.: 69.53%] [G loss: 0.482605]\n",
      "epoch:9 step:9027 [D loss: 0.565099, acc.: 72.66%] [G loss: 0.625126]\n",
      "epoch:9 step:9028 [D loss: 0.560587, acc.: 69.53%] [G loss: 0.542674]\n",
      "epoch:9 step:9029 [D loss: 0.583196, acc.: 66.41%] [G loss: 0.589360]\n",
      "epoch:9 step:9030 [D loss: 0.581127, acc.: 64.84%] [G loss: 0.473716]\n",
      "epoch:9 step:9031 [D loss: 0.525496, acc.: 73.44%] [G loss: 0.620603]\n",
      "epoch:9 step:9032 [D loss: 0.544714, acc.: 71.09%] [G loss: 0.646726]\n",
      "epoch:9 step:9033 [D loss: 0.578910, acc.: 61.72%] [G loss: 0.647404]\n",
      "epoch:9 step:9034 [D loss: 0.542840, acc.: 68.75%] [G loss: 0.578209]\n",
      "epoch:9 step:9035 [D loss: 0.476488, acc.: 77.34%] [G loss: 0.640658]\n",
      "epoch:9 step:9036 [D loss: 0.512976, acc.: 74.22%] [G loss: 0.635396]\n",
      "epoch:9 step:9037 [D loss: 0.639366, acc.: 63.28%] [G loss: 0.545666]\n",
      "epoch:9 step:9038 [D loss: 0.434839, acc.: 81.25%] [G loss: 0.672407]\n",
      "epoch:9 step:9039 [D loss: 0.593454, acc.: 69.53%] [G loss: 0.514671]\n",
      "epoch:9 step:9040 [D loss: 0.484208, acc.: 78.12%] [G loss: 0.578111]\n",
      "epoch:9 step:9041 [D loss: 0.545622, acc.: 68.75%] [G loss: 0.561937]\n",
      "epoch:9 step:9042 [D loss: 0.523561, acc.: 71.09%] [G loss: 0.506022]\n",
      "epoch:9 step:9043 [D loss: 0.554448, acc.: 68.75%] [G loss: 0.576854]\n",
      "epoch:9 step:9044 [D loss: 0.560397, acc.: 72.66%] [G loss: 0.556711]\n",
      "epoch:9 step:9045 [D loss: 0.539054, acc.: 71.09%] [G loss: 0.594704]\n",
      "epoch:9 step:9046 [D loss: 0.513519, acc.: 75.00%] [G loss: 0.580277]\n",
      "epoch:9 step:9047 [D loss: 0.565438, acc.: 66.41%] [G loss: 0.460337]\n",
      "epoch:9 step:9048 [D loss: 0.633031, acc.: 59.38%] [G loss: 0.513635]\n",
      "epoch:9 step:9049 [D loss: 0.598995, acc.: 65.62%] [G loss: 0.483822]\n",
      "epoch:9 step:9050 [D loss: 0.555217, acc.: 71.09%] [G loss: 0.545500]\n",
      "epoch:9 step:9051 [D loss: 0.559906, acc.: 68.75%] [G loss: 0.806292]\n",
      "epoch:9 step:9052 [D loss: 0.571274, acc.: 69.53%] [G loss: 0.629006]\n",
      "epoch:9 step:9053 [D loss: 0.506796, acc.: 72.66%] [G loss: 0.518462]\n",
      "epoch:9 step:9054 [D loss: 0.543785, acc.: 68.75%] [G loss: 0.506101]\n",
      "epoch:9 step:9055 [D loss: 0.592519, acc.: 66.41%] [G loss: 0.556566]\n",
      "epoch:9 step:9056 [D loss: 0.476010, acc.: 77.34%] [G loss: 0.687070]\n",
      "epoch:9 step:9057 [D loss: 0.491274, acc.: 74.22%] [G loss: 0.706258]\n",
      "epoch:9 step:9058 [D loss: 0.575663, acc.: 68.75%] [G loss: 0.666553]\n",
      "epoch:9 step:9059 [D loss: 0.590717, acc.: 64.84%] [G loss: 0.629166]\n",
      "epoch:9 step:9060 [D loss: 0.559118, acc.: 67.97%] [G loss: 0.665309]\n",
      "epoch:9 step:9061 [D loss: 0.551472, acc.: 71.09%] [G loss: 0.572003]\n",
      "epoch:9 step:9062 [D loss: 0.525374, acc.: 71.88%] [G loss: 0.680724]\n",
      "epoch:9 step:9063 [D loss: 0.492089, acc.: 79.69%] [G loss: 0.688972]\n",
      "epoch:9 step:9064 [D loss: 0.510393, acc.: 75.78%] [G loss: 0.603757]\n",
      "epoch:9 step:9065 [D loss: 0.501748, acc.: 78.12%] [G loss: 0.677422]\n",
      "epoch:9 step:9066 [D loss: 0.555891, acc.: 72.66%] [G loss: 0.593017]\n",
      "epoch:9 step:9067 [D loss: 0.480014, acc.: 77.34%] [G loss: 0.793970]\n",
      "epoch:9 step:9068 [D loss: 0.501600, acc.: 73.44%] [G loss: 0.729846]\n",
      "epoch:9 step:9069 [D loss: 0.581413, acc.: 67.97%] [G loss: 0.572632]\n",
      "epoch:9 step:9070 [D loss: 0.522558, acc.: 77.34%] [G loss: 0.485676]\n",
      "epoch:9 step:9071 [D loss: 0.516299, acc.: 72.66%] [G loss: 0.538667]\n",
      "epoch:9 step:9072 [D loss: 0.505843, acc.: 74.22%] [G loss: 0.534339]\n",
      "epoch:9 step:9073 [D loss: 0.504609, acc.: 71.88%] [G loss: 0.683666]\n",
      "epoch:9 step:9074 [D loss: 0.443254, acc.: 79.69%] [G loss: 0.803302]\n",
      "epoch:9 step:9075 [D loss: 0.484621, acc.: 73.44%] [G loss: 0.965175]\n",
      "epoch:9 step:9076 [D loss: 0.526990, acc.: 70.31%] [G loss: 0.656018]\n",
      "epoch:9 step:9077 [D loss: 0.555408, acc.: 69.53%] [G loss: 0.619237]\n",
      "epoch:9 step:9078 [D loss: 0.513646, acc.: 74.22%] [G loss: 0.561971]\n",
      "epoch:9 step:9079 [D loss: 0.563998, acc.: 68.75%] [G loss: 0.659149]\n",
      "epoch:9 step:9080 [D loss: 0.478151, acc.: 77.34%] [G loss: 0.695238]\n",
      "epoch:9 step:9081 [D loss: 0.421174, acc.: 79.69%] [G loss: 0.853434]\n",
      "epoch:9 step:9082 [D loss: 0.468435, acc.: 77.34%] [G loss: 1.041747]\n",
      "epoch:9 step:9083 [D loss: 0.495528, acc.: 75.00%] [G loss: 0.741823]\n",
      "epoch:9 step:9084 [D loss: 0.519556, acc.: 71.88%] [G loss: 0.799130]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:9 step:9085 [D loss: 0.619266, acc.: 63.28%] [G loss: 0.645355]\n",
      "epoch:9 step:9086 [D loss: 0.623115, acc.: 62.50%] [G loss: 0.500408]\n",
      "epoch:9 step:9087 [D loss: 0.529957, acc.: 67.97%] [G loss: 0.540294]\n",
      "epoch:9 step:9088 [D loss: 0.536138, acc.: 75.78%] [G loss: 0.593795]\n",
      "epoch:9 step:9089 [D loss: 0.520655, acc.: 78.91%] [G loss: 0.580665]\n",
      "epoch:9 step:9090 [D loss: 0.549549, acc.: 68.75%] [G loss: 0.618527]\n",
      "epoch:9 step:9091 [D loss: 0.585846, acc.: 67.97%] [G loss: 0.641592]\n",
      "epoch:9 step:9092 [D loss: 0.522429, acc.: 73.44%] [G loss: 0.614698]\n",
      "epoch:9 step:9093 [D loss: 0.514200, acc.: 72.66%] [G loss: 0.690340]\n",
      "epoch:9 step:9094 [D loss: 0.497207, acc.: 76.56%] [G loss: 0.641044]\n",
      "epoch:9 step:9095 [D loss: 0.555681, acc.: 74.22%] [G loss: 0.620875]\n",
      "epoch:9 step:9096 [D loss: 0.533944, acc.: 70.31%] [G loss: 0.674465]\n",
      "epoch:9 step:9097 [D loss: 0.575553, acc.: 66.41%] [G loss: 0.521551]\n",
      "epoch:9 step:9098 [D loss: 0.544946, acc.: 70.31%] [G loss: 0.524330]\n",
      "epoch:9 step:9099 [D loss: 0.594815, acc.: 66.41%] [G loss: 0.513686]\n",
      "epoch:9 step:9100 [D loss: 0.599621, acc.: 64.84%] [G loss: 0.474871]\n",
      "epoch:9 step:9101 [D loss: 0.577863, acc.: 68.75%] [G loss: 0.587683]\n",
      "epoch:9 step:9102 [D loss: 0.546840, acc.: 69.53%] [G loss: 0.496646]\n",
      "epoch:9 step:9103 [D loss: 0.527248, acc.: 73.44%] [G loss: 0.648907]\n",
      "epoch:9 step:9104 [D loss: 0.519870, acc.: 69.53%] [G loss: 0.587393]\n",
      "epoch:9 step:9105 [D loss: 0.618092, acc.: 67.19%] [G loss: 0.519192]\n",
      "epoch:9 step:9106 [D loss: 0.524533, acc.: 78.91%] [G loss: 0.547314]\n",
      "epoch:9 step:9107 [D loss: 0.508477, acc.: 72.66%] [G loss: 0.686962]\n",
      "epoch:9 step:9108 [D loss: 0.632598, acc.: 66.41%] [G loss: 0.576377]\n",
      "epoch:9 step:9109 [D loss: 0.617700, acc.: 66.41%] [G loss: 0.747577]\n",
      "epoch:9 step:9110 [D loss: 0.506053, acc.: 72.66%] [G loss: 0.627353]\n",
      "epoch:9 step:9111 [D loss: 0.565906, acc.: 70.31%] [G loss: 0.573480]\n",
      "epoch:9 step:9112 [D loss: 0.502163, acc.: 74.22%] [G loss: 0.606095]\n",
      "epoch:9 step:9113 [D loss: 0.516388, acc.: 75.00%] [G loss: 0.613104]\n",
      "epoch:9 step:9114 [D loss: 0.468643, acc.: 78.12%] [G loss: 0.669128]\n",
      "epoch:9 step:9115 [D loss: 0.535153, acc.: 73.44%] [G loss: 0.554355]\n",
      "epoch:9 step:9116 [D loss: 0.539519, acc.: 72.66%] [G loss: 0.594889]\n",
      "epoch:9 step:9117 [D loss: 0.563557, acc.: 74.22%] [G loss: 0.483928]\n",
      "epoch:9 step:9118 [D loss: 0.552377, acc.: 72.66%] [G loss: 0.426107]\n",
      "epoch:9 step:9119 [D loss: 0.617283, acc.: 61.72%] [G loss: 0.477925]\n",
      "epoch:9 step:9120 [D loss: 0.560495, acc.: 67.97%] [G loss: 0.485188]\n",
      "epoch:9 step:9121 [D loss: 0.534168, acc.: 71.88%] [G loss: 0.568461]\n",
      "epoch:9 step:9122 [D loss: 0.603151, acc.: 60.16%] [G loss: 0.614680]\n",
      "epoch:9 step:9123 [D loss: 0.533976, acc.: 72.66%] [G loss: 0.596691]\n",
      "epoch:9 step:9124 [D loss: 0.480276, acc.: 75.78%] [G loss: 0.694863]\n",
      "epoch:9 step:9125 [D loss: 0.545646, acc.: 71.88%] [G loss: 0.735537]\n",
      "epoch:9 step:9126 [D loss: 0.514683, acc.: 75.00%] [G loss: 0.534484]\n",
      "epoch:9 step:9127 [D loss: 0.515314, acc.: 71.88%] [G loss: 0.610243]\n",
      "epoch:9 step:9128 [D loss: 0.570272, acc.: 68.75%] [G loss: 0.612205]\n",
      "epoch:9 step:9129 [D loss: 0.617070, acc.: 64.84%] [G loss: 0.520934]\n",
      "epoch:9 step:9130 [D loss: 0.598715, acc.: 66.41%] [G loss: 0.429902]\n",
      "epoch:9 step:9131 [D loss: 0.505544, acc.: 76.56%] [G loss: 0.489312]\n",
      "epoch:9 step:9132 [D loss: 0.541018, acc.: 71.88%] [G loss: 0.436514]\n",
      "epoch:9 step:9133 [D loss: 0.517556, acc.: 75.00%] [G loss: 0.727212]\n",
      "epoch:9 step:9134 [D loss: 0.475021, acc.: 78.12%] [G loss: 0.659416]\n",
      "epoch:9 step:9135 [D loss: 0.589848, acc.: 67.19%] [G loss: 0.580919]\n",
      "epoch:9 step:9136 [D loss: 0.600001, acc.: 60.16%] [G loss: 0.593524]\n",
      "epoch:9 step:9137 [D loss: 0.597208, acc.: 68.75%] [G loss: 0.457867]\n",
      "epoch:9 step:9138 [D loss: 0.545138, acc.: 72.66%] [G loss: 0.608951]\n",
      "epoch:9 step:9139 [D loss: 0.600040, acc.: 67.19%] [G loss: 0.529548]\n",
      "epoch:9 step:9140 [D loss: 0.537912, acc.: 67.97%] [G loss: 0.556551]\n",
      "epoch:9 step:9141 [D loss: 0.492805, acc.: 76.56%] [G loss: 0.774457]\n",
      "epoch:9 step:9142 [D loss: 0.536383, acc.: 69.53%] [G loss: 0.590295]\n",
      "epoch:9 step:9143 [D loss: 0.587111, acc.: 71.09%] [G loss: 0.601263]\n",
      "epoch:9 step:9144 [D loss: 0.576487, acc.: 67.97%] [G loss: 0.495943]\n",
      "epoch:9 step:9145 [D loss: 0.520833, acc.: 69.53%] [G loss: 0.576375]\n",
      "epoch:9 step:9146 [D loss: 0.583084, acc.: 65.62%] [G loss: 0.493869]\n",
      "epoch:9 step:9147 [D loss: 0.535017, acc.: 72.66%] [G loss: 0.547652]\n",
      "epoch:9 step:9148 [D loss: 0.559590, acc.: 70.31%] [G loss: 0.500305]\n",
      "epoch:9 step:9149 [D loss: 0.614835, acc.: 63.28%] [G loss: 0.505347]\n",
      "epoch:9 step:9150 [D loss: 0.615619, acc.: 63.28%] [G loss: 0.595929]\n",
      "epoch:9 step:9151 [D loss: 0.581448, acc.: 68.75%] [G loss: 0.512980]\n",
      "epoch:9 step:9152 [D loss: 0.510011, acc.: 73.44%] [G loss: 0.591171]\n",
      "epoch:9 step:9153 [D loss: 0.577886, acc.: 70.31%] [G loss: 0.509795]\n",
      "epoch:9 step:9154 [D loss: 0.585614, acc.: 67.19%] [G loss: 0.443142]\n",
      "epoch:9 step:9155 [D loss: 0.547214, acc.: 67.97%] [G loss: 0.523414]\n",
      "epoch:9 step:9156 [D loss: 0.617050, acc.: 60.94%] [G loss: 0.473452]\n",
      "epoch:9 step:9157 [D loss: 0.538684, acc.: 72.66%] [G loss: 0.548278]\n",
      "epoch:9 step:9158 [D loss: 0.472215, acc.: 79.69%] [G loss: 0.721917]\n",
      "epoch:9 step:9159 [D loss: 0.545885, acc.: 75.78%] [G loss: 0.661137]\n",
      "epoch:9 step:9160 [D loss: 0.599942, acc.: 67.19%] [G loss: 0.504324]\n",
      "epoch:9 step:9161 [D loss: 0.541054, acc.: 71.09%] [G loss: 0.560962]\n",
      "epoch:9 step:9162 [D loss: 0.534686, acc.: 70.31%] [G loss: 0.505497]\n",
      "epoch:9 step:9163 [D loss: 0.531138, acc.: 69.53%] [G loss: 0.484594]\n",
      "epoch:9 step:9164 [D loss: 0.555950, acc.: 65.62%] [G loss: 0.670565]\n",
      "epoch:9 step:9165 [D loss: 0.558336, acc.: 66.41%] [G loss: 0.586104]\n",
      "epoch:9 step:9166 [D loss: 0.541902, acc.: 69.53%] [G loss: 0.569630]\n",
      "epoch:9 step:9167 [D loss: 0.516006, acc.: 71.88%] [G loss: 0.565979]\n",
      "epoch:9 step:9168 [D loss: 0.541552, acc.: 67.97%] [G loss: 0.548994]\n",
      "epoch:9 step:9169 [D loss: 0.502566, acc.: 73.44%] [G loss: 0.678508]\n",
      "epoch:9 step:9170 [D loss: 0.551232, acc.: 67.19%] [G loss: 0.636398]\n",
      "epoch:9 step:9171 [D loss: 0.568997, acc.: 70.31%] [G loss: 0.523758]\n",
      "epoch:9 step:9172 [D loss: 0.650924, acc.: 62.50%] [G loss: 0.396231]\n",
      "epoch:9 step:9173 [D loss: 0.658884, acc.: 59.38%] [G loss: 0.397101]\n",
      "epoch:9 step:9174 [D loss: 0.546321, acc.: 72.66%] [G loss: 0.538657]\n",
      "epoch:9 step:9175 [D loss: 0.527676, acc.: 71.88%] [G loss: 0.716190]\n",
      "epoch:9 step:9176 [D loss: 0.448311, acc.: 80.47%] [G loss: 0.698728]\n",
      "epoch:9 step:9177 [D loss: 0.546234, acc.: 75.00%] [G loss: 0.649965]\n",
      "epoch:9 step:9178 [D loss: 0.581825, acc.: 67.19%] [G loss: 0.590040]\n",
      "epoch:9 step:9179 [D loss: 0.417819, acc.: 80.47%] [G loss: 0.698582]\n",
      "epoch:9 step:9180 [D loss: 0.420652, acc.: 79.69%] [G loss: 0.836633]\n",
      "epoch:9 step:9181 [D loss: 0.547345, acc.: 68.75%] [G loss: 0.562683]\n",
      "epoch:9 step:9182 [D loss: 0.556299, acc.: 67.97%] [G loss: 0.573695]\n",
      "epoch:9 step:9183 [D loss: 0.522885, acc.: 75.78%] [G loss: 0.798213]\n",
      "epoch:9 step:9184 [D loss: 0.508587, acc.: 75.78%] [G loss: 0.821264]\n",
      "epoch:9 step:9185 [D loss: 0.609274, acc.: 65.62%] [G loss: 0.691855]\n",
      "epoch:9 step:9186 [D loss: 0.545849, acc.: 71.09%] [G loss: 0.576674]\n",
      "epoch:9 step:9187 [D loss: 0.504999, acc.: 73.44%] [G loss: 0.566898]\n",
      "epoch:9 step:9188 [D loss: 0.544374, acc.: 67.97%] [G loss: 0.548784]\n",
      "epoch:9 step:9189 [D loss: 0.630782, acc.: 66.41%] [G loss: 0.440936]\n",
      "epoch:9 step:9190 [D loss: 0.566886, acc.: 69.53%] [G loss: 0.520554]\n",
      "epoch:9 step:9191 [D loss: 0.528955, acc.: 74.22%] [G loss: 0.483859]\n",
      "epoch:9 step:9192 [D loss: 0.536574, acc.: 71.09%] [G loss: 0.523242]\n",
      "epoch:9 step:9193 [D loss: 0.532052, acc.: 73.44%] [G loss: 0.476264]\n",
      "epoch:9 step:9194 [D loss: 0.548557, acc.: 70.31%] [G loss: 0.558256]\n",
      "epoch:9 step:9195 [D loss: 0.582231, acc.: 71.09%] [G loss: 0.592028]\n",
      "epoch:9 step:9196 [D loss: 0.554839, acc.: 68.75%] [G loss: 0.528247]\n",
      "epoch:9 step:9197 [D loss: 0.556769, acc.: 66.41%] [G loss: 0.533735]\n",
      "epoch:9 step:9198 [D loss: 0.602774, acc.: 61.72%] [G loss: 0.514330]\n",
      "epoch:9 step:9199 [D loss: 0.645799, acc.: 62.50%] [G loss: 0.469168]\n",
      "epoch:9 step:9200 [D loss: 0.528428, acc.: 71.09%] [G loss: 0.542829]\n",
      "epoch:9 step:9201 [D loss: 0.487687, acc.: 74.22%] [G loss: 0.571692]\n",
      "epoch:9 step:9202 [D loss: 0.508055, acc.: 76.56%] [G loss: 0.639962]\n",
      "epoch:9 step:9203 [D loss: 0.556070, acc.: 70.31%] [G loss: 0.569396]\n",
      "epoch:9 step:9204 [D loss: 0.523226, acc.: 71.09%] [G loss: 0.744511]\n",
      "epoch:9 step:9205 [D loss: 0.525665, acc.: 69.53%] [G loss: 0.608162]\n",
      "epoch:9 step:9206 [D loss: 0.576372, acc.: 70.31%] [G loss: 0.446307]\n",
      "epoch:9 step:9207 [D loss: 0.540248, acc.: 71.88%] [G loss: 0.591413]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:9 step:9208 [D loss: 0.547933, acc.: 71.88%] [G loss: 0.617435]\n",
      "epoch:9 step:9209 [D loss: 0.635131, acc.: 64.06%] [G loss: 0.606038]\n",
      "epoch:9 step:9210 [D loss: 0.553512, acc.: 71.88%] [G loss: 0.551421]\n",
      "epoch:9 step:9211 [D loss: 0.565245, acc.: 71.88%] [G loss: 0.716539]\n",
      "epoch:9 step:9212 [D loss: 0.582218, acc.: 68.75%] [G loss: 0.454511]\n",
      "epoch:9 step:9213 [D loss: 0.570232, acc.: 74.22%] [G loss: 0.531117]\n",
      "epoch:9 step:9214 [D loss: 0.508931, acc.: 71.88%] [G loss: 0.717542]\n",
      "epoch:9 step:9215 [D loss: 0.485978, acc.: 75.00%] [G loss: 0.759061]\n",
      "epoch:9 step:9216 [D loss: 0.629439, acc.: 57.03%] [G loss: 0.700208]\n",
      "epoch:9 step:9217 [D loss: 0.628829, acc.: 59.38%] [G loss: 0.520878]\n",
      "epoch:9 step:9218 [D loss: 0.524916, acc.: 71.09%] [G loss: 0.564042]\n",
      "epoch:9 step:9219 [D loss: 0.561102, acc.: 67.97%] [G loss: 0.503914]\n",
      "epoch:9 step:9220 [D loss: 0.560355, acc.: 67.19%] [G loss: 0.540016]\n",
      "epoch:9 step:9221 [D loss: 0.646313, acc.: 64.84%] [G loss: 0.563843]\n",
      "epoch:9 step:9222 [D loss: 0.524868, acc.: 77.34%] [G loss: 0.488666]\n",
      "epoch:9 step:9223 [D loss: 0.542675, acc.: 69.53%] [G loss: 0.457609]\n",
      "epoch:9 step:9224 [D loss: 0.548976, acc.: 71.88%] [G loss: 0.515997]\n",
      "epoch:9 step:9225 [D loss: 0.461678, acc.: 82.03%] [G loss: 0.596139]\n",
      "epoch:9 step:9226 [D loss: 0.586183, acc.: 71.09%] [G loss: 0.588172]\n",
      "epoch:9 step:9227 [D loss: 0.602330, acc.: 65.62%] [G loss: 0.611154]\n",
      "epoch:9 step:9228 [D loss: 0.576483, acc.: 71.88%] [G loss: 0.615142]\n",
      "epoch:9 step:9229 [D loss: 0.516549, acc.: 71.09%] [G loss: 0.539949]\n",
      "epoch:9 step:9230 [D loss: 0.545817, acc.: 70.31%] [G loss: 0.520805]\n",
      "epoch:9 step:9231 [D loss: 0.553732, acc.: 64.06%] [G loss: 0.527176]\n",
      "epoch:9 step:9232 [D loss: 0.570881, acc.: 71.09%] [G loss: 0.544288]\n",
      "epoch:9 step:9233 [D loss: 0.619121, acc.: 63.28%] [G loss: 0.599972]\n",
      "epoch:9 step:9234 [D loss: 0.451388, acc.: 82.03%] [G loss: 0.726281]\n",
      "epoch:9 step:9235 [D loss: 0.518551, acc.: 71.09%] [G loss: 0.702468]\n",
      "epoch:9 step:9236 [D loss: 0.522487, acc.: 73.44%] [G loss: 0.700034]\n",
      "epoch:9 step:9237 [D loss: 0.559530, acc.: 68.75%] [G loss: 0.621453]\n",
      "epoch:9 step:9238 [D loss: 0.551129, acc.: 65.62%] [G loss: 0.510237]\n",
      "epoch:9 step:9239 [D loss: 0.520448, acc.: 73.44%] [G loss: 0.542451]\n",
      "epoch:9 step:9240 [D loss: 0.539572, acc.: 72.66%] [G loss: 0.478021]\n",
      "epoch:9 step:9241 [D loss: 0.547053, acc.: 74.22%] [G loss: 0.579035]\n",
      "epoch:9 step:9242 [D loss: 0.549317, acc.: 73.44%] [G loss: 0.445679]\n",
      "epoch:9 step:9243 [D loss: 0.492788, acc.: 77.34%] [G loss: 0.546389]\n",
      "epoch:9 step:9244 [D loss: 0.542641, acc.: 70.31%] [G loss: 0.519460]\n",
      "epoch:9 step:9245 [D loss: 0.603516, acc.: 66.41%] [G loss: 0.573130]\n",
      "epoch:9 step:9246 [D loss: 0.539424, acc.: 70.31%] [G loss: 0.546064]\n",
      "epoch:9 step:9247 [D loss: 0.514262, acc.: 72.66%] [G loss: 0.516980]\n",
      "epoch:9 step:9248 [D loss: 0.536782, acc.: 72.66%] [G loss: 0.651690]\n",
      "epoch:9 step:9249 [D loss: 0.501291, acc.: 75.78%] [G loss: 0.731741]\n",
      "epoch:9 step:9250 [D loss: 0.552328, acc.: 76.56%] [G loss: 0.522951]\n",
      "epoch:9 step:9251 [D loss: 0.584292, acc.: 67.97%] [G loss: 0.560799]\n",
      "epoch:9 step:9252 [D loss: 0.538707, acc.: 73.44%] [G loss: 0.692466]\n",
      "epoch:9 step:9253 [D loss: 0.611260, acc.: 65.62%] [G loss: 0.450543]\n",
      "epoch:9 step:9254 [D loss: 0.529502, acc.: 71.09%] [G loss: 0.540808]\n",
      "epoch:9 step:9255 [D loss: 0.500826, acc.: 73.44%] [G loss: 0.510567]\n",
      "epoch:9 step:9256 [D loss: 0.485969, acc.: 76.56%] [G loss: 0.536809]\n",
      "epoch:9 step:9257 [D loss: 0.666812, acc.: 60.94%] [G loss: 0.578278]\n",
      "epoch:9 step:9258 [D loss: 0.500597, acc.: 77.34%] [G loss: 0.582354]\n",
      "epoch:9 step:9259 [D loss: 0.521571, acc.: 75.00%] [G loss: 0.583013]\n",
      "epoch:9 step:9260 [D loss: 0.603869, acc.: 61.72%] [G loss: 0.716773]\n",
      "epoch:9 step:9261 [D loss: 0.613422, acc.: 62.50%] [G loss: 0.632739]\n",
      "epoch:9 step:9262 [D loss: 0.512684, acc.: 73.44%] [G loss: 0.809104]\n",
      "epoch:9 step:9263 [D loss: 0.514696, acc.: 74.22%] [G loss: 0.640364]\n",
      "epoch:9 step:9264 [D loss: 0.589041, acc.: 71.09%] [G loss: 0.481535]\n",
      "epoch:9 step:9265 [D loss: 0.495887, acc.: 73.44%] [G loss: 0.568570]\n",
      "epoch:9 step:9266 [D loss: 0.509416, acc.: 74.22%] [G loss: 0.595320]\n",
      "epoch:9 step:9267 [D loss: 0.491283, acc.: 75.78%] [G loss: 0.508954]\n",
      "epoch:9 step:9268 [D loss: 0.525249, acc.: 70.31%] [G loss: 0.571862]\n",
      "epoch:9 step:9269 [D loss: 0.596986, acc.: 64.84%] [G loss: 0.538173]\n",
      "epoch:9 step:9270 [D loss: 0.494146, acc.: 76.56%] [G loss: 0.555636]\n",
      "epoch:9 step:9271 [D loss: 0.502115, acc.: 74.22%] [G loss: 0.647308]\n",
      "epoch:9 step:9272 [D loss: 0.559246, acc.: 70.31%] [G loss: 0.431653]\n",
      "epoch:9 step:9273 [D loss: 0.545937, acc.: 73.44%] [G loss: 0.515733]\n",
      "epoch:9 step:9274 [D loss: 0.546398, acc.: 68.75%] [G loss: 0.357225]\n",
      "epoch:9 step:9275 [D loss: 0.543239, acc.: 72.66%] [G loss: 0.535608]\n",
      "epoch:9 step:9276 [D loss: 0.517461, acc.: 74.22%] [G loss: 0.501809]\n",
      "epoch:9 step:9277 [D loss: 0.613177, acc.: 63.28%] [G loss: 0.473288]\n",
      "epoch:9 step:9278 [D loss: 0.575977, acc.: 62.50%] [G loss: 0.517918]\n",
      "epoch:9 step:9279 [D loss: 0.603058, acc.: 67.97%] [G loss: 0.487820]\n",
      "epoch:9 step:9280 [D loss: 0.627771, acc.: 59.38%] [G loss: 0.416009]\n",
      "epoch:9 step:9281 [D loss: 0.553048, acc.: 67.19%] [G loss: 0.475150]\n",
      "epoch:9 step:9282 [D loss: 0.576792, acc.: 66.41%] [G loss: 0.502239]\n",
      "epoch:9 step:9283 [D loss: 0.581284, acc.: 69.53%] [G loss: 0.546698]\n",
      "epoch:9 step:9284 [D loss: 0.624211, acc.: 61.72%] [G loss: 0.390932]\n",
      "epoch:9 step:9285 [D loss: 0.505337, acc.: 75.00%] [G loss: 0.613420]\n",
      "epoch:9 step:9286 [D loss: 0.559632, acc.: 68.75%] [G loss: 0.571562]\n",
      "epoch:9 step:9287 [D loss: 0.466279, acc.: 75.78%] [G loss: 0.635169]\n",
      "epoch:9 step:9288 [D loss: 0.559070, acc.: 67.97%] [G loss: 0.734407]\n",
      "epoch:9 step:9289 [D loss: 0.638153, acc.: 68.75%] [G loss: 0.628027]\n",
      "epoch:9 step:9290 [D loss: 0.445596, acc.: 77.34%] [G loss: 0.556927]\n",
      "epoch:9 step:9291 [D loss: 0.683130, acc.: 61.72%] [G loss: 0.520620]\n",
      "epoch:9 step:9292 [D loss: 0.546448, acc.: 71.09%] [G loss: 0.722550]\n",
      "epoch:9 step:9293 [D loss: 0.465170, acc.: 77.34%] [G loss: 0.686310]\n",
      "epoch:9 step:9294 [D loss: 0.659492, acc.: 61.72%] [G loss: 0.573341]\n",
      "epoch:9 step:9295 [D loss: 0.538251, acc.: 75.00%] [G loss: 0.527568]\n",
      "epoch:9 step:9296 [D loss: 0.603706, acc.: 64.84%] [G loss: 0.436202]\n",
      "epoch:9 step:9297 [D loss: 0.495531, acc.: 72.66%] [G loss: 0.586881]\n",
      "epoch:9 step:9298 [D loss: 0.545582, acc.: 71.88%] [G loss: 0.585794]\n",
      "epoch:9 step:9299 [D loss: 0.519188, acc.: 69.53%] [G loss: 0.479029]\n",
      "epoch:9 step:9300 [D loss: 0.667644, acc.: 60.16%] [G loss: 0.425133]\n",
      "epoch:9 step:9301 [D loss: 0.538816, acc.: 75.00%] [G loss: 0.463159]\n",
      "epoch:9 step:9302 [D loss: 0.539421, acc.: 66.41%] [G loss: 0.514324]\n",
      "epoch:9 step:9303 [D loss: 0.473160, acc.: 82.03%] [G loss: 0.573492]\n",
      "epoch:9 step:9304 [D loss: 0.493359, acc.: 74.22%] [G loss: 0.832163]\n",
      "epoch:9 step:9305 [D loss: 0.548365, acc.: 72.66%] [G loss: 0.477741]\n",
      "epoch:9 step:9306 [D loss: 0.575632, acc.: 66.41%] [G loss: 0.460405]\n",
      "epoch:9 step:9307 [D loss: 0.568884, acc.: 68.75%] [G loss: 0.544051]\n",
      "epoch:9 step:9308 [D loss: 0.492130, acc.: 78.12%] [G loss: 0.620345]\n",
      "epoch:9 step:9309 [D loss: 0.574275, acc.: 67.97%] [G loss: 0.524885]\n",
      "epoch:9 step:9310 [D loss: 0.548572, acc.: 69.53%] [G loss: 0.423588]\n",
      "epoch:9 step:9311 [D loss: 0.595115, acc.: 65.62%] [G loss: 0.420541]\n",
      "epoch:9 step:9312 [D loss: 0.572975, acc.: 70.31%] [G loss: 0.518263]\n",
      "epoch:9 step:9313 [D loss: 0.626227, acc.: 60.16%] [G loss: 0.504950]\n",
      "epoch:9 step:9314 [D loss: 0.604787, acc.: 61.72%] [G loss: 0.408272]\n",
      "epoch:9 step:9315 [D loss: 0.618880, acc.: 60.94%] [G loss: 0.401389]\n",
      "epoch:9 step:9316 [D loss: 0.625650, acc.: 62.50%] [G loss: 0.446225]\n",
      "epoch:9 step:9317 [D loss: 0.494090, acc.: 78.12%] [G loss: 0.453124]\n",
      "epoch:9 step:9318 [D loss: 0.503030, acc.: 74.22%] [G loss: 0.646949]\n",
      "epoch:9 step:9319 [D loss: 0.528797, acc.: 73.44%] [G loss: 0.662337]\n",
      "epoch:9 step:9320 [D loss: 0.546299, acc.: 66.41%] [G loss: 0.753557]\n",
      "epoch:9 step:9321 [D loss: 0.544369, acc.: 67.19%] [G loss: 0.620571]\n",
      "epoch:9 step:9322 [D loss: 0.535946, acc.: 71.09%] [G loss: 0.513342]\n",
      "epoch:9 step:9323 [D loss: 0.465159, acc.: 77.34%] [G loss: 0.753234]\n",
      "epoch:9 step:9324 [D loss: 0.652317, acc.: 63.28%] [G loss: 0.614321]\n",
      "epoch:9 step:9325 [D loss: 0.620596, acc.: 60.94%] [G loss: 0.623573]\n",
      "epoch:9 step:9326 [D loss: 0.540900, acc.: 73.44%] [G loss: 0.495224]\n",
      "epoch:9 step:9327 [D loss: 0.480297, acc.: 75.78%] [G loss: 0.716760]\n",
      "epoch:9 step:9328 [D loss: 0.486166, acc.: 77.34%] [G loss: 0.726387]\n",
      "epoch:9 step:9329 [D loss: 0.567682, acc.: 67.97%] [G loss: 0.795771]\n",
      "epoch:9 step:9330 [D loss: 0.492174, acc.: 75.00%] [G loss: 0.766004]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:9 step:9331 [D loss: 0.467250, acc.: 81.25%] [G loss: 0.691023]\n",
      "epoch:9 step:9332 [D loss: 0.480594, acc.: 76.56%] [G loss: 0.671834]\n",
      "epoch:9 step:9333 [D loss: 0.584240, acc.: 69.53%] [G loss: 0.643793]\n",
      "epoch:9 step:9334 [D loss: 0.484659, acc.: 77.34%] [G loss: 0.759762]\n",
      "epoch:9 step:9335 [D loss: 0.597071, acc.: 62.50%] [G loss: 0.497001]\n",
      "epoch:9 step:9336 [D loss: 0.607518, acc.: 63.28%] [G loss: 0.544933]\n",
      "epoch:9 step:9337 [D loss: 0.557158, acc.: 69.53%] [G loss: 0.456937]\n",
      "epoch:9 step:9338 [D loss: 0.548030, acc.: 71.88%] [G loss: 0.586010]\n",
      "epoch:9 step:9339 [D loss: 0.492183, acc.: 75.00%] [G loss: 0.694016]\n",
      "epoch:9 step:9340 [D loss: 0.583094, acc.: 65.62%] [G loss: 0.579773]\n",
      "epoch:9 step:9341 [D loss: 0.524987, acc.: 70.31%] [G loss: 0.640612]\n",
      "epoch:9 step:9342 [D loss: 0.489607, acc.: 75.78%] [G loss: 0.604758]\n",
      "epoch:9 step:9343 [D loss: 0.477158, acc.: 78.12%] [G loss: 0.781375]\n",
      "epoch:9 step:9344 [D loss: 0.490689, acc.: 76.56%] [G loss: 0.688364]\n",
      "epoch:9 step:9345 [D loss: 0.468226, acc.: 78.12%] [G loss: 0.766599]\n",
      "epoch:9 step:9346 [D loss: 0.601532, acc.: 68.75%] [G loss: 0.742044]\n",
      "epoch:9 step:9347 [D loss: 0.520399, acc.: 73.44%] [G loss: 0.858898]\n",
      "epoch:9 step:9348 [D loss: 0.576669, acc.: 64.84%] [G loss: 0.678840]\n",
      "epoch:9 step:9349 [D loss: 0.482815, acc.: 77.34%] [G loss: 0.641168]\n",
      "epoch:9 step:9350 [D loss: 0.631887, acc.: 60.94%] [G loss: 0.571674]\n",
      "epoch:9 step:9351 [D loss: 0.507456, acc.: 72.66%] [G loss: 0.526179]\n",
      "epoch:9 step:9352 [D loss: 0.443654, acc.: 82.03%] [G loss: 0.830529]\n",
      "epoch:9 step:9353 [D loss: 0.814718, acc.: 57.03%] [G loss: 0.681310]\n",
      "epoch:9 step:9354 [D loss: 0.496900, acc.: 72.66%] [G loss: 0.793195]\n",
      "epoch:9 step:9355 [D loss: 0.522288, acc.: 71.09%] [G loss: 0.639760]\n",
      "epoch:9 step:9356 [D loss: 0.517214, acc.: 73.44%] [G loss: 0.656144]\n",
      "epoch:9 step:9357 [D loss: 0.456624, acc.: 78.12%] [G loss: 0.791596]\n",
      "epoch:9 step:9358 [D loss: 0.468112, acc.: 75.00%] [G loss: 0.753964]\n",
      "epoch:9 step:9359 [D loss: 0.418951, acc.: 82.81%] [G loss: 1.016834]\n",
      "epoch:9 step:9360 [D loss: 0.522778, acc.: 69.53%] [G loss: 0.936922]\n",
      "epoch:9 step:9361 [D loss: 0.801658, acc.: 64.06%] [G loss: 0.893535]\n",
      "epoch:9 step:9362 [D loss: 0.547637, acc.: 65.62%] [G loss: 0.822031]\n",
      "epoch:9 step:9363 [D loss: 0.487798, acc.: 73.44%] [G loss: 0.876637]\n",
      "epoch:9 step:9364 [D loss: 0.482073, acc.: 74.22%] [G loss: 0.747365]\n",
      "epoch:9 step:9365 [D loss: 0.558898, acc.: 68.75%] [G loss: 0.698507]\n",
      "epoch:9 step:9366 [D loss: 0.519794, acc.: 71.09%] [G loss: 0.931124]\n",
      "epoch:9 step:9367 [D loss: 0.529560, acc.: 69.53%] [G loss: 1.023240]\n",
      "epoch:9 step:9368 [D loss: 0.473288, acc.: 71.09%] [G loss: 0.810727]\n",
      "epoch:9 step:9369 [D loss: 0.427333, acc.: 83.59%] [G loss: 1.221791]\n",
      "epoch:9 step:9370 [D loss: 0.435353, acc.: 81.25%] [G loss: 1.249942]\n",
      "epoch:10 step:9371 [D loss: 0.570456, acc.: 68.75%] [G loss: 1.049185]\n",
      "epoch:10 step:9372 [D loss: 0.510446, acc.: 74.22%] [G loss: 0.902750]\n",
      "epoch:10 step:9373 [D loss: 0.599178, acc.: 67.97%] [G loss: 0.738125]\n",
      "epoch:10 step:9374 [D loss: 0.541150, acc.: 74.22%] [G loss: 0.634325]\n",
      "epoch:10 step:9375 [D loss: 0.539564, acc.: 74.22%] [G loss: 0.629503]\n",
      "epoch:10 step:9376 [D loss: 0.570581, acc.: 66.41%] [G loss: 0.617715]\n",
      "epoch:10 step:9377 [D loss: 0.510282, acc.: 74.22%] [G loss: 0.664065]\n",
      "epoch:10 step:9378 [D loss: 0.495310, acc.: 78.91%] [G loss: 0.645390]\n",
      "epoch:10 step:9379 [D loss: 0.474400, acc.: 78.12%] [G loss: 0.753346]\n",
      "epoch:10 step:9380 [D loss: 0.564705, acc.: 69.53%] [G loss: 0.731027]\n",
      "epoch:10 step:9381 [D loss: 0.518826, acc.: 73.44%] [G loss: 0.684759]\n",
      "epoch:10 step:9382 [D loss: 0.553243, acc.: 68.75%] [G loss: 0.607749]\n",
      "epoch:10 step:9383 [D loss: 0.550556, acc.: 70.31%] [G loss: 0.495386]\n",
      "epoch:10 step:9384 [D loss: 0.563295, acc.: 70.31%] [G loss: 0.662120]\n",
      "epoch:10 step:9385 [D loss: 0.427119, acc.: 84.38%] [G loss: 0.697310]\n",
      "epoch:10 step:9386 [D loss: 0.478544, acc.: 74.22%] [G loss: 0.741114]\n",
      "epoch:10 step:9387 [D loss: 0.592315, acc.: 66.41%] [G loss: 0.681374]\n",
      "epoch:10 step:9388 [D loss: 0.528437, acc.: 74.22%] [G loss: 0.753615]\n",
      "epoch:10 step:9389 [D loss: 0.674097, acc.: 60.16%] [G loss: 0.542064]\n",
      "epoch:10 step:9390 [D loss: 0.720832, acc.: 55.47%] [G loss: 0.492310]\n",
      "epoch:10 step:9391 [D loss: 0.544054, acc.: 66.41%] [G loss: 0.728625]\n",
      "epoch:10 step:9392 [D loss: 0.478097, acc.: 77.34%] [G loss: 0.797989]\n",
      "epoch:10 step:9393 [D loss: 0.544787, acc.: 67.19%] [G loss: 0.566820]\n",
      "epoch:10 step:9394 [D loss: 0.545590, acc.: 70.31%] [G loss: 0.548947]\n",
      "epoch:10 step:9395 [D loss: 0.481962, acc.: 79.69%] [G loss: 0.609499]\n",
      "epoch:10 step:9396 [D loss: 0.551257, acc.: 64.84%] [G loss: 0.632445]\n",
      "epoch:10 step:9397 [D loss: 0.471615, acc.: 72.66%] [G loss: 0.667076]\n",
      "epoch:10 step:9398 [D loss: 0.623157, acc.: 64.84%] [G loss: 0.605212]\n",
      "epoch:10 step:9399 [D loss: 0.500385, acc.: 75.78%] [G loss: 0.583724]\n",
      "epoch:10 step:9400 [D loss: 0.533716, acc.: 72.66%] [G loss: 0.584656]\n",
      "epoch:10 step:9401 [D loss: 0.613219, acc.: 63.28%] [G loss: 0.551742]\n",
      "epoch:10 step:9402 [D loss: 0.538422, acc.: 71.88%] [G loss: 0.530000]\n",
      "epoch:10 step:9403 [D loss: 0.530859, acc.: 71.88%] [G loss: 0.551296]\n",
      "epoch:10 step:9404 [D loss: 0.472067, acc.: 78.12%] [G loss: 0.603463]\n",
      "epoch:10 step:9405 [D loss: 0.562824, acc.: 69.53%] [G loss: 0.450152]\n",
      "epoch:10 step:9406 [D loss: 0.520440, acc.: 72.66%] [G loss: 0.571729]\n",
      "epoch:10 step:9407 [D loss: 0.476058, acc.: 82.81%] [G loss: 0.414011]\n",
      "epoch:10 step:9408 [D loss: 0.628477, acc.: 64.06%] [G loss: 0.510973]\n",
      "epoch:10 step:9409 [D loss: 0.532570, acc.: 73.44%] [G loss: 0.471813]\n",
      "epoch:10 step:9410 [D loss: 0.435875, acc.: 82.03%] [G loss: 0.649685]\n",
      "epoch:10 step:9411 [D loss: 0.505113, acc.: 73.44%] [G loss: 0.560945]\n",
      "epoch:10 step:9412 [D loss: 0.477540, acc.: 73.44%] [G loss: 0.610027]\n",
      "epoch:10 step:9413 [D loss: 0.544168, acc.: 76.56%] [G loss: 0.691257]\n",
      "epoch:10 step:9414 [D loss: 0.592087, acc.: 64.84%] [G loss: 0.507328]\n",
      "epoch:10 step:9415 [D loss: 0.503242, acc.: 74.22%] [G loss: 0.553956]\n",
      "epoch:10 step:9416 [D loss: 0.526803, acc.: 71.88%] [G loss: 0.556780]\n",
      "epoch:10 step:9417 [D loss: 0.492288, acc.: 75.78%] [G loss: 0.693255]\n",
      "epoch:10 step:9418 [D loss: 0.518738, acc.: 71.88%] [G loss: 0.663030]\n",
      "epoch:10 step:9419 [D loss: 0.507793, acc.: 72.66%] [G loss: 0.667327]\n",
      "epoch:10 step:9420 [D loss: 0.532413, acc.: 75.78%] [G loss: 0.746015]\n",
      "epoch:10 step:9421 [D loss: 0.645183, acc.: 57.81%] [G loss: 0.582103]\n",
      "epoch:10 step:9422 [D loss: 0.624991, acc.: 62.50%] [G loss: 0.498970]\n",
      "epoch:10 step:9423 [D loss: 0.502134, acc.: 77.34%] [G loss: 0.590526]\n",
      "epoch:10 step:9424 [D loss: 0.495910, acc.: 77.34%] [G loss: 0.637382]\n",
      "epoch:10 step:9425 [D loss: 0.559479, acc.: 69.53%] [G loss: 0.606922]\n",
      "epoch:10 step:9426 [D loss: 0.499389, acc.: 75.00%] [G loss: 0.711556]\n",
      "epoch:10 step:9427 [D loss: 0.502457, acc.: 72.66%] [G loss: 0.679513]\n",
      "epoch:10 step:9428 [D loss: 0.536240, acc.: 69.53%] [G loss: 0.535445]\n",
      "epoch:10 step:9429 [D loss: 0.466029, acc.: 78.91%] [G loss: 0.607491]\n",
      "epoch:10 step:9430 [D loss: 0.606048, acc.: 62.50%] [G loss: 0.626340]\n",
      "epoch:10 step:9431 [D loss: 0.549024, acc.: 71.88%] [G loss: 0.633220]\n",
      "epoch:10 step:9432 [D loss: 0.542411, acc.: 76.56%] [G loss: 0.564036]\n",
      "epoch:10 step:9433 [D loss: 0.568693, acc.: 64.84%] [G loss: 0.446515]\n",
      "epoch:10 step:9434 [D loss: 0.573849, acc.: 67.97%] [G loss: 0.515357]\n",
      "epoch:10 step:9435 [D loss: 0.555232, acc.: 66.41%] [G loss: 0.548244]\n",
      "epoch:10 step:9436 [D loss: 0.523692, acc.: 68.75%] [G loss: 0.605679]\n",
      "epoch:10 step:9437 [D loss: 0.562716, acc.: 67.97%] [G loss: 0.492021]\n",
      "epoch:10 step:9438 [D loss: 0.538472, acc.: 71.88%] [G loss: 0.555512]\n",
      "epoch:10 step:9439 [D loss: 0.494142, acc.: 75.78%] [G loss: 0.614489]\n",
      "epoch:10 step:9440 [D loss: 0.511869, acc.: 71.88%] [G loss: 0.671830]\n",
      "epoch:10 step:9441 [D loss: 0.567327, acc.: 67.97%] [G loss: 0.544680]\n",
      "epoch:10 step:9442 [D loss: 0.540113, acc.: 68.75%] [G loss: 0.496084]\n",
      "epoch:10 step:9443 [D loss: 0.561724, acc.: 67.97%] [G loss: 0.421143]\n",
      "epoch:10 step:9444 [D loss: 0.492204, acc.: 80.47%] [G loss: 0.520412]\n",
      "epoch:10 step:9445 [D loss: 0.585811, acc.: 65.62%] [G loss: 0.643846]\n",
      "epoch:10 step:9446 [D loss: 0.571945, acc.: 67.19%] [G loss: 0.660474]\n",
      "epoch:10 step:9447 [D loss: 0.447605, acc.: 75.00%] [G loss: 0.809903]\n",
      "epoch:10 step:9448 [D loss: 0.573534, acc.: 74.22%] [G loss: 0.607249]\n",
      "epoch:10 step:9449 [D loss: 0.545395, acc.: 68.75%] [G loss: 0.558653]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:10 step:9450 [D loss: 0.487240, acc.: 77.34%] [G loss: 0.656030]\n",
      "epoch:10 step:9451 [D loss: 0.519259, acc.: 71.09%] [G loss: 0.622456]\n",
      "epoch:10 step:9452 [D loss: 0.537992, acc.: 68.75%] [G loss: 0.736193]\n",
      "epoch:10 step:9453 [D loss: 0.484537, acc.: 78.12%] [G loss: 0.613135]\n",
      "epoch:10 step:9454 [D loss: 0.562969, acc.: 69.53%] [G loss: 0.643961]\n",
      "epoch:10 step:9455 [D loss: 0.616080, acc.: 60.94%] [G loss: 0.608050]\n",
      "epoch:10 step:9456 [D loss: 0.570446, acc.: 70.31%] [G loss: 0.611626]\n",
      "epoch:10 step:9457 [D loss: 0.491223, acc.: 74.22%] [G loss: 0.684131]\n",
      "epoch:10 step:9458 [D loss: 0.515796, acc.: 73.44%] [G loss: 0.602490]\n",
      "epoch:10 step:9459 [D loss: 0.467814, acc.: 77.34%] [G loss: 0.638937]\n",
      "epoch:10 step:9460 [D loss: 0.498548, acc.: 74.22%] [G loss: 0.684234]\n",
      "epoch:10 step:9461 [D loss: 0.522041, acc.: 69.53%] [G loss: 0.651954]\n",
      "epoch:10 step:9462 [D loss: 0.454209, acc.: 82.03%] [G loss: 0.639334]\n",
      "epoch:10 step:9463 [D loss: 0.480281, acc.: 77.34%] [G loss: 0.554375]\n",
      "epoch:10 step:9464 [D loss: 0.486473, acc.: 75.78%] [G loss: 0.650852]\n",
      "epoch:10 step:9465 [D loss: 0.508446, acc.: 75.00%] [G loss: 0.815439]\n",
      "epoch:10 step:9466 [D loss: 0.545068, acc.: 72.66%] [G loss: 0.802686]\n",
      "epoch:10 step:9467 [D loss: 0.534395, acc.: 69.53%] [G loss: 0.584175]\n",
      "epoch:10 step:9468 [D loss: 0.619601, acc.: 61.72%] [G loss: 0.595860]\n",
      "epoch:10 step:9469 [D loss: 0.579226, acc.: 67.97%] [G loss: 0.614811]\n",
      "epoch:10 step:9470 [D loss: 0.495779, acc.: 72.66%] [G loss: 0.758570]\n",
      "epoch:10 step:9471 [D loss: 0.545506, acc.: 69.53%] [G loss: 0.828425]\n",
      "epoch:10 step:9472 [D loss: 0.601951, acc.: 66.41%] [G loss: 0.555604]\n",
      "epoch:10 step:9473 [D loss: 0.524724, acc.: 68.75%] [G loss: 0.475344]\n",
      "epoch:10 step:9474 [D loss: 0.589765, acc.: 67.19%] [G loss: 0.500704]\n",
      "epoch:10 step:9475 [D loss: 0.549987, acc.: 72.66%] [G loss: 0.647100]\n",
      "epoch:10 step:9476 [D loss: 0.512521, acc.: 75.00%] [G loss: 0.570980]\n",
      "epoch:10 step:9477 [D loss: 0.593831, acc.: 65.62%] [G loss: 0.482874]\n",
      "epoch:10 step:9478 [D loss: 0.604551, acc.: 64.84%] [G loss: 0.591014]\n",
      "epoch:10 step:9479 [D loss: 0.599890, acc.: 65.62%] [G loss: 0.481871]\n",
      "epoch:10 step:9480 [D loss: 0.543561, acc.: 72.66%] [G loss: 0.545459]\n",
      "epoch:10 step:9481 [D loss: 0.478393, acc.: 77.34%] [G loss: 0.589850]\n",
      "epoch:10 step:9482 [D loss: 0.549240, acc.: 71.88%] [G loss: 0.558848]\n",
      "epoch:10 step:9483 [D loss: 0.586622, acc.: 68.75%] [G loss: 0.546591]\n",
      "epoch:10 step:9484 [D loss: 0.572046, acc.: 71.88%] [G loss: 0.653576]\n",
      "epoch:10 step:9485 [D loss: 0.582431, acc.: 68.75%] [G loss: 0.583799]\n",
      "epoch:10 step:9486 [D loss: 0.512444, acc.: 74.22%] [G loss: 0.692602]\n",
      "epoch:10 step:9487 [D loss: 0.543483, acc.: 67.97%] [G loss: 0.743797]\n",
      "epoch:10 step:9488 [D loss: 0.516774, acc.: 75.78%] [G loss: 0.648702]\n",
      "epoch:10 step:9489 [D loss: 0.503498, acc.: 75.00%] [G loss: 0.712569]\n",
      "epoch:10 step:9490 [D loss: 0.583482, acc.: 72.66%] [G loss: 0.595526]\n",
      "epoch:10 step:9491 [D loss: 0.573324, acc.: 67.97%] [G loss: 0.656452]\n",
      "epoch:10 step:9492 [D loss: 0.497496, acc.: 77.34%] [G loss: 0.668622]\n",
      "epoch:10 step:9493 [D loss: 0.539235, acc.: 67.19%] [G loss: 0.596506]\n",
      "epoch:10 step:9494 [D loss: 0.603035, acc.: 67.97%] [G loss: 0.587723]\n",
      "epoch:10 step:9495 [D loss: 0.634148, acc.: 67.97%] [G loss: 0.616937]\n",
      "epoch:10 step:9496 [D loss: 0.513222, acc.: 75.00%] [G loss: 0.576908]\n",
      "epoch:10 step:9497 [D loss: 0.503268, acc.: 73.44%] [G loss: 0.664721]\n",
      "epoch:10 step:9498 [D loss: 0.536865, acc.: 71.88%] [G loss: 0.544191]\n",
      "epoch:10 step:9499 [D loss: 0.526440, acc.: 72.66%] [G loss: 0.615045]\n",
      "epoch:10 step:9500 [D loss: 0.518368, acc.: 75.78%] [G loss: 0.527631]\n",
      "epoch:10 step:9501 [D loss: 0.486755, acc.: 74.22%] [G loss: 0.559314]\n",
      "epoch:10 step:9502 [D loss: 0.565881, acc.: 71.09%] [G loss: 0.572031]\n",
      "epoch:10 step:9503 [D loss: 0.565036, acc.: 69.53%] [G loss: 0.521114]\n",
      "epoch:10 step:9504 [D loss: 0.560520, acc.: 65.62%] [G loss: 0.685044]\n",
      "epoch:10 step:9505 [D loss: 0.502963, acc.: 78.12%] [G loss: 0.637607]\n",
      "epoch:10 step:9506 [D loss: 0.577832, acc.: 67.97%] [G loss: 0.541890]\n",
      "epoch:10 step:9507 [D loss: 0.643935, acc.: 62.50%] [G loss: 0.526981]\n",
      "epoch:10 step:9508 [D loss: 0.580613, acc.: 66.41%] [G loss: 0.483606]\n",
      "epoch:10 step:9509 [D loss: 0.560758, acc.: 73.44%] [G loss: 0.455541]\n",
      "epoch:10 step:9510 [D loss: 0.559925, acc.: 71.09%] [G loss: 0.555495]\n",
      "epoch:10 step:9511 [D loss: 0.520487, acc.: 77.34%] [G loss: 0.489512]\n",
      "epoch:10 step:9512 [D loss: 0.581871, acc.: 69.53%] [G loss: 0.520345]\n",
      "epoch:10 step:9513 [D loss: 0.602531, acc.: 67.19%] [G loss: 0.465402]\n",
      "epoch:10 step:9514 [D loss: 0.508078, acc.: 72.66%] [G loss: 0.484512]\n",
      "epoch:10 step:9515 [D loss: 0.573592, acc.: 67.97%] [G loss: 0.554154]\n",
      "epoch:10 step:9516 [D loss: 0.480509, acc.: 79.69%] [G loss: 0.693908]\n",
      "epoch:10 step:9517 [D loss: 0.625597, acc.: 67.19%] [G loss: 0.579318]\n",
      "epoch:10 step:9518 [D loss: 0.537427, acc.: 69.53%] [G loss: 0.669217]\n",
      "epoch:10 step:9519 [D loss: 0.509206, acc.: 71.88%] [G loss: 0.581960]\n",
      "epoch:10 step:9520 [D loss: 0.642763, acc.: 69.53%] [G loss: 0.585125]\n",
      "epoch:10 step:9521 [D loss: 0.540193, acc.: 71.09%] [G loss: 0.543182]\n",
      "epoch:10 step:9522 [D loss: 0.494221, acc.: 74.22%] [G loss: 0.683231]\n",
      "epoch:10 step:9523 [D loss: 0.530824, acc.: 73.44%] [G loss: 0.543945]\n",
      "epoch:10 step:9524 [D loss: 0.506379, acc.: 75.00%] [G loss: 0.587139]\n",
      "epoch:10 step:9525 [D loss: 0.507222, acc.: 77.34%] [G loss: 0.607520]\n",
      "epoch:10 step:9526 [D loss: 0.519479, acc.: 72.66%] [G loss: 0.757165]\n",
      "epoch:10 step:9527 [D loss: 0.573842, acc.: 64.84%] [G loss: 0.596115]\n",
      "epoch:10 step:9528 [D loss: 0.528666, acc.: 71.88%] [G loss: 0.674618]\n",
      "epoch:10 step:9529 [D loss: 0.546605, acc.: 66.41%] [G loss: 0.540669]\n",
      "epoch:10 step:9530 [D loss: 0.615106, acc.: 65.62%] [G loss: 0.537673]\n",
      "epoch:10 step:9531 [D loss: 0.505479, acc.: 70.31%] [G loss: 0.620092]\n",
      "epoch:10 step:9532 [D loss: 0.469832, acc.: 75.78%] [G loss: 0.836898]\n",
      "epoch:10 step:9533 [D loss: 0.546897, acc.: 68.75%] [G loss: 0.757398]\n",
      "epoch:10 step:9534 [D loss: 0.566225, acc.: 70.31%] [G loss: 0.663708]\n",
      "epoch:10 step:9535 [D loss: 0.528634, acc.: 72.66%] [G loss: 0.667314]\n",
      "epoch:10 step:9536 [D loss: 0.551453, acc.: 70.31%] [G loss: 0.437713]\n",
      "epoch:10 step:9537 [D loss: 0.556925, acc.: 67.19%] [G loss: 0.553050]\n",
      "epoch:10 step:9538 [D loss: 0.566007, acc.: 67.19%] [G loss: 0.463507]\n",
      "epoch:10 step:9539 [D loss: 0.566719, acc.: 66.41%] [G loss: 0.537882]\n",
      "epoch:10 step:9540 [D loss: 0.528944, acc.: 71.09%] [G loss: 0.512448]\n",
      "epoch:10 step:9541 [D loss: 0.512648, acc.: 75.78%] [G loss: 0.633345]\n",
      "epoch:10 step:9542 [D loss: 0.542422, acc.: 71.88%] [G loss: 0.539358]\n",
      "epoch:10 step:9543 [D loss: 0.499233, acc.: 72.66%] [G loss: 0.653204]\n",
      "epoch:10 step:9544 [D loss: 0.582206, acc.: 64.06%] [G loss: 0.641884]\n",
      "epoch:10 step:9545 [D loss: 0.590593, acc.: 62.50%] [G loss: 0.581550]\n",
      "epoch:10 step:9546 [D loss: 0.517249, acc.: 72.66%] [G loss: 0.538597]\n",
      "epoch:10 step:9547 [D loss: 0.511584, acc.: 66.41%] [G loss: 0.510316]\n",
      "epoch:10 step:9548 [D loss: 0.568101, acc.: 67.97%] [G loss: 0.629811]\n",
      "epoch:10 step:9549 [D loss: 0.544421, acc.: 72.66%] [G loss: 0.432531]\n",
      "epoch:10 step:9550 [D loss: 0.607767, acc.: 67.97%] [G loss: 0.436794]\n",
      "epoch:10 step:9551 [D loss: 0.594965, acc.: 68.75%] [G loss: 0.444588]\n",
      "epoch:10 step:9552 [D loss: 0.511653, acc.: 78.12%] [G loss: 0.664735]\n",
      "epoch:10 step:9553 [D loss: 0.563683, acc.: 70.31%] [G loss: 0.641275]\n",
      "epoch:10 step:9554 [D loss: 0.472336, acc.: 78.12%] [G loss: 0.710293]\n",
      "epoch:10 step:9555 [D loss: 0.591078, acc.: 64.84%] [G loss: 0.541115]\n",
      "epoch:10 step:9556 [D loss: 0.536193, acc.: 71.88%] [G loss: 0.589888]\n",
      "epoch:10 step:9557 [D loss: 0.602441, acc.: 62.50%] [G loss: 0.537148]\n",
      "epoch:10 step:9558 [D loss: 0.581431, acc.: 67.97%] [G loss: 0.556684]\n",
      "epoch:10 step:9559 [D loss: 0.595275, acc.: 64.06%] [G loss: 0.521547]\n",
      "epoch:10 step:9560 [D loss: 0.483193, acc.: 77.34%] [G loss: 0.483340]\n",
      "epoch:10 step:9561 [D loss: 0.561489, acc.: 64.84%] [G loss: 0.578696]\n",
      "epoch:10 step:9562 [D loss: 0.514427, acc.: 73.44%] [G loss: 0.576554]\n",
      "epoch:10 step:9563 [D loss: 0.512794, acc.: 75.78%] [G loss: 0.659231]\n",
      "epoch:10 step:9564 [D loss: 0.457018, acc.: 81.25%] [G loss: 0.654008]\n",
      "epoch:10 step:9565 [D loss: 0.597720, acc.: 64.06%] [G loss: 0.562827]\n",
      "epoch:10 step:9566 [D loss: 0.562813, acc.: 67.97%] [G loss: 0.601577]\n",
      "epoch:10 step:9567 [D loss: 0.495515, acc.: 78.12%] [G loss: 0.668734]\n",
      "epoch:10 step:9568 [D loss: 0.454294, acc.: 78.91%] [G loss: 0.745113]\n",
      "epoch:10 step:9569 [D loss: 0.522405, acc.: 75.00%] [G loss: 0.675543]\n",
      "epoch:10 step:9570 [D loss: 0.588320, acc.: 69.53%] [G loss: 0.433071]\n",
      "epoch:10 step:9571 [D loss: 0.564911, acc.: 69.53%] [G loss: 0.588978]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:10 step:9572 [D loss: 0.519275, acc.: 73.44%] [G loss: 0.601934]\n",
      "epoch:10 step:9573 [D loss: 0.622994, acc.: 67.97%] [G loss: 0.530327]\n",
      "epoch:10 step:9574 [D loss: 0.557569, acc.: 68.75%] [G loss: 0.548722]\n",
      "epoch:10 step:9575 [D loss: 0.546249, acc.: 70.31%] [G loss: 0.627380]\n",
      "epoch:10 step:9576 [D loss: 0.507750, acc.: 72.66%] [G loss: 0.604934]\n",
      "epoch:10 step:9577 [D loss: 0.465178, acc.: 78.91%] [G loss: 0.683697]\n",
      "epoch:10 step:9578 [D loss: 0.427058, acc.: 79.69%] [G loss: 0.716276]\n",
      "epoch:10 step:9579 [D loss: 0.537409, acc.: 72.66%] [G loss: 0.823259]\n",
      "epoch:10 step:9580 [D loss: 0.589188, acc.: 71.09%] [G loss: 0.539337]\n",
      "epoch:10 step:9581 [D loss: 0.563150, acc.: 65.62%] [G loss: 0.512803]\n",
      "epoch:10 step:9582 [D loss: 0.582054, acc.: 67.97%] [G loss: 0.410617]\n",
      "epoch:10 step:9583 [D loss: 0.514291, acc.: 73.44%] [G loss: 0.585092]\n",
      "epoch:10 step:9584 [D loss: 0.624419, acc.: 65.62%] [G loss: 0.550310]\n",
      "epoch:10 step:9585 [D loss: 0.558177, acc.: 66.41%] [G loss: 0.437515]\n",
      "epoch:10 step:9586 [D loss: 0.520205, acc.: 71.88%] [G loss: 0.513551]\n",
      "epoch:10 step:9587 [D loss: 0.538485, acc.: 71.09%] [G loss: 0.522004]\n",
      "epoch:10 step:9588 [D loss: 0.515078, acc.: 78.91%] [G loss: 0.552399]\n",
      "epoch:10 step:9589 [D loss: 0.494912, acc.: 78.91%] [G loss: 0.606950]\n",
      "epoch:10 step:9590 [D loss: 0.649961, acc.: 69.53%] [G loss: 0.566768]\n",
      "epoch:10 step:9591 [D loss: 0.513878, acc.: 74.22%] [G loss: 0.514050]\n",
      "epoch:10 step:9592 [D loss: 0.511746, acc.: 72.66%] [G loss: 0.633126]\n",
      "epoch:10 step:9593 [D loss: 0.492869, acc.: 79.69%] [G loss: 0.669688]\n",
      "epoch:10 step:9594 [D loss: 0.580410, acc.: 68.75%] [G loss: 0.545509]\n",
      "epoch:10 step:9595 [D loss: 0.595601, acc.: 64.06%] [G loss: 0.643259]\n",
      "epoch:10 step:9596 [D loss: 0.577803, acc.: 66.41%] [G loss: 0.500887]\n",
      "epoch:10 step:9597 [D loss: 0.556803, acc.: 71.09%] [G loss: 0.448153]\n",
      "epoch:10 step:9598 [D loss: 0.595335, acc.: 64.84%] [G loss: 0.576997]\n",
      "epoch:10 step:9599 [D loss: 0.520802, acc.: 79.69%] [G loss: 0.531182]\n",
      "epoch:10 step:9600 [D loss: 0.514916, acc.: 78.12%] [G loss: 0.701640]\n",
      "epoch:10 step:9601 [D loss: 0.474459, acc.: 78.91%] [G loss: 0.765573]\n",
      "epoch:10 step:9602 [D loss: 0.463204, acc.: 82.03%] [G loss: 0.795551]\n",
      "epoch:10 step:9603 [D loss: 0.584506, acc.: 68.75%] [G loss: 0.653342]\n",
      "epoch:10 step:9604 [D loss: 0.535335, acc.: 76.56%] [G loss: 0.641931]\n",
      "epoch:10 step:9605 [D loss: 0.564151, acc.: 64.06%] [G loss: 0.583139]\n",
      "epoch:10 step:9606 [D loss: 0.477327, acc.: 80.47%] [G loss: 0.578795]\n",
      "epoch:10 step:9607 [D loss: 0.552611, acc.: 66.41%] [G loss: 0.563762]\n",
      "epoch:10 step:9608 [D loss: 0.562868, acc.: 71.09%] [G loss: 0.502537]\n",
      "epoch:10 step:9609 [D loss: 0.524040, acc.: 71.88%] [G loss: 0.583229]\n",
      "epoch:10 step:9610 [D loss: 0.571936, acc.: 70.31%] [G loss: 0.513611]\n",
      "epoch:10 step:9611 [D loss: 0.536127, acc.: 76.56%] [G loss: 0.597155]\n",
      "epoch:10 step:9612 [D loss: 0.536977, acc.: 72.66%] [G loss: 0.522510]\n",
      "epoch:10 step:9613 [D loss: 0.549206, acc.: 64.06%] [G loss: 0.572467]\n",
      "epoch:10 step:9614 [D loss: 0.482233, acc.: 73.44%] [G loss: 0.594327]\n",
      "epoch:10 step:9615 [D loss: 0.547840, acc.: 71.88%] [G loss: 0.597684]\n",
      "epoch:10 step:9616 [D loss: 0.533840, acc.: 72.66%] [G loss: 0.572790]\n",
      "epoch:10 step:9617 [D loss: 0.592915, acc.: 67.97%] [G loss: 0.557835]\n",
      "epoch:10 step:9618 [D loss: 0.533303, acc.: 75.00%] [G loss: 0.587298]\n",
      "epoch:10 step:9619 [D loss: 0.533176, acc.: 70.31%] [G loss: 0.592881]\n",
      "epoch:10 step:9620 [D loss: 0.608725, acc.: 61.72%] [G loss: 0.530465]\n",
      "epoch:10 step:9621 [D loss: 0.604484, acc.: 67.97%] [G loss: 0.563206]\n",
      "epoch:10 step:9622 [D loss: 0.509552, acc.: 73.44%] [G loss: 0.570625]\n",
      "epoch:10 step:9623 [D loss: 0.552092, acc.: 67.19%] [G loss: 0.604296]\n",
      "epoch:10 step:9624 [D loss: 0.530194, acc.: 67.97%] [G loss: 0.492188]\n",
      "epoch:10 step:9625 [D loss: 0.557169, acc.: 71.88%] [G loss: 0.703779]\n",
      "epoch:10 step:9626 [D loss: 0.542393, acc.: 68.75%] [G loss: 0.624407]\n",
      "epoch:10 step:9627 [D loss: 0.566808, acc.: 69.53%] [G loss: 0.581468]\n",
      "epoch:10 step:9628 [D loss: 0.513510, acc.: 71.88%] [G loss: 0.559104]\n",
      "epoch:10 step:9629 [D loss: 0.486353, acc.: 75.00%] [G loss: 0.619032]\n",
      "epoch:10 step:9630 [D loss: 0.610838, acc.: 60.94%] [G loss: 0.457584]\n",
      "epoch:10 step:9631 [D loss: 0.537956, acc.: 76.56%] [G loss: 0.472915]\n",
      "epoch:10 step:9632 [D loss: 0.527744, acc.: 73.44%] [G loss: 0.514031]\n",
      "epoch:10 step:9633 [D loss: 0.648424, acc.: 62.50%] [G loss: 0.450762]\n",
      "epoch:10 step:9634 [D loss: 0.512572, acc.: 74.22%] [G loss: 0.637709]\n",
      "epoch:10 step:9635 [D loss: 0.569428, acc.: 65.62%] [G loss: 0.542696]\n",
      "epoch:10 step:9636 [D loss: 0.519923, acc.: 73.44%] [G loss: 0.615887]\n",
      "epoch:10 step:9637 [D loss: 0.565679, acc.: 67.97%] [G loss: 0.504967]\n",
      "epoch:10 step:9638 [D loss: 0.544920, acc.: 69.53%] [G loss: 0.531051]\n",
      "epoch:10 step:9639 [D loss: 0.551406, acc.: 74.22%] [G loss: 0.560725]\n",
      "epoch:10 step:9640 [D loss: 0.537896, acc.: 70.31%] [G loss: 0.592056]\n",
      "epoch:10 step:9641 [D loss: 0.478890, acc.: 76.56%] [G loss: 0.758000]\n",
      "epoch:10 step:9642 [D loss: 0.534969, acc.: 70.31%] [G loss: 0.618501]\n",
      "epoch:10 step:9643 [D loss: 0.549350, acc.: 70.31%] [G loss: 0.638666]\n",
      "epoch:10 step:9644 [D loss: 0.564431, acc.: 67.97%] [G loss: 0.599465]\n",
      "epoch:10 step:9645 [D loss: 0.602862, acc.: 64.06%] [G loss: 0.618514]\n",
      "epoch:10 step:9646 [D loss: 0.489197, acc.: 78.91%] [G loss: 0.720479]\n",
      "epoch:10 step:9647 [D loss: 0.672730, acc.: 61.72%] [G loss: 0.437181]\n",
      "epoch:10 step:9648 [D loss: 0.614108, acc.: 61.72%] [G loss: 0.443212]\n",
      "epoch:10 step:9649 [D loss: 0.543026, acc.: 67.97%] [G loss: 0.564048]\n",
      "epoch:10 step:9650 [D loss: 0.559614, acc.: 71.88%] [G loss: 0.607398]\n",
      "epoch:10 step:9651 [D loss: 0.612350, acc.: 67.97%] [G loss: 0.536212]\n",
      "epoch:10 step:9652 [D loss: 0.562001, acc.: 71.88%] [G loss: 0.492897]\n",
      "epoch:10 step:9653 [D loss: 0.491079, acc.: 77.34%] [G loss: 0.530109]\n",
      "epoch:10 step:9654 [D loss: 0.506851, acc.: 75.78%] [G loss: 0.611583]\n",
      "epoch:10 step:9655 [D loss: 0.490968, acc.: 74.22%] [G loss: 0.616477]\n",
      "epoch:10 step:9656 [D loss: 0.468910, acc.: 78.12%] [G loss: 0.683759]\n",
      "epoch:10 step:9657 [D loss: 0.542956, acc.: 67.19%] [G loss: 0.690517]\n",
      "epoch:10 step:9658 [D loss: 0.548220, acc.: 67.97%] [G loss: 0.651875]\n",
      "epoch:10 step:9659 [D loss: 0.549522, acc.: 67.19%] [G loss: 0.661548]\n",
      "epoch:10 step:9660 [D loss: 0.542208, acc.: 71.09%] [G loss: 0.528626]\n",
      "epoch:10 step:9661 [D loss: 0.576984, acc.: 66.41%] [G loss: 0.447154]\n",
      "epoch:10 step:9662 [D loss: 0.564552, acc.: 69.53%] [G loss: 0.444136]\n",
      "epoch:10 step:9663 [D loss: 0.557775, acc.: 69.53%] [G loss: 0.519386]\n",
      "epoch:10 step:9664 [D loss: 0.589425, acc.: 64.06%] [G loss: 0.395698]\n",
      "epoch:10 step:9665 [D loss: 0.575484, acc.: 62.50%] [G loss: 0.493950]\n",
      "epoch:10 step:9666 [D loss: 0.490867, acc.: 75.78%] [G loss: 0.475884]\n",
      "epoch:10 step:9667 [D loss: 0.544929, acc.: 74.22%] [G loss: 0.708128]\n",
      "epoch:10 step:9668 [D loss: 0.532503, acc.: 74.22%] [G loss: 0.671525]\n",
      "epoch:10 step:9669 [D loss: 0.524274, acc.: 71.88%] [G loss: 0.754343]\n",
      "epoch:10 step:9670 [D loss: 0.487944, acc.: 78.12%] [G loss: 0.672875]\n",
      "epoch:10 step:9671 [D loss: 0.537507, acc.: 73.44%] [G loss: 0.707800]\n",
      "epoch:10 step:9672 [D loss: 0.548695, acc.: 69.53%] [G loss: 0.471060]\n",
      "epoch:10 step:9673 [D loss: 0.566818, acc.: 70.31%] [G loss: 0.597589]\n",
      "epoch:10 step:9674 [D loss: 0.486228, acc.: 78.12%] [G loss: 0.798075]\n",
      "epoch:10 step:9675 [D loss: 0.549678, acc.: 72.66%] [G loss: 0.641107]\n",
      "epoch:10 step:9676 [D loss: 0.555625, acc.: 68.75%] [G loss: 0.571020]\n",
      "epoch:10 step:9677 [D loss: 0.495286, acc.: 74.22%] [G loss: 0.591786]\n",
      "epoch:10 step:9678 [D loss: 0.556514, acc.: 71.09%] [G loss: 0.531633]\n",
      "epoch:10 step:9679 [D loss: 0.463550, acc.: 80.47%] [G loss: 0.661373]\n",
      "epoch:10 step:9680 [D loss: 0.542122, acc.: 70.31%] [G loss: 0.609390]\n",
      "epoch:10 step:9681 [D loss: 0.447561, acc.: 79.69%] [G loss: 0.693408]\n",
      "epoch:10 step:9682 [D loss: 0.458624, acc.: 76.56%] [G loss: 0.789976]\n",
      "epoch:10 step:9683 [D loss: 0.537693, acc.: 68.75%] [G loss: 0.731354]\n",
      "epoch:10 step:9684 [D loss: 0.446214, acc.: 79.69%] [G loss: 1.002442]\n",
      "epoch:10 step:9685 [D loss: 0.429268, acc.: 82.81%] [G loss: 1.010608]\n",
      "epoch:10 step:9686 [D loss: 0.734899, acc.: 58.59%] [G loss: 0.592086]\n",
      "epoch:10 step:9687 [D loss: 0.592117, acc.: 64.84%] [G loss: 0.549948]\n",
      "epoch:10 step:9688 [D loss: 0.584033, acc.: 67.19%] [G loss: 0.512975]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:10 step:9689 [D loss: 0.552979, acc.: 71.88%] [G loss: 0.635959]\n",
      "epoch:10 step:9690 [D loss: 0.543001, acc.: 71.09%] [G loss: 0.592957]\n",
      "epoch:10 step:9691 [D loss: 0.461484, acc.: 81.25%] [G loss: 0.583118]\n",
      "epoch:10 step:9692 [D loss: 0.570433, acc.: 70.31%] [G loss: 0.656199]\n",
      "epoch:10 step:9693 [D loss: 0.569653, acc.: 71.88%] [G loss: 0.553453]\n",
      "epoch:10 step:9694 [D loss: 0.618674, acc.: 63.28%] [G loss: 0.512571]\n",
      "epoch:10 step:9695 [D loss: 0.558086, acc.: 69.53%] [G loss: 0.502102]\n",
      "epoch:10 step:9696 [D loss: 0.495213, acc.: 74.22%] [G loss: 0.535454]\n",
      "epoch:10 step:9697 [D loss: 0.538154, acc.: 71.88%] [G loss: 0.573927]\n",
      "epoch:10 step:9698 [D loss: 0.503690, acc.: 75.78%] [G loss: 0.693696]\n",
      "epoch:10 step:9699 [D loss: 0.477771, acc.: 78.12%] [G loss: 0.708549]\n",
      "epoch:10 step:9700 [D loss: 0.567917, acc.: 68.75%] [G loss: 0.519053]\n",
      "epoch:10 step:9701 [D loss: 0.511725, acc.: 75.78%] [G loss: 0.636330]\n",
      "epoch:10 step:9702 [D loss: 0.509036, acc.: 75.00%] [G loss: 0.442183]\n",
      "epoch:10 step:9703 [D loss: 0.493714, acc.: 78.91%] [G loss: 0.639804]\n",
      "epoch:10 step:9704 [D loss: 0.525423, acc.: 74.22%] [G loss: 0.604640]\n",
      "epoch:10 step:9705 [D loss: 0.503246, acc.: 71.88%] [G loss: 0.607800]\n",
      "epoch:10 step:9706 [D loss: 0.527874, acc.: 72.66%] [G loss: 0.610356]\n",
      "epoch:10 step:9707 [D loss: 0.505476, acc.: 73.44%] [G loss: 0.590647]\n",
      "epoch:10 step:9708 [D loss: 0.483662, acc.: 74.22%] [G loss: 0.634437]\n",
      "epoch:10 step:9709 [D loss: 0.489552, acc.: 75.78%] [G loss: 0.661576]\n",
      "epoch:10 step:9710 [D loss: 0.487695, acc.: 71.09%] [G loss: 0.656900]\n",
      "epoch:10 step:9711 [D loss: 0.606184, acc.: 64.06%] [G loss: 0.567752]\n",
      "epoch:10 step:9712 [D loss: 0.698846, acc.: 58.59%] [G loss: 0.631367]\n",
      "epoch:10 step:9713 [D loss: 0.480161, acc.: 79.69%] [G loss: 0.836218]\n",
      "epoch:10 step:9714 [D loss: 0.522910, acc.: 75.78%] [G loss: 0.582841]\n",
      "epoch:10 step:9715 [D loss: 0.538947, acc.: 74.22%] [G loss: 0.695448]\n",
      "epoch:10 step:9716 [D loss: 0.572973, acc.: 69.53%] [G loss: 0.685831]\n",
      "epoch:10 step:9717 [D loss: 0.457898, acc.: 79.69%] [G loss: 0.736235]\n",
      "epoch:10 step:9718 [D loss: 0.633512, acc.: 64.84%] [G loss: 0.674676]\n",
      "epoch:10 step:9719 [D loss: 0.683493, acc.: 56.25%] [G loss: 0.459155]\n",
      "epoch:10 step:9720 [D loss: 0.496824, acc.: 75.78%] [G loss: 0.561859]\n",
      "epoch:10 step:9721 [D loss: 0.489372, acc.: 76.56%] [G loss: 0.715889]\n",
      "epoch:10 step:9722 [D loss: 0.518583, acc.: 75.78%] [G loss: 0.712820]\n",
      "epoch:10 step:9723 [D loss: 0.593073, acc.: 62.50%] [G loss: 0.612068]\n",
      "epoch:10 step:9724 [D loss: 0.428955, acc.: 80.47%] [G loss: 0.716712]\n",
      "epoch:10 step:9725 [D loss: 0.533649, acc.: 73.44%] [G loss: 0.801454]\n",
      "epoch:10 step:9726 [D loss: 0.561161, acc.: 70.31%] [G loss: 0.745767]\n",
      "epoch:10 step:9727 [D loss: 0.469559, acc.: 76.56%] [G loss: 0.700426]\n",
      "epoch:10 step:9728 [D loss: 0.423707, acc.: 83.59%] [G loss: 0.783565]\n",
      "epoch:10 step:9729 [D loss: 0.525485, acc.: 70.31%] [G loss: 0.730559]\n",
      "epoch:10 step:9730 [D loss: 0.523609, acc.: 72.66%] [G loss: 0.720837]\n",
      "epoch:10 step:9731 [D loss: 0.545756, acc.: 71.88%] [G loss: 0.776089]\n",
      "epoch:10 step:9732 [D loss: 0.572365, acc.: 73.44%] [G loss: 0.647802]\n",
      "epoch:10 step:9733 [D loss: 0.526846, acc.: 76.56%] [G loss: 0.509668]\n",
      "epoch:10 step:9734 [D loss: 0.518436, acc.: 71.88%] [G loss: 0.499328]\n",
      "epoch:10 step:9735 [D loss: 0.544157, acc.: 71.09%] [G loss: 0.511038]\n",
      "epoch:10 step:9736 [D loss: 0.482365, acc.: 74.22%] [G loss: 0.623048]\n",
      "epoch:10 step:9737 [D loss: 0.582237, acc.: 68.75%] [G loss: 0.703323]\n",
      "epoch:10 step:9738 [D loss: 0.538192, acc.: 74.22%] [G loss: 0.567934]\n",
      "epoch:10 step:9739 [D loss: 0.529078, acc.: 71.09%] [G loss: 0.530460]\n",
      "epoch:10 step:9740 [D loss: 0.522858, acc.: 74.22%] [G loss: 0.590774]\n",
      "epoch:10 step:9741 [D loss: 0.498049, acc.: 77.34%] [G loss: 0.765683]\n",
      "epoch:10 step:9742 [D loss: 0.570114, acc.: 71.88%] [G loss: 0.674891]\n",
      "epoch:10 step:9743 [D loss: 0.603764, acc.: 70.31%] [G loss: 0.620774]\n",
      "epoch:10 step:9744 [D loss: 0.452751, acc.: 77.34%] [G loss: 0.718791]\n",
      "epoch:10 step:9745 [D loss: 0.577015, acc.: 67.97%] [G loss: 0.698066]\n",
      "epoch:10 step:9746 [D loss: 0.703811, acc.: 63.28%] [G loss: 0.432636]\n",
      "epoch:10 step:9747 [D loss: 0.618775, acc.: 63.28%] [G loss: 0.342058]\n",
      "epoch:10 step:9748 [D loss: 0.500179, acc.: 72.66%] [G loss: 0.585076]\n",
      "epoch:10 step:9749 [D loss: 0.576873, acc.: 69.53%] [G loss: 0.454063]\n",
      "epoch:10 step:9750 [D loss: 0.600477, acc.: 67.97%] [G loss: 0.439422]\n",
      "epoch:10 step:9751 [D loss: 0.456627, acc.: 81.25%] [G loss: 0.531056]\n",
      "epoch:10 step:9752 [D loss: 0.582018, acc.: 65.62%] [G loss: 0.509282]\n",
      "epoch:10 step:9753 [D loss: 0.527169, acc.: 71.09%] [G loss: 0.723165]\n",
      "epoch:10 step:9754 [D loss: 0.521038, acc.: 70.31%] [G loss: 0.673399]\n",
      "epoch:10 step:9755 [D loss: 0.483418, acc.: 75.00%] [G loss: 0.602728]\n",
      "epoch:10 step:9756 [D loss: 0.617969, acc.: 63.28%] [G loss: 0.564700]\n",
      "epoch:10 step:9757 [D loss: 0.561316, acc.: 62.50%] [G loss: 0.492729]\n",
      "epoch:10 step:9758 [D loss: 0.621887, acc.: 64.06%] [G loss: 0.622178]\n",
      "epoch:10 step:9759 [D loss: 0.538763, acc.: 71.09%] [G loss: 0.706045]\n",
      "epoch:10 step:9760 [D loss: 0.595182, acc.: 67.19%] [G loss: 0.573660]\n",
      "epoch:10 step:9761 [D loss: 0.583090, acc.: 64.06%] [G loss: 0.502287]\n",
      "epoch:10 step:9762 [D loss: 0.528865, acc.: 71.88%] [G loss: 0.465832]\n",
      "epoch:10 step:9763 [D loss: 0.560009, acc.: 65.62%] [G loss: 0.681742]\n",
      "epoch:10 step:9764 [D loss: 0.545231, acc.: 70.31%] [G loss: 0.548869]\n",
      "epoch:10 step:9765 [D loss: 0.517356, acc.: 71.88%] [G loss: 0.536141]\n",
      "epoch:10 step:9766 [D loss: 0.630252, acc.: 63.28%] [G loss: 0.547963]\n",
      "epoch:10 step:9767 [D loss: 0.565561, acc.: 64.84%] [G loss: 0.531913]\n",
      "epoch:10 step:9768 [D loss: 0.485351, acc.: 77.34%] [G loss: 0.720154]\n",
      "epoch:10 step:9769 [D loss: 0.559551, acc.: 67.97%] [G loss: 0.610605]\n",
      "epoch:10 step:9770 [D loss: 0.658320, acc.: 56.25%] [G loss: 0.441807]\n",
      "epoch:10 step:9771 [D loss: 0.631414, acc.: 57.81%] [G loss: 0.503148]\n",
      "epoch:10 step:9772 [D loss: 0.495194, acc.: 75.78%] [G loss: 0.649592]\n",
      "epoch:10 step:9773 [D loss: 0.459047, acc.: 80.47%] [G loss: 0.673689]\n",
      "epoch:10 step:9774 [D loss: 0.611079, acc.: 64.84%] [G loss: 0.586903]\n",
      "epoch:10 step:9775 [D loss: 0.555345, acc.: 71.88%] [G loss: 0.530567]\n",
      "epoch:10 step:9776 [D loss: 0.490192, acc.: 77.34%] [G loss: 0.721255]\n",
      "epoch:10 step:9777 [D loss: 0.573899, acc.: 67.97%] [G loss: 0.546760]\n",
      "epoch:10 step:9778 [D loss: 0.584626, acc.: 66.41%] [G loss: 0.566824]\n",
      "epoch:10 step:9779 [D loss: 0.689726, acc.: 60.16%] [G loss: 0.445386]\n",
      "epoch:10 step:9780 [D loss: 0.564688, acc.: 68.75%] [G loss: 0.558732]\n",
      "epoch:10 step:9781 [D loss: 0.586791, acc.: 63.28%] [G loss: 0.499705]\n",
      "epoch:10 step:9782 [D loss: 0.585944, acc.: 69.53%] [G loss: 0.517962]\n",
      "epoch:10 step:9783 [D loss: 0.540755, acc.: 71.88%] [G loss: 0.445841]\n",
      "epoch:10 step:9784 [D loss: 0.538592, acc.: 70.31%] [G loss: 0.601582]\n",
      "epoch:10 step:9785 [D loss: 0.549690, acc.: 66.41%] [G loss: 0.724118]\n",
      "epoch:10 step:9786 [D loss: 0.507270, acc.: 76.56%] [G loss: 0.665912]\n",
      "epoch:10 step:9787 [D loss: 0.576040, acc.: 69.53%] [G loss: 0.708604]\n",
      "epoch:10 step:9788 [D loss: 0.607039, acc.: 64.84%] [G loss: 0.465662]\n",
      "epoch:10 step:9789 [D loss: 0.557243, acc.: 69.53%] [G loss: 0.528310]\n",
      "epoch:10 step:9790 [D loss: 0.584938, acc.: 65.62%] [G loss: 0.479970]\n",
      "epoch:10 step:9791 [D loss: 0.537866, acc.: 73.44%] [G loss: 0.441466]\n",
      "epoch:10 step:9792 [D loss: 0.573812, acc.: 64.84%] [G loss: 0.526750]\n",
      "epoch:10 step:9793 [D loss: 0.543402, acc.: 66.41%] [G loss: 0.502832]\n",
      "epoch:10 step:9794 [D loss: 0.638109, acc.: 64.06%] [G loss: 0.496627]\n",
      "epoch:10 step:9795 [D loss: 0.498595, acc.: 75.00%] [G loss: 0.741079]\n",
      "epoch:10 step:9796 [D loss: 0.483471, acc.: 76.56%] [G loss: 0.607493]\n",
      "epoch:10 step:9797 [D loss: 0.476130, acc.: 75.78%] [G loss: 0.911157]\n",
      "epoch:10 step:9798 [D loss: 0.500897, acc.: 75.00%] [G loss: 0.699723]\n",
      "epoch:10 step:9799 [D loss: 0.543928, acc.: 67.97%] [G loss: 0.628365]\n",
      "epoch:10 step:9800 [D loss: 0.489090, acc.: 75.00%] [G loss: 0.746187]\n",
      "epoch:10 step:9801 [D loss: 0.495255, acc.: 73.44%] [G loss: 0.784240]\n",
      "epoch:10 step:9802 [D loss: 0.564502, acc.: 67.97%] [G loss: 0.523464]\n",
      "epoch:10 step:9803 [D loss: 0.566751, acc.: 67.97%] [G loss: 0.597545]\n",
      "epoch:10 step:9804 [D loss: 0.553458, acc.: 70.31%] [G loss: 0.536165]\n",
      "epoch:10 step:9805 [D loss: 0.534412, acc.: 76.56%] [G loss: 0.525425]\n",
      "epoch:10 step:9806 [D loss: 0.529473, acc.: 75.00%] [G loss: 0.627955]\n",
      "epoch:10 step:9807 [D loss: 0.655125, acc.: 62.50%] [G loss: 0.577628]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:10 step:9808 [D loss: 0.557546, acc.: 69.53%] [G loss: 0.528832]\n",
      "epoch:10 step:9809 [D loss: 0.510270, acc.: 76.56%] [G loss: 0.680541]\n",
      "epoch:10 step:9810 [D loss: 0.476167, acc.: 77.34%] [G loss: 0.853987]\n",
      "epoch:10 step:9811 [D loss: 0.538648, acc.: 72.66%] [G loss: 0.708886]\n",
      "epoch:10 step:9812 [D loss: 0.520485, acc.: 69.53%] [G loss: 0.629527]\n",
      "epoch:10 step:9813 [D loss: 0.500402, acc.: 74.22%] [G loss: 0.741999]\n",
      "epoch:10 step:9814 [D loss: 0.495645, acc.: 75.78%] [G loss: 0.641398]\n",
      "epoch:10 step:9815 [D loss: 0.547907, acc.: 67.97%] [G loss: 0.623486]\n",
      "epoch:10 step:9816 [D loss: 0.589079, acc.: 64.06%] [G loss: 0.655901]\n",
      "epoch:10 step:9817 [D loss: 0.532549, acc.: 71.88%] [G loss: 0.649176]\n",
      "epoch:10 step:9818 [D loss: 0.545421, acc.: 68.75%] [G loss: 0.575663]\n",
      "epoch:10 step:9819 [D loss: 0.511177, acc.: 75.78%] [G loss: 0.675568]\n",
      "epoch:10 step:9820 [D loss: 0.497004, acc.: 71.88%] [G loss: 0.732490]\n",
      "epoch:10 step:9821 [D loss: 0.399069, acc.: 82.81%] [G loss: 0.783152]\n",
      "epoch:10 step:9822 [D loss: 0.563811, acc.: 65.62%] [G loss: 0.687706]\n",
      "epoch:10 step:9823 [D loss: 0.545890, acc.: 74.22%] [G loss: 0.791472]\n",
      "epoch:10 step:9824 [D loss: 0.581065, acc.: 65.62%] [G loss: 0.602881]\n",
      "epoch:10 step:9825 [D loss: 0.562005, acc.: 67.19%] [G loss: 0.656352]\n",
      "epoch:10 step:9826 [D loss: 0.598007, acc.: 65.62%] [G loss: 0.522850]\n",
      "epoch:10 step:9827 [D loss: 0.469671, acc.: 76.56%] [G loss: 0.733193]\n",
      "epoch:10 step:9828 [D loss: 0.639569, acc.: 64.84%] [G loss: 0.578753]\n",
      "epoch:10 step:9829 [D loss: 0.554188, acc.: 71.88%] [G loss: 0.532134]\n",
      "epoch:10 step:9830 [D loss: 0.529433, acc.: 68.75%] [G loss: 0.626203]\n",
      "epoch:10 step:9831 [D loss: 0.472142, acc.: 75.78%] [G loss: 0.714162]\n",
      "epoch:10 step:9832 [D loss: 0.568714, acc.: 67.97%] [G loss: 0.583548]\n",
      "epoch:10 step:9833 [D loss: 0.529256, acc.: 67.97%] [G loss: 0.624397]\n",
      "epoch:10 step:9834 [D loss: 0.515463, acc.: 69.53%] [G loss: 0.598614]\n",
      "epoch:10 step:9835 [D loss: 0.605571, acc.: 67.19%] [G loss: 0.586021]\n",
      "epoch:10 step:9836 [D loss: 0.496789, acc.: 76.56%] [G loss: 0.583107]\n",
      "epoch:10 step:9837 [D loss: 0.529548, acc.: 69.53%] [G loss: 0.665042]\n",
      "epoch:10 step:9838 [D loss: 0.548893, acc.: 72.66%] [G loss: 0.646353]\n",
      "epoch:10 step:9839 [D loss: 0.486682, acc.: 78.91%] [G loss: 0.683923]\n",
      "epoch:10 step:9840 [D loss: 0.582937, acc.: 67.97%] [G loss: 0.598793]\n",
      "epoch:10 step:9841 [D loss: 0.436548, acc.: 82.81%] [G loss: 0.664555]\n",
      "epoch:10 step:9842 [D loss: 0.477193, acc.: 79.69%] [G loss: 0.771497]\n",
      "epoch:10 step:9843 [D loss: 0.627765, acc.: 60.16%] [G loss: 0.715101]\n",
      "epoch:10 step:9844 [D loss: 0.546254, acc.: 69.53%] [G loss: 0.647748]\n",
      "epoch:10 step:9845 [D loss: 0.517081, acc.: 71.09%] [G loss: 0.707083]\n",
      "epoch:10 step:9846 [D loss: 0.534789, acc.: 75.78%] [G loss: 0.780081]\n",
      "epoch:10 step:9847 [D loss: 0.636343, acc.: 67.97%] [G loss: 0.528569]\n",
      "epoch:10 step:9848 [D loss: 0.596388, acc.: 65.62%] [G loss: 0.425946]\n",
      "epoch:10 step:9849 [D loss: 0.564091, acc.: 67.97%] [G loss: 0.464588]\n",
      "epoch:10 step:9850 [D loss: 0.599356, acc.: 63.28%] [G loss: 0.402766]\n",
      "epoch:10 step:9851 [D loss: 0.536982, acc.: 73.44%] [G loss: 0.405781]\n",
      "epoch:10 step:9852 [D loss: 0.609089, acc.: 60.94%] [G loss: 0.469563]\n",
      "epoch:10 step:9853 [D loss: 0.561807, acc.: 73.44%] [G loss: 0.486184]\n",
      "epoch:10 step:9854 [D loss: 0.486493, acc.: 78.91%] [G loss: 0.705936]\n",
      "epoch:10 step:9855 [D loss: 0.513213, acc.: 76.56%] [G loss: 0.629407]\n",
      "epoch:10 step:9856 [D loss: 0.554647, acc.: 67.97%] [G loss: 0.562434]\n",
      "epoch:10 step:9857 [D loss: 0.545337, acc.: 68.75%] [G loss: 0.547232]\n",
      "epoch:10 step:9858 [D loss: 0.469033, acc.: 77.34%] [G loss: 0.608721]\n",
      "epoch:10 step:9859 [D loss: 0.544843, acc.: 71.09%] [G loss: 0.636286]\n",
      "epoch:10 step:9860 [D loss: 0.585818, acc.: 66.41%] [G loss: 0.590652]\n",
      "epoch:10 step:9861 [D loss: 0.522256, acc.: 72.66%] [G loss: 0.621701]\n",
      "epoch:10 step:9862 [D loss: 0.549516, acc.: 70.31%] [G loss: 0.562671]\n",
      "epoch:10 step:9863 [D loss: 0.586349, acc.: 67.97%] [G loss: 0.560810]\n",
      "epoch:10 step:9864 [D loss: 0.585393, acc.: 67.19%] [G loss: 0.556709]\n",
      "epoch:10 step:9865 [D loss: 0.538591, acc.: 70.31%] [G loss: 0.611743]\n",
      "epoch:10 step:9866 [D loss: 0.622220, acc.: 69.53%] [G loss: 0.516506]\n",
      "epoch:10 step:9867 [D loss: 0.500776, acc.: 75.78%] [G loss: 0.655605]\n",
      "epoch:10 step:9868 [D loss: 0.538903, acc.: 72.66%] [G loss: 0.651191]\n",
      "epoch:10 step:9869 [D loss: 0.513972, acc.: 71.09%] [G loss: 0.621145]\n",
      "epoch:10 step:9870 [D loss: 0.617677, acc.: 62.50%] [G loss: 0.545217]\n",
      "epoch:10 step:9871 [D loss: 0.645062, acc.: 69.53%] [G loss: 0.514666]\n",
      "epoch:10 step:9872 [D loss: 0.611073, acc.: 61.72%] [G loss: 0.422734]\n",
      "epoch:10 step:9873 [D loss: 0.521212, acc.: 73.44%] [G loss: 0.476787]\n",
      "epoch:10 step:9874 [D loss: 0.484081, acc.: 82.81%] [G loss: 0.621317]\n",
      "epoch:10 step:9875 [D loss: 0.515848, acc.: 77.34%] [G loss: 0.621573]\n",
      "epoch:10 step:9876 [D loss: 0.537568, acc.: 75.00%] [G loss: 0.604211]\n",
      "epoch:10 step:9877 [D loss: 0.516639, acc.: 75.78%] [G loss: 0.776744]\n",
      "epoch:10 step:9878 [D loss: 0.484194, acc.: 78.12%] [G loss: 0.851472]\n",
      "epoch:10 step:9879 [D loss: 0.541972, acc.: 71.88%] [G loss: 0.690139]\n",
      "epoch:10 step:9880 [D loss: 0.563523, acc.: 69.53%] [G loss: 0.621425]\n",
      "epoch:10 step:9881 [D loss: 0.692254, acc.: 53.91%] [G loss: 0.566030]\n",
      "epoch:10 step:9882 [D loss: 0.593811, acc.: 63.28%] [G loss: 0.451784]\n",
      "epoch:10 step:9883 [D loss: 0.587409, acc.: 66.41%] [G loss: 0.446168]\n",
      "epoch:10 step:9884 [D loss: 0.499577, acc.: 71.88%] [G loss: 0.544372]\n",
      "epoch:10 step:9885 [D loss: 0.539640, acc.: 70.31%] [G loss: 0.565765]\n",
      "epoch:10 step:9886 [D loss: 0.485975, acc.: 76.56%] [G loss: 0.656941]\n",
      "epoch:10 step:9887 [D loss: 0.501293, acc.: 75.00%] [G loss: 0.691189]\n",
      "epoch:10 step:9888 [D loss: 0.508344, acc.: 73.44%] [G loss: 0.566011]\n",
      "epoch:10 step:9889 [D loss: 0.472216, acc.: 78.91%] [G loss: 0.810809]\n",
      "epoch:10 step:9890 [D loss: 0.469090, acc.: 78.91%] [G loss: 0.589908]\n",
      "epoch:10 step:9891 [D loss: 0.501444, acc.: 73.44%] [G loss: 0.663476]\n",
      "epoch:10 step:9892 [D loss: 0.552211, acc.: 69.53%] [G loss: 0.804336]\n",
      "epoch:10 step:9893 [D loss: 0.492027, acc.: 77.34%] [G loss: 0.811427]\n",
      "epoch:10 step:9894 [D loss: 0.555460, acc.: 65.62%] [G loss: 0.663398]\n",
      "epoch:10 step:9895 [D loss: 0.558449, acc.: 68.75%] [G loss: 0.570618]\n",
      "epoch:10 step:9896 [D loss: 0.518042, acc.: 75.00%] [G loss: 0.603074]\n",
      "epoch:10 step:9897 [D loss: 0.578190, acc.: 63.28%] [G loss: 0.665834]\n",
      "epoch:10 step:9898 [D loss: 0.712779, acc.: 53.12%] [G loss: 0.516131]\n",
      "epoch:10 step:9899 [D loss: 0.613715, acc.: 62.50%] [G loss: 0.593318]\n",
      "epoch:10 step:9900 [D loss: 0.523042, acc.: 73.44%] [G loss: 0.624619]\n",
      "epoch:10 step:9901 [D loss: 0.600936, acc.: 61.72%] [G loss: 0.546184]\n",
      "epoch:10 step:9902 [D loss: 0.598586, acc.: 65.62%] [G loss: 0.459763]\n",
      "epoch:10 step:9903 [D loss: 0.580294, acc.: 68.75%] [G loss: 0.605787]\n",
      "epoch:10 step:9904 [D loss: 0.520114, acc.: 72.66%] [G loss: 0.716649]\n",
      "epoch:10 step:9905 [D loss: 0.654135, acc.: 58.59%] [G loss: 0.559982]\n",
      "epoch:10 step:9906 [D loss: 0.501794, acc.: 71.09%] [G loss: 0.507047]\n",
      "epoch:10 step:9907 [D loss: 0.547570, acc.: 69.53%] [G loss: 0.517190]\n",
      "epoch:10 step:9908 [D loss: 0.573214, acc.: 70.31%] [G loss: 0.543787]\n",
      "epoch:10 step:9909 [D loss: 0.531631, acc.: 72.66%] [G loss: 0.555520]\n",
      "epoch:10 step:9910 [D loss: 0.540744, acc.: 68.75%] [G loss: 0.456833]\n",
      "epoch:10 step:9911 [D loss: 0.545468, acc.: 67.97%] [G loss: 0.498875]\n",
      "epoch:10 step:9912 [D loss: 0.618749, acc.: 64.84%] [G loss: 0.546848]\n",
      "epoch:10 step:9913 [D loss: 0.567322, acc.: 69.53%] [G loss: 0.539000]\n",
      "epoch:10 step:9914 [D loss: 0.521994, acc.: 71.09%] [G loss: 0.580266]\n",
      "epoch:10 step:9915 [D loss: 0.572078, acc.: 65.62%] [G loss: 0.529279]\n",
      "epoch:10 step:9916 [D loss: 0.438773, acc.: 80.47%] [G loss: 0.851288]\n",
      "epoch:10 step:9917 [D loss: 0.537331, acc.: 67.97%] [G loss: 0.630948]\n",
      "epoch:10 step:9918 [D loss: 0.461527, acc.: 78.12%] [G loss: 0.709170]\n",
      "epoch:10 step:9919 [D loss: 0.515176, acc.: 71.88%] [G loss: 0.693481]\n",
      "epoch:10 step:9920 [D loss: 0.541101, acc.: 72.66%] [G loss: 0.643907]\n",
      "epoch:10 step:9921 [D loss: 0.470448, acc.: 78.91%] [G loss: 0.640104]\n",
      "epoch:10 step:9922 [D loss: 0.497978, acc.: 71.09%] [G loss: 0.568649]\n",
      "epoch:10 step:9923 [D loss: 0.545502, acc.: 67.97%] [G loss: 0.594694]\n",
      "epoch:10 step:9924 [D loss: 0.439292, acc.: 79.69%] [G loss: 0.684886]\n",
      "epoch:10 step:9925 [D loss: 0.495606, acc.: 78.91%] [G loss: 0.639624]\n",
      "epoch:10 step:9926 [D loss: 0.556215, acc.: 69.53%] [G loss: 0.562229]\n",
      "epoch:10 step:9927 [D loss: 0.560847, acc.: 73.44%] [G loss: 0.584473]\n",
      "epoch:10 step:9928 [D loss: 0.509639, acc.: 71.09%] [G loss: 0.666142]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:10 step:9929 [D loss: 0.620910, acc.: 61.72%] [G loss: 0.532272]\n",
      "epoch:10 step:9930 [D loss: 0.549696, acc.: 67.97%] [G loss: 0.492066]\n",
      "epoch:10 step:9931 [D loss: 0.528967, acc.: 74.22%] [G loss: 0.567228]\n",
      "epoch:10 step:9932 [D loss: 0.606867, acc.: 68.75%] [G loss: 0.647074]\n",
      "epoch:10 step:9933 [D loss: 0.504765, acc.: 74.22%] [G loss: 0.693807]\n",
      "epoch:10 step:9934 [D loss: 0.501532, acc.: 75.00%] [G loss: 0.689367]\n",
      "epoch:10 step:9935 [D loss: 0.606812, acc.: 61.72%] [G loss: 0.521641]\n",
      "epoch:10 step:9936 [D loss: 0.674258, acc.: 62.50%] [G loss: 0.530131]\n",
      "epoch:10 step:9937 [D loss: 0.538721, acc.: 71.09%] [G loss: 0.472193]\n",
      "epoch:10 step:9938 [D loss: 0.467778, acc.: 78.91%] [G loss: 0.461392]\n",
      "epoch:10 step:9939 [D loss: 0.552860, acc.: 69.53%] [G loss: 0.580505]\n",
      "epoch:10 step:9940 [D loss: 0.504858, acc.: 75.00%] [G loss: 0.546027]\n",
      "epoch:10 step:9941 [D loss: 0.563366, acc.: 67.19%] [G loss: 0.580225]\n",
      "epoch:10 step:9942 [D loss: 0.534500, acc.: 73.44%] [G loss: 0.574490]\n",
      "epoch:10 step:9943 [D loss: 0.596232, acc.: 66.41%] [G loss: 0.644914]\n",
      "epoch:10 step:9944 [D loss: 0.433002, acc.: 82.81%] [G loss: 0.725949]\n",
      "epoch:10 step:9945 [D loss: 0.510201, acc.: 75.78%] [G loss: 0.621661]\n",
      "epoch:10 step:9946 [D loss: 0.560565, acc.: 68.75%] [G loss: 0.649708]\n",
      "epoch:10 step:9947 [D loss: 0.548406, acc.: 71.09%] [G loss: 0.532019]\n",
      "epoch:10 step:9948 [D loss: 0.551837, acc.: 71.88%] [G loss: 0.453242]\n",
      "epoch:10 step:9949 [D loss: 0.530215, acc.: 70.31%] [G loss: 0.617579]\n",
      "epoch:10 step:9950 [D loss: 0.553553, acc.: 69.53%] [G loss: 0.510673]\n",
      "epoch:10 step:9951 [D loss: 0.575475, acc.: 71.09%] [G loss: 0.678077]\n",
      "epoch:10 step:9952 [D loss: 0.478593, acc.: 77.34%] [G loss: 0.653121]\n",
      "epoch:10 step:9953 [D loss: 0.557866, acc.: 72.66%] [G loss: 0.589604]\n",
      "epoch:10 step:9954 [D loss: 0.575588, acc.: 61.72%] [G loss: 0.613258]\n",
      "epoch:10 step:9955 [D loss: 0.565369, acc.: 71.88%] [G loss: 0.537695]\n",
      "epoch:10 step:9956 [D loss: 0.577001, acc.: 70.31%] [G loss: 0.389265]\n",
      "epoch:10 step:9957 [D loss: 0.594713, acc.: 64.06%] [G loss: 0.473421]\n",
      "epoch:10 step:9958 [D loss: 0.518493, acc.: 72.66%] [G loss: 0.518741]\n",
      "epoch:10 step:9959 [D loss: 0.519328, acc.: 73.44%] [G loss: 0.746461]\n",
      "epoch:10 step:9960 [D loss: 0.656977, acc.: 65.62%] [G loss: 0.817275]\n",
      "epoch:10 step:9961 [D loss: 0.589964, acc.: 68.75%] [G loss: 0.544108]\n",
      "epoch:10 step:9962 [D loss: 0.485763, acc.: 75.78%] [G loss: 0.561301]\n",
      "epoch:10 step:9963 [D loss: 0.521239, acc.: 75.78%] [G loss: 0.552007]\n",
      "epoch:10 step:9964 [D loss: 0.602018, acc.: 64.84%] [G loss: 0.602982]\n",
      "epoch:10 step:9965 [D loss: 0.594926, acc.: 67.97%] [G loss: 0.472187]\n",
      "epoch:10 step:9966 [D loss: 0.510026, acc.: 75.00%] [G loss: 0.657288]\n",
      "epoch:10 step:9967 [D loss: 0.518250, acc.: 75.00%] [G loss: 0.568126]\n",
      "epoch:10 step:9968 [D loss: 0.515891, acc.: 75.78%] [G loss: 0.738645]\n",
      "epoch:10 step:9969 [D loss: 0.505468, acc.: 71.88%] [G loss: 0.784826]\n",
      "epoch:10 step:9970 [D loss: 0.672641, acc.: 55.47%] [G loss: 0.626113]\n",
      "epoch:10 step:9971 [D loss: 0.508085, acc.: 72.66%] [G loss: 0.728931]\n",
      "epoch:10 step:9972 [D loss: 0.467515, acc.: 75.00%] [G loss: 0.815891]\n",
      "epoch:10 step:9973 [D loss: 0.477621, acc.: 78.91%] [G loss: 0.611786]\n",
      "epoch:10 step:9974 [D loss: 0.611478, acc.: 64.06%] [G loss: 0.456686]\n",
      "epoch:10 step:9975 [D loss: 0.477049, acc.: 78.12%] [G loss: 0.498917]\n",
      "epoch:10 step:9976 [D loss: 0.562494, acc.: 66.41%] [G loss: 0.570047]\n",
      "epoch:10 step:9977 [D loss: 0.542377, acc.: 67.97%] [G loss: 0.573136]\n",
      "epoch:10 step:9978 [D loss: 0.583746, acc.: 66.41%] [G loss: 0.586947]\n",
      "epoch:10 step:9979 [D loss: 0.524258, acc.: 71.88%] [G loss: 0.616700]\n",
      "epoch:10 step:9980 [D loss: 0.550671, acc.: 69.53%] [G loss: 0.441711]\n",
      "epoch:10 step:9981 [D loss: 0.532850, acc.: 67.97%] [G loss: 0.479415]\n",
      "epoch:10 step:9982 [D loss: 0.576606, acc.: 67.97%] [G loss: 0.486581]\n",
      "epoch:10 step:9983 [D loss: 0.490514, acc.: 76.56%] [G loss: 0.446577]\n",
      "epoch:10 step:9984 [D loss: 0.558534, acc.: 71.09%] [G loss: 0.550635]\n",
      "epoch:10 step:9985 [D loss: 0.593151, acc.: 64.84%] [G loss: 0.576762]\n",
      "epoch:10 step:9986 [D loss: 0.553157, acc.: 70.31%] [G loss: 0.609301]\n",
      "epoch:10 step:9987 [D loss: 0.509143, acc.: 74.22%] [G loss: 0.564879]\n",
      "epoch:10 step:9988 [D loss: 0.562592, acc.: 65.62%] [G loss: 0.521667]\n",
      "epoch:10 step:9989 [D loss: 0.618236, acc.: 67.19%] [G loss: 0.525946]\n",
      "epoch:10 step:9990 [D loss: 0.493751, acc.: 75.00%] [G loss: 0.577498]\n",
      "epoch:10 step:9991 [D loss: 0.567165, acc.: 66.41%] [G loss: 0.648692]\n",
      "epoch:10 step:9992 [D loss: 0.607345, acc.: 65.62%] [G loss: 0.434314]\n",
      "epoch:10 step:9993 [D loss: 0.538590, acc.: 69.53%] [G loss: 0.625482]\n",
      "epoch:10 step:9994 [D loss: 0.483877, acc.: 76.56%] [G loss: 0.741084]\n",
      "epoch:10 step:9995 [D loss: 0.591916, acc.: 66.41%] [G loss: 0.603577]\n",
      "epoch:10 step:9996 [D loss: 0.509279, acc.: 75.00%] [G loss: 0.651074]\n",
      "epoch:10 step:9997 [D loss: 0.549428, acc.: 71.88%] [G loss: 0.516253]\n",
      "epoch:10 step:9998 [D loss: 0.556069, acc.: 66.41%] [G loss: 0.502737]\n",
      "epoch:10 step:9999 [D loss: 0.494431, acc.: 77.34%] [G loss: 0.634275]\n",
      "epoch:10 step:10000 [D loss: 0.545219, acc.: 72.66%] [G loss: 0.446701]\n",
      "epoch:10 step:10001 [D loss: 0.490191, acc.: 81.25%] [G loss: 0.644464]\n",
      "epoch:10 step:10002 [D loss: 0.515927, acc.: 72.66%] [G loss: 0.609121]\n",
      "epoch:10 step:10003 [D loss: 0.488469, acc.: 79.69%] [G loss: 0.695154]\n",
      "epoch:10 step:10004 [D loss: 0.467218, acc.: 78.91%] [G loss: 0.757316]\n",
      "epoch:10 step:10005 [D loss: 0.552278, acc.: 66.41%] [G loss: 0.679214]\n",
      "epoch:10 step:10006 [D loss: 0.559464, acc.: 67.97%] [G loss: 0.592791]\n",
      "epoch:10 step:10007 [D loss: 0.560170, acc.: 70.31%] [G loss: 0.568655]\n",
      "epoch:10 step:10008 [D loss: 0.530465, acc.: 73.44%] [G loss: 0.605007]\n",
      "epoch:10 step:10009 [D loss: 0.462502, acc.: 80.47%] [G loss: 0.660829]\n",
      "epoch:10 step:10010 [D loss: 0.504694, acc.: 75.00%] [G loss: 0.646940]\n",
      "epoch:10 step:10011 [D loss: 0.479278, acc.: 75.78%] [G loss: 0.789627]\n",
      "epoch:10 step:10012 [D loss: 0.447699, acc.: 78.12%] [G loss: 0.763534]\n",
      "epoch:10 step:10013 [D loss: 0.530768, acc.: 71.88%] [G loss: 0.701772]\n",
      "epoch:10 step:10014 [D loss: 0.600757, acc.: 65.62%] [G loss: 0.523728]\n",
      "epoch:10 step:10015 [D loss: 0.548959, acc.: 70.31%] [G loss: 0.557678]\n",
      "epoch:10 step:10016 [D loss: 0.520580, acc.: 70.31%] [G loss: 0.600166]\n",
      "epoch:10 step:10017 [D loss: 0.473649, acc.: 77.34%] [G loss: 0.641543]\n",
      "epoch:10 step:10018 [D loss: 0.407701, acc.: 78.12%] [G loss: 0.912004]\n",
      "epoch:10 step:10019 [D loss: 0.468870, acc.: 77.34%] [G loss: 0.899601]\n",
      "epoch:10 step:10020 [D loss: 0.503177, acc.: 75.78%] [G loss: 0.691761]\n",
      "epoch:10 step:10021 [D loss: 0.513183, acc.: 73.44%] [G loss: 0.733163]\n",
      "epoch:10 step:10022 [D loss: 0.614600, acc.: 67.19%] [G loss: 0.580481]\n",
      "epoch:10 step:10023 [D loss: 0.595132, acc.: 62.50%] [G loss: 0.496665]\n",
      "epoch:10 step:10024 [D loss: 0.542906, acc.: 68.75%] [G loss: 0.563641]\n",
      "epoch:10 step:10025 [D loss: 0.515316, acc.: 77.34%] [G loss: 0.634861]\n",
      "epoch:10 step:10026 [D loss: 0.560250, acc.: 71.09%] [G loss: 0.560736]\n",
      "epoch:10 step:10027 [D loss: 0.526715, acc.: 75.00%] [G loss: 0.615074]\n",
      "epoch:10 step:10028 [D loss: 0.535549, acc.: 73.44%] [G loss: 0.638997]\n",
      "epoch:10 step:10029 [D loss: 0.562006, acc.: 68.75%] [G loss: 0.652935]\n",
      "epoch:10 step:10030 [D loss: 0.514926, acc.: 72.66%] [G loss: 0.577401]\n",
      "epoch:10 step:10031 [D loss: 0.515956, acc.: 74.22%] [G loss: 0.627956]\n",
      "epoch:10 step:10032 [D loss: 0.583365, acc.: 67.97%] [G loss: 0.633413]\n",
      "epoch:10 step:10033 [D loss: 0.582070, acc.: 67.97%] [G loss: 0.586797]\n",
      "epoch:10 step:10034 [D loss: 0.545105, acc.: 66.41%] [G loss: 0.630691]\n",
      "epoch:10 step:10035 [D loss: 0.567281, acc.: 70.31%] [G loss: 0.774449]\n",
      "epoch:10 step:10036 [D loss: 0.522586, acc.: 72.66%] [G loss: 0.632722]\n",
      "epoch:10 step:10037 [D loss: 0.517160, acc.: 75.00%] [G loss: 0.604445]\n",
      "epoch:10 step:10038 [D loss: 0.498466, acc.: 72.66%] [G loss: 0.595407]\n",
      "epoch:10 step:10039 [D loss: 0.550484, acc.: 71.09%] [G loss: 0.536731]\n",
      "epoch:10 step:10040 [D loss: 0.506823, acc.: 75.00%] [G loss: 0.609633]\n",
      "epoch:10 step:10041 [D loss: 0.579141, acc.: 65.62%] [G loss: 0.489344]\n",
      "epoch:10 step:10042 [D loss: 0.525322, acc.: 75.00%] [G loss: 0.633959]\n",
      "epoch:10 step:10043 [D loss: 0.592764, acc.: 67.19%] [G loss: 0.691801]\n",
      "epoch:10 step:10044 [D loss: 0.568601, acc.: 72.66%] [G loss: 0.557798]\n",
      "epoch:10 step:10045 [D loss: 0.560713, acc.: 69.53%] [G loss: 0.760427]\n",
      "epoch:10 step:10046 [D loss: 0.528090, acc.: 72.66%] [G loss: 0.798238]\n",
      "epoch:10 step:10047 [D loss: 0.481810, acc.: 76.56%] [G loss: 0.771726]\n",
      "epoch:10 step:10048 [D loss: 0.620074, acc.: 61.72%] [G loss: 0.605617]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:10 step:10049 [D loss: 0.499499, acc.: 74.22%] [G loss: 0.575043]\n",
      "epoch:10 step:10050 [D loss: 0.490416, acc.: 73.44%] [G loss: 0.662060]\n",
      "epoch:10 step:10051 [D loss: 0.482936, acc.: 75.00%] [G loss: 0.676719]\n",
      "epoch:10 step:10052 [D loss: 0.544552, acc.: 74.22%] [G loss: 0.541793]\n",
      "epoch:10 step:10053 [D loss: 0.525119, acc.: 68.75%] [G loss: 0.685787]\n",
      "epoch:10 step:10054 [D loss: 0.582067, acc.: 64.06%] [G loss: 0.511751]\n",
      "epoch:10 step:10055 [D loss: 0.496290, acc.: 75.78%] [G loss: 0.625911]\n",
      "epoch:10 step:10056 [D loss: 0.564999, acc.: 68.75%] [G loss: 0.473888]\n",
      "epoch:10 step:10057 [D loss: 0.543080, acc.: 71.88%] [G loss: 0.587447]\n",
      "epoch:10 step:10058 [D loss: 0.500404, acc.: 76.56%] [G loss: 0.494755]\n",
      "epoch:10 step:10059 [D loss: 0.578404, acc.: 69.53%] [G loss: 0.504232]\n",
      "epoch:10 step:10060 [D loss: 0.505868, acc.: 79.69%] [G loss: 0.723603]\n",
      "epoch:10 step:10061 [D loss: 0.445835, acc.: 82.03%] [G loss: 0.685918]\n",
      "epoch:10 step:10062 [D loss: 0.518365, acc.: 75.00%] [G loss: 0.556996]\n",
      "epoch:10 step:10063 [D loss: 0.481966, acc.: 75.78%] [G loss: 0.671034]\n",
      "epoch:10 step:10064 [D loss: 0.461727, acc.: 81.25%] [G loss: 0.640568]\n",
      "epoch:10 step:10065 [D loss: 0.630831, acc.: 67.19%] [G loss: 0.596840]\n",
      "epoch:10 step:10066 [D loss: 0.676239, acc.: 57.81%] [G loss: 0.489462]\n",
      "epoch:10 step:10067 [D loss: 0.570077, acc.: 64.84%] [G loss: 0.505821]\n",
      "epoch:10 step:10068 [D loss: 0.563906, acc.: 70.31%] [G loss: 0.633320]\n",
      "epoch:10 step:10069 [D loss: 0.521861, acc.: 72.66%] [G loss: 0.600476]\n",
      "epoch:10 step:10070 [D loss: 0.531133, acc.: 71.88%] [G loss: 0.785086]\n",
      "epoch:10 step:10071 [D loss: 0.497084, acc.: 78.12%] [G loss: 0.756679]\n",
      "epoch:10 step:10072 [D loss: 0.608842, acc.: 64.06%] [G loss: 0.624234]\n",
      "epoch:10 step:10073 [D loss: 0.566103, acc.: 69.53%] [G loss: 0.540851]\n",
      "epoch:10 step:10074 [D loss: 0.617658, acc.: 60.94%] [G loss: 0.442868]\n",
      "epoch:10 step:10075 [D loss: 0.538879, acc.: 71.88%] [G loss: 0.539456]\n",
      "epoch:10 step:10076 [D loss: 0.539200, acc.: 71.09%] [G loss: 0.635238]\n",
      "epoch:10 step:10077 [D loss: 0.521680, acc.: 70.31%] [G loss: 0.655095]\n",
      "epoch:10 step:10078 [D loss: 0.509534, acc.: 78.91%] [G loss: 0.609465]\n",
      "epoch:10 step:10079 [D loss: 0.558804, acc.: 69.53%] [G loss: 0.656189]\n",
      "epoch:10 step:10080 [D loss: 0.565853, acc.: 67.97%] [G loss: 0.542184]\n",
      "epoch:10 step:10081 [D loss: 0.568486, acc.: 68.75%] [G loss: 0.492010]\n",
      "epoch:10 step:10082 [D loss: 0.497158, acc.: 70.31%] [G loss: 0.546589]\n",
      "epoch:10 step:10083 [D loss: 0.586548, acc.: 64.84%] [G loss: 0.547762]\n",
      "epoch:10 step:10084 [D loss: 0.523912, acc.: 72.66%] [G loss: 0.622203]\n",
      "epoch:10 step:10085 [D loss: 0.534410, acc.: 74.22%] [G loss: 0.524964]\n",
      "epoch:10 step:10086 [D loss: 0.603854, acc.: 66.41%] [G loss: 0.470091]\n",
      "epoch:10 step:10087 [D loss: 0.573670, acc.: 66.41%] [G loss: 0.485509]\n",
      "epoch:10 step:10088 [D loss: 0.602201, acc.: 61.72%] [G loss: 0.509519]\n",
      "epoch:10 step:10089 [D loss: 0.471270, acc.: 75.78%] [G loss: 0.767593]\n",
      "epoch:10 step:10090 [D loss: 0.617317, acc.: 65.62%] [G loss: 0.517089]\n",
      "epoch:10 step:10091 [D loss: 0.547381, acc.: 68.75%] [G loss: 0.634739]\n",
      "epoch:10 step:10092 [D loss: 0.574875, acc.: 64.84%] [G loss: 0.575014]\n",
      "epoch:10 step:10093 [D loss: 0.525645, acc.: 72.66%] [G loss: 0.592590]\n",
      "epoch:10 step:10094 [D loss: 0.504191, acc.: 75.00%] [G loss: 0.471794]\n",
      "epoch:10 step:10095 [D loss: 0.476480, acc.: 78.91%] [G loss: 0.676887]\n",
      "epoch:10 step:10096 [D loss: 0.516785, acc.: 71.88%] [G loss: 0.588356]\n",
      "epoch:10 step:10097 [D loss: 0.560194, acc.: 70.31%] [G loss: 0.594555]\n",
      "epoch:10 step:10098 [D loss: 0.526844, acc.: 69.53%] [G loss: 0.647685]\n",
      "epoch:10 step:10099 [D loss: 0.601833, acc.: 64.84%] [G loss: 0.627041]\n",
      "epoch:10 step:10100 [D loss: 0.551870, acc.: 68.75%] [G loss: 0.470955]\n",
      "epoch:10 step:10101 [D loss: 0.541091, acc.: 71.09%] [G loss: 0.597729]\n",
      "epoch:10 step:10102 [D loss: 0.505594, acc.: 72.66%] [G loss: 0.625982]\n",
      "epoch:10 step:10103 [D loss: 0.555894, acc.: 70.31%] [G loss: 0.466767]\n",
      "epoch:10 step:10104 [D loss: 0.522604, acc.: 71.88%] [G loss: 0.591011]\n",
      "epoch:10 step:10105 [D loss: 0.534246, acc.: 67.97%] [G loss: 0.603004]\n",
      "epoch:10 step:10106 [D loss: 0.476976, acc.: 75.78%] [G loss: 0.588615]\n",
      "epoch:10 step:10107 [D loss: 0.504423, acc.: 74.22%] [G loss: 0.628755]\n",
      "epoch:10 step:10108 [D loss: 0.597423, acc.: 63.28%] [G loss: 0.552007]\n",
      "epoch:10 step:10109 [D loss: 0.629797, acc.: 64.06%] [G loss: 0.537673]\n",
      "epoch:10 step:10110 [D loss: 0.612046, acc.: 61.72%] [G loss: 0.467200]\n",
      "epoch:10 step:10111 [D loss: 0.524743, acc.: 67.97%] [G loss: 0.509341]\n",
      "epoch:10 step:10112 [D loss: 0.503403, acc.: 74.22%] [G loss: 0.558678]\n",
      "epoch:10 step:10113 [D loss: 0.487999, acc.: 77.34%] [G loss: 0.649070]\n",
      "epoch:10 step:10114 [D loss: 0.546791, acc.: 70.31%] [G loss: 0.649299]\n",
      "epoch:10 step:10115 [D loss: 0.537268, acc.: 72.66%] [G loss: 0.654522]\n",
      "epoch:10 step:10116 [D loss: 0.438756, acc.: 81.25%] [G loss: 0.697609]\n",
      "epoch:10 step:10117 [D loss: 0.495805, acc.: 75.00%] [G loss: 0.692328]\n",
      "epoch:10 step:10118 [D loss: 0.532745, acc.: 71.09%] [G loss: 0.692638]\n",
      "epoch:10 step:10119 [D loss: 0.569059, acc.: 70.31%] [G loss: 0.604578]\n",
      "epoch:10 step:10120 [D loss: 0.505368, acc.: 75.78%] [G loss: 0.689159]\n",
      "epoch:10 step:10121 [D loss: 0.497843, acc.: 78.12%] [G loss: 0.618915]\n",
      "epoch:10 step:10122 [D loss: 0.590842, acc.: 65.62%] [G loss: 0.559178]\n",
      "epoch:10 step:10123 [D loss: 0.520116, acc.: 69.53%] [G loss: 0.653257]\n",
      "epoch:10 step:10124 [D loss: 0.522904, acc.: 71.88%] [G loss: 0.770085]\n",
      "epoch:10 step:10125 [D loss: 0.537790, acc.: 72.66%] [G loss: 0.615853]\n",
      "epoch:10 step:10126 [D loss: 0.565052, acc.: 68.75%] [G loss: 0.427380]\n",
      "epoch:10 step:10127 [D loss: 0.546794, acc.: 71.88%] [G loss: 0.527313]\n",
      "epoch:10 step:10128 [D loss: 0.488821, acc.: 76.56%] [G loss: 0.615462]\n",
      "epoch:10 step:10129 [D loss: 0.532244, acc.: 69.53%] [G loss: 0.533705]\n",
      "epoch:10 step:10130 [D loss: 0.481161, acc.: 75.78%] [G loss: 0.516173]\n",
      "epoch:10 step:10131 [D loss: 0.548279, acc.: 73.44%] [G loss: 0.551347]\n",
      "epoch:10 step:10132 [D loss: 0.597419, acc.: 66.41%] [G loss: 0.666414]\n",
      "epoch:10 step:10133 [D loss: 0.615436, acc.: 65.62%] [G loss: 0.574140]\n",
      "epoch:10 step:10134 [D loss: 0.574037, acc.: 67.19%] [G loss: 0.614760]\n",
      "epoch:10 step:10135 [D loss: 0.586576, acc.: 64.84%] [G loss: 0.580061]\n",
      "epoch:10 step:10136 [D loss: 0.616880, acc.: 66.41%] [G loss: 0.474317]\n",
      "epoch:10 step:10137 [D loss: 0.534693, acc.: 69.53%] [G loss: 0.506967]\n",
      "epoch:10 step:10138 [D loss: 0.551202, acc.: 67.97%] [G loss: 0.689365]\n",
      "epoch:10 step:10139 [D loss: 0.501558, acc.: 71.88%] [G loss: 0.768237]\n",
      "epoch:10 step:10140 [D loss: 0.511293, acc.: 72.66%] [G loss: 0.760289]\n",
      "epoch:10 step:10141 [D loss: 0.508980, acc.: 75.00%] [G loss: 0.780276]\n",
      "epoch:10 step:10142 [D loss: 0.523833, acc.: 72.66%] [G loss: 0.745235]\n",
      "epoch:10 step:10143 [D loss: 0.508781, acc.: 71.09%] [G loss: 0.649817]\n",
      "epoch:10 step:10144 [D loss: 0.570249, acc.: 68.75%] [G loss: 0.561408]\n",
      "epoch:10 step:10145 [D loss: 0.565591, acc.: 69.53%] [G loss: 0.572068]\n",
      "epoch:10 step:10146 [D loss: 0.593371, acc.: 67.19%] [G loss: 0.588624]\n",
      "epoch:10 step:10147 [D loss: 0.558349, acc.: 70.31%] [G loss: 0.646622]\n",
      "epoch:10 step:10148 [D loss: 0.633972, acc.: 65.62%] [G loss: 0.663021]\n",
      "epoch:10 step:10149 [D loss: 0.581068, acc.: 68.75%] [G loss: 0.570072]\n",
      "epoch:10 step:10150 [D loss: 0.536165, acc.: 75.00%] [G loss: 0.687463]\n",
      "epoch:10 step:10151 [D loss: 0.426687, acc.: 82.81%] [G loss: 0.755756]\n",
      "epoch:10 step:10152 [D loss: 0.464771, acc.: 75.78%] [G loss: 0.805716]\n",
      "epoch:10 step:10153 [D loss: 0.531953, acc.: 67.97%] [G loss: 0.723972]\n",
      "epoch:10 step:10154 [D loss: 0.646730, acc.: 64.06%] [G loss: 0.522997]\n",
      "epoch:10 step:10155 [D loss: 0.533938, acc.: 73.44%] [G loss: 0.636712]\n",
      "epoch:10 step:10156 [D loss: 0.541672, acc.: 68.75%] [G loss: 0.539690]\n",
      "epoch:10 step:10157 [D loss: 0.604213, acc.: 67.19%] [G loss: 0.583313]\n",
      "epoch:10 step:10158 [D loss: 0.667839, acc.: 57.81%] [G loss: 0.468705]\n",
      "epoch:10 step:10159 [D loss: 0.546810, acc.: 74.22%] [G loss: 0.507699]\n",
      "epoch:10 step:10160 [D loss: 0.531570, acc.: 69.53%] [G loss: 0.597569]\n",
      "epoch:10 step:10161 [D loss: 0.507390, acc.: 78.12%] [G loss: 0.635534]\n",
      "epoch:10 step:10162 [D loss: 0.497384, acc.: 72.66%] [G loss: 0.591349]\n",
      "epoch:10 step:10163 [D loss: 0.584919, acc.: 68.75%] [G loss: 0.616103]\n",
      "epoch:10 step:10164 [D loss: 0.616394, acc.: 64.84%] [G loss: 0.678588]\n",
      "epoch:10 step:10165 [D loss: 0.495595, acc.: 75.78%] [G loss: 0.742117]\n",
      "epoch:10 step:10166 [D loss: 0.518574, acc.: 71.09%] [G loss: 0.663532]\n",
      "epoch:10 step:10167 [D loss: 0.596543, acc.: 62.50%] [G loss: 0.633304]\n",
      "epoch:10 step:10168 [D loss: 0.530776, acc.: 66.41%] [G loss: 0.674822]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:10 step:10169 [D loss: 0.564456, acc.: 75.00%] [G loss: 0.666095]\n",
      "epoch:10 step:10170 [D loss: 0.554038, acc.: 64.84%] [G loss: 0.582767]\n",
      "epoch:10 step:10171 [D loss: 0.488142, acc.: 79.69%] [G loss: 0.624882]\n",
      "epoch:10 step:10172 [D loss: 0.497083, acc.: 77.34%] [G loss: 0.638135]\n",
      "epoch:10 step:10173 [D loss: 0.513056, acc.: 75.78%] [G loss: 0.702627]\n",
      "epoch:10 step:10174 [D loss: 0.529310, acc.: 67.19%] [G loss: 0.658911]\n",
      "epoch:10 step:10175 [D loss: 0.599144, acc.: 64.84%] [G loss: 0.543910]\n",
      "epoch:10 step:10176 [D loss: 0.520713, acc.: 72.66%] [G loss: 0.458496]\n",
      "epoch:10 step:10177 [D loss: 0.512680, acc.: 75.00%] [G loss: 0.489638]\n",
      "epoch:10 step:10178 [D loss: 0.567853, acc.: 74.22%] [G loss: 0.667712]\n",
      "epoch:10 step:10179 [D loss: 0.510969, acc.: 75.00%] [G loss: 0.441446]\n",
      "epoch:10 step:10180 [D loss: 0.483544, acc.: 77.34%] [G loss: 0.647585]\n",
      "epoch:10 step:10181 [D loss: 0.541018, acc.: 75.78%] [G loss: 0.723013]\n",
      "epoch:10 step:10182 [D loss: 0.593025, acc.: 64.84%] [G loss: 0.551436]\n",
      "epoch:10 step:10183 [D loss: 0.552404, acc.: 66.41%] [G loss: 0.551724]\n",
      "epoch:10 step:10184 [D loss: 0.501841, acc.: 75.00%] [G loss: 0.540054]\n",
      "epoch:10 step:10185 [D loss: 0.522462, acc.: 68.75%] [G loss: 0.647213]\n",
      "epoch:10 step:10186 [D loss: 0.576776, acc.: 68.75%] [G loss: 0.662743]\n",
      "epoch:10 step:10187 [D loss: 0.609308, acc.: 67.97%] [G loss: 0.534396]\n",
      "epoch:10 step:10188 [D loss: 0.572818, acc.: 69.53%] [G loss: 0.775476]\n",
      "epoch:10 step:10189 [D loss: 0.526865, acc.: 73.44%] [G loss: 0.636528]\n",
      "epoch:10 step:10190 [D loss: 0.573861, acc.: 73.44%] [G loss: 0.503971]\n",
      "epoch:10 step:10191 [D loss: 0.560086, acc.: 64.84%] [G loss: 0.510774]\n",
      "epoch:10 step:10192 [D loss: 0.508099, acc.: 74.22%] [G loss: 0.469187]\n",
      "epoch:10 step:10193 [D loss: 0.483754, acc.: 72.66%] [G loss: 0.601661]\n",
      "epoch:10 step:10194 [D loss: 0.587356, acc.: 64.84%] [G loss: 0.552295]\n",
      "epoch:10 step:10195 [D loss: 0.500032, acc.: 73.44%] [G loss: 0.589196]\n",
      "epoch:10 step:10196 [D loss: 0.529446, acc.: 70.31%] [G loss: 0.642439]\n",
      "epoch:10 step:10197 [D loss: 0.562931, acc.: 70.31%] [G loss: 0.539189]\n",
      "epoch:10 step:10198 [D loss: 0.629284, acc.: 58.59%] [G loss: 0.656752]\n",
      "epoch:10 step:10199 [D loss: 0.557519, acc.: 67.19%] [G loss: 0.731049]\n",
      "epoch:10 step:10200 [D loss: 0.567481, acc.: 66.41%] [G loss: 0.695527]\n",
      "epoch:10 step:10201 [D loss: 0.558277, acc.: 72.66%] [G loss: 0.589498]\n",
      "epoch:10 step:10202 [D loss: 0.559924, acc.: 67.97%] [G loss: 0.565639]\n",
      "epoch:10 step:10203 [D loss: 0.487790, acc.: 76.56%] [G loss: 0.635867]\n",
      "epoch:10 step:10204 [D loss: 0.524148, acc.: 67.97%] [G loss: 0.494882]\n",
      "epoch:10 step:10205 [D loss: 0.500773, acc.: 75.00%] [G loss: 0.560957]\n",
      "epoch:10 step:10206 [D loss: 0.607745, acc.: 66.41%] [G loss: 0.414774]\n",
      "epoch:10 step:10207 [D loss: 0.506401, acc.: 73.44%] [G loss: 0.631606]\n",
      "epoch:10 step:10208 [D loss: 0.503518, acc.: 74.22%] [G loss: 0.664926]\n",
      "epoch:10 step:10209 [D loss: 0.568896, acc.: 68.75%] [G loss: 0.471598]\n",
      "epoch:10 step:10210 [D loss: 0.605304, acc.: 64.06%] [G loss: 0.466087]\n",
      "epoch:10 step:10211 [D loss: 0.516908, acc.: 73.44%] [G loss: 0.531715]\n",
      "epoch:10 step:10212 [D loss: 0.504099, acc.: 73.44%] [G loss: 0.538969]\n",
      "epoch:10 step:10213 [D loss: 0.483813, acc.: 75.00%] [G loss: 0.656315]\n",
      "epoch:10 step:10214 [D loss: 0.568481, acc.: 68.75%] [G loss: 0.677915]\n",
      "epoch:10 step:10215 [D loss: 0.567248, acc.: 64.84%] [G loss: 0.704112]\n",
      "epoch:10 step:10216 [D loss: 0.573174, acc.: 71.09%] [G loss: 0.569203]\n",
      "epoch:10 step:10217 [D loss: 0.585581, acc.: 67.19%] [G loss: 0.483917]\n",
      "epoch:10 step:10218 [D loss: 0.557716, acc.: 64.84%] [G loss: 0.523696]\n",
      "epoch:10 step:10219 [D loss: 0.572290, acc.: 69.53%] [G loss: 0.603749]\n",
      "epoch:10 step:10220 [D loss: 0.579215, acc.: 68.75%] [G loss: 0.484014]\n",
      "epoch:10 step:10221 [D loss: 0.609376, acc.: 62.50%] [G loss: 0.608873]\n",
      "epoch:10 step:10222 [D loss: 0.530592, acc.: 70.31%] [G loss: 0.510581]\n",
      "epoch:10 step:10223 [D loss: 0.589788, acc.: 65.62%] [G loss: 0.613999]\n",
      "epoch:10 step:10224 [D loss: 0.473088, acc.: 71.88%] [G loss: 0.656256]\n",
      "epoch:10 step:10225 [D loss: 0.531144, acc.: 67.19%] [G loss: 0.572275]\n",
      "epoch:10 step:10226 [D loss: 0.613620, acc.: 65.62%] [G loss: 0.489577]\n",
      "epoch:10 step:10227 [D loss: 0.490605, acc.: 74.22%] [G loss: 0.653043]\n",
      "epoch:10 step:10228 [D loss: 0.696145, acc.: 59.38%] [G loss: 0.633966]\n",
      "epoch:10 step:10229 [D loss: 0.568975, acc.: 67.97%] [G loss: 0.665063]\n",
      "epoch:10 step:10230 [D loss: 0.425503, acc.: 82.81%] [G loss: 0.809227]\n",
      "epoch:10 step:10231 [D loss: 0.662104, acc.: 64.06%] [G loss: 0.574188]\n",
      "epoch:10 step:10232 [D loss: 0.558919, acc.: 67.19%] [G loss: 0.483223]\n",
      "epoch:10 step:10233 [D loss: 0.538650, acc.: 70.31%] [G loss: 0.481338]\n",
      "epoch:10 step:10234 [D loss: 0.523328, acc.: 68.75%] [G loss: 0.436030]\n",
      "epoch:10 step:10235 [D loss: 0.548870, acc.: 70.31%] [G loss: 0.575478]\n",
      "epoch:10 step:10236 [D loss: 0.537900, acc.: 69.53%] [G loss: 0.530158]\n",
      "epoch:10 step:10237 [D loss: 0.672298, acc.: 59.38%] [G loss: 0.437618]\n",
      "epoch:10 step:10238 [D loss: 0.501426, acc.: 73.44%] [G loss: 0.463162]\n",
      "epoch:10 step:10239 [D loss: 0.568549, acc.: 66.41%] [G loss: 0.484419]\n",
      "epoch:10 step:10240 [D loss: 0.454390, acc.: 81.25%] [G loss: 0.662053]\n",
      "epoch:10 step:10241 [D loss: 0.492825, acc.: 76.56%] [G loss: 0.590877]\n",
      "epoch:10 step:10242 [D loss: 0.562690, acc.: 67.97%] [G loss: 0.622530]\n",
      "epoch:10 step:10243 [D loss: 0.645437, acc.: 60.16%] [G loss: 0.533482]\n",
      "epoch:10 step:10244 [D loss: 0.564925, acc.: 65.62%] [G loss: 0.429669]\n",
      "epoch:10 step:10245 [D loss: 0.481387, acc.: 78.12%] [G loss: 0.558042]\n",
      "epoch:10 step:10246 [D loss: 0.530129, acc.: 72.66%] [G loss: 0.666774]\n",
      "epoch:10 step:10247 [D loss: 0.590536, acc.: 62.50%] [G loss: 0.655172]\n",
      "epoch:10 step:10248 [D loss: 0.573176, acc.: 70.31%] [G loss: 0.486354]\n",
      "epoch:10 step:10249 [D loss: 0.572632, acc.: 69.53%] [G loss: 0.405430]\n",
      "epoch:10 step:10250 [D loss: 0.618308, acc.: 56.25%] [G loss: 0.519654]\n",
      "epoch:10 step:10251 [D loss: 0.590697, acc.: 57.03%] [G loss: 0.517702]\n",
      "epoch:10 step:10252 [D loss: 0.605269, acc.: 62.50%] [G loss: 0.510537]\n",
      "epoch:10 step:10253 [D loss: 0.629590, acc.: 63.28%] [G loss: 0.450710]\n",
      "epoch:10 step:10254 [D loss: 0.468299, acc.: 79.69%] [G loss: 0.625072]\n",
      "epoch:10 step:10255 [D loss: 0.503843, acc.: 73.44%] [G loss: 0.627148]\n",
      "epoch:10 step:10256 [D loss: 0.522809, acc.: 75.00%] [G loss: 0.747556]\n",
      "epoch:10 step:10257 [D loss: 0.493608, acc.: 71.09%] [G loss: 0.727440]\n",
      "epoch:10 step:10258 [D loss: 0.586332, acc.: 67.97%] [G loss: 0.533025]\n",
      "epoch:10 step:10259 [D loss: 0.557669, acc.: 67.19%] [G loss: 0.517297]\n",
      "epoch:10 step:10260 [D loss: 0.493974, acc.: 76.56%] [G loss: 0.553586]\n",
      "epoch:10 step:10261 [D loss: 0.576143, acc.: 67.97%] [G loss: 0.614459]\n",
      "epoch:10 step:10262 [D loss: 0.657304, acc.: 65.62%] [G loss: 0.431585]\n",
      "epoch:10 step:10263 [D loss: 0.547517, acc.: 66.41%] [G loss: 0.445713]\n",
      "epoch:10 step:10264 [D loss: 0.505855, acc.: 75.00%] [G loss: 0.589902]\n",
      "epoch:10 step:10265 [D loss: 0.538645, acc.: 72.66%] [G loss: 0.689004]\n",
      "epoch:10 step:10266 [D loss: 0.545450, acc.: 71.88%] [G loss: 0.587905]\n",
      "epoch:10 step:10267 [D loss: 0.517656, acc.: 78.12%] [G loss: 0.778302]\n",
      "epoch:10 step:10268 [D loss: 0.482974, acc.: 80.47%] [G loss: 0.729863]\n",
      "epoch:10 step:10269 [D loss: 0.486778, acc.: 76.56%] [G loss: 0.697867]\n",
      "epoch:10 step:10270 [D loss: 0.568915, acc.: 73.44%] [G loss: 0.578268]\n",
      "epoch:10 step:10271 [D loss: 0.527031, acc.: 71.09%] [G loss: 0.647256]\n",
      "epoch:10 step:10272 [D loss: 0.583854, acc.: 64.06%] [G loss: 0.574061]\n",
      "epoch:10 step:10273 [D loss: 0.530974, acc.: 71.09%] [G loss: 0.642166]\n",
      "epoch:10 step:10274 [D loss: 0.589111, acc.: 68.75%] [G loss: 0.646361]\n",
      "epoch:10 step:10275 [D loss: 0.518136, acc.: 73.44%] [G loss: 0.722304]\n",
      "epoch:10 step:10276 [D loss: 0.563711, acc.: 69.53%] [G loss: 0.600551]\n",
      "epoch:10 step:10277 [D loss: 0.555946, acc.: 73.44%] [G loss: 0.505388]\n",
      "epoch:10 step:10278 [D loss: 0.593314, acc.: 63.28%] [G loss: 0.512377]\n",
      "epoch:10 step:10279 [D loss: 0.490470, acc.: 75.00%] [G loss: 0.693543]\n",
      "epoch:10 step:10280 [D loss: 0.479735, acc.: 80.47%] [G loss: 0.629049]\n",
      "epoch:10 step:10281 [D loss: 0.491159, acc.: 77.34%] [G loss: 0.715656]\n",
      "epoch:10 step:10282 [D loss: 0.465558, acc.: 75.78%] [G loss: 0.841975]\n",
      "epoch:10 step:10283 [D loss: 0.607866, acc.: 71.88%] [G loss: 0.874861]\n",
      "epoch:10 step:10284 [D loss: 0.489192, acc.: 75.78%] [G loss: 0.667367]\n",
      "epoch:10 step:10285 [D loss: 0.595411, acc.: 65.62%] [G loss: 0.604720]\n",
      "epoch:10 step:10286 [D loss: 0.490586, acc.: 74.22%] [G loss: 0.756641]\n",
      "epoch:10 step:10287 [D loss: 0.655940, acc.: 57.81%] [G loss: 0.532913]\n",
      "epoch:10 step:10288 [D loss: 0.515586, acc.: 72.66%] [G loss: 0.627949]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:10 step:10289 [D loss: 0.494847, acc.: 78.12%] [G loss: 0.659055]\n",
      "epoch:10 step:10290 [D loss: 0.673896, acc.: 60.94%] [G loss: 0.665701]\n",
      "epoch:10 step:10291 [D loss: 0.501438, acc.: 75.78%] [G loss: 0.618541]\n",
      "epoch:10 step:10292 [D loss: 0.526859, acc.: 71.88%] [G loss: 0.638345]\n",
      "epoch:10 step:10293 [D loss: 0.498336, acc.: 74.22%] [G loss: 0.590852]\n",
      "epoch:10 step:10294 [D loss: 0.477334, acc.: 75.00%] [G loss: 0.713823]\n",
      "epoch:10 step:10295 [D loss: 0.409785, acc.: 78.91%] [G loss: 0.821405]\n",
      "epoch:10 step:10296 [D loss: 0.468126, acc.: 74.22%] [G loss: 0.782598]\n",
      "epoch:10 step:10297 [D loss: 0.530007, acc.: 71.88%] [G loss: 0.936024]\n",
      "epoch:10 step:10298 [D loss: 0.662755, acc.: 64.84%] [G loss: 0.703690]\n",
      "epoch:10 step:10299 [D loss: 0.488375, acc.: 79.69%] [G loss: 0.898430]\n",
      "epoch:10 step:10300 [D loss: 0.471022, acc.: 76.56%] [G loss: 0.993794]\n",
      "epoch:10 step:10301 [D loss: 0.546558, acc.: 70.31%] [G loss: 0.812679]\n",
      "epoch:10 step:10302 [D loss: 0.559756, acc.: 69.53%] [G loss: 0.812189]\n",
      "epoch:10 step:10303 [D loss: 0.519092, acc.: 72.66%] [G loss: 0.722040]\n",
      "epoch:10 step:10304 [D loss: 0.642194, acc.: 62.50%] [G loss: 0.894366]\n",
      "epoch:10 step:10305 [D loss: 0.491361, acc.: 72.66%] [G loss: 0.866036]\n",
      "epoch:10 step:10306 [D loss: 0.452437, acc.: 78.12%] [G loss: 0.838503]\n",
      "epoch:10 step:10307 [D loss: 0.539108, acc.: 72.66%] [G loss: 1.179079]\n",
      "epoch:11 step:10308 [D loss: 0.616146, acc.: 66.41%] [G loss: 1.152677]\n",
      "epoch:11 step:10309 [D loss: 0.477972, acc.: 79.69%] [G loss: 0.887879]\n",
      "epoch:11 step:10310 [D loss: 0.623891, acc.: 66.41%] [G loss: 0.621722]\n",
      "epoch:11 step:10311 [D loss: 0.500506, acc.: 75.78%] [G loss: 0.674486]\n",
      "epoch:11 step:10312 [D loss: 0.592740, acc.: 62.50%] [G loss: 0.642081]\n",
      "epoch:11 step:10313 [D loss: 0.565018, acc.: 65.62%] [G loss: 0.683330]\n",
      "epoch:11 step:10314 [D loss: 0.486047, acc.: 76.56%] [G loss: 0.794693]\n",
      "epoch:11 step:10315 [D loss: 0.500260, acc.: 78.12%] [G loss: 0.774142]\n",
      "epoch:11 step:10316 [D loss: 0.479352, acc.: 71.88%] [G loss: 0.684038]\n",
      "epoch:11 step:10317 [D loss: 0.529144, acc.: 74.22%] [G loss: 0.680178]\n",
      "epoch:11 step:10318 [D loss: 0.453121, acc.: 79.69%] [G loss: 0.700624]\n",
      "epoch:11 step:10319 [D loss: 0.539880, acc.: 71.88%] [G loss: 0.531638]\n",
      "epoch:11 step:10320 [D loss: 0.483997, acc.: 75.78%] [G loss: 0.593984]\n",
      "epoch:11 step:10321 [D loss: 0.499234, acc.: 75.00%] [G loss: 0.581289]\n",
      "epoch:11 step:10322 [D loss: 0.465770, acc.: 78.91%] [G loss: 0.724663]\n",
      "epoch:11 step:10323 [D loss: 0.491185, acc.: 78.91%] [G loss: 0.645359]\n",
      "epoch:11 step:10324 [D loss: 0.566990, acc.: 71.88%] [G loss: 0.734418]\n",
      "epoch:11 step:10325 [D loss: 0.523906, acc.: 74.22%] [G loss: 0.578030]\n",
      "epoch:11 step:10326 [D loss: 0.566818, acc.: 69.53%] [G loss: 0.591960]\n",
      "epoch:11 step:10327 [D loss: 0.641483, acc.: 60.94%] [G loss: 0.549840]\n",
      "epoch:11 step:10328 [D loss: 0.578301, acc.: 65.62%] [G loss: 0.674430]\n",
      "epoch:11 step:10329 [D loss: 0.478440, acc.: 76.56%] [G loss: 0.616149]\n",
      "epoch:11 step:10330 [D loss: 0.541344, acc.: 68.75%] [G loss: 0.721038]\n",
      "epoch:11 step:10331 [D loss: 0.494686, acc.: 77.34%] [G loss: 0.687620]\n",
      "epoch:11 step:10332 [D loss: 0.545441, acc.: 71.09%] [G loss: 0.592922]\n",
      "epoch:11 step:10333 [D loss: 0.559655, acc.: 69.53%] [G loss: 0.542567]\n",
      "epoch:11 step:10334 [D loss: 0.485611, acc.: 73.44%] [G loss: 0.696273]\n",
      "epoch:11 step:10335 [D loss: 0.591159, acc.: 67.19%] [G loss: 0.491190]\n",
      "epoch:11 step:10336 [D loss: 0.515130, acc.: 74.22%] [G loss: 0.596727]\n",
      "epoch:11 step:10337 [D loss: 0.583443, acc.: 63.28%] [G loss: 0.586644]\n",
      "epoch:11 step:10338 [D loss: 0.598746, acc.: 64.06%] [G loss: 0.545060]\n",
      "epoch:11 step:10339 [D loss: 0.539888, acc.: 68.75%] [G loss: 0.572548]\n",
      "epoch:11 step:10340 [D loss: 0.520306, acc.: 71.88%] [G loss: 0.575542]\n",
      "epoch:11 step:10341 [D loss: 0.514319, acc.: 74.22%] [G loss: 0.536160]\n",
      "epoch:11 step:10342 [D loss: 0.561379, acc.: 70.31%] [G loss: 0.516875]\n",
      "epoch:11 step:10343 [D loss: 0.534509, acc.: 71.88%] [G loss: 0.687334]\n",
      "epoch:11 step:10344 [D loss: 0.447224, acc.: 82.03%] [G loss: 0.721759]\n",
      "epoch:11 step:10345 [D loss: 0.585151, acc.: 63.28%] [G loss: 0.593205]\n",
      "epoch:11 step:10346 [D loss: 0.525967, acc.: 73.44%] [G loss: 0.592841]\n",
      "epoch:11 step:10347 [D loss: 0.442400, acc.: 78.12%] [G loss: 0.625304]\n",
      "epoch:11 step:10348 [D loss: 0.490183, acc.: 75.00%] [G loss: 0.598975]\n",
      "epoch:11 step:10349 [D loss: 0.535287, acc.: 69.53%] [G loss: 0.598795]\n",
      "epoch:11 step:10350 [D loss: 0.539465, acc.: 67.97%] [G loss: 0.641120]\n",
      "epoch:11 step:10351 [D loss: 0.560851, acc.: 67.97%] [G loss: 0.729531]\n",
      "epoch:11 step:10352 [D loss: 0.480149, acc.: 74.22%] [G loss: 0.615823]\n",
      "epoch:11 step:10353 [D loss: 0.474517, acc.: 81.25%] [G loss: 0.784454]\n",
      "epoch:11 step:10354 [D loss: 0.533167, acc.: 68.75%] [G loss: 0.660181]\n",
      "epoch:11 step:10355 [D loss: 0.562055, acc.: 64.84%] [G loss: 0.571007]\n",
      "epoch:11 step:10356 [D loss: 0.490173, acc.: 74.22%] [G loss: 0.753220]\n",
      "epoch:11 step:10357 [D loss: 0.505709, acc.: 77.34%] [G loss: 0.741519]\n",
      "epoch:11 step:10358 [D loss: 0.659797, acc.: 63.28%] [G loss: 0.476856]\n",
      "epoch:11 step:10359 [D loss: 0.528923, acc.: 70.31%] [G loss: 0.527970]\n",
      "epoch:11 step:10360 [D loss: 0.501938, acc.: 79.69%] [G loss: 0.712236]\n",
      "epoch:11 step:10361 [D loss: 0.457004, acc.: 81.25%] [G loss: 0.636599]\n",
      "epoch:11 step:10362 [D loss: 0.554461, acc.: 67.97%] [G loss: 0.688760]\n",
      "epoch:11 step:10363 [D loss: 0.545084, acc.: 68.75%] [G loss: 0.538540]\n",
      "epoch:11 step:10364 [D loss: 0.532276, acc.: 69.53%] [G loss: 0.657585]\n",
      "epoch:11 step:10365 [D loss: 0.529470, acc.: 73.44%] [G loss: 0.569959]\n",
      "epoch:11 step:10366 [D loss: 0.479182, acc.: 78.91%] [G loss: 0.683178]\n",
      "epoch:11 step:10367 [D loss: 0.569920, acc.: 67.97%] [G loss: 0.564467]\n",
      "epoch:11 step:10368 [D loss: 0.558735, acc.: 71.09%] [G loss: 0.564848]\n",
      "epoch:11 step:10369 [D loss: 0.560836, acc.: 72.66%] [G loss: 0.582702]\n",
      "epoch:11 step:10370 [D loss: 0.525524, acc.: 75.00%] [G loss: 0.585000]\n",
      "epoch:11 step:10371 [D loss: 0.512470, acc.: 71.88%] [G loss: 0.684316]\n",
      "epoch:11 step:10372 [D loss: 0.585808, acc.: 67.19%] [G loss: 0.568176]\n",
      "epoch:11 step:10373 [D loss: 0.499296, acc.: 74.22%] [G loss: 0.620530]\n",
      "epoch:11 step:10374 [D loss: 0.553766, acc.: 70.31%] [G loss: 0.517100]\n",
      "epoch:11 step:10375 [D loss: 0.499544, acc.: 77.34%] [G loss: 0.649689]\n",
      "epoch:11 step:10376 [D loss: 0.493174, acc.: 74.22%] [G loss: 0.631140]\n",
      "epoch:11 step:10377 [D loss: 0.539553, acc.: 73.44%] [G loss: 0.612959]\n",
      "epoch:11 step:10378 [D loss: 0.544542, acc.: 70.31%] [G loss: 0.538801]\n",
      "epoch:11 step:10379 [D loss: 0.490911, acc.: 75.78%] [G loss: 0.636785]\n",
      "epoch:11 step:10380 [D loss: 0.559065, acc.: 71.09%] [G loss: 0.552614]\n",
      "epoch:11 step:10381 [D loss: 0.440944, acc.: 81.25%] [G loss: 0.523584]\n",
      "epoch:11 step:10382 [D loss: 0.513866, acc.: 73.44%] [G loss: 0.693999]\n",
      "epoch:11 step:10383 [D loss: 0.540570, acc.: 69.53%] [G loss: 0.623581]\n",
      "epoch:11 step:10384 [D loss: 0.445819, acc.: 78.91%] [G loss: 0.827728]\n",
      "epoch:11 step:10385 [D loss: 0.594837, acc.: 70.31%] [G loss: 0.624635]\n",
      "epoch:11 step:10386 [D loss: 0.530005, acc.: 73.44%] [G loss: 0.545541]\n",
      "epoch:11 step:10387 [D loss: 0.509880, acc.: 73.44%] [G loss: 0.696395]\n",
      "epoch:11 step:10388 [D loss: 0.538618, acc.: 69.53%] [G loss: 0.648668]\n",
      "epoch:11 step:10389 [D loss: 0.505302, acc.: 72.66%] [G loss: 0.717689]\n",
      "epoch:11 step:10390 [D loss: 0.505538, acc.: 75.78%] [G loss: 0.841913]\n",
      "epoch:11 step:10391 [D loss: 0.521456, acc.: 75.78%] [G loss: 0.662037]\n",
      "epoch:11 step:10392 [D loss: 0.564825, acc.: 66.41%] [G loss: 0.600792]\n",
      "epoch:11 step:10393 [D loss: 0.560588, acc.: 70.31%] [G loss: 0.579877]\n",
      "epoch:11 step:10394 [D loss: 0.539596, acc.: 69.53%] [G loss: 0.520113]\n",
      "epoch:11 step:10395 [D loss: 0.495590, acc.: 72.66%] [G loss: 0.741871]\n",
      "epoch:11 step:10396 [D loss: 0.498561, acc.: 76.56%] [G loss: 0.641898]\n",
      "epoch:11 step:10397 [D loss: 0.510172, acc.: 75.00%] [G loss: 0.638860]\n",
      "epoch:11 step:10398 [D loss: 0.603645, acc.: 60.94%] [G loss: 0.498007]\n",
      "epoch:11 step:10399 [D loss: 0.481362, acc.: 74.22%] [G loss: 0.736122]\n",
      "epoch:11 step:10400 [D loss: 0.496781, acc.: 75.00%] [G loss: 0.668348]\n",
      "epoch:11 step:10401 [D loss: 0.519092, acc.: 75.78%] [G loss: 0.685886]\n",
      "epoch:11 step:10402 [D loss: 0.541905, acc.: 67.19%] [G loss: 0.673199]\n",
      "epoch:11 step:10403 [D loss: 0.567892, acc.: 67.19%] [G loss: 0.525653]\n",
      "epoch:11 step:10404 [D loss: 0.509943, acc.: 74.22%] [G loss: 0.698044]\n",
      "epoch:11 step:10405 [D loss: 0.566303, acc.: 67.19%] [G loss: 0.543556]\n",
      "epoch:11 step:10406 [D loss: 0.526633, acc.: 75.00%] [G loss: 0.740328]\n",
      "epoch:11 step:10407 [D loss: 0.437510, acc.: 81.25%] [G loss: 0.734500]\n",
      "epoch:11 step:10408 [D loss: 0.457383, acc.: 76.56%] [G loss: 0.864230]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:11 step:10409 [D loss: 0.648481, acc.: 64.06%] [G loss: 0.521247]\n",
      "epoch:11 step:10410 [D loss: 0.513016, acc.: 70.31%] [G loss: 0.619109]\n",
      "epoch:11 step:10411 [D loss: 0.504671, acc.: 72.66%] [G loss: 0.803100]\n",
      "epoch:11 step:10412 [D loss: 0.574924, acc.: 68.75%] [G loss: 0.491244]\n",
      "epoch:11 step:10413 [D loss: 0.555866, acc.: 67.19%] [G loss: 0.597192]\n",
      "epoch:11 step:10414 [D loss: 0.570576, acc.: 68.75%] [G loss: 0.567602]\n",
      "epoch:11 step:10415 [D loss: 0.618526, acc.: 60.94%] [G loss: 0.630821]\n",
      "epoch:11 step:10416 [D loss: 0.593719, acc.: 60.94%] [G loss: 0.432642]\n",
      "epoch:11 step:10417 [D loss: 0.561280, acc.: 70.31%] [G loss: 0.551696]\n",
      "epoch:11 step:10418 [D loss: 0.484055, acc.: 72.66%] [G loss: 0.583468]\n",
      "epoch:11 step:10419 [D loss: 0.545903, acc.: 72.66%] [G loss: 0.636625]\n",
      "epoch:11 step:10420 [D loss: 0.545058, acc.: 70.31%] [G loss: 0.637415]\n",
      "epoch:11 step:10421 [D loss: 0.604243, acc.: 64.06%] [G loss: 0.597108]\n",
      "epoch:11 step:10422 [D loss: 0.569707, acc.: 72.66%] [G loss: 0.619783]\n",
      "epoch:11 step:10423 [D loss: 0.500060, acc.: 73.44%] [G loss: 0.722943]\n",
      "epoch:11 step:10424 [D loss: 0.558800, acc.: 75.00%] [G loss: 0.655379]\n",
      "epoch:11 step:10425 [D loss: 0.550378, acc.: 65.62%] [G loss: 0.702240]\n",
      "epoch:11 step:10426 [D loss: 0.458036, acc.: 76.56%] [G loss: 0.911191]\n",
      "epoch:11 step:10427 [D loss: 0.570248, acc.: 74.22%] [G loss: 0.722800]\n",
      "epoch:11 step:10428 [D loss: 0.524129, acc.: 72.66%] [G loss: 0.623248]\n",
      "epoch:11 step:10429 [D loss: 0.525147, acc.: 75.78%] [G loss: 0.523414]\n",
      "epoch:11 step:10430 [D loss: 0.506138, acc.: 75.00%] [G loss: 0.539120]\n",
      "epoch:11 step:10431 [D loss: 0.576877, acc.: 67.97%] [G loss: 0.596483]\n",
      "epoch:11 step:10432 [D loss: 0.625150, acc.: 64.84%] [G loss: 0.600171]\n",
      "epoch:11 step:10433 [D loss: 0.516484, acc.: 71.88%] [G loss: 0.771945]\n",
      "epoch:11 step:10434 [D loss: 0.489976, acc.: 75.00%] [G loss: 0.641463]\n",
      "epoch:11 step:10435 [D loss: 0.484355, acc.: 70.31%] [G loss: 0.654450]\n",
      "epoch:11 step:10436 [D loss: 0.572280, acc.: 65.62%] [G loss: 0.595752]\n",
      "epoch:11 step:10437 [D loss: 0.529126, acc.: 71.88%] [G loss: 0.466433]\n",
      "epoch:11 step:10438 [D loss: 0.513383, acc.: 73.44%] [G loss: 0.496509]\n",
      "epoch:11 step:10439 [D loss: 0.544149, acc.: 74.22%] [G loss: 0.466167]\n",
      "epoch:11 step:10440 [D loss: 0.574504, acc.: 70.31%] [G loss: 0.613614]\n",
      "epoch:11 step:10441 [D loss: 0.546966, acc.: 71.88%] [G loss: 0.499218]\n",
      "epoch:11 step:10442 [D loss: 0.529215, acc.: 76.56%] [G loss: 0.716730]\n",
      "epoch:11 step:10443 [D loss: 0.530850, acc.: 71.09%] [G loss: 0.689566]\n",
      "epoch:11 step:10444 [D loss: 0.634549, acc.: 68.75%] [G loss: 0.658537]\n",
      "epoch:11 step:10445 [D loss: 0.549279, acc.: 71.09%] [G loss: 0.580458]\n",
      "epoch:11 step:10446 [D loss: 0.569354, acc.: 67.19%] [G loss: 0.564348]\n",
      "epoch:11 step:10447 [D loss: 0.633328, acc.: 66.41%] [G loss: 0.432143]\n",
      "epoch:11 step:10448 [D loss: 0.523704, acc.: 67.97%] [G loss: 0.537654]\n",
      "epoch:11 step:10449 [D loss: 0.563566, acc.: 67.97%] [G loss: 0.535362]\n",
      "epoch:11 step:10450 [D loss: 0.592582, acc.: 64.06%] [G loss: 0.484677]\n",
      "epoch:11 step:10451 [D loss: 0.523980, acc.: 69.53%] [G loss: 0.544431]\n",
      "epoch:11 step:10452 [D loss: 0.563151, acc.: 64.06%] [G loss: 0.678003]\n",
      "epoch:11 step:10453 [D loss: 0.487255, acc.: 78.91%] [G loss: 0.527353]\n",
      "epoch:11 step:10454 [D loss: 0.591707, acc.: 68.75%] [G loss: 0.509895]\n",
      "epoch:11 step:10455 [D loss: 0.541023, acc.: 73.44%] [G loss: 0.452322]\n",
      "epoch:11 step:10456 [D loss: 0.478992, acc.: 80.47%] [G loss: 0.586213]\n",
      "epoch:11 step:10457 [D loss: 0.595007, acc.: 67.19%] [G loss: 0.542367]\n",
      "epoch:11 step:10458 [D loss: 0.582166, acc.: 70.31%] [G loss: 0.563673]\n",
      "epoch:11 step:10459 [D loss: 0.528223, acc.: 71.09%] [G loss: 0.735928]\n",
      "epoch:11 step:10460 [D loss: 0.571067, acc.: 71.09%] [G loss: 0.636046]\n",
      "epoch:11 step:10461 [D loss: 0.505810, acc.: 72.66%] [G loss: 0.569523]\n",
      "epoch:11 step:10462 [D loss: 0.461045, acc.: 82.81%] [G loss: 0.654474]\n",
      "epoch:11 step:10463 [D loss: 0.500965, acc.: 73.44%] [G loss: 0.687654]\n",
      "epoch:11 step:10464 [D loss: 0.600011, acc.: 65.62%] [G loss: 0.527142]\n",
      "epoch:11 step:10465 [D loss: 0.576611, acc.: 69.53%] [G loss: 0.502005]\n",
      "epoch:11 step:10466 [D loss: 0.521454, acc.: 69.53%] [G loss: 0.668649]\n",
      "epoch:11 step:10467 [D loss: 0.675331, acc.: 65.62%] [G loss: 0.541250]\n",
      "epoch:11 step:10468 [D loss: 0.509610, acc.: 75.00%] [G loss: 0.706477]\n",
      "epoch:11 step:10469 [D loss: 0.480611, acc.: 74.22%] [G loss: 0.670815]\n",
      "epoch:11 step:10470 [D loss: 0.600947, acc.: 60.94%] [G loss: 0.844789]\n",
      "epoch:11 step:10471 [D loss: 0.554070, acc.: 65.62%] [G loss: 0.662085]\n",
      "epoch:11 step:10472 [D loss: 0.490986, acc.: 74.22%] [G loss: 0.588611]\n",
      "epoch:11 step:10473 [D loss: 0.592187, acc.: 64.06%] [G loss: 0.682723]\n",
      "epoch:11 step:10474 [D loss: 0.546161, acc.: 68.75%] [G loss: 0.492614]\n",
      "epoch:11 step:10475 [D loss: 0.536987, acc.: 72.66%] [G loss: 0.540419]\n",
      "epoch:11 step:10476 [D loss: 0.577102, acc.: 68.75%] [G loss: 0.610365]\n",
      "epoch:11 step:10477 [D loss: 0.538804, acc.: 69.53%] [G loss: 0.479207]\n",
      "epoch:11 step:10478 [D loss: 0.530491, acc.: 71.88%] [G loss: 0.459567]\n",
      "epoch:11 step:10479 [D loss: 0.572207, acc.: 69.53%] [G loss: 0.554228]\n",
      "epoch:11 step:10480 [D loss: 0.450177, acc.: 78.12%] [G loss: 0.653719]\n",
      "epoch:11 step:10481 [D loss: 0.570913, acc.: 65.62%] [G loss: 0.642220]\n",
      "epoch:11 step:10482 [D loss: 0.571311, acc.: 67.19%] [G loss: 0.499518]\n",
      "epoch:11 step:10483 [D loss: 0.520340, acc.: 71.09%] [G loss: 0.603611]\n",
      "epoch:11 step:10484 [D loss: 0.469236, acc.: 77.34%] [G loss: 0.680966]\n",
      "epoch:11 step:10485 [D loss: 0.617948, acc.: 67.19%] [G loss: 0.614750]\n",
      "epoch:11 step:10486 [D loss: 0.581102, acc.: 69.53%] [G loss: 0.691679]\n",
      "epoch:11 step:10487 [D loss: 0.622029, acc.: 59.38%] [G loss: 0.521948]\n",
      "epoch:11 step:10488 [D loss: 0.554839, acc.: 69.53%] [G loss: 0.534784]\n",
      "epoch:11 step:10489 [D loss: 0.533345, acc.: 71.09%] [G loss: 0.503151]\n",
      "epoch:11 step:10490 [D loss: 0.569567, acc.: 69.53%] [G loss: 0.668777]\n",
      "epoch:11 step:10491 [D loss: 0.507137, acc.: 74.22%] [G loss: 0.537243]\n",
      "epoch:11 step:10492 [D loss: 0.580486, acc.: 67.19%] [G loss: 0.563687]\n",
      "epoch:11 step:10493 [D loss: 0.558766, acc.: 70.31%] [G loss: 0.636462]\n",
      "epoch:11 step:10494 [D loss: 0.585922, acc.: 68.75%] [G loss: 0.416795]\n",
      "epoch:11 step:10495 [D loss: 0.562481, acc.: 67.19%] [G loss: 0.510119]\n",
      "epoch:11 step:10496 [D loss: 0.619287, acc.: 58.59%] [G loss: 0.560032]\n",
      "epoch:11 step:10497 [D loss: 0.496513, acc.: 74.22%] [G loss: 0.631760]\n",
      "epoch:11 step:10498 [D loss: 0.478476, acc.: 77.34%] [G loss: 0.652077]\n",
      "epoch:11 step:10499 [D loss: 0.530934, acc.: 74.22%] [G loss: 0.673981]\n",
      "epoch:11 step:10500 [D loss: 0.513046, acc.: 76.56%] [G loss: 0.780982]\n",
      "epoch:11 step:10501 [D loss: 0.422148, acc.: 82.03%] [G loss: 0.773708]\n",
      "epoch:11 step:10502 [D loss: 0.539691, acc.: 70.31%] [G loss: 0.690543]\n",
      "epoch:11 step:10503 [D loss: 0.589534, acc.: 64.84%] [G loss: 0.600835]\n",
      "epoch:11 step:10504 [D loss: 0.528129, acc.: 71.09%] [G loss: 0.687318]\n",
      "epoch:11 step:10505 [D loss: 0.501560, acc.: 74.22%] [G loss: 0.576046]\n",
      "epoch:11 step:10506 [D loss: 0.526790, acc.: 71.09%] [G loss: 0.674756]\n",
      "epoch:11 step:10507 [D loss: 0.630696, acc.: 63.28%] [G loss: 0.596895]\n",
      "epoch:11 step:10508 [D loss: 0.545089, acc.: 72.66%] [G loss: 0.552456]\n",
      "epoch:11 step:10509 [D loss: 0.557883, acc.: 69.53%] [G loss: 0.781489]\n",
      "epoch:11 step:10510 [D loss: 0.626024, acc.: 67.97%] [G loss: 0.564639]\n",
      "epoch:11 step:10511 [D loss: 0.557563, acc.: 71.09%] [G loss: 0.498006]\n",
      "epoch:11 step:10512 [D loss: 0.468487, acc.: 75.78%] [G loss: 0.629845]\n",
      "epoch:11 step:10513 [D loss: 0.440747, acc.: 78.12%] [G loss: 0.709388]\n",
      "epoch:11 step:10514 [D loss: 0.474769, acc.: 79.69%] [G loss: 0.812325]\n",
      "epoch:11 step:10515 [D loss: 0.479043, acc.: 78.12%] [G loss: 0.949719]\n",
      "epoch:11 step:10516 [D loss: 0.563987, acc.: 71.88%] [G loss: 0.771451]\n",
      "epoch:11 step:10517 [D loss: 0.642388, acc.: 60.16%] [G loss: 0.527579]\n",
      "epoch:11 step:10518 [D loss: 0.625409, acc.: 63.28%] [G loss: 0.409782]\n",
      "epoch:11 step:10519 [D loss: 0.568167, acc.: 71.09%] [G loss: 0.483456]\n",
      "epoch:11 step:10520 [D loss: 0.463130, acc.: 78.12%] [G loss: 0.543672]\n",
      "epoch:11 step:10521 [D loss: 0.626435, acc.: 60.94%] [G loss: 0.513843]\n",
      "epoch:11 step:10522 [D loss: 0.566969, acc.: 66.41%] [G loss: 0.468879]\n",
      "epoch:11 step:10523 [D loss: 0.514314, acc.: 74.22%] [G loss: 0.625712]\n",
      "epoch:11 step:10524 [D loss: 0.518845, acc.: 71.09%] [G loss: 0.489162]\n",
      "epoch:11 step:10525 [D loss: 0.508217, acc.: 76.56%] [G loss: 0.666540]\n",
      "epoch:11 step:10526 [D loss: 0.500614, acc.: 79.69%] [G loss: 0.673680]\n",
      "epoch:11 step:10527 [D loss: 0.729569, acc.: 60.16%] [G loss: 0.645915]\n",
      "epoch:11 step:10528 [D loss: 0.515986, acc.: 76.56%] [G loss: 0.708042]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:11 step:10529 [D loss: 0.528694, acc.: 75.00%] [G loss: 0.718521]\n",
      "epoch:11 step:10530 [D loss: 0.468936, acc.: 78.12%] [G loss: 0.817810]\n",
      "epoch:11 step:10531 [D loss: 0.568329, acc.: 69.53%] [G loss: 0.545470]\n",
      "epoch:11 step:10532 [D loss: 0.561073, acc.: 72.66%] [G loss: 0.583576]\n",
      "epoch:11 step:10533 [D loss: 0.587364, acc.: 63.28%] [G loss: 0.564913]\n",
      "epoch:11 step:10534 [D loss: 0.522230, acc.: 76.56%] [G loss: 0.555825]\n",
      "epoch:11 step:10535 [D loss: 0.562101, acc.: 70.31%] [G loss: 0.548295]\n",
      "epoch:11 step:10536 [D loss: 0.487401, acc.: 75.78%] [G loss: 0.676006]\n",
      "epoch:11 step:10537 [D loss: 0.512162, acc.: 72.66%] [G loss: 0.613609]\n",
      "epoch:11 step:10538 [D loss: 0.441072, acc.: 80.47%] [G loss: 0.810551]\n",
      "epoch:11 step:10539 [D loss: 0.436823, acc.: 84.38%] [G loss: 0.887650]\n",
      "epoch:11 step:10540 [D loss: 0.517313, acc.: 72.66%] [G loss: 0.688985]\n",
      "epoch:11 step:10541 [D loss: 0.572621, acc.: 72.66%] [G loss: 0.617157]\n",
      "epoch:11 step:10542 [D loss: 0.576344, acc.: 64.84%] [G loss: 0.580783]\n",
      "epoch:11 step:10543 [D loss: 0.519845, acc.: 73.44%] [G loss: 0.686701]\n",
      "epoch:11 step:10544 [D loss: 0.554997, acc.: 66.41%] [G loss: 0.623967]\n",
      "epoch:11 step:10545 [D loss: 0.589354, acc.: 68.75%] [G loss: 0.705084]\n",
      "epoch:11 step:10546 [D loss: 0.499213, acc.: 72.66%] [G loss: 0.623442]\n",
      "epoch:11 step:10547 [D loss: 0.529513, acc.: 70.31%] [G loss: 0.595353]\n",
      "epoch:11 step:10548 [D loss: 0.532830, acc.: 71.88%] [G loss: 0.572874]\n",
      "epoch:11 step:10549 [D loss: 0.507924, acc.: 74.22%] [G loss: 0.552028]\n",
      "epoch:11 step:10550 [D loss: 0.526164, acc.: 71.88%] [G loss: 0.555313]\n",
      "epoch:11 step:10551 [D loss: 0.482541, acc.: 78.12%] [G loss: 0.654396]\n",
      "epoch:11 step:10552 [D loss: 0.530296, acc.: 75.78%] [G loss: 0.724212]\n",
      "epoch:11 step:10553 [D loss: 0.529633, acc.: 73.44%] [G loss: 0.714760]\n",
      "epoch:11 step:10554 [D loss: 0.546005, acc.: 73.44%] [G loss: 0.731577]\n",
      "epoch:11 step:10555 [D loss: 0.486082, acc.: 75.00%] [G loss: 0.616486]\n",
      "epoch:11 step:10556 [D loss: 0.544083, acc.: 70.31%] [G loss: 0.725870]\n",
      "epoch:11 step:10557 [D loss: 0.628602, acc.: 64.06%] [G loss: 0.597581]\n",
      "epoch:11 step:10558 [D loss: 0.590225, acc.: 65.62%] [G loss: 0.568322]\n",
      "epoch:11 step:10559 [D loss: 0.543164, acc.: 74.22%] [G loss: 0.655588]\n",
      "epoch:11 step:10560 [D loss: 0.547357, acc.: 74.22%] [G loss: 0.624920]\n",
      "epoch:11 step:10561 [D loss: 0.507984, acc.: 74.22%] [G loss: 0.539518]\n",
      "epoch:11 step:10562 [D loss: 0.522939, acc.: 79.69%] [G loss: 0.490330]\n",
      "epoch:11 step:10563 [D loss: 0.560578, acc.: 69.53%] [G loss: 0.521734]\n",
      "epoch:11 step:10564 [D loss: 0.548408, acc.: 70.31%] [G loss: 0.583905]\n",
      "epoch:11 step:10565 [D loss: 0.539108, acc.: 73.44%] [G loss: 0.679559]\n",
      "epoch:11 step:10566 [D loss: 0.533402, acc.: 67.97%] [G loss: 0.541956]\n",
      "epoch:11 step:10567 [D loss: 0.565328, acc.: 71.09%] [G loss: 0.607723]\n",
      "epoch:11 step:10568 [D loss: 0.553702, acc.: 71.88%] [G loss: 0.600832]\n",
      "epoch:11 step:10569 [D loss: 0.549520, acc.: 71.09%] [G loss: 0.522719]\n",
      "epoch:11 step:10570 [D loss: 0.611760, acc.: 67.19%] [G loss: 0.539041]\n",
      "epoch:11 step:10571 [D loss: 0.569402, acc.: 67.97%] [G loss: 0.625842]\n",
      "epoch:11 step:10572 [D loss: 0.550822, acc.: 71.88%] [G loss: 0.500162]\n",
      "epoch:11 step:10573 [D loss: 0.532712, acc.: 71.88%] [G loss: 0.533640]\n",
      "epoch:11 step:10574 [D loss: 0.559243, acc.: 68.75%] [G loss: 0.516474]\n",
      "epoch:11 step:10575 [D loss: 0.543690, acc.: 72.66%] [G loss: 0.576268]\n",
      "epoch:11 step:10576 [D loss: 0.512095, acc.: 71.88%] [G loss: 0.718286]\n",
      "epoch:11 step:10577 [D loss: 0.510764, acc.: 74.22%] [G loss: 0.594036]\n",
      "epoch:11 step:10578 [D loss: 0.485291, acc.: 76.56%] [G loss: 0.635389]\n",
      "epoch:11 step:10579 [D loss: 0.538062, acc.: 74.22%] [G loss: 0.717009]\n",
      "epoch:11 step:10580 [D loss: 0.499736, acc.: 73.44%] [G loss: 0.665826]\n",
      "epoch:11 step:10581 [D loss: 0.530551, acc.: 75.00%] [G loss: 0.669096]\n",
      "epoch:11 step:10582 [D loss: 0.592367, acc.: 67.19%] [G loss: 0.607491]\n",
      "epoch:11 step:10583 [D loss: 0.490196, acc.: 76.56%] [G loss: 0.809952]\n",
      "epoch:11 step:10584 [D loss: 0.688417, acc.: 60.94%] [G loss: 0.581831]\n",
      "epoch:11 step:10585 [D loss: 0.632698, acc.: 60.16%] [G loss: 0.413161]\n",
      "epoch:11 step:10586 [D loss: 0.546589, acc.: 67.97%] [G loss: 0.550739]\n",
      "epoch:11 step:10587 [D loss: 0.532438, acc.: 75.00%] [G loss: 0.556792]\n",
      "epoch:11 step:10588 [D loss: 0.572815, acc.: 67.97%] [G loss: 0.537567]\n",
      "epoch:11 step:10589 [D loss: 0.553046, acc.: 71.88%] [G loss: 0.515390]\n",
      "epoch:11 step:10590 [D loss: 0.491736, acc.: 78.91%] [G loss: 0.594697]\n",
      "epoch:11 step:10591 [D loss: 0.551072, acc.: 70.31%] [G loss: 0.509015]\n",
      "epoch:11 step:10592 [D loss: 0.511314, acc.: 77.34%] [G loss: 0.593538]\n",
      "epoch:11 step:10593 [D loss: 0.470757, acc.: 78.91%] [G loss: 0.670537]\n",
      "epoch:11 step:10594 [D loss: 0.577542, acc.: 66.41%] [G loss: 0.549761]\n",
      "epoch:11 step:10595 [D loss: 0.581176, acc.: 64.06%] [G loss: 0.609145]\n",
      "epoch:11 step:10596 [D loss: 0.542618, acc.: 71.09%] [G loss: 0.586785]\n",
      "epoch:11 step:10597 [D loss: 0.521669, acc.: 74.22%] [G loss: 0.540135]\n",
      "epoch:11 step:10598 [D loss: 0.521788, acc.: 71.88%] [G loss: 0.561041]\n",
      "epoch:11 step:10599 [D loss: 0.608816, acc.: 67.19%] [G loss: 0.634510]\n",
      "epoch:11 step:10600 [D loss: 0.555069, acc.: 70.31%] [G loss: 0.690595]\n",
      "epoch:11 step:10601 [D loss: 0.578835, acc.: 68.75%] [G loss: 0.492678]\n",
      "epoch:11 step:10602 [D loss: 0.546703, acc.: 67.97%] [G loss: 0.500572]\n",
      "epoch:11 step:10603 [D loss: 0.452032, acc.: 80.47%] [G loss: 0.643360]\n",
      "epoch:11 step:10604 [D loss: 0.525143, acc.: 71.09%] [G loss: 0.669971]\n",
      "epoch:11 step:10605 [D loss: 0.483154, acc.: 77.34%] [G loss: 0.730082]\n",
      "epoch:11 step:10606 [D loss: 0.485996, acc.: 75.78%] [G loss: 0.640476]\n",
      "epoch:11 step:10607 [D loss: 0.483891, acc.: 75.00%] [G loss: 0.652016]\n",
      "epoch:11 step:10608 [D loss: 0.609321, acc.: 66.41%] [G loss: 0.740349]\n",
      "epoch:11 step:10609 [D loss: 0.507187, acc.: 76.56%] [G loss: 0.643270]\n",
      "epoch:11 step:10610 [D loss: 0.536227, acc.: 75.00%] [G loss: 0.787515]\n",
      "epoch:11 step:10611 [D loss: 0.524400, acc.: 73.44%] [G loss: 0.704066]\n",
      "epoch:11 step:10612 [D loss: 0.510131, acc.: 76.56%] [G loss: 0.538686]\n",
      "epoch:11 step:10613 [D loss: 0.532379, acc.: 69.53%] [G loss: 0.673631]\n",
      "epoch:11 step:10614 [D loss: 0.495269, acc.: 69.53%] [G loss: 0.769549]\n",
      "epoch:11 step:10615 [D loss: 0.550797, acc.: 65.62%] [G loss: 0.621979]\n",
      "epoch:11 step:10616 [D loss: 0.489683, acc.: 78.91%] [G loss: 0.592812]\n",
      "epoch:11 step:10617 [D loss: 0.502390, acc.: 78.12%] [G loss: 0.606934]\n",
      "epoch:11 step:10618 [D loss: 0.496147, acc.: 75.00%] [G loss: 0.668913]\n",
      "epoch:11 step:10619 [D loss: 0.469810, acc.: 77.34%] [G loss: 1.005105]\n",
      "epoch:11 step:10620 [D loss: 0.470300, acc.: 73.44%] [G loss: 0.837870]\n",
      "epoch:11 step:10621 [D loss: 0.475691, acc.: 74.22%] [G loss: 1.000501]\n",
      "epoch:11 step:10622 [D loss: 0.564788, acc.: 71.09%] [G loss: 0.948664]\n",
      "epoch:11 step:10623 [D loss: 0.642613, acc.: 66.41%] [G loss: 0.749889]\n",
      "epoch:11 step:10624 [D loss: 0.641224, acc.: 61.72%] [G loss: 0.668435]\n",
      "epoch:11 step:10625 [D loss: 0.533460, acc.: 69.53%] [G loss: 0.703571]\n",
      "epoch:11 step:10626 [D loss: 0.570044, acc.: 70.31%] [G loss: 0.652564]\n",
      "epoch:11 step:10627 [D loss: 0.541731, acc.: 72.66%] [G loss: 0.556363]\n",
      "epoch:11 step:10628 [D loss: 0.461675, acc.: 80.47%] [G loss: 0.586774]\n",
      "epoch:11 step:10629 [D loss: 0.595508, acc.: 67.97%] [G loss: 0.633436]\n",
      "epoch:11 step:10630 [D loss: 0.646089, acc.: 64.06%] [G loss: 0.529480]\n",
      "epoch:11 step:10631 [D loss: 0.602932, acc.: 67.19%] [G loss: 0.436701]\n",
      "epoch:11 step:10632 [D loss: 0.508103, acc.: 71.09%] [G loss: 0.599278]\n",
      "epoch:11 step:10633 [D loss: 0.506089, acc.: 75.78%] [G loss: 0.637279]\n",
      "epoch:11 step:10634 [D loss: 0.531556, acc.: 75.00%] [G loss: 0.637012]\n",
      "epoch:11 step:10635 [D loss: 0.514764, acc.: 75.00%] [G loss: 0.668707]\n",
      "epoch:11 step:10636 [D loss: 0.493031, acc.: 74.22%] [G loss: 0.686378]\n",
      "epoch:11 step:10637 [D loss: 0.552338, acc.: 67.19%] [G loss: 0.637102]\n",
      "epoch:11 step:10638 [D loss: 0.558869, acc.: 71.88%] [G loss: 0.580985]\n",
      "epoch:11 step:10639 [D loss: 0.481841, acc.: 74.22%] [G loss: 0.585292]\n",
      "epoch:11 step:10640 [D loss: 0.499290, acc.: 72.66%] [G loss: 0.621518]\n",
      "epoch:11 step:10641 [D loss: 0.505006, acc.: 75.78%] [G loss: 0.672669]\n",
      "epoch:11 step:10642 [D loss: 0.470626, acc.: 75.78%] [G loss: 0.626258]\n",
      "epoch:11 step:10643 [D loss: 0.496998, acc.: 74.22%] [G loss: 0.602596]\n",
      "epoch:11 step:10644 [D loss: 0.483009, acc.: 75.78%] [G loss: 0.625191]\n",
      "epoch:11 step:10645 [D loss: 0.509110, acc.: 71.09%] [G loss: 0.644383]\n",
      "epoch:11 step:10646 [D loss: 0.491177, acc.: 75.78%] [G loss: 0.708344]\n",
      "epoch:11 step:10647 [D loss: 0.529700, acc.: 70.31%] [G loss: 0.647580]\n",
      "epoch:11 step:10648 [D loss: 0.565797, acc.: 69.53%] [G loss: 0.736030]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:11 step:10649 [D loss: 0.661622, acc.: 60.94%] [G loss: 0.600346]\n",
      "epoch:11 step:10650 [D loss: 0.529345, acc.: 70.31%] [G loss: 0.465223]\n",
      "epoch:11 step:10651 [D loss: 0.474232, acc.: 79.69%] [G loss: 0.654254]\n",
      "epoch:11 step:10652 [D loss: 0.533662, acc.: 71.88%] [G loss: 0.753459]\n",
      "epoch:11 step:10653 [D loss: 0.579481, acc.: 64.84%] [G loss: 0.668623]\n",
      "epoch:11 step:10654 [D loss: 0.490682, acc.: 75.00%] [G loss: 0.935615]\n",
      "epoch:11 step:10655 [D loss: 0.602707, acc.: 67.97%] [G loss: 0.633438]\n",
      "epoch:11 step:10656 [D loss: 0.668030, acc.: 59.38%] [G loss: 0.474298]\n",
      "epoch:11 step:10657 [D loss: 0.525615, acc.: 73.44%] [G loss: 0.532474]\n",
      "epoch:11 step:10658 [D loss: 0.485289, acc.: 82.81%] [G loss: 0.689706]\n",
      "epoch:11 step:10659 [D loss: 0.522167, acc.: 69.53%] [G loss: 0.720824]\n",
      "epoch:11 step:10660 [D loss: 0.604907, acc.: 69.53%] [G loss: 0.623514]\n",
      "epoch:11 step:10661 [D loss: 0.400711, acc.: 83.59%] [G loss: 0.735853]\n",
      "epoch:11 step:10662 [D loss: 0.550546, acc.: 71.09%] [G loss: 0.716898]\n",
      "epoch:11 step:10663 [D loss: 0.533005, acc.: 71.09%] [G loss: 0.671406]\n",
      "epoch:11 step:10664 [D loss: 0.511006, acc.: 75.78%] [G loss: 0.655770]\n",
      "epoch:11 step:10665 [D loss: 0.430886, acc.: 78.12%] [G loss: 0.713060]\n",
      "epoch:11 step:10666 [D loss: 0.495670, acc.: 75.00%] [G loss: 0.677748]\n",
      "epoch:11 step:10667 [D loss: 0.513955, acc.: 75.78%] [G loss: 0.697834]\n",
      "epoch:11 step:10668 [D loss: 0.526955, acc.: 72.66%] [G loss: 0.683339]\n",
      "epoch:11 step:10669 [D loss: 0.535693, acc.: 69.53%] [G loss: 0.658650]\n",
      "epoch:11 step:10670 [D loss: 0.554837, acc.: 71.09%] [G loss: 0.623355]\n",
      "epoch:11 step:10671 [D loss: 0.483051, acc.: 74.22%] [G loss: 0.654876]\n",
      "epoch:11 step:10672 [D loss: 0.508334, acc.: 75.00%] [G loss: 0.670271]\n",
      "epoch:11 step:10673 [D loss: 0.502451, acc.: 72.66%] [G loss: 0.586603]\n",
      "epoch:11 step:10674 [D loss: 0.531816, acc.: 72.66%] [G loss: 0.585414]\n",
      "epoch:11 step:10675 [D loss: 0.542256, acc.: 69.53%] [G loss: 0.599745]\n",
      "epoch:11 step:10676 [D loss: 0.548774, acc.: 68.75%] [G loss: 0.522753]\n",
      "epoch:11 step:10677 [D loss: 0.548134, acc.: 71.09%] [G loss: 0.699095]\n",
      "epoch:11 step:10678 [D loss: 0.451806, acc.: 80.47%] [G loss: 0.749632]\n",
      "epoch:11 step:10679 [D loss: 0.553492, acc.: 68.75%] [G loss: 0.575341]\n",
      "epoch:11 step:10680 [D loss: 0.506799, acc.: 77.34%] [G loss: 0.601798]\n",
      "epoch:11 step:10681 [D loss: 0.471433, acc.: 73.44%] [G loss: 0.662106]\n",
      "epoch:11 step:10682 [D loss: 0.540909, acc.: 71.09%] [G loss: 0.589481]\n",
      "epoch:11 step:10683 [D loss: 0.691061, acc.: 62.50%] [G loss: 0.533336]\n",
      "epoch:11 step:10684 [D loss: 0.564894, acc.: 67.19%] [G loss: 0.536864]\n",
      "epoch:11 step:10685 [D loss: 0.528834, acc.: 69.53%] [G loss: 0.739319]\n",
      "epoch:11 step:10686 [D loss: 0.601650, acc.: 66.41%] [G loss: 0.599783]\n",
      "epoch:11 step:10687 [D loss: 0.605621, acc.: 69.53%] [G loss: 0.522329]\n",
      "epoch:11 step:10688 [D loss: 0.434109, acc.: 80.47%] [G loss: 0.694189]\n",
      "epoch:11 step:10689 [D loss: 0.525102, acc.: 74.22%] [G loss: 0.615184]\n",
      "epoch:11 step:10690 [D loss: 0.586773, acc.: 70.31%] [G loss: 0.550386]\n",
      "epoch:11 step:10691 [D loss: 0.519008, acc.: 75.78%] [G loss: 0.505519]\n",
      "epoch:11 step:10692 [D loss: 0.509518, acc.: 69.53%] [G loss: 0.594488]\n",
      "epoch:11 step:10693 [D loss: 0.615050, acc.: 59.38%] [G loss: 0.485006]\n",
      "epoch:11 step:10694 [D loss: 0.588244, acc.: 64.06%] [G loss: 0.461160]\n",
      "epoch:11 step:10695 [D loss: 0.561777, acc.: 71.88%] [G loss: 0.664795]\n",
      "epoch:11 step:10696 [D loss: 0.518279, acc.: 78.12%] [G loss: 0.702959]\n",
      "epoch:11 step:10697 [D loss: 0.649218, acc.: 62.50%] [G loss: 0.521998]\n",
      "epoch:11 step:10698 [D loss: 0.536565, acc.: 66.41%] [G loss: 0.560730]\n",
      "epoch:11 step:10699 [D loss: 0.478914, acc.: 75.00%] [G loss: 0.543491]\n",
      "epoch:11 step:10700 [D loss: 0.564261, acc.: 66.41%] [G loss: 0.532082]\n",
      "epoch:11 step:10701 [D loss: 0.575383, acc.: 70.31%] [G loss: 0.558740]\n",
      "epoch:11 step:10702 [D loss: 0.485145, acc.: 80.47%] [G loss: 0.632335]\n",
      "epoch:11 step:10703 [D loss: 0.642504, acc.: 64.84%] [G loss: 0.509155]\n",
      "epoch:11 step:10704 [D loss: 0.575040, acc.: 62.50%] [G loss: 0.531289]\n",
      "epoch:11 step:10705 [D loss: 0.527529, acc.: 68.75%] [G loss: 0.646253]\n",
      "epoch:11 step:10706 [D loss: 0.520205, acc.: 75.78%] [G loss: 0.614369]\n",
      "epoch:11 step:10707 [D loss: 0.642982, acc.: 64.06%] [G loss: 0.719926]\n",
      "epoch:11 step:10708 [D loss: 0.659533, acc.: 54.69%] [G loss: 0.513951]\n",
      "epoch:11 step:10709 [D loss: 0.459617, acc.: 78.12%] [G loss: 0.618484]\n",
      "epoch:11 step:10710 [D loss: 0.465540, acc.: 76.56%] [G loss: 0.705082]\n",
      "epoch:11 step:10711 [D loss: 0.577064, acc.: 67.19%] [G loss: 0.563422]\n",
      "epoch:11 step:10712 [D loss: 0.525307, acc.: 70.31%] [G loss: 0.684287]\n",
      "epoch:11 step:10713 [D loss: 0.526515, acc.: 79.69%] [G loss: 0.688095]\n",
      "epoch:11 step:10714 [D loss: 0.548939, acc.: 70.31%] [G loss: 0.603363]\n",
      "epoch:11 step:10715 [D loss: 0.582985, acc.: 67.19%] [G loss: 0.492314]\n",
      "epoch:11 step:10716 [D loss: 0.571621, acc.: 70.31%] [G loss: 0.497811]\n",
      "epoch:11 step:10717 [D loss: 0.529677, acc.: 73.44%] [G loss: 0.636321]\n",
      "epoch:11 step:10718 [D loss: 0.573796, acc.: 67.97%] [G loss: 0.554081]\n",
      "epoch:11 step:10719 [D loss: 0.606086, acc.: 64.84%] [G loss: 0.425146]\n",
      "epoch:11 step:10720 [D loss: 0.556139, acc.: 71.09%] [G loss: 0.563606]\n",
      "epoch:11 step:10721 [D loss: 0.496405, acc.: 73.44%] [G loss: 0.643916]\n",
      "epoch:11 step:10722 [D loss: 0.554618, acc.: 71.88%] [G loss: 0.702555]\n",
      "epoch:11 step:10723 [D loss: 0.530591, acc.: 74.22%] [G loss: 0.555315]\n",
      "epoch:11 step:10724 [D loss: 0.565161, acc.: 71.88%] [G loss: 0.714059]\n",
      "epoch:11 step:10725 [D loss: 0.646766, acc.: 62.50%] [G loss: 0.578116]\n",
      "epoch:11 step:10726 [D loss: 0.595088, acc.: 67.97%] [G loss: 0.572961]\n",
      "epoch:11 step:10727 [D loss: 0.632430, acc.: 60.94%] [G loss: 0.526029]\n",
      "epoch:11 step:10728 [D loss: 0.591365, acc.: 65.62%] [G loss: 0.580090]\n",
      "epoch:11 step:10729 [D loss: 0.579099, acc.: 64.06%] [G loss: 0.583197]\n",
      "epoch:11 step:10730 [D loss: 0.541440, acc.: 71.09%] [G loss: 0.444559]\n",
      "epoch:11 step:10731 [D loss: 0.627930, acc.: 65.62%] [G loss: 0.539423]\n",
      "epoch:11 step:10732 [D loss: 0.537892, acc.: 74.22%] [G loss: 0.541463]\n",
      "epoch:11 step:10733 [D loss: 0.483853, acc.: 77.34%] [G loss: 0.767571]\n",
      "epoch:11 step:10734 [D loss: 0.475970, acc.: 75.00%] [G loss: 0.649414]\n",
      "epoch:11 step:10735 [D loss: 0.530852, acc.: 69.53%] [G loss: 0.769564]\n",
      "epoch:11 step:10736 [D loss: 0.469756, acc.: 75.00%] [G loss: 0.835911]\n",
      "epoch:11 step:10737 [D loss: 0.445294, acc.: 82.03%] [G loss: 0.783408]\n",
      "epoch:11 step:10738 [D loss: 0.568214, acc.: 68.75%] [G loss: 0.583398]\n",
      "epoch:11 step:10739 [D loss: 0.601350, acc.: 67.97%] [G loss: 0.609548]\n",
      "epoch:11 step:10740 [D loss: 0.547791, acc.: 74.22%] [G loss: 0.556664]\n",
      "epoch:11 step:10741 [D loss: 0.546799, acc.: 71.88%] [G loss: 0.585399]\n",
      "epoch:11 step:10742 [D loss: 0.501943, acc.: 73.44%] [G loss: 0.616765]\n",
      "epoch:11 step:10743 [D loss: 0.503589, acc.: 75.78%] [G loss: 0.663374]\n",
      "epoch:11 step:10744 [D loss: 0.663448, acc.: 65.62%] [G loss: 0.613807]\n",
      "epoch:11 step:10745 [D loss: 0.586569, acc.: 68.75%] [G loss: 0.559060]\n",
      "epoch:11 step:10746 [D loss: 0.502223, acc.: 73.44%] [G loss: 0.688799]\n",
      "epoch:11 step:10747 [D loss: 0.490283, acc.: 72.66%] [G loss: 0.726656]\n",
      "epoch:11 step:10748 [D loss: 0.546498, acc.: 68.75%] [G loss: 0.644801]\n",
      "epoch:11 step:10749 [D loss: 0.556122, acc.: 68.75%] [G loss: 0.576369]\n",
      "epoch:11 step:10750 [D loss: 0.503670, acc.: 75.00%] [G loss: 0.722552]\n",
      "epoch:11 step:10751 [D loss: 0.513405, acc.: 71.88%] [G loss: 0.683859]\n",
      "epoch:11 step:10752 [D loss: 0.635222, acc.: 61.72%] [G loss: 0.660549]\n",
      "epoch:11 step:10753 [D loss: 0.505645, acc.: 76.56%] [G loss: 0.776767]\n",
      "epoch:11 step:10754 [D loss: 0.523362, acc.: 73.44%] [G loss: 0.717236]\n",
      "epoch:11 step:10755 [D loss: 0.548091, acc.: 68.75%] [G loss: 0.626577]\n",
      "epoch:11 step:10756 [D loss: 0.472260, acc.: 74.22%] [G loss: 0.762922]\n",
      "epoch:11 step:10757 [D loss: 0.463594, acc.: 78.91%] [G loss: 0.642810]\n",
      "epoch:11 step:10758 [D loss: 0.407205, acc.: 82.03%] [G loss: 0.793127]\n",
      "epoch:11 step:10759 [D loss: 0.582123, acc.: 74.22%] [G loss: 0.892836]\n",
      "epoch:11 step:10760 [D loss: 0.538793, acc.: 68.75%] [G loss: 0.679027]\n",
      "epoch:11 step:10761 [D loss: 0.520754, acc.: 71.09%] [G loss: 0.624585]\n",
      "epoch:11 step:10762 [D loss: 0.572295, acc.: 66.41%] [G loss: 0.599940]\n",
      "epoch:11 step:10763 [D loss: 0.648803, acc.: 57.81%] [G loss: 0.509818]\n",
      "epoch:11 step:10764 [D loss: 0.526671, acc.: 71.88%] [G loss: 0.517080]\n",
      "epoch:11 step:10765 [D loss: 0.619351, acc.: 62.50%] [G loss: 0.593408]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:11 step:10766 [D loss: 0.577869, acc.: 67.19%] [G loss: 0.589637]\n",
      "epoch:11 step:10767 [D loss: 0.526344, acc.: 71.09%] [G loss: 0.649216]\n",
      "epoch:11 step:10768 [D loss: 0.499726, acc.: 75.78%] [G loss: 0.608280]\n",
      "epoch:11 step:10769 [D loss: 0.533173, acc.: 67.97%] [G loss: 0.482963]\n",
      "epoch:11 step:10770 [D loss: 0.530658, acc.: 67.19%] [G loss: 0.529680]\n",
      "epoch:11 step:10771 [D loss: 0.481566, acc.: 76.56%] [G loss: 0.650317]\n",
      "epoch:11 step:10772 [D loss: 0.614591, acc.: 63.28%] [G loss: 0.459489]\n",
      "epoch:11 step:10773 [D loss: 0.541919, acc.: 70.31%] [G loss: 0.521742]\n",
      "epoch:11 step:10774 [D loss: 0.515500, acc.: 72.66%] [G loss: 0.627277]\n",
      "epoch:11 step:10775 [D loss: 0.515206, acc.: 73.44%] [G loss: 0.610818]\n",
      "epoch:11 step:10776 [D loss: 0.558986, acc.: 67.19%] [G loss: 0.653975]\n",
      "epoch:11 step:10777 [D loss: 0.565467, acc.: 68.75%] [G loss: 0.578764]\n",
      "epoch:11 step:10778 [D loss: 0.451143, acc.: 77.34%] [G loss: 0.636343]\n",
      "epoch:11 step:10779 [D loss: 0.449699, acc.: 78.12%] [G loss: 0.815637]\n",
      "epoch:11 step:10780 [D loss: 0.658252, acc.: 55.47%] [G loss: 0.613281]\n",
      "epoch:11 step:10781 [D loss: 0.523693, acc.: 70.31%] [G loss: 0.529921]\n",
      "epoch:11 step:10782 [D loss: 0.549262, acc.: 71.09%] [G loss: 0.739630]\n",
      "epoch:11 step:10783 [D loss: 0.572455, acc.: 71.09%] [G loss: 0.743212]\n",
      "epoch:11 step:10784 [D loss: 0.626742, acc.: 67.97%] [G loss: 0.536533]\n",
      "epoch:11 step:10785 [D loss: 0.598704, acc.: 68.75%] [G loss: 0.508937]\n",
      "epoch:11 step:10786 [D loss: 0.514609, acc.: 75.78%] [G loss: 0.439144]\n",
      "epoch:11 step:10787 [D loss: 0.608426, acc.: 67.19%] [G loss: 0.557202]\n",
      "epoch:11 step:10788 [D loss: 0.477457, acc.: 78.91%] [G loss: 0.547171]\n",
      "epoch:11 step:10789 [D loss: 0.621254, acc.: 66.41%] [G loss: 0.493955]\n",
      "epoch:11 step:10790 [D loss: 0.559346, acc.: 64.06%] [G loss: 0.647944]\n",
      "epoch:11 step:10791 [D loss: 0.516999, acc.: 74.22%] [G loss: 0.574231]\n",
      "epoch:11 step:10792 [D loss: 0.486953, acc.: 80.47%] [G loss: 0.709780]\n",
      "epoch:11 step:10793 [D loss: 0.570243, acc.: 66.41%] [G loss: 0.580040]\n",
      "epoch:11 step:10794 [D loss: 0.567760, acc.: 65.62%] [G loss: 0.556768]\n",
      "epoch:11 step:10795 [D loss: 0.526710, acc.: 67.97%] [G loss: 0.585187]\n",
      "epoch:11 step:10796 [D loss: 0.527098, acc.: 74.22%] [G loss: 0.571146]\n",
      "epoch:11 step:10797 [D loss: 0.553780, acc.: 66.41%] [G loss: 0.602424]\n",
      "epoch:11 step:10798 [D loss: 0.533920, acc.: 72.66%] [G loss: 0.546787]\n",
      "epoch:11 step:10799 [D loss: 0.506311, acc.: 76.56%] [G loss: 0.632816]\n",
      "epoch:11 step:10800 [D loss: 0.573054, acc.: 69.53%] [G loss: 0.558104]\n",
      "epoch:11 step:10801 [D loss: 0.562303, acc.: 69.53%] [G loss: 0.572573]\n",
      "epoch:11 step:10802 [D loss: 0.535625, acc.: 75.00%] [G loss: 0.520449]\n",
      "epoch:11 step:10803 [D loss: 0.570214, acc.: 73.44%] [G loss: 0.508616]\n",
      "epoch:11 step:10804 [D loss: 0.545591, acc.: 71.09%] [G loss: 0.621096]\n",
      "epoch:11 step:10805 [D loss: 0.476599, acc.: 73.44%] [G loss: 0.778239]\n",
      "epoch:11 step:10806 [D loss: 0.459041, acc.: 80.47%] [G loss: 0.784845]\n",
      "epoch:11 step:10807 [D loss: 0.597223, acc.: 66.41%] [G loss: 0.733466]\n",
      "epoch:11 step:10808 [D loss: 0.668975, acc.: 64.84%] [G loss: 0.538593]\n",
      "epoch:11 step:10809 [D loss: 0.601992, acc.: 63.28%] [G loss: 0.398018]\n",
      "epoch:11 step:10810 [D loss: 0.475623, acc.: 79.69%] [G loss: 0.467408]\n",
      "epoch:11 step:10811 [D loss: 0.505964, acc.: 78.12%] [G loss: 0.611163]\n",
      "epoch:11 step:10812 [D loss: 0.527127, acc.: 70.31%] [G loss: 0.613194]\n",
      "epoch:11 step:10813 [D loss: 0.505620, acc.: 72.66%] [G loss: 0.842630]\n",
      "epoch:11 step:10814 [D loss: 0.593785, acc.: 67.19%] [G loss: 0.832649]\n",
      "epoch:11 step:10815 [D loss: 0.454027, acc.: 79.69%] [G loss: 0.815871]\n",
      "epoch:11 step:10816 [D loss: 0.479933, acc.: 75.00%] [G loss: 0.752246]\n",
      "epoch:11 step:10817 [D loss: 0.640638, acc.: 60.16%] [G loss: 0.587599]\n",
      "epoch:11 step:10818 [D loss: 0.606934, acc.: 64.84%] [G loss: 0.517452]\n",
      "epoch:11 step:10819 [D loss: 0.549520, acc.: 67.97%] [G loss: 0.572247]\n",
      "epoch:11 step:10820 [D loss: 0.546429, acc.: 71.09%] [G loss: 0.484288]\n",
      "epoch:11 step:10821 [D loss: 0.482656, acc.: 77.34%] [G loss: 0.517194]\n",
      "epoch:11 step:10822 [D loss: 0.528605, acc.: 74.22%] [G loss: 0.792983]\n",
      "epoch:11 step:10823 [D loss: 0.481180, acc.: 78.12%] [G loss: 0.610323]\n",
      "epoch:11 step:10824 [D loss: 0.569191, acc.: 70.31%] [G loss: 0.723956]\n",
      "epoch:11 step:10825 [D loss: 0.528077, acc.: 71.09%] [G loss: 0.704683]\n",
      "epoch:11 step:10826 [D loss: 0.461887, acc.: 78.91%] [G loss: 0.774423]\n",
      "epoch:11 step:10827 [D loss: 0.499153, acc.: 75.78%] [G loss: 0.516980]\n",
      "epoch:11 step:10828 [D loss: 0.507269, acc.: 72.66%] [G loss: 0.646136]\n",
      "epoch:11 step:10829 [D loss: 0.525723, acc.: 74.22%] [G loss: 0.675874]\n",
      "epoch:11 step:10830 [D loss: 0.482926, acc.: 75.00%] [G loss: 0.738263]\n",
      "epoch:11 step:10831 [D loss: 0.590443, acc.: 65.62%] [G loss: 0.637433]\n",
      "epoch:11 step:10832 [D loss: 0.585953, acc.: 67.97%] [G loss: 0.679563]\n",
      "epoch:11 step:10833 [D loss: 0.522958, acc.: 71.09%] [G loss: 0.769922]\n",
      "epoch:11 step:10834 [D loss: 0.562306, acc.: 67.97%] [G loss: 0.530059]\n",
      "epoch:11 step:10835 [D loss: 0.645769, acc.: 61.72%] [G loss: 0.582102]\n",
      "epoch:11 step:10836 [D loss: 0.638779, acc.: 64.84%] [G loss: 0.540046]\n",
      "epoch:11 step:10837 [D loss: 0.578412, acc.: 64.06%] [G loss: 0.497876]\n",
      "epoch:11 step:10838 [D loss: 0.567120, acc.: 67.97%] [G loss: 0.626145]\n",
      "epoch:11 step:10839 [D loss: 0.590166, acc.: 67.19%] [G loss: 0.555980]\n",
      "epoch:11 step:10840 [D loss: 0.561364, acc.: 69.53%] [G loss: 0.505330]\n",
      "epoch:11 step:10841 [D loss: 0.505604, acc.: 69.53%] [G loss: 0.747498]\n",
      "epoch:11 step:10842 [D loss: 0.636781, acc.: 66.41%] [G loss: 0.511453]\n",
      "epoch:11 step:10843 [D loss: 0.499611, acc.: 70.31%] [G loss: 0.745962]\n",
      "epoch:11 step:10844 [D loss: 0.556656, acc.: 66.41%] [G loss: 0.527187]\n",
      "epoch:11 step:10845 [D loss: 0.585047, acc.: 67.97%] [G loss: 0.509281]\n",
      "epoch:11 step:10846 [D loss: 0.570844, acc.: 75.00%] [G loss: 0.615334]\n",
      "epoch:11 step:10847 [D loss: 0.554450, acc.: 67.97%] [G loss: 0.530794]\n",
      "epoch:11 step:10848 [D loss: 0.546272, acc.: 73.44%] [G loss: 0.563246]\n",
      "epoch:11 step:10849 [D loss: 0.620433, acc.: 59.38%] [G loss: 0.442980]\n",
      "epoch:11 step:10850 [D loss: 0.531450, acc.: 71.88%] [G loss: 0.531740]\n",
      "epoch:11 step:10851 [D loss: 0.527398, acc.: 70.31%] [G loss: 0.558801]\n",
      "epoch:11 step:10852 [D loss: 0.537212, acc.: 73.44%] [G loss: 0.601757]\n",
      "epoch:11 step:10853 [D loss: 0.460107, acc.: 76.56%] [G loss: 0.663226]\n",
      "epoch:11 step:10854 [D loss: 0.526057, acc.: 71.09%] [G loss: 0.777392]\n",
      "epoch:11 step:10855 [D loss: 0.476246, acc.: 73.44%] [G loss: 0.680030]\n",
      "epoch:11 step:10856 [D loss: 0.512116, acc.: 72.66%] [G loss: 0.586805]\n",
      "epoch:11 step:10857 [D loss: 0.557671, acc.: 71.88%] [G loss: 0.643029]\n",
      "epoch:11 step:10858 [D loss: 0.468306, acc.: 80.47%] [G loss: 0.752467]\n",
      "epoch:11 step:10859 [D loss: 0.464698, acc.: 78.91%] [G loss: 0.608622]\n",
      "epoch:11 step:10860 [D loss: 0.576885, acc.: 69.53%] [G loss: 0.548981]\n",
      "epoch:11 step:10861 [D loss: 0.429953, acc.: 77.34%] [G loss: 0.715653]\n",
      "epoch:11 step:10862 [D loss: 0.480678, acc.: 80.47%] [G loss: 0.583994]\n",
      "epoch:11 step:10863 [D loss: 0.492950, acc.: 72.66%] [G loss: 0.661862]\n",
      "epoch:11 step:10864 [D loss: 0.559977, acc.: 70.31%] [G loss: 0.584417]\n",
      "epoch:11 step:10865 [D loss: 0.471991, acc.: 81.25%] [G loss: 0.670950]\n",
      "epoch:11 step:10866 [D loss: 0.580269, acc.: 68.75%] [G loss: 0.589531]\n",
      "epoch:11 step:10867 [D loss: 0.570957, acc.: 64.84%] [G loss: 0.451628]\n",
      "epoch:11 step:10868 [D loss: 0.552207, acc.: 69.53%] [G loss: 0.622431]\n",
      "epoch:11 step:10869 [D loss: 0.614383, acc.: 65.62%] [G loss: 0.653200]\n",
      "epoch:11 step:10870 [D loss: 0.527574, acc.: 69.53%] [G loss: 0.684923]\n",
      "epoch:11 step:10871 [D loss: 0.484357, acc.: 77.34%] [G loss: 0.718295]\n",
      "epoch:11 step:10872 [D loss: 0.569605, acc.: 68.75%] [G loss: 0.619450]\n",
      "epoch:11 step:10873 [D loss: 0.691497, acc.: 56.25%] [G loss: 0.363672]\n",
      "epoch:11 step:10874 [D loss: 0.526564, acc.: 71.88%] [G loss: 0.516330]\n",
      "epoch:11 step:10875 [D loss: 0.502120, acc.: 75.00%] [G loss: 0.611012]\n",
      "epoch:11 step:10876 [D loss: 0.524486, acc.: 73.44%] [G loss: 0.592392]\n",
      "epoch:11 step:10877 [D loss: 0.571888, acc.: 67.97%] [G loss: 0.555334]\n",
      "epoch:11 step:10878 [D loss: 0.535352, acc.: 67.97%] [G loss: 0.605293]\n",
      "epoch:11 step:10879 [D loss: 0.592296, acc.: 69.53%] [G loss: 0.451858]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:11 step:10880 [D loss: 0.553456, acc.: 71.88%] [G loss: 0.658632]\n",
      "epoch:11 step:10881 [D loss: 0.490365, acc.: 78.91%] [G loss: 0.662582]\n",
      "epoch:11 step:10882 [D loss: 0.491692, acc.: 76.56%] [G loss: 0.743873]\n",
      "epoch:11 step:10883 [D loss: 0.636475, acc.: 66.41%] [G loss: 0.544845]\n",
      "epoch:11 step:10884 [D loss: 0.599372, acc.: 68.75%] [G loss: 0.733927]\n",
      "epoch:11 step:10885 [D loss: 0.589763, acc.: 66.41%] [G loss: 0.473617]\n",
      "epoch:11 step:10886 [D loss: 0.501552, acc.: 74.22%] [G loss: 0.518987]\n",
      "epoch:11 step:10887 [D loss: 0.546278, acc.: 68.75%] [G loss: 0.610875]\n",
      "epoch:11 step:10888 [D loss: 0.566306, acc.: 68.75%] [G loss: 0.635858]\n",
      "epoch:11 step:10889 [D loss: 0.500440, acc.: 76.56%] [G loss: 0.647832]\n",
      "epoch:11 step:10890 [D loss: 0.585213, acc.: 66.41%] [G loss: 0.570593]\n",
      "epoch:11 step:10891 [D loss: 0.551186, acc.: 69.53%] [G loss: 0.615898]\n",
      "epoch:11 step:10892 [D loss: 0.526350, acc.: 78.12%] [G loss: 0.582337]\n",
      "epoch:11 step:10893 [D loss: 0.557228, acc.: 70.31%] [G loss: 0.560071]\n",
      "epoch:11 step:10894 [D loss: 0.591841, acc.: 64.06%] [G loss: 0.463945]\n",
      "epoch:11 step:10895 [D loss: 0.538034, acc.: 69.53%] [G loss: 0.566182]\n",
      "epoch:11 step:10896 [D loss: 0.552011, acc.: 69.53%] [G loss: 0.642471]\n",
      "epoch:11 step:10897 [D loss: 0.579285, acc.: 67.97%] [G loss: 0.541091]\n",
      "epoch:11 step:10898 [D loss: 0.573005, acc.: 74.22%] [G loss: 0.471960]\n",
      "epoch:11 step:10899 [D loss: 0.546352, acc.: 71.09%] [G loss: 0.573111]\n",
      "epoch:11 step:10900 [D loss: 0.530273, acc.: 75.00%] [G loss: 0.513979]\n",
      "epoch:11 step:10901 [D loss: 0.571741, acc.: 68.75%] [G loss: 0.602955]\n",
      "epoch:11 step:10902 [D loss: 0.547314, acc.: 73.44%] [G loss: 0.538849]\n",
      "epoch:11 step:10903 [D loss: 0.547004, acc.: 68.75%] [G loss: 0.590538]\n",
      "epoch:11 step:10904 [D loss: 0.524498, acc.: 70.31%] [G loss: 0.610588]\n",
      "epoch:11 step:10905 [D loss: 0.510577, acc.: 71.09%] [G loss: 0.597351]\n",
      "epoch:11 step:10906 [D loss: 0.530398, acc.: 67.97%] [G loss: 0.655904]\n",
      "epoch:11 step:10907 [D loss: 0.573919, acc.: 68.75%] [G loss: 0.504062]\n",
      "epoch:11 step:10908 [D loss: 0.514549, acc.: 69.53%] [G loss: 0.605267]\n",
      "epoch:11 step:10909 [D loss: 0.457111, acc.: 80.47%] [G loss: 0.642429]\n",
      "epoch:11 step:10910 [D loss: 0.480345, acc.: 78.12%] [G loss: 0.596583]\n",
      "epoch:11 step:10911 [D loss: 0.622292, acc.: 71.09%] [G loss: 0.642526]\n",
      "epoch:11 step:10912 [D loss: 0.507680, acc.: 78.91%] [G loss: 0.686931]\n",
      "epoch:11 step:10913 [D loss: 0.616291, acc.: 64.84%] [G loss: 0.548060]\n",
      "epoch:11 step:10914 [D loss: 0.526436, acc.: 71.09%] [G loss: 0.566424]\n",
      "epoch:11 step:10915 [D loss: 0.568327, acc.: 65.62%] [G loss: 0.533116]\n",
      "epoch:11 step:10916 [D loss: 0.553725, acc.: 71.88%] [G loss: 0.673096]\n",
      "epoch:11 step:10917 [D loss: 0.516054, acc.: 71.88%] [G loss: 0.466361]\n",
      "epoch:11 step:10918 [D loss: 0.518219, acc.: 71.88%] [G loss: 0.487851]\n",
      "epoch:11 step:10919 [D loss: 0.572411, acc.: 68.75%] [G loss: 0.565315]\n",
      "epoch:11 step:10920 [D loss: 0.500487, acc.: 75.78%] [G loss: 0.526276]\n",
      "epoch:11 step:10921 [D loss: 0.530371, acc.: 71.88%] [G loss: 0.549134]\n",
      "epoch:11 step:10922 [D loss: 0.553609, acc.: 68.75%] [G loss: 0.585287]\n",
      "epoch:11 step:10923 [D loss: 0.532858, acc.: 70.31%] [G loss: 0.745960]\n",
      "epoch:11 step:10924 [D loss: 0.520597, acc.: 75.00%] [G loss: 0.666351]\n",
      "epoch:11 step:10925 [D loss: 0.550173, acc.: 72.66%] [G loss: 0.652613]\n",
      "epoch:11 step:10926 [D loss: 0.552359, acc.: 71.09%] [G loss: 0.788702]\n",
      "epoch:11 step:10927 [D loss: 0.526650, acc.: 71.88%] [G loss: 0.683417]\n",
      "epoch:11 step:10928 [D loss: 0.575797, acc.: 71.09%] [G loss: 0.689463]\n",
      "epoch:11 step:10929 [D loss: 0.591252, acc.: 68.75%] [G loss: 0.615172]\n",
      "epoch:11 step:10930 [D loss: 0.529958, acc.: 74.22%] [G loss: 0.678531]\n",
      "epoch:11 step:10931 [D loss: 0.464579, acc.: 80.47%] [G loss: 0.746398]\n",
      "epoch:11 step:10932 [D loss: 0.609566, acc.: 60.94%] [G loss: 0.627774]\n",
      "epoch:11 step:10933 [D loss: 0.566755, acc.: 65.62%] [G loss: 0.555719]\n",
      "epoch:11 step:10934 [D loss: 0.594226, acc.: 62.50%] [G loss: 0.641217]\n",
      "epoch:11 step:10935 [D loss: 0.562923, acc.: 68.75%] [G loss: 0.516740]\n",
      "epoch:11 step:10936 [D loss: 0.491673, acc.: 79.69%] [G loss: 0.529099]\n",
      "epoch:11 step:10937 [D loss: 0.477928, acc.: 79.69%] [G loss: 0.623093]\n",
      "epoch:11 step:10938 [D loss: 0.462499, acc.: 78.91%] [G loss: 0.596131]\n",
      "epoch:11 step:10939 [D loss: 0.514756, acc.: 75.00%] [G loss: 0.664210]\n",
      "epoch:11 step:10940 [D loss: 0.535776, acc.: 71.88%] [G loss: 0.613828]\n",
      "epoch:11 step:10941 [D loss: 0.485023, acc.: 76.56%] [G loss: 0.705317]\n",
      "epoch:11 step:10942 [D loss: 0.524533, acc.: 73.44%] [G loss: 0.745068]\n",
      "epoch:11 step:10943 [D loss: 0.578605, acc.: 65.62%] [G loss: 0.622334]\n",
      "epoch:11 step:10944 [D loss: 0.537099, acc.: 68.75%] [G loss: 0.557863]\n",
      "epoch:11 step:10945 [D loss: 0.503458, acc.: 77.34%] [G loss: 0.555829]\n",
      "epoch:11 step:10946 [D loss: 0.479952, acc.: 74.22%] [G loss: 0.581272]\n",
      "epoch:11 step:10947 [D loss: 0.503392, acc.: 75.78%] [G loss: 0.594613]\n",
      "epoch:11 step:10948 [D loss: 0.512093, acc.: 69.53%] [G loss: 0.756802]\n",
      "epoch:11 step:10949 [D loss: 0.497075, acc.: 77.34%] [G loss: 0.855518]\n",
      "epoch:11 step:10950 [D loss: 0.526183, acc.: 75.00%] [G loss: 0.951996]\n",
      "epoch:11 step:10951 [D loss: 0.559018, acc.: 67.19%] [G loss: 0.666084]\n",
      "epoch:11 step:10952 [D loss: 0.524914, acc.: 75.00%] [G loss: 0.565938]\n",
      "epoch:11 step:10953 [D loss: 0.602707, acc.: 63.28%] [G loss: 0.465870]\n",
      "epoch:11 step:10954 [D loss: 0.469139, acc.: 77.34%] [G loss: 0.785706]\n",
      "epoch:11 step:10955 [D loss: 0.439522, acc.: 77.34%] [G loss: 0.711542]\n",
      "epoch:11 step:10956 [D loss: 0.501635, acc.: 72.66%] [G loss: 0.930113]\n",
      "epoch:11 step:10957 [D loss: 0.503094, acc.: 73.44%] [G loss: 0.909152]\n",
      "epoch:11 step:10958 [D loss: 0.531819, acc.: 75.00%] [G loss: 0.822475]\n",
      "epoch:11 step:10959 [D loss: 0.621747, acc.: 64.06%] [G loss: 0.586658]\n",
      "epoch:11 step:10960 [D loss: 0.606620, acc.: 64.84%] [G loss: 0.514577]\n",
      "epoch:11 step:10961 [D loss: 0.447384, acc.: 78.91%] [G loss: 0.622009]\n",
      "epoch:11 step:10962 [D loss: 0.548072, acc.: 71.09%] [G loss: 0.585760]\n",
      "epoch:11 step:10963 [D loss: 0.528064, acc.: 73.44%] [G loss: 0.605821]\n",
      "epoch:11 step:10964 [D loss: 0.496103, acc.: 72.66%] [G loss: 0.760765]\n",
      "epoch:11 step:10965 [D loss: 0.611364, acc.: 65.62%] [G loss: 0.674691]\n",
      "epoch:11 step:10966 [D loss: 0.544828, acc.: 70.31%] [G loss: 0.600905]\n",
      "epoch:11 step:10967 [D loss: 0.500554, acc.: 72.66%] [G loss: 0.701396]\n",
      "epoch:11 step:10968 [D loss: 0.444776, acc.: 81.25%] [G loss: 0.764851]\n",
      "epoch:11 step:10969 [D loss: 0.526303, acc.: 70.31%] [G loss: 0.629986]\n",
      "epoch:11 step:10970 [D loss: 0.549341, acc.: 67.19%] [G loss: 0.600798]\n",
      "epoch:11 step:10971 [D loss: 0.520481, acc.: 68.75%] [G loss: 0.764974]\n",
      "epoch:11 step:10972 [D loss: 0.641049, acc.: 65.62%] [G loss: 0.531438]\n",
      "epoch:11 step:10973 [D loss: 0.498906, acc.: 74.22%] [G loss: 0.667687]\n",
      "epoch:11 step:10974 [D loss: 0.551893, acc.: 68.75%] [G loss: 0.689127]\n",
      "epoch:11 step:10975 [D loss: 0.585219, acc.: 70.31%] [G loss: 0.602860]\n",
      "epoch:11 step:10976 [D loss: 0.537365, acc.: 72.66%] [G loss: 0.584690]\n",
      "epoch:11 step:10977 [D loss: 0.550859, acc.: 67.97%] [G loss: 0.649077]\n",
      "epoch:11 step:10978 [D loss: 0.543649, acc.: 71.88%] [G loss: 0.625247]\n",
      "epoch:11 step:10979 [D loss: 0.576901, acc.: 72.66%] [G loss: 0.627419]\n",
      "epoch:11 step:10980 [D loss: 0.585748, acc.: 67.19%] [G loss: 0.563805]\n",
      "epoch:11 step:10981 [D loss: 0.507385, acc.: 75.78%] [G loss: 0.581847]\n",
      "epoch:11 step:10982 [D loss: 0.581073, acc.: 67.97%] [G loss: 0.727051]\n",
      "epoch:11 step:10983 [D loss: 0.537262, acc.: 71.88%] [G loss: 0.681129]\n",
      "epoch:11 step:10984 [D loss: 0.491229, acc.: 75.78%] [G loss: 0.788580]\n",
      "epoch:11 step:10985 [D loss: 0.564827, acc.: 67.19%] [G loss: 0.522070]\n",
      "epoch:11 step:10986 [D loss: 0.542362, acc.: 67.97%] [G loss: 0.661902]\n",
      "epoch:11 step:10987 [D loss: 0.511718, acc.: 70.31%] [G loss: 0.665128]\n",
      "epoch:11 step:10988 [D loss: 0.495408, acc.: 75.00%] [G loss: 0.737675]\n",
      "epoch:11 step:10989 [D loss: 0.524317, acc.: 75.00%] [G loss: 0.815823]\n",
      "epoch:11 step:10990 [D loss: 0.533269, acc.: 71.09%] [G loss: 0.617846]\n",
      "epoch:11 step:10991 [D loss: 0.629058, acc.: 63.28%] [G loss: 0.411727]\n",
      "epoch:11 step:10992 [D loss: 0.522650, acc.: 73.44%] [G loss: 0.580095]\n",
      "epoch:11 step:10993 [D loss: 0.590752, acc.: 70.31%] [G loss: 0.478220]\n",
      "epoch:11 step:10994 [D loss: 0.531865, acc.: 70.31%] [G loss: 0.539739]\n",
      "epoch:11 step:10995 [D loss: 0.543810, acc.: 66.41%] [G loss: 0.582222]\n",
      "epoch:11 step:10996 [D loss: 0.549017, acc.: 68.75%] [G loss: 0.638246]\n",
      "epoch:11 step:10997 [D loss: 0.509860, acc.: 73.44%] [G loss: 0.686780]\n",
      "epoch:11 step:10998 [D loss: 0.515665, acc.: 73.44%] [G loss: 0.643315]\n",
      "epoch:11 step:10999 [D loss: 0.489985, acc.: 75.00%] [G loss: 0.677382]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:11 step:11000 [D loss: 0.449593, acc.: 83.59%] [G loss: 0.705566]\n",
      "epoch:11 step:11001 [D loss: 0.519690, acc.: 74.22%] [G loss: 0.667661]\n",
      "epoch:11 step:11002 [D loss: 0.522874, acc.: 73.44%] [G loss: 0.634759]\n",
      "epoch:11 step:11003 [D loss: 0.631514, acc.: 62.50%] [G loss: 0.593520]\n",
      "epoch:11 step:11004 [D loss: 0.570107, acc.: 72.66%] [G loss: 0.545487]\n",
      "epoch:11 step:11005 [D loss: 0.577712, acc.: 68.75%] [G loss: 0.528755]\n",
      "epoch:11 step:11006 [D loss: 0.530069, acc.: 73.44%] [G loss: 0.542691]\n",
      "epoch:11 step:11007 [D loss: 0.519659, acc.: 71.88%] [G loss: 0.635676]\n",
      "epoch:11 step:11008 [D loss: 0.534567, acc.: 68.75%] [G loss: 0.524727]\n",
      "epoch:11 step:11009 [D loss: 0.589462, acc.: 62.50%] [G loss: 0.699368]\n",
      "epoch:11 step:11010 [D loss: 0.526766, acc.: 71.09%] [G loss: 0.535115]\n",
      "epoch:11 step:11011 [D loss: 0.579911, acc.: 66.41%] [G loss: 0.547927]\n",
      "epoch:11 step:11012 [D loss: 0.561456, acc.: 70.31%] [G loss: 0.501760]\n",
      "epoch:11 step:11013 [D loss: 0.543830, acc.: 69.53%] [G loss: 0.494975]\n",
      "epoch:11 step:11014 [D loss: 0.527063, acc.: 71.88%] [G loss: 0.627049]\n",
      "epoch:11 step:11015 [D loss: 0.495321, acc.: 75.78%] [G loss: 0.847507]\n",
      "epoch:11 step:11016 [D loss: 0.561289, acc.: 66.41%] [G loss: 0.744511]\n",
      "epoch:11 step:11017 [D loss: 0.628958, acc.: 60.16%] [G loss: 0.706884]\n",
      "epoch:11 step:11018 [D loss: 0.565922, acc.: 70.31%] [G loss: 0.627487]\n",
      "epoch:11 step:11019 [D loss: 0.504279, acc.: 71.09%] [G loss: 0.566840]\n",
      "epoch:11 step:11020 [D loss: 0.661776, acc.: 60.16%] [G loss: 0.429012]\n",
      "epoch:11 step:11021 [D loss: 0.552907, acc.: 67.19%] [G loss: 0.541935]\n",
      "epoch:11 step:11022 [D loss: 0.563963, acc.: 67.97%] [G loss: 0.520965]\n",
      "epoch:11 step:11023 [D loss: 0.628860, acc.: 62.50%] [G loss: 0.509984]\n",
      "epoch:11 step:11024 [D loss: 0.561175, acc.: 71.09%] [G loss: 0.546677]\n",
      "epoch:11 step:11025 [D loss: 0.567859, acc.: 68.75%] [G loss: 0.503490]\n",
      "epoch:11 step:11026 [D loss: 0.502822, acc.: 72.66%] [G loss: 0.617023]\n",
      "epoch:11 step:11027 [D loss: 0.596718, acc.: 64.06%] [G loss: 0.592203]\n",
      "epoch:11 step:11028 [D loss: 0.528514, acc.: 74.22%] [G loss: 0.526650]\n",
      "epoch:11 step:11029 [D loss: 0.574859, acc.: 68.75%] [G loss: 0.559858]\n",
      "epoch:11 step:11030 [D loss: 0.539184, acc.: 75.78%] [G loss: 0.616127]\n",
      "epoch:11 step:11031 [D loss: 0.495860, acc.: 76.56%] [G loss: 0.667104]\n",
      "epoch:11 step:11032 [D loss: 0.483180, acc.: 73.44%] [G loss: 0.803818]\n",
      "epoch:11 step:11033 [D loss: 0.534635, acc.: 73.44%] [G loss: 0.599300]\n",
      "epoch:11 step:11034 [D loss: 0.562945, acc.: 66.41%] [G loss: 0.539341]\n",
      "epoch:11 step:11035 [D loss: 0.533490, acc.: 70.31%] [G loss: 0.525391]\n",
      "epoch:11 step:11036 [D loss: 0.572866, acc.: 66.41%] [G loss: 0.449291]\n",
      "epoch:11 step:11037 [D loss: 0.493797, acc.: 77.34%] [G loss: 0.629750]\n",
      "epoch:11 step:11038 [D loss: 0.580271, acc.: 67.19%] [G loss: 0.531042]\n",
      "epoch:11 step:11039 [D loss: 0.530687, acc.: 71.09%] [G loss: 0.588249]\n",
      "epoch:11 step:11040 [D loss: 0.546830, acc.: 68.75%] [G loss: 0.663898]\n",
      "epoch:11 step:11041 [D loss: 0.519181, acc.: 71.88%] [G loss: 0.569556]\n",
      "epoch:11 step:11042 [D loss: 0.560519, acc.: 66.41%] [G loss: 0.529618]\n",
      "epoch:11 step:11043 [D loss: 0.464181, acc.: 77.34%] [G loss: 0.540373]\n",
      "epoch:11 step:11044 [D loss: 0.544388, acc.: 70.31%] [G loss: 0.568631]\n",
      "epoch:11 step:11045 [D loss: 0.555772, acc.: 66.41%] [G loss: 0.541065]\n",
      "epoch:11 step:11046 [D loss: 0.604255, acc.: 69.53%] [G loss: 0.597006]\n",
      "epoch:11 step:11047 [D loss: 0.694773, acc.: 60.16%] [G loss: 0.588084]\n",
      "epoch:11 step:11048 [D loss: 0.526037, acc.: 75.78%] [G loss: 0.475521]\n",
      "epoch:11 step:11049 [D loss: 0.501552, acc.: 73.44%] [G loss: 0.560550]\n",
      "epoch:11 step:11050 [D loss: 0.492992, acc.: 74.22%] [G loss: 0.741625]\n",
      "epoch:11 step:11051 [D loss: 0.606258, acc.: 67.97%] [G loss: 0.630787]\n",
      "epoch:11 step:11052 [D loss: 0.595784, acc.: 67.97%] [G loss: 0.703152]\n",
      "epoch:11 step:11053 [D loss: 0.496923, acc.: 74.22%] [G loss: 0.565894]\n",
      "epoch:11 step:11054 [D loss: 0.444950, acc.: 77.34%] [G loss: 0.653379]\n",
      "epoch:11 step:11055 [D loss: 0.560592, acc.: 70.31%] [G loss: 0.730699]\n",
      "epoch:11 step:11056 [D loss: 0.539953, acc.: 69.53%] [G loss: 0.578761]\n",
      "epoch:11 step:11057 [D loss: 0.491044, acc.: 77.34%] [G loss: 0.605129]\n",
      "epoch:11 step:11058 [D loss: 0.531094, acc.: 77.34%] [G loss: 0.624728]\n",
      "epoch:11 step:11059 [D loss: 0.573290, acc.: 67.19%] [G loss: 0.661644]\n",
      "epoch:11 step:11060 [D loss: 0.521465, acc.: 74.22%] [G loss: 0.604128]\n",
      "epoch:11 step:11061 [D loss: 0.555557, acc.: 70.31%] [G loss: 0.716246]\n",
      "epoch:11 step:11062 [D loss: 0.500024, acc.: 74.22%] [G loss: 0.661878]\n",
      "epoch:11 step:11063 [D loss: 0.538970, acc.: 74.22%] [G loss: 0.619144]\n",
      "epoch:11 step:11064 [D loss: 0.528467, acc.: 74.22%] [G loss: 0.680348]\n",
      "epoch:11 step:11065 [D loss: 0.556161, acc.: 70.31%] [G loss: 0.626347]\n",
      "epoch:11 step:11066 [D loss: 0.545696, acc.: 68.75%] [G loss: 0.633466]\n",
      "epoch:11 step:11067 [D loss: 0.565317, acc.: 67.19%] [G loss: 0.607628]\n",
      "epoch:11 step:11068 [D loss: 0.561731, acc.: 67.97%] [G loss: 0.651311]\n",
      "epoch:11 step:11069 [D loss: 0.557825, acc.: 71.88%] [G loss: 0.701986]\n",
      "epoch:11 step:11070 [D loss: 0.537309, acc.: 73.44%] [G loss: 0.507618]\n",
      "epoch:11 step:11071 [D loss: 0.545077, acc.: 71.88%] [G loss: 0.503309]\n",
      "epoch:11 step:11072 [D loss: 0.565595, acc.: 67.19%] [G loss: 0.491203]\n",
      "epoch:11 step:11073 [D loss: 0.649075, acc.: 63.28%] [G loss: 0.435270]\n",
      "epoch:11 step:11074 [D loss: 0.538357, acc.: 72.66%] [G loss: 0.433400]\n",
      "epoch:11 step:11075 [D loss: 0.498585, acc.: 73.44%] [G loss: 0.712912]\n",
      "epoch:11 step:11076 [D loss: 0.485817, acc.: 75.00%] [G loss: 0.833441]\n",
      "epoch:11 step:11077 [D loss: 0.464340, acc.: 77.34%] [G loss: 0.831207]\n",
      "epoch:11 step:11078 [D loss: 0.509640, acc.: 76.56%] [G loss: 0.625700]\n",
      "epoch:11 step:11079 [D loss: 0.564007, acc.: 64.06%] [G loss: 0.665646]\n",
      "epoch:11 step:11080 [D loss: 0.558733, acc.: 66.41%] [G loss: 0.667530]\n",
      "epoch:11 step:11081 [D loss: 0.504326, acc.: 76.56%] [G loss: 0.590037]\n",
      "epoch:11 step:11082 [D loss: 0.531665, acc.: 72.66%] [G loss: 0.546212]\n",
      "epoch:11 step:11083 [D loss: 0.589728, acc.: 64.06%] [G loss: 0.761635]\n",
      "epoch:11 step:11084 [D loss: 0.567031, acc.: 71.88%] [G loss: 0.637898]\n",
      "epoch:11 step:11085 [D loss: 0.566151, acc.: 65.62%] [G loss: 0.526042]\n",
      "epoch:11 step:11086 [D loss: 0.532993, acc.: 74.22%] [G loss: 0.555395]\n",
      "epoch:11 step:11087 [D loss: 0.524989, acc.: 71.09%] [G loss: 0.697547]\n",
      "epoch:11 step:11088 [D loss: 0.450141, acc.: 78.12%] [G loss: 0.737939]\n",
      "epoch:11 step:11089 [D loss: 0.462427, acc.: 77.34%] [G loss: 0.953193]\n",
      "epoch:11 step:11090 [D loss: 0.557029, acc.: 66.41%] [G loss: 0.704550]\n",
      "epoch:11 step:11091 [D loss: 0.619790, acc.: 64.84%] [G loss: 0.620305]\n",
      "epoch:11 step:11092 [D loss: 0.519973, acc.: 75.00%] [G loss: 0.519556]\n",
      "epoch:11 step:11093 [D loss: 0.520080, acc.: 75.00%] [G loss: 0.648195]\n",
      "epoch:11 step:11094 [D loss: 0.581048, acc.: 70.31%] [G loss: 0.521319]\n",
      "epoch:11 step:11095 [D loss: 0.651289, acc.: 58.59%] [G loss: 0.403012]\n",
      "epoch:11 step:11096 [D loss: 0.498031, acc.: 77.34%] [G loss: 0.560165]\n",
      "epoch:11 step:11097 [D loss: 0.565091, acc.: 60.94%] [G loss: 0.442519]\n",
      "epoch:11 step:11098 [D loss: 0.534316, acc.: 71.88%] [G loss: 0.534419]\n",
      "epoch:11 step:11099 [D loss: 0.506790, acc.: 72.66%] [G loss: 0.527842]\n",
      "epoch:11 step:11100 [D loss: 0.588536, acc.: 65.62%] [G loss: 0.615233]\n",
      "epoch:11 step:11101 [D loss: 0.632363, acc.: 65.62%] [G loss: 0.892464]\n",
      "epoch:11 step:11102 [D loss: 0.519261, acc.: 72.66%] [G loss: 0.791232]\n",
      "epoch:11 step:11103 [D loss: 0.499508, acc.: 75.00%] [G loss: 0.706668]\n",
      "epoch:11 step:11104 [D loss: 0.542148, acc.: 72.66%] [G loss: 0.660666]\n",
      "epoch:11 step:11105 [D loss: 0.534466, acc.: 71.09%] [G loss: 0.685462]\n",
      "epoch:11 step:11106 [D loss: 0.566823, acc.: 71.88%] [G loss: 0.500060]\n",
      "epoch:11 step:11107 [D loss: 0.583086, acc.: 66.41%] [G loss: 0.681068]\n",
      "epoch:11 step:11108 [D loss: 0.459293, acc.: 83.59%] [G loss: 0.785718]\n",
      "epoch:11 step:11109 [D loss: 0.512030, acc.: 71.09%] [G loss: 0.817766]\n",
      "epoch:11 step:11110 [D loss: 0.525253, acc.: 73.44%] [G loss: 0.809742]\n",
      "epoch:11 step:11111 [D loss: 0.520483, acc.: 76.56%] [G loss: 0.623638]\n",
      "epoch:11 step:11112 [D loss: 0.536250, acc.: 67.19%] [G loss: 0.491003]\n",
      "epoch:11 step:11113 [D loss: 0.506869, acc.: 78.12%] [G loss: 0.566707]\n",
      "epoch:11 step:11114 [D loss: 0.547417, acc.: 71.88%] [G loss: 0.722133]\n",
      "epoch:11 step:11115 [D loss: 0.554647, acc.: 74.22%] [G loss: 0.491302]\n",
      "epoch:11 step:11116 [D loss: 0.553643, acc.: 74.22%] [G loss: 0.672192]\n",
      "epoch:11 step:11117 [D loss: 0.524285, acc.: 76.56%] [G loss: 0.722969]\n",
      "epoch:11 step:11118 [D loss: 0.561104, acc.: 68.75%] [G loss: 0.598156]\n",
      "epoch:11 step:11119 [D loss: 0.626681, acc.: 64.84%] [G loss: 0.496527]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:11 step:11120 [D loss: 0.533238, acc.: 68.75%] [G loss: 0.511853]\n",
      "epoch:11 step:11121 [D loss: 0.481580, acc.: 78.12%] [G loss: 0.662585]\n",
      "epoch:11 step:11122 [D loss: 0.479250, acc.: 76.56%] [G loss: 0.756533]\n",
      "epoch:11 step:11123 [D loss: 0.575288, acc.: 67.19%] [G loss: 0.696454]\n",
      "epoch:11 step:11124 [D loss: 0.552581, acc.: 75.00%] [G loss: 0.728831]\n",
      "epoch:11 step:11125 [D loss: 0.594278, acc.: 66.41%] [G loss: 0.624858]\n",
      "epoch:11 step:11126 [D loss: 0.513054, acc.: 78.91%] [G loss: 0.517115]\n",
      "epoch:11 step:11127 [D loss: 0.609272, acc.: 66.41%] [G loss: 0.458971]\n",
      "epoch:11 step:11128 [D loss: 0.579993, acc.: 60.94%] [G loss: 0.557712]\n",
      "epoch:11 step:11129 [D loss: 0.510824, acc.: 71.09%] [G loss: 0.610854]\n",
      "epoch:11 step:11130 [D loss: 0.438104, acc.: 75.78%] [G loss: 0.738890]\n",
      "epoch:11 step:11131 [D loss: 0.616665, acc.: 62.50%] [G loss: 0.582732]\n",
      "epoch:11 step:11132 [D loss: 0.563098, acc.: 70.31%] [G loss: 0.509056]\n",
      "epoch:11 step:11133 [D loss: 0.514709, acc.: 72.66%] [G loss: 0.671991]\n",
      "epoch:11 step:11134 [D loss: 0.588907, acc.: 71.88%] [G loss: 0.469527]\n",
      "epoch:11 step:11135 [D loss: 0.642279, acc.: 61.72%] [G loss: 0.567584]\n",
      "epoch:11 step:11136 [D loss: 0.537868, acc.: 68.75%] [G loss: 0.592791]\n",
      "epoch:11 step:11137 [D loss: 0.512523, acc.: 76.56%] [G loss: 0.655555]\n",
      "epoch:11 step:11138 [D loss: 0.615086, acc.: 60.94%] [G loss: 0.535267]\n",
      "epoch:11 step:11139 [D loss: 0.498869, acc.: 72.66%] [G loss: 0.629044]\n",
      "epoch:11 step:11140 [D loss: 0.465291, acc.: 78.12%] [G loss: 0.754231]\n",
      "epoch:11 step:11141 [D loss: 0.526711, acc.: 69.53%] [G loss: 0.582339]\n",
      "epoch:11 step:11142 [D loss: 0.508757, acc.: 74.22%] [G loss: 0.535435]\n",
      "epoch:11 step:11143 [D loss: 0.574098, acc.: 69.53%] [G loss: 0.577103]\n",
      "epoch:11 step:11144 [D loss: 0.511490, acc.: 73.44%] [G loss: 0.586019]\n",
      "epoch:11 step:11145 [D loss: 0.505812, acc.: 75.78%] [G loss: 0.587008]\n",
      "epoch:11 step:11146 [D loss: 0.550780, acc.: 71.09%] [G loss: 0.558826]\n",
      "epoch:11 step:11147 [D loss: 0.558954, acc.: 69.53%] [G loss: 0.542538]\n",
      "epoch:11 step:11148 [D loss: 0.525814, acc.: 75.00%] [G loss: 0.432563]\n",
      "epoch:11 step:11149 [D loss: 0.494447, acc.: 74.22%] [G loss: 0.576794]\n",
      "epoch:11 step:11150 [D loss: 0.520425, acc.: 71.88%] [G loss: 0.530451]\n",
      "epoch:11 step:11151 [D loss: 0.579046, acc.: 67.19%] [G loss: 0.676820]\n",
      "epoch:11 step:11152 [D loss: 0.601410, acc.: 65.62%] [G loss: 0.632514]\n",
      "epoch:11 step:11153 [D loss: 0.570880, acc.: 64.06%] [G loss: 0.482152]\n",
      "epoch:11 step:11154 [D loss: 0.591403, acc.: 66.41%] [G loss: 0.480088]\n",
      "epoch:11 step:11155 [D loss: 0.517007, acc.: 69.53%] [G loss: 0.507079]\n",
      "epoch:11 step:11156 [D loss: 0.567128, acc.: 69.53%] [G loss: 0.424880]\n",
      "epoch:11 step:11157 [D loss: 0.548126, acc.: 69.53%] [G loss: 0.480080]\n",
      "epoch:11 step:11158 [D loss: 0.618780, acc.: 63.28%] [G loss: 0.448786]\n",
      "epoch:11 step:11159 [D loss: 0.548697, acc.: 67.19%] [G loss: 0.435066]\n",
      "epoch:11 step:11160 [D loss: 0.559843, acc.: 70.31%] [G loss: 0.487046]\n",
      "epoch:11 step:11161 [D loss: 0.512510, acc.: 73.44%] [G loss: 0.645365]\n",
      "epoch:11 step:11162 [D loss: 0.494943, acc.: 72.66%] [G loss: 0.682239]\n",
      "epoch:11 step:11163 [D loss: 0.595040, acc.: 69.53%] [G loss: 0.630281]\n",
      "epoch:11 step:11164 [D loss: 0.469728, acc.: 75.00%] [G loss: 0.650674]\n",
      "epoch:11 step:11165 [D loss: 0.660237, acc.: 64.84%] [G loss: 0.723517]\n",
      "epoch:11 step:11166 [D loss: 0.511137, acc.: 71.09%] [G loss: 0.637575]\n",
      "epoch:11 step:11167 [D loss: 0.445508, acc.: 80.47%] [G loss: 0.782623]\n",
      "epoch:11 step:11168 [D loss: 0.632779, acc.: 61.72%] [G loss: 0.578130]\n",
      "epoch:11 step:11169 [D loss: 0.617290, acc.: 67.97%] [G loss: 0.512098]\n",
      "epoch:11 step:11170 [D loss: 0.550176, acc.: 71.09%] [G loss: 0.612413]\n",
      "epoch:11 step:11171 [D loss: 0.496384, acc.: 73.44%] [G loss: 0.556361]\n",
      "epoch:11 step:11172 [D loss: 0.564977, acc.: 67.19%] [G loss: 0.434121]\n",
      "epoch:11 step:11173 [D loss: 0.511189, acc.: 72.66%] [G loss: 0.492302]\n",
      "epoch:11 step:11174 [D loss: 0.617660, acc.: 60.94%] [G loss: 0.544780]\n",
      "epoch:11 step:11175 [D loss: 0.531343, acc.: 74.22%] [G loss: 0.423229]\n",
      "epoch:11 step:11176 [D loss: 0.551274, acc.: 67.19%] [G loss: 0.478089]\n",
      "epoch:11 step:11177 [D loss: 0.484695, acc.: 74.22%] [G loss: 0.661205]\n",
      "epoch:11 step:11178 [D loss: 0.457449, acc.: 78.91%] [G loss: 0.840784]\n",
      "epoch:11 step:11179 [D loss: 0.526141, acc.: 71.88%] [G loss: 0.652357]\n",
      "epoch:11 step:11180 [D loss: 0.607689, acc.: 64.06%] [G loss: 0.585220]\n",
      "epoch:11 step:11181 [D loss: 0.566183, acc.: 67.97%] [G loss: 0.616562]\n",
      "epoch:11 step:11182 [D loss: 0.509566, acc.: 75.78%] [G loss: 0.594514]\n",
      "epoch:11 step:11183 [D loss: 0.575346, acc.: 64.84%] [G loss: 0.711881]\n",
      "epoch:11 step:11184 [D loss: 0.560494, acc.: 68.75%] [G loss: 0.540624]\n",
      "epoch:11 step:11185 [D loss: 0.559181, acc.: 67.97%] [G loss: 0.535973]\n",
      "epoch:11 step:11186 [D loss: 0.540519, acc.: 73.44%] [G loss: 0.511873]\n",
      "epoch:11 step:11187 [D loss: 0.636164, acc.: 59.38%] [G loss: 0.527878]\n",
      "epoch:11 step:11188 [D loss: 0.613425, acc.: 59.38%] [G loss: 0.378737]\n",
      "epoch:11 step:11189 [D loss: 0.568420, acc.: 67.19%] [G loss: 0.472446]\n",
      "epoch:11 step:11190 [D loss: 0.596216, acc.: 64.84%] [G loss: 0.590470]\n",
      "epoch:11 step:11191 [D loss: 0.506469, acc.: 72.66%] [G loss: 0.758316]\n",
      "epoch:11 step:11192 [D loss: 0.493366, acc.: 75.00%] [G loss: 0.711451]\n",
      "epoch:11 step:11193 [D loss: 0.513969, acc.: 73.44%] [G loss: 0.828040]\n",
      "epoch:11 step:11194 [D loss: 0.557203, acc.: 66.41%] [G loss: 0.660175]\n",
      "epoch:11 step:11195 [D loss: 0.621815, acc.: 64.84%] [G loss: 0.463028]\n",
      "epoch:11 step:11196 [D loss: 0.511498, acc.: 78.91%] [G loss: 0.580361]\n",
      "epoch:11 step:11197 [D loss: 0.452442, acc.: 81.25%] [G loss: 0.654193]\n",
      "epoch:11 step:11198 [D loss: 0.550392, acc.: 70.31%] [G loss: 0.545679]\n",
      "epoch:11 step:11199 [D loss: 0.628615, acc.: 64.06%] [G loss: 0.507511]\n",
      "epoch:11 step:11200 [D loss: 0.519899, acc.: 72.66%] [G loss: 0.534841]\n",
      "epoch:11 step:11201 [D loss: 0.459108, acc.: 80.47%] [G loss: 0.640585]\n",
      "epoch:11 step:11202 [D loss: 0.529227, acc.: 71.09%] [G loss: 0.675070]\n",
      "epoch:11 step:11203 [D loss: 0.531657, acc.: 71.09%] [G loss: 0.704482]\n",
      "epoch:11 step:11204 [D loss: 0.471526, acc.: 75.00%] [G loss: 0.814569]\n",
      "epoch:11 step:11205 [D loss: 0.508712, acc.: 73.44%] [G loss: 0.660461]\n",
      "epoch:11 step:11206 [D loss: 0.480364, acc.: 78.12%] [G loss: 0.725981]\n",
      "epoch:11 step:11207 [D loss: 0.514322, acc.: 76.56%] [G loss: 0.726511]\n",
      "epoch:11 step:11208 [D loss: 0.547290, acc.: 69.53%] [G loss: 0.685068]\n",
      "epoch:11 step:11209 [D loss: 0.633991, acc.: 58.59%] [G loss: 0.607248]\n",
      "epoch:11 step:11210 [D loss: 0.566613, acc.: 68.75%] [G loss: 0.580644]\n",
      "epoch:11 step:11211 [D loss: 0.592642, acc.: 66.41%] [G loss: 0.617018]\n",
      "epoch:11 step:11212 [D loss: 0.546061, acc.: 72.66%] [G loss: 0.661886]\n",
      "epoch:11 step:11213 [D loss: 0.475774, acc.: 80.47%] [G loss: 0.623711]\n",
      "epoch:11 step:11214 [D loss: 0.539415, acc.: 67.97%] [G loss: 0.575790]\n",
      "epoch:11 step:11215 [D loss: 0.549935, acc.: 72.66%] [G loss: 0.650626]\n",
      "epoch:11 step:11216 [D loss: 0.501688, acc.: 78.12%] [G loss: 0.573290]\n",
      "epoch:11 step:11217 [D loss: 0.531200, acc.: 71.88%] [G loss: 0.697347]\n",
      "epoch:11 step:11218 [D loss: 0.519137, acc.: 71.88%] [G loss: 0.670681]\n",
      "epoch:11 step:11219 [D loss: 0.473581, acc.: 76.56%] [G loss: 0.846902]\n",
      "epoch:11 step:11220 [D loss: 0.600548, acc.: 68.75%] [G loss: 0.787418]\n",
      "epoch:11 step:11221 [D loss: 0.472608, acc.: 78.91%] [G loss: 0.748399]\n",
      "epoch:11 step:11222 [D loss: 0.639626, acc.: 63.28%] [G loss: 0.628008]\n",
      "epoch:11 step:11223 [D loss: 0.526233, acc.: 73.44%] [G loss: 0.503548]\n",
      "epoch:11 step:11224 [D loss: 0.608463, acc.: 65.62%] [G loss: 0.561115]\n",
      "epoch:11 step:11225 [D loss: 0.509578, acc.: 73.44%] [G loss: 0.614498]\n",
      "epoch:11 step:11226 [D loss: 0.442011, acc.: 84.38%] [G loss: 0.932035]\n",
      "epoch:11 step:11227 [D loss: 0.764604, acc.: 59.38%] [G loss: 0.609428]\n",
      "epoch:11 step:11228 [D loss: 0.505592, acc.: 71.09%] [G loss: 0.670848]\n",
      "epoch:11 step:11229 [D loss: 0.496122, acc.: 75.78%] [G loss: 0.732518]\n",
      "epoch:11 step:11230 [D loss: 0.462208, acc.: 76.56%] [G loss: 0.640447]\n",
      "epoch:11 step:11231 [D loss: 0.476954, acc.: 75.78%] [G loss: 0.841200]\n",
      "epoch:11 step:11232 [D loss: 0.444971, acc.: 78.91%] [G loss: 0.821310]\n",
      "epoch:11 step:11233 [D loss: 0.414713, acc.: 82.81%] [G loss: 1.116286]\n",
      "epoch:11 step:11234 [D loss: 0.406030, acc.: 82.81%] [G loss: 1.052985]\n",
      "epoch:11 step:11235 [D loss: 0.817863, acc.: 58.59%] [G loss: 1.112874]\n",
      "epoch:11 step:11236 [D loss: 0.511526, acc.: 76.56%] [G loss: 1.196806]\n",
      "epoch:11 step:11237 [D loss: 0.481539, acc.: 74.22%] [G loss: 1.013705]\n",
      "epoch:11 step:11238 [D loss: 0.625531, acc.: 62.50%] [G loss: 0.924562]\n",
      "epoch:11 step:11239 [D loss: 0.574923, acc.: 66.41%] [G loss: 0.729863]\n",
      "epoch:11 step:11240 [D loss: 0.516849, acc.: 77.34%] [G loss: 0.882097]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:11 step:11241 [D loss: 0.526683, acc.: 72.66%] [G loss: 0.718674]\n",
      "epoch:11 step:11242 [D loss: 0.466843, acc.: 78.91%] [G loss: 0.853384]\n",
      "epoch:11 step:11243 [D loss: 0.346325, acc.: 89.84%] [G loss: 1.229957]\n",
      "epoch:11 step:11244 [D loss: 0.446160, acc.: 82.03%] [G loss: 1.199138]\n",
      "epoch:12 step:11245 [D loss: 0.598749, acc.: 67.19%] [G loss: 0.935405]\n",
      "epoch:12 step:11246 [D loss: 0.466480, acc.: 78.12%] [G loss: 0.845394]\n",
      "epoch:12 step:11247 [D loss: 0.646449, acc.: 61.72%] [G loss: 0.885585]\n",
      "epoch:12 step:11248 [D loss: 0.520620, acc.: 72.66%] [G loss: 0.819953]\n",
      "epoch:12 step:11249 [D loss: 0.581523, acc.: 69.53%] [G loss: 0.755876]\n",
      "epoch:12 step:11250 [D loss: 0.559251, acc.: 67.19%] [G loss: 0.778956]\n",
      "epoch:12 step:11251 [D loss: 0.498311, acc.: 75.78%] [G loss: 0.769207]\n",
      "epoch:12 step:11252 [D loss: 0.506651, acc.: 80.47%] [G loss: 0.825642]\n",
      "epoch:12 step:11253 [D loss: 0.562329, acc.: 67.19%] [G loss: 0.656951]\n",
      "epoch:12 step:11254 [D loss: 0.558876, acc.: 69.53%] [G loss: 0.598270]\n",
      "epoch:12 step:11255 [D loss: 0.473587, acc.: 76.56%] [G loss: 0.792498]\n",
      "epoch:12 step:11256 [D loss: 0.510639, acc.: 76.56%] [G loss: 0.636488]\n",
      "epoch:12 step:11257 [D loss: 0.530784, acc.: 71.88%] [G loss: 0.584429]\n",
      "epoch:12 step:11258 [D loss: 0.568177, acc.: 68.75%] [G loss: 0.561844]\n",
      "epoch:12 step:11259 [D loss: 0.461494, acc.: 81.25%] [G loss: 0.702416]\n",
      "epoch:12 step:11260 [D loss: 0.481021, acc.: 75.00%] [G loss: 0.710524]\n",
      "epoch:12 step:11261 [D loss: 0.568467, acc.: 71.09%] [G loss: 0.730854]\n",
      "epoch:12 step:11262 [D loss: 0.629773, acc.: 65.62%] [G loss: 0.536442]\n",
      "epoch:12 step:11263 [D loss: 0.606561, acc.: 64.84%] [G loss: 0.549743]\n",
      "epoch:12 step:11264 [D loss: 0.661856, acc.: 62.50%] [G loss: 0.668813]\n",
      "epoch:12 step:11265 [D loss: 0.530837, acc.: 75.00%] [G loss: 0.624416]\n",
      "epoch:12 step:11266 [D loss: 0.475247, acc.: 80.47%] [G loss: 0.923457]\n",
      "epoch:12 step:11267 [D loss: 0.574896, acc.: 70.31%] [G loss: 0.642316]\n",
      "epoch:12 step:11268 [D loss: 0.497792, acc.: 76.56%] [G loss: 0.623054]\n",
      "epoch:12 step:11269 [D loss: 0.491578, acc.: 78.91%] [G loss: 0.710884]\n",
      "epoch:12 step:11270 [D loss: 0.584770, acc.: 66.41%] [G loss: 0.601369]\n",
      "epoch:12 step:11271 [D loss: 0.462857, acc.: 78.12%] [G loss: 0.659637]\n",
      "epoch:12 step:11272 [D loss: 0.551934, acc.: 67.97%] [G loss: 0.657809]\n",
      "epoch:12 step:11273 [D loss: 0.516616, acc.: 73.44%] [G loss: 0.670998]\n",
      "epoch:12 step:11274 [D loss: 0.572993, acc.: 68.75%] [G loss: 0.512312]\n",
      "epoch:12 step:11275 [D loss: 0.649442, acc.: 57.81%] [G loss: 0.550228]\n",
      "epoch:12 step:11276 [D loss: 0.504433, acc.: 72.66%] [G loss: 0.736820]\n",
      "epoch:12 step:11277 [D loss: 0.480241, acc.: 75.00%] [G loss: 0.580450]\n",
      "epoch:12 step:11278 [D loss: 0.511330, acc.: 73.44%] [G loss: 0.666570]\n",
      "epoch:12 step:11279 [D loss: 0.533139, acc.: 71.09%] [G loss: 0.528362]\n",
      "epoch:12 step:11280 [D loss: 0.543862, acc.: 68.75%] [G loss: 0.727102]\n",
      "epoch:12 step:11281 [D loss: 0.492422, acc.: 77.34%] [G loss: 0.529691]\n",
      "epoch:12 step:11282 [D loss: 0.555276, acc.: 68.75%] [G loss: 0.636023]\n",
      "epoch:12 step:11283 [D loss: 0.535406, acc.: 68.75%] [G loss: 0.674439]\n",
      "epoch:12 step:11284 [D loss: 0.448927, acc.: 79.69%] [G loss: 0.617963]\n",
      "epoch:12 step:11285 [D loss: 0.513119, acc.: 73.44%] [G loss: 0.620820]\n",
      "epoch:12 step:11286 [D loss: 0.540992, acc.: 72.66%] [G loss: 0.555280]\n",
      "epoch:12 step:11287 [D loss: 0.495454, acc.: 77.34%] [G loss: 0.573594]\n",
      "epoch:12 step:11288 [D loss: 0.635347, acc.: 63.28%] [G loss: 0.382963]\n",
      "epoch:12 step:11289 [D loss: 0.467664, acc.: 77.34%] [G loss: 0.617264]\n",
      "epoch:12 step:11290 [D loss: 0.516184, acc.: 70.31%] [G loss: 0.722001]\n",
      "epoch:12 step:11291 [D loss: 0.544313, acc.: 71.88%] [G loss: 0.601648]\n",
      "epoch:12 step:11292 [D loss: 0.539751, acc.: 71.09%] [G loss: 0.623116]\n",
      "epoch:12 step:11293 [D loss: 0.493715, acc.: 77.34%] [G loss: 0.627162]\n",
      "epoch:12 step:11294 [D loss: 0.523605, acc.: 73.44%] [G loss: 0.601380]\n",
      "epoch:12 step:11295 [D loss: 0.622933, acc.: 63.28%] [G loss: 0.630394]\n",
      "epoch:12 step:11296 [D loss: 0.598399, acc.: 64.84%] [G loss: 0.561799]\n",
      "epoch:12 step:11297 [D loss: 0.494255, acc.: 76.56%] [G loss: 0.699533]\n",
      "epoch:12 step:11298 [D loss: 0.499596, acc.: 74.22%] [G loss: 0.832153]\n",
      "epoch:12 step:11299 [D loss: 0.534270, acc.: 72.66%] [G loss: 0.594081]\n",
      "epoch:12 step:11300 [D loss: 0.563923, acc.: 74.22%] [G loss: 0.672942]\n",
      "epoch:12 step:11301 [D loss: 0.510808, acc.: 75.78%] [G loss: 0.546928]\n",
      "epoch:12 step:11302 [D loss: 0.547511, acc.: 69.53%] [G loss: 0.607252]\n",
      "epoch:12 step:11303 [D loss: 0.499061, acc.: 76.56%] [G loss: 0.598320]\n",
      "epoch:12 step:11304 [D loss: 0.571233, acc.: 69.53%] [G loss: 0.617659]\n",
      "epoch:12 step:11305 [D loss: 0.518795, acc.: 73.44%] [G loss: 0.654964]\n",
      "epoch:12 step:11306 [D loss: 0.593762, acc.: 69.53%] [G loss: 0.638609]\n",
      "epoch:12 step:11307 [D loss: 0.490100, acc.: 77.34%] [G loss: 0.539415]\n",
      "epoch:12 step:11308 [D loss: 0.586006, acc.: 64.06%] [G loss: 0.568116]\n",
      "epoch:12 step:11309 [D loss: 0.565726, acc.: 70.31%] [G loss: 0.645492]\n",
      "epoch:12 step:11310 [D loss: 0.535487, acc.: 64.06%] [G loss: 0.545473]\n",
      "epoch:12 step:11311 [D loss: 0.579380, acc.: 69.53%] [G loss: 0.558269]\n",
      "epoch:12 step:11312 [D loss: 0.536017, acc.: 71.09%] [G loss: 0.497090]\n",
      "epoch:12 step:11313 [D loss: 0.488803, acc.: 75.78%] [G loss: 0.614412]\n",
      "epoch:12 step:11314 [D loss: 0.485650, acc.: 78.91%] [G loss: 0.568719]\n",
      "epoch:12 step:11315 [D loss: 0.558060, acc.: 68.75%] [G loss: 0.569736]\n",
      "epoch:12 step:11316 [D loss: 0.509341, acc.: 74.22%] [G loss: 0.696245]\n",
      "epoch:12 step:11317 [D loss: 0.530378, acc.: 71.09%] [G loss: 0.559865]\n",
      "epoch:12 step:11318 [D loss: 0.508543, acc.: 75.78%] [G loss: 0.527398]\n",
      "epoch:12 step:11319 [D loss: 0.571737, acc.: 66.41%] [G loss: 0.596643]\n",
      "epoch:12 step:11320 [D loss: 0.437441, acc.: 78.91%] [G loss: 0.703244]\n",
      "epoch:12 step:11321 [D loss: 0.458655, acc.: 76.56%] [G loss: 0.657697]\n",
      "epoch:12 step:11322 [D loss: 0.548328, acc.: 75.78%] [G loss: 0.650695]\n",
      "epoch:12 step:11323 [D loss: 0.509295, acc.: 73.44%] [G loss: 0.641542]\n",
      "epoch:12 step:11324 [D loss: 0.525540, acc.: 74.22%] [G loss: 0.651337]\n",
      "epoch:12 step:11325 [D loss: 0.570786, acc.: 68.75%] [G loss: 0.461386]\n",
      "epoch:12 step:11326 [D loss: 0.550132, acc.: 71.88%] [G loss: 0.584028]\n",
      "epoch:12 step:11327 [D loss: 0.493899, acc.: 78.12%] [G loss: 0.632235]\n",
      "epoch:12 step:11328 [D loss: 0.529235, acc.: 72.66%] [G loss: 0.632388]\n",
      "epoch:12 step:11329 [D loss: 0.520465, acc.: 73.44%] [G loss: 0.549393]\n",
      "epoch:12 step:11330 [D loss: 0.534958, acc.: 70.31%] [G loss: 0.593145]\n",
      "epoch:12 step:11331 [D loss: 0.546120, acc.: 67.97%] [G loss: 0.636129]\n",
      "epoch:12 step:11332 [D loss: 0.485202, acc.: 76.56%] [G loss: 0.701479]\n",
      "epoch:12 step:11333 [D loss: 0.500292, acc.: 75.78%] [G loss: 0.626970]\n",
      "epoch:12 step:11334 [D loss: 0.509224, acc.: 75.78%] [G loss: 0.621572]\n",
      "epoch:12 step:11335 [D loss: 0.512736, acc.: 74.22%] [G loss: 0.710469]\n",
      "epoch:12 step:11336 [D loss: 0.458400, acc.: 79.69%] [G loss: 0.761826]\n",
      "epoch:12 step:11337 [D loss: 0.488243, acc.: 75.00%] [G loss: 0.765427]\n",
      "epoch:12 step:11338 [D loss: 0.469335, acc.: 74.22%] [G loss: 0.759082]\n",
      "epoch:12 step:11339 [D loss: 0.525867, acc.: 71.09%] [G loss: 0.724276]\n",
      "epoch:12 step:11340 [D loss: 0.512137, acc.: 76.56%] [G loss: 0.639458]\n",
      "epoch:12 step:11341 [D loss: 0.571277, acc.: 67.97%] [G loss: 0.537571]\n",
      "epoch:12 step:11342 [D loss: 0.541350, acc.: 70.31%] [G loss: 0.662687]\n",
      "epoch:12 step:11343 [D loss: 0.534047, acc.: 71.09%] [G loss: 0.632318]\n",
      "epoch:12 step:11344 [D loss: 0.474979, acc.: 78.12%] [G loss: 0.658320]\n",
      "epoch:12 step:11345 [D loss: 0.530777, acc.: 70.31%] [G loss: 0.862080]\n",
      "epoch:12 step:11346 [D loss: 0.628805, acc.: 64.84%] [G loss: 0.573130]\n",
      "epoch:12 step:11347 [D loss: 0.491240, acc.: 74.22%] [G loss: 0.551896]\n",
      "epoch:12 step:11348 [D loss: 0.501130, acc.: 73.44%] [G loss: 0.693719]\n",
      "epoch:12 step:11349 [D loss: 0.611002, acc.: 63.28%] [G loss: 0.535887]\n",
      "epoch:12 step:11350 [D loss: 0.556494, acc.: 66.41%] [G loss: 0.525821]\n",
      "epoch:12 step:11351 [D loss: 0.596050, acc.: 65.62%] [G loss: 0.619644]\n",
      "epoch:12 step:11352 [D loss: 0.584299, acc.: 69.53%] [G loss: 0.605166]\n",
      "epoch:12 step:11353 [D loss: 0.584849, acc.: 67.97%] [G loss: 0.551870]\n",
      "epoch:12 step:11354 [D loss: 0.513923, acc.: 70.31%] [G loss: 0.693005]\n",
      "epoch:12 step:11355 [D loss: 0.492751, acc.: 75.78%] [G loss: 0.688526]\n",
      "epoch:12 step:11356 [D loss: 0.498828, acc.: 77.34%] [G loss: 0.669753]\n",
      "epoch:12 step:11357 [D loss: 0.555465, acc.: 71.88%] [G loss: 0.587459]\n",
      "epoch:12 step:11358 [D loss: 0.578505, acc.: 69.53%] [G loss: 0.567949]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:12 step:11359 [D loss: 0.564296, acc.: 72.66%] [G loss: 0.668270]\n",
      "epoch:12 step:11360 [D loss: 0.562531, acc.: 67.19%] [G loss: 0.677828]\n",
      "epoch:12 step:11361 [D loss: 0.514733, acc.: 72.66%] [G loss: 0.873917]\n",
      "epoch:12 step:11362 [D loss: 0.560283, acc.: 67.19%] [G loss: 0.788188]\n",
      "epoch:12 step:11363 [D loss: 0.445264, acc.: 76.56%] [G loss: 0.805798]\n",
      "epoch:12 step:11364 [D loss: 0.574130, acc.: 70.31%] [G loss: 0.808934]\n",
      "epoch:12 step:11365 [D loss: 0.499299, acc.: 74.22%] [G loss: 0.657741]\n",
      "epoch:12 step:11366 [D loss: 0.456666, acc.: 81.25%] [G loss: 0.740867]\n",
      "epoch:12 step:11367 [D loss: 0.521764, acc.: 73.44%] [G loss: 0.726513]\n",
      "epoch:12 step:11368 [D loss: 0.566028, acc.: 71.88%] [G loss: 0.694840]\n",
      "epoch:12 step:11369 [D loss: 0.606579, acc.: 64.06%] [G loss: 0.554423]\n",
      "epoch:12 step:11370 [D loss: 0.480429, acc.: 77.34%] [G loss: 0.797275]\n",
      "epoch:12 step:11371 [D loss: 0.544710, acc.: 73.44%] [G loss: 0.634258]\n",
      "epoch:12 step:11372 [D loss: 0.499443, acc.: 71.88%] [G loss: 0.554883]\n",
      "epoch:12 step:11373 [D loss: 0.554489, acc.: 65.62%] [G loss: 0.495869]\n",
      "epoch:12 step:11374 [D loss: 0.504728, acc.: 75.78%] [G loss: 0.553935]\n",
      "epoch:12 step:11375 [D loss: 0.517535, acc.: 71.88%] [G loss: 0.558997]\n",
      "epoch:12 step:11376 [D loss: 0.541002, acc.: 70.31%] [G loss: 0.601592]\n",
      "epoch:12 step:11377 [D loss: 0.521117, acc.: 69.53%] [G loss: 0.734158]\n",
      "epoch:12 step:11378 [D loss: 0.585723, acc.: 65.62%] [G loss: 0.704766]\n",
      "epoch:12 step:11379 [D loss: 0.517126, acc.: 76.56%] [G loss: 0.766456]\n",
      "epoch:12 step:11380 [D loss: 0.519269, acc.: 73.44%] [G loss: 0.718049]\n",
      "epoch:12 step:11381 [D loss: 0.593345, acc.: 71.88%] [G loss: 0.533505]\n",
      "epoch:12 step:11382 [D loss: 0.519819, acc.: 71.88%] [G loss: 0.534363]\n",
      "epoch:12 step:11383 [D loss: 0.527793, acc.: 74.22%] [G loss: 0.614716]\n",
      "epoch:12 step:11384 [D loss: 0.565059, acc.: 63.28%] [G loss: 0.610605]\n",
      "epoch:12 step:11385 [D loss: 0.498633, acc.: 71.09%] [G loss: 0.613865]\n",
      "epoch:12 step:11386 [D loss: 0.544715, acc.: 67.97%] [G loss: 0.651328]\n",
      "epoch:12 step:11387 [D loss: 0.587524, acc.: 66.41%] [G loss: 0.519784]\n",
      "epoch:12 step:11388 [D loss: 0.531079, acc.: 71.09%] [G loss: 0.611010]\n",
      "epoch:12 step:11389 [D loss: 0.540278, acc.: 66.41%] [G loss: 0.457826]\n",
      "epoch:12 step:11390 [D loss: 0.438854, acc.: 83.59%] [G loss: 0.720500]\n",
      "epoch:12 step:11391 [D loss: 0.588065, acc.: 73.44%] [G loss: 0.509174]\n",
      "epoch:12 step:11392 [D loss: 0.558109, acc.: 64.84%] [G loss: 0.570701]\n",
      "epoch:12 step:11393 [D loss: 0.548297, acc.: 71.88%] [G loss: 0.667990]\n",
      "epoch:12 step:11394 [D loss: 0.624499, acc.: 65.62%] [G loss: 0.481866]\n",
      "epoch:12 step:11395 [D loss: 0.571857, acc.: 70.31%] [G loss: 0.596364]\n",
      "epoch:12 step:11396 [D loss: 0.476916, acc.: 76.56%] [G loss: 0.662319]\n",
      "epoch:12 step:11397 [D loss: 0.608748, acc.: 66.41%] [G loss: 0.582116]\n",
      "epoch:12 step:11398 [D loss: 0.490286, acc.: 75.00%] [G loss: 0.594419]\n",
      "epoch:12 step:11399 [D loss: 0.462201, acc.: 79.69%] [G loss: 0.664191]\n",
      "epoch:12 step:11400 [D loss: 0.496933, acc.: 73.44%] [G loss: 0.781729]\n",
      "epoch:12 step:11401 [D loss: 0.538075, acc.: 68.75%] [G loss: 0.668818]\n",
      "epoch:12 step:11402 [D loss: 0.587133, acc.: 71.88%] [G loss: 0.494327]\n",
      "epoch:12 step:11403 [D loss: 0.520739, acc.: 75.78%] [G loss: 0.764017]\n",
      "epoch:12 step:11404 [D loss: 0.546944, acc.: 67.97%] [G loss: 0.698037]\n",
      "epoch:12 step:11405 [D loss: 0.574893, acc.: 67.19%] [G loss: 0.602685]\n",
      "epoch:12 step:11406 [D loss: 0.431985, acc.: 80.47%] [G loss: 0.880008]\n",
      "epoch:12 step:11407 [D loss: 0.592080, acc.: 67.97%] [G loss: 0.782905]\n",
      "epoch:12 step:11408 [D loss: 0.556078, acc.: 67.19%] [G loss: 0.599819]\n",
      "epoch:12 step:11409 [D loss: 0.499161, acc.: 76.56%] [G loss: 0.639574]\n",
      "epoch:12 step:11410 [D loss: 0.544360, acc.: 67.19%] [G loss: 0.563936]\n",
      "epoch:12 step:11411 [D loss: 0.588496, acc.: 64.84%] [G loss: 0.555802]\n",
      "epoch:12 step:11412 [D loss: 0.555863, acc.: 68.75%] [G loss: 0.604902]\n",
      "epoch:12 step:11413 [D loss: 0.591293, acc.: 70.31%] [G loss: 0.445681]\n",
      "epoch:12 step:11414 [D loss: 0.528273, acc.: 75.78%] [G loss: 0.511964]\n",
      "epoch:12 step:11415 [D loss: 0.516021, acc.: 73.44%] [G loss: 0.543081]\n",
      "epoch:12 step:11416 [D loss: 0.550236, acc.: 70.31%] [G loss: 0.761532]\n",
      "epoch:12 step:11417 [D loss: 0.478518, acc.: 75.00%] [G loss: 0.689287]\n",
      "epoch:12 step:11418 [D loss: 0.642827, acc.: 61.72%] [G loss: 0.501318]\n",
      "epoch:12 step:11419 [D loss: 0.547892, acc.: 66.41%] [G loss: 0.566669]\n",
      "epoch:12 step:11420 [D loss: 0.503761, acc.: 75.00%] [G loss: 0.672612]\n",
      "epoch:12 step:11421 [D loss: 0.507707, acc.: 74.22%] [G loss: 0.685340]\n",
      "epoch:12 step:11422 [D loss: 0.557135, acc.: 67.97%] [G loss: 0.541733]\n",
      "epoch:12 step:11423 [D loss: 0.565899, acc.: 70.31%] [G loss: 0.754771]\n",
      "epoch:12 step:11424 [D loss: 0.602364, acc.: 60.94%] [G loss: 0.535547]\n",
      "epoch:12 step:11425 [D loss: 0.513404, acc.: 73.44%] [G loss: 0.550454]\n",
      "epoch:12 step:11426 [D loss: 0.508872, acc.: 74.22%] [G loss: 0.612311]\n",
      "epoch:12 step:11427 [D loss: 0.584355, acc.: 66.41%] [G loss: 0.588446]\n",
      "epoch:12 step:11428 [D loss: 0.504696, acc.: 79.69%] [G loss: 0.631180]\n",
      "epoch:12 step:11429 [D loss: 0.563018, acc.: 67.97%] [G loss: 0.573905]\n",
      "epoch:12 step:11430 [D loss: 0.564194, acc.: 71.09%] [G loss: 0.594048]\n",
      "epoch:12 step:11431 [D loss: 0.599323, acc.: 63.28%] [G loss: 0.518867]\n",
      "epoch:12 step:11432 [D loss: 0.476179, acc.: 75.78%] [G loss: 0.566904]\n",
      "epoch:12 step:11433 [D loss: 0.586643, acc.: 64.06%] [G loss: 0.500951]\n",
      "epoch:12 step:11434 [D loss: 0.502830, acc.: 78.12%] [G loss: 0.526908]\n",
      "epoch:12 step:11435 [D loss: 0.492424, acc.: 70.31%] [G loss: 0.573904]\n",
      "epoch:12 step:11436 [D loss: 0.519007, acc.: 72.66%] [G loss: 0.780718]\n",
      "epoch:12 step:11437 [D loss: 0.537726, acc.: 71.09%] [G loss: 0.629061]\n",
      "epoch:12 step:11438 [D loss: 0.439527, acc.: 79.69%] [G loss: 0.731116]\n",
      "epoch:12 step:11439 [D loss: 0.570930, acc.: 70.31%] [G loss: 0.675101]\n",
      "epoch:12 step:11440 [D loss: 0.563157, acc.: 67.19%] [G loss: 0.686259]\n",
      "epoch:12 step:11441 [D loss: 0.537023, acc.: 68.75%] [G loss: 0.607111]\n",
      "epoch:12 step:11442 [D loss: 0.498290, acc.: 71.88%] [G loss: 0.690811]\n",
      "epoch:12 step:11443 [D loss: 0.485523, acc.: 75.78%] [G loss: 0.823381]\n",
      "epoch:12 step:11444 [D loss: 0.574314, acc.: 67.19%] [G loss: 0.518361]\n",
      "epoch:12 step:11445 [D loss: 0.527204, acc.: 73.44%] [G loss: 0.637526]\n",
      "epoch:12 step:11446 [D loss: 0.520518, acc.: 74.22%] [G loss: 0.583983]\n",
      "epoch:12 step:11447 [D loss: 0.598655, acc.: 67.19%] [G loss: 0.544284]\n",
      "epoch:12 step:11448 [D loss: 0.543427, acc.: 71.88%] [G loss: 0.586665]\n",
      "epoch:12 step:11449 [D loss: 0.527092, acc.: 71.09%] [G loss: 0.728596]\n",
      "epoch:12 step:11450 [D loss: 0.503747, acc.: 70.31%] [G loss: 0.806776]\n",
      "epoch:12 step:11451 [D loss: 0.435098, acc.: 80.47%] [G loss: 0.688989]\n",
      "epoch:12 step:11452 [D loss: 0.452284, acc.: 76.56%] [G loss: 0.774554]\n",
      "epoch:12 step:11453 [D loss: 0.530475, acc.: 75.00%] [G loss: 0.861732]\n",
      "epoch:12 step:11454 [D loss: 0.695860, acc.: 60.94%] [G loss: 0.543102]\n",
      "epoch:12 step:11455 [D loss: 0.587905, acc.: 64.06%] [G loss: 0.484464]\n",
      "epoch:12 step:11456 [D loss: 0.518720, acc.: 74.22%] [G loss: 0.558919]\n",
      "epoch:12 step:11457 [D loss: 0.524028, acc.: 70.31%] [G loss: 0.556869]\n",
      "epoch:12 step:11458 [D loss: 0.607861, acc.: 65.62%] [G loss: 0.628305]\n",
      "epoch:12 step:11459 [D loss: 0.568152, acc.: 65.62%] [G loss: 0.548122]\n",
      "epoch:12 step:11460 [D loss: 0.541417, acc.: 71.88%] [G loss: 0.518870]\n",
      "epoch:12 step:11461 [D loss: 0.480962, acc.: 74.22%] [G loss: 0.600037]\n",
      "epoch:12 step:11462 [D loss: 0.542625, acc.: 72.66%] [G loss: 0.588334]\n",
      "epoch:12 step:11463 [D loss: 0.501548, acc.: 74.22%] [G loss: 0.746827]\n",
      "epoch:12 step:11464 [D loss: 0.730641, acc.: 57.81%] [G loss: 0.657436]\n",
      "epoch:12 step:11465 [D loss: 0.539011, acc.: 70.31%] [G loss: 0.699068]\n",
      "epoch:12 step:11466 [D loss: 0.519973, acc.: 71.09%] [G loss: 0.555792]\n",
      "epoch:12 step:11467 [D loss: 0.478539, acc.: 82.81%] [G loss: 0.725155]\n",
      "epoch:12 step:11468 [D loss: 0.555827, acc.: 71.09%] [G loss: 0.682076]\n",
      "epoch:12 step:11469 [D loss: 0.581582, acc.: 67.19%] [G loss: 0.571245]\n",
      "epoch:12 step:11470 [D loss: 0.658353, acc.: 61.72%] [G loss: 0.538784]\n",
      "epoch:12 step:11471 [D loss: 0.525952, acc.: 72.66%] [G loss: 0.600049]\n",
      "epoch:12 step:11472 [D loss: 0.602024, acc.: 64.84%] [G loss: 0.572748]\n",
      "epoch:12 step:11473 [D loss: 0.526352, acc.: 73.44%] [G loss: 0.575443]\n",
      "epoch:12 step:11474 [D loss: 0.479388, acc.: 77.34%] [G loss: 0.673623]\n",
      "epoch:12 step:11475 [D loss: 0.468951, acc.: 77.34%] [G loss: 0.618337]\n",
      "epoch:12 step:11476 [D loss: 0.467969, acc.: 76.56%] [G loss: 0.879621]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:12 step:11477 [D loss: 0.558577, acc.: 66.41%] [G loss: 0.824620]\n",
      "epoch:12 step:11478 [D loss: 0.555073, acc.: 71.88%] [G loss: 0.674483]\n",
      "epoch:12 step:11479 [D loss: 0.574661, acc.: 65.62%] [G loss: 0.594155]\n",
      "epoch:12 step:11480 [D loss: 0.558450, acc.: 70.31%] [G loss: 0.542758]\n",
      "epoch:12 step:11481 [D loss: 0.531243, acc.: 69.53%] [G loss: 0.729318]\n",
      "epoch:12 step:11482 [D loss: 0.583547, acc.: 64.84%] [G loss: 0.503524]\n",
      "epoch:12 step:11483 [D loss: 0.525628, acc.: 70.31%] [G loss: 0.545925]\n",
      "epoch:12 step:11484 [D loss: 0.512552, acc.: 76.56%] [G loss: 0.666099]\n",
      "epoch:12 step:11485 [D loss: 0.537655, acc.: 68.75%] [G loss: 0.677653]\n",
      "epoch:12 step:11486 [D loss: 0.520766, acc.: 73.44%] [G loss: 0.674188]\n",
      "epoch:12 step:11487 [D loss: 0.509435, acc.: 74.22%] [G loss: 0.692683]\n",
      "epoch:12 step:11488 [D loss: 0.441019, acc.: 77.34%] [G loss: 0.835202]\n",
      "epoch:12 step:11489 [D loss: 0.523812, acc.: 71.88%] [G loss: 0.635085]\n",
      "epoch:12 step:11490 [D loss: 0.519593, acc.: 67.19%] [G loss: 0.736658]\n",
      "epoch:12 step:11491 [D loss: 0.460038, acc.: 78.12%] [G loss: 0.690517]\n",
      "epoch:12 step:11492 [D loss: 0.513212, acc.: 73.44%] [G loss: 0.666079]\n",
      "epoch:12 step:11493 [D loss: 0.545440, acc.: 67.97%] [G loss: 0.635646]\n",
      "epoch:12 step:11494 [D loss: 0.563779, acc.: 67.97%] [G loss: 0.541032]\n",
      "epoch:12 step:11495 [D loss: 0.623071, acc.: 63.28%] [G loss: 0.657344]\n",
      "epoch:12 step:11496 [D loss: 0.576804, acc.: 65.62%] [G loss: 0.533837]\n",
      "epoch:12 step:11497 [D loss: 0.538530, acc.: 75.78%] [G loss: 0.549947]\n",
      "epoch:12 step:11498 [D loss: 0.518694, acc.: 72.66%] [G loss: 0.605827]\n",
      "epoch:12 step:11499 [D loss: 0.563865, acc.: 66.41%] [G loss: 0.544710]\n",
      "epoch:12 step:11500 [D loss: 0.559133, acc.: 67.19%] [G loss: 0.629621]\n",
      "epoch:12 step:11501 [D loss: 0.574131, acc.: 64.06%] [G loss: 0.538330]\n",
      "epoch:12 step:11502 [D loss: 0.497798, acc.: 76.56%] [G loss: 0.634224]\n",
      "epoch:12 step:11503 [D loss: 0.509980, acc.: 73.44%] [G loss: 0.602617]\n",
      "epoch:12 step:11504 [D loss: 0.562401, acc.: 67.97%] [G loss: 0.563101]\n",
      "epoch:12 step:11505 [D loss: 0.522963, acc.: 78.12%] [G loss: 0.642042]\n",
      "epoch:12 step:11506 [D loss: 0.515509, acc.: 73.44%] [G loss: 0.641064]\n",
      "epoch:12 step:11507 [D loss: 0.547501, acc.: 74.22%] [G loss: 0.624240]\n",
      "epoch:12 step:11508 [D loss: 0.576508, acc.: 68.75%] [G loss: 0.686192]\n",
      "epoch:12 step:11509 [D loss: 0.513698, acc.: 71.88%] [G loss: 0.637546]\n",
      "epoch:12 step:11510 [D loss: 0.570518, acc.: 67.97%] [G loss: 0.659971]\n",
      "epoch:12 step:11511 [D loss: 0.519616, acc.: 75.78%] [G loss: 0.581967]\n",
      "epoch:12 step:11512 [D loss: 0.539075, acc.: 67.19%] [G loss: 0.680009]\n",
      "epoch:12 step:11513 [D loss: 0.576443, acc.: 71.09%] [G loss: 0.473170]\n",
      "epoch:12 step:11514 [D loss: 0.499300, acc.: 74.22%] [G loss: 0.551720]\n",
      "epoch:12 step:11515 [D loss: 0.482292, acc.: 72.66%] [G loss: 0.690400]\n",
      "epoch:12 step:11516 [D loss: 0.556489, acc.: 70.31%] [G loss: 0.709781]\n",
      "epoch:12 step:11517 [D loss: 0.532725, acc.: 71.88%] [G loss: 0.517530]\n",
      "epoch:12 step:11518 [D loss: 0.483118, acc.: 75.00%] [G loss: 0.689679]\n",
      "epoch:12 step:11519 [D loss: 0.567861, acc.: 71.88%] [G loss: 0.704225]\n",
      "epoch:12 step:11520 [D loss: 0.441108, acc.: 82.03%] [G loss: 0.698706]\n",
      "epoch:12 step:11521 [D loss: 0.685831, acc.: 59.38%] [G loss: 0.468457]\n",
      "epoch:12 step:11522 [D loss: 0.607870, acc.: 64.06%] [G loss: 0.466407]\n",
      "epoch:12 step:11523 [D loss: 0.533728, acc.: 67.19%] [G loss: 0.526176]\n",
      "epoch:12 step:11524 [D loss: 0.615731, acc.: 65.62%] [G loss: 0.460216]\n",
      "epoch:12 step:11525 [D loss: 0.573521, acc.: 67.97%] [G loss: 0.488909]\n",
      "epoch:12 step:11526 [D loss: 0.522658, acc.: 70.31%] [G loss: 0.610630]\n",
      "epoch:12 step:11527 [D loss: 0.534704, acc.: 71.09%] [G loss: 0.643023]\n",
      "epoch:12 step:11528 [D loss: 0.561982, acc.: 71.09%] [G loss: 0.599724]\n",
      "epoch:12 step:11529 [D loss: 0.454670, acc.: 76.56%] [G loss: 0.689891]\n",
      "epoch:12 step:11530 [D loss: 0.484803, acc.: 74.22%] [G loss: 0.794936]\n",
      "epoch:12 step:11531 [D loss: 0.561571, acc.: 62.50%] [G loss: 0.629496]\n",
      "epoch:12 step:11532 [D loss: 0.546679, acc.: 64.84%] [G loss: 0.673709]\n",
      "epoch:12 step:11533 [D loss: 0.516784, acc.: 75.78%] [G loss: 0.683510]\n",
      "epoch:12 step:11534 [D loss: 0.519289, acc.: 78.12%] [G loss: 0.617940]\n",
      "epoch:12 step:11535 [D loss: 0.591461, acc.: 69.53%] [G loss: 0.517205]\n",
      "epoch:12 step:11536 [D loss: 0.516866, acc.: 71.88%] [G loss: 0.614678]\n",
      "epoch:12 step:11537 [D loss: 0.569676, acc.: 68.75%] [G loss: 0.546072]\n",
      "epoch:12 step:11538 [D loss: 0.543627, acc.: 74.22%] [G loss: 0.498230]\n",
      "epoch:12 step:11539 [D loss: 0.500565, acc.: 76.56%] [G loss: 0.606978]\n",
      "epoch:12 step:11540 [D loss: 0.431782, acc.: 76.56%] [G loss: 0.694948]\n",
      "epoch:12 step:11541 [D loss: 0.507647, acc.: 72.66%] [G loss: 0.677699]\n",
      "epoch:12 step:11542 [D loss: 0.502332, acc.: 74.22%] [G loss: 0.611137]\n",
      "epoch:12 step:11543 [D loss: 0.501028, acc.: 75.78%] [G loss: 0.696714]\n",
      "epoch:12 step:11544 [D loss: 0.535416, acc.: 72.66%] [G loss: 0.726138]\n",
      "epoch:12 step:11545 [D loss: 0.685627, acc.: 57.81%] [G loss: 0.692813]\n",
      "epoch:12 step:11546 [D loss: 0.526638, acc.: 71.88%] [G loss: 0.675730]\n",
      "epoch:12 step:11547 [D loss: 0.517821, acc.: 77.34%] [G loss: 0.560557]\n",
      "epoch:12 step:11548 [D loss: 0.488870, acc.: 73.44%] [G loss: 0.697112]\n",
      "epoch:12 step:11549 [D loss: 0.530411, acc.: 70.31%] [G loss: 0.769923]\n",
      "epoch:12 step:11550 [D loss: 0.493032, acc.: 75.78%] [G loss: 0.686962]\n",
      "epoch:12 step:11551 [D loss: 0.463559, acc.: 75.78%] [G loss: 0.750139]\n",
      "epoch:12 step:11552 [D loss: 0.596807, acc.: 69.53%] [G loss: 0.652176]\n",
      "epoch:12 step:11553 [D loss: 0.466754, acc.: 75.00%] [G loss: 0.649670]\n",
      "epoch:12 step:11554 [D loss: 0.560761, acc.: 69.53%] [G loss: 0.569519]\n",
      "epoch:12 step:11555 [D loss: 0.463988, acc.: 78.91%] [G loss: 0.554502]\n",
      "epoch:12 step:11556 [D loss: 0.525507, acc.: 75.78%] [G loss: 0.810268]\n",
      "epoch:12 step:11557 [D loss: 0.468264, acc.: 78.91%] [G loss: 0.895990]\n",
      "epoch:12 step:11558 [D loss: 0.478306, acc.: 76.56%] [G loss: 0.904596]\n",
      "epoch:12 step:11559 [D loss: 0.467059, acc.: 81.25%] [G loss: 0.901451]\n",
      "epoch:12 step:11560 [D loss: 0.793708, acc.: 57.03%] [G loss: 0.718792]\n",
      "epoch:12 step:11561 [D loss: 0.595303, acc.: 66.41%] [G loss: 0.659399]\n",
      "epoch:12 step:11562 [D loss: 0.543419, acc.: 66.41%] [G loss: 0.632338]\n",
      "epoch:12 step:11563 [D loss: 0.508490, acc.: 72.66%] [G loss: 0.590624]\n",
      "epoch:12 step:11564 [D loss: 0.604225, acc.: 57.03%] [G loss: 0.412130]\n",
      "epoch:12 step:11565 [D loss: 0.485417, acc.: 75.78%] [G loss: 0.576876]\n",
      "epoch:12 step:11566 [D loss: 0.536317, acc.: 71.09%] [G loss: 0.639804]\n",
      "epoch:12 step:11567 [D loss: 0.630127, acc.: 67.97%] [G loss: 0.559610]\n",
      "epoch:12 step:11568 [D loss: 0.560055, acc.: 71.09%] [G loss: 0.502671]\n",
      "epoch:12 step:11569 [D loss: 0.540589, acc.: 73.44%] [G loss: 0.498066]\n",
      "epoch:12 step:11570 [D loss: 0.498378, acc.: 75.00%] [G loss: 0.600800]\n",
      "epoch:12 step:11571 [D loss: 0.531533, acc.: 72.66%] [G loss: 0.639909]\n",
      "epoch:12 step:11572 [D loss: 0.481564, acc.: 76.56%] [G loss: 0.720804]\n",
      "epoch:12 step:11573 [D loss: 0.533515, acc.: 74.22%] [G loss: 0.800043]\n",
      "epoch:12 step:11574 [D loss: 0.562462, acc.: 69.53%] [G loss: 0.560412]\n",
      "epoch:12 step:11575 [D loss: 0.582700, acc.: 67.19%] [G loss: 0.446472]\n",
      "epoch:12 step:11576 [D loss: 0.516252, acc.: 73.44%] [G loss: 0.704205]\n",
      "epoch:12 step:11577 [D loss: 0.481653, acc.: 75.78%] [G loss: 0.560979]\n",
      "epoch:12 step:11578 [D loss: 0.511272, acc.: 75.00%] [G loss: 0.669228]\n",
      "epoch:12 step:11579 [D loss: 0.492331, acc.: 76.56%] [G loss: 0.849930]\n",
      "epoch:12 step:11580 [D loss: 0.500323, acc.: 75.78%] [G loss: 0.848415]\n",
      "epoch:12 step:11581 [D loss: 0.474529, acc.: 76.56%] [G loss: 0.775710]\n",
      "epoch:12 step:11582 [D loss: 0.544004, acc.: 67.19%] [G loss: 0.663569]\n",
      "epoch:12 step:11583 [D loss: 0.519132, acc.: 68.75%] [G loss: 0.678893]\n",
      "epoch:12 step:11584 [D loss: 0.494231, acc.: 75.00%] [G loss: 0.546097]\n",
      "epoch:12 step:11585 [D loss: 0.569152, acc.: 73.44%] [G loss: 0.632376]\n",
      "epoch:12 step:11586 [D loss: 0.647333, acc.: 61.72%] [G loss: 0.645327]\n",
      "epoch:12 step:11587 [D loss: 0.514161, acc.: 69.53%] [G loss: 0.674617]\n",
      "epoch:12 step:11588 [D loss: 0.454950, acc.: 76.56%] [G loss: 1.015782]\n",
      "epoch:12 step:11589 [D loss: 0.585105, acc.: 67.97%] [G loss: 0.855636]\n",
      "epoch:12 step:11590 [D loss: 0.552587, acc.: 71.09%] [G loss: 0.719538]\n",
      "epoch:12 step:11591 [D loss: 0.463803, acc.: 77.34%] [G loss: 0.823209]\n",
      "epoch:12 step:11592 [D loss: 0.621918, acc.: 68.75%] [G loss: 0.612729]\n",
      "epoch:12 step:11593 [D loss: 0.672175, acc.: 60.16%] [G loss: 0.477036]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:12 step:11594 [D loss: 0.512357, acc.: 72.66%] [G loss: 0.585595]\n",
      "epoch:12 step:11595 [D loss: 0.562516, acc.: 71.09%] [G loss: 0.635598]\n",
      "epoch:12 step:11596 [D loss: 0.526990, acc.: 69.53%] [G loss: 0.707908]\n",
      "epoch:12 step:11597 [D loss: 0.521122, acc.: 71.88%] [G loss: 0.598590]\n",
      "epoch:12 step:11598 [D loss: 0.392031, acc.: 84.38%] [G loss: 0.864655]\n",
      "epoch:12 step:11599 [D loss: 0.479654, acc.: 82.03%] [G loss: 0.825424]\n",
      "epoch:12 step:11600 [D loss: 0.553785, acc.: 72.66%] [G loss: 0.709657]\n",
      "epoch:12 step:11601 [D loss: 0.478331, acc.: 75.78%] [G loss: 0.716128]\n",
      "epoch:12 step:11602 [D loss: 0.466347, acc.: 71.09%] [G loss: 0.688577]\n",
      "epoch:12 step:11603 [D loss: 0.491495, acc.: 75.78%] [G loss: 0.709775]\n",
      "epoch:12 step:11604 [D loss: 0.501210, acc.: 73.44%] [G loss: 0.784407]\n",
      "epoch:12 step:11605 [D loss: 0.565237, acc.: 70.31%] [G loss: 0.770336]\n",
      "epoch:12 step:11606 [D loss: 0.557897, acc.: 69.53%] [G loss: 0.760612]\n",
      "epoch:12 step:11607 [D loss: 0.515032, acc.: 74.22%] [G loss: 0.630136]\n",
      "epoch:12 step:11608 [D loss: 0.511312, acc.: 71.88%] [G loss: 0.662684]\n",
      "epoch:12 step:11609 [D loss: 0.573282, acc.: 62.50%] [G loss: 0.641034]\n",
      "epoch:12 step:11610 [D loss: 0.474267, acc.: 76.56%] [G loss: 0.720993]\n",
      "epoch:12 step:11611 [D loss: 0.566537, acc.: 66.41%] [G loss: 0.582922]\n",
      "epoch:12 step:11612 [D loss: 0.547065, acc.: 70.31%] [G loss: 0.766145]\n",
      "epoch:12 step:11613 [D loss: 0.502825, acc.: 72.66%] [G loss: 0.628823]\n",
      "epoch:12 step:11614 [D loss: 0.530482, acc.: 71.88%] [G loss: 0.591141]\n",
      "epoch:12 step:11615 [D loss: 0.511927, acc.: 76.56%] [G loss: 0.706374]\n",
      "epoch:12 step:11616 [D loss: 0.563678, acc.: 68.75%] [G loss: 0.581980]\n",
      "epoch:12 step:11617 [D loss: 0.560634, acc.: 67.19%] [G loss: 0.635720]\n",
      "epoch:12 step:11618 [D loss: 0.457655, acc.: 75.00%] [G loss: 0.664664]\n",
      "epoch:12 step:11619 [D loss: 0.578261, acc.: 70.31%] [G loss: 0.582613]\n",
      "epoch:12 step:11620 [D loss: 0.740744, acc.: 57.81%] [G loss: 0.471789]\n",
      "epoch:12 step:11621 [D loss: 0.579383, acc.: 66.41%] [G loss: 0.524101]\n",
      "epoch:12 step:11622 [D loss: 0.543190, acc.: 73.44%] [G loss: 0.649203]\n",
      "epoch:12 step:11623 [D loss: 0.606122, acc.: 71.09%] [G loss: 0.620225]\n",
      "epoch:12 step:11624 [D loss: 0.584816, acc.: 64.84%] [G loss: 0.483122]\n",
      "epoch:12 step:11625 [D loss: 0.430318, acc.: 84.38%] [G loss: 0.503164]\n",
      "epoch:12 step:11626 [D loss: 0.545157, acc.: 72.66%] [G loss: 0.552101]\n",
      "epoch:12 step:11627 [D loss: 0.533234, acc.: 73.44%] [G loss: 0.558149]\n",
      "epoch:12 step:11628 [D loss: 0.563810, acc.: 66.41%] [G loss: 0.642360]\n",
      "epoch:12 step:11629 [D loss: 0.499215, acc.: 75.00%] [G loss: 0.613328]\n",
      "epoch:12 step:11630 [D loss: 0.636844, acc.: 63.28%] [G loss: 0.537243]\n",
      "epoch:12 step:11631 [D loss: 0.586142, acc.: 67.97%] [G loss: 0.444113]\n",
      "epoch:12 step:11632 [D loss: 0.586212, acc.: 70.31%] [G loss: 0.577593]\n",
      "epoch:12 step:11633 [D loss: 0.519781, acc.: 72.66%] [G loss: 0.613914]\n",
      "epoch:12 step:11634 [D loss: 0.562580, acc.: 67.97%] [G loss: 0.529241]\n",
      "epoch:12 step:11635 [D loss: 0.535760, acc.: 68.75%] [G loss: 0.459110]\n",
      "epoch:12 step:11636 [D loss: 0.496080, acc.: 71.88%] [G loss: 0.524084]\n",
      "epoch:12 step:11637 [D loss: 0.548982, acc.: 71.09%] [G loss: 0.489157]\n",
      "epoch:12 step:11638 [D loss: 0.535721, acc.: 69.53%] [G loss: 0.502338]\n",
      "epoch:12 step:11639 [D loss: 0.510641, acc.: 73.44%] [G loss: 0.590287]\n",
      "epoch:12 step:11640 [D loss: 0.557749, acc.: 67.19%] [G loss: 0.575477]\n",
      "epoch:12 step:11641 [D loss: 0.545124, acc.: 68.75%] [G loss: 0.537946]\n",
      "epoch:12 step:11642 [D loss: 0.486615, acc.: 78.91%] [G loss: 0.591794]\n",
      "epoch:12 step:11643 [D loss: 0.558528, acc.: 72.66%] [G loss: 0.681436]\n",
      "epoch:12 step:11644 [D loss: 0.632999, acc.: 60.94%] [G loss: 0.573966]\n",
      "epoch:12 step:11645 [D loss: 0.658877, acc.: 53.12%] [G loss: 0.470473]\n",
      "epoch:12 step:11646 [D loss: 0.484582, acc.: 71.88%] [G loss: 0.589675]\n",
      "epoch:12 step:11647 [D loss: 0.512081, acc.: 78.91%] [G loss: 0.602609]\n",
      "epoch:12 step:11648 [D loss: 0.599846, acc.: 67.97%] [G loss: 0.547492]\n",
      "epoch:12 step:11649 [D loss: 0.618879, acc.: 64.06%] [G loss: 0.629520]\n",
      "epoch:12 step:11650 [D loss: 0.495918, acc.: 71.88%] [G loss: 0.689142]\n",
      "epoch:12 step:11651 [D loss: 0.609907, acc.: 64.84%] [G loss: 0.742639]\n",
      "epoch:12 step:11652 [D loss: 0.609195, acc.: 67.19%] [G loss: 0.482186]\n",
      "epoch:12 step:11653 [D loss: 0.609684, acc.: 63.28%] [G loss: 0.589489]\n",
      "epoch:12 step:11654 [D loss: 0.560035, acc.: 72.66%] [G loss: 0.549445]\n",
      "epoch:12 step:11655 [D loss: 0.630036, acc.: 58.59%] [G loss: 0.528937]\n",
      "epoch:12 step:11656 [D loss: 0.583852, acc.: 68.75%] [G loss: 0.539676]\n",
      "epoch:12 step:11657 [D loss: 0.503138, acc.: 75.78%] [G loss: 0.471904]\n",
      "epoch:12 step:11658 [D loss: 0.516650, acc.: 68.75%] [G loss: 0.642902]\n",
      "epoch:12 step:11659 [D loss: 0.537579, acc.: 67.97%] [G loss: 0.724262]\n",
      "epoch:12 step:11660 [D loss: 0.467110, acc.: 78.12%] [G loss: 0.703895]\n",
      "epoch:12 step:11661 [D loss: 0.569379, acc.: 72.66%] [G loss: 0.685803]\n",
      "epoch:12 step:11662 [D loss: 0.604403, acc.: 68.75%] [G loss: 0.554433]\n",
      "epoch:12 step:11663 [D loss: 0.559976, acc.: 72.66%] [G loss: 0.619086]\n",
      "epoch:12 step:11664 [D loss: 0.594547, acc.: 64.84%] [G loss: 0.540932]\n",
      "epoch:12 step:11665 [D loss: 0.580655, acc.: 65.62%] [G loss: 0.521572]\n",
      "epoch:12 step:11666 [D loss: 0.559029, acc.: 71.09%] [G loss: 0.620771]\n",
      "epoch:12 step:11667 [D loss: 0.568816, acc.: 60.16%] [G loss: 0.569446]\n",
      "epoch:12 step:11668 [D loss: 0.605872, acc.: 67.97%] [G loss: 0.451468]\n",
      "epoch:12 step:11669 [D loss: 0.507436, acc.: 77.34%] [G loss: 0.677240]\n",
      "epoch:12 step:11670 [D loss: 0.513064, acc.: 69.53%] [G loss: 0.688174]\n",
      "epoch:12 step:11671 [D loss: 0.466292, acc.: 75.00%] [G loss: 0.816296]\n",
      "epoch:12 step:11672 [D loss: 0.556868, acc.: 71.09%] [G loss: 0.699758]\n",
      "epoch:12 step:11673 [D loss: 0.461441, acc.: 81.25%] [G loss: 0.693447]\n",
      "epoch:12 step:11674 [D loss: 0.474587, acc.: 73.44%] [G loss: 0.788358]\n",
      "epoch:12 step:11675 [D loss: 0.551519, acc.: 67.19%] [G loss: 0.776957]\n",
      "epoch:12 step:11676 [D loss: 0.589661, acc.: 67.19%] [G loss: 0.556881]\n",
      "epoch:12 step:11677 [D loss: 0.586106, acc.: 70.31%] [G loss: 0.502295]\n",
      "epoch:12 step:11678 [D loss: 0.531861, acc.: 73.44%] [G loss: 0.611844]\n",
      "epoch:12 step:11679 [D loss: 0.523013, acc.: 75.00%] [G loss: 0.600954]\n",
      "epoch:12 step:11680 [D loss: 0.489198, acc.: 74.22%] [G loss: 0.667235]\n",
      "epoch:12 step:11681 [D loss: 0.685264, acc.: 61.72%] [G loss: 0.573662]\n",
      "epoch:12 step:11682 [D loss: 0.557372, acc.: 69.53%] [G loss: 0.542060]\n",
      "epoch:12 step:11683 [D loss: 0.500021, acc.: 75.00%] [G loss: 0.657606]\n",
      "epoch:12 step:11684 [D loss: 0.498637, acc.: 74.22%] [G loss: 0.821931]\n",
      "epoch:12 step:11685 [D loss: 0.494851, acc.: 71.09%] [G loss: 0.776134]\n",
      "epoch:12 step:11686 [D loss: 0.530218, acc.: 73.44%] [G loss: 0.791921]\n",
      "epoch:12 step:11687 [D loss: 0.495911, acc.: 73.44%] [G loss: 0.707157]\n",
      "epoch:12 step:11688 [D loss: 0.569359, acc.: 71.88%] [G loss: 0.828543]\n",
      "epoch:12 step:11689 [D loss: 0.615644, acc.: 61.72%] [G loss: 0.699211]\n",
      "epoch:12 step:11690 [D loss: 0.493586, acc.: 78.91%] [G loss: 0.660121]\n",
      "epoch:12 step:11691 [D loss: 0.519225, acc.: 68.75%] [G loss: 0.697917]\n",
      "epoch:12 step:11692 [D loss: 0.533792, acc.: 75.00%] [G loss: 0.543994]\n",
      "epoch:12 step:11693 [D loss: 0.536803, acc.: 72.66%] [G loss: 0.658796]\n",
      "epoch:12 step:11694 [D loss: 0.535815, acc.: 74.22%] [G loss: 0.576197]\n",
      "epoch:12 step:11695 [D loss: 0.438827, acc.: 81.25%] [G loss: 0.799660]\n",
      "epoch:12 step:11696 [D loss: 0.486879, acc.: 75.00%] [G loss: 0.724366]\n",
      "epoch:12 step:11697 [D loss: 0.504896, acc.: 76.56%] [G loss: 0.729321]\n",
      "epoch:12 step:11698 [D loss: 0.614564, acc.: 67.19%] [G loss: 0.603778]\n",
      "epoch:12 step:11699 [D loss: 0.492764, acc.: 76.56%] [G loss: 0.752238]\n",
      "epoch:12 step:11700 [D loss: 0.609911, acc.: 64.84%] [G loss: 0.541976]\n",
      "epoch:12 step:11701 [D loss: 0.481849, acc.: 74.22%] [G loss: 0.601150]\n",
      "epoch:12 step:11702 [D loss: 0.574799, acc.: 71.09%] [G loss: 0.674069]\n",
      "epoch:12 step:11703 [D loss: 0.582660, acc.: 65.62%] [G loss: 0.601077]\n",
      "epoch:12 step:11704 [D loss: 0.554249, acc.: 71.09%] [G loss: 0.598515]\n",
      "epoch:12 step:11705 [D loss: 0.495321, acc.: 75.00%] [G loss: 0.780668]\n",
      "epoch:12 step:11706 [D loss: 0.583818, acc.: 63.28%] [G loss: 0.665806]\n",
      "epoch:12 step:11707 [D loss: 0.576627, acc.: 67.97%] [G loss: 0.533295]\n",
      "epoch:12 step:11708 [D loss: 0.558982, acc.: 73.44%] [G loss: 0.649593]\n",
      "epoch:12 step:11709 [D loss: 0.689853, acc.: 54.69%] [G loss: 0.401175]\n",
      "epoch:12 step:11710 [D loss: 0.528637, acc.: 68.75%] [G loss: 0.716736]\n",
      "epoch:12 step:11711 [D loss: 0.536099, acc.: 72.66%] [G loss: 0.726365]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:12 step:11712 [D loss: 0.543675, acc.: 67.19%] [G loss: 0.665149]\n",
      "epoch:12 step:11713 [D loss: 0.540968, acc.: 74.22%] [G loss: 0.684348]\n",
      "epoch:12 step:11714 [D loss: 0.553927, acc.: 75.78%] [G loss: 0.604280]\n",
      "epoch:12 step:11715 [D loss: 0.467753, acc.: 78.12%] [G loss: 0.605996]\n",
      "epoch:12 step:11716 [D loss: 0.481266, acc.: 78.12%] [G loss: 0.861549]\n",
      "epoch:12 step:11717 [D loss: 0.677504, acc.: 60.94%] [G loss: 0.672091]\n",
      "epoch:12 step:11718 [D loss: 0.585182, acc.: 60.94%] [G loss: 0.597269]\n",
      "epoch:12 step:11719 [D loss: 0.455786, acc.: 81.25%] [G loss: 0.673310]\n",
      "epoch:12 step:11720 [D loss: 0.567578, acc.: 72.66%] [G loss: 0.644747]\n",
      "epoch:12 step:11721 [D loss: 0.602453, acc.: 69.53%] [G loss: 0.493589]\n",
      "epoch:12 step:11722 [D loss: 0.521773, acc.: 75.00%] [G loss: 0.482549]\n",
      "epoch:12 step:11723 [D loss: 0.553380, acc.: 68.75%] [G loss: 0.432274]\n",
      "epoch:12 step:11724 [D loss: 0.572991, acc.: 66.41%] [G loss: 0.363795]\n",
      "epoch:12 step:11725 [D loss: 0.521832, acc.: 76.56%] [G loss: 0.490539]\n",
      "epoch:12 step:11726 [D loss: 0.569216, acc.: 68.75%] [G loss: 0.505486]\n",
      "epoch:12 step:11727 [D loss: 0.582253, acc.: 67.97%] [G loss: 0.542193]\n",
      "epoch:12 step:11728 [D loss: 0.523221, acc.: 76.56%] [G loss: 0.640091]\n",
      "epoch:12 step:11729 [D loss: 0.557223, acc.: 71.88%] [G loss: 0.821813]\n",
      "epoch:12 step:11730 [D loss: 0.545211, acc.: 68.75%] [G loss: 0.670006]\n",
      "epoch:12 step:11731 [D loss: 0.604315, acc.: 67.97%] [G loss: 0.591266]\n",
      "epoch:12 step:11732 [D loss: 0.458857, acc.: 73.44%] [G loss: 0.654648]\n",
      "epoch:12 step:11733 [D loss: 0.557968, acc.: 68.75%] [G loss: 0.528773]\n",
      "epoch:12 step:11734 [D loss: 0.553190, acc.: 67.97%] [G loss: 0.635962]\n",
      "epoch:12 step:11735 [D loss: 0.532401, acc.: 70.31%] [G loss: 0.546003]\n",
      "epoch:12 step:11736 [D loss: 0.542186, acc.: 71.09%] [G loss: 0.449087]\n",
      "epoch:12 step:11737 [D loss: 0.587989, acc.: 62.50%] [G loss: 0.432608]\n",
      "epoch:12 step:11738 [D loss: 0.560596, acc.: 70.31%] [G loss: 0.578139]\n",
      "epoch:12 step:11739 [D loss: 0.505898, acc.: 73.44%] [G loss: 0.539446]\n",
      "epoch:12 step:11740 [D loss: 0.562795, acc.: 70.31%] [G loss: 0.521332]\n",
      "epoch:12 step:11741 [D loss: 0.599121, acc.: 64.84%] [G loss: 0.653594]\n",
      "epoch:12 step:11742 [D loss: 0.533828, acc.: 70.31%] [G loss: 0.725055]\n",
      "epoch:12 step:11743 [D loss: 0.501432, acc.: 76.56%] [G loss: 0.821467]\n",
      "epoch:12 step:11744 [D loss: 0.594319, acc.: 63.28%] [G loss: 0.617337]\n",
      "epoch:12 step:11745 [D loss: 0.649835, acc.: 62.50%] [G loss: 0.508975]\n",
      "epoch:12 step:11746 [D loss: 0.595074, acc.: 60.94%] [G loss: 0.433831]\n",
      "epoch:12 step:11747 [D loss: 0.548863, acc.: 67.19%] [G loss: 0.507859]\n",
      "epoch:12 step:11748 [D loss: 0.455338, acc.: 79.69%] [G loss: 0.756445]\n",
      "epoch:12 step:11749 [D loss: 0.536126, acc.: 74.22%] [G loss: 0.688466]\n",
      "epoch:12 step:11750 [D loss: 0.493830, acc.: 75.00%] [G loss: 0.813500]\n",
      "epoch:12 step:11751 [D loss: 0.475226, acc.: 78.91%] [G loss: 0.801031]\n",
      "epoch:12 step:11752 [D loss: 0.439254, acc.: 78.12%] [G loss: 0.774779]\n",
      "epoch:12 step:11753 [D loss: 0.600545, acc.: 65.62%] [G loss: 0.576956]\n",
      "epoch:12 step:11754 [D loss: 0.598417, acc.: 64.84%] [G loss: 0.560268]\n",
      "epoch:12 step:11755 [D loss: 0.634408, acc.: 62.50%] [G loss: 0.526366]\n",
      "epoch:12 step:11756 [D loss: 0.559243, acc.: 71.09%] [G loss: 0.527702]\n",
      "epoch:12 step:11757 [D loss: 0.571150, acc.: 68.75%] [G loss: 0.615689]\n",
      "epoch:12 step:11758 [D loss: 0.512467, acc.: 68.75%] [G loss: 0.699094]\n",
      "epoch:12 step:11759 [D loss: 0.522922, acc.: 73.44%] [G loss: 0.659741]\n",
      "epoch:12 step:11760 [D loss: 0.471900, acc.: 77.34%] [G loss: 0.812265]\n",
      "epoch:12 step:11761 [D loss: 0.556970, acc.: 69.53%] [G loss: 0.704896]\n",
      "epoch:12 step:11762 [D loss: 0.555493, acc.: 67.19%] [G loss: 0.599604]\n",
      "epoch:12 step:11763 [D loss: 0.445136, acc.: 82.03%] [G loss: 0.764300]\n",
      "epoch:12 step:11764 [D loss: 0.471464, acc.: 79.69%] [G loss: 0.632791]\n",
      "epoch:12 step:11765 [D loss: 0.551990, acc.: 71.09%] [G loss: 0.662429]\n",
      "epoch:12 step:11766 [D loss: 0.503527, acc.: 73.44%] [G loss: 0.818696]\n",
      "epoch:12 step:11767 [D loss: 0.468590, acc.: 78.91%] [G loss: 0.675484]\n",
      "epoch:12 step:11768 [D loss: 0.511541, acc.: 73.44%] [G loss: 0.690619]\n",
      "epoch:12 step:11769 [D loss: 0.603409, acc.: 66.41%] [G loss: 0.464501]\n",
      "epoch:12 step:11770 [D loss: 0.492553, acc.: 78.12%] [G loss: 0.669068]\n",
      "epoch:12 step:11771 [D loss: 0.523890, acc.: 73.44%] [G loss: 0.671853]\n",
      "epoch:12 step:11772 [D loss: 0.633564, acc.: 61.72%] [G loss: 0.735324]\n",
      "epoch:12 step:11773 [D loss: 0.605216, acc.: 69.53%] [G loss: 0.604673]\n",
      "epoch:12 step:11774 [D loss: 0.549729, acc.: 67.19%] [G loss: 0.698570]\n",
      "epoch:12 step:11775 [D loss: 0.620169, acc.: 63.28%] [G loss: 0.556963]\n",
      "epoch:12 step:11776 [D loss: 0.557380, acc.: 72.66%] [G loss: 0.537244]\n",
      "epoch:12 step:11777 [D loss: 0.538366, acc.: 69.53%] [G loss: 0.474309]\n",
      "epoch:12 step:11778 [D loss: 0.469204, acc.: 76.56%] [G loss: 0.773699]\n",
      "epoch:12 step:11779 [D loss: 0.621739, acc.: 63.28%] [G loss: 0.435422]\n",
      "epoch:12 step:11780 [D loss: 0.502655, acc.: 72.66%] [G loss: 0.572673]\n",
      "epoch:12 step:11781 [D loss: 0.573179, acc.: 73.44%] [G loss: 0.534490]\n",
      "epoch:12 step:11782 [D loss: 0.564530, acc.: 68.75%] [G loss: 0.616773]\n",
      "epoch:12 step:11783 [D loss: 0.572521, acc.: 67.19%] [G loss: 0.529018]\n",
      "epoch:12 step:11784 [D loss: 0.546164, acc.: 69.53%] [G loss: 0.628703]\n",
      "epoch:12 step:11785 [D loss: 0.539426, acc.: 64.84%] [G loss: 0.554875]\n",
      "epoch:12 step:11786 [D loss: 0.594916, acc.: 68.75%] [G loss: 0.519807]\n",
      "epoch:12 step:11787 [D loss: 0.577165, acc.: 67.19%] [G loss: 0.616159]\n",
      "epoch:12 step:11788 [D loss: 0.538232, acc.: 72.66%] [G loss: 0.589223]\n",
      "epoch:12 step:11789 [D loss: 0.603223, acc.: 65.62%] [G loss: 0.682874]\n",
      "epoch:12 step:11790 [D loss: 0.453739, acc.: 78.91%] [G loss: 0.680866]\n",
      "epoch:12 step:11791 [D loss: 0.585443, acc.: 63.28%] [G loss: 0.573375]\n",
      "epoch:12 step:11792 [D loss: 0.464455, acc.: 77.34%] [G loss: 0.712058]\n",
      "epoch:12 step:11793 [D loss: 0.500579, acc.: 78.91%] [G loss: 0.611685]\n",
      "epoch:12 step:11794 [D loss: 0.540514, acc.: 71.88%] [G loss: 0.597814]\n",
      "epoch:12 step:11795 [D loss: 0.451857, acc.: 82.03%] [G loss: 0.640858]\n",
      "epoch:12 step:11796 [D loss: 0.472979, acc.: 76.56%] [G loss: 0.612561]\n",
      "epoch:12 step:11797 [D loss: 0.573916, acc.: 67.19%] [G loss: 0.657602]\n",
      "epoch:12 step:11798 [D loss: 0.405778, acc.: 82.03%] [G loss: 0.717100]\n",
      "epoch:12 step:11799 [D loss: 0.505999, acc.: 74.22%] [G loss: 0.755754]\n",
      "epoch:12 step:11800 [D loss: 0.517315, acc.: 73.44%] [G loss: 0.656333]\n",
      "epoch:12 step:11801 [D loss: 0.496786, acc.: 77.34%] [G loss: 0.597007]\n",
      "epoch:12 step:11802 [D loss: 0.472219, acc.: 78.91%] [G loss: 0.722213]\n",
      "epoch:12 step:11803 [D loss: 0.626944, acc.: 66.41%] [G loss: 0.608609]\n",
      "epoch:12 step:11804 [D loss: 0.553829, acc.: 71.09%] [G loss: 0.612043]\n",
      "epoch:12 step:11805 [D loss: 0.529496, acc.: 71.09%] [G loss: 0.738126]\n",
      "epoch:12 step:11806 [D loss: 0.584778, acc.: 67.97%] [G loss: 0.632561]\n",
      "epoch:12 step:11807 [D loss: 0.524218, acc.: 72.66%] [G loss: 0.630810]\n",
      "epoch:12 step:11808 [D loss: 0.509848, acc.: 72.66%] [G loss: 0.845730]\n",
      "epoch:12 step:11809 [D loss: 0.560152, acc.: 71.09%] [G loss: 0.753248]\n",
      "epoch:12 step:11810 [D loss: 0.706464, acc.: 66.41%] [G loss: 0.599020]\n",
      "epoch:12 step:11811 [D loss: 0.475653, acc.: 82.03%] [G loss: 0.613112]\n",
      "epoch:12 step:11812 [D loss: 0.492826, acc.: 72.66%] [G loss: 0.648103]\n",
      "epoch:12 step:11813 [D loss: 0.543653, acc.: 72.66%] [G loss: 0.695986]\n",
      "epoch:12 step:11814 [D loss: 0.516101, acc.: 74.22%] [G loss: 0.690876]\n",
      "epoch:12 step:11815 [D loss: 0.545318, acc.: 72.66%] [G loss: 0.603850]\n",
      "epoch:12 step:11816 [D loss: 0.502351, acc.: 75.78%] [G loss: 0.701508]\n",
      "epoch:12 step:11817 [D loss: 0.526761, acc.: 72.66%] [G loss: 0.732703]\n",
      "epoch:12 step:11818 [D loss: 0.485295, acc.: 72.66%] [G loss: 0.767323]\n",
      "epoch:12 step:11819 [D loss: 0.489438, acc.: 74.22%] [G loss: 0.762143]\n",
      "epoch:12 step:11820 [D loss: 0.607541, acc.: 69.53%] [G loss: 0.616618]\n",
      "epoch:12 step:11821 [D loss: 0.541695, acc.: 71.88%] [G loss: 0.663612]\n",
      "epoch:12 step:11822 [D loss: 0.540912, acc.: 73.44%] [G loss: 0.622376]\n",
      "epoch:12 step:11823 [D loss: 0.506399, acc.: 73.44%] [G loss: 0.660198]\n",
      "epoch:12 step:11824 [D loss: 0.562380, acc.: 71.88%] [G loss: 0.602544]\n",
      "epoch:12 step:11825 [D loss: 0.564500, acc.: 71.09%] [G loss: 0.619597]\n",
      "epoch:12 step:11826 [D loss: 0.464009, acc.: 78.12%] [G loss: 0.648960]\n",
      "epoch:12 step:11827 [D loss: 0.565795, acc.: 66.41%] [G loss: 0.626103]\n",
      "epoch:12 step:11828 [D loss: 0.591272, acc.: 63.28%] [G loss: 0.530561]\n",
      "epoch:12 step:11829 [D loss: 0.502739, acc.: 68.75%] [G loss: 0.526650]\n",
      "epoch:12 step:11830 [D loss: 0.546765, acc.: 70.31%] [G loss: 0.532348]\n",
      "epoch:12 step:11831 [D loss: 0.558541, acc.: 67.19%] [G loss: 0.477836]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:12 step:11832 [D loss: 0.553485, acc.: 67.19%] [G loss: 0.494212]\n",
      "epoch:12 step:11833 [D loss: 0.504454, acc.: 75.78%] [G loss: 0.624886]\n",
      "epoch:12 step:11834 [D loss: 0.515999, acc.: 73.44%] [G loss: 0.605495]\n",
      "epoch:12 step:11835 [D loss: 0.630333, acc.: 63.28%] [G loss: 0.500337]\n",
      "epoch:12 step:11836 [D loss: 0.461842, acc.: 78.91%] [G loss: 0.671264]\n",
      "epoch:12 step:11837 [D loss: 0.535999, acc.: 70.31%] [G loss: 0.583857]\n",
      "epoch:12 step:11838 [D loss: 0.545275, acc.: 69.53%] [G loss: 0.538888]\n",
      "epoch:12 step:11839 [D loss: 0.493786, acc.: 79.69%] [G loss: 0.631069]\n",
      "epoch:12 step:11840 [D loss: 0.511353, acc.: 70.31%] [G loss: 0.627030]\n",
      "epoch:12 step:11841 [D loss: 0.501288, acc.: 75.78%] [G loss: 0.621358]\n",
      "epoch:12 step:11842 [D loss: 0.507390, acc.: 77.34%] [G loss: 0.666063]\n",
      "epoch:12 step:11843 [D loss: 0.528538, acc.: 71.88%] [G loss: 0.771270]\n",
      "epoch:12 step:11844 [D loss: 0.567871, acc.: 66.41%] [G loss: 0.549981]\n",
      "epoch:12 step:11845 [D loss: 0.496513, acc.: 73.44%] [G loss: 0.588324]\n",
      "epoch:12 step:11846 [D loss: 0.473565, acc.: 76.56%] [G loss: 0.672109]\n",
      "epoch:12 step:11847 [D loss: 0.472385, acc.: 75.00%] [G loss: 0.666687]\n",
      "epoch:12 step:11848 [D loss: 0.590376, acc.: 69.53%] [G loss: 0.571769]\n",
      "epoch:12 step:11849 [D loss: 0.464342, acc.: 75.78%] [G loss: 0.795845]\n",
      "epoch:12 step:11850 [D loss: 0.571956, acc.: 64.84%] [G loss: 0.618630]\n",
      "epoch:12 step:11851 [D loss: 0.554839, acc.: 75.00%] [G loss: 0.732482]\n",
      "epoch:12 step:11852 [D loss: 0.531930, acc.: 69.53%] [G loss: 0.533111]\n",
      "epoch:12 step:11853 [D loss: 0.508725, acc.: 75.78%] [G loss: 0.599486]\n",
      "epoch:12 step:11854 [D loss: 0.535016, acc.: 73.44%] [G loss: 0.553372]\n",
      "epoch:12 step:11855 [D loss: 0.564590, acc.: 65.62%] [G loss: 0.458876]\n",
      "epoch:12 step:11856 [D loss: 0.532214, acc.: 73.44%] [G loss: 0.554695]\n",
      "epoch:12 step:11857 [D loss: 0.483865, acc.: 73.44%] [G loss: 0.458464]\n",
      "epoch:12 step:11858 [D loss: 0.552063, acc.: 67.19%] [G loss: 0.493206]\n",
      "epoch:12 step:11859 [D loss: 0.590921, acc.: 62.50%] [G loss: 0.583581]\n",
      "epoch:12 step:11860 [D loss: 0.552333, acc.: 69.53%] [G loss: 0.537916]\n",
      "epoch:12 step:11861 [D loss: 0.486714, acc.: 77.34%] [G loss: 0.578927]\n",
      "epoch:12 step:11862 [D loss: 0.532673, acc.: 73.44%] [G loss: 0.511757]\n",
      "epoch:12 step:11863 [D loss: 0.516708, acc.: 67.19%] [G loss: 0.598299]\n",
      "epoch:12 step:11864 [D loss: 0.545499, acc.: 71.09%] [G loss: 0.594549]\n",
      "epoch:12 step:11865 [D loss: 0.548182, acc.: 71.88%] [G loss: 0.624523]\n",
      "epoch:12 step:11866 [D loss: 0.602004, acc.: 66.41%] [G loss: 0.540816]\n",
      "epoch:12 step:11867 [D loss: 0.464878, acc.: 76.56%] [G loss: 0.600269]\n",
      "epoch:12 step:11868 [D loss: 0.492511, acc.: 76.56%] [G loss: 0.797840]\n",
      "epoch:12 step:11869 [D loss: 0.597081, acc.: 66.41%] [G loss: 0.610636]\n",
      "epoch:12 step:11870 [D loss: 0.572885, acc.: 60.94%] [G loss: 0.574793]\n",
      "epoch:12 step:11871 [D loss: 0.521394, acc.: 68.75%] [G loss: 0.567733]\n",
      "epoch:12 step:11872 [D loss: 0.555442, acc.: 71.88%] [G loss: 0.614895]\n",
      "epoch:12 step:11873 [D loss: 0.532589, acc.: 71.09%] [G loss: 0.603790]\n",
      "epoch:12 step:11874 [D loss: 0.540721, acc.: 68.75%] [G loss: 0.686896]\n",
      "epoch:12 step:11875 [D loss: 0.453330, acc.: 78.91%] [G loss: 0.729172]\n",
      "epoch:12 step:11876 [D loss: 0.495509, acc.: 74.22%] [G loss: 0.713172]\n",
      "epoch:12 step:11877 [D loss: 0.508316, acc.: 72.66%] [G loss: 0.689930]\n",
      "epoch:12 step:11878 [D loss: 0.475111, acc.: 78.12%] [G loss: 0.653570]\n",
      "epoch:12 step:11879 [D loss: 0.486248, acc.: 77.34%] [G loss: 0.814998]\n",
      "epoch:12 step:11880 [D loss: 0.560892, acc.: 70.31%] [G loss: 0.587561]\n",
      "epoch:12 step:11881 [D loss: 0.488137, acc.: 75.78%] [G loss: 0.604512]\n",
      "epoch:12 step:11882 [D loss: 0.505718, acc.: 74.22%] [G loss: 0.619341]\n",
      "epoch:12 step:11883 [D loss: 0.514174, acc.: 74.22%] [G loss: 0.530468]\n",
      "epoch:12 step:11884 [D loss: 0.576819, acc.: 66.41%] [G loss: 0.622888]\n",
      "epoch:12 step:11885 [D loss: 0.465845, acc.: 78.91%] [G loss: 0.614171]\n",
      "epoch:12 step:11886 [D loss: 0.451646, acc.: 79.69%] [G loss: 0.808871]\n",
      "epoch:12 step:11887 [D loss: 0.553629, acc.: 64.06%] [G loss: 0.751071]\n",
      "epoch:12 step:11888 [D loss: 0.549479, acc.: 69.53%] [G loss: 0.731956]\n",
      "epoch:12 step:11889 [D loss: 0.537595, acc.: 69.53%] [G loss: 0.625082]\n",
      "epoch:12 step:11890 [D loss: 0.537405, acc.: 72.66%] [G loss: 0.588156]\n",
      "epoch:12 step:11891 [D loss: 0.469749, acc.: 75.78%] [G loss: 0.656839]\n",
      "epoch:12 step:11892 [D loss: 0.407236, acc.: 83.59%] [G loss: 0.861066]\n",
      "epoch:12 step:11893 [D loss: 0.496966, acc.: 75.78%] [G loss: 0.891986]\n",
      "epoch:12 step:11894 [D loss: 0.527916, acc.: 71.09%] [G loss: 0.727903]\n",
      "epoch:12 step:11895 [D loss: 0.560215, acc.: 69.53%] [G loss: 0.770133]\n",
      "epoch:12 step:11896 [D loss: 0.561630, acc.: 70.31%] [G loss: 0.697420]\n",
      "epoch:12 step:11897 [D loss: 0.577094, acc.: 69.53%] [G loss: 0.516968]\n",
      "epoch:12 step:11898 [D loss: 0.516124, acc.: 69.53%] [G loss: 0.577664]\n",
      "epoch:12 step:11899 [D loss: 0.574577, acc.: 69.53%] [G loss: 0.664860]\n",
      "epoch:12 step:11900 [D loss: 0.518579, acc.: 72.66%] [G loss: 0.639530]\n",
      "epoch:12 step:11901 [D loss: 0.536622, acc.: 70.31%] [G loss: 0.596442]\n",
      "epoch:12 step:11902 [D loss: 0.559638, acc.: 66.41%] [G loss: 0.783646]\n",
      "epoch:12 step:11903 [D loss: 0.528053, acc.: 72.66%] [G loss: 0.642724]\n",
      "epoch:12 step:11904 [D loss: 0.505425, acc.: 71.88%] [G loss: 0.548053]\n",
      "epoch:12 step:11905 [D loss: 0.477317, acc.: 75.00%] [G loss: 0.735239]\n",
      "epoch:12 step:11906 [D loss: 0.549145, acc.: 71.09%] [G loss: 0.683389]\n",
      "epoch:12 step:11907 [D loss: 0.529812, acc.: 70.31%] [G loss: 0.602665]\n",
      "epoch:12 step:11908 [D loss: 0.487854, acc.: 75.78%] [G loss: 0.803949]\n",
      "epoch:12 step:11909 [D loss: 0.611060, acc.: 67.19%] [G loss: 0.680803]\n",
      "epoch:12 step:11910 [D loss: 0.547888, acc.: 73.44%] [G loss: 0.785416]\n",
      "epoch:12 step:11911 [D loss: 0.558516, acc.: 73.44%] [G loss: 0.863349]\n",
      "epoch:12 step:11912 [D loss: 0.527700, acc.: 74.22%] [G loss: 0.490292]\n",
      "epoch:12 step:11913 [D loss: 0.499273, acc.: 77.34%] [G loss: 0.788093]\n",
      "epoch:12 step:11914 [D loss: 0.588451, acc.: 65.62%] [G loss: 0.529268]\n",
      "epoch:12 step:11915 [D loss: 0.521253, acc.: 73.44%] [G loss: 0.595844]\n",
      "epoch:12 step:11916 [D loss: 0.686873, acc.: 63.28%] [G loss: 0.611017]\n",
      "epoch:12 step:11917 [D loss: 0.615110, acc.: 60.94%] [G loss: 0.560373]\n",
      "epoch:12 step:11918 [D loss: 0.503397, acc.: 71.88%] [G loss: 0.777031]\n",
      "epoch:12 step:11919 [D loss: 0.587923, acc.: 64.84%] [G loss: 0.632769]\n",
      "epoch:12 step:11920 [D loss: 0.553881, acc.: 67.97%] [G loss: 0.787503]\n",
      "epoch:12 step:11921 [D loss: 0.495006, acc.: 75.00%] [G loss: 0.754879]\n",
      "epoch:12 step:11922 [D loss: 0.581040, acc.: 67.97%] [G loss: 0.619098]\n",
      "epoch:12 step:11923 [D loss: 0.571537, acc.: 68.75%] [G loss: 0.645288]\n",
      "epoch:12 step:11924 [D loss: 0.506424, acc.: 74.22%] [G loss: 0.682161]\n",
      "epoch:12 step:11925 [D loss: 0.473600, acc.: 78.12%] [G loss: 0.653066]\n",
      "epoch:12 step:11926 [D loss: 0.546854, acc.: 69.53%] [G loss: 0.633751]\n",
      "epoch:12 step:11927 [D loss: 0.524464, acc.: 70.31%] [G loss: 0.582388]\n",
      "epoch:12 step:11928 [D loss: 0.549355, acc.: 71.09%] [G loss: 0.466206]\n",
      "epoch:12 step:11929 [D loss: 0.543412, acc.: 67.97%] [G loss: 0.444283]\n",
      "epoch:12 step:11930 [D loss: 0.562758, acc.: 68.75%] [G loss: 0.451580]\n",
      "epoch:12 step:11931 [D loss: 0.549650, acc.: 67.19%] [G loss: 0.507546]\n",
      "epoch:12 step:11932 [D loss: 0.502999, acc.: 75.78%] [G loss: 0.628247]\n",
      "epoch:12 step:11933 [D loss: 0.571063, acc.: 67.97%] [G loss: 0.531783]\n",
      "epoch:12 step:11934 [D loss: 0.495312, acc.: 74.22%] [G loss: 0.629107]\n",
      "epoch:12 step:11935 [D loss: 0.459416, acc.: 78.91%] [G loss: 0.704570]\n",
      "epoch:12 step:11936 [D loss: 0.500822, acc.: 74.22%] [G loss: 0.557412]\n",
      "epoch:12 step:11937 [D loss: 0.483053, acc.: 75.78%] [G loss: 0.562852]\n",
      "epoch:12 step:11938 [D loss: 0.474351, acc.: 77.34%] [G loss: 0.863097]\n",
      "epoch:12 step:11939 [D loss: 0.536308, acc.: 73.44%] [G loss: 0.760641]\n",
      "epoch:12 step:11940 [D loss: 0.622687, acc.: 61.72%] [G loss: 0.458670]\n",
      "epoch:12 step:11941 [D loss: 0.567601, acc.: 67.19%] [G loss: 0.624736]\n",
      "epoch:12 step:11942 [D loss: 0.595822, acc.: 63.28%] [G loss: 0.564627]\n",
      "epoch:12 step:11943 [D loss: 0.525324, acc.: 75.78%] [G loss: 0.628142]\n",
      "epoch:12 step:11944 [D loss: 0.549885, acc.: 69.53%] [G loss: 0.688103]\n",
      "epoch:12 step:11945 [D loss: 0.485758, acc.: 78.12%] [G loss: 0.655447]\n",
      "epoch:12 step:11946 [D loss: 0.567251, acc.: 68.75%] [G loss: 0.547750]\n",
      "epoch:12 step:11947 [D loss: 0.516480, acc.: 72.66%] [G loss: 0.553636]\n",
      "epoch:12 step:11948 [D loss: 0.620476, acc.: 62.50%] [G loss: 0.639568]\n",
      "epoch:12 step:11949 [D loss: 0.566696, acc.: 70.31%] [G loss: 0.635487]\n",
      "epoch:12 step:11950 [D loss: 0.534104, acc.: 71.88%] [G loss: 0.517835]\n",
      "epoch:12 step:11951 [D loss: 0.524491, acc.: 72.66%] [G loss: 0.577145]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:12 step:11952 [D loss: 0.497296, acc.: 76.56%] [G loss: 0.699435]\n",
      "epoch:12 step:11953 [D loss: 0.567142, acc.: 67.19%] [G loss: 0.592268]\n",
      "epoch:12 step:11954 [D loss: 0.612509, acc.: 65.62%] [G loss: 0.564284]\n",
      "epoch:12 step:11955 [D loss: 0.564956, acc.: 68.75%] [G loss: 0.689749]\n",
      "epoch:12 step:11956 [D loss: 0.525081, acc.: 71.09%] [G loss: 0.803388]\n",
      "epoch:12 step:11957 [D loss: 0.657769, acc.: 60.16%] [G loss: 0.499802]\n",
      "epoch:12 step:11958 [D loss: 0.542072, acc.: 65.62%] [G loss: 0.685106]\n",
      "epoch:12 step:11959 [D loss: 0.601780, acc.: 60.94%] [G loss: 0.438935]\n",
      "epoch:12 step:11960 [D loss: 0.620620, acc.: 67.19%] [G loss: 0.558662]\n",
      "epoch:12 step:11961 [D loss: 0.575617, acc.: 69.53%] [G loss: 0.578845]\n",
      "epoch:12 step:11962 [D loss: 0.546236, acc.: 68.75%] [G loss: 0.471641]\n",
      "epoch:12 step:11963 [D loss: 0.507127, acc.: 75.78%] [G loss: 0.751286]\n",
      "epoch:12 step:11964 [D loss: 0.623033, acc.: 62.50%] [G loss: 0.587262]\n",
      "epoch:12 step:11965 [D loss: 0.539331, acc.: 69.53%] [G loss: 0.644880]\n",
      "epoch:12 step:11966 [D loss: 0.540912, acc.: 71.88%] [G loss: 0.599555]\n",
      "epoch:12 step:11967 [D loss: 0.555298, acc.: 73.44%] [G loss: 0.498854]\n",
      "epoch:12 step:11968 [D loss: 0.513934, acc.: 78.12%] [G loss: 0.570535]\n",
      "epoch:12 step:11969 [D loss: 0.534940, acc.: 70.31%] [G loss: 0.754764]\n",
      "epoch:12 step:11970 [D loss: 0.498453, acc.: 78.91%] [G loss: 0.743142]\n",
      "epoch:12 step:11971 [D loss: 0.578098, acc.: 65.62%] [G loss: 0.512969]\n",
      "epoch:12 step:11972 [D loss: 0.583379, acc.: 67.97%] [G loss: 0.496397]\n",
      "epoch:12 step:11973 [D loss: 0.595842, acc.: 67.19%] [G loss: 0.526485]\n",
      "epoch:12 step:11974 [D loss: 0.540630, acc.: 73.44%] [G loss: 0.611178]\n",
      "epoch:12 step:11975 [D loss: 0.582838, acc.: 65.62%] [G loss: 0.523902]\n",
      "epoch:12 step:11976 [D loss: 0.535935, acc.: 71.09%] [G loss: 0.561278]\n",
      "epoch:12 step:11977 [D loss: 0.530166, acc.: 71.88%] [G loss: 0.611434]\n",
      "epoch:12 step:11978 [D loss: 0.554721, acc.: 67.97%] [G loss: 0.619590]\n",
      "epoch:12 step:11979 [D loss: 0.532343, acc.: 70.31%] [G loss: 0.531426]\n",
      "epoch:12 step:11980 [D loss: 0.478257, acc.: 75.00%] [G loss: 0.679322]\n",
      "epoch:12 step:11981 [D loss: 0.570988, acc.: 66.41%] [G loss: 0.546354]\n",
      "epoch:12 step:11982 [D loss: 0.556099, acc.: 68.75%] [G loss: 0.501561]\n",
      "epoch:12 step:11983 [D loss: 0.597389, acc.: 66.41%] [G loss: 0.542006]\n",
      "epoch:12 step:11984 [D loss: 0.650325, acc.: 62.50%] [G loss: 0.465317]\n",
      "epoch:12 step:11985 [D loss: 0.539954, acc.: 72.66%] [G loss: 0.480779]\n",
      "epoch:12 step:11986 [D loss: 0.517016, acc.: 75.00%] [G loss: 0.713796]\n",
      "epoch:12 step:11987 [D loss: 0.493035, acc.: 75.78%] [G loss: 0.619001]\n",
      "epoch:12 step:11988 [D loss: 0.516898, acc.: 78.12%] [G loss: 0.655772]\n",
      "epoch:12 step:11989 [D loss: 0.607435, acc.: 65.62%] [G loss: 0.667928]\n",
      "epoch:12 step:11990 [D loss: 0.505126, acc.: 71.88%] [G loss: 0.650203]\n",
      "epoch:12 step:11991 [D loss: 0.429038, acc.: 81.25%] [G loss: 0.661769]\n",
      "epoch:12 step:11992 [D loss: 0.504401, acc.: 72.66%] [G loss: 0.811869]\n",
      "epoch:12 step:11993 [D loss: 0.568312, acc.: 66.41%] [G loss: 0.529749]\n",
      "epoch:12 step:11994 [D loss: 0.494457, acc.: 77.34%] [G loss: 0.771003]\n",
      "epoch:12 step:11995 [D loss: 0.507227, acc.: 76.56%] [G loss: 0.640230]\n",
      "epoch:12 step:11996 [D loss: 0.586036, acc.: 65.62%] [G loss: 0.652805]\n",
      "epoch:12 step:11997 [D loss: 0.528031, acc.: 71.88%] [G loss: 0.615883]\n",
      "epoch:12 step:11998 [D loss: 0.522645, acc.: 71.09%] [G loss: 0.558274]\n",
      "epoch:12 step:11999 [D loss: 0.525058, acc.: 69.53%] [G loss: 0.474297]\n",
      "epoch:12 step:12000 [D loss: 0.599050, acc.: 67.19%] [G loss: 0.541728]\n",
      "epoch:12 step:12001 [D loss: 0.575867, acc.: 67.97%] [G loss: 0.519877]\n",
      "epoch:12 step:12002 [D loss: 0.567632, acc.: 70.31%] [G loss: 0.586156]\n",
      "epoch:12 step:12003 [D loss: 0.512782, acc.: 72.66%] [G loss: 0.676357]\n",
      "epoch:12 step:12004 [D loss: 0.518106, acc.: 71.88%] [G loss: 0.601358]\n",
      "epoch:12 step:12005 [D loss: 0.567746, acc.: 67.19%] [G loss: 0.553508]\n",
      "epoch:12 step:12006 [D loss: 0.604136, acc.: 61.72%] [G loss: 0.528886]\n",
      "epoch:12 step:12007 [D loss: 0.559791, acc.: 64.84%] [G loss: 0.590006]\n",
      "epoch:12 step:12008 [D loss: 0.517315, acc.: 71.09%] [G loss: 0.603005]\n",
      "epoch:12 step:12009 [D loss: 0.620617, acc.: 65.62%] [G loss: 0.521724]\n",
      "epoch:12 step:12010 [D loss: 0.638414, acc.: 66.41%] [G loss: 0.544635]\n",
      "epoch:12 step:12011 [D loss: 0.514636, acc.: 73.44%] [G loss: 0.622934]\n",
      "epoch:12 step:12012 [D loss: 0.512820, acc.: 75.78%] [G loss: 0.800549]\n",
      "epoch:12 step:12013 [D loss: 0.435730, acc.: 85.16%] [G loss: 0.754891]\n",
      "epoch:12 step:12014 [D loss: 0.509158, acc.: 71.88%] [G loss: 0.750009]\n",
      "epoch:12 step:12015 [D loss: 0.543109, acc.: 73.44%] [G loss: 0.737028]\n",
      "epoch:12 step:12016 [D loss: 0.500582, acc.: 70.31%] [G loss: 0.650732]\n",
      "epoch:12 step:12017 [D loss: 0.530674, acc.: 69.53%] [G loss: 0.718222]\n",
      "epoch:12 step:12018 [D loss: 0.582399, acc.: 67.19%] [G loss: 0.567021]\n",
      "epoch:12 step:12019 [D loss: 0.536604, acc.: 71.88%] [G loss: 0.650349]\n",
      "epoch:12 step:12020 [D loss: 0.588863, acc.: 67.19%] [G loss: 0.615038]\n",
      "epoch:12 step:12021 [D loss: 0.547977, acc.: 72.66%] [G loss: 0.562682]\n",
      "epoch:12 step:12022 [D loss: 0.588363, acc.: 67.19%] [G loss: 0.506497]\n",
      "epoch:12 step:12023 [D loss: 0.544858, acc.: 72.66%] [G loss: 0.613651]\n",
      "epoch:12 step:12024 [D loss: 0.510678, acc.: 74.22%] [G loss: 0.643575]\n",
      "epoch:12 step:12025 [D loss: 0.506099, acc.: 71.88%] [G loss: 0.919152]\n",
      "epoch:12 step:12026 [D loss: 0.483628, acc.: 74.22%] [G loss: 0.826876]\n",
      "epoch:12 step:12027 [D loss: 0.556432, acc.: 69.53%] [G loss: 0.634135]\n",
      "epoch:12 step:12028 [D loss: 0.580573, acc.: 66.41%] [G loss: 0.559598]\n",
      "epoch:12 step:12029 [D loss: 0.548899, acc.: 67.97%] [G loss: 0.574139]\n",
      "epoch:12 step:12030 [D loss: 0.509723, acc.: 69.53%] [G loss: 0.538635]\n",
      "epoch:12 step:12031 [D loss: 0.620815, acc.: 66.41%] [G loss: 0.501019]\n",
      "epoch:12 step:12032 [D loss: 0.682809, acc.: 60.16%] [G loss: 0.521318]\n",
      "epoch:12 step:12033 [D loss: 0.513312, acc.: 76.56%] [G loss: 0.509842]\n",
      "epoch:12 step:12034 [D loss: 0.511979, acc.: 72.66%] [G loss: 0.583320]\n",
      "epoch:12 step:12035 [D loss: 0.494255, acc.: 75.00%] [G loss: 0.556470]\n",
      "epoch:12 step:12036 [D loss: 0.450283, acc.: 76.56%] [G loss: 0.778627]\n",
      "epoch:12 step:12037 [D loss: 0.573981, acc.: 67.97%] [G loss: 0.555643]\n",
      "epoch:12 step:12038 [D loss: 0.666460, acc.: 62.50%] [G loss: 0.574257]\n",
      "epoch:12 step:12039 [D loss: 0.501152, acc.: 73.44%] [G loss: 0.763301]\n",
      "epoch:12 step:12040 [D loss: 0.487060, acc.: 73.44%] [G loss: 0.840592]\n",
      "epoch:12 step:12041 [D loss: 0.528763, acc.: 75.00%] [G loss: 0.628535]\n",
      "epoch:12 step:12042 [D loss: 0.517903, acc.: 71.09%] [G loss: 0.766257]\n",
      "epoch:12 step:12043 [D loss: 0.555646, acc.: 74.22%] [G loss: 0.716502]\n",
      "epoch:12 step:12044 [D loss: 0.591280, acc.: 68.75%] [G loss: 0.703924]\n",
      "epoch:12 step:12045 [D loss: 0.438497, acc.: 85.16%] [G loss: 0.727896]\n",
      "epoch:12 step:12046 [D loss: 0.485375, acc.: 76.56%] [G loss: 0.812855]\n",
      "epoch:12 step:12047 [D loss: 0.525682, acc.: 75.00%] [G loss: 0.683781]\n",
      "epoch:12 step:12048 [D loss: 0.554541, acc.: 71.88%] [G loss: 0.529661]\n",
      "epoch:12 step:12049 [D loss: 0.528735, acc.: 71.09%] [G loss: 0.589604]\n",
      "epoch:12 step:12050 [D loss: 0.522754, acc.: 69.53%] [G loss: 0.617375]\n",
      "epoch:12 step:12051 [D loss: 0.509660, acc.: 73.44%] [G loss: 0.555526]\n",
      "epoch:12 step:12052 [D loss: 0.572624, acc.: 67.19%] [G loss: 0.488561]\n",
      "epoch:12 step:12053 [D loss: 0.553011, acc.: 74.22%] [G loss: 0.531089]\n",
      "epoch:12 step:12054 [D loss: 0.488765, acc.: 74.22%] [G loss: 0.656926]\n",
      "epoch:12 step:12055 [D loss: 0.550152, acc.: 74.22%] [G loss: 0.525132]\n",
      "epoch:12 step:12056 [D loss: 0.591464, acc.: 67.19%] [G loss: 0.517162]\n",
      "epoch:12 step:12057 [D loss: 0.523322, acc.: 69.53%] [G loss: 0.509456]\n",
      "epoch:12 step:12058 [D loss: 0.503983, acc.: 74.22%] [G loss: 0.736321]\n",
      "epoch:12 step:12059 [D loss: 0.488363, acc.: 75.00%] [G loss: 0.911473]\n",
      "epoch:12 step:12060 [D loss: 0.541774, acc.: 73.44%] [G loss: 0.776132]\n",
      "epoch:12 step:12061 [D loss: 0.602351, acc.: 71.09%] [G loss: 0.674237]\n",
      "epoch:12 step:12062 [D loss: 0.611365, acc.: 64.06%] [G loss: 0.676269]\n",
      "epoch:12 step:12063 [D loss: 0.564902, acc.: 69.53%] [G loss: 0.614896]\n",
      "epoch:12 step:12064 [D loss: 0.630566, acc.: 65.62%] [G loss: 0.523551]\n",
      "epoch:12 step:12065 [D loss: 0.494637, acc.: 76.56%] [G loss: 0.660616]\n",
      "epoch:12 step:12066 [D loss: 0.555758, acc.: 71.09%] [G loss: 0.488083]\n",
      "epoch:12 step:12067 [D loss: 0.408532, acc.: 81.25%] [G loss: 0.661559]\n",
      "epoch:12 step:12068 [D loss: 0.613357, acc.: 67.97%] [G loss: 0.507429]\n",
      "epoch:12 step:12069 [D loss: 0.507222, acc.: 71.88%] [G loss: 0.566132]\n",
      "epoch:12 step:12070 [D loss: 0.581299, acc.: 71.09%] [G loss: 0.498968]\n",
      "epoch:12 step:12071 [D loss: 0.501384, acc.: 76.56%] [G loss: 0.637807]\n",
      "epoch:12 step:12072 [D loss: 0.628785, acc.: 64.06%] [G loss: 0.641145]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:12 step:12073 [D loss: 0.542337, acc.: 67.97%] [G loss: 0.701203]\n",
      "epoch:12 step:12074 [D loss: 0.576078, acc.: 64.84%] [G loss: 0.699428]\n",
      "epoch:12 step:12075 [D loss: 0.531366, acc.: 67.97%] [G loss: 0.605847]\n",
      "epoch:12 step:12076 [D loss: 0.519338, acc.: 69.53%] [G loss: 0.492403]\n",
      "epoch:12 step:12077 [D loss: 0.554495, acc.: 71.09%] [G loss: 0.564350]\n",
      "epoch:12 step:12078 [D loss: 0.537155, acc.: 75.00%] [G loss: 0.512647]\n",
      "epoch:12 step:12079 [D loss: 0.545512, acc.: 73.44%] [G loss: 0.581307]\n",
      "epoch:12 step:12080 [D loss: 0.511171, acc.: 75.00%] [G loss: 0.544771]\n",
      "epoch:12 step:12081 [D loss: 0.501699, acc.: 72.66%] [G loss: 0.488741]\n",
      "epoch:12 step:12082 [D loss: 0.535020, acc.: 70.31%] [G loss: 0.550962]\n",
      "epoch:12 step:12083 [D loss: 0.548027, acc.: 72.66%] [G loss: 0.605814]\n",
      "epoch:12 step:12084 [D loss: 0.571415, acc.: 69.53%] [G loss: 0.516029]\n",
      "epoch:12 step:12085 [D loss: 0.549251, acc.: 66.41%] [G loss: 0.492171]\n",
      "epoch:12 step:12086 [D loss: 0.513427, acc.: 73.44%] [G loss: 0.498358]\n",
      "epoch:12 step:12087 [D loss: 0.510069, acc.: 72.66%] [G loss: 0.496607]\n",
      "epoch:12 step:12088 [D loss: 0.574747, acc.: 67.19%] [G loss: 0.643591]\n",
      "epoch:12 step:12089 [D loss: 0.567110, acc.: 66.41%] [G loss: 0.591080]\n",
      "epoch:12 step:12090 [D loss: 0.556759, acc.: 68.75%] [G loss: 0.619088]\n",
      "epoch:12 step:12091 [D loss: 0.593659, acc.: 67.19%] [G loss: 0.433642]\n",
      "epoch:12 step:12092 [D loss: 0.538184, acc.: 68.75%] [G loss: 0.421029]\n",
      "epoch:12 step:12093 [D loss: 0.572025, acc.: 67.19%] [G loss: 0.382596]\n",
      "epoch:12 step:12094 [D loss: 0.531395, acc.: 71.88%] [G loss: 0.565965]\n",
      "epoch:12 step:12095 [D loss: 0.569014, acc.: 68.75%] [G loss: 0.590010]\n",
      "epoch:12 step:12096 [D loss: 0.498082, acc.: 74.22%] [G loss: 0.578684]\n",
      "epoch:12 step:12097 [D loss: 0.544274, acc.: 69.53%] [G loss: 0.636398]\n",
      "epoch:12 step:12098 [D loss: 0.515943, acc.: 76.56%] [G loss: 0.583081]\n",
      "epoch:12 step:12099 [D loss: 0.539320, acc.: 67.19%] [G loss: 0.669258]\n",
      "epoch:12 step:12100 [D loss: 0.558079, acc.: 71.88%] [G loss: 0.585355]\n",
      "epoch:12 step:12101 [D loss: 0.429477, acc.: 80.47%] [G loss: 0.697261]\n",
      "epoch:12 step:12102 [D loss: 0.620851, acc.: 63.28%] [G loss: 0.595095]\n",
      "epoch:12 step:12103 [D loss: 0.584210, acc.: 67.19%] [G loss: 0.630099]\n",
      "epoch:12 step:12104 [D loss: 0.438761, acc.: 79.69%] [G loss: 0.716943]\n",
      "epoch:12 step:12105 [D loss: 0.619136, acc.: 64.84%] [G loss: 0.560285]\n",
      "epoch:12 step:12106 [D loss: 0.558794, acc.: 66.41%] [G loss: 0.606970]\n",
      "epoch:12 step:12107 [D loss: 0.541514, acc.: 71.09%] [G loss: 0.574606]\n",
      "epoch:12 step:12108 [D loss: 0.538234, acc.: 71.88%] [G loss: 0.613448]\n",
      "epoch:12 step:12109 [D loss: 0.600945, acc.: 66.41%] [G loss: 0.568709]\n",
      "epoch:12 step:12110 [D loss: 0.485047, acc.: 73.44%] [G loss: 0.652925]\n",
      "epoch:12 step:12111 [D loss: 0.660140, acc.: 60.16%] [G loss: 0.406187]\n",
      "epoch:12 step:12112 [D loss: 0.512851, acc.: 71.88%] [G loss: 0.574056]\n",
      "epoch:12 step:12113 [D loss: 0.567566, acc.: 70.31%] [G loss: 0.461738]\n",
      "epoch:12 step:12114 [D loss: 0.462745, acc.: 78.12%] [G loss: 0.647107]\n",
      "epoch:12 step:12115 [D loss: 0.490658, acc.: 78.12%] [G loss: 0.635080]\n",
      "epoch:12 step:12116 [D loss: 0.523837, acc.: 68.75%] [G loss: 0.584145]\n",
      "epoch:12 step:12117 [D loss: 0.601719, acc.: 67.19%] [G loss: 0.523826]\n",
      "epoch:12 step:12118 [D loss: 0.541016, acc.: 71.09%] [G loss: 0.562067]\n",
      "epoch:12 step:12119 [D loss: 0.511108, acc.: 70.31%] [G loss: 0.632211]\n",
      "epoch:12 step:12120 [D loss: 0.562377, acc.: 67.19%] [G loss: 0.577702]\n",
      "epoch:12 step:12121 [D loss: 0.620642, acc.: 63.28%] [G loss: 0.499358]\n",
      "epoch:12 step:12122 [D loss: 0.537358, acc.: 71.88%] [G loss: 0.614742]\n",
      "epoch:12 step:12123 [D loss: 0.549275, acc.: 71.09%] [G loss: 0.574947]\n",
      "epoch:12 step:12124 [D loss: 0.640880, acc.: 59.38%] [G loss: 0.434685]\n",
      "epoch:12 step:12125 [D loss: 0.541659, acc.: 71.88%] [G loss: 0.560343]\n",
      "epoch:12 step:12126 [D loss: 0.567554, acc.: 64.84%] [G loss: 0.486475]\n",
      "epoch:12 step:12127 [D loss: 0.572375, acc.: 69.53%] [G loss: 0.575112]\n",
      "epoch:12 step:12128 [D loss: 0.468716, acc.: 77.34%] [G loss: 0.636526]\n",
      "epoch:12 step:12129 [D loss: 0.499875, acc.: 75.00%] [G loss: 0.715619]\n",
      "epoch:12 step:12130 [D loss: 0.540501, acc.: 71.88%] [G loss: 0.827695]\n",
      "epoch:12 step:12131 [D loss: 0.602384, acc.: 64.84%] [G loss: 0.796309]\n",
      "epoch:12 step:12132 [D loss: 0.594840, acc.: 64.84%] [G loss: 0.509159]\n",
      "epoch:12 step:12133 [D loss: 0.518010, acc.: 67.97%] [G loss: 0.782255]\n",
      "epoch:12 step:12134 [D loss: 0.497502, acc.: 74.22%] [G loss: 0.637697]\n",
      "epoch:12 step:12135 [D loss: 0.605739, acc.: 67.19%] [G loss: 0.526626]\n",
      "epoch:12 step:12136 [D loss: 0.613845, acc.: 69.53%] [G loss: 0.528757]\n",
      "epoch:12 step:12137 [D loss: 0.516773, acc.: 77.34%] [G loss: 0.552969]\n",
      "epoch:12 step:12138 [D loss: 0.490437, acc.: 73.44%] [G loss: 0.720930]\n",
      "epoch:12 step:12139 [D loss: 0.494849, acc.: 79.69%] [G loss: 0.867953]\n",
      "epoch:12 step:12140 [D loss: 0.540193, acc.: 73.44%] [G loss: 0.813556]\n",
      "epoch:12 step:12141 [D loss: 0.470356, acc.: 78.91%] [G loss: 0.682882]\n",
      "epoch:12 step:12142 [D loss: 0.497500, acc.: 79.69%] [G loss: 0.719738]\n",
      "epoch:12 step:12143 [D loss: 0.494721, acc.: 77.34%] [G loss: 0.730889]\n",
      "epoch:12 step:12144 [D loss: 0.474549, acc.: 82.03%] [G loss: 0.677203]\n",
      "epoch:12 step:12145 [D loss: 0.515343, acc.: 72.66%] [G loss: 0.669854]\n",
      "epoch:12 step:12146 [D loss: 0.593454, acc.: 64.06%] [G loss: 0.600410]\n",
      "epoch:12 step:12147 [D loss: 0.513496, acc.: 74.22%] [G loss: 0.607902]\n",
      "epoch:12 step:12148 [D loss: 0.604722, acc.: 65.62%] [G loss: 0.536252]\n",
      "epoch:12 step:12149 [D loss: 0.597186, acc.: 69.53%] [G loss: 0.634952]\n",
      "epoch:12 step:12150 [D loss: 0.482666, acc.: 78.12%] [G loss: 0.769558]\n",
      "epoch:12 step:12151 [D loss: 0.539065, acc.: 70.31%] [G loss: 0.590596]\n",
      "epoch:12 step:12152 [D loss: 0.509837, acc.: 75.00%] [G loss: 0.660861]\n",
      "epoch:12 step:12153 [D loss: 0.460111, acc.: 80.47%] [G loss: 0.600884]\n",
      "epoch:12 step:12154 [D loss: 0.523000, acc.: 71.88%] [G loss: 0.584415]\n",
      "epoch:12 step:12155 [D loss: 0.480134, acc.: 78.91%] [G loss: 0.705016]\n",
      "epoch:12 step:12156 [D loss: 0.481355, acc.: 80.47%] [G loss: 0.793064]\n",
      "epoch:12 step:12157 [D loss: 0.578165, acc.: 68.75%] [G loss: 0.740195]\n",
      "epoch:12 step:12158 [D loss: 0.489739, acc.: 75.78%] [G loss: 0.917590]\n",
      "epoch:12 step:12159 [D loss: 0.618716, acc.: 64.84%] [G loss: 0.623265]\n",
      "epoch:12 step:12160 [D loss: 0.543373, acc.: 73.44%] [G loss: 0.665239]\n",
      "epoch:12 step:12161 [D loss: 0.596408, acc.: 64.84%] [G loss: 0.670856]\n",
      "epoch:12 step:12162 [D loss: 0.490178, acc.: 80.47%] [G loss: 0.698446]\n",
      "epoch:12 step:12163 [D loss: 0.518312, acc.: 77.34%] [G loss: 0.735759]\n",
      "epoch:12 step:12164 [D loss: 0.639046, acc.: 67.19%] [G loss: 0.878278]\n",
      "epoch:12 step:12165 [D loss: 0.483025, acc.: 77.34%] [G loss: 0.867335]\n",
      "epoch:12 step:12166 [D loss: 0.529338, acc.: 74.22%] [G loss: 0.628111]\n",
      "epoch:12 step:12167 [D loss: 0.497102, acc.: 70.31%] [G loss: 0.699664]\n",
      "epoch:12 step:12168 [D loss: 0.453219, acc.: 76.56%] [G loss: 0.771583]\n",
      "epoch:12 step:12169 [D loss: 0.427325, acc.: 79.69%] [G loss: 0.999865]\n",
      "epoch:12 step:12170 [D loss: 0.489668, acc.: 73.44%] [G loss: 1.191334]\n",
      "epoch:12 step:12171 [D loss: 0.419809, acc.: 81.25%] [G loss: 1.323481]\n",
      "epoch:12 step:12172 [D loss: 0.762235, acc.: 61.72%] [G loss: 1.099816]\n",
      "epoch:12 step:12173 [D loss: 0.469773, acc.: 75.78%] [G loss: 0.880828]\n",
      "epoch:12 step:12174 [D loss: 0.485021, acc.: 72.66%] [G loss: 0.995204]\n",
      "epoch:12 step:12175 [D loss: 0.508199, acc.: 72.66%] [G loss: 0.963226]\n",
      "epoch:12 step:12176 [D loss: 0.558871, acc.: 71.09%] [G loss: 0.813429]\n",
      "epoch:12 step:12177 [D loss: 0.472682, acc.: 76.56%] [G loss: 0.740702]\n",
      "epoch:12 step:12178 [D loss: 0.558322, acc.: 71.09%] [G loss: 1.052570]\n",
      "epoch:12 step:12179 [D loss: 0.461055, acc.: 78.12%] [G loss: 0.942875]\n",
      "epoch:12 step:12180 [D loss: 0.425487, acc.: 80.47%] [G loss: 1.307216]\n",
      "epoch:12 step:12181 [D loss: 0.426677, acc.: 82.81%] [G loss: 1.336781]\n",
      "epoch:13 step:12182 [D loss: 0.619992, acc.: 69.53%] [G loss: 1.030098]\n",
      "epoch:13 step:12183 [D loss: 0.514000, acc.: 78.12%] [G loss: 0.911996]\n",
      "epoch:13 step:12184 [D loss: 0.649680, acc.: 68.75%] [G loss: 0.761170]\n",
      "epoch:13 step:12185 [D loss: 0.482084, acc.: 77.34%] [G loss: 0.839938]\n",
      "epoch:13 step:12186 [D loss: 0.536970, acc.: 71.88%] [G loss: 0.827443]\n",
      "epoch:13 step:12187 [D loss: 0.580635, acc.: 67.19%] [G loss: 0.710630]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:13 step:12188 [D loss: 0.482708, acc.: 76.56%] [G loss: 0.911891]\n",
      "epoch:13 step:12189 [D loss: 0.495285, acc.: 77.34%] [G loss: 0.819282]\n",
      "epoch:13 step:12190 [D loss: 0.520402, acc.: 71.88%] [G loss: 0.694679]\n",
      "epoch:13 step:12191 [D loss: 0.494922, acc.: 74.22%] [G loss: 0.742382]\n",
      "epoch:13 step:12192 [D loss: 0.482147, acc.: 77.34%] [G loss: 0.737491]\n",
      "epoch:13 step:12193 [D loss: 0.596907, acc.: 66.41%] [G loss: 0.592028]\n",
      "epoch:13 step:12194 [D loss: 0.546736, acc.: 70.31%] [G loss: 0.581606]\n",
      "epoch:13 step:12195 [D loss: 0.531036, acc.: 74.22%] [G loss: 0.600747]\n",
      "epoch:13 step:12196 [D loss: 0.523184, acc.: 67.19%] [G loss: 0.557349]\n",
      "epoch:13 step:12197 [D loss: 0.476860, acc.: 74.22%] [G loss: 0.701478]\n",
      "epoch:13 step:12198 [D loss: 0.537090, acc.: 76.56%] [G loss: 0.590064]\n",
      "epoch:13 step:12199 [D loss: 0.537780, acc.: 69.53%] [G loss: 0.737244]\n",
      "epoch:13 step:12200 [D loss: 0.603577, acc.: 65.62%] [G loss: 0.658299]\n",
      "epoch:13 step:12201 [D loss: 0.671619, acc.: 58.59%] [G loss: 0.518923]\n",
      "epoch:13 step:12202 [D loss: 0.534379, acc.: 71.88%] [G loss: 0.547928]\n",
      "epoch:13 step:12203 [D loss: 0.469740, acc.: 77.34%] [G loss: 0.684602]\n",
      "epoch:13 step:12204 [D loss: 0.583789, acc.: 64.06%] [G loss: 0.630905]\n",
      "epoch:13 step:12205 [D loss: 0.467513, acc.: 80.47%] [G loss: 0.532548]\n",
      "epoch:13 step:12206 [D loss: 0.524355, acc.: 75.78%] [G loss: 0.641921]\n",
      "epoch:13 step:12207 [D loss: 0.546866, acc.: 74.22%] [G loss: 0.593009]\n",
      "epoch:13 step:12208 [D loss: 0.477908, acc.: 75.78%] [G loss: 0.714015]\n",
      "epoch:13 step:12209 [D loss: 0.552087, acc.: 68.75%] [G loss: 0.573429]\n",
      "epoch:13 step:12210 [D loss: 0.504783, acc.: 72.66%] [G loss: 0.602300]\n",
      "epoch:13 step:12211 [D loss: 0.536164, acc.: 68.75%] [G loss: 0.688622]\n",
      "epoch:13 step:12212 [D loss: 0.622916, acc.: 64.84%] [G loss: 0.512356]\n",
      "epoch:13 step:12213 [D loss: 0.546455, acc.: 69.53%] [G loss: 0.517022]\n",
      "epoch:13 step:12214 [D loss: 0.511599, acc.: 75.00%] [G loss: 0.618281]\n",
      "epoch:13 step:12215 [D loss: 0.510134, acc.: 70.31%] [G loss: 0.524569]\n",
      "epoch:13 step:12216 [D loss: 0.548146, acc.: 68.75%] [G loss: 0.484356]\n",
      "epoch:13 step:12217 [D loss: 0.564102, acc.: 67.19%] [G loss: 0.913439]\n",
      "epoch:13 step:12218 [D loss: 0.440427, acc.: 86.72%] [G loss: 0.874348]\n",
      "epoch:13 step:12219 [D loss: 0.589568, acc.: 65.62%] [G loss: 0.487513]\n",
      "epoch:13 step:12220 [D loss: 0.576666, acc.: 67.19%] [G loss: 0.534335]\n",
      "epoch:13 step:12221 [D loss: 0.417955, acc.: 82.81%] [G loss: 0.697614]\n",
      "epoch:13 step:12222 [D loss: 0.557516, acc.: 71.88%] [G loss: 0.474487]\n",
      "epoch:13 step:12223 [D loss: 0.531334, acc.: 67.97%] [G loss: 0.636096]\n",
      "epoch:13 step:12224 [D loss: 0.517630, acc.: 71.09%] [G loss: 0.774486]\n",
      "epoch:13 step:12225 [D loss: 0.599891, acc.: 61.72%] [G loss: 0.499100]\n",
      "epoch:13 step:12226 [D loss: 0.502488, acc.: 71.88%] [G loss: 0.651717]\n",
      "epoch:13 step:12227 [D loss: 0.509126, acc.: 75.78%] [G loss: 0.666311]\n",
      "epoch:13 step:12228 [D loss: 0.517443, acc.: 72.66%] [G loss: 0.596976]\n",
      "epoch:13 step:12229 [D loss: 0.527472, acc.: 69.53%] [G loss: 0.612064]\n",
      "epoch:13 step:12230 [D loss: 0.493487, acc.: 73.44%] [G loss: 0.582659]\n",
      "epoch:13 step:12231 [D loss: 0.527168, acc.: 73.44%] [G loss: 0.597826]\n",
      "epoch:13 step:12232 [D loss: 0.624581, acc.: 64.84%] [G loss: 0.492807]\n",
      "epoch:13 step:12233 [D loss: 0.563712, acc.: 68.75%] [G loss: 0.511665]\n",
      "epoch:13 step:12234 [D loss: 0.517348, acc.: 74.22%] [G loss: 0.546296]\n",
      "epoch:13 step:12235 [D loss: 0.489713, acc.: 75.78%] [G loss: 0.672383]\n",
      "epoch:13 step:12236 [D loss: 0.507457, acc.: 77.34%] [G loss: 0.748467]\n",
      "epoch:13 step:12237 [D loss: 0.520365, acc.: 76.56%] [G loss: 0.736010]\n",
      "epoch:13 step:12238 [D loss: 0.505705, acc.: 77.34%] [G loss: 0.743967]\n",
      "epoch:13 step:12239 [D loss: 0.543172, acc.: 70.31%] [G loss: 0.633044]\n",
      "epoch:13 step:12240 [D loss: 0.522011, acc.: 72.66%] [G loss: 0.748256]\n",
      "epoch:13 step:12241 [D loss: 0.564209, acc.: 67.19%] [G loss: 0.641860]\n",
      "epoch:13 step:12242 [D loss: 0.566450, acc.: 67.19%] [G loss: 0.574533]\n",
      "epoch:13 step:12243 [D loss: 0.610573, acc.: 65.62%] [G loss: 0.523409]\n",
      "epoch:13 step:12244 [D loss: 0.552958, acc.: 72.66%] [G loss: 0.532035]\n",
      "epoch:13 step:12245 [D loss: 0.548419, acc.: 68.75%] [G loss: 0.648261]\n",
      "epoch:13 step:12246 [D loss: 0.520898, acc.: 80.47%] [G loss: 0.553217]\n",
      "epoch:13 step:12247 [D loss: 0.526896, acc.: 65.62%] [G loss: 0.543683]\n",
      "epoch:13 step:12248 [D loss: 0.502542, acc.: 76.56%] [G loss: 0.560368]\n",
      "epoch:13 step:12249 [D loss: 0.550229, acc.: 68.75%] [G loss: 0.579827]\n",
      "epoch:13 step:12250 [D loss: 0.490925, acc.: 76.56%] [G loss: 0.623192]\n",
      "epoch:13 step:12251 [D loss: 0.529741, acc.: 71.88%] [G loss: 0.614309]\n",
      "epoch:13 step:12252 [D loss: 0.514781, acc.: 71.09%] [G loss: 0.685706]\n",
      "epoch:13 step:12253 [D loss: 0.488630, acc.: 78.91%] [G loss: 0.477419]\n",
      "epoch:13 step:12254 [D loss: 0.572177, acc.: 64.84%] [G loss: 0.580518]\n",
      "epoch:13 step:12255 [D loss: 0.492866, acc.: 72.66%] [G loss: 0.582054]\n",
      "epoch:13 step:12256 [D loss: 0.466498, acc.: 75.78%] [G loss: 0.691789]\n",
      "epoch:13 step:12257 [D loss: 0.454397, acc.: 78.91%] [G loss: 0.748571]\n",
      "epoch:13 step:12258 [D loss: 0.479345, acc.: 75.00%] [G loss: 0.782335]\n",
      "epoch:13 step:12259 [D loss: 0.597282, acc.: 71.09%] [G loss: 0.708462]\n",
      "epoch:13 step:12260 [D loss: 0.527071, acc.: 72.66%] [G loss: 0.746488]\n",
      "epoch:13 step:12261 [D loss: 0.533417, acc.: 70.31%] [G loss: 0.737499]\n",
      "epoch:13 step:12262 [D loss: 0.542392, acc.: 69.53%] [G loss: 0.865375]\n",
      "epoch:13 step:12263 [D loss: 0.584200, acc.: 71.09%] [G loss: 0.625099]\n",
      "epoch:13 step:12264 [D loss: 0.445086, acc.: 78.91%] [G loss: 0.752189]\n",
      "epoch:13 step:12265 [D loss: 0.549471, acc.: 73.44%] [G loss: 0.724402]\n",
      "epoch:13 step:12266 [D loss: 0.599519, acc.: 65.62%] [G loss: 0.568325]\n",
      "epoch:13 step:12267 [D loss: 0.541695, acc.: 75.00%] [G loss: 0.695364]\n",
      "epoch:13 step:12268 [D loss: 0.481978, acc.: 76.56%] [G loss: 0.580905]\n",
      "epoch:13 step:12269 [D loss: 0.506151, acc.: 76.56%] [G loss: 0.637629]\n",
      "epoch:13 step:12270 [D loss: 0.481644, acc.: 75.00%] [G loss: 0.647426]\n",
      "epoch:13 step:12271 [D loss: 0.503622, acc.: 76.56%] [G loss: 0.780425]\n",
      "epoch:13 step:12272 [D loss: 0.531732, acc.: 71.88%] [G loss: 0.684873]\n",
      "epoch:13 step:12273 [D loss: 0.462502, acc.: 76.56%] [G loss: 0.730412]\n",
      "epoch:13 step:12274 [D loss: 0.491067, acc.: 73.44%] [G loss: 0.758911]\n",
      "epoch:13 step:12275 [D loss: 0.492088, acc.: 73.44%] [G loss: 0.730453]\n",
      "epoch:13 step:12276 [D loss: 0.520782, acc.: 69.53%] [G loss: 0.779205]\n",
      "epoch:13 step:12277 [D loss: 0.524705, acc.: 71.88%] [G loss: 0.620297]\n",
      "epoch:13 step:12278 [D loss: 0.516494, acc.: 76.56%] [G loss: 0.768946]\n",
      "epoch:13 step:12279 [D loss: 0.577395, acc.: 64.06%] [G loss: 0.630569]\n",
      "epoch:13 step:12280 [D loss: 0.549281, acc.: 71.09%] [G loss: 0.666100]\n",
      "epoch:13 step:12281 [D loss: 0.409581, acc.: 82.03%] [G loss: 0.894426]\n",
      "epoch:13 step:12282 [D loss: 0.543914, acc.: 71.09%] [G loss: 0.809806]\n",
      "epoch:13 step:12283 [D loss: 0.643233, acc.: 64.06%] [G loss: 0.562647]\n",
      "epoch:13 step:12284 [D loss: 0.532031, acc.: 73.44%] [G loss: 0.749807]\n",
      "epoch:13 step:12285 [D loss: 0.540559, acc.: 70.31%] [G loss: 0.706957]\n",
      "epoch:13 step:12286 [D loss: 0.620663, acc.: 63.28%] [G loss: 0.445901]\n",
      "epoch:13 step:12287 [D loss: 0.557538, acc.: 65.62%] [G loss: 0.658961]\n",
      "epoch:13 step:12288 [D loss: 0.602506, acc.: 70.31%] [G loss: 0.613194]\n",
      "epoch:13 step:12289 [D loss: 0.640897, acc.: 58.59%] [G loss: 0.650593]\n",
      "epoch:13 step:12290 [D loss: 0.562482, acc.: 68.75%] [G loss: 0.549434]\n",
      "epoch:13 step:12291 [D loss: 0.545683, acc.: 66.41%] [G loss: 0.521268]\n",
      "epoch:13 step:12292 [D loss: 0.516744, acc.: 70.31%] [G loss: 0.555295]\n",
      "epoch:13 step:12293 [D loss: 0.488470, acc.: 74.22%] [G loss: 0.709480]\n",
      "epoch:13 step:12294 [D loss: 0.551605, acc.: 68.75%] [G loss: 0.605144]\n",
      "epoch:13 step:12295 [D loss: 0.592054, acc.: 68.75%] [G loss: 0.661265]\n",
      "epoch:13 step:12296 [D loss: 0.550792, acc.: 71.88%] [G loss: 0.605108]\n",
      "epoch:13 step:12297 [D loss: 0.539616, acc.: 69.53%] [G loss: 0.757851]\n",
      "epoch:13 step:12298 [D loss: 0.472053, acc.: 75.78%] [G loss: 0.824405]\n",
      "epoch:13 step:12299 [D loss: 0.570971, acc.: 66.41%] [G loss: 0.771831]\n",
      "epoch:13 step:12300 [D loss: 0.420917, acc.: 83.59%] [G loss: 1.055773]\n",
      "epoch:13 step:12301 [D loss: 0.587386, acc.: 67.19%] [G loss: 0.913599]\n",
      "epoch:13 step:12302 [D loss: 0.515931, acc.: 72.66%] [G loss: 0.723758]\n",
      "epoch:13 step:12303 [D loss: 0.460187, acc.: 82.03%] [G loss: 0.714977]\n",
      "epoch:13 step:12304 [D loss: 0.495348, acc.: 74.22%] [G loss: 0.712674]\n",
      "epoch:13 step:12305 [D loss: 0.586822, acc.: 71.88%] [G loss: 0.647430]\n",
      "epoch:13 step:12306 [D loss: 0.571859, acc.: 67.97%] [G loss: 0.587050]\n",
      "epoch:13 step:12307 [D loss: 0.535602, acc.: 71.09%] [G loss: 0.492926]\n",
      "epoch:13 step:12308 [D loss: 0.504913, acc.: 74.22%] [G loss: 0.585654]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:13 step:12309 [D loss: 0.501485, acc.: 70.31%] [G loss: 0.643758]\n",
      "epoch:13 step:12310 [D loss: 0.540437, acc.: 69.53%] [G loss: 0.579564]\n",
      "epoch:13 step:12311 [D loss: 0.524689, acc.: 67.19%] [G loss: 0.508689]\n",
      "epoch:13 step:12312 [D loss: 0.470034, acc.: 77.34%] [G loss: 0.770199]\n",
      "epoch:13 step:12313 [D loss: 0.564875, acc.: 67.97%] [G loss: 0.740992]\n",
      "epoch:13 step:12314 [D loss: 0.529140, acc.: 72.66%] [G loss: 0.716240]\n",
      "epoch:13 step:12315 [D loss: 0.590789, acc.: 71.09%] [G loss: 0.659596]\n",
      "epoch:13 step:12316 [D loss: 0.493546, acc.: 75.78%] [G loss: 0.651794]\n",
      "epoch:13 step:12317 [D loss: 0.540312, acc.: 71.88%] [G loss: 0.506308]\n",
      "epoch:13 step:12318 [D loss: 0.579826, acc.: 67.19%] [G loss: 0.593467]\n",
      "epoch:13 step:12319 [D loss: 0.619772, acc.: 63.28%] [G loss: 0.522922]\n",
      "epoch:13 step:12320 [D loss: 0.599786, acc.: 65.62%] [G loss: 0.498408]\n",
      "epoch:13 step:12321 [D loss: 0.514807, acc.: 74.22%] [G loss: 0.666984]\n",
      "epoch:13 step:12322 [D loss: 0.526719, acc.: 68.75%] [G loss: 0.671325]\n",
      "epoch:13 step:12323 [D loss: 0.565008, acc.: 63.28%] [G loss: 0.635422]\n",
      "epoch:13 step:12324 [D loss: 0.596526, acc.: 70.31%] [G loss: 0.615785]\n",
      "epoch:13 step:12325 [D loss: 0.513872, acc.: 71.09%] [G loss: 0.492387]\n",
      "epoch:13 step:12326 [D loss: 0.543004, acc.: 70.31%] [G loss: 0.564675]\n",
      "epoch:13 step:12327 [D loss: 0.507868, acc.: 77.34%] [G loss: 0.609342]\n",
      "epoch:13 step:12328 [D loss: 0.644064, acc.: 64.84%] [G loss: 0.593946]\n",
      "epoch:13 step:12329 [D loss: 0.510836, acc.: 71.09%] [G loss: 0.614856]\n",
      "epoch:13 step:12330 [D loss: 0.485419, acc.: 74.22%] [G loss: 0.513103]\n",
      "epoch:13 step:12331 [D loss: 0.592616, acc.: 68.75%] [G loss: 0.559268]\n",
      "epoch:13 step:12332 [D loss: 0.602498, acc.: 67.97%] [G loss: 0.624244]\n",
      "epoch:13 step:12333 [D loss: 0.428879, acc.: 81.25%] [G loss: 0.717417]\n",
      "epoch:13 step:12334 [D loss: 0.580874, acc.: 64.84%] [G loss: 0.667282]\n",
      "epoch:13 step:12335 [D loss: 0.521062, acc.: 71.88%] [G loss: 0.526462]\n",
      "epoch:13 step:12336 [D loss: 0.464017, acc.: 78.91%] [G loss: 0.713480]\n",
      "epoch:13 step:12337 [D loss: 0.490871, acc.: 73.44%] [G loss: 0.705973]\n",
      "epoch:13 step:12338 [D loss: 0.581545, acc.: 67.19%] [G loss: 0.718481]\n",
      "epoch:13 step:12339 [D loss: 0.534952, acc.: 74.22%] [G loss: 0.704189]\n",
      "epoch:13 step:12340 [D loss: 0.468775, acc.: 78.12%] [G loss: 0.761725]\n",
      "epoch:13 step:12341 [D loss: 0.631719, acc.: 65.62%] [G loss: 0.560068]\n",
      "epoch:13 step:12342 [D loss: 0.549096, acc.: 67.97%] [G loss: 0.936738]\n",
      "epoch:13 step:12343 [D loss: 0.424762, acc.: 80.47%] [G loss: 0.829406]\n",
      "epoch:13 step:12344 [D loss: 0.544007, acc.: 69.53%] [G loss: 0.954328]\n",
      "epoch:13 step:12345 [D loss: 0.555811, acc.: 70.31%] [G loss: 0.823063]\n",
      "epoch:13 step:12346 [D loss: 0.479049, acc.: 75.00%] [G loss: 0.632410]\n",
      "epoch:13 step:12347 [D loss: 0.550161, acc.: 68.75%] [G loss: 0.547010]\n",
      "epoch:13 step:12348 [D loss: 0.537571, acc.: 67.19%] [G loss: 0.594844]\n",
      "epoch:13 step:12349 [D loss: 0.556043, acc.: 71.09%] [G loss: 0.584435]\n",
      "epoch:13 step:12350 [D loss: 0.575670, acc.: 70.31%] [G loss: 0.460399]\n",
      "epoch:13 step:12351 [D loss: 0.566161, acc.: 69.53%] [G loss: 0.708005]\n",
      "epoch:13 step:12352 [D loss: 0.503842, acc.: 73.44%] [G loss: 0.656888]\n",
      "epoch:13 step:12353 [D loss: 0.495012, acc.: 73.44%] [G loss: 0.691803]\n",
      "epoch:13 step:12354 [D loss: 0.469650, acc.: 75.00%] [G loss: 0.688705]\n",
      "epoch:13 step:12355 [D loss: 0.567114, acc.: 67.19%] [G loss: 0.500697]\n",
      "epoch:13 step:12356 [D loss: 0.623035, acc.: 58.59%] [G loss: 0.406905]\n",
      "epoch:13 step:12357 [D loss: 0.478353, acc.: 75.78%] [G loss: 0.566116]\n",
      "epoch:13 step:12358 [D loss: 0.514484, acc.: 76.56%] [G loss: 0.634469]\n",
      "epoch:13 step:12359 [D loss: 0.601161, acc.: 65.62%] [G loss: 0.571137]\n",
      "epoch:13 step:12360 [D loss: 0.549491, acc.: 68.75%] [G loss: 0.677607]\n",
      "epoch:13 step:12361 [D loss: 0.676253, acc.: 60.94%] [G loss: 0.515988]\n",
      "epoch:13 step:12362 [D loss: 0.541895, acc.: 67.97%] [G loss: 0.445374]\n",
      "epoch:13 step:12363 [D loss: 0.507059, acc.: 75.78%] [G loss: 0.659961]\n",
      "epoch:13 step:12364 [D loss: 0.528342, acc.: 72.66%] [G loss: 0.514769]\n",
      "epoch:13 step:12365 [D loss: 0.522735, acc.: 71.88%] [G loss: 0.602170]\n",
      "epoch:13 step:12366 [D loss: 0.588337, acc.: 65.62%] [G loss: 0.638878]\n",
      "epoch:13 step:12367 [D loss: 0.521767, acc.: 70.31%] [G loss: 0.697929]\n",
      "epoch:13 step:12368 [D loss: 0.560902, acc.: 69.53%] [G loss: 0.571815]\n",
      "epoch:13 step:12369 [D loss: 0.510623, acc.: 70.31%] [G loss: 0.657450]\n",
      "epoch:13 step:12370 [D loss: 0.617169, acc.: 63.28%] [G loss: 0.618543]\n",
      "epoch:13 step:12371 [D loss: 0.503818, acc.: 76.56%] [G loss: 0.557541]\n",
      "epoch:13 step:12372 [D loss: 0.504238, acc.: 74.22%] [G loss: 0.740886]\n",
      "epoch:13 step:12373 [D loss: 0.498286, acc.: 75.00%] [G loss: 0.730630]\n",
      "epoch:13 step:12374 [D loss: 0.539438, acc.: 71.88%] [G loss: 0.491552]\n",
      "epoch:13 step:12375 [D loss: 0.465198, acc.: 76.56%] [G loss: 0.742263]\n",
      "epoch:13 step:12376 [D loss: 0.594250, acc.: 67.19%] [G loss: 0.575080]\n",
      "epoch:13 step:12377 [D loss: 0.535802, acc.: 71.09%] [G loss: 0.569406]\n",
      "epoch:13 step:12378 [D loss: 0.515762, acc.: 72.66%] [G loss: 0.554317]\n",
      "epoch:13 step:12379 [D loss: 0.462831, acc.: 77.34%] [G loss: 0.608128]\n",
      "epoch:13 step:12380 [D loss: 0.510393, acc.: 71.88%] [G loss: 0.657132]\n",
      "epoch:13 step:12381 [D loss: 0.618874, acc.: 60.94%] [G loss: 0.528251]\n",
      "epoch:13 step:12382 [D loss: 0.520157, acc.: 75.78%] [G loss: 0.671203]\n",
      "epoch:13 step:12383 [D loss: 0.542249, acc.: 71.88%] [G loss: 0.678154]\n",
      "epoch:13 step:12384 [D loss: 0.590838, acc.: 64.06%] [G loss: 0.479492]\n",
      "epoch:13 step:12385 [D loss: 0.613019, acc.: 66.41%] [G loss: 0.492865]\n",
      "epoch:13 step:12386 [D loss: 0.543692, acc.: 75.00%] [G loss: 0.545436]\n",
      "epoch:13 step:12387 [D loss: 0.499672, acc.: 71.88%] [G loss: 0.646379]\n",
      "epoch:13 step:12388 [D loss: 0.489650, acc.: 76.56%] [G loss: 0.621924]\n",
      "epoch:13 step:12389 [D loss: 0.477196, acc.: 77.34%] [G loss: 0.698414]\n",
      "epoch:13 step:12390 [D loss: 0.471145, acc.: 78.91%] [G loss: 0.842393]\n",
      "epoch:13 step:12391 [D loss: 0.668433, acc.: 61.72%] [G loss: 0.547476]\n",
      "epoch:13 step:12392 [D loss: 0.562554, acc.: 68.75%] [G loss: 0.580976]\n",
      "epoch:13 step:12393 [D loss: 0.562465, acc.: 67.97%] [G loss: 0.611000]\n",
      "epoch:13 step:12394 [D loss: 0.459945, acc.: 76.56%] [G loss: 0.660216]\n",
      "epoch:13 step:12395 [D loss: 0.564364, acc.: 71.09%] [G loss: 0.639181]\n",
      "epoch:13 step:12396 [D loss: 0.539710, acc.: 67.97%] [G loss: 0.596838]\n",
      "epoch:13 step:12397 [D loss: 0.521500, acc.: 70.31%] [G loss: 0.455874]\n",
      "epoch:13 step:12398 [D loss: 0.541508, acc.: 70.31%] [G loss: 0.512199]\n",
      "epoch:13 step:12399 [D loss: 0.541860, acc.: 71.09%] [G loss: 0.650792]\n",
      "epoch:13 step:12400 [D loss: 0.479553, acc.: 80.47%] [G loss: 0.640679]\n",
      "epoch:13 step:12401 [D loss: 0.687104, acc.: 61.72%] [G loss: 0.589313]\n",
      "epoch:13 step:12402 [D loss: 0.532059, acc.: 71.88%] [G loss: 0.541210]\n",
      "epoch:13 step:12403 [D loss: 0.470378, acc.: 75.00%] [G loss: 0.910894]\n",
      "epoch:13 step:12404 [D loss: 0.499050, acc.: 79.69%] [G loss: 0.630226]\n",
      "epoch:13 step:12405 [D loss: 0.607385, acc.: 65.62%] [G loss: 0.525295]\n",
      "epoch:13 step:12406 [D loss: 0.557528, acc.: 71.09%] [G loss: 0.543129]\n",
      "epoch:13 step:12407 [D loss: 0.648089, acc.: 57.81%] [G loss: 0.485377]\n",
      "epoch:13 step:12408 [D loss: 0.537917, acc.: 71.88%] [G loss: 0.557699]\n",
      "epoch:13 step:12409 [D loss: 0.602313, acc.: 64.84%] [G loss: 0.433850]\n",
      "epoch:13 step:12410 [D loss: 0.523565, acc.: 77.34%] [G loss: 0.641132]\n",
      "epoch:13 step:12411 [D loss: 0.477454, acc.: 79.69%] [G loss: 0.568024]\n",
      "epoch:13 step:12412 [D loss: 0.446753, acc.: 78.91%] [G loss: 0.848284]\n",
      "epoch:13 step:12413 [D loss: 0.443908, acc.: 80.47%] [G loss: 0.897516]\n",
      "epoch:13 step:12414 [D loss: 0.550434, acc.: 72.66%] [G loss: 0.818298]\n",
      "epoch:13 step:12415 [D loss: 0.550193, acc.: 70.31%] [G loss: 0.644975]\n",
      "epoch:13 step:12416 [D loss: 0.569892, acc.: 72.66%] [G loss: 0.687941]\n",
      "epoch:13 step:12417 [D loss: 0.492934, acc.: 78.12%] [G loss: 0.638223]\n",
      "epoch:13 step:12418 [D loss: 0.528115, acc.: 71.09%] [G loss: 0.747793]\n",
      "epoch:13 step:12419 [D loss: 0.550137, acc.: 67.97%] [G loss: 0.554091]\n",
      "epoch:13 step:12420 [D loss: 0.531106, acc.: 68.75%] [G loss: 0.645210]\n",
      "epoch:13 step:12421 [D loss: 0.528560, acc.: 72.66%] [G loss: 0.563192]\n",
      "epoch:13 step:12422 [D loss: 0.529523, acc.: 67.19%] [G loss: 0.642800]\n",
      "epoch:13 step:12423 [D loss: 0.455984, acc.: 79.69%] [G loss: 0.869525]\n",
      "epoch:13 step:12424 [D loss: 0.497467, acc.: 72.66%] [G loss: 0.694524]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:13 step:12425 [D loss: 0.492326, acc.: 72.66%] [G loss: 0.711979]\n",
      "epoch:13 step:12426 [D loss: 0.540622, acc.: 70.31%] [G loss: 0.774206]\n",
      "epoch:13 step:12427 [D loss: 0.441799, acc.: 82.81%] [G loss: 0.850938]\n",
      "epoch:13 step:12428 [D loss: 0.553880, acc.: 70.31%] [G loss: 0.705654]\n",
      "epoch:13 step:12429 [D loss: 0.471486, acc.: 74.22%] [G loss: 0.828320]\n",
      "epoch:13 step:12430 [D loss: 0.551504, acc.: 68.75%] [G loss: 0.679055]\n",
      "epoch:13 step:12431 [D loss: 0.560548, acc.: 66.41%] [G loss: 0.692506]\n",
      "epoch:13 step:12432 [D loss: 0.586101, acc.: 69.53%] [G loss: 0.682110]\n",
      "epoch:13 step:12433 [D loss: 0.509011, acc.: 75.00%] [G loss: 0.837042]\n",
      "epoch:13 step:12434 [D loss: 0.542492, acc.: 71.09%] [G loss: 0.678212]\n",
      "epoch:13 step:12435 [D loss: 0.505478, acc.: 77.34%] [G loss: 0.628074]\n",
      "epoch:13 step:12436 [D loss: 0.589312, acc.: 67.97%] [G loss: 0.537948]\n",
      "epoch:13 step:12437 [D loss: 0.553428, acc.: 67.97%] [G loss: 0.644500]\n",
      "epoch:13 step:12438 [D loss: 0.552108, acc.: 70.31%] [G loss: 0.576407]\n",
      "epoch:13 step:12439 [D loss: 0.518143, acc.: 70.31%] [G loss: 0.574119]\n",
      "epoch:13 step:12440 [D loss: 0.506024, acc.: 71.88%] [G loss: 0.669536]\n",
      "epoch:13 step:12441 [D loss: 0.543427, acc.: 67.97%] [G loss: 0.706311]\n",
      "epoch:13 step:12442 [D loss: 0.527214, acc.: 72.66%] [G loss: 0.696869]\n",
      "epoch:13 step:12443 [D loss: 0.535584, acc.: 71.09%] [G loss: 0.715050]\n",
      "epoch:13 step:12444 [D loss: 0.603013, acc.: 71.09%] [G loss: 0.467229]\n",
      "epoch:13 step:12445 [D loss: 0.511558, acc.: 73.44%] [G loss: 0.583926]\n",
      "epoch:13 step:12446 [D loss: 0.561229, acc.: 71.88%] [G loss: 0.615151]\n",
      "epoch:13 step:12447 [D loss: 0.534748, acc.: 71.88%] [G loss: 0.584018]\n",
      "epoch:13 step:12448 [D loss: 0.571667, acc.: 67.19%] [G loss: 0.578665]\n",
      "epoch:13 step:12449 [D loss: 0.547436, acc.: 67.97%] [G loss: 0.708881]\n",
      "epoch:13 step:12450 [D loss: 0.565812, acc.: 71.88%] [G loss: 0.592832]\n",
      "epoch:13 step:12451 [D loss: 0.481133, acc.: 75.78%] [G loss: 0.639801]\n",
      "epoch:13 step:12452 [D loss: 0.469137, acc.: 79.69%] [G loss: 0.726171]\n",
      "epoch:13 step:12453 [D loss: 0.557079, acc.: 71.09%] [G loss: 0.612090]\n",
      "epoch:13 step:12454 [D loss: 0.491178, acc.: 71.88%] [G loss: 0.799346]\n",
      "epoch:13 step:12455 [D loss: 0.466011, acc.: 80.47%] [G loss: 0.648198]\n",
      "epoch:13 step:12456 [D loss: 0.558695, acc.: 68.75%] [G loss: 0.813576]\n",
      "epoch:13 step:12457 [D loss: 0.432602, acc.: 82.03%] [G loss: 0.701381]\n",
      "epoch:13 step:12458 [D loss: 0.641621, acc.: 63.28%] [G loss: 0.596584]\n",
      "epoch:13 step:12459 [D loss: 0.562361, acc.: 67.97%] [G loss: 0.590704]\n",
      "epoch:13 step:12460 [D loss: 0.556819, acc.: 65.62%] [G loss: 0.498464]\n",
      "epoch:13 step:12461 [D loss: 0.518388, acc.: 67.97%] [G loss: 0.568410]\n",
      "epoch:13 step:12462 [D loss: 0.546724, acc.: 71.09%] [G loss: 0.491903]\n",
      "epoch:13 step:12463 [D loss: 0.535058, acc.: 68.75%] [G loss: 0.557376]\n",
      "epoch:13 step:12464 [D loss: 0.490442, acc.: 76.56%] [G loss: 0.641728]\n",
      "epoch:13 step:12465 [D loss: 0.505516, acc.: 68.75%] [G loss: 0.758424]\n",
      "epoch:13 step:12466 [D loss: 0.508288, acc.: 72.66%] [G loss: 0.625132]\n",
      "epoch:13 step:12467 [D loss: 0.490805, acc.: 80.47%] [G loss: 0.660290]\n",
      "epoch:13 step:12468 [D loss: 0.568983, acc.: 64.84%] [G loss: 0.666721]\n",
      "epoch:13 step:12469 [D loss: 0.563219, acc.: 70.31%] [G loss: 0.639425]\n",
      "epoch:13 step:12470 [D loss: 0.541612, acc.: 65.62%] [G loss: 0.748538]\n",
      "epoch:13 step:12471 [D loss: 0.546975, acc.: 69.53%] [G loss: 0.744727]\n",
      "epoch:13 step:12472 [D loss: 0.560486, acc.: 70.31%] [G loss: 0.591918]\n",
      "epoch:13 step:12473 [D loss: 0.524319, acc.: 78.12%] [G loss: 0.562478]\n",
      "epoch:13 step:12474 [D loss: 0.583658, acc.: 67.19%] [G loss: 0.552604]\n",
      "epoch:13 step:12475 [D loss: 0.591773, acc.: 68.75%] [G loss: 0.568376]\n",
      "epoch:13 step:12476 [D loss: 0.570233, acc.: 68.75%] [G loss: 0.483052]\n",
      "epoch:13 step:12477 [D loss: 0.485405, acc.: 75.00%] [G loss: 0.577773]\n",
      "epoch:13 step:12478 [D loss: 0.561578, acc.: 71.09%] [G loss: 0.577192]\n",
      "epoch:13 step:12479 [D loss: 0.497253, acc.: 75.78%] [G loss: 0.631725]\n",
      "epoch:13 step:12480 [D loss: 0.456573, acc.: 76.56%] [G loss: 0.871828]\n",
      "epoch:13 step:12481 [D loss: 0.458586, acc.: 78.91%] [G loss: 0.606504]\n",
      "epoch:13 step:12482 [D loss: 0.610677, acc.: 68.75%] [G loss: 0.618374]\n",
      "epoch:13 step:12483 [D loss: 0.489014, acc.: 74.22%] [G loss: 0.775934]\n",
      "epoch:13 step:12484 [D loss: 0.582527, acc.: 69.53%] [G loss: 0.664653]\n",
      "epoch:13 step:12485 [D loss: 0.518452, acc.: 75.00%] [G loss: 0.660516]\n",
      "epoch:13 step:12486 [D loss: 0.539052, acc.: 71.88%] [G loss: 0.671798]\n",
      "epoch:13 step:12487 [D loss: 0.550302, acc.: 73.44%] [G loss: 0.654319]\n",
      "epoch:13 step:12488 [D loss: 0.504506, acc.: 77.34%] [G loss: 0.719925]\n",
      "epoch:13 step:12489 [D loss: 0.546741, acc.: 72.66%] [G loss: 0.613359]\n",
      "epoch:13 step:12490 [D loss: 0.468873, acc.: 75.78%] [G loss: 0.679523]\n",
      "epoch:13 step:12491 [D loss: 0.535071, acc.: 75.78%] [G loss: 0.704275]\n",
      "epoch:13 step:12492 [D loss: 0.444929, acc.: 79.69%] [G loss: 0.724175]\n",
      "epoch:13 step:12493 [D loss: 0.480273, acc.: 82.03%] [G loss: 0.922522]\n",
      "epoch:13 step:12494 [D loss: 0.541985, acc.: 71.09%] [G loss: 1.076478]\n",
      "epoch:13 step:12495 [D loss: 0.472328, acc.: 77.34%] [G loss: 0.984729]\n",
      "epoch:13 step:12496 [D loss: 0.457998, acc.: 78.91%] [G loss: 0.996267]\n",
      "epoch:13 step:12497 [D loss: 0.658689, acc.: 67.19%] [G loss: 0.629432]\n",
      "epoch:13 step:12498 [D loss: 0.590477, acc.: 65.62%] [G loss: 0.613424]\n",
      "epoch:13 step:12499 [D loss: 0.566450, acc.: 67.19%] [G loss: 0.553619]\n",
      "epoch:13 step:12500 [D loss: 0.556453, acc.: 67.97%] [G loss: 0.587786]\n",
      "epoch:13 step:12501 [D loss: 0.578538, acc.: 65.62%] [G loss: 0.559926]\n",
      "epoch:13 step:12502 [D loss: 0.466761, acc.: 75.78%] [G loss: 0.674568]\n",
      "epoch:13 step:12503 [D loss: 0.575355, acc.: 67.97%] [G loss: 0.571862]\n",
      "epoch:13 step:12504 [D loss: 0.586985, acc.: 69.53%] [G loss: 0.563506]\n",
      "epoch:13 step:12505 [D loss: 0.562131, acc.: 70.31%] [G loss: 0.451510]\n",
      "epoch:13 step:12506 [D loss: 0.542827, acc.: 71.88%] [G loss: 0.616907]\n",
      "epoch:13 step:12507 [D loss: 0.507679, acc.: 71.88%] [G loss: 0.679133]\n",
      "epoch:13 step:12508 [D loss: 0.526177, acc.: 73.44%] [G loss: 0.739256]\n",
      "epoch:13 step:12509 [D loss: 0.479495, acc.: 76.56%] [G loss: 0.726670]\n",
      "epoch:13 step:12510 [D loss: 0.534628, acc.: 69.53%] [G loss: 0.717088]\n",
      "epoch:13 step:12511 [D loss: 0.538763, acc.: 69.53%] [G loss: 0.625421]\n",
      "epoch:13 step:12512 [D loss: 0.542449, acc.: 72.66%] [G loss: 0.498058]\n",
      "epoch:13 step:12513 [D loss: 0.499579, acc.: 71.09%] [G loss: 0.612898]\n",
      "epoch:13 step:12514 [D loss: 0.484316, acc.: 71.88%] [G loss: 0.597712]\n",
      "epoch:13 step:12515 [D loss: 0.533260, acc.: 72.66%] [G loss: 0.698175]\n",
      "epoch:13 step:12516 [D loss: 0.452148, acc.: 81.25%] [G loss: 0.615218]\n",
      "epoch:13 step:12517 [D loss: 0.499866, acc.: 77.34%] [G loss: 0.747411]\n",
      "epoch:13 step:12518 [D loss: 0.545297, acc.: 68.75%] [G loss: 0.711746]\n",
      "epoch:13 step:12519 [D loss: 0.511474, acc.: 70.31%] [G loss: 0.817453]\n",
      "epoch:13 step:12520 [D loss: 0.542878, acc.: 70.31%] [G loss: 0.740064]\n",
      "epoch:13 step:12521 [D loss: 0.449341, acc.: 75.78%] [G loss: 0.680590]\n",
      "epoch:13 step:12522 [D loss: 0.572415, acc.: 73.44%] [G loss: 0.668114]\n",
      "epoch:13 step:12523 [D loss: 0.696769, acc.: 57.03%] [G loss: 0.610635]\n",
      "epoch:13 step:12524 [D loss: 0.502365, acc.: 75.00%] [G loss: 0.578037]\n",
      "epoch:13 step:12525 [D loss: 0.500127, acc.: 74.22%] [G loss: 0.687401]\n",
      "epoch:13 step:12526 [D loss: 0.547246, acc.: 69.53%] [G loss: 0.898805]\n",
      "epoch:13 step:12527 [D loss: 0.519675, acc.: 72.66%] [G loss: 0.774141]\n",
      "epoch:13 step:12528 [D loss: 0.499352, acc.: 80.47%] [G loss: 0.922345]\n",
      "epoch:13 step:12529 [D loss: 0.654577, acc.: 66.41%] [G loss: 0.692911]\n",
      "epoch:13 step:12530 [D loss: 0.639977, acc.: 64.06%] [G loss: 0.461345]\n",
      "epoch:13 step:12531 [D loss: 0.531846, acc.: 72.66%] [G loss: 0.462036]\n",
      "epoch:13 step:12532 [D loss: 0.510604, acc.: 74.22%] [G loss: 0.485769]\n",
      "epoch:13 step:12533 [D loss: 0.611997, acc.: 64.06%] [G loss: 0.637481]\n",
      "epoch:13 step:12534 [D loss: 0.553222, acc.: 69.53%] [G loss: 0.657909]\n",
      "epoch:13 step:12535 [D loss: 0.384778, acc.: 83.59%] [G loss: 0.765360]\n",
      "epoch:13 step:12536 [D loss: 0.529463, acc.: 72.66%] [G loss: 0.823649]\n",
      "epoch:13 step:12537 [D loss: 0.571769, acc.: 67.19%] [G loss: 0.756658]\n",
      "epoch:13 step:12538 [D loss: 0.475022, acc.: 76.56%] [G loss: 0.777295]\n",
      "epoch:13 step:12539 [D loss: 0.442271, acc.: 82.03%] [G loss: 0.804819]\n",
      "epoch:13 step:12540 [D loss: 0.475707, acc.: 76.56%] [G loss: 1.004045]\n",
      "epoch:13 step:12541 [D loss: 0.509325, acc.: 71.09%] [G loss: 0.692087]\n",
      "epoch:13 step:12542 [D loss: 0.538668, acc.: 71.09%] [G loss: 0.764663]\n",
      "epoch:13 step:12543 [D loss: 0.559504, acc.: 70.31%] [G loss: 0.849231]\n",
      "epoch:13 step:12544 [D loss: 0.545212, acc.: 67.97%] [G loss: 0.591736]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:13 step:12545 [D loss: 0.534167, acc.: 69.53%] [G loss: 0.761588]\n",
      "epoch:13 step:12546 [D loss: 0.540694, acc.: 71.88%] [G loss: 0.641804]\n",
      "epoch:13 step:12547 [D loss: 0.466672, acc.: 79.69%] [G loss: 0.876261]\n",
      "epoch:13 step:12548 [D loss: 0.535870, acc.: 71.88%] [G loss: 0.773375]\n",
      "epoch:13 step:12549 [D loss: 0.484582, acc.: 73.44%] [G loss: 0.638819]\n",
      "epoch:13 step:12550 [D loss: 0.533451, acc.: 70.31%] [G loss: 0.480509]\n",
      "epoch:13 step:12551 [D loss: 0.471793, acc.: 77.34%] [G loss: 0.654762]\n",
      "epoch:13 step:12552 [D loss: 0.517794, acc.: 73.44%] [G loss: 0.645090]\n",
      "epoch:13 step:12553 [D loss: 0.595279, acc.: 64.84%] [G loss: 0.603018]\n",
      "epoch:13 step:12554 [D loss: 0.579662, acc.: 67.19%] [G loss: 0.670289]\n",
      "epoch:13 step:12555 [D loss: 0.437169, acc.: 78.91%] [G loss: 0.701478]\n",
      "epoch:13 step:12556 [D loss: 0.574053, acc.: 65.62%] [G loss: 0.692923]\n",
      "epoch:13 step:12557 [D loss: 0.668070, acc.: 60.16%] [G loss: 0.461438]\n",
      "epoch:13 step:12558 [D loss: 0.589320, acc.: 66.41%] [G loss: 0.426323]\n",
      "epoch:13 step:12559 [D loss: 0.487420, acc.: 76.56%] [G loss: 0.700685]\n",
      "epoch:13 step:12560 [D loss: 0.528859, acc.: 71.88%] [G loss: 0.608918]\n",
      "epoch:13 step:12561 [D loss: 0.644551, acc.: 58.59%] [G loss: 0.393615]\n",
      "epoch:13 step:12562 [D loss: 0.450278, acc.: 82.03%] [G loss: 0.550394]\n",
      "epoch:13 step:12563 [D loss: 0.519423, acc.: 71.09%] [G loss: 0.600527]\n",
      "epoch:13 step:12564 [D loss: 0.524161, acc.: 73.44%] [G loss: 0.694170]\n",
      "epoch:13 step:12565 [D loss: 0.516803, acc.: 75.78%] [G loss: 0.549407]\n",
      "epoch:13 step:12566 [D loss: 0.471705, acc.: 77.34%] [G loss: 0.604991]\n",
      "epoch:13 step:12567 [D loss: 0.633868, acc.: 65.62%] [G loss: 0.549702]\n",
      "epoch:13 step:12568 [D loss: 0.549281, acc.: 69.53%] [G loss: 0.562794]\n",
      "epoch:13 step:12569 [D loss: 0.546533, acc.: 73.44%] [G loss: 0.685485]\n",
      "epoch:13 step:12570 [D loss: 0.541448, acc.: 75.00%] [G loss: 0.601166]\n",
      "epoch:13 step:12571 [D loss: 0.633126, acc.: 61.72%] [G loss: 0.662163]\n",
      "epoch:13 step:12572 [D loss: 0.554580, acc.: 67.19%] [G loss: 0.407426]\n",
      "epoch:13 step:12573 [D loss: 0.536240, acc.: 68.75%] [G loss: 0.570186]\n",
      "epoch:13 step:12574 [D loss: 0.574144, acc.: 69.53%] [G loss: 0.587332]\n",
      "epoch:13 step:12575 [D loss: 0.534976, acc.: 71.88%] [G loss: 0.466318]\n",
      "epoch:13 step:12576 [D loss: 0.517505, acc.: 75.00%] [G loss: 0.548018]\n",
      "epoch:13 step:12577 [D loss: 0.601324, acc.: 67.19%] [G loss: 0.469025]\n",
      "epoch:13 step:12578 [D loss: 0.590098, acc.: 64.84%] [G loss: 0.513198]\n",
      "epoch:13 step:12579 [D loss: 0.451796, acc.: 80.47%] [G loss: 0.776544]\n",
      "epoch:13 step:12580 [D loss: 0.532187, acc.: 76.56%] [G loss: 0.731698]\n",
      "epoch:13 step:12581 [D loss: 0.662929, acc.: 58.59%] [G loss: 0.501362]\n",
      "epoch:13 step:12582 [D loss: 0.641823, acc.: 60.94%] [G loss: 0.377369]\n",
      "epoch:13 step:12583 [D loss: 0.413793, acc.: 84.38%] [G loss: 0.656988]\n",
      "epoch:13 step:12584 [D loss: 0.516916, acc.: 74.22%] [G loss: 0.696436]\n",
      "epoch:13 step:12585 [D loss: 0.565580, acc.: 71.09%] [G loss: 0.721625]\n",
      "epoch:13 step:12586 [D loss: 0.558745, acc.: 68.75%] [G loss: 0.857089]\n",
      "epoch:13 step:12587 [D loss: 0.542762, acc.: 70.31%] [G loss: 0.792661]\n",
      "epoch:13 step:12588 [D loss: 0.595757, acc.: 65.62%] [G loss: 0.756640]\n",
      "epoch:13 step:12589 [D loss: 0.587382, acc.: 67.97%] [G loss: 0.645755]\n",
      "epoch:13 step:12590 [D loss: 0.602209, acc.: 64.06%] [G loss: 0.723528]\n",
      "epoch:13 step:12591 [D loss: 0.578932, acc.: 67.97%] [G loss: 0.592809]\n",
      "epoch:13 step:12592 [D loss: 0.605919, acc.: 67.97%] [G loss: 0.497579]\n",
      "epoch:13 step:12593 [D loss: 0.623867, acc.: 64.06%] [G loss: 0.453506]\n",
      "epoch:13 step:12594 [D loss: 0.534725, acc.: 74.22%] [G loss: 0.481710]\n",
      "epoch:13 step:12595 [D loss: 0.494579, acc.: 75.78%] [G loss: 0.684617]\n",
      "epoch:13 step:12596 [D loss: 0.575101, acc.: 69.53%] [G loss: 0.577610]\n",
      "epoch:13 step:12597 [D loss: 0.500107, acc.: 73.44%] [G loss: 0.673877]\n",
      "epoch:13 step:12598 [D loss: 0.540683, acc.: 75.78%] [G loss: 0.680965]\n",
      "epoch:13 step:12599 [D loss: 0.596474, acc.: 62.50%] [G loss: 0.581251]\n",
      "epoch:13 step:12600 [D loss: 0.590052, acc.: 69.53%] [G loss: 0.496646]\n",
      "epoch:13 step:12601 [D loss: 0.612644, acc.: 60.16%] [G loss: 0.482686]\n",
      "epoch:13 step:12602 [D loss: 0.561770, acc.: 72.66%] [G loss: 0.539951]\n",
      "epoch:13 step:12603 [D loss: 0.573694, acc.: 68.75%] [G loss: 0.536282]\n",
      "epoch:13 step:12604 [D loss: 0.541983, acc.: 73.44%] [G loss: 0.449667]\n",
      "epoch:13 step:12605 [D loss: 0.554425, acc.: 67.19%] [G loss: 0.645950]\n",
      "epoch:13 step:12606 [D loss: 0.509099, acc.: 70.31%] [G loss: 0.600035]\n",
      "epoch:13 step:12607 [D loss: 0.476065, acc.: 79.69%] [G loss: 0.721303]\n",
      "epoch:13 step:12608 [D loss: 0.477712, acc.: 74.22%] [G loss: 0.806950]\n",
      "epoch:13 step:12609 [D loss: 0.508238, acc.: 76.56%] [G loss: 0.867267]\n",
      "epoch:13 step:12610 [D loss: 0.472728, acc.: 77.34%] [G loss: 0.659532]\n",
      "epoch:13 step:12611 [D loss: 0.536511, acc.: 71.88%] [G loss: 0.627960]\n",
      "epoch:13 step:12612 [D loss: 0.528053, acc.: 66.41%] [G loss: 0.587058]\n",
      "epoch:13 step:12613 [D loss: 0.595604, acc.: 67.19%] [G loss: 0.710562]\n",
      "epoch:13 step:12614 [D loss: 0.553129, acc.: 67.97%] [G loss: 0.545286]\n",
      "epoch:13 step:12615 [D loss: 0.507645, acc.: 71.88%] [G loss: 0.608025]\n",
      "epoch:13 step:12616 [D loss: 0.565351, acc.: 69.53%] [G loss: 0.585217]\n",
      "epoch:13 step:12617 [D loss: 0.532090, acc.: 68.75%] [G loss: 0.644121]\n",
      "epoch:13 step:12618 [D loss: 0.680187, acc.: 61.72%] [G loss: 0.482011]\n",
      "epoch:13 step:12619 [D loss: 0.574155, acc.: 67.97%] [G loss: 0.487615]\n",
      "epoch:13 step:12620 [D loss: 0.504388, acc.: 78.12%] [G loss: 0.580169]\n",
      "epoch:13 step:12621 [D loss: 0.513368, acc.: 68.75%] [G loss: 0.563309]\n",
      "epoch:13 step:12622 [D loss: 0.507755, acc.: 69.53%] [G loss: 0.671777]\n",
      "epoch:13 step:12623 [D loss: 0.552937, acc.: 67.19%] [G loss: 0.761672]\n",
      "epoch:13 step:12624 [D loss: 0.518733, acc.: 74.22%] [G loss: 0.601542]\n",
      "epoch:13 step:12625 [D loss: 0.493492, acc.: 75.00%] [G loss: 0.857186]\n",
      "epoch:13 step:12626 [D loss: 0.592715, acc.: 61.72%] [G loss: 0.745072]\n",
      "epoch:13 step:12627 [D loss: 0.525641, acc.: 72.66%] [G loss: 0.646069]\n",
      "epoch:13 step:12628 [D loss: 0.567880, acc.: 66.41%] [G loss: 0.611119]\n",
      "epoch:13 step:12629 [D loss: 0.511563, acc.: 75.00%] [G loss: 0.619268]\n",
      "epoch:13 step:12630 [D loss: 0.475572, acc.: 76.56%] [G loss: 0.667973]\n",
      "epoch:13 step:12631 [D loss: 0.461196, acc.: 76.56%] [G loss: 0.734935]\n",
      "epoch:13 step:12632 [D loss: 0.404307, acc.: 82.81%] [G loss: 0.733568]\n",
      "epoch:13 step:12633 [D loss: 0.468310, acc.: 76.56%] [G loss: 0.859745]\n",
      "epoch:13 step:12634 [D loss: 0.527278, acc.: 73.44%] [G loss: 0.739314]\n",
      "epoch:13 step:12635 [D loss: 0.520599, acc.: 75.78%] [G loss: 0.660885]\n",
      "epoch:13 step:12636 [D loss: 0.549430, acc.: 69.53%] [G loss: 0.822629]\n",
      "epoch:13 step:12637 [D loss: 0.597637, acc.: 67.19%] [G loss: 0.670432]\n",
      "epoch:13 step:12638 [D loss: 0.485276, acc.: 77.34%] [G loss: 0.700761]\n",
      "epoch:13 step:12639 [D loss: 0.627504, acc.: 64.84%] [G loss: 0.462152]\n",
      "epoch:13 step:12640 [D loss: 0.518615, acc.: 71.09%] [G loss: 0.570742]\n",
      "epoch:13 step:12641 [D loss: 0.505459, acc.: 69.53%] [G loss: 0.625581]\n",
      "epoch:13 step:12642 [D loss: 0.481650, acc.: 75.78%] [G loss: 0.798927]\n",
      "epoch:13 step:12643 [D loss: 0.584059, acc.: 67.19%] [G loss: 0.618957]\n",
      "epoch:13 step:12644 [D loss: 0.515899, acc.: 71.88%] [G loss: 0.500347]\n",
      "epoch:13 step:12645 [D loss: 0.484761, acc.: 73.44%] [G loss: 0.557817]\n",
      "epoch:13 step:12646 [D loss: 0.586918, acc.: 68.75%] [G loss: 0.491682]\n",
      "epoch:13 step:12647 [D loss: 0.499700, acc.: 72.66%] [G loss: 0.552834]\n",
      "epoch:13 step:12648 [D loss: 0.538822, acc.: 68.75%] [G loss: 0.537080]\n",
      "epoch:13 step:12649 [D loss: 0.522201, acc.: 70.31%] [G loss: 0.555480]\n",
      "epoch:13 step:12650 [D loss: 0.511457, acc.: 72.66%] [G loss: 0.613656]\n",
      "epoch:13 step:12651 [D loss: 0.492732, acc.: 75.00%] [G loss: 0.633078]\n",
      "epoch:13 step:12652 [D loss: 0.450983, acc.: 75.78%] [G loss: 0.798623]\n",
      "epoch:13 step:12653 [D loss: 0.452843, acc.: 79.69%] [G loss: 0.938790]\n",
      "epoch:13 step:12654 [D loss: 0.651975, acc.: 64.84%] [G loss: 0.754312]\n",
      "epoch:13 step:12655 [D loss: 0.582669, acc.: 67.97%] [G loss: 0.571295]\n",
      "epoch:13 step:12656 [D loss: 0.513911, acc.: 72.66%] [G loss: 0.564179]\n",
      "epoch:13 step:12657 [D loss: 0.531684, acc.: 75.00%] [G loss: 0.678945]\n",
      "epoch:13 step:12658 [D loss: 0.640057, acc.: 64.06%] [G loss: 0.623215]\n",
      "epoch:13 step:12659 [D loss: 0.543512, acc.: 71.88%] [G loss: 0.671116]\n",
      "epoch:13 step:12660 [D loss: 0.485892, acc.: 75.00%] [G loss: 0.593225]\n",
      "epoch:13 step:12661 [D loss: 0.601490, acc.: 66.41%] [G loss: 0.526910]\n",
      "epoch:13 step:12662 [D loss: 0.471545, acc.: 81.25%] [G loss: 0.592317]\n",
      "epoch:13 step:12663 [D loss: 0.614260, acc.: 61.72%] [G loss: 0.598646]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:13 step:12664 [D loss: 0.534860, acc.: 73.44%] [G loss: 0.781003]\n",
      "epoch:13 step:12665 [D loss: 0.548882, acc.: 73.44%] [G loss: 0.759409]\n",
      "epoch:13 step:12666 [D loss: 0.514493, acc.: 75.78%] [G loss: 0.696565]\n",
      "epoch:13 step:12667 [D loss: 0.560420, acc.: 67.19%] [G loss: 0.579336]\n",
      "epoch:13 step:12668 [D loss: 0.507459, acc.: 72.66%] [G loss: 0.671582]\n",
      "epoch:13 step:12669 [D loss: 0.472293, acc.: 72.66%] [G loss: 0.741674]\n",
      "epoch:13 step:12670 [D loss: 0.525564, acc.: 75.78%] [G loss: 0.524521]\n",
      "epoch:13 step:12671 [D loss: 0.556274, acc.: 68.75%] [G loss: 0.622968]\n",
      "epoch:13 step:12672 [D loss: 0.494906, acc.: 77.34%] [G loss: 0.634546]\n",
      "epoch:13 step:12673 [D loss: 0.552240, acc.: 68.75%] [G loss: 0.672975]\n",
      "epoch:13 step:12674 [D loss: 0.564260, acc.: 68.75%] [G loss: 0.576108]\n",
      "epoch:13 step:12675 [D loss: 0.565481, acc.: 73.44%] [G loss: 0.570335]\n",
      "epoch:13 step:12676 [D loss: 0.487491, acc.: 77.34%] [G loss: 0.560559]\n",
      "epoch:13 step:12677 [D loss: 0.573599, acc.: 70.31%] [G loss: 0.576477]\n",
      "epoch:13 step:12678 [D loss: 0.598842, acc.: 66.41%] [G loss: 0.616632]\n",
      "epoch:13 step:12679 [D loss: 0.535810, acc.: 71.09%] [G loss: 0.763195]\n",
      "epoch:13 step:12680 [D loss: 0.467737, acc.: 73.44%] [G loss: 0.788242]\n",
      "epoch:13 step:12681 [D loss: 0.658732, acc.: 57.03%] [G loss: 0.639676]\n",
      "epoch:13 step:12682 [D loss: 0.685078, acc.: 62.50%] [G loss: 0.475955]\n",
      "epoch:13 step:12683 [D loss: 0.576620, acc.: 64.84%] [G loss: 0.631526]\n",
      "epoch:13 step:12684 [D loss: 0.489491, acc.: 78.91%] [G loss: 0.598677]\n",
      "epoch:13 step:12685 [D loss: 0.443807, acc.: 83.59%] [G loss: 0.675219]\n",
      "epoch:13 step:12686 [D loss: 0.524535, acc.: 77.34%] [G loss: 0.650529]\n",
      "epoch:13 step:12687 [D loss: 0.494830, acc.: 75.00%] [G loss: 0.696993]\n",
      "epoch:13 step:12688 [D loss: 0.504550, acc.: 75.78%] [G loss: 0.733295]\n",
      "epoch:13 step:12689 [D loss: 0.458516, acc.: 78.91%] [G loss: 0.881661]\n",
      "epoch:13 step:12690 [D loss: 0.480804, acc.: 78.12%] [G loss: 0.774322]\n",
      "epoch:13 step:12691 [D loss: 0.578449, acc.: 71.09%] [G loss: 0.637716]\n",
      "epoch:13 step:12692 [D loss: 0.727649, acc.: 57.03%] [G loss: 0.547101]\n",
      "epoch:13 step:12693 [D loss: 0.538780, acc.: 70.31%] [G loss: 0.550137]\n",
      "epoch:13 step:12694 [D loss: 0.525997, acc.: 70.31%] [G loss: 0.580663]\n",
      "epoch:13 step:12695 [D loss: 0.523916, acc.: 70.31%] [G loss: 0.637458]\n",
      "epoch:13 step:12696 [D loss: 0.551928, acc.: 71.09%] [G loss: 0.732621]\n",
      "epoch:13 step:12697 [D loss: 0.514768, acc.: 72.66%] [G loss: 0.688858]\n",
      "epoch:13 step:12698 [D loss: 0.484700, acc.: 75.00%] [G loss: 0.783733]\n",
      "epoch:13 step:12699 [D loss: 0.553274, acc.: 65.62%] [G loss: 0.589024]\n",
      "epoch:13 step:12700 [D loss: 0.500659, acc.: 75.78%] [G loss: 0.691217]\n",
      "epoch:13 step:12701 [D loss: 0.533352, acc.: 74.22%] [G loss: 0.718940]\n",
      "epoch:13 step:12702 [D loss: 0.536774, acc.: 73.44%] [G loss: 0.586198]\n",
      "epoch:13 step:12703 [D loss: 0.490352, acc.: 70.31%] [G loss: 0.579948]\n",
      "epoch:13 step:12704 [D loss: 0.426995, acc.: 81.25%] [G loss: 0.738671]\n",
      "epoch:13 step:12705 [D loss: 0.535801, acc.: 71.09%] [G loss: 0.721825]\n",
      "epoch:13 step:12706 [D loss: 0.608683, acc.: 67.97%] [G loss: 0.611784]\n",
      "epoch:13 step:12707 [D loss: 0.499942, acc.: 75.78%] [G loss: 0.620851]\n",
      "epoch:13 step:12708 [D loss: 0.547063, acc.: 67.97%] [G loss: 0.637288]\n",
      "epoch:13 step:12709 [D loss: 0.628716, acc.: 60.16%] [G loss: 0.576008]\n",
      "epoch:13 step:12710 [D loss: 0.530090, acc.: 67.97%] [G loss: 0.615470]\n",
      "epoch:13 step:12711 [D loss: 0.614150, acc.: 60.94%] [G loss: 0.658959]\n",
      "epoch:13 step:12712 [D loss: 0.497701, acc.: 71.88%] [G loss: 0.907607]\n",
      "epoch:13 step:12713 [D loss: 0.592175, acc.: 66.41%] [G loss: 0.627362]\n",
      "epoch:13 step:12714 [D loss: 0.550708, acc.: 68.75%] [G loss: 0.532193]\n",
      "epoch:13 step:12715 [D loss: 0.498522, acc.: 74.22%] [G loss: 0.640068]\n",
      "epoch:13 step:12716 [D loss: 0.628880, acc.: 64.84%] [G loss: 0.583469]\n",
      "epoch:13 step:12717 [D loss: 0.509426, acc.: 72.66%] [G loss: 0.571425]\n",
      "epoch:13 step:12718 [D loss: 0.578151, acc.: 64.84%] [G loss: 0.542806]\n",
      "epoch:13 step:12719 [D loss: 0.522373, acc.: 72.66%] [G loss: 0.620836]\n",
      "epoch:13 step:12720 [D loss: 0.555023, acc.: 73.44%] [G loss: 0.585920]\n",
      "epoch:13 step:12721 [D loss: 0.564335, acc.: 67.97%] [G loss: 0.475481]\n",
      "epoch:13 step:12722 [D loss: 0.546214, acc.: 66.41%] [G loss: 0.555563]\n",
      "epoch:13 step:12723 [D loss: 0.639411, acc.: 64.84%] [G loss: 0.668122]\n",
      "epoch:13 step:12724 [D loss: 0.562418, acc.: 67.97%] [G loss: 0.579784]\n",
      "epoch:13 step:12725 [D loss: 0.563941, acc.: 66.41%] [G loss: 0.615934]\n",
      "epoch:13 step:12726 [D loss: 0.558466, acc.: 67.19%] [G loss: 0.629659]\n",
      "epoch:13 step:12727 [D loss: 0.494594, acc.: 75.78%] [G loss: 0.793945]\n",
      "epoch:13 step:12728 [D loss: 0.545069, acc.: 71.09%] [G loss: 0.714693]\n",
      "epoch:13 step:12729 [D loss: 0.526676, acc.: 68.75%] [G loss: 0.694537]\n",
      "epoch:13 step:12730 [D loss: 0.536880, acc.: 71.09%] [G loss: 0.618745]\n",
      "epoch:13 step:12731 [D loss: 0.487523, acc.: 76.56%] [G loss: 0.593779]\n",
      "epoch:13 step:12732 [D loss: 0.495460, acc.: 74.22%] [G loss: 0.577919]\n",
      "epoch:13 step:12733 [D loss: 0.446490, acc.: 76.56%] [G loss: 0.623820]\n",
      "epoch:13 step:12734 [D loss: 0.566962, acc.: 68.75%] [G loss: 0.564722]\n",
      "epoch:13 step:12735 [D loss: 0.444656, acc.: 76.56%] [G loss: 0.568956]\n",
      "epoch:13 step:12736 [D loss: 0.494772, acc.: 72.66%] [G loss: 0.605641]\n",
      "epoch:13 step:12737 [D loss: 0.515051, acc.: 76.56%] [G loss: 0.676163]\n",
      "epoch:13 step:12738 [D loss: 0.528067, acc.: 73.44%] [G loss: 0.646777]\n",
      "epoch:13 step:12739 [D loss: 0.470223, acc.: 76.56%] [G loss: 0.702533]\n",
      "epoch:13 step:12740 [D loss: 0.574865, acc.: 68.75%] [G loss: 0.663972]\n",
      "epoch:13 step:12741 [D loss: 0.563743, acc.: 70.31%] [G loss: 0.558708]\n",
      "epoch:13 step:12742 [D loss: 0.547586, acc.: 71.88%] [G loss: 0.680133]\n",
      "epoch:13 step:12743 [D loss: 0.539065, acc.: 68.75%] [G loss: 0.667606]\n",
      "epoch:13 step:12744 [D loss: 0.515703, acc.: 70.31%] [G loss: 0.667340]\n",
      "epoch:13 step:12745 [D loss: 0.512191, acc.: 75.78%] [G loss: 0.737685]\n",
      "epoch:13 step:12746 [D loss: 0.529220, acc.: 78.12%] [G loss: 0.901347]\n",
      "epoch:13 step:12747 [D loss: 0.706567, acc.: 62.50%] [G loss: 0.500582]\n",
      "epoch:13 step:12748 [D loss: 0.542128, acc.: 72.66%] [G loss: 0.585104]\n",
      "epoch:13 step:12749 [D loss: 0.462054, acc.: 78.91%] [G loss: 0.709327]\n",
      "epoch:13 step:12750 [D loss: 0.548403, acc.: 73.44%] [G loss: 0.730329]\n",
      "epoch:13 step:12751 [D loss: 0.502426, acc.: 76.56%] [G loss: 0.593916]\n",
      "epoch:13 step:12752 [D loss: 0.557140, acc.: 67.19%] [G loss: 0.704154]\n",
      "epoch:13 step:12753 [D loss: 0.595993, acc.: 66.41%] [G loss: 0.652821]\n",
      "epoch:13 step:12754 [D loss: 0.513271, acc.: 75.00%] [G loss: 0.735586]\n",
      "epoch:13 step:12755 [D loss: 0.435576, acc.: 82.81%] [G loss: 0.798634]\n",
      "epoch:13 step:12756 [D loss: 0.499856, acc.: 72.66%] [G loss: 0.800570]\n",
      "epoch:13 step:12757 [D loss: 0.563745, acc.: 71.88%] [G loss: 0.962856]\n",
      "epoch:13 step:12758 [D loss: 0.531804, acc.: 75.00%] [G loss: 0.975357]\n",
      "epoch:13 step:12759 [D loss: 0.569571, acc.: 67.19%] [G loss: 0.689327]\n",
      "epoch:13 step:12760 [D loss: 0.579143, acc.: 67.97%] [G loss: 0.533489]\n",
      "epoch:13 step:12761 [D loss: 0.541463, acc.: 75.00%] [G loss: 0.560520]\n",
      "epoch:13 step:12762 [D loss: 0.535493, acc.: 71.09%] [G loss: 0.580732]\n",
      "epoch:13 step:12763 [D loss: 0.470373, acc.: 76.56%] [G loss: 0.722117]\n",
      "epoch:13 step:12764 [D loss: 0.573259, acc.: 71.88%] [G loss: 0.831099]\n",
      "epoch:13 step:12765 [D loss: 0.604420, acc.: 61.72%] [G loss: 0.621426]\n",
      "epoch:13 step:12766 [D loss: 0.521331, acc.: 71.09%] [G loss: 0.647072]\n",
      "epoch:13 step:12767 [D loss: 0.533797, acc.: 71.09%] [G loss: 0.582242]\n",
      "epoch:13 step:12768 [D loss: 0.545559, acc.: 64.84%] [G loss: 0.606724]\n",
      "epoch:13 step:12769 [D loss: 0.552694, acc.: 67.19%] [G loss: 0.642053]\n",
      "epoch:13 step:12770 [D loss: 0.521533, acc.: 67.97%] [G loss: 0.729900]\n",
      "epoch:13 step:12771 [D loss: 0.548348, acc.: 69.53%] [G loss: 0.573549]\n",
      "epoch:13 step:12772 [D loss: 0.559389, acc.: 69.53%] [G loss: 0.601694]\n",
      "epoch:13 step:12773 [D loss: 0.533320, acc.: 70.31%] [G loss: 0.592221]\n",
      "epoch:13 step:12774 [D loss: 0.485232, acc.: 75.00%] [G loss: 0.658472]\n",
      "epoch:13 step:12775 [D loss: 0.571332, acc.: 64.84%] [G loss: 0.660460]\n",
      "epoch:13 step:12776 [D loss: 0.546054, acc.: 71.88%] [G loss: 0.608197]\n",
      "epoch:13 step:12777 [D loss: 0.540457, acc.: 73.44%] [G loss: 0.600181]\n",
      "epoch:13 step:12778 [D loss: 0.524645, acc.: 66.41%] [G loss: 0.552702]\n",
      "epoch:13 step:12779 [D loss: 0.501358, acc.: 75.78%] [G loss: 0.610869]\n",
      "epoch:13 step:12780 [D loss: 0.529962, acc.: 74.22%] [G loss: 0.663162]\n",
      "epoch:13 step:12781 [D loss: 0.575267, acc.: 67.19%] [G loss: 0.584246]\n",
      "epoch:13 step:12782 [D loss: 0.498720, acc.: 72.66%] [G loss: 0.665948]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:13 step:12783 [D loss: 0.488851, acc.: 75.78%] [G loss: 0.713760]\n",
      "epoch:13 step:12784 [D loss: 0.494585, acc.: 73.44%] [G loss: 0.627845]\n",
      "epoch:13 step:12785 [D loss: 0.612705, acc.: 67.97%] [G loss: 0.700426]\n",
      "epoch:13 step:12786 [D loss: 0.461331, acc.: 78.91%] [G loss: 0.765603]\n",
      "epoch:13 step:12787 [D loss: 0.642673, acc.: 65.62%] [G loss: 0.613388]\n",
      "epoch:13 step:12788 [D loss: 0.553469, acc.: 70.31%] [G loss: 0.533014]\n",
      "epoch:13 step:12789 [D loss: 0.514839, acc.: 73.44%] [G loss: 0.565392]\n",
      "epoch:13 step:12790 [D loss: 0.477089, acc.: 74.22%] [G loss: 0.590771]\n",
      "epoch:13 step:12791 [D loss: 0.547859, acc.: 68.75%] [G loss: 0.530134]\n",
      "epoch:13 step:12792 [D loss: 0.529716, acc.: 70.31%] [G loss: 0.513848]\n",
      "epoch:13 step:12793 [D loss: 0.561224, acc.: 68.75%] [G loss: 0.536519]\n",
      "epoch:13 step:12794 [D loss: 0.457404, acc.: 72.66%] [G loss: 0.723200]\n",
      "epoch:13 step:12795 [D loss: 0.545298, acc.: 67.19%] [G loss: 0.557222]\n",
      "epoch:13 step:12796 [D loss: 0.623788, acc.: 58.59%] [G loss: 0.604619]\n",
      "epoch:13 step:12797 [D loss: 0.523064, acc.: 72.66%] [G loss: 0.597474]\n",
      "epoch:13 step:12798 [D loss: 0.487112, acc.: 77.34%] [G loss: 0.730754]\n",
      "epoch:13 step:12799 [D loss: 0.532212, acc.: 72.66%] [G loss: 0.813194]\n",
      "epoch:13 step:12800 [D loss: 0.541293, acc.: 68.75%] [G loss: 0.500010]\n",
      "epoch:13 step:12801 [D loss: 0.478884, acc.: 78.12%] [G loss: 0.674552]\n",
      "epoch:13 step:12802 [D loss: 0.511683, acc.: 78.91%] [G loss: 0.595114]\n",
      "epoch:13 step:12803 [D loss: 0.556174, acc.: 70.31%] [G loss: 0.562662]\n",
      "epoch:13 step:12804 [D loss: 0.485717, acc.: 75.78%] [G loss: 0.642529]\n",
      "epoch:13 step:12805 [D loss: 0.428326, acc.: 81.25%] [G loss: 0.766602]\n",
      "epoch:13 step:12806 [D loss: 0.601901, acc.: 70.31%] [G loss: 0.824272]\n",
      "epoch:13 step:12807 [D loss: 0.533317, acc.: 67.97%] [G loss: 0.599903]\n",
      "epoch:13 step:12808 [D loss: 0.588319, acc.: 65.62%] [G loss: 0.694899]\n",
      "epoch:13 step:12809 [D loss: 0.526136, acc.: 74.22%] [G loss: 0.656758]\n",
      "epoch:13 step:12810 [D loss: 0.489644, acc.: 77.34%] [G loss: 0.698151]\n",
      "epoch:13 step:12811 [D loss: 0.491155, acc.: 75.78%] [G loss: 0.603752]\n",
      "epoch:13 step:12812 [D loss: 0.490701, acc.: 74.22%] [G loss: 0.647896]\n",
      "epoch:13 step:12813 [D loss: 0.479115, acc.: 79.69%] [G loss: 0.756717]\n",
      "epoch:13 step:12814 [D loss: 0.517880, acc.: 72.66%] [G loss: 0.741613]\n",
      "epoch:13 step:12815 [D loss: 0.501533, acc.: 74.22%] [G loss: 0.659838]\n",
      "epoch:13 step:12816 [D loss: 0.537817, acc.: 71.09%] [G loss: 0.653014]\n",
      "epoch:13 step:12817 [D loss: 0.592358, acc.: 67.19%] [G loss: 0.726308]\n",
      "epoch:13 step:12818 [D loss: 0.532716, acc.: 71.88%] [G loss: 0.512748]\n",
      "epoch:13 step:12819 [D loss: 0.505406, acc.: 71.09%] [G loss: 0.691101]\n",
      "epoch:13 step:12820 [D loss: 0.475205, acc.: 71.88%] [G loss: 0.640382]\n",
      "epoch:13 step:12821 [D loss: 0.572958, acc.: 67.97%] [G loss: 0.556681]\n",
      "epoch:13 step:12822 [D loss: 0.503253, acc.: 75.00%] [G loss: 0.859691]\n",
      "epoch:13 step:12823 [D loss: 0.528025, acc.: 71.09%] [G loss: 0.680361]\n",
      "epoch:13 step:12824 [D loss: 0.496156, acc.: 72.66%] [G loss: 0.877630]\n",
      "epoch:13 step:12825 [D loss: 0.529272, acc.: 69.53%] [G loss: 0.666405]\n",
      "epoch:13 step:12826 [D loss: 0.473011, acc.: 77.34%] [G loss: 0.662830]\n",
      "epoch:13 step:12827 [D loss: 0.537056, acc.: 68.75%] [G loss: 0.687095]\n",
      "epoch:13 step:12828 [D loss: 0.474113, acc.: 79.69%] [G loss: 0.692948]\n",
      "epoch:13 step:12829 [D loss: 0.384822, acc.: 87.50%] [G loss: 0.775263]\n",
      "epoch:13 step:12830 [D loss: 0.455050, acc.: 80.47%] [G loss: 0.920597]\n",
      "epoch:13 step:12831 [D loss: 0.498781, acc.: 75.78%] [G loss: 0.864686]\n",
      "epoch:13 step:12832 [D loss: 0.527398, acc.: 73.44%] [G loss: 0.723950]\n",
      "epoch:13 step:12833 [D loss: 0.590798, acc.: 67.97%] [G loss: 0.681125]\n",
      "epoch:13 step:12834 [D loss: 0.543574, acc.: 68.75%] [G loss: 0.600749]\n",
      "epoch:13 step:12835 [D loss: 0.471080, acc.: 75.78%] [G loss: 0.663581]\n",
      "epoch:13 step:12836 [D loss: 0.577504, acc.: 71.09%] [G loss: 0.576961]\n",
      "epoch:13 step:12837 [D loss: 0.511301, acc.: 70.31%] [G loss: 0.706079]\n",
      "epoch:13 step:12838 [D loss: 0.502049, acc.: 74.22%] [G loss: 0.735619]\n",
      "epoch:13 step:12839 [D loss: 0.588611, acc.: 65.62%] [G loss: 0.715048]\n",
      "epoch:13 step:12840 [D loss: 0.521099, acc.: 72.66%] [G loss: 0.744727]\n",
      "epoch:13 step:12841 [D loss: 0.492064, acc.: 75.00%] [G loss: 0.720135]\n",
      "epoch:13 step:12842 [D loss: 0.522249, acc.: 71.88%] [G loss: 0.598187]\n",
      "epoch:13 step:12843 [D loss: 0.521960, acc.: 73.44%] [G loss: 0.667424]\n",
      "epoch:13 step:12844 [D loss: 0.562703, acc.: 67.97%] [G loss: 0.627780]\n",
      "epoch:13 step:12845 [D loss: 0.546591, acc.: 68.75%] [G loss: 0.719769]\n",
      "epoch:13 step:12846 [D loss: 0.559638, acc.: 68.75%] [G loss: 0.595709]\n",
      "epoch:13 step:12847 [D loss: 0.541887, acc.: 71.88%] [G loss: 0.585492]\n",
      "epoch:13 step:12848 [D loss: 0.540913, acc.: 70.31%] [G loss: 0.591396]\n",
      "epoch:13 step:12849 [D loss: 0.575161, acc.: 69.53%] [G loss: 0.570562]\n",
      "epoch:13 step:12850 [D loss: 0.544048, acc.: 68.75%] [G loss: 0.562892]\n",
      "epoch:13 step:12851 [D loss: 0.579821, acc.: 62.50%] [G loss: 0.670617]\n",
      "epoch:13 step:12852 [D loss: 0.562995, acc.: 68.75%] [G loss: 0.592826]\n",
      "epoch:13 step:12853 [D loss: 0.598808, acc.: 67.97%] [G loss: 0.527416]\n",
      "epoch:13 step:12854 [D loss: 0.600826, acc.: 68.75%] [G loss: 0.473333]\n",
      "epoch:13 step:12855 [D loss: 0.541710, acc.: 71.09%] [G loss: 0.644045]\n",
      "epoch:13 step:12856 [D loss: 0.622771, acc.: 60.94%] [G loss: 0.560466]\n",
      "epoch:13 step:12857 [D loss: 0.524639, acc.: 73.44%] [G loss: 0.699753]\n",
      "epoch:13 step:12858 [D loss: 0.497035, acc.: 74.22%] [G loss: 0.601689]\n",
      "epoch:13 step:12859 [D loss: 0.513805, acc.: 72.66%] [G loss: 0.618907]\n",
      "epoch:13 step:12860 [D loss: 0.517594, acc.: 71.09%] [G loss: 0.622275]\n",
      "epoch:13 step:12861 [D loss: 0.543360, acc.: 70.31%] [G loss: 0.585909]\n",
      "epoch:13 step:12862 [D loss: 0.473127, acc.: 77.34%] [G loss: 0.683139]\n",
      "epoch:13 step:12863 [D loss: 0.554742, acc.: 71.09%] [G loss: 0.668841]\n",
      "epoch:13 step:12864 [D loss: 0.557569, acc.: 67.19%] [G loss: 0.507270]\n",
      "epoch:13 step:12865 [D loss: 0.563992, acc.: 67.97%] [G loss: 0.579024]\n",
      "epoch:13 step:12866 [D loss: 0.547835, acc.: 71.09%] [G loss: 0.530132]\n",
      "epoch:13 step:12867 [D loss: 0.587936, acc.: 64.84%] [G loss: 0.505926]\n",
      "epoch:13 step:12868 [D loss: 0.580193, acc.: 64.84%] [G loss: 0.444378]\n",
      "epoch:13 step:12869 [D loss: 0.491830, acc.: 75.00%] [G loss: 0.651005]\n",
      "epoch:13 step:12870 [D loss: 0.562042, acc.: 65.62%] [G loss: 0.624847]\n",
      "epoch:13 step:12871 [D loss: 0.505859, acc.: 75.78%] [G loss: 0.615673]\n",
      "epoch:13 step:12872 [D loss: 0.465065, acc.: 78.91%] [G loss: 0.747030]\n",
      "epoch:13 step:12873 [D loss: 0.530273, acc.: 71.88%] [G loss: 0.632921]\n",
      "epoch:13 step:12874 [D loss: 0.468708, acc.: 74.22%] [G loss: 0.874721]\n",
      "epoch:13 step:12875 [D loss: 0.560535, acc.: 70.31%] [G loss: 0.709242]\n",
      "epoch:13 step:12876 [D loss: 0.532948, acc.: 72.66%] [G loss: 0.777947]\n",
      "epoch:13 step:12877 [D loss: 0.608141, acc.: 62.50%] [G loss: 0.606280]\n",
      "epoch:13 step:12878 [D loss: 0.569583, acc.: 65.62%] [G loss: 0.506238]\n",
      "epoch:13 step:12879 [D loss: 0.538817, acc.: 69.53%] [G loss: 0.502799]\n",
      "epoch:13 step:12880 [D loss: 0.471404, acc.: 78.12%] [G loss: 0.638023]\n",
      "epoch:13 step:12881 [D loss: 0.529476, acc.: 71.88%] [G loss: 0.712078]\n",
      "epoch:13 step:12882 [D loss: 0.522501, acc.: 75.00%] [G loss: 0.749664]\n",
      "epoch:13 step:12883 [D loss: 0.578264, acc.: 64.84%] [G loss: 0.707345]\n",
      "epoch:13 step:12884 [D loss: 0.522903, acc.: 71.09%] [G loss: 0.584831]\n",
      "epoch:13 step:12885 [D loss: 0.604526, acc.: 63.28%] [G loss: 0.528068]\n",
      "epoch:13 step:12886 [D loss: 0.571528, acc.: 67.19%] [G loss: 0.652284]\n",
      "epoch:13 step:12887 [D loss: 0.553776, acc.: 71.09%] [G loss: 0.567611]\n",
      "epoch:13 step:12888 [D loss: 0.512445, acc.: 68.75%] [G loss: 0.643029]\n",
      "epoch:13 step:12889 [D loss: 0.507751, acc.: 75.78%] [G loss: 0.747953]\n",
      "epoch:13 step:12890 [D loss: 0.579776, acc.: 67.97%] [G loss: 0.717605]\n",
      "epoch:13 step:12891 [D loss: 0.602462, acc.: 65.62%] [G loss: 0.582234]\n",
      "epoch:13 step:12892 [D loss: 0.577813, acc.: 67.19%] [G loss: 0.545479]\n",
      "epoch:13 step:12893 [D loss: 0.531906, acc.: 71.09%] [G loss: 0.603624]\n",
      "epoch:13 step:12894 [D loss: 0.603616, acc.: 67.19%] [G loss: 0.552075]\n",
      "epoch:13 step:12895 [D loss: 0.529818, acc.: 68.75%] [G loss: 0.550947]\n",
      "epoch:13 step:12896 [D loss: 0.580317, acc.: 68.75%] [G loss: 0.527224]\n",
      "epoch:13 step:12897 [D loss: 0.604763, acc.: 64.84%] [G loss: 0.562323]\n",
      "epoch:13 step:12898 [D loss: 0.555936, acc.: 67.97%] [G loss: 0.498154]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:13 step:12899 [D loss: 0.583031, acc.: 63.28%] [G loss: 0.532431]\n",
      "epoch:13 step:12900 [D loss: 0.467180, acc.: 78.91%] [G loss: 0.789447]\n",
      "epoch:13 step:12901 [D loss: 0.571721, acc.: 71.09%] [G loss: 0.743475]\n",
      "epoch:13 step:12902 [D loss: 0.534864, acc.: 71.88%] [G loss: 0.648750]\n",
      "epoch:13 step:12903 [D loss: 0.589396, acc.: 66.41%] [G loss: 0.557269]\n",
      "epoch:13 step:12904 [D loss: 0.533105, acc.: 71.88%] [G loss: 0.626409]\n",
      "epoch:13 step:12905 [D loss: 0.518896, acc.: 73.44%] [G loss: 0.616483]\n",
      "epoch:13 step:12906 [D loss: 0.525215, acc.: 70.31%] [G loss: 0.655570]\n",
      "epoch:13 step:12907 [D loss: 0.520571, acc.: 75.78%] [G loss: 0.713825]\n",
      "epoch:13 step:12908 [D loss: 0.565305, acc.: 68.75%] [G loss: 0.575150]\n",
      "epoch:13 step:12909 [D loss: 0.546935, acc.: 69.53%] [G loss: 0.472224]\n",
      "epoch:13 step:12910 [D loss: 0.575596, acc.: 64.84%] [G loss: 0.454703]\n",
      "epoch:13 step:12911 [D loss: 0.531864, acc.: 70.31%] [G loss: 0.599665]\n",
      "epoch:13 step:12912 [D loss: 0.582083, acc.: 64.06%] [G loss: 0.511754]\n",
      "epoch:13 step:12913 [D loss: 0.551213, acc.: 65.62%] [G loss: 0.469958]\n",
      "epoch:13 step:12914 [D loss: 0.543371, acc.: 71.88%] [G loss: 0.556203]\n",
      "epoch:13 step:12915 [D loss: 0.532451, acc.: 65.62%] [G loss: 0.525834]\n",
      "epoch:13 step:12916 [D loss: 0.551170, acc.: 70.31%] [G loss: 0.648197]\n",
      "epoch:13 step:12917 [D loss: 0.483794, acc.: 72.66%] [G loss: 0.646677]\n",
      "epoch:13 step:12918 [D loss: 0.526412, acc.: 69.53%] [G loss: 0.756251]\n",
      "epoch:13 step:12919 [D loss: 0.548121, acc.: 68.75%] [G loss: 0.684904]\n",
      "epoch:13 step:12920 [D loss: 0.611402, acc.: 67.19%] [G loss: 0.516432]\n",
      "epoch:13 step:12921 [D loss: 0.601965, acc.: 65.62%] [G loss: 0.376478]\n",
      "epoch:13 step:12922 [D loss: 0.530884, acc.: 74.22%] [G loss: 0.536082]\n",
      "epoch:13 step:12923 [D loss: 0.554068, acc.: 68.75%] [G loss: 0.674894]\n",
      "epoch:13 step:12924 [D loss: 0.489700, acc.: 76.56%] [G loss: 0.658719]\n",
      "epoch:13 step:12925 [D loss: 0.535932, acc.: 73.44%] [G loss: 0.638331]\n",
      "epoch:13 step:12926 [D loss: 0.598533, acc.: 68.75%] [G loss: 0.637578]\n",
      "epoch:13 step:12927 [D loss: 0.460235, acc.: 78.91%] [G loss: 0.783991]\n",
      "epoch:13 step:12928 [D loss: 0.409252, acc.: 79.69%] [G loss: 0.715555]\n",
      "epoch:13 step:12929 [D loss: 0.606957, acc.: 63.28%] [G loss: 0.662787]\n",
      "epoch:13 step:12930 [D loss: 0.561431, acc.: 71.88%] [G loss: 0.577296]\n",
      "epoch:13 step:12931 [D loss: 0.520611, acc.: 72.66%] [G loss: 0.692459]\n",
      "epoch:13 step:12932 [D loss: 0.537697, acc.: 69.53%] [G loss: 0.572213]\n",
      "epoch:13 step:12933 [D loss: 0.556068, acc.: 71.09%] [G loss: 0.582020]\n",
      "epoch:13 step:12934 [D loss: 0.522489, acc.: 75.78%] [G loss: 0.577190]\n",
      "epoch:13 step:12935 [D loss: 0.525455, acc.: 71.09%] [G loss: 0.542355]\n",
      "epoch:13 step:12936 [D loss: 0.519695, acc.: 73.44%] [G loss: 0.686942]\n",
      "epoch:13 step:12937 [D loss: 0.546805, acc.: 71.88%] [G loss: 0.663269]\n",
      "epoch:13 step:12938 [D loss: 0.560682, acc.: 71.88%] [G loss: 0.569786]\n",
      "epoch:13 step:12939 [D loss: 0.565640, acc.: 67.19%] [G loss: 0.550216]\n",
      "epoch:13 step:12940 [D loss: 0.561483, acc.: 63.28%] [G loss: 0.536399]\n",
      "epoch:13 step:12941 [D loss: 0.506587, acc.: 73.44%] [G loss: 0.534837]\n",
      "epoch:13 step:12942 [D loss: 0.563632, acc.: 67.19%] [G loss: 0.604921]\n",
      "epoch:13 step:12943 [D loss: 0.622938, acc.: 67.19%] [G loss: 0.672685]\n",
      "epoch:13 step:12944 [D loss: 0.545063, acc.: 70.31%] [G loss: 0.597495]\n",
      "epoch:13 step:12945 [D loss: 0.543305, acc.: 71.09%] [G loss: 0.552878]\n",
      "epoch:13 step:12946 [D loss: 0.577833, acc.: 70.31%] [G loss: 0.572702]\n",
      "epoch:13 step:12947 [D loss: 0.670174, acc.: 57.03%] [G loss: 0.391896]\n",
      "epoch:13 step:12948 [D loss: 0.480505, acc.: 79.69%] [G loss: 0.460015]\n",
      "epoch:13 step:12949 [D loss: 0.540014, acc.: 72.66%] [G loss: 0.721152]\n",
      "epoch:13 step:12950 [D loss: 0.459005, acc.: 75.00%] [G loss: 0.948655]\n",
      "epoch:13 step:12951 [D loss: 0.501132, acc.: 78.12%] [G loss: 0.800095]\n",
      "epoch:13 step:12952 [D loss: 0.537894, acc.: 70.31%] [G loss: 0.786932]\n",
      "epoch:13 step:12953 [D loss: 0.537751, acc.: 71.09%] [G loss: 0.722632]\n",
      "epoch:13 step:12954 [D loss: 0.549409, acc.: 68.75%] [G loss: 0.653579]\n",
      "epoch:13 step:12955 [D loss: 0.561316, acc.: 67.19%] [G loss: 0.662244]\n",
      "epoch:13 step:12956 [D loss: 0.553350, acc.: 71.09%] [G loss: 0.618936]\n",
      "epoch:13 step:12957 [D loss: 0.536121, acc.: 71.88%] [G loss: 0.642106]\n",
      "epoch:13 step:12958 [D loss: 0.591417, acc.: 64.06%] [G loss: 0.581600]\n",
      "epoch:13 step:12959 [D loss: 0.544825, acc.: 74.22%] [G loss: 0.687280]\n",
      "epoch:13 step:12960 [D loss: 0.525339, acc.: 71.88%] [G loss: 0.602268]\n",
      "epoch:13 step:12961 [D loss: 0.530556, acc.: 75.78%] [G loss: 0.659333]\n",
      "epoch:13 step:12962 [D loss: 0.490494, acc.: 74.22%] [G loss: 0.856831]\n",
      "epoch:13 step:12963 [D loss: 0.518304, acc.: 75.00%] [G loss: 0.793665]\n",
      "epoch:13 step:12964 [D loss: 0.581815, acc.: 64.06%] [G loss: 0.833321]\n",
      "epoch:13 step:12965 [D loss: 0.603107, acc.: 73.44%] [G loss: 0.648564]\n",
      "epoch:13 step:12966 [D loss: 0.577126, acc.: 69.53%] [G loss: 0.629277]\n",
      "epoch:13 step:12967 [D loss: 0.529843, acc.: 69.53%] [G loss: 0.541408]\n",
      "epoch:13 step:12968 [D loss: 0.586648, acc.: 67.19%] [G loss: 0.473874]\n",
      "epoch:13 step:12969 [D loss: 0.700031, acc.: 60.94%] [G loss: 0.551046]\n",
      "epoch:13 step:12970 [D loss: 0.541428, acc.: 72.66%] [G loss: 0.617282]\n",
      "epoch:13 step:12971 [D loss: 0.518602, acc.: 72.66%] [G loss: 0.564128]\n",
      "epoch:13 step:12972 [D loss: 0.524187, acc.: 71.88%] [G loss: 0.547435]\n",
      "epoch:13 step:12973 [D loss: 0.457989, acc.: 78.12%] [G loss: 0.678255]\n",
      "epoch:13 step:12974 [D loss: 0.599120, acc.: 67.19%] [G loss: 0.612015]\n",
      "epoch:13 step:12975 [D loss: 0.641167, acc.: 59.38%] [G loss: 0.491893]\n",
      "epoch:13 step:12976 [D loss: 0.525917, acc.: 72.66%] [G loss: 0.596303]\n",
      "epoch:13 step:12977 [D loss: 0.486007, acc.: 81.25%] [G loss: 0.690215]\n",
      "epoch:13 step:12978 [D loss: 0.500002, acc.: 75.00%] [G loss: 0.724105]\n",
      "epoch:13 step:12979 [D loss: 0.521898, acc.: 72.66%] [G loss: 0.758192]\n",
      "epoch:13 step:12980 [D loss: 0.624464, acc.: 67.19%] [G loss: 0.529052]\n",
      "epoch:13 step:12981 [D loss: 0.618967, acc.: 62.50%] [G loss: 0.612472]\n",
      "epoch:13 step:12982 [D loss: 0.502597, acc.: 72.66%] [G loss: 0.617458]\n",
      "epoch:13 step:12983 [D loss: 0.480268, acc.: 76.56%] [G loss: 0.815016]\n",
      "epoch:13 step:12984 [D loss: 0.478352, acc.: 75.78%] [G loss: 0.729767]\n",
      "epoch:13 step:12985 [D loss: 0.512589, acc.: 77.34%] [G loss: 0.548186]\n",
      "epoch:13 step:12986 [D loss: 0.583606, acc.: 66.41%] [G loss: 0.476597]\n",
      "epoch:13 step:12987 [D loss: 0.563209, acc.: 70.31%] [G loss: 0.470767]\n",
      "epoch:13 step:12988 [D loss: 0.525425, acc.: 74.22%] [G loss: 0.568371]\n",
      "epoch:13 step:12989 [D loss: 0.576983, acc.: 67.97%] [G loss: 0.522134]\n",
      "epoch:13 step:12990 [D loss: 0.551028, acc.: 75.00%] [G loss: 0.604144]\n",
      "epoch:13 step:12991 [D loss: 0.531438, acc.: 72.66%] [G loss: 0.589417]\n",
      "epoch:13 step:12992 [D loss: 0.535477, acc.: 71.88%] [G loss: 0.664708]\n",
      "epoch:13 step:12993 [D loss: 0.613859, acc.: 60.16%] [G loss: 0.447848]\n",
      "epoch:13 step:12994 [D loss: 0.550125, acc.: 67.19%] [G loss: 0.620631]\n",
      "epoch:13 step:12995 [D loss: 0.522786, acc.: 71.88%] [G loss: 0.529188]\n",
      "epoch:13 step:12996 [D loss: 0.498156, acc.: 76.56%] [G loss: 0.643906]\n",
      "epoch:13 step:12997 [D loss: 0.542243, acc.: 72.66%] [G loss: 0.779088]\n",
      "epoch:13 step:12998 [D loss: 0.552051, acc.: 73.44%] [G loss: 0.679592]\n",
      "epoch:13 step:12999 [D loss: 0.588394, acc.: 64.84%] [G loss: 0.481000]\n",
      "epoch:13 step:13000 [D loss: 0.506424, acc.: 71.09%] [G loss: 0.626876]\n",
      "epoch:13 step:13001 [D loss: 0.598073, acc.: 63.28%] [G loss: 0.565014]\n",
      "epoch:13 step:13002 [D loss: 0.545679, acc.: 69.53%] [G loss: 0.517895]\n",
      "epoch:13 step:13003 [D loss: 0.565713, acc.: 68.75%] [G loss: 0.444182]\n",
      "epoch:13 step:13004 [D loss: 0.458317, acc.: 78.12%] [G loss: 0.646117]\n",
      "epoch:13 step:13005 [D loss: 0.561976, acc.: 75.00%] [G loss: 0.544124]\n",
      "epoch:13 step:13006 [D loss: 0.548780, acc.: 73.44%] [G loss: 0.564916]\n",
      "epoch:13 step:13007 [D loss: 0.521198, acc.: 71.88%] [G loss: 0.621810]\n",
      "epoch:13 step:13008 [D loss: 0.559613, acc.: 71.09%] [G loss: 0.513718]\n",
      "epoch:13 step:13009 [D loss: 0.651679, acc.: 60.94%] [G loss: 0.563116]\n",
      "epoch:13 step:13010 [D loss: 0.513768, acc.: 72.66%] [G loss: 0.760560]\n",
      "epoch:13 step:13011 [D loss: 0.517464, acc.: 74.22%] [G loss: 0.613391]\n",
      "epoch:13 step:13012 [D loss: 0.551434, acc.: 73.44%] [G loss: 0.495906]\n",
      "epoch:13 step:13013 [D loss: 0.522730, acc.: 70.31%] [G loss: 0.570097]\n",
      "epoch:13 step:13014 [D loss: 0.534364, acc.: 68.75%] [G loss: 0.516512]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:13 step:13015 [D loss: 0.524867, acc.: 71.88%] [G loss: 0.527012]\n",
      "epoch:13 step:13016 [D loss: 0.512153, acc.: 70.31%] [G loss: 0.550417]\n",
      "epoch:13 step:13017 [D loss: 0.522728, acc.: 71.88%] [G loss: 0.532933]\n",
      "epoch:13 step:13018 [D loss: 0.511288, acc.: 67.19%] [G loss: 0.544423]\n",
      "epoch:13 step:13019 [D loss: 0.516689, acc.: 72.66%] [G loss: 0.603949]\n",
      "epoch:13 step:13020 [D loss: 0.552913, acc.: 67.97%] [G loss: 0.547324]\n",
      "epoch:13 step:13021 [D loss: 0.565565, acc.: 69.53%] [G loss: 0.463333]\n",
      "epoch:13 step:13022 [D loss: 0.526616, acc.: 69.53%] [G loss: 0.451409]\n",
      "epoch:13 step:13023 [D loss: 0.510443, acc.: 76.56%] [G loss: 0.524581]\n",
      "epoch:13 step:13024 [D loss: 0.553223, acc.: 69.53%] [G loss: 0.543601]\n",
      "epoch:13 step:13025 [D loss: 0.547388, acc.: 72.66%] [G loss: 0.512836]\n",
      "epoch:13 step:13026 [D loss: 0.585920, acc.: 65.62%] [G loss: 0.507172]\n",
      "epoch:13 step:13027 [D loss: 0.621680, acc.: 64.06%] [G loss: 0.501040]\n",
      "epoch:13 step:13028 [D loss: 0.586033, acc.: 66.41%] [G loss: 0.478460]\n",
      "epoch:13 step:13029 [D loss: 0.556940, acc.: 69.53%] [G loss: 0.458278]\n",
      "epoch:13 step:13030 [D loss: 0.567478, acc.: 67.19%] [G loss: 0.487912]\n",
      "epoch:13 step:13031 [D loss: 0.548683, acc.: 72.66%] [G loss: 0.491782]\n",
      "epoch:13 step:13032 [D loss: 0.568941, acc.: 68.75%] [G loss: 0.479933]\n",
      "epoch:13 step:13033 [D loss: 0.504332, acc.: 75.00%] [G loss: 0.603765]\n",
      "epoch:13 step:13034 [D loss: 0.538016, acc.: 71.88%] [G loss: 0.648265]\n",
      "epoch:13 step:13035 [D loss: 0.499485, acc.: 73.44%] [G loss: 0.585535]\n",
      "epoch:13 step:13036 [D loss: 0.538910, acc.: 71.09%] [G loss: 0.608628]\n",
      "epoch:13 step:13037 [D loss: 0.552018, acc.: 73.44%] [G loss: 0.683490]\n",
      "epoch:13 step:13038 [D loss: 0.534525, acc.: 66.41%] [G loss: 0.573065]\n",
      "epoch:13 step:13039 [D loss: 0.589776, acc.: 71.09%] [G loss: 0.519701]\n",
      "epoch:13 step:13040 [D loss: 0.602470, acc.: 66.41%] [G loss: 0.537029]\n",
      "epoch:13 step:13041 [D loss: 0.471043, acc.: 78.12%] [G loss: 0.615224]\n",
      "epoch:13 step:13042 [D loss: 0.601278, acc.: 66.41%] [G loss: 0.688685]\n",
      "epoch:13 step:13043 [D loss: 0.545783, acc.: 67.97%] [G loss: 0.554731]\n",
      "epoch:13 step:13044 [D loss: 0.538276, acc.: 68.75%] [G loss: 0.702652]\n",
      "epoch:13 step:13045 [D loss: 0.523156, acc.: 71.09%] [G loss: 0.664995]\n",
      "epoch:13 step:13046 [D loss: 0.582942, acc.: 67.19%] [G loss: 0.552360]\n",
      "epoch:13 step:13047 [D loss: 0.531724, acc.: 67.97%] [G loss: 0.553551]\n",
      "epoch:13 step:13048 [D loss: 0.666869, acc.: 62.50%] [G loss: 0.480439]\n",
      "epoch:13 step:13049 [D loss: 0.497267, acc.: 77.34%] [G loss: 0.672405]\n",
      "epoch:13 step:13050 [D loss: 0.562520, acc.: 67.19%] [G loss: 0.567664]\n",
      "epoch:13 step:13051 [D loss: 0.473896, acc.: 75.00%] [G loss: 0.562615]\n",
      "epoch:13 step:13052 [D loss: 0.479476, acc.: 77.34%] [G loss: 0.717362]\n",
      "epoch:13 step:13053 [D loss: 0.534949, acc.: 67.97%] [G loss: 0.671690]\n",
      "epoch:13 step:13054 [D loss: 0.585279, acc.: 66.41%] [G loss: 0.609663]\n",
      "epoch:13 step:13055 [D loss: 0.542611, acc.: 74.22%] [G loss: 0.510736]\n",
      "epoch:13 step:13056 [D loss: 0.474431, acc.: 78.91%] [G loss: 0.476825]\n",
      "epoch:13 step:13057 [D loss: 0.495728, acc.: 75.00%] [G loss: 0.783848]\n",
      "epoch:13 step:13058 [D loss: 0.598640, acc.: 63.28%] [G loss: 0.563938]\n",
      "epoch:13 step:13059 [D loss: 0.563155, acc.: 64.84%] [G loss: 0.518395]\n",
      "epoch:13 step:13060 [D loss: 0.524003, acc.: 73.44%] [G loss: 0.642351]\n",
      "epoch:13 step:13061 [D loss: 0.668673, acc.: 53.12%] [G loss: 0.491680]\n",
      "epoch:13 step:13062 [D loss: 0.633861, acc.: 58.59%] [G loss: 0.494356]\n",
      "epoch:13 step:13063 [D loss: 0.563152, acc.: 67.19%] [G loss: 0.652558]\n",
      "epoch:13 step:13064 [D loss: 0.618645, acc.: 66.41%] [G loss: 0.686197]\n",
      "epoch:13 step:13065 [D loss: 0.471929, acc.: 76.56%] [G loss: 0.704638]\n",
      "epoch:13 step:13066 [D loss: 0.491347, acc.: 75.00%] [G loss: 0.731613]\n",
      "epoch:13 step:13067 [D loss: 0.523853, acc.: 75.78%] [G loss: 0.698415]\n",
      "epoch:13 step:13068 [D loss: 0.532701, acc.: 70.31%] [G loss: 0.659768]\n",
      "epoch:13 step:13069 [D loss: 0.526085, acc.: 71.09%] [G loss: 0.741767]\n",
      "epoch:13 step:13070 [D loss: 0.538769, acc.: 71.09%] [G loss: 0.713259]\n",
      "epoch:13 step:13071 [D loss: 0.523927, acc.: 70.31%] [G loss: 0.582753]\n",
      "epoch:13 step:13072 [D loss: 0.575991, acc.: 67.19%] [G loss: 0.554521]\n",
      "epoch:13 step:13073 [D loss: 0.647104, acc.: 60.94%] [G loss: 0.417384]\n",
      "epoch:13 step:13074 [D loss: 0.525905, acc.: 75.00%] [G loss: 0.551171]\n",
      "epoch:13 step:13075 [D loss: 0.462134, acc.: 78.12%] [G loss: 0.730697]\n",
      "epoch:13 step:13076 [D loss: 0.551015, acc.: 70.31%] [G loss: 0.717707]\n",
      "epoch:13 step:13077 [D loss: 0.468132, acc.: 77.34%] [G loss: 0.783609]\n",
      "epoch:13 step:13078 [D loss: 0.487121, acc.: 72.66%] [G loss: 0.647191]\n",
      "epoch:13 step:13079 [D loss: 0.473680, acc.: 78.91%] [G loss: 0.741875]\n",
      "epoch:13 step:13080 [D loss: 0.478954, acc.: 78.12%] [G loss: 0.793819]\n",
      "epoch:13 step:13081 [D loss: 0.512015, acc.: 74.22%] [G loss: 0.743578]\n",
      "epoch:13 step:13082 [D loss: 0.490513, acc.: 75.00%] [G loss: 0.654836]\n",
      "epoch:13 step:13083 [D loss: 0.594473, acc.: 71.09%] [G loss: 0.549487]\n",
      "epoch:13 step:13084 [D loss: 0.589168, acc.: 66.41%] [G loss: 0.717170]\n",
      "epoch:13 step:13085 [D loss: 0.570553, acc.: 73.44%] [G loss: 0.657869]\n",
      "epoch:13 step:13086 [D loss: 0.584900, acc.: 67.97%] [G loss: 0.695469]\n",
      "epoch:13 step:13087 [D loss: 0.531984, acc.: 70.31%] [G loss: 0.719394]\n",
      "epoch:13 step:13088 [D loss: 0.492937, acc.: 78.12%] [G loss: 0.739380]\n",
      "epoch:13 step:13089 [D loss: 0.495245, acc.: 75.78%] [G loss: 0.677000]\n",
      "epoch:13 step:13090 [D loss: 0.488307, acc.: 76.56%] [G loss: 0.687778]\n",
      "epoch:13 step:13091 [D loss: 0.545463, acc.: 67.97%] [G loss: 0.665442]\n",
      "epoch:13 step:13092 [D loss: 0.483844, acc.: 78.12%] [G loss: 0.718641]\n",
      "epoch:13 step:13093 [D loss: 0.471836, acc.: 78.91%] [G loss: 0.842216]\n",
      "epoch:13 step:13094 [D loss: 0.492673, acc.: 74.22%] [G loss: 0.824813]\n",
      "epoch:13 step:13095 [D loss: 0.434031, acc.: 81.25%] [G loss: 0.752859]\n",
      "epoch:13 step:13096 [D loss: 0.621261, acc.: 64.06%] [G loss: 0.836957]\n",
      "epoch:13 step:13097 [D loss: 0.530053, acc.: 72.66%] [G loss: 0.719071]\n",
      "epoch:13 step:13098 [D loss: 0.628793, acc.: 65.62%] [G loss: 0.575793]\n",
      "epoch:13 step:13099 [D loss: 0.493558, acc.: 72.66%] [G loss: 0.720853]\n",
      "epoch:13 step:13100 [D loss: 0.459448, acc.: 79.69%] [G loss: 0.799294]\n",
      "epoch:13 step:13101 [D loss: 0.685477, acc.: 60.16%] [G loss: 0.732511]\n",
      "epoch:13 step:13102 [D loss: 0.481838, acc.: 75.00%] [G loss: 0.791598]\n",
      "epoch:13 step:13103 [D loss: 0.485009, acc.: 71.88%] [G loss: 0.737133]\n",
      "epoch:13 step:13104 [D loss: 0.470288, acc.: 74.22%] [G loss: 0.785019]\n",
      "epoch:13 step:13105 [D loss: 0.488240, acc.: 77.34%] [G loss: 0.817124]\n",
      "epoch:13 step:13106 [D loss: 0.390597, acc.: 85.16%] [G loss: 0.981015]\n",
      "epoch:13 step:13107 [D loss: 0.449127, acc.: 78.91%] [G loss: 1.142985]\n",
      "epoch:13 step:13108 [D loss: 0.487621, acc.: 73.44%] [G loss: 1.320940]\n",
      "epoch:13 step:13109 [D loss: 0.767784, acc.: 61.72%] [G loss: 1.032329]\n",
      "epoch:13 step:13110 [D loss: 0.548186, acc.: 68.75%] [G loss: 1.050404]\n",
      "epoch:13 step:13111 [D loss: 0.461075, acc.: 75.00%] [G loss: 1.108612]\n",
      "epoch:13 step:13112 [D loss: 0.511823, acc.: 69.53%] [G loss: 0.789654]\n",
      "epoch:13 step:13113 [D loss: 0.576405, acc.: 72.66%] [G loss: 0.632166]\n",
      "epoch:13 step:13114 [D loss: 0.528739, acc.: 72.66%] [G loss: 0.798074]\n",
      "epoch:13 step:13115 [D loss: 0.553372, acc.: 69.53%] [G loss: 0.756208]\n",
      "epoch:13 step:13116 [D loss: 0.538814, acc.: 69.53%] [G loss: 0.744852]\n",
      "epoch:13 step:13117 [D loss: 0.382278, acc.: 82.03%] [G loss: 0.919091]\n",
      "epoch:13 step:13118 [D loss: 0.443020, acc.: 78.91%] [G loss: 1.419409]\n",
      "epoch:14 step:13119 [D loss: 0.563379, acc.: 71.88%] [G loss: 0.956584]\n",
      "epoch:14 step:13120 [D loss: 0.514027, acc.: 75.00%] [G loss: 0.902983]\n",
      "epoch:14 step:13121 [D loss: 0.603817, acc.: 68.75%] [G loss: 0.832956]\n",
      "epoch:14 step:13122 [D loss: 0.571049, acc.: 67.19%] [G loss: 0.657121]\n",
      "epoch:14 step:13123 [D loss: 0.572365, acc.: 69.53%] [G loss: 0.758358]\n",
      "epoch:14 step:13124 [D loss: 0.619441, acc.: 67.19%] [G loss: 0.705768]\n",
      "epoch:14 step:13125 [D loss: 0.515114, acc.: 73.44%] [G loss: 0.744198]\n",
      "epoch:14 step:13126 [D loss: 0.502283, acc.: 78.12%] [G loss: 0.663917]\n",
      "epoch:14 step:13127 [D loss: 0.495034, acc.: 76.56%] [G loss: 0.710473]\n",
      "epoch:14 step:13128 [D loss: 0.540009, acc.: 71.09%] [G loss: 0.779554]\n",
      "epoch:14 step:13129 [D loss: 0.515950, acc.: 75.00%] [G loss: 0.636132]\n",
      "epoch:14 step:13130 [D loss: 0.580886, acc.: 67.19%] [G loss: 0.730354]\n",
      "epoch:14 step:13131 [D loss: 0.532862, acc.: 68.75%] [G loss: 0.669886]\n",
      "epoch:14 step:13132 [D loss: 0.536186, acc.: 73.44%] [G loss: 0.584521]\n",
      "epoch:14 step:13133 [D loss: 0.518683, acc.: 71.09%] [G loss: 0.742312]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:14 step:13134 [D loss: 0.490208, acc.: 75.78%] [G loss: 0.860625]\n",
      "epoch:14 step:13135 [D loss: 0.575882, acc.: 70.31%] [G loss: 0.742053]\n",
      "epoch:14 step:13136 [D loss: 0.574123, acc.: 67.19%] [G loss: 0.729778]\n",
      "epoch:14 step:13137 [D loss: 0.668170, acc.: 60.94%] [G loss: 0.629825]\n",
      "epoch:14 step:13138 [D loss: 0.634160, acc.: 64.84%] [G loss: 0.598854]\n",
      "epoch:14 step:13139 [D loss: 0.579412, acc.: 67.19%] [G loss: 0.635856]\n",
      "epoch:14 step:13140 [D loss: 0.482478, acc.: 74.22%] [G loss: 0.670326]\n",
      "epoch:14 step:13141 [D loss: 0.525200, acc.: 71.88%] [G loss: 0.611826]\n",
      "epoch:14 step:13142 [D loss: 0.453658, acc.: 83.59%] [G loss: 0.614681]\n",
      "epoch:14 step:13143 [D loss: 0.522350, acc.: 74.22%] [G loss: 0.666236]\n",
      "epoch:14 step:13144 [D loss: 0.570819, acc.: 70.31%] [G loss: 0.545548]\n",
      "epoch:14 step:13145 [D loss: 0.474527, acc.: 75.78%] [G loss: 0.745164]\n",
      "epoch:14 step:13146 [D loss: 0.588948, acc.: 67.19%] [G loss: 0.737561]\n",
      "epoch:14 step:13147 [D loss: 0.499518, acc.: 73.44%] [G loss: 0.633801]\n",
      "epoch:14 step:13148 [D loss: 0.517548, acc.: 71.88%] [G loss: 0.634781]\n",
      "epoch:14 step:13149 [D loss: 0.643105, acc.: 57.81%] [G loss: 0.530517]\n",
      "epoch:14 step:13150 [D loss: 0.510913, acc.: 75.78%] [G loss: 0.513835]\n",
      "epoch:14 step:13151 [D loss: 0.507025, acc.: 70.31%] [G loss: 0.610058]\n",
      "epoch:14 step:13152 [D loss: 0.519317, acc.: 71.09%] [G loss: 0.606600]\n",
      "epoch:14 step:13153 [D loss: 0.499854, acc.: 75.00%] [G loss: 0.638027]\n",
      "epoch:14 step:13154 [D loss: 0.510727, acc.: 67.97%] [G loss: 0.561377]\n",
      "epoch:14 step:13155 [D loss: 0.456494, acc.: 82.81%] [G loss: 0.669251]\n",
      "epoch:14 step:13156 [D loss: 0.562064, acc.: 66.41%] [G loss: 0.712265]\n",
      "epoch:14 step:13157 [D loss: 0.556923, acc.: 68.75%] [G loss: 0.575691]\n",
      "epoch:14 step:13158 [D loss: 0.423264, acc.: 84.38%] [G loss: 0.541334]\n",
      "epoch:14 step:13159 [D loss: 0.548185, acc.: 70.31%] [G loss: 0.692225]\n",
      "epoch:14 step:13160 [D loss: 0.519074, acc.: 70.31%] [G loss: 0.590916]\n",
      "epoch:14 step:13161 [D loss: 0.501168, acc.: 71.88%] [G loss: 0.600672]\n",
      "epoch:14 step:13162 [D loss: 0.562639, acc.: 67.19%] [G loss: 0.594762]\n",
      "epoch:14 step:13163 [D loss: 0.519680, acc.: 74.22%] [G loss: 0.705058]\n",
      "epoch:14 step:13164 [D loss: 0.506714, acc.: 71.09%] [G loss: 0.699851]\n",
      "epoch:14 step:13165 [D loss: 0.537406, acc.: 67.97%] [G loss: 0.660574]\n",
      "epoch:14 step:13166 [D loss: 0.483940, acc.: 76.56%] [G loss: 0.775407]\n",
      "epoch:14 step:13167 [D loss: 0.514396, acc.: 74.22%] [G loss: 0.897678]\n",
      "epoch:14 step:13168 [D loss: 0.532241, acc.: 75.78%] [G loss: 0.684570]\n",
      "epoch:14 step:13169 [D loss: 0.687980, acc.: 60.16%] [G loss: 0.525221]\n",
      "epoch:14 step:13170 [D loss: 0.608340, acc.: 65.62%] [G loss: 0.637515]\n",
      "epoch:14 step:13171 [D loss: 0.554615, acc.: 70.31%] [G loss: 0.645762]\n",
      "epoch:14 step:13172 [D loss: 0.452459, acc.: 80.47%] [G loss: 0.635230]\n",
      "epoch:14 step:13173 [D loss: 0.553578, acc.: 73.44%] [G loss: 0.620536]\n",
      "epoch:14 step:13174 [D loss: 0.512945, acc.: 72.66%] [G loss: 0.758013]\n",
      "epoch:14 step:13175 [D loss: 0.489507, acc.: 73.44%] [G loss: 0.682184]\n",
      "epoch:14 step:13176 [D loss: 0.532757, acc.: 71.88%] [G loss: 0.634420]\n",
      "epoch:14 step:13177 [D loss: 0.512105, acc.: 72.66%] [G loss: 0.637916]\n",
      "epoch:14 step:13178 [D loss: 0.538843, acc.: 75.00%] [G loss: 0.588476]\n",
      "epoch:14 step:13179 [D loss: 0.500297, acc.: 72.66%] [G loss: 0.716260]\n",
      "epoch:14 step:13180 [D loss: 0.586196, acc.: 72.66%] [G loss: 0.672545]\n",
      "epoch:14 step:13181 [D loss: 0.527826, acc.: 71.88%] [G loss: 0.651272]\n",
      "epoch:14 step:13182 [D loss: 0.616661, acc.: 66.41%] [G loss: 0.690866]\n",
      "epoch:14 step:13183 [D loss: 0.497808, acc.: 75.00%] [G loss: 0.690604]\n",
      "epoch:14 step:13184 [D loss: 0.509184, acc.: 71.88%] [G loss: 0.491250]\n",
      "epoch:14 step:13185 [D loss: 0.496205, acc.: 77.34%] [G loss: 0.499812]\n",
      "epoch:14 step:13186 [D loss: 0.514323, acc.: 73.44%] [G loss: 0.548287]\n",
      "epoch:14 step:13187 [D loss: 0.424396, acc.: 85.16%] [G loss: 0.578882]\n",
      "epoch:14 step:13188 [D loss: 0.568314, acc.: 70.31%] [G loss: 0.590440]\n",
      "epoch:14 step:13189 [D loss: 0.505511, acc.: 72.66%] [G loss: 0.657415]\n",
      "epoch:14 step:13190 [D loss: 0.504456, acc.: 73.44%] [G loss: 0.661207]\n",
      "epoch:14 step:13191 [D loss: 0.557433, acc.: 67.97%] [G loss: 0.538711]\n",
      "epoch:14 step:13192 [D loss: 0.521208, acc.: 76.56%] [G loss: 0.569420]\n",
      "epoch:14 step:13193 [D loss: 0.563966, acc.: 71.09%] [G loss: 0.624103]\n",
      "epoch:14 step:13194 [D loss: 0.503861, acc.: 77.34%] [G loss: 0.759337]\n",
      "epoch:14 step:13195 [D loss: 0.414734, acc.: 79.69%] [G loss: 0.836379]\n",
      "epoch:14 step:13196 [D loss: 0.580584, acc.: 67.19%] [G loss: 0.681957]\n",
      "epoch:14 step:13197 [D loss: 0.527044, acc.: 71.88%] [G loss: 0.788092]\n",
      "epoch:14 step:13198 [D loss: 0.539521, acc.: 73.44%] [G loss: 0.666860]\n",
      "epoch:14 step:13199 [D loss: 0.564242, acc.: 66.41%] [G loss: 0.683802]\n",
      "epoch:14 step:13200 [D loss: 0.528696, acc.: 71.88%] [G loss: 0.565749]\n",
      "epoch:14 step:13201 [D loss: 0.495881, acc.: 71.88%] [G loss: 0.722090]\n",
      "epoch:14 step:13202 [D loss: 0.512447, acc.: 69.53%] [G loss: 0.722063]\n",
      "epoch:14 step:13203 [D loss: 0.594677, acc.: 66.41%] [G loss: 0.645997]\n",
      "epoch:14 step:13204 [D loss: 0.522905, acc.: 74.22%] [G loss: 0.646879]\n",
      "epoch:14 step:13205 [D loss: 0.486428, acc.: 73.44%] [G loss: 0.604975]\n",
      "epoch:14 step:13206 [D loss: 0.496241, acc.: 75.78%] [G loss: 0.734203]\n",
      "epoch:14 step:13207 [D loss: 0.483624, acc.: 74.22%] [G loss: 0.761597]\n",
      "epoch:14 step:13208 [D loss: 0.518120, acc.: 71.88%] [G loss: 0.764596]\n",
      "epoch:14 step:13209 [D loss: 0.577436, acc.: 71.09%] [G loss: 0.697304]\n",
      "epoch:14 step:13210 [D loss: 0.483072, acc.: 77.34%] [G loss: 0.703827]\n",
      "epoch:14 step:13211 [D loss: 0.496594, acc.: 77.34%] [G loss: 0.646725]\n",
      "epoch:14 step:13212 [D loss: 0.531652, acc.: 71.09%] [G loss: 0.714557]\n",
      "epoch:14 step:13213 [D loss: 0.522688, acc.: 70.31%] [G loss: 0.698493]\n",
      "epoch:14 step:13214 [D loss: 0.547323, acc.: 71.88%] [G loss: 0.633486]\n",
      "epoch:14 step:13215 [D loss: 0.501323, acc.: 74.22%] [G loss: 0.771052]\n",
      "epoch:14 step:13216 [D loss: 0.527209, acc.: 73.44%] [G loss: 0.666439]\n",
      "epoch:14 step:13217 [D loss: 0.587384, acc.: 67.97%] [G loss: 0.704572]\n",
      "epoch:14 step:13218 [D loss: 0.414890, acc.: 81.25%] [G loss: 0.997615]\n",
      "epoch:14 step:13219 [D loss: 0.487823, acc.: 71.88%] [G loss: 0.798823]\n",
      "epoch:14 step:13220 [D loss: 0.615372, acc.: 63.28%] [G loss: 0.476596]\n",
      "epoch:14 step:13221 [D loss: 0.507914, acc.: 73.44%] [G loss: 0.538100]\n",
      "epoch:14 step:13222 [D loss: 0.515447, acc.: 71.88%] [G loss: 0.594264]\n",
      "epoch:14 step:13223 [D loss: 0.581059, acc.: 64.84%] [G loss: 0.521686]\n",
      "epoch:14 step:13224 [D loss: 0.511019, acc.: 76.56%] [G loss: 0.571063]\n",
      "epoch:14 step:13225 [D loss: 0.576110, acc.: 65.62%] [G loss: 0.659478]\n",
      "epoch:14 step:13226 [D loss: 0.573509, acc.: 70.31%] [G loss: 0.644808]\n",
      "epoch:14 step:13227 [D loss: 0.628767, acc.: 68.75%] [G loss: 0.613223]\n",
      "epoch:14 step:13228 [D loss: 0.543552, acc.: 69.53%] [G loss: 0.610049]\n",
      "epoch:14 step:13229 [D loss: 0.473946, acc.: 75.00%] [G loss: 0.672442]\n",
      "epoch:14 step:13230 [D loss: 0.486556, acc.: 74.22%] [G loss: 0.729457]\n",
      "epoch:14 step:13231 [D loss: 0.539064, acc.: 67.19%] [G loss: 0.604797]\n",
      "epoch:14 step:13232 [D loss: 0.555514, acc.: 69.53%] [G loss: 0.564213]\n",
      "epoch:14 step:13233 [D loss: 0.514542, acc.: 71.88%] [G loss: 0.725011]\n",
      "epoch:14 step:13234 [D loss: 0.531990, acc.: 66.41%] [G loss: 0.665328]\n",
      "epoch:14 step:13235 [D loss: 0.528534, acc.: 72.66%] [G loss: 0.720567]\n",
      "epoch:14 step:13236 [D loss: 0.518285, acc.: 74.22%] [G loss: 0.847359]\n",
      "epoch:14 step:13237 [D loss: 0.456527, acc.: 78.91%] [G loss: 1.011474]\n",
      "epoch:14 step:13238 [D loss: 0.592131, acc.: 69.53%] [G loss: 0.752110]\n",
      "epoch:14 step:13239 [D loss: 0.487647, acc.: 78.12%] [G loss: 0.735739]\n",
      "epoch:14 step:13240 [D loss: 0.460979, acc.: 82.81%] [G loss: 0.861751]\n",
      "epoch:14 step:13241 [D loss: 0.524890, acc.: 73.44%] [G loss: 0.777192]\n",
      "epoch:14 step:13242 [D loss: 0.545142, acc.: 70.31%] [G loss: 0.614263]\n",
      "epoch:14 step:13243 [D loss: 0.561990, acc.: 69.53%] [G loss: 0.596534]\n",
      "epoch:14 step:13244 [D loss: 0.502212, acc.: 76.56%] [G loss: 0.722048]\n",
      "epoch:14 step:13245 [D loss: 0.523763, acc.: 71.09%] [G loss: 0.723384]\n",
      "epoch:14 step:13246 [D loss: 0.501915, acc.: 71.09%] [G loss: 0.580862]\n",
      "epoch:14 step:13247 [D loss: 0.587992, acc.: 68.75%] [G loss: 0.578964]\n",
      "epoch:14 step:13248 [D loss: 0.522538, acc.: 68.75%] [G loss: 0.623700]\n",
      "epoch:14 step:13249 [D loss: 0.479251, acc.: 73.44%] [G loss: 0.637400]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:14 step:13250 [D loss: 0.572679, acc.: 69.53%] [G loss: 0.681489]\n",
      "epoch:14 step:13251 [D loss: 0.559943, acc.: 70.31%] [G loss: 0.708718]\n",
      "epoch:14 step:13252 [D loss: 0.505917, acc.: 73.44%] [G loss: 0.853987]\n",
      "epoch:14 step:13253 [D loss: 0.507186, acc.: 76.56%] [G loss: 0.746564]\n",
      "epoch:14 step:13254 [D loss: 0.563798, acc.: 68.75%] [G loss: 0.781458]\n",
      "epoch:14 step:13255 [D loss: 0.655387, acc.: 63.28%] [G loss: 0.684397]\n",
      "epoch:14 step:13256 [D loss: 0.594515, acc.: 65.62%] [G loss: 0.574626]\n",
      "epoch:14 step:13257 [D loss: 0.539286, acc.: 72.66%] [G loss: 0.570176]\n",
      "epoch:14 step:13258 [D loss: 0.546387, acc.: 70.31%] [G loss: 0.512304]\n",
      "epoch:14 step:13259 [D loss: 0.497164, acc.: 71.09%] [G loss: 0.721061]\n",
      "epoch:14 step:13260 [D loss: 0.601525, acc.: 61.72%] [G loss: 0.600772]\n",
      "epoch:14 step:13261 [D loss: 0.583944, acc.: 63.28%] [G loss: 0.622838]\n",
      "epoch:14 step:13262 [D loss: 0.527335, acc.: 66.41%] [G loss: 0.644080]\n",
      "epoch:14 step:13263 [D loss: 0.530555, acc.: 71.88%] [G loss: 0.610683]\n",
      "epoch:14 step:13264 [D loss: 0.473418, acc.: 79.69%] [G loss: 0.773950]\n",
      "epoch:14 step:13265 [D loss: 0.667677, acc.: 67.97%] [G loss: 0.565133]\n",
      "epoch:14 step:13266 [D loss: 0.536731, acc.: 69.53%] [G loss: 0.588963]\n",
      "epoch:14 step:13267 [D loss: 0.528333, acc.: 72.66%] [G loss: 0.570292]\n",
      "epoch:14 step:13268 [D loss: 0.621095, acc.: 64.06%] [G loss: 0.538674]\n",
      "epoch:14 step:13269 [D loss: 0.538731, acc.: 70.31%] [G loss: 0.676226]\n",
      "epoch:14 step:13270 [D loss: 0.523943, acc.: 72.66%] [G loss: 0.779907]\n",
      "epoch:14 step:13271 [D loss: 0.585304, acc.: 65.62%] [G loss: 0.553240]\n",
      "epoch:14 step:13272 [D loss: 0.517754, acc.: 71.09%] [G loss: 0.570956]\n",
      "epoch:14 step:13273 [D loss: 0.471799, acc.: 79.69%] [G loss: 0.623960]\n",
      "epoch:14 step:13274 [D loss: 0.471810, acc.: 76.56%] [G loss: 0.901723]\n",
      "epoch:14 step:13275 [D loss: 0.592410, acc.: 66.41%] [G loss: 0.699673]\n",
      "epoch:14 step:13276 [D loss: 0.529936, acc.: 71.88%] [G loss: 0.606368]\n",
      "epoch:14 step:13277 [D loss: 0.481156, acc.: 75.78%] [G loss: 0.662414]\n",
      "epoch:14 step:13278 [D loss: 0.587758, acc.: 69.53%] [G loss: 0.711349]\n",
      "epoch:14 step:13279 [D loss: 0.546461, acc.: 69.53%] [G loss: 0.697940]\n",
      "epoch:14 step:13280 [D loss: 0.481198, acc.: 74.22%] [G loss: 0.629112]\n",
      "epoch:14 step:13281 [D loss: 0.523790, acc.: 68.75%] [G loss: 0.733709]\n",
      "epoch:14 step:13282 [D loss: 0.540385, acc.: 67.97%] [G loss: 0.736444]\n",
      "epoch:14 step:13283 [D loss: 0.467983, acc.: 77.34%] [G loss: 0.679244]\n",
      "epoch:14 step:13284 [D loss: 0.544120, acc.: 72.66%] [G loss: 0.546677]\n",
      "epoch:14 step:13285 [D loss: 0.516785, acc.: 72.66%] [G loss: 0.566029]\n",
      "epoch:14 step:13286 [D loss: 0.555444, acc.: 66.41%] [G loss: 0.536042]\n",
      "epoch:14 step:13287 [D loss: 0.550694, acc.: 74.22%] [G loss: 0.458184]\n",
      "epoch:14 step:13288 [D loss: 0.516010, acc.: 69.53%] [G loss: 0.480733]\n",
      "epoch:14 step:13289 [D loss: 0.513709, acc.: 71.09%] [G loss: 0.631658]\n",
      "epoch:14 step:13290 [D loss: 0.568190, acc.: 67.97%] [G loss: 0.583639]\n",
      "epoch:14 step:13291 [D loss: 0.466437, acc.: 74.22%] [G loss: 0.769793]\n",
      "epoch:14 step:13292 [D loss: 0.616063, acc.: 62.50%] [G loss: 0.515686]\n",
      "epoch:14 step:13293 [D loss: 0.562766, acc.: 62.50%] [G loss: 0.608687]\n",
      "epoch:14 step:13294 [D loss: 0.519868, acc.: 67.97%] [G loss: 0.669230]\n",
      "epoch:14 step:13295 [D loss: 0.493745, acc.: 78.91%] [G loss: 0.561524]\n",
      "epoch:14 step:13296 [D loss: 0.550483, acc.: 68.75%] [G loss: 0.549409]\n",
      "epoch:14 step:13297 [D loss: 0.562056, acc.: 71.09%] [G loss: 0.518135]\n",
      "epoch:14 step:13298 [D loss: 0.648928, acc.: 62.50%] [G loss: 0.504520]\n",
      "epoch:14 step:13299 [D loss: 0.521147, acc.: 71.09%] [G loss: 0.465138]\n",
      "epoch:14 step:13300 [D loss: 0.564198, acc.: 73.44%] [G loss: 0.651409]\n",
      "epoch:14 step:13301 [D loss: 0.545280, acc.: 71.09%] [G loss: 0.666088]\n",
      "epoch:14 step:13302 [D loss: 0.496789, acc.: 76.56%] [G loss: 0.654301]\n",
      "epoch:14 step:13303 [D loss: 0.587800, acc.: 71.88%] [G loss: 0.533546]\n",
      "epoch:14 step:13304 [D loss: 0.489426, acc.: 71.09%] [G loss: 0.635553]\n",
      "epoch:14 step:13305 [D loss: 0.598331, acc.: 64.84%] [G loss: 0.560177]\n",
      "epoch:14 step:13306 [D loss: 0.557219, acc.: 69.53%] [G loss: 0.530920]\n",
      "epoch:14 step:13307 [D loss: 0.567481, acc.: 69.53%] [G loss: 0.509497]\n",
      "epoch:14 step:13308 [D loss: 0.472689, acc.: 78.12%] [G loss: 0.571200]\n",
      "epoch:14 step:13309 [D loss: 0.515838, acc.: 76.56%] [G loss: 0.521031]\n",
      "epoch:14 step:13310 [D loss: 0.583152, acc.: 67.19%] [G loss: 0.645480]\n",
      "epoch:14 step:13311 [D loss: 0.534783, acc.: 71.88%] [G loss: 0.614872]\n",
      "epoch:14 step:13312 [D loss: 0.450629, acc.: 75.78%] [G loss: 0.695951]\n",
      "epoch:14 step:13313 [D loss: 0.522162, acc.: 74.22%] [G loss: 0.725337]\n",
      "epoch:14 step:13314 [D loss: 0.573814, acc.: 65.62%] [G loss: 0.644601]\n",
      "epoch:14 step:13315 [D loss: 0.512175, acc.: 72.66%] [G loss: 0.657059]\n",
      "epoch:14 step:13316 [D loss: 0.499227, acc.: 71.09%] [G loss: 0.747430]\n",
      "epoch:14 step:13317 [D loss: 0.518428, acc.: 70.31%] [G loss: 0.658526]\n",
      "epoch:14 step:13318 [D loss: 0.636346, acc.: 60.16%] [G loss: 0.603316]\n",
      "epoch:14 step:13319 [D loss: 0.552640, acc.: 67.97%] [G loss: 0.587456]\n",
      "epoch:14 step:13320 [D loss: 0.564901, acc.: 68.75%] [G loss: 0.575696]\n",
      "epoch:14 step:13321 [D loss: 0.609954, acc.: 64.84%] [G loss: 0.495912]\n",
      "epoch:14 step:13322 [D loss: 0.512723, acc.: 71.09%] [G loss: 0.626193]\n",
      "epoch:14 step:13323 [D loss: 0.500026, acc.: 71.09%] [G loss: 0.755239]\n",
      "epoch:14 step:13324 [D loss: 0.510235, acc.: 73.44%] [G loss: 0.581420]\n",
      "epoch:14 step:13325 [D loss: 0.486344, acc.: 74.22%] [G loss: 0.542179]\n",
      "epoch:14 step:13326 [D loss: 0.433636, acc.: 78.12%] [G loss: 0.698834]\n",
      "epoch:14 step:13327 [D loss: 0.477980, acc.: 75.78%] [G loss: 0.653473]\n",
      "epoch:14 step:13328 [D loss: 0.627694, acc.: 63.28%] [G loss: 0.509364]\n",
      "epoch:14 step:13329 [D loss: 0.631833, acc.: 61.72%] [G loss: 0.527129]\n",
      "epoch:14 step:13330 [D loss: 0.554884, acc.: 72.66%] [G loss: 0.515924]\n",
      "epoch:14 step:13331 [D loss: 0.509042, acc.: 72.66%] [G loss: 0.782854]\n",
      "epoch:14 step:13332 [D loss: 0.583202, acc.: 67.19%] [G loss: 0.506719]\n",
      "epoch:14 step:13333 [D loss: 0.539044, acc.: 71.09%] [G loss: 0.528766]\n",
      "epoch:14 step:13334 [D loss: 0.527858, acc.: 71.09%] [G loss: 0.455410]\n",
      "epoch:14 step:13335 [D loss: 0.500322, acc.: 71.88%] [G loss: 0.547325]\n",
      "epoch:14 step:13336 [D loss: 0.509087, acc.: 77.34%] [G loss: 0.579203]\n",
      "epoch:14 step:13337 [D loss: 0.454721, acc.: 79.69%] [G loss: 0.631325]\n",
      "epoch:14 step:13338 [D loss: 0.648448, acc.: 61.72%] [G loss: 0.605672]\n",
      "epoch:14 step:13339 [D loss: 0.498302, acc.: 74.22%] [G loss: 0.635489]\n",
      "epoch:14 step:13340 [D loss: 0.514714, acc.: 73.44%] [G loss: 0.770170]\n",
      "epoch:14 step:13341 [D loss: 0.485635, acc.: 75.78%] [G loss: 0.844218]\n",
      "epoch:14 step:13342 [D loss: 0.606901, acc.: 65.62%] [G loss: 0.687650]\n",
      "epoch:14 step:13343 [D loss: 0.551333, acc.: 71.09%] [G loss: 0.724866]\n",
      "epoch:14 step:13344 [D loss: 0.585016, acc.: 63.28%] [G loss: 0.468502]\n",
      "epoch:14 step:13345 [D loss: 0.598533, acc.: 62.50%] [G loss: 0.583580]\n",
      "epoch:14 step:13346 [D loss: 0.609452, acc.: 62.50%] [G loss: 0.518247]\n",
      "epoch:14 step:13347 [D loss: 0.591224, acc.: 66.41%] [G loss: 0.458227]\n",
      "epoch:14 step:13348 [D loss: 0.515995, acc.: 71.09%] [G loss: 0.631615]\n",
      "epoch:14 step:13349 [D loss: 0.425791, acc.: 80.47%] [G loss: 0.792100]\n",
      "epoch:14 step:13350 [D loss: 0.449225, acc.: 78.12%] [G loss: 0.803861]\n",
      "epoch:14 step:13351 [D loss: 0.527431, acc.: 72.66%] [G loss: 0.803986]\n",
      "epoch:14 step:13352 [D loss: 0.527433, acc.: 67.97%] [G loss: 0.718029]\n",
      "epoch:14 step:13353 [D loss: 0.583503, acc.: 62.50%] [G loss: 0.728205]\n",
      "epoch:14 step:13354 [D loss: 0.521047, acc.: 72.66%] [G loss: 0.567860]\n",
      "epoch:14 step:13355 [D loss: 0.500558, acc.: 72.66%] [G loss: 0.612902]\n",
      "epoch:14 step:13356 [D loss: 0.578840, acc.: 66.41%] [G loss: 0.526779]\n",
      "epoch:14 step:13357 [D loss: 0.510203, acc.: 72.66%] [G loss: 0.634136]\n",
      "epoch:14 step:13358 [D loss: 0.516645, acc.: 71.09%] [G loss: 0.611006]\n",
      "epoch:14 step:13359 [D loss: 0.559775, acc.: 64.06%] [G loss: 0.467655]\n",
      "epoch:14 step:13360 [D loss: 0.512167, acc.: 73.44%] [G loss: 0.803426]\n",
      "epoch:14 step:13361 [D loss: 0.540226, acc.: 71.88%] [G loss: 0.690594]\n",
      "epoch:14 step:13362 [D loss: 0.472179, acc.: 78.91%] [G loss: 0.689933]\n",
      "epoch:14 step:13363 [D loss: 0.556552, acc.: 70.31%] [G loss: 0.631400]\n",
      "epoch:14 step:13364 [D loss: 0.487843, acc.: 75.00%] [G loss: 0.813974]\n",
      "epoch:14 step:13365 [D loss: 0.498927, acc.: 78.12%] [G loss: 0.704430]\n",
      "epoch:14 step:13366 [D loss: 0.522368, acc.: 71.88%] [G loss: 0.743385]\n",
      "epoch:14 step:13367 [D loss: 0.566502, acc.: 67.97%] [G loss: 0.591032]\n",
      "epoch:14 step:13368 [D loss: 0.596296, acc.: 63.28%] [G loss: 0.678896]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:14 step:13369 [D loss: 0.551250, acc.: 71.88%] [G loss: 0.552838]\n",
      "epoch:14 step:13370 [D loss: 0.566806, acc.: 67.19%] [G loss: 0.653378]\n",
      "epoch:14 step:13371 [D loss: 0.570857, acc.: 74.22%] [G loss: 0.677894]\n",
      "epoch:14 step:13372 [D loss: 0.489719, acc.: 71.88%] [G loss: 0.666011]\n",
      "epoch:14 step:13373 [D loss: 0.532871, acc.: 74.22%] [G loss: 0.613105]\n",
      "epoch:14 step:13374 [D loss: 0.561312, acc.: 68.75%] [G loss: 0.663543]\n",
      "epoch:14 step:13375 [D loss: 0.563931, acc.: 60.16%] [G loss: 0.610613]\n",
      "epoch:14 step:13376 [D loss: 0.493977, acc.: 75.00%] [G loss: 0.788994]\n",
      "epoch:14 step:13377 [D loss: 0.507815, acc.: 74.22%] [G loss: 0.621651]\n",
      "epoch:14 step:13378 [D loss: 0.555188, acc.: 70.31%] [G loss: 0.603584]\n",
      "epoch:14 step:13379 [D loss: 0.576673, acc.: 65.62%] [G loss: 0.511751]\n",
      "epoch:14 step:13380 [D loss: 0.523518, acc.: 70.31%] [G loss: 0.608929]\n",
      "epoch:14 step:13381 [D loss: 0.587604, acc.: 67.97%] [G loss: 0.583097]\n",
      "epoch:14 step:13382 [D loss: 0.478386, acc.: 77.34%] [G loss: 0.619252]\n",
      "epoch:14 step:13383 [D loss: 0.567198, acc.: 67.19%] [G loss: 0.542962]\n",
      "epoch:14 step:13384 [D loss: 0.584922, acc.: 67.19%] [G loss: 0.651093]\n",
      "epoch:14 step:13385 [D loss: 0.546584, acc.: 71.09%] [G loss: 0.690104]\n",
      "epoch:14 step:13386 [D loss: 0.601438, acc.: 65.62%] [G loss: 0.590346]\n",
      "epoch:14 step:13387 [D loss: 0.567233, acc.: 68.75%] [G loss: 0.672194]\n",
      "epoch:14 step:13388 [D loss: 0.466977, acc.: 78.12%] [G loss: 0.655083]\n",
      "epoch:14 step:13389 [D loss: 0.489835, acc.: 75.78%] [G loss: 0.670202]\n",
      "epoch:14 step:13390 [D loss: 0.557396, acc.: 74.22%] [G loss: 0.606408]\n",
      "epoch:14 step:13391 [D loss: 0.513275, acc.: 71.88%] [G loss: 0.634237]\n",
      "epoch:14 step:13392 [D loss: 0.493884, acc.: 74.22%] [G loss: 0.595851]\n",
      "epoch:14 step:13393 [D loss: 0.586667, acc.: 65.62%] [G loss: 0.554638]\n",
      "epoch:14 step:13394 [D loss: 0.497109, acc.: 77.34%] [G loss: 0.662926]\n",
      "epoch:14 step:13395 [D loss: 0.681081, acc.: 59.38%] [G loss: 0.686278]\n",
      "epoch:14 step:13396 [D loss: 0.652739, acc.: 60.16%] [G loss: 0.412939]\n",
      "epoch:14 step:13397 [D loss: 0.552347, acc.: 67.97%] [G loss: 0.398229]\n",
      "epoch:14 step:13398 [D loss: 0.567541, acc.: 66.41%] [G loss: 0.496854]\n",
      "epoch:14 step:13399 [D loss: 0.573365, acc.: 67.19%] [G loss: 0.629113]\n",
      "epoch:14 step:13400 [D loss: 0.521217, acc.: 71.88%] [G loss: 0.638731]\n",
      "epoch:14 step:13401 [D loss: 0.504366, acc.: 72.66%] [G loss: 0.543222]\n",
      "epoch:14 step:13402 [D loss: 0.564998, acc.: 66.41%] [G loss: 0.505716]\n",
      "epoch:14 step:13403 [D loss: 0.512630, acc.: 74.22%] [G loss: 0.539664]\n",
      "epoch:14 step:13404 [D loss: 0.478147, acc.: 77.34%] [G loss: 0.612160]\n",
      "epoch:14 step:13405 [D loss: 0.591190, acc.: 64.06%] [G loss: 0.468537]\n",
      "epoch:14 step:13406 [D loss: 0.547639, acc.: 69.53%] [G loss: 0.636276]\n",
      "epoch:14 step:13407 [D loss: 0.500299, acc.: 75.00%] [G loss: 0.659442]\n",
      "epoch:14 step:13408 [D loss: 0.530959, acc.: 73.44%] [G loss: 0.749794]\n",
      "epoch:14 step:13409 [D loss: 0.584621, acc.: 73.44%] [G loss: 0.672735]\n",
      "epoch:14 step:13410 [D loss: 0.506892, acc.: 75.00%] [G loss: 0.718666]\n",
      "epoch:14 step:13411 [D loss: 0.601098, acc.: 64.84%] [G loss: 0.545779]\n",
      "epoch:14 step:13412 [D loss: 0.546782, acc.: 69.53%] [G loss: 0.614361]\n",
      "epoch:14 step:13413 [D loss: 0.514875, acc.: 73.44%] [G loss: 0.543704]\n",
      "epoch:14 step:13414 [D loss: 0.455282, acc.: 75.78%] [G loss: 0.620860]\n",
      "epoch:14 step:13415 [D loss: 0.527083, acc.: 71.09%] [G loss: 0.682563]\n",
      "epoch:14 step:13416 [D loss: 0.463968, acc.: 80.47%] [G loss: 0.653941]\n",
      "epoch:14 step:13417 [D loss: 0.531434, acc.: 74.22%] [G loss: 0.721159]\n",
      "epoch:14 step:13418 [D loss: 0.467324, acc.: 78.91%] [G loss: 0.803920]\n",
      "epoch:14 step:13419 [D loss: 0.622162, acc.: 65.62%] [G loss: 0.634106]\n",
      "epoch:14 step:13420 [D loss: 0.514878, acc.: 74.22%] [G loss: 0.612166]\n",
      "epoch:14 step:13421 [D loss: 0.543290, acc.: 71.88%] [G loss: 0.775732]\n",
      "epoch:14 step:13422 [D loss: 0.473193, acc.: 76.56%] [G loss: 0.744278]\n",
      "epoch:14 step:13423 [D loss: 0.524307, acc.: 71.88%] [G loss: 0.634275]\n",
      "epoch:14 step:13424 [D loss: 0.556537, acc.: 70.31%] [G loss: 0.585948]\n",
      "epoch:14 step:13425 [D loss: 0.535975, acc.: 71.09%] [G loss: 0.825890]\n",
      "epoch:14 step:13426 [D loss: 0.553569, acc.: 67.19%] [G loss: 0.584860]\n",
      "epoch:14 step:13427 [D loss: 0.493327, acc.: 75.00%] [G loss: 0.691507]\n",
      "epoch:14 step:13428 [D loss: 0.541194, acc.: 70.31%] [G loss: 0.640621]\n",
      "epoch:14 step:13429 [D loss: 0.414421, acc.: 85.94%] [G loss: 0.608147]\n",
      "epoch:14 step:13430 [D loss: 0.464693, acc.: 79.69%] [G loss: 1.079055]\n",
      "epoch:14 step:13431 [D loss: 0.503882, acc.: 76.56%] [G loss: 0.923428]\n",
      "epoch:14 step:13432 [D loss: 0.445932, acc.: 78.91%] [G loss: 0.963142]\n",
      "epoch:14 step:13433 [D loss: 0.505067, acc.: 77.34%] [G loss: 0.931623]\n",
      "epoch:14 step:13434 [D loss: 0.730066, acc.: 57.03%] [G loss: 0.536002]\n",
      "epoch:14 step:13435 [D loss: 0.631846, acc.: 61.72%] [G loss: 0.537941]\n",
      "epoch:14 step:13436 [D loss: 0.520525, acc.: 73.44%] [G loss: 0.653747]\n",
      "epoch:14 step:13437 [D loss: 0.538889, acc.: 72.66%] [G loss: 0.528908]\n",
      "epoch:14 step:13438 [D loss: 0.523327, acc.: 72.66%] [G loss: 0.552637]\n",
      "epoch:14 step:13439 [D loss: 0.458423, acc.: 79.69%] [G loss: 0.576381]\n",
      "epoch:14 step:13440 [D loss: 0.577004, acc.: 71.09%] [G loss: 0.829344]\n",
      "epoch:14 step:13441 [D loss: 0.558644, acc.: 71.09%] [G loss: 0.485628]\n",
      "epoch:14 step:13442 [D loss: 0.575310, acc.: 64.06%] [G loss: 0.583139]\n",
      "epoch:14 step:13443 [D loss: 0.534642, acc.: 69.53%] [G loss: 0.438991]\n",
      "epoch:14 step:13444 [D loss: 0.467796, acc.: 74.22%] [G loss: 0.724876]\n",
      "epoch:14 step:13445 [D loss: 0.621346, acc.: 67.19%] [G loss: 0.750769]\n",
      "epoch:14 step:13446 [D loss: 0.463218, acc.: 78.12%] [G loss: 0.746171]\n",
      "epoch:14 step:13447 [D loss: 0.502039, acc.: 74.22%] [G loss: 0.723397]\n",
      "epoch:14 step:13448 [D loss: 0.527978, acc.: 72.66%] [G loss: 0.602795]\n",
      "epoch:14 step:13449 [D loss: 0.543936, acc.: 71.09%] [G loss: 0.675874]\n",
      "epoch:14 step:13450 [D loss: 0.536763, acc.: 73.44%] [G loss: 0.609623]\n",
      "epoch:14 step:13451 [D loss: 0.449089, acc.: 79.69%] [G loss: 0.656393]\n",
      "epoch:14 step:13452 [D loss: 0.463560, acc.: 78.12%] [G loss: 0.718444]\n",
      "epoch:14 step:13453 [D loss: 0.449765, acc.: 78.91%] [G loss: 0.724573]\n",
      "epoch:14 step:13454 [D loss: 0.510797, acc.: 74.22%] [G loss: 0.918386]\n",
      "epoch:14 step:13455 [D loss: 0.460828, acc.: 77.34%] [G loss: 0.772331]\n",
      "epoch:14 step:13456 [D loss: 0.579927, acc.: 64.84%] [G loss: 0.555324]\n",
      "epoch:14 step:13457 [D loss: 0.547309, acc.: 69.53%] [G loss: 0.575854]\n",
      "epoch:14 step:13458 [D loss: 0.460361, acc.: 76.56%] [G loss: 0.852520]\n",
      "epoch:14 step:13459 [D loss: 0.537873, acc.: 74.22%] [G loss: 0.791366]\n",
      "epoch:14 step:13460 [D loss: 0.711814, acc.: 57.81%] [G loss: 0.485674]\n",
      "epoch:14 step:13461 [D loss: 0.493552, acc.: 77.34%] [G loss: 0.506054]\n",
      "epoch:14 step:13462 [D loss: 0.492097, acc.: 72.66%] [G loss: 0.805375]\n",
      "epoch:14 step:13463 [D loss: 0.505141, acc.: 70.31%] [G loss: 0.831328]\n",
      "epoch:14 step:13464 [D loss: 0.531590, acc.: 71.09%] [G loss: 0.752952]\n",
      "epoch:14 step:13465 [D loss: 0.532743, acc.: 78.12%] [G loss: 0.894759]\n",
      "epoch:14 step:13466 [D loss: 0.565738, acc.: 73.44%] [G loss: 0.873178]\n",
      "epoch:14 step:13467 [D loss: 0.643669, acc.: 64.84%] [G loss: 0.511554]\n",
      "epoch:14 step:13468 [D loss: 0.511447, acc.: 76.56%] [G loss: 0.570488]\n",
      "epoch:14 step:13469 [D loss: 0.547264, acc.: 69.53%] [G loss: 0.662142]\n",
      "epoch:14 step:13470 [D loss: 0.622987, acc.: 63.28%] [G loss: 0.656225]\n",
      "epoch:14 step:13471 [D loss: 0.581990, acc.: 67.19%] [G loss: 0.721085]\n",
      "epoch:14 step:13472 [D loss: 0.379860, acc.: 85.94%] [G loss: 0.859250]\n",
      "epoch:14 step:13473 [D loss: 0.487061, acc.: 77.34%] [G loss: 0.834438]\n",
      "epoch:14 step:13474 [D loss: 0.605548, acc.: 67.19%] [G loss: 0.665158]\n",
      "epoch:14 step:13475 [D loss: 0.411265, acc.: 84.38%] [G loss: 0.830788]\n",
      "epoch:14 step:13476 [D loss: 0.408828, acc.: 81.25%] [G loss: 0.898415]\n",
      "epoch:14 step:13477 [D loss: 0.473118, acc.: 78.91%] [G loss: 0.830153]\n",
      "epoch:14 step:13478 [D loss: 0.494848, acc.: 75.00%] [G loss: 0.871015]\n",
      "epoch:14 step:13479 [D loss: 0.520198, acc.: 76.56%] [G loss: 0.675001]\n",
      "epoch:14 step:13480 [D loss: 0.513857, acc.: 75.00%] [G loss: 0.771041]\n",
      "epoch:14 step:13481 [D loss: 0.541243, acc.: 70.31%] [G loss: 0.738286]\n",
      "epoch:14 step:13482 [D loss: 0.556016, acc.: 69.53%] [G loss: 0.555964]\n",
      "epoch:14 step:13483 [D loss: 0.501863, acc.: 74.22%] [G loss: 0.719177]\n",
      "epoch:14 step:13484 [D loss: 0.520217, acc.: 74.22%] [G loss: 0.849944]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:14 step:13485 [D loss: 0.543539, acc.: 74.22%] [G loss: 0.598963]\n",
      "epoch:14 step:13486 [D loss: 0.515607, acc.: 71.88%] [G loss: 0.719760]\n",
      "epoch:14 step:13487 [D loss: 0.553944, acc.: 64.84%] [G loss: 0.728056]\n",
      "epoch:14 step:13488 [D loss: 0.523119, acc.: 72.66%] [G loss: 0.687470]\n",
      "epoch:14 step:13489 [D loss: 0.469692, acc.: 82.81%] [G loss: 0.718489]\n",
      "epoch:14 step:13490 [D loss: 0.547552, acc.: 71.88%] [G loss: 0.613857]\n",
      "epoch:14 step:13491 [D loss: 0.534503, acc.: 73.44%] [G loss: 0.644235]\n",
      "epoch:14 step:13492 [D loss: 0.469730, acc.: 78.12%] [G loss: 0.898485]\n",
      "epoch:14 step:13493 [D loss: 0.550525, acc.: 70.31%] [G loss: 0.774762]\n",
      "epoch:14 step:13494 [D loss: 0.637763, acc.: 63.28%] [G loss: 0.587570]\n",
      "epoch:14 step:13495 [D loss: 0.581102, acc.: 67.19%] [G loss: 0.519413]\n",
      "epoch:14 step:13496 [D loss: 0.534542, acc.: 72.66%] [G loss: 0.744574]\n",
      "epoch:14 step:13497 [D loss: 0.565032, acc.: 72.66%] [G loss: 0.586533]\n",
      "epoch:14 step:13498 [D loss: 0.541270, acc.: 68.75%] [G loss: 0.538446]\n",
      "epoch:14 step:13499 [D loss: 0.456897, acc.: 78.91%] [G loss: 0.609378]\n",
      "epoch:14 step:13500 [D loss: 0.515612, acc.: 70.31%] [G loss: 0.772364]\n",
      "epoch:14 step:13501 [D loss: 0.526686, acc.: 67.97%] [G loss: 0.558410]\n",
      "epoch:14 step:13502 [D loss: 0.527187, acc.: 75.78%] [G loss: 0.538868]\n",
      "epoch:14 step:13503 [D loss: 0.465458, acc.: 76.56%] [G loss: 0.636332]\n",
      "epoch:14 step:13504 [D loss: 0.589169, acc.: 67.19%] [G loss: 0.491085]\n",
      "epoch:14 step:13505 [D loss: 0.560726, acc.: 67.97%] [G loss: 0.596155]\n",
      "epoch:14 step:13506 [D loss: 0.573587, acc.: 69.53%] [G loss: 0.751610]\n",
      "epoch:14 step:13507 [D loss: 0.517605, acc.: 73.44%] [G loss: 0.666528]\n",
      "epoch:14 step:13508 [D loss: 0.564796, acc.: 74.22%] [G loss: 0.575230]\n",
      "epoch:14 step:13509 [D loss: 0.559890, acc.: 68.75%] [G loss: 0.537414]\n",
      "epoch:14 step:13510 [D loss: 0.499141, acc.: 73.44%] [G loss: 0.705069]\n",
      "epoch:14 step:13511 [D loss: 0.571808, acc.: 66.41%] [G loss: 0.607433]\n",
      "epoch:14 step:13512 [D loss: 0.546387, acc.: 67.97%] [G loss: 0.523204]\n",
      "epoch:14 step:13513 [D loss: 0.545725, acc.: 71.09%] [G loss: 0.501144]\n",
      "epoch:14 step:13514 [D loss: 0.583831, acc.: 67.19%] [G loss: 0.606465]\n",
      "epoch:14 step:13515 [D loss: 0.602666, acc.: 67.19%] [G loss: 0.653081]\n",
      "epoch:14 step:13516 [D loss: 0.438996, acc.: 83.59%] [G loss: 0.983814]\n",
      "epoch:14 step:13517 [D loss: 0.500947, acc.: 79.69%] [G loss: 0.785731]\n",
      "epoch:14 step:13518 [D loss: 0.685254, acc.: 57.03%] [G loss: 0.617120]\n",
      "epoch:14 step:13519 [D loss: 0.603083, acc.: 61.72%] [G loss: 0.532534]\n",
      "epoch:14 step:13520 [D loss: 0.473808, acc.: 75.00%] [G loss: 0.669512]\n",
      "epoch:14 step:13521 [D loss: 0.489327, acc.: 75.78%] [G loss: 0.744317]\n",
      "epoch:14 step:13522 [D loss: 0.553541, acc.: 69.53%] [G loss: 0.754105]\n",
      "epoch:14 step:13523 [D loss: 0.581897, acc.: 67.97%] [G loss: 0.707153]\n",
      "epoch:14 step:13524 [D loss: 0.489573, acc.: 75.00%] [G loss: 0.850665]\n",
      "epoch:14 step:13525 [D loss: 0.626137, acc.: 61.72%] [G loss: 0.650035]\n",
      "epoch:14 step:13526 [D loss: 0.624995, acc.: 66.41%] [G loss: 0.505493]\n",
      "epoch:14 step:13527 [D loss: 0.598848, acc.: 63.28%] [G loss: 0.633714]\n",
      "epoch:14 step:13528 [D loss: 0.570296, acc.: 65.62%] [G loss: 0.558267]\n",
      "epoch:14 step:13529 [D loss: 0.605976, acc.: 64.06%] [G loss: 0.667549]\n",
      "epoch:14 step:13530 [D loss: 0.613133, acc.: 64.06%] [G loss: 0.441211]\n",
      "epoch:14 step:13531 [D loss: 0.491775, acc.: 74.22%] [G loss: 0.588305]\n",
      "epoch:14 step:13532 [D loss: 0.505062, acc.: 75.00%] [G loss: 0.804637]\n",
      "epoch:14 step:13533 [D loss: 0.519284, acc.: 72.66%] [G loss: 0.592641]\n",
      "epoch:14 step:13534 [D loss: 0.515920, acc.: 76.56%] [G loss: 0.687120]\n",
      "epoch:14 step:13535 [D loss: 0.536773, acc.: 75.78%] [G loss: 0.757254]\n",
      "epoch:14 step:13536 [D loss: 0.598077, acc.: 65.62%] [G loss: 0.621486]\n",
      "epoch:14 step:13537 [D loss: 0.586114, acc.: 69.53%] [G loss: 0.628299]\n",
      "epoch:14 step:13538 [D loss: 0.564157, acc.: 67.97%] [G loss: 0.475586]\n",
      "epoch:14 step:13539 [D loss: 0.628532, acc.: 61.72%] [G loss: 0.470681]\n",
      "epoch:14 step:13540 [D loss: 0.570855, acc.: 64.84%] [G loss: 0.661337]\n",
      "epoch:14 step:13541 [D loss: 0.524624, acc.: 71.09%] [G loss: 0.550676]\n",
      "epoch:14 step:13542 [D loss: 0.559090, acc.: 67.19%] [G loss: 0.607731]\n",
      "epoch:14 step:13543 [D loss: 0.563275, acc.: 67.19%] [G loss: 0.657009]\n",
      "epoch:14 step:13544 [D loss: 0.482255, acc.: 73.44%] [G loss: 0.760059]\n",
      "epoch:14 step:13545 [D loss: 0.473618, acc.: 76.56%] [G loss: 0.847051]\n",
      "epoch:14 step:13546 [D loss: 0.497993, acc.: 75.00%] [G loss: 0.587085]\n",
      "epoch:14 step:13547 [D loss: 0.430091, acc.: 79.69%] [G loss: 0.721337]\n",
      "epoch:14 step:13548 [D loss: 0.548657, acc.: 67.97%] [G loss: 0.784263]\n",
      "epoch:14 step:13549 [D loss: 0.468993, acc.: 73.44%] [G loss: 0.927788]\n",
      "epoch:14 step:13550 [D loss: 0.537046, acc.: 67.97%] [G loss: 0.653717]\n",
      "epoch:14 step:13551 [D loss: 0.581385, acc.: 63.28%] [G loss: 0.548820]\n",
      "epoch:14 step:13552 [D loss: 0.490647, acc.: 75.00%] [G loss: 0.737285]\n",
      "epoch:14 step:13553 [D loss: 0.507939, acc.: 74.22%] [G loss: 0.714492]\n",
      "epoch:14 step:13554 [D loss: 0.485691, acc.: 79.69%] [G loss: 0.633331]\n",
      "epoch:14 step:13555 [D loss: 0.659120, acc.: 63.28%] [G loss: 0.621091]\n",
      "epoch:14 step:13556 [D loss: 0.556017, acc.: 70.31%] [G loss: 0.571000]\n",
      "epoch:14 step:13557 [D loss: 0.530481, acc.: 74.22%] [G loss: 0.574413]\n",
      "epoch:14 step:13558 [D loss: 0.481436, acc.: 77.34%] [G loss: 0.773739]\n",
      "epoch:14 step:13559 [D loss: 0.567778, acc.: 66.41%] [G loss: 0.720986]\n",
      "epoch:14 step:13560 [D loss: 0.579089, acc.: 66.41%] [G loss: 0.751436]\n",
      "epoch:14 step:13561 [D loss: 0.540595, acc.: 73.44%] [G loss: 0.590104]\n",
      "epoch:14 step:13562 [D loss: 0.545402, acc.: 70.31%] [G loss: 0.694014]\n",
      "epoch:14 step:13563 [D loss: 0.549317, acc.: 71.09%] [G loss: 0.641909]\n",
      "epoch:14 step:13564 [D loss: 0.531680, acc.: 69.53%] [G loss: 0.798447]\n",
      "epoch:14 step:13565 [D loss: 0.507629, acc.: 72.66%] [G loss: 0.720254]\n",
      "epoch:14 step:13566 [D loss: 0.544781, acc.: 69.53%] [G loss: 0.679866]\n",
      "epoch:14 step:13567 [D loss: 0.489233, acc.: 78.12%] [G loss: 0.715778]\n",
      "epoch:14 step:13568 [D loss: 0.529381, acc.: 71.09%] [G loss: 0.714149]\n",
      "epoch:14 step:13569 [D loss: 0.408461, acc.: 81.25%] [G loss: 0.770340]\n",
      "epoch:14 step:13570 [D loss: 0.496747, acc.: 74.22%] [G loss: 0.703517]\n",
      "epoch:14 step:13571 [D loss: 0.508407, acc.: 74.22%] [G loss: 0.692197]\n",
      "epoch:14 step:13572 [D loss: 0.506778, acc.: 78.91%] [G loss: 0.741654]\n",
      "epoch:14 step:13573 [D loss: 0.530574, acc.: 75.00%] [G loss: 0.785719]\n",
      "epoch:14 step:13574 [D loss: 0.565978, acc.: 68.75%] [G loss: 0.575348]\n",
      "epoch:14 step:13575 [D loss: 0.516592, acc.: 74.22%] [G loss: 0.689637]\n",
      "epoch:14 step:13576 [D loss: 0.631377, acc.: 63.28%] [G loss: 0.675937]\n",
      "epoch:14 step:13577 [D loss: 0.575325, acc.: 67.97%] [G loss: 0.689835]\n",
      "epoch:14 step:13578 [D loss: 0.504828, acc.: 73.44%] [G loss: 0.706185]\n",
      "epoch:14 step:13579 [D loss: 0.482215, acc.: 75.78%] [G loss: 0.653964]\n",
      "epoch:14 step:13580 [D loss: 0.577120, acc.: 60.94%] [G loss: 0.653230]\n",
      "epoch:14 step:13581 [D loss: 0.527591, acc.: 71.88%] [G loss: 0.652731]\n",
      "epoch:14 step:13582 [D loss: 0.527102, acc.: 71.09%] [G loss: 0.595464]\n",
      "epoch:14 step:13583 [D loss: 0.608744, acc.: 65.62%] [G loss: 0.632672]\n",
      "epoch:14 step:13584 [D loss: 0.540644, acc.: 67.19%] [G loss: 0.665479]\n",
      "epoch:14 step:13585 [D loss: 0.575080, acc.: 67.97%] [G loss: 0.668370]\n",
      "epoch:14 step:13586 [D loss: 0.504409, acc.: 71.09%] [G loss: 0.741310]\n",
      "epoch:14 step:13587 [D loss: 0.510562, acc.: 74.22%] [G loss: 0.769160]\n",
      "epoch:14 step:13588 [D loss: 0.524939, acc.: 74.22%] [G loss: 0.748970]\n",
      "epoch:14 step:13589 [D loss: 0.466434, acc.: 76.56%] [G loss: 0.776905]\n",
      "epoch:14 step:13590 [D loss: 0.463680, acc.: 81.25%] [G loss: 0.906122]\n",
      "epoch:14 step:13591 [D loss: 0.668059, acc.: 60.94%] [G loss: 0.676389]\n",
      "epoch:14 step:13592 [D loss: 0.553970, acc.: 66.41%] [G loss: 0.610205]\n",
      "epoch:14 step:13593 [D loss: 0.499484, acc.: 76.56%] [G loss: 0.576886]\n",
      "epoch:14 step:13594 [D loss: 0.496364, acc.: 81.25%] [G loss: 0.576304]\n",
      "epoch:14 step:13595 [D loss: 0.637483, acc.: 63.28%] [G loss: 0.567263]\n",
      "epoch:14 step:13596 [D loss: 0.516065, acc.: 77.34%] [G loss: 0.523576]\n",
      "epoch:14 step:13597 [D loss: 0.555144, acc.: 65.62%] [G loss: 0.556836]\n",
      "epoch:14 step:13598 [D loss: 0.599151, acc.: 66.41%] [G loss: 0.435744]\n",
      "epoch:14 step:13599 [D loss: 0.483361, acc.: 81.25%] [G loss: 0.658533]\n",
      "epoch:14 step:13600 [D loss: 0.576226, acc.: 67.97%] [G loss: 0.568509]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:14 step:13601 [D loss: 0.545361, acc.: 71.09%] [G loss: 0.600098]\n",
      "epoch:14 step:13602 [D loss: 0.555102, acc.: 71.88%] [G loss: 0.597094]\n",
      "epoch:14 step:13603 [D loss: 0.500083, acc.: 76.56%] [G loss: 0.848532]\n",
      "epoch:14 step:13604 [D loss: 0.547408, acc.: 70.31%] [G loss: 0.580859]\n",
      "epoch:14 step:13605 [D loss: 0.546500, acc.: 69.53%] [G loss: 0.628586]\n",
      "epoch:14 step:13606 [D loss: 0.480615, acc.: 70.31%] [G loss: 0.762937]\n",
      "epoch:14 step:13607 [D loss: 0.503948, acc.: 73.44%] [G loss: 0.674594]\n",
      "epoch:14 step:13608 [D loss: 0.565879, acc.: 67.97%] [G loss: 0.683780]\n",
      "epoch:14 step:13609 [D loss: 0.515801, acc.: 73.44%] [G loss: 0.533176]\n",
      "epoch:14 step:13610 [D loss: 0.566610, acc.: 69.53%] [G loss: 0.614090]\n",
      "epoch:14 step:13611 [D loss: 0.565812, acc.: 69.53%] [G loss: 0.658123]\n",
      "epoch:14 step:13612 [D loss: 0.561599, acc.: 75.00%] [G loss: 0.388127]\n",
      "epoch:14 step:13613 [D loss: 0.510318, acc.: 75.00%] [G loss: 0.484435]\n",
      "epoch:14 step:13614 [D loss: 0.523759, acc.: 72.66%] [G loss: 0.460501]\n",
      "epoch:14 step:13615 [D loss: 0.530525, acc.: 71.09%] [G loss: 0.615535]\n",
      "epoch:14 step:13616 [D loss: 0.512022, acc.: 71.88%] [G loss: 0.643569]\n",
      "epoch:14 step:13617 [D loss: 0.457840, acc.: 75.78%] [G loss: 0.832980]\n",
      "epoch:14 step:13618 [D loss: 0.593261, acc.: 64.84%] [G loss: 0.758424]\n",
      "epoch:14 step:13619 [D loss: 0.595665, acc.: 70.31%] [G loss: 0.785440]\n",
      "epoch:14 step:13620 [D loss: 0.635339, acc.: 62.50%] [G loss: 0.434215]\n",
      "epoch:14 step:13621 [D loss: 0.448590, acc.: 77.34%] [G loss: 0.727592]\n",
      "epoch:14 step:13622 [D loss: 0.460894, acc.: 80.47%] [G loss: 0.785828]\n",
      "epoch:14 step:13623 [D loss: 0.471325, acc.: 80.47%] [G loss: 0.884191]\n",
      "epoch:14 step:13624 [D loss: 0.487533, acc.: 77.34%] [G loss: 1.058607]\n",
      "epoch:14 step:13625 [D loss: 0.476197, acc.: 78.91%] [G loss: 0.824154]\n",
      "epoch:14 step:13626 [D loss: 0.449598, acc.: 81.25%] [G loss: 0.767925]\n",
      "epoch:14 step:13627 [D loss: 0.500787, acc.: 72.66%] [G loss: 0.777254]\n",
      "epoch:14 step:13628 [D loss: 0.567661, acc.: 70.31%] [G loss: 0.695856]\n",
      "epoch:14 step:13629 [D loss: 0.609125, acc.: 64.06%] [G loss: 0.586781]\n",
      "epoch:14 step:13630 [D loss: 0.562675, acc.: 66.41%] [G loss: 0.653285]\n",
      "epoch:14 step:13631 [D loss: 0.504645, acc.: 71.09%] [G loss: 0.593586]\n",
      "epoch:14 step:13632 [D loss: 0.483162, acc.: 70.31%] [G loss: 0.646491]\n",
      "epoch:14 step:13633 [D loss: 0.507520, acc.: 73.44%] [G loss: 0.650749]\n",
      "epoch:14 step:13634 [D loss: 0.485318, acc.: 75.00%] [G loss: 0.674648]\n",
      "epoch:14 step:13635 [D loss: 0.458962, acc.: 85.16%] [G loss: 0.732731]\n",
      "epoch:14 step:13636 [D loss: 0.515923, acc.: 72.66%] [G loss: 0.774071]\n",
      "epoch:14 step:13637 [D loss: 0.486622, acc.: 76.56%] [G loss: 0.651659]\n",
      "epoch:14 step:13638 [D loss: 0.517808, acc.: 74.22%] [G loss: 0.770483]\n",
      "epoch:14 step:13639 [D loss: 0.535268, acc.: 72.66%] [G loss: 0.772060]\n",
      "epoch:14 step:13640 [D loss: 0.497100, acc.: 75.78%] [G loss: 0.702501]\n",
      "epoch:14 step:13641 [D loss: 0.496100, acc.: 75.78%] [G loss: 0.718160]\n",
      "epoch:14 step:13642 [D loss: 0.572068, acc.: 67.97%] [G loss: 0.699361]\n",
      "epoch:14 step:13643 [D loss: 0.563673, acc.: 67.97%] [G loss: 0.683837]\n",
      "epoch:14 step:13644 [D loss: 0.477357, acc.: 78.12%] [G loss: 0.739250]\n",
      "epoch:14 step:13645 [D loss: 0.565483, acc.: 69.53%] [G loss: 0.672775]\n",
      "epoch:14 step:13646 [D loss: 0.703722, acc.: 57.81%] [G loss: 0.471555]\n",
      "epoch:14 step:13647 [D loss: 0.566499, acc.: 64.84%] [G loss: 0.501054]\n",
      "epoch:14 step:13648 [D loss: 0.527692, acc.: 71.09%] [G loss: 0.496195]\n",
      "epoch:14 step:13649 [D loss: 0.546762, acc.: 68.75%] [G loss: 0.719888]\n",
      "epoch:14 step:13650 [D loss: 0.584393, acc.: 69.53%] [G loss: 0.688965]\n",
      "epoch:14 step:13651 [D loss: 0.532961, acc.: 70.31%] [G loss: 0.472285]\n",
      "epoch:14 step:13652 [D loss: 0.452975, acc.: 76.56%] [G loss: 0.601979]\n",
      "epoch:14 step:13653 [D loss: 0.621284, acc.: 62.50%] [G loss: 0.489126]\n",
      "epoch:14 step:13654 [D loss: 0.445459, acc.: 76.56%] [G loss: 0.677749]\n",
      "epoch:14 step:13655 [D loss: 0.541736, acc.: 74.22%] [G loss: 0.609820]\n",
      "epoch:14 step:13656 [D loss: 0.558877, acc.: 67.19%] [G loss: 0.645362]\n",
      "epoch:14 step:13657 [D loss: 0.529044, acc.: 74.22%] [G loss: 0.623739]\n",
      "epoch:14 step:13658 [D loss: 0.547967, acc.: 64.84%] [G loss: 0.635888]\n",
      "epoch:14 step:13659 [D loss: 0.584293, acc.: 66.41%] [G loss: 0.523618]\n",
      "epoch:14 step:13660 [D loss: 0.583917, acc.: 66.41%] [G loss: 0.642048]\n",
      "epoch:14 step:13661 [D loss: 0.567338, acc.: 67.97%] [G loss: 0.488859]\n",
      "epoch:14 step:13662 [D loss: 0.572122, acc.: 71.88%] [G loss: 0.436639]\n",
      "epoch:14 step:13663 [D loss: 0.566639, acc.: 70.31%] [G loss: 0.624347]\n",
      "epoch:14 step:13664 [D loss: 0.478282, acc.: 82.81%] [G loss: 0.713067]\n",
      "epoch:14 step:13665 [D loss: 0.559111, acc.: 69.53%] [G loss: 0.665196]\n",
      "epoch:14 step:13666 [D loss: 0.504342, acc.: 71.09%] [G loss: 0.630836]\n",
      "epoch:14 step:13667 [D loss: 0.506860, acc.: 73.44%] [G loss: 0.684708]\n",
      "epoch:14 step:13668 [D loss: 0.567187, acc.: 69.53%] [G loss: 0.616137]\n",
      "epoch:14 step:13669 [D loss: 0.504169, acc.: 77.34%] [G loss: 0.765202]\n",
      "epoch:14 step:13670 [D loss: 0.472497, acc.: 77.34%] [G loss: 0.586662]\n",
      "epoch:14 step:13671 [D loss: 0.572495, acc.: 67.97%] [G loss: 0.530330]\n",
      "epoch:14 step:13672 [D loss: 0.442269, acc.: 80.47%] [G loss: 0.607491]\n",
      "epoch:14 step:13673 [D loss: 0.483538, acc.: 76.56%] [G loss: 0.676040]\n",
      "epoch:14 step:13674 [D loss: 0.523987, acc.: 70.31%] [G loss: 0.644545]\n",
      "epoch:14 step:13675 [D loss: 0.508914, acc.: 73.44%] [G loss: 0.608243]\n",
      "epoch:14 step:13676 [D loss: 0.469836, acc.: 77.34%] [G loss: 0.652986]\n",
      "epoch:14 step:13677 [D loss: 0.596982, acc.: 63.28%] [G loss: 0.676329]\n",
      "epoch:14 step:13678 [D loss: 0.546566, acc.: 72.66%] [G loss: 0.473216]\n",
      "epoch:14 step:13679 [D loss: 0.499237, acc.: 76.56%] [G loss: 0.611114]\n",
      "epoch:14 step:13680 [D loss: 0.564239, acc.: 67.19%] [G loss: 0.488823]\n",
      "epoch:14 step:13681 [D loss: 0.501407, acc.: 77.34%] [G loss: 0.576107]\n",
      "epoch:14 step:13682 [D loss: 0.521611, acc.: 72.66%] [G loss: 0.635697]\n",
      "epoch:14 step:13683 [D loss: 0.506761, acc.: 75.78%] [G loss: 0.812295]\n",
      "epoch:14 step:13684 [D loss: 0.637345, acc.: 63.28%] [G loss: 0.536445]\n",
      "epoch:14 step:13685 [D loss: 0.501068, acc.: 74.22%] [G loss: 0.639189]\n",
      "epoch:14 step:13686 [D loss: 0.482420, acc.: 77.34%] [G loss: 0.659981]\n",
      "epoch:14 step:13687 [D loss: 0.501639, acc.: 77.34%] [G loss: 0.662356]\n",
      "epoch:14 step:13688 [D loss: 0.523715, acc.: 76.56%] [G loss: 0.671099]\n",
      "epoch:14 step:13689 [D loss: 0.533753, acc.: 74.22%] [G loss: 0.768817]\n",
      "epoch:14 step:13690 [D loss: 0.554837, acc.: 71.88%] [G loss: 0.581731]\n",
      "epoch:14 step:13691 [D loss: 0.631335, acc.: 62.50%] [G loss: 0.626477]\n",
      "epoch:14 step:13692 [D loss: 0.482352, acc.: 75.00%] [G loss: 0.660719]\n",
      "epoch:14 step:13693 [D loss: 0.492066, acc.: 78.91%] [G loss: 0.765199]\n",
      "epoch:14 step:13694 [D loss: 0.628679, acc.: 62.50%] [G loss: 0.646206]\n",
      "epoch:14 step:13695 [D loss: 0.509601, acc.: 74.22%] [G loss: 0.687181]\n",
      "epoch:14 step:13696 [D loss: 0.593218, acc.: 69.53%] [G loss: 0.585348]\n",
      "epoch:14 step:13697 [D loss: 0.491559, acc.: 68.75%] [G loss: 0.614697]\n",
      "epoch:14 step:13698 [D loss: 0.549078, acc.: 74.22%] [G loss: 0.606447]\n",
      "epoch:14 step:13699 [D loss: 0.537333, acc.: 73.44%] [G loss: 0.603996]\n",
      "epoch:14 step:13700 [D loss: 0.478689, acc.: 80.47%] [G loss: 0.825830]\n",
      "epoch:14 step:13701 [D loss: 0.568960, acc.: 73.44%] [G loss: 0.617304]\n",
      "epoch:14 step:13702 [D loss: 0.581762, acc.: 69.53%] [G loss: 0.621702]\n",
      "epoch:14 step:13703 [D loss: 0.504839, acc.: 75.00%] [G loss: 0.645553]\n",
      "epoch:14 step:13704 [D loss: 0.540318, acc.: 71.88%] [G loss: 0.498735]\n",
      "epoch:14 step:13705 [D loss: 0.553870, acc.: 67.97%] [G loss: 0.538995]\n",
      "epoch:14 step:13706 [D loss: 0.535734, acc.: 70.31%] [G loss: 0.765364]\n",
      "epoch:14 step:13707 [D loss: 0.539966, acc.: 64.84%] [G loss: 0.681859]\n",
      "epoch:14 step:13708 [D loss: 0.570752, acc.: 71.09%] [G loss: 0.559696]\n",
      "epoch:14 step:13709 [D loss: 0.591872, acc.: 67.97%] [G loss: 0.529831]\n",
      "epoch:14 step:13710 [D loss: 0.486994, acc.: 78.12%] [G loss: 0.499774]\n",
      "epoch:14 step:13711 [D loss: 0.505737, acc.: 76.56%] [G loss: 0.622678]\n",
      "epoch:14 step:13712 [D loss: 0.510881, acc.: 75.00%] [G loss: 0.642286]\n",
      "epoch:14 step:13713 [D loss: 0.546550, acc.: 74.22%] [G loss: 0.499369]\n",
      "epoch:14 step:13714 [D loss: 0.512964, acc.: 71.88%] [G loss: 0.538090]\n",
      "epoch:14 step:13715 [D loss: 0.538813, acc.: 70.31%] [G loss: 0.704760]\n",
      "epoch:14 step:13716 [D loss: 0.502182, acc.: 75.00%] [G loss: 0.731353]\n",
      "epoch:14 step:13717 [D loss: 0.519148, acc.: 71.88%] [G loss: 0.634779]\n",
      "epoch:14 step:13718 [D loss: 0.582013, acc.: 69.53%] [G loss: 0.541860]\n",
      "epoch:14 step:13719 [D loss: 0.461050, acc.: 75.00%] [G loss: 0.607150]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:14 step:13720 [D loss: 0.446136, acc.: 76.56%] [G loss: 0.634481]\n",
      "epoch:14 step:13721 [D loss: 0.443726, acc.: 78.12%] [G loss: 0.642874]\n",
      "epoch:14 step:13722 [D loss: 0.565225, acc.: 69.53%] [G loss: 0.650927]\n",
      "epoch:14 step:13723 [D loss: 0.441961, acc.: 81.25%] [G loss: 0.686901]\n",
      "epoch:14 step:13724 [D loss: 0.573381, acc.: 65.62%] [G loss: 0.701137]\n",
      "epoch:14 step:13725 [D loss: 0.524310, acc.: 71.88%] [G loss: 0.643331]\n",
      "epoch:14 step:13726 [D loss: 0.550461, acc.: 71.09%] [G loss: 0.516729]\n",
      "epoch:14 step:13727 [D loss: 0.509161, acc.: 72.66%] [G loss: 0.638608]\n",
      "epoch:14 step:13728 [D loss: 0.554077, acc.: 67.97%] [G loss: 0.740871]\n",
      "epoch:14 step:13729 [D loss: 0.532945, acc.: 71.09%] [G loss: 0.575793]\n",
      "epoch:14 step:13730 [D loss: 0.515928, acc.: 71.09%] [G loss: 0.787524]\n",
      "epoch:14 step:13731 [D loss: 0.492785, acc.: 73.44%] [G loss: 0.574868]\n",
      "epoch:14 step:13732 [D loss: 0.560410, acc.: 70.31%] [G loss: 0.646560]\n",
      "epoch:14 step:13733 [D loss: 0.601413, acc.: 65.62%] [G loss: 0.516223]\n",
      "epoch:14 step:13734 [D loss: 0.546438, acc.: 70.31%] [G loss: 0.625928]\n",
      "epoch:14 step:13735 [D loss: 0.500562, acc.: 75.78%] [G loss: 0.627493]\n",
      "epoch:14 step:13736 [D loss: 0.546738, acc.: 73.44%] [G loss: 0.798953]\n",
      "epoch:14 step:13737 [D loss: 0.503458, acc.: 74.22%] [G loss: 0.761680]\n",
      "epoch:14 step:13738 [D loss: 0.528238, acc.: 71.09%] [G loss: 0.553151]\n",
      "epoch:14 step:13739 [D loss: 0.558509, acc.: 71.09%] [G loss: 0.601806]\n",
      "epoch:14 step:13740 [D loss: 0.573131, acc.: 71.09%] [G loss: 0.478710]\n",
      "epoch:14 step:13741 [D loss: 0.499143, acc.: 75.00%] [G loss: 0.671291]\n",
      "epoch:14 step:13742 [D loss: 0.463455, acc.: 81.25%] [G loss: 0.823962]\n",
      "epoch:14 step:13743 [D loss: 0.581737, acc.: 62.50%] [G loss: 0.485797]\n",
      "epoch:14 step:13744 [D loss: 0.549170, acc.: 70.31%] [G loss: 0.613294]\n",
      "epoch:14 step:13745 [D loss: 0.538360, acc.: 73.44%] [G loss: 0.632347]\n",
      "epoch:14 step:13746 [D loss: 0.545381, acc.: 69.53%] [G loss: 0.562993]\n",
      "epoch:14 step:13747 [D loss: 0.519318, acc.: 68.75%] [G loss: 0.505154]\n",
      "epoch:14 step:13748 [D loss: 0.507992, acc.: 76.56%] [G loss: 0.548187]\n",
      "epoch:14 step:13749 [D loss: 0.462641, acc.: 78.12%] [G loss: 0.683777]\n",
      "epoch:14 step:13750 [D loss: 0.492658, acc.: 77.34%] [G loss: 0.689050]\n",
      "epoch:14 step:13751 [D loss: 0.522628, acc.: 69.53%] [G loss: 0.611243]\n",
      "epoch:14 step:13752 [D loss: 0.506447, acc.: 79.69%] [G loss: 0.660729]\n",
      "epoch:14 step:13753 [D loss: 0.477588, acc.: 76.56%] [G loss: 0.863009]\n",
      "epoch:14 step:13754 [D loss: 0.569327, acc.: 71.88%] [G loss: 0.487166]\n",
      "epoch:14 step:13755 [D loss: 0.495518, acc.: 75.78%] [G loss: 0.560998]\n",
      "epoch:14 step:13756 [D loss: 0.504161, acc.: 75.78%] [G loss: 0.730618]\n",
      "epoch:14 step:13757 [D loss: 0.488278, acc.: 73.44%] [G loss: 0.560174]\n",
      "epoch:14 step:13758 [D loss: 0.525839, acc.: 77.34%] [G loss: 0.603054]\n",
      "epoch:14 step:13759 [D loss: 0.534455, acc.: 71.09%] [G loss: 0.668651]\n",
      "epoch:14 step:13760 [D loss: 0.479781, acc.: 73.44%] [G loss: 1.120913]\n",
      "epoch:14 step:13761 [D loss: 0.508728, acc.: 75.78%] [G loss: 0.795316]\n",
      "epoch:14 step:13762 [D loss: 0.544342, acc.: 70.31%] [G loss: 0.688831]\n",
      "epoch:14 step:13763 [D loss: 0.510227, acc.: 71.09%] [G loss: 0.669884]\n",
      "epoch:14 step:13764 [D loss: 0.503741, acc.: 75.78%] [G loss: 0.688075]\n",
      "epoch:14 step:13765 [D loss: 0.453450, acc.: 77.34%] [G loss: 0.676705]\n",
      "epoch:14 step:13766 [D loss: 0.402837, acc.: 83.59%] [G loss: 1.010791]\n",
      "epoch:14 step:13767 [D loss: 0.506557, acc.: 73.44%] [G loss: 0.990155]\n",
      "epoch:14 step:13768 [D loss: 0.479796, acc.: 75.00%] [G loss: 0.868556]\n",
      "epoch:14 step:13769 [D loss: 0.517664, acc.: 76.56%] [G loss: 0.598101]\n",
      "epoch:14 step:13770 [D loss: 0.631968, acc.: 60.94%] [G loss: 0.572309]\n",
      "epoch:14 step:13771 [D loss: 0.548383, acc.: 70.31%] [G loss: 0.646499]\n",
      "epoch:14 step:13772 [D loss: 0.471894, acc.: 77.34%] [G loss: 0.756324]\n",
      "epoch:14 step:13773 [D loss: 0.594105, acc.: 67.97%] [G loss: 0.739411]\n",
      "epoch:14 step:13774 [D loss: 0.512041, acc.: 72.66%] [G loss: 0.794480]\n",
      "epoch:14 step:13775 [D loss: 0.563635, acc.: 71.09%] [G loss: 0.725637]\n",
      "epoch:14 step:13776 [D loss: 0.577694, acc.: 67.19%] [G loss: 0.736545]\n",
      "epoch:14 step:13777 [D loss: 0.540822, acc.: 71.88%] [G loss: 0.666860]\n",
      "epoch:14 step:13778 [D loss: 0.532201, acc.: 71.09%] [G loss: 0.574192]\n",
      "epoch:14 step:13779 [D loss: 0.477591, acc.: 78.91%] [G loss: 0.653519]\n",
      "epoch:14 step:13780 [D loss: 0.562823, acc.: 68.75%] [G loss: 0.597347]\n",
      "epoch:14 step:13781 [D loss: 0.558655, acc.: 67.19%] [G loss: 0.520497]\n",
      "epoch:14 step:13782 [D loss: 0.530019, acc.: 70.31%] [G loss: 0.678955]\n",
      "epoch:14 step:13783 [D loss: 0.578585, acc.: 66.41%] [G loss: 0.646183]\n",
      "epoch:14 step:13784 [D loss: 0.518612, acc.: 71.88%] [G loss: 0.664304]\n",
      "epoch:14 step:13785 [D loss: 0.571063, acc.: 71.09%] [G loss: 0.601171]\n",
      "epoch:14 step:13786 [D loss: 0.585335, acc.: 71.09%] [G loss: 0.657387]\n",
      "epoch:14 step:13787 [D loss: 0.519136, acc.: 69.53%] [G loss: 0.560941]\n",
      "epoch:14 step:13788 [D loss: 0.561967, acc.: 67.19%] [G loss: 0.617550]\n",
      "epoch:14 step:13789 [D loss: 0.512756, acc.: 71.88%] [G loss: 0.630504]\n",
      "epoch:14 step:13790 [D loss: 0.552580, acc.: 67.97%] [G loss: 0.652822]\n",
      "epoch:14 step:13791 [D loss: 0.548728, acc.: 67.19%] [G loss: 0.792204]\n",
      "epoch:14 step:13792 [D loss: 0.542828, acc.: 71.88%] [G loss: 0.701238]\n",
      "epoch:14 step:13793 [D loss: 0.611191, acc.: 61.72%] [G loss: 0.543220]\n",
      "epoch:14 step:13794 [D loss: 0.525074, acc.: 74.22%] [G loss: 0.701500]\n",
      "epoch:14 step:13795 [D loss: 0.500449, acc.: 72.66%] [G loss: 0.779179]\n",
      "epoch:14 step:13796 [D loss: 0.546929, acc.: 72.66%] [G loss: 0.561197]\n",
      "epoch:14 step:13797 [D loss: 0.521358, acc.: 73.44%] [G loss: 0.728320]\n",
      "epoch:14 step:13798 [D loss: 0.536833, acc.: 74.22%] [G loss: 0.783547]\n",
      "epoch:14 step:13799 [D loss: 0.450622, acc.: 78.12%] [G loss: 0.573127]\n",
      "epoch:14 step:13800 [D loss: 0.546000, acc.: 69.53%] [G loss: 0.758725]\n",
      "epoch:14 step:13801 [D loss: 0.496338, acc.: 72.66%] [G loss: 0.516865]\n",
      "epoch:14 step:13802 [D loss: 0.587743, acc.: 66.41%] [G loss: 0.476442]\n",
      "epoch:14 step:13803 [D loss: 0.507446, acc.: 75.00%] [G loss: 0.441953]\n",
      "epoch:14 step:13804 [D loss: 0.538932, acc.: 71.88%] [G loss: 0.515854]\n",
      "epoch:14 step:13805 [D loss: 0.598489, acc.: 67.97%] [G loss: 0.450544]\n",
      "epoch:14 step:13806 [D loss: 0.520306, acc.: 72.66%] [G loss: 0.640896]\n",
      "epoch:14 step:13807 [D loss: 0.599296, acc.: 64.84%] [G loss: 0.579112]\n",
      "epoch:14 step:13808 [D loss: 0.571207, acc.: 71.88%] [G loss: 0.769259]\n",
      "epoch:14 step:13809 [D loss: 0.453445, acc.: 80.47%] [G loss: 0.658062]\n",
      "epoch:14 step:13810 [D loss: 0.495677, acc.: 76.56%] [G loss: 0.733541]\n",
      "epoch:14 step:13811 [D loss: 0.471808, acc.: 79.69%] [G loss: 0.747588]\n",
      "epoch:14 step:13812 [D loss: 0.541901, acc.: 68.75%] [G loss: 0.751880]\n",
      "epoch:14 step:13813 [D loss: 0.503865, acc.: 75.78%] [G loss: 0.968660]\n",
      "epoch:14 step:13814 [D loss: 0.646208, acc.: 64.06%] [G loss: 0.669611]\n",
      "epoch:14 step:13815 [D loss: 0.599925, acc.: 62.50%] [G loss: 0.459332]\n",
      "epoch:14 step:13816 [D loss: 0.551474, acc.: 68.75%] [G loss: 0.451853]\n",
      "epoch:14 step:13817 [D loss: 0.526533, acc.: 72.66%] [G loss: 0.629217]\n",
      "epoch:14 step:13818 [D loss: 0.536271, acc.: 71.09%] [G loss: 0.697417]\n",
      "epoch:14 step:13819 [D loss: 0.494485, acc.: 75.78%] [G loss: 0.742896]\n",
      "epoch:14 step:13820 [D loss: 0.604161, acc.: 65.62%] [G loss: 0.606198]\n",
      "epoch:14 step:13821 [D loss: 0.561309, acc.: 71.09%] [G loss: 0.585087]\n",
      "epoch:14 step:13822 [D loss: 0.591368, acc.: 64.84%] [G loss: 0.644004]\n",
      "epoch:14 step:13823 [D loss: 0.546360, acc.: 69.53%] [G loss: 0.543500]\n",
      "epoch:14 step:13824 [D loss: 0.543873, acc.: 72.66%] [G loss: 0.646367]\n",
      "epoch:14 step:13825 [D loss: 0.488078, acc.: 75.00%] [G loss: 0.753881]\n",
      "epoch:14 step:13826 [D loss: 0.485719, acc.: 77.34%] [G loss: 0.684125]\n",
      "epoch:14 step:13827 [D loss: 0.535132, acc.: 75.78%] [G loss: 0.697222]\n",
      "epoch:14 step:13828 [D loss: 0.570184, acc.: 68.75%] [G loss: 0.733761]\n",
      "epoch:14 step:13829 [D loss: 0.547062, acc.: 69.53%] [G loss: 0.581194]\n",
      "epoch:14 step:13830 [D loss: 0.534246, acc.: 68.75%] [G loss: 0.591224]\n",
      "epoch:14 step:13831 [D loss: 0.572657, acc.: 71.09%] [G loss: 0.663094]\n",
      "epoch:14 step:13832 [D loss: 0.543984, acc.: 67.97%] [G loss: 0.641588]\n",
      "epoch:14 step:13833 [D loss: 0.555636, acc.: 72.66%] [G loss: 0.550362]\n",
      "epoch:14 step:13834 [D loss: 0.653139, acc.: 60.94%] [G loss: 0.597294]\n",
      "epoch:14 step:13835 [D loss: 0.578325, acc.: 67.97%] [G loss: 0.501069]\n",
      "epoch:14 step:13836 [D loss: 0.590086, acc.: 65.62%] [G loss: 0.552789]\n",
      "epoch:14 step:13837 [D loss: 0.528368, acc.: 74.22%] [G loss: 0.617322]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:14 step:13838 [D loss: 0.612354, acc.: 67.97%] [G loss: 0.625514]\n",
      "epoch:14 step:13839 [D loss: 0.500135, acc.: 78.91%] [G loss: 0.612756]\n",
      "epoch:14 step:13840 [D loss: 0.557945, acc.: 67.19%] [G loss: 0.629485]\n",
      "epoch:14 step:13841 [D loss: 0.538004, acc.: 69.53%] [G loss: 0.620133]\n",
      "epoch:14 step:13842 [D loss: 0.523337, acc.: 75.00%] [G loss: 0.632642]\n",
      "epoch:14 step:13843 [D loss: 0.503715, acc.: 75.78%] [G loss: 0.825902]\n",
      "epoch:14 step:13844 [D loss: 0.537990, acc.: 72.66%] [G loss: 0.704220]\n",
      "epoch:14 step:13845 [D loss: 0.551764, acc.: 67.19%] [G loss: 0.742829]\n",
      "epoch:14 step:13846 [D loss: 0.544276, acc.: 67.97%] [G loss: 0.680344]\n",
      "epoch:14 step:13847 [D loss: 0.586442, acc.: 69.53%] [G loss: 0.449336]\n",
      "epoch:14 step:13848 [D loss: 0.533781, acc.: 73.44%] [G loss: 0.493709]\n",
      "epoch:14 step:13849 [D loss: 0.609707, acc.: 57.81%] [G loss: 0.488588]\n",
      "epoch:14 step:13850 [D loss: 0.516350, acc.: 72.66%] [G loss: 0.550119]\n",
      "epoch:14 step:13851 [D loss: 0.568223, acc.: 65.62%] [G loss: 0.662136]\n",
      "epoch:14 step:13852 [D loss: 0.479150, acc.: 74.22%] [G loss: 0.580282]\n",
      "epoch:14 step:13853 [D loss: 0.572003, acc.: 65.62%] [G loss: 0.530575]\n",
      "epoch:14 step:13854 [D loss: 0.512242, acc.: 71.88%] [G loss: 0.552650]\n",
      "epoch:14 step:13855 [D loss: 0.532731, acc.: 70.31%] [G loss: 0.631873]\n",
      "epoch:14 step:13856 [D loss: 0.543506, acc.: 69.53%] [G loss: 0.636138]\n",
      "epoch:14 step:13857 [D loss: 0.570122, acc.: 68.75%] [G loss: 0.491910]\n",
      "epoch:14 step:13858 [D loss: 0.574685, acc.: 67.19%] [G loss: 0.471701]\n",
      "epoch:14 step:13859 [D loss: 0.578989, acc.: 64.06%] [G loss: 0.503149]\n",
      "epoch:14 step:13860 [D loss: 0.535756, acc.: 71.88%] [G loss: 0.551488]\n",
      "epoch:14 step:13861 [D loss: 0.455658, acc.: 81.25%] [G loss: 0.697608]\n",
      "epoch:14 step:13862 [D loss: 0.498962, acc.: 80.47%] [G loss: 0.901540]\n",
      "epoch:14 step:13863 [D loss: 0.620402, acc.: 64.84%] [G loss: 0.620188]\n",
      "epoch:14 step:13864 [D loss: 0.455096, acc.: 75.00%] [G loss: 0.666487]\n",
      "epoch:14 step:13865 [D loss: 0.460448, acc.: 75.00%] [G loss: 0.834472]\n",
      "epoch:14 step:13866 [D loss: 0.546412, acc.: 73.44%] [G loss: 0.717142]\n",
      "epoch:14 step:13867 [D loss: 0.512825, acc.: 71.88%] [G loss: 0.675761]\n",
      "epoch:14 step:13868 [D loss: 0.521057, acc.: 71.09%] [G loss: 0.639898]\n",
      "epoch:14 step:13869 [D loss: 0.486497, acc.: 73.44%] [G loss: 0.738851]\n",
      "epoch:14 step:13870 [D loss: 0.591227, acc.: 64.06%] [G loss: 0.747706]\n",
      "epoch:14 step:13871 [D loss: 0.499305, acc.: 76.56%] [G loss: 0.643151]\n",
      "epoch:14 step:13872 [D loss: 0.539831, acc.: 75.00%] [G loss: 0.637478]\n",
      "epoch:14 step:13873 [D loss: 0.545827, acc.: 66.41%] [G loss: 0.579047]\n",
      "epoch:14 step:13874 [D loss: 0.542839, acc.: 66.41%] [G loss: 0.597460]\n",
      "epoch:14 step:13875 [D loss: 0.563687, acc.: 67.19%] [G loss: 0.755233]\n",
      "epoch:14 step:13876 [D loss: 0.543911, acc.: 69.53%] [G loss: 0.620260]\n",
      "epoch:14 step:13877 [D loss: 0.513593, acc.: 75.78%] [G loss: 0.619190]\n",
      "epoch:14 step:13878 [D loss: 0.510130, acc.: 73.44%] [G loss: 0.680478]\n",
      "epoch:14 step:13879 [D loss: 0.549199, acc.: 69.53%] [G loss: 0.581169]\n",
      "epoch:14 step:13880 [D loss: 0.607203, acc.: 67.19%] [G loss: 0.451056]\n",
      "epoch:14 step:13881 [D loss: 0.562933, acc.: 70.31%] [G loss: 0.545170]\n",
      "epoch:14 step:13882 [D loss: 0.639273, acc.: 63.28%] [G loss: 0.667443]\n",
      "epoch:14 step:13883 [D loss: 0.629734, acc.: 65.62%] [G loss: 0.588167]\n",
      "epoch:14 step:13884 [D loss: 0.634043, acc.: 61.72%] [G loss: 0.490506]\n",
      "epoch:14 step:13885 [D loss: 0.540116, acc.: 71.09%] [G loss: 0.619312]\n",
      "epoch:14 step:13886 [D loss: 0.534046, acc.: 75.00%] [G loss: 0.695718]\n",
      "epoch:14 step:13887 [D loss: 0.528186, acc.: 73.44%] [G loss: 0.845900]\n",
      "epoch:14 step:13888 [D loss: 0.457591, acc.: 77.34%] [G loss: 0.799341]\n",
      "epoch:14 step:13889 [D loss: 0.548471, acc.: 71.09%] [G loss: 0.678627]\n",
      "epoch:14 step:13890 [D loss: 0.565691, acc.: 68.75%] [G loss: 0.759215]\n",
      "epoch:14 step:13891 [D loss: 0.560571, acc.: 69.53%] [G loss: 0.696568]\n",
      "epoch:14 step:13892 [D loss: 0.547944, acc.: 71.09%] [G loss: 0.683320]\n",
      "epoch:14 step:13893 [D loss: 0.526420, acc.: 74.22%] [G loss: 0.640184]\n",
      "epoch:14 step:13894 [D loss: 0.573445, acc.: 66.41%] [G loss: 0.672963]\n",
      "epoch:14 step:13895 [D loss: 0.517216, acc.: 73.44%] [G loss: 0.633736]\n",
      "epoch:14 step:13896 [D loss: 0.545478, acc.: 73.44%] [G loss: 0.735258]\n",
      "epoch:14 step:13897 [D loss: 0.537090, acc.: 73.44%] [G loss: 0.601851]\n",
      "epoch:14 step:13898 [D loss: 0.494025, acc.: 78.12%] [G loss: 0.715770]\n",
      "epoch:14 step:13899 [D loss: 0.517185, acc.: 71.88%] [G loss: 0.721303]\n",
      "epoch:14 step:13900 [D loss: 0.539450, acc.: 71.88%] [G loss: 0.790102]\n",
      "epoch:14 step:13901 [D loss: 0.564984, acc.: 68.75%] [G loss: 0.817172]\n",
      "epoch:14 step:13902 [D loss: 0.627884, acc.: 62.50%] [G loss: 0.644630]\n",
      "epoch:14 step:13903 [D loss: 0.560323, acc.: 67.97%] [G loss: 0.566013]\n",
      "epoch:14 step:13904 [D loss: 0.521590, acc.: 71.88%] [G loss: 0.649315]\n",
      "epoch:14 step:13905 [D loss: 0.565624, acc.: 67.97%] [G loss: 0.561921]\n",
      "epoch:14 step:13906 [D loss: 0.626751, acc.: 65.62%] [G loss: 0.481134]\n",
      "epoch:14 step:13907 [D loss: 0.547893, acc.: 71.88%] [G loss: 0.672331]\n",
      "epoch:14 step:13908 [D loss: 0.521292, acc.: 68.75%] [G loss: 0.649144]\n",
      "epoch:14 step:13909 [D loss: 0.525458, acc.: 75.78%] [G loss: 0.547970]\n",
      "epoch:14 step:13910 [D loss: 0.450058, acc.: 77.34%] [G loss: 0.732487]\n",
      "epoch:14 step:13911 [D loss: 0.615985, acc.: 64.06%] [G loss: 0.561343]\n",
      "epoch:14 step:13912 [D loss: 0.657694, acc.: 63.28%] [G loss: 0.690498]\n",
      "epoch:14 step:13913 [D loss: 0.539941, acc.: 75.78%] [G loss: 0.744330]\n",
      "epoch:14 step:13914 [D loss: 0.520329, acc.: 72.66%] [G loss: 0.883796]\n",
      "epoch:14 step:13915 [D loss: 0.541423, acc.: 71.09%] [G loss: 0.751669]\n",
      "epoch:14 step:13916 [D loss: 0.534907, acc.: 69.53%] [G loss: 0.684432]\n",
      "epoch:14 step:13917 [D loss: 0.537987, acc.: 70.31%] [G loss: 0.706997]\n",
      "epoch:14 step:13918 [D loss: 0.639745, acc.: 61.72%] [G loss: 0.528168]\n",
      "epoch:14 step:13919 [D loss: 0.491029, acc.: 73.44%] [G loss: 0.672343]\n",
      "epoch:14 step:13920 [D loss: 0.507269, acc.: 75.00%] [G loss: 0.765935]\n",
      "epoch:14 step:13921 [D loss: 0.488955, acc.: 78.12%] [G loss: 0.789255]\n",
      "epoch:14 step:13922 [D loss: 0.568714, acc.: 71.09%] [G loss: 0.728220]\n",
      "epoch:14 step:13923 [D loss: 0.567205, acc.: 68.75%] [G loss: 0.647069]\n",
      "epoch:14 step:13924 [D loss: 0.566178, acc.: 68.75%] [G loss: 0.448538]\n",
      "epoch:14 step:13925 [D loss: 0.552318, acc.: 68.75%] [G loss: 0.524941]\n",
      "epoch:14 step:13926 [D loss: 0.589974, acc.: 67.19%] [G loss: 0.571392]\n",
      "epoch:14 step:13927 [D loss: 0.550045, acc.: 73.44%] [G loss: 0.501230]\n",
      "epoch:14 step:13928 [D loss: 0.489995, acc.: 70.31%] [G loss: 0.589009]\n",
      "epoch:14 step:13929 [D loss: 0.568722, acc.: 66.41%] [G loss: 0.516842]\n",
      "epoch:14 step:13930 [D loss: 0.596485, acc.: 64.84%] [G loss: 0.412578]\n",
      "epoch:14 step:13931 [D loss: 0.520246, acc.: 76.56%] [G loss: 0.520258]\n",
      "epoch:14 step:13932 [D loss: 0.481572, acc.: 75.78%] [G loss: 0.639494]\n",
      "epoch:14 step:13933 [D loss: 0.478878, acc.: 75.78%] [G loss: 0.736067]\n",
      "epoch:14 step:13934 [D loss: 0.534124, acc.: 71.09%] [G loss: 0.905120]\n",
      "epoch:14 step:13935 [D loss: 0.601525, acc.: 67.97%] [G loss: 0.591409]\n",
      "epoch:14 step:13936 [D loss: 0.633282, acc.: 57.81%] [G loss: 0.639608]\n",
      "epoch:14 step:13937 [D loss: 0.484502, acc.: 79.69%] [G loss: 0.751096]\n",
      "epoch:14 step:13938 [D loss: 0.614117, acc.: 66.41%] [G loss: 0.632143]\n",
      "epoch:14 step:13939 [D loss: 0.518715, acc.: 75.00%] [G loss: 0.492497]\n",
      "epoch:14 step:13940 [D loss: 0.522405, acc.: 73.44%] [G loss: 0.566501]\n",
      "epoch:14 step:13941 [D loss: 0.437595, acc.: 79.69%] [G loss: 0.669444]\n",
      "epoch:14 step:13942 [D loss: 0.608762, acc.: 67.97%] [G loss: 0.692467]\n",
      "epoch:14 step:13943 [D loss: 0.527863, acc.: 75.00%] [G loss: 0.554419]\n",
      "epoch:14 step:13944 [D loss: 0.505669, acc.: 75.00%] [G loss: 0.689839]\n",
      "epoch:14 step:13945 [D loss: 0.574244, acc.: 65.62%] [G loss: 0.621406]\n",
      "epoch:14 step:13946 [D loss: 0.616130, acc.: 66.41%] [G loss: 0.629129]\n",
      "epoch:14 step:13947 [D loss: 0.513327, acc.: 71.09%] [G loss: 0.706223]\n",
      "epoch:14 step:13948 [D loss: 0.520479, acc.: 75.00%] [G loss: 0.726630]\n",
      "epoch:14 step:13949 [D loss: 0.558455, acc.: 71.09%] [G loss: 0.615991]\n",
      "epoch:14 step:13950 [D loss: 0.516399, acc.: 73.44%] [G loss: 0.601821]\n",
      "epoch:14 step:13951 [D loss: 0.512000, acc.: 75.00%] [G loss: 0.608966]\n",
      "epoch:14 step:13952 [D loss: 0.509031, acc.: 73.44%] [G loss: 0.607770]\n",
      "epoch:14 step:13953 [D loss: 0.550350, acc.: 67.97%] [G loss: 0.556015]\n",
      "epoch:14 step:13954 [D loss: 0.512355, acc.: 75.00%] [G loss: 0.468200]\n",
      "epoch:14 step:13955 [D loss: 0.497260, acc.: 72.66%] [G loss: 0.534258]\n",
      "epoch:14 step:13956 [D loss: 0.523962, acc.: 74.22%] [G loss: 0.420260]\n",
      "epoch:14 step:13957 [D loss: 0.545739, acc.: 68.75%] [G loss: 0.602082]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:14 step:13958 [D loss: 0.580382, acc.: 71.88%] [G loss: 0.575011]\n",
      "epoch:14 step:13959 [D loss: 0.533163, acc.: 71.09%] [G loss: 0.530515]\n",
      "epoch:14 step:13960 [D loss: 0.524680, acc.: 71.88%] [G loss: 0.572577]\n",
      "epoch:14 step:13961 [D loss: 0.501159, acc.: 77.34%] [G loss: 0.737568]\n",
      "epoch:14 step:13962 [D loss: 0.597768, acc.: 66.41%] [G loss: 0.643839]\n",
      "epoch:14 step:13963 [D loss: 0.598012, acc.: 66.41%] [G loss: 0.631014]\n",
      "epoch:14 step:13964 [D loss: 0.545849, acc.: 71.88%] [G loss: 0.531321]\n",
      "epoch:14 step:13965 [D loss: 0.601419, acc.: 65.62%] [G loss: 0.516651]\n",
      "epoch:14 step:13966 [D loss: 0.524002, acc.: 74.22%] [G loss: 0.518293]\n",
      "epoch:14 step:13967 [D loss: 0.567226, acc.: 68.75%] [G loss: 0.570542]\n",
      "epoch:14 step:13968 [D loss: 0.574857, acc.: 65.62%] [G loss: 0.552217]\n",
      "epoch:14 step:13969 [D loss: 0.554408, acc.: 67.19%] [G loss: 0.703324]\n",
      "epoch:14 step:13970 [D loss: 0.555549, acc.: 74.22%] [G loss: 0.605503]\n",
      "epoch:14 step:13971 [D loss: 0.554936, acc.: 67.97%] [G loss: 0.604458]\n",
      "epoch:14 step:13972 [D loss: 0.491396, acc.: 69.53%] [G loss: 0.598071]\n",
      "epoch:14 step:13973 [D loss: 0.504025, acc.: 74.22%] [G loss: 0.917945]\n",
      "epoch:14 step:13974 [D loss: 0.587274, acc.: 69.53%] [G loss: 0.696268]\n",
      "epoch:14 step:13975 [D loss: 0.493376, acc.: 75.00%] [G loss: 0.672887]\n",
      "epoch:14 step:13976 [D loss: 0.628154, acc.: 62.50%] [G loss: 0.474552]\n",
      "epoch:14 step:13977 [D loss: 0.565808, acc.: 72.66%] [G loss: 0.600689]\n",
      "epoch:14 step:13978 [D loss: 0.418161, acc.: 78.12%] [G loss: 0.602699]\n",
      "epoch:14 step:13979 [D loss: 0.683886, acc.: 57.81%] [G loss: 0.612136]\n",
      "epoch:14 step:13980 [D loss: 0.551175, acc.: 70.31%] [G loss: 0.553460]\n",
      "epoch:14 step:13981 [D loss: 0.563682, acc.: 67.19%] [G loss: 0.505696]\n",
      "epoch:14 step:13982 [D loss: 0.537726, acc.: 69.53%] [G loss: 0.697377]\n",
      "epoch:14 step:13983 [D loss: 0.566647, acc.: 63.28%] [G loss: 0.585340]\n",
      "epoch:14 step:13984 [D loss: 0.625299, acc.: 62.50%] [G loss: 0.631964]\n",
      "epoch:14 step:13985 [D loss: 0.696120, acc.: 57.03%] [G loss: 0.457396]\n",
      "epoch:14 step:13986 [D loss: 0.571201, acc.: 70.31%] [G loss: 0.430226]\n",
      "epoch:14 step:13987 [D loss: 0.582844, acc.: 65.62%] [G loss: 0.544779]\n",
      "epoch:14 step:13988 [D loss: 0.471922, acc.: 79.69%] [G loss: 0.657299]\n",
      "epoch:14 step:13989 [D loss: 0.448930, acc.: 81.25%] [G loss: 0.679505]\n",
      "epoch:14 step:13990 [D loss: 0.508955, acc.: 71.88%] [G loss: 0.610134]\n",
      "epoch:14 step:13991 [D loss: 0.585217, acc.: 64.84%] [G loss: 0.631203]\n",
      "epoch:14 step:13992 [D loss: 0.562696, acc.: 65.62%] [G loss: 0.566234]\n",
      "epoch:14 step:13993 [D loss: 0.491393, acc.: 75.78%] [G loss: 0.499397]\n",
      "epoch:14 step:13994 [D loss: 0.512765, acc.: 74.22%] [G loss: 0.440403]\n",
      "epoch:14 step:13995 [D loss: 0.552777, acc.: 67.19%] [G loss: 0.457747]\n",
      "epoch:14 step:13996 [D loss: 0.530262, acc.: 67.19%] [G loss: 0.582225]\n",
      "epoch:14 step:13997 [D loss: 0.550334, acc.: 71.09%] [G loss: 0.524239]\n",
      "epoch:14 step:13998 [D loss: 0.607420, acc.: 58.59%] [G loss: 0.530776]\n",
      "epoch:14 step:13999 [D loss: 0.536374, acc.: 71.88%] [G loss: 0.496855]\n",
      "epoch:14 step:14000 [D loss: 0.592438, acc.: 64.84%] [G loss: 0.457209]\n",
      "epoch:14 step:14001 [D loss: 0.605111, acc.: 61.72%] [G loss: 0.477905]\n",
      "epoch:14 step:14002 [D loss: 0.486355, acc.: 77.34%] [G loss: 0.621641]\n",
      "epoch:14 step:14003 [D loss: 0.529579, acc.: 69.53%] [G loss: 0.709190]\n",
      "epoch:14 step:14004 [D loss: 0.534498, acc.: 73.44%] [G loss: 0.724949]\n",
      "epoch:14 step:14005 [D loss: 0.571743, acc.: 66.41%] [G loss: 0.753433]\n",
      "epoch:14 step:14006 [D loss: 0.554626, acc.: 68.75%] [G loss: 0.740705]\n",
      "epoch:14 step:14007 [D loss: 0.537754, acc.: 69.53%] [G loss: 0.672506]\n",
      "epoch:14 step:14008 [D loss: 0.540307, acc.: 71.09%] [G loss: 0.600655]\n",
      "epoch:14 step:14009 [D loss: 0.610443, acc.: 64.06%] [G loss: 0.627037]\n",
      "epoch:14 step:14010 [D loss: 0.627674, acc.: 63.28%] [G loss: 0.454352]\n",
      "epoch:14 step:14011 [D loss: 0.571026, acc.: 67.19%] [G loss: 0.635515]\n",
      "epoch:14 step:14012 [D loss: 0.451285, acc.: 82.03%] [G loss: 0.613607]\n",
      "epoch:14 step:14013 [D loss: 0.546081, acc.: 70.31%] [G loss: 0.589482]\n",
      "epoch:14 step:14014 [D loss: 0.516306, acc.: 75.78%] [G loss: 0.719015]\n",
      "epoch:14 step:14015 [D loss: 0.462116, acc.: 75.78%] [G loss: 0.935679]\n",
      "epoch:14 step:14016 [D loss: 0.515610, acc.: 78.12%] [G loss: 0.638712]\n",
      "epoch:14 step:14017 [D loss: 0.534969, acc.: 73.44%] [G loss: 0.652768]\n",
      "epoch:14 step:14018 [D loss: 0.530259, acc.: 73.44%] [G loss: 0.739104]\n",
      "epoch:14 step:14019 [D loss: 0.497262, acc.: 75.78%] [G loss: 0.717513]\n",
      "epoch:14 step:14020 [D loss: 0.582907, acc.: 67.97%] [G loss: 0.450445]\n",
      "epoch:14 step:14021 [D loss: 0.499637, acc.: 76.56%] [G loss: 0.497560]\n",
      "epoch:14 step:14022 [D loss: 0.547666, acc.: 73.44%] [G loss: 0.606699]\n",
      "epoch:14 step:14023 [D loss: 0.544477, acc.: 71.88%] [G loss: 0.645268]\n",
      "epoch:14 step:14024 [D loss: 0.507494, acc.: 72.66%] [G loss: 0.641391]\n",
      "epoch:14 step:14025 [D loss: 0.555815, acc.: 73.44%] [G loss: 0.565092]\n",
      "epoch:14 step:14026 [D loss: 0.534211, acc.: 68.75%] [G loss: 0.622431]\n",
      "epoch:14 step:14027 [D loss: 0.507088, acc.: 77.34%] [G loss: 0.593383]\n",
      "epoch:14 step:14028 [D loss: 0.531130, acc.: 71.09%] [G loss: 0.637335]\n",
      "epoch:14 step:14029 [D loss: 0.477808, acc.: 77.34%] [G loss: 0.769521]\n",
      "epoch:14 step:14030 [D loss: 0.534333, acc.: 68.75%] [G loss: 0.669249]\n",
      "epoch:14 step:14031 [D loss: 0.568264, acc.: 67.97%] [G loss: 0.749240]\n",
      "epoch:14 step:14032 [D loss: 0.531018, acc.: 70.31%] [G loss: 0.656977]\n",
      "epoch:14 step:14033 [D loss: 0.618233, acc.: 64.84%] [G loss: 0.507057]\n",
      "epoch:14 step:14034 [D loss: 0.539165, acc.: 72.66%] [G loss: 0.715100]\n",
      "epoch:14 step:14035 [D loss: 0.574536, acc.: 66.41%] [G loss: 0.643233]\n",
      "epoch:14 step:14036 [D loss: 0.512853, acc.: 69.53%] [G loss: 0.780094]\n",
      "epoch:14 step:14037 [D loss: 0.442708, acc.: 82.03%] [G loss: 0.922678]\n",
      "epoch:14 step:14038 [D loss: 0.692638, acc.: 62.50%] [G loss: 0.732277]\n",
      "epoch:14 step:14039 [D loss: 0.515508, acc.: 71.88%] [G loss: 0.648169]\n",
      "epoch:14 step:14040 [D loss: 0.526565, acc.: 73.44%] [G loss: 0.693142]\n",
      "epoch:14 step:14041 [D loss: 0.504676, acc.: 71.88%] [G loss: 0.605813]\n",
      "epoch:14 step:14042 [D loss: 0.437433, acc.: 81.25%] [G loss: 0.810188]\n",
      "epoch:14 step:14043 [D loss: 0.411098, acc.: 77.34%] [G loss: 0.968561]\n",
      "epoch:14 step:14044 [D loss: 0.468569, acc.: 75.00%] [G loss: 1.024066]\n",
      "epoch:14 step:14045 [D loss: 0.477575, acc.: 78.91%] [G loss: 1.277192]\n",
      "epoch:14 step:14046 [D loss: 0.768200, acc.: 62.50%] [G loss: 1.345556]\n",
      "epoch:14 step:14047 [D loss: 0.509005, acc.: 72.66%] [G loss: 1.488703]\n",
      "epoch:14 step:14048 [D loss: 0.488515, acc.: 75.00%] [G loss: 0.781923]\n",
      "epoch:14 step:14049 [D loss: 0.533442, acc.: 67.19%] [G loss: 1.026554]\n",
      "epoch:14 step:14050 [D loss: 0.612190, acc.: 67.19%] [G loss: 0.836278]\n",
      "epoch:14 step:14051 [D loss: 0.514942, acc.: 75.00%] [G loss: 0.759298]\n",
      "epoch:14 step:14052 [D loss: 0.556745, acc.: 64.84%] [G loss: 0.844265]\n",
      "epoch:14 step:14053 [D loss: 0.453930, acc.: 78.12%] [G loss: 0.845364]\n",
      "epoch:14 step:14054 [D loss: 0.415474, acc.: 79.69%] [G loss: 0.903935]\n",
      "epoch:14 step:14055 [D loss: 0.443310, acc.: 81.25%] [G loss: 1.161347]\n",
      "epoch:15 step:14056 [D loss: 0.536135, acc.: 73.44%] [G loss: 1.038949]\n",
      "epoch:15 step:14057 [D loss: 0.474418, acc.: 73.44%] [G loss: 1.040676]\n",
      "epoch:15 step:14058 [D loss: 0.652312, acc.: 67.19%] [G loss: 0.872796]\n",
      "epoch:15 step:14059 [D loss: 0.498383, acc.: 77.34%] [G loss: 0.899777]\n",
      "epoch:15 step:14060 [D loss: 0.534737, acc.: 75.00%] [G loss: 0.832283]\n",
      "epoch:15 step:14061 [D loss: 0.562407, acc.: 68.75%] [G loss: 0.784471]\n",
      "epoch:15 step:14062 [D loss: 0.479485, acc.: 78.12%] [G loss: 0.761275]\n",
      "epoch:15 step:14063 [D loss: 0.489972, acc.: 76.56%] [G loss: 0.581471]\n",
      "epoch:15 step:14064 [D loss: 0.502508, acc.: 75.78%] [G loss: 0.608058]\n",
      "epoch:15 step:14065 [D loss: 0.516796, acc.: 75.78%] [G loss: 0.806501]\n",
      "epoch:15 step:14066 [D loss: 0.488851, acc.: 78.12%] [G loss: 1.025792]\n",
      "epoch:15 step:14067 [D loss: 0.593987, acc.: 68.75%] [G loss: 0.811995]\n",
      "epoch:15 step:14068 [D loss: 0.608624, acc.: 61.72%] [G loss: 0.673672]\n",
      "epoch:15 step:14069 [D loss: 0.577500, acc.: 70.31%] [G loss: 0.595719]\n",
      "epoch:15 step:14070 [D loss: 0.480038, acc.: 77.34%] [G loss: 0.735649]\n",
      "epoch:15 step:14071 [D loss: 0.497887, acc.: 75.78%] [G loss: 0.811006]\n",
      "epoch:15 step:14072 [D loss: 0.599980, acc.: 69.53%] [G loss: 0.615315]\n",
      "epoch:15 step:14073 [D loss: 0.549041, acc.: 71.88%] [G loss: 0.691469]\n",
      "epoch:15 step:14074 [D loss: 0.584297, acc.: 71.88%] [G loss: 0.585467]\n",
      "epoch:15 step:14075 [D loss: 0.616030, acc.: 64.84%] [G loss: 0.553634]\n",
      "epoch:15 step:14076 [D loss: 0.518357, acc.: 71.09%] [G loss: 0.643038]\n",
      "epoch:15 step:14077 [D loss: 0.447215, acc.: 78.91%] [G loss: 0.907690]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:15 step:14078 [D loss: 0.554701, acc.: 66.41%] [G loss: 0.724772]\n",
      "epoch:15 step:14079 [D loss: 0.501562, acc.: 75.78%] [G loss: 0.651579]\n",
      "epoch:15 step:14080 [D loss: 0.472756, acc.: 78.91%] [G loss: 0.663167]\n",
      "epoch:15 step:14081 [D loss: 0.558861, acc.: 69.53%] [G loss: 0.623061]\n",
      "epoch:15 step:14082 [D loss: 0.479404, acc.: 75.78%] [G loss: 0.536290]\n",
      "epoch:15 step:14083 [D loss: 0.582735, acc.: 62.50%] [G loss: 0.540839]\n",
      "epoch:15 step:14084 [D loss: 0.518204, acc.: 72.66%] [G loss: 0.658058]\n",
      "epoch:15 step:14085 [D loss: 0.553128, acc.: 71.09%] [G loss: 0.598536]\n",
      "epoch:15 step:14086 [D loss: 0.622657, acc.: 61.72%] [G loss: 0.546511]\n",
      "epoch:15 step:14087 [D loss: 0.572671, acc.: 66.41%] [G loss: 0.648880]\n",
      "epoch:15 step:14088 [D loss: 0.552871, acc.: 67.97%] [G loss: 0.655235]\n",
      "epoch:15 step:14089 [D loss: 0.542472, acc.: 69.53%] [G loss: 0.599706]\n",
      "epoch:15 step:14090 [D loss: 0.554612, acc.: 73.44%] [G loss: 0.596962]\n",
      "epoch:15 step:14091 [D loss: 0.547899, acc.: 66.41%] [G loss: 0.815796]\n",
      "epoch:15 step:14092 [D loss: 0.501633, acc.: 74.22%] [G loss: 0.557580]\n",
      "epoch:15 step:14093 [D loss: 0.585299, acc.: 67.19%] [G loss: 0.528946]\n",
      "epoch:15 step:14094 [D loss: 0.593616, acc.: 63.28%] [G loss: 0.655478]\n",
      "epoch:15 step:14095 [D loss: 0.479026, acc.: 73.44%] [G loss: 0.634285]\n",
      "epoch:15 step:14096 [D loss: 0.494882, acc.: 75.78%] [G loss: 0.747343]\n",
      "epoch:15 step:14097 [D loss: 0.530528, acc.: 73.44%] [G loss: 0.629981]\n",
      "epoch:15 step:14098 [D loss: 0.488065, acc.: 74.22%] [G loss: 0.593464]\n",
      "epoch:15 step:14099 [D loss: 0.534837, acc.: 67.97%] [G loss: 0.638128]\n",
      "epoch:15 step:14100 [D loss: 0.553202, acc.: 70.31%] [G loss: 0.608687]\n",
      "epoch:15 step:14101 [D loss: 0.479250, acc.: 76.56%] [G loss: 0.725817]\n",
      "epoch:15 step:14102 [D loss: 0.530310, acc.: 68.75%] [G loss: 0.796345]\n",
      "epoch:15 step:14103 [D loss: 0.490737, acc.: 77.34%] [G loss: 0.644566]\n",
      "epoch:15 step:14104 [D loss: 0.508879, acc.: 75.78%] [G loss: 0.648591]\n",
      "epoch:15 step:14105 [D loss: 0.526842, acc.: 72.66%] [G loss: 0.709436]\n",
      "epoch:15 step:14106 [D loss: 0.663217, acc.: 60.94%] [G loss: 0.494477]\n",
      "epoch:15 step:14107 [D loss: 0.594529, acc.: 64.84%] [G loss: 0.558539]\n",
      "epoch:15 step:14108 [D loss: 0.520381, acc.: 75.78%] [G loss: 0.560474]\n",
      "epoch:15 step:14109 [D loss: 0.508374, acc.: 75.78%] [G loss: 0.752671]\n",
      "epoch:15 step:14110 [D loss: 0.531491, acc.: 73.44%] [G loss: 0.876922]\n",
      "epoch:15 step:14111 [D loss: 0.547971, acc.: 73.44%] [G loss: 0.522631]\n",
      "epoch:15 step:14112 [D loss: 0.540698, acc.: 70.31%] [G loss: 0.602400]\n",
      "epoch:15 step:14113 [D loss: 0.522211, acc.: 78.12%] [G loss: 0.618055]\n",
      "epoch:15 step:14114 [D loss: 0.485909, acc.: 75.78%] [G loss: 0.713688]\n",
      "epoch:15 step:14115 [D loss: 0.565111, acc.: 69.53%] [G loss: 0.702713]\n",
      "epoch:15 step:14116 [D loss: 0.571777, acc.: 68.75%] [G loss: 0.627803]\n",
      "epoch:15 step:14117 [D loss: 0.578885, acc.: 71.09%] [G loss: 0.554686]\n",
      "epoch:15 step:14118 [D loss: 0.524678, acc.: 71.09%] [G loss: 0.633025]\n",
      "epoch:15 step:14119 [D loss: 0.522518, acc.: 73.44%] [G loss: 0.647822]\n",
      "epoch:15 step:14120 [D loss: 0.528021, acc.: 69.53%] [G loss: 0.526945]\n",
      "epoch:15 step:14121 [D loss: 0.601358, acc.: 71.09%] [G loss: 0.615711]\n",
      "epoch:15 step:14122 [D loss: 0.533793, acc.: 71.88%] [G loss: 0.530701]\n",
      "epoch:15 step:14123 [D loss: 0.590825, acc.: 64.84%] [G loss: 0.694115]\n",
      "epoch:15 step:14124 [D loss: 0.489022, acc.: 72.66%] [G loss: 0.776670]\n",
      "epoch:15 step:14125 [D loss: 0.502766, acc.: 75.78%] [G loss: 0.742443]\n",
      "epoch:15 step:14126 [D loss: 0.509643, acc.: 73.44%] [G loss: 0.710294]\n",
      "epoch:15 step:14127 [D loss: 0.523323, acc.: 73.44%] [G loss: 0.576141]\n",
      "epoch:15 step:14128 [D loss: 0.536254, acc.: 68.75%] [G loss: 0.540639]\n",
      "epoch:15 step:14129 [D loss: 0.452351, acc.: 77.34%] [G loss: 0.624190]\n",
      "epoch:15 step:14130 [D loss: 0.551574, acc.: 65.62%] [G loss: 0.734251]\n",
      "epoch:15 step:14131 [D loss: 0.482168, acc.: 78.91%] [G loss: 0.663195]\n",
      "epoch:15 step:14132 [D loss: 0.471287, acc.: 79.69%] [G loss: 0.925364]\n",
      "epoch:15 step:14133 [D loss: 0.545566, acc.: 73.44%] [G loss: 0.775631]\n",
      "epoch:15 step:14134 [D loss: 0.562109, acc.: 68.75%] [G loss: 0.513376]\n",
      "epoch:15 step:14135 [D loss: 0.525114, acc.: 71.09%] [G loss: 0.663688]\n",
      "epoch:15 step:14136 [D loss: 0.542621, acc.: 68.75%] [G loss: 0.560119]\n",
      "epoch:15 step:14137 [D loss: 0.554797, acc.: 70.31%] [G loss: 0.652224]\n",
      "epoch:15 step:14138 [D loss: 0.525937, acc.: 74.22%] [G loss: 0.673294]\n",
      "epoch:15 step:14139 [D loss: 0.553289, acc.: 69.53%] [G loss: 0.641474]\n",
      "epoch:15 step:14140 [D loss: 0.563116, acc.: 68.75%] [G loss: 0.476795]\n",
      "epoch:15 step:14141 [D loss: 0.543639, acc.: 75.00%] [G loss: 0.614270]\n",
      "epoch:15 step:14142 [D loss: 0.496018, acc.: 73.44%] [G loss: 0.640108]\n",
      "epoch:15 step:14143 [D loss: 0.483464, acc.: 75.78%] [G loss: 0.631803]\n",
      "epoch:15 step:14144 [D loss: 0.512178, acc.: 74.22%] [G loss: 0.573855]\n",
      "epoch:15 step:14145 [D loss: 0.522960, acc.: 71.88%] [G loss: 0.775887]\n",
      "epoch:15 step:14146 [D loss: 0.523756, acc.: 72.66%] [G loss: 0.718763]\n",
      "epoch:15 step:14147 [D loss: 0.500367, acc.: 74.22%] [G loss: 0.719299]\n",
      "epoch:15 step:14148 [D loss: 0.477071, acc.: 78.91%] [G loss: 0.845975]\n",
      "epoch:15 step:14149 [D loss: 0.501462, acc.: 73.44%] [G loss: 0.885315]\n",
      "epoch:15 step:14150 [D loss: 0.514609, acc.: 72.66%] [G loss: 0.644844]\n",
      "epoch:15 step:14151 [D loss: 0.537978, acc.: 68.75%] [G loss: 0.732273]\n",
      "epoch:15 step:14152 [D loss: 0.548113, acc.: 72.66%] [G loss: 0.660705]\n",
      "epoch:15 step:14153 [D loss: 0.554271, acc.: 66.41%] [G loss: 0.626438]\n",
      "epoch:15 step:14154 [D loss: 0.512266, acc.: 74.22%] [G loss: 0.687931]\n",
      "epoch:15 step:14155 [D loss: 0.457864, acc.: 77.34%] [G loss: 0.902847]\n",
      "epoch:15 step:14156 [D loss: 0.549129, acc.: 73.44%] [G loss: 0.707228]\n",
      "epoch:15 step:14157 [D loss: 0.635402, acc.: 60.16%] [G loss: 0.664695]\n",
      "epoch:15 step:14158 [D loss: 0.503172, acc.: 73.44%] [G loss: 0.644059]\n",
      "epoch:15 step:14159 [D loss: 0.519267, acc.: 71.88%] [G loss: 0.809384]\n",
      "epoch:15 step:14160 [D loss: 0.586915, acc.: 64.84%] [G loss: 0.702023]\n",
      "epoch:15 step:14161 [D loss: 0.562433, acc.: 71.88%] [G loss: 0.685143]\n",
      "epoch:15 step:14162 [D loss: 0.572484, acc.: 66.41%] [G loss: 0.512297]\n",
      "epoch:15 step:14163 [D loss: 0.668798, acc.: 65.62%] [G loss: 0.773155]\n",
      "epoch:15 step:14164 [D loss: 0.558510, acc.: 69.53%] [G loss: 0.592784]\n",
      "epoch:15 step:14165 [D loss: 0.541824, acc.: 72.66%] [G loss: 0.537475]\n",
      "epoch:15 step:14166 [D loss: 0.509768, acc.: 71.88%] [G loss: 0.528708]\n",
      "epoch:15 step:14167 [D loss: 0.565312, acc.: 72.66%] [G loss: 0.498723]\n",
      "epoch:15 step:14168 [D loss: 0.523051, acc.: 73.44%] [G loss: 0.627303]\n",
      "epoch:15 step:14169 [D loss: 0.581347, acc.: 67.97%] [G loss: 0.703250]\n",
      "epoch:15 step:14170 [D loss: 0.512727, acc.: 74.22%] [G loss: 0.676290]\n",
      "epoch:15 step:14171 [D loss: 0.477819, acc.: 78.91%] [G loss: 0.707788]\n",
      "epoch:15 step:14172 [D loss: 0.531636, acc.: 69.53%] [G loss: 0.751581]\n",
      "epoch:15 step:14173 [D loss: 0.558469, acc.: 67.19%] [G loss: 0.814746]\n",
      "epoch:15 step:14174 [D loss: 0.451913, acc.: 80.47%] [G loss: 0.755321]\n",
      "epoch:15 step:14175 [D loss: 0.571173, acc.: 71.88%] [G loss: 0.691772]\n",
      "epoch:15 step:14176 [D loss: 0.526327, acc.: 70.31%] [G loss: 0.639995]\n",
      "epoch:15 step:14177 [D loss: 0.493011, acc.: 77.34%] [G loss: 0.800392]\n",
      "epoch:15 step:14178 [D loss: 0.519487, acc.: 75.00%] [G loss: 0.902217]\n",
      "epoch:15 step:14179 [D loss: 0.591736, acc.: 68.75%] [G loss: 0.752436]\n",
      "epoch:15 step:14180 [D loss: 0.581744, acc.: 67.97%] [G loss: 0.664194]\n",
      "epoch:15 step:14181 [D loss: 0.539420, acc.: 67.19%] [G loss: 0.608690]\n",
      "epoch:15 step:14182 [D loss: 0.493239, acc.: 78.12%] [G loss: 0.551428]\n",
      "epoch:15 step:14183 [D loss: 0.507610, acc.: 69.53%] [G loss: 0.737550]\n",
      "epoch:15 step:14184 [D loss: 0.569824, acc.: 67.97%] [G loss: 0.607147]\n",
      "epoch:15 step:14185 [D loss: 0.486679, acc.: 77.34%] [G loss: 0.603542]\n",
      "epoch:15 step:14186 [D loss: 0.471788, acc.: 74.22%] [G loss: 0.693625]\n",
      "epoch:15 step:14187 [D loss: 0.536897, acc.: 71.09%] [G loss: 0.680137]\n",
      "epoch:15 step:14188 [D loss: 0.545519, acc.: 68.75%] [G loss: 0.610763]\n",
      "epoch:15 step:14189 [D loss: 0.594125, acc.: 63.28%] [G loss: 0.526867]\n",
      "epoch:15 step:14190 [D loss: 0.537651, acc.: 76.56%] [G loss: 0.618552]\n",
      "epoch:15 step:14191 [D loss: 0.482408, acc.: 75.78%] [G loss: 0.850652]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:15 step:14192 [D loss: 0.586835, acc.: 68.75%] [G loss: 0.712865]\n",
      "epoch:15 step:14193 [D loss: 0.588403, acc.: 68.75%] [G loss: 0.578788]\n",
      "epoch:15 step:14194 [D loss: 0.597537, acc.: 66.41%] [G loss: 0.535388]\n",
      "epoch:15 step:14195 [D loss: 0.564532, acc.: 72.66%] [G loss: 0.528793]\n",
      "epoch:15 step:14196 [D loss: 0.504838, acc.: 67.97%] [G loss: 0.607197]\n",
      "epoch:15 step:14197 [D loss: 0.528474, acc.: 67.97%] [G loss: 0.681967]\n",
      "epoch:15 step:14198 [D loss: 0.616999, acc.: 63.28%] [G loss: 0.481649]\n",
      "epoch:15 step:14199 [D loss: 0.514736, acc.: 74.22%] [G loss: 0.539497]\n",
      "epoch:15 step:14200 [D loss: 0.526357, acc.: 68.75%] [G loss: 0.783531]\n",
      "epoch:15 step:14201 [D loss: 0.472222, acc.: 78.91%] [G loss: 0.622638]\n",
      "epoch:15 step:14202 [D loss: 0.651810, acc.: 60.94%] [G loss: 0.539242]\n",
      "epoch:15 step:14203 [D loss: 0.530825, acc.: 69.53%] [G loss: 0.616428]\n",
      "epoch:15 step:14204 [D loss: 0.543490, acc.: 71.88%] [G loss: 0.590120]\n",
      "epoch:15 step:14205 [D loss: 0.605941, acc.: 64.84%] [G loss: 0.651854]\n",
      "epoch:15 step:14206 [D loss: 0.529871, acc.: 70.31%] [G loss: 0.559078]\n",
      "epoch:15 step:14207 [D loss: 0.466417, acc.: 73.44%] [G loss: 0.737190]\n",
      "epoch:15 step:14208 [D loss: 0.627553, acc.: 62.50%] [G loss: 0.536950]\n",
      "epoch:15 step:14209 [D loss: 0.544582, acc.: 70.31%] [G loss: 0.641720]\n",
      "epoch:15 step:14210 [D loss: 0.456592, acc.: 77.34%] [G loss: 0.757950]\n",
      "epoch:15 step:14211 [D loss: 0.512706, acc.: 71.88%] [G loss: 0.704582]\n",
      "epoch:15 step:14212 [D loss: 0.602907, acc.: 64.84%] [G loss: 0.622489]\n",
      "epoch:15 step:14213 [D loss: 0.568547, acc.: 71.88%] [G loss: 0.647882]\n",
      "epoch:15 step:14214 [D loss: 0.475731, acc.: 77.34%] [G loss: 0.822751]\n",
      "epoch:15 step:14215 [D loss: 0.624971, acc.: 63.28%] [G loss: 0.723883]\n",
      "epoch:15 step:14216 [D loss: 0.519556, acc.: 69.53%] [G loss: 0.907842]\n",
      "epoch:15 step:14217 [D loss: 0.497565, acc.: 79.69%] [G loss: 0.848272]\n",
      "epoch:15 step:14218 [D loss: 0.525581, acc.: 71.09%] [G loss: 0.712036]\n",
      "epoch:15 step:14219 [D loss: 0.489713, acc.: 75.00%] [G loss: 0.888297]\n",
      "epoch:15 step:14220 [D loss: 0.479476, acc.: 73.44%] [G loss: 0.774759]\n",
      "epoch:15 step:14221 [D loss: 0.551915, acc.: 68.75%] [G loss: 0.598626]\n",
      "epoch:15 step:14222 [D loss: 0.567855, acc.: 64.84%] [G loss: 0.707986]\n",
      "epoch:15 step:14223 [D loss: 0.581424, acc.: 68.75%] [G loss: 0.554095]\n",
      "epoch:15 step:14224 [D loss: 0.557043, acc.: 70.31%] [G loss: 0.499339]\n",
      "epoch:15 step:14225 [D loss: 0.563761, acc.: 64.06%] [G loss: 0.495251]\n",
      "epoch:15 step:14226 [D loss: 0.512603, acc.: 72.66%] [G loss: 0.555214]\n",
      "epoch:15 step:14227 [D loss: 0.525052, acc.: 70.31%] [G loss: 0.600430]\n",
      "epoch:15 step:14228 [D loss: 0.489030, acc.: 76.56%] [G loss: 0.728026]\n",
      "epoch:15 step:14229 [D loss: 0.588559, acc.: 63.28%] [G loss: 0.686783]\n",
      "epoch:15 step:14230 [D loss: 0.562648, acc.: 68.75%] [G loss: 0.672724]\n",
      "epoch:15 step:14231 [D loss: 0.537123, acc.: 68.75%] [G loss: 0.635944]\n",
      "epoch:15 step:14232 [D loss: 0.504121, acc.: 71.88%] [G loss: 0.676913]\n",
      "epoch:15 step:14233 [D loss: 0.614991, acc.: 64.84%] [G loss: 0.437815]\n",
      "epoch:15 step:14234 [D loss: 0.531905, acc.: 67.19%] [G loss: 0.517306]\n",
      "epoch:15 step:14235 [D loss: 0.620341, acc.: 61.72%] [G loss: 0.561649]\n",
      "epoch:15 step:14236 [D loss: 0.530317, acc.: 70.31%] [G loss: 0.651455]\n",
      "epoch:15 step:14237 [D loss: 0.509845, acc.: 74.22%] [G loss: 0.698079]\n",
      "epoch:15 step:14238 [D loss: 0.568408, acc.: 67.97%] [G loss: 0.602219]\n",
      "epoch:15 step:14239 [D loss: 0.508368, acc.: 75.00%] [G loss: 0.721980]\n",
      "epoch:15 step:14240 [D loss: 0.544227, acc.: 68.75%] [G loss: 0.596933]\n",
      "epoch:15 step:14241 [D loss: 0.583415, acc.: 62.50%] [G loss: 0.618749]\n",
      "epoch:15 step:14242 [D loss: 0.605209, acc.: 60.94%] [G loss: 0.620427]\n",
      "epoch:15 step:14243 [D loss: 0.547266, acc.: 66.41%] [G loss: 0.748553]\n",
      "epoch:15 step:14244 [D loss: 0.559848, acc.: 70.31%] [G loss: 0.494420]\n",
      "epoch:15 step:14245 [D loss: 0.534850, acc.: 71.88%] [G loss: 0.571323]\n",
      "epoch:15 step:14246 [D loss: 0.465183, acc.: 78.12%] [G loss: 0.737430]\n",
      "epoch:15 step:14247 [D loss: 0.529883, acc.: 75.00%] [G loss: 0.678394]\n",
      "epoch:15 step:14248 [D loss: 0.534957, acc.: 74.22%] [G loss: 0.650571]\n",
      "epoch:15 step:14249 [D loss: 0.473060, acc.: 75.78%] [G loss: 0.633236]\n",
      "epoch:15 step:14250 [D loss: 0.575892, acc.: 70.31%] [G loss: 0.559016]\n",
      "epoch:15 step:14251 [D loss: 0.597800, acc.: 66.41%] [G loss: 0.602896]\n",
      "epoch:15 step:14252 [D loss: 0.553760, acc.: 71.09%] [G loss: 0.707330]\n",
      "epoch:15 step:14253 [D loss: 0.476393, acc.: 75.78%] [G loss: 0.824723]\n",
      "epoch:15 step:14254 [D loss: 0.485542, acc.: 71.88%] [G loss: 0.880719]\n",
      "epoch:15 step:14255 [D loss: 0.629941, acc.: 63.28%] [G loss: 0.585725]\n",
      "epoch:15 step:14256 [D loss: 0.520148, acc.: 75.00%] [G loss: 0.574667]\n",
      "epoch:15 step:14257 [D loss: 0.589601, acc.: 67.97%] [G loss: 0.499167]\n",
      "epoch:15 step:14258 [D loss: 0.563361, acc.: 71.09%] [G loss: 0.435854]\n",
      "epoch:15 step:14259 [D loss: 0.549394, acc.: 67.97%] [G loss: 0.519747]\n",
      "epoch:15 step:14260 [D loss: 0.517918, acc.: 69.53%] [G loss: 0.580766]\n",
      "epoch:15 step:14261 [D loss: 0.502098, acc.: 75.78%] [G loss: 0.677457]\n",
      "epoch:15 step:14262 [D loss: 0.430685, acc.: 81.25%] [G loss: 0.809229]\n",
      "epoch:15 step:14263 [D loss: 0.475602, acc.: 76.56%] [G loss: 0.822199]\n",
      "epoch:15 step:14264 [D loss: 0.448394, acc.: 78.12%] [G loss: 1.020202]\n",
      "epoch:15 step:14265 [D loss: 0.632337, acc.: 65.62%] [G loss: 0.639849]\n",
      "epoch:15 step:14266 [D loss: 0.606282, acc.: 66.41%] [G loss: 0.660634]\n",
      "epoch:15 step:14267 [D loss: 0.481842, acc.: 78.91%] [G loss: 0.511980]\n",
      "epoch:15 step:14268 [D loss: 0.542692, acc.: 69.53%] [G loss: 0.778406]\n",
      "epoch:15 step:14269 [D loss: 0.669555, acc.: 59.38%] [G loss: 0.598624]\n",
      "epoch:15 step:14270 [D loss: 0.557020, acc.: 66.41%] [G loss: 0.688619]\n",
      "epoch:15 step:14271 [D loss: 0.535338, acc.: 70.31%] [G loss: 0.604631]\n",
      "epoch:15 step:14272 [D loss: 0.501256, acc.: 75.78%] [G loss: 0.562018]\n",
      "epoch:15 step:14273 [D loss: 0.517920, acc.: 72.66%] [G loss: 0.625794]\n",
      "epoch:15 step:14274 [D loss: 0.478513, acc.: 79.69%] [G loss: 0.592045]\n",
      "epoch:15 step:14275 [D loss: 0.660059, acc.: 57.81%] [G loss: 0.537469]\n",
      "epoch:15 step:14276 [D loss: 0.542486, acc.: 71.88%] [G loss: 0.630015]\n",
      "epoch:15 step:14277 [D loss: 0.510558, acc.: 73.44%] [G loss: 0.693151]\n",
      "epoch:15 step:14278 [D loss: 0.487810, acc.: 81.25%] [G loss: 0.648574]\n",
      "epoch:15 step:14279 [D loss: 0.575448, acc.: 70.31%] [G loss: 0.536764]\n",
      "epoch:15 step:14280 [D loss: 0.518386, acc.: 78.12%] [G loss: 0.594944]\n",
      "epoch:15 step:14281 [D loss: 0.572399, acc.: 66.41%] [G loss: 0.678730]\n",
      "epoch:15 step:14282 [D loss: 0.518903, acc.: 74.22%] [G loss: 0.626473]\n",
      "epoch:15 step:14283 [D loss: 0.597032, acc.: 64.06%] [G loss: 0.510937]\n",
      "epoch:15 step:14284 [D loss: 0.519626, acc.: 75.78%] [G loss: 0.534633]\n",
      "epoch:15 step:14285 [D loss: 0.463639, acc.: 76.56%] [G loss: 0.664771]\n",
      "epoch:15 step:14286 [D loss: 0.469734, acc.: 80.47%] [G loss: 0.696467]\n",
      "epoch:15 step:14287 [D loss: 0.440483, acc.: 86.72%] [G loss: 0.917329]\n",
      "epoch:15 step:14288 [D loss: 0.511034, acc.: 72.66%] [G loss: 0.918881]\n",
      "epoch:15 step:14289 [D loss: 0.591359, acc.: 67.97%] [G loss: 0.571154]\n",
      "epoch:15 step:14290 [D loss: 0.621581, acc.: 67.97%] [G loss: 0.462261]\n",
      "epoch:15 step:14291 [D loss: 0.527479, acc.: 71.09%] [G loss: 0.644794]\n",
      "epoch:15 step:14292 [D loss: 0.545286, acc.: 68.75%] [G loss: 0.565799]\n",
      "epoch:15 step:14293 [D loss: 0.579826, acc.: 67.97%] [G loss: 0.611359]\n",
      "epoch:15 step:14294 [D loss: 0.575724, acc.: 67.19%] [G loss: 0.603100]\n",
      "epoch:15 step:14295 [D loss: 0.499011, acc.: 78.12%] [G loss: 0.592250]\n",
      "epoch:15 step:14296 [D loss: 0.531176, acc.: 71.88%] [G loss: 0.497201]\n",
      "epoch:15 step:14297 [D loss: 0.476961, acc.: 76.56%] [G loss: 0.635904]\n",
      "epoch:15 step:14298 [D loss: 0.534015, acc.: 71.88%] [G loss: 0.689355]\n",
      "epoch:15 step:14299 [D loss: 0.449512, acc.: 81.25%] [G loss: 0.682155]\n",
      "epoch:15 step:14300 [D loss: 0.534691, acc.: 73.44%] [G loss: 0.759679]\n",
      "epoch:15 step:14301 [D loss: 0.486557, acc.: 75.00%] [G loss: 0.810118]\n",
      "epoch:15 step:14302 [D loss: 0.467185, acc.: 80.47%] [G loss: 0.707106]\n",
      "epoch:15 step:14303 [D loss: 0.497771, acc.: 71.88%] [G loss: 0.717505]\n",
      "epoch:15 step:14304 [D loss: 0.562085, acc.: 71.09%] [G loss: 0.657042]\n",
      "epoch:15 step:14305 [D loss: 0.632995, acc.: 61.72%] [G loss: 0.581671]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:15 step:14306 [D loss: 0.568186, acc.: 70.31%] [G loss: 0.641155]\n",
      "epoch:15 step:14307 [D loss: 0.557756, acc.: 69.53%] [G loss: 0.688274]\n",
      "epoch:15 step:14308 [D loss: 0.556013, acc.: 78.12%] [G loss: 0.673239]\n",
      "epoch:15 step:14309 [D loss: 0.499287, acc.: 70.31%] [G loss: 0.677798]\n",
      "epoch:15 step:14310 [D loss: 0.535507, acc.: 67.97%] [G loss: 0.512495]\n",
      "epoch:15 step:14311 [D loss: 0.547765, acc.: 73.44%] [G loss: 0.464713]\n",
      "epoch:15 step:14312 [D loss: 0.536245, acc.: 67.97%] [G loss: 0.580362]\n",
      "epoch:15 step:14313 [D loss: 0.536950, acc.: 71.09%] [G loss: 0.588137]\n",
      "epoch:15 step:14314 [D loss: 0.477638, acc.: 74.22%] [G loss: 0.680380]\n",
      "epoch:15 step:14315 [D loss: 0.571201, acc.: 67.97%] [G loss: 0.622738]\n",
      "epoch:15 step:14316 [D loss: 0.508780, acc.: 75.00%] [G loss: 0.698403]\n",
      "epoch:15 step:14317 [D loss: 0.525802, acc.: 72.66%] [G loss: 0.614714]\n",
      "epoch:15 step:14318 [D loss: 0.604030, acc.: 65.62%] [G loss: 0.449458]\n",
      "epoch:15 step:14319 [D loss: 0.514675, acc.: 71.88%] [G loss: 0.760449]\n",
      "epoch:15 step:14320 [D loss: 0.512935, acc.: 70.31%] [G loss: 0.536692]\n",
      "epoch:15 step:14321 [D loss: 0.523886, acc.: 72.66%] [G loss: 0.573892]\n",
      "epoch:15 step:14322 [D loss: 0.554590, acc.: 71.88%] [G loss: 0.531819]\n",
      "epoch:15 step:14323 [D loss: 0.542021, acc.: 73.44%] [G loss: 0.663974]\n",
      "epoch:15 step:14324 [D loss: 0.553490, acc.: 71.09%] [G loss: 0.662588]\n",
      "epoch:15 step:14325 [D loss: 0.490759, acc.: 76.56%] [G loss: 0.645688]\n",
      "epoch:15 step:14326 [D loss: 0.491085, acc.: 75.78%] [G loss: 0.668863]\n",
      "epoch:15 step:14327 [D loss: 0.574727, acc.: 71.09%] [G loss: 0.695527]\n",
      "epoch:15 step:14328 [D loss: 0.498786, acc.: 74.22%] [G loss: 0.738212]\n",
      "epoch:15 step:14329 [D loss: 0.550622, acc.: 73.44%] [G loss: 0.524978]\n",
      "epoch:15 step:14330 [D loss: 0.546657, acc.: 71.88%] [G loss: 0.691701]\n",
      "epoch:15 step:14331 [D loss: 0.424466, acc.: 83.59%] [G loss: 0.829375]\n",
      "epoch:15 step:14332 [D loss: 0.668368, acc.: 63.28%] [G loss: 0.511364]\n",
      "epoch:15 step:14333 [D loss: 0.590389, acc.: 67.19%] [G loss: 0.364689]\n",
      "epoch:15 step:14334 [D loss: 0.513514, acc.: 68.75%] [G loss: 0.537176]\n",
      "epoch:15 step:14335 [D loss: 0.551826, acc.: 67.97%] [G loss: 0.553393]\n",
      "epoch:15 step:14336 [D loss: 0.595277, acc.: 63.28%] [G loss: 0.569060]\n",
      "epoch:15 step:14337 [D loss: 0.575376, acc.: 64.06%] [G loss: 0.508423]\n",
      "epoch:15 step:14338 [D loss: 0.491790, acc.: 76.56%] [G loss: 0.624791]\n",
      "epoch:15 step:14339 [D loss: 0.571460, acc.: 67.19%] [G loss: 0.747350]\n",
      "epoch:15 step:14340 [D loss: 0.523995, acc.: 71.09%] [G loss: 0.719186]\n",
      "epoch:15 step:14341 [D loss: 0.516258, acc.: 76.56%] [G loss: 0.677067]\n",
      "epoch:15 step:14342 [D loss: 0.559044, acc.: 71.09%] [G loss: 0.714291]\n",
      "epoch:15 step:14343 [D loss: 0.535959, acc.: 70.31%] [G loss: 0.599980]\n",
      "epoch:15 step:14344 [D loss: 0.517938, acc.: 69.53%] [G loss: 0.676881]\n",
      "epoch:15 step:14345 [D loss: 0.540333, acc.: 71.09%] [G loss: 0.618460]\n",
      "epoch:15 step:14346 [D loss: 0.528842, acc.: 71.88%] [G loss: 0.734734]\n",
      "epoch:15 step:14347 [D loss: 0.508653, acc.: 77.34%] [G loss: 0.572155]\n",
      "epoch:15 step:14348 [D loss: 0.588210, acc.: 62.50%] [G loss: 0.523017]\n",
      "epoch:15 step:14349 [D loss: 0.587772, acc.: 67.97%] [G loss: 0.500042]\n",
      "epoch:15 step:14350 [D loss: 0.544159, acc.: 67.19%] [G loss: 0.488864]\n",
      "epoch:15 step:14351 [D loss: 0.451285, acc.: 80.47%] [G loss: 0.680574]\n",
      "epoch:15 step:14352 [D loss: 0.528623, acc.: 70.31%] [G loss: 0.576474]\n",
      "epoch:15 step:14353 [D loss: 0.492916, acc.: 78.12%] [G loss: 0.667106]\n",
      "epoch:15 step:14354 [D loss: 0.515680, acc.: 70.31%] [G loss: 0.860286]\n",
      "epoch:15 step:14355 [D loss: 0.485958, acc.: 75.78%] [G loss: 0.746706]\n",
      "epoch:15 step:14356 [D loss: 0.561906, acc.: 70.31%] [G loss: 0.681063]\n",
      "epoch:15 step:14357 [D loss: 0.516589, acc.: 69.53%] [G loss: 0.564754]\n",
      "epoch:15 step:14358 [D loss: 0.566248, acc.: 67.19%] [G loss: 0.648699]\n",
      "epoch:15 step:14359 [D loss: 0.518917, acc.: 74.22%] [G loss: 0.738690]\n",
      "epoch:15 step:14360 [D loss: 0.589801, acc.: 64.06%] [G loss: 0.625610]\n",
      "epoch:15 step:14361 [D loss: 0.555668, acc.: 66.41%] [G loss: 0.808738]\n",
      "epoch:15 step:14362 [D loss: 0.486468, acc.: 76.56%] [G loss: 0.703101]\n",
      "epoch:15 step:14363 [D loss: 0.540453, acc.: 73.44%] [G loss: 0.726821]\n",
      "epoch:15 step:14364 [D loss: 0.458139, acc.: 77.34%] [G loss: 0.838963]\n",
      "epoch:15 step:14365 [D loss: 0.517738, acc.: 71.09%] [G loss: 0.792735]\n",
      "epoch:15 step:14366 [D loss: 0.478065, acc.: 79.69%] [G loss: 0.645770]\n",
      "epoch:15 step:14367 [D loss: 0.422785, acc.: 80.47%] [G loss: 0.841745]\n",
      "epoch:15 step:14368 [D loss: 0.515675, acc.: 75.00%] [G loss: 0.980512]\n",
      "epoch:15 step:14369 [D loss: 0.419768, acc.: 82.03%] [G loss: 1.056302]\n",
      "epoch:15 step:14370 [D loss: 0.473324, acc.: 78.12%] [G loss: 0.950024]\n",
      "epoch:15 step:14371 [D loss: 0.674787, acc.: 62.50%] [G loss: 0.599695]\n",
      "epoch:15 step:14372 [D loss: 0.601235, acc.: 68.75%] [G loss: 0.535381]\n",
      "epoch:15 step:14373 [D loss: 0.558312, acc.: 67.97%] [G loss: 0.484988]\n",
      "epoch:15 step:14374 [D loss: 0.556319, acc.: 68.75%] [G loss: 0.516877]\n",
      "epoch:15 step:14375 [D loss: 0.517951, acc.: 73.44%] [G loss: 0.666352]\n",
      "epoch:15 step:14376 [D loss: 0.488234, acc.: 75.00%] [G loss: 0.749193]\n",
      "epoch:15 step:14377 [D loss: 0.610537, acc.: 67.97%] [G loss: 0.717718]\n",
      "epoch:15 step:14378 [D loss: 0.621973, acc.: 67.97%] [G loss: 0.569486]\n",
      "epoch:15 step:14379 [D loss: 0.533917, acc.: 75.78%] [G loss: 0.439901]\n",
      "epoch:15 step:14380 [D loss: 0.502896, acc.: 71.09%] [G loss: 0.588318]\n",
      "epoch:15 step:14381 [D loss: 0.543630, acc.: 68.75%] [G loss: 0.578763]\n",
      "epoch:15 step:14382 [D loss: 0.498559, acc.: 76.56%] [G loss: 0.694457]\n",
      "epoch:15 step:14383 [D loss: 0.511101, acc.: 73.44%] [G loss: 0.748463]\n",
      "epoch:15 step:14384 [D loss: 0.471904, acc.: 76.56%] [G loss: 0.649569]\n",
      "epoch:15 step:14385 [D loss: 0.536620, acc.: 67.97%] [G loss: 0.606368]\n",
      "epoch:15 step:14386 [D loss: 0.540187, acc.: 74.22%] [G loss: 0.619052]\n",
      "epoch:15 step:14387 [D loss: 0.457708, acc.: 76.56%] [G loss: 0.646961]\n",
      "epoch:15 step:14388 [D loss: 0.443129, acc.: 78.91%] [G loss: 0.735208]\n",
      "epoch:15 step:14389 [D loss: 0.532300, acc.: 75.00%] [G loss: 0.603615]\n",
      "epoch:15 step:14390 [D loss: 0.467188, acc.: 76.56%] [G loss: 0.721191]\n",
      "epoch:15 step:14391 [D loss: 0.527703, acc.: 73.44%] [G loss: 0.815388]\n",
      "epoch:15 step:14392 [D loss: 0.473363, acc.: 75.00%] [G loss: 0.703117]\n",
      "epoch:15 step:14393 [D loss: 0.539936, acc.: 68.75%] [G loss: 0.733321]\n",
      "epoch:15 step:14394 [D loss: 0.539085, acc.: 75.78%] [G loss: 0.570128]\n",
      "epoch:15 step:14395 [D loss: 0.448226, acc.: 76.56%] [G loss: 0.755466]\n",
      "epoch:15 step:14396 [D loss: 0.580102, acc.: 69.53%] [G loss: 0.745723]\n",
      "epoch:15 step:14397 [D loss: 0.652026, acc.: 62.50%] [G loss: 0.699119]\n",
      "epoch:15 step:14398 [D loss: 0.533914, acc.: 66.41%] [G loss: 0.672089]\n",
      "epoch:15 step:14399 [D loss: 0.525938, acc.: 74.22%] [G loss: 0.668690]\n",
      "epoch:15 step:14400 [D loss: 0.567162, acc.: 67.97%] [G loss: 0.635369]\n",
      "epoch:15 step:14401 [D loss: 0.555760, acc.: 67.19%] [G loss: 0.634535]\n",
      "epoch:15 step:14402 [D loss: 0.443253, acc.: 82.03%] [G loss: 0.805896]\n",
      "epoch:15 step:14403 [D loss: 0.618935, acc.: 65.62%] [G loss: 0.631432]\n",
      "epoch:15 step:14404 [D loss: 0.661588, acc.: 61.72%] [G loss: 0.551228]\n",
      "epoch:15 step:14405 [D loss: 0.507703, acc.: 71.88%] [G loss: 0.487987]\n",
      "epoch:15 step:14406 [D loss: 0.539283, acc.: 73.44%] [G loss: 0.733935]\n",
      "epoch:15 step:14407 [D loss: 0.536505, acc.: 71.09%] [G loss: 0.632335]\n",
      "epoch:15 step:14408 [D loss: 0.544506, acc.: 69.53%] [G loss: 0.629000]\n",
      "epoch:15 step:14409 [D loss: 0.409364, acc.: 78.91%] [G loss: 0.795409]\n",
      "epoch:15 step:14410 [D loss: 0.511886, acc.: 74.22%] [G loss: 0.758587]\n",
      "epoch:15 step:14411 [D loss: 0.611253, acc.: 67.97%] [G loss: 0.635297]\n",
      "epoch:15 step:14412 [D loss: 0.441282, acc.: 81.25%] [G loss: 0.677709]\n",
      "epoch:15 step:14413 [D loss: 0.469894, acc.: 80.47%] [G loss: 0.898291]\n",
      "epoch:15 step:14414 [D loss: 0.487106, acc.: 71.88%] [G loss: 0.799527]\n",
      "epoch:15 step:14415 [D loss: 0.499928, acc.: 71.88%] [G loss: 0.898030]\n",
      "epoch:15 step:14416 [D loss: 0.462406, acc.: 80.47%] [G loss: 0.793274]\n",
      "epoch:15 step:14417 [D loss: 0.569863, acc.: 67.19%] [G loss: 0.689867]\n",
      "epoch:15 step:14418 [D loss: 0.533875, acc.: 71.88%] [G loss: 0.603512]\n",
      "epoch:15 step:14419 [D loss: 0.503089, acc.: 74.22%] [G loss: 0.665544]\n",
      "epoch:15 step:14420 [D loss: 0.566251, acc.: 66.41%] [G loss: 0.572027]\n",
      "epoch:15 step:14421 [D loss: 0.477418, acc.: 75.78%] [G loss: 0.682721]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:15 step:14422 [D loss: 0.603022, acc.: 68.75%] [G loss: 0.688140]\n",
      "epoch:15 step:14423 [D loss: 0.514753, acc.: 73.44%] [G loss: 0.738594]\n",
      "epoch:15 step:14424 [D loss: 0.491616, acc.: 74.22%] [G loss: 0.656453]\n",
      "epoch:15 step:14425 [D loss: 0.549847, acc.: 72.66%] [G loss: 0.653803]\n",
      "epoch:15 step:14426 [D loss: 0.473700, acc.: 76.56%] [G loss: 0.853625]\n",
      "epoch:15 step:14427 [D loss: 0.539852, acc.: 71.09%] [G loss: 0.823143]\n",
      "epoch:15 step:14428 [D loss: 0.541275, acc.: 74.22%] [G loss: 0.682188]\n",
      "epoch:15 step:14429 [D loss: 0.410084, acc.: 80.47%] [G loss: 0.800471]\n",
      "epoch:15 step:14430 [D loss: 0.526950, acc.: 69.53%] [G loss: 0.776036]\n",
      "epoch:15 step:14431 [D loss: 0.726692, acc.: 63.28%] [G loss: 0.669659]\n",
      "epoch:15 step:14432 [D loss: 0.600347, acc.: 65.62%] [G loss: 0.617370]\n",
      "epoch:15 step:14433 [D loss: 0.521657, acc.: 75.00%] [G loss: 0.652211]\n",
      "epoch:15 step:14434 [D loss: 0.609073, acc.: 68.75%] [G loss: 0.615022]\n",
      "epoch:15 step:14435 [D loss: 0.599374, acc.: 67.97%] [G loss: 0.599297]\n",
      "epoch:15 step:14436 [D loss: 0.457747, acc.: 78.12%] [G loss: 0.651547]\n",
      "epoch:15 step:14437 [D loss: 0.513049, acc.: 76.56%] [G loss: 0.617821]\n",
      "epoch:15 step:14438 [D loss: 0.553586, acc.: 69.53%] [G loss: 0.733284]\n",
      "epoch:15 step:14439 [D loss: 0.540021, acc.: 72.66%] [G loss: 0.580246]\n",
      "epoch:15 step:14440 [D loss: 0.490688, acc.: 72.66%] [G loss: 0.810187]\n",
      "epoch:15 step:14441 [D loss: 0.588778, acc.: 69.53%] [G loss: 0.550002]\n",
      "epoch:15 step:14442 [D loss: 0.528641, acc.: 72.66%] [G loss: 0.759066]\n",
      "epoch:15 step:14443 [D loss: 0.532174, acc.: 73.44%] [G loss: 0.525609]\n",
      "epoch:15 step:14444 [D loss: 0.521844, acc.: 69.53%] [G loss: 0.746550]\n",
      "epoch:15 step:14445 [D loss: 0.558914, acc.: 69.53%] [G loss: 0.665353]\n",
      "epoch:15 step:14446 [D loss: 0.507305, acc.: 74.22%] [G loss: 0.596494]\n",
      "epoch:15 step:14447 [D loss: 0.471867, acc.: 74.22%] [G loss: 0.588638]\n",
      "epoch:15 step:14448 [D loss: 0.604327, acc.: 65.62%] [G loss: 0.672563]\n",
      "epoch:15 step:14449 [D loss: 0.525528, acc.: 73.44%] [G loss: 0.648157]\n",
      "epoch:15 step:14450 [D loss: 0.500279, acc.: 75.78%] [G loss: 0.728703]\n",
      "epoch:15 step:14451 [D loss: 0.603792, acc.: 61.72%] [G loss: 0.547824]\n",
      "epoch:15 step:14452 [D loss: 0.576963, acc.: 64.84%] [G loss: 0.647867]\n",
      "epoch:15 step:14453 [D loss: 0.437767, acc.: 81.25%] [G loss: 0.755249]\n",
      "epoch:15 step:14454 [D loss: 0.487668, acc.: 75.00%] [G loss: 0.704652]\n",
      "epoch:15 step:14455 [D loss: 0.649468, acc.: 60.94%] [G loss: 0.657251]\n",
      "epoch:15 step:14456 [D loss: 0.650667, acc.: 59.38%] [G loss: 0.397807]\n",
      "epoch:15 step:14457 [D loss: 0.466015, acc.: 76.56%] [G loss: 0.494547]\n",
      "epoch:15 step:14458 [D loss: 0.496566, acc.: 74.22%] [G loss: 0.620551]\n",
      "epoch:15 step:14459 [D loss: 0.587194, acc.: 62.50%] [G loss: 0.689070]\n",
      "epoch:15 step:14460 [D loss: 0.531225, acc.: 71.88%] [G loss: 0.800868]\n",
      "epoch:15 step:14461 [D loss: 0.507687, acc.: 71.88%] [G loss: 0.688938]\n",
      "epoch:15 step:14462 [D loss: 0.569312, acc.: 72.66%] [G loss: 0.780630]\n",
      "epoch:15 step:14463 [D loss: 0.621070, acc.: 64.84%] [G loss: 0.602813]\n",
      "epoch:15 step:14464 [D loss: 0.548181, acc.: 68.75%] [G loss: 0.608577]\n",
      "epoch:15 step:14465 [D loss: 0.571472, acc.: 67.97%] [G loss: 0.536805]\n",
      "epoch:15 step:14466 [D loss: 0.591002, acc.: 67.19%] [G loss: 0.511503]\n",
      "epoch:15 step:14467 [D loss: 0.585724, acc.: 67.97%] [G loss: 0.531705]\n",
      "epoch:15 step:14468 [D loss: 0.545920, acc.: 70.31%] [G loss: 0.549759]\n",
      "epoch:15 step:14469 [D loss: 0.522177, acc.: 71.09%] [G loss: 0.597481]\n",
      "epoch:15 step:14470 [D loss: 0.545091, acc.: 69.53%] [G loss: 0.606609]\n",
      "epoch:15 step:14471 [D loss: 0.457334, acc.: 75.00%] [G loss: 0.726328]\n",
      "epoch:15 step:14472 [D loss: 0.541713, acc.: 70.31%] [G loss: 0.667055]\n",
      "epoch:15 step:14473 [D loss: 0.599418, acc.: 62.50%] [G loss: 0.585110]\n",
      "epoch:15 step:14474 [D loss: 0.554537, acc.: 64.84%] [G loss: 0.644020]\n",
      "epoch:15 step:14475 [D loss: 0.586128, acc.: 64.06%] [G loss: 0.643547]\n",
      "epoch:15 step:14476 [D loss: 0.562854, acc.: 73.44%] [G loss: 0.629513]\n",
      "epoch:15 step:14477 [D loss: 0.578156, acc.: 67.19%] [G loss: 0.618889]\n",
      "epoch:15 step:14478 [D loss: 0.564043, acc.: 67.97%] [G loss: 0.519985]\n",
      "epoch:15 step:14479 [D loss: 0.543526, acc.: 71.09%] [G loss: 0.587152]\n",
      "epoch:15 step:14480 [D loss: 0.514348, acc.: 71.88%] [G loss: 0.695699]\n",
      "epoch:15 step:14481 [D loss: 0.480660, acc.: 74.22%] [G loss: 0.692949]\n",
      "epoch:15 step:14482 [D loss: 0.469849, acc.: 78.12%] [G loss: 0.707587]\n",
      "epoch:15 step:14483 [D loss: 0.502204, acc.: 70.31%] [G loss: 0.668406]\n",
      "epoch:15 step:14484 [D loss: 0.479242, acc.: 77.34%] [G loss: 0.802467]\n",
      "epoch:15 step:14485 [D loss: 0.507744, acc.: 76.56%] [G loss: 0.663097]\n",
      "epoch:15 step:14486 [D loss: 0.502781, acc.: 71.09%] [G loss: 0.680787]\n",
      "epoch:15 step:14487 [D loss: 0.569435, acc.: 67.19%] [G loss: 0.699740]\n",
      "epoch:15 step:14488 [D loss: 0.545509, acc.: 72.66%] [G loss: 0.636399]\n",
      "epoch:15 step:14489 [D loss: 0.503200, acc.: 73.44%] [G loss: 0.646353]\n",
      "epoch:15 step:14490 [D loss: 0.517774, acc.: 72.66%] [G loss: 0.697625]\n",
      "epoch:15 step:14491 [D loss: 0.494776, acc.: 75.78%] [G loss: 0.810038]\n",
      "epoch:15 step:14492 [D loss: 0.713662, acc.: 59.38%] [G loss: 0.499878]\n",
      "epoch:15 step:14493 [D loss: 0.546056, acc.: 69.53%] [G loss: 0.646013]\n",
      "epoch:15 step:14494 [D loss: 0.524798, acc.: 71.09%] [G loss: 0.639033]\n",
      "epoch:15 step:14495 [D loss: 0.492252, acc.: 69.53%] [G loss: 0.811525]\n",
      "epoch:15 step:14496 [D loss: 0.532539, acc.: 69.53%] [G loss: 0.585275]\n",
      "epoch:15 step:14497 [D loss: 0.513638, acc.: 71.09%] [G loss: 0.712185]\n",
      "epoch:15 step:14498 [D loss: 0.517562, acc.: 74.22%] [G loss: 0.541887]\n",
      "epoch:15 step:14499 [D loss: 0.518412, acc.: 74.22%] [G loss: 0.730119]\n",
      "epoch:15 step:14500 [D loss: 0.533810, acc.: 69.53%] [G loss: 0.747188]\n",
      "epoch:15 step:14501 [D loss: 0.486974, acc.: 74.22%] [G loss: 0.746950]\n",
      "epoch:15 step:14502 [D loss: 0.483546, acc.: 75.78%] [G loss: 0.766648]\n",
      "epoch:15 step:14503 [D loss: 0.586443, acc.: 65.62%] [G loss: 0.495576]\n",
      "epoch:15 step:14504 [D loss: 0.484920, acc.: 75.00%] [G loss: 0.735262]\n",
      "epoch:15 step:14505 [D loss: 0.497368, acc.: 78.12%] [G loss: 0.757605]\n",
      "epoch:15 step:14506 [D loss: 0.428853, acc.: 78.91%] [G loss: 0.746256]\n",
      "epoch:15 step:14507 [D loss: 0.507074, acc.: 72.66%] [G loss: 0.762168]\n",
      "epoch:15 step:14508 [D loss: 0.512867, acc.: 78.91%] [G loss: 0.844469]\n",
      "epoch:15 step:14509 [D loss: 0.587678, acc.: 68.75%] [G loss: 0.590313]\n",
      "epoch:15 step:14510 [D loss: 0.545998, acc.: 70.31%] [G loss: 0.553205]\n",
      "epoch:15 step:14511 [D loss: 0.558407, acc.: 70.31%] [G loss: 0.670418]\n",
      "epoch:15 step:14512 [D loss: 0.486824, acc.: 75.00%] [G loss: 0.744996]\n",
      "epoch:15 step:14513 [D loss: 0.601709, acc.: 64.84%] [G loss: 0.608884]\n",
      "epoch:15 step:14514 [D loss: 0.542166, acc.: 72.66%] [G loss: 0.530542]\n",
      "epoch:15 step:14515 [D loss: 0.528386, acc.: 72.66%] [G loss: 0.653766]\n",
      "epoch:15 step:14516 [D loss: 0.474912, acc.: 74.22%] [G loss: 0.783542]\n",
      "epoch:15 step:14517 [D loss: 0.588413, acc.: 64.84%] [G loss: 0.626689]\n",
      "epoch:15 step:14518 [D loss: 0.562173, acc.: 66.41%] [G loss: 0.448350]\n",
      "epoch:15 step:14519 [D loss: 0.501640, acc.: 73.44%] [G loss: 0.619619]\n",
      "epoch:15 step:14520 [D loss: 0.624907, acc.: 60.94%] [G loss: 0.559740]\n",
      "epoch:15 step:14521 [D loss: 0.518505, acc.: 68.75%] [G loss: 0.565554]\n",
      "epoch:15 step:14522 [D loss: 0.499520, acc.: 73.44%] [G loss: 0.637185]\n",
      "epoch:15 step:14523 [D loss: 0.509731, acc.: 75.78%] [G loss: 0.557147]\n",
      "epoch:15 step:14524 [D loss: 0.496478, acc.: 77.34%] [G loss: 0.673448]\n",
      "epoch:15 step:14525 [D loss: 0.569783, acc.: 69.53%] [G loss: 0.736892]\n",
      "epoch:15 step:14526 [D loss: 0.447989, acc.: 76.56%] [G loss: 0.756921]\n",
      "epoch:15 step:14527 [D loss: 0.451361, acc.: 76.56%] [G loss: 0.872382]\n",
      "epoch:15 step:14528 [D loss: 0.617270, acc.: 64.84%] [G loss: 0.742972]\n",
      "epoch:15 step:14529 [D loss: 0.560025, acc.: 65.62%] [G loss: 0.666070]\n",
      "epoch:15 step:14530 [D loss: 0.509902, acc.: 72.66%] [G loss: 0.815157]\n",
      "epoch:15 step:14531 [D loss: 0.495782, acc.: 76.56%] [G loss: 0.807001]\n",
      "epoch:15 step:14532 [D loss: 0.624324, acc.: 63.28%] [G loss: 0.578114]\n",
      "epoch:15 step:14533 [D loss: 0.545238, acc.: 71.09%] [G loss: 0.502975]\n",
      "epoch:15 step:14534 [D loss: 0.576448, acc.: 66.41%] [G loss: 0.528569]\n",
      "epoch:15 step:14535 [D loss: 0.548708, acc.: 73.44%] [G loss: 0.551899]\n",
      "epoch:15 step:14536 [D loss: 0.510826, acc.: 78.91%] [G loss: 0.565825]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:15 step:14537 [D loss: 0.554176, acc.: 73.44%] [G loss: 0.500847]\n",
      "epoch:15 step:14538 [D loss: 0.489647, acc.: 77.34%] [G loss: 0.689345]\n",
      "epoch:15 step:14539 [D loss: 0.473249, acc.: 78.91%] [G loss: 0.827760]\n",
      "epoch:15 step:14540 [D loss: 0.497747, acc.: 76.56%] [G loss: 0.617824]\n",
      "epoch:15 step:14541 [D loss: 0.573009, acc.: 64.06%] [G loss: 0.570130]\n",
      "epoch:15 step:14542 [D loss: 0.572759, acc.: 68.75%] [G loss: 0.595457]\n",
      "epoch:15 step:14543 [D loss: 0.494230, acc.: 67.97%] [G loss: 0.698166]\n",
      "epoch:15 step:14544 [D loss: 0.551146, acc.: 70.31%] [G loss: 0.542840]\n",
      "epoch:15 step:14545 [D loss: 0.537102, acc.: 73.44%] [G loss: 0.550006]\n",
      "epoch:15 step:14546 [D loss: 0.519939, acc.: 71.88%] [G loss: 0.732939]\n",
      "epoch:15 step:14547 [D loss: 0.530288, acc.: 72.66%] [G loss: 0.656220]\n",
      "epoch:15 step:14548 [D loss: 0.509426, acc.: 75.00%] [G loss: 0.522483]\n",
      "epoch:15 step:14549 [D loss: 0.559815, acc.: 73.44%] [G loss: 0.596321]\n",
      "epoch:15 step:14550 [D loss: 0.497104, acc.: 77.34%] [G loss: 0.631955]\n",
      "epoch:15 step:14551 [D loss: 0.563126, acc.: 75.00%] [G loss: 0.770194]\n",
      "epoch:15 step:14552 [D loss: 0.516724, acc.: 75.00%] [G loss: 0.676645]\n",
      "epoch:15 step:14553 [D loss: 0.519627, acc.: 69.53%] [G loss: 0.716801]\n",
      "epoch:15 step:14554 [D loss: 0.457891, acc.: 81.25%] [G loss: 0.826369]\n",
      "epoch:15 step:14555 [D loss: 0.645592, acc.: 64.06%] [G loss: 0.642129]\n",
      "epoch:15 step:14556 [D loss: 0.624394, acc.: 69.53%] [G loss: 0.615130]\n",
      "epoch:15 step:14557 [D loss: 0.684355, acc.: 58.59%] [G loss: 0.424228]\n",
      "epoch:15 step:14558 [D loss: 0.502504, acc.: 75.00%] [G loss: 0.656946]\n",
      "epoch:15 step:14559 [D loss: 0.464750, acc.: 78.12%] [G loss: 0.608302]\n",
      "epoch:15 step:14560 [D loss: 0.522187, acc.: 75.00%] [G loss: 0.797445]\n",
      "epoch:15 step:14561 [D loss: 0.526011, acc.: 72.66%] [G loss: 0.871949]\n",
      "epoch:15 step:14562 [D loss: 0.460498, acc.: 80.47%] [G loss: 0.850676]\n",
      "epoch:15 step:14563 [D loss: 0.447968, acc.: 78.12%] [G loss: 1.048749]\n",
      "epoch:15 step:14564 [D loss: 0.512879, acc.: 75.78%] [G loss: 0.834783]\n",
      "epoch:15 step:14565 [D loss: 0.599524, acc.: 65.62%] [G loss: 0.734690]\n",
      "epoch:15 step:14566 [D loss: 0.681980, acc.: 56.25%] [G loss: 0.557132]\n",
      "epoch:15 step:14567 [D loss: 0.552830, acc.: 70.31%] [G loss: 0.471987]\n",
      "epoch:15 step:14568 [D loss: 0.518782, acc.: 75.78%] [G loss: 0.535348]\n",
      "epoch:15 step:14569 [D loss: 0.483659, acc.: 75.00%] [G loss: 0.542890]\n",
      "epoch:15 step:14570 [D loss: 0.545258, acc.: 71.88%] [G loss: 0.606660]\n",
      "epoch:15 step:14571 [D loss: 0.465798, acc.: 82.03%] [G loss: 0.624068]\n",
      "epoch:15 step:14572 [D loss: 0.465720, acc.: 77.34%] [G loss: 0.875211]\n",
      "epoch:15 step:14573 [D loss: 0.552572, acc.: 67.19%] [G loss: 0.791402]\n",
      "epoch:15 step:14574 [D loss: 0.492540, acc.: 75.78%] [G loss: 0.751265]\n",
      "epoch:15 step:14575 [D loss: 0.479757, acc.: 75.00%] [G loss: 0.801188]\n",
      "epoch:15 step:14576 [D loss: 0.538065, acc.: 73.44%] [G loss: 0.574255]\n",
      "epoch:15 step:14577 [D loss: 0.500799, acc.: 76.56%] [G loss: 0.710159]\n",
      "epoch:15 step:14578 [D loss: 0.490808, acc.: 77.34%] [G loss: 0.861303]\n",
      "epoch:15 step:14579 [D loss: 0.609207, acc.: 69.53%] [G loss: 0.615096]\n",
      "epoch:15 step:14580 [D loss: 0.576491, acc.: 69.53%] [G loss: 0.692405]\n",
      "epoch:15 step:14581 [D loss: 0.494099, acc.: 75.00%] [G loss: 0.787539]\n",
      "epoch:15 step:14582 [D loss: 0.537038, acc.: 72.66%] [G loss: 0.733566]\n",
      "epoch:15 step:14583 [D loss: 0.682707, acc.: 57.03%] [G loss: 0.472099]\n",
      "epoch:15 step:14584 [D loss: 0.617003, acc.: 60.94%] [G loss: 0.623475]\n",
      "epoch:15 step:14585 [D loss: 0.468689, acc.: 80.47%] [G loss: 0.698945]\n",
      "epoch:15 step:14586 [D loss: 0.563071, acc.: 66.41%] [G loss: 0.733673]\n",
      "epoch:15 step:14587 [D loss: 0.640673, acc.: 58.59%] [G loss: 0.408582]\n",
      "epoch:15 step:14588 [D loss: 0.570233, acc.: 67.97%] [G loss: 0.585697]\n",
      "epoch:15 step:14589 [D loss: 0.518012, acc.: 73.44%] [G loss: 0.815465]\n",
      "epoch:15 step:14590 [D loss: 0.535812, acc.: 70.31%] [G loss: 0.614753]\n",
      "epoch:15 step:14591 [D loss: 0.531399, acc.: 72.66%] [G loss: 0.486665]\n",
      "epoch:15 step:14592 [D loss: 0.592589, acc.: 67.97%] [G loss: 0.550702]\n",
      "epoch:15 step:14593 [D loss: 0.525840, acc.: 71.09%] [G loss: 0.597767]\n",
      "epoch:15 step:14594 [D loss: 0.533051, acc.: 72.66%] [G loss: 0.662692]\n",
      "epoch:15 step:14595 [D loss: 0.530754, acc.: 71.88%] [G loss: 0.703242]\n",
      "epoch:15 step:14596 [D loss: 0.540099, acc.: 67.19%] [G loss: 0.575737]\n",
      "epoch:15 step:14597 [D loss: 0.625368, acc.: 64.06%] [G loss: 0.529312]\n",
      "epoch:15 step:14598 [D loss: 0.531400, acc.: 71.09%] [G loss: 0.594109]\n",
      "epoch:15 step:14599 [D loss: 0.597778, acc.: 68.75%] [G loss: 0.579068]\n",
      "epoch:15 step:14600 [D loss: 0.548621, acc.: 69.53%] [G loss: 0.638393]\n",
      "epoch:15 step:14601 [D loss: 0.489109, acc.: 77.34%] [G loss: 0.704484]\n",
      "epoch:15 step:14602 [D loss: 0.532445, acc.: 71.88%] [G loss: 0.767711]\n",
      "epoch:15 step:14603 [D loss: 0.496730, acc.: 71.88%] [G loss: 0.763616]\n",
      "epoch:15 step:14604 [D loss: 0.530848, acc.: 71.88%] [G loss: 0.719756]\n",
      "epoch:15 step:14605 [D loss: 0.519369, acc.: 72.66%] [G loss: 0.640701]\n",
      "epoch:15 step:14606 [D loss: 0.546825, acc.: 72.66%] [G loss: 0.494025]\n",
      "epoch:15 step:14607 [D loss: 0.486742, acc.: 75.78%] [G loss: 0.679353]\n",
      "epoch:15 step:14608 [D loss: 0.542394, acc.: 69.53%] [G loss: 0.676803]\n",
      "epoch:15 step:14609 [D loss: 0.491133, acc.: 74.22%] [G loss: 0.651268]\n",
      "epoch:15 step:14610 [D loss: 0.497562, acc.: 75.78%] [G loss: 0.768961]\n",
      "epoch:15 step:14611 [D loss: 0.548878, acc.: 71.09%] [G loss: 0.801088]\n",
      "epoch:15 step:14612 [D loss: 0.522056, acc.: 75.00%] [G loss: 0.662826]\n",
      "epoch:15 step:14613 [D loss: 0.463923, acc.: 78.12%] [G loss: 0.700926]\n",
      "epoch:15 step:14614 [D loss: 0.592903, acc.: 68.75%] [G loss: 0.700614]\n",
      "epoch:15 step:14615 [D loss: 0.554495, acc.: 71.09%] [G loss: 0.566862]\n",
      "epoch:15 step:14616 [D loss: 0.540626, acc.: 67.97%] [G loss: 0.768008]\n",
      "epoch:15 step:14617 [D loss: 0.595551, acc.: 64.06%] [G loss: 0.742664]\n",
      "epoch:15 step:14618 [D loss: 0.536358, acc.: 71.88%] [G loss: 0.744704]\n",
      "epoch:15 step:14619 [D loss: 0.455520, acc.: 77.34%] [G loss: 0.871663]\n",
      "epoch:15 step:14620 [D loss: 0.547447, acc.: 71.88%] [G loss: 0.698336]\n",
      "epoch:15 step:14621 [D loss: 0.646874, acc.: 62.50%] [G loss: 0.510694]\n",
      "epoch:15 step:14622 [D loss: 0.500043, acc.: 76.56%] [G loss: 0.628583]\n",
      "epoch:15 step:14623 [D loss: 0.503846, acc.: 76.56%] [G loss: 0.546058]\n",
      "epoch:15 step:14624 [D loss: 0.537794, acc.: 68.75%] [G loss: 0.642444]\n",
      "epoch:15 step:14625 [D loss: 0.488674, acc.: 77.34%] [G loss: 0.689183]\n",
      "epoch:15 step:14626 [D loss: 0.573385, acc.: 64.84%] [G loss: 0.542438]\n",
      "epoch:15 step:14627 [D loss: 0.533101, acc.: 73.44%] [G loss: 0.614770]\n",
      "epoch:15 step:14628 [D loss: 0.520373, acc.: 74.22%] [G loss: 0.667290]\n",
      "epoch:15 step:14629 [D loss: 0.499480, acc.: 78.12%] [G loss: 0.713900]\n",
      "epoch:15 step:14630 [D loss: 0.495908, acc.: 77.34%] [G loss: 0.736774]\n",
      "epoch:15 step:14631 [D loss: 0.584190, acc.: 67.97%] [G loss: 0.637363]\n",
      "epoch:15 step:14632 [D loss: 0.526726, acc.: 68.75%] [G loss: 0.599168]\n",
      "epoch:15 step:14633 [D loss: 0.577764, acc.: 66.41%] [G loss: 0.569774]\n",
      "epoch:15 step:14634 [D loss: 0.517678, acc.: 73.44%] [G loss: 0.574361]\n",
      "epoch:15 step:14635 [D loss: 0.591703, acc.: 66.41%] [G loss: 0.529913]\n",
      "epoch:15 step:14636 [D loss: 0.562205, acc.: 66.41%] [G loss: 0.539280]\n",
      "epoch:15 step:14637 [D loss: 0.460131, acc.: 78.91%] [G loss: 0.770420]\n",
      "epoch:15 step:14638 [D loss: 0.518709, acc.: 72.66%] [G loss: 0.772082]\n",
      "epoch:15 step:14639 [D loss: 0.536666, acc.: 73.44%] [G loss: 0.776661]\n",
      "epoch:15 step:14640 [D loss: 0.563781, acc.: 67.19%] [G loss: 0.599843]\n",
      "epoch:15 step:14641 [D loss: 0.604128, acc.: 66.41%] [G loss: 0.655274]\n",
      "epoch:15 step:14642 [D loss: 0.547778, acc.: 69.53%] [G loss: 0.629098]\n",
      "epoch:15 step:14643 [D loss: 0.525420, acc.: 70.31%] [G loss: 0.715530]\n",
      "epoch:15 step:14644 [D loss: 0.555673, acc.: 64.84%] [G loss: 0.689069]\n",
      "epoch:15 step:14645 [D loss: 0.577592, acc.: 67.19%] [G loss: 0.698910]\n",
      "epoch:15 step:14646 [D loss: 0.541243, acc.: 71.09%] [G loss: 0.683619]\n",
      "epoch:15 step:14647 [D loss: 0.483377, acc.: 78.91%] [G loss: 0.625399]\n",
      "epoch:15 step:14648 [D loss: 0.536639, acc.: 68.75%] [G loss: 0.733666]\n",
      "epoch:15 step:14649 [D loss: 0.558890, acc.: 70.31%] [G loss: 0.742541]\n",
      "epoch:15 step:14650 [D loss: 0.522676, acc.: 74.22%] [G loss: 0.683048]\n",
      "epoch:15 step:14651 [D loss: 0.533436, acc.: 71.09%] [G loss: 0.726346]\n",
      "epoch:15 step:14652 [D loss: 0.546422, acc.: 71.09%] [G loss: 0.664236]\n",
      "epoch:15 step:14653 [D loss: 0.475197, acc.: 76.56%] [G loss: 0.808463]\n",
      "epoch:15 step:14654 [D loss: 0.551060, acc.: 71.09%] [G loss: 0.863804]\n",
      "epoch:15 step:14655 [D loss: 0.587950, acc.: 68.75%] [G loss: 0.757117]\n",
      "epoch:15 step:14656 [D loss: 0.496319, acc.: 74.22%] [G loss: 0.750772]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:15 step:14657 [D loss: 0.484851, acc.: 77.34%] [G loss: 0.785432]\n",
      "epoch:15 step:14658 [D loss: 0.542243, acc.: 70.31%] [G loss: 0.607942]\n",
      "epoch:15 step:14659 [D loss: 0.543980, acc.: 71.09%] [G loss: 0.730956]\n",
      "epoch:15 step:14660 [D loss: 0.482570, acc.: 74.22%] [G loss: 0.675987]\n",
      "epoch:15 step:14661 [D loss: 0.618322, acc.: 64.84%] [G loss: 0.569969]\n",
      "epoch:15 step:14662 [D loss: 0.500780, acc.: 74.22%] [G loss: 0.516546]\n",
      "epoch:15 step:14663 [D loss: 0.568924, acc.: 71.88%] [G loss: 0.486579]\n",
      "epoch:15 step:14664 [D loss: 0.549888, acc.: 74.22%] [G loss: 0.601920]\n",
      "epoch:15 step:14665 [D loss: 0.543948, acc.: 71.88%] [G loss: 0.564814]\n",
      "epoch:15 step:14666 [D loss: 0.497961, acc.: 72.66%] [G loss: 0.523333]\n",
      "epoch:15 step:14667 [D loss: 0.514202, acc.: 73.44%] [G loss: 0.611390]\n",
      "epoch:15 step:14668 [D loss: 0.497157, acc.: 75.00%] [G loss: 0.524886]\n",
      "epoch:15 step:14669 [D loss: 0.551499, acc.: 71.09%] [G loss: 0.514116]\n",
      "epoch:15 step:14670 [D loss: 0.586491, acc.: 63.28%] [G loss: 0.618556]\n",
      "epoch:15 step:14671 [D loss: 0.570583, acc.: 71.09%] [G loss: 0.613666]\n",
      "epoch:15 step:14672 [D loss: 0.511789, acc.: 75.78%] [G loss: 0.756505]\n",
      "epoch:15 step:14673 [D loss: 0.499060, acc.: 75.00%] [G loss: 0.822051]\n",
      "epoch:15 step:14674 [D loss: 0.556954, acc.: 66.41%] [G loss: 0.607505]\n",
      "epoch:15 step:14675 [D loss: 0.553064, acc.: 68.75%] [G loss: 0.711524]\n",
      "epoch:15 step:14676 [D loss: 0.582857, acc.: 69.53%] [G loss: 0.611864]\n",
      "epoch:15 step:14677 [D loss: 0.616999, acc.: 67.19%] [G loss: 0.498489]\n",
      "epoch:15 step:14678 [D loss: 0.466303, acc.: 77.34%] [G loss: 0.656112]\n",
      "epoch:15 step:14679 [D loss: 0.488932, acc.: 75.00%] [G loss: 0.869121]\n",
      "epoch:15 step:14680 [D loss: 0.586571, acc.: 64.84%] [G loss: 0.690359]\n",
      "epoch:15 step:14681 [D loss: 0.549916, acc.: 71.09%] [G loss: 0.610105]\n",
      "epoch:15 step:14682 [D loss: 0.561994, acc.: 66.41%] [G loss: 0.550601]\n",
      "epoch:15 step:14683 [D loss: 0.576986, acc.: 64.06%] [G loss: 0.502765]\n",
      "epoch:15 step:14684 [D loss: 0.520032, acc.: 73.44%] [G loss: 0.604670]\n",
      "epoch:15 step:14685 [D loss: 0.559201, acc.: 70.31%] [G loss: 0.676842]\n",
      "epoch:15 step:14686 [D loss: 0.476373, acc.: 79.69%] [G loss: 0.730362]\n",
      "epoch:15 step:14687 [D loss: 0.510250, acc.: 75.00%] [G loss: 0.722206]\n",
      "epoch:15 step:14688 [D loss: 0.518810, acc.: 75.00%] [G loss: 0.635955]\n",
      "epoch:15 step:14689 [D loss: 0.484690, acc.: 77.34%] [G loss: 0.907316]\n",
      "epoch:15 step:14690 [D loss: 0.496093, acc.: 75.78%] [G loss: 0.730152]\n",
      "epoch:15 step:14691 [D loss: 0.579048, acc.: 68.75%] [G loss: 0.576260]\n",
      "epoch:15 step:14692 [D loss: 0.554391, acc.: 68.75%] [G loss: 0.486027]\n",
      "epoch:15 step:14693 [D loss: 0.483067, acc.: 73.44%] [G loss: 0.692613]\n",
      "epoch:15 step:14694 [D loss: 0.484264, acc.: 72.66%] [G loss: 0.492343]\n",
      "epoch:15 step:14695 [D loss: 0.584343, acc.: 65.62%] [G loss: 0.709460]\n",
      "epoch:15 step:14696 [D loss: 0.471162, acc.: 75.00%] [G loss: 0.695320]\n",
      "epoch:15 step:14697 [D loss: 0.430544, acc.: 82.03%] [G loss: 0.792168]\n",
      "epoch:15 step:14698 [D loss: 0.531204, acc.: 73.44%] [G loss: 0.840370]\n",
      "epoch:15 step:14699 [D loss: 0.516863, acc.: 74.22%] [G loss: 0.669519]\n",
      "epoch:15 step:14700 [D loss: 0.558964, acc.: 67.97%] [G loss: 0.623671]\n",
      "epoch:15 step:14701 [D loss: 0.529705, acc.: 70.31%] [G loss: 0.485014]\n",
      "epoch:15 step:14702 [D loss: 0.504395, acc.: 75.78%] [G loss: 0.686633]\n",
      "epoch:15 step:14703 [D loss: 0.428149, acc.: 78.12%] [G loss: 0.858742]\n",
      "epoch:15 step:14704 [D loss: 0.485976, acc.: 77.34%] [G loss: 0.840050]\n",
      "epoch:15 step:14705 [D loss: 0.505875, acc.: 71.88%] [G loss: 0.784215]\n",
      "epoch:15 step:14706 [D loss: 0.489386, acc.: 76.56%] [G loss: 0.711328]\n",
      "epoch:15 step:14707 [D loss: 0.608509, acc.: 66.41%] [G loss: 0.640495]\n",
      "epoch:15 step:14708 [D loss: 0.564528, acc.: 67.97%] [G loss: 0.503654]\n",
      "epoch:15 step:14709 [D loss: 0.478931, acc.: 76.56%] [G loss: 0.651110]\n",
      "epoch:15 step:14710 [D loss: 0.514249, acc.: 76.56%] [G loss: 0.613210]\n",
      "epoch:15 step:14711 [D loss: 0.527166, acc.: 68.75%] [G loss: 0.691567]\n",
      "epoch:15 step:14712 [D loss: 0.509750, acc.: 72.66%] [G loss: 0.772046]\n",
      "epoch:15 step:14713 [D loss: 0.571175, acc.: 70.31%] [G loss: 0.650986]\n",
      "epoch:15 step:14714 [D loss: 0.535382, acc.: 69.53%] [G loss: 0.704193]\n",
      "epoch:15 step:14715 [D loss: 0.512314, acc.: 73.44%] [G loss: 0.697383]\n",
      "epoch:15 step:14716 [D loss: 0.501959, acc.: 73.44%] [G loss: 0.804828]\n",
      "epoch:15 step:14717 [D loss: 0.535201, acc.: 68.75%] [G loss: 0.669773]\n",
      "epoch:15 step:14718 [D loss: 0.536745, acc.: 67.97%] [G loss: 0.537711]\n",
      "epoch:15 step:14719 [D loss: 0.551534, acc.: 70.31%] [G loss: 0.697333]\n",
      "epoch:15 step:14720 [D loss: 0.553487, acc.: 74.22%] [G loss: 0.646067]\n",
      "epoch:15 step:14721 [D loss: 0.564731, acc.: 64.06%] [G loss: 0.673381]\n",
      "epoch:15 step:14722 [D loss: 0.559177, acc.: 71.09%] [G loss: 0.564467]\n",
      "epoch:15 step:14723 [D loss: 0.598137, acc.: 67.97%] [G loss: 0.657506]\n",
      "epoch:15 step:14724 [D loss: 0.538902, acc.: 71.09%] [G loss: 0.572222]\n",
      "epoch:15 step:14725 [D loss: 0.537483, acc.: 69.53%] [G loss: 0.509003]\n",
      "epoch:15 step:14726 [D loss: 0.507135, acc.: 74.22%] [G loss: 0.583011]\n",
      "epoch:15 step:14727 [D loss: 0.540200, acc.: 67.97%] [G loss: 0.520141]\n",
      "epoch:15 step:14728 [D loss: 0.634540, acc.: 64.06%] [G loss: 0.720191]\n",
      "epoch:15 step:14729 [D loss: 0.627055, acc.: 63.28%] [G loss: 0.638345]\n",
      "epoch:15 step:14730 [D loss: 0.552792, acc.: 71.09%] [G loss: 0.574924]\n",
      "epoch:15 step:14731 [D loss: 0.577264, acc.: 68.75%] [G loss: 0.649868]\n",
      "epoch:15 step:14732 [D loss: 0.445474, acc.: 82.81%] [G loss: 0.848194]\n",
      "epoch:15 step:14733 [D loss: 0.563253, acc.: 67.97%] [G loss: 0.493600]\n",
      "epoch:15 step:14734 [D loss: 0.494305, acc.: 71.88%] [G loss: 0.717082]\n",
      "epoch:15 step:14735 [D loss: 0.510254, acc.: 72.66%] [G loss: 0.742086]\n",
      "epoch:15 step:14736 [D loss: 0.458422, acc.: 77.34%] [G loss: 0.777596]\n",
      "epoch:15 step:14737 [D loss: 0.472782, acc.: 73.44%] [G loss: 0.606654]\n",
      "epoch:15 step:14738 [D loss: 0.551717, acc.: 69.53%] [G loss: 0.632487]\n",
      "epoch:15 step:14739 [D loss: 0.609251, acc.: 64.84%] [G loss: 0.468650]\n",
      "epoch:15 step:14740 [D loss: 0.498792, acc.: 75.00%] [G loss: 0.615431]\n",
      "epoch:15 step:14741 [D loss: 0.581042, acc.: 67.19%] [G loss: 0.454180]\n",
      "epoch:15 step:14742 [D loss: 0.562739, acc.: 69.53%] [G loss: 0.495835]\n",
      "epoch:15 step:14743 [D loss: 0.507992, acc.: 75.78%] [G loss: 0.625359]\n",
      "epoch:15 step:14744 [D loss: 0.568896, acc.: 67.97%] [G loss: 0.692254]\n",
      "epoch:15 step:14745 [D loss: 0.531515, acc.: 71.09%] [G loss: 0.641951]\n",
      "epoch:15 step:14746 [D loss: 0.463629, acc.: 78.12%] [G loss: 0.785898]\n",
      "epoch:15 step:14747 [D loss: 0.471983, acc.: 82.03%] [G loss: 0.832863]\n",
      "epoch:15 step:14748 [D loss: 0.484999, acc.: 71.09%] [G loss: 0.768878]\n",
      "epoch:15 step:14749 [D loss: 0.420937, acc.: 82.81%] [G loss: 0.734694]\n",
      "epoch:15 step:14750 [D loss: 0.557885, acc.: 71.88%] [G loss: 0.596870]\n",
      "epoch:15 step:14751 [D loss: 0.651552, acc.: 60.94%] [G loss: 0.663950]\n",
      "epoch:15 step:14752 [D loss: 0.591214, acc.: 65.62%] [G loss: 0.506171]\n",
      "epoch:15 step:14753 [D loss: 0.564961, acc.: 66.41%] [G loss: 0.478514]\n",
      "epoch:15 step:14754 [D loss: 0.492152, acc.: 77.34%] [G loss: 0.535567]\n",
      "epoch:15 step:14755 [D loss: 0.521181, acc.: 71.09%] [G loss: 0.506035]\n",
      "epoch:15 step:14756 [D loss: 0.556161, acc.: 70.31%] [G loss: 0.712423]\n",
      "epoch:15 step:14757 [D loss: 0.580951, acc.: 66.41%] [G loss: 0.761555]\n",
      "epoch:15 step:14758 [D loss: 0.591453, acc.: 68.75%] [G loss: 0.664595]\n",
      "epoch:15 step:14759 [D loss: 0.599643, acc.: 64.84%] [G loss: 0.538896]\n",
      "epoch:15 step:14760 [D loss: 0.487446, acc.: 74.22%] [G loss: 0.639293]\n",
      "epoch:15 step:14761 [D loss: 0.539930, acc.: 70.31%] [G loss: 0.571027]\n",
      "epoch:15 step:14762 [D loss: 0.509760, acc.: 72.66%] [G loss: 0.577990]\n",
      "epoch:15 step:14763 [D loss: 0.498820, acc.: 75.78%] [G loss: 0.661920]\n",
      "epoch:15 step:14764 [D loss: 0.551166, acc.: 67.97%] [G loss: 0.790753]\n",
      "epoch:15 step:14765 [D loss: 0.612958, acc.: 63.28%] [G loss: 0.578861]\n",
      "epoch:15 step:14766 [D loss: 0.538244, acc.: 67.19%] [G loss: 0.553864]\n",
      "epoch:15 step:14767 [D loss: 0.522432, acc.: 71.09%] [G loss: 0.575343]\n",
      "epoch:15 step:14768 [D loss: 0.580251, acc.: 64.06%] [G loss: 0.431398]\n",
      "epoch:15 step:14769 [D loss: 0.532359, acc.: 70.31%] [G loss: 0.624208]\n",
      "epoch:15 step:14770 [D loss: 0.591822, acc.: 66.41%] [G loss: 0.624371]\n",
      "epoch:15 step:14771 [D loss: 0.651540, acc.: 65.62%] [G loss: 0.641032]\n",
      "epoch:15 step:14772 [D loss: 0.562261, acc.: 67.19%] [G loss: 0.837208]\n",
      "epoch:15 step:14773 [D loss: 0.564003, acc.: 74.22%] [G loss: 0.590544]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:15 step:14774 [D loss: 0.481370, acc.: 79.69%] [G loss: 0.793369]\n",
      "epoch:15 step:14775 [D loss: 0.639745, acc.: 65.62%] [G loss: 0.755688]\n",
      "epoch:15 step:14776 [D loss: 0.533773, acc.: 71.09%] [G loss: 0.596769]\n",
      "epoch:15 step:14777 [D loss: 0.572410, acc.: 68.75%] [G loss: 0.475018]\n",
      "epoch:15 step:14778 [D loss: 0.536389, acc.: 70.31%] [G loss: 0.531163]\n",
      "epoch:15 step:14779 [D loss: 0.489145, acc.: 75.78%] [G loss: 0.488894]\n",
      "epoch:15 step:14780 [D loss: 0.553643, acc.: 71.09%] [G loss: 0.698810]\n",
      "epoch:15 step:14781 [D loss: 0.518704, acc.: 70.31%] [G loss: 0.685680]\n",
      "epoch:15 step:14782 [D loss: 0.559723, acc.: 67.19%] [G loss: 0.736386]\n",
      "epoch:15 step:14783 [D loss: 0.503511, acc.: 73.44%] [G loss: 0.828130]\n",
      "epoch:15 step:14784 [D loss: 0.519536, acc.: 75.00%] [G loss: 0.522318]\n",
      "epoch:15 step:14785 [D loss: 0.521419, acc.: 74.22%] [G loss: 0.581503]\n",
      "epoch:15 step:14786 [D loss: 0.588408, acc.: 64.06%] [G loss: 0.519274]\n",
      "epoch:15 step:14787 [D loss: 0.574013, acc.: 61.72%] [G loss: 0.530203]\n",
      "epoch:15 step:14788 [D loss: 0.557596, acc.: 71.88%] [G loss: 0.640073]\n",
      "epoch:15 step:14789 [D loss: 0.533213, acc.: 71.88%] [G loss: 0.443935]\n",
      "epoch:15 step:14790 [D loss: 0.558877, acc.: 67.19%] [G loss: 0.546929]\n",
      "epoch:15 step:14791 [D loss: 0.507806, acc.: 69.53%] [G loss: 0.615710]\n",
      "epoch:15 step:14792 [D loss: 0.520100, acc.: 71.09%] [G loss: 0.687048]\n",
      "epoch:15 step:14793 [D loss: 0.548249, acc.: 70.31%] [G loss: 0.596198]\n",
      "epoch:15 step:14794 [D loss: 0.544558, acc.: 73.44%] [G loss: 0.581609]\n",
      "epoch:15 step:14795 [D loss: 0.585026, acc.: 64.06%] [G loss: 0.331211]\n",
      "epoch:15 step:14796 [D loss: 0.541914, acc.: 69.53%] [G loss: 0.548639]\n",
      "epoch:15 step:14797 [D loss: 0.478283, acc.: 74.22%] [G loss: 0.549459]\n",
      "epoch:15 step:14798 [D loss: 0.460867, acc.: 77.34%] [G loss: 0.760083]\n",
      "epoch:15 step:14799 [D loss: 0.481375, acc.: 79.69%] [G loss: 0.881789]\n",
      "epoch:15 step:14800 [D loss: 0.601908, acc.: 64.06%] [G loss: 0.538025]\n",
      "epoch:15 step:14801 [D loss: 0.535761, acc.: 70.31%] [G loss: 0.544581]\n",
      "epoch:15 step:14802 [D loss: 0.428705, acc.: 79.69%] [G loss: 0.848718]\n",
      "epoch:15 step:14803 [D loss: 0.542569, acc.: 71.88%] [G loss: 0.732658]\n",
      "epoch:15 step:14804 [D loss: 0.508913, acc.: 75.00%] [G loss: 0.792421]\n",
      "epoch:15 step:14805 [D loss: 0.480074, acc.: 76.56%] [G loss: 0.857059]\n",
      "epoch:15 step:14806 [D loss: 0.462787, acc.: 79.69%] [G loss: 0.680654]\n",
      "epoch:15 step:14807 [D loss: 0.596337, acc.: 66.41%] [G loss: 0.617867]\n",
      "epoch:15 step:14808 [D loss: 0.516511, acc.: 72.66%] [G loss: 0.631337]\n",
      "epoch:15 step:14809 [D loss: 0.547051, acc.: 71.88%] [G loss: 0.700468]\n",
      "epoch:15 step:14810 [D loss: 0.513361, acc.: 71.88%] [G loss: 0.581834]\n",
      "epoch:15 step:14811 [D loss: 0.524209, acc.: 74.22%] [G loss: 0.655038]\n",
      "epoch:15 step:14812 [D loss: 0.596578, acc.: 66.41%] [G loss: 0.566118]\n",
      "epoch:15 step:14813 [D loss: 0.543699, acc.: 71.09%] [G loss: 0.664378]\n",
      "epoch:15 step:14814 [D loss: 0.546079, acc.: 71.88%] [G loss: 0.559220]\n",
      "epoch:15 step:14815 [D loss: 0.524994, acc.: 71.88%] [G loss: 0.562436]\n",
      "epoch:15 step:14816 [D loss: 0.576424, acc.: 65.62%] [G loss: 0.589472]\n",
      "epoch:15 step:14817 [D loss: 0.613989, acc.: 65.62%] [G loss: 0.463390]\n",
      "epoch:15 step:14818 [D loss: 0.589154, acc.: 67.97%] [G loss: 0.502031]\n",
      "epoch:15 step:14819 [D loss: 0.557039, acc.: 65.62%] [G loss: 0.593054]\n",
      "epoch:15 step:14820 [D loss: 0.628714, acc.: 63.28%] [G loss: 0.523032]\n",
      "epoch:15 step:14821 [D loss: 0.647772, acc.: 60.16%] [G loss: 0.418635]\n",
      "epoch:15 step:14822 [D loss: 0.499473, acc.: 78.91%] [G loss: 0.550320]\n",
      "epoch:15 step:14823 [D loss: 0.566166, acc.: 71.88%] [G loss: 0.587780]\n",
      "epoch:15 step:14824 [D loss: 0.541888, acc.: 70.31%] [G loss: 0.657766]\n",
      "epoch:15 step:14825 [D loss: 0.518520, acc.: 75.00%] [G loss: 0.738929]\n",
      "epoch:15 step:14826 [D loss: 0.516938, acc.: 71.88%] [G loss: 0.688601]\n",
      "epoch:15 step:14827 [D loss: 0.502103, acc.: 71.88%] [G loss: 0.642135]\n",
      "epoch:15 step:14828 [D loss: 0.516221, acc.: 70.31%] [G loss: 0.670167]\n",
      "epoch:15 step:14829 [D loss: 0.544516, acc.: 71.88%] [G loss: 0.643082]\n",
      "epoch:15 step:14830 [D loss: 0.521995, acc.: 72.66%] [G loss: 0.636235]\n",
      "epoch:15 step:14831 [D loss: 0.566323, acc.: 69.53%] [G loss: 0.558581]\n",
      "epoch:15 step:14832 [D loss: 0.550213, acc.: 68.75%] [G loss: 0.555221]\n",
      "epoch:15 step:14833 [D loss: 0.569814, acc.: 69.53%] [G loss: 0.571910]\n",
      "epoch:15 step:14834 [D loss: 0.560591, acc.: 66.41%] [G loss: 0.608186]\n",
      "epoch:15 step:14835 [D loss: 0.544405, acc.: 68.75%] [G loss: 0.712394]\n",
      "epoch:15 step:14836 [D loss: 0.487400, acc.: 74.22%] [G loss: 0.877729]\n",
      "epoch:15 step:14837 [D loss: 0.526844, acc.: 74.22%] [G loss: 0.919602]\n",
      "epoch:15 step:14838 [D loss: 0.532963, acc.: 74.22%] [G loss: 0.851152]\n",
      "epoch:15 step:14839 [D loss: 0.634805, acc.: 57.81%] [G loss: 0.494453]\n",
      "epoch:15 step:14840 [D loss: 0.563736, acc.: 68.75%] [G loss: 0.574174]\n",
      "epoch:15 step:14841 [D loss: 0.509475, acc.: 73.44%] [G loss: 0.624148]\n",
      "epoch:15 step:14842 [D loss: 0.597351, acc.: 67.97%] [G loss: 0.579603]\n",
      "epoch:15 step:14843 [D loss: 0.643369, acc.: 59.38%] [G loss: 0.501471]\n",
      "epoch:15 step:14844 [D loss: 0.500980, acc.: 72.66%] [G loss: 0.506756]\n",
      "epoch:15 step:14845 [D loss: 0.537798, acc.: 68.75%] [G loss: 0.648704]\n",
      "epoch:15 step:14846 [D loss: 0.543651, acc.: 71.88%] [G loss: 0.517876]\n",
      "epoch:15 step:14847 [D loss: 0.485294, acc.: 78.12%] [G loss: 0.728356]\n",
      "epoch:15 step:14848 [D loss: 0.580505, acc.: 68.75%] [G loss: 0.725548]\n",
      "epoch:15 step:14849 [D loss: 0.638818, acc.: 63.28%] [G loss: 0.574653]\n",
      "epoch:15 step:14850 [D loss: 0.552187, acc.: 66.41%] [G loss: 0.656070]\n",
      "epoch:15 step:14851 [D loss: 0.494208, acc.: 75.00%] [G loss: 0.741772]\n",
      "epoch:15 step:14852 [D loss: 0.551114, acc.: 67.19%] [G loss: 0.723928]\n",
      "epoch:15 step:14853 [D loss: 0.597238, acc.: 64.84%] [G loss: 0.664894]\n",
      "epoch:15 step:14854 [D loss: 0.553855, acc.: 69.53%] [G loss: 0.785639]\n",
      "epoch:15 step:14855 [D loss: 0.618309, acc.: 64.06%] [G loss: 0.582862]\n",
      "epoch:15 step:14856 [D loss: 0.460150, acc.: 77.34%] [G loss: 0.744536]\n",
      "epoch:15 step:14857 [D loss: 0.527695, acc.: 77.34%] [G loss: 0.711869]\n",
      "epoch:15 step:14858 [D loss: 0.481756, acc.: 77.34%] [G loss: 0.716663]\n",
      "epoch:15 step:14859 [D loss: 0.517105, acc.: 67.97%] [G loss: 0.625870]\n",
      "epoch:15 step:14860 [D loss: 0.557226, acc.: 66.41%] [G loss: 0.601937]\n",
      "epoch:15 step:14861 [D loss: 0.543395, acc.: 69.53%] [G loss: 0.608785]\n",
      "epoch:15 step:14862 [D loss: 0.525320, acc.: 69.53%] [G loss: 0.604681]\n",
      "epoch:15 step:14863 [D loss: 0.544990, acc.: 72.66%] [G loss: 0.583452]\n",
      "epoch:15 step:14864 [D loss: 0.495598, acc.: 75.00%] [G loss: 0.683983]\n",
      "epoch:15 step:14865 [D loss: 0.532882, acc.: 70.31%] [G loss: 0.563766]\n",
      "epoch:15 step:14866 [D loss: 0.572185, acc.: 73.44%] [G loss: 0.545064]\n",
      "epoch:15 step:14867 [D loss: 0.569763, acc.: 72.66%] [G loss: 0.438222]\n",
      "epoch:15 step:14868 [D loss: 0.532543, acc.: 67.97%] [G loss: 0.479982]\n",
      "epoch:15 step:14869 [D loss: 0.520888, acc.: 75.00%] [G loss: 0.459760]\n",
      "epoch:15 step:14870 [D loss: 0.485986, acc.: 75.78%] [G loss: 0.702163]\n",
      "epoch:15 step:14871 [D loss: 0.529380, acc.: 71.88%] [G loss: 0.594380]\n",
      "epoch:15 step:14872 [D loss: 0.563810, acc.: 72.66%] [G loss: 0.584639]\n",
      "epoch:15 step:14873 [D loss: 0.591185, acc.: 64.84%] [G loss: 0.600049]\n",
      "epoch:15 step:14874 [D loss: 0.510056, acc.: 71.09%] [G loss: 0.712352]\n",
      "epoch:15 step:14875 [D loss: 0.591813, acc.: 66.41%] [G loss: 0.641035]\n",
      "epoch:15 step:14876 [D loss: 0.543894, acc.: 67.19%] [G loss: 0.594880]\n",
      "epoch:15 step:14877 [D loss: 0.537697, acc.: 67.97%] [G loss: 0.654928]\n",
      "epoch:15 step:14878 [D loss: 0.467449, acc.: 75.00%] [G loss: 0.641458]\n",
      "epoch:15 step:14879 [D loss: 0.594803, acc.: 64.84%] [G loss: 0.639220]\n",
      "epoch:15 step:14880 [D loss: 0.519378, acc.: 73.44%] [G loss: 0.612139]\n",
      "epoch:15 step:14881 [D loss: 0.482199, acc.: 78.12%] [G loss: 0.666528]\n",
      "epoch:15 step:14882 [D loss: 0.578979, acc.: 67.19%] [G loss: 0.617233]\n",
      "epoch:15 step:14883 [D loss: 0.620914, acc.: 62.50%] [G loss: 0.569971]\n",
      "epoch:15 step:14884 [D loss: 0.543528, acc.: 71.09%] [G loss: 0.558085]\n",
      "epoch:15 step:14885 [D loss: 0.565211, acc.: 67.97%] [G loss: 0.687833]\n",
      "epoch:15 step:14886 [D loss: 0.546310, acc.: 72.66%] [G loss: 0.495709]\n",
      "epoch:15 step:14887 [D loss: 0.520113, acc.: 67.97%] [G loss: 0.473278]\n",
      "epoch:15 step:14888 [D loss: 0.522622, acc.: 75.00%] [G loss: 0.628691]\n",
      "epoch:15 step:14889 [D loss: 0.523063, acc.: 70.31%] [G loss: 0.661982]\n",
      "epoch:15 step:14890 [D loss: 0.520407, acc.: 73.44%] [G loss: 0.556353]\n",
      "epoch:15 step:14891 [D loss: 0.524826, acc.: 75.00%] [G loss: 0.460354]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:15 step:14892 [D loss: 0.535765, acc.: 73.44%] [G loss: 0.543606]\n",
      "epoch:15 step:14893 [D loss: 0.555920, acc.: 67.97%] [G loss: 0.540676]\n",
      "epoch:15 step:14894 [D loss: 0.546498, acc.: 70.31%] [G loss: 0.613662]\n",
      "epoch:15 step:14895 [D loss: 0.566251, acc.: 72.66%] [G loss: 0.468030]\n",
      "epoch:15 step:14896 [D loss: 0.557808, acc.: 66.41%] [G loss: 0.435662]\n",
      "epoch:15 step:14897 [D loss: 0.519292, acc.: 71.09%] [G loss: 0.445368]\n",
      "epoch:15 step:14898 [D loss: 0.507131, acc.: 72.66%] [G loss: 0.571962]\n",
      "epoch:15 step:14899 [D loss: 0.567219, acc.: 67.97%] [G loss: 0.711952]\n",
      "epoch:15 step:14900 [D loss: 0.574928, acc.: 68.75%] [G loss: 0.684777]\n",
      "epoch:15 step:14901 [D loss: 0.575274, acc.: 64.84%] [G loss: 0.551932]\n",
      "epoch:15 step:14902 [D loss: 0.629679, acc.: 65.62%] [G loss: 0.518346]\n",
      "epoch:15 step:14903 [D loss: 0.484904, acc.: 74.22%] [G loss: 0.467806]\n",
      "epoch:15 step:14904 [D loss: 0.566473, acc.: 69.53%] [G loss: 0.500310]\n",
      "epoch:15 step:14905 [D loss: 0.502775, acc.: 75.00%] [G loss: 0.570259]\n",
      "epoch:15 step:14906 [D loss: 0.565270, acc.: 67.97%] [G loss: 0.520188]\n",
      "epoch:15 step:14907 [D loss: 0.509407, acc.: 74.22%] [G loss: 0.567930]\n",
      "epoch:15 step:14908 [D loss: 0.545205, acc.: 74.22%] [G loss: 0.671141]\n",
      "epoch:15 step:14909 [D loss: 0.525132, acc.: 70.31%] [G loss: 0.628866]\n",
      "epoch:15 step:14910 [D loss: 0.560689, acc.: 64.06%] [G loss: 0.661752]\n",
      "epoch:15 step:14911 [D loss: 0.609579, acc.: 67.97%] [G loss: 0.634323]\n",
      "epoch:15 step:14912 [D loss: 0.475323, acc.: 79.69%] [G loss: 0.552264]\n",
      "epoch:15 step:14913 [D loss: 0.615259, acc.: 67.97%] [G loss: 0.578850]\n",
      "epoch:15 step:14914 [D loss: 0.498675, acc.: 74.22%] [G loss: 0.757808]\n",
      "epoch:15 step:14915 [D loss: 0.460847, acc.: 78.12%] [G loss: 0.850667]\n",
      "epoch:15 step:14916 [D loss: 0.672948, acc.: 63.28%] [G loss: 0.662369]\n",
      "epoch:15 step:14917 [D loss: 0.541568, acc.: 70.31%] [G loss: 0.477979]\n",
      "epoch:15 step:14918 [D loss: 0.565822, acc.: 71.88%] [G loss: 0.532747]\n",
      "epoch:15 step:14919 [D loss: 0.571640, acc.: 66.41%] [G loss: 0.481907]\n",
      "epoch:15 step:14920 [D loss: 0.573838, acc.: 67.19%] [G loss: 0.530294]\n",
      "epoch:15 step:14921 [D loss: 0.559093, acc.: 68.75%] [G loss: 0.575503]\n",
      "epoch:15 step:14922 [D loss: 0.670059, acc.: 55.47%] [G loss: 0.524983]\n",
      "epoch:15 step:14923 [D loss: 0.538271, acc.: 71.88%] [G loss: 0.392592]\n",
      "epoch:15 step:14924 [D loss: 0.556490, acc.: 67.97%] [G loss: 0.594014]\n",
      "epoch:15 step:14925 [D loss: 0.515265, acc.: 72.66%] [G loss: 0.513501]\n",
      "epoch:15 step:14926 [D loss: 0.500831, acc.: 73.44%] [G loss: 0.728802]\n",
      "epoch:15 step:14927 [D loss: 0.479539, acc.: 73.44%] [G loss: 0.721988]\n",
      "epoch:15 step:14928 [D loss: 0.590598, acc.: 68.75%] [G loss: 0.550001]\n",
      "epoch:15 step:14929 [D loss: 0.551861, acc.: 68.75%] [G loss: 0.565876]\n",
      "epoch:15 step:14930 [D loss: 0.464245, acc.: 77.34%] [G loss: 0.664504]\n",
      "epoch:15 step:14931 [D loss: 0.528375, acc.: 71.88%] [G loss: 0.623417]\n",
      "epoch:15 step:14932 [D loss: 0.595003, acc.: 64.06%] [G loss: 0.625376]\n",
      "epoch:15 step:14933 [D loss: 0.559909, acc.: 71.09%] [G loss: 0.550269]\n",
      "epoch:15 step:14934 [D loss: 0.557122, acc.: 71.09%] [G loss: 0.631331]\n",
      "epoch:15 step:14935 [D loss: 0.652370, acc.: 58.59%] [G loss: 0.453794]\n",
      "epoch:15 step:14936 [D loss: 0.570629, acc.: 69.53%] [G loss: 0.549231]\n",
      "epoch:15 step:14937 [D loss: 0.606561, acc.: 64.06%] [G loss: 0.523719]\n",
      "epoch:15 step:14938 [D loss: 0.616430, acc.: 66.41%] [G loss: 0.448074]\n",
      "epoch:15 step:14939 [D loss: 0.489131, acc.: 77.34%] [G loss: 0.719004]\n",
      "epoch:15 step:14940 [D loss: 0.492801, acc.: 70.31%] [G loss: 0.712584]\n",
      "epoch:15 step:14941 [D loss: 0.523422, acc.: 77.34%] [G loss: 0.691508]\n",
      "epoch:15 step:14942 [D loss: 0.595320, acc.: 64.06%] [G loss: 0.588002]\n",
      "epoch:15 step:14943 [D loss: 0.565072, acc.: 64.06%] [G loss: 0.717014]\n",
      "epoch:15 step:14944 [D loss: 0.521705, acc.: 73.44%] [G loss: 0.588547]\n",
      "epoch:15 step:14945 [D loss: 0.441083, acc.: 81.25%] [G loss: 0.529890]\n",
      "epoch:15 step:14946 [D loss: 0.621686, acc.: 64.84%] [G loss: 0.606830]\n",
      "epoch:15 step:14947 [D loss: 0.602760, acc.: 65.62%] [G loss: 0.514106]\n",
      "epoch:15 step:14948 [D loss: 0.527961, acc.: 72.66%] [G loss: 0.509960]\n",
      "epoch:15 step:14949 [D loss: 0.472226, acc.: 75.78%] [G loss: 0.801472]\n",
      "epoch:15 step:14950 [D loss: 0.559738, acc.: 65.62%] [G loss: 0.882581]\n",
      "epoch:15 step:14951 [D loss: 0.494015, acc.: 75.00%] [G loss: 0.803699]\n",
      "epoch:15 step:14952 [D loss: 0.464267, acc.: 77.34%] [G loss: 0.714304]\n",
      "epoch:15 step:14953 [D loss: 0.503832, acc.: 77.34%] [G loss: 0.522654]\n",
      "epoch:15 step:14954 [D loss: 0.501043, acc.: 76.56%] [G loss: 0.609767]\n",
      "epoch:15 step:14955 [D loss: 0.509996, acc.: 71.88%] [G loss: 0.634722]\n",
      "epoch:15 step:14956 [D loss: 0.487648, acc.: 77.34%] [G loss: 0.679733]\n",
      "epoch:15 step:14957 [D loss: 0.563835, acc.: 72.66%] [G loss: 0.672433]\n",
      "epoch:15 step:14958 [D loss: 0.587550, acc.: 67.19%] [G loss: 0.576651]\n",
      "epoch:15 step:14959 [D loss: 0.587947, acc.: 67.97%] [G loss: 0.553100]\n",
      "epoch:15 step:14960 [D loss: 0.630450, acc.: 65.62%] [G loss: 0.538991]\n",
      "epoch:15 step:14961 [D loss: 0.516474, acc.: 78.12%] [G loss: 0.719097]\n",
      "epoch:15 step:14962 [D loss: 0.542371, acc.: 71.88%] [G loss: 0.668762]\n",
      "epoch:15 step:14963 [D loss: 0.553126, acc.: 71.09%] [G loss: 0.726326]\n",
      "epoch:15 step:14964 [D loss: 0.538272, acc.: 72.66%] [G loss: 0.586459]\n",
      "epoch:15 step:14965 [D loss: 0.533878, acc.: 71.88%] [G loss: 0.762364]\n",
      "epoch:15 step:14966 [D loss: 0.492546, acc.: 77.34%] [G loss: 0.735057]\n",
      "epoch:15 step:14967 [D loss: 0.504649, acc.: 73.44%] [G loss: 0.660408]\n",
      "epoch:15 step:14968 [D loss: 0.552761, acc.: 72.66%] [G loss: 0.734362]\n",
      "epoch:15 step:14969 [D loss: 0.493904, acc.: 78.12%] [G loss: 0.813119]\n",
      "epoch:15 step:14970 [D loss: 0.652807, acc.: 59.38%] [G loss: 0.546388]\n",
      "epoch:15 step:14971 [D loss: 0.493829, acc.: 74.22%] [G loss: 0.706919]\n",
      "epoch:15 step:14972 [D loss: 0.578403, acc.: 66.41%] [G loss: 0.651533]\n",
      "epoch:15 step:14973 [D loss: 0.468858, acc.: 78.91%] [G loss: 0.798409]\n",
      "epoch:15 step:14974 [D loss: 0.476319, acc.: 75.78%] [G loss: 0.940404]\n",
      "epoch:15 step:14975 [D loss: 0.608199, acc.: 71.09%] [G loss: 0.922664]\n",
      "epoch:15 step:14976 [D loss: 0.512703, acc.: 71.88%] [G loss: 0.741734]\n",
      "epoch:15 step:14977 [D loss: 0.522199, acc.: 75.78%] [G loss: 0.773764]\n",
      "epoch:15 step:14978 [D loss: 0.535993, acc.: 72.66%] [G loss: 0.649418]\n",
      "epoch:15 step:14979 [D loss: 0.440119, acc.: 80.47%] [G loss: 0.812003]\n",
      "epoch:15 step:14980 [D loss: 0.376888, acc.: 83.59%] [G loss: 1.091989]\n",
      "epoch:15 step:14981 [D loss: 0.443053, acc.: 77.34%] [G loss: 1.298223]\n",
      "epoch:15 step:14982 [D loss: 0.498046, acc.: 76.56%] [G loss: 1.006181]\n",
      "epoch:15 step:14983 [D loss: 0.765321, acc.: 59.38%] [G loss: 0.853753]\n",
      "epoch:15 step:14984 [D loss: 0.483426, acc.: 80.47%] [G loss: 1.257082]\n",
      "epoch:15 step:14985 [D loss: 0.484643, acc.: 71.09%] [G loss: 1.128189]\n",
      "epoch:15 step:14986 [D loss: 0.530407, acc.: 70.31%] [G loss: 0.891434]\n",
      "epoch:15 step:14987 [D loss: 0.643879, acc.: 63.28%] [G loss: 0.734846]\n",
      "epoch:15 step:14988 [D loss: 0.541912, acc.: 69.53%] [G loss: 0.757395]\n",
      "epoch:15 step:14989 [D loss: 0.533787, acc.: 68.75%] [G loss: 0.777555]\n",
      "epoch:15 step:14990 [D loss: 0.479237, acc.: 78.12%] [G loss: 1.094725]\n",
      "epoch:15 step:14991 [D loss: 0.381899, acc.: 80.47%] [G loss: 1.154092]\n",
      "epoch:15 step:14992 [D loss: 0.452149, acc.: 78.91%] [G loss: 1.333858]\n",
      "epoch:16 step:14993 [D loss: 0.585121, acc.: 71.09%] [G loss: 1.098511]\n",
      "epoch:16 step:14994 [D loss: 0.526029, acc.: 77.34%] [G loss: 1.136496]\n",
      "epoch:16 step:14995 [D loss: 0.602660, acc.: 66.41%] [G loss: 0.843028]\n",
      "epoch:16 step:14996 [D loss: 0.551095, acc.: 71.09%] [G loss: 0.999404]\n",
      "epoch:16 step:14997 [D loss: 0.557015, acc.: 68.75%] [G loss: 0.850079]\n",
      "epoch:16 step:14998 [D loss: 0.568529, acc.: 67.97%] [G loss: 0.689798]\n",
      "epoch:16 step:14999 [D loss: 0.494182, acc.: 75.00%] [G loss: 0.714812]\n",
      "epoch:16 step:15000 [D loss: 0.450983, acc.: 80.47%] [G loss: 0.643785]\n",
      "epoch:16 step:15001 [D loss: 0.496815, acc.: 81.25%] [G loss: 0.691710]\n",
      "epoch:16 step:15002 [D loss: 0.542027, acc.: 72.66%] [G loss: 0.854048]\n",
      "epoch:16 step:15003 [D loss: 0.435861, acc.: 81.25%] [G loss: 0.854788]\n",
      "epoch:16 step:15004 [D loss: 0.543198, acc.: 74.22%] [G loss: 0.791189]\n",
      "epoch:16 step:15005 [D loss: 0.576944, acc.: 66.41%] [G loss: 0.678302]\n",
      "epoch:16 step:15006 [D loss: 0.554330, acc.: 73.44%] [G loss: 0.596006]\n",
      "epoch:16 step:15007 [D loss: 0.509348, acc.: 75.00%] [G loss: 0.797925]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:16 step:15008 [D loss: 0.471619, acc.: 75.00%] [G loss: 0.829685]\n",
      "epoch:16 step:15009 [D loss: 0.548766, acc.: 75.00%] [G loss: 0.760572]\n",
      "epoch:16 step:15010 [D loss: 0.556204, acc.: 73.44%] [G loss: 0.713162]\n",
      "epoch:16 step:15011 [D loss: 0.563844, acc.: 72.66%] [G loss: 0.669538]\n",
      "epoch:16 step:15012 [D loss: 0.645187, acc.: 64.06%] [G loss: 0.540330]\n",
      "epoch:16 step:15013 [D loss: 0.532864, acc.: 69.53%] [G loss: 0.631967]\n",
      "epoch:16 step:15014 [D loss: 0.449903, acc.: 75.78%] [G loss: 0.922184]\n",
      "epoch:16 step:15015 [D loss: 0.551146, acc.: 70.31%] [G loss: 0.738064]\n",
      "epoch:16 step:15016 [D loss: 0.512056, acc.: 73.44%] [G loss: 0.582467]\n",
      "epoch:16 step:15017 [D loss: 0.475534, acc.: 77.34%] [G loss: 0.618952]\n",
      "epoch:16 step:15018 [D loss: 0.595385, acc.: 64.06%] [G loss: 0.552524]\n",
      "epoch:16 step:15019 [D loss: 0.430706, acc.: 78.12%] [G loss: 0.662033]\n",
      "epoch:16 step:15020 [D loss: 0.539818, acc.: 67.19%] [G loss: 0.801445]\n",
      "epoch:16 step:15021 [D loss: 0.514948, acc.: 73.44%] [G loss: 0.664899]\n",
      "epoch:16 step:15022 [D loss: 0.547415, acc.: 69.53%] [G loss: 0.543081]\n",
      "epoch:16 step:15023 [D loss: 0.604451, acc.: 66.41%] [G loss: 0.543628]\n",
      "epoch:16 step:15024 [D loss: 0.538010, acc.: 70.31%] [G loss: 0.777887]\n",
      "epoch:16 step:15025 [D loss: 0.530188, acc.: 67.97%] [G loss: 0.676710]\n",
      "epoch:16 step:15026 [D loss: 0.503284, acc.: 70.31%] [G loss: 0.661353]\n",
      "epoch:16 step:15027 [D loss: 0.525695, acc.: 78.12%] [G loss: 0.666983]\n",
      "epoch:16 step:15028 [D loss: 0.528583, acc.: 71.09%] [G loss: 0.575676]\n",
      "epoch:16 step:15029 [D loss: 0.507736, acc.: 75.00%] [G loss: 0.764242]\n",
      "epoch:16 step:15030 [D loss: 0.557745, acc.: 71.88%] [G loss: 0.557888]\n",
      "epoch:16 step:15031 [D loss: 0.576137, acc.: 65.62%] [G loss: 0.519902]\n",
      "epoch:16 step:15032 [D loss: 0.439921, acc.: 81.25%] [G loss: 0.702933]\n",
      "epoch:16 step:15033 [D loss: 0.562363, acc.: 67.97%] [G loss: 0.724220]\n",
      "epoch:16 step:15034 [D loss: 0.515523, acc.: 71.88%] [G loss: 0.672177]\n",
      "epoch:16 step:15035 [D loss: 0.513583, acc.: 74.22%] [G loss: 0.549530]\n",
      "epoch:16 step:15036 [D loss: 0.599145, acc.: 64.84%] [G loss: 0.689312]\n",
      "epoch:16 step:15037 [D loss: 0.490357, acc.: 76.56%] [G loss: 0.643821]\n",
      "epoch:16 step:15038 [D loss: 0.493960, acc.: 73.44%] [G loss: 0.737693]\n",
      "epoch:16 step:15039 [D loss: 0.550891, acc.: 67.19%] [G loss: 0.737804]\n",
      "epoch:16 step:15040 [D loss: 0.509735, acc.: 75.00%] [G loss: 0.654724]\n",
      "epoch:16 step:15041 [D loss: 0.504424, acc.: 71.09%] [G loss: 0.658247]\n",
      "epoch:16 step:15042 [D loss: 0.521853, acc.: 72.66%] [G loss: 0.640029]\n",
      "epoch:16 step:15043 [D loss: 0.647366, acc.: 63.28%] [G loss: 0.490910]\n",
      "epoch:16 step:15044 [D loss: 0.552791, acc.: 68.75%] [G loss: 0.625926]\n",
      "epoch:16 step:15045 [D loss: 0.497920, acc.: 76.56%] [G loss: 0.580706]\n",
      "epoch:16 step:15046 [D loss: 0.486453, acc.: 73.44%] [G loss: 0.921332]\n",
      "epoch:16 step:15047 [D loss: 0.554109, acc.: 74.22%] [G loss: 0.701485]\n",
      "epoch:16 step:15048 [D loss: 0.524487, acc.: 73.44%] [G loss: 0.910894]\n",
      "epoch:16 step:15049 [D loss: 0.530827, acc.: 76.56%] [G loss: 0.755828]\n",
      "epoch:16 step:15050 [D loss: 0.562080, acc.: 71.09%] [G loss: 0.694825]\n",
      "epoch:16 step:15051 [D loss: 0.459375, acc.: 78.12%] [G loss: 0.716816]\n",
      "epoch:16 step:15052 [D loss: 0.579644, acc.: 66.41%] [G loss: 0.650781]\n",
      "epoch:16 step:15053 [D loss: 0.529348, acc.: 68.75%] [G loss: 0.769270]\n",
      "epoch:16 step:15054 [D loss: 0.556845, acc.: 71.88%] [G loss: 0.591733]\n",
      "epoch:16 step:15055 [D loss: 0.550291, acc.: 69.53%] [G loss: 0.570262]\n",
      "epoch:16 step:15056 [D loss: 0.550828, acc.: 68.75%] [G loss: 0.594010]\n",
      "epoch:16 step:15057 [D loss: 0.497535, acc.: 73.44%] [G loss: 0.490044]\n",
      "epoch:16 step:15058 [D loss: 0.562676, acc.: 71.09%] [G loss: 0.667369]\n",
      "epoch:16 step:15059 [D loss: 0.510044, acc.: 73.44%] [G loss: 0.602552]\n",
      "epoch:16 step:15060 [D loss: 0.528647, acc.: 72.66%] [G loss: 0.633126]\n",
      "epoch:16 step:15061 [D loss: 0.478408, acc.: 78.12%] [G loss: 0.732016]\n",
      "epoch:16 step:15062 [D loss: 0.566411, acc.: 66.41%] [G loss: 0.685343]\n",
      "epoch:16 step:15063 [D loss: 0.492384, acc.: 75.00%] [G loss: 0.674075]\n",
      "epoch:16 step:15064 [D loss: 0.523083, acc.: 74.22%] [G loss: 0.626274]\n",
      "epoch:16 step:15065 [D loss: 0.539032, acc.: 71.09%] [G loss: 0.697070]\n",
      "epoch:16 step:15066 [D loss: 0.452394, acc.: 79.69%] [G loss: 0.594796]\n",
      "epoch:16 step:15067 [D loss: 0.538627, acc.: 69.53%] [G loss: 0.779558]\n",
      "epoch:16 step:15068 [D loss: 0.497483, acc.: 70.31%] [G loss: 0.762325]\n",
      "epoch:16 step:15069 [D loss: 0.473956, acc.: 75.00%] [G loss: 0.770496]\n",
      "epoch:16 step:15070 [D loss: 0.558130, acc.: 75.00%] [G loss: 0.750280]\n",
      "epoch:16 step:15071 [D loss: 0.556862, acc.: 70.31%] [G loss: 0.734462]\n",
      "epoch:16 step:15072 [D loss: 0.468863, acc.: 78.91%] [G loss: 0.756204]\n",
      "epoch:16 step:15073 [D loss: 0.496147, acc.: 77.34%] [G loss: 0.659621]\n",
      "epoch:16 step:15074 [D loss: 0.497532, acc.: 70.31%] [G loss: 0.568438]\n",
      "epoch:16 step:15075 [D loss: 0.524670, acc.: 73.44%] [G loss: 0.700332]\n",
      "epoch:16 step:15076 [D loss: 0.487689, acc.: 70.31%] [G loss: 0.734365]\n",
      "epoch:16 step:15077 [D loss: 0.608074, acc.: 68.75%] [G loss: 0.497269]\n",
      "epoch:16 step:15078 [D loss: 0.539746, acc.: 68.75%] [G loss: 0.563808]\n",
      "epoch:16 step:15079 [D loss: 0.501749, acc.: 73.44%] [G loss: 0.695991]\n",
      "epoch:16 step:15080 [D loss: 0.519404, acc.: 70.31%] [G loss: 0.775512]\n",
      "epoch:16 step:15081 [D loss: 0.510648, acc.: 72.66%] [G loss: 0.688874]\n",
      "epoch:16 step:15082 [D loss: 0.488463, acc.: 72.66%] [G loss: 0.915597]\n",
      "epoch:16 step:15083 [D loss: 0.569470, acc.: 69.53%] [G loss: 0.747506]\n",
      "epoch:16 step:15084 [D loss: 0.430741, acc.: 77.34%] [G loss: 0.797506]\n",
      "epoch:16 step:15085 [D loss: 0.484161, acc.: 75.78%] [G loss: 0.676197]\n",
      "epoch:16 step:15086 [D loss: 0.517455, acc.: 70.31%] [G loss: 0.757616]\n",
      "epoch:16 step:15087 [D loss: 0.488896, acc.: 71.88%] [G loss: 0.934748]\n",
      "epoch:16 step:15088 [D loss: 0.534476, acc.: 75.00%] [G loss: 0.791915]\n",
      "epoch:16 step:15089 [D loss: 0.519500, acc.: 71.09%] [G loss: 0.744612]\n",
      "epoch:16 step:15090 [D loss: 0.541449, acc.: 71.09%] [G loss: 0.751320]\n",
      "epoch:16 step:15091 [D loss: 0.542046, acc.: 75.78%] [G loss: 0.724591]\n",
      "epoch:16 step:15092 [D loss: 0.463554, acc.: 79.69%] [G loss: 0.846356]\n",
      "epoch:16 step:15093 [D loss: 0.515080, acc.: 72.66%] [G loss: 0.812979]\n",
      "epoch:16 step:15094 [D loss: 0.616372, acc.: 67.19%] [G loss: 0.564299]\n",
      "epoch:16 step:15095 [D loss: 0.527618, acc.: 69.53%] [G loss: 0.662432]\n",
      "epoch:16 step:15096 [D loss: 0.480410, acc.: 79.69%] [G loss: 0.682765]\n",
      "epoch:16 step:15097 [D loss: 0.628834, acc.: 61.72%] [G loss: 0.576869]\n",
      "epoch:16 step:15098 [D loss: 0.543533, acc.: 65.62%] [G loss: 0.585359]\n",
      "epoch:16 step:15099 [D loss: 0.616554, acc.: 62.50%] [G loss: 0.808789]\n",
      "epoch:16 step:15100 [D loss: 0.580403, acc.: 70.31%] [G loss: 0.682463]\n",
      "epoch:16 step:15101 [D loss: 0.569217, acc.: 73.44%] [G loss: 0.730307]\n",
      "epoch:16 step:15102 [D loss: 0.552116, acc.: 71.88%] [G loss: 0.585674]\n",
      "epoch:16 step:15103 [D loss: 0.514229, acc.: 68.75%] [G loss: 0.488970]\n",
      "epoch:16 step:15104 [D loss: 0.527875, acc.: 73.44%] [G loss: 0.587022]\n",
      "epoch:16 step:15105 [D loss: 0.514596, acc.: 77.34%] [G loss: 0.565589]\n",
      "epoch:16 step:15106 [D loss: 0.547062, acc.: 67.97%] [G loss: 0.687610]\n",
      "epoch:16 step:15107 [D loss: 0.529985, acc.: 73.44%] [G loss: 0.655227]\n",
      "epoch:16 step:15108 [D loss: 0.447415, acc.: 82.81%] [G loss: 0.731516]\n",
      "epoch:16 step:15109 [D loss: 0.550567, acc.: 67.19%] [G loss: 0.865375]\n",
      "epoch:16 step:15110 [D loss: 0.550971, acc.: 67.97%] [G loss: 0.676921]\n",
      "epoch:16 step:15111 [D loss: 0.478908, acc.: 78.12%] [G loss: 1.059143]\n",
      "epoch:16 step:15112 [D loss: 0.604695, acc.: 69.53%] [G loss: 0.814830]\n",
      "epoch:16 step:15113 [D loss: 0.533002, acc.: 70.31%] [G loss: 0.716850]\n",
      "epoch:16 step:15114 [D loss: 0.503345, acc.: 78.91%] [G loss: 0.766273]\n",
      "epoch:16 step:15115 [D loss: 0.491082, acc.: 78.91%] [G loss: 0.969589]\n",
      "epoch:16 step:15116 [D loss: 0.544800, acc.: 71.88%] [G loss: 0.808168]\n",
      "epoch:16 step:15117 [D loss: 0.534833, acc.: 70.31%] [G loss: 0.691585]\n",
      "epoch:16 step:15118 [D loss: 0.493244, acc.: 74.22%] [G loss: 0.645328]\n",
      "epoch:16 step:15119 [D loss: 0.490976, acc.: 75.00%] [G loss: 0.706409]\n",
      "epoch:16 step:15120 [D loss: 0.493457, acc.: 74.22%] [G loss: 0.530458]\n",
      "epoch:16 step:15121 [D loss: 0.524256, acc.: 73.44%] [G loss: 0.667677]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:16 step:15122 [D loss: 0.490306, acc.: 71.09%] [G loss: 0.658287]\n",
      "epoch:16 step:15123 [D loss: 0.477065, acc.: 77.34%] [G loss: 0.761372]\n",
      "epoch:16 step:15124 [D loss: 0.558926, acc.: 71.88%] [G loss: 0.612418]\n",
      "epoch:16 step:15125 [D loss: 0.617915, acc.: 64.84%] [G loss: 0.683244]\n",
      "epoch:16 step:15126 [D loss: 0.570925, acc.: 66.41%] [G loss: 0.649287]\n",
      "epoch:16 step:15127 [D loss: 0.478645, acc.: 78.91%] [G loss: 0.633115]\n",
      "epoch:16 step:15128 [D loss: 0.546077, acc.: 75.00%] [G loss: 0.764828]\n",
      "epoch:16 step:15129 [D loss: 0.641521, acc.: 67.97%] [G loss: 0.742294]\n",
      "epoch:16 step:15130 [D loss: 0.547616, acc.: 69.53%] [G loss: 0.600662]\n",
      "epoch:16 step:15131 [D loss: 0.550950, acc.: 64.84%] [G loss: 0.594574]\n",
      "epoch:16 step:15132 [D loss: 0.560417, acc.: 66.41%] [G loss: 0.734376]\n",
      "epoch:16 step:15133 [D loss: 0.522014, acc.: 71.88%] [G loss: 0.653271]\n",
      "epoch:16 step:15134 [D loss: 0.549150, acc.: 67.19%] [G loss: 0.539621]\n",
      "epoch:16 step:15135 [D loss: 0.587986, acc.: 64.06%] [G loss: 0.602992]\n",
      "epoch:16 step:15136 [D loss: 0.488898, acc.: 75.00%] [G loss: 0.649110]\n",
      "epoch:16 step:15137 [D loss: 0.587551, acc.: 60.94%] [G loss: 0.775884]\n",
      "epoch:16 step:15138 [D loss: 0.480213, acc.: 78.12%] [G loss: 0.674978]\n",
      "epoch:16 step:15139 [D loss: 0.620138, acc.: 67.19%] [G loss: 0.588818]\n",
      "epoch:16 step:15140 [D loss: 0.583711, acc.: 65.62%] [G loss: 0.533965]\n",
      "epoch:16 step:15141 [D loss: 0.550581, acc.: 70.31%] [G loss: 0.650076]\n",
      "epoch:16 step:15142 [D loss: 0.559178, acc.: 67.97%] [G loss: 0.580456]\n",
      "epoch:16 step:15143 [D loss: 0.569368, acc.: 66.41%] [G loss: 0.713102]\n",
      "epoch:16 step:15144 [D loss: 0.481763, acc.: 78.12%] [G loss: 0.706939]\n",
      "epoch:16 step:15145 [D loss: 0.548174, acc.: 70.31%] [G loss: 0.722599]\n",
      "epoch:16 step:15146 [D loss: 0.502383, acc.: 74.22%] [G loss: 0.597114]\n",
      "epoch:16 step:15147 [D loss: 0.473215, acc.: 78.12%] [G loss: 0.659261]\n",
      "epoch:16 step:15148 [D loss: 0.490404, acc.: 75.78%] [G loss: 0.977819]\n",
      "epoch:16 step:15149 [D loss: 0.556705, acc.: 68.75%] [G loss: 0.748370]\n",
      "epoch:16 step:15150 [D loss: 0.524372, acc.: 72.66%] [G loss: 0.679162]\n",
      "epoch:16 step:15151 [D loss: 0.481447, acc.: 72.66%] [G loss: 0.557192]\n",
      "epoch:16 step:15152 [D loss: 0.610921, acc.: 60.94%] [G loss: 0.675491]\n",
      "epoch:16 step:15153 [D loss: 0.521384, acc.: 73.44%] [G loss: 0.684428]\n",
      "epoch:16 step:15154 [D loss: 0.510053, acc.: 71.09%] [G loss: 0.627882]\n",
      "epoch:16 step:15155 [D loss: 0.513260, acc.: 71.09%] [G loss: 0.746975]\n",
      "epoch:16 step:15156 [D loss: 0.526673, acc.: 66.41%] [G loss: 0.665832]\n",
      "epoch:16 step:15157 [D loss: 0.516655, acc.: 71.88%] [G loss: 0.591369]\n",
      "epoch:16 step:15158 [D loss: 0.555667, acc.: 68.75%] [G loss: 0.622785]\n",
      "epoch:16 step:15159 [D loss: 0.557324, acc.: 67.97%] [G loss: 0.598415]\n",
      "epoch:16 step:15160 [D loss: 0.547710, acc.: 75.00%] [G loss: 0.595217]\n",
      "epoch:16 step:15161 [D loss: 0.650680, acc.: 64.84%] [G loss: 0.421541]\n",
      "epoch:16 step:15162 [D loss: 0.521420, acc.: 72.66%] [G loss: 0.695540]\n",
      "epoch:16 step:15163 [D loss: 0.521094, acc.: 75.00%] [G loss: 0.542384]\n",
      "epoch:16 step:15164 [D loss: 0.584211, acc.: 62.50%] [G loss: 0.475234]\n",
      "epoch:16 step:15165 [D loss: 0.487782, acc.: 75.78%] [G loss: 0.646506]\n",
      "epoch:16 step:15166 [D loss: 0.582289, acc.: 63.28%] [G loss: 0.561954]\n",
      "epoch:16 step:15167 [D loss: 0.573244, acc.: 63.28%] [G loss: 0.615491]\n",
      "epoch:16 step:15168 [D loss: 0.549594, acc.: 69.53%] [G loss: 0.563269]\n",
      "epoch:16 step:15169 [D loss: 0.475431, acc.: 76.56%] [G loss: 0.617250]\n",
      "epoch:16 step:15170 [D loss: 0.538365, acc.: 68.75%] [G loss: 0.512061]\n",
      "epoch:16 step:15171 [D loss: 0.533569, acc.: 71.09%] [G loss: 0.573741]\n",
      "epoch:16 step:15172 [D loss: 0.637634, acc.: 61.72%] [G loss: 0.472541]\n",
      "epoch:16 step:15173 [D loss: 0.498479, acc.: 77.34%] [G loss: 0.579455]\n",
      "epoch:16 step:15174 [D loss: 0.502191, acc.: 74.22%] [G loss: 0.694523]\n",
      "epoch:16 step:15175 [D loss: 0.475571, acc.: 78.91%] [G loss: 0.735950]\n",
      "epoch:16 step:15176 [D loss: 0.524401, acc.: 71.09%] [G loss: 0.700315]\n",
      "epoch:16 step:15177 [D loss: 0.555085, acc.: 67.19%] [G loss: 0.598709]\n",
      "epoch:16 step:15178 [D loss: 0.510187, acc.: 73.44%] [G loss: 0.782093]\n",
      "epoch:16 step:15179 [D loss: 0.607352, acc.: 66.41%] [G loss: 0.569171]\n",
      "epoch:16 step:15180 [D loss: 0.542523, acc.: 66.41%] [G loss: 0.496550]\n",
      "epoch:16 step:15181 [D loss: 0.569511, acc.: 70.31%] [G loss: 0.468592]\n",
      "epoch:16 step:15182 [D loss: 0.493503, acc.: 77.34%] [G loss: 0.510427]\n",
      "epoch:16 step:15183 [D loss: 0.490447, acc.: 74.22%] [G loss: 0.691868]\n",
      "epoch:16 step:15184 [D loss: 0.528810, acc.: 75.00%] [G loss: 0.590673]\n",
      "epoch:16 step:15185 [D loss: 0.562964, acc.: 70.31%] [G loss: 0.612264]\n",
      "epoch:16 step:15186 [D loss: 0.453568, acc.: 78.91%] [G loss: 0.610987]\n",
      "epoch:16 step:15187 [D loss: 0.580674, acc.: 70.31%] [G loss: 0.621087]\n",
      "epoch:16 step:15188 [D loss: 0.572633, acc.: 68.75%] [G loss: 0.536791]\n",
      "epoch:16 step:15189 [D loss: 0.523029, acc.: 69.53%] [G loss: 0.625901]\n",
      "epoch:16 step:15190 [D loss: 0.457055, acc.: 77.34%] [G loss: 0.719709]\n",
      "epoch:16 step:15191 [D loss: 0.530320, acc.: 69.53%] [G loss: 0.747251]\n",
      "epoch:16 step:15192 [D loss: 0.613634, acc.: 67.97%] [G loss: 0.711306]\n",
      "epoch:16 step:15193 [D loss: 0.593557, acc.: 69.53%] [G loss: 0.601359]\n",
      "epoch:16 step:15194 [D loss: 0.541837, acc.: 71.09%] [G loss: 0.628039]\n",
      "epoch:16 step:15195 [D loss: 0.565700, acc.: 69.53%] [G loss: 0.526394]\n",
      "epoch:16 step:15196 [D loss: 0.545059, acc.: 71.09%] [G loss: 0.539513]\n",
      "epoch:16 step:15197 [D loss: 0.462298, acc.: 77.34%] [G loss: 0.632698]\n",
      "epoch:16 step:15198 [D loss: 0.523657, acc.: 74.22%] [G loss: 0.638353]\n",
      "epoch:16 step:15199 [D loss: 0.510505, acc.: 74.22%] [G loss: 0.720554]\n",
      "epoch:16 step:15200 [D loss: 0.419535, acc.: 77.34%] [G loss: 0.946037]\n",
      "epoch:16 step:15201 [D loss: 0.481769, acc.: 78.91%] [G loss: 0.742033]\n",
      "epoch:16 step:15202 [D loss: 0.589691, acc.: 69.53%] [G loss: 0.661996]\n",
      "epoch:16 step:15203 [D loss: 0.565717, acc.: 65.62%] [G loss: 0.489157]\n",
      "epoch:16 step:15204 [D loss: 0.501454, acc.: 76.56%] [G loss: 0.523293]\n",
      "epoch:16 step:15205 [D loss: 0.496247, acc.: 78.12%] [G loss: 0.717618]\n",
      "epoch:16 step:15206 [D loss: 0.659075, acc.: 62.50%] [G loss: 0.558664]\n",
      "epoch:16 step:15207 [D loss: 0.611261, acc.: 61.72%] [G loss: 0.640513]\n",
      "epoch:16 step:15208 [D loss: 0.553429, acc.: 65.62%] [G loss: 0.614770]\n",
      "epoch:16 step:15209 [D loss: 0.548761, acc.: 70.31%] [G loss: 0.821355]\n",
      "epoch:16 step:15210 [D loss: 0.540472, acc.: 70.31%] [G loss: 0.637485]\n",
      "epoch:16 step:15211 [D loss: 0.487725, acc.: 77.34%] [G loss: 0.738216]\n",
      "epoch:16 step:15212 [D loss: 0.678700, acc.: 61.72%] [G loss: 0.574120]\n",
      "epoch:16 step:15213 [D loss: 0.493285, acc.: 76.56%] [G loss: 0.673199]\n",
      "epoch:16 step:15214 [D loss: 0.487737, acc.: 74.22%] [G loss: 0.677307]\n",
      "epoch:16 step:15215 [D loss: 0.478183, acc.: 74.22%] [G loss: 0.733760]\n",
      "epoch:16 step:15216 [D loss: 0.504588, acc.: 70.31%] [G loss: 0.657826]\n",
      "epoch:16 step:15217 [D loss: 0.496026, acc.: 76.56%] [G loss: 0.644571]\n",
      "epoch:16 step:15218 [D loss: 0.580237, acc.: 69.53%] [G loss: 0.589584]\n",
      "epoch:16 step:15219 [D loss: 0.534946, acc.: 72.66%] [G loss: 0.677709]\n",
      "epoch:16 step:15220 [D loss: 0.545958, acc.: 71.88%] [G loss: 0.661669]\n",
      "epoch:16 step:15221 [D loss: 0.514058, acc.: 70.31%] [G loss: 0.754618]\n",
      "epoch:16 step:15222 [D loss: 0.468113, acc.: 80.47%] [G loss: 0.817295]\n",
      "epoch:16 step:15223 [D loss: 0.395779, acc.: 84.38%] [G loss: 0.785692]\n",
      "epoch:16 step:15224 [D loss: 0.467683, acc.: 78.91%] [G loss: 0.717090]\n",
      "epoch:16 step:15225 [D loss: 0.537472, acc.: 71.09%] [G loss: 0.828517]\n",
      "epoch:16 step:15226 [D loss: 0.543955, acc.: 71.88%] [G loss: 0.727607]\n",
      "epoch:16 step:15227 [D loss: 0.546117, acc.: 71.09%] [G loss: 0.708983]\n",
      "epoch:16 step:15228 [D loss: 0.548704, acc.: 72.66%] [G loss: 0.700261]\n",
      "epoch:16 step:15229 [D loss: 0.509228, acc.: 69.53%] [G loss: 0.622816]\n",
      "epoch:16 step:15230 [D loss: 0.588791, acc.: 66.41%] [G loss: 0.619176]\n",
      "epoch:16 step:15231 [D loss: 0.523879, acc.: 66.41%] [G loss: 0.500272]\n",
      "epoch:16 step:15232 [D loss: 0.494567, acc.: 77.34%] [G loss: 0.636356]\n",
      "epoch:16 step:15233 [D loss: 0.514325, acc.: 73.44%] [G loss: 0.610295]\n",
      "epoch:16 step:15234 [D loss: 0.474792, acc.: 75.78%] [G loss: 0.732929]\n",
      "epoch:16 step:15235 [D loss: 0.531176, acc.: 71.09%] [G loss: 0.824658]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:16 step:15236 [D loss: 0.474188, acc.: 82.81%] [G loss: 0.774147]\n",
      "epoch:16 step:15237 [D loss: 0.499652, acc.: 73.44%] [G loss: 0.727639]\n",
      "epoch:16 step:15238 [D loss: 0.515906, acc.: 70.31%] [G loss: 0.865396]\n",
      "epoch:16 step:15239 [D loss: 0.467978, acc.: 78.91%] [G loss: 0.943226]\n",
      "epoch:16 step:15240 [D loss: 0.468714, acc.: 76.56%] [G loss: 0.854475]\n",
      "epoch:16 step:15241 [D loss: 0.596266, acc.: 67.19%] [G loss: 0.685570]\n",
      "epoch:16 step:15242 [D loss: 0.569145, acc.: 71.09%] [G loss: 0.693577]\n",
      "epoch:16 step:15243 [D loss: 0.610852, acc.: 67.97%] [G loss: 0.620862]\n",
      "epoch:16 step:15244 [D loss: 0.529706, acc.: 71.88%] [G loss: 0.731736]\n",
      "epoch:16 step:15245 [D loss: 0.590629, acc.: 66.41%] [G loss: 0.650430]\n",
      "epoch:16 step:15246 [D loss: 0.469611, acc.: 74.22%] [G loss: 0.653869]\n",
      "epoch:16 step:15247 [D loss: 0.558406, acc.: 69.53%] [G loss: 0.660147]\n",
      "epoch:16 step:15248 [D loss: 0.546868, acc.: 68.75%] [G loss: 0.628726]\n",
      "epoch:16 step:15249 [D loss: 0.560214, acc.: 69.53%] [G loss: 0.694003]\n",
      "epoch:16 step:15250 [D loss: 0.546034, acc.: 67.97%] [G loss: 0.608303]\n",
      "epoch:16 step:15251 [D loss: 0.487165, acc.: 78.12%] [G loss: 0.628052]\n",
      "epoch:16 step:15252 [D loss: 0.565914, acc.: 71.09%] [G loss: 0.641602]\n",
      "epoch:16 step:15253 [D loss: 0.503750, acc.: 72.66%] [G loss: 0.716829]\n",
      "epoch:16 step:15254 [D loss: 0.523582, acc.: 71.88%] [G loss: 0.691407]\n",
      "epoch:16 step:15255 [D loss: 0.566319, acc.: 71.09%] [G loss: 0.606019]\n",
      "epoch:16 step:15256 [D loss: 0.529971, acc.: 73.44%] [G loss: 0.616590]\n",
      "epoch:16 step:15257 [D loss: 0.546667, acc.: 71.09%] [G loss: 0.616037]\n",
      "epoch:16 step:15258 [D loss: 0.534982, acc.: 70.31%] [G loss: 0.571206]\n",
      "epoch:16 step:15259 [D loss: 0.517648, acc.: 74.22%] [G loss: 0.575673]\n",
      "epoch:16 step:15260 [D loss: 0.559974, acc.: 70.31%] [G loss: 0.662785]\n",
      "epoch:16 step:15261 [D loss: 0.545515, acc.: 69.53%] [G loss: 0.680732]\n",
      "epoch:16 step:15262 [D loss: 0.487813, acc.: 72.66%] [G loss: 0.556342]\n",
      "epoch:16 step:15263 [D loss: 0.458697, acc.: 79.69%] [G loss: 0.806903]\n",
      "epoch:16 step:15264 [D loss: 0.558987, acc.: 71.09%] [G loss: 0.757435]\n",
      "epoch:16 step:15265 [D loss: 0.447784, acc.: 78.91%] [G loss: 0.765772]\n",
      "epoch:16 step:15266 [D loss: 0.575555, acc.: 70.31%] [G loss: 0.599123]\n",
      "epoch:16 step:15267 [D loss: 0.538800, acc.: 68.75%] [G loss: 0.651712]\n",
      "epoch:16 step:15268 [D loss: 0.452306, acc.: 82.81%] [G loss: 0.588901]\n",
      "epoch:16 step:15269 [D loss: 0.650621, acc.: 65.62%] [G loss: 0.471259]\n",
      "epoch:16 step:15270 [D loss: 0.578204, acc.: 67.19%] [G loss: 0.447738]\n",
      "epoch:16 step:15271 [D loss: 0.541729, acc.: 66.41%] [G loss: 0.491139]\n",
      "epoch:16 step:15272 [D loss: 0.580176, acc.: 72.66%] [G loss: 0.638492]\n",
      "epoch:16 step:15273 [D loss: 0.553453, acc.: 71.09%] [G loss: 0.573230]\n",
      "epoch:16 step:15274 [D loss: 0.583210, acc.: 67.19%] [G loss: 0.511747]\n",
      "epoch:16 step:15275 [D loss: 0.491413, acc.: 80.47%] [G loss: 0.650605]\n",
      "epoch:16 step:15276 [D loss: 0.530756, acc.: 72.66%] [G loss: 0.520641]\n",
      "epoch:16 step:15277 [D loss: 0.511557, acc.: 70.31%] [G loss: 0.693478]\n",
      "epoch:16 step:15278 [D loss: 0.523665, acc.: 69.53%] [G loss: 0.672405]\n",
      "epoch:16 step:15279 [D loss: 0.558981, acc.: 71.09%] [G loss: 0.552011]\n",
      "epoch:16 step:15280 [D loss: 0.553382, acc.: 67.19%] [G loss: 0.648341]\n",
      "epoch:16 step:15281 [D loss: 0.518498, acc.: 75.78%] [G loss: 0.692575]\n",
      "epoch:16 step:15282 [D loss: 0.559142, acc.: 71.09%] [G loss: 0.644191]\n",
      "epoch:16 step:15283 [D loss: 0.551301, acc.: 68.75%] [G loss: 0.496223]\n",
      "epoch:16 step:15284 [D loss: 0.518205, acc.: 74.22%] [G loss: 0.602767]\n",
      "epoch:16 step:15285 [D loss: 0.540268, acc.: 67.19%] [G loss: 0.662213]\n",
      "epoch:16 step:15286 [D loss: 0.622679, acc.: 60.94%] [G loss: 0.500837]\n",
      "epoch:16 step:15287 [D loss: 0.543366, acc.: 71.88%] [G loss: 0.496096]\n",
      "epoch:16 step:15288 [D loss: 0.414812, acc.: 84.38%] [G loss: 0.630786]\n",
      "epoch:16 step:15289 [D loss: 0.514485, acc.: 71.09%] [G loss: 0.635994]\n",
      "epoch:16 step:15290 [D loss: 0.502487, acc.: 74.22%] [G loss: 0.750994]\n",
      "epoch:16 step:15291 [D loss: 0.491142, acc.: 71.88%] [G loss: 0.780239]\n",
      "epoch:16 step:15292 [D loss: 0.461227, acc.: 79.69%] [G loss: 0.839523]\n",
      "epoch:16 step:15293 [D loss: 0.610834, acc.: 67.19%] [G loss: 0.714494]\n",
      "epoch:16 step:15294 [D loss: 0.499829, acc.: 71.88%] [G loss: 0.734779]\n",
      "epoch:16 step:15295 [D loss: 0.579675, acc.: 67.97%] [G loss: 0.798991]\n",
      "epoch:16 step:15296 [D loss: 0.496668, acc.: 73.44%] [G loss: 0.804956]\n",
      "epoch:16 step:15297 [D loss: 0.590718, acc.: 67.19%] [G loss: 0.598783]\n",
      "epoch:16 step:15298 [D loss: 0.513846, acc.: 70.31%] [G loss: 0.528410]\n",
      "epoch:16 step:15299 [D loss: 0.538498, acc.: 72.66%] [G loss: 0.643010]\n",
      "epoch:16 step:15300 [D loss: 0.587129, acc.: 64.06%] [G loss: 0.646303]\n",
      "epoch:16 step:15301 [D loss: 0.466836, acc.: 76.56%] [G loss: 0.671154]\n",
      "epoch:16 step:15302 [D loss: 0.544660, acc.: 73.44%] [G loss: 0.612125]\n",
      "epoch:16 step:15303 [D loss: 0.457150, acc.: 76.56%] [G loss: 0.584266]\n",
      "epoch:16 step:15304 [D loss: 0.477203, acc.: 75.78%] [G loss: 0.864749]\n",
      "epoch:16 step:15305 [D loss: 0.465592, acc.: 77.34%] [G loss: 0.955512]\n",
      "epoch:16 step:15306 [D loss: 0.420845, acc.: 82.03%] [G loss: 0.959646]\n",
      "epoch:16 step:15307 [D loss: 0.474943, acc.: 73.44%] [G loss: 1.055810]\n",
      "epoch:16 step:15308 [D loss: 0.619610, acc.: 67.97%] [G loss: 0.743764]\n",
      "epoch:16 step:15309 [D loss: 0.592699, acc.: 65.62%] [G loss: 0.588844]\n",
      "epoch:16 step:15310 [D loss: 0.542915, acc.: 73.44%] [G loss: 0.776021]\n",
      "epoch:16 step:15311 [D loss: 0.544202, acc.: 68.75%] [G loss: 0.554291]\n",
      "epoch:16 step:15312 [D loss: 0.567241, acc.: 61.72%] [G loss: 0.505984]\n",
      "epoch:16 step:15313 [D loss: 0.497428, acc.: 71.09%] [G loss: 0.656222]\n",
      "epoch:16 step:15314 [D loss: 0.550262, acc.: 71.88%] [G loss: 0.753344]\n",
      "epoch:16 step:15315 [D loss: 0.571277, acc.: 67.97%] [G loss: 0.589997]\n",
      "epoch:16 step:15316 [D loss: 0.543060, acc.: 73.44%] [G loss: 0.499906]\n",
      "epoch:16 step:15317 [D loss: 0.509567, acc.: 66.41%] [G loss: 0.516401]\n",
      "epoch:16 step:15318 [D loss: 0.467041, acc.: 75.78%] [G loss: 0.569207]\n",
      "epoch:16 step:15319 [D loss: 0.522794, acc.: 77.34%] [G loss: 0.679992]\n",
      "epoch:16 step:15320 [D loss: 0.402696, acc.: 82.03%] [G loss: 0.883308]\n",
      "epoch:16 step:15321 [D loss: 0.519983, acc.: 73.44%] [G loss: 0.813178]\n",
      "epoch:16 step:15322 [D loss: 0.556899, acc.: 71.88%] [G loss: 0.630534]\n",
      "epoch:16 step:15323 [D loss: 0.565476, acc.: 70.31%] [G loss: 0.604422]\n",
      "epoch:16 step:15324 [D loss: 0.512768, acc.: 75.00%] [G loss: 0.562630]\n",
      "epoch:16 step:15325 [D loss: 0.482913, acc.: 73.44%] [G loss: 0.768203]\n",
      "epoch:16 step:15326 [D loss: 0.473009, acc.: 78.91%] [G loss: 0.730039]\n",
      "epoch:16 step:15327 [D loss: 0.436940, acc.: 78.91%] [G loss: 0.951530]\n",
      "epoch:16 step:15328 [D loss: 0.500971, acc.: 72.66%] [G loss: 0.748641]\n",
      "epoch:16 step:15329 [D loss: 0.504386, acc.: 75.00%] [G loss: 0.915181]\n",
      "epoch:16 step:15330 [D loss: 0.535880, acc.: 71.88%] [G loss: 0.626960]\n",
      "epoch:16 step:15331 [D loss: 0.565787, acc.: 64.06%] [G loss: 0.542006]\n",
      "epoch:16 step:15332 [D loss: 0.456713, acc.: 76.56%] [G loss: 0.802317]\n",
      "epoch:16 step:15333 [D loss: 0.590355, acc.: 69.53%] [G loss: 0.569259]\n",
      "epoch:16 step:15334 [D loss: 0.680101, acc.: 59.38%] [G loss: 0.624801]\n",
      "epoch:16 step:15335 [D loss: 0.554480, acc.: 67.97%] [G loss: 0.760164]\n",
      "epoch:16 step:15336 [D loss: 0.489624, acc.: 75.00%] [G loss: 0.837931]\n",
      "epoch:16 step:15337 [D loss: 0.621266, acc.: 65.62%] [G loss: 0.661162]\n",
      "epoch:16 step:15338 [D loss: 0.507168, acc.: 74.22%] [G loss: 0.703889]\n",
      "epoch:16 step:15339 [D loss: 0.452823, acc.: 76.56%] [G loss: 0.966394]\n",
      "epoch:16 step:15340 [D loss: 0.648551, acc.: 61.72%] [G loss: 0.656119]\n",
      "epoch:16 step:15341 [D loss: 0.660733, acc.: 58.59%] [G loss: 0.469006]\n",
      "epoch:16 step:15342 [D loss: 0.496920, acc.: 73.44%] [G loss: 0.591905]\n",
      "epoch:16 step:15343 [D loss: 0.527710, acc.: 76.56%] [G loss: 0.770855]\n",
      "epoch:16 step:15344 [D loss: 0.572409, acc.: 66.41%] [G loss: 0.714445]\n",
      "epoch:16 step:15345 [D loss: 0.549953, acc.: 67.97%] [G loss: 0.649729]\n",
      "epoch:16 step:15346 [D loss: 0.379917, acc.: 82.03%] [G loss: 0.813137]\n",
      "epoch:16 step:15347 [D loss: 0.492075, acc.: 75.00%] [G loss: 0.906566]\n",
      "epoch:16 step:15348 [D loss: 0.581174, acc.: 67.97%] [G loss: 0.757302]\n",
      "epoch:16 step:15349 [D loss: 0.462804, acc.: 78.12%] [G loss: 0.750886]\n",
      "epoch:16 step:15350 [D loss: 0.424659, acc.: 81.25%] [G loss: 0.942303]\n",
      "epoch:16 step:15351 [D loss: 0.474889, acc.: 78.91%] [G loss: 0.856467]\n",
      "epoch:16 step:15352 [D loss: 0.464275, acc.: 76.56%] [G loss: 0.678956]\n",
      "epoch:16 step:15353 [D loss: 0.510595, acc.: 72.66%] [G loss: 0.802131]\n",
      "epoch:16 step:15354 [D loss: 0.544400, acc.: 71.88%] [G loss: 0.652431]\n",
      "epoch:16 step:15355 [D loss: 0.572514, acc.: 69.53%] [G loss: 0.726413]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:16 step:15356 [D loss: 0.480770, acc.: 73.44%] [G loss: 0.672931]\n",
      "epoch:16 step:15357 [D loss: 0.499284, acc.: 71.09%] [G loss: 0.869546]\n",
      "epoch:16 step:15358 [D loss: 0.480990, acc.: 75.00%] [G loss: 0.673884]\n",
      "epoch:16 step:15359 [D loss: 0.545966, acc.: 66.41%] [G loss: 0.607958]\n",
      "epoch:16 step:15360 [D loss: 0.533764, acc.: 68.75%] [G loss: 0.690470]\n",
      "epoch:16 step:15361 [D loss: 0.526822, acc.: 71.09%] [G loss: 0.623388]\n",
      "epoch:16 step:15362 [D loss: 0.514868, acc.: 72.66%] [G loss: 0.779484]\n",
      "epoch:16 step:15363 [D loss: 0.520150, acc.: 75.78%] [G loss: 0.689164]\n",
      "epoch:16 step:15364 [D loss: 0.595901, acc.: 67.97%] [G loss: 0.640564]\n",
      "epoch:16 step:15365 [D loss: 0.516210, acc.: 72.66%] [G loss: 0.687188]\n",
      "epoch:16 step:15366 [D loss: 0.444817, acc.: 79.69%] [G loss: 0.778414]\n",
      "epoch:16 step:15367 [D loss: 0.552835, acc.: 69.53%] [G loss: 0.749528]\n",
      "epoch:16 step:15368 [D loss: 0.707051, acc.: 59.38%] [G loss: 0.397487]\n",
      "epoch:16 step:15369 [D loss: 0.635899, acc.: 59.38%] [G loss: 0.589108]\n",
      "epoch:16 step:15370 [D loss: 0.587398, acc.: 67.97%] [G loss: 0.587482]\n",
      "epoch:16 step:15371 [D loss: 0.605507, acc.: 67.97%] [G loss: 0.519053]\n",
      "epoch:16 step:15372 [D loss: 0.563584, acc.: 70.31%] [G loss: 0.717142]\n",
      "epoch:16 step:15373 [D loss: 0.455846, acc.: 79.69%] [G loss: 0.633482]\n",
      "epoch:16 step:15374 [D loss: 0.518538, acc.: 75.00%] [G loss: 0.777170]\n",
      "epoch:16 step:15375 [D loss: 0.568464, acc.: 67.97%] [G loss: 0.491466]\n",
      "epoch:16 step:15376 [D loss: 0.550772, acc.: 74.22%] [G loss: 0.612561]\n",
      "epoch:16 step:15377 [D loss: 0.519104, acc.: 74.22%] [G loss: 0.558449]\n",
      "epoch:16 step:15378 [D loss: 0.613484, acc.: 61.72%] [G loss: 0.478026]\n",
      "epoch:16 step:15379 [D loss: 0.525571, acc.: 71.88%] [G loss: 0.546878]\n",
      "epoch:16 step:15380 [D loss: 0.530836, acc.: 71.09%] [G loss: 0.593349]\n",
      "epoch:16 step:15381 [D loss: 0.508822, acc.: 75.00%] [G loss: 0.546824]\n",
      "epoch:16 step:15382 [D loss: 0.580423, acc.: 64.06%] [G loss: 0.593678]\n",
      "epoch:16 step:15383 [D loss: 0.532820, acc.: 72.66%] [G loss: 0.574400]\n",
      "epoch:16 step:15384 [D loss: 0.473792, acc.: 76.56%] [G loss: 0.776021]\n",
      "epoch:16 step:15385 [D loss: 0.569178, acc.: 72.66%] [G loss: 0.780448]\n",
      "epoch:16 step:15386 [D loss: 0.535014, acc.: 71.88%] [G loss: 0.653206]\n",
      "epoch:16 step:15387 [D loss: 0.484155, acc.: 75.78%] [G loss: 0.680149]\n",
      "epoch:16 step:15388 [D loss: 0.607834, acc.: 64.84%] [G loss: 0.494797]\n",
      "epoch:16 step:15389 [D loss: 0.596959, acc.: 58.59%] [G loss: 0.682850]\n",
      "epoch:16 step:15390 [D loss: 0.452050, acc.: 81.25%] [G loss: 0.815189]\n",
      "epoch:16 step:15391 [D loss: 0.509358, acc.: 76.56%] [G loss: 0.549483]\n",
      "epoch:16 step:15392 [D loss: 0.616103, acc.: 65.62%] [G loss: 0.615274]\n",
      "epoch:16 step:15393 [D loss: 0.601065, acc.: 62.50%] [G loss: 0.694498]\n",
      "epoch:16 step:15394 [D loss: 0.509018, acc.: 75.00%] [G loss: 0.706327]\n",
      "epoch:16 step:15395 [D loss: 0.522852, acc.: 73.44%] [G loss: 0.554640]\n",
      "epoch:16 step:15396 [D loss: 0.548883, acc.: 71.88%] [G loss: 0.688830]\n",
      "epoch:16 step:15397 [D loss: 0.505846, acc.: 77.34%] [G loss: 0.684438]\n",
      "epoch:16 step:15398 [D loss: 0.520846, acc.: 71.88%] [G loss: 0.710069]\n",
      "epoch:16 step:15399 [D loss: 0.611262, acc.: 61.72%] [G loss: 0.813343]\n",
      "epoch:16 step:15400 [D loss: 0.606008, acc.: 66.41%] [G loss: 0.671956]\n",
      "epoch:16 step:15401 [D loss: 0.551260, acc.: 68.75%] [G loss: 0.633478]\n",
      "epoch:16 step:15402 [D loss: 0.555603, acc.: 66.41%] [G loss: 0.647681]\n",
      "epoch:16 step:15403 [D loss: 0.575435, acc.: 63.28%] [G loss: 0.624407]\n",
      "epoch:16 step:15404 [D loss: 0.569224, acc.: 67.97%] [G loss: 0.536060]\n",
      "epoch:16 step:15405 [D loss: 0.502490, acc.: 73.44%] [G loss: 0.645440]\n",
      "epoch:16 step:15406 [D loss: 0.485417, acc.: 76.56%] [G loss: 0.730212]\n",
      "epoch:16 step:15407 [D loss: 0.537789, acc.: 71.09%] [G loss: 0.676471]\n",
      "epoch:16 step:15408 [D loss: 0.501668, acc.: 78.12%] [G loss: 0.779404]\n",
      "epoch:16 step:15409 [D loss: 0.530297, acc.: 73.44%] [G loss: 0.776629]\n",
      "epoch:16 step:15410 [D loss: 0.579022, acc.: 67.19%] [G loss: 0.750869]\n",
      "epoch:16 step:15411 [D loss: 0.595367, acc.: 67.19%] [G loss: 0.614991]\n",
      "epoch:16 step:15412 [D loss: 0.584647, acc.: 62.50%] [G loss: 0.783341]\n",
      "epoch:16 step:15413 [D loss: 0.583455, acc.: 66.41%] [G loss: 0.585505]\n",
      "epoch:16 step:15414 [D loss: 0.597192, acc.: 66.41%] [G loss: 0.496670]\n",
      "epoch:16 step:15415 [D loss: 0.525972, acc.: 73.44%] [G loss: 0.569339]\n",
      "epoch:16 step:15416 [D loss: 0.585797, acc.: 68.75%] [G loss: 0.590639]\n",
      "epoch:16 step:15417 [D loss: 0.499185, acc.: 72.66%] [G loss: 0.684078]\n",
      "epoch:16 step:15418 [D loss: 0.517319, acc.: 72.66%] [G loss: 0.684454]\n",
      "epoch:16 step:15419 [D loss: 0.471590, acc.: 75.00%] [G loss: 0.764220]\n",
      "epoch:16 step:15420 [D loss: 0.494324, acc.: 71.88%] [G loss: 0.822393]\n",
      "epoch:16 step:15421 [D loss: 0.477971, acc.: 78.12%] [G loss: 0.654628]\n",
      "epoch:16 step:15422 [D loss: 0.480632, acc.: 75.78%] [G loss: 0.821267]\n",
      "epoch:16 step:15423 [D loss: 0.518850, acc.: 73.44%] [G loss: 0.876850]\n",
      "epoch:16 step:15424 [D loss: 0.533169, acc.: 69.53%] [G loss: 0.767092]\n",
      "epoch:16 step:15425 [D loss: 0.526353, acc.: 71.09%] [G loss: 0.615597]\n",
      "epoch:16 step:15426 [D loss: 0.539114, acc.: 67.19%] [G loss: 0.529897]\n",
      "epoch:16 step:15427 [D loss: 0.511242, acc.: 75.00%] [G loss: 0.711278]\n",
      "epoch:16 step:15428 [D loss: 0.480566, acc.: 75.78%] [G loss: 0.711075]\n",
      "epoch:16 step:15429 [D loss: 0.626164, acc.: 64.84%] [G loss: 0.620127]\n",
      "epoch:16 step:15430 [D loss: 0.582439, acc.: 62.50%] [G loss: 0.460018]\n",
      "epoch:16 step:15431 [D loss: 0.496233, acc.: 78.12%] [G loss: 0.575011]\n",
      "epoch:16 step:15432 [D loss: 0.489975, acc.: 75.00%] [G loss: 0.770354]\n",
      "epoch:16 step:15433 [D loss: 0.516639, acc.: 71.88%] [G loss: 0.636853]\n",
      "epoch:16 step:15434 [D loss: 0.579059, acc.: 64.06%] [G loss: 0.585087]\n",
      "epoch:16 step:15435 [D loss: 0.509758, acc.: 73.44%] [G loss: 0.785328]\n",
      "epoch:16 step:15436 [D loss: 0.544720, acc.: 70.31%] [G loss: 0.766523]\n",
      "epoch:16 step:15437 [D loss: 0.560543, acc.: 67.97%] [G loss: 0.728479]\n",
      "epoch:16 step:15438 [D loss: 0.535428, acc.: 70.31%] [G loss: 0.831846]\n",
      "epoch:16 step:15439 [D loss: 0.513342, acc.: 71.88%] [G loss: 0.666832]\n",
      "epoch:16 step:15440 [D loss: 0.530420, acc.: 75.00%] [G loss: 0.672816]\n",
      "epoch:16 step:15441 [D loss: 0.512815, acc.: 70.31%] [G loss: 0.619729]\n",
      "epoch:16 step:15442 [D loss: 0.472302, acc.: 82.81%] [G loss: 0.779542]\n",
      "epoch:16 step:15443 [D loss: 0.394406, acc.: 82.03%] [G loss: 0.794820]\n",
      "epoch:16 step:15444 [D loss: 0.512756, acc.: 75.78%] [G loss: 0.749020]\n",
      "epoch:16 step:15445 [D loss: 0.538929, acc.: 71.88%] [G loss: 0.768010]\n",
      "epoch:16 step:15446 [D loss: 0.534446, acc.: 71.88%] [G loss: 0.764816]\n",
      "epoch:16 step:15447 [D loss: 0.536921, acc.: 71.88%] [G loss: 0.737367]\n",
      "epoch:16 step:15448 [D loss: 0.612000, acc.: 63.28%] [G loss: 0.507614]\n",
      "epoch:16 step:15449 [D loss: 0.505644, acc.: 75.78%] [G loss: 0.555520]\n",
      "epoch:16 step:15450 [D loss: 0.630278, acc.: 62.50%] [G loss: 0.649445]\n",
      "epoch:16 step:15451 [D loss: 0.512131, acc.: 70.31%] [G loss: 0.643602]\n",
      "epoch:16 step:15452 [D loss: 0.498504, acc.: 71.88%] [G loss: 0.910614]\n",
      "epoch:16 step:15453 [D loss: 0.522188, acc.: 75.78%] [G loss: 0.762501]\n",
      "epoch:16 step:15454 [D loss: 0.530219, acc.: 71.09%] [G loss: 0.592311]\n",
      "epoch:16 step:15455 [D loss: 0.527540, acc.: 71.09%] [G loss: 0.617606]\n",
      "epoch:16 step:15456 [D loss: 0.507727, acc.: 70.31%] [G loss: 0.534102]\n",
      "epoch:16 step:15457 [D loss: 0.631796, acc.: 61.72%] [G loss: 0.524093]\n",
      "epoch:16 step:15458 [D loss: 0.566421, acc.: 65.62%] [G loss: 0.560778]\n",
      "epoch:16 step:15459 [D loss: 0.525684, acc.: 73.44%] [G loss: 0.611918]\n",
      "epoch:16 step:15460 [D loss: 0.544672, acc.: 70.31%] [G loss: 0.648343]\n",
      "epoch:16 step:15461 [D loss: 0.494203, acc.: 78.12%] [G loss: 0.690485]\n",
      "epoch:16 step:15462 [D loss: 0.519303, acc.: 73.44%] [G loss: 0.497067]\n",
      "epoch:16 step:15463 [D loss: 0.487848, acc.: 75.00%] [G loss: 0.639094]\n",
      "epoch:16 step:15464 [D loss: 0.433244, acc.: 86.72%] [G loss: 0.803870]\n",
      "epoch:16 step:15465 [D loss: 0.642669, acc.: 59.38%] [G loss: 0.714204]\n",
      "epoch:16 step:15466 [D loss: 0.560070, acc.: 65.62%] [G loss: 0.683640]\n",
      "epoch:16 step:15467 [D loss: 0.439052, acc.: 78.91%] [G loss: 0.916696]\n",
      "epoch:16 step:15468 [D loss: 0.521345, acc.: 76.56%] [G loss: 0.650670]\n",
      "epoch:16 step:15469 [D loss: 0.613703, acc.: 65.62%] [G loss: 0.628818]\n",
      "epoch:16 step:15470 [D loss: 0.567953, acc.: 68.75%] [G loss: 0.574333]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:16 step:15471 [D loss: 0.554718, acc.: 71.88%] [G loss: 0.538100]\n",
      "epoch:16 step:15472 [D loss: 0.583829, acc.: 67.19%] [G loss: 0.492546]\n",
      "epoch:16 step:15473 [D loss: 0.518465, acc.: 77.34%] [G loss: 0.600042]\n",
      "epoch:16 step:15474 [D loss: 0.577965, acc.: 67.19%] [G loss: 0.600479]\n",
      "epoch:16 step:15475 [D loss: 0.519989, acc.: 74.22%] [G loss: 0.680352]\n",
      "epoch:16 step:15476 [D loss: 0.536030, acc.: 71.88%] [G loss: 0.660836]\n",
      "epoch:16 step:15477 [D loss: 0.513221, acc.: 76.56%] [G loss: 0.769268]\n",
      "epoch:16 step:15478 [D loss: 0.592389, acc.: 70.31%] [G loss: 0.719816]\n",
      "epoch:16 step:15479 [D loss: 0.590808, acc.: 64.06%] [G loss: 0.521716]\n",
      "epoch:16 step:15480 [D loss: 0.501547, acc.: 75.78%] [G loss: 0.569730]\n",
      "epoch:16 step:15481 [D loss: 0.531928, acc.: 72.66%] [G loss: 0.738623]\n",
      "epoch:16 step:15482 [D loss: 0.536443, acc.: 74.22%] [G loss: 0.631631]\n",
      "epoch:16 step:15483 [D loss: 0.528696, acc.: 73.44%] [G loss: 0.610807]\n",
      "epoch:16 step:15484 [D loss: 0.551346, acc.: 72.66%] [G loss: 0.604933]\n",
      "epoch:16 step:15485 [D loss: 0.509960, acc.: 76.56%] [G loss: 0.551882]\n",
      "epoch:16 step:15486 [D loss: 0.606909, acc.: 64.84%] [G loss: 0.671054]\n",
      "epoch:16 step:15487 [D loss: 0.483937, acc.: 75.78%] [G loss: 0.701554]\n",
      "epoch:16 step:15488 [D loss: 0.517083, acc.: 75.78%] [G loss: 0.721973]\n",
      "epoch:16 step:15489 [D loss: 0.571212, acc.: 70.31%] [G loss: 0.626532]\n",
      "epoch:16 step:15490 [D loss: 0.605160, acc.: 65.62%] [G loss: 0.694341]\n",
      "epoch:16 step:15491 [D loss: 0.473568, acc.: 76.56%] [G loss: 0.846036]\n",
      "epoch:16 step:15492 [D loss: 0.608316, acc.: 64.84%] [G loss: 0.743552]\n",
      "epoch:16 step:15493 [D loss: 0.668572, acc.: 64.84%] [G loss: 0.516445]\n",
      "epoch:16 step:15494 [D loss: 0.604260, acc.: 65.62%] [G loss: 0.483066]\n",
      "epoch:16 step:15495 [D loss: 0.457437, acc.: 78.91%] [G loss: 0.628227]\n",
      "epoch:16 step:15496 [D loss: 0.487852, acc.: 76.56%] [G loss: 0.772819]\n",
      "epoch:16 step:15497 [D loss: 0.555404, acc.: 67.97%] [G loss: 0.663983]\n",
      "epoch:16 step:15498 [D loss: 0.487534, acc.: 75.78%] [G loss: 0.784787]\n",
      "epoch:16 step:15499 [D loss: 0.521282, acc.: 75.00%] [G loss: 0.681163]\n",
      "epoch:16 step:15500 [D loss: 0.463806, acc.: 78.12%] [G loss: 0.875098]\n",
      "epoch:16 step:15501 [D loss: 0.510633, acc.: 75.00%] [G loss: 0.790240]\n",
      "epoch:16 step:15502 [D loss: 0.617791, acc.: 64.84%] [G loss: 0.574836]\n",
      "epoch:16 step:15503 [D loss: 0.638216, acc.: 60.16%] [G loss: 0.505106]\n",
      "epoch:16 step:15504 [D loss: 0.546665, acc.: 70.31%] [G loss: 0.579577]\n",
      "epoch:16 step:15505 [D loss: 0.569363, acc.: 65.62%] [G loss: 0.556045]\n",
      "epoch:16 step:15506 [D loss: 0.483113, acc.: 70.31%] [G loss: 0.663655]\n",
      "epoch:16 step:15507 [D loss: 0.554536, acc.: 68.75%] [G loss: 0.633119]\n",
      "epoch:16 step:15508 [D loss: 0.470773, acc.: 77.34%] [G loss: 0.690712]\n",
      "epoch:16 step:15509 [D loss: 0.493348, acc.: 77.34%] [G loss: 0.725477]\n",
      "epoch:16 step:15510 [D loss: 0.528335, acc.: 67.97%] [G loss: 0.672772]\n",
      "epoch:16 step:15511 [D loss: 0.446638, acc.: 79.69%] [G loss: 0.697529]\n",
      "epoch:16 step:15512 [D loss: 0.476548, acc.: 74.22%] [G loss: 0.715443]\n",
      "epoch:16 step:15513 [D loss: 0.530681, acc.: 71.88%] [G loss: 0.730138]\n",
      "epoch:16 step:15514 [D loss: 0.552725, acc.: 68.75%] [G loss: 0.763584]\n",
      "epoch:16 step:15515 [D loss: 0.466361, acc.: 78.91%] [G loss: 0.775603]\n",
      "epoch:16 step:15516 [D loss: 0.546852, acc.: 70.31%] [G loss: 0.746081]\n",
      "epoch:16 step:15517 [D loss: 0.592776, acc.: 66.41%] [G loss: 0.646590]\n",
      "epoch:16 step:15518 [D loss: 0.446294, acc.: 79.69%] [G loss: 0.730156]\n",
      "epoch:16 step:15519 [D loss: 0.566597, acc.: 67.19%] [G loss: 0.794595]\n",
      "epoch:16 step:15520 [D loss: 0.685019, acc.: 57.03%] [G loss: 0.627489]\n",
      "epoch:16 step:15521 [D loss: 0.628271, acc.: 60.94%] [G loss: 0.630442]\n",
      "epoch:16 step:15522 [D loss: 0.510444, acc.: 71.09%] [G loss: 0.616493]\n",
      "epoch:16 step:15523 [D loss: 0.538600, acc.: 67.97%] [G loss: 0.729767]\n",
      "epoch:16 step:15524 [D loss: 0.582220, acc.: 64.06%] [G loss: 0.482597]\n",
      "epoch:16 step:15525 [D loss: 0.511971, acc.: 69.53%] [G loss: 0.644371]\n",
      "epoch:16 step:15526 [D loss: 0.457595, acc.: 76.56%] [G loss: 0.692811]\n",
      "epoch:16 step:15527 [D loss: 0.592063, acc.: 64.84%] [G loss: 0.494904]\n",
      "epoch:16 step:15528 [D loss: 0.528823, acc.: 65.62%] [G loss: 0.465205]\n",
      "epoch:16 step:15529 [D loss: 0.638257, acc.: 63.28%] [G loss: 0.506950]\n",
      "epoch:16 step:15530 [D loss: 0.504661, acc.: 71.88%] [G loss: 0.591178]\n",
      "epoch:16 step:15531 [D loss: 0.518320, acc.: 70.31%] [G loss: 0.684986]\n",
      "epoch:16 step:15532 [D loss: 0.585365, acc.: 65.62%] [G loss: 0.564208]\n",
      "epoch:16 step:15533 [D loss: 0.519934, acc.: 76.56%] [G loss: 0.622592]\n",
      "epoch:16 step:15534 [D loss: 0.635127, acc.: 60.94%] [G loss: 0.524097]\n",
      "epoch:16 step:15535 [D loss: 0.545519, acc.: 67.19%] [G loss: 0.622697]\n",
      "epoch:16 step:15536 [D loss: 0.529840, acc.: 71.09%] [G loss: 0.494803]\n",
      "epoch:16 step:15537 [D loss: 0.558985, acc.: 68.75%] [G loss: 0.602646]\n",
      "epoch:16 step:15538 [D loss: 0.514988, acc.: 73.44%] [G loss: 0.633156]\n",
      "epoch:16 step:15539 [D loss: 0.527993, acc.: 74.22%] [G loss: 0.639887]\n",
      "epoch:16 step:15540 [D loss: 0.485944, acc.: 76.56%] [G loss: 0.639792]\n",
      "epoch:16 step:15541 [D loss: 0.517172, acc.: 72.66%] [G loss: 0.718444]\n",
      "epoch:16 step:15542 [D loss: 0.542460, acc.: 70.31%] [G loss: 0.744360]\n",
      "epoch:16 step:15543 [D loss: 0.467775, acc.: 78.91%] [G loss: 0.632962]\n",
      "epoch:16 step:15544 [D loss: 0.439087, acc.: 80.47%] [G loss: 0.601757]\n",
      "epoch:16 step:15545 [D loss: 0.559196, acc.: 67.97%] [G loss: 0.566480]\n",
      "epoch:16 step:15546 [D loss: 0.431627, acc.: 78.91%] [G loss: 0.779105]\n",
      "epoch:16 step:15547 [D loss: 0.523970, acc.: 71.88%] [G loss: 0.588795]\n",
      "epoch:16 step:15548 [D loss: 0.540085, acc.: 72.66%] [G loss: 0.701691]\n",
      "epoch:16 step:15549 [D loss: 0.564785, acc.: 71.88%] [G loss: 0.754206]\n",
      "epoch:16 step:15550 [D loss: 0.455825, acc.: 76.56%] [G loss: 0.894274]\n",
      "epoch:16 step:15551 [D loss: 0.604781, acc.: 62.50%] [G loss: 0.654411]\n",
      "epoch:16 step:15552 [D loss: 0.552482, acc.: 69.53%] [G loss: 0.652474]\n",
      "epoch:16 step:15553 [D loss: 0.531151, acc.: 73.44%] [G loss: 0.761314]\n",
      "epoch:16 step:15554 [D loss: 0.581668, acc.: 62.50%] [G loss: 0.633180]\n",
      "epoch:16 step:15555 [D loss: 0.559896, acc.: 70.31%] [G loss: 0.652983]\n",
      "epoch:16 step:15556 [D loss: 0.508906, acc.: 71.09%] [G loss: 0.795765]\n",
      "epoch:16 step:15557 [D loss: 0.568719, acc.: 71.88%] [G loss: 0.750153]\n",
      "epoch:16 step:15558 [D loss: 0.652205, acc.: 64.84%] [G loss: 0.545417]\n",
      "epoch:16 step:15559 [D loss: 0.485390, acc.: 77.34%] [G loss: 0.592400]\n",
      "epoch:16 step:15560 [D loss: 0.492049, acc.: 75.00%] [G loss: 0.694731]\n",
      "epoch:16 step:15561 [D loss: 0.573375, acc.: 69.53%] [G loss: 0.644089]\n",
      "epoch:16 step:15562 [D loss: 0.509370, acc.: 74.22%] [G loss: 0.622821]\n",
      "epoch:16 step:15563 [D loss: 0.586213, acc.: 67.19%] [G loss: 0.646850]\n",
      "epoch:16 step:15564 [D loss: 0.497612, acc.: 73.44%] [G loss: 0.700863]\n",
      "epoch:16 step:15565 [D loss: 0.561445, acc.: 66.41%] [G loss: 0.692931]\n",
      "epoch:16 step:15566 [D loss: 0.452844, acc.: 79.69%] [G loss: 1.024016]\n",
      "epoch:16 step:15567 [D loss: 0.553739, acc.: 71.09%] [G loss: 0.862822]\n",
      "epoch:16 step:15568 [D loss: 0.582674, acc.: 64.84%] [G loss: 0.823874]\n",
      "epoch:16 step:15569 [D loss: 0.534753, acc.: 71.88%] [G loss: 0.620375]\n",
      "epoch:16 step:15570 [D loss: 0.534845, acc.: 70.31%] [G loss: 0.550074]\n",
      "epoch:16 step:15571 [D loss: 0.537424, acc.: 70.31%] [G loss: 0.549825]\n",
      "epoch:16 step:15572 [D loss: 0.571566, acc.: 67.19%] [G loss: 0.564719]\n",
      "epoch:16 step:15573 [D loss: 0.521730, acc.: 69.53%] [G loss: 0.535041]\n",
      "epoch:16 step:15574 [D loss: 0.426447, acc.: 83.59%] [G loss: 0.767008]\n",
      "epoch:16 step:15575 [D loss: 0.544542, acc.: 71.88%] [G loss: 0.760697]\n",
      "epoch:16 step:15576 [D loss: 0.578629, acc.: 65.62%] [G loss: 0.661126]\n",
      "epoch:16 step:15577 [D loss: 0.535288, acc.: 71.88%] [G loss: 0.679288]\n",
      "epoch:16 step:15578 [D loss: 0.589317, acc.: 68.75%] [G loss: 0.698694]\n",
      "epoch:16 step:15579 [D loss: 0.563270, acc.: 67.19%] [G loss: 0.598015]\n",
      "epoch:16 step:15580 [D loss: 0.532660, acc.: 70.31%] [G loss: 0.744901]\n",
      "epoch:16 step:15581 [D loss: 0.500054, acc.: 72.66%] [G loss: 0.891391]\n",
      "epoch:16 step:15582 [D loss: 0.538337, acc.: 70.31%] [G loss: 0.760806]\n",
      "epoch:16 step:15583 [D loss: 0.613627, acc.: 68.75%] [G loss: 0.585329]\n",
      "epoch:16 step:15584 [D loss: 0.508329, acc.: 78.12%] [G loss: 0.494174]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:16 step:15585 [D loss: 0.614515, acc.: 58.59%] [G loss: 0.457977]\n",
      "epoch:16 step:15586 [D loss: 0.519161, acc.: 72.66%] [G loss: 0.686664]\n",
      "epoch:16 step:15587 [D loss: 0.554395, acc.: 69.53%] [G loss: 0.603105]\n",
      "epoch:16 step:15588 [D loss: 0.532885, acc.: 67.19%] [G loss: 0.636923]\n",
      "epoch:16 step:15589 [D loss: 0.527112, acc.: 70.31%] [G loss: 0.627135]\n",
      "epoch:16 step:15590 [D loss: 0.477646, acc.: 75.78%] [G loss: 0.688382]\n",
      "epoch:16 step:15591 [D loss: 0.535739, acc.: 68.75%] [G loss: 0.757430]\n",
      "epoch:16 step:15592 [D loss: 0.549800, acc.: 67.19%] [G loss: 0.708331]\n",
      "epoch:16 step:15593 [D loss: 0.555034, acc.: 65.62%] [G loss: 0.678985]\n",
      "epoch:16 step:15594 [D loss: 0.455991, acc.: 76.56%] [G loss: 0.656052]\n",
      "epoch:16 step:15595 [D loss: 0.486785, acc.: 75.78%] [G loss: 0.629524]\n",
      "epoch:16 step:15596 [D loss: 0.621655, acc.: 67.19%] [G loss: 0.683806]\n",
      "epoch:16 step:15597 [D loss: 0.480885, acc.: 76.56%] [G loss: 0.768297]\n",
      "epoch:16 step:15598 [D loss: 0.616677, acc.: 65.62%] [G loss: 0.641679]\n",
      "epoch:16 step:15599 [D loss: 0.519813, acc.: 71.88%] [G loss: 0.459095]\n",
      "epoch:16 step:15600 [D loss: 0.514686, acc.: 74.22%] [G loss: 0.639357]\n",
      "epoch:16 step:15601 [D loss: 0.527478, acc.: 71.09%] [G loss: 0.557550]\n",
      "epoch:16 step:15602 [D loss: 0.541876, acc.: 68.75%] [G loss: 0.605037]\n",
      "epoch:16 step:15603 [D loss: 0.496775, acc.: 74.22%] [G loss: 0.661402]\n",
      "epoch:16 step:15604 [D loss: 0.525277, acc.: 71.88%] [G loss: 0.618943]\n",
      "epoch:16 step:15605 [D loss: 0.497024, acc.: 74.22%] [G loss: 0.658815]\n",
      "epoch:16 step:15606 [D loss: 0.584480, acc.: 66.41%] [G loss: 0.623313]\n",
      "epoch:16 step:15607 [D loss: 0.564080, acc.: 68.75%] [G loss: 0.547206]\n",
      "epoch:16 step:15608 [D loss: 0.541329, acc.: 71.88%] [G loss: 0.579584]\n",
      "epoch:16 step:15609 [D loss: 0.494359, acc.: 75.00%] [G loss: 0.456731]\n",
      "epoch:16 step:15610 [D loss: 0.550151, acc.: 69.53%] [G loss: 0.727806]\n",
      "epoch:16 step:15611 [D loss: 0.560813, acc.: 66.41%] [G loss: 0.615650]\n",
      "epoch:16 step:15612 [D loss: 0.508413, acc.: 73.44%] [G loss: 0.867493]\n",
      "epoch:16 step:15613 [D loss: 0.550535, acc.: 75.78%] [G loss: 0.520030]\n",
      "epoch:16 step:15614 [D loss: 0.590601, acc.: 66.41%] [G loss: 0.558303]\n",
      "epoch:16 step:15615 [D loss: 0.455488, acc.: 75.00%] [G loss: 0.880130]\n",
      "epoch:16 step:15616 [D loss: 0.426012, acc.: 82.03%] [G loss: 0.891366]\n",
      "epoch:16 step:15617 [D loss: 0.608137, acc.: 64.06%] [G loss: 0.664218]\n",
      "epoch:16 step:15618 [D loss: 0.561229, acc.: 69.53%] [G loss: 0.628980]\n",
      "epoch:16 step:15619 [D loss: 0.563592, acc.: 69.53%] [G loss: 0.515981]\n",
      "epoch:16 step:15620 [D loss: 0.538792, acc.: 71.09%] [G loss: 0.524967]\n",
      "epoch:16 step:15621 [D loss: 0.490843, acc.: 72.66%] [G loss: 0.577075]\n",
      "epoch:16 step:15622 [D loss: 0.502987, acc.: 75.78%] [G loss: 0.660395]\n",
      "epoch:16 step:15623 [D loss: 0.437267, acc.: 85.16%] [G loss: 0.672362]\n",
      "epoch:16 step:15624 [D loss: 0.472532, acc.: 78.91%] [G loss: 0.801117]\n",
      "epoch:16 step:15625 [D loss: 0.494717, acc.: 78.12%] [G loss: 0.722120]\n",
      "epoch:16 step:15626 [D loss: 0.520510, acc.: 75.00%] [G loss: 0.762802]\n",
      "epoch:16 step:15627 [D loss: 0.537184, acc.: 72.66%] [G loss: 0.818307]\n",
      "epoch:16 step:15628 [D loss: 0.595318, acc.: 66.41%] [G loss: 0.537121]\n",
      "epoch:16 step:15629 [D loss: 0.536020, acc.: 68.75%] [G loss: 0.559809]\n",
      "epoch:16 step:15630 [D loss: 0.489195, acc.: 74.22%] [G loss: 0.611262]\n",
      "epoch:16 step:15631 [D loss: 0.495157, acc.: 75.00%] [G loss: 0.718730]\n",
      "epoch:16 step:15632 [D loss: 0.522710, acc.: 75.00%] [G loss: 0.687058]\n",
      "epoch:16 step:15633 [D loss: 0.465690, acc.: 77.34%] [G loss: 0.692226]\n",
      "epoch:16 step:15634 [D loss: 0.499618, acc.: 75.00%] [G loss: 0.672907]\n",
      "epoch:16 step:15635 [D loss: 0.508187, acc.: 72.66%] [G loss: 0.878949]\n",
      "epoch:16 step:15636 [D loss: 0.570210, acc.: 64.84%] [G loss: 0.537560]\n",
      "epoch:16 step:15637 [D loss: 0.536478, acc.: 68.75%] [G loss: 0.634420]\n",
      "epoch:16 step:15638 [D loss: 0.556951, acc.: 69.53%] [G loss: 0.532767]\n",
      "epoch:16 step:15639 [D loss: 0.481033, acc.: 78.12%] [G loss: 0.666294]\n",
      "epoch:16 step:15640 [D loss: 0.405735, acc.: 81.25%] [G loss: 0.915050]\n",
      "epoch:16 step:15641 [D loss: 0.513883, acc.: 72.66%] [G loss: 0.812936]\n",
      "epoch:16 step:15642 [D loss: 0.530945, acc.: 73.44%] [G loss: 0.822016]\n",
      "epoch:16 step:15643 [D loss: 0.494750, acc.: 73.44%] [G loss: 0.832827]\n",
      "epoch:16 step:15644 [D loss: 0.578677, acc.: 71.88%] [G loss: 0.612347]\n",
      "epoch:16 step:15645 [D loss: 0.530057, acc.: 78.91%] [G loss: 0.558437]\n",
      "epoch:16 step:15646 [D loss: 0.478569, acc.: 77.34%] [G loss: 0.849863]\n",
      "epoch:16 step:15647 [D loss: 0.569352, acc.: 72.66%] [G loss: 0.769903]\n",
      "epoch:16 step:15648 [D loss: 0.521375, acc.: 75.78%] [G loss: 0.793451]\n",
      "epoch:16 step:15649 [D loss: 0.516085, acc.: 71.88%] [G loss: 0.754676]\n",
      "epoch:16 step:15650 [D loss: 0.593260, acc.: 69.53%] [G loss: 0.745079]\n",
      "epoch:16 step:15651 [D loss: 0.528067, acc.: 67.19%] [G loss: 0.762297]\n",
      "epoch:16 step:15652 [D loss: 0.497214, acc.: 71.09%] [G loss: 0.807306]\n",
      "epoch:16 step:15653 [D loss: 0.479906, acc.: 76.56%] [G loss: 0.743087]\n",
      "epoch:16 step:15654 [D loss: 0.541330, acc.: 72.66%] [G loss: 0.692897]\n",
      "epoch:16 step:15655 [D loss: 0.522417, acc.: 67.97%] [G loss: 0.613748]\n",
      "epoch:16 step:15656 [D loss: 0.505442, acc.: 70.31%] [G loss: 0.675459]\n",
      "epoch:16 step:15657 [D loss: 0.559584, acc.: 71.09%] [G loss: 0.746662]\n",
      "epoch:16 step:15658 [D loss: 0.493744, acc.: 73.44%] [G loss: 0.994187]\n",
      "epoch:16 step:15659 [D loss: 0.535409, acc.: 71.09%] [G loss: 0.718801]\n",
      "epoch:16 step:15660 [D loss: 0.501892, acc.: 75.00%] [G loss: 0.601297]\n",
      "epoch:16 step:15661 [D loss: 0.555408, acc.: 67.97%] [G loss: 0.626556]\n",
      "epoch:16 step:15662 [D loss: 0.557889, acc.: 69.53%] [G loss: 0.605770]\n",
      "epoch:16 step:15663 [D loss: 0.546176, acc.: 73.44%] [G loss: 0.718142]\n",
      "epoch:16 step:15664 [D loss: 0.496769, acc.: 74.22%] [G loss: 0.741770]\n",
      "epoch:16 step:15665 [D loss: 0.627829, acc.: 63.28%] [G loss: 0.662138]\n",
      "epoch:16 step:15666 [D loss: 0.546342, acc.: 70.31%] [G loss: 0.660308]\n",
      "epoch:16 step:15667 [D loss: 0.581957, acc.: 66.41%] [G loss: 0.617330]\n",
      "epoch:16 step:15668 [D loss: 0.536217, acc.: 71.88%] [G loss: 0.619451]\n",
      "epoch:16 step:15669 [D loss: 0.481589, acc.: 81.25%] [G loss: 0.723003]\n",
      "epoch:16 step:15670 [D loss: 0.555493, acc.: 70.31%] [G loss: 0.629800]\n",
      "epoch:16 step:15671 [D loss: 0.511896, acc.: 70.31%] [G loss: 0.662584]\n",
      "epoch:16 step:15672 [D loss: 0.501201, acc.: 80.47%] [G loss: 0.732435]\n",
      "epoch:16 step:15673 [D loss: 0.506296, acc.: 74.22%] [G loss: 0.733086]\n",
      "epoch:16 step:15674 [D loss: 0.491976, acc.: 75.00%] [G loss: 0.705408]\n",
      "epoch:16 step:15675 [D loss: 0.516999, acc.: 75.78%] [G loss: 0.572950]\n",
      "epoch:16 step:15676 [D loss: 0.572199, acc.: 67.19%] [G loss: 0.536141]\n",
      "epoch:16 step:15677 [D loss: 0.512826, acc.: 74.22%] [G loss: 0.566556]\n",
      "epoch:16 step:15678 [D loss: 0.565303, acc.: 71.88%] [G loss: 0.539313]\n",
      "epoch:16 step:15679 [D loss: 0.557116, acc.: 71.88%] [G loss: 0.536098]\n",
      "epoch:16 step:15680 [D loss: 0.483553, acc.: 75.78%] [G loss: 0.605618]\n",
      "epoch:16 step:15681 [D loss: 0.561206, acc.: 67.19%] [G loss: 0.572077]\n",
      "epoch:16 step:15682 [D loss: 0.493446, acc.: 73.44%] [G loss: 0.655766]\n",
      "epoch:16 step:15683 [D loss: 0.488360, acc.: 77.34%] [G loss: 0.753827]\n",
      "epoch:16 step:15684 [D loss: 0.490389, acc.: 77.34%] [G loss: 0.760875]\n",
      "epoch:16 step:15685 [D loss: 0.494177, acc.: 77.34%] [G loss: 0.854183]\n",
      "epoch:16 step:15686 [D loss: 0.548508, acc.: 68.75%] [G loss: 0.763272]\n",
      "epoch:16 step:15687 [D loss: 0.527573, acc.: 71.09%] [G loss: 0.696940]\n",
      "epoch:16 step:15688 [D loss: 0.597655, acc.: 64.06%] [G loss: 0.549144]\n",
      "epoch:16 step:15689 [D loss: 0.572258, acc.: 64.06%] [G loss: 0.583885]\n",
      "epoch:16 step:15690 [D loss: 0.559666, acc.: 66.41%] [G loss: 0.578705]\n",
      "epoch:16 step:15691 [D loss: 0.527092, acc.: 73.44%] [G loss: 0.556284]\n",
      "epoch:16 step:15692 [D loss: 0.534622, acc.: 72.66%] [G loss: 0.795590]\n",
      "epoch:16 step:15693 [D loss: 0.514795, acc.: 74.22%] [G loss: 0.838549]\n",
      "epoch:16 step:15694 [D loss: 0.568647, acc.: 67.19%] [G loss: 0.688457]\n",
      "epoch:16 step:15695 [D loss: 0.622726, acc.: 61.72%] [G loss: 0.666034]\n",
      "epoch:16 step:15696 [D loss: 0.561386, acc.: 69.53%] [G loss: 0.463441]\n",
      "epoch:16 step:15697 [D loss: 0.529102, acc.: 75.78%] [G loss: 0.630894]\n",
      "epoch:16 step:15698 [D loss: 0.518489, acc.: 77.34%] [G loss: 0.561164]\n",
      "epoch:16 step:15699 [D loss: 0.490387, acc.: 73.44%] [G loss: 0.754758]\n",
      "epoch:16 step:15700 [D loss: 0.516384, acc.: 72.66%] [G loss: 0.660995]\n",
      "epoch:16 step:15701 [D loss: 0.537923, acc.: 71.88%] [G loss: 0.816800]\n",
      "epoch:16 step:15702 [D loss: 0.642945, acc.: 60.16%] [G loss: 0.611598]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:16 step:15703 [D loss: 0.582893, acc.: 63.28%] [G loss: 0.537618]\n",
      "epoch:16 step:15704 [D loss: 0.513795, acc.: 71.88%] [G loss: 0.743970]\n",
      "epoch:16 step:15705 [D loss: 0.513330, acc.: 75.00%] [G loss: 0.669058]\n",
      "epoch:16 step:15706 [D loss: 0.535914, acc.: 66.41%] [G loss: 0.603952]\n",
      "epoch:16 step:15707 [D loss: 0.500220, acc.: 73.44%] [G loss: 0.672394]\n",
      "epoch:16 step:15708 [D loss: 0.604297, acc.: 65.62%] [G loss: 0.753769]\n",
      "epoch:16 step:15709 [D loss: 0.577896, acc.: 67.19%] [G loss: 0.540607]\n",
      "epoch:16 step:15710 [D loss: 0.541901, acc.: 68.75%] [G loss: 0.541455]\n",
      "epoch:16 step:15711 [D loss: 0.517143, acc.: 74.22%] [G loss: 0.769502]\n",
      "epoch:16 step:15712 [D loss: 0.603384, acc.: 65.62%] [G loss: 0.528656]\n",
      "epoch:16 step:15713 [D loss: 0.525698, acc.: 73.44%] [G loss: 0.658465]\n",
      "epoch:16 step:15714 [D loss: 0.560485, acc.: 71.09%] [G loss: 0.589601]\n",
      "epoch:16 step:15715 [D loss: 0.525616, acc.: 70.31%] [G loss: 0.579488]\n",
      "epoch:16 step:15716 [D loss: 0.511918, acc.: 74.22%] [G loss: 0.659949]\n",
      "epoch:16 step:15717 [D loss: 0.482562, acc.: 76.56%] [G loss: 0.938911]\n",
      "epoch:16 step:15718 [D loss: 0.490278, acc.: 74.22%] [G loss: 0.782525]\n",
      "epoch:16 step:15719 [D loss: 0.525689, acc.: 71.88%] [G loss: 0.761938]\n",
      "epoch:16 step:15720 [D loss: 0.518559, acc.: 71.88%] [G loss: 0.649080]\n",
      "epoch:16 step:15721 [D loss: 0.630037, acc.: 65.62%] [G loss: 0.568166]\n",
      "epoch:16 step:15722 [D loss: 0.544806, acc.: 68.75%] [G loss: 0.584046]\n",
      "epoch:16 step:15723 [D loss: 0.555668, acc.: 69.53%] [G loss: 0.628704]\n",
      "epoch:16 step:15724 [D loss: 0.527738, acc.: 67.97%] [G loss: 0.650329]\n",
      "epoch:16 step:15725 [D loss: 0.516007, acc.: 74.22%] [G loss: 0.564924]\n",
      "epoch:16 step:15726 [D loss: 0.487116, acc.: 76.56%] [G loss: 0.681620]\n",
      "epoch:16 step:15727 [D loss: 0.512761, acc.: 71.09%] [G loss: 0.631056]\n",
      "epoch:16 step:15728 [D loss: 0.516106, acc.: 68.75%] [G loss: 0.584825]\n",
      "epoch:16 step:15729 [D loss: 0.497178, acc.: 75.00%] [G loss: 0.631577]\n",
      "epoch:16 step:15730 [D loss: 0.522154, acc.: 66.41%] [G loss: 0.536715]\n",
      "epoch:16 step:15731 [D loss: 0.555817, acc.: 70.31%] [G loss: 0.583885]\n",
      "epoch:16 step:15732 [D loss: 0.646641, acc.: 58.59%] [G loss: 0.513800]\n",
      "epoch:16 step:15733 [D loss: 0.583638, acc.: 68.75%] [G loss: 0.618057]\n",
      "epoch:16 step:15734 [D loss: 0.540037, acc.: 69.53%] [G loss: 0.553605]\n",
      "epoch:16 step:15735 [D loss: 0.468897, acc.: 78.91%] [G loss: 0.926933]\n",
      "epoch:16 step:15736 [D loss: 0.565010, acc.: 76.56%] [G loss: 0.861940]\n",
      "epoch:16 step:15737 [D loss: 0.567645, acc.: 69.53%] [G loss: 0.631428]\n",
      "epoch:16 step:15738 [D loss: 0.466655, acc.: 76.56%] [G loss: 0.754939]\n",
      "epoch:16 step:15739 [D loss: 0.428904, acc.: 80.47%] [G loss: 0.754587]\n",
      "epoch:16 step:15740 [D loss: 0.539683, acc.: 74.22%] [G loss: 0.700617]\n",
      "epoch:16 step:15741 [D loss: 0.556706, acc.: 66.41%] [G loss: 0.643704]\n",
      "epoch:16 step:15742 [D loss: 0.522495, acc.: 72.66%] [G loss: 0.658624]\n",
      "epoch:16 step:15743 [D loss: 0.484557, acc.: 75.00%] [G loss: 0.707794]\n",
      "epoch:16 step:15744 [D loss: 0.579635, acc.: 67.19%] [G loss: 0.651175]\n",
      "epoch:16 step:15745 [D loss: 0.554900, acc.: 68.75%] [G loss: 0.725938]\n",
      "epoch:16 step:15746 [D loss: 0.540373, acc.: 63.28%] [G loss: 0.684508]\n",
      "epoch:16 step:15747 [D loss: 0.537824, acc.: 68.75%] [G loss: 0.627901]\n",
      "epoch:16 step:15748 [D loss: 0.547236, acc.: 70.31%] [G loss: 0.676023]\n",
      "epoch:16 step:15749 [D loss: 0.527689, acc.: 69.53%] [G loss: 0.645896]\n",
      "epoch:16 step:15750 [D loss: 0.580508, acc.: 66.41%] [G loss: 0.542221]\n",
      "epoch:16 step:15751 [D loss: 0.581263, acc.: 64.84%] [G loss: 0.622032]\n",
      "epoch:16 step:15752 [D loss: 0.518748, acc.: 73.44%] [G loss: 0.680893]\n",
      "epoch:16 step:15753 [D loss: 0.509742, acc.: 72.66%] [G loss: 0.695666]\n",
      "epoch:16 step:15754 [D loss: 0.566869, acc.: 68.75%] [G loss: 0.516412]\n",
      "epoch:16 step:15755 [D loss: 0.540246, acc.: 71.09%] [G loss: 0.462772]\n",
      "epoch:16 step:15756 [D loss: 0.607882, acc.: 62.50%] [G loss: 0.519289]\n",
      "epoch:16 step:15757 [D loss: 0.582285, acc.: 66.41%] [G loss: 0.446571]\n",
      "epoch:16 step:15758 [D loss: 0.709129, acc.: 54.69%] [G loss: 0.528006]\n",
      "epoch:16 step:15759 [D loss: 0.566330, acc.: 68.75%] [G loss: 0.617550]\n",
      "epoch:16 step:15760 [D loss: 0.513124, acc.: 75.00%] [G loss: 0.758959]\n",
      "epoch:16 step:15761 [D loss: 0.475451, acc.: 74.22%] [G loss: 0.919490]\n",
      "epoch:16 step:15762 [D loss: 0.538748, acc.: 69.53%] [G loss: 0.950857]\n",
      "epoch:16 step:15763 [D loss: 0.531274, acc.: 75.00%] [G loss: 0.795358]\n",
      "epoch:16 step:15764 [D loss: 0.567063, acc.: 67.97%] [G loss: 0.672632]\n",
      "epoch:16 step:15765 [D loss: 0.577819, acc.: 68.75%] [G loss: 0.624731]\n",
      "epoch:16 step:15766 [D loss: 0.586893, acc.: 67.19%] [G loss: 0.768337]\n",
      "epoch:16 step:15767 [D loss: 0.529244, acc.: 69.53%] [G loss: 0.639756]\n",
      "epoch:16 step:15768 [D loss: 0.587408, acc.: 63.28%] [G loss: 0.634863]\n",
      "epoch:16 step:15769 [D loss: 0.539310, acc.: 67.97%] [G loss: 0.610360]\n",
      "epoch:16 step:15770 [D loss: 0.560749, acc.: 70.31%] [G loss: 0.818807]\n",
      "epoch:16 step:15771 [D loss: 0.591212, acc.: 64.84%] [G loss: 0.809722]\n",
      "epoch:16 step:15772 [D loss: 0.502003, acc.: 73.44%] [G loss: 0.689864]\n",
      "epoch:16 step:15773 [D loss: 0.480442, acc.: 78.12%] [G loss: 0.819787]\n",
      "epoch:16 step:15774 [D loss: 0.464887, acc.: 79.69%] [G loss: 1.004372]\n",
      "epoch:16 step:15775 [D loss: 0.549695, acc.: 69.53%] [G loss: 0.734014]\n",
      "epoch:16 step:15776 [D loss: 0.622683, acc.: 67.97%] [G loss: 0.594921]\n",
      "epoch:16 step:15777 [D loss: 0.531811, acc.: 72.66%] [G loss: 0.670371]\n",
      "epoch:16 step:15778 [D loss: 0.515790, acc.: 71.09%] [G loss: 0.658215]\n",
      "epoch:16 step:15779 [D loss: 0.571074, acc.: 66.41%] [G loss: 0.644559]\n",
      "epoch:16 step:15780 [D loss: 0.663705, acc.: 63.28%] [G loss: 0.674219]\n",
      "epoch:16 step:15781 [D loss: 0.505375, acc.: 74.22%] [G loss: 0.507971]\n",
      "epoch:16 step:15782 [D loss: 0.541117, acc.: 71.88%] [G loss: 0.794219]\n",
      "epoch:16 step:15783 [D loss: 0.530801, acc.: 75.78%] [G loss: 0.443393]\n",
      "epoch:16 step:15784 [D loss: 0.494406, acc.: 73.44%] [G loss: 0.672163]\n",
      "epoch:16 step:15785 [D loss: 0.614719, acc.: 64.84%] [G loss: 0.729124]\n",
      "epoch:16 step:15786 [D loss: 0.611502, acc.: 67.97%] [G loss: 0.793156]\n",
      "epoch:16 step:15787 [D loss: 0.508022, acc.: 73.44%] [G loss: 0.845609]\n",
      "epoch:16 step:15788 [D loss: 0.489648, acc.: 77.34%] [G loss: 0.752804]\n",
      "epoch:16 step:15789 [D loss: 0.548166, acc.: 71.88%] [G loss: 0.675407]\n",
      "epoch:16 step:15790 [D loss: 0.509275, acc.: 71.09%] [G loss: 0.739771]\n",
      "epoch:16 step:15791 [D loss: 0.530388, acc.: 75.78%] [G loss: 0.461049]\n",
      "epoch:16 step:15792 [D loss: 0.617613, acc.: 65.62%] [G loss: 0.550431]\n",
      "epoch:16 step:15793 [D loss: 0.525749, acc.: 73.44%] [G loss: 0.666556]\n",
      "epoch:16 step:15794 [D loss: 0.485874, acc.: 75.00%] [G loss: 0.910205]\n",
      "epoch:16 step:15795 [D loss: 0.498642, acc.: 77.34%] [G loss: 0.755772]\n",
      "epoch:16 step:15796 [D loss: 0.561605, acc.: 69.53%] [G loss: 0.757150]\n",
      "epoch:16 step:15797 [D loss: 0.534688, acc.: 68.75%] [G loss: 0.527585]\n",
      "epoch:16 step:15798 [D loss: 0.562693, acc.: 73.44%] [G loss: 0.508599]\n",
      "epoch:16 step:15799 [D loss: 0.525855, acc.: 70.31%] [G loss: 0.474708]\n",
      "epoch:16 step:15800 [D loss: 0.567481, acc.: 71.09%] [G loss: 0.487192]\n",
      "epoch:16 step:15801 [D loss: 0.512743, acc.: 75.00%] [G loss: 0.622858]\n",
      "epoch:16 step:15802 [D loss: 0.500654, acc.: 71.88%] [G loss: 0.679832]\n",
      "epoch:16 step:15803 [D loss: 0.532964, acc.: 74.22%] [G loss: 0.653730]\n",
      "epoch:16 step:15804 [D loss: 0.619025, acc.: 60.94%] [G loss: 0.438455]\n",
      "epoch:16 step:15805 [D loss: 0.540450, acc.: 68.75%] [G loss: 0.654038]\n",
      "epoch:16 step:15806 [D loss: 0.470290, acc.: 76.56%] [G loss: 0.808918]\n",
      "epoch:16 step:15807 [D loss: 0.576725, acc.: 70.31%] [G loss: 0.912585]\n",
      "epoch:16 step:15808 [D loss: 0.549423, acc.: 73.44%] [G loss: 0.598939]\n",
      "epoch:16 step:15809 [D loss: 0.585388, acc.: 68.75%] [G loss: 0.660959]\n",
      "epoch:16 step:15810 [D loss: 0.608677, acc.: 64.06%] [G loss: 0.626027]\n",
      "epoch:16 step:15811 [D loss: 0.470610, acc.: 79.69%] [G loss: 0.778295]\n",
      "epoch:16 step:15812 [D loss: 0.632402, acc.: 66.41%] [G loss: 0.541127]\n",
      "epoch:16 step:15813 [D loss: 0.493219, acc.: 71.09%] [G loss: 0.630419]\n",
      "epoch:16 step:15814 [D loss: 0.534462, acc.: 71.88%] [G loss: 0.544004]\n",
      "epoch:16 step:15815 [D loss: 0.407461, acc.: 80.47%] [G loss: 0.667418]\n",
      "epoch:16 step:15816 [D loss: 0.553715, acc.: 75.00%] [G loss: 0.524752]\n",
      "epoch:16 step:15817 [D loss: 0.473714, acc.: 73.44%] [G loss: 0.512405]\n",
      "epoch:16 step:15818 [D loss: 0.535973, acc.: 71.09%] [G loss: 0.597507]\n",
      "epoch:16 step:15819 [D loss: 0.546518, acc.: 73.44%] [G loss: 0.581099]\n",
      "epoch:16 step:15820 [D loss: 0.610688, acc.: 67.19%] [G loss: 0.548293]\n",
      "epoch:16 step:15821 [D loss: 0.557814, acc.: 70.31%] [G loss: 0.638062]\n",
      "epoch:16 step:15822 [D loss: 0.544209, acc.: 71.88%] [G loss: 0.641271]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:16 step:15823 [D loss: 0.563575, acc.: 66.41%] [G loss: 0.564396]\n",
      "epoch:16 step:15824 [D loss: 0.536118, acc.: 76.56%] [G loss: 0.595328]\n",
      "epoch:16 step:15825 [D loss: 0.491132, acc.: 76.56%] [G loss: 0.691023]\n",
      "epoch:16 step:15826 [D loss: 0.569499, acc.: 65.62%] [G loss: 0.491640]\n",
      "epoch:16 step:15827 [D loss: 0.512649, acc.: 69.53%] [G loss: 0.620418]\n",
      "epoch:16 step:15828 [D loss: 0.552809, acc.: 71.88%] [G loss: 0.748973]\n",
      "epoch:16 step:15829 [D loss: 0.534778, acc.: 72.66%] [G loss: 0.598533]\n",
      "epoch:16 step:15830 [D loss: 0.479617, acc.: 78.12%] [G loss: 0.595037]\n",
      "epoch:16 step:15831 [D loss: 0.534329, acc.: 70.31%] [G loss: 0.530569]\n",
      "epoch:16 step:15832 [D loss: 0.540838, acc.: 72.66%] [G loss: 0.622965]\n",
      "epoch:16 step:15833 [D loss: 0.499682, acc.: 75.78%] [G loss: 0.524428]\n",
      "epoch:16 step:15834 [D loss: 0.478519, acc.: 78.12%] [G loss: 0.561911]\n",
      "epoch:16 step:15835 [D loss: 0.523193, acc.: 70.31%] [G loss: 0.580174]\n",
      "epoch:16 step:15836 [D loss: 0.559695, acc.: 70.31%] [G loss: 0.624340]\n",
      "epoch:16 step:15837 [D loss: 0.571649, acc.: 67.97%] [G loss: 0.547059]\n",
      "epoch:16 step:15838 [D loss: 0.584379, acc.: 64.84%] [G loss: 0.484572]\n",
      "epoch:16 step:15839 [D loss: 0.599171, acc.: 62.50%] [G loss: 0.483244]\n",
      "epoch:16 step:15840 [D loss: 0.534320, acc.: 74.22%] [G loss: 0.448844]\n",
      "epoch:16 step:15841 [D loss: 0.575742, acc.: 66.41%] [G loss: 0.457667]\n",
      "epoch:16 step:15842 [D loss: 0.534387, acc.: 71.09%] [G loss: 0.453041]\n",
      "epoch:16 step:15843 [D loss: 0.557982, acc.: 65.62%] [G loss: 0.540843]\n",
      "epoch:16 step:15844 [D loss: 0.515066, acc.: 75.00%] [G loss: 0.583673]\n",
      "epoch:16 step:15845 [D loss: 0.556043, acc.: 69.53%] [G loss: 0.694815]\n",
      "epoch:16 step:15846 [D loss: 0.533476, acc.: 65.62%] [G loss: 0.673151]\n",
      "epoch:16 step:15847 [D loss: 0.568063, acc.: 67.19%] [G loss: 0.685930]\n",
      "epoch:16 step:15848 [D loss: 0.550275, acc.: 70.31%] [G loss: 0.709603]\n",
      "epoch:16 step:15849 [D loss: 0.460706, acc.: 79.69%] [G loss: 0.543917]\n",
      "epoch:16 step:15850 [D loss: 0.626794, acc.: 66.41%] [G loss: 0.447485]\n",
      "epoch:16 step:15851 [D loss: 0.527475, acc.: 73.44%] [G loss: 0.609804]\n",
      "epoch:16 step:15852 [D loss: 0.429932, acc.: 77.34%] [G loss: 0.658151]\n",
      "epoch:16 step:15853 [D loss: 0.688474, acc.: 60.94%] [G loss: 0.604710]\n",
      "epoch:16 step:15854 [D loss: 0.557625, acc.: 65.62%] [G loss: 0.471841]\n",
      "epoch:16 step:15855 [D loss: 0.562815, acc.: 66.41%] [G loss: 0.589659]\n",
      "epoch:16 step:15856 [D loss: 0.557557, acc.: 64.84%] [G loss: 0.533942]\n",
      "epoch:16 step:15857 [D loss: 0.559328, acc.: 67.97%] [G loss: 0.578578]\n",
      "epoch:16 step:15858 [D loss: 0.530293, acc.: 71.88%] [G loss: 0.619122]\n",
      "epoch:16 step:15859 [D loss: 0.688236, acc.: 57.03%] [G loss: 0.446942]\n",
      "epoch:16 step:15860 [D loss: 0.536796, acc.: 73.44%] [G loss: 0.523950]\n",
      "epoch:16 step:15861 [D loss: 0.550917, acc.: 68.75%] [G loss: 0.524664]\n",
      "epoch:16 step:15862 [D loss: 0.493337, acc.: 75.78%] [G loss: 0.653967]\n",
      "epoch:16 step:15863 [D loss: 0.529992, acc.: 68.75%] [G loss: 0.796565]\n",
      "epoch:16 step:15864 [D loss: 0.519495, acc.: 67.97%] [G loss: 0.761600]\n",
      "epoch:16 step:15865 [D loss: 0.544569, acc.: 71.09%] [G loss: 0.709873]\n",
      "epoch:16 step:15866 [D loss: 0.534799, acc.: 67.97%] [G loss: 0.559535]\n",
      "epoch:16 step:15867 [D loss: 0.517440, acc.: 74.22%] [G loss: 0.689840]\n",
      "epoch:16 step:15868 [D loss: 0.542835, acc.: 72.66%] [G loss: 0.656057]\n",
      "epoch:16 step:15869 [D loss: 0.608567, acc.: 64.06%] [G loss: 0.710310]\n",
      "epoch:16 step:15870 [D loss: 0.575419, acc.: 70.31%] [G loss: 0.555565]\n",
      "epoch:16 step:15871 [D loss: 0.568491, acc.: 72.66%] [G loss: 0.574028]\n",
      "epoch:16 step:15872 [D loss: 0.654283, acc.: 59.38%] [G loss: 0.404326]\n",
      "epoch:16 step:15873 [D loss: 0.576996, acc.: 65.62%] [G loss: 0.504617]\n",
      "epoch:16 step:15874 [D loss: 0.580624, acc.: 66.41%] [G loss: 0.547943]\n",
      "epoch:16 step:15875 [D loss: 0.613075, acc.: 64.84%] [G loss: 0.446616]\n",
      "epoch:16 step:15876 [D loss: 0.509599, acc.: 75.00%] [G loss: 0.607222]\n",
      "epoch:16 step:15877 [D loss: 0.489734, acc.: 75.78%] [G loss: 0.807084]\n",
      "epoch:16 step:15878 [D loss: 0.567873, acc.: 69.53%] [G loss: 0.789794]\n",
      "epoch:16 step:15879 [D loss: 0.537565, acc.: 68.75%] [G loss: 0.980418]\n",
      "epoch:16 step:15880 [D loss: 0.528841, acc.: 71.88%] [G loss: 0.700440]\n",
      "epoch:16 step:15881 [D loss: 0.504723, acc.: 74.22%] [G loss: 0.633101]\n",
      "epoch:16 step:15882 [D loss: 0.474598, acc.: 76.56%] [G loss: 0.655857]\n",
      "epoch:16 step:15883 [D loss: 0.573288, acc.: 67.97%] [G loss: 0.516764]\n",
      "epoch:16 step:15884 [D loss: 0.641803, acc.: 61.72%] [G loss: 0.502326]\n",
      "epoch:16 step:15885 [D loss: 0.522368, acc.: 70.31%] [G loss: 0.718010]\n",
      "epoch:16 step:15886 [D loss: 0.459775, acc.: 77.34%] [G loss: 0.747683]\n",
      "epoch:16 step:15887 [D loss: 0.518057, acc.: 72.66%] [G loss: 0.769657]\n",
      "epoch:16 step:15888 [D loss: 0.511554, acc.: 73.44%] [G loss: 0.848473]\n",
      "epoch:16 step:15889 [D loss: 0.518915, acc.: 74.22%] [G loss: 0.691416]\n",
      "epoch:16 step:15890 [D loss: 0.449734, acc.: 81.25%] [G loss: 0.701537]\n",
      "epoch:16 step:15891 [D loss: 0.477389, acc.: 80.47%] [G loss: 0.816333]\n",
      "epoch:16 step:15892 [D loss: 0.541646, acc.: 75.00%] [G loss: 0.642898]\n",
      "epoch:16 step:15893 [D loss: 0.526125, acc.: 76.56%] [G loss: 0.691631]\n",
      "epoch:16 step:15894 [D loss: 0.624242, acc.: 70.31%] [G loss: 0.666865]\n",
      "epoch:16 step:15895 [D loss: 0.500189, acc.: 75.78%] [G loss: 0.769202]\n",
      "epoch:16 step:15896 [D loss: 0.592795, acc.: 65.62%] [G loss: 0.548193]\n",
      "epoch:16 step:15897 [D loss: 0.569046, acc.: 65.62%] [G loss: 0.625711]\n",
      "epoch:16 step:15898 [D loss: 0.491078, acc.: 76.56%] [G loss: 0.633753]\n",
      "epoch:16 step:15899 [D loss: 0.505213, acc.: 76.56%] [G loss: 0.595617]\n",
      "epoch:16 step:15900 [D loss: 0.479171, acc.: 77.34%] [G loss: 0.662247]\n",
      "epoch:16 step:15901 [D loss: 0.493622, acc.: 75.78%] [G loss: 0.647152]\n",
      "epoch:16 step:15902 [D loss: 0.544317, acc.: 71.88%] [G loss: 0.636890]\n",
      "epoch:16 step:15903 [D loss: 0.481698, acc.: 77.34%] [G loss: 0.734065]\n",
      "epoch:16 step:15904 [D loss: 0.506000, acc.: 75.00%] [G loss: 0.695960]\n",
      "epoch:16 step:15905 [D loss: 0.545298, acc.: 72.66%] [G loss: 0.640624]\n",
      "epoch:16 step:15906 [D loss: 0.497407, acc.: 75.00%] [G loss: 0.726069]\n",
      "epoch:16 step:15907 [D loss: 0.650574, acc.: 60.16%] [G loss: 0.612841]\n",
      "epoch:16 step:15908 [D loss: 0.501849, acc.: 71.88%] [G loss: 0.774811]\n",
      "epoch:16 step:15909 [D loss: 0.528681, acc.: 68.75%] [G loss: 0.761311]\n",
      "epoch:16 step:15910 [D loss: 0.479756, acc.: 82.03%] [G loss: 0.757845]\n",
      "epoch:16 step:15911 [D loss: 0.428237, acc.: 85.16%] [G loss: 0.729631]\n",
      "epoch:16 step:15912 [D loss: 0.665192, acc.: 63.28%] [G loss: 0.649136]\n",
      "epoch:16 step:15913 [D loss: 0.488495, acc.: 75.00%] [G loss: 0.682088]\n",
      "epoch:16 step:15914 [D loss: 0.554424, acc.: 69.53%] [G loss: 0.687216]\n",
      "epoch:16 step:15915 [D loss: 0.441704, acc.: 78.91%] [G loss: 0.795494]\n",
      "epoch:16 step:15916 [D loss: 0.442333, acc.: 78.12%] [G loss: 0.708831]\n",
      "epoch:16 step:15917 [D loss: 0.479582, acc.: 72.66%] [G loss: 0.990592]\n",
      "epoch:16 step:15918 [D loss: 0.438204, acc.: 75.78%] [G loss: 1.122528]\n",
      "epoch:16 step:15919 [D loss: 0.513745, acc.: 72.66%] [G loss: 1.143901]\n",
      "epoch:16 step:15920 [D loss: 0.755024, acc.: 64.84%] [G loss: 1.122673]\n",
      "epoch:16 step:15921 [D loss: 0.551012, acc.: 70.31%] [G loss: 1.196641]\n",
      "epoch:16 step:15922 [D loss: 0.444668, acc.: 78.91%] [G loss: 1.218673]\n",
      "epoch:16 step:15923 [D loss: 0.522528, acc.: 68.75%] [G loss: 0.890414]\n",
      "epoch:16 step:15924 [D loss: 0.600039, acc.: 62.50%] [G loss: 0.611656]\n",
      "epoch:16 step:15925 [D loss: 0.499093, acc.: 76.56%] [G loss: 0.683815]\n",
      "epoch:16 step:15926 [D loss: 0.593072, acc.: 60.94%] [G loss: 0.971976]\n",
      "epoch:16 step:15927 [D loss: 0.521579, acc.: 67.97%] [G loss: 0.792605]\n",
      "epoch:16 step:15928 [D loss: 0.443213, acc.: 75.78%] [G loss: 1.292393]\n",
      "epoch:16 step:15929 [D loss: 0.368884, acc.: 86.72%] [G loss: 1.207292]\n",
      "epoch:17 step:15930 [D loss: 0.606387, acc.: 65.62%] [G loss: 1.173150]\n",
      "epoch:17 step:15931 [D loss: 0.460509, acc.: 76.56%] [G loss: 0.920025]\n",
      "epoch:17 step:15932 [D loss: 0.559325, acc.: 71.09%] [G loss: 0.924984]\n",
      "epoch:17 step:15933 [D loss: 0.492750, acc.: 75.78%] [G loss: 0.876836]\n",
      "epoch:17 step:15934 [D loss: 0.521036, acc.: 74.22%] [G loss: 0.786827]\n",
      "epoch:17 step:15935 [D loss: 0.584146, acc.: 71.09%] [G loss: 0.710040]\n",
      "epoch:17 step:15936 [D loss: 0.478268, acc.: 75.00%] [G loss: 0.757294]\n",
      "epoch:17 step:15937 [D loss: 0.448867, acc.: 78.91%] [G loss: 0.765441]\n",
      "epoch:17 step:15938 [D loss: 0.493019, acc.: 77.34%] [G loss: 0.842013]\n",
      "epoch:17 step:15939 [D loss: 0.512735, acc.: 74.22%] [G loss: 0.828400]\n",
      "epoch:17 step:15940 [D loss: 0.486263, acc.: 78.91%] [G loss: 0.809725]\n",
      "epoch:17 step:15941 [D loss: 0.617893, acc.: 64.84%] [G loss: 0.701071]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:17 step:15942 [D loss: 0.561615, acc.: 69.53%] [G loss: 0.593169]\n",
      "epoch:17 step:15943 [D loss: 0.512692, acc.: 72.66%] [G loss: 0.688342]\n",
      "epoch:17 step:15944 [D loss: 0.456490, acc.: 79.69%] [G loss: 0.835541]\n",
      "epoch:17 step:15945 [D loss: 0.476419, acc.: 75.78%] [G loss: 0.788120]\n",
      "epoch:17 step:15946 [D loss: 0.554042, acc.: 74.22%] [G loss: 0.579332]\n",
      "epoch:17 step:15947 [D loss: 0.546938, acc.: 71.88%] [G loss: 0.558811]\n",
      "epoch:17 step:15948 [D loss: 0.536531, acc.: 72.66%] [G loss: 0.622171]\n",
      "epoch:17 step:15949 [D loss: 0.709303, acc.: 57.03%] [G loss: 0.650848]\n",
      "epoch:17 step:15950 [D loss: 0.535950, acc.: 69.53%] [G loss: 0.661577]\n",
      "epoch:17 step:15951 [D loss: 0.457100, acc.: 77.34%] [G loss: 0.895795]\n",
      "epoch:17 step:15952 [D loss: 0.525137, acc.: 74.22%] [G loss: 0.776494]\n",
      "epoch:17 step:15953 [D loss: 0.493097, acc.: 74.22%] [G loss: 0.825250]\n",
      "epoch:17 step:15954 [D loss: 0.502511, acc.: 72.66%] [G loss: 0.740413]\n",
      "epoch:17 step:15955 [D loss: 0.569769, acc.: 67.97%] [G loss: 0.648506]\n",
      "epoch:17 step:15956 [D loss: 0.434073, acc.: 79.69%] [G loss: 0.781257]\n",
      "epoch:17 step:15957 [D loss: 0.594256, acc.: 67.19%] [G loss: 0.538562]\n",
      "epoch:17 step:15958 [D loss: 0.512304, acc.: 70.31%] [G loss: 0.593621]\n",
      "epoch:17 step:15959 [D loss: 0.509597, acc.: 73.44%] [G loss: 0.581299]\n",
      "epoch:17 step:15960 [D loss: 0.588865, acc.: 63.28%] [G loss: 0.550716]\n",
      "epoch:17 step:15961 [D loss: 0.528422, acc.: 70.31%] [G loss: 0.662213]\n",
      "epoch:17 step:15962 [D loss: 0.500496, acc.: 72.66%] [G loss: 0.623824]\n",
      "epoch:17 step:15963 [D loss: 0.494683, acc.: 70.31%] [G loss: 0.747504]\n",
      "epoch:17 step:15964 [D loss: 0.548837, acc.: 71.88%] [G loss: 0.578178]\n",
      "epoch:17 step:15965 [D loss: 0.533839, acc.: 68.75%] [G loss: 0.632847]\n",
      "epoch:17 step:15966 [D loss: 0.485637, acc.: 76.56%] [G loss: 0.822548]\n",
      "epoch:17 step:15967 [D loss: 0.604549, acc.: 71.88%] [G loss: 0.765675]\n",
      "epoch:17 step:15968 [D loss: 0.573720, acc.: 67.97%] [G loss: 0.607816]\n",
      "epoch:17 step:15969 [D loss: 0.471512, acc.: 78.91%] [G loss: 0.709690]\n",
      "epoch:17 step:15970 [D loss: 0.505097, acc.: 71.09%] [G loss: 0.654032]\n",
      "epoch:17 step:15971 [D loss: 0.482053, acc.: 76.56%] [G loss: 0.655161]\n",
      "epoch:17 step:15972 [D loss: 0.511142, acc.: 76.56%] [G loss: 0.616139]\n",
      "epoch:17 step:15973 [D loss: 0.606539, acc.: 64.06%] [G loss: 0.503120]\n",
      "epoch:17 step:15974 [D loss: 0.497479, acc.: 73.44%] [G loss: 0.585842]\n",
      "epoch:17 step:15975 [D loss: 0.496616, acc.: 73.44%] [G loss: 0.588596]\n",
      "epoch:17 step:15976 [D loss: 0.519256, acc.: 69.53%] [G loss: 0.807387]\n",
      "epoch:17 step:15977 [D loss: 0.522106, acc.: 70.31%] [G loss: 0.767401]\n",
      "epoch:17 step:15978 [D loss: 0.493151, acc.: 74.22%] [G loss: 1.032834]\n",
      "epoch:17 step:15979 [D loss: 0.519264, acc.: 73.44%] [G loss: 0.928044]\n",
      "epoch:17 step:15980 [D loss: 0.640255, acc.: 64.06%] [G loss: 0.708157]\n",
      "epoch:17 step:15981 [D loss: 0.576236, acc.: 64.84%] [G loss: 0.562822]\n",
      "epoch:17 step:15982 [D loss: 0.516985, acc.: 71.88%] [G loss: 0.627325]\n",
      "epoch:17 step:15983 [D loss: 0.489046, acc.: 78.12%] [G loss: 0.826406]\n",
      "epoch:17 step:15984 [D loss: 0.591443, acc.: 70.31%] [G loss: 0.670496]\n",
      "epoch:17 step:15985 [D loss: 0.511536, acc.: 75.78%] [G loss: 0.712332]\n",
      "epoch:17 step:15986 [D loss: 0.529594, acc.: 71.09%] [G loss: 0.819005]\n",
      "epoch:17 step:15987 [D loss: 0.582827, acc.: 62.50%] [G loss: 0.768229]\n",
      "epoch:17 step:15988 [D loss: 0.478478, acc.: 75.78%] [G loss: 0.961361]\n",
      "epoch:17 step:15989 [D loss: 0.614810, acc.: 61.72%] [G loss: 0.539536]\n",
      "epoch:17 step:15990 [D loss: 0.508757, acc.: 70.31%] [G loss: 0.598493]\n",
      "epoch:17 step:15991 [D loss: 0.541578, acc.: 75.00%] [G loss: 0.558978]\n",
      "epoch:17 step:15992 [D loss: 0.542208, acc.: 69.53%] [G loss: 0.547416]\n",
      "epoch:17 step:15993 [D loss: 0.565050, acc.: 72.66%] [G loss: 0.543670]\n",
      "epoch:17 step:15994 [D loss: 0.559057, acc.: 70.31%] [G loss: 0.569131]\n",
      "epoch:17 step:15995 [D loss: 0.544399, acc.: 72.66%] [G loss: 0.599934]\n",
      "epoch:17 step:15996 [D loss: 0.521603, acc.: 72.66%] [G loss: 0.586570]\n",
      "epoch:17 step:15997 [D loss: 0.511967, acc.: 75.78%] [G loss: 0.610648]\n",
      "epoch:17 step:15998 [D loss: 0.505471, acc.: 77.34%] [G loss: 0.594861]\n",
      "epoch:17 step:15999 [D loss: 0.505603, acc.: 73.44%] [G loss: 0.801275]\n",
      "epoch:17 step:16000 [D loss: 0.517710, acc.: 69.53%] [G loss: 0.613085]\n",
      "epoch:17 step:16001 [D loss: 0.525571, acc.: 75.00%] [G loss: 0.587677]\n",
      "epoch:17 step:16002 [D loss: 0.512231, acc.: 74.22%] [G loss: 0.681602]\n",
      "epoch:17 step:16003 [D loss: 0.466420, acc.: 79.69%] [G loss: 0.657033]\n",
      "epoch:17 step:16004 [D loss: 0.636034, acc.: 63.28%] [G loss: 0.647697]\n",
      "epoch:17 step:16005 [D loss: 0.456692, acc.: 82.81%] [G loss: 0.693153]\n",
      "epoch:17 step:16006 [D loss: 0.418182, acc.: 75.00%] [G loss: 0.808165]\n",
      "epoch:17 step:16007 [D loss: 0.581501, acc.: 70.31%] [G loss: 0.634188]\n",
      "epoch:17 step:16008 [D loss: 0.522456, acc.: 76.56%] [G loss: 0.704660]\n",
      "epoch:17 step:16009 [D loss: 0.470751, acc.: 78.12%] [G loss: 0.844066]\n",
      "epoch:17 step:16010 [D loss: 0.504557, acc.: 67.97%] [G loss: 0.739835]\n",
      "epoch:17 step:16011 [D loss: 0.546367, acc.: 67.19%] [G loss: 0.734492]\n",
      "epoch:17 step:16012 [D loss: 0.488073, acc.: 76.56%] [G loss: 0.828089]\n",
      "epoch:17 step:16013 [D loss: 0.528594, acc.: 68.75%] [G loss: 0.618362]\n",
      "epoch:17 step:16014 [D loss: 0.585175, acc.: 71.09%] [G loss: 0.529957]\n",
      "epoch:17 step:16015 [D loss: 0.539951, acc.: 71.09%] [G loss: 0.635307]\n",
      "epoch:17 step:16016 [D loss: 0.493809, acc.: 74.22%] [G loss: 0.647052]\n",
      "epoch:17 step:16017 [D loss: 0.490753, acc.: 79.69%] [G loss: 0.644331]\n",
      "epoch:17 step:16018 [D loss: 0.498168, acc.: 71.88%] [G loss: 0.806527]\n",
      "epoch:17 step:16019 [D loss: 0.512838, acc.: 75.78%] [G loss: 0.704924]\n",
      "epoch:17 step:16020 [D loss: 0.567088, acc.: 71.09%] [G loss: 0.638229]\n",
      "epoch:17 step:16021 [D loss: 0.468327, acc.: 78.91%] [G loss: 0.615493]\n",
      "epoch:17 step:16022 [D loss: 0.468600, acc.: 78.91%] [G loss: 0.602569]\n",
      "epoch:17 step:16023 [D loss: 0.496601, acc.: 72.66%] [G loss: 0.855033]\n",
      "epoch:17 step:16024 [D loss: 0.507525, acc.: 71.09%] [G loss: 0.856058]\n",
      "epoch:17 step:16025 [D loss: 0.485212, acc.: 76.56%] [G loss: 0.684160]\n",
      "epoch:17 step:16026 [D loss: 0.584757, acc.: 65.62%] [G loss: 0.682710]\n",
      "epoch:17 step:16027 [D loss: 0.545622, acc.: 71.09%] [G loss: 0.748851]\n",
      "epoch:17 step:16028 [D loss: 0.558348, acc.: 73.44%] [G loss: 0.872612]\n",
      "epoch:17 step:16029 [D loss: 0.521613, acc.: 71.88%] [G loss: 0.780986]\n",
      "epoch:17 step:16030 [D loss: 0.526484, acc.: 73.44%] [G loss: 0.790921]\n",
      "epoch:17 step:16031 [D loss: 0.592610, acc.: 65.62%] [G loss: 0.715359]\n",
      "epoch:17 step:16032 [D loss: 0.519450, acc.: 72.66%] [G loss: 0.637882]\n",
      "epoch:17 step:16033 [D loss: 0.486191, acc.: 75.78%] [G loss: 0.666858]\n",
      "epoch:17 step:16034 [D loss: 0.627696, acc.: 62.50%] [G loss: 0.601751]\n",
      "epoch:17 step:16035 [D loss: 0.560491, acc.: 71.09%] [G loss: 0.620087]\n",
      "epoch:17 step:16036 [D loss: 0.567559, acc.: 64.84%] [G loss: 0.656554]\n",
      "epoch:17 step:16037 [D loss: 0.630399, acc.: 59.38%] [G loss: 0.679212]\n",
      "epoch:17 step:16038 [D loss: 0.562914, acc.: 68.75%] [G loss: 0.626338]\n",
      "epoch:17 step:16039 [D loss: 0.580688, acc.: 71.09%] [G loss: 0.685457]\n",
      "epoch:17 step:16040 [D loss: 0.499810, acc.: 73.44%] [G loss: 0.656470]\n",
      "epoch:17 step:16041 [D loss: 0.502408, acc.: 75.00%] [G loss: 0.771300]\n",
      "epoch:17 step:16042 [D loss: 0.497338, acc.: 77.34%] [G loss: 0.649358]\n",
      "epoch:17 step:16043 [D loss: 0.521194, acc.: 75.78%] [G loss: 0.560993]\n",
      "epoch:17 step:16044 [D loss: 0.511892, acc.: 72.66%] [G loss: 0.776961]\n",
      "epoch:17 step:16045 [D loss: 0.491409, acc.: 74.22%] [G loss: 0.807432]\n",
      "epoch:17 step:16046 [D loss: 0.534956, acc.: 69.53%] [G loss: 0.807365]\n",
      "epoch:17 step:16047 [D loss: 0.548946, acc.: 68.75%] [G loss: 0.728406]\n",
      "epoch:17 step:16048 [D loss: 0.402252, acc.: 83.59%] [G loss: 0.938428]\n",
      "epoch:17 step:16049 [D loss: 0.542937, acc.: 73.44%] [G loss: 0.715404]\n",
      "epoch:17 step:16050 [D loss: 0.498917, acc.: 75.78%] [G loss: 0.657224]\n",
      "epoch:17 step:16051 [D loss: 0.553696, acc.: 78.12%] [G loss: 0.742879]\n",
      "epoch:17 step:16052 [D loss: 0.507065, acc.: 71.88%] [G loss: 0.708830]\n",
      "epoch:17 step:16053 [D loss: 0.560411, acc.: 71.88%] [G loss: 0.762613]\n",
      "epoch:17 step:16054 [D loss: 0.580141, acc.: 67.97%] [G loss: 0.641879]\n",
      "epoch:17 step:16055 [D loss: 0.496589, acc.: 75.00%] [G loss: 0.740188]\n",
      "epoch:17 step:16056 [D loss: 0.481134, acc.: 71.09%] [G loss: 0.754629]\n",
      "epoch:17 step:16057 [D loss: 0.498936, acc.: 66.41%] [G loss: 0.746065]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:17 step:16058 [D loss: 0.587529, acc.: 68.75%] [G loss: 0.685334]\n",
      "epoch:17 step:16059 [D loss: 0.497734, acc.: 68.75%] [G loss: 0.751016]\n",
      "epoch:17 step:16060 [D loss: 0.463210, acc.: 78.12%] [G loss: 0.606407]\n",
      "epoch:17 step:16061 [D loss: 0.577843, acc.: 69.53%] [G loss: 0.691936]\n",
      "epoch:17 step:16062 [D loss: 0.567599, acc.: 67.97%] [G loss: 0.656657]\n",
      "epoch:17 step:16063 [D loss: 0.509199, acc.: 76.56%] [G loss: 0.683702]\n",
      "epoch:17 step:16064 [D loss: 0.512577, acc.: 74.22%] [G loss: 0.771213]\n",
      "epoch:17 step:16065 [D loss: 0.522227, acc.: 74.22%] [G loss: 0.741903]\n",
      "epoch:17 step:16066 [D loss: 0.603184, acc.: 64.84%] [G loss: 0.606461]\n",
      "epoch:17 step:16067 [D loss: 0.510321, acc.: 76.56%] [G loss: 0.694577]\n",
      "epoch:17 step:16068 [D loss: 0.587618, acc.: 64.84%] [G loss: 0.819192]\n",
      "epoch:17 step:16069 [D loss: 0.585579, acc.: 66.41%] [G loss: 0.593675]\n",
      "epoch:17 step:16070 [D loss: 0.489632, acc.: 74.22%] [G loss: 0.636004]\n",
      "epoch:17 step:16071 [D loss: 0.513543, acc.: 69.53%] [G loss: 0.639059]\n",
      "epoch:17 step:16072 [D loss: 0.632495, acc.: 60.16%] [G loss: 0.491663]\n",
      "epoch:17 step:16073 [D loss: 0.492908, acc.: 75.78%] [G loss: 0.789657]\n",
      "epoch:17 step:16074 [D loss: 0.566318, acc.: 64.84%] [G loss: 0.715719]\n",
      "epoch:17 step:16075 [D loss: 0.495195, acc.: 75.78%] [G loss: 0.714858]\n",
      "epoch:17 step:16076 [D loss: 0.651418, acc.: 67.97%] [G loss: 0.650525]\n",
      "epoch:17 step:16077 [D loss: 0.525891, acc.: 71.88%] [G loss: 0.588106]\n",
      "epoch:17 step:16078 [D loss: 0.527020, acc.: 71.88%] [G loss: 0.503383]\n",
      "epoch:17 step:16079 [D loss: 0.591735, acc.: 65.62%] [G loss: 0.542808]\n",
      "epoch:17 step:16080 [D loss: 0.533665, acc.: 72.66%] [G loss: 0.629272]\n",
      "epoch:17 step:16081 [D loss: 0.490720, acc.: 75.00%] [G loss: 0.905022]\n",
      "epoch:17 step:16082 [D loss: 0.591436, acc.: 65.62%] [G loss: 0.747103]\n",
      "epoch:17 step:16083 [D loss: 0.513030, acc.: 73.44%] [G loss: 0.630556]\n",
      "epoch:17 step:16084 [D loss: 0.468595, acc.: 78.91%] [G loss: 0.714929]\n",
      "epoch:17 step:16085 [D loss: 0.460000, acc.: 77.34%] [G loss: 0.678414]\n",
      "epoch:17 step:16086 [D loss: 0.563125, acc.: 71.09%] [G loss: 0.609861]\n",
      "epoch:17 step:16087 [D loss: 0.544704, acc.: 71.88%] [G loss: 0.660276]\n",
      "epoch:17 step:16088 [D loss: 0.547987, acc.: 65.62%] [G loss: 0.609666]\n",
      "epoch:17 step:16089 [D loss: 0.617236, acc.: 62.50%] [G loss: 0.576689]\n",
      "epoch:17 step:16090 [D loss: 0.524298, acc.: 71.88%] [G loss: 0.705522]\n",
      "epoch:17 step:16091 [D loss: 0.471203, acc.: 75.78%] [G loss: 0.622977]\n",
      "epoch:17 step:16092 [D loss: 0.572954, acc.: 69.53%] [G loss: 0.628481]\n",
      "epoch:17 step:16093 [D loss: 0.515044, acc.: 75.00%] [G loss: 0.827761]\n",
      "epoch:17 step:16094 [D loss: 0.504552, acc.: 77.34%] [G loss: 0.632573]\n",
      "epoch:17 step:16095 [D loss: 0.519863, acc.: 72.66%] [G loss: 0.634185]\n",
      "epoch:17 step:16096 [D loss: 0.537598, acc.: 69.53%] [G loss: 0.594665]\n",
      "epoch:17 step:16097 [D loss: 0.546589, acc.: 71.09%] [G loss: 0.468654]\n",
      "epoch:17 step:16098 [D loss: 0.572183, acc.: 66.41%] [G loss: 0.556179]\n",
      "epoch:17 step:16099 [D loss: 0.509823, acc.: 75.00%] [G loss: 0.575902]\n",
      "epoch:17 step:16100 [D loss: 0.574139, acc.: 68.75%] [G loss: 0.611412]\n",
      "epoch:17 step:16101 [D loss: 0.522532, acc.: 72.66%] [G loss: 0.538119]\n",
      "epoch:17 step:16102 [D loss: 0.486641, acc.: 75.78%] [G loss: 0.576141]\n",
      "epoch:17 step:16103 [D loss: 0.670151, acc.: 63.28%] [G loss: 0.741992]\n",
      "epoch:17 step:16104 [D loss: 0.588151, acc.: 62.50%] [G loss: 0.492480]\n",
      "epoch:17 step:16105 [D loss: 0.540462, acc.: 71.09%] [G loss: 0.587264]\n",
      "epoch:17 step:16106 [D loss: 0.503543, acc.: 74.22%] [G loss: 0.621931]\n",
      "epoch:17 step:16107 [D loss: 0.552514, acc.: 66.41%] [G loss: 0.602026]\n",
      "epoch:17 step:16108 [D loss: 0.505868, acc.: 73.44%] [G loss: 0.685627]\n",
      "epoch:17 step:16109 [D loss: 0.613702, acc.: 66.41%] [G loss: 0.524730]\n",
      "epoch:17 step:16110 [D loss: 0.552563, acc.: 67.19%] [G loss: 0.483408]\n",
      "epoch:17 step:16111 [D loss: 0.522827, acc.: 73.44%] [G loss: 0.679306]\n",
      "epoch:17 step:16112 [D loss: 0.613250, acc.: 64.84%] [G loss: 0.677734]\n",
      "epoch:17 step:16113 [D loss: 0.475366, acc.: 80.47%] [G loss: 0.652671]\n",
      "epoch:17 step:16114 [D loss: 0.605833, acc.: 67.19%] [G loss: 0.693083]\n",
      "epoch:17 step:16115 [D loss: 0.559241, acc.: 67.97%] [G loss: 0.636910]\n",
      "epoch:17 step:16116 [D loss: 0.623774, acc.: 62.50%] [G loss: 0.425585]\n",
      "epoch:17 step:16117 [D loss: 0.560000, acc.: 65.62%] [G loss: 0.517334]\n",
      "epoch:17 step:16118 [D loss: 0.539798, acc.: 73.44%] [G loss: 0.540100]\n",
      "epoch:17 step:16119 [D loss: 0.506883, acc.: 75.00%] [G loss: 0.725613]\n",
      "epoch:17 step:16120 [D loss: 0.515274, acc.: 71.88%] [G loss: 0.676605]\n",
      "epoch:17 step:16121 [D loss: 0.510787, acc.: 75.00%] [G loss: 0.837574]\n",
      "epoch:17 step:16122 [D loss: 0.581513, acc.: 67.97%] [G loss: 0.573782]\n",
      "epoch:17 step:16123 [D loss: 0.471923, acc.: 75.78%] [G loss: 0.780485]\n",
      "epoch:17 step:16124 [D loss: 0.520883, acc.: 73.44%] [G loss: 0.644278]\n",
      "epoch:17 step:16125 [D loss: 0.585247, acc.: 68.75%] [G loss: 0.633596]\n",
      "epoch:17 step:16126 [D loss: 0.519267, acc.: 71.88%] [G loss: 0.617349]\n",
      "epoch:17 step:16127 [D loss: 0.461444, acc.: 76.56%] [G loss: 0.764515]\n",
      "epoch:17 step:16128 [D loss: 0.466283, acc.: 79.69%] [G loss: 0.840836]\n",
      "epoch:17 step:16129 [D loss: 0.638060, acc.: 64.06%] [G loss: 0.731870]\n",
      "epoch:17 step:16130 [D loss: 0.564218, acc.: 67.97%] [G loss: 0.661663]\n",
      "epoch:17 step:16131 [D loss: 0.524819, acc.: 74.22%] [G loss: 0.710008]\n",
      "epoch:17 step:16132 [D loss: 0.563313, acc.: 68.75%] [G loss: 0.498473]\n",
      "epoch:17 step:16133 [D loss: 0.557888, acc.: 70.31%] [G loss: 0.621122]\n",
      "epoch:17 step:16134 [D loss: 0.504508, acc.: 72.66%] [G loss: 0.652715]\n",
      "epoch:17 step:16135 [D loss: 0.512047, acc.: 71.88%] [G loss: 0.583189]\n",
      "epoch:17 step:16136 [D loss: 0.451245, acc.: 79.69%] [G loss: 0.837274]\n",
      "epoch:17 step:16137 [D loss: 0.435814, acc.: 78.91%] [G loss: 0.816511]\n",
      "epoch:17 step:16138 [D loss: 0.475613, acc.: 75.78%] [G loss: 0.675448]\n",
      "epoch:17 step:16139 [D loss: 0.643415, acc.: 63.28%] [G loss: 0.613256]\n",
      "epoch:17 step:16140 [D loss: 0.580392, acc.: 69.53%] [G loss: 0.536575]\n",
      "epoch:17 step:16141 [D loss: 0.566010, acc.: 72.66%] [G loss: 0.663884]\n",
      "epoch:17 step:16142 [D loss: 0.470200, acc.: 73.44%] [G loss: 0.724653]\n",
      "epoch:17 step:16143 [D loss: 0.637336, acc.: 66.41%] [G loss: 0.631881]\n",
      "epoch:17 step:16144 [D loss: 0.558731, acc.: 67.97%] [G loss: 0.658726]\n",
      "epoch:17 step:16145 [D loss: 0.513571, acc.: 71.09%] [G loss: 0.682947]\n",
      "epoch:17 step:16146 [D loss: 0.512222, acc.: 70.31%] [G loss: 0.622803]\n",
      "epoch:17 step:16147 [D loss: 0.553244, acc.: 74.22%] [G loss: 0.641724]\n",
      "epoch:17 step:16148 [D loss: 0.512951, acc.: 78.12%] [G loss: 0.683205]\n",
      "epoch:17 step:16149 [D loss: 0.676796, acc.: 64.06%] [G loss: 0.577245]\n",
      "epoch:17 step:16150 [D loss: 0.525612, acc.: 75.00%] [G loss: 0.601342]\n",
      "epoch:17 step:16151 [D loss: 0.508269, acc.: 72.66%] [G loss: 0.635127]\n",
      "epoch:17 step:16152 [D loss: 0.495014, acc.: 74.22%] [G loss: 0.768528]\n",
      "epoch:17 step:16153 [D loss: 0.500239, acc.: 77.34%] [G loss: 0.584387]\n",
      "epoch:17 step:16154 [D loss: 0.534765, acc.: 74.22%] [G loss: 0.847468]\n",
      "epoch:17 step:16155 [D loss: 0.596560, acc.: 68.75%] [G loss: 0.601347]\n",
      "epoch:17 step:16156 [D loss: 0.552776, acc.: 70.31%] [G loss: 0.634498]\n",
      "epoch:17 step:16157 [D loss: 0.607332, acc.: 64.06%] [G loss: 0.491819]\n",
      "epoch:17 step:16158 [D loss: 0.523474, acc.: 75.78%] [G loss: 0.723111]\n",
      "epoch:17 step:16159 [D loss: 0.476574, acc.: 78.12%] [G loss: 0.861623]\n",
      "epoch:17 step:16160 [D loss: 0.446299, acc.: 79.69%] [G loss: 0.762306]\n",
      "epoch:17 step:16161 [D loss: 0.462091, acc.: 76.56%] [G loss: 1.051575]\n",
      "epoch:17 step:16162 [D loss: 0.546282, acc.: 67.97%] [G loss: 0.968075]\n",
      "epoch:17 step:16163 [D loss: 0.562386, acc.: 67.19%] [G loss: 0.696381]\n",
      "epoch:17 step:16164 [D loss: 0.525333, acc.: 71.09%] [G loss: 0.723939]\n",
      "epoch:17 step:16165 [D loss: 0.487387, acc.: 78.91%] [G loss: 0.630699]\n",
      "epoch:17 step:16166 [D loss: 0.503739, acc.: 76.56%] [G loss: 0.718678]\n",
      "epoch:17 step:16167 [D loss: 0.586366, acc.: 64.06%] [G loss: 0.669577]\n",
      "epoch:17 step:16168 [D loss: 0.487008, acc.: 76.56%] [G loss: 0.658529]\n",
      "epoch:17 step:16169 [D loss: 0.530992, acc.: 71.09%] [G loss: 0.801305]\n",
      "epoch:17 step:16170 [D loss: 0.515248, acc.: 70.31%] [G loss: 0.659818]\n",
      "epoch:17 step:16171 [D loss: 0.483198, acc.: 74.22%] [G loss: 0.585735]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:17 step:16172 [D loss: 0.509763, acc.: 74.22%] [G loss: 0.768136]\n",
      "epoch:17 step:16173 [D loss: 0.464957, acc.: 77.34%] [G loss: 0.810950]\n",
      "epoch:17 step:16174 [D loss: 0.500623, acc.: 76.56%] [G loss: 0.678684]\n",
      "epoch:17 step:16175 [D loss: 0.466549, acc.: 76.56%] [G loss: 1.011118]\n",
      "epoch:17 step:16176 [D loss: 0.467337, acc.: 75.78%] [G loss: 0.798306]\n",
      "epoch:17 step:16177 [D loss: 0.468989, acc.: 77.34%] [G loss: 0.852791]\n",
      "epoch:17 step:16178 [D loss: 0.521039, acc.: 71.88%] [G loss: 0.687872]\n",
      "epoch:17 step:16179 [D loss: 0.575367, acc.: 71.88%] [G loss: 0.694358]\n",
      "epoch:17 step:16180 [D loss: 0.600050, acc.: 63.28%] [G loss: 0.758994]\n",
      "epoch:17 step:16181 [D loss: 0.486126, acc.: 75.00%] [G loss: 0.753266]\n",
      "epoch:17 step:16182 [D loss: 0.582603, acc.: 73.44%] [G loss: 0.626779]\n",
      "epoch:17 step:16183 [D loss: 0.528713, acc.: 68.75%] [G loss: 0.695714]\n",
      "epoch:17 step:16184 [D loss: 0.565614, acc.: 62.50%] [G loss: 0.668265]\n",
      "epoch:17 step:16185 [D loss: 0.539728, acc.: 71.88%] [G loss: 0.657916]\n",
      "epoch:17 step:16186 [D loss: 0.605377, acc.: 65.62%] [G loss: 0.599119]\n",
      "epoch:17 step:16187 [D loss: 0.484163, acc.: 76.56%] [G loss: 0.641207]\n",
      "epoch:17 step:16188 [D loss: 0.476318, acc.: 78.12%] [G loss: 0.700298]\n",
      "epoch:17 step:16189 [D loss: 0.623409, acc.: 61.72%] [G loss: 0.555286]\n",
      "epoch:17 step:16190 [D loss: 0.521890, acc.: 73.44%] [G loss: 0.662203]\n",
      "epoch:17 step:16191 [D loss: 0.555360, acc.: 74.22%] [G loss: 0.825205]\n",
      "epoch:17 step:16192 [D loss: 0.627166, acc.: 64.84%] [G loss: 0.782945]\n",
      "epoch:17 step:16193 [D loss: 0.530264, acc.: 72.66%] [G loss: 0.605759]\n",
      "epoch:17 step:16194 [D loss: 0.551636, acc.: 68.75%] [G loss: 0.567844]\n",
      "epoch:17 step:16195 [D loss: 0.572485, acc.: 66.41%] [G loss: 0.650061]\n",
      "epoch:17 step:16196 [D loss: 0.539904, acc.: 71.88%] [G loss: 0.758209]\n",
      "epoch:17 step:16197 [D loss: 0.560606, acc.: 73.44%] [G loss: 0.637831]\n",
      "epoch:17 step:16198 [D loss: 0.566395, acc.: 68.75%] [G loss: 0.550521]\n",
      "epoch:17 step:16199 [D loss: 0.513919, acc.: 76.56%] [G loss: 0.655243]\n",
      "epoch:17 step:16200 [D loss: 0.512645, acc.: 71.09%] [G loss: 0.677101]\n",
      "epoch:17 step:16201 [D loss: 0.545740, acc.: 73.44%] [G loss: 0.817018]\n",
      "epoch:17 step:16202 [D loss: 0.456548, acc.: 76.56%] [G loss: 0.802507]\n",
      "epoch:17 step:16203 [D loss: 0.504857, acc.: 72.66%] [G loss: 0.605060]\n",
      "epoch:17 step:16204 [D loss: 0.508663, acc.: 70.31%] [G loss: 0.713229]\n",
      "epoch:17 step:16205 [D loss: 0.409762, acc.: 84.38%] [G loss: 0.738224]\n",
      "epoch:17 step:16206 [D loss: 0.671336, acc.: 59.38%] [G loss: 0.578694]\n",
      "epoch:17 step:16207 [D loss: 0.557285, acc.: 72.66%] [G loss: 0.547954]\n",
      "epoch:17 step:16208 [D loss: 0.595398, acc.: 64.06%] [G loss: 0.614288]\n",
      "epoch:17 step:16209 [D loss: 0.520459, acc.: 71.09%] [G loss: 0.741655]\n",
      "epoch:17 step:16210 [D loss: 0.577955, acc.: 65.62%] [G loss: 0.637262]\n",
      "epoch:17 step:16211 [D loss: 0.584234, acc.: 66.41%] [G loss: 0.669227]\n",
      "epoch:17 step:16212 [D loss: 0.512715, acc.: 75.78%] [G loss: 0.665779]\n",
      "epoch:17 step:16213 [D loss: 0.578633, acc.: 64.06%] [G loss: 0.614000]\n",
      "epoch:17 step:16214 [D loss: 0.520384, acc.: 71.09%] [G loss: 0.593912]\n",
      "epoch:17 step:16215 [D loss: 0.477106, acc.: 78.91%] [G loss: 0.777180]\n",
      "epoch:17 step:16216 [D loss: 0.590299, acc.: 67.19%] [G loss: 0.657339]\n",
      "epoch:17 step:16217 [D loss: 0.542673, acc.: 68.75%] [G loss: 0.657571]\n",
      "epoch:17 step:16218 [D loss: 0.512594, acc.: 73.44%] [G loss: 0.546640]\n",
      "epoch:17 step:16219 [D loss: 0.561607, acc.: 67.97%] [G loss: 0.551751]\n",
      "epoch:17 step:16220 [D loss: 0.538050, acc.: 75.78%] [G loss: 0.616556]\n",
      "epoch:17 step:16221 [D loss: 0.521527, acc.: 73.44%] [G loss: 0.689064]\n",
      "epoch:17 step:16222 [D loss: 0.548275, acc.: 69.53%] [G loss: 0.717788]\n",
      "epoch:17 step:16223 [D loss: 0.564709, acc.: 67.19%] [G loss: 0.477568]\n",
      "epoch:17 step:16224 [D loss: 0.570420, acc.: 67.19%] [G loss: 0.537828]\n",
      "epoch:17 step:16225 [D loss: 0.471615, acc.: 75.00%] [G loss: 0.754614]\n",
      "epoch:17 step:16226 [D loss: 0.526416, acc.: 66.41%] [G loss: 0.743705]\n",
      "epoch:17 step:16227 [D loss: 0.475744, acc.: 75.78%] [G loss: 0.798695]\n",
      "epoch:17 step:16228 [D loss: 0.482339, acc.: 73.44%] [G loss: 0.675255]\n",
      "epoch:17 step:16229 [D loss: 0.490753, acc.: 74.22%] [G loss: 0.809552]\n",
      "epoch:17 step:16230 [D loss: 0.580050, acc.: 71.88%] [G loss: 0.743587]\n",
      "epoch:17 step:16231 [D loss: 0.510653, acc.: 74.22%] [G loss: 0.669087]\n",
      "epoch:17 step:16232 [D loss: 0.590968, acc.: 64.06%] [G loss: 0.691966]\n",
      "epoch:17 step:16233 [D loss: 0.454740, acc.: 78.91%] [G loss: 0.849032]\n",
      "epoch:17 step:16234 [D loss: 0.571449, acc.: 68.75%] [G loss: 0.603120]\n",
      "epoch:17 step:16235 [D loss: 0.561227, acc.: 75.00%] [G loss: 0.757255]\n",
      "epoch:17 step:16236 [D loss: 0.525474, acc.: 73.44%] [G loss: 0.627668]\n",
      "epoch:17 step:16237 [D loss: 0.559666, acc.: 69.53%] [G loss: 0.639487]\n",
      "epoch:17 step:16238 [D loss: 0.465827, acc.: 77.34%] [G loss: 0.809092]\n",
      "epoch:17 step:16239 [D loss: 0.555658, acc.: 69.53%] [G loss: 0.677351]\n",
      "epoch:17 step:16240 [D loss: 0.485754, acc.: 73.44%] [G loss: 0.668063]\n",
      "epoch:17 step:16241 [D loss: 0.482710, acc.: 72.66%] [G loss: 0.843032]\n",
      "epoch:17 step:16242 [D loss: 0.503717, acc.: 73.44%] [G loss: 0.862526]\n",
      "epoch:17 step:16243 [D loss: 0.446382, acc.: 80.47%] [G loss: 1.048076]\n",
      "epoch:17 step:16244 [D loss: 0.462201, acc.: 82.03%] [G loss: 1.090297]\n",
      "epoch:17 step:16245 [D loss: 0.658939, acc.: 64.06%] [G loss: 0.640828]\n",
      "epoch:17 step:16246 [D loss: 0.625001, acc.: 64.84%] [G loss: 0.725353]\n",
      "epoch:17 step:16247 [D loss: 0.575520, acc.: 71.09%] [G loss: 0.702602]\n",
      "epoch:17 step:16248 [D loss: 0.560724, acc.: 67.19%] [G loss: 0.619167]\n",
      "epoch:17 step:16249 [D loss: 0.530947, acc.: 72.66%] [G loss: 0.453408]\n",
      "epoch:17 step:16250 [D loss: 0.493599, acc.: 73.44%] [G loss: 0.662438]\n",
      "epoch:17 step:16251 [D loss: 0.608431, acc.: 69.53%] [G loss: 0.566535]\n",
      "epoch:17 step:16252 [D loss: 0.592648, acc.: 64.84%] [G loss: 0.551134]\n",
      "epoch:17 step:16253 [D loss: 0.535536, acc.: 71.09%] [G loss: 0.440342]\n",
      "epoch:17 step:16254 [D loss: 0.535459, acc.: 72.66%] [G loss: 0.553195]\n",
      "epoch:17 step:16255 [D loss: 0.471994, acc.: 75.78%] [G loss: 0.563058]\n",
      "epoch:17 step:16256 [D loss: 0.521753, acc.: 75.00%] [G loss: 0.641804]\n",
      "epoch:17 step:16257 [D loss: 0.472862, acc.: 74.22%] [G loss: 0.631433]\n",
      "epoch:17 step:16258 [D loss: 0.536488, acc.: 70.31%] [G loss: 0.641161]\n",
      "epoch:17 step:16259 [D loss: 0.546365, acc.: 68.75%] [G loss: 0.701789]\n",
      "epoch:17 step:16260 [D loss: 0.558963, acc.: 71.09%] [G loss: 0.545982]\n",
      "epoch:17 step:16261 [D loss: 0.505081, acc.: 73.44%] [G loss: 0.590312]\n",
      "epoch:17 step:16262 [D loss: 0.458415, acc.: 82.81%] [G loss: 0.692437]\n",
      "epoch:17 step:16263 [D loss: 0.428619, acc.: 76.56%] [G loss: 0.914580]\n",
      "epoch:17 step:16264 [D loss: 0.447683, acc.: 82.03%] [G loss: 0.628406]\n",
      "epoch:17 step:16265 [D loss: 0.514038, acc.: 70.31%] [G loss: 0.781092]\n",
      "epoch:17 step:16266 [D loss: 0.505371, acc.: 73.44%] [G loss: 0.819447]\n",
      "epoch:17 step:16267 [D loss: 0.531037, acc.: 70.31%] [G loss: 0.619650]\n",
      "epoch:17 step:16268 [D loss: 0.569463, acc.: 66.41%] [G loss: 0.629988]\n",
      "epoch:17 step:16269 [D loss: 0.464195, acc.: 75.00%] [G loss: 0.569761]\n",
      "epoch:17 step:16270 [D loss: 0.588193, acc.: 67.97%] [G loss: 0.673646]\n",
      "epoch:17 step:16271 [D loss: 0.591005, acc.: 66.41%] [G loss: 0.742260]\n",
      "epoch:17 step:16272 [D loss: 0.542987, acc.: 73.44%] [G loss: 0.700498]\n",
      "epoch:17 step:16273 [D loss: 0.457173, acc.: 82.03%] [G loss: 1.010834]\n",
      "epoch:17 step:16274 [D loss: 0.579850, acc.: 63.28%] [G loss: 0.841539]\n",
      "epoch:17 step:16275 [D loss: 0.559393, acc.: 70.31%] [G loss: 0.851397]\n",
      "epoch:17 step:16276 [D loss: 0.407003, acc.: 79.69%] [G loss: 1.134002]\n",
      "epoch:17 step:16277 [D loss: 0.649403, acc.: 65.62%] [G loss: 0.769706]\n",
      "epoch:17 step:16278 [D loss: 0.703662, acc.: 55.47%] [G loss: 0.442471]\n",
      "epoch:17 step:16279 [D loss: 0.461016, acc.: 78.12%] [G loss: 0.704576]\n",
      "epoch:17 step:16280 [D loss: 0.525440, acc.: 74.22%] [G loss: 0.596782]\n",
      "epoch:17 step:16281 [D loss: 0.558923, acc.: 70.31%] [G loss: 0.640458]\n",
      "epoch:17 step:16282 [D loss: 0.565284, acc.: 71.09%] [G loss: 0.732456]\n",
      "epoch:17 step:16283 [D loss: 0.397588, acc.: 80.47%] [G loss: 0.934958]\n",
      "epoch:17 step:16284 [D loss: 0.499151, acc.: 73.44%] [G loss: 0.826677]\n",
      "epoch:17 step:16285 [D loss: 0.542432, acc.: 66.41%] [G loss: 0.834910]\n",
      "epoch:17 step:16286 [D loss: 0.461554, acc.: 77.34%] [G loss: 0.738111]\n",
      "epoch:17 step:16287 [D loss: 0.408730, acc.: 82.03%] [G loss: 0.883835]\n",
      "epoch:17 step:16288 [D loss: 0.491671, acc.: 76.56%] [G loss: 0.804877]\n",
      "epoch:17 step:16289 [D loss: 0.503906, acc.: 72.66%] [G loss: 0.670954]\n",
      "epoch:17 step:16290 [D loss: 0.521242, acc.: 70.31%] [G loss: 0.809139]\n",
      "epoch:17 step:16291 [D loss: 0.607590, acc.: 64.84%] [G loss: 0.612169]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:17 step:16292 [D loss: 0.548284, acc.: 72.66%] [G loss: 0.659586]\n",
      "epoch:17 step:16293 [D loss: 0.570107, acc.: 70.31%] [G loss: 0.795149]\n",
      "epoch:17 step:16294 [D loss: 0.544138, acc.: 69.53%] [G loss: 0.791285]\n",
      "epoch:17 step:16295 [D loss: 0.521894, acc.: 72.66%] [G loss: 0.692189]\n",
      "epoch:17 step:16296 [D loss: 0.528966, acc.: 70.31%] [G loss: 0.676653]\n",
      "epoch:17 step:16297 [D loss: 0.552290, acc.: 69.53%] [G loss: 0.838659]\n",
      "epoch:17 step:16298 [D loss: 0.533853, acc.: 68.75%] [G loss: 0.611897]\n",
      "epoch:17 step:16299 [D loss: 0.530114, acc.: 68.75%] [G loss: 0.725395]\n",
      "epoch:17 step:16300 [D loss: 0.502843, acc.: 73.44%] [G loss: 0.702181]\n",
      "epoch:17 step:16301 [D loss: 0.543368, acc.: 71.09%] [G loss: 0.665080]\n",
      "epoch:17 step:16302 [D loss: 0.498873, acc.: 72.66%] [G loss: 0.684229]\n",
      "epoch:17 step:16303 [D loss: 0.459034, acc.: 75.78%] [G loss: 0.814485]\n",
      "epoch:17 step:16304 [D loss: 0.571342, acc.: 70.31%] [G loss: 0.716988]\n",
      "epoch:17 step:16305 [D loss: 0.702175, acc.: 63.28%] [G loss: 0.555502]\n",
      "epoch:17 step:16306 [D loss: 0.594532, acc.: 60.94%] [G loss: 0.451363]\n",
      "epoch:17 step:16307 [D loss: 0.542890, acc.: 69.53%] [G loss: 0.629297]\n",
      "epoch:17 step:16308 [D loss: 0.539247, acc.: 73.44%] [G loss: 0.535520]\n",
      "epoch:17 step:16309 [D loss: 0.547509, acc.: 75.00%] [G loss: 0.573231]\n",
      "epoch:17 step:16310 [D loss: 0.449523, acc.: 80.47%] [G loss: 0.613695]\n",
      "epoch:17 step:16311 [D loss: 0.511138, acc.: 75.00%] [G loss: 0.650873]\n",
      "epoch:17 step:16312 [D loss: 0.531059, acc.: 68.75%] [G loss: 0.736642]\n",
      "epoch:17 step:16313 [D loss: 0.579143, acc.: 71.09%] [G loss: 0.610461]\n",
      "epoch:17 step:16314 [D loss: 0.461829, acc.: 78.12%] [G loss: 0.640029]\n",
      "epoch:17 step:16315 [D loss: 0.584964, acc.: 68.75%] [G loss: 0.638694]\n",
      "epoch:17 step:16316 [D loss: 0.502733, acc.: 72.66%] [G loss: 0.599071]\n",
      "epoch:17 step:16317 [D loss: 0.529624, acc.: 74.22%] [G loss: 0.589674]\n",
      "epoch:17 step:16318 [D loss: 0.504257, acc.: 72.66%] [G loss: 0.630710]\n",
      "epoch:17 step:16319 [D loss: 0.588773, acc.: 65.62%] [G loss: 0.555684]\n",
      "epoch:17 step:16320 [D loss: 0.559924, acc.: 68.75%] [G loss: 0.562021]\n",
      "epoch:17 step:16321 [D loss: 0.458590, acc.: 76.56%] [G loss: 0.611831]\n",
      "epoch:17 step:16322 [D loss: 0.524902, acc.: 69.53%] [G loss: 0.735304]\n",
      "epoch:17 step:16323 [D loss: 0.559325, acc.: 69.53%] [G loss: 0.642323]\n",
      "epoch:17 step:16324 [D loss: 0.516312, acc.: 73.44%] [G loss: 0.645577]\n",
      "epoch:17 step:16325 [D loss: 0.568754, acc.: 67.97%] [G loss: 0.602498]\n",
      "epoch:17 step:16326 [D loss: 0.556991, acc.: 65.62%] [G loss: 0.580950]\n",
      "epoch:17 step:16327 [D loss: 0.466095, acc.: 73.44%] [G loss: 0.742299]\n",
      "epoch:17 step:16328 [D loss: 0.523538, acc.: 75.00%] [G loss: 0.822175]\n",
      "epoch:17 step:16329 [D loss: 0.652207, acc.: 62.50%] [G loss: 0.487231]\n",
      "epoch:17 step:16330 [D loss: 0.661591, acc.: 60.16%] [G loss: 0.564583]\n",
      "epoch:17 step:16331 [D loss: 0.499554, acc.: 74.22%] [G loss: 0.541432]\n",
      "epoch:17 step:16332 [D loss: 0.486091, acc.: 71.09%] [G loss: 0.724096]\n",
      "epoch:17 step:16333 [D loss: 0.560895, acc.: 71.09%] [G loss: 0.672130]\n",
      "epoch:17 step:16334 [D loss: 0.504971, acc.: 75.78%] [G loss: 0.709537]\n",
      "epoch:17 step:16335 [D loss: 0.504510, acc.: 74.22%] [G loss: 0.813580]\n",
      "epoch:17 step:16336 [D loss: 0.602317, acc.: 64.06%] [G loss: 0.720792]\n",
      "epoch:17 step:16337 [D loss: 0.590181, acc.: 64.84%] [G loss: 0.715218]\n",
      "epoch:17 step:16338 [D loss: 0.594556, acc.: 65.62%] [G loss: 0.753357]\n",
      "epoch:17 step:16339 [D loss: 0.579182, acc.: 64.06%] [G loss: 0.750567]\n",
      "epoch:17 step:16340 [D loss: 0.580891, acc.: 64.84%] [G loss: 0.548770]\n",
      "epoch:17 step:16341 [D loss: 0.579805, acc.: 65.62%] [G loss: 0.508185]\n",
      "epoch:17 step:16342 [D loss: 0.568874, acc.: 66.41%] [G loss: 0.537498]\n",
      "epoch:17 step:16343 [D loss: 0.528886, acc.: 73.44%] [G loss: 0.684674]\n",
      "epoch:17 step:16344 [D loss: 0.560289, acc.: 70.31%] [G loss: 0.720183]\n",
      "epoch:17 step:16345 [D loss: 0.467489, acc.: 77.34%] [G loss: 0.630864]\n",
      "epoch:17 step:16346 [D loss: 0.519125, acc.: 77.34%] [G loss: 0.692627]\n",
      "epoch:17 step:16347 [D loss: 0.598311, acc.: 65.62%] [G loss: 0.653213]\n",
      "epoch:17 step:16348 [D loss: 0.577199, acc.: 68.75%] [G loss: 0.516180]\n",
      "epoch:17 step:16349 [D loss: 0.573853, acc.: 64.84%] [G loss: 0.574719]\n",
      "epoch:17 step:16350 [D loss: 0.602577, acc.: 60.16%] [G loss: 0.583392]\n",
      "epoch:17 step:16351 [D loss: 0.586372, acc.: 74.22%] [G loss: 0.586002]\n",
      "epoch:17 step:16352 [D loss: 0.502305, acc.: 75.00%] [G loss: 0.693572]\n",
      "epoch:17 step:16353 [D loss: 0.534475, acc.: 70.31%] [G loss: 0.633109]\n",
      "epoch:17 step:16354 [D loss: 0.485802, acc.: 78.91%] [G loss: 0.681756]\n",
      "epoch:17 step:16355 [D loss: 0.455522, acc.: 78.91%] [G loss: 0.809805]\n",
      "epoch:17 step:16356 [D loss: 0.490831, acc.: 73.44%] [G loss: 0.840998]\n",
      "epoch:17 step:16357 [D loss: 0.517578, acc.: 71.88%] [G loss: 0.642684]\n",
      "epoch:17 step:16358 [D loss: 0.437415, acc.: 79.69%] [G loss: 0.936241]\n",
      "epoch:17 step:16359 [D loss: 0.479666, acc.: 78.12%] [G loss: 0.793617]\n",
      "epoch:17 step:16360 [D loss: 0.506724, acc.: 71.09%] [G loss: 0.608637]\n",
      "epoch:17 step:16361 [D loss: 0.551698, acc.: 71.09%] [G loss: 0.548464]\n",
      "epoch:17 step:16362 [D loss: 0.541845, acc.: 71.09%] [G loss: 0.552724]\n",
      "epoch:17 step:16363 [D loss: 0.521836, acc.: 69.53%] [G loss: 0.598183]\n",
      "epoch:17 step:16364 [D loss: 0.487026, acc.: 76.56%] [G loss: 0.756040]\n",
      "epoch:17 step:16365 [D loss: 0.479434, acc.: 79.69%] [G loss: 0.626692]\n",
      "epoch:17 step:16366 [D loss: 0.660297, acc.: 66.41%] [G loss: 0.613657]\n",
      "epoch:17 step:16367 [D loss: 0.591182, acc.: 64.84%] [G loss: 0.540255]\n",
      "epoch:17 step:16368 [D loss: 0.519630, acc.: 72.66%] [G loss: 0.808133]\n",
      "epoch:17 step:16369 [D loss: 0.487761, acc.: 75.00%] [G loss: 0.810963]\n",
      "epoch:17 step:16370 [D loss: 0.545548, acc.: 71.88%] [G loss: 0.726924]\n",
      "epoch:17 step:16371 [D loss: 0.498468, acc.: 72.66%] [G loss: 0.767647]\n",
      "epoch:17 step:16372 [D loss: 0.546648, acc.: 67.19%] [G loss: 0.712680]\n",
      "epoch:17 step:16373 [D loss: 0.525952, acc.: 75.00%] [G loss: 0.835990]\n",
      "epoch:17 step:16374 [D loss: 0.568234, acc.: 64.84%] [G loss: 0.624205]\n",
      "epoch:17 step:16375 [D loss: 0.494187, acc.: 71.88%] [G loss: 0.855638]\n",
      "epoch:17 step:16376 [D loss: 0.535042, acc.: 70.31%] [G loss: 0.825356]\n",
      "epoch:17 step:16377 [D loss: 0.558452, acc.: 70.31%] [G loss: 0.794782]\n",
      "epoch:17 step:16378 [D loss: 0.509148, acc.: 67.19%] [G loss: 0.614170]\n",
      "epoch:17 step:16379 [D loss: 0.521133, acc.: 74.22%] [G loss: 0.709055]\n",
      "epoch:17 step:16380 [D loss: 0.429116, acc.: 81.25%] [G loss: 0.798486]\n",
      "epoch:17 step:16381 [D loss: 0.469457, acc.: 74.22%] [G loss: 0.719825]\n",
      "epoch:17 step:16382 [D loss: 0.510902, acc.: 76.56%] [G loss: 0.700867]\n",
      "epoch:17 step:16383 [D loss: 0.539925, acc.: 72.66%] [G loss: 0.757867]\n",
      "epoch:17 step:16384 [D loss: 0.500157, acc.: 72.66%] [G loss: 0.660246]\n",
      "epoch:17 step:16385 [D loss: 0.588993, acc.: 61.72%] [G loss: 0.824402]\n",
      "epoch:17 step:16386 [D loss: 0.501654, acc.: 76.56%] [G loss: 0.916752]\n",
      "epoch:17 step:16387 [D loss: 0.671900, acc.: 61.72%] [G loss: 0.577919]\n",
      "epoch:17 step:16388 [D loss: 0.513515, acc.: 71.09%] [G loss: 0.796124]\n",
      "epoch:17 step:16389 [D loss: 0.535793, acc.: 64.84%] [G loss: 0.615559]\n",
      "epoch:17 step:16390 [D loss: 0.463493, acc.: 75.00%] [G loss: 0.860524]\n",
      "epoch:17 step:16391 [D loss: 0.549374, acc.: 67.19%] [G loss: 0.593051]\n",
      "epoch:17 step:16392 [D loss: 0.533479, acc.: 68.75%] [G loss: 0.782273]\n",
      "epoch:17 step:16393 [D loss: 0.488620, acc.: 76.56%] [G loss: 0.563187]\n",
      "epoch:17 step:16394 [D loss: 0.572713, acc.: 69.53%] [G loss: 0.553257]\n",
      "epoch:17 step:16395 [D loss: 0.532224, acc.: 67.19%] [G loss: 0.551249]\n",
      "epoch:17 step:16396 [D loss: 0.524797, acc.: 68.75%] [G loss: 0.600906]\n",
      "epoch:17 step:16397 [D loss: 0.520310, acc.: 71.88%] [G loss: 0.869445]\n",
      "epoch:17 step:16398 [D loss: 0.546509, acc.: 71.88%] [G loss: 0.688003]\n",
      "epoch:17 step:16399 [D loss: 0.556557, acc.: 75.00%] [G loss: 0.604624]\n",
      "epoch:17 step:16400 [D loss: 0.424750, acc.: 82.03%] [G loss: 0.821918]\n",
      "epoch:17 step:16401 [D loss: 0.470645, acc.: 80.47%] [G loss: 0.760024]\n",
      "epoch:17 step:16402 [D loss: 0.634467, acc.: 65.62%] [G loss: 0.638978]\n",
      "epoch:17 step:16403 [D loss: 0.565299, acc.: 67.19%] [G loss: 0.636136]\n",
      "epoch:17 step:16404 [D loss: 0.407537, acc.: 82.03%] [G loss: 0.884068]\n",
      "epoch:17 step:16405 [D loss: 0.524854, acc.: 75.78%] [G loss: 0.700709]\n",
      "epoch:17 step:16406 [D loss: 0.602065, acc.: 70.31%] [G loss: 0.795406]\n",
      "epoch:17 step:16407 [D loss: 0.604991, acc.: 68.75%] [G loss: 0.429113]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:17 step:16408 [D loss: 0.532225, acc.: 69.53%] [G loss: 0.479541]\n",
      "epoch:17 step:16409 [D loss: 0.605104, acc.: 66.41%] [G loss: 0.660013]\n",
      "epoch:17 step:16410 [D loss: 0.464365, acc.: 81.25%] [G loss: 0.769040]\n",
      "epoch:17 step:16411 [D loss: 0.552297, acc.: 66.41%] [G loss: 0.626678]\n",
      "epoch:17 step:16412 [D loss: 0.538378, acc.: 70.31%] [G loss: 0.712298]\n",
      "epoch:17 step:16413 [D loss: 0.484651, acc.: 71.88%] [G loss: 0.765608]\n",
      "epoch:17 step:16414 [D loss: 0.569441, acc.: 72.66%] [G loss: 0.820646]\n",
      "epoch:17 step:16415 [D loss: 0.558904, acc.: 67.97%] [G loss: 0.643875]\n",
      "epoch:17 step:16416 [D loss: 0.533412, acc.: 69.53%] [G loss: 0.632638]\n",
      "epoch:17 step:16417 [D loss: 0.422737, acc.: 81.25%] [G loss: 0.642482]\n",
      "epoch:17 step:16418 [D loss: 0.514441, acc.: 72.66%] [G loss: 0.631779]\n",
      "epoch:17 step:16419 [D loss: 0.610796, acc.: 64.06%] [G loss: 0.635631]\n",
      "epoch:17 step:16420 [D loss: 0.497871, acc.: 74.22%] [G loss: 0.816328]\n",
      "epoch:17 step:16421 [D loss: 0.531892, acc.: 74.22%] [G loss: 0.565225]\n",
      "epoch:17 step:16422 [D loss: 0.543782, acc.: 70.31%] [G loss: 0.598014]\n",
      "epoch:17 step:16423 [D loss: 0.557572, acc.: 74.22%] [G loss: 0.543573]\n",
      "epoch:17 step:16424 [D loss: 0.490140, acc.: 75.78%] [G loss: 0.788647]\n",
      "epoch:17 step:16425 [D loss: 0.557906, acc.: 75.00%] [G loss: 0.661805]\n",
      "epoch:17 step:16426 [D loss: 0.541610, acc.: 72.66%] [G loss: 0.656438]\n",
      "epoch:17 step:16427 [D loss: 0.554435, acc.: 70.31%] [G loss: 0.751908]\n",
      "epoch:17 step:16428 [D loss: 0.460925, acc.: 77.34%] [G loss: 0.963190]\n",
      "epoch:17 step:16429 [D loss: 0.580116, acc.: 67.19%] [G loss: 0.872432]\n",
      "epoch:17 step:16430 [D loss: 0.633546, acc.: 64.84%] [G loss: 0.565821]\n",
      "epoch:17 step:16431 [D loss: 0.612931, acc.: 60.16%] [G loss: 0.555132]\n",
      "epoch:17 step:16432 [D loss: 0.563390, acc.: 67.97%] [G loss: 0.609990]\n",
      "epoch:17 step:16433 [D loss: 0.438029, acc.: 78.12%] [G loss: 0.764292]\n",
      "epoch:17 step:16434 [D loss: 0.502710, acc.: 78.91%] [G loss: 0.720827]\n",
      "epoch:17 step:16435 [D loss: 0.510176, acc.: 78.12%] [G loss: 0.626136]\n",
      "epoch:17 step:16436 [D loss: 0.500718, acc.: 77.34%] [G loss: 0.848658]\n",
      "epoch:17 step:16437 [D loss: 0.405222, acc.: 82.81%] [G loss: 0.936684]\n",
      "epoch:17 step:16438 [D loss: 0.522264, acc.: 74.22%] [G loss: 0.963636]\n",
      "epoch:17 step:16439 [D loss: 0.592620, acc.: 67.19%] [G loss: 0.667380]\n",
      "epoch:17 step:16440 [D loss: 0.634357, acc.: 57.81%] [G loss: 0.555024]\n",
      "epoch:17 step:16441 [D loss: 0.546635, acc.: 67.97%] [G loss: 0.639487]\n",
      "epoch:17 step:16442 [D loss: 0.523319, acc.: 72.66%] [G loss: 0.704992]\n",
      "epoch:17 step:16443 [D loss: 0.459142, acc.: 77.34%] [G loss: 0.755482]\n",
      "epoch:17 step:16444 [D loss: 0.514452, acc.: 71.09%] [G loss: 0.826293]\n",
      "epoch:17 step:16445 [D loss: 0.461185, acc.: 81.25%] [G loss: 0.838148]\n",
      "epoch:17 step:16446 [D loss: 0.513866, acc.: 75.00%] [G loss: 0.655148]\n",
      "epoch:17 step:16447 [D loss: 0.570891, acc.: 68.75%] [G loss: 0.624584]\n",
      "epoch:17 step:16448 [D loss: 0.524409, acc.: 70.31%] [G loss: 0.638538]\n",
      "epoch:17 step:16449 [D loss: 0.484542, acc.: 71.88%] [G loss: 0.774278]\n",
      "epoch:17 step:16450 [D loss: 0.567185, acc.: 67.97%] [G loss: 0.600040]\n",
      "epoch:17 step:16451 [D loss: 0.501593, acc.: 73.44%] [G loss: 0.752767]\n",
      "epoch:17 step:16452 [D loss: 0.466467, acc.: 76.56%] [G loss: 0.657331]\n",
      "epoch:17 step:16453 [D loss: 0.558274, acc.: 72.66%] [G loss: 0.627411]\n",
      "epoch:17 step:16454 [D loss: 0.558745, acc.: 69.53%] [G loss: 0.591668]\n",
      "epoch:17 step:16455 [D loss: 0.459419, acc.: 81.25%] [G loss: 0.603345]\n",
      "epoch:17 step:16456 [D loss: 0.544134, acc.: 71.09%] [G loss: 0.614536]\n",
      "epoch:17 step:16457 [D loss: 0.645522, acc.: 62.50%] [G loss: 0.546265]\n",
      "epoch:17 step:16458 [D loss: 0.571196, acc.: 66.41%] [G loss: 0.534151]\n",
      "epoch:17 step:16459 [D loss: 0.570199, acc.: 65.62%] [G loss: 0.625751]\n",
      "epoch:17 step:16460 [D loss: 0.559888, acc.: 67.19%] [G loss: 0.760128]\n",
      "epoch:17 step:16461 [D loss: 0.581128, acc.: 64.84%] [G loss: 0.603273]\n",
      "epoch:17 step:16462 [D loss: 0.553980, acc.: 69.53%] [G loss: 0.589698]\n",
      "epoch:17 step:16463 [D loss: 0.449890, acc.: 78.12%] [G loss: 0.692581]\n",
      "epoch:17 step:16464 [D loss: 0.573947, acc.: 66.41%] [G loss: 0.670532]\n",
      "epoch:17 step:16465 [D loss: 0.492988, acc.: 75.78%] [G loss: 0.686293]\n",
      "epoch:17 step:16466 [D loss: 0.558886, acc.: 67.97%] [G loss: 0.459114]\n",
      "epoch:17 step:16467 [D loss: 0.558245, acc.: 69.53%] [G loss: 0.482631]\n",
      "epoch:17 step:16468 [D loss: 0.534386, acc.: 71.09%] [G loss: 0.620611]\n",
      "epoch:17 step:16469 [D loss: 0.534669, acc.: 71.09%] [G loss: 0.556511]\n",
      "epoch:17 step:16470 [D loss: 0.531581, acc.: 69.53%] [G loss: 0.519955]\n",
      "epoch:17 step:16471 [D loss: 0.630198, acc.: 63.28%] [G loss: 0.469294]\n",
      "epoch:17 step:16472 [D loss: 0.556579, acc.: 68.75%] [G loss: 0.596191]\n",
      "epoch:17 step:16473 [D loss: 0.530132, acc.: 73.44%] [G loss: 0.684117]\n",
      "epoch:17 step:16474 [D loss: 0.490175, acc.: 75.00%] [G loss: 0.659403]\n",
      "epoch:17 step:16475 [D loss: 0.508824, acc.: 79.69%] [G loss: 0.711909]\n",
      "epoch:17 step:16476 [D loss: 0.515092, acc.: 71.88%] [G loss: 0.601356]\n",
      "epoch:17 step:16477 [D loss: 0.468837, acc.: 75.78%] [G loss: 0.678317]\n",
      "epoch:17 step:16478 [D loss: 0.563135, acc.: 68.75%] [G loss: 0.605921]\n",
      "epoch:17 step:16479 [D loss: 0.512633, acc.: 72.66%] [G loss: 0.702454]\n",
      "epoch:17 step:16480 [D loss: 0.470999, acc.: 75.78%] [G loss: 0.711341]\n",
      "epoch:17 step:16481 [D loss: 0.467596, acc.: 77.34%] [G loss: 0.706342]\n",
      "epoch:17 step:16482 [D loss: 0.560337, acc.: 73.44%] [G loss: 0.650134]\n",
      "epoch:17 step:16483 [D loss: 0.472747, acc.: 76.56%] [G loss: 0.645171]\n",
      "epoch:17 step:16484 [D loss: 0.507684, acc.: 75.00%] [G loss: 0.725524]\n",
      "epoch:17 step:16485 [D loss: 0.544348, acc.: 70.31%] [G loss: 0.737083]\n",
      "epoch:17 step:16486 [D loss: 0.499732, acc.: 76.56%] [G loss: 0.666904]\n",
      "epoch:17 step:16487 [D loss: 0.497912, acc.: 73.44%] [G loss: 0.619171]\n",
      "epoch:17 step:16488 [D loss: 0.592877, acc.: 67.19%] [G loss: 0.516257]\n",
      "epoch:17 step:16489 [D loss: 0.529025, acc.: 69.53%] [G loss: 0.556598]\n",
      "epoch:17 step:16490 [D loss: 0.488573, acc.: 77.34%] [G loss: 0.484348]\n",
      "epoch:17 step:16491 [D loss: 0.519892, acc.: 70.31%] [G loss: 0.783689]\n",
      "epoch:17 step:16492 [D loss: 0.518017, acc.: 75.00%] [G loss: 0.679055]\n",
      "epoch:17 step:16493 [D loss: 0.524308, acc.: 72.66%] [G loss: 0.641448]\n",
      "epoch:17 step:16494 [D loss: 0.554037, acc.: 74.22%] [G loss: 0.824031]\n",
      "epoch:17 step:16495 [D loss: 0.594320, acc.: 65.62%] [G loss: 0.770400]\n",
      "epoch:17 step:16496 [D loss: 0.534793, acc.: 71.09%] [G loss: 0.682507]\n",
      "epoch:17 step:16497 [D loss: 0.555059, acc.: 75.00%] [G loss: 0.739372]\n",
      "epoch:17 step:16498 [D loss: 0.554457, acc.: 70.31%] [G loss: 0.669611]\n",
      "epoch:17 step:16499 [D loss: 0.481351, acc.: 76.56%] [G loss: 0.429720]\n",
      "epoch:17 step:16500 [D loss: 0.537306, acc.: 71.88%] [G loss: 0.585274]\n",
      "epoch:17 step:16501 [D loss: 0.536824, acc.: 73.44%] [G loss: 0.610861]\n",
      "epoch:17 step:16502 [D loss: 0.494979, acc.: 76.56%] [G loss: 0.632790]\n",
      "epoch:17 step:16503 [D loss: 0.433623, acc.: 82.03%] [G loss: 0.821106]\n",
      "epoch:17 step:16504 [D loss: 0.501421, acc.: 78.12%] [G loss: 0.905435]\n",
      "epoch:17 step:16505 [D loss: 0.561750, acc.: 69.53%] [G loss: 0.866687]\n",
      "epoch:17 step:16506 [D loss: 0.578215, acc.: 67.19%] [G loss: 0.582714]\n",
      "epoch:17 step:16507 [D loss: 0.560863, acc.: 70.31%] [G loss: 0.591625]\n",
      "epoch:17 step:16508 [D loss: 0.535691, acc.: 70.31%] [G loss: 0.626805]\n",
      "epoch:17 step:16509 [D loss: 0.545710, acc.: 70.31%] [G loss: 0.600821]\n",
      "epoch:17 step:16510 [D loss: 0.548769, acc.: 67.19%] [G loss: 0.514932]\n",
      "epoch:17 step:16511 [D loss: 0.429501, acc.: 82.81%] [G loss: 0.682477]\n",
      "epoch:17 step:16512 [D loss: 0.538738, acc.: 72.66%] [G loss: 0.765983]\n",
      "epoch:17 step:16513 [D loss: 0.556942, acc.: 69.53%] [G loss: 0.686992]\n",
      "epoch:17 step:16514 [D loss: 0.547663, acc.: 68.75%] [G loss: 0.586024]\n",
      "epoch:17 step:16515 [D loss: 0.576965, acc.: 67.97%] [G loss: 0.686799]\n",
      "epoch:17 step:16516 [D loss: 0.549858, acc.: 69.53%] [G loss: 0.628175]\n",
      "epoch:17 step:16517 [D loss: 0.499481, acc.: 75.78%] [G loss: 0.888781]\n",
      "epoch:17 step:16518 [D loss: 0.503303, acc.: 75.78%] [G loss: 0.826497]\n",
      "epoch:17 step:16519 [D loss: 0.538339, acc.: 70.31%] [G loss: 0.739399]\n",
      "epoch:17 step:16520 [D loss: 0.581602, acc.: 71.09%] [G loss: 0.614611]\n",
      "epoch:17 step:16521 [D loss: 0.477475, acc.: 73.44%] [G loss: 0.527423]\n",
      "epoch:17 step:16522 [D loss: 0.509342, acc.: 73.44%] [G loss: 0.617774]\n",
      "epoch:17 step:16523 [D loss: 0.527637, acc.: 73.44%] [G loss: 0.673810]\n",
      "epoch:17 step:16524 [D loss: 0.523909, acc.: 73.44%] [G loss: 0.608638]\n",
      "epoch:17 step:16525 [D loss: 0.556819, acc.: 72.66%] [G loss: 0.749736]\n",
      "epoch:17 step:16526 [D loss: 0.525745, acc.: 71.09%] [G loss: 0.620704]\n",
      "epoch:17 step:16527 [D loss: 0.515078, acc.: 71.09%] [G loss: 0.635916]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:17 step:16528 [D loss: 0.529673, acc.: 70.31%] [G loss: 0.736197]\n",
      "epoch:17 step:16529 [D loss: 0.583798, acc.: 64.06%] [G loss: 0.479616]\n",
      "epoch:17 step:16530 [D loss: 0.495373, acc.: 75.00%] [G loss: 0.763506]\n",
      "epoch:17 step:16531 [D loss: 0.439348, acc.: 78.12%] [G loss: 0.688536]\n",
      "epoch:17 step:16532 [D loss: 0.516332, acc.: 74.22%] [G loss: 0.877510]\n",
      "epoch:17 step:16533 [D loss: 0.568089, acc.: 69.53%] [G loss: 0.690730]\n",
      "epoch:17 step:16534 [D loss: 0.425657, acc.: 82.03%] [G loss: 0.700866]\n",
      "epoch:17 step:16535 [D loss: 0.585248, acc.: 65.62%] [G loss: 0.539941]\n",
      "epoch:17 step:16536 [D loss: 0.507241, acc.: 72.66%] [G loss: 0.540299]\n",
      "epoch:17 step:16537 [D loss: 0.526778, acc.: 74.22%] [G loss: 0.528726]\n",
      "epoch:17 step:16538 [D loss: 0.516692, acc.: 72.66%] [G loss: 0.555514]\n",
      "epoch:17 step:16539 [D loss: 0.540011, acc.: 69.53%] [G loss: 0.601106]\n",
      "epoch:17 step:16540 [D loss: 0.493374, acc.: 73.44%] [G loss: 0.512810]\n",
      "epoch:17 step:16541 [D loss: 0.552115, acc.: 67.19%] [G loss: 0.518909]\n",
      "epoch:17 step:16542 [D loss: 0.482608, acc.: 72.66%] [G loss: 0.585920]\n",
      "epoch:17 step:16543 [D loss: 0.571137, acc.: 66.41%] [G loss: 0.592031]\n",
      "epoch:17 step:16544 [D loss: 0.631051, acc.: 57.03%] [G loss: 0.722255]\n",
      "epoch:17 step:16545 [D loss: 0.539873, acc.: 71.09%] [G loss: 0.815443]\n",
      "epoch:17 step:16546 [D loss: 0.500077, acc.: 73.44%] [G loss: 0.803567]\n",
      "epoch:17 step:16547 [D loss: 0.551122, acc.: 70.31%] [G loss: 0.873863]\n",
      "epoch:17 step:16548 [D loss: 0.547538, acc.: 70.31%] [G loss: 0.666340]\n",
      "epoch:17 step:16549 [D loss: 0.487417, acc.: 77.34%] [G loss: 0.808862]\n",
      "epoch:17 step:16550 [D loss: 0.531559, acc.: 72.66%] [G loss: 0.708670]\n",
      "epoch:17 step:16551 [D loss: 0.627793, acc.: 65.62%] [G loss: 0.527917]\n",
      "epoch:17 step:16552 [D loss: 0.483166, acc.: 76.56%] [G loss: 0.720069]\n",
      "epoch:17 step:16553 [D loss: 0.457261, acc.: 76.56%] [G loss: 0.823644]\n",
      "epoch:17 step:16554 [D loss: 0.576649, acc.: 69.53%] [G loss: 0.657575]\n",
      "epoch:17 step:16555 [D loss: 0.588923, acc.: 66.41%] [G loss: 0.552169]\n",
      "epoch:17 step:16556 [D loss: 0.527838, acc.: 68.75%] [G loss: 0.603796]\n",
      "epoch:17 step:16557 [D loss: 0.519713, acc.: 72.66%] [G loss: 0.670628]\n",
      "epoch:17 step:16558 [D loss: 0.510164, acc.: 74.22%] [G loss: 0.522665]\n",
      "epoch:17 step:16559 [D loss: 0.479150, acc.: 76.56%] [G loss: 0.717215]\n",
      "epoch:17 step:16560 [D loss: 0.453266, acc.: 80.47%] [G loss: 0.650721]\n",
      "epoch:17 step:16561 [D loss: 0.483494, acc.: 76.56%] [G loss: 0.669487]\n",
      "epoch:17 step:16562 [D loss: 0.551129, acc.: 67.97%] [G loss: 0.681512]\n",
      "epoch:17 step:16563 [D loss: 0.481130, acc.: 75.78%] [G loss: 0.761798]\n",
      "epoch:17 step:16564 [D loss: 0.481956, acc.: 75.00%] [G loss: 0.670890]\n",
      "epoch:17 step:16565 [D loss: 0.561999, acc.: 69.53%] [G loss: 0.649411]\n",
      "epoch:17 step:16566 [D loss: 0.507522, acc.: 69.53%] [G loss: 0.625522]\n",
      "epoch:17 step:16567 [D loss: 0.491888, acc.: 72.66%] [G loss: 0.615906]\n",
      "epoch:17 step:16568 [D loss: 0.480305, acc.: 74.22%] [G loss: 0.567761]\n",
      "epoch:17 step:16569 [D loss: 0.528598, acc.: 74.22%] [G loss: 0.582304]\n",
      "epoch:17 step:16570 [D loss: 0.514379, acc.: 71.09%] [G loss: 0.742065]\n",
      "epoch:17 step:16571 [D loss: 0.448240, acc.: 81.25%] [G loss: 0.816591]\n",
      "epoch:17 step:16572 [D loss: 0.486832, acc.: 76.56%] [G loss: 0.882966]\n",
      "epoch:17 step:16573 [D loss: 0.510473, acc.: 67.97%] [G loss: 0.653113]\n",
      "epoch:17 step:16574 [D loss: 0.504111, acc.: 72.66%] [G loss: 0.592630]\n",
      "epoch:17 step:16575 [D loss: 0.532887, acc.: 77.34%] [G loss: 0.633720]\n",
      "epoch:17 step:16576 [D loss: 0.434105, acc.: 78.12%] [G loss: 0.678394]\n",
      "epoch:17 step:16577 [D loss: 0.402168, acc.: 82.03%] [G loss: 0.881565]\n",
      "epoch:17 step:16578 [D loss: 0.452844, acc.: 79.69%] [G loss: 0.996474]\n",
      "epoch:17 step:16579 [D loss: 0.442418, acc.: 78.91%] [G loss: 0.861853]\n",
      "epoch:17 step:16580 [D loss: 0.483301, acc.: 76.56%] [G loss: 0.817077]\n",
      "epoch:17 step:16581 [D loss: 0.642092, acc.: 61.72%] [G loss: 0.671015]\n",
      "epoch:17 step:16582 [D loss: 0.538097, acc.: 71.09%] [G loss: 0.731803]\n",
      "epoch:17 step:16583 [D loss: 0.473196, acc.: 77.34%] [G loss: 0.828994]\n",
      "epoch:17 step:16584 [D loss: 0.564676, acc.: 67.97%] [G loss: 0.777937]\n",
      "epoch:17 step:16585 [D loss: 0.539604, acc.: 68.75%] [G loss: 0.739332]\n",
      "epoch:17 step:16586 [D loss: 0.532037, acc.: 67.97%] [G loss: 0.678069]\n",
      "epoch:17 step:16587 [D loss: 0.568924, acc.: 70.31%] [G loss: 0.704866]\n",
      "epoch:17 step:16588 [D loss: 0.485728, acc.: 75.00%] [G loss: 0.783601]\n",
      "epoch:17 step:16589 [D loss: 0.493786, acc.: 75.78%] [G loss: 0.788403]\n",
      "epoch:17 step:16590 [D loss: 0.481869, acc.: 78.12%] [G loss: 0.838641]\n",
      "epoch:17 step:16591 [D loss: 0.477906, acc.: 74.22%] [G loss: 0.798220]\n",
      "epoch:17 step:16592 [D loss: 0.576191, acc.: 70.31%] [G loss: 0.744770]\n",
      "epoch:17 step:16593 [D loss: 0.605834, acc.: 67.97%] [G loss: 0.789289]\n",
      "epoch:17 step:16594 [D loss: 0.532344, acc.: 71.88%] [G loss: 0.625895]\n",
      "epoch:17 step:16595 [D loss: 0.471529, acc.: 77.34%] [G loss: 0.793995]\n",
      "epoch:17 step:16596 [D loss: 0.599220, acc.: 68.75%] [G loss: 0.657456]\n",
      "epoch:17 step:16597 [D loss: 0.552510, acc.: 69.53%] [G loss: 0.804679]\n",
      "epoch:17 step:16598 [D loss: 0.519274, acc.: 74.22%] [G loss: 0.545056]\n",
      "epoch:17 step:16599 [D loss: 0.560541, acc.: 65.62%] [G loss: 0.501535]\n",
      "epoch:17 step:16600 [D loss: 0.462424, acc.: 79.69%] [G loss: 0.641561]\n",
      "epoch:17 step:16601 [D loss: 0.531098, acc.: 71.09%] [G loss: 0.676514]\n",
      "epoch:17 step:16602 [D loss: 0.556767, acc.: 68.75%] [G loss: 0.647831]\n",
      "epoch:17 step:16603 [D loss: 0.545716, acc.: 71.88%] [G loss: 0.608807]\n",
      "epoch:17 step:16604 [D loss: 0.566193, acc.: 70.31%] [G loss: 0.598681]\n",
      "epoch:17 step:16605 [D loss: 0.557857, acc.: 71.09%] [G loss: 0.643378]\n",
      "epoch:17 step:16606 [D loss: 0.462791, acc.: 77.34%] [G loss: 0.768446]\n",
      "epoch:17 step:16607 [D loss: 0.584909, acc.: 67.97%] [G loss: 0.550927]\n",
      "epoch:17 step:16608 [D loss: 0.498528, acc.: 70.31%] [G loss: 0.791542]\n",
      "epoch:17 step:16609 [D loss: 0.537770, acc.: 78.91%] [G loss: 0.677561]\n",
      "epoch:17 step:16610 [D loss: 0.475615, acc.: 77.34%] [G loss: 0.685201]\n",
      "epoch:17 step:16611 [D loss: 0.551972, acc.: 70.31%] [G loss: 0.668957]\n",
      "epoch:17 step:16612 [D loss: 0.570254, acc.: 67.19%] [G loss: 0.681090]\n",
      "epoch:17 step:16613 [D loss: 0.585076, acc.: 66.41%] [G loss: 0.569933]\n",
      "epoch:17 step:16614 [D loss: 0.530578, acc.: 71.88%] [G loss: 0.676831]\n",
      "epoch:17 step:16615 [D loss: 0.585174, acc.: 67.97%] [G loss: 0.664760]\n",
      "epoch:17 step:16616 [D loss: 0.536876, acc.: 71.09%] [G loss: 0.631044]\n",
      "epoch:17 step:16617 [D loss: 0.514541, acc.: 73.44%] [G loss: 0.657113]\n",
      "epoch:17 step:16618 [D loss: 0.509066, acc.: 73.44%] [G loss: 0.675552]\n",
      "epoch:17 step:16619 [D loss: 0.557064, acc.: 67.19%] [G loss: 0.721095]\n",
      "epoch:17 step:16620 [D loss: 0.462015, acc.: 79.69%] [G loss: 0.897030]\n",
      "epoch:17 step:16621 [D loss: 0.546715, acc.: 72.66%] [G loss: 0.694673]\n",
      "epoch:17 step:16622 [D loss: 0.453695, acc.: 78.91%] [G loss: 0.748975]\n",
      "epoch:17 step:16623 [D loss: 0.488388, acc.: 71.88%] [G loss: 0.805077]\n",
      "epoch:17 step:16624 [D loss: 0.518849, acc.: 73.44%] [G loss: 0.699324]\n",
      "epoch:17 step:16625 [D loss: 0.626558, acc.: 59.38%] [G loss: 0.498536]\n",
      "epoch:17 step:16626 [D loss: 0.590275, acc.: 65.62%] [G loss: 0.442534]\n",
      "epoch:17 step:16627 [D loss: 0.535828, acc.: 71.88%] [G loss: 0.606413]\n",
      "epoch:17 step:16628 [D loss: 0.516886, acc.: 75.78%] [G loss: 0.656403]\n",
      "epoch:17 step:16629 [D loss: 0.478609, acc.: 76.56%] [G loss: 0.768005]\n",
      "epoch:17 step:16630 [D loss: 0.493056, acc.: 79.69%] [G loss: 0.832888]\n",
      "epoch:17 step:16631 [D loss: 0.611752, acc.: 64.06%] [G loss: 0.610494]\n",
      "epoch:17 step:16632 [D loss: 0.572360, acc.: 69.53%] [G loss: 0.765098]\n",
      "epoch:17 step:16633 [D loss: 0.650201, acc.: 60.16%] [G loss: 0.647611]\n",
      "epoch:17 step:16634 [D loss: 0.532790, acc.: 73.44%] [G loss: 0.722111]\n",
      "epoch:17 step:16635 [D loss: 0.509354, acc.: 71.09%] [G loss: 0.781330]\n",
      "epoch:17 step:16636 [D loss: 0.547293, acc.: 67.97%] [G loss: 0.541174]\n",
      "epoch:17 step:16637 [D loss: 0.488046, acc.: 78.91%] [G loss: 0.683381]\n",
      "epoch:17 step:16638 [D loss: 0.500711, acc.: 74.22%] [G loss: 0.671031]\n",
      "epoch:17 step:16639 [D loss: 0.571525, acc.: 64.84%] [G loss: 0.548920]\n",
      "epoch:17 step:16640 [D loss: 0.533636, acc.: 67.97%] [G loss: 0.629235]\n",
      "epoch:17 step:16641 [D loss: 0.542997, acc.: 69.53%] [G loss: 0.651343]\n",
      "epoch:17 step:16642 [D loss: 0.531651, acc.: 71.88%] [G loss: 0.679744]\n",
      "epoch:17 step:16643 [D loss: 0.518506, acc.: 71.88%] [G loss: 0.639184]\n",
      "epoch:17 step:16644 [D loss: 0.577120, acc.: 68.75%] [G loss: 0.646323]\n",
      "epoch:17 step:16645 [D loss: 0.649005, acc.: 62.50%] [G loss: 0.611051]\n",
      "epoch:17 step:16646 [D loss: 0.539671, acc.: 67.97%] [G loss: 0.525885]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:17 step:16647 [D loss: 0.542263, acc.: 64.06%] [G loss: 0.538448]\n",
      "epoch:17 step:16648 [D loss: 0.456752, acc.: 82.81%] [G loss: 0.650986]\n",
      "epoch:17 step:16649 [D loss: 0.630349, acc.: 60.16%] [G loss: 0.698714]\n",
      "epoch:17 step:16650 [D loss: 0.552669, acc.: 68.75%] [G loss: 0.597611]\n",
      "epoch:17 step:16651 [D loss: 0.598585, acc.: 68.75%] [G loss: 0.589788]\n",
      "epoch:17 step:16652 [D loss: 0.605159, acc.: 68.75%] [G loss: 0.679169]\n",
      "epoch:17 step:16653 [D loss: 0.511831, acc.: 70.31%] [G loss: 0.701205]\n",
      "epoch:17 step:16654 [D loss: 0.527406, acc.: 71.88%] [G loss: 0.547965]\n",
      "epoch:17 step:16655 [D loss: 0.495316, acc.: 75.78%] [G loss: 0.725313]\n",
      "epoch:17 step:16656 [D loss: 0.585460, acc.: 70.31%] [G loss: 0.746260]\n",
      "epoch:17 step:16657 [D loss: 0.532645, acc.: 71.09%] [G loss: 0.720892]\n",
      "epoch:17 step:16658 [D loss: 0.577544, acc.: 67.97%] [G loss: 0.538637]\n",
      "epoch:17 step:16659 [D loss: 0.542748, acc.: 71.88%] [G loss: 0.455518]\n",
      "epoch:17 step:16660 [D loss: 0.596793, acc.: 60.16%] [G loss: 0.501809]\n",
      "epoch:17 step:16661 [D loss: 0.527637, acc.: 73.44%] [G loss: 0.538870]\n",
      "epoch:17 step:16662 [D loss: 0.515268, acc.: 73.44%] [G loss: 0.652850]\n",
      "epoch:17 step:16663 [D loss: 0.544185, acc.: 71.09%] [G loss: 0.481145]\n",
      "epoch:17 step:16664 [D loss: 0.564620, acc.: 64.06%] [G loss: 0.534130]\n",
      "epoch:17 step:16665 [D loss: 0.495704, acc.: 74.22%] [G loss: 0.722210]\n",
      "epoch:17 step:16666 [D loss: 0.497640, acc.: 74.22%] [G loss: 0.584258]\n",
      "epoch:17 step:16667 [D loss: 0.582166, acc.: 64.84%] [G loss: 0.505871]\n",
      "epoch:17 step:16668 [D loss: 0.586373, acc.: 67.97%] [G loss: 0.568845]\n",
      "epoch:17 step:16669 [D loss: 0.616610, acc.: 64.84%] [G loss: 0.476891]\n",
      "epoch:17 step:16670 [D loss: 0.524959, acc.: 73.44%] [G loss: 0.510678]\n",
      "epoch:17 step:16671 [D loss: 0.525334, acc.: 72.66%] [G loss: 0.634609]\n",
      "epoch:17 step:16672 [D loss: 0.495832, acc.: 74.22%] [G loss: 0.658698]\n",
      "epoch:17 step:16673 [D loss: 0.504569, acc.: 75.78%] [G loss: 0.588646]\n",
      "epoch:17 step:16674 [D loss: 0.572402, acc.: 69.53%] [G loss: 0.711641]\n",
      "epoch:17 step:16675 [D loss: 0.513143, acc.: 71.09%] [G loss: 0.692449]\n",
      "epoch:17 step:16676 [D loss: 0.419343, acc.: 81.25%] [G loss: 0.751050]\n",
      "epoch:17 step:16677 [D loss: 0.581263, acc.: 68.75%] [G loss: 0.743711]\n",
      "epoch:17 step:16678 [D loss: 0.523125, acc.: 73.44%] [G loss: 0.614019]\n",
      "epoch:17 step:16679 [D loss: 0.559743, acc.: 69.53%] [G loss: 0.704105]\n",
      "epoch:17 step:16680 [D loss: 0.498688, acc.: 76.56%] [G loss: 0.669237]\n",
      "epoch:17 step:16681 [D loss: 0.613786, acc.: 65.62%] [G loss: 0.568328]\n",
      "epoch:17 step:16682 [D loss: 0.522131, acc.: 73.44%] [G loss: 0.615095]\n",
      "epoch:17 step:16683 [D loss: 0.543860, acc.: 71.09%] [G loss: 0.558790]\n",
      "epoch:17 step:16684 [D loss: 0.519018, acc.: 72.66%] [G loss: 0.540835]\n",
      "epoch:17 step:16685 [D loss: 0.581485, acc.: 67.97%] [G loss: 0.472862]\n",
      "epoch:17 step:16686 [D loss: 0.531294, acc.: 71.88%] [G loss: 0.628874]\n",
      "epoch:17 step:16687 [D loss: 0.544789, acc.: 71.09%] [G loss: 0.672387]\n",
      "epoch:17 step:16688 [D loss: 0.548169, acc.: 71.09%] [G loss: 0.661886]\n",
      "epoch:17 step:16689 [D loss: 0.518118, acc.: 69.53%] [G loss: 0.648849]\n",
      "epoch:17 step:16690 [D loss: 0.544704, acc.: 72.66%] [G loss: 0.729452]\n",
      "epoch:17 step:16691 [D loss: 0.582171, acc.: 68.75%] [G loss: 0.605990]\n",
      "epoch:17 step:16692 [D loss: 0.525906, acc.: 68.75%] [G loss: 0.636992]\n",
      "epoch:17 step:16693 [D loss: 0.570491, acc.: 67.97%] [G loss: 0.499109]\n",
      "epoch:17 step:16694 [D loss: 0.528353, acc.: 72.66%] [G loss: 0.608016]\n",
      "epoch:17 step:16695 [D loss: 0.657056, acc.: 57.03%] [G loss: 0.474768]\n",
      "epoch:17 step:16696 [D loss: 0.544566, acc.: 67.97%] [G loss: 0.549651]\n",
      "epoch:17 step:16697 [D loss: 0.535680, acc.: 72.66%] [G loss: 0.819788]\n",
      "epoch:17 step:16698 [D loss: 0.491119, acc.: 75.78%] [G loss: 0.908254]\n",
      "epoch:17 step:16699 [D loss: 0.510122, acc.: 71.88%] [G loss: 0.750556]\n",
      "epoch:17 step:16700 [D loss: 0.551979, acc.: 67.97%] [G loss: 0.705830]\n",
      "epoch:17 step:16701 [D loss: 0.521651, acc.: 70.31%] [G loss: 0.605182]\n",
      "epoch:17 step:16702 [D loss: 0.546760, acc.: 67.97%] [G loss: 0.684115]\n",
      "epoch:17 step:16703 [D loss: 0.596238, acc.: 69.53%] [G loss: 0.647087]\n",
      "epoch:17 step:16704 [D loss: 0.534026, acc.: 73.44%] [G loss: 0.823606]\n",
      "epoch:17 step:16705 [D loss: 0.576030, acc.: 69.53%] [G loss: 0.614908]\n",
      "epoch:17 step:16706 [D loss: 0.601116, acc.: 65.62%] [G loss: 0.690285]\n",
      "epoch:17 step:16707 [D loss: 0.522805, acc.: 71.88%] [G loss: 0.621933]\n",
      "epoch:17 step:16708 [D loss: 0.562591, acc.: 71.88%] [G loss: 0.728570]\n",
      "epoch:17 step:16709 [D loss: 0.496014, acc.: 79.69%] [G loss: 0.713484]\n",
      "epoch:17 step:16710 [D loss: 0.449567, acc.: 79.69%] [G loss: 0.753972]\n",
      "epoch:17 step:16711 [D loss: 0.480967, acc.: 75.78%] [G loss: 0.708460]\n",
      "epoch:17 step:16712 [D loss: 0.653941, acc.: 60.94%] [G loss: 0.708163]\n",
      "epoch:17 step:16713 [D loss: 0.597799, acc.: 67.97%] [G loss: 0.738093]\n",
      "epoch:17 step:16714 [D loss: 0.579974, acc.: 70.31%] [G loss: 0.551672]\n",
      "epoch:17 step:16715 [D loss: 0.478539, acc.: 76.56%] [G loss: 0.663039]\n",
      "epoch:17 step:16716 [D loss: 0.606475, acc.: 67.19%] [G loss: 0.668630]\n",
      "epoch:17 step:16717 [D loss: 0.615532, acc.: 61.72%] [G loss: 0.543824]\n",
      "epoch:17 step:16718 [D loss: 0.510417, acc.: 71.88%] [G loss: 0.521216]\n",
      "epoch:17 step:16719 [D loss: 0.513319, acc.: 70.31%] [G loss: 0.571273]\n",
      "epoch:17 step:16720 [D loss: 0.563401, acc.: 71.09%] [G loss: 0.484176]\n",
      "epoch:17 step:16721 [D loss: 0.487911, acc.: 75.00%] [G loss: 0.758467]\n",
      "epoch:17 step:16722 [D loss: 0.604105, acc.: 69.53%] [G loss: 0.762112]\n",
      "epoch:17 step:16723 [D loss: 0.620106, acc.: 66.41%] [G loss: 0.817782]\n",
      "epoch:17 step:16724 [D loss: 0.531989, acc.: 70.31%] [G loss: 0.651565]\n",
      "epoch:17 step:16725 [D loss: 0.517897, acc.: 70.31%] [G loss: 0.685088]\n",
      "epoch:17 step:16726 [D loss: 0.571216, acc.: 69.53%] [G loss: 0.635027]\n",
      "epoch:17 step:16727 [D loss: 0.600083, acc.: 61.72%] [G loss: 0.624488]\n",
      "epoch:17 step:16728 [D loss: 0.542207, acc.: 72.66%] [G loss: 0.632084]\n",
      "epoch:17 step:16729 [D loss: 0.560580, acc.: 65.62%] [G loss: 0.594153]\n",
      "epoch:17 step:16730 [D loss: 0.524108, acc.: 69.53%] [G loss: 0.514430]\n",
      "epoch:17 step:16731 [D loss: 0.475229, acc.: 76.56%] [G loss: 0.759000]\n",
      "epoch:17 step:16732 [D loss: 0.496589, acc.: 75.00%] [G loss: 0.805667]\n",
      "epoch:17 step:16733 [D loss: 0.548470, acc.: 72.66%] [G loss: 0.692340]\n",
      "epoch:17 step:16734 [D loss: 0.537619, acc.: 70.31%] [G loss: 0.626197]\n",
      "epoch:17 step:16735 [D loss: 0.544996, acc.: 71.09%] [G loss: 0.608046]\n",
      "epoch:17 step:16736 [D loss: 0.507747, acc.: 71.09%] [G loss: 0.543231]\n",
      "epoch:17 step:16737 [D loss: 0.559841, acc.: 73.44%] [G loss: 0.661315]\n",
      "epoch:17 step:16738 [D loss: 0.496136, acc.: 73.44%] [G loss: 0.528877]\n",
      "epoch:17 step:16739 [D loss: 0.468825, acc.: 77.34%] [G loss: 0.617678]\n",
      "epoch:17 step:16740 [D loss: 0.521286, acc.: 74.22%] [G loss: 0.544998]\n",
      "epoch:17 step:16741 [D loss: 0.577326, acc.: 64.84%] [G loss: 0.618672]\n",
      "epoch:17 step:16742 [D loss: 0.560319, acc.: 66.41%] [G loss: 0.599862]\n",
      "epoch:17 step:16743 [D loss: 0.492829, acc.: 75.78%] [G loss: 0.710294]\n",
      "epoch:17 step:16744 [D loss: 0.477771, acc.: 80.47%] [G loss: 0.852961]\n",
      "epoch:17 step:16745 [D loss: 0.536357, acc.: 69.53%] [G loss: 0.682563]\n",
      "epoch:17 step:16746 [D loss: 0.621481, acc.: 67.97%] [G loss: 0.794935]\n",
      "epoch:17 step:16747 [D loss: 0.619815, acc.: 61.72%] [G loss: 0.692243]\n",
      "epoch:17 step:16748 [D loss: 0.458672, acc.: 78.12%] [G loss: 0.774810]\n",
      "epoch:17 step:16749 [D loss: 0.608820, acc.: 63.28%] [G loss: 0.648257]\n",
      "epoch:17 step:16750 [D loss: 0.513649, acc.: 72.66%] [G loss: 0.536817]\n",
      "epoch:17 step:16751 [D loss: 0.590343, acc.: 63.28%] [G loss: 0.504215]\n",
      "epoch:17 step:16752 [D loss: 0.436230, acc.: 79.69%] [G loss: 0.582006]\n",
      "epoch:17 step:16753 [D loss: 0.617664, acc.: 69.53%] [G loss: 0.602206]\n",
      "epoch:17 step:16754 [D loss: 0.513018, acc.: 73.44%] [G loss: 0.611465]\n",
      "epoch:17 step:16755 [D loss: 0.498564, acc.: 77.34%] [G loss: 0.689914]\n",
      "epoch:17 step:16756 [D loss: 0.537146, acc.: 71.88%] [G loss: 0.563901]\n",
      "epoch:17 step:16757 [D loss: 0.582183, acc.: 64.06%] [G loss: 0.563690]\n",
      "epoch:17 step:16758 [D loss: 0.532284, acc.: 67.19%] [G loss: 0.569740]\n",
      "epoch:17 step:16759 [D loss: 0.524412, acc.: 71.09%] [G loss: 0.692102]\n",
      "epoch:17 step:16760 [D loss: 0.502108, acc.: 75.78%] [G loss: 0.686287]\n",
      "epoch:17 step:16761 [D loss: 0.570402, acc.: 64.06%] [G loss: 0.570144]\n",
      "epoch:17 step:16762 [D loss: 0.526619, acc.: 71.88%] [G loss: 0.732339]\n",
      "epoch:17 step:16763 [D loss: 0.529065, acc.: 65.62%] [G loss: 0.624240]\n",
      "epoch:17 step:16764 [D loss: 0.513284, acc.: 75.78%] [G loss: 0.691540]\n",
      "epoch:17 step:16765 [D loss: 0.564439, acc.: 69.53%] [G loss: 0.500248]\n",
      "epoch:17 step:16766 [D loss: 0.552668, acc.: 66.41%] [G loss: 0.524993]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:17 step:16767 [D loss: 0.509801, acc.: 72.66%] [G loss: 0.611922]\n",
      "epoch:17 step:16768 [D loss: 0.574152, acc.: 68.75%] [G loss: 0.571603]\n",
      "epoch:17 step:16769 [D loss: 0.548853, acc.: 71.09%] [G loss: 0.531255]\n",
      "epoch:17 step:16770 [D loss: 0.538176, acc.: 75.00%] [G loss: 0.538251]\n",
      "epoch:17 step:16771 [D loss: 0.462791, acc.: 75.00%] [G loss: 0.574801]\n",
      "epoch:17 step:16772 [D loss: 0.554395, acc.: 71.09%] [G loss: 0.593832]\n",
      "epoch:17 step:16773 [D loss: 0.555171, acc.: 67.19%] [G loss: 0.659001]\n",
      "epoch:17 step:16774 [D loss: 0.569526, acc.: 68.75%] [G loss: 0.558007]\n",
      "epoch:17 step:16775 [D loss: 0.607201, acc.: 64.06%] [G loss: 0.486588]\n",
      "epoch:17 step:16776 [D loss: 0.577285, acc.: 63.28%] [G loss: 0.479859]\n",
      "epoch:17 step:16777 [D loss: 0.548291, acc.: 67.19%] [G loss: 0.473502]\n",
      "epoch:17 step:16778 [D loss: 0.529012, acc.: 74.22%] [G loss: 0.516337]\n",
      "epoch:17 step:16779 [D loss: 0.522511, acc.: 74.22%] [G loss: 0.614424]\n",
      "epoch:17 step:16780 [D loss: 0.581042, acc.: 65.62%] [G loss: 0.606185]\n",
      "epoch:17 step:16781 [D loss: 0.512637, acc.: 71.88%] [G loss: 0.711847]\n",
      "epoch:17 step:16782 [D loss: 0.524705, acc.: 75.00%] [G loss: 0.780057]\n",
      "epoch:17 step:16783 [D loss: 0.517399, acc.: 72.66%] [G loss: 0.574878]\n",
      "epoch:17 step:16784 [D loss: 0.553177, acc.: 67.97%] [G loss: 0.577789]\n",
      "epoch:17 step:16785 [D loss: 0.587357, acc.: 67.97%] [G loss: 0.615569]\n",
      "epoch:17 step:16786 [D loss: 0.437127, acc.: 78.12%] [G loss: 0.661723]\n",
      "epoch:17 step:16787 [D loss: 0.651386, acc.: 63.28%] [G loss: 0.515584]\n",
      "epoch:17 step:16788 [D loss: 0.530581, acc.: 76.56%] [G loss: 0.651775]\n",
      "epoch:17 step:16789 [D loss: 0.425571, acc.: 79.69%] [G loss: 0.866859]\n",
      "epoch:17 step:16790 [D loss: 0.580998, acc.: 68.75%] [G loss: 0.616734]\n",
      "epoch:17 step:16791 [D loss: 0.555889, acc.: 67.97%] [G loss: 0.531507]\n",
      "epoch:17 step:16792 [D loss: 0.550134, acc.: 67.97%] [G loss: 0.736872]\n",
      "epoch:17 step:16793 [D loss: 0.506464, acc.: 72.66%] [G loss: 0.643456]\n",
      "epoch:17 step:16794 [D loss: 0.552535, acc.: 67.19%] [G loss: 0.479429]\n",
      "epoch:17 step:16795 [D loss: 0.500522, acc.: 73.44%] [G loss: 0.514072]\n",
      "epoch:17 step:16796 [D loss: 0.655632, acc.: 62.50%] [G loss: 0.505180]\n",
      "epoch:17 step:16797 [D loss: 0.501779, acc.: 75.00%] [G loss: 0.608445]\n",
      "epoch:17 step:16798 [D loss: 0.600971, acc.: 64.06%] [G loss: 0.543507]\n",
      "epoch:17 step:16799 [D loss: 0.476375, acc.: 74.22%] [G loss: 0.532773]\n",
      "epoch:17 step:16800 [D loss: 0.501166, acc.: 77.34%] [G loss: 0.652497]\n",
      "epoch:17 step:16801 [D loss: 0.526121, acc.: 71.09%] [G loss: 0.686817]\n",
      "epoch:17 step:16802 [D loss: 0.606938, acc.: 64.84%] [G loss: 0.643165]\n",
      "epoch:17 step:16803 [D loss: 0.517884, acc.: 75.00%] [G loss: 0.649514]\n",
      "epoch:17 step:16804 [D loss: 0.498296, acc.: 77.34%] [G loss: 0.547730]\n",
      "epoch:17 step:16805 [D loss: 0.519120, acc.: 70.31%] [G loss: 0.563315]\n",
      "epoch:17 step:16806 [D loss: 0.554384, acc.: 67.19%] [G loss: 0.537965]\n",
      "epoch:17 step:16807 [D loss: 0.549117, acc.: 70.31%] [G loss: 0.507928]\n",
      "epoch:17 step:16808 [D loss: 0.580552, acc.: 64.06%] [G loss: 0.559218]\n",
      "epoch:17 step:16809 [D loss: 0.649698, acc.: 60.16%] [G loss: 0.473315]\n",
      "epoch:17 step:16810 [D loss: 0.574590, acc.: 65.62%] [G loss: 0.546794]\n",
      "epoch:17 step:16811 [D loss: 0.578034, acc.: 69.53%] [G loss: 0.542482]\n",
      "epoch:17 step:16812 [D loss: 0.589869, acc.: 66.41%] [G loss: 0.525611]\n",
      "epoch:17 step:16813 [D loss: 0.508606, acc.: 68.75%] [G loss: 0.536499]\n",
      "epoch:17 step:16814 [D loss: 0.462944, acc.: 78.12%] [G loss: 0.806820]\n",
      "epoch:17 step:16815 [D loss: 0.518096, acc.: 68.75%] [G loss: 0.846335]\n",
      "epoch:17 step:16816 [D loss: 0.631780, acc.: 61.72%] [G loss: 0.717721]\n",
      "epoch:17 step:16817 [D loss: 0.533851, acc.: 69.53%] [G loss: 0.698176]\n",
      "epoch:17 step:16818 [D loss: 0.541867, acc.: 67.19%] [G loss: 0.646601]\n",
      "epoch:17 step:16819 [D loss: 0.514041, acc.: 67.19%] [G loss: 0.581669]\n",
      "epoch:17 step:16820 [D loss: 0.552664, acc.: 70.31%] [G loss: 0.612326]\n",
      "epoch:17 step:16821 [D loss: 0.618198, acc.: 63.28%] [G loss: 0.479754]\n",
      "epoch:17 step:16822 [D loss: 0.534192, acc.: 71.88%] [G loss: 0.512090]\n",
      "epoch:17 step:16823 [D loss: 0.494072, acc.: 76.56%] [G loss: 0.661911]\n",
      "epoch:17 step:16824 [D loss: 0.557134, acc.: 71.09%] [G loss: 0.761706]\n",
      "epoch:17 step:16825 [D loss: 0.551272, acc.: 69.53%] [G loss: 0.806974]\n",
      "epoch:17 step:16826 [D loss: 0.501399, acc.: 70.31%] [G loss: 0.727358]\n",
      "epoch:17 step:16827 [D loss: 0.515911, acc.: 75.78%] [G loss: 0.704849]\n",
      "epoch:17 step:16828 [D loss: 0.470400, acc.: 75.78%] [G loss: 0.873579]\n",
      "epoch:17 step:16829 [D loss: 0.519344, acc.: 70.31%] [G loss: 0.757978]\n",
      "epoch:17 step:16830 [D loss: 0.508197, acc.: 74.22%] [G loss: 0.856119]\n",
      "epoch:17 step:16831 [D loss: 0.608046, acc.: 64.06%] [G loss: 0.576186]\n",
      "epoch:17 step:16832 [D loss: 0.567954, acc.: 67.97%] [G loss: 0.754617]\n",
      "epoch:17 step:16833 [D loss: 0.549867, acc.: 69.53%] [G loss: 0.637056]\n",
      "epoch:17 step:16834 [D loss: 0.578823, acc.: 71.88%] [G loss: 0.581721]\n",
      "epoch:17 step:16835 [D loss: 0.529801, acc.: 76.56%] [G loss: 0.679382]\n",
      "epoch:17 step:16836 [D loss: 0.553686, acc.: 69.53%] [G loss: 0.637221]\n",
      "epoch:17 step:16837 [D loss: 0.573608, acc.: 67.97%] [G loss: 0.559691]\n",
      "epoch:17 step:16838 [D loss: 0.475575, acc.: 78.12%] [G loss: 0.597925]\n",
      "epoch:17 step:16839 [D loss: 0.617732, acc.: 71.09%] [G loss: 0.789990]\n",
      "epoch:17 step:16840 [D loss: 0.469954, acc.: 81.25%] [G loss: 0.743336]\n",
      "epoch:17 step:16841 [D loss: 0.477847, acc.: 77.34%] [G loss: 0.676010]\n",
      "epoch:17 step:16842 [D loss: 0.502023, acc.: 75.00%] [G loss: 0.915177]\n",
      "epoch:17 step:16843 [D loss: 0.445838, acc.: 78.91%] [G loss: 0.858542]\n",
      "epoch:17 step:16844 [D loss: 0.617462, acc.: 63.28%] [G loss: 0.657011]\n",
      "epoch:17 step:16845 [D loss: 0.526142, acc.: 73.44%] [G loss: 0.596746]\n",
      "epoch:17 step:16846 [D loss: 0.581220, acc.: 64.06%] [G loss: 0.590563]\n",
      "epoch:17 step:16847 [D loss: 0.532345, acc.: 74.22%] [G loss: 0.776088]\n",
      "epoch:17 step:16848 [D loss: 0.466045, acc.: 75.78%] [G loss: 1.107153]\n",
      "epoch:17 step:16849 [D loss: 0.693300, acc.: 62.50%] [G loss: 0.581629]\n",
      "epoch:17 step:16850 [D loss: 0.497391, acc.: 73.44%] [G loss: 0.788375]\n",
      "epoch:17 step:16851 [D loss: 0.548356, acc.: 73.44%] [G loss: 0.631540]\n",
      "epoch:17 step:16852 [D loss: 0.482274, acc.: 74.22%] [G loss: 0.604108]\n",
      "epoch:17 step:16853 [D loss: 0.458703, acc.: 79.69%] [G loss: 0.804139]\n",
      "epoch:17 step:16854 [D loss: 0.513824, acc.: 72.66%] [G loss: 1.003768]\n",
      "epoch:17 step:16855 [D loss: 0.426906, acc.: 81.25%] [G loss: 1.153370]\n",
      "epoch:17 step:16856 [D loss: 0.561322, acc.: 71.09%] [G loss: 1.220313]\n",
      "epoch:17 step:16857 [D loss: 0.741176, acc.: 64.84%] [G loss: 0.996649]\n",
      "epoch:17 step:16858 [D loss: 0.547646, acc.: 71.09%] [G loss: 1.314522]\n",
      "epoch:17 step:16859 [D loss: 0.473484, acc.: 76.56%] [G loss: 1.174381]\n",
      "epoch:17 step:16860 [D loss: 0.615706, acc.: 68.75%] [G loss: 0.947228]\n",
      "epoch:17 step:16861 [D loss: 0.604991, acc.: 63.28%] [G loss: 0.728125]\n",
      "epoch:17 step:16862 [D loss: 0.477447, acc.: 75.00%] [G loss: 0.867836]\n",
      "epoch:17 step:16863 [D loss: 0.508937, acc.: 71.09%] [G loss: 0.690699]\n",
      "epoch:17 step:16864 [D loss: 0.553911, acc.: 70.31%] [G loss: 0.794199]\n",
      "epoch:17 step:16865 [D loss: 0.402341, acc.: 78.12%] [G loss: 1.001611]\n",
      "epoch:17 step:16866 [D loss: 0.472428, acc.: 83.59%] [G loss: 1.282957]\n",
      "epoch:18 step:16867 [D loss: 0.581021, acc.: 67.97%] [G loss: 0.977357]\n",
      "epoch:18 step:16868 [D loss: 0.486175, acc.: 75.00%] [G loss: 1.232686]\n",
      "epoch:18 step:16869 [D loss: 0.544514, acc.: 72.66%] [G loss: 0.931335]\n",
      "epoch:18 step:16870 [D loss: 0.477125, acc.: 77.34%] [G loss: 0.823762]\n",
      "epoch:18 step:16871 [D loss: 0.558480, acc.: 72.66%] [G loss: 0.681039]\n",
      "epoch:18 step:16872 [D loss: 0.596485, acc.: 66.41%] [G loss: 0.730048]\n",
      "epoch:18 step:16873 [D loss: 0.474624, acc.: 78.12%] [G loss: 0.858505]\n",
      "epoch:18 step:16874 [D loss: 0.494544, acc.: 76.56%] [G loss: 0.801872]\n",
      "epoch:18 step:16875 [D loss: 0.511031, acc.: 76.56%] [G loss: 0.809824]\n",
      "epoch:18 step:16876 [D loss: 0.501011, acc.: 77.34%] [G loss: 0.763037]\n",
      "epoch:18 step:16877 [D loss: 0.499189, acc.: 75.78%] [G loss: 0.742762]\n",
      "epoch:18 step:16878 [D loss: 0.548646, acc.: 69.53%] [G loss: 0.671188]\n",
      "epoch:18 step:16879 [D loss: 0.544624, acc.: 72.66%] [G loss: 0.767407]\n",
      "epoch:18 step:16880 [D loss: 0.527457, acc.: 71.88%] [G loss: 0.629867]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:18 step:16881 [D loss: 0.480701, acc.: 73.44%] [G loss: 0.761824]\n",
      "epoch:18 step:16882 [D loss: 0.452699, acc.: 76.56%] [G loss: 0.746754]\n",
      "epoch:18 step:16883 [D loss: 0.557767, acc.: 69.53%] [G loss: 0.669644]\n",
      "epoch:18 step:16884 [D loss: 0.508099, acc.: 75.78%] [G loss: 0.676482]\n",
      "epoch:18 step:16885 [D loss: 0.590970, acc.: 71.88%] [G loss: 0.646078]\n",
      "epoch:18 step:16886 [D loss: 0.636956, acc.: 60.94%] [G loss: 0.717253]\n",
      "epoch:18 step:16887 [D loss: 0.608250, acc.: 65.62%] [G loss: 0.691591]\n",
      "epoch:18 step:16888 [D loss: 0.453261, acc.: 76.56%] [G loss: 0.967229]\n",
      "epoch:18 step:16889 [D loss: 0.556346, acc.: 69.53%] [G loss: 0.856694]\n",
      "epoch:18 step:16890 [D loss: 0.553204, acc.: 71.09%] [G loss: 0.542239]\n",
      "epoch:18 step:16891 [D loss: 0.505919, acc.: 77.34%] [G loss: 0.692639]\n",
      "epoch:18 step:16892 [D loss: 0.553765, acc.: 68.75%] [G loss: 0.594882]\n",
      "epoch:18 step:16893 [D loss: 0.450670, acc.: 78.12%] [G loss: 0.639856]\n",
      "epoch:18 step:16894 [D loss: 0.537685, acc.: 69.53%] [G loss: 0.610189]\n",
      "epoch:18 step:16895 [D loss: 0.509157, acc.: 71.09%] [G loss: 0.752901]\n",
      "epoch:18 step:16896 [D loss: 0.490490, acc.: 73.44%] [G loss: 0.501952]\n",
      "epoch:18 step:16897 [D loss: 0.587239, acc.: 67.97%] [G loss: 0.580772]\n",
      "epoch:18 step:16898 [D loss: 0.557239, acc.: 65.62%] [G loss: 0.624314]\n",
      "epoch:18 step:16899 [D loss: 0.549894, acc.: 70.31%] [G loss: 0.606562]\n",
      "epoch:18 step:16900 [D loss: 0.534263, acc.: 68.75%] [G loss: 0.769333]\n",
      "epoch:18 step:16901 [D loss: 0.558609, acc.: 68.75%] [G loss: 0.659230]\n",
      "epoch:18 step:16902 [D loss: 0.464117, acc.: 78.91%] [G loss: 0.783765]\n",
      "epoch:18 step:16903 [D loss: 0.487209, acc.: 75.78%] [G loss: 0.863410]\n",
      "epoch:18 step:16904 [D loss: 0.557937, acc.: 71.09%] [G loss: 0.783101]\n",
      "epoch:18 step:16905 [D loss: 0.543647, acc.: 70.31%] [G loss: 0.722117]\n",
      "epoch:18 step:16906 [D loss: 0.438888, acc.: 82.81%] [G loss: 0.609362]\n",
      "epoch:18 step:16907 [D loss: 0.511555, acc.: 70.31%] [G loss: 0.458415]\n",
      "epoch:18 step:16908 [D loss: 0.535297, acc.: 74.22%] [G loss: 0.585967]\n",
      "epoch:18 step:16909 [D loss: 0.508361, acc.: 74.22%] [G loss: 0.748020]\n",
      "epoch:18 step:16910 [D loss: 0.590768, acc.: 67.97%] [G loss: 0.719923]\n",
      "epoch:18 step:16911 [D loss: 0.510729, acc.: 75.00%] [G loss: 0.751995]\n",
      "epoch:18 step:16912 [D loss: 0.496740, acc.: 72.66%] [G loss: 0.719848]\n",
      "epoch:18 step:16913 [D loss: 0.544603, acc.: 70.31%] [G loss: 0.690923]\n",
      "epoch:18 step:16914 [D loss: 0.493082, acc.: 77.34%] [G loss: 0.695108]\n",
      "epoch:18 step:16915 [D loss: 0.462858, acc.: 78.12%] [G loss: 0.730587]\n",
      "epoch:18 step:16916 [D loss: 0.530635, acc.: 71.88%] [G loss: 0.758610]\n",
      "epoch:18 step:16917 [D loss: 0.608400, acc.: 69.53%] [G loss: 0.605785]\n",
      "epoch:18 step:16918 [D loss: 0.582149, acc.: 68.75%] [G loss: 0.457358]\n",
      "epoch:18 step:16919 [D loss: 0.520801, acc.: 69.53%] [G loss: 0.690002]\n",
      "epoch:18 step:16920 [D loss: 0.532881, acc.: 71.09%] [G loss: 0.803860]\n",
      "epoch:18 step:16921 [D loss: 0.530727, acc.: 71.09%] [G loss: 0.691292]\n",
      "epoch:18 step:16922 [D loss: 0.486416, acc.: 75.00%] [G loss: 0.826476]\n",
      "epoch:18 step:16923 [D loss: 0.451766, acc.: 80.47%] [G loss: 0.750086]\n",
      "epoch:18 step:16924 [D loss: 0.538795, acc.: 75.00%] [G loss: 0.626387]\n",
      "epoch:18 step:16925 [D loss: 0.448730, acc.: 79.69%] [G loss: 0.934629]\n",
      "epoch:18 step:16926 [D loss: 0.579532, acc.: 67.19%] [G loss: 0.839594]\n",
      "epoch:18 step:16927 [D loss: 0.543788, acc.: 71.88%] [G loss: 0.681873]\n",
      "epoch:18 step:16928 [D loss: 0.567402, acc.: 67.97%] [G loss: 0.535999]\n",
      "epoch:18 step:16929 [D loss: 0.511341, acc.: 75.00%] [G loss: 0.532700]\n",
      "epoch:18 step:16930 [D loss: 0.613827, acc.: 67.19%] [G loss: 0.501705]\n",
      "epoch:18 step:16931 [D loss: 0.514864, acc.: 75.78%] [G loss: 0.528884]\n",
      "epoch:18 step:16932 [D loss: 0.551402, acc.: 66.41%] [G loss: 0.519250]\n",
      "epoch:18 step:16933 [D loss: 0.496842, acc.: 74.22%] [G loss: 0.815732]\n",
      "epoch:18 step:16934 [D loss: 0.511207, acc.: 72.66%] [G loss: 0.760482]\n",
      "epoch:18 step:16935 [D loss: 0.466103, acc.: 78.12%] [G loss: 0.734143]\n",
      "epoch:18 step:16936 [D loss: 0.491249, acc.: 76.56%] [G loss: 0.627472]\n",
      "epoch:18 step:16937 [D loss: 0.550399, acc.: 71.09%] [G loss: 0.465336]\n",
      "epoch:18 step:16938 [D loss: 0.511478, acc.: 70.31%] [G loss: 0.571468]\n",
      "epoch:18 step:16939 [D loss: 0.558313, acc.: 71.88%] [G loss: 0.644382]\n",
      "epoch:18 step:16940 [D loss: 0.485646, acc.: 77.34%] [G loss: 0.698046]\n",
      "epoch:18 step:16941 [D loss: 0.572331, acc.: 68.75%] [G loss: 0.702370]\n",
      "epoch:18 step:16942 [D loss: 0.483222, acc.: 75.00%] [G loss: 0.862161]\n",
      "epoch:18 step:16943 [D loss: 0.468243, acc.: 73.44%] [G loss: 0.865334]\n",
      "epoch:18 step:16944 [D loss: 0.549703, acc.: 71.09%] [G loss: 0.634653]\n",
      "epoch:18 step:16945 [D loss: 0.532043, acc.: 71.09%] [G loss: 0.755849]\n",
      "epoch:18 step:16946 [D loss: 0.525203, acc.: 67.97%] [G loss: 0.762298]\n",
      "epoch:18 step:16947 [D loss: 0.554393, acc.: 67.97%] [G loss: 0.742973]\n",
      "epoch:18 step:16948 [D loss: 0.563478, acc.: 67.97%] [G loss: 0.817881]\n",
      "epoch:18 step:16949 [D loss: 0.464598, acc.: 79.69%] [G loss: 0.664653]\n",
      "epoch:18 step:16950 [D loss: 0.521886, acc.: 68.75%] [G loss: 0.762666]\n",
      "epoch:18 step:16951 [D loss: 0.571022, acc.: 68.75%] [G loss: 0.596343]\n",
      "epoch:18 step:16952 [D loss: 0.524652, acc.: 73.44%] [G loss: 0.592863]\n",
      "epoch:18 step:16953 [D loss: 0.570302, acc.: 67.19%] [G loss: 0.686874]\n",
      "epoch:18 step:16954 [D loss: 0.501155, acc.: 71.09%] [G loss: 0.865146]\n",
      "epoch:18 step:16955 [D loss: 0.461291, acc.: 78.12%] [G loss: 0.748591]\n",
      "epoch:18 step:16956 [D loss: 0.529728, acc.: 69.53%] [G loss: 0.808160]\n",
      "epoch:18 step:16957 [D loss: 0.534335, acc.: 70.31%] [G loss: 0.595789]\n",
      "epoch:18 step:16958 [D loss: 0.493784, acc.: 72.66%] [G loss: 0.631436]\n",
      "epoch:18 step:16959 [D loss: 0.441183, acc.: 80.47%] [G loss: 0.755812]\n",
      "epoch:18 step:16960 [D loss: 0.433188, acc.: 80.47%] [G loss: 0.776987]\n",
      "epoch:18 step:16961 [D loss: 0.527958, acc.: 65.62%] [G loss: 0.752223]\n",
      "epoch:18 step:16962 [D loss: 0.530809, acc.: 71.09%] [G loss: 0.649743]\n",
      "epoch:18 step:16963 [D loss: 0.544218, acc.: 67.97%] [G loss: 0.807658]\n",
      "epoch:18 step:16964 [D loss: 0.573740, acc.: 67.97%] [G loss: 0.704249]\n",
      "epoch:18 step:16965 [D loss: 0.494044, acc.: 75.78%] [G loss: 0.640165]\n",
      "epoch:18 step:16966 [D loss: 0.452900, acc.: 78.91%] [G loss: 0.819533]\n",
      "epoch:18 step:16967 [D loss: 0.507136, acc.: 75.78%] [G loss: 0.830778]\n",
      "epoch:18 step:16968 [D loss: 0.647062, acc.: 61.72%] [G loss: 0.693160]\n",
      "epoch:18 step:16969 [D loss: 0.526413, acc.: 70.31%] [G loss: 0.566406]\n",
      "epoch:18 step:16970 [D loss: 0.516103, acc.: 68.75%] [G loss: 0.543944]\n",
      "epoch:18 step:16971 [D loss: 0.609388, acc.: 64.06%] [G loss: 0.669438]\n",
      "epoch:18 step:16972 [D loss: 0.453143, acc.: 80.47%] [G loss: 0.688487]\n",
      "epoch:18 step:16973 [D loss: 0.546462, acc.: 71.88%] [G loss: 0.741902]\n",
      "epoch:18 step:16974 [D loss: 0.587732, acc.: 68.75%] [G loss: 0.889903]\n",
      "epoch:18 step:16975 [D loss: 0.576840, acc.: 67.19%] [G loss: 0.694236]\n",
      "epoch:18 step:16976 [D loss: 0.567940, acc.: 68.75%] [G loss: 0.705727]\n",
      "epoch:18 step:16977 [D loss: 0.523071, acc.: 69.53%] [G loss: 0.594517]\n",
      "epoch:18 step:16978 [D loss: 0.531238, acc.: 71.88%] [G loss: 0.624789]\n",
      "epoch:18 step:16979 [D loss: 0.514229, acc.: 76.56%] [G loss: 0.696078]\n",
      "epoch:18 step:16980 [D loss: 0.566799, acc.: 69.53%] [G loss: 0.636212]\n",
      "epoch:18 step:16981 [D loss: 0.508183, acc.: 74.22%] [G loss: 0.696082]\n",
      "epoch:18 step:16982 [D loss: 0.515501, acc.: 71.09%] [G loss: 0.791437]\n",
      "epoch:18 step:16983 [D loss: 0.559661, acc.: 65.62%] [G loss: 0.855518]\n",
      "epoch:18 step:16984 [D loss: 0.480163, acc.: 75.78%] [G loss: 0.941356]\n",
      "epoch:18 step:16985 [D loss: 0.442147, acc.: 80.47%] [G loss: 0.787749]\n",
      "epoch:18 step:16986 [D loss: 0.549970, acc.: 74.22%] [G loss: 0.759838]\n",
      "epoch:18 step:16987 [D loss: 0.556053, acc.: 72.66%] [G loss: 0.776905]\n",
      "epoch:18 step:16988 [D loss: 0.524202, acc.: 75.78%] [G loss: 0.758204]\n",
      "epoch:18 step:16989 [D loss: 0.521285, acc.: 74.22%] [G loss: 0.782797]\n",
      "epoch:18 step:16990 [D loss: 0.550677, acc.: 66.41%] [G loss: 0.801408]\n",
      "epoch:18 step:16991 [D loss: 0.558295, acc.: 66.41%] [G loss: 0.684046]\n",
      "epoch:18 step:16992 [D loss: 0.518825, acc.: 68.75%] [G loss: 0.732269]\n",
      "epoch:18 step:16993 [D loss: 0.490656, acc.: 76.56%] [G loss: 0.729009]\n",
      "epoch:18 step:16994 [D loss: 0.521039, acc.: 74.22%] [G loss: 0.718852]\n",
      "epoch:18 step:16995 [D loss: 0.561128, acc.: 67.19%] [G loss: 0.644910]\n",
      "epoch:18 step:16996 [D loss: 0.485865, acc.: 71.88%] [G loss: 0.539053]\n",
      "epoch:18 step:16997 [D loss: 0.474932, acc.: 78.91%] [G loss: 0.658421]\n",
      "epoch:18 step:16998 [D loss: 0.511048, acc.: 75.00%] [G loss: 0.668118]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:18 step:16999 [D loss: 0.560934, acc.: 67.97%] [G loss: 0.732399]\n",
      "epoch:18 step:17000 [D loss: 0.516757, acc.: 67.97%] [G loss: 0.727925]\n",
      "epoch:18 step:17001 [D loss: 0.527791, acc.: 73.44%] [G loss: 0.672909]\n",
      "epoch:18 step:17002 [D loss: 0.559111, acc.: 68.75%] [G loss: 0.705896]\n",
      "epoch:18 step:17003 [D loss: 0.611487, acc.: 66.41%] [G loss: 0.593303]\n",
      "epoch:18 step:17004 [D loss: 0.552665, acc.: 71.88%] [G loss: 0.670448]\n",
      "epoch:18 step:17005 [D loss: 0.547847, acc.: 74.22%] [G loss: 0.650276]\n",
      "epoch:18 step:17006 [D loss: 0.517074, acc.: 72.66%] [G loss: 0.616261]\n",
      "epoch:18 step:17007 [D loss: 0.520044, acc.: 71.88%] [G loss: 0.753839]\n",
      "epoch:18 step:17008 [D loss: 0.604904, acc.: 60.16%] [G loss: 0.567077]\n",
      "epoch:18 step:17009 [D loss: 0.572522, acc.: 71.09%] [G loss: 0.596212]\n",
      "epoch:18 step:17010 [D loss: 0.507633, acc.: 73.44%] [G loss: 0.824752]\n",
      "epoch:18 step:17011 [D loss: 0.556085, acc.: 64.06%] [G loss: 0.596909]\n",
      "epoch:18 step:17012 [D loss: 0.477307, acc.: 78.91%] [G loss: 0.743617]\n",
      "epoch:18 step:17013 [D loss: 0.622324, acc.: 69.53%] [G loss: 0.661310]\n",
      "epoch:18 step:17014 [D loss: 0.531000, acc.: 71.88%] [G loss: 0.670662]\n",
      "epoch:18 step:17015 [D loss: 0.499823, acc.: 71.88%] [G loss: 0.647621]\n",
      "epoch:18 step:17016 [D loss: 0.542981, acc.: 73.44%] [G loss: 0.707242]\n",
      "epoch:18 step:17017 [D loss: 0.582015, acc.: 67.19%] [G loss: 0.652087]\n",
      "epoch:18 step:17018 [D loss: 0.484788, acc.: 75.00%] [G loss: 0.923528]\n",
      "epoch:18 step:17019 [D loss: 0.594710, acc.: 69.53%] [G loss: 0.717020]\n",
      "epoch:18 step:17020 [D loss: 0.514062, acc.: 74.22%] [G loss: 0.756200]\n",
      "epoch:18 step:17021 [D loss: 0.448696, acc.: 78.91%] [G loss: 0.814270]\n",
      "epoch:18 step:17022 [D loss: 0.452553, acc.: 77.34%] [G loss: 0.798871]\n",
      "epoch:18 step:17023 [D loss: 0.571561, acc.: 66.41%] [G loss: 0.589549]\n",
      "epoch:18 step:17024 [D loss: 0.558345, acc.: 72.66%] [G loss: 0.670812]\n",
      "epoch:18 step:17025 [D loss: 0.480150, acc.: 77.34%] [G loss: 0.657861]\n",
      "epoch:18 step:17026 [D loss: 0.605411, acc.: 68.75%] [G loss: 0.697004]\n",
      "epoch:18 step:17027 [D loss: 0.518193, acc.: 71.88%] [G loss: 0.633511]\n",
      "epoch:18 step:17028 [D loss: 0.500287, acc.: 75.78%] [G loss: 0.979681]\n",
      "epoch:18 step:17029 [D loss: 0.552175, acc.: 67.97%] [G loss: 0.852939]\n",
      "epoch:18 step:17030 [D loss: 0.535760, acc.: 67.97%] [G loss: 0.805484]\n",
      "epoch:18 step:17031 [D loss: 0.553479, acc.: 65.62%] [G loss: 0.575931]\n",
      "epoch:18 step:17032 [D loss: 0.549835, acc.: 65.62%] [G loss: 0.646783]\n",
      "epoch:18 step:17033 [D loss: 0.553208, acc.: 68.75%] [G loss: 0.643762]\n",
      "epoch:18 step:17034 [D loss: 0.515167, acc.: 74.22%] [G loss: 0.628822]\n",
      "epoch:18 step:17035 [D loss: 0.549216, acc.: 70.31%] [G loss: 0.573416]\n",
      "epoch:18 step:17036 [D loss: 0.524606, acc.: 73.44%] [G loss: 0.664576]\n",
      "epoch:18 step:17037 [D loss: 0.539213, acc.: 66.41%] [G loss: 0.530691]\n",
      "epoch:18 step:17038 [D loss: 0.530411, acc.: 73.44%] [G loss: 0.669435]\n",
      "epoch:18 step:17039 [D loss: 0.458234, acc.: 75.00%] [G loss: 0.682807]\n",
      "epoch:18 step:17040 [D loss: 0.559427, acc.: 66.41%] [G loss: 0.665818]\n",
      "epoch:18 step:17041 [D loss: 0.553748, acc.: 64.84%] [G loss: 0.619681]\n",
      "epoch:18 step:17042 [D loss: 0.453276, acc.: 82.81%] [G loss: 0.600329]\n",
      "epoch:18 step:17043 [D loss: 0.521992, acc.: 71.09%] [G loss: 0.595863]\n",
      "epoch:18 step:17044 [D loss: 0.539272, acc.: 71.09%] [G loss: 0.528063]\n",
      "epoch:18 step:17045 [D loss: 0.545993, acc.: 71.09%] [G loss: 0.623461]\n",
      "epoch:18 step:17046 [D loss: 0.614806, acc.: 65.62%] [G loss: 0.616003]\n",
      "epoch:18 step:17047 [D loss: 0.553493, acc.: 73.44%] [G loss: 0.603839]\n",
      "epoch:18 step:17048 [D loss: 0.564387, acc.: 68.75%] [G loss: 0.711072]\n",
      "epoch:18 step:17049 [D loss: 0.544460, acc.: 69.53%] [G loss: 0.710914]\n",
      "epoch:18 step:17050 [D loss: 0.518469, acc.: 70.31%] [G loss: 0.687150]\n",
      "epoch:18 step:17051 [D loss: 0.583700, acc.: 67.19%] [G loss: 0.547373]\n",
      "epoch:18 step:17052 [D loss: 0.508548, acc.: 73.44%] [G loss: 0.653185]\n",
      "epoch:18 step:17053 [D loss: 0.587394, acc.: 63.28%] [G loss: 0.524304]\n",
      "epoch:18 step:17054 [D loss: 0.534937, acc.: 72.66%] [G loss: 0.572758]\n",
      "epoch:18 step:17055 [D loss: 0.569739, acc.: 75.00%] [G loss: 0.427183]\n",
      "epoch:18 step:17056 [D loss: 0.461591, acc.: 80.47%] [G loss: 0.769404]\n",
      "epoch:18 step:17057 [D loss: 0.491134, acc.: 76.56%] [G loss: 0.692930]\n",
      "epoch:18 step:17058 [D loss: 0.525660, acc.: 69.53%] [G loss: 0.598976]\n",
      "epoch:18 step:17059 [D loss: 0.548992, acc.: 67.97%] [G loss: 0.644471]\n",
      "epoch:18 step:17060 [D loss: 0.442865, acc.: 82.03%] [G loss: 0.836083]\n",
      "epoch:18 step:17061 [D loss: 0.565258, acc.: 73.44%] [G loss: 0.777558]\n",
      "epoch:18 step:17062 [D loss: 0.612187, acc.: 63.28%] [G loss: 0.617504]\n",
      "epoch:18 step:17063 [D loss: 0.553875, acc.: 70.31%] [G loss: 0.687538]\n",
      "epoch:18 step:17064 [D loss: 0.460474, acc.: 75.78%] [G loss: 0.748341]\n",
      "epoch:18 step:17065 [D loss: 0.539302, acc.: 70.31%] [G loss: 0.788316]\n",
      "epoch:18 step:17066 [D loss: 0.607407, acc.: 67.19%] [G loss: 0.588464]\n",
      "epoch:18 step:17067 [D loss: 0.555781, acc.: 71.09%] [G loss: 0.572211]\n",
      "epoch:18 step:17068 [D loss: 0.535488, acc.: 71.88%] [G loss: 0.603085]\n",
      "epoch:18 step:17069 [D loss: 0.553306, acc.: 67.19%] [G loss: 0.537943]\n",
      "epoch:18 step:17070 [D loss: 0.554639, acc.: 71.09%] [G loss: 0.600853]\n",
      "epoch:18 step:17071 [D loss: 0.537534, acc.: 71.09%] [G loss: 0.863711]\n",
      "epoch:18 step:17072 [D loss: 0.455195, acc.: 78.91%] [G loss: 0.721825]\n",
      "epoch:18 step:17073 [D loss: 0.411721, acc.: 80.47%] [G loss: 0.852128]\n",
      "epoch:18 step:17074 [D loss: 0.472441, acc.: 69.53%] [G loss: 0.737483]\n",
      "epoch:18 step:17075 [D loss: 0.452498, acc.: 77.34%] [G loss: 0.833080]\n",
      "epoch:18 step:17076 [D loss: 0.558210, acc.: 67.97%] [G loss: 0.838451]\n",
      "epoch:18 step:17077 [D loss: 0.556258, acc.: 70.31%] [G loss: 0.557752]\n",
      "epoch:18 step:17078 [D loss: 0.522620, acc.: 72.66%] [G loss: 0.551380]\n",
      "epoch:18 step:17079 [D loss: 0.466581, acc.: 79.69%] [G loss: 0.690661]\n",
      "epoch:18 step:17080 [D loss: 0.622680, acc.: 63.28%] [G loss: 0.706127]\n",
      "epoch:18 step:17081 [D loss: 0.590883, acc.: 60.16%] [G loss: 0.508707]\n",
      "epoch:18 step:17082 [D loss: 0.585529, acc.: 67.19%] [G loss: 0.583510]\n",
      "epoch:18 step:17083 [D loss: 0.502302, acc.: 75.00%] [G loss: 0.745570]\n",
      "epoch:18 step:17084 [D loss: 0.557845, acc.: 71.09%] [G loss: 0.621367]\n",
      "epoch:18 step:17085 [D loss: 0.476064, acc.: 76.56%] [G loss: 0.681322]\n",
      "epoch:18 step:17086 [D loss: 0.706845, acc.: 59.38%] [G loss: 0.692125]\n",
      "epoch:18 step:17087 [D loss: 0.513196, acc.: 72.66%] [G loss: 0.642960]\n",
      "epoch:18 step:17088 [D loss: 0.537603, acc.: 71.09%] [G loss: 0.862327]\n",
      "epoch:18 step:17089 [D loss: 0.501348, acc.: 78.12%] [G loss: 0.669495]\n",
      "epoch:18 step:17090 [D loss: 0.553802, acc.: 68.75%] [G loss: 0.661188]\n",
      "epoch:18 step:17091 [D loss: 0.553803, acc.: 72.66%] [G loss: 0.678796]\n",
      "epoch:18 step:17092 [D loss: 0.612875, acc.: 64.06%] [G loss: 0.507766]\n",
      "epoch:18 step:17093 [D loss: 0.568841, acc.: 66.41%] [G loss: 0.512939]\n",
      "epoch:18 step:17094 [D loss: 0.574357, acc.: 67.97%] [G loss: 0.540455]\n",
      "epoch:18 step:17095 [D loss: 0.520404, acc.: 75.00%] [G loss: 0.567638]\n",
      "epoch:18 step:17096 [D loss: 0.483518, acc.: 79.69%] [G loss: 0.711901]\n",
      "epoch:18 step:17097 [D loss: 0.477776, acc.: 76.56%] [G loss: 0.757471]\n",
      "epoch:18 step:17098 [D loss: 0.446984, acc.: 82.03%] [G loss: 0.880333]\n",
      "epoch:18 step:17099 [D loss: 0.486285, acc.: 75.00%] [G loss: 0.850463]\n",
      "epoch:18 step:17100 [D loss: 0.558521, acc.: 72.66%] [G loss: 0.711131]\n",
      "epoch:18 step:17101 [D loss: 0.564926, acc.: 66.41%] [G loss: 0.613933]\n",
      "epoch:18 step:17102 [D loss: 0.530494, acc.: 66.41%] [G loss: 0.629123]\n",
      "epoch:18 step:17103 [D loss: 0.490069, acc.: 75.00%] [G loss: 0.631898]\n",
      "epoch:18 step:17104 [D loss: 0.590285, acc.: 64.06%] [G loss: 0.611008]\n",
      "epoch:18 step:17105 [D loss: 0.554174, acc.: 71.09%] [G loss: 0.531304]\n",
      "epoch:18 step:17106 [D loss: 0.545307, acc.: 69.53%] [G loss: 0.599131]\n",
      "epoch:18 step:17107 [D loss: 0.494380, acc.: 74.22%] [G loss: 0.641059]\n",
      "epoch:18 step:17108 [D loss: 0.494229, acc.: 77.34%] [G loss: 0.670718]\n",
      "epoch:18 step:17109 [D loss: 0.533411, acc.: 70.31%] [G loss: 0.729442]\n",
      "epoch:18 step:17110 [D loss: 0.447614, acc.: 77.34%] [G loss: 0.873531]\n",
      "epoch:18 step:17111 [D loss: 0.510628, acc.: 70.31%] [G loss: 0.803110]\n",
      "epoch:18 step:17112 [D loss: 0.478922, acc.: 75.00%] [G loss: 0.922992]\n",
      "epoch:18 step:17113 [D loss: 0.499726, acc.: 75.78%] [G loss: 0.840430]\n",
      "epoch:18 step:17114 [D loss: 0.478975, acc.: 77.34%] [G loss: 0.884652]\n",
      "epoch:18 step:17115 [D loss: 0.605958, acc.: 68.75%] [G loss: 0.747593]\n",
      "epoch:18 step:17116 [D loss: 0.586708, acc.: 67.19%] [G loss: 0.540741]\n",
      "epoch:18 step:17117 [D loss: 0.571458, acc.: 68.75%] [G loss: 0.574259]\n",
      "epoch:18 step:17118 [D loss: 0.563616, acc.: 66.41%] [G loss: 0.580958]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:18 step:17119 [D loss: 0.583626, acc.: 72.66%] [G loss: 0.567421]\n",
      "epoch:18 step:17120 [D loss: 0.501899, acc.: 72.66%] [G loss: 0.634438]\n",
      "epoch:18 step:17121 [D loss: 0.550624, acc.: 65.62%] [G loss: 0.654711]\n",
      "epoch:18 step:17122 [D loss: 0.581654, acc.: 64.84%] [G loss: 0.503850]\n",
      "epoch:18 step:17123 [D loss: 0.545034, acc.: 67.97%] [G loss: 0.562701]\n",
      "epoch:18 step:17124 [D loss: 0.483437, acc.: 75.00%] [G loss: 0.669777]\n",
      "epoch:18 step:17125 [D loss: 0.490485, acc.: 75.00%] [G loss: 0.817937]\n",
      "epoch:18 step:17126 [D loss: 0.543796, acc.: 70.31%] [G loss: 0.677461]\n",
      "epoch:18 step:17127 [D loss: 0.501651, acc.: 76.56%] [G loss: 0.653596]\n",
      "epoch:18 step:17128 [D loss: 0.522995, acc.: 75.78%] [G loss: 0.496549]\n",
      "epoch:18 step:17129 [D loss: 0.554281, acc.: 70.31%] [G loss: 0.597328]\n",
      "epoch:18 step:17130 [D loss: 0.495833, acc.: 76.56%] [G loss: 0.724644]\n",
      "epoch:18 step:17131 [D loss: 0.485560, acc.: 74.22%] [G loss: 0.673677]\n",
      "epoch:18 step:17132 [D loss: 0.568759, acc.: 71.09%] [G loss: 0.561814]\n",
      "epoch:18 step:17133 [D loss: 0.519813, acc.: 75.78%] [G loss: 0.706199]\n",
      "epoch:18 step:17134 [D loss: 0.521478, acc.: 71.88%] [G loss: 0.685731]\n",
      "epoch:18 step:17135 [D loss: 0.555748, acc.: 67.19%] [G loss: 0.638526]\n",
      "epoch:18 step:17136 [D loss: 0.525562, acc.: 73.44%] [G loss: 0.593721]\n",
      "epoch:18 step:17137 [D loss: 0.501426, acc.: 74.22%] [G loss: 0.726388]\n",
      "epoch:18 step:17138 [D loss: 0.559496, acc.: 70.31%] [G loss: 0.544660]\n",
      "epoch:18 step:17139 [D loss: 0.499584, acc.: 73.44%] [G loss: 0.685307]\n",
      "epoch:18 step:17140 [D loss: 0.493647, acc.: 75.00%] [G loss: 0.671070]\n",
      "epoch:18 step:17141 [D loss: 0.596275, acc.: 63.28%] [G loss: 0.641371]\n",
      "epoch:18 step:17142 [D loss: 0.467991, acc.: 78.91%] [G loss: 0.692020]\n",
      "epoch:18 step:17143 [D loss: 0.594990, acc.: 67.19%] [G loss: 0.608243]\n",
      "epoch:18 step:17144 [D loss: 0.590539, acc.: 66.41%] [G loss: 0.510344]\n",
      "epoch:18 step:17145 [D loss: 0.552308, acc.: 69.53%] [G loss: 0.573450]\n",
      "epoch:18 step:17146 [D loss: 0.526828, acc.: 71.09%] [G loss: 0.551330]\n",
      "epoch:18 step:17147 [D loss: 0.617890, acc.: 70.31%] [G loss: 0.549341]\n",
      "epoch:18 step:17148 [D loss: 0.562740, acc.: 70.31%] [G loss: 0.592416]\n",
      "epoch:18 step:17149 [D loss: 0.485519, acc.: 75.78%] [G loss: 0.644393]\n",
      "epoch:18 step:17150 [D loss: 0.549298, acc.: 66.41%] [G loss: 0.585671]\n",
      "epoch:18 step:17151 [D loss: 0.492116, acc.: 74.22%] [G loss: 0.587620]\n",
      "epoch:18 step:17152 [D loss: 0.504537, acc.: 73.44%] [G loss: 0.654308]\n",
      "epoch:18 step:17153 [D loss: 0.525024, acc.: 72.66%] [G loss: 0.629848]\n",
      "epoch:18 step:17154 [D loss: 0.489308, acc.: 75.78%] [G loss: 0.715812]\n",
      "epoch:18 step:17155 [D loss: 0.471431, acc.: 78.12%] [G loss: 0.628084]\n",
      "epoch:18 step:17156 [D loss: 0.565905, acc.: 69.53%] [G loss: 0.583732]\n",
      "epoch:18 step:17157 [D loss: 0.518500, acc.: 74.22%] [G loss: 0.701342]\n",
      "epoch:18 step:17158 [D loss: 0.500994, acc.: 72.66%] [G loss: 0.642427]\n",
      "epoch:18 step:17159 [D loss: 0.549165, acc.: 67.97%] [G loss: 0.683346]\n",
      "epoch:18 step:17160 [D loss: 0.592236, acc.: 65.62%] [G loss: 0.441420]\n",
      "epoch:18 step:17161 [D loss: 0.559372, acc.: 71.09%] [G loss: 0.509437]\n",
      "epoch:18 step:17162 [D loss: 0.512760, acc.: 67.19%] [G loss: 0.580368]\n",
      "epoch:18 step:17163 [D loss: 0.517693, acc.: 67.97%] [G loss: 0.769269]\n",
      "epoch:18 step:17164 [D loss: 0.460256, acc.: 81.25%] [G loss: 0.781643]\n",
      "epoch:18 step:17165 [D loss: 0.519441, acc.: 74.22%] [G loss: 0.809605]\n",
      "epoch:18 step:17166 [D loss: 0.496293, acc.: 76.56%] [G loss: 0.764499]\n",
      "epoch:18 step:17167 [D loss: 0.636847, acc.: 66.41%] [G loss: 0.781067]\n",
      "epoch:18 step:17168 [D loss: 0.532895, acc.: 69.53%] [G loss: 0.473769]\n",
      "epoch:18 step:17169 [D loss: 0.614294, acc.: 66.41%] [G loss: 0.577267]\n",
      "epoch:18 step:17170 [D loss: 0.475086, acc.: 73.44%] [G loss: 0.549950]\n",
      "epoch:18 step:17171 [D loss: 0.549833, acc.: 69.53%] [G loss: 0.780028]\n",
      "epoch:18 step:17172 [D loss: 0.528113, acc.: 74.22%] [G loss: 0.764477]\n",
      "epoch:18 step:17173 [D loss: 0.453412, acc.: 78.91%] [G loss: 0.742437]\n",
      "epoch:18 step:17174 [D loss: 0.539972, acc.: 67.97%] [G loss: 0.627162]\n",
      "epoch:18 step:17175 [D loss: 0.505538, acc.: 70.31%] [G loss: 0.580189]\n",
      "epoch:18 step:17176 [D loss: 0.495611, acc.: 78.91%] [G loss: 0.697096]\n",
      "epoch:18 step:17177 [D loss: 0.440680, acc.: 82.81%] [G loss: 0.682817]\n",
      "epoch:18 step:17178 [D loss: 0.465079, acc.: 82.03%] [G loss: 1.068233]\n",
      "epoch:18 step:17179 [D loss: 0.518354, acc.: 75.00%] [G loss: 0.928651]\n",
      "epoch:18 step:17180 [D loss: 0.449793, acc.: 78.91%] [G loss: 0.840271]\n",
      "epoch:18 step:17181 [D loss: 0.477515, acc.: 76.56%] [G loss: 0.773985]\n",
      "epoch:18 step:17182 [D loss: 0.615418, acc.: 71.88%] [G loss: 0.721199]\n",
      "epoch:18 step:17183 [D loss: 0.573064, acc.: 69.53%] [G loss: 0.656511]\n",
      "epoch:18 step:17184 [D loss: 0.517860, acc.: 70.31%] [G loss: 0.665490]\n",
      "epoch:18 step:17185 [D loss: 0.542452, acc.: 71.88%] [G loss: 0.683382]\n",
      "epoch:18 step:17186 [D loss: 0.558641, acc.: 66.41%] [G loss: 0.590220]\n",
      "epoch:18 step:17187 [D loss: 0.462537, acc.: 80.47%] [G loss: 0.778189]\n",
      "epoch:18 step:17188 [D loss: 0.534452, acc.: 74.22%] [G loss: 0.642835]\n",
      "epoch:18 step:17189 [D loss: 0.583029, acc.: 67.97%] [G loss: 0.591754]\n",
      "epoch:18 step:17190 [D loss: 0.517461, acc.: 74.22%] [G loss: 0.752580]\n",
      "epoch:18 step:17191 [D loss: 0.548975, acc.: 67.97%] [G loss: 0.695606]\n",
      "epoch:18 step:17192 [D loss: 0.407176, acc.: 83.59%] [G loss: 0.703802]\n",
      "epoch:18 step:17193 [D loss: 0.513521, acc.: 74.22%] [G loss: 0.667264]\n",
      "epoch:18 step:17194 [D loss: 0.440260, acc.: 77.34%] [G loss: 0.750201]\n",
      "epoch:18 step:17195 [D loss: 0.526259, acc.: 71.88%] [G loss: 0.734581]\n",
      "epoch:18 step:17196 [D loss: 0.507533, acc.: 78.91%] [G loss: 0.560014]\n",
      "epoch:18 step:17197 [D loss: 0.554980, acc.: 76.56%] [G loss: 0.497344]\n",
      "epoch:18 step:17198 [D loss: 0.518742, acc.: 71.09%] [G loss: 0.536794]\n",
      "epoch:18 step:17199 [D loss: 0.470769, acc.: 77.34%] [G loss: 0.688592]\n",
      "epoch:18 step:17200 [D loss: 0.445566, acc.: 78.12%] [G loss: 0.749789]\n",
      "epoch:18 step:17201 [D loss: 0.476011, acc.: 75.00%] [G loss: 0.773328]\n",
      "epoch:18 step:17202 [D loss: 0.490060, acc.: 73.44%] [G loss: 0.784657]\n",
      "epoch:18 step:17203 [D loss: 0.498659, acc.: 72.66%] [G loss: 0.785218]\n",
      "epoch:18 step:17204 [D loss: 0.527806, acc.: 75.00%] [G loss: 0.760777]\n",
      "epoch:18 step:17205 [D loss: 0.510118, acc.: 75.78%] [G loss: 0.592067]\n",
      "epoch:18 step:17206 [D loss: 0.501689, acc.: 71.88%] [G loss: 0.906422]\n",
      "epoch:18 step:17207 [D loss: 0.574889, acc.: 73.44%] [G loss: 0.619459]\n",
      "epoch:18 step:17208 [D loss: 0.686656, acc.: 63.28%] [G loss: 0.828746]\n",
      "epoch:18 step:17209 [D loss: 0.517382, acc.: 69.53%] [G loss: 0.820389]\n",
      "epoch:18 step:17210 [D loss: 0.442894, acc.: 81.25%] [G loss: 0.706274]\n",
      "epoch:18 step:17211 [D loss: 0.634097, acc.: 61.72%] [G loss: 0.630829]\n",
      "epoch:18 step:17212 [D loss: 0.553158, acc.: 67.19%] [G loss: 0.793763]\n",
      "epoch:18 step:17213 [D loss: 0.395733, acc.: 83.59%] [G loss: 0.842111]\n",
      "epoch:18 step:17214 [D loss: 0.595378, acc.: 65.62%] [G loss: 0.592633]\n",
      "epoch:18 step:17215 [D loss: 0.632732, acc.: 62.50%] [G loss: 0.546467]\n",
      "epoch:18 step:17216 [D loss: 0.527823, acc.: 72.66%] [G loss: 0.573435]\n",
      "epoch:18 step:17217 [D loss: 0.480964, acc.: 80.47%] [G loss: 0.874339]\n",
      "epoch:18 step:17218 [D loss: 0.590480, acc.: 69.53%] [G loss: 0.734043]\n",
      "epoch:18 step:17219 [D loss: 0.543235, acc.: 72.66%] [G loss: 0.584049]\n",
      "epoch:18 step:17220 [D loss: 0.408284, acc.: 78.91%] [G loss: 0.973978]\n",
      "epoch:18 step:17221 [D loss: 0.524005, acc.: 72.66%] [G loss: 0.764267]\n",
      "epoch:18 step:17222 [D loss: 0.592779, acc.: 70.31%] [G loss: 1.042283]\n",
      "epoch:18 step:17223 [D loss: 0.451734, acc.: 78.12%] [G loss: 0.782795]\n",
      "epoch:18 step:17224 [D loss: 0.436294, acc.: 79.69%] [G loss: 0.877766]\n",
      "epoch:18 step:17225 [D loss: 0.499034, acc.: 73.44%] [G loss: 1.026804]\n",
      "epoch:18 step:17226 [D loss: 0.485439, acc.: 73.44%] [G loss: 0.910866]\n",
      "epoch:18 step:17227 [D loss: 0.478635, acc.: 74.22%] [G loss: 0.888034]\n",
      "epoch:18 step:17228 [D loss: 0.532235, acc.: 71.88%] [G loss: 0.777000]\n",
      "epoch:18 step:17229 [D loss: 0.482872, acc.: 74.22%] [G loss: 0.667538]\n",
      "epoch:18 step:17230 [D loss: 0.487796, acc.: 73.44%] [G loss: 0.678524]\n",
      "epoch:18 step:17231 [D loss: 0.491552, acc.: 75.00%] [G loss: 0.596113]\n",
      "epoch:18 step:17232 [D loss: 0.508042, acc.: 71.09%] [G loss: 0.840415]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:18 step:17233 [D loss: 0.592520, acc.: 67.19%] [G loss: 0.718149]\n",
      "epoch:18 step:17234 [D loss: 0.523165, acc.: 66.41%] [G loss: 0.686128]\n",
      "epoch:18 step:17235 [D loss: 0.547586, acc.: 71.09%] [G loss: 0.639281]\n",
      "epoch:18 step:17236 [D loss: 0.544815, acc.: 71.88%] [G loss: 0.682317]\n",
      "epoch:18 step:17237 [D loss: 0.486803, acc.: 75.78%] [G loss: 0.686015]\n",
      "epoch:18 step:17238 [D loss: 0.529139, acc.: 72.66%] [G loss: 0.710459]\n",
      "epoch:18 step:17239 [D loss: 0.510833, acc.: 74.22%] [G loss: 0.667021]\n",
      "epoch:18 step:17240 [D loss: 0.444128, acc.: 80.47%] [G loss: 0.724855]\n",
      "epoch:18 step:17241 [D loss: 0.558382, acc.: 67.97%] [G loss: 0.764118]\n",
      "epoch:18 step:17242 [D loss: 0.684229, acc.: 63.28%] [G loss: 0.511793]\n",
      "epoch:18 step:17243 [D loss: 0.608401, acc.: 62.50%] [G loss: 0.410105]\n",
      "epoch:18 step:17244 [D loss: 0.562209, acc.: 69.53%] [G loss: 0.512825]\n",
      "epoch:18 step:17245 [D loss: 0.551212, acc.: 71.09%] [G loss: 0.622093]\n",
      "epoch:18 step:17246 [D loss: 0.615490, acc.: 69.53%] [G loss: 0.478619]\n",
      "epoch:18 step:17247 [D loss: 0.440912, acc.: 78.12%] [G loss: 0.633790]\n",
      "epoch:18 step:17248 [D loss: 0.498693, acc.: 73.44%] [G loss: 0.815618]\n",
      "epoch:18 step:17249 [D loss: 0.536561, acc.: 71.09%] [G loss: 0.860762]\n",
      "epoch:18 step:17250 [D loss: 0.531784, acc.: 71.09%] [G loss: 0.689431]\n",
      "epoch:18 step:17251 [D loss: 0.496079, acc.: 74.22%] [G loss: 0.542735]\n",
      "epoch:18 step:17252 [D loss: 0.596334, acc.: 64.06%] [G loss: 0.542879]\n",
      "epoch:18 step:17253 [D loss: 0.556103, acc.: 70.31%] [G loss: 0.468113]\n",
      "epoch:18 step:17254 [D loss: 0.563007, acc.: 68.75%] [G loss: 0.546226]\n",
      "epoch:18 step:17255 [D loss: 0.504059, acc.: 73.44%] [G loss: 0.653238]\n",
      "epoch:18 step:17256 [D loss: 0.582359, acc.: 65.62%] [G loss: 0.701941]\n",
      "epoch:18 step:17257 [D loss: 0.555100, acc.: 65.62%] [G loss: 0.673584]\n",
      "epoch:18 step:17258 [D loss: 0.465936, acc.: 73.44%] [G loss: 0.717338]\n",
      "epoch:18 step:17259 [D loss: 0.611913, acc.: 62.50%] [G loss: 0.555523]\n",
      "epoch:18 step:17260 [D loss: 0.514759, acc.: 71.09%] [G loss: 0.732353]\n",
      "epoch:18 step:17261 [D loss: 0.462749, acc.: 80.47%] [G loss: 0.634387]\n",
      "epoch:18 step:17262 [D loss: 0.636580, acc.: 64.84%] [G loss: 0.683661]\n",
      "epoch:18 step:17263 [D loss: 0.592715, acc.: 61.72%] [G loss: 0.635683]\n",
      "epoch:18 step:17264 [D loss: 0.453521, acc.: 79.69%] [G loss: 0.727503]\n",
      "epoch:18 step:17265 [D loss: 0.471461, acc.: 77.34%] [G loss: 0.712643]\n",
      "epoch:18 step:17266 [D loss: 0.595999, acc.: 71.88%] [G loss: 0.602221]\n",
      "epoch:18 step:17267 [D loss: 0.616727, acc.: 58.59%] [G loss: 0.592884]\n",
      "epoch:18 step:17268 [D loss: 0.467057, acc.: 79.69%] [G loss: 0.701181]\n",
      "epoch:18 step:17269 [D loss: 0.538492, acc.: 72.66%] [G loss: 0.571845]\n",
      "epoch:18 step:17270 [D loss: 0.581471, acc.: 67.19%] [G loss: 0.623346]\n",
      "epoch:18 step:17271 [D loss: 0.526285, acc.: 74.22%] [G loss: 0.636471]\n",
      "epoch:18 step:17272 [D loss: 0.487550, acc.: 75.00%] [G loss: 0.684318]\n",
      "epoch:18 step:17273 [D loss: 0.552240, acc.: 69.53%] [G loss: 0.579851]\n",
      "epoch:18 step:17274 [D loss: 0.522196, acc.: 72.66%] [G loss: 0.698554]\n",
      "epoch:18 step:17275 [D loss: 0.546094, acc.: 69.53%] [G loss: 0.598187]\n",
      "epoch:18 step:17276 [D loss: 0.567993, acc.: 74.22%] [G loss: 0.764575]\n",
      "epoch:18 step:17277 [D loss: 0.559897, acc.: 65.62%] [G loss: 0.598694]\n",
      "epoch:18 step:17278 [D loss: 0.612976, acc.: 64.06%] [G loss: 0.569565]\n",
      "epoch:18 step:17279 [D loss: 0.523109, acc.: 75.00%] [G loss: 0.810758]\n",
      "epoch:18 step:17280 [D loss: 0.479559, acc.: 77.34%] [G loss: 0.674739]\n",
      "epoch:18 step:17281 [D loss: 0.534692, acc.: 67.97%] [G loss: 0.564592]\n",
      "epoch:18 step:17282 [D loss: 0.448343, acc.: 75.78%] [G loss: 0.866399]\n",
      "epoch:18 step:17283 [D loss: 0.572536, acc.: 66.41%] [G loss: 0.716506]\n",
      "epoch:18 step:17284 [D loss: 0.565256, acc.: 70.31%] [G loss: 0.709874]\n",
      "epoch:18 step:17285 [D loss: 0.582245, acc.: 68.75%] [G loss: 0.658862]\n",
      "epoch:18 step:17286 [D loss: 0.596591, acc.: 62.50%] [G loss: 0.753173]\n",
      "epoch:18 step:17287 [D loss: 0.545310, acc.: 74.22%] [G loss: 0.637829]\n",
      "epoch:18 step:17288 [D loss: 0.619846, acc.: 65.62%] [G loss: 0.628296]\n",
      "epoch:18 step:17289 [D loss: 0.557173, acc.: 67.97%] [G loss: 0.584722]\n",
      "epoch:18 step:17290 [D loss: 0.538969, acc.: 67.19%] [G loss: 0.587264]\n",
      "epoch:18 step:17291 [D loss: 0.483637, acc.: 73.44%] [G loss: 0.724943]\n",
      "epoch:18 step:17292 [D loss: 0.494801, acc.: 72.66%] [G loss: 0.844435]\n",
      "epoch:18 step:17293 [D loss: 0.445992, acc.: 77.34%] [G loss: 0.728149]\n",
      "epoch:18 step:17294 [D loss: 0.519179, acc.: 70.31%] [G loss: 0.805308]\n",
      "epoch:18 step:17295 [D loss: 0.503527, acc.: 73.44%] [G loss: 0.778289]\n",
      "epoch:18 step:17296 [D loss: 0.494304, acc.: 71.88%] [G loss: 0.929680]\n",
      "epoch:18 step:17297 [D loss: 0.497930, acc.: 75.78%] [G loss: 0.650735]\n",
      "epoch:18 step:17298 [D loss: 0.556178, acc.: 67.19%] [G loss: 0.749931]\n",
      "epoch:18 step:17299 [D loss: 0.586160, acc.: 65.62%] [G loss: 0.517097]\n",
      "epoch:18 step:17300 [D loss: 0.502775, acc.: 74.22%] [G loss: 0.685876]\n",
      "epoch:18 step:17301 [D loss: 0.513991, acc.: 75.78%] [G loss: 0.721009]\n",
      "epoch:18 step:17302 [D loss: 0.482587, acc.: 77.34%] [G loss: 0.732407]\n",
      "epoch:18 step:17303 [D loss: 0.644494, acc.: 62.50%] [G loss: 0.707881]\n",
      "epoch:18 step:17304 [D loss: 0.589567, acc.: 64.84%] [G loss: 0.687659]\n",
      "epoch:18 step:17305 [D loss: 0.512735, acc.: 75.78%] [G loss: 0.755957]\n",
      "epoch:18 step:17306 [D loss: 0.484514, acc.: 72.66%] [G loss: 0.771160]\n",
      "epoch:18 step:17307 [D loss: 0.524179, acc.: 72.66%] [G loss: 0.653078]\n",
      "epoch:18 step:17308 [D loss: 0.505464, acc.: 72.66%] [G loss: 0.837212]\n",
      "epoch:18 step:17309 [D loss: 0.505142, acc.: 71.88%] [G loss: 0.655862]\n",
      "epoch:18 step:17310 [D loss: 0.483416, acc.: 78.12%] [G loss: 0.664303]\n",
      "epoch:18 step:17311 [D loss: 0.545548, acc.: 69.53%] [G loss: 0.720698]\n",
      "epoch:18 step:17312 [D loss: 0.544832, acc.: 65.62%] [G loss: 0.834659]\n",
      "epoch:18 step:17313 [D loss: 0.543852, acc.: 67.19%] [G loss: 0.504902]\n",
      "epoch:18 step:17314 [D loss: 0.505389, acc.: 78.12%] [G loss: 0.617039]\n",
      "epoch:18 step:17315 [D loss: 0.441018, acc.: 77.34%] [G loss: 0.839227]\n",
      "epoch:18 step:17316 [D loss: 0.507514, acc.: 73.44%] [G loss: 0.672462]\n",
      "epoch:18 step:17317 [D loss: 0.410381, acc.: 82.81%] [G loss: 0.783647]\n",
      "epoch:18 step:17318 [D loss: 0.589011, acc.: 71.88%] [G loss: 0.794768]\n",
      "epoch:18 step:17319 [D loss: 0.503118, acc.: 75.78%] [G loss: 0.867636]\n",
      "epoch:18 step:17320 [D loss: 0.526760, acc.: 73.44%] [G loss: 0.713506]\n",
      "epoch:18 step:17321 [D loss: 0.591257, acc.: 66.41%] [G loss: 0.639241]\n",
      "epoch:18 step:17322 [D loss: 0.598063, acc.: 65.62%] [G loss: 0.600507]\n",
      "epoch:18 step:17323 [D loss: 0.518706, acc.: 76.56%] [G loss: 0.710803]\n",
      "epoch:18 step:17324 [D loss: 0.665105, acc.: 61.72%] [G loss: 0.557693]\n",
      "epoch:18 step:17325 [D loss: 0.529976, acc.: 71.88%] [G loss: 0.517293]\n",
      "epoch:18 step:17326 [D loss: 0.520460, acc.: 70.31%] [G loss: 0.710538]\n",
      "epoch:18 step:17327 [D loss: 0.492998, acc.: 75.00%] [G loss: 0.641272]\n",
      "epoch:18 step:17328 [D loss: 0.586933, acc.: 63.28%] [G loss: 0.604284]\n",
      "epoch:18 step:17329 [D loss: 0.523354, acc.: 70.31%] [G loss: 0.568928]\n",
      "epoch:18 step:17330 [D loss: 0.508023, acc.: 74.22%] [G loss: 0.603445]\n",
      "epoch:18 step:17331 [D loss: 0.571286, acc.: 69.53%] [G loss: 0.476668]\n",
      "epoch:18 step:17332 [D loss: 0.549331, acc.: 66.41%] [G loss: 0.426864]\n",
      "epoch:18 step:17333 [D loss: 0.546471, acc.: 71.88%] [G loss: 0.593772]\n",
      "epoch:18 step:17334 [D loss: 0.539393, acc.: 73.44%] [G loss: 0.577253]\n",
      "epoch:18 step:17335 [D loss: 0.547932, acc.: 67.19%] [G loss: 0.691488]\n",
      "epoch:18 step:17336 [D loss: 0.511185, acc.: 73.44%] [G loss: 0.713414]\n",
      "epoch:18 step:17337 [D loss: 0.447598, acc.: 79.69%] [G loss: 0.796728]\n",
      "epoch:18 step:17338 [D loss: 0.464597, acc.: 78.12%] [G loss: 0.906245]\n",
      "epoch:18 step:17339 [D loss: 0.633877, acc.: 63.28%] [G loss: 0.643452]\n",
      "epoch:18 step:17340 [D loss: 0.584905, acc.: 69.53%] [G loss: 0.607317]\n",
      "epoch:18 step:17341 [D loss: 0.446138, acc.: 78.91%] [G loss: 0.732384]\n",
      "epoch:18 step:17342 [D loss: 0.470619, acc.: 79.69%] [G loss: 0.821119]\n",
      "epoch:18 step:17343 [D loss: 0.640150, acc.: 63.28%] [G loss: 0.592082]\n",
      "epoch:18 step:17344 [D loss: 0.590873, acc.: 68.75%] [G loss: 0.510859]\n",
      "epoch:18 step:17345 [D loss: 0.516938, acc.: 71.09%] [G loss: 0.598218]\n",
      "epoch:18 step:17346 [D loss: 0.580461, acc.: 70.31%] [G loss: 0.532832]\n",
      "epoch:18 step:17347 [D loss: 0.507952, acc.: 75.78%] [G loss: 0.574135]\n",
      "epoch:18 step:17348 [D loss: 0.565488, acc.: 70.31%] [G loss: 0.641535]\n",
      "epoch:18 step:17349 [D loss: 0.530438, acc.: 68.75%] [G loss: 0.594773]\n",
      "epoch:18 step:17350 [D loss: 0.504258, acc.: 73.44%] [G loss: 0.784289]\n",
      "epoch:18 step:17351 [D loss: 0.557608, acc.: 67.97%] [G loss: 0.983332]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:18 step:17352 [D loss: 0.565228, acc.: 67.97%] [G loss: 0.848765]\n",
      "epoch:18 step:17353 [D loss: 0.561895, acc.: 67.19%] [G loss: 0.727888]\n",
      "epoch:18 step:17354 [D loss: 0.486248, acc.: 74.22%] [G loss: 0.649125]\n",
      "epoch:18 step:17355 [D loss: 0.543756, acc.: 72.66%] [G loss: 0.638714]\n",
      "epoch:18 step:17356 [D loss: 0.531136, acc.: 72.66%] [G loss: 0.728734]\n",
      "epoch:18 step:17357 [D loss: 0.509723, acc.: 70.31%] [G loss: 0.714001]\n",
      "epoch:18 step:17358 [D loss: 0.548702, acc.: 72.66%] [G loss: 0.594727]\n",
      "epoch:18 step:17359 [D loss: 0.541162, acc.: 71.88%] [G loss: 0.570784]\n",
      "epoch:18 step:17360 [D loss: 0.539340, acc.: 74.22%] [G loss: 0.454942]\n",
      "epoch:18 step:17361 [D loss: 0.568893, acc.: 67.19%] [G loss: 0.628521]\n",
      "epoch:18 step:17362 [D loss: 0.573005, acc.: 68.75%] [G loss: 0.721912]\n",
      "epoch:18 step:17363 [D loss: 0.543697, acc.: 74.22%] [G loss: 0.693793]\n",
      "epoch:18 step:17364 [D loss: 0.519106, acc.: 71.88%] [G loss: 0.706401]\n",
      "epoch:18 step:17365 [D loss: 0.446250, acc.: 75.78%] [G loss: 0.787879]\n",
      "epoch:18 step:17366 [D loss: 0.559235, acc.: 68.75%] [G loss: 0.722454]\n",
      "epoch:18 step:17367 [D loss: 0.584988, acc.: 66.41%] [G loss: 0.579168]\n",
      "epoch:18 step:17368 [D loss: 0.702881, acc.: 54.69%] [G loss: 0.471815]\n",
      "epoch:18 step:17369 [D loss: 0.483869, acc.: 73.44%] [G loss: 0.752289]\n",
      "epoch:18 step:17370 [D loss: 0.478016, acc.: 80.47%] [G loss: 0.831194]\n",
      "epoch:18 step:17371 [D loss: 0.500466, acc.: 75.78%] [G loss: 0.764098]\n",
      "epoch:18 step:17372 [D loss: 0.476758, acc.: 78.91%] [G loss: 0.783989]\n",
      "epoch:18 step:17373 [D loss: 0.479889, acc.: 78.91%] [G loss: 0.842902]\n",
      "epoch:18 step:17374 [D loss: 0.463458, acc.: 78.12%] [G loss: 1.029551]\n",
      "epoch:18 step:17375 [D loss: 0.490609, acc.: 73.44%] [G loss: 0.875645]\n",
      "epoch:18 step:17376 [D loss: 0.639263, acc.: 67.19%] [G loss: 0.764762]\n",
      "epoch:18 step:17377 [D loss: 0.591667, acc.: 67.19%] [G loss: 0.536254]\n",
      "epoch:18 step:17378 [D loss: 0.579797, acc.: 62.50%] [G loss: 0.558179]\n",
      "epoch:18 step:17379 [D loss: 0.517747, acc.: 73.44%] [G loss: 0.649960]\n",
      "epoch:18 step:17380 [D loss: 0.479997, acc.: 76.56%] [G loss: 0.661345]\n",
      "epoch:18 step:17381 [D loss: 0.527880, acc.: 71.09%] [G loss: 0.745420]\n",
      "epoch:18 step:17382 [D loss: 0.483063, acc.: 74.22%] [G loss: 0.842403]\n",
      "epoch:18 step:17383 [D loss: 0.484742, acc.: 76.56%] [G loss: 0.763289]\n",
      "epoch:18 step:17384 [D loss: 0.521155, acc.: 74.22%] [G loss: 0.681051]\n",
      "epoch:18 step:17385 [D loss: 0.501550, acc.: 73.44%] [G loss: 0.579185]\n",
      "epoch:18 step:17386 [D loss: 0.509557, acc.: 71.88%] [G loss: 0.797997]\n",
      "epoch:18 step:17387 [D loss: 0.503403, acc.: 72.66%] [G loss: 0.709594]\n",
      "epoch:18 step:17388 [D loss: 0.509840, acc.: 78.91%] [G loss: 0.763027]\n",
      "epoch:18 step:17389 [D loss: 0.445819, acc.: 78.12%] [G loss: 0.828533]\n",
      "epoch:18 step:17390 [D loss: 0.533544, acc.: 69.53%] [G loss: 0.851252]\n",
      "epoch:18 step:17391 [D loss: 0.547966, acc.: 73.44%] [G loss: 0.702720]\n",
      "epoch:18 step:17392 [D loss: 0.497623, acc.: 75.78%] [G loss: 0.668425]\n",
      "epoch:18 step:17393 [D loss: 0.549130, acc.: 64.06%] [G loss: 0.869374]\n",
      "epoch:18 step:17394 [D loss: 0.655872, acc.: 62.50%] [G loss: 0.669597]\n",
      "epoch:18 step:17395 [D loss: 0.561335, acc.: 68.75%] [G loss: 0.608378]\n",
      "epoch:18 step:17396 [D loss: 0.516002, acc.: 71.88%] [G loss: 0.783412]\n",
      "epoch:18 step:17397 [D loss: 0.571177, acc.: 66.41%] [G loss: 0.647641]\n",
      "epoch:18 step:17398 [D loss: 0.603414, acc.: 64.84%] [G loss: 0.578850]\n",
      "epoch:18 step:17399 [D loss: 0.523716, acc.: 74.22%] [G loss: 0.689542]\n",
      "epoch:18 step:17400 [D loss: 0.466984, acc.: 77.34%] [G loss: 0.661504]\n",
      "epoch:18 step:17401 [D loss: 0.606944, acc.: 65.62%] [G loss: 0.520625]\n",
      "epoch:18 step:17402 [D loss: 0.460495, acc.: 77.34%] [G loss: 0.567560]\n",
      "epoch:18 step:17403 [D loss: 0.563817, acc.: 67.97%] [G loss: 0.659717]\n",
      "epoch:18 step:17404 [D loss: 0.534627, acc.: 72.66%] [G loss: 0.483477]\n",
      "epoch:18 step:17405 [D loss: 0.541551, acc.: 69.53%] [G loss: 0.573497]\n",
      "epoch:18 step:17406 [D loss: 0.556058, acc.: 71.09%] [G loss: 0.519346]\n",
      "epoch:18 step:17407 [D loss: 0.515489, acc.: 74.22%] [G loss: 0.660879]\n",
      "epoch:18 step:17408 [D loss: 0.631853, acc.: 66.41%] [G loss: 0.535241]\n",
      "epoch:18 step:17409 [D loss: 0.580853, acc.: 64.84%] [G loss: 0.559209]\n",
      "epoch:18 step:17410 [D loss: 0.473563, acc.: 78.12%] [G loss: 0.562073]\n",
      "epoch:18 step:17411 [D loss: 0.531571, acc.: 72.66%] [G loss: 0.740648]\n",
      "epoch:18 step:17412 [D loss: 0.496663, acc.: 75.78%] [G loss: 0.772109]\n",
      "epoch:18 step:17413 [D loss: 0.493901, acc.: 74.22%] [G loss: 0.793122]\n",
      "epoch:18 step:17414 [D loss: 0.487527, acc.: 73.44%] [G loss: 0.770843]\n",
      "epoch:18 step:17415 [D loss: 0.500919, acc.: 75.00%] [G loss: 0.609387]\n",
      "epoch:18 step:17416 [D loss: 0.481003, acc.: 70.31%] [G loss: 0.618022]\n",
      "epoch:18 step:17417 [D loss: 0.498629, acc.: 72.66%] [G loss: 0.705491]\n",
      "epoch:18 step:17418 [D loss: 0.466584, acc.: 75.78%] [G loss: 0.856730]\n",
      "epoch:18 step:17419 [D loss: 0.591092, acc.: 67.19%] [G loss: 0.680471]\n",
      "epoch:18 step:17420 [D loss: 0.423347, acc.: 82.03%] [G loss: 0.782949]\n",
      "epoch:18 step:17421 [D loss: 0.436148, acc.: 82.03%] [G loss: 0.821991]\n",
      "epoch:18 step:17422 [D loss: 0.502551, acc.: 75.00%] [G loss: 0.768967]\n",
      "epoch:18 step:17423 [D loss: 0.520164, acc.: 72.66%] [G loss: 0.764639]\n",
      "epoch:18 step:17424 [D loss: 0.462196, acc.: 76.56%] [G loss: 0.746744]\n",
      "epoch:18 step:17425 [D loss: 0.594830, acc.: 70.31%] [G loss: 0.598773]\n",
      "epoch:18 step:17426 [D loss: 0.531966, acc.: 68.75%] [G loss: 0.794835]\n",
      "epoch:18 step:17427 [D loss: 0.525012, acc.: 68.75%] [G loss: 0.729505]\n",
      "epoch:18 step:17428 [D loss: 0.587767, acc.: 67.97%] [G loss: 0.516027]\n",
      "epoch:18 step:17429 [D loss: 0.520371, acc.: 71.88%] [G loss: 0.542579]\n",
      "epoch:18 step:17430 [D loss: 0.463185, acc.: 77.34%] [G loss: 0.759305]\n",
      "epoch:18 step:17431 [D loss: 0.576065, acc.: 74.22%] [G loss: 0.759378]\n",
      "epoch:18 step:17432 [D loss: 0.612596, acc.: 70.31%] [G loss: 0.744359]\n",
      "epoch:18 step:17433 [D loss: 0.516439, acc.: 75.78%] [G loss: 0.691445]\n",
      "epoch:18 step:17434 [D loss: 0.477595, acc.: 76.56%] [G loss: 0.667932]\n",
      "epoch:18 step:17435 [D loss: 0.519911, acc.: 72.66%] [G loss: 0.687114]\n",
      "epoch:18 step:17436 [D loss: 0.461883, acc.: 78.12%] [G loss: 0.629441]\n",
      "epoch:18 step:17437 [D loss: 0.581110, acc.: 67.19%] [G loss: 0.805758]\n",
      "epoch:18 step:17438 [D loss: 0.542844, acc.: 67.97%] [G loss: 0.576401]\n",
      "epoch:18 step:17439 [D loss: 0.562281, acc.: 67.97%] [G loss: 0.787531]\n",
      "epoch:18 step:17440 [D loss: 0.491996, acc.: 74.22%] [G loss: 0.777619]\n",
      "epoch:18 step:17441 [D loss: 0.536507, acc.: 74.22%] [G loss: 0.870423]\n",
      "epoch:18 step:17442 [D loss: 0.567742, acc.: 68.75%] [G loss: 0.752177]\n",
      "epoch:18 step:17443 [D loss: 0.519752, acc.: 74.22%] [G loss: 0.655124]\n",
      "epoch:18 step:17444 [D loss: 0.576764, acc.: 70.31%] [G loss: 0.660405]\n",
      "epoch:18 step:17445 [D loss: 0.475306, acc.: 75.00%] [G loss: 0.651382]\n",
      "epoch:18 step:17446 [D loss: 0.600183, acc.: 64.84%] [G loss: 0.555124]\n",
      "epoch:18 step:17447 [D loss: 0.540160, acc.: 67.19%] [G loss: 0.717618]\n",
      "epoch:18 step:17448 [D loss: 0.410125, acc.: 85.94%] [G loss: 0.747371]\n",
      "epoch:18 step:17449 [D loss: 0.538424, acc.: 66.41%] [G loss: 0.584652]\n",
      "epoch:18 step:17450 [D loss: 0.573515, acc.: 64.84%] [G loss: 0.629227]\n",
      "epoch:18 step:17451 [D loss: 0.546601, acc.: 75.78%] [G loss: 0.615970]\n",
      "epoch:18 step:17452 [D loss: 0.518594, acc.: 67.97%] [G loss: 0.519809]\n",
      "epoch:18 step:17453 [D loss: 0.530903, acc.: 72.66%] [G loss: 0.615134]\n",
      "epoch:18 step:17454 [D loss: 0.527311, acc.: 71.88%] [G loss: 0.822248]\n",
      "epoch:18 step:17455 [D loss: 0.493502, acc.: 72.66%] [G loss: 0.732566]\n",
      "epoch:18 step:17456 [D loss: 0.561841, acc.: 73.44%] [G loss: 0.675673]\n",
      "epoch:18 step:17457 [D loss: 0.570208, acc.: 71.09%] [G loss: 0.703799]\n",
      "epoch:18 step:17458 [D loss: 0.492156, acc.: 78.12%] [G loss: 0.679481]\n",
      "epoch:18 step:17459 [D loss: 0.497706, acc.: 76.56%] [G loss: 0.680985]\n",
      "epoch:18 step:17460 [D loss: 0.550645, acc.: 69.53%] [G loss: 0.643481]\n",
      "epoch:18 step:17461 [D loss: 0.517748, acc.: 72.66%] [G loss: 0.642468]\n",
      "epoch:18 step:17462 [D loss: 0.545025, acc.: 67.19%] [G loss: 0.701150]\n",
      "epoch:18 step:17463 [D loss: 0.488506, acc.: 77.34%] [G loss: 0.663034]\n",
      "epoch:18 step:17464 [D loss: 0.508512, acc.: 71.88%] [G loss: 0.741957]\n",
      "epoch:18 step:17465 [D loss: 0.574941, acc.: 68.75%] [G loss: 0.707008]\n",
      "epoch:18 step:17466 [D loss: 0.628497, acc.: 67.97%] [G loss: 0.676723]\n",
      "epoch:18 step:17467 [D loss: 0.496821, acc.: 78.12%] [G loss: 0.593207]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:18 step:17468 [D loss: 0.453578, acc.: 78.12%] [G loss: 0.583340]\n",
      "epoch:18 step:17469 [D loss: 0.467154, acc.: 78.12%] [G loss: 0.734010]\n",
      "epoch:18 step:17470 [D loss: 0.519139, acc.: 73.44%] [G loss: 0.859165]\n",
      "epoch:18 step:17471 [D loss: 0.442304, acc.: 77.34%] [G loss: 0.841313]\n",
      "epoch:18 step:17472 [D loss: 0.629669, acc.: 62.50%] [G loss: 0.675877]\n",
      "epoch:18 step:17473 [D loss: 0.511008, acc.: 72.66%] [G loss: 0.740392]\n",
      "epoch:18 step:17474 [D loss: 0.512443, acc.: 71.09%] [G loss: 0.616545]\n",
      "epoch:18 step:17475 [D loss: 0.554200, acc.: 65.62%] [G loss: 0.546759]\n",
      "epoch:18 step:17476 [D loss: 0.623819, acc.: 64.06%] [G loss: 0.477542]\n",
      "epoch:18 step:17477 [D loss: 0.510938, acc.: 72.66%] [G loss: 0.647629]\n",
      "epoch:18 step:17478 [D loss: 0.527791, acc.: 72.66%] [G loss: 0.560927]\n",
      "epoch:18 step:17479 [D loss: 0.539835, acc.: 73.44%] [G loss: 0.432035]\n",
      "epoch:18 step:17480 [D loss: 0.574619, acc.: 66.41%] [G loss: 0.558341]\n",
      "epoch:18 step:17481 [D loss: 0.595740, acc.: 65.62%] [G loss: 0.568910]\n",
      "epoch:18 step:17482 [D loss: 0.485375, acc.: 75.78%] [G loss: 0.579001]\n",
      "epoch:18 step:17483 [D loss: 0.515351, acc.: 77.34%] [G loss: 0.829267]\n",
      "epoch:18 step:17484 [D loss: 0.505014, acc.: 72.66%] [G loss: 0.627954]\n",
      "epoch:18 step:17485 [D loss: 0.535871, acc.: 67.19%] [G loss: 0.718598]\n",
      "epoch:18 step:17486 [D loss: 0.501997, acc.: 72.66%] [G loss: 0.911114]\n",
      "epoch:18 step:17487 [D loss: 0.516595, acc.: 72.66%] [G loss: 0.778014]\n",
      "epoch:18 step:17488 [D loss: 0.569622, acc.: 67.97%] [G loss: 0.688796]\n",
      "epoch:18 step:17489 [D loss: 0.453012, acc.: 77.34%] [G loss: 0.650778]\n",
      "epoch:18 step:17490 [D loss: 0.460217, acc.: 77.34%] [G loss: 0.922200]\n",
      "epoch:18 step:17491 [D loss: 0.575284, acc.: 68.75%] [G loss: 0.694559]\n",
      "epoch:18 step:17492 [D loss: 0.540722, acc.: 71.09%] [G loss: 0.700379]\n",
      "epoch:18 step:17493 [D loss: 0.565437, acc.: 67.19%] [G loss: 0.793079]\n",
      "epoch:18 step:17494 [D loss: 0.557458, acc.: 71.88%] [G loss: 0.673495]\n",
      "epoch:18 step:17495 [D loss: 0.531372, acc.: 66.41%] [G loss: 0.594352]\n",
      "epoch:18 step:17496 [D loss: 0.510133, acc.: 78.12%] [G loss: 0.596453]\n",
      "epoch:18 step:17497 [D loss: 0.389453, acc.: 85.94%] [G loss: 0.832782]\n",
      "epoch:18 step:17498 [D loss: 0.509450, acc.: 75.00%] [G loss: 0.735150]\n",
      "epoch:18 step:17499 [D loss: 0.590155, acc.: 66.41%] [G loss: 0.840393]\n",
      "epoch:18 step:17500 [D loss: 0.486664, acc.: 75.00%] [G loss: 0.919905]\n",
      "epoch:18 step:17501 [D loss: 0.504521, acc.: 75.00%] [G loss: 0.976885]\n",
      "epoch:18 step:17502 [D loss: 0.611605, acc.: 62.50%] [G loss: 0.614642]\n",
      "epoch:18 step:17503 [D loss: 0.530577, acc.: 70.31%] [G loss: 0.706041]\n",
      "epoch:18 step:17504 [D loss: 0.459329, acc.: 76.56%] [G loss: 0.734588]\n",
      "epoch:18 step:17505 [D loss: 0.510933, acc.: 75.00%] [G loss: 0.615094]\n",
      "epoch:18 step:17506 [D loss: 0.570492, acc.: 67.97%] [G loss: 0.766398]\n",
      "epoch:18 step:17507 [D loss: 0.511343, acc.: 73.44%] [G loss: 0.798999]\n",
      "epoch:18 step:17508 [D loss: 0.556427, acc.: 75.00%] [G loss: 0.932896]\n",
      "epoch:18 step:17509 [D loss: 0.483866, acc.: 76.56%] [G loss: 0.813834]\n",
      "epoch:18 step:17510 [D loss: 0.524667, acc.: 69.53%] [G loss: 0.600329]\n",
      "epoch:18 step:17511 [D loss: 0.508514, acc.: 72.66%] [G loss: 0.606569]\n",
      "epoch:18 step:17512 [D loss: 0.508774, acc.: 75.78%] [G loss: 0.672253]\n",
      "epoch:18 step:17513 [D loss: 0.422466, acc.: 82.81%] [G loss: 0.678697]\n",
      "epoch:18 step:17514 [D loss: 0.393453, acc.: 81.25%] [G loss: 0.985783]\n",
      "epoch:18 step:17515 [D loss: 0.476278, acc.: 79.69%] [G loss: 0.951882]\n",
      "epoch:18 step:17516 [D loss: 0.522590, acc.: 72.66%] [G loss: 0.948189]\n",
      "epoch:18 step:17517 [D loss: 0.487252, acc.: 74.22%] [G loss: 0.865687]\n",
      "epoch:18 step:17518 [D loss: 0.586996, acc.: 64.84%] [G loss: 0.586523]\n",
      "epoch:18 step:17519 [D loss: 0.514410, acc.: 75.78%] [G loss: 0.726615]\n",
      "epoch:18 step:17520 [D loss: 0.452079, acc.: 77.34%] [G loss: 0.893339]\n",
      "epoch:18 step:17521 [D loss: 0.589352, acc.: 74.22%] [G loss: 0.673422]\n",
      "epoch:18 step:17522 [D loss: 0.582566, acc.: 66.41%] [G loss: 0.601073]\n",
      "epoch:18 step:17523 [D loss: 0.512792, acc.: 72.66%] [G loss: 0.756246]\n",
      "epoch:18 step:17524 [D loss: 0.599253, acc.: 64.84%] [G loss: 0.557551]\n",
      "epoch:18 step:17525 [D loss: 0.521378, acc.: 71.09%] [G loss: 0.586547]\n",
      "epoch:18 step:17526 [D loss: 0.514160, acc.: 71.09%] [G loss: 0.692026]\n",
      "epoch:18 step:17527 [D loss: 0.481925, acc.: 75.78%] [G loss: 0.783810]\n",
      "epoch:18 step:17528 [D loss: 0.492531, acc.: 71.09%] [G loss: 0.765211]\n",
      "epoch:18 step:17529 [D loss: 0.528491, acc.: 68.75%] [G loss: 0.621887]\n",
      "epoch:18 step:17530 [D loss: 0.507134, acc.: 69.53%] [G loss: 0.669968]\n",
      "epoch:18 step:17531 [D loss: 0.567267, acc.: 69.53%] [G loss: 0.701178]\n",
      "epoch:18 step:17532 [D loss: 0.502707, acc.: 74.22%] [G loss: 0.627077]\n",
      "epoch:18 step:17533 [D loss: 0.529292, acc.: 71.09%] [G loss: 0.631231]\n",
      "epoch:18 step:17534 [D loss: 0.532016, acc.: 74.22%] [G loss: 0.728303]\n",
      "epoch:18 step:17535 [D loss: 0.517922, acc.: 70.31%] [G loss: 0.841912]\n",
      "epoch:18 step:17536 [D loss: 0.556251, acc.: 67.97%] [G loss: 0.593018]\n",
      "epoch:18 step:17537 [D loss: 0.531210, acc.: 71.88%] [G loss: 0.595922]\n",
      "epoch:18 step:17538 [D loss: 0.506388, acc.: 77.34%] [G loss: 0.672782]\n",
      "epoch:18 step:17539 [D loss: 0.543097, acc.: 72.66%] [G loss: 0.661788]\n",
      "epoch:18 step:17540 [D loss: 0.544328, acc.: 69.53%] [G loss: 0.585579]\n",
      "epoch:18 step:17541 [D loss: 0.612965, acc.: 64.84%] [G loss: 0.611417]\n",
      "epoch:18 step:17542 [D loss: 0.579908, acc.: 64.84%] [G loss: 0.479460]\n",
      "epoch:18 step:17543 [D loss: 0.482015, acc.: 78.12%] [G loss: 0.603412]\n",
      "epoch:18 step:17544 [D loss: 0.512729, acc.: 71.88%] [G loss: 0.570819]\n",
      "epoch:18 step:17545 [D loss: 0.486490, acc.: 72.66%] [G loss: 0.593304]\n",
      "epoch:18 step:17546 [D loss: 0.506395, acc.: 74.22%] [G loss: 0.694849]\n",
      "epoch:18 step:17547 [D loss: 0.483169, acc.: 72.66%] [G loss: 0.671533]\n",
      "epoch:18 step:17548 [D loss: 0.526403, acc.: 73.44%] [G loss: 0.727816]\n",
      "epoch:18 step:17549 [D loss: 0.557798, acc.: 67.19%] [G loss: 0.570207]\n",
      "epoch:18 step:17550 [D loss: 0.602361, acc.: 61.72%] [G loss: 0.487505]\n",
      "epoch:18 step:17551 [D loss: 0.521771, acc.: 73.44%] [G loss: 0.527484]\n",
      "epoch:18 step:17552 [D loss: 0.528369, acc.: 70.31%] [G loss: 0.654286]\n",
      "epoch:18 step:17553 [D loss: 0.507717, acc.: 77.34%] [G loss: 0.584416]\n",
      "epoch:18 step:17554 [D loss: 0.504667, acc.: 75.78%] [G loss: 0.576394]\n",
      "epoch:18 step:17555 [D loss: 0.540709, acc.: 71.09%] [G loss: 0.598672]\n",
      "epoch:18 step:17556 [D loss: 0.527904, acc.: 71.88%] [G loss: 0.769452]\n",
      "epoch:18 step:17557 [D loss: 0.444382, acc.: 82.03%] [G loss: 0.878532]\n",
      "epoch:18 step:17558 [D loss: 0.585980, acc.: 70.31%] [G loss: 0.576685]\n",
      "epoch:18 step:17559 [D loss: 0.474292, acc.: 74.22%] [G loss: 0.754984]\n",
      "epoch:18 step:17560 [D loss: 0.502142, acc.: 75.78%] [G loss: 0.619652]\n",
      "epoch:18 step:17561 [D loss: 0.542301, acc.: 75.00%] [G loss: 0.806285]\n",
      "epoch:18 step:17562 [D loss: 0.621410, acc.: 63.28%] [G loss: 0.623735]\n",
      "epoch:18 step:17563 [D loss: 0.581896, acc.: 67.97%] [G loss: 0.621117]\n",
      "epoch:18 step:17564 [D loss: 0.598666, acc.: 63.28%] [G loss: 0.573417]\n",
      "epoch:18 step:17565 [D loss: 0.452045, acc.: 76.56%] [G loss: 0.631415]\n",
      "epoch:18 step:17566 [D loss: 0.550775, acc.: 67.19%] [G loss: 0.747433]\n",
      "epoch:18 step:17567 [D loss: 0.467125, acc.: 81.25%] [G loss: 0.740576]\n",
      "epoch:18 step:17568 [D loss: 0.573637, acc.: 66.41%] [G loss: 0.608470]\n",
      "epoch:18 step:17569 [D loss: 0.573527, acc.: 68.75%] [G loss: 0.564148]\n",
      "epoch:18 step:17570 [D loss: 0.600188, acc.: 64.84%] [G loss: 0.640295]\n",
      "epoch:18 step:17571 [D loss: 0.582332, acc.: 67.97%] [G loss: 0.590330]\n",
      "epoch:18 step:17572 [D loss: 0.496331, acc.: 73.44%] [G loss: 0.575025]\n",
      "epoch:18 step:17573 [D loss: 0.519435, acc.: 71.88%] [G loss: 0.807299]\n",
      "epoch:18 step:17574 [D loss: 0.499660, acc.: 74.22%] [G loss: 0.629519]\n",
      "epoch:18 step:17575 [D loss: 0.581662, acc.: 68.75%] [G loss: 0.650091]\n",
      "epoch:18 step:17576 [D loss: 0.531799, acc.: 75.78%] [G loss: 0.561695]\n",
      "epoch:18 step:17577 [D loss: 0.596843, acc.: 68.75%] [G loss: 0.709830]\n",
      "epoch:18 step:17578 [D loss: 0.507976, acc.: 71.88%] [G loss: 0.730669]\n",
      "epoch:18 step:17579 [D loss: 0.568997, acc.: 67.19%] [G loss: 0.686856]\n",
      "epoch:18 step:17580 [D loss: 0.564024, acc.: 67.97%] [G loss: 0.616040]\n",
      "epoch:18 step:17581 [D loss: 0.518363, acc.: 72.66%] [G loss: 0.754924]\n",
      "epoch:18 step:17582 [D loss: 0.605302, acc.: 63.28%] [G loss: 0.694929]\n",
      "epoch:18 step:17583 [D loss: 0.569397, acc.: 65.62%] [G loss: 0.576308]\n",
      "epoch:18 step:17584 [D loss: 0.547019, acc.: 69.53%] [G loss: 0.606394]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:18 step:17585 [D loss: 0.486624, acc.: 75.78%] [G loss: 0.683485]\n",
      "epoch:18 step:17586 [D loss: 0.561695, acc.: 69.53%] [G loss: 0.633403]\n",
      "epoch:18 step:17587 [D loss: 0.514984, acc.: 75.00%] [G loss: 0.847038]\n",
      "epoch:18 step:17588 [D loss: 0.534320, acc.: 74.22%] [G loss: 0.590617]\n",
      "epoch:18 step:17589 [D loss: 0.515359, acc.: 76.56%] [G loss: 0.472606]\n",
      "epoch:18 step:17590 [D loss: 0.484891, acc.: 77.34%] [G loss: 0.676935]\n",
      "epoch:18 step:17591 [D loss: 0.486299, acc.: 77.34%] [G loss: 0.682990]\n",
      "epoch:18 step:17592 [D loss: 0.499398, acc.: 77.34%] [G loss: 0.823084]\n",
      "epoch:18 step:17593 [D loss: 0.523434, acc.: 70.31%] [G loss: 0.832535]\n",
      "epoch:18 step:17594 [D loss: 0.554677, acc.: 67.19%] [G loss: 0.698593]\n",
      "epoch:18 step:17595 [D loss: 0.553562, acc.: 69.53%] [G loss: 0.540846]\n",
      "epoch:18 step:17596 [D loss: 0.513775, acc.: 75.00%] [G loss: 0.442740]\n",
      "epoch:18 step:17597 [D loss: 0.573302, acc.: 64.84%] [G loss: 0.551717]\n",
      "epoch:18 step:17598 [D loss: 0.534854, acc.: 71.88%] [G loss: 0.564613]\n",
      "epoch:18 step:17599 [D loss: 0.546901, acc.: 70.31%] [G loss: 0.659221]\n",
      "epoch:18 step:17600 [D loss: 0.539918, acc.: 70.31%] [G loss: 0.606178]\n",
      "epoch:18 step:17601 [D loss: 0.616581, acc.: 67.97%] [G loss: 0.588083]\n",
      "epoch:18 step:17602 [D loss: 0.483549, acc.: 74.22%] [G loss: 0.678011]\n",
      "epoch:18 step:17603 [D loss: 0.565295, acc.: 69.53%] [G loss: 0.655689]\n",
      "epoch:18 step:17604 [D loss: 0.571640, acc.: 67.97%] [G loss: 0.669621]\n",
      "epoch:18 step:17605 [D loss: 0.629965, acc.: 67.19%] [G loss: 0.587915]\n",
      "epoch:18 step:17606 [D loss: 0.583448, acc.: 66.41%] [G loss: 0.521534]\n",
      "epoch:18 step:17607 [D loss: 0.590001, acc.: 67.19%] [G loss: 0.571483]\n",
      "epoch:18 step:17608 [D loss: 0.551022, acc.: 72.66%] [G loss: 0.639428]\n",
      "epoch:18 step:17609 [D loss: 0.480826, acc.: 71.09%] [G loss: 0.694102]\n",
      "epoch:18 step:17610 [D loss: 0.548436, acc.: 72.66%] [G loss: 0.749085]\n",
      "epoch:18 step:17611 [D loss: 0.605597, acc.: 65.62%] [G loss: 0.697913]\n",
      "epoch:18 step:17612 [D loss: 0.445704, acc.: 78.91%] [G loss: 0.815797]\n",
      "epoch:18 step:17613 [D loss: 0.443552, acc.: 75.78%] [G loss: 0.881500]\n",
      "epoch:18 step:17614 [D loss: 0.549158, acc.: 72.66%] [G loss: 0.696057]\n",
      "epoch:18 step:17615 [D loss: 0.519569, acc.: 71.88%] [G loss: 0.637983]\n",
      "epoch:18 step:17616 [D loss: 0.459728, acc.: 74.22%] [G loss: 0.728484]\n",
      "epoch:18 step:17617 [D loss: 0.544217, acc.: 71.09%] [G loss: 0.637294]\n",
      "epoch:18 step:17618 [D loss: 0.530006, acc.: 71.88%] [G loss: 0.731713]\n",
      "epoch:18 step:17619 [D loss: 0.495047, acc.: 78.91%] [G loss: 0.628509]\n",
      "epoch:18 step:17620 [D loss: 0.551579, acc.: 65.62%] [G loss: 0.647337]\n",
      "epoch:18 step:17621 [D loss: 0.545682, acc.: 74.22%] [G loss: 0.571406]\n",
      "epoch:18 step:17622 [D loss: 0.508610, acc.: 75.00%] [G loss: 0.648654]\n",
      "epoch:18 step:17623 [D loss: 0.550285, acc.: 67.19%] [G loss: 0.738051]\n",
      "epoch:18 step:17624 [D loss: 0.545360, acc.: 74.22%] [G loss: 0.680429]\n",
      "epoch:18 step:17625 [D loss: 0.579075, acc.: 68.75%] [G loss: 0.519952]\n",
      "epoch:18 step:17626 [D loss: 0.575010, acc.: 67.19%] [G loss: 0.569192]\n",
      "epoch:18 step:17627 [D loss: 0.538135, acc.: 68.75%] [G loss: 0.607002]\n",
      "epoch:18 step:17628 [D loss: 0.563549, acc.: 67.19%] [G loss: 0.615519]\n",
      "epoch:18 step:17629 [D loss: 0.542390, acc.: 67.19%] [G loss: 0.571495]\n",
      "epoch:18 step:17630 [D loss: 0.558816, acc.: 67.97%] [G loss: 0.686667]\n",
      "epoch:18 step:17631 [D loss: 0.537109, acc.: 65.62%] [G loss: 0.615021]\n",
      "epoch:18 step:17632 [D loss: 0.630168, acc.: 68.75%] [G loss: 0.515560]\n",
      "epoch:18 step:17633 [D loss: 0.493631, acc.: 76.56%] [G loss: 0.733970]\n",
      "epoch:18 step:17634 [D loss: 0.580537, acc.: 70.31%] [G loss: 0.652063]\n",
      "epoch:18 step:17635 [D loss: 0.523125, acc.: 70.31%] [G loss: 0.754742]\n",
      "epoch:18 step:17636 [D loss: 0.531637, acc.: 68.75%] [G loss: 0.779946]\n",
      "epoch:18 step:17637 [D loss: 0.503976, acc.: 75.78%] [G loss: 0.759267]\n",
      "epoch:18 step:17638 [D loss: 0.518244, acc.: 74.22%] [G loss: 0.864404]\n",
      "epoch:18 step:17639 [D loss: 0.569705, acc.: 64.06%] [G loss: 0.702610]\n",
      "epoch:18 step:17640 [D loss: 0.592677, acc.: 64.84%] [G loss: 0.682794]\n",
      "epoch:18 step:17641 [D loss: 0.529341, acc.: 70.31%] [G loss: 0.621367]\n",
      "epoch:18 step:17642 [D loss: 0.561609, acc.: 66.41%] [G loss: 0.727083]\n",
      "epoch:18 step:17643 [D loss: 0.556339, acc.: 71.88%] [G loss: 0.670659]\n",
      "epoch:18 step:17644 [D loss: 0.580279, acc.: 70.31%] [G loss: 0.702155]\n",
      "epoch:18 step:17645 [D loss: 0.526400, acc.: 74.22%] [G loss: 0.682475]\n",
      "epoch:18 step:17646 [D loss: 0.541628, acc.: 72.66%] [G loss: 0.694623]\n",
      "epoch:18 step:17647 [D loss: 0.484694, acc.: 78.91%] [G loss: 0.808438]\n",
      "epoch:18 step:17648 [D loss: 0.486888, acc.: 74.22%] [G loss: 1.070625]\n",
      "epoch:18 step:17649 [D loss: 0.573378, acc.: 64.84%] [G loss: 0.829638]\n",
      "epoch:18 step:17650 [D loss: 0.598866, acc.: 64.06%] [G loss: 0.740780]\n",
      "epoch:18 step:17651 [D loss: 0.518194, acc.: 72.66%] [G loss: 0.647999]\n",
      "epoch:18 step:17652 [D loss: 0.480897, acc.: 75.78%] [G loss: 0.730173]\n",
      "epoch:18 step:17653 [D loss: 0.626527, acc.: 64.06%] [G loss: 0.546403]\n",
      "epoch:18 step:17654 [D loss: 0.632307, acc.: 61.72%] [G loss: 0.568449]\n",
      "epoch:18 step:17655 [D loss: 0.481624, acc.: 72.66%] [G loss: 0.648138]\n",
      "epoch:18 step:17656 [D loss: 0.496022, acc.: 74.22%] [G loss: 0.643766]\n",
      "epoch:18 step:17657 [D loss: 0.521051, acc.: 75.78%] [G loss: 0.704913]\n",
      "epoch:18 step:17658 [D loss: 0.473971, acc.: 77.34%] [G loss: 0.732284]\n",
      "epoch:18 step:17659 [D loss: 0.569957, acc.: 70.31%] [G loss: 0.492334]\n",
      "epoch:18 step:17660 [D loss: 0.541625, acc.: 68.75%] [G loss: 0.597273]\n",
      "epoch:18 step:17661 [D loss: 0.548826, acc.: 66.41%] [G loss: 0.739853]\n",
      "epoch:18 step:17662 [D loss: 0.462731, acc.: 77.34%] [G loss: 0.890066]\n",
      "epoch:18 step:17663 [D loss: 0.495763, acc.: 76.56%] [G loss: 0.781517]\n",
      "epoch:18 step:17664 [D loss: 0.562327, acc.: 67.19%] [G loss: 0.768369]\n",
      "epoch:18 step:17665 [D loss: 0.613375, acc.: 60.16%] [G loss: 0.579972]\n",
      "epoch:18 step:17666 [D loss: 0.587585, acc.: 63.28%] [G loss: 0.734350]\n",
      "epoch:18 step:17667 [D loss: 0.477582, acc.: 71.09%] [G loss: 0.813526]\n",
      "epoch:18 step:17668 [D loss: 0.506377, acc.: 71.88%] [G loss: 0.760106]\n",
      "epoch:18 step:17669 [D loss: 0.504234, acc.: 77.34%] [G loss: 0.675523]\n",
      "epoch:18 step:17670 [D loss: 0.535458, acc.: 71.88%] [G loss: 0.719545]\n",
      "epoch:18 step:17671 [D loss: 0.526329, acc.: 72.66%] [G loss: 0.540748]\n",
      "epoch:18 step:17672 [D loss: 0.542874, acc.: 72.66%] [G loss: 0.397010]\n",
      "epoch:18 step:17673 [D loss: 0.553596, acc.: 68.75%] [G loss: 0.598598]\n",
      "epoch:18 step:17674 [D loss: 0.576262, acc.: 70.31%] [G loss: 0.475306]\n",
      "epoch:18 step:17675 [D loss: 0.530455, acc.: 72.66%] [G loss: 0.551262]\n",
      "epoch:18 step:17676 [D loss: 0.473604, acc.: 72.66%] [G loss: 0.718794]\n",
      "epoch:18 step:17677 [D loss: 0.532757, acc.: 72.66%] [G loss: 0.743621]\n",
      "epoch:18 step:17678 [D loss: 0.596533, acc.: 68.75%] [G loss: 0.657733]\n",
      "epoch:18 step:17679 [D loss: 0.564272, acc.: 67.19%] [G loss: 0.616712]\n",
      "epoch:18 step:17680 [D loss: 0.501338, acc.: 73.44%] [G loss: 0.629601]\n",
      "epoch:18 step:17681 [D loss: 0.471105, acc.: 81.25%] [G loss: 0.769021]\n",
      "epoch:18 step:17682 [D loss: 0.576421, acc.: 70.31%] [G loss: 0.691393]\n",
      "epoch:18 step:17683 [D loss: 0.587580, acc.: 71.88%] [G loss: 0.751146]\n",
      "epoch:18 step:17684 [D loss: 0.568523, acc.: 66.41%] [G loss: 0.783388]\n",
      "epoch:18 step:17685 [D loss: 0.509475, acc.: 70.31%] [G loss: 0.584861]\n",
      "epoch:18 step:17686 [D loss: 0.613869, acc.: 67.19%] [G loss: 0.541760]\n",
      "epoch:18 step:17687 [D loss: 0.506196, acc.: 73.44%] [G loss: 0.593903]\n",
      "epoch:18 step:17688 [D loss: 0.539282, acc.: 69.53%] [G loss: 0.520324]\n",
      "epoch:18 step:17689 [D loss: 0.432509, acc.: 77.34%] [G loss: 0.621652]\n",
      "epoch:18 step:17690 [D loss: 0.515924, acc.: 76.56%] [G loss: 0.760986]\n",
      "epoch:18 step:17691 [D loss: 0.530688, acc.: 70.31%] [G loss: 0.667349]\n",
      "epoch:18 step:17692 [D loss: 0.536923, acc.: 72.66%] [G loss: 0.583276]\n",
      "epoch:18 step:17693 [D loss: 0.519969, acc.: 71.88%] [G loss: 0.665776]\n",
      "epoch:18 step:17694 [D loss: 0.619545, acc.: 68.75%] [G loss: 0.535421]\n",
      "epoch:18 step:17695 [D loss: 0.583594, acc.: 60.16%] [G loss: 0.753492]\n",
      "epoch:18 step:17696 [D loss: 0.538512, acc.: 67.19%] [G loss: 0.701167]\n",
      "epoch:18 step:17697 [D loss: 0.539176, acc.: 72.66%] [G loss: 0.590449]\n",
      "epoch:18 step:17698 [D loss: 0.539185, acc.: 71.88%] [G loss: 0.549704]\n",
      "epoch:18 step:17699 [D loss: 0.509181, acc.: 68.75%] [G loss: 0.667025]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:18 step:17700 [D loss: 0.505574, acc.: 74.22%] [G loss: 0.700999]\n",
      "epoch:18 step:17701 [D loss: 0.509907, acc.: 76.56%] [G loss: 0.672956]\n",
      "epoch:18 step:17702 [D loss: 0.504647, acc.: 74.22%] [G loss: 0.636812]\n",
      "epoch:18 step:17703 [D loss: 0.504747, acc.: 77.34%] [G loss: 0.635976]\n",
      "epoch:18 step:17704 [D loss: 0.536640, acc.: 72.66%] [G loss: 0.491758]\n",
      "epoch:18 step:17705 [D loss: 0.613623, acc.: 63.28%] [G loss: 0.521501]\n",
      "epoch:18 step:17706 [D loss: 0.596491, acc.: 67.19%] [G loss: 0.568867]\n",
      "epoch:18 step:17707 [D loss: 0.531420, acc.: 72.66%] [G loss: 0.589414]\n",
      "epoch:18 step:17708 [D loss: 0.470631, acc.: 81.25%] [G loss: 0.677119]\n",
      "epoch:18 step:17709 [D loss: 0.509868, acc.: 73.44%] [G loss: 0.632567]\n",
      "epoch:18 step:17710 [D loss: 0.534785, acc.: 69.53%] [G loss: 0.797641]\n",
      "epoch:18 step:17711 [D loss: 0.612064, acc.: 65.62%] [G loss: 0.712381]\n",
      "epoch:18 step:17712 [D loss: 0.550936, acc.: 71.88%] [G loss: 0.683558]\n",
      "epoch:18 step:17713 [D loss: 0.624820, acc.: 61.72%] [G loss: 0.483295]\n",
      "epoch:18 step:17714 [D loss: 0.603252, acc.: 58.59%] [G loss: 0.580458]\n",
      "epoch:18 step:17715 [D loss: 0.534837, acc.: 70.31%] [G loss: 0.570380]\n",
      "epoch:18 step:17716 [D loss: 0.522588, acc.: 71.88%] [G loss: 0.642625]\n",
      "epoch:18 step:17717 [D loss: 0.533015, acc.: 73.44%] [G loss: 0.615610]\n",
      "epoch:18 step:17718 [D loss: 0.483336, acc.: 76.56%] [G loss: 0.658137]\n",
      "epoch:18 step:17719 [D loss: 0.501222, acc.: 74.22%] [G loss: 0.775326]\n",
      "epoch:18 step:17720 [D loss: 0.468978, acc.: 71.09%] [G loss: 0.695679]\n",
      "epoch:18 step:17721 [D loss: 0.533871, acc.: 70.31%] [G loss: 0.750265]\n",
      "epoch:18 step:17722 [D loss: 0.534561, acc.: 73.44%] [G loss: 0.597376]\n",
      "epoch:18 step:17723 [D loss: 0.451392, acc.: 73.44%] [G loss: 0.740140]\n",
      "epoch:18 step:17724 [D loss: 0.605452, acc.: 64.84%] [G loss: 0.576239]\n",
      "epoch:18 step:17725 [D loss: 0.512788, acc.: 74.22%] [G loss: 0.693607]\n",
      "epoch:18 step:17726 [D loss: 0.383960, acc.: 87.50%] [G loss: 0.841090]\n",
      "epoch:18 step:17727 [D loss: 0.620706, acc.: 61.72%] [G loss: 0.582017]\n",
      "epoch:18 step:17728 [D loss: 0.598754, acc.: 67.19%] [G loss: 0.525128]\n",
      "epoch:18 step:17729 [D loss: 0.584446, acc.: 66.41%] [G loss: 0.556112]\n",
      "epoch:18 step:17730 [D loss: 0.511669, acc.: 74.22%] [G loss: 0.627433]\n",
      "epoch:18 step:17731 [D loss: 0.563423, acc.: 67.97%] [G loss: 0.531737]\n",
      "epoch:18 step:17732 [D loss: 0.472058, acc.: 77.34%] [G loss: 0.612186]\n",
      "epoch:18 step:17733 [D loss: 0.656563, acc.: 60.94%] [G loss: 0.395563]\n",
      "epoch:18 step:17734 [D loss: 0.552934, acc.: 69.53%] [G loss: 0.562511]\n",
      "epoch:18 step:17735 [D loss: 0.556823, acc.: 64.06%] [G loss: 0.610661]\n",
      "epoch:18 step:17736 [D loss: 0.441405, acc.: 79.69%] [G loss: 0.699489]\n",
      "epoch:18 step:17737 [D loss: 0.474530, acc.: 75.78%] [G loss: 0.765150]\n",
      "epoch:18 step:17738 [D loss: 0.506691, acc.: 69.53%] [G loss: 0.770019]\n",
      "epoch:18 step:17739 [D loss: 0.607120, acc.: 67.19%] [G loss: 0.564860]\n",
      "epoch:18 step:17740 [D loss: 0.543287, acc.: 69.53%] [G loss: 0.775673]\n",
      "epoch:18 step:17741 [D loss: 0.487898, acc.: 72.66%] [G loss: 0.750327]\n",
      "epoch:18 step:17742 [D loss: 0.503889, acc.: 71.09%] [G loss: 0.665853]\n",
      "epoch:18 step:17743 [D loss: 0.621198, acc.: 64.06%] [G loss: 0.582649]\n",
      "epoch:18 step:17744 [D loss: 0.534155, acc.: 74.22%] [G loss: 0.494007]\n",
      "epoch:18 step:17745 [D loss: 0.587261, acc.: 70.31%] [G loss: 0.494007]\n",
      "epoch:18 step:17746 [D loss: 0.622049, acc.: 62.50%] [G loss: 0.553103]\n",
      "epoch:18 step:17747 [D loss: 0.564032, acc.: 64.84%] [G loss: 0.564447]\n",
      "epoch:18 step:17748 [D loss: 0.599471, acc.: 64.06%] [G loss: 0.559882]\n",
      "epoch:18 step:17749 [D loss: 0.607559, acc.: 62.50%] [G loss: 0.529902]\n",
      "epoch:18 step:17750 [D loss: 0.490322, acc.: 78.91%] [G loss: 0.619210]\n",
      "epoch:18 step:17751 [D loss: 0.511296, acc.: 71.09%] [G loss: 1.037862]\n",
      "epoch:18 step:17752 [D loss: 0.515157, acc.: 71.88%] [G loss: 0.849621]\n",
      "epoch:18 step:17753 [D loss: 0.570165, acc.: 67.97%] [G loss: 0.804366]\n",
      "epoch:18 step:17754 [D loss: 0.533171, acc.: 71.09%] [G loss: 0.728100]\n",
      "epoch:18 step:17755 [D loss: 0.597343, acc.: 63.28%] [G loss: 0.551298]\n",
      "epoch:18 step:17756 [D loss: 0.467582, acc.: 80.47%] [G loss: 0.874850]\n",
      "epoch:18 step:17757 [D loss: 0.553572, acc.: 70.31%] [G loss: 0.633519]\n",
      "epoch:18 step:17758 [D loss: 0.603988, acc.: 64.06%] [G loss: 0.509540]\n",
      "epoch:18 step:17759 [D loss: 0.553621, acc.: 70.31%] [G loss: 0.573953]\n",
      "epoch:18 step:17760 [D loss: 0.467035, acc.: 75.00%] [G loss: 0.602951]\n",
      "epoch:18 step:17761 [D loss: 0.567246, acc.: 67.19%] [G loss: 0.752139]\n",
      "epoch:18 step:17762 [D loss: 0.443742, acc.: 76.56%] [G loss: 0.887070]\n",
      "epoch:18 step:17763 [D loss: 0.483880, acc.: 76.56%] [G loss: 0.661315]\n",
      "epoch:18 step:17764 [D loss: 0.451195, acc.: 78.91%] [G loss: 0.814350]\n",
      "epoch:18 step:17765 [D loss: 0.444918, acc.: 79.69%] [G loss: 0.889387]\n",
      "epoch:18 step:17766 [D loss: 0.490006, acc.: 76.56%] [G loss: 0.824154]\n",
      "epoch:18 step:17767 [D loss: 0.488352, acc.: 75.78%] [G loss: 0.787458]\n",
      "epoch:18 step:17768 [D loss: 0.626651, acc.: 69.53%] [G loss: 0.808030]\n",
      "epoch:18 step:17769 [D loss: 0.521575, acc.: 73.44%] [G loss: 0.683622]\n",
      "epoch:18 step:17770 [D loss: 0.502760, acc.: 75.78%] [G loss: 0.695095]\n",
      "epoch:18 step:17771 [D loss: 0.575623, acc.: 67.97%] [G loss: 0.621747]\n",
      "epoch:18 step:17772 [D loss: 0.534703, acc.: 75.00%] [G loss: 0.763062]\n",
      "epoch:18 step:17773 [D loss: 0.524786, acc.: 71.88%] [G loss: 0.737432]\n",
      "epoch:18 step:17774 [D loss: 0.514138, acc.: 75.00%] [G loss: 0.736925]\n",
      "epoch:18 step:17775 [D loss: 0.471035, acc.: 77.34%] [G loss: 0.592888]\n",
      "epoch:18 step:17776 [D loss: 0.563871, acc.: 72.66%] [G loss: 0.648598]\n",
      "epoch:18 step:17777 [D loss: 0.454068, acc.: 78.91%] [G loss: 0.592119]\n",
      "epoch:18 step:17778 [D loss: 0.514604, acc.: 74.22%] [G loss: 0.823766]\n",
      "epoch:18 step:17779 [D loss: 0.528888, acc.: 72.66%] [G loss: 0.773913]\n",
      "epoch:18 step:17780 [D loss: 0.507750, acc.: 74.22%] [G loss: 0.921594]\n",
      "epoch:18 step:17781 [D loss: 0.693510, acc.: 59.38%] [G loss: 0.682276]\n",
      "epoch:18 step:17782 [D loss: 0.463958, acc.: 76.56%] [G loss: 0.645811]\n",
      "epoch:18 step:17783 [D loss: 0.537991, acc.: 71.09%] [G loss: 0.633906]\n",
      "epoch:18 step:17784 [D loss: 0.490809, acc.: 74.22%] [G loss: 0.724041]\n",
      "epoch:18 step:17785 [D loss: 0.461093, acc.: 82.03%] [G loss: 0.892551]\n",
      "epoch:18 step:17786 [D loss: 0.632394, acc.: 68.75%] [G loss: 0.743230]\n",
      "epoch:18 step:17787 [D loss: 0.477127, acc.: 75.00%] [G loss: 0.748316]\n",
      "epoch:18 step:17788 [D loss: 0.481370, acc.: 79.69%] [G loss: 0.612146]\n",
      "epoch:18 step:17789 [D loss: 0.442825, acc.: 75.78%] [G loss: 0.772776]\n",
      "epoch:18 step:17790 [D loss: 0.467507, acc.: 75.00%] [G loss: 0.974001]\n",
      "epoch:18 step:17791 [D loss: 0.417750, acc.: 82.03%] [G loss: 1.175551]\n",
      "epoch:18 step:17792 [D loss: 0.430941, acc.: 77.34%] [G loss: 1.440033]\n",
      "epoch:18 step:17793 [D loss: 0.446979, acc.: 72.66%] [G loss: 1.232925]\n",
      "epoch:18 step:17794 [D loss: 0.737872, acc.: 67.97%] [G loss: 0.933626]\n",
      "epoch:18 step:17795 [D loss: 0.611038, acc.: 67.97%] [G loss: 0.997885]\n",
      "epoch:18 step:17796 [D loss: 0.395417, acc.: 76.56%] [G loss: 1.236202]\n",
      "epoch:18 step:17797 [D loss: 0.596226, acc.: 65.62%] [G loss: 0.901482]\n",
      "epoch:18 step:17798 [D loss: 0.687995, acc.: 62.50%] [G loss: 0.904374]\n",
      "epoch:18 step:17799 [D loss: 0.494956, acc.: 70.31%] [G loss: 0.958342]\n",
      "epoch:18 step:17800 [D loss: 0.520465, acc.: 71.88%] [G loss: 1.004637]\n",
      "epoch:18 step:17801 [D loss: 0.443382, acc.: 75.00%] [G loss: 1.154926]\n",
      "epoch:18 step:17802 [D loss: 0.356696, acc.: 85.94%] [G loss: 1.265777]\n",
      "epoch:18 step:17803 [D loss: 0.351655, acc.: 87.50%] [G loss: 1.276643]\n",
      "epoch:19 step:17804 [D loss: 0.625188, acc.: 67.97%] [G loss: 1.180074]\n",
      "epoch:19 step:17805 [D loss: 0.528191, acc.: 75.00%] [G loss: 1.073457]\n",
      "epoch:19 step:17806 [D loss: 0.555165, acc.: 71.09%] [G loss: 1.223850]\n",
      "epoch:19 step:17807 [D loss: 0.561475, acc.: 75.00%] [G loss: 0.807034]\n",
      "epoch:19 step:17808 [D loss: 0.538770, acc.: 69.53%] [G loss: 0.823380]\n",
      "epoch:19 step:17809 [D loss: 0.601224, acc.: 65.62%] [G loss: 0.798418]\n",
      "epoch:19 step:17810 [D loss: 0.514505, acc.: 76.56%] [G loss: 0.795324]\n",
      "epoch:19 step:17811 [D loss: 0.510410, acc.: 73.44%] [G loss: 0.638355]\n",
      "epoch:19 step:17812 [D loss: 0.490255, acc.: 74.22%] [G loss: 0.763793]\n",
      "epoch:19 step:17813 [D loss: 0.505167, acc.: 75.00%] [G loss: 0.719891]\n",
      "epoch:19 step:17814 [D loss: 0.449710, acc.: 79.69%] [G loss: 0.925090]\n",
      "epoch:19 step:17815 [D loss: 0.579887, acc.: 64.84%] [G loss: 0.692551]\n",
      "epoch:19 step:17816 [D loss: 0.537295, acc.: 70.31%] [G loss: 0.723117]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:19 step:17817 [D loss: 0.562004, acc.: 67.19%] [G loss: 0.651477]\n",
      "epoch:19 step:17818 [D loss: 0.457708, acc.: 78.12%] [G loss: 0.727221]\n",
      "epoch:19 step:17819 [D loss: 0.456344, acc.: 78.91%] [G loss: 0.878985]\n",
      "epoch:19 step:17820 [D loss: 0.558673, acc.: 72.66%] [G loss: 0.799350]\n",
      "epoch:19 step:17821 [D loss: 0.557996, acc.: 70.31%] [G loss: 0.750716]\n",
      "epoch:19 step:17822 [D loss: 0.551816, acc.: 72.66%] [G loss: 0.722915]\n",
      "epoch:19 step:17823 [D loss: 0.647728, acc.: 63.28%] [G loss: 0.634840]\n",
      "epoch:19 step:17824 [D loss: 0.579654, acc.: 64.84%] [G loss: 0.525113]\n",
      "epoch:19 step:17825 [D loss: 0.475542, acc.: 78.91%] [G loss: 0.826241]\n",
      "epoch:19 step:17826 [D loss: 0.518183, acc.: 75.00%] [G loss: 0.701485]\n",
      "epoch:19 step:17827 [D loss: 0.500869, acc.: 73.44%] [G loss: 0.733162]\n",
      "epoch:19 step:17828 [D loss: 0.451960, acc.: 82.03%] [G loss: 0.760831]\n",
      "epoch:19 step:17829 [D loss: 0.558124, acc.: 68.75%] [G loss: 0.618501]\n",
      "epoch:19 step:17830 [D loss: 0.448456, acc.: 78.91%] [G loss: 0.880555]\n",
      "epoch:19 step:17831 [D loss: 0.537864, acc.: 70.31%] [G loss: 0.748245]\n",
      "epoch:19 step:17832 [D loss: 0.473013, acc.: 75.78%] [G loss: 0.665452]\n",
      "epoch:19 step:17833 [D loss: 0.564739, acc.: 71.88%] [G loss: 0.643924]\n",
      "epoch:19 step:17834 [D loss: 0.658226, acc.: 63.28%] [G loss: 0.467714]\n",
      "epoch:19 step:17835 [D loss: 0.560564, acc.: 73.44%] [G loss: 0.680633]\n",
      "epoch:19 step:17836 [D loss: 0.497220, acc.: 71.88%] [G loss: 0.730160]\n",
      "epoch:19 step:17837 [D loss: 0.583195, acc.: 64.06%] [G loss: 0.472249]\n",
      "epoch:19 step:17838 [D loss: 0.557199, acc.: 71.88%] [G loss: 0.665240]\n",
      "epoch:19 step:17839 [D loss: 0.516090, acc.: 73.44%] [G loss: 0.584540]\n",
      "epoch:19 step:17840 [D loss: 0.483729, acc.: 76.56%] [G loss: 0.805255]\n",
      "epoch:19 step:17841 [D loss: 0.531822, acc.: 75.78%] [G loss: 0.634124]\n",
      "epoch:19 step:17842 [D loss: 0.547148, acc.: 72.66%] [G loss: 0.558801]\n",
      "epoch:19 step:17843 [D loss: 0.417230, acc.: 82.81%] [G loss: 0.761912]\n",
      "epoch:19 step:17844 [D loss: 0.511639, acc.: 73.44%] [G loss: 0.707571]\n",
      "epoch:19 step:17845 [D loss: 0.481842, acc.: 77.34%] [G loss: 0.711407]\n",
      "epoch:19 step:17846 [D loss: 0.558872, acc.: 68.75%] [G loss: 0.702008]\n",
      "epoch:19 step:17847 [D loss: 0.568303, acc.: 67.97%] [G loss: 1.071727]\n",
      "epoch:19 step:17848 [D loss: 0.474696, acc.: 82.03%] [G loss: 0.618131]\n",
      "epoch:19 step:17849 [D loss: 0.482400, acc.: 70.31%] [G loss: 0.835969]\n",
      "epoch:19 step:17850 [D loss: 0.550115, acc.: 70.31%] [G loss: 0.806915]\n",
      "epoch:19 step:17851 [D loss: 0.541176, acc.: 68.75%] [G loss: 0.658422]\n",
      "epoch:19 step:17852 [D loss: 0.474147, acc.: 78.12%] [G loss: 0.716605]\n",
      "epoch:19 step:17853 [D loss: 0.529498, acc.: 72.66%] [G loss: 0.715669]\n",
      "epoch:19 step:17854 [D loss: 0.623419, acc.: 60.16%] [G loss: 0.483886]\n",
      "epoch:19 step:17855 [D loss: 0.591864, acc.: 67.97%] [G loss: 0.696921]\n",
      "epoch:19 step:17856 [D loss: 0.529818, acc.: 70.31%] [G loss: 0.711587]\n",
      "epoch:19 step:17857 [D loss: 0.493421, acc.: 79.69%] [G loss: 0.872935]\n",
      "epoch:19 step:17858 [D loss: 0.555409, acc.: 68.75%] [G loss: 0.725262]\n",
      "epoch:19 step:17859 [D loss: 0.490493, acc.: 76.56%] [G loss: 0.729884]\n",
      "epoch:19 step:17860 [D loss: 0.504235, acc.: 73.44%] [G loss: 0.792592]\n",
      "epoch:19 step:17861 [D loss: 0.588166, acc.: 64.84%] [G loss: 0.767264]\n",
      "epoch:19 step:17862 [D loss: 0.522063, acc.: 71.88%] [G loss: 0.768064]\n",
      "epoch:19 step:17863 [D loss: 0.534298, acc.: 71.09%] [G loss: 0.761368]\n",
      "epoch:19 step:17864 [D loss: 0.529378, acc.: 69.53%] [G loss: 0.777429]\n",
      "epoch:19 step:17865 [D loss: 0.543392, acc.: 69.53%] [G loss: 0.632158]\n",
      "epoch:19 step:17866 [D loss: 0.534885, acc.: 70.31%] [G loss: 0.585146]\n",
      "epoch:19 step:17867 [D loss: 0.569961, acc.: 67.97%] [G loss: 0.548225]\n",
      "epoch:19 step:17868 [D loss: 0.514651, acc.: 71.88%] [G loss: 0.556043]\n",
      "epoch:19 step:17869 [D loss: 0.530186, acc.: 71.09%] [G loss: 0.635636]\n",
      "epoch:19 step:17870 [D loss: 0.527678, acc.: 75.78%] [G loss: 0.626897]\n",
      "epoch:19 step:17871 [D loss: 0.522420, acc.: 68.75%] [G loss: 0.629640]\n",
      "epoch:19 step:17872 [D loss: 0.532437, acc.: 70.31%] [G loss: 0.686278]\n",
      "epoch:19 step:17873 [D loss: 0.503828, acc.: 74.22%] [G loss: 0.773631]\n",
      "epoch:19 step:17874 [D loss: 0.552270, acc.: 69.53%] [G loss: 0.721664]\n",
      "epoch:19 step:17875 [D loss: 0.543447, acc.: 71.88%] [G loss: 0.666990]\n",
      "epoch:19 step:17876 [D loss: 0.579535, acc.: 67.97%] [G loss: 0.544422]\n",
      "epoch:19 step:17877 [D loss: 0.438054, acc.: 79.69%] [G loss: 0.711770]\n",
      "epoch:19 step:17878 [D loss: 0.479659, acc.: 76.56%] [G loss: 0.742613]\n",
      "epoch:19 step:17879 [D loss: 0.498877, acc.: 72.66%] [G loss: 0.850849]\n",
      "epoch:19 step:17880 [D loss: 0.477546, acc.: 75.00%] [G loss: 0.928656]\n",
      "epoch:19 step:17881 [D loss: 0.582157, acc.: 67.97%] [G loss: 0.895718]\n",
      "epoch:19 step:17882 [D loss: 0.604684, acc.: 67.19%] [G loss: 0.604052]\n",
      "epoch:19 step:17883 [D loss: 0.526450, acc.: 71.09%] [G loss: 0.708560]\n",
      "epoch:19 step:17884 [D loss: 0.519322, acc.: 71.88%] [G loss: 0.729424]\n",
      "epoch:19 step:17885 [D loss: 0.483957, acc.: 74.22%] [G loss: 0.746752]\n",
      "epoch:19 step:17886 [D loss: 0.455560, acc.: 78.91%] [G loss: 0.734774]\n",
      "epoch:19 step:17887 [D loss: 0.537544, acc.: 72.66%] [G loss: 0.688160]\n",
      "epoch:19 step:17888 [D loss: 0.590765, acc.: 65.62%] [G loss: 0.601355]\n",
      "epoch:19 step:17889 [D loss: 0.482786, acc.: 78.12%] [G loss: 0.650349]\n",
      "epoch:19 step:17890 [D loss: 0.541742, acc.: 68.75%] [G loss: 0.617725]\n",
      "epoch:19 step:17891 [D loss: 0.512500, acc.: 74.22%] [G loss: 0.750900]\n",
      "epoch:19 step:17892 [D loss: 0.474039, acc.: 75.00%] [G loss: 0.840015]\n",
      "epoch:19 step:17893 [D loss: 0.513358, acc.: 71.88%] [G loss: 0.684237]\n",
      "epoch:19 step:17894 [D loss: 0.574647, acc.: 67.97%] [G loss: 0.852679]\n",
      "epoch:19 step:17895 [D loss: 0.459082, acc.: 76.56%] [G loss: 0.850855]\n",
      "epoch:19 step:17896 [D loss: 0.484824, acc.: 75.00%] [G loss: 0.771558]\n",
      "epoch:19 step:17897 [D loss: 0.483472, acc.: 71.09%] [G loss: 0.723799]\n",
      "epoch:19 step:17898 [D loss: 0.548224, acc.: 70.31%] [G loss: 0.799491]\n",
      "epoch:19 step:17899 [D loss: 0.516327, acc.: 74.22%] [G loss: 0.833286]\n",
      "epoch:19 step:17900 [D loss: 0.525937, acc.: 73.44%] [G loss: 0.707914]\n",
      "epoch:19 step:17901 [D loss: 0.520702, acc.: 71.09%] [G loss: 0.840304]\n",
      "epoch:19 step:17902 [D loss: 0.515146, acc.: 73.44%] [G loss: 0.862287]\n",
      "epoch:19 step:17903 [D loss: 0.510542, acc.: 75.00%] [G loss: 0.756189]\n",
      "epoch:19 step:17904 [D loss: 0.491011, acc.: 70.31%] [G loss: 0.877049]\n",
      "epoch:19 step:17905 [D loss: 0.577535, acc.: 70.31%] [G loss: 0.572186]\n",
      "epoch:19 step:17906 [D loss: 0.499346, acc.: 75.00%] [G loss: 0.557627]\n",
      "epoch:19 step:17907 [D loss: 0.474585, acc.: 73.44%] [G loss: 0.639533]\n",
      "epoch:19 step:17908 [D loss: 0.592165, acc.: 64.06%] [G loss: 0.695337]\n",
      "epoch:19 step:17909 [D loss: 0.496332, acc.: 70.31%] [G loss: 0.617305]\n",
      "epoch:19 step:17910 [D loss: 0.543415, acc.: 74.22%] [G loss: 0.664423]\n",
      "epoch:19 step:17911 [D loss: 0.603532, acc.: 64.06%] [G loss: 0.577701]\n",
      "epoch:19 step:17912 [D loss: 0.588000, acc.: 66.41%] [G loss: 0.624633]\n",
      "epoch:19 step:17913 [D loss: 0.569495, acc.: 66.41%] [G loss: 0.593987]\n",
      "epoch:19 step:17914 [D loss: 0.489354, acc.: 78.12%] [G loss: 0.580422]\n",
      "epoch:19 step:17915 [D loss: 0.532858, acc.: 67.97%] [G loss: 0.809586]\n",
      "epoch:19 step:17916 [D loss: 0.533879, acc.: 68.75%] [G loss: 0.684462]\n",
      "epoch:19 step:17917 [D loss: 0.542944, acc.: 68.75%] [G loss: 0.708546]\n",
      "epoch:19 step:17918 [D loss: 0.566327, acc.: 71.09%] [G loss: 0.857139]\n",
      "epoch:19 step:17919 [D loss: 0.525028, acc.: 71.88%] [G loss: 0.763973]\n",
      "epoch:19 step:17920 [D loss: 0.524680, acc.: 71.09%] [G loss: 0.840578]\n",
      "epoch:19 step:17921 [D loss: 0.537750, acc.: 68.75%] [G loss: 0.890736]\n",
      "epoch:19 step:17922 [D loss: 0.433850, acc.: 81.25%] [G loss: 0.979864]\n",
      "epoch:19 step:17923 [D loss: 0.630670, acc.: 65.62%] [G loss: 0.853352]\n",
      "epoch:19 step:17924 [D loss: 0.533543, acc.: 71.88%] [G loss: 0.755177]\n",
      "epoch:19 step:17925 [D loss: 0.518461, acc.: 75.78%] [G loss: 0.770164]\n",
      "epoch:19 step:17926 [D loss: 0.488980, acc.: 74.22%] [G loss: 0.767632]\n",
      "epoch:19 step:17927 [D loss: 0.541285, acc.: 69.53%] [G loss: 0.848376]\n",
      "epoch:19 step:17928 [D loss: 0.565226, acc.: 70.31%] [G loss: 0.654625]\n",
      "epoch:19 step:17929 [D loss: 0.460487, acc.: 74.22%] [G loss: 0.686462]\n",
      "epoch:19 step:17930 [D loss: 0.458572, acc.: 78.91%] [G loss: 0.640405]\n",
      "epoch:19 step:17931 [D loss: 0.510792, acc.: 71.09%] [G loss: 0.657198]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:19 step:17932 [D loss: 0.594550, acc.: 61.72%] [G loss: 0.472836]\n",
      "epoch:19 step:17933 [D loss: 0.458269, acc.: 75.78%] [G loss: 0.673001]\n",
      "epoch:19 step:17934 [D loss: 0.448075, acc.: 76.56%] [G loss: 0.807513]\n",
      "epoch:19 step:17935 [D loss: 0.565598, acc.: 72.66%] [G loss: 0.747867]\n",
      "epoch:19 step:17936 [D loss: 0.549186, acc.: 67.97%] [G loss: 0.775464]\n",
      "epoch:19 step:17937 [D loss: 0.546622, acc.: 70.31%] [G loss: 0.700193]\n",
      "epoch:19 step:17938 [D loss: 0.485861, acc.: 76.56%] [G loss: 0.725423]\n",
      "epoch:19 step:17939 [D loss: 0.506163, acc.: 77.34%] [G loss: 0.811908]\n",
      "epoch:19 step:17940 [D loss: 0.648751, acc.: 60.94%] [G loss: 0.655027]\n",
      "epoch:19 step:17941 [D loss: 0.517942, acc.: 72.66%] [G loss: 0.681822]\n",
      "epoch:19 step:17942 [D loss: 0.577700, acc.: 69.53%] [G loss: 0.609570]\n",
      "epoch:19 step:17943 [D loss: 0.580169, acc.: 69.53%] [G loss: 0.663813]\n",
      "epoch:19 step:17944 [D loss: 0.520189, acc.: 72.66%] [G loss: 0.801212]\n",
      "epoch:19 step:17945 [D loss: 0.572118, acc.: 67.19%] [G loss: 0.620516]\n",
      "epoch:19 step:17946 [D loss: 0.619959, acc.: 63.28%] [G loss: 0.634487]\n",
      "epoch:19 step:17947 [D loss: 0.505414, acc.: 73.44%] [G loss: 0.722817]\n",
      "epoch:19 step:17948 [D loss: 0.535646, acc.: 68.75%] [G loss: 0.618583]\n",
      "epoch:19 step:17949 [D loss: 0.522856, acc.: 72.66%] [G loss: 0.607735]\n",
      "epoch:19 step:17950 [D loss: 0.629465, acc.: 67.97%] [G loss: 0.681506]\n",
      "epoch:19 step:17951 [D loss: 0.531481, acc.: 71.09%] [G loss: 0.768143]\n",
      "epoch:19 step:17952 [D loss: 0.453543, acc.: 77.34%] [G loss: 0.639587]\n",
      "epoch:19 step:17953 [D loss: 0.535406, acc.: 67.97%] [G loss: 0.549180]\n",
      "epoch:19 step:17954 [D loss: 0.509293, acc.: 74.22%] [G loss: 0.683135]\n",
      "epoch:19 step:17955 [D loss: 0.485097, acc.: 79.69%] [G loss: 0.763489]\n",
      "epoch:19 step:17956 [D loss: 0.508596, acc.: 74.22%] [G loss: 0.825661]\n",
      "epoch:19 step:17957 [D loss: 0.516884, acc.: 73.44%] [G loss: 0.703755]\n",
      "epoch:19 step:17958 [D loss: 0.509947, acc.: 71.09%] [G loss: 0.646323]\n",
      "epoch:19 step:17959 [D loss: 0.478416, acc.: 79.69%] [G loss: 0.740821]\n",
      "epoch:19 step:17960 [D loss: 0.541717, acc.: 71.09%] [G loss: 0.686127]\n",
      "epoch:19 step:17961 [D loss: 0.517128, acc.: 75.00%] [G loss: 0.686155]\n",
      "epoch:19 step:17962 [D loss: 0.488197, acc.: 76.56%] [G loss: 0.598201]\n",
      "epoch:19 step:17963 [D loss: 0.559581, acc.: 66.41%] [G loss: 0.690673]\n",
      "epoch:19 step:17964 [D loss: 0.524900, acc.: 76.56%] [G loss: 0.675090]\n",
      "epoch:19 step:17965 [D loss: 0.455442, acc.: 75.78%] [G loss: 0.865941]\n",
      "epoch:19 step:17966 [D loss: 0.527837, acc.: 72.66%] [G loss: 0.686015]\n",
      "epoch:19 step:17967 [D loss: 0.527123, acc.: 72.66%] [G loss: 0.732439]\n",
      "epoch:19 step:17968 [D loss: 0.501704, acc.: 74.22%] [G loss: 0.579353]\n",
      "epoch:19 step:17969 [D loss: 0.541844, acc.: 70.31%] [G loss: 0.605010]\n",
      "epoch:19 step:17970 [D loss: 0.563126, acc.: 67.19%] [G loss: 0.566263]\n",
      "epoch:19 step:17971 [D loss: 0.535586, acc.: 74.22%] [G loss: 0.699191]\n",
      "epoch:19 step:17972 [D loss: 0.579018, acc.: 64.84%] [G loss: 0.631271]\n",
      "epoch:19 step:17973 [D loss: 0.531031, acc.: 69.53%] [G loss: 0.539859]\n",
      "epoch:19 step:17974 [D loss: 0.543716, acc.: 71.88%] [G loss: 0.722955]\n",
      "epoch:19 step:17975 [D loss: 0.485948, acc.: 72.66%] [G loss: 0.756446]\n",
      "epoch:19 step:17976 [D loss: 0.482114, acc.: 71.88%] [G loss: 0.727427]\n",
      "epoch:19 step:17977 [D loss: 0.588915, acc.: 59.38%] [G loss: 0.611549]\n",
      "epoch:19 step:17978 [D loss: 0.593884, acc.: 61.72%] [G loss: 0.603472]\n",
      "epoch:19 step:17979 [D loss: 0.526361, acc.: 71.09%] [G loss: 0.670629]\n",
      "epoch:19 step:17980 [D loss: 0.482312, acc.: 77.34%] [G loss: 0.644731]\n",
      "epoch:19 step:17981 [D loss: 0.576406, acc.: 65.62%] [G loss: 0.608728]\n",
      "epoch:19 step:17982 [D loss: 0.483826, acc.: 75.00%] [G loss: 0.687160]\n",
      "epoch:19 step:17983 [D loss: 0.618990, acc.: 64.84%] [G loss: 0.585856]\n",
      "epoch:19 step:17984 [D loss: 0.545310, acc.: 71.88%] [G loss: 0.676775]\n",
      "epoch:19 step:17985 [D loss: 0.501977, acc.: 71.88%] [G loss: 0.537449]\n",
      "epoch:19 step:17986 [D loss: 0.569061, acc.: 69.53%] [G loss: 0.799108]\n",
      "epoch:19 step:17987 [D loss: 0.500921, acc.: 78.12%] [G loss: 0.646262]\n",
      "epoch:19 step:17988 [D loss: 0.524559, acc.: 71.88%] [G loss: 0.653903]\n",
      "epoch:19 step:17989 [D loss: 0.567118, acc.: 64.84%] [G loss: 0.530593]\n",
      "epoch:19 step:17990 [D loss: 0.637507, acc.: 58.59%] [G loss: 0.554207]\n",
      "epoch:19 step:17991 [D loss: 0.530354, acc.: 66.41%] [G loss: 0.721573]\n",
      "epoch:19 step:17992 [D loss: 0.631321, acc.: 68.75%] [G loss: 0.535052]\n",
      "epoch:19 step:17993 [D loss: 0.478534, acc.: 77.34%] [G loss: 0.587708]\n",
      "epoch:19 step:17994 [D loss: 0.461469, acc.: 78.12%] [G loss: 0.780496]\n",
      "epoch:19 step:17995 [D loss: 0.491356, acc.: 75.00%] [G loss: 0.726223]\n",
      "epoch:19 step:17996 [D loss: 0.546582, acc.: 67.97%] [G loss: 0.640969]\n",
      "epoch:19 step:17997 [D loss: 0.429455, acc.: 81.25%] [G loss: 0.768932]\n",
      "epoch:19 step:17998 [D loss: 0.535797, acc.: 71.09%] [G loss: 0.776092]\n",
      "epoch:19 step:17999 [D loss: 0.564519, acc.: 68.75%] [G loss: 0.621425]\n",
      "epoch:19 step:18000 [D loss: 0.496132, acc.: 71.09%] [G loss: 0.728119]\n",
      "epoch:19 step:18001 [D loss: 0.411936, acc.: 84.38%] [G loss: 0.920668]\n",
      "epoch:19 step:18002 [D loss: 0.501916, acc.: 73.44%] [G loss: 0.884405]\n",
      "epoch:19 step:18003 [D loss: 0.632547, acc.: 64.84%] [G loss: 0.724027]\n",
      "epoch:19 step:18004 [D loss: 0.541631, acc.: 72.66%] [G loss: 0.715866]\n",
      "epoch:19 step:18005 [D loss: 0.570508, acc.: 71.09%] [G loss: 0.795614]\n",
      "epoch:19 step:18006 [D loss: 0.599702, acc.: 67.97%] [G loss: 0.771321]\n",
      "epoch:19 step:18007 [D loss: 0.518619, acc.: 70.31%] [G loss: 0.661182]\n",
      "epoch:19 step:18008 [D loss: 0.493740, acc.: 72.66%] [G loss: 0.725617]\n",
      "epoch:19 step:18009 [D loss: 0.486079, acc.: 75.78%] [G loss: 0.803928]\n",
      "epoch:19 step:18010 [D loss: 0.441824, acc.: 82.03%] [G loss: 0.829907]\n",
      "epoch:19 step:18011 [D loss: 0.468977, acc.: 77.34%] [G loss: 0.840106]\n",
      "epoch:19 step:18012 [D loss: 0.513793, acc.: 77.34%] [G loss: 0.889001]\n",
      "epoch:19 step:18013 [D loss: 0.590075, acc.: 71.09%] [G loss: 0.669912]\n",
      "epoch:19 step:18014 [D loss: 0.581670, acc.: 68.75%] [G loss: 0.671597]\n",
      "epoch:19 step:18015 [D loss: 0.543669, acc.: 70.31%] [G loss: 0.554970]\n",
      "epoch:19 step:18016 [D loss: 0.486309, acc.: 74.22%] [G loss: 0.733478]\n",
      "epoch:19 step:18017 [D loss: 0.599428, acc.: 63.28%] [G loss: 0.658502]\n",
      "epoch:19 step:18018 [D loss: 0.586136, acc.: 67.19%] [G loss: 0.517644]\n",
      "epoch:19 step:18019 [D loss: 0.514810, acc.: 74.22%] [G loss: 0.657848]\n",
      "epoch:19 step:18020 [D loss: 0.510979, acc.: 74.22%] [G loss: 0.704178]\n",
      "epoch:19 step:18021 [D loss: 0.513748, acc.: 78.12%] [G loss: 0.683104]\n",
      "epoch:19 step:18022 [D loss: 0.460871, acc.: 80.47%] [G loss: 0.889187]\n",
      "epoch:19 step:18023 [D loss: 0.652680, acc.: 66.41%] [G loss: 0.908307]\n",
      "epoch:19 step:18024 [D loss: 0.559919, acc.: 71.09%] [G loss: 0.717849]\n",
      "epoch:19 step:18025 [D loss: 0.478981, acc.: 76.56%] [G loss: 0.785635]\n",
      "epoch:19 step:18026 [D loss: 0.498643, acc.: 78.12%] [G loss: 0.861879]\n",
      "epoch:19 step:18027 [D loss: 0.549878, acc.: 64.84%] [G loss: 0.632782]\n",
      "epoch:19 step:18028 [D loss: 0.480007, acc.: 77.34%] [G loss: 0.698121]\n",
      "epoch:19 step:18029 [D loss: 0.542465, acc.: 69.53%] [G loss: 0.561797]\n",
      "epoch:19 step:18030 [D loss: 0.534405, acc.: 69.53%] [G loss: 0.565234]\n",
      "epoch:19 step:18031 [D loss: 0.570279, acc.: 67.19%] [G loss: 0.592518]\n",
      "epoch:19 step:18032 [D loss: 0.473202, acc.: 77.34%] [G loss: 0.698143]\n",
      "epoch:19 step:18033 [D loss: 0.464294, acc.: 80.47%] [G loss: 0.747784]\n",
      "epoch:19 step:18034 [D loss: 0.465658, acc.: 75.78%] [G loss: 0.837765]\n",
      "epoch:19 step:18035 [D loss: 0.429958, acc.: 82.03%] [G loss: 0.950196]\n",
      "epoch:19 step:18036 [D loss: 0.518390, acc.: 75.00%] [G loss: 0.790694]\n",
      "epoch:19 step:18037 [D loss: 0.621656, acc.: 71.88%] [G loss: 0.839086]\n",
      "epoch:19 step:18038 [D loss: 0.582619, acc.: 64.84%] [G loss: 0.740161]\n",
      "epoch:19 step:18039 [D loss: 0.514969, acc.: 70.31%] [G loss: 0.706778]\n",
      "epoch:19 step:18040 [D loss: 0.533784, acc.: 70.31%] [G loss: 0.576612]\n",
      "epoch:19 step:18041 [D loss: 0.582691, acc.: 63.28%] [G loss: 0.614006]\n",
      "epoch:19 step:18042 [D loss: 0.527066, acc.: 65.62%] [G loss: 0.640967]\n",
      "epoch:19 step:18043 [D loss: 0.531225, acc.: 72.66%] [G loss: 0.566148]\n",
      "epoch:19 step:18044 [D loss: 0.507168, acc.: 76.56%] [G loss: 0.580790]\n",
      "epoch:19 step:18045 [D loss: 0.436962, acc.: 82.03%] [G loss: 0.962019]\n",
      "epoch:19 step:18046 [D loss: 0.501138, acc.: 70.31%] [G loss: 0.860668]\n",
      "epoch:19 step:18047 [D loss: 0.454223, acc.: 78.12%] [G loss: 0.775424]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:19 step:18048 [D loss: 0.471199, acc.: 75.00%] [G loss: 0.783586]\n",
      "epoch:19 step:18049 [D loss: 0.495763, acc.: 72.66%] [G loss: 0.704931]\n",
      "epoch:19 step:18050 [D loss: 0.486706, acc.: 73.44%] [G loss: 0.911214]\n",
      "epoch:19 step:18051 [D loss: 0.465487, acc.: 76.56%] [G loss: 0.781590]\n",
      "epoch:19 step:18052 [D loss: 0.603257, acc.: 67.97%] [G loss: 0.779898]\n",
      "epoch:19 step:18053 [D loss: 0.548365, acc.: 67.19%] [G loss: 0.710215]\n",
      "epoch:19 step:18054 [D loss: 0.553845, acc.: 67.97%] [G loss: 0.710844]\n",
      "epoch:19 step:18055 [D loss: 0.558901, acc.: 72.66%] [G loss: 0.831184]\n",
      "epoch:19 step:18056 [D loss: 0.586504, acc.: 71.09%] [G loss: 0.646413]\n",
      "epoch:19 step:18057 [D loss: 0.488607, acc.: 71.88%] [G loss: 0.772884]\n",
      "epoch:19 step:18058 [D loss: 0.500906, acc.: 74.22%] [G loss: 0.737203]\n",
      "epoch:19 step:18059 [D loss: 0.477600, acc.: 74.22%] [G loss: 0.782568]\n",
      "epoch:19 step:18060 [D loss: 0.520795, acc.: 72.66%] [G loss: 0.645595]\n",
      "epoch:19 step:18061 [D loss: 0.482711, acc.: 72.66%] [G loss: 0.702271]\n",
      "epoch:19 step:18062 [D loss: 0.488610, acc.: 77.34%] [G loss: 0.892410]\n",
      "epoch:19 step:18063 [D loss: 0.582487, acc.: 61.72%] [G loss: 0.603284]\n",
      "epoch:19 step:18064 [D loss: 0.531784, acc.: 75.78%] [G loss: 0.597080]\n",
      "epoch:19 step:18065 [D loss: 0.479587, acc.: 75.78%] [G loss: 0.817239]\n",
      "epoch:19 step:18066 [D loss: 0.640389, acc.: 63.28%] [G loss: 0.607006]\n",
      "epoch:19 step:18067 [D loss: 0.472529, acc.: 77.34%] [G loss: 0.795508]\n",
      "epoch:19 step:18068 [D loss: 0.548465, acc.: 69.53%] [G loss: 0.645666]\n",
      "epoch:19 step:18069 [D loss: 0.512990, acc.: 73.44%] [G loss: 0.722644]\n",
      "epoch:19 step:18070 [D loss: 0.588754, acc.: 72.66%] [G loss: 0.853472]\n",
      "epoch:19 step:18071 [D loss: 0.508117, acc.: 74.22%] [G loss: 0.769891]\n",
      "epoch:19 step:18072 [D loss: 0.579030, acc.: 67.97%] [G loss: 0.604448]\n",
      "epoch:19 step:18073 [D loss: 0.473388, acc.: 78.12%] [G loss: 0.615923]\n",
      "epoch:19 step:18074 [D loss: 0.485763, acc.: 71.88%] [G loss: 0.730000]\n",
      "epoch:19 step:18075 [D loss: 0.556234, acc.: 67.97%] [G loss: 0.551803]\n",
      "epoch:19 step:18076 [D loss: 0.523706, acc.: 71.09%] [G loss: 0.563536]\n",
      "epoch:19 step:18077 [D loss: 0.461423, acc.: 78.12%] [G loss: 0.630673]\n",
      "epoch:19 step:18078 [D loss: 0.544704, acc.: 74.22%] [G loss: 0.560984]\n",
      "epoch:19 step:18079 [D loss: 0.469732, acc.: 78.12%] [G loss: 0.662302]\n",
      "epoch:19 step:18080 [D loss: 0.615131, acc.: 65.62%] [G loss: 0.622078]\n",
      "epoch:19 step:18081 [D loss: 0.520633, acc.: 74.22%] [G loss: 0.656390]\n",
      "epoch:19 step:18082 [D loss: 0.534751, acc.: 71.88%] [G loss: 0.873219]\n",
      "epoch:19 step:18083 [D loss: 0.529644, acc.: 70.31%] [G loss: 0.584157]\n",
      "epoch:19 step:18084 [D loss: 0.547140, acc.: 74.22%] [G loss: 0.595094]\n",
      "epoch:19 step:18085 [D loss: 0.530763, acc.: 73.44%] [G loss: 0.741451]\n",
      "epoch:19 step:18086 [D loss: 0.479349, acc.: 77.34%] [G loss: 0.795057]\n",
      "epoch:19 step:18087 [D loss: 0.534035, acc.: 67.97%] [G loss: 0.749594]\n",
      "epoch:19 step:18088 [D loss: 0.522115, acc.: 66.41%] [G loss: 0.754187]\n",
      "epoch:19 step:18089 [D loss: 0.480555, acc.: 78.12%] [G loss: 0.808187]\n",
      "epoch:19 step:18090 [D loss: 0.601835, acc.: 67.19%] [G loss: 0.624864]\n",
      "epoch:19 step:18091 [D loss: 0.534131, acc.: 70.31%] [G loss: 0.625533]\n",
      "epoch:19 step:18092 [D loss: 0.495842, acc.: 71.88%] [G loss: 0.734758]\n",
      "epoch:19 step:18093 [D loss: 0.545605, acc.: 69.53%] [G loss: 0.663697]\n",
      "epoch:19 step:18094 [D loss: 0.551416, acc.: 72.66%] [G loss: 0.535973]\n",
      "epoch:19 step:18095 [D loss: 0.542231, acc.: 68.75%] [G loss: 0.814690]\n",
      "epoch:19 step:18096 [D loss: 0.577051, acc.: 67.19%] [G loss: 0.567935]\n",
      "epoch:19 step:18097 [D loss: 0.557016, acc.: 69.53%] [G loss: 0.567831]\n",
      "epoch:19 step:18098 [D loss: 0.520087, acc.: 69.53%] [G loss: 0.464928]\n",
      "epoch:19 step:18099 [D loss: 0.464721, acc.: 74.22%] [G loss: 0.595112]\n",
      "epoch:19 step:18100 [D loss: 0.545268, acc.: 73.44%] [G loss: 0.590282]\n",
      "epoch:19 step:18101 [D loss: 0.506412, acc.: 75.78%] [G loss: 0.650609]\n",
      "epoch:19 step:18102 [D loss: 0.489271, acc.: 71.09%] [G loss: 0.849896]\n",
      "epoch:19 step:18103 [D loss: 0.480349, acc.: 77.34%] [G loss: 0.762362]\n",
      "epoch:19 step:18104 [D loss: 0.605346, acc.: 67.19%] [G loss: 0.727195]\n",
      "epoch:19 step:18105 [D loss: 0.512276, acc.: 71.88%] [G loss: 0.860839]\n",
      "epoch:19 step:18106 [D loss: 0.571230, acc.: 69.53%] [G loss: 0.653359]\n",
      "epoch:19 step:18107 [D loss: 0.472960, acc.: 75.78%] [G loss: 0.763495]\n",
      "epoch:19 step:18108 [D loss: 0.560223, acc.: 69.53%] [G loss: 0.714434]\n",
      "epoch:19 step:18109 [D loss: 0.518743, acc.: 77.34%] [G loss: 0.797512]\n",
      "epoch:19 step:18110 [D loss: 0.457228, acc.: 77.34%] [G loss: 0.710619]\n",
      "epoch:19 step:18111 [D loss: 0.569401, acc.: 67.19%] [G loss: 0.592613]\n",
      "epoch:19 step:18112 [D loss: 0.518057, acc.: 69.53%] [G loss: 0.770758]\n",
      "epoch:19 step:18113 [D loss: 0.524332, acc.: 70.31%] [G loss: 0.696918]\n",
      "epoch:19 step:18114 [D loss: 0.440704, acc.: 78.91%] [G loss: 0.921925]\n",
      "epoch:19 step:18115 [D loss: 0.496315, acc.: 72.66%] [G loss: 0.736059]\n",
      "epoch:19 step:18116 [D loss: 0.495150, acc.: 75.00%] [G loss: 1.097513]\n",
      "epoch:19 step:18117 [D loss: 0.477480, acc.: 75.78%] [G loss: 0.848907]\n",
      "epoch:19 step:18118 [D loss: 0.403692, acc.: 82.81%] [G loss: 1.029453]\n",
      "epoch:19 step:18119 [D loss: 0.682174, acc.: 64.84%] [G loss: 0.786338]\n",
      "epoch:19 step:18120 [D loss: 0.594941, acc.: 69.53%] [G loss: 0.659842]\n",
      "epoch:19 step:18121 [D loss: 0.548445, acc.: 66.41%] [G loss: 0.636379]\n",
      "epoch:19 step:18122 [D loss: 0.609457, acc.: 75.00%] [G loss: 0.600123]\n",
      "epoch:19 step:18123 [D loss: 0.581047, acc.: 69.53%] [G loss: 0.679060]\n",
      "epoch:19 step:18124 [D loss: 0.483385, acc.: 78.91%] [G loss: 0.797821]\n",
      "epoch:19 step:18125 [D loss: 0.567194, acc.: 68.75%] [G loss: 0.728966]\n",
      "epoch:19 step:18126 [D loss: 0.618106, acc.: 67.19%] [G loss: 0.687036]\n",
      "epoch:19 step:18127 [D loss: 0.527782, acc.: 72.66%] [G loss: 0.615683]\n",
      "epoch:19 step:18128 [D loss: 0.558631, acc.: 65.62%] [G loss: 0.713119]\n",
      "epoch:19 step:18129 [D loss: 0.475703, acc.: 74.22%] [G loss: 0.743788]\n",
      "epoch:19 step:18130 [D loss: 0.565131, acc.: 71.09%] [G loss: 0.675603]\n",
      "epoch:19 step:18131 [D loss: 0.404326, acc.: 81.25%] [G loss: 0.758202]\n",
      "epoch:19 step:18132 [D loss: 0.529940, acc.: 72.66%] [G loss: 0.683976]\n",
      "epoch:19 step:18133 [D loss: 0.502603, acc.: 73.44%] [G loss: 0.602714]\n",
      "epoch:19 step:18134 [D loss: 0.509062, acc.: 74.22%] [G loss: 0.565058]\n",
      "epoch:19 step:18135 [D loss: 0.515688, acc.: 71.09%] [G loss: 0.524437]\n",
      "epoch:19 step:18136 [D loss: 0.520216, acc.: 74.22%] [G loss: 0.814617]\n",
      "epoch:19 step:18137 [D loss: 0.444722, acc.: 76.56%] [G loss: 0.873893]\n",
      "epoch:19 step:18138 [D loss: 0.487223, acc.: 74.22%] [G loss: 0.881978]\n",
      "epoch:19 step:18139 [D loss: 0.496668, acc.: 75.78%] [G loss: 0.781225]\n",
      "epoch:19 step:18140 [D loss: 0.469681, acc.: 77.34%] [G loss: 0.845947]\n",
      "epoch:19 step:18141 [D loss: 0.537033, acc.: 66.41%] [G loss: 0.743646]\n",
      "epoch:19 step:18142 [D loss: 0.527783, acc.: 75.00%] [G loss: 0.847969]\n",
      "epoch:19 step:18143 [D loss: 0.451911, acc.: 75.78%] [G loss: 0.792569]\n",
      "epoch:19 step:18144 [D loss: 0.597677, acc.: 71.88%] [G loss: 0.810412]\n",
      "epoch:19 step:18145 [D loss: 0.686587, acc.: 57.81%] [G loss: 0.722914]\n",
      "epoch:19 step:18146 [D loss: 0.537926, acc.: 71.09%] [G loss: 0.701041]\n",
      "epoch:19 step:18147 [D loss: 0.473727, acc.: 79.69%] [G loss: 1.103420]\n",
      "epoch:19 step:18148 [D loss: 0.548747, acc.: 64.84%] [G loss: 0.824228]\n",
      "epoch:19 step:18149 [D loss: 0.515611, acc.: 71.09%] [G loss: 0.758803]\n",
      "epoch:19 step:18150 [D loss: 0.421325, acc.: 85.16%] [G loss: 1.020486]\n",
      "epoch:19 step:18151 [D loss: 0.643927, acc.: 64.84%] [G loss: 0.703437]\n",
      "epoch:19 step:18152 [D loss: 0.645147, acc.: 64.84%] [G loss: 0.702914]\n",
      "epoch:19 step:18153 [D loss: 0.524283, acc.: 73.44%] [G loss: 0.511460]\n",
      "epoch:19 step:18154 [D loss: 0.481368, acc.: 73.44%] [G loss: 0.774247]\n",
      "epoch:19 step:18155 [D loss: 0.558955, acc.: 70.31%] [G loss: 0.597276]\n",
      "epoch:19 step:18156 [D loss: 0.507627, acc.: 71.09%] [G loss: 0.802113]\n",
      "epoch:19 step:18157 [D loss: 0.391766, acc.: 82.03%] [G loss: 0.870804]\n",
      "epoch:19 step:18158 [D loss: 0.490240, acc.: 77.34%] [G loss: 0.767602]\n",
      "epoch:19 step:18159 [D loss: 0.592298, acc.: 66.41%] [G loss: 0.716393]\n",
      "epoch:19 step:18160 [D loss: 0.451721, acc.: 78.91%] [G loss: 0.807408]\n",
      "epoch:19 step:18161 [D loss: 0.448302, acc.: 78.91%] [G loss: 0.881839]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:19 step:18162 [D loss: 0.493044, acc.: 71.09%] [G loss: 0.820702]\n",
      "epoch:19 step:18163 [D loss: 0.459039, acc.: 77.34%] [G loss: 0.798284]\n",
      "epoch:19 step:18164 [D loss: 0.537634, acc.: 70.31%] [G loss: 0.789760]\n",
      "epoch:19 step:18165 [D loss: 0.553453, acc.: 72.66%] [G loss: 0.728759]\n",
      "epoch:19 step:18166 [D loss: 0.562851, acc.: 67.19%] [G loss: 0.691848]\n",
      "epoch:19 step:18167 [D loss: 0.510686, acc.: 73.44%] [G loss: 0.878034]\n",
      "epoch:19 step:18168 [D loss: 0.546992, acc.: 71.88%] [G loss: 0.745834]\n",
      "epoch:19 step:18169 [D loss: 0.530524, acc.: 71.88%] [G loss: 0.654920]\n",
      "epoch:19 step:18170 [D loss: 0.609415, acc.: 66.41%] [G loss: 0.658041]\n",
      "epoch:19 step:18171 [D loss: 0.535307, acc.: 68.75%] [G loss: 0.571892]\n",
      "epoch:19 step:18172 [D loss: 0.509228, acc.: 71.88%] [G loss: 0.687676]\n",
      "epoch:19 step:18173 [D loss: 0.515645, acc.: 76.56%] [G loss: 0.653743]\n",
      "epoch:19 step:18174 [D loss: 0.503174, acc.: 78.91%] [G loss: 0.771514]\n",
      "epoch:19 step:18175 [D loss: 0.585932, acc.: 63.28%] [G loss: 0.565509]\n",
      "epoch:19 step:18176 [D loss: 0.555816, acc.: 67.97%] [G loss: 0.561061]\n",
      "epoch:19 step:18177 [D loss: 0.463991, acc.: 75.78%] [G loss: 0.711224]\n",
      "epoch:19 step:18178 [D loss: 0.501832, acc.: 76.56%] [G loss: 0.830092]\n",
      "epoch:19 step:18179 [D loss: 0.646415, acc.: 67.19%] [G loss: 0.481432]\n",
      "epoch:19 step:18180 [D loss: 0.564425, acc.: 61.72%] [G loss: 0.623677]\n",
      "epoch:19 step:18181 [D loss: 0.508919, acc.: 72.66%] [G loss: 0.647935]\n",
      "epoch:19 step:18182 [D loss: 0.557782, acc.: 71.88%] [G loss: 0.649791]\n",
      "epoch:19 step:18183 [D loss: 0.600876, acc.: 67.97%] [G loss: 0.643436]\n",
      "epoch:19 step:18184 [D loss: 0.475652, acc.: 78.12%] [G loss: 0.577167]\n",
      "epoch:19 step:18185 [D loss: 0.540470, acc.: 70.31%] [G loss: 0.582113]\n",
      "epoch:19 step:18186 [D loss: 0.537418, acc.: 70.31%] [G loss: 0.733400]\n",
      "epoch:19 step:18187 [D loss: 0.521854, acc.: 69.53%] [G loss: 0.809928]\n",
      "epoch:19 step:18188 [D loss: 0.443504, acc.: 82.03%] [G loss: 0.625231]\n",
      "epoch:19 step:18189 [D loss: 0.635436, acc.: 65.62%] [G loss: 0.456678]\n",
      "epoch:19 step:18190 [D loss: 0.564174, acc.: 67.97%] [G loss: 0.700268]\n",
      "epoch:19 step:18191 [D loss: 0.577478, acc.: 68.75%] [G loss: 0.697629]\n",
      "epoch:19 step:18192 [D loss: 0.532807, acc.: 72.66%] [G loss: 0.632055]\n",
      "epoch:19 step:18193 [D loss: 0.632663, acc.: 67.97%] [G loss: 0.790460]\n",
      "epoch:19 step:18194 [D loss: 0.583255, acc.: 62.50%] [G loss: 0.590378]\n",
      "epoch:19 step:18195 [D loss: 0.474154, acc.: 76.56%] [G loss: 0.931626]\n",
      "epoch:19 step:18196 [D loss: 0.585412, acc.: 65.62%] [G loss: 0.696288]\n",
      "epoch:19 step:18197 [D loss: 0.518795, acc.: 75.00%] [G loss: 0.619256]\n",
      "epoch:19 step:18198 [D loss: 0.508133, acc.: 75.78%] [G loss: 0.573083]\n",
      "epoch:19 step:18199 [D loss: 0.537005, acc.: 71.88%] [G loss: 0.670917]\n",
      "epoch:19 step:18200 [D loss: 0.571429, acc.: 67.19%] [G loss: 0.583975]\n",
      "epoch:19 step:18201 [D loss: 0.468254, acc.: 80.47%] [G loss: 0.699664]\n",
      "epoch:19 step:18202 [D loss: 0.501651, acc.: 75.78%] [G loss: 0.716174]\n",
      "epoch:19 step:18203 [D loss: 0.618299, acc.: 60.94%] [G loss: 0.574874]\n",
      "epoch:19 step:18204 [D loss: 0.610422, acc.: 61.72%] [G loss: 0.552339]\n",
      "epoch:19 step:18205 [D loss: 0.456011, acc.: 78.12%] [G loss: 0.757907]\n",
      "epoch:19 step:18206 [D loss: 0.452181, acc.: 78.91%] [G loss: 0.864386]\n",
      "epoch:19 step:18207 [D loss: 0.566668, acc.: 67.97%] [G loss: 0.657817]\n",
      "epoch:19 step:18208 [D loss: 0.540342, acc.: 72.66%] [G loss: 0.703407]\n",
      "epoch:19 step:18209 [D loss: 0.488059, acc.: 72.66%] [G loss: 0.872757]\n",
      "epoch:19 step:18210 [D loss: 0.595288, acc.: 65.62%] [G loss: 0.766373]\n",
      "epoch:19 step:18211 [D loss: 0.571185, acc.: 67.97%] [G loss: 0.616294]\n",
      "epoch:19 step:18212 [D loss: 0.552056, acc.: 64.84%] [G loss: 0.791581]\n",
      "epoch:19 step:18213 [D loss: 0.567988, acc.: 67.97%] [G loss: 0.838602]\n",
      "epoch:19 step:18214 [D loss: 0.592026, acc.: 59.38%] [G loss: 0.800778]\n",
      "epoch:19 step:18215 [D loss: 0.629780, acc.: 65.62%] [G loss: 0.468582]\n",
      "epoch:19 step:18216 [D loss: 0.516776, acc.: 73.44%] [G loss: 0.573136]\n",
      "epoch:19 step:18217 [D loss: 0.508966, acc.: 71.88%] [G loss: 0.808827]\n",
      "epoch:19 step:18218 [D loss: 0.525407, acc.: 72.66%] [G loss: 0.829424]\n",
      "epoch:19 step:18219 [D loss: 0.465931, acc.: 77.34%] [G loss: 0.739016]\n",
      "epoch:19 step:18220 [D loss: 0.476026, acc.: 80.47%] [G loss: 0.856666]\n",
      "epoch:19 step:18221 [D loss: 0.634505, acc.: 64.06%] [G loss: 0.680750]\n",
      "epoch:19 step:18222 [D loss: 0.569037, acc.: 66.41%] [G loss: 0.581437]\n",
      "epoch:19 step:18223 [D loss: 0.603741, acc.: 65.62%] [G loss: 0.756432]\n",
      "epoch:19 step:18224 [D loss: 0.535917, acc.: 67.19%] [G loss: 0.667005]\n",
      "epoch:19 step:18225 [D loss: 0.577350, acc.: 65.62%] [G loss: 0.489283]\n",
      "epoch:19 step:18226 [D loss: 0.535798, acc.: 66.41%] [G loss: 0.585548]\n",
      "epoch:19 step:18227 [D loss: 0.565667, acc.: 65.62%] [G loss: 0.664420]\n",
      "epoch:19 step:18228 [D loss: 0.503277, acc.: 75.78%] [G loss: 0.728232]\n",
      "epoch:19 step:18229 [D loss: 0.463247, acc.: 78.12%] [G loss: 0.913714]\n",
      "epoch:19 step:18230 [D loss: 0.464056, acc.: 77.34%] [G loss: 1.018360]\n",
      "epoch:19 step:18231 [D loss: 0.529507, acc.: 68.75%] [G loss: 0.918718]\n",
      "epoch:19 step:18232 [D loss: 0.518988, acc.: 73.44%] [G loss: 0.801501]\n",
      "epoch:19 step:18233 [D loss: 0.459009, acc.: 78.12%] [G loss: 0.909455]\n",
      "epoch:19 step:18234 [D loss: 0.533719, acc.: 72.66%] [G loss: 0.732588]\n",
      "epoch:19 step:18235 [D loss: 0.535014, acc.: 74.22%] [G loss: 0.886256]\n",
      "epoch:19 step:18236 [D loss: 0.511900, acc.: 76.56%] [G loss: 0.595286]\n",
      "epoch:19 step:18237 [D loss: 0.514666, acc.: 69.53%] [G loss: 0.845968]\n",
      "epoch:19 step:18238 [D loss: 0.556897, acc.: 69.53%] [G loss: 0.695109]\n",
      "epoch:19 step:18239 [D loss: 0.453485, acc.: 77.34%] [G loss: 0.826570]\n",
      "epoch:19 step:18240 [D loss: 0.618023, acc.: 63.28%] [G loss: 0.626819]\n",
      "epoch:19 step:18241 [D loss: 0.572105, acc.: 71.09%] [G loss: 0.469515]\n",
      "epoch:19 step:18242 [D loss: 0.490800, acc.: 75.00%] [G loss: 0.649819]\n",
      "epoch:19 step:18243 [D loss: 0.524057, acc.: 73.44%] [G loss: 0.739090]\n",
      "epoch:19 step:18244 [D loss: 0.498821, acc.: 72.66%] [G loss: 0.808745]\n",
      "epoch:19 step:18245 [D loss: 0.536225, acc.: 71.88%] [G loss: 0.786161]\n",
      "epoch:19 step:18246 [D loss: 0.507861, acc.: 71.88%] [G loss: 0.685170]\n",
      "epoch:19 step:18247 [D loss: 0.475494, acc.: 76.56%] [G loss: 0.994557]\n",
      "epoch:19 step:18248 [D loss: 0.522789, acc.: 66.41%] [G loss: 0.743043]\n",
      "epoch:19 step:18249 [D loss: 0.466029, acc.: 78.91%] [G loss: 0.812011]\n",
      "epoch:19 step:18250 [D loss: 0.463101, acc.: 75.00%] [G loss: 0.802186]\n",
      "epoch:19 step:18251 [D loss: 0.572474, acc.: 67.97%] [G loss: 0.631583]\n",
      "epoch:19 step:18252 [D loss: 0.532113, acc.: 72.66%] [G loss: 0.726712]\n",
      "epoch:19 step:18253 [D loss: 0.535742, acc.: 71.88%] [G loss: 0.876612]\n",
      "epoch:19 step:18254 [D loss: 0.416796, acc.: 82.03%] [G loss: 1.060531]\n",
      "epoch:19 step:18255 [D loss: 0.471014, acc.: 73.44%] [G loss: 0.783082]\n",
      "epoch:19 step:18256 [D loss: 0.557834, acc.: 67.97%] [G loss: 0.711488]\n",
      "epoch:19 step:18257 [D loss: 0.504115, acc.: 77.34%] [G loss: 0.887965]\n",
      "epoch:19 step:18258 [D loss: 0.548662, acc.: 67.97%] [G loss: 0.617494]\n",
      "epoch:19 step:18259 [D loss: 0.597086, acc.: 66.41%] [G loss: 0.720844]\n",
      "epoch:19 step:18260 [D loss: 0.472066, acc.: 78.12%] [G loss: 0.918871]\n",
      "epoch:19 step:18261 [D loss: 0.668236, acc.: 67.19%] [G loss: 0.598688]\n",
      "epoch:19 step:18262 [D loss: 0.559490, acc.: 66.41%] [G loss: 0.632516]\n",
      "epoch:19 step:18263 [D loss: 0.523569, acc.: 70.31%] [G loss: 0.642600]\n",
      "epoch:19 step:18264 [D loss: 0.466710, acc.: 78.12%] [G loss: 0.689425]\n",
      "epoch:19 step:18265 [D loss: 0.584463, acc.: 67.19%] [G loss: 0.633723]\n",
      "epoch:19 step:18266 [D loss: 0.496373, acc.: 73.44%] [G loss: 0.539566]\n",
      "epoch:19 step:18267 [D loss: 0.545181, acc.: 73.44%] [G loss: 0.546064]\n",
      "epoch:19 step:18268 [D loss: 0.541176, acc.: 67.97%] [G loss: 0.526070]\n",
      "epoch:19 step:18269 [D loss: 0.498332, acc.: 71.09%] [G loss: 0.587857]\n",
      "epoch:19 step:18270 [D loss: 0.517691, acc.: 71.09%] [G loss: 0.728074]\n",
      "epoch:19 step:18271 [D loss: 0.479028, acc.: 75.78%] [G loss: 0.775510]\n",
      "epoch:19 step:18272 [D loss: 0.547123, acc.: 70.31%] [G loss: 0.666405]\n",
      "epoch:19 step:18273 [D loss: 0.505993, acc.: 74.22%] [G loss: 0.872931]\n",
      "epoch:19 step:18274 [D loss: 0.393714, acc.: 80.47%] [G loss: 0.842029]\n",
      "epoch:19 step:18275 [D loss: 0.452156, acc.: 82.03%] [G loss: 0.993557]\n",
      "epoch:19 step:18276 [D loss: 0.643234, acc.: 63.28%] [G loss: 0.693611]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:19 step:18277 [D loss: 0.545954, acc.: 73.44%] [G loss: 0.601637]\n",
      "epoch:19 step:18278 [D loss: 0.487155, acc.: 72.66%] [G loss: 0.766781]\n",
      "epoch:19 step:18279 [D loss: 0.522611, acc.: 73.44%] [G loss: 0.628987]\n",
      "epoch:19 step:18280 [D loss: 0.643244, acc.: 64.84%] [G loss: 0.571644]\n",
      "epoch:19 step:18281 [D loss: 0.502986, acc.: 77.34%] [G loss: 0.560594]\n",
      "epoch:19 step:18282 [D loss: 0.534326, acc.: 76.56%] [G loss: 0.663562]\n",
      "epoch:19 step:18283 [D loss: 0.558788, acc.: 65.62%] [G loss: 0.647634]\n",
      "epoch:19 step:18284 [D loss: 0.474772, acc.: 81.25%] [G loss: 0.637605]\n",
      "epoch:19 step:18285 [D loss: 0.589251, acc.: 67.19%] [G loss: 0.742608]\n",
      "epoch:19 step:18286 [D loss: 0.524729, acc.: 69.53%] [G loss: 0.811052]\n",
      "epoch:19 step:18287 [D loss: 0.535655, acc.: 71.09%] [G loss: 1.017297]\n",
      "epoch:19 step:18288 [D loss: 0.498921, acc.: 75.00%] [G loss: 1.020276]\n",
      "epoch:19 step:18289 [D loss: 0.524786, acc.: 73.44%] [G loss: 0.735278]\n",
      "epoch:19 step:18290 [D loss: 0.529580, acc.: 73.44%] [G loss: 0.541707]\n",
      "epoch:19 step:18291 [D loss: 0.533109, acc.: 68.75%] [G loss: 0.823813]\n",
      "epoch:19 step:18292 [D loss: 0.555417, acc.: 67.97%] [G loss: 0.701729]\n",
      "epoch:19 step:18293 [D loss: 0.571195, acc.: 64.84%] [G loss: 0.677273]\n",
      "epoch:19 step:18294 [D loss: 0.534652, acc.: 71.09%] [G loss: 0.632041]\n",
      "epoch:19 step:18295 [D loss: 0.504634, acc.: 72.66%] [G loss: 0.569350]\n",
      "epoch:19 step:18296 [D loss: 0.622885, acc.: 64.06%] [G loss: 0.570285]\n",
      "epoch:19 step:18297 [D loss: 0.540521, acc.: 76.56%] [G loss: 0.698834]\n",
      "epoch:19 step:18298 [D loss: 0.485646, acc.: 77.34%] [G loss: 0.673266]\n",
      "epoch:19 step:18299 [D loss: 0.497601, acc.: 77.34%] [G loss: 0.760355]\n",
      "epoch:19 step:18300 [D loss: 0.515223, acc.: 73.44%] [G loss: 0.781948]\n",
      "epoch:19 step:18301 [D loss: 0.523598, acc.: 71.88%] [G loss: 0.832419]\n",
      "epoch:19 step:18302 [D loss: 0.465795, acc.: 78.12%] [G loss: 0.714813]\n",
      "epoch:19 step:18303 [D loss: 0.558263, acc.: 68.75%] [G loss: 0.731958]\n",
      "epoch:19 step:18304 [D loss: 0.639745, acc.: 66.41%] [G loss: 0.706311]\n",
      "epoch:19 step:18305 [D loss: 0.623985, acc.: 57.03%] [G loss: 0.491094]\n",
      "epoch:19 step:18306 [D loss: 0.527609, acc.: 72.66%] [G loss: 0.519328]\n",
      "epoch:19 step:18307 [D loss: 0.447557, acc.: 77.34%] [G loss: 0.801003]\n",
      "epoch:19 step:18308 [D loss: 0.474571, acc.: 82.03%] [G loss: 0.640012]\n",
      "epoch:19 step:18309 [D loss: 0.494054, acc.: 74.22%] [G loss: 0.781974]\n",
      "epoch:19 step:18310 [D loss: 0.509851, acc.: 72.66%] [G loss: 0.899520]\n",
      "epoch:19 step:18311 [D loss: 0.368711, acc.: 86.72%] [G loss: 1.002223]\n",
      "epoch:19 step:18312 [D loss: 0.481490, acc.: 75.00%] [G loss: 0.982024]\n",
      "epoch:19 step:18313 [D loss: 0.611642, acc.: 64.06%] [G loss: 0.791858]\n",
      "epoch:19 step:18314 [D loss: 0.644309, acc.: 62.50%] [G loss: 0.589620]\n",
      "epoch:19 step:18315 [D loss: 0.536939, acc.: 73.44%] [G loss: 0.531603]\n",
      "epoch:19 step:18316 [D loss: 0.510209, acc.: 72.66%] [G loss: 0.637427]\n",
      "epoch:19 step:18317 [D loss: 0.449628, acc.: 77.34%] [G loss: 0.660323]\n",
      "epoch:19 step:18318 [D loss: 0.527743, acc.: 67.19%] [G loss: 0.743833]\n",
      "epoch:19 step:18319 [D loss: 0.433691, acc.: 80.47%] [G loss: 0.897021]\n",
      "epoch:19 step:18320 [D loss: 0.495983, acc.: 74.22%] [G loss: 0.640127]\n",
      "epoch:19 step:18321 [D loss: 0.567648, acc.: 71.09%] [G loss: 0.634699]\n",
      "epoch:19 step:18322 [D loss: 0.493011, acc.: 78.91%] [G loss: 0.762041]\n",
      "epoch:19 step:18323 [D loss: 0.475702, acc.: 74.22%] [G loss: 0.724831]\n",
      "epoch:19 step:18324 [D loss: 0.476388, acc.: 78.12%] [G loss: 0.641020]\n",
      "epoch:19 step:18325 [D loss: 0.489585, acc.: 79.69%] [G loss: 0.672673]\n",
      "epoch:19 step:18326 [D loss: 0.449110, acc.: 78.91%] [G loss: 0.740215]\n",
      "epoch:19 step:18327 [D loss: 0.537912, acc.: 71.09%] [G loss: 0.611673]\n",
      "epoch:19 step:18328 [D loss: 0.563407, acc.: 72.66%] [G loss: 0.744140]\n",
      "epoch:19 step:18329 [D loss: 0.438389, acc.: 85.16%] [G loss: 0.788396]\n",
      "epoch:19 step:18330 [D loss: 0.567741, acc.: 71.09%] [G loss: 0.615105]\n",
      "epoch:19 step:18331 [D loss: 0.661002, acc.: 57.03%] [G loss: 0.472582]\n",
      "epoch:19 step:18332 [D loss: 0.604689, acc.: 64.06%] [G loss: 0.535194]\n",
      "epoch:19 step:18333 [D loss: 0.545209, acc.: 72.66%] [G loss: 0.552655]\n",
      "epoch:19 step:18334 [D loss: 0.532409, acc.: 71.88%] [G loss: 0.610325]\n",
      "epoch:19 step:18335 [D loss: 0.537764, acc.: 68.75%] [G loss: 0.562917]\n",
      "epoch:19 step:18336 [D loss: 0.547636, acc.: 64.84%] [G loss: 0.646957]\n",
      "epoch:19 step:18337 [D loss: 0.481021, acc.: 75.78%] [G loss: 0.753613]\n",
      "epoch:19 step:18338 [D loss: 0.609702, acc.: 60.16%] [G loss: 0.741654]\n",
      "epoch:19 step:18339 [D loss: 0.481213, acc.: 71.88%] [G loss: 0.658016]\n",
      "epoch:19 step:18340 [D loss: 0.602971, acc.: 64.84%] [G loss: 0.576103]\n",
      "epoch:19 step:18341 [D loss: 0.531532, acc.: 73.44%] [G loss: 0.673555]\n",
      "epoch:19 step:18342 [D loss: 0.519512, acc.: 72.66%] [G loss: 0.641810]\n",
      "epoch:19 step:18343 [D loss: 0.516756, acc.: 71.09%] [G loss: 0.626063]\n",
      "epoch:19 step:18344 [D loss: 0.470754, acc.: 77.34%] [G loss: 0.711539]\n",
      "epoch:19 step:18345 [D loss: 0.614641, acc.: 62.50%] [G loss: 0.439417]\n",
      "epoch:19 step:18346 [D loss: 0.584648, acc.: 63.28%] [G loss: 0.580034]\n",
      "epoch:19 step:18347 [D loss: 0.512440, acc.: 75.00%] [G loss: 0.578875]\n",
      "epoch:19 step:18348 [D loss: 0.519606, acc.: 71.09%] [G loss: 0.652440]\n",
      "epoch:19 step:18349 [D loss: 0.518152, acc.: 74.22%] [G loss: 0.537794]\n",
      "epoch:19 step:18350 [D loss: 0.530489, acc.: 70.31%] [G loss: 0.769543]\n",
      "epoch:19 step:18351 [D loss: 0.491326, acc.: 75.00%] [G loss: 0.690901]\n",
      "epoch:19 step:18352 [D loss: 0.503294, acc.: 72.66%] [G loss: 0.682209]\n",
      "epoch:19 step:18353 [D loss: 0.539591, acc.: 71.88%] [G loss: 0.497919]\n",
      "epoch:19 step:18354 [D loss: 0.482325, acc.: 75.78%] [G loss: 0.602930]\n",
      "epoch:19 step:18355 [D loss: 0.510905, acc.: 69.53%] [G loss: 0.632079]\n",
      "epoch:19 step:18356 [D loss: 0.576981, acc.: 66.41%] [G loss: 0.703173]\n",
      "epoch:19 step:18357 [D loss: 0.431163, acc.: 80.47%] [G loss: 0.897510]\n",
      "epoch:19 step:18358 [D loss: 0.469956, acc.: 76.56%] [G loss: 0.909331]\n",
      "epoch:19 step:18359 [D loss: 0.541736, acc.: 72.66%] [G loss: 0.817112]\n",
      "epoch:19 step:18360 [D loss: 0.483919, acc.: 78.12%] [G loss: 0.848348]\n",
      "epoch:19 step:18361 [D loss: 0.495309, acc.: 75.00%] [G loss: 0.787364]\n",
      "epoch:19 step:18362 [D loss: 0.577710, acc.: 66.41%] [G loss: 0.562229]\n",
      "epoch:19 step:18363 [D loss: 0.543641, acc.: 69.53%] [G loss: 0.578133]\n",
      "epoch:19 step:18364 [D loss: 0.542256, acc.: 71.88%] [G loss: 0.744770]\n",
      "epoch:19 step:18365 [D loss: 0.563455, acc.: 71.09%] [G loss: 0.623016]\n",
      "epoch:19 step:18366 [D loss: 0.506121, acc.: 72.66%] [G loss: 0.627378]\n",
      "epoch:19 step:18367 [D loss: 0.445531, acc.: 79.69%] [G loss: 0.752323]\n",
      "epoch:19 step:18368 [D loss: 0.495283, acc.: 75.00%] [G loss: 0.765988]\n",
      "epoch:19 step:18369 [D loss: 0.618572, acc.: 69.53%] [G loss: 0.617716]\n",
      "epoch:19 step:18370 [D loss: 0.528222, acc.: 71.09%] [G loss: 0.730179]\n",
      "epoch:19 step:18371 [D loss: 0.498701, acc.: 74.22%] [G loss: 0.811245]\n",
      "epoch:19 step:18372 [D loss: 0.510515, acc.: 77.34%] [G loss: 0.820981]\n",
      "epoch:19 step:18373 [D loss: 0.524728, acc.: 74.22%] [G loss: 0.558417]\n",
      "epoch:19 step:18374 [D loss: 0.540780, acc.: 69.53%] [G loss: 0.559865]\n",
      "epoch:19 step:18375 [D loss: 0.567899, acc.: 71.09%] [G loss: 0.595035]\n",
      "epoch:19 step:18376 [D loss: 0.547691, acc.: 71.09%] [G loss: 0.645774]\n",
      "epoch:19 step:18377 [D loss: 0.494064, acc.: 76.56%] [G loss: 0.768301]\n",
      "epoch:19 step:18378 [D loss: 0.436451, acc.: 78.91%] [G loss: 0.819018]\n",
      "epoch:19 step:18379 [D loss: 0.588422, acc.: 67.97%] [G loss: 0.728173]\n",
      "epoch:19 step:18380 [D loss: 0.600287, acc.: 66.41%] [G loss: 0.690648]\n",
      "epoch:19 step:18381 [D loss: 0.544591, acc.: 71.09%] [G loss: 0.579886]\n",
      "epoch:19 step:18382 [D loss: 0.525459, acc.: 66.41%] [G loss: 0.588088]\n",
      "epoch:19 step:18383 [D loss: 0.541025, acc.: 72.66%] [G loss: 0.604719]\n",
      "epoch:19 step:18384 [D loss: 0.510400, acc.: 74.22%] [G loss: 0.700475]\n",
      "epoch:19 step:18385 [D loss: 0.461125, acc.: 80.47%] [G loss: 0.740368]\n",
      "epoch:19 step:18386 [D loss: 0.507142, acc.: 75.00%] [G loss: 0.713016]\n",
      "epoch:19 step:18387 [D loss: 0.582256, acc.: 65.62%] [G loss: 0.763247]\n",
      "epoch:19 step:18388 [D loss: 0.548132, acc.: 66.41%] [G loss: 0.681553]\n",
      "epoch:19 step:18389 [D loss: 0.562806, acc.: 65.62%] [G loss: 0.573055]\n",
      "epoch:19 step:18390 [D loss: 0.556030, acc.: 71.88%] [G loss: 0.580381]\n",
      "epoch:19 step:18391 [D loss: 0.585652, acc.: 65.62%] [G loss: 0.515519]\n",
      "epoch:19 step:18392 [D loss: 0.498543, acc.: 72.66%] [G loss: 0.672218]\n",
      "epoch:19 step:18393 [D loss: 0.484163, acc.: 77.34%] [G loss: 0.883516]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:19 step:18394 [D loss: 0.630853, acc.: 64.84%] [G loss: 0.695732]\n",
      "epoch:19 step:18395 [D loss: 0.465180, acc.: 79.69%] [G loss: 0.807584]\n",
      "epoch:19 step:18396 [D loss: 0.520981, acc.: 71.09%] [G loss: 0.672031]\n",
      "epoch:19 step:18397 [D loss: 0.539352, acc.: 71.88%] [G loss: 0.628697]\n",
      "epoch:19 step:18398 [D loss: 0.571684, acc.: 64.06%] [G loss: 0.547095]\n",
      "epoch:19 step:18399 [D loss: 0.580630, acc.: 67.97%] [G loss: 0.526419]\n",
      "epoch:19 step:18400 [D loss: 0.524296, acc.: 71.09%] [G loss: 0.750529]\n",
      "epoch:19 step:18401 [D loss: 0.517143, acc.: 71.09%] [G loss: 0.823595]\n",
      "epoch:19 step:18402 [D loss: 0.516251, acc.: 70.31%] [G loss: 0.721809]\n",
      "epoch:19 step:18403 [D loss: 0.592756, acc.: 67.97%] [G loss: 0.652913]\n",
      "epoch:19 step:18404 [D loss: 0.481366, acc.: 78.12%] [G loss: 0.888568]\n",
      "epoch:19 step:18405 [D loss: 0.444083, acc.: 81.25%] [G loss: 0.761063]\n",
      "epoch:19 step:18406 [D loss: 0.484041, acc.: 78.91%] [G loss: 0.797227]\n",
      "epoch:19 step:18407 [D loss: 0.553386, acc.: 68.75%] [G loss: 0.804615]\n",
      "epoch:19 step:18408 [D loss: 0.468436, acc.: 76.56%] [G loss: 0.765250]\n",
      "epoch:19 step:18409 [D loss: 0.586029, acc.: 70.31%] [G loss: 0.645620]\n",
      "epoch:19 step:18410 [D loss: 0.533707, acc.: 69.53%] [G loss: 0.591317]\n",
      "epoch:19 step:18411 [D loss: 0.499333, acc.: 75.78%] [G loss: 0.673520]\n",
      "epoch:19 step:18412 [D loss: 0.516059, acc.: 73.44%] [G loss: 0.562151]\n",
      "epoch:19 step:18413 [D loss: 0.552280, acc.: 73.44%] [G loss: 0.495519]\n",
      "epoch:19 step:18414 [D loss: 0.501450, acc.: 75.00%] [G loss: 0.580438]\n",
      "epoch:19 step:18415 [D loss: 0.547111, acc.: 69.53%] [G loss: 0.469655]\n",
      "epoch:19 step:18416 [D loss: 0.446892, acc.: 79.69%] [G loss: 0.616821]\n",
      "epoch:19 step:18417 [D loss: 0.541716, acc.: 70.31%] [G loss: 0.571880]\n",
      "epoch:19 step:18418 [D loss: 0.567435, acc.: 68.75%] [G loss: 0.762055]\n",
      "epoch:19 step:18419 [D loss: 0.619680, acc.: 62.50%] [G loss: 0.581277]\n",
      "epoch:19 step:18420 [D loss: 0.492788, acc.: 79.69%] [G loss: 0.664109]\n",
      "epoch:19 step:18421 [D loss: 0.573629, acc.: 66.41%] [G loss: 0.649331]\n",
      "epoch:19 step:18422 [D loss: 0.545331, acc.: 68.75%] [G loss: 0.710102]\n",
      "epoch:19 step:18423 [D loss: 0.527399, acc.: 71.09%] [G loss: 0.646821]\n",
      "epoch:19 step:18424 [D loss: 0.537494, acc.: 73.44%] [G loss: 0.578687]\n",
      "epoch:19 step:18425 [D loss: 0.535017, acc.: 73.44%] [G loss: 0.718989]\n",
      "epoch:19 step:18426 [D loss: 0.549668, acc.: 75.78%] [G loss: 0.589949]\n",
      "epoch:19 step:18427 [D loss: 0.438245, acc.: 79.69%] [G loss: 0.833215]\n",
      "epoch:19 step:18428 [D loss: 0.626980, acc.: 67.19%] [G loss: 0.607670]\n",
      "epoch:19 step:18429 [D loss: 0.566289, acc.: 66.41%] [G loss: 0.603316]\n",
      "epoch:19 step:18430 [D loss: 0.536161, acc.: 71.09%] [G loss: 0.504949]\n",
      "epoch:19 step:18431 [D loss: 0.563532, acc.: 69.53%] [G loss: 0.636444]\n",
      "epoch:19 step:18432 [D loss: 0.480659, acc.: 74.22%] [G loss: 0.584600]\n",
      "epoch:19 step:18433 [D loss: 0.505048, acc.: 76.56%] [G loss: 0.643867]\n",
      "epoch:19 step:18434 [D loss: 0.489805, acc.: 78.91%] [G loss: 0.576403]\n",
      "epoch:19 step:18435 [D loss: 0.514356, acc.: 76.56%] [G loss: 0.718808]\n",
      "epoch:19 step:18436 [D loss: 0.501923, acc.: 72.66%] [G loss: 0.778203]\n",
      "epoch:19 step:18437 [D loss: 0.455095, acc.: 80.47%] [G loss: 0.761730]\n",
      "epoch:19 step:18438 [D loss: 0.505154, acc.: 71.09%] [G loss: 0.877398]\n",
      "epoch:19 step:18439 [D loss: 0.588428, acc.: 67.19%] [G loss: 0.649402]\n",
      "epoch:19 step:18440 [D loss: 0.500655, acc.: 71.09%] [G loss: 0.705934]\n",
      "epoch:19 step:18441 [D loss: 0.481029, acc.: 79.69%] [G loss: 0.552812]\n",
      "epoch:19 step:18442 [D loss: 0.536414, acc.: 72.66%] [G loss: 0.738807]\n",
      "epoch:19 step:18443 [D loss: 0.536478, acc.: 73.44%] [G loss: 0.693749]\n",
      "epoch:19 step:18444 [D loss: 0.503139, acc.: 77.34%] [G loss: 0.936203]\n",
      "epoch:19 step:18445 [D loss: 0.504919, acc.: 76.56%] [G loss: 0.864530]\n",
      "epoch:19 step:18446 [D loss: 0.532997, acc.: 69.53%] [G loss: 0.790598]\n",
      "epoch:19 step:18447 [D loss: 0.573500, acc.: 64.84%] [G loss: 0.824118]\n",
      "epoch:19 step:18448 [D loss: 0.473311, acc.: 78.12%] [G loss: 0.748578]\n",
      "epoch:19 step:18449 [D loss: 0.506940, acc.: 75.78%] [G loss: 0.782850]\n",
      "epoch:19 step:18450 [D loss: 0.440785, acc.: 80.47%] [G loss: 0.692559]\n",
      "epoch:19 step:18451 [D loss: 0.386885, acc.: 84.38%] [G loss: 0.929800]\n",
      "epoch:19 step:18452 [D loss: 0.417419, acc.: 79.69%] [G loss: 1.042191]\n",
      "epoch:19 step:18453 [D loss: 0.480396, acc.: 75.78%] [G loss: 1.025846]\n",
      "epoch:19 step:18454 [D loss: 0.457708, acc.: 77.34%] [G loss: 0.842305]\n",
      "epoch:19 step:18455 [D loss: 0.598457, acc.: 67.19%] [G loss: 0.590444]\n",
      "epoch:19 step:18456 [D loss: 0.517063, acc.: 74.22%] [G loss: 0.839854]\n",
      "epoch:19 step:18457 [D loss: 0.449698, acc.: 78.91%] [G loss: 0.800178]\n",
      "epoch:19 step:18458 [D loss: 0.595466, acc.: 69.53%] [G loss: 0.792847]\n",
      "epoch:19 step:18459 [D loss: 0.534250, acc.: 70.31%] [G loss: 0.712237]\n",
      "epoch:19 step:18460 [D loss: 0.489595, acc.: 71.09%] [G loss: 0.809334]\n",
      "epoch:19 step:18461 [D loss: 0.569823, acc.: 66.41%] [G loss: 0.587633]\n",
      "epoch:19 step:18462 [D loss: 0.515782, acc.: 70.31%] [G loss: 0.728538]\n",
      "epoch:19 step:18463 [D loss: 0.499054, acc.: 75.78%] [G loss: 0.773889]\n",
      "epoch:19 step:18464 [D loss: 0.549981, acc.: 69.53%] [G loss: 0.675135]\n",
      "epoch:19 step:18465 [D loss: 0.510370, acc.: 73.44%] [G loss: 0.588047]\n",
      "epoch:19 step:18466 [D loss: 0.533894, acc.: 67.19%] [G loss: 0.767793]\n",
      "epoch:19 step:18467 [D loss: 0.577758, acc.: 67.97%] [G loss: 0.684321]\n",
      "epoch:19 step:18468 [D loss: 0.553314, acc.: 70.31%] [G loss: 0.731177]\n",
      "epoch:19 step:18469 [D loss: 0.484626, acc.: 78.12%] [G loss: 0.662697]\n",
      "epoch:19 step:18470 [D loss: 0.515043, acc.: 73.44%] [G loss: 0.798690]\n",
      "epoch:19 step:18471 [D loss: 0.540916, acc.: 70.31%] [G loss: 0.752569]\n",
      "epoch:19 step:18472 [D loss: 0.523423, acc.: 70.31%] [G loss: 0.702544]\n",
      "epoch:19 step:18473 [D loss: 0.562617, acc.: 65.62%] [G loss: 0.528302]\n",
      "epoch:19 step:18474 [D loss: 0.550437, acc.: 67.19%] [G loss: 0.546774]\n",
      "epoch:19 step:18475 [D loss: 0.530688, acc.: 74.22%] [G loss: 0.679974]\n",
      "epoch:19 step:18476 [D loss: 0.602329, acc.: 67.19%] [G loss: 0.534354]\n",
      "epoch:19 step:18477 [D loss: 0.525708, acc.: 71.09%] [G loss: 0.662011]\n",
      "epoch:19 step:18478 [D loss: 0.595593, acc.: 62.50%] [G loss: 0.624655]\n",
      "epoch:19 step:18479 [D loss: 0.533304, acc.: 68.75%] [G loss: 0.711220]\n",
      "epoch:19 step:18480 [D loss: 0.498171, acc.: 78.12%] [G loss: 0.650396]\n",
      "epoch:19 step:18481 [D loss: 0.612439, acc.: 64.84%] [G loss: 0.670858]\n",
      "epoch:19 step:18482 [D loss: 0.487352, acc.: 78.12%] [G loss: 0.692701]\n",
      "epoch:19 step:18483 [D loss: 0.547274, acc.: 71.09%] [G loss: 0.628824]\n",
      "epoch:19 step:18484 [D loss: 0.449251, acc.: 79.69%] [G loss: 0.800742]\n",
      "epoch:19 step:18485 [D loss: 0.522218, acc.: 72.66%] [G loss: 0.589257]\n",
      "epoch:19 step:18486 [D loss: 0.523717, acc.: 74.22%] [G loss: 0.816528]\n",
      "epoch:19 step:18487 [D loss: 0.630621, acc.: 60.94%] [G loss: 0.577324]\n",
      "epoch:19 step:18488 [D loss: 0.529557, acc.: 72.66%] [G loss: 0.648262]\n",
      "epoch:19 step:18489 [D loss: 0.537001, acc.: 68.75%] [G loss: 0.624876]\n",
      "epoch:19 step:18490 [D loss: 0.565275, acc.: 70.31%] [G loss: 0.499565]\n",
      "epoch:19 step:18491 [D loss: 0.443264, acc.: 78.12%] [G loss: 0.638125]\n",
      "epoch:19 step:18492 [D loss: 0.567073, acc.: 65.62%] [G loss: 0.663619]\n",
      "epoch:19 step:18493 [D loss: 0.521774, acc.: 71.88%] [G loss: 0.635799]\n",
      "epoch:19 step:18494 [D loss: 0.505909, acc.: 76.56%] [G loss: 0.796680]\n",
      "epoch:19 step:18495 [D loss: 0.513012, acc.: 73.44%] [G loss: 0.722816]\n",
      "epoch:19 step:18496 [D loss: 0.470858, acc.: 72.66%] [G loss: 0.978774]\n",
      "epoch:19 step:18497 [D loss: 0.490738, acc.: 75.78%] [G loss: 0.862548]\n",
      "epoch:19 step:18498 [D loss: 0.492610, acc.: 79.69%] [G loss: 0.857672]\n",
      "epoch:19 step:18499 [D loss: 0.611303, acc.: 65.62%] [G loss: 0.729273]\n",
      "epoch:19 step:18500 [D loss: 0.616925, acc.: 63.28%] [G loss: 0.586677]\n",
      "epoch:19 step:18501 [D loss: 0.550392, acc.: 70.31%] [G loss: 0.459432]\n",
      "epoch:19 step:18502 [D loss: 0.503438, acc.: 71.88%] [G loss: 0.609348]\n",
      "epoch:19 step:18503 [D loss: 0.530599, acc.: 70.31%] [G loss: 0.809863]\n",
      "epoch:19 step:18504 [D loss: 0.458889, acc.: 78.91%] [G loss: 0.803611]\n",
      "epoch:19 step:18505 [D loss: 0.602252, acc.: 64.06%] [G loss: 0.701222]\n",
      "epoch:19 step:18506 [D loss: 0.587029, acc.: 66.41%] [G loss: 0.788670]\n",
      "epoch:19 step:18507 [D loss: 0.624913, acc.: 64.06%] [G loss: 0.523685]\n",
      "epoch:19 step:18508 [D loss: 0.479454, acc.: 77.34%] [G loss: 0.811772]\n",
      "epoch:19 step:18509 [D loss: 0.508120, acc.: 75.00%] [G loss: 0.537541]\n",
      "epoch:19 step:18510 [D loss: 0.529899, acc.: 67.19%] [G loss: 0.637233]\n",
      "epoch:19 step:18511 [D loss: 0.453029, acc.: 77.34%] [G loss: 0.796121]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:19 step:18512 [D loss: 0.504178, acc.: 75.00%] [G loss: 0.859973]\n",
      "epoch:19 step:18513 [D loss: 0.545956, acc.: 65.62%] [G loss: 0.594505]\n",
      "epoch:19 step:18514 [D loss: 0.550800, acc.: 74.22%] [G loss: 0.669569]\n",
      "epoch:19 step:18515 [D loss: 0.522431, acc.: 70.31%] [G loss: 0.566418]\n",
      "epoch:19 step:18516 [D loss: 0.521365, acc.: 75.78%] [G loss: 0.627665]\n",
      "epoch:19 step:18517 [D loss: 0.525868, acc.: 71.09%] [G loss: 0.607955]\n",
      "epoch:19 step:18518 [D loss: 0.546040, acc.: 72.66%] [G loss: 0.811532]\n",
      "epoch:19 step:18519 [D loss: 0.609995, acc.: 65.62%] [G loss: 0.617736]\n",
      "epoch:19 step:18520 [D loss: 0.578449, acc.: 64.84%] [G loss: 0.651623]\n",
      "epoch:19 step:18521 [D loss: 0.506019, acc.: 73.44%] [G loss: 0.666676]\n",
      "epoch:19 step:18522 [D loss: 0.491878, acc.: 77.34%] [G loss: 0.999194]\n",
      "epoch:19 step:18523 [D loss: 0.592405, acc.: 68.75%] [G loss: 0.739815]\n",
      "epoch:19 step:18524 [D loss: 0.558330, acc.: 71.09%] [G loss: 0.642114]\n",
      "epoch:19 step:18525 [D loss: 0.546009, acc.: 70.31%] [G loss: 0.444680]\n",
      "epoch:19 step:18526 [D loss: 0.559759, acc.: 69.53%] [G loss: 0.683711]\n",
      "epoch:19 step:18527 [D loss: 0.579426, acc.: 69.53%] [G loss: 0.739415]\n",
      "epoch:19 step:18528 [D loss: 0.485119, acc.: 77.34%] [G loss: 0.785762]\n",
      "epoch:19 step:18529 [D loss: 0.484646, acc.: 75.78%] [G loss: 0.693255]\n",
      "epoch:19 step:18530 [D loss: 0.527117, acc.: 69.53%] [G loss: 0.744606]\n",
      "epoch:19 step:18531 [D loss: 0.526336, acc.: 71.88%] [G loss: 0.533530]\n",
      "epoch:19 step:18532 [D loss: 0.572413, acc.: 67.19%] [G loss: 0.676210]\n",
      "epoch:19 step:18533 [D loss: 0.506432, acc.: 71.88%] [G loss: 0.598203]\n",
      "epoch:19 step:18534 [D loss: 0.616946, acc.: 62.50%] [G loss: 0.537704]\n",
      "epoch:19 step:18535 [D loss: 0.505229, acc.: 74.22%] [G loss: 0.660283]\n",
      "epoch:19 step:18536 [D loss: 0.562642, acc.: 67.19%] [G loss: 0.612970]\n",
      "epoch:19 step:18537 [D loss: 0.490411, acc.: 72.66%] [G loss: 0.628757]\n",
      "epoch:19 step:18538 [D loss: 0.559574, acc.: 67.97%] [G loss: 0.671916]\n",
      "epoch:19 step:18539 [D loss: 0.453399, acc.: 76.56%] [G loss: 0.721377]\n",
      "epoch:19 step:18540 [D loss: 0.534595, acc.: 73.44%] [G loss: 0.640292]\n",
      "epoch:19 step:18541 [D loss: 0.505029, acc.: 71.88%] [G loss: 0.781125]\n",
      "epoch:19 step:18542 [D loss: 0.511781, acc.: 74.22%] [G loss: 0.683992]\n",
      "epoch:19 step:18543 [D loss: 0.588201, acc.: 66.41%] [G loss: 0.595335]\n",
      "epoch:19 step:18544 [D loss: 0.469623, acc.: 75.78%] [G loss: 0.569308]\n",
      "epoch:19 step:18545 [D loss: 0.463299, acc.: 75.78%] [G loss: 0.777837]\n",
      "epoch:19 step:18546 [D loss: 0.517696, acc.: 74.22%] [G loss: 0.749209]\n",
      "epoch:19 step:18547 [D loss: 0.523262, acc.: 75.00%] [G loss: 0.856021]\n",
      "epoch:19 step:18548 [D loss: 0.623320, acc.: 66.41%] [G loss: 0.733625]\n",
      "epoch:19 step:18549 [D loss: 0.410945, acc.: 82.81%] [G loss: 0.848059]\n",
      "epoch:19 step:18550 [D loss: 0.464611, acc.: 80.47%] [G loss: 0.956347]\n",
      "epoch:19 step:18551 [D loss: 0.534692, acc.: 73.44%] [G loss: 0.795388]\n",
      "epoch:19 step:18552 [D loss: 0.499387, acc.: 77.34%] [G loss: 0.698570]\n",
      "epoch:19 step:18553 [D loss: 0.463502, acc.: 77.34%] [G loss: 0.692150]\n",
      "epoch:19 step:18554 [D loss: 0.500226, acc.: 72.66%] [G loss: 0.705916]\n",
      "epoch:19 step:18555 [D loss: 0.569273, acc.: 70.31%] [G loss: 0.626995]\n",
      "epoch:19 step:18556 [D loss: 0.498945, acc.: 78.12%] [G loss: 0.597638]\n",
      "epoch:19 step:18557 [D loss: 0.552703, acc.: 67.97%] [G loss: 0.652712]\n",
      "epoch:19 step:18558 [D loss: 0.514863, acc.: 69.53%] [G loss: 0.742720]\n",
      "epoch:19 step:18559 [D loss: 0.526678, acc.: 66.41%] [G loss: 0.582720]\n",
      "epoch:19 step:18560 [D loss: 0.555332, acc.: 69.53%] [G loss: 0.661456]\n",
      "epoch:19 step:18561 [D loss: 0.560491, acc.: 71.88%] [G loss: 0.579434]\n",
      "epoch:19 step:18562 [D loss: 0.575028, acc.: 70.31%] [G loss: 0.615927]\n",
      "epoch:19 step:18563 [D loss: 0.501441, acc.: 75.78%] [G loss: 0.703068]\n",
      "epoch:19 step:18564 [D loss: 0.560155, acc.: 69.53%] [G loss: 0.669918]\n",
      "epoch:19 step:18565 [D loss: 0.572782, acc.: 65.62%] [G loss: 0.552614]\n",
      "epoch:19 step:18566 [D loss: 0.528157, acc.: 70.31%] [G loss: 0.611291]\n",
      "epoch:19 step:18567 [D loss: 0.515927, acc.: 67.97%] [G loss: 0.690333]\n",
      "epoch:19 step:18568 [D loss: 0.614731, acc.: 61.72%] [G loss: 0.564135]\n",
      "epoch:19 step:18569 [D loss: 0.593316, acc.: 64.06%] [G loss: 0.609700]\n",
      "epoch:19 step:18570 [D loss: 0.514625, acc.: 71.09%] [G loss: 0.581262]\n",
      "epoch:19 step:18571 [D loss: 0.546556, acc.: 69.53%] [G loss: 0.823829]\n",
      "epoch:19 step:18572 [D loss: 0.502174, acc.: 74.22%] [G loss: 0.976888]\n",
      "epoch:19 step:18573 [D loss: 0.492727, acc.: 70.31%] [G loss: 0.943745]\n",
      "epoch:19 step:18574 [D loss: 0.534015, acc.: 74.22%] [G loss: 0.787802]\n",
      "epoch:19 step:18575 [D loss: 0.551578, acc.: 71.09%] [G loss: 0.834625]\n",
      "epoch:19 step:18576 [D loss: 0.566099, acc.: 68.75%] [G loss: 0.937800]\n",
      "epoch:19 step:18577 [D loss: 0.592914, acc.: 69.53%] [G loss: 0.625205]\n",
      "epoch:19 step:18578 [D loss: 0.517717, acc.: 71.09%] [G loss: 0.766388]\n",
      "epoch:19 step:18579 [D loss: 0.565367, acc.: 68.75%] [G loss: 0.726844]\n",
      "epoch:19 step:18580 [D loss: 0.574394, acc.: 70.31%] [G loss: 0.838975]\n",
      "epoch:19 step:18581 [D loss: 0.530552, acc.: 72.66%] [G loss: 0.660850]\n",
      "epoch:19 step:18582 [D loss: 0.559571, acc.: 70.31%] [G loss: 0.641256]\n",
      "epoch:19 step:18583 [D loss: 0.487299, acc.: 75.00%] [G loss: 0.623061]\n",
      "epoch:19 step:18584 [D loss: 0.482427, acc.: 77.34%] [G loss: 0.999727]\n",
      "epoch:19 step:18585 [D loss: 0.498697, acc.: 72.66%] [G loss: 0.985683]\n",
      "epoch:19 step:18586 [D loss: 0.515921, acc.: 69.53%] [G loss: 1.109070]\n",
      "epoch:19 step:18587 [D loss: 0.617941, acc.: 64.06%] [G loss: 0.749604]\n",
      "epoch:19 step:18588 [D loss: 0.533360, acc.: 77.34%] [G loss: 0.605171]\n",
      "epoch:19 step:18589 [D loss: 0.521140, acc.: 73.44%] [G loss: 0.548886]\n",
      "epoch:19 step:18590 [D loss: 0.599199, acc.: 65.62%] [G loss: 0.684665]\n",
      "epoch:19 step:18591 [D loss: 0.660437, acc.: 59.38%] [G loss: 0.497156]\n",
      "epoch:19 step:18592 [D loss: 0.501215, acc.: 73.44%] [G loss: 0.590914]\n",
      "epoch:19 step:18593 [D loss: 0.559881, acc.: 71.88%] [G loss: 0.565771]\n",
      "epoch:19 step:18594 [D loss: 0.536555, acc.: 73.44%] [G loss: 0.667427]\n",
      "epoch:19 step:18595 [D loss: 0.486880, acc.: 73.44%] [G loss: 0.727578]\n",
      "epoch:19 step:18596 [D loss: 0.558520, acc.: 67.19%] [G loss: 0.661695]\n",
      "epoch:19 step:18597 [D loss: 0.594533, acc.: 65.62%] [G loss: 0.697475]\n",
      "epoch:19 step:18598 [D loss: 0.508903, acc.: 72.66%] [G loss: 0.733933]\n",
      "epoch:19 step:18599 [D loss: 0.505730, acc.: 78.12%] [G loss: 0.636297]\n",
      "epoch:19 step:18600 [D loss: 0.562642, acc.: 67.97%] [G loss: 0.732942]\n",
      "epoch:19 step:18601 [D loss: 0.565853, acc.: 66.41%] [G loss: 0.679651]\n",
      "epoch:19 step:18602 [D loss: 0.579492, acc.: 65.62%] [G loss: 0.664008]\n",
      "epoch:19 step:18603 [D loss: 0.585776, acc.: 67.97%] [G loss: 0.582648]\n",
      "epoch:19 step:18604 [D loss: 0.452816, acc.: 79.69%] [G loss: 0.568953]\n",
      "epoch:19 step:18605 [D loss: 0.484535, acc.: 73.44%] [G loss: 0.763112]\n",
      "epoch:19 step:18606 [D loss: 0.458523, acc.: 82.03%] [G loss: 0.825002]\n",
      "epoch:19 step:18607 [D loss: 0.569277, acc.: 71.09%] [G loss: 0.533412]\n",
      "epoch:19 step:18608 [D loss: 0.515670, acc.: 72.66%] [G loss: 0.577598]\n",
      "epoch:19 step:18609 [D loss: 0.592417, acc.: 68.75%] [G loss: 0.625641]\n",
      "epoch:19 step:18610 [D loss: 0.512057, acc.: 71.88%] [G loss: 0.592801]\n",
      "epoch:19 step:18611 [D loss: 0.508992, acc.: 73.44%] [G loss: 0.658341]\n",
      "epoch:19 step:18612 [D loss: 0.513160, acc.: 75.78%] [G loss: 0.621464]\n",
      "epoch:19 step:18613 [D loss: 0.488267, acc.: 75.00%] [G loss: 0.808104]\n",
      "epoch:19 step:18614 [D loss: 0.547575, acc.: 67.97%] [G loss: 0.648429]\n",
      "epoch:19 step:18615 [D loss: 0.632581, acc.: 63.28%] [G loss: 0.651570]\n",
      "epoch:19 step:18616 [D loss: 0.502175, acc.: 75.00%] [G loss: 0.657609]\n",
      "epoch:19 step:18617 [D loss: 0.452703, acc.: 75.78%] [G loss: 0.720494]\n",
      "epoch:19 step:18618 [D loss: 0.467204, acc.: 76.56%] [G loss: 0.899007]\n",
      "epoch:19 step:18619 [D loss: 0.511457, acc.: 75.78%] [G loss: 0.830647]\n",
      "epoch:19 step:18620 [D loss: 0.555888, acc.: 71.88%] [G loss: 0.749780]\n",
      "epoch:19 step:18621 [D loss: 0.582268, acc.: 67.19%] [G loss: 0.658658]\n",
      "epoch:19 step:18622 [D loss: 0.479921, acc.: 74.22%] [G loss: 0.702448]\n",
      "epoch:19 step:18623 [D loss: 0.637693, acc.: 67.19%] [G loss: 0.454429]\n",
      "epoch:19 step:18624 [D loss: 0.531388, acc.: 68.75%] [G loss: 0.648456]\n",
      "epoch:19 step:18625 [D loss: 0.546161, acc.: 67.97%] [G loss: 0.528737]\n",
      "epoch:19 step:18626 [D loss: 0.438823, acc.: 78.91%] [G loss: 0.572182]\n",
      "epoch:19 step:18627 [D loss: 0.613367, acc.: 68.75%] [G loss: 0.659555]\n",
      "epoch:19 step:18628 [D loss: 0.505138, acc.: 74.22%] [G loss: 0.653801]\n",
      "epoch:19 step:18629 [D loss: 0.527982, acc.: 71.88%] [G loss: 0.576149]\n",
      "epoch:19 step:18630 [D loss: 0.556737, acc.: 67.19%] [G loss: 0.521402]\n",
      "epoch:19 step:18631 [D loss: 0.621067, acc.: 62.50%] [G loss: 0.435552]\n",
      "epoch:19 step:18632 [D loss: 0.567565, acc.: 63.28%] [G loss: 0.582191]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:19 step:18633 [D loss: 0.555285, acc.: 67.97%] [G loss: 0.758982]\n",
      "epoch:19 step:18634 [D loss: 0.604183, acc.: 61.72%] [G loss: 0.445564]\n",
      "epoch:19 step:18635 [D loss: 0.511416, acc.: 71.09%] [G loss: 0.647975]\n",
      "epoch:19 step:18636 [D loss: 0.497540, acc.: 77.34%] [G loss: 0.602979]\n",
      "epoch:19 step:18637 [D loss: 0.541853, acc.: 67.97%] [G loss: 0.519413]\n",
      "epoch:19 step:18638 [D loss: 0.547809, acc.: 75.00%] [G loss: 0.612721]\n",
      "epoch:19 step:18639 [D loss: 0.545935, acc.: 69.53%] [G loss: 0.547113]\n",
      "epoch:19 step:18640 [D loss: 0.551697, acc.: 71.09%] [G loss: 0.546320]\n",
      "epoch:19 step:18641 [D loss: 0.535791, acc.: 69.53%] [G loss: 0.508193]\n",
      "epoch:19 step:18642 [D loss: 0.579797, acc.: 66.41%] [G loss: 0.643063]\n",
      "epoch:19 step:18643 [D loss: 0.559656, acc.: 70.31%] [G loss: 0.611924]\n",
      "epoch:19 step:18644 [D loss: 0.530469, acc.: 69.53%] [G loss: 0.432002]\n",
      "epoch:19 step:18645 [D loss: 0.515775, acc.: 69.53%] [G loss: 0.588145]\n",
      "epoch:19 step:18646 [D loss: 0.485791, acc.: 76.56%] [G loss: 0.598397]\n",
      "epoch:19 step:18647 [D loss: 0.571933, acc.: 65.62%] [G loss: 0.607728]\n",
      "epoch:19 step:18648 [D loss: 0.520998, acc.: 72.66%] [G loss: 0.651856]\n",
      "epoch:19 step:18649 [D loss: 0.561183, acc.: 69.53%] [G loss: 0.546806]\n",
      "epoch:19 step:18650 [D loss: 0.620114, acc.: 60.16%] [G loss: 0.511071]\n",
      "epoch:19 step:18651 [D loss: 0.522316, acc.: 71.88%] [G loss: 0.445959]\n",
      "epoch:19 step:18652 [D loss: 0.536310, acc.: 72.66%] [G loss: 0.551911]\n",
      "epoch:19 step:18653 [D loss: 0.558993, acc.: 68.75%] [G loss: 0.591793]\n",
      "epoch:19 step:18654 [D loss: 0.550707, acc.: 67.97%] [G loss: 0.559753]\n",
      "epoch:19 step:18655 [D loss: 0.489509, acc.: 75.00%] [G loss: 0.682556]\n",
      "epoch:19 step:18656 [D loss: 0.544748, acc.: 69.53%] [G loss: 0.742154]\n",
      "epoch:19 step:18657 [D loss: 0.477867, acc.: 72.66%] [G loss: 0.943633]\n",
      "epoch:19 step:18658 [D loss: 0.525511, acc.: 75.78%] [G loss: 0.634233]\n",
      "epoch:19 step:18659 [D loss: 0.594654, acc.: 67.19%] [G loss: 0.531867]\n",
      "epoch:19 step:18660 [D loss: 0.469870, acc.: 72.66%] [G loss: 0.844733]\n",
      "epoch:19 step:18661 [D loss: 0.599008, acc.: 67.19%] [G loss: 0.585764]\n",
      "epoch:19 step:18662 [D loss: 0.499805, acc.: 71.88%] [G loss: 0.634225]\n",
      "epoch:19 step:18663 [D loss: 0.454921, acc.: 79.69%] [G loss: 0.765040]\n",
      "epoch:19 step:18664 [D loss: 0.614191, acc.: 66.41%] [G loss: 0.534252]\n",
      "epoch:19 step:18665 [D loss: 0.544645, acc.: 66.41%] [G loss: 0.503533]\n",
      "epoch:19 step:18666 [D loss: 0.560750, acc.: 67.19%] [G loss: 0.442249]\n",
      "epoch:19 step:18667 [D loss: 0.558802, acc.: 67.19%] [G loss: 0.594799]\n",
      "epoch:19 step:18668 [D loss: 0.582834, acc.: 64.06%] [G loss: 0.531866]\n",
      "epoch:19 step:18669 [D loss: 0.493567, acc.: 75.78%] [G loss: 0.705279]\n",
      "epoch:19 step:18670 [D loss: 0.670940, acc.: 53.91%] [G loss: 0.589509]\n",
      "epoch:19 step:18671 [D loss: 0.514188, acc.: 72.66%] [G loss: 0.621830]\n",
      "epoch:19 step:18672 [D loss: 0.549969, acc.: 64.06%] [G loss: 0.632220]\n",
      "epoch:19 step:18673 [D loss: 0.523340, acc.: 68.75%] [G loss: 0.497945]\n",
      "epoch:19 step:18674 [D loss: 0.469516, acc.: 74.22%] [G loss: 0.721747]\n",
      "epoch:19 step:18675 [D loss: 0.516492, acc.: 69.53%] [G loss: 0.684871]\n",
      "epoch:19 step:18676 [D loss: 0.558254, acc.: 75.00%] [G loss: 0.612013]\n",
      "epoch:19 step:18677 [D loss: 0.512752, acc.: 73.44%] [G loss: 0.658107]\n",
      "epoch:19 step:18678 [D loss: 0.482920, acc.: 75.00%] [G loss: 0.616950]\n",
      "epoch:19 step:18679 [D loss: 0.507694, acc.: 67.97%] [G loss: 0.691875]\n",
      "epoch:19 step:18680 [D loss: 0.600681, acc.: 67.19%] [G loss: 0.570711]\n",
      "epoch:19 step:18681 [D loss: 0.512742, acc.: 78.91%] [G loss: 0.590403]\n",
      "epoch:19 step:18682 [D loss: 0.551329, acc.: 73.44%] [G loss: 0.581712]\n",
      "epoch:19 step:18683 [D loss: 0.618576, acc.: 60.16%] [G loss: 0.486782]\n",
      "epoch:19 step:18684 [D loss: 0.583986, acc.: 62.50%] [G loss: 0.388635]\n",
      "epoch:19 step:18685 [D loss: 0.565784, acc.: 73.44%] [G loss: 0.505981]\n",
      "epoch:19 step:18686 [D loss: 0.573404, acc.: 66.41%] [G loss: 0.552122]\n",
      "epoch:19 step:18687 [D loss: 0.448430, acc.: 82.03%] [G loss: 0.603719]\n",
      "epoch:19 step:18688 [D loss: 0.506913, acc.: 76.56%] [G loss: 0.902694]\n",
      "epoch:19 step:18689 [D loss: 0.493308, acc.: 73.44%] [G loss: 0.899919]\n",
      "epoch:19 step:18690 [D loss: 0.564651, acc.: 72.66%] [G loss: 0.702609]\n",
      "epoch:19 step:18691 [D loss: 0.554921, acc.: 68.75%] [G loss: 0.719386]\n",
      "epoch:19 step:18692 [D loss: 0.607111, acc.: 61.72%] [G loss: 0.747395]\n",
      "epoch:19 step:18693 [D loss: 0.494106, acc.: 74.22%] [G loss: 0.626414]\n",
      "epoch:19 step:18694 [D loss: 0.602415, acc.: 67.19%] [G loss: 0.611907]\n",
      "epoch:19 step:18695 [D loss: 0.645407, acc.: 60.16%] [G loss: 0.554349]\n",
      "epoch:19 step:18696 [D loss: 0.483215, acc.: 78.91%] [G loss: 0.533476]\n",
      "epoch:19 step:18697 [D loss: 0.477136, acc.: 74.22%] [G loss: 0.710431]\n",
      "epoch:19 step:18698 [D loss: 0.552209, acc.: 71.09%] [G loss: 0.643740]\n",
      "epoch:19 step:18699 [D loss: 0.484680, acc.: 76.56%] [G loss: 0.829231]\n",
      "epoch:19 step:18700 [D loss: 0.517786, acc.: 70.31%] [G loss: 0.775752]\n",
      "epoch:19 step:18701 [D loss: 0.455440, acc.: 81.25%] [G loss: 0.815609]\n",
      "epoch:19 step:18702 [D loss: 0.467823, acc.: 74.22%] [G loss: 0.666894]\n",
      "epoch:19 step:18703 [D loss: 0.543573, acc.: 73.44%] [G loss: 0.900585]\n",
      "epoch:19 step:18704 [D loss: 0.538918, acc.: 72.66%] [G loss: 0.811475]\n",
      "epoch:19 step:18705 [D loss: 0.574855, acc.: 67.97%] [G loss: 0.694822]\n",
      "epoch:19 step:18706 [D loss: 0.512658, acc.: 71.88%] [G loss: 0.629580]\n",
      "epoch:19 step:18707 [D loss: 0.590070, acc.: 62.50%] [G loss: 0.578397]\n",
      "epoch:19 step:18708 [D loss: 0.554019, acc.: 71.09%] [G loss: 0.602702]\n",
      "epoch:19 step:18709 [D loss: 0.540522, acc.: 75.00%] [G loss: 0.696570]\n",
      "epoch:19 step:18710 [D loss: 0.519194, acc.: 75.00%] [G loss: 0.704301]\n",
      "epoch:19 step:18711 [D loss: 0.492426, acc.: 79.69%] [G loss: 0.725969]\n",
      "epoch:19 step:18712 [D loss: 0.520849, acc.: 69.53%] [G loss: 0.599963]\n",
      "epoch:19 step:18713 [D loss: 0.548555, acc.: 69.53%] [G loss: 0.631234]\n",
      "epoch:19 step:18714 [D loss: 0.470115, acc.: 75.00%] [G loss: 0.712853]\n",
      "epoch:19 step:18715 [D loss: 0.551565, acc.: 72.66%] [G loss: 0.722810]\n",
      "epoch:19 step:18716 [D loss: 0.580508, acc.: 71.09%] [G loss: 0.616287]\n",
      "epoch:19 step:18717 [D loss: 0.473326, acc.: 75.78%] [G loss: 0.692311]\n",
      "epoch:19 step:18718 [D loss: 0.612429, acc.: 64.06%] [G loss: 0.769084]\n",
      "epoch:19 step:18719 [D loss: 0.489385, acc.: 75.00%] [G loss: 0.881642]\n",
      "epoch:19 step:18720 [D loss: 0.569590, acc.: 75.78%] [G loss: 0.742902]\n",
      "epoch:19 step:18721 [D loss: 0.501601, acc.: 70.31%] [G loss: 0.809848]\n",
      "epoch:19 step:18722 [D loss: 0.454045, acc.: 81.25%] [G loss: 0.885233]\n",
      "epoch:19 step:18723 [D loss: 0.665116, acc.: 63.28%] [G loss: 0.765273]\n",
      "epoch:19 step:18724 [D loss: 0.467195, acc.: 77.34%] [G loss: 0.746207]\n",
      "epoch:19 step:18725 [D loss: 0.497732, acc.: 70.31%] [G loss: 0.737892]\n",
      "epoch:19 step:18726 [D loss: 0.429018, acc.: 78.12%] [G loss: 0.654725]\n",
      "epoch:19 step:18727 [D loss: 0.451588, acc.: 76.56%] [G loss: 0.811639]\n",
      "epoch:19 step:18728 [D loss: 0.388165, acc.: 82.03%] [G loss: 1.149414]\n",
      "epoch:19 step:18729 [D loss: 0.434182, acc.: 78.12%] [G loss: 1.003164]\n",
      "epoch:19 step:18730 [D loss: 0.483033, acc.: 75.78%] [G loss: 1.214222]\n",
      "epoch:19 step:18731 [D loss: 0.732877, acc.: 67.19%] [G loss: 1.173304]\n",
      "epoch:19 step:18732 [D loss: 0.505395, acc.: 72.66%] [G loss: 1.700418]\n",
      "epoch:19 step:18733 [D loss: 0.515265, acc.: 71.88%] [G loss: 1.142113]\n",
      "epoch:19 step:18734 [D loss: 0.548450, acc.: 66.41%] [G loss: 0.897385]\n",
      "epoch:19 step:18735 [D loss: 0.573576, acc.: 67.97%] [G loss: 0.615088]\n",
      "epoch:19 step:18736 [D loss: 0.475127, acc.: 75.00%] [G loss: 0.732262]\n",
      "epoch:19 step:18737 [D loss: 0.516250, acc.: 67.19%] [G loss: 0.857645]\n",
      "epoch:19 step:18738 [D loss: 0.526989, acc.: 73.44%] [G loss: 0.973928]\n",
      "epoch:19 step:18739 [D loss: 0.371887, acc.: 82.03%] [G loss: 1.026388]\n",
      "epoch:19 step:18740 [D loss: 0.428331, acc.: 85.16%] [G loss: 1.233587]\n",
      "epoch:20 step:18741 [D loss: 0.592530, acc.: 71.09%] [G loss: 1.241606]\n",
      "epoch:20 step:18742 [D loss: 0.470116, acc.: 77.34%] [G loss: 1.072553]\n",
      "epoch:20 step:18743 [D loss: 0.567251, acc.: 69.53%] [G loss: 1.110854]\n",
      "epoch:20 step:18744 [D loss: 0.465019, acc.: 77.34%] [G loss: 0.969862]\n",
      "epoch:20 step:18745 [D loss: 0.568209, acc.: 68.75%] [G loss: 0.762959]\n",
      "epoch:20 step:18746 [D loss: 0.604885, acc.: 67.19%] [G loss: 0.811918]\n",
      "epoch:20 step:18747 [D loss: 0.482094, acc.: 77.34%] [G loss: 0.773782]\n",
      "epoch:20 step:18748 [D loss: 0.450938, acc.: 78.12%] [G loss: 0.741901]\n",
      "epoch:20 step:18749 [D loss: 0.499268, acc.: 72.66%] [G loss: 0.815074]\n",
      "epoch:20 step:18750 [D loss: 0.457727, acc.: 78.91%] [G loss: 0.849780]\n",
      "epoch:20 step:18751 [D loss: 0.467321, acc.: 78.91%] [G loss: 0.907602]\n",
      "epoch:20 step:18752 [D loss: 0.539856, acc.: 75.78%] [G loss: 0.663906]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:20 step:18753 [D loss: 0.554706, acc.: 70.31%] [G loss: 0.592681]\n",
      "epoch:20 step:18754 [D loss: 0.560096, acc.: 69.53%] [G loss: 0.677648]\n",
      "epoch:20 step:18755 [D loss: 0.494318, acc.: 74.22%] [G loss: 0.736951]\n",
      "epoch:20 step:18756 [D loss: 0.471094, acc.: 78.12%] [G loss: 0.776687]\n",
      "epoch:20 step:18757 [D loss: 0.639564, acc.: 66.41%] [G loss: 0.643376]\n",
      "epoch:20 step:18758 [D loss: 0.535316, acc.: 72.66%] [G loss: 0.798524]\n",
      "epoch:20 step:18759 [D loss: 0.595949, acc.: 68.75%] [G loss: 0.705676]\n",
      "epoch:20 step:18760 [D loss: 0.641869, acc.: 58.59%] [G loss: 0.679782]\n",
      "epoch:20 step:18761 [D loss: 0.561418, acc.: 67.97%] [G loss: 0.755174]\n",
      "epoch:20 step:18762 [D loss: 0.497505, acc.: 78.12%] [G loss: 0.837923]\n",
      "epoch:20 step:18763 [D loss: 0.511540, acc.: 73.44%] [G loss: 0.815676]\n",
      "epoch:20 step:18764 [D loss: 0.475867, acc.: 76.56%] [G loss: 0.707942]\n",
      "epoch:20 step:18765 [D loss: 0.469451, acc.: 74.22%] [G loss: 0.808180]\n",
      "epoch:20 step:18766 [D loss: 0.565608, acc.: 67.19%] [G loss: 0.637323]\n",
      "epoch:20 step:18767 [D loss: 0.481614, acc.: 75.78%] [G loss: 0.888880]\n",
      "epoch:20 step:18768 [D loss: 0.547701, acc.: 67.97%] [G loss: 0.682286]\n",
      "epoch:20 step:18769 [D loss: 0.472659, acc.: 78.91%] [G loss: 0.627997]\n",
      "epoch:20 step:18770 [D loss: 0.509190, acc.: 70.31%] [G loss: 0.576265]\n",
      "epoch:20 step:18771 [D loss: 0.601933, acc.: 65.62%] [G loss: 0.643487]\n",
      "epoch:20 step:18772 [D loss: 0.478997, acc.: 78.91%] [G loss: 0.720611]\n",
      "epoch:20 step:18773 [D loss: 0.470643, acc.: 77.34%] [G loss: 0.778840]\n",
      "epoch:20 step:18774 [D loss: 0.507780, acc.: 68.75%] [G loss: 0.761726]\n",
      "epoch:20 step:18775 [D loss: 0.514518, acc.: 74.22%] [G loss: 0.691723]\n",
      "epoch:20 step:18776 [D loss: 0.497182, acc.: 73.44%] [G loss: 0.561190]\n",
      "epoch:20 step:18777 [D loss: 0.549768, acc.: 71.88%] [G loss: 0.468981]\n",
      "epoch:20 step:18778 [D loss: 0.533863, acc.: 73.44%] [G loss: 0.668029]\n",
      "epoch:20 step:18779 [D loss: 0.548349, acc.: 70.31%] [G loss: 0.581068]\n",
      "epoch:20 step:18780 [D loss: 0.439639, acc.: 79.69%] [G loss: 0.615281]\n",
      "epoch:20 step:18781 [D loss: 0.556832, acc.: 67.97%] [G loss: 0.642063]\n",
      "epoch:20 step:18782 [D loss: 0.565019, acc.: 68.75%] [G loss: 0.799368]\n",
      "epoch:20 step:18783 [D loss: 0.492950, acc.: 75.78%] [G loss: 0.627379]\n",
      "epoch:20 step:18784 [D loss: 0.573048, acc.: 65.62%] [G loss: 0.627263]\n",
      "epoch:20 step:18785 [D loss: 0.502920, acc.: 73.44%] [G loss: 0.657334]\n",
      "epoch:20 step:18786 [D loss: 0.534740, acc.: 73.44%] [G loss: 0.914732]\n",
      "epoch:20 step:18787 [D loss: 0.552987, acc.: 70.31%] [G loss: 0.776133]\n",
      "epoch:20 step:18788 [D loss: 0.527976, acc.: 73.44%] [G loss: 0.744440]\n",
      "epoch:20 step:18789 [D loss: 0.473656, acc.: 78.12%] [G loss: 0.706843]\n",
      "epoch:20 step:18790 [D loss: 0.575232, acc.: 72.66%] [G loss: 0.589744]\n",
      "epoch:20 step:18791 [D loss: 0.582295, acc.: 64.84%] [G loss: 0.588188]\n",
      "epoch:20 step:18792 [D loss: 0.586982, acc.: 65.62%] [G loss: 0.621892]\n",
      "epoch:20 step:18793 [D loss: 0.542238, acc.: 69.53%] [G loss: 0.668287]\n",
      "epoch:20 step:18794 [D loss: 0.489038, acc.: 76.56%] [G loss: 0.841784]\n",
      "epoch:20 step:18795 [D loss: 0.585111, acc.: 70.31%] [G loss: 0.825237]\n",
      "epoch:20 step:18796 [D loss: 0.496805, acc.: 72.66%] [G loss: 0.817137]\n",
      "epoch:20 step:18797 [D loss: 0.480884, acc.: 75.00%] [G loss: 0.813789]\n",
      "epoch:20 step:18798 [D loss: 0.555297, acc.: 70.31%] [G loss: 0.615123]\n",
      "epoch:20 step:18799 [D loss: 0.470693, acc.: 78.91%] [G loss: 0.618994]\n",
      "epoch:20 step:18800 [D loss: 0.598331, acc.: 64.84%] [G loss: 0.727521]\n",
      "epoch:20 step:18801 [D loss: 0.524039, acc.: 77.34%] [G loss: 0.603537]\n",
      "epoch:20 step:18802 [D loss: 0.611676, acc.: 71.09%] [G loss: 0.646046]\n",
      "epoch:20 step:18803 [D loss: 0.489386, acc.: 74.22%] [G loss: 0.592543]\n",
      "epoch:20 step:18804 [D loss: 0.577834, acc.: 68.75%] [G loss: 0.587004]\n",
      "epoch:20 step:18805 [D loss: 0.517647, acc.: 76.56%] [G loss: 0.572541]\n",
      "epoch:20 step:18806 [D loss: 0.507738, acc.: 70.31%] [G loss: 0.980562]\n",
      "epoch:20 step:18807 [D loss: 0.548990, acc.: 66.41%] [G loss: 0.772031]\n",
      "epoch:20 step:18808 [D loss: 0.542106, acc.: 69.53%] [G loss: 0.523113]\n",
      "epoch:20 step:18809 [D loss: 0.479544, acc.: 81.25%] [G loss: 0.645909]\n",
      "epoch:20 step:18810 [D loss: 0.526284, acc.: 73.44%] [G loss: 0.676229]\n",
      "epoch:20 step:18811 [D loss: 0.498544, acc.: 74.22%] [G loss: 0.726868]\n",
      "epoch:20 step:18812 [D loss: 0.513245, acc.: 71.88%] [G loss: 0.559605]\n",
      "epoch:20 step:18813 [D loss: 0.572671, acc.: 65.62%] [G loss: 0.536095]\n",
      "epoch:20 step:18814 [D loss: 0.493068, acc.: 73.44%] [G loss: 0.708448]\n",
      "epoch:20 step:18815 [D loss: 0.523287, acc.: 69.53%] [G loss: 0.914977]\n",
      "epoch:20 step:18816 [D loss: 0.550914, acc.: 73.44%] [G loss: 0.787554]\n",
      "epoch:20 step:18817 [D loss: 0.423045, acc.: 82.03%] [G loss: 0.790140]\n",
      "epoch:20 step:18818 [D loss: 0.626864, acc.: 67.97%] [G loss: 0.643642]\n",
      "epoch:20 step:18819 [D loss: 0.548615, acc.: 71.88%] [G loss: 0.743729]\n",
      "epoch:20 step:18820 [D loss: 0.502233, acc.: 74.22%] [G loss: 0.831120]\n",
      "epoch:20 step:18821 [D loss: 0.538393, acc.: 69.53%] [G loss: 0.688666]\n",
      "epoch:20 step:18822 [D loss: 0.502041, acc.: 72.66%] [G loss: 0.713854]\n",
      "epoch:20 step:18823 [D loss: 0.453037, acc.: 79.69%] [G loss: 0.735516]\n",
      "epoch:20 step:18824 [D loss: 0.527363, acc.: 71.09%] [G loss: 0.674433]\n",
      "epoch:20 step:18825 [D loss: 0.603520, acc.: 66.41%] [G loss: 0.619931]\n",
      "epoch:20 step:18826 [D loss: 0.531085, acc.: 69.53%] [G loss: 0.640525]\n",
      "epoch:20 step:18827 [D loss: 0.486231, acc.: 72.66%] [G loss: 0.762811]\n",
      "epoch:20 step:18828 [D loss: 0.531310, acc.: 74.22%] [G loss: 0.594670]\n",
      "epoch:20 step:18829 [D loss: 0.458821, acc.: 72.66%] [G loss: 0.821588]\n",
      "epoch:20 step:18830 [D loss: 0.497525, acc.: 74.22%] [G loss: 0.659073]\n",
      "epoch:20 step:18831 [D loss: 0.648022, acc.: 62.50%] [G loss: 0.676580]\n",
      "epoch:20 step:18832 [D loss: 0.443077, acc.: 80.47%] [G loss: 0.835383]\n",
      "epoch:20 step:18833 [D loss: 0.509975, acc.: 71.09%] [G loss: 0.874241]\n",
      "epoch:20 step:18834 [D loss: 0.463758, acc.: 76.56%] [G loss: 0.674940]\n",
      "epoch:20 step:18835 [D loss: 0.528743, acc.: 68.75%] [G loss: 0.823182]\n",
      "epoch:20 step:18836 [D loss: 0.506324, acc.: 70.31%] [G loss: 0.795825]\n",
      "epoch:20 step:18837 [D loss: 0.510791, acc.: 74.22%] [G loss: 0.655174]\n",
      "epoch:20 step:18838 [D loss: 0.511919, acc.: 69.53%] [G loss: 0.762403]\n",
      "epoch:20 step:18839 [D loss: 0.494941, acc.: 73.44%] [G loss: 0.720237]\n",
      "epoch:20 step:18840 [D loss: 0.483951, acc.: 77.34%] [G loss: 1.133975]\n",
      "epoch:20 step:18841 [D loss: 0.485383, acc.: 75.00%] [G loss: 0.945737]\n",
      "epoch:20 step:18842 [D loss: 0.671208, acc.: 62.50%] [G loss: 0.698471]\n",
      "epoch:20 step:18843 [D loss: 0.494829, acc.: 72.66%] [G loss: 0.691092]\n",
      "epoch:20 step:18844 [D loss: 0.511912, acc.: 71.09%] [G loss: 0.748386]\n",
      "epoch:20 step:18845 [D loss: 0.577893, acc.: 68.75%] [G loss: 0.761557]\n",
      "epoch:20 step:18846 [D loss: 0.471190, acc.: 74.22%] [G loss: 0.682987]\n",
      "epoch:20 step:18847 [D loss: 0.570775, acc.: 71.88%] [G loss: 0.599808]\n",
      "epoch:20 step:18848 [D loss: 0.635965, acc.: 64.06%] [G loss: 0.518275]\n",
      "epoch:20 step:18849 [D loss: 0.505136, acc.: 73.44%] [G loss: 0.638771]\n",
      "epoch:20 step:18850 [D loss: 0.541242, acc.: 71.09%] [G loss: 0.650988]\n",
      "epoch:20 step:18851 [D loss: 0.502699, acc.: 73.44%] [G loss: 0.660709]\n",
      "epoch:20 step:18852 [D loss: 0.514129, acc.: 68.75%] [G loss: 0.661863]\n",
      "epoch:20 step:18853 [D loss: 0.546393, acc.: 71.88%] [G loss: 0.571061]\n",
      "epoch:20 step:18854 [D loss: 0.587197, acc.: 66.41%] [G loss: 0.757666]\n",
      "epoch:20 step:18855 [D loss: 0.506136, acc.: 76.56%] [G loss: 0.774014]\n",
      "epoch:20 step:18856 [D loss: 0.502912, acc.: 75.00%] [G loss: 0.740060]\n",
      "epoch:20 step:18857 [D loss: 0.518925, acc.: 75.00%] [G loss: 0.608521]\n",
      "epoch:20 step:18858 [D loss: 0.551245, acc.: 67.97%] [G loss: 0.801102]\n",
      "epoch:20 step:18859 [D loss: 0.460187, acc.: 78.91%] [G loss: 0.780053]\n",
      "epoch:20 step:18860 [D loss: 0.521701, acc.: 77.34%] [G loss: 0.836338]\n",
      "epoch:20 step:18861 [D loss: 0.537363, acc.: 74.22%] [G loss: 0.788979]\n",
      "epoch:20 step:18862 [D loss: 0.446641, acc.: 82.03%] [G loss: 0.836097]\n",
      "epoch:20 step:18863 [D loss: 0.512451, acc.: 73.44%] [G loss: 0.865656]\n",
      "epoch:20 step:18864 [D loss: 0.542473, acc.: 72.66%] [G loss: 0.844627]\n",
      "epoch:20 step:18865 [D loss: 0.615607, acc.: 68.75%] [G loss: 0.824949]\n",
      "epoch:20 step:18866 [D loss: 0.484050, acc.: 74.22%] [G loss: 0.783013]\n",
      "epoch:20 step:18867 [D loss: 0.499849, acc.: 75.78%] [G loss: 0.588792]\n",
      "epoch:20 step:18868 [D loss: 0.493887, acc.: 73.44%] [G loss: 0.733911]\n",
      "epoch:20 step:18869 [D loss: 0.553700, acc.: 72.66%] [G loss: 0.617963]\n",
      "epoch:20 step:18870 [D loss: 0.514286, acc.: 71.88%] [G loss: 0.546624]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:20 step:18871 [D loss: 0.470469, acc.: 73.44%] [G loss: 0.717116]\n",
      "epoch:20 step:18872 [D loss: 0.523835, acc.: 73.44%] [G loss: 0.767897]\n",
      "epoch:20 step:18873 [D loss: 0.535717, acc.: 71.09%] [G loss: 0.584891]\n",
      "epoch:20 step:18874 [D loss: 0.525936, acc.: 69.53%] [G loss: 0.721402]\n",
      "epoch:20 step:18875 [D loss: 0.505473, acc.: 74.22%] [G loss: 0.804574]\n",
      "epoch:20 step:18876 [D loss: 0.530165, acc.: 72.66%] [G loss: 0.901889]\n",
      "epoch:20 step:18877 [D loss: 0.580050, acc.: 70.31%] [G loss: 0.739403]\n",
      "epoch:20 step:18878 [D loss: 0.563411, acc.: 73.44%] [G loss: 0.540253]\n",
      "epoch:20 step:18879 [D loss: 0.642368, acc.: 64.84%] [G loss: 0.661725]\n",
      "epoch:20 step:18880 [D loss: 0.533143, acc.: 70.31%] [G loss: 0.652253]\n",
      "epoch:20 step:18881 [D loss: 0.550177, acc.: 70.31%] [G loss: 0.505915]\n",
      "epoch:20 step:18882 [D loss: 0.522734, acc.: 72.66%] [G loss: 0.589527]\n",
      "epoch:20 step:18883 [D loss: 0.589167, acc.: 67.19%] [G loss: 0.573318]\n",
      "epoch:20 step:18884 [D loss: 0.473966, acc.: 74.22%] [G loss: 0.652557]\n",
      "epoch:20 step:18885 [D loss: 0.508788, acc.: 67.97%] [G loss: 0.725813]\n",
      "epoch:20 step:18886 [D loss: 0.504119, acc.: 73.44%] [G loss: 0.769779]\n",
      "epoch:20 step:18887 [D loss: 0.637158, acc.: 67.19%] [G loss: 0.546435]\n",
      "epoch:20 step:18888 [D loss: 0.560763, acc.: 67.97%] [G loss: 0.620407]\n",
      "epoch:20 step:18889 [D loss: 0.597528, acc.: 67.97%] [G loss: 0.871008]\n",
      "epoch:20 step:18890 [D loss: 0.576957, acc.: 67.97%] [G loss: 0.676460]\n",
      "epoch:20 step:18891 [D loss: 0.553002, acc.: 64.84%] [G loss: 0.514021]\n",
      "epoch:20 step:18892 [D loss: 0.488556, acc.: 78.12%] [G loss: 0.705217]\n",
      "epoch:20 step:18893 [D loss: 0.600595, acc.: 66.41%] [G loss: 0.768524]\n",
      "epoch:20 step:18894 [D loss: 0.556413, acc.: 70.31%] [G loss: 0.626490]\n",
      "epoch:20 step:18895 [D loss: 0.446360, acc.: 80.47%] [G loss: 0.567601]\n",
      "epoch:20 step:18896 [D loss: 0.491253, acc.: 75.00%] [G loss: 0.622343]\n",
      "epoch:20 step:18897 [D loss: 0.552983, acc.: 65.62%] [G loss: 0.601412]\n",
      "epoch:20 step:18898 [D loss: 0.571214, acc.: 66.41%] [G loss: 0.703945]\n",
      "epoch:20 step:18899 [D loss: 0.488144, acc.: 75.00%] [G loss: 0.540408]\n",
      "epoch:20 step:18900 [D loss: 0.550730, acc.: 69.53%] [G loss: 0.667303]\n",
      "epoch:20 step:18901 [D loss: 0.515033, acc.: 71.88%] [G loss: 0.829420]\n",
      "epoch:20 step:18902 [D loss: 0.460971, acc.: 78.12%] [G loss: 0.853261]\n",
      "epoch:20 step:18903 [D loss: 0.523753, acc.: 71.09%] [G loss: 0.782580]\n",
      "epoch:20 step:18904 [D loss: 0.567608, acc.: 64.84%] [G loss: 0.731656]\n",
      "epoch:20 step:18905 [D loss: 0.519641, acc.: 71.88%] [G loss: 0.624773]\n",
      "epoch:20 step:18906 [D loss: 0.561708, acc.: 67.19%] [G loss: 0.546246]\n",
      "epoch:20 step:18907 [D loss: 0.535189, acc.: 65.62%] [G loss: 0.545413]\n",
      "epoch:20 step:18908 [D loss: 0.501405, acc.: 75.78%] [G loss: 0.604932]\n",
      "epoch:20 step:18909 [D loss: 0.602876, acc.: 68.75%] [G loss: 0.569763]\n",
      "epoch:20 step:18910 [D loss: 0.535411, acc.: 69.53%] [G loss: 0.628258]\n",
      "epoch:20 step:18911 [D loss: 0.504052, acc.: 71.88%] [G loss: 0.705628]\n",
      "epoch:20 step:18912 [D loss: 0.534799, acc.: 71.88%] [G loss: 0.753694]\n",
      "epoch:20 step:18913 [D loss: 0.494148, acc.: 73.44%] [G loss: 0.669802]\n",
      "epoch:20 step:18914 [D loss: 0.566102, acc.: 68.75%] [G loss: 0.766026]\n",
      "epoch:20 step:18915 [D loss: 0.561858, acc.: 67.19%] [G loss: 0.651036]\n",
      "epoch:20 step:18916 [D loss: 0.505299, acc.: 71.88%] [G loss: 0.596742]\n",
      "epoch:20 step:18917 [D loss: 0.484159, acc.: 71.88%] [G loss: 0.685524]\n",
      "epoch:20 step:18918 [D loss: 0.532822, acc.: 70.31%] [G loss: 0.550020]\n",
      "epoch:20 step:18919 [D loss: 0.514119, acc.: 72.66%] [G loss: 0.473111]\n",
      "epoch:20 step:18920 [D loss: 0.602882, acc.: 65.62%] [G loss: 0.663699]\n",
      "epoch:20 step:18921 [D loss: 0.552134, acc.: 69.53%] [G loss: 0.448161]\n",
      "epoch:20 step:18922 [D loss: 0.469283, acc.: 76.56%] [G loss: 0.663270]\n",
      "epoch:20 step:18923 [D loss: 0.501614, acc.: 74.22%] [G loss: 0.737123]\n",
      "epoch:20 step:18924 [D loss: 0.516621, acc.: 69.53%] [G loss: 0.702031]\n",
      "epoch:20 step:18925 [D loss: 0.576517, acc.: 68.75%] [G loss: 0.625869]\n",
      "epoch:20 step:18926 [D loss: 0.504104, acc.: 75.78%] [G loss: 0.631143]\n",
      "epoch:20 step:18927 [D loss: 0.577170, acc.: 67.97%] [G loss: 0.628765]\n",
      "epoch:20 step:18928 [D loss: 0.561368, acc.: 67.97%] [G loss: 0.605877]\n",
      "epoch:20 step:18929 [D loss: 0.582993, acc.: 67.19%] [G loss: 0.721932]\n",
      "epoch:20 step:18930 [D loss: 0.494271, acc.: 73.44%] [G loss: 0.660405]\n",
      "epoch:20 step:18931 [D loss: 0.472377, acc.: 75.78%] [G loss: 0.678486]\n",
      "epoch:20 step:18932 [D loss: 0.517409, acc.: 75.00%] [G loss: 0.766248]\n",
      "epoch:20 step:18933 [D loss: 0.519994, acc.: 73.44%] [G loss: 0.694542]\n",
      "epoch:20 step:18934 [D loss: 0.414508, acc.: 85.16%] [G loss: 0.729233]\n",
      "epoch:20 step:18935 [D loss: 0.552595, acc.: 69.53%] [G loss: 0.712212]\n",
      "epoch:20 step:18936 [D loss: 0.587975, acc.: 67.97%] [G loss: 0.786511]\n",
      "epoch:20 step:18937 [D loss: 0.467021, acc.: 73.44%] [G loss: 0.789984]\n",
      "epoch:20 step:18938 [D loss: 0.417068, acc.: 83.59%] [G loss: 0.778574]\n",
      "epoch:20 step:18939 [D loss: 0.474317, acc.: 72.66%] [G loss: 0.835308]\n",
      "epoch:20 step:18940 [D loss: 0.554980, acc.: 67.19%] [G loss: 0.787961]\n",
      "epoch:20 step:18941 [D loss: 0.522880, acc.: 73.44%] [G loss: 0.466922]\n",
      "epoch:20 step:18942 [D loss: 0.499177, acc.: 74.22%] [G loss: 0.621664]\n",
      "epoch:20 step:18943 [D loss: 0.552796, acc.: 67.97%] [G loss: 0.636162]\n",
      "epoch:20 step:18944 [D loss: 0.551337, acc.: 74.22%] [G loss: 0.831805]\n",
      "epoch:20 step:18945 [D loss: 0.486335, acc.: 75.00%] [G loss: 0.741794]\n",
      "epoch:20 step:18946 [D loss: 0.497762, acc.: 76.56%] [G loss: 0.909027]\n",
      "epoch:20 step:18947 [D loss: 0.494073, acc.: 75.00%] [G loss: 0.679966]\n",
      "epoch:20 step:18948 [D loss: 0.437169, acc.: 80.47%] [G loss: 0.874964]\n",
      "epoch:20 step:18949 [D loss: 0.481741, acc.: 73.44%] [G loss: 0.894750]\n",
      "epoch:20 step:18950 [D loss: 0.636322, acc.: 66.41%] [G loss: 0.627216]\n",
      "epoch:20 step:18951 [D loss: 0.597535, acc.: 64.06%] [G loss: 0.586644]\n",
      "epoch:20 step:18952 [D loss: 0.532942, acc.: 67.19%] [G loss: 0.734152]\n",
      "epoch:20 step:18953 [D loss: 0.456793, acc.: 79.69%] [G loss: 0.678847]\n",
      "epoch:20 step:18954 [D loss: 0.541868, acc.: 71.88%] [G loss: 0.699098]\n",
      "epoch:20 step:18955 [D loss: 0.543077, acc.: 68.75%] [G loss: 0.528517]\n",
      "epoch:20 step:18956 [D loss: 0.568335, acc.: 68.75%] [G loss: 0.626830]\n",
      "epoch:20 step:18957 [D loss: 0.471348, acc.: 75.78%] [G loss: 0.773893]\n",
      "epoch:20 step:18958 [D loss: 0.458403, acc.: 79.69%] [G loss: 0.807963]\n",
      "epoch:20 step:18959 [D loss: 0.454308, acc.: 77.34%] [G loss: 0.937681]\n",
      "epoch:20 step:18960 [D loss: 0.642112, acc.: 65.62%] [G loss: 0.700258]\n",
      "epoch:20 step:18961 [D loss: 0.513458, acc.: 74.22%] [G loss: 0.649372]\n",
      "epoch:20 step:18962 [D loss: 0.487114, acc.: 75.78%] [G loss: 0.809454]\n",
      "epoch:20 step:18963 [D loss: 0.540432, acc.: 73.44%] [G loss: 0.671875]\n",
      "epoch:20 step:18964 [D loss: 0.542315, acc.: 70.31%] [G loss: 0.726723]\n",
      "epoch:20 step:18965 [D loss: 0.497686, acc.: 81.25%] [G loss: 0.705909]\n",
      "epoch:20 step:18966 [D loss: 0.575311, acc.: 64.84%] [G loss: 0.757304]\n",
      "epoch:20 step:18967 [D loss: 0.512205, acc.: 71.88%] [G loss: 0.714883]\n",
      "epoch:20 step:18968 [D loss: 0.561502, acc.: 67.97%] [G loss: 0.610268]\n",
      "epoch:20 step:18969 [D loss: 0.492939, acc.: 75.78%] [G loss: 0.622441]\n",
      "epoch:20 step:18970 [D loss: 0.551618, acc.: 71.09%] [G loss: 0.722447]\n",
      "epoch:20 step:18971 [D loss: 0.424851, acc.: 80.47%] [G loss: 0.994254]\n",
      "epoch:20 step:18972 [D loss: 0.420737, acc.: 83.59%] [G loss: 0.936722]\n",
      "epoch:20 step:18973 [D loss: 0.533360, acc.: 75.00%] [G loss: 0.788261]\n",
      "epoch:20 step:18974 [D loss: 0.540054, acc.: 70.31%] [G loss: 0.746164]\n",
      "epoch:20 step:18975 [D loss: 0.565796, acc.: 66.41%] [G loss: 0.584752]\n",
      "epoch:20 step:18976 [D loss: 0.473981, acc.: 78.91%] [G loss: 0.651631]\n",
      "epoch:20 step:18977 [D loss: 0.548425, acc.: 67.19%] [G loss: 0.506158]\n",
      "epoch:20 step:18978 [D loss: 0.565809, acc.: 67.19%] [G loss: 0.562559]\n",
      "epoch:20 step:18979 [D loss: 0.515347, acc.: 70.31%] [G loss: 0.589173]\n",
      "epoch:20 step:18980 [D loss: 0.506716, acc.: 71.09%] [G loss: 0.662403]\n",
      "epoch:20 step:18981 [D loss: 0.517272, acc.: 71.09%] [G loss: 0.620069]\n",
      "epoch:20 step:18982 [D loss: 0.481984, acc.: 73.44%] [G loss: 0.686563]\n",
      "epoch:20 step:18983 [D loss: 0.500437, acc.: 71.88%] [G loss: 0.736919]\n",
      "epoch:20 step:18984 [D loss: 0.443289, acc.: 78.12%] [G loss: 0.737065]\n",
      "epoch:20 step:18985 [D loss: 0.515919, acc.: 73.44%] [G loss: 0.665891]\n",
      "epoch:20 step:18986 [D loss: 0.458074, acc.: 78.12%] [G loss: 0.766185]\n",
      "epoch:20 step:18987 [D loss: 0.469367, acc.: 76.56%] [G loss: 0.802426]\n",
      "epoch:20 step:18988 [D loss: 0.445500, acc.: 79.69%] [G loss: 0.860433]\n",
      "epoch:20 step:18989 [D loss: 0.545336, acc.: 68.75%] [G loss: 0.697714]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:20 step:18990 [D loss: 0.558437, acc.: 68.75%] [G loss: 0.720188]\n",
      "epoch:20 step:18991 [D loss: 0.625652, acc.: 61.72%] [G loss: 0.802873]\n",
      "epoch:20 step:18992 [D loss: 0.576128, acc.: 66.41%] [G loss: 0.947570]\n",
      "epoch:20 step:18993 [D loss: 0.549192, acc.: 69.53%] [G loss: 0.642371]\n",
      "epoch:20 step:18994 [D loss: 0.489341, acc.: 78.91%] [G loss: 0.687343]\n",
      "epoch:20 step:18995 [D loss: 0.550141, acc.: 70.31%] [G loss: 0.722716]\n",
      "epoch:20 step:18996 [D loss: 0.553042, acc.: 70.31%] [G loss: 0.723157]\n",
      "epoch:20 step:18997 [D loss: 0.600262, acc.: 60.16%] [G loss: 0.465239]\n",
      "epoch:20 step:18998 [D loss: 0.504479, acc.: 73.44%] [G loss: 0.707586]\n",
      "epoch:20 step:18999 [D loss: 0.520620, acc.: 72.66%] [G loss: 0.621513]\n",
      "epoch:20 step:19000 [D loss: 0.560840, acc.: 66.41%] [G loss: 0.592036]\n",
      "epoch:20 step:19001 [D loss: 0.518192, acc.: 70.31%] [G loss: 0.694202]\n",
      "epoch:20 step:19002 [D loss: 0.502450, acc.: 76.56%] [G loss: 0.688306]\n",
      "epoch:20 step:19003 [D loss: 0.624650, acc.: 67.97%] [G loss: 0.665079]\n",
      "epoch:20 step:19004 [D loss: 0.461490, acc.: 82.03%] [G loss: 0.629552]\n",
      "epoch:20 step:19005 [D loss: 0.519888, acc.: 72.66%] [G loss: 0.657710]\n",
      "epoch:20 step:19006 [D loss: 0.562339, acc.: 67.97%] [G loss: 0.654789]\n",
      "epoch:20 step:19007 [D loss: 0.501957, acc.: 75.78%] [G loss: 0.675870]\n",
      "epoch:20 step:19008 [D loss: 0.463842, acc.: 78.12%] [G loss: 0.721583]\n",
      "epoch:20 step:19009 [D loss: 0.545625, acc.: 67.97%] [G loss: 0.605954]\n",
      "epoch:20 step:19010 [D loss: 0.479990, acc.: 74.22%] [G loss: 0.795023]\n",
      "epoch:20 step:19011 [D loss: 0.452668, acc.: 78.91%] [G loss: 0.813583]\n",
      "epoch:20 step:19012 [D loss: 0.544679, acc.: 71.09%] [G loss: 0.740519]\n",
      "epoch:20 step:19013 [D loss: 0.474140, acc.: 75.00%] [G loss: 0.843625]\n",
      "epoch:20 step:19014 [D loss: 0.494154, acc.: 72.66%] [G loss: 0.694438]\n",
      "epoch:20 step:19015 [D loss: 0.570462, acc.: 64.84%] [G loss: 0.593278]\n",
      "epoch:20 step:19016 [D loss: 0.453985, acc.: 82.03%] [G loss: 0.826641]\n",
      "epoch:20 step:19017 [D loss: 0.662954, acc.: 59.38%] [G loss: 0.634157]\n",
      "epoch:20 step:19018 [D loss: 0.603557, acc.: 65.62%] [G loss: 0.668124]\n",
      "epoch:20 step:19019 [D loss: 0.573307, acc.: 60.94%] [G loss: 0.544665]\n",
      "epoch:20 step:19020 [D loss: 0.538489, acc.: 70.31%] [G loss: 0.783905]\n",
      "epoch:20 step:19021 [D loss: 0.559010, acc.: 68.75%] [G loss: 0.463065]\n",
      "epoch:20 step:19022 [D loss: 0.573927, acc.: 72.66%] [G loss: 0.565500]\n",
      "epoch:20 step:19023 [D loss: 0.482651, acc.: 75.78%] [G loss: 0.570222]\n",
      "epoch:20 step:19024 [D loss: 0.534729, acc.: 66.41%] [G loss: 0.637256]\n",
      "epoch:20 step:19025 [D loss: 0.492166, acc.: 76.56%] [G loss: 0.684222]\n",
      "epoch:20 step:19026 [D loss: 0.490805, acc.: 74.22%] [G loss: 0.756837]\n",
      "epoch:20 step:19027 [D loss: 0.557139, acc.: 68.75%] [G loss: 0.586552]\n",
      "epoch:20 step:19028 [D loss: 0.552661, acc.: 66.41%] [G loss: 0.632050]\n",
      "epoch:20 step:19029 [D loss: 0.534767, acc.: 70.31%] [G loss: 0.725380]\n",
      "epoch:20 step:19030 [D loss: 0.549955, acc.: 69.53%] [G loss: 0.650082]\n",
      "epoch:20 step:19031 [D loss: 0.575727, acc.: 69.53%] [G loss: 0.595997]\n",
      "epoch:20 step:19032 [D loss: 0.470574, acc.: 79.69%] [G loss: 0.740482]\n",
      "epoch:20 step:19033 [D loss: 0.550164, acc.: 68.75%] [G loss: 0.755198]\n",
      "epoch:20 step:19034 [D loss: 0.611921, acc.: 67.19%] [G loss: 0.534850]\n",
      "epoch:20 step:19035 [D loss: 0.559104, acc.: 67.97%] [G loss: 0.506949]\n",
      "epoch:20 step:19036 [D loss: 0.446592, acc.: 78.12%] [G loss: 0.716660]\n",
      "epoch:20 step:19037 [D loss: 0.549774, acc.: 63.28%] [G loss: 0.649160]\n",
      "epoch:20 step:19038 [D loss: 0.507836, acc.: 75.00%] [G loss: 0.589180]\n",
      "epoch:20 step:19039 [D loss: 0.505249, acc.: 73.44%] [G loss: 0.792034]\n",
      "epoch:20 step:19040 [D loss: 0.475302, acc.: 75.00%] [G loss: 0.774333]\n",
      "epoch:20 step:19041 [D loss: 0.619687, acc.: 64.84%] [G loss: 0.577429]\n",
      "epoch:20 step:19042 [D loss: 0.484385, acc.: 77.34%] [G loss: 0.729652]\n",
      "epoch:20 step:19043 [D loss: 0.514197, acc.: 67.97%] [G loss: 0.703301]\n",
      "epoch:20 step:19044 [D loss: 0.565467, acc.: 66.41%] [G loss: 0.660156]\n",
      "epoch:20 step:19045 [D loss: 0.524291, acc.: 76.56%] [G loss: 0.631890]\n",
      "epoch:20 step:19046 [D loss: 0.502394, acc.: 77.34%] [G loss: 0.715550]\n",
      "epoch:20 step:19047 [D loss: 0.479630, acc.: 75.00%] [G loss: 0.716395]\n",
      "epoch:20 step:19048 [D loss: 0.509765, acc.: 75.78%] [G loss: 0.690821]\n",
      "epoch:20 step:19049 [D loss: 0.464975, acc.: 75.00%] [G loss: 0.738420]\n",
      "epoch:20 step:19050 [D loss: 0.539646, acc.: 74.22%] [G loss: 0.674774]\n",
      "epoch:20 step:19051 [D loss: 0.490730, acc.: 75.00%] [G loss: 0.678136]\n",
      "epoch:20 step:19052 [D loss: 0.509190, acc.: 75.00%] [G loss: 0.961719]\n",
      "epoch:20 step:19053 [D loss: 0.482394, acc.: 71.88%] [G loss: 0.951197]\n",
      "epoch:20 step:19054 [D loss: 0.464000, acc.: 77.34%] [G loss: 1.046223]\n",
      "epoch:20 step:19055 [D loss: 0.476877, acc.: 78.12%] [G loss: 0.972457]\n",
      "epoch:20 step:19056 [D loss: 0.614936, acc.: 67.19%] [G loss: 0.766084]\n",
      "epoch:20 step:19057 [D loss: 0.597565, acc.: 69.53%] [G loss: 0.618253]\n",
      "epoch:20 step:19058 [D loss: 0.514794, acc.: 72.66%] [G loss: 0.598802]\n",
      "epoch:20 step:19059 [D loss: 0.573431, acc.: 67.97%] [G loss: 0.726876]\n",
      "epoch:20 step:19060 [D loss: 0.564153, acc.: 67.97%] [G loss: 0.622520]\n",
      "epoch:20 step:19061 [D loss: 0.491308, acc.: 72.66%] [G loss: 0.838759]\n",
      "epoch:20 step:19062 [D loss: 0.587861, acc.: 70.31%] [G loss: 0.737417]\n",
      "epoch:20 step:19063 [D loss: 0.631495, acc.: 61.72%] [G loss: 0.607643]\n",
      "epoch:20 step:19064 [D loss: 0.535296, acc.: 71.09%] [G loss: 0.717298]\n",
      "epoch:20 step:19065 [D loss: 0.536707, acc.: 75.00%] [G loss: 0.579845]\n",
      "epoch:20 step:19066 [D loss: 0.488856, acc.: 78.12%] [G loss: 0.732535]\n",
      "epoch:20 step:19067 [D loss: 0.545105, acc.: 73.44%] [G loss: 0.669060]\n",
      "epoch:20 step:19068 [D loss: 0.476721, acc.: 71.09%] [G loss: 0.582897]\n",
      "epoch:20 step:19069 [D loss: 0.510444, acc.: 74.22%] [G loss: 0.779534]\n",
      "epoch:20 step:19070 [D loss: 0.543927, acc.: 71.88%] [G loss: 0.551660]\n",
      "epoch:20 step:19071 [D loss: 0.550261, acc.: 73.44%] [G loss: 0.589352]\n",
      "epoch:20 step:19072 [D loss: 0.491472, acc.: 73.44%] [G loss: 0.684466]\n",
      "epoch:20 step:19073 [D loss: 0.523131, acc.: 71.88%] [G loss: 0.709388]\n",
      "epoch:20 step:19074 [D loss: 0.437609, acc.: 79.69%] [G loss: 0.801258]\n",
      "epoch:20 step:19075 [D loss: 0.457048, acc.: 76.56%] [G loss: 0.770202]\n",
      "epoch:20 step:19076 [D loss: 0.484705, acc.: 70.31%] [G loss: 1.012590]\n",
      "epoch:20 step:19077 [D loss: 0.488922, acc.: 75.00%] [G loss: 0.861544]\n",
      "epoch:20 step:19078 [D loss: 0.493483, acc.: 70.31%] [G loss: 0.859157]\n",
      "epoch:20 step:19079 [D loss: 0.475468, acc.: 75.78%] [G loss: 0.692903]\n",
      "epoch:20 step:19080 [D loss: 0.527788, acc.: 74.22%] [G loss: 0.711392]\n",
      "epoch:20 step:19081 [D loss: 0.566579, acc.: 75.00%] [G loss: 0.760949]\n",
      "epoch:20 step:19082 [D loss: 0.669625, acc.: 62.50%] [G loss: 0.799127]\n",
      "epoch:20 step:19083 [D loss: 0.509614, acc.: 70.31%] [G loss: 0.705967]\n",
      "epoch:20 step:19084 [D loss: 0.530921, acc.: 70.31%] [G loss: 0.865787]\n",
      "epoch:20 step:19085 [D loss: 0.530405, acc.: 70.31%] [G loss: 0.870934]\n",
      "epoch:20 step:19086 [D loss: 0.474589, acc.: 75.78%] [G loss: 0.805334]\n",
      "epoch:20 step:19087 [D loss: 0.443689, acc.: 82.03%] [G loss: 0.811708]\n",
      "epoch:20 step:19088 [D loss: 0.620891, acc.: 64.06%] [G loss: 0.825793]\n",
      "epoch:20 step:19089 [D loss: 0.660214, acc.: 62.50%] [G loss: 0.671510]\n",
      "epoch:20 step:19090 [D loss: 0.501059, acc.: 76.56%] [G loss: 0.530802]\n",
      "epoch:20 step:19091 [D loss: 0.465178, acc.: 78.91%] [G loss: 0.668054]\n",
      "epoch:20 step:19092 [D loss: 0.563549, acc.: 68.75%] [G loss: 0.668949]\n",
      "epoch:20 step:19093 [D loss: 0.533095, acc.: 70.31%] [G loss: 0.841463]\n",
      "epoch:20 step:19094 [D loss: 0.381031, acc.: 83.59%] [G loss: 0.958271]\n",
      "epoch:20 step:19095 [D loss: 0.473480, acc.: 75.78%] [G loss: 0.898538]\n",
      "epoch:20 step:19096 [D loss: 0.551785, acc.: 67.19%] [G loss: 0.720263]\n",
      "epoch:20 step:19097 [D loss: 0.419733, acc.: 82.03%] [G loss: 0.824640]\n",
      "epoch:20 step:19098 [D loss: 0.404051, acc.: 79.69%] [G loss: 0.854087]\n",
      "epoch:20 step:19099 [D loss: 0.458267, acc.: 76.56%] [G loss: 0.887059]\n",
      "epoch:20 step:19100 [D loss: 0.513458, acc.: 72.66%] [G loss: 0.795921]\n",
      "epoch:20 step:19101 [D loss: 0.444213, acc.: 80.47%] [G loss: 1.028354]\n",
      "epoch:20 step:19102 [D loss: 0.543836, acc.: 69.53%] [G loss: 0.662199]\n",
      "epoch:20 step:19103 [D loss: 0.548744, acc.: 73.44%] [G loss: 0.671494]\n",
      "epoch:20 step:19104 [D loss: 0.484772, acc.: 73.44%] [G loss: 0.758143]\n",
      "epoch:20 step:19105 [D loss: 0.529712, acc.: 71.88%] [G loss: 0.691151]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:20 step:19106 [D loss: 0.539331, acc.: 70.31%] [G loss: 0.784827]\n",
      "epoch:20 step:19107 [D loss: 0.543334, acc.: 69.53%] [G loss: 0.708339]\n",
      "epoch:20 step:19108 [D loss: 0.536060, acc.: 71.09%] [G loss: 0.720957]\n",
      "epoch:20 step:19109 [D loss: 0.538872, acc.: 71.09%] [G loss: 0.679527]\n",
      "epoch:20 step:19110 [D loss: 0.485589, acc.: 75.78%] [G loss: 0.666026]\n",
      "epoch:20 step:19111 [D loss: 0.479548, acc.: 78.91%] [G loss: 0.650716]\n",
      "epoch:20 step:19112 [D loss: 0.544866, acc.: 71.88%] [G loss: 0.798845]\n",
      "epoch:20 step:19113 [D loss: 0.528159, acc.: 67.19%] [G loss: 0.789338]\n",
      "epoch:20 step:19114 [D loss: 0.464943, acc.: 76.56%] [G loss: 0.733035]\n",
      "epoch:20 step:19115 [D loss: 0.571387, acc.: 70.31%] [G loss: 0.737442]\n",
      "epoch:20 step:19116 [D loss: 0.626382, acc.: 67.19%] [G loss: 0.641578]\n",
      "epoch:20 step:19117 [D loss: 0.557654, acc.: 70.31%] [G loss: 0.585508]\n",
      "epoch:20 step:19118 [D loss: 0.514131, acc.: 70.31%] [G loss: 0.739213]\n",
      "epoch:20 step:19119 [D loss: 0.576540, acc.: 62.50%] [G loss: 0.779539]\n",
      "epoch:20 step:19120 [D loss: 0.604895, acc.: 68.75%] [G loss: 0.532410]\n",
      "epoch:20 step:19121 [D loss: 0.468397, acc.: 74.22%] [G loss: 0.539564]\n",
      "epoch:20 step:19122 [D loss: 0.535474, acc.: 71.88%] [G loss: 0.622309]\n",
      "epoch:20 step:19123 [D loss: 0.514457, acc.: 76.56%] [G loss: 0.763945]\n",
      "epoch:20 step:19124 [D loss: 0.515251, acc.: 75.78%] [G loss: 0.724162]\n",
      "epoch:20 step:19125 [D loss: 0.503030, acc.: 70.31%] [G loss: 0.745128]\n",
      "epoch:20 step:19126 [D loss: 0.579126, acc.: 68.75%] [G loss: 0.598688]\n",
      "epoch:20 step:19127 [D loss: 0.553350, acc.: 71.09%] [G loss: 0.507604]\n",
      "epoch:20 step:19128 [D loss: 0.494640, acc.: 79.69%] [G loss: 0.697331]\n",
      "epoch:20 step:19129 [D loss: 0.563714, acc.: 65.62%] [G loss: 0.590777]\n",
      "epoch:20 step:19130 [D loss: 0.556775, acc.: 69.53%] [G loss: 0.734265]\n",
      "epoch:20 step:19131 [D loss: 0.563365, acc.: 63.28%] [G loss: 0.591539]\n",
      "epoch:20 step:19132 [D loss: 0.445835, acc.: 81.25%] [G loss: 0.756913]\n",
      "epoch:20 step:19133 [D loss: 0.530850, acc.: 71.88%] [G loss: 0.755732]\n",
      "epoch:20 step:19134 [D loss: 0.540131, acc.: 71.09%] [G loss: 0.712895]\n",
      "epoch:20 step:19135 [D loss: 0.488371, acc.: 71.88%] [G loss: 0.811005]\n",
      "epoch:20 step:19136 [D loss: 0.653134, acc.: 64.06%] [G loss: 0.674415]\n",
      "epoch:20 step:19137 [D loss: 0.581963, acc.: 66.41%] [G loss: 0.603009]\n",
      "epoch:20 step:19138 [D loss: 0.484653, acc.: 72.66%] [G loss: 0.944152]\n",
      "epoch:20 step:19139 [D loss: 0.513612, acc.: 78.12%] [G loss: 0.861873]\n",
      "epoch:20 step:19140 [D loss: 0.671510, acc.: 62.50%] [G loss: 0.507627]\n",
      "epoch:20 step:19141 [D loss: 0.613141, acc.: 62.50%] [G loss: 0.578870]\n",
      "epoch:20 step:19142 [D loss: 0.477829, acc.: 77.34%] [G loss: 0.752971]\n",
      "epoch:20 step:19143 [D loss: 0.497215, acc.: 73.44%] [G loss: 0.752012]\n",
      "epoch:20 step:19144 [D loss: 0.583705, acc.: 67.97%] [G loss: 0.655879]\n",
      "epoch:20 step:19145 [D loss: 0.552923, acc.: 69.53%] [G loss: 0.737077]\n",
      "epoch:20 step:19146 [D loss: 0.486201, acc.: 71.88%] [G loss: 0.842728]\n",
      "epoch:20 step:19147 [D loss: 0.535363, acc.: 68.75%] [G loss: 0.689416]\n",
      "epoch:20 step:19148 [D loss: 0.586002, acc.: 68.75%] [G loss: 0.625925]\n",
      "epoch:20 step:19149 [D loss: 0.564743, acc.: 64.06%] [G loss: 0.559527]\n",
      "epoch:20 step:19150 [D loss: 0.556167, acc.: 71.88%] [G loss: 0.649387]\n",
      "epoch:20 step:19151 [D loss: 0.582061, acc.: 67.97%] [G loss: 0.650525]\n",
      "epoch:20 step:19152 [D loss: 0.616762, acc.: 67.19%] [G loss: 0.563013]\n",
      "epoch:20 step:19153 [D loss: 0.576859, acc.: 66.41%] [G loss: 0.638378]\n",
      "epoch:20 step:19154 [D loss: 0.467073, acc.: 75.00%] [G loss: 0.757464]\n",
      "epoch:20 step:19155 [D loss: 0.569417, acc.: 68.75%] [G loss: 0.684088]\n",
      "epoch:20 step:19156 [D loss: 0.456379, acc.: 79.69%] [G loss: 0.887434]\n",
      "epoch:20 step:19157 [D loss: 0.518821, acc.: 71.09%] [G loss: 0.967673]\n",
      "epoch:20 step:19158 [D loss: 0.604478, acc.: 67.19%] [G loss: 0.730979]\n",
      "epoch:20 step:19159 [D loss: 0.548376, acc.: 74.22%] [G loss: 0.707016]\n",
      "epoch:20 step:19160 [D loss: 0.589719, acc.: 57.81%] [G loss: 0.636577]\n",
      "epoch:20 step:19161 [D loss: 0.551642, acc.: 68.75%] [G loss: 0.591920]\n",
      "epoch:20 step:19162 [D loss: 0.595909, acc.: 67.97%] [G loss: 0.608545]\n",
      "epoch:20 step:19163 [D loss: 0.526940, acc.: 73.44%] [G loss: 0.693459]\n",
      "epoch:20 step:19164 [D loss: 0.570289, acc.: 67.97%] [G loss: 0.631975]\n",
      "epoch:20 step:19165 [D loss: 0.534363, acc.: 73.44%] [G loss: 0.762927]\n",
      "epoch:20 step:19166 [D loss: 0.458851, acc.: 78.12%] [G loss: 0.664014]\n",
      "epoch:20 step:19167 [D loss: 0.453594, acc.: 77.34%] [G loss: 0.779791]\n",
      "epoch:20 step:19168 [D loss: 0.518628, acc.: 73.44%] [G loss: 0.785124]\n",
      "epoch:20 step:19169 [D loss: 0.408038, acc.: 78.91%] [G loss: 0.977766]\n",
      "epoch:20 step:19170 [D loss: 0.481865, acc.: 76.56%] [G loss: 0.958881]\n",
      "epoch:20 step:19171 [D loss: 0.527351, acc.: 75.00%] [G loss: 0.870587]\n",
      "epoch:20 step:19172 [D loss: 0.569330, acc.: 69.53%] [G loss: 0.783859]\n",
      "epoch:20 step:19173 [D loss: 0.545897, acc.: 69.53%] [G loss: 0.733480]\n",
      "epoch:20 step:19174 [D loss: 0.479603, acc.: 78.12%] [G loss: 0.652152]\n",
      "epoch:20 step:19175 [D loss: 0.488977, acc.: 80.47%] [G loss: 0.695375]\n",
      "epoch:20 step:19176 [D loss: 0.498592, acc.: 71.09%] [G loss: 0.792576]\n",
      "epoch:20 step:19177 [D loss: 0.675389, acc.: 62.50%] [G loss: 0.521093]\n",
      "epoch:20 step:19178 [D loss: 0.591212, acc.: 63.28%] [G loss: 0.628086]\n",
      "epoch:20 step:19179 [D loss: 0.513507, acc.: 76.56%] [G loss: 0.705237]\n",
      "epoch:20 step:19180 [D loss: 0.530238, acc.: 66.41%] [G loss: 0.763240]\n",
      "epoch:20 step:19181 [D loss: 0.536413, acc.: 67.97%] [G loss: 0.850959]\n",
      "epoch:20 step:19182 [D loss: 0.556045, acc.: 65.62%] [G loss: 0.688366]\n",
      "epoch:20 step:19183 [D loss: 0.505703, acc.: 74.22%] [G loss: 0.648461]\n",
      "epoch:20 step:19184 [D loss: 0.465556, acc.: 78.91%] [G loss: 0.791489]\n",
      "epoch:20 step:19185 [D loss: 0.499987, acc.: 72.66%] [G loss: 0.831447]\n",
      "epoch:20 step:19186 [D loss: 0.499480, acc.: 71.88%] [G loss: 0.879158]\n",
      "epoch:20 step:19187 [D loss: 0.553731, acc.: 69.53%] [G loss: 0.798261]\n",
      "epoch:20 step:19188 [D loss: 0.545408, acc.: 68.75%] [G loss: 0.702686]\n",
      "epoch:20 step:19189 [D loss: 0.533996, acc.: 75.00%] [G loss: 0.999959]\n",
      "epoch:20 step:19190 [D loss: 0.493165, acc.: 75.00%] [G loss: 0.798814]\n",
      "epoch:20 step:19191 [D loss: 0.386029, acc.: 79.69%] [G loss: 0.866943]\n",
      "epoch:20 step:19192 [D loss: 0.486329, acc.: 81.25%] [G loss: 0.847395]\n",
      "epoch:20 step:19193 [D loss: 0.546675, acc.: 71.88%] [G loss: 0.735041]\n",
      "epoch:20 step:19194 [D loss: 0.493709, acc.: 72.66%] [G loss: 0.851992]\n",
      "epoch:20 step:19195 [D loss: 0.579567, acc.: 66.41%] [G loss: 0.642887]\n",
      "epoch:20 step:19196 [D loss: 0.572739, acc.: 71.09%] [G loss: 0.931786]\n",
      "epoch:20 step:19197 [D loss: 0.489777, acc.: 79.69%] [G loss: 0.824657]\n",
      "epoch:20 step:19198 [D loss: 0.618932, acc.: 70.31%] [G loss: 0.675665]\n",
      "epoch:20 step:19199 [D loss: 0.526698, acc.: 68.75%] [G loss: 0.616589]\n",
      "epoch:20 step:19200 [D loss: 0.510448, acc.: 73.44%] [G loss: 0.646415]\n",
      "epoch:20 step:19201 [D loss: 0.452940, acc.: 78.91%] [G loss: 0.630605]\n",
      "epoch:20 step:19202 [D loss: 0.626400, acc.: 64.06%] [G loss: 0.631059]\n",
      "epoch:20 step:19203 [D loss: 0.504609, acc.: 71.09%] [G loss: 0.721046]\n",
      "epoch:20 step:19204 [D loss: 0.499282, acc.: 71.09%] [G loss: 0.701970]\n",
      "epoch:20 step:19205 [D loss: 0.609410, acc.: 69.53%] [G loss: 0.639030]\n",
      "epoch:20 step:19206 [D loss: 0.550955, acc.: 66.41%] [G loss: 0.639686]\n",
      "epoch:20 step:19207 [D loss: 0.495107, acc.: 75.78%] [G loss: 0.698081]\n",
      "epoch:20 step:19208 [D loss: 0.562453, acc.: 68.75%] [G loss: 0.706451]\n",
      "epoch:20 step:19209 [D loss: 0.526018, acc.: 67.97%] [G loss: 0.695430]\n",
      "epoch:20 step:19210 [D loss: 0.581944, acc.: 67.19%] [G loss: 0.704993]\n",
      "epoch:20 step:19211 [D loss: 0.446985, acc.: 75.00%] [G loss: 0.914776]\n",
      "epoch:20 step:19212 [D loss: 0.469886, acc.: 77.34%] [G loss: 0.875781]\n",
      "epoch:20 step:19213 [D loss: 0.604551, acc.: 65.62%] [G loss: 0.746077]\n",
      "epoch:20 step:19214 [D loss: 0.545637, acc.: 67.19%] [G loss: 0.630552]\n",
      "epoch:20 step:19215 [D loss: 0.420708, acc.: 83.59%] [G loss: 0.894993]\n",
      "epoch:20 step:19216 [D loss: 0.463507, acc.: 79.69%] [G loss: 0.917590]\n",
      "epoch:20 step:19217 [D loss: 0.604643, acc.: 67.97%] [G loss: 0.703775]\n",
      "epoch:20 step:19218 [D loss: 0.538302, acc.: 75.00%] [G loss: 0.517727]\n",
      "epoch:20 step:19219 [D loss: 0.502506, acc.: 76.56%] [G loss: 0.536497]\n",
      "epoch:20 step:19220 [D loss: 0.569211, acc.: 72.66%] [G loss: 0.617802]\n",
      "epoch:20 step:19221 [D loss: 0.442019, acc.: 80.47%] [G loss: 0.766745]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:20 step:19222 [D loss: 0.583969, acc.: 68.75%] [G loss: 0.543598]\n",
      "epoch:20 step:19223 [D loss: 0.575577, acc.: 67.97%] [G loss: 0.639941]\n",
      "epoch:20 step:19224 [D loss: 0.497447, acc.: 72.66%] [G loss: 0.792360]\n",
      "epoch:20 step:19225 [D loss: 0.546826, acc.: 70.31%] [G loss: 0.976261]\n",
      "epoch:20 step:19226 [D loss: 0.574664, acc.: 67.97%] [G loss: 0.713818]\n",
      "epoch:20 step:19227 [D loss: 0.561431, acc.: 67.19%] [G loss: 0.569407]\n",
      "epoch:20 step:19228 [D loss: 0.455446, acc.: 77.34%] [G loss: 0.678613]\n",
      "epoch:20 step:19229 [D loss: 0.535412, acc.: 70.31%] [G loss: 0.595178]\n",
      "epoch:20 step:19230 [D loss: 0.583187, acc.: 67.97%] [G loss: 0.644995]\n",
      "epoch:20 step:19231 [D loss: 0.504782, acc.: 75.00%] [G loss: 0.711449]\n",
      "epoch:20 step:19232 [D loss: 0.499350, acc.: 72.66%] [G loss: 0.780825]\n",
      "epoch:20 step:19233 [D loss: 0.553234, acc.: 72.66%] [G loss: 0.586166]\n",
      "epoch:20 step:19234 [D loss: 0.556764, acc.: 76.56%] [G loss: 0.664586]\n",
      "epoch:20 step:19235 [D loss: 0.458433, acc.: 83.59%] [G loss: 0.664701]\n",
      "epoch:20 step:19236 [D loss: 0.552838, acc.: 70.31%] [G loss: 0.716792]\n",
      "epoch:20 step:19237 [D loss: 0.579663, acc.: 68.75%] [G loss: 0.747915]\n",
      "epoch:20 step:19238 [D loss: 0.481213, acc.: 75.78%] [G loss: 0.891808]\n",
      "epoch:20 step:19239 [D loss: 0.477189, acc.: 79.69%] [G loss: 1.141229]\n",
      "epoch:20 step:19240 [D loss: 0.534606, acc.: 71.88%] [G loss: 0.731138]\n",
      "epoch:20 step:19241 [D loss: 0.629585, acc.: 65.62%] [G loss: 0.678168]\n",
      "epoch:20 step:19242 [D loss: 0.633746, acc.: 59.38%] [G loss: 0.543593]\n",
      "epoch:20 step:19243 [D loss: 0.497995, acc.: 73.44%] [G loss: 0.667574]\n",
      "epoch:20 step:19244 [D loss: 0.469471, acc.: 79.69%] [G loss: 0.659159]\n",
      "epoch:20 step:19245 [D loss: 0.506742, acc.: 72.66%] [G loss: 0.917017]\n",
      "epoch:20 step:19246 [D loss: 0.457447, acc.: 78.12%] [G loss: 0.699009]\n",
      "epoch:20 step:19247 [D loss: 0.471530, acc.: 78.91%] [G loss: 0.995885]\n",
      "epoch:20 step:19248 [D loss: 0.388893, acc.: 82.81%] [G loss: 1.014319]\n",
      "epoch:20 step:19249 [D loss: 0.463365, acc.: 77.34%] [G loss: 1.080102]\n",
      "epoch:20 step:19250 [D loss: 0.581908, acc.: 73.44%] [G loss: 0.763862]\n",
      "epoch:20 step:19251 [D loss: 0.706999, acc.: 57.81%] [G loss: 0.530225]\n",
      "epoch:20 step:19252 [D loss: 0.559777, acc.: 66.41%] [G loss: 0.525912]\n",
      "epoch:20 step:19253 [D loss: 0.514497, acc.: 75.00%] [G loss: 0.594527]\n",
      "epoch:20 step:19254 [D loss: 0.502841, acc.: 68.75%] [G loss: 0.680644]\n",
      "epoch:20 step:19255 [D loss: 0.491243, acc.: 77.34%] [G loss: 0.807379]\n",
      "epoch:20 step:19256 [D loss: 0.495662, acc.: 71.09%] [G loss: 0.700243]\n",
      "epoch:20 step:19257 [D loss: 0.516554, acc.: 74.22%] [G loss: 0.646290]\n",
      "epoch:20 step:19258 [D loss: 0.523604, acc.: 74.22%] [G loss: 0.700712]\n",
      "epoch:20 step:19259 [D loss: 0.472654, acc.: 72.66%] [G loss: 0.747195]\n",
      "epoch:20 step:19260 [D loss: 0.467123, acc.: 77.34%] [G loss: 0.636203]\n",
      "epoch:20 step:19261 [D loss: 0.516109, acc.: 69.53%] [G loss: 0.729190]\n",
      "epoch:20 step:19262 [D loss: 0.503772, acc.: 73.44%] [G loss: 0.699909]\n",
      "epoch:20 step:19263 [D loss: 0.496327, acc.: 75.78%] [G loss: 0.769072]\n",
      "epoch:20 step:19264 [D loss: 0.578362, acc.: 67.97%] [G loss: 0.615531]\n",
      "epoch:20 step:19265 [D loss: 0.555638, acc.: 67.19%] [G loss: 0.566374]\n",
      "epoch:20 step:19266 [D loss: 0.468646, acc.: 75.00%] [G loss: 0.817113]\n",
      "epoch:20 step:19267 [D loss: 0.582054, acc.: 66.41%] [G loss: 0.680760]\n",
      "epoch:20 step:19268 [D loss: 0.669360, acc.: 57.81%] [G loss: 0.635270]\n",
      "epoch:20 step:19269 [D loss: 0.572624, acc.: 63.28%] [G loss: 0.642437]\n",
      "epoch:20 step:19270 [D loss: 0.555066, acc.: 68.75%] [G loss: 0.586536]\n",
      "epoch:20 step:19271 [D loss: 0.525863, acc.: 71.09%] [G loss: 0.733319]\n",
      "epoch:20 step:19272 [D loss: 0.543180, acc.: 68.75%] [G loss: 0.612209]\n",
      "epoch:20 step:19273 [D loss: 0.501119, acc.: 72.66%] [G loss: 0.719122]\n",
      "epoch:20 step:19274 [D loss: 0.513955, acc.: 69.53%] [G loss: 0.692981]\n",
      "epoch:20 step:19275 [D loss: 0.605735, acc.: 65.62%] [G loss: 0.563029]\n",
      "epoch:20 step:19276 [D loss: 0.521528, acc.: 70.31%] [G loss: 0.635463]\n",
      "epoch:20 step:19277 [D loss: 0.581291, acc.: 65.62%] [G loss: 0.635894]\n",
      "epoch:20 step:19278 [D loss: 0.517106, acc.: 72.66%] [G loss: 0.657159]\n",
      "epoch:20 step:19279 [D loss: 0.527022, acc.: 71.09%] [G loss: 0.566560]\n",
      "epoch:20 step:19280 [D loss: 0.501299, acc.: 71.09%] [G loss: 0.664274]\n",
      "epoch:20 step:19281 [D loss: 0.530117, acc.: 71.09%] [G loss: 0.720975]\n",
      "epoch:20 step:19282 [D loss: 0.573082, acc.: 71.09%] [G loss: 0.560345]\n",
      "epoch:20 step:19283 [D loss: 0.582479, acc.: 63.28%] [G loss: 0.607219]\n",
      "epoch:20 step:19284 [D loss: 0.562227, acc.: 62.50%] [G loss: 0.545528]\n",
      "epoch:20 step:19285 [D loss: 0.536904, acc.: 71.09%] [G loss: 0.637745]\n",
      "epoch:20 step:19286 [D loss: 0.480552, acc.: 76.56%] [G loss: 0.741905]\n",
      "epoch:20 step:19287 [D loss: 0.532829, acc.: 70.31%] [G loss: 0.815067]\n",
      "epoch:20 step:19288 [D loss: 0.452077, acc.: 75.78%] [G loss: 0.880788]\n",
      "epoch:20 step:19289 [D loss: 0.543946, acc.: 71.88%] [G loss: 0.625601]\n",
      "epoch:20 step:19290 [D loss: 0.565462, acc.: 67.19%] [G loss: 0.754748]\n",
      "epoch:20 step:19291 [D loss: 0.504822, acc.: 73.44%] [G loss: 0.604277]\n",
      "epoch:20 step:19292 [D loss: 0.477577, acc.: 75.78%] [G loss: 0.739039]\n",
      "epoch:20 step:19293 [D loss: 0.580728, acc.: 65.62%] [G loss: 0.710324]\n",
      "epoch:20 step:19294 [D loss: 0.460094, acc.: 79.69%] [G loss: 0.774499]\n",
      "epoch:20 step:19295 [D loss: 0.478677, acc.: 77.34%] [G loss: 0.763366]\n",
      "epoch:20 step:19296 [D loss: 0.542226, acc.: 71.88%] [G loss: 0.632188]\n",
      "epoch:20 step:19297 [D loss: 0.491222, acc.: 73.44%] [G loss: 0.857264]\n",
      "epoch:20 step:19298 [D loss: 0.465615, acc.: 76.56%] [G loss: 1.017871]\n",
      "epoch:20 step:19299 [D loss: 0.593209, acc.: 68.75%] [G loss: 0.730686]\n",
      "epoch:20 step:19300 [D loss: 0.486066, acc.: 78.12%] [G loss: 0.760378]\n",
      "epoch:20 step:19301 [D loss: 0.540224, acc.: 70.31%] [G loss: 0.629936]\n",
      "epoch:20 step:19302 [D loss: 0.541776, acc.: 70.31%] [G loss: 0.567625]\n",
      "epoch:20 step:19303 [D loss: 0.559686, acc.: 67.97%] [G loss: 0.578912]\n",
      "epoch:20 step:19304 [D loss: 0.474464, acc.: 75.00%] [G loss: 0.668707]\n",
      "epoch:20 step:19305 [D loss: 0.530181, acc.: 74.22%] [G loss: 0.920177]\n",
      "epoch:20 step:19306 [D loss: 0.687391, acc.: 59.38%] [G loss: 0.622451]\n",
      "epoch:20 step:19307 [D loss: 0.512701, acc.: 71.09%] [G loss: 0.780050]\n",
      "epoch:20 step:19308 [D loss: 0.496618, acc.: 73.44%] [G loss: 0.666466]\n",
      "epoch:20 step:19309 [D loss: 0.548502, acc.: 72.66%] [G loss: 0.744478]\n",
      "epoch:20 step:19310 [D loss: 0.516300, acc.: 74.22%] [G loss: 0.675235]\n",
      "epoch:20 step:19311 [D loss: 0.539094, acc.: 69.53%] [G loss: 0.669071]\n",
      "epoch:20 step:19312 [D loss: 0.573470, acc.: 69.53%] [G loss: 0.742914]\n",
      "epoch:20 step:19313 [D loss: 0.563648, acc.: 73.44%] [G loss: 0.733318]\n",
      "epoch:20 step:19314 [D loss: 0.449832, acc.: 79.69%] [G loss: 0.985458]\n",
      "epoch:20 step:19315 [D loss: 0.517944, acc.: 70.31%] [G loss: 0.926738]\n",
      "epoch:20 step:19316 [D loss: 0.592129, acc.: 69.53%] [G loss: 0.746937]\n",
      "epoch:20 step:19317 [D loss: 0.550639, acc.: 72.66%] [G loss: 0.712367]\n",
      "epoch:20 step:19318 [D loss: 0.600439, acc.: 69.53%] [G loss: 0.711561]\n",
      "epoch:20 step:19319 [D loss: 0.514041, acc.: 71.88%] [G loss: 0.566077]\n",
      "epoch:20 step:19320 [D loss: 0.515385, acc.: 73.44%] [G loss: 0.591359]\n",
      "epoch:20 step:19321 [D loss: 0.521447, acc.: 74.22%] [G loss: 0.639529]\n",
      "epoch:20 step:19322 [D loss: 0.391431, acc.: 85.16%] [G loss: 0.759818]\n",
      "epoch:20 step:19323 [D loss: 0.570171, acc.: 70.31%] [G loss: 0.738564]\n",
      "epoch:20 step:19324 [D loss: 0.590198, acc.: 64.06%] [G loss: 0.792543]\n",
      "epoch:20 step:19325 [D loss: 0.521034, acc.: 74.22%] [G loss: 0.619205]\n",
      "epoch:20 step:19326 [D loss: 0.542916, acc.: 67.97%] [G loss: 0.687338]\n",
      "epoch:20 step:19327 [D loss: 0.571657, acc.: 69.53%] [G loss: 0.600343]\n",
      "epoch:20 step:19328 [D loss: 0.555927, acc.: 61.72%] [G loss: 0.680986]\n",
      "epoch:20 step:19329 [D loss: 0.478646, acc.: 77.34%] [G loss: 0.677909]\n",
      "epoch:20 step:19330 [D loss: 0.517887, acc.: 75.00%] [G loss: 0.797846]\n",
      "epoch:20 step:19331 [D loss: 0.609007, acc.: 68.75%] [G loss: 0.556337]\n",
      "epoch:20 step:19332 [D loss: 0.479842, acc.: 79.69%] [G loss: 0.804562]\n",
      "epoch:20 step:19333 [D loss: 0.480865, acc.: 77.34%] [G loss: 0.681353]\n",
      "epoch:20 step:19334 [D loss: 0.514921, acc.: 75.00%] [G loss: 0.654216]\n",
      "epoch:20 step:19335 [D loss: 0.545678, acc.: 67.19%] [G loss: 0.705786]\n",
      "epoch:20 step:19336 [D loss: 0.521008, acc.: 74.22%] [G loss: 0.808270]\n",
      "epoch:20 step:19337 [D loss: 0.545690, acc.: 71.88%] [G loss: 0.684375]\n",
      "epoch:20 step:19338 [D loss: 0.496882, acc.: 72.66%] [G loss: 0.642140]\n",
      "epoch:20 step:19339 [D loss: 0.516535, acc.: 75.00%] [G loss: 0.717925]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:20 step:19340 [D loss: 0.586697, acc.: 65.62%] [G loss: 0.594595]\n",
      "epoch:20 step:19341 [D loss: 0.485524, acc.: 77.34%] [G loss: 0.862118]\n",
      "epoch:20 step:19342 [D loss: 0.488482, acc.: 74.22%] [G loss: 0.838413]\n",
      "epoch:20 step:19343 [D loss: 0.475112, acc.: 77.34%] [G loss: 0.837366]\n",
      "epoch:20 step:19344 [D loss: 0.592617, acc.: 68.75%] [G loss: 0.835813]\n",
      "epoch:20 step:19345 [D loss: 0.456604, acc.: 78.91%] [G loss: 0.704853]\n",
      "epoch:20 step:19346 [D loss: 0.647443, acc.: 65.62%] [G loss: 0.667407]\n",
      "epoch:20 step:19347 [D loss: 0.501975, acc.: 71.88%] [G loss: 0.698594]\n",
      "epoch:20 step:19348 [D loss: 0.543219, acc.: 70.31%] [G loss: 0.471704]\n",
      "epoch:20 step:19349 [D loss: 0.487045, acc.: 76.56%] [G loss: 0.533535]\n",
      "epoch:20 step:19350 [D loss: 0.589998, acc.: 65.62%] [G loss: 0.498263]\n",
      "epoch:20 step:19351 [D loss: 0.538823, acc.: 71.09%] [G loss: 0.518743]\n",
      "epoch:20 step:19352 [D loss: 0.547747, acc.: 70.31%] [G loss: 0.674276]\n",
      "epoch:20 step:19353 [D loss: 0.469060, acc.: 71.09%] [G loss: 0.622974]\n",
      "epoch:20 step:19354 [D loss: 0.589245, acc.: 67.97%] [G loss: 0.654772]\n",
      "epoch:20 step:19355 [D loss: 0.553642, acc.: 71.09%] [G loss: 0.505410]\n",
      "epoch:20 step:19356 [D loss: 0.514653, acc.: 75.00%] [G loss: 0.619323]\n",
      "epoch:20 step:19357 [D loss: 0.519382, acc.: 73.44%] [G loss: 0.657954]\n",
      "epoch:20 step:19358 [D loss: 0.556556, acc.: 66.41%] [G loss: 0.583758]\n",
      "epoch:20 step:19359 [D loss: 0.608282, acc.: 61.72%] [G loss: 0.665719]\n",
      "epoch:20 step:19360 [D loss: 0.566884, acc.: 67.19%] [G loss: 0.638919]\n",
      "epoch:20 step:19361 [D loss: 0.543463, acc.: 73.44%] [G loss: 0.725212]\n",
      "epoch:20 step:19362 [D loss: 0.577129, acc.: 67.97%] [G loss: 0.591814]\n",
      "epoch:20 step:19363 [D loss: 0.484340, acc.: 75.78%] [G loss: 0.782985]\n",
      "epoch:20 step:19364 [D loss: 0.470840, acc.: 76.56%] [G loss: 0.881174]\n",
      "epoch:20 step:19365 [D loss: 0.602639, acc.: 62.50%] [G loss: 0.690163]\n",
      "epoch:20 step:19366 [D loss: 0.517560, acc.: 70.31%] [G loss: 0.617568]\n",
      "epoch:20 step:19367 [D loss: 0.517720, acc.: 70.31%] [G loss: 0.605458]\n",
      "epoch:20 step:19368 [D loss: 0.548901, acc.: 66.41%] [G loss: 0.607060]\n",
      "epoch:20 step:19369 [D loss: 0.526393, acc.: 69.53%] [G loss: 0.537235]\n",
      "epoch:20 step:19370 [D loss: 0.517303, acc.: 74.22%] [G loss: 0.579146]\n",
      "epoch:20 step:19371 [D loss: 0.477350, acc.: 78.91%] [G loss: 0.558927]\n",
      "epoch:20 step:19372 [D loss: 0.468879, acc.: 71.88%] [G loss: 0.733866]\n",
      "epoch:20 step:19373 [D loss: 0.516841, acc.: 69.53%] [G loss: 0.741823]\n",
      "epoch:20 step:19374 [D loss: 0.490678, acc.: 75.00%] [G loss: 0.680105]\n",
      "epoch:20 step:19375 [D loss: 0.501391, acc.: 70.31%] [G loss: 0.836793]\n",
      "epoch:20 step:19376 [D loss: 0.594003, acc.: 64.06%] [G loss: 0.591596]\n",
      "epoch:20 step:19377 [D loss: 0.517442, acc.: 69.53%] [G loss: 0.584767]\n",
      "epoch:20 step:19378 [D loss: 0.469734, acc.: 75.78%] [G loss: 0.611894]\n",
      "epoch:20 step:19379 [D loss: 0.490296, acc.: 72.66%] [G loss: 0.657559]\n",
      "epoch:20 step:19380 [D loss: 0.590744, acc.: 69.53%] [G loss: 0.579838]\n",
      "epoch:20 step:19381 [D loss: 0.513181, acc.: 70.31%] [G loss: 0.687433]\n",
      "epoch:20 step:19382 [D loss: 0.498252, acc.: 75.00%] [G loss: 0.902680]\n",
      "epoch:20 step:19383 [D loss: 0.539892, acc.: 72.66%] [G loss: 0.899292]\n",
      "epoch:20 step:19384 [D loss: 0.525221, acc.: 69.53%] [G loss: 0.626711]\n",
      "epoch:20 step:19385 [D loss: 0.523481, acc.: 72.66%] [G loss: 0.667385]\n",
      "epoch:20 step:19386 [D loss: 0.532628, acc.: 69.53%] [G loss: 0.647426]\n",
      "epoch:20 step:19387 [D loss: 0.425524, acc.: 83.59%] [G loss: 0.940650]\n",
      "epoch:20 step:19388 [D loss: 0.373521, acc.: 85.16%] [G loss: 0.886849]\n",
      "epoch:20 step:19389 [D loss: 0.500924, acc.: 75.78%] [G loss: 0.892415]\n",
      "epoch:20 step:19390 [D loss: 0.509933, acc.: 75.00%] [G loss: 1.026873]\n",
      "epoch:20 step:19391 [D loss: 0.470808, acc.: 76.56%] [G loss: 0.741710]\n",
      "epoch:20 step:19392 [D loss: 0.576646, acc.: 67.19%] [G loss: 0.764109]\n",
      "epoch:20 step:19393 [D loss: 0.550063, acc.: 70.31%] [G loss: 0.750749]\n",
      "epoch:20 step:19394 [D loss: 0.435399, acc.: 78.12%] [G loss: 0.824646]\n",
      "epoch:20 step:19395 [D loss: 0.587440, acc.: 67.19%] [G loss: 0.565118]\n",
      "epoch:20 step:19396 [D loss: 0.542130, acc.: 70.31%] [G loss: 0.739688]\n",
      "epoch:20 step:19397 [D loss: 0.542201, acc.: 70.31%] [G loss: 0.678063]\n",
      "epoch:20 step:19398 [D loss: 0.602782, acc.: 67.19%] [G loss: 0.589584]\n",
      "epoch:20 step:19399 [D loss: 0.553805, acc.: 70.31%] [G loss: 0.530424]\n",
      "epoch:20 step:19400 [D loss: 0.506387, acc.: 69.53%] [G loss: 0.786217]\n",
      "epoch:20 step:19401 [D loss: 0.490616, acc.: 77.34%] [G loss: 0.657145]\n",
      "epoch:20 step:19402 [D loss: 0.508183, acc.: 73.44%] [G loss: 0.614067]\n",
      "epoch:20 step:19403 [D loss: 0.552284, acc.: 67.97%] [G loss: 0.628725]\n",
      "epoch:20 step:19404 [D loss: 0.498480, acc.: 74.22%] [G loss: 0.895841]\n",
      "epoch:20 step:19405 [D loss: 0.527284, acc.: 74.22%] [G loss: 0.714515]\n",
      "epoch:20 step:19406 [D loss: 0.527615, acc.: 73.44%] [G loss: 0.707329]\n",
      "epoch:20 step:19407 [D loss: 0.535860, acc.: 71.88%] [G loss: 0.713218]\n",
      "epoch:20 step:19408 [D loss: 0.617005, acc.: 67.19%] [G loss: 0.664732]\n",
      "epoch:20 step:19409 [D loss: 0.532913, acc.: 67.97%] [G loss: 0.803361]\n",
      "epoch:20 step:19410 [D loss: 0.552388, acc.: 64.06%] [G loss: 0.633815]\n",
      "epoch:20 step:19411 [D loss: 0.538773, acc.: 70.31%] [G loss: 0.691816]\n",
      "epoch:20 step:19412 [D loss: 0.584014, acc.: 64.06%] [G loss: 0.583340]\n",
      "epoch:20 step:19413 [D loss: 0.563260, acc.: 71.09%] [G loss: 0.638342]\n",
      "epoch:20 step:19414 [D loss: 0.480032, acc.: 72.66%] [G loss: 0.682930]\n",
      "epoch:20 step:19415 [D loss: 0.551907, acc.: 69.53%] [G loss: 0.653000]\n",
      "epoch:20 step:19416 [D loss: 0.568482, acc.: 67.97%] [G loss: 0.795831]\n",
      "epoch:20 step:19417 [D loss: 0.499763, acc.: 75.78%] [G loss: 0.630390]\n",
      "epoch:20 step:19418 [D loss: 0.543460, acc.: 70.31%] [G loss: 0.704306]\n",
      "epoch:20 step:19419 [D loss: 0.460485, acc.: 78.91%] [G loss: 0.664484]\n",
      "epoch:20 step:19420 [D loss: 0.549428, acc.: 73.44%] [G loss: 0.554286]\n",
      "epoch:20 step:19421 [D loss: 0.474794, acc.: 76.56%] [G loss: 0.719578]\n",
      "epoch:20 step:19422 [D loss: 0.550820, acc.: 73.44%] [G loss: 0.705696]\n",
      "epoch:20 step:19423 [D loss: 0.520434, acc.: 73.44%] [G loss: 0.708007]\n",
      "epoch:20 step:19424 [D loss: 0.611798, acc.: 65.62%] [G loss: 0.523506]\n",
      "epoch:20 step:19425 [D loss: 0.520447, acc.: 74.22%] [G loss: 0.726181]\n",
      "epoch:20 step:19426 [D loss: 0.613099, acc.: 68.75%] [G loss: 0.516127]\n",
      "epoch:20 step:19427 [D loss: 0.547976, acc.: 71.09%] [G loss: 0.610751]\n",
      "epoch:20 step:19428 [D loss: 0.524706, acc.: 71.09%] [G loss: 0.615191]\n",
      "epoch:20 step:19429 [D loss: 0.557003, acc.: 69.53%] [G loss: 0.706095]\n",
      "epoch:20 step:19430 [D loss: 0.475636, acc.: 74.22%] [G loss: 0.682671]\n",
      "epoch:20 step:19431 [D loss: 0.492543, acc.: 75.78%] [G loss: 0.683463]\n",
      "epoch:20 step:19432 [D loss: 0.509386, acc.: 75.78%] [G loss: 0.772208]\n",
      "epoch:20 step:19433 [D loss: 0.510801, acc.: 72.66%] [G loss: 0.805672]\n",
      "epoch:20 step:19434 [D loss: 0.506660, acc.: 72.66%] [G loss: 0.758745]\n",
      "epoch:20 step:19435 [D loss: 0.515521, acc.: 77.34%] [G loss: 0.750274]\n",
      "epoch:20 step:19436 [D loss: 0.631214, acc.: 60.94%] [G loss: 0.539324]\n",
      "epoch:20 step:19437 [D loss: 0.570102, acc.: 65.62%] [G loss: 0.511644]\n",
      "epoch:20 step:19438 [D loss: 0.543120, acc.: 69.53%] [G loss: 0.636745]\n",
      "epoch:20 step:19439 [D loss: 0.473720, acc.: 76.56%] [G loss: 0.779753]\n",
      "epoch:20 step:19440 [D loss: 0.515732, acc.: 70.31%] [G loss: 0.714521]\n",
      "epoch:20 step:19441 [D loss: 0.460467, acc.: 80.47%] [G loss: 0.968165]\n",
      "epoch:20 step:19442 [D loss: 0.585393, acc.: 69.53%] [G loss: 0.741751]\n",
      "epoch:20 step:19443 [D loss: 0.606629, acc.: 65.62%] [G loss: 0.660820]\n",
      "epoch:20 step:19444 [D loss: 0.597541, acc.: 67.97%] [G loss: 0.443356]\n",
      "epoch:20 step:19445 [D loss: 0.508443, acc.: 73.44%] [G loss: 0.533551]\n",
      "epoch:20 step:19446 [D loss: 0.493069, acc.: 75.00%] [G loss: 0.651373]\n",
      "epoch:20 step:19447 [D loss: 0.455968, acc.: 74.22%] [G loss: 0.752999]\n",
      "epoch:20 step:19448 [D loss: 0.545188, acc.: 75.78%] [G loss: 0.558138]\n",
      "epoch:20 step:19449 [D loss: 0.532900, acc.: 69.53%] [G loss: 0.701759]\n",
      "epoch:20 step:19450 [D loss: 0.534437, acc.: 73.44%] [G loss: 0.670493]\n",
      "epoch:20 step:19451 [D loss: 0.559982, acc.: 68.75%] [G loss: 0.647012]\n",
      "epoch:20 step:19452 [D loss: 0.540655, acc.: 71.88%] [G loss: 0.587690]\n",
      "epoch:20 step:19453 [D loss: 0.619445, acc.: 63.28%] [G loss: 0.642821]\n",
      "epoch:20 step:19454 [D loss: 0.524029, acc.: 71.88%] [G loss: 0.701939]\n",
      "epoch:20 step:19455 [D loss: 0.525051, acc.: 73.44%] [G loss: 0.751431]\n",
      "epoch:20 step:19456 [D loss: 0.619723, acc.: 63.28%] [G loss: 0.662296]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:20 step:19457 [D loss: 0.526814, acc.: 70.31%] [G loss: 0.755500]\n",
      "epoch:20 step:19458 [D loss: 0.546576, acc.: 73.44%] [G loss: 0.659126]\n",
      "epoch:20 step:19459 [D loss: 0.489833, acc.: 74.22%] [G loss: 0.764568]\n",
      "epoch:20 step:19460 [D loss: 0.594703, acc.: 65.62%] [G loss: 0.594127]\n",
      "epoch:20 step:19461 [D loss: 0.602647, acc.: 69.53%] [G loss: 0.809334]\n",
      "epoch:20 step:19462 [D loss: 0.510740, acc.: 77.34%] [G loss: 0.694012]\n",
      "epoch:20 step:19463 [D loss: 0.533510, acc.: 73.44%] [G loss: 0.611691]\n",
      "epoch:20 step:19464 [D loss: 0.457839, acc.: 82.81%] [G loss: 0.741334]\n",
      "epoch:20 step:19465 [D loss: 0.447939, acc.: 78.91%] [G loss: 0.719250]\n",
      "epoch:20 step:19466 [D loss: 0.474567, acc.: 74.22%] [G loss: 0.811881]\n",
      "epoch:20 step:19467 [D loss: 0.568848, acc.: 69.53%] [G loss: 0.715575]\n",
      "epoch:20 step:19468 [D loss: 0.560275, acc.: 65.62%] [G loss: 0.563148]\n",
      "epoch:20 step:19469 [D loss: 0.542554, acc.: 73.44%] [G loss: 0.503598]\n",
      "epoch:20 step:19470 [D loss: 0.522335, acc.: 68.75%] [G loss: 0.647794]\n",
      "epoch:20 step:19471 [D loss: 0.562558, acc.: 68.75%] [G loss: 0.756390]\n",
      "epoch:20 step:19472 [D loss: 0.514001, acc.: 69.53%] [G loss: 0.587173]\n",
      "epoch:20 step:19473 [D loss: 0.530986, acc.: 69.53%] [G loss: 0.626233]\n",
      "epoch:20 step:19474 [D loss: 0.553150, acc.: 64.06%] [G loss: 0.644440]\n",
      "epoch:20 step:19475 [D loss: 0.545713, acc.: 67.97%] [G loss: 0.598468]\n",
      "epoch:20 step:19476 [D loss: 0.512600, acc.: 71.88%] [G loss: 0.646991]\n",
      "epoch:20 step:19477 [D loss: 0.501283, acc.: 76.56%] [G loss: 0.729348]\n",
      "epoch:20 step:19478 [D loss: 0.530716, acc.: 71.09%] [G loss: 0.518334]\n",
      "epoch:20 step:19479 [D loss: 0.543498, acc.: 71.09%] [G loss: 0.559935]\n",
      "epoch:20 step:19480 [D loss: 0.621177, acc.: 64.06%] [G loss: 0.490814]\n",
      "epoch:20 step:19481 [D loss: 0.457758, acc.: 77.34%] [G loss: 0.613659]\n",
      "epoch:20 step:19482 [D loss: 0.527260, acc.: 70.31%] [G loss: 0.549297]\n",
      "epoch:20 step:19483 [D loss: 0.516910, acc.: 71.09%] [G loss: 0.801237]\n",
      "epoch:20 step:19484 [D loss: 0.488777, acc.: 77.34%] [G loss: 0.881640]\n",
      "epoch:20 step:19485 [D loss: 0.578644, acc.: 67.19%] [G loss: 0.551538]\n",
      "epoch:20 step:19486 [D loss: 0.477407, acc.: 78.12%] [G loss: 0.723427]\n",
      "epoch:20 step:19487 [D loss: 0.440174, acc.: 75.78%] [G loss: 0.687250]\n",
      "epoch:20 step:19488 [D loss: 0.512363, acc.: 70.31%] [G loss: 0.785471]\n",
      "epoch:20 step:19489 [D loss: 0.489487, acc.: 78.12%] [G loss: 0.664446]\n",
      "epoch:20 step:19490 [D loss: 0.521595, acc.: 71.09%] [G loss: 0.659572]\n",
      "epoch:20 step:19491 [D loss: 0.479218, acc.: 75.78%] [G loss: 0.831837]\n",
      "epoch:20 step:19492 [D loss: 0.548084, acc.: 73.44%] [G loss: 0.615504]\n",
      "epoch:20 step:19493 [D loss: 0.510211, acc.: 71.88%] [G loss: 0.727451]\n",
      "epoch:20 step:19494 [D loss: 0.540228, acc.: 67.19%] [G loss: 0.832303]\n",
      "epoch:20 step:19495 [D loss: 0.562016, acc.: 70.31%] [G loss: 0.893804]\n",
      "epoch:20 step:19496 [D loss: 0.567663, acc.: 72.66%] [G loss: 0.712168]\n",
      "epoch:20 step:19497 [D loss: 0.535489, acc.: 74.22%] [G loss: 0.739927]\n",
      "epoch:20 step:19498 [D loss: 0.650765, acc.: 68.75%] [G loss: 0.676385]\n",
      "epoch:20 step:19499 [D loss: 0.607741, acc.: 63.28%] [G loss: 0.469493]\n",
      "epoch:20 step:19500 [D loss: 0.499296, acc.: 70.31%] [G loss: 0.829762]\n",
      "epoch:20 step:19501 [D loss: 0.569513, acc.: 66.41%] [G loss: 0.546445]\n",
      "epoch:20 step:19502 [D loss: 0.539089, acc.: 72.66%] [G loss: 0.555515]\n",
      "epoch:20 step:19503 [D loss: 0.538472, acc.: 70.31%] [G loss: 0.570136]\n",
      "epoch:20 step:19504 [D loss: 0.607129, acc.: 66.41%] [G loss: 0.594338]\n",
      "epoch:20 step:19505 [D loss: 0.548455, acc.: 72.66%] [G loss: 0.545270]\n",
      "epoch:20 step:19506 [D loss: 0.657396, acc.: 58.59%] [G loss: 0.398120]\n",
      "epoch:20 step:19507 [D loss: 0.525940, acc.: 72.66%] [G loss: 0.563303]\n",
      "epoch:20 step:19508 [D loss: 0.475188, acc.: 78.12%] [G loss: 0.755381]\n",
      "epoch:20 step:19509 [D loss: 0.551437, acc.: 73.44%] [G loss: 0.981056]\n",
      "epoch:20 step:19510 [D loss: 0.473522, acc.: 75.00%] [G loss: 0.990055]\n",
      "epoch:20 step:19511 [D loss: 0.552373, acc.: 69.53%] [G loss: 0.849433]\n",
      "epoch:20 step:19512 [D loss: 0.593499, acc.: 64.84%] [G loss: 0.685323]\n",
      "epoch:20 step:19513 [D loss: 0.547702, acc.: 67.97%] [G loss: 0.755501]\n",
      "epoch:20 step:19514 [D loss: 0.524998, acc.: 75.78%] [G loss: 0.668160]\n",
      "epoch:20 step:19515 [D loss: 0.524531, acc.: 73.44%] [G loss: 0.834097]\n",
      "epoch:20 step:19516 [D loss: 0.540495, acc.: 68.75%] [G loss: 0.666264]\n",
      "epoch:20 step:19517 [D loss: 0.512139, acc.: 75.78%] [G loss: 0.713747]\n",
      "epoch:20 step:19518 [D loss: 0.507873, acc.: 73.44%] [G loss: 0.568811]\n",
      "epoch:20 step:19519 [D loss: 0.534085, acc.: 74.22%] [G loss: 0.652570]\n",
      "epoch:20 step:19520 [D loss: 0.499373, acc.: 73.44%] [G loss: 0.749560]\n",
      "epoch:20 step:19521 [D loss: 0.444828, acc.: 82.81%] [G loss: 0.993536]\n",
      "epoch:20 step:19522 [D loss: 0.511445, acc.: 71.88%] [G loss: 0.841586]\n",
      "epoch:20 step:19523 [D loss: 0.594590, acc.: 64.06%] [G loss: 0.773902]\n",
      "epoch:20 step:19524 [D loss: 0.579131, acc.: 62.50%] [G loss: 0.777215]\n",
      "epoch:20 step:19525 [D loss: 0.511093, acc.: 74.22%] [G loss: 0.749287]\n",
      "epoch:20 step:19526 [D loss: 0.520462, acc.: 75.00%] [G loss: 0.625488]\n",
      "epoch:20 step:19527 [D loss: 0.581176, acc.: 71.09%] [G loss: 0.789540]\n",
      "epoch:20 step:19528 [D loss: 0.591605, acc.: 66.41%] [G loss: 0.622517]\n",
      "epoch:20 step:19529 [D loss: 0.497672, acc.: 73.44%] [G loss: 0.665026]\n",
      "epoch:20 step:19530 [D loss: 0.521524, acc.: 70.31%] [G loss: 0.662191]\n",
      "epoch:20 step:19531 [D loss: 0.529857, acc.: 71.09%] [G loss: 0.586340]\n",
      "epoch:20 step:19532 [D loss: 0.475981, acc.: 70.31%] [G loss: 0.743245]\n",
      "epoch:20 step:19533 [D loss: 0.519790, acc.: 71.88%] [G loss: 0.752288]\n",
      "epoch:20 step:19534 [D loss: 0.605199, acc.: 63.28%] [G loss: 0.742532]\n",
      "epoch:20 step:19535 [D loss: 0.533338, acc.: 69.53%] [G loss: 0.645184]\n",
      "epoch:20 step:19536 [D loss: 0.504656, acc.: 72.66%] [G loss: 0.761551]\n",
      "epoch:20 step:19537 [D loss: 0.521517, acc.: 72.66%] [G loss: 0.752935]\n",
      "epoch:20 step:19538 [D loss: 0.539717, acc.: 69.53%] [G loss: 0.692629]\n",
      "epoch:20 step:19539 [D loss: 0.545628, acc.: 70.31%] [G loss: 0.647928]\n",
      "epoch:20 step:19540 [D loss: 0.622375, acc.: 64.06%] [G loss: 0.702671]\n",
      "epoch:20 step:19541 [D loss: 0.481427, acc.: 76.56%] [G loss: 0.731390]\n",
      "epoch:20 step:19542 [D loss: 0.452182, acc.: 80.47%] [G loss: 0.793742]\n",
      "epoch:20 step:19543 [D loss: 0.486065, acc.: 78.12%] [G loss: 0.739988]\n",
      "epoch:20 step:19544 [D loss: 0.567399, acc.: 70.31%] [G loss: 0.536317]\n",
      "epoch:20 step:19545 [D loss: 0.500808, acc.: 76.56%] [G loss: 0.690269]\n",
      "epoch:20 step:19546 [D loss: 0.542473, acc.: 71.09%] [G loss: 0.608617]\n",
      "epoch:20 step:19547 [D loss: 0.542580, acc.: 69.53%] [G loss: 0.616795]\n",
      "epoch:20 step:19548 [D loss: 0.540074, acc.: 70.31%] [G loss: 0.626321]\n",
      "epoch:20 step:19549 [D loss: 0.495006, acc.: 76.56%] [G loss: 0.770390]\n",
      "epoch:20 step:19550 [D loss: 0.496652, acc.: 76.56%] [G loss: 0.547537]\n",
      "epoch:20 step:19551 [D loss: 0.615940, acc.: 66.41%] [G loss: 0.767558]\n",
      "epoch:20 step:19552 [D loss: 0.624887, acc.: 64.84%] [G loss: 0.643367]\n",
      "epoch:20 step:19553 [D loss: 0.517856, acc.: 72.66%] [G loss: 0.558264]\n",
      "epoch:20 step:19554 [D loss: 0.495910, acc.: 73.44%] [G loss: 0.819500]\n",
      "epoch:20 step:19555 [D loss: 0.481006, acc.: 78.12%] [G loss: 0.958930]\n",
      "epoch:20 step:19556 [D loss: 0.526114, acc.: 75.78%] [G loss: 0.876150]\n",
      "epoch:20 step:19557 [D loss: 0.545385, acc.: 70.31%] [G loss: 0.668514]\n",
      "epoch:20 step:19558 [D loss: 0.584933, acc.: 67.19%] [G loss: 0.590856]\n",
      "epoch:20 step:19559 [D loss: 0.521155, acc.: 76.56%] [G loss: 0.676201]\n",
      "epoch:20 step:19560 [D loss: 0.695127, acc.: 61.72%] [G loss: 0.554881]\n",
      "epoch:20 step:19561 [D loss: 0.533585, acc.: 70.31%] [G loss: 0.583882]\n",
      "epoch:20 step:19562 [D loss: 0.553508, acc.: 68.75%] [G loss: 0.586460]\n",
      "epoch:20 step:19563 [D loss: 0.413599, acc.: 76.56%] [G loss: 0.713842]\n",
      "epoch:20 step:19564 [D loss: 0.563239, acc.: 71.88%] [G loss: 0.634924]\n",
      "epoch:20 step:19565 [D loss: 0.512055, acc.: 75.78%] [G loss: 0.545611]\n",
      "epoch:20 step:19566 [D loss: 0.522447, acc.: 69.53%] [G loss: 0.687126]\n",
      "epoch:20 step:19567 [D loss: 0.541234, acc.: 70.31%] [G loss: 0.570764]\n",
      "epoch:20 step:19568 [D loss: 0.629426, acc.: 65.62%] [G loss: 0.579787]\n",
      "epoch:20 step:19569 [D loss: 0.544209, acc.: 69.53%] [G loss: 0.566212]\n",
      "epoch:20 step:19570 [D loss: 0.531998, acc.: 71.88%] [G loss: 0.678326]\n",
      "epoch:20 step:19571 [D loss: 0.516701, acc.: 74.22%] [G loss: 0.639424]\n",
      "epoch:20 step:19572 [D loss: 0.523080, acc.: 69.53%] [G loss: 0.627332]\n",
      "epoch:20 step:19573 [D loss: 0.490082, acc.: 78.91%] [G loss: 0.643622]\n",
      "epoch:20 step:19574 [D loss: 0.509744, acc.: 68.75%] [G loss: 0.639212]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:20 step:19575 [D loss: 0.526866, acc.: 69.53%] [G loss: 0.593916]\n",
      "epoch:20 step:19576 [D loss: 0.526900, acc.: 71.09%] [G loss: 0.620436]\n",
      "epoch:20 step:19577 [D loss: 0.512970, acc.: 73.44%] [G loss: 0.492483]\n",
      "epoch:20 step:19578 [D loss: 0.509022, acc.: 74.22%] [G loss: 0.663967]\n",
      "epoch:20 step:19579 [D loss: 0.514198, acc.: 74.22%] [G loss: 0.612286]\n",
      "epoch:20 step:19580 [D loss: 0.580879, acc.: 67.97%] [G loss: 0.463853]\n",
      "epoch:20 step:19581 [D loss: 0.543164, acc.: 70.31%] [G loss: 0.641563]\n",
      "epoch:20 step:19582 [D loss: 0.496551, acc.: 69.53%] [G loss: 0.570008]\n",
      "epoch:20 step:19583 [D loss: 0.505412, acc.: 76.56%] [G loss: 0.721004]\n",
      "epoch:20 step:19584 [D loss: 0.552884, acc.: 71.88%] [G loss: 0.651563]\n",
      "epoch:20 step:19585 [D loss: 0.593384, acc.: 67.97%] [G loss: 0.653417]\n",
      "epoch:20 step:19586 [D loss: 0.586418, acc.: 66.41%] [G loss: 0.478707]\n",
      "epoch:20 step:19587 [D loss: 0.618109, acc.: 57.03%] [G loss: 0.468157]\n",
      "epoch:20 step:19588 [D loss: 0.542146, acc.: 67.97%] [G loss: 0.555828]\n",
      "epoch:20 step:19589 [D loss: 0.523218, acc.: 71.88%] [G loss: 0.550011]\n",
      "epoch:20 step:19590 [D loss: 0.547208, acc.: 64.84%] [G loss: 0.556234]\n",
      "epoch:20 step:19591 [D loss: 0.552665, acc.: 67.19%] [G loss: 0.631409]\n",
      "epoch:20 step:19592 [D loss: 0.554272, acc.: 66.41%] [G loss: 0.475078]\n",
      "epoch:20 step:19593 [D loss: 0.591434, acc.: 64.84%] [G loss: 0.610356]\n",
      "epoch:20 step:19594 [D loss: 0.485842, acc.: 72.66%] [G loss: 0.688188]\n",
      "epoch:20 step:19595 [D loss: 0.481534, acc.: 78.91%] [G loss: 0.761960]\n",
      "epoch:20 step:19596 [D loss: 0.547366, acc.: 69.53%] [G loss: 0.667265]\n",
      "epoch:20 step:19597 [D loss: 0.466125, acc.: 75.78%] [G loss: 0.756349]\n",
      "epoch:20 step:19598 [D loss: 0.594735, acc.: 67.97%] [G loss: 0.673863]\n",
      "epoch:20 step:19599 [D loss: 0.518586, acc.: 72.66%] [G loss: 0.548123]\n",
      "epoch:20 step:19600 [D loss: 0.437442, acc.: 81.25%] [G loss: 0.774801]\n",
      "epoch:20 step:19601 [D loss: 0.637645, acc.: 64.06%] [G loss: 0.587568]\n",
      "epoch:20 step:19602 [D loss: 0.554081, acc.: 69.53%] [G loss: 0.633777]\n",
      "epoch:20 step:19603 [D loss: 0.535929, acc.: 72.66%] [G loss: 0.584514]\n",
      "epoch:20 step:19604 [D loss: 0.523365, acc.: 69.53%] [G loss: 0.485672]\n",
      "epoch:20 step:19605 [D loss: 0.625772, acc.: 60.94%] [G loss: 0.645577]\n",
      "epoch:20 step:19606 [D loss: 0.493014, acc.: 69.53%] [G loss: 0.704024]\n",
      "epoch:20 step:19607 [D loss: 0.666681, acc.: 62.50%] [G loss: 0.391705]\n",
      "epoch:20 step:19608 [D loss: 0.513624, acc.: 70.31%] [G loss: 0.454775]\n",
      "epoch:20 step:19609 [D loss: 0.547158, acc.: 68.75%] [G loss: 0.495698]\n",
      "epoch:20 step:19610 [D loss: 0.479067, acc.: 75.78%] [G loss: 0.686590]\n",
      "epoch:20 step:19611 [D loss: 0.506359, acc.: 76.56%] [G loss: 0.594912]\n",
      "epoch:20 step:19612 [D loss: 0.541151, acc.: 71.09%] [G loss: 0.637665]\n",
      "epoch:20 step:19613 [D loss: 0.554216, acc.: 71.09%] [G loss: 0.759928]\n",
      "epoch:20 step:19614 [D loss: 0.526719, acc.: 71.88%] [G loss: 0.609200]\n",
      "epoch:20 step:19615 [D loss: 0.456516, acc.: 76.56%] [G loss: 0.942891]\n",
      "epoch:20 step:19616 [D loss: 0.588345, acc.: 65.62%] [G loss: 0.642421]\n",
      "epoch:20 step:19617 [D loss: 0.636442, acc.: 61.72%] [G loss: 0.396205]\n",
      "epoch:20 step:19618 [D loss: 0.549332, acc.: 69.53%] [G loss: 0.670642]\n",
      "epoch:20 step:19619 [D loss: 0.554115, acc.: 72.66%] [G loss: 0.688459]\n",
      "epoch:20 step:19620 [D loss: 0.614665, acc.: 62.50%] [G loss: 0.569668]\n",
      "epoch:20 step:19621 [D loss: 0.569969, acc.: 65.62%] [G loss: 0.463105]\n",
      "epoch:20 step:19622 [D loss: 0.578394, acc.: 69.53%] [G loss: 0.545460]\n",
      "epoch:20 step:19623 [D loss: 0.591505, acc.: 66.41%] [G loss: 0.513410]\n",
      "epoch:20 step:19624 [D loss: 0.467925, acc.: 76.56%] [G loss: 0.681955]\n",
      "epoch:20 step:19625 [D loss: 0.487648, acc.: 77.34%] [G loss: 0.759721]\n",
      "epoch:20 step:19626 [D loss: 0.517834, acc.: 73.44%] [G loss: 0.814272]\n",
      "epoch:20 step:19627 [D loss: 0.544465, acc.: 67.97%] [G loss: 0.809839]\n",
      "epoch:20 step:19628 [D loss: 0.545310, acc.: 69.53%] [G loss: 0.705505]\n",
      "epoch:20 step:19629 [D loss: 0.545130, acc.: 73.44%] [G loss: 0.516072]\n",
      "epoch:20 step:19630 [D loss: 0.476427, acc.: 76.56%] [G loss: 0.699311]\n",
      "epoch:20 step:19631 [D loss: 0.549137, acc.: 69.53%] [G loss: 0.573950]\n",
      "epoch:20 step:19632 [D loss: 0.589888, acc.: 65.62%] [G loss: 0.529435]\n",
      "epoch:20 step:19633 [D loss: 0.561812, acc.: 68.75%] [G loss: 0.627759]\n",
      "epoch:20 step:19634 [D loss: 0.460555, acc.: 80.47%] [G loss: 0.537123]\n",
      "epoch:20 step:19635 [D loss: 0.557810, acc.: 70.31%] [G loss: 0.618961]\n",
      "epoch:20 step:19636 [D loss: 0.501982, acc.: 78.12%] [G loss: 0.723159]\n",
      "epoch:20 step:19637 [D loss: 0.466349, acc.: 75.78%] [G loss: 0.783393]\n",
      "epoch:20 step:19638 [D loss: 0.452254, acc.: 78.12%] [G loss: 0.810935]\n",
      "epoch:20 step:19639 [D loss: 0.443968, acc.: 78.12%] [G loss: 0.734083]\n",
      "epoch:20 step:19640 [D loss: 0.523227, acc.: 74.22%] [G loss: 0.800210]\n",
      "epoch:20 step:19641 [D loss: 0.513231, acc.: 75.78%] [G loss: 0.860546]\n",
      "epoch:20 step:19642 [D loss: 0.557853, acc.: 67.97%] [G loss: 0.643015]\n",
      "epoch:20 step:19643 [D loss: 0.515204, acc.: 76.56%] [G loss: 0.716716]\n",
      "epoch:20 step:19644 [D loss: 0.604189, acc.: 60.94%] [G loss: 0.685184]\n",
      "epoch:20 step:19645 [D loss: 0.587454, acc.: 67.19%] [G loss: 0.774152]\n",
      "epoch:20 step:19646 [D loss: 0.489664, acc.: 75.00%] [G loss: 0.812294]\n",
      "epoch:20 step:19647 [D loss: 0.573223, acc.: 67.97%] [G loss: 0.715852]\n",
      "epoch:20 step:19648 [D loss: 0.535302, acc.: 75.00%] [G loss: 0.810571]\n",
      "epoch:20 step:19649 [D loss: 0.513073, acc.: 69.53%] [G loss: 0.669111]\n",
      "epoch:20 step:19650 [D loss: 0.534849, acc.: 71.09%] [G loss: 0.598142]\n",
      "epoch:20 step:19651 [D loss: 0.503378, acc.: 76.56%] [G loss: 0.720668]\n",
      "epoch:20 step:19652 [D loss: 0.498268, acc.: 75.00%] [G loss: 0.722464]\n",
      "epoch:20 step:19653 [D loss: 0.552755, acc.: 71.09%] [G loss: 0.965438]\n",
      "epoch:20 step:19654 [D loss: 0.469195, acc.: 75.78%] [G loss: 0.837947]\n",
      "epoch:20 step:19655 [D loss: 0.655908, acc.: 62.50%] [G loss: 0.787321]\n",
      "epoch:20 step:19656 [D loss: 0.485969, acc.: 76.56%] [G loss: 0.876980]\n",
      "epoch:20 step:19657 [D loss: 0.547556, acc.: 71.88%] [G loss: 0.680675]\n",
      "epoch:20 step:19658 [D loss: 0.462192, acc.: 75.78%] [G loss: 0.826052]\n",
      "epoch:20 step:19659 [D loss: 0.424774, acc.: 80.47%] [G loss: 0.925636]\n",
      "epoch:20 step:19660 [D loss: 0.653244, acc.: 62.50%] [G loss: 0.843736]\n",
      "epoch:20 step:19661 [D loss: 0.460448, acc.: 78.12%] [G loss: 0.872239]\n",
      "epoch:20 step:19662 [D loss: 0.573740, acc.: 63.28%] [G loss: 0.753495]\n",
      "epoch:20 step:19663 [D loss: 0.448321, acc.: 76.56%] [G loss: 0.693628]\n",
      "epoch:20 step:19664 [D loss: 0.426369, acc.: 79.69%] [G loss: 0.923758]\n",
      "epoch:20 step:19665 [D loss: 0.399557, acc.: 80.47%] [G loss: 1.237277]\n",
      "epoch:20 step:19666 [D loss: 0.452701, acc.: 76.56%] [G loss: 1.340296]\n",
      "epoch:20 step:19667 [D loss: 0.471027, acc.: 76.56%] [G loss: 1.488190]\n",
      "epoch:20 step:19668 [D loss: 0.789168, acc.: 62.50%] [G loss: 0.889204]\n",
      "epoch:20 step:19669 [D loss: 0.571581, acc.: 71.09%] [G loss: 1.255873]\n",
      "epoch:20 step:19670 [D loss: 0.469646, acc.: 72.66%] [G loss: 1.316823]\n",
      "epoch:20 step:19671 [D loss: 0.558917, acc.: 64.84%] [G loss: 0.848278]\n",
      "epoch:20 step:19672 [D loss: 0.610443, acc.: 64.06%] [G loss: 0.686881]\n",
      "epoch:20 step:19673 [D loss: 0.497710, acc.: 74.22%] [G loss: 0.968082]\n",
      "epoch:20 step:19674 [D loss: 0.550481, acc.: 65.62%] [G loss: 0.944507]\n",
      "epoch:20 step:19675 [D loss: 0.482197, acc.: 74.22%] [G loss: 0.974585]\n",
      "epoch:20 step:19676 [D loss: 0.441526, acc.: 75.00%] [G loss: 1.165924]\n",
      "epoch:20 step:19677 [D loss: 0.416238, acc.: 83.59%] [G loss: 1.183380]\n",
      "epoch:21 step:19678 [D loss: 0.628777, acc.: 66.41%] [G loss: 1.121231]\n",
      "epoch:21 step:19679 [D loss: 0.468673, acc.: 75.00%] [G loss: 1.151554]\n",
      "epoch:21 step:19680 [D loss: 0.560937, acc.: 72.66%] [G loss: 0.868018]\n",
      "epoch:21 step:19681 [D loss: 0.478708, acc.: 76.56%] [G loss: 0.849038]\n",
      "epoch:21 step:19682 [D loss: 0.527334, acc.: 73.44%] [G loss: 0.747663]\n",
      "epoch:21 step:19683 [D loss: 0.618703, acc.: 64.06%] [G loss: 0.655658]\n",
      "epoch:21 step:19684 [D loss: 0.492912, acc.: 75.00%] [G loss: 0.956193]\n",
      "epoch:21 step:19685 [D loss: 0.464651, acc.: 80.47%] [G loss: 0.777307]\n",
      "epoch:21 step:19686 [D loss: 0.475762, acc.: 75.00%] [G loss: 0.774394]\n",
      "epoch:21 step:19687 [D loss: 0.513688, acc.: 73.44%] [G loss: 0.828609]\n",
      "epoch:21 step:19688 [D loss: 0.457397, acc.: 82.81%] [G loss: 0.995748]\n",
      "epoch:21 step:19689 [D loss: 0.545990, acc.: 68.75%] [G loss: 0.853251]\n",
      "epoch:21 step:19690 [D loss: 0.544775, acc.: 71.09%] [G loss: 0.553121]\n",
      "epoch:21 step:19691 [D loss: 0.533988, acc.: 73.44%] [G loss: 0.603289]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:21 step:19692 [D loss: 0.479188, acc.: 76.56%] [G loss: 0.799269]\n",
      "epoch:21 step:19693 [D loss: 0.474108, acc.: 76.56%] [G loss: 0.988838]\n",
      "epoch:21 step:19694 [D loss: 0.572543, acc.: 71.09%] [G loss: 0.978221]\n",
      "epoch:21 step:19695 [D loss: 0.608379, acc.: 69.53%] [G loss: 0.730957]\n",
      "epoch:21 step:19696 [D loss: 0.588668, acc.: 68.75%] [G loss: 0.723657]\n",
      "epoch:21 step:19697 [D loss: 0.647747, acc.: 61.72%] [G loss: 0.687518]\n",
      "epoch:21 step:19698 [D loss: 0.562537, acc.: 65.62%] [G loss: 0.675142]\n",
      "epoch:21 step:19699 [D loss: 0.439772, acc.: 77.34%] [G loss: 0.971142]\n",
      "epoch:21 step:19700 [D loss: 0.589860, acc.: 64.84%] [G loss: 0.734879]\n",
      "epoch:21 step:19701 [D loss: 0.536262, acc.: 72.66%] [G loss: 0.560729]\n",
      "epoch:21 step:19702 [D loss: 0.488554, acc.: 75.00%] [G loss: 0.633596]\n",
      "epoch:21 step:19703 [D loss: 0.592692, acc.: 71.09%] [G loss: 0.694574]\n",
      "epoch:21 step:19704 [D loss: 0.501790, acc.: 73.44%] [G loss: 0.813128]\n",
      "epoch:21 step:19705 [D loss: 0.544083, acc.: 66.41%] [G loss: 0.746582]\n",
      "epoch:21 step:19706 [D loss: 0.469223, acc.: 76.56%] [G loss: 0.604939]\n",
      "epoch:21 step:19707 [D loss: 0.509976, acc.: 72.66%] [G loss: 0.617408]\n",
      "epoch:21 step:19708 [D loss: 0.605809, acc.: 66.41%] [G loss: 0.744337]\n",
      "epoch:21 step:19709 [D loss: 0.507668, acc.: 76.56%] [G loss: 0.727251]\n",
      "epoch:21 step:19710 [D loss: 0.493762, acc.: 71.88%] [G loss: 0.774918]\n",
      "epoch:21 step:19711 [D loss: 0.579346, acc.: 67.97%] [G loss: 0.587669]\n",
      "epoch:21 step:19712 [D loss: 0.544277, acc.: 71.09%] [G loss: 0.672041]\n",
      "epoch:21 step:19713 [D loss: 0.521015, acc.: 71.88%] [G loss: 0.643837]\n",
      "epoch:21 step:19714 [D loss: 0.449833, acc.: 76.56%] [G loss: 0.873345]\n",
      "epoch:21 step:19715 [D loss: 0.551869, acc.: 74.22%] [G loss: 0.553915]\n",
      "epoch:21 step:19716 [D loss: 0.520985, acc.: 72.66%] [G loss: 0.699329]\n",
      "epoch:21 step:19717 [D loss: 0.417442, acc.: 81.25%] [G loss: 0.883687]\n",
      "epoch:21 step:19718 [D loss: 0.515519, acc.: 71.09%] [G loss: 0.778072]\n",
      "epoch:21 step:19719 [D loss: 0.532541, acc.: 69.53%] [G loss: 0.747884]\n",
      "epoch:21 step:19720 [D loss: 0.505364, acc.: 78.91%] [G loss: 0.838879]\n",
      "epoch:21 step:19721 [D loss: 0.585507, acc.: 66.41%] [G loss: 0.741829]\n",
      "epoch:21 step:19722 [D loss: 0.493585, acc.: 76.56%] [G loss: 0.676924]\n",
      "epoch:21 step:19723 [D loss: 0.495826, acc.: 73.44%] [G loss: 0.893694]\n",
      "epoch:21 step:19724 [D loss: 0.496571, acc.: 70.31%] [G loss: 0.789387]\n",
      "epoch:21 step:19725 [D loss: 0.571850, acc.: 66.41%] [G loss: 0.870399]\n",
      "epoch:21 step:19726 [D loss: 0.477021, acc.: 76.56%] [G loss: 0.885607]\n",
      "epoch:21 step:19727 [D loss: 0.530205, acc.: 71.88%] [G loss: 0.682692]\n",
      "epoch:21 step:19728 [D loss: 0.666213, acc.: 59.38%] [G loss: 0.617050]\n",
      "epoch:21 step:19729 [D loss: 0.598577, acc.: 63.28%] [G loss: 0.635382]\n",
      "epoch:21 step:19730 [D loss: 0.530263, acc.: 70.31%] [G loss: 0.550270]\n",
      "epoch:21 step:19731 [D loss: 0.472300, acc.: 78.12%] [G loss: 0.882705]\n",
      "epoch:21 step:19732 [D loss: 0.499615, acc.: 77.34%] [G loss: 0.675032]\n",
      "epoch:21 step:19733 [D loss: 0.503163, acc.: 75.00%] [G loss: 0.648725]\n",
      "epoch:21 step:19734 [D loss: 0.501893, acc.: 79.69%] [G loss: 0.631345]\n",
      "epoch:21 step:19735 [D loss: 0.562274, acc.: 71.09%] [G loss: 0.729731]\n",
      "epoch:21 step:19736 [D loss: 0.496154, acc.: 76.56%] [G loss: 0.756674]\n",
      "epoch:21 step:19737 [D loss: 0.561662, acc.: 67.97%] [G loss: 0.718267]\n",
      "epoch:21 step:19738 [D loss: 0.542765, acc.: 68.75%] [G loss: 0.682810]\n",
      "epoch:21 step:19739 [D loss: 0.542251, acc.: 68.75%] [G loss: 0.699686]\n",
      "epoch:21 step:19740 [D loss: 0.517387, acc.: 73.44%] [G loss: 0.737889]\n",
      "epoch:21 step:19741 [D loss: 0.586429, acc.: 71.88%] [G loss: 0.788927]\n",
      "epoch:21 step:19742 [D loss: 0.517868, acc.: 71.88%] [G loss: 0.514922]\n",
      "epoch:21 step:19743 [D loss: 0.521398, acc.: 71.09%] [G loss: 0.671958]\n",
      "epoch:21 step:19744 [D loss: 0.552682, acc.: 71.09%] [G loss: 0.539069]\n",
      "epoch:21 step:19745 [D loss: 0.504552, acc.: 71.88%] [G loss: 0.586972]\n",
      "epoch:21 step:19746 [D loss: 0.516341, acc.: 75.78%] [G loss: 0.625629]\n",
      "epoch:21 step:19747 [D loss: 0.546594, acc.: 71.88%] [G loss: 0.717245]\n",
      "epoch:21 step:19748 [D loss: 0.521253, acc.: 71.88%] [G loss: 0.781229]\n",
      "epoch:21 step:19749 [D loss: 0.479910, acc.: 75.00%] [G loss: 0.633544]\n",
      "epoch:21 step:19750 [D loss: 0.547231, acc.: 67.97%] [G loss: 0.501970]\n",
      "epoch:21 step:19751 [D loss: 0.447844, acc.: 78.91%] [G loss: 0.603671]\n",
      "epoch:21 step:19752 [D loss: 0.530185, acc.: 71.88%] [G loss: 0.741792]\n",
      "epoch:21 step:19753 [D loss: 0.483706, acc.: 76.56%] [G loss: 0.918677]\n",
      "epoch:21 step:19754 [D loss: 0.406291, acc.: 80.47%] [G loss: 0.923631]\n",
      "epoch:21 step:19755 [D loss: 0.584735, acc.: 69.53%] [G loss: 0.661236]\n",
      "epoch:21 step:19756 [D loss: 0.552633, acc.: 68.75%] [G loss: 0.641655]\n",
      "epoch:21 step:19757 [D loss: 0.481515, acc.: 74.22%] [G loss: 0.745614]\n",
      "epoch:21 step:19758 [D loss: 0.546271, acc.: 72.66%] [G loss: 0.749373]\n",
      "epoch:21 step:19759 [D loss: 0.509255, acc.: 65.62%] [G loss: 0.843957]\n",
      "epoch:21 step:19760 [D loss: 0.504712, acc.: 71.09%] [G loss: 0.761671]\n",
      "epoch:21 step:19761 [D loss: 0.568056, acc.: 64.84%] [G loss: 0.827873]\n",
      "epoch:21 step:19762 [D loss: 0.552822, acc.: 67.97%] [G loss: 0.646003]\n",
      "epoch:21 step:19763 [D loss: 0.561375, acc.: 71.88%] [G loss: 0.603065]\n",
      "epoch:21 step:19764 [D loss: 0.521972, acc.: 71.09%] [G loss: 0.614772]\n",
      "epoch:21 step:19765 [D loss: 0.506866, acc.: 77.34%] [G loss: 0.747074]\n",
      "epoch:21 step:19766 [D loss: 0.475492, acc.: 75.00%] [G loss: 0.944627]\n",
      "epoch:21 step:19767 [D loss: 0.523800, acc.: 71.09%] [G loss: 0.826132]\n",
      "epoch:21 step:19768 [D loss: 0.618860, acc.: 68.75%] [G loss: 0.828441]\n",
      "epoch:21 step:19769 [D loss: 0.453132, acc.: 78.91%] [G loss: 0.876940]\n",
      "epoch:21 step:19770 [D loss: 0.496890, acc.: 75.78%] [G loss: 0.741143]\n",
      "epoch:21 step:19771 [D loss: 0.475564, acc.: 75.00%] [G loss: 0.743987]\n",
      "epoch:21 step:19772 [D loss: 0.531900, acc.: 73.44%] [G loss: 0.740639]\n",
      "epoch:21 step:19773 [D loss: 0.567323, acc.: 67.19%] [G loss: 0.781851]\n",
      "epoch:21 step:19774 [D loss: 0.475300, acc.: 75.00%] [G loss: 0.987365]\n",
      "epoch:21 step:19775 [D loss: 0.517390, acc.: 71.88%] [G loss: 0.904437]\n",
      "epoch:21 step:19776 [D loss: 0.553677, acc.: 69.53%] [G loss: 0.713951]\n",
      "epoch:21 step:19777 [D loss: 0.436973, acc.: 82.03%] [G loss: 1.105672]\n",
      "epoch:21 step:19778 [D loss: 0.482365, acc.: 77.34%] [G loss: 0.934257]\n",
      "epoch:21 step:19779 [D loss: 0.617253, acc.: 67.19%] [G loss: 0.698188]\n",
      "epoch:21 step:19780 [D loss: 0.529650, acc.: 71.09%] [G loss: 0.651899]\n",
      "epoch:21 step:19781 [D loss: 0.505752, acc.: 67.97%] [G loss: 0.628862]\n",
      "epoch:21 step:19782 [D loss: 0.582130, acc.: 64.84%] [G loss: 0.744156]\n",
      "epoch:21 step:19783 [D loss: 0.545333, acc.: 68.75%] [G loss: 0.664632]\n",
      "epoch:21 step:19784 [D loss: 0.541454, acc.: 71.88%] [G loss: 0.758983]\n",
      "epoch:21 step:19785 [D loss: 0.565956, acc.: 67.19%] [G loss: 0.633516]\n",
      "epoch:21 step:19786 [D loss: 0.517336, acc.: 75.00%] [G loss: 0.718455]\n",
      "epoch:21 step:19787 [D loss: 0.596133, acc.: 69.53%] [G loss: 0.702123]\n",
      "epoch:21 step:19788 [D loss: 0.486282, acc.: 71.09%] [G loss: 0.777734]\n",
      "epoch:21 step:19789 [D loss: 0.476465, acc.: 79.69%] [G loss: 0.655196]\n",
      "epoch:21 step:19790 [D loss: 0.497298, acc.: 74.22%] [G loss: 0.597861]\n",
      "epoch:21 step:19791 [D loss: 0.536527, acc.: 71.09%] [G loss: 0.617181]\n",
      "epoch:21 step:19792 [D loss: 0.535097, acc.: 71.88%] [G loss: 0.750291]\n",
      "epoch:21 step:19793 [D loss: 0.475338, acc.: 73.44%] [G loss: 0.771867]\n",
      "epoch:21 step:19794 [D loss: 0.509551, acc.: 73.44%] [G loss: 0.901125]\n",
      "epoch:21 step:19795 [D loss: 0.504906, acc.: 70.31%] [G loss: 0.903481]\n",
      "epoch:21 step:19796 [D loss: 0.406390, acc.: 83.59%] [G loss: 0.994422]\n",
      "epoch:21 step:19797 [D loss: 0.528237, acc.: 69.53%] [G loss: 0.837460]\n",
      "epoch:21 step:19798 [D loss: 0.526311, acc.: 72.66%] [G loss: 0.755284]\n",
      "epoch:21 step:19799 [D loss: 0.469075, acc.: 76.56%] [G loss: 0.811284]\n",
      "epoch:21 step:19800 [D loss: 0.517996, acc.: 71.09%] [G loss: 0.822097]\n",
      "epoch:21 step:19801 [D loss: 0.578046, acc.: 66.41%] [G loss: 0.933167]\n",
      "epoch:21 step:19802 [D loss: 0.601061, acc.: 67.19%] [G loss: 0.616222]\n",
      "epoch:21 step:19803 [D loss: 0.488424, acc.: 73.44%] [G loss: 0.692630]\n",
      "epoch:21 step:19804 [D loss: 0.474880, acc.: 74.22%] [G loss: 0.637989]\n",
      "epoch:21 step:19805 [D loss: 0.587733, acc.: 62.50%] [G loss: 0.624611]\n",
      "epoch:21 step:19806 [D loss: 0.608352, acc.: 58.59%] [G loss: 0.614003]\n",
      "epoch:21 step:19807 [D loss: 0.474739, acc.: 74.22%] [G loss: 0.701130]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:21 step:19808 [D loss: 0.480846, acc.: 76.56%] [G loss: 0.698061]\n",
      "epoch:21 step:19809 [D loss: 0.571883, acc.: 67.97%] [G loss: 0.700580]\n",
      "epoch:21 step:19810 [D loss: 0.563482, acc.: 69.53%] [G loss: 0.825488]\n",
      "epoch:21 step:19811 [D loss: 0.570955, acc.: 67.19%] [G loss: 0.685665]\n",
      "epoch:21 step:19812 [D loss: 0.515167, acc.: 69.53%] [G loss: 0.618717]\n",
      "epoch:21 step:19813 [D loss: 0.503793, acc.: 74.22%] [G loss: 0.888662]\n",
      "epoch:21 step:19814 [D loss: 0.645959, acc.: 67.19%] [G loss: 0.656030]\n",
      "epoch:21 step:19815 [D loss: 0.580127, acc.: 71.09%] [G loss: 0.699791]\n",
      "epoch:21 step:19816 [D loss: 0.536080, acc.: 70.31%] [G loss: 0.721149]\n",
      "epoch:21 step:19817 [D loss: 0.534216, acc.: 71.09%] [G loss: 0.606079]\n",
      "epoch:21 step:19818 [D loss: 0.579148, acc.: 67.97%] [G loss: 0.849352]\n",
      "epoch:21 step:19819 [D loss: 0.546321, acc.: 68.75%] [G loss: 0.742699]\n",
      "epoch:21 step:19820 [D loss: 0.582589, acc.: 64.06%] [G loss: 0.531209]\n",
      "epoch:21 step:19821 [D loss: 0.500743, acc.: 75.78%] [G loss: 0.534533]\n",
      "epoch:21 step:19822 [D loss: 0.546525, acc.: 65.62%] [G loss: 0.740646]\n",
      "epoch:21 step:19823 [D loss: 0.459249, acc.: 78.91%] [G loss: 0.752941]\n",
      "epoch:21 step:19824 [D loss: 0.643606, acc.: 69.53%] [G loss: 0.601689]\n",
      "epoch:21 step:19825 [D loss: 0.607383, acc.: 60.94%] [G loss: 0.675872]\n",
      "epoch:21 step:19826 [D loss: 0.493465, acc.: 72.66%] [G loss: 0.618285]\n",
      "epoch:21 step:19827 [D loss: 0.566396, acc.: 70.31%] [G loss: 0.618026]\n",
      "epoch:21 step:19828 [D loss: 0.594185, acc.: 63.28%] [G loss: 0.667961]\n",
      "epoch:21 step:19829 [D loss: 0.521984, acc.: 71.88%] [G loss: 0.657982]\n",
      "epoch:21 step:19830 [D loss: 0.577573, acc.: 68.75%] [G loss: 0.596520]\n",
      "epoch:21 step:19831 [D loss: 0.546674, acc.: 67.19%] [G loss: 0.648251]\n",
      "epoch:21 step:19832 [D loss: 0.491328, acc.: 72.66%] [G loss: 0.709421]\n",
      "epoch:21 step:19833 [D loss: 0.507667, acc.: 78.91%] [G loss: 0.971333]\n",
      "epoch:21 step:19834 [D loss: 0.566085, acc.: 67.19%] [G loss: 0.813158]\n",
      "epoch:21 step:19835 [D loss: 0.545815, acc.: 67.19%] [G loss: 0.674200]\n",
      "epoch:21 step:19836 [D loss: 0.467860, acc.: 73.44%] [G loss: 0.696602]\n",
      "epoch:21 step:19837 [D loss: 0.583510, acc.: 69.53%] [G loss: 0.810834]\n",
      "epoch:21 step:19838 [D loss: 0.557627, acc.: 73.44%] [G loss: 0.896480]\n",
      "epoch:21 step:19839 [D loss: 0.496705, acc.: 73.44%] [G loss: 0.791154]\n",
      "epoch:21 step:19840 [D loss: 0.542891, acc.: 69.53%] [G loss: 0.841325]\n",
      "epoch:21 step:19841 [D loss: 0.545712, acc.: 68.75%] [G loss: 0.695876]\n",
      "epoch:21 step:19842 [D loss: 0.513170, acc.: 72.66%] [G loss: 0.813951]\n",
      "epoch:21 step:19843 [D loss: 0.544028, acc.: 73.44%] [G loss: 0.635974]\n",
      "epoch:21 step:19844 [D loss: 0.529705, acc.: 71.88%] [G loss: 0.586252]\n",
      "epoch:21 step:19845 [D loss: 0.518619, acc.: 75.78%] [G loss: 0.611656]\n",
      "epoch:21 step:19846 [D loss: 0.547555, acc.: 71.09%] [G loss: 0.629695]\n",
      "epoch:21 step:19847 [D loss: 0.489517, acc.: 74.22%] [G loss: 0.641921]\n",
      "epoch:21 step:19848 [D loss: 0.545232, acc.: 69.53%] [G loss: 0.600912]\n",
      "epoch:21 step:19849 [D loss: 0.538019, acc.: 71.09%] [G loss: 0.681052]\n",
      "epoch:21 step:19850 [D loss: 0.459016, acc.: 75.78%] [G loss: 0.714469]\n",
      "epoch:21 step:19851 [D loss: 0.582027, acc.: 65.62%] [G loss: 0.468326]\n",
      "epoch:21 step:19852 [D loss: 0.571634, acc.: 65.62%] [G loss: 0.632788]\n",
      "epoch:21 step:19853 [D loss: 0.493978, acc.: 77.34%] [G loss: 0.697774]\n",
      "epoch:21 step:19854 [D loss: 0.501230, acc.: 73.44%] [G loss: 0.718692]\n",
      "epoch:21 step:19855 [D loss: 0.589775, acc.: 65.62%] [G loss: 0.601565]\n",
      "epoch:21 step:19856 [D loss: 0.514698, acc.: 72.66%] [G loss: 0.615263]\n",
      "epoch:21 step:19857 [D loss: 0.617035, acc.: 64.84%] [G loss: 0.506323]\n",
      "epoch:21 step:19858 [D loss: 0.498515, acc.: 76.56%] [G loss: 0.573716]\n",
      "epoch:21 step:19859 [D loss: 0.475551, acc.: 78.91%] [G loss: 0.664063]\n",
      "epoch:21 step:19860 [D loss: 0.512260, acc.: 74.22%] [G loss: 0.755454]\n",
      "epoch:21 step:19861 [D loss: 0.527144, acc.: 74.22%] [G loss: 0.738095]\n",
      "epoch:21 step:19862 [D loss: 0.522336, acc.: 71.09%] [G loss: 0.922179]\n",
      "epoch:21 step:19863 [D loss: 0.533988, acc.: 71.88%] [G loss: 0.684754]\n",
      "epoch:21 step:19864 [D loss: 0.603119, acc.: 64.06%] [G loss: 0.616778]\n",
      "epoch:21 step:19865 [D loss: 0.531534, acc.: 70.31%] [G loss: 0.640109]\n",
      "epoch:21 step:19866 [D loss: 0.538669, acc.: 70.31%] [G loss: 0.616175]\n",
      "epoch:21 step:19867 [D loss: 0.475127, acc.: 75.00%] [G loss: 0.657833]\n",
      "epoch:21 step:19868 [D loss: 0.488855, acc.: 73.44%] [G loss: 0.565313]\n",
      "epoch:21 step:19869 [D loss: 0.533637, acc.: 75.00%] [G loss: 0.741550]\n",
      "epoch:21 step:19870 [D loss: 0.525969, acc.: 75.00%] [G loss: 0.622577]\n",
      "epoch:21 step:19871 [D loss: 0.444918, acc.: 78.12%] [G loss: 0.881236]\n",
      "epoch:21 step:19872 [D loss: 0.525646, acc.: 71.09%] [G loss: 0.938839]\n",
      "epoch:21 step:19873 [D loss: 0.587831, acc.: 65.62%] [G loss: 0.715144]\n",
      "epoch:21 step:19874 [D loss: 0.477385, acc.: 79.69%] [G loss: 0.572479]\n",
      "epoch:21 step:19875 [D loss: 0.442062, acc.: 82.81%] [G loss: 0.761301]\n",
      "epoch:21 step:19876 [D loss: 0.526639, acc.: 67.19%] [G loss: 0.702268]\n",
      "epoch:21 step:19877 [D loss: 0.551100, acc.: 72.66%] [G loss: 0.625653]\n",
      "epoch:21 step:19878 [D loss: 0.527358, acc.: 73.44%] [G loss: 0.700741]\n",
      "epoch:21 step:19879 [D loss: 0.578938, acc.: 64.84%] [G loss: 0.633040]\n",
      "epoch:21 step:19880 [D loss: 0.549579, acc.: 68.75%] [G loss: 0.734421]\n",
      "epoch:21 step:19881 [D loss: 0.522493, acc.: 71.09%] [G loss: 0.771365]\n",
      "epoch:21 step:19882 [D loss: 0.453978, acc.: 78.12%] [G loss: 0.773670]\n",
      "epoch:21 step:19883 [D loss: 0.499344, acc.: 74.22%] [G loss: 0.795016]\n",
      "epoch:21 step:19884 [D loss: 0.500403, acc.: 76.56%] [G loss: 0.829521]\n",
      "epoch:21 step:19885 [D loss: 0.399989, acc.: 82.81%] [G loss: 0.918783]\n",
      "epoch:21 step:19886 [D loss: 0.512520, acc.: 76.56%] [G loss: 0.902221]\n",
      "epoch:21 step:19887 [D loss: 0.602674, acc.: 65.62%] [G loss: 0.758898]\n",
      "epoch:21 step:19888 [D loss: 0.540808, acc.: 66.41%] [G loss: 0.552469]\n",
      "epoch:21 step:19889 [D loss: 0.600631, acc.: 65.62%] [G loss: 0.546815]\n",
      "epoch:21 step:19890 [D loss: 0.505421, acc.: 71.88%] [G loss: 0.649604]\n",
      "epoch:21 step:19891 [D loss: 0.596594, acc.: 67.97%] [G loss: 0.549530]\n",
      "epoch:21 step:19892 [D loss: 0.546514, acc.: 68.75%] [G loss: 0.641289]\n",
      "epoch:21 step:19893 [D loss: 0.518960, acc.: 74.22%] [G loss: 0.656364]\n",
      "epoch:21 step:19894 [D loss: 0.524532, acc.: 74.22%] [G loss: 0.747176]\n",
      "epoch:21 step:19895 [D loss: 0.440993, acc.: 78.91%] [G loss: 0.776166]\n",
      "epoch:21 step:19896 [D loss: 0.470131, acc.: 79.69%] [G loss: 0.931933]\n",
      "epoch:21 step:19897 [D loss: 0.649069, acc.: 64.84%] [G loss: 0.640357]\n",
      "epoch:21 step:19898 [D loss: 0.548970, acc.: 70.31%] [G loss: 0.769791]\n",
      "epoch:21 step:19899 [D loss: 0.505629, acc.: 71.88%] [G loss: 0.888827]\n",
      "epoch:21 step:19900 [D loss: 0.479886, acc.: 80.47%] [G loss: 0.666071]\n",
      "epoch:21 step:19901 [D loss: 0.519944, acc.: 73.44%] [G loss: 0.726303]\n",
      "epoch:21 step:19902 [D loss: 0.507972, acc.: 75.78%] [G loss: 0.827828]\n",
      "epoch:21 step:19903 [D loss: 0.565389, acc.: 67.19%] [G loss: 0.513989]\n",
      "epoch:21 step:19904 [D loss: 0.503498, acc.: 72.66%] [G loss: 0.685445]\n",
      "epoch:21 step:19905 [D loss: 0.586070, acc.: 61.72%] [G loss: 0.572921]\n",
      "epoch:21 step:19906 [D loss: 0.476516, acc.: 80.47%] [G loss: 0.647873]\n",
      "epoch:21 step:19907 [D loss: 0.486011, acc.: 72.66%] [G loss: 0.677700]\n",
      "epoch:21 step:19908 [D loss: 0.423173, acc.: 82.81%] [G loss: 0.919141]\n",
      "epoch:21 step:19909 [D loss: 0.380723, acc.: 85.94%] [G loss: 1.119077]\n",
      "epoch:21 step:19910 [D loss: 0.556052, acc.: 70.31%] [G loss: 0.779451]\n",
      "epoch:21 step:19911 [D loss: 0.584354, acc.: 71.09%] [G loss: 0.679401]\n",
      "epoch:21 step:19912 [D loss: 0.540667, acc.: 75.00%] [G loss: 0.714117]\n",
      "epoch:21 step:19913 [D loss: 0.496677, acc.: 72.66%] [G loss: 0.725129]\n",
      "epoch:21 step:19914 [D loss: 0.539697, acc.: 67.97%] [G loss: 0.572650]\n",
      "epoch:21 step:19915 [D loss: 0.569673, acc.: 65.62%] [G loss: 0.537772]\n",
      "epoch:21 step:19916 [D loss: 0.540074, acc.: 71.09%] [G loss: 0.517374]\n",
      "epoch:21 step:19917 [D loss: 0.513415, acc.: 73.44%] [G loss: 0.624269]\n",
      "epoch:21 step:19918 [D loss: 0.475841, acc.: 77.34%] [G loss: 0.539154]\n",
      "epoch:21 step:19919 [D loss: 0.487802, acc.: 76.56%] [G loss: 0.773503]\n",
      "epoch:21 step:19920 [D loss: 0.568026, acc.: 69.53%] [G loss: 0.697561]\n",
      "epoch:21 step:19921 [D loss: 0.451493, acc.: 78.12%] [G loss: 0.900179]\n",
      "epoch:21 step:19922 [D loss: 0.456526, acc.: 79.69%] [G loss: 0.875159]\n",
      "epoch:21 step:19923 [D loss: 0.441182, acc.: 83.59%] [G loss: 0.672793]\n",
      "epoch:21 step:19924 [D loss: 0.501733, acc.: 74.22%] [G loss: 0.758841]\n",
      "epoch:21 step:19925 [D loss: 0.445912, acc.: 77.34%] [G loss: 0.814443]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:21 step:19926 [D loss: 0.611929, acc.: 67.97%] [G loss: 0.639032]\n",
      "epoch:21 step:19927 [D loss: 0.559591, acc.: 70.31%] [G loss: 0.703762]\n",
      "epoch:21 step:19928 [D loss: 0.571653, acc.: 68.75%] [G loss: 0.830192]\n",
      "epoch:21 step:19929 [D loss: 0.514908, acc.: 72.66%] [G loss: 0.661720]\n",
      "epoch:21 step:19930 [D loss: 0.593960, acc.: 64.06%] [G loss: 0.655693]\n",
      "epoch:21 step:19931 [D loss: 0.506147, acc.: 72.66%] [G loss: 0.600791]\n",
      "epoch:21 step:19932 [D loss: 0.519851, acc.: 72.66%] [G loss: 0.696064]\n",
      "epoch:21 step:19933 [D loss: 0.537470, acc.: 70.31%] [G loss: 0.665280]\n",
      "epoch:21 step:19934 [D loss: 0.598108, acc.: 62.50%] [G loss: 0.752105]\n",
      "epoch:21 step:19935 [D loss: 0.467645, acc.: 75.78%] [G loss: 0.619479]\n",
      "epoch:21 step:19936 [D loss: 0.541354, acc.: 68.75%] [G loss: 0.619642]\n",
      "epoch:21 step:19937 [D loss: 0.567213, acc.: 67.19%] [G loss: 0.596289]\n",
      "epoch:21 step:19938 [D loss: 0.421504, acc.: 82.03%] [G loss: 0.823418]\n",
      "epoch:21 step:19939 [D loss: 0.535263, acc.: 69.53%] [G loss: 0.865242]\n",
      "epoch:21 step:19940 [D loss: 0.573107, acc.: 73.44%] [G loss: 0.688694]\n",
      "epoch:21 step:19941 [D loss: 0.473038, acc.: 78.91%] [G loss: 0.823581]\n",
      "epoch:21 step:19942 [D loss: 0.530300, acc.: 73.44%] [G loss: 0.661228]\n",
      "epoch:21 step:19943 [D loss: 0.546805, acc.: 71.09%] [G loss: 0.719699]\n",
      "epoch:21 step:19944 [D loss: 0.549667, acc.: 71.88%] [G loss: 0.653426]\n",
      "epoch:21 step:19945 [D loss: 0.561064, acc.: 69.53%] [G loss: 0.701594]\n",
      "epoch:21 step:19946 [D loss: 0.513367, acc.: 72.66%] [G loss: 0.709533]\n",
      "epoch:21 step:19947 [D loss: 0.490480, acc.: 77.34%] [G loss: 0.761653]\n",
      "epoch:21 step:19948 [D loss: 0.481558, acc.: 72.66%] [G loss: 0.739914]\n",
      "epoch:21 step:19949 [D loss: 0.511526, acc.: 70.31%] [G loss: 0.634145]\n",
      "epoch:21 step:19950 [D loss: 0.519336, acc.: 67.97%] [G loss: 0.852016]\n",
      "epoch:21 step:19951 [D loss: 0.507704, acc.: 72.66%] [G loss: 0.748363]\n",
      "epoch:21 step:19952 [D loss: 0.540862, acc.: 70.31%] [G loss: 0.695011]\n",
      "epoch:21 step:19953 [D loss: 0.461899, acc.: 78.91%] [G loss: 0.662081]\n",
      "epoch:21 step:19954 [D loss: 0.628533, acc.: 66.41%] [G loss: 0.663884]\n",
      "epoch:21 step:19955 [D loss: 0.594810, acc.: 65.62%] [G loss: 0.635712]\n",
      "epoch:21 step:19956 [D loss: 0.523057, acc.: 70.31%] [G loss: 0.523771]\n",
      "epoch:21 step:19957 [D loss: 0.550327, acc.: 72.66%] [G loss: 0.594521]\n",
      "epoch:21 step:19958 [D loss: 0.574053, acc.: 66.41%] [G loss: 0.631105]\n",
      "epoch:21 step:19959 [D loss: 0.623433, acc.: 64.84%] [G loss: 0.563218]\n",
      "epoch:21 step:19960 [D loss: 0.537542, acc.: 72.66%] [G loss: 0.709362]\n",
      "epoch:21 step:19961 [D loss: 0.523120, acc.: 67.97%] [G loss: 0.666517]\n",
      "epoch:21 step:19962 [D loss: 0.497165, acc.: 75.00%] [G loss: 0.698884]\n",
      "epoch:21 step:19963 [D loss: 0.505276, acc.: 73.44%] [G loss: 0.819309]\n",
      "epoch:21 step:19964 [D loss: 0.569157, acc.: 64.84%] [G loss: 0.545771]\n",
      "epoch:21 step:19965 [D loss: 0.546943, acc.: 68.75%] [G loss: 0.690830]\n",
      "epoch:21 step:19966 [D loss: 0.484575, acc.: 73.44%] [G loss: 0.592411]\n",
      "epoch:21 step:19967 [D loss: 0.531365, acc.: 73.44%] [G loss: 0.678322]\n",
      "epoch:21 step:19968 [D loss: 0.527710, acc.: 68.75%] [G loss: 0.770093]\n",
      "epoch:21 step:19969 [D loss: 0.530717, acc.: 68.75%] [G loss: 0.678286]\n",
      "epoch:21 step:19970 [D loss: 0.563695, acc.: 64.84%] [G loss: 0.540899]\n",
      "epoch:21 step:19971 [D loss: 0.570677, acc.: 69.53%] [G loss: 0.641396]\n",
      "epoch:21 step:19972 [D loss: 0.538913, acc.: 71.88%] [G loss: 0.575694]\n",
      "epoch:21 step:19973 [D loss: 0.424263, acc.: 82.03%] [G loss: 0.659020]\n",
      "epoch:21 step:19974 [D loss: 0.523502, acc.: 69.53%] [G loss: 0.617661]\n",
      "epoch:21 step:19975 [D loss: 0.505416, acc.: 71.09%] [G loss: 0.771447]\n",
      "epoch:21 step:19976 [D loss: 0.494128, acc.: 70.31%] [G loss: 0.793111]\n",
      "epoch:21 step:19977 [D loss: 0.476979, acc.: 77.34%] [G loss: 0.728073]\n",
      "epoch:21 step:19978 [D loss: 0.610439, acc.: 64.84%] [G loss: 0.738253]\n",
      "epoch:21 step:19979 [D loss: 0.496856, acc.: 71.09%] [G loss: 0.964965]\n",
      "epoch:21 step:19980 [D loss: 0.542405, acc.: 70.31%] [G loss: 0.757097]\n",
      "epoch:21 step:19981 [D loss: 0.450978, acc.: 78.91%] [G loss: 0.674134]\n",
      "epoch:21 step:19982 [D loss: 0.527523, acc.: 73.44%] [G loss: 0.660260]\n",
      "epoch:21 step:19983 [D loss: 0.537510, acc.: 72.66%] [G loss: 0.596184]\n",
      "epoch:21 step:19984 [D loss: 0.509046, acc.: 75.00%] [G loss: 0.750936]\n",
      "epoch:21 step:19985 [D loss: 0.539734, acc.: 68.75%] [G loss: 0.667085]\n",
      "epoch:21 step:19986 [D loss: 0.472490, acc.: 72.66%] [G loss: 0.790433]\n",
      "epoch:21 step:19987 [D loss: 0.544998, acc.: 71.09%] [G loss: 0.609031]\n",
      "epoch:21 step:19988 [D loss: 0.436940, acc.: 82.03%] [G loss: 0.789240]\n",
      "epoch:21 step:19989 [D loss: 0.497087, acc.: 73.44%] [G loss: 0.724292]\n",
      "epoch:21 step:19990 [D loss: 0.455666, acc.: 78.12%] [G loss: 1.214460]\n",
      "epoch:21 step:19991 [D loss: 0.436714, acc.: 79.69%] [G loss: 0.947885]\n",
      "epoch:21 step:19992 [D loss: 0.464486, acc.: 77.34%] [G loss: 1.100522]\n",
      "epoch:21 step:19993 [D loss: 0.664570, acc.: 65.62%] [G loss: 0.727712]\n",
      "epoch:21 step:19994 [D loss: 0.569908, acc.: 70.31%] [G loss: 0.565823]\n",
      "epoch:21 step:19995 [D loss: 0.526812, acc.: 71.88%] [G loss: 0.526289]\n",
      "epoch:21 step:19996 [D loss: 0.521407, acc.: 71.09%] [G loss: 0.729832]\n",
      "epoch:21 step:19997 [D loss: 0.527404, acc.: 70.31%] [G loss: 0.668355]\n",
      "epoch:21 step:19998 [D loss: 0.480717, acc.: 75.00%] [G loss: 0.749088]\n",
      "epoch:21 step:19999 [D loss: 0.569089, acc.: 71.09%] [G loss: 0.636382]\n",
      "epoch:21 step:20000 [D loss: 0.561258, acc.: 68.75%] [G loss: 0.713067]\n",
      "epoch:21 step:20001 [D loss: 0.572044, acc.: 70.31%] [G loss: 0.641440]\n",
      "epoch:21 step:20002 [D loss: 0.600391, acc.: 67.19%] [G loss: 0.565779]\n",
      "epoch:21 step:20003 [D loss: 0.432296, acc.: 78.91%] [G loss: 0.713210]\n",
      "epoch:21 step:20004 [D loss: 0.579906, acc.: 69.53%] [G loss: 0.699798]\n",
      "epoch:21 step:20005 [D loss: 0.451348, acc.: 78.91%] [G loss: 0.855876]\n",
      "epoch:21 step:20006 [D loss: 0.480446, acc.: 75.78%] [G loss: 0.701601]\n",
      "epoch:21 step:20007 [D loss: 0.571249, acc.: 69.53%] [G loss: 0.717748]\n",
      "epoch:21 step:20008 [D loss: 0.547267, acc.: 71.88%] [G loss: 0.646777]\n",
      "epoch:21 step:20009 [D loss: 0.517141, acc.: 69.53%] [G loss: 0.765816]\n",
      "epoch:21 step:20010 [D loss: 0.488105, acc.: 73.44%] [G loss: 0.776511]\n",
      "epoch:21 step:20011 [D loss: 0.448845, acc.: 77.34%] [G loss: 0.897283]\n",
      "epoch:21 step:20012 [D loss: 0.503162, acc.: 71.88%] [G loss: 0.744313]\n",
      "epoch:21 step:20013 [D loss: 0.509547, acc.: 73.44%] [G loss: 0.723007]\n",
      "epoch:21 step:20014 [D loss: 0.488312, acc.: 75.78%] [G loss: 0.790493]\n",
      "epoch:21 step:20015 [D loss: 0.556811, acc.: 69.53%] [G loss: 0.791802]\n",
      "epoch:21 step:20016 [D loss: 0.589528, acc.: 65.62%] [G loss: 0.635759]\n",
      "epoch:21 step:20017 [D loss: 0.443762, acc.: 78.12%] [G loss: 0.755076]\n",
      "epoch:21 step:20018 [D loss: 0.547036, acc.: 72.66%] [G loss: 0.713820]\n",
      "epoch:21 step:20019 [D loss: 0.675495, acc.: 60.94%] [G loss: 0.630461]\n",
      "epoch:21 step:20020 [D loss: 0.516459, acc.: 71.09%] [G loss: 0.918773]\n",
      "epoch:21 step:20021 [D loss: 0.459296, acc.: 78.91%] [G loss: 0.729096]\n",
      "epoch:21 step:20022 [D loss: 0.509920, acc.: 72.66%] [G loss: 0.959531]\n",
      "epoch:21 step:20023 [D loss: 0.541268, acc.: 70.31%] [G loss: 0.930347]\n",
      "epoch:21 step:20024 [D loss: 0.445854, acc.: 79.69%] [G loss: 0.995604]\n",
      "epoch:21 step:20025 [D loss: 0.599044, acc.: 69.53%] [G loss: 0.826756]\n",
      "epoch:21 step:20026 [D loss: 0.684498, acc.: 63.28%] [G loss: 0.697070]\n",
      "epoch:21 step:20027 [D loss: 0.474235, acc.: 76.56%] [G loss: 0.624738]\n",
      "epoch:21 step:20028 [D loss: 0.515469, acc.: 71.09%] [G loss: 0.705659]\n",
      "epoch:21 step:20029 [D loss: 0.571711, acc.: 71.88%] [G loss: 0.494901]\n",
      "epoch:21 step:20030 [D loss: 0.542900, acc.: 72.66%] [G loss: 0.661003]\n",
      "epoch:21 step:20031 [D loss: 0.362096, acc.: 84.38%] [G loss: 0.927961]\n",
      "epoch:21 step:20032 [D loss: 0.521993, acc.: 68.75%] [G loss: 0.831091]\n",
      "epoch:21 step:20033 [D loss: 0.557924, acc.: 68.75%] [G loss: 0.744982]\n",
      "epoch:21 step:20034 [D loss: 0.435450, acc.: 81.25%] [G loss: 0.990819]\n",
      "epoch:21 step:20035 [D loss: 0.483080, acc.: 82.81%] [G loss: 0.884158]\n",
      "epoch:21 step:20036 [D loss: 0.470623, acc.: 76.56%] [G loss: 0.777494]\n",
      "epoch:21 step:20037 [D loss: 0.505700, acc.: 73.44%] [G loss: 1.073255]\n",
      "epoch:21 step:20038 [D loss: 0.512761, acc.: 72.66%] [G loss: 0.966863]\n",
      "epoch:21 step:20039 [D loss: 0.526681, acc.: 67.97%] [G loss: 0.772456]\n",
      "epoch:21 step:20040 [D loss: 0.493103, acc.: 76.56%] [G loss: 0.910793]\n",
      "epoch:21 step:20041 [D loss: 0.514177, acc.: 72.66%] [G loss: 0.741581]\n",
      "epoch:21 step:20042 [D loss: 0.597759, acc.: 62.50%] [G loss: 0.701670]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:21 step:20043 [D loss: 0.500196, acc.: 72.66%] [G loss: 0.824799]\n",
      "epoch:21 step:20044 [D loss: 0.585800, acc.: 69.53%] [G loss: 0.572418]\n",
      "epoch:21 step:20045 [D loss: 0.489204, acc.: 75.78%] [G loss: 0.737088]\n",
      "epoch:21 step:20046 [D loss: 0.484334, acc.: 75.00%] [G loss: 0.692968]\n",
      "epoch:21 step:20047 [D loss: 0.528531, acc.: 71.88%] [G loss: 0.865189]\n",
      "epoch:21 step:20048 [D loss: 0.491731, acc.: 72.66%] [G loss: 0.923964]\n",
      "epoch:21 step:20049 [D loss: 0.527043, acc.: 73.44%] [G loss: 0.799080]\n",
      "epoch:21 step:20050 [D loss: 0.547851, acc.: 68.75%] [G loss: 0.775355]\n",
      "epoch:21 step:20051 [D loss: 0.444589, acc.: 80.47%] [G loss: 0.803252]\n",
      "epoch:21 step:20052 [D loss: 0.586763, acc.: 65.62%] [G loss: 0.674966]\n",
      "epoch:21 step:20053 [D loss: 0.710298, acc.: 60.94%] [G loss: 0.559226]\n",
      "epoch:21 step:20054 [D loss: 0.571529, acc.: 64.84%] [G loss: 0.636666]\n",
      "epoch:21 step:20055 [D loss: 0.532586, acc.: 69.53%] [G loss: 0.520283]\n",
      "epoch:21 step:20056 [D loss: 0.528438, acc.: 72.66%] [G loss: 0.564651]\n",
      "epoch:21 step:20057 [D loss: 0.593991, acc.: 63.28%] [G loss: 0.516508]\n",
      "epoch:21 step:20058 [D loss: 0.432873, acc.: 84.38%] [G loss: 0.608433]\n",
      "epoch:21 step:20059 [D loss: 0.496745, acc.: 75.00%] [G loss: 0.660524]\n",
      "epoch:21 step:20060 [D loss: 0.530572, acc.: 74.22%] [G loss: 0.745802]\n",
      "epoch:21 step:20061 [D loss: 0.537114, acc.: 71.09%] [G loss: 0.567895]\n",
      "epoch:21 step:20062 [D loss: 0.500963, acc.: 73.44%] [G loss: 0.745191]\n",
      "epoch:21 step:20063 [D loss: 0.589063, acc.: 67.19%] [G loss: 0.686834]\n",
      "epoch:21 step:20064 [D loss: 0.524464, acc.: 69.53%] [G loss: 0.608182]\n",
      "epoch:21 step:20065 [D loss: 0.522994, acc.: 71.09%] [G loss: 0.818417]\n",
      "epoch:21 step:20066 [D loss: 0.532518, acc.: 71.09%] [G loss: 0.692433]\n",
      "epoch:21 step:20067 [D loss: 0.600349, acc.: 65.62%] [G loss: 0.583354]\n",
      "epoch:21 step:20068 [D loss: 0.534412, acc.: 64.84%] [G loss: 0.609213]\n",
      "epoch:21 step:20069 [D loss: 0.452603, acc.: 79.69%] [G loss: 0.784473]\n",
      "epoch:21 step:20070 [D loss: 0.559786, acc.: 69.53%] [G loss: 0.638756]\n",
      "epoch:21 step:20071 [D loss: 0.537317, acc.: 69.53%] [G loss: 0.622545]\n",
      "epoch:21 step:20072 [D loss: 0.542826, acc.: 71.09%] [G loss: 0.727925]\n",
      "epoch:21 step:20073 [D loss: 0.545066, acc.: 73.44%] [G loss: 0.715304]\n",
      "epoch:21 step:20074 [D loss: 0.522655, acc.: 71.88%] [G loss: 0.786896]\n",
      "epoch:21 step:20075 [D loss: 0.445844, acc.: 81.25%] [G loss: 0.800460]\n",
      "epoch:21 step:20076 [D loss: 0.472497, acc.: 81.25%] [G loss: 0.636391]\n",
      "epoch:21 step:20077 [D loss: 0.637566, acc.: 60.16%] [G loss: 0.626550]\n",
      "epoch:21 step:20078 [D loss: 0.610588, acc.: 59.38%] [G loss: 0.487196]\n",
      "epoch:21 step:20079 [D loss: 0.526084, acc.: 75.00%] [G loss: 0.599565]\n",
      "epoch:21 step:20080 [D loss: 0.464745, acc.: 77.34%] [G loss: 0.832788]\n",
      "epoch:21 step:20081 [D loss: 0.613699, acc.: 63.28%] [G loss: 0.593406]\n",
      "epoch:21 step:20082 [D loss: 0.516036, acc.: 71.88%] [G loss: 0.756630]\n",
      "epoch:21 step:20083 [D loss: 0.454951, acc.: 74.22%] [G loss: 0.695979]\n",
      "epoch:21 step:20084 [D loss: 0.549528, acc.: 74.22%] [G loss: 0.706306]\n",
      "epoch:21 step:20085 [D loss: 0.564577, acc.: 65.62%] [G loss: 0.727019]\n",
      "epoch:21 step:20086 [D loss: 0.553897, acc.: 63.28%] [G loss: 0.778353]\n",
      "epoch:21 step:20087 [D loss: 0.565072, acc.: 67.97%] [G loss: 0.727911]\n",
      "epoch:21 step:20088 [D loss: 0.585746, acc.: 64.84%] [G loss: 0.651689]\n",
      "epoch:21 step:20089 [D loss: 0.593164, acc.: 64.84%] [G loss: 0.692480]\n",
      "epoch:21 step:20090 [D loss: 0.566419, acc.: 65.62%] [G loss: 0.670176]\n",
      "epoch:21 step:20091 [D loss: 0.522357, acc.: 68.75%] [G loss: 0.787957]\n",
      "epoch:21 step:20092 [D loss: 0.544708, acc.: 69.53%] [G loss: 0.714706]\n",
      "epoch:21 step:20093 [D loss: 0.447173, acc.: 77.34%] [G loss: 1.037118]\n",
      "epoch:21 step:20094 [D loss: 0.560109, acc.: 69.53%] [G loss: 0.932832]\n",
      "epoch:21 step:20095 [D loss: 0.559112, acc.: 70.31%] [G loss: 0.713091]\n",
      "epoch:21 step:20096 [D loss: 0.576805, acc.: 68.75%] [G loss: 0.610186]\n",
      "epoch:21 step:20097 [D loss: 0.618782, acc.: 62.50%] [G loss: 0.556523]\n",
      "epoch:21 step:20098 [D loss: 0.558209, acc.: 67.97%] [G loss: 0.540981]\n",
      "epoch:21 step:20099 [D loss: 0.584740, acc.: 65.62%] [G loss: 0.518755]\n",
      "epoch:21 step:20100 [D loss: 0.569322, acc.: 67.19%] [G loss: 0.572255]\n",
      "epoch:21 step:20101 [D loss: 0.582438, acc.: 66.41%] [G loss: 0.561059]\n",
      "epoch:21 step:20102 [D loss: 0.572202, acc.: 70.31%] [G loss: 0.516363]\n",
      "epoch:21 step:20103 [D loss: 0.472860, acc.: 75.00%] [G loss: 0.863614]\n",
      "epoch:21 step:20104 [D loss: 0.501191, acc.: 75.00%] [G loss: 0.975878]\n",
      "epoch:21 step:20105 [D loss: 0.503753, acc.: 73.44%] [G loss: 0.795499]\n",
      "epoch:21 step:20106 [D loss: 0.487331, acc.: 74.22%] [G loss: 0.894827]\n",
      "epoch:21 step:20107 [D loss: 0.477449, acc.: 78.12%] [G loss: 0.890623]\n",
      "epoch:21 step:20108 [D loss: 0.539853, acc.: 71.88%] [G loss: 0.762490]\n",
      "epoch:21 step:20109 [D loss: 0.542429, acc.: 72.66%] [G loss: 0.549844]\n",
      "epoch:21 step:20110 [D loss: 0.508469, acc.: 75.00%] [G loss: 0.716271]\n",
      "epoch:21 step:20111 [D loss: 0.530264, acc.: 70.31%] [G loss: 0.675968]\n",
      "epoch:21 step:20112 [D loss: 0.505896, acc.: 75.78%] [G loss: 0.808454]\n",
      "epoch:21 step:20113 [D loss: 0.492090, acc.: 77.34%] [G loss: 0.817421]\n",
      "epoch:21 step:20114 [D loss: 0.668087, acc.: 64.06%] [G loss: 0.621740]\n",
      "epoch:21 step:20115 [D loss: 0.580658, acc.: 70.31%] [G loss: 0.539277]\n",
      "epoch:21 step:20116 [D loss: 0.506170, acc.: 75.78%] [G loss: 0.718073]\n",
      "epoch:21 step:20117 [D loss: 0.477295, acc.: 78.91%] [G loss: 0.791535]\n",
      "epoch:21 step:20118 [D loss: 0.562313, acc.: 64.84%] [G loss: 0.860209]\n",
      "epoch:21 step:20119 [D loss: 0.501366, acc.: 71.88%] [G loss: 0.750059]\n",
      "epoch:21 step:20120 [D loss: 0.501235, acc.: 76.56%] [G loss: 0.732054]\n",
      "epoch:21 step:20121 [D loss: 0.521796, acc.: 71.09%] [G loss: 0.757982]\n",
      "epoch:21 step:20122 [D loss: 0.554710, acc.: 64.84%] [G loss: 0.804464]\n",
      "epoch:21 step:20123 [D loss: 0.527031, acc.: 74.22%] [G loss: 0.649740]\n",
      "epoch:21 step:20124 [D loss: 0.536173, acc.: 67.97%] [G loss: 0.778987]\n",
      "epoch:21 step:20125 [D loss: 0.506388, acc.: 78.12%] [G loss: 0.871019]\n",
      "epoch:21 step:20126 [D loss: 0.530890, acc.: 72.66%] [G loss: 0.674895]\n",
      "epoch:21 step:20127 [D loss: 0.530473, acc.: 71.09%] [G loss: 0.736877]\n",
      "epoch:21 step:20128 [D loss: 0.419751, acc.: 82.03%] [G loss: 0.855723]\n",
      "epoch:21 step:20129 [D loss: 0.437314, acc.: 75.78%] [G loss: 0.897468]\n",
      "epoch:21 step:20130 [D loss: 0.488614, acc.: 75.00%] [G loss: 0.799747]\n",
      "epoch:21 step:20131 [D loss: 0.519482, acc.: 73.44%] [G loss: 0.710808]\n",
      "epoch:21 step:20132 [D loss: 0.517630, acc.: 77.34%] [G loss: 0.781604]\n",
      "epoch:21 step:20133 [D loss: 0.557079, acc.: 72.66%] [G loss: 0.660445]\n",
      "epoch:21 step:20134 [D loss: 0.493390, acc.: 76.56%] [G loss: 0.780476]\n",
      "epoch:21 step:20135 [D loss: 0.671854, acc.: 64.84%] [G loss: 0.534692]\n",
      "epoch:21 step:20136 [D loss: 0.552759, acc.: 66.41%] [G loss: 0.658404]\n",
      "epoch:21 step:20137 [D loss: 0.492916, acc.: 76.56%] [G loss: 0.737554]\n",
      "epoch:21 step:20138 [D loss: 0.487365, acc.: 76.56%] [G loss: 0.852900]\n",
      "epoch:21 step:20139 [D loss: 0.555020, acc.: 73.44%] [G loss: 0.771328]\n",
      "epoch:21 step:20140 [D loss: 0.528524, acc.: 74.22%] [G loss: 0.651480]\n",
      "epoch:21 step:20141 [D loss: 0.489535, acc.: 73.44%] [G loss: 0.668841]\n",
      "epoch:21 step:20142 [D loss: 0.566153, acc.: 69.53%] [G loss: 0.625448]\n",
      "epoch:21 step:20143 [D loss: 0.519122, acc.: 74.22%] [G loss: 0.531058]\n",
      "epoch:21 step:20144 [D loss: 0.502301, acc.: 73.44%] [G loss: 0.716556]\n",
      "epoch:21 step:20145 [D loss: 0.542490, acc.: 68.75%] [G loss: 0.628943]\n",
      "epoch:21 step:20146 [D loss: 0.520484, acc.: 72.66%] [G loss: 0.750568]\n",
      "epoch:21 step:20147 [D loss: 0.498397, acc.: 74.22%] [G loss: 0.820014]\n",
      "epoch:21 step:20148 [D loss: 0.451832, acc.: 77.34%] [G loss: 0.745981]\n",
      "epoch:21 step:20149 [D loss: 0.457506, acc.: 78.12%] [G loss: 0.918160]\n",
      "epoch:21 step:20150 [D loss: 0.598688, acc.: 64.84%] [G loss: 0.794153]\n",
      "epoch:21 step:20151 [D loss: 0.489459, acc.: 75.00%] [G loss: 0.642686]\n",
      "epoch:21 step:20152 [D loss: 0.451382, acc.: 79.69%] [G loss: 1.003581]\n",
      "epoch:21 step:20153 [D loss: 0.478038, acc.: 82.81%] [G loss: 0.833692]\n",
      "epoch:21 step:20154 [D loss: 0.572477, acc.: 70.31%] [G loss: 0.642030]\n",
      "epoch:21 step:20155 [D loss: 0.563579, acc.: 68.75%] [G loss: 0.573361]\n",
      "epoch:21 step:20156 [D loss: 0.529571, acc.: 68.75%] [G loss: 0.520594]\n",
      "epoch:21 step:20157 [D loss: 0.601135, acc.: 63.28%] [G loss: 0.632421]\n",
      "epoch:21 step:20158 [D loss: 0.434111, acc.: 82.81%] [G loss: 0.689876]\n",
      "epoch:21 step:20159 [D loss: 0.562347, acc.: 69.53%] [G loss: 0.534860]\n",
      "epoch:21 step:20160 [D loss: 0.581379, acc.: 67.97%] [G loss: 0.536031]\n",
      "epoch:21 step:20161 [D loss: 0.468133, acc.: 78.12%] [G loss: 0.832585]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:21 step:20162 [D loss: 0.522736, acc.: 72.66%] [G loss: 0.791997]\n",
      "epoch:21 step:20163 [D loss: 0.555818, acc.: 69.53%] [G loss: 0.700755]\n",
      "epoch:21 step:20164 [D loss: 0.562563, acc.: 72.66%] [G loss: 0.602239]\n",
      "epoch:21 step:20165 [D loss: 0.488812, acc.: 71.88%] [G loss: 0.695727]\n",
      "epoch:21 step:20166 [D loss: 0.531325, acc.: 71.88%] [G loss: 0.650978]\n",
      "epoch:21 step:20167 [D loss: 0.565495, acc.: 71.09%] [G loss: 0.735290]\n",
      "epoch:21 step:20168 [D loss: 0.548101, acc.: 73.44%] [G loss: 0.677574]\n",
      "epoch:21 step:20169 [D loss: 0.549486, acc.: 68.75%] [G loss: 0.655986]\n",
      "epoch:21 step:20170 [D loss: 0.572332, acc.: 69.53%] [G loss: 0.536913]\n",
      "epoch:21 step:20171 [D loss: 0.580346, acc.: 73.44%] [G loss: 0.634007]\n",
      "epoch:21 step:20172 [D loss: 0.492426, acc.: 77.34%] [G loss: 0.501628]\n",
      "epoch:21 step:20173 [D loss: 0.509574, acc.: 77.34%] [G loss: 0.708596]\n",
      "epoch:21 step:20174 [D loss: 0.538851, acc.: 70.31%] [G loss: 0.678775]\n",
      "epoch:21 step:20175 [D loss: 0.513251, acc.: 74.22%] [G loss: 0.757325]\n",
      "epoch:21 step:20176 [D loss: 0.472643, acc.: 76.56%] [G loss: 0.833068]\n",
      "epoch:21 step:20177 [D loss: 0.492370, acc.: 76.56%] [G loss: 0.858468]\n",
      "epoch:21 step:20178 [D loss: 0.691782, acc.: 60.16%] [G loss: 0.654575]\n",
      "epoch:21 step:20179 [D loss: 0.638333, acc.: 60.94%] [G loss: 0.638172]\n",
      "epoch:21 step:20180 [D loss: 0.544653, acc.: 68.75%] [G loss: 0.567246]\n",
      "epoch:21 step:20181 [D loss: 0.482155, acc.: 78.12%] [G loss: 0.685977]\n",
      "epoch:21 step:20182 [D loss: 0.533619, acc.: 73.44%] [G loss: 0.666224]\n",
      "epoch:21 step:20183 [D loss: 0.480096, acc.: 77.34%] [G loss: 0.700808]\n",
      "epoch:21 step:20184 [D loss: 0.520212, acc.: 75.00%] [G loss: 0.812383]\n",
      "epoch:21 step:20185 [D loss: 0.454457, acc.: 77.34%] [G loss: 0.933387]\n",
      "epoch:21 step:20186 [D loss: 0.519276, acc.: 71.88%] [G loss: 0.842875]\n",
      "epoch:21 step:20187 [D loss: 0.544597, acc.: 71.09%] [G loss: 0.909646]\n",
      "epoch:21 step:20188 [D loss: 0.650886, acc.: 60.94%] [G loss: 0.524378]\n",
      "epoch:21 step:20189 [D loss: 0.558714, acc.: 70.31%] [G loss: 0.601492]\n",
      "epoch:21 step:20190 [D loss: 0.530873, acc.: 71.09%] [G loss: 0.681306]\n",
      "epoch:21 step:20191 [D loss: 0.495753, acc.: 72.66%] [G loss: 0.688945]\n",
      "epoch:21 step:20192 [D loss: 0.551519, acc.: 70.31%] [G loss: 0.664417]\n",
      "epoch:21 step:20193 [D loss: 0.472738, acc.: 79.69%] [G loss: 0.714692]\n",
      "epoch:21 step:20194 [D loss: 0.540153, acc.: 70.31%] [G loss: 0.562850]\n",
      "epoch:21 step:20195 [D loss: 0.546308, acc.: 72.66%] [G loss: 0.707326]\n",
      "epoch:21 step:20196 [D loss: 0.480329, acc.: 75.00%] [G loss: 0.628661]\n",
      "epoch:21 step:20197 [D loss: 0.490356, acc.: 74.22%] [G loss: 0.674150]\n",
      "epoch:21 step:20198 [D loss: 0.479295, acc.: 77.34%] [G loss: 0.826871]\n",
      "epoch:21 step:20199 [D loss: 0.479125, acc.: 72.66%] [G loss: 0.799133]\n",
      "epoch:21 step:20200 [D loss: 0.440263, acc.: 77.34%] [G loss: 0.852799]\n",
      "epoch:21 step:20201 [D loss: 0.530391, acc.: 68.75%] [G loss: 0.716170]\n",
      "epoch:21 step:20202 [D loss: 0.545818, acc.: 69.53%] [G loss: 0.771366]\n",
      "epoch:21 step:20203 [D loss: 0.466871, acc.: 78.12%] [G loss: 0.653372]\n",
      "epoch:21 step:20204 [D loss: 0.503277, acc.: 72.66%] [G loss: 0.657211]\n",
      "epoch:21 step:20205 [D loss: 0.697232, acc.: 57.03%] [G loss: 0.462898]\n",
      "epoch:21 step:20206 [D loss: 0.555127, acc.: 67.19%] [G loss: 0.647453]\n",
      "epoch:21 step:20207 [D loss: 0.515307, acc.: 71.88%] [G loss: 0.642148]\n",
      "epoch:21 step:20208 [D loss: 0.526624, acc.: 70.31%] [G loss: 0.678417]\n",
      "epoch:21 step:20209 [D loss: 0.578600, acc.: 64.84%] [G loss: 0.614801]\n",
      "epoch:21 step:20210 [D loss: 0.569565, acc.: 66.41%] [G loss: 0.639181]\n",
      "epoch:21 step:20211 [D loss: 0.492677, acc.: 78.12%] [G loss: 0.738987]\n",
      "epoch:21 step:20212 [D loss: 0.642745, acc.: 57.81%] [G loss: 0.589803]\n",
      "epoch:21 step:20213 [D loss: 0.484644, acc.: 75.78%] [G loss: 0.528585]\n",
      "epoch:21 step:20214 [D loss: 0.629987, acc.: 64.06%] [G loss: 0.587929]\n",
      "epoch:21 step:20215 [D loss: 0.522461, acc.: 69.53%] [G loss: 0.486552]\n",
      "epoch:21 step:20216 [D loss: 0.522901, acc.: 72.66%] [G loss: 0.774155]\n",
      "epoch:21 step:20217 [D loss: 0.541363, acc.: 68.75%] [G loss: 0.540294]\n",
      "epoch:21 step:20218 [D loss: 0.569003, acc.: 67.19%] [G loss: 0.555999]\n",
      "epoch:21 step:20219 [D loss: 0.587751, acc.: 68.75%] [G loss: 0.546242]\n",
      "epoch:21 step:20220 [D loss: 0.575248, acc.: 63.28%] [G loss: 0.656556]\n",
      "epoch:21 step:20221 [D loss: 0.543147, acc.: 68.75%] [G loss: 0.534310]\n",
      "epoch:21 step:20222 [D loss: 0.527653, acc.: 74.22%] [G loss: 0.630134]\n",
      "epoch:21 step:20223 [D loss: 0.485284, acc.: 75.78%] [G loss: 0.754560]\n",
      "epoch:21 step:20224 [D loss: 0.516397, acc.: 75.78%] [G loss: 0.756340]\n",
      "epoch:21 step:20225 [D loss: 0.486475, acc.: 71.09%] [G loss: 0.682231]\n",
      "epoch:21 step:20226 [D loss: 0.536886, acc.: 68.75%] [G loss: 0.877124]\n",
      "epoch:21 step:20227 [D loss: 0.507238, acc.: 72.66%] [G loss: 0.732242]\n",
      "epoch:21 step:20228 [D loss: 0.473640, acc.: 74.22%] [G loss: 0.777476]\n",
      "epoch:21 step:20229 [D loss: 0.496085, acc.: 73.44%] [G loss: 0.856539]\n",
      "epoch:21 step:20230 [D loss: 0.608057, acc.: 67.19%] [G loss: 0.625297]\n",
      "epoch:21 step:20231 [D loss: 0.442191, acc.: 75.78%] [G loss: 0.849875]\n",
      "epoch:21 step:20232 [D loss: 0.470075, acc.: 78.91%] [G loss: 0.855174]\n",
      "epoch:21 step:20233 [D loss: 0.531943, acc.: 71.09%] [G loss: 0.728855]\n",
      "epoch:21 step:20234 [D loss: 0.511411, acc.: 75.00%] [G loss: 0.785048]\n",
      "epoch:21 step:20235 [D loss: 0.464683, acc.: 77.34%] [G loss: 0.809969]\n",
      "epoch:21 step:20236 [D loss: 0.567750, acc.: 66.41%] [G loss: 0.659840]\n",
      "epoch:21 step:20237 [D loss: 0.562878, acc.: 64.06%] [G loss: 0.600423]\n",
      "epoch:21 step:20238 [D loss: 0.518215, acc.: 74.22%] [G loss: 0.738627]\n",
      "epoch:21 step:20239 [D loss: 0.583101, acc.: 66.41%] [G loss: 0.763788]\n",
      "epoch:21 step:20240 [D loss: 0.524246, acc.: 71.88%] [G loss: 0.773265]\n",
      "epoch:21 step:20241 [D loss: 0.476887, acc.: 74.22%] [G loss: 0.940265]\n",
      "epoch:21 step:20242 [D loss: 0.563111, acc.: 74.22%] [G loss: 0.679928]\n",
      "epoch:21 step:20243 [D loss: 0.762133, acc.: 61.72%] [G loss: 0.551206]\n",
      "epoch:21 step:20244 [D loss: 0.529971, acc.: 75.78%] [G loss: 0.560971]\n",
      "epoch:21 step:20245 [D loss: 0.487867, acc.: 77.34%] [G loss: 0.633077]\n",
      "epoch:21 step:20246 [D loss: 0.519593, acc.: 71.09%] [G loss: 0.596612]\n",
      "epoch:21 step:20247 [D loss: 0.504705, acc.: 75.00%] [G loss: 0.546411]\n",
      "epoch:21 step:20248 [D loss: 0.539045, acc.: 73.44%] [G loss: 0.746353]\n",
      "epoch:21 step:20249 [D loss: 0.556639, acc.: 72.66%] [G loss: 0.728890]\n",
      "epoch:21 step:20250 [D loss: 0.524952, acc.: 72.66%] [G loss: 0.686739]\n",
      "epoch:21 step:20251 [D loss: 0.492355, acc.: 75.78%] [G loss: 0.747804]\n",
      "epoch:21 step:20252 [D loss: 0.506899, acc.: 73.44%] [G loss: 0.912638]\n",
      "epoch:21 step:20253 [D loss: 0.571353, acc.: 67.97%] [G loss: 0.764107]\n",
      "epoch:21 step:20254 [D loss: 0.551237, acc.: 71.09%] [G loss: 0.667028]\n",
      "epoch:21 step:20255 [D loss: 0.577672, acc.: 67.19%] [G loss: 0.555335]\n",
      "epoch:21 step:20256 [D loss: 0.537873, acc.: 68.75%] [G loss: 0.687518]\n",
      "epoch:21 step:20257 [D loss: 0.555392, acc.: 69.53%] [G loss: 0.615254]\n",
      "epoch:21 step:20258 [D loss: 0.498827, acc.: 75.00%] [G loss: 0.774925]\n",
      "epoch:21 step:20259 [D loss: 0.458226, acc.: 77.34%] [G loss: 0.799877]\n",
      "epoch:21 step:20260 [D loss: 0.516002, acc.: 73.44%] [G loss: 0.736217]\n",
      "epoch:21 step:20261 [D loss: 0.570466, acc.: 67.97%] [G loss: 0.568048]\n",
      "epoch:21 step:20262 [D loss: 0.520188, acc.: 73.44%] [G loss: 0.739153]\n",
      "epoch:21 step:20263 [D loss: 0.524338, acc.: 71.09%] [G loss: 0.610832]\n",
      "epoch:21 step:20264 [D loss: 0.548358, acc.: 69.53%] [G loss: 0.684474]\n",
      "epoch:21 step:20265 [D loss: 0.522866, acc.: 70.31%] [G loss: 0.676069]\n",
      "epoch:21 step:20266 [D loss: 0.531231, acc.: 69.53%] [G loss: 0.818527]\n",
      "epoch:21 step:20267 [D loss: 0.593427, acc.: 70.31%] [G loss: 0.735439]\n",
      "epoch:21 step:20268 [D loss: 0.559942, acc.: 72.66%] [G loss: 0.555907]\n",
      "epoch:21 step:20269 [D loss: 0.499966, acc.: 76.56%] [G loss: 0.548924]\n",
      "epoch:21 step:20270 [D loss: 0.509581, acc.: 77.34%] [G loss: 0.683847]\n",
      "epoch:21 step:20271 [D loss: 0.524172, acc.: 72.66%] [G loss: 0.642778]\n",
      "epoch:21 step:20272 [D loss: 0.538016, acc.: 71.88%] [G loss: 0.727365]\n",
      "epoch:21 step:20273 [D loss: 0.541027, acc.: 71.09%] [G loss: 0.612576]\n",
      "epoch:21 step:20274 [D loss: 0.525035, acc.: 71.09%] [G loss: 0.535550]\n",
      "epoch:21 step:20275 [D loss: 0.476445, acc.: 77.34%] [G loss: 0.795974]\n",
      "epoch:21 step:20276 [D loss: 0.564800, acc.: 67.97%] [G loss: 0.678098]\n",
      "epoch:21 step:20277 [D loss: 0.512175, acc.: 75.78%] [G loss: 0.635716]\n",
      "epoch:21 step:20278 [D loss: 0.457187, acc.: 82.81%] [G loss: 0.723083]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:21 step:20279 [D loss: 0.440602, acc.: 82.03%] [G loss: 0.934226]\n",
      "epoch:21 step:20280 [D loss: 0.470326, acc.: 76.56%] [G loss: 0.992995]\n",
      "epoch:21 step:20281 [D loss: 0.592634, acc.: 70.31%] [G loss: 0.882060]\n",
      "epoch:21 step:20282 [D loss: 0.471931, acc.: 75.78%] [G loss: 0.811057]\n",
      "epoch:21 step:20283 [D loss: 0.629984, acc.: 67.19%] [G loss: 0.652420]\n",
      "epoch:21 step:20284 [D loss: 0.522566, acc.: 71.88%] [G loss: 0.617488]\n",
      "epoch:21 step:20285 [D loss: 0.555345, acc.: 67.19%] [G loss: 0.665142]\n",
      "epoch:21 step:20286 [D loss: 0.545552, acc.: 68.75%] [G loss: 0.623621]\n",
      "epoch:21 step:20287 [D loss: 0.550154, acc.: 68.75%] [G loss: 0.640443]\n",
      "epoch:21 step:20288 [D loss: 0.473920, acc.: 77.34%] [G loss: 0.697722]\n",
      "epoch:21 step:20289 [D loss: 0.522695, acc.: 69.53%] [G loss: 0.662642]\n",
      "epoch:21 step:20290 [D loss: 0.507562, acc.: 71.88%] [G loss: 0.637688]\n",
      "epoch:21 step:20291 [D loss: 0.593264, acc.: 63.28%] [G loss: 0.514330]\n",
      "epoch:21 step:20292 [D loss: 0.556340, acc.: 67.19%] [G loss: 0.535273]\n",
      "epoch:21 step:20293 [D loss: 0.569820, acc.: 69.53%] [G loss: 0.739724]\n",
      "epoch:21 step:20294 [D loss: 0.474625, acc.: 80.47%] [G loss: 1.017465]\n",
      "epoch:21 step:20295 [D loss: 0.555347, acc.: 69.53%] [G loss: 0.728888]\n",
      "epoch:21 step:20296 [D loss: 0.547565, acc.: 69.53%] [G loss: 0.875093]\n",
      "epoch:21 step:20297 [D loss: 0.491672, acc.: 77.34%] [G loss: 0.760024]\n",
      "epoch:21 step:20298 [D loss: 0.564583, acc.: 68.75%] [G loss: 0.683803]\n",
      "epoch:21 step:20299 [D loss: 0.564451, acc.: 71.88%] [G loss: 0.748398]\n",
      "epoch:21 step:20300 [D loss: 0.466626, acc.: 75.00%] [G loss: 0.827843]\n",
      "epoch:21 step:20301 [D loss: 0.428931, acc.: 83.59%] [G loss: 0.851704]\n",
      "epoch:21 step:20302 [D loss: 0.606850, acc.: 64.06%] [G loss: 0.826174]\n",
      "epoch:21 step:20303 [D loss: 0.555162, acc.: 67.97%] [G loss: 0.507083]\n",
      "epoch:21 step:20304 [D loss: 0.529724, acc.: 66.41%] [G loss: 0.751019]\n",
      "epoch:21 step:20305 [D loss: 0.551915, acc.: 74.22%] [G loss: 0.621841]\n",
      "epoch:21 step:20306 [D loss: 0.485331, acc.: 78.12%] [G loss: 0.667255]\n",
      "epoch:21 step:20307 [D loss: 0.509422, acc.: 75.00%] [G loss: 0.590814]\n",
      "epoch:21 step:20308 [D loss: 0.437665, acc.: 83.59%] [G loss: 0.794961]\n",
      "epoch:21 step:20309 [D loss: 0.479146, acc.: 73.44%] [G loss: 0.851525]\n",
      "epoch:21 step:20310 [D loss: 0.508191, acc.: 75.78%] [G loss: 0.681490]\n",
      "epoch:21 step:20311 [D loss: 0.449292, acc.: 81.25%] [G loss: 0.733877]\n",
      "epoch:21 step:20312 [D loss: 0.497128, acc.: 78.12%] [G loss: 0.878528]\n",
      "epoch:21 step:20313 [D loss: 0.578893, acc.: 71.09%] [G loss: 0.615815]\n",
      "epoch:21 step:20314 [D loss: 0.506663, acc.: 72.66%] [G loss: 0.614668]\n",
      "epoch:21 step:20315 [D loss: 0.495980, acc.: 73.44%] [G loss: 0.549893]\n",
      "epoch:21 step:20316 [D loss: 0.457915, acc.: 78.12%] [G loss: 0.717742]\n",
      "epoch:21 step:20317 [D loss: 0.521824, acc.: 72.66%] [G loss: 0.884711]\n",
      "epoch:21 step:20318 [D loss: 0.469384, acc.: 74.22%] [G loss: 1.057877]\n",
      "epoch:21 step:20319 [D loss: 0.444673, acc.: 79.69%] [G loss: 0.966733]\n",
      "epoch:21 step:20320 [D loss: 0.543506, acc.: 71.09%] [G loss: 0.891011]\n",
      "epoch:21 step:20321 [D loss: 0.509736, acc.: 73.44%] [G loss: 0.863764]\n",
      "epoch:21 step:20322 [D loss: 0.556064, acc.: 67.19%] [G loss: 0.660714]\n",
      "epoch:21 step:20323 [D loss: 0.557811, acc.: 71.88%] [G loss: 0.660695]\n",
      "epoch:21 step:20324 [D loss: 0.387995, acc.: 83.59%] [G loss: 0.773507]\n",
      "epoch:21 step:20325 [D loss: 0.361473, acc.: 84.38%] [G loss: 1.011144]\n",
      "epoch:21 step:20326 [D loss: 0.518698, acc.: 74.22%] [G loss: 0.812235]\n",
      "epoch:21 step:20327 [D loss: 0.484306, acc.: 74.22%] [G loss: 0.904950]\n",
      "epoch:21 step:20328 [D loss: 0.475948, acc.: 74.22%] [G loss: 0.872002]\n",
      "epoch:21 step:20329 [D loss: 0.553713, acc.: 67.97%] [G loss: 0.748106]\n",
      "epoch:21 step:20330 [D loss: 0.507600, acc.: 79.69%] [G loss: 0.666858]\n",
      "epoch:21 step:20331 [D loss: 0.430111, acc.: 78.12%] [G loss: 0.778549]\n",
      "epoch:21 step:20332 [D loss: 0.580107, acc.: 70.31%] [G loss: 0.709787]\n",
      "epoch:21 step:20333 [D loss: 0.538846, acc.: 71.09%] [G loss: 0.593608]\n",
      "epoch:21 step:20334 [D loss: 0.483498, acc.: 75.78%] [G loss: 0.748310]\n",
      "epoch:21 step:20335 [D loss: 0.578534, acc.: 67.97%] [G loss: 0.764693]\n",
      "epoch:21 step:20336 [D loss: 0.473762, acc.: 75.78%] [G loss: 0.880292]\n",
      "epoch:21 step:20337 [D loss: 0.519960, acc.: 72.66%] [G loss: 0.714693]\n",
      "epoch:21 step:20338 [D loss: 0.505386, acc.: 76.56%] [G loss: 0.879202]\n",
      "epoch:21 step:20339 [D loss: 0.528846, acc.: 73.44%] [G loss: 0.719029]\n",
      "epoch:21 step:20340 [D loss: 0.617206, acc.: 61.72%] [G loss: 0.678523]\n",
      "epoch:21 step:20341 [D loss: 0.607068, acc.: 64.84%] [G loss: 0.523609]\n",
      "epoch:21 step:20342 [D loss: 0.536663, acc.: 66.41%] [G loss: 0.894727]\n",
      "epoch:21 step:20343 [D loss: 0.531131, acc.: 67.97%] [G loss: 0.767337]\n",
      "epoch:21 step:20344 [D loss: 0.497617, acc.: 73.44%] [G loss: 0.673871]\n",
      "epoch:21 step:20345 [D loss: 0.564999, acc.: 70.31%] [G loss: 0.726746]\n",
      "epoch:21 step:20346 [D loss: 0.563427, acc.: 70.31%] [G loss: 0.700526]\n",
      "epoch:21 step:20347 [D loss: 0.563182, acc.: 71.88%] [G loss: 0.582768]\n",
      "epoch:21 step:20348 [D loss: 0.590551, acc.: 68.75%] [G loss: 0.657203]\n",
      "epoch:21 step:20349 [D loss: 0.527351, acc.: 71.88%] [G loss: 0.768660]\n",
      "epoch:21 step:20350 [D loss: 0.576216, acc.: 71.88%] [G loss: 0.740917]\n",
      "epoch:21 step:20351 [D loss: 0.529464, acc.: 71.88%] [G loss: 0.895828]\n",
      "epoch:21 step:20352 [D loss: 0.560716, acc.: 65.62%] [G loss: 0.703025]\n",
      "epoch:21 step:20353 [D loss: 0.531687, acc.: 71.09%] [G loss: 0.815292]\n",
      "epoch:21 step:20354 [D loss: 0.496868, acc.: 70.31%] [G loss: 0.831238]\n",
      "epoch:21 step:20355 [D loss: 0.559160, acc.: 67.19%] [G loss: 0.707460]\n",
      "epoch:21 step:20356 [D loss: 0.536144, acc.: 70.31%] [G loss: 0.619385]\n",
      "epoch:21 step:20357 [D loss: 0.502737, acc.: 72.66%] [G loss: 0.744481]\n",
      "epoch:21 step:20358 [D loss: 0.491706, acc.: 71.09%] [G loss: 0.792164]\n",
      "epoch:21 step:20359 [D loss: 0.524731, acc.: 71.09%] [G loss: 0.771743]\n",
      "epoch:21 step:20360 [D loss: 0.517522, acc.: 71.88%] [G loss: 0.781609]\n",
      "epoch:21 step:20361 [D loss: 0.614886, acc.: 64.06%] [G loss: 0.582891]\n",
      "epoch:21 step:20362 [D loss: 0.491597, acc.: 75.78%] [G loss: 0.554559]\n",
      "epoch:21 step:20363 [D loss: 0.500036, acc.: 78.12%] [G loss: 0.584018]\n",
      "epoch:21 step:20364 [D loss: 0.541000, acc.: 71.09%] [G loss: 0.572197]\n",
      "epoch:21 step:20365 [D loss: 0.514093, acc.: 69.53%] [G loss: 0.675167]\n",
      "epoch:21 step:20366 [D loss: 0.565125, acc.: 61.72%] [G loss: 0.557955]\n",
      "epoch:21 step:20367 [D loss: 0.498568, acc.: 72.66%] [G loss: 0.700997]\n",
      "epoch:21 step:20368 [D loss: 0.469812, acc.: 78.12%] [G loss: 0.665410]\n",
      "epoch:21 step:20369 [D loss: 0.477055, acc.: 77.34%] [G loss: 0.855758]\n",
      "epoch:21 step:20370 [D loss: 0.434463, acc.: 83.59%] [G loss: 0.749265]\n",
      "epoch:21 step:20371 [D loss: 0.492224, acc.: 75.78%] [G loss: 0.793946]\n",
      "epoch:21 step:20372 [D loss: 0.506909, acc.: 73.44%] [G loss: 0.813364]\n",
      "epoch:21 step:20373 [D loss: 0.630966, acc.: 61.72%] [G loss: 0.548706]\n",
      "epoch:21 step:20374 [D loss: 0.609057, acc.: 63.28%] [G loss: 0.501362]\n",
      "epoch:21 step:20375 [D loss: 0.598951, acc.: 70.31%] [G loss: 0.634224]\n",
      "epoch:21 step:20376 [D loss: 0.509287, acc.: 75.00%] [G loss: 0.537932]\n",
      "epoch:21 step:20377 [D loss: 0.529439, acc.: 65.62%] [G loss: 0.686274]\n",
      "epoch:21 step:20378 [D loss: 0.552388, acc.: 68.75%] [G loss: 0.828530]\n",
      "epoch:21 step:20379 [D loss: 0.575498, acc.: 68.75%] [G loss: 0.757008]\n",
      "epoch:21 step:20380 [D loss: 0.586872, acc.: 66.41%] [G loss: 0.569590]\n",
      "epoch:21 step:20381 [D loss: 0.583136, acc.: 70.31%] [G loss: 0.609770]\n",
      "epoch:21 step:20382 [D loss: 0.536362, acc.: 70.31%] [G loss: 0.577786]\n",
      "epoch:21 step:20383 [D loss: 0.469979, acc.: 78.12%] [G loss: 0.662318]\n",
      "epoch:21 step:20384 [D loss: 0.482745, acc.: 73.44%] [G loss: 0.610292]\n",
      "epoch:21 step:20385 [D loss: 0.514578, acc.: 74.22%] [G loss: 0.600375]\n",
      "epoch:21 step:20386 [D loss: 0.507737, acc.: 74.22%] [G loss: 0.759225]\n",
      "epoch:21 step:20387 [D loss: 0.542912, acc.: 71.88%] [G loss: 0.638426]\n",
      "epoch:21 step:20388 [D loss: 0.606785, acc.: 59.38%] [G loss: 0.648086]\n",
      "epoch:21 step:20389 [D loss: 0.484317, acc.: 75.00%] [G loss: 0.677439]\n",
      "epoch:21 step:20390 [D loss: 0.553962, acc.: 68.75%] [G loss: 0.687199]\n",
      "epoch:21 step:20391 [D loss: 0.535596, acc.: 67.97%] [G loss: 0.674014]\n",
      "epoch:21 step:20392 [D loss: 0.563736, acc.: 71.88%] [G loss: 0.681358]\n",
      "epoch:21 step:20393 [D loss: 0.600927, acc.: 67.97%] [G loss: 0.568631]\n",
      "epoch:21 step:20394 [D loss: 0.530685, acc.: 67.97%] [G loss: 0.581833]\n",
      "epoch:21 step:20395 [D loss: 0.553053, acc.: 66.41%] [G loss: 0.637604]\n",
      "epoch:21 step:20396 [D loss: 0.480175, acc.: 78.12%] [G loss: 0.736261]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:21 step:20397 [D loss: 0.597607, acc.: 67.19%] [G loss: 0.693405]\n",
      "epoch:21 step:20398 [D loss: 0.519973, acc.: 70.31%] [G loss: 0.610861]\n",
      "epoch:21 step:20399 [D loss: 0.534464, acc.: 72.66%] [G loss: 0.790361]\n",
      "epoch:21 step:20400 [D loss: 0.510516, acc.: 75.00%] [G loss: 0.536189]\n",
      "epoch:21 step:20401 [D loss: 0.540761, acc.: 67.97%] [G loss: 0.601539]\n",
      "epoch:21 step:20402 [D loss: 0.462922, acc.: 76.56%] [G loss: 0.804926]\n",
      "epoch:21 step:20403 [D loss: 0.499385, acc.: 78.12%] [G loss: 0.830498]\n",
      "epoch:21 step:20404 [D loss: 0.555512, acc.: 67.97%] [G loss: 0.796815]\n",
      "epoch:21 step:20405 [D loss: 0.541388, acc.: 71.09%] [G loss: 0.644827]\n",
      "epoch:21 step:20406 [D loss: 0.551120, acc.: 69.53%] [G loss: 0.735814]\n",
      "epoch:21 step:20407 [D loss: 0.545431, acc.: 67.97%] [G loss: 0.545079]\n",
      "epoch:21 step:20408 [D loss: 0.552495, acc.: 64.06%] [G loss: 0.709205]\n",
      "epoch:21 step:20409 [D loss: 0.512874, acc.: 70.31%] [G loss: 0.815382]\n",
      "epoch:21 step:20410 [D loss: 0.580545, acc.: 70.31%] [G loss: 0.747160]\n",
      "epoch:21 step:20411 [D loss: 0.538498, acc.: 67.97%] [G loss: 0.633640]\n",
      "epoch:21 step:20412 [D loss: 0.612706, acc.: 63.28%] [G loss: 0.573052]\n",
      "epoch:21 step:20413 [D loss: 0.510501, acc.: 75.00%] [G loss: 0.625902]\n",
      "epoch:21 step:20414 [D loss: 0.518238, acc.: 72.66%] [G loss: 0.760390]\n",
      "epoch:21 step:20415 [D loss: 0.539457, acc.: 68.75%] [G loss: 0.697313]\n",
      "epoch:21 step:20416 [D loss: 0.556427, acc.: 71.09%] [G loss: 0.659753]\n",
      "epoch:21 step:20417 [D loss: 0.633690, acc.: 61.72%] [G loss: 0.415146]\n",
      "epoch:21 step:20418 [D loss: 0.503836, acc.: 75.00%] [G loss: 0.531327]\n",
      "epoch:21 step:20419 [D loss: 0.507099, acc.: 75.00%] [G loss: 0.696710]\n",
      "epoch:21 step:20420 [D loss: 0.494709, acc.: 77.34%] [G loss: 0.761560]\n",
      "epoch:21 step:20421 [D loss: 0.526078, acc.: 77.34%] [G loss: 0.664524]\n",
      "epoch:21 step:20422 [D loss: 0.580198, acc.: 66.41%] [G loss: 0.534072]\n",
      "epoch:21 step:20423 [D loss: 0.457812, acc.: 80.47%] [G loss: 0.753582]\n",
      "epoch:21 step:20424 [D loss: 0.410058, acc.: 79.69%] [G loss: 0.754541]\n",
      "epoch:21 step:20425 [D loss: 0.562395, acc.: 68.75%] [G loss: 0.759997]\n",
      "epoch:21 step:20426 [D loss: 0.535622, acc.: 69.53%] [G loss: 0.727541]\n",
      "epoch:21 step:20427 [D loss: 0.484932, acc.: 75.00%] [G loss: 0.748256]\n",
      "epoch:21 step:20428 [D loss: 0.504974, acc.: 73.44%] [G loss: 0.703338]\n",
      "epoch:21 step:20429 [D loss: 0.576478, acc.: 67.97%] [G loss: 0.526725]\n",
      "epoch:21 step:20430 [D loss: 0.490172, acc.: 75.78%] [G loss: 0.610573]\n",
      "epoch:21 step:20431 [D loss: 0.541561, acc.: 71.09%] [G loss: 0.660844]\n",
      "epoch:21 step:20432 [D loss: 0.545701, acc.: 66.41%] [G loss: 0.743353]\n",
      "epoch:21 step:20433 [D loss: 0.554235, acc.: 69.53%] [G loss: 0.851551]\n",
      "epoch:21 step:20434 [D loss: 0.567775, acc.: 71.09%] [G loss: 0.750089]\n",
      "epoch:21 step:20435 [D loss: 0.541993, acc.: 71.88%] [G loss: 0.697256]\n",
      "epoch:21 step:20436 [D loss: 0.570625, acc.: 72.66%] [G loss: 0.658177]\n",
      "epoch:21 step:20437 [D loss: 0.481002, acc.: 74.22%] [G loss: 0.759995]\n",
      "epoch:21 step:20438 [D loss: 0.531112, acc.: 71.09%] [G loss: 0.571746]\n",
      "epoch:21 step:20439 [D loss: 0.571137, acc.: 67.19%] [G loss: 0.570057]\n",
      "epoch:21 step:20440 [D loss: 0.478427, acc.: 75.00%] [G loss: 0.722133]\n",
      "epoch:21 step:20441 [D loss: 0.566320, acc.: 71.88%] [G loss: 0.628788]\n",
      "epoch:21 step:20442 [D loss: 0.548806, acc.: 70.31%] [G loss: 0.614803]\n",
      "epoch:21 step:20443 [D loss: 0.651014, acc.: 59.38%] [G loss: 0.435816]\n",
      "epoch:21 step:20444 [D loss: 0.489289, acc.: 72.66%] [G loss: 0.604933]\n",
      "epoch:21 step:20445 [D loss: 0.503527, acc.: 71.88%] [G loss: 0.737248]\n",
      "epoch:21 step:20446 [D loss: 0.504557, acc.: 76.56%] [G loss: 0.852230]\n",
      "epoch:21 step:20447 [D loss: 0.516240, acc.: 74.22%] [G loss: 0.978922]\n",
      "epoch:21 step:20448 [D loss: 0.485367, acc.: 75.78%] [G loss: 0.907968]\n",
      "epoch:21 step:20449 [D loss: 0.532525, acc.: 70.31%] [G loss: 0.961274]\n",
      "epoch:21 step:20450 [D loss: 0.539594, acc.: 71.88%] [G loss: 0.767167]\n",
      "epoch:21 step:20451 [D loss: 0.521376, acc.: 71.88%] [G loss: 0.650694]\n",
      "epoch:21 step:20452 [D loss: 0.533233, acc.: 71.09%] [G loss: 0.693926]\n",
      "epoch:21 step:20453 [D loss: 0.579841, acc.: 70.31%] [G loss: 0.817040]\n",
      "epoch:21 step:20454 [D loss: 0.591311, acc.: 64.84%] [G loss: 0.702764]\n",
      "epoch:21 step:20455 [D loss: 0.573215, acc.: 69.53%] [G loss: 0.579777]\n",
      "epoch:21 step:20456 [D loss: 0.566503, acc.: 65.62%] [G loss: 0.685430]\n",
      "epoch:21 step:20457 [D loss: 0.529965, acc.: 73.44%] [G loss: 0.678127]\n",
      "epoch:21 step:20458 [D loss: 0.509707, acc.: 70.31%] [G loss: 0.803081]\n",
      "epoch:21 step:20459 [D loss: 0.488091, acc.: 77.34%] [G loss: 0.844999]\n",
      "epoch:21 step:20460 [D loss: 0.494813, acc.: 72.66%] [G loss: 0.951476]\n",
      "epoch:21 step:20461 [D loss: 0.598450, acc.: 65.62%] [G loss: 0.637589]\n",
      "epoch:21 step:20462 [D loss: 0.545242, acc.: 70.31%] [G loss: 0.853692]\n",
      "epoch:21 step:20463 [D loss: 0.495879, acc.: 74.22%] [G loss: 0.645975]\n",
      "epoch:21 step:20464 [D loss: 0.625917, acc.: 64.06%] [G loss: 0.643898]\n",
      "epoch:21 step:20465 [D loss: 0.650492, acc.: 61.72%] [G loss: 0.443258]\n",
      "epoch:21 step:20466 [D loss: 0.482977, acc.: 75.78%] [G loss: 0.608293]\n",
      "epoch:21 step:20467 [D loss: 0.546449, acc.: 68.75%] [G loss: 0.711772]\n",
      "epoch:21 step:20468 [D loss: 0.517740, acc.: 71.09%] [G loss: 0.680684]\n",
      "epoch:21 step:20469 [D loss: 0.482510, acc.: 76.56%] [G loss: 0.711555]\n",
      "epoch:21 step:20470 [D loss: 0.612708, acc.: 65.62%] [G loss: 0.704546]\n",
      "epoch:21 step:20471 [D loss: 0.633104, acc.: 63.28%] [G loss: 0.769187]\n",
      "epoch:21 step:20472 [D loss: 0.519756, acc.: 72.66%] [G loss: 0.837883]\n",
      "epoch:21 step:20473 [D loss: 0.559282, acc.: 66.41%] [G loss: 0.812929]\n",
      "epoch:21 step:20474 [D loss: 0.503111, acc.: 73.44%] [G loss: 0.709195]\n",
      "epoch:21 step:20475 [D loss: 0.551275, acc.: 64.84%] [G loss: 0.537343]\n",
      "epoch:21 step:20476 [D loss: 0.543459, acc.: 69.53%] [G loss: 0.745970]\n",
      "epoch:21 step:20477 [D loss: 0.603564, acc.: 64.06%] [G loss: 0.588690]\n",
      "epoch:21 step:20478 [D loss: 0.448012, acc.: 77.34%] [G loss: 0.772982]\n",
      "epoch:21 step:20479 [D loss: 0.493676, acc.: 72.66%] [G loss: 0.681736]\n",
      "epoch:21 step:20480 [D loss: 0.516575, acc.: 75.00%] [G loss: 0.660622]\n",
      "epoch:21 step:20481 [D loss: 0.483806, acc.: 74.22%] [G loss: 0.682183]\n",
      "epoch:21 step:20482 [D loss: 0.532735, acc.: 67.19%] [G loss: 0.622568]\n",
      "epoch:21 step:20483 [D loss: 0.535804, acc.: 69.53%] [G loss: 0.517256]\n",
      "epoch:21 step:20484 [D loss: 0.555630, acc.: 67.19%] [G loss: 0.627486]\n",
      "epoch:21 step:20485 [D loss: 0.565067, acc.: 71.88%] [G loss: 0.592339]\n",
      "epoch:21 step:20486 [D loss: 0.480118, acc.: 79.69%] [G loss: 0.635200]\n",
      "epoch:21 step:20487 [D loss: 0.488207, acc.: 78.91%] [G loss: 0.766766]\n",
      "epoch:21 step:20488 [D loss: 0.559251, acc.: 68.75%] [G loss: 0.720641]\n",
      "epoch:21 step:20489 [D loss: 0.597769, acc.: 67.97%] [G loss: 0.479782]\n",
      "epoch:21 step:20490 [D loss: 0.503817, acc.: 75.78%] [G loss: 0.653515]\n",
      "epoch:21 step:20491 [D loss: 0.472469, acc.: 75.78%] [G loss: 0.822513]\n",
      "epoch:21 step:20492 [D loss: 0.427965, acc.: 81.25%] [G loss: 0.875783]\n",
      "epoch:21 step:20493 [D loss: 0.556459, acc.: 71.88%] [G loss: 0.926538]\n",
      "epoch:21 step:20494 [D loss: 0.556578, acc.: 71.09%] [G loss: 0.771003]\n",
      "epoch:21 step:20495 [D loss: 0.616516, acc.: 68.75%] [G loss: 0.616820]\n",
      "epoch:21 step:20496 [D loss: 0.489408, acc.: 76.56%] [G loss: 0.737570]\n",
      "epoch:21 step:20497 [D loss: 0.607735, acc.: 64.84%] [G loss: 0.592280]\n",
      "epoch:21 step:20498 [D loss: 0.538264, acc.: 70.31%] [G loss: 0.516736]\n",
      "epoch:21 step:20499 [D loss: 0.626446, acc.: 58.59%] [G loss: 0.498267]\n",
      "epoch:21 step:20500 [D loss: 0.416542, acc.: 82.03%] [G loss: 0.729850]\n",
      "epoch:21 step:20501 [D loss: 0.556672, acc.: 66.41%] [G loss: 0.656007]\n",
      "epoch:21 step:20502 [D loss: 0.464934, acc.: 73.44%] [G loss: 0.753591]\n",
      "epoch:21 step:20503 [D loss: 0.482084, acc.: 75.00%] [G loss: 0.744947]\n",
      "epoch:21 step:20504 [D loss: 0.546078, acc.: 70.31%] [G loss: 0.617226]\n",
      "epoch:21 step:20505 [D loss: 0.637284, acc.: 64.84%] [G loss: 0.664931]\n",
      "epoch:21 step:20506 [D loss: 0.559027, acc.: 68.75%] [G loss: 0.578590]\n",
      "epoch:21 step:20507 [D loss: 0.506231, acc.: 74.22%] [G loss: 0.692774]\n",
      "epoch:21 step:20508 [D loss: 0.528637, acc.: 76.56%] [G loss: 0.601366]\n",
      "epoch:21 step:20509 [D loss: 0.542457, acc.: 65.62%] [G loss: 0.625231]\n",
      "epoch:21 step:20510 [D loss: 0.502832, acc.: 73.44%] [G loss: 0.608693]\n",
      "epoch:21 step:20511 [D loss: 0.499214, acc.: 74.22%] [G loss: 0.572987]\n",
      "epoch:21 step:20512 [D loss: 0.470663, acc.: 75.78%] [G loss: 0.644155]\n",
      "epoch:21 step:20513 [D loss: 0.569321, acc.: 72.66%] [G loss: 0.672623]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:21 step:20514 [D loss: 0.500839, acc.: 75.00%] [G loss: 0.521618]\n",
      "epoch:21 step:20515 [D loss: 0.506966, acc.: 75.00%] [G loss: 0.550367]\n",
      "epoch:21 step:20516 [D loss: 0.562497, acc.: 64.84%] [G loss: 0.577555]\n",
      "epoch:21 step:20517 [D loss: 0.599448, acc.: 64.84%] [G loss: 0.640686]\n",
      "epoch:21 step:20518 [D loss: 0.561600, acc.: 65.62%] [G loss: 0.544636]\n",
      "epoch:21 step:20519 [D loss: 0.504112, acc.: 71.09%] [G loss: 0.630963]\n",
      "epoch:21 step:20520 [D loss: 0.493839, acc.: 79.69%] [G loss: 0.694159]\n",
      "epoch:21 step:20521 [D loss: 0.495148, acc.: 77.34%] [G loss: 0.832236]\n",
      "epoch:21 step:20522 [D loss: 0.553019, acc.: 70.31%] [G loss: 0.683868]\n",
      "epoch:21 step:20523 [D loss: 0.553192, acc.: 70.31%] [G loss: 0.624972]\n",
      "epoch:21 step:20524 [D loss: 0.639023, acc.: 60.16%] [G loss: 0.348625]\n",
      "epoch:21 step:20525 [D loss: 0.550145, acc.: 65.62%] [G loss: 0.521342]\n",
      "epoch:21 step:20526 [D loss: 0.535016, acc.: 69.53%] [G loss: 0.574204]\n",
      "epoch:21 step:20527 [D loss: 0.515747, acc.: 75.78%] [G loss: 0.641132]\n",
      "epoch:21 step:20528 [D loss: 0.572473, acc.: 64.84%] [G loss: 0.587623]\n",
      "epoch:21 step:20529 [D loss: 0.509713, acc.: 73.44%] [G loss: 0.592123]\n",
      "epoch:21 step:20530 [D loss: 0.527161, acc.: 69.53%] [G loss: 0.658562]\n",
      "epoch:21 step:20531 [D loss: 0.529494, acc.: 71.09%] [G loss: 0.716398]\n",
      "epoch:21 step:20532 [D loss: 0.561821, acc.: 69.53%] [G loss: 0.628349]\n",
      "epoch:21 step:20533 [D loss: 0.567423, acc.: 70.31%] [G loss: 0.544924]\n",
      "epoch:21 step:20534 [D loss: 0.452511, acc.: 81.25%] [G loss: 0.653497]\n",
      "epoch:21 step:20535 [D loss: 0.614993, acc.: 62.50%] [G loss: 0.571785]\n",
      "epoch:21 step:20536 [D loss: 0.503816, acc.: 72.66%] [G loss: 0.667139]\n",
      "epoch:21 step:20537 [D loss: 0.459285, acc.: 77.34%] [G loss: 0.797098]\n",
      "epoch:21 step:20538 [D loss: 0.602926, acc.: 66.41%] [G loss: 0.706596]\n",
      "epoch:21 step:20539 [D loss: 0.647172, acc.: 65.62%] [G loss: 0.620846]\n",
      "epoch:21 step:20540 [D loss: 0.534030, acc.: 67.97%] [G loss: 0.616606]\n",
      "epoch:21 step:20541 [D loss: 0.526663, acc.: 67.19%] [G loss: 0.576766]\n",
      "epoch:21 step:20542 [D loss: 0.597598, acc.: 67.19%] [G loss: 0.630431]\n",
      "epoch:21 step:20543 [D loss: 0.509962, acc.: 72.66%] [G loss: 0.808276]\n",
      "epoch:21 step:20544 [D loss: 0.710478, acc.: 55.47%] [G loss: 0.434070]\n",
      "epoch:21 step:20545 [D loss: 0.503500, acc.: 72.66%] [G loss: 0.612757]\n",
      "epoch:21 step:20546 [D loss: 0.553710, acc.: 65.62%] [G loss: 0.513011]\n",
      "epoch:21 step:20547 [D loss: 0.457397, acc.: 75.78%] [G loss: 0.730049]\n",
      "epoch:21 step:20548 [D loss: 0.550310, acc.: 69.53%] [G loss: 0.739424]\n",
      "epoch:21 step:20549 [D loss: 0.522698, acc.: 71.09%] [G loss: 0.787834]\n",
      "epoch:21 step:20550 [D loss: 0.509984, acc.: 75.00%] [G loss: 0.645173]\n",
      "epoch:21 step:20551 [D loss: 0.568131, acc.: 68.75%] [G loss: 0.498589]\n",
      "epoch:21 step:20552 [D loss: 0.492994, acc.: 74.22%] [G loss: 0.646790]\n",
      "epoch:21 step:20553 [D loss: 0.505034, acc.: 73.44%] [G loss: 0.754578]\n",
      "epoch:21 step:20554 [D loss: 0.636778, acc.: 65.62%] [G loss: 0.530406]\n",
      "epoch:21 step:20555 [D loss: 0.503334, acc.: 75.00%] [G loss: 0.624640]\n",
      "epoch:21 step:20556 [D loss: 0.615482, acc.: 67.97%] [G loss: 0.824723]\n",
      "epoch:21 step:20557 [D loss: 0.697435, acc.: 55.47%] [G loss: 0.417607]\n",
      "epoch:21 step:20558 [D loss: 0.583386, acc.: 61.72%] [G loss: 0.629415]\n",
      "epoch:21 step:20559 [D loss: 0.574688, acc.: 67.97%] [G loss: 0.506221]\n",
      "epoch:21 step:20560 [D loss: 0.660843, acc.: 59.38%] [G loss: 0.510892]\n",
      "epoch:21 step:20561 [D loss: 0.475442, acc.: 75.00%] [G loss: 0.609343]\n",
      "epoch:21 step:20562 [D loss: 0.497710, acc.: 75.00%] [G loss: 0.709313]\n",
      "epoch:21 step:20563 [D loss: 0.511468, acc.: 72.66%] [G loss: 0.753743]\n",
      "epoch:21 step:20564 [D loss: 0.544063, acc.: 71.88%] [G loss: 0.669464]\n",
      "epoch:21 step:20565 [D loss: 0.558699, acc.: 67.97%] [G loss: 0.594746]\n",
      "epoch:21 step:20566 [D loss: 0.537018, acc.: 68.75%] [G loss: 0.765504]\n",
      "epoch:21 step:20567 [D loss: 0.506193, acc.: 69.53%] [G loss: 0.656671]\n",
      "epoch:21 step:20568 [D loss: 0.623956, acc.: 63.28%] [G loss: 0.603964]\n",
      "epoch:21 step:20569 [D loss: 0.608159, acc.: 64.06%] [G loss: 0.478475]\n",
      "epoch:21 step:20570 [D loss: 0.518940, acc.: 72.66%] [G loss: 0.494977]\n",
      "epoch:21 step:20571 [D loss: 0.467438, acc.: 77.34%] [G loss: 0.753224]\n",
      "epoch:21 step:20572 [D loss: 0.524297, acc.: 73.44%] [G loss: 0.829866]\n",
      "epoch:21 step:20573 [D loss: 0.488502, acc.: 75.00%] [G loss: 0.876261]\n",
      "epoch:21 step:20574 [D loss: 0.529064, acc.: 71.09%] [G loss: 0.724525]\n",
      "epoch:21 step:20575 [D loss: 0.471910, acc.: 78.12%] [G loss: 0.750195]\n",
      "epoch:21 step:20576 [D loss: 0.418696, acc.: 80.47%] [G loss: 0.921717]\n",
      "epoch:21 step:20577 [D loss: 0.504326, acc.: 75.00%] [G loss: 0.755404]\n",
      "epoch:21 step:20578 [D loss: 0.554246, acc.: 74.22%] [G loss: 0.798133]\n",
      "epoch:21 step:20579 [D loss: 0.599610, acc.: 67.97%] [G loss: 0.755158]\n",
      "epoch:21 step:20580 [D loss: 0.511897, acc.: 72.66%] [G loss: 0.672272]\n",
      "epoch:21 step:20581 [D loss: 0.579172, acc.: 70.31%] [G loss: 0.596869]\n",
      "epoch:21 step:20582 [D loss: 0.588942, acc.: 66.41%] [G loss: 0.733887]\n",
      "epoch:21 step:20583 [D loss: 0.507492, acc.: 74.22%] [G loss: 0.739062]\n",
      "epoch:21 step:20584 [D loss: 0.540566, acc.: 73.44%] [G loss: 0.674807]\n",
      "epoch:21 step:20585 [D loss: 0.549406, acc.: 71.88%] [G loss: 0.683708]\n",
      "epoch:21 step:20586 [D loss: 0.505284, acc.: 75.78%] [G loss: 0.698796]\n",
      "epoch:21 step:20587 [D loss: 0.569880, acc.: 71.09%] [G loss: 0.641136]\n",
      "epoch:21 step:20588 [D loss: 0.452367, acc.: 79.69%] [G loss: 0.740277]\n",
      "epoch:21 step:20589 [D loss: 0.487804, acc.: 72.66%] [G loss: 0.865276]\n",
      "epoch:21 step:20590 [D loss: 0.590372, acc.: 67.97%] [G loss: 0.626158]\n",
      "epoch:21 step:20591 [D loss: 0.449102, acc.: 78.91%] [G loss: 0.873016]\n",
      "epoch:21 step:20592 [D loss: 0.646983, acc.: 60.94%] [G loss: 0.683772]\n",
      "epoch:21 step:20593 [D loss: 0.483224, acc.: 77.34%] [G loss: 0.828139]\n",
      "epoch:21 step:20594 [D loss: 0.603463, acc.: 61.72%] [G loss: 0.664034]\n",
      "epoch:21 step:20595 [D loss: 0.517871, acc.: 71.09%] [G loss: 0.639536]\n",
      "epoch:21 step:20596 [D loss: 0.450767, acc.: 80.47%] [G loss: 0.995910]\n",
      "epoch:21 step:20597 [D loss: 0.635086, acc.: 63.28%] [G loss: 0.858848]\n",
      "epoch:21 step:20598 [D loss: 0.491279, acc.: 76.56%] [G loss: 0.796893]\n",
      "epoch:21 step:20599 [D loss: 0.543530, acc.: 67.97%] [G loss: 0.673798]\n",
      "epoch:21 step:20600 [D loss: 0.528994, acc.: 67.97%] [G loss: 0.725811]\n",
      "epoch:21 step:20601 [D loss: 0.484882, acc.: 76.56%] [G loss: 0.798744]\n",
      "epoch:21 step:20602 [D loss: 0.410149, acc.: 81.25%] [G loss: 0.875970]\n",
      "epoch:21 step:20603 [D loss: 0.457983, acc.: 78.12%] [G loss: 1.208594]\n",
      "epoch:21 step:20604 [D loss: 0.496801, acc.: 73.44%] [G loss: 1.027959]\n",
      "epoch:21 step:20605 [D loss: 0.671611, acc.: 63.28%] [G loss: 1.019979]\n",
      "epoch:21 step:20606 [D loss: 0.560251, acc.: 70.31%] [G loss: 1.373396]\n",
      "epoch:21 step:20607 [D loss: 0.478071, acc.: 74.22%] [G loss: 1.104020]\n",
      "epoch:21 step:20608 [D loss: 0.484305, acc.: 71.09%] [G loss: 0.871617]\n",
      "epoch:21 step:20609 [D loss: 0.625636, acc.: 61.72%] [G loss: 0.747233]\n",
      "epoch:21 step:20610 [D loss: 0.504732, acc.: 73.44%] [G loss: 0.883147]\n",
      "epoch:21 step:20611 [D loss: 0.479406, acc.: 72.66%] [G loss: 0.746702]\n",
      "epoch:21 step:20612 [D loss: 0.481559, acc.: 77.34%] [G loss: 0.822927]\n",
      "epoch:21 step:20613 [D loss: 0.359762, acc.: 83.59%] [G loss: 1.291990]\n",
      "epoch:21 step:20614 [D loss: 0.358683, acc.: 89.84%] [G loss: 1.146170]\n",
      "epoch:22 step:20615 [D loss: 0.658838, acc.: 68.75%] [G loss: 1.059536]\n",
      "epoch:22 step:20616 [D loss: 0.451370, acc.: 78.91%] [G loss: 1.174122]\n",
      "epoch:22 step:20617 [D loss: 0.515745, acc.: 75.78%] [G loss: 0.993410]\n",
      "epoch:22 step:20618 [D loss: 0.503814, acc.: 73.44%] [G loss: 1.073137]\n",
      "epoch:22 step:20619 [D loss: 0.482091, acc.: 78.12%] [G loss: 0.771556]\n",
      "epoch:22 step:20620 [D loss: 0.567944, acc.: 72.66%] [G loss: 0.670556]\n",
      "epoch:22 step:20621 [D loss: 0.506337, acc.: 75.00%] [G loss: 0.673653]\n",
      "epoch:22 step:20622 [D loss: 0.447210, acc.: 85.94%] [G loss: 0.915953]\n",
      "epoch:22 step:20623 [D loss: 0.455216, acc.: 81.25%] [G loss: 0.949273]\n",
      "epoch:22 step:20624 [D loss: 0.507945, acc.: 75.78%] [G loss: 0.837296]\n",
      "epoch:22 step:20625 [D loss: 0.465095, acc.: 78.12%] [G loss: 0.913285]\n",
      "epoch:22 step:20626 [D loss: 0.544815, acc.: 71.09%] [G loss: 0.788990]\n",
      "epoch:22 step:20627 [D loss: 0.551161, acc.: 72.66%] [G loss: 0.636693]\n",
      "epoch:22 step:20628 [D loss: 0.522066, acc.: 74.22%] [G loss: 0.578572]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:22 step:20629 [D loss: 0.489556, acc.: 70.31%] [G loss: 0.752752]\n",
      "epoch:22 step:20630 [D loss: 0.433039, acc.: 80.47%] [G loss: 0.765750]\n",
      "epoch:22 step:20631 [D loss: 0.558699, acc.: 75.00%] [G loss: 0.680746]\n",
      "epoch:22 step:20632 [D loss: 0.537555, acc.: 71.88%] [G loss: 0.653373]\n",
      "epoch:22 step:20633 [D loss: 0.583133, acc.: 67.19%] [G loss: 0.646732]\n",
      "epoch:22 step:20634 [D loss: 0.682798, acc.: 60.94%] [G loss: 0.715786]\n",
      "epoch:22 step:20635 [D loss: 0.573549, acc.: 64.06%] [G loss: 0.761253]\n",
      "epoch:22 step:20636 [D loss: 0.435170, acc.: 80.47%] [G loss: 1.032870]\n",
      "epoch:22 step:20637 [D loss: 0.586658, acc.: 70.31%] [G loss: 0.771369]\n",
      "epoch:22 step:20638 [D loss: 0.485162, acc.: 76.56%] [G loss: 0.626482]\n",
      "epoch:22 step:20639 [D loss: 0.457579, acc.: 78.12%] [G loss: 0.752674]\n",
      "epoch:22 step:20640 [D loss: 0.562297, acc.: 64.84%] [G loss: 0.677890]\n",
      "epoch:22 step:20641 [D loss: 0.506292, acc.: 73.44%] [G loss: 0.821967]\n",
      "epoch:22 step:20642 [D loss: 0.554762, acc.: 67.19%] [G loss: 0.687877]\n",
      "epoch:22 step:20643 [D loss: 0.525936, acc.: 72.66%] [G loss: 0.635868]\n",
      "epoch:22 step:20644 [D loss: 0.490628, acc.: 78.12%] [G loss: 0.709055]\n",
      "epoch:22 step:20645 [D loss: 0.596449, acc.: 61.72%] [G loss: 0.681112]\n",
      "epoch:22 step:20646 [D loss: 0.532534, acc.: 69.53%] [G loss: 0.831115]\n",
      "epoch:22 step:20647 [D loss: 0.505189, acc.: 68.75%] [G loss: 0.548266]\n",
      "epoch:22 step:20648 [D loss: 0.519416, acc.: 68.75%] [G loss: 0.818084]\n",
      "epoch:22 step:20649 [D loss: 0.536701, acc.: 75.78%] [G loss: 0.779970]\n",
      "epoch:22 step:20650 [D loss: 0.484881, acc.: 71.88%] [G loss: 0.599021]\n",
      "epoch:22 step:20651 [D loss: 0.534126, acc.: 75.78%] [G loss: 0.699348]\n",
      "epoch:22 step:20652 [D loss: 0.574354, acc.: 75.00%] [G loss: 0.615916]\n",
      "epoch:22 step:20653 [D loss: 0.511064, acc.: 69.53%] [G loss: 0.662646]\n",
      "epoch:22 step:20654 [D loss: 0.493762, acc.: 74.22%] [G loss: 0.815846]\n",
      "epoch:22 step:20655 [D loss: 0.531365, acc.: 72.66%] [G loss: 0.827816]\n",
      "epoch:22 step:20656 [D loss: 0.492961, acc.: 75.78%] [G loss: 0.700948]\n",
      "epoch:22 step:20657 [D loss: 0.518067, acc.: 75.00%] [G loss: 0.611653]\n",
      "epoch:22 step:20658 [D loss: 0.603269, acc.: 62.50%] [G loss: 0.581798]\n",
      "epoch:22 step:20659 [D loss: 0.475053, acc.: 76.56%] [G loss: 0.777358]\n",
      "epoch:22 step:20660 [D loss: 0.464205, acc.: 75.00%] [G loss: 0.702728]\n",
      "epoch:22 step:20661 [D loss: 0.518455, acc.: 70.31%] [G loss: 0.597932]\n",
      "epoch:22 step:20662 [D loss: 0.612583, acc.: 69.53%] [G loss: 0.687756]\n",
      "epoch:22 step:20663 [D loss: 0.500425, acc.: 75.00%] [G loss: 0.877967]\n",
      "epoch:22 step:20664 [D loss: 0.531285, acc.: 70.31%] [G loss: 0.828091]\n",
      "epoch:22 step:20665 [D loss: 0.604267, acc.: 62.50%] [G loss: 0.808369]\n",
      "epoch:22 step:20666 [D loss: 0.551480, acc.: 67.19%] [G loss: 0.689704]\n",
      "epoch:22 step:20667 [D loss: 0.508598, acc.: 73.44%] [G loss: 0.597329]\n",
      "epoch:22 step:20668 [D loss: 0.472859, acc.: 74.22%] [G loss: 0.768550]\n",
      "epoch:22 step:20669 [D loss: 0.523705, acc.: 68.75%] [G loss: 0.908725]\n",
      "epoch:22 step:20670 [D loss: 0.503134, acc.: 75.00%] [G loss: 0.742189]\n",
      "epoch:22 step:20671 [D loss: 0.507314, acc.: 73.44%] [G loss: 0.847361]\n",
      "epoch:22 step:20672 [D loss: 0.553312, acc.: 66.41%] [G loss: 0.610583]\n",
      "epoch:22 step:20673 [D loss: 0.522783, acc.: 74.22%] [G loss: 0.599853]\n",
      "epoch:22 step:20674 [D loss: 0.543853, acc.: 75.78%] [G loss: 0.627814]\n",
      "epoch:22 step:20675 [D loss: 0.551852, acc.: 68.75%] [G loss: 0.678080]\n",
      "epoch:22 step:20676 [D loss: 0.579348, acc.: 71.88%] [G loss: 0.615891]\n",
      "epoch:22 step:20677 [D loss: 0.506820, acc.: 71.88%] [G loss: 0.536209]\n",
      "epoch:22 step:20678 [D loss: 0.580982, acc.: 74.22%] [G loss: 0.590938]\n",
      "epoch:22 step:20679 [D loss: 0.513111, acc.: 71.88%] [G loss: 0.658597]\n",
      "epoch:22 step:20680 [D loss: 0.557132, acc.: 71.09%] [G loss: 0.538681]\n",
      "epoch:22 step:20681 [D loss: 0.490316, acc.: 78.91%] [G loss: 0.649601]\n",
      "epoch:22 step:20682 [D loss: 0.500847, acc.: 71.88%] [G loss: 0.498088]\n",
      "epoch:22 step:20683 [D loss: 0.482373, acc.: 79.69%] [G loss: 0.583964]\n",
      "epoch:22 step:20684 [D loss: 0.554681, acc.: 70.31%] [G loss: 0.626671]\n",
      "epoch:22 step:20685 [D loss: 0.508545, acc.: 69.53%] [G loss: 0.585331]\n",
      "epoch:22 step:20686 [D loss: 0.550295, acc.: 71.09%] [G loss: 0.724225]\n",
      "epoch:22 step:20687 [D loss: 0.616961, acc.: 62.50%] [G loss: 0.567667]\n",
      "epoch:22 step:20688 [D loss: 0.475548, acc.: 76.56%] [G loss: 0.562341]\n",
      "epoch:22 step:20689 [D loss: 0.509460, acc.: 74.22%] [G loss: 0.717891]\n",
      "epoch:22 step:20690 [D loss: 0.506384, acc.: 77.34%] [G loss: 0.778092]\n",
      "epoch:22 step:20691 [D loss: 0.418518, acc.: 81.25%] [G loss: 0.951487]\n",
      "epoch:22 step:20692 [D loss: 0.617008, acc.: 65.62%] [G loss: 0.675963]\n",
      "epoch:22 step:20693 [D loss: 0.515620, acc.: 75.78%] [G loss: 0.819222]\n",
      "epoch:22 step:20694 [D loss: 0.516662, acc.: 76.56%] [G loss: 0.707707]\n",
      "epoch:22 step:20695 [D loss: 0.517125, acc.: 71.09%] [G loss: 0.631295]\n",
      "epoch:22 step:20696 [D loss: 0.437360, acc.: 75.78%] [G loss: 0.942776]\n",
      "epoch:22 step:20697 [D loss: 0.441883, acc.: 76.56%] [G loss: 0.766850]\n",
      "epoch:22 step:20698 [D loss: 0.490606, acc.: 76.56%] [G loss: 0.803174]\n",
      "epoch:22 step:20699 [D loss: 0.543401, acc.: 68.75%] [G loss: 0.701661]\n",
      "epoch:22 step:20700 [D loss: 0.501631, acc.: 75.78%] [G loss: 0.744086]\n",
      "epoch:22 step:20701 [D loss: 0.479253, acc.: 74.22%] [G loss: 0.680877]\n",
      "epoch:22 step:20702 [D loss: 0.511484, acc.: 71.88%] [G loss: 0.687486]\n",
      "epoch:22 step:20703 [D loss: 0.514106, acc.: 75.78%] [G loss: 0.828232]\n",
      "epoch:22 step:20704 [D loss: 0.486645, acc.: 74.22%] [G loss: 0.875914]\n",
      "epoch:22 step:20705 [D loss: 0.585231, acc.: 68.75%] [G loss: 0.655781]\n",
      "epoch:22 step:20706 [D loss: 0.511148, acc.: 69.53%] [G loss: 0.775769]\n",
      "epoch:22 step:20707 [D loss: 0.480825, acc.: 76.56%] [G loss: 0.832556]\n",
      "epoch:22 step:20708 [D loss: 0.497708, acc.: 71.88%] [G loss: 0.861425]\n",
      "epoch:22 step:20709 [D loss: 0.543369, acc.: 70.31%] [G loss: 0.710163]\n",
      "epoch:22 step:20710 [D loss: 0.549821, acc.: 70.31%] [G loss: 0.862067]\n",
      "epoch:22 step:20711 [D loss: 0.515106, acc.: 72.66%] [G loss: 0.789344]\n",
      "epoch:22 step:20712 [D loss: 0.481151, acc.: 76.56%] [G loss: 0.785414]\n",
      "epoch:22 step:20713 [D loss: 0.502942, acc.: 73.44%] [G loss: 0.584738]\n",
      "epoch:22 step:20714 [D loss: 0.428824, acc.: 79.69%] [G loss: 0.833366]\n",
      "epoch:22 step:20715 [D loss: 0.465414, acc.: 74.22%] [G loss: 0.883885]\n",
      "epoch:22 step:20716 [D loss: 0.613494, acc.: 64.84%] [G loss: 0.723329]\n",
      "epoch:22 step:20717 [D loss: 0.570153, acc.: 67.97%] [G loss: 0.607711]\n",
      "epoch:22 step:20718 [D loss: 0.544019, acc.: 67.19%] [G loss: 0.569229]\n",
      "epoch:22 step:20719 [D loss: 0.566195, acc.: 70.31%] [G loss: 0.671431]\n",
      "epoch:22 step:20720 [D loss: 0.522940, acc.: 71.88%] [G loss: 0.681335]\n",
      "epoch:22 step:20721 [D loss: 0.509983, acc.: 72.66%] [G loss: 0.775212]\n",
      "epoch:22 step:20722 [D loss: 0.608701, acc.: 60.94%] [G loss: 0.729378]\n",
      "epoch:22 step:20723 [D loss: 0.558906, acc.: 67.19%] [G loss: 0.716252]\n",
      "epoch:22 step:20724 [D loss: 0.555688, acc.: 68.75%] [G loss: 0.714399]\n",
      "epoch:22 step:20725 [D loss: 0.536169, acc.: 68.75%] [G loss: 0.624497]\n",
      "epoch:22 step:20726 [D loss: 0.544857, acc.: 70.31%] [G loss: 0.737791]\n",
      "epoch:22 step:20727 [D loss: 0.514269, acc.: 73.44%] [G loss: 0.787674]\n",
      "epoch:22 step:20728 [D loss: 0.513072, acc.: 75.00%] [G loss: 0.677624]\n",
      "epoch:22 step:20729 [D loss: 0.453812, acc.: 82.03%] [G loss: 0.665568]\n",
      "epoch:22 step:20730 [D loss: 0.461529, acc.: 73.44%] [G loss: 0.762169]\n",
      "epoch:22 step:20731 [D loss: 0.492134, acc.: 72.66%] [G loss: 0.978708]\n",
      "epoch:22 step:20732 [D loss: 0.507188, acc.: 72.66%] [G loss: 0.790214]\n",
      "epoch:22 step:20733 [D loss: 0.480196, acc.: 75.78%] [G loss: 0.933853]\n",
      "epoch:22 step:20734 [D loss: 0.543767, acc.: 70.31%] [G loss: 0.971178]\n",
      "epoch:22 step:20735 [D loss: 0.523077, acc.: 71.88%] [G loss: 0.811731]\n",
      "epoch:22 step:20736 [D loss: 0.452904, acc.: 79.69%] [G loss: 1.019769]\n",
      "epoch:22 step:20737 [D loss: 0.541061, acc.: 71.88%] [G loss: 0.872213]\n",
      "epoch:22 step:20738 [D loss: 0.550257, acc.: 72.66%] [G loss: 0.733615]\n",
      "epoch:22 step:20739 [D loss: 0.519493, acc.: 75.78%] [G loss: 0.736814]\n",
      "epoch:22 step:20740 [D loss: 0.528814, acc.: 72.66%] [G loss: 0.746914]\n",
      "epoch:22 step:20741 [D loss: 0.498236, acc.: 76.56%] [G loss: 0.744700]\n",
      "epoch:22 step:20742 [D loss: 0.453891, acc.: 75.00%] [G loss: 0.752694]\n",
      "epoch:22 step:20743 [D loss: 0.614014, acc.: 64.84%] [G loss: 0.655286]\n",
      "epoch:22 step:20744 [D loss: 0.460351, acc.: 75.00%] [G loss: 0.760025]\n",
      "epoch:22 step:20745 [D loss: 0.518893, acc.: 73.44%] [G loss: 0.753150]\n",
      "epoch:22 step:20746 [D loss: 0.568708, acc.: 69.53%] [G loss: 0.825779]\n",
      "epoch:22 step:20747 [D loss: 0.630755, acc.: 65.62%] [G loss: 0.631974]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:22 step:20748 [D loss: 0.499822, acc.: 70.31%] [G loss: 0.722522]\n",
      "epoch:22 step:20749 [D loss: 0.537237, acc.: 71.88%] [G loss: 0.733072]\n",
      "epoch:22 step:20750 [D loss: 0.478120, acc.: 77.34%] [G loss: 0.857873]\n",
      "epoch:22 step:20751 [D loss: 0.588856, acc.: 71.88%] [G loss: 0.734671]\n",
      "epoch:22 step:20752 [D loss: 0.577426, acc.: 65.62%] [G loss: 0.652201]\n",
      "epoch:22 step:20753 [D loss: 0.518308, acc.: 70.31%] [G loss: 0.819926]\n",
      "epoch:22 step:20754 [D loss: 0.535372, acc.: 69.53%] [G loss: 0.749526]\n",
      "epoch:22 step:20755 [D loss: 0.486068, acc.: 76.56%] [G loss: 0.735480]\n",
      "epoch:22 step:20756 [D loss: 0.533758, acc.: 65.62%] [G loss: 0.699312]\n",
      "epoch:22 step:20757 [D loss: 0.585842, acc.: 63.28%] [G loss: 0.570099]\n",
      "epoch:22 step:20758 [D loss: 0.526975, acc.: 73.44%] [G loss: 0.758045]\n",
      "epoch:22 step:20759 [D loss: 0.544618, acc.: 68.75%] [G loss: 0.713950]\n",
      "epoch:22 step:20760 [D loss: 0.439879, acc.: 79.69%] [G loss: 0.761798]\n",
      "epoch:22 step:20761 [D loss: 0.629097, acc.: 64.06%] [G loss: 0.603381]\n",
      "epoch:22 step:20762 [D loss: 0.564447, acc.: 65.62%] [G loss: 0.582812]\n",
      "epoch:22 step:20763 [D loss: 0.537273, acc.: 71.88%] [G loss: 0.621610]\n",
      "epoch:22 step:20764 [D loss: 0.549899, acc.: 71.88%] [G loss: 0.627196]\n",
      "epoch:22 step:20765 [D loss: 0.560091, acc.: 66.41%] [G loss: 0.700414]\n",
      "epoch:22 step:20766 [D loss: 0.493486, acc.: 76.56%] [G loss: 0.865021]\n",
      "epoch:22 step:20767 [D loss: 0.612228, acc.: 67.19%] [G loss: 0.713775]\n",
      "epoch:22 step:20768 [D loss: 0.566200, acc.: 68.75%] [G loss: 0.434223]\n",
      "epoch:22 step:20769 [D loss: 0.497195, acc.: 72.66%] [G loss: 0.687308]\n",
      "epoch:22 step:20770 [D loss: 0.509278, acc.: 75.00%] [G loss: 0.793321]\n",
      "epoch:22 step:20771 [D loss: 0.526322, acc.: 71.88%] [G loss: 0.657360]\n",
      "epoch:22 step:20772 [D loss: 0.598059, acc.: 62.50%] [G loss: 0.516070]\n",
      "epoch:22 step:20773 [D loss: 0.491578, acc.: 77.34%] [G loss: 0.703443]\n",
      "epoch:22 step:20774 [D loss: 0.570113, acc.: 67.19%] [G loss: 0.610239]\n",
      "epoch:22 step:20775 [D loss: 0.513992, acc.: 71.88%] [G loss: 0.771172]\n",
      "epoch:22 step:20776 [D loss: 0.506006, acc.: 71.88%] [G loss: 0.881856]\n",
      "epoch:22 step:20777 [D loss: 0.539846, acc.: 71.88%] [G loss: 0.744084]\n",
      "epoch:22 step:20778 [D loss: 0.541728, acc.: 68.75%] [G loss: 0.949076]\n",
      "epoch:22 step:20779 [D loss: 0.447224, acc.: 80.47%] [G loss: 0.784296]\n",
      "epoch:22 step:20780 [D loss: 0.585602, acc.: 70.31%] [G loss: 0.566430]\n",
      "epoch:22 step:20781 [D loss: 0.549329, acc.: 72.66%] [G loss: 0.498385]\n",
      "epoch:22 step:20782 [D loss: 0.538416, acc.: 75.00%] [G loss: 0.561315]\n",
      "epoch:22 step:20783 [D loss: 0.621361, acc.: 60.94%] [G loss: 0.493420]\n",
      "epoch:22 step:20784 [D loss: 0.545448, acc.: 71.09%] [G loss: 0.616228]\n",
      "epoch:22 step:20785 [D loss: 0.532108, acc.: 65.62%] [G loss: 0.623542]\n",
      "epoch:22 step:20786 [D loss: 0.507420, acc.: 73.44%] [G loss: 0.758551]\n",
      "epoch:22 step:20787 [D loss: 0.474309, acc.: 75.78%] [G loss: 0.811220]\n",
      "epoch:22 step:20788 [D loss: 0.629311, acc.: 63.28%] [G loss: 0.636338]\n",
      "epoch:22 step:20789 [D loss: 0.502947, acc.: 73.44%] [G loss: 0.775234]\n",
      "epoch:22 step:20790 [D loss: 0.470471, acc.: 78.91%] [G loss: 0.744896]\n",
      "epoch:22 step:20791 [D loss: 0.541361, acc.: 71.09%] [G loss: 0.598935]\n",
      "epoch:22 step:20792 [D loss: 0.537291, acc.: 71.09%] [G loss: 0.632838]\n",
      "epoch:22 step:20793 [D loss: 0.532748, acc.: 69.53%] [G loss: 0.651635]\n",
      "epoch:22 step:20794 [D loss: 0.627158, acc.: 65.62%] [G loss: 0.563708]\n",
      "epoch:22 step:20795 [D loss: 0.599487, acc.: 65.62%] [G loss: 0.670942]\n",
      "epoch:22 step:20796 [D loss: 0.518401, acc.: 72.66%] [G loss: 0.789161]\n",
      "epoch:22 step:20797 [D loss: 0.549514, acc.: 75.00%] [G loss: 0.807780]\n",
      "epoch:22 step:20798 [D loss: 0.520874, acc.: 72.66%] [G loss: 0.679269]\n",
      "epoch:22 step:20799 [D loss: 0.566736, acc.: 69.53%] [G loss: 0.663446]\n",
      "epoch:22 step:20800 [D loss: 0.496342, acc.: 78.12%] [G loss: 0.770742]\n",
      "epoch:22 step:20801 [D loss: 0.636545, acc.: 60.94%] [G loss: 0.542609]\n",
      "epoch:22 step:20802 [D loss: 0.535248, acc.: 67.97%] [G loss: 0.697866]\n",
      "epoch:22 step:20803 [D loss: 0.572644, acc.: 70.31%] [G loss: 0.632206]\n",
      "epoch:22 step:20804 [D loss: 0.480318, acc.: 73.44%] [G loss: 0.736566]\n",
      "epoch:22 step:20805 [D loss: 0.478181, acc.: 78.12%] [G loss: 0.701971]\n",
      "epoch:22 step:20806 [D loss: 0.533972, acc.: 72.66%] [G loss: 0.807838]\n",
      "epoch:22 step:20807 [D loss: 0.526070, acc.: 74.22%] [G loss: 0.632404]\n",
      "epoch:22 step:20808 [D loss: 0.406307, acc.: 84.38%] [G loss: 0.784905]\n",
      "epoch:22 step:20809 [D loss: 0.549959, acc.: 72.66%] [G loss: 0.576868]\n",
      "epoch:22 step:20810 [D loss: 0.613218, acc.: 64.84%] [G loss: 0.612504]\n",
      "epoch:22 step:20811 [D loss: 0.503418, acc.: 72.66%] [G loss: 0.641161]\n",
      "epoch:22 step:20812 [D loss: 0.448836, acc.: 76.56%] [G loss: 0.731795]\n",
      "epoch:22 step:20813 [D loss: 0.485962, acc.: 73.44%] [G loss: 0.906065]\n",
      "epoch:22 step:20814 [D loss: 0.624580, acc.: 66.41%] [G loss: 0.610288]\n",
      "epoch:22 step:20815 [D loss: 0.520121, acc.: 74.22%] [G loss: 0.624357]\n",
      "epoch:22 step:20816 [D loss: 0.528561, acc.: 73.44%] [G loss: 0.738527]\n",
      "epoch:22 step:20817 [D loss: 0.582192, acc.: 71.88%] [G loss: 0.592018]\n",
      "epoch:22 step:20818 [D loss: 0.550316, acc.: 70.31%] [G loss: 0.655975]\n",
      "epoch:22 step:20819 [D loss: 0.509105, acc.: 70.31%] [G loss: 0.731579]\n",
      "epoch:22 step:20820 [D loss: 0.452755, acc.: 78.12%] [G loss: 0.929893]\n",
      "epoch:22 step:20821 [D loss: 0.460249, acc.: 76.56%] [G loss: 0.964078]\n",
      "epoch:22 step:20822 [D loss: 0.463048, acc.: 75.00%] [G loss: 0.884059]\n",
      "epoch:22 step:20823 [D loss: 0.466052, acc.: 75.00%] [G loss: 1.034082]\n",
      "epoch:22 step:20824 [D loss: 0.664180, acc.: 62.50%] [G loss: 0.678530]\n",
      "epoch:22 step:20825 [D loss: 0.571558, acc.: 71.09%] [G loss: 0.460056]\n",
      "epoch:22 step:20826 [D loss: 0.523344, acc.: 72.66%] [G loss: 0.708228]\n",
      "epoch:22 step:20827 [D loss: 0.459613, acc.: 78.91%] [G loss: 0.598867]\n",
      "epoch:22 step:20828 [D loss: 0.563066, acc.: 72.66%] [G loss: 0.637052]\n",
      "epoch:22 step:20829 [D loss: 0.530162, acc.: 71.88%] [G loss: 0.654369]\n",
      "epoch:22 step:20830 [D loss: 0.536924, acc.: 67.97%] [G loss: 0.709073]\n",
      "epoch:22 step:20831 [D loss: 0.457237, acc.: 76.56%] [G loss: 0.839639]\n",
      "epoch:22 step:20832 [D loss: 0.525293, acc.: 70.31%] [G loss: 0.676412]\n",
      "epoch:22 step:20833 [D loss: 0.513070, acc.: 75.00%] [G loss: 0.852845]\n",
      "epoch:22 step:20834 [D loss: 0.659841, acc.: 67.19%] [G loss: 0.782830]\n",
      "epoch:22 step:20835 [D loss: 0.551865, acc.: 70.31%] [G loss: 0.715774]\n",
      "epoch:22 step:20836 [D loss: 0.500301, acc.: 75.00%] [G loss: 0.971099]\n",
      "epoch:22 step:20837 [D loss: 0.493564, acc.: 78.12%] [G loss: 0.717916]\n",
      "epoch:22 step:20838 [D loss: 0.506678, acc.: 73.44%] [G loss: 0.639124]\n",
      "epoch:22 step:20839 [D loss: 0.484715, acc.: 76.56%] [G loss: 0.805086]\n",
      "epoch:22 step:20840 [D loss: 0.577554, acc.: 62.50%] [G loss: 0.648035]\n",
      "epoch:22 step:20841 [D loss: 0.526925, acc.: 72.66%] [G loss: 0.717556]\n",
      "epoch:22 step:20842 [D loss: 0.596244, acc.: 62.50%] [G loss: 0.633052]\n",
      "epoch:22 step:20843 [D loss: 0.504542, acc.: 71.09%] [G loss: 0.635135]\n",
      "epoch:22 step:20844 [D loss: 0.495011, acc.: 70.31%] [G loss: 0.662182]\n",
      "epoch:22 step:20845 [D loss: 0.448854, acc.: 76.56%] [G loss: 0.873749]\n",
      "epoch:22 step:20846 [D loss: 0.428734, acc.: 80.47%] [G loss: 0.974450]\n",
      "epoch:22 step:20847 [D loss: 0.506146, acc.: 74.22%] [G loss: 0.968873]\n",
      "epoch:22 step:20848 [D loss: 0.562718, acc.: 73.44%] [G loss: 0.749836]\n",
      "epoch:22 step:20849 [D loss: 0.551056, acc.: 72.66%] [G loss: 0.672919]\n",
      "epoch:22 step:20850 [D loss: 0.502467, acc.: 74.22%] [G loss: 0.588403]\n",
      "epoch:22 step:20851 [D loss: 0.498207, acc.: 75.00%] [G loss: 0.560247]\n",
      "epoch:22 step:20852 [D loss: 0.550481, acc.: 67.97%] [G loss: 0.615090]\n",
      "epoch:22 step:20853 [D loss: 0.481272, acc.: 75.78%] [G loss: 0.665580]\n",
      "epoch:22 step:20854 [D loss: 0.508511, acc.: 73.44%] [G loss: 0.623499]\n",
      "epoch:22 step:20855 [D loss: 0.499501, acc.: 71.88%] [G loss: 0.581338]\n",
      "epoch:22 step:20856 [D loss: 0.453736, acc.: 75.00%] [G loss: 0.856716]\n",
      "epoch:22 step:20857 [D loss: 0.496567, acc.: 70.31%] [G loss: 0.787401]\n",
      "epoch:22 step:20858 [D loss: 0.444252, acc.: 77.34%] [G loss: 0.880811]\n",
      "epoch:22 step:20859 [D loss: 0.494556, acc.: 75.00%] [G loss: 0.746334]\n",
      "epoch:22 step:20860 [D loss: 0.495849, acc.: 75.00%] [G loss: 0.752594]\n",
      "epoch:22 step:20861 [D loss: 0.472138, acc.: 74.22%] [G loss: 0.734066]\n",
      "epoch:22 step:20862 [D loss: 0.485845, acc.: 72.66%] [G loss: 0.878124]\n",
      "epoch:22 step:20863 [D loss: 0.593305, acc.: 67.19%] [G loss: 0.850872]\n",
      "epoch:22 step:20864 [D loss: 0.644230, acc.: 62.50%] [G loss: 0.847659]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:22 step:20865 [D loss: 0.597878, acc.: 65.62%] [G loss: 0.636602]\n",
      "epoch:22 step:20866 [D loss: 0.573667, acc.: 67.97%] [G loss: 0.661903]\n",
      "epoch:22 step:20867 [D loss: 0.571314, acc.: 69.53%] [G loss: 0.709243]\n",
      "epoch:22 step:20868 [D loss: 0.487127, acc.: 75.00%] [G loss: 0.695145]\n",
      "epoch:22 step:20869 [D loss: 0.515728, acc.: 72.66%] [G loss: 0.670966]\n",
      "epoch:22 step:20870 [D loss: 0.519735, acc.: 69.53%] [G loss: 0.751959]\n",
      "epoch:22 step:20871 [D loss: 0.589511, acc.: 63.28%] [G loss: 0.601924]\n",
      "epoch:22 step:20872 [D loss: 0.470515, acc.: 72.66%] [G loss: 0.694474]\n",
      "epoch:22 step:20873 [D loss: 0.482070, acc.: 78.91%] [G loss: 0.742674]\n",
      "epoch:22 step:20874 [D loss: 0.565976, acc.: 64.84%] [G loss: 0.595723]\n",
      "epoch:22 step:20875 [D loss: 0.485304, acc.: 75.78%] [G loss: 0.747787]\n",
      "epoch:22 step:20876 [D loss: 0.500542, acc.: 73.44%] [G loss: 0.774928]\n",
      "epoch:22 step:20877 [D loss: 0.527878, acc.: 73.44%] [G loss: 0.776278]\n",
      "epoch:22 step:20878 [D loss: 0.481663, acc.: 75.78%] [G loss: 0.761204]\n",
      "epoch:22 step:20879 [D loss: 0.494454, acc.: 76.56%] [G loss: 0.772071]\n",
      "epoch:22 step:20880 [D loss: 0.566447, acc.: 70.31%] [G loss: 0.715247]\n",
      "epoch:22 step:20881 [D loss: 0.483236, acc.: 76.56%] [G loss: 0.776292]\n",
      "epoch:22 step:20882 [D loss: 0.546717, acc.: 67.19%] [G loss: 0.705806]\n",
      "epoch:22 step:20883 [D loss: 0.592842, acc.: 70.31%] [G loss: 0.786232]\n",
      "epoch:22 step:20884 [D loss: 0.477736, acc.: 77.34%] [G loss: 0.874140]\n",
      "epoch:22 step:20885 [D loss: 0.486340, acc.: 74.22%] [G loss: 0.767601]\n",
      "epoch:22 step:20886 [D loss: 0.498181, acc.: 74.22%] [G loss: 0.897016]\n",
      "epoch:22 step:20887 [D loss: 0.480824, acc.: 75.00%] [G loss: 0.703216]\n",
      "epoch:22 step:20888 [D loss: 0.523901, acc.: 71.09%] [G loss: 0.741088]\n",
      "epoch:22 step:20889 [D loss: 0.552738, acc.: 70.31%] [G loss: 0.643509]\n",
      "epoch:22 step:20890 [D loss: 0.420030, acc.: 84.38%] [G loss: 0.747500]\n",
      "epoch:22 step:20891 [D loss: 0.736689, acc.: 61.72%] [G loss: 0.652837]\n",
      "epoch:22 step:20892 [D loss: 0.583883, acc.: 64.84%] [G loss: 0.480977]\n",
      "epoch:22 step:20893 [D loss: 0.485763, acc.: 70.31%] [G loss: 0.744037]\n",
      "epoch:22 step:20894 [D loss: 0.529058, acc.: 71.88%] [G loss: 0.600604]\n",
      "epoch:22 step:20895 [D loss: 0.545720, acc.: 68.75%] [G loss: 0.607704]\n",
      "epoch:22 step:20896 [D loss: 0.551633, acc.: 67.19%] [G loss: 0.675393]\n",
      "epoch:22 step:20897 [D loss: 0.555696, acc.: 65.62%] [G loss: 0.608131]\n",
      "epoch:22 step:20898 [D loss: 0.509191, acc.: 71.09%] [G loss: 0.839734]\n",
      "epoch:22 step:20899 [D loss: 0.537769, acc.: 67.19%] [G loss: 0.728081]\n",
      "epoch:22 step:20900 [D loss: 0.476044, acc.: 75.78%] [G loss: 0.627679]\n",
      "epoch:22 step:20901 [D loss: 0.563668, acc.: 67.97%] [G loss: 0.574240]\n",
      "epoch:22 step:20902 [D loss: 0.578862, acc.: 66.41%] [G loss: 0.709097]\n",
      "epoch:22 step:20903 [D loss: 0.505623, acc.: 72.66%] [G loss: 1.035308]\n",
      "epoch:22 step:20904 [D loss: 0.544375, acc.: 64.84%] [G loss: 0.875130]\n",
      "epoch:22 step:20905 [D loss: 0.564163, acc.: 70.31%] [G loss: 0.603993]\n",
      "epoch:22 step:20906 [D loss: 0.493914, acc.: 75.78%] [G loss: 0.550035]\n",
      "epoch:22 step:20907 [D loss: 0.577413, acc.: 68.75%] [G loss: 0.514766]\n",
      "epoch:22 step:20908 [D loss: 0.608300, acc.: 64.06%] [G loss: 0.501532]\n",
      "epoch:22 step:20909 [D loss: 0.568125, acc.: 67.97%] [G loss: 0.522977]\n",
      "epoch:22 step:20910 [D loss: 0.482137, acc.: 77.34%] [G loss: 0.540209]\n",
      "epoch:22 step:20911 [D loss: 0.566792, acc.: 67.97%] [G loss: 0.588298]\n",
      "epoch:22 step:20912 [D loss: 0.479146, acc.: 75.78%] [G loss: 0.648369]\n",
      "epoch:22 step:20913 [D loss: 0.445905, acc.: 77.34%] [G loss: 0.796901]\n",
      "epoch:22 step:20914 [D loss: 0.458086, acc.: 78.12%] [G loss: 0.644453]\n",
      "epoch:22 step:20915 [D loss: 0.603618, acc.: 67.19%] [G loss: 0.608685]\n",
      "epoch:22 step:20916 [D loss: 0.484035, acc.: 75.00%] [G loss: 0.721600]\n",
      "epoch:22 step:20917 [D loss: 0.561422, acc.: 69.53%] [G loss: 0.848648]\n",
      "epoch:22 step:20918 [D loss: 0.556012, acc.: 71.88%] [G loss: 0.603472]\n",
      "epoch:22 step:20919 [D loss: 0.504247, acc.: 77.34%] [G loss: 0.726451]\n",
      "epoch:22 step:20920 [D loss: 0.503597, acc.: 74.22%] [G loss: 0.699306]\n",
      "epoch:22 step:20921 [D loss: 0.507362, acc.: 74.22%] [G loss: 0.715448]\n",
      "epoch:22 step:20922 [D loss: 0.549613, acc.: 65.62%] [G loss: 0.598464]\n",
      "epoch:22 step:20923 [D loss: 0.489878, acc.: 71.88%] [G loss: 0.778353]\n",
      "epoch:22 step:20924 [D loss: 0.499527, acc.: 76.56%] [G loss: 0.754754]\n",
      "epoch:22 step:20925 [D loss: 0.447548, acc.: 80.47%] [G loss: 0.806171]\n",
      "epoch:22 step:20926 [D loss: 0.390870, acc.: 85.16%] [G loss: 0.974858]\n",
      "epoch:22 step:20927 [D loss: 0.443998, acc.: 82.03%] [G loss: 1.030211]\n",
      "epoch:22 step:20928 [D loss: 0.432648, acc.: 79.69%] [G loss: 1.077014]\n",
      "epoch:22 step:20929 [D loss: 0.490580, acc.: 75.00%] [G loss: 1.033908]\n",
      "epoch:22 step:20930 [D loss: 0.669014, acc.: 62.50%] [G loss: 0.862667]\n",
      "epoch:22 step:20931 [D loss: 0.589066, acc.: 67.97%] [G loss: 0.607016]\n",
      "epoch:22 step:20932 [D loss: 0.555243, acc.: 64.06%] [G loss: 0.620106]\n",
      "epoch:22 step:20933 [D loss: 0.564313, acc.: 67.19%] [G loss: 0.647047]\n",
      "epoch:22 step:20934 [D loss: 0.543236, acc.: 67.97%] [G loss: 0.710649]\n",
      "epoch:22 step:20935 [D loss: 0.514391, acc.: 72.66%] [G loss: 0.615581]\n",
      "epoch:22 step:20936 [D loss: 0.570070, acc.: 74.22%] [G loss: 0.713611]\n",
      "epoch:22 step:20937 [D loss: 0.638688, acc.: 64.06%] [G loss: 0.634169]\n",
      "epoch:22 step:20938 [D loss: 0.544556, acc.: 75.00%] [G loss: 0.637386]\n",
      "epoch:22 step:20939 [D loss: 0.530022, acc.: 75.00%] [G loss: 0.713776]\n",
      "epoch:22 step:20940 [D loss: 0.452388, acc.: 79.69%] [G loss: 0.607035]\n",
      "epoch:22 step:20941 [D loss: 0.533648, acc.: 73.44%] [G loss: 0.630425]\n",
      "epoch:22 step:20942 [D loss: 0.444478, acc.: 80.47%] [G loss: 0.703936]\n",
      "epoch:22 step:20943 [D loss: 0.547846, acc.: 74.22%] [G loss: 0.840646]\n",
      "epoch:22 step:20944 [D loss: 0.556077, acc.: 70.31%] [G loss: 0.807233]\n",
      "epoch:22 step:20945 [D loss: 0.533819, acc.: 73.44%] [G loss: 0.554682]\n",
      "epoch:22 step:20946 [D loss: 0.495151, acc.: 71.88%] [G loss: 0.667032]\n",
      "epoch:22 step:20947 [D loss: 0.479193, acc.: 75.78%] [G loss: 0.664517]\n",
      "epoch:22 step:20948 [D loss: 0.409562, acc.: 82.81%] [G loss: 0.759384]\n",
      "epoch:22 step:20949 [D loss: 0.456456, acc.: 74.22%] [G loss: 0.870184]\n",
      "epoch:22 step:20950 [D loss: 0.508551, acc.: 71.88%] [G loss: 0.758097]\n",
      "epoch:22 step:20951 [D loss: 0.518457, acc.: 73.44%] [G loss: 0.902137]\n",
      "epoch:22 step:20952 [D loss: 0.575732, acc.: 67.19%] [G loss: 0.757864]\n",
      "epoch:22 step:20953 [D loss: 0.530441, acc.: 71.88%] [G loss: 0.767083]\n",
      "epoch:22 step:20954 [D loss: 0.444694, acc.: 79.69%] [G loss: 0.824894]\n",
      "epoch:22 step:20955 [D loss: 0.554843, acc.: 71.88%] [G loss: 0.656146]\n",
      "epoch:22 step:20956 [D loss: 0.654288, acc.: 61.72%] [G loss: 0.850489]\n",
      "epoch:22 step:20957 [D loss: 0.464205, acc.: 79.69%] [G loss: 0.764090]\n",
      "epoch:22 step:20958 [D loss: 0.479852, acc.: 74.22%] [G loss: 0.911811]\n",
      "epoch:22 step:20959 [D loss: 0.574477, acc.: 67.97%] [G loss: 1.052328]\n",
      "epoch:22 step:20960 [D loss: 0.508023, acc.: 70.31%] [G loss: 1.023931]\n",
      "epoch:22 step:20961 [D loss: 0.385572, acc.: 85.94%] [G loss: 0.951490]\n",
      "epoch:22 step:20962 [D loss: 0.589507, acc.: 71.09%] [G loss: 0.662589]\n",
      "epoch:22 step:20963 [D loss: 0.701901, acc.: 53.12%] [G loss: 0.539186]\n",
      "epoch:22 step:20964 [D loss: 0.444117, acc.: 77.34%] [G loss: 0.749925]\n",
      "epoch:22 step:20965 [D loss: 0.500486, acc.: 75.00%] [G loss: 0.701650]\n",
      "epoch:22 step:20966 [D loss: 0.540649, acc.: 73.44%] [G loss: 0.686358]\n",
      "epoch:22 step:20967 [D loss: 0.573409, acc.: 69.53%] [G loss: 0.892651]\n",
      "epoch:22 step:20968 [D loss: 0.380864, acc.: 84.38%] [G loss: 0.939836]\n",
      "epoch:22 step:20969 [D loss: 0.563423, acc.: 71.09%] [G loss: 0.804927]\n",
      "epoch:22 step:20970 [D loss: 0.552231, acc.: 72.66%] [G loss: 0.902157]\n",
      "epoch:22 step:20971 [D loss: 0.408114, acc.: 81.25%] [G loss: 0.947749]\n",
      "epoch:22 step:20972 [D loss: 0.445157, acc.: 79.69%] [G loss: 0.836371]\n",
      "epoch:22 step:20973 [D loss: 0.440662, acc.: 77.34%] [G loss: 0.821997]\n",
      "epoch:22 step:20974 [D loss: 0.487212, acc.: 71.88%] [G loss: 0.963211]\n",
      "epoch:22 step:20975 [D loss: 0.479116, acc.: 75.00%] [G loss: 0.776821]\n",
      "epoch:22 step:20976 [D loss: 0.548531, acc.: 72.66%] [G loss: 0.943426]\n",
      "epoch:22 step:20977 [D loss: 0.539337, acc.: 70.31%] [G loss: 0.763165]\n",
      "epoch:22 step:20978 [D loss: 0.480343, acc.: 75.00%] [G loss: 0.721127]\n",
      "epoch:22 step:20979 [D loss: 0.556832, acc.: 71.09%] [G loss: 0.558873]\n",
      "epoch:22 step:20980 [D loss: 0.568194, acc.: 67.97%] [G loss: 0.605039]\n",
      "epoch:22 step:20981 [D loss: 0.500060, acc.: 75.78%] [G loss: 0.830122]\n",
      "epoch:22 step:20982 [D loss: 0.555755, acc.: 69.53%] [G loss: 0.702854]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:22 step:20983 [D loss: 0.514096, acc.: 77.34%] [G loss: 0.760799]\n",
      "epoch:22 step:20984 [D loss: 0.531701, acc.: 69.53%] [G loss: 0.773694]\n",
      "epoch:22 step:20985 [D loss: 0.478240, acc.: 78.12%] [G loss: 0.812826]\n",
      "epoch:22 step:20986 [D loss: 0.529233, acc.: 75.78%] [G loss: 0.779402]\n",
      "epoch:22 step:20987 [D loss: 0.521414, acc.: 71.09%] [G loss: 0.710496]\n",
      "epoch:22 step:20988 [D loss: 0.464855, acc.: 75.00%] [G loss: 0.758301]\n",
      "epoch:22 step:20989 [D loss: 0.507284, acc.: 73.44%] [G loss: 0.843594]\n",
      "epoch:22 step:20990 [D loss: 0.666999, acc.: 61.72%] [G loss: 0.725766]\n",
      "epoch:22 step:20991 [D loss: 0.563726, acc.: 68.75%] [G loss: 0.572401]\n",
      "epoch:22 step:20992 [D loss: 0.490676, acc.: 76.56%] [G loss: 0.783864]\n",
      "epoch:22 step:20993 [D loss: 0.530238, acc.: 73.44%] [G loss: 0.788161]\n",
      "epoch:22 step:20994 [D loss: 0.570634, acc.: 67.97%] [G loss: 0.682616]\n",
      "epoch:22 step:20995 [D loss: 0.451676, acc.: 76.56%] [G loss: 0.857064]\n",
      "epoch:22 step:20996 [D loss: 0.492543, acc.: 75.00%] [G loss: 0.786531]\n",
      "epoch:22 step:20997 [D loss: 0.519851, acc.: 75.78%] [G loss: 0.643557]\n",
      "epoch:22 step:20998 [D loss: 0.532806, acc.: 70.31%] [G loss: 0.704409]\n",
      "epoch:22 step:20999 [D loss: 0.483115, acc.: 72.66%] [G loss: 0.751676]\n",
      "epoch:22 step:21000 [D loss: 0.619106, acc.: 64.06%] [G loss: 0.725272]\n",
      "epoch:22 step:21001 [D loss: 0.515907, acc.: 71.09%] [G loss: 0.659134]\n",
      "epoch:22 step:21002 [D loss: 0.523656, acc.: 70.31%] [G loss: 0.718079]\n",
      "epoch:22 step:21003 [D loss: 0.580023, acc.: 64.84%] [G loss: 0.631765]\n",
      "epoch:22 step:21004 [D loss: 0.624350, acc.: 60.94%] [G loss: 0.598871]\n",
      "epoch:22 step:21005 [D loss: 0.548596, acc.: 69.53%] [G loss: 0.759136]\n",
      "epoch:22 step:21006 [D loss: 0.468285, acc.: 77.34%] [G loss: 0.726499]\n",
      "epoch:22 step:21007 [D loss: 0.595758, acc.: 64.84%] [G loss: 0.705858]\n",
      "epoch:22 step:21008 [D loss: 0.516719, acc.: 76.56%] [G loss: 0.715395]\n",
      "epoch:22 step:21009 [D loss: 0.499283, acc.: 72.66%] [G loss: 0.645077]\n",
      "epoch:22 step:21010 [D loss: 0.592560, acc.: 65.62%] [G loss: 0.691522]\n",
      "epoch:22 step:21011 [D loss: 0.555307, acc.: 63.28%] [G loss: 0.710769]\n",
      "epoch:22 step:21012 [D loss: 0.472234, acc.: 73.44%] [G loss: 0.872032]\n",
      "epoch:22 step:21013 [D loss: 0.575324, acc.: 70.31%] [G loss: 0.920008]\n",
      "epoch:22 step:21014 [D loss: 0.629621, acc.: 60.94%] [G loss: 0.639627]\n",
      "epoch:22 step:21015 [D loss: 0.665599, acc.: 57.81%] [G loss: 0.376081]\n",
      "epoch:22 step:21016 [D loss: 0.510027, acc.: 70.31%] [G loss: 0.583694]\n",
      "epoch:22 step:21017 [D loss: 0.462745, acc.: 76.56%] [G loss: 0.783112]\n",
      "epoch:22 step:21018 [D loss: 0.551251, acc.: 72.66%] [G loss: 0.579964]\n",
      "epoch:22 step:21019 [D loss: 0.559229, acc.: 67.97%] [G loss: 0.715767]\n",
      "epoch:22 step:21020 [D loss: 0.461260, acc.: 75.78%] [G loss: 0.730042]\n",
      "epoch:22 step:21021 [D loss: 0.504396, acc.: 71.88%] [G loss: 0.774106]\n",
      "epoch:22 step:21022 [D loss: 0.584526, acc.: 67.19%] [G loss: 0.786512]\n",
      "epoch:22 step:21023 [D loss: 0.527785, acc.: 67.97%] [G loss: 0.715547]\n",
      "epoch:22 step:21024 [D loss: 0.515925, acc.: 74.22%] [G loss: 0.966109]\n",
      "epoch:22 step:21025 [D loss: 0.591334, acc.: 64.84%] [G loss: 0.669671]\n",
      "epoch:22 step:21026 [D loss: 0.609741, acc.: 61.72%] [G loss: 0.594545]\n",
      "epoch:22 step:21027 [D loss: 0.529533, acc.: 71.88%] [G loss: 0.690068]\n",
      "epoch:22 step:21028 [D loss: 0.531726, acc.: 71.88%] [G loss: 0.692817]\n",
      "epoch:22 step:21029 [D loss: 0.546214, acc.: 68.75%] [G loss: 0.766590]\n",
      "epoch:22 step:21030 [D loss: 0.511605, acc.: 71.88%] [G loss: 0.748999]\n",
      "epoch:22 step:21031 [D loss: 0.484512, acc.: 75.00%] [G loss: 0.825920]\n",
      "epoch:22 step:21032 [D loss: 0.636371, acc.: 61.72%] [G loss: 0.697587]\n",
      "epoch:22 step:21033 [D loss: 0.553417, acc.: 71.88%] [G loss: 0.613448]\n",
      "epoch:22 step:21034 [D loss: 0.620348, acc.: 59.38%] [G loss: 0.582915]\n",
      "epoch:22 step:21035 [D loss: 0.544118, acc.: 65.62%] [G loss: 0.496939]\n",
      "epoch:22 step:21036 [D loss: 0.576036, acc.: 67.97%] [G loss: 0.558518]\n",
      "epoch:22 step:21037 [D loss: 0.533925, acc.: 72.66%] [G loss: 0.572700]\n",
      "epoch:22 step:21038 [D loss: 0.550225, acc.: 71.09%] [G loss: 0.509019]\n",
      "epoch:22 step:21039 [D loss: 0.533707, acc.: 70.31%] [G loss: 0.542437]\n",
      "epoch:22 step:21040 [D loss: 0.456549, acc.: 76.56%] [G loss: 0.835613]\n",
      "epoch:22 step:21041 [D loss: 0.430536, acc.: 80.47%] [G loss: 0.910442]\n",
      "epoch:22 step:21042 [D loss: 0.485266, acc.: 76.56%] [G loss: 0.610495]\n",
      "epoch:22 step:21043 [D loss: 0.426684, acc.: 76.56%] [G loss: 0.950583]\n",
      "epoch:22 step:21044 [D loss: 0.496531, acc.: 74.22%] [G loss: 0.920288]\n",
      "epoch:22 step:21045 [D loss: 0.547289, acc.: 66.41%] [G loss: 0.749310]\n",
      "epoch:22 step:21046 [D loss: 0.603859, acc.: 67.97%] [G loss: 0.594641]\n",
      "epoch:22 step:21047 [D loss: 0.568236, acc.: 67.19%] [G loss: 0.561952]\n",
      "epoch:22 step:21048 [D loss: 0.532253, acc.: 71.88%] [G loss: 0.714948]\n",
      "epoch:22 step:21049 [D loss: 0.556355, acc.: 65.62%] [G loss: 0.589690]\n",
      "epoch:22 step:21050 [D loss: 0.462222, acc.: 76.56%] [G loss: 0.734034]\n",
      "epoch:22 step:21051 [D loss: 0.655386, acc.: 60.16%] [G loss: 0.513787]\n",
      "epoch:22 step:21052 [D loss: 0.575805, acc.: 71.09%] [G loss: 0.545852]\n",
      "epoch:22 step:21053 [D loss: 0.476291, acc.: 77.34%] [G loss: 0.673681]\n",
      "epoch:22 step:21054 [D loss: 0.502322, acc.: 73.44%] [G loss: 0.718404]\n",
      "epoch:22 step:21055 [D loss: 0.491397, acc.: 72.66%] [G loss: 0.792367]\n",
      "epoch:22 step:21056 [D loss: 0.511024, acc.: 71.09%] [G loss: 0.886714]\n",
      "epoch:22 step:21057 [D loss: 0.529475, acc.: 71.88%] [G loss: 0.781651]\n",
      "epoch:22 step:21058 [D loss: 0.488921, acc.: 75.00%] [G loss: 0.762886]\n",
      "epoch:22 step:21059 [D loss: 0.527107, acc.: 71.09%] [G loss: 0.688452]\n",
      "epoch:22 step:21060 [D loss: 0.540936, acc.: 69.53%] [G loss: 0.829595]\n",
      "epoch:22 step:21061 [D loss: 0.492767, acc.: 71.09%] [G loss: 0.866828]\n",
      "epoch:22 step:21062 [D loss: 0.501544, acc.: 75.00%] [G loss: 0.834106]\n",
      "epoch:22 step:21063 [D loss: 0.484846, acc.: 74.22%] [G loss: 0.905569]\n",
      "epoch:22 step:21064 [D loss: 0.525641, acc.: 74.22%] [G loss: 0.771849]\n",
      "epoch:22 step:21065 [D loss: 0.381183, acc.: 84.38%] [G loss: 0.748432]\n",
      "epoch:22 step:21066 [D loss: 0.485478, acc.: 78.12%] [G loss: 0.983601]\n",
      "epoch:22 step:21067 [D loss: 0.517094, acc.: 71.88%] [G loss: 0.818516]\n",
      "epoch:22 step:21068 [D loss: 0.530408, acc.: 75.78%] [G loss: 0.556754]\n",
      "epoch:22 step:21069 [D loss: 0.559283, acc.: 66.41%] [G loss: 0.701790]\n",
      "epoch:22 step:21070 [D loss: 0.566296, acc.: 68.75%] [G loss: 0.786933]\n",
      "epoch:22 step:21071 [D loss: 0.476600, acc.: 76.56%] [G loss: 0.765144]\n",
      "epoch:22 step:21072 [D loss: 0.658688, acc.: 61.72%] [G loss: 0.781859]\n",
      "epoch:22 step:21073 [D loss: 0.537305, acc.: 71.88%] [G loss: 0.743206]\n",
      "epoch:22 step:21074 [D loss: 0.561709, acc.: 65.62%] [G loss: 0.858125]\n",
      "epoch:22 step:21075 [D loss: 0.475137, acc.: 78.12%] [G loss: 0.978610]\n",
      "epoch:22 step:21076 [D loss: 0.621101, acc.: 61.72%] [G loss: 0.755244]\n",
      "epoch:22 step:21077 [D loss: 0.544387, acc.: 68.75%] [G loss: 0.684439]\n",
      "epoch:22 step:21078 [D loss: 0.482501, acc.: 75.78%] [G loss: 0.751836]\n",
      "epoch:22 step:21079 [D loss: 0.540114, acc.: 71.88%] [G loss: 0.516865]\n",
      "epoch:22 step:21080 [D loss: 0.543950, acc.: 65.62%] [G loss: 0.713255]\n",
      "epoch:22 step:21081 [D loss: 0.539688, acc.: 70.31%] [G loss: 0.735991]\n",
      "epoch:22 step:21082 [D loss: 0.538617, acc.: 71.88%] [G loss: 0.739896]\n",
      "epoch:22 step:21083 [D loss: 0.575109, acc.: 69.53%] [G loss: 0.735383]\n",
      "epoch:22 step:21084 [D loss: 0.529735, acc.: 71.09%] [G loss: 0.805349]\n",
      "epoch:22 step:21085 [D loss: 0.430042, acc.: 82.81%] [G loss: 0.748620]\n",
      "epoch:22 step:21086 [D loss: 0.449737, acc.: 75.78%] [G loss: 1.000551]\n",
      "epoch:22 step:21087 [D loss: 0.656184, acc.: 63.28%] [G loss: 0.804798]\n",
      "epoch:22 step:21088 [D loss: 0.511852, acc.: 71.88%] [G loss: 0.800252]\n",
      "epoch:22 step:21089 [D loss: 0.444568, acc.: 81.25%] [G loss: 0.787517]\n",
      "epoch:22 step:21090 [D loss: 0.501533, acc.: 76.56%] [G loss: 0.865567]\n",
      "epoch:22 step:21091 [D loss: 0.627247, acc.: 66.41%] [G loss: 0.645952]\n",
      "epoch:22 step:21092 [D loss: 0.590671, acc.: 68.75%] [G loss: 0.504011]\n",
      "epoch:22 step:21093 [D loss: 0.548710, acc.: 67.19%] [G loss: 0.488175]\n",
      "epoch:22 step:21094 [D loss: 0.542026, acc.: 69.53%] [G loss: 0.536826]\n",
      "epoch:22 step:21095 [D loss: 0.487777, acc.: 78.91%] [G loss: 0.657517]\n",
      "epoch:22 step:21096 [D loss: 0.544392, acc.: 71.88%] [G loss: 0.506616]\n",
      "epoch:22 step:21097 [D loss: 0.526217, acc.: 73.44%] [G loss: 0.761024]\n",
      "epoch:22 step:21098 [D loss: 0.476018, acc.: 78.12%] [G loss: 0.830029]\n",
      "epoch:22 step:21099 [D loss: 0.556152, acc.: 72.66%] [G loss: 0.882027]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:22 step:21100 [D loss: 0.585224, acc.: 67.19%] [G loss: 0.692671]\n",
      "epoch:22 step:21101 [D loss: 0.534798, acc.: 67.97%] [G loss: 0.634172]\n",
      "epoch:22 step:21102 [D loss: 0.523192, acc.: 71.88%] [G loss: 0.704234]\n",
      "epoch:22 step:21103 [D loss: 0.522461, acc.: 70.31%] [G loss: 0.777256]\n",
      "epoch:22 step:21104 [D loss: 0.503089, acc.: 74.22%] [G loss: 0.667030]\n",
      "epoch:22 step:21105 [D loss: 0.509808, acc.: 73.44%] [G loss: 0.810930]\n",
      "epoch:22 step:21106 [D loss: 0.522479, acc.: 75.00%] [G loss: 0.690357]\n",
      "epoch:22 step:21107 [D loss: 0.596700, acc.: 65.62%] [G loss: 0.700546]\n",
      "epoch:22 step:21108 [D loss: 0.553562, acc.: 67.19%] [G loss: 0.737307]\n",
      "epoch:22 step:21109 [D loss: 0.470695, acc.: 81.25%] [G loss: 0.692013]\n",
      "epoch:22 step:21110 [D loss: 0.515428, acc.: 71.88%] [G loss: 0.768693]\n",
      "epoch:22 step:21111 [D loss: 0.485610, acc.: 76.56%] [G loss: 0.975158]\n",
      "epoch:22 step:21112 [D loss: 0.523631, acc.: 72.66%] [G loss: 0.828244]\n",
      "epoch:22 step:21113 [D loss: 0.433117, acc.: 80.47%] [G loss: 1.079729]\n",
      "epoch:22 step:21114 [D loss: 0.567564, acc.: 72.66%] [G loss: 0.746860]\n",
      "epoch:22 step:21115 [D loss: 0.589085, acc.: 69.53%] [G loss: 0.501129]\n",
      "epoch:22 step:21116 [D loss: 0.673734, acc.: 57.03%] [G loss: 0.613482]\n",
      "epoch:22 step:21117 [D loss: 0.519509, acc.: 73.44%] [G loss: 0.710841]\n",
      "epoch:22 step:21118 [D loss: 0.482036, acc.: 75.00%] [G loss: 0.789569]\n",
      "epoch:22 step:21119 [D loss: 0.533970, acc.: 75.78%] [G loss: 0.826715]\n",
      "epoch:22 step:21120 [D loss: 0.475396, acc.: 75.78%] [G loss: 0.740084]\n",
      "epoch:22 step:21121 [D loss: 0.483682, acc.: 75.00%] [G loss: 0.864644]\n",
      "epoch:22 step:21122 [D loss: 0.380591, acc.: 87.50%] [G loss: 0.900800]\n",
      "epoch:22 step:21123 [D loss: 0.480215, acc.: 77.34%] [G loss: 0.933255]\n",
      "epoch:22 step:21124 [D loss: 0.588049, acc.: 73.44%] [G loss: 0.763064]\n",
      "epoch:22 step:21125 [D loss: 0.622809, acc.: 64.06%] [G loss: 0.684091]\n",
      "epoch:22 step:21126 [D loss: 0.535088, acc.: 70.31%] [G loss: 0.662319]\n",
      "epoch:22 step:21127 [D loss: 0.521757, acc.: 72.66%] [G loss: 0.579796]\n",
      "epoch:22 step:21128 [D loss: 0.529232, acc.: 67.97%] [G loss: 0.547940]\n",
      "epoch:22 step:21129 [D loss: 0.541148, acc.: 67.97%] [G loss: 0.514163]\n",
      "epoch:22 step:21130 [D loss: 0.491904, acc.: 75.00%] [G loss: 0.867741]\n",
      "epoch:22 step:21131 [D loss: 0.496647, acc.: 71.88%] [G loss: 0.851737]\n",
      "epoch:22 step:21132 [D loss: 0.575884, acc.: 73.44%] [G loss: 0.808637]\n",
      "epoch:22 step:21133 [D loss: 0.444596, acc.: 79.69%] [G loss: 0.857305]\n",
      "epoch:22 step:21134 [D loss: 0.471966, acc.: 78.91%] [G loss: 0.722365]\n",
      "epoch:22 step:21135 [D loss: 0.466891, acc.: 76.56%] [G loss: 0.872599]\n",
      "epoch:22 step:21136 [D loss: 0.464925, acc.: 77.34%] [G loss: 0.696099]\n",
      "epoch:22 step:21137 [D loss: 0.472575, acc.: 75.78%] [G loss: 0.810764]\n",
      "epoch:22 step:21138 [D loss: 0.531394, acc.: 72.66%] [G loss: 0.776445]\n",
      "epoch:22 step:21139 [D loss: 0.546971, acc.: 72.66%] [G loss: 0.596799]\n",
      "epoch:22 step:21140 [D loss: 0.494518, acc.: 77.34%] [G loss: 0.754773]\n",
      "epoch:22 step:21141 [D loss: 0.545780, acc.: 69.53%] [G loss: 0.720316]\n",
      "epoch:22 step:21142 [D loss: 0.670042, acc.: 59.38%] [G loss: 0.455829]\n",
      "epoch:22 step:21143 [D loss: 0.591724, acc.: 62.50%] [G loss: 0.630842]\n",
      "epoch:22 step:21144 [D loss: 0.495966, acc.: 74.22%] [G loss: 0.797144]\n",
      "epoch:22 step:21145 [D loss: 0.537350, acc.: 68.75%] [G loss: 0.594112]\n",
      "epoch:22 step:21146 [D loss: 0.566179, acc.: 65.62%] [G loss: 0.723961]\n",
      "epoch:22 step:21147 [D loss: 0.528628, acc.: 66.41%] [G loss: 0.715625]\n",
      "epoch:22 step:21148 [D loss: 0.469771, acc.: 78.12%] [G loss: 0.654376]\n",
      "epoch:22 step:21149 [D loss: 0.601149, acc.: 66.41%] [G loss: 0.648417]\n",
      "epoch:22 step:21150 [D loss: 0.506724, acc.: 74.22%] [G loss: 0.532105]\n",
      "epoch:22 step:21151 [D loss: 0.620074, acc.: 61.72%] [G loss: 0.552615]\n",
      "epoch:22 step:21152 [D loss: 0.512343, acc.: 72.66%] [G loss: 0.613564]\n",
      "epoch:22 step:21153 [D loss: 0.554367, acc.: 67.19%] [G loss: 0.696999]\n",
      "epoch:22 step:21154 [D loss: 0.554410, acc.: 71.09%] [G loss: 0.616088]\n",
      "epoch:22 step:21155 [D loss: 0.535975, acc.: 73.44%] [G loss: 0.550983]\n",
      "epoch:22 step:21156 [D loss: 0.548409, acc.: 72.66%] [G loss: 0.495671]\n",
      "epoch:22 step:21157 [D loss: 0.563632, acc.: 64.06%] [G loss: 0.601948]\n",
      "epoch:22 step:21158 [D loss: 0.521013, acc.: 73.44%] [G loss: 0.657829]\n",
      "epoch:22 step:21159 [D loss: 0.524029, acc.: 70.31%] [G loss: 0.681046]\n",
      "epoch:22 step:21160 [D loss: 0.492603, acc.: 75.78%] [G loss: 0.655142]\n",
      "epoch:22 step:21161 [D loss: 0.515001, acc.: 71.88%] [G loss: 0.853210]\n",
      "epoch:22 step:21162 [D loss: 0.467383, acc.: 75.00%] [G loss: 0.881970]\n",
      "epoch:22 step:21163 [D loss: 0.546147, acc.: 71.09%] [G loss: 0.667840]\n",
      "epoch:22 step:21164 [D loss: 0.588332, acc.: 64.06%] [G loss: 0.705723]\n",
      "epoch:22 step:21165 [D loss: 0.526692, acc.: 71.09%] [G loss: 0.752806]\n",
      "epoch:22 step:21166 [D loss: 0.433689, acc.: 80.47%] [G loss: 0.713278]\n",
      "epoch:22 step:21167 [D loss: 0.548943, acc.: 72.66%] [G loss: 0.626653]\n",
      "epoch:22 step:21168 [D loss: 0.410872, acc.: 82.81%] [G loss: 0.768831]\n",
      "epoch:22 step:21169 [D loss: 0.490973, acc.: 74.22%] [G loss: 0.725022]\n",
      "epoch:22 step:21170 [D loss: 0.566828, acc.: 67.97%] [G loss: 0.836604]\n",
      "epoch:22 step:21171 [D loss: 0.516420, acc.: 70.31%] [G loss: 0.574359]\n",
      "epoch:22 step:21172 [D loss: 0.417823, acc.: 78.91%] [G loss: 0.903971]\n",
      "epoch:22 step:21173 [D loss: 0.563945, acc.: 69.53%] [G loss: 0.671937]\n",
      "epoch:22 step:21174 [D loss: 0.553758, acc.: 71.09%] [G loss: 0.524958]\n",
      "epoch:22 step:21175 [D loss: 0.568796, acc.: 67.97%] [G loss: 0.773527]\n",
      "epoch:22 step:21176 [D loss: 0.555822, acc.: 70.31%] [G loss: 0.572976]\n",
      "epoch:22 step:21177 [D loss: 0.511771, acc.: 71.88%] [G loss: 0.702601]\n",
      "epoch:22 step:21178 [D loss: 0.452836, acc.: 78.12%] [G loss: 0.863772]\n",
      "epoch:22 step:21179 [D loss: 0.539119, acc.: 75.00%] [G loss: 0.870858]\n",
      "epoch:22 step:21180 [D loss: 0.703958, acc.: 58.59%] [G loss: 0.643390]\n",
      "epoch:22 step:21181 [D loss: 0.555662, acc.: 64.06%] [G loss: 0.615385]\n",
      "epoch:22 step:21182 [D loss: 0.483029, acc.: 78.12%] [G loss: 0.544271]\n",
      "epoch:22 step:21183 [D loss: 0.542450, acc.: 73.44%] [G loss: 0.738360]\n",
      "epoch:22 step:21184 [D loss: 0.524675, acc.: 73.44%] [G loss: 0.670886]\n",
      "epoch:22 step:21185 [D loss: 0.573704, acc.: 67.97%] [G loss: 0.618510]\n",
      "epoch:22 step:21186 [D loss: 0.546661, acc.: 72.66%] [G loss: 0.731896]\n",
      "epoch:22 step:21187 [D loss: 0.497634, acc.: 78.91%] [G loss: 0.748345]\n",
      "epoch:22 step:21188 [D loss: 0.478606, acc.: 79.69%] [G loss: 0.919561]\n",
      "epoch:22 step:21189 [D loss: 0.526769, acc.: 74.22%] [G loss: 0.948722]\n",
      "epoch:22 step:21190 [D loss: 0.583063, acc.: 67.97%] [G loss: 0.755529]\n",
      "epoch:22 step:21191 [D loss: 0.481882, acc.: 75.78%] [G loss: 0.828434]\n",
      "epoch:22 step:21192 [D loss: 0.543194, acc.: 70.31%] [G loss: 0.586347]\n",
      "epoch:22 step:21193 [D loss: 0.484459, acc.: 71.88%] [G loss: 0.693511]\n",
      "epoch:22 step:21194 [D loss: 0.536544, acc.: 72.66%] [G loss: 0.656873]\n",
      "epoch:22 step:21195 [D loss: 0.511857, acc.: 75.78%] [G loss: 0.758042]\n",
      "epoch:22 step:21196 [D loss: 0.428166, acc.: 82.03%] [G loss: 0.815922]\n",
      "epoch:22 step:21197 [D loss: 0.522202, acc.: 71.88%] [G loss: 0.753911]\n",
      "epoch:22 step:21198 [D loss: 0.562528, acc.: 66.41%] [G loss: 0.743534]\n",
      "epoch:22 step:21199 [D loss: 0.529443, acc.: 68.75%] [G loss: 0.656685]\n",
      "epoch:22 step:21200 [D loss: 0.504183, acc.: 71.09%] [G loss: 0.679318]\n",
      "epoch:22 step:21201 [D loss: 0.562886, acc.: 66.41%] [G loss: 0.558157]\n",
      "epoch:22 step:21202 [D loss: 0.578602, acc.: 64.84%] [G loss: 0.559576]\n",
      "epoch:22 step:21203 [D loss: 0.503389, acc.: 71.09%] [G loss: 0.707842]\n",
      "epoch:22 step:21204 [D loss: 0.535350, acc.: 74.22%] [G loss: 0.773873]\n",
      "epoch:22 step:21205 [D loss: 0.616079, acc.: 65.62%] [G loss: 0.686485]\n",
      "epoch:22 step:21206 [D loss: 0.463338, acc.: 79.69%] [G loss: 0.620763]\n",
      "epoch:22 step:21207 [D loss: 0.506256, acc.: 75.78%] [G loss: 0.757641]\n",
      "epoch:22 step:21208 [D loss: 0.572380, acc.: 67.97%] [G loss: 0.582168]\n",
      "epoch:22 step:21209 [D loss: 0.550452, acc.: 69.53%] [G loss: 0.633201]\n",
      "epoch:22 step:21210 [D loss: 0.483202, acc.: 75.00%] [G loss: 0.678221]\n",
      "epoch:22 step:21211 [D loss: 0.502036, acc.: 75.00%] [G loss: 0.541030]\n",
      "epoch:22 step:21212 [D loss: 0.480352, acc.: 77.34%] [G loss: 0.785984]\n",
      "epoch:22 step:21213 [D loss: 0.527718, acc.: 75.00%] [G loss: 0.884055]\n",
      "epoch:22 step:21214 [D loss: 0.537517, acc.: 68.75%] [G loss: 0.669484]\n",
      "epoch:22 step:21215 [D loss: 0.489071, acc.: 74.22%] [G loss: 0.902967]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:22 step:21216 [D loss: 0.467770, acc.: 78.12%] [G loss: 0.825870]\n",
      "epoch:22 step:21217 [D loss: 0.473998, acc.: 74.22%] [G loss: 0.813630]\n",
      "epoch:22 step:21218 [D loss: 0.566021, acc.: 69.53%] [G loss: 0.745592]\n",
      "epoch:22 step:21219 [D loss: 0.469190, acc.: 74.22%] [G loss: 0.784350]\n",
      "epoch:22 step:21220 [D loss: 0.575531, acc.: 71.09%] [G loss: 0.708373]\n",
      "epoch:22 step:21221 [D loss: 0.515211, acc.: 73.44%] [G loss: 0.737968]\n",
      "epoch:22 step:21222 [D loss: 0.535308, acc.: 70.31%] [G loss: 0.625008]\n",
      "epoch:22 step:21223 [D loss: 0.502344, acc.: 73.44%] [G loss: 0.670301]\n",
      "epoch:22 step:21224 [D loss: 0.557067, acc.: 72.66%] [G loss: 0.596326]\n",
      "epoch:22 step:21225 [D loss: 0.513673, acc.: 72.66%] [G loss: 0.638908]\n",
      "epoch:22 step:21226 [D loss: 0.537082, acc.: 73.44%] [G loss: 0.667023]\n",
      "epoch:22 step:21227 [D loss: 0.487516, acc.: 75.00%] [G loss: 0.624647]\n",
      "epoch:22 step:21228 [D loss: 0.564802, acc.: 67.97%] [G loss: 0.596444]\n",
      "epoch:22 step:21229 [D loss: 0.600060, acc.: 59.38%] [G loss: 0.709977]\n",
      "epoch:22 step:21230 [D loss: 0.523019, acc.: 70.31%] [G loss: 0.735567]\n",
      "epoch:22 step:21231 [D loss: 0.492320, acc.: 72.66%] [G loss: 0.873852]\n",
      "epoch:22 step:21232 [D loss: 0.528690, acc.: 71.09%] [G loss: 0.885311]\n",
      "epoch:22 step:21233 [D loss: 0.570636, acc.: 67.19%] [G loss: 0.679060]\n",
      "epoch:22 step:21234 [D loss: 0.513943, acc.: 75.00%] [G loss: 0.738553]\n",
      "epoch:22 step:21235 [D loss: 0.532123, acc.: 71.09%] [G loss: 0.643477]\n",
      "epoch:22 step:21236 [D loss: 0.554511, acc.: 74.22%] [G loss: 0.682603]\n",
      "epoch:22 step:21237 [D loss: 0.469345, acc.: 76.56%] [G loss: 0.696586]\n",
      "epoch:22 step:21238 [D loss: 0.455261, acc.: 76.56%] [G loss: 1.064096]\n",
      "epoch:22 step:21239 [D loss: 0.587020, acc.: 66.41%] [G loss: 0.768724]\n",
      "epoch:22 step:21240 [D loss: 0.557501, acc.: 65.62%] [G loss: 0.750779]\n",
      "epoch:22 step:21241 [D loss: 0.527056, acc.: 71.88%] [G loss: 0.859272]\n",
      "epoch:22 step:21242 [D loss: 0.581589, acc.: 71.88%] [G loss: 0.605332]\n",
      "epoch:22 step:21243 [D loss: 0.506435, acc.: 73.44%] [G loss: 0.705942]\n",
      "epoch:22 step:21244 [D loss: 0.498191, acc.: 75.78%] [G loss: 0.597083]\n",
      "epoch:22 step:21245 [D loss: 0.485179, acc.: 74.22%] [G loss: 0.721557]\n",
      "epoch:22 step:21246 [D loss: 0.494683, acc.: 68.75%] [G loss: 0.787982]\n",
      "epoch:22 step:21247 [D loss: 0.535941, acc.: 67.97%] [G loss: 0.733798]\n",
      "epoch:22 step:21248 [D loss: 0.480625, acc.: 78.12%] [G loss: 0.761185]\n",
      "epoch:22 step:21249 [D loss: 0.529579, acc.: 69.53%] [G loss: 0.814230]\n",
      "epoch:22 step:21250 [D loss: 0.554313, acc.: 67.97%] [G loss: 0.651769]\n",
      "epoch:22 step:21251 [D loss: 0.544612, acc.: 69.53%] [G loss: 0.694448]\n",
      "epoch:22 step:21252 [D loss: 0.483681, acc.: 73.44%] [G loss: 0.701480]\n",
      "epoch:22 step:21253 [D loss: 0.469252, acc.: 75.78%] [G loss: 0.771123]\n",
      "epoch:22 step:21254 [D loss: 0.527989, acc.: 72.66%] [G loss: 0.697767]\n",
      "epoch:22 step:21255 [D loss: 0.523437, acc.: 71.88%] [G loss: 0.759631]\n",
      "epoch:22 step:21256 [D loss: 0.479238, acc.: 73.44%] [G loss: 0.690702]\n",
      "epoch:22 step:21257 [D loss: 0.530764, acc.: 68.75%] [G loss: 0.837945]\n",
      "epoch:22 step:21258 [D loss: 0.509964, acc.: 71.09%] [G loss: 0.783675]\n",
      "epoch:22 step:21259 [D loss: 0.514223, acc.: 76.56%] [G loss: 0.528395]\n",
      "epoch:22 step:21260 [D loss: 0.552406, acc.: 69.53%] [G loss: 0.695599]\n",
      "epoch:22 step:21261 [D loss: 0.417176, acc.: 80.47%] [G loss: 0.823556]\n",
      "epoch:22 step:21262 [D loss: 0.403945, acc.: 80.47%] [G loss: 1.032276]\n",
      "epoch:22 step:21263 [D loss: 0.557429, acc.: 71.88%] [G loss: 1.010171]\n",
      "epoch:22 step:21264 [D loss: 0.439323, acc.: 80.47%] [G loss: 0.973179]\n",
      "epoch:22 step:21265 [D loss: 0.497912, acc.: 75.78%] [G loss: 0.931343]\n",
      "epoch:22 step:21266 [D loss: 0.589417, acc.: 64.06%] [G loss: 0.583275]\n",
      "epoch:22 step:21267 [D loss: 0.511088, acc.: 73.44%] [G loss: 0.756283]\n",
      "epoch:22 step:21268 [D loss: 0.457620, acc.: 78.91%] [G loss: 0.754298]\n",
      "epoch:22 step:21269 [D loss: 0.581151, acc.: 67.19%] [G loss: 0.722649]\n",
      "epoch:22 step:21270 [D loss: 0.607550, acc.: 63.28%] [G loss: 0.611570]\n",
      "epoch:22 step:21271 [D loss: 0.528566, acc.: 69.53%] [G loss: 0.797036]\n",
      "epoch:22 step:21272 [D loss: 0.539852, acc.: 68.75%] [G loss: 0.718921]\n",
      "epoch:22 step:21273 [D loss: 0.508349, acc.: 71.09%] [G loss: 0.843629]\n",
      "epoch:22 step:21274 [D loss: 0.488004, acc.: 76.56%] [G loss: 0.747490]\n",
      "epoch:22 step:21275 [D loss: 0.482475, acc.: 78.12%] [G loss: 0.932927]\n",
      "epoch:22 step:21276 [D loss: 0.444528, acc.: 80.47%] [G loss: 0.750926]\n",
      "epoch:22 step:21277 [D loss: 0.503122, acc.: 69.53%] [G loss: 0.687357]\n",
      "epoch:22 step:21278 [D loss: 0.562004, acc.: 67.19%] [G loss: 0.575872]\n",
      "epoch:22 step:21279 [D loss: 0.573478, acc.: 70.31%] [G loss: 0.652633]\n",
      "epoch:22 step:21280 [D loss: 0.458991, acc.: 79.69%] [G loss: 1.036567]\n",
      "epoch:22 step:21281 [D loss: 0.553504, acc.: 68.75%] [G loss: 0.782412]\n",
      "epoch:22 step:21282 [D loss: 0.531091, acc.: 72.66%] [G loss: 0.925265]\n",
      "epoch:22 step:21283 [D loss: 0.539285, acc.: 75.00%] [G loss: 0.968774]\n",
      "epoch:22 step:21284 [D loss: 0.559042, acc.: 69.53%] [G loss: 0.814863]\n",
      "epoch:22 step:21285 [D loss: 0.517573, acc.: 72.66%] [G loss: 0.680271]\n",
      "epoch:22 step:21286 [D loss: 0.477267, acc.: 75.00%] [G loss: 0.767497]\n",
      "epoch:22 step:21287 [D loss: 0.562012, acc.: 67.19%] [G loss: 0.816837]\n",
      "epoch:22 step:21288 [D loss: 0.504062, acc.: 73.44%] [G loss: 0.689346]\n",
      "epoch:22 step:21289 [D loss: 0.589504, acc.: 62.50%] [G loss: 0.707140]\n",
      "epoch:22 step:21290 [D loss: 0.548380, acc.: 68.75%] [G loss: 0.571419]\n",
      "epoch:22 step:21291 [D loss: 0.447234, acc.: 77.34%] [G loss: 0.691096]\n",
      "epoch:22 step:21292 [D loss: 0.535207, acc.: 68.75%] [G loss: 0.761893]\n",
      "epoch:22 step:21293 [D loss: 0.451672, acc.: 81.25%] [G loss: 0.735469]\n",
      "epoch:22 step:21294 [D loss: 0.533186, acc.: 73.44%] [G loss: 0.633991]\n",
      "epoch:22 step:21295 [D loss: 0.449291, acc.: 78.91%] [G loss: 0.712129]\n",
      "epoch:22 step:21296 [D loss: 0.512977, acc.: 74.22%] [G loss: 0.687108]\n",
      "epoch:22 step:21297 [D loss: 0.511715, acc.: 72.66%] [G loss: 0.708043]\n",
      "epoch:22 step:21298 [D loss: 0.572998, acc.: 70.31%] [G loss: 0.588458]\n",
      "epoch:22 step:21299 [D loss: 0.515337, acc.: 71.88%] [G loss: 0.541754]\n",
      "epoch:22 step:21300 [D loss: 0.518174, acc.: 73.44%] [G loss: 0.586171]\n",
      "epoch:22 step:21301 [D loss: 0.529845, acc.: 75.00%] [G loss: 0.635802]\n",
      "epoch:22 step:21302 [D loss: 0.538414, acc.: 70.31%] [G loss: 0.788137]\n",
      "epoch:22 step:21303 [D loss: 0.525400, acc.: 71.88%] [G loss: 0.770401]\n",
      "epoch:22 step:21304 [D loss: 0.533581, acc.: 67.97%] [G loss: 0.741726]\n",
      "epoch:22 step:21305 [D loss: 0.487780, acc.: 73.44%] [G loss: 0.870601]\n",
      "epoch:22 step:21306 [D loss: 0.516721, acc.: 75.00%] [G loss: 0.812434]\n",
      "epoch:22 step:21307 [D loss: 0.541807, acc.: 75.00%] [G loss: 0.888218]\n",
      "epoch:22 step:21308 [D loss: 0.515601, acc.: 74.22%] [G loss: 0.643867]\n",
      "epoch:22 step:21309 [D loss: 0.471257, acc.: 82.81%] [G loss: 0.976418]\n",
      "epoch:22 step:21310 [D loss: 0.588620, acc.: 69.53%] [G loss: 0.552677]\n",
      "epoch:22 step:21311 [D loss: 0.592116, acc.: 64.84%] [G loss: 0.489349]\n",
      "epoch:22 step:21312 [D loss: 0.557071, acc.: 67.97%] [G loss: 0.582139]\n",
      "epoch:22 step:21313 [D loss: 0.484968, acc.: 78.12%] [G loss: 0.658029]\n",
      "epoch:22 step:21314 [D loss: 0.549083, acc.: 67.19%] [G loss: 0.680986]\n",
      "epoch:22 step:21315 [D loss: 0.500745, acc.: 77.34%] [G loss: 0.788862]\n",
      "epoch:22 step:21316 [D loss: 0.579190, acc.: 67.19%] [G loss: 0.918083]\n",
      "epoch:22 step:21317 [D loss: 0.613656, acc.: 61.72%] [G loss: 0.738566]\n",
      "epoch:22 step:21318 [D loss: 0.632120, acc.: 60.94%] [G loss: 0.570803]\n",
      "epoch:22 step:21319 [D loss: 0.523135, acc.: 74.22%] [G loss: 0.564898]\n",
      "epoch:22 step:21320 [D loss: 0.509481, acc.: 72.66%] [G loss: 0.678739]\n",
      "epoch:22 step:21321 [D loss: 0.530079, acc.: 69.53%] [G loss: 0.802372]\n",
      "epoch:22 step:21322 [D loss: 0.485453, acc.: 78.91%] [G loss: 0.750378]\n",
      "epoch:22 step:21323 [D loss: 0.595429, acc.: 66.41%] [G loss: 0.674309]\n",
      "epoch:22 step:21324 [D loss: 0.572378, acc.: 69.53%] [G loss: 0.867099]\n",
      "epoch:22 step:21325 [D loss: 0.552022, acc.: 71.88%] [G loss: 0.760076]\n",
      "epoch:22 step:21326 [D loss: 0.572142, acc.: 68.75%] [G loss: 0.650405]\n",
      "epoch:22 step:21327 [D loss: 0.572681, acc.: 64.84%] [G loss: 0.706938]\n",
      "epoch:22 step:21328 [D loss: 0.510875, acc.: 71.09%] [G loss: 0.681516]\n",
      "epoch:22 step:21329 [D loss: 0.530025, acc.: 75.78%] [G loss: 0.793526]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:22 step:21330 [D loss: 0.555642, acc.: 67.97%] [G loss: 0.625513]\n",
      "epoch:22 step:21331 [D loss: 0.552368, acc.: 64.84%] [G loss: 0.547780]\n",
      "epoch:22 step:21332 [D loss: 0.556701, acc.: 69.53%] [G loss: 0.671543]\n",
      "epoch:22 step:21333 [D loss: 0.486329, acc.: 75.78%] [G loss: 0.888873]\n",
      "epoch:22 step:21334 [D loss: 0.575017, acc.: 73.44%] [G loss: 0.759630]\n",
      "epoch:22 step:21335 [D loss: 0.548701, acc.: 71.09%] [G loss: 0.762248]\n",
      "epoch:22 step:21336 [D loss: 0.498770, acc.: 71.88%] [G loss: 0.842676]\n",
      "epoch:22 step:21337 [D loss: 0.536437, acc.: 69.53%] [G loss: 0.637564]\n",
      "epoch:22 step:21338 [D loss: 0.514029, acc.: 71.88%] [G loss: 0.835337]\n",
      "epoch:22 step:21339 [D loss: 0.496405, acc.: 77.34%] [G loss: 0.825602]\n",
      "epoch:22 step:21340 [D loss: 0.541745, acc.: 71.88%] [G loss: 0.791096]\n",
      "epoch:22 step:21341 [D loss: 0.500221, acc.: 71.09%] [G loss: 0.674105]\n",
      "epoch:22 step:21342 [D loss: 0.506498, acc.: 73.44%] [G loss: 0.641442]\n",
      "epoch:22 step:21343 [D loss: 0.522051, acc.: 74.22%] [G loss: 0.600863]\n",
      "epoch:22 step:21344 [D loss: 0.528751, acc.: 73.44%] [G loss: 0.714602]\n",
      "epoch:22 step:21345 [D loss: 0.591565, acc.: 67.19%] [G loss: 0.592334]\n",
      "epoch:22 step:21346 [D loss: 0.476381, acc.: 73.44%] [G loss: 0.600231]\n",
      "epoch:22 step:21347 [D loss: 0.513069, acc.: 72.66%] [G loss: 0.726532]\n",
      "epoch:22 step:21348 [D loss: 0.507651, acc.: 72.66%] [G loss: 0.629960]\n",
      "epoch:22 step:21349 [D loss: 0.589369, acc.: 64.06%] [G loss: 0.622939]\n",
      "epoch:22 step:21350 [D loss: 0.499623, acc.: 75.78%] [G loss: 0.629538]\n",
      "epoch:22 step:21351 [D loss: 0.512645, acc.: 74.22%] [G loss: 0.826477]\n",
      "epoch:22 step:21352 [D loss: 0.506699, acc.: 67.97%] [G loss: 0.745756]\n",
      "epoch:22 step:21353 [D loss: 0.575268, acc.: 65.62%] [G loss: 0.743398]\n",
      "epoch:22 step:21354 [D loss: 0.652613, acc.: 56.25%] [G loss: 0.523572]\n",
      "epoch:22 step:21355 [D loss: 0.535969, acc.: 74.22%] [G loss: 0.501047]\n",
      "epoch:22 step:21356 [D loss: 0.478435, acc.: 78.12%] [G loss: 0.769875]\n",
      "epoch:22 step:21357 [D loss: 0.473645, acc.: 76.56%] [G loss: 0.964775]\n",
      "epoch:22 step:21358 [D loss: 0.556225, acc.: 71.88%] [G loss: 0.763787]\n",
      "epoch:22 step:21359 [D loss: 0.575525, acc.: 68.75%] [G loss: 0.702461]\n",
      "epoch:22 step:21360 [D loss: 0.450181, acc.: 73.44%] [G loss: 0.743094]\n",
      "epoch:22 step:21361 [D loss: 0.464485, acc.: 74.22%] [G loss: 0.873057]\n",
      "epoch:22 step:21362 [D loss: 0.497933, acc.: 72.66%] [G loss: 0.759257]\n",
      "epoch:22 step:21363 [D loss: 0.482716, acc.: 73.44%] [G loss: 0.790860]\n",
      "epoch:22 step:21364 [D loss: 0.477029, acc.: 75.00%] [G loss: 0.780063]\n",
      "epoch:22 step:21365 [D loss: 0.590832, acc.: 67.19%] [G loss: 0.802191]\n",
      "epoch:22 step:21366 [D loss: 0.540265, acc.: 71.88%] [G loss: 0.591703]\n",
      "epoch:22 step:21367 [D loss: 0.520853, acc.: 71.88%] [G loss: 0.597786]\n",
      "epoch:22 step:21368 [D loss: 0.561902, acc.: 67.97%] [G loss: 0.726755]\n",
      "epoch:22 step:21369 [D loss: 0.549783, acc.: 67.19%] [G loss: 0.707023]\n",
      "epoch:22 step:21370 [D loss: 0.535501, acc.: 74.22%] [G loss: 0.633009]\n",
      "epoch:22 step:21371 [D loss: 0.574265, acc.: 67.97%] [G loss: 0.738273]\n",
      "epoch:22 step:21372 [D loss: 0.503109, acc.: 76.56%] [G loss: 0.645420]\n",
      "epoch:22 step:21373 [D loss: 0.515278, acc.: 73.44%] [G loss: 0.601725]\n",
      "epoch:22 step:21374 [D loss: 0.521786, acc.: 70.31%] [G loss: 0.775381]\n",
      "epoch:22 step:21375 [D loss: 0.543608, acc.: 68.75%] [G loss: 0.685357]\n",
      "epoch:22 step:21376 [D loss: 0.615816, acc.: 67.97%] [G loss: 0.657101]\n",
      "epoch:22 step:21377 [D loss: 0.546681, acc.: 71.88%] [G loss: 0.844997]\n",
      "epoch:22 step:21378 [D loss: 0.582339, acc.: 64.84%] [G loss: 0.629579]\n",
      "epoch:22 step:21379 [D loss: 0.528498, acc.: 72.66%] [G loss: 0.632338]\n",
      "epoch:22 step:21380 [D loss: 0.607206, acc.: 64.06%] [G loss: 0.657539]\n",
      "epoch:22 step:21381 [D loss: 0.511751, acc.: 71.09%] [G loss: 0.605203]\n",
      "epoch:22 step:21382 [D loss: 0.484551, acc.: 76.56%] [G loss: 0.974399]\n",
      "epoch:22 step:21383 [D loss: 0.494753, acc.: 75.78%] [G loss: 0.876463]\n",
      "epoch:22 step:21384 [D loss: 0.549773, acc.: 67.19%] [G loss: 0.941368]\n",
      "epoch:22 step:21385 [D loss: 0.539331, acc.: 73.44%] [G loss: 0.852658]\n",
      "epoch:22 step:21386 [D loss: 0.577227, acc.: 67.97%] [G loss: 0.601497]\n",
      "epoch:22 step:21387 [D loss: 0.534751, acc.: 71.09%] [G loss: 0.704269]\n",
      "epoch:22 step:21388 [D loss: 0.555106, acc.: 71.09%] [G loss: 0.652888]\n",
      "epoch:22 step:21389 [D loss: 0.533554, acc.: 71.09%] [G loss: 0.696474]\n",
      "epoch:22 step:21390 [D loss: 0.536693, acc.: 69.53%] [G loss: 0.629389]\n",
      "epoch:22 step:21391 [D loss: 0.536934, acc.: 66.41%] [G loss: 0.638634]\n",
      "epoch:22 step:21392 [D loss: 0.534910, acc.: 73.44%] [G loss: 0.575182]\n",
      "epoch:22 step:21393 [D loss: 0.502977, acc.: 72.66%] [G loss: 0.649957]\n",
      "epoch:22 step:21394 [D loss: 0.474524, acc.: 75.78%] [G loss: 0.850421]\n",
      "epoch:22 step:21395 [D loss: 0.494991, acc.: 71.09%] [G loss: 0.997449]\n",
      "epoch:22 step:21396 [D loss: 0.497554, acc.: 72.66%] [G loss: 0.937366]\n",
      "epoch:22 step:21397 [D loss: 0.544531, acc.: 66.41%] [G loss: 0.895363]\n",
      "epoch:22 step:21398 [D loss: 0.590529, acc.: 65.62%] [G loss: 0.689614]\n",
      "epoch:22 step:21399 [D loss: 0.516671, acc.: 72.66%] [G loss: 0.693825]\n",
      "epoch:22 step:21400 [D loss: 0.515751, acc.: 71.88%] [G loss: 0.733142]\n",
      "epoch:22 step:21401 [D loss: 0.579505, acc.: 66.41%] [G loss: 0.538323]\n",
      "epoch:22 step:21402 [D loss: 0.631341, acc.: 65.62%] [G loss: 0.592208]\n",
      "epoch:22 step:21403 [D loss: 0.475258, acc.: 78.12%] [G loss: 0.679165]\n",
      "epoch:22 step:21404 [D loss: 0.530080, acc.: 67.97%] [G loss: 0.619341]\n",
      "epoch:22 step:21405 [D loss: 0.526171, acc.: 72.66%] [G loss: 0.649607]\n",
      "epoch:22 step:21406 [D loss: 0.491257, acc.: 72.66%] [G loss: 0.735579]\n",
      "epoch:22 step:21407 [D loss: 0.546773, acc.: 71.09%] [G loss: 0.674146]\n",
      "epoch:22 step:21408 [D loss: 0.578440, acc.: 66.41%] [G loss: 0.674860]\n",
      "epoch:22 step:21409 [D loss: 0.504362, acc.: 72.66%] [G loss: 0.834442]\n",
      "epoch:22 step:21410 [D loss: 0.507472, acc.: 70.31%] [G loss: 0.816317]\n",
      "epoch:22 step:21411 [D loss: 0.551880, acc.: 69.53%] [G loss: 0.818050]\n",
      "epoch:22 step:21412 [D loss: 0.493555, acc.: 73.44%] [G loss: 0.819236]\n",
      "epoch:22 step:21413 [D loss: 0.505285, acc.: 78.91%] [G loss: 0.671632]\n",
      "epoch:22 step:21414 [D loss: 0.589526, acc.: 65.62%] [G loss: 0.657160]\n",
      "epoch:22 step:21415 [D loss: 0.533445, acc.: 74.22%] [G loss: 0.761447]\n",
      "epoch:22 step:21416 [D loss: 0.475519, acc.: 75.00%] [G loss: 0.863523]\n",
      "epoch:22 step:21417 [D loss: 0.470431, acc.: 78.12%] [G loss: 0.798066]\n",
      "epoch:22 step:21418 [D loss: 0.523149, acc.: 75.78%] [G loss: 0.684950]\n",
      "epoch:22 step:21419 [D loss: 0.518182, acc.: 73.44%] [G loss: 0.683934]\n",
      "epoch:22 step:21420 [D loss: 0.559922, acc.: 68.75%] [G loss: 0.758187]\n",
      "epoch:22 step:21421 [D loss: 0.520776, acc.: 71.88%] [G loss: 0.615674]\n",
      "epoch:22 step:21422 [D loss: 0.526350, acc.: 71.88%] [G loss: 0.481809]\n",
      "epoch:22 step:21423 [D loss: 0.477515, acc.: 79.69%] [G loss: 0.729671]\n",
      "epoch:22 step:21424 [D loss: 0.505205, acc.: 71.88%] [G loss: 0.682863]\n",
      "epoch:22 step:21425 [D loss: 0.547731, acc.: 69.53%] [G loss: 0.810681]\n",
      "epoch:22 step:21426 [D loss: 0.624128, acc.: 65.62%] [G loss: 0.657039]\n",
      "epoch:22 step:21427 [D loss: 0.555504, acc.: 67.97%] [G loss: 0.672092]\n",
      "epoch:22 step:21428 [D loss: 0.474967, acc.: 75.00%] [G loss: 0.714437]\n",
      "epoch:22 step:21429 [D loss: 0.504926, acc.: 76.56%] [G loss: 0.893039]\n",
      "epoch:22 step:21430 [D loss: 0.506693, acc.: 73.44%] [G loss: 0.988069]\n",
      "epoch:22 step:21431 [D loss: 0.658716, acc.: 63.28%] [G loss: 0.880051]\n",
      "epoch:22 step:21432 [D loss: 0.563752, acc.: 71.88%] [G loss: 0.674338]\n",
      "epoch:22 step:21433 [D loss: 0.493622, acc.: 77.34%] [G loss: 0.583640]\n",
      "epoch:22 step:21434 [D loss: 0.635562, acc.: 66.41%] [G loss: 0.618559]\n",
      "epoch:22 step:21435 [D loss: 0.547105, acc.: 64.84%] [G loss: 0.682331]\n",
      "epoch:22 step:21436 [D loss: 0.545103, acc.: 66.41%] [G loss: 0.567000]\n",
      "epoch:22 step:21437 [D loss: 0.463562, acc.: 75.78%] [G loss: 0.645466]\n",
      "epoch:22 step:21438 [D loss: 0.580338, acc.: 68.75%] [G loss: 0.668392]\n",
      "epoch:22 step:21439 [D loss: 0.509515, acc.: 75.78%] [G loss: 0.737981]\n",
      "epoch:22 step:21440 [D loss: 0.497119, acc.: 74.22%] [G loss: 0.790175]\n",
      "epoch:22 step:21441 [D loss: 0.545803, acc.: 71.09%] [G loss: 0.733770]\n",
      "epoch:22 step:21442 [D loss: 0.614427, acc.: 67.97%] [G loss: 0.647377]\n",
      "epoch:22 step:21443 [D loss: 0.525350, acc.: 71.09%] [G loss: 0.734789]\n",
      "epoch:22 step:21444 [D loss: 0.513391, acc.: 75.00%] [G loss: 0.775682]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:22 step:21445 [D loss: 0.509025, acc.: 74.22%] [G loss: 0.804215]\n",
      "epoch:22 step:21446 [D loss: 0.525369, acc.: 69.53%] [G loss: 0.665750]\n",
      "epoch:22 step:21447 [D loss: 0.509673, acc.: 72.66%] [G loss: 0.684345]\n",
      "epoch:22 step:21448 [D loss: 0.500701, acc.: 71.88%] [G loss: 0.631884]\n",
      "epoch:22 step:21449 [D loss: 0.545170, acc.: 69.53%] [G loss: 0.628430]\n",
      "epoch:22 step:21450 [D loss: 0.530411, acc.: 70.31%] [G loss: 0.623152]\n",
      "epoch:22 step:21451 [D loss: 0.512679, acc.: 71.09%] [G loss: 0.726908]\n",
      "epoch:22 step:21452 [D loss: 0.559855, acc.: 64.06%] [G loss: 0.650407]\n",
      "epoch:22 step:21453 [D loss: 0.549645, acc.: 65.62%] [G loss: 0.695499]\n",
      "epoch:22 step:21454 [D loss: 0.585155, acc.: 65.62%] [G loss: 0.586172]\n",
      "epoch:22 step:21455 [D loss: 0.535892, acc.: 68.75%] [G loss: 0.482785]\n",
      "epoch:22 step:21456 [D loss: 0.470492, acc.: 78.12%] [G loss: 0.645374]\n",
      "epoch:22 step:21457 [D loss: 0.491395, acc.: 74.22%] [G loss: 0.585415]\n",
      "epoch:22 step:21458 [D loss: 0.530384, acc.: 69.53%] [G loss: 0.661496]\n",
      "epoch:22 step:21459 [D loss: 0.547185, acc.: 68.75%] [G loss: 0.556682]\n",
      "epoch:22 step:21460 [D loss: 0.576360, acc.: 68.75%] [G loss: 0.578690]\n",
      "epoch:22 step:21461 [D loss: 0.599448, acc.: 64.84%] [G loss: 0.381987]\n",
      "epoch:22 step:21462 [D loss: 0.590184, acc.: 65.62%] [G loss: 0.462298]\n",
      "epoch:22 step:21463 [D loss: 0.492263, acc.: 73.44%] [G loss: 0.656901]\n",
      "epoch:22 step:21464 [D loss: 0.493696, acc.: 75.78%] [G loss: 0.606199]\n",
      "epoch:22 step:21465 [D loss: 0.554229, acc.: 70.31%] [G loss: 0.626072]\n",
      "epoch:22 step:21466 [D loss: 0.566434, acc.: 67.19%] [G loss: 0.567965]\n",
      "epoch:22 step:21467 [D loss: 0.534408, acc.: 71.09%] [G loss: 0.720153]\n",
      "epoch:22 step:21468 [D loss: 0.480249, acc.: 76.56%] [G loss: 0.774839]\n",
      "epoch:22 step:21469 [D loss: 0.557802, acc.: 65.62%] [G loss: 0.793578]\n",
      "epoch:22 step:21470 [D loss: 0.636700, acc.: 68.75%] [G loss: 0.528258]\n",
      "epoch:22 step:21471 [D loss: 0.445490, acc.: 77.34%] [G loss: 0.778023]\n",
      "epoch:22 step:21472 [D loss: 0.574676, acc.: 68.75%] [G loss: 0.666787]\n",
      "epoch:22 step:21473 [D loss: 0.589867, acc.: 61.72%] [G loss: 0.756339]\n",
      "epoch:22 step:21474 [D loss: 0.447875, acc.: 78.12%] [G loss: 0.852118]\n",
      "epoch:22 step:21475 [D loss: 0.646290, acc.: 64.84%] [G loss: 0.695315]\n",
      "epoch:22 step:21476 [D loss: 0.569272, acc.: 64.84%] [G loss: 0.566183]\n",
      "epoch:22 step:21477 [D loss: 0.529538, acc.: 71.88%] [G loss: 0.559933]\n",
      "epoch:22 step:21478 [D loss: 0.541205, acc.: 69.53%] [G loss: 0.617745]\n",
      "epoch:22 step:21479 [D loss: 0.536514, acc.: 69.53%] [G loss: 0.571226]\n",
      "epoch:22 step:21480 [D loss: 0.534205, acc.: 71.88%] [G loss: 0.546762]\n",
      "epoch:22 step:21481 [D loss: 0.636989, acc.: 60.16%] [G loss: 0.558169]\n",
      "epoch:22 step:21482 [D loss: 0.509172, acc.: 74.22%] [G loss: 0.521697]\n",
      "epoch:22 step:21483 [D loss: 0.541251, acc.: 64.84%] [G loss: 0.683739]\n",
      "epoch:22 step:21484 [D loss: 0.463566, acc.: 75.78%] [G loss: 0.675144]\n",
      "epoch:22 step:21485 [D loss: 0.475582, acc.: 72.66%] [G loss: 0.690151]\n",
      "epoch:22 step:21486 [D loss: 0.499037, acc.: 71.88%] [G loss: 0.675269]\n",
      "epoch:22 step:21487 [D loss: 0.575333, acc.: 67.97%] [G loss: 0.631345]\n",
      "epoch:22 step:21488 [D loss: 0.546729, acc.: 65.62%] [G loss: 0.673252]\n",
      "epoch:22 step:21489 [D loss: 0.452943, acc.: 78.91%] [G loss: 0.830459]\n",
      "epoch:22 step:21490 [D loss: 0.544850, acc.: 66.41%] [G loss: 0.599490]\n",
      "epoch:22 step:21491 [D loss: 0.610431, acc.: 68.75%] [G loss: 0.567420]\n",
      "epoch:22 step:21492 [D loss: 0.505293, acc.: 76.56%] [G loss: 0.588776]\n",
      "epoch:22 step:21493 [D loss: 0.523532, acc.: 67.97%] [G loss: 0.627394]\n",
      "epoch:22 step:21494 [D loss: 0.634990, acc.: 64.06%] [G loss: 0.536201]\n",
      "epoch:22 step:21495 [D loss: 0.569109, acc.: 64.84%] [G loss: 0.549369]\n",
      "epoch:22 step:21496 [D loss: 0.554734, acc.: 71.09%] [G loss: 0.572264]\n",
      "epoch:22 step:21497 [D loss: 0.558288, acc.: 73.44%] [G loss: 0.639405]\n",
      "epoch:22 step:21498 [D loss: 0.485909, acc.: 77.34%] [G loss: 0.670655]\n",
      "epoch:22 step:21499 [D loss: 0.561614, acc.: 70.31%] [G loss: 0.755785]\n",
      "epoch:22 step:21500 [D loss: 0.532915, acc.: 71.88%] [G loss: 0.764715]\n",
      "epoch:22 step:21501 [D loss: 0.543722, acc.: 70.31%] [G loss: 0.767316]\n",
      "epoch:22 step:21502 [D loss: 0.587338, acc.: 66.41%] [G loss: 0.802446]\n",
      "epoch:22 step:21503 [D loss: 0.567228, acc.: 67.97%] [G loss: 0.702542]\n",
      "epoch:22 step:21504 [D loss: 0.532862, acc.: 70.31%] [G loss: 0.598750]\n",
      "epoch:22 step:21505 [D loss: 0.565920, acc.: 70.31%] [G loss: 0.534887]\n",
      "epoch:22 step:21506 [D loss: 0.650119, acc.: 60.16%] [G loss: 0.533601]\n",
      "epoch:22 step:21507 [D loss: 0.506242, acc.: 75.78%] [G loss: 0.745437]\n",
      "epoch:22 step:21508 [D loss: 0.463399, acc.: 81.25%] [G loss: 0.802312]\n",
      "epoch:22 step:21509 [D loss: 0.493287, acc.: 75.00%] [G loss: 0.902869]\n",
      "epoch:22 step:21510 [D loss: 0.492828, acc.: 75.00%] [G loss: 0.978608]\n",
      "epoch:22 step:21511 [D loss: 0.449394, acc.: 80.47%] [G loss: 0.724650]\n",
      "epoch:22 step:21512 [D loss: 0.482273, acc.: 75.78%] [G loss: 0.891346]\n",
      "epoch:22 step:21513 [D loss: 0.459257, acc.: 78.12%] [G loss: 0.757603]\n",
      "epoch:22 step:21514 [D loss: 0.487877, acc.: 78.91%] [G loss: 0.832627]\n",
      "epoch:22 step:21515 [D loss: 0.520507, acc.: 73.44%] [G loss: 0.766672]\n",
      "epoch:22 step:21516 [D loss: 0.559521, acc.: 68.75%] [G loss: 0.782749]\n",
      "epoch:22 step:21517 [D loss: 0.507623, acc.: 72.66%] [G loss: 0.844573]\n",
      "epoch:22 step:21518 [D loss: 0.577603, acc.: 69.53%] [G loss: 0.677687]\n",
      "epoch:22 step:21519 [D loss: 0.555035, acc.: 71.09%] [G loss: 0.798265]\n",
      "epoch:22 step:21520 [D loss: 0.523392, acc.: 69.53%] [G loss: 0.826102]\n",
      "epoch:22 step:21521 [D loss: 0.542921, acc.: 72.66%] [G loss: 0.675557]\n",
      "epoch:22 step:21522 [D loss: 0.515307, acc.: 75.00%] [G loss: 0.629300]\n",
      "epoch:22 step:21523 [D loss: 0.479663, acc.: 74.22%] [G loss: 0.631167]\n",
      "epoch:22 step:21524 [D loss: 0.529350, acc.: 71.09%] [G loss: 0.629939]\n",
      "epoch:22 step:21525 [D loss: 0.454133, acc.: 78.12%] [G loss: 0.668288]\n",
      "epoch:22 step:21526 [D loss: 0.511158, acc.: 75.00%] [G loss: 0.786158]\n",
      "epoch:22 step:21527 [D loss: 0.526293, acc.: 76.56%] [G loss: 0.955432]\n",
      "epoch:22 step:21528 [D loss: 0.451437, acc.: 75.00%] [G loss: 0.971385]\n",
      "epoch:22 step:21529 [D loss: 0.673454, acc.: 63.28%] [G loss: 0.662856]\n",
      "epoch:22 step:21530 [D loss: 0.495124, acc.: 75.00%] [G loss: 0.712851]\n",
      "epoch:22 step:21531 [D loss: 0.610140, acc.: 63.28%] [G loss: 0.669569]\n",
      "epoch:22 step:21532 [D loss: 0.530768, acc.: 69.53%] [G loss: 0.604535]\n",
      "epoch:22 step:21533 [D loss: 0.400057, acc.: 85.16%] [G loss: 0.865012]\n",
      "epoch:22 step:21534 [D loss: 0.718427, acc.: 53.12%] [G loss: 0.655220]\n",
      "epoch:22 step:21535 [D loss: 0.483947, acc.: 71.09%] [G loss: 0.747679]\n",
      "epoch:22 step:21536 [D loss: 0.445333, acc.: 78.91%] [G loss: 0.777695]\n",
      "epoch:22 step:21537 [D loss: 0.464283, acc.: 74.22%] [G loss: 0.842510]\n",
      "epoch:22 step:21538 [D loss: 0.479614, acc.: 75.78%] [G loss: 0.844293]\n",
      "epoch:22 step:21539 [D loss: 0.423537, acc.: 83.59%] [G loss: 1.027497]\n",
      "epoch:22 step:21540 [D loss: 0.467006, acc.: 75.00%] [G loss: 1.255382]\n",
      "epoch:22 step:21541 [D loss: 0.434763, acc.: 77.34%] [G loss: 1.097959]\n",
      "epoch:22 step:21542 [D loss: 0.706222, acc.: 63.28%] [G loss: 1.014739]\n",
      "epoch:22 step:21543 [D loss: 0.525572, acc.: 72.66%] [G loss: 1.267784]\n",
      "epoch:22 step:21544 [D loss: 0.502865, acc.: 70.31%] [G loss: 0.977648]\n",
      "epoch:22 step:21545 [D loss: 0.504840, acc.: 72.66%] [G loss: 0.924492]\n",
      "epoch:22 step:21546 [D loss: 0.586852, acc.: 60.16%] [G loss: 0.727673]\n",
      "epoch:22 step:21547 [D loss: 0.487356, acc.: 74.22%] [G loss: 0.795270]\n",
      "epoch:22 step:21548 [D loss: 0.558155, acc.: 69.53%] [G loss: 1.025065]\n",
      "epoch:22 step:21549 [D loss: 0.518874, acc.: 71.09%] [G loss: 0.925367]\n",
      "epoch:22 step:21550 [D loss: 0.393368, acc.: 79.69%] [G loss: 1.411029]\n",
      "epoch:22 step:21551 [D loss: 0.430118, acc.: 84.38%] [G loss: 1.195744]\n",
      "epoch:23 step:21552 [D loss: 0.546737, acc.: 71.88%] [G loss: 1.112436]\n",
      "epoch:23 step:21553 [D loss: 0.514633, acc.: 74.22%] [G loss: 1.276978]\n",
      "epoch:23 step:21554 [D loss: 0.555956, acc.: 74.22%] [G loss: 1.252106]\n",
      "epoch:23 step:21555 [D loss: 0.509893, acc.: 73.44%] [G loss: 1.200855]\n",
      "epoch:23 step:21556 [D loss: 0.569856, acc.: 64.84%] [G loss: 0.920695]\n",
      "epoch:23 step:21557 [D loss: 0.599936, acc.: 66.41%] [G loss: 0.836087]\n",
      "epoch:23 step:21558 [D loss: 0.450808, acc.: 80.47%] [G loss: 0.955974]\n",
      "epoch:23 step:21559 [D loss: 0.531068, acc.: 71.88%] [G loss: 0.744213]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:23 step:21560 [D loss: 0.458285, acc.: 78.91%] [G loss: 0.753625]\n",
      "epoch:23 step:21561 [D loss: 0.497076, acc.: 71.09%] [G loss: 0.858520]\n",
      "epoch:23 step:21562 [D loss: 0.438330, acc.: 82.81%] [G loss: 0.889146]\n",
      "epoch:23 step:21563 [D loss: 0.493940, acc.: 73.44%] [G loss: 0.759580]\n",
      "epoch:23 step:21564 [D loss: 0.549218, acc.: 68.75%] [G loss: 0.746477]\n",
      "epoch:23 step:21565 [D loss: 0.492438, acc.: 76.56%] [G loss: 0.772225]\n",
      "epoch:23 step:21566 [D loss: 0.443384, acc.: 81.25%] [G loss: 0.748883]\n",
      "epoch:23 step:21567 [D loss: 0.436907, acc.: 81.25%] [G loss: 0.781824]\n",
      "epoch:23 step:21568 [D loss: 0.622324, acc.: 63.28%] [G loss: 0.805657]\n",
      "epoch:23 step:21569 [D loss: 0.494605, acc.: 75.78%] [G loss: 0.781405]\n",
      "epoch:23 step:21570 [D loss: 0.533961, acc.: 69.53%] [G loss: 0.914271]\n",
      "epoch:23 step:21571 [D loss: 0.666163, acc.: 62.50%] [G loss: 0.822465]\n",
      "epoch:23 step:21572 [D loss: 0.527836, acc.: 74.22%] [G loss: 0.809144]\n",
      "epoch:23 step:21573 [D loss: 0.417153, acc.: 82.03%] [G loss: 1.031442]\n",
      "epoch:23 step:21574 [D loss: 0.575372, acc.: 64.06%] [G loss: 0.694815]\n",
      "epoch:23 step:21575 [D loss: 0.545174, acc.: 72.66%] [G loss: 0.671096]\n",
      "epoch:23 step:21576 [D loss: 0.510239, acc.: 78.12%] [G loss: 0.695537]\n",
      "epoch:23 step:21577 [D loss: 0.628511, acc.: 62.50%] [G loss: 0.662037]\n",
      "epoch:23 step:21578 [D loss: 0.461567, acc.: 76.56%] [G loss: 0.794346]\n",
      "epoch:23 step:21579 [D loss: 0.552338, acc.: 67.19%] [G loss: 0.686466]\n",
      "epoch:23 step:21580 [D loss: 0.511548, acc.: 74.22%] [G loss: 0.844779]\n",
      "epoch:23 step:21581 [D loss: 0.523729, acc.: 71.88%] [G loss: 0.780039]\n",
      "epoch:23 step:21582 [D loss: 0.626574, acc.: 62.50%] [G loss: 0.593124]\n",
      "epoch:23 step:21583 [D loss: 0.522906, acc.: 70.31%] [G loss: 0.527134]\n",
      "epoch:23 step:21584 [D loss: 0.540120, acc.: 67.19%] [G loss: 0.725426]\n",
      "epoch:23 step:21585 [D loss: 0.485794, acc.: 72.66%] [G loss: 0.888396]\n",
      "epoch:23 step:21586 [D loss: 0.543431, acc.: 66.41%] [G loss: 0.753333]\n",
      "epoch:23 step:21587 [D loss: 0.552184, acc.: 66.41%] [G loss: 0.536727]\n",
      "epoch:23 step:21588 [D loss: 0.480447, acc.: 72.66%] [G loss: 0.781892]\n",
      "epoch:23 step:21589 [D loss: 0.597515, acc.: 68.75%] [G loss: 0.645158]\n",
      "epoch:23 step:21590 [D loss: 0.531893, acc.: 75.00%] [G loss: 0.569868]\n",
      "epoch:23 step:21591 [D loss: 0.478588, acc.: 78.12%] [G loss: 0.858830]\n",
      "epoch:23 step:21592 [D loss: 0.506293, acc.: 73.44%] [G loss: 0.843439]\n",
      "epoch:23 step:21593 [D loss: 0.551155, acc.: 68.75%] [G loss: 0.638988]\n",
      "epoch:23 step:21594 [D loss: 0.531361, acc.: 73.44%] [G loss: 0.673541]\n",
      "epoch:23 step:21595 [D loss: 0.570480, acc.: 66.41%] [G loss: 0.601797]\n",
      "epoch:23 step:21596 [D loss: 0.501106, acc.: 71.09%] [G loss: 0.560781]\n",
      "epoch:23 step:21597 [D loss: 0.428034, acc.: 81.25%] [G loss: 0.711604]\n",
      "epoch:23 step:21598 [D loss: 0.564473, acc.: 67.97%] [G loss: 0.744526]\n",
      "epoch:23 step:21599 [D loss: 0.499849, acc.: 71.09%] [G loss: 0.876764]\n",
      "epoch:23 step:21600 [D loss: 0.493891, acc.: 74.22%] [G loss: 0.724384]\n",
      "epoch:23 step:21601 [D loss: 0.532591, acc.: 66.41%] [G loss: 0.826463]\n",
      "epoch:23 step:21602 [D loss: 0.613110, acc.: 66.41%] [G loss: 0.706909]\n",
      "epoch:23 step:21603 [D loss: 0.544065, acc.: 69.53%] [G loss: 0.615659]\n",
      "epoch:23 step:21604 [D loss: 0.525390, acc.: 71.09%] [G loss: 0.884621]\n",
      "epoch:23 step:21605 [D loss: 0.478100, acc.: 78.12%] [G loss: 0.909613]\n",
      "epoch:23 step:21606 [D loss: 0.527357, acc.: 73.44%] [G loss: 0.788834]\n",
      "epoch:23 step:21607 [D loss: 0.495580, acc.: 73.44%] [G loss: 0.864162]\n",
      "epoch:23 step:21608 [D loss: 0.498717, acc.: 74.22%] [G loss: 0.808698]\n",
      "epoch:23 step:21609 [D loss: 0.543305, acc.: 69.53%] [G loss: 0.815065]\n",
      "epoch:23 step:21610 [D loss: 0.472933, acc.: 79.69%] [G loss: 0.821974]\n",
      "epoch:23 step:21611 [D loss: 0.569415, acc.: 67.97%] [G loss: 0.723491]\n",
      "epoch:23 step:21612 [D loss: 0.524420, acc.: 72.66%] [G loss: 0.828523]\n",
      "epoch:23 step:21613 [D loss: 0.558452, acc.: 75.00%] [G loss: 0.604120]\n",
      "epoch:23 step:21614 [D loss: 0.505608, acc.: 73.44%] [G loss: 0.525074]\n",
      "epoch:23 step:21615 [D loss: 0.558409, acc.: 71.88%] [G loss: 0.510911]\n",
      "epoch:23 step:21616 [D loss: 0.511400, acc.: 71.88%] [G loss: 0.528363]\n",
      "epoch:23 step:21617 [D loss: 0.537644, acc.: 71.09%] [G loss: 0.719479]\n",
      "epoch:23 step:21618 [D loss: 0.578081, acc.: 66.41%] [G loss: 0.653717]\n",
      "epoch:23 step:21619 [D loss: 0.548791, acc.: 71.88%] [G loss: 0.498913]\n",
      "epoch:23 step:21620 [D loss: 0.464749, acc.: 83.59%] [G loss: 0.751103]\n",
      "epoch:23 step:21621 [D loss: 0.515245, acc.: 71.09%] [G loss: 0.650871]\n",
      "epoch:23 step:21622 [D loss: 0.532693, acc.: 75.00%] [G loss: 0.616906]\n",
      "epoch:23 step:21623 [D loss: 0.490922, acc.: 72.66%] [G loss: 0.694249]\n",
      "epoch:23 step:21624 [D loss: 0.549105, acc.: 71.88%] [G loss: 0.621229]\n",
      "epoch:23 step:21625 [D loss: 0.471664, acc.: 81.25%] [G loss: 0.707217]\n",
      "epoch:23 step:21626 [D loss: 0.544548, acc.: 75.00%] [G loss: 0.704352]\n",
      "epoch:23 step:21627 [D loss: 0.505832, acc.: 72.66%] [G loss: 0.947227]\n",
      "epoch:23 step:21628 [D loss: 0.450277, acc.: 76.56%] [G loss: 0.775985]\n",
      "epoch:23 step:21629 [D loss: 0.514416, acc.: 77.34%] [G loss: 0.964433]\n",
      "epoch:23 step:21630 [D loss: 0.530136, acc.: 73.44%] [G loss: 0.767278]\n",
      "epoch:23 step:21631 [D loss: 0.513184, acc.: 72.66%] [G loss: 0.615234]\n",
      "epoch:23 step:21632 [D loss: 0.518449, acc.: 73.44%] [G loss: 0.748290]\n",
      "epoch:23 step:21633 [D loss: 0.483663, acc.: 75.00%] [G loss: 0.817022]\n",
      "epoch:23 step:21634 [D loss: 0.441014, acc.: 78.91%] [G loss: 0.727417]\n",
      "epoch:23 step:21635 [D loss: 0.526083, acc.: 71.88%] [G loss: 0.814339]\n",
      "epoch:23 step:21636 [D loss: 0.588382, acc.: 64.06%] [G loss: 0.702675]\n",
      "epoch:23 step:21637 [D loss: 0.507129, acc.: 71.88%] [G loss: 0.732310]\n",
      "epoch:23 step:21638 [D loss: 0.502798, acc.: 74.22%] [G loss: 0.892154]\n",
      "epoch:23 step:21639 [D loss: 0.493663, acc.: 76.56%] [G loss: 0.782449]\n",
      "epoch:23 step:21640 [D loss: 0.486375, acc.: 75.78%] [G loss: 0.856369]\n",
      "epoch:23 step:21641 [D loss: 0.486015, acc.: 73.44%] [G loss: 1.086006]\n",
      "epoch:23 step:21642 [D loss: 0.573114, acc.: 68.75%] [G loss: 0.552574]\n",
      "epoch:23 step:21643 [D loss: 0.435227, acc.: 78.91%] [G loss: 0.733031]\n",
      "epoch:23 step:21644 [D loss: 0.539695, acc.: 68.75%] [G loss: 0.807925]\n",
      "epoch:23 step:21645 [D loss: 0.458238, acc.: 78.12%] [G loss: 0.818585]\n",
      "epoch:23 step:21646 [D loss: 0.532514, acc.: 71.88%] [G loss: 0.802163]\n",
      "epoch:23 step:21647 [D loss: 0.499541, acc.: 74.22%] [G loss: 0.875814]\n",
      "epoch:23 step:21648 [D loss: 0.501828, acc.: 73.44%] [G loss: 0.879271]\n",
      "epoch:23 step:21649 [D loss: 0.604077, acc.: 64.84%] [G loss: 0.789965]\n",
      "epoch:23 step:21650 [D loss: 0.546465, acc.: 71.88%] [G loss: 0.819807]\n",
      "epoch:23 step:21651 [D loss: 0.456959, acc.: 76.56%] [G loss: 1.048229]\n",
      "epoch:23 step:21652 [D loss: 0.510254, acc.: 75.00%] [G loss: 0.845507]\n",
      "epoch:23 step:21653 [D loss: 0.637017, acc.: 65.62%] [G loss: 0.691093]\n",
      "epoch:23 step:21654 [D loss: 0.499985, acc.: 70.31%] [G loss: 0.691501]\n",
      "epoch:23 step:21655 [D loss: 0.503421, acc.: 71.88%] [G loss: 0.750221]\n",
      "epoch:23 step:21656 [D loss: 0.556584, acc.: 71.09%] [G loss: 0.659343]\n",
      "epoch:23 step:21657 [D loss: 0.487611, acc.: 73.44%] [G loss: 0.647378]\n",
      "epoch:23 step:21658 [D loss: 0.510838, acc.: 75.78%] [G loss: 0.686469]\n",
      "epoch:23 step:21659 [D loss: 0.568027, acc.: 74.22%] [G loss: 0.684128]\n",
      "epoch:23 step:21660 [D loss: 0.523698, acc.: 72.66%] [G loss: 0.630781]\n",
      "epoch:23 step:21661 [D loss: 0.581219, acc.: 63.28%] [G loss: 0.586475]\n",
      "epoch:23 step:21662 [D loss: 0.525897, acc.: 68.75%] [G loss: 0.701946]\n",
      "epoch:23 step:21663 [D loss: 0.492377, acc.: 75.78%] [G loss: 0.621766]\n",
      "epoch:23 step:21664 [D loss: 0.463019, acc.: 79.69%] [G loss: 0.636401]\n",
      "epoch:23 step:21665 [D loss: 0.511156, acc.: 71.88%] [G loss: 0.679329]\n",
      "epoch:23 step:21666 [D loss: 0.497015, acc.: 75.78%] [G loss: 0.779877]\n",
      "epoch:23 step:21667 [D loss: 0.538127, acc.: 71.09%] [G loss: 0.937166]\n",
      "epoch:23 step:21668 [D loss: 0.476641, acc.: 78.91%] [G loss: 1.119198]\n",
      "epoch:23 step:21669 [D loss: 0.489683, acc.: 73.44%] [G loss: 0.834133]\n",
      "epoch:23 step:21670 [D loss: 0.436899, acc.: 80.47%] [G loss: 0.909137]\n",
      "epoch:23 step:21671 [D loss: 0.549412, acc.: 71.88%] [G loss: 0.874764]\n",
      "epoch:23 step:21672 [D loss: 0.438760, acc.: 79.69%] [G loss: 0.851552]\n",
      "epoch:23 step:21673 [D loss: 0.472647, acc.: 82.03%] [G loss: 0.839529]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:23 step:21674 [D loss: 0.484103, acc.: 76.56%] [G loss: 0.815497]\n",
      "epoch:23 step:21675 [D loss: 0.548792, acc.: 72.66%] [G loss: 0.862613]\n",
      "epoch:23 step:21676 [D loss: 0.549129, acc.: 67.19%] [G loss: 0.758583]\n",
      "epoch:23 step:21677 [D loss: 0.493404, acc.: 74.22%] [G loss: 0.739965]\n",
      "epoch:23 step:21678 [D loss: 0.496511, acc.: 73.44%] [G loss: 0.804301]\n",
      "epoch:23 step:21679 [D loss: 0.523372, acc.: 67.19%] [G loss: 0.636301]\n",
      "epoch:23 step:21680 [D loss: 0.592610, acc.: 69.53%] [G loss: 0.854192]\n",
      "epoch:23 step:21681 [D loss: 0.488087, acc.: 75.00%] [G loss: 0.851012]\n",
      "epoch:23 step:21682 [D loss: 0.489544, acc.: 76.56%] [G loss: 0.916086]\n",
      "epoch:23 step:21683 [D loss: 0.563317, acc.: 73.44%] [G loss: 0.775509]\n",
      "epoch:23 step:21684 [D loss: 0.497000, acc.: 72.66%] [G loss: 0.852963]\n",
      "epoch:23 step:21685 [D loss: 0.531903, acc.: 71.09%] [G loss: 0.683509]\n",
      "epoch:23 step:21686 [D loss: 0.530391, acc.: 71.88%] [G loss: 0.647600]\n",
      "epoch:23 step:21687 [D loss: 0.496782, acc.: 79.69%] [G loss: 0.914206]\n",
      "epoch:23 step:21688 [D loss: 0.562724, acc.: 71.09%] [G loss: 0.694409]\n",
      "epoch:23 step:21689 [D loss: 0.576035, acc.: 67.19%] [G loss: 0.619990]\n",
      "epoch:23 step:21690 [D loss: 0.508014, acc.: 74.22%] [G loss: 0.926100]\n",
      "epoch:23 step:21691 [D loss: 0.583028, acc.: 66.41%] [G loss: 0.709203]\n",
      "epoch:23 step:21692 [D loss: 0.520624, acc.: 72.66%] [G loss: 0.487962]\n",
      "epoch:23 step:21693 [D loss: 0.537069, acc.: 70.31%] [G loss: 0.598067]\n",
      "epoch:23 step:21694 [D loss: 0.621850, acc.: 66.41%] [G loss: 0.601653]\n",
      "epoch:23 step:21695 [D loss: 0.542544, acc.: 73.44%] [G loss: 0.589771]\n",
      "epoch:23 step:21696 [D loss: 0.544059, acc.: 71.09%] [G loss: 0.728621]\n",
      "epoch:23 step:21697 [D loss: 0.453146, acc.: 77.34%] [G loss: 0.791153]\n",
      "epoch:23 step:21698 [D loss: 0.576207, acc.: 68.75%] [G loss: 0.807890]\n",
      "epoch:23 step:21699 [D loss: 0.526639, acc.: 69.53%] [G loss: 0.775902]\n",
      "epoch:23 step:21700 [D loss: 0.505807, acc.: 76.56%] [G loss: 0.616805]\n",
      "epoch:23 step:21701 [D loss: 0.552607, acc.: 68.75%] [G loss: 0.747887]\n",
      "epoch:23 step:21702 [D loss: 0.525879, acc.: 73.44%] [G loss: 0.767548]\n",
      "epoch:23 step:21703 [D loss: 0.505736, acc.: 71.88%] [G loss: 0.765859]\n",
      "epoch:23 step:21704 [D loss: 0.534950, acc.: 73.44%] [G loss: 0.686250]\n",
      "epoch:23 step:21705 [D loss: 0.527049, acc.: 67.97%] [G loss: 0.611870]\n",
      "epoch:23 step:21706 [D loss: 0.474820, acc.: 73.44%] [G loss: 0.753174]\n",
      "epoch:23 step:21707 [D loss: 0.469360, acc.: 78.91%] [G loss: 0.723206]\n",
      "epoch:23 step:21708 [D loss: 0.577197, acc.: 67.19%] [G loss: 0.714072]\n",
      "epoch:23 step:21709 [D loss: 0.515358, acc.: 77.34%] [G loss: 0.727788]\n",
      "epoch:23 step:21710 [D loss: 0.514938, acc.: 71.88%] [G loss: 0.595282]\n",
      "epoch:23 step:21711 [D loss: 0.593794, acc.: 67.19%] [G loss: 0.792572]\n",
      "epoch:23 step:21712 [D loss: 0.499015, acc.: 73.44%] [G loss: 0.897602]\n",
      "epoch:23 step:21713 [D loss: 0.469109, acc.: 75.78%] [G loss: 0.872794]\n",
      "epoch:23 step:21714 [D loss: 0.576733, acc.: 67.97%] [G loss: 0.841932]\n",
      "epoch:23 step:21715 [D loss: 0.541871, acc.: 71.88%] [G loss: 1.001631]\n",
      "epoch:23 step:21716 [D loss: 0.450283, acc.: 77.34%] [G loss: 0.817528]\n",
      "epoch:23 step:21717 [D loss: 0.522182, acc.: 69.53%] [G loss: 0.762565]\n",
      "epoch:23 step:21718 [D loss: 0.509573, acc.: 72.66%] [G loss: 0.612895]\n",
      "epoch:23 step:21719 [D loss: 0.622408, acc.: 67.19%] [G loss: 0.608942]\n",
      "epoch:23 step:21720 [D loss: 0.577845, acc.: 71.88%] [G loss: 0.638235]\n",
      "epoch:23 step:21721 [D loss: 0.562668, acc.: 69.53%] [G loss: 0.701844]\n",
      "epoch:23 step:21722 [D loss: 0.548078, acc.: 71.09%] [G loss: 0.709833]\n",
      "epoch:23 step:21723 [D loss: 0.465148, acc.: 76.56%] [G loss: 0.683152]\n",
      "epoch:23 step:21724 [D loss: 0.514895, acc.: 77.34%] [G loss: 0.694925]\n",
      "epoch:23 step:21725 [D loss: 0.565128, acc.: 67.97%] [G loss: 0.655505]\n",
      "epoch:23 step:21726 [D loss: 0.552493, acc.: 67.19%] [G loss: 0.599918]\n",
      "epoch:23 step:21727 [D loss: 0.499703, acc.: 71.88%] [G loss: 0.632325]\n",
      "epoch:23 step:21728 [D loss: 0.501852, acc.: 73.44%] [G loss: 0.704132]\n",
      "epoch:23 step:21729 [D loss: 0.550444, acc.: 72.66%] [G loss: 0.632724]\n",
      "epoch:23 step:21730 [D loss: 0.511075, acc.: 72.66%] [G loss: 0.653106]\n",
      "epoch:23 step:21731 [D loss: 0.620146, acc.: 63.28%] [G loss: 0.618874]\n",
      "epoch:23 step:21732 [D loss: 0.548355, acc.: 67.19%] [G loss: 0.614063]\n",
      "epoch:23 step:21733 [D loss: 0.471422, acc.: 73.44%] [G loss: 0.634157]\n",
      "epoch:23 step:21734 [D loss: 0.512165, acc.: 75.00%] [G loss: 0.584388]\n",
      "epoch:23 step:21735 [D loss: 0.488283, acc.: 76.56%] [G loss: 0.776079]\n",
      "epoch:23 step:21736 [D loss: 0.549969, acc.: 70.31%] [G loss: 0.796056]\n",
      "epoch:23 step:21737 [D loss: 0.462133, acc.: 75.00%] [G loss: 0.794894]\n",
      "epoch:23 step:21738 [D loss: 0.655432, acc.: 64.06%] [G loss: 0.646194]\n",
      "epoch:23 step:21739 [D loss: 0.499439, acc.: 71.88%] [G loss: 0.801181]\n",
      "epoch:23 step:21740 [D loss: 0.567727, acc.: 71.88%] [G loss: 0.659844]\n",
      "epoch:23 step:21741 [D loss: 0.459456, acc.: 78.12%] [G loss: 0.690095]\n",
      "epoch:23 step:21742 [D loss: 0.503626, acc.: 75.00%] [G loss: 0.782574]\n",
      "epoch:23 step:21743 [D loss: 0.478372, acc.: 77.34%] [G loss: 0.743526]\n",
      "epoch:23 step:21744 [D loss: 0.561434, acc.: 70.31%] [G loss: 0.919873]\n",
      "epoch:23 step:21745 [D loss: 0.480978, acc.: 74.22%] [G loss: 0.805351]\n",
      "epoch:23 step:21746 [D loss: 0.502328, acc.: 73.44%] [G loss: 1.016576]\n",
      "epoch:23 step:21747 [D loss: 0.576971, acc.: 66.41%] [G loss: 0.670970]\n",
      "epoch:23 step:21748 [D loss: 0.465182, acc.: 77.34%] [G loss: 0.701517]\n",
      "epoch:23 step:21749 [D loss: 0.472982, acc.: 78.12%] [G loss: 0.717489]\n",
      "epoch:23 step:21750 [D loss: 0.505191, acc.: 76.56%] [G loss: 0.875279]\n",
      "epoch:23 step:21751 [D loss: 0.581439, acc.: 65.62%] [G loss: 0.580416]\n",
      "epoch:23 step:21752 [D loss: 0.534572, acc.: 67.97%] [G loss: 0.738788]\n",
      "epoch:23 step:21753 [D loss: 0.540634, acc.: 74.22%] [G loss: 0.686443]\n",
      "epoch:23 step:21754 [D loss: 0.537285, acc.: 72.66%] [G loss: 0.812868]\n",
      "epoch:23 step:21755 [D loss: 0.494275, acc.: 74.22%] [G loss: 0.691770]\n",
      "epoch:23 step:21756 [D loss: 0.492947, acc.: 78.91%] [G loss: 0.787447]\n",
      "epoch:23 step:21757 [D loss: 0.464661, acc.: 75.78%] [G loss: 0.890297]\n",
      "epoch:23 step:21758 [D loss: 0.452288, acc.: 80.47%] [G loss: 0.939150]\n",
      "epoch:23 step:21759 [D loss: 0.428160, acc.: 78.91%] [G loss: 0.890108]\n",
      "epoch:23 step:21760 [D loss: 0.491962, acc.: 77.34%] [G loss: 0.932757]\n",
      "epoch:23 step:21761 [D loss: 0.666191, acc.: 60.94%] [G loss: 0.778366]\n",
      "epoch:23 step:21762 [D loss: 0.579548, acc.: 68.75%] [G loss: 0.662768]\n",
      "epoch:23 step:21763 [D loss: 0.563185, acc.: 67.19%] [G loss: 0.534825]\n",
      "epoch:23 step:21764 [D loss: 0.513609, acc.: 73.44%] [G loss: 0.679471]\n",
      "epoch:23 step:21765 [D loss: 0.571778, acc.: 68.75%] [G loss: 0.584404]\n",
      "epoch:23 step:21766 [D loss: 0.545670, acc.: 69.53%] [G loss: 0.624747]\n",
      "epoch:23 step:21767 [D loss: 0.526409, acc.: 68.75%] [G loss: 0.698201]\n",
      "epoch:23 step:21768 [D loss: 0.486886, acc.: 76.56%] [G loss: 0.649778]\n",
      "epoch:23 step:21769 [D loss: 0.531745, acc.: 73.44%] [G loss: 0.789300]\n",
      "epoch:23 step:21770 [D loss: 0.466145, acc.: 78.91%] [G loss: 0.987214]\n",
      "epoch:23 step:21771 [D loss: 0.614778, acc.: 70.31%] [G loss: 0.606083]\n",
      "epoch:23 step:21772 [D loss: 0.595622, acc.: 67.19%] [G loss: 0.609122]\n",
      "epoch:23 step:21773 [D loss: 0.475606, acc.: 78.12%] [G loss: 0.732566]\n",
      "epoch:23 step:21774 [D loss: 0.518821, acc.: 74.22%] [G loss: 0.706288]\n",
      "epoch:23 step:21775 [D loss: 0.542073, acc.: 71.88%] [G loss: 0.627214]\n",
      "epoch:23 step:21776 [D loss: 0.492778, acc.: 76.56%] [G loss: 0.734609]\n",
      "epoch:23 step:21777 [D loss: 0.575268, acc.: 64.84%] [G loss: 0.706278]\n",
      "epoch:23 step:21778 [D loss: 0.507326, acc.: 74.22%] [G loss: 0.755341]\n",
      "epoch:23 step:21779 [D loss: 0.610753, acc.: 60.16%] [G loss: 0.573168]\n",
      "epoch:23 step:21780 [D loss: 0.502970, acc.: 76.56%] [G loss: 0.596858]\n",
      "epoch:23 step:21781 [D loss: 0.463247, acc.: 77.34%] [G loss: 0.874057]\n",
      "epoch:23 step:21782 [D loss: 0.430991, acc.: 77.34%] [G loss: 0.931050]\n",
      "epoch:23 step:21783 [D loss: 0.417494, acc.: 82.03%] [G loss: 1.040702]\n",
      "epoch:23 step:21784 [D loss: 0.593147, acc.: 67.19%] [G loss: 1.018596]\n",
      "epoch:23 step:21785 [D loss: 0.545153, acc.: 70.31%] [G loss: 0.822805]\n",
      "epoch:23 step:21786 [D loss: 0.539957, acc.: 69.53%] [G loss: 0.730418]\n",
      "epoch:23 step:21787 [D loss: 0.478370, acc.: 72.66%] [G loss: 0.667802]\n",
      "epoch:23 step:21788 [D loss: 0.588329, acc.: 65.62%] [G loss: 0.615769]\n",
      "epoch:23 step:21789 [D loss: 0.598174, acc.: 62.50%] [G loss: 0.704690]\n",
      "epoch:23 step:21790 [D loss: 0.540453, acc.: 71.09%] [G loss: 0.566172]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:23 step:21791 [D loss: 0.553728, acc.: 66.41%] [G loss: 0.626755]\n",
      "epoch:23 step:21792 [D loss: 0.530855, acc.: 70.31%] [G loss: 0.505330]\n",
      "epoch:23 step:21793 [D loss: 0.490404, acc.: 74.22%] [G loss: 0.605142]\n",
      "epoch:23 step:21794 [D loss: 0.526889, acc.: 66.41%] [G loss: 0.582041]\n",
      "epoch:23 step:21795 [D loss: 0.477025, acc.: 75.00%] [G loss: 0.877290]\n",
      "epoch:23 step:21796 [D loss: 0.483197, acc.: 76.56%] [G loss: 0.854824]\n",
      "epoch:23 step:21797 [D loss: 0.465662, acc.: 82.81%] [G loss: 0.743489]\n",
      "epoch:23 step:21798 [D loss: 0.492371, acc.: 78.12%] [G loss: 0.805155]\n",
      "epoch:23 step:21799 [D loss: 0.521226, acc.: 68.75%] [G loss: 0.971865]\n",
      "epoch:23 step:21800 [D loss: 0.532150, acc.: 71.88%] [G loss: 1.001964]\n",
      "epoch:23 step:21801 [D loss: 0.534334, acc.: 71.09%] [G loss: 0.968589]\n",
      "epoch:23 step:21802 [D loss: 0.579151, acc.: 69.53%] [G loss: 0.830153]\n",
      "epoch:23 step:21803 [D loss: 0.641647, acc.: 64.84%] [G loss: 0.814494]\n",
      "epoch:23 step:21804 [D loss: 0.585918, acc.: 64.84%] [G loss: 0.855008]\n",
      "epoch:23 step:21805 [D loss: 0.488857, acc.: 72.66%] [G loss: 0.648966]\n",
      "epoch:23 step:21806 [D loss: 0.528522, acc.: 69.53%] [G loss: 0.596682]\n",
      "epoch:23 step:21807 [D loss: 0.571931, acc.: 62.50%] [G loss: 0.697579]\n",
      "epoch:23 step:21808 [D loss: 0.634035, acc.: 58.59%] [G loss: 0.596620]\n",
      "epoch:23 step:21809 [D loss: 0.480900, acc.: 78.12%] [G loss: 0.622023]\n",
      "epoch:23 step:21810 [D loss: 0.511138, acc.: 75.78%] [G loss: 0.745976]\n",
      "epoch:23 step:21811 [D loss: 0.595646, acc.: 67.19%] [G loss: 0.752079]\n",
      "epoch:23 step:21812 [D loss: 0.471593, acc.: 75.78%] [G loss: 0.621852]\n",
      "epoch:23 step:21813 [D loss: 0.506107, acc.: 75.00%] [G loss: 0.712392]\n",
      "epoch:23 step:21814 [D loss: 0.562128, acc.: 67.97%] [G loss: 0.771288]\n",
      "epoch:23 step:21815 [D loss: 0.464944, acc.: 75.78%] [G loss: 0.817591]\n",
      "epoch:23 step:21816 [D loss: 0.536421, acc.: 72.66%] [G loss: 0.699256]\n",
      "epoch:23 step:21817 [D loss: 0.527869, acc.: 71.88%] [G loss: 0.723599]\n",
      "epoch:23 step:21818 [D loss: 0.518481, acc.: 75.00%] [G loss: 0.723494]\n",
      "epoch:23 step:21819 [D loss: 0.521003, acc.: 67.97%] [G loss: 0.636174]\n",
      "epoch:23 step:21820 [D loss: 0.527435, acc.: 75.00%] [G loss: 0.702573]\n",
      "epoch:23 step:21821 [D loss: 0.481648, acc.: 77.34%] [G loss: 0.697784]\n",
      "epoch:23 step:21822 [D loss: 0.496766, acc.: 71.09%] [G loss: 0.729105]\n",
      "epoch:23 step:21823 [D loss: 0.532914, acc.: 72.66%] [G loss: 0.710898]\n",
      "epoch:23 step:21824 [D loss: 0.500845, acc.: 72.66%] [G loss: 0.698821]\n",
      "epoch:23 step:21825 [D loss: 0.480204, acc.: 77.34%] [G loss: 0.692187]\n",
      "epoch:23 step:21826 [D loss: 0.541481, acc.: 69.53%] [G loss: 0.657957]\n",
      "epoch:23 step:21827 [D loss: 0.451402, acc.: 82.03%] [G loss: 0.750454]\n",
      "epoch:23 step:21828 [D loss: 0.673626, acc.: 63.28%] [G loss: 0.542294]\n",
      "epoch:23 step:21829 [D loss: 0.652466, acc.: 64.06%] [G loss: 0.497368]\n",
      "epoch:23 step:21830 [D loss: 0.512343, acc.: 70.31%] [G loss: 0.674566]\n",
      "epoch:23 step:21831 [D loss: 0.533706, acc.: 66.41%] [G loss: 0.705958]\n",
      "epoch:23 step:21832 [D loss: 0.568056, acc.: 66.41%] [G loss: 0.575757]\n",
      "epoch:23 step:21833 [D loss: 0.561561, acc.: 66.41%] [G loss: 0.509169]\n",
      "epoch:23 step:21834 [D loss: 0.515096, acc.: 71.88%] [G loss: 0.633585]\n",
      "epoch:23 step:21835 [D loss: 0.515033, acc.: 73.44%] [G loss: 0.695811]\n",
      "epoch:23 step:21836 [D loss: 0.482033, acc.: 72.66%] [G loss: 0.815972]\n",
      "epoch:23 step:21837 [D loss: 0.511426, acc.: 70.31%] [G loss: 0.690406]\n",
      "epoch:23 step:21838 [D loss: 0.547461, acc.: 69.53%] [G loss: 0.615909]\n",
      "epoch:23 step:21839 [D loss: 0.538554, acc.: 67.97%] [G loss: 0.761296]\n",
      "epoch:23 step:21840 [D loss: 0.536900, acc.: 67.19%] [G loss: 1.043912]\n",
      "epoch:23 step:21841 [D loss: 0.560061, acc.: 67.97%] [G loss: 0.720950]\n",
      "epoch:23 step:21842 [D loss: 0.559460, acc.: 71.88%] [G loss: 0.707369]\n",
      "epoch:23 step:21843 [D loss: 0.544084, acc.: 69.53%] [G loss: 0.627935]\n",
      "epoch:23 step:21844 [D loss: 0.566041, acc.: 66.41%] [G loss: 0.583250]\n",
      "epoch:23 step:21845 [D loss: 0.622306, acc.: 62.50%] [G loss: 0.500549]\n",
      "epoch:23 step:21846 [D loss: 0.529819, acc.: 70.31%] [G loss: 0.473935]\n",
      "epoch:23 step:21847 [D loss: 0.463270, acc.: 78.12%] [G loss: 0.585165]\n",
      "epoch:23 step:21848 [D loss: 0.540664, acc.: 70.31%] [G loss: 0.646292]\n",
      "epoch:23 step:21849 [D loss: 0.504874, acc.: 70.31%] [G loss: 0.619620]\n",
      "epoch:23 step:21850 [D loss: 0.451603, acc.: 77.34%] [G loss: 0.752371]\n",
      "epoch:23 step:21851 [D loss: 0.492873, acc.: 74.22%] [G loss: 0.802370]\n",
      "epoch:23 step:21852 [D loss: 0.603267, acc.: 68.75%] [G loss: 0.649994]\n",
      "epoch:23 step:21853 [D loss: 0.522242, acc.: 72.66%] [G loss: 0.618109]\n",
      "epoch:23 step:21854 [D loss: 0.551154, acc.: 73.44%] [G loss: 0.661637]\n",
      "epoch:23 step:21855 [D loss: 0.561553, acc.: 66.41%] [G loss: 0.771150]\n",
      "epoch:23 step:21856 [D loss: 0.519633, acc.: 73.44%] [G loss: 0.585109]\n",
      "epoch:23 step:21857 [D loss: 0.512016, acc.: 75.78%] [G loss: 0.831897]\n",
      "epoch:23 step:21858 [D loss: 0.475053, acc.: 75.78%] [G loss: 0.783058]\n",
      "epoch:23 step:21859 [D loss: 0.587023, acc.: 67.19%] [G loss: 0.625118]\n",
      "epoch:23 step:21860 [D loss: 0.467131, acc.: 78.12%] [G loss: 0.699304]\n",
      "epoch:23 step:21861 [D loss: 0.505429, acc.: 73.44%] [G loss: 0.584671]\n",
      "epoch:23 step:21862 [D loss: 0.481644, acc.: 75.78%] [G loss: 0.656328]\n",
      "epoch:23 step:21863 [D loss: 0.433546, acc.: 83.59%] [G loss: 0.835070]\n",
      "epoch:23 step:21864 [D loss: 0.485774, acc.: 75.00%] [G loss: 0.806159]\n",
      "epoch:23 step:21865 [D loss: 0.381690, acc.: 81.25%] [G loss: 0.938420]\n",
      "epoch:23 step:21866 [D loss: 0.443909, acc.: 82.03%] [G loss: 1.142730]\n",
      "epoch:23 step:21867 [D loss: 0.652466, acc.: 64.84%] [G loss: 0.724930]\n",
      "epoch:23 step:21868 [D loss: 0.562012, acc.: 74.22%] [G loss: 0.755998]\n",
      "epoch:23 step:21869 [D loss: 0.548891, acc.: 67.97%] [G loss: 0.802336]\n",
      "epoch:23 step:21870 [D loss: 0.576716, acc.: 64.06%] [G loss: 0.661728]\n",
      "epoch:23 step:21871 [D loss: 0.540671, acc.: 70.31%] [G loss: 0.547876]\n",
      "epoch:23 step:21872 [D loss: 0.498568, acc.: 72.66%] [G loss: 0.632528]\n",
      "epoch:23 step:21873 [D loss: 0.590132, acc.: 67.19%] [G loss: 0.709344]\n",
      "epoch:23 step:21874 [D loss: 0.555588, acc.: 71.09%] [G loss: 0.697294]\n",
      "epoch:23 step:21875 [D loss: 0.544430, acc.: 71.88%] [G loss: 0.576058]\n",
      "epoch:23 step:21876 [D loss: 0.539836, acc.: 68.75%] [G loss: 0.648334]\n",
      "epoch:23 step:21877 [D loss: 0.426639, acc.: 75.78%] [G loss: 0.758052]\n",
      "epoch:23 step:21878 [D loss: 0.569349, acc.: 69.53%] [G loss: 0.605609]\n",
      "epoch:23 step:21879 [D loss: 0.416320, acc.: 81.25%] [G loss: 0.849434]\n",
      "epoch:23 step:21880 [D loss: 0.499512, acc.: 77.34%] [G loss: 0.828803]\n",
      "epoch:23 step:21881 [D loss: 0.579345, acc.: 69.53%] [G loss: 0.659371]\n",
      "epoch:23 step:21882 [D loss: 0.554417, acc.: 71.09%] [G loss: 0.593474]\n",
      "epoch:23 step:21883 [D loss: 0.482933, acc.: 76.56%] [G loss: 0.741589]\n",
      "epoch:23 step:21884 [D loss: 0.451431, acc.: 78.91%] [G loss: 0.810481]\n",
      "epoch:23 step:21885 [D loss: 0.464377, acc.: 79.69%] [G loss: 0.691638]\n",
      "epoch:23 step:21886 [D loss: 0.512172, acc.: 71.88%] [G loss: 0.764991]\n",
      "epoch:23 step:21887 [D loss: 0.437368, acc.: 81.25%] [G loss: 0.736547]\n",
      "epoch:23 step:21888 [D loss: 0.486776, acc.: 75.78%] [G loss: 0.755627]\n",
      "epoch:23 step:21889 [D loss: 0.561960, acc.: 69.53%] [G loss: 0.716732]\n",
      "epoch:23 step:21890 [D loss: 0.548232, acc.: 71.09%] [G loss: 0.744456]\n",
      "epoch:23 step:21891 [D loss: 0.470574, acc.: 76.56%] [G loss: 0.718507]\n",
      "epoch:23 step:21892 [D loss: 0.648926, acc.: 68.75%] [G loss: 0.648802]\n",
      "epoch:23 step:21893 [D loss: 0.600605, acc.: 66.41%] [G loss: 0.667478]\n",
      "epoch:23 step:21894 [D loss: 0.503720, acc.: 71.09%] [G loss: 0.735031]\n",
      "epoch:23 step:21895 [D loss: 0.479866, acc.: 78.91%] [G loss: 0.868058]\n",
      "epoch:23 step:21896 [D loss: 0.512217, acc.: 71.88%] [G loss: 0.721635]\n",
      "epoch:23 step:21897 [D loss: 0.537502, acc.: 69.53%] [G loss: 0.687230]\n",
      "epoch:23 step:21898 [D loss: 0.438982, acc.: 80.47%] [G loss: 1.138344]\n",
      "epoch:23 step:21899 [D loss: 0.557727, acc.: 71.88%] [G loss: 0.995713]\n",
      "epoch:23 step:21900 [D loss: 0.673881, acc.: 59.38%] [G loss: 0.589190]\n",
      "epoch:23 step:21901 [D loss: 0.476236, acc.: 79.69%] [G loss: 0.550200]\n",
      "epoch:23 step:21902 [D loss: 0.506689, acc.: 74.22%] [G loss: 0.706284]\n",
      "epoch:23 step:21903 [D loss: 0.606048, acc.: 61.72%] [G loss: 0.565236]\n",
      "epoch:23 step:21904 [D loss: 0.569293, acc.: 71.09%] [G loss: 0.784338]\n",
      "epoch:23 step:21905 [D loss: 0.405184, acc.: 85.16%] [G loss: 0.791542]\n",
      "epoch:23 step:21906 [D loss: 0.511769, acc.: 75.00%] [G loss: 0.912400]\n",
      "epoch:23 step:21907 [D loss: 0.553263, acc.: 70.31%] [G loss: 0.820679]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:23 step:21908 [D loss: 0.463694, acc.: 76.56%] [G loss: 0.831875]\n",
      "epoch:23 step:21909 [D loss: 0.433292, acc.: 78.91%] [G loss: 0.870609]\n",
      "epoch:23 step:21910 [D loss: 0.504746, acc.: 74.22%] [G loss: 0.958768]\n",
      "epoch:23 step:21911 [D loss: 0.525313, acc.: 70.31%] [G loss: 0.859390]\n",
      "epoch:23 step:21912 [D loss: 0.478053, acc.: 75.78%] [G loss: 0.820847]\n",
      "epoch:23 step:21913 [D loss: 0.537698, acc.: 70.31%] [G loss: 0.749742]\n",
      "epoch:23 step:21914 [D loss: 0.525586, acc.: 75.00%] [G loss: 0.771742]\n",
      "epoch:23 step:21915 [D loss: 0.475669, acc.: 74.22%] [G loss: 0.776023]\n",
      "epoch:23 step:21916 [D loss: 0.574230, acc.: 67.97%] [G loss: 0.898655]\n",
      "epoch:23 step:21917 [D loss: 0.477612, acc.: 78.91%] [G loss: 0.737316]\n",
      "epoch:23 step:21918 [D loss: 0.583162, acc.: 65.62%] [G loss: 0.564362]\n",
      "epoch:23 step:21919 [D loss: 0.588646, acc.: 64.06%] [G loss: 0.589914]\n",
      "epoch:23 step:21920 [D loss: 0.506480, acc.: 71.09%] [G loss: 0.797983]\n",
      "epoch:23 step:21921 [D loss: 0.500982, acc.: 74.22%] [G loss: 0.764687]\n",
      "epoch:23 step:21922 [D loss: 0.492296, acc.: 75.78%] [G loss: 0.829459]\n",
      "epoch:23 step:21923 [D loss: 0.537054, acc.: 72.66%] [G loss: 0.849923]\n",
      "epoch:23 step:21924 [D loss: 0.518286, acc.: 70.31%] [G loss: 0.809780]\n",
      "epoch:23 step:21925 [D loss: 0.424099, acc.: 81.25%] [G loss: 0.948805]\n",
      "epoch:23 step:21926 [D loss: 0.558295, acc.: 73.44%] [G loss: 0.852574]\n",
      "epoch:23 step:21927 [D loss: 0.695014, acc.: 63.28%] [G loss: 0.558888]\n",
      "epoch:23 step:21928 [D loss: 0.547557, acc.: 66.41%] [G loss: 0.763569]\n",
      "epoch:23 step:21929 [D loss: 0.503428, acc.: 71.09%] [G loss: 0.678241]\n",
      "epoch:23 step:21930 [D loss: 0.532544, acc.: 74.22%] [G loss: 0.612283]\n",
      "epoch:23 step:21931 [D loss: 0.588841, acc.: 67.19%] [G loss: 0.535102]\n",
      "epoch:23 step:21932 [D loss: 0.467935, acc.: 79.69%] [G loss: 0.588993]\n",
      "epoch:23 step:21933 [D loss: 0.571225, acc.: 69.53%] [G loss: 0.639476]\n",
      "epoch:23 step:21934 [D loss: 0.520550, acc.: 71.88%] [G loss: 0.769405]\n",
      "epoch:23 step:21935 [D loss: 0.493871, acc.: 74.22%] [G loss: 0.741090]\n",
      "epoch:23 step:21936 [D loss: 0.418029, acc.: 82.03%] [G loss: 0.724504]\n",
      "epoch:23 step:21937 [D loss: 0.591199, acc.: 67.97%] [G loss: 0.643746]\n",
      "epoch:23 step:21938 [D loss: 0.499523, acc.: 69.53%] [G loss: 0.811280]\n",
      "epoch:23 step:21939 [D loss: 0.495011, acc.: 75.00%] [G loss: 0.763521]\n",
      "epoch:23 step:21940 [D loss: 0.510020, acc.: 71.09%] [G loss: 0.674744]\n",
      "epoch:23 step:21941 [D loss: 0.583033, acc.: 65.62%] [G loss: 0.540843]\n",
      "epoch:23 step:21942 [D loss: 0.544051, acc.: 66.41%] [G loss: 0.541438]\n",
      "epoch:23 step:21943 [D loss: 0.461608, acc.: 73.44%] [G loss: 0.683572]\n",
      "epoch:23 step:21944 [D loss: 0.641167, acc.: 64.06%] [G loss: 0.580440]\n",
      "epoch:23 step:21945 [D loss: 0.496244, acc.: 77.34%] [G loss: 0.874713]\n",
      "epoch:23 step:21946 [D loss: 0.487467, acc.: 75.78%] [G loss: 0.772998]\n",
      "epoch:23 step:21947 [D loss: 0.579071, acc.: 67.19%] [G loss: 0.614193]\n",
      "epoch:23 step:21948 [D loss: 0.597718, acc.: 64.06%] [G loss: 0.687387]\n",
      "epoch:23 step:21949 [D loss: 0.460469, acc.: 75.78%] [G loss: 0.700631]\n",
      "epoch:23 step:21950 [D loss: 0.514859, acc.: 75.78%] [G loss: 0.791543]\n",
      "epoch:23 step:21951 [D loss: 0.595047, acc.: 67.97%] [G loss: 0.672217]\n",
      "epoch:23 step:21952 [D loss: 0.646160, acc.: 63.28%] [G loss: 0.612265]\n",
      "epoch:23 step:21953 [D loss: 0.448187, acc.: 82.81%] [G loss: 0.687246]\n",
      "epoch:23 step:21954 [D loss: 0.481204, acc.: 74.22%] [G loss: 0.776025]\n",
      "epoch:23 step:21955 [D loss: 0.565369, acc.: 68.75%] [G loss: 0.765314]\n",
      "epoch:23 step:21956 [D loss: 0.512843, acc.: 70.31%] [G loss: 0.725379]\n",
      "epoch:23 step:21957 [D loss: 0.458054, acc.: 78.91%] [G loss: 0.888100]\n",
      "epoch:23 step:21958 [D loss: 0.554437, acc.: 69.53%] [G loss: 0.645861]\n",
      "epoch:23 step:21959 [D loss: 0.546507, acc.: 71.88%] [G loss: 0.726216]\n",
      "epoch:23 step:21960 [D loss: 0.530139, acc.: 71.88%] [G loss: 0.744216]\n",
      "epoch:23 step:21961 [D loss: 0.581187, acc.: 64.06%] [G loss: 0.742694]\n",
      "epoch:23 step:21962 [D loss: 0.583834, acc.: 65.62%] [G loss: 0.629572]\n",
      "epoch:23 step:21963 [D loss: 0.568097, acc.: 64.84%] [G loss: 0.604478]\n",
      "epoch:23 step:21964 [D loss: 0.500531, acc.: 72.66%] [G loss: 0.750162]\n",
      "epoch:23 step:21965 [D loss: 0.499716, acc.: 71.88%] [G loss: 0.828580]\n",
      "epoch:23 step:21966 [D loss: 0.502522, acc.: 73.44%] [G loss: 0.778114]\n",
      "epoch:23 step:21967 [D loss: 0.496333, acc.: 75.78%] [G loss: 0.779006]\n",
      "epoch:23 step:21968 [D loss: 0.495648, acc.: 75.00%] [G loss: 0.869579]\n",
      "epoch:23 step:21969 [D loss: 0.604017, acc.: 64.06%] [G loss: 0.690252]\n",
      "epoch:23 step:21970 [D loss: 0.556489, acc.: 69.53%] [G loss: 0.610695]\n",
      "epoch:23 step:21971 [D loss: 0.549485, acc.: 68.75%] [G loss: 0.706541]\n",
      "epoch:23 step:21972 [D loss: 0.545446, acc.: 70.31%] [G loss: 0.576579]\n",
      "epoch:23 step:21973 [D loss: 0.619212, acc.: 61.72%] [G loss: 0.541066]\n",
      "epoch:23 step:21974 [D loss: 0.523581, acc.: 72.66%] [G loss: 0.679580]\n",
      "epoch:23 step:21975 [D loss: 0.593584, acc.: 64.06%] [G loss: 0.527999]\n",
      "epoch:23 step:21976 [D loss: 0.524868, acc.: 69.53%] [G loss: 0.663551]\n",
      "epoch:23 step:21977 [D loss: 0.478158, acc.: 76.56%] [G loss: 0.774530]\n",
      "epoch:23 step:21978 [D loss: 0.446054, acc.: 75.78%] [G loss: 0.727352]\n",
      "epoch:23 step:21979 [D loss: 0.522733, acc.: 72.66%] [G loss: 0.757542]\n",
      "epoch:23 step:21980 [D loss: 0.435050, acc.: 78.12%] [G loss: 0.959275]\n",
      "epoch:23 step:21981 [D loss: 0.501134, acc.: 70.31%] [G loss: 0.846922]\n",
      "epoch:23 step:21982 [D loss: 0.516939, acc.: 70.31%] [G loss: 0.876285]\n",
      "epoch:23 step:21983 [D loss: 0.567699, acc.: 70.31%] [G loss: 0.732329]\n",
      "epoch:23 step:21984 [D loss: 0.552186, acc.: 67.19%] [G loss: 0.534258]\n",
      "epoch:23 step:21985 [D loss: 0.512549, acc.: 75.78%] [G loss: 0.638501]\n",
      "epoch:23 step:21986 [D loss: 0.516576, acc.: 71.88%] [G loss: 0.691575]\n",
      "epoch:23 step:21987 [D loss: 0.482809, acc.: 77.34%] [G loss: 0.749428]\n",
      "epoch:23 step:21988 [D loss: 0.641324, acc.: 67.97%] [G loss: 0.847350]\n",
      "epoch:23 step:21989 [D loss: 0.572869, acc.: 67.97%] [G loss: 0.547479]\n",
      "epoch:23 step:21990 [D loss: 0.495731, acc.: 70.31%] [G loss: 0.780532]\n",
      "epoch:23 step:21991 [D loss: 0.498736, acc.: 75.78%] [G loss: 0.816013]\n",
      "epoch:23 step:21992 [D loss: 0.529733, acc.: 73.44%] [G loss: 0.809099]\n",
      "epoch:23 step:21993 [D loss: 0.553773, acc.: 64.84%] [G loss: 0.775043]\n",
      "epoch:23 step:21994 [D loss: 0.468103, acc.: 76.56%] [G loss: 0.938009]\n",
      "epoch:23 step:21995 [D loss: 0.460822, acc.: 75.00%] [G loss: 0.893739]\n",
      "epoch:23 step:21996 [D loss: 0.563426, acc.: 67.97%] [G loss: 0.899989]\n",
      "epoch:23 step:21997 [D loss: 0.461562, acc.: 75.78%] [G loss: 0.819537]\n",
      "epoch:23 step:21998 [D loss: 0.522008, acc.: 66.41%] [G loss: 0.840169]\n",
      "epoch:23 step:21999 [D loss: 0.516809, acc.: 73.44%] [G loss: 0.802797]\n",
      "epoch:23 step:22000 [D loss: 0.474886, acc.: 75.78%] [G loss: 0.816685]\n",
      "epoch:23 step:22001 [D loss: 0.537429, acc.: 73.44%] [G loss: 0.805029]\n",
      "epoch:23 step:22002 [D loss: 0.387058, acc.: 81.25%] [G loss: 0.957252]\n",
      "epoch:23 step:22003 [D loss: 0.507904, acc.: 71.88%] [G loss: 0.858614]\n",
      "epoch:23 step:22004 [D loss: 0.535147, acc.: 70.31%] [G loss: 0.997842]\n",
      "epoch:23 step:22005 [D loss: 0.515911, acc.: 71.88%] [G loss: 0.987378]\n",
      "epoch:23 step:22006 [D loss: 0.591018, acc.: 70.31%] [G loss: 0.992322]\n",
      "epoch:23 step:22007 [D loss: 0.565807, acc.: 71.09%] [G loss: 0.747557]\n",
      "epoch:23 step:22008 [D loss: 0.421948, acc.: 81.25%] [G loss: 0.887204]\n",
      "epoch:23 step:22009 [D loss: 0.608153, acc.: 69.53%] [G loss: 0.596650]\n",
      "epoch:23 step:22010 [D loss: 0.519864, acc.: 72.66%] [G loss: 0.634018]\n",
      "epoch:23 step:22011 [D loss: 0.491827, acc.: 72.66%] [G loss: 0.833098]\n",
      "epoch:23 step:22012 [D loss: 0.497559, acc.: 75.00%] [G loss: 0.811944]\n",
      "epoch:23 step:22013 [D loss: 0.556699, acc.: 67.19%] [G loss: 0.646155]\n",
      "epoch:23 step:22014 [D loss: 0.536660, acc.: 67.19%] [G loss: 0.652295]\n",
      "epoch:23 step:22015 [D loss: 0.519980, acc.: 76.56%] [G loss: 0.697002]\n",
      "epoch:23 step:22016 [D loss: 0.657649, acc.: 63.28%] [G loss: 0.821944]\n",
      "epoch:23 step:22017 [D loss: 0.493213, acc.: 70.31%] [G loss: 0.669809]\n",
      "epoch:23 step:22018 [D loss: 0.519843, acc.: 74.22%] [G loss: 0.719277]\n",
      "epoch:23 step:22019 [D loss: 0.554119, acc.: 67.19%] [G loss: 0.997723]\n",
      "epoch:23 step:22020 [D loss: 0.510483, acc.: 75.00%] [G loss: 0.935370]\n",
      "epoch:23 step:22021 [D loss: 0.542508, acc.: 71.88%] [G loss: 0.794743]\n",
      "epoch:23 step:22022 [D loss: 0.448411, acc.: 76.56%] [G loss: 0.815528]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:23 step:22023 [D loss: 0.420859, acc.: 80.47%] [G loss: 0.997459]\n",
      "epoch:23 step:22024 [D loss: 0.669392, acc.: 64.06%] [G loss: 0.704101]\n",
      "epoch:23 step:22025 [D loss: 0.520535, acc.: 70.31%] [G loss: 0.826665]\n",
      "epoch:23 step:22026 [D loss: 0.433604, acc.: 85.16%] [G loss: 0.837363]\n",
      "epoch:23 step:22027 [D loss: 0.492987, acc.: 75.78%] [G loss: 0.889137]\n",
      "epoch:23 step:22028 [D loss: 0.620745, acc.: 67.19%] [G loss: 0.598699]\n",
      "epoch:23 step:22029 [D loss: 0.551971, acc.: 70.31%] [G loss: 0.615499]\n",
      "epoch:23 step:22030 [D loss: 0.546872, acc.: 70.31%] [G loss: 0.586058]\n",
      "epoch:23 step:22031 [D loss: 0.588674, acc.: 67.97%] [G loss: 0.611343]\n",
      "epoch:23 step:22032 [D loss: 0.466958, acc.: 80.47%] [G loss: 0.755178]\n",
      "epoch:23 step:22033 [D loss: 0.588887, acc.: 67.97%] [G loss: 0.768553]\n",
      "epoch:23 step:22034 [D loss: 0.499688, acc.: 73.44%] [G loss: 0.681751]\n",
      "epoch:23 step:22035 [D loss: 0.481702, acc.: 75.00%] [G loss: 0.772142]\n",
      "epoch:23 step:22036 [D loss: 0.506163, acc.: 72.66%] [G loss: 0.821366]\n",
      "epoch:23 step:22037 [D loss: 0.557624, acc.: 67.19%] [G loss: 0.735785]\n",
      "epoch:23 step:22038 [D loss: 0.557154, acc.: 71.09%] [G loss: 0.736082]\n",
      "epoch:23 step:22039 [D loss: 0.483422, acc.: 71.09%] [G loss: 0.860219]\n",
      "epoch:23 step:22040 [D loss: 0.524989, acc.: 71.88%] [G loss: 0.638424]\n",
      "epoch:23 step:22041 [D loss: 0.537894, acc.: 70.31%] [G loss: 0.714756]\n",
      "epoch:23 step:22042 [D loss: 0.552305, acc.: 71.09%] [G loss: 0.674022]\n",
      "epoch:23 step:22043 [D loss: 0.522853, acc.: 75.00%] [G loss: 0.756147]\n",
      "epoch:23 step:22044 [D loss: 0.528822, acc.: 69.53%] [G loss: 0.738300]\n",
      "epoch:23 step:22045 [D loss: 0.579330, acc.: 71.09%] [G loss: 0.585844]\n",
      "epoch:23 step:22046 [D loss: 0.505002, acc.: 76.56%] [G loss: 0.729857]\n",
      "epoch:23 step:22047 [D loss: 0.504924, acc.: 78.12%] [G loss: 0.776525]\n",
      "epoch:23 step:22048 [D loss: 0.524970, acc.: 71.88%] [G loss: 0.892726]\n",
      "epoch:23 step:22049 [D loss: 0.627767, acc.: 63.28%] [G loss: 0.727651]\n",
      "epoch:23 step:22050 [D loss: 0.451015, acc.: 78.91%] [G loss: 0.977556]\n",
      "epoch:23 step:22051 [D loss: 0.599228, acc.: 69.53%] [G loss: 0.838817]\n",
      "epoch:23 step:22052 [D loss: 0.620030, acc.: 64.84%] [G loss: 0.634115]\n",
      "epoch:23 step:22053 [D loss: 0.578240, acc.: 66.41%] [G loss: 0.555225]\n",
      "epoch:23 step:22054 [D loss: 0.463854, acc.: 78.12%] [G loss: 0.638066]\n",
      "epoch:23 step:22055 [D loss: 0.447616, acc.: 75.78%] [G loss: 0.710210]\n",
      "epoch:23 step:22056 [D loss: 0.514412, acc.: 74.22%] [G loss: 0.951903]\n",
      "epoch:23 step:22057 [D loss: 0.477203, acc.: 76.56%] [G loss: 0.808776]\n",
      "epoch:23 step:22058 [D loss: 0.496892, acc.: 75.78%] [G loss: 0.800175]\n",
      "epoch:23 step:22059 [D loss: 0.390647, acc.: 80.47%] [G loss: 0.945446]\n",
      "epoch:23 step:22060 [D loss: 0.470508, acc.: 77.34%] [G loss: 0.818043]\n",
      "epoch:23 step:22061 [D loss: 0.601031, acc.: 64.84%] [G loss: 0.723378]\n",
      "epoch:23 step:22062 [D loss: 0.631968, acc.: 66.41%] [G loss: 0.582123]\n",
      "epoch:23 step:22063 [D loss: 0.533629, acc.: 74.22%] [G loss: 0.653511]\n",
      "epoch:23 step:22064 [D loss: 0.526121, acc.: 73.44%] [G loss: 0.593763]\n",
      "epoch:23 step:22065 [D loss: 0.498060, acc.: 69.53%] [G loss: 0.612603]\n",
      "epoch:23 step:22066 [D loss: 0.527109, acc.: 74.22%] [G loss: 0.589545]\n",
      "epoch:23 step:22067 [D loss: 0.481200, acc.: 74.22%] [G loss: 0.718463]\n",
      "epoch:23 step:22068 [D loss: 0.525182, acc.: 71.88%] [G loss: 0.691457]\n",
      "epoch:23 step:22069 [D loss: 0.482686, acc.: 76.56%] [G loss: 0.745054]\n",
      "epoch:23 step:22070 [D loss: 0.460699, acc.: 79.69%] [G loss: 0.735211]\n",
      "epoch:23 step:22071 [D loss: 0.462743, acc.: 78.91%] [G loss: 0.819012]\n",
      "epoch:23 step:22072 [D loss: 0.460005, acc.: 79.69%] [G loss: 0.845030]\n",
      "epoch:23 step:22073 [D loss: 0.455593, acc.: 81.25%] [G loss: 0.856698]\n",
      "epoch:23 step:22074 [D loss: 0.455026, acc.: 78.91%] [G loss: 0.987479]\n",
      "epoch:23 step:22075 [D loss: 0.543436, acc.: 71.09%] [G loss: 0.813335]\n",
      "epoch:23 step:22076 [D loss: 0.616342, acc.: 64.06%] [G loss: 0.643842]\n",
      "epoch:23 step:22077 [D loss: 0.458205, acc.: 76.56%] [G loss: 0.916173]\n",
      "epoch:23 step:22078 [D loss: 0.582023, acc.: 67.19%] [G loss: 0.630291]\n",
      "epoch:23 step:22079 [D loss: 0.638148, acc.: 62.50%] [G loss: 0.687825]\n",
      "epoch:23 step:22080 [D loss: 0.627048, acc.: 61.72%] [G loss: 0.626663]\n",
      "epoch:23 step:22081 [D loss: 0.537998, acc.: 70.31%] [G loss: 0.744873]\n",
      "epoch:23 step:22082 [D loss: 0.501272, acc.: 75.00%] [G loss: 0.765863]\n",
      "epoch:23 step:22083 [D loss: 0.552979, acc.: 67.19%] [G loss: 0.603093]\n",
      "epoch:23 step:22084 [D loss: 0.524991, acc.: 69.53%] [G loss: 0.568136]\n",
      "epoch:23 step:22085 [D loss: 0.477542, acc.: 78.91%] [G loss: 0.785756]\n",
      "epoch:23 step:22086 [D loss: 0.571993, acc.: 67.19%] [G loss: 0.697691]\n",
      "epoch:23 step:22087 [D loss: 0.491198, acc.: 72.66%] [G loss: 0.687798]\n",
      "epoch:23 step:22088 [D loss: 0.586193, acc.: 69.53%] [G loss: 0.589626]\n",
      "epoch:23 step:22089 [D loss: 0.521239, acc.: 71.09%] [G loss: 0.627646]\n",
      "epoch:23 step:22090 [D loss: 0.533158, acc.: 71.88%] [G loss: 0.479417]\n",
      "epoch:23 step:22091 [D loss: 0.517269, acc.: 70.31%] [G loss: 0.739572]\n",
      "epoch:23 step:22092 [D loss: 0.541965, acc.: 68.75%] [G loss: 0.688786]\n",
      "epoch:23 step:22093 [D loss: 0.607290, acc.: 68.75%] [G loss: 0.478550]\n",
      "epoch:23 step:22094 [D loss: 0.592207, acc.: 63.28%] [G loss: 0.601336]\n",
      "epoch:23 step:22095 [D loss: 0.522026, acc.: 71.88%] [G loss: 0.620556]\n",
      "epoch:23 step:22096 [D loss: 0.509850, acc.: 72.66%] [G loss: 0.627776]\n",
      "epoch:23 step:22097 [D loss: 0.503656, acc.: 75.00%] [G loss: 0.659168]\n",
      "epoch:23 step:22098 [D loss: 0.588638, acc.: 64.84%] [G loss: 0.793006]\n",
      "epoch:23 step:22099 [D loss: 0.433011, acc.: 80.47%] [G loss: 0.802861]\n",
      "epoch:23 step:22100 [D loss: 0.519872, acc.: 77.34%] [G loss: 0.677224]\n",
      "epoch:23 step:22101 [D loss: 0.511650, acc.: 70.31%] [G loss: 0.674869]\n",
      "epoch:23 step:22102 [D loss: 0.474736, acc.: 75.78%] [G loss: 0.722863]\n",
      "epoch:23 step:22103 [D loss: 0.467951, acc.: 75.00%] [G loss: 0.713300]\n",
      "epoch:23 step:22104 [D loss: 0.585829, acc.: 66.41%] [G loss: 0.555406]\n",
      "epoch:23 step:22105 [D loss: 0.417758, acc.: 82.03%] [G loss: 0.678617]\n",
      "epoch:23 step:22106 [D loss: 0.473145, acc.: 79.69%] [G loss: 0.789380]\n",
      "epoch:23 step:22107 [D loss: 0.581430, acc.: 65.62%] [G loss: 0.898876]\n",
      "epoch:23 step:22108 [D loss: 0.533849, acc.: 72.66%] [G loss: 0.779553]\n",
      "epoch:23 step:22109 [D loss: 0.478356, acc.: 75.78%] [G loss: 0.841028]\n",
      "epoch:23 step:22110 [D loss: 0.603010, acc.: 68.75%] [G loss: 0.845189]\n",
      "epoch:23 step:22111 [D loss: 0.527605, acc.: 74.22%] [G loss: 0.821845]\n",
      "epoch:23 step:22112 [D loss: 0.559905, acc.: 67.97%] [G loss: 0.769342]\n",
      "epoch:23 step:22113 [D loss: 0.529267, acc.: 70.31%] [G loss: 0.761909]\n",
      "epoch:23 step:22114 [D loss: 0.524167, acc.: 71.09%] [G loss: 0.821688]\n",
      "epoch:23 step:22115 [D loss: 0.467046, acc.: 79.69%] [G loss: 0.915319]\n",
      "epoch:23 step:22116 [D loss: 0.550015, acc.: 75.78%] [G loss: 0.849932]\n",
      "epoch:23 step:22117 [D loss: 0.745290, acc.: 58.59%] [G loss: 0.666623]\n",
      "epoch:23 step:22118 [D loss: 0.443783, acc.: 78.91%] [G loss: 0.765974]\n",
      "epoch:23 step:22119 [D loss: 0.493376, acc.: 71.88%] [G loss: 0.765541]\n",
      "epoch:23 step:22120 [D loss: 0.569217, acc.: 67.19%] [G loss: 0.678712]\n",
      "epoch:23 step:22121 [D loss: 0.519723, acc.: 70.31%] [G loss: 0.614886]\n",
      "epoch:23 step:22122 [D loss: 0.545498, acc.: 74.22%] [G loss: 0.764374]\n",
      "epoch:23 step:22123 [D loss: 0.525737, acc.: 71.09%] [G loss: 0.703077]\n",
      "epoch:23 step:22124 [D loss: 0.577033, acc.: 64.06%] [G loss: 0.645270]\n",
      "epoch:23 step:22125 [D loss: 0.455830, acc.: 75.00%] [G loss: 0.884125]\n",
      "epoch:23 step:22126 [D loss: 0.455946, acc.: 78.12%] [G loss: 0.941956]\n",
      "epoch:23 step:22127 [D loss: 0.555455, acc.: 71.88%] [G loss: 0.825157]\n",
      "epoch:23 step:22128 [D loss: 0.577021, acc.: 68.75%] [G loss: 0.714182]\n",
      "epoch:23 step:22129 [D loss: 0.625593, acc.: 68.75%] [G loss: 0.742650]\n",
      "epoch:23 step:22130 [D loss: 0.493097, acc.: 72.66%] [G loss: 0.881178]\n",
      "epoch:23 step:22131 [D loss: 0.523414, acc.: 74.22%] [G loss: 0.732652]\n",
      "epoch:23 step:22132 [D loss: 0.517107, acc.: 74.22%] [G loss: 0.715823]\n",
      "epoch:23 step:22133 [D loss: 0.453354, acc.: 80.47%] [G loss: 0.711394]\n",
      "epoch:23 step:22134 [D loss: 0.485665, acc.: 75.78%] [G loss: 0.779386]\n",
      "epoch:23 step:22135 [D loss: 0.583435, acc.: 65.62%] [G loss: 0.624407]\n",
      "epoch:23 step:22136 [D loss: 0.513654, acc.: 71.09%] [G loss: 0.699713]\n",
      "epoch:23 step:22137 [D loss: 0.530927, acc.: 70.31%] [G loss: 0.523505]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:23 step:22138 [D loss: 0.567082, acc.: 66.41%] [G loss: 0.582539]\n",
      "epoch:23 step:22139 [D loss: 0.553690, acc.: 69.53%] [G loss: 0.816727]\n",
      "epoch:23 step:22140 [D loss: 0.505101, acc.: 74.22%] [G loss: 0.636000]\n",
      "epoch:23 step:22141 [D loss: 0.577213, acc.: 71.88%] [G loss: 0.701333]\n",
      "epoch:23 step:22142 [D loss: 0.534537, acc.: 70.31%] [G loss: 0.626293]\n",
      "epoch:23 step:22143 [D loss: 0.464180, acc.: 82.81%] [G loss: 0.746307]\n",
      "epoch:23 step:22144 [D loss: 0.509698, acc.: 75.00%] [G loss: 0.657492]\n",
      "epoch:23 step:22145 [D loss: 0.541014, acc.: 67.97%] [G loss: 0.698385]\n",
      "epoch:23 step:22146 [D loss: 0.591395, acc.: 61.72%] [G loss: 0.563125]\n",
      "epoch:23 step:22147 [D loss: 0.543023, acc.: 70.31%] [G loss: 0.578238]\n",
      "epoch:23 step:22148 [D loss: 0.520670, acc.: 70.31%] [G loss: 0.661423]\n",
      "epoch:23 step:22149 [D loss: 0.547725, acc.: 74.22%] [G loss: 0.625919]\n",
      "epoch:23 step:22150 [D loss: 0.546008, acc.: 71.09%] [G loss: 0.680890]\n",
      "epoch:23 step:22151 [D loss: 0.609761, acc.: 64.06%] [G loss: 0.796519]\n",
      "epoch:23 step:22152 [D loss: 0.463798, acc.: 78.12%] [G loss: 0.675990]\n",
      "epoch:23 step:22153 [D loss: 0.509938, acc.: 71.09%] [G loss: 0.916521]\n",
      "epoch:23 step:22154 [D loss: 0.484140, acc.: 77.34%] [G loss: 0.908587]\n",
      "epoch:23 step:22155 [D loss: 0.534422, acc.: 70.31%] [G loss: 0.826619]\n",
      "epoch:23 step:22156 [D loss: 0.454072, acc.: 77.34%] [G loss: 0.730691]\n",
      "epoch:23 step:22157 [D loss: 0.574126, acc.: 69.53%] [G loss: 0.643013]\n",
      "epoch:23 step:22158 [D loss: 0.502567, acc.: 73.44%] [G loss: 0.761308]\n",
      "epoch:23 step:22159 [D loss: 0.516026, acc.: 70.31%] [G loss: 0.498035]\n",
      "epoch:23 step:22160 [D loss: 0.473852, acc.: 77.34%] [G loss: 0.638908]\n",
      "epoch:23 step:22161 [D loss: 0.597938, acc.: 65.62%] [G loss: 0.465331]\n",
      "epoch:23 step:22162 [D loss: 0.451717, acc.: 79.69%] [G loss: 0.700223]\n",
      "epoch:23 step:22163 [D loss: 0.507007, acc.: 71.88%] [G loss: 0.735319]\n",
      "epoch:23 step:22164 [D loss: 0.493109, acc.: 71.09%] [G loss: 0.560003]\n",
      "epoch:23 step:22165 [D loss: 0.552358, acc.: 68.75%] [G loss: 0.718958]\n",
      "epoch:23 step:22166 [D loss: 0.580210, acc.: 61.72%] [G loss: 0.779819]\n",
      "epoch:23 step:22167 [D loss: 0.533661, acc.: 78.91%] [G loss: 0.729244]\n",
      "epoch:23 step:22168 [D loss: 0.516438, acc.: 72.66%] [G loss: 0.677942]\n",
      "epoch:23 step:22169 [D loss: 0.519486, acc.: 73.44%] [G loss: 0.790513]\n",
      "epoch:23 step:22170 [D loss: 0.524852, acc.: 67.19%] [G loss: 0.735455]\n",
      "epoch:23 step:22171 [D loss: 0.478362, acc.: 75.78%] [G loss: 0.753694]\n",
      "epoch:23 step:22172 [D loss: 0.556095, acc.: 71.88%] [G loss: 0.724171]\n",
      "epoch:23 step:22173 [D loss: 0.604839, acc.: 70.31%] [G loss: 0.671518]\n",
      "epoch:23 step:22174 [D loss: 0.529604, acc.: 71.88%] [G loss: 0.670582]\n",
      "epoch:23 step:22175 [D loss: 0.441628, acc.: 78.91%] [G loss: 0.915872]\n",
      "epoch:23 step:22176 [D loss: 0.574585, acc.: 71.09%] [G loss: 0.711070]\n",
      "epoch:23 step:22177 [D loss: 0.550621, acc.: 67.97%] [G loss: 0.543986]\n",
      "epoch:23 step:22178 [D loss: 0.528096, acc.: 67.19%] [G loss: 0.629867]\n",
      "epoch:23 step:22179 [D loss: 0.546580, acc.: 70.31%] [G loss: 0.479989]\n",
      "epoch:23 step:22180 [D loss: 0.467576, acc.: 75.00%] [G loss: 0.658094]\n",
      "epoch:23 step:22181 [D loss: 0.530324, acc.: 70.31%] [G loss: 0.550808]\n",
      "epoch:23 step:22182 [D loss: 0.418051, acc.: 81.25%] [G loss: 0.905673]\n",
      "epoch:23 step:22183 [D loss: 0.447687, acc.: 80.47%] [G loss: 0.838730]\n",
      "epoch:23 step:22184 [D loss: 0.482866, acc.: 75.78%] [G loss: 0.804328]\n",
      "epoch:23 step:22185 [D loss: 0.428283, acc.: 82.81%] [G loss: 0.993197]\n",
      "epoch:23 step:22186 [D loss: 0.460637, acc.: 75.00%] [G loss: 0.897177]\n",
      "epoch:23 step:22187 [D loss: 0.645340, acc.: 64.84%] [G loss: 0.674553]\n",
      "epoch:23 step:22188 [D loss: 0.526283, acc.: 71.09%] [G loss: 0.700536]\n",
      "epoch:23 step:22189 [D loss: 0.484167, acc.: 75.78%] [G loss: 0.694366]\n",
      "epoch:23 step:22190 [D loss: 0.470258, acc.: 76.56%] [G loss: 0.707532]\n",
      "epoch:23 step:22191 [D loss: 0.540166, acc.: 68.75%] [G loss: 0.805151]\n",
      "epoch:23 step:22192 [D loss: 0.487989, acc.: 73.44%] [G loss: 0.837866]\n",
      "epoch:23 step:22193 [D loss: 0.511330, acc.: 69.53%] [G loss: 1.203416]\n",
      "epoch:23 step:22194 [D loss: 0.500781, acc.: 74.22%] [G loss: 0.965977]\n",
      "epoch:23 step:22195 [D loss: 0.538219, acc.: 70.31%] [G loss: 0.645674]\n",
      "epoch:23 step:22196 [D loss: 0.529846, acc.: 72.66%] [G loss: 0.683145]\n",
      "epoch:23 step:22197 [D loss: 0.528452, acc.: 69.53%] [G loss: 0.660608]\n",
      "epoch:23 step:22198 [D loss: 0.450651, acc.: 81.25%] [G loss: 0.737401]\n",
      "epoch:23 step:22199 [D loss: 0.400627, acc.: 83.59%] [G loss: 0.902667]\n",
      "epoch:23 step:22200 [D loss: 0.476400, acc.: 76.56%] [G loss: 1.027503]\n",
      "epoch:23 step:22201 [D loss: 0.469149, acc.: 80.47%] [G loss: 0.856665]\n",
      "epoch:23 step:22202 [D loss: 0.485385, acc.: 74.22%] [G loss: 0.920254]\n",
      "epoch:23 step:22203 [D loss: 0.569671, acc.: 66.41%] [G loss: 0.680692]\n",
      "epoch:23 step:22204 [D loss: 0.475575, acc.: 80.47%] [G loss: 0.770592]\n",
      "epoch:23 step:22205 [D loss: 0.434822, acc.: 82.03%] [G loss: 0.723975]\n",
      "epoch:23 step:22206 [D loss: 0.538286, acc.: 71.09%] [G loss: 0.622343]\n",
      "epoch:23 step:22207 [D loss: 0.557047, acc.: 70.31%] [G loss: 0.599931]\n",
      "epoch:23 step:22208 [D loss: 0.486579, acc.: 74.22%] [G loss: 0.842563]\n",
      "epoch:23 step:22209 [D loss: 0.577104, acc.: 66.41%] [G loss: 0.893730]\n",
      "epoch:23 step:22210 [D loss: 0.533781, acc.: 72.66%] [G loss: 0.802386]\n",
      "epoch:23 step:22211 [D loss: 0.539773, acc.: 67.97%] [G loss: 1.033376]\n",
      "epoch:23 step:22212 [D loss: 0.476062, acc.: 76.56%] [G loss: 0.861164]\n",
      "epoch:23 step:22213 [D loss: 0.498206, acc.: 75.00%] [G loss: 0.818762]\n",
      "epoch:23 step:22214 [D loss: 0.524449, acc.: 73.44%] [G loss: 0.861193]\n",
      "epoch:23 step:22215 [D loss: 0.518826, acc.: 72.66%] [G loss: 0.742779]\n",
      "epoch:23 step:22216 [D loss: 0.550591, acc.: 72.66%] [G loss: 0.752707]\n",
      "epoch:23 step:22217 [D loss: 0.489606, acc.: 72.66%] [G loss: 0.656968]\n",
      "epoch:23 step:22218 [D loss: 0.525612, acc.: 71.88%] [G loss: 0.911936]\n",
      "epoch:23 step:22219 [D loss: 0.532951, acc.: 71.88%] [G loss: 0.892942]\n",
      "epoch:23 step:22220 [D loss: 0.528100, acc.: 69.53%] [G loss: 0.647764]\n",
      "epoch:23 step:22221 [D loss: 0.549143, acc.: 67.97%] [G loss: 0.658058]\n",
      "epoch:23 step:22222 [D loss: 0.523694, acc.: 72.66%] [G loss: 0.709920]\n",
      "epoch:23 step:22223 [D loss: 0.494899, acc.: 78.12%] [G loss: 0.797994]\n",
      "epoch:23 step:22224 [D loss: 0.635561, acc.: 63.28%] [G loss: 0.733644]\n",
      "epoch:23 step:22225 [D loss: 0.540786, acc.: 71.88%] [G loss: 0.831715]\n",
      "epoch:23 step:22226 [D loss: 0.552890, acc.: 64.84%] [G loss: 0.677473]\n",
      "epoch:23 step:22227 [D loss: 0.540753, acc.: 67.19%] [G loss: 0.880712]\n",
      "epoch:23 step:22228 [D loss: 0.491340, acc.: 75.00%] [G loss: 0.762059]\n",
      "epoch:23 step:22229 [D loss: 0.546432, acc.: 69.53%] [G loss: 0.743503]\n",
      "epoch:23 step:22230 [D loss: 0.496669, acc.: 74.22%] [G loss: 0.740704]\n",
      "epoch:23 step:22231 [D loss: 0.550987, acc.: 75.00%] [G loss: 0.722370]\n",
      "epoch:23 step:22232 [D loss: 0.468110, acc.: 76.56%] [G loss: 0.763403]\n",
      "epoch:23 step:22233 [D loss: 0.525935, acc.: 71.88%] [G loss: 0.754703]\n",
      "epoch:23 step:22234 [D loss: 0.521840, acc.: 76.56%] [G loss: 0.779364]\n",
      "epoch:23 step:22235 [D loss: 0.541811, acc.: 71.88%] [G loss: 0.603121]\n",
      "epoch:23 step:22236 [D loss: 0.557445, acc.: 70.31%] [G loss: 0.547841]\n",
      "epoch:23 step:22237 [D loss: 0.598950, acc.: 62.50%] [G loss: 0.695760]\n",
      "epoch:23 step:22238 [D loss: 0.552603, acc.: 69.53%] [G loss: 0.811510]\n",
      "epoch:23 step:22239 [D loss: 0.539861, acc.: 71.09%] [G loss: 0.696071]\n",
      "epoch:23 step:22240 [D loss: 0.564924, acc.: 63.28%] [G loss: 0.569492]\n",
      "epoch:23 step:22241 [D loss: 0.500269, acc.: 72.66%] [G loss: 0.632217]\n",
      "epoch:23 step:22242 [D loss: 0.435833, acc.: 81.25%] [G loss: 0.730488]\n",
      "epoch:23 step:22243 [D loss: 0.496923, acc.: 78.91%] [G loss: 0.771937]\n",
      "epoch:23 step:22244 [D loss: 0.477962, acc.: 78.91%] [G loss: 0.827433]\n",
      "epoch:23 step:22245 [D loss: 0.473971, acc.: 78.12%] [G loss: 0.739282]\n",
      "epoch:23 step:22246 [D loss: 0.500443, acc.: 75.78%] [G loss: 0.758240]\n",
      "epoch:23 step:22247 [D loss: 0.580531, acc.: 67.19%] [G loss: 0.676051]\n",
      "epoch:23 step:22248 [D loss: 0.584949, acc.: 64.84%] [G loss: 0.570770]\n",
      "epoch:23 step:22249 [D loss: 0.552904, acc.: 68.75%] [G loss: 0.511798]\n",
      "epoch:23 step:22250 [D loss: 0.476529, acc.: 78.12%] [G loss: 0.650669]\n",
      "epoch:23 step:22251 [D loss: 0.552408, acc.: 68.75%] [G loss: 0.633462]\n",
      "epoch:23 step:22252 [D loss: 0.504813, acc.: 75.78%] [G loss: 0.740809]\n",
      "epoch:23 step:22253 [D loss: 0.590881, acc.: 68.75%] [G loss: 0.688329]\n",
      "epoch:23 step:22254 [D loss: 0.582799, acc.: 67.19%] [G loss: 0.673524]\n",
      "epoch:23 step:22255 [D loss: 0.576156, acc.: 64.84%] [G loss: 0.533529]\n",
      "epoch:23 step:22256 [D loss: 0.556638, acc.: 69.53%] [G loss: 0.560391]\n",
      "epoch:23 step:22257 [D loss: 0.539259, acc.: 70.31%] [G loss: 0.749983]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:23 step:22258 [D loss: 0.533780, acc.: 67.19%] [G loss: 0.794010]\n",
      "epoch:23 step:22259 [D loss: 0.495313, acc.: 77.34%] [G loss: 1.084134]\n",
      "epoch:23 step:22260 [D loss: 0.520320, acc.: 72.66%] [G loss: 0.660804]\n",
      "epoch:23 step:22261 [D loss: 0.539970, acc.: 72.66%] [G loss: 0.597653]\n",
      "epoch:23 step:22262 [D loss: 0.572931, acc.: 61.72%] [G loss: 0.522230]\n",
      "epoch:23 step:22263 [D loss: 0.551583, acc.: 66.41%] [G loss: 0.565374]\n",
      "epoch:23 step:22264 [D loss: 0.548651, acc.: 72.66%] [G loss: 0.648165]\n",
      "epoch:23 step:22265 [D loss: 0.519410, acc.: 70.31%] [G loss: 0.691925]\n",
      "epoch:23 step:22266 [D loss: 0.551700, acc.: 64.84%] [G loss: 0.674653]\n",
      "epoch:23 step:22267 [D loss: 0.582770, acc.: 65.62%] [G loss: 0.667207]\n",
      "epoch:23 step:22268 [D loss: 0.547845, acc.: 68.75%] [G loss: 0.667064]\n",
      "epoch:23 step:22269 [D loss: 0.527164, acc.: 68.75%] [G loss: 0.699777]\n",
      "epoch:23 step:22270 [D loss: 0.511654, acc.: 73.44%] [G loss: 0.708764]\n",
      "epoch:23 step:22271 [D loss: 0.590320, acc.: 64.84%] [G loss: 0.700889]\n",
      "epoch:23 step:22272 [D loss: 0.599055, acc.: 67.97%] [G loss: 0.710177]\n",
      "epoch:23 step:22273 [D loss: 0.510718, acc.: 71.88%] [G loss: 0.784333]\n",
      "epoch:23 step:22274 [D loss: 0.568635, acc.: 70.31%] [G loss: 0.579773]\n",
      "epoch:23 step:22275 [D loss: 0.486632, acc.: 72.66%] [G loss: 0.608906]\n",
      "epoch:23 step:22276 [D loss: 0.507336, acc.: 77.34%] [G loss: 0.675140]\n",
      "epoch:23 step:22277 [D loss: 0.499795, acc.: 75.00%] [G loss: 0.707998]\n",
      "epoch:23 step:22278 [D loss: 0.554524, acc.: 71.09%] [G loss: 0.626398]\n",
      "epoch:23 step:22279 [D loss: 0.508072, acc.: 67.19%] [G loss: 0.670909]\n",
      "epoch:23 step:22280 [D loss: 0.552607, acc.: 67.97%] [G loss: 0.687191]\n",
      "epoch:23 step:22281 [D loss: 0.534660, acc.: 73.44%] [G loss: 0.747651]\n",
      "epoch:23 step:22282 [D loss: 0.597757, acc.: 62.50%] [G loss: 0.708809]\n",
      "epoch:23 step:22283 [D loss: 0.487219, acc.: 75.78%] [G loss: 0.800710]\n",
      "epoch:23 step:22284 [D loss: 0.544816, acc.: 67.97%] [G loss: 0.640942]\n",
      "epoch:23 step:22285 [D loss: 0.535814, acc.: 69.53%] [G loss: 0.639958]\n",
      "epoch:23 step:22286 [D loss: 0.558523, acc.: 68.75%] [G loss: 0.574404]\n",
      "epoch:23 step:22287 [D loss: 0.463770, acc.: 77.34%] [G loss: 0.734733]\n",
      "epoch:23 step:22288 [D loss: 0.500001, acc.: 72.66%] [G loss: 0.749822]\n",
      "epoch:23 step:22289 [D loss: 0.533962, acc.: 72.66%] [G loss: 0.719452]\n",
      "epoch:23 step:22290 [D loss: 0.588168, acc.: 65.62%] [G loss: 0.702607]\n",
      "epoch:23 step:22291 [D loss: 0.612381, acc.: 65.62%] [G loss: 0.505286]\n",
      "epoch:23 step:22292 [D loss: 0.553546, acc.: 69.53%] [G loss: 0.538570]\n",
      "epoch:23 step:22293 [D loss: 0.551672, acc.: 72.66%] [G loss: 0.576882]\n",
      "epoch:23 step:22294 [D loss: 0.470754, acc.: 76.56%] [G loss: 0.791857]\n",
      "epoch:23 step:22295 [D loss: 0.520613, acc.: 79.69%] [G loss: 0.770987]\n",
      "epoch:23 step:22296 [D loss: 0.562430, acc.: 64.06%] [G loss: 0.710899]\n",
      "epoch:23 step:22297 [D loss: 0.408293, acc.: 79.69%] [G loss: 0.759915]\n",
      "epoch:23 step:22298 [D loss: 0.406853, acc.: 77.34%] [G loss: 0.771642]\n",
      "epoch:23 step:22299 [D loss: 0.554276, acc.: 68.75%] [G loss: 0.620187]\n",
      "epoch:23 step:22300 [D loss: 0.526073, acc.: 71.88%] [G loss: 0.767533]\n",
      "epoch:23 step:22301 [D loss: 0.476368, acc.: 74.22%] [G loss: 0.750769]\n",
      "epoch:23 step:22302 [D loss: 0.511865, acc.: 74.22%] [G loss: 0.770281]\n",
      "epoch:23 step:22303 [D loss: 0.533693, acc.: 71.09%] [G loss: 0.762983]\n",
      "epoch:23 step:22304 [D loss: 0.477038, acc.: 80.47%] [G loss: 0.629354]\n",
      "epoch:23 step:22305 [D loss: 0.571886, acc.: 68.75%] [G loss: 0.563479]\n",
      "epoch:23 step:22306 [D loss: 0.545557, acc.: 71.09%] [G loss: 0.612823]\n",
      "epoch:23 step:22307 [D loss: 0.587660, acc.: 68.75%] [G loss: 0.677343]\n",
      "epoch:23 step:22308 [D loss: 0.536974, acc.: 68.75%] [G loss: 0.653188]\n",
      "epoch:23 step:22309 [D loss: 0.591022, acc.: 70.31%] [G loss: 0.744907]\n",
      "epoch:23 step:22310 [D loss: 0.503053, acc.: 73.44%] [G loss: 0.751236]\n",
      "epoch:23 step:22311 [D loss: 0.471034, acc.: 77.34%] [G loss: 0.781140]\n",
      "epoch:23 step:22312 [D loss: 0.529702, acc.: 71.88%] [G loss: 0.610385]\n",
      "epoch:23 step:22313 [D loss: 0.564015, acc.: 70.31%] [G loss: 0.555769]\n",
      "epoch:23 step:22314 [D loss: 0.532715, acc.: 69.53%] [G loss: 0.630214]\n",
      "epoch:23 step:22315 [D loss: 0.571989, acc.: 64.84%] [G loss: 0.680994]\n",
      "epoch:23 step:22316 [D loss: 0.583655, acc.: 67.19%] [G loss: 0.625147]\n",
      "epoch:23 step:22317 [D loss: 0.623837, acc.: 63.28%] [G loss: 0.520937]\n",
      "epoch:23 step:22318 [D loss: 0.499647, acc.: 75.78%] [G loss: 0.586407]\n",
      "epoch:23 step:22319 [D loss: 0.501798, acc.: 74.22%] [G loss: 0.724755]\n",
      "epoch:23 step:22320 [D loss: 0.481167, acc.: 72.66%] [G loss: 0.953387]\n",
      "epoch:23 step:22321 [D loss: 0.534735, acc.: 71.09%] [G loss: 0.897106]\n",
      "epoch:23 step:22322 [D loss: 0.490313, acc.: 71.09%] [G loss: 0.908127]\n",
      "epoch:23 step:22323 [D loss: 0.575189, acc.: 71.09%] [G loss: 0.730772]\n",
      "epoch:23 step:22324 [D loss: 0.531280, acc.: 71.88%] [G loss: 0.723689]\n",
      "epoch:23 step:22325 [D loss: 0.549007, acc.: 72.66%] [G loss: 0.725096]\n",
      "epoch:23 step:22326 [D loss: 0.494475, acc.: 75.00%] [G loss: 0.815792]\n",
      "epoch:23 step:22327 [D loss: 0.552438, acc.: 67.97%] [G loss: 0.743888]\n",
      "epoch:23 step:22328 [D loss: 0.572473, acc.: 68.75%] [G loss: 0.710580]\n",
      "epoch:23 step:22329 [D loss: 0.546644, acc.: 68.75%] [G loss: 0.726133]\n",
      "epoch:23 step:22330 [D loss: 0.471445, acc.: 77.34%] [G loss: 0.731850]\n",
      "epoch:23 step:22331 [D loss: 0.435769, acc.: 82.03%] [G loss: 0.685265]\n",
      "epoch:23 step:22332 [D loss: 0.508329, acc.: 67.19%] [G loss: 0.931108]\n",
      "epoch:23 step:22333 [D loss: 0.482033, acc.: 80.47%] [G loss: 1.042045]\n",
      "epoch:23 step:22334 [D loss: 0.504678, acc.: 71.88%] [G loss: 1.111925]\n",
      "epoch:23 step:22335 [D loss: 0.640471, acc.: 66.41%] [G loss: 0.758544]\n",
      "epoch:23 step:22336 [D loss: 0.531921, acc.: 74.22%] [G loss: 0.725163]\n",
      "epoch:23 step:22337 [D loss: 0.504893, acc.: 74.22%] [G loss: 0.595830]\n",
      "epoch:23 step:22338 [D loss: 0.596853, acc.: 72.66%] [G loss: 0.630674]\n",
      "epoch:23 step:22339 [D loss: 0.639811, acc.: 63.28%] [G loss: 0.469115]\n",
      "epoch:23 step:22340 [D loss: 0.509683, acc.: 72.66%] [G loss: 0.649891]\n",
      "epoch:23 step:22341 [D loss: 0.529556, acc.: 67.19%] [G loss: 0.674246]\n",
      "epoch:23 step:22342 [D loss: 0.536226, acc.: 71.88%] [G loss: 0.833041]\n",
      "epoch:23 step:22343 [D loss: 0.511384, acc.: 70.31%] [G loss: 0.853541]\n",
      "epoch:23 step:22344 [D loss: 0.559015, acc.: 71.09%] [G loss: 0.915663]\n",
      "epoch:23 step:22345 [D loss: 0.580222, acc.: 64.06%] [G loss: 0.672313]\n",
      "epoch:23 step:22346 [D loss: 0.525898, acc.: 67.19%] [G loss: 0.745500]\n",
      "epoch:23 step:22347 [D loss: 0.490628, acc.: 74.22%] [G loss: 0.898854]\n",
      "epoch:23 step:22348 [D loss: 0.547659, acc.: 71.09%] [G loss: 0.646084]\n",
      "epoch:23 step:22349 [D loss: 0.545272, acc.: 64.84%] [G loss: 0.585136]\n",
      "epoch:23 step:22350 [D loss: 0.526722, acc.: 76.56%] [G loss: 0.699703]\n",
      "epoch:23 step:22351 [D loss: 0.568171, acc.: 71.88%] [G loss: 0.613417]\n",
      "epoch:23 step:22352 [D loss: 0.446363, acc.: 80.47%] [G loss: 0.751558]\n",
      "epoch:23 step:22353 [D loss: 0.464012, acc.: 78.91%] [G loss: 0.874965]\n",
      "epoch:23 step:22354 [D loss: 0.476853, acc.: 75.78%] [G loss: 0.856999]\n",
      "epoch:23 step:22355 [D loss: 0.496433, acc.: 75.00%] [G loss: 0.775989]\n",
      "epoch:23 step:22356 [D loss: 0.512101, acc.: 75.78%] [G loss: 0.687848]\n",
      "epoch:23 step:22357 [D loss: 0.535701, acc.: 73.44%] [G loss: 0.626936]\n",
      "epoch:23 step:22358 [D loss: 0.551866, acc.: 65.62%] [G loss: 0.480824]\n",
      "epoch:23 step:22359 [D loss: 0.483356, acc.: 77.34%] [G loss: 0.696521]\n",
      "epoch:23 step:22360 [D loss: 0.456582, acc.: 82.03%] [G loss: 0.617163]\n",
      "epoch:23 step:22361 [D loss: 0.485365, acc.: 78.12%] [G loss: 0.685246]\n",
      "epoch:23 step:22362 [D loss: 0.548335, acc.: 68.75%] [G loss: 0.517975]\n",
      "epoch:23 step:22363 [D loss: 0.592114, acc.: 67.19%] [G loss: 0.564176]\n",
      "epoch:23 step:22364 [D loss: 0.495813, acc.: 80.47%] [G loss: 0.567512]\n",
      "epoch:23 step:22365 [D loss: 0.422325, acc.: 81.25%] [G loss: 0.766903]\n",
      "epoch:23 step:22366 [D loss: 0.440803, acc.: 82.81%] [G loss: 0.923751]\n",
      "epoch:23 step:22367 [D loss: 0.483204, acc.: 77.34%] [G loss: 0.726242]\n",
      "epoch:23 step:22368 [D loss: 0.570804, acc.: 67.97%] [G loss: 0.830965]\n",
      "epoch:23 step:22369 [D loss: 0.586393, acc.: 70.31%] [G loss: 0.705492]\n",
      "epoch:23 step:22370 [D loss: 0.521364, acc.: 74.22%] [G loss: 0.686263]\n",
      "epoch:23 step:22371 [D loss: 0.636995, acc.: 64.06%] [G loss: 0.479399]\n",
      "epoch:23 step:22372 [D loss: 0.520961, acc.: 71.09%] [G loss: 0.552705]\n",
      "epoch:23 step:22373 [D loss: 0.555616, acc.: 68.75%] [G loss: 0.758316]\n",
      "epoch:23 step:22374 [D loss: 0.450175, acc.: 77.34%] [G loss: 0.787163]\n",
      "epoch:23 step:22375 [D loss: 0.555726, acc.: 68.75%] [G loss: 0.695737]\n",
      "epoch:23 step:22376 [D loss: 0.542972, acc.: 72.66%] [G loss: 0.700703]\n",
      "epoch:23 step:22377 [D loss: 0.476787, acc.: 75.78%] [G loss: 0.784918]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:23 step:22378 [D loss: 0.540934, acc.: 70.31%] [G loss: 0.635526]\n",
      "epoch:23 step:22379 [D loss: 0.629758, acc.: 63.28%] [G loss: 0.536656]\n",
      "epoch:23 step:22380 [D loss: 0.532342, acc.: 70.31%] [G loss: 0.601233]\n",
      "epoch:23 step:22381 [D loss: 0.514048, acc.: 70.31%] [G loss: 0.640844]\n",
      "epoch:23 step:22382 [D loss: 0.557881, acc.: 70.31%] [G loss: 0.762193]\n",
      "epoch:23 step:22383 [D loss: 0.546448, acc.: 71.09%] [G loss: 0.785100]\n",
      "epoch:23 step:22384 [D loss: 0.462452, acc.: 82.03%] [G loss: 0.711377]\n",
      "epoch:23 step:22385 [D loss: 0.507037, acc.: 70.31%] [G loss: 0.650143]\n",
      "epoch:23 step:22386 [D loss: 0.540154, acc.: 72.66%] [G loss: 0.566823]\n",
      "epoch:23 step:22387 [D loss: 0.524382, acc.: 75.78%] [G loss: 0.599651]\n",
      "epoch:23 step:22388 [D loss: 0.536637, acc.: 70.31%] [G loss: 0.572626]\n",
      "epoch:23 step:22389 [D loss: 0.502199, acc.: 74.22%] [G loss: 0.759902]\n",
      "epoch:23 step:22390 [D loss: 0.535305, acc.: 68.75%] [G loss: 0.702458]\n",
      "epoch:23 step:22391 [D loss: 0.573428, acc.: 63.28%] [G loss: 0.566617]\n",
      "epoch:23 step:22392 [D loss: 0.522713, acc.: 71.88%] [G loss: 0.563779]\n",
      "epoch:23 step:22393 [D loss: 0.523245, acc.: 69.53%] [G loss: 0.712844]\n",
      "epoch:23 step:22394 [D loss: 0.489109, acc.: 78.12%] [G loss: 0.766042]\n",
      "epoch:23 step:22395 [D loss: 0.502397, acc.: 74.22%] [G loss: 0.861933]\n",
      "epoch:23 step:22396 [D loss: 0.581445, acc.: 63.28%] [G loss: 0.532317]\n",
      "epoch:23 step:22397 [D loss: 0.558425, acc.: 62.50%] [G loss: 0.777198]\n",
      "epoch:23 step:22398 [D loss: 0.598085, acc.: 64.84%] [G loss: 0.516142]\n",
      "epoch:23 step:22399 [D loss: 0.513505, acc.: 74.22%] [G loss: 0.540661]\n",
      "epoch:23 step:22400 [D loss: 0.496288, acc.: 75.00%] [G loss: 0.836149]\n",
      "epoch:23 step:22401 [D loss: 0.503505, acc.: 71.88%] [G loss: 0.680854]\n",
      "epoch:23 step:22402 [D loss: 0.539551, acc.: 71.88%] [G loss: 0.669473]\n",
      "epoch:23 step:22403 [D loss: 0.508607, acc.: 72.66%] [G loss: 0.636622]\n",
      "epoch:23 step:22404 [D loss: 0.518353, acc.: 71.88%] [G loss: 0.756624]\n",
      "epoch:23 step:22405 [D loss: 0.522120, acc.: 75.78%] [G loss: 0.945311]\n",
      "epoch:23 step:22406 [D loss: 0.558525, acc.: 67.97%] [G loss: 0.782625]\n",
      "epoch:23 step:22407 [D loss: 0.619718, acc.: 67.19%] [G loss: 0.678739]\n",
      "epoch:23 step:22408 [D loss: 0.441501, acc.: 81.25%] [G loss: 0.691134]\n",
      "epoch:23 step:22409 [D loss: 0.655867, acc.: 62.50%] [G loss: 0.651239]\n",
      "epoch:23 step:22410 [D loss: 0.484697, acc.: 78.91%] [G loss: 0.711930]\n",
      "epoch:23 step:22411 [D loss: 0.430803, acc.: 82.81%] [G loss: 0.924029]\n",
      "epoch:23 step:22412 [D loss: 0.647112, acc.: 62.50%] [G loss: 0.656655]\n",
      "epoch:23 step:22413 [D loss: 0.561552, acc.: 69.53%] [G loss: 0.546031]\n",
      "epoch:23 step:22414 [D loss: 0.565521, acc.: 67.19%] [G loss: 0.648583]\n",
      "epoch:23 step:22415 [D loss: 0.512350, acc.: 70.31%] [G loss: 0.710000]\n",
      "epoch:23 step:22416 [D loss: 0.565593, acc.: 72.66%] [G loss: 0.742221]\n",
      "epoch:23 step:22417 [D loss: 0.539850, acc.: 67.97%] [G loss: 0.605668]\n",
      "epoch:23 step:22418 [D loss: 0.646778, acc.: 61.72%] [G loss: 0.486366]\n",
      "epoch:23 step:22419 [D loss: 0.465270, acc.: 78.91%] [G loss: 0.547788]\n",
      "epoch:23 step:22420 [D loss: 0.571952, acc.: 64.06%] [G loss: 0.534664]\n",
      "epoch:23 step:22421 [D loss: 0.433797, acc.: 79.69%] [G loss: 0.740569]\n",
      "epoch:23 step:22422 [D loss: 0.463213, acc.: 77.34%] [G loss: 0.827656]\n",
      "epoch:23 step:22423 [D loss: 0.497285, acc.: 74.22%] [G loss: 0.814888]\n",
      "epoch:23 step:22424 [D loss: 0.570598, acc.: 68.75%] [G loss: 0.535431]\n",
      "epoch:23 step:22425 [D loss: 0.534630, acc.: 71.09%] [G loss: 0.598293]\n",
      "epoch:23 step:22426 [D loss: 0.471848, acc.: 77.34%] [G loss: 0.771358]\n",
      "epoch:23 step:22427 [D loss: 0.539204, acc.: 71.88%] [G loss: 0.557846]\n",
      "epoch:23 step:22428 [D loss: 0.541788, acc.: 72.66%] [G loss: 0.577178]\n",
      "epoch:23 step:22429 [D loss: 0.475682, acc.: 77.34%] [G loss: 0.694584]\n",
      "epoch:23 step:22430 [D loss: 0.526173, acc.: 73.44%] [G loss: 0.687701]\n",
      "epoch:23 step:22431 [D loss: 0.646456, acc.: 56.25%] [G loss: 0.439287]\n",
      "epoch:23 step:22432 [D loss: 0.602487, acc.: 64.06%] [G loss: 0.522187]\n",
      "epoch:23 step:22433 [D loss: 0.591664, acc.: 67.19%] [G loss: 0.503329]\n",
      "epoch:23 step:22434 [D loss: 0.593110, acc.: 67.97%] [G loss: 0.576615]\n",
      "epoch:23 step:22435 [D loss: 0.462084, acc.: 75.78%] [G loss: 0.726722]\n",
      "epoch:23 step:22436 [D loss: 0.523477, acc.: 71.88%] [G loss: 0.690798]\n",
      "epoch:23 step:22437 [D loss: 0.477529, acc.: 75.78%] [G loss: 0.948953]\n",
      "epoch:23 step:22438 [D loss: 0.582757, acc.: 67.97%] [G loss: 0.915969]\n",
      "epoch:23 step:22439 [D loss: 0.607395, acc.: 61.72%] [G loss: 0.759676]\n",
      "epoch:23 step:22440 [D loss: 0.579509, acc.: 64.84%] [G loss: 0.678367]\n",
      "epoch:23 step:22441 [D loss: 0.558623, acc.: 63.28%] [G loss: 0.895016]\n",
      "epoch:23 step:22442 [D loss: 0.598546, acc.: 67.19%] [G loss: 0.582973]\n",
      "epoch:23 step:22443 [D loss: 0.643048, acc.: 60.94%] [G loss: 0.478279]\n",
      "epoch:23 step:22444 [D loss: 0.538980, acc.: 67.97%] [G loss: 0.537332]\n",
      "epoch:23 step:22445 [D loss: 0.486948, acc.: 73.44%] [G loss: 0.736379]\n",
      "epoch:23 step:22446 [D loss: 0.527764, acc.: 73.44%] [G loss: 0.811854]\n",
      "epoch:23 step:22447 [D loss: 0.466496, acc.: 79.69%] [G loss: 0.933391]\n",
      "epoch:23 step:22448 [D loss: 0.486744, acc.: 72.66%] [G loss: 0.899791]\n",
      "epoch:23 step:22449 [D loss: 0.479857, acc.: 77.34%] [G loss: 0.760279]\n",
      "epoch:23 step:22450 [D loss: 0.471499, acc.: 79.69%] [G loss: 0.840054]\n",
      "epoch:23 step:22451 [D loss: 0.456905, acc.: 79.69%] [G loss: 0.894401]\n",
      "epoch:23 step:22452 [D loss: 0.506825, acc.: 70.31%] [G loss: 0.748190]\n",
      "epoch:23 step:22453 [D loss: 0.568096, acc.: 69.53%] [G loss: 0.708255]\n",
      "epoch:23 step:22454 [D loss: 0.518515, acc.: 71.88%] [G loss: 0.535724]\n",
      "epoch:23 step:22455 [D loss: 0.550412, acc.: 68.75%] [G loss: 0.754177]\n",
      "epoch:23 step:22456 [D loss: 0.546304, acc.: 72.66%] [G loss: 0.738359]\n",
      "epoch:23 step:22457 [D loss: 0.487731, acc.: 77.34%] [G loss: 0.884409]\n",
      "epoch:23 step:22458 [D loss: 0.544469, acc.: 70.31%] [G loss: 0.801807]\n",
      "epoch:23 step:22459 [D loss: 0.521445, acc.: 71.88%] [G loss: 0.752128]\n",
      "epoch:23 step:22460 [D loss: 0.515051, acc.: 76.56%] [G loss: 0.677416]\n",
      "epoch:23 step:22461 [D loss: 0.562287, acc.: 67.19%] [G loss: 0.739110]\n",
      "epoch:23 step:22462 [D loss: 0.444982, acc.: 78.91%] [G loss: 0.770241]\n",
      "epoch:23 step:22463 [D loss: 0.487715, acc.: 78.12%] [G loss: 0.827627]\n",
      "epoch:23 step:22464 [D loss: 0.501201, acc.: 78.12%] [G loss: 0.904991]\n",
      "epoch:23 step:22465 [D loss: 0.443640, acc.: 79.69%] [G loss: 1.005037]\n",
      "epoch:23 step:22466 [D loss: 0.690343, acc.: 61.72%] [G loss: 0.687304]\n",
      "epoch:23 step:22467 [D loss: 0.509175, acc.: 75.78%] [G loss: 0.841989]\n",
      "epoch:23 step:22468 [D loss: 0.578451, acc.: 69.53%] [G loss: 0.694955]\n",
      "epoch:23 step:22469 [D loss: 0.456400, acc.: 76.56%] [G loss: 0.782744]\n",
      "epoch:23 step:22470 [D loss: 0.436518, acc.: 81.25%] [G loss: 1.136339]\n",
      "epoch:23 step:22471 [D loss: 0.670647, acc.: 58.59%] [G loss: 0.771503]\n",
      "epoch:23 step:22472 [D loss: 0.474141, acc.: 72.66%] [G loss: 0.772860]\n",
      "epoch:23 step:22473 [D loss: 0.517227, acc.: 70.31%] [G loss: 0.811975]\n",
      "epoch:23 step:22474 [D loss: 0.480811, acc.: 74.22%] [G loss: 0.907424]\n",
      "epoch:23 step:22475 [D loss: 0.433672, acc.: 79.69%] [G loss: 0.888445]\n",
      "epoch:23 step:22476 [D loss: 0.416865, acc.: 79.69%] [G loss: 0.980546]\n",
      "epoch:23 step:22477 [D loss: 0.438816, acc.: 79.69%] [G loss: 1.319426]\n",
      "epoch:23 step:22478 [D loss: 0.457511, acc.: 71.09%] [G loss: 1.315708]\n",
      "epoch:23 step:22479 [D loss: 0.706201, acc.: 64.06%] [G loss: 1.046668]\n",
      "epoch:23 step:22480 [D loss: 0.551045, acc.: 69.53%] [G loss: 1.163947]\n",
      "epoch:23 step:22481 [D loss: 0.432605, acc.: 80.47%] [G loss: 1.006047]\n",
      "epoch:23 step:22482 [D loss: 0.518327, acc.: 72.66%] [G loss: 0.943368]\n",
      "epoch:23 step:22483 [D loss: 0.669589, acc.: 54.69%] [G loss: 0.857072]\n",
      "epoch:23 step:22484 [D loss: 0.512239, acc.: 75.00%] [G loss: 0.867839]\n",
      "epoch:23 step:22485 [D loss: 0.534905, acc.: 70.31%] [G loss: 0.869642]\n",
      "epoch:23 step:22486 [D loss: 0.497965, acc.: 71.09%] [G loss: 0.776757]\n",
      "epoch:23 step:22487 [D loss: 0.397246, acc.: 83.59%] [G loss: 0.901473]\n",
      "epoch:23 step:22488 [D loss: 0.409587, acc.: 85.16%] [G loss: 1.277330]\n",
      "epoch:24 step:22489 [D loss: 0.547150, acc.: 73.44%] [G loss: 1.179404]\n",
      "epoch:24 step:22490 [D loss: 0.515372, acc.: 72.66%] [G loss: 1.132601]\n",
      "epoch:24 step:22491 [D loss: 0.599864, acc.: 66.41%] [G loss: 0.891201]\n",
      "epoch:24 step:22492 [D loss: 0.469241, acc.: 78.91%] [G loss: 0.985340]\n",
      "epoch:24 step:22493 [D loss: 0.550885, acc.: 69.53%] [G loss: 0.762730]\n",
      "epoch:24 step:22494 [D loss: 0.604828, acc.: 70.31%] [G loss: 0.632301]\n",
      "epoch:24 step:22495 [D loss: 0.455603, acc.: 82.03%] [G loss: 0.817798]\n",
      "epoch:24 step:22496 [D loss: 0.505450, acc.: 72.66%] [G loss: 0.607718]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:24 step:22497 [D loss: 0.454951, acc.: 79.69%] [G loss: 0.845559]\n",
      "epoch:24 step:22498 [D loss: 0.509323, acc.: 72.66%] [G loss: 0.798944]\n",
      "epoch:24 step:22499 [D loss: 0.458389, acc.: 75.78%] [G loss: 0.772600]\n",
      "epoch:24 step:22500 [D loss: 0.566266, acc.: 69.53%] [G loss: 0.827028]\n",
      "epoch:24 step:22501 [D loss: 0.561556, acc.: 67.19%] [G loss: 0.715820]\n",
      "epoch:24 step:22502 [D loss: 0.542880, acc.: 76.56%] [G loss: 0.757638]\n",
      "epoch:24 step:22503 [D loss: 0.489447, acc.: 75.78%] [G loss: 0.761930]\n",
      "epoch:24 step:22504 [D loss: 0.470627, acc.: 76.56%] [G loss: 0.776530]\n",
      "epoch:24 step:22505 [D loss: 0.573687, acc.: 65.62%] [G loss: 0.752517]\n",
      "epoch:24 step:22506 [D loss: 0.517312, acc.: 75.00%] [G loss: 0.756631]\n",
      "epoch:24 step:22507 [D loss: 0.515957, acc.: 71.09%] [G loss: 0.698773]\n",
      "epoch:24 step:22508 [D loss: 0.585731, acc.: 65.62%] [G loss: 0.723718]\n",
      "epoch:24 step:22509 [D loss: 0.572826, acc.: 68.75%] [G loss: 0.762025]\n",
      "epoch:24 step:22510 [D loss: 0.426738, acc.: 77.34%] [G loss: 0.808684]\n",
      "epoch:24 step:22511 [D loss: 0.550681, acc.: 67.97%] [G loss: 0.675318]\n",
      "epoch:24 step:22512 [D loss: 0.497484, acc.: 75.78%] [G loss: 0.718983]\n",
      "epoch:24 step:22513 [D loss: 0.563694, acc.: 69.53%] [G loss: 0.551910]\n",
      "epoch:24 step:22514 [D loss: 0.582023, acc.: 66.41%] [G loss: 0.637279]\n",
      "epoch:24 step:22515 [D loss: 0.431733, acc.: 78.12%] [G loss: 0.700485]\n",
      "epoch:24 step:22516 [D loss: 0.559191, acc.: 63.28%] [G loss: 0.858815]\n",
      "epoch:24 step:22517 [D loss: 0.490701, acc.: 73.44%] [G loss: 0.766874]\n",
      "epoch:24 step:22518 [D loss: 0.516956, acc.: 72.66%] [G loss: 0.641925]\n",
      "epoch:24 step:22519 [D loss: 0.642116, acc.: 64.84%] [G loss: 0.660613]\n",
      "epoch:24 step:22520 [D loss: 0.578998, acc.: 65.62%] [G loss: 0.641318]\n",
      "epoch:24 step:22521 [D loss: 0.548957, acc.: 69.53%] [G loss: 0.718360]\n",
      "epoch:24 step:22522 [D loss: 0.535384, acc.: 67.97%] [G loss: 0.699069]\n",
      "epoch:24 step:22523 [D loss: 0.498753, acc.: 75.00%] [G loss: 0.685069]\n",
      "epoch:24 step:22524 [D loss: 0.493160, acc.: 74.22%] [G loss: 0.572794]\n",
      "epoch:24 step:22525 [D loss: 0.493050, acc.: 75.78%] [G loss: 0.738812]\n",
      "epoch:24 step:22526 [D loss: 0.538804, acc.: 71.09%] [G loss: 0.734060]\n",
      "epoch:24 step:22527 [D loss: 0.503035, acc.: 69.53%] [G loss: 0.603913]\n",
      "epoch:24 step:22528 [D loss: 0.449126, acc.: 79.69%] [G loss: 0.768663]\n",
      "epoch:24 step:22529 [D loss: 0.555833, acc.: 68.75%] [G loss: 0.524092]\n",
      "epoch:24 step:22530 [D loss: 0.549536, acc.: 66.41%] [G loss: 0.686073]\n",
      "epoch:24 step:22531 [D loss: 0.544471, acc.: 71.09%] [G loss: 0.487083]\n",
      "epoch:24 step:22532 [D loss: 0.568606, acc.: 68.75%] [G loss: 0.700829]\n",
      "epoch:24 step:22533 [D loss: 0.447571, acc.: 77.34%] [G loss: 0.723629]\n",
      "epoch:24 step:22534 [D loss: 0.433051, acc.: 76.56%] [G loss: 0.701791]\n",
      "epoch:24 step:22535 [D loss: 0.531718, acc.: 69.53%] [G loss: 0.801939]\n",
      "epoch:24 step:22536 [D loss: 0.534408, acc.: 72.66%] [G loss: 0.771567]\n",
      "epoch:24 step:22537 [D loss: 0.487369, acc.: 74.22%] [G loss: 0.675586]\n",
      "epoch:24 step:22538 [D loss: 0.598065, acc.: 67.97%] [G loss: 0.694982]\n",
      "epoch:24 step:22539 [D loss: 0.658803, acc.: 62.50%] [G loss: 0.477319]\n",
      "epoch:24 step:22540 [D loss: 0.597304, acc.: 68.75%] [G loss: 0.556582]\n",
      "epoch:24 step:22541 [D loss: 0.505779, acc.: 74.22%] [G loss: 0.853984]\n",
      "epoch:24 step:22542 [D loss: 0.447913, acc.: 79.69%] [G loss: 0.804824]\n",
      "epoch:24 step:22543 [D loss: 0.507342, acc.: 77.34%] [G loss: 0.896792]\n",
      "epoch:24 step:22544 [D loss: 0.506842, acc.: 72.66%] [G loss: 0.913675]\n",
      "epoch:24 step:22545 [D loss: 0.475742, acc.: 74.22%] [G loss: 0.795112]\n",
      "epoch:24 step:22546 [D loss: 0.573017, acc.: 68.75%] [G loss: 0.723490]\n",
      "epoch:24 step:22547 [D loss: 0.463328, acc.: 78.12%] [G loss: 0.741578]\n",
      "epoch:24 step:22548 [D loss: 0.609337, acc.: 63.28%] [G loss: 0.711732]\n",
      "epoch:24 step:22549 [D loss: 0.569097, acc.: 67.19%] [G loss: 0.693236]\n",
      "epoch:24 step:22550 [D loss: 0.544857, acc.: 73.44%] [G loss: 0.597159]\n",
      "epoch:24 step:22551 [D loss: 0.505556, acc.: 75.00%] [G loss: 0.731093]\n",
      "epoch:24 step:22552 [D loss: 0.576557, acc.: 71.88%] [G loss: 0.662058]\n",
      "epoch:24 step:22553 [D loss: 0.570254, acc.: 71.88%] [G loss: 0.618589]\n",
      "epoch:24 step:22554 [D loss: 0.541530, acc.: 67.97%] [G loss: 0.697403]\n",
      "epoch:24 step:22555 [D loss: 0.517262, acc.: 71.09%] [G loss: 0.521810]\n",
      "epoch:24 step:22556 [D loss: 0.550103, acc.: 67.97%] [G loss: 0.505456]\n",
      "epoch:24 step:22557 [D loss: 0.458642, acc.: 81.25%] [G loss: 0.669895]\n",
      "epoch:24 step:22558 [D loss: 0.506954, acc.: 77.34%] [G loss: 0.752780]\n",
      "epoch:24 step:22559 [D loss: 0.497307, acc.: 75.00%] [G loss: 0.745437]\n",
      "epoch:24 step:22560 [D loss: 0.479191, acc.: 73.44%] [G loss: 0.637334]\n",
      "epoch:24 step:22561 [D loss: 0.529412, acc.: 69.53%] [G loss: 0.527111]\n",
      "epoch:24 step:22562 [D loss: 0.540664, acc.: 71.88%] [G loss: 0.728632]\n",
      "epoch:24 step:22563 [D loss: 0.546339, acc.: 67.19%] [G loss: 0.814085]\n",
      "epoch:24 step:22564 [D loss: 0.463974, acc.: 78.91%] [G loss: 0.696778]\n",
      "epoch:24 step:22565 [D loss: 0.440666, acc.: 79.69%] [G loss: 0.811385]\n",
      "epoch:24 step:22566 [D loss: 0.589319, acc.: 67.19%] [G loss: 0.708263]\n",
      "epoch:24 step:22567 [D loss: 0.545393, acc.: 74.22%] [G loss: 0.711400]\n",
      "epoch:24 step:22568 [D loss: 0.499155, acc.: 72.66%] [G loss: 0.725002]\n",
      "epoch:24 step:22569 [D loss: 0.538541, acc.: 72.66%] [G loss: 0.587782]\n",
      "epoch:24 step:22570 [D loss: 0.478558, acc.: 76.56%] [G loss: 0.692295]\n",
      "epoch:24 step:22571 [D loss: 0.471308, acc.: 79.69%] [G loss: 0.822453]\n",
      "epoch:24 step:22572 [D loss: 0.564328, acc.: 71.09%] [G loss: 0.793129]\n",
      "epoch:24 step:22573 [D loss: 0.555469, acc.: 68.75%] [G loss: 0.626812]\n",
      "epoch:24 step:22574 [D loss: 0.538420, acc.: 74.22%] [G loss: 0.730636]\n",
      "epoch:24 step:22575 [D loss: 0.505058, acc.: 76.56%] [G loss: 0.715825]\n",
      "epoch:24 step:22576 [D loss: 0.515978, acc.: 71.09%] [G loss: 1.035988]\n",
      "epoch:24 step:22577 [D loss: 0.528036, acc.: 67.19%] [G loss: 0.840693]\n",
      "epoch:24 step:22578 [D loss: 0.497072, acc.: 73.44%] [G loss: 0.866081]\n",
      "epoch:24 step:22579 [D loss: 0.578700, acc.: 71.09%] [G loss: 0.752738]\n",
      "epoch:24 step:22580 [D loss: 0.445269, acc.: 78.91%] [G loss: 0.967126]\n",
      "epoch:24 step:22581 [D loss: 0.503248, acc.: 75.78%] [G loss: 0.975960]\n",
      "epoch:24 step:22582 [D loss: 0.471742, acc.: 75.78%] [G loss: 0.763505]\n",
      "epoch:24 step:22583 [D loss: 0.528440, acc.: 72.66%] [G loss: 0.868023]\n",
      "epoch:24 step:22584 [D loss: 0.502532, acc.: 73.44%] [G loss: 0.836101]\n",
      "epoch:24 step:22585 [D loss: 0.521560, acc.: 71.88%] [G loss: 0.898969]\n",
      "epoch:24 step:22586 [D loss: 0.516818, acc.: 75.00%] [G loss: 0.842330]\n",
      "epoch:24 step:22587 [D loss: 0.596064, acc.: 65.62%] [G loss: 0.693968]\n",
      "epoch:24 step:22588 [D loss: 0.481012, acc.: 73.44%] [G loss: 0.812548]\n",
      "epoch:24 step:22589 [D loss: 0.518543, acc.: 73.44%] [G loss: 0.945743]\n",
      "epoch:24 step:22590 [D loss: 0.622870, acc.: 64.84%] [G loss: 0.616129]\n",
      "epoch:24 step:22591 [D loss: 0.523150, acc.: 70.31%] [G loss: 0.610916]\n",
      "epoch:24 step:22592 [D loss: 0.509064, acc.: 74.22%] [G loss: 0.659924]\n",
      "epoch:24 step:22593 [D loss: 0.591097, acc.: 64.06%] [G loss: 0.660732]\n",
      "epoch:24 step:22594 [D loss: 0.503072, acc.: 77.34%] [G loss: 0.653559]\n",
      "epoch:24 step:22595 [D loss: 0.514709, acc.: 75.00%] [G loss: 0.678500]\n",
      "epoch:24 step:22596 [D loss: 0.589652, acc.: 66.41%] [G loss: 0.717685]\n",
      "epoch:24 step:22597 [D loss: 0.517223, acc.: 72.66%] [G loss: 0.801971]\n",
      "epoch:24 step:22598 [D loss: 0.594401, acc.: 64.06%] [G loss: 0.665737]\n",
      "epoch:24 step:22599 [D loss: 0.551980, acc.: 67.97%] [G loss: 0.665925]\n",
      "epoch:24 step:22600 [D loss: 0.542842, acc.: 75.00%] [G loss: 0.587443]\n",
      "epoch:24 step:22601 [D loss: 0.480324, acc.: 76.56%] [G loss: 0.736799]\n",
      "epoch:24 step:22602 [D loss: 0.534025, acc.: 74.22%] [G loss: 0.812372]\n",
      "epoch:24 step:22603 [D loss: 0.501889, acc.: 77.34%] [G loss: 0.738200]\n",
      "epoch:24 step:22604 [D loss: 0.466076, acc.: 77.34%] [G loss: 0.771680]\n",
      "epoch:24 step:22605 [D loss: 0.517638, acc.: 71.88%] [G loss: 0.905719]\n",
      "epoch:24 step:22606 [D loss: 0.506801, acc.: 71.88%] [G loss: 0.867867]\n",
      "epoch:24 step:22607 [D loss: 0.453602, acc.: 81.25%] [G loss: 1.107652]\n",
      "epoch:24 step:22608 [D loss: 0.561699, acc.: 69.53%] [G loss: 0.860048]\n",
      "epoch:24 step:22609 [D loss: 0.498502, acc.: 74.22%] [G loss: 0.828784]\n",
      "epoch:24 step:22610 [D loss: 0.523048, acc.: 75.00%] [G loss: 0.799138]\n",
      "epoch:24 step:22611 [D loss: 0.481048, acc.: 76.56%] [G loss: 0.924345]\n",
      "epoch:24 step:22612 [D loss: 0.511746, acc.: 72.66%] [G loss: 0.818502]\n",
      "epoch:24 step:22613 [D loss: 0.542569, acc.: 70.31%] [G loss: 0.648538]\n",
      "epoch:24 step:22614 [D loss: 0.454934, acc.: 81.25%] [G loss: 0.856837]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:24 step:22615 [D loss: 0.471498, acc.: 75.00%] [G loss: 0.823336]\n",
      "epoch:24 step:22616 [D loss: 0.483473, acc.: 73.44%] [G loss: 0.917128]\n",
      "epoch:24 step:22617 [D loss: 0.540273, acc.: 70.31%] [G loss: 0.580995]\n",
      "epoch:24 step:22618 [D loss: 0.524648, acc.: 70.31%] [G loss: 0.857428]\n",
      "epoch:24 step:22619 [D loss: 0.505076, acc.: 74.22%] [G loss: 0.876768]\n",
      "epoch:24 step:22620 [D loss: 0.548868, acc.: 67.19%] [G loss: 0.741509]\n",
      "epoch:24 step:22621 [D loss: 0.607682, acc.: 66.41%] [G loss: 0.819610]\n",
      "epoch:24 step:22622 [D loss: 0.495959, acc.: 73.44%] [G loss: 0.569319]\n",
      "epoch:24 step:22623 [D loss: 0.524381, acc.: 75.78%] [G loss: 0.772869]\n",
      "epoch:24 step:22624 [D loss: 0.458286, acc.: 79.69%] [G loss: 0.754854]\n",
      "epoch:24 step:22625 [D loss: 0.565155, acc.: 71.09%] [G loss: 0.804541]\n",
      "epoch:24 step:22626 [D loss: 0.527060, acc.: 72.66%] [G loss: 0.604242]\n",
      "epoch:24 step:22627 [D loss: 0.552284, acc.: 70.31%] [G loss: 0.673038]\n",
      "epoch:24 step:22628 [D loss: 0.575277, acc.: 67.19%] [G loss: 0.627907]\n",
      "epoch:24 step:22629 [D loss: 0.514900, acc.: 69.53%] [G loss: 0.612059]\n",
      "epoch:24 step:22630 [D loss: 0.530234, acc.: 67.19%] [G loss: 0.715683]\n",
      "epoch:24 step:22631 [D loss: 0.597557, acc.: 62.50%] [G loss: 0.625742]\n",
      "epoch:24 step:22632 [D loss: 0.493834, acc.: 76.56%] [G loss: 0.607546]\n",
      "epoch:24 step:22633 [D loss: 0.553559, acc.: 70.31%] [G loss: 0.756678]\n",
      "epoch:24 step:22634 [D loss: 0.462149, acc.: 77.34%] [G loss: 0.754168]\n",
      "epoch:24 step:22635 [D loss: 0.614946, acc.: 67.97%] [G loss: 0.723817]\n",
      "epoch:24 step:22636 [D loss: 0.518311, acc.: 71.09%] [G loss: 0.891353]\n",
      "epoch:24 step:22637 [D loss: 0.560974, acc.: 68.75%] [G loss: 0.641856]\n",
      "epoch:24 step:22638 [D loss: 0.584527, acc.: 66.41%] [G loss: 0.493336]\n",
      "epoch:24 step:22639 [D loss: 0.536137, acc.: 66.41%] [G loss: 0.619315]\n",
      "epoch:24 step:22640 [D loss: 0.457628, acc.: 81.25%] [G loss: 0.601213]\n",
      "epoch:24 step:22641 [D loss: 0.618839, acc.: 64.06%] [G loss: 0.641239]\n",
      "epoch:24 step:22642 [D loss: 0.522627, acc.: 72.66%] [G loss: 0.569427]\n",
      "epoch:24 step:22643 [D loss: 0.487611, acc.: 72.66%] [G loss: 0.664440]\n",
      "epoch:24 step:22644 [D loss: 0.495553, acc.: 75.78%] [G loss: 0.714012]\n",
      "epoch:24 step:22645 [D loss: 0.536143, acc.: 71.88%] [G loss: 0.637577]\n",
      "epoch:24 step:22646 [D loss: 0.592421, acc.: 69.53%] [G loss: 0.696063]\n",
      "epoch:24 step:22647 [D loss: 0.440953, acc.: 79.69%] [G loss: 0.782919]\n",
      "epoch:24 step:22648 [D loss: 0.593606, acc.: 67.19%] [G loss: 0.657241]\n",
      "epoch:24 step:22649 [D loss: 0.537476, acc.: 68.75%] [G loss: 0.634101]\n",
      "epoch:24 step:22650 [D loss: 0.493385, acc.: 71.09%] [G loss: 1.009929]\n",
      "epoch:24 step:22651 [D loss: 0.552995, acc.: 67.97%] [G loss: 1.122319]\n",
      "epoch:24 step:22652 [D loss: 0.627806, acc.: 66.41%] [G loss: 0.728548]\n",
      "epoch:24 step:22653 [D loss: 0.473678, acc.: 75.00%] [G loss: 0.642524]\n",
      "epoch:24 step:22654 [D loss: 0.586833, acc.: 65.62%] [G loss: 0.618637]\n",
      "epoch:24 step:22655 [D loss: 0.569485, acc.: 71.88%] [G loss: 0.504986]\n",
      "epoch:24 step:22656 [D loss: 0.495986, acc.: 75.78%] [G loss: 0.696890]\n",
      "epoch:24 step:22657 [D loss: 0.586609, acc.: 69.53%] [G loss: 0.503686]\n",
      "epoch:24 step:22658 [D loss: 0.507002, acc.: 71.88%] [G loss: 0.637769]\n",
      "epoch:24 step:22659 [D loss: 0.508942, acc.: 72.66%] [G loss: 0.672068]\n",
      "epoch:24 step:22660 [D loss: 0.474241, acc.: 76.56%] [G loss: 0.887497]\n",
      "epoch:24 step:22661 [D loss: 0.440880, acc.: 82.03%] [G loss: 0.800114]\n",
      "epoch:24 step:22662 [D loss: 0.637277, acc.: 62.50%] [G loss: 0.761157]\n",
      "epoch:24 step:22663 [D loss: 0.587003, acc.: 63.28%] [G loss: 0.538536]\n",
      "epoch:24 step:22664 [D loss: 0.463558, acc.: 78.12%] [G loss: 0.710595]\n",
      "epoch:24 step:22665 [D loss: 0.557019, acc.: 65.62%] [G loss: 0.634686]\n",
      "epoch:24 step:22666 [D loss: 0.538928, acc.: 68.75%] [G loss: 0.587232]\n",
      "epoch:24 step:22667 [D loss: 0.519945, acc.: 71.09%] [G loss: 0.636669]\n",
      "epoch:24 step:22668 [D loss: 0.641403, acc.: 60.16%] [G loss: 0.479065]\n",
      "epoch:24 step:22669 [D loss: 0.538175, acc.: 69.53%] [G loss: 0.484870]\n",
      "epoch:24 step:22670 [D loss: 0.479259, acc.: 71.88%] [G loss: 0.597650]\n",
      "epoch:24 step:22671 [D loss: 0.506397, acc.: 73.44%] [G loss: 0.742771]\n",
      "epoch:24 step:22672 [D loss: 0.529143, acc.: 71.88%] [G loss: 0.756581]\n",
      "epoch:24 step:22673 [D loss: 0.522255, acc.: 71.09%] [G loss: 0.695218]\n",
      "epoch:24 step:22674 [D loss: 0.543271, acc.: 70.31%] [G loss: 0.787330]\n",
      "epoch:24 step:22675 [D loss: 0.620879, acc.: 63.28%] [G loss: 0.527581]\n",
      "epoch:24 step:22676 [D loss: 0.548822, acc.: 67.19%] [G loss: 0.653894]\n",
      "epoch:24 step:22677 [D loss: 0.566349, acc.: 71.88%] [G loss: 0.673218]\n",
      "epoch:24 step:22678 [D loss: 0.455824, acc.: 77.34%] [G loss: 0.779014]\n",
      "epoch:24 step:22679 [D loss: 0.520006, acc.: 78.12%] [G loss: 0.653194]\n",
      "epoch:24 step:22680 [D loss: 0.531575, acc.: 73.44%] [G loss: 0.792584]\n",
      "epoch:24 step:22681 [D loss: 0.592763, acc.: 67.97%] [G loss: 0.729517]\n",
      "epoch:24 step:22682 [D loss: 0.456533, acc.: 78.91%] [G loss: 0.906685]\n",
      "epoch:24 step:22683 [D loss: 0.586063, acc.: 61.72%] [G loss: 0.814351]\n",
      "epoch:24 step:22684 [D loss: 0.527224, acc.: 71.88%] [G loss: 0.692754]\n",
      "epoch:24 step:22685 [D loss: 0.487853, acc.: 75.78%] [G loss: 0.534700]\n",
      "epoch:24 step:22686 [D loss: 0.490633, acc.: 74.22%] [G loss: 0.716904]\n",
      "epoch:24 step:22687 [D loss: 0.507596, acc.: 75.00%] [G loss: 0.765187]\n",
      "epoch:24 step:22688 [D loss: 0.566125, acc.: 69.53%] [G loss: 0.746900]\n",
      "epoch:24 step:22689 [D loss: 0.536402, acc.: 68.75%] [G loss: 0.658796]\n",
      "epoch:24 step:22690 [D loss: 0.497929, acc.: 71.88%] [G loss: 0.643432]\n",
      "epoch:24 step:22691 [D loss: 0.561368, acc.: 68.75%] [G loss: 0.702697]\n",
      "epoch:24 step:22692 [D loss: 0.548793, acc.: 68.75%] [G loss: 0.634526]\n",
      "epoch:24 step:22693 [D loss: 0.446809, acc.: 78.91%] [G loss: 0.848863]\n",
      "epoch:24 step:22694 [D loss: 0.462852, acc.: 78.91%] [G loss: 0.651994]\n",
      "epoch:24 step:22695 [D loss: 0.430239, acc.: 83.59%] [G loss: 0.860001]\n",
      "epoch:24 step:22696 [D loss: 0.450122, acc.: 78.12%] [G loss: 1.039084]\n",
      "epoch:24 step:22697 [D loss: 0.518767, acc.: 74.22%] [G loss: 1.057440]\n",
      "epoch:24 step:22698 [D loss: 0.668405, acc.: 57.03%] [G loss: 0.625469]\n",
      "epoch:24 step:22699 [D loss: 0.551871, acc.: 72.66%] [G loss: 0.684258]\n",
      "epoch:24 step:22700 [D loss: 0.559755, acc.: 68.75%] [G loss: 0.693829]\n",
      "epoch:24 step:22701 [D loss: 0.467203, acc.: 75.78%] [G loss: 0.711570]\n",
      "epoch:24 step:22702 [D loss: 0.633948, acc.: 66.41%] [G loss: 0.589127]\n",
      "epoch:24 step:22703 [D loss: 0.534465, acc.: 72.66%] [G loss: 0.558663]\n",
      "epoch:24 step:22704 [D loss: 0.520891, acc.: 71.09%] [G loss: 0.590024]\n",
      "epoch:24 step:22705 [D loss: 0.501593, acc.: 77.34%] [G loss: 0.758810]\n",
      "epoch:24 step:22706 [D loss: 0.441110, acc.: 81.25%] [G loss: 0.925982]\n",
      "epoch:24 step:22707 [D loss: 0.452304, acc.: 78.12%] [G loss: 1.034974]\n",
      "epoch:24 step:22708 [D loss: 0.614015, acc.: 71.09%] [G loss: 0.774064]\n",
      "epoch:24 step:22709 [D loss: 0.513346, acc.: 68.75%] [G loss: 0.736244]\n",
      "epoch:24 step:22710 [D loss: 0.484615, acc.: 73.44%] [G loss: 0.682168]\n",
      "epoch:24 step:22711 [D loss: 0.518442, acc.: 73.44%] [G loss: 0.837240]\n",
      "epoch:24 step:22712 [D loss: 0.540469, acc.: 70.31%] [G loss: 0.421226]\n",
      "epoch:24 step:22713 [D loss: 0.490302, acc.: 77.34%] [G loss: 0.710510]\n",
      "epoch:24 step:22714 [D loss: 0.586993, acc.: 60.94%] [G loss: 0.722763]\n",
      "epoch:24 step:22715 [D loss: 0.477887, acc.: 77.34%] [G loss: 0.732126]\n",
      "epoch:24 step:22716 [D loss: 0.600849, acc.: 65.62%] [G loss: 0.671262]\n",
      "epoch:24 step:22717 [D loss: 0.456144, acc.: 78.12%] [G loss: 0.707939]\n",
      "epoch:24 step:22718 [D loss: 0.495057, acc.: 76.56%] [G loss: 0.819296]\n",
      "epoch:24 step:22719 [D loss: 0.492957, acc.: 81.25%] [G loss: 1.132428]\n",
      "epoch:24 step:22720 [D loss: 0.468067, acc.: 77.34%] [G loss: 1.085942]\n",
      "epoch:24 step:22721 [D loss: 0.564921, acc.: 71.88%] [G loss: 0.757757]\n",
      "epoch:24 step:22722 [D loss: 0.573178, acc.: 65.62%] [G loss: 0.772438]\n",
      "epoch:24 step:22723 [D loss: 0.547917, acc.: 71.88%] [G loss: 0.807769]\n",
      "epoch:24 step:22724 [D loss: 0.494543, acc.: 76.56%] [G loss: 0.566459]\n",
      "epoch:24 step:22725 [D loss: 0.569414, acc.: 70.31%] [G loss: 0.648718]\n",
      "epoch:24 step:22726 [D loss: 0.573007, acc.: 64.06%] [G loss: 0.600418]\n",
      "epoch:24 step:22727 [D loss: 0.532132, acc.: 69.53%] [G loss: 0.643539]\n",
      "epoch:24 step:22728 [D loss: 0.545186, acc.: 67.97%] [G loss: 0.606625]\n",
      "epoch:24 step:22729 [D loss: 0.505679, acc.: 72.66%] [G loss: 0.493687]\n",
      "epoch:24 step:22730 [D loss: 0.492694, acc.: 74.22%] [G loss: 0.701376]\n",
      "epoch:24 step:22731 [D loss: 0.492959, acc.: 71.09%] [G loss: 0.929621]\n",
      "epoch:24 step:22732 [D loss: 0.501473, acc.: 70.31%] [G loss: 0.806020]\n",
      "epoch:24 step:22733 [D loss: 0.513813, acc.: 75.00%] [G loss: 0.723492]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:24 step:22734 [D loss: 0.526014, acc.: 67.97%] [G loss: 0.769163]\n",
      "epoch:24 step:22735 [D loss: 0.493425, acc.: 73.44%] [G loss: 0.832351]\n",
      "epoch:24 step:22736 [D loss: 0.471766, acc.: 76.56%] [G loss: 0.741125]\n",
      "epoch:24 step:22737 [D loss: 0.580467, acc.: 66.41%] [G loss: 0.934531]\n",
      "epoch:24 step:22738 [D loss: 0.533424, acc.: 70.31%] [G loss: 0.917173]\n",
      "epoch:24 step:22739 [D loss: 0.577359, acc.: 69.53%] [G loss: 0.610367]\n",
      "epoch:24 step:22740 [D loss: 0.527072, acc.: 71.88%] [G loss: 0.683854]\n",
      "epoch:24 step:22741 [D loss: 0.586952, acc.: 66.41%] [G loss: 0.729919]\n",
      "epoch:24 step:22742 [D loss: 0.496585, acc.: 75.78%] [G loss: 0.725311]\n",
      "epoch:24 step:22743 [D loss: 0.515358, acc.: 71.09%] [G loss: 0.815518]\n",
      "epoch:24 step:22744 [D loss: 0.591507, acc.: 66.41%] [G loss: 0.684211]\n",
      "epoch:24 step:22745 [D loss: 0.585132, acc.: 65.62%] [G loss: 0.706719]\n",
      "epoch:24 step:22746 [D loss: 0.480619, acc.: 74.22%] [G loss: 0.691575]\n",
      "epoch:24 step:22747 [D loss: 0.521793, acc.: 71.88%] [G loss: 0.779819]\n",
      "epoch:24 step:22748 [D loss: 0.591487, acc.: 64.06%] [G loss: 0.674046]\n",
      "epoch:24 step:22749 [D loss: 0.545972, acc.: 73.44%] [G loss: 0.652539]\n",
      "epoch:24 step:22750 [D loss: 0.506956, acc.: 75.00%] [G loss: 0.628980]\n",
      "epoch:24 step:22751 [D loss: 0.542133, acc.: 68.75%] [G loss: 0.670509]\n",
      "epoch:24 step:22752 [D loss: 0.531066, acc.: 73.44%] [G loss: 0.712427]\n",
      "epoch:24 step:22753 [D loss: 0.474326, acc.: 78.12%] [G loss: 0.735960]\n",
      "epoch:24 step:22754 [D loss: 0.576040, acc.: 69.53%] [G loss: 0.806872]\n",
      "epoch:24 step:22755 [D loss: 0.496769, acc.: 70.31%] [G loss: 0.691151]\n",
      "epoch:24 step:22756 [D loss: 0.515926, acc.: 71.09%] [G loss: 0.789193]\n",
      "epoch:24 step:22757 [D loss: 0.586238, acc.: 67.97%] [G loss: 0.693095]\n",
      "epoch:24 step:22758 [D loss: 0.468643, acc.: 78.12%] [G loss: 0.722541]\n",
      "epoch:24 step:22759 [D loss: 0.524525, acc.: 74.22%] [G loss: 0.826635]\n",
      "epoch:24 step:22760 [D loss: 0.515332, acc.: 73.44%] [G loss: 0.728919]\n",
      "epoch:24 step:22761 [D loss: 0.522856, acc.: 75.00%] [G loss: 0.723949]\n",
      "epoch:24 step:22762 [D loss: 0.522275, acc.: 75.78%] [G loss: 0.734929]\n",
      "epoch:24 step:22763 [D loss: 0.548450, acc.: 70.31%] [G loss: 0.723961]\n",
      "epoch:24 step:22764 [D loss: 0.452473, acc.: 83.59%] [G loss: 0.814263]\n",
      "epoch:24 step:22765 [D loss: 0.664563, acc.: 60.94%] [G loss: 0.692402]\n",
      "epoch:24 step:22766 [D loss: 0.596904, acc.: 67.97%] [G loss: 0.566524]\n",
      "epoch:24 step:22767 [D loss: 0.518006, acc.: 71.88%] [G loss: 0.652305]\n",
      "epoch:24 step:22768 [D loss: 0.533665, acc.: 71.09%] [G loss: 0.614997]\n",
      "epoch:24 step:22769 [D loss: 0.583430, acc.: 71.09%] [G loss: 0.594612]\n",
      "epoch:24 step:22770 [D loss: 0.498076, acc.: 75.00%] [G loss: 0.678541]\n",
      "epoch:24 step:22771 [D loss: 0.570109, acc.: 67.97%] [G loss: 0.583193]\n",
      "epoch:24 step:22772 [D loss: 0.508621, acc.: 71.88%] [G loss: 0.852629]\n",
      "epoch:24 step:22773 [D loss: 0.492109, acc.: 71.09%] [G loss: 0.821674]\n",
      "epoch:24 step:22774 [D loss: 0.507559, acc.: 71.09%] [G loss: 0.896784]\n",
      "epoch:24 step:22775 [D loss: 0.602964, acc.: 63.28%] [G loss: 0.605456]\n",
      "epoch:24 step:22776 [D loss: 0.545028, acc.: 68.75%] [G loss: 0.698797]\n",
      "epoch:24 step:22777 [D loss: 0.476317, acc.: 76.56%] [G loss: 0.854642]\n",
      "epoch:24 step:22778 [D loss: 0.551927, acc.: 72.66%] [G loss: 0.746113]\n",
      "epoch:24 step:22779 [D loss: 0.556703, acc.: 74.22%] [G loss: 0.835730]\n",
      "epoch:24 step:22780 [D loss: 0.514847, acc.: 75.78%] [G loss: 0.667059]\n",
      "epoch:24 step:22781 [D loss: 0.566046, acc.: 70.31%] [G loss: 0.608608]\n",
      "epoch:24 step:22782 [D loss: 0.565564, acc.: 68.75%] [G loss: 0.515869]\n",
      "epoch:24 step:22783 [D loss: 0.522183, acc.: 69.53%] [G loss: 0.654224]\n",
      "epoch:24 step:22784 [D loss: 0.496235, acc.: 73.44%] [G loss: 0.617241]\n",
      "epoch:24 step:22785 [D loss: 0.524253, acc.: 65.62%] [G loss: 0.813714]\n",
      "epoch:24 step:22786 [D loss: 0.471039, acc.: 75.00%] [G loss: 0.816753]\n",
      "epoch:24 step:22787 [D loss: 0.468120, acc.: 75.78%] [G loss: 0.731001]\n",
      "epoch:24 step:22788 [D loss: 0.520610, acc.: 71.88%] [G loss: 0.824189]\n",
      "epoch:24 step:22789 [D loss: 0.589085, acc.: 66.41%] [G loss: 0.876207]\n",
      "epoch:24 step:22790 [D loss: 0.534606, acc.: 69.53%] [G loss: 0.652244]\n",
      "epoch:24 step:22791 [D loss: 0.542047, acc.: 71.09%] [G loss: 0.673716]\n",
      "epoch:24 step:22792 [D loss: 0.559343, acc.: 73.44%] [G loss: 0.739966]\n",
      "epoch:24 step:22793 [D loss: 0.507060, acc.: 71.88%] [G loss: 0.589529]\n",
      "epoch:24 step:22794 [D loss: 0.518880, acc.: 70.31%] [G loss: 0.642398]\n",
      "epoch:24 step:22795 [D loss: 0.522681, acc.: 73.44%] [G loss: 0.607336]\n",
      "epoch:24 step:22796 [D loss: 0.548398, acc.: 67.97%] [G loss: 0.669170]\n",
      "epoch:24 step:22797 [D loss: 0.510522, acc.: 74.22%] [G loss: 0.684504]\n",
      "epoch:24 step:22798 [D loss: 0.526799, acc.: 72.66%] [G loss: 0.696996]\n",
      "epoch:24 step:22799 [D loss: 0.426149, acc.: 78.91%] [G loss: 0.886233]\n",
      "epoch:24 step:22800 [D loss: 0.443132, acc.: 82.03%] [G loss: 0.821008]\n",
      "epoch:24 step:22801 [D loss: 0.455382, acc.: 77.34%] [G loss: 0.992213]\n",
      "epoch:24 step:22802 [D loss: 0.466441, acc.: 75.00%] [G loss: 1.109845]\n",
      "epoch:24 step:22803 [D loss: 0.409450, acc.: 82.81%] [G loss: 1.066585]\n",
      "epoch:24 step:22804 [D loss: 0.585956, acc.: 69.53%] [G loss: 0.710828]\n",
      "epoch:24 step:22805 [D loss: 0.659591, acc.: 61.72%] [G loss: 0.550842]\n",
      "epoch:24 step:22806 [D loss: 0.524756, acc.: 68.75%] [G loss: 0.782691]\n",
      "epoch:24 step:22807 [D loss: 0.519453, acc.: 74.22%] [G loss: 0.700516]\n",
      "epoch:24 step:22808 [D loss: 0.580242, acc.: 65.62%] [G loss: 0.601348]\n",
      "epoch:24 step:22809 [D loss: 0.463571, acc.: 75.00%] [G loss: 0.799024]\n",
      "epoch:24 step:22810 [D loss: 0.571023, acc.: 75.00%] [G loss: 0.776745]\n",
      "epoch:24 step:22811 [D loss: 0.656729, acc.: 64.06%] [G loss: 0.543817]\n",
      "epoch:24 step:22812 [D loss: 0.592630, acc.: 64.84%] [G loss: 0.423283]\n",
      "epoch:24 step:22813 [D loss: 0.547991, acc.: 69.53%] [G loss: 0.655752]\n",
      "epoch:24 step:22814 [D loss: 0.455387, acc.: 74.22%] [G loss: 0.891675]\n",
      "epoch:24 step:22815 [D loss: 0.525146, acc.: 74.22%] [G loss: 0.691853]\n",
      "epoch:24 step:22816 [D loss: 0.472825, acc.: 74.22%] [G loss: 0.735026]\n",
      "epoch:24 step:22817 [D loss: 0.495809, acc.: 75.00%] [G loss: 0.686168]\n",
      "epoch:24 step:22818 [D loss: 0.520426, acc.: 73.44%] [G loss: 0.696793]\n",
      "epoch:24 step:22819 [D loss: 0.543559, acc.: 68.75%] [G loss: 0.701703]\n",
      "epoch:24 step:22820 [D loss: 0.509012, acc.: 71.88%] [G loss: 0.807578]\n",
      "epoch:24 step:22821 [D loss: 0.493054, acc.: 75.00%] [G loss: 0.683654]\n",
      "epoch:24 step:22822 [D loss: 0.472860, acc.: 75.00%] [G loss: 0.856712]\n",
      "epoch:24 step:22823 [D loss: 0.485213, acc.: 74.22%] [G loss: 0.778267]\n",
      "epoch:24 step:22824 [D loss: 0.496386, acc.: 75.78%] [G loss: 0.852663]\n",
      "epoch:24 step:22825 [D loss: 0.463940, acc.: 77.34%] [G loss: 0.964675]\n",
      "epoch:24 step:22826 [D loss: 0.551684, acc.: 69.53%] [G loss: 0.811734]\n",
      "epoch:24 step:22827 [D loss: 0.561822, acc.: 71.09%] [G loss: 0.777252]\n",
      "epoch:24 step:22828 [D loss: 0.433484, acc.: 81.25%] [G loss: 0.828185]\n",
      "epoch:24 step:22829 [D loss: 0.556416, acc.: 71.88%] [G loss: 0.875799]\n",
      "epoch:24 step:22830 [D loss: 0.600521, acc.: 60.16%] [G loss: 1.006912]\n",
      "epoch:24 step:22831 [D loss: 0.531866, acc.: 72.66%] [G loss: 0.914568]\n",
      "epoch:24 step:22832 [D loss: 0.447384, acc.: 79.69%] [G loss: 1.127670]\n",
      "epoch:24 step:22833 [D loss: 0.561981, acc.: 74.22%] [G loss: 0.877636]\n",
      "epoch:24 step:22834 [D loss: 0.543512, acc.: 73.44%] [G loss: 1.173719]\n",
      "epoch:24 step:22835 [D loss: 0.451036, acc.: 76.56%] [G loss: 1.142091]\n",
      "epoch:24 step:22836 [D loss: 0.602058, acc.: 69.53%] [G loss: 0.783530]\n",
      "epoch:24 step:22837 [D loss: 0.693878, acc.: 56.25%] [G loss: 0.604848]\n",
      "epoch:24 step:22838 [D loss: 0.463060, acc.: 78.12%] [G loss: 0.696383]\n",
      "epoch:24 step:22839 [D loss: 0.474607, acc.: 78.12%] [G loss: 0.702783]\n",
      "epoch:24 step:22840 [D loss: 0.581027, acc.: 68.75%] [G loss: 0.661112]\n",
      "epoch:24 step:22841 [D loss: 0.524318, acc.: 69.53%] [G loss: 0.674005]\n",
      "epoch:24 step:22842 [D loss: 0.405504, acc.: 83.59%] [G loss: 0.788558]\n",
      "epoch:24 step:22843 [D loss: 0.452001, acc.: 76.56%] [G loss: 0.887211]\n",
      "epoch:24 step:22844 [D loss: 0.565415, acc.: 66.41%] [G loss: 0.818649]\n",
      "epoch:24 step:22845 [D loss: 0.420519, acc.: 82.81%] [G loss: 0.834753]\n",
      "epoch:24 step:22846 [D loss: 0.440503, acc.: 77.34%] [G loss: 0.830159]\n",
      "epoch:24 step:22847 [D loss: 0.450991, acc.: 78.91%] [G loss: 0.962693]\n",
      "epoch:24 step:22848 [D loss: 0.521350, acc.: 71.09%] [G loss: 0.963902]\n",
      "epoch:24 step:22849 [D loss: 0.495171, acc.: 72.66%] [G loss: 0.963347]\n",
      "epoch:24 step:22850 [D loss: 0.485288, acc.: 75.78%] [G loss: 0.703079]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:24 step:22851 [D loss: 0.523084, acc.: 69.53%] [G loss: 0.595207]\n",
      "epoch:24 step:22852 [D loss: 0.469272, acc.: 75.78%] [G loss: 0.775927]\n",
      "epoch:24 step:22853 [D loss: 0.531991, acc.: 69.53%] [G loss: 0.825327]\n",
      "epoch:24 step:22854 [D loss: 0.493419, acc.: 77.34%] [G loss: 0.769546]\n",
      "epoch:24 step:22855 [D loss: 0.532842, acc.: 71.09%] [G loss: 0.715468]\n",
      "epoch:24 step:22856 [D loss: 0.525078, acc.: 72.66%] [G loss: 0.721108]\n",
      "epoch:24 step:22857 [D loss: 0.545031, acc.: 68.75%] [G loss: 0.609398]\n",
      "epoch:24 step:22858 [D loss: 0.525142, acc.: 71.88%] [G loss: 0.815981]\n",
      "epoch:24 step:22859 [D loss: 0.447958, acc.: 82.03%] [G loss: 0.819617]\n",
      "epoch:24 step:22860 [D loss: 0.593568, acc.: 66.41%] [G loss: 0.800262]\n",
      "epoch:24 step:22861 [D loss: 0.540984, acc.: 70.31%] [G loss: 0.909061]\n",
      "epoch:24 step:22862 [D loss: 0.450130, acc.: 78.12%] [G loss: 1.061226]\n",
      "epoch:24 step:22863 [D loss: 0.531294, acc.: 74.22%] [G loss: 0.846370]\n",
      "epoch:24 step:22864 [D loss: 0.716562, acc.: 60.16%] [G loss: 0.451566]\n",
      "epoch:24 step:22865 [D loss: 0.560405, acc.: 64.84%] [G loss: 0.536608]\n",
      "epoch:24 step:22866 [D loss: 0.523516, acc.: 73.44%] [G loss: 0.606354]\n",
      "epoch:24 step:22867 [D loss: 0.499933, acc.: 75.00%] [G loss: 0.565322]\n",
      "epoch:24 step:22868 [D loss: 0.568797, acc.: 67.19%] [G loss: 0.725136]\n",
      "epoch:24 step:22869 [D loss: 0.458390, acc.: 77.34%] [G loss: 0.716859]\n",
      "epoch:24 step:22870 [D loss: 0.496848, acc.: 75.00%] [G loss: 0.833689]\n",
      "epoch:24 step:22871 [D loss: 0.564920, acc.: 69.53%] [G loss: 0.723400]\n",
      "epoch:24 step:22872 [D loss: 0.527045, acc.: 70.31%] [G loss: 0.666339]\n",
      "epoch:24 step:22873 [D loss: 0.477128, acc.: 78.91%] [G loss: 0.723716]\n",
      "epoch:24 step:22874 [D loss: 0.618418, acc.: 67.97%] [G loss: 0.734190]\n",
      "epoch:24 step:22875 [D loss: 0.514169, acc.: 71.09%] [G loss: 0.713471]\n",
      "epoch:24 step:22876 [D loss: 0.516051, acc.: 74.22%] [G loss: 0.760559]\n",
      "epoch:24 step:22877 [D loss: 0.527952, acc.: 72.66%] [G loss: 0.618964]\n",
      "epoch:24 step:22878 [D loss: 0.607452, acc.: 60.16%] [G loss: 0.501241]\n",
      "epoch:24 step:22879 [D loss: 0.578286, acc.: 67.19%] [G loss: 0.678717]\n",
      "epoch:24 step:22880 [D loss: 0.458013, acc.: 77.34%] [G loss: 0.690499]\n",
      "epoch:24 step:22881 [D loss: 0.552716, acc.: 70.31%] [G loss: 0.576976]\n",
      "epoch:24 step:22882 [D loss: 0.573473, acc.: 71.09%] [G loss: 0.561444]\n",
      "epoch:24 step:22883 [D loss: 0.507489, acc.: 72.66%] [G loss: 0.698025]\n",
      "epoch:24 step:22884 [D loss: 0.589726, acc.: 67.19%] [G loss: 0.645055]\n",
      "epoch:24 step:22885 [D loss: 0.530484, acc.: 73.44%] [G loss: 0.662769]\n",
      "epoch:24 step:22886 [D loss: 0.472526, acc.: 75.00%] [G loss: 0.631335]\n",
      "epoch:24 step:22887 [D loss: 0.456137, acc.: 79.69%] [G loss: 0.839201]\n",
      "epoch:24 step:22888 [D loss: 0.627459, acc.: 64.84%] [G loss: 0.682434]\n",
      "epoch:24 step:22889 [D loss: 0.584874, acc.: 67.19%] [G loss: 0.461791]\n",
      "epoch:24 step:22890 [D loss: 0.459823, acc.: 73.44%] [G loss: 0.612022]\n",
      "epoch:24 step:22891 [D loss: 0.464323, acc.: 76.56%] [G loss: 0.748013]\n",
      "epoch:24 step:22892 [D loss: 0.611740, acc.: 59.38%] [G loss: 0.616315]\n",
      "epoch:24 step:22893 [D loss: 0.531526, acc.: 64.06%] [G loss: 0.725158]\n",
      "epoch:24 step:22894 [D loss: 0.453366, acc.: 79.69%] [G loss: 0.842376]\n",
      "epoch:24 step:22895 [D loss: 0.626192, acc.: 62.50%] [G loss: 0.679630]\n",
      "epoch:24 step:22896 [D loss: 0.586499, acc.: 67.19%] [G loss: 0.938255]\n",
      "epoch:24 step:22897 [D loss: 0.570698, acc.: 66.41%] [G loss: 0.708485]\n",
      "epoch:24 step:22898 [D loss: 0.564952, acc.: 68.75%] [G loss: 0.777444]\n",
      "epoch:24 step:22899 [D loss: 0.551077, acc.: 69.53%] [G loss: 0.657220]\n",
      "epoch:24 step:22900 [D loss: 0.597764, acc.: 62.50%] [G loss: 0.499004]\n",
      "epoch:24 step:22901 [D loss: 0.563744, acc.: 67.97%] [G loss: 0.597052]\n",
      "epoch:24 step:22902 [D loss: 0.469180, acc.: 75.00%] [G loss: 0.919579]\n",
      "epoch:24 step:22903 [D loss: 0.492683, acc.: 72.66%] [G loss: 0.803930]\n",
      "epoch:24 step:22904 [D loss: 0.487254, acc.: 73.44%] [G loss: 0.839505]\n",
      "epoch:24 step:22905 [D loss: 0.589596, acc.: 64.84%] [G loss: 0.849384]\n",
      "epoch:24 step:22906 [D loss: 0.656458, acc.: 59.38%] [G loss: 0.861535]\n",
      "epoch:24 step:22907 [D loss: 0.531075, acc.: 68.75%] [G loss: 0.654332]\n",
      "epoch:24 step:22908 [D loss: 0.629976, acc.: 58.59%] [G loss: 0.669794]\n",
      "epoch:24 step:22909 [D loss: 0.529793, acc.: 74.22%] [G loss: 0.527993]\n",
      "epoch:24 step:22910 [D loss: 0.575851, acc.: 68.75%] [G loss: 0.570911]\n",
      "epoch:24 step:22911 [D loss: 0.544928, acc.: 71.88%] [G loss: 0.587551]\n",
      "epoch:24 step:22912 [D loss: 0.551660, acc.: 68.75%] [G loss: 0.628146]\n",
      "epoch:24 step:22913 [D loss: 0.489585, acc.: 75.00%] [G loss: 0.733969]\n",
      "epoch:24 step:22914 [D loss: 0.466225, acc.: 75.78%] [G loss: 0.787874]\n",
      "epoch:24 step:22915 [D loss: 0.477381, acc.: 75.78%] [G loss: 0.923882]\n",
      "epoch:24 step:22916 [D loss: 0.543824, acc.: 70.31%] [G loss: 0.851470]\n",
      "epoch:24 step:22917 [D loss: 0.407477, acc.: 82.81%] [G loss: 0.866780]\n",
      "epoch:24 step:22918 [D loss: 0.509032, acc.: 73.44%] [G loss: 0.913549]\n",
      "epoch:24 step:22919 [D loss: 0.455643, acc.: 72.66%] [G loss: 0.816281]\n",
      "epoch:24 step:22920 [D loss: 0.525590, acc.: 67.97%] [G loss: 0.732873]\n",
      "epoch:24 step:22921 [D loss: 0.529146, acc.: 72.66%] [G loss: 0.711177]\n",
      "epoch:24 step:22922 [D loss: 0.501572, acc.: 70.31%] [G loss: 0.742742]\n",
      "epoch:24 step:22923 [D loss: 0.536286, acc.: 68.75%] [G loss: 0.831133]\n",
      "epoch:24 step:22924 [D loss: 0.522635, acc.: 71.09%] [G loss: 0.862544]\n",
      "epoch:24 step:22925 [D loss: 0.665691, acc.: 63.28%] [G loss: 0.662050]\n",
      "epoch:24 step:22926 [D loss: 0.578929, acc.: 67.19%] [G loss: 0.596360]\n",
      "epoch:24 step:22927 [D loss: 0.489018, acc.: 75.78%] [G loss: 0.779459]\n",
      "epoch:24 step:22928 [D loss: 0.522792, acc.: 70.31%] [G loss: 0.904246]\n",
      "epoch:24 step:22929 [D loss: 0.523248, acc.: 71.09%] [G loss: 0.791682]\n",
      "epoch:24 step:22930 [D loss: 0.595800, acc.: 68.75%] [G loss: 0.875460]\n",
      "epoch:24 step:22931 [D loss: 0.538545, acc.: 70.31%] [G loss: 0.690609]\n",
      "epoch:24 step:22932 [D loss: 0.499364, acc.: 79.69%] [G loss: 0.862019]\n",
      "epoch:24 step:22933 [D loss: 0.558125, acc.: 69.53%] [G loss: 0.934694]\n",
      "epoch:24 step:22934 [D loss: 0.524894, acc.: 71.88%] [G loss: 0.972140]\n",
      "epoch:24 step:22935 [D loss: 0.473585, acc.: 73.44%] [G loss: 0.792229]\n",
      "epoch:24 step:22936 [D loss: 0.506228, acc.: 72.66%] [G loss: 0.713385]\n",
      "epoch:24 step:22937 [D loss: 0.469168, acc.: 76.56%] [G loss: 0.687678]\n",
      "epoch:24 step:22938 [D loss: 0.524614, acc.: 72.66%] [G loss: 0.652347]\n",
      "epoch:24 step:22939 [D loss: 0.400749, acc.: 82.03%] [G loss: 0.780613]\n",
      "epoch:24 step:22940 [D loss: 0.522208, acc.: 69.53%] [G loss: 0.794056]\n",
      "epoch:24 step:22941 [D loss: 0.499425, acc.: 78.12%] [G loss: 0.932548]\n",
      "epoch:24 step:22942 [D loss: 0.532363, acc.: 75.00%] [G loss: 0.726051]\n",
      "epoch:24 step:22943 [D loss: 0.565465, acc.: 66.41%] [G loss: 0.661570]\n",
      "epoch:24 step:22944 [D loss: 0.587528, acc.: 65.62%] [G loss: 0.682537]\n",
      "epoch:24 step:22945 [D loss: 0.425114, acc.: 82.03%] [G loss: 1.006640]\n",
      "epoch:24 step:22946 [D loss: 0.639468, acc.: 63.28%] [G loss: 0.601831]\n",
      "epoch:24 step:22947 [D loss: 0.586769, acc.: 68.75%] [G loss: 0.625513]\n",
      "epoch:24 step:22948 [D loss: 0.505472, acc.: 73.44%] [G loss: 0.735656]\n",
      "epoch:24 step:22949 [D loss: 0.473254, acc.: 76.56%] [G loss: 0.736544]\n",
      "epoch:24 step:22950 [D loss: 0.587609, acc.: 67.19%] [G loss: 0.672506]\n",
      "epoch:24 step:22951 [D loss: 0.541611, acc.: 68.75%] [G loss: 0.628364]\n",
      "epoch:24 step:22952 [D loss: 0.471690, acc.: 75.78%] [G loss: 0.695664]\n",
      "epoch:24 step:22953 [D loss: 0.542547, acc.: 70.31%] [G loss: 0.586650]\n",
      "epoch:24 step:22954 [D loss: 0.489833, acc.: 71.88%] [G loss: 0.597384]\n",
      "epoch:24 step:22955 [D loss: 0.520608, acc.: 71.88%] [G loss: 0.653841]\n",
      "epoch:24 step:22956 [D loss: 0.519311, acc.: 73.44%] [G loss: 0.552634]\n",
      "epoch:24 step:22957 [D loss: 0.514926, acc.: 71.09%] [G loss: 0.660531]\n",
      "epoch:24 step:22958 [D loss: 0.536781, acc.: 71.88%] [G loss: 0.667072]\n",
      "epoch:24 step:22959 [D loss: 0.439128, acc.: 77.34%] [G loss: 0.856354]\n",
      "epoch:24 step:22960 [D loss: 0.450622, acc.: 79.69%] [G loss: 1.017928]\n",
      "epoch:24 step:22961 [D loss: 0.611695, acc.: 64.84%] [G loss: 0.807482]\n",
      "epoch:24 step:22962 [D loss: 0.544988, acc.: 65.62%] [G loss: 0.855177]\n",
      "epoch:24 step:22963 [D loss: 0.431909, acc.: 79.69%] [G loss: 0.886224]\n",
      "epoch:24 step:22964 [D loss: 0.556116, acc.: 68.75%] [G loss: 0.877100]\n",
      "epoch:24 step:22965 [D loss: 0.583812, acc.: 67.19%] [G loss: 0.711273]\n",
      "epoch:24 step:22966 [D loss: 0.546046, acc.: 71.88%] [G loss: 0.636253]\n",
      "epoch:24 step:22967 [D loss: 0.511923, acc.: 76.56%] [G loss: 0.616586]\n",
      "epoch:24 step:22968 [D loss: 0.577216, acc.: 67.97%] [G loss: 0.543831]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:24 step:22969 [D loss: 0.432719, acc.: 83.59%] [G loss: 0.717448]\n",
      "epoch:24 step:22970 [D loss: 0.573985, acc.: 66.41%] [G loss: 0.682825]\n",
      "epoch:24 step:22971 [D loss: 0.591804, acc.: 64.06%] [G loss: 0.735317]\n",
      "epoch:24 step:22972 [D loss: 0.493018, acc.: 72.66%] [G loss: 0.654384]\n",
      "epoch:24 step:22973 [D loss: 0.555286, acc.: 67.19%] [G loss: 0.723369]\n",
      "epoch:24 step:22974 [D loss: 0.557303, acc.: 67.97%] [G loss: 0.757426]\n",
      "epoch:24 step:22975 [D loss: 0.576380, acc.: 65.62%] [G loss: 0.579679]\n",
      "epoch:24 step:22976 [D loss: 0.448184, acc.: 76.56%] [G loss: 0.734067]\n",
      "epoch:24 step:22977 [D loss: 0.495880, acc.: 73.44%] [G loss: 0.739156]\n",
      "epoch:24 step:22978 [D loss: 0.567770, acc.: 71.88%] [G loss: 0.618817]\n",
      "epoch:24 step:22979 [D loss: 0.506754, acc.: 71.88%] [G loss: 0.655722]\n",
      "epoch:24 step:22980 [D loss: 0.567056, acc.: 66.41%] [G loss: 0.700854]\n",
      "epoch:24 step:22981 [D loss: 0.541522, acc.: 74.22%] [G loss: 0.720184]\n",
      "epoch:24 step:22982 [D loss: 0.573911, acc.: 67.19%] [G loss: 0.631396]\n",
      "epoch:24 step:22983 [D loss: 0.506606, acc.: 77.34%] [G loss: 0.610510]\n",
      "epoch:24 step:22984 [D loss: 0.489794, acc.: 76.56%] [G loss: 0.713985]\n",
      "epoch:24 step:22985 [D loss: 0.530953, acc.: 76.56%] [G loss: 0.729099]\n",
      "epoch:24 step:22986 [D loss: 0.519491, acc.: 75.78%] [G loss: 0.830056]\n",
      "epoch:24 step:22987 [D loss: 0.470318, acc.: 75.78%] [G loss: 0.883455]\n",
      "epoch:24 step:22988 [D loss: 0.537974, acc.: 72.66%] [G loss: 0.751822]\n",
      "epoch:24 step:22989 [D loss: 0.621051, acc.: 64.06%] [G loss: 0.628968]\n",
      "epoch:24 step:22990 [D loss: 0.619159, acc.: 61.72%] [G loss: 0.572044]\n",
      "epoch:24 step:22991 [D loss: 0.505516, acc.: 69.53%] [G loss: 0.602495]\n",
      "epoch:24 step:22992 [D loss: 0.454229, acc.: 82.03%] [G loss: 0.828673]\n",
      "epoch:24 step:22993 [D loss: 0.493335, acc.: 74.22%] [G loss: 0.818142]\n",
      "epoch:24 step:22994 [D loss: 0.507173, acc.: 77.34%] [G loss: 0.769060]\n",
      "epoch:24 step:22995 [D loss: 0.478574, acc.: 78.91%] [G loss: 0.868667]\n",
      "epoch:24 step:22996 [D loss: 0.416552, acc.: 81.25%] [G loss: 0.895315]\n",
      "epoch:24 step:22997 [D loss: 0.496991, acc.: 76.56%] [G loss: 0.997691]\n",
      "epoch:24 step:22998 [D loss: 0.618528, acc.: 67.97%] [G loss: 0.696026]\n",
      "epoch:24 step:22999 [D loss: 0.583200, acc.: 68.75%] [G loss: 0.676905]\n",
      "epoch:24 step:23000 [D loss: 0.554187, acc.: 69.53%] [G loss: 0.610685]\n",
      "epoch:24 step:23001 [D loss: 0.520531, acc.: 74.22%] [G loss: 0.591941]\n",
      "epoch:24 step:23002 [D loss: 0.510709, acc.: 70.31%] [G loss: 0.622073]\n",
      "epoch:24 step:23003 [D loss: 0.529378, acc.: 71.88%] [G loss: 0.628151]\n",
      "epoch:24 step:23004 [D loss: 0.446333, acc.: 78.12%] [G loss: 0.758592]\n",
      "epoch:24 step:23005 [D loss: 0.541751, acc.: 67.97%] [G loss: 0.678331]\n",
      "epoch:24 step:23006 [D loss: 0.558981, acc.: 67.19%] [G loss: 0.555794]\n",
      "epoch:24 step:23007 [D loss: 0.446986, acc.: 79.69%] [G loss: 0.843804]\n",
      "epoch:24 step:23008 [D loss: 0.462381, acc.: 76.56%] [G loss: 0.756206]\n",
      "epoch:24 step:23009 [D loss: 0.487884, acc.: 77.34%] [G loss: 0.807488]\n",
      "epoch:24 step:23010 [D loss: 0.512587, acc.: 74.22%] [G loss: 0.679993]\n",
      "epoch:24 step:23011 [D loss: 0.419665, acc.: 80.47%] [G loss: 0.891242]\n",
      "epoch:24 step:23012 [D loss: 0.563406, acc.: 67.97%] [G loss: 0.743204]\n",
      "epoch:24 step:23013 [D loss: 0.560217, acc.: 71.09%] [G loss: 0.641544]\n",
      "epoch:24 step:23014 [D loss: 0.479234, acc.: 75.00%] [G loss: 0.812957]\n",
      "epoch:24 step:23015 [D loss: 0.567937, acc.: 67.97%] [G loss: 0.866291]\n",
      "epoch:24 step:23016 [D loss: 0.685850, acc.: 57.03%] [G loss: 0.725434]\n",
      "epoch:24 step:23017 [D loss: 0.617422, acc.: 60.16%] [G loss: 0.691336]\n",
      "epoch:24 step:23018 [D loss: 0.515750, acc.: 71.09%] [G loss: 0.732544]\n",
      "epoch:24 step:23019 [D loss: 0.501152, acc.: 72.66%] [G loss: 0.529115]\n",
      "epoch:24 step:23020 [D loss: 0.579415, acc.: 64.84%] [G loss: 0.676363]\n",
      "epoch:24 step:23021 [D loss: 0.542496, acc.: 71.09%] [G loss: 0.728030]\n",
      "epoch:24 step:23022 [D loss: 0.493720, acc.: 74.22%] [G loss: 0.798619]\n",
      "epoch:24 step:23023 [D loss: 0.565986, acc.: 65.62%] [G loss: 0.669805]\n",
      "epoch:24 step:23024 [D loss: 0.541591, acc.: 72.66%] [G loss: 0.637988]\n",
      "epoch:24 step:23025 [D loss: 0.597564, acc.: 64.06%] [G loss: 0.593548]\n",
      "epoch:24 step:23026 [D loss: 0.575225, acc.: 68.75%] [G loss: 0.556349]\n",
      "epoch:24 step:23027 [D loss: 0.581200, acc.: 65.62%] [G loss: 0.391596]\n",
      "epoch:24 step:23028 [D loss: 0.507081, acc.: 71.88%] [G loss: 0.668127]\n",
      "epoch:24 step:23029 [D loss: 0.579970, acc.: 63.28%] [G loss: 0.564158]\n",
      "epoch:24 step:23030 [D loss: 0.568562, acc.: 72.66%] [G loss: 0.601626]\n",
      "epoch:24 step:23031 [D loss: 0.557821, acc.: 69.53%] [G loss: 0.678112]\n",
      "epoch:24 step:23032 [D loss: 0.560554, acc.: 64.06%] [G loss: 0.839692]\n",
      "epoch:24 step:23033 [D loss: 0.536661, acc.: 73.44%] [G loss: 0.704291]\n",
      "epoch:24 step:23034 [D loss: 0.444100, acc.: 82.81%] [G loss: 0.869487]\n",
      "epoch:24 step:23035 [D loss: 0.553477, acc.: 68.75%] [G loss: 0.651274]\n",
      "epoch:24 step:23036 [D loss: 0.470492, acc.: 78.91%] [G loss: 0.811175]\n",
      "epoch:24 step:23037 [D loss: 0.559262, acc.: 68.75%] [G loss: 0.722518]\n",
      "epoch:24 step:23038 [D loss: 0.481769, acc.: 75.78%] [G loss: 0.757280]\n",
      "epoch:24 step:23039 [D loss: 0.482471, acc.: 77.34%] [G loss: 0.651874]\n",
      "epoch:24 step:23040 [D loss: 0.492272, acc.: 72.66%] [G loss: 0.753917]\n",
      "epoch:24 step:23041 [D loss: 0.584589, acc.: 67.97%] [G loss: 0.826126]\n",
      "epoch:24 step:23042 [D loss: 0.453938, acc.: 80.47%] [G loss: 0.769793]\n",
      "epoch:24 step:23043 [D loss: 0.437985, acc.: 82.03%] [G loss: 0.858976]\n",
      "epoch:24 step:23044 [D loss: 0.569231, acc.: 66.41%] [G loss: 0.863154]\n",
      "epoch:24 step:23045 [D loss: 0.540055, acc.: 75.78%] [G loss: 0.740942]\n",
      "epoch:24 step:23046 [D loss: 0.405914, acc.: 80.47%] [G loss: 0.904473]\n",
      "epoch:24 step:23047 [D loss: 0.573835, acc.: 64.84%] [G loss: 0.608679]\n",
      "epoch:24 step:23048 [D loss: 0.518305, acc.: 73.44%] [G loss: 0.760462]\n",
      "epoch:24 step:23049 [D loss: 0.495226, acc.: 74.22%] [G loss: 0.779037]\n",
      "epoch:24 step:23050 [D loss: 0.507131, acc.: 75.78%] [G loss: 0.773267]\n",
      "epoch:24 step:23051 [D loss: 0.535977, acc.: 67.19%] [G loss: 0.737686]\n",
      "epoch:24 step:23052 [D loss: 0.449672, acc.: 82.81%] [G loss: 0.768603]\n",
      "epoch:24 step:23053 [D loss: 0.552963, acc.: 72.66%] [G loss: 1.002217]\n",
      "epoch:24 step:23054 [D loss: 0.636368, acc.: 64.06%] [G loss: 1.048340]\n",
      "epoch:24 step:23055 [D loss: 0.504578, acc.: 76.56%] [G loss: 0.973191]\n",
      "epoch:24 step:23056 [D loss: 0.468884, acc.: 78.91%] [G loss: 0.763173]\n",
      "epoch:24 step:23057 [D loss: 0.519300, acc.: 74.22%] [G loss: 0.724092]\n",
      "epoch:24 step:23058 [D loss: 0.490920, acc.: 75.00%] [G loss: 0.744508]\n",
      "epoch:24 step:23059 [D loss: 0.566632, acc.: 66.41%] [G loss: 0.637230]\n",
      "epoch:24 step:23060 [D loss: 0.532316, acc.: 72.66%] [G loss: 0.743240]\n",
      "epoch:24 step:23061 [D loss: 0.507982, acc.: 74.22%] [G loss: 0.837256]\n",
      "epoch:24 step:23062 [D loss: 0.494321, acc.: 73.44%] [G loss: 0.953262]\n",
      "epoch:24 step:23063 [D loss: 0.495755, acc.: 75.78%] [G loss: 0.938076]\n",
      "epoch:24 step:23064 [D loss: 0.585446, acc.: 69.53%] [G loss: 0.721635]\n",
      "epoch:24 step:23065 [D loss: 0.548680, acc.: 67.19%] [G loss: 0.701700]\n",
      "epoch:24 step:23066 [D loss: 0.584586, acc.: 65.62%] [G loss: 0.717826]\n",
      "epoch:24 step:23067 [D loss: 0.489629, acc.: 77.34%] [G loss: 0.766142]\n",
      "epoch:24 step:23068 [D loss: 0.532219, acc.: 71.88%] [G loss: 0.620975]\n",
      "epoch:24 step:23069 [D loss: 0.525060, acc.: 69.53%] [G loss: 0.786005]\n",
      "epoch:24 step:23070 [D loss: 0.434590, acc.: 80.47%] [G loss: 0.784997]\n",
      "epoch:24 step:23071 [D loss: 0.549994, acc.: 73.44%] [G loss: 0.671909]\n",
      "epoch:24 step:23072 [D loss: 0.612330, acc.: 62.50%] [G loss: 0.664490]\n",
      "epoch:24 step:23073 [D loss: 0.517225, acc.: 75.78%] [G loss: 0.882165]\n",
      "epoch:24 step:23074 [D loss: 0.543856, acc.: 68.75%] [G loss: 0.716027]\n",
      "epoch:24 step:23075 [D loss: 0.528866, acc.: 70.31%] [G loss: 0.597977]\n",
      "epoch:24 step:23076 [D loss: 0.571807, acc.: 67.97%] [G loss: 0.662802]\n",
      "epoch:24 step:23077 [D loss: 0.532268, acc.: 71.09%] [G loss: 0.734527]\n",
      "epoch:24 step:23078 [D loss: 0.538077, acc.: 71.88%] [G loss: 0.762855]\n",
      "epoch:24 step:23079 [D loss: 0.672240, acc.: 61.72%] [G loss: 0.588431]\n",
      "epoch:24 step:23080 [D loss: 0.494643, acc.: 78.12%] [G loss: 0.746577]\n",
      "epoch:24 step:23081 [D loss: 0.530168, acc.: 75.00%] [G loss: 0.956100]\n",
      "epoch:24 step:23082 [D loss: 0.544073, acc.: 71.09%] [G loss: 0.612646]\n",
      "epoch:24 step:23083 [D loss: 0.524493, acc.: 74.22%] [G loss: 0.721101]\n",
      "epoch:24 step:23084 [D loss: 0.511343, acc.: 72.66%] [G loss: 0.547635]\n",
      "epoch:24 step:23085 [D loss: 0.551622, acc.: 74.22%] [G loss: 0.682271]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:24 step:23086 [D loss: 0.483831, acc.: 72.66%] [G loss: 0.646722]\n",
      "epoch:24 step:23087 [D loss: 0.564278, acc.: 71.09%] [G loss: 0.766040]\n",
      "epoch:24 step:23088 [D loss: 0.576274, acc.: 68.75%] [G loss: 0.744849]\n",
      "epoch:24 step:23089 [D loss: 0.435971, acc.: 82.81%] [G loss: 0.806359]\n",
      "epoch:24 step:23090 [D loss: 0.452711, acc.: 77.34%] [G loss: 0.923679]\n",
      "epoch:24 step:23091 [D loss: 0.507145, acc.: 73.44%] [G loss: 0.846586]\n",
      "epoch:24 step:23092 [D loss: 0.584561, acc.: 69.53%] [G loss: 0.860694]\n",
      "epoch:24 step:23093 [D loss: 0.473965, acc.: 75.78%] [G loss: 0.818110]\n",
      "epoch:24 step:23094 [D loss: 0.621470, acc.: 65.62%] [G loss: 0.736759]\n",
      "epoch:24 step:23095 [D loss: 0.511796, acc.: 75.00%] [G loss: 0.586628]\n",
      "epoch:24 step:23096 [D loss: 0.558932, acc.: 69.53%] [G loss: 0.624092]\n",
      "epoch:24 step:23097 [D loss: 0.528546, acc.: 71.09%] [G loss: 0.583257]\n",
      "epoch:24 step:23098 [D loss: 0.561588, acc.: 67.97%] [G loss: 0.553303]\n",
      "epoch:24 step:23099 [D loss: 0.439974, acc.: 80.47%] [G loss: 0.625853]\n",
      "epoch:24 step:23100 [D loss: 0.533707, acc.: 70.31%] [G loss: 0.636008]\n",
      "epoch:24 step:23101 [D loss: 0.504684, acc.: 73.44%] [G loss: 0.658599]\n",
      "epoch:24 step:23102 [D loss: 0.503018, acc.: 72.66%] [G loss: 0.700153]\n",
      "epoch:24 step:23103 [D loss: 0.585937, acc.: 67.97%] [G loss: 0.666621]\n",
      "epoch:24 step:23104 [D loss: 0.530299, acc.: 70.31%] [G loss: 0.665382]\n",
      "epoch:24 step:23105 [D loss: 0.506225, acc.: 75.78%] [G loss: 0.909583]\n",
      "epoch:24 step:23106 [D loss: 0.512088, acc.: 74.22%] [G loss: 0.717504]\n",
      "epoch:24 step:23107 [D loss: 0.525581, acc.: 69.53%] [G loss: 0.665212]\n",
      "epoch:24 step:23108 [D loss: 0.511764, acc.: 73.44%] [G loss: 0.729477]\n",
      "epoch:24 step:23109 [D loss: 0.622427, acc.: 63.28%] [G loss: 0.855033]\n",
      "epoch:24 step:23110 [D loss: 0.552489, acc.: 71.88%] [G loss: 0.673161]\n",
      "epoch:24 step:23111 [D loss: 0.464192, acc.: 75.78%] [G loss: 0.757596]\n",
      "epoch:24 step:23112 [D loss: 0.396579, acc.: 85.94%] [G loss: 0.820352]\n",
      "epoch:24 step:23113 [D loss: 0.541516, acc.: 70.31%] [G loss: 0.674381]\n",
      "epoch:24 step:23114 [D loss: 0.538663, acc.: 70.31%] [G loss: 0.738099]\n",
      "epoch:24 step:23115 [D loss: 0.536456, acc.: 68.75%] [G loss: 0.744013]\n",
      "epoch:24 step:23116 [D loss: 0.564712, acc.: 71.09%] [G loss: 0.634724]\n",
      "epoch:24 step:23117 [D loss: 0.481994, acc.: 78.12%] [G loss: 0.715335]\n",
      "epoch:24 step:23118 [D loss: 0.521463, acc.: 68.75%] [G loss: 0.697751]\n",
      "epoch:24 step:23119 [D loss: 0.499864, acc.: 77.34%] [G loss: 0.747899]\n",
      "epoch:24 step:23120 [D loss: 0.469727, acc.: 76.56%] [G loss: 0.798317]\n",
      "epoch:24 step:23121 [D loss: 0.517577, acc.: 71.88%] [G loss: 0.705432]\n",
      "epoch:24 step:23122 [D loss: 0.436657, acc.: 81.25%] [G loss: 0.816240]\n",
      "epoch:24 step:23123 [D loss: 0.442897, acc.: 78.12%] [G loss: 0.762459]\n",
      "epoch:24 step:23124 [D loss: 0.616549, acc.: 64.84%] [G loss: 0.625177]\n",
      "epoch:24 step:23125 [D loss: 0.478953, acc.: 76.56%] [G loss: 0.772024]\n",
      "epoch:24 step:23126 [D loss: 0.514571, acc.: 68.75%] [G loss: 0.661577]\n",
      "epoch:24 step:23127 [D loss: 0.517896, acc.: 72.66%] [G loss: 0.810250]\n",
      "epoch:24 step:23128 [D loss: 0.549595, acc.: 72.66%] [G loss: 0.728121]\n",
      "epoch:24 step:23129 [D loss: 0.532225, acc.: 70.31%] [G loss: 0.834008]\n",
      "epoch:24 step:23130 [D loss: 0.473570, acc.: 77.34%] [G loss: 0.960693]\n",
      "epoch:24 step:23131 [D loss: 0.504561, acc.: 75.00%] [G loss: 0.950928]\n",
      "epoch:24 step:23132 [D loss: 0.591121, acc.: 64.06%] [G loss: 0.705371]\n",
      "epoch:24 step:23133 [D loss: 0.514453, acc.: 74.22%] [G loss: 0.695481]\n",
      "epoch:24 step:23134 [D loss: 0.498454, acc.: 71.09%] [G loss: 0.833522]\n",
      "epoch:24 step:23135 [D loss: 0.407542, acc.: 83.59%] [G loss: 0.768218]\n",
      "epoch:24 step:23136 [D loss: 0.420691, acc.: 77.34%] [G loss: 1.143215]\n",
      "epoch:24 step:23137 [D loss: 0.459304, acc.: 78.12%] [G loss: 0.910228]\n",
      "epoch:24 step:23138 [D loss: 0.513531, acc.: 76.56%] [G loss: 1.009853]\n",
      "epoch:24 step:23139 [D loss: 0.489359, acc.: 74.22%] [G loss: 0.944981]\n",
      "epoch:24 step:23140 [D loss: 0.648583, acc.: 61.72%] [G loss: 0.835562]\n",
      "epoch:24 step:23141 [D loss: 0.544716, acc.: 73.44%] [G loss: 0.906674]\n",
      "epoch:24 step:23142 [D loss: 0.459582, acc.: 73.44%] [G loss: 1.031991]\n",
      "epoch:24 step:23143 [D loss: 0.543685, acc.: 74.22%] [G loss: 0.743654]\n",
      "epoch:24 step:23144 [D loss: 0.522507, acc.: 74.22%] [G loss: 0.717316]\n",
      "epoch:24 step:23145 [D loss: 0.489173, acc.: 75.78%] [G loss: 0.655197]\n",
      "epoch:24 step:23146 [D loss: 0.577935, acc.: 69.53%] [G loss: 0.723103]\n",
      "epoch:24 step:23147 [D loss: 0.483531, acc.: 76.56%] [G loss: 1.009495]\n",
      "epoch:24 step:23148 [D loss: 0.524819, acc.: 65.62%] [G loss: 0.870381]\n",
      "epoch:24 step:23149 [D loss: 0.474544, acc.: 78.12%] [G loss: 0.723459]\n",
      "epoch:24 step:23150 [D loss: 0.480295, acc.: 78.12%] [G loss: 0.692976]\n",
      "epoch:24 step:23151 [D loss: 0.558364, acc.: 65.62%] [G loss: 0.625207]\n",
      "epoch:24 step:23152 [D loss: 0.510335, acc.: 72.66%] [G loss: 0.803863]\n",
      "epoch:24 step:23153 [D loss: 0.538222, acc.: 72.66%] [G loss: 0.758303]\n",
      "epoch:24 step:23154 [D loss: 0.551156, acc.: 70.31%] [G loss: 0.614739]\n",
      "epoch:24 step:23155 [D loss: 0.460203, acc.: 80.47%] [G loss: 0.956462]\n",
      "epoch:24 step:23156 [D loss: 0.621629, acc.: 65.62%] [G loss: 0.732304]\n",
      "epoch:24 step:23157 [D loss: 0.555396, acc.: 65.62%] [G loss: 0.745164]\n",
      "epoch:24 step:23158 [D loss: 0.530060, acc.: 70.31%] [G loss: 0.704131]\n",
      "epoch:24 step:23159 [D loss: 0.543910, acc.: 72.66%] [G loss: 0.726272]\n",
      "epoch:24 step:23160 [D loss: 0.498939, acc.: 71.88%] [G loss: 0.775011]\n",
      "epoch:24 step:23161 [D loss: 0.650617, acc.: 63.28%] [G loss: 0.699696]\n",
      "epoch:24 step:23162 [D loss: 0.544851, acc.: 71.88%] [G loss: 1.045710]\n",
      "epoch:24 step:23163 [D loss: 0.586236, acc.: 63.28%] [G loss: 0.742601]\n",
      "epoch:24 step:23164 [D loss: 0.571587, acc.: 71.88%] [G loss: 0.706383]\n",
      "epoch:24 step:23165 [D loss: 0.511206, acc.: 75.00%] [G loss: 0.723997]\n",
      "epoch:24 step:23166 [D loss: 0.520297, acc.: 73.44%] [G loss: 0.788035]\n",
      "epoch:24 step:23167 [D loss: 0.493447, acc.: 71.88%] [G loss: 0.788824]\n",
      "epoch:24 step:23168 [D loss: 0.509506, acc.: 75.78%] [G loss: 0.715894]\n",
      "epoch:24 step:23169 [D loss: 0.485848, acc.: 75.78%] [G loss: 0.828146]\n",
      "epoch:24 step:23170 [D loss: 0.542396, acc.: 69.53%] [G loss: 0.870864]\n",
      "epoch:24 step:23171 [D loss: 0.500638, acc.: 74.22%] [G loss: 0.745624]\n",
      "epoch:24 step:23172 [D loss: 0.605928, acc.: 67.19%] [G loss: 0.630497]\n",
      "epoch:24 step:23173 [D loss: 0.577910, acc.: 67.97%] [G loss: 0.475033]\n",
      "epoch:24 step:23174 [D loss: 0.516470, acc.: 74.22%] [G loss: 0.699326]\n",
      "epoch:24 step:23175 [D loss: 0.562037, acc.: 71.09%] [G loss: 0.615754]\n",
      "epoch:24 step:23176 [D loss: 0.525119, acc.: 72.66%] [G loss: 0.773074]\n",
      "epoch:24 step:23177 [D loss: 0.577319, acc.: 64.84%] [G loss: 0.640072]\n",
      "epoch:24 step:23178 [D loss: 0.525124, acc.: 67.19%] [G loss: 0.535855]\n",
      "epoch:24 step:23179 [D loss: 0.470244, acc.: 75.00%] [G loss: 0.797925]\n",
      "epoch:24 step:23180 [D loss: 0.504146, acc.: 74.22%] [G loss: 0.810413]\n",
      "epoch:24 step:23181 [D loss: 0.461123, acc.: 80.47%] [G loss: 0.993590]\n",
      "epoch:24 step:23182 [D loss: 0.514540, acc.: 75.78%] [G loss: 0.780842]\n",
      "epoch:24 step:23183 [D loss: 0.498690, acc.: 75.78%] [G loss: 0.890883]\n",
      "epoch:24 step:23184 [D loss: 0.637552, acc.: 64.84%] [G loss: 0.664878]\n",
      "epoch:24 step:23185 [D loss: 0.551509, acc.: 69.53%] [G loss: 0.547590]\n",
      "epoch:24 step:23186 [D loss: 0.572040, acc.: 67.97%] [G loss: 0.663229]\n",
      "epoch:24 step:23187 [D loss: 0.497789, acc.: 75.78%] [G loss: 0.776976]\n",
      "epoch:24 step:23188 [D loss: 0.498143, acc.: 72.66%] [G loss: 0.721736]\n",
      "epoch:24 step:23189 [D loss: 0.519961, acc.: 70.31%] [G loss: 0.926856]\n",
      "epoch:24 step:23190 [D loss: 0.565807, acc.: 66.41%] [G loss: 0.820051]\n",
      "epoch:24 step:23191 [D loss: 0.600624, acc.: 63.28%] [G loss: 0.747382]\n",
      "epoch:24 step:23192 [D loss: 0.633798, acc.: 59.38%] [G loss: 0.650576]\n",
      "epoch:24 step:23193 [D loss: 0.531475, acc.: 72.66%] [G loss: 0.763797]\n",
      "epoch:24 step:23194 [D loss: 0.502842, acc.: 75.00%] [G loss: 0.710205]\n",
      "epoch:24 step:23195 [D loss: 0.491630, acc.: 73.44%] [G loss: 0.896368]\n",
      "epoch:24 step:23196 [D loss: 0.461376, acc.: 78.12%] [G loss: 0.921833]\n",
      "epoch:24 step:23197 [D loss: 0.491833, acc.: 73.44%] [G loss: 0.743194]\n",
      "epoch:24 step:23198 [D loss: 0.559258, acc.: 67.19%] [G loss: 0.746344]\n",
      "epoch:24 step:23199 [D loss: 0.523337, acc.: 68.75%] [G loss: 0.674738]\n",
      "epoch:24 step:23200 [D loss: 0.580716, acc.: 64.06%] [G loss: 0.701449]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:24 step:23201 [D loss: 0.582938, acc.: 64.06%] [G loss: 0.659062]\n",
      "epoch:24 step:23202 [D loss: 0.529320, acc.: 69.53%] [G loss: 0.749297]\n",
      "epoch:24 step:23203 [D loss: 0.518670, acc.: 73.44%] [G loss: 0.731643]\n",
      "epoch:24 step:23204 [D loss: 0.589019, acc.: 66.41%] [G loss: 0.596052]\n",
      "epoch:24 step:23205 [D loss: 0.546599, acc.: 75.00%] [G loss: 0.684869]\n",
      "epoch:24 step:23206 [D loss: 0.545477, acc.: 72.66%] [G loss: 0.683550]\n",
      "epoch:24 step:23207 [D loss: 0.456459, acc.: 79.69%] [G loss: 0.909456]\n",
      "epoch:24 step:23208 [D loss: 0.577277, acc.: 69.53%] [G loss: 0.699709]\n",
      "epoch:24 step:23209 [D loss: 0.546618, acc.: 68.75%] [G loss: 0.571921]\n",
      "epoch:24 step:23210 [D loss: 0.534350, acc.: 71.09%] [G loss: 0.725078]\n",
      "epoch:24 step:23211 [D loss: 0.526112, acc.: 77.34%] [G loss: 0.726011]\n",
      "epoch:24 step:23212 [D loss: 0.492027, acc.: 75.78%] [G loss: 0.627547]\n",
      "epoch:24 step:23213 [D loss: 0.512605, acc.: 72.66%] [G loss: 0.747034]\n",
      "epoch:24 step:23214 [D loss: 0.476658, acc.: 78.91%] [G loss: 0.727348]\n",
      "epoch:24 step:23215 [D loss: 0.549609, acc.: 66.41%] [G loss: 0.763631]\n",
      "epoch:24 step:23216 [D loss: 0.502516, acc.: 75.00%] [G loss: 0.748913]\n",
      "epoch:24 step:23217 [D loss: 0.571839, acc.: 65.62%] [G loss: 0.556758]\n",
      "epoch:24 step:23218 [D loss: 0.475937, acc.: 78.91%] [G loss: 0.743850]\n",
      "epoch:24 step:23219 [D loss: 0.532487, acc.: 71.88%] [G loss: 0.677258]\n",
      "epoch:24 step:23220 [D loss: 0.517575, acc.: 67.97%] [G loss: 0.814123]\n",
      "epoch:24 step:23221 [D loss: 0.505670, acc.: 75.00%] [G loss: 0.914382]\n",
      "epoch:24 step:23222 [D loss: 0.521060, acc.: 69.53%] [G loss: 0.732571]\n",
      "epoch:24 step:23223 [D loss: 0.542612, acc.: 67.97%] [G loss: 0.857323]\n",
      "epoch:24 step:23224 [D loss: 0.454917, acc.: 78.12%] [G loss: 0.788820]\n",
      "epoch:24 step:23225 [D loss: 0.484889, acc.: 77.34%] [G loss: 0.541646]\n",
      "epoch:24 step:23226 [D loss: 0.550733, acc.: 67.97%] [G loss: 0.577089]\n",
      "epoch:24 step:23227 [D loss: 0.561965, acc.: 65.62%] [G loss: 0.841647]\n",
      "epoch:24 step:23228 [D loss: 0.641197, acc.: 60.94%] [G loss: 0.560570]\n",
      "epoch:24 step:23229 [D loss: 0.501476, acc.: 72.66%] [G loss: 0.655640]\n",
      "epoch:24 step:23230 [D loss: 0.510601, acc.: 74.22%] [G loss: 0.790246]\n",
      "epoch:24 step:23231 [D loss: 0.494589, acc.: 74.22%] [G loss: 0.849472]\n",
      "epoch:24 step:23232 [D loss: 0.501515, acc.: 75.78%] [G loss: 0.716974]\n",
      "epoch:24 step:23233 [D loss: 0.570738, acc.: 67.97%] [G loss: 0.824285]\n",
      "epoch:24 step:23234 [D loss: 0.544415, acc.: 71.09%] [G loss: 0.615809]\n",
      "epoch:24 step:23235 [D loss: 0.415063, acc.: 83.59%] [G loss: 0.890374]\n",
      "epoch:24 step:23236 [D loss: 0.529880, acc.: 71.09%] [G loss: 0.897399]\n",
      "epoch:24 step:23237 [D loss: 0.599514, acc.: 65.62%] [G loss: 0.622454]\n",
      "epoch:24 step:23238 [D loss: 0.507978, acc.: 75.78%] [G loss: 0.784734]\n",
      "epoch:24 step:23239 [D loss: 0.489035, acc.: 74.22%] [G loss: 0.808948]\n",
      "epoch:24 step:23240 [D loss: 0.555938, acc.: 67.97%] [G loss: 0.713151]\n",
      "epoch:24 step:23241 [D loss: 0.480248, acc.: 75.78%] [G loss: 0.743125]\n",
      "epoch:24 step:23242 [D loss: 0.500190, acc.: 72.66%] [G loss: 0.560282]\n",
      "epoch:24 step:23243 [D loss: 0.540163, acc.: 69.53%] [G loss: 0.721956]\n",
      "epoch:24 step:23244 [D loss: 0.524978, acc.: 67.97%] [G loss: 0.725776]\n",
      "epoch:24 step:23245 [D loss: 0.542043, acc.: 64.84%] [G loss: 0.737489]\n",
      "epoch:24 step:23246 [D loss: 0.504261, acc.: 78.12%] [G loss: 0.578407]\n",
      "epoch:24 step:23247 [D loss: 0.571604, acc.: 67.19%] [G loss: 0.625970]\n",
      "epoch:24 step:23248 [D loss: 0.523685, acc.: 75.78%] [G loss: 0.756251]\n",
      "epoch:24 step:23249 [D loss: 0.549688, acc.: 70.31%] [G loss: 0.663867]\n",
      "epoch:24 step:23250 [D loss: 0.541896, acc.: 72.66%] [G loss: 0.726528]\n",
      "epoch:24 step:23251 [D loss: 0.534274, acc.: 71.09%] [G loss: 0.644463]\n",
      "epoch:24 step:23252 [D loss: 0.560363, acc.: 74.22%] [G loss: 0.606495]\n",
      "epoch:24 step:23253 [D loss: 0.602754, acc.: 67.19%] [G loss: 0.613496]\n",
      "epoch:24 step:23254 [D loss: 0.614814, acc.: 62.50%] [G loss: 0.569023]\n",
      "epoch:24 step:23255 [D loss: 0.505132, acc.: 75.78%] [G loss: 0.595287]\n",
      "epoch:24 step:23256 [D loss: 0.506715, acc.: 76.56%] [G loss: 0.806899]\n",
      "epoch:24 step:23257 [D loss: 0.453593, acc.: 80.47%] [G loss: 0.955037]\n",
      "epoch:24 step:23258 [D loss: 0.538496, acc.: 71.88%] [G loss: 0.938429]\n",
      "epoch:24 step:23259 [D loss: 0.530384, acc.: 72.66%] [G loss: 0.821373]\n",
      "epoch:24 step:23260 [D loss: 0.544889, acc.: 67.19%] [G loss: 0.900215]\n",
      "epoch:24 step:23261 [D loss: 0.537591, acc.: 75.78%] [G loss: 0.708052]\n",
      "epoch:24 step:23262 [D loss: 0.582437, acc.: 69.53%] [G loss: 0.709401]\n",
      "epoch:24 step:23263 [D loss: 0.491079, acc.: 74.22%] [G loss: 0.795563]\n",
      "epoch:24 step:23264 [D loss: 0.591935, acc.: 71.88%] [G loss: 0.946155]\n",
      "epoch:24 step:23265 [D loss: 0.577670, acc.: 70.31%] [G loss: 0.749059]\n",
      "epoch:24 step:23266 [D loss: 0.471984, acc.: 77.34%] [G loss: 0.969966]\n",
      "epoch:24 step:23267 [D loss: 0.528557, acc.: 73.44%] [G loss: 0.673996]\n",
      "epoch:24 step:23268 [D loss: 0.495159, acc.: 76.56%] [G loss: 0.664346]\n",
      "epoch:24 step:23269 [D loss: 0.529018, acc.: 70.31%] [G loss: 0.658301]\n",
      "epoch:24 step:23270 [D loss: 0.476336, acc.: 75.00%] [G loss: 0.815122]\n",
      "epoch:24 step:23271 [D loss: 0.509201, acc.: 72.66%] [G loss: 0.846544]\n",
      "epoch:24 step:23272 [D loss: 0.616619, acc.: 68.75%] [G loss: 0.780597]\n",
      "epoch:24 step:23273 [D loss: 0.562057, acc.: 69.53%] [G loss: 0.708425]\n",
      "epoch:24 step:23274 [D loss: 0.450157, acc.: 80.47%] [G loss: 0.666842]\n",
      "epoch:24 step:23275 [D loss: 0.571690, acc.: 68.75%] [G loss: 0.635244]\n",
      "epoch:24 step:23276 [D loss: 0.621982, acc.: 62.50%] [G loss: 0.619344]\n",
      "epoch:24 step:23277 [D loss: 0.447037, acc.: 79.69%] [G loss: 0.803340]\n",
      "epoch:24 step:23278 [D loss: 0.527637, acc.: 73.44%] [G loss: 1.008179]\n",
      "epoch:24 step:23279 [D loss: 0.526586, acc.: 71.88%] [G loss: 0.691446]\n",
      "epoch:24 step:23280 [D loss: 0.416711, acc.: 82.03%] [G loss: 0.949209]\n",
      "epoch:24 step:23281 [D loss: 0.619686, acc.: 67.97%] [G loss: 0.798724]\n",
      "epoch:24 step:23282 [D loss: 0.571153, acc.: 67.19%] [G loss: 0.770136]\n",
      "epoch:24 step:23283 [D loss: 0.514822, acc.: 69.53%] [G loss: 0.924234]\n",
      "epoch:24 step:23284 [D loss: 0.470546, acc.: 78.12%] [G loss: 0.873591]\n",
      "epoch:24 step:23285 [D loss: 0.510705, acc.: 68.75%] [G loss: 0.779461]\n",
      "epoch:24 step:23286 [D loss: 0.529979, acc.: 66.41%] [G loss: 0.724057]\n",
      "epoch:24 step:23287 [D loss: 0.535781, acc.: 70.31%] [G loss: 0.693019]\n",
      "epoch:24 step:23288 [D loss: 0.592484, acc.: 68.75%] [G loss: 0.781869]\n",
      "epoch:24 step:23289 [D loss: 0.472510, acc.: 77.34%] [G loss: 0.784794]\n",
      "epoch:24 step:23290 [D loss: 0.438508, acc.: 79.69%] [G loss: 0.883129]\n",
      "epoch:24 step:23291 [D loss: 0.520244, acc.: 71.88%] [G loss: 0.780779]\n",
      "epoch:24 step:23292 [D loss: 0.568882, acc.: 65.62%] [G loss: 0.806072]\n",
      "epoch:24 step:23293 [D loss: 0.502923, acc.: 77.34%] [G loss: 0.703784]\n",
      "epoch:24 step:23294 [D loss: 0.592443, acc.: 64.06%] [G loss: 0.546033]\n",
      "epoch:24 step:23295 [D loss: 0.479712, acc.: 73.44%] [G loss: 0.683071]\n",
      "epoch:24 step:23296 [D loss: 0.536533, acc.: 73.44%] [G loss: 0.794662]\n",
      "epoch:24 step:23297 [D loss: 0.488759, acc.: 73.44%] [G loss: 0.672938]\n",
      "epoch:24 step:23298 [D loss: 0.483638, acc.: 72.66%] [G loss: 0.662549]\n",
      "epoch:24 step:23299 [D loss: 0.492743, acc.: 74.22%] [G loss: 0.811461]\n",
      "epoch:24 step:23300 [D loss: 0.606052, acc.: 66.41%] [G loss: 0.500778]\n",
      "epoch:24 step:23301 [D loss: 0.531737, acc.: 71.09%] [G loss: 0.675540]\n",
      "epoch:24 step:23302 [D loss: 0.454645, acc.: 77.34%] [G loss: 0.768447]\n",
      "epoch:24 step:23303 [D loss: 0.453377, acc.: 77.34%] [G loss: 0.870303]\n",
      "epoch:24 step:23304 [D loss: 0.458725, acc.: 80.47%] [G loss: 0.774041]\n",
      "epoch:24 step:23305 [D loss: 0.607744, acc.: 67.19%] [G loss: 0.792510]\n",
      "epoch:24 step:23306 [D loss: 0.554070, acc.: 68.75%] [G loss: 0.704499]\n",
      "epoch:24 step:23307 [D loss: 0.534171, acc.: 71.88%] [G loss: 0.676671]\n",
      "epoch:24 step:23308 [D loss: 0.586915, acc.: 67.19%] [G loss: 0.675346]\n",
      "epoch:24 step:23309 [D loss: 0.532094, acc.: 68.75%] [G loss: 0.508179]\n",
      "epoch:24 step:23310 [D loss: 0.537692, acc.: 70.31%] [G loss: 0.686880]\n",
      "epoch:24 step:23311 [D loss: 0.435646, acc.: 75.78%] [G loss: 0.604128]\n",
      "epoch:24 step:23312 [D loss: 0.588348, acc.: 70.31%] [G loss: 0.641403]\n",
      "epoch:24 step:23313 [D loss: 0.541283, acc.: 73.44%] [G loss: 0.794410]\n",
      "epoch:24 step:23314 [D loss: 0.528418, acc.: 71.88%] [G loss: 0.762298]\n",
      "epoch:24 step:23315 [D loss: 0.567631, acc.: 70.31%] [G loss: 0.588082]\n",
      "epoch:24 step:23316 [D loss: 0.632486, acc.: 60.94%] [G loss: 0.558190]\n",
      "epoch:24 step:23317 [D loss: 0.524444, acc.: 72.66%] [G loss: 0.690379]\n",
      "epoch:24 step:23318 [D loss: 0.551935, acc.: 71.88%] [G loss: 0.543573]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:24 step:23319 [D loss: 0.520047, acc.: 76.56%] [G loss: 0.602668]\n",
      "epoch:24 step:23320 [D loss: 0.522444, acc.: 73.44%] [G loss: 0.634069]\n",
      "epoch:24 step:23321 [D loss: 0.498532, acc.: 76.56%] [G loss: 0.750365]\n",
      "epoch:24 step:23322 [D loss: 0.449437, acc.: 77.34%] [G loss: 0.730696]\n",
      "epoch:24 step:23323 [D loss: 0.511342, acc.: 75.78%] [G loss: 0.487070]\n",
      "epoch:24 step:23324 [D loss: 0.499569, acc.: 73.44%] [G loss: 0.709990]\n",
      "epoch:24 step:23325 [D loss: 0.496145, acc.: 77.34%] [G loss: 0.622142]\n",
      "epoch:24 step:23326 [D loss: 0.558382, acc.: 71.09%] [G loss: 0.709533]\n",
      "epoch:24 step:23327 [D loss: 0.578493, acc.: 65.62%] [G loss: 0.601682]\n",
      "epoch:24 step:23328 [D loss: 0.563482, acc.: 71.88%] [G loss: 0.597001]\n",
      "epoch:24 step:23329 [D loss: 0.582414, acc.: 67.97%] [G loss: 0.646480]\n",
      "epoch:24 step:23330 [D loss: 0.493840, acc.: 76.56%] [G loss: 0.686974]\n",
      "epoch:24 step:23331 [D loss: 0.472934, acc.: 79.69%] [G loss: 0.663729]\n",
      "epoch:24 step:23332 [D loss: 0.517474, acc.: 74.22%] [G loss: 0.765128]\n",
      "epoch:24 step:23333 [D loss: 0.552788, acc.: 69.53%] [G loss: 0.721188]\n",
      "epoch:24 step:23334 [D loss: 0.564498, acc.: 68.75%] [G loss: 0.497198]\n",
      "epoch:24 step:23335 [D loss: 0.601717, acc.: 65.62%] [G loss: 0.591575]\n",
      "epoch:24 step:23336 [D loss: 0.534661, acc.: 67.97%] [G loss: 0.586414]\n",
      "epoch:24 step:23337 [D loss: 0.520864, acc.: 68.75%] [G loss: 0.760257]\n",
      "epoch:24 step:23338 [D loss: 0.515643, acc.: 73.44%] [G loss: 0.707859]\n",
      "epoch:24 step:23339 [D loss: 0.567158, acc.: 67.19%] [G loss: 0.650038]\n",
      "epoch:24 step:23340 [D loss: 0.545118, acc.: 71.88%] [G loss: 0.527745]\n",
      "epoch:24 step:23341 [D loss: 0.508461, acc.: 71.88%] [G loss: 0.725249]\n",
      "epoch:24 step:23342 [D loss: 0.518233, acc.: 71.09%] [G loss: 0.715602]\n",
      "epoch:24 step:23343 [D loss: 0.558176, acc.: 68.75%] [G loss: 0.681914]\n",
      "epoch:24 step:23344 [D loss: 0.620904, acc.: 62.50%] [G loss: 0.659613]\n",
      "epoch:24 step:23345 [D loss: 0.505886, acc.: 73.44%] [G loss: 0.638305]\n",
      "epoch:24 step:23346 [D loss: 0.598441, acc.: 67.19%] [G loss: 0.761584]\n",
      "epoch:24 step:23347 [D loss: 0.537010, acc.: 75.00%] [G loss: 0.800848]\n",
      "epoch:24 step:23348 [D loss: 0.433287, acc.: 82.81%] [G loss: 0.838041]\n",
      "epoch:24 step:23349 [D loss: 0.642939, acc.: 60.16%] [G loss: 0.578033]\n",
      "epoch:24 step:23350 [D loss: 0.490192, acc.: 71.09%] [G loss: 0.626671]\n",
      "epoch:24 step:23351 [D loss: 0.554603, acc.: 68.75%] [G loss: 0.552596]\n",
      "epoch:24 step:23352 [D loss: 0.545185, acc.: 62.50%] [G loss: 0.636590]\n",
      "epoch:24 step:23353 [D loss: 0.571450, acc.: 64.84%] [G loss: 0.684094]\n",
      "epoch:24 step:23354 [D loss: 0.524824, acc.: 68.75%] [G loss: 0.621304]\n",
      "epoch:24 step:23355 [D loss: 0.654348, acc.: 61.72%] [G loss: 0.545308]\n",
      "epoch:24 step:23356 [D loss: 0.498966, acc.: 78.12%] [G loss: 0.565828]\n",
      "epoch:24 step:23357 [D loss: 0.608236, acc.: 57.81%] [G loss: 0.528869]\n",
      "epoch:24 step:23358 [D loss: 0.459853, acc.: 76.56%] [G loss: 0.726193]\n",
      "epoch:24 step:23359 [D loss: 0.477266, acc.: 76.56%] [G loss: 0.692024]\n",
      "epoch:24 step:23360 [D loss: 0.550235, acc.: 69.53%] [G loss: 0.857346]\n",
      "epoch:24 step:23361 [D loss: 0.616605, acc.: 60.16%] [G loss: 0.691530]\n",
      "epoch:24 step:23362 [D loss: 0.510757, acc.: 76.56%] [G loss: 0.837670]\n",
      "epoch:24 step:23363 [D loss: 0.461445, acc.: 75.78%] [G loss: 0.787020]\n",
      "epoch:24 step:23364 [D loss: 0.500893, acc.: 72.66%] [G loss: 0.730169]\n",
      "epoch:24 step:23365 [D loss: 0.556422, acc.: 70.31%] [G loss: 0.603878]\n",
      "epoch:24 step:23366 [D loss: 0.521699, acc.: 73.44%] [G loss: 0.671173]\n",
      "epoch:24 step:23367 [D loss: 0.572852, acc.: 65.62%] [G loss: 0.588909]\n",
      "epoch:24 step:23368 [D loss: 0.645938, acc.: 67.97%] [G loss: 0.548274]\n",
      "epoch:24 step:23369 [D loss: 0.618985, acc.: 58.59%] [G loss: 0.529493]\n",
      "epoch:24 step:23370 [D loss: 0.590208, acc.: 65.62%] [G loss: 0.548280]\n",
      "epoch:24 step:23371 [D loss: 0.590838, acc.: 68.75%] [G loss: 0.679135]\n",
      "epoch:24 step:23372 [D loss: 0.491192, acc.: 72.66%] [G loss: 0.575247]\n",
      "epoch:24 step:23373 [D loss: 0.517714, acc.: 71.88%] [G loss: 0.851378]\n",
      "epoch:24 step:23374 [D loss: 0.516341, acc.: 69.53%] [G loss: 0.884907]\n",
      "epoch:24 step:23375 [D loss: 0.499273, acc.: 75.00%] [G loss: 0.807668]\n",
      "epoch:24 step:23376 [D loss: 0.545928, acc.: 70.31%] [G loss: 0.720765]\n",
      "epoch:24 step:23377 [D loss: 0.539136, acc.: 68.75%] [G loss: 0.436680]\n",
      "epoch:24 step:23378 [D loss: 0.514677, acc.: 72.66%] [G loss: 0.816237]\n",
      "epoch:24 step:23379 [D loss: 0.582689, acc.: 66.41%] [G loss: 0.851296]\n",
      "epoch:24 step:23380 [D loss: 0.602309, acc.: 67.97%] [G loss: 0.561421]\n",
      "epoch:24 step:23381 [D loss: 0.545172, acc.: 69.53%] [G loss: 0.648465]\n",
      "epoch:24 step:23382 [D loss: 0.460057, acc.: 77.34%] [G loss: 0.657933]\n",
      "epoch:24 step:23383 [D loss: 0.521079, acc.: 70.31%] [G loss: 0.808572]\n",
      "epoch:24 step:23384 [D loss: 0.534229, acc.: 67.19%] [G loss: 0.764051]\n",
      "epoch:24 step:23385 [D loss: 0.497466, acc.: 73.44%] [G loss: 0.820936]\n",
      "epoch:24 step:23386 [D loss: 0.431886, acc.: 79.69%] [G loss: 1.091713]\n",
      "epoch:24 step:23387 [D loss: 0.489461, acc.: 75.78%] [G loss: 0.796627]\n",
      "epoch:24 step:23388 [D loss: 0.475016, acc.: 79.69%] [G loss: 0.812815]\n",
      "epoch:24 step:23389 [D loss: 0.570466, acc.: 68.75%] [G loss: 0.699358]\n",
      "epoch:24 step:23390 [D loss: 0.532356, acc.: 75.78%] [G loss: 0.717896]\n",
      "epoch:24 step:23391 [D loss: 0.531063, acc.: 73.44%] [G loss: 0.585560]\n",
      "epoch:24 step:23392 [D loss: 0.526003, acc.: 71.88%] [G loss: 0.760172]\n",
      "epoch:24 step:23393 [D loss: 0.515552, acc.: 72.66%] [G loss: 0.700978]\n",
      "epoch:24 step:23394 [D loss: 0.526113, acc.: 72.66%] [G loss: 0.731382]\n",
      "epoch:24 step:23395 [D loss: 0.564898, acc.: 68.75%] [G loss: 0.773917]\n",
      "epoch:24 step:23396 [D loss: 0.573229, acc.: 68.75%] [G loss: 0.763907]\n",
      "epoch:24 step:23397 [D loss: 0.511285, acc.: 74.22%] [G loss: 0.699736]\n",
      "epoch:24 step:23398 [D loss: 0.556744, acc.: 67.19%] [G loss: 0.757770]\n",
      "epoch:24 step:23399 [D loss: 0.471899, acc.: 79.69%] [G loss: 0.845712]\n",
      "epoch:24 step:23400 [D loss: 0.452284, acc.: 80.47%] [G loss: 0.816477]\n",
      "epoch:24 step:23401 [D loss: 0.553181, acc.: 70.31%] [G loss: 0.918820]\n",
      "epoch:24 step:23402 [D loss: 0.491231, acc.: 71.09%] [G loss: 1.026537]\n",
      "epoch:24 step:23403 [D loss: 0.723644, acc.: 58.59%] [G loss: 0.751904]\n",
      "epoch:24 step:23404 [D loss: 0.503331, acc.: 75.00%] [G loss: 0.755464]\n",
      "epoch:24 step:23405 [D loss: 0.602580, acc.: 69.53%] [G loss: 0.651718]\n",
      "epoch:24 step:23406 [D loss: 0.485686, acc.: 75.78%] [G loss: 0.793430]\n",
      "epoch:24 step:23407 [D loss: 0.435933, acc.: 79.69%] [G loss: 0.817145]\n",
      "epoch:24 step:23408 [D loss: 0.672096, acc.: 57.81%] [G loss: 0.689733]\n",
      "epoch:24 step:23409 [D loss: 0.452867, acc.: 76.56%] [G loss: 0.912119]\n",
      "epoch:24 step:23410 [D loss: 0.483179, acc.: 73.44%] [G loss: 0.678549]\n",
      "epoch:24 step:23411 [D loss: 0.426865, acc.: 78.91%] [G loss: 0.868826]\n",
      "epoch:24 step:23412 [D loss: 0.486867, acc.: 73.44%] [G loss: 0.799997]\n",
      "epoch:24 step:23413 [D loss: 0.411226, acc.: 82.03%] [G loss: 1.042299]\n",
      "epoch:24 step:23414 [D loss: 0.426353, acc.: 77.34%] [G loss: 1.043585]\n",
      "epoch:24 step:23415 [D loss: 0.454027, acc.: 73.44%] [G loss: 1.160983]\n",
      "epoch:24 step:23416 [D loss: 0.735055, acc.: 60.16%] [G loss: 1.007287]\n",
      "epoch:24 step:23417 [D loss: 0.511878, acc.: 75.78%] [G loss: 1.417770]\n",
      "epoch:24 step:23418 [D loss: 0.469275, acc.: 75.00%] [G loss: 1.322011]\n",
      "epoch:24 step:23419 [D loss: 0.515063, acc.: 75.00%] [G loss: 0.823720]\n",
      "epoch:24 step:23420 [D loss: 0.607040, acc.: 67.19%] [G loss: 0.836226]\n",
      "epoch:24 step:23421 [D loss: 0.446387, acc.: 78.91%] [G loss: 0.750785]\n",
      "epoch:24 step:23422 [D loss: 0.523006, acc.: 71.09%] [G loss: 0.868962]\n",
      "epoch:24 step:23423 [D loss: 0.508087, acc.: 76.56%] [G loss: 0.885524]\n",
      "epoch:24 step:23424 [D loss: 0.368563, acc.: 84.38%] [G loss: 1.162520]\n",
      "epoch:24 step:23425 [D loss: 0.458299, acc.: 82.03%] [G loss: 1.280418]\n",
      "epoch:25 step:23426 [D loss: 0.543763, acc.: 72.66%] [G loss: 1.011852]\n",
      "epoch:25 step:23427 [D loss: 0.459842, acc.: 81.25%] [G loss: 1.128749]\n",
      "epoch:25 step:23428 [D loss: 0.551893, acc.: 70.31%] [G loss: 0.944380]\n",
      "epoch:25 step:23429 [D loss: 0.495932, acc.: 78.91%] [G loss: 0.885809]\n",
      "epoch:25 step:23430 [D loss: 0.508038, acc.: 75.78%] [G loss: 0.715425]\n",
      "epoch:25 step:23431 [D loss: 0.595608, acc.: 67.19%] [G loss: 0.800832]\n",
      "epoch:25 step:23432 [D loss: 0.500316, acc.: 74.22%] [G loss: 0.882957]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:25 step:23433 [D loss: 0.488212, acc.: 74.22%] [G loss: 0.916902]\n",
      "epoch:25 step:23434 [D loss: 0.494071, acc.: 74.22%] [G loss: 0.860451]\n",
      "epoch:25 step:23435 [D loss: 0.488199, acc.: 77.34%] [G loss: 0.873571]\n",
      "epoch:25 step:23436 [D loss: 0.481665, acc.: 81.25%] [G loss: 0.742134]\n",
      "epoch:25 step:23437 [D loss: 0.533542, acc.: 71.09%] [G loss: 0.857093]\n",
      "epoch:25 step:23438 [D loss: 0.557061, acc.: 67.97%] [G loss: 0.560437]\n",
      "epoch:25 step:23439 [D loss: 0.533063, acc.: 71.88%] [G loss: 0.662273]\n",
      "epoch:25 step:23440 [D loss: 0.464116, acc.: 79.69%] [G loss: 0.734783]\n",
      "epoch:25 step:23441 [D loss: 0.459307, acc.: 78.91%] [G loss: 0.917556]\n",
      "epoch:25 step:23442 [D loss: 0.531176, acc.: 73.44%] [G loss: 0.891833]\n",
      "epoch:25 step:23443 [D loss: 0.582359, acc.: 70.31%] [G loss: 0.893602]\n",
      "epoch:25 step:23444 [D loss: 0.531248, acc.: 73.44%] [G loss: 0.828293]\n",
      "epoch:25 step:23445 [D loss: 0.678291, acc.: 61.72%] [G loss: 0.712580]\n",
      "epoch:25 step:23446 [D loss: 0.549842, acc.: 70.31%] [G loss: 0.737523]\n",
      "epoch:25 step:23447 [D loss: 0.504678, acc.: 75.00%] [G loss: 0.991404]\n",
      "epoch:25 step:23448 [D loss: 0.455304, acc.: 77.34%] [G loss: 0.827665]\n",
      "epoch:25 step:23449 [D loss: 0.542872, acc.: 72.66%] [G loss: 0.665959]\n",
      "epoch:25 step:23450 [D loss: 0.509001, acc.: 75.00%] [G loss: 0.829086]\n",
      "epoch:25 step:23451 [D loss: 0.553109, acc.: 70.31%] [G loss: 0.660032]\n",
      "epoch:25 step:23452 [D loss: 0.444305, acc.: 78.91%] [G loss: 0.670662]\n",
      "epoch:25 step:23453 [D loss: 0.535957, acc.: 68.75%] [G loss: 0.783108]\n",
      "epoch:25 step:23454 [D loss: 0.491269, acc.: 77.34%] [G loss: 0.809773]\n",
      "epoch:25 step:23455 [D loss: 0.519342, acc.: 69.53%] [G loss: 0.797439]\n",
      "epoch:25 step:23456 [D loss: 0.611706, acc.: 63.28%] [G loss: 0.631030]\n",
      "epoch:25 step:23457 [D loss: 0.498382, acc.: 74.22%] [G loss: 0.574838]\n",
      "epoch:25 step:23458 [D loss: 0.556151, acc.: 67.97%] [G loss: 0.748846]\n",
      "epoch:25 step:23459 [D loss: 0.536312, acc.: 67.97%] [G loss: 0.682840]\n",
      "epoch:25 step:23460 [D loss: 0.568722, acc.: 70.31%] [G loss: 0.666502]\n",
      "epoch:25 step:23461 [D loss: 0.501384, acc.: 74.22%] [G loss: 0.788148]\n",
      "epoch:25 step:23462 [D loss: 0.441499, acc.: 78.91%] [G loss: 0.708319]\n",
      "epoch:25 step:23463 [D loss: 0.566678, acc.: 70.31%] [G loss: 0.535444]\n",
      "epoch:25 step:23464 [D loss: 0.554887, acc.: 68.75%] [G loss: 0.653389]\n",
      "epoch:25 step:23465 [D loss: 0.442538, acc.: 81.25%] [G loss: 0.843653]\n",
      "epoch:25 step:23466 [D loss: 0.524464, acc.: 71.88%] [G loss: 0.752785]\n",
      "epoch:25 step:23467 [D loss: 0.529090, acc.: 71.88%] [G loss: 0.723136]\n",
      "epoch:25 step:23468 [D loss: 0.491952, acc.: 71.09%] [G loss: 0.689559]\n",
      "epoch:25 step:23469 [D loss: 0.538906, acc.: 67.97%] [G loss: 0.676892]\n",
      "epoch:25 step:23470 [D loss: 0.440688, acc.: 75.78%] [G loss: 0.864255]\n",
      "epoch:25 step:23471 [D loss: 0.456044, acc.: 75.00%] [G loss: 0.834923]\n",
      "epoch:25 step:23472 [D loss: 0.532608, acc.: 70.31%] [G loss: 0.910846]\n",
      "epoch:25 step:23473 [D loss: 0.528474, acc.: 73.44%] [G loss: 0.678327]\n",
      "epoch:25 step:23474 [D loss: 0.433646, acc.: 80.47%] [G loss: 0.825596]\n",
      "epoch:25 step:23475 [D loss: 0.555890, acc.: 70.31%] [G loss: 0.816716]\n",
      "epoch:25 step:23476 [D loss: 0.643674, acc.: 63.28%] [G loss: 0.634221]\n",
      "epoch:25 step:23477 [D loss: 0.543056, acc.: 66.41%] [G loss: 0.589143]\n",
      "epoch:25 step:23478 [D loss: 0.498225, acc.: 72.66%] [G loss: 0.824300]\n",
      "epoch:25 step:23479 [D loss: 0.467510, acc.: 75.78%] [G loss: 0.729929]\n",
      "epoch:25 step:23480 [D loss: 0.532472, acc.: 72.66%] [G loss: 0.750224]\n",
      "epoch:25 step:23481 [D loss: 0.547490, acc.: 73.44%] [G loss: 0.813181]\n",
      "epoch:25 step:23482 [D loss: 0.473609, acc.: 78.12%] [G loss: 0.780660]\n",
      "epoch:25 step:23483 [D loss: 0.569936, acc.: 71.09%] [G loss: 0.778692]\n",
      "epoch:25 step:23484 [D loss: 0.477357, acc.: 79.69%] [G loss: 0.773945]\n",
      "epoch:25 step:23485 [D loss: 0.547034, acc.: 71.88%] [G loss: 0.715982]\n",
      "epoch:25 step:23486 [D loss: 0.508278, acc.: 75.78%] [G loss: 0.640550]\n",
      "epoch:25 step:23487 [D loss: 0.520179, acc.: 74.22%] [G loss: 0.639364]\n",
      "epoch:25 step:23488 [D loss: 0.481021, acc.: 75.78%] [G loss: 0.685179]\n",
      "epoch:25 step:23489 [D loss: 0.609820, acc.: 71.09%] [G loss: 0.746788]\n",
      "epoch:25 step:23490 [D loss: 0.470267, acc.: 77.34%] [G loss: 0.624125]\n",
      "epoch:25 step:23491 [D loss: 0.536615, acc.: 66.41%] [G loss: 0.669999]\n",
      "epoch:25 step:23492 [D loss: 0.489268, acc.: 76.56%] [G loss: 0.689398]\n",
      "epoch:25 step:23493 [D loss: 0.513426, acc.: 71.88%] [G loss: 0.638448]\n",
      "epoch:25 step:23494 [D loss: 0.475184, acc.: 77.34%] [G loss: 0.703748]\n",
      "epoch:25 step:23495 [D loss: 0.540564, acc.: 69.53%] [G loss: 0.826135]\n",
      "epoch:25 step:23496 [D loss: 0.472429, acc.: 73.44%] [G loss: 0.778810]\n",
      "epoch:25 step:23497 [D loss: 0.495906, acc.: 72.66%] [G loss: 0.642298]\n",
      "epoch:25 step:23498 [D loss: 0.535206, acc.: 69.53%] [G loss: 0.725124]\n",
      "epoch:25 step:23499 [D loss: 0.495366, acc.: 74.22%] [G loss: 0.602288]\n",
      "epoch:25 step:23500 [D loss: 0.497763, acc.: 74.22%] [G loss: 0.740369]\n",
      "epoch:25 step:23501 [D loss: 0.511462, acc.: 71.09%] [G loss: 0.737901]\n",
      "epoch:25 step:23502 [D loss: 0.399073, acc.: 82.03%] [G loss: 0.988287]\n",
      "epoch:25 step:23503 [D loss: 0.548763, acc.: 67.97%] [G loss: 0.714799]\n",
      "epoch:25 step:23504 [D loss: 0.519456, acc.: 71.09%] [G loss: 0.730050]\n",
      "epoch:25 step:23505 [D loss: 0.524262, acc.: 69.53%] [G loss: 0.748711]\n",
      "epoch:25 step:23506 [D loss: 0.550642, acc.: 67.19%] [G loss: 0.729865]\n",
      "epoch:25 step:23507 [D loss: 0.497320, acc.: 74.22%] [G loss: 0.678515]\n",
      "epoch:25 step:23508 [D loss: 0.448609, acc.: 78.12%] [G loss: 0.757909]\n",
      "epoch:25 step:23509 [D loss: 0.515684, acc.: 73.44%] [G loss: 0.746781]\n",
      "epoch:25 step:23510 [D loss: 0.560474, acc.: 64.06%] [G loss: 0.626157]\n",
      "epoch:25 step:23511 [D loss: 0.505424, acc.: 74.22%] [G loss: 0.543031]\n",
      "epoch:25 step:23512 [D loss: 0.481664, acc.: 75.78%] [G loss: 0.671529]\n",
      "epoch:25 step:23513 [D loss: 0.547080, acc.: 72.66%] [G loss: 0.764301]\n",
      "epoch:25 step:23514 [D loss: 0.449160, acc.: 80.47%] [G loss: 0.981485]\n",
      "epoch:25 step:23515 [D loss: 0.509533, acc.: 74.22%] [G loss: 0.827397]\n",
      "epoch:25 step:23516 [D loss: 0.606736, acc.: 61.72%] [G loss: 0.828448]\n",
      "epoch:25 step:23517 [D loss: 0.464411, acc.: 75.78%] [G loss: 0.817891]\n",
      "epoch:25 step:23518 [D loss: 0.527754, acc.: 75.78%] [G loss: 0.824368]\n",
      "epoch:25 step:23519 [D loss: 0.481185, acc.: 71.88%] [G loss: 0.942087]\n",
      "epoch:25 step:23520 [D loss: 0.539346, acc.: 71.09%] [G loss: 0.955410]\n",
      "epoch:25 step:23521 [D loss: 0.532723, acc.: 70.31%] [G loss: 0.833656]\n",
      "epoch:25 step:23522 [D loss: 0.497042, acc.: 75.00%] [G loss: 0.854032]\n",
      "epoch:25 step:23523 [D loss: 0.521563, acc.: 75.00%] [G loss: 0.805303]\n",
      "epoch:25 step:23524 [D loss: 0.513010, acc.: 69.53%] [G loss: 1.010166]\n",
      "epoch:25 step:23525 [D loss: 0.455128, acc.: 75.78%] [G loss: 0.914486]\n",
      "epoch:25 step:23526 [D loss: 0.517003, acc.: 74.22%] [G loss: 0.756380]\n",
      "epoch:25 step:23527 [D loss: 0.594384, acc.: 65.62%] [G loss: 0.683033]\n",
      "epoch:25 step:23528 [D loss: 0.531177, acc.: 70.31%] [G loss: 0.541212]\n",
      "epoch:25 step:23529 [D loss: 0.509365, acc.: 71.88%] [G loss: 0.660360]\n",
      "epoch:25 step:23530 [D loss: 0.541455, acc.: 71.09%] [G loss: 0.823788]\n",
      "epoch:25 step:23531 [D loss: 0.516370, acc.: 71.88%] [G loss: 0.687615]\n",
      "epoch:25 step:23532 [D loss: 0.511321, acc.: 78.91%] [G loss: 0.834699]\n",
      "epoch:25 step:23533 [D loss: 0.608373, acc.: 66.41%] [G loss: 0.844806]\n",
      "epoch:25 step:23534 [D loss: 0.544763, acc.: 71.09%] [G loss: 0.863520]\n",
      "epoch:25 step:23535 [D loss: 0.589602, acc.: 66.41%] [G loss: 0.865029]\n",
      "epoch:25 step:23536 [D loss: 0.520941, acc.: 74.22%] [G loss: 0.949939]\n",
      "epoch:25 step:23537 [D loss: 0.511142, acc.: 74.22%] [G loss: 0.703989]\n",
      "epoch:25 step:23538 [D loss: 0.533686, acc.: 69.53%] [G loss: 0.759399]\n",
      "epoch:25 step:23539 [D loss: 0.516799, acc.: 71.09%] [G loss: 0.740956]\n",
      "epoch:25 step:23540 [D loss: 0.510566, acc.: 75.78%] [G loss: 0.768437]\n",
      "epoch:25 step:23541 [D loss: 0.471430, acc.: 74.22%] [G loss: 0.659034]\n",
      "epoch:25 step:23542 [D loss: 0.524911, acc.: 69.53%] [G loss: 0.760190]\n",
      "epoch:25 step:23543 [D loss: 0.490539, acc.: 71.88%] [G loss: 1.114661]\n",
      "epoch:25 step:23544 [D loss: 0.458339, acc.: 76.56%] [G loss: 1.113582]\n",
      "epoch:25 step:23545 [D loss: 0.490169, acc.: 73.44%] [G loss: 0.789917]\n",
      "epoch:25 step:23546 [D loss: 0.486509, acc.: 77.34%] [G loss: 0.795128]\n",
      "epoch:25 step:23547 [D loss: 0.463563, acc.: 81.25%] [G loss: 0.877011]\n",
      "epoch:25 step:23548 [D loss: 0.495273, acc.: 72.66%] [G loss: 1.067791]\n",
      "epoch:25 step:23549 [D loss: 0.527799, acc.: 74.22%] [G loss: 0.822580]\n",
      "epoch:25 step:23550 [D loss: 0.576995, acc.: 67.97%] [G loss: 0.883642]\n",
      "epoch:25 step:23551 [D loss: 0.452550, acc.: 76.56%] [G loss: 0.830395]\n",
      "epoch:25 step:23552 [D loss: 0.441529, acc.: 78.91%] [G loss: 0.916188]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:25 step:23553 [D loss: 0.472063, acc.: 73.44%] [G loss: 0.978872]\n",
      "epoch:25 step:23554 [D loss: 0.577302, acc.: 66.41%] [G loss: 0.659520]\n",
      "epoch:25 step:23555 [D loss: 0.437824, acc.: 81.25%] [G loss: 0.781108]\n",
      "epoch:25 step:23556 [D loss: 0.439646, acc.: 78.12%] [G loss: 0.881991]\n",
      "epoch:25 step:23557 [D loss: 0.521952, acc.: 75.00%] [G loss: 0.726963]\n",
      "epoch:25 step:23558 [D loss: 0.502835, acc.: 73.44%] [G loss: 0.820078]\n",
      "epoch:25 step:23559 [D loss: 0.516949, acc.: 70.31%] [G loss: 0.991439]\n",
      "epoch:25 step:23560 [D loss: 0.492593, acc.: 74.22%] [G loss: 0.856324]\n",
      "epoch:25 step:23561 [D loss: 0.573019, acc.: 68.75%] [G loss: 0.862301]\n",
      "epoch:25 step:23562 [D loss: 0.624016, acc.: 64.06%] [G loss: 0.637664]\n",
      "epoch:25 step:23563 [D loss: 0.657078, acc.: 67.19%] [G loss: 0.853209]\n",
      "epoch:25 step:23564 [D loss: 0.489550, acc.: 75.00%] [G loss: 0.702608]\n",
      "epoch:25 step:23565 [D loss: 0.547136, acc.: 70.31%] [G loss: 0.642139]\n",
      "epoch:25 step:23566 [D loss: 0.491109, acc.: 74.22%] [G loss: 0.760122]\n",
      "epoch:25 step:23567 [D loss: 0.552287, acc.: 73.44%] [G loss: 0.655667]\n",
      "epoch:25 step:23568 [D loss: 0.601921, acc.: 61.72%] [G loss: 0.597725]\n",
      "epoch:25 step:23569 [D loss: 0.484299, acc.: 76.56%] [G loss: 0.633269]\n",
      "epoch:25 step:23570 [D loss: 0.530374, acc.: 67.19%] [G loss: 0.693837]\n",
      "epoch:25 step:23571 [D loss: 0.465259, acc.: 81.25%] [G loss: 0.757502]\n",
      "epoch:25 step:23572 [D loss: 0.589854, acc.: 70.31%] [G loss: 0.696237]\n",
      "epoch:25 step:23573 [D loss: 0.553735, acc.: 65.62%] [G loss: 0.527556]\n",
      "epoch:25 step:23574 [D loss: 0.535178, acc.: 71.09%] [G loss: 0.656549]\n",
      "epoch:25 step:23575 [D loss: 0.605255, acc.: 66.41%] [G loss: 0.695751]\n",
      "epoch:25 step:23576 [D loss: 0.508007, acc.: 73.44%] [G loss: 0.707945]\n",
      "epoch:25 step:23577 [D loss: 0.524054, acc.: 71.88%] [G loss: 0.827605]\n",
      "epoch:25 step:23578 [D loss: 0.575109, acc.: 68.75%] [G loss: 0.679209]\n",
      "epoch:25 step:23579 [D loss: 0.552075, acc.: 67.19%] [G loss: 0.654411]\n",
      "epoch:25 step:23580 [D loss: 0.438800, acc.: 78.12%] [G loss: 0.855563]\n",
      "epoch:25 step:23581 [D loss: 0.467457, acc.: 77.34%] [G loss: 0.843241]\n",
      "epoch:25 step:23582 [D loss: 0.534364, acc.: 70.31%] [G loss: 0.748595]\n",
      "epoch:25 step:23583 [D loss: 0.558061, acc.: 71.88%] [G loss: 0.668947]\n",
      "epoch:25 step:23584 [D loss: 0.456029, acc.: 78.91%] [G loss: 0.804467]\n",
      "epoch:25 step:23585 [D loss: 0.620866, acc.: 67.97%] [G loss: 0.705670]\n",
      "epoch:25 step:23586 [D loss: 0.497078, acc.: 75.78%] [G loss: 0.860333]\n",
      "epoch:25 step:23587 [D loss: 0.464696, acc.: 77.34%] [G loss: 0.947559]\n",
      "epoch:25 step:23588 [D loss: 0.525147, acc.: 70.31%] [G loss: 0.874405]\n",
      "epoch:25 step:23589 [D loss: 0.576970, acc.: 64.06%] [G loss: 0.627724]\n",
      "epoch:25 step:23590 [D loss: 0.444175, acc.: 82.03%] [G loss: 0.936565]\n",
      "epoch:25 step:23591 [D loss: 0.612044, acc.: 62.50%] [G loss: 0.645589]\n",
      "epoch:25 step:23592 [D loss: 0.590710, acc.: 66.41%] [G loss: 0.584986]\n",
      "epoch:25 step:23593 [D loss: 0.524335, acc.: 73.44%] [G loss: 0.734970]\n",
      "epoch:25 step:23594 [D loss: 0.573585, acc.: 68.75%] [G loss: 0.595835]\n",
      "epoch:25 step:23595 [D loss: 0.543067, acc.: 67.97%] [G loss: 0.491079]\n",
      "epoch:25 step:23596 [D loss: 0.553043, acc.: 70.31%] [G loss: 0.657264]\n",
      "epoch:25 step:23597 [D loss: 0.494821, acc.: 71.88%] [G loss: 0.509937]\n",
      "epoch:25 step:23598 [D loss: 0.522297, acc.: 76.56%] [G loss: 0.821314]\n",
      "epoch:25 step:23599 [D loss: 0.585368, acc.: 67.97%] [G loss: 0.691590]\n",
      "epoch:25 step:23600 [D loss: 0.600849, acc.: 64.06%] [G loss: 0.554282]\n",
      "epoch:25 step:23601 [D loss: 0.479964, acc.: 75.78%] [G loss: 0.882032]\n",
      "epoch:25 step:23602 [D loss: 0.502386, acc.: 75.00%] [G loss: 0.724711]\n",
      "epoch:25 step:23603 [D loss: 0.551593, acc.: 69.53%] [G loss: 0.698276]\n",
      "epoch:25 step:23604 [D loss: 0.499641, acc.: 75.00%] [G loss: 0.613603]\n",
      "epoch:25 step:23605 [D loss: 0.601375, acc.: 64.06%] [G loss: 0.594903]\n",
      "epoch:25 step:23606 [D loss: 0.604795, acc.: 64.06%] [G loss: 0.473758]\n",
      "epoch:25 step:23607 [D loss: 0.489405, acc.: 72.66%] [G loss: 0.688768]\n",
      "epoch:25 step:23608 [D loss: 0.573650, acc.: 67.97%] [G loss: 0.807334]\n",
      "epoch:25 step:23609 [D loss: 0.546847, acc.: 70.31%] [G loss: 0.819171]\n",
      "epoch:25 step:23610 [D loss: 0.535439, acc.: 69.53%] [G loss: 0.940508]\n",
      "epoch:25 step:23611 [D loss: 0.517422, acc.: 72.66%] [G loss: 0.798168]\n",
      "epoch:25 step:23612 [D loss: 0.580512, acc.: 65.62%] [G loss: 0.681787]\n",
      "epoch:25 step:23613 [D loss: 0.550762, acc.: 63.28%] [G loss: 0.710754]\n",
      "epoch:25 step:23614 [D loss: 0.628709, acc.: 64.06%] [G loss: 0.504938]\n",
      "epoch:25 step:23615 [D loss: 0.503220, acc.: 73.44%] [G loss: 0.519901]\n",
      "epoch:25 step:23616 [D loss: 0.451233, acc.: 78.91%] [G loss: 0.841998]\n",
      "epoch:25 step:23617 [D loss: 0.465651, acc.: 78.12%] [G loss: 0.744929]\n",
      "epoch:25 step:23618 [D loss: 0.547745, acc.: 74.22%] [G loss: 0.754154]\n",
      "epoch:25 step:23619 [D loss: 0.416029, acc.: 83.59%] [G loss: 0.749616]\n",
      "epoch:25 step:23620 [D loss: 0.535640, acc.: 72.66%] [G loss: 0.736634]\n",
      "epoch:25 step:23621 [D loss: 0.518452, acc.: 71.88%] [G loss: 0.819065]\n",
      "epoch:25 step:23622 [D loss: 0.467273, acc.: 76.56%] [G loss: 0.802836]\n",
      "epoch:25 step:23623 [D loss: 0.457112, acc.: 81.25%] [G loss: 0.962570]\n",
      "epoch:25 step:23624 [D loss: 0.507785, acc.: 74.22%] [G loss: 0.883860]\n",
      "epoch:25 step:23625 [D loss: 0.582943, acc.: 70.31%] [G loss: 0.812193]\n",
      "epoch:25 step:23626 [D loss: 0.520008, acc.: 71.88%] [G loss: 0.655693]\n",
      "epoch:25 step:23627 [D loss: 0.549101, acc.: 71.09%] [G loss: 0.857349]\n",
      "epoch:25 step:23628 [D loss: 0.542875, acc.: 67.19%] [G loss: 0.727281]\n",
      "epoch:25 step:23629 [D loss: 0.588929, acc.: 67.97%] [G loss: 0.762237]\n",
      "epoch:25 step:23630 [D loss: 0.464463, acc.: 76.56%] [G loss: 0.749623]\n",
      "epoch:25 step:23631 [D loss: 0.464841, acc.: 75.78%] [G loss: 0.979066]\n",
      "epoch:25 step:23632 [D loss: 0.415826, acc.: 83.59%] [G loss: 0.944857]\n",
      "epoch:25 step:23633 [D loss: 0.388404, acc.: 83.59%] [G loss: 1.000822]\n",
      "epoch:25 step:23634 [D loss: 0.496379, acc.: 78.12%] [G loss: 0.891070]\n",
      "epoch:25 step:23635 [D loss: 0.629840, acc.: 64.84%] [G loss: 0.638330]\n",
      "epoch:25 step:23636 [D loss: 0.555508, acc.: 70.31%] [G loss: 0.664072]\n",
      "epoch:25 step:23637 [D loss: 0.486161, acc.: 77.34%] [G loss: 0.610472]\n",
      "epoch:25 step:23638 [D loss: 0.464643, acc.: 77.34%] [G loss: 0.638811]\n",
      "epoch:25 step:23639 [D loss: 0.559337, acc.: 71.88%] [G loss: 0.571292]\n",
      "epoch:25 step:23640 [D loss: 0.584672, acc.: 64.84%] [G loss: 0.691276]\n",
      "epoch:25 step:23641 [D loss: 0.498866, acc.: 73.44%] [G loss: 0.815618]\n",
      "epoch:25 step:23642 [D loss: 0.505772, acc.: 77.34%] [G loss: 0.759733]\n",
      "epoch:25 step:23643 [D loss: 0.459310, acc.: 81.25%] [G loss: 1.028507]\n",
      "epoch:25 step:23644 [D loss: 0.500555, acc.: 74.22%] [G loss: 0.979306]\n",
      "epoch:25 step:23645 [D loss: 0.685058, acc.: 62.50%] [G loss: 0.797118]\n",
      "epoch:25 step:23646 [D loss: 0.552324, acc.: 68.75%] [G loss: 0.758959]\n",
      "epoch:25 step:23647 [D loss: 0.524440, acc.: 74.22%] [G loss: 0.853575]\n",
      "epoch:25 step:23648 [D loss: 0.507747, acc.: 77.34%] [G loss: 0.841739]\n",
      "epoch:25 step:23649 [D loss: 0.516184, acc.: 75.00%] [G loss: 0.753558]\n",
      "epoch:25 step:23650 [D loss: 0.513830, acc.: 71.88%] [G loss: 0.658376]\n",
      "epoch:25 step:23651 [D loss: 0.649497, acc.: 59.38%] [G loss: 0.727899]\n",
      "epoch:25 step:23652 [D loss: 0.473617, acc.: 78.12%] [G loss: 0.684875]\n",
      "epoch:25 step:23653 [D loss: 0.576323, acc.: 66.41%] [G loss: 0.744958]\n",
      "epoch:25 step:23654 [D loss: 0.499911, acc.: 72.66%] [G loss: 0.702420]\n",
      "epoch:25 step:23655 [D loss: 0.501951, acc.: 75.78%] [G loss: 0.719143]\n",
      "epoch:25 step:23656 [D loss: 0.432198, acc.: 80.47%] [G loss: 0.809452]\n",
      "epoch:25 step:23657 [D loss: 0.460056, acc.: 79.69%] [G loss: 1.063660]\n",
      "epoch:25 step:23658 [D loss: 0.563538, acc.: 71.09%] [G loss: 0.907973]\n",
      "epoch:25 step:23659 [D loss: 0.577396, acc.: 68.75%] [G loss: 0.879078]\n",
      "epoch:25 step:23660 [D loss: 0.539179, acc.: 71.88%] [G loss: 0.769859]\n",
      "epoch:25 step:23661 [D loss: 0.474803, acc.: 76.56%] [G loss: 0.585801]\n",
      "epoch:25 step:23662 [D loss: 0.507174, acc.: 73.44%] [G loss: 0.588073]\n",
      "epoch:25 step:23663 [D loss: 0.576166, acc.: 65.62%] [G loss: 0.740279]\n",
      "epoch:25 step:23664 [D loss: 0.493113, acc.: 76.56%] [G loss: 0.839026]\n",
      "epoch:25 step:23665 [D loss: 0.567746, acc.: 71.09%] [G loss: 0.676663]\n",
      "epoch:25 step:23666 [D loss: 0.511224, acc.: 71.88%] [G loss: 0.748540]\n",
      "epoch:25 step:23667 [D loss: 0.490760, acc.: 74.22%] [G loss: 0.749823]\n",
      "epoch:25 step:23668 [D loss: 0.489075, acc.: 75.78%] [G loss: 0.885294]\n",
      "epoch:25 step:23669 [D loss: 0.470320, acc.: 76.56%] [G loss: 0.871755]\n",
      "epoch:25 step:23670 [D loss: 0.477925, acc.: 74.22%] [G loss: 0.858859]\n",
      "epoch:25 step:23671 [D loss: 0.478170, acc.: 78.12%] [G loss: 0.888738]\n",
      "epoch:25 step:23672 [D loss: 0.524462, acc.: 75.00%] [G loss: 0.944548]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:25 step:23673 [D loss: 0.458527, acc.: 78.91%] [G loss: 0.960373]\n",
      "epoch:25 step:23674 [D loss: 0.558533, acc.: 69.53%] [G loss: 0.729326]\n",
      "epoch:25 step:23675 [D loss: 0.616075, acc.: 64.06%] [G loss: 0.638463]\n",
      "epoch:25 step:23676 [D loss: 0.553495, acc.: 74.22%] [G loss: 0.739611]\n",
      "epoch:25 step:23677 [D loss: 0.520843, acc.: 71.88%] [G loss: 0.681000]\n",
      "epoch:25 step:23678 [D loss: 0.589789, acc.: 63.28%] [G loss: 0.601067]\n",
      "epoch:25 step:23679 [D loss: 0.469291, acc.: 78.91%] [G loss: 0.722420]\n",
      "epoch:25 step:23680 [D loss: 0.495698, acc.: 74.22%] [G loss: 0.667823]\n",
      "epoch:25 step:23681 [D loss: 0.523609, acc.: 69.53%] [G loss: 0.645282]\n",
      "epoch:25 step:23682 [D loss: 0.571532, acc.: 66.41%] [G loss: 0.451023]\n",
      "epoch:25 step:23683 [D loss: 0.516188, acc.: 75.00%] [G loss: 0.687488]\n",
      "epoch:25 step:23684 [D loss: 0.495871, acc.: 68.75%] [G loss: 0.688596]\n",
      "epoch:25 step:23685 [D loss: 0.622742, acc.: 61.72%] [G loss: 0.619640]\n",
      "epoch:25 step:23686 [D loss: 0.513330, acc.: 75.78%] [G loss: 0.573783]\n",
      "epoch:25 step:23687 [D loss: 0.467771, acc.: 75.78%] [G loss: 0.676668]\n",
      "epoch:25 step:23688 [D loss: 0.571715, acc.: 66.41%] [G loss: 0.754270]\n",
      "epoch:25 step:23689 [D loss: 0.539291, acc.: 68.75%] [G loss: 0.883588]\n",
      "epoch:25 step:23690 [D loss: 0.505366, acc.: 71.88%] [G loss: 0.762301]\n",
      "epoch:25 step:23691 [D loss: 0.611708, acc.: 66.41%] [G loss: 0.678014]\n",
      "epoch:25 step:23692 [D loss: 0.610209, acc.: 63.28%] [G loss: 0.858625]\n",
      "epoch:25 step:23693 [D loss: 0.494964, acc.: 73.44%] [G loss: 0.610710]\n",
      "epoch:25 step:23694 [D loss: 0.584054, acc.: 75.00%] [G loss: 0.663248]\n",
      "epoch:25 step:23695 [D loss: 0.491211, acc.: 78.91%] [G loss: 0.767876]\n",
      "epoch:25 step:23696 [D loss: 0.479224, acc.: 75.78%] [G loss: 0.835236]\n",
      "epoch:25 step:23697 [D loss: 0.506061, acc.: 73.44%] [G loss: 0.640622]\n",
      "epoch:25 step:23698 [D loss: 0.535831, acc.: 71.88%] [G loss: 0.796127]\n",
      "epoch:25 step:23699 [D loss: 0.485803, acc.: 75.78%] [G loss: 0.858600]\n",
      "epoch:25 step:23700 [D loss: 0.521059, acc.: 74.22%] [G loss: 0.704590]\n",
      "epoch:25 step:23701 [D loss: 0.429334, acc.: 79.69%] [G loss: 0.775609]\n",
      "epoch:25 step:23702 [D loss: 0.676056, acc.: 61.72%] [G loss: 0.572164]\n",
      "epoch:25 step:23703 [D loss: 0.602575, acc.: 65.62%] [G loss: 0.566141]\n",
      "epoch:25 step:23704 [D loss: 0.554193, acc.: 65.62%] [G loss: 0.483645]\n",
      "epoch:25 step:23705 [D loss: 0.564174, acc.: 64.84%] [G loss: 0.735681]\n",
      "epoch:25 step:23706 [D loss: 0.557257, acc.: 67.97%] [G loss: 0.758511]\n",
      "epoch:25 step:23707 [D loss: 0.546485, acc.: 66.41%] [G loss: 0.688168]\n",
      "epoch:25 step:23708 [D loss: 0.501019, acc.: 71.09%] [G loss: 0.734505]\n",
      "epoch:25 step:23709 [D loss: 0.576192, acc.: 65.62%] [G loss: 0.648913]\n",
      "epoch:25 step:23710 [D loss: 0.499049, acc.: 71.09%] [G loss: 0.624232]\n",
      "epoch:25 step:23711 [D loss: 0.449610, acc.: 76.56%] [G loss: 0.840957]\n",
      "epoch:25 step:23712 [D loss: 0.640216, acc.: 63.28%] [G loss: 0.663460]\n",
      "epoch:25 step:23713 [D loss: 0.526650, acc.: 73.44%] [G loss: 0.622328]\n",
      "epoch:25 step:23714 [D loss: 0.494007, acc.: 75.78%] [G loss: 0.705025]\n",
      "epoch:25 step:23715 [D loss: 0.511621, acc.: 75.00%] [G loss: 0.670308]\n",
      "epoch:25 step:23716 [D loss: 0.582922, acc.: 64.84%] [G loss: 0.651244]\n",
      "epoch:25 step:23717 [D loss: 0.561504, acc.: 64.84%] [G loss: 0.693159]\n",
      "epoch:25 step:23718 [D loss: 0.580477, acc.: 64.84%] [G loss: 0.655157]\n",
      "epoch:25 step:23719 [D loss: 0.582816, acc.: 68.75%] [G loss: 0.519893]\n",
      "epoch:25 step:23720 [D loss: 0.536170, acc.: 68.75%] [G loss: 0.616840]\n",
      "epoch:25 step:23721 [D loss: 0.435153, acc.: 77.34%] [G loss: 0.725241]\n",
      "epoch:25 step:23722 [D loss: 0.545189, acc.: 68.75%] [G loss: 0.659664]\n",
      "epoch:25 step:23723 [D loss: 0.489058, acc.: 74.22%] [G loss: 0.656086]\n",
      "epoch:25 step:23724 [D loss: 0.513609, acc.: 70.31%] [G loss: 0.888184]\n",
      "epoch:25 step:23725 [D loss: 0.426439, acc.: 82.03%] [G loss: 0.717857]\n",
      "epoch:25 step:23726 [D loss: 0.643085, acc.: 70.31%] [G loss: 0.584553]\n",
      "epoch:25 step:23727 [D loss: 0.522430, acc.: 74.22%] [G loss: 0.767952]\n",
      "epoch:25 step:23728 [D loss: 0.568419, acc.: 67.97%] [G loss: 0.821012]\n",
      "epoch:25 step:23729 [D loss: 0.490638, acc.: 76.56%] [G loss: 0.841345]\n",
      "epoch:25 step:23730 [D loss: 0.575952, acc.: 69.53%] [G loss: 0.724197]\n",
      "epoch:25 step:23731 [D loss: 0.544598, acc.: 74.22%] [G loss: 0.557334]\n",
      "epoch:25 step:23732 [D loss: 0.534754, acc.: 71.88%] [G loss: 0.847630]\n",
      "epoch:25 step:23733 [D loss: 0.506005, acc.: 71.88%] [G loss: 0.861035]\n",
      "epoch:25 step:23734 [D loss: 0.450618, acc.: 75.78%] [G loss: 0.765273]\n",
      "epoch:25 step:23735 [D loss: 0.495185, acc.: 75.78%] [G loss: 0.636385]\n",
      "epoch:25 step:23736 [D loss: 0.458395, acc.: 75.00%] [G loss: 0.866347]\n",
      "epoch:25 step:23737 [D loss: 0.435524, acc.: 82.81%] [G loss: 0.884512]\n",
      "epoch:25 step:23738 [D loss: 0.465300, acc.: 78.12%] [G loss: 1.031556]\n",
      "epoch:25 step:23739 [D loss: 0.446074, acc.: 75.78%] [G loss: 1.215279]\n",
      "epoch:25 step:23740 [D loss: 0.448617, acc.: 78.91%] [G loss: 0.956354]\n",
      "epoch:25 step:23741 [D loss: 0.613298, acc.: 71.09%] [G loss: 0.893661]\n",
      "epoch:25 step:23742 [D loss: 0.582363, acc.: 67.19%] [G loss: 0.688668]\n",
      "epoch:25 step:23743 [D loss: 0.525640, acc.: 69.53%] [G loss: 0.673925]\n",
      "epoch:25 step:23744 [D loss: 0.558078, acc.: 67.97%] [G loss: 0.613379]\n",
      "epoch:25 step:23745 [D loss: 0.557184, acc.: 67.97%] [G loss: 0.638701]\n",
      "epoch:25 step:23746 [D loss: 0.482195, acc.: 75.78%] [G loss: 0.743823]\n",
      "epoch:25 step:23747 [D loss: 0.522437, acc.: 72.66%] [G loss: 0.769469]\n",
      "epoch:25 step:23748 [D loss: 0.602544, acc.: 64.06%] [G loss: 0.728591]\n",
      "epoch:25 step:23749 [D loss: 0.554425, acc.: 73.44%] [G loss: 0.715422]\n",
      "epoch:25 step:23750 [D loss: 0.506445, acc.: 78.12%] [G loss: 0.709476]\n",
      "epoch:25 step:23751 [D loss: 0.460447, acc.: 77.34%] [G loss: 0.685417]\n",
      "epoch:25 step:23752 [D loss: 0.557755, acc.: 68.75%] [G loss: 0.878818]\n",
      "epoch:25 step:23753 [D loss: 0.436454, acc.: 78.91%] [G loss: 0.786170]\n",
      "epoch:25 step:23754 [D loss: 0.502847, acc.: 78.12%] [G loss: 0.857495]\n",
      "epoch:25 step:23755 [D loss: 0.581486, acc.: 70.31%] [G loss: 0.758103]\n",
      "epoch:25 step:23756 [D loss: 0.529396, acc.: 74.22%] [G loss: 0.660308]\n",
      "epoch:25 step:23757 [D loss: 0.492636, acc.: 74.22%] [G loss: 0.725496]\n",
      "epoch:25 step:23758 [D loss: 0.503978, acc.: 75.00%] [G loss: 0.843881]\n",
      "epoch:25 step:23759 [D loss: 0.440152, acc.: 78.12%] [G loss: 0.851233]\n",
      "epoch:25 step:23760 [D loss: 0.492114, acc.: 75.78%] [G loss: 0.834076]\n",
      "epoch:25 step:23761 [D loss: 0.438679, acc.: 80.47%] [G loss: 0.835152]\n",
      "epoch:25 step:23762 [D loss: 0.483390, acc.: 72.66%] [G loss: 0.862188]\n",
      "epoch:25 step:23763 [D loss: 0.553026, acc.: 70.31%] [G loss: 0.782946]\n",
      "epoch:25 step:23764 [D loss: 0.501249, acc.: 74.22%] [G loss: 0.745517]\n",
      "epoch:25 step:23765 [D loss: 0.472835, acc.: 75.78%] [G loss: 0.682400]\n",
      "epoch:25 step:23766 [D loss: 0.606724, acc.: 71.88%] [G loss: 0.858177]\n",
      "epoch:25 step:23767 [D loss: 0.602551, acc.: 61.72%] [G loss: 1.044314]\n",
      "epoch:25 step:23768 [D loss: 0.547938, acc.: 71.09%] [G loss: 1.047075]\n",
      "epoch:25 step:23769 [D loss: 0.426440, acc.: 82.81%] [G loss: 1.147941]\n",
      "epoch:25 step:23770 [D loss: 0.521589, acc.: 72.66%] [G loss: 0.905329]\n",
      "epoch:25 step:23771 [D loss: 0.536477, acc.: 73.44%] [G loss: 0.961652]\n",
      "epoch:25 step:23772 [D loss: 0.365357, acc.: 85.94%] [G loss: 1.252127]\n",
      "epoch:25 step:23773 [D loss: 0.649740, acc.: 65.62%] [G loss: 0.786157]\n",
      "epoch:25 step:23774 [D loss: 0.713521, acc.: 50.00%] [G loss: 0.523867]\n",
      "epoch:25 step:23775 [D loss: 0.517102, acc.: 74.22%] [G loss: 0.534191]\n",
      "epoch:25 step:23776 [D loss: 0.478261, acc.: 75.78%] [G loss: 0.618156]\n",
      "epoch:25 step:23777 [D loss: 0.598676, acc.: 68.75%] [G loss: 0.696105]\n",
      "epoch:25 step:23778 [D loss: 0.540528, acc.: 71.09%] [G loss: 0.691160]\n",
      "epoch:25 step:23779 [D loss: 0.404949, acc.: 82.03%] [G loss: 0.824317]\n",
      "epoch:25 step:23780 [D loss: 0.492760, acc.: 79.69%] [G loss: 0.947034]\n",
      "epoch:25 step:23781 [D loss: 0.484806, acc.: 73.44%] [G loss: 0.727938]\n",
      "epoch:25 step:23782 [D loss: 0.427601, acc.: 80.47%] [G loss: 0.885841]\n",
      "epoch:25 step:23783 [D loss: 0.494583, acc.: 75.00%] [G loss: 0.930947]\n",
      "epoch:25 step:23784 [D loss: 0.463508, acc.: 76.56%] [G loss: 0.970737]\n",
      "epoch:25 step:23785 [D loss: 0.498719, acc.: 68.75%] [G loss: 0.917193]\n",
      "epoch:25 step:23786 [D loss: 0.542023, acc.: 69.53%] [G loss: 0.761730]\n",
      "epoch:25 step:23787 [D loss: 0.512852, acc.: 74.22%] [G loss: 0.768942]\n",
      "epoch:25 step:23788 [D loss: 0.589901, acc.: 63.28%] [G loss: 0.666152]\n",
      "epoch:25 step:23789 [D loss: 0.450937, acc.: 78.91%] [G loss: 0.782135]\n",
      "epoch:25 step:23790 [D loss: 0.529031, acc.: 67.19%] [G loss: 0.789093]\n",
      "epoch:25 step:23791 [D loss: 0.552446, acc.: 68.75%] [G loss: 0.690515]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:25 step:23792 [D loss: 0.476051, acc.: 76.56%] [G loss: 0.904045]\n",
      "epoch:25 step:23793 [D loss: 0.585932, acc.: 70.31%] [G loss: 0.874601]\n",
      "epoch:25 step:23794 [D loss: 0.515387, acc.: 71.88%] [G loss: 0.721307]\n",
      "epoch:25 step:23795 [D loss: 0.511943, acc.: 75.00%] [G loss: 0.759265]\n",
      "epoch:25 step:23796 [D loss: 0.488849, acc.: 77.34%] [G loss: 0.752658]\n",
      "epoch:25 step:23797 [D loss: 0.516636, acc.: 70.31%] [G loss: 0.619531]\n",
      "epoch:25 step:23798 [D loss: 0.527074, acc.: 71.88%] [G loss: 0.695231]\n",
      "epoch:25 step:23799 [D loss: 0.425183, acc.: 82.81%] [G loss: 0.863554]\n",
      "epoch:25 step:23800 [D loss: 0.500483, acc.: 75.78%] [G loss: 0.947479]\n",
      "epoch:25 step:23801 [D loss: 0.753967, acc.: 57.81%] [G loss: 0.648784]\n",
      "epoch:25 step:23802 [D loss: 0.538400, acc.: 69.53%] [G loss: 0.629344]\n",
      "epoch:25 step:23803 [D loss: 0.574800, acc.: 64.84%] [G loss: 0.728184]\n",
      "epoch:25 step:23804 [D loss: 0.540793, acc.: 72.66%] [G loss: 0.766216]\n",
      "epoch:25 step:23805 [D loss: 0.556658, acc.: 72.66%] [G loss: 0.752378]\n",
      "epoch:25 step:23806 [D loss: 0.491444, acc.: 78.91%] [G loss: 0.792276]\n",
      "epoch:25 step:23807 [D loss: 0.465097, acc.: 78.12%] [G loss: 0.951313]\n",
      "epoch:25 step:23808 [D loss: 0.539677, acc.: 70.31%] [G loss: 0.855205]\n",
      "epoch:25 step:23809 [D loss: 0.526110, acc.: 71.88%] [G loss: 0.737344]\n",
      "epoch:25 step:23810 [D loss: 0.449663, acc.: 78.12%] [G loss: 0.910866]\n",
      "epoch:25 step:23811 [D loss: 0.566133, acc.: 70.31%] [G loss: 0.794206]\n",
      "epoch:25 step:23812 [D loss: 0.512042, acc.: 73.44%] [G loss: 0.707361]\n",
      "epoch:25 step:23813 [D loss: 0.575000, acc.: 64.84%] [G loss: 0.668975]\n",
      "epoch:25 step:23814 [D loss: 0.546372, acc.: 70.31%] [G loss: 0.747422]\n",
      "epoch:25 step:23815 [D loss: 0.631794, acc.: 63.28%] [G loss: 0.571522]\n",
      "epoch:25 step:23816 [D loss: 0.522784, acc.: 75.78%] [G loss: 0.539780]\n",
      "epoch:25 step:23817 [D loss: 0.446801, acc.: 76.56%] [G loss: 0.756092]\n",
      "epoch:25 step:23818 [D loss: 0.544782, acc.: 71.88%] [G loss: 0.617850]\n",
      "epoch:25 step:23819 [D loss: 0.491414, acc.: 78.12%] [G loss: 0.590277]\n",
      "epoch:25 step:23820 [D loss: 0.524448, acc.: 71.88%] [G loss: 0.626593]\n",
      "epoch:25 step:23821 [D loss: 0.524365, acc.: 73.44%] [G loss: 0.618900]\n",
      "epoch:25 step:23822 [D loss: 0.565166, acc.: 67.19%] [G loss: 0.883640]\n",
      "epoch:25 step:23823 [D loss: 0.469177, acc.: 77.34%] [G loss: 0.813772]\n",
      "epoch:25 step:23824 [D loss: 0.488874, acc.: 77.34%] [G loss: 0.733493]\n",
      "epoch:25 step:23825 [D loss: 0.629568, acc.: 61.72%] [G loss: 0.682352]\n",
      "epoch:25 step:23826 [D loss: 0.626576, acc.: 61.72%] [G loss: 0.625183]\n",
      "epoch:25 step:23827 [D loss: 0.469255, acc.: 78.91%] [G loss: 0.746357]\n",
      "epoch:25 step:23828 [D loss: 0.395193, acc.: 78.91%] [G loss: 0.815004]\n",
      "epoch:25 step:23829 [D loss: 0.567449, acc.: 68.75%] [G loss: 0.717665]\n",
      "epoch:25 step:23830 [D loss: 0.519665, acc.: 68.75%] [G loss: 0.926333]\n",
      "epoch:25 step:23831 [D loss: 0.463462, acc.: 76.56%] [G loss: 1.047862]\n",
      "epoch:25 step:23832 [D loss: 0.650124, acc.: 60.16%] [G loss: 0.777610]\n",
      "epoch:25 step:23833 [D loss: 0.506425, acc.: 71.88%] [G loss: 0.943006]\n",
      "epoch:25 step:23834 [D loss: 0.573234, acc.: 64.06%] [G loss: 0.822953]\n",
      "epoch:25 step:23835 [D loss: 0.548860, acc.: 74.22%] [G loss: 0.800999]\n",
      "epoch:25 step:23836 [D loss: 0.591015, acc.: 63.28%] [G loss: 0.654909]\n",
      "epoch:25 step:23837 [D loss: 0.600710, acc.: 64.06%] [G loss: 0.754609]\n",
      "epoch:25 step:23838 [D loss: 0.502038, acc.: 76.56%] [G loss: 0.701675]\n",
      "epoch:25 step:23839 [D loss: 0.506260, acc.: 73.44%] [G loss: 0.916240]\n",
      "epoch:25 step:23840 [D loss: 0.479111, acc.: 75.00%] [G loss: 1.007393]\n",
      "epoch:25 step:23841 [D loss: 0.523988, acc.: 75.00%] [G loss: 1.010297]\n",
      "epoch:25 step:23842 [D loss: 0.468442, acc.: 77.34%] [G loss: 0.963600]\n",
      "epoch:25 step:23843 [D loss: 0.575890, acc.: 65.62%] [G loss: 0.750530]\n",
      "epoch:25 step:23844 [D loss: 0.564544, acc.: 73.44%] [G loss: 0.621015]\n",
      "epoch:25 step:23845 [D loss: 0.607908, acc.: 63.28%] [G loss: 0.653791]\n",
      "epoch:25 step:23846 [D loss: 0.575068, acc.: 68.75%] [G loss: 0.624052]\n",
      "epoch:25 step:23847 [D loss: 0.579799, acc.: 71.09%] [G loss: 0.595562]\n",
      "epoch:25 step:23848 [D loss: 0.548320, acc.: 71.09%] [G loss: 0.687804]\n",
      "epoch:25 step:23849 [D loss: 0.566639, acc.: 71.09%] [G loss: 0.656695]\n",
      "epoch:25 step:23850 [D loss: 0.472460, acc.: 79.69%] [G loss: 0.716248]\n",
      "epoch:25 step:23851 [D loss: 0.455291, acc.: 76.56%] [G loss: 0.931933]\n",
      "epoch:25 step:23852 [D loss: 0.479336, acc.: 74.22%] [G loss: 0.949303]\n",
      "epoch:25 step:23853 [D loss: 0.514088, acc.: 71.88%] [G loss: 0.871946]\n",
      "epoch:25 step:23854 [D loss: 0.434734, acc.: 78.91%] [G loss: 0.997720]\n",
      "epoch:25 step:23855 [D loss: 0.529181, acc.: 72.66%] [G loss: 0.752911]\n",
      "epoch:25 step:23856 [D loss: 0.553890, acc.: 70.31%] [G loss: 0.774848]\n",
      "epoch:25 step:23857 [D loss: 0.521479, acc.: 71.09%] [G loss: 0.845749]\n",
      "epoch:25 step:23858 [D loss: 0.538014, acc.: 69.53%] [G loss: 0.657774]\n",
      "epoch:25 step:23859 [D loss: 0.484611, acc.: 75.78%] [G loss: 0.686386]\n",
      "epoch:25 step:23860 [D loss: 0.531793, acc.: 67.97%] [G loss: 0.600277]\n",
      "epoch:25 step:23861 [D loss: 0.523144, acc.: 75.00%] [G loss: 0.851956]\n",
      "epoch:25 step:23862 [D loss: 0.645099, acc.: 65.62%] [G loss: 0.722400]\n",
      "epoch:25 step:23863 [D loss: 0.561415, acc.: 67.97%] [G loss: 0.669552]\n",
      "epoch:25 step:23864 [D loss: 0.497220, acc.: 75.78%] [G loss: 0.545081]\n",
      "epoch:25 step:23865 [D loss: 0.529930, acc.: 72.66%] [G loss: 0.627631]\n",
      "epoch:25 step:23866 [D loss: 0.490202, acc.: 74.22%] [G loss: 0.901206]\n",
      "epoch:25 step:23867 [D loss: 0.511723, acc.: 70.31%] [G loss: 0.917773]\n",
      "epoch:25 step:23868 [D loss: 0.573829, acc.: 67.97%] [G loss: 0.858520]\n",
      "epoch:25 step:23869 [D loss: 0.512844, acc.: 74.22%] [G loss: 0.955346]\n",
      "epoch:25 step:23870 [D loss: 0.526593, acc.: 72.66%] [G loss: 0.774020]\n",
      "epoch:25 step:23871 [D loss: 0.502039, acc.: 72.66%] [G loss: 0.872652]\n",
      "epoch:25 step:23872 [D loss: 0.541940, acc.: 69.53%] [G loss: 0.767850]\n",
      "epoch:25 step:23873 [D loss: 0.534643, acc.: 74.22%] [G loss: 0.815103]\n",
      "epoch:25 step:23874 [D loss: 0.472860, acc.: 75.78%] [G loss: 0.694537]\n",
      "epoch:25 step:23875 [D loss: 0.505985, acc.: 71.88%] [G loss: 0.762471]\n",
      "epoch:25 step:23876 [D loss: 0.460977, acc.: 78.91%] [G loss: 0.862723]\n",
      "epoch:25 step:23877 [D loss: 0.480450, acc.: 77.34%] [G loss: 0.946754]\n",
      "epoch:25 step:23878 [D loss: 0.572384, acc.: 68.75%] [G loss: 0.748342]\n",
      "epoch:25 step:23879 [D loss: 0.503941, acc.: 72.66%] [G loss: 0.881728]\n",
      "epoch:25 step:23880 [D loss: 0.537423, acc.: 75.78%] [G loss: 0.725211]\n",
      "epoch:25 step:23881 [D loss: 0.577492, acc.: 67.97%] [G loss: 0.726275]\n",
      "epoch:25 step:23882 [D loss: 0.481182, acc.: 77.34%] [G loss: 0.923230]\n",
      "epoch:25 step:23883 [D loss: 0.654539, acc.: 64.84%] [G loss: 0.770851]\n",
      "epoch:25 step:23884 [D loss: 0.484178, acc.: 74.22%] [G loss: 0.661576]\n",
      "epoch:25 step:23885 [D loss: 0.470365, acc.: 73.44%] [G loss: 0.756535]\n",
      "epoch:25 step:23886 [D loss: 0.480972, acc.: 80.47%] [G loss: 0.795096]\n",
      "epoch:25 step:23887 [D loss: 0.569166, acc.: 64.84%] [G loss: 0.795304]\n",
      "epoch:25 step:23888 [D loss: 0.550128, acc.: 69.53%] [G loss: 0.661734]\n",
      "epoch:25 step:23889 [D loss: 0.467110, acc.: 75.00%] [G loss: 0.785012]\n",
      "epoch:25 step:23890 [D loss: 0.560845, acc.: 69.53%] [G loss: 0.778504]\n",
      "epoch:25 step:23891 [D loss: 0.535385, acc.: 64.06%] [G loss: 0.706838]\n",
      "epoch:25 step:23892 [D loss: 0.524021, acc.: 66.41%] [G loss: 0.587714]\n",
      "epoch:25 step:23893 [D loss: 0.593312, acc.: 69.53%] [G loss: 0.795535]\n",
      "epoch:25 step:23894 [D loss: 0.529055, acc.: 73.44%] [G loss: 0.657045]\n",
      "epoch:25 step:23895 [D loss: 0.590761, acc.: 65.62%] [G loss: 0.687492]\n",
      "epoch:25 step:23896 [D loss: 0.431855, acc.: 78.12%] [G loss: 0.941271]\n",
      "epoch:25 step:23897 [D loss: 0.448409, acc.: 76.56%] [G loss: 0.951107]\n",
      "epoch:25 step:23898 [D loss: 0.615839, acc.: 66.41%] [G loss: 0.834461]\n",
      "epoch:25 step:23899 [D loss: 0.514195, acc.: 71.09%] [G loss: 0.869642]\n",
      "epoch:25 step:23900 [D loss: 0.428282, acc.: 80.47%] [G loss: 1.094853]\n",
      "epoch:25 step:23901 [D loss: 0.517926, acc.: 75.78%] [G loss: 0.894822]\n",
      "epoch:25 step:23902 [D loss: 0.626610, acc.: 67.19%] [G loss: 0.591208]\n",
      "epoch:25 step:23903 [D loss: 0.520046, acc.: 74.22%] [G loss: 0.666908]\n",
      "epoch:25 step:23904 [D loss: 0.509565, acc.: 77.34%] [G loss: 0.714895]\n",
      "epoch:25 step:23905 [D loss: 0.576579, acc.: 67.97%] [G loss: 0.803647]\n",
      "epoch:25 step:23906 [D loss: 0.485870, acc.: 75.78%] [G loss: 0.679656]\n",
      "epoch:25 step:23907 [D loss: 0.546532, acc.: 69.53%] [G loss: 0.633362]\n",
      "epoch:25 step:23908 [D loss: 0.524032, acc.: 72.66%] [G loss: 0.650680]\n",
      "epoch:25 step:23909 [D loss: 0.469181, acc.: 72.66%] [G loss: 0.870754]\n",
      "epoch:25 step:23910 [D loss: 0.499382, acc.: 75.00%] [G loss: 0.928601]\n",
      "epoch:25 step:23911 [D loss: 0.597877, acc.: 60.16%] [G loss: 0.662738]\n",
      "epoch:25 step:23912 [D loss: 0.513803, acc.: 76.56%] [G loss: 0.702437]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:25 step:23913 [D loss: 0.479626, acc.: 77.34%] [G loss: 0.857828]\n",
      "epoch:25 step:23914 [D loss: 0.517709, acc.: 74.22%] [G loss: 0.860006]\n",
      "epoch:25 step:23915 [D loss: 0.521019, acc.: 76.56%] [G loss: 0.783013]\n",
      "epoch:25 step:23916 [D loss: 0.536860, acc.: 71.09%] [G loss: 0.741450]\n",
      "epoch:25 step:23917 [D loss: 0.519779, acc.: 73.44%] [G loss: 0.687298]\n",
      "epoch:25 step:23918 [D loss: 0.536361, acc.: 72.66%] [G loss: 0.683038]\n",
      "epoch:25 step:23919 [D loss: 0.603740, acc.: 63.28%] [G loss: 0.705553]\n",
      "epoch:25 step:23920 [D loss: 0.473841, acc.: 74.22%] [G loss: 0.869331]\n",
      "epoch:25 step:23921 [D loss: 0.511801, acc.: 73.44%] [G loss: 0.778739]\n",
      "epoch:25 step:23922 [D loss: 0.502901, acc.: 76.56%] [G loss: 0.807841]\n",
      "epoch:25 step:23923 [D loss: 0.488842, acc.: 77.34%] [G loss: 1.045148]\n",
      "epoch:25 step:23924 [D loss: 0.497787, acc.: 75.00%] [G loss: 0.921185]\n",
      "epoch:25 step:23925 [D loss: 0.565336, acc.: 73.44%] [G loss: 0.813166]\n",
      "epoch:25 step:23926 [D loss: 0.667123, acc.: 64.06%] [G loss: 0.821346]\n",
      "epoch:25 step:23927 [D loss: 0.668762, acc.: 56.25%] [G loss: 0.635055]\n",
      "epoch:25 step:23928 [D loss: 0.498712, acc.: 75.78%] [G loss: 0.644940]\n",
      "epoch:25 step:23929 [D loss: 0.399501, acc.: 84.38%] [G loss: 0.911543]\n",
      "epoch:25 step:23930 [D loss: 0.536388, acc.: 73.44%] [G loss: 0.921370]\n",
      "epoch:25 step:23931 [D loss: 0.476683, acc.: 76.56%] [G loss: 1.028760]\n",
      "epoch:25 step:23932 [D loss: 0.492388, acc.: 78.12%] [G loss: 0.827351]\n",
      "epoch:25 step:23933 [D loss: 0.365226, acc.: 85.94%] [G loss: 1.013128]\n",
      "epoch:25 step:23934 [D loss: 0.483224, acc.: 75.78%] [G loss: 0.880539]\n",
      "epoch:25 step:23935 [D loss: 0.594848, acc.: 67.19%] [G loss: 0.758891]\n",
      "epoch:25 step:23936 [D loss: 0.590390, acc.: 67.19%] [G loss: 0.697779]\n",
      "epoch:25 step:23937 [D loss: 0.564687, acc.: 67.97%] [G loss: 0.522048]\n",
      "epoch:25 step:23938 [D loss: 0.513698, acc.: 71.88%] [G loss: 0.635081]\n",
      "epoch:25 step:23939 [D loss: 0.442885, acc.: 79.69%] [G loss: 0.718320]\n",
      "epoch:25 step:23940 [D loss: 0.533582, acc.: 73.44%] [G loss: 0.669911]\n",
      "epoch:25 step:23941 [D loss: 0.405043, acc.: 85.16%] [G loss: 1.087059]\n",
      "epoch:25 step:23942 [D loss: 0.522883, acc.: 75.00%] [G loss: 0.722151]\n",
      "epoch:25 step:23943 [D loss: 0.553897, acc.: 71.09%] [G loss: 0.774738]\n",
      "epoch:25 step:23944 [D loss: 0.449682, acc.: 77.34%] [G loss: 0.790617]\n",
      "epoch:25 step:23945 [D loss: 0.466313, acc.: 76.56%] [G loss: 0.739246]\n",
      "epoch:25 step:23946 [D loss: 0.536752, acc.: 67.97%] [G loss: 0.953645]\n",
      "epoch:25 step:23947 [D loss: 0.453936, acc.: 81.25%] [G loss: 0.960391]\n",
      "epoch:25 step:23948 [D loss: 0.486404, acc.: 75.00%] [G loss: 0.921754]\n",
      "epoch:25 step:23949 [D loss: 0.535305, acc.: 70.31%] [G loss: 0.803744]\n",
      "epoch:25 step:23950 [D loss: 0.559229, acc.: 71.09%] [G loss: 0.800809]\n",
      "epoch:25 step:23951 [D loss: 0.518614, acc.: 70.31%] [G loss: 0.713679]\n",
      "epoch:25 step:23952 [D loss: 0.588103, acc.: 67.97%] [G loss: 0.847031]\n",
      "epoch:25 step:23953 [D loss: 0.692247, acc.: 59.38%] [G loss: 0.654702]\n",
      "epoch:25 step:23954 [D loss: 0.564201, acc.: 69.53%] [G loss: 0.547317]\n",
      "epoch:25 step:23955 [D loss: 0.497286, acc.: 76.56%] [G loss: 0.701552]\n",
      "epoch:25 step:23956 [D loss: 0.551052, acc.: 67.97%] [G loss: 0.629933]\n",
      "epoch:25 step:23957 [D loss: 0.552411, acc.: 67.97%] [G loss: 0.550654]\n",
      "epoch:25 step:23958 [D loss: 0.566419, acc.: 67.97%] [G loss: 0.608184]\n",
      "epoch:25 step:23959 [D loss: 0.488564, acc.: 75.00%] [G loss: 0.671634]\n",
      "epoch:25 step:23960 [D loss: 0.562890, acc.: 68.75%] [G loss: 0.597254]\n",
      "epoch:25 step:23961 [D loss: 0.497989, acc.: 68.75%] [G loss: 0.747620]\n",
      "epoch:25 step:23962 [D loss: 0.596313, acc.: 62.50%] [G loss: 0.611459]\n",
      "epoch:25 step:23963 [D loss: 0.502295, acc.: 75.00%] [G loss: 0.739988]\n",
      "epoch:25 step:23964 [D loss: 0.523708, acc.: 71.09%] [G loss: 0.759639]\n",
      "epoch:25 step:23965 [D loss: 0.539451, acc.: 67.97%] [G loss: 0.521015]\n",
      "epoch:25 step:23966 [D loss: 0.528731, acc.: 68.75%] [G loss: 0.633056]\n",
      "epoch:25 step:23967 [D loss: 0.613023, acc.: 64.06%] [G loss: 0.535145]\n",
      "epoch:25 step:23968 [D loss: 0.545512, acc.: 68.75%] [G loss: 0.696117]\n",
      "epoch:25 step:23969 [D loss: 0.549311, acc.: 69.53%] [G loss: 0.568059]\n",
      "epoch:25 step:23970 [D loss: 0.551047, acc.: 68.75%] [G loss: 0.661309]\n",
      "epoch:25 step:23971 [D loss: 0.494760, acc.: 74.22%] [G loss: 0.656969]\n",
      "epoch:25 step:23972 [D loss: 0.567985, acc.: 71.09%] [G loss: 0.760647]\n",
      "epoch:25 step:23973 [D loss: 0.496629, acc.: 75.78%] [G loss: 0.813572]\n",
      "epoch:25 step:23974 [D loss: 0.475286, acc.: 77.34%] [G loss: 0.777358]\n",
      "epoch:25 step:23975 [D loss: 0.558862, acc.: 69.53%] [G loss: 0.590647]\n",
      "epoch:25 step:23976 [D loss: 0.465132, acc.: 75.78%] [G loss: 0.814912]\n",
      "epoch:25 step:23977 [D loss: 0.454532, acc.: 75.78%] [G loss: 1.034528]\n",
      "epoch:25 step:23978 [D loss: 0.554427, acc.: 71.88%] [G loss: 0.698254]\n",
      "epoch:25 step:23979 [D loss: 0.448457, acc.: 77.34%] [G loss: 0.915636]\n",
      "epoch:25 step:23980 [D loss: 0.493601, acc.: 78.12%] [G loss: 0.902888]\n",
      "epoch:25 step:23981 [D loss: 0.518717, acc.: 75.78%] [G loss: 0.902381]\n",
      "epoch:25 step:23982 [D loss: 0.493271, acc.: 75.78%] [G loss: 0.836873]\n",
      "epoch:25 step:23983 [D loss: 0.468663, acc.: 77.34%] [G loss: 0.793116]\n",
      "epoch:25 step:23984 [D loss: 0.581945, acc.: 66.41%] [G loss: 0.768911]\n",
      "epoch:25 step:23985 [D loss: 0.557630, acc.: 68.75%] [G loss: 0.509328]\n",
      "epoch:25 step:23986 [D loss: 0.505559, acc.: 78.12%] [G loss: 0.615102]\n",
      "epoch:25 step:23987 [D loss: 0.532834, acc.: 70.31%] [G loss: 0.695108]\n",
      "epoch:25 step:23988 [D loss: 0.520613, acc.: 70.31%] [G loss: 0.652375]\n",
      "epoch:25 step:23989 [D loss: 0.478071, acc.: 78.12%] [G loss: 0.912023]\n",
      "epoch:25 step:23990 [D loss: 0.489743, acc.: 78.91%] [G loss: 0.818758]\n",
      "epoch:25 step:23991 [D loss: 0.660629, acc.: 63.28%] [G loss: 0.605667]\n",
      "epoch:25 step:23992 [D loss: 0.499595, acc.: 74.22%] [G loss: 0.613170]\n",
      "epoch:25 step:23993 [D loss: 0.475906, acc.: 72.66%] [G loss: 0.601931]\n",
      "epoch:25 step:23994 [D loss: 0.500956, acc.: 78.12%] [G loss: 0.724657]\n",
      "epoch:25 step:23995 [D loss: 0.467427, acc.: 81.25%] [G loss: 0.642669]\n",
      "epoch:25 step:23996 [D loss: 0.505651, acc.: 75.78%] [G loss: 0.659834]\n",
      "epoch:25 step:23997 [D loss: 0.498222, acc.: 78.12%] [G loss: 0.706397]\n",
      "epoch:25 step:23998 [D loss: 0.555849, acc.: 69.53%] [G loss: 0.723952]\n",
      "epoch:25 step:23999 [D loss: 0.443545, acc.: 81.25%] [G loss: 0.956205]\n",
      "epoch:25 step:24000 [D loss: 0.436418, acc.: 78.12%] [G loss: 1.045496]\n",
      "epoch:25 step:24001 [D loss: 0.633495, acc.: 61.72%] [G loss: 0.686363]\n",
      "epoch:25 step:24002 [D loss: 0.517179, acc.: 71.88%] [G loss: 0.716074]\n",
      "epoch:25 step:24003 [D loss: 0.527673, acc.: 71.88%] [G loss: 0.726487]\n",
      "epoch:25 step:24004 [D loss: 0.505245, acc.: 69.53%] [G loss: 0.825632]\n",
      "epoch:25 step:24005 [D loss: 0.539337, acc.: 69.53%] [G loss: 0.786072]\n",
      "epoch:25 step:24006 [D loss: 0.510182, acc.: 77.34%] [G loss: 0.762105]\n",
      "epoch:25 step:24007 [D loss: 0.457404, acc.: 82.03%] [G loss: 0.574150]\n",
      "epoch:25 step:24008 [D loss: 0.501305, acc.: 73.44%] [G loss: 0.831885]\n",
      "epoch:25 step:24009 [D loss: 0.547184, acc.: 69.53%] [G loss: 0.584113]\n",
      "epoch:25 step:24010 [D loss: 0.552587, acc.: 69.53%] [G loss: 0.693958]\n",
      "epoch:25 step:24011 [D loss: 0.531999, acc.: 67.97%] [G loss: 0.684725]\n",
      "epoch:25 step:24012 [D loss: 0.540079, acc.: 67.19%] [G loss: 0.780610]\n",
      "epoch:25 step:24013 [D loss: 0.495340, acc.: 75.00%] [G loss: 0.776466]\n",
      "epoch:25 step:24014 [D loss: 0.497196, acc.: 80.47%] [G loss: 0.676658]\n",
      "epoch:25 step:24015 [D loss: 0.597017, acc.: 66.41%] [G loss: 0.755290]\n",
      "epoch:25 step:24016 [D loss: 0.598359, acc.: 67.97%] [G loss: 0.642532]\n",
      "epoch:25 step:24017 [D loss: 0.516699, acc.: 74.22%] [G loss: 0.634802]\n",
      "epoch:25 step:24018 [D loss: 0.507305, acc.: 77.34%] [G loss: 0.768420]\n",
      "epoch:25 step:24019 [D loss: 0.515267, acc.: 71.09%] [G loss: 0.793991]\n",
      "epoch:25 step:24020 [D loss: 0.535234, acc.: 75.00%] [G loss: 0.646642]\n",
      "epoch:25 step:24021 [D loss: 0.513847, acc.: 74.22%] [G loss: 0.732472]\n",
      "epoch:25 step:24022 [D loss: 0.502668, acc.: 76.56%] [G loss: 0.770104]\n",
      "epoch:25 step:24023 [D loss: 0.503254, acc.: 75.78%] [G loss: 0.860586]\n",
      "epoch:25 step:24024 [D loss: 0.518188, acc.: 75.00%] [G loss: 0.848931]\n",
      "epoch:25 step:24025 [D loss: 0.595384, acc.: 64.06%] [G loss: 0.810169]\n",
      "epoch:25 step:24026 [D loss: 0.475498, acc.: 75.78%] [G loss: 0.648658]\n",
      "epoch:25 step:24027 [D loss: 0.476085, acc.: 78.12%] [G loss: 0.776926]\n",
      "epoch:25 step:24028 [D loss: 0.468051, acc.: 76.56%] [G loss: 0.802408]\n",
      "epoch:25 step:24029 [D loss: 0.537490, acc.: 71.88%] [G loss: 0.939509]\n",
      "epoch:25 step:24030 [D loss: 0.436145, acc.: 80.47%] [G loss: 0.841839]\n",
      "epoch:25 step:24031 [D loss: 0.616663, acc.: 64.06%] [G loss: 0.582878]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:25 step:24032 [D loss: 0.501366, acc.: 71.88%] [G loss: 0.799259]\n",
      "epoch:25 step:24033 [D loss: 0.513017, acc.: 75.00%] [G loss: 0.705581]\n",
      "epoch:25 step:24034 [D loss: 0.504247, acc.: 70.31%] [G loss: 0.637558]\n",
      "epoch:25 step:24035 [D loss: 0.561171, acc.: 71.09%] [G loss: 0.745915]\n",
      "epoch:25 step:24036 [D loss: 0.484661, acc.: 76.56%] [G loss: 0.675705]\n",
      "epoch:25 step:24037 [D loss: 0.534388, acc.: 67.97%] [G loss: 0.694303]\n",
      "epoch:25 step:24038 [D loss: 0.500501, acc.: 74.22%] [G loss: 0.848133]\n",
      "epoch:25 step:24039 [D loss: 0.553207, acc.: 68.75%] [G loss: 0.844087]\n",
      "epoch:25 step:24040 [D loss: 0.547587, acc.: 69.53%] [G loss: 0.646892]\n",
      "epoch:25 step:24041 [D loss: 0.552798, acc.: 67.19%] [G loss: 0.664695]\n",
      "epoch:25 step:24042 [D loss: 0.499410, acc.: 75.00%] [G loss: 0.873649]\n",
      "epoch:25 step:24043 [D loss: 0.549854, acc.: 69.53%] [G loss: 0.940321]\n",
      "epoch:25 step:24044 [D loss: 0.532210, acc.: 65.62%] [G loss: 0.953570]\n",
      "epoch:25 step:24045 [D loss: 0.536909, acc.: 71.09%] [G loss: 0.835590]\n",
      "epoch:25 step:24046 [D loss: 0.621822, acc.: 64.06%] [G loss: 0.622838]\n",
      "epoch:25 step:24047 [D loss: 0.607721, acc.: 64.06%] [G loss: 0.707052]\n",
      "epoch:25 step:24048 [D loss: 0.485944, acc.: 75.00%] [G loss: 0.577622]\n",
      "epoch:25 step:24049 [D loss: 0.446433, acc.: 82.81%] [G loss: 0.804227]\n",
      "epoch:25 step:24050 [D loss: 0.613202, acc.: 64.84%] [G loss: 0.808612]\n",
      "epoch:25 step:24051 [D loss: 0.528323, acc.: 71.09%] [G loss: 0.771679]\n",
      "epoch:25 step:24052 [D loss: 0.504793, acc.: 72.66%] [G loss: 0.809441]\n",
      "epoch:25 step:24053 [D loss: 0.630106, acc.: 67.97%] [G loss: 0.617617]\n",
      "epoch:25 step:24054 [D loss: 0.537548, acc.: 69.53%] [G loss: 0.595558]\n",
      "epoch:25 step:24055 [D loss: 0.477717, acc.: 81.25%] [G loss: 0.772186]\n",
      "epoch:25 step:24056 [D loss: 0.401202, acc.: 82.81%] [G loss: 0.816150]\n",
      "epoch:25 step:24057 [D loss: 0.531582, acc.: 71.09%] [G loss: 0.841766]\n",
      "epoch:25 step:24058 [D loss: 0.485681, acc.: 71.88%] [G loss: 1.052632]\n",
      "epoch:25 step:24059 [D loss: 0.496656, acc.: 77.34%] [G loss: 0.768383]\n",
      "epoch:25 step:24060 [D loss: 0.513058, acc.: 72.66%] [G loss: 0.777961]\n",
      "epoch:25 step:24061 [D loss: 0.584154, acc.: 67.97%] [G loss: 0.692598]\n",
      "epoch:25 step:24062 [D loss: 0.520816, acc.: 74.22%] [G loss: 0.579297]\n",
      "epoch:25 step:24063 [D loss: 0.449674, acc.: 78.12%] [G loss: 0.694024]\n",
      "epoch:25 step:24064 [D loss: 0.466731, acc.: 77.34%] [G loss: 0.734555]\n",
      "epoch:25 step:24065 [D loss: 0.537211, acc.: 73.44%] [G loss: 0.732889]\n",
      "epoch:25 step:24066 [D loss: 0.492245, acc.: 74.22%] [G loss: 0.741784]\n",
      "epoch:25 step:24067 [D loss: 0.459050, acc.: 78.12%] [G loss: 0.860758]\n",
      "epoch:25 step:24068 [D loss: 0.600018, acc.: 65.62%] [G loss: 0.758572]\n",
      "epoch:25 step:24069 [D loss: 0.561924, acc.: 66.41%] [G loss: 0.783115]\n",
      "epoch:25 step:24070 [D loss: 0.532103, acc.: 71.09%] [G loss: 0.799831]\n",
      "epoch:25 step:24071 [D loss: 0.531821, acc.: 71.09%] [G loss: 0.545620]\n",
      "epoch:25 step:24072 [D loss: 0.404544, acc.: 85.16%] [G loss: 0.905595]\n",
      "epoch:25 step:24073 [D loss: 0.423669, acc.: 80.47%] [G loss: 0.991551]\n",
      "epoch:25 step:24074 [D loss: 0.485355, acc.: 76.56%] [G loss: 1.127046]\n",
      "epoch:25 step:24075 [D loss: 0.454964, acc.: 77.34%] [G loss: 1.206428]\n",
      "epoch:25 step:24076 [D loss: 0.497035, acc.: 75.00%] [G loss: 0.985316]\n",
      "epoch:25 step:24077 [D loss: 0.628487, acc.: 66.41%] [G loss: 0.744010]\n",
      "epoch:25 step:24078 [D loss: 0.512988, acc.: 78.12%] [G loss: 0.873528]\n",
      "epoch:25 step:24079 [D loss: 0.467208, acc.: 75.00%] [G loss: 0.929495]\n",
      "epoch:25 step:24080 [D loss: 0.561305, acc.: 72.66%] [G loss: 0.738596]\n",
      "epoch:25 step:24081 [D loss: 0.558018, acc.: 71.88%] [G loss: 0.596864]\n",
      "epoch:25 step:24082 [D loss: 0.487583, acc.: 75.00%] [G loss: 0.670661]\n",
      "epoch:25 step:24083 [D loss: 0.597076, acc.: 64.06%] [G loss: 0.730455]\n",
      "epoch:25 step:24084 [D loss: 0.537916, acc.: 70.31%] [G loss: 0.712828]\n",
      "epoch:25 step:24085 [D loss: 0.498524, acc.: 75.78%] [G loss: 0.744347]\n",
      "epoch:25 step:24086 [D loss: 0.475559, acc.: 78.12%] [G loss: 0.836196]\n",
      "epoch:25 step:24087 [D loss: 0.502522, acc.: 71.88%] [G loss: 0.796991]\n",
      "epoch:25 step:24088 [D loss: 0.575985, acc.: 67.97%] [G loss: 0.717014]\n",
      "epoch:25 step:24089 [D loss: 0.569272, acc.: 64.84%] [G loss: 0.768971]\n",
      "epoch:25 step:24090 [D loss: 0.592948, acc.: 69.53%] [G loss: 0.604118]\n",
      "epoch:25 step:24091 [D loss: 0.541972, acc.: 67.19%] [G loss: 0.672714]\n",
      "epoch:25 step:24092 [D loss: 0.535085, acc.: 71.09%] [G loss: 0.711068]\n",
      "epoch:25 step:24093 [D loss: 0.546956, acc.: 71.88%] [G loss: 0.668295]\n",
      "epoch:25 step:24094 [D loss: 0.500769, acc.: 75.78%] [G loss: 0.626914]\n",
      "epoch:25 step:24095 [D loss: 0.570500, acc.: 66.41%] [G loss: 0.613883]\n",
      "epoch:25 step:24096 [D loss: 0.510180, acc.: 71.88%] [G loss: 0.734690]\n",
      "epoch:25 step:24097 [D loss: 0.514588, acc.: 73.44%] [G loss: 0.682844]\n",
      "epoch:25 step:24098 [D loss: 0.606758, acc.: 67.19%] [G loss: 0.699855]\n",
      "epoch:25 step:24099 [D loss: 0.489062, acc.: 75.00%] [G loss: 0.651305]\n",
      "epoch:25 step:24100 [D loss: 0.620985, acc.: 60.16%] [G loss: 0.633447]\n",
      "epoch:25 step:24101 [D loss: 0.515825, acc.: 72.66%] [G loss: 0.552779]\n",
      "epoch:25 step:24102 [D loss: 0.480756, acc.: 72.66%] [G loss: 0.718248]\n",
      "epoch:25 step:24103 [D loss: 0.586307, acc.: 67.19%] [G loss: 0.608493]\n",
      "epoch:25 step:24104 [D loss: 0.439671, acc.: 79.69%] [G loss: 0.874909]\n",
      "epoch:25 step:24105 [D loss: 0.482842, acc.: 78.91%] [G loss: 0.636260]\n",
      "epoch:25 step:24106 [D loss: 0.480950, acc.: 75.00%] [G loss: 0.939329]\n",
      "epoch:25 step:24107 [D loss: 0.495953, acc.: 74.22%] [G loss: 0.803161]\n",
      "epoch:25 step:24108 [D loss: 0.524946, acc.: 73.44%] [G loss: 0.646821]\n",
      "epoch:25 step:24109 [D loss: 0.603645, acc.: 64.84%] [G loss: 0.613692]\n",
      "epoch:25 step:24110 [D loss: 0.518857, acc.: 73.44%] [G loss: 0.549295]\n",
      "epoch:25 step:24111 [D loss: 0.513832, acc.: 73.44%] [G loss: 0.615452]\n",
      "epoch:25 step:24112 [D loss: 0.597974, acc.: 63.28%] [G loss: 0.619600]\n",
      "epoch:25 step:24113 [D loss: 0.513446, acc.: 72.66%] [G loss: 0.625716]\n",
      "epoch:25 step:24114 [D loss: 0.494023, acc.: 71.88%] [G loss: 0.894021]\n",
      "epoch:25 step:24115 [D loss: 0.473929, acc.: 75.78%] [G loss: 0.827135]\n",
      "epoch:25 step:24116 [D loss: 0.452611, acc.: 74.22%] [G loss: 0.839975]\n",
      "epoch:25 step:24117 [D loss: 0.521816, acc.: 71.88%] [G loss: 0.868032]\n",
      "epoch:25 step:24118 [D loss: 0.477050, acc.: 75.00%] [G loss: 0.872811]\n",
      "epoch:25 step:24119 [D loss: 0.517679, acc.: 76.56%] [G loss: 0.892138]\n",
      "epoch:25 step:24120 [D loss: 0.466372, acc.: 77.34%] [G loss: 0.833549]\n",
      "epoch:25 step:24121 [D loss: 0.564019, acc.: 70.31%] [G loss: 0.618625]\n",
      "epoch:25 step:24122 [D loss: 0.595218, acc.: 64.06%] [G loss: 0.608188]\n",
      "epoch:25 step:24123 [D loss: 0.583310, acc.: 67.97%] [G loss: 0.513814]\n",
      "epoch:25 step:24124 [D loss: 0.493512, acc.: 77.34%] [G loss: 0.778482]\n",
      "epoch:25 step:24125 [D loss: 0.481438, acc.: 75.78%] [G loss: 0.714808]\n",
      "epoch:25 step:24126 [D loss: 0.504726, acc.: 75.78%] [G loss: 0.810353]\n",
      "epoch:25 step:24127 [D loss: 0.585536, acc.: 68.75%] [G loss: 0.765576]\n",
      "epoch:25 step:24128 [D loss: 0.590359, acc.: 64.06%] [G loss: 0.602818]\n",
      "epoch:25 step:24129 [D loss: 0.638194, acc.: 63.28%] [G loss: 0.638635]\n",
      "epoch:25 step:24130 [D loss: 0.493967, acc.: 75.00%] [G loss: 0.616289]\n",
      "epoch:25 step:24131 [D loss: 0.502447, acc.: 78.12%] [G loss: 0.689584]\n",
      "epoch:25 step:24132 [D loss: 0.497654, acc.: 74.22%] [G loss: 0.744731]\n",
      "epoch:25 step:24133 [D loss: 0.474749, acc.: 80.47%] [G loss: 0.853440]\n",
      "epoch:25 step:24134 [D loss: 0.560548, acc.: 67.97%] [G loss: 0.741233]\n",
      "epoch:25 step:24135 [D loss: 0.550675, acc.: 68.75%] [G loss: 0.701223]\n",
      "epoch:25 step:24136 [D loss: 0.527361, acc.: 66.41%] [G loss: 0.733715]\n",
      "epoch:25 step:24137 [D loss: 0.523816, acc.: 68.75%] [G loss: 0.825635]\n",
      "epoch:25 step:24138 [D loss: 0.554664, acc.: 67.19%] [G loss: 0.861969]\n",
      "epoch:25 step:24139 [D loss: 0.523905, acc.: 69.53%] [G loss: 0.727605]\n",
      "epoch:25 step:24140 [D loss: 0.503121, acc.: 75.78%] [G loss: 0.790736]\n",
      "epoch:25 step:24141 [D loss: 0.615988, acc.: 67.19%] [G loss: 0.455747]\n",
      "epoch:25 step:24142 [D loss: 0.525291, acc.: 73.44%] [G loss: 0.599802]\n",
      "epoch:25 step:24143 [D loss: 0.573703, acc.: 68.75%] [G loss: 0.607544]\n",
      "epoch:25 step:24144 [D loss: 0.493150, acc.: 77.34%] [G loss: 0.804021]\n",
      "epoch:25 step:24145 [D loss: 0.580301, acc.: 69.53%] [G loss: 0.736330]\n",
      "epoch:25 step:24146 [D loss: 0.525752, acc.: 69.53%] [G loss: 0.800439]\n",
      "epoch:25 step:24147 [D loss: 0.533164, acc.: 72.66%] [G loss: 0.653076]\n",
      "epoch:25 step:24148 [D loss: 0.484785, acc.: 78.91%] [G loss: 0.850948]\n",
      "epoch:25 step:24149 [D loss: 0.500044, acc.: 73.44%] [G loss: 0.790237]\n",
      "epoch:25 step:24150 [D loss: 0.487345, acc.: 77.34%] [G loss: 0.906808]\n",
      "epoch:25 step:24151 [D loss: 0.498118, acc.: 72.66%] [G loss: 0.749394]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:25 step:24152 [D loss: 0.537532, acc.: 71.88%] [G loss: 0.794876]\n",
      "epoch:25 step:24153 [D loss: 0.533742, acc.: 70.31%] [G loss: 0.667450]\n",
      "epoch:25 step:24154 [D loss: 0.556681, acc.: 71.88%] [G loss: 0.634309]\n",
      "epoch:25 step:24155 [D loss: 0.479472, acc.: 74.22%] [G loss: 0.642563]\n",
      "epoch:25 step:24156 [D loss: 0.572582, acc.: 64.84%] [G loss: 0.566564]\n",
      "epoch:25 step:24157 [D loss: 0.541702, acc.: 72.66%] [G loss: 0.642079]\n",
      "epoch:25 step:24158 [D loss: 0.524902, acc.: 68.75%] [G loss: 0.751040]\n",
      "epoch:25 step:24159 [D loss: 0.498557, acc.: 73.44%] [G loss: 0.601805]\n",
      "epoch:25 step:24160 [D loss: 0.604156, acc.: 64.06%] [G loss: 0.651406]\n",
      "epoch:25 step:24161 [D loss: 0.473658, acc.: 74.22%] [G loss: 0.681533]\n",
      "epoch:25 step:24162 [D loss: 0.501832, acc.: 71.88%] [G loss: 0.640455]\n",
      "epoch:25 step:24163 [D loss: 0.536862, acc.: 73.44%] [G loss: 0.693300]\n",
      "epoch:25 step:24164 [D loss: 0.559888, acc.: 70.31%] [G loss: 0.728734]\n",
      "epoch:25 step:24165 [D loss: 0.629797, acc.: 61.72%] [G loss: 0.577844]\n",
      "epoch:25 step:24166 [D loss: 0.484885, acc.: 71.88%] [G loss: 0.555137]\n",
      "epoch:25 step:24167 [D loss: 0.565212, acc.: 70.31%] [G loss: 0.679765]\n",
      "epoch:25 step:24168 [D loss: 0.489056, acc.: 73.44%] [G loss: 0.794451]\n",
      "epoch:25 step:24169 [D loss: 0.559207, acc.: 73.44%] [G loss: 0.703102]\n",
      "epoch:25 step:24170 [D loss: 0.597595, acc.: 64.84%] [G loss: 0.743851]\n",
      "epoch:25 step:24171 [D loss: 0.397250, acc.: 80.47%] [G loss: 0.847256]\n",
      "epoch:25 step:24172 [D loss: 0.438874, acc.: 75.78%] [G loss: 1.108594]\n",
      "epoch:25 step:24173 [D loss: 0.552747, acc.: 69.53%] [G loss: 0.889297]\n",
      "epoch:25 step:24174 [D loss: 0.552288, acc.: 70.31%] [G loss: 0.867592]\n",
      "epoch:25 step:24175 [D loss: 0.481101, acc.: 77.34%] [G loss: 0.751975]\n",
      "epoch:25 step:24176 [D loss: 0.509602, acc.: 71.09%] [G loss: 0.759249]\n",
      "epoch:25 step:24177 [D loss: 0.561551, acc.: 71.09%] [G loss: 0.865917]\n",
      "epoch:25 step:24178 [D loss: 0.478025, acc.: 76.56%] [G loss: 0.820489]\n",
      "epoch:25 step:24179 [D loss: 0.545969, acc.: 70.31%] [G loss: 0.705823]\n",
      "epoch:25 step:24180 [D loss: 0.522600, acc.: 67.97%] [G loss: 0.745464]\n",
      "epoch:25 step:24181 [D loss: 0.497732, acc.: 76.56%] [G loss: 0.733499]\n",
      "epoch:25 step:24182 [D loss: 0.537830, acc.: 71.09%] [G loss: 0.675490]\n",
      "epoch:25 step:24183 [D loss: 0.529344, acc.: 69.53%] [G loss: 0.744748]\n",
      "epoch:25 step:24184 [D loss: 0.519789, acc.: 72.66%] [G loss: 0.766268]\n",
      "epoch:25 step:24185 [D loss: 0.522181, acc.: 73.44%] [G loss: 0.820604]\n",
      "epoch:25 step:24186 [D loss: 0.532236, acc.: 70.31%] [G loss: 0.809014]\n",
      "epoch:25 step:24187 [D loss: 0.638560, acc.: 63.28%] [G loss: 0.542320]\n",
      "epoch:25 step:24188 [D loss: 0.564914, acc.: 67.97%] [G loss: 0.855161]\n",
      "epoch:25 step:24189 [D loss: 0.553278, acc.: 66.41%] [G loss: 0.860814]\n",
      "epoch:25 step:24190 [D loss: 0.579279, acc.: 71.88%] [G loss: 0.653733]\n",
      "epoch:25 step:24191 [D loss: 0.602462, acc.: 64.84%] [G loss: 0.678831]\n",
      "epoch:25 step:24192 [D loss: 0.496912, acc.: 76.56%] [G loss: 0.683158]\n",
      "epoch:25 step:24193 [D loss: 0.509402, acc.: 72.66%] [G loss: 0.849262]\n",
      "epoch:25 step:24194 [D loss: 0.473342, acc.: 78.12%] [G loss: 0.930320]\n",
      "epoch:25 step:24195 [D loss: 0.531142, acc.: 70.31%] [G loss: 0.893340]\n",
      "epoch:25 step:24196 [D loss: 0.471701, acc.: 77.34%] [G loss: 0.869066]\n",
      "epoch:25 step:24197 [D loss: 0.554899, acc.: 67.97%] [G loss: 0.775971]\n",
      "epoch:25 step:24198 [D loss: 0.510043, acc.: 71.09%] [G loss: 0.695556]\n",
      "epoch:25 step:24199 [D loss: 0.539831, acc.: 73.44%] [G loss: 0.722886]\n",
      "epoch:25 step:24200 [D loss: 0.492565, acc.: 73.44%] [G loss: 0.878305]\n",
      "epoch:25 step:24201 [D loss: 0.671226, acc.: 60.16%] [G loss: 0.888993]\n",
      "epoch:25 step:24202 [D loss: 0.555441, acc.: 71.88%] [G loss: 0.852891]\n",
      "epoch:25 step:24203 [D loss: 0.546388, acc.: 70.31%] [G loss: 0.709976]\n",
      "epoch:25 step:24204 [D loss: 0.538302, acc.: 70.31%] [G loss: 0.800739]\n",
      "epoch:25 step:24205 [D loss: 0.470043, acc.: 76.56%] [G loss: 0.829922]\n",
      "epoch:25 step:24206 [D loss: 0.450657, acc.: 78.91%] [G loss: 1.023283]\n",
      "epoch:25 step:24207 [D loss: 0.452676, acc.: 81.25%] [G loss: 1.169496]\n",
      "epoch:25 step:24208 [D loss: 0.542057, acc.: 72.66%] [G loss: 0.923521]\n",
      "epoch:25 step:24209 [D loss: 0.655890, acc.: 62.50%] [G loss: 0.583778]\n",
      "epoch:25 step:24210 [D loss: 0.503841, acc.: 76.56%] [G loss: 0.694097]\n",
      "epoch:25 step:24211 [D loss: 0.521994, acc.: 67.97%] [G loss: 0.656774]\n",
      "epoch:25 step:24212 [D loss: 0.563592, acc.: 69.53%] [G loss: 0.879734]\n",
      "epoch:25 step:24213 [D loss: 0.615647, acc.: 66.41%] [G loss: 0.564675]\n",
      "epoch:25 step:24214 [D loss: 0.494494, acc.: 75.78%] [G loss: 0.624937]\n",
      "epoch:25 step:24215 [D loss: 0.511131, acc.: 70.31%] [G loss: 0.815704]\n",
      "epoch:25 step:24216 [D loss: 0.521441, acc.: 71.88%] [G loss: 0.684567]\n",
      "epoch:25 step:24217 [D loss: 0.488920, acc.: 75.78%] [G loss: 0.837645]\n",
      "epoch:25 step:24218 [D loss: 0.601546, acc.: 64.06%] [G loss: 0.797135]\n",
      "epoch:25 step:24219 [D loss: 0.635384, acc.: 63.28%] [G loss: 0.996495]\n",
      "epoch:25 step:24220 [D loss: 0.509515, acc.: 71.09%] [G loss: 1.049945]\n",
      "epoch:25 step:24221 [D loss: 0.449450, acc.: 81.25%] [G loss: 0.786912]\n",
      "epoch:25 step:24222 [D loss: 0.497576, acc.: 73.44%] [G loss: 0.880863]\n",
      "epoch:25 step:24223 [D loss: 0.553660, acc.: 68.75%] [G loss: 0.768527]\n",
      "epoch:25 step:24224 [D loss: 0.594167, acc.: 67.97%] [G loss: 0.765255]\n",
      "epoch:25 step:24225 [D loss: 0.616139, acc.: 63.28%] [G loss: 0.771241]\n",
      "epoch:25 step:24226 [D loss: 0.499476, acc.: 77.34%] [G loss: 0.723165]\n",
      "epoch:25 step:24227 [D loss: 0.484616, acc.: 75.78%] [G loss: 0.864411]\n",
      "epoch:25 step:24228 [D loss: 0.499176, acc.: 75.78%] [G loss: 0.944775]\n",
      "epoch:25 step:24229 [D loss: 0.525575, acc.: 74.22%] [G loss: 0.746586]\n",
      "epoch:25 step:24230 [D loss: 0.527649, acc.: 69.53%] [G loss: 0.652941]\n",
      "epoch:25 step:24231 [D loss: 0.528207, acc.: 69.53%] [G loss: 0.488650]\n",
      "epoch:25 step:24232 [D loss: 0.523321, acc.: 71.88%] [G loss: 0.617606]\n",
      "epoch:25 step:24233 [D loss: 0.538846, acc.: 75.78%] [G loss: 0.761273]\n",
      "epoch:25 step:24234 [D loss: 0.478468, acc.: 77.34%] [G loss: 0.587842]\n",
      "epoch:25 step:24235 [D loss: 0.493118, acc.: 75.00%] [G loss: 0.741070]\n",
      "epoch:25 step:24236 [D loss: 0.562717, acc.: 68.75%] [G loss: 0.663421]\n",
      "epoch:25 step:24237 [D loss: 0.612816, acc.: 68.75%] [G loss: 0.589184]\n",
      "epoch:25 step:24238 [D loss: 0.487276, acc.: 75.78%] [G loss: 0.828355]\n",
      "epoch:25 step:24239 [D loss: 0.480395, acc.: 78.12%] [G loss: 0.754423]\n",
      "epoch:25 step:24240 [D loss: 0.458303, acc.: 80.47%] [G loss: 0.842246]\n",
      "epoch:25 step:24241 [D loss: 0.505135, acc.: 72.66%] [G loss: 0.939625]\n",
      "epoch:25 step:24242 [D loss: 0.615413, acc.: 67.19%] [G loss: 0.834587]\n",
      "epoch:25 step:24243 [D loss: 0.521510, acc.: 75.00%] [G loss: 0.800957]\n",
      "epoch:25 step:24244 [D loss: 0.527884, acc.: 71.88%] [G loss: 0.738186]\n",
      "epoch:25 step:24245 [D loss: 0.616801, acc.: 70.31%] [G loss: 0.684606]\n",
      "epoch:25 step:24246 [D loss: 0.530508, acc.: 74.22%] [G loss: 0.609141]\n",
      "epoch:25 step:24247 [D loss: 0.562022, acc.: 66.41%] [G loss: 0.748474]\n",
      "epoch:25 step:24248 [D loss: 0.430884, acc.: 76.56%] [G loss: 0.754796]\n",
      "epoch:25 step:24249 [D loss: 0.580246, acc.: 67.19%] [G loss: 0.726476]\n",
      "epoch:25 step:24250 [D loss: 0.487773, acc.: 73.44%] [G loss: 0.697399]\n",
      "epoch:25 step:24251 [D loss: 0.490773, acc.: 75.00%] [G loss: 0.745041]\n",
      "epoch:25 step:24252 [D loss: 0.587462, acc.: 63.28%] [G loss: 0.724809]\n",
      "epoch:25 step:24253 [D loss: 0.668695, acc.: 60.94%] [G loss: 0.617626]\n",
      "epoch:25 step:24254 [D loss: 0.540011, acc.: 65.62%] [G loss: 0.812021]\n",
      "epoch:25 step:24255 [D loss: 0.505937, acc.: 66.41%] [G loss: 0.693243]\n",
      "epoch:25 step:24256 [D loss: 0.582890, acc.: 68.75%] [G loss: 0.571196]\n",
      "epoch:25 step:24257 [D loss: 0.492463, acc.: 74.22%] [G loss: 0.643016]\n",
      "epoch:25 step:24258 [D loss: 0.511423, acc.: 75.00%] [G loss: 0.599180]\n",
      "epoch:25 step:24259 [D loss: 0.542421, acc.: 71.09%] [G loss: 0.682060]\n",
      "epoch:25 step:24260 [D loss: 0.530347, acc.: 69.53%] [G loss: 0.701003]\n",
      "epoch:25 step:24261 [D loss: 0.549805, acc.: 71.88%] [G loss: 0.597996]\n",
      "epoch:25 step:24262 [D loss: 0.585759, acc.: 66.41%] [G loss: 0.507475]\n",
      "epoch:25 step:24263 [D loss: 0.515431, acc.: 69.53%] [G loss: 0.673234]\n",
      "epoch:25 step:24264 [D loss: 0.580309, acc.: 64.06%] [G loss: 0.691844]\n",
      "epoch:25 step:24265 [D loss: 0.551622, acc.: 70.31%] [G loss: 0.547079]\n",
      "epoch:25 step:24266 [D loss: 0.556021, acc.: 67.19%] [G loss: 0.560658]\n",
      "epoch:25 step:24267 [D loss: 0.517625, acc.: 70.31%] [G loss: 0.653941]\n",
      "epoch:25 step:24268 [D loss: 0.497520, acc.: 71.88%] [G loss: 0.700400]\n",
      "epoch:25 step:24269 [D loss: 0.552318, acc.: 70.31%] [G loss: 0.664761]\n",
      "epoch:25 step:24270 [D loss: 0.540965, acc.: 70.31%] [G loss: 0.651021]\n",
      "epoch:25 step:24271 [D loss: 0.557124, acc.: 67.97%] [G loss: 0.592164]\n",
      "epoch:25 step:24272 [D loss: 0.609251, acc.: 63.28%] [G loss: 0.526747]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:25 step:24273 [D loss: 0.532275, acc.: 74.22%] [G loss: 0.482757]\n",
      "epoch:25 step:24274 [D loss: 0.498743, acc.: 74.22%] [G loss: 0.517119]\n",
      "epoch:25 step:24275 [D loss: 0.540989, acc.: 71.88%] [G loss: 0.698192]\n",
      "epoch:25 step:24276 [D loss: 0.534751, acc.: 69.53%] [G loss: 0.515487]\n",
      "epoch:25 step:24277 [D loss: 0.528078, acc.: 71.88%] [G loss: 0.565739]\n",
      "epoch:25 step:24278 [D loss: 0.522720, acc.: 69.53%] [G loss: 0.733998]\n",
      "epoch:25 step:24279 [D loss: 0.465211, acc.: 78.91%] [G loss: 0.860481]\n",
      "epoch:25 step:24280 [D loss: 0.552665, acc.: 67.97%] [G loss: 0.731800]\n",
      "epoch:25 step:24281 [D loss: 0.556408, acc.: 71.88%] [G loss: 0.861671]\n",
      "epoch:25 step:24282 [D loss: 0.424607, acc.: 80.47%] [G loss: 0.796780]\n",
      "epoch:25 step:24283 [D loss: 0.651475, acc.: 65.62%] [G loss: 0.582248]\n",
      "epoch:25 step:24284 [D loss: 0.513498, acc.: 74.22%] [G loss: 0.756144]\n",
      "epoch:25 step:24285 [D loss: 0.441331, acc.: 77.34%] [G loss: 0.837689]\n",
      "epoch:25 step:24286 [D loss: 0.590944, acc.: 68.75%] [G loss: 0.682526]\n",
      "epoch:25 step:24287 [D loss: 0.589764, acc.: 64.84%] [G loss: 0.571116]\n",
      "epoch:25 step:24288 [D loss: 0.535228, acc.: 66.41%] [G loss: 0.697611]\n",
      "epoch:25 step:24289 [D loss: 0.537681, acc.: 66.41%] [G loss: 0.588192]\n",
      "epoch:25 step:24290 [D loss: 0.602174, acc.: 62.50%] [G loss: 0.528431]\n",
      "epoch:25 step:24291 [D loss: 0.546659, acc.: 64.84%] [G loss: 0.625557]\n",
      "epoch:25 step:24292 [D loss: 0.663730, acc.: 58.59%] [G loss: 0.479101]\n",
      "epoch:25 step:24293 [D loss: 0.545555, acc.: 71.09%] [G loss: 0.534724]\n",
      "epoch:25 step:24294 [D loss: 0.582909, acc.: 58.59%] [G loss: 0.616210]\n",
      "epoch:25 step:24295 [D loss: 0.493998, acc.: 70.31%] [G loss: 0.681557]\n",
      "epoch:25 step:24296 [D loss: 0.518595, acc.: 71.09%] [G loss: 0.810119]\n",
      "epoch:25 step:24297 [D loss: 0.542214, acc.: 67.97%] [G loss: 0.655427]\n",
      "epoch:25 step:24298 [D loss: 0.569152, acc.: 66.41%] [G loss: 0.597317]\n",
      "epoch:25 step:24299 [D loss: 0.544980, acc.: 67.97%] [G loss: 0.660056]\n",
      "epoch:25 step:24300 [D loss: 0.498277, acc.: 75.78%] [G loss: 0.848501]\n",
      "epoch:25 step:24301 [D loss: 0.488409, acc.: 76.56%] [G loss: 0.957169]\n",
      "epoch:25 step:24302 [D loss: 0.597602, acc.: 68.75%] [G loss: 0.485155]\n",
      "epoch:25 step:24303 [D loss: 0.570335, acc.: 68.75%] [G loss: 0.623048]\n",
      "epoch:25 step:24304 [D loss: 0.506055, acc.: 71.88%] [G loss: 0.760656]\n",
      "epoch:25 step:24305 [D loss: 0.600892, acc.: 66.41%] [G loss: 0.721243]\n",
      "epoch:25 step:24306 [D loss: 0.577333, acc.: 68.75%] [G loss: 0.432214]\n",
      "epoch:25 step:24307 [D loss: 0.555009, acc.: 71.88%] [G loss: 0.709807]\n",
      "epoch:25 step:24308 [D loss: 0.636687, acc.: 64.84%] [G loss: 0.595142]\n",
      "epoch:25 step:24309 [D loss: 0.462804, acc.: 75.00%] [G loss: 0.836343]\n",
      "epoch:25 step:24310 [D loss: 0.582213, acc.: 68.75%] [G loss: 0.865906]\n",
      "epoch:25 step:24311 [D loss: 0.499984, acc.: 74.22%] [G loss: 0.922033]\n",
      "epoch:25 step:24312 [D loss: 0.549293, acc.: 70.31%] [G loss: 0.891636]\n",
      "epoch:25 step:24313 [D loss: 0.574885, acc.: 68.75%] [G loss: 0.923271]\n",
      "epoch:25 step:24314 [D loss: 0.535884, acc.: 71.88%] [G loss: 0.828162]\n",
      "epoch:25 step:24315 [D loss: 0.448266, acc.: 78.91%] [G loss: 0.834497]\n",
      "epoch:25 step:24316 [D loss: 0.570697, acc.: 70.31%] [G loss: 0.703808]\n",
      "epoch:25 step:24317 [D loss: 0.569580, acc.: 68.75%] [G loss: 0.553560]\n",
      "epoch:25 step:24318 [D loss: 0.491270, acc.: 76.56%] [G loss: 0.686819]\n",
      "epoch:25 step:24319 [D loss: 0.472164, acc.: 76.56%] [G loss: 0.711509]\n",
      "epoch:25 step:24320 [D loss: 0.551526, acc.: 71.88%] [G loss: 0.632210]\n",
      "epoch:25 step:24321 [D loss: 0.451970, acc.: 79.69%] [G loss: 0.800446]\n",
      "epoch:25 step:24322 [D loss: 0.512149, acc.: 75.00%] [G loss: 0.832935]\n",
      "epoch:25 step:24323 [D loss: 0.423833, acc.: 79.69%] [G loss: 0.941190]\n",
      "epoch:25 step:24324 [D loss: 0.432706, acc.: 85.16%] [G loss: 0.914694]\n",
      "epoch:25 step:24325 [D loss: 0.443766, acc.: 76.56%] [G loss: 0.982056]\n",
      "epoch:25 step:24326 [D loss: 0.477177, acc.: 75.78%] [G loss: 0.870365]\n",
      "epoch:25 step:24327 [D loss: 0.565252, acc.: 71.88%] [G loss: 0.807022]\n",
      "epoch:25 step:24328 [D loss: 0.529267, acc.: 70.31%] [G loss: 0.675392]\n",
      "epoch:25 step:24329 [D loss: 0.550655, acc.: 71.88%] [G loss: 0.616273]\n",
      "epoch:25 step:24330 [D loss: 0.537577, acc.: 74.22%] [G loss: 0.683089]\n",
      "epoch:25 step:24331 [D loss: 0.546801, acc.: 71.09%] [G loss: 0.738861]\n",
      "epoch:25 step:24332 [D loss: 0.573289, acc.: 68.75%] [G loss: 0.621112]\n",
      "epoch:25 step:24333 [D loss: 0.565423, acc.: 69.53%] [G loss: 0.784618]\n",
      "epoch:25 step:24334 [D loss: 0.507817, acc.: 69.53%] [G loss: 0.783283]\n",
      "epoch:25 step:24335 [D loss: 0.521027, acc.: 75.00%] [G loss: 0.725829]\n",
      "epoch:25 step:24336 [D loss: 0.476795, acc.: 75.78%] [G loss: 0.597880]\n",
      "epoch:25 step:24337 [D loss: 0.528714, acc.: 72.66%] [G loss: 0.876478]\n",
      "epoch:25 step:24338 [D loss: 0.551011, acc.: 72.66%] [G loss: 0.755094]\n",
      "epoch:25 step:24339 [D loss: 0.460941, acc.: 77.34%] [G loss: 0.916207]\n",
      "epoch:25 step:24340 [D loss: 0.614229, acc.: 67.97%] [G loss: 0.706903]\n",
      "epoch:25 step:24341 [D loss: 0.530435, acc.: 75.00%] [G loss: 0.903258]\n",
      "epoch:25 step:24342 [D loss: 0.583258, acc.: 66.41%] [G loss: 0.825910]\n",
      "epoch:25 step:24343 [D loss: 0.484507, acc.: 76.56%] [G loss: 0.801225]\n",
      "epoch:25 step:24344 [D loss: 0.397089, acc.: 87.50%] [G loss: 0.992184]\n",
      "epoch:25 step:24345 [D loss: 0.651122, acc.: 66.41%] [G loss: 0.819390]\n",
      "epoch:25 step:24346 [D loss: 0.489568, acc.: 76.56%] [G loss: 0.803170]\n",
      "epoch:25 step:24347 [D loss: 0.539370, acc.: 67.97%] [G loss: 0.897709]\n",
      "epoch:25 step:24348 [D loss: 0.430328, acc.: 82.03%] [G loss: 0.801430]\n",
      "epoch:25 step:24349 [D loss: 0.435638, acc.: 75.00%] [G loss: 0.985956]\n",
      "epoch:25 step:24350 [D loss: 0.382675, acc.: 83.59%] [G loss: 1.189442]\n",
      "epoch:25 step:24351 [D loss: 0.438016, acc.: 75.78%] [G loss: 1.357530]\n",
      "epoch:25 step:24352 [D loss: 0.568736, acc.: 68.75%] [G loss: 1.297874]\n",
      "epoch:25 step:24353 [D loss: 0.645312, acc.: 67.19%] [G loss: 1.138877]\n",
      "epoch:25 step:24354 [D loss: 0.630439, acc.: 66.41%] [G loss: 1.462694]\n",
      "epoch:25 step:24355 [D loss: 0.500857, acc.: 71.88%] [G loss: 1.333798]\n",
      "epoch:25 step:24356 [D loss: 0.515910, acc.: 76.56%] [G loss: 0.982010]\n",
      "epoch:25 step:24357 [D loss: 0.676497, acc.: 57.03%] [G loss: 0.874022]\n",
      "epoch:25 step:24358 [D loss: 0.560298, acc.: 71.09%] [G loss: 0.960265]\n",
      "epoch:25 step:24359 [D loss: 0.564999, acc.: 67.19%] [G loss: 0.762664]\n",
      "epoch:25 step:24360 [D loss: 0.509593, acc.: 72.66%] [G loss: 0.864578]\n",
      "epoch:25 step:24361 [D loss: 0.483118, acc.: 71.88%] [G loss: 1.135571]\n",
      "epoch:25 step:24362 [D loss: 0.388283, acc.: 87.50%] [G loss: 1.175566]\n",
      "epoch:26 step:24363 [D loss: 0.569525, acc.: 66.41%] [G loss: 1.235290]\n",
      "epoch:26 step:24364 [D loss: 0.533932, acc.: 71.09%] [G loss: 0.996282]\n",
      "epoch:26 step:24365 [D loss: 0.561000, acc.: 71.09%] [G loss: 0.944669]\n",
      "epoch:26 step:24366 [D loss: 0.539405, acc.: 69.53%] [G loss: 0.704928]\n",
      "epoch:26 step:24367 [D loss: 0.501967, acc.: 75.78%] [G loss: 0.790301]\n",
      "epoch:26 step:24368 [D loss: 0.616330, acc.: 63.28%] [G loss: 0.725146]\n",
      "epoch:26 step:24369 [D loss: 0.485486, acc.: 75.00%] [G loss: 0.621231]\n",
      "epoch:26 step:24370 [D loss: 0.429301, acc.: 77.34%] [G loss: 0.778039]\n",
      "epoch:26 step:24371 [D loss: 0.462316, acc.: 77.34%] [G loss: 0.744090]\n",
      "epoch:26 step:24372 [D loss: 0.494042, acc.: 74.22%] [G loss: 0.818809]\n",
      "epoch:26 step:24373 [D loss: 0.461273, acc.: 77.34%] [G loss: 0.860371]\n",
      "epoch:26 step:24374 [D loss: 0.598378, acc.: 73.44%] [G loss: 0.678006]\n",
      "epoch:26 step:24375 [D loss: 0.589503, acc.: 67.97%] [G loss: 0.621697]\n",
      "epoch:26 step:24376 [D loss: 0.550896, acc.: 70.31%] [G loss: 0.687346]\n",
      "epoch:26 step:24377 [D loss: 0.504568, acc.: 75.78%] [G loss: 0.708344]\n",
      "epoch:26 step:24378 [D loss: 0.475632, acc.: 79.69%] [G loss: 0.836530]\n",
      "epoch:26 step:24379 [D loss: 0.562097, acc.: 67.97%] [G loss: 0.751243]\n",
      "epoch:26 step:24380 [D loss: 0.552788, acc.: 66.41%] [G loss: 0.925678]\n",
      "epoch:26 step:24381 [D loss: 0.565972, acc.: 67.97%] [G loss: 0.848175]\n",
      "epoch:26 step:24382 [D loss: 0.674134, acc.: 66.41%] [G loss: 0.829114]\n",
      "epoch:26 step:24383 [D loss: 0.561213, acc.: 67.19%] [G loss: 0.923374]\n",
      "epoch:26 step:24384 [D loss: 0.487361, acc.: 75.78%] [G loss: 1.029166]\n",
      "epoch:26 step:24385 [D loss: 0.550338, acc.: 72.66%] [G loss: 0.596308]\n",
      "epoch:26 step:24386 [D loss: 0.496709, acc.: 72.66%] [G loss: 0.574997]\n",
      "epoch:26 step:24387 [D loss: 0.506341, acc.: 72.66%] [G loss: 0.854824]\n",
      "epoch:26 step:24388 [D loss: 0.586254, acc.: 68.75%] [G loss: 0.765912]\n",
      "epoch:26 step:24389 [D loss: 0.486338, acc.: 72.66%] [G loss: 0.613622]\n",
      "epoch:26 step:24390 [D loss: 0.558009, acc.: 69.53%] [G loss: 0.787743]\n",
      "epoch:26 step:24391 [D loss: 0.503076, acc.: 75.78%] [G loss: 0.918749]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:26 step:24392 [D loss: 0.482498, acc.: 75.00%] [G loss: 0.812587]\n",
      "epoch:26 step:24393 [D loss: 0.601684, acc.: 66.41%] [G loss: 0.647501]\n",
      "epoch:26 step:24394 [D loss: 0.534408, acc.: 74.22%] [G loss: 0.599885]\n",
      "epoch:26 step:24395 [D loss: 0.522662, acc.: 67.19%] [G loss: 0.674437]\n",
      "epoch:26 step:24396 [D loss: 0.537676, acc.: 71.09%] [G loss: 0.724469]\n",
      "epoch:26 step:24397 [D loss: 0.597191, acc.: 61.72%] [G loss: 0.689770]\n",
      "epoch:26 step:24398 [D loss: 0.508332, acc.: 68.75%] [G loss: 0.630697]\n",
      "epoch:26 step:24399 [D loss: 0.477331, acc.: 75.78%] [G loss: 0.573415]\n",
      "epoch:26 step:24400 [D loss: 0.537283, acc.: 71.88%] [G loss: 0.654916]\n",
      "epoch:26 step:24401 [D loss: 0.529642, acc.: 76.56%] [G loss: 0.683387]\n",
      "epoch:26 step:24402 [D loss: 0.449379, acc.: 77.34%] [G loss: 0.814812]\n",
      "epoch:26 step:24403 [D loss: 0.531909, acc.: 71.88%] [G loss: 0.779062]\n",
      "epoch:26 step:24404 [D loss: 0.517238, acc.: 71.88%] [G loss: 0.677353]\n",
      "epoch:26 step:24405 [D loss: 0.521379, acc.: 75.00%] [G loss: 0.637713]\n",
      "epoch:26 step:24406 [D loss: 0.546587, acc.: 71.09%] [G loss: 0.770368]\n",
      "epoch:26 step:24407 [D loss: 0.454907, acc.: 75.78%] [G loss: 0.753115]\n",
      "epoch:26 step:24408 [D loss: 0.459760, acc.: 76.56%] [G loss: 0.812770]\n",
      "epoch:26 step:24409 [D loss: 0.533289, acc.: 71.09%] [G loss: 0.996027]\n",
      "epoch:26 step:24410 [D loss: 0.526930, acc.: 68.75%] [G loss: 0.807096]\n",
      "epoch:26 step:24411 [D loss: 0.524312, acc.: 74.22%] [G loss: 0.868495]\n",
      "epoch:26 step:24412 [D loss: 0.565047, acc.: 71.88%] [G loss: 0.713164]\n",
      "epoch:26 step:24413 [D loss: 0.582997, acc.: 64.06%] [G loss: 0.627705]\n",
      "epoch:26 step:24414 [D loss: 0.584297, acc.: 66.41%] [G loss: 0.551530]\n",
      "epoch:26 step:24415 [D loss: 0.513649, acc.: 70.31%] [G loss: 0.893896]\n",
      "epoch:26 step:24416 [D loss: 0.464327, acc.: 78.91%] [G loss: 0.774847]\n",
      "epoch:26 step:24417 [D loss: 0.523650, acc.: 74.22%] [G loss: 0.817192]\n",
      "epoch:26 step:24418 [D loss: 0.432315, acc.: 82.03%] [G loss: 0.892910]\n",
      "epoch:26 step:24419 [D loss: 0.544891, acc.: 71.88%] [G loss: 0.677524]\n",
      "epoch:26 step:24420 [D loss: 0.541453, acc.: 70.31%] [G loss: 0.735100]\n",
      "epoch:26 step:24421 [D loss: 0.461229, acc.: 75.78%] [G loss: 0.803747]\n",
      "epoch:26 step:24422 [D loss: 0.563214, acc.: 67.97%] [G loss: 0.657141]\n",
      "epoch:26 step:24423 [D loss: 0.552714, acc.: 68.75%] [G loss: 0.864420]\n",
      "epoch:26 step:24424 [D loss: 0.536373, acc.: 70.31%] [G loss: 0.730758]\n",
      "epoch:26 step:24425 [D loss: 0.546921, acc.: 70.31%] [G loss: 0.806923]\n",
      "epoch:26 step:24426 [D loss: 0.604495, acc.: 71.88%] [G loss: 0.787005]\n",
      "epoch:26 step:24427 [D loss: 0.515265, acc.: 72.66%] [G loss: 0.709167]\n",
      "epoch:26 step:24428 [D loss: 0.487715, acc.: 76.56%] [G loss: 0.636232]\n",
      "epoch:26 step:24429 [D loss: 0.510351, acc.: 74.22%] [G loss: 0.541576]\n",
      "epoch:26 step:24430 [D loss: 0.514972, acc.: 75.00%] [G loss: 0.629322]\n",
      "epoch:26 step:24431 [D loss: 0.494578, acc.: 77.34%] [G loss: 0.780167]\n",
      "epoch:26 step:24432 [D loss: 0.493138, acc.: 75.78%] [G loss: 0.766427]\n",
      "epoch:26 step:24433 [D loss: 0.521039, acc.: 70.31%] [G loss: 0.787896]\n",
      "epoch:26 step:24434 [D loss: 0.533379, acc.: 67.19%] [G loss: 0.576965]\n",
      "epoch:26 step:24435 [D loss: 0.560614, acc.: 66.41%] [G loss: 0.662999]\n",
      "epoch:26 step:24436 [D loss: 0.498398, acc.: 75.78%] [G loss: 0.646927]\n",
      "epoch:26 step:24437 [D loss: 0.508236, acc.: 68.75%] [G loss: 0.695544]\n",
      "epoch:26 step:24438 [D loss: 0.486658, acc.: 72.66%] [G loss: 0.808823]\n",
      "epoch:26 step:24439 [D loss: 0.398796, acc.: 83.59%] [G loss: 1.015483]\n",
      "epoch:26 step:24440 [D loss: 0.560216, acc.: 69.53%] [G loss: 0.732820]\n",
      "epoch:26 step:24441 [D loss: 0.564903, acc.: 68.75%] [G loss: 0.800653]\n",
      "epoch:26 step:24442 [D loss: 0.514093, acc.: 71.88%] [G loss: 0.695929]\n",
      "epoch:26 step:24443 [D loss: 0.554882, acc.: 70.31%] [G loss: 0.782320]\n",
      "epoch:26 step:24444 [D loss: 0.562603, acc.: 67.19%] [G loss: 0.735448]\n",
      "epoch:26 step:24445 [D loss: 0.435127, acc.: 81.25%] [G loss: 0.804247]\n",
      "epoch:26 step:24446 [D loss: 0.508175, acc.: 75.00%] [G loss: 0.920840]\n",
      "epoch:26 step:24447 [D loss: 0.569074, acc.: 61.72%] [G loss: 0.713710]\n",
      "epoch:26 step:24448 [D loss: 0.529870, acc.: 70.31%] [G loss: 0.601366]\n",
      "epoch:26 step:24449 [D loss: 0.456514, acc.: 78.91%] [G loss: 0.612903]\n",
      "epoch:26 step:24450 [D loss: 0.507350, acc.: 77.34%] [G loss: 0.772394]\n",
      "epoch:26 step:24451 [D loss: 0.511211, acc.: 76.56%] [G loss: 0.709795]\n",
      "epoch:26 step:24452 [D loss: 0.479799, acc.: 75.78%] [G loss: 0.759944]\n",
      "epoch:26 step:24453 [D loss: 0.636964, acc.: 61.72%] [G loss: 0.616735]\n",
      "epoch:26 step:24454 [D loss: 0.430962, acc.: 81.25%] [G loss: 0.982293]\n",
      "epoch:26 step:24455 [D loss: 0.499904, acc.: 76.56%] [G loss: 0.869832]\n",
      "epoch:26 step:24456 [D loss: 0.442217, acc.: 81.25%] [G loss: 0.856197]\n",
      "epoch:26 step:24457 [D loss: 0.510316, acc.: 75.78%] [G loss: 0.840480]\n",
      "epoch:26 step:24458 [D loss: 0.509045, acc.: 73.44%] [G loss: 0.736231]\n",
      "epoch:26 step:24459 [D loss: 0.583083, acc.: 71.09%] [G loss: 0.831403]\n",
      "epoch:26 step:24460 [D loss: 0.563191, acc.: 71.88%] [G loss: 0.900274]\n",
      "epoch:26 step:24461 [D loss: 0.491760, acc.: 75.78%] [G loss: 0.996583]\n",
      "epoch:26 step:24462 [D loss: 0.433743, acc.: 78.12%] [G loss: 1.195212]\n",
      "epoch:26 step:24463 [D loss: 0.500136, acc.: 76.56%] [G loss: 1.094078]\n",
      "epoch:26 step:24464 [D loss: 0.617049, acc.: 63.28%] [G loss: 0.636111]\n",
      "epoch:26 step:24465 [D loss: 0.556660, acc.: 66.41%] [G loss: 0.701315]\n",
      "epoch:26 step:24466 [D loss: 0.472569, acc.: 73.44%] [G loss: 0.715699]\n",
      "epoch:26 step:24467 [D loss: 0.563935, acc.: 67.19%] [G loss: 0.815831]\n",
      "epoch:26 step:24468 [D loss: 0.485681, acc.: 72.66%] [G loss: 0.675404]\n",
      "epoch:26 step:24469 [D loss: 0.553886, acc.: 72.66%] [G loss: 0.684911]\n",
      "epoch:26 step:24470 [D loss: 0.574186, acc.: 64.84%] [G loss: 0.752331]\n",
      "epoch:26 step:24471 [D loss: 0.521873, acc.: 72.66%] [G loss: 0.933516]\n",
      "epoch:26 step:24472 [D loss: 0.545678, acc.: 71.09%] [G loss: 0.589698]\n",
      "epoch:26 step:24473 [D loss: 0.512632, acc.: 71.88%] [G loss: 0.699558]\n",
      "epoch:26 step:24474 [D loss: 0.564311, acc.: 69.53%] [G loss: 0.757407]\n",
      "epoch:26 step:24475 [D loss: 0.498564, acc.: 74.22%] [G loss: 0.840417]\n",
      "epoch:26 step:24476 [D loss: 0.494079, acc.: 75.00%] [G loss: 0.767302]\n",
      "epoch:26 step:24477 [D loss: 0.489683, acc.: 78.12%] [G loss: 0.737424]\n",
      "epoch:26 step:24478 [D loss: 0.515843, acc.: 71.09%] [G loss: 0.774448]\n",
      "epoch:26 step:24479 [D loss: 0.525798, acc.: 67.97%] [G loss: 0.867640]\n",
      "epoch:26 step:24480 [D loss: 0.519225, acc.: 68.75%] [G loss: 0.715066]\n",
      "epoch:26 step:24481 [D loss: 0.455656, acc.: 83.59%] [G loss: 0.732579]\n",
      "epoch:26 step:24482 [D loss: 0.548666, acc.: 75.00%] [G loss: 0.804841]\n",
      "epoch:26 step:24483 [D loss: 0.514067, acc.: 75.78%] [G loss: 0.755206]\n",
      "epoch:26 step:24484 [D loss: 0.460837, acc.: 75.78%] [G loss: 0.830661]\n",
      "epoch:26 step:24485 [D loss: 0.500307, acc.: 75.00%] [G loss: 0.785563]\n",
      "epoch:26 step:24486 [D loss: 0.552792, acc.: 73.44%] [G loss: 0.798515]\n",
      "epoch:26 step:24487 [D loss: 0.563420, acc.: 70.31%] [G loss: 0.790295]\n",
      "epoch:26 step:24488 [D loss: 0.455187, acc.: 78.91%] [G loss: 0.775189]\n",
      "epoch:26 step:24489 [D loss: 0.493717, acc.: 73.44%] [G loss: 0.802513]\n",
      "epoch:26 step:24490 [D loss: 0.516269, acc.: 69.53%] [G loss: 0.611307]\n",
      "epoch:26 step:24491 [D loss: 0.520162, acc.: 75.00%] [G loss: 0.761276]\n",
      "epoch:26 step:24492 [D loss: 0.452134, acc.: 79.69%] [G loss: 0.716345]\n",
      "epoch:26 step:24493 [D loss: 0.429950, acc.: 80.47%] [G loss: 0.936038]\n",
      "epoch:26 step:24494 [D loss: 0.560369, acc.: 70.31%] [G loss: 0.795379]\n",
      "epoch:26 step:24495 [D loss: 0.548942, acc.: 67.19%] [G loss: 0.856919]\n",
      "epoch:26 step:24496 [D loss: 0.497793, acc.: 75.00%] [G loss: 0.905289]\n",
      "epoch:26 step:24497 [D loss: 0.549249, acc.: 67.97%] [G loss: 0.792630]\n",
      "epoch:26 step:24498 [D loss: 0.474466, acc.: 75.00%] [G loss: 0.870087]\n",
      "epoch:26 step:24499 [D loss: 0.679957, acc.: 62.50%] [G loss: 0.596160]\n",
      "epoch:26 step:24500 [D loss: 0.626366, acc.: 67.19%] [G loss: 0.644325]\n",
      "epoch:26 step:24501 [D loss: 0.493860, acc.: 80.47%] [G loss: 0.674576]\n",
      "epoch:26 step:24502 [D loss: 0.531678, acc.: 67.97%] [G loss: 0.727132]\n",
      "epoch:26 step:24503 [D loss: 0.474095, acc.: 74.22%] [G loss: 0.704082]\n",
      "epoch:26 step:24504 [D loss: 0.522014, acc.: 71.09%] [G loss: 0.667328]\n",
      "epoch:26 step:24505 [D loss: 0.598498, acc.: 64.84%] [G loss: 0.622274]\n",
      "epoch:26 step:24506 [D loss: 0.448241, acc.: 79.69%] [G loss: 0.826190]\n",
      "epoch:26 step:24507 [D loss: 0.503534, acc.: 67.19%] [G loss: 0.835097]\n",
      "epoch:26 step:24508 [D loss: 0.462056, acc.: 76.56%] [G loss: 0.752726]\n",
      "epoch:26 step:24509 [D loss: 0.596692, acc.: 69.53%] [G loss: 0.709102]\n",
      "epoch:26 step:24510 [D loss: 0.525027, acc.: 67.97%] [G loss: 0.774551]\n",
      "epoch:26 step:24511 [D loss: 0.481964, acc.: 74.22%] [G loss: 0.804511]\n",
      "epoch:26 step:24512 [D loss: 0.562648, acc.: 70.31%] [G loss: 0.668959]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:26 step:24513 [D loss: 0.531078, acc.: 70.31%] [G loss: 0.784359]\n",
      "epoch:26 step:24514 [D loss: 0.447641, acc.: 82.81%] [G loss: 0.778179]\n",
      "epoch:26 step:24515 [D loss: 0.610429, acc.: 65.62%] [G loss: 0.687466]\n",
      "epoch:26 step:24516 [D loss: 0.502051, acc.: 73.44%] [G loss: 0.730413]\n",
      "epoch:26 step:24517 [D loss: 0.495327, acc.: 73.44%] [G loss: 0.616122]\n",
      "epoch:26 step:24518 [D loss: 0.473779, acc.: 76.56%] [G loss: 0.708386]\n",
      "epoch:26 step:24519 [D loss: 0.542913, acc.: 71.88%] [G loss: 0.824962]\n",
      "epoch:26 step:24520 [D loss: 0.579405, acc.: 67.19%] [G loss: 0.739825]\n",
      "epoch:26 step:24521 [D loss: 0.468569, acc.: 77.34%] [G loss: 0.934775]\n",
      "epoch:26 step:24522 [D loss: 0.558441, acc.: 71.09%] [G loss: 0.732798]\n",
      "epoch:26 step:24523 [D loss: 0.519266, acc.: 73.44%] [G loss: 1.081012]\n",
      "epoch:26 step:24524 [D loss: 0.446646, acc.: 76.56%] [G loss: 1.174044]\n",
      "epoch:26 step:24525 [D loss: 0.589989, acc.: 67.19%] [G loss: 0.758503]\n",
      "epoch:26 step:24526 [D loss: 0.550129, acc.: 70.31%] [G loss: 0.936236]\n",
      "epoch:26 step:24527 [D loss: 0.500685, acc.: 76.56%] [G loss: 0.746187]\n",
      "epoch:26 step:24528 [D loss: 0.575289, acc.: 67.19%] [G loss: 0.630200]\n",
      "epoch:26 step:24529 [D loss: 0.522650, acc.: 71.09%] [G loss: 0.646175]\n",
      "epoch:26 step:24530 [D loss: 0.510124, acc.: 76.56%] [G loss: 0.574977]\n",
      "epoch:26 step:24531 [D loss: 0.562304, acc.: 68.75%] [G loss: 0.538734]\n",
      "epoch:26 step:24532 [D loss: 0.523886, acc.: 68.75%] [G loss: 0.467702]\n",
      "epoch:26 step:24533 [D loss: 0.540473, acc.: 66.41%] [G loss: 0.588997]\n",
      "epoch:26 step:24534 [D loss: 0.492848, acc.: 72.66%] [G loss: 0.772655]\n",
      "epoch:26 step:24535 [D loss: 0.473023, acc.: 78.91%] [G loss: 0.923142]\n",
      "epoch:26 step:24536 [D loss: 0.557384, acc.: 68.75%] [G loss: 0.599746]\n",
      "epoch:26 step:24537 [D loss: 0.539863, acc.: 66.41%] [G loss: 0.645976]\n",
      "epoch:26 step:24538 [D loss: 0.487247, acc.: 73.44%] [G loss: 0.651920]\n",
      "epoch:26 step:24539 [D loss: 0.528358, acc.: 71.09%] [G loss: 0.762383]\n",
      "epoch:26 step:24540 [D loss: 0.575218, acc.: 67.97%] [G loss: 0.603160]\n",
      "epoch:26 step:24541 [D loss: 0.501449, acc.: 72.66%] [G loss: 0.779705]\n",
      "epoch:26 step:24542 [D loss: 0.587345, acc.: 67.97%] [G loss: 0.523017]\n",
      "epoch:26 step:24543 [D loss: 0.582941, acc.: 67.19%] [G loss: 0.641224]\n",
      "epoch:26 step:24544 [D loss: 0.522199, acc.: 71.88%] [G loss: 0.783998]\n",
      "epoch:26 step:24545 [D loss: 0.567784, acc.: 71.09%] [G loss: 0.794910]\n",
      "epoch:26 step:24546 [D loss: 0.535175, acc.: 71.09%] [G loss: 0.715906]\n",
      "epoch:26 step:24547 [D loss: 0.546426, acc.: 67.19%] [G loss: 0.722599]\n",
      "epoch:26 step:24548 [D loss: 0.513832, acc.: 71.88%] [G loss: 0.776967]\n",
      "epoch:26 step:24549 [D loss: 0.571965, acc.: 64.84%] [G loss: 0.645677]\n",
      "epoch:26 step:24550 [D loss: 0.516908, acc.: 75.00%] [G loss: 0.659430]\n",
      "epoch:26 step:24551 [D loss: 0.581359, acc.: 67.19%] [G loss: 0.604066]\n",
      "epoch:26 step:24552 [D loss: 0.462521, acc.: 78.91%] [G loss: 0.752789]\n",
      "epoch:26 step:24553 [D loss: 0.477003, acc.: 73.44%] [G loss: 0.669877]\n",
      "epoch:26 step:24554 [D loss: 0.482524, acc.: 79.69%] [G loss: 0.622963]\n",
      "epoch:26 step:24555 [D loss: 0.609338, acc.: 66.41%] [G loss: 0.716530]\n",
      "epoch:26 step:24556 [D loss: 0.416076, acc.: 82.81%] [G loss: 0.973203]\n",
      "epoch:26 step:24557 [D loss: 0.560953, acc.: 71.09%] [G loss: 0.794565]\n",
      "epoch:26 step:24558 [D loss: 0.568522, acc.: 68.75%] [G loss: 0.670026]\n",
      "epoch:26 step:24559 [D loss: 0.502449, acc.: 75.78%] [G loss: 0.716582]\n",
      "epoch:26 step:24560 [D loss: 0.457136, acc.: 76.56%] [G loss: 1.031098]\n",
      "epoch:26 step:24561 [D loss: 0.463560, acc.: 74.22%] [G loss: 0.984229]\n",
      "epoch:26 step:24562 [D loss: 0.553771, acc.: 71.88%] [G loss: 0.871072]\n",
      "epoch:26 step:24563 [D loss: 0.524889, acc.: 70.31%] [G loss: 0.645817]\n",
      "epoch:26 step:24564 [D loss: 0.555512, acc.: 67.97%] [G loss: 0.735989]\n",
      "epoch:26 step:24565 [D loss: 0.508894, acc.: 75.00%] [G loss: 0.757078]\n",
      "epoch:26 step:24566 [D loss: 0.546662, acc.: 69.53%] [G loss: 0.615703]\n",
      "epoch:26 step:24567 [D loss: 0.491638, acc.: 70.31%] [G loss: 0.940380]\n",
      "epoch:26 step:24568 [D loss: 0.504471, acc.: 74.22%] [G loss: 0.891817]\n",
      "epoch:26 step:24569 [D loss: 0.444086, acc.: 82.03%] [G loss: 0.981183]\n",
      "epoch:26 step:24570 [D loss: 0.440053, acc.: 78.12%] [G loss: 0.971888]\n",
      "epoch:26 step:24571 [D loss: 0.448688, acc.: 81.25%] [G loss: 1.038429]\n",
      "epoch:26 step:24572 [D loss: 0.666323, acc.: 65.62%] [G loss: 0.799679]\n",
      "epoch:26 step:24573 [D loss: 0.590312, acc.: 67.19%] [G loss: 0.495820]\n",
      "epoch:26 step:24574 [D loss: 0.513094, acc.: 70.31%] [G loss: 0.614251]\n",
      "epoch:26 step:24575 [D loss: 0.439812, acc.: 80.47%] [G loss: 0.632173]\n",
      "epoch:26 step:24576 [D loss: 0.630669, acc.: 64.06%] [G loss: 0.661940]\n",
      "epoch:26 step:24577 [D loss: 0.545352, acc.: 67.97%] [G loss: 0.639293]\n",
      "epoch:26 step:24578 [D loss: 0.510230, acc.: 71.88%] [G loss: 0.746279]\n",
      "epoch:26 step:24579 [D loss: 0.469327, acc.: 78.12%] [G loss: 0.849133]\n",
      "epoch:26 step:24580 [D loss: 0.476590, acc.: 77.34%] [G loss: 0.957835]\n",
      "epoch:26 step:24581 [D loss: 0.481071, acc.: 78.12%] [G loss: 0.839647]\n",
      "epoch:26 step:24582 [D loss: 0.678712, acc.: 66.41%] [G loss: 0.742747]\n",
      "epoch:26 step:24583 [D loss: 0.561847, acc.: 71.88%] [G loss: 0.662315]\n",
      "epoch:26 step:24584 [D loss: 0.472669, acc.: 78.91%] [G loss: 0.882574]\n",
      "epoch:26 step:24585 [D loss: 0.542894, acc.: 72.66%] [G loss: 0.907069]\n",
      "epoch:26 step:24586 [D loss: 0.472065, acc.: 77.34%] [G loss: 0.813171]\n",
      "epoch:26 step:24587 [D loss: 0.496028, acc.: 78.91%] [G loss: 0.677480]\n",
      "epoch:26 step:24588 [D loss: 0.550200, acc.: 68.75%] [G loss: 0.701384]\n",
      "epoch:26 step:24589 [D loss: 0.551523, acc.: 67.97%] [G loss: 0.638362]\n",
      "epoch:26 step:24590 [D loss: 0.535925, acc.: 73.44%] [G loss: 0.669568]\n",
      "epoch:26 step:24591 [D loss: 0.525988, acc.: 75.78%] [G loss: 0.757542]\n",
      "epoch:26 step:24592 [D loss: 0.482946, acc.: 78.12%] [G loss: 0.908873]\n",
      "epoch:26 step:24593 [D loss: 0.442739, acc.: 82.03%] [G loss: 0.865289]\n",
      "epoch:26 step:24594 [D loss: 0.407607, acc.: 83.59%] [G loss: 0.941221]\n",
      "epoch:26 step:24595 [D loss: 0.504767, acc.: 75.00%] [G loss: 0.959664]\n",
      "epoch:26 step:24596 [D loss: 0.588525, acc.: 68.75%] [G loss: 0.842674]\n",
      "epoch:26 step:24597 [D loss: 0.535844, acc.: 69.53%] [G loss: 0.747268]\n",
      "epoch:26 step:24598 [D loss: 0.531976, acc.: 72.66%] [G loss: 0.580486]\n",
      "epoch:26 step:24599 [D loss: 0.527481, acc.: 72.66%] [G loss: 0.736938]\n",
      "epoch:26 step:24600 [D loss: 0.538314, acc.: 67.97%] [G loss: 0.576851]\n",
      "epoch:26 step:24601 [D loss: 0.522402, acc.: 72.66%] [G loss: 0.682376]\n",
      "epoch:26 step:24602 [D loss: 0.517321, acc.: 67.97%] [G loss: 0.711532]\n",
      "epoch:26 step:24603 [D loss: 0.484068, acc.: 71.88%] [G loss: 0.788556]\n",
      "epoch:26 step:24604 [D loss: 0.482353, acc.: 75.00%] [G loss: 0.769763]\n",
      "epoch:26 step:24605 [D loss: 0.498217, acc.: 71.88%] [G loss: 0.878881]\n",
      "epoch:26 step:24606 [D loss: 0.485137, acc.: 72.66%] [G loss: 0.788616]\n",
      "epoch:26 step:24607 [D loss: 0.485868, acc.: 73.44%] [G loss: 0.869458]\n",
      "epoch:26 step:24608 [D loss: 0.505800, acc.: 73.44%] [G loss: 0.837989]\n",
      "epoch:26 step:24609 [D loss: 0.517913, acc.: 73.44%] [G loss: 0.726069]\n",
      "epoch:26 step:24610 [D loss: 0.514605, acc.: 71.88%] [G loss: 0.877204]\n",
      "epoch:26 step:24611 [D loss: 0.556311, acc.: 69.53%] [G loss: 0.832211]\n",
      "epoch:26 step:24612 [D loss: 0.594327, acc.: 64.06%] [G loss: 0.780132]\n",
      "epoch:26 step:24613 [D loss: 0.563763, acc.: 70.31%] [G loss: 0.856235]\n",
      "epoch:26 step:24614 [D loss: 0.514150, acc.: 72.66%] [G loss: 0.885960]\n",
      "epoch:26 step:24615 [D loss: 0.597514, acc.: 70.31%] [G loss: 0.702180]\n",
      "epoch:26 step:24616 [D loss: 0.487554, acc.: 75.78%] [G loss: 0.676966]\n",
      "epoch:26 step:24617 [D loss: 0.497954, acc.: 71.09%] [G loss: 0.800393]\n",
      "epoch:26 step:24618 [D loss: 0.606453, acc.: 62.50%] [G loss: 0.661967]\n",
      "epoch:26 step:24619 [D loss: 0.576709, acc.: 66.41%] [G loss: 0.676163]\n",
      "epoch:26 step:24620 [D loss: 0.512757, acc.: 75.78%] [G loss: 0.670764]\n",
      "epoch:26 step:24621 [D loss: 0.496681, acc.: 74.22%] [G loss: 0.674796]\n",
      "epoch:26 step:24622 [D loss: 0.631831, acc.: 60.94%] [G loss: 0.622068]\n",
      "epoch:26 step:24623 [D loss: 0.489339, acc.: 75.00%] [G loss: 0.737956]\n",
      "epoch:26 step:24624 [D loss: 0.495337, acc.: 75.78%] [G loss: 0.774713]\n",
      "epoch:26 step:24625 [D loss: 0.572870, acc.: 68.75%] [G loss: 0.665893]\n",
      "epoch:26 step:24626 [D loss: 0.511594, acc.: 75.00%] [G loss: 0.881281]\n",
      "epoch:26 step:24627 [D loss: 0.526008, acc.: 71.88%] [G loss: 0.769089]\n",
      "epoch:26 step:24628 [D loss: 0.634742, acc.: 65.62%] [G loss: 0.853502]\n",
      "epoch:26 step:24629 [D loss: 0.530873, acc.: 71.88%] [G loss: 0.779002]\n",
      "epoch:26 step:24630 [D loss: 0.502640, acc.: 75.78%] [G loss: 0.821052]\n",
      "epoch:26 step:24631 [D loss: 0.598757, acc.: 74.22%] [G loss: 0.569218]\n",
      "epoch:26 step:24632 [D loss: 0.514012, acc.: 73.44%] [G loss: 0.594127]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:26 step:24633 [D loss: 0.483966, acc.: 71.88%] [G loss: 0.598759]\n",
      "epoch:26 step:24634 [D loss: 0.558511, acc.: 66.41%] [G loss: 0.830599]\n",
      "epoch:26 step:24635 [D loss: 0.487328, acc.: 75.00%] [G loss: 0.742695]\n",
      "epoch:26 step:24636 [D loss: 0.477507, acc.: 74.22%] [G loss: 0.841025]\n",
      "epoch:26 step:24637 [D loss: 0.545750, acc.: 71.09%] [G loss: 0.716163]\n",
      "epoch:26 step:24638 [D loss: 0.438556, acc.: 81.25%] [G loss: 0.895806]\n",
      "epoch:26 step:24639 [D loss: 0.631048, acc.: 66.41%] [G loss: 0.649026]\n",
      "epoch:26 step:24640 [D loss: 0.576311, acc.: 64.84%] [G loss: 0.644941]\n",
      "epoch:26 step:24641 [D loss: 0.548592, acc.: 66.41%] [G loss: 0.619846]\n",
      "epoch:26 step:24642 [D loss: 0.490639, acc.: 74.22%] [G loss: 0.849866]\n",
      "epoch:26 step:24643 [D loss: 0.592949, acc.: 72.66%] [G loss: 0.655453]\n",
      "epoch:26 step:24644 [D loss: 0.533029, acc.: 70.31%] [G loss: 0.737674]\n",
      "epoch:26 step:24645 [D loss: 0.526561, acc.: 71.88%] [G loss: 0.800159]\n",
      "epoch:26 step:24646 [D loss: 0.511175, acc.: 71.88%] [G loss: 0.720347]\n",
      "epoch:26 step:24647 [D loss: 0.511268, acc.: 73.44%] [G loss: 0.746213]\n",
      "epoch:26 step:24648 [D loss: 0.564256, acc.: 73.44%] [G loss: 0.753722]\n",
      "epoch:26 step:24649 [D loss: 0.561847, acc.: 70.31%] [G loss: 0.563884]\n",
      "epoch:26 step:24650 [D loss: 0.526044, acc.: 70.31%] [G loss: 0.822925]\n",
      "epoch:26 step:24651 [D loss: 0.505773, acc.: 74.22%] [G loss: 0.848438]\n",
      "epoch:26 step:24652 [D loss: 0.553368, acc.: 71.88%] [G loss: 0.616068]\n",
      "epoch:26 step:24653 [D loss: 0.499833, acc.: 77.34%] [G loss: 0.653175]\n",
      "epoch:26 step:24654 [D loss: 0.545183, acc.: 71.09%] [G loss: 0.746970]\n",
      "epoch:26 step:24655 [D loss: 0.589106, acc.: 64.84%] [G loss: 0.779716]\n",
      "epoch:26 step:24656 [D loss: 0.562819, acc.: 69.53%] [G loss: 0.589500]\n",
      "epoch:26 step:24657 [D loss: 0.533887, acc.: 70.31%] [G loss: 0.684760]\n",
      "epoch:26 step:24658 [D loss: 0.478509, acc.: 75.00%] [G loss: 0.710006]\n",
      "epoch:26 step:24659 [D loss: 0.574820, acc.: 65.62%] [G loss: 0.738329]\n",
      "epoch:26 step:24660 [D loss: 0.473631, acc.: 75.78%] [G loss: 0.834308]\n",
      "epoch:26 step:24661 [D loss: 0.514059, acc.: 71.09%] [G loss: 0.774780]\n",
      "epoch:26 step:24662 [D loss: 0.500784, acc.: 75.78%] [G loss: 0.663742]\n",
      "epoch:26 step:24663 [D loss: 0.598760, acc.: 70.31%] [G loss: 0.652872]\n",
      "epoch:26 step:24664 [D loss: 0.502249, acc.: 75.78%] [G loss: 0.718653]\n",
      "epoch:26 step:24665 [D loss: 0.503293, acc.: 73.44%] [G loss: 0.754360]\n",
      "epoch:26 step:24666 [D loss: 0.552096, acc.: 67.19%] [G loss: 0.740517]\n",
      "epoch:26 step:24667 [D loss: 0.504072, acc.: 74.22%] [G loss: 0.753614]\n",
      "epoch:26 step:24668 [D loss: 0.509535, acc.: 74.22%] [G loss: 0.909914]\n",
      "epoch:26 step:24669 [D loss: 0.508402, acc.: 70.31%] [G loss: 0.721162]\n",
      "epoch:26 step:24670 [D loss: 0.549785, acc.: 69.53%] [G loss: 0.749876]\n",
      "epoch:26 step:24671 [D loss: 0.430903, acc.: 80.47%] [G loss: 0.857612]\n",
      "epoch:26 step:24672 [D loss: 0.541119, acc.: 68.75%] [G loss: 0.701131]\n",
      "epoch:26 step:24673 [D loss: 0.428730, acc.: 82.03%] [G loss: 0.814976]\n",
      "epoch:26 step:24674 [D loss: 0.444752, acc.: 82.03%] [G loss: 0.871186]\n",
      "epoch:26 step:24675 [D loss: 0.474244, acc.: 73.44%] [G loss: 0.861509]\n",
      "epoch:26 step:24676 [D loss: 0.387144, acc.: 85.16%] [G loss: 0.915826]\n",
      "epoch:26 step:24677 [D loss: 0.518950, acc.: 77.34%] [G loss: 0.919502]\n",
      "epoch:26 step:24678 [D loss: 0.691379, acc.: 63.28%] [G loss: 0.761256]\n",
      "epoch:26 step:24679 [D loss: 0.629945, acc.: 65.62%] [G loss: 0.758185]\n",
      "epoch:26 step:24680 [D loss: 0.514139, acc.: 72.66%] [G loss: 0.597418]\n",
      "epoch:26 step:24681 [D loss: 0.554720, acc.: 67.19%] [G loss: 0.644732]\n",
      "epoch:26 step:24682 [D loss: 0.547375, acc.: 70.31%] [G loss: 0.705073]\n",
      "epoch:26 step:24683 [D loss: 0.522173, acc.: 70.31%] [G loss: 0.747048]\n",
      "epoch:26 step:24684 [D loss: 0.574091, acc.: 67.19%] [G loss: 0.755340]\n",
      "epoch:26 step:24685 [D loss: 0.607668, acc.: 67.19%] [G loss: 0.831973]\n",
      "epoch:26 step:24686 [D loss: 0.574846, acc.: 67.19%] [G loss: 0.540169]\n",
      "epoch:26 step:24687 [D loss: 0.542358, acc.: 70.31%] [G loss: 0.548311]\n",
      "epoch:26 step:24688 [D loss: 0.434889, acc.: 80.47%] [G loss: 0.728933]\n",
      "epoch:26 step:24689 [D loss: 0.572119, acc.: 71.09%] [G loss: 0.640628]\n",
      "epoch:26 step:24690 [D loss: 0.491921, acc.: 74.22%] [G loss: 0.878641]\n",
      "epoch:26 step:24691 [D loss: 0.545441, acc.: 71.88%] [G loss: 0.924165]\n",
      "epoch:26 step:24692 [D loss: 0.548254, acc.: 71.09%] [G loss: 0.843842]\n",
      "epoch:26 step:24693 [D loss: 0.545258, acc.: 67.97%] [G loss: 0.617833]\n",
      "epoch:26 step:24694 [D loss: 0.480515, acc.: 75.78%] [G loss: 0.704200]\n",
      "epoch:26 step:24695 [D loss: 0.466300, acc.: 78.12%] [G loss: 0.729347]\n",
      "epoch:26 step:24696 [D loss: 0.459644, acc.: 80.47%] [G loss: 0.925309]\n",
      "epoch:26 step:24697 [D loss: 0.497295, acc.: 75.78%] [G loss: 0.709882]\n",
      "epoch:26 step:24698 [D loss: 0.470939, acc.: 78.12%] [G loss: 0.762024]\n",
      "epoch:26 step:24699 [D loss: 0.511398, acc.: 71.88%] [G loss: 0.776517]\n",
      "epoch:26 step:24700 [D loss: 0.534516, acc.: 69.53%] [G loss: 0.759156]\n",
      "epoch:26 step:24701 [D loss: 0.567660, acc.: 71.09%] [G loss: 0.823831]\n",
      "epoch:26 step:24702 [D loss: 0.480087, acc.: 75.00%] [G loss: 0.904539]\n",
      "epoch:26 step:24703 [D loss: 0.550666, acc.: 70.31%] [G loss: 0.916368]\n",
      "epoch:26 step:24704 [D loss: 0.620330, acc.: 63.28%] [G loss: 0.897418]\n",
      "epoch:26 step:24705 [D loss: 0.458842, acc.: 82.81%] [G loss: 0.659755]\n",
      "epoch:26 step:24706 [D loss: 0.434744, acc.: 81.25%] [G loss: 0.855870]\n",
      "epoch:26 step:24707 [D loss: 0.568386, acc.: 68.75%] [G loss: 0.750320]\n",
      "epoch:26 step:24708 [D loss: 0.582541, acc.: 64.84%] [G loss: 1.199327]\n",
      "epoch:26 step:24709 [D loss: 0.436775, acc.: 78.12%] [G loss: 1.216428]\n",
      "epoch:26 step:24710 [D loss: 0.589512, acc.: 71.88%] [G loss: 0.812879]\n",
      "epoch:26 step:24711 [D loss: 0.679629, acc.: 58.59%] [G loss: 0.675722]\n",
      "epoch:26 step:24712 [D loss: 0.494679, acc.: 71.09%] [G loss: 0.612385]\n",
      "epoch:26 step:24713 [D loss: 0.503315, acc.: 72.66%] [G loss: 0.828153]\n",
      "epoch:26 step:24714 [D loss: 0.549344, acc.: 68.75%] [G loss: 0.732022]\n",
      "epoch:26 step:24715 [D loss: 0.540385, acc.: 73.44%] [G loss: 0.829610]\n",
      "epoch:26 step:24716 [D loss: 0.396141, acc.: 81.25%] [G loss: 0.948128]\n",
      "epoch:26 step:24717 [D loss: 0.433977, acc.: 77.34%] [G loss: 1.041529]\n",
      "epoch:26 step:24718 [D loss: 0.588392, acc.: 67.19%] [G loss: 0.918625]\n",
      "epoch:26 step:24719 [D loss: 0.429195, acc.: 82.81%] [G loss: 0.878743]\n",
      "epoch:26 step:24720 [D loss: 0.447042, acc.: 78.91%] [G loss: 0.976542]\n",
      "epoch:26 step:24721 [D loss: 0.484417, acc.: 74.22%] [G loss: 0.892913]\n",
      "epoch:26 step:24722 [D loss: 0.508789, acc.: 73.44%] [G loss: 0.876104]\n",
      "epoch:26 step:24723 [D loss: 0.466474, acc.: 76.56%] [G loss: 0.981913]\n",
      "epoch:26 step:24724 [D loss: 0.502925, acc.: 77.34%] [G loss: 0.831407]\n",
      "epoch:26 step:24725 [D loss: 0.523883, acc.: 74.22%] [G loss: 0.700836]\n",
      "epoch:26 step:24726 [D loss: 0.529151, acc.: 71.88%] [G loss: 0.565966]\n",
      "epoch:26 step:24727 [D loss: 0.557202, acc.: 68.75%] [G loss: 0.764122]\n",
      "epoch:26 step:24728 [D loss: 0.531905, acc.: 72.66%] [G loss: 0.826530]\n",
      "epoch:26 step:24729 [D loss: 0.589250, acc.: 65.62%] [G loss: 0.659750]\n",
      "epoch:26 step:24730 [D loss: 0.523527, acc.: 71.09%] [G loss: 0.977481]\n",
      "epoch:26 step:24731 [D loss: 0.495802, acc.: 73.44%] [G loss: 0.805392]\n",
      "epoch:26 step:24732 [D loss: 0.501409, acc.: 78.91%] [G loss: 0.975300]\n",
      "epoch:26 step:24733 [D loss: 0.464595, acc.: 78.91%] [G loss: 0.911386]\n",
      "epoch:26 step:24734 [D loss: 0.561815, acc.: 69.53%] [G loss: 0.804521]\n",
      "epoch:26 step:24735 [D loss: 0.546231, acc.: 69.53%] [G loss: 0.771291]\n",
      "epoch:26 step:24736 [D loss: 0.459425, acc.: 75.00%] [G loss: 0.760338]\n",
      "epoch:26 step:24737 [D loss: 0.550335, acc.: 66.41%] [G loss: 0.793433]\n",
      "epoch:26 step:24738 [D loss: 0.655964, acc.: 65.62%] [G loss: 0.731926]\n",
      "epoch:26 step:24739 [D loss: 0.535378, acc.: 67.19%] [G loss: 0.692041]\n",
      "epoch:26 step:24740 [D loss: 0.494851, acc.: 73.44%] [G loss: 0.899538]\n",
      "epoch:26 step:24741 [D loss: 0.564356, acc.: 71.88%] [G loss: 0.581910]\n",
      "epoch:26 step:24742 [D loss: 0.576095, acc.: 70.31%] [G loss: 0.670198]\n",
      "epoch:26 step:24743 [D loss: 0.526084, acc.: 71.09%] [G loss: 0.790264]\n",
      "epoch:26 step:24744 [D loss: 0.545786, acc.: 70.31%] [G loss: 0.758326]\n",
      "epoch:26 step:24745 [D loss: 0.579869, acc.: 66.41%] [G loss: 0.867670]\n",
      "epoch:26 step:24746 [D loss: 0.515346, acc.: 73.44%] [G loss: 0.718296]\n",
      "epoch:26 step:24747 [D loss: 0.451861, acc.: 78.12%] [G loss: 0.758321]\n",
      "epoch:26 step:24748 [D loss: 0.662286, acc.: 62.50%] [G loss: 0.644436]\n",
      "epoch:26 step:24749 [D loss: 0.503581, acc.: 71.09%] [G loss: 0.800133]\n",
      "epoch:26 step:24750 [D loss: 0.501058, acc.: 75.00%] [G loss: 0.658127]\n",
      "epoch:26 step:24751 [D loss: 0.526754, acc.: 69.53%] [G loss: 0.618024]\n",
      "epoch:26 step:24752 [D loss: 0.590278, acc.: 63.28%] [G loss: 0.687948]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:26 step:24753 [D loss: 0.526739, acc.: 69.53%] [G loss: 0.574948]\n",
      "epoch:26 step:24754 [D loss: 0.504552, acc.: 73.44%] [G loss: 0.750373]\n",
      "epoch:26 step:24755 [D loss: 0.525946, acc.: 71.09%] [G loss: 0.571897]\n",
      "epoch:26 step:24756 [D loss: 0.515937, acc.: 74.22%] [G loss: 0.704060]\n",
      "epoch:26 step:24757 [D loss: 0.489607, acc.: 75.78%] [G loss: 0.693862]\n",
      "epoch:26 step:24758 [D loss: 0.526515, acc.: 72.66%] [G loss: 0.624462]\n",
      "epoch:26 step:24759 [D loss: 0.536528, acc.: 65.62%] [G loss: 0.673107]\n",
      "epoch:26 step:24760 [D loss: 0.471213, acc.: 78.12%] [G loss: 0.762593]\n",
      "epoch:26 step:24761 [D loss: 0.487141, acc.: 78.91%] [G loss: 0.695843]\n",
      "epoch:26 step:24762 [D loss: 0.636854, acc.: 62.50%] [G loss: 0.755052]\n",
      "epoch:26 step:24763 [D loss: 0.582200, acc.: 64.84%] [G loss: 0.619516]\n",
      "epoch:26 step:24764 [D loss: 0.512137, acc.: 74.22%] [G loss: 0.707894]\n",
      "epoch:26 step:24765 [D loss: 0.450317, acc.: 77.34%] [G loss: 0.655738]\n",
      "epoch:26 step:24766 [D loss: 0.552257, acc.: 67.19%] [G loss: 0.629630]\n",
      "epoch:26 step:24767 [D loss: 0.509375, acc.: 74.22%] [G loss: 0.693291]\n",
      "epoch:26 step:24768 [D loss: 0.471916, acc.: 74.22%] [G loss: 0.754223]\n",
      "epoch:26 step:24769 [D loss: 0.560891, acc.: 70.31%] [G loss: 0.886499]\n",
      "epoch:26 step:24770 [D loss: 0.531930, acc.: 75.00%] [G loss: 0.900619]\n",
      "epoch:26 step:24771 [D loss: 0.571500, acc.: 62.50%] [G loss: 0.806079]\n",
      "epoch:26 step:24772 [D loss: 0.528132, acc.: 72.66%] [G loss: 0.659810]\n",
      "epoch:26 step:24773 [D loss: 0.604368, acc.: 61.72%] [G loss: 0.765870]\n",
      "epoch:26 step:24774 [D loss: 0.551981, acc.: 67.97%] [G loss: 0.579566]\n",
      "epoch:26 step:24775 [D loss: 0.546153, acc.: 69.53%] [G loss: 0.597410]\n",
      "epoch:26 step:24776 [D loss: 0.482222, acc.: 75.78%] [G loss: 0.856843]\n",
      "epoch:26 step:24777 [D loss: 0.529051, acc.: 70.31%] [G loss: 0.712528]\n",
      "epoch:26 step:24778 [D loss: 0.452800, acc.: 79.69%] [G loss: 0.890060]\n",
      "epoch:26 step:24779 [D loss: 0.550967, acc.: 70.31%] [G loss: 0.837019]\n",
      "epoch:26 step:24780 [D loss: 0.604333, acc.: 59.38%] [G loss: 0.845037]\n",
      "epoch:26 step:24781 [D loss: 0.593550, acc.: 67.97%] [G loss: 0.705463]\n",
      "epoch:26 step:24782 [D loss: 0.572534, acc.: 66.41%] [G loss: 0.672619]\n",
      "epoch:26 step:24783 [D loss: 0.544187, acc.: 73.44%] [G loss: 0.598111]\n",
      "epoch:26 step:24784 [D loss: 0.613676, acc.: 65.62%] [G loss: 0.480012]\n",
      "epoch:26 step:24785 [D loss: 0.523132, acc.: 73.44%] [G loss: 0.534149]\n",
      "epoch:26 step:24786 [D loss: 0.535853, acc.: 70.31%] [G loss: 0.595816]\n",
      "epoch:26 step:24787 [D loss: 0.488060, acc.: 74.22%] [G loss: 0.552897]\n",
      "epoch:26 step:24788 [D loss: 0.460886, acc.: 76.56%] [G loss: 0.810917]\n",
      "epoch:26 step:24789 [D loss: 0.416175, acc.: 78.12%] [G loss: 0.685216]\n",
      "epoch:26 step:24790 [D loss: 0.497683, acc.: 73.44%] [G loss: 0.812100]\n",
      "epoch:26 step:24791 [D loss: 0.429502, acc.: 79.69%] [G loss: 0.800915]\n",
      "epoch:26 step:24792 [D loss: 0.443581, acc.: 79.69%] [G loss: 0.852989]\n",
      "epoch:26 step:24793 [D loss: 0.455129, acc.: 75.78%] [G loss: 0.872947]\n",
      "epoch:26 step:24794 [D loss: 0.527909, acc.: 70.31%] [G loss: 0.593171]\n",
      "epoch:26 step:24795 [D loss: 0.541892, acc.: 75.00%] [G loss: 0.904304]\n",
      "epoch:26 step:24796 [D loss: 0.510568, acc.: 68.75%] [G loss: 0.719140]\n",
      "epoch:26 step:24797 [D loss: 0.504754, acc.: 70.31%] [G loss: 0.840272]\n",
      "epoch:26 step:24798 [D loss: 0.473870, acc.: 71.88%] [G loss: 0.871158]\n",
      "epoch:26 step:24799 [D loss: 0.678612, acc.: 61.72%] [G loss: 0.661239]\n",
      "epoch:26 step:24800 [D loss: 0.568651, acc.: 66.41%] [G loss: 0.707141]\n",
      "epoch:26 step:24801 [D loss: 0.500014, acc.: 76.56%] [G loss: 0.736983]\n",
      "epoch:26 step:24802 [D loss: 0.463283, acc.: 78.12%] [G loss: 1.020127]\n",
      "epoch:26 step:24803 [D loss: 0.501091, acc.: 75.00%] [G loss: 1.070436]\n",
      "epoch:26 step:24804 [D loss: 0.548734, acc.: 68.75%] [G loss: 0.618230]\n",
      "epoch:26 step:24805 [D loss: 0.530378, acc.: 69.53%] [G loss: 0.924415]\n",
      "epoch:26 step:24806 [D loss: 0.505265, acc.: 74.22%] [G loss: 0.759489]\n",
      "epoch:26 step:24807 [D loss: 0.536199, acc.: 66.41%] [G loss: 0.848099]\n",
      "epoch:26 step:24808 [D loss: 0.485908, acc.: 77.34%] [G loss: 0.860897]\n",
      "epoch:26 step:24809 [D loss: 0.488851, acc.: 75.78%] [G loss: 0.978488]\n",
      "epoch:26 step:24810 [D loss: 0.546781, acc.: 67.97%] [G loss: 0.701855]\n",
      "epoch:26 step:24811 [D loss: 0.508630, acc.: 72.66%] [G loss: 0.719957]\n",
      "epoch:26 step:24812 [D loss: 0.584715, acc.: 65.62%] [G loss: 0.777502]\n",
      "epoch:26 step:24813 [D loss: 0.416691, acc.: 79.69%] [G loss: 0.779404]\n",
      "epoch:26 step:24814 [D loss: 0.431126, acc.: 76.56%] [G loss: 0.944267]\n",
      "epoch:26 step:24815 [D loss: 0.487669, acc.: 75.78%] [G loss: 0.778926]\n",
      "epoch:26 step:24816 [D loss: 0.496113, acc.: 71.88%] [G loss: 0.859025]\n",
      "epoch:26 step:24817 [D loss: 0.563761, acc.: 71.88%] [G loss: 0.727122]\n",
      "epoch:26 step:24818 [D loss: 0.603043, acc.: 63.28%] [G loss: 0.680639]\n",
      "epoch:26 step:24819 [D loss: 0.446618, acc.: 78.91%] [G loss: 0.792003]\n",
      "epoch:26 step:24820 [D loss: 0.623197, acc.: 71.09%] [G loss: 0.833474]\n",
      "epoch:26 step:24821 [D loss: 0.521198, acc.: 71.88%] [G loss: 0.805101]\n",
      "epoch:26 step:24822 [D loss: 0.505680, acc.: 73.44%] [G loss: 0.751673]\n",
      "epoch:26 step:24823 [D loss: 0.478386, acc.: 75.00%] [G loss: 0.747446]\n",
      "epoch:26 step:24824 [D loss: 0.573981, acc.: 66.41%] [G loss: 0.578269]\n",
      "epoch:26 step:24825 [D loss: 0.539679, acc.: 64.84%] [G loss: 0.803059]\n",
      "epoch:26 step:24826 [D loss: 0.513858, acc.: 71.09%] [G loss: 0.711074]\n",
      "epoch:26 step:24827 [D loss: 0.579348, acc.: 68.75%] [G loss: 0.695137]\n",
      "epoch:26 step:24828 [D loss: 0.482592, acc.: 73.44%] [G loss: 0.724468]\n",
      "epoch:26 step:24829 [D loss: 0.557798, acc.: 64.84%] [G loss: 0.508554]\n",
      "epoch:26 step:24830 [D loss: 0.503413, acc.: 77.34%] [G loss: 0.763763]\n",
      "epoch:26 step:24831 [D loss: 0.518450, acc.: 72.66%] [G loss: 0.760823]\n",
      "epoch:26 step:24832 [D loss: 0.500283, acc.: 75.78%] [G loss: 0.882986]\n",
      "epoch:26 step:24833 [D loss: 0.415517, acc.: 80.47%] [G loss: 0.834566]\n",
      "epoch:26 step:24834 [D loss: 0.469432, acc.: 76.56%] [G loss: 0.991086]\n",
      "epoch:26 step:24835 [D loss: 0.636757, acc.: 65.62%] [G loss: 0.793572]\n",
      "epoch:26 step:24836 [D loss: 0.568735, acc.: 65.62%] [G loss: 0.684073]\n",
      "epoch:26 step:24837 [D loss: 0.427867, acc.: 80.47%] [G loss: 0.823819]\n",
      "epoch:26 step:24838 [D loss: 0.518413, acc.: 70.31%] [G loss: 0.848401]\n",
      "epoch:26 step:24839 [D loss: 0.612595, acc.: 65.62%] [G loss: 0.678072]\n",
      "epoch:26 step:24840 [D loss: 0.549944, acc.: 71.88%] [G loss: 0.637654]\n",
      "epoch:26 step:24841 [D loss: 0.560645, acc.: 68.75%] [G loss: 0.495170]\n",
      "epoch:26 step:24842 [D loss: 0.556686, acc.: 71.09%] [G loss: 0.746419]\n",
      "epoch:26 step:24843 [D loss: 0.461995, acc.: 83.59%] [G loss: 0.661113]\n",
      "epoch:26 step:24844 [D loss: 0.547907, acc.: 71.88%] [G loss: 0.683650]\n",
      "epoch:26 step:24845 [D loss: 0.527904, acc.: 73.44%] [G loss: 0.688512]\n",
      "epoch:26 step:24846 [D loss: 0.534856, acc.: 70.31%] [G loss: 0.791641]\n",
      "epoch:26 step:24847 [D loss: 0.500283, acc.: 75.78%] [G loss: 0.946726]\n",
      "epoch:26 step:24848 [D loss: 0.555925, acc.: 65.62%] [G loss: 0.726704]\n",
      "epoch:26 step:24849 [D loss: 0.576739, acc.: 64.84%] [G loss: 0.745668]\n",
      "epoch:26 step:24850 [D loss: 0.434671, acc.: 79.69%] [G loss: 0.666187]\n",
      "epoch:26 step:24851 [D loss: 0.543580, acc.: 70.31%] [G loss: 0.705405]\n",
      "epoch:26 step:24852 [D loss: 0.562221, acc.: 68.75%] [G loss: 0.723953]\n",
      "epoch:26 step:24853 [D loss: 0.508207, acc.: 75.00%] [G loss: 0.703887]\n",
      "epoch:26 step:24854 [D loss: 0.498954, acc.: 75.00%] [G loss: 0.772077]\n",
      "epoch:26 step:24855 [D loss: 0.542242, acc.: 75.00%] [G loss: 0.768835]\n",
      "epoch:26 step:24856 [D loss: 0.581217, acc.: 67.97%] [G loss: 0.541722]\n",
      "epoch:26 step:24857 [D loss: 0.495093, acc.: 76.56%] [G loss: 0.845181]\n",
      "epoch:26 step:24858 [D loss: 0.572378, acc.: 69.53%] [G loss: 0.692589]\n",
      "epoch:26 step:24859 [D loss: 0.550229, acc.: 71.88%] [G loss: 0.719953]\n",
      "epoch:26 step:24860 [D loss: 0.499019, acc.: 74.22%] [G loss: 0.878094]\n",
      "epoch:26 step:24861 [D loss: 0.471030, acc.: 75.78%] [G loss: 0.884457]\n",
      "epoch:26 step:24862 [D loss: 0.570303, acc.: 67.97%] [G loss: 0.710415]\n",
      "epoch:26 step:24863 [D loss: 0.648510, acc.: 70.31%] [G loss: 0.749126]\n",
      "epoch:26 step:24864 [D loss: 0.584738, acc.: 64.84%] [G loss: 0.615235]\n",
      "epoch:26 step:24865 [D loss: 0.521669, acc.: 73.44%] [G loss: 0.446390]\n",
      "epoch:26 step:24866 [D loss: 0.463381, acc.: 77.34%] [G loss: 0.694258]\n",
      "epoch:26 step:24867 [D loss: 0.487623, acc.: 75.78%] [G loss: 0.835955]\n",
      "epoch:26 step:24868 [D loss: 0.505513, acc.: 75.00%] [G loss: 0.956795]\n",
      "epoch:26 step:24869 [D loss: 0.477237, acc.: 76.56%] [G loss: 0.911117]\n",
      "epoch:26 step:24870 [D loss: 0.403903, acc.: 82.03%] [G loss: 1.174864]\n",
      "epoch:26 step:24871 [D loss: 0.503876, acc.: 74.22%] [G loss: 1.188227]\n",
      "epoch:26 step:24872 [D loss: 0.567519, acc.: 72.66%] [G loss: 0.764832]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:26 step:24873 [D loss: 0.673620, acc.: 61.72%] [G loss: 0.533254]\n",
      "epoch:26 step:24874 [D loss: 0.547486, acc.: 68.75%] [G loss: 0.690002]\n",
      "epoch:26 step:24875 [D loss: 0.484997, acc.: 77.34%] [G loss: 0.835235]\n",
      "epoch:26 step:24876 [D loss: 0.466140, acc.: 75.00%] [G loss: 0.785980]\n",
      "epoch:26 step:24877 [D loss: 0.571743, acc.: 67.19%] [G loss: 0.626903]\n",
      "epoch:26 step:24878 [D loss: 0.453181, acc.: 79.69%] [G loss: 0.805933]\n",
      "epoch:26 step:24879 [D loss: 0.480078, acc.: 74.22%] [G loss: 0.779118]\n",
      "epoch:26 step:24880 [D loss: 0.506089, acc.: 74.22%] [G loss: 0.751765]\n",
      "epoch:26 step:24881 [D loss: 0.488184, acc.: 78.12%] [G loss: 0.721264]\n",
      "epoch:26 step:24882 [D loss: 0.454295, acc.: 75.00%] [G loss: 0.725457]\n",
      "epoch:26 step:24883 [D loss: 0.503828, acc.: 75.78%] [G loss: 0.772604]\n",
      "epoch:26 step:24884 [D loss: 0.504590, acc.: 77.34%] [G loss: 0.870574]\n",
      "epoch:26 step:24885 [D loss: 0.420222, acc.: 80.47%] [G loss: 0.947523]\n",
      "epoch:26 step:24886 [D loss: 0.553138, acc.: 68.75%] [G loss: 0.770572]\n",
      "epoch:26 step:24887 [D loss: 0.519095, acc.: 76.56%] [G loss: 0.747103]\n",
      "epoch:26 step:24888 [D loss: 0.492189, acc.: 71.88%] [G loss: 0.869421]\n",
      "epoch:26 step:24889 [D loss: 0.521327, acc.: 71.09%] [G loss: 0.883375]\n",
      "epoch:26 step:24890 [D loss: 0.705472, acc.: 58.59%] [G loss: 0.534665]\n",
      "epoch:26 step:24891 [D loss: 0.582088, acc.: 65.62%] [G loss: 0.583155]\n",
      "epoch:26 step:24892 [D loss: 0.543174, acc.: 70.31%] [G loss: 0.771452]\n",
      "epoch:26 step:24893 [D loss: 0.508029, acc.: 72.66%] [G loss: 0.690753]\n",
      "epoch:26 step:24894 [D loss: 0.582934, acc.: 72.66%] [G loss: 0.639600]\n",
      "epoch:26 step:24895 [D loss: 0.552547, acc.: 69.53%] [G loss: 0.747504]\n",
      "epoch:26 step:24896 [D loss: 0.475206, acc.: 75.78%] [G loss: 0.707444]\n",
      "epoch:26 step:24897 [D loss: 0.660600, acc.: 60.16%] [G loss: 0.462587]\n",
      "epoch:26 step:24898 [D loss: 0.506013, acc.: 73.44%] [G loss: 0.515541]\n",
      "epoch:26 step:24899 [D loss: 0.560524, acc.: 68.75%] [G loss: 0.735688]\n",
      "epoch:26 step:24900 [D loss: 0.546491, acc.: 68.75%] [G loss: 0.708486]\n",
      "epoch:26 step:24901 [D loss: 0.514910, acc.: 72.66%] [G loss: 0.778359]\n",
      "epoch:26 step:24902 [D loss: 0.525224, acc.: 71.09%] [G loss: 0.637948]\n",
      "epoch:26 step:24903 [D loss: 0.500150, acc.: 71.09%] [G loss: 0.819544]\n",
      "epoch:26 step:24904 [D loss: 0.664319, acc.: 60.94%] [G loss: 0.696106]\n",
      "epoch:26 step:24905 [D loss: 0.550575, acc.: 67.97%] [G loss: 0.668560]\n",
      "epoch:26 step:24906 [D loss: 0.525051, acc.: 68.75%] [G loss: 0.637908]\n",
      "epoch:26 step:24907 [D loss: 0.531960, acc.: 72.66%] [G loss: 0.766817]\n",
      "epoch:26 step:24908 [D loss: 0.446634, acc.: 79.69%] [G loss: 0.860871]\n",
      "epoch:26 step:24909 [D loss: 0.549196, acc.: 67.19%] [G loss: 0.834845]\n",
      "epoch:26 step:24910 [D loss: 0.464531, acc.: 79.69%] [G loss: 0.702241]\n",
      "epoch:26 step:24911 [D loss: 0.571661, acc.: 67.97%] [G loss: 0.656537]\n",
      "epoch:26 step:24912 [D loss: 0.472480, acc.: 78.12%] [G loss: 0.760133]\n",
      "epoch:26 step:24913 [D loss: 0.437093, acc.: 78.12%] [G loss: 0.862672]\n",
      "epoch:26 step:24914 [D loss: 0.457857, acc.: 77.34%] [G loss: 0.739600]\n",
      "epoch:26 step:24915 [D loss: 0.617282, acc.: 64.84%] [G loss: 0.739208]\n",
      "epoch:26 step:24916 [D loss: 0.514914, acc.: 75.78%] [G loss: 0.773251]\n",
      "epoch:26 step:24917 [D loss: 0.433551, acc.: 78.12%] [G loss: 0.816903]\n",
      "epoch:26 step:24918 [D loss: 0.543349, acc.: 71.88%] [G loss: 0.860573]\n",
      "epoch:26 step:24919 [D loss: 0.518180, acc.: 74.22%] [G loss: 0.761910]\n",
      "epoch:26 step:24920 [D loss: 0.464573, acc.: 78.91%] [G loss: 1.026071]\n",
      "epoch:26 step:24921 [D loss: 0.567430, acc.: 70.31%] [G loss: 0.694191]\n",
      "epoch:26 step:24922 [D loss: 0.567133, acc.: 68.75%] [G loss: 0.577235]\n",
      "epoch:26 step:24923 [D loss: 0.512725, acc.: 73.44%] [G loss: 0.633657]\n",
      "epoch:26 step:24924 [D loss: 0.544189, acc.: 68.75%] [G loss: 0.638606]\n",
      "epoch:26 step:24925 [D loss: 0.538743, acc.: 71.09%] [G loss: 0.622474]\n",
      "epoch:26 step:24926 [D loss: 0.526460, acc.: 73.44%] [G loss: 1.004510]\n",
      "epoch:26 step:24927 [D loss: 0.470668, acc.: 84.38%] [G loss: 0.959293]\n",
      "epoch:26 step:24928 [D loss: 0.701367, acc.: 63.28%] [G loss: 0.720293]\n",
      "epoch:26 step:24929 [D loss: 0.513927, acc.: 74.22%] [G loss: 0.655365]\n",
      "epoch:26 step:24930 [D loss: 0.478455, acc.: 79.69%] [G loss: 0.701880]\n",
      "epoch:26 step:24931 [D loss: 0.521119, acc.: 74.22%] [G loss: 0.856256]\n",
      "epoch:26 step:24932 [D loss: 0.527685, acc.: 72.66%] [G loss: 0.877781]\n",
      "epoch:26 step:24933 [D loss: 0.505150, acc.: 75.00%] [G loss: 0.637593]\n",
      "epoch:26 step:24934 [D loss: 0.571254, acc.: 71.09%] [G loss: 0.765079]\n",
      "epoch:26 step:24935 [D loss: 0.572901, acc.: 70.31%] [G loss: 0.701951]\n",
      "epoch:26 step:24936 [D loss: 0.501959, acc.: 75.00%] [G loss: 0.786329]\n",
      "epoch:26 step:24937 [D loss: 0.441751, acc.: 80.47%] [G loss: 0.929079]\n",
      "epoch:26 step:24938 [D loss: 0.596451, acc.: 64.84%] [G loss: 0.884963]\n",
      "epoch:26 step:24939 [D loss: 0.522398, acc.: 74.22%] [G loss: 0.802883]\n",
      "epoch:26 step:24940 [D loss: 0.520406, acc.: 71.88%] [G loss: 0.701428]\n",
      "epoch:26 step:24941 [D loss: 0.501098, acc.: 75.78%] [G loss: 0.680946]\n",
      "epoch:26 step:24942 [D loss: 0.535228, acc.: 73.44%] [G loss: 0.664013]\n",
      "epoch:26 step:24943 [D loss: 0.521853, acc.: 75.00%] [G loss: 0.560834]\n",
      "epoch:26 step:24944 [D loss: 0.451073, acc.: 78.12%] [G loss: 0.812443]\n",
      "epoch:26 step:24945 [D loss: 0.510037, acc.: 71.88%] [G loss: 0.871773]\n",
      "epoch:26 step:24946 [D loss: 0.593719, acc.: 64.06%] [G loss: 0.793093]\n",
      "epoch:26 step:24947 [D loss: 0.558190, acc.: 71.88%] [G loss: 0.647775]\n",
      "epoch:26 step:24948 [D loss: 0.536447, acc.: 67.97%] [G loss: 0.616828]\n",
      "epoch:26 step:24949 [D loss: 0.583290, acc.: 65.62%] [G loss: 0.545269]\n",
      "epoch:26 step:24950 [D loss: 0.521442, acc.: 73.44%] [G loss: 0.732108]\n",
      "epoch:26 step:24951 [D loss: 0.551402, acc.: 71.88%] [G loss: 0.696544]\n",
      "epoch:26 step:24952 [D loss: 0.535116, acc.: 71.09%] [G loss: 0.899529]\n",
      "epoch:26 step:24953 [D loss: 0.627604, acc.: 67.97%] [G loss: 0.778923]\n",
      "epoch:26 step:24954 [D loss: 0.464063, acc.: 76.56%] [G loss: 0.785281]\n",
      "epoch:26 step:24955 [D loss: 0.466589, acc.: 75.78%] [G loss: 0.782209]\n",
      "epoch:26 step:24956 [D loss: 0.517982, acc.: 70.31%] [G loss: 0.917101]\n",
      "epoch:26 step:24957 [D loss: 0.523819, acc.: 72.66%] [G loss: 0.694048]\n",
      "epoch:26 step:24958 [D loss: 0.494555, acc.: 71.88%] [G loss: 0.719807]\n",
      "epoch:26 step:24959 [D loss: 0.513503, acc.: 77.34%] [G loss: 0.802077]\n",
      "epoch:26 step:24960 [D loss: 0.457038, acc.: 77.34%] [G loss: 0.796135]\n",
      "epoch:26 step:24961 [D loss: 0.548125, acc.: 67.97%] [G loss: 0.750360]\n",
      "epoch:26 step:24962 [D loss: 0.515409, acc.: 71.09%] [G loss: 0.676016]\n",
      "epoch:26 step:24963 [D loss: 0.439731, acc.: 78.12%] [G loss: 0.943527]\n",
      "epoch:26 step:24964 [D loss: 0.491717, acc.: 71.09%] [G loss: 1.152004]\n",
      "epoch:26 step:24965 [D loss: 0.511321, acc.: 74.22%] [G loss: 0.955069]\n",
      "epoch:26 step:24966 [D loss: 0.512066, acc.: 75.78%] [G loss: 0.965384]\n",
      "epoch:26 step:24967 [D loss: 0.471422, acc.: 78.91%] [G loss: 0.938437]\n",
      "epoch:26 step:24968 [D loss: 0.565853, acc.: 71.88%] [G loss: 0.728627]\n",
      "epoch:26 step:24969 [D loss: 0.470951, acc.: 75.78%] [G loss: 0.593025]\n",
      "epoch:26 step:24970 [D loss: 0.554897, acc.: 68.75%] [G loss: 0.665382]\n",
      "epoch:26 step:24971 [D loss: 0.499219, acc.: 75.78%] [G loss: 0.604094]\n",
      "epoch:26 step:24972 [D loss: 0.556275, acc.: 70.31%] [G loss: 0.636621]\n",
      "epoch:26 step:24973 [D loss: 0.479788, acc.: 76.56%] [G loss: 0.596290]\n",
      "epoch:26 step:24974 [D loss: 0.539731, acc.: 69.53%] [G loss: 0.691330]\n",
      "epoch:26 step:24975 [D loss: 0.466847, acc.: 78.91%] [G loss: 0.875539]\n",
      "epoch:26 step:24976 [D loss: 0.523612, acc.: 72.66%] [G loss: 0.742338]\n",
      "epoch:26 step:24977 [D loss: 0.563869, acc.: 67.97%] [G loss: 0.713946]\n",
      "epoch:26 step:24978 [D loss: 0.468541, acc.: 77.34%] [G loss: 0.763315]\n",
      "epoch:26 step:24979 [D loss: 0.567822, acc.: 67.97%] [G loss: 0.632076]\n",
      "epoch:26 step:24980 [D loss: 0.500632, acc.: 73.44%] [G loss: 0.828407]\n",
      "epoch:26 step:24981 [D loss: 0.562988, acc.: 64.84%] [G loss: 0.779527]\n",
      "epoch:26 step:24982 [D loss: 0.543140, acc.: 72.66%] [G loss: 0.845859]\n",
      "epoch:26 step:24983 [D loss: 0.552929, acc.: 74.22%] [G loss: 0.763426]\n",
      "epoch:26 step:24984 [D loss: 0.557862, acc.: 68.75%] [G loss: 0.570236]\n",
      "epoch:26 step:24985 [D loss: 0.447571, acc.: 75.00%] [G loss: 0.671241]\n",
      "epoch:26 step:24986 [D loss: 0.494882, acc.: 75.00%] [G loss: 0.896982]\n",
      "epoch:26 step:24987 [D loss: 0.507499, acc.: 71.88%] [G loss: 1.000423]\n",
      "epoch:26 step:24988 [D loss: 0.581936, acc.: 70.31%] [G loss: 0.699003]\n",
      "epoch:26 step:24989 [D loss: 0.513561, acc.: 68.75%] [G loss: 0.765372]\n",
      "epoch:26 step:24990 [D loss: 0.530948, acc.: 71.09%] [G loss: 0.703952]\n",
      "epoch:26 step:24991 [D loss: 0.548740, acc.: 65.62%] [G loss: 0.677519]\n",
      "epoch:26 step:24992 [D loss: 0.544024, acc.: 70.31%] [G loss: 0.768438]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:26 step:24993 [D loss: 0.453490, acc.: 82.03%] [G loss: 0.711182]\n",
      "epoch:26 step:24994 [D loss: 0.478979, acc.: 75.78%] [G loss: 0.892117]\n",
      "epoch:26 step:24995 [D loss: 0.486999, acc.: 71.88%] [G loss: 0.769453]\n",
      "epoch:26 step:24996 [D loss: 0.442655, acc.: 78.91%] [G loss: 0.866771]\n",
      "epoch:26 step:24997 [D loss: 0.504956, acc.: 71.88%] [G loss: 0.841634]\n",
      "epoch:26 step:24998 [D loss: 0.570090, acc.: 68.75%] [G loss: 0.821519]\n",
      "epoch:26 step:24999 [D loss: 0.550424, acc.: 71.88%] [G loss: 0.692315]\n",
      "epoch:26 step:25000 [D loss: 0.475614, acc.: 75.00%] [G loss: 0.771802]\n",
      "epoch:26 step:25001 [D loss: 0.451875, acc.: 78.12%] [G loss: 0.818366]\n",
      "epoch:26 step:25002 [D loss: 0.568543, acc.: 71.88%] [G loss: 0.568792]\n",
      "epoch:26 step:25003 [D loss: 0.471296, acc.: 77.34%] [G loss: 0.868760]\n",
      "epoch:26 step:25004 [D loss: 0.483671, acc.: 75.00%] [G loss: 0.954335]\n",
      "epoch:26 step:25005 [D loss: 0.486445, acc.: 75.00%] [G loss: 0.997773]\n",
      "epoch:26 step:25006 [D loss: 0.569840, acc.: 67.19%] [G loss: 0.729652]\n",
      "epoch:26 step:25007 [D loss: 0.516476, acc.: 71.09%] [G loss: 0.793517]\n",
      "epoch:26 step:25008 [D loss: 0.581751, acc.: 71.09%] [G loss: 0.686688]\n",
      "epoch:26 step:25009 [D loss: 0.413000, acc.: 82.03%] [G loss: 0.902976]\n",
      "epoch:26 step:25010 [D loss: 0.411478, acc.: 82.81%] [G loss: 0.904418]\n",
      "epoch:26 step:25011 [D loss: 0.434041, acc.: 78.91%] [G loss: 0.921174]\n",
      "epoch:26 step:25012 [D loss: 0.455605, acc.: 74.22%] [G loss: 0.906277]\n",
      "epoch:26 step:25013 [D loss: 0.503214, acc.: 74.22%] [G loss: 0.861486]\n",
      "epoch:26 step:25014 [D loss: 0.585773, acc.: 64.06%] [G loss: 0.768041]\n",
      "epoch:26 step:25015 [D loss: 0.510980, acc.: 72.66%] [G loss: 0.781097]\n",
      "epoch:26 step:25016 [D loss: 0.450722, acc.: 77.34%] [G loss: 0.969809]\n",
      "epoch:26 step:25017 [D loss: 0.539981, acc.: 75.00%] [G loss: 0.770813]\n",
      "epoch:26 step:25018 [D loss: 0.542076, acc.: 73.44%] [G loss: 0.622600]\n",
      "epoch:26 step:25019 [D loss: 0.480135, acc.: 75.00%] [G loss: 0.680594]\n",
      "epoch:26 step:25020 [D loss: 0.554854, acc.: 68.75%] [G loss: 0.811626]\n",
      "epoch:26 step:25021 [D loss: 0.509743, acc.: 72.66%] [G loss: 0.749776]\n",
      "epoch:26 step:25022 [D loss: 0.495679, acc.: 68.75%] [G loss: 0.893924]\n",
      "epoch:26 step:25023 [D loss: 0.500738, acc.: 75.00%] [G loss: 0.778710]\n",
      "epoch:26 step:25024 [D loss: 0.495155, acc.: 78.12%] [G loss: 0.849752]\n",
      "epoch:26 step:25025 [D loss: 0.576370, acc.: 67.19%] [G loss: 0.751419]\n",
      "epoch:26 step:25026 [D loss: 0.480369, acc.: 73.44%] [G loss: 1.014810]\n",
      "epoch:26 step:25027 [D loss: 0.541760, acc.: 71.88%] [G loss: 0.846868]\n",
      "epoch:26 step:25028 [D loss: 0.487484, acc.: 73.44%] [G loss: 0.913991]\n",
      "epoch:26 step:25029 [D loss: 0.535650, acc.: 71.88%] [G loss: 0.778445]\n",
      "epoch:26 step:25030 [D loss: 0.514478, acc.: 75.00%] [G loss: 0.874575]\n",
      "epoch:26 step:25031 [D loss: 0.526557, acc.: 71.88%] [G loss: 0.708752]\n",
      "epoch:26 step:25032 [D loss: 0.530095, acc.: 72.66%] [G loss: 0.636343]\n",
      "epoch:26 step:25033 [D loss: 0.516655, acc.: 72.66%] [G loss: 0.790927]\n",
      "epoch:26 step:25034 [D loss: 0.485160, acc.: 76.56%] [G loss: 0.736527]\n",
      "epoch:26 step:25035 [D loss: 0.561762, acc.: 67.97%] [G loss: 0.660821]\n",
      "epoch:26 step:25036 [D loss: 0.455491, acc.: 78.12%] [G loss: 0.748787]\n",
      "epoch:26 step:25037 [D loss: 0.652501, acc.: 60.16%] [G loss: 0.633625]\n",
      "epoch:26 step:25038 [D loss: 0.470940, acc.: 73.44%] [G loss: 0.770563]\n",
      "epoch:26 step:25039 [D loss: 0.529935, acc.: 70.31%] [G loss: 0.751885]\n",
      "epoch:26 step:25040 [D loss: 0.540689, acc.: 67.97%] [G loss: 0.785469]\n",
      "epoch:26 step:25041 [D loss: 0.480727, acc.: 75.00%] [G loss: 0.796181]\n",
      "epoch:26 step:25042 [D loss: 0.497218, acc.: 77.34%] [G loss: 0.775292]\n",
      "epoch:26 step:25043 [D loss: 0.447746, acc.: 77.34%] [G loss: 0.777307]\n",
      "epoch:26 step:25044 [D loss: 0.548828, acc.: 75.00%] [G loss: 0.793356]\n",
      "epoch:26 step:25045 [D loss: 0.537711, acc.: 68.75%] [G loss: 0.669301]\n",
      "epoch:26 step:25046 [D loss: 0.590009, acc.: 64.84%] [G loss: 0.726483]\n",
      "epoch:26 step:25047 [D loss: 0.542331, acc.: 70.31%] [G loss: 0.581855]\n",
      "epoch:26 step:25048 [D loss: 0.532565, acc.: 70.31%] [G loss: 0.750972]\n",
      "epoch:26 step:25049 [D loss: 0.544062, acc.: 71.88%] [G loss: 0.677043]\n",
      "epoch:26 step:25050 [D loss: 0.491412, acc.: 73.44%] [G loss: 0.789276]\n",
      "epoch:26 step:25051 [D loss: 0.531988, acc.: 67.19%] [G loss: 0.710582]\n",
      "epoch:26 step:25052 [D loss: 0.504173, acc.: 69.53%] [G loss: 0.717647]\n",
      "epoch:26 step:25053 [D loss: 0.532986, acc.: 71.88%] [G loss: 0.793286]\n",
      "epoch:26 step:25054 [D loss: 0.496463, acc.: 75.00%] [G loss: 0.696349]\n",
      "epoch:26 step:25055 [D loss: 0.476317, acc.: 71.88%] [G loss: 0.924726]\n",
      "epoch:26 step:25056 [D loss: 0.447627, acc.: 79.69%] [G loss: 0.799753]\n",
      "epoch:26 step:25057 [D loss: 0.517870, acc.: 74.22%] [G loss: 0.655180]\n",
      "epoch:26 step:25058 [D loss: 0.582823, acc.: 71.88%] [G loss: 0.775909]\n",
      "epoch:26 step:25059 [D loss: 0.558001, acc.: 71.88%] [G loss: 0.770959]\n",
      "epoch:26 step:25060 [D loss: 0.588447, acc.: 64.06%] [G loss: 0.481126]\n",
      "epoch:26 step:25061 [D loss: 0.474435, acc.: 77.34%] [G loss: 0.679063]\n",
      "epoch:26 step:25062 [D loss: 0.516400, acc.: 74.22%] [G loss: 0.698068]\n",
      "epoch:26 step:25063 [D loss: 0.480716, acc.: 76.56%] [G loss: 0.823863]\n",
      "epoch:26 step:25064 [D loss: 0.595642, acc.: 63.28%] [G loss: 0.702829]\n",
      "epoch:26 step:25065 [D loss: 0.602292, acc.: 66.41%] [G loss: 0.709439]\n",
      "epoch:26 step:25066 [D loss: 0.598581, acc.: 64.84%] [G loss: 0.437864]\n",
      "epoch:26 step:25067 [D loss: 0.491336, acc.: 71.88%] [G loss: 0.555851]\n",
      "epoch:26 step:25068 [D loss: 0.523852, acc.: 71.09%] [G loss: 0.592287]\n",
      "epoch:26 step:25069 [D loss: 0.495219, acc.: 71.88%] [G loss: 0.689010]\n",
      "epoch:26 step:25070 [D loss: 0.492756, acc.: 76.56%] [G loss: 0.686265]\n",
      "epoch:26 step:25071 [D loss: 0.523994, acc.: 72.66%] [G loss: 0.668407]\n",
      "epoch:26 step:25072 [D loss: 0.584688, acc.: 63.28%] [G loss: 0.600370]\n",
      "epoch:26 step:25073 [D loss: 0.496543, acc.: 71.88%] [G loss: 0.612340]\n",
      "epoch:26 step:25074 [D loss: 0.529954, acc.: 73.44%] [G loss: 0.666151]\n",
      "epoch:26 step:25075 [D loss: 0.527028, acc.: 68.75%] [G loss: 0.734444]\n",
      "epoch:26 step:25076 [D loss: 0.545586, acc.: 65.62%] [G loss: 0.719697]\n",
      "epoch:26 step:25077 [D loss: 0.522151, acc.: 71.09%] [G loss: 0.822038]\n",
      "epoch:26 step:25078 [D loss: 0.552666, acc.: 71.88%] [G loss: 0.676464]\n",
      "epoch:26 step:25079 [D loss: 0.522243, acc.: 72.66%] [G loss: 0.558193]\n",
      "epoch:26 step:25080 [D loss: 0.536139, acc.: 67.19%] [G loss: 0.722406]\n",
      "epoch:26 step:25081 [D loss: 0.455107, acc.: 82.03%] [G loss: 0.808013]\n",
      "epoch:26 step:25082 [D loss: 0.630636, acc.: 64.84%] [G loss: 0.723217]\n",
      "epoch:26 step:25083 [D loss: 0.548266, acc.: 72.66%] [G loss: 0.679186]\n",
      "epoch:26 step:25084 [D loss: 0.543492, acc.: 71.09%] [G loss: 0.687528]\n",
      "epoch:26 step:25085 [D loss: 0.521728, acc.: 72.66%] [G loss: 0.736315]\n",
      "epoch:26 step:25086 [D loss: 0.491721, acc.: 77.34%] [G loss: 0.772863]\n",
      "epoch:26 step:25087 [D loss: 0.589032, acc.: 68.75%] [G loss: 0.783888]\n",
      "epoch:26 step:25088 [D loss: 0.512449, acc.: 74.22%] [G loss: 0.910454]\n",
      "epoch:26 step:25089 [D loss: 0.550228, acc.: 64.84%] [G loss: 0.736187]\n",
      "epoch:26 step:25090 [D loss: 0.496466, acc.: 71.09%] [G loss: 0.767892]\n",
      "epoch:26 step:25091 [D loss: 0.514613, acc.: 73.44%] [G loss: 0.644896]\n",
      "epoch:26 step:25092 [D loss: 0.562317, acc.: 67.97%] [G loss: 0.770292]\n",
      "epoch:26 step:25093 [D loss: 0.596236, acc.: 60.94%] [G loss: 0.904938]\n",
      "epoch:26 step:25094 [D loss: 0.509428, acc.: 67.97%] [G loss: 0.864466]\n",
      "epoch:26 step:25095 [D loss: 0.514061, acc.: 74.22%] [G loss: 0.723752]\n",
      "epoch:26 step:25096 [D loss: 0.503639, acc.: 73.44%] [G loss: 0.589134]\n",
      "epoch:26 step:25097 [D loss: 0.551893, acc.: 68.75%] [G loss: 0.626047]\n",
      "epoch:26 step:25098 [D loss: 0.458228, acc.: 78.91%] [G loss: 0.739022]\n",
      "epoch:26 step:25099 [D loss: 0.507915, acc.: 71.88%] [G loss: 0.748926]\n",
      "epoch:26 step:25100 [D loss: 0.493060, acc.: 73.44%] [G loss: 0.692801]\n",
      "epoch:26 step:25101 [D loss: 0.556027, acc.: 70.31%] [G loss: 0.623983]\n",
      "epoch:26 step:25102 [D loss: 0.614041, acc.: 62.50%] [G loss: 0.499398]\n",
      "epoch:26 step:25103 [D loss: 0.480810, acc.: 75.00%] [G loss: 0.556378]\n",
      "epoch:26 step:25104 [D loss: 0.450494, acc.: 78.91%] [G loss: 0.890013]\n",
      "epoch:26 step:25105 [D loss: 0.470119, acc.: 75.78%] [G loss: 0.822072]\n",
      "epoch:26 step:25106 [D loss: 0.518203, acc.: 76.56%] [G loss: 0.856885]\n",
      "epoch:26 step:25107 [D loss: 0.561110, acc.: 67.19%] [G loss: 0.863804]\n",
      "epoch:26 step:25108 [D loss: 0.411573, acc.: 82.03%] [G loss: 0.682775]\n",
      "epoch:26 step:25109 [D loss: 0.412138, acc.: 84.38%] [G loss: 0.785396]\n",
      "epoch:26 step:25110 [D loss: 0.540123, acc.: 72.66%] [G loss: 0.681768]\n",
      "epoch:26 step:25111 [D loss: 0.594732, acc.: 71.09%] [G loss: 0.909514]\n",
      "epoch:26 step:25112 [D loss: 0.526948, acc.: 74.22%] [G loss: 0.716546]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:26 step:25113 [D loss: 0.518440, acc.: 67.97%] [G loss: 0.750941]\n",
      "epoch:26 step:25114 [D loss: 0.560915, acc.: 67.97%] [G loss: 0.740291]\n",
      "epoch:26 step:25115 [D loss: 0.512563, acc.: 71.09%] [G loss: 0.802556]\n",
      "epoch:26 step:25116 [D loss: 0.556546, acc.: 67.97%] [G loss: 0.805228]\n",
      "epoch:26 step:25117 [D loss: 0.530194, acc.: 67.19%] [G loss: 0.745066]\n",
      "epoch:26 step:25118 [D loss: 0.551129, acc.: 68.75%] [G loss: 0.681534]\n",
      "epoch:26 step:25119 [D loss: 0.531443, acc.: 72.66%] [G loss: 0.626772]\n",
      "epoch:26 step:25120 [D loss: 0.499893, acc.: 76.56%] [G loss: 0.876782]\n",
      "epoch:26 step:25121 [D loss: 0.534651, acc.: 70.31%] [G loss: 0.776563]\n",
      "epoch:26 step:25122 [D loss: 0.500752, acc.: 73.44%] [G loss: 0.690167]\n",
      "epoch:26 step:25123 [D loss: 0.562980, acc.: 68.75%] [G loss: 0.741661]\n",
      "epoch:26 step:25124 [D loss: 0.546677, acc.: 70.31%] [G loss: 0.579928]\n",
      "epoch:26 step:25125 [D loss: 0.534677, acc.: 70.31%] [G loss: 0.590250]\n",
      "epoch:26 step:25126 [D loss: 0.601899, acc.: 64.84%] [G loss: 0.598589]\n",
      "epoch:26 step:25127 [D loss: 0.549761, acc.: 67.97%] [G loss: 0.655343]\n",
      "epoch:26 step:25128 [D loss: 0.615019, acc.: 61.72%] [G loss: 0.449222]\n",
      "epoch:26 step:25129 [D loss: 0.507019, acc.: 76.56%] [G loss: 0.675543]\n",
      "epoch:26 step:25130 [D loss: 0.560299, acc.: 73.44%] [G loss: 0.700014]\n",
      "epoch:26 step:25131 [D loss: 0.477083, acc.: 75.78%] [G loss: 0.966315]\n",
      "epoch:26 step:25132 [D loss: 0.546010, acc.: 71.09%] [G loss: 0.792929]\n",
      "epoch:26 step:25133 [D loss: 0.496937, acc.: 71.09%] [G loss: 0.763057]\n",
      "epoch:26 step:25134 [D loss: 0.503329, acc.: 72.66%] [G loss: 0.932418]\n",
      "epoch:26 step:25135 [D loss: 0.502885, acc.: 74.22%] [G loss: 0.671368]\n",
      "epoch:26 step:25136 [D loss: 0.564273, acc.: 71.09%] [G loss: 0.682153]\n",
      "epoch:26 step:25137 [D loss: 0.484693, acc.: 75.78%] [G loss: 0.743749]\n",
      "epoch:26 step:25138 [D loss: 0.507469, acc.: 74.22%] [G loss: 0.773863]\n",
      "epoch:26 step:25139 [D loss: 0.493986, acc.: 75.00%] [G loss: 0.663658]\n",
      "epoch:26 step:25140 [D loss: 0.616056, acc.: 66.41%] [G loss: 0.590492]\n",
      "epoch:26 step:25141 [D loss: 0.497187, acc.: 78.12%] [G loss: 0.785962]\n",
      "epoch:26 step:25142 [D loss: 0.466680, acc.: 77.34%] [G loss: 0.755052]\n",
      "epoch:26 step:25143 [D loss: 0.467326, acc.: 78.12%] [G loss: 0.762448]\n",
      "epoch:26 step:25144 [D loss: 0.485057, acc.: 78.91%] [G loss: 0.873216]\n",
      "epoch:26 step:25145 [D loss: 0.549652, acc.: 68.75%] [G loss: 0.915596]\n",
      "epoch:26 step:25146 [D loss: 0.593161, acc.: 69.53%] [G loss: 0.981628]\n",
      "epoch:26 step:25147 [D loss: 0.527861, acc.: 70.31%] [G loss: 0.792921]\n",
      "epoch:26 step:25148 [D loss: 0.500533, acc.: 74.22%] [G loss: 0.897963]\n",
      "epoch:26 step:25149 [D loss: 0.542185, acc.: 68.75%] [G loss: 0.763199]\n",
      "epoch:26 step:25150 [D loss: 0.607927, acc.: 65.62%] [G loss: 0.711882]\n",
      "epoch:26 step:25151 [D loss: 0.491125, acc.: 74.22%] [G loss: 0.836580]\n",
      "epoch:26 step:25152 [D loss: 0.515515, acc.: 72.66%] [G loss: 0.607302]\n",
      "epoch:26 step:25153 [D loss: 0.490983, acc.: 72.66%] [G loss: 0.971182]\n",
      "epoch:26 step:25154 [D loss: 0.423392, acc.: 78.91%] [G loss: 0.940545]\n",
      "epoch:26 step:25155 [D loss: 0.571335, acc.: 67.97%] [G loss: 0.952181]\n",
      "epoch:26 step:25156 [D loss: 0.566088, acc.: 67.97%] [G loss: 1.042041]\n",
      "epoch:26 step:25157 [D loss: 0.564833, acc.: 70.31%] [G loss: 0.774369]\n",
      "epoch:26 step:25158 [D loss: 0.550248, acc.: 70.31%] [G loss: 0.952178]\n",
      "epoch:26 step:25159 [D loss: 0.497560, acc.: 75.78%] [G loss: 0.979432]\n",
      "epoch:26 step:25160 [D loss: 0.527481, acc.: 70.31%] [G loss: 0.629868]\n",
      "epoch:26 step:25161 [D loss: 0.595890, acc.: 67.97%] [G loss: 0.816778]\n",
      "epoch:26 step:25162 [D loss: 0.641544, acc.: 64.06%] [G loss: 0.659552]\n",
      "epoch:26 step:25163 [D loss: 0.565541, acc.: 75.00%] [G loss: 0.688255]\n",
      "epoch:26 step:25164 [D loss: 0.500394, acc.: 75.78%] [G loss: 0.823594]\n",
      "epoch:26 step:25165 [D loss: 0.476419, acc.: 78.12%] [G loss: 0.749210]\n",
      "epoch:26 step:25166 [D loss: 0.465378, acc.: 78.12%] [G loss: 0.679784]\n",
      "epoch:26 step:25167 [D loss: 0.502181, acc.: 70.31%] [G loss: 0.763313]\n",
      "epoch:26 step:25168 [D loss: 0.529011, acc.: 73.44%] [G loss: 0.598954]\n",
      "epoch:26 step:25169 [D loss: 0.511734, acc.: 74.22%] [G loss: 0.556211]\n",
      "epoch:26 step:25170 [D loss: 0.489236, acc.: 78.91%] [G loss: 0.693353]\n",
      "epoch:26 step:25171 [D loss: 0.491766, acc.: 76.56%] [G loss: 0.835731]\n",
      "epoch:26 step:25172 [D loss: 0.532543, acc.: 72.66%] [G loss: 0.658686]\n",
      "epoch:26 step:25173 [D loss: 0.525069, acc.: 77.34%] [G loss: 0.736175]\n",
      "epoch:26 step:25174 [D loss: 0.605797, acc.: 64.06%] [G loss: 0.732189]\n",
      "epoch:26 step:25175 [D loss: 0.465783, acc.: 77.34%] [G loss: 0.684538]\n",
      "epoch:26 step:25176 [D loss: 0.445737, acc.: 78.91%] [G loss: 0.707338]\n",
      "epoch:26 step:25177 [D loss: 0.521171, acc.: 71.88%] [G loss: 0.894385]\n",
      "epoch:26 step:25178 [D loss: 0.486681, acc.: 75.78%] [G loss: 0.863907]\n",
      "epoch:26 step:25179 [D loss: 0.585385, acc.: 68.75%] [G loss: 1.071506]\n",
      "epoch:26 step:25180 [D loss: 0.574843, acc.: 67.19%] [G loss: 0.828682]\n",
      "epoch:26 step:25181 [D loss: 0.476217, acc.: 78.12%] [G loss: 0.679956]\n",
      "epoch:26 step:25182 [D loss: 0.616644, acc.: 64.84%] [G loss: 0.650190]\n",
      "epoch:26 step:25183 [D loss: 0.518427, acc.: 72.66%] [G loss: 0.710554]\n",
      "epoch:26 step:25184 [D loss: 0.539023, acc.: 65.62%] [G loss: 0.756846]\n",
      "epoch:26 step:25185 [D loss: 0.460692, acc.: 80.47%] [G loss: 0.596333]\n",
      "epoch:26 step:25186 [D loss: 0.550237, acc.: 71.09%] [G loss: 0.623142]\n",
      "epoch:26 step:25187 [D loss: 0.477835, acc.: 74.22%] [G loss: 0.661229]\n",
      "epoch:26 step:25188 [D loss: 0.478368, acc.: 71.88%] [G loss: 0.689910]\n",
      "epoch:26 step:25189 [D loss: 0.484877, acc.: 71.88%] [G loss: 0.983078]\n",
      "epoch:26 step:25190 [D loss: 0.659150, acc.: 60.94%] [G loss: 0.678021]\n",
      "epoch:26 step:25191 [D loss: 0.578304, acc.: 66.41%] [G loss: 0.676380]\n",
      "epoch:26 step:25192 [D loss: 0.534591, acc.: 73.44%] [G loss: 0.752996]\n",
      "epoch:26 step:25193 [D loss: 0.541215, acc.: 70.31%] [G loss: 0.803095]\n",
      "epoch:26 step:25194 [D loss: 0.528268, acc.: 70.31%] [G loss: 0.671328]\n",
      "epoch:26 step:25195 [D loss: 0.494498, acc.: 77.34%] [G loss: 0.591888]\n",
      "epoch:26 step:25196 [D loss: 0.459954, acc.: 73.44%] [G loss: 0.623443]\n",
      "epoch:26 step:25197 [D loss: 0.494069, acc.: 74.22%] [G loss: 0.713742]\n",
      "epoch:26 step:25198 [D loss: 0.525634, acc.: 67.97%] [G loss: 0.767723]\n",
      "epoch:26 step:25199 [D loss: 0.509047, acc.: 74.22%] [G loss: 0.791364]\n",
      "epoch:26 step:25200 [D loss: 0.508926, acc.: 71.09%] [G loss: 0.737103]\n",
      "epoch:26 step:25201 [D loss: 0.542010, acc.: 71.88%] [G loss: 0.647209]\n",
      "epoch:26 step:25202 [D loss: 0.542391, acc.: 71.09%] [G loss: 0.718529]\n",
      "epoch:26 step:25203 [D loss: 0.514623, acc.: 76.56%] [G loss: 0.716296]\n",
      "epoch:26 step:25204 [D loss: 0.520050, acc.: 74.22%] [G loss: 0.674473]\n",
      "epoch:26 step:25205 [D loss: 0.501916, acc.: 75.00%] [G loss: 0.779158]\n",
      "epoch:26 step:25206 [D loss: 0.532231, acc.: 72.66%] [G loss: 0.730530]\n",
      "epoch:26 step:25207 [D loss: 0.531726, acc.: 75.78%] [G loss: 0.726264]\n",
      "epoch:26 step:25208 [D loss: 0.504101, acc.: 72.66%] [G loss: 0.726573]\n",
      "epoch:26 step:25209 [D loss: 0.575687, acc.: 66.41%] [G loss: 0.619371]\n",
      "epoch:26 step:25210 [D loss: 0.502700, acc.: 73.44%] [G loss: 0.408038]\n",
      "epoch:26 step:25211 [D loss: 0.514330, acc.: 73.44%] [G loss: 0.692348]\n",
      "epoch:26 step:25212 [D loss: 0.487188, acc.: 75.78%] [G loss: 0.810441]\n",
      "epoch:26 step:25213 [D loss: 0.614966, acc.: 62.50%] [G loss: 0.614664]\n",
      "epoch:26 step:25214 [D loss: 0.544360, acc.: 71.88%] [G loss: 0.738261]\n",
      "epoch:26 step:25215 [D loss: 0.518757, acc.: 71.88%] [G loss: 0.879074]\n",
      "epoch:26 step:25216 [D loss: 0.453498, acc.: 75.00%] [G loss: 1.190222]\n",
      "epoch:26 step:25217 [D loss: 0.560924, acc.: 68.75%] [G loss: 0.781352]\n",
      "epoch:26 step:25218 [D loss: 0.595352, acc.: 71.88%] [G loss: 0.802837]\n",
      "epoch:26 step:25219 [D loss: 0.450969, acc.: 78.91%] [G loss: 0.693085]\n",
      "epoch:26 step:25220 [D loss: 0.596443, acc.: 67.19%] [G loss: 0.689395]\n",
      "epoch:26 step:25221 [D loss: 0.474945, acc.: 77.34%] [G loss: 0.700604]\n",
      "epoch:26 step:25222 [D loss: 0.438068, acc.: 75.78%] [G loss: 0.984298]\n",
      "epoch:26 step:25223 [D loss: 0.625369, acc.: 65.62%] [G loss: 0.645739]\n",
      "epoch:26 step:25224 [D loss: 0.531906, acc.: 68.75%] [G loss: 0.669623]\n",
      "epoch:26 step:25225 [D loss: 0.469619, acc.: 78.12%] [G loss: 0.894548]\n",
      "epoch:26 step:25226 [D loss: 0.533566, acc.: 67.19%] [G loss: 0.602530]\n",
      "epoch:26 step:25227 [D loss: 0.524476, acc.: 71.88%] [G loss: 0.741550]\n",
      "epoch:26 step:25228 [D loss: 0.534708, acc.: 71.09%] [G loss: 0.648256]\n",
      "epoch:26 step:25229 [D loss: 0.645750, acc.: 60.16%] [G loss: 0.591274]\n",
      "epoch:26 step:25230 [D loss: 0.526584, acc.: 70.31%] [G loss: 0.527878]\n",
      "epoch:26 step:25231 [D loss: 0.563207, acc.: 66.41%] [G loss: 0.662477]\n",
      "epoch:26 step:25232 [D loss: 0.493602, acc.: 71.09%] [G loss: 0.823071]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:26 step:25233 [D loss: 0.442990, acc.: 76.56%] [G loss: 0.716832]\n",
      "epoch:26 step:25234 [D loss: 0.494684, acc.: 71.88%] [G loss: 0.690099]\n",
      "epoch:26 step:25235 [D loss: 0.614927, acc.: 68.75%] [G loss: 0.685072]\n",
      "epoch:26 step:25236 [D loss: 0.534464, acc.: 71.09%] [G loss: 0.600274]\n",
      "epoch:26 step:25237 [D loss: 0.441474, acc.: 80.47%] [G loss: 0.786531]\n",
      "epoch:26 step:25238 [D loss: 0.527315, acc.: 72.66%] [G loss: 0.717767]\n",
      "epoch:26 step:25239 [D loss: 0.581216, acc.: 69.53%] [G loss: 0.523879]\n",
      "epoch:26 step:25240 [D loss: 0.548360, acc.: 70.31%] [G loss: 0.559866]\n",
      "epoch:26 step:25241 [D loss: 0.505083, acc.: 74.22%] [G loss: 0.758948]\n",
      "epoch:26 step:25242 [D loss: 0.656621, acc.: 62.50%] [G loss: 0.538246]\n",
      "epoch:26 step:25243 [D loss: 0.545808, acc.: 63.28%] [G loss: 0.757271]\n",
      "epoch:26 step:25244 [D loss: 0.599162, acc.: 64.84%] [G loss: 0.528205]\n",
      "epoch:26 step:25245 [D loss: 0.584059, acc.: 64.06%] [G loss: 0.665071]\n",
      "epoch:26 step:25246 [D loss: 0.447581, acc.: 77.34%] [G loss: 0.930313]\n",
      "epoch:26 step:25247 [D loss: 0.473592, acc.: 76.56%] [G loss: 0.785188]\n",
      "epoch:26 step:25248 [D loss: 0.521582, acc.: 74.22%] [G loss: 0.806230]\n",
      "epoch:26 step:25249 [D loss: 0.582489, acc.: 71.09%] [G loss: 0.765985]\n",
      "epoch:26 step:25250 [D loss: 0.578847, acc.: 65.62%] [G loss: 0.715825]\n",
      "epoch:26 step:25251 [D loss: 0.543438, acc.: 70.31%] [G loss: 0.600927]\n",
      "epoch:26 step:25252 [D loss: 0.495375, acc.: 77.34%] [G loss: 0.800270]\n",
      "epoch:26 step:25253 [D loss: 0.577245, acc.: 64.84%] [G loss: 0.695495]\n",
      "epoch:26 step:25254 [D loss: 0.598098, acc.: 60.94%] [G loss: 0.571927]\n",
      "epoch:26 step:25255 [D loss: 0.490558, acc.: 74.22%] [G loss: 0.590168]\n",
      "epoch:26 step:25256 [D loss: 0.443267, acc.: 78.91%] [G loss: 0.833901]\n",
      "epoch:26 step:25257 [D loss: 0.539157, acc.: 64.84%] [G loss: 0.729278]\n",
      "epoch:26 step:25258 [D loss: 0.508966, acc.: 72.66%] [G loss: 0.905909]\n",
      "epoch:26 step:25259 [D loss: 0.484662, acc.: 75.78%] [G loss: 0.854543]\n",
      "epoch:26 step:25260 [D loss: 0.492961, acc.: 77.34%] [G loss: 0.951293]\n",
      "epoch:26 step:25261 [D loss: 0.455191, acc.: 77.34%] [G loss: 0.976503]\n",
      "epoch:26 step:25262 [D loss: 0.474308, acc.: 76.56%] [G loss: 1.036716]\n",
      "epoch:26 step:25263 [D loss: 0.501161, acc.: 77.34%] [G loss: 0.862936]\n",
      "epoch:26 step:25264 [D loss: 0.576001, acc.: 67.19%] [G loss: 0.723988]\n",
      "epoch:26 step:25265 [D loss: 0.484022, acc.: 77.34%] [G loss: 0.556596]\n",
      "epoch:26 step:25266 [D loss: 0.590108, acc.: 66.41%] [G loss: 0.692219]\n",
      "epoch:26 step:25267 [D loss: 0.565633, acc.: 68.75%] [G loss: 0.794171]\n",
      "epoch:26 step:25268 [D loss: 0.489378, acc.: 78.12%] [G loss: 0.632936]\n",
      "epoch:26 step:25269 [D loss: 0.565670, acc.: 66.41%] [G loss: 0.656841]\n",
      "epoch:26 step:25270 [D loss: 0.551045, acc.: 68.75%] [G loss: 0.647535]\n",
      "epoch:26 step:25271 [D loss: 0.456876, acc.: 77.34%] [G loss: 0.760700]\n",
      "epoch:26 step:25272 [D loss: 0.512327, acc.: 77.34%] [G loss: 0.614266]\n",
      "epoch:26 step:25273 [D loss: 0.487103, acc.: 75.78%] [G loss: 0.811915]\n",
      "epoch:26 step:25274 [D loss: 0.447104, acc.: 78.12%] [G loss: 0.816511]\n",
      "epoch:26 step:25275 [D loss: 0.478161, acc.: 74.22%] [G loss: 1.120828]\n",
      "epoch:26 step:25276 [D loss: 0.478142, acc.: 78.12%] [G loss: 0.950062]\n",
      "epoch:26 step:25277 [D loss: 0.680177, acc.: 62.50%] [G loss: 0.680985]\n",
      "epoch:26 step:25278 [D loss: 0.440328, acc.: 81.25%] [G loss: 0.788916]\n",
      "epoch:26 step:25279 [D loss: 0.579889, acc.: 67.19%] [G loss: 0.666359]\n",
      "epoch:26 step:25280 [D loss: 0.492863, acc.: 73.44%] [G loss: 0.950990]\n",
      "epoch:26 step:25281 [D loss: 0.385037, acc.: 84.38%] [G loss: 0.946053]\n",
      "epoch:26 step:25282 [D loss: 0.569009, acc.: 68.75%] [G loss: 0.871009]\n",
      "epoch:26 step:25283 [D loss: 0.507759, acc.: 73.44%] [G loss: 0.945321]\n",
      "epoch:26 step:25284 [D loss: 0.510225, acc.: 70.31%] [G loss: 0.968320]\n",
      "epoch:26 step:25285 [D loss: 0.412258, acc.: 85.16%] [G loss: 0.769901]\n",
      "epoch:26 step:25286 [D loss: 0.460944, acc.: 75.78%] [G loss: 0.771080]\n",
      "epoch:26 step:25287 [D loss: 0.422465, acc.: 80.47%] [G loss: 1.138368]\n",
      "epoch:26 step:25288 [D loss: 0.417031, acc.: 76.56%] [G loss: 1.140793]\n",
      "epoch:26 step:25289 [D loss: 0.483928, acc.: 75.78%] [G loss: 1.508786]\n",
      "epoch:26 step:25290 [D loss: 0.615558, acc.: 68.75%] [G loss: 1.216403]\n",
      "epoch:26 step:25291 [D loss: 0.574787, acc.: 69.53%] [G loss: 1.648072]\n",
      "epoch:26 step:25292 [D loss: 0.463847, acc.: 74.22%] [G loss: 1.646619]\n",
      "epoch:26 step:25293 [D loss: 0.540959, acc.: 73.44%] [G loss: 1.128686]\n",
      "epoch:26 step:25294 [D loss: 0.580320, acc.: 64.06%] [G loss: 1.058151]\n",
      "epoch:26 step:25295 [D loss: 0.504483, acc.: 74.22%] [G loss: 0.813496]\n",
      "epoch:26 step:25296 [D loss: 0.500715, acc.: 74.22%] [G loss: 0.816182]\n",
      "epoch:26 step:25297 [D loss: 0.509002, acc.: 68.75%] [G loss: 0.959881]\n",
      "epoch:26 step:25298 [D loss: 0.407255, acc.: 79.69%] [G loss: 1.082961]\n",
      "epoch:26 step:25299 [D loss: 0.435370, acc.: 81.25%] [G loss: 1.286158]\n",
      "epoch:27 step:25300 [D loss: 0.523869, acc.: 73.44%] [G loss: 1.245733]\n",
      "epoch:27 step:25301 [D loss: 0.465198, acc.: 77.34%] [G loss: 1.388625]\n",
      "epoch:27 step:25302 [D loss: 0.534201, acc.: 73.44%] [G loss: 0.973270]\n",
      "epoch:27 step:25303 [D loss: 0.507158, acc.: 72.66%] [G loss: 0.933281]\n",
      "epoch:27 step:25304 [D loss: 0.513498, acc.: 78.12%] [G loss: 0.891545]\n",
      "epoch:27 step:25305 [D loss: 0.578009, acc.: 69.53%] [G loss: 0.922064]\n",
      "epoch:27 step:25306 [D loss: 0.513184, acc.: 74.22%] [G loss: 0.771131]\n",
      "epoch:27 step:25307 [D loss: 0.487072, acc.: 78.12%] [G loss: 0.824071]\n",
      "epoch:27 step:25308 [D loss: 0.500959, acc.: 72.66%] [G loss: 0.833734]\n",
      "epoch:27 step:25309 [D loss: 0.529861, acc.: 73.44%] [G loss: 0.815435]\n",
      "epoch:27 step:25310 [D loss: 0.468194, acc.: 82.03%] [G loss: 0.822356]\n",
      "epoch:27 step:25311 [D loss: 0.582379, acc.: 69.53%] [G loss: 0.783017]\n",
      "epoch:27 step:25312 [D loss: 0.559305, acc.: 69.53%] [G loss: 0.702114]\n",
      "epoch:27 step:25313 [D loss: 0.536763, acc.: 71.09%] [G loss: 0.551618]\n",
      "epoch:27 step:25314 [D loss: 0.492321, acc.: 73.44%] [G loss: 0.708494]\n",
      "epoch:27 step:25315 [D loss: 0.498665, acc.: 73.44%] [G loss: 0.737490]\n",
      "epoch:27 step:25316 [D loss: 0.538521, acc.: 75.00%] [G loss: 0.785908]\n",
      "epoch:27 step:25317 [D loss: 0.481743, acc.: 73.44%] [G loss: 0.816042]\n",
      "epoch:27 step:25318 [D loss: 0.570349, acc.: 69.53%] [G loss: 0.636512]\n",
      "epoch:27 step:25319 [D loss: 0.592261, acc.: 67.19%] [G loss: 0.781066]\n",
      "epoch:27 step:25320 [D loss: 0.557716, acc.: 73.44%] [G loss: 0.851749]\n",
      "epoch:27 step:25321 [D loss: 0.448162, acc.: 78.91%] [G loss: 1.006162]\n",
      "epoch:27 step:25322 [D loss: 0.542943, acc.: 67.19%] [G loss: 0.788718]\n",
      "epoch:27 step:25323 [D loss: 0.503797, acc.: 75.00%] [G loss: 0.759553]\n",
      "epoch:27 step:25324 [D loss: 0.482167, acc.: 72.66%] [G loss: 0.827327]\n",
      "epoch:27 step:25325 [D loss: 0.517770, acc.: 69.53%] [G loss: 0.657649]\n",
      "epoch:27 step:25326 [D loss: 0.470471, acc.: 76.56%] [G loss: 0.701926]\n",
      "epoch:27 step:25327 [D loss: 0.527690, acc.: 71.09%] [G loss: 0.798003]\n",
      "epoch:27 step:25328 [D loss: 0.481144, acc.: 75.00%] [G loss: 0.805780]\n",
      "epoch:27 step:25329 [D loss: 0.523824, acc.: 72.66%] [G loss: 0.601977]\n",
      "epoch:27 step:25330 [D loss: 0.570806, acc.: 67.19%] [G loss: 0.680971]\n",
      "epoch:27 step:25331 [D loss: 0.529095, acc.: 69.53%] [G loss: 0.641824]\n",
      "epoch:27 step:25332 [D loss: 0.577714, acc.: 69.53%] [G loss: 0.802269]\n",
      "epoch:27 step:25333 [D loss: 0.528179, acc.: 68.75%] [G loss: 0.647117]\n",
      "epoch:27 step:25334 [D loss: 0.531312, acc.: 69.53%] [G loss: 0.815869]\n",
      "epoch:27 step:25335 [D loss: 0.503946, acc.: 71.09%] [G loss: 0.676724]\n",
      "epoch:27 step:25336 [D loss: 0.491708, acc.: 75.00%] [G loss: 0.737850]\n",
      "epoch:27 step:25337 [D loss: 0.543095, acc.: 74.22%] [G loss: 0.664329]\n",
      "epoch:27 step:25338 [D loss: 0.555205, acc.: 68.75%] [G loss: 0.901097]\n",
      "epoch:27 step:25339 [D loss: 0.434987, acc.: 78.12%] [G loss: 0.906707]\n",
      "epoch:27 step:25340 [D loss: 0.544808, acc.: 71.88%] [G loss: 0.700993]\n",
      "epoch:27 step:25341 [D loss: 0.544166, acc.: 70.31%] [G loss: 0.636586]\n",
      "epoch:27 step:25342 [D loss: 0.469499, acc.: 77.34%] [G loss: 0.716552]\n",
      "epoch:27 step:25343 [D loss: 0.539040, acc.: 68.75%] [G loss: 0.716234]\n",
      "epoch:27 step:25344 [D loss: 0.470354, acc.: 75.00%] [G loss: 0.795668]\n",
      "epoch:27 step:25345 [D loss: 0.490466, acc.: 75.00%] [G loss: 0.772747]\n",
      "epoch:27 step:25346 [D loss: 0.512509, acc.: 71.09%] [G loss: 0.754466]\n",
      "epoch:27 step:25347 [D loss: 0.541028, acc.: 71.09%] [G loss: 0.744438]\n",
      "epoch:27 step:25348 [D loss: 0.502953, acc.: 71.88%] [G loss: 0.899709]\n",
      "epoch:27 step:25349 [D loss: 0.539863, acc.: 73.44%] [G loss: 0.917338]\n",
      "epoch:27 step:25350 [D loss: 0.615898, acc.: 64.84%] [G loss: 0.601166]\n",
      "epoch:27 step:25351 [D loss: 0.522378, acc.: 71.88%] [G loss: 0.746841]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:27 step:25352 [D loss: 0.515164, acc.: 71.88%] [G loss: 0.814206]\n",
      "epoch:27 step:25353 [D loss: 0.471774, acc.: 75.78%] [G loss: 0.849581]\n",
      "epoch:27 step:25354 [D loss: 0.519608, acc.: 76.56%] [G loss: 0.819852]\n",
      "epoch:27 step:25355 [D loss: 0.504377, acc.: 75.78%] [G loss: 0.602769]\n",
      "epoch:27 step:25356 [D loss: 0.514886, acc.: 74.22%] [G loss: 0.847471]\n",
      "epoch:27 step:25357 [D loss: 0.522109, acc.: 71.88%] [G loss: 0.731750]\n",
      "epoch:27 step:25358 [D loss: 0.468094, acc.: 77.34%] [G loss: 0.787130]\n",
      "epoch:27 step:25359 [D loss: 0.561705, acc.: 65.62%] [G loss: 0.734847]\n",
      "epoch:27 step:25360 [D loss: 0.517685, acc.: 70.31%] [G loss: 0.828540]\n",
      "epoch:27 step:25361 [D loss: 0.522291, acc.: 72.66%] [G loss: 0.678564]\n",
      "epoch:27 step:25362 [D loss: 0.473699, acc.: 71.88%] [G loss: 0.841112]\n",
      "epoch:27 step:25363 [D loss: 0.581630, acc.: 72.66%] [G loss: 0.752708]\n",
      "epoch:27 step:25364 [D loss: 0.517571, acc.: 70.31%] [G loss: 0.770872]\n",
      "epoch:27 step:25365 [D loss: 0.521607, acc.: 75.78%] [G loss: 0.665391]\n",
      "epoch:27 step:25366 [D loss: 0.520984, acc.: 75.00%] [G loss: 0.596328]\n",
      "epoch:27 step:25367 [D loss: 0.500232, acc.: 73.44%] [G loss: 0.656322]\n",
      "epoch:27 step:25368 [D loss: 0.479561, acc.: 78.91%] [G loss: 0.681764]\n",
      "epoch:27 step:25369 [D loss: 0.470991, acc.: 78.12%] [G loss: 0.822088]\n",
      "epoch:27 step:25370 [D loss: 0.463757, acc.: 75.00%] [G loss: 0.757940]\n",
      "epoch:27 step:25371 [D loss: 0.571786, acc.: 67.97%] [G loss: 0.629834]\n",
      "epoch:27 step:25372 [D loss: 0.565085, acc.: 65.62%] [G loss: 0.752216]\n",
      "epoch:27 step:25373 [D loss: 0.479746, acc.: 72.66%] [G loss: 0.752838]\n",
      "epoch:27 step:25374 [D loss: 0.544260, acc.: 66.41%] [G loss: 0.840901]\n",
      "epoch:27 step:25375 [D loss: 0.469077, acc.: 78.12%] [G loss: 1.052558]\n",
      "epoch:27 step:25376 [D loss: 0.440371, acc.: 78.12%] [G loss: 0.912126]\n",
      "epoch:27 step:25377 [D loss: 0.579031, acc.: 68.75%] [G loss: 0.921987]\n",
      "epoch:27 step:25378 [D loss: 0.523030, acc.: 71.88%] [G loss: 0.836136]\n",
      "epoch:27 step:25379 [D loss: 0.511718, acc.: 70.31%] [G loss: 0.737435]\n",
      "epoch:27 step:25380 [D loss: 0.493691, acc.: 74.22%] [G loss: 0.742369]\n",
      "epoch:27 step:25381 [D loss: 0.480914, acc.: 74.22%] [G loss: 0.871080]\n",
      "epoch:27 step:25382 [D loss: 0.476236, acc.: 78.91%] [G loss: 0.885490]\n",
      "epoch:27 step:25383 [D loss: 0.573089, acc.: 65.62%] [G loss: 0.732630]\n",
      "epoch:27 step:25384 [D loss: 0.540774, acc.: 71.88%] [G loss: 0.680187]\n",
      "epoch:27 step:25385 [D loss: 0.522365, acc.: 71.88%] [G loss: 0.567511]\n",
      "epoch:27 step:25386 [D loss: 0.501438, acc.: 76.56%] [G loss: 0.825403]\n",
      "epoch:27 step:25387 [D loss: 0.507155, acc.: 71.09%] [G loss: 0.892452]\n",
      "epoch:27 step:25388 [D loss: 0.461367, acc.: 73.44%] [G loss: 0.906669]\n",
      "epoch:27 step:25389 [D loss: 0.455040, acc.: 75.78%] [G loss: 1.041571]\n",
      "epoch:27 step:25390 [D loss: 0.599908, acc.: 66.41%] [G loss: 0.778956]\n",
      "epoch:27 step:25391 [D loss: 0.493008, acc.: 74.22%] [G loss: 0.590051]\n",
      "epoch:27 step:25392 [D loss: 0.473677, acc.: 78.12%] [G loss: 0.764535]\n",
      "epoch:27 step:25393 [D loss: 0.458113, acc.: 77.34%] [G loss: 0.833480]\n",
      "epoch:27 step:25394 [D loss: 0.528482, acc.: 71.09%] [G loss: 0.719724]\n",
      "epoch:27 step:25395 [D loss: 0.493093, acc.: 78.12%] [G loss: 0.932065]\n",
      "epoch:27 step:25396 [D loss: 0.500048, acc.: 74.22%] [G loss: 1.079320]\n",
      "epoch:27 step:25397 [D loss: 0.525564, acc.: 71.88%] [G loss: 0.890773]\n",
      "epoch:27 step:25398 [D loss: 0.552464, acc.: 77.34%] [G loss: 0.971568]\n",
      "epoch:27 step:25399 [D loss: 0.486436, acc.: 75.00%] [G loss: 1.049769]\n",
      "epoch:27 step:25400 [D loss: 0.470896, acc.: 76.56%] [G loss: 1.061448]\n",
      "epoch:27 step:25401 [D loss: 0.568920, acc.: 71.88%] [G loss: 0.615681]\n",
      "epoch:27 step:25402 [D loss: 0.516226, acc.: 71.09%] [G loss: 0.656988]\n",
      "epoch:27 step:25403 [D loss: 0.504187, acc.: 67.19%] [G loss: 0.711909]\n",
      "epoch:27 step:25404 [D loss: 0.570024, acc.: 67.97%] [G loss: 0.828813]\n",
      "epoch:27 step:25405 [D loss: 0.487135, acc.: 72.66%] [G loss: 0.906560]\n",
      "epoch:27 step:25406 [D loss: 0.546648, acc.: 70.31%] [G loss: 0.830923]\n",
      "epoch:27 step:25407 [D loss: 0.605462, acc.: 67.19%] [G loss: 0.786376]\n",
      "epoch:27 step:25408 [D loss: 0.501477, acc.: 75.78%] [G loss: 0.839118]\n",
      "epoch:27 step:25409 [D loss: 0.572529, acc.: 70.31%] [G loss: 0.738928]\n",
      "epoch:27 step:25410 [D loss: 0.526158, acc.: 67.97%] [G loss: 0.785766]\n",
      "epoch:27 step:25411 [D loss: 0.470549, acc.: 77.34%] [G loss: 0.883955]\n",
      "epoch:27 step:25412 [D loss: 0.528235, acc.: 71.88%] [G loss: 0.930312]\n",
      "epoch:27 step:25413 [D loss: 0.530011, acc.: 71.09%] [G loss: 0.809969]\n",
      "epoch:27 step:25414 [D loss: 0.574190, acc.: 68.75%] [G loss: 0.817813]\n",
      "epoch:27 step:25415 [D loss: 0.477949, acc.: 74.22%] [G loss: 1.023465]\n",
      "epoch:27 step:25416 [D loss: 0.589541, acc.: 64.84%] [G loss: 0.991658]\n",
      "epoch:27 step:25417 [D loss: 0.499372, acc.: 74.22%] [G loss: 0.766860]\n",
      "epoch:27 step:25418 [D loss: 0.420032, acc.: 77.34%] [G loss: 1.009908]\n",
      "epoch:27 step:25419 [D loss: 0.521451, acc.: 74.22%] [G loss: 0.842856]\n",
      "epoch:27 step:25420 [D loss: 0.531925, acc.: 70.31%] [G loss: 0.752547]\n",
      "epoch:27 step:25421 [D loss: 0.482823, acc.: 75.78%] [G loss: 1.023292]\n",
      "epoch:27 step:25422 [D loss: 0.516881, acc.: 73.44%] [G loss: 1.143930]\n",
      "epoch:27 step:25423 [D loss: 0.533152, acc.: 74.22%] [G loss: 0.862990]\n",
      "epoch:27 step:25424 [D loss: 0.541678, acc.: 71.09%] [G loss: 0.725548]\n",
      "epoch:27 step:25425 [D loss: 0.491629, acc.: 75.78%] [G loss: 0.781936]\n",
      "epoch:27 step:25426 [D loss: 0.447743, acc.: 76.56%] [G loss: 0.741699]\n",
      "epoch:27 step:25427 [D loss: 0.525351, acc.: 67.19%] [G loss: 0.754370]\n",
      "epoch:27 step:25428 [D loss: 0.557414, acc.: 70.31%] [G loss: 0.674055]\n",
      "epoch:27 step:25429 [D loss: 0.433174, acc.: 78.12%] [G loss: 0.932297]\n",
      "epoch:27 step:25430 [D loss: 0.478762, acc.: 77.34%] [G loss: 0.773740]\n",
      "epoch:27 step:25431 [D loss: 0.564548, acc.: 71.09%] [G loss: 0.761044]\n",
      "epoch:27 step:25432 [D loss: 0.513510, acc.: 71.88%] [G loss: 0.670917]\n",
      "epoch:27 step:25433 [D loss: 0.555873, acc.: 67.97%] [G loss: 0.794682]\n",
      "epoch:27 step:25434 [D loss: 0.512023, acc.: 74.22%] [G loss: 0.863434]\n",
      "epoch:27 step:25435 [D loss: 0.482060, acc.: 79.69%] [G loss: 0.988213]\n",
      "epoch:27 step:25436 [D loss: 0.617522, acc.: 69.53%] [G loss: 0.925720]\n",
      "epoch:27 step:25437 [D loss: 0.600219, acc.: 60.94%] [G loss: 0.575569]\n",
      "epoch:27 step:25438 [D loss: 0.517118, acc.: 68.75%] [G loss: 0.663788]\n",
      "epoch:27 step:25439 [D loss: 0.501065, acc.: 72.66%] [G loss: 0.783086]\n",
      "epoch:27 step:25440 [D loss: 0.524296, acc.: 72.66%] [G loss: 0.975343]\n",
      "epoch:27 step:25441 [D loss: 0.604659, acc.: 63.28%] [G loss: 0.700600]\n",
      "epoch:27 step:25442 [D loss: 0.594894, acc.: 67.19%] [G loss: 0.818987]\n",
      "epoch:27 step:25443 [D loss: 0.481977, acc.: 77.34%] [G loss: 0.694107]\n",
      "epoch:27 step:25444 [D loss: 0.550785, acc.: 67.19%] [G loss: 0.843035]\n",
      "epoch:27 step:25445 [D loss: 0.457893, acc.: 82.81%] [G loss: 0.949110]\n",
      "epoch:27 step:25446 [D loss: 0.634113, acc.: 68.75%] [G loss: 0.844836]\n",
      "epoch:27 step:25447 [D loss: 0.595518, acc.: 65.62%] [G loss: 0.747776]\n",
      "epoch:27 step:25448 [D loss: 0.492481, acc.: 75.00%] [G loss: 0.927222]\n",
      "epoch:27 step:25449 [D loss: 0.552413, acc.: 68.75%] [G loss: 0.615868]\n",
      "epoch:27 step:25450 [D loss: 0.484070, acc.: 75.00%] [G loss: 0.662485]\n",
      "epoch:27 step:25451 [D loss: 0.469989, acc.: 75.00%] [G loss: 0.663561]\n",
      "epoch:27 step:25452 [D loss: 0.615465, acc.: 66.41%] [G loss: 0.739307]\n",
      "epoch:27 step:25453 [D loss: 0.517242, acc.: 71.88%] [G loss: 0.839651]\n",
      "epoch:27 step:25454 [D loss: 0.470150, acc.: 78.91%] [G loss: 0.912967]\n",
      "epoch:27 step:25455 [D loss: 0.488729, acc.: 78.12%] [G loss: 0.904493]\n",
      "epoch:27 step:25456 [D loss: 0.504385, acc.: 71.88%] [G loss: 0.877839]\n",
      "epoch:27 step:25457 [D loss: 0.575561, acc.: 70.31%] [G loss: 0.776368]\n",
      "epoch:27 step:25458 [D loss: 0.465215, acc.: 75.78%] [G loss: 0.881376]\n",
      "epoch:27 step:25459 [D loss: 0.583390, acc.: 72.66%] [G loss: 0.950561]\n",
      "epoch:27 step:25460 [D loss: 0.528293, acc.: 68.75%] [G loss: 0.919180]\n",
      "epoch:27 step:25461 [D loss: 0.465796, acc.: 75.78%] [G loss: 1.004914]\n",
      "epoch:27 step:25462 [D loss: 0.609476, acc.: 64.84%] [G loss: 0.948913]\n",
      "epoch:27 step:25463 [D loss: 0.495909, acc.: 73.44%] [G loss: 0.981963]\n",
      "epoch:27 step:25464 [D loss: 0.490976, acc.: 75.00%] [G loss: 0.692412]\n",
      "epoch:27 step:25465 [D loss: 0.589995, acc.: 65.62%] [G loss: 0.555604]\n",
      "epoch:27 step:25466 [D loss: 0.518717, acc.: 74.22%] [G loss: 0.776965]\n",
      "epoch:27 step:25467 [D loss: 0.553885, acc.: 71.88%] [G loss: 0.588029]\n",
      "epoch:27 step:25468 [D loss: 0.606765, acc.: 67.97%] [G loss: 0.617211]\n",
      "epoch:27 step:25469 [D loss: 0.501763, acc.: 72.66%] [G loss: 0.638102]\n",
      "epoch:27 step:25470 [D loss: 0.513314, acc.: 70.31%] [G loss: 0.727414]\n",
      "epoch:27 step:25471 [D loss: 0.472753, acc.: 76.56%] [G loss: 0.869764]\n",
      "epoch:27 step:25472 [D loss: 0.455991, acc.: 76.56%] [G loss: 0.749191]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:27 step:25473 [D loss: 0.594290, acc.: 68.75%] [G loss: 0.776567]\n",
      "epoch:27 step:25474 [D loss: 0.580091, acc.: 64.84%] [G loss: 0.485142]\n",
      "epoch:27 step:25475 [D loss: 0.501433, acc.: 74.22%] [G loss: 0.839104]\n",
      "epoch:27 step:25476 [D loss: 0.525207, acc.: 70.31%] [G loss: 0.690957]\n",
      "epoch:27 step:25477 [D loss: 0.588219, acc.: 70.31%] [G loss: 0.693656]\n",
      "epoch:27 step:25478 [D loss: 0.521347, acc.: 67.97%] [G loss: 0.607291]\n",
      "epoch:27 step:25479 [D loss: 0.628627, acc.: 64.06%] [G loss: 0.547239]\n",
      "epoch:27 step:25480 [D loss: 0.539223, acc.: 71.09%] [G loss: 0.639187]\n",
      "epoch:27 step:25481 [D loss: 0.463917, acc.: 77.34%] [G loss: 0.661566]\n",
      "epoch:27 step:25482 [D loss: 0.543959, acc.: 71.09%] [G loss: 0.638054]\n",
      "epoch:27 step:25483 [D loss: 0.487691, acc.: 73.44%] [G loss: 0.649527]\n",
      "epoch:27 step:25484 [D loss: 0.543518, acc.: 72.66%] [G loss: 0.792467]\n",
      "epoch:27 step:25485 [D loss: 0.525201, acc.: 69.53%] [G loss: 0.749320]\n",
      "epoch:27 step:25486 [D loss: 0.563637, acc.: 67.19%] [G loss: 0.728283]\n",
      "epoch:27 step:25487 [D loss: 0.531159, acc.: 74.22%] [G loss: 0.606450]\n",
      "epoch:27 step:25488 [D loss: 0.531298, acc.: 74.22%] [G loss: 0.629697]\n",
      "epoch:27 step:25489 [D loss: 0.461658, acc.: 78.12%] [G loss: 0.706649]\n",
      "epoch:27 step:25490 [D loss: 0.452075, acc.: 81.25%] [G loss: 0.785241]\n",
      "epoch:27 step:25491 [D loss: 0.525189, acc.: 73.44%] [G loss: 0.785643]\n",
      "epoch:27 step:25492 [D loss: 0.540129, acc.: 71.88%] [G loss: 0.604760]\n",
      "epoch:27 step:25493 [D loss: 0.483910, acc.: 78.91%] [G loss: 1.015090]\n",
      "epoch:27 step:25494 [D loss: 0.603495, acc.: 66.41%] [G loss: 0.741096]\n",
      "epoch:27 step:25495 [D loss: 0.542259, acc.: 69.53%] [G loss: 0.720344]\n",
      "epoch:27 step:25496 [D loss: 0.440651, acc.: 81.25%] [G loss: 0.824020]\n",
      "epoch:27 step:25497 [D loss: 0.426218, acc.: 82.81%] [G loss: 0.856599]\n",
      "epoch:27 step:25498 [D loss: 0.473717, acc.: 76.56%] [G loss: 1.039258]\n",
      "epoch:27 step:25499 [D loss: 0.585244, acc.: 67.97%] [G loss: 0.662632]\n",
      "epoch:27 step:25500 [D loss: 0.500963, acc.: 73.44%] [G loss: 0.712113]\n",
      "epoch:27 step:25501 [D loss: 0.499242, acc.: 74.22%] [G loss: 0.765306]\n",
      "epoch:27 step:25502 [D loss: 0.540364, acc.: 74.22%] [G loss: 0.807237]\n",
      "epoch:27 step:25503 [D loss: 0.600450, acc.: 63.28%] [G loss: 0.690249]\n",
      "epoch:27 step:25504 [D loss: 0.477489, acc.: 76.56%] [G loss: 0.822903]\n",
      "epoch:27 step:25505 [D loss: 0.514284, acc.: 71.88%] [G loss: 0.805660]\n",
      "epoch:27 step:25506 [D loss: 0.419967, acc.: 78.91%] [G loss: 1.023797]\n",
      "epoch:27 step:25507 [D loss: 0.421307, acc.: 77.34%] [G loss: 0.976228]\n",
      "epoch:27 step:25508 [D loss: 0.486833, acc.: 72.66%] [G loss: 0.978129]\n",
      "epoch:27 step:25509 [D loss: 0.609517, acc.: 67.97%] [G loss: 0.670418]\n",
      "epoch:27 step:25510 [D loss: 0.592209, acc.: 65.62%] [G loss: 0.472067]\n",
      "epoch:27 step:25511 [D loss: 0.507770, acc.: 75.00%] [G loss: 0.673053]\n",
      "epoch:27 step:25512 [D loss: 0.441701, acc.: 78.91%] [G loss: 0.698345]\n",
      "epoch:27 step:25513 [D loss: 0.599007, acc.: 64.84%] [G loss: 0.663367]\n",
      "epoch:27 step:25514 [D loss: 0.536264, acc.: 67.97%] [G loss: 0.642756]\n",
      "epoch:27 step:25515 [D loss: 0.511993, acc.: 72.66%] [G loss: 0.728161]\n",
      "epoch:27 step:25516 [D loss: 0.487991, acc.: 74.22%] [G loss: 0.739075]\n",
      "epoch:27 step:25517 [D loss: 0.461939, acc.: 81.25%] [G loss: 0.999003]\n",
      "epoch:27 step:25518 [D loss: 0.488156, acc.: 78.91%] [G loss: 0.897017]\n",
      "epoch:27 step:25519 [D loss: 0.643768, acc.: 67.97%] [G loss: 0.776544]\n",
      "epoch:27 step:25520 [D loss: 0.531463, acc.: 67.97%] [G loss: 0.805408]\n",
      "epoch:27 step:25521 [D loss: 0.485135, acc.: 75.78%] [G loss: 0.853456]\n",
      "epoch:27 step:25522 [D loss: 0.494180, acc.: 78.12%] [G loss: 0.787308]\n",
      "epoch:27 step:25523 [D loss: 0.506310, acc.: 71.09%] [G loss: 0.765084]\n",
      "epoch:27 step:25524 [D loss: 0.483228, acc.: 76.56%] [G loss: 0.721001]\n",
      "epoch:27 step:25525 [D loss: 0.590758, acc.: 65.62%] [G loss: 0.824079]\n",
      "epoch:27 step:25526 [D loss: 0.499992, acc.: 75.00%] [G loss: 0.726691]\n",
      "epoch:27 step:25527 [D loss: 0.559381, acc.: 66.41%] [G loss: 0.725192]\n",
      "epoch:27 step:25528 [D loss: 0.533429, acc.: 75.00%] [G loss: 0.603308]\n",
      "epoch:27 step:25529 [D loss: 0.501985, acc.: 76.56%] [G loss: 0.967385]\n",
      "epoch:27 step:25530 [D loss: 0.475577, acc.: 75.00%] [G loss: 0.934059]\n",
      "epoch:27 step:25531 [D loss: 0.438249, acc.: 82.03%] [G loss: 1.072629]\n",
      "epoch:27 step:25532 [D loss: 0.506942, acc.: 73.44%] [G loss: 0.885757]\n",
      "epoch:27 step:25533 [D loss: 0.577126, acc.: 71.09%] [G loss: 0.800575]\n",
      "epoch:27 step:25534 [D loss: 0.572799, acc.: 67.19%] [G loss: 0.733763]\n",
      "epoch:27 step:25535 [D loss: 0.489321, acc.: 75.00%] [G loss: 0.599987]\n",
      "epoch:27 step:25536 [D loss: 0.533244, acc.: 71.09%] [G loss: 0.705602]\n",
      "epoch:27 step:25537 [D loss: 0.621232, acc.: 62.50%] [G loss: 0.650394]\n",
      "epoch:27 step:25538 [D loss: 0.522290, acc.: 68.75%] [G loss: 0.703074]\n",
      "epoch:27 step:25539 [D loss: 0.532910, acc.: 67.97%] [G loss: 0.691141]\n",
      "epoch:27 step:25540 [D loss: 0.480858, acc.: 82.03%] [G loss: 0.790161]\n",
      "epoch:27 step:25541 [D loss: 0.488202, acc.: 77.34%] [G loss: 0.770026]\n",
      "epoch:27 step:25542 [D loss: 0.562516, acc.: 67.97%] [G loss: 0.715367]\n",
      "epoch:27 step:25543 [D loss: 0.442525, acc.: 79.69%] [G loss: 0.734477]\n",
      "epoch:27 step:25544 [D loss: 0.446713, acc.: 78.12%] [G loss: 0.836880]\n",
      "epoch:27 step:25545 [D loss: 0.519295, acc.: 74.22%] [G loss: 0.827858]\n",
      "epoch:27 step:25546 [D loss: 0.502276, acc.: 75.00%] [G loss: 0.701431]\n",
      "epoch:27 step:25547 [D loss: 0.510603, acc.: 67.97%] [G loss: 0.824458]\n",
      "epoch:27 step:25548 [D loss: 0.564172, acc.: 70.31%] [G loss: 0.910444]\n",
      "epoch:27 step:25549 [D loss: 0.622860, acc.: 63.28%] [G loss: 0.756643]\n",
      "epoch:27 step:25550 [D loss: 0.550737, acc.: 68.75%] [G loss: 1.026166]\n",
      "epoch:27 step:25551 [D loss: 0.577909, acc.: 68.75%] [G loss: 0.673450]\n",
      "epoch:27 step:25552 [D loss: 0.582099, acc.: 71.88%] [G loss: 0.812599]\n",
      "epoch:27 step:25553 [D loss: 0.480505, acc.: 75.00%] [G loss: 0.656015]\n",
      "epoch:27 step:25554 [D loss: 0.509889, acc.: 75.78%] [G loss: 0.809256]\n",
      "epoch:27 step:25555 [D loss: 0.545540, acc.: 68.75%] [G loss: 0.750441]\n",
      "epoch:27 step:25556 [D loss: 0.524292, acc.: 71.09%] [G loss: 0.728298]\n",
      "epoch:27 step:25557 [D loss: 0.486368, acc.: 75.78%] [G loss: 0.816894]\n",
      "epoch:27 step:25558 [D loss: 0.519975, acc.: 71.09%] [G loss: 0.796112]\n",
      "epoch:27 step:25559 [D loss: 0.565415, acc.: 63.28%] [G loss: 0.633207]\n",
      "epoch:27 step:25560 [D loss: 0.485059, acc.: 75.78%] [G loss: 0.699804]\n",
      "epoch:27 step:25561 [D loss: 0.499946, acc.: 67.97%] [G loss: 0.737378]\n",
      "epoch:27 step:25562 [D loss: 0.611977, acc.: 64.06%] [G loss: 0.616264]\n",
      "epoch:27 step:25563 [D loss: 0.516456, acc.: 71.88%] [G loss: 0.744177]\n",
      "epoch:27 step:25564 [D loss: 0.481943, acc.: 76.56%] [G loss: 0.745472]\n",
      "epoch:27 step:25565 [D loss: 0.560331, acc.: 68.75%] [G loss: 0.764468]\n",
      "epoch:27 step:25566 [D loss: 0.483079, acc.: 77.34%] [G loss: 0.725841]\n",
      "epoch:27 step:25567 [D loss: 0.541284, acc.: 67.19%] [G loss: 0.748459]\n",
      "epoch:27 step:25568 [D loss: 0.528612, acc.: 75.78%] [G loss: 0.659654]\n",
      "epoch:27 step:25569 [D loss: 0.519538, acc.: 72.66%] [G loss: 0.735596]\n",
      "epoch:27 step:25570 [D loss: 0.499991, acc.: 71.09%] [G loss: 0.709086]\n",
      "epoch:27 step:25571 [D loss: 0.559008, acc.: 73.44%] [G loss: 0.637369]\n",
      "epoch:27 step:25572 [D loss: 0.496709, acc.: 78.12%] [G loss: 0.710966]\n",
      "epoch:27 step:25573 [D loss: 0.488935, acc.: 76.56%] [G loss: 0.885713]\n",
      "epoch:27 step:25574 [D loss: 0.567186, acc.: 72.66%] [G loss: 0.754300]\n",
      "epoch:27 step:25575 [D loss: 0.424990, acc.: 81.25%] [G loss: 0.872439]\n",
      "epoch:27 step:25576 [D loss: 0.608067, acc.: 68.75%] [G loss: 0.740388]\n",
      "epoch:27 step:25577 [D loss: 0.642343, acc.: 62.50%] [G loss: 0.501152]\n",
      "epoch:27 step:25578 [D loss: 0.538017, acc.: 69.53%] [G loss: 0.761167]\n",
      "epoch:27 step:25579 [D loss: 0.535784, acc.: 70.31%] [G loss: 0.760754]\n",
      "epoch:27 step:25580 [D loss: 0.577982, acc.: 67.97%] [G loss: 0.594328]\n",
      "epoch:27 step:25581 [D loss: 0.559734, acc.: 67.97%] [G loss: 0.576337]\n",
      "epoch:27 step:25582 [D loss: 0.476190, acc.: 77.34%] [G loss: 0.695870]\n",
      "epoch:27 step:25583 [D loss: 0.498794, acc.: 71.88%] [G loss: 0.809783]\n",
      "epoch:27 step:25584 [D loss: 0.488884, acc.: 73.44%] [G loss: 0.752605]\n",
      "epoch:27 step:25585 [D loss: 0.470558, acc.: 72.66%] [G loss: 0.661288]\n",
      "epoch:27 step:25586 [D loss: 0.603015, acc.: 64.06%] [G loss: 0.714238]\n",
      "epoch:27 step:25587 [D loss: 0.553081, acc.: 70.31%] [G loss: 0.733294]\n",
      "epoch:27 step:25588 [D loss: 0.485302, acc.: 74.22%] [G loss: 0.840027]\n",
      "epoch:27 step:25589 [D loss: 0.604917, acc.: 67.19%] [G loss: 0.694108]\n",
      "epoch:27 step:25590 [D loss: 0.539028, acc.: 71.09%] [G loss: 0.661705]\n",
      "epoch:27 step:25591 [D loss: 0.526773, acc.: 72.66%] [G loss: 0.560611]\n",
      "epoch:27 step:25592 [D loss: 0.584506, acc.: 67.19%] [G loss: 0.658201]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:27 step:25593 [D loss: 0.599632, acc.: 67.19%] [G loss: 0.650870]\n",
      "epoch:27 step:25594 [D loss: 0.548944, acc.: 69.53%] [G loss: 0.659440]\n",
      "epoch:27 step:25595 [D loss: 0.456677, acc.: 78.12%] [G loss: 0.683532]\n",
      "epoch:27 step:25596 [D loss: 0.546967, acc.: 71.09%] [G loss: 0.750052]\n",
      "epoch:27 step:25597 [D loss: 0.437088, acc.: 83.59%] [G loss: 0.706074]\n",
      "epoch:27 step:25598 [D loss: 0.425645, acc.: 78.12%] [G loss: 0.757578]\n",
      "epoch:27 step:25599 [D loss: 0.467822, acc.: 76.56%] [G loss: 0.854116]\n",
      "epoch:27 step:25600 [D loss: 0.658579, acc.: 61.72%] [G loss: 0.823389]\n",
      "epoch:27 step:25601 [D loss: 0.519564, acc.: 71.88%] [G loss: 0.537546]\n",
      "epoch:27 step:25602 [D loss: 0.581711, acc.: 67.19%] [G loss: 0.695375]\n",
      "epoch:27 step:25603 [D loss: 0.428874, acc.: 78.91%] [G loss: 0.925088]\n",
      "epoch:27 step:25604 [D loss: 0.479033, acc.: 80.47%] [G loss: 0.726361]\n",
      "epoch:27 step:25605 [D loss: 0.522158, acc.: 71.09%] [G loss: 0.606246]\n",
      "epoch:27 step:25606 [D loss: 0.515089, acc.: 71.09%] [G loss: 0.636271]\n",
      "epoch:27 step:25607 [D loss: 0.543268, acc.: 70.31%] [G loss: 0.697115]\n",
      "epoch:27 step:25608 [D loss: 0.457863, acc.: 74.22%] [G loss: 0.715898]\n",
      "epoch:27 step:25609 [D loss: 0.545820, acc.: 69.53%] [G loss: 0.593449]\n",
      "epoch:27 step:25610 [D loss: 0.431032, acc.: 81.25%] [G loss: 0.859042]\n",
      "epoch:27 step:25611 [D loss: 0.411673, acc.: 85.94%] [G loss: 0.922617]\n",
      "epoch:27 step:25612 [D loss: 0.503121, acc.: 76.56%] [G loss: 0.958289]\n",
      "epoch:27 step:25613 [D loss: 0.425377, acc.: 82.81%] [G loss: 0.909209]\n",
      "epoch:27 step:25614 [D loss: 0.457640, acc.: 81.25%] [G loss: 1.082988]\n",
      "epoch:27 step:25615 [D loss: 0.624290, acc.: 67.19%] [G loss: 1.005758]\n",
      "epoch:27 step:25616 [D loss: 0.586613, acc.: 67.97%] [G loss: 0.879380]\n",
      "epoch:27 step:25617 [D loss: 0.499066, acc.: 71.09%] [G loss: 0.929005]\n",
      "epoch:27 step:25618 [D loss: 0.608159, acc.: 63.28%] [G loss: 0.644736]\n",
      "epoch:27 step:25619 [D loss: 0.511762, acc.: 71.09%] [G loss: 0.720966]\n",
      "epoch:27 step:25620 [D loss: 0.480272, acc.: 77.34%] [G loss: 0.639566]\n",
      "epoch:27 step:25621 [D loss: 0.547008, acc.: 73.44%] [G loss: 0.577578]\n",
      "epoch:27 step:25622 [D loss: 0.553357, acc.: 71.88%] [G loss: 0.649440]\n",
      "epoch:27 step:25623 [D loss: 0.528203, acc.: 73.44%] [G loss: 0.577216]\n",
      "epoch:27 step:25624 [D loss: 0.551507, acc.: 69.53%] [G loss: 0.676696]\n",
      "epoch:27 step:25625 [D loss: 0.429380, acc.: 80.47%] [G loss: 0.738179]\n",
      "epoch:27 step:25626 [D loss: 0.481311, acc.: 75.00%] [G loss: 0.969246]\n",
      "epoch:27 step:25627 [D loss: 0.510238, acc.: 76.56%] [G loss: 0.888931]\n",
      "epoch:27 step:25628 [D loss: 0.471852, acc.: 78.91%] [G loss: 0.824598]\n",
      "epoch:27 step:25629 [D loss: 0.560719, acc.: 71.88%] [G loss: 0.639684]\n",
      "epoch:27 step:25630 [D loss: 0.585824, acc.: 67.19%] [G loss: 0.633197]\n",
      "epoch:27 step:25631 [D loss: 0.448390, acc.: 79.69%] [G loss: 0.762263]\n",
      "epoch:27 step:25632 [D loss: 0.478445, acc.: 75.78%] [G loss: 0.816946]\n",
      "epoch:27 step:25633 [D loss: 0.465645, acc.: 75.00%] [G loss: 0.876229]\n",
      "epoch:27 step:25634 [D loss: 0.486583, acc.: 75.78%] [G loss: 0.778186]\n",
      "epoch:27 step:25635 [D loss: 0.474571, acc.: 75.78%] [G loss: 0.927750]\n",
      "epoch:27 step:25636 [D loss: 0.492399, acc.: 71.88%] [G loss: 0.744586]\n",
      "epoch:27 step:25637 [D loss: 0.534799, acc.: 72.66%] [G loss: 0.872060]\n",
      "epoch:27 step:25638 [D loss: 0.540902, acc.: 67.97%] [G loss: 0.910551]\n",
      "epoch:27 step:25639 [D loss: 0.432680, acc.: 83.59%] [G loss: 0.837338]\n",
      "epoch:27 step:25640 [D loss: 0.532291, acc.: 75.00%] [G loss: 0.917405]\n",
      "epoch:27 step:25641 [D loss: 0.671772, acc.: 59.38%] [G loss: 0.485236]\n",
      "epoch:27 step:25642 [D loss: 0.556828, acc.: 66.41%] [G loss: 0.741876]\n",
      "epoch:27 step:25643 [D loss: 0.410808, acc.: 85.94%] [G loss: 1.020685]\n",
      "epoch:27 step:25644 [D loss: 0.549627, acc.: 72.66%] [G loss: 0.925654]\n",
      "epoch:27 step:25645 [D loss: 0.545034, acc.: 71.09%] [G loss: 0.886912]\n",
      "epoch:27 step:25646 [D loss: 0.383611, acc.: 84.38%] [G loss: 1.106085]\n",
      "epoch:27 step:25647 [D loss: 0.563267, acc.: 70.31%] [G loss: 1.026900]\n",
      "epoch:27 step:25648 [D loss: 0.710136, acc.: 54.69%] [G loss: 0.696330]\n",
      "epoch:27 step:25649 [D loss: 0.511371, acc.: 75.00%] [G loss: 0.599337]\n",
      "epoch:27 step:25650 [D loss: 0.483204, acc.: 77.34%] [G loss: 0.786631]\n",
      "epoch:27 step:25651 [D loss: 0.585295, acc.: 71.88%] [G loss: 0.760195]\n",
      "epoch:27 step:25652 [D loss: 0.548587, acc.: 67.97%] [G loss: 0.663386]\n",
      "epoch:27 step:25653 [D loss: 0.345171, acc.: 89.06%] [G loss: 0.942674]\n",
      "epoch:27 step:25654 [D loss: 0.451903, acc.: 78.12%] [G loss: 0.937031]\n",
      "epoch:27 step:25655 [D loss: 0.582739, acc.: 65.62%] [G loss: 0.664211]\n",
      "epoch:27 step:25656 [D loss: 0.439368, acc.: 82.03%] [G loss: 0.817126]\n",
      "epoch:27 step:25657 [D loss: 0.436600, acc.: 78.12%] [G loss: 1.040186]\n",
      "epoch:27 step:25658 [D loss: 0.447455, acc.: 82.03%] [G loss: 1.138057]\n",
      "epoch:27 step:25659 [D loss: 0.485086, acc.: 72.66%] [G loss: 0.827887]\n",
      "epoch:27 step:25660 [D loss: 0.555147, acc.: 75.00%] [G loss: 0.876011]\n",
      "epoch:27 step:25661 [D loss: 0.539312, acc.: 72.66%] [G loss: 0.912426]\n",
      "epoch:27 step:25662 [D loss: 0.536734, acc.: 70.31%] [G loss: 0.685104]\n",
      "epoch:27 step:25663 [D loss: 0.442679, acc.: 76.56%] [G loss: 1.057078]\n",
      "epoch:27 step:25664 [D loss: 0.533473, acc.: 67.19%] [G loss: 0.752018]\n",
      "epoch:27 step:25665 [D loss: 0.540785, acc.: 68.75%] [G loss: 0.992886]\n",
      "epoch:27 step:25666 [D loss: 0.573832, acc.: 66.41%] [G loss: 0.764173]\n",
      "epoch:27 step:25667 [D loss: 0.531932, acc.: 73.44%] [G loss: 0.851990]\n",
      "epoch:27 step:25668 [D loss: 0.474567, acc.: 78.12%] [G loss: 0.660091]\n",
      "epoch:27 step:25669 [D loss: 0.492873, acc.: 78.91%] [G loss: 0.786890]\n",
      "epoch:27 step:25670 [D loss: 0.512279, acc.: 74.22%] [G loss: 1.053816]\n",
      "epoch:27 step:25671 [D loss: 0.534801, acc.: 71.88%] [G loss: 0.767747]\n",
      "epoch:27 step:25672 [D loss: 0.534325, acc.: 67.97%] [G loss: 0.746105]\n",
      "epoch:27 step:25673 [D loss: 0.437025, acc.: 77.34%] [G loss: 0.830706]\n",
      "epoch:27 step:25674 [D loss: 0.548005, acc.: 71.09%] [G loss: 0.732962]\n",
      "epoch:27 step:25675 [D loss: 0.656927, acc.: 61.72%] [G loss: 0.849239]\n",
      "epoch:27 step:25676 [D loss: 0.520096, acc.: 70.31%] [G loss: 0.800977]\n",
      "epoch:27 step:25677 [D loss: 0.519940, acc.: 71.09%] [G loss: 0.857564]\n",
      "epoch:27 step:25678 [D loss: 0.530407, acc.: 71.88%] [G loss: 0.655241]\n",
      "epoch:27 step:25679 [D loss: 0.613412, acc.: 68.75%] [G loss: 0.507706]\n",
      "epoch:27 step:25680 [D loss: 0.468333, acc.: 78.12%] [G loss: 0.651295]\n",
      "epoch:27 step:25681 [D loss: 0.528841, acc.: 74.22%] [G loss: 0.760501]\n",
      "epoch:27 step:25682 [D loss: 0.514444, acc.: 71.88%] [G loss: 0.842926]\n",
      "epoch:27 step:25683 [D loss: 0.498290, acc.: 73.44%] [G loss: 0.768728]\n",
      "epoch:27 step:25684 [D loss: 0.459728, acc.: 77.34%] [G loss: 0.805925]\n",
      "epoch:27 step:25685 [D loss: 0.611587, acc.: 67.97%] [G loss: 0.747051]\n",
      "epoch:27 step:25686 [D loss: 0.533425, acc.: 70.31%] [G loss: 0.698077]\n",
      "epoch:27 step:25687 [D loss: 0.577805, acc.: 67.19%] [G loss: 0.717784]\n",
      "epoch:27 step:25688 [D loss: 0.480535, acc.: 74.22%] [G loss: 0.795376]\n",
      "epoch:27 step:25689 [D loss: 0.631930, acc.: 64.06%] [G loss: 0.700795]\n",
      "epoch:27 step:25690 [D loss: 0.518136, acc.: 69.53%] [G loss: 0.722958]\n",
      "epoch:27 step:25691 [D loss: 0.446324, acc.: 76.56%] [G loss: 0.761139]\n",
      "epoch:27 step:25692 [D loss: 0.604652, acc.: 59.38%] [G loss: 0.664176]\n",
      "epoch:27 step:25693 [D loss: 0.559352, acc.: 74.22%] [G loss: 0.640470]\n",
      "epoch:27 step:25694 [D loss: 0.542236, acc.: 72.66%] [G loss: 0.765827]\n",
      "epoch:27 step:25695 [D loss: 0.585269, acc.: 66.41%] [G loss: 0.642071]\n",
      "epoch:27 step:25696 [D loss: 0.529969, acc.: 68.75%] [G loss: 0.711818]\n",
      "epoch:27 step:25697 [D loss: 0.514545, acc.: 72.66%] [G loss: 0.758385]\n",
      "epoch:27 step:25698 [D loss: 0.510667, acc.: 73.44%] [G loss: 0.899255]\n",
      "epoch:27 step:25699 [D loss: 0.654333, acc.: 57.03%] [G loss: 0.547442]\n",
      "epoch:27 step:25700 [D loss: 0.644296, acc.: 58.59%] [G loss: 0.541736]\n",
      "epoch:27 step:25701 [D loss: 0.456753, acc.: 80.47%] [G loss: 0.801059]\n",
      "epoch:27 step:25702 [D loss: 0.485556, acc.: 72.66%] [G loss: 0.782096]\n",
      "epoch:27 step:25703 [D loss: 0.543521, acc.: 69.53%] [G loss: 0.713489]\n",
      "epoch:27 step:25704 [D loss: 0.471030, acc.: 76.56%] [G loss: 0.812241]\n",
      "epoch:27 step:25705 [D loss: 0.494432, acc.: 75.00%] [G loss: 0.852192]\n",
      "epoch:27 step:25706 [D loss: 0.573216, acc.: 67.19%] [G loss: 0.987125]\n",
      "epoch:27 step:25707 [D loss: 0.540271, acc.: 71.09%] [G loss: 0.738238]\n",
      "epoch:27 step:25708 [D loss: 0.510029, acc.: 67.19%] [G loss: 0.820421]\n",
      "epoch:27 step:25709 [D loss: 0.579095, acc.: 64.06%] [G loss: 0.832400]\n",
      "epoch:27 step:25710 [D loss: 0.596832, acc.: 63.28%] [G loss: 0.869897]\n",
      "epoch:27 step:25711 [D loss: 0.618465, acc.: 58.59%] [G loss: 0.688749]\n",
      "epoch:27 step:25712 [D loss: 0.558960, acc.: 71.88%] [G loss: 0.576703]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:27 step:25713 [D loss: 0.499541, acc.: 77.34%] [G loss: 0.635045]\n",
      "epoch:27 step:25714 [D loss: 0.538294, acc.: 68.75%] [G loss: 0.800715]\n",
      "epoch:27 step:25715 [D loss: 0.481177, acc.: 75.00%] [G loss: 0.935689]\n",
      "epoch:27 step:25716 [D loss: 0.507130, acc.: 77.34%] [G loss: 0.842599]\n",
      "epoch:27 step:25717 [D loss: 0.567497, acc.: 68.75%] [G loss: 0.846753]\n",
      "epoch:27 step:25718 [D loss: 0.566632, acc.: 70.31%] [G loss: 0.676159]\n",
      "epoch:27 step:25719 [D loss: 0.550044, acc.: 71.88%] [G loss: 0.728020]\n",
      "epoch:27 step:25720 [D loss: 0.540933, acc.: 69.53%] [G loss: 0.664366]\n",
      "epoch:27 step:25721 [D loss: 0.611014, acc.: 69.53%] [G loss: 0.651482]\n",
      "epoch:27 step:25722 [D loss: 0.534996, acc.: 69.53%] [G loss: 0.589688]\n",
      "epoch:27 step:25723 [D loss: 0.555089, acc.: 67.97%] [G loss: 0.668338]\n",
      "epoch:27 step:25724 [D loss: 0.526117, acc.: 74.22%] [G loss: 0.642809]\n",
      "epoch:27 step:25725 [D loss: 0.437790, acc.: 75.00%] [G loss: 0.845536]\n",
      "epoch:27 step:25726 [D loss: 0.454544, acc.: 75.00%] [G loss: 0.881758]\n",
      "epoch:27 step:25727 [D loss: 0.535109, acc.: 71.09%] [G loss: 0.727775]\n",
      "epoch:27 step:25728 [D loss: 0.436834, acc.: 80.47%] [G loss: 0.883537]\n",
      "epoch:27 step:25729 [D loss: 0.476238, acc.: 76.56%] [G loss: 0.963150]\n",
      "epoch:27 step:25730 [D loss: 0.537917, acc.: 71.09%] [G loss: 0.869775]\n",
      "epoch:27 step:25731 [D loss: 0.572223, acc.: 67.97%] [G loss: 0.730527]\n",
      "epoch:27 step:25732 [D loss: 0.458850, acc.: 78.12%] [G loss: 0.830320]\n",
      "epoch:27 step:25733 [D loss: 0.528052, acc.: 74.22%] [G loss: 0.600934]\n",
      "epoch:27 step:25734 [D loss: 0.517483, acc.: 70.31%] [G loss: 0.844316]\n",
      "epoch:27 step:25735 [D loss: 0.460451, acc.: 77.34%] [G loss: 0.934515]\n",
      "epoch:27 step:25736 [D loss: 0.664858, acc.: 60.94%] [G loss: 0.709156]\n",
      "epoch:27 step:25737 [D loss: 0.566868, acc.: 67.19%] [G loss: 0.676285]\n",
      "epoch:27 step:25738 [D loss: 0.505066, acc.: 74.22%] [G loss: 0.705106]\n",
      "epoch:27 step:25739 [D loss: 0.491765, acc.: 72.66%] [G loss: 0.848886]\n",
      "epoch:27 step:25740 [D loss: 0.509136, acc.: 70.31%] [G loss: 0.972213]\n",
      "epoch:27 step:25741 [D loss: 0.592959, acc.: 66.41%] [G loss: 0.638433]\n",
      "epoch:27 step:25742 [D loss: 0.540749, acc.: 71.09%] [G loss: 0.822756]\n",
      "epoch:27 step:25743 [D loss: 0.474119, acc.: 76.56%] [G loss: 0.903772]\n",
      "epoch:27 step:25744 [D loss: 0.591275, acc.: 67.97%] [G loss: 0.921635]\n",
      "epoch:27 step:25745 [D loss: 0.462303, acc.: 79.69%] [G loss: 0.716152]\n",
      "epoch:27 step:25746 [D loss: 0.502848, acc.: 74.22%] [G loss: 0.948671]\n",
      "epoch:27 step:25747 [D loss: 0.565906, acc.: 67.19%] [G loss: 0.650133]\n",
      "epoch:27 step:25748 [D loss: 0.533699, acc.: 70.31%] [G loss: 0.713404]\n",
      "epoch:27 step:25749 [D loss: 0.517879, acc.: 71.09%] [G loss: 0.780115]\n",
      "epoch:27 step:25750 [D loss: 0.373562, acc.: 82.03%] [G loss: 0.836965]\n",
      "epoch:27 step:25751 [D loss: 0.499987, acc.: 71.88%] [G loss: 0.934774]\n",
      "epoch:27 step:25752 [D loss: 0.510808, acc.: 75.78%] [G loss: 0.843749]\n",
      "epoch:27 step:25753 [D loss: 0.574209, acc.: 69.53%] [G loss: 0.669312]\n",
      "epoch:27 step:25754 [D loss: 0.496249, acc.: 75.78%] [G loss: 0.843105]\n",
      "epoch:27 step:25755 [D loss: 0.589770, acc.: 68.75%] [G loss: 0.738199]\n",
      "epoch:27 step:25756 [D loss: 0.442923, acc.: 80.47%] [G loss: 0.852251]\n",
      "epoch:27 step:25757 [D loss: 0.637378, acc.: 66.41%] [G loss: 0.743412]\n",
      "epoch:27 step:25758 [D loss: 0.554457, acc.: 69.53%] [G loss: 0.696901]\n",
      "epoch:27 step:25759 [D loss: 0.475409, acc.: 76.56%] [G loss: 0.950924]\n",
      "epoch:27 step:25760 [D loss: 0.478067, acc.: 74.22%] [G loss: 0.778442]\n",
      "epoch:27 step:25761 [D loss: 0.557198, acc.: 67.97%] [G loss: 0.791902]\n",
      "epoch:27 step:25762 [D loss: 0.512696, acc.: 70.31%] [G loss: 0.634362]\n",
      "epoch:27 step:25763 [D loss: 0.450304, acc.: 78.91%] [G loss: 0.642920]\n",
      "epoch:27 step:25764 [D loss: 0.604118, acc.: 62.50%] [G loss: 0.740842]\n",
      "epoch:27 step:25765 [D loss: 0.515725, acc.: 68.75%] [G loss: 0.750862]\n",
      "epoch:27 step:25766 [D loss: 0.527385, acc.: 71.09%] [G loss: 0.747417]\n",
      "epoch:27 step:25767 [D loss: 0.618623, acc.: 66.41%] [G loss: 0.621248]\n",
      "epoch:27 step:25768 [D loss: 0.506761, acc.: 75.00%] [G loss: 0.920505]\n",
      "epoch:27 step:25769 [D loss: 0.559456, acc.: 70.31%] [G loss: 0.711799]\n",
      "epoch:27 step:25770 [D loss: 0.448565, acc.: 79.69%] [G loss: 0.920954]\n",
      "epoch:27 step:25771 [D loss: 0.476112, acc.: 73.44%] [G loss: 1.029733]\n",
      "epoch:27 step:25772 [D loss: 0.595241, acc.: 67.19%] [G loss: 0.733477]\n",
      "epoch:27 step:25773 [D loss: 0.543919, acc.: 67.97%] [G loss: 0.591190]\n",
      "epoch:27 step:25774 [D loss: 0.440596, acc.: 81.25%] [G loss: 0.927255]\n",
      "epoch:27 step:25775 [D loss: 0.500585, acc.: 75.00%] [G loss: 0.950212]\n",
      "epoch:27 step:25776 [D loss: 0.625226, acc.: 61.72%] [G loss: 0.745602]\n",
      "epoch:27 step:25777 [D loss: 0.569258, acc.: 70.31%] [G loss: 0.603930]\n",
      "epoch:27 step:25778 [D loss: 0.511119, acc.: 73.44%] [G loss: 0.611916]\n",
      "epoch:27 step:25779 [D loss: 0.597460, acc.: 65.62%] [G loss: 0.562894]\n",
      "epoch:27 step:25780 [D loss: 0.475085, acc.: 84.38%] [G loss: 0.720814]\n",
      "epoch:27 step:25781 [D loss: 0.553769, acc.: 67.97%] [G loss: 0.558913]\n",
      "epoch:27 step:25782 [D loss: 0.540663, acc.: 70.31%] [G loss: 0.571244]\n",
      "epoch:27 step:25783 [D loss: 0.462478, acc.: 75.78%] [G loss: 0.714936]\n",
      "epoch:27 step:25784 [D loss: 0.526994, acc.: 71.88%] [G loss: 0.720055]\n",
      "epoch:27 step:25785 [D loss: 0.551971, acc.: 68.75%] [G loss: 0.658265]\n",
      "epoch:27 step:25786 [D loss: 0.522952, acc.: 71.09%] [G loss: 0.697490]\n",
      "epoch:27 step:25787 [D loss: 0.451074, acc.: 75.78%] [G loss: 0.825165]\n",
      "epoch:27 step:25788 [D loss: 0.480028, acc.: 77.34%] [G loss: 0.901286]\n",
      "epoch:27 step:25789 [D loss: 0.545331, acc.: 71.88%] [G loss: 0.687440]\n",
      "epoch:27 step:25790 [D loss: 0.537979, acc.: 72.66%] [G loss: 0.763017]\n",
      "epoch:27 step:25791 [D loss: 0.516547, acc.: 71.09%] [G loss: 0.693809]\n",
      "epoch:27 step:25792 [D loss: 0.512074, acc.: 73.44%] [G loss: 0.777745]\n",
      "epoch:27 step:25793 [D loss: 0.572670, acc.: 71.09%] [G loss: 0.671668]\n",
      "epoch:27 step:25794 [D loss: 0.460848, acc.: 82.03%] [G loss: 0.891397]\n",
      "epoch:27 step:25795 [D loss: 0.508505, acc.: 75.00%] [G loss: 0.663700]\n",
      "epoch:27 step:25796 [D loss: 0.539869, acc.: 72.66%] [G loss: 0.748331]\n",
      "epoch:27 step:25797 [D loss: 0.546569, acc.: 71.88%] [G loss: 0.805365]\n",
      "epoch:27 step:25798 [D loss: 0.432459, acc.: 78.12%] [G loss: 1.015749]\n",
      "epoch:27 step:25799 [D loss: 0.475556, acc.: 76.56%] [G loss: 0.908078]\n",
      "epoch:27 step:25800 [D loss: 0.609348, acc.: 66.41%] [G loss: 0.743485]\n",
      "epoch:27 step:25801 [D loss: 0.648157, acc.: 59.38%] [G loss: 0.523125]\n",
      "epoch:27 step:25802 [D loss: 0.439498, acc.: 78.91%] [G loss: 0.724829]\n",
      "epoch:27 step:25803 [D loss: 0.475102, acc.: 76.56%] [G loss: 0.751454]\n",
      "epoch:27 step:25804 [D loss: 0.491747, acc.: 75.78%] [G loss: 0.953935]\n",
      "epoch:27 step:25805 [D loss: 0.454094, acc.: 78.91%] [G loss: 0.774643]\n",
      "epoch:27 step:25806 [D loss: 0.522014, acc.: 75.00%] [G loss: 0.785444]\n",
      "epoch:27 step:25807 [D loss: 0.441493, acc.: 78.91%] [G loss: 1.185786]\n",
      "epoch:27 step:25808 [D loss: 0.460929, acc.: 75.78%] [G loss: 1.130360]\n",
      "epoch:27 step:25809 [D loss: 0.542420, acc.: 73.44%] [G loss: 0.860384]\n",
      "epoch:27 step:25810 [D loss: 0.623415, acc.: 64.06%] [G loss: 0.690233]\n",
      "epoch:27 step:25811 [D loss: 0.548716, acc.: 69.53%] [G loss: 0.591858]\n",
      "epoch:27 step:25812 [D loss: 0.513156, acc.: 74.22%] [G loss: 0.612715]\n",
      "epoch:27 step:25813 [D loss: 0.497507, acc.: 73.44%] [G loss: 0.772041]\n",
      "epoch:27 step:25814 [D loss: 0.526967, acc.: 75.00%] [G loss: 0.613260]\n",
      "epoch:27 step:25815 [D loss: 0.490501, acc.: 78.12%] [G loss: 0.733147]\n",
      "epoch:27 step:25816 [D loss: 0.506867, acc.: 72.66%] [G loss: 0.791268]\n",
      "epoch:27 step:25817 [D loss: 0.588099, acc.: 66.41%] [G loss: 0.665833]\n",
      "epoch:27 step:25818 [D loss: 0.499742, acc.: 71.88%] [G loss: 0.780034]\n",
      "epoch:27 step:25819 [D loss: 0.460559, acc.: 78.12%] [G loss: 0.742946]\n",
      "epoch:27 step:25820 [D loss: 0.502210, acc.: 75.00%] [G loss: 0.639104]\n",
      "epoch:27 step:25821 [D loss: 0.508106, acc.: 74.22%] [G loss: 1.018048]\n",
      "epoch:27 step:25822 [D loss: 0.406466, acc.: 80.47%] [G loss: 0.867766]\n",
      "epoch:27 step:25823 [D loss: 0.537063, acc.: 76.56%] [G loss: 0.813072]\n",
      "epoch:27 step:25824 [D loss: 0.568791, acc.: 67.19%] [G loss: 0.637960]\n",
      "epoch:27 step:25825 [D loss: 0.512182, acc.: 71.09%] [G loss: 0.696116]\n",
      "epoch:27 step:25826 [D loss: 0.543854, acc.: 70.31%] [G loss: 0.764320]\n",
      "epoch:27 step:25827 [D loss: 0.669414, acc.: 57.81%] [G loss: 0.549791]\n",
      "epoch:27 step:25828 [D loss: 0.585345, acc.: 62.50%] [G loss: 0.749896]\n",
      "epoch:27 step:25829 [D loss: 0.534676, acc.: 70.31%] [G loss: 0.993275]\n",
      "epoch:27 step:25830 [D loss: 0.544309, acc.: 71.09%] [G loss: 0.834342]\n",
      "epoch:27 step:25831 [D loss: 0.563957, acc.: 66.41%] [G loss: 0.720586]\n",
      "epoch:27 step:25832 [D loss: 0.540406, acc.: 68.75%] [G loss: 0.759782]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:27 step:25833 [D loss: 0.478565, acc.: 71.88%] [G loss: 0.781917]\n",
      "epoch:27 step:25834 [D loss: 0.593903, acc.: 68.75%] [G loss: 0.697247]\n",
      "epoch:27 step:25835 [D loss: 0.487774, acc.: 73.44%] [G loss: 0.550709]\n",
      "epoch:27 step:25836 [D loss: 0.542532, acc.: 66.41%] [G loss: 0.667091]\n",
      "epoch:27 step:25837 [D loss: 0.530642, acc.: 69.53%] [G loss: 0.573750]\n",
      "epoch:27 step:25838 [D loss: 0.546514, acc.: 70.31%] [G loss: 0.501718]\n",
      "epoch:27 step:25839 [D loss: 0.551016, acc.: 68.75%] [G loss: 0.600406]\n",
      "epoch:27 step:25840 [D loss: 0.543501, acc.: 71.88%] [G loss: 0.692905]\n",
      "epoch:27 step:25841 [D loss: 0.595276, acc.: 68.75%] [G loss: 0.594703]\n",
      "epoch:27 step:25842 [D loss: 0.602043, acc.: 61.72%] [G loss: 0.595339]\n",
      "epoch:27 step:25843 [D loss: 0.552898, acc.: 72.66%] [G loss: 0.533492]\n",
      "epoch:27 step:25844 [D loss: 0.544970, acc.: 71.09%] [G loss: 0.612029]\n",
      "epoch:27 step:25845 [D loss: 0.520964, acc.: 71.88%] [G loss: 0.683176]\n",
      "epoch:27 step:25846 [D loss: 0.543925, acc.: 71.09%] [G loss: 0.678452]\n",
      "epoch:27 step:25847 [D loss: 0.456038, acc.: 77.34%] [G loss: 0.856918]\n",
      "epoch:27 step:25848 [D loss: 0.531991, acc.: 72.66%] [G loss: 0.856710]\n",
      "epoch:27 step:25849 [D loss: 0.503999, acc.: 74.22%] [G loss: 0.733732]\n",
      "epoch:27 step:25850 [D loss: 0.455020, acc.: 76.56%] [G loss: 0.788284]\n",
      "epoch:27 step:25851 [D loss: 0.506762, acc.: 71.88%] [G loss: 0.748187]\n",
      "epoch:27 step:25852 [D loss: 0.579847, acc.: 68.75%] [G loss: 0.663672]\n",
      "epoch:27 step:25853 [D loss: 0.453378, acc.: 78.91%] [G loss: 0.742449]\n",
      "epoch:27 step:25854 [D loss: 0.457584, acc.: 80.47%] [G loss: 0.755398]\n",
      "epoch:27 step:25855 [D loss: 0.510730, acc.: 74.22%] [G loss: 0.700328]\n",
      "epoch:27 step:25856 [D loss: 0.493589, acc.: 75.78%] [G loss: 0.801505]\n",
      "epoch:27 step:25857 [D loss: 0.426036, acc.: 82.03%] [G loss: 0.886834]\n",
      "epoch:27 step:25858 [D loss: 0.590031, acc.: 63.28%] [G loss: 0.678570]\n",
      "epoch:27 step:25859 [D loss: 0.531484, acc.: 68.75%] [G loss: 0.794955]\n",
      "epoch:27 step:25860 [D loss: 0.487968, acc.: 70.31%] [G loss: 0.766753]\n",
      "epoch:27 step:25861 [D loss: 0.555241, acc.: 71.09%] [G loss: 0.564623]\n",
      "epoch:27 step:25862 [D loss: 0.519523, acc.: 70.31%] [G loss: 0.757153]\n",
      "epoch:27 step:25863 [D loss: 0.459497, acc.: 78.91%] [G loss: 0.930439]\n",
      "epoch:27 step:25864 [D loss: 0.539083, acc.: 74.22%] [G loss: 0.758312]\n",
      "epoch:27 step:25865 [D loss: 0.642817, acc.: 64.84%] [G loss: 0.506071]\n",
      "epoch:27 step:25866 [D loss: 0.514711, acc.: 74.22%] [G loss: 0.541504]\n",
      "epoch:27 step:25867 [D loss: 0.472155, acc.: 76.56%] [G loss: 0.691584]\n",
      "epoch:27 step:25868 [D loss: 0.500290, acc.: 76.56%] [G loss: 0.702621]\n",
      "epoch:27 step:25869 [D loss: 0.513329, acc.: 74.22%] [G loss: 0.835594]\n",
      "epoch:27 step:25870 [D loss: 0.534098, acc.: 69.53%] [G loss: 0.657858]\n",
      "epoch:27 step:25871 [D loss: 0.499912, acc.: 76.56%] [G loss: 0.803420]\n",
      "epoch:27 step:25872 [D loss: 0.497447, acc.: 75.00%] [G loss: 0.825195]\n",
      "epoch:27 step:25873 [D loss: 0.446527, acc.: 77.34%] [G loss: 0.871606]\n",
      "epoch:27 step:25874 [D loss: 0.473327, acc.: 75.00%] [G loss: 0.847481]\n",
      "epoch:27 step:25875 [D loss: 0.574125, acc.: 69.53%] [G loss: 0.890521]\n",
      "epoch:27 step:25876 [D loss: 0.527317, acc.: 71.09%] [G loss: 0.929441]\n",
      "epoch:27 step:25877 [D loss: 0.525878, acc.: 71.09%] [G loss: 0.573805]\n",
      "epoch:27 step:25878 [D loss: 0.499763, acc.: 72.66%] [G loss: 0.931754]\n",
      "epoch:27 step:25879 [D loss: 0.541754, acc.: 72.66%] [G loss: 0.839332]\n",
      "epoch:27 step:25880 [D loss: 0.510424, acc.: 74.22%] [G loss: 0.766547]\n",
      "epoch:27 step:25881 [D loss: 0.432521, acc.: 79.69%] [G loss: 0.758142]\n",
      "epoch:27 step:25882 [D loss: 0.460215, acc.: 77.34%] [G loss: 1.069252]\n",
      "epoch:27 step:25883 [D loss: 0.587886, acc.: 68.75%] [G loss: 0.705515]\n",
      "epoch:27 step:25884 [D loss: 0.516762, acc.: 72.66%] [G loss: 0.663388]\n",
      "epoch:27 step:25885 [D loss: 0.571422, acc.: 64.84%] [G loss: 0.611978]\n",
      "epoch:27 step:25886 [D loss: 0.547932, acc.: 67.97%] [G loss: 0.735563]\n",
      "epoch:27 step:25887 [D loss: 0.591281, acc.: 67.19%] [G loss: 0.690716]\n",
      "epoch:27 step:25888 [D loss: 0.547310, acc.: 65.62%] [G loss: 0.702189]\n",
      "epoch:27 step:25889 [D loss: 0.508893, acc.: 74.22%] [G loss: 0.746473]\n",
      "epoch:27 step:25890 [D loss: 0.523132, acc.: 75.00%] [G loss: 0.719977]\n",
      "epoch:27 step:25891 [D loss: 0.503096, acc.: 72.66%] [G loss: 0.774568]\n",
      "epoch:27 step:25892 [D loss: 0.472044, acc.: 78.12%] [G loss: 0.784949]\n",
      "epoch:27 step:25893 [D loss: 0.506678, acc.: 71.88%] [G loss: 0.808820]\n",
      "epoch:27 step:25894 [D loss: 0.535222, acc.: 67.97%] [G loss: 0.846217]\n",
      "epoch:27 step:25895 [D loss: 0.575022, acc.: 66.41%] [G loss: 0.752602]\n",
      "epoch:27 step:25896 [D loss: 0.522933, acc.: 74.22%] [G loss: 0.778556]\n",
      "epoch:27 step:25897 [D loss: 0.527062, acc.: 71.88%] [G loss: 0.922901]\n",
      "epoch:27 step:25898 [D loss: 0.601296, acc.: 68.75%] [G loss: 0.771853]\n",
      "epoch:27 step:25899 [D loss: 0.552542, acc.: 67.97%] [G loss: 0.722488]\n",
      "epoch:27 step:25900 [D loss: 0.539758, acc.: 71.09%] [G loss: 0.783027]\n",
      "epoch:27 step:25901 [D loss: 0.478852, acc.: 75.78%] [G loss: 0.845690]\n",
      "epoch:27 step:25902 [D loss: 0.484829, acc.: 75.78%] [G loss: 1.003124]\n",
      "epoch:27 step:25903 [D loss: 0.568179, acc.: 68.75%] [G loss: 0.738843]\n",
      "epoch:27 step:25904 [D loss: 0.403475, acc.: 82.81%] [G loss: 1.028188]\n",
      "epoch:27 step:25905 [D loss: 0.594995, acc.: 68.75%] [G loss: 0.682581]\n",
      "epoch:27 step:25906 [D loss: 0.548932, acc.: 72.66%] [G loss: 0.783742]\n",
      "epoch:27 step:25907 [D loss: 0.513581, acc.: 74.22%] [G loss: 0.676844]\n",
      "epoch:27 step:25908 [D loss: 0.521573, acc.: 71.88%] [G loss: 0.638628]\n",
      "epoch:27 step:25909 [D loss: 0.568903, acc.: 68.75%] [G loss: 0.488235]\n",
      "epoch:27 step:25910 [D loss: 0.472886, acc.: 78.91%] [G loss: 0.736574]\n",
      "epoch:27 step:25911 [D loss: 0.513804, acc.: 68.75%] [G loss: 0.761567]\n",
      "epoch:27 step:25912 [D loss: 0.454669, acc.: 72.66%] [G loss: 0.859654]\n",
      "epoch:27 step:25913 [D loss: 0.594999, acc.: 64.84%] [G loss: 0.732005]\n",
      "epoch:27 step:25914 [D loss: 0.544693, acc.: 68.75%] [G loss: 0.671695]\n",
      "epoch:27 step:25915 [D loss: 0.569218, acc.: 70.31%] [G loss: 0.946568]\n",
      "epoch:27 step:25916 [D loss: 0.480638, acc.: 79.69%] [G loss: 0.837591]\n",
      "epoch:27 step:25917 [D loss: 0.531873, acc.: 71.88%] [G loss: 0.717600]\n",
      "epoch:27 step:25918 [D loss: 0.553706, acc.: 67.19%] [G loss: 0.739895]\n",
      "epoch:27 step:25919 [D loss: 0.479725, acc.: 77.34%] [G loss: 0.708656]\n",
      "epoch:27 step:25920 [D loss: 0.493214, acc.: 74.22%] [G loss: 0.625589]\n",
      "epoch:27 step:25921 [D loss: 0.549299, acc.: 70.31%] [G loss: 0.720561]\n",
      "epoch:27 step:25922 [D loss: 0.426761, acc.: 80.47%] [G loss: 0.728265]\n",
      "epoch:27 step:25923 [D loss: 0.445880, acc.: 81.25%] [G loss: 0.912897]\n",
      "epoch:27 step:25924 [D loss: 0.544702, acc.: 69.53%] [G loss: 0.805356]\n",
      "epoch:27 step:25925 [D loss: 0.505933, acc.: 73.44%] [G loss: 0.780608]\n",
      "epoch:27 step:25926 [D loss: 0.505439, acc.: 71.88%] [G loss: 0.806067]\n",
      "epoch:27 step:25927 [D loss: 0.557003, acc.: 67.19%] [G loss: 0.678342]\n",
      "epoch:27 step:25928 [D loss: 0.518805, acc.: 71.88%] [G loss: 0.721978]\n",
      "epoch:27 step:25929 [D loss: 0.465040, acc.: 77.34%] [G loss: 0.610747]\n",
      "epoch:27 step:25930 [D loss: 0.435318, acc.: 84.38%] [G loss: 0.808457]\n",
      "epoch:27 step:25931 [D loss: 0.490657, acc.: 76.56%] [G loss: 0.684439]\n",
      "epoch:27 step:25932 [D loss: 0.470874, acc.: 79.69%] [G loss: 0.723212]\n",
      "epoch:27 step:25933 [D loss: 0.470307, acc.: 77.34%] [G loss: 0.699488]\n",
      "epoch:27 step:25934 [D loss: 0.485769, acc.: 75.78%] [G loss: 0.764425]\n",
      "epoch:27 step:25935 [D loss: 0.572335, acc.: 67.97%] [G loss: 0.713283]\n",
      "epoch:27 step:25936 [D loss: 0.549323, acc.: 72.66%] [G loss: 0.684415]\n",
      "epoch:27 step:25937 [D loss: 0.495832, acc.: 75.78%] [G loss: 0.523929]\n",
      "epoch:27 step:25938 [D loss: 0.460291, acc.: 77.34%] [G loss: 0.734021]\n",
      "epoch:27 step:25939 [D loss: 0.539009, acc.: 71.88%] [G loss: 0.870003]\n",
      "epoch:27 step:25940 [D loss: 0.503882, acc.: 72.66%] [G loss: 0.830475]\n",
      "epoch:27 step:25941 [D loss: 0.471122, acc.: 75.78%] [G loss: 0.988255]\n",
      "epoch:27 step:25942 [D loss: 0.481304, acc.: 74.22%] [G loss: 1.020776]\n",
      "epoch:27 step:25943 [D loss: 0.561509, acc.: 67.97%] [G loss: 0.688115]\n",
      "epoch:27 step:25944 [D loss: 0.499274, acc.: 75.78%] [G loss: 0.761986]\n",
      "epoch:27 step:25945 [D loss: 0.539003, acc.: 74.22%] [G loss: 0.626647]\n",
      "epoch:27 step:25946 [D loss: 0.400352, acc.: 85.16%] [G loss: 0.803673]\n",
      "epoch:27 step:25947 [D loss: 0.371964, acc.: 88.28%] [G loss: 1.033486]\n",
      "epoch:27 step:25948 [D loss: 0.430676, acc.: 78.12%] [G loss: 1.016963]\n",
      "epoch:27 step:25949 [D loss: 0.472773, acc.: 75.78%] [G loss: 1.061105]\n",
      "epoch:27 step:25950 [D loss: 0.464620, acc.: 75.00%] [G loss: 0.947776]\n",
      "epoch:27 step:25951 [D loss: 0.581956, acc.: 71.88%] [G loss: 0.707615]\n",
      "epoch:27 step:25952 [D loss: 0.446044, acc.: 79.69%] [G loss: 1.036566]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:27 step:25953 [D loss: 0.433372, acc.: 75.78%] [G loss: 1.070165]\n",
      "epoch:27 step:25954 [D loss: 0.558803, acc.: 68.75%] [G loss: 0.882723]\n",
      "epoch:27 step:25955 [D loss: 0.556161, acc.: 68.75%] [G loss: 0.715124]\n",
      "epoch:27 step:25956 [D loss: 0.501589, acc.: 77.34%] [G loss: 0.708423]\n",
      "epoch:27 step:25957 [D loss: 0.554392, acc.: 67.19%] [G loss: 0.882384]\n",
      "epoch:27 step:25958 [D loss: 0.489992, acc.: 72.66%] [G loss: 0.914645]\n",
      "epoch:27 step:25959 [D loss: 0.490969, acc.: 71.09%] [G loss: 0.835015]\n",
      "epoch:27 step:25960 [D loss: 0.487939, acc.: 75.78%] [G loss: 0.850994]\n",
      "epoch:27 step:25961 [D loss: 0.514246, acc.: 73.44%] [G loss: 0.675275]\n",
      "epoch:27 step:25962 [D loss: 0.635469, acc.: 62.50%] [G loss: 0.773101]\n",
      "epoch:27 step:25963 [D loss: 0.527301, acc.: 71.88%] [G loss: 0.722945]\n",
      "epoch:27 step:25964 [D loss: 0.548461, acc.: 70.31%] [G loss: 0.876332]\n",
      "epoch:27 step:25965 [D loss: 0.519778, acc.: 70.31%] [G loss: 0.692395]\n",
      "epoch:27 step:25966 [D loss: 0.461233, acc.: 78.91%] [G loss: 0.830807]\n",
      "epoch:27 step:25967 [D loss: 0.502943, acc.: 76.56%] [G loss: 0.853255]\n",
      "epoch:27 step:25968 [D loss: 0.572036, acc.: 66.41%] [G loss: 0.813330]\n",
      "epoch:27 step:25969 [D loss: 0.541148, acc.: 70.31%] [G loss: 0.705711]\n",
      "epoch:27 step:25970 [D loss: 0.518971, acc.: 72.66%] [G loss: 0.658284]\n",
      "epoch:27 step:25971 [D loss: 0.527747, acc.: 71.88%] [G loss: 0.746006]\n",
      "epoch:27 step:25972 [D loss: 0.586577, acc.: 65.62%] [G loss: 0.788671]\n",
      "epoch:27 step:25973 [D loss: 0.533780, acc.: 70.31%] [G loss: 0.657136]\n",
      "epoch:27 step:25974 [D loss: 0.627235, acc.: 64.84%] [G loss: 0.616480]\n",
      "epoch:27 step:25975 [D loss: 0.554223, acc.: 66.41%] [G loss: 0.691896]\n",
      "epoch:27 step:25976 [D loss: 0.518500, acc.: 70.31%] [G loss: 0.531318]\n",
      "epoch:27 step:25977 [D loss: 0.539929, acc.: 72.66%] [G loss: 0.757512]\n",
      "epoch:27 step:25978 [D loss: 0.486105, acc.: 75.00%] [G loss: 0.801042]\n",
      "epoch:27 step:25979 [D loss: 0.518730, acc.: 75.00%] [G loss: 0.676171]\n",
      "epoch:27 step:25980 [D loss: 0.452836, acc.: 77.34%] [G loss: 0.811656]\n",
      "epoch:27 step:25981 [D loss: 0.512382, acc.: 75.00%] [G loss: 0.875067]\n",
      "epoch:27 step:25982 [D loss: 0.472638, acc.: 78.12%] [G loss: 0.755085]\n",
      "epoch:27 step:25983 [D loss: 0.595297, acc.: 64.84%] [G loss: 0.719606]\n",
      "epoch:27 step:25984 [D loss: 0.568671, acc.: 68.75%] [G loss: 0.610327]\n",
      "epoch:27 step:25985 [D loss: 0.525381, acc.: 71.88%] [G loss: 0.655669]\n",
      "epoch:27 step:25986 [D loss: 0.514581, acc.: 74.22%] [G loss: 0.681674]\n",
      "epoch:27 step:25987 [D loss: 0.499499, acc.: 76.56%] [G loss: 0.637919]\n",
      "epoch:27 step:25988 [D loss: 0.530908, acc.: 67.19%] [G loss: 0.872849]\n",
      "epoch:27 step:25989 [D loss: 0.473173, acc.: 75.00%] [G loss: 0.927755]\n",
      "epoch:27 step:25990 [D loss: 0.492646, acc.: 75.78%] [G loss: 0.761513]\n",
      "epoch:27 step:25991 [D loss: 0.508972, acc.: 73.44%] [G loss: 0.793932]\n",
      "epoch:27 step:25992 [D loss: 0.490936, acc.: 75.78%] [G loss: 0.834920]\n",
      "epoch:27 step:25993 [D loss: 0.481971, acc.: 73.44%] [G loss: 0.802587]\n",
      "epoch:27 step:25994 [D loss: 0.465207, acc.: 76.56%] [G loss: 0.790316]\n",
      "epoch:27 step:25995 [D loss: 0.655262, acc.: 60.94%] [G loss: 0.735149]\n",
      "epoch:27 step:25996 [D loss: 0.547327, acc.: 66.41%] [G loss: 0.733597]\n",
      "epoch:27 step:25997 [D loss: 0.633514, acc.: 60.16%] [G loss: 0.418109]\n",
      "epoch:27 step:25998 [D loss: 0.485159, acc.: 72.66%] [G loss: 0.632171]\n",
      "epoch:27 step:25999 [D loss: 0.448745, acc.: 78.12%] [G loss: 0.898158]\n",
      "epoch:27 step:26000 [D loss: 0.552554, acc.: 71.09%] [G loss: 0.860852]\n",
      "epoch:27 step:26001 [D loss: 0.640638, acc.: 64.06%] [G loss: 0.844526]\n",
      "epoch:27 step:26002 [D loss: 0.581900, acc.: 65.62%] [G loss: 0.581787]\n",
      "epoch:27 step:26003 [D loss: 0.566455, acc.: 65.62%] [G loss: 0.699579]\n",
      "epoch:27 step:26004 [D loss: 0.503428, acc.: 75.00%] [G loss: 0.721635]\n",
      "epoch:27 step:26005 [D loss: 0.486880, acc.: 74.22%] [G loss: 0.789149]\n",
      "epoch:27 step:26006 [D loss: 0.460093, acc.: 76.56%] [G loss: 0.774443]\n",
      "epoch:27 step:26007 [D loss: 0.481057, acc.: 78.12%] [G loss: 0.842122]\n",
      "epoch:27 step:26008 [D loss: 0.534007, acc.: 69.53%] [G loss: 0.824334]\n",
      "epoch:27 step:26009 [D loss: 0.552853, acc.: 67.97%] [G loss: 0.818107]\n",
      "epoch:27 step:26010 [D loss: 0.580285, acc.: 64.06%] [G loss: 0.820932]\n",
      "epoch:27 step:26011 [D loss: 0.487103, acc.: 74.22%] [G loss: 0.701377]\n",
      "epoch:27 step:26012 [D loss: 0.532179, acc.: 65.62%] [G loss: 0.910480]\n",
      "epoch:27 step:26013 [D loss: 0.542893, acc.: 71.09%] [G loss: 0.840761]\n",
      "epoch:27 step:26014 [D loss: 0.549361, acc.: 73.44%] [G loss: 0.760676]\n",
      "epoch:27 step:26015 [D loss: 0.570894, acc.: 68.75%] [G loss: 0.702431]\n",
      "epoch:27 step:26016 [D loss: 0.553007, acc.: 71.09%] [G loss: 0.521993]\n",
      "epoch:27 step:26017 [D loss: 0.514803, acc.: 71.09%] [G loss: 0.693720]\n",
      "epoch:27 step:26018 [D loss: 0.491067, acc.: 75.00%] [G loss: 0.887092]\n",
      "epoch:27 step:26019 [D loss: 0.548132, acc.: 71.88%] [G loss: 0.658564]\n",
      "epoch:27 step:26020 [D loss: 0.474931, acc.: 78.12%] [G loss: 0.713895]\n",
      "epoch:27 step:26021 [D loss: 0.565889, acc.: 68.75%] [G loss: 0.675063]\n",
      "epoch:27 step:26022 [D loss: 0.546853, acc.: 72.66%] [G loss: 0.629874]\n",
      "epoch:27 step:26023 [D loss: 0.449102, acc.: 79.69%] [G loss: 0.878434]\n",
      "epoch:27 step:26024 [D loss: 0.438924, acc.: 82.03%] [G loss: 0.894954]\n",
      "epoch:27 step:26025 [D loss: 0.500461, acc.: 75.78%] [G loss: 0.673679]\n",
      "epoch:27 step:26026 [D loss: 0.533928, acc.: 71.09%] [G loss: 0.643929]\n",
      "epoch:27 step:26027 [D loss: 0.498267, acc.: 72.66%] [G loss: 0.709385]\n",
      "epoch:27 step:26028 [D loss: 0.580742, acc.: 68.75%] [G loss: 0.714704]\n",
      "epoch:27 step:26029 [D loss: 0.486841, acc.: 78.12%] [G loss: 0.848356]\n",
      "epoch:27 step:26030 [D loss: 0.539755, acc.: 68.75%] [G loss: 0.854558]\n",
      "epoch:27 step:26031 [D loss: 0.560664, acc.: 68.75%] [G loss: 0.668662]\n",
      "epoch:27 step:26032 [D loss: 0.512234, acc.: 74.22%] [G loss: 0.977621]\n",
      "epoch:27 step:26033 [D loss: 0.499020, acc.: 71.88%] [G loss: 0.700774]\n",
      "epoch:27 step:26034 [D loss: 0.540992, acc.: 71.09%] [G loss: 0.673000]\n",
      "epoch:27 step:26035 [D loss: 0.532872, acc.: 72.66%] [G loss: 0.584630]\n",
      "epoch:27 step:26036 [D loss: 0.506047, acc.: 71.09%] [G loss: 0.836669]\n",
      "epoch:27 step:26037 [D loss: 0.540807, acc.: 71.09%] [G loss: 0.688565]\n",
      "epoch:27 step:26038 [D loss: 0.545108, acc.: 71.09%] [G loss: 0.753686]\n",
      "epoch:27 step:26039 [D loss: 0.618539, acc.: 61.72%] [G loss: 0.564300]\n",
      "epoch:27 step:26040 [D loss: 0.533558, acc.: 71.09%] [G loss: 0.565852]\n",
      "epoch:27 step:26041 [D loss: 0.487565, acc.: 74.22%] [G loss: 0.596341]\n",
      "epoch:27 step:26042 [D loss: 0.432878, acc.: 77.34%] [G loss: 0.755212]\n",
      "epoch:27 step:26043 [D loss: 0.491928, acc.: 77.34%] [G loss: 0.924494]\n",
      "epoch:27 step:26044 [D loss: 0.640694, acc.: 63.28%] [G loss: 0.674673]\n",
      "epoch:27 step:26045 [D loss: 0.434225, acc.: 77.34%] [G loss: 0.938042]\n",
      "epoch:27 step:26046 [D loss: 0.440581, acc.: 82.81%] [G loss: 0.868977]\n",
      "epoch:27 step:26047 [D loss: 0.512624, acc.: 68.75%] [G loss: 0.840178]\n",
      "epoch:27 step:26048 [D loss: 0.515284, acc.: 75.00%] [G loss: 0.886812]\n",
      "epoch:27 step:26049 [D loss: 0.507324, acc.: 78.12%] [G loss: 0.756206]\n",
      "epoch:27 step:26050 [D loss: 0.452687, acc.: 78.12%] [G loss: 0.951008]\n",
      "epoch:27 step:26051 [D loss: 0.597004, acc.: 66.41%] [G loss: 0.700932]\n",
      "epoch:27 step:26052 [D loss: 0.530885, acc.: 73.44%] [G loss: 0.986016]\n",
      "epoch:27 step:26053 [D loss: 0.544978, acc.: 70.31%] [G loss: 0.704873]\n",
      "epoch:27 step:26054 [D loss: 0.556113, acc.: 67.19%] [G loss: 0.904147]\n",
      "epoch:27 step:26055 [D loss: 0.576450, acc.: 66.41%] [G loss: 0.827708]\n",
      "epoch:27 step:26056 [D loss: 0.542270, acc.: 68.75%] [G loss: 0.721717]\n",
      "epoch:27 step:26057 [D loss: 0.481869, acc.: 78.91%] [G loss: 0.655149]\n",
      "epoch:27 step:26058 [D loss: 0.540736, acc.: 71.88%] [G loss: 0.896016]\n",
      "epoch:27 step:26059 [D loss: 0.521843, acc.: 70.31%] [G loss: 0.683188]\n",
      "epoch:27 step:26060 [D loss: 0.507234, acc.: 75.00%] [G loss: 0.680193]\n",
      "epoch:27 step:26061 [D loss: 0.565594, acc.: 69.53%] [G loss: 0.718336]\n",
      "epoch:27 step:26062 [D loss: 0.528796, acc.: 70.31%] [G loss: 0.519715]\n",
      "epoch:27 step:26063 [D loss: 0.552091, acc.: 71.09%] [G loss: 0.738558]\n",
      "epoch:27 step:26064 [D loss: 0.608595, acc.: 61.72%] [G loss: 0.672145]\n",
      "epoch:27 step:26065 [D loss: 0.586729, acc.: 62.50%] [G loss: 0.720508]\n",
      "epoch:27 step:26066 [D loss: 0.516903, acc.: 70.31%] [G loss: 0.700596]\n",
      "epoch:27 step:26067 [D loss: 0.496729, acc.: 78.91%] [G loss: 0.863290]\n",
      "epoch:27 step:26068 [D loss: 0.478368, acc.: 75.00%] [G loss: 0.891740]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:27 step:26069 [D loss: 0.475185, acc.: 75.78%] [G loss: 0.988031]\n",
      "epoch:27 step:26070 [D loss: 0.540457, acc.: 71.09%] [G loss: 1.028495]\n",
      "epoch:27 step:26071 [D loss: 0.541823, acc.: 73.44%] [G loss: 0.899507]\n",
      "epoch:27 step:26072 [D loss: 0.538192, acc.: 71.09%] [G loss: 0.819093]\n",
      "epoch:27 step:26073 [D loss: 0.595569, acc.: 71.09%] [G loss: 0.788545]\n",
      "epoch:27 step:26074 [D loss: 0.503879, acc.: 71.88%] [G loss: 0.794050]\n",
      "epoch:27 step:26075 [D loss: 0.502991, acc.: 73.44%] [G loss: 0.763284]\n",
      "epoch:27 step:26076 [D loss: 0.515926, acc.: 73.44%] [G loss: 0.781659]\n",
      "epoch:27 step:26077 [D loss: 0.575388, acc.: 69.53%] [G loss: 0.647044]\n",
      "epoch:27 step:26078 [D loss: 0.501269, acc.: 75.78%] [G loss: 0.743649]\n",
      "epoch:27 step:26079 [D loss: 0.480471, acc.: 75.78%] [G loss: 0.826285]\n",
      "epoch:27 step:26080 [D loss: 0.457612, acc.: 76.56%] [G loss: 1.060708]\n",
      "epoch:27 step:26081 [D loss: 0.502967, acc.: 72.66%] [G loss: 0.967541]\n",
      "epoch:27 step:26082 [D loss: 0.516425, acc.: 71.88%] [G loss: 1.237491]\n",
      "epoch:27 step:26083 [D loss: 0.638023, acc.: 65.62%] [G loss: 0.731033]\n",
      "epoch:27 step:26084 [D loss: 0.525827, acc.: 69.53%] [G loss: 0.609264]\n",
      "epoch:27 step:26085 [D loss: 0.503639, acc.: 73.44%] [G loss: 0.637313]\n",
      "epoch:27 step:26086 [D loss: 0.538294, acc.: 70.31%] [G loss: 0.668265]\n",
      "epoch:27 step:26087 [D loss: 0.567780, acc.: 64.84%] [G loss: 0.594730]\n",
      "epoch:27 step:26088 [D loss: 0.570072, acc.: 72.66%] [G loss: 0.883463]\n",
      "epoch:27 step:26089 [D loss: 0.538733, acc.: 68.75%] [G loss: 0.925858]\n",
      "epoch:27 step:26090 [D loss: 0.517768, acc.: 73.44%] [G loss: 0.879589]\n",
      "epoch:27 step:26091 [D loss: 0.422752, acc.: 80.47%] [G loss: 0.904372]\n",
      "epoch:27 step:26092 [D loss: 0.552816, acc.: 72.66%] [G loss: 0.695102]\n",
      "epoch:27 step:26093 [D loss: 0.636435, acc.: 64.06%] [G loss: 0.807546]\n",
      "epoch:27 step:26094 [D loss: 0.504429, acc.: 75.00%] [G loss: 0.834739]\n",
      "epoch:27 step:26095 [D loss: 0.549682, acc.: 66.41%] [G loss: 0.881978]\n",
      "epoch:27 step:26096 [D loss: 0.556197, acc.: 73.44%] [G loss: 0.804781]\n",
      "epoch:27 step:26097 [D loss: 0.552390, acc.: 61.72%] [G loss: 0.895660]\n",
      "epoch:27 step:26098 [D loss: 0.550695, acc.: 73.44%] [G loss: 0.775344]\n",
      "epoch:27 step:26099 [D loss: 0.589528, acc.: 66.41%] [G loss: 0.787270]\n",
      "epoch:27 step:26100 [D loss: 0.454157, acc.: 78.91%] [G loss: 0.787623]\n",
      "epoch:27 step:26101 [D loss: 0.428709, acc.: 78.91%] [G loss: 0.905112]\n",
      "epoch:27 step:26102 [D loss: 0.456520, acc.: 79.69%] [G loss: 1.004384]\n",
      "epoch:27 step:26103 [D loss: 0.500153, acc.: 71.88%] [G loss: 0.800912]\n",
      "epoch:27 step:26104 [D loss: 0.505896, acc.: 73.44%] [G loss: 0.698898]\n",
      "epoch:27 step:26105 [D loss: 0.569941, acc.: 70.31%] [G loss: 0.562613]\n",
      "epoch:27 step:26106 [D loss: 0.472633, acc.: 78.91%] [G loss: 0.666021]\n",
      "epoch:27 step:26107 [D loss: 0.507458, acc.: 70.31%] [G loss: 0.586711]\n",
      "epoch:27 step:26108 [D loss: 0.546221, acc.: 68.75%] [G loss: 0.683129]\n",
      "epoch:27 step:26109 [D loss: 0.498342, acc.: 73.44%] [G loss: 0.649040]\n",
      "epoch:27 step:26110 [D loss: 0.577646, acc.: 66.41%] [G loss: 0.782306]\n",
      "epoch:27 step:26111 [D loss: 0.661919, acc.: 64.06%] [G loss: 0.484871]\n",
      "epoch:27 step:26112 [D loss: 0.532507, acc.: 75.00%] [G loss: 0.520285]\n",
      "epoch:27 step:26113 [D loss: 0.477743, acc.: 81.25%] [G loss: 0.821856]\n",
      "epoch:27 step:26114 [D loss: 0.452072, acc.: 78.12%] [G loss: 0.983932]\n",
      "epoch:27 step:26115 [D loss: 0.507800, acc.: 75.78%] [G loss: 0.903085]\n",
      "epoch:27 step:26116 [D loss: 0.623438, acc.: 67.19%] [G loss: 0.851431]\n",
      "epoch:27 step:26117 [D loss: 0.561015, acc.: 70.31%] [G loss: 0.832326]\n",
      "epoch:27 step:26118 [D loss: 0.484782, acc.: 73.44%] [G loss: 0.721489]\n",
      "epoch:27 step:26119 [D loss: 0.551898, acc.: 71.09%] [G loss: 0.672374]\n",
      "epoch:27 step:26120 [D loss: 0.540867, acc.: 68.75%] [G loss: 0.630163]\n",
      "epoch:27 step:26121 [D loss: 0.558065, acc.: 71.09%] [G loss: 0.606193]\n",
      "epoch:27 step:26122 [D loss: 0.452183, acc.: 76.56%] [G loss: 0.696968]\n",
      "epoch:27 step:26123 [D loss: 0.557256, acc.: 74.22%] [G loss: 0.679827]\n",
      "epoch:27 step:26124 [D loss: 0.500881, acc.: 76.56%] [G loss: 0.767663]\n",
      "epoch:27 step:26125 [D loss: 0.524257, acc.: 77.34%] [G loss: 0.737994]\n",
      "epoch:27 step:26126 [D loss: 0.533024, acc.: 67.97%] [G loss: 0.647623]\n",
      "epoch:27 step:26127 [D loss: 0.673870, acc.: 61.72%] [G loss: 0.673596]\n",
      "epoch:27 step:26128 [D loss: 0.513211, acc.: 69.53%] [G loss: 0.701220]\n",
      "epoch:27 step:26129 [D loss: 0.470476, acc.: 76.56%] [G loss: 0.681574]\n",
      "epoch:27 step:26130 [D loss: 0.549329, acc.: 69.53%] [G loss: 0.711853]\n",
      "epoch:27 step:26131 [D loss: 0.516214, acc.: 70.31%] [G loss: 0.802021]\n",
      "epoch:27 step:26132 [D loss: 0.536420, acc.: 71.09%] [G loss: 0.540409]\n",
      "epoch:27 step:26133 [D loss: 0.502200, acc.: 71.88%] [G loss: 0.677296]\n",
      "epoch:27 step:26134 [D loss: 0.487681, acc.: 72.66%] [G loss: 0.671996]\n",
      "epoch:27 step:26135 [D loss: 0.509498, acc.: 74.22%] [G loss: 0.620645]\n",
      "epoch:27 step:26136 [D loss: 0.516537, acc.: 71.09%] [G loss: 0.705734]\n",
      "epoch:27 step:26137 [D loss: 0.479037, acc.: 78.91%] [G loss: 0.660545]\n",
      "epoch:27 step:26138 [D loss: 0.552834, acc.: 69.53%] [G loss: 0.584812]\n",
      "epoch:27 step:26139 [D loss: 0.515213, acc.: 75.78%] [G loss: 0.700205]\n",
      "epoch:27 step:26140 [D loss: 0.522028, acc.: 72.66%] [G loss: 0.622647]\n",
      "epoch:27 step:26141 [D loss: 0.491561, acc.: 74.22%] [G loss: 0.689901]\n",
      "epoch:27 step:26142 [D loss: 0.478323, acc.: 76.56%] [G loss: 0.819669]\n",
      "epoch:27 step:26143 [D loss: 0.505082, acc.: 74.22%] [G loss: 0.703220]\n",
      "epoch:27 step:26144 [D loss: 0.578933, acc.: 67.97%] [G loss: 0.572161]\n",
      "epoch:27 step:26145 [D loss: 0.551359, acc.: 67.97%] [G loss: 0.637820]\n",
      "epoch:27 step:26146 [D loss: 0.582557, acc.: 64.84%] [G loss: 0.540890]\n",
      "epoch:27 step:26147 [D loss: 0.527633, acc.: 70.31%] [G loss: 0.593638]\n",
      "epoch:27 step:26148 [D loss: 0.492585, acc.: 75.00%] [G loss: 0.675959]\n",
      "epoch:27 step:26149 [D loss: 0.574224, acc.: 71.09%] [G loss: 0.653674]\n",
      "epoch:27 step:26150 [D loss: 0.554060, acc.: 70.31%] [G loss: 0.649584]\n",
      "epoch:27 step:26151 [D loss: 0.533114, acc.: 75.78%] [G loss: 0.630911]\n",
      "epoch:27 step:26152 [D loss: 0.544183, acc.: 67.19%] [G loss: 0.800245]\n",
      "epoch:27 step:26153 [D loss: 0.473508, acc.: 75.78%] [G loss: 0.777296]\n",
      "epoch:27 step:26154 [D loss: 0.567382, acc.: 71.09%] [G loss: 0.743740]\n",
      "epoch:27 step:26155 [D loss: 0.544667, acc.: 74.22%] [G loss: 0.654168]\n",
      "epoch:27 step:26156 [D loss: 0.457347, acc.: 75.78%] [G loss: 0.840221]\n",
      "epoch:27 step:26157 [D loss: 0.578808, acc.: 69.53%] [G loss: 0.677226]\n",
      "epoch:27 step:26158 [D loss: 0.475973, acc.: 79.69%] [G loss: 0.627284]\n",
      "epoch:27 step:26159 [D loss: 0.421109, acc.: 82.03%] [G loss: 1.006400]\n",
      "epoch:27 step:26160 [D loss: 0.617796, acc.: 62.50%] [G loss: 0.814263]\n",
      "epoch:27 step:26161 [D loss: 0.575878, acc.: 66.41%] [G loss: 0.590471]\n",
      "epoch:27 step:26162 [D loss: 0.522298, acc.: 71.09%] [G loss: 0.604200]\n",
      "epoch:27 step:26163 [D loss: 0.526600, acc.: 66.41%] [G loss: 0.674052]\n",
      "epoch:27 step:26164 [D loss: 0.559045, acc.: 70.31%] [G loss: 0.481684]\n",
      "epoch:27 step:26165 [D loss: 0.539361, acc.: 68.75%] [G loss: 0.623833]\n",
      "epoch:27 step:26166 [D loss: 0.640153, acc.: 57.81%] [G loss: 0.485768]\n",
      "epoch:27 step:26167 [D loss: 0.559116, acc.: 66.41%] [G loss: 0.523343]\n",
      "epoch:27 step:26168 [D loss: 0.515754, acc.: 69.53%] [G loss: 0.628124]\n",
      "epoch:27 step:26169 [D loss: 0.452912, acc.: 75.00%] [G loss: 0.575981]\n",
      "epoch:27 step:26170 [D loss: 0.496172, acc.: 73.44%] [G loss: 0.819190]\n",
      "epoch:27 step:26171 [D loss: 0.513999, acc.: 70.31%] [G loss: 0.817327]\n",
      "epoch:27 step:26172 [D loss: 0.600607, acc.: 62.50%] [G loss: 0.751680]\n",
      "epoch:27 step:26173 [D loss: 0.533738, acc.: 69.53%] [G loss: 0.697965]\n",
      "epoch:27 step:26174 [D loss: 0.459766, acc.: 77.34%] [G loss: 0.820897]\n",
      "epoch:27 step:26175 [D loss: 0.575423, acc.: 68.75%] [G loss: 0.610123]\n",
      "epoch:27 step:26176 [D loss: 0.584951, acc.: 64.06%] [G loss: 0.560334]\n",
      "epoch:27 step:26177 [D loss: 0.500631, acc.: 75.00%] [G loss: 0.574420]\n",
      "epoch:27 step:26178 [D loss: 0.539892, acc.: 69.53%] [G loss: 0.677422]\n",
      "epoch:27 step:26179 [D loss: 0.643818, acc.: 57.81%] [G loss: 0.604200]\n",
      "epoch:27 step:26180 [D loss: 0.550680, acc.: 67.19%] [G loss: 0.608936]\n",
      "epoch:27 step:26181 [D loss: 0.566748, acc.: 65.62%] [G loss: 0.656384]\n",
      "epoch:27 step:26182 [D loss: 0.601267, acc.: 64.84%] [G loss: 0.654414]\n",
      "epoch:27 step:26183 [D loss: 0.501606, acc.: 72.66%] [G loss: 0.742814]\n",
      "epoch:27 step:26184 [D loss: 0.451164, acc.: 78.91%] [G loss: 0.834811]\n",
      "epoch:27 step:26185 [D loss: 0.547050, acc.: 69.53%] [G loss: 0.929109]\n",
      "epoch:27 step:26186 [D loss: 0.541023, acc.: 75.00%] [G loss: 0.831059]\n",
      "epoch:27 step:26187 [D loss: 0.514390, acc.: 71.88%] [G loss: 0.705470]\n",
      "epoch:27 step:26188 [D loss: 0.544704, acc.: 67.97%] [G loss: 0.680877]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:27 step:26189 [D loss: 0.448788, acc.: 75.78%] [G loss: 0.814463]\n",
      "epoch:27 step:26190 [D loss: 0.599354, acc.: 65.62%] [G loss: 0.717529]\n",
      "epoch:27 step:26191 [D loss: 0.591799, acc.: 67.97%] [G loss: 0.726247]\n",
      "epoch:27 step:26192 [D loss: 0.529662, acc.: 74.22%] [G loss: 0.595680]\n",
      "epoch:27 step:26193 [D loss: 0.459683, acc.: 75.78%] [G loss: 0.772463]\n",
      "epoch:27 step:26194 [D loss: 0.500237, acc.: 77.34%] [G loss: 0.740680]\n",
      "epoch:27 step:26195 [D loss: 0.481421, acc.: 77.34%] [G loss: 0.849080]\n",
      "epoch:27 step:26196 [D loss: 0.472532, acc.: 79.69%] [G loss: 0.683286]\n",
      "epoch:27 step:26197 [D loss: 0.409755, acc.: 85.16%] [G loss: 0.917143]\n",
      "epoch:27 step:26198 [D loss: 0.432832, acc.: 81.25%] [G loss: 1.002756]\n",
      "epoch:27 step:26199 [D loss: 0.492680, acc.: 75.78%] [G loss: 0.935736]\n",
      "epoch:27 step:26200 [D loss: 0.509264, acc.: 75.78%] [G loss: 0.850864]\n",
      "epoch:27 step:26201 [D loss: 0.628468, acc.: 63.28%] [G loss: 0.805420]\n",
      "epoch:27 step:26202 [D loss: 0.536224, acc.: 71.88%] [G loss: 0.793152]\n",
      "epoch:27 step:26203 [D loss: 0.577914, acc.: 69.53%] [G loss: 0.650906]\n",
      "epoch:27 step:26204 [D loss: 0.542426, acc.: 75.78%] [G loss: 0.716126]\n",
      "epoch:27 step:26205 [D loss: 0.469189, acc.: 78.12%] [G loss: 0.681301]\n",
      "epoch:27 step:26206 [D loss: 0.540260, acc.: 67.97%] [G loss: 0.731970]\n",
      "epoch:27 step:26207 [D loss: 0.509568, acc.: 72.66%] [G loss: 0.794076]\n",
      "epoch:27 step:26208 [D loss: 0.489131, acc.: 75.78%] [G loss: 0.723022]\n",
      "epoch:27 step:26209 [D loss: 0.541242, acc.: 70.31%] [G loss: 0.895423]\n",
      "epoch:27 step:26210 [D loss: 0.460833, acc.: 77.34%] [G loss: 0.828096]\n",
      "epoch:27 step:26211 [D loss: 0.472750, acc.: 75.00%] [G loss: 0.847125]\n",
      "epoch:27 step:26212 [D loss: 0.494922, acc.: 75.00%] [G loss: 0.988718]\n",
      "epoch:27 step:26213 [D loss: 0.438015, acc.: 78.12%] [G loss: 0.984187]\n",
      "epoch:27 step:26214 [D loss: 0.674150, acc.: 63.28%] [G loss: 0.834103]\n",
      "epoch:27 step:26215 [D loss: 0.464637, acc.: 78.91%] [G loss: 0.860932]\n",
      "epoch:27 step:26216 [D loss: 0.543153, acc.: 71.09%] [G loss: 0.905661]\n",
      "epoch:27 step:26217 [D loss: 0.501447, acc.: 77.34%] [G loss: 0.737008]\n",
      "epoch:27 step:26218 [D loss: 0.393054, acc.: 85.16%] [G loss: 0.997383]\n",
      "epoch:27 step:26219 [D loss: 0.657881, acc.: 59.38%] [G loss: 0.672542]\n",
      "epoch:27 step:26220 [D loss: 0.409252, acc.: 83.59%] [G loss: 0.767709]\n",
      "epoch:27 step:26221 [D loss: 0.448401, acc.: 76.56%] [G loss: 1.007805]\n",
      "epoch:27 step:26222 [D loss: 0.436267, acc.: 80.47%] [G loss: 1.036517]\n",
      "epoch:27 step:26223 [D loss: 0.500134, acc.: 70.31%] [G loss: 0.998701]\n",
      "epoch:27 step:26224 [D loss: 0.425485, acc.: 82.03%] [G loss: 1.292719]\n",
      "epoch:27 step:26225 [D loss: 0.431647, acc.: 78.12%] [G loss: 1.260348]\n",
      "epoch:27 step:26226 [D loss: 0.483327, acc.: 75.78%] [G loss: 1.233723]\n",
      "epoch:27 step:26227 [D loss: 0.678808, acc.: 66.41%] [G loss: 1.302957]\n",
      "epoch:27 step:26228 [D loss: 0.527111, acc.: 72.66%] [G loss: 1.370231]\n",
      "epoch:27 step:26229 [D loss: 0.514447, acc.: 74.22%] [G loss: 1.350856]\n",
      "epoch:27 step:26230 [D loss: 0.532900, acc.: 68.75%] [G loss: 1.049798]\n",
      "epoch:27 step:26231 [D loss: 0.634190, acc.: 60.94%] [G loss: 0.897455]\n",
      "epoch:27 step:26232 [D loss: 0.463490, acc.: 78.91%] [G loss: 0.983395]\n",
      "epoch:27 step:26233 [D loss: 0.511951, acc.: 73.44%] [G loss: 1.005499]\n",
      "epoch:27 step:26234 [D loss: 0.510987, acc.: 73.44%] [G loss: 0.873791]\n",
      "epoch:27 step:26235 [D loss: 0.406991, acc.: 81.25%] [G loss: 1.024524]\n",
      "epoch:27 step:26236 [D loss: 0.443083, acc.: 82.81%] [G loss: 1.192303]\n",
      "epoch:28 step:26237 [D loss: 0.600082, acc.: 67.97%] [G loss: 1.242395]\n",
      "epoch:28 step:26238 [D loss: 0.503526, acc.: 73.44%] [G loss: 1.169600]\n",
      "epoch:28 step:26239 [D loss: 0.566537, acc.: 71.09%] [G loss: 0.910303]\n",
      "epoch:28 step:26240 [D loss: 0.509196, acc.: 73.44%] [G loss: 1.038153]\n",
      "epoch:28 step:26241 [D loss: 0.518151, acc.: 73.44%] [G loss: 0.944686]\n",
      "epoch:28 step:26242 [D loss: 0.588199, acc.: 67.97%] [G loss: 0.836086]\n",
      "epoch:28 step:26243 [D loss: 0.443796, acc.: 81.25%] [G loss: 0.762745]\n",
      "epoch:28 step:26244 [D loss: 0.488239, acc.: 76.56%] [G loss: 0.905984]\n",
      "epoch:28 step:26245 [D loss: 0.503829, acc.: 75.00%] [G loss: 0.869743]\n",
      "epoch:28 step:26246 [D loss: 0.438961, acc.: 81.25%] [G loss: 0.781196]\n",
      "epoch:28 step:26247 [D loss: 0.495413, acc.: 76.56%] [G loss: 0.990167]\n",
      "epoch:28 step:26248 [D loss: 0.526823, acc.: 72.66%] [G loss: 1.010826]\n",
      "epoch:28 step:26249 [D loss: 0.537317, acc.: 71.88%] [G loss: 0.696439]\n",
      "epoch:28 step:26250 [D loss: 0.553365, acc.: 70.31%] [G loss: 0.721028]\n",
      "epoch:28 step:26251 [D loss: 0.485012, acc.: 72.66%] [G loss: 0.749541]\n",
      "epoch:28 step:26252 [D loss: 0.448821, acc.: 77.34%] [G loss: 0.913782]\n",
      "epoch:28 step:26253 [D loss: 0.548321, acc.: 72.66%] [G loss: 0.582879]\n",
      "epoch:28 step:26254 [D loss: 0.558248, acc.: 75.00%] [G loss: 0.753275]\n",
      "epoch:28 step:26255 [D loss: 0.516112, acc.: 74.22%] [G loss: 0.938093]\n",
      "epoch:28 step:26256 [D loss: 0.633966, acc.: 65.62%] [G loss: 0.742163]\n",
      "epoch:28 step:26257 [D loss: 0.570102, acc.: 66.41%] [G loss: 0.799456]\n",
      "epoch:28 step:26258 [D loss: 0.440642, acc.: 79.69%] [G loss: 1.307538]\n",
      "epoch:28 step:26259 [D loss: 0.571294, acc.: 67.97%] [G loss: 0.805036]\n",
      "epoch:28 step:26260 [D loss: 0.551826, acc.: 72.66%] [G loss: 0.716758]\n",
      "epoch:28 step:26261 [D loss: 0.467470, acc.: 76.56%] [G loss: 0.793411]\n",
      "epoch:28 step:26262 [D loss: 0.546610, acc.: 74.22%] [G loss: 0.729397]\n",
      "epoch:28 step:26263 [D loss: 0.475871, acc.: 73.44%] [G loss: 0.749547]\n",
      "epoch:28 step:26264 [D loss: 0.543260, acc.: 66.41%] [G loss: 0.834853]\n",
      "epoch:28 step:26265 [D loss: 0.475311, acc.: 77.34%] [G loss: 0.708619]\n",
      "epoch:28 step:26266 [D loss: 0.506446, acc.: 71.09%] [G loss: 0.714216]\n",
      "epoch:28 step:26267 [D loss: 0.630624, acc.: 65.62%] [G loss: 0.639367]\n",
      "epoch:28 step:26268 [D loss: 0.520639, acc.: 72.66%] [G loss: 0.856831]\n",
      "epoch:28 step:26269 [D loss: 0.491642, acc.: 77.34%] [G loss: 0.605636]\n",
      "epoch:28 step:26270 [D loss: 0.533282, acc.: 68.75%] [G loss: 0.645372]\n",
      "epoch:28 step:26271 [D loss: 0.523721, acc.: 72.66%] [G loss: 0.660156]\n",
      "epoch:28 step:26272 [D loss: 0.507748, acc.: 69.53%] [G loss: 0.596498]\n",
      "epoch:28 step:26273 [D loss: 0.463973, acc.: 74.22%] [G loss: 0.683580]\n",
      "epoch:28 step:26274 [D loss: 0.536238, acc.: 71.09%] [G loss: 0.757324]\n",
      "epoch:28 step:26275 [D loss: 0.532214, acc.: 71.88%] [G loss: 0.715262]\n",
      "epoch:28 step:26276 [D loss: 0.472332, acc.: 78.12%] [G loss: 0.739190]\n",
      "epoch:28 step:26277 [D loss: 0.518909, acc.: 74.22%] [G loss: 0.864984]\n",
      "epoch:28 step:26278 [D loss: 0.563980, acc.: 70.31%] [G loss: 0.585573]\n",
      "epoch:28 step:26279 [D loss: 0.522907, acc.: 70.31%] [G loss: 0.644894]\n",
      "epoch:28 step:26280 [D loss: 0.565096, acc.: 69.53%] [G loss: 0.643394]\n",
      "epoch:28 step:26281 [D loss: 0.450452, acc.: 82.03%] [G loss: 0.751539]\n",
      "epoch:28 step:26282 [D loss: 0.508728, acc.: 72.66%] [G loss: 0.910182]\n",
      "epoch:28 step:26283 [D loss: 0.523336, acc.: 71.09%] [G loss: 0.817884]\n",
      "epoch:28 step:26284 [D loss: 0.523292, acc.: 72.66%] [G loss: 0.572188]\n",
      "epoch:28 step:26285 [D loss: 0.480171, acc.: 72.66%] [G loss: 0.948860]\n",
      "epoch:28 step:26286 [D loss: 0.561244, acc.: 72.66%] [G loss: 0.904209]\n",
      "epoch:28 step:26287 [D loss: 0.614845, acc.: 66.41%] [G loss: 0.590589]\n",
      "epoch:28 step:26288 [D loss: 0.561172, acc.: 67.19%] [G loss: 0.742105]\n",
      "epoch:28 step:26289 [D loss: 0.475805, acc.: 73.44%] [G loss: 0.826058]\n",
      "epoch:28 step:26290 [D loss: 0.454945, acc.: 79.69%] [G loss: 0.901034]\n",
      "epoch:28 step:26291 [D loss: 0.544665, acc.: 75.78%] [G loss: 0.904977]\n",
      "epoch:28 step:26292 [D loss: 0.490140, acc.: 77.34%] [G loss: 0.967628]\n",
      "epoch:28 step:26293 [D loss: 0.550681, acc.: 71.09%] [G loss: 0.815294]\n",
      "epoch:28 step:26294 [D loss: 0.560106, acc.: 72.66%] [G loss: 0.821333]\n",
      "epoch:28 step:26295 [D loss: 0.515521, acc.: 70.31%] [G loss: 0.744547]\n",
      "epoch:28 step:26296 [D loss: 0.546782, acc.: 69.53%] [G loss: 0.770899]\n",
      "epoch:28 step:26297 [D loss: 0.498734, acc.: 76.56%] [G loss: 0.659255]\n",
      "epoch:28 step:26298 [D loss: 0.544724, acc.: 75.00%] [G loss: 0.585961]\n",
      "epoch:28 step:26299 [D loss: 0.520484, acc.: 71.88%] [G loss: 0.781416]\n",
      "epoch:28 step:26300 [D loss: 0.575865, acc.: 70.31%] [G loss: 0.639686]\n",
      "epoch:28 step:26301 [D loss: 0.462906, acc.: 80.47%] [G loss: 0.847499]\n",
      "epoch:28 step:26302 [D loss: 0.510397, acc.: 74.22%] [G loss: 0.796597]\n",
      "epoch:28 step:26303 [D loss: 0.544212, acc.: 73.44%] [G loss: 0.576345]\n",
      "epoch:28 step:26304 [D loss: 0.497575, acc.: 74.22%] [G loss: 0.755746]\n",
      "epoch:28 step:26305 [D loss: 0.443778, acc.: 78.91%] [G loss: 0.677533]\n",
      "epoch:28 step:26306 [D loss: 0.508117, acc.: 75.78%] [G loss: 0.614355]\n",
      "epoch:28 step:26307 [D loss: 0.485979, acc.: 72.66%] [G loss: 0.717064]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:28 step:26308 [D loss: 0.503923, acc.: 74.22%] [G loss: 0.747785]\n",
      "epoch:28 step:26309 [D loss: 0.585289, acc.: 68.75%] [G loss: 0.634916]\n",
      "epoch:28 step:26310 [D loss: 0.464383, acc.: 75.00%] [G loss: 0.844996]\n",
      "epoch:28 step:26311 [D loss: 0.508312, acc.: 71.09%] [G loss: 0.875339]\n",
      "epoch:28 step:26312 [D loss: 0.514762, acc.: 75.00%] [G loss: 0.906916]\n",
      "epoch:28 step:26313 [D loss: 0.413361, acc.: 80.47%] [G loss: 0.796318]\n",
      "epoch:28 step:26314 [D loss: 0.529414, acc.: 71.09%] [G loss: 0.810307]\n",
      "epoch:28 step:26315 [D loss: 0.544687, acc.: 71.88%] [G loss: 0.778358]\n",
      "epoch:28 step:26316 [D loss: 0.513388, acc.: 74.22%] [G loss: 0.755799]\n",
      "epoch:28 step:26317 [D loss: 0.560210, acc.: 71.88%] [G loss: 0.804154]\n",
      "epoch:28 step:26318 [D loss: 0.518010, acc.: 75.78%] [G loss: 0.975678]\n",
      "epoch:28 step:26319 [D loss: 0.431978, acc.: 81.25%] [G loss: 0.748052]\n",
      "epoch:28 step:26320 [D loss: 0.499190, acc.: 70.31%] [G loss: 0.773144]\n",
      "epoch:28 step:26321 [D loss: 0.590478, acc.: 65.62%] [G loss: 0.632992]\n",
      "epoch:28 step:26322 [D loss: 0.470527, acc.: 76.56%] [G loss: 0.666264]\n",
      "epoch:28 step:26323 [D loss: 0.501656, acc.: 76.56%] [G loss: 0.760742]\n",
      "epoch:28 step:26324 [D loss: 0.496389, acc.: 75.78%] [G loss: 0.896178]\n",
      "epoch:28 step:26325 [D loss: 0.461860, acc.: 76.56%] [G loss: 0.955441]\n",
      "epoch:28 step:26326 [D loss: 0.472015, acc.: 77.34%] [G loss: 0.904030]\n",
      "epoch:28 step:26327 [D loss: 0.562383, acc.: 67.19%] [G loss: 0.851052]\n",
      "epoch:28 step:26328 [D loss: 0.481925, acc.: 73.44%] [G loss: 0.912326]\n",
      "epoch:28 step:26329 [D loss: 0.510022, acc.: 75.78%] [G loss: 0.992380]\n",
      "epoch:28 step:26330 [D loss: 0.468315, acc.: 75.00%] [G loss: 0.974092]\n",
      "epoch:28 step:26331 [D loss: 0.519174, acc.: 73.44%] [G loss: 0.838867]\n",
      "epoch:28 step:26332 [D loss: 0.534264, acc.: 71.09%] [G loss: 0.826451]\n",
      "epoch:28 step:26333 [D loss: 0.516959, acc.: 75.00%] [G loss: 0.916028]\n",
      "epoch:28 step:26334 [D loss: 0.530191, acc.: 67.97%] [G loss: 1.026187]\n",
      "epoch:28 step:26335 [D loss: 0.560098, acc.: 68.75%] [G loss: 0.893057]\n",
      "epoch:28 step:26336 [D loss: 0.393777, acc.: 83.59%] [G loss: 0.834701]\n",
      "epoch:28 step:26337 [D loss: 0.479989, acc.: 73.44%] [G loss: 0.982789]\n",
      "epoch:28 step:26338 [D loss: 0.630921, acc.: 65.62%] [G loss: 0.918348]\n",
      "epoch:28 step:26339 [D loss: 0.536790, acc.: 69.53%] [G loss: 0.708745]\n",
      "epoch:28 step:26340 [D loss: 0.478691, acc.: 77.34%] [G loss: 0.752616]\n",
      "epoch:28 step:26341 [D loss: 0.561832, acc.: 67.97%] [G loss: 0.789118]\n",
      "epoch:28 step:26342 [D loss: 0.518998, acc.: 73.44%] [G loss: 0.725151]\n",
      "epoch:28 step:26343 [D loss: 0.553827, acc.: 71.88%] [G loss: 0.718701]\n",
      "epoch:28 step:26344 [D loss: 0.615210, acc.: 68.75%] [G loss: 0.677134]\n",
      "epoch:28 step:26345 [D loss: 0.504411, acc.: 73.44%] [G loss: 0.684943]\n",
      "epoch:28 step:26346 [D loss: 0.582741, acc.: 64.06%] [G loss: 0.729689]\n",
      "epoch:28 step:26347 [D loss: 0.510665, acc.: 72.66%] [G loss: 0.663767]\n",
      "epoch:28 step:26348 [D loss: 0.499016, acc.: 75.78%] [G loss: 0.777253]\n",
      "epoch:28 step:26349 [D loss: 0.566537, acc.: 70.31%] [G loss: 0.730231]\n",
      "epoch:28 step:26350 [D loss: 0.547520, acc.: 68.75%] [G loss: 0.858761]\n",
      "epoch:28 step:26351 [D loss: 0.546195, acc.: 73.44%] [G loss: 0.923653]\n",
      "epoch:28 step:26352 [D loss: 0.489070, acc.: 71.88%] [G loss: 0.882542]\n",
      "epoch:28 step:26353 [D loss: 0.501241, acc.: 75.78%] [G loss: 0.794079]\n",
      "epoch:28 step:26354 [D loss: 0.495280, acc.: 74.22%] [G loss: 0.893437]\n",
      "epoch:28 step:26355 [D loss: 0.500152, acc.: 72.66%] [G loss: 0.927389]\n",
      "epoch:28 step:26356 [D loss: 0.518464, acc.: 76.56%] [G loss: 1.070899]\n",
      "epoch:28 step:26357 [D loss: 0.561546, acc.: 72.66%] [G loss: 0.771796]\n",
      "epoch:28 step:26358 [D loss: 0.445446, acc.: 80.47%] [G loss: 0.937929]\n",
      "epoch:28 step:26359 [D loss: 0.558664, acc.: 67.19%] [G loss: 0.887774]\n",
      "epoch:28 step:26360 [D loss: 0.578221, acc.: 71.88%] [G loss: 0.786679]\n",
      "epoch:28 step:26361 [D loss: 0.574373, acc.: 66.41%] [G loss: 0.787797]\n",
      "epoch:28 step:26362 [D loss: 0.484739, acc.: 74.22%] [G loss: 0.701710]\n",
      "epoch:28 step:26363 [D loss: 0.457772, acc.: 77.34%] [G loss: 0.856439]\n",
      "epoch:28 step:26364 [D loss: 0.476360, acc.: 73.44%] [G loss: 0.797112]\n",
      "epoch:28 step:26365 [D loss: 0.557243, acc.: 67.19%] [G loss: 0.631278]\n",
      "epoch:28 step:26366 [D loss: 0.433152, acc.: 79.69%] [G loss: 0.872808]\n",
      "epoch:28 step:26367 [D loss: 0.482534, acc.: 77.34%] [G loss: 0.810554]\n",
      "epoch:28 step:26368 [D loss: 0.582140, acc.: 70.31%] [G loss: 1.007179]\n",
      "epoch:28 step:26369 [D loss: 0.519740, acc.: 70.31%] [G loss: 0.731705]\n",
      "epoch:28 step:26370 [D loss: 0.518232, acc.: 72.66%] [G loss: 0.826041]\n",
      "epoch:28 step:26371 [D loss: 0.577715, acc.: 68.75%] [G loss: 0.818751]\n",
      "epoch:28 step:26372 [D loss: 0.464931, acc.: 77.34%] [G loss: 0.907581]\n",
      "epoch:28 step:26373 [D loss: 0.596142, acc.: 67.97%] [G loss: 0.588047]\n",
      "epoch:28 step:26374 [D loss: 0.570117, acc.: 70.31%] [G loss: 0.622222]\n",
      "epoch:28 step:26375 [D loss: 0.482647, acc.: 75.78%] [G loss: 0.740581]\n",
      "epoch:28 step:26376 [D loss: 0.572454, acc.: 70.31%] [G loss: 0.667872]\n",
      "epoch:28 step:26377 [D loss: 0.532287, acc.: 70.31%] [G loss: 0.624243]\n",
      "epoch:28 step:26378 [D loss: 0.530658, acc.: 67.97%] [G loss: 0.757169]\n",
      "epoch:28 step:26379 [D loss: 0.553877, acc.: 69.53%] [G loss: 0.578535]\n",
      "epoch:28 step:26380 [D loss: 0.487893, acc.: 78.12%] [G loss: 0.782462]\n",
      "epoch:28 step:26381 [D loss: 0.552909, acc.: 68.75%] [G loss: 0.924734]\n",
      "epoch:28 step:26382 [D loss: 0.468315, acc.: 78.12%] [G loss: 0.932737]\n",
      "epoch:28 step:26383 [D loss: 0.614356, acc.: 67.19%] [G loss: 0.649958]\n",
      "epoch:28 step:26384 [D loss: 0.619144, acc.: 64.84%] [G loss: 0.586766]\n",
      "epoch:28 step:26385 [D loss: 0.477113, acc.: 75.00%] [G loss: 0.602686]\n",
      "epoch:28 step:26386 [D loss: 0.545811, acc.: 69.53%] [G loss: 0.668025]\n",
      "epoch:28 step:26387 [D loss: 0.481116, acc.: 77.34%] [G loss: 0.674056]\n",
      "epoch:28 step:26388 [D loss: 0.465640, acc.: 75.78%] [G loss: 0.820674]\n",
      "epoch:28 step:26389 [D loss: 0.556054, acc.: 70.31%] [G loss: 0.628683]\n",
      "epoch:28 step:26390 [D loss: 0.527751, acc.: 70.31%] [G loss: 0.691837]\n",
      "epoch:28 step:26391 [D loss: 0.494554, acc.: 75.00%] [G loss: 0.787390]\n",
      "epoch:28 step:26392 [D loss: 0.455806, acc.: 78.12%] [G loss: 0.886875]\n",
      "epoch:28 step:26393 [D loss: 0.531896, acc.: 71.09%] [G loss: 0.712685]\n",
      "epoch:28 step:26394 [D loss: 0.549553, acc.: 75.00%] [G loss: 0.811530]\n",
      "epoch:28 step:26395 [D loss: 0.459119, acc.: 75.78%] [G loss: 0.745811]\n",
      "epoch:28 step:26396 [D loss: 0.561449, acc.: 70.31%] [G loss: 0.946832]\n",
      "epoch:28 step:26397 [D loss: 0.544574, acc.: 67.97%] [G loss: 0.881852]\n",
      "epoch:28 step:26398 [D loss: 0.477181, acc.: 76.56%] [G loss: 1.167735]\n",
      "epoch:28 step:26399 [D loss: 0.561133, acc.: 75.00%] [G loss: 0.814328]\n",
      "epoch:28 step:26400 [D loss: 0.508963, acc.: 67.19%] [G loss: 0.718039]\n",
      "epoch:28 step:26401 [D loss: 0.479120, acc.: 77.34%] [G loss: 0.806616]\n",
      "epoch:28 step:26402 [D loss: 0.522309, acc.: 71.88%] [G loss: 0.654583]\n",
      "epoch:28 step:26403 [D loss: 0.568788, acc.: 71.88%] [G loss: 0.589328]\n",
      "epoch:28 step:26404 [D loss: 0.585706, acc.: 68.75%] [G loss: 0.689876]\n",
      "epoch:28 step:26405 [D loss: 0.550373, acc.: 73.44%] [G loss: 0.661760]\n",
      "epoch:28 step:26406 [D loss: 0.543489, acc.: 70.31%] [G loss: 0.692148]\n",
      "epoch:28 step:26407 [D loss: 0.498211, acc.: 72.66%] [G loss: 0.692782]\n",
      "epoch:28 step:26408 [D loss: 0.522189, acc.: 73.44%] [G loss: 0.738786]\n",
      "epoch:28 step:26409 [D loss: 0.440019, acc.: 78.91%] [G loss: 0.789576]\n",
      "epoch:28 step:26410 [D loss: 0.545124, acc.: 67.19%] [G loss: 0.696103]\n",
      "epoch:28 step:26411 [D loss: 0.611450, acc.: 62.50%] [G loss: 0.622481]\n",
      "epoch:28 step:26412 [D loss: 0.482393, acc.: 77.34%] [G loss: 0.557956]\n",
      "epoch:28 step:26413 [D loss: 0.470004, acc.: 79.69%] [G loss: 0.715279]\n",
      "epoch:28 step:26414 [D loss: 0.612345, acc.: 69.53%] [G loss: 0.604326]\n",
      "epoch:28 step:26415 [D loss: 0.592178, acc.: 60.16%] [G loss: 0.536642]\n",
      "epoch:28 step:26416 [D loss: 0.589058, acc.: 64.84%] [G loss: 0.614361]\n",
      "epoch:28 step:26417 [D loss: 0.517429, acc.: 71.09%] [G loss: 0.694889]\n",
      "epoch:28 step:26418 [D loss: 0.540821, acc.: 72.66%] [G loss: 0.937503]\n",
      "epoch:28 step:26419 [D loss: 0.511302, acc.: 71.09%] [G loss: 0.896878]\n",
      "epoch:28 step:26420 [D loss: 0.524039, acc.: 72.66%] [G loss: 0.721901]\n",
      "epoch:28 step:26421 [D loss: 0.570481, acc.: 67.19%] [G loss: 0.869922]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:28 step:26422 [D loss: 0.516428, acc.: 71.88%] [G loss: 0.674751]\n",
      "epoch:28 step:26423 [D loss: 0.656720, acc.: 64.84%] [G loss: 0.781378]\n",
      "epoch:28 step:26424 [D loss: 0.484816, acc.: 74.22%] [G loss: 0.655543]\n",
      "epoch:28 step:26425 [D loss: 0.554041, acc.: 68.75%] [G loss: 0.602180]\n",
      "epoch:28 step:26426 [D loss: 0.467116, acc.: 77.34%] [G loss: 0.806601]\n",
      "epoch:28 step:26427 [D loss: 0.484716, acc.: 76.56%] [G loss: 0.836900]\n",
      "epoch:28 step:26428 [D loss: 0.535719, acc.: 71.09%] [G loss: 0.677799]\n",
      "epoch:28 step:26429 [D loss: 0.535974, acc.: 71.88%] [G loss: 0.629549]\n",
      "epoch:28 step:26430 [D loss: 0.435576, acc.: 82.81%] [G loss: 0.796215]\n",
      "epoch:28 step:26431 [D loss: 0.525129, acc.: 75.00%] [G loss: 0.885343]\n",
      "epoch:28 step:26432 [D loss: 0.575286, acc.: 67.19%] [G loss: 0.644090]\n",
      "epoch:28 step:26433 [D loss: 0.490697, acc.: 71.88%] [G loss: 0.773725]\n",
      "epoch:28 step:26434 [D loss: 0.460461, acc.: 76.56%] [G loss: 0.781609]\n",
      "epoch:28 step:26435 [D loss: 0.483322, acc.: 81.25%] [G loss: 0.768999]\n",
      "epoch:28 step:26436 [D loss: 0.618418, acc.: 62.50%] [G loss: 0.650566]\n",
      "epoch:28 step:26437 [D loss: 0.536241, acc.: 67.97%] [G loss: 0.688414]\n",
      "epoch:28 step:26438 [D loss: 0.569800, acc.: 69.53%] [G loss: 0.790191]\n",
      "epoch:28 step:26439 [D loss: 0.593591, acc.: 65.62%] [G loss: 0.727808]\n",
      "epoch:28 step:26440 [D loss: 0.515360, acc.: 73.44%] [G loss: 0.822572]\n",
      "epoch:28 step:26441 [D loss: 0.464535, acc.: 75.00%] [G loss: 0.894852]\n",
      "epoch:28 step:26442 [D loss: 0.455071, acc.: 78.12%] [G loss: 0.923061]\n",
      "epoch:28 step:26443 [D loss: 0.465276, acc.: 78.12%] [G loss: 0.815307]\n",
      "epoch:28 step:26444 [D loss: 0.449098, acc.: 79.69%] [G loss: 0.938379]\n",
      "epoch:28 step:26445 [D loss: 0.474715, acc.: 72.66%] [G loss: 0.967504]\n",
      "epoch:28 step:26446 [D loss: 0.647132, acc.: 64.06%] [G loss: 0.666601]\n",
      "epoch:28 step:26447 [D loss: 0.534807, acc.: 71.09%] [G loss: 0.543822]\n",
      "epoch:28 step:26448 [D loss: 0.545215, acc.: 68.75%] [G loss: 0.551416]\n",
      "epoch:28 step:26449 [D loss: 0.493093, acc.: 81.25%] [G loss: 0.694807]\n",
      "epoch:28 step:26450 [D loss: 0.645404, acc.: 60.16%] [G loss: 0.644449]\n",
      "epoch:28 step:26451 [D loss: 0.537134, acc.: 68.75%] [G loss: 0.816774]\n",
      "epoch:28 step:26452 [D loss: 0.514729, acc.: 76.56%] [G loss: 0.775594]\n",
      "epoch:28 step:26453 [D loss: 0.520829, acc.: 74.22%] [G loss: 0.691829]\n",
      "epoch:28 step:26454 [D loss: 0.479716, acc.: 75.00%] [G loss: 0.955777]\n",
      "epoch:28 step:26455 [D loss: 0.452943, acc.: 76.56%] [G loss: 0.878560]\n",
      "epoch:28 step:26456 [D loss: 0.683505, acc.: 67.19%] [G loss: 0.748506]\n",
      "epoch:28 step:26457 [D loss: 0.570804, acc.: 71.09%] [G loss: 0.713674]\n",
      "epoch:28 step:26458 [D loss: 0.459234, acc.: 76.56%] [G loss: 0.913483]\n",
      "epoch:28 step:26459 [D loss: 0.500842, acc.: 74.22%] [G loss: 1.006083]\n",
      "epoch:28 step:26460 [D loss: 0.487101, acc.: 69.53%] [G loss: 0.842517]\n",
      "epoch:28 step:26461 [D loss: 0.516419, acc.: 75.78%] [G loss: 0.641411]\n",
      "epoch:28 step:26462 [D loss: 0.581390, acc.: 67.97%] [G loss: 0.770371]\n",
      "epoch:28 step:26463 [D loss: 0.547739, acc.: 68.75%] [G loss: 0.654191]\n",
      "epoch:28 step:26464 [D loss: 0.555764, acc.: 70.31%] [G loss: 0.760192]\n",
      "epoch:28 step:26465 [D loss: 0.533219, acc.: 74.22%] [G loss: 0.741542]\n",
      "epoch:28 step:26466 [D loss: 0.521857, acc.: 71.88%] [G loss: 0.884016]\n",
      "epoch:28 step:26467 [D loss: 0.433490, acc.: 81.25%] [G loss: 0.956613]\n",
      "epoch:28 step:26468 [D loss: 0.357123, acc.: 86.72%] [G loss: 1.363266]\n",
      "epoch:28 step:26469 [D loss: 0.553495, acc.: 71.88%] [G loss: 1.136386]\n",
      "epoch:28 step:26470 [D loss: 0.514910, acc.: 75.78%] [G loss: 0.703635]\n",
      "epoch:28 step:26471 [D loss: 0.580421, acc.: 63.28%] [G loss: 0.784509]\n",
      "epoch:28 step:26472 [D loss: 0.477361, acc.: 77.34%] [G loss: 0.912694]\n",
      "epoch:28 step:26473 [D loss: 0.511896, acc.: 72.66%] [G loss: 0.721137]\n",
      "epoch:28 step:26474 [D loss: 0.582131, acc.: 64.84%] [G loss: 0.557533]\n",
      "epoch:28 step:26475 [D loss: 0.488399, acc.: 75.00%] [G loss: 0.688355]\n",
      "epoch:28 step:26476 [D loss: 0.523790, acc.: 72.66%] [G loss: 0.818640]\n",
      "epoch:28 step:26477 [D loss: 0.519969, acc.: 74.22%] [G loss: 0.696268]\n",
      "epoch:28 step:26478 [D loss: 0.454843, acc.: 75.78%] [G loss: 0.648829]\n",
      "epoch:28 step:26479 [D loss: 0.493231, acc.: 73.44%] [G loss: 0.906760]\n",
      "epoch:28 step:26480 [D loss: 0.489212, acc.: 75.00%] [G loss: 0.884299]\n",
      "epoch:28 step:26481 [D loss: 0.487655, acc.: 73.44%] [G loss: 0.836058]\n",
      "epoch:28 step:26482 [D loss: 0.511783, acc.: 76.56%] [G loss: 0.868072]\n",
      "epoch:28 step:26483 [D loss: 0.522316, acc.: 73.44%] [G loss: 0.928785]\n",
      "epoch:28 step:26484 [D loss: 0.436841, acc.: 79.69%] [G loss: 1.060273]\n",
      "epoch:28 step:26485 [D loss: 0.527458, acc.: 69.53%] [G loss: 0.732735]\n",
      "epoch:28 step:26486 [D loss: 0.562871, acc.: 65.62%] [G loss: 0.808859]\n",
      "epoch:28 step:26487 [D loss: 0.558458, acc.: 66.41%] [G loss: 0.795622]\n",
      "epoch:28 step:26488 [D loss: 0.529484, acc.: 74.22%] [G loss: 0.720161]\n",
      "epoch:28 step:26489 [D loss: 0.551368, acc.: 70.31%] [G loss: 0.768926]\n",
      "epoch:28 step:26490 [D loss: 0.461364, acc.: 78.91%] [G loss: 0.759624]\n",
      "epoch:28 step:26491 [D loss: 0.526561, acc.: 67.97%] [G loss: 0.682373]\n",
      "epoch:28 step:26492 [D loss: 0.585218, acc.: 64.84%] [G loss: 0.609630]\n",
      "epoch:28 step:26493 [D loss: 0.596919, acc.: 62.50%] [G loss: 0.659270]\n",
      "epoch:28 step:26494 [D loss: 0.522421, acc.: 64.84%] [G loss: 0.646374]\n",
      "epoch:28 step:26495 [D loss: 0.522111, acc.: 70.31%] [G loss: 0.597802]\n",
      "epoch:28 step:26496 [D loss: 0.573178, acc.: 68.75%] [G loss: 0.638232]\n",
      "epoch:28 step:26497 [D loss: 0.523540, acc.: 76.56%] [G loss: 0.775526]\n",
      "epoch:28 step:26498 [D loss: 0.491905, acc.: 75.00%] [G loss: 0.896912]\n",
      "epoch:28 step:26499 [D loss: 0.515908, acc.: 75.78%] [G loss: 0.652634]\n",
      "epoch:28 step:26500 [D loss: 0.520846, acc.: 69.53%] [G loss: 0.757412]\n",
      "epoch:28 step:26501 [D loss: 0.493697, acc.: 71.88%] [G loss: 0.881961]\n",
      "epoch:28 step:26502 [D loss: 0.636485, acc.: 71.09%] [G loss: 0.742717]\n",
      "epoch:28 step:26503 [D loss: 0.565472, acc.: 73.44%] [G loss: 0.696307]\n",
      "epoch:28 step:26504 [D loss: 0.563441, acc.: 68.75%] [G loss: 0.604230]\n",
      "epoch:28 step:26505 [D loss: 0.594584, acc.: 65.62%] [G loss: 0.546527]\n",
      "epoch:28 step:26506 [D loss: 0.453338, acc.: 78.91%] [G loss: 0.889333]\n",
      "epoch:28 step:26507 [D loss: 0.512363, acc.: 71.09%] [G loss: 0.700581]\n",
      "epoch:28 step:26508 [D loss: 0.517241, acc.: 71.88%] [G loss: 0.824151]\n",
      "epoch:28 step:26509 [D loss: 0.516880, acc.: 72.66%] [G loss: 0.682551]\n",
      "epoch:28 step:26510 [D loss: 0.507417, acc.: 76.56%] [G loss: 0.650249]\n",
      "epoch:28 step:26511 [D loss: 0.524616, acc.: 67.97%] [G loss: 0.683271]\n",
      "epoch:28 step:26512 [D loss: 0.438707, acc.: 79.69%] [G loss: 0.691938]\n",
      "epoch:28 step:26513 [D loss: 0.688587, acc.: 61.72%] [G loss: 0.568018]\n",
      "epoch:28 step:26514 [D loss: 0.608615, acc.: 67.97%] [G loss: 0.665086]\n",
      "epoch:28 step:26515 [D loss: 0.496371, acc.: 73.44%] [G loss: 0.711918]\n",
      "epoch:28 step:26516 [D loss: 0.477792, acc.: 80.47%] [G loss: 0.734726]\n",
      "epoch:28 step:26517 [D loss: 0.550701, acc.: 68.75%] [G loss: 0.556122]\n",
      "epoch:28 step:26518 [D loss: 0.518326, acc.: 69.53%] [G loss: 0.704761]\n",
      "epoch:28 step:26519 [D loss: 0.544253, acc.: 67.97%] [G loss: 0.629804]\n",
      "epoch:28 step:26520 [D loss: 0.518020, acc.: 71.09%] [G loss: 0.709723]\n",
      "epoch:28 step:26521 [D loss: 0.503223, acc.: 73.44%] [G loss: 0.793708]\n",
      "epoch:28 step:26522 [D loss: 0.520665, acc.: 75.00%] [G loss: 0.614119]\n",
      "epoch:28 step:26523 [D loss: 0.578183, acc.: 63.28%] [G loss: 0.651204]\n",
      "epoch:28 step:26524 [D loss: 0.551151, acc.: 64.84%] [G loss: 0.852769]\n",
      "epoch:28 step:26525 [D loss: 0.491796, acc.: 76.56%] [G loss: 1.075389]\n",
      "epoch:28 step:26526 [D loss: 0.543621, acc.: 73.44%] [G loss: 0.737995]\n",
      "epoch:28 step:26527 [D loss: 0.550939, acc.: 67.97%] [G loss: 0.785994]\n",
      "epoch:28 step:26528 [D loss: 0.525236, acc.: 69.53%] [G loss: 0.636281]\n",
      "epoch:28 step:26529 [D loss: 0.531377, acc.: 71.88%] [G loss: 0.759862]\n",
      "epoch:28 step:26530 [D loss: 0.589211, acc.: 67.19%] [G loss: 0.493944]\n",
      "epoch:28 step:26531 [D loss: 0.541908, acc.: 69.53%] [G loss: 0.502785]\n",
      "epoch:28 step:26532 [D loss: 0.419103, acc.: 78.91%] [G loss: 0.815462]\n",
      "epoch:28 step:26533 [D loss: 0.556852, acc.: 65.62%] [G loss: 0.598675]\n",
      "epoch:28 step:26534 [D loss: 0.470525, acc.: 74.22%] [G loss: 0.772449]\n",
      "epoch:28 step:26535 [D loss: 0.519965, acc.: 74.22%] [G loss: 0.735022]\n",
      "epoch:28 step:26536 [D loss: 0.433780, acc.: 78.12%] [G loss: 1.104883]\n",
      "epoch:28 step:26537 [D loss: 0.577076, acc.: 70.31%] [G loss: 0.765526]\n",
      "epoch:28 step:26538 [D loss: 0.510254, acc.: 71.09%] [G loss: 0.680732]\n",
      "epoch:28 step:26539 [D loss: 0.528891, acc.: 70.31%] [G loss: 0.696631]\n",
      "epoch:28 step:26540 [D loss: 0.490610, acc.: 75.78%] [G loss: 0.874847]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:28 step:26541 [D loss: 0.503564, acc.: 75.00%] [G loss: 0.821288]\n",
      "epoch:28 step:26542 [D loss: 0.566785, acc.: 71.09%] [G loss: 0.817102]\n",
      "epoch:28 step:26543 [D loss: 0.498617, acc.: 73.44%] [G loss: 0.868426]\n",
      "epoch:28 step:26544 [D loss: 0.535114, acc.: 71.88%] [G loss: 0.778258]\n",
      "epoch:28 step:26545 [D loss: 0.463118, acc.: 75.78%] [G loss: 0.821913]\n",
      "epoch:28 step:26546 [D loss: 0.507405, acc.: 75.00%] [G loss: 0.680805]\n",
      "epoch:28 step:26547 [D loss: 0.478196, acc.: 75.78%] [G loss: 0.660004]\n",
      "epoch:28 step:26548 [D loss: 0.383527, acc.: 85.94%] [G loss: 1.058356]\n",
      "epoch:28 step:26549 [D loss: 0.433856, acc.: 78.91%] [G loss: 1.051091]\n",
      "epoch:28 step:26550 [D loss: 0.441840, acc.: 79.69%] [G loss: 1.116980]\n",
      "epoch:28 step:26551 [D loss: 0.457983, acc.: 75.78%] [G loss: 1.109411]\n",
      "epoch:28 step:26552 [D loss: 0.602984, acc.: 66.41%] [G loss: 0.898722]\n",
      "epoch:28 step:26553 [D loss: 0.595178, acc.: 66.41%] [G loss: 0.673722]\n",
      "epoch:28 step:26554 [D loss: 0.522740, acc.: 71.09%] [G loss: 0.745632]\n",
      "epoch:28 step:26555 [D loss: 0.577511, acc.: 66.41%] [G loss: 0.604746]\n",
      "epoch:28 step:26556 [D loss: 0.535082, acc.: 69.53%] [G loss: 0.792202]\n",
      "epoch:28 step:26557 [D loss: 0.447871, acc.: 76.56%] [G loss: 0.899929]\n",
      "epoch:28 step:26558 [D loss: 0.552251, acc.: 71.88%] [G loss: 0.629141]\n",
      "epoch:28 step:26559 [D loss: 0.533248, acc.: 69.53%] [G loss: 0.744048]\n",
      "epoch:28 step:26560 [D loss: 0.524311, acc.: 70.31%] [G loss: 0.572926]\n",
      "epoch:28 step:26561 [D loss: 0.562874, acc.: 67.19%] [G loss: 0.623232]\n",
      "epoch:28 step:26562 [D loss: 0.429427, acc.: 83.59%] [G loss: 0.840535]\n",
      "epoch:28 step:26563 [D loss: 0.586627, acc.: 69.53%] [G loss: 0.717277]\n",
      "epoch:28 step:26564 [D loss: 0.427375, acc.: 78.12%] [G loss: 0.921232]\n",
      "epoch:28 step:26565 [D loss: 0.454141, acc.: 75.78%] [G loss: 0.861981]\n",
      "epoch:28 step:26566 [D loss: 0.524051, acc.: 75.00%] [G loss: 0.600877]\n",
      "epoch:28 step:26567 [D loss: 0.587346, acc.: 64.06%] [G loss: 0.551417]\n",
      "epoch:28 step:26568 [D loss: 0.499140, acc.: 73.44%] [G loss: 0.792749]\n",
      "epoch:28 step:26569 [D loss: 0.563130, acc.: 70.31%] [G loss: 0.581820]\n",
      "epoch:28 step:26570 [D loss: 0.469808, acc.: 75.00%] [G loss: 0.832229]\n",
      "epoch:28 step:26571 [D loss: 0.497856, acc.: 76.56%] [G loss: 0.829401]\n",
      "epoch:28 step:26572 [D loss: 0.465853, acc.: 74.22%] [G loss: 0.844176]\n",
      "epoch:28 step:26573 [D loss: 0.508198, acc.: 72.66%] [G loss: 0.888025]\n",
      "epoch:28 step:26574 [D loss: 0.621418, acc.: 61.72%] [G loss: 0.603084]\n",
      "epoch:28 step:26575 [D loss: 0.501405, acc.: 75.00%] [G loss: 0.702972]\n",
      "epoch:28 step:26576 [D loss: 0.440261, acc.: 79.69%] [G loss: 0.772332]\n",
      "epoch:28 step:26577 [D loss: 0.536614, acc.: 73.44%] [G loss: 0.837734]\n",
      "epoch:28 step:26578 [D loss: 0.641704, acc.: 60.94%] [G loss: 0.720392]\n",
      "epoch:28 step:26579 [D loss: 0.477614, acc.: 75.00%] [G loss: 1.023686]\n",
      "epoch:28 step:26580 [D loss: 0.458416, acc.: 79.69%] [G loss: 1.161544]\n",
      "epoch:28 step:26581 [D loss: 0.611017, acc.: 62.50%] [G loss: 0.817489]\n",
      "epoch:28 step:26582 [D loss: 0.535611, acc.: 71.09%] [G loss: 0.966901]\n",
      "epoch:28 step:26583 [D loss: 0.389105, acc.: 85.16%] [G loss: 1.099745]\n",
      "epoch:28 step:26584 [D loss: 0.629789, acc.: 64.84%] [G loss: 0.780457]\n",
      "epoch:28 step:26585 [D loss: 0.664652, acc.: 64.84%] [G loss: 0.609580]\n",
      "epoch:28 step:26586 [D loss: 0.487901, acc.: 75.00%] [G loss: 0.614549]\n",
      "epoch:28 step:26587 [D loss: 0.472304, acc.: 75.78%] [G loss: 0.758575]\n",
      "epoch:28 step:26588 [D loss: 0.533072, acc.: 73.44%] [G loss: 0.790800]\n",
      "epoch:28 step:26589 [D loss: 0.528053, acc.: 71.88%] [G loss: 0.710456]\n",
      "epoch:28 step:26590 [D loss: 0.396957, acc.: 83.59%] [G loss: 0.910223]\n",
      "epoch:28 step:26591 [D loss: 0.468597, acc.: 78.12%] [G loss: 0.923372]\n",
      "epoch:28 step:26592 [D loss: 0.589174, acc.: 63.28%] [G loss: 0.861654]\n",
      "epoch:28 step:26593 [D loss: 0.452596, acc.: 79.69%] [G loss: 0.846837]\n",
      "epoch:28 step:26594 [D loss: 0.447684, acc.: 78.12%] [G loss: 1.100616]\n",
      "epoch:28 step:26595 [D loss: 0.483566, acc.: 76.56%] [G loss: 0.985788]\n",
      "epoch:28 step:26596 [D loss: 0.509013, acc.: 72.66%] [G loss: 0.896816]\n",
      "epoch:28 step:26597 [D loss: 0.481887, acc.: 75.78%] [G loss: 0.741945]\n",
      "epoch:28 step:26598 [D loss: 0.519515, acc.: 71.09%] [G loss: 0.807838]\n",
      "epoch:28 step:26599 [D loss: 0.498107, acc.: 75.00%] [G loss: 0.775440]\n",
      "epoch:28 step:26600 [D loss: 0.471398, acc.: 72.66%] [G loss: 0.776700]\n",
      "epoch:28 step:26601 [D loss: 0.578266, acc.: 67.19%] [G loss: 0.740771]\n",
      "epoch:28 step:26602 [D loss: 0.580032, acc.: 68.75%] [G loss: 0.859085]\n",
      "epoch:28 step:26603 [D loss: 0.574485, acc.: 68.75%] [G loss: 0.659449]\n",
      "epoch:28 step:26604 [D loss: 0.491557, acc.: 75.00%] [G loss: 0.817022]\n",
      "epoch:28 step:26605 [D loss: 0.517088, acc.: 71.88%] [G loss: 0.873086]\n",
      "epoch:28 step:26606 [D loss: 0.472843, acc.: 78.12%] [G loss: 0.777696]\n",
      "epoch:28 step:26607 [D loss: 0.468065, acc.: 78.12%] [G loss: 0.892305]\n",
      "epoch:28 step:26608 [D loss: 0.541060, acc.: 70.31%] [G loss: 0.818249]\n",
      "epoch:28 step:26609 [D loss: 0.541813, acc.: 67.97%] [G loss: 0.771473]\n",
      "epoch:28 step:26610 [D loss: 0.452694, acc.: 81.25%] [G loss: 0.978885]\n",
      "epoch:28 step:26611 [D loss: 0.548939, acc.: 70.31%] [G loss: 0.860094]\n",
      "epoch:28 step:26612 [D loss: 0.632951, acc.: 60.16%] [G loss: 0.581115]\n",
      "epoch:28 step:26613 [D loss: 0.525134, acc.: 69.53%] [G loss: 0.568614]\n",
      "epoch:28 step:26614 [D loss: 0.510610, acc.: 71.88%] [G loss: 0.674207]\n",
      "epoch:28 step:26615 [D loss: 0.565964, acc.: 69.53%] [G loss: 0.841283]\n",
      "epoch:28 step:26616 [D loss: 0.549266, acc.: 71.09%] [G loss: 0.602303]\n",
      "epoch:28 step:26617 [D loss: 0.498259, acc.: 74.22%] [G loss: 0.627554]\n",
      "epoch:28 step:26618 [D loss: 0.544490, acc.: 77.34%] [G loss: 0.711716]\n",
      "epoch:28 step:26619 [D loss: 0.540276, acc.: 71.09%] [G loss: 0.669939]\n",
      "epoch:28 step:26620 [D loss: 0.553445, acc.: 61.72%] [G loss: 0.614702]\n",
      "epoch:28 step:26621 [D loss: 0.453496, acc.: 76.56%] [G loss: 0.749320]\n",
      "epoch:28 step:26622 [D loss: 0.565007, acc.: 66.41%] [G loss: 0.837452]\n",
      "epoch:28 step:26623 [D loss: 0.533343, acc.: 72.66%] [G loss: 0.793430]\n",
      "epoch:28 step:26624 [D loss: 0.508091, acc.: 71.88%] [G loss: 0.791154]\n",
      "epoch:28 step:26625 [D loss: 0.502212, acc.: 74.22%] [G loss: 0.723390]\n",
      "epoch:28 step:26626 [D loss: 0.570593, acc.: 71.09%] [G loss: 0.634153]\n",
      "epoch:28 step:26627 [D loss: 0.507498, acc.: 71.88%] [G loss: 0.767433]\n",
      "epoch:28 step:26628 [D loss: 0.466726, acc.: 73.44%] [G loss: 0.813159]\n",
      "epoch:28 step:26629 [D loss: 0.531706, acc.: 66.41%] [G loss: 0.630427]\n",
      "epoch:28 step:26630 [D loss: 0.551313, acc.: 71.09%] [G loss: 0.628815]\n",
      "epoch:28 step:26631 [D loss: 0.529978, acc.: 72.66%] [G loss: 0.643990]\n",
      "epoch:28 step:26632 [D loss: 0.520723, acc.: 71.88%] [G loss: 0.683726]\n",
      "epoch:28 step:26633 [D loss: 0.552601, acc.: 70.31%] [G loss: 0.562035]\n",
      "epoch:28 step:26634 [D loss: 0.474719, acc.: 75.78%] [G loss: 0.669635]\n",
      "epoch:28 step:26635 [D loss: 0.472560, acc.: 75.78%] [G loss: 0.863793]\n",
      "epoch:28 step:26636 [D loss: 0.621493, acc.: 61.72%] [G loss: 0.783564]\n",
      "epoch:28 step:26637 [D loss: 0.649123, acc.: 57.81%] [G loss: 0.502392]\n",
      "epoch:28 step:26638 [D loss: 0.490490, acc.: 74.22%] [G loss: 0.595304]\n",
      "epoch:28 step:26639 [D loss: 0.436281, acc.: 79.69%] [G loss: 0.761005]\n",
      "epoch:28 step:26640 [D loss: 0.552948, acc.: 69.53%] [G loss: 0.798347]\n",
      "epoch:28 step:26641 [D loss: 0.490871, acc.: 76.56%] [G loss: 0.851544]\n",
      "epoch:28 step:26642 [D loss: 0.501276, acc.: 71.88%] [G loss: 0.938491]\n",
      "epoch:28 step:26643 [D loss: 0.572761, acc.: 71.09%] [G loss: 0.666084]\n",
      "epoch:28 step:26644 [D loss: 0.514034, acc.: 73.44%] [G loss: 0.972047]\n",
      "epoch:28 step:26645 [D loss: 0.557162, acc.: 67.19%] [G loss: 0.710299]\n",
      "epoch:28 step:26646 [D loss: 0.533512, acc.: 70.31%] [G loss: 0.743460]\n",
      "epoch:28 step:26647 [D loss: 0.598082, acc.: 66.41%] [G loss: 0.590994]\n",
      "epoch:28 step:26648 [D loss: 0.548286, acc.: 67.97%] [G loss: 0.622837]\n",
      "epoch:28 step:26649 [D loss: 0.510745, acc.: 74.22%] [G loss: 0.721621]\n",
      "epoch:28 step:26650 [D loss: 0.451298, acc.: 75.00%] [G loss: 0.851671]\n",
      "epoch:28 step:26651 [D loss: 0.525230, acc.: 73.44%] [G loss: 0.860064]\n",
      "epoch:28 step:26652 [D loss: 0.513987, acc.: 78.12%] [G loss: 0.808203]\n",
      "epoch:28 step:26653 [D loss: 0.512387, acc.: 75.78%] [G loss: 0.914311]\n",
      "epoch:28 step:26654 [D loss: 0.577556, acc.: 70.31%] [G loss: 0.780349]\n",
      "epoch:28 step:26655 [D loss: 0.574787, acc.: 68.75%] [G loss: 0.705581]\n",
      "epoch:28 step:26656 [D loss: 0.597430, acc.: 64.06%] [G loss: 0.577921]\n",
      "epoch:28 step:26657 [D loss: 0.524740, acc.: 75.78%] [G loss: 0.596321]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:28 step:26658 [D loss: 0.573529, acc.: 69.53%] [G loss: 0.606589]\n",
      "epoch:28 step:26659 [D loss: 0.561831, acc.: 70.31%] [G loss: 0.531584]\n",
      "epoch:28 step:26660 [D loss: 0.561459, acc.: 68.75%] [G loss: 0.564953]\n",
      "epoch:28 step:26661 [D loss: 0.524071, acc.: 71.09%] [G loss: 0.811368]\n",
      "epoch:28 step:26662 [D loss: 0.430358, acc.: 77.34%] [G loss: 0.782475]\n",
      "epoch:28 step:26663 [D loss: 0.455872, acc.: 74.22%] [G loss: 0.903539]\n",
      "epoch:28 step:26664 [D loss: 0.532891, acc.: 71.09%] [G loss: 0.759574]\n",
      "epoch:28 step:26665 [D loss: 0.444601, acc.: 77.34%] [G loss: 0.833372]\n",
      "epoch:28 step:26666 [D loss: 0.437941, acc.: 79.69%] [G loss: 0.843230]\n",
      "epoch:28 step:26667 [D loss: 0.527960, acc.: 67.97%] [G loss: 0.820704]\n",
      "epoch:28 step:26668 [D loss: 0.542481, acc.: 70.31%] [G loss: 0.658081]\n",
      "epoch:28 step:26669 [D loss: 0.505566, acc.: 69.53%] [G loss: 0.790091]\n",
      "epoch:28 step:26670 [D loss: 0.521776, acc.: 72.66%] [G loss: 0.810121]\n",
      "epoch:28 step:26671 [D loss: 0.494527, acc.: 76.56%] [G loss: 0.614902]\n",
      "epoch:28 step:26672 [D loss: 0.505205, acc.: 71.88%] [G loss: 0.764943]\n",
      "epoch:28 step:26673 [D loss: 0.637094, acc.: 63.28%] [G loss: 0.778395]\n",
      "epoch:28 step:26674 [D loss: 0.554175, acc.: 68.75%] [G loss: 0.691518]\n",
      "epoch:28 step:26675 [D loss: 0.537625, acc.: 67.19%] [G loss: 0.747884]\n",
      "epoch:28 step:26676 [D loss: 0.465240, acc.: 75.78%] [G loss: 1.095205]\n",
      "epoch:28 step:26677 [D loss: 0.483666, acc.: 75.00%] [G loss: 1.011021]\n",
      "epoch:28 step:26678 [D loss: 0.533941, acc.: 68.75%] [G loss: 0.995273]\n",
      "epoch:28 step:26679 [D loss: 0.482212, acc.: 75.00%] [G loss: 0.783140]\n",
      "epoch:28 step:26680 [D loss: 0.470138, acc.: 73.44%] [G loss: 0.862607]\n",
      "epoch:28 step:26681 [D loss: 0.555049, acc.: 68.75%] [G loss: 0.858481]\n",
      "epoch:28 step:26682 [D loss: 0.465792, acc.: 75.00%] [G loss: 0.871437]\n",
      "epoch:28 step:26683 [D loss: 0.579232, acc.: 66.41%] [G loss: 0.945420]\n",
      "epoch:28 step:26684 [D loss: 0.547661, acc.: 66.41%] [G loss: 0.798098]\n",
      "epoch:28 step:26685 [D loss: 0.479913, acc.: 76.56%] [G loss: 0.933092]\n",
      "epoch:28 step:26686 [D loss: 0.529518, acc.: 69.53%] [G loss: 0.746856]\n",
      "epoch:28 step:26687 [D loss: 0.421640, acc.: 80.47%] [G loss: 0.830907]\n",
      "epoch:28 step:26688 [D loss: 0.499772, acc.: 76.56%] [G loss: 0.651160]\n",
      "epoch:28 step:26689 [D loss: 0.511249, acc.: 73.44%] [G loss: 0.830245]\n",
      "epoch:28 step:26690 [D loss: 0.527948, acc.: 74.22%] [G loss: 0.803738]\n",
      "epoch:28 step:26691 [D loss: 0.481431, acc.: 78.91%] [G loss: 0.729367]\n",
      "epoch:28 step:26692 [D loss: 0.549682, acc.: 66.41%] [G loss: 0.639284]\n",
      "epoch:28 step:26693 [D loss: 0.452492, acc.: 81.25%] [G loss: 0.869393]\n",
      "epoch:28 step:26694 [D loss: 0.677756, acc.: 61.72%] [G loss: 0.876253]\n",
      "epoch:28 step:26695 [D loss: 0.541004, acc.: 67.19%] [G loss: 0.807651]\n",
      "epoch:28 step:26696 [D loss: 0.549484, acc.: 70.31%] [G loss: 0.706408]\n",
      "epoch:28 step:26697 [D loss: 0.477221, acc.: 76.56%] [G loss: 0.795712]\n",
      "epoch:28 step:26698 [D loss: 0.575224, acc.: 66.41%] [G loss: 0.675052]\n",
      "epoch:28 step:26699 [D loss: 0.535868, acc.: 71.88%] [G loss: 0.728807]\n",
      "epoch:28 step:26700 [D loss: 0.508424, acc.: 70.31%] [G loss: 0.781177]\n",
      "epoch:28 step:26701 [D loss: 0.585512, acc.: 67.97%] [G loss: 0.877477]\n",
      "epoch:28 step:26702 [D loss: 0.560593, acc.: 66.41%] [G loss: 0.710426]\n",
      "epoch:28 step:26703 [D loss: 0.536257, acc.: 67.97%] [G loss: 0.762296]\n",
      "epoch:28 step:26704 [D loss: 0.544484, acc.: 67.97%] [G loss: 0.848075]\n",
      "epoch:28 step:26705 [D loss: 0.535226, acc.: 75.00%] [G loss: 0.691849]\n",
      "epoch:28 step:26706 [D loss: 0.499428, acc.: 79.69%] [G loss: 0.876878]\n",
      "epoch:28 step:26707 [D loss: 0.434120, acc.: 78.91%] [G loss: 0.833564]\n",
      "epoch:28 step:26708 [D loss: 0.520434, acc.: 77.34%] [G loss: 0.886991]\n",
      "epoch:28 step:26709 [D loss: 0.616140, acc.: 65.62%] [G loss: 0.739572]\n",
      "epoch:28 step:26710 [D loss: 0.578346, acc.: 62.50%] [G loss: 0.916692]\n",
      "epoch:28 step:26711 [D loss: 0.419021, acc.: 82.03%] [G loss: 1.076826]\n",
      "epoch:28 step:26712 [D loss: 0.533894, acc.: 73.44%] [G loss: 0.728176]\n",
      "epoch:28 step:26713 [D loss: 0.650211, acc.: 63.28%] [G loss: 0.698142]\n",
      "epoch:28 step:26714 [D loss: 0.567044, acc.: 71.88%] [G loss: 0.635457]\n",
      "epoch:28 step:26715 [D loss: 0.537899, acc.: 73.44%] [G loss: 0.532543]\n",
      "epoch:28 step:26716 [D loss: 0.550695, acc.: 71.88%] [G loss: 0.700951]\n",
      "epoch:28 step:26717 [D loss: 0.442924, acc.: 82.81%] [G loss: 0.740441]\n",
      "epoch:28 step:26718 [D loss: 0.572238, acc.: 65.62%] [G loss: 0.519470]\n",
      "epoch:28 step:26719 [D loss: 0.500525, acc.: 70.31%] [G loss: 0.810971]\n",
      "epoch:28 step:26720 [D loss: 0.473010, acc.: 75.78%] [G loss: 1.036598]\n",
      "epoch:28 step:26721 [D loss: 0.549770, acc.: 67.19%] [G loss: 0.749601]\n",
      "epoch:28 step:26722 [D loss: 0.563975, acc.: 64.84%] [G loss: 0.832002]\n",
      "epoch:28 step:26723 [D loss: 0.533465, acc.: 74.22%] [G loss: 0.598253]\n",
      "epoch:28 step:26724 [D loss: 0.440840, acc.: 77.34%] [G loss: 0.668232]\n",
      "epoch:28 step:26725 [D loss: 0.500982, acc.: 74.22%] [G loss: 0.804177]\n",
      "epoch:28 step:26726 [D loss: 0.506268, acc.: 72.66%] [G loss: 0.795910]\n",
      "epoch:28 step:26727 [D loss: 0.495529, acc.: 75.00%] [G loss: 0.680348]\n",
      "epoch:28 step:26728 [D loss: 0.553050, acc.: 67.97%] [G loss: 0.752689]\n",
      "epoch:28 step:26729 [D loss: 0.530291, acc.: 71.88%] [G loss: 0.634724]\n",
      "epoch:28 step:26730 [D loss: 0.583048, acc.: 67.19%] [G loss: 0.766903]\n",
      "epoch:28 step:26731 [D loss: 0.458662, acc.: 77.34%] [G loss: 0.713786]\n",
      "epoch:28 step:26732 [D loss: 0.568470, acc.: 75.00%] [G loss: 0.666858]\n",
      "epoch:28 step:26733 [D loss: 0.565179, acc.: 70.31%] [G loss: 0.578571]\n",
      "epoch:28 step:26734 [D loss: 0.528619, acc.: 73.44%] [G loss: 0.680480]\n",
      "epoch:28 step:26735 [D loss: 0.441680, acc.: 79.69%] [G loss: 1.046922]\n",
      "epoch:28 step:26736 [D loss: 0.537365, acc.: 71.09%] [G loss: 0.611672]\n",
      "epoch:28 step:26737 [D loss: 0.639512, acc.: 61.72%] [G loss: 0.866596]\n",
      "epoch:28 step:26738 [D loss: 0.606313, acc.: 63.28%] [G loss: 0.738915]\n",
      "epoch:28 step:26739 [D loss: 0.516686, acc.: 72.66%] [G loss: 0.656238]\n",
      "epoch:28 step:26740 [D loss: 0.412494, acc.: 80.47%] [G loss: 0.713460]\n",
      "epoch:28 step:26741 [D loss: 0.509750, acc.: 74.22%] [G loss: 0.815045]\n",
      "epoch:28 step:26742 [D loss: 0.551609, acc.: 70.31%] [G loss: 0.706360]\n",
      "epoch:28 step:26743 [D loss: 0.536136, acc.: 74.22%] [G loss: 0.964271]\n",
      "epoch:28 step:26744 [D loss: 0.466727, acc.: 77.34%] [G loss: 0.998739]\n",
      "epoch:28 step:26745 [D loss: 0.484576, acc.: 75.00%] [G loss: 0.984284]\n",
      "epoch:28 step:26746 [D loss: 0.553672, acc.: 72.66%] [G loss: 0.867633]\n",
      "epoch:28 step:26747 [D loss: 0.627826, acc.: 66.41%] [G loss: 0.686262]\n",
      "epoch:28 step:26748 [D loss: 0.545759, acc.: 68.75%] [G loss: 0.624085]\n",
      "epoch:28 step:26749 [D loss: 0.505070, acc.: 72.66%] [G loss: 0.722125]\n",
      "epoch:28 step:26750 [D loss: 0.469827, acc.: 78.91%] [G loss: 0.704764]\n",
      "epoch:28 step:26751 [D loss: 0.547162, acc.: 71.09%] [G loss: 0.802867]\n",
      "epoch:28 step:26752 [D loss: 0.471008, acc.: 76.56%] [G loss: 0.747616]\n",
      "epoch:28 step:26753 [D loss: 0.553738, acc.: 68.75%] [G loss: 0.785589]\n",
      "epoch:28 step:26754 [D loss: 0.516523, acc.: 75.00%] [G loss: 0.740479]\n",
      "epoch:28 step:26755 [D loss: 0.501406, acc.: 71.09%] [G loss: 0.801723]\n",
      "epoch:28 step:26756 [D loss: 0.445877, acc.: 78.12%] [G loss: 0.926723]\n",
      "epoch:28 step:26757 [D loss: 0.490867, acc.: 74.22%] [G loss: 1.038203]\n",
      "epoch:28 step:26758 [D loss: 0.495827, acc.: 76.56%] [G loss: 0.946695]\n",
      "epoch:28 step:26759 [D loss: 0.476223, acc.: 78.12%] [G loss: 0.820800]\n",
      "epoch:28 step:26760 [D loss: 0.484004, acc.: 74.22%] [G loss: 0.721712]\n",
      "epoch:28 step:26761 [D loss: 0.635631, acc.: 67.19%] [G loss: 0.661296]\n",
      "epoch:28 step:26762 [D loss: 0.470869, acc.: 76.56%] [G loss: 0.722179]\n",
      "epoch:28 step:26763 [D loss: 0.499571, acc.: 74.22%] [G loss: 0.771336]\n",
      "epoch:28 step:26764 [D loss: 0.607006, acc.: 60.94%] [G loss: 0.727271]\n",
      "epoch:28 step:26765 [D loss: 0.542232, acc.: 71.09%] [G loss: 0.598349]\n",
      "epoch:28 step:26766 [D loss: 0.519991, acc.: 71.88%] [G loss: 0.777937]\n",
      "epoch:28 step:26767 [D loss: 0.630093, acc.: 67.19%] [G loss: 0.765602]\n",
      "epoch:28 step:26768 [D loss: 0.588090, acc.: 72.66%] [G loss: 0.518821]\n",
      "epoch:28 step:26769 [D loss: 0.509750, acc.: 74.22%] [G loss: 0.784601]\n",
      "epoch:28 step:26770 [D loss: 0.501912, acc.: 66.41%] [G loss: 0.877952]\n",
      "epoch:28 step:26771 [D loss: 0.584033, acc.: 68.75%] [G loss: 0.624279]\n",
      "epoch:28 step:26772 [D loss: 0.505858, acc.: 69.53%] [G loss: 0.656181]\n",
      "epoch:28 step:26773 [D loss: 0.588797, acc.: 59.38%] [G loss: 0.561935]\n",
      "epoch:28 step:26774 [D loss: 0.508362, acc.: 73.44%] [G loss: 0.586267]\n",
      "epoch:28 step:26775 [D loss: 0.553349, acc.: 63.28%] [G loss: 0.580146]\n",
      "epoch:28 step:26776 [D loss: 0.474842, acc.: 78.12%] [G loss: 0.749431]\n",
      "epoch:28 step:26777 [D loss: 0.534516, acc.: 69.53%] [G loss: 0.780463]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:28 step:26778 [D loss: 0.619524, acc.: 66.41%] [G loss: 0.598636]\n",
      "epoch:28 step:26779 [D loss: 0.568398, acc.: 66.41%] [G loss: 0.634330]\n",
      "epoch:28 step:26780 [D loss: 0.521891, acc.: 77.34%] [G loss: 0.641454]\n",
      "epoch:28 step:26781 [D loss: 0.534087, acc.: 74.22%] [G loss: 0.791943]\n",
      "epoch:28 step:26782 [D loss: 0.491012, acc.: 79.69%] [G loss: 0.696519]\n",
      "epoch:28 step:26783 [D loss: 0.500208, acc.: 73.44%] [G loss: 0.904505]\n",
      "epoch:28 step:26784 [D loss: 0.489676, acc.: 74.22%] [G loss: 0.678659]\n",
      "epoch:28 step:26785 [D loss: 0.563104, acc.: 69.53%] [G loss: 0.678821]\n",
      "epoch:28 step:26786 [D loss: 0.540340, acc.: 71.09%] [G loss: 0.818791]\n",
      "epoch:28 step:26787 [D loss: 0.467262, acc.: 81.25%] [G loss: 0.911953]\n",
      "epoch:28 step:26788 [D loss: 0.453546, acc.: 78.91%] [G loss: 0.944911]\n",
      "epoch:28 step:26789 [D loss: 0.590955, acc.: 63.28%] [G loss: 0.646621]\n",
      "epoch:28 step:26790 [D loss: 0.406786, acc.: 85.16%] [G loss: 0.771217]\n",
      "epoch:28 step:26791 [D loss: 0.469127, acc.: 81.25%] [G loss: 0.751708]\n",
      "epoch:28 step:26792 [D loss: 0.535684, acc.: 74.22%] [G loss: 0.854299]\n",
      "epoch:28 step:26793 [D loss: 0.479488, acc.: 76.56%] [G loss: 0.829381]\n",
      "epoch:28 step:26794 [D loss: 0.471971, acc.: 77.34%] [G loss: 1.162270]\n",
      "epoch:28 step:26795 [D loss: 0.560851, acc.: 70.31%] [G loss: 0.803765]\n",
      "epoch:28 step:26796 [D loss: 0.569647, acc.: 67.97%] [G loss: 0.657871]\n",
      "epoch:28 step:26797 [D loss: 0.511406, acc.: 75.00%] [G loss: 0.870005]\n",
      "epoch:28 step:26798 [D loss: 0.580268, acc.: 71.88%] [G loss: 0.846591]\n",
      "epoch:28 step:26799 [D loss: 0.505960, acc.: 74.22%] [G loss: 0.846041]\n",
      "epoch:28 step:26800 [D loss: 0.472672, acc.: 75.00%] [G loss: 0.963920]\n",
      "epoch:28 step:26801 [D loss: 0.581422, acc.: 71.09%] [G loss: 0.744538]\n",
      "epoch:28 step:26802 [D loss: 0.697934, acc.: 60.94%] [G loss: 0.659993]\n",
      "epoch:28 step:26803 [D loss: 0.524766, acc.: 72.66%] [G loss: 0.749935]\n",
      "epoch:28 step:26804 [D loss: 0.489826, acc.: 78.12%] [G loss: 0.862143]\n",
      "epoch:28 step:26805 [D loss: 0.580045, acc.: 71.09%] [G loss: 0.559572]\n",
      "epoch:28 step:26806 [D loss: 0.481309, acc.: 73.44%] [G loss: 0.798430]\n",
      "epoch:28 step:26807 [D loss: 0.542000, acc.: 74.22%] [G loss: 0.513961]\n",
      "epoch:28 step:26808 [D loss: 0.479625, acc.: 78.91%] [G loss: 0.639496]\n",
      "epoch:28 step:26809 [D loss: 0.571060, acc.: 67.19%] [G loss: 0.783452]\n",
      "epoch:28 step:26810 [D loss: 0.427195, acc.: 82.03%] [G loss: 1.009946]\n",
      "epoch:28 step:26811 [D loss: 0.488572, acc.: 74.22%] [G loss: 1.092508]\n",
      "epoch:28 step:26812 [D loss: 0.579766, acc.: 68.75%] [G loss: 0.933900]\n",
      "epoch:28 step:26813 [D loss: 0.582141, acc.: 68.75%] [G loss: 0.616470]\n",
      "epoch:28 step:26814 [D loss: 0.559612, acc.: 68.75%] [G loss: 0.661709]\n",
      "epoch:28 step:26815 [D loss: 0.525338, acc.: 68.75%] [G loss: 0.835346]\n",
      "epoch:28 step:26816 [D loss: 0.526442, acc.: 72.66%] [G loss: 0.561931]\n",
      "epoch:28 step:26817 [D loss: 0.510931, acc.: 75.00%] [G loss: 0.640333]\n",
      "epoch:28 step:26818 [D loss: 0.388535, acc.: 83.59%] [G loss: 0.903784]\n",
      "epoch:28 step:26819 [D loss: 0.499807, acc.: 71.88%] [G loss: 0.877201]\n",
      "epoch:28 step:26820 [D loss: 0.576711, acc.: 68.75%] [G loss: 0.798543]\n",
      "epoch:28 step:26821 [D loss: 0.562905, acc.: 69.53%] [G loss: 0.812773]\n",
      "epoch:28 step:26822 [D loss: 0.503633, acc.: 71.88%] [G loss: 0.682657]\n",
      "epoch:28 step:26823 [D loss: 0.566506, acc.: 67.97%] [G loss: 0.588297]\n",
      "epoch:28 step:26824 [D loss: 0.607129, acc.: 64.06%] [G loss: 0.694277]\n",
      "epoch:28 step:26825 [D loss: 0.505537, acc.: 71.88%] [G loss: 0.905774]\n",
      "epoch:28 step:26826 [D loss: 0.593313, acc.: 69.53%] [G loss: 0.749165]\n",
      "epoch:28 step:26827 [D loss: 0.601511, acc.: 69.53%] [G loss: 0.718565]\n",
      "epoch:28 step:26828 [D loss: 0.502155, acc.: 73.44%] [G loss: 0.650972]\n",
      "epoch:28 step:26829 [D loss: 0.519962, acc.: 71.88%] [G loss: 0.768458]\n",
      "epoch:28 step:26830 [D loss: 0.581365, acc.: 67.19%] [G loss: 0.764258]\n",
      "epoch:28 step:26831 [D loss: 0.522728, acc.: 73.44%] [G loss: 0.777605]\n",
      "epoch:28 step:26832 [D loss: 0.498133, acc.: 75.00%] [G loss: 0.697625]\n",
      "epoch:28 step:26833 [D loss: 0.508815, acc.: 72.66%] [G loss: 0.646050]\n",
      "epoch:28 step:26834 [D loss: 0.487457, acc.: 76.56%] [G loss: 0.766602]\n",
      "epoch:28 step:26835 [D loss: 0.507339, acc.: 70.31%] [G loss: 0.790749]\n",
      "epoch:28 step:26836 [D loss: 0.590889, acc.: 67.97%] [G loss: 0.761560]\n",
      "epoch:28 step:26837 [D loss: 0.481659, acc.: 77.34%] [G loss: 0.738345]\n",
      "epoch:28 step:26838 [D loss: 0.466167, acc.: 78.12%] [G loss: 0.878302]\n",
      "epoch:28 step:26839 [D loss: 0.497202, acc.: 73.44%] [G loss: 0.844192]\n",
      "epoch:28 step:26840 [D loss: 0.556284, acc.: 71.88%] [G loss: 0.585236]\n",
      "epoch:28 step:26841 [D loss: 0.487911, acc.: 78.12%] [G loss: 1.017514]\n",
      "epoch:28 step:26842 [D loss: 0.609919, acc.: 68.75%] [G loss: 0.599434]\n",
      "epoch:28 step:26843 [D loss: 0.520994, acc.: 73.44%] [G loss: 0.672491]\n",
      "epoch:28 step:26844 [D loss: 0.526116, acc.: 75.00%] [G loss: 0.566299]\n",
      "epoch:28 step:26845 [D loss: 0.561957, acc.: 69.53%] [G loss: 0.682389]\n",
      "epoch:28 step:26846 [D loss: 0.551053, acc.: 67.97%] [G loss: 0.710460]\n",
      "epoch:28 step:26847 [D loss: 0.545211, acc.: 69.53%] [G loss: 0.425731]\n",
      "epoch:28 step:26848 [D loss: 0.510623, acc.: 71.88%] [G loss: 0.754584]\n",
      "epoch:28 step:26849 [D loss: 0.455666, acc.: 75.00%] [G loss: 0.827626]\n",
      "epoch:28 step:26850 [D loss: 0.551695, acc.: 69.53%] [G loss: 0.679237]\n",
      "epoch:28 step:26851 [D loss: 0.543651, acc.: 67.19%] [G loss: 0.733196]\n",
      "epoch:28 step:26852 [D loss: 0.529881, acc.: 66.41%] [G loss: 0.807745]\n",
      "epoch:28 step:26853 [D loss: 0.540590, acc.: 68.75%] [G loss: 0.778509]\n",
      "epoch:28 step:26854 [D loss: 0.512570, acc.: 72.66%] [G loss: 0.909360]\n",
      "epoch:28 step:26855 [D loss: 0.573548, acc.: 69.53%] [G loss: 0.709535]\n",
      "epoch:28 step:26856 [D loss: 0.510733, acc.: 70.31%] [G loss: 0.756308]\n",
      "epoch:28 step:26857 [D loss: 0.529094, acc.: 71.88%] [G loss: 0.631225]\n",
      "epoch:28 step:26858 [D loss: 0.520412, acc.: 74.22%] [G loss: 0.716238]\n",
      "epoch:28 step:26859 [D loss: 0.456689, acc.: 75.00%] [G loss: 0.685510]\n",
      "epoch:28 step:26860 [D loss: 0.396743, acc.: 83.59%] [G loss: 0.945608]\n",
      "epoch:28 step:26861 [D loss: 0.603421, acc.: 67.97%] [G loss: 0.827261]\n",
      "epoch:28 step:26862 [D loss: 0.553732, acc.: 70.31%] [G loss: 0.734611]\n",
      "epoch:28 step:26863 [D loss: 0.550950, acc.: 69.53%] [G loss: 0.644167]\n",
      "epoch:28 step:26864 [D loss: 0.551340, acc.: 75.78%] [G loss: 0.676531]\n",
      "epoch:28 step:26865 [D loss: 0.518782, acc.: 73.44%] [G loss: 0.863183]\n",
      "epoch:28 step:26866 [D loss: 0.528128, acc.: 70.31%] [G loss: 0.724939]\n",
      "epoch:28 step:26867 [D loss: 0.458320, acc.: 81.25%] [G loss: 0.787769]\n",
      "epoch:28 step:26868 [D loss: 0.455267, acc.: 80.47%] [G loss: 0.811551]\n",
      "epoch:28 step:26869 [D loss: 0.461682, acc.: 78.12%] [G loss: 0.823535]\n",
      "epoch:28 step:26870 [D loss: 0.420708, acc.: 79.69%] [G loss: 0.890066]\n",
      "epoch:28 step:26871 [D loss: 0.502625, acc.: 75.78%] [G loss: 0.876313]\n",
      "epoch:28 step:26872 [D loss: 0.541841, acc.: 71.88%] [G loss: 0.797199]\n",
      "epoch:28 step:26873 [D loss: 0.492205, acc.: 76.56%] [G loss: 0.712746]\n",
      "epoch:28 step:26874 [D loss: 0.443009, acc.: 76.56%] [G loss: 0.810130]\n",
      "epoch:28 step:26875 [D loss: 0.519643, acc.: 71.88%] [G loss: 0.748316]\n",
      "epoch:28 step:26876 [D loss: 0.564526, acc.: 70.31%] [G loss: 0.806595]\n",
      "epoch:28 step:26877 [D loss: 0.500068, acc.: 75.00%] [G loss: 0.912504]\n",
      "epoch:28 step:26878 [D loss: 0.469863, acc.: 78.91%] [G loss: 0.891988]\n",
      "epoch:28 step:26879 [D loss: 0.529162, acc.: 68.75%] [G loss: 1.014933]\n",
      "epoch:28 step:26880 [D loss: 0.542490, acc.: 68.75%] [G loss: 0.734206]\n",
      "epoch:28 step:26881 [D loss: 0.509704, acc.: 73.44%] [G loss: 0.747492]\n",
      "epoch:28 step:26882 [D loss: 0.515741, acc.: 75.00%] [G loss: 0.599038]\n",
      "epoch:28 step:26883 [D loss: 0.429605, acc.: 80.47%] [G loss: 0.749836]\n",
      "epoch:28 step:26884 [D loss: 0.368415, acc.: 84.38%] [G loss: 1.023081]\n",
      "epoch:28 step:26885 [D loss: 0.493702, acc.: 75.78%] [G loss: 0.942596]\n",
      "epoch:28 step:26886 [D loss: 0.451385, acc.: 76.56%] [G loss: 0.865328]\n",
      "epoch:28 step:26887 [D loss: 0.479845, acc.: 75.00%] [G loss: 0.772359]\n",
      "epoch:28 step:26888 [D loss: 0.581835, acc.: 67.19%] [G loss: 0.896930]\n",
      "epoch:28 step:26889 [D loss: 0.530957, acc.: 71.88%] [G loss: 0.760027]\n",
      "epoch:28 step:26890 [D loss: 0.397368, acc.: 81.25%] [G loss: 1.338462]\n",
      "epoch:28 step:26891 [D loss: 0.620851, acc.: 66.41%] [G loss: 0.735137]\n",
      "epoch:28 step:26892 [D loss: 0.539972, acc.: 70.31%] [G loss: 0.786276]\n",
      "epoch:28 step:26893 [D loss: 0.484602, acc.: 75.78%] [G loss: 0.860098]\n",
      "epoch:28 step:26894 [D loss: 0.549576, acc.: 71.09%] [G loss: 0.868445]\n",
      "epoch:28 step:26895 [D loss: 0.472876, acc.: 75.78%] [G loss: 0.804494]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:28 step:26896 [D loss: 0.507123, acc.: 74.22%] [G loss: 0.731413]\n",
      "epoch:28 step:26897 [D loss: 0.467801, acc.: 76.56%] [G loss: 0.893539]\n",
      "epoch:28 step:26898 [D loss: 0.514488, acc.: 75.78%] [G loss: 0.798830]\n",
      "epoch:28 step:26899 [D loss: 0.586860, acc.: 70.31%] [G loss: 0.739420]\n",
      "epoch:28 step:26900 [D loss: 0.546769, acc.: 69.53%] [G loss: 0.819317]\n",
      "epoch:28 step:26901 [D loss: 0.513404, acc.: 74.22%] [G loss: 0.707973]\n",
      "epoch:28 step:26902 [D loss: 0.498456, acc.: 75.00%] [G loss: 0.861749]\n",
      "epoch:28 step:26903 [D loss: 0.529358, acc.: 72.66%] [G loss: 0.743475]\n",
      "epoch:28 step:26904 [D loss: 0.512748, acc.: 76.56%] [G loss: 0.707130]\n",
      "epoch:28 step:26905 [D loss: 0.571097, acc.: 66.41%] [G loss: 0.746973]\n",
      "epoch:28 step:26906 [D loss: 0.608527, acc.: 62.50%] [G loss: 0.667060]\n",
      "epoch:28 step:26907 [D loss: 0.542993, acc.: 75.00%] [G loss: 0.626369]\n",
      "epoch:28 step:26908 [D loss: 0.525035, acc.: 71.88%] [G loss: 0.761451]\n",
      "epoch:28 step:26909 [D loss: 0.533951, acc.: 71.88%] [G loss: 0.824815]\n",
      "epoch:28 step:26910 [D loss: 0.566745, acc.: 70.31%] [G loss: 0.807734]\n",
      "epoch:28 step:26911 [D loss: 0.609834, acc.: 64.06%] [G loss: 0.737098]\n",
      "epoch:28 step:26912 [D loss: 0.554802, acc.: 67.97%] [G loss: 0.807897]\n",
      "epoch:28 step:26913 [D loss: 0.482761, acc.: 73.44%] [G loss: 0.894514]\n",
      "epoch:28 step:26914 [D loss: 0.542301, acc.: 69.53%] [G loss: 0.817636]\n",
      "epoch:28 step:26915 [D loss: 0.475365, acc.: 77.34%] [G loss: 0.675452]\n",
      "epoch:28 step:26916 [D loss: 0.493234, acc.: 75.00%] [G loss: 0.853059]\n",
      "epoch:28 step:26917 [D loss: 0.449824, acc.: 75.00%] [G loss: 0.702912]\n",
      "epoch:28 step:26918 [D loss: 0.489899, acc.: 75.00%] [G loss: 0.677186]\n",
      "epoch:28 step:26919 [D loss: 0.489988, acc.: 77.34%] [G loss: 0.614385]\n",
      "epoch:28 step:26920 [D loss: 0.597517, acc.: 65.62%] [G loss: 0.593212]\n",
      "epoch:28 step:26921 [D loss: 0.488323, acc.: 75.78%] [G loss: 0.716306]\n",
      "epoch:28 step:26922 [D loss: 0.521655, acc.: 72.66%] [G loss: 0.734773]\n",
      "epoch:28 step:26923 [D loss: 0.523272, acc.: 71.09%] [G loss: 0.746718]\n",
      "epoch:28 step:26924 [D loss: 0.479031, acc.: 77.34%] [G loss: 0.779225]\n",
      "epoch:28 step:26925 [D loss: 0.540927, acc.: 65.62%] [G loss: 0.778877]\n",
      "epoch:28 step:26926 [D loss: 0.484907, acc.: 74.22%] [G loss: 0.636899]\n",
      "epoch:28 step:26927 [D loss: 0.516882, acc.: 75.00%] [G loss: 0.755213]\n",
      "epoch:28 step:26928 [D loss: 0.469369, acc.: 77.34%] [G loss: 0.898308]\n",
      "epoch:28 step:26929 [D loss: 0.435178, acc.: 82.81%] [G loss: 0.793780]\n",
      "epoch:28 step:26930 [D loss: 0.488956, acc.: 79.69%] [G loss: 0.945327]\n",
      "epoch:28 step:26931 [D loss: 0.510415, acc.: 75.00%] [G loss: 0.872987]\n",
      "epoch:28 step:26932 [D loss: 0.576732, acc.: 68.75%] [G loss: 0.914374]\n",
      "epoch:28 step:26933 [D loss: 0.576581, acc.: 69.53%] [G loss: 0.911960]\n",
      "epoch:28 step:26934 [D loss: 0.543724, acc.: 71.88%] [G loss: 0.600543]\n",
      "epoch:28 step:26935 [D loss: 0.488772, acc.: 75.00%] [G loss: 0.805892]\n",
      "epoch:28 step:26936 [D loss: 0.492759, acc.: 74.22%] [G loss: 0.684265]\n",
      "epoch:28 step:26937 [D loss: 0.526652, acc.: 71.88%] [G loss: 0.781834]\n",
      "epoch:28 step:26938 [D loss: 0.576213, acc.: 69.53%] [G loss: 0.823524]\n",
      "epoch:28 step:26939 [D loss: 0.590865, acc.: 68.75%] [G loss: 0.588693]\n",
      "epoch:28 step:26940 [D loss: 0.581396, acc.: 66.41%] [G loss: 0.432232]\n",
      "epoch:28 step:26941 [D loss: 0.487988, acc.: 76.56%] [G loss: 0.705336]\n",
      "epoch:28 step:26942 [D loss: 0.478101, acc.: 78.12%] [G loss: 0.635140]\n",
      "epoch:28 step:26943 [D loss: 0.484559, acc.: 75.00%] [G loss: 0.722898]\n",
      "epoch:28 step:26944 [D loss: 0.475181, acc.: 80.47%] [G loss: 1.026835]\n",
      "epoch:28 step:26945 [D loss: 0.535550, acc.: 71.09%] [G loss: 0.864816]\n",
      "epoch:28 step:26946 [D loss: 0.638786, acc.: 62.50%] [G loss: 0.762037]\n",
      "epoch:28 step:26947 [D loss: 0.589571, acc.: 67.19%] [G loss: 0.770975]\n",
      "epoch:28 step:26948 [D loss: 0.545432, acc.: 68.75%] [G loss: 0.777190]\n",
      "epoch:28 step:26949 [D loss: 0.543144, acc.: 67.97%] [G loss: 0.728439]\n",
      "epoch:28 step:26950 [D loss: 0.614394, acc.: 67.19%] [G loss: 0.541202]\n",
      "epoch:28 step:26951 [D loss: 0.526131, acc.: 71.09%] [G loss: 0.582931]\n",
      "epoch:28 step:26952 [D loss: 0.543270, acc.: 71.88%] [G loss: 0.656599]\n",
      "epoch:28 step:26953 [D loss: 0.530813, acc.: 72.66%] [G loss: 0.617995]\n",
      "epoch:28 step:26954 [D loss: 0.528990, acc.: 73.44%] [G loss: 0.636794]\n",
      "epoch:28 step:26955 [D loss: 0.493880, acc.: 73.44%] [G loss: 0.832655]\n",
      "epoch:28 step:26956 [D loss: 0.550837, acc.: 69.53%] [G loss: 0.854666]\n",
      "epoch:28 step:26957 [D loss: 0.541167, acc.: 68.75%] [G loss: 0.776809]\n",
      "epoch:28 step:26958 [D loss: 0.539835, acc.: 70.31%] [G loss: 0.772620]\n",
      "epoch:28 step:26959 [D loss: 0.560280, acc.: 67.19%] [G loss: 0.606332]\n",
      "epoch:28 step:26960 [D loss: 0.496677, acc.: 73.44%] [G loss: 0.818031]\n",
      "epoch:28 step:26961 [D loss: 0.459340, acc.: 77.34%] [G loss: 0.791674]\n",
      "epoch:28 step:26962 [D loss: 0.462860, acc.: 79.69%] [G loss: 0.831797]\n",
      "epoch:28 step:26963 [D loss: 0.542511, acc.: 71.09%] [G loss: 0.688788]\n",
      "epoch:28 step:26964 [D loss: 0.499528, acc.: 71.88%] [G loss: 0.779560]\n",
      "epoch:28 step:26965 [D loss: 0.531030, acc.: 75.78%] [G loss: 0.645381]\n",
      "epoch:28 step:26966 [D loss: 0.478720, acc.: 78.12%] [G loss: 0.670666]\n",
      "epoch:28 step:26967 [D loss: 0.584207, acc.: 66.41%] [G loss: 0.607893]\n",
      "epoch:28 step:26968 [D loss: 0.478938, acc.: 78.12%] [G loss: 0.777600]\n",
      "epoch:28 step:26969 [D loss: 0.486000, acc.: 81.25%] [G loss: 0.888050]\n",
      "epoch:28 step:26970 [D loss: 0.547144, acc.: 67.97%] [G loss: 0.612616]\n",
      "epoch:28 step:26971 [D loss: 0.536322, acc.: 67.19%] [G loss: 0.816929]\n",
      "epoch:28 step:26972 [D loss: 0.466217, acc.: 74.22%] [G loss: 0.680309]\n",
      "epoch:28 step:26973 [D loss: 0.499312, acc.: 75.78%] [G loss: 0.683808]\n",
      "epoch:28 step:26974 [D loss: 0.505007, acc.: 72.66%] [G loss: 0.599061]\n",
      "epoch:28 step:26975 [D loss: 0.549932, acc.: 72.66%] [G loss: 0.779260]\n",
      "epoch:28 step:26976 [D loss: 0.591972, acc.: 61.72%] [G loss: 0.668052]\n",
      "epoch:28 step:26977 [D loss: 0.475832, acc.: 75.78%] [G loss: 0.530908]\n",
      "epoch:28 step:26978 [D loss: 0.473285, acc.: 74.22%] [G loss: 0.671144]\n",
      "epoch:28 step:26979 [D loss: 0.515049, acc.: 72.66%] [G loss: 0.837890]\n",
      "epoch:28 step:26980 [D loss: 0.518531, acc.: 77.34%] [G loss: 0.786304]\n",
      "epoch:28 step:26981 [D loss: 0.543813, acc.: 69.53%] [G loss: 0.830045]\n",
      "epoch:28 step:26982 [D loss: 0.551535, acc.: 69.53%] [G loss: 0.699242]\n",
      "epoch:28 step:26983 [D loss: 0.420901, acc.: 77.34%] [G loss: 0.992803]\n",
      "epoch:28 step:26984 [D loss: 0.533589, acc.: 69.53%] [G loss: 0.769719]\n",
      "epoch:28 step:26985 [D loss: 0.540214, acc.: 74.22%] [G loss: 0.692186]\n",
      "epoch:28 step:26986 [D loss: 0.511076, acc.: 75.78%] [G loss: 0.681039]\n",
      "epoch:28 step:26987 [D loss: 0.485240, acc.: 75.00%] [G loss: 0.636771]\n",
      "epoch:28 step:26988 [D loss: 0.561431, acc.: 73.44%] [G loss: 0.720771]\n",
      "epoch:28 step:26989 [D loss: 0.508309, acc.: 71.88%] [G loss: 0.924581]\n",
      "epoch:28 step:26990 [D loss: 0.555127, acc.: 73.44%] [G loss: 0.727004]\n",
      "epoch:28 step:26991 [D loss: 0.517160, acc.: 71.88%] [G loss: 0.741931]\n",
      "epoch:28 step:26992 [D loss: 0.505418, acc.: 72.66%] [G loss: 0.582337]\n",
      "epoch:28 step:26993 [D loss: 0.558217, acc.: 69.53%] [G loss: 0.777142]\n",
      "epoch:28 step:26994 [D loss: 0.493719, acc.: 76.56%] [G loss: 0.791585]\n",
      "epoch:28 step:26995 [D loss: 0.536655, acc.: 71.88%] [G loss: 0.798610]\n",
      "epoch:28 step:26996 [D loss: 0.502929, acc.: 70.31%] [G loss: 0.690294]\n",
      "epoch:28 step:26997 [D loss: 0.558846, acc.: 70.31%] [G loss: 0.501015]\n",
      "epoch:28 step:26998 [D loss: 0.600834, acc.: 67.97%] [G loss: 0.677997]\n",
      "epoch:28 step:26999 [D loss: 0.493165, acc.: 74.22%] [G loss: 0.859598]\n",
      "epoch:28 step:27000 [D loss: 0.544038, acc.: 69.53%] [G loss: 0.655593]\n",
      "epoch:28 step:27001 [D loss: 0.570004, acc.: 72.66%] [G loss: 0.421095]\n",
      "epoch:28 step:27002 [D loss: 0.617993, acc.: 57.03%] [G loss: 0.582014]\n",
      "epoch:28 step:27003 [D loss: 0.539072, acc.: 71.88%] [G loss: 0.710113]\n",
      "epoch:28 step:27004 [D loss: 0.482448, acc.: 78.91%] [G loss: 0.694927]\n",
      "epoch:28 step:27005 [D loss: 0.534347, acc.: 73.44%] [G loss: 0.920718]\n",
      "epoch:28 step:27006 [D loss: 0.496158, acc.: 74.22%] [G loss: 0.890397]\n",
      "epoch:28 step:27007 [D loss: 0.485672, acc.: 76.56%] [G loss: 1.134308]\n",
      "epoch:28 step:27008 [D loss: 0.575469, acc.: 67.19%] [G loss: 0.809577]\n",
      "epoch:28 step:27009 [D loss: 0.563033, acc.: 66.41%] [G loss: 0.843165]\n",
      "epoch:28 step:27010 [D loss: 0.478766, acc.: 76.56%] [G loss: 0.697523]\n",
      "epoch:28 step:27011 [D loss: 0.452253, acc.: 76.56%] [G loss: 0.941620]\n",
      "epoch:28 step:27012 [D loss: 0.549479, acc.: 71.09%] [G loss: 0.635095]\n",
      "epoch:28 step:27013 [D loss: 0.542719, acc.: 71.09%] [G loss: 0.968777]\n",
      "epoch:28 step:27014 [D loss: 0.572651, acc.: 75.00%] [G loss: 0.656079]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:28 step:27015 [D loss: 0.534386, acc.: 71.09%] [G loss: 0.806248]\n",
      "epoch:28 step:27016 [D loss: 0.467388, acc.: 78.91%] [G loss: 0.716827]\n",
      "epoch:28 step:27017 [D loss: 0.439528, acc.: 75.78%] [G loss: 1.089760]\n",
      "epoch:28 step:27018 [D loss: 0.430046, acc.: 80.47%] [G loss: 1.040394]\n",
      "epoch:28 step:27019 [D loss: 0.507485, acc.: 75.00%] [G loss: 0.879667]\n",
      "epoch:28 step:27020 [D loss: 0.575840, acc.: 71.09%] [G loss: 0.681517]\n",
      "epoch:28 step:27021 [D loss: 0.520453, acc.: 74.22%] [G loss: 0.682930]\n",
      "epoch:28 step:27022 [D loss: 0.484635, acc.: 72.66%] [G loss: 0.711917]\n",
      "epoch:28 step:27023 [D loss: 0.574801, acc.: 68.75%] [G loss: 0.973299]\n",
      "epoch:28 step:27024 [D loss: 0.607733, acc.: 68.75%] [G loss: 0.668144]\n",
      "epoch:28 step:27025 [D loss: 0.484211, acc.: 75.78%] [G loss: 0.765744]\n",
      "epoch:28 step:27026 [D loss: 0.472484, acc.: 71.09%] [G loss: 0.742673]\n",
      "epoch:28 step:27027 [D loss: 0.560621, acc.: 69.53%] [G loss: 0.712141]\n",
      "epoch:28 step:27028 [D loss: 0.471881, acc.: 76.56%] [G loss: 0.785651]\n",
      "epoch:28 step:27029 [D loss: 0.575331, acc.: 71.09%] [G loss: 0.866318]\n",
      "epoch:28 step:27030 [D loss: 0.584873, acc.: 67.19%] [G loss: 0.816789]\n",
      "epoch:28 step:27031 [D loss: 0.530179, acc.: 69.53%] [G loss: 0.938892]\n",
      "epoch:28 step:27032 [D loss: 0.505113, acc.: 69.53%] [G loss: 0.839503]\n",
      "epoch:28 step:27033 [D loss: 0.527672, acc.: 67.97%] [G loss: 0.805040]\n",
      "epoch:28 step:27034 [D loss: 0.553978, acc.: 66.41%] [G loss: 0.657661]\n",
      "epoch:28 step:27035 [D loss: 0.547476, acc.: 72.66%] [G loss: 0.791224]\n",
      "epoch:28 step:27036 [D loss: 0.626206, acc.: 63.28%] [G loss: 0.549061]\n",
      "epoch:28 step:27037 [D loss: 0.540709, acc.: 70.31%] [G loss: 0.781661]\n",
      "epoch:28 step:27038 [D loss: 0.423609, acc.: 79.69%] [G loss: 0.863231]\n",
      "epoch:28 step:27039 [D loss: 0.459150, acc.: 75.78%] [G loss: 0.896804]\n",
      "epoch:28 step:27040 [D loss: 0.543474, acc.: 75.00%] [G loss: 0.661215]\n",
      "epoch:28 step:27041 [D loss: 0.555457, acc.: 65.62%] [G loss: 0.739600]\n",
      "epoch:28 step:27042 [D loss: 0.577290, acc.: 68.75%] [G loss: 0.666657]\n",
      "epoch:28 step:27043 [D loss: 0.537068, acc.: 69.53%] [G loss: 0.665568]\n",
      "epoch:28 step:27044 [D loss: 0.499102, acc.: 75.00%] [G loss: 0.639037]\n",
      "epoch:28 step:27045 [D loss: 0.489869, acc.: 77.34%] [G loss: 0.771857]\n",
      "epoch:28 step:27046 [D loss: 0.444149, acc.: 78.91%] [G loss: 0.722913]\n",
      "epoch:28 step:27047 [D loss: 0.577849, acc.: 67.97%] [G loss: 0.791609]\n",
      "epoch:28 step:27048 [D loss: 0.612282, acc.: 64.84%] [G loss: 0.674356]\n",
      "epoch:28 step:27049 [D loss: 0.520121, acc.: 70.31%] [G loss: 0.766918]\n",
      "epoch:28 step:27050 [D loss: 0.498213, acc.: 69.53%] [G loss: 0.816398]\n",
      "epoch:28 step:27051 [D loss: 0.505043, acc.: 72.66%] [G loss: 0.928746]\n",
      "epoch:28 step:27052 [D loss: 0.513638, acc.: 74.22%] [G loss: 0.931792]\n",
      "epoch:28 step:27053 [D loss: 0.585697, acc.: 72.66%] [G loss: 0.878354]\n",
      "epoch:28 step:27054 [D loss: 0.599170, acc.: 66.41%] [G loss: 0.775817]\n",
      "epoch:28 step:27055 [D loss: 0.520715, acc.: 74.22%] [G loss: 0.595016]\n",
      "epoch:28 step:27056 [D loss: 0.623969, acc.: 64.84%] [G loss: 0.584510]\n",
      "epoch:28 step:27057 [D loss: 0.495774, acc.: 75.78%] [G loss: 0.583603]\n",
      "epoch:28 step:27058 [D loss: 0.560456, acc.: 69.53%] [G loss: 0.699029]\n",
      "epoch:28 step:27059 [D loss: 0.437979, acc.: 78.12%] [G loss: 0.758278]\n",
      "epoch:28 step:27060 [D loss: 0.540640, acc.: 70.31%] [G loss: 0.672963]\n",
      "epoch:28 step:27061 [D loss: 0.493947, acc.: 73.44%] [G loss: 0.787478]\n",
      "epoch:28 step:27062 [D loss: 0.479433, acc.: 78.91%] [G loss: 0.776992]\n",
      "epoch:28 step:27063 [D loss: 0.588547, acc.: 64.84%] [G loss: 0.721436]\n",
      "epoch:28 step:27064 [D loss: 0.580264, acc.: 69.53%] [G loss: 0.741314]\n",
      "epoch:28 step:27065 [D loss: 0.541393, acc.: 68.75%] [G loss: 0.697250]\n",
      "epoch:28 step:27066 [D loss: 0.492543, acc.: 71.09%] [G loss: 0.740831]\n",
      "epoch:28 step:27067 [D loss: 0.563493, acc.: 67.97%] [G loss: 0.587064]\n",
      "epoch:28 step:27068 [D loss: 0.514168, acc.: 72.66%] [G loss: 0.600240]\n",
      "epoch:28 step:27069 [D loss: 0.480995, acc.: 78.91%] [G loss: 0.665564]\n",
      "epoch:28 step:27070 [D loss: 0.512909, acc.: 69.53%] [G loss: 0.741555]\n",
      "epoch:28 step:27071 [D loss: 0.555846, acc.: 64.84%] [G loss: 0.532070]\n",
      "epoch:28 step:27072 [D loss: 0.558908, acc.: 71.09%] [G loss: 0.534446]\n",
      "epoch:28 step:27073 [D loss: 0.511886, acc.: 73.44%] [G loss: 0.626781]\n",
      "epoch:28 step:27074 [D loss: 0.541645, acc.: 69.53%] [G loss: 0.490307]\n",
      "epoch:28 step:27075 [D loss: 0.527644, acc.: 68.75%] [G loss: 0.687112]\n",
      "epoch:28 step:27076 [D loss: 0.556164, acc.: 68.75%] [G loss: 0.536548]\n",
      "epoch:28 step:27077 [D loss: 0.543098, acc.: 71.88%] [G loss: 0.581873]\n",
      "epoch:28 step:27078 [D loss: 0.462929, acc.: 77.34%] [G loss: 0.820375]\n",
      "epoch:28 step:27079 [D loss: 0.461738, acc.: 78.91%] [G loss: 0.700174]\n",
      "epoch:28 step:27080 [D loss: 0.548510, acc.: 65.62%] [G loss: 0.507640]\n",
      "epoch:28 step:27081 [D loss: 0.526371, acc.: 74.22%] [G loss: 0.583464]\n",
      "epoch:28 step:27082 [D loss: 0.555391, acc.: 70.31%] [G loss: 0.643539]\n",
      "epoch:28 step:27083 [D loss: 0.587622, acc.: 62.50%] [G loss: 0.587158]\n",
      "epoch:28 step:27084 [D loss: 0.511675, acc.: 73.44%] [G loss: 0.550000]\n",
      "epoch:28 step:27085 [D loss: 0.472020, acc.: 77.34%] [G loss: 0.893689]\n",
      "epoch:28 step:27086 [D loss: 0.538672, acc.: 67.97%] [G loss: 0.672516]\n",
      "epoch:28 step:27087 [D loss: 0.562977, acc.: 66.41%] [G loss: 0.767179]\n",
      "epoch:28 step:27088 [D loss: 0.483046, acc.: 74.22%] [G loss: 0.700647]\n",
      "epoch:28 step:27089 [D loss: 0.517332, acc.: 69.53%] [G loss: 0.748631]\n",
      "epoch:28 step:27090 [D loss: 0.481997, acc.: 77.34%] [G loss: 0.744694]\n",
      "epoch:28 step:27091 [D loss: 0.550124, acc.: 66.41%] [G loss: 0.542612]\n",
      "epoch:28 step:27092 [D loss: 0.559786, acc.: 70.31%] [G loss: 0.839304]\n",
      "epoch:28 step:27093 [D loss: 0.453164, acc.: 79.69%] [G loss: 0.893192]\n",
      "epoch:28 step:27094 [D loss: 0.628408, acc.: 63.28%] [G loss: 0.653541]\n",
      "epoch:28 step:27095 [D loss: 0.529455, acc.: 70.31%] [G loss: 0.732851]\n",
      "epoch:28 step:27096 [D loss: 0.456657, acc.: 74.22%] [G loss: 0.991820]\n",
      "epoch:28 step:27097 [D loss: 0.587537, acc.: 66.41%] [G loss: 0.740170]\n",
      "epoch:28 step:27098 [D loss: 0.548708, acc.: 67.97%] [G loss: 0.595499]\n",
      "epoch:28 step:27099 [D loss: 0.538143, acc.: 67.97%] [G loss: 0.679630]\n",
      "epoch:28 step:27100 [D loss: 0.521854, acc.: 72.66%] [G loss: 0.661243]\n",
      "epoch:28 step:27101 [D loss: 0.588953, acc.: 66.41%] [G loss: 0.603948]\n",
      "epoch:28 step:27102 [D loss: 0.519602, acc.: 70.31%] [G loss: 0.664928]\n",
      "epoch:28 step:27103 [D loss: 0.649886, acc.: 58.59%] [G loss: 0.571438]\n",
      "epoch:28 step:27104 [D loss: 0.529406, acc.: 72.66%] [G loss: 0.571392]\n",
      "epoch:28 step:27105 [D loss: 0.523302, acc.: 67.97%] [G loss: 0.666114]\n",
      "epoch:28 step:27106 [D loss: 0.452882, acc.: 78.91%] [G loss: 0.876001]\n",
      "epoch:28 step:27107 [D loss: 0.513023, acc.: 68.75%] [G loss: 0.842236]\n",
      "epoch:28 step:27108 [D loss: 0.512105, acc.: 73.44%] [G loss: 0.886565]\n",
      "epoch:28 step:27109 [D loss: 0.635897, acc.: 64.06%] [G loss: 0.659020]\n",
      "epoch:28 step:27110 [D loss: 0.515902, acc.: 74.22%] [G loss: 0.589035]\n",
      "epoch:28 step:27111 [D loss: 0.458772, acc.: 78.91%] [G loss: 0.802336]\n",
      "epoch:28 step:27112 [D loss: 0.528023, acc.: 71.09%] [G loss: 0.884108]\n",
      "epoch:28 step:27113 [D loss: 0.555562, acc.: 70.31%] [G loss: 0.630208]\n",
      "epoch:28 step:27114 [D loss: 0.501011, acc.: 75.00%] [G loss: 0.657386]\n",
      "epoch:28 step:27115 [D loss: 0.516114, acc.: 72.66%] [G loss: 0.685997]\n",
      "epoch:28 step:27116 [D loss: 0.601397, acc.: 64.84%] [G loss: 0.487202]\n",
      "epoch:28 step:27117 [D loss: 0.544439, acc.: 71.09%] [G loss: 0.459753]\n",
      "epoch:28 step:27118 [D loss: 0.594476, acc.: 67.97%] [G loss: 0.503240]\n",
      "epoch:28 step:27119 [D loss: 0.586591, acc.: 71.88%] [G loss: 0.585849]\n",
      "epoch:28 step:27120 [D loss: 0.524977, acc.: 74.22%] [G loss: 0.569104]\n",
      "epoch:28 step:27121 [D loss: 0.492804, acc.: 75.00%] [G loss: 0.849877]\n",
      "epoch:28 step:27122 [D loss: 0.536495, acc.: 72.66%] [G loss: 0.684829]\n",
      "epoch:28 step:27123 [D loss: 0.515038, acc.: 71.88%] [G loss: 0.836696]\n",
      "epoch:28 step:27124 [D loss: 0.545219, acc.: 68.75%] [G loss: 0.899150]\n",
      "epoch:28 step:27125 [D loss: 0.570017, acc.: 64.06%] [G loss: 0.725730]\n",
      "epoch:28 step:27126 [D loss: 0.483653, acc.: 75.78%] [G loss: 0.845282]\n",
      "epoch:28 step:27127 [D loss: 0.557930, acc.: 70.31%] [G loss: 0.606159]\n",
      "epoch:28 step:27128 [D loss: 0.601038, acc.: 67.97%] [G loss: 0.606416]\n",
      "epoch:28 step:27129 [D loss: 0.527350, acc.: 71.09%] [G loss: 0.612100]\n",
      "epoch:28 step:27130 [D loss: 0.456542, acc.: 78.12%] [G loss: 0.741207]\n",
      "epoch:28 step:27131 [D loss: 0.541962, acc.: 68.75%] [G loss: 0.783193]\n",
      "epoch:28 step:27132 [D loss: 0.443928, acc.: 78.12%] [G loss: 0.837790]\n",
      "epoch:28 step:27133 [D loss: 0.513935, acc.: 75.00%] [G loss: 0.795165]\n",
      "epoch:28 step:27134 [D loss: 0.445755, acc.: 75.00%] [G loss: 1.006497]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:28 step:27135 [D loss: 0.460101, acc.: 78.12%] [G loss: 0.863786]\n",
      "epoch:28 step:27136 [D loss: 0.492764, acc.: 76.56%] [G loss: 0.815175]\n",
      "epoch:28 step:27137 [D loss: 0.533066, acc.: 71.88%] [G loss: 0.834043]\n",
      "epoch:28 step:27138 [D loss: 0.580186, acc.: 68.75%] [G loss: 0.638576]\n",
      "epoch:28 step:27139 [D loss: 0.509089, acc.: 72.66%] [G loss: 0.581703]\n",
      "epoch:28 step:27140 [D loss: 0.569129, acc.: 67.97%] [G loss: 0.688650]\n",
      "epoch:28 step:27141 [D loss: 0.586994, acc.: 68.75%] [G loss: 0.805413]\n",
      "epoch:28 step:27142 [D loss: 0.459477, acc.: 79.69%] [G loss: 0.798830]\n",
      "epoch:28 step:27143 [D loss: 0.507643, acc.: 75.78%] [G loss: 0.785600]\n",
      "epoch:28 step:27144 [D loss: 0.494654, acc.: 76.56%] [G loss: 0.750959]\n",
      "epoch:28 step:27145 [D loss: 0.469882, acc.: 78.12%] [G loss: 0.804294]\n",
      "epoch:28 step:27146 [D loss: 0.596327, acc.: 70.31%] [G loss: 0.702147]\n",
      "epoch:28 step:27147 [D loss: 0.445427, acc.: 81.25%] [G loss: 0.886714]\n",
      "epoch:28 step:27148 [D loss: 0.468825, acc.: 79.69%] [G loss: 0.901123]\n",
      "epoch:28 step:27149 [D loss: 0.496179, acc.: 75.00%] [G loss: 0.755239]\n",
      "epoch:28 step:27150 [D loss: 0.462257, acc.: 75.00%] [G loss: 0.840203]\n",
      "epoch:28 step:27151 [D loss: 0.632172, acc.: 66.41%] [G loss: 0.832340]\n",
      "epoch:28 step:27152 [D loss: 0.472597, acc.: 78.91%] [G loss: 0.927478]\n",
      "epoch:28 step:27153 [D loss: 0.536925, acc.: 67.97%] [G loss: 0.765749]\n",
      "epoch:28 step:27154 [D loss: 0.443473, acc.: 79.69%] [G loss: 0.893634]\n",
      "epoch:28 step:27155 [D loss: 0.471642, acc.: 80.47%] [G loss: 1.161412]\n",
      "epoch:28 step:27156 [D loss: 0.636250, acc.: 67.19%] [G loss: 0.760631]\n",
      "epoch:28 step:27157 [D loss: 0.458560, acc.: 78.12%] [G loss: 1.013097]\n",
      "epoch:28 step:27158 [D loss: 0.494547, acc.: 71.88%] [G loss: 0.917905]\n",
      "epoch:28 step:27159 [D loss: 0.388105, acc.: 82.03%] [G loss: 0.981856]\n",
      "epoch:28 step:27160 [D loss: 0.430180, acc.: 79.69%] [G loss: 1.172542]\n",
      "epoch:28 step:27161 [D loss: 0.397811, acc.: 81.25%] [G loss: 1.373409]\n",
      "epoch:28 step:27162 [D loss: 0.437505, acc.: 78.12%] [G loss: 1.247068]\n",
      "epoch:28 step:27163 [D loss: 0.505485, acc.: 75.00%] [G loss: 1.215848]\n",
      "epoch:28 step:27164 [D loss: 0.740446, acc.: 60.16%] [G loss: 1.185297]\n",
      "epoch:28 step:27165 [D loss: 0.563971, acc.: 67.19%] [G loss: 1.353122]\n",
      "epoch:28 step:27166 [D loss: 0.425070, acc.: 80.47%] [G loss: 1.282968]\n",
      "epoch:28 step:27167 [D loss: 0.544234, acc.: 71.88%] [G loss: 1.097095]\n",
      "epoch:28 step:27168 [D loss: 0.581274, acc.: 64.84%] [G loss: 0.853828]\n",
      "epoch:28 step:27169 [D loss: 0.487204, acc.: 74.22%] [G loss: 1.019663]\n",
      "epoch:28 step:27170 [D loss: 0.505289, acc.: 73.44%] [G loss: 0.969908]\n",
      "epoch:28 step:27171 [D loss: 0.507403, acc.: 71.88%] [G loss: 0.996057]\n",
      "epoch:28 step:27172 [D loss: 0.459392, acc.: 77.34%] [G loss: 0.997343]\n",
      "epoch:28 step:27173 [D loss: 0.390633, acc.: 86.72%] [G loss: 1.573709]\n",
      "epoch:29 step:27174 [D loss: 0.557221, acc.: 70.31%] [G loss: 1.330656]\n",
      "epoch:29 step:27175 [D loss: 0.394542, acc.: 81.25%] [G loss: 1.420385]\n",
      "epoch:29 step:27176 [D loss: 0.563686, acc.: 70.31%] [G loss: 1.202724]\n",
      "epoch:29 step:27177 [D loss: 0.496806, acc.: 73.44%] [G loss: 1.054253]\n",
      "epoch:29 step:27178 [D loss: 0.579892, acc.: 66.41%] [G loss: 0.821489]\n",
      "epoch:29 step:27179 [D loss: 0.579646, acc.: 65.62%] [G loss: 0.908874]\n",
      "epoch:29 step:27180 [D loss: 0.521118, acc.: 78.12%] [G loss: 0.792122]\n",
      "epoch:29 step:27181 [D loss: 0.476652, acc.: 72.66%] [G loss: 0.836955]\n",
      "epoch:29 step:27182 [D loss: 0.507677, acc.: 75.00%] [G loss: 0.955111]\n",
      "epoch:29 step:27183 [D loss: 0.469926, acc.: 77.34%] [G loss: 0.947700]\n",
      "epoch:29 step:27184 [D loss: 0.441248, acc.: 78.91%] [G loss: 0.937274]\n",
      "epoch:29 step:27185 [D loss: 0.572219, acc.: 70.31%] [G loss: 0.964541]\n",
      "epoch:29 step:27186 [D loss: 0.509260, acc.: 72.66%] [G loss: 0.980824]\n",
      "epoch:29 step:27187 [D loss: 0.544838, acc.: 69.53%] [G loss: 0.721038]\n",
      "epoch:29 step:27188 [D loss: 0.520189, acc.: 71.88%] [G loss: 0.907987]\n",
      "epoch:29 step:27189 [D loss: 0.473785, acc.: 78.91%] [G loss: 1.008476]\n",
      "epoch:29 step:27190 [D loss: 0.564706, acc.: 68.75%] [G loss: 0.785145]\n",
      "epoch:29 step:27191 [D loss: 0.504526, acc.: 73.44%] [G loss: 0.712760]\n",
      "epoch:29 step:27192 [D loss: 0.554857, acc.: 68.75%] [G loss: 0.859776]\n",
      "epoch:29 step:27193 [D loss: 0.617220, acc.: 67.19%] [G loss: 0.815857]\n",
      "epoch:29 step:27194 [D loss: 0.559958, acc.: 67.97%] [G loss: 0.832155]\n",
      "epoch:29 step:27195 [D loss: 0.487347, acc.: 74.22%] [G loss: 1.168198]\n",
      "epoch:29 step:27196 [D loss: 0.549372, acc.: 69.53%] [G loss: 0.906612]\n",
      "epoch:29 step:27197 [D loss: 0.519901, acc.: 65.62%] [G loss: 0.676148]\n",
      "epoch:29 step:27198 [D loss: 0.466607, acc.: 78.12%] [G loss: 0.746482]\n",
      "epoch:29 step:27199 [D loss: 0.563394, acc.: 68.75%] [G loss: 0.617694]\n",
      "epoch:29 step:27200 [D loss: 0.441074, acc.: 80.47%] [G loss: 0.811933]\n",
      "epoch:29 step:27201 [D loss: 0.562303, acc.: 70.31%] [G loss: 0.791911]\n",
      "epoch:29 step:27202 [D loss: 0.505614, acc.: 78.12%] [G loss: 0.843233]\n",
      "epoch:29 step:27203 [D loss: 0.518074, acc.: 70.31%] [G loss: 0.773573]\n",
      "epoch:29 step:27204 [D loss: 0.605331, acc.: 65.62%] [G loss: 0.775311]\n",
      "epoch:29 step:27205 [D loss: 0.520903, acc.: 64.84%] [G loss: 0.607509]\n",
      "epoch:29 step:27206 [D loss: 0.507699, acc.: 72.66%] [G loss: 0.725829]\n",
      "epoch:29 step:27207 [D loss: 0.539811, acc.: 67.97%] [G loss: 0.747075]\n",
      "epoch:29 step:27208 [D loss: 0.494426, acc.: 78.12%] [G loss: 0.616588]\n",
      "epoch:29 step:27209 [D loss: 0.492445, acc.: 73.44%] [G loss: 0.757281]\n",
      "epoch:29 step:27210 [D loss: 0.478766, acc.: 76.56%] [G loss: 0.668824]\n",
      "epoch:29 step:27211 [D loss: 0.500952, acc.: 71.09%] [G loss: 0.676978]\n",
      "epoch:29 step:27212 [D loss: 0.582099, acc.: 67.19%] [G loss: 0.660102]\n",
      "epoch:29 step:27213 [D loss: 0.495382, acc.: 76.56%] [G loss: 0.778384]\n",
      "epoch:29 step:27214 [D loss: 0.510102, acc.: 72.66%] [G loss: 0.858592]\n",
      "epoch:29 step:27215 [D loss: 0.525997, acc.: 75.78%] [G loss: 0.811856]\n",
      "epoch:29 step:27216 [D loss: 0.500640, acc.: 75.00%] [G loss: 0.815159]\n",
      "epoch:29 step:27217 [D loss: 0.559558, acc.: 66.41%] [G loss: 0.652904]\n",
      "epoch:29 step:27218 [D loss: 0.481510, acc.: 73.44%] [G loss: 0.846696]\n",
      "epoch:29 step:27219 [D loss: 0.485028, acc.: 73.44%] [G loss: 0.821156]\n",
      "epoch:29 step:27220 [D loss: 0.529719, acc.: 69.53%] [G loss: 0.779136]\n",
      "epoch:29 step:27221 [D loss: 0.522739, acc.: 71.88%] [G loss: 0.700047]\n",
      "epoch:29 step:27222 [D loss: 0.446650, acc.: 79.69%] [G loss: 0.901840]\n",
      "epoch:29 step:27223 [D loss: 0.547806, acc.: 73.44%] [G loss: 0.775979]\n",
      "epoch:29 step:27224 [D loss: 0.594203, acc.: 64.84%] [G loss: 0.681982]\n",
      "epoch:29 step:27225 [D loss: 0.561960, acc.: 71.09%] [G loss: 0.716011]\n",
      "epoch:29 step:27226 [D loss: 0.510354, acc.: 69.53%] [G loss: 0.583814]\n",
      "epoch:29 step:27227 [D loss: 0.421204, acc.: 83.59%] [G loss: 0.850498]\n",
      "epoch:29 step:27228 [D loss: 0.540674, acc.: 71.09%] [G loss: 0.898457]\n",
      "epoch:29 step:27229 [D loss: 0.430309, acc.: 79.69%] [G loss: 0.758570]\n",
      "epoch:29 step:27230 [D loss: 0.532784, acc.: 70.31%] [G loss: 0.863366]\n",
      "epoch:29 step:27231 [D loss: 0.624025, acc.: 70.31%] [G loss: 0.710516]\n",
      "epoch:29 step:27232 [D loss: 0.458306, acc.: 78.91%] [G loss: 0.938695]\n",
      "epoch:29 step:27233 [D loss: 0.514460, acc.: 71.09%] [G loss: 0.872987]\n",
      "epoch:29 step:27234 [D loss: 0.562960, acc.: 69.53%] [G loss: 0.764027]\n",
      "epoch:29 step:27235 [D loss: 0.542367, acc.: 74.22%] [G loss: 0.667978]\n",
      "epoch:29 step:27236 [D loss: 0.495084, acc.: 74.22%] [G loss: 0.771697]\n",
      "epoch:29 step:27237 [D loss: 0.571940, acc.: 67.19%] [G loss: 0.683595]\n",
      "epoch:29 step:27238 [D loss: 0.483257, acc.: 75.78%] [G loss: 0.711200]\n",
      "epoch:29 step:27239 [D loss: 0.523238, acc.: 67.97%] [G loss: 0.729393]\n",
      "epoch:29 step:27240 [D loss: 0.475059, acc.: 73.44%] [G loss: 0.838819]\n",
      "epoch:29 step:27241 [D loss: 0.523188, acc.: 72.66%] [G loss: 0.561359]\n",
      "epoch:29 step:27242 [D loss: 0.455377, acc.: 82.03%] [G loss: 0.873250]\n",
      "epoch:29 step:27243 [D loss: 0.494556, acc.: 77.34%] [G loss: 0.690864]\n",
      "epoch:29 step:27244 [D loss: 0.490635, acc.: 73.44%] [G loss: 0.776643]\n",
      "epoch:29 step:27245 [D loss: 0.529987, acc.: 69.53%] [G loss: 0.616024]\n",
      "epoch:29 step:27246 [D loss: 0.545364, acc.: 70.31%] [G loss: 0.508358]\n",
      "epoch:29 step:27247 [D loss: 0.458975, acc.: 78.91%] [G loss: 0.846406]\n",
      "epoch:29 step:27248 [D loss: 0.515752, acc.: 74.22%] [G loss: 0.772686]\n",
      "epoch:29 step:27249 [D loss: 0.498208, acc.: 72.66%] [G loss: 0.848431]\n",
      "epoch:29 step:27250 [D loss: 0.411493, acc.: 78.91%] [G loss: 1.056220]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:29 step:27251 [D loss: 0.545225, acc.: 71.88%] [G loss: 0.694273]\n",
      "epoch:29 step:27252 [D loss: 0.504777, acc.: 74.22%] [G loss: 0.926753]\n",
      "epoch:29 step:27253 [D loss: 0.460754, acc.: 76.56%] [G loss: 0.819097]\n",
      "epoch:29 step:27254 [D loss: 0.516837, acc.: 72.66%] [G loss: 0.798125]\n",
      "epoch:29 step:27255 [D loss: 0.510794, acc.: 71.09%] [G loss: 0.763827]\n",
      "epoch:29 step:27256 [D loss: 0.485217, acc.: 77.34%] [G loss: 0.799674]\n",
      "epoch:29 step:27257 [D loss: 0.518503, acc.: 69.53%] [G loss: 0.849361]\n",
      "epoch:29 step:27258 [D loss: 0.618707, acc.: 62.50%] [G loss: 0.698115]\n",
      "epoch:29 step:27259 [D loss: 0.471652, acc.: 74.22%] [G loss: 0.871974]\n",
      "epoch:29 step:27260 [D loss: 0.523521, acc.: 72.66%] [G loss: 0.704137]\n",
      "epoch:29 step:27261 [D loss: 0.477982, acc.: 77.34%] [G loss: 0.693054]\n",
      "epoch:29 step:27262 [D loss: 0.484171, acc.: 77.34%] [G loss: 0.813237]\n",
      "epoch:29 step:27263 [D loss: 0.499670, acc.: 70.31%] [G loss: 0.890617]\n",
      "epoch:29 step:27264 [D loss: 0.595289, acc.: 70.31%] [G loss: 0.870435]\n",
      "epoch:29 step:27265 [D loss: 0.453445, acc.: 78.12%] [G loss: 0.738024]\n",
      "epoch:29 step:27266 [D loss: 0.491250, acc.: 75.78%] [G loss: 0.774864]\n",
      "epoch:29 step:27267 [D loss: 0.462237, acc.: 74.22%] [G loss: 0.939701]\n",
      "epoch:29 step:27268 [D loss: 0.556310, acc.: 68.75%] [G loss: 0.839804]\n",
      "epoch:29 step:27269 [D loss: 0.513612, acc.: 74.22%] [G loss: 0.925151]\n",
      "epoch:29 step:27270 [D loss: 0.433564, acc.: 79.69%] [G loss: 0.916829]\n",
      "epoch:29 step:27271 [D loss: 0.543338, acc.: 74.22%] [G loss: 0.923961]\n",
      "epoch:29 step:27272 [D loss: 0.511810, acc.: 72.66%] [G loss: 0.774380]\n",
      "epoch:29 step:27273 [D loss: 0.468657, acc.: 77.34%] [G loss: 1.021230]\n",
      "epoch:29 step:27274 [D loss: 0.485431, acc.: 78.12%] [G loss: 0.894832]\n",
      "epoch:29 step:27275 [D loss: 0.577522, acc.: 71.09%] [G loss: 0.802601]\n",
      "epoch:29 step:27276 [D loss: 0.508412, acc.: 71.88%] [G loss: 0.725582]\n",
      "epoch:29 step:27277 [D loss: 0.434233, acc.: 79.69%] [G loss: 0.802600]\n",
      "epoch:29 step:27278 [D loss: 0.591293, acc.: 64.84%] [G loss: 0.805435]\n",
      "epoch:29 step:27279 [D loss: 0.527905, acc.: 70.31%] [G loss: 0.739413]\n",
      "epoch:29 step:27280 [D loss: 0.504287, acc.: 74.22%] [G loss: 0.857338]\n",
      "epoch:29 step:27281 [D loss: 0.569390, acc.: 68.75%] [G loss: 0.771839]\n",
      "epoch:29 step:27282 [D loss: 0.553640, acc.: 67.19%] [G loss: 0.791549]\n",
      "epoch:29 step:27283 [D loss: 0.496419, acc.: 76.56%] [G loss: 0.743452]\n",
      "epoch:29 step:27284 [D loss: 0.515828, acc.: 72.66%] [G loss: 0.760203]\n",
      "epoch:29 step:27285 [D loss: 0.515114, acc.: 71.88%] [G loss: 0.771359]\n",
      "epoch:29 step:27286 [D loss: 0.482956, acc.: 75.78%] [G loss: 0.880839]\n",
      "epoch:29 step:27287 [D loss: 0.572954, acc.: 69.53%] [G loss: 0.664665]\n",
      "epoch:29 step:27288 [D loss: 0.483411, acc.: 74.22%] [G loss: 0.860937]\n",
      "epoch:29 step:27289 [D loss: 0.515995, acc.: 70.31%] [G loss: 0.839452]\n",
      "epoch:29 step:27290 [D loss: 0.524439, acc.: 71.88%] [G loss: 0.765046]\n",
      "epoch:29 step:27291 [D loss: 0.535829, acc.: 70.31%] [G loss: 1.123003]\n",
      "epoch:29 step:27292 [D loss: 0.463366, acc.: 77.34%] [G loss: 0.956591]\n",
      "epoch:29 step:27293 [D loss: 0.588278, acc.: 73.44%] [G loss: 0.757434]\n",
      "epoch:29 step:27294 [D loss: 0.495764, acc.: 74.22%] [G loss: 0.849272]\n",
      "epoch:29 step:27295 [D loss: 0.461944, acc.: 78.12%] [G loss: 0.960318]\n",
      "epoch:29 step:27296 [D loss: 0.446672, acc.: 75.00%] [G loss: 0.943550]\n",
      "epoch:29 step:27297 [D loss: 0.532229, acc.: 72.66%] [G loss: 0.982175]\n",
      "epoch:29 step:27298 [D loss: 0.564952, acc.: 70.31%] [G loss: 0.786528]\n",
      "epoch:29 step:27299 [D loss: 0.530324, acc.: 71.88%] [G loss: 0.652184]\n",
      "epoch:29 step:27300 [D loss: 0.421903, acc.: 78.12%] [G loss: 0.760685]\n",
      "epoch:29 step:27301 [D loss: 0.461624, acc.: 75.00%] [G loss: 0.814742]\n",
      "epoch:29 step:27302 [D loss: 0.527631, acc.: 71.88%] [G loss: 0.889303]\n",
      "epoch:29 step:27303 [D loss: 0.487284, acc.: 74.22%] [G loss: 0.941609]\n",
      "epoch:29 step:27304 [D loss: 0.486454, acc.: 75.78%] [G loss: 0.846073]\n",
      "epoch:29 step:27305 [D loss: 0.514403, acc.: 75.00%] [G loss: 0.770030]\n",
      "epoch:29 step:27306 [D loss: 0.633407, acc.: 62.50%] [G loss: 0.818874]\n",
      "epoch:29 step:27307 [D loss: 0.512161, acc.: 70.31%] [G loss: 1.000646]\n",
      "epoch:29 step:27308 [D loss: 0.509591, acc.: 71.09%] [G loss: 1.073837]\n",
      "epoch:29 step:27309 [D loss: 0.509109, acc.: 73.44%] [G loss: 0.930580]\n",
      "epoch:29 step:27310 [D loss: 0.610178, acc.: 70.31%] [G loss: 0.866043]\n",
      "epoch:29 step:27311 [D loss: 0.537455, acc.: 68.75%] [G loss: 0.745876]\n",
      "epoch:29 step:27312 [D loss: 0.566806, acc.: 68.75%] [G loss: 0.710297]\n",
      "epoch:29 step:27313 [D loss: 0.611284, acc.: 67.19%] [G loss: 0.611827]\n",
      "epoch:29 step:27314 [D loss: 0.484992, acc.: 75.00%] [G loss: 0.658681]\n",
      "epoch:29 step:27315 [D loss: 0.521321, acc.: 68.75%] [G loss: 0.767424]\n",
      "epoch:29 step:27316 [D loss: 0.560528, acc.: 70.31%] [G loss: 0.662107]\n",
      "epoch:29 step:27317 [D loss: 0.540482, acc.: 72.66%] [G loss: 0.724882]\n",
      "epoch:29 step:27318 [D loss: 0.521145, acc.: 73.44%] [G loss: 0.821171]\n",
      "epoch:29 step:27319 [D loss: 0.436111, acc.: 82.03%] [G loss: 1.010335]\n",
      "epoch:29 step:27320 [D loss: 0.645656, acc.: 67.19%] [G loss: 0.826705]\n",
      "epoch:29 step:27321 [D loss: 0.554379, acc.: 66.41%] [G loss: 0.624809]\n",
      "epoch:29 step:27322 [D loss: 0.513388, acc.: 70.31%] [G loss: 0.720436]\n",
      "epoch:29 step:27323 [D loss: 0.580454, acc.: 66.41%] [G loss: 0.696128]\n",
      "epoch:29 step:27324 [D loss: 0.514055, acc.: 72.66%] [G loss: 0.793017]\n",
      "epoch:29 step:27325 [D loss: 0.431506, acc.: 85.16%] [G loss: 0.881398]\n",
      "epoch:29 step:27326 [D loss: 0.586001, acc.: 64.84%] [G loss: 0.758592]\n",
      "epoch:29 step:27327 [D loss: 0.633818, acc.: 67.19%] [G loss: 0.792789]\n",
      "epoch:29 step:27328 [D loss: 0.474211, acc.: 71.88%] [G loss: 0.745905]\n",
      "epoch:29 step:27329 [D loss: 0.464140, acc.: 78.12%] [G loss: 0.746053]\n",
      "epoch:29 step:27330 [D loss: 0.568621, acc.: 68.75%] [G loss: 0.811077]\n",
      "epoch:29 step:27331 [D loss: 0.519555, acc.: 73.44%] [G loss: 0.825866]\n",
      "epoch:29 step:27332 [D loss: 0.447582, acc.: 78.12%] [G loss: 0.679611]\n",
      "epoch:29 step:27333 [D loss: 0.598928, acc.: 67.19%] [G loss: 0.775378]\n",
      "epoch:29 step:27334 [D loss: 0.536417, acc.: 71.09%] [G loss: 0.814634]\n",
      "epoch:29 step:27335 [D loss: 0.474419, acc.: 73.44%] [G loss: 0.798108]\n",
      "epoch:29 step:27336 [D loss: 0.557539, acc.: 68.75%] [G loss: 1.082627]\n",
      "epoch:29 step:27337 [D loss: 0.505756, acc.: 75.78%] [G loss: 0.917337]\n",
      "epoch:29 step:27338 [D loss: 0.517258, acc.: 74.22%] [G loss: 0.893319]\n",
      "epoch:29 step:27339 [D loss: 0.506546, acc.: 71.09%] [G loss: 0.810559]\n",
      "epoch:29 step:27340 [D loss: 0.500998, acc.: 76.56%] [G loss: 0.694656]\n",
      "epoch:29 step:27341 [D loss: 0.522889, acc.: 72.66%] [G loss: 0.592162]\n",
      "epoch:29 step:27342 [D loss: 0.548585, acc.: 70.31%] [G loss: 0.529917]\n",
      "epoch:29 step:27343 [D loss: 0.497078, acc.: 71.09%] [G loss: 0.587668]\n",
      "epoch:29 step:27344 [D loss: 0.541380, acc.: 71.88%] [G loss: 0.715874]\n",
      "epoch:29 step:27345 [D loss: 0.426800, acc.: 82.03%] [G loss: 0.712364]\n",
      "epoch:29 step:27346 [D loss: 0.464944, acc.: 77.34%] [G loss: 1.006584]\n",
      "epoch:29 step:27347 [D loss: 0.563004, acc.: 70.31%] [G loss: 0.747412]\n",
      "epoch:29 step:27348 [D loss: 0.615429, acc.: 63.28%] [G loss: 0.543952]\n",
      "epoch:29 step:27349 [D loss: 0.526092, acc.: 70.31%] [G loss: 0.567661]\n",
      "epoch:29 step:27350 [D loss: 0.524415, acc.: 71.09%] [G loss: 0.741451]\n",
      "epoch:29 step:27351 [D loss: 0.564574, acc.: 68.75%] [G loss: 0.675522]\n",
      "epoch:29 step:27352 [D loss: 0.548286, acc.: 65.62%] [G loss: 0.708547]\n",
      "epoch:29 step:27353 [D loss: 0.614642, acc.: 61.72%] [G loss: 0.727971]\n",
      "epoch:29 step:27354 [D loss: 0.583368, acc.: 68.75%] [G loss: 0.733179]\n",
      "epoch:29 step:27355 [D loss: 0.505028, acc.: 75.00%] [G loss: 0.876010]\n",
      "epoch:29 step:27356 [D loss: 0.529639, acc.: 72.66%] [G loss: 0.774501]\n",
      "epoch:29 step:27357 [D loss: 0.481891, acc.: 75.78%] [G loss: 0.659672]\n",
      "epoch:29 step:27358 [D loss: 0.564282, acc.: 71.09%] [G loss: 0.829577]\n",
      "epoch:29 step:27359 [D loss: 0.529849, acc.: 72.66%] [G loss: 0.618778]\n",
      "epoch:29 step:27360 [D loss: 0.576301, acc.: 64.06%] [G loss: 0.745103]\n",
      "epoch:29 step:27361 [D loss: 0.525521, acc.: 71.88%] [G loss: 0.703271]\n",
      "epoch:29 step:27362 [D loss: 0.517620, acc.: 74.22%] [G loss: 0.742112]\n",
      "epoch:29 step:27363 [D loss: 0.458519, acc.: 78.12%] [G loss: 0.635291]\n",
      "epoch:29 step:27364 [D loss: 0.469108, acc.: 74.22%] [G loss: 0.908320]\n",
      "epoch:29 step:27365 [D loss: 0.565478, acc.: 67.97%] [G loss: 0.652414]\n",
      "epoch:29 step:27366 [D loss: 0.515807, acc.: 75.00%] [G loss: 0.702821]\n",
      "epoch:29 step:27367 [D loss: 0.431990, acc.: 84.38%] [G loss: 0.698072]\n",
      "epoch:29 step:27368 [D loss: 0.557797, acc.: 71.09%] [G loss: 0.866737]\n",
      "epoch:29 step:27369 [D loss: 0.595994, acc.: 63.28%] [G loss: 0.714758]\n",
      "epoch:29 step:27370 [D loss: 0.464373, acc.: 78.91%] [G loss: 0.925947]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:29 step:27371 [D loss: 0.427830, acc.: 81.25%] [G loss: 1.052873]\n",
      "epoch:29 step:27372 [D loss: 0.479071, acc.: 72.66%] [G loss: 0.916787]\n",
      "epoch:29 step:27373 [D loss: 0.598085, acc.: 66.41%] [G loss: 0.762906]\n",
      "epoch:29 step:27374 [D loss: 0.567586, acc.: 69.53%] [G loss: 0.732218]\n",
      "epoch:29 step:27375 [D loss: 0.531002, acc.: 69.53%] [G loss: 0.770558]\n",
      "epoch:29 step:27376 [D loss: 0.540237, acc.: 70.31%] [G loss: 0.833547]\n",
      "epoch:29 step:27377 [D loss: 0.484806, acc.: 72.66%] [G loss: 0.932105]\n",
      "epoch:29 step:27378 [D loss: 0.488034, acc.: 75.00%] [G loss: 0.943312]\n",
      "epoch:29 step:27379 [D loss: 0.508922, acc.: 75.78%] [G loss: 0.795460]\n",
      "epoch:29 step:27380 [D loss: 0.472310, acc.: 77.34%] [G loss: 0.887801]\n",
      "epoch:29 step:27381 [D loss: 0.420836, acc.: 76.56%] [G loss: 1.145229]\n",
      "epoch:29 step:27382 [D loss: 0.435129, acc.: 81.25%] [G loss: 0.972433]\n",
      "epoch:29 step:27383 [D loss: 0.645146, acc.: 64.06%] [G loss: 0.698429]\n",
      "epoch:29 step:27384 [D loss: 0.572216, acc.: 65.62%] [G loss: 0.608539]\n",
      "epoch:29 step:27385 [D loss: 0.503900, acc.: 78.12%] [G loss: 0.647853]\n",
      "epoch:29 step:27386 [D loss: 0.464242, acc.: 77.34%] [G loss: 0.915433]\n",
      "epoch:29 step:27387 [D loss: 0.634748, acc.: 58.59%] [G loss: 0.776411]\n",
      "epoch:29 step:27388 [D loss: 0.501362, acc.: 72.66%] [G loss: 0.817894]\n",
      "epoch:29 step:27389 [D loss: 0.500226, acc.: 73.44%] [G loss: 0.843557]\n",
      "epoch:29 step:27390 [D loss: 0.438519, acc.: 80.47%] [G loss: 0.846829]\n",
      "epoch:29 step:27391 [D loss: 0.464597, acc.: 80.47%] [G loss: 0.857929]\n",
      "epoch:29 step:27392 [D loss: 0.496842, acc.: 75.78%] [G loss: 1.020625]\n",
      "epoch:29 step:27393 [D loss: 0.661585, acc.: 67.19%] [G loss: 0.857750]\n",
      "epoch:29 step:27394 [D loss: 0.541792, acc.: 66.41%] [G loss: 0.835500]\n",
      "epoch:29 step:27395 [D loss: 0.489768, acc.: 73.44%] [G loss: 0.832246]\n",
      "epoch:29 step:27396 [D loss: 0.466844, acc.: 75.78%] [G loss: 0.864794]\n",
      "epoch:29 step:27397 [D loss: 0.477546, acc.: 75.78%] [G loss: 0.621644]\n",
      "epoch:29 step:27398 [D loss: 0.505111, acc.: 75.00%] [G loss: 0.726624]\n",
      "epoch:29 step:27399 [D loss: 0.598849, acc.: 67.97%] [G loss: 0.650521]\n",
      "epoch:29 step:27400 [D loss: 0.512540, acc.: 73.44%] [G loss: 0.703823]\n",
      "epoch:29 step:27401 [D loss: 0.545706, acc.: 71.88%] [G loss: 0.617020]\n",
      "epoch:29 step:27402 [D loss: 0.568824, acc.: 71.88%] [G loss: 0.758381]\n",
      "epoch:29 step:27403 [D loss: 0.455907, acc.: 74.22%] [G loss: 0.780863]\n",
      "epoch:29 step:27404 [D loss: 0.493489, acc.: 72.66%] [G loss: 1.013447]\n",
      "epoch:29 step:27405 [D loss: 0.472388, acc.: 79.69%] [G loss: 1.088139]\n",
      "epoch:29 step:27406 [D loss: 0.615729, acc.: 69.53%] [G loss: 0.988703]\n",
      "epoch:29 step:27407 [D loss: 0.531512, acc.: 76.56%] [G loss: 0.991054]\n",
      "epoch:29 step:27408 [D loss: 0.538133, acc.: 75.00%] [G loss: 0.897547]\n",
      "epoch:29 step:27409 [D loss: 0.493217, acc.: 74.22%] [G loss: 0.813519]\n",
      "epoch:29 step:27410 [D loss: 0.507269, acc.: 73.44%] [G loss: 0.698334]\n",
      "epoch:29 step:27411 [D loss: 0.551644, acc.: 69.53%] [G loss: 0.651531]\n",
      "epoch:29 step:27412 [D loss: 0.496752, acc.: 74.22%] [G loss: 0.536411]\n",
      "epoch:29 step:27413 [D loss: 0.532635, acc.: 71.09%] [G loss: 0.675437]\n",
      "epoch:29 step:27414 [D loss: 0.511426, acc.: 70.31%] [G loss: 0.754579]\n",
      "epoch:29 step:27415 [D loss: 0.475236, acc.: 78.12%] [G loss: 0.729202]\n",
      "epoch:29 step:27416 [D loss: 0.510425, acc.: 72.66%] [G loss: 0.810377]\n",
      "epoch:29 step:27417 [D loss: 0.479011, acc.: 75.00%] [G loss: 0.924968]\n",
      "epoch:29 step:27418 [D loss: 0.513206, acc.: 69.53%] [G loss: 0.871067]\n",
      "epoch:29 step:27419 [D loss: 0.475774, acc.: 75.00%] [G loss: 0.811067]\n",
      "epoch:29 step:27420 [D loss: 0.482399, acc.: 77.34%] [G loss: 0.823960]\n",
      "epoch:29 step:27421 [D loss: 0.505065, acc.: 73.44%] [G loss: 1.171260]\n",
      "epoch:29 step:27422 [D loss: 0.644072, acc.: 65.62%] [G loss: 0.661587]\n",
      "epoch:29 step:27423 [D loss: 0.560737, acc.: 69.53%] [G loss: 0.797300]\n",
      "epoch:29 step:27424 [D loss: 0.649527, acc.: 64.06%] [G loss: 0.640547]\n",
      "epoch:29 step:27425 [D loss: 0.530621, acc.: 71.88%] [G loss: 0.754589]\n",
      "epoch:29 step:27426 [D loss: 0.566058, acc.: 68.75%] [G loss: 0.808214]\n",
      "epoch:29 step:27427 [D loss: 0.503433, acc.: 75.00%] [G loss: 0.810594]\n",
      "epoch:29 step:27428 [D loss: 0.601732, acc.: 65.62%] [G loss: 0.726578]\n",
      "epoch:29 step:27429 [D loss: 0.544203, acc.: 68.75%] [G loss: 0.731194]\n",
      "epoch:29 step:27430 [D loss: 0.604508, acc.: 63.28%] [G loss: 0.618150]\n",
      "epoch:29 step:27431 [D loss: 0.476624, acc.: 77.34%] [G loss: 0.833873]\n",
      "epoch:29 step:27432 [D loss: 0.528192, acc.: 68.75%] [G loss: 0.641728]\n",
      "epoch:29 step:27433 [D loss: 0.617933, acc.: 62.50%] [G loss: 0.728014]\n",
      "epoch:29 step:27434 [D loss: 0.534354, acc.: 72.66%] [G loss: 0.668115]\n",
      "epoch:29 step:27435 [D loss: 0.534232, acc.: 73.44%] [G loss: 0.735419]\n",
      "epoch:29 step:27436 [D loss: 0.523389, acc.: 74.22%] [G loss: 0.716320]\n",
      "epoch:29 step:27437 [D loss: 0.465711, acc.: 74.22%] [G loss: 0.820547]\n",
      "epoch:29 step:27438 [D loss: 0.529549, acc.: 67.97%] [G loss: 0.690335]\n",
      "epoch:29 step:27439 [D loss: 0.528641, acc.: 66.41%] [G loss: 0.815327]\n",
      "epoch:29 step:27440 [D loss: 0.515858, acc.: 74.22%] [G loss: 0.744757]\n",
      "epoch:29 step:27441 [D loss: 0.522453, acc.: 73.44%] [G loss: 0.714914]\n",
      "epoch:29 step:27442 [D loss: 0.534819, acc.: 76.56%] [G loss: 0.691956]\n",
      "epoch:29 step:27443 [D loss: 0.438576, acc.: 82.81%] [G loss: 0.940173]\n",
      "epoch:29 step:27444 [D loss: 0.569706, acc.: 68.75%] [G loss: 0.851971]\n",
      "epoch:29 step:27445 [D loss: 0.547496, acc.: 66.41%] [G loss: 0.725314]\n",
      "epoch:29 step:27446 [D loss: 0.507348, acc.: 72.66%] [G loss: 0.763431]\n",
      "epoch:29 step:27447 [D loss: 0.440866, acc.: 79.69%] [G loss: 0.990128]\n",
      "epoch:29 step:27448 [D loss: 0.510562, acc.: 73.44%] [G loss: 0.902804]\n",
      "epoch:29 step:27449 [D loss: 0.415384, acc.: 78.91%] [G loss: 0.991667]\n",
      "epoch:29 step:27450 [D loss: 0.687718, acc.: 64.84%] [G loss: 0.656105]\n",
      "epoch:29 step:27451 [D loss: 0.595880, acc.: 66.41%] [G loss: 0.547811]\n",
      "epoch:29 step:27452 [D loss: 0.510201, acc.: 68.75%] [G loss: 0.616708]\n",
      "epoch:29 step:27453 [D loss: 0.547791, acc.: 70.31%] [G loss: 0.765075]\n",
      "epoch:29 step:27454 [D loss: 0.539371, acc.: 71.88%] [G loss: 0.710367]\n",
      "epoch:29 step:27455 [D loss: 0.544593, acc.: 70.31%] [G loss: 0.603580]\n",
      "epoch:29 step:27456 [D loss: 0.509631, acc.: 78.12%] [G loss: 0.709330]\n",
      "epoch:29 step:27457 [D loss: 0.494578, acc.: 74.22%] [G loss: 0.784760]\n",
      "epoch:29 step:27458 [D loss: 0.526459, acc.: 72.66%] [G loss: 0.716273]\n",
      "epoch:29 step:27459 [D loss: 0.545140, acc.: 67.19%] [G loss: 0.706274]\n",
      "epoch:29 step:27460 [D loss: 0.567033, acc.: 67.19%] [G loss: 0.575621]\n",
      "epoch:29 step:27461 [D loss: 0.511030, acc.: 75.00%] [G loss: 0.726251]\n",
      "epoch:29 step:27462 [D loss: 0.492959, acc.: 74.22%] [G loss: 0.781078]\n",
      "epoch:29 step:27463 [D loss: 0.568864, acc.: 66.41%] [G loss: 0.707633]\n",
      "epoch:29 step:27464 [D loss: 0.509247, acc.: 74.22%] [G loss: 0.905783]\n",
      "epoch:29 step:27465 [D loss: 0.467903, acc.: 75.00%] [G loss: 0.899713]\n",
      "epoch:29 step:27466 [D loss: 0.558223, acc.: 70.31%] [G loss: 0.881999]\n",
      "epoch:29 step:27467 [D loss: 0.660236, acc.: 58.59%] [G loss: 0.469854]\n",
      "epoch:29 step:27468 [D loss: 0.530719, acc.: 71.88%] [G loss: 0.536955]\n",
      "epoch:29 step:27469 [D loss: 0.505509, acc.: 77.34%] [G loss: 0.644605]\n",
      "epoch:29 step:27470 [D loss: 0.559029, acc.: 63.28%] [G loss: 0.579641]\n",
      "epoch:29 step:27471 [D loss: 0.503390, acc.: 72.66%] [G loss: 0.885127]\n",
      "epoch:29 step:27472 [D loss: 0.460012, acc.: 76.56%] [G loss: 1.136735]\n",
      "epoch:29 step:27473 [D loss: 0.455417, acc.: 76.56%] [G loss: 0.900593]\n",
      "epoch:29 step:27474 [D loss: 0.579775, acc.: 71.88%] [G loss: 0.733939]\n",
      "epoch:29 step:27475 [D loss: 0.503958, acc.: 69.53%] [G loss: 0.792676]\n",
      "epoch:29 step:27476 [D loss: 0.518142, acc.: 74.22%] [G loss: 0.791059]\n",
      "epoch:29 step:27477 [D loss: 0.470692, acc.: 75.78%] [G loss: 0.739932]\n",
      "epoch:29 step:27478 [D loss: 0.508144, acc.: 75.78%] [G loss: 0.742457]\n",
      "epoch:29 step:27479 [D loss: 0.533501, acc.: 72.66%] [G loss: 0.746291]\n",
      "epoch:29 step:27480 [D loss: 0.546405, acc.: 72.66%] [G loss: 0.746238]\n",
      "epoch:29 step:27481 [D loss: 0.500224, acc.: 76.56%] [G loss: 0.802173]\n",
      "epoch:29 step:27482 [D loss: 0.484384, acc.: 72.66%] [G loss: 0.782374]\n",
      "epoch:29 step:27483 [D loss: 0.541489, acc.: 70.31%] [G loss: 0.764916]\n",
      "epoch:29 step:27484 [D loss: 0.442789, acc.: 76.56%] [G loss: 1.132483]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:29 step:27485 [D loss: 0.448988, acc.: 81.25%] [G loss: 1.017561]\n",
      "epoch:29 step:27486 [D loss: 0.459103, acc.: 78.91%] [G loss: 1.162064]\n",
      "epoch:29 step:27487 [D loss: 0.437403, acc.: 76.56%] [G loss: 1.050867]\n",
      "epoch:29 step:27488 [D loss: 0.397536, acc.: 82.81%] [G loss: 1.115487]\n",
      "epoch:29 step:27489 [D loss: 0.596303, acc.: 66.41%] [G loss: 0.620217]\n",
      "epoch:29 step:27490 [D loss: 0.567557, acc.: 71.09%] [G loss: 0.834619]\n",
      "epoch:29 step:27491 [D loss: 0.496180, acc.: 69.53%] [G loss: 0.713669]\n",
      "epoch:29 step:27492 [D loss: 0.531940, acc.: 70.31%] [G loss: 0.770429]\n",
      "epoch:29 step:27493 [D loss: 0.558461, acc.: 67.97%] [G loss: 0.613126]\n",
      "epoch:29 step:27494 [D loss: 0.498393, acc.: 75.00%] [G loss: 0.778207]\n",
      "epoch:29 step:27495 [D loss: 0.558966, acc.: 69.53%] [G loss: 0.611956]\n",
      "epoch:29 step:27496 [D loss: 0.570501, acc.: 68.75%] [G loss: 0.763121]\n",
      "epoch:29 step:27497 [D loss: 0.535988, acc.: 71.88%] [G loss: 0.643707]\n",
      "epoch:29 step:27498 [D loss: 0.526189, acc.: 74.22%] [G loss: 0.655483]\n",
      "epoch:29 step:27499 [D loss: 0.425152, acc.: 78.91%] [G loss: 0.849409]\n",
      "epoch:29 step:27500 [D loss: 0.511062, acc.: 76.56%] [G loss: 0.818324]\n",
      "epoch:29 step:27501 [D loss: 0.521450, acc.: 72.66%] [G loss: 0.738140]\n",
      "epoch:29 step:27502 [D loss: 0.516240, acc.: 71.09%] [G loss: 0.865575]\n",
      "epoch:29 step:27503 [D loss: 0.507742, acc.: 77.34%] [G loss: 0.824368]\n",
      "epoch:29 step:27504 [D loss: 0.520882, acc.: 73.44%] [G loss: 0.661805]\n",
      "epoch:29 step:27505 [D loss: 0.493272, acc.: 71.88%] [G loss: 0.849345]\n",
      "epoch:29 step:27506 [D loss: 0.484306, acc.: 73.44%] [G loss: 0.725938]\n",
      "epoch:29 step:27507 [D loss: 0.466161, acc.: 77.34%] [G loss: 0.973431]\n",
      "epoch:29 step:27508 [D loss: 0.461792, acc.: 74.22%] [G loss: 0.901629]\n",
      "epoch:29 step:27509 [D loss: 0.485982, acc.: 75.00%] [G loss: 0.923824]\n",
      "epoch:29 step:27510 [D loss: 0.474463, acc.: 76.56%] [G loss: 0.885962]\n",
      "epoch:29 step:27511 [D loss: 0.527574, acc.: 69.53%] [G loss: 0.818377]\n",
      "epoch:29 step:27512 [D loss: 0.545039, acc.: 72.66%] [G loss: 0.711911]\n",
      "epoch:29 step:27513 [D loss: 0.437141, acc.: 79.69%] [G loss: 0.903162]\n",
      "epoch:29 step:27514 [D loss: 0.543761, acc.: 71.09%] [G loss: 1.008630]\n",
      "epoch:29 step:27515 [D loss: 0.661077, acc.: 60.94%] [G loss: 0.730577]\n",
      "epoch:29 step:27516 [D loss: 0.491904, acc.: 73.44%] [G loss: 0.832995]\n",
      "epoch:29 step:27517 [D loss: 0.440887, acc.: 80.47%] [G loss: 1.101173]\n",
      "epoch:29 step:27518 [D loss: 0.586087, acc.: 64.06%] [G loss: 0.879999]\n",
      "epoch:29 step:27519 [D loss: 0.522996, acc.: 74.22%] [G loss: 0.904520]\n",
      "epoch:29 step:27520 [D loss: 0.411753, acc.: 82.03%] [G loss: 1.107782]\n",
      "epoch:29 step:27521 [D loss: 0.574859, acc.: 67.97%] [G loss: 0.820166]\n",
      "epoch:29 step:27522 [D loss: 0.670149, acc.: 63.28%] [G loss: 0.618322]\n",
      "epoch:29 step:27523 [D loss: 0.481685, acc.: 77.34%] [G loss: 0.537591]\n",
      "epoch:29 step:27524 [D loss: 0.480704, acc.: 78.12%] [G loss: 0.738740]\n",
      "epoch:29 step:27525 [D loss: 0.581817, acc.: 73.44%] [G loss: 0.653812]\n",
      "epoch:29 step:27526 [D loss: 0.519077, acc.: 75.00%] [G loss: 0.744692]\n",
      "epoch:29 step:27527 [D loss: 0.397594, acc.: 83.59%] [G loss: 0.859093]\n",
      "epoch:29 step:27528 [D loss: 0.437155, acc.: 78.91%] [G loss: 0.894633]\n",
      "epoch:29 step:27529 [D loss: 0.517029, acc.: 72.66%] [G loss: 0.910715]\n",
      "epoch:29 step:27530 [D loss: 0.417929, acc.: 78.12%] [G loss: 1.060962]\n",
      "epoch:29 step:27531 [D loss: 0.453841, acc.: 79.69%] [G loss: 1.058187]\n",
      "epoch:29 step:27532 [D loss: 0.460062, acc.: 78.12%] [G loss: 0.894045]\n",
      "epoch:29 step:27533 [D loss: 0.544095, acc.: 69.53%] [G loss: 0.858693]\n",
      "epoch:29 step:27534 [D loss: 0.431705, acc.: 81.25%] [G loss: 0.893493]\n",
      "epoch:29 step:27535 [D loss: 0.570038, acc.: 71.88%] [G loss: 0.686361]\n",
      "epoch:29 step:27536 [D loss: 0.496367, acc.: 75.00%] [G loss: 0.827620]\n",
      "epoch:29 step:27537 [D loss: 0.533094, acc.: 73.44%] [G loss: 0.860128]\n",
      "epoch:29 step:27538 [D loss: 0.541991, acc.: 67.19%] [G loss: 0.679063]\n",
      "epoch:29 step:27539 [D loss: 0.521110, acc.: 71.09%] [G loss: 0.875403]\n",
      "epoch:29 step:27540 [D loss: 0.526290, acc.: 67.97%] [G loss: 0.872426]\n",
      "epoch:29 step:27541 [D loss: 0.522611, acc.: 72.66%] [G loss: 0.755404]\n",
      "epoch:29 step:27542 [D loss: 0.526527, acc.: 72.66%] [G loss: 0.808489]\n",
      "epoch:29 step:27543 [D loss: 0.504344, acc.: 75.78%] [G loss: 0.824872]\n",
      "epoch:29 step:27544 [D loss: 0.469714, acc.: 77.34%] [G loss: 0.855292]\n",
      "epoch:29 step:27545 [D loss: 0.597115, acc.: 67.19%] [G loss: 0.786464]\n",
      "epoch:29 step:27546 [D loss: 0.512333, acc.: 72.66%] [G loss: 0.936078]\n",
      "epoch:29 step:27547 [D loss: 0.498953, acc.: 75.00%] [G loss: 0.905633]\n",
      "epoch:29 step:27548 [D loss: 0.565014, acc.: 71.88%] [G loss: 0.897731]\n",
      "epoch:29 step:27549 [D loss: 0.695457, acc.: 60.16%] [G loss: 0.579885]\n",
      "epoch:29 step:27550 [D loss: 0.601058, acc.: 64.06%] [G loss: 0.575921]\n",
      "epoch:29 step:27551 [D loss: 0.549707, acc.: 71.09%] [G loss: 0.798781]\n",
      "epoch:29 step:27552 [D loss: 0.523982, acc.: 72.66%] [G loss: 0.641442]\n",
      "epoch:29 step:27553 [D loss: 0.584563, acc.: 66.41%] [G loss: 0.873417]\n",
      "epoch:29 step:27554 [D loss: 0.488150, acc.: 76.56%] [G loss: 0.658889]\n",
      "epoch:29 step:27555 [D loss: 0.472659, acc.: 81.25%] [G loss: 0.946439]\n",
      "epoch:29 step:27556 [D loss: 0.534103, acc.: 71.09%] [G loss: 0.757925]\n",
      "epoch:29 step:27557 [D loss: 0.519332, acc.: 71.09%] [G loss: 0.754511]\n",
      "epoch:29 step:27558 [D loss: 0.452494, acc.: 82.81%] [G loss: 0.850740]\n",
      "epoch:29 step:27559 [D loss: 0.587734, acc.: 67.97%] [G loss: 0.920645]\n",
      "epoch:29 step:27560 [D loss: 0.531733, acc.: 70.31%] [G loss: 0.610149]\n",
      "epoch:29 step:27561 [D loss: 0.515539, acc.: 71.88%] [G loss: 0.773615]\n",
      "epoch:29 step:27562 [D loss: 0.492482, acc.: 70.31%] [G loss: 0.762463]\n",
      "epoch:29 step:27563 [D loss: 0.583749, acc.: 67.97%] [G loss: 0.679288]\n",
      "epoch:29 step:27564 [D loss: 0.518175, acc.: 68.75%] [G loss: 0.643295]\n",
      "epoch:29 step:27565 [D loss: 0.459143, acc.: 75.00%] [G loss: 0.783393]\n",
      "epoch:29 step:27566 [D loss: 0.587557, acc.: 69.53%] [G loss: 0.639910]\n",
      "epoch:29 step:27567 [D loss: 0.511259, acc.: 73.44%] [G loss: 0.722229]\n",
      "epoch:29 step:27568 [D loss: 0.550830, acc.: 69.53%] [G loss: 0.697478]\n",
      "epoch:29 step:27569 [D loss: 0.531772, acc.: 70.31%] [G loss: 0.771589]\n",
      "epoch:29 step:27570 [D loss: 0.503919, acc.: 67.97%] [G loss: 0.917486]\n",
      "epoch:29 step:27571 [D loss: 0.519722, acc.: 73.44%] [G loss: 0.777916]\n",
      "epoch:29 step:27572 [D loss: 0.427293, acc.: 82.81%] [G loss: 0.854895]\n",
      "epoch:29 step:27573 [D loss: 0.679671, acc.: 60.16%] [G loss: 0.697223]\n",
      "epoch:29 step:27574 [D loss: 0.616803, acc.: 64.84%] [G loss: 0.644496]\n",
      "epoch:29 step:27575 [D loss: 0.464248, acc.: 80.47%] [G loss: 0.650622]\n",
      "epoch:29 step:27576 [D loss: 0.477172, acc.: 76.56%] [G loss: 0.689704]\n",
      "epoch:29 step:27577 [D loss: 0.612208, acc.: 60.16%] [G loss: 0.771131]\n",
      "epoch:29 step:27578 [D loss: 0.562127, acc.: 63.28%] [G loss: 0.809229]\n",
      "epoch:29 step:27579 [D loss: 0.500266, acc.: 72.66%] [G loss: 1.090630]\n",
      "epoch:29 step:27580 [D loss: 0.558999, acc.: 71.09%] [G loss: 0.846402]\n",
      "epoch:29 step:27581 [D loss: 0.563770, acc.: 67.97%] [G loss: 0.774273]\n",
      "epoch:29 step:27582 [D loss: 0.535119, acc.: 64.84%] [G loss: 0.713525]\n",
      "epoch:29 step:27583 [D loss: 0.558119, acc.: 66.41%] [G loss: 0.724040]\n",
      "epoch:29 step:27584 [D loss: 0.564000, acc.: 67.97%] [G loss: 0.773177]\n",
      "epoch:29 step:27585 [D loss: 0.583207, acc.: 65.62%] [G loss: 0.641154]\n",
      "epoch:29 step:27586 [D loss: 0.485019, acc.: 72.66%] [G loss: 0.612439]\n",
      "epoch:29 step:27587 [D loss: 0.512492, acc.: 72.66%] [G loss: 0.784705]\n",
      "epoch:29 step:27588 [D loss: 0.538445, acc.: 69.53%] [G loss: 0.826363]\n",
      "epoch:29 step:27589 [D loss: 0.468904, acc.: 76.56%] [G loss: 1.166535]\n",
      "epoch:29 step:27590 [D loss: 0.489534, acc.: 75.78%] [G loss: 0.859436]\n",
      "epoch:29 step:27591 [D loss: 0.569408, acc.: 66.41%] [G loss: 0.770681]\n",
      "epoch:29 step:27592 [D loss: 0.574451, acc.: 70.31%] [G loss: 0.688223]\n",
      "epoch:29 step:27593 [D loss: 0.612832, acc.: 62.50%] [G loss: 0.673270]\n",
      "epoch:29 step:27594 [D loss: 0.564766, acc.: 65.62%] [G loss: 0.707249]\n",
      "epoch:29 step:27595 [D loss: 0.584457, acc.: 67.97%] [G loss: 0.535031]\n",
      "epoch:29 step:27596 [D loss: 0.571247, acc.: 67.97%] [G loss: 0.564555]\n",
      "epoch:29 step:27597 [D loss: 0.572759, acc.: 67.19%] [G loss: 0.754661]\n",
      "epoch:29 step:27598 [D loss: 0.497562, acc.: 74.22%] [G loss: 0.879275]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:29 step:27599 [D loss: 0.441641, acc.: 80.47%] [G loss: 0.928314]\n",
      "epoch:29 step:27600 [D loss: 0.418387, acc.: 81.25%] [G loss: 1.117514]\n",
      "epoch:29 step:27601 [D loss: 0.502750, acc.: 75.00%] [G loss: 0.807177]\n",
      "epoch:29 step:27602 [D loss: 0.428889, acc.: 79.69%] [G loss: 1.101907]\n",
      "epoch:29 step:27603 [D loss: 0.470315, acc.: 77.34%] [G loss: 0.928697]\n",
      "epoch:29 step:27604 [D loss: 0.510597, acc.: 71.88%] [G loss: 0.706391]\n",
      "epoch:29 step:27605 [D loss: 0.545740, acc.: 69.53%] [G loss: 0.787190]\n",
      "epoch:29 step:27606 [D loss: 0.494961, acc.: 72.66%] [G loss: 0.790927]\n",
      "epoch:29 step:27607 [D loss: 0.502234, acc.: 74.22%] [G loss: 0.697735]\n",
      "epoch:29 step:27608 [D loss: 0.527646, acc.: 67.97%] [G loss: 0.826253]\n",
      "epoch:29 step:27609 [D loss: 0.458363, acc.: 74.22%] [G loss: 0.912994]\n",
      "epoch:29 step:27610 [D loss: 0.663972, acc.: 59.38%] [G loss: 0.625465]\n",
      "epoch:29 step:27611 [D loss: 0.578889, acc.: 64.84%] [G loss: 0.712283]\n",
      "epoch:29 step:27612 [D loss: 0.523997, acc.: 75.78%] [G loss: 0.919111]\n",
      "epoch:29 step:27613 [D loss: 0.488025, acc.: 76.56%] [G loss: 0.887393]\n",
      "epoch:29 step:27614 [D loss: 0.505492, acc.: 75.00%] [G loss: 0.899512]\n",
      "epoch:29 step:27615 [D loss: 0.524639, acc.: 71.09%] [G loss: 0.922546]\n",
      "epoch:29 step:27616 [D loss: 0.495780, acc.: 74.22%] [G loss: 0.728097]\n",
      "epoch:29 step:27617 [D loss: 0.462884, acc.: 78.91%] [G loss: 0.937232]\n",
      "epoch:29 step:27618 [D loss: 0.569247, acc.: 68.75%] [G loss: 0.674779]\n",
      "epoch:29 step:27619 [D loss: 0.513173, acc.: 69.53%] [G loss: 0.858973]\n",
      "epoch:29 step:27620 [D loss: 0.430595, acc.: 79.69%] [G loss: 0.778084]\n",
      "epoch:29 step:27621 [D loss: 0.586777, acc.: 68.75%] [G loss: 0.852199]\n",
      "epoch:29 step:27622 [D loss: 0.503296, acc.: 72.66%] [G loss: 0.762927]\n",
      "epoch:29 step:27623 [D loss: 0.492209, acc.: 75.78%] [G loss: 0.665397]\n",
      "epoch:29 step:27624 [D loss: 0.384828, acc.: 85.94%] [G loss: 0.781360]\n",
      "epoch:29 step:27625 [D loss: 0.486554, acc.: 72.66%] [G loss: 1.008067]\n",
      "epoch:29 step:27626 [D loss: 0.528646, acc.: 71.88%] [G loss: 0.886109]\n",
      "epoch:29 step:27627 [D loss: 0.524710, acc.: 72.66%] [G loss: 0.725357]\n",
      "epoch:29 step:27628 [D loss: 0.537441, acc.: 71.88%] [G loss: 0.762532]\n",
      "epoch:29 step:27629 [D loss: 0.539487, acc.: 70.31%] [G loss: 0.902881]\n",
      "epoch:29 step:27630 [D loss: 0.480692, acc.: 74.22%] [G loss: 0.882359]\n",
      "epoch:29 step:27631 [D loss: 0.647715, acc.: 62.50%] [G loss: 0.701702]\n",
      "epoch:29 step:27632 [D loss: 0.486111, acc.: 78.91%] [G loss: 0.785163]\n",
      "epoch:29 step:27633 [D loss: 0.520072, acc.: 68.75%] [G loss: 0.646108]\n",
      "epoch:29 step:27634 [D loss: 0.464024, acc.: 78.12%] [G loss: 0.776780]\n",
      "epoch:29 step:27635 [D loss: 0.517639, acc.: 71.88%] [G loss: 0.682300]\n",
      "epoch:29 step:27636 [D loss: 0.532056, acc.: 67.19%] [G loss: 0.617314]\n",
      "epoch:29 step:27637 [D loss: 0.473647, acc.: 76.56%] [G loss: 0.843331]\n",
      "epoch:29 step:27638 [D loss: 0.590277, acc.: 64.84%] [G loss: 0.529626]\n",
      "epoch:29 step:27639 [D loss: 0.486501, acc.: 75.00%] [G loss: 0.694356]\n",
      "epoch:29 step:27640 [D loss: 0.464039, acc.: 79.69%] [G loss: 0.823151]\n",
      "epoch:29 step:27641 [D loss: 0.561358, acc.: 65.62%] [G loss: 0.812228]\n",
      "epoch:29 step:27642 [D loss: 0.485796, acc.: 73.44%] [G loss: 0.742736]\n",
      "epoch:29 step:27643 [D loss: 0.503606, acc.: 79.69%] [G loss: 0.671787]\n",
      "epoch:29 step:27644 [D loss: 0.443584, acc.: 80.47%] [G loss: 0.852448]\n",
      "epoch:29 step:27645 [D loss: 0.480373, acc.: 74.22%] [G loss: 0.951588]\n",
      "epoch:29 step:27646 [D loss: 0.614843, acc.: 65.62%] [G loss: 0.801954]\n",
      "epoch:29 step:27647 [D loss: 0.517684, acc.: 72.66%] [G loss: 0.671593]\n",
      "epoch:29 step:27648 [D loss: 0.464424, acc.: 76.56%] [G loss: 0.815001]\n",
      "epoch:29 step:27649 [D loss: 0.468307, acc.: 78.12%] [G loss: 0.843781]\n",
      "epoch:29 step:27650 [D loss: 0.564281, acc.: 68.75%] [G loss: 0.696815]\n",
      "epoch:29 step:27651 [D loss: 0.538151, acc.: 74.22%] [G loss: 0.746825]\n",
      "epoch:29 step:27652 [D loss: 0.570140, acc.: 66.41%] [G loss: 0.770230]\n",
      "epoch:29 step:27653 [D loss: 0.587020, acc.: 67.19%] [G loss: 0.922624]\n",
      "epoch:29 step:27654 [D loss: 0.480008, acc.: 78.12%] [G loss: 0.759240]\n",
      "epoch:29 step:27655 [D loss: 0.587513, acc.: 65.62%] [G loss: 0.724252]\n",
      "epoch:29 step:27656 [D loss: 0.505287, acc.: 77.34%] [G loss: 0.659218]\n",
      "epoch:29 step:27657 [D loss: 0.497189, acc.: 76.56%] [G loss: 0.844835]\n",
      "epoch:29 step:27658 [D loss: 0.502437, acc.: 73.44%] [G loss: 0.765423]\n",
      "epoch:29 step:27659 [D loss: 0.552883, acc.: 67.19%] [G loss: 0.734397]\n",
      "epoch:29 step:27660 [D loss: 0.513937, acc.: 67.97%] [G loss: 0.776746]\n",
      "epoch:29 step:27661 [D loss: 0.441430, acc.: 81.25%] [G loss: 0.691537]\n",
      "epoch:29 step:27662 [D loss: 0.505886, acc.: 74.22%] [G loss: 0.781361]\n",
      "epoch:29 step:27663 [D loss: 0.563911, acc.: 70.31%] [G loss: 0.802005]\n",
      "epoch:29 step:27664 [D loss: 0.509445, acc.: 74.22%] [G loss: 0.666155]\n",
      "epoch:29 step:27665 [D loss: 0.615669, acc.: 64.06%] [G loss: 0.825453]\n",
      "epoch:29 step:27666 [D loss: 0.579814, acc.: 65.62%] [G loss: 0.629027]\n",
      "epoch:29 step:27667 [D loss: 0.559872, acc.: 71.09%] [G loss: 0.635258]\n",
      "epoch:29 step:27668 [D loss: 0.494512, acc.: 73.44%] [G loss: 0.672636]\n",
      "epoch:29 step:27669 [D loss: 0.577476, acc.: 70.31%] [G loss: 0.541343]\n",
      "epoch:29 step:27670 [D loss: 0.515313, acc.: 74.22%] [G loss: 0.706006]\n",
      "epoch:29 step:27671 [D loss: 0.503110, acc.: 75.00%] [G loss: 0.769334]\n",
      "epoch:29 step:27672 [D loss: 0.411389, acc.: 82.81%] [G loss: 0.830345]\n",
      "epoch:29 step:27673 [D loss: 0.545559, acc.: 70.31%] [G loss: 0.701492]\n",
      "epoch:29 step:27674 [D loss: 0.612001, acc.: 66.41%] [G loss: 0.669729]\n",
      "epoch:29 step:27675 [D loss: 0.610016, acc.: 65.62%] [G loss: 0.601764]\n",
      "epoch:29 step:27676 [D loss: 0.484172, acc.: 75.00%] [G loss: 0.653689]\n",
      "epoch:29 step:27677 [D loss: 0.399139, acc.: 81.25%] [G loss: 0.793956]\n",
      "epoch:29 step:27678 [D loss: 0.527255, acc.: 71.88%] [G loss: 0.782498]\n",
      "epoch:29 step:27679 [D loss: 0.528581, acc.: 76.56%] [G loss: 0.915811]\n",
      "epoch:29 step:27680 [D loss: 0.516245, acc.: 72.66%] [G loss: 0.906504]\n",
      "epoch:29 step:27681 [D loss: 0.388773, acc.: 82.03%] [G loss: 0.974925]\n",
      "epoch:29 step:27682 [D loss: 0.518879, acc.: 75.78%] [G loss: 1.162265]\n",
      "epoch:29 step:27683 [D loss: 0.581482, acc.: 72.66%] [G loss: 0.759265]\n",
      "epoch:29 step:27684 [D loss: 0.603698, acc.: 65.62%] [G loss: 0.538187]\n",
      "epoch:29 step:27685 [D loss: 0.537070, acc.: 68.75%] [G loss: 0.604814]\n",
      "epoch:29 step:27686 [D loss: 0.496736, acc.: 76.56%] [G loss: 0.811798]\n",
      "epoch:29 step:27687 [D loss: 0.476859, acc.: 75.78%] [G loss: 0.766071]\n",
      "epoch:29 step:27688 [D loss: 0.531857, acc.: 71.88%] [G loss: 0.645969]\n",
      "epoch:29 step:27689 [D loss: 0.430735, acc.: 83.59%] [G loss: 0.986879]\n",
      "epoch:29 step:27690 [D loss: 0.509627, acc.: 75.78%] [G loss: 0.797947]\n",
      "epoch:29 step:27691 [D loss: 0.537384, acc.: 70.31%] [G loss: 0.761126]\n",
      "epoch:29 step:27692 [D loss: 0.482534, acc.: 71.09%] [G loss: 0.907064]\n",
      "epoch:29 step:27693 [D loss: 0.455361, acc.: 78.12%] [G loss: 0.823311]\n",
      "epoch:29 step:27694 [D loss: 0.500644, acc.: 75.78%] [G loss: 1.006920]\n",
      "epoch:29 step:27695 [D loss: 0.521193, acc.: 74.22%] [G loss: 0.692543]\n",
      "epoch:29 step:27696 [D loss: 0.439024, acc.: 80.47%] [G loss: 0.856505]\n",
      "epoch:29 step:27697 [D loss: 0.544693, acc.: 71.88%] [G loss: 0.937907]\n",
      "epoch:29 step:27698 [D loss: 0.537631, acc.: 75.78%] [G loss: 0.780616]\n",
      "epoch:29 step:27699 [D loss: 0.449775, acc.: 78.91%] [G loss: 0.755818]\n",
      "epoch:29 step:27700 [D loss: 0.582953, acc.: 67.19%] [G loss: 0.726407]\n",
      "epoch:29 step:27701 [D loss: 0.687605, acc.: 55.47%] [G loss: 0.564491]\n",
      "epoch:29 step:27702 [D loss: 0.606810, acc.: 60.94%] [G loss: 0.706837]\n",
      "epoch:29 step:27703 [D loss: 0.499057, acc.: 74.22%] [G loss: 0.649660]\n",
      "epoch:29 step:27704 [D loss: 0.514039, acc.: 74.22%] [G loss: 0.824295]\n",
      "epoch:29 step:27705 [D loss: 0.563235, acc.: 67.97%] [G loss: 0.637141]\n",
      "epoch:29 step:27706 [D loss: 0.515351, acc.: 69.53%] [G loss: 0.674583]\n",
      "epoch:29 step:27707 [D loss: 0.452605, acc.: 77.34%] [G loss: 0.705611]\n",
      "epoch:29 step:27708 [D loss: 0.621840, acc.: 64.06%] [G loss: 0.739242]\n",
      "epoch:29 step:27709 [D loss: 0.491738, acc.: 72.66%] [G loss: 0.798284]\n",
      "epoch:29 step:27710 [D loss: 0.609656, acc.: 67.19%] [G loss: 0.502041]\n",
      "epoch:29 step:27711 [D loss: 0.565898, acc.: 67.19%] [G loss: 0.491351]\n",
      "epoch:29 step:27712 [D loss: 0.577463, acc.: 69.53%] [G loss: 0.579239]\n",
      "epoch:29 step:27713 [D loss: 0.514336, acc.: 72.66%] [G loss: 0.729788]\n",
      "epoch:29 step:27714 [D loss: 0.510353, acc.: 73.44%] [G loss: 0.632660]\n",
      "epoch:29 step:27715 [D loss: 0.635700, acc.: 62.50%] [G loss: 0.606835]\n",
      "epoch:29 step:27716 [D loss: 0.630454, acc.: 62.50%] [G loss: 0.684676]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:29 step:27717 [D loss: 0.558148, acc.: 71.88%] [G loss: 0.684731]\n",
      "epoch:29 step:27718 [D loss: 0.554824, acc.: 71.09%] [G loss: 0.813334]\n",
      "epoch:29 step:27719 [D loss: 0.457913, acc.: 78.91%] [G loss: 0.913282]\n",
      "epoch:29 step:27720 [D loss: 0.555941, acc.: 67.19%] [G loss: 0.962627]\n",
      "epoch:29 step:27721 [D loss: 0.503335, acc.: 75.78%] [G loss: 0.961106]\n",
      "epoch:29 step:27722 [D loss: 0.482206, acc.: 75.00%] [G loss: 0.793044]\n",
      "epoch:29 step:27723 [D loss: 0.475389, acc.: 74.22%] [G loss: 0.776832]\n",
      "epoch:29 step:27724 [D loss: 0.466946, acc.: 78.12%] [G loss: 0.798258]\n",
      "epoch:29 step:27725 [D loss: 0.468547, acc.: 77.34%] [G loss: 0.725733]\n",
      "epoch:29 step:27726 [D loss: 0.568672, acc.: 70.31%] [G loss: 0.768910]\n",
      "epoch:29 step:27727 [D loss: 0.434442, acc.: 78.12%] [G loss: 1.039485]\n",
      "epoch:29 step:27728 [D loss: 0.428037, acc.: 78.12%] [G loss: 0.948554]\n",
      "epoch:29 step:27729 [D loss: 0.534732, acc.: 73.44%] [G loss: 0.887731]\n",
      "epoch:29 step:27730 [D loss: 0.513956, acc.: 75.00%] [G loss: 0.801616]\n",
      "epoch:29 step:27731 [D loss: 0.461019, acc.: 75.00%] [G loss: 0.871566]\n",
      "epoch:29 step:27732 [D loss: 0.608678, acc.: 60.94%] [G loss: 0.773674]\n",
      "epoch:29 step:27733 [D loss: 0.541359, acc.: 73.44%] [G loss: 0.869692]\n",
      "epoch:29 step:27734 [D loss: 0.500401, acc.: 72.66%] [G loss: 0.890779]\n",
      "epoch:29 step:27735 [D loss: 0.505041, acc.: 72.66%] [G loss: 0.757741]\n",
      "epoch:29 step:27736 [D loss: 0.497648, acc.: 70.31%] [G loss: 0.795462]\n",
      "epoch:29 step:27737 [D loss: 0.462092, acc.: 76.56%] [G loss: 0.875047]\n",
      "epoch:29 step:27738 [D loss: 0.511035, acc.: 76.56%] [G loss: 0.843570]\n",
      "epoch:29 step:27739 [D loss: 0.664342, acc.: 64.06%] [G loss: 0.730026]\n",
      "epoch:29 step:27740 [D loss: 0.482169, acc.: 75.00%] [G loss: 0.745393]\n",
      "epoch:29 step:27741 [D loss: 0.531628, acc.: 70.31%] [G loss: 0.879434]\n",
      "epoch:29 step:27742 [D loss: 0.501525, acc.: 76.56%] [G loss: 0.887722]\n",
      "epoch:29 step:27743 [D loss: 0.539631, acc.: 72.66%] [G loss: 0.883606]\n",
      "epoch:29 step:27744 [D loss: 0.500531, acc.: 76.56%] [G loss: 0.901824]\n",
      "epoch:29 step:27745 [D loss: 0.468348, acc.: 79.69%] [G loss: 0.792216]\n",
      "epoch:29 step:27746 [D loss: 0.564746, acc.: 70.31%] [G loss: 0.713194]\n",
      "epoch:29 step:27747 [D loss: 0.461569, acc.: 78.91%] [G loss: 0.832312]\n",
      "epoch:29 step:27748 [D loss: 0.467520, acc.: 82.81%] [G loss: 1.102398]\n",
      "epoch:29 step:27749 [D loss: 0.528277, acc.: 72.66%] [G loss: 0.859078]\n",
      "epoch:29 step:27750 [D loss: 0.527150, acc.: 72.66%] [G loss: 0.830238]\n",
      "epoch:29 step:27751 [D loss: 0.538766, acc.: 74.22%] [G loss: 1.053389]\n",
      "epoch:29 step:27752 [D loss: 0.543724, acc.: 71.88%] [G loss: 0.791674]\n",
      "epoch:29 step:27753 [D loss: 0.572726, acc.: 67.19%] [G loss: 0.699908]\n",
      "epoch:29 step:27754 [D loss: 0.493264, acc.: 73.44%] [G loss: 0.785832]\n",
      "epoch:29 step:27755 [D loss: 0.417222, acc.: 84.38%] [G loss: 1.080209]\n",
      "epoch:29 step:27756 [D loss: 0.536415, acc.: 71.09%] [G loss: 0.820205]\n",
      "epoch:29 step:27757 [D loss: 0.559361, acc.: 68.75%] [G loss: 0.632942]\n",
      "epoch:29 step:27758 [D loss: 0.523543, acc.: 74.22%] [G loss: 0.824457]\n",
      "epoch:29 step:27759 [D loss: 0.529012, acc.: 67.19%] [G loss: 0.776554]\n",
      "epoch:29 step:27760 [D loss: 0.551843, acc.: 66.41%] [G loss: 0.630834]\n",
      "epoch:29 step:27761 [D loss: 0.518125, acc.: 67.97%] [G loss: 0.676244]\n",
      "epoch:29 step:27762 [D loss: 0.450626, acc.: 78.91%] [G loss: 1.038858]\n",
      "epoch:29 step:27763 [D loss: 0.495236, acc.: 73.44%] [G loss: 0.785781]\n",
      "epoch:29 step:27764 [D loss: 0.586578, acc.: 67.97%] [G loss: 0.577229]\n",
      "epoch:29 step:27765 [D loss: 0.497205, acc.: 75.78%] [G loss: 0.741933]\n",
      "epoch:29 step:27766 [D loss: 0.514528, acc.: 75.00%] [G loss: 0.755354]\n",
      "epoch:29 step:27767 [D loss: 0.545811, acc.: 74.22%] [G loss: 0.856455]\n",
      "epoch:29 step:27768 [D loss: 0.535953, acc.: 71.88%] [G loss: 0.650872]\n",
      "epoch:29 step:27769 [D loss: 0.494221, acc.: 74.22%] [G loss: 0.696941]\n",
      "epoch:29 step:27770 [D loss: 0.504879, acc.: 75.00%] [G loss: 0.726222]\n",
      "epoch:29 step:27771 [D loss: 0.519208, acc.: 71.09%] [G loss: 0.870986]\n",
      "epoch:29 step:27772 [D loss: 0.530132, acc.: 71.09%] [G loss: 0.788419]\n",
      "epoch:29 step:27773 [D loss: 0.501868, acc.: 71.09%] [G loss: 0.718938]\n",
      "epoch:29 step:27774 [D loss: 0.504146, acc.: 73.44%] [G loss: 0.754321]\n",
      "epoch:29 step:27775 [D loss: 0.487924, acc.: 76.56%] [G loss: 0.811306]\n",
      "epoch:29 step:27776 [D loss: 0.433655, acc.: 82.03%] [G loss: 1.017009]\n",
      "epoch:29 step:27777 [D loss: 0.562394, acc.: 70.31%] [G loss: 0.998170]\n",
      "epoch:29 step:27778 [D loss: 0.450716, acc.: 79.69%] [G loss: 0.973520]\n",
      "epoch:29 step:27779 [D loss: 0.657060, acc.: 66.41%] [G loss: 0.690499]\n",
      "epoch:29 step:27780 [D loss: 0.519370, acc.: 74.22%] [G loss: 0.529570]\n",
      "epoch:29 step:27781 [D loss: 0.520706, acc.: 71.88%] [G loss: 0.758960]\n",
      "epoch:29 step:27782 [D loss: 0.519173, acc.: 71.09%] [G loss: 0.745694]\n",
      "epoch:29 step:27783 [D loss: 0.515307, acc.: 76.56%] [G loss: 0.619245]\n",
      "epoch:29 step:27784 [D loss: 0.493253, acc.: 71.09%] [G loss: 0.806492]\n",
      "epoch:29 step:27785 [D loss: 0.484043, acc.: 75.78%] [G loss: 0.755077]\n",
      "epoch:29 step:27786 [D loss: 0.474887, acc.: 75.00%] [G loss: 0.860087]\n",
      "epoch:29 step:27787 [D loss: 0.545443, acc.: 68.75%] [G loss: 0.726062]\n",
      "epoch:29 step:27788 [D loss: 0.550188, acc.: 64.84%] [G loss: 0.703028]\n",
      "epoch:29 step:27789 [D loss: 0.455157, acc.: 82.03%] [G loss: 0.759898]\n",
      "epoch:29 step:27790 [D loss: 0.492188, acc.: 73.44%] [G loss: 0.743800]\n",
      "epoch:29 step:27791 [D loss: 0.562827, acc.: 68.75%] [G loss: 0.739432]\n",
      "epoch:29 step:27792 [D loss: 0.507272, acc.: 72.66%] [G loss: 0.804823]\n",
      "epoch:29 step:27793 [D loss: 0.460692, acc.: 75.00%] [G loss: 0.778208]\n",
      "epoch:29 step:27794 [D loss: 0.578729, acc.: 70.31%] [G loss: 0.624716]\n",
      "epoch:29 step:27795 [D loss: 0.558686, acc.: 72.66%] [G loss: 0.691343]\n",
      "epoch:29 step:27796 [D loss: 0.424466, acc.: 83.59%] [G loss: 0.918449]\n",
      "epoch:29 step:27797 [D loss: 0.418495, acc.: 83.59%] [G loss: 0.869588]\n",
      "epoch:29 step:27798 [D loss: 0.546305, acc.: 69.53%] [G loss: 0.770906]\n",
      "epoch:29 step:27799 [D loss: 0.514270, acc.: 71.09%] [G loss: 0.846542]\n",
      "epoch:29 step:27800 [D loss: 0.464324, acc.: 75.00%] [G loss: 0.792692]\n",
      "epoch:29 step:27801 [D loss: 0.521584, acc.: 72.66%] [G loss: 0.911090]\n",
      "epoch:29 step:27802 [D loss: 0.473626, acc.: 75.78%] [G loss: 1.021111]\n",
      "epoch:29 step:27803 [D loss: 0.543319, acc.: 71.88%] [G loss: 0.762775]\n",
      "epoch:29 step:27804 [D loss: 0.473654, acc.: 77.34%] [G loss: 0.892165]\n",
      "epoch:29 step:27805 [D loss: 0.500013, acc.: 75.00%] [G loss: 0.850360]\n",
      "epoch:29 step:27806 [D loss: 0.535785, acc.: 71.88%] [G loss: 1.057593]\n",
      "epoch:29 step:27807 [D loss: 0.442173, acc.: 81.25%] [G loss: 0.817957]\n",
      "epoch:29 step:27808 [D loss: 0.509673, acc.: 71.09%] [G loss: 0.927699]\n",
      "epoch:29 step:27809 [D loss: 0.537619, acc.: 69.53%] [G loss: 0.714941]\n",
      "epoch:29 step:27810 [D loss: 0.495903, acc.: 71.88%] [G loss: 0.775098]\n",
      "epoch:29 step:27811 [D loss: 0.546269, acc.: 67.19%] [G loss: 0.695568]\n",
      "epoch:29 step:27812 [D loss: 0.482664, acc.: 77.34%] [G loss: 0.684573]\n",
      "epoch:29 step:27813 [D loss: 0.506400, acc.: 73.44%] [G loss: 0.794942]\n",
      "epoch:29 step:27814 [D loss: 0.459137, acc.: 78.91%] [G loss: 0.772709]\n",
      "epoch:29 step:27815 [D loss: 0.420350, acc.: 81.25%] [G loss: 0.950699]\n",
      "epoch:29 step:27816 [D loss: 0.486811, acc.: 75.00%] [G loss: 1.093913]\n",
      "epoch:29 step:27817 [D loss: 0.530259, acc.: 69.53%] [G loss: 0.839775]\n",
      "epoch:29 step:27818 [D loss: 0.538366, acc.: 71.09%] [G loss: 0.862304]\n",
      "epoch:29 step:27819 [D loss: 0.515710, acc.: 73.44%] [G loss: 0.825695]\n",
      "epoch:29 step:27820 [D loss: 0.444287, acc.: 76.56%] [G loss: 0.950168]\n",
      "epoch:29 step:27821 [D loss: 0.329395, acc.: 89.84%] [G loss: 1.108883]\n",
      "epoch:29 step:27822 [D loss: 0.450870, acc.: 79.69%] [G loss: 1.196348]\n",
      "epoch:29 step:27823 [D loss: 0.461545, acc.: 75.78%] [G loss: 1.122839]\n",
      "epoch:29 step:27824 [D loss: 0.468170, acc.: 78.91%] [G loss: 0.932463]\n",
      "epoch:29 step:27825 [D loss: 0.557093, acc.: 70.31%] [G loss: 0.818305]\n",
      "epoch:29 step:27826 [D loss: 0.580889, acc.: 69.53%] [G loss: 0.837626]\n",
      "epoch:29 step:27827 [D loss: 0.421948, acc.: 82.03%] [G loss: 0.974767]\n",
      "epoch:29 step:27828 [D loss: 0.555801, acc.: 67.97%] [G loss: 0.847136]\n",
      "epoch:29 step:27829 [D loss: 0.541561, acc.: 73.44%] [G loss: 0.836168]\n",
      "epoch:29 step:27830 [D loss: 0.477369, acc.: 75.78%] [G loss: 0.640946]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:29 step:27831 [D loss: 0.519780, acc.: 70.31%] [G loss: 0.821565]\n",
      "epoch:29 step:27832 [D loss: 0.513206, acc.: 72.66%] [G loss: 0.821273]\n",
      "epoch:29 step:27833 [D loss: 0.498527, acc.: 75.00%] [G loss: 0.902377]\n",
      "epoch:29 step:27834 [D loss: 0.499254, acc.: 73.44%] [G loss: 0.915270]\n",
      "epoch:29 step:27835 [D loss: 0.445936, acc.: 75.78%] [G loss: 0.896988]\n",
      "epoch:29 step:27836 [D loss: 0.514795, acc.: 71.88%] [G loss: 0.712216]\n",
      "epoch:29 step:27837 [D loss: 0.564200, acc.: 65.62%] [G loss: 0.929595]\n",
      "epoch:29 step:27838 [D loss: 0.573253, acc.: 69.53%] [G loss: 0.739696]\n",
      "epoch:29 step:27839 [D loss: 0.449615, acc.: 81.25%] [G loss: 0.781886]\n",
      "epoch:29 step:27840 [D loss: 0.520236, acc.: 77.34%] [G loss: 0.793285]\n",
      "epoch:29 step:27841 [D loss: 0.619246, acc.: 61.72%] [G loss: 0.618081]\n",
      "epoch:29 step:27842 [D loss: 0.510580, acc.: 75.00%] [G loss: 0.748386]\n",
      "epoch:29 step:27843 [D loss: 0.566728, acc.: 71.09%] [G loss: 0.592248]\n",
      "epoch:29 step:27844 [D loss: 0.581588, acc.: 67.97%] [G loss: 0.751593]\n",
      "epoch:29 step:27845 [D loss: 0.541463, acc.: 68.75%] [G loss: 0.867609]\n",
      "epoch:29 step:27846 [D loss: 0.563034, acc.: 70.31%] [G loss: 0.723106]\n",
      "epoch:29 step:27847 [D loss: 0.472908, acc.: 75.78%] [G loss: 0.878450]\n",
      "epoch:29 step:27848 [D loss: 0.603923, acc.: 66.41%] [G loss: 0.627523]\n",
      "epoch:29 step:27849 [D loss: 0.530290, acc.: 71.09%] [G loss: 0.786070]\n",
      "epoch:29 step:27850 [D loss: 0.515734, acc.: 76.56%] [G loss: 0.891525]\n",
      "epoch:29 step:27851 [D loss: 0.507652, acc.: 75.00%] [G loss: 0.826349]\n",
      "epoch:29 step:27852 [D loss: 0.516610, acc.: 75.78%] [G loss: 0.715783]\n",
      "epoch:29 step:27853 [D loss: 0.473449, acc.: 77.34%] [G loss: 0.810179]\n",
      "epoch:29 step:27854 [D loss: 0.458287, acc.: 78.91%] [G loss: 0.912500]\n",
      "epoch:29 step:27855 [D loss: 0.487556, acc.: 71.88%] [G loss: 0.850530]\n",
      "epoch:29 step:27856 [D loss: 0.509789, acc.: 74.22%] [G loss: 0.716676]\n",
      "epoch:29 step:27857 [D loss: 0.590456, acc.: 63.28%] [G loss: 0.587468]\n",
      "epoch:29 step:27858 [D loss: 0.486945, acc.: 78.12%] [G loss: 0.778995]\n",
      "epoch:29 step:27859 [D loss: 0.563294, acc.: 71.09%] [G loss: 0.578045]\n",
      "epoch:29 step:27860 [D loss: 0.523654, acc.: 68.75%] [G loss: 0.591529]\n",
      "epoch:29 step:27861 [D loss: 0.498394, acc.: 74.22%] [G loss: 0.783978]\n",
      "epoch:29 step:27862 [D loss: 0.580771, acc.: 67.19%] [G loss: 0.576313]\n",
      "epoch:29 step:27863 [D loss: 0.466138, acc.: 78.12%] [G loss: 0.781474]\n",
      "epoch:29 step:27864 [D loss: 0.457747, acc.: 80.47%] [G loss: 0.940188]\n",
      "epoch:29 step:27865 [D loss: 0.508430, acc.: 73.44%] [G loss: 0.870235]\n",
      "epoch:29 step:27866 [D loss: 0.448064, acc.: 77.34%] [G loss: 0.761875]\n",
      "epoch:29 step:27867 [D loss: 0.496372, acc.: 74.22%] [G loss: 0.724110]\n",
      "epoch:29 step:27868 [D loss: 0.509320, acc.: 76.56%] [G loss: 0.783304]\n",
      "epoch:29 step:27869 [D loss: 0.599834, acc.: 67.97%] [G loss: 1.024642]\n",
      "epoch:29 step:27870 [D loss: 0.593231, acc.: 64.06%] [G loss: 0.723891]\n",
      "epoch:29 step:27871 [D loss: 0.580085, acc.: 65.62%] [G loss: 0.687874]\n",
      "epoch:29 step:27872 [D loss: 0.526507, acc.: 68.75%] [G loss: 0.735770]\n",
      "epoch:29 step:27873 [D loss: 0.485030, acc.: 76.56%] [G loss: 0.862322]\n",
      "epoch:29 step:27874 [D loss: 0.521406, acc.: 74.22%] [G loss: 1.025362]\n",
      "epoch:29 step:27875 [D loss: 0.583984, acc.: 69.53%] [G loss: 0.784291]\n",
      "epoch:29 step:27876 [D loss: 0.583610, acc.: 67.97%] [G loss: 0.686753]\n",
      "epoch:29 step:27877 [D loss: 0.609933, acc.: 64.84%] [G loss: 0.725701]\n",
      "epoch:29 step:27878 [D loss: 0.520243, acc.: 73.44%] [G loss: 0.556239]\n",
      "epoch:29 step:27879 [D loss: 0.475030, acc.: 78.12%] [G loss: 0.829720]\n",
      "epoch:29 step:27880 [D loss: 0.518843, acc.: 69.53%] [G loss: 0.813820]\n",
      "epoch:29 step:27881 [D loss: 0.428554, acc.: 78.12%] [G loss: 1.067557]\n",
      "epoch:29 step:27882 [D loss: 0.547896, acc.: 71.88%] [G loss: 1.032269]\n",
      "epoch:29 step:27883 [D loss: 0.574128, acc.: 67.19%] [G loss: 0.735098]\n",
      "epoch:29 step:27884 [D loss: 0.505628, acc.: 71.09%] [G loss: 0.824936]\n",
      "epoch:29 step:27885 [D loss: 0.491999, acc.: 71.88%] [G loss: 0.938302]\n",
      "epoch:29 step:27886 [D loss: 0.607969, acc.: 61.72%] [G loss: 0.726457]\n",
      "epoch:29 step:27887 [D loss: 0.489685, acc.: 72.66%] [G loss: 0.721213]\n",
      "epoch:29 step:27888 [D loss: 0.524689, acc.: 72.66%] [G loss: 0.749834]\n",
      "epoch:29 step:27889 [D loss: 0.560472, acc.: 71.88%] [G loss: 0.779324]\n",
      "epoch:29 step:27890 [D loss: 0.514250, acc.: 73.44%] [G loss: 0.685777]\n",
      "epoch:29 step:27891 [D loss: 0.496751, acc.: 78.91%] [G loss: 0.567343]\n",
      "epoch:29 step:27892 [D loss: 0.442487, acc.: 81.25%] [G loss: 0.741757]\n",
      "epoch:29 step:27893 [D loss: 0.541856, acc.: 70.31%] [G loss: 0.667794]\n",
      "epoch:29 step:27894 [D loss: 0.579644, acc.: 67.97%] [G loss: 0.770832]\n",
      "epoch:29 step:27895 [D loss: 0.502952, acc.: 77.34%] [G loss: 0.783127]\n",
      "epoch:29 step:27896 [D loss: 0.506975, acc.: 75.78%] [G loss: 0.664294]\n",
      "epoch:29 step:27897 [D loss: 0.481580, acc.: 72.66%] [G loss: 0.781258]\n",
      "epoch:29 step:27898 [D loss: 0.496408, acc.: 71.09%] [G loss: 0.813766]\n",
      "epoch:29 step:27899 [D loss: 0.453778, acc.: 79.69%] [G loss: 0.937798]\n",
      "epoch:29 step:27900 [D loss: 0.509154, acc.: 73.44%] [G loss: 0.763777]\n",
      "epoch:29 step:27901 [D loss: 0.492451, acc.: 71.88%] [G loss: 0.811212]\n",
      "epoch:29 step:27902 [D loss: 0.557645, acc.: 69.53%] [G loss: 0.799039]\n",
      "epoch:29 step:27903 [D loss: 0.445346, acc.: 81.25%] [G loss: 0.806455]\n",
      "epoch:29 step:27904 [D loss: 0.553919, acc.: 70.31%] [G loss: 0.582001]\n",
      "epoch:29 step:27905 [D loss: 0.497208, acc.: 72.66%] [G loss: 0.858212]\n",
      "epoch:29 step:27906 [D loss: 0.492098, acc.: 74.22%] [G loss: 0.635692]\n",
      "epoch:29 step:27907 [D loss: 0.527226, acc.: 72.66%] [G loss: 0.691404]\n",
      "epoch:29 step:27908 [D loss: 0.508450, acc.: 74.22%] [G loss: 0.737976]\n",
      "epoch:29 step:27909 [D loss: 0.472465, acc.: 75.00%] [G loss: 0.697049]\n",
      "epoch:29 step:27910 [D loss: 0.557715, acc.: 67.97%] [G loss: 0.609525]\n",
      "epoch:29 step:27911 [D loss: 0.526509, acc.: 73.44%] [G loss: 0.649644]\n",
      "epoch:29 step:27912 [D loss: 0.535425, acc.: 73.44%] [G loss: 0.680976]\n",
      "epoch:29 step:27913 [D loss: 0.633010, acc.: 61.72%] [G loss: 0.529467]\n",
      "epoch:29 step:27914 [D loss: 0.507819, acc.: 74.22%] [G loss: 0.504889]\n",
      "epoch:29 step:27915 [D loss: 0.531707, acc.: 73.44%] [G loss: 0.752741]\n",
      "epoch:29 step:27916 [D loss: 0.476163, acc.: 75.00%] [G loss: 0.698324]\n",
      "epoch:29 step:27917 [D loss: 0.543679, acc.: 73.44%] [G loss: 0.723030]\n",
      "epoch:29 step:27918 [D loss: 0.588280, acc.: 66.41%] [G loss: 0.940673]\n",
      "epoch:29 step:27919 [D loss: 0.423114, acc.: 81.25%] [G loss: 0.880513]\n",
      "epoch:29 step:27920 [D loss: 0.393606, acc.: 82.03%] [G loss: 1.008997]\n",
      "epoch:29 step:27921 [D loss: 0.589250, acc.: 67.97%] [G loss: 0.815338]\n",
      "epoch:29 step:27922 [D loss: 0.492886, acc.: 74.22%] [G loss: 0.866761]\n",
      "epoch:29 step:27923 [D loss: 0.442758, acc.: 79.69%] [G loss: 0.814511]\n",
      "epoch:29 step:27924 [D loss: 0.476263, acc.: 72.66%] [G loss: 0.883882]\n",
      "epoch:29 step:27925 [D loss: 0.570237, acc.: 69.53%] [G loss: 0.820616]\n",
      "epoch:29 step:27926 [D loss: 0.500127, acc.: 76.56%] [G loss: 0.815452]\n",
      "epoch:29 step:27927 [D loss: 0.566605, acc.: 66.41%] [G loss: 0.835958]\n",
      "epoch:29 step:27928 [D loss: 0.504517, acc.: 74.22%] [G loss: 0.688218]\n",
      "epoch:29 step:27929 [D loss: 0.561871, acc.: 67.19%] [G loss: 0.696995]\n",
      "epoch:29 step:27930 [D loss: 0.574292, acc.: 70.31%] [G loss: 0.720170]\n",
      "epoch:29 step:27931 [D loss: 0.534780, acc.: 75.00%] [G loss: 0.894861]\n",
      "epoch:29 step:27932 [D loss: 0.499184, acc.: 75.00%] [G loss: 0.745235]\n",
      "epoch:29 step:27933 [D loss: 0.519324, acc.: 71.88%] [G loss: 0.588276]\n",
      "epoch:29 step:27934 [D loss: 0.533015, acc.: 72.66%] [G loss: 0.667084]\n",
      "epoch:29 step:27935 [D loss: 0.552127, acc.: 70.31%] [G loss: 0.645577]\n",
      "epoch:29 step:27936 [D loss: 0.541732, acc.: 71.09%] [G loss: 0.599465]\n",
      "epoch:29 step:27937 [D loss: 0.559842, acc.: 61.72%] [G loss: 0.661341]\n",
      "epoch:29 step:27938 [D loss: 0.554779, acc.: 67.97%] [G loss: 0.837402]\n",
      "epoch:29 step:27939 [D loss: 0.584438, acc.: 69.53%] [G loss: 0.676147]\n",
      "epoch:29 step:27940 [D loss: 0.528808, acc.: 71.09%] [G loss: 0.661781]\n",
      "epoch:29 step:27941 [D loss: 0.506490, acc.: 73.44%] [G loss: 0.800317]\n",
      "epoch:29 step:27942 [D loss: 0.498909, acc.: 75.00%] [G loss: 0.980395]\n",
      "epoch:29 step:27943 [D loss: 0.520067, acc.: 72.66%] [G loss: 1.009720]\n",
      "epoch:29 step:27944 [D loss: 0.493848, acc.: 73.44%] [G loss: 0.990262]\n",
      "epoch:29 step:27945 [D loss: 0.551570, acc.: 68.75%] [G loss: 0.926902]\n",
      "epoch:29 step:27946 [D loss: 0.538566, acc.: 70.31%] [G loss: 0.944916]\n",
      "epoch:29 step:27947 [D loss: 0.474145, acc.: 75.78%] [G loss: 0.797098]\n",
      "epoch:29 step:27948 [D loss: 0.511979, acc.: 71.88%] [G loss: 0.912413]\n",
      "epoch:29 step:27949 [D loss: 0.532701, acc.: 71.09%] [G loss: 0.837378]\n",
      "epoch:29 step:27950 [D loss: 0.499415, acc.: 71.88%] [G loss: 0.739938]\n",
      "epoch:29 step:27951 [D loss: 0.532302, acc.: 71.88%] [G loss: 0.808195]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:29 step:27952 [D loss: 0.534866, acc.: 73.44%] [G loss: 0.790321]\n",
      "epoch:29 step:27953 [D loss: 0.428416, acc.: 79.69%] [G loss: 0.761788]\n",
      "epoch:29 step:27954 [D loss: 0.454136, acc.: 75.00%] [G loss: 0.809543]\n",
      "epoch:29 step:27955 [D loss: 0.460669, acc.: 78.12%] [G loss: 1.098123]\n",
      "epoch:29 step:27956 [D loss: 0.482582, acc.: 75.78%] [G loss: 1.332481]\n",
      "epoch:29 step:27957 [D loss: 0.587496, acc.: 70.31%] [G loss: 0.890623]\n",
      "epoch:29 step:27958 [D loss: 0.500198, acc.: 78.12%] [G loss: 0.703218]\n",
      "epoch:29 step:27959 [D loss: 0.496747, acc.: 75.78%] [G loss: 0.794322]\n",
      "epoch:29 step:27960 [D loss: 0.559474, acc.: 70.31%] [G loss: 0.783280]\n",
      "epoch:29 step:27961 [D loss: 0.582156, acc.: 70.31%] [G loss: 0.814230]\n",
      "epoch:29 step:27962 [D loss: 0.512605, acc.: 75.00%] [G loss: 0.758502]\n",
      "epoch:29 step:27963 [D loss: 0.478396, acc.: 73.44%] [G loss: 0.747051]\n",
      "epoch:29 step:27964 [D loss: 0.574365, acc.: 71.09%] [G loss: 0.713365]\n",
      "epoch:29 step:27965 [D loss: 0.463402, acc.: 71.88%] [G loss: 0.819328]\n",
      "epoch:29 step:27966 [D loss: 0.602247, acc.: 68.75%] [G loss: 0.642679]\n",
      "epoch:29 step:27967 [D loss: 0.587169, acc.: 62.50%] [G loss: 0.707597]\n",
      "epoch:29 step:27968 [D loss: 0.609016, acc.: 67.19%] [G loss: 0.752430]\n",
      "epoch:29 step:27969 [D loss: 0.453256, acc.: 78.91%] [G loss: 0.966038]\n",
      "epoch:29 step:27970 [D loss: 0.525170, acc.: 67.97%] [G loss: 0.878196]\n",
      "epoch:29 step:27971 [D loss: 0.561048, acc.: 69.53%] [G loss: 0.725261]\n",
      "epoch:29 step:27972 [D loss: 0.553232, acc.: 71.09%] [G loss: 0.677138]\n",
      "epoch:29 step:27973 [D loss: 0.597927, acc.: 69.53%] [G loss: 0.802956]\n",
      "epoch:29 step:27974 [D loss: 0.515821, acc.: 74.22%] [G loss: 0.706762]\n",
      "epoch:29 step:27975 [D loss: 0.456388, acc.: 77.34%] [G loss: 0.911478]\n",
      "epoch:29 step:27976 [D loss: 0.466671, acc.: 75.78%] [G loss: 1.050270]\n",
      "epoch:29 step:27977 [D loss: 0.477091, acc.: 74.22%] [G loss: 0.829200]\n",
      "epoch:29 step:27978 [D loss: 0.521554, acc.: 72.66%] [G loss: 0.802019]\n",
      "epoch:29 step:27979 [D loss: 0.582502, acc.: 69.53%] [G loss: 0.530756]\n",
      "epoch:29 step:27980 [D loss: 0.486854, acc.: 76.56%] [G loss: 0.664815]\n",
      "epoch:29 step:27981 [D loss: 0.532746, acc.: 76.56%] [G loss: 0.640644]\n",
      "epoch:29 step:27982 [D loss: 0.482136, acc.: 78.12%] [G loss: 0.726150]\n",
      "epoch:29 step:27983 [D loss: 0.472080, acc.: 75.78%] [G loss: 0.701811]\n",
      "epoch:29 step:27984 [D loss: 0.555626, acc.: 71.88%] [G loss: 0.747220]\n",
      "epoch:29 step:27985 [D loss: 0.596192, acc.: 66.41%] [G loss: 0.601527]\n",
      "epoch:29 step:27986 [D loss: 0.492876, acc.: 73.44%] [G loss: 0.622219]\n",
      "epoch:29 step:27987 [D loss: 0.452171, acc.: 79.69%] [G loss: 0.815924]\n",
      "epoch:29 step:27988 [D loss: 0.480628, acc.: 80.47%] [G loss: 1.068152]\n",
      "epoch:29 step:27989 [D loss: 0.479411, acc.: 76.56%] [G loss: 0.923880]\n",
      "epoch:29 step:27990 [D loss: 0.542496, acc.: 72.66%] [G loss: 0.847014]\n",
      "epoch:29 step:27991 [D loss: 0.608446, acc.: 64.06%] [G loss: 0.677616]\n",
      "epoch:29 step:27992 [D loss: 0.481016, acc.: 80.47%] [G loss: 0.794758]\n",
      "epoch:29 step:27993 [D loss: 0.630270, acc.: 60.94%] [G loss: 0.709375]\n",
      "epoch:29 step:27994 [D loss: 0.529365, acc.: 71.09%] [G loss: 0.503854]\n",
      "epoch:29 step:27995 [D loss: 0.547292, acc.: 67.97%] [G loss: 0.684381]\n",
      "epoch:29 step:27996 [D loss: 0.400002, acc.: 80.47%] [G loss: 0.552895]\n",
      "epoch:29 step:27997 [D loss: 0.536843, acc.: 75.00%] [G loss: 0.620344]\n",
      "epoch:29 step:27998 [D loss: 0.471218, acc.: 77.34%] [G loss: 0.728660]\n",
      "epoch:29 step:27999 [D loss: 0.493455, acc.: 76.56%] [G loss: 0.699526]\n",
      "epoch:29 step:28000 [D loss: 0.617142, acc.: 67.97%] [G loss: 0.763876]\n",
      "epoch:29 step:28001 [D loss: 0.652864, acc.: 61.72%] [G loss: 0.693857]\n",
      "epoch:29 step:28002 [D loss: 0.568067, acc.: 67.97%] [G loss: 0.690690]\n",
      "epoch:29 step:28003 [D loss: 0.520022, acc.: 71.09%] [G loss: 0.623018]\n",
      "epoch:29 step:28004 [D loss: 0.532708, acc.: 65.62%] [G loss: 0.616852]\n",
      "epoch:29 step:28005 [D loss: 0.463136, acc.: 76.56%] [G loss: 0.674923]\n",
      "epoch:29 step:28006 [D loss: 0.507779, acc.: 75.78%] [G loss: 0.785822]\n",
      "epoch:29 step:28007 [D loss: 0.456955, acc.: 76.56%] [G loss: 0.737461]\n",
      "epoch:29 step:28008 [D loss: 0.487562, acc.: 72.66%] [G loss: 0.673623]\n",
      "epoch:29 step:28009 [D loss: 0.557262, acc.: 68.75%] [G loss: 0.556432]\n",
      "epoch:29 step:28010 [D loss: 0.516366, acc.: 74.22%] [G loss: 0.724621]\n",
      "epoch:29 step:28011 [D loss: 0.551201, acc.: 69.53%] [G loss: 0.645957]\n",
      "epoch:29 step:28012 [D loss: 0.528824, acc.: 67.97%] [G loss: 0.757591]\n",
      "epoch:29 step:28013 [D loss: 0.569758, acc.: 68.75%] [G loss: 0.645492]\n",
      "epoch:29 step:28014 [D loss: 0.516741, acc.: 74.22%] [G loss: 0.603824]\n",
      "epoch:29 step:28015 [D loss: 0.469785, acc.: 76.56%] [G loss: 0.613019]\n",
      "epoch:29 step:28016 [D loss: 0.483304, acc.: 77.34%] [G loss: 0.741655]\n",
      "epoch:29 step:28017 [D loss: 0.497106, acc.: 73.44%] [G loss: 0.733259]\n",
      "epoch:29 step:28018 [D loss: 0.580658, acc.: 68.75%] [G loss: 0.816563]\n",
      "epoch:29 step:28019 [D loss: 0.508797, acc.: 71.09%] [G loss: 0.727211]\n",
      "epoch:29 step:28020 [D loss: 0.644559, acc.: 61.72%] [G loss: 0.510271]\n",
      "epoch:29 step:28021 [D loss: 0.513883, acc.: 71.88%] [G loss: 0.501196]\n",
      "epoch:29 step:28022 [D loss: 0.520636, acc.: 76.56%] [G loss: 0.707056]\n",
      "epoch:29 step:28023 [D loss: 0.533096, acc.: 67.19%] [G loss: 0.716456]\n",
      "epoch:29 step:28024 [D loss: 0.611597, acc.: 69.53%] [G loss: 0.599517]\n",
      "epoch:29 step:28025 [D loss: 0.489174, acc.: 74.22%] [G loss: 0.702569]\n",
      "epoch:29 step:28026 [D loss: 0.538063, acc.: 67.19%] [G loss: 0.769935]\n",
      "epoch:29 step:28027 [D loss: 0.509257, acc.: 67.19%] [G loss: 0.671618]\n",
      "epoch:29 step:28028 [D loss: 0.610968, acc.: 64.06%] [G loss: 0.784489]\n",
      "epoch:29 step:28029 [D loss: 0.577140, acc.: 69.53%] [G loss: 0.654944]\n",
      "epoch:29 step:28030 [D loss: 0.454949, acc.: 72.66%] [G loss: 0.665882]\n",
      "epoch:29 step:28031 [D loss: 0.614635, acc.: 61.72%] [G loss: 0.623972]\n",
      "epoch:29 step:28032 [D loss: 0.549470, acc.: 70.31%] [G loss: 0.781935]\n",
      "epoch:29 step:28033 [D loss: 0.449946, acc.: 79.69%] [G loss: 0.910121]\n",
      "epoch:29 step:28034 [D loss: 0.588164, acc.: 67.19%] [G loss: 0.729802]\n",
      "epoch:29 step:28035 [D loss: 0.552768, acc.: 72.66%] [G loss: 0.546320]\n",
      "epoch:29 step:28036 [D loss: 0.565508, acc.: 64.84%] [G loss: 0.495286]\n",
      "epoch:29 step:28037 [D loss: 0.508830, acc.: 71.88%] [G loss: 0.644921]\n",
      "epoch:29 step:28038 [D loss: 0.551734, acc.: 71.09%] [G loss: 0.683786]\n",
      "epoch:29 step:28039 [D loss: 0.533153, acc.: 71.09%] [G loss: 0.684998]\n",
      "epoch:29 step:28040 [D loss: 0.626964, acc.: 64.06%] [G loss: 0.570576]\n",
      "epoch:29 step:28041 [D loss: 0.483954, acc.: 77.34%] [G loss: 0.505338]\n",
      "epoch:29 step:28042 [D loss: 0.566218, acc.: 65.62%] [G loss: 0.597322]\n",
      "epoch:29 step:28043 [D loss: 0.472000, acc.: 78.91%] [G loss: 0.817494]\n",
      "epoch:29 step:28044 [D loss: 0.442306, acc.: 78.91%] [G loss: 0.939249]\n",
      "epoch:29 step:28045 [D loss: 0.516005, acc.: 75.78%] [G loss: 0.930893]\n",
      "epoch:29 step:28046 [D loss: 0.557261, acc.: 70.31%] [G loss: 0.602668]\n",
      "epoch:29 step:28047 [D loss: 0.504848, acc.: 70.31%] [G loss: 0.839167]\n",
      "epoch:29 step:28048 [D loss: 0.462796, acc.: 78.12%] [G loss: 0.562131]\n",
      "epoch:29 step:28049 [D loss: 0.535300, acc.: 71.09%] [G loss: 0.572263]\n",
      "epoch:29 step:28050 [D loss: 0.556620, acc.: 69.53%] [G loss: 0.580006]\n",
      "epoch:29 step:28051 [D loss: 0.505268, acc.: 75.00%] [G loss: 0.702639]\n",
      "epoch:29 step:28052 [D loss: 0.552423, acc.: 72.66%] [G loss: 0.687140]\n",
      "epoch:29 step:28053 [D loss: 0.620309, acc.: 67.19%] [G loss: 0.562838]\n",
      "epoch:29 step:28054 [D loss: 0.605154, acc.: 57.03%] [G loss: 0.576174]\n",
      "epoch:29 step:28055 [D loss: 0.578347, acc.: 67.97%] [G loss: 0.537739]\n",
      "epoch:29 step:28056 [D loss: 0.617642, acc.: 63.28%] [G loss: 0.531632]\n",
      "epoch:29 step:28057 [D loss: 0.520658, acc.: 71.88%] [G loss: 0.714962]\n",
      "epoch:29 step:28058 [D loss: 0.501405, acc.: 73.44%] [G loss: 0.793668]\n",
      "epoch:29 step:28059 [D loss: 0.489733, acc.: 75.00%] [G loss: 0.846293]\n",
      "epoch:29 step:28060 [D loss: 0.551125, acc.: 67.19%] [G loss: 0.816378]\n",
      "epoch:29 step:28061 [D loss: 0.517411, acc.: 73.44%] [G loss: 0.921858]\n",
      "epoch:29 step:28062 [D loss: 0.491765, acc.: 73.44%] [G loss: 0.721063]\n",
      "epoch:29 step:28063 [D loss: 0.468755, acc.: 78.12%] [G loss: 0.723281]\n",
      "epoch:29 step:28064 [D loss: 0.572892, acc.: 70.31%] [G loss: 0.959588]\n",
      "epoch:29 step:28065 [D loss: 0.660467, acc.: 61.72%] [G loss: 0.612507]\n",
      "epoch:29 step:28066 [D loss: 0.550462, acc.: 67.19%] [G loss: 0.526189]\n",
      "epoch:29 step:28067 [D loss: 0.482503, acc.: 76.56%] [G loss: 0.727151]\n",
      "epoch:29 step:28068 [D loss: 0.548319, acc.: 72.66%] [G loss: 0.802701]\n",
      "epoch:29 step:28069 [D loss: 0.501454, acc.: 71.88%] [G loss: 0.783000]\n",
      "epoch:29 step:28070 [D loss: 0.503286, acc.: 67.97%] [G loss: 0.903046]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:29 step:28071 [D loss: 0.388833, acc.: 83.59%] [G loss: 0.980645]\n",
      "epoch:29 step:28072 [D loss: 0.437649, acc.: 79.69%] [G loss: 0.982872]\n",
      "epoch:29 step:28073 [D loss: 0.454860, acc.: 82.03%] [G loss: 0.807591]\n",
      "epoch:29 step:28074 [D loss: 0.566378, acc.: 71.09%] [G loss: 0.776410]\n",
      "epoch:29 step:28075 [D loss: 0.617441, acc.: 64.84%] [G loss: 0.654344]\n",
      "epoch:29 step:28076 [D loss: 0.522473, acc.: 69.53%] [G loss: 0.728431]\n",
      "epoch:29 step:28077 [D loss: 0.583220, acc.: 71.09%] [G loss: 0.720243]\n",
      "epoch:29 step:28078 [D loss: 0.560016, acc.: 67.97%] [G loss: 0.663932]\n",
      "epoch:29 step:28079 [D loss: 0.446026, acc.: 82.03%] [G loss: 0.849584]\n",
      "epoch:29 step:28080 [D loss: 0.524890, acc.: 72.66%] [G loss: 0.705915]\n",
      "epoch:29 step:28081 [D loss: 0.565975, acc.: 66.41%] [G loss: 0.673951]\n",
      "epoch:29 step:28082 [D loss: 0.456006, acc.: 75.00%] [G loss: 0.987622]\n",
      "epoch:29 step:28083 [D loss: 0.565168, acc.: 70.31%] [G loss: 0.707872]\n",
      "epoch:29 step:28084 [D loss: 0.486660, acc.: 75.00%] [G loss: 0.659368]\n",
      "epoch:29 step:28085 [D loss: 0.422750, acc.: 79.69%] [G loss: 1.058224]\n",
      "epoch:29 step:28086 [D loss: 0.556284, acc.: 72.66%] [G loss: 0.912330]\n",
      "epoch:29 step:28087 [D loss: 0.505991, acc.: 70.31%] [G loss: 0.918097]\n",
      "epoch:29 step:28088 [D loss: 0.625661, acc.: 64.06%] [G loss: 0.684478]\n",
      "epoch:29 step:28089 [D loss: 0.491018, acc.: 75.78%] [G loss: 0.817843]\n",
      "epoch:29 step:28090 [D loss: 0.549792, acc.: 67.19%] [G loss: 0.715028]\n",
      "epoch:29 step:28091 [D loss: 0.435295, acc.: 80.47%] [G loss: 0.906176]\n",
      "epoch:29 step:28092 [D loss: 0.404348, acc.: 85.94%] [G loss: 0.996404]\n",
      "epoch:29 step:28093 [D loss: 0.651103, acc.: 59.38%] [G loss: 0.840026]\n",
      "epoch:29 step:28094 [D loss: 0.459475, acc.: 78.12%] [G loss: 0.969569]\n",
      "epoch:29 step:28095 [D loss: 0.566415, acc.: 67.97%] [G loss: 0.886317]\n",
      "epoch:29 step:28096 [D loss: 0.387210, acc.: 81.25%] [G loss: 0.910408]\n",
      "epoch:29 step:28097 [D loss: 0.455693, acc.: 79.69%] [G loss: 1.051246]\n",
      "epoch:29 step:28098 [D loss: 0.351121, acc.: 85.94%] [G loss: 1.151216]\n",
      "epoch:29 step:28099 [D loss: 0.463232, acc.: 71.88%] [G loss: 1.249666]\n",
      "epoch:29 step:28100 [D loss: 0.482454, acc.: 73.44%] [G loss: 1.546758]\n",
      "epoch:29 step:28101 [D loss: 0.658125, acc.: 63.28%] [G loss: 1.562445]\n",
      "epoch:29 step:28102 [D loss: 0.474192, acc.: 77.34%] [G loss: 1.348412]\n",
      "epoch:29 step:28103 [D loss: 0.467461, acc.: 73.44%] [G loss: 1.235466]\n",
      "epoch:29 step:28104 [D loss: 0.440800, acc.: 76.56%] [G loss: 1.225673]\n",
      "epoch:29 step:28105 [D loss: 0.564310, acc.: 67.97%] [G loss: 0.755179]\n",
      "epoch:29 step:28106 [D loss: 0.469076, acc.: 72.66%] [G loss: 0.985777]\n",
      "epoch:29 step:28107 [D loss: 0.589200, acc.: 67.19%] [G loss: 1.026320]\n",
      "epoch:29 step:28108 [D loss: 0.449021, acc.: 76.56%] [G loss: 1.076393]\n",
      "epoch:29 step:28109 [D loss: 0.385395, acc.: 82.03%] [G loss: 1.469348]\n",
      "epoch:29 step:28110 [D loss: 0.395016, acc.: 83.59%] [G loss: 1.506380]\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function, division\n",
    "\n",
    "from keras.datasets import mnist\n",
    "from keras.layers import Input, Dense, Reshape, Flatten, Dropout\n",
    "from keras.layers import BatchNormalization, Activation, ZeroPadding2D\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "from keras.layers.convolutional import UpSampling2D, Conv2D\n",
    "from keras.models import Sequential, Model\n",
    "from keras.optimizers import Adam\n",
    "import keras.backend as K\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "class BGAN():\n",
    "    \"\"\"Reference: https://wiseodd.github.io/techblog/2017/03/07/boundary-seeking-gan/\"\"\"\n",
    "    def __init__(self):\n",
    "        self.img_rows = 28\n",
    "        self.img_cols = 28\n",
    "        self.channels = 1\n",
    "        self.img_shape = (self.img_rows, self.img_cols, self.channels)\n",
    "        self.latent_dim = 100\n",
    "\n",
    "        optimizer = Adam(0.0002, 0.5)\n",
    "\n",
    "        # Build and compile the discriminator\n",
    "        self.discriminator = self.build_discriminator()\n",
    "        self.discriminator.compile(loss='binary_crossentropy',\n",
    "            optimizer=optimizer,\n",
    "            metrics=['accuracy'])\n",
    "\n",
    "        # Build the generator\n",
    "        self.generator = self.build_generator()\n",
    "\n",
    "        # The generator takes noise as input and generated imgs\n",
    "        z = Input(shape=(self.latent_dim,))\n",
    "        img = self.generator(z)\n",
    "\n",
    "        # For the combined model we will only train the generator\n",
    "        self.discriminator.trainable = False\n",
    "\n",
    "        # The valid takes generated images as input and determines validity\n",
    "        valid = self.discriminator(img)\n",
    "\n",
    "        # The combined model  (stacked generator and discriminator)\n",
    "        # Trains the generator to fool the discriminator\n",
    "        self.combined = Model(z, valid)\n",
    "        self.combined.compile(loss=self.boundary_loss, optimizer=optimizer)\n",
    "\n",
    "    def build_generator(self):\n",
    "\n",
    "        model = Sequential()\n",
    "\n",
    "        model.add(Dense(256, input_dim=self.latent_dim))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(BatchNormalization(momentum=0.8))\n",
    "        model.add(Dense(512))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(BatchNormalization(momentum=0.8))\n",
    "        model.add(Dense(1024))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(BatchNormalization(momentum=0.8))\n",
    "        model.add(Dense(np.prod(self.img_shape), activation='tanh'))\n",
    "        model.add(Reshape(self.img_shape))\n",
    "\n",
    "        model.summary()\n",
    "\n",
    "        noise = Input(shape=(self.latent_dim,))\n",
    "        img = model(noise)\n",
    "\n",
    "        return Model(noise, img)\n",
    "\n",
    "    def build_discriminator(self):\n",
    "\n",
    "        model = Sequential()\n",
    "\n",
    "        model.add(Flatten(input_shape=self.img_shape))\n",
    "        model.add(Dense(512))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(Dense(256))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(Dense(1, activation='sigmoid'))\n",
    "        model.summary()\n",
    "\n",
    "        img = Input(shape=self.img_shape)\n",
    "        validity = model(img)\n",
    "\n",
    "        return Model(img, validity)\n",
    "\n",
    "    def boundary_loss(self, y_true, y_pred):\n",
    "        \"\"\"\n",
    "        Boundary seeking loss.\n",
    "        Reference: https://wiseodd.github.io/techblog/2017/03/07/boundary-seeking-gan/\n",
    "        \"\"\"\n",
    "        return 0.5 * K.mean((K.log(y_pred) - K.log(1 - y_pred))**2)\n",
    "\n",
    "    def train(self, epochs, batch_size=128, sample_interval=50):\n",
    "\n",
    "        # Load the dataset\n",
    "        (X_train, _), (_, _) = mnist.load_data()\n",
    "\n",
    "        # Rescale -1 to 1\n",
    "        X_train = X_train / 127.5 - 1.\n",
    "        X_train = np.expand_dims(X_train, axis=3)\n",
    "\n",
    "        # Adversarial ground truths\n",
    "        valid = np.ones((batch_size, 1))\n",
    "        fake = np.zeros((batch_size, 1))\n",
    "        nb_batches = int(X_train.shape[0] / batch_size)\n",
    "        global_step = 0\n",
    "\n",
    "        for epoch in range(epochs):\n",
    "\n",
    "            # ---------------------\n",
    "            #  Train Discriminator\n",
    "            # ---------------------\n",
    "\n",
    "            # Select a random batch of images\n",
    "            # idx = np.random.randint(0, X_train.shape[0], batch_size)\n",
    "            for index in range(nb_batches):\n",
    "                global_step += 1\n",
    "                # progress_bar.update(index)\n",
    "\n",
    "                # get a batch of real images\n",
    "                image_batch = X_train[index * batch_size:(index + 1) * batch_size]\n",
    "\n",
    "                noise = np.random.normal(0, 1, (batch_size, self.latent_dim))\n",
    "\n",
    "                # Generate a batch of new images\n",
    "                gen_imgs = self.generator.predict(noise)\n",
    "\n",
    "                # Train the discriminator\n",
    "                d_loss_real = self.discriminator.train_on_batch(image_batch, valid)\n",
    "                d_loss_fake = self.discriminator.train_on_batch(gen_imgs, fake)\n",
    "                d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)\n",
    "\n",
    "                # ---------------------\n",
    "                #  Train Generator\n",
    "                # ---------------------\n",
    "\n",
    "                g_loss = self.combined.train_on_batch(noise, valid)\n",
    "\n",
    "                # Plot the progress\n",
    "                print(\"epoch:%d step:%d [D loss: %f, acc.: %.2f%%] [G loss: %f]\" % (epoch,global_step, d_loss[0], 100 * d_loss[1], g_loss))\n",
    "\n",
    "                # If at save interval => save generated image samples\n",
    "                if global_step % sample_interval == 0:\n",
    "                    self.sample_images(epoch,global_step)\n",
    "\n",
    "\n",
    "    def sample_images(self, epoch,global_step):\n",
    "        r, c = 10, 10\n",
    "        noise = np.random.normal(0, 1, (r * c, self.latent_dim))\n",
    "        gen_imgs = self.generator.predict(noise)\n",
    "        # Rescale images 0 - 1\n",
    "        gen_imgs = 0.5 * gen_imgs + 0.5\n",
    "\n",
    "        fig, axs = plt.subplots(r, c)\n",
    "        cnt = 0\n",
    "        for i in range(r):\n",
    "            for j in range(c):\n",
    "                axs[i,j].imshow(gen_imgs[cnt, :,:,0], cmap='gray')\n",
    "                axs[i,j].axis('off')\n",
    "                cnt += 1\n",
    "        if not os.path.isdir('images_bgan'):\n",
    "            os.mkdir('images_bgan')\n",
    "        fig.savefig(\"images_bgan/epoch_%d_step_%d.png\" % (epoch,global_step))\n",
    "        plt.close()\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    bgan = BGAN()\n",
    "    bgan.train(epochs=30, batch_size=64, sample_interval=200)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pppppppp [conda env:root] *",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
