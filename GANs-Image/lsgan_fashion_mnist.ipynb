{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 14, 14, 16)        160       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_1 (LeakyReLU)    (None, 14, 14, 16)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 14, 14, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 7, 7, 32)          4640      \n",
      "_________________________________________________________________\n",
      "zero_padding2d_1 (ZeroPaddin (None, 8, 8, 32)          0         \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_2 (LeakyReLU)    (None, 8, 8, 32)          0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 8, 8, 32)          0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 8, 8, 32)          128       \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 4, 4, 64)          18496     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_3 (LeakyReLU)    (None, 4, 4, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 4, 4, 64)          0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 4, 4, 64)          256       \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 4, 4, 128)         73856     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_4 (LeakyReLU)    (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 2049      \n",
      "=================================================================\n",
      "Total params: 99,585\n",
      "Trainable params: 99,393\n",
      "Non-trainable params: 192\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_2 (Dense)              (None, 6272)              633472    \n",
      "_________________________________________________________________\n",
      "reshape_1 (Reshape)          (None, 7, 7, 128)         0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 7, 7, 128)         512       \n",
      "_________________________________________________________________\n",
      "up_sampling2d_1 (UpSampling2 (None, 14, 14, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 14, 14, 128)       147584    \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 14, 14, 128)       0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 14, 14, 128)       512       \n",
      "_________________________________________________________________\n",
      "up_sampling2d_2 (UpSampling2 (None, 28, 28, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 28, 28, 64)        73792     \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 28, 28, 64)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 28, 28, 64)        256       \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 28, 28, 1)         577       \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 28, 28, 1)         0         \n",
      "=================================================================\n",
      "Total params: 856,705\n",
      "Trainable params: 856,065\n",
      "Non-trainable params: 640\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/imi432_006/anaconda3/envs/tf/lib/python3.5/site-packages/keras/engine/training.py:490: UserWarning: Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?\n",
      "  'Discrepancy between trainable weights and collected trainable'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0 step:1 [D loss: 0.314850, acc.: 39.06%] [G loss: 0.281866]\n",
      "epoch:0 step:2 [D loss: 0.249928, acc.: 53.91%] [G loss: 0.328754]\n",
      "epoch:0 step:3 [D loss: 0.238551, acc.: 53.12%] [G loss: 0.300702]\n",
      "epoch:0 step:4 [D loss: 0.208830, acc.: 70.31%] [G loss: 0.298793]\n",
      "epoch:0 step:5 [D loss: 0.207171, acc.: 67.19%] [G loss: 0.311713]\n",
      "epoch:0 step:6 [D loss: 0.183434, acc.: 68.75%] [G loss: 0.336693]\n",
      "epoch:0 step:7 [D loss: 0.172553, acc.: 75.00%] [G loss: 0.356387]\n",
      "epoch:0 step:8 [D loss: 0.186004, acc.: 71.09%] [G loss: 0.360509]\n",
      "epoch:0 step:9 [D loss: 0.167336, acc.: 81.25%] [G loss: 0.350154]\n",
      "epoch:0 step:10 [D loss: 0.197334, acc.: 70.31%] [G loss: 0.365294]\n",
      "epoch:0 step:11 [D loss: 0.182676, acc.: 75.00%] [G loss: 0.381655]\n",
      "epoch:0 step:12 [D loss: 0.163693, acc.: 78.12%] [G loss: 0.419036]\n",
      "epoch:0 step:13 [D loss: 0.164487, acc.: 75.78%] [G loss: 0.363244]\n",
      "epoch:0 step:14 [D loss: 0.174652, acc.: 76.56%] [G loss: 0.404243]\n",
      "epoch:0 step:15 [D loss: 0.173998, acc.: 71.09%] [G loss: 0.412454]\n",
      "epoch:0 step:16 [D loss: 0.199965, acc.: 71.09%] [G loss: 0.438038]\n",
      "epoch:0 step:17 [D loss: 0.187620, acc.: 71.88%] [G loss: 0.425556]\n",
      "epoch:0 step:18 [D loss: 0.149354, acc.: 82.03%] [G loss: 0.487568]\n",
      "epoch:0 step:19 [D loss: 0.172032, acc.: 76.56%] [G loss: 0.463011]\n",
      "epoch:0 step:20 [D loss: 0.159743, acc.: 75.00%] [G loss: 0.478523]\n",
      "epoch:0 step:21 [D loss: 0.148164, acc.: 81.25%] [G loss: 0.449047]\n",
      "epoch:0 step:22 [D loss: 0.155870, acc.: 78.91%] [G loss: 0.506977]\n",
      "epoch:0 step:23 [D loss: 0.151951, acc.: 82.81%] [G loss: 0.509231]\n",
      "epoch:0 step:24 [D loss: 0.179117, acc.: 71.88%] [G loss: 0.474109]\n",
      "epoch:0 step:25 [D loss: 0.158677, acc.: 78.12%] [G loss: 0.530438]\n",
      "epoch:0 step:26 [D loss: 0.160450, acc.: 80.47%] [G loss: 0.503732]\n",
      "epoch:0 step:27 [D loss: 0.143063, acc.: 85.16%] [G loss: 0.472815]\n",
      "epoch:0 step:28 [D loss: 0.149560, acc.: 77.34%] [G loss: 0.522687]\n",
      "epoch:0 step:29 [D loss: 0.145529, acc.: 82.03%] [G loss: 0.574293]\n",
      "epoch:0 step:30 [D loss: 0.144585, acc.: 78.91%] [G loss: 0.524110]\n",
      "epoch:0 step:31 [D loss: 0.130643, acc.: 81.25%] [G loss: 0.531271]\n",
      "epoch:0 step:32 [D loss: 0.126795, acc.: 85.16%] [G loss: 0.546136]\n",
      "epoch:0 step:33 [D loss: 0.156348, acc.: 81.25%] [G loss: 0.522834]\n",
      "epoch:0 step:34 [D loss: 0.107448, acc.: 89.06%] [G loss: 0.567330]\n",
      "epoch:0 step:35 [D loss: 0.109130, acc.: 89.84%] [G loss: 0.511899]\n",
      "epoch:0 step:36 [D loss: 0.176800, acc.: 75.78%] [G loss: 0.491785]\n",
      "epoch:0 step:37 [D loss: 0.117140, acc.: 85.94%] [G loss: 0.537295]\n",
      "epoch:0 step:38 [D loss: 0.123276, acc.: 84.38%] [G loss: 0.524115]\n",
      "epoch:0 step:39 [D loss: 0.121550, acc.: 86.72%] [G loss: 0.541194]\n",
      "epoch:0 step:40 [D loss: 0.148215, acc.: 78.91%] [G loss: 0.543327]\n",
      "epoch:0 step:41 [D loss: 0.158439, acc.: 76.56%] [G loss: 0.525946]\n",
      "epoch:0 step:42 [D loss: 0.138758, acc.: 84.38%] [G loss: 0.566612]\n",
      "epoch:0 step:43 [D loss: 0.167848, acc.: 74.22%] [G loss: 0.498783]\n",
      "epoch:0 step:44 [D loss: 0.138734, acc.: 82.81%] [G loss: 0.523416]\n",
      "epoch:0 step:45 [D loss: 0.117588, acc.: 89.06%] [G loss: 0.542500]\n",
      "epoch:0 step:46 [D loss: 0.114952, acc.: 86.72%] [G loss: 0.522883]\n",
      "epoch:0 step:47 [D loss: 0.133557, acc.: 82.81%] [G loss: 0.518905]\n",
      "epoch:0 step:48 [D loss: 0.133323, acc.: 82.81%] [G loss: 0.495290]\n",
      "epoch:0 step:49 [D loss: 0.124672, acc.: 82.03%] [G loss: 0.518384]\n",
      "epoch:0 step:50 [D loss: 0.115941, acc.: 87.50%] [G loss: 0.477782]\n",
      "epoch:0 step:51 [D loss: 0.123926, acc.: 80.47%] [G loss: 0.488250]\n",
      "epoch:0 step:52 [D loss: 0.207247, acc.: 65.62%] [G loss: 0.533322]\n",
      "epoch:0 step:53 [D loss: 0.198089, acc.: 68.75%] [G loss: 0.479163]\n",
      "epoch:0 step:54 [D loss: 0.113432, acc.: 84.38%] [G loss: 0.535259]\n",
      "epoch:0 step:55 [D loss: 0.141135, acc.: 78.91%] [G loss: 0.516528]\n",
      "epoch:0 step:56 [D loss: 0.114811, acc.: 88.28%] [G loss: 0.509141]\n",
      "epoch:0 step:57 [D loss: 0.168348, acc.: 74.22%] [G loss: 0.498229]\n",
      "epoch:0 step:58 [D loss: 0.125851, acc.: 86.72%] [G loss: 0.474177]\n",
      "epoch:0 step:59 [D loss: 0.173649, acc.: 72.66%] [G loss: 0.401632]\n",
      "epoch:0 step:60 [D loss: 0.190610, acc.: 68.75%] [G loss: 0.458505]\n",
      "epoch:0 step:61 [D loss: 0.148747, acc.: 77.34%] [G loss: 0.522798]\n",
      "epoch:0 step:62 [D loss: 0.173199, acc.: 73.44%] [G loss: 0.494647]\n",
      "epoch:0 step:63 [D loss: 0.206089, acc.: 67.97%] [G loss: 0.448947]\n",
      "epoch:0 step:64 [D loss: 0.146257, acc.: 78.91%] [G loss: 0.495029]\n",
      "epoch:0 step:65 [D loss: 0.144186, acc.: 82.81%] [G loss: 0.486571]\n",
      "epoch:0 step:66 [D loss: 0.133598, acc.: 84.38%] [G loss: 0.416962]\n",
      "epoch:0 step:67 [D loss: 0.160171, acc.: 75.00%] [G loss: 0.410353]\n",
      "epoch:0 step:68 [D loss: 0.136022, acc.: 82.81%] [G loss: 0.431241]\n",
      "epoch:0 step:69 [D loss: 0.144120, acc.: 85.94%] [G loss: 0.438928]\n",
      "epoch:0 step:70 [D loss: 0.169706, acc.: 74.22%] [G loss: 0.440755]\n",
      "epoch:0 step:71 [D loss: 0.185288, acc.: 69.53%] [G loss: 0.462835]\n",
      "epoch:0 step:72 [D loss: 0.171186, acc.: 73.44%] [G loss: 0.445345]\n",
      "epoch:0 step:73 [D loss: 0.257199, acc.: 56.25%] [G loss: 0.502889]\n",
      "epoch:0 step:74 [D loss: 0.169186, acc.: 75.78%] [G loss: 0.474513]\n",
      "epoch:0 step:75 [D loss: 0.201793, acc.: 68.75%] [G loss: 0.412463]\n",
      "epoch:0 step:76 [D loss: 0.181415, acc.: 78.12%] [G loss: 0.447932]\n",
      "epoch:0 step:77 [D loss: 0.175294, acc.: 77.34%] [G loss: 0.536342]\n",
      "epoch:0 step:78 [D loss: 0.213753, acc.: 63.28%] [G loss: 0.481804]\n",
      "epoch:0 step:79 [D loss: 0.180177, acc.: 75.00%] [G loss: 0.466235]\n",
      "epoch:0 step:80 [D loss: 0.152793, acc.: 75.00%] [G loss: 0.505478]\n",
      "epoch:0 step:81 [D loss: 0.275349, acc.: 58.59%] [G loss: 0.500266]\n",
      "epoch:0 step:82 [D loss: 0.154961, acc.: 77.34%] [G loss: 0.501751]\n",
      "epoch:0 step:83 [D loss: 0.215859, acc.: 69.53%] [G loss: 0.580789]\n",
      "epoch:0 step:84 [D loss: 0.193077, acc.: 74.22%] [G loss: 0.508099]\n",
      "epoch:0 step:85 [D loss: 0.154788, acc.: 78.91%] [G loss: 0.517896]\n",
      "epoch:0 step:86 [D loss: 0.182600, acc.: 75.78%] [G loss: 0.457159]\n",
      "epoch:0 step:87 [D loss: 0.182229, acc.: 75.78%] [G loss: 0.454026]\n",
      "epoch:0 step:88 [D loss: 0.242144, acc.: 61.72%] [G loss: 0.460927]\n",
      "epoch:0 step:89 [D loss: 0.171695, acc.: 75.00%] [G loss: 0.477548]\n",
      "epoch:0 step:90 [D loss: 0.188574, acc.: 68.75%] [G loss: 0.458722]\n",
      "epoch:0 step:91 [D loss: 0.194074, acc.: 68.75%] [G loss: 0.574249]\n",
      "epoch:0 step:92 [D loss: 0.238079, acc.: 63.28%] [G loss: 0.476866]\n",
      "epoch:0 step:93 [D loss: 0.219104, acc.: 61.72%] [G loss: 0.478204]\n",
      "epoch:0 step:94 [D loss: 0.224860, acc.: 65.62%] [G loss: 0.453292]\n",
      "epoch:0 step:95 [D loss: 0.210694, acc.: 70.31%] [G loss: 0.472156]\n",
      "epoch:0 step:96 [D loss: 0.186324, acc.: 72.66%] [G loss: 0.456819]\n",
      "epoch:0 step:97 [D loss: 0.193329, acc.: 71.88%] [G loss: 0.497007]\n",
      "epoch:0 step:98 [D loss: 0.238438, acc.: 64.06%] [G loss: 0.480652]\n",
      "epoch:0 step:99 [D loss: 0.195793, acc.: 68.75%] [G loss: 0.569061]\n",
      "epoch:0 step:100 [D loss: 0.212328, acc.: 65.62%] [G loss: 0.446739]\n",
      "epoch:0 step:101 [D loss: 0.172553, acc.: 71.09%] [G loss: 0.515406]\n",
      "epoch:0 step:102 [D loss: 0.232566, acc.: 65.62%] [G loss: 0.430040]\n",
      "epoch:0 step:103 [D loss: 0.274743, acc.: 55.47%] [G loss: 0.428491]\n",
      "epoch:0 step:104 [D loss: 0.235177, acc.: 60.16%] [G loss: 0.435024]\n",
      "epoch:0 step:105 [D loss: 0.229000, acc.: 59.38%] [G loss: 0.473123]\n",
      "epoch:0 step:106 [D loss: 0.244093, acc.: 63.28%] [G loss: 0.434946]\n",
      "epoch:0 step:107 [D loss: 0.258361, acc.: 57.03%] [G loss: 0.521374]\n",
      "epoch:0 step:108 [D loss: 0.232918, acc.: 60.94%] [G loss: 0.470472]\n",
      "epoch:0 step:109 [D loss: 0.224960, acc.: 68.75%] [G loss: 0.388327]\n",
      "epoch:0 step:110 [D loss: 0.264284, acc.: 58.59%] [G loss: 0.417001]\n",
      "epoch:0 step:111 [D loss: 0.259329, acc.: 53.91%] [G loss: 0.456508]\n",
      "epoch:0 step:112 [D loss: 0.253167, acc.: 58.59%] [G loss: 0.440839]\n",
      "epoch:0 step:113 [D loss: 0.252597, acc.: 57.03%] [G loss: 0.362449]\n",
      "epoch:0 step:114 [D loss: 0.242799, acc.: 64.06%] [G loss: 0.332594]\n",
      "epoch:0 step:115 [D loss: 0.311769, acc.: 46.88%] [G loss: 0.455384]\n",
      "epoch:0 step:116 [D loss: 0.267376, acc.: 57.81%] [G loss: 0.450474]\n",
      "epoch:0 step:117 [D loss: 0.265816, acc.: 58.59%] [G loss: 0.371628]\n",
      "epoch:0 step:118 [D loss: 0.254481, acc.: 63.28%] [G loss: 0.437326]\n",
      "epoch:0 step:119 [D loss: 0.246859, acc.: 64.06%] [G loss: 0.370880]\n",
      "epoch:0 step:120 [D loss: 0.258886, acc.: 58.59%] [G loss: 0.404622]\n",
      "epoch:0 step:121 [D loss: 0.292382, acc.: 53.12%] [G loss: 0.406446]\n",
      "epoch:0 step:122 [D loss: 0.246650, acc.: 61.72%] [G loss: 0.389206]\n",
      "epoch:0 step:123 [D loss: 0.260337, acc.: 59.38%] [G loss: 0.408547]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0 step:124 [D loss: 0.289338, acc.: 46.09%] [G loss: 0.393073]\n",
      "epoch:0 step:125 [D loss: 0.250224, acc.: 61.72%] [G loss: 0.394401]\n",
      "epoch:0 step:126 [D loss: 0.263195, acc.: 59.38%] [G loss: 0.328207]\n",
      "epoch:0 step:127 [D loss: 0.252397, acc.: 57.81%] [G loss: 0.321680]\n",
      "epoch:0 step:128 [D loss: 0.237877, acc.: 62.50%] [G loss: 0.344814]\n",
      "epoch:0 step:129 [D loss: 0.293350, acc.: 50.00%] [G loss: 0.303204]\n",
      "epoch:0 step:130 [D loss: 0.274623, acc.: 55.47%] [G loss: 0.428913]\n",
      "epoch:0 step:131 [D loss: 0.233291, acc.: 60.94%] [G loss: 0.382323]\n",
      "epoch:0 step:132 [D loss: 0.262333, acc.: 60.16%] [G loss: 0.428073]\n",
      "epoch:0 step:133 [D loss: 0.273514, acc.: 57.03%] [G loss: 0.358978]\n",
      "epoch:0 step:134 [D loss: 0.290392, acc.: 52.34%] [G loss: 0.381754]\n",
      "epoch:0 step:135 [D loss: 0.277717, acc.: 58.59%] [G loss: 0.378144]\n",
      "epoch:0 step:136 [D loss: 0.239116, acc.: 60.16%] [G loss: 0.409796]\n",
      "epoch:0 step:137 [D loss: 0.250929, acc.: 59.38%] [G loss: 0.393274]\n",
      "epoch:0 step:138 [D loss: 0.271794, acc.: 59.38%] [G loss: 0.431139]\n",
      "epoch:0 step:139 [D loss: 0.255189, acc.: 57.03%] [G loss: 0.409225]\n",
      "epoch:0 step:140 [D loss: 0.238410, acc.: 64.06%] [G loss: 0.411826]\n",
      "epoch:0 step:141 [D loss: 0.245934, acc.: 60.16%] [G loss: 0.376402]\n",
      "epoch:0 step:142 [D loss: 0.240269, acc.: 59.38%] [G loss: 0.440998]\n",
      "epoch:0 step:143 [D loss: 0.257548, acc.: 60.16%] [G loss: 0.448231]\n",
      "epoch:0 step:144 [D loss: 0.261978, acc.: 57.03%] [G loss: 0.429011]\n",
      "epoch:0 step:145 [D loss: 0.286172, acc.: 48.44%] [G loss: 0.396791]\n",
      "epoch:0 step:146 [D loss: 0.230480, acc.: 57.81%] [G loss: 0.452986]\n",
      "epoch:0 step:147 [D loss: 0.221229, acc.: 67.97%] [G loss: 0.440522]\n",
      "epoch:0 step:148 [D loss: 0.250056, acc.: 62.50%] [G loss: 0.424725]\n",
      "epoch:0 step:149 [D loss: 0.238312, acc.: 60.94%] [G loss: 0.445123]\n",
      "epoch:0 step:150 [D loss: 0.256815, acc.: 60.16%] [G loss: 0.421933]\n",
      "epoch:0 step:151 [D loss: 0.285468, acc.: 50.78%] [G loss: 0.387100]\n",
      "epoch:0 step:152 [D loss: 0.227966, acc.: 60.94%] [G loss: 0.343234]\n",
      "epoch:0 step:153 [D loss: 0.260838, acc.: 56.25%] [G loss: 0.351725]\n",
      "epoch:0 step:154 [D loss: 0.235045, acc.: 64.06%] [G loss: 0.414844]\n",
      "epoch:0 step:155 [D loss: 0.237535, acc.: 57.81%] [G loss: 0.364802]\n",
      "epoch:0 step:156 [D loss: 0.211818, acc.: 63.28%] [G loss: 0.403188]\n",
      "epoch:0 step:157 [D loss: 0.208792, acc.: 67.97%] [G loss: 0.393357]\n",
      "epoch:0 step:158 [D loss: 0.227278, acc.: 63.28%] [G loss: 0.405058]\n",
      "epoch:0 step:159 [D loss: 0.215920, acc.: 70.31%] [G loss: 0.412238]\n",
      "epoch:0 step:160 [D loss: 0.220061, acc.: 69.53%] [G loss: 0.407832]\n",
      "epoch:0 step:161 [D loss: 0.271778, acc.: 57.81%] [G loss: 0.422509]\n",
      "epoch:0 step:162 [D loss: 0.276795, acc.: 52.34%] [G loss: 0.319983]\n",
      "epoch:0 step:163 [D loss: 0.272633, acc.: 54.69%] [G loss: 0.422114]\n",
      "epoch:0 step:164 [D loss: 0.259740, acc.: 56.25%] [G loss: 0.453092]\n",
      "epoch:0 step:165 [D loss: 0.250317, acc.: 59.38%] [G loss: 0.563205]\n",
      "epoch:0 step:166 [D loss: 0.245662, acc.: 57.81%] [G loss: 0.454580]\n",
      "epoch:0 step:167 [D loss: 0.276532, acc.: 51.56%] [G loss: 0.466047]\n",
      "epoch:0 step:168 [D loss: 0.255609, acc.: 60.16%] [G loss: 0.498966]\n",
      "epoch:0 step:169 [D loss: 0.222456, acc.: 66.41%] [G loss: 0.397509]\n",
      "epoch:0 step:170 [D loss: 0.249158, acc.: 57.03%] [G loss: 0.417092]\n",
      "epoch:0 step:171 [D loss: 0.238782, acc.: 60.94%] [G loss: 0.387227]\n",
      "epoch:0 step:172 [D loss: 0.248051, acc.: 61.72%] [G loss: 0.331398]\n",
      "epoch:0 step:173 [D loss: 0.269487, acc.: 53.91%] [G loss: 0.312055]\n",
      "epoch:0 step:174 [D loss: 0.258962, acc.: 51.56%] [G loss: 0.293058]\n",
      "epoch:0 step:175 [D loss: 0.237798, acc.: 60.94%] [G loss: 0.381926]\n",
      "epoch:0 step:176 [D loss: 0.261349, acc.: 54.69%] [G loss: 0.397456]\n",
      "epoch:0 step:177 [D loss: 0.212504, acc.: 67.97%] [G loss: 0.393259]\n",
      "epoch:0 step:178 [D loss: 0.218144, acc.: 62.50%] [G loss: 0.391479]\n",
      "epoch:0 step:179 [D loss: 0.213403, acc.: 64.84%] [G loss: 0.400428]\n",
      "epoch:0 step:180 [D loss: 0.215972, acc.: 67.97%] [G loss: 0.371947]\n",
      "epoch:0 step:181 [D loss: 0.236470, acc.: 61.72%] [G loss: 0.420683]\n",
      "epoch:0 step:182 [D loss: 0.225390, acc.: 64.84%] [G loss: 0.426788]\n",
      "epoch:0 step:183 [D loss: 0.210886, acc.: 67.19%] [G loss: 0.415665]\n",
      "epoch:0 step:184 [D loss: 0.252418, acc.: 58.59%] [G loss: 0.342240]\n",
      "epoch:0 step:185 [D loss: 0.281121, acc.: 44.53%] [G loss: 0.366958]\n",
      "epoch:0 step:186 [D loss: 0.271182, acc.: 53.12%] [G loss: 0.418271]\n",
      "epoch:0 step:187 [D loss: 0.213282, acc.: 63.28%] [G loss: 0.435525]\n",
      "epoch:0 step:188 [D loss: 0.222429, acc.: 65.62%] [G loss: 0.433178]\n",
      "epoch:0 step:189 [D loss: 0.243802, acc.: 55.47%] [G loss: 0.432508]\n",
      "epoch:0 step:190 [D loss: 0.264223, acc.: 52.34%] [G loss: 0.372410]\n",
      "epoch:0 step:191 [D loss: 0.239597, acc.: 60.94%] [G loss: 0.422396]\n",
      "epoch:0 step:192 [D loss: 0.230313, acc.: 64.06%] [G loss: 0.386244]\n",
      "epoch:0 step:193 [D loss: 0.249711, acc.: 59.38%] [G loss: 0.427880]\n",
      "epoch:0 step:194 [D loss: 0.225479, acc.: 65.62%] [G loss: 0.361720]\n",
      "epoch:0 step:195 [D loss: 0.265125, acc.: 57.81%] [G loss: 0.415521]\n",
      "epoch:0 step:196 [D loss: 0.218392, acc.: 67.19%] [G loss: 0.361546]\n",
      "epoch:0 step:197 [D loss: 0.281801, acc.: 52.34%] [G loss: 0.389054]\n",
      "epoch:0 step:198 [D loss: 0.268650, acc.: 52.34%] [G loss: 0.334205]\n",
      "epoch:0 step:199 [D loss: 0.271340, acc.: 46.88%] [G loss: 0.348431]\n",
      "epoch:0 step:200 [D loss: 0.229671, acc.: 61.72%] [G loss: 0.442068]\n",
      "epoch:0 step:201 [D loss: 0.265839, acc.: 55.47%] [G loss: 0.390794]\n",
      "epoch:0 step:202 [D loss: 0.279077, acc.: 55.47%] [G loss: 0.442646]\n",
      "epoch:0 step:203 [D loss: 0.263573, acc.: 57.03%] [G loss: 0.423212]\n",
      "epoch:0 step:204 [D loss: 0.276995, acc.: 59.38%] [G loss: 0.384344]\n",
      "epoch:0 step:205 [D loss: 0.241726, acc.: 63.28%] [G loss: 0.386169]\n",
      "epoch:0 step:206 [D loss: 0.271472, acc.: 57.03%] [G loss: 0.381710]\n",
      "epoch:0 step:207 [D loss: 0.257527, acc.: 57.81%] [G loss: 0.392053]\n",
      "epoch:0 step:208 [D loss: 0.271610, acc.: 52.34%] [G loss: 0.432587]\n",
      "epoch:0 step:209 [D loss: 0.282440, acc.: 51.56%] [G loss: 0.393836]\n",
      "epoch:0 step:210 [D loss: 0.238321, acc.: 59.38%] [G loss: 0.405682]\n",
      "epoch:0 step:211 [D loss: 0.244841, acc.: 62.50%] [G loss: 0.415875]\n",
      "epoch:0 step:212 [D loss: 0.269750, acc.: 53.91%] [G loss: 0.364145]\n",
      "epoch:0 step:213 [D loss: 0.255927, acc.: 56.25%] [G loss: 0.365565]\n",
      "epoch:0 step:214 [D loss: 0.264715, acc.: 52.34%] [G loss: 0.343916]\n",
      "epoch:0 step:215 [D loss: 0.273870, acc.: 53.12%] [G loss: 0.369700]\n",
      "epoch:0 step:216 [D loss: 0.247068, acc.: 59.38%] [G loss: 0.354496]\n",
      "epoch:0 step:217 [D loss: 0.244450, acc.: 62.50%] [G loss: 0.420849]\n",
      "epoch:0 step:218 [D loss: 0.264119, acc.: 49.22%] [G loss: 0.336566]\n",
      "epoch:0 step:219 [D loss: 0.238137, acc.: 60.94%] [G loss: 0.363669]\n",
      "epoch:0 step:220 [D loss: 0.249661, acc.: 55.47%] [G loss: 0.355182]\n",
      "epoch:0 step:221 [D loss: 0.239017, acc.: 62.50%] [G loss: 0.350576]\n",
      "epoch:0 step:222 [D loss: 0.238706, acc.: 60.16%] [G loss: 0.297702]\n",
      "epoch:0 step:223 [D loss: 0.257206, acc.: 60.16%] [G loss: 0.351343]\n",
      "epoch:0 step:224 [D loss: 0.264097, acc.: 54.69%] [G loss: 0.306730]\n",
      "epoch:0 step:225 [D loss: 0.266730, acc.: 57.81%] [G loss: 0.294098]\n",
      "epoch:0 step:226 [D loss: 0.216367, acc.: 64.84%] [G loss: 0.355315]\n",
      "epoch:0 step:227 [D loss: 0.268955, acc.: 54.69%] [G loss: 0.319584]\n",
      "epoch:0 step:228 [D loss: 0.260635, acc.: 54.69%] [G loss: 0.341007]\n",
      "epoch:0 step:229 [D loss: 0.255080, acc.: 56.25%] [G loss: 0.334277]\n",
      "epoch:0 step:230 [D loss: 0.258518, acc.: 63.28%] [G loss: 0.333980]\n",
      "epoch:0 step:231 [D loss: 0.280341, acc.: 49.22%] [G loss: 0.364917]\n",
      "epoch:0 step:232 [D loss: 0.263659, acc.: 56.25%] [G loss: 0.313256]\n",
      "epoch:0 step:233 [D loss: 0.278238, acc.: 49.22%] [G loss: 0.329275]\n",
      "epoch:0 step:234 [D loss: 0.257320, acc.: 59.38%] [G loss: 0.359774]\n",
      "epoch:0 step:235 [D loss: 0.273589, acc.: 51.56%] [G loss: 0.343089]\n",
      "epoch:0 step:236 [D loss: 0.300391, acc.: 46.88%] [G loss: 0.324090]\n",
      "epoch:0 step:237 [D loss: 0.261502, acc.: 53.12%] [G loss: 0.323063]\n",
      "epoch:0 step:238 [D loss: 0.242685, acc.: 60.16%] [G loss: 0.328492]\n",
      "epoch:0 step:239 [D loss: 0.262342, acc.: 54.69%] [G loss: 0.350906]\n",
      "epoch:0 step:240 [D loss: 0.281344, acc.: 51.56%] [G loss: 0.345814]\n",
      "epoch:0 step:241 [D loss: 0.248276, acc.: 55.47%] [G loss: 0.349358]\n",
      "epoch:0 step:242 [D loss: 0.290701, acc.: 46.09%] [G loss: 0.334647]\n",
      "epoch:0 step:243 [D loss: 0.245602, acc.: 60.16%] [G loss: 0.350514]\n",
      "epoch:0 step:244 [D loss: 0.277084, acc.: 48.44%] [G loss: 0.305173]\n",
      "epoch:0 step:245 [D loss: 0.274182, acc.: 50.78%] [G loss: 0.373098]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0 step:246 [D loss: 0.269772, acc.: 53.91%] [G loss: 0.378846]\n",
      "epoch:0 step:247 [D loss: 0.231660, acc.: 64.84%] [G loss: 0.330182]\n",
      "epoch:0 step:248 [D loss: 0.265932, acc.: 58.59%] [G loss: 0.307238]\n",
      "epoch:0 step:249 [D loss: 0.295549, acc.: 49.22%] [G loss: 0.345522]\n",
      "epoch:0 step:250 [D loss: 0.240412, acc.: 60.16%] [G loss: 0.347830]\n",
      "epoch:0 step:251 [D loss: 0.278221, acc.: 51.56%] [G loss: 0.327394]\n",
      "epoch:0 step:252 [D loss: 0.230181, acc.: 70.31%] [G loss: 0.395494]\n",
      "epoch:0 step:253 [D loss: 0.252545, acc.: 53.12%] [G loss: 0.371105]\n",
      "epoch:0 step:254 [D loss: 0.264628, acc.: 53.91%] [G loss: 0.329776]\n",
      "epoch:0 step:255 [D loss: 0.258778, acc.: 53.91%] [G loss: 0.365451]\n",
      "epoch:0 step:256 [D loss: 0.251890, acc.: 56.25%] [G loss: 0.362967]\n",
      "epoch:0 step:257 [D loss: 0.223255, acc.: 62.50%] [G loss: 0.412579]\n",
      "epoch:0 step:258 [D loss: 0.296632, acc.: 51.56%] [G loss: 0.366152]\n",
      "epoch:0 step:259 [D loss: 0.305951, acc.: 43.75%] [G loss: 0.343217]\n",
      "epoch:0 step:260 [D loss: 0.288785, acc.: 50.00%] [G loss: 0.393516]\n",
      "epoch:0 step:261 [D loss: 0.295104, acc.: 46.88%] [G loss: 0.378137]\n",
      "epoch:0 step:262 [D loss: 0.265370, acc.: 54.69%] [G loss: 0.345703]\n",
      "epoch:0 step:263 [D loss: 0.264704, acc.: 53.12%] [G loss: 0.408495]\n",
      "epoch:0 step:264 [D loss: 0.268140, acc.: 50.78%] [G loss: 0.420849]\n",
      "epoch:0 step:265 [D loss: 0.262356, acc.: 55.47%] [G loss: 0.391802]\n",
      "epoch:0 step:266 [D loss: 0.271199, acc.: 53.12%] [G loss: 0.372563]\n",
      "epoch:0 step:267 [D loss: 0.248395, acc.: 59.38%] [G loss: 0.371281]\n",
      "epoch:0 step:268 [D loss: 0.261919, acc.: 57.03%] [G loss: 0.370106]\n",
      "epoch:0 step:269 [D loss: 0.251490, acc.: 54.69%] [G loss: 0.391533]\n",
      "epoch:0 step:270 [D loss: 0.244536, acc.: 61.72%] [G loss: 0.396539]\n",
      "epoch:0 step:271 [D loss: 0.257673, acc.: 54.69%] [G loss: 0.407267]\n",
      "epoch:0 step:272 [D loss: 0.265765, acc.: 54.69%] [G loss: 0.357869]\n",
      "epoch:0 step:273 [D loss: 0.247742, acc.: 57.81%] [G loss: 0.337093]\n",
      "epoch:0 step:274 [D loss: 0.271015, acc.: 54.69%] [G loss: 0.325828]\n",
      "epoch:0 step:275 [D loss: 0.249673, acc.: 58.59%] [G loss: 0.319624]\n",
      "epoch:0 step:276 [D loss: 0.267518, acc.: 53.12%] [G loss: 0.328004]\n",
      "epoch:0 step:277 [D loss: 0.256513, acc.: 57.81%] [G loss: 0.307245]\n",
      "epoch:0 step:278 [D loss: 0.250430, acc.: 60.16%] [G loss: 0.378899]\n",
      "epoch:0 step:279 [D loss: 0.240517, acc.: 57.81%] [G loss: 0.347327]\n",
      "epoch:0 step:280 [D loss: 0.265321, acc.: 53.12%] [G loss: 0.370077]\n",
      "epoch:0 step:281 [D loss: 0.226905, acc.: 64.84%] [G loss: 0.363100]\n",
      "epoch:0 step:282 [D loss: 0.240555, acc.: 60.94%] [G loss: 0.402357]\n",
      "epoch:0 step:283 [D loss: 0.240081, acc.: 60.16%] [G loss: 0.372827]\n",
      "epoch:0 step:284 [D loss: 0.248531, acc.: 59.38%] [G loss: 0.309660]\n",
      "epoch:0 step:285 [D loss: 0.266522, acc.: 47.66%] [G loss: 0.354239]\n",
      "epoch:0 step:286 [D loss: 0.253442, acc.: 60.16%] [G loss: 0.340730]\n",
      "epoch:0 step:287 [D loss: 0.258156, acc.: 57.81%] [G loss: 0.328895]\n",
      "epoch:0 step:288 [D loss: 0.242699, acc.: 55.47%] [G loss: 0.337824]\n",
      "epoch:0 step:289 [D loss: 0.240701, acc.: 63.28%] [G loss: 0.322209]\n",
      "epoch:0 step:290 [D loss: 0.270016, acc.: 53.12%] [G loss: 0.372431]\n",
      "epoch:0 step:291 [D loss: 0.255962, acc.: 52.34%] [G loss: 0.330244]\n",
      "epoch:0 step:292 [D loss: 0.261581, acc.: 49.22%] [G loss: 0.355296]\n",
      "epoch:0 step:293 [D loss: 0.250767, acc.: 58.59%] [G loss: 0.358176]\n",
      "epoch:0 step:294 [D loss: 0.274934, acc.: 52.34%] [G loss: 0.360435]\n",
      "epoch:0 step:295 [D loss: 0.284315, acc.: 46.09%] [G loss: 0.368470]\n",
      "epoch:0 step:296 [D loss: 0.260393, acc.: 57.03%] [G loss: 0.346239]\n",
      "epoch:0 step:297 [D loss: 0.255432, acc.: 52.34%] [G loss: 0.326530]\n",
      "epoch:0 step:298 [D loss: 0.247922, acc.: 56.25%] [G loss: 0.376514]\n",
      "epoch:0 step:299 [D loss: 0.232984, acc.: 62.50%] [G loss: 0.358599]\n",
      "epoch:0 step:300 [D loss: 0.266901, acc.: 50.78%] [G loss: 0.377420]\n",
      "epoch:0 step:301 [D loss: 0.246628, acc.: 56.25%] [G loss: 0.362207]\n",
      "epoch:0 step:302 [D loss: 0.250045, acc.: 56.25%] [G loss: 0.385699]\n",
      "epoch:0 step:303 [D loss: 0.256464, acc.: 51.56%] [G loss: 0.388581]\n",
      "epoch:0 step:304 [D loss: 0.221042, acc.: 65.62%] [G loss: 0.322536]\n",
      "epoch:0 step:305 [D loss: 0.217281, acc.: 66.41%] [G loss: 0.349872]\n",
      "epoch:0 step:306 [D loss: 0.219561, acc.: 67.97%] [G loss: 0.327592]\n",
      "epoch:0 step:307 [D loss: 0.239675, acc.: 53.91%] [G loss: 0.346284]\n",
      "epoch:0 step:308 [D loss: 0.239069, acc.: 66.41%] [G loss: 0.323718]\n",
      "epoch:0 step:309 [D loss: 0.246094, acc.: 58.59%] [G loss: 0.357367]\n",
      "epoch:0 step:310 [D loss: 0.259088, acc.: 57.03%] [G loss: 0.369644]\n",
      "epoch:0 step:311 [D loss: 0.263769, acc.: 53.12%] [G loss: 0.377903]\n",
      "epoch:0 step:312 [D loss: 0.256118, acc.: 52.34%] [G loss: 0.348914]\n",
      "epoch:0 step:313 [D loss: 0.259081, acc.: 57.03%] [G loss: 0.373081]\n",
      "epoch:0 step:314 [D loss: 0.253250, acc.: 57.03%] [G loss: 0.358816]\n",
      "epoch:0 step:315 [D loss: 0.232500, acc.: 63.28%] [G loss: 0.361814]\n",
      "epoch:0 step:316 [D loss: 0.225187, acc.: 58.59%] [G loss: 0.350717]\n",
      "epoch:0 step:317 [D loss: 0.239569, acc.: 62.50%] [G loss: 0.356861]\n",
      "epoch:0 step:318 [D loss: 0.209755, acc.: 68.75%] [G loss: 0.363710]\n",
      "epoch:0 step:319 [D loss: 0.260415, acc.: 58.59%] [G loss: 0.315003]\n",
      "epoch:0 step:320 [D loss: 0.253530, acc.: 53.12%] [G loss: 0.364969]\n",
      "epoch:0 step:321 [D loss: 0.208069, acc.: 66.41%] [G loss: 0.355113]\n",
      "epoch:0 step:322 [D loss: 0.245106, acc.: 58.59%] [G loss: 0.372777]\n",
      "epoch:0 step:323 [D loss: 0.276703, acc.: 46.88%] [G loss: 0.357236]\n",
      "epoch:0 step:324 [D loss: 0.271737, acc.: 51.56%] [G loss: 0.322976]\n",
      "epoch:0 step:325 [D loss: 0.229829, acc.: 62.50%] [G loss: 0.362577]\n",
      "epoch:0 step:326 [D loss: 0.225059, acc.: 60.16%] [G loss: 0.389451]\n",
      "epoch:0 step:327 [D loss: 0.259384, acc.: 57.81%] [G loss: 0.304041]\n",
      "epoch:0 step:328 [D loss: 0.242335, acc.: 59.38%] [G loss: 0.358595]\n",
      "epoch:0 step:329 [D loss: 0.249130, acc.: 61.72%] [G loss: 0.373176]\n",
      "epoch:0 step:330 [D loss: 0.244230, acc.: 57.03%] [G loss: 0.367769]\n",
      "epoch:0 step:331 [D loss: 0.234215, acc.: 66.41%] [G loss: 0.387314]\n",
      "epoch:0 step:332 [D loss: 0.229777, acc.: 68.75%] [G loss: 0.343650]\n",
      "epoch:0 step:333 [D loss: 0.242510, acc.: 60.94%] [G loss: 0.388805]\n",
      "epoch:0 step:334 [D loss: 0.242576, acc.: 57.81%] [G loss: 0.346820]\n",
      "epoch:0 step:335 [D loss: 0.247698, acc.: 59.38%] [G loss: 0.336334]\n",
      "epoch:0 step:336 [D loss: 0.242204, acc.: 63.28%] [G loss: 0.359450]\n",
      "epoch:0 step:337 [D loss: 0.268890, acc.: 52.34%] [G loss: 0.343466]\n",
      "epoch:0 step:338 [D loss: 0.233547, acc.: 63.28%] [G loss: 0.357541]\n",
      "epoch:0 step:339 [D loss: 0.247185, acc.: 59.38%] [G loss: 0.366979]\n",
      "epoch:0 step:340 [D loss: 0.237856, acc.: 57.81%] [G loss: 0.360588]\n",
      "epoch:0 step:341 [D loss: 0.228663, acc.: 60.94%] [G loss: 0.337091]\n",
      "epoch:0 step:342 [D loss: 0.256607, acc.: 55.47%] [G loss: 0.337906]\n",
      "epoch:0 step:343 [D loss: 0.273049, acc.: 50.78%] [G loss: 0.346718]\n",
      "epoch:0 step:344 [D loss: 0.255034, acc.: 56.25%] [G loss: 0.316503]\n",
      "epoch:0 step:345 [D loss: 0.245698, acc.: 60.94%] [G loss: 0.359553]\n",
      "epoch:0 step:346 [D loss: 0.258343, acc.: 57.03%] [G loss: 0.322051]\n",
      "epoch:0 step:347 [D loss: 0.223026, acc.: 65.62%] [G loss: 0.331823]\n",
      "epoch:0 step:348 [D loss: 0.242706, acc.: 57.81%] [G loss: 0.330299]\n",
      "epoch:0 step:349 [D loss: 0.234931, acc.: 62.50%] [G loss: 0.285300]\n",
      "epoch:0 step:350 [D loss: 0.225399, acc.: 64.84%] [G loss: 0.356746]\n",
      "epoch:0 step:351 [D loss: 0.252959, acc.: 53.91%] [G loss: 0.336215]\n",
      "epoch:0 step:352 [D loss: 0.231645, acc.: 59.38%] [G loss: 0.350422]\n",
      "epoch:0 step:353 [D loss: 0.255608, acc.: 54.69%] [G loss: 0.367804]\n",
      "epoch:0 step:354 [D loss: 0.245923, acc.: 60.94%] [G loss: 0.377976]\n",
      "epoch:0 step:355 [D loss: 0.257328, acc.: 51.56%] [G loss: 0.321189]\n",
      "epoch:0 step:356 [D loss: 0.228830, acc.: 64.84%] [G loss: 0.351569]\n",
      "epoch:0 step:357 [D loss: 0.236512, acc.: 62.50%] [G loss: 0.373831]\n",
      "epoch:0 step:358 [D loss: 0.203040, acc.: 71.88%] [G loss: 0.429822]\n",
      "epoch:0 step:359 [D loss: 0.247052, acc.: 54.69%] [G loss: 0.367704]\n",
      "epoch:0 step:360 [D loss: 0.268928, acc.: 54.69%] [G loss: 0.413096]\n",
      "epoch:0 step:361 [D loss: 0.221405, acc.: 64.84%] [G loss: 0.388708]\n",
      "epoch:0 step:362 [D loss: 0.213382, acc.: 61.72%] [G loss: 0.353826]\n",
      "epoch:0 step:363 [D loss: 0.257803, acc.: 53.91%] [G loss: 0.352189]\n",
      "epoch:0 step:364 [D loss: 0.254528, acc.: 54.69%] [G loss: 0.333160]\n",
      "epoch:0 step:365 [D loss: 0.252897, acc.: 55.47%] [G loss: 0.351619]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0 step:366 [D loss: 0.260277, acc.: 55.47%] [G loss: 0.364816]\n",
      "epoch:0 step:367 [D loss: 0.238510, acc.: 55.47%] [G loss: 0.374283]\n",
      "epoch:0 step:368 [D loss: 0.232354, acc.: 65.62%] [G loss: 0.366799]\n",
      "epoch:0 step:369 [D loss: 0.252688, acc.: 55.47%] [G loss: 0.320465]\n",
      "epoch:0 step:370 [D loss: 0.264655, acc.: 50.78%] [G loss: 0.383912]\n",
      "epoch:0 step:371 [D loss: 0.263321, acc.: 53.91%] [G loss: 0.312799]\n",
      "epoch:0 step:372 [D loss: 0.242231, acc.: 57.03%] [G loss: 0.358730]\n",
      "epoch:0 step:373 [D loss: 0.237884, acc.: 59.38%] [G loss: 0.366934]\n",
      "epoch:0 step:374 [D loss: 0.231516, acc.: 61.72%] [G loss: 0.392009]\n",
      "epoch:0 step:375 [D loss: 0.244523, acc.: 59.38%] [G loss: 0.390980]\n",
      "epoch:0 step:376 [D loss: 0.240822, acc.: 59.38%] [G loss: 0.345611]\n",
      "epoch:0 step:377 [D loss: 0.261544, acc.: 54.69%] [G loss: 0.336191]\n",
      "epoch:0 step:378 [D loss: 0.248911, acc.: 57.03%] [G loss: 0.337938]\n",
      "epoch:0 step:379 [D loss: 0.262641, acc.: 55.47%] [G loss: 0.362217]\n",
      "epoch:0 step:380 [D loss: 0.226338, acc.: 61.72%] [G loss: 0.357308]\n",
      "epoch:0 step:381 [D loss: 0.260453, acc.: 57.03%] [G loss: 0.312161]\n",
      "epoch:0 step:382 [D loss: 0.232369, acc.: 60.16%] [G loss: 0.283122]\n",
      "epoch:0 step:383 [D loss: 0.231033, acc.: 58.59%] [G loss: 0.339975]\n",
      "epoch:0 step:384 [D loss: 0.235697, acc.: 61.72%] [G loss: 0.351874]\n",
      "epoch:0 step:385 [D loss: 0.258792, acc.: 57.03%] [G loss: 0.305603]\n",
      "epoch:0 step:386 [D loss: 0.243875, acc.: 58.59%] [G loss: 0.353697]\n",
      "epoch:0 step:387 [D loss: 0.254413, acc.: 58.59%] [G loss: 0.346684]\n",
      "epoch:0 step:388 [D loss: 0.233932, acc.: 56.25%] [G loss: 0.349099]\n",
      "epoch:0 step:389 [D loss: 0.248625, acc.: 60.94%] [G loss: 0.341656]\n",
      "epoch:0 step:390 [D loss: 0.258603, acc.: 54.69%] [G loss: 0.383075]\n",
      "epoch:0 step:391 [D loss: 0.244107, acc.: 59.38%] [G loss: 0.343995]\n",
      "epoch:0 step:392 [D loss: 0.249445, acc.: 61.72%] [G loss: 0.341052]\n",
      "epoch:0 step:393 [D loss: 0.246058, acc.: 60.94%] [G loss: 0.308237]\n",
      "epoch:0 step:394 [D loss: 0.261511, acc.: 51.56%] [G loss: 0.379404]\n",
      "epoch:0 step:395 [D loss: 0.238710, acc.: 59.38%] [G loss: 0.352366]\n",
      "epoch:0 step:396 [D loss: 0.224145, acc.: 63.28%] [G loss: 0.376351]\n",
      "epoch:0 step:397 [D loss: 0.231889, acc.: 63.28%] [G loss: 0.325751]\n",
      "epoch:0 step:398 [D loss: 0.250477, acc.: 57.03%] [G loss: 0.330446]\n",
      "epoch:0 step:399 [D loss: 0.247860, acc.: 58.59%] [G loss: 0.309970]\n",
      "epoch:0 step:400 [D loss: 0.237725, acc.: 60.94%] [G loss: 0.335430]\n",
      "epoch:0 step:401 [D loss: 0.229373, acc.: 59.38%] [G loss: 0.383132]\n",
      "epoch:0 step:402 [D loss: 0.259300, acc.: 50.78%] [G loss: 0.377348]\n",
      "epoch:0 step:403 [D loss: 0.235461, acc.: 62.50%] [G loss: 0.327338]\n",
      "epoch:0 step:404 [D loss: 0.259488, acc.: 53.12%] [G loss: 0.373085]\n",
      "epoch:0 step:405 [D loss: 0.237833, acc.: 63.28%] [G loss: 0.381488]\n",
      "epoch:0 step:406 [D loss: 0.245845, acc.: 59.38%] [G loss: 0.367081]\n",
      "epoch:0 step:407 [D loss: 0.249255, acc.: 53.12%] [G loss: 0.351456]\n",
      "epoch:0 step:408 [D loss: 0.239870, acc.: 63.28%] [G loss: 0.381400]\n",
      "epoch:0 step:409 [D loss: 0.255140, acc.: 55.47%] [G loss: 0.349846]\n",
      "epoch:0 step:410 [D loss: 0.241906, acc.: 60.94%] [G loss: 0.359672]\n",
      "epoch:0 step:411 [D loss: 0.243781, acc.: 57.03%] [G loss: 0.338629]\n",
      "epoch:0 step:412 [D loss: 0.248198, acc.: 58.59%] [G loss: 0.367460]\n",
      "epoch:0 step:413 [D loss: 0.245300, acc.: 61.72%] [G loss: 0.318004]\n",
      "epoch:0 step:414 [D loss: 0.240750, acc.: 57.03%] [G loss: 0.338740]\n",
      "epoch:0 step:415 [D loss: 0.265253, acc.: 51.56%] [G loss: 0.334943]\n",
      "epoch:0 step:416 [D loss: 0.243591, acc.: 55.47%] [G loss: 0.324606]\n",
      "epoch:0 step:417 [D loss: 0.251047, acc.: 59.38%] [G loss: 0.342656]\n",
      "epoch:0 step:418 [D loss: 0.235757, acc.: 64.06%] [G loss: 0.344932]\n",
      "epoch:0 step:419 [D loss: 0.223718, acc.: 63.28%] [G loss: 0.363780]\n",
      "epoch:0 step:420 [D loss: 0.240628, acc.: 56.25%] [G loss: 0.356986]\n",
      "epoch:0 step:421 [D loss: 0.227386, acc.: 64.84%] [G loss: 0.327588]\n",
      "epoch:0 step:422 [D loss: 0.251847, acc.: 58.59%] [G loss: 0.339568]\n",
      "epoch:0 step:423 [D loss: 0.214154, acc.: 60.94%] [G loss: 0.309734]\n",
      "epoch:0 step:424 [D loss: 0.255351, acc.: 56.25%] [G loss: 0.356567]\n",
      "epoch:0 step:425 [D loss: 0.235233, acc.: 61.72%] [G loss: 0.400217]\n",
      "epoch:0 step:426 [D loss: 0.252968, acc.: 51.56%] [G loss: 0.346191]\n",
      "epoch:0 step:427 [D loss: 0.220783, acc.: 64.84%] [G loss: 0.359060]\n",
      "epoch:0 step:428 [D loss: 0.239888, acc.: 62.50%] [G loss: 0.402219]\n",
      "epoch:0 step:429 [D loss: 0.250299, acc.: 57.03%] [G loss: 0.351754]\n",
      "epoch:0 step:430 [D loss: 0.214822, acc.: 68.75%] [G loss: 0.349526]\n",
      "epoch:0 step:431 [D loss: 0.239807, acc.: 55.47%] [G loss: 0.334094]\n",
      "epoch:0 step:432 [D loss: 0.253953, acc.: 51.56%] [G loss: 0.327561]\n",
      "epoch:0 step:433 [D loss: 0.238743, acc.: 61.72%] [G loss: 0.325943]\n",
      "epoch:0 step:434 [D loss: 0.232276, acc.: 55.47%] [G loss: 0.327158]\n",
      "epoch:0 step:435 [D loss: 0.244115, acc.: 58.59%] [G loss: 0.353745]\n",
      "epoch:0 step:436 [D loss: 0.230859, acc.: 60.94%] [G loss: 0.364425]\n",
      "epoch:0 step:437 [D loss: 0.248479, acc.: 60.94%] [G loss: 0.364368]\n",
      "epoch:0 step:438 [D loss: 0.246873, acc.: 56.25%] [G loss: 0.374249]\n",
      "epoch:0 step:439 [D loss: 0.243431, acc.: 56.25%] [G loss: 0.353885]\n",
      "epoch:0 step:440 [D loss: 0.250742, acc.: 64.06%] [G loss: 0.351306]\n",
      "epoch:0 step:441 [D loss: 0.248733, acc.: 58.59%] [G loss: 0.339337]\n",
      "epoch:0 step:442 [D loss: 0.227596, acc.: 60.94%] [G loss: 0.336755]\n",
      "epoch:0 step:443 [D loss: 0.257280, acc.: 52.34%] [G loss: 0.335960]\n",
      "epoch:0 step:444 [D loss: 0.229472, acc.: 62.50%] [G loss: 0.373346]\n",
      "epoch:0 step:445 [D loss: 0.235741, acc.: 61.72%] [G loss: 0.383830]\n",
      "epoch:0 step:446 [D loss: 0.237714, acc.: 57.81%] [G loss: 0.412085]\n",
      "epoch:0 step:447 [D loss: 0.271637, acc.: 52.34%] [G loss: 0.313841]\n",
      "epoch:0 step:448 [D loss: 0.234502, acc.: 64.06%] [G loss: 0.304143]\n",
      "epoch:0 step:449 [D loss: 0.240998, acc.: 60.94%] [G loss: 0.363770]\n",
      "epoch:0 step:450 [D loss: 0.239818, acc.: 57.81%] [G loss: 0.337974]\n",
      "epoch:0 step:451 [D loss: 0.255541, acc.: 59.38%] [G loss: 0.391786]\n",
      "epoch:0 step:452 [D loss: 0.234317, acc.: 60.94%] [G loss: 0.381767]\n",
      "epoch:0 step:453 [D loss: 0.263440, acc.: 57.03%] [G loss: 0.381666]\n",
      "epoch:0 step:454 [D loss: 0.235817, acc.: 60.16%] [G loss: 0.384290]\n",
      "epoch:0 step:455 [D loss: 0.220210, acc.: 65.62%] [G loss: 0.347997]\n",
      "epoch:0 step:456 [D loss: 0.247675, acc.: 61.72%] [G loss: 0.336563]\n",
      "epoch:0 step:457 [D loss: 0.243627, acc.: 55.47%] [G loss: 0.374922]\n",
      "epoch:0 step:458 [D loss: 0.246915, acc.: 56.25%] [G loss: 0.339494]\n",
      "epoch:0 step:459 [D loss: 0.234753, acc.: 60.16%] [G loss: 0.337504]\n",
      "epoch:0 step:460 [D loss: 0.236822, acc.: 56.25%] [G loss: 0.340071]\n",
      "epoch:0 step:461 [D loss: 0.226241, acc.: 67.19%] [G loss: 0.359941]\n",
      "epoch:0 step:462 [D loss: 0.236682, acc.: 56.25%] [G loss: 0.343459]\n",
      "epoch:0 step:463 [D loss: 0.241602, acc.: 56.25%] [G loss: 0.365155]\n",
      "epoch:0 step:464 [D loss: 0.265902, acc.: 48.44%] [G loss: 0.320260]\n",
      "epoch:0 step:465 [D loss: 0.212965, acc.: 65.62%] [G loss: 0.357609]\n",
      "epoch:0 step:466 [D loss: 0.231880, acc.: 57.03%] [G loss: 0.363731]\n",
      "epoch:0 step:467 [D loss: 0.260377, acc.: 50.78%] [G loss: 0.350381]\n",
      "epoch:0 step:468 [D loss: 0.235405, acc.: 65.62%] [G loss: 0.314027]\n",
      "epoch:0 step:469 [D loss: 0.228522, acc.: 63.28%] [G loss: 0.382620]\n",
      "epoch:0 step:470 [D loss: 0.218964, acc.: 60.94%] [G loss: 0.352562]\n",
      "epoch:0 step:471 [D loss: 0.247740, acc.: 58.59%] [G loss: 0.368466]\n",
      "epoch:0 step:472 [D loss: 0.231370, acc.: 58.59%] [G loss: 0.356098]\n",
      "epoch:0 step:473 [D loss: 0.260384, acc.: 56.25%] [G loss: 0.396843]\n",
      "epoch:0 step:474 [D loss: 0.255102, acc.: 57.81%] [G loss: 0.373316]\n",
      "epoch:0 step:475 [D loss: 0.223024, acc.: 67.97%] [G loss: 0.368994]\n",
      "epoch:0 step:476 [D loss: 0.242623, acc.: 60.16%] [G loss: 0.349092]\n",
      "epoch:0 step:477 [D loss: 0.243812, acc.: 61.72%] [G loss: 0.381193]\n",
      "epoch:0 step:478 [D loss: 0.242796, acc.: 59.38%] [G loss: 0.302927]\n",
      "epoch:0 step:479 [D loss: 0.243749, acc.: 60.16%] [G loss: 0.345743]\n",
      "epoch:0 step:480 [D loss: 0.232444, acc.: 60.16%] [G loss: 0.302100]\n",
      "epoch:0 step:481 [D loss: 0.226254, acc.: 62.50%] [G loss: 0.352078]\n",
      "epoch:0 step:482 [D loss: 0.247406, acc.: 62.50%] [G loss: 0.319001]\n",
      "epoch:0 step:483 [D loss: 0.254789, acc.: 56.25%] [G loss: 0.366816]\n",
      "epoch:0 step:484 [D loss: 0.228614, acc.: 60.16%] [G loss: 0.327007]\n",
      "epoch:0 step:485 [D loss: 0.234123, acc.: 63.28%] [G loss: 0.357709]\n",
      "epoch:0 step:486 [D loss: 0.235593, acc.: 62.50%] [G loss: 0.363635]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0 step:487 [D loss: 0.252469, acc.: 59.38%] [G loss: 0.350638]\n",
      "epoch:0 step:488 [D loss: 0.255164, acc.: 53.12%] [G loss: 0.365726]\n",
      "epoch:0 step:489 [D loss: 0.208392, acc.: 68.75%] [G loss: 0.322158]\n",
      "epoch:0 step:490 [D loss: 0.236474, acc.: 60.94%] [G loss: 0.334746]\n",
      "epoch:0 step:491 [D loss: 0.223515, acc.: 65.62%] [G loss: 0.398811]\n",
      "epoch:0 step:492 [D loss: 0.250057, acc.: 55.47%] [G loss: 0.328435]\n",
      "epoch:0 step:493 [D loss: 0.213843, acc.: 64.06%] [G loss: 0.358057]\n",
      "epoch:0 step:494 [D loss: 0.227718, acc.: 64.84%] [G loss: 0.370593]\n",
      "epoch:0 step:495 [D loss: 0.249601, acc.: 57.03%] [G loss: 0.339945]\n",
      "epoch:0 step:496 [D loss: 0.269104, acc.: 50.00%] [G loss: 0.338641]\n",
      "epoch:0 step:497 [D loss: 0.249017, acc.: 57.03%] [G loss: 0.348643]\n",
      "epoch:0 step:498 [D loss: 0.219094, acc.: 66.41%] [G loss: 0.368800]\n",
      "epoch:0 step:499 [D loss: 0.226476, acc.: 57.81%] [G loss: 0.375243]\n",
      "epoch:0 step:500 [D loss: 0.246045, acc.: 58.59%] [G loss: 0.416633]\n",
      "epoch:0 step:501 [D loss: 0.245714, acc.: 59.38%] [G loss: 0.358149]\n",
      "epoch:0 step:502 [D loss: 0.237631, acc.: 57.81%] [G loss: 0.377982]\n",
      "epoch:0 step:503 [D loss: 0.229429, acc.: 62.50%] [G loss: 0.334588]\n",
      "epoch:0 step:504 [D loss: 0.239769, acc.: 57.03%] [G loss: 0.371797]\n",
      "epoch:0 step:505 [D loss: 0.240844, acc.: 55.47%] [G loss: 0.336518]\n",
      "epoch:0 step:506 [D loss: 0.229063, acc.: 67.19%] [G loss: 0.314889]\n",
      "epoch:0 step:507 [D loss: 0.231559, acc.: 60.16%] [G loss: 0.301876]\n",
      "epoch:0 step:508 [D loss: 0.234981, acc.: 59.38%] [G loss: 0.333329]\n",
      "epoch:0 step:509 [D loss: 0.243619, acc.: 58.59%] [G loss: 0.348668]\n",
      "epoch:0 step:510 [D loss: 0.229187, acc.: 64.84%] [G loss: 0.315313]\n",
      "epoch:0 step:511 [D loss: 0.265319, acc.: 54.69%] [G loss: 0.363867]\n",
      "epoch:0 step:512 [D loss: 0.231516, acc.: 60.94%] [G loss: 0.332820]\n",
      "epoch:0 step:513 [D loss: 0.243354, acc.: 58.59%] [G loss: 0.340866]\n",
      "epoch:0 step:514 [D loss: 0.236536, acc.: 62.50%] [G loss: 0.382198]\n",
      "epoch:0 step:515 [D loss: 0.239613, acc.: 60.16%] [G loss: 0.350556]\n",
      "epoch:0 step:516 [D loss: 0.232583, acc.: 66.41%] [G loss: 0.352698]\n",
      "epoch:0 step:517 [D loss: 0.216771, acc.: 64.06%] [G loss: 0.338876]\n",
      "epoch:0 step:518 [D loss: 0.215698, acc.: 64.06%] [G loss: 0.378939]\n",
      "epoch:0 step:519 [D loss: 0.230934, acc.: 67.19%] [G loss: 0.336491]\n",
      "epoch:0 step:520 [D loss: 0.225815, acc.: 67.19%] [G loss: 0.371736]\n",
      "epoch:0 step:521 [D loss: 0.250399, acc.: 60.16%] [G loss: 0.357383]\n",
      "epoch:0 step:522 [D loss: 0.229687, acc.: 60.16%] [G loss: 0.359735]\n",
      "epoch:0 step:523 [D loss: 0.234171, acc.: 59.38%] [G loss: 0.354304]\n",
      "epoch:0 step:524 [D loss: 0.253778, acc.: 53.91%] [G loss: 0.375572]\n",
      "epoch:0 step:525 [D loss: 0.235712, acc.: 61.72%] [G loss: 0.369301]\n",
      "epoch:0 step:526 [D loss: 0.245536, acc.: 57.03%] [G loss: 0.324972]\n",
      "epoch:0 step:527 [D loss: 0.249580, acc.: 57.03%] [G loss: 0.356651]\n",
      "epoch:0 step:528 [D loss: 0.236102, acc.: 55.47%] [G loss: 0.337906]\n",
      "epoch:0 step:529 [D loss: 0.259080, acc.: 57.03%] [G loss: 0.322818]\n",
      "epoch:0 step:530 [D loss: 0.216615, acc.: 67.19%] [G loss: 0.357508]\n",
      "epoch:0 step:531 [D loss: 0.235862, acc.: 64.06%] [G loss: 0.361534]\n",
      "epoch:0 step:532 [D loss: 0.250426, acc.: 58.59%] [G loss: 0.353199]\n",
      "epoch:0 step:533 [D loss: 0.233862, acc.: 57.81%] [G loss: 0.417032]\n",
      "epoch:0 step:534 [D loss: 0.238175, acc.: 61.72%] [G loss: 0.368643]\n",
      "epoch:0 step:535 [D loss: 0.223670, acc.: 66.41%] [G loss: 0.344127]\n",
      "epoch:0 step:536 [D loss: 0.242017, acc.: 57.81%] [G loss: 0.367576]\n",
      "epoch:0 step:537 [D loss: 0.241055, acc.: 60.16%] [G loss: 0.351859]\n",
      "epoch:0 step:538 [D loss: 0.244466, acc.: 57.81%] [G loss: 0.371507]\n",
      "epoch:0 step:539 [D loss: 0.230426, acc.: 64.84%] [G loss: 0.372606]\n",
      "epoch:0 step:540 [D loss: 0.233154, acc.: 57.81%] [G loss: 0.368695]\n",
      "epoch:0 step:541 [D loss: 0.235142, acc.: 63.28%] [G loss: 0.352136]\n",
      "epoch:0 step:542 [D loss: 0.247628, acc.: 58.59%] [G loss: 0.315047]\n",
      "epoch:0 step:543 [D loss: 0.223092, acc.: 62.50%] [G loss: 0.389369]\n",
      "epoch:0 step:544 [D loss: 0.215351, acc.: 65.62%] [G loss: 0.358918]\n",
      "epoch:0 step:545 [D loss: 0.235077, acc.: 60.16%] [G loss: 0.348673]\n",
      "epoch:0 step:546 [D loss: 0.230639, acc.: 61.72%] [G loss: 0.363991]\n",
      "epoch:0 step:547 [D loss: 0.245839, acc.: 58.59%] [G loss: 0.348051]\n",
      "epoch:0 step:548 [D loss: 0.211040, acc.: 68.75%] [G loss: 0.380943]\n",
      "epoch:0 step:549 [D loss: 0.223229, acc.: 64.84%] [G loss: 0.362122]\n",
      "epoch:0 step:550 [D loss: 0.241330, acc.: 57.03%] [G loss: 0.362148]\n",
      "epoch:0 step:551 [D loss: 0.239519, acc.: 57.03%] [G loss: 0.353508]\n",
      "epoch:0 step:552 [D loss: 0.272423, acc.: 53.12%] [G loss: 0.337194]\n",
      "epoch:0 step:553 [D loss: 0.249690, acc.: 53.91%] [G loss: 0.309410]\n",
      "epoch:0 step:554 [D loss: 0.239863, acc.: 56.25%] [G loss: 0.356197]\n",
      "epoch:0 step:555 [D loss: 0.264117, acc.: 53.91%] [G loss: 0.346536]\n",
      "epoch:0 step:556 [D loss: 0.244472, acc.: 60.16%] [G loss: 0.333701]\n",
      "epoch:0 step:557 [D loss: 0.228719, acc.: 61.72%] [G loss: 0.342950]\n",
      "epoch:0 step:558 [D loss: 0.248103, acc.: 53.12%] [G loss: 0.339980]\n",
      "epoch:0 step:559 [D loss: 0.244517, acc.: 57.81%] [G loss: 0.367566]\n",
      "epoch:0 step:560 [D loss: 0.234277, acc.: 63.28%] [G loss: 0.329615]\n",
      "epoch:0 step:561 [D loss: 0.219612, acc.: 64.84%] [G loss: 0.321844]\n",
      "epoch:0 step:562 [D loss: 0.244031, acc.: 56.25%] [G loss: 0.393486]\n",
      "epoch:0 step:563 [D loss: 0.252101, acc.: 60.16%] [G loss: 0.372421]\n",
      "epoch:0 step:564 [D loss: 0.239946, acc.: 59.38%] [G loss: 0.349923]\n",
      "epoch:0 step:565 [D loss: 0.249844, acc.: 53.12%] [G loss: 0.357331]\n",
      "epoch:0 step:566 [D loss: 0.235323, acc.: 59.38%] [G loss: 0.359578]\n",
      "epoch:0 step:567 [D loss: 0.226253, acc.: 66.41%] [G loss: 0.344075]\n",
      "epoch:0 step:568 [D loss: 0.255562, acc.: 53.12%] [G loss: 0.395060]\n",
      "epoch:0 step:569 [D loss: 0.240789, acc.: 60.16%] [G loss: 0.304895]\n",
      "epoch:0 step:570 [D loss: 0.226037, acc.: 64.84%] [G loss: 0.342841]\n",
      "epoch:0 step:571 [D loss: 0.221517, acc.: 62.50%] [G loss: 0.339935]\n",
      "epoch:0 step:572 [D loss: 0.229529, acc.: 57.81%] [G loss: 0.356237]\n",
      "epoch:0 step:573 [D loss: 0.235594, acc.: 60.94%] [G loss: 0.313469]\n",
      "epoch:0 step:574 [D loss: 0.215843, acc.: 66.41%] [G loss: 0.345979]\n",
      "epoch:0 step:575 [D loss: 0.221660, acc.: 62.50%] [G loss: 0.352143]\n",
      "epoch:0 step:576 [D loss: 0.213215, acc.: 67.19%] [G loss: 0.347392]\n",
      "epoch:0 step:577 [D loss: 0.229519, acc.: 62.50%] [G loss: 0.352109]\n",
      "epoch:0 step:578 [D loss: 0.232809, acc.: 62.50%] [G loss: 0.351050]\n",
      "epoch:0 step:579 [D loss: 0.237297, acc.: 64.84%] [G loss: 0.324684]\n",
      "epoch:0 step:580 [D loss: 0.236913, acc.: 64.06%] [G loss: 0.349199]\n",
      "epoch:0 step:581 [D loss: 0.238119, acc.: 60.94%] [G loss: 0.355469]\n",
      "epoch:0 step:582 [D loss: 0.235220, acc.: 63.28%] [G loss: 0.403893]\n",
      "epoch:0 step:583 [D loss: 0.232598, acc.: 64.06%] [G loss: 0.342239]\n",
      "epoch:0 step:584 [D loss: 0.252588, acc.: 52.34%] [G loss: 0.398654]\n",
      "epoch:0 step:585 [D loss: 0.233299, acc.: 59.38%] [G loss: 0.372222]\n",
      "epoch:0 step:586 [D loss: 0.265714, acc.: 47.66%] [G loss: 0.420044]\n",
      "epoch:0 step:587 [D loss: 0.247423, acc.: 57.03%] [G loss: 0.358407]\n",
      "epoch:0 step:588 [D loss: 0.220380, acc.: 62.50%] [G loss: 0.341114]\n",
      "epoch:0 step:589 [D loss: 0.221463, acc.: 64.84%] [G loss: 0.359265]\n",
      "epoch:0 step:590 [D loss: 0.238445, acc.: 60.94%] [G loss: 0.358168]\n",
      "epoch:0 step:591 [D loss: 0.212207, acc.: 65.62%] [G loss: 0.338767]\n",
      "epoch:0 step:592 [D loss: 0.223099, acc.: 62.50%] [G loss: 0.361411]\n",
      "epoch:0 step:593 [D loss: 0.237516, acc.: 60.94%] [G loss: 0.345471]\n",
      "epoch:0 step:594 [D loss: 0.215139, acc.: 67.97%] [G loss: 0.350424]\n",
      "epoch:0 step:595 [D loss: 0.224567, acc.: 67.97%] [G loss: 0.309575]\n",
      "epoch:0 step:596 [D loss: 0.216726, acc.: 64.84%] [G loss: 0.375477]\n",
      "epoch:0 step:597 [D loss: 0.253909, acc.: 58.59%] [G loss: 0.349105]\n",
      "epoch:0 step:598 [D loss: 0.229217, acc.: 61.72%] [G loss: 0.352326]\n",
      "epoch:0 step:599 [D loss: 0.236412, acc.: 60.94%] [G loss: 0.360407]\n",
      "epoch:0 step:600 [D loss: 0.213943, acc.: 66.41%] [G loss: 0.387367]\n",
      "epoch:0 step:601 [D loss: 0.245025, acc.: 60.16%] [G loss: 0.342773]\n",
      "epoch:0 step:602 [D loss: 0.206465, acc.: 70.31%] [G loss: 0.382712]\n",
      "epoch:0 step:603 [D loss: 0.244074, acc.: 59.38%] [G loss: 0.350449]\n",
      "epoch:0 step:604 [D loss: 0.222372, acc.: 64.06%] [G loss: 0.339889]\n",
      "epoch:0 step:605 [D loss: 0.217126, acc.: 66.41%] [G loss: 0.385738]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0 step:606 [D loss: 0.208252, acc.: 66.41%] [G loss: 0.354661]\n",
      "epoch:0 step:607 [D loss: 0.247933, acc.: 58.59%] [G loss: 0.370747]\n",
      "epoch:0 step:608 [D loss: 0.209313, acc.: 64.84%] [G loss: 0.359767]\n",
      "epoch:0 step:609 [D loss: 0.248507, acc.: 56.25%] [G loss: 0.329600]\n",
      "epoch:0 step:610 [D loss: 0.227366, acc.: 63.28%] [G loss: 0.318690]\n",
      "epoch:0 step:611 [D loss: 0.259887, acc.: 60.94%] [G loss: 0.336532]\n",
      "epoch:0 step:612 [D loss: 0.225125, acc.: 62.50%] [G loss: 0.337505]\n",
      "epoch:0 step:613 [D loss: 0.217084, acc.: 68.75%] [G loss: 0.370247]\n",
      "epoch:0 step:614 [D loss: 0.214090, acc.: 66.41%] [G loss: 0.338838]\n",
      "epoch:0 step:615 [D loss: 0.227187, acc.: 62.50%] [G loss: 0.373801]\n",
      "epoch:0 step:616 [D loss: 0.200096, acc.: 68.75%] [G loss: 0.387811]\n",
      "epoch:0 step:617 [D loss: 0.217855, acc.: 62.50%] [G loss: 0.333823]\n",
      "epoch:0 step:618 [D loss: 0.227337, acc.: 62.50%] [G loss: 0.387218]\n",
      "epoch:0 step:619 [D loss: 0.253445, acc.: 58.59%] [G loss: 0.359258]\n",
      "epoch:0 step:620 [D loss: 0.226637, acc.: 64.06%] [G loss: 0.355764]\n",
      "epoch:0 step:621 [D loss: 0.255230, acc.: 56.25%] [G loss: 0.336403]\n",
      "epoch:0 step:622 [D loss: 0.223167, acc.: 64.84%] [G loss: 0.333032]\n",
      "epoch:0 step:623 [D loss: 0.236778, acc.: 61.72%] [G loss: 0.400948]\n",
      "epoch:0 step:624 [D loss: 0.247695, acc.: 56.25%] [G loss: 0.360638]\n",
      "epoch:0 step:625 [D loss: 0.226117, acc.: 65.62%] [G loss: 0.410905]\n",
      "epoch:0 step:626 [D loss: 0.235529, acc.: 61.72%] [G loss: 0.402505]\n",
      "epoch:0 step:627 [D loss: 0.218152, acc.: 62.50%] [G loss: 0.342164]\n",
      "epoch:0 step:628 [D loss: 0.255110, acc.: 57.03%] [G loss: 0.349166]\n",
      "epoch:0 step:629 [D loss: 0.217534, acc.: 64.84%] [G loss: 0.328684]\n",
      "epoch:0 step:630 [D loss: 0.240877, acc.: 64.06%] [G loss: 0.398430]\n",
      "epoch:0 step:631 [D loss: 0.228174, acc.: 64.84%] [G loss: 0.385600]\n",
      "epoch:0 step:632 [D loss: 0.221512, acc.: 67.19%] [G loss: 0.352532]\n",
      "epoch:0 step:633 [D loss: 0.215708, acc.: 66.41%] [G loss: 0.367950]\n",
      "epoch:0 step:634 [D loss: 0.197465, acc.: 72.66%] [G loss: 0.407272]\n",
      "epoch:0 step:635 [D loss: 0.202227, acc.: 71.09%] [G loss: 0.420281]\n",
      "epoch:0 step:636 [D loss: 0.238464, acc.: 64.06%] [G loss: 0.368976]\n",
      "epoch:0 step:637 [D loss: 0.229901, acc.: 63.28%] [G loss: 0.407822]\n",
      "epoch:0 step:638 [D loss: 0.221742, acc.: 60.94%] [G loss: 0.387586]\n",
      "epoch:0 step:639 [D loss: 0.243431, acc.: 59.38%] [G loss: 0.359156]\n",
      "epoch:0 step:640 [D loss: 0.264567, acc.: 58.59%] [G loss: 0.332535]\n",
      "epoch:0 step:641 [D loss: 0.234686, acc.: 62.50%] [G loss: 0.353750]\n",
      "epoch:0 step:642 [D loss: 0.215485, acc.: 61.72%] [G loss: 0.329190]\n",
      "epoch:0 step:643 [D loss: 0.233134, acc.: 60.94%] [G loss: 0.390542]\n",
      "epoch:0 step:644 [D loss: 0.235273, acc.: 62.50%] [G loss: 0.323848]\n",
      "epoch:0 step:645 [D loss: 0.237353, acc.: 57.81%] [G loss: 0.403585]\n",
      "epoch:0 step:646 [D loss: 0.239653, acc.: 63.28%] [G loss: 0.327027]\n",
      "epoch:0 step:647 [D loss: 0.251847, acc.: 55.47%] [G loss: 0.344118]\n",
      "epoch:0 step:648 [D loss: 0.218860, acc.: 64.84%] [G loss: 0.383985]\n",
      "epoch:0 step:649 [D loss: 0.232705, acc.: 62.50%] [G loss: 0.348905]\n",
      "epoch:0 step:650 [D loss: 0.230666, acc.: 61.72%] [G loss: 0.365193]\n",
      "epoch:0 step:651 [D loss: 0.233358, acc.: 57.03%] [G loss: 0.357670]\n",
      "epoch:0 step:652 [D loss: 0.219507, acc.: 68.75%] [G loss: 0.374533]\n",
      "epoch:0 step:653 [D loss: 0.215843, acc.: 64.84%] [G loss: 0.360982]\n",
      "epoch:0 step:654 [D loss: 0.232970, acc.: 57.81%] [G loss: 0.365275]\n",
      "epoch:0 step:655 [D loss: 0.239936, acc.: 63.28%] [G loss: 0.366640]\n",
      "epoch:0 step:656 [D loss: 0.204041, acc.: 70.31%] [G loss: 0.380832]\n",
      "epoch:0 step:657 [D loss: 0.235622, acc.: 62.50%] [G loss: 0.409972]\n",
      "epoch:0 step:658 [D loss: 0.237191, acc.: 62.50%] [G loss: 0.371661]\n",
      "epoch:0 step:659 [D loss: 0.234718, acc.: 57.03%] [G loss: 0.384606]\n",
      "epoch:0 step:660 [D loss: 0.211194, acc.: 67.19%] [G loss: 0.375312]\n",
      "epoch:0 step:661 [D loss: 0.214010, acc.: 67.19%] [G loss: 0.394382]\n",
      "epoch:0 step:662 [D loss: 0.235992, acc.: 63.28%] [G loss: 0.364504]\n",
      "epoch:0 step:663 [D loss: 0.219076, acc.: 63.28%] [G loss: 0.330537]\n",
      "epoch:0 step:664 [D loss: 0.234169, acc.: 64.06%] [G loss: 0.354454]\n",
      "epoch:0 step:665 [D loss: 0.232980, acc.: 62.50%] [G loss: 0.355525]\n",
      "epoch:0 step:666 [D loss: 0.238922, acc.: 59.38%] [G loss: 0.353592]\n",
      "epoch:0 step:667 [D loss: 0.248004, acc.: 58.59%] [G loss: 0.335347]\n",
      "epoch:0 step:668 [D loss: 0.222101, acc.: 65.62%] [G loss: 0.370717]\n",
      "epoch:0 step:669 [D loss: 0.234344, acc.: 60.16%] [G loss: 0.355247]\n",
      "epoch:0 step:670 [D loss: 0.243954, acc.: 59.38%] [G loss: 0.333998]\n",
      "epoch:0 step:671 [D loss: 0.228436, acc.: 59.38%] [G loss: 0.370958]\n",
      "epoch:0 step:672 [D loss: 0.251525, acc.: 60.94%] [G loss: 0.345905]\n",
      "epoch:0 step:673 [D loss: 0.219035, acc.: 61.72%] [G loss: 0.367827]\n",
      "epoch:0 step:674 [D loss: 0.232890, acc.: 66.41%] [G loss: 0.349732]\n",
      "epoch:0 step:675 [D loss: 0.232212, acc.: 59.38%] [G loss: 0.397301]\n",
      "epoch:0 step:676 [D loss: 0.232198, acc.: 59.38%] [G loss: 0.344578]\n",
      "epoch:0 step:677 [D loss: 0.279212, acc.: 52.34%] [G loss: 0.330232]\n",
      "epoch:0 step:678 [D loss: 0.219178, acc.: 66.41%] [G loss: 0.340079]\n",
      "epoch:0 step:679 [D loss: 0.245971, acc.: 56.25%] [G loss: 0.387946]\n",
      "epoch:0 step:680 [D loss: 0.249781, acc.: 53.12%] [G loss: 0.355149]\n",
      "epoch:0 step:681 [D loss: 0.238862, acc.: 57.03%] [G loss: 0.414754]\n",
      "epoch:0 step:682 [D loss: 0.225631, acc.: 61.72%] [G loss: 0.369030]\n",
      "epoch:0 step:683 [D loss: 0.202743, acc.: 65.62%] [G loss: 0.354408]\n",
      "epoch:0 step:684 [D loss: 0.239107, acc.: 58.59%] [G loss: 0.376673]\n",
      "epoch:0 step:685 [D loss: 0.250654, acc.: 58.59%] [G loss: 0.350386]\n",
      "epoch:0 step:686 [D loss: 0.223499, acc.: 63.28%] [G loss: 0.334427]\n",
      "epoch:0 step:687 [D loss: 0.243538, acc.: 59.38%] [G loss: 0.361127]\n",
      "epoch:0 step:688 [D loss: 0.214697, acc.: 66.41%] [G loss: 0.381902]\n",
      "epoch:0 step:689 [D loss: 0.248264, acc.: 53.91%] [G loss: 0.297210]\n",
      "epoch:0 step:690 [D loss: 0.214924, acc.: 69.53%] [G loss: 0.367701]\n",
      "epoch:0 step:691 [D loss: 0.249447, acc.: 60.16%] [G loss: 0.373249]\n",
      "epoch:0 step:692 [D loss: 0.215713, acc.: 61.72%] [G loss: 0.399571]\n",
      "epoch:0 step:693 [D loss: 0.215986, acc.: 69.53%] [G loss: 0.371812]\n",
      "epoch:0 step:694 [D loss: 0.243310, acc.: 55.47%] [G loss: 0.343253]\n",
      "epoch:0 step:695 [D loss: 0.233892, acc.: 60.94%] [G loss: 0.405068]\n",
      "epoch:0 step:696 [D loss: 0.264475, acc.: 53.12%] [G loss: 0.351100]\n",
      "epoch:0 step:697 [D loss: 0.238384, acc.: 63.28%] [G loss: 0.370060]\n",
      "epoch:0 step:698 [D loss: 0.214791, acc.: 67.97%] [G loss: 0.387130]\n",
      "epoch:0 step:699 [D loss: 0.229140, acc.: 57.81%] [G loss: 0.320221]\n",
      "epoch:0 step:700 [D loss: 0.177013, acc.: 76.56%] [G loss: 0.348640]\n",
      "epoch:0 step:701 [D loss: 0.249548, acc.: 55.47%] [G loss: 0.331628]\n",
      "epoch:0 step:702 [D loss: 0.250116, acc.: 52.34%] [G loss: 0.341207]\n",
      "epoch:0 step:703 [D loss: 0.230692, acc.: 64.84%] [G loss: 0.358658]\n",
      "epoch:0 step:704 [D loss: 0.221240, acc.: 65.62%] [G loss: 0.369934]\n",
      "epoch:0 step:705 [D loss: 0.220161, acc.: 67.19%] [G loss: 0.393937]\n",
      "epoch:0 step:706 [D loss: 0.247069, acc.: 59.38%] [G loss: 0.381222]\n",
      "epoch:0 step:707 [D loss: 0.226975, acc.: 64.84%] [G loss: 0.384830]\n",
      "epoch:0 step:708 [D loss: 0.240485, acc.: 61.72%] [G loss: 0.340858]\n",
      "epoch:0 step:709 [D loss: 0.225516, acc.: 63.28%] [G loss: 0.377670]\n",
      "epoch:0 step:710 [D loss: 0.226538, acc.: 60.94%] [G loss: 0.419252]\n",
      "epoch:0 step:711 [D loss: 0.238914, acc.: 57.81%] [G loss: 0.349965]\n",
      "epoch:0 step:712 [D loss: 0.246835, acc.: 56.25%] [G loss: 0.348994]\n",
      "epoch:0 step:713 [D loss: 0.220575, acc.: 64.06%] [G loss: 0.358625]\n",
      "epoch:0 step:714 [D loss: 0.214154, acc.: 62.50%] [G loss: 0.373252]\n",
      "epoch:0 step:715 [D loss: 0.226133, acc.: 60.94%] [G loss: 0.371298]\n",
      "epoch:0 step:716 [D loss: 0.217980, acc.: 64.84%] [G loss: 0.344616]\n",
      "epoch:0 step:717 [D loss: 0.212610, acc.: 68.75%] [G loss: 0.336767]\n",
      "epoch:0 step:718 [D loss: 0.217906, acc.: 61.72%] [G loss: 0.369919]\n",
      "epoch:0 step:719 [D loss: 0.234053, acc.: 57.81%] [G loss: 0.348581]\n",
      "epoch:0 step:720 [D loss: 0.241513, acc.: 62.50%] [G loss: 0.343273]\n",
      "epoch:0 step:721 [D loss: 0.227260, acc.: 61.72%] [G loss: 0.356697]\n",
      "epoch:0 step:722 [D loss: 0.219654, acc.: 64.06%] [G loss: 0.359631]\n",
      "epoch:0 step:723 [D loss: 0.231390, acc.: 60.94%] [G loss: 0.368500]\n",
      "epoch:0 step:724 [D loss: 0.252138, acc.: 54.69%] [G loss: 0.344266]\n",
      "epoch:0 step:725 [D loss: 0.201932, acc.: 67.97%] [G loss: 0.394767]\n",
      "epoch:0 step:726 [D loss: 0.227783, acc.: 60.94%] [G loss: 0.394536]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0 step:727 [D loss: 0.238562, acc.: 57.03%] [G loss: 0.423662]\n",
      "epoch:0 step:728 [D loss: 0.210949, acc.: 69.53%] [G loss: 0.368432]\n",
      "epoch:0 step:729 [D loss: 0.219785, acc.: 59.38%] [G loss: 0.376140]\n",
      "epoch:0 step:730 [D loss: 0.239705, acc.: 57.81%] [G loss: 0.328329]\n",
      "epoch:0 step:731 [D loss: 0.242838, acc.: 57.81%] [G loss: 0.337342]\n",
      "epoch:0 step:732 [D loss: 0.207488, acc.: 69.53%] [G loss: 0.344612]\n",
      "epoch:0 step:733 [D loss: 0.241851, acc.: 64.06%] [G loss: 0.315882]\n",
      "epoch:0 step:734 [D loss: 0.211942, acc.: 67.19%] [G loss: 0.403987]\n",
      "epoch:0 step:735 [D loss: 0.205409, acc.: 67.19%] [G loss: 0.325855]\n",
      "epoch:0 step:736 [D loss: 0.231591, acc.: 64.06%] [G loss: 0.362940]\n",
      "epoch:0 step:737 [D loss: 0.226246, acc.: 67.19%] [G loss: 0.379275]\n",
      "epoch:0 step:738 [D loss: 0.234282, acc.: 63.28%] [G loss: 0.379785]\n",
      "epoch:0 step:739 [D loss: 0.211658, acc.: 68.75%] [G loss: 0.378236]\n",
      "epoch:0 step:740 [D loss: 0.236738, acc.: 54.69%] [G loss: 0.408560]\n",
      "epoch:0 step:741 [D loss: 0.234435, acc.: 63.28%] [G loss: 0.358430]\n",
      "epoch:0 step:742 [D loss: 0.262398, acc.: 50.78%] [G loss: 0.379646]\n",
      "epoch:0 step:743 [D loss: 0.255752, acc.: 57.03%] [G loss: 0.346782]\n",
      "epoch:0 step:744 [D loss: 0.232433, acc.: 57.03%] [G loss: 0.326269]\n",
      "epoch:0 step:745 [D loss: 0.215977, acc.: 64.06%] [G loss: 0.371948]\n",
      "epoch:0 step:746 [D loss: 0.237056, acc.: 66.41%] [G loss: 0.333403]\n",
      "epoch:0 step:747 [D loss: 0.241943, acc.: 58.59%] [G loss: 0.377850]\n",
      "epoch:0 step:748 [D loss: 0.234460, acc.: 57.81%] [G loss: 0.399627]\n",
      "epoch:0 step:749 [D loss: 0.246938, acc.: 59.38%] [G loss: 0.338622]\n",
      "epoch:0 step:750 [D loss: 0.215357, acc.: 67.97%] [G loss: 0.372259]\n",
      "epoch:0 step:751 [D loss: 0.234472, acc.: 61.72%] [G loss: 0.401621]\n",
      "epoch:0 step:752 [D loss: 0.229698, acc.: 59.38%] [G loss: 0.357016]\n",
      "epoch:0 step:753 [D loss: 0.213718, acc.: 64.84%] [G loss: 0.365705]\n",
      "epoch:0 step:754 [D loss: 0.226374, acc.: 61.72%] [G loss: 0.414444]\n",
      "epoch:0 step:755 [D loss: 0.206436, acc.: 65.62%] [G loss: 0.375899]\n",
      "epoch:0 step:756 [D loss: 0.218197, acc.: 66.41%] [G loss: 0.346462]\n",
      "epoch:0 step:757 [D loss: 0.237540, acc.: 58.59%] [G loss: 0.373533]\n",
      "epoch:0 step:758 [D loss: 0.258128, acc.: 52.34%] [G loss: 0.358221]\n",
      "epoch:0 step:759 [D loss: 0.212261, acc.: 68.75%] [G loss: 0.340254]\n",
      "epoch:0 step:760 [D loss: 0.209718, acc.: 70.31%] [G loss: 0.382267]\n",
      "epoch:0 step:761 [D loss: 0.256506, acc.: 53.91%] [G loss: 0.399295]\n",
      "epoch:0 step:762 [D loss: 0.241791, acc.: 57.03%] [G loss: 0.317737]\n",
      "epoch:0 step:763 [D loss: 0.226149, acc.: 67.19%] [G loss: 0.389163]\n",
      "epoch:0 step:764 [D loss: 0.247679, acc.: 57.03%] [G loss: 0.347703]\n",
      "epoch:0 step:765 [D loss: 0.231524, acc.: 63.28%] [G loss: 0.419099]\n",
      "epoch:0 step:766 [D loss: 0.217425, acc.: 67.19%] [G loss: 0.342617]\n",
      "epoch:0 step:767 [D loss: 0.241564, acc.: 60.94%] [G loss: 0.381220]\n",
      "epoch:0 step:768 [D loss: 0.240691, acc.: 55.47%] [G loss: 0.377892]\n",
      "epoch:0 step:769 [D loss: 0.257444, acc.: 50.78%] [G loss: 0.351044]\n",
      "epoch:0 step:770 [D loss: 0.229138, acc.: 64.06%] [G loss: 0.373801]\n",
      "epoch:0 step:771 [D loss: 0.212207, acc.: 67.19%] [G loss: 0.343557]\n",
      "epoch:0 step:772 [D loss: 0.229537, acc.: 58.59%] [G loss: 0.369026]\n",
      "epoch:0 step:773 [D loss: 0.232667, acc.: 60.94%] [G loss: 0.376008]\n",
      "epoch:0 step:774 [D loss: 0.210623, acc.: 71.09%] [G loss: 0.409098]\n",
      "epoch:0 step:775 [D loss: 0.227593, acc.: 58.59%] [G loss: 0.389101]\n",
      "epoch:0 step:776 [D loss: 0.207321, acc.: 67.97%] [G loss: 0.395420]\n",
      "epoch:0 step:777 [D loss: 0.230452, acc.: 62.50%] [G loss: 0.340274]\n",
      "epoch:0 step:778 [D loss: 0.226553, acc.: 67.19%] [G loss: 0.361693]\n",
      "epoch:0 step:779 [D loss: 0.213561, acc.: 64.84%] [G loss: 0.363853]\n",
      "epoch:0 step:780 [D loss: 0.243905, acc.: 57.03%] [G loss: 0.334001]\n",
      "epoch:0 step:781 [D loss: 0.228002, acc.: 60.94%] [G loss: 0.342090]\n",
      "epoch:0 step:782 [D loss: 0.253538, acc.: 57.03%] [G loss: 0.389000]\n",
      "epoch:0 step:783 [D loss: 0.237395, acc.: 62.50%] [G loss: 0.393196]\n",
      "epoch:0 step:784 [D loss: 0.233048, acc.: 63.28%] [G loss: 0.311749]\n",
      "epoch:0 step:785 [D loss: 0.224056, acc.: 60.16%] [G loss: 0.339366]\n",
      "epoch:0 step:786 [D loss: 0.212417, acc.: 66.41%] [G loss: 0.374742]\n",
      "epoch:0 step:787 [D loss: 0.213975, acc.: 67.97%] [G loss: 0.395665]\n",
      "epoch:0 step:788 [D loss: 0.236079, acc.: 61.72%] [G loss: 0.393546]\n",
      "epoch:0 step:789 [D loss: 0.253359, acc.: 55.47%] [G loss: 0.373033]\n",
      "epoch:0 step:790 [D loss: 0.211257, acc.: 67.97%] [G loss: 0.362378]\n",
      "epoch:0 step:791 [D loss: 0.226163, acc.: 60.16%] [G loss: 0.364898]\n",
      "epoch:0 step:792 [D loss: 0.227335, acc.: 61.72%] [G loss: 0.386936]\n",
      "epoch:0 step:793 [D loss: 0.259035, acc.: 56.25%] [G loss: 0.355486]\n",
      "epoch:0 step:794 [D loss: 0.222675, acc.: 64.84%] [G loss: 0.341865]\n",
      "epoch:0 step:795 [D loss: 0.264468, acc.: 56.25%] [G loss: 0.390417]\n",
      "epoch:0 step:796 [D loss: 0.246534, acc.: 57.03%] [G loss: 0.341952]\n",
      "epoch:0 step:797 [D loss: 0.245971, acc.: 59.38%] [G loss: 0.319776]\n",
      "epoch:0 step:798 [D loss: 0.226924, acc.: 61.72%] [G loss: 0.382799]\n",
      "epoch:0 step:799 [D loss: 0.201380, acc.: 71.88%] [G loss: 0.332048]\n",
      "epoch:0 step:800 [D loss: 0.251869, acc.: 53.91%] [G loss: 0.362681]\n",
      "epoch:0 step:801 [D loss: 0.228795, acc.: 66.41%] [G loss: 0.305694]\n",
      "epoch:0 step:802 [D loss: 0.251260, acc.: 57.81%] [G loss: 0.341888]\n",
      "epoch:0 step:803 [D loss: 0.254912, acc.: 56.25%] [G loss: 0.364420]\n",
      "epoch:0 step:804 [D loss: 0.203983, acc.: 67.19%] [G loss: 0.409968]\n",
      "epoch:0 step:805 [D loss: 0.254725, acc.: 54.69%] [G loss: 0.352716]\n",
      "epoch:0 step:806 [D loss: 0.227708, acc.: 59.38%] [G loss: 0.369260]\n",
      "epoch:0 step:807 [D loss: 0.235406, acc.: 64.84%] [G loss: 0.380088]\n",
      "epoch:0 step:808 [D loss: 0.228689, acc.: 62.50%] [G loss: 0.377145]\n",
      "epoch:0 step:809 [D loss: 0.210696, acc.: 67.19%] [G loss: 0.371203]\n",
      "epoch:0 step:810 [D loss: 0.212229, acc.: 67.19%] [G loss: 0.327400]\n",
      "epoch:0 step:811 [D loss: 0.244631, acc.: 57.03%] [G loss: 0.354361]\n",
      "epoch:0 step:812 [D loss: 0.209956, acc.: 65.62%] [G loss: 0.381806]\n",
      "epoch:0 step:813 [D loss: 0.240324, acc.: 60.16%] [G loss: 0.393481]\n",
      "epoch:0 step:814 [D loss: 0.223962, acc.: 64.84%] [G loss: 0.412773]\n",
      "epoch:0 step:815 [D loss: 0.236739, acc.: 59.38%] [G loss: 0.399613]\n",
      "epoch:0 step:816 [D loss: 0.213784, acc.: 64.84%] [G loss: 0.369097]\n",
      "epoch:0 step:817 [D loss: 0.249625, acc.: 54.69%] [G loss: 0.366168]\n",
      "epoch:0 step:818 [D loss: 0.214881, acc.: 66.41%] [G loss: 0.335535]\n",
      "epoch:0 step:819 [D loss: 0.235589, acc.: 61.72%] [G loss: 0.353900]\n",
      "epoch:0 step:820 [D loss: 0.221699, acc.: 67.19%] [G loss: 0.388043]\n",
      "epoch:0 step:821 [D loss: 0.209134, acc.: 68.75%] [G loss: 0.366427]\n",
      "epoch:0 step:822 [D loss: 0.209445, acc.: 71.88%] [G loss: 0.422577]\n",
      "epoch:0 step:823 [D loss: 0.248751, acc.: 59.38%] [G loss: 0.338100]\n",
      "epoch:0 step:824 [D loss: 0.220095, acc.: 64.06%] [G loss: 0.324773]\n",
      "epoch:0 step:825 [D loss: 0.241973, acc.: 60.16%] [G loss: 0.349213]\n",
      "epoch:0 step:826 [D loss: 0.238823, acc.: 64.84%] [G loss: 0.304393]\n",
      "epoch:0 step:827 [D loss: 0.214401, acc.: 63.28%] [G loss: 0.383158]\n",
      "epoch:0 step:828 [D loss: 0.254309, acc.: 59.38%] [G loss: 0.310972]\n",
      "epoch:0 step:829 [D loss: 0.207607, acc.: 64.06%] [G loss: 0.364413]\n",
      "epoch:0 step:830 [D loss: 0.259187, acc.: 51.56%] [G loss: 0.318007]\n",
      "epoch:0 step:831 [D loss: 0.253550, acc.: 53.12%] [G loss: 0.327270]\n",
      "epoch:0 step:832 [D loss: 0.225541, acc.: 64.06%] [G loss: 0.337957]\n",
      "epoch:0 step:833 [D loss: 0.215031, acc.: 62.50%] [G loss: 0.364393]\n",
      "epoch:0 step:834 [D loss: 0.270815, acc.: 51.56%] [G loss: 0.335010]\n",
      "epoch:0 step:835 [D loss: 0.240350, acc.: 60.16%] [G loss: 0.317127]\n",
      "epoch:0 step:836 [D loss: 0.218250, acc.: 64.84%] [G loss: 0.376000]\n",
      "epoch:0 step:837 [D loss: 0.233460, acc.: 61.72%] [G loss: 0.369890]\n",
      "epoch:0 step:838 [D loss: 0.249975, acc.: 57.03%] [G loss: 0.350309]\n",
      "epoch:0 step:839 [D loss: 0.221875, acc.: 62.50%] [G loss: 0.336519]\n",
      "epoch:0 step:840 [D loss: 0.213248, acc.: 66.41%] [G loss: 0.392541]\n",
      "epoch:0 step:841 [D loss: 0.222121, acc.: 67.19%] [G loss: 0.337213]\n",
      "epoch:0 step:842 [D loss: 0.232862, acc.: 57.81%] [G loss: 0.382880]\n",
      "epoch:0 step:843 [D loss: 0.239268, acc.: 58.59%] [G loss: 0.362652]\n",
      "epoch:0 step:844 [D loss: 0.236868, acc.: 59.38%] [G loss: 0.370386]\n",
      "epoch:0 step:845 [D loss: 0.238072, acc.: 61.72%] [G loss: 0.399019]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0 step:846 [D loss: 0.211375, acc.: 69.53%] [G loss: 0.394014]\n",
      "epoch:0 step:847 [D loss: 0.217661, acc.: 64.84%] [G loss: 0.381273]\n",
      "epoch:0 step:848 [D loss: 0.216317, acc.: 67.19%] [G loss: 0.353377]\n",
      "epoch:0 step:849 [D loss: 0.227018, acc.: 60.94%] [G loss: 0.399767]\n",
      "epoch:0 step:850 [D loss: 0.205260, acc.: 71.09%] [G loss: 0.329972]\n",
      "epoch:0 step:851 [D loss: 0.216448, acc.: 70.31%] [G loss: 0.358473]\n",
      "epoch:0 step:852 [D loss: 0.222130, acc.: 65.62%] [G loss: 0.346306]\n",
      "epoch:0 step:853 [D loss: 0.233038, acc.: 62.50%] [G loss: 0.373692]\n",
      "epoch:0 step:854 [D loss: 0.189911, acc.: 71.09%] [G loss: 0.390324]\n",
      "epoch:0 step:855 [D loss: 0.229164, acc.: 65.62%] [G loss: 0.415994]\n",
      "epoch:0 step:856 [D loss: 0.239132, acc.: 63.28%] [G loss: 0.365917]\n",
      "epoch:0 step:857 [D loss: 0.272359, acc.: 49.22%] [G loss: 0.349001]\n",
      "epoch:0 step:858 [D loss: 0.237230, acc.: 62.50%] [G loss: 0.387237]\n",
      "epoch:0 step:859 [D loss: 0.209725, acc.: 66.41%] [G loss: 0.400419]\n",
      "epoch:0 step:860 [D loss: 0.235941, acc.: 57.81%] [G loss: 0.384682]\n",
      "epoch:0 step:861 [D loss: 0.216365, acc.: 64.06%] [G loss: 0.348060]\n",
      "epoch:0 step:862 [D loss: 0.196307, acc.: 70.31%] [G loss: 0.383023]\n",
      "epoch:0 step:863 [D loss: 0.227575, acc.: 64.06%] [G loss: 0.355927]\n",
      "epoch:0 step:864 [D loss: 0.245317, acc.: 57.03%] [G loss: 0.376334]\n",
      "epoch:0 step:865 [D loss: 0.246576, acc.: 56.25%] [G loss: 0.363280]\n",
      "epoch:0 step:866 [D loss: 0.230140, acc.: 60.94%] [G loss: 0.340698]\n",
      "epoch:0 step:867 [D loss: 0.234497, acc.: 57.81%] [G loss: 0.340357]\n",
      "epoch:0 step:868 [D loss: 0.230958, acc.: 64.06%] [G loss: 0.396547]\n",
      "epoch:0 step:869 [D loss: 0.227081, acc.: 64.84%] [G loss: 0.403393]\n",
      "epoch:0 step:870 [D loss: 0.230172, acc.: 63.28%] [G loss: 0.377957]\n",
      "epoch:0 step:871 [D loss: 0.228311, acc.: 57.81%] [G loss: 0.371771]\n",
      "epoch:0 step:872 [D loss: 0.236029, acc.: 57.81%] [G loss: 0.313411]\n",
      "epoch:0 step:873 [D loss: 0.219671, acc.: 64.06%] [G loss: 0.387758]\n",
      "epoch:0 step:874 [D loss: 0.241048, acc.: 60.94%] [G loss: 0.377835]\n",
      "epoch:0 step:875 [D loss: 0.226766, acc.: 59.38%] [G loss: 0.343188]\n",
      "epoch:0 step:876 [D loss: 0.238530, acc.: 57.81%] [G loss: 0.374874]\n",
      "epoch:0 step:877 [D loss: 0.218583, acc.: 65.62%] [G loss: 0.355872]\n",
      "epoch:0 step:878 [D loss: 0.216605, acc.: 69.53%] [G loss: 0.387309]\n",
      "epoch:0 step:879 [D loss: 0.231653, acc.: 60.94%] [G loss: 0.382285]\n",
      "epoch:0 step:880 [D loss: 0.227821, acc.: 64.06%] [G loss: 0.361402]\n",
      "epoch:0 step:881 [D loss: 0.245385, acc.: 59.38%] [G loss: 0.350458]\n",
      "epoch:0 step:882 [D loss: 0.220206, acc.: 63.28%] [G loss: 0.354303]\n",
      "epoch:0 step:883 [D loss: 0.236379, acc.: 65.62%] [G loss: 0.352413]\n",
      "epoch:0 step:884 [D loss: 0.221190, acc.: 61.72%] [G loss: 0.370749]\n",
      "epoch:0 step:885 [D loss: 0.235550, acc.: 70.31%] [G loss: 0.363613]\n",
      "epoch:0 step:886 [D loss: 0.223386, acc.: 59.38%] [G loss: 0.358082]\n",
      "epoch:0 step:887 [D loss: 0.219186, acc.: 62.50%] [G loss: 0.352991]\n",
      "epoch:0 step:888 [D loss: 0.231072, acc.: 61.72%] [G loss: 0.375578]\n",
      "epoch:0 step:889 [D loss: 0.218922, acc.: 60.94%] [G loss: 0.394989]\n",
      "epoch:0 step:890 [D loss: 0.251143, acc.: 52.34%] [G loss: 0.359160]\n",
      "epoch:0 step:891 [D loss: 0.214905, acc.: 70.31%] [G loss: 0.378303]\n",
      "epoch:0 step:892 [D loss: 0.227332, acc.: 64.84%] [G loss: 0.351818]\n",
      "epoch:0 step:893 [D loss: 0.228571, acc.: 64.84%] [G loss: 0.395258]\n",
      "epoch:0 step:894 [D loss: 0.218383, acc.: 64.06%] [G loss: 0.419283]\n",
      "epoch:0 step:895 [D loss: 0.222724, acc.: 66.41%] [G loss: 0.361760]\n",
      "epoch:0 step:896 [D loss: 0.224448, acc.: 64.06%] [G loss: 0.378307]\n",
      "epoch:0 step:897 [D loss: 0.230261, acc.: 62.50%] [G loss: 0.370756]\n",
      "epoch:0 step:898 [D loss: 0.238032, acc.: 58.59%] [G loss: 0.311112]\n",
      "epoch:0 step:899 [D loss: 0.264133, acc.: 48.44%] [G loss: 0.347660]\n",
      "epoch:0 step:900 [D loss: 0.257375, acc.: 58.59%] [G loss: 0.282624]\n",
      "epoch:0 step:901 [D loss: 0.207280, acc.: 67.19%] [G loss: 0.328885]\n",
      "epoch:0 step:902 [D loss: 0.206085, acc.: 71.09%] [G loss: 0.375381]\n",
      "epoch:0 step:903 [D loss: 0.224343, acc.: 64.06%] [G loss: 0.351116]\n",
      "epoch:0 step:904 [D loss: 0.229540, acc.: 64.06%] [G loss: 0.397389]\n",
      "epoch:0 step:905 [D loss: 0.217020, acc.: 65.62%] [G loss: 0.392605]\n",
      "epoch:0 step:906 [D loss: 0.219309, acc.: 67.19%] [G loss: 0.368413]\n",
      "epoch:0 step:907 [D loss: 0.222489, acc.: 67.97%] [G loss: 0.329893]\n",
      "epoch:0 step:908 [D loss: 0.244153, acc.: 60.16%] [G loss: 0.398777]\n",
      "epoch:0 step:909 [D loss: 0.223888, acc.: 65.62%] [G loss: 0.344712]\n",
      "epoch:0 step:910 [D loss: 0.215696, acc.: 60.94%] [G loss: 0.437331]\n",
      "epoch:0 step:911 [D loss: 0.256945, acc.: 56.25%] [G loss: 0.338127]\n",
      "epoch:0 step:912 [D loss: 0.242445, acc.: 57.03%] [G loss: 0.318791]\n",
      "epoch:0 step:913 [D loss: 0.251273, acc.: 60.94%] [G loss: 0.333368]\n",
      "epoch:0 step:914 [D loss: 0.236992, acc.: 55.47%] [G loss: 0.398411]\n",
      "epoch:0 step:915 [D loss: 0.226026, acc.: 63.28%] [G loss: 0.362309]\n",
      "epoch:0 step:916 [D loss: 0.208265, acc.: 66.41%] [G loss: 0.353554]\n",
      "epoch:0 step:917 [D loss: 0.263499, acc.: 54.69%] [G loss: 0.359857]\n",
      "epoch:0 step:918 [D loss: 0.205720, acc.: 74.22%] [G loss: 0.393371]\n",
      "epoch:0 step:919 [D loss: 0.226643, acc.: 64.06%] [G loss: 0.320930]\n",
      "epoch:0 step:920 [D loss: 0.235038, acc.: 60.16%] [G loss: 0.372334]\n",
      "epoch:0 step:921 [D loss: 0.224778, acc.: 66.41%] [G loss: 0.380544]\n",
      "epoch:0 step:922 [D loss: 0.237085, acc.: 63.28%] [G loss: 0.358133]\n",
      "epoch:0 step:923 [D loss: 0.244324, acc.: 64.06%] [G loss: 0.319150]\n",
      "epoch:0 step:924 [D loss: 0.248583, acc.: 59.38%] [G loss: 0.373156]\n",
      "epoch:0 step:925 [D loss: 0.240030, acc.: 57.81%] [G loss: 0.327520]\n",
      "epoch:0 step:926 [D loss: 0.207160, acc.: 71.09%] [G loss: 0.345679]\n",
      "epoch:0 step:927 [D loss: 0.240315, acc.: 60.16%] [G loss: 0.373116]\n",
      "epoch:0 step:928 [D loss: 0.199528, acc.: 66.41%] [G loss: 0.409438]\n",
      "epoch:0 step:929 [D loss: 0.216953, acc.: 65.62%] [G loss: 0.401051]\n",
      "epoch:0 step:930 [D loss: 0.240569, acc.: 58.59%] [G loss: 0.365104]\n",
      "epoch:0 step:931 [D loss: 0.225868, acc.: 63.28%] [G loss: 0.364920]\n",
      "epoch:0 step:932 [D loss: 0.254087, acc.: 54.69%] [G loss: 0.375469]\n",
      "epoch:0 step:933 [D loss: 0.200746, acc.: 65.62%] [G loss: 0.373506]\n",
      "epoch:0 step:934 [D loss: 0.232537, acc.: 57.81%] [G loss: 0.402900]\n",
      "epoch:0 step:935 [D loss: 0.251576, acc.: 56.25%] [G loss: 0.327303]\n",
      "epoch:0 step:936 [D loss: 0.231135, acc.: 62.50%] [G loss: 0.410378]\n",
      "epoch:0 step:937 [D loss: 0.217910, acc.: 64.84%] [G loss: 0.392952]\n",
      "epoch:1 step:938 [D loss: 0.224700, acc.: 64.06%] [G loss: 0.358431]\n",
      "epoch:1 step:939 [D loss: 0.256910, acc.: 57.03%] [G loss: 0.329211]\n",
      "epoch:1 step:940 [D loss: 0.243191, acc.: 59.38%] [G loss: 0.372467]\n",
      "epoch:1 step:941 [D loss: 0.204713, acc.: 66.41%] [G loss: 0.369633]\n",
      "epoch:1 step:942 [D loss: 0.225288, acc.: 59.38%] [G loss: 0.375696]\n",
      "epoch:1 step:943 [D loss: 0.227204, acc.: 60.94%] [G loss: 0.326906]\n",
      "epoch:1 step:944 [D loss: 0.218043, acc.: 64.84%] [G loss: 0.391413]\n",
      "epoch:1 step:945 [D loss: 0.237861, acc.: 61.72%] [G loss: 0.389548]\n",
      "epoch:1 step:946 [D loss: 0.220387, acc.: 64.06%] [G loss: 0.375412]\n",
      "epoch:1 step:947 [D loss: 0.218884, acc.: 63.28%] [G loss: 0.346750]\n",
      "epoch:1 step:948 [D loss: 0.221514, acc.: 64.84%] [G loss: 0.392707]\n",
      "epoch:1 step:949 [D loss: 0.214438, acc.: 65.62%] [G loss: 0.361385]\n",
      "epoch:1 step:950 [D loss: 0.214087, acc.: 62.50%] [G loss: 0.381636]\n",
      "epoch:1 step:951 [D loss: 0.205702, acc.: 64.84%] [G loss: 0.336401]\n",
      "epoch:1 step:952 [D loss: 0.223586, acc.: 60.94%] [G loss: 0.381890]\n",
      "epoch:1 step:953 [D loss: 0.201332, acc.: 71.88%] [G loss: 0.352800]\n",
      "epoch:1 step:954 [D loss: 0.229604, acc.: 59.38%] [G loss: 0.379079]\n",
      "epoch:1 step:955 [D loss: 0.246644, acc.: 58.59%] [G loss: 0.404495]\n",
      "epoch:1 step:956 [D loss: 0.224646, acc.: 66.41%] [G loss: 0.420570]\n",
      "epoch:1 step:957 [D loss: 0.246137, acc.: 60.16%] [G loss: 0.364151]\n",
      "epoch:1 step:958 [D loss: 0.240789, acc.: 59.38%] [G loss: 0.323497]\n",
      "epoch:1 step:959 [D loss: 0.205283, acc.: 65.62%] [G loss: 0.372933]\n",
      "epoch:1 step:960 [D loss: 0.230882, acc.: 63.28%] [G loss: 0.340484]\n",
      "epoch:1 step:961 [D loss: 0.217055, acc.: 71.09%] [G loss: 0.351368]\n",
      "epoch:1 step:962 [D loss: 0.208180, acc.: 62.50%] [G loss: 0.390606]\n",
      "epoch:1 step:963 [D loss: 0.224262, acc.: 65.62%] [G loss: 0.397071]\n",
      "epoch:1 step:964 [D loss: 0.243836, acc.: 57.03%] [G loss: 0.386329]\n",
      "epoch:1 step:965 [D loss: 0.213533, acc.: 64.06%] [G loss: 0.378742]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:1 step:966 [D loss: 0.223576, acc.: 64.06%] [G loss: 0.367213]\n",
      "epoch:1 step:967 [D loss: 0.226610, acc.: 60.16%] [G loss: 0.359723]\n",
      "epoch:1 step:968 [D loss: 0.238514, acc.: 58.59%] [G loss: 0.366591]\n",
      "epoch:1 step:969 [D loss: 0.203919, acc.: 72.66%] [G loss: 0.387200]\n",
      "epoch:1 step:970 [D loss: 0.232631, acc.: 66.41%] [G loss: 0.342054]\n",
      "epoch:1 step:971 [D loss: 0.222219, acc.: 64.06%] [G loss: 0.366345]\n",
      "epoch:1 step:972 [D loss: 0.221948, acc.: 64.84%] [G loss: 0.351035]\n",
      "epoch:1 step:973 [D loss: 0.218641, acc.: 64.84%] [G loss: 0.379654]\n",
      "epoch:1 step:974 [D loss: 0.197500, acc.: 69.53%] [G loss: 0.393814]\n",
      "epoch:1 step:975 [D loss: 0.254241, acc.: 52.34%] [G loss: 0.371281]\n",
      "epoch:1 step:976 [D loss: 0.233975, acc.: 60.94%] [G loss: 0.416460]\n",
      "epoch:1 step:977 [D loss: 0.237703, acc.: 60.16%] [G loss: 0.400873]\n",
      "epoch:1 step:978 [D loss: 0.224127, acc.: 67.19%] [G loss: 0.372016]\n",
      "epoch:1 step:979 [D loss: 0.206447, acc.: 69.53%] [G loss: 0.391703]\n",
      "epoch:1 step:980 [D loss: 0.225442, acc.: 62.50%] [G loss: 0.413569]\n",
      "epoch:1 step:981 [D loss: 0.245081, acc.: 61.72%] [G loss: 0.380896]\n",
      "epoch:1 step:982 [D loss: 0.202265, acc.: 67.19%] [G loss: 0.376480]\n",
      "epoch:1 step:983 [D loss: 0.226287, acc.: 64.06%] [G loss: 0.348891]\n",
      "epoch:1 step:984 [D loss: 0.248539, acc.: 58.59%] [G loss: 0.354510]\n",
      "epoch:1 step:985 [D loss: 0.210877, acc.: 64.84%] [G loss: 0.353817]\n",
      "epoch:1 step:986 [D loss: 0.233556, acc.: 58.59%] [G loss: 0.388456]\n",
      "epoch:1 step:987 [D loss: 0.228316, acc.: 64.06%] [G loss: 0.382156]\n",
      "epoch:1 step:988 [D loss: 0.192717, acc.: 72.66%] [G loss: 0.344128]\n",
      "epoch:1 step:989 [D loss: 0.231896, acc.: 61.72%] [G loss: 0.404399]\n",
      "epoch:1 step:990 [D loss: 0.264056, acc.: 55.47%] [G loss: 0.377777]\n",
      "epoch:1 step:991 [D loss: 0.242335, acc.: 57.81%] [G loss: 0.391454]\n",
      "epoch:1 step:992 [D loss: 0.230662, acc.: 64.06%] [G loss: 0.409780]\n",
      "epoch:1 step:993 [D loss: 0.231010, acc.: 60.16%] [G loss: 0.358553]\n",
      "epoch:1 step:994 [D loss: 0.219494, acc.: 68.75%] [G loss: 0.372475]\n",
      "epoch:1 step:995 [D loss: 0.220979, acc.: 64.06%] [G loss: 0.384126]\n",
      "epoch:1 step:996 [D loss: 0.230200, acc.: 57.81%] [G loss: 0.352082]\n",
      "epoch:1 step:997 [D loss: 0.218955, acc.: 62.50%] [G loss: 0.417288]\n",
      "epoch:1 step:998 [D loss: 0.227649, acc.: 68.75%] [G loss: 0.374352]\n",
      "epoch:1 step:999 [D loss: 0.228108, acc.: 61.72%] [G loss: 0.381145]\n",
      "epoch:1 step:1000 [D loss: 0.254739, acc.: 55.47%] [G loss: 0.365780]\n",
      "epoch:1 step:1001 [D loss: 0.213751, acc.: 66.41%] [G loss: 0.373952]\n",
      "epoch:1 step:1002 [D loss: 0.210324, acc.: 63.28%] [G loss: 0.366331]\n",
      "epoch:1 step:1003 [D loss: 0.224043, acc.: 60.16%] [G loss: 0.373813]\n",
      "epoch:1 step:1004 [D loss: 0.209362, acc.: 69.53%] [G loss: 0.373218]\n",
      "epoch:1 step:1005 [D loss: 0.235285, acc.: 58.59%] [G loss: 0.384896]\n",
      "epoch:1 step:1006 [D loss: 0.206036, acc.: 67.97%] [G loss: 0.362519]\n",
      "epoch:1 step:1007 [D loss: 0.248694, acc.: 59.38%] [G loss: 0.379838]\n",
      "epoch:1 step:1008 [D loss: 0.242943, acc.: 59.38%] [G loss: 0.375406]\n",
      "epoch:1 step:1009 [D loss: 0.241586, acc.: 61.72%] [G loss: 0.350509]\n",
      "epoch:1 step:1010 [D loss: 0.234964, acc.: 58.59%] [G loss: 0.383713]\n",
      "epoch:1 step:1011 [D loss: 0.239863, acc.: 56.25%] [G loss: 0.361491]\n",
      "epoch:1 step:1012 [D loss: 0.214981, acc.: 65.62%] [G loss: 0.346122]\n",
      "epoch:1 step:1013 [D loss: 0.219683, acc.: 64.84%] [G loss: 0.409508]\n",
      "epoch:1 step:1014 [D loss: 0.252405, acc.: 57.81%] [G loss: 0.335997]\n",
      "epoch:1 step:1015 [D loss: 0.225583, acc.: 64.84%] [G loss: 0.373315]\n",
      "epoch:1 step:1016 [D loss: 0.250207, acc.: 53.91%] [G loss: 0.402408]\n",
      "epoch:1 step:1017 [D loss: 0.239328, acc.: 59.38%] [G loss: 0.360975]\n",
      "epoch:1 step:1018 [D loss: 0.232042, acc.: 59.38%] [G loss: 0.376995]\n",
      "epoch:1 step:1019 [D loss: 0.219112, acc.: 67.19%] [G loss: 0.380746]\n",
      "epoch:1 step:1020 [D loss: 0.231985, acc.: 57.03%] [G loss: 0.343117]\n",
      "epoch:1 step:1021 [D loss: 0.234872, acc.: 60.94%] [G loss: 0.315372]\n",
      "epoch:1 step:1022 [D loss: 0.206834, acc.: 69.53%] [G loss: 0.359033]\n",
      "epoch:1 step:1023 [D loss: 0.206701, acc.: 69.53%] [G loss: 0.401090]\n",
      "epoch:1 step:1024 [D loss: 0.219431, acc.: 65.62%] [G loss: 0.345330]\n",
      "epoch:1 step:1025 [D loss: 0.244681, acc.: 57.03%] [G loss: 0.369299]\n",
      "epoch:1 step:1026 [D loss: 0.245648, acc.: 55.47%] [G loss: 0.372194]\n",
      "epoch:1 step:1027 [D loss: 0.235720, acc.: 60.94%] [G loss: 0.332161]\n",
      "epoch:1 step:1028 [D loss: 0.238858, acc.: 55.47%] [G loss: 0.357823]\n",
      "epoch:1 step:1029 [D loss: 0.200417, acc.: 67.97%] [G loss: 0.395918]\n",
      "epoch:1 step:1030 [D loss: 0.237907, acc.: 61.72%] [G loss: 0.330208]\n",
      "epoch:1 step:1031 [D loss: 0.234076, acc.: 63.28%] [G loss: 0.349079]\n",
      "epoch:1 step:1032 [D loss: 0.198673, acc.: 67.97%] [G loss: 0.387997]\n",
      "epoch:1 step:1033 [D loss: 0.226187, acc.: 63.28%] [G loss: 0.391659]\n",
      "epoch:1 step:1034 [D loss: 0.203407, acc.: 68.75%] [G loss: 0.360684]\n",
      "epoch:1 step:1035 [D loss: 0.237288, acc.: 60.16%] [G loss: 0.407993]\n",
      "epoch:1 step:1036 [D loss: 0.215440, acc.: 66.41%] [G loss: 0.397115]\n",
      "epoch:1 step:1037 [D loss: 0.232226, acc.: 57.81%] [G loss: 0.376309]\n",
      "epoch:1 step:1038 [D loss: 0.239344, acc.: 58.59%] [G loss: 0.362036]\n",
      "epoch:1 step:1039 [D loss: 0.218001, acc.: 66.41%] [G loss: 0.383283]\n",
      "epoch:1 step:1040 [D loss: 0.221189, acc.: 62.50%] [G loss: 0.320162]\n",
      "epoch:1 step:1041 [D loss: 0.177516, acc.: 77.34%] [G loss: 0.386933]\n",
      "epoch:1 step:1042 [D loss: 0.200745, acc.: 70.31%] [G loss: 0.393203]\n",
      "epoch:1 step:1043 [D loss: 0.247459, acc.: 60.94%] [G loss: 0.342156]\n",
      "epoch:1 step:1044 [D loss: 0.226632, acc.: 65.62%] [G loss: 0.375580]\n",
      "epoch:1 step:1045 [D loss: 0.195958, acc.: 72.66%] [G loss: 0.397846]\n",
      "epoch:1 step:1046 [D loss: 0.231534, acc.: 61.72%] [G loss: 0.384643]\n",
      "epoch:1 step:1047 [D loss: 0.245687, acc.: 58.59%] [G loss: 0.352433]\n",
      "epoch:1 step:1048 [D loss: 0.218506, acc.: 68.75%] [G loss: 0.370547]\n",
      "epoch:1 step:1049 [D loss: 0.221062, acc.: 66.41%] [G loss: 0.368864]\n",
      "epoch:1 step:1050 [D loss: 0.230341, acc.: 62.50%] [G loss: 0.392767]\n",
      "epoch:1 step:1051 [D loss: 0.215914, acc.: 63.28%] [G loss: 0.364274]\n",
      "epoch:1 step:1052 [D loss: 0.238544, acc.: 57.81%] [G loss: 0.354941]\n",
      "epoch:1 step:1053 [D loss: 0.232075, acc.: 59.38%] [G loss: 0.375201]\n",
      "epoch:1 step:1054 [D loss: 0.230308, acc.: 64.84%] [G loss: 0.347408]\n",
      "epoch:1 step:1055 [D loss: 0.232918, acc.: 61.72%] [G loss: 0.370880]\n",
      "epoch:1 step:1056 [D loss: 0.231245, acc.: 61.72%] [G loss: 0.401585]\n",
      "epoch:1 step:1057 [D loss: 0.222201, acc.: 65.62%] [G loss: 0.353076]\n",
      "epoch:1 step:1058 [D loss: 0.259340, acc.: 55.47%] [G loss: 0.364496]\n",
      "epoch:1 step:1059 [D loss: 0.240854, acc.: 56.25%] [G loss: 0.345176]\n",
      "epoch:1 step:1060 [D loss: 0.220598, acc.: 60.16%] [G loss: 0.326457]\n",
      "epoch:1 step:1061 [D loss: 0.227516, acc.: 58.59%] [G loss: 0.358682]\n",
      "epoch:1 step:1062 [D loss: 0.218847, acc.: 67.97%] [G loss: 0.383611]\n",
      "epoch:1 step:1063 [D loss: 0.256850, acc.: 50.78%] [G loss: 0.391969]\n",
      "epoch:1 step:1064 [D loss: 0.230760, acc.: 61.72%] [G loss: 0.352911]\n",
      "epoch:1 step:1065 [D loss: 0.240099, acc.: 60.94%] [G loss: 0.376810]\n",
      "epoch:1 step:1066 [D loss: 0.241275, acc.: 60.94%] [G loss: 0.379012]\n",
      "epoch:1 step:1067 [D loss: 0.218048, acc.: 63.28%] [G loss: 0.388516]\n",
      "epoch:1 step:1068 [D loss: 0.271646, acc.: 50.78%] [G loss: 0.355716]\n",
      "epoch:1 step:1069 [D loss: 0.238606, acc.: 58.59%] [G loss: 0.338715]\n",
      "epoch:1 step:1070 [D loss: 0.231219, acc.: 61.72%] [G loss: 0.390298]\n",
      "epoch:1 step:1071 [D loss: 0.223404, acc.: 62.50%] [G loss: 0.372106]\n",
      "epoch:1 step:1072 [D loss: 0.255137, acc.: 54.69%] [G loss: 0.378298]\n",
      "epoch:1 step:1073 [D loss: 0.236287, acc.: 56.25%] [G loss: 0.322172]\n",
      "epoch:1 step:1074 [D loss: 0.221222, acc.: 64.84%] [G loss: 0.370958]\n",
      "epoch:1 step:1075 [D loss: 0.220866, acc.: 64.06%] [G loss: 0.347660]\n",
      "epoch:1 step:1076 [D loss: 0.229227, acc.: 61.72%] [G loss: 0.393967]\n",
      "epoch:1 step:1077 [D loss: 0.232426, acc.: 67.97%] [G loss: 0.354137]\n",
      "epoch:1 step:1078 [D loss: 0.246264, acc.: 55.47%] [G loss: 0.329513]\n",
      "epoch:1 step:1079 [D loss: 0.243963, acc.: 56.25%] [G loss: 0.407381]\n",
      "epoch:1 step:1080 [D loss: 0.225322, acc.: 61.72%] [G loss: 0.369845]\n",
      "epoch:1 step:1081 [D loss: 0.233772, acc.: 61.72%] [G loss: 0.365450]\n",
      "epoch:1 step:1082 [D loss: 0.245520, acc.: 54.69%] [G loss: 0.336422]\n",
      "epoch:1 step:1083 [D loss: 0.253668, acc.: 60.16%] [G loss: 0.349477]\n",
      "epoch:1 step:1084 [D loss: 0.229217, acc.: 60.94%] [G loss: 0.352767]\n",
      "epoch:1 step:1085 [D loss: 0.227939, acc.: 60.94%] [G loss: 0.340901]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:1 step:1086 [D loss: 0.246634, acc.: 55.47%] [G loss: 0.370851]\n",
      "epoch:1 step:1087 [D loss: 0.219999, acc.: 65.62%] [G loss: 0.360076]\n",
      "epoch:1 step:1088 [D loss: 0.224435, acc.: 68.75%] [G loss: 0.365696]\n",
      "epoch:1 step:1089 [D loss: 0.213317, acc.: 67.19%] [G loss: 0.367949]\n",
      "epoch:1 step:1090 [D loss: 0.228018, acc.: 67.97%] [G loss: 0.375972]\n",
      "epoch:1 step:1091 [D loss: 0.215491, acc.: 68.75%] [G loss: 0.340051]\n",
      "epoch:1 step:1092 [D loss: 0.233518, acc.: 53.12%] [G loss: 0.363775]\n",
      "epoch:1 step:1093 [D loss: 0.238894, acc.: 57.81%] [G loss: 0.353503]\n",
      "epoch:1 step:1094 [D loss: 0.233761, acc.: 64.06%] [G loss: 0.360121]\n",
      "epoch:1 step:1095 [D loss: 0.241256, acc.: 58.59%] [G loss: 0.360410]\n",
      "epoch:1 step:1096 [D loss: 0.240558, acc.: 62.50%] [G loss: 0.341564]\n",
      "epoch:1 step:1097 [D loss: 0.219377, acc.: 64.84%] [G loss: 0.388855]\n",
      "epoch:1 step:1098 [D loss: 0.255097, acc.: 56.25%] [G loss: 0.359825]\n",
      "epoch:1 step:1099 [D loss: 0.231773, acc.: 61.72%] [G loss: 0.350451]\n",
      "epoch:1 step:1100 [D loss: 0.242311, acc.: 58.59%] [G loss: 0.383907]\n",
      "epoch:1 step:1101 [D loss: 0.209651, acc.: 69.53%] [G loss: 0.406554]\n",
      "epoch:1 step:1102 [D loss: 0.184154, acc.: 72.66%] [G loss: 0.377106]\n",
      "epoch:1 step:1103 [D loss: 0.240348, acc.: 60.16%] [G loss: 0.330409]\n",
      "epoch:1 step:1104 [D loss: 0.237054, acc.: 61.72%] [G loss: 0.328011]\n",
      "epoch:1 step:1105 [D loss: 0.230183, acc.: 60.16%] [G loss: 0.362121]\n",
      "epoch:1 step:1106 [D loss: 0.240926, acc.: 60.94%] [G loss: 0.341530]\n",
      "epoch:1 step:1107 [D loss: 0.221588, acc.: 61.72%] [G loss: 0.379130]\n",
      "epoch:1 step:1108 [D loss: 0.215337, acc.: 64.06%] [G loss: 0.359228]\n",
      "epoch:1 step:1109 [D loss: 0.247692, acc.: 61.72%] [G loss: 0.371960]\n",
      "epoch:1 step:1110 [D loss: 0.241487, acc.: 58.59%] [G loss: 0.396222]\n",
      "epoch:1 step:1111 [D loss: 0.243605, acc.: 63.28%] [G loss: 0.382631]\n",
      "epoch:1 step:1112 [D loss: 0.238991, acc.: 62.50%] [G loss: 0.350135]\n",
      "epoch:1 step:1113 [D loss: 0.226268, acc.: 60.94%] [G loss: 0.384704]\n",
      "epoch:1 step:1114 [D loss: 0.227332, acc.: 59.38%] [G loss: 0.376918]\n",
      "epoch:1 step:1115 [D loss: 0.241796, acc.: 57.03%] [G loss: 0.345035]\n",
      "epoch:1 step:1116 [D loss: 0.239443, acc.: 60.16%] [G loss: 0.377027]\n",
      "epoch:1 step:1117 [D loss: 0.259870, acc.: 52.34%] [G loss: 0.354406]\n",
      "epoch:1 step:1118 [D loss: 0.267930, acc.: 51.56%] [G loss: 0.359555]\n",
      "epoch:1 step:1119 [D loss: 0.226015, acc.: 64.06%] [G loss: 0.390324]\n",
      "epoch:1 step:1120 [D loss: 0.265003, acc.: 53.91%] [G loss: 0.312915]\n",
      "epoch:1 step:1121 [D loss: 0.228540, acc.: 63.28%] [G loss: 0.360868]\n",
      "epoch:1 step:1122 [D loss: 0.246492, acc.: 55.47%] [G loss: 0.329632]\n",
      "epoch:1 step:1123 [D loss: 0.229450, acc.: 61.72%] [G loss: 0.329754]\n",
      "epoch:1 step:1124 [D loss: 0.206135, acc.: 70.31%] [G loss: 0.366034]\n",
      "epoch:1 step:1125 [D loss: 0.221076, acc.: 65.62%] [G loss: 0.317081]\n",
      "epoch:1 step:1126 [D loss: 0.223949, acc.: 65.62%] [G loss: 0.376904]\n",
      "epoch:1 step:1127 [D loss: 0.221982, acc.: 63.28%] [G loss: 0.391871]\n",
      "epoch:1 step:1128 [D loss: 0.214148, acc.: 67.97%] [G loss: 0.371387]\n",
      "epoch:1 step:1129 [D loss: 0.230760, acc.: 60.16%] [G loss: 0.375632]\n",
      "epoch:1 step:1130 [D loss: 0.258635, acc.: 52.34%] [G loss: 0.352803]\n",
      "epoch:1 step:1131 [D loss: 0.230448, acc.: 63.28%] [G loss: 0.378171]\n",
      "epoch:1 step:1132 [D loss: 0.234715, acc.: 64.06%] [G loss: 0.361305]\n",
      "epoch:1 step:1133 [D loss: 0.217221, acc.: 63.28%] [G loss: 0.363914]\n",
      "epoch:1 step:1134 [D loss: 0.241055, acc.: 60.16%] [G loss: 0.358539]\n",
      "epoch:1 step:1135 [D loss: 0.224690, acc.: 60.94%] [G loss: 0.290020]\n",
      "epoch:1 step:1136 [D loss: 0.217336, acc.: 65.62%] [G loss: 0.350631]\n",
      "epoch:1 step:1137 [D loss: 0.220288, acc.: 62.50%] [G loss: 0.355181]\n",
      "epoch:1 step:1138 [D loss: 0.247680, acc.: 57.03%] [G loss: 0.351918]\n",
      "epoch:1 step:1139 [D loss: 0.228613, acc.: 65.62%] [G loss: 0.333866]\n",
      "epoch:1 step:1140 [D loss: 0.230750, acc.: 63.28%] [G loss: 0.374718]\n",
      "epoch:1 step:1141 [D loss: 0.244234, acc.: 60.94%] [G loss: 0.366159]\n",
      "epoch:1 step:1142 [D loss: 0.203536, acc.: 66.41%] [G loss: 0.371367]\n",
      "epoch:1 step:1143 [D loss: 0.232646, acc.: 63.28%] [G loss: 0.375030]\n",
      "epoch:1 step:1144 [D loss: 0.224040, acc.: 64.06%] [G loss: 0.390194]\n",
      "epoch:1 step:1145 [D loss: 0.222148, acc.: 66.41%] [G loss: 0.311478]\n",
      "epoch:1 step:1146 [D loss: 0.239250, acc.: 57.81%] [G loss: 0.314937]\n",
      "epoch:1 step:1147 [D loss: 0.236403, acc.: 57.81%] [G loss: 0.353679]\n",
      "epoch:1 step:1148 [D loss: 0.225726, acc.: 60.94%] [G loss: 0.348779]\n",
      "epoch:1 step:1149 [D loss: 0.206101, acc.: 67.19%] [G loss: 0.359833]\n",
      "epoch:1 step:1150 [D loss: 0.250543, acc.: 54.69%] [G loss: 0.373456]\n",
      "epoch:1 step:1151 [D loss: 0.236728, acc.: 62.50%] [G loss: 0.392428]\n",
      "epoch:1 step:1152 [D loss: 0.225495, acc.: 64.84%] [G loss: 0.394856]\n",
      "epoch:1 step:1153 [D loss: 0.236334, acc.: 60.94%] [G loss: 0.395234]\n",
      "epoch:1 step:1154 [D loss: 0.246491, acc.: 59.38%] [G loss: 0.345371]\n",
      "epoch:1 step:1155 [D loss: 0.231911, acc.: 60.94%] [G loss: 0.351696]\n",
      "epoch:1 step:1156 [D loss: 0.231709, acc.: 64.06%] [G loss: 0.360145]\n",
      "epoch:1 step:1157 [D loss: 0.247382, acc.: 56.25%] [G loss: 0.315070]\n",
      "epoch:1 step:1158 [D loss: 0.211109, acc.: 64.84%] [G loss: 0.343843]\n",
      "epoch:1 step:1159 [D loss: 0.266320, acc.: 57.03%] [G loss: 0.367336]\n",
      "epoch:1 step:1160 [D loss: 0.248480, acc.: 53.91%] [G loss: 0.344481]\n",
      "epoch:1 step:1161 [D loss: 0.231133, acc.: 63.28%] [G loss: 0.352496]\n",
      "epoch:1 step:1162 [D loss: 0.245884, acc.: 58.59%] [G loss: 0.353356]\n",
      "epoch:1 step:1163 [D loss: 0.232292, acc.: 57.81%] [G loss: 0.370862]\n",
      "epoch:1 step:1164 [D loss: 0.235795, acc.: 66.41%] [G loss: 0.377174]\n",
      "epoch:1 step:1165 [D loss: 0.214374, acc.: 64.84%] [G loss: 0.344015]\n",
      "epoch:1 step:1166 [D loss: 0.231162, acc.: 64.06%] [G loss: 0.336763]\n",
      "epoch:1 step:1167 [D loss: 0.254586, acc.: 53.91%] [G loss: 0.322128]\n",
      "epoch:1 step:1168 [D loss: 0.255569, acc.: 53.91%] [G loss: 0.340113]\n",
      "epoch:1 step:1169 [D loss: 0.230980, acc.: 61.72%] [G loss: 0.352902]\n",
      "epoch:1 step:1170 [D loss: 0.234959, acc.: 62.50%] [G loss: 0.389919]\n",
      "epoch:1 step:1171 [D loss: 0.246782, acc.: 57.81%] [G loss: 0.318707]\n",
      "epoch:1 step:1172 [D loss: 0.244867, acc.: 59.38%] [G loss: 0.370532]\n",
      "epoch:1 step:1173 [D loss: 0.233727, acc.: 57.81%] [G loss: 0.343557]\n",
      "epoch:1 step:1174 [D loss: 0.255163, acc.: 55.47%] [G loss: 0.321115]\n",
      "epoch:1 step:1175 [D loss: 0.234148, acc.: 60.94%] [G loss: 0.343995]\n",
      "epoch:1 step:1176 [D loss: 0.231304, acc.: 64.84%] [G loss: 0.343096]\n",
      "epoch:1 step:1177 [D loss: 0.226273, acc.: 61.72%] [G loss: 0.405998]\n",
      "epoch:1 step:1178 [D loss: 0.250729, acc.: 56.25%] [G loss: 0.360577]\n",
      "epoch:1 step:1179 [D loss: 0.250212, acc.: 58.59%] [G loss: 0.332879]\n",
      "epoch:1 step:1180 [D loss: 0.198180, acc.: 68.75%] [G loss: 0.309626]\n",
      "epoch:1 step:1181 [D loss: 0.230282, acc.: 63.28%] [G loss: 0.345229]\n",
      "epoch:1 step:1182 [D loss: 0.266412, acc.: 50.78%] [G loss: 0.338140]\n",
      "epoch:1 step:1183 [D loss: 0.241951, acc.: 54.69%] [G loss: 0.360076]\n",
      "epoch:1 step:1184 [D loss: 0.280386, acc.: 50.00%] [G loss: 0.379692]\n",
      "epoch:1 step:1185 [D loss: 0.228751, acc.: 64.06%] [G loss: 0.366224]\n",
      "epoch:1 step:1186 [D loss: 0.250156, acc.: 57.81%] [G loss: 0.358048]\n",
      "epoch:1 step:1187 [D loss: 0.249574, acc.: 59.38%] [G loss: 0.364903]\n",
      "epoch:1 step:1188 [D loss: 0.248100, acc.: 57.03%] [G loss: 0.338629]\n",
      "epoch:1 step:1189 [D loss: 0.227073, acc.: 60.94%] [G loss: 0.334831]\n",
      "epoch:1 step:1190 [D loss: 0.241042, acc.: 62.50%] [G loss: 0.369768]\n",
      "epoch:1 step:1191 [D loss: 0.235862, acc.: 60.16%] [G loss: 0.339986]\n",
      "epoch:1 step:1192 [D loss: 0.217360, acc.: 66.41%] [G loss: 0.361364]\n",
      "epoch:1 step:1193 [D loss: 0.258877, acc.: 53.12%] [G loss: 0.333972]\n",
      "epoch:1 step:1194 [D loss: 0.236812, acc.: 60.16%] [G loss: 0.401407]\n",
      "epoch:1 step:1195 [D loss: 0.206877, acc.: 64.84%] [G loss: 0.382384]\n",
      "epoch:1 step:1196 [D loss: 0.220590, acc.: 63.28%] [G loss: 0.378104]\n",
      "epoch:1 step:1197 [D loss: 0.256819, acc.: 55.47%] [G loss: 0.352348]\n",
      "epoch:1 step:1198 [D loss: 0.209269, acc.: 68.75%] [G loss: 0.356410]\n",
      "epoch:1 step:1199 [D loss: 0.238085, acc.: 59.38%] [G loss: 0.368536]\n",
      "epoch:1 step:1200 [D loss: 0.229595, acc.: 60.16%] [G loss: 0.395832]\n",
      "epoch:1 step:1201 [D loss: 0.283167, acc.: 46.88%] [G loss: 0.355226]\n",
      "epoch:1 step:1202 [D loss: 0.246050, acc.: 58.59%] [G loss: 0.370254]\n",
      "epoch:1 step:1203 [D loss: 0.271023, acc.: 56.25%] [G loss: 0.307809]\n",
      "epoch:1 step:1204 [D loss: 0.247565, acc.: 57.03%] [G loss: 0.358399]\n",
      "epoch:1 step:1205 [D loss: 0.253029, acc.: 50.78%] [G loss: 0.356391]\n",
      "epoch:1 step:1206 [D loss: 0.230977, acc.: 62.50%] [G loss: 0.343669]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:1 step:1207 [D loss: 0.236491, acc.: 60.94%] [G loss: 0.326895]\n",
      "epoch:1 step:1208 [D loss: 0.238890, acc.: 57.03%] [G loss: 0.340014]\n",
      "epoch:1 step:1209 [D loss: 0.274151, acc.: 52.34%] [G loss: 0.332093]\n",
      "epoch:1 step:1210 [D loss: 0.231476, acc.: 62.50%] [G loss: 0.357013]\n",
      "epoch:1 step:1211 [D loss: 0.260407, acc.: 54.69%] [G loss: 0.315704]\n",
      "epoch:1 step:1212 [D loss: 0.259213, acc.: 60.16%] [G loss: 0.376075]\n",
      "epoch:1 step:1213 [D loss: 0.250964, acc.: 60.94%] [G loss: 0.354603]\n",
      "epoch:1 step:1214 [D loss: 0.256785, acc.: 55.47%] [G loss: 0.332428]\n",
      "epoch:1 step:1215 [D loss: 0.242507, acc.: 56.25%] [G loss: 0.359914]\n",
      "epoch:1 step:1216 [D loss: 0.242780, acc.: 56.25%] [G loss: 0.376877]\n",
      "epoch:1 step:1217 [D loss: 0.250578, acc.: 52.34%] [G loss: 0.303886]\n",
      "epoch:1 step:1218 [D loss: 0.244167, acc.: 60.16%] [G loss: 0.356082]\n",
      "epoch:1 step:1219 [D loss: 0.262641, acc.: 53.12%] [G loss: 0.344469]\n",
      "epoch:1 step:1220 [D loss: 0.254854, acc.: 57.03%] [G loss: 0.330503]\n",
      "epoch:1 step:1221 [D loss: 0.227724, acc.: 61.72%] [G loss: 0.365722]\n",
      "epoch:1 step:1222 [D loss: 0.256556, acc.: 55.47%] [G loss: 0.363027]\n",
      "epoch:1 step:1223 [D loss: 0.252919, acc.: 52.34%] [G loss: 0.358402]\n",
      "epoch:1 step:1224 [D loss: 0.199504, acc.: 71.88%] [G loss: 0.384410]\n",
      "epoch:1 step:1225 [D loss: 0.224154, acc.: 64.84%] [G loss: 0.350703]\n",
      "epoch:1 step:1226 [D loss: 0.254412, acc.: 58.59%] [G loss: 0.376382]\n",
      "epoch:1 step:1227 [D loss: 0.249209, acc.: 58.59%] [G loss: 0.346591]\n",
      "epoch:1 step:1228 [D loss: 0.250344, acc.: 60.16%] [G loss: 0.355137]\n",
      "epoch:1 step:1229 [D loss: 0.224681, acc.: 61.72%] [G loss: 0.341335]\n",
      "epoch:1 step:1230 [D loss: 0.217233, acc.: 65.62%] [G loss: 0.385686]\n",
      "epoch:1 step:1231 [D loss: 0.234135, acc.: 57.81%] [G loss: 0.335879]\n",
      "epoch:1 step:1232 [D loss: 0.237459, acc.: 57.81%] [G loss: 0.357790]\n",
      "epoch:1 step:1233 [D loss: 0.220154, acc.: 61.72%] [G loss: 0.347721]\n",
      "epoch:1 step:1234 [D loss: 0.248633, acc.: 56.25%] [G loss: 0.314716]\n",
      "epoch:1 step:1235 [D loss: 0.233249, acc.: 67.19%] [G loss: 0.372129]\n",
      "epoch:1 step:1236 [D loss: 0.244451, acc.: 57.81%] [G loss: 0.327478]\n",
      "epoch:1 step:1237 [D loss: 0.227019, acc.: 58.59%] [G loss: 0.399350]\n",
      "epoch:1 step:1238 [D loss: 0.232269, acc.: 58.59%] [G loss: 0.346578]\n",
      "epoch:1 step:1239 [D loss: 0.256824, acc.: 47.66%] [G loss: 0.384536]\n",
      "epoch:1 step:1240 [D loss: 0.224795, acc.: 62.50%] [G loss: 0.324421]\n",
      "epoch:1 step:1241 [D loss: 0.225122, acc.: 62.50%] [G loss: 0.366074]\n",
      "epoch:1 step:1242 [D loss: 0.233809, acc.: 62.50%] [G loss: 0.334682]\n",
      "epoch:1 step:1243 [D loss: 0.207128, acc.: 65.62%] [G loss: 0.388695]\n",
      "epoch:1 step:1244 [D loss: 0.240594, acc.: 55.47%] [G loss: 0.306780]\n",
      "epoch:1 step:1245 [D loss: 0.222633, acc.: 62.50%] [G loss: 0.328128]\n",
      "epoch:1 step:1246 [D loss: 0.226506, acc.: 60.16%] [G loss: 0.349637]\n",
      "epoch:1 step:1247 [D loss: 0.263256, acc.: 53.91%] [G loss: 0.362928]\n",
      "epoch:1 step:1248 [D loss: 0.245945, acc.: 57.03%] [G loss: 0.353413]\n",
      "epoch:1 step:1249 [D loss: 0.259546, acc.: 53.12%] [G loss: 0.314828]\n",
      "epoch:1 step:1250 [D loss: 0.254107, acc.: 56.25%] [G loss: 0.342172]\n",
      "epoch:1 step:1251 [D loss: 0.253201, acc.: 57.03%] [G loss: 0.337294]\n",
      "epoch:1 step:1252 [D loss: 0.226568, acc.: 60.16%] [G loss: 0.343411]\n",
      "epoch:1 step:1253 [D loss: 0.272799, acc.: 48.44%] [G loss: 0.333955]\n",
      "epoch:1 step:1254 [D loss: 0.243704, acc.: 58.59%] [G loss: 0.374009]\n",
      "epoch:1 step:1255 [D loss: 0.271052, acc.: 50.00%] [G loss: 0.359409]\n",
      "epoch:1 step:1256 [D loss: 0.261708, acc.: 56.25%] [G loss: 0.342460]\n",
      "epoch:1 step:1257 [D loss: 0.217586, acc.: 63.28%] [G loss: 0.355158]\n",
      "epoch:1 step:1258 [D loss: 0.226626, acc.: 59.38%] [G loss: 0.355313]\n",
      "epoch:1 step:1259 [D loss: 0.237495, acc.: 59.38%] [G loss: 0.394743]\n",
      "epoch:1 step:1260 [D loss: 0.243154, acc.: 60.16%] [G loss: 0.354694]\n",
      "epoch:1 step:1261 [D loss: 0.243578, acc.: 55.47%] [G loss: 0.355645]\n",
      "epoch:1 step:1262 [D loss: 0.226159, acc.: 64.06%] [G loss: 0.344901]\n",
      "epoch:1 step:1263 [D loss: 0.243937, acc.: 61.72%] [G loss: 0.317161]\n",
      "epoch:1 step:1264 [D loss: 0.229995, acc.: 62.50%] [G loss: 0.325560]\n",
      "epoch:1 step:1265 [D loss: 0.235674, acc.: 59.38%] [G loss: 0.337758]\n",
      "epoch:1 step:1266 [D loss: 0.256016, acc.: 54.69%] [G loss: 0.376330]\n",
      "epoch:1 step:1267 [D loss: 0.236379, acc.: 61.72%] [G loss: 0.309817]\n",
      "epoch:1 step:1268 [D loss: 0.224628, acc.: 66.41%] [G loss: 0.357306]\n",
      "epoch:1 step:1269 [D loss: 0.235893, acc.: 62.50%] [G loss: 0.309686]\n",
      "epoch:1 step:1270 [D loss: 0.233861, acc.: 57.81%] [G loss: 0.345114]\n",
      "epoch:1 step:1271 [D loss: 0.222542, acc.: 64.06%] [G loss: 0.358270]\n",
      "epoch:1 step:1272 [D loss: 0.207598, acc.: 64.84%] [G loss: 0.402224]\n",
      "epoch:1 step:1273 [D loss: 0.213148, acc.: 71.88%] [G loss: 0.372317]\n",
      "epoch:1 step:1274 [D loss: 0.250843, acc.: 56.25%] [G loss: 0.350449]\n",
      "epoch:1 step:1275 [D loss: 0.210409, acc.: 63.28%] [G loss: 0.357111]\n",
      "epoch:1 step:1276 [D loss: 0.234112, acc.: 62.50%] [G loss: 0.374404]\n",
      "epoch:1 step:1277 [D loss: 0.232177, acc.: 65.62%] [G loss: 0.378720]\n",
      "epoch:1 step:1278 [D loss: 0.213155, acc.: 69.53%] [G loss: 0.338284]\n",
      "epoch:1 step:1279 [D loss: 0.210324, acc.: 67.97%] [G loss: 0.381957]\n",
      "epoch:1 step:1280 [D loss: 0.211353, acc.: 66.41%] [G loss: 0.350053]\n",
      "epoch:1 step:1281 [D loss: 0.234791, acc.: 61.72%] [G loss: 0.326364]\n",
      "epoch:1 step:1282 [D loss: 0.244302, acc.: 58.59%] [G loss: 0.355300]\n",
      "epoch:1 step:1283 [D loss: 0.239683, acc.: 55.47%] [G loss: 0.347698]\n",
      "epoch:1 step:1284 [D loss: 0.221748, acc.: 66.41%] [G loss: 0.353580]\n",
      "epoch:1 step:1285 [D loss: 0.232332, acc.: 60.16%] [G loss: 0.403580]\n",
      "epoch:1 step:1286 [D loss: 0.255051, acc.: 56.25%] [G loss: 0.357552]\n",
      "epoch:1 step:1287 [D loss: 0.255125, acc.: 55.47%] [G loss: 0.340137]\n",
      "epoch:1 step:1288 [D loss: 0.241748, acc.: 58.59%] [G loss: 0.351124]\n",
      "epoch:1 step:1289 [D loss: 0.244803, acc.: 57.03%] [G loss: 0.317783]\n",
      "epoch:1 step:1290 [D loss: 0.230478, acc.: 64.06%] [G loss: 0.315565]\n",
      "epoch:1 step:1291 [D loss: 0.238186, acc.: 60.16%] [G loss: 0.331838]\n",
      "epoch:1 step:1292 [D loss: 0.227362, acc.: 63.28%] [G loss: 0.340059]\n",
      "epoch:1 step:1293 [D loss: 0.239595, acc.: 63.28%] [G loss: 0.343623]\n",
      "epoch:1 step:1294 [D loss: 0.200560, acc.: 71.88%] [G loss: 0.347779]\n",
      "epoch:1 step:1295 [D loss: 0.244153, acc.: 54.69%] [G loss: 0.360379]\n",
      "epoch:1 step:1296 [D loss: 0.257915, acc.: 56.25%] [G loss: 0.330317]\n",
      "epoch:1 step:1297 [D loss: 0.222980, acc.: 64.06%] [G loss: 0.353896]\n",
      "epoch:1 step:1298 [D loss: 0.233061, acc.: 62.50%] [G loss: 0.348383]\n",
      "epoch:1 step:1299 [D loss: 0.227340, acc.: 65.62%] [G loss: 0.335554]\n",
      "epoch:1 step:1300 [D loss: 0.238844, acc.: 62.50%] [G loss: 0.370595]\n",
      "epoch:1 step:1301 [D loss: 0.235064, acc.: 61.72%] [G loss: 0.385856]\n",
      "epoch:1 step:1302 [D loss: 0.248438, acc.: 57.03%] [G loss: 0.344162]\n",
      "epoch:1 step:1303 [D loss: 0.242159, acc.: 55.47%] [G loss: 0.301698]\n",
      "epoch:1 step:1304 [D loss: 0.264362, acc.: 51.56%] [G loss: 0.374614]\n",
      "epoch:1 step:1305 [D loss: 0.228763, acc.: 64.06%] [G loss: 0.316853]\n",
      "epoch:1 step:1306 [D loss: 0.257248, acc.: 57.81%] [G loss: 0.336993]\n",
      "epoch:1 step:1307 [D loss: 0.218835, acc.: 69.53%] [G loss: 0.332083]\n",
      "epoch:1 step:1308 [D loss: 0.227801, acc.: 64.84%] [G loss: 0.349934]\n",
      "epoch:1 step:1309 [D loss: 0.227820, acc.: 64.06%] [G loss: 0.359342]\n",
      "epoch:1 step:1310 [D loss: 0.234082, acc.: 58.59%] [G loss: 0.315768]\n",
      "epoch:1 step:1311 [D loss: 0.230553, acc.: 62.50%] [G loss: 0.331948]\n",
      "epoch:1 step:1312 [D loss: 0.246246, acc.: 56.25%] [G loss: 0.364718]\n",
      "epoch:1 step:1313 [D loss: 0.260804, acc.: 60.16%] [G loss: 0.303692]\n",
      "epoch:1 step:1314 [D loss: 0.226041, acc.: 63.28%] [G loss: 0.347546]\n",
      "epoch:1 step:1315 [D loss: 0.245229, acc.: 63.28%] [G loss: 0.317145]\n",
      "epoch:1 step:1316 [D loss: 0.238663, acc.: 61.72%] [G loss: 0.346941]\n",
      "epoch:1 step:1317 [D loss: 0.263782, acc.: 52.34%] [G loss: 0.352833]\n",
      "epoch:1 step:1318 [D loss: 0.242033, acc.: 60.94%] [G loss: 0.338447]\n",
      "epoch:1 step:1319 [D loss: 0.228350, acc.: 65.62%] [G loss: 0.362784]\n",
      "epoch:1 step:1320 [D loss: 0.218741, acc.: 64.06%] [G loss: 0.348534]\n",
      "epoch:1 step:1321 [D loss: 0.236619, acc.: 60.16%] [G loss: 0.370543]\n",
      "epoch:1 step:1322 [D loss: 0.240278, acc.: 54.69%] [G loss: 0.379044]\n",
      "epoch:1 step:1323 [D loss: 0.234972, acc.: 59.38%] [G loss: 0.315994]\n",
      "epoch:1 step:1324 [D loss: 0.225308, acc.: 62.50%] [G loss: 0.323697]\n",
      "epoch:1 step:1325 [D loss: 0.234213, acc.: 63.28%] [G loss: 0.358725]\n",
      "epoch:1 step:1326 [D loss: 0.256017, acc.: 52.34%] [G loss: 0.283626]\n",
      "epoch:1 step:1327 [D loss: 0.236796, acc.: 57.81%] [G loss: 0.359714]\n",
      "epoch:1 step:1328 [D loss: 0.260406, acc.: 51.56%] [G loss: 0.333409]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:1 step:1329 [D loss: 0.260709, acc.: 54.69%] [G loss: 0.378564]\n",
      "epoch:1 step:1330 [D loss: 0.245047, acc.: 57.03%] [G loss: 0.348745]\n",
      "epoch:1 step:1331 [D loss: 0.256115, acc.: 55.47%] [G loss: 0.357965]\n",
      "epoch:1 step:1332 [D loss: 0.213711, acc.: 68.75%] [G loss: 0.372304]\n",
      "epoch:1 step:1333 [D loss: 0.235912, acc.: 64.84%] [G loss: 0.326128]\n",
      "epoch:1 step:1334 [D loss: 0.248912, acc.: 55.47%] [G loss: 0.360844]\n",
      "epoch:1 step:1335 [D loss: 0.245674, acc.: 58.59%] [G loss: 0.406224]\n",
      "epoch:1 step:1336 [D loss: 0.230590, acc.: 59.38%] [G loss: 0.371052]\n",
      "epoch:1 step:1337 [D loss: 0.226196, acc.: 60.16%] [G loss: 0.342775]\n",
      "epoch:1 step:1338 [D loss: 0.250714, acc.: 54.69%] [G loss: 0.375289]\n",
      "epoch:1 step:1339 [D loss: 0.226907, acc.: 67.19%] [G loss: 0.392972]\n",
      "epoch:1 step:1340 [D loss: 0.268138, acc.: 53.91%] [G loss: 0.299794]\n",
      "epoch:1 step:1341 [D loss: 0.243691, acc.: 56.25%] [G loss: 0.369121]\n",
      "epoch:1 step:1342 [D loss: 0.229950, acc.: 64.06%] [G loss: 0.329533]\n",
      "epoch:1 step:1343 [D loss: 0.233493, acc.: 60.16%] [G loss: 0.359410]\n",
      "epoch:1 step:1344 [D loss: 0.223955, acc.: 64.84%] [G loss: 0.350929]\n",
      "epoch:1 step:1345 [D loss: 0.251330, acc.: 50.00%] [G loss: 0.397874]\n",
      "epoch:1 step:1346 [D loss: 0.254406, acc.: 55.47%] [G loss: 0.357486]\n",
      "epoch:1 step:1347 [D loss: 0.235566, acc.: 60.94%] [G loss: 0.361579]\n",
      "epoch:1 step:1348 [D loss: 0.239160, acc.: 63.28%] [G loss: 0.322418]\n",
      "epoch:1 step:1349 [D loss: 0.226324, acc.: 63.28%] [G loss: 0.342852]\n",
      "epoch:1 step:1350 [D loss: 0.263261, acc.: 56.25%] [G loss: 0.326526]\n",
      "epoch:1 step:1351 [D loss: 0.215639, acc.: 65.62%] [G loss: 0.318528]\n",
      "epoch:1 step:1352 [D loss: 0.252661, acc.: 55.47%] [G loss: 0.311900]\n",
      "epoch:1 step:1353 [D loss: 0.229673, acc.: 60.16%] [G loss: 0.317754]\n",
      "epoch:1 step:1354 [D loss: 0.254346, acc.: 60.16%] [G loss: 0.307122]\n",
      "epoch:1 step:1355 [D loss: 0.225578, acc.: 65.62%] [G loss: 0.350756]\n",
      "epoch:1 step:1356 [D loss: 0.219818, acc.: 67.97%] [G loss: 0.357412]\n",
      "epoch:1 step:1357 [D loss: 0.224535, acc.: 60.94%] [G loss: 0.332384]\n",
      "epoch:1 step:1358 [D loss: 0.240956, acc.: 55.47%] [G loss: 0.323733]\n",
      "epoch:1 step:1359 [D loss: 0.242415, acc.: 56.25%] [G loss: 0.320810]\n",
      "epoch:1 step:1360 [D loss: 0.214627, acc.: 67.97%] [G loss: 0.340497]\n",
      "epoch:1 step:1361 [D loss: 0.227148, acc.: 62.50%] [G loss: 0.390058]\n",
      "epoch:1 step:1362 [D loss: 0.237396, acc.: 59.38%] [G loss: 0.370820]\n",
      "epoch:1 step:1363 [D loss: 0.230685, acc.: 59.38%] [G loss: 0.333690]\n",
      "epoch:1 step:1364 [D loss: 0.224449, acc.: 65.62%] [G loss: 0.334229]\n",
      "epoch:1 step:1365 [D loss: 0.241316, acc.: 60.94%] [G loss: 0.349360]\n",
      "epoch:1 step:1366 [D loss: 0.257537, acc.: 53.12%] [G loss: 0.354606]\n",
      "epoch:1 step:1367 [D loss: 0.242066, acc.: 57.81%] [G loss: 0.323213]\n",
      "epoch:1 step:1368 [D loss: 0.257850, acc.: 57.03%] [G loss: 0.339663]\n",
      "epoch:1 step:1369 [D loss: 0.250738, acc.: 56.25%] [G loss: 0.352331]\n",
      "epoch:1 step:1370 [D loss: 0.228989, acc.: 61.72%] [G loss: 0.351016]\n",
      "epoch:1 step:1371 [D loss: 0.271504, acc.: 50.00%] [G loss: 0.353846]\n",
      "epoch:1 step:1372 [D loss: 0.242550, acc.: 61.72%] [G loss: 0.334540]\n",
      "epoch:1 step:1373 [D loss: 0.244888, acc.: 59.38%] [G loss: 0.384151]\n",
      "epoch:1 step:1374 [D loss: 0.269401, acc.: 48.44%] [G loss: 0.319998]\n",
      "epoch:1 step:1375 [D loss: 0.256843, acc.: 59.38%] [G loss: 0.334205]\n",
      "epoch:1 step:1376 [D loss: 0.219652, acc.: 67.19%] [G loss: 0.310874]\n",
      "epoch:1 step:1377 [D loss: 0.235423, acc.: 58.59%] [G loss: 0.341295]\n",
      "epoch:1 step:1378 [D loss: 0.245519, acc.: 60.94%] [G loss: 0.347849]\n",
      "epoch:1 step:1379 [D loss: 0.232878, acc.: 58.59%] [G loss: 0.340633]\n",
      "epoch:1 step:1380 [D loss: 0.242479, acc.: 60.94%] [G loss: 0.382999]\n",
      "epoch:1 step:1381 [D loss: 0.241760, acc.: 58.59%] [G loss: 0.341519]\n",
      "epoch:1 step:1382 [D loss: 0.223044, acc.: 64.06%] [G loss: 0.390510]\n",
      "epoch:1 step:1383 [D loss: 0.261174, acc.: 50.78%] [G loss: 0.318478]\n",
      "epoch:1 step:1384 [D loss: 0.244789, acc.: 60.16%] [G loss: 0.362891]\n",
      "epoch:1 step:1385 [D loss: 0.231588, acc.: 66.41%] [G loss: 0.356984]\n",
      "epoch:1 step:1386 [D loss: 0.247221, acc.: 59.38%] [G loss: 0.361832]\n",
      "epoch:1 step:1387 [D loss: 0.261322, acc.: 53.12%] [G loss: 0.327825]\n",
      "epoch:1 step:1388 [D loss: 0.238178, acc.: 62.50%] [G loss: 0.355723]\n",
      "epoch:1 step:1389 [D loss: 0.256544, acc.: 53.12%] [G loss: 0.375300]\n",
      "epoch:1 step:1390 [D loss: 0.254287, acc.: 55.47%] [G loss: 0.339712]\n",
      "epoch:1 step:1391 [D loss: 0.229637, acc.: 60.16%] [G loss: 0.367332]\n",
      "epoch:1 step:1392 [D loss: 0.231646, acc.: 59.38%] [G loss: 0.316384]\n",
      "epoch:1 step:1393 [D loss: 0.230557, acc.: 64.06%] [G loss: 0.372908]\n",
      "epoch:1 step:1394 [D loss: 0.253998, acc.: 57.81%] [G loss: 0.371589]\n",
      "epoch:1 step:1395 [D loss: 0.247169, acc.: 54.69%] [G loss: 0.369221]\n",
      "epoch:1 step:1396 [D loss: 0.234109, acc.: 61.72%] [G loss: 0.379957]\n",
      "epoch:1 step:1397 [D loss: 0.246908, acc.: 57.03%] [G loss: 0.328258]\n",
      "epoch:1 step:1398 [D loss: 0.264941, acc.: 53.91%] [G loss: 0.355882]\n",
      "epoch:1 step:1399 [D loss: 0.242283, acc.: 58.59%] [G loss: 0.348645]\n",
      "epoch:1 step:1400 [D loss: 0.258405, acc.: 55.47%] [G loss: 0.319037]\n",
      "epoch:1 step:1401 [D loss: 0.239495, acc.: 55.47%] [G loss: 0.355851]\n",
      "epoch:1 step:1402 [D loss: 0.237600, acc.: 57.81%] [G loss: 0.332828]\n",
      "epoch:1 step:1403 [D loss: 0.256968, acc.: 53.91%] [G loss: 0.347821]\n",
      "epoch:1 step:1404 [D loss: 0.266928, acc.: 55.47%] [G loss: 0.321998]\n",
      "epoch:1 step:1405 [D loss: 0.244112, acc.: 60.94%] [G loss: 0.362626]\n",
      "epoch:1 step:1406 [D loss: 0.241147, acc.: 57.03%] [G loss: 0.344304]\n",
      "epoch:1 step:1407 [D loss: 0.235721, acc.: 62.50%] [G loss: 0.340808]\n",
      "epoch:1 step:1408 [D loss: 0.238657, acc.: 57.81%] [G loss: 0.363185]\n",
      "epoch:1 step:1409 [D loss: 0.248354, acc.: 59.38%] [G loss: 0.313377]\n",
      "epoch:1 step:1410 [D loss: 0.245135, acc.: 58.59%] [G loss: 0.361813]\n",
      "epoch:1 step:1411 [D loss: 0.238628, acc.: 62.50%] [G loss: 0.356301]\n",
      "epoch:1 step:1412 [D loss: 0.210885, acc.: 68.75%] [G loss: 0.346136]\n",
      "epoch:1 step:1413 [D loss: 0.248073, acc.: 51.56%] [G loss: 0.349188]\n",
      "epoch:1 step:1414 [D loss: 0.231641, acc.: 61.72%] [G loss: 0.351286]\n",
      "epoch:1 step:1415 [D loss: 0.251007, acc.: 57.81%] [G loss: 0.307938]\n",
      "epoch:1 step:1416 [D loss: 0.257392, acc.: 55.47%] [G loss: 0.374346]\n",
      "epoch:1 step:1417 [D loss: 0.231899, acc.: 58.59%] [G loss: 0.344230]\n",
      "epoch:1 step:1418 [D loss: 0.256070, acc.: 53.12%] [G loss: 0.313867]\n",
      "epoch:1 step:1419 [D loss: 0.202254, acc.: 68.75%] [G loss: 0.358900]\n",
      "epoch:1 step:1420 [D loss: 0.241963, acc.: 60.94%] [G loss: 0.356726]\n",
      "epoch:1 step:1421 [D loss: 0.235996, acc.: 63.28%] [G loss: 0.312920]\n",
      "epoch:1 step:1422 [D loss: 0.255924, acc.: 56.25%] [G loss: 0.310476]\n",
      "epoch:1 step:1423 [D loss: 0.235188, acc.: 60.16%] [G loss: 0.346375]\n",
      "epoch:1 step:1424 [D loss: 0.216870, acc.: 61.72%] [G loss: 0.316418]\n",
      "epoch:1 step:1425 [D loss: 0.248929, acc.: 55.47%] [G loss: 0.297884]\n",
      "epoch:1 step:1426 [D loss: 0.248154, acc.: 57.81%] [G loss: 0.355809]\n",
      "epoch:1 step:1427 [D loss: 0.228567, acc.: 61.72%] [G loss: 0.341330]\n",
      "epoch:1 step:1428 [D loss: 0.232772, acc.: 60.94%] [G loss: 0.379135]\n",
      "epoch:1 step:1429 [D loss: 0.242998, acc.: 57.03%] [G loss: 0.347232]\n",
      "epoch:1 step:1430 [D loss: 0.239144, acc.: 58.59%] [G loss: 0.328863]\n",
      "epoch:1 step:1431 [D loss: 0.233728, acc.: 60.94%] [G loss: 0.338408]\n",
      "epoch:1 step:1432 [D loss: 0.237084, acc.: 59.38%] [G loss: 0.317199]\n",
      "epoch:1 step:1433 [D loss: 0.241715, acc.: 58.59%] [G loss: 0.335011]\n",
      "epoch:1 step:1434 [D loss: 0.222875, acc.: 66.41%] [G loss: 0.305460]\n",
      "epoch:1 step:1435 [D loss: 0.234182, acc.: 60.94%] [G loss: 0.363544]\n",
      "epoch:1 step:1436 [D loss: 0.226394, acc.: 57.81%] [G loss: 0.359281]\n",
      "epoch:1 step:1437 [D loss: 0.281125, acc.: 47.66%] [G loss: 0.326297]\n",
      "epoch:1 step:1438 [D loss: 0.246480, acc.: 52.34%] [G loss: 0.404725]\n",
      "epoch:1 step:1439 [D loss: 0.240785, acc.: 58.59%] [G loss: 0.367714]\n",
      "epoch:1 step:1440 [D loss: 0.240218, acc.: 59.38%] [G loss: 0.337982]\n",
      "epoch:1 step:1441 [D loss: 0.243363, acc.: 54.69%] [G loss: 0.341656]\n",
      "epoch:1 step:1442 [D loss: 0.249162, acc.: 57.81%] [G loss: 0.296124]\n",
      "epoch:1 step:1443 [D loss: 0.233437, acc.: 60.16%] [G loss: 0.372161]\n",
      "epoch:1 step:1444 [D loss: 0.262330, acc.: 53.91%] [G loss: 0.322802]\n",
      "epoch:1 step:1445 [D loss: 0.237926, acc.: 57.03%] [G loss: 0.344253]\n",
      "epoch:1 step:1446 [D loss: 0.248276, acc.: 57.03%] [G loss: 0.352066]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:1 step:1447 [D loss: 0.247397, acc.: 59.38%] [G loss: 0.323651]\n",
      "epoch:1 step:1448 [D loss: 0.237869, acc.: 64.84%] [G loss: 0.327428]\n",
      "epoch:1 step:1449 [D loss: 0.261543, acc.: 53.91%] [G loss: 0.374439]\n",
      "epoch:1 step:1450 [D loss: 0.250299, acc.: 60.94%] [G loss: 0.325829]\n",
      "epoch:1 step:1451 [D loss: 0.258526, acc.: 55.47%] [G loss: 0.368922]\n",
      "epoch:1 step:1452 [D loss: 0.257267, acc.: 53.91%] [G loss: 0.343189]\n",
      "epoch:1 step:1453 [D loss: 0.232024, acc.: 64.84%] [G loss: 0.352111]\n",
      "epoch:1 step:1454 [D loss: 0.215094, acc.: 66.41%] [G loss: 0.371336]\n",
      "epoch:1 step:1455 [D loss: 0.238371, acc.: 59.38%] [G loss: 0.373561]\n",
      "epoch:1 step:1456 [D loss: 0.236927, acc.: 57.81%] [G loss: 0.302074]\n",
      "epoch:1 step:1457 [D loss: 0.257859, acc.: 57.81%] [G loss: 0.355266]\n",
      "epoch:1 step:1458 [D loss: 0.264475, acc.: 53.91%] [G loss: 0.328501]\n",
      "epoch:1 step:1459 [D loss: 0.217371, acc.: 63.28%] [G loss: 0.400315]\n",
      "epoch:1 step:1460 [D loss: 0.211057, acc.: 64.84%] [G loss: 0.320323]\n",
      "epoch:1 step:1461 [D loss: 0.249397, acc.: 60.16%] [G loss: 0.328546]\n",
      "epoch:1 step:1462 [D loss: 0.251178, acc.: 51.56%] [G loss: 0.310430]\n",
      "epoch:1 step:1463 [D loss: 0.238756, acc.: 58.59%] [G loss: 0.335067]\n",
      "epoch:1 step:1464 [D loss: 0.227280, acc.: 63.28%] [G loss: 0.375735]\n",
      "epoch:1 step:1465 [D loss: 0.247642, acc.: 57.03%] [G loss: 0.336401]\n",
      "epoch:1 step:1466 [D loss: 0.252907, acc.: 57.03%] [G loss: 0.353898]\n",
      "epoch:1 step:1467 [D loss: 0.221987, acc.: 65.62%] [G loss: 0.319181]\n",
      "epoch:1 step:1468 [D loss: 0.245689, acc.: 58.59%] [G loss: 0.325115]\n",
      "epoch:1 step:1469 [D loss: 0.228844, acc.: 63.28%] [G loss: 0.328049]\n",
      "epoch:1 step:1470 [D loss: 0.256929, acc.: 52.34%] [G loss: 0.323112]\n",
      "epoch:1 step:1471 [D loss: 0.263349, acc.: 53.91%] [G loss: 0.328536]\n",
      "epoch:1 step:1472 [D loss: 0.216690, acc.: 65.62%] [G loss: 0.308420]\n",
      "epoch:1 step:1473 [D loss: 0.243714, acc.: 60.16%] [G loss: 0.364422]\n",
      "epoch:1 step:1474 [D loss: 0.218366, acc.: 65.62%] [G loss: 0.387518]\n",
      "epoch:1 step:1475 [D loss: 0.255919, acc.: 53.91%] [G loss: 0.303249]\n",
      "epoch:1 step:1476 [D loss: 0.240314, acc.: 57.81%] [G loss: 0.339771]\n",
      "epoch:1 step:1477 [D loss: 0.251295, acc.: 57.03%] [G loss: 0.301926]\n",
      "epoch:1 step:1478 [D loss: 0.246700, acc.: 56.25%] [G loss: 0.352413]\n",
      "epoch:1 step:1479 [D loss: 0.236222, acc.: 58.59%] [G loss: 0.338573]\n",
      "epoch:1 step:1480 [D loss: 0.236515, acc.: 57.03%] [G loss: 0.311689]\n",
      "epoch:1 step:1481 [D loss: 0.207754, acc.: 71.88%] [G loss: 0.332215]\n",
      "epoch:1 step:1482 [D loss: 0.239730, acc.: 59.38%] [G loss: 0.290729]\n",
      "epoch:1 step:1483 [D loss: 0.217554, acc.: 67.97%] [G loss: 0.383329]\n",
      "epoch:1 step:1484 [D loss: 0.264389, acc.: 47.66%] [G loss: 0.333549]\n",
      "epoch:1 step:1485 [D loss: 0.229491, acc.: 60.94%] [G loss: 0.355741]\n",
      "epoch:1 step:1486 [D loss: 0.240928, acc.: 57.81%] [G loss: 0.387727]\n",
      "epoch:1 step:1487 [D loss: 0.200073, acc.: 70.31%] [G loss: 0.370670]\n",
      "epoch:1 step:1488 [D loss: 0.255667, acc.: 52.34%] [G loss: 0.352837]\n",
      "epoch:1 step:1489 [D loss: 0.266035, acc.: 48.44%] [G loss: 0.315087]\n",
      "epoch:1 step:1490 [D loss: 0.267338, acc.: 54.69%] [G loss: 0.337670]\n",
      "epoch:1 step:1491 [D loss: 0.221248, acc.: 64.06%] [G loss: 0.348490]\n",
      "epoch:1 step:1492 [D loss: 0.231958, acc.: 61.72%] [G loss: 0.356554]\n",
      "epoch:1 step:1493 [D loss: 0.252729, acc.: 58.59%] [G loss: 0.321806]\n",
      "epoch:1 step:1494 [D loss: 0.233081, acc.: 57.81%] [G loss: 0.358757]\n",
      "epoch:1 step:1495 [D loss: 0.244822, acc.: 57.03%] [G loss: 0.377372]\n",
      "epoch:1 step:1496 [D loss: 0.234564, acc.: 63.28%] [G loss: 0.379733]\n",
      "epoch:1 step:1497 [D loss: 0.234859, acc.: 61.72%] [G loss: 0.352427]\n",
      "epoch:1 step:1498 [D loss: 0.252565, acc.: 55.47%] [G loss: 0.367391]\n",
      "epoch:1 step:1499 [D loss: 0.262548, acc.: 55.47%] [G loss: 0.325180]\n",
      "epoch:1 step:1500 [D loss: 0.269463, acc.: 45.31%] [G loss: 0.352385]\n",
      "epoch:1 step:1501 [D loss: 0.217798, acc.: 65.62%] [G loss: 0.339606]\n",
      "epoch:1 step:1502 [D loss: 0.242414, acc.: 55.47%] [G loss: 0.322871]\n",
      "epoch:1 step:1503 [D loss: 0.248078, acc.: 60.16%] [G loss: 0.351332]\n",
      "epoch:1 step:1504 [D loss: 0.231667, acc.: 60.94%] [G loss: 0.358445]\n",
      "epoch:1 step:1505 [D loss: 0.272131, acc.: 49.22%] [G loss: 0.364705]\n",
      "epoch:1 step:1506 [D loss: 0.246366, acc.: 60.94%] [G loss: 0.367247]\n",
      "epoch:1 step:1507 [D loss: 0.239586, acc.: 56.25%] [G loss: 0.337893]\n",
      "epoch:1 step:1508 [D loss: 0.232209, acc.: 63.28%] [G loss: 0.336953]\n",
      "epoch:1 step:1509 [D loss: 0.236119, acc.: 60.94%] [G loss: 0.355366]\n",
      "epoch:1 step:1510 [D loss: 0.264686, acc.: 55.47%] [G loss: 0.346698]\n",
      "epoch:1 step:1511 [D loss: 0.246098, acc.: 60.94%] [G loss: 0.358990]\n",
      "epoch:1 step:1512 [D loss: 0.286433, acc.: 46.09%] [G loss: 0.301328]\n",
      "epoch:1 step:1513 [D loss: 0.232650, acc.: 57.81%] [G loss: 0.364565]\n",
      "epoch:1 step:1514 [D loss: 0.253210, acc.: 59.38%] [G loss: 0.369062]\n",
      "epoch:1 step:1515 [D loss: 0.251470, acc.: 58.59%] [G loss: 0.368420]\n",
      "epoch:1 step:1516 [D loss: 0.215237, acc.: 66.41%] [G loss: 0.331166]\n",
      "epoch:1 step:1517 [D loss: 0.233093, acc.: 62.50%] [G loss: 0.335715]\n",
      "epoch:1 step:1518 [D loss: 0.288403, acc.: 46.09%] [G loss: 0.333291]\n",
      "epoch:1 step:1519 [D loss: 0.248070, acc.: 56.25%] [G loss: 0.408547]\n",
      "epoch:1 step:1520 [D loss: 0.256241, acc.: 53.12%] [G loss: 0.324750]\n",
      "epoch:1 step:1521 [D loss: 0.225599, acc.: 63.28%] [G loss: 0.377571]\n",
      "epoch:1 step:1522 [D loss: 0.232308, acc.: 60.16%] [G loss: 0.356908]\n",
      "epoch:1 step:1523 [D loss: 0.244870, acc.: 57.81%] [G loss: 0.323242]\n",
      "epoch:1 step:1524 [D loss: 0.248336, acc.: 61.72%] [G loss: 0.346299]\n",
      "epoch:1 step:1525 [D loss: 0.265815, acc.: 57.81%] [G loss: 0.334476]\n",
      "epoch:1 step:1526 [D loss: 0.249169, acc.: 59.38%] [G loss: 0.388850]\n",
      "epoch:1 step:1527 [D loss: 0.235277, acc.: 60.94%] [G loss: 0.331039]\n",
      "epoch:1 step:1528 [D loss: 0.228125, acc.: 60.94%] [G loss: 0.361529]\n",
      "epoch:1 step:1529 [D loss: 0.258190, acc.: 51.56%] [G loss: 0.330005]\n",
      "epoch:1 step:1530 [D loss: 0.260526, acc.: 54.69%] [G loss: 0.365919]\n",
      "epoch:1 step:1531 [D loss: 0.245460, acc.: 57.81%] [G loss: 0.365408]\n",
      "epoch:1 step:1532 [D loss: 0.231083, acc.: 58.59%] [G loss: 0.335828]\n",
      "epoch:1 step:1533 [D loss: 0.238882, acc.: 57.81%] [G loss: 0.353960]\n",
      "epoch:1 step:1534 [D loss: 0.229022, acc.: 63.28%] [G loss: 0.348796]\n",
      "epoch:1 step:1535 [D loss: 0.257009, acc.: 57.03%] [G loss: 0.324749]\n",
      "epoch:1 step:1536 [D loss: 0.234173, acc.: 63.28%] [G loss: 0.345903]\n",
      "epoch:1 step:1537 [D loss: 0.225625, acc.: 61.72%] [G loss: 0.349699]\n",
      "epoch:1 step:1538 [D loss: 0.245505, acc.: 58.59%] [G loss: 0.337668]\n",
      "epoch:1 step:1539 [D loss: 0.223087, acc.: 64.06%] [G loss: 0.350021]\n",
      "epoch:1 step:1540 [D loss: 0.238429, acc.: 60.94%] [G loss: 0.320149]\n",
      "epoch:1 step:1541 [D loss: 0.262295, acc.: 53.12%] [G loss: 0.316948]\n",
      "epoch:1 step:1542 [D loss: 0.233777, acc.: 61.72%] [G loss: 0.320893]\n",
      "epoch:1 step:1543 [D loss: 0.256213, acc.: 57.03%] [G loss: 0.321208]\n",
      "epoch:1 step:1544 [D loss: 0.257306, acc.: 53.91%] [G loss: 0.332636]\n",
      "epoch:1 step:1545 [D loss: 0.234509, acc.: 65.62%] [G loss: 0.359432]\n",
      "epoch:1 step:1546 [D loss: 0.218274, acc.: 62.50%] [G loss: 0.350768]\n",
      "epoch:1 step:1547 [D loss: 0.232097, acc.: 59.38%] [G loss: 0.373641]\n",
      "epoch:1 step:1548 [D loss: 0.228788, acc.: 61.72%] [G loss: 0.374582]\n",
      "epoch:1 step:1549 [D loss: 0.230109, acc.: 63.28%] [G loss: 0.383097]\n",
      "epoch:1 step:1550 [D loss: 0.226897, acc.: 63.28%] [G loss: 0.373413]\n",
      "epoch:1 step:1551 [D loss: 0.234249, acc.: 60.94%] [G loss: 0.329255]\n",
      "epoch:1 step:1552 [D loss: 0.227755, acc.: 65.62%] [G loss: 0.364265]\n",
      "epoch:1 step:1553 [D loss: 0.233301, acc.: 59.38%] [G loss: 0.375180]\n",
      "epoch:1 step:1554 [D loss: 0.241683, acc.: 60.16%] [G loss: 0.369802]\n",
      "epoch:1 step:1555 [D loss: 0.243042, acc.: 59.38%] [G loss: 0.325722]\n",
      "epoch:1 step:1556 [D loss: 0.229798, acc.: 60.94%] [G loss: 0.316496]\n",
      "epoch:1 step:1557 [D loss: 0.241151, acc.: 61.72%] [G loss: 0.323275]\n",
      "epoch:1 step:1558 [D loss: 0.232677, acc.: 56.25%] [G loss: 0.312582]\n",
      "epoch:1 step:1559 [D loss: 0.248470, acc.: 54.69%] [G loss: 0.309360]\n",
      "epoch:1 step:1560 [D loss: 0.222119, acc.: 66.41%] [G loss: 0.343534]\n",
      "epoch:1 step:1561 [D loss: 0.231814, acc.: 60.16%] [G loss: 0.330231]\n",
      "epoch:1 step:1562 [D loss: 0.249293, acc.: 56.25%] [G loss: 0.343179]\n",
      "epoch:1 step:1563 [D loss: 0.245829, acc.: 59.38%] [G loss: 0.331715]\n",
      "epoch:1 step:1564 [D loss: 0.229214, acc.: 63.28%] [G loss: 0.364074]\n",
      "epoch:1 step:1565 [D loss: 0.233077, acc.: 61.72%] [G loss: 0.344755]\n",
      "epoch:1 step:1566 [D loss: 0.240012, acc.: 56.25%] [G loss: 0.384224]\n",
      "epoch:1 step:1567 [D loss: 0.247817, acc.: 56.25%] [G loss: 0.350023]\n",
      "epoch:1 step:1568 [D loss: 0.221292, acc.: 63.28%] [G loss: 0.318523]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:1 step:1569 [D loss: 0.221294, acc.: 63.28%] [G loss: 0.319983]\n",
      "epoch:1 step:1570 [D loss: 0.205646, acc.: 68.75%] [G loss: 0.321229]\n",
      "epoch:1 step:1571 [D loss: 0.254567, acc.: 54.69%] [G loss: 0.352190]\n",
      "epoch:1 step:1572 [D loss: 0.230711, acc.: 61.72%] [G loss: 0.306081]\n",
      "epoch:1 step:1573 [D loss: 0.265707, acc.: 56.25%] [G loss: 0.356103]\n",
      "epoch:1 step:1574 [D loss: 0.258689, acc.: 57.03%] [G loss: 0.347662]\n",
      "epoch:1 step:1575 [D loss: 0.244480, acc.: 55.47%] [G loss: 0.335306]\n",
      "epoch:1 step:1576 [D loss: 0.237426, acc.: 60.94%] [G loss: 0.366161]\n",
      "epoch:1 step:1577 [D loss: 0.239591, acc.: 60.16%] [G loss: 0.358866]\n",
      "epoch:1 step:1578 [D loss: 0.265397, acc.: 51.56%] [G loss: 0.289238]\n",
      "epoch:1 step:1579 [D loss: 0.218797, acc.: 65.62%] [G loss: 0.370819]\n",
      "epoch:1 step:1580 [D loss: 0.241217, acc.: 57.03%] [G loss: 0.330598]\n",
      "epoch:1 step:1581 [D loss: 0.247852, acc.: 57.03%] [G loss: 0.340452]\n",
      "epoch:1 step:1582 [D loss: 0.244750, acc.: 57.03%] [G loss: 0.337605]\n",
      "epoch:1 step:1583 [D loss: 0.264950, acc.: 50.00%] [G loss: 0.310353]\n",
      "epoch:1 step:1584 [D loss: 0.243824, acc.: 59.38%] [G loss: 0.359342]\n",
      "epoch:1 step:1585 [D loss: 0.230937, acc.: 60.94%] [G loss: 0.313236]\n",
      "epoch:1 step:1586 [D loss: 0.262852, acc.: 55.47%] [G loss: 0.322482]\n",
      "epoch:1 step:1587 [D loss: 0.215916, acc.: 63.28%] [G loss: 0.344248]\n",
      "epoch:1 step:1588 [D loss: 0.271101, acc.: 53.12%] [G loss: 0.322734]\n",
      "epoch:1 step:1589 [D loss: 0.246995, acc.: 57.03%] [G loss: 0.341655]\n",
      "epoch:1 step:1590 [D loss: 0.211928, acc.: 67.19%] [G loss: 0.320806]\n",
      "epoch:1 step:1591 [D loss: 0.242008, acc.: 56.25%] [G loss: 0.344411]\n",
      "epoch:1 step:1592 [D loss: 0.237044, acc.: 57.81%] [G loss: 0.330433]\n",
      "epoch:1 step:1593 [D loss: 0.267253, acc.: 58.59%] [G loss: 0.362341]\n",
      "epoch:1 step:1594 [D loss: 0.215976, acc.: 62.50%] [G loss: 0.305768]\n",
      "epoch:1 step:1595 [D loss: 0.231228, acc.: 58.59%] [G loss: 0.335926]\n",
      "epoch:1 step:1596 [D loss: 0.232252, acc.: 60.16%] [G loss: 0.324855]\n",
      "epoch:1 step:1597 [D loss: 0.225314, acc.: 64.06%] [G loss: 0.341391]\n",
      "epoch:1 step:1598 [D loss: 0.241006, acc.: 57.03%] [G loss: 0.319871]\n",
      "epoch:1 step:1599 [D loss: 0.246180, acc.: 57.03%] [G loss: 0.297316]\n",
      "epoch:1 step:1600 [D loss: 0.234391, acc.: 60.16%] [G loss: 0.321094]\n",
      "epoch:1 step:1601 [D loss: 0.226666, acc.: 60.94%] [G loss: 0.341624]\n",
      "epoch:1 step:1602 [D loss: 0.242445, acc.: 58.59%] [G loss: 0.346674]\n",
      "epoch:1 step:1603 [D loss: 0.234990, acc.: 63.28%] [G loss: 0.377694]\n",
      "epoch:1 step:1604 [D loss: 0.235958, acc.: 59.38%] [G loss: 0.328509]\n",
      "epoch:1 step:1605 [D loss: 0.231540, acc.: 65.62%] [G loss: 0.327898]\n",
      "epoch:1 step:1606 [D loss: 0.246486, acc.: 61.72%] [G loss: 0.333610]\n",
      "epoch:1 step:1607 [D loss: 0.242330, acc.: 55.47%] [G loss: 0.337535]\n",
      "epoch:1 step:1608 [D loss: 0.240247, acc.: 58.59%] [G loss: 0.370493]\n",
      "epoch:1 step:1609 [D loss: 0.230111, acc.: 63.28%] [G loss: 0.347181]\n",
      "epoch:1 step:1610 [D loss: 0.237147, acc.: 57.81%] [G loss: 0.334339]\n",
      "epoch:1 step:1611 [D loss: 0.242230, acc.: 57.81%] [G loss: 0.327989]\n",
      "epoch:1 step:1612 [D loss: 0.237868, acc.: 56.25%] [G loss: 0.365297]\n",
      "epoch:1 step:1613 [D loss: 0.258834, acc.: 49.22%] [G loss: 0.326644]\n",
      "epoch:1 step:1614 [D loss: 0.241170, acc.: 55.47%] [G loss: 0.351272]\n",
      "epoch:1 step:1615 [D loss: 0.232922, acc.: 58.59%] [G loss: 0.362007]\n",
      "epoch:1 step:1616 [D loss: 0.244001, acc.: 57.81%] [G loss: 0.327778]\n",
      "epoch:1 step:1617 [D loss: 0.251281, acc.: 55.47%] [G loss: 0.377649]\n",
      "epoch:1 step:1618 [D loss: 0.236087, acc.: 58.59%] [G loss: 0.296467]\n",
      "epoch:1 step:1619 [D loss: 0.224778, acc.: 63.28%] [G loss: 0.355010]\n",
      "epoch:1 step:1620 [D loss: 0.216432, acc.: 65.62%] [G loss: 0.344220]\n",
      "epoch:1 step:1621 [D loss: 0.231152, acc.: 64.06%] [G loss: 0.309108]\n",
      "epoch:1 step:1622 [D loss: 0.215925, acc.: 67.97%] [G loss: 0.331206]\n",
      "epoch:1 step:1623 [D loss: 0.233465, acc.: 59.38%] [G loss: 0.341119]\n",
      "epoch:1 step:1624 [D loss: 0.253073, acc.: 54.69%] [G loss: 0.325838]\n",
      "epoch:1 step:1625 [D loss: 0.237106, acc.: 62.50%] [G loss: 0.346105]\n",
      "epoch:1 step:1626 [D loss: 0.262901, acc.: 50.78%] [G loss: 0.329150]\n",
      "epoch:1 step:1627 [D loss: 0.217918, acc.: 67.19%] [G loss: 0.327064]\n",
      "epoch:1 step:1628 [D loss: 0.240256, acc.: 63.28%] [G loss: 0.341657]\n",
      "epoch:1 step:1629 [D loss: 0.247584, acc.: 57.03%] [G loss: 0.328543]\n",
      "epoch:1 step:1630 [D loss: 0.244465, acc.: 58.59%] [G loss: 0.328738]\n",
      "epoch:1 step:1631 [D loss: 0.220432, acc.: 65.62%] [G loss: 0.361411]\n",
      "epoch:1 step:1632 [D loss: 0.253826, acc.: 57.03%] [G loss: 0.330529]\n",
      "epoch:1 step:1633 [D loss: 0.249999, acc.: 54.69%] [G loss: 0.319198]\n",
      "epoch:1 step:1634 [D loss: 0.245661, acc.: 57.03%] [G loss: 0.327608]\n",
      "epoch:1 step:1635 [D loss: 0.212498, acc.: 68.75%] [G loss: 0.364092]\n",
      "epoch:1 step:1636 [D loss: 0.236355, acc.: 56.25%] [G loss: 0.348391]\n",
      "epoch:1 step:1637 [D loss: 0.206161, acc.: 68.75%] [G loss: 0.336834]\n",
      "epoch:1 step:1638 [D loss: 0.221162, acc.: 64.84%] [G loss: 0.374197]\n",
      "epoch:1 step:1639 [D loss: 0.237730, acc.: 59.38%] [G loss: 0.340853]\n",
      "epoch:1 step:1640 [D loss: 0.258398, acc.: 55.47%] [G loss: 0.377247]\n",
      "epoch:1 step:1641 [D loss: 0.231128, acc.: 63.28%] [G loss: 0.361447]\n",
      "epoch:1 step:1642 [D loss: 0.239180, acc.: 60.16%] [G loss: 0.365156]\n",
      "epoch:1 step:1643 [D loss: 0.244736, acc.: 57.81%] [G loss: 0.325764]\n",
      "epoch:1 step:1644 [D loss: 0.230266, acc.: 61.72%] [G loss: 0.319176]\n",
      "epoch:1 step:1645 [D loss: 0.222950, acc.: 64.84%] [G loss: 0.313342]\n",
      "epoch:1 step:1646 [D loss: 0.245191, acc.: 55.47%] [G loss: 0.356554]\n",
      "epoch:1 step:1647 [D loss: 0.213890, acc.: 61.72%] [G loss: 0.333190]\n",
      "epoch:1 step:1648 [D loss: 0.247153, acc.: 57.03%] [G loss: 0.291393]\n",
      "epoch:1 step:1649 [D loss: 0.226856, acc.: 61.72%] [G loss: 0.353188]\n",
      "epoch:1 step:1650 [D loss: 0.229552, acc.: 61.72%] [G loss: 0.324654]\n",
      "epoch:1 step:1651 [D loss: 0.258532, acc.: 55.47%] [G loss: 0.317733]\n",
      "epoch:1 step:1652 [D loss: 0.237476, acc.: 57.03%] [G loss: 0.325665]\n",
      "epoch:1 step:1653 [D loss: 0.241595, acc.: 60.94%] [G loss: 0.335255]\n",
      "epoch:1 step:1654 [D loss: 0.231450, acc.: 62.50%] [G loss: 0.308452]\n",
      "epoch:1 step:1655 [D loss: 0.238702, acc.: 60.94%] [G loss: 0.306327]\n",
      "epoch:1 step:1656 [D loss: 0.266554, acc.: 54.69%] [G loss: 0.312373]\n",
      "epoch:1 step:1657 [D loss: 0.211430, acc.: 66.41%] [G loss: 0.348064]\n",
      "epoch:1 step:1658 [D loss: 0.211341, acc.: 67.19%] [G loss: 0.343496]\n",
      "epoch:1 step:1659 [D loss: 0.222062, acc.: 63.28%] [G loss: 0.320087]\n",
      "epoch:1 step:1660 [D loss: 0.220938, acc.: 67.97%] [G loss: 0.335207]\n",
      "epoch:1 step:1661 [D loss: 0.236617, acc.: 58.59%] [G loss: 0.353411]\n",
      "epoch:1 step:1662 [D loss: 0.239189, acc.: 58.59%] [G loss: 0.292144]\n",
      "epoch:1 step:1663 [D loss: 0.225127, acc.: 62.50%] [G loss: 0.351117]\n",
      "epoch:1 step:1664 [D loss: 0.243706, acc.: 58.59%] [G loss: 0.377390]\n",
      "epoch:1 step:1665 [D loss: 0.242915, acc.: 60.16%] [G loss: 0.359246]\n",
      "epoch:1 step:1666 [D loss: 0.250738, acc.: 57.03%] [G loss: 0.370003]\n",
      "epoch:1 step:1667 [D loss: 0.249621, acc.: 56.25%] [G loss: 0.309166]\n",
      "epoch:1 step:1668 [D loss: 0.238323, acc.: 62.50%] [G loss: 0.356712]\n",
      "epoch:1 step:1669 [D loss: 0.229200, acc.: 60.16%] [G loss: 0.286797]\n",
      "epoch:1 step:1670 [D loss: 0.253714, acc.: 56.25%] [G loss: 0.309094]\n",
      "epoch:1 step:1671 [D loss: 0.230798, acc.: 63.28%] [G loss: 0.319923]\n",
      "epoch:1 step:1672 [D loss: 0.238680, acc.: 58.59%] [G loss: 0.339898]\n",
      "epoch:1 step:1673 [D loss: 0.240703, acc.: 55.47%] [G loss: 0.317579]\n",
      "epoch:1 step:1674 [D loss: 0.267871, acc.: 53.12%] [G loss: 0.331585]\n",
      "epoch:1 step:1675 [D loss: 0.231931, acc.: 62.50%] [G loss: 0.348796]\n",
      "epoch:1 step:1676 [D loss: 0.241610, acc.: 60.94%] [G loss: 0.340425]\n",
      "epoch:1 step:1677 [D loss: 0.206141, acc.: 68.75%] [G loss: 0.311343]\n",
      "epoch:1 step:1678 [D loss: 0.240196, acc.: 60.16%] [G loss: 0.344502]\n",
      "epoch:1 step:1679 [D loss: 0.230901, acc.: 59.38%] [G loss: 0.368382]\n",
      "epoch:1 step:1680 [D loss: 0.241815, acc.: 57.03%] [G loss: 0.339495]\n",
      "epoch:1 step:1681 [D loss: 0.225497, acc.: 67.19%] [G loss: 0.323988]\n",
      "epoch:1 step:1682 [D loss: 0.244742, acc.: 54.69%] [G loss: 0.305946]\n",
      "epoch:1 step:1683 [D loss: 0.220132, acc.: 62.50%] [G loss: 0.386328]\n",
      "epoch:1 step:1684 [D loss: 0.245820, acc.: 57.81%] [G loss: 0.356875]\n",
      "epoch:1 step:1685 [D loss: 0.245455, acc.: 54.69%] [G loss: 0.315279]\n",
      "epoch:1 step:1686 [D loss: 0.259643, acc.: 54.69%] [G loss: 0.330464]\n",
      "epoch:1 step:1687 [D loss: 0.214176, acc.: 67.97%] [G loss: 0.364458]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:1 step:1688 [D loss: 0.235839, acc.: 58.59%] [G loss: 0.315905]\n",
      "epoch:1 step:1689 [D loss: 0.236617, acc.: 57.81%] [G loss: 0.362200]\n",
      "epoch:1 step:1690 [D loss: 0.231327, acc.: 62.50%] [G loss: 0.368367]\n",
      "epoch:1 step:1691 [D loss: 0.238425, acc.: 61.72%] [G loss: 0.358023]\n",
      "epoch:1 step:1692 [D loss: 0.231085, acc.: 62.50%] [G loss: 0.382167]\n",
      "epoch:1 step:1693 [D loss: 0.225082, acc.: 60.16%] [G loss: 0.364685]\n",
      "epoch:1 step:1694 [D loss: 0.249446, acc.: 58.59%] [G loss: 0.316368]\n",
      "epoch:1 step:1695 [D loss: 0.251397, acc.: 56.25%] [G loss: 0.333110]\n",
      "epoch:1 step:1696 [D loss: 0.231073, acc.: 60.16%] [G loss: 0.360566]\n",
      "epoch:1 step:1697 [D loss: 0.256312, acc.: 57.03%] [G loss: 0.348742]\n",
      "epoch:1 step:1698 [D loss: 0.260066, acc.: 53.12%] [G loss: 0.342722]\n",
      "epoch:1 step:1699 [D loss: 0.267295, acc.: 52.34%] [G loss: 0.357309]\n",
      "epoch:1 step:1700 [D loss: 0.228306, acc.: 63.28%] [G loss: 0.311737]\n",
      "epoch:1 step:1701 [D loss: 0.235501, acc.: 62.50%] [G loss: 0.345279]\n",
      "epoch:1 step:1702 [D loss: 0.247894, acc.: 54.69%] [G loss: 0.332748]\n",
      "epoch:1 step:1703 [D loss: 0.231722, acc.: 60.16%] [G loss: 0.354038]\n",
      "epoch:1 step:1704 [D loss: 0.271637, acc.: 50.00%] [G loss: 0.302987]\n",
      "epoch:1 step:1705 [D loss: 0.229385, acc.: 59.38%] [G loss: 0.328007]\n",
      "epoch:1 step:1706 [D loss: 0.235141, acc.: 58.59%] [G loss: 0.299386]\n",
      "epoch:1 step:1707 [D loss: 0.219705, acc.: 66.41%] [G loss: 0.328660]\n",
      "epoch:1 step:1708 [D loss: 0.252986, acc.: 57.03%] [G loss: 0.319235]\n",
      "epoch:1 step:1709 [D loss: 0.239039, acc.: 57.03%] [G loss: 0.344202]\n",
      "epoch:1 step:1710 [D loss: 0.247748, acc.: 59.38%] [G loss: 0.327306]\n",
      "epoch:1 step:1711 [D loss: 0.252997, acc.: 58.59%] [G loss: 0.359803]\n",
      "epoch:1 step:1712 [D loss: 0.219092, acc.: 64.06%] [G loss: 0.327239]\n",
      "epoch:1 step:1713 [D loss: 0.215570, acc.: 67.97%] [G loss: 0.390935]\n",
      "epoch:1 step:1714 [D loss: 0.221166, acc.: 62.50%] [G loss: 0.337618]\n",
      "epoch:1 step:1715 [D loss: 0.221837, acc.: 61.72%] [G loss: 0.311741]\n",
      "epoch:1 step:1716 [D loss: 0.223588, acc.: 64.84%] [G loss: 0.299668]\n",
      "epoch:1 step:1717 [D loss: 0.238929, acc.: 57.81%] [G loss: 0.345097]\n",
      "epoch:1 step:1718 [D loss: 0.268284, acc.: 45.31%] [G loss: 0.284660]\n",
      "epoch:1 step:1719 [D loss: 0.237936, acc.: 61.72%] [G loss: 0.294206]\n",
      "epoch:1 step:1720 [D loss: 0.235038, acc.: 57.03%] [G loss: 0.346784]\n",
      "epoch:1 step:1721 [D loss: 0.254218, acc.: 54.69%] [G loss: 0.323701]\n",
      "epoch:1 step:1722 [D loss: 0.249408, acc.: 56.25%] [G loss: 0.304681]\n",
      "epoch:1 step:1723 [D loss: 0.239153, acc.: 62.50%] [G loss: 0.327499]\n",
      "epoch:1 step:1724 [D loss: 0.229667, acc.: 64.84%] [G loss: 0.303368]\n",
      "epoch:1 step:1725 [D loss: 0.230751, acc.: 63.28%] [G loss: 0.330385]\n",
      "epoch:1 step:1726 [D loss: 0.231189, acc.: 53.91%] [G loss: 0.344208]\n",
      "epoch:1 step:1727 [D loss: 0.266898, acc.: 53.12%] [G loss: 0.345541]\n",
      "epoch:1 step:1728 [D loss: 0.258042, acc.: 51.56%] [G loss: 0.340954]\n",
      "epoch:1 step:1729 [D loss: 0.256506, acc.: 50.00%] [G loss: 0.328627]\n",
      "epoch:1 step:1730 [D loss: 0.254642, acc.: 52.34%] [G loss: 0.306941]\n",
      "epoch:1 step:1731 [D loss: 0.220664, acc.: 64.06%] [G loss: 0.343810]\n",
      "epoch:1 step:1732 [D loss: 0.241808, acc.: 56.25%] [G loss: 0.326830]\n",
      "epoch:1 step:1733 [D loss: 0.224693, acc.: 64.84%] [G loss: 0.272316]\n",
      "epoch:1 step:1734 [D loss: 0.252330, acc.: 57.81%] [G loss: 0.333996]\n",
      "epoch:1 step:1735 [D loss: 0.230162, acc.: 64.06%] [G loss: 0.311938]\n",
      "epoch:1 step:1736 [D loss: 0.248318, acc.: 57.81%] [G loss: 0.339845]\n",
      "epoch:1 step:1737 [D loss: 0.260545, acc.: 57.03%] [G loss: 0.328777]\n",
      "epoch:1 step:1738 [D loss: 0.240891, acc.: 56.25%] [G loss: 0.340545]\n",
      "epoch:1 step:1739 [D loss: 0.241377, acc.: 60.16%] [G loss: 0.365923]\n",
      "epoch:1 step:1740 [D loss: 0.237685, acc.: 56.25%] [G loss: 0.364727]\n",
      "epoch:1 step:1741 [D loss: 0.226767, acc.: 61.72%] [G loss: 0.347978]\n",
      "epoch:1 step:1742 [D loss: 0.215613, acc.: 67.19%] [G loss: 0.313436]\n",
      "epoch:1 step:1743 [D loss: 0.237174, acc.: 59.38%] [G loss: 0.340654]\n",
      "epoch:1 step:1744 [D loss: 0.228282, acc.: 67.19%] [G loss: 0.340605]\n",
      "epoch:1 step:1745 [D loss: 0.245598, acc.: 58.59%] [G loss: 0.311415]\n",
      "epoch:1 step:1746 [D loss: 0.247666, acc.: 57.03%] [G loss: 0.346566]\n",
      "epoch:1 step:1747 [D loss: 0.234410, acc.: 60.94%] [G loss: 0.359614]\n",
      "epoch:1 step:1748 [D loss: 0.250236, acc.: 60.94%] [G loss: 0.364363]\n",
      "epoch:1 step:1749 [D loss: 0.236462, acc.: 59.38%] [G loss: 0.325373]\n",
      "epoch:1 step:1750 [D loss: 0.244021, acc.: 56.25%] [G loss: 0.350287]\n",
      "epoch:1 step:1751 [D loss: 0.255491, acc.: 57.03%] [G loss: 0.298578]\n",
      "epoch:1 step:1752 [D loss: 0.231950, acc.: 58.59%] [G loss: 0.298251]\n",
      "epoch:1 step:1753 [D loss: 0.235389, acc.: 60.16%] [G loss: 0.318841]\n",
      "epoch:1 step:1754 [D loss: 0.239551, acc.: 62.50%] [G loss: 0.282252]\n",
      "epoch:1 step:1755 [D loss: 0.243300, acc.: 54.69%] [G loss: 0.334478]\n",
      "epoch:1 step:1756 [D loss: 0.242574, acc.: 57.81%] [G loss: 0.316451]\n",
      "epoch:1 step:1757 [D loss: 0.251703, acc.: 53.12%] [G loss: 0.337875]\n",
      "epoch:1 step:1758 [D loss: 0.230406, acc.: 58.59%] [G loss: 0.313134]\n",
      "epoch:1 step:1759 [D loss: 0.274637, acc.: 51.56%] [G loss: 0.318379]\n",
      "epoch:1 step:1760 [D loss: 0.223727, acc.: 62.50%] [G loss: 0.318664]\n",
      "epoch:1 step:1761 [D loss: 0.231542, acc.: 60.16%] [G loss: 0.308725]\n",
      "epoch:1 step:1762 [D loss: 0.253904, acc.: 52.34%] [G loss: 0.310838]\n",
      "epoch:1 step:1763 [D loss: 0.220019, acc.: 63.28%] [G loss: 0.336709]\n",
      "epoch:1 step:1764 [D loss: 0.233023, acc.: 57.81%] [G loss: 0.331596]\n",
      "epoch:1 step:1765 [D loss: 0.248157, acc.: 57.81%] [G loss: 0.324934]\n",
      "epoch:1 step:1766 [D loss: 0.259556, acc.: 50.78%] [G loss: 0.316895]\n",
      "epoch:1 step:1767 [D loss: 0.256809, acc.: 55.47%] [G loss: 0.311286]\n",
      "epoch:1 step:1768 [D loss: 0.235596, acc.: 61.72%] [G loss: 0.320860]\n",
      "epoch:1 step:1769 [D loss: 0.229158, acc.: 56.25%] [G loss: 0.321622]\n",
      "epoch:1 step:1770 [D loss: 0.237530, acc.: 64.84%] [G loss: 0.311475]\n",
      "epoch:1 step:1771 [D loss: 0.233717, acc.: 62.50%] [G loss: 0.359297]\n",
      "epoch:1 step:1772 [D loss: 0.242843, acc.: 56.25%] [G loss: 0.359969]\n",
      "epoch:1 step:1773 [D loss: 0.239606, acc.: 60.16%] [G loss: 0.346274]\n",
      "epoch:1 step:1774 [D loss: 0.282623, acc.: 42.19%] [G loss: 0.312251]\n",
      "epoch:1 step:1775 [D loss: 0.240265, acc.: 58.59%] [G loss: 0.336946]\n",
      "epoch:1 step:1776 [D loss: 0.249048, acc.: 53.91%] [G loss: 0.349145]\n",
      "epoch:1 step:1777 [D loss: 0.216645, acc.: 62.50%] [G loss: 0.286776]\n",
      "epoch:1 step:1778 [D loss: 0.230005, acc.: 59.38%] [G loss: 0.329048]\n",
      "epoch:1 step:1779 [D loss: 0.235858, acc.: 64.84%] [G loss: 0.333989]\n",
      "epoch:1 step:1780 [D loss: 0.246491, acc.: 57.81%] [G loss: 0.314210]\n",
      "epoch:1 step:1781 [D loss: 0.229741, acc.: 61.72%] [G loss: 0.328115]\n",
      "epoch:1 step:1782 [D loss: 0.243996, acc.: 53.91%] [G loss: 0.337930]\n",
      "epoch:1 step:1783 [D loss: 0.253050, acc.: 57.03%] [G loss: 0.354704]\n",
      "epoch:1 step:1784 [D loss: 0.244301, acc.: 62.50%] [G loss: 0.369383]\n",
      "epoch:1 step:1785 [D loss: 0.215666, acc.: 63.28%] [G loss: 0.346586]\n",
      "epoch:1 step:1786 [D loss: 0.223618, acc.: 66.41%] [G loss: 0.380988]\n",
      "epoch:1 step:1787 [D loss: 0.237847, acc.: 60.94%] [G loss: 0.356223]\n",
      "epoch:1 step:1788 [D loss: 0.243678, acc.: 56.25%] [G loss: 0.317438]\n",
      "epoch:1 step:1789 [D loss: 0.199970, acc.: 69.53%] [G loss: 0.390662]\n",
      "epoch:1 step:1790 [D loss: 0.253569, acc.: 55.47%] [G loss: 0.359685]\n",
      "epoch:1 step:1791 [D loss: 0.264864, acc.: 50.78%] [G loss: 0.346568]\n",
      "epoch:1 step:1792 [D loss: 0.258459, acc.: 57.81%] [G loss: 0.348035]\n",
      "epoch:1 step:1793 [D loss: 0.220321, acc.: 67.19%] [G loss: 0.363635]\n",
      "epoch:1 step:1794 [D loss: 0.262842, acc.: 59.38%] [G loss: 0.323418]\n",
      "epoch:1 step:1795 [D loss: 0.247217, acc.: 60.16%] [G loss: 0.334249]\n",
      "epoch:1 step:1796 [D loss: 0.224584, acc.: 64.84%] [G loss: 0.384166]\n",
      "epoch:1 step:1797 [D loss: 0.234413, acc.: 63.28%] [G loss: 0.309448]\n",
      "epoch:1 step:1798 [D loss: 0.214641, acc.: 66.41%] [G loss: 0.335805]\n",
      "epoch:1 step:1799 [D loss: 0.273367, acc.: 57.03%] [G loss: 0.312829]\n",
      "epoch:1 step:1800 [D loss: 0.242128, acc.: 58.59%] [G loss: 0.372163]\n",
      "epoch:1 step:1801 [D loss: 0.244447, acc.: 62.50%] [G loss: 0.346205]\n",
      "epoch:1 step:1802 [D loss: 0.239574, acc.: 54.69%] [G loss: 0.305728]\n",
      "epoch:1 step:1803 [D loss: 0.238782, acc.: 60.16%] [G loss: 0.329582]\n",
      "epoch:1 step:1804 [D loss: 0.274890, acc.: 46.88%] [G loss: 0.307636]\n",
      "epoch:1 step:1805 [D loss: 0.245207, acc.: 56.25%] [G loss: 0.320145]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:1 step:1806 [D loss: 0.238432, acc.: 59.38%] [G loss: 0.335413]\n",
      "epoch:1 step:1807 [D loss: 0.241548, acc.: 57.03%] [G loss: 0.344058]\n",
      "epoch:1 step:1808 [D loss: 0.222735, acc.: 58.59%] [G loss: 0.370678]\n",
      "epoch:1 step:1809 [D loss: 0.252485, acc.: 57.03%] [G loss: 0.343576]\n",
      "epoch:1 step:1810 [D loss: 0.236529, acc.: 65.62%] [G loss: 0.344094]\n",
      "epoch:1 step:1811 [D loss: 0.245628, acc.: 54.69%] [G loss: 0.363097]\n",
      "epoch:1 step:1812 [D loss: 0.235265, acc.: 62.50%] [G loss: 0.361431]\n",
      "epoch:1 step:1813 [D loss: 0.258786, acc.: 51.56%] [G loss: 0.339076]\n",
      "epoch:1 step:1814 [D loss: 0.230313, acc.: 64.84%] [G loss: 0.348713]\n",
      "epoch:1 step:1815 [D loss: 0.253342, acc.: 54.69%] [G loss: 0.326592]\n",
      "epoch:1 step:1816 [D loss: 0.211574, acc.: 64.06%] [G loss: 0.340498]\n",
      "epoch:1 step:1817 [D loss: 0.241096, acc.: 57.81%] [G loss: 0.317435]\n",
      "epoch:1 step:1818 [D loss: 0.269075, acc.: 50.00%] [G loss: 0.329699]\n",
      "epoch:1 step:1819 [D loss: 0.222753, acc.: 64.06%] [G loss: 0.329680]\n",
      "epoch:1 step:1820 [D loss: 0.239017, acc.: 62.50%] [G loss: 0.360760]\n",
      "epoch:1 step:1821 [D loss: 0.258080, acc.: 57.03%] [G loss: 0.350976]\n",
      "epoch:1 step:1822 [D loss: 0.233400, acc.: 64.84%] [G loss: 0.372076]\n",
      "epoch:1 step:1823 [D loss: 0.237628, acc.: 61.72%] [G loss: 0.384954]\n",
      "epoch:1 step:1824 [D loss: 0.231737, acc.: 63.28%] [G loss: 0.315440]\n",
      "epoch:1 step:1825 [D loss: 0.255746, acc.: 53.91%] [G loss: 0.343344]\n",
      "epoch:1 step:1826 [D loss: 0.217689, acc.: 63.28%] [G loss: 0.352544]\n",
      "epoch:1 step:1827 [D loss: 0.236655, acc.: 59.38%] [G loss: 0.309900]\n",
      "epoch:1 step:1828 [D loss: 0.257883, acc.: 53.12%] [G loss: 0.376544]\n",
      "epoch:1 step:1829 [D loss: 0.240248, acc.: 57.03%] [G loss: 0.316066]\n",
      "epoch:1 step:1830 [D loss: 0.276284, acc.: 45.31%] [G loss: 0.337778]\n",
      "epoch:1 step:1831 [D loss: 0.251532, acc.: 57.03%] [G loss: 0.290634]\n",
      "epoch:1 step:1832 [D loss: 0.238843, acc.: 58.59%] [G loss: 0.353217]\n",
      "epoch:1 step:1833 [D loss: 0.260660, acc.: 57.81%] [G loss: 0.297062]\n",
      "epoch:1 step:1834 [D loss: 0.237687, acc.: 59.38%] [G loss: 0.349647]\n",
      "epoch:1 step:1835 [D loss: 0.230653, acc.: 63.28%] [G loss: 0.333452]\n",
      "epoch:1 step:1836 [D loss: 0.248398, acc.: 50.78%] [G loss: 0.338156]\n",
      "epoch:1 step:1837 [D loss: 0.234079, acc.: 60.16%] [G loss: 0.320739]\n",
      "epoch:1 step:1838 [D loss: 0.242937, acc.: 60.16%] [G loss: 0.327169]\n",
      "epoch:1 step:1839 [D loss: 0.221854, acc.: 63.28%] [G loss: 0.359004]\n",
      "epoch:1 step:1840 [D loss: 0.219626, acc.: 64.84%] [G loss: 0.404716]\n",
      "epoch:1 step:1841 [D loss: 0.229002, acc.: 60.16%] [G loss: 0.313500]\n",
      "epoch:1 step:1842 [D loss: 0.245001, acc.: 56.25%] [G loss: 0.328764]\n",
      "epoch:1 step:1843 [D loss: 0.241971, acc.: 57.03%] [G loss: 0.305187]\n",
      "epoch:1 step:1844 [D loss: 0.246632, acc.: 57.03%] [G loss: 0.353551]\n",
      "epoch:1 step:1845 [D loss: 0.244771, acc.: 58.59%] [G loss: 0.379147]\n",
      "epoch:1 step:1846 [D loss: 0.258030, acc.: 52.34%] [G loss: 0.327949]\n",
      "epoch:1 step:1847 [D loss: 0.243396, acc.: 57.03%] [G loss: 0.335444]\n",
      "epoch:1 step:1848 [D loss: 0.245335, acc.: 56.25%] [G loss: 0.350724]\n",
      "epoch:1 step:1849 [D loss: 0.263329, acc.: 50.78%] [G loss: 0.346268]\n",
      "epoch:1 step:1850 [D loss: 0.233174, acc.: 62.50%] [G loss: 0.344292]\n",
      "epoch:1 step:1851 [D loss: 0.253936, acc.: 58.59%] [G loss: 0.317596]\n",
      "epoch:1 step:1852 [D loss: 0.239058, acc.: 58.59%] [G loss: 0.290237]\n",
      "epoch:1 step:1853 [D loss: 0.219205, acc.: 64.84%] [G loss: 0.336164]\n",
      "epoch:1 step:1854 [D loss: 0.235607, acc.: 58.59%] [G loss: 0.298193]\n",
      "epoch:1 step:1855 [D loss: 0.225379, acc.: 64.06%] [G loss: 0.331345]\n",
      "epoch:1 step:1856 [D loss: 0.235636, acc.: 67.19%] [G loss: 0.346861]\n",
      "epoch:1 step:1857 [D loss: 0.243004, acc.: 55.47%] [G loss: 0.347700]\n",
      "epoch:1 step:1858 [D loss: 0.232728, acc.: 61.72%] [G loss: 0.328794]\n",
      "epoch:1 step:1859 [D loss: 0.237233, acc.: 58.59%] [G loss: 0.354463]\n",
      "epoch:1 step:1860 [D loss: 0.236982, acc.: 58.59%] [G loss: 0.316953]\n",
      "epoch:1 step:1861 [D loss: 0.262453, acc.: 50.78%] [G loss: 0.371661]\n",
      "epoch:1 step:1862 [D loss: 0.245488, acc.: 60.94%] [G loss: 0.359302]\n",
      "epoch:1 step:1863 [D loss: 0.218021, acc.: 67.19%] [G loss: 0.328283]\n",
      "epoch:1 step:1864 [D loss: 0.242776, acc.: 60.94%] [G loss: 0.322918]\n",
      "epoch:1 step:1865 [D loss: 0.245634, acc.: 59.38%] [G loss: 0.327112]\n",
      "epoch:1 step:1866 [D loss: 0.218201, acc.: 67.19%] [G loss: 0.331201]\n",
      "epoch:1 step:1867 [D loss: 0.236188, acc.: 63.28%] [G loss: 0.332777]\n",
      "epoch:1 step:1868 [D loss: 0.242015, acc.: 59.38%] [G loss: 0.315115]\n",
      "epoch:1 step:1869 [D loss: 0.223091, acc.: 64.84%] [G loss: 0.322464]\n",
      "epoch:1 step:1870 [D loss: 0.257313, acc.: 55.47%] [G loss: 0.332946]\n",
      "epoch:1 step:1871 [D loss: 0.251458, acc.: 58.59%] [G loss: 0.323656]\n",
      "epoch:1 step:1872 [D loss: 0.229118, acc.: 61.72%] [G loss: 0.351446]\n",
      "epoch:1 step:1873 [D loss: 0.219658, acc.: 68.75%] [G loss: 0.323574]\n",
      "epoch:1 step:1874 [D loss: 0.238809, acc.: 58.59%] [G loss: 0.358185]\n",
      "epoch:2 step:1875 [D loss: 0.228773, acc.: 60.16%] [G loss: 0.371955]\n",
      "epoch:2 step:1876 [D loss: 0.245001, acc.: 55.47%] [G loss: 0.290167]\n",
      "epoch:2 step:1877 [D loss: 0.245722, acc.: 58.59%] [G loss: 0.332198]\n",
      "epoch:2 step:1878 [D loss: 0.244145, acc.: 57.81%] [G loss: 0.363084]\n",
      "epoch:2 step:1879 [D loss: 0.234548, acc.: 64.06%] [G loss: 0.354640]\n",
      "epoch:2 step:1880 [D loss: 0.249787, acc.: 59.38%] [G loss: 0.341041]\n",
      "epoch:2 step:1881 [D loss: 0.228856, acc.: 59.38%] [G loss: 0.348916]\n",
      "epoch:2 step:1882 [D loss: 0.243404, acc.: 59.38%] [G loss: 0.342708]\n",
      "epoch:2 step:1883 [D loss: 0.223985, acc.: 60.16%] [G loss: 0.339866]\n",
      "epoch:2 step:1884 [D loss: 0.233065, acc.: 59.38%] [G loss: 0.267441]\n",
      "epoch:2 step:1885 [D loss: 0.244932, acc.: 54.69%] [G loss: 0.322518]\n",
      "epoch:2 step:1886 [D loss: 0.252200, acc.: 55.47%] [G loss: 0.328875]\n",
      "epoch:2 step:1887 [D loss: 0.256666, acc.: 53.91%] [G loss: 0.316672]\n",
      "epoch:2 step:1888 [D loss: 0.237498, acc.: 60.94%] [G loss: 0.302223]\n",
      "epoch:2 step:1889 [D loss: 0.241683, acc.: 58.59%] [G loss: 0.392639]\n",
      "epoch:2 step:1890 [D loss: 0.266679, acc.: 52.34%] [G loss: 0.315511]\n",
      "epoch:2 step:1891 [D loss: 0.242590, acc.: 57.03%] [G loss: 0.327168]\n",
      "epoch:2 step:1892 [D loss: 0.242914, acc.: 58.59%] [G loss: 0.352969]\n",
      "epoch:2 step:1893 [D loss: 0.253909, acc.: 56.25%] [G loss: 0.369109]\n",
      "epoch:2 step:1894 [D loss: 0.221453, acc.: 66.41%] [G loss: 0.356606]\n",
      "epoch:2 step:1895 [D loss: 0.263229, acc.: 53.91%] [G loss: 0.341320]\n",
      "epoch:2 step:1896 [D loss: 0.233341, acc.: 57.81%] [G loss: 0.298966]\n",
      "epoch:2 step:1897 [D loss: 0.256067, acc.: 53.91%] [G loss: 0.301626]\n",
      "epoch:2 step:1898 [D loss: 0.221195, acc.: 69.53%] [G loss: 0.308729]\n",
      "epoch:2 step:1899 [D loss: 0.231744, acc.: 60.16%] [G loss: 0.329379]\n",
      "epoch:2 step:1900 [D loss: 0.244454, acc.: 54.69%] [G loss: 0.341677]\n",
      "epoch:2 step:1901 [D loss: 0.232487, acc.: 60.16%] [G loss: 0.333845]\n",
      "epoch:2 step:1902 [D loss: 0.227292, acc.: 65.62%] [G loss: 0.329531]\n",
      "epoch:2 step:1903 [D loss: 0.253656, acc.: 53.91%] [G loss: 0.351299]\n",
      "epoch:2 step:1904 [D loss: 0.234735, acc.: 63.28%] [G loss: 0.334682]\n",
      "epoch:2 step:1905 [D loss: 0.254426, acc.: 52.34%] [G loss: 0.308158]\n",
      "epoch:2 step:1906 [D loss: 0.205013, acc.: 67.97%] [G loss: 0.358680]\n",
      "epoch:2 step:1907 [D loss: 0.236604, acc.: 57.81%] [G loss: 0.308193]\n",
      "epoch:2 step:1908 [D loss: 0.227231, acc.: 60.16%] [G loss: 0.350785]\n",
      "epoch:2 step:1909 [D loss: 0.239410, acc.: 63.28%] [G loss: 0.328886]\n",
      "epoch:2 step:1910 [D loss: 0.240971, acc.: 57.03%] [G loss: 0.324710]\n",
      "epoch:2 step:1911 [D loss: 0.246628, acc.: 53.91%] [G loss: 0.313333]\n",
      "epoch:2 step:1912 [D loss: 0.269307, acc.: 53.12%] [G loss: 0.335661]\n",
      "epoch:2 step:1913 [D loss: 0.220389, acc.: 65.62%] [G loss: 0.328283]\n",
      "epoch:2 step:1914 [D loss: 0.241391, acc.: 60.94%] [G loss: 0.338854]\n",
      "epoch:2 step:1915 [D loss: 0.211440, acc.: 66.41%] [G loss: 0.364209]\n",
      "epoch:2 step:1916 [D loss: 0.216596, acc.: 65.62%] [G loss: 0.366173]\n",
      "epoch:2 step:1917 [D loss: 0.248516, acc.: 56.25%] [G loss: 0.353328]\n",
      "epoch:2 step:1918 [D loss: 0.273700, acc.: 51.56%] [G loss: 0.318643]\n",
      "epoch:2 step:1919 [D loss: 0.250829, acc.: 57.03%] [G loss: 0.360534]\n",
      "epoch:2 step:1920 [D loss: 0.249321, acc.: 53.91%] [G loss: 0.330888]\n",
      "epoch:2 step:1921 [D loss: 0.260071, acc.: 53.91%] [G loss: 0.311877]\n",
      "epoch:2 step:1922 [D loss: 0.236592, acc.: 60.16%] [G loss: 0.358970]\n",
      "epoch:2 step:1923 [D loss: 0.233075, acc.: 63.28%] [G loss: 0.346327]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:2 step:1924 [D loss: 0.218744, acc.: 63.28%] [G loss: 0.331211]\n",
      "epoch:2 step:1925 [D loss: 0.230433, acc.: 67.97%] [G loss: 0.336873]\n",
      "epoch:2 step:1926 [D loss: 0.234443, acc.: 63.28%] [G loss: 0.317630]\n",
      "epoch:2 step:1927 [D loss: 0.258430, acc.: 52.34%] [G loss: 0.329347]\n",
      "epoch:2 step:1928 [D loss: 0.237638, acc.: 64.06%] [G loss: 0.335197]\n",
      "epoch:2 step:1929 [D loss: 0.238155, acc.: 60.16%] [G loss: 0.373396]\n",
      "epoch:2 step:1930 [D loss: 0.248656, acc.: 54.69%] [G loss: 0.328009]\n",
      "epoch:2 step:1931 [D loss: 0.230996, acc.: 64.84%] [G loss: 0.320847]\n",
      "epoch:2 step:1932 [D loss: 0.238939, acc.: 61.72%] [G loss: 0.366282]\n",
      "epoch:2 step:1933 [D loss: 0.242384, acc.: 57.81%] [G loss: 0.351149]\n",
      "epoch:2 step:1934 [D loss: 0.217611, acc.: 62.50%] [G loss: 0.331447]\n",
      "epoch:2 step:1935 [D loss: 0.249959, acc.: 58.59%] [G loss: 0.354136]\n",
      "epoch:2 step:1936 [D loss: 0.248516, acc.: 52.34%] [G loss: 0.303850]\n",
      "epoch:2 step:1937 [D loss: 0.223457, acc.: 62.50%] [G loss: 0.336915]\n",
      "epoch:2 step:1938 [D loss: 0.240461, acc.: 60.94%] [G loss: 0.317127]\n",
      "epoch:2 step:1939 [D loss: 0.236387, acc.: 60.94%] [G loss: 0.298264]\n",
      "epoch:2 step:1940 [D loss: 0.235559, acc.: 59.38%] [G loss: 0.297094]\n",
      "epoch:2 step:1941 [D loss: 0.261416, acc.: 47.66%] [G loss: 0.347434]\n",
      "epoch:2 step:1942 [D loss: 0.224177, acc.: 69.53%] [G loss: 0.352369]\n",
      "epoch:2 step:1943 [D loss: 0.244572, acc.: 60.16%] [G loss: 0.340012]\n",
      "epoch:2 step:1944 [D loss: 0.228705, acc.: 64.84%] [G loss: 0.311551]\n",
      "epoch:2 step:1945 [D loss: 0.250346, acc.: 57.03%] [G loss: 0.317466]\n",
      "epoch:2 step:1946 [D loss: 0.233054, acc.: 57.81%] [G loss: 0.339239]\n",
      "epoch:2 step:1947 [D loss: 0.250848, acc.: 60.94%] [G loss: 0.308699]\n",
      "epoch:2 step:1948 [D loss: 0.239906, acc.: 60.94%] [G loss: 0.319104]\n",
      "epoch:2 step:1949 [D loss: 0.233014, acc.: 56.25%] [G loss: 0.303587]\n",
      "epoch:2 step:1950 [D loss: 0.244489, acc.: 54.69%] [G loss: 0.323843]\n",
      "epoch:2 step:1951 [D loss: 0.253350, acc.: 52.34%] [G loss: 0.323308]\n",
      "epoch:2 step:1952 [D loss: 0.251862, acc.: 55.47%] [G loss: 0.330214]\n",
      "epoch:2 step:1953 [D loss: 0.235412, acc.: 58.59%] [G loss: 0.323564]\n",
      "epoch:2 step:1954 [D loss: 0.244920, acc.: 57.81%] [G loss: 0.352565]\n",
      "epoch:2 step:1955 [D loss: 0.233222, acc.: 61.72%] [G loss: 0.323800]\n",
      "epoch:2 step:1956 [D loss: 0.238581, acc.: 59.38%] [G loss: 0.333740]\n",
      "epoch:2 step:1957 [D loss: 0.270388, acc.: 47.66%] [G loss: 0.268233]\n",
      "epoch:2 step:1958 [D loss: 0.277257, acc.: 49.22%] [G loss: 0.329320]\n",
      "epoch:2 step:1959 [D loss: 0.241243, acc.: 57.03%] [G loss: 0.317463]\n",
      "epoch:2 step:1960 [D loss: 0.241640, acc.: 54.69%] [G loss: 0.328417]\n",
      "epoch:2 step:1961 [D loss: 0.246903, acc.: 60.16%] [G loss: 0.381730]\n",
      "epoch:2 step:1962 [D loss: 0.237072, acc.: 62.50%] [G loss: 0.308343]\n",
      "epoch:2 step:1963 [D loss: 0.268954, acc.: 55.47%] [G loss: 0.295287]\n",
      "epoch:2 step:1964 [D loss: 0.230071, acc.: 60.94%] [G loss: 0.321588]\n",
      "epoch:2 step:1965 [D loss: 0.246711, acc.: 58.59%] [G loss: 0.329720]\n",
      "epoch:2 step:1966 [D loss: 0.251634, acc.: 57.03%] [G loss: 0.351340]\n",
      "epoch:2 step:1967 [D loss: 0.260732, acc.: 54.69%] [G loss: 0.350292]\n",
      "epoch:2 step:1968 [D loss: 0.248944, acc.: 53.12%] [G loss: 0.337894]\n",
      "epoch:2 step:1969 [D loss: 0.228756, acc.: 60.16%] [G loss: 0.337052]\n",
      "epoch:2 step:1970 [D loss: 0.240976, acc.: 56.25%] [G loss: 0.325526]\n",
      "epoch:2 step:1971 [D loss: 0.213338, acc.: 68.75%] [G loss: 0.298587]\n",
      "epoch:2 step:1972 [D loss: 0.250131, acc.: 58.59%] [G loss: 0.372853]\n",
      "epoch:2 step:1973 [D loss: 0.267500, acc.: 48.44%] [G loss: 0.280346]\n",
      "epoch:2 step:1974 [D loss: 0.257213, acc.: 48.44%] [G loss: 0.317593]\n",
      "epoch:2 step:1975 [D loss: 0.257976, acc.: 50.78%] [G loss: 0.324117]\n",
      "epoch:2 step:1976 [D loss: 0.256993, acc.: 55.47%] [G loss: 0.319569]\n",
      "epoch:2 step:1977 [D loss: 0.233949, acc.: 59.38%] [G loss: 0.330616]\n",
      "epoch:2 step:1978 [D loss: 0.236373, acc.: 60.94%] [G loss: 0.366574]\n",
      "epoch:2 step:1979 [D loss: 0.227647, acc.: 63.28%] [G loss: 0.360696]\n",
      "epoch:2 step:1980 [D loss: 0.243809, acc.: 57.81%] [G loss: 0.356420]\n",
      "epoch:2 step:1981 [D loss: 0.236176, acc.: 57.03%] [G loss: 0.313828]\n",
      "epoch:2 step:1982 [D loss: 0.241413, acc.: 60.16%] [G loss: 0.363494]\n",
      "epoch:2 step:1983 [D loss: 0.236653, acc.: 58.59%] [G loss: 0.292435]\n",
      "epoch:2 step:1984 [D loss: 0.247295, acc.: 54.69%] [G loss: 0.350239]\n",
      "epoch:2 step:1985 [D loss: 0.233734, acc.: 60.16%] [G loss: 0.368236]\n",
      "epoch:2 step:1986 [D loss: 0.234270, acc.: 64.06%] [G loss: 0.362339]\n",
      "epoch:2 step:1987 [D loss: 0.242726, acc.: 57.81%] [G loss: 0.324656]\n",
      "epoch:2 step:1988 [D loss: 0.256696, acc.: 50.78%] [G loss: 0.370285]\n",
      "epoch:2 step:1989 [D loss: 0.231338, acc.: 59.38%] [G loss: 0.321796]\n",
      "epoch:2 step:1990 [D loss: 0.250292, acc.: 60.16%] [G loss: 0.356837]\n",
      "epoch:2 step:1991 [D loss: 0.236823, acc.: 60.16%] [G loss: 0.331920]\n",
      "epoch:2 step:1992 [D loss: 0.249976, acc.: 57.03%] [G loss: 0.358448]\n",
      "epoch:2 step:1993 [D loss: 0.250831, acc.: 54.69%] [G loss: 0.333477]\n",
      "epoch:2 step:1994 [D loss: 0.237466, acc.: 62.50%] [G loss: 0.349767]\n",
      "epoch:2 step:1995 [D loss: 0.230339, acc.: 57.81%] [G loss: 0.347734]\n",
      "epoch:2 step:1996 [D loss: 0.274921, acc.: 48.44%] [G loss: 0.347384]\n",
      "epoch:2 step:1997 [D loss: 0.220905, acc.: 65.62%] [G loss: 0.369481]\n",
      "epoch:2 step:1998 [D loss: 0.274222, acc.: 51.56%] [G loss: 0.332254]\n",
      "epoch:2 step:1999 [D loss: 0.259744, acc.: 54.69%] [G loss: 0.306941]\n",
      "epoch:2 step:2000 [D loss: 0.248991, acc.: 57.03%] [G loss: 0.342883]\n",
      "epoch:2 step:2001 [D loss: 0.224497, acc.: 63.28%] [G loss: 0.354660]\n",
      "epoch:2 step:2002 [D loss: 0.241190, acc.: 61.72%] [G loss: 0.372191]\n",
      "epoch:2 step:2003 [D loss: 0.233230, acc.: 56.25%] [G loss: 0.326913]\n",
      "epoch:2 step:2004 [D loss: 0.213133, acc.: 65.62%] [G loss: 0.317814]\n",
      "epoch:2 step:2005 [D loss: 0.246549, acc.: 60.16%] [G loss: 0.304573]\n",
      "epoch:2 step:2006 [D loss: 0.237944, acc.: 57.03%] [G loss: 0.344395]\n",
      "epoch:2 step:2007 [D loss: 0.243027, acc.: 60.16%] [G loss: 0.336925]\n",
      "epoch:2 step:2008 [D loss: 0.227629, acc.: 63.28%] [G loss: 0.331095]\n",
      "epoch:2 step:2009 [D loss: 0.225627, acc.: 62.50%] [G loss: 0.327022]\n",
      "epoch:2 step:2010 [D loss: 0.256712, acc.: 53.12%] [G loss: 0.326660]\n",
      "epoch:2 step:2011 [D loss: 0.231357, acc.: 62.50%] [G loss: 0.319593]\n",
      "epoch:2 step:2012 [D loss: 0.230463, acc.: 63.28%] [G loss: 0.345659]\n",
      "epoch:2 step:2013 [D loss: 0.218941, acc.: 63.28%] [G loss: 0.384429]\n",
      "epoch:2 step:2014 [D loss: 0.243080, acc.: 59.38%] [G loss: 0.365003]\n",
      "epoch:2 step:2015 [D loss: 0.272253, acc.: 53.12%] [G loss: 0.335727]\n",
      "epoch:2 step:2016 [D loss: 0.219806, acc.: 64.06%] [G loss: 0.330188]\n",
      "epoch:2 step:2017 [D loss: 0.245728, acc.: 55.47%] [G loss: 0.353772]\n",
      "epoch:2 step:2018 [D loss: 0.238129, acc.: 57.03%] [G loss: 0.367960]\n",
      "epoch:2 step:2019 [D loss: 0.227022, acc.: 63.28%] [G loss: 0.313750]\n",
      "epoch:2 step:2020 [D loss: 0.221189, acc.: 62.50%] [G loss: 0.321138]\n",
      "epoch:2 step:2021 [D loss: 0.222424, acc.: 60.16%] [G loss: 0.328861]\n",
      "epoch:2 step:2022 [D loss: 0.229256, acc.: 61.72%] [G loss: 0.353309]\n",
      "epoch:2 step:2023 [D loss: 0.253438, acc.: 52.34%] [G loss: 0.295836]\n",
      "epoch:2 step:2024 [D loss: 0.218909, acc.: 67.19%] [G loss: 0.371609]\n",
      "epoch:2 step:2025 [D loss: 0.254500, acc.: 54.69%] [G loss: 0.325944]\n",
      "epoch:2 step:2026 [D loss: 0.256111, acc.: 56.25%] [G loss: 0.331656]\n",
      "epoch:2 step:2027 [D loss: 0.239443, acc.: 63.28%] [G loss: 0.318755]\n",
      "epoch:2 step:2028 [D loss: 0.227768, acc.: 66.41%] [G loss: 0.301926]\n",
      "epoch:2 step:2029 [D loss: 0.258485, acc.: 54.69%] [G loss: 0.328515]\n",
      "epoch:2 step:2030 [D loss: 0.247666, acc.: 54.69%] [G loss: 0.314724]\n",
      "epoch:2 step:2031 [D loss: 0.225549, acc.: 62.50%] [G loss: 0.285077]\n",
      "epoch:2 step:2032 [D loss: 0.238529, acc.: 56.25%] [G loss: 0.321867]\n",
      "epoch:2 step:2033 [D loss: 0.240477, acc.: 66.41%] [G loss: 0.332241]\n",
      "epoch:2 step:2034 [D loss: 0.236289, acc.: 60.94%] [G loss: 0.298080]\n",
      "epoch:2 step:2035 [D loss: 0.229481, acc.: 64.06%] [G loss: 0.340490]\n",
      "epoch:2 step:2036 [D loss: 0.229757, acc.: 62.50%] [G loss: 0.319021]\n",
      "epoch:2 step:2037 [D loss: 0.239322, acc.: 58.59%] [G loss: 0.339402]\n",
      "epoch:2 step:2038 [D loss: 0.217418, acc.: 66.41%] [G loss: 0.348734]\n",
      "epoch:2 step:2039 [D loss: 0.245457, acc.: 55.47%] [G loss: 0.352060]\n",
      "epoch:2 step:2040 [D loss: 0.230361, acc.: 66.41%] [G loss: 0.340694]\n",
      "epoch:2 step:2041 [D loss: 0.220815, acc.: 67.19%] [G loss: 0.321111]\n",
      "epoch:2 step:2042 [D loss: 0.218278, acc.: 62.50%] [G loss: 0.315233]\n",
      "epoch:2 step:2043 [D loss: 0.249227, acc.: 49.22%] [G loss: 0.362283]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:2 step:2044 [D loss: 0.243043, acc.: 60.94%] [G loss: 0.317495]\n",
      "epoch:2 step:2045 [D loss: 0.225402, acc.: 60.94%] [G loss: 0.327171]\n",
      "epoch:2 step:2046 [D loss: 0.235298, acc.: 61.72%] [G loss: 0.300515]\n",
      "epoch:2 step:2047 [D loss: 0.243750, acc.: 53.91%] [G loss: 0.333833]\n",
      "epoch:2 step:2048 [D loss: 0.264850, acc.: 57.81%] [G loss: 0.374506]\n",
      "epoch:2 step:2049 [D loss: 0.226272, acc.: 64.84%] [G loss: 0.349573]\n",
      "epoch:2 step:2050 [D loss: 0.235740, acc.: 60.16%] [G loss: 0.337000]\n",
      "epoch:2 step:2051 [D loss: 0.236170, acc.: 60.16%] [G loss: 0.346790]\n",
      "epoch:2 step:2052 [D loss: 0.237577, acc.: 57.03%] [G loss: 0.349517]\n",
      "epoch:2 step:2053 [D loss: 0.254203, acc.: 47.66%] [G loss: 0.309398]\n",
      "epoch:2 step:2054 [D loss: 0.239836, acc.: 60.16%] [G loss: 0.352667]\n",
      "epoch:2 step:2055 [D loss: 0.242940, acc.: 60.94%] [G loss: 0.348471]\n",
      "epoch:2 step:2056 [D loss: 0.243963, acc.: 58.59%] [G loss: 0.309403]\n",
      "epoch:2 step:2057 [D loss: 0.250690, acc.: 51.56%] [G loss: 0.316054]\n",
      "epoch:2 step:2058 [D loss: 0.244137, acc.: 57.03%] [G loss: 0.353536]\n",
      "epoch:2 step:2059 [D loss: 0.232524, acc.: 60.16%] [G loss: 0.311164]\n",
      "epoch:2 step:2060 [D loss: 0.240464, acc.: 58.59%] [G loss: 0.325753]\n",
      "epoch:2 step:2061 [D loss: 0.258324, acc.: 55.47%] [G loss: 0.335978]\n",
      "epoch:2 step:2062 [D loss: 0.238587, acc.: 64.84%] [G loss: 0.336261]\n",
      "epoch:2 step:2063 [D loss: 0.244028, acc.: 57.81%] [G loss: 0.318269]\n",
      "epoch:2 step:2064 [D loss: 0.251691, acc.: 54.69%] [G loss: 0.334063]\n",
      "epoch:2 step:2065 [D loss: 0.202901, acc.: 69.53%] [G loss: 0.337905]\n",
      "epoch:2 step:2066 [D loss: 0.227143, acc.: 62.50%] [G loss: 0.333990]\n",
      "epoch:2 step:2067 [D loss: 0.236078, acc.: 58.59%] [G loss: 0.312999]\n",
      "epoch:2 step:2068 [D loss: 0.239773, acc.: 61.72%] [G loss: 0.327921]\n",
      "epoch:2 step:2069 [D loss: 0.255646, acc.: 53.12%] [G loss: 0.324072]\n",
      "epoch:2 step:2070 [D loss: 0.220319, acc.: 66.41%] [G loss: 0.343212]\n",
      "epoch:2 step:2071 [D loss: 0.250784, acc.: 55.47%] [G loss: 0.335896]\n",
      "epoch:2 step:2072 [D loss: 0.250382, acc.: 56.25%] [G loss: 0.281300]\n",
      "epoch:2 step:2073 [D loss: 0.246020, acc.: 55.47%] [G loss: 0.354470]\n",
      "epoch:2 step:2074 [D loss: 0.238936, acc.: 58.59%] [G loss: 0.328734]\n",
      "epoch:2 step:2075 [D loss: 0.243485, acc.: 56.25%] [G loss: 0.336061]\n",
      "epoch:2 step:2076 [D loss: 0.224277, acc.: 63.28%] [G loss: 0.319406]\n",
      "epoch:2 step:2077 [D loss: 0.241503, acc.: 58.59%] [G loss: 0.346147]\n",
      "epoch:2 step:2078 [D loss: 0.251881, acc.: 54.69%] [G loss: 0.299938]\n",
      "epoch:2 step:2079 [D loss: 0.240005, acc.: 58.59%] [G loss: 0.307677]\n",
      "epoch:2 step:2080 [D loss: 0.259661, acc.: 51.56%] [G loss: 0.323188]\n",
      "epoch:2 step:2081 [D loss: 0.233252, acc.: 61.72%] [G loss: 0.314759]\n",
      "epoch:2 step:2082 [D loss: 0.237771, acc.: 55.47%] [G loss: 0.326886]\n",
      "epoch:2 step:2083 [D loss: 0.258759, acc.: 48.44%] [G loss: 0.321994]\n",
      "epoch:2 step:2084 [D loss: 0.228516, acc.: 59.38%] [G loss: 0.322371]\n",
      "epoch:2 step:2085 [D loss: 0.245361, acc.: 57.81%] [G loss: 0.332424]\n",
      "epoch:2 step:2086 [D loss: 0.248505, acc.: 58.59%] [G loss: 0.323635]\n",
      "epoch:2 step:2087 [D loss: 0.221383, acc.: 65.62%] [G loss: 0.351754]\n",
      "epoch:2 step:2088 [D loss: 0.222071, acc.: 67.19%] [G loss: 0.364828]\n",
      "epoch:2 step:2089 [D loss: 0.251393, acc.: 57.81%] [G loss: 0.297219]\n",
      "epoch:2 step:2090 [D loss: 0.226442, acc.: 64.06%] [G loss: 0.330077]\n",
      "epoch:2 step:2091 [D loss: 0.242301, acc.: 62.50%] [G loss: 0.350555]\n",
      "epoch:2 step:2092 [D loss: 0.261078, acc.: 53.91%] [G loss: 0.328137]\n",
      "epoch:2 step:2093 [D loss: 0.233377, acc.: 61.72%] [G loss: 0.297637]\n",
      "epoch:2 step:2094 [D loss: 0.228281, acc.: 59.38%] [G loss: 0.324001]\n",
      "epoch:2 step:2095 [D loss: 0.226309, acc.: 63.28%] [G loss: 0.354337]\n",
      "epoch:2 step:2096 [D loss: 0.242238, acc.: 56.25%] [G loss: 0.338501]\n",
      "epoch:2 step:2097 [D loss: 0.258626, acc.: 50.78%] [G loss: 0.324257]\n",
      "epoch:2 step:2098 [D loss: 0.234898, acc.: 59.38%] [G loss: 0.322478]\n",
      "epoch:2 step:2099 [D loss: 0.247179, acc.: 59.38%] [G loss: 0.336008]\n",
      "epoch:2 step:2100 [D loss: 0.214485, acc.: 66.41%] [G loss: 0.318128]\n",
      "epoch:2 step:2101 [D loss: 0.233805, acc.: 59.38%] [G loss: 0.316130]\n",
      "epoch:2 step:2102 [D loss: 0.222732, acc.: 62.50%] [G loss: 0.332281]\n",
      "epoch:2 step:2103 [D loss: 0.234152, acc.: 59.38%] [G loss: 0.346056]\n",
      "epoch:2 step:2104 [D loss: 0.237195, acc.: 57.03%] [G loss: 0.353406]\n",
      "epoch:2 step:2105 [D loss: 0.256240, acc.: 54.69%] [G loss: 0.353938]\n",
      "epoch:2 step:2106 [D loss: 0.232281, acc.: 60.16%] [G loss: 0.355066]\n",
      "epoch:2 step:2107 [D loss: 0.240014, acc.: 60.94%] [G loss: 0.306429]\n",
      "epoch:2 step:2108 [D loss: 0.246756, acc.: 54.69%] [G loss: 0.330251]\n",
      "epoch:2 step:2109 [D loss: 0.240199, acc.: 60.16%] [G loss: 0.317541]\n",
      "epoch:2 step:2110 [D loss: 0.228696, acc.: 62.50%] [G loss: 0.322507]\n",
      "epoch:2 step:2111 [D loss: 0.261947, acc.: 55.47%] [G loss: 0.358832]\n",
      "epoch:2 step:2112 [D loss: 0.234808, acc.: 58.59%] [G loss: 0.366858]\n",
      "epoch:2 step:2113 [D loss: 0.225708, acc.: 62.50%] [G loss: 0.360437]\n",
      "epoch:2 step:2114 [D loss: 0.277388, acc.: 50.00%] [G loss: 0.360988]\n",
      "epoch:2 step:2115 [D loss: 0.260348, acc.: 53.12%] [G loss: 0.311079]\n",
      "epoch:2 step:2116 [D loss: 0.265244, acc.: 52.34%] [G loss: 0.294150]\n",
      "epoch:2 step:2117 [D loss: 0.221798, acc.: 65.62%] [G loss: 0.337597]\n",
      "epoch:2 step:2118 [D loss: 0.242197, acc.: 61.72%] [G loss: 0.329250]\n",
      "epoch:2 step:2119 [D loss: 0.255331, acc.: 49.22%] [G loss: 0.321967]\n",
      "epoch:2 step:2120 [D loss: 0.248300, acc.: 59.38%] [G loss: 0.384151]\n",
      "epoch:2 step:2121 [D loss: 0.260328, acc.: 49.22%] [G loss: 0.309825]\n",
      "epoch:2 step:2122 [D loss: 0.241980, acc.: 58.59%] [G loss: 0.341336]\n",
      "epoch:2 step:2123 [D loss: 0.229655, acc.: 65.62%] [G loss: 0.323962]\n",
      "epoch:2 step:2124 [D loss: 0.247149, acc.: 55.47%] [G loss: 0.303032]\n",
      "epoch:2 step:2125 [D loss: 0.246336, acc.: 59.38%] [G loss: 0.327915]\n",
      "epoch:2 step:2126 [D loss: 0.259717, acc.: 55.47%] [G loss: 0.314431]\n",
      "epoch:2 step:2127 [D loss: 0.228377, acc.: 60.94%] [G loss: 0.316013]\n",
      "epoch:2 step:2128 [D loss: 0.226021, acc.: 62.50%] [G loss: 0.368189]\n",
      "epoch:2 step:2129 [D loss: 0.241441, acc.: 54.69%] [G loss: 0.331261]\n",
      "epoch:2 step:2130 [D loss: 0.236973, acc.: 63.28%] [G loss: 0.329308]\n",
      "epoch:2 step:2131 [D loss: 0.204859, acc.: 70.31%] [G loss: 0.370308]\n",
      "epoch:2 step:2132 [D loss: 0.251655, acc.: 60.16%] [G loss: 0.350098]\n",
      "epoch:2 step:2133 [D loss: 0.227246, acc.: 60.16%] [G loss: 0.334512]\n",
      "epoch:2 step:2134 [D loss: 0.226695, acc.: 59.38%] [G loss: 0.306046]\n",
      "epoch:2 step:2135 [D loss: 0.225649, acc.: 62.50%] [G loss: 0.362330]\n",
      "epoch:2 step:2136 [D loss: 0.235518, acc.: 57.81%] [G loss: 0.326542]\n",
      "epoch:2 step:2137 [D loss: 0.242470, acc.: 59.38%] [G loss: 0.347269]\n",
      "epoch:2 step:2138 [D loss: 0.244473, acc.: 58.59%] [G loss: 0.327476]\n",
      "epoch:2 step:2139 [D loss: 0.250423, acc.: 58.59%] [G loss: 0.337992]\n",
      "epoch:2 step:2140 [D loss: 0.245060, acc.: 61.72%] [G loss: 0.343267]\n",
      "epoch:2 step:2141 [D loss: 0.236776, acc.: 59.38%] [G loss: 0.331113]\n",
      "epoch:2 step:2142 [D loss: 0.219617, acc.: 71.09%] [G loss: 0.339801]\n",
      "epoch:2 step:2143 [D loss: 0.254573, acc.: 53.12%] [G loss: 0.350549]\n",
      "epoch:2 step:2144 [D loss: 0.244855, acc.: 57.03%] [G loss: 0.327426]\n",
      "epoch:2 step:2145 [D loss: 0.258653, acc.: 55.47%] [G loss: 0.364076]\n",
      "epoch:2 step:2146 [D loss: 0.236932, acc.: 60.16%] [G loss: 0.334306]\n",
      "epoch:2 step:2147 [D loss: 0.245559, acc.: 56.25%] [G loss: 0.322801]\n",
      "epoch:2 step:2148 [D loss: 0.246067, acc.: 58.59%] [G loss: 0.321494]\n",
      "epoch:2 step:2149 [D loss: 0.260060, acc.: 48.44%] [G loss: 0.309930]\n",
      "epoch:2 step:2150 [D loss: 0.224287, acc.: 64.06%] [G loss: 0.361569]\n",
      "epoch:2 step:2151 [D loss: 0.253495, acc.: 55.47%] [G loss: 0.343230]\n",
      "epoch:2 step:2152 [D loss: 0.240867, acc.: 60.94%] [G loss: 0.324775]\n",
      "epoch:2 step:2153 [D loss: 0.246244, acc.: 60.16%] [G loss: 0.323283]\n",
      "epoch:2 step:2154 [D loss: 0.266544, acc.: 50.00%] [G loss: 0.335694]\n",
      "epoch:2 step:2155 [D loss: 0.256125, acc.: 52.34%] [G loss: 0.324521]\n",
      "epoch:2 step:2156 [D loss: 0.270924, acc.: 45.31%] [G loss: 0.321538]\n",
      "epoch:2 step:2157 [D loss: 0.236968, acc.: 66.41%] [G loss: 0.315791]\n",
      "epoch:2 step:2158 [D loss: 0.257392, acc.: 57.81%] [G loss: 0.304200]\n",
      "epoch:2 step:2159 [D loss: 0.235080, acc.: 61.72%] [G loss: 0.302756]\n",
      "epoch:2 step:2160 [D loss: 0.250349, acc.: 59.38%] [G loss: 0.347776]\n",
      "epoch:2 step:2161 [D loss: 0.253517, acc.: 53.91%] [G loss: 0.352740]\n",
      "epoch:2 step:2162 [D loss: 0.234194, acc.: 55.47%] [G loss: 0.381079]\n",
      "epoch:2 step:2163 [D loss: 0.236004, acc.: 58.59%] [G loss: 0.363843]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:2 step:2164 [D loss: 0.245340, acc.: 58.59%] [G loss: 0.327679]\n",
      "epoch:2 step:2165 [D loss: 0.214993, acc.: 64.06%] [G loss: 0.362413]\n",
      "epoch:2 step:2166 [D loss: 0.232122, acc.: 63.28%] [G loss: 0.328170]\n",
      "epoch:2 step:2167 [D loss: 0.242710, acc.: 56.25%] [G loss: 0.344035]\n",
      "epoch:2 step:2168 [D loss: 0.222148, acc.: 62.50%] [G loss: 0.312654]\n",
      "epoch:2 step:2169 [D loss: 0.229854, acc.: 64.84%] [G loss: 0.312491]\n",
      "epoch:2 step:2170 [D loss: 0.242215, acc.: 59.38%] [G loss: 0.297995]\n",
      "epoch:2 step:2171 [D loss: 0.255042, acc.: 54.69%] [G loss: 0.331382]\n",
      "epoch:2 step:2172 [D loss: 0.241139, acc.: 59.38%] [G loss: 0.325865]\n",
      "epoch:2 step:2173 [D loss: 0.245174, acc.: 58.59%] [G loss: 0.346694]\n",
      "epoch:2 step:2174 [D loss: 0.239958, acc.: 55.47%] [G loss: 0.375344]\n",
      "epoch:2 step:2175 [D loss: 0.227888, acc.: 62.50%] [G loss: 0.340943]\n",
      "epoch:2 step:2176 [D loss: 0.247486, acc.: 55.47%] [G loss: 0.351005]\n",
      "epoch:2 step:2177 [D loss: 0.239568, acc.: 57.81%] [G loss: 0.335144]\n",
      "epoch:2 step:2178 [D loss: 0.230076, acc.: 61.72%] [G loss: 0.340558]\n",
      "epoch:2 step:2179 [D loss: 0.240937, acc.: 57.81%] [G loss: 0.337926]\n",
      "epoch:2 step:2180 [D loss: 0.236154, acc.: 60.94%] [G loss: 0.300728]\n",
      "epoch:2 step:2181 [D loss: 0.234151, acc.: 64.06%] [G loss: 0.315719]\n",
      "epoch:2 step:2182 [D loss: 0.224583, acc.: 62.50%] [G loss: 0.373715]\n",
      "epoch:2 step:2183 [D loss: 0.243703, acc.: 59.38%] [G loss: 0.315270]\n",
      "epoch:2 step:2184 [D loss: 0.256212, acc.: 58.59%] [G loss: 0.334852]\n",
      "epoch:2 step:2185 [D loss: 0.229454, acc.: 67.19%] [G loss: 0.341836]\n",
      "epoch:2 step:2186 [D loss: 0.231278, acc.: 58.59%] [G loss: 0.370772]\n",
      "epoch:2 step:2187 [D loss: 0.243919, acc.: 62.50%] [G loss: 0.313637]\n",
      "epoch:2 step:2188 [D loss: 0.221691, acc.: 67.19%] [G loss: 0.332504]\n",
      "epoch:2 step:2189 [D loss: 0.236930, acc.: 63.28%] [G loss: 0.351382]\n",
      "epoch:2 step:2190 [D loss: 0.237426, acc.: 57.03%] [G loss: 0.338185]\n",
      "epoch:2 step:2191 [D loss: 0.272460, acc.: 50.00%] [G loss: 0.334121]\n",
      "epoch:2 step:2192 [D loss: 0.254220, acc.: 57.03%] [G loss: 0.351300]\n",
      "epoch:2 step:2193 [D loss: 0.279654, acc.: 43.75%] [G loss: 0.356395]\n",
      "epoch:2 step:2194 [D loss: 0.250976, acc.: 52.34%] [G loss: 0.354386]\n",
      "epoch:2 step:2195 [D loss: 0.248886, acc.: 53.91%] [G loss: 0.315398]\n",
      "epoch:2 step:2196 [D loss: 0.242420, acc.: 59.38%] [G loss: 0.354039]\n",
      "epoch:2 step:2197 [D loss: 0.258973, acc.: 50.78%] [G loss: 0.317028]\n",
      "epoch:2 step:2198 [D loss: 0.243897, acc.: 63.28%] [G loss: 0.356412]\n",
      "epoch:2 step:2199 [D loss: 0.232435, acc.: 64.84%] [G loss: 0.319577]\n",
      "epoch:2 step:2200 [D loss: 0.253321, acc.: 53.91%] [G loss: 0.332424]\n",
      "epoch:2 step:2201 [D loss: 0.231488, acc.: 62.50%] [G loss: 0.325409]\n",
      "epoch:2 step:2202 [D loss: 0.232381, acc.: 59.38%] [G loss: 0.335965]\n",
      "epoch:2 step:2203 [D loss: 0.246365, acc.: 60.16%] [G loss: 0.335050]\n",
      "epoch:2 step:2204 [D loss: 0.241339, acc.: 65.62%] [G loss: 0.299962]\n",
      "epoch:2 step:2205 [D loss: 0.243358, acc.: 61.72%] [G loss: 0.283640]\n",
      "epoch:2 step:2206 [D loss: 0.246085, acc.: 59.38%] [G loss: 0.322443]\n",
      "epoch:2 step:2207 [D loss: 0.240297, acc.: 57.81%] [G loss: 0.291284]\n",
      "epoch:2 step:2208 [D loss: 0.270547, acc.: 56.25%] [G loss: 0.322018]\n",
      "epoch:2 step:2209 [D loss: 0.227923, acc.: 60.94%] [G loss: 0.303095]\n",
      "epoch:2 step:2210 [D loss: 0.214799, acc.: 72.66%] [G loss: 0.340712]\n",
      "epoch:2 step:2211 [D loss: 0.233666, acc.: 59.38%] [G loss: 0.325736]\n",
      "epoch:2 step:2212 [D loss: 0.221251, acc.: 67.19%] [G loss: 0.311298]\n",
      "epoch:2 step:2213 [D loss: 0.242000, acc.: 54.69%] [G loss: 0.314013]\n",
      "epoch:2 step:2214 [D loss: 0.234593, acc.: 59.38%] [G loss: 0.326917]\n",
      "epoch:2 step:2215 [D loss: 0.235449, acc.: 62.50%] [G loss: 0.333907]\n",
      "epoch:2 step:2216 [D loss: 0.237729, acc.: 60.94%] [G loss: 0.348443]\n",
      "epoch:2 step:2217 [D loss: 0.225135, acc.: 65.62%] [G loss: 0.333456]\n",
      "epoch:2 step:2218 [D loss: 0.228592, acc.: 59.38%] [G loss: 0.364424]\n",
      "epoch:2 step:2219 [D loss: 0.235330, acc.: 60.94%] [G loss: 0.317754]\n",
      "epoch:2 step:2220 [D loss: 0.250084, acc.: 58.59%] [G loss: 0.289094]\n",
      "epoch:2 step:2221 [D loss: 0.245305, acc.: 58.59%] [G loss: 0.314410]\n",
      "epoch:2 step:2222 [D loss: 0.255959, acc.: 55.47%] [G loss: 0.297595]\n",
      "epoch:2 step:2223 [D loss: 0.247960, acc.: 60.16%] [G loss: 0.285225]\n",
      "epoch:2 step:2224 [D loss: 0.230106, acc.: 63.28%] [G loss: 0.306363]\n",
      "epoch:2 step:2225 [D loss: 0.237978, acc.: 61.72%] [G loss: 0.319417]\n",
      "epoch:2 step:2226 [D loss: 0.243607, acc.: 57.81%] [G loss: 0.334423]\n",
      "epoch:2 step:2227 [D loss: 0.235227, acc.: 64.06%] [G loss: 0.297691]\n",
      "epoch:2 step:2228 [D loss: 0.252595, acc.: 53.91%] [G loss: 0.292664]\n",
      "epoch:2 step:2229 [D loss: 0.235904, acc.: 58.59%] [G loss: 0.334924]\n",
      "epoch:2 step:2230 [D loss: 0.221437, acc.: 64.84%] [G loss: 0.348302]\n",
      "epoch:2 step:2231 [D loss: 0.235696, acc.: 59.38%] [G loss: 0.315032]\n",
      "epoch:2 step:2232 [D loss: 0.241989, acc.: 53.91%] [G loss: 0.333354]\n",
      "epoch:2 step:2233 [D loss: 0.220856, acc.: 64.06%] [G loss: 0.312057]\n",
      "epoch:2 step:2234 [D loss: 0.221063, acc.: 65.62%] [G loss: 0.331321]\n",
      "epoch:2 step:2235 [D loss: 0.251909, acc.: 59.38%] [G loss: 0.341466]\n",
      "epoch:2 step:2236 [D loss: 0.262601, acc.: 50.00%] [G loss: 0.346307]\n",
      "epoch:2 step:2237 [D loss: 0.237985, acc.: 57.81%] [G loss: 0.316423]\n",
      "epoch:2 step:2238 [D loss: 0.232057, acc.: 65.62%] [G loss: 0.330990]\n",
      "epoch:2 step:2239 [D loss: 0.227594, acc.: 62.50%] [G loss: 0.352348]\n",
      "epoch:2 step:2240 [D loss: 0.249111, acc.: 64.06%] [G loss: 0.290866]\n",
      "epoch:2 step:2241 [D loss: 0.236445, acc.: 63.28%] [G loss: 0.363451]\n",
      "epoch:2 step:2242 [D loss: 0.237511, acc.: 60.94%] [G loss: 0.332177]\n",
      "epoch:2 step:2243 [D loss: 0.246837, acc.: 57.03%] [G loss: 0.322229]\n",
      "epoch:2 step:2244 [D loss: 0.229792, acc.: 62.50%] [G loss: 0.367214]\n",
      "epoch:2 step:2245 [D loss: 0.236209, acc.: 67.97%] [G loss: 0.338335]\n",
      "epoch:2 step:2246 [D loss: 0.241725, acc.: 59.38%] [G loss: 0.329767]\n",
      "epoch:2 step:2247 [D loss: 0.247012, acc.: 58.59%] [G loss: 0.332165]\n",
      "epoch:2 step:2248 [D loss: 0.262901, acc.: 46.88%] [G loss: 0.326872]\n",
      "epoch:2 step:2249 [D loss: 0.259367, acc.: 56.25%] [G loss: 0.329636]\n",
      "epoch:2 step:2250 [D loss: 0.245269, acc.: 53.91%] [G loss: 0.317924]\n",
      "epoch:2 step:2251 [D loss: 0.245004, acc.: 53.91%] [G loss: 0.332152]\n",
      "epoch:2 step:2252 [D loss: 0.239437, acc.: 60.94%] [G loss: 0.350964]\n",
      "epoch:2 step:2253 [D loss: 0.236389, acc.: 63.28%] [G loss: 0.315134]\n",
      "epoch:2 step:2254 [D loss: 0.257069, acc.: 54.69%] [G loss: 0.357918]\n",
      "epoch:2 step:2255 [D loss: 0.255849, acc.: 52.34%] [G loss: 0.320279]\n",
      "epoch:2 step:2256 [D loss: 0.228779, acc.: 65.62%] [G loss: 0.354576]\n",
      "epoch:2 step:2257 [D loss: 0.262627, acc.: 50.78%] [G loss: 0.318059]\n",
      "epoch:2 step:2258 [D loss: 0.247146, acc.: 58.59%] [G loss: 0.375417]\n",
      "epoch:2 step:2259 [D loss: 0.222943, acc.: 65.62%] [G loss: 0.347819]\n",
      "epoch:2 step:2260 [D loss: 0.244897, acc.: 59.38%] [G loss: 0.303202]\n",
      "epoch:2 step:2261 [D loss: 0.245766, acc.: 54.69%] [G loss: 0.282382]\n",
      "epoch:2 step:2262 [D loss: 0.244968, acc.: 55.47%] [G loss: 0.299161]\n",
      "epoch:2 step:2263 [D loss: 0.227455, acc.: 61.72%] [G loss: 0.319396]\n",
      "epoch:2 step:2264 [D loss: 0.223844, acc.: 64.84%] [G loss: 0.387853]\n",
      "epoch:2 step:2265 [D loss: 0.224118, acc.: 60.16%] [G loss: 0.300602]\n",
      "epoch:2 step:2266 [D loss: 0.250688, acc.: 59.38%] [G loss: 0.384579]\n",
      "epoch:2 step:2267 [D loss: 0.271742, acc.: 51.56%] [G loss: 0.348145]\n",
      "epoch:2 step:2268 [D loss: 0.241912, acc.: 58.59%] [G loss: 0.373633]\n",
      "epoch:2 step:2269 [D loss: 0.232674, acc.: 57.81%] [G loss: 0.327947]\n",
      "epoch:2 step:2270 [D loss: 0.238325, acc.: 61.72%] [G loss: 0.337458]\n",
      "epoch:2 step:2271 [D loss: 0.243672, acc.: 53.12%] [G loss: 0.338365]\n",
      "epoch:2 step:2272 [D loss: 0.261840, acc.: 51.56%] [G loss: 0.308096]\n",
      "epoch:2 step:2273 [D loss: 0.236434, acc.: 58.59%] [G loss: 0.342459]\n",
      "epoch:2 step:2274 [D loss: 0.247196, acc.: 55.47%] [G loss: 0.345985]\n",
      "epoch:2 step:2275 [D loss: 0.248203, acc.: 57.03%] [G loss: 0.370252]\n",
      "epoch:2 step:2276 [D loss: 0.225664, acc.: 62.50%] [G loss: 0.322617]\n",
      "epoch:2 step:2277 [D loss: 0.241701, acc.: 57.03%] [G loss: 0.310565]\n",
      "epoch:2 step:2278 [D loss: 0.232145, acc.: 64.06%] [G loss: 0.315560]\n",
      "epoch:2 step:2279 [D loss: 0.235597, acc.: 66.41%] [G loss: 0.346554]\n",
      "epoch:2 step:2280 [D loss: 0.250767, acc.: 53.91%] [G loss: 0.320008]\n",
      "epoch:2 step:2281 [D loss: 0.262021, acc.: 56.25%] [G loss: 0.302919]\n",
      "epoch:2 step:2282 [D loss: 0.228113, acc.: 58.59%] [G loss: 0.352913]\n",
      "epoch:2 step:2283 [D loss: 0.243416, acc.: 57.81%] [G loss: 0.300315]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:2 step:2284 [D loss: 0.251735, acc.: 53.91%] [G loss: 0.326355]\n",
      "epoch:2 step:2285 [D loss: 0.259586, acc.: 55.47%] [G loss: 0.339904]\n",
      "epoch:2 step:2286 [D loss: 0.241859, acc.: 57.03%] [G loss: 0.320834]\n",
      "epoch:2 step:2287 [D loss: 0.251815, acc.: 56.25%] [G loss: 0.363651]\n",
      "epoch:2 step:2288 [D loss: 0.228205, acc.: 62.50%] [G loss: 0.340166]\n",
      "epoch:2 step:2289 [D loss: 0.224285, acc.: 69.53%] [G loss: 0.358665]\n",
      "epoch:2 step:2290 [D loss: 0.249614, acc.: 53.91%] [G loss: 0.330905]\n",
      "epoch:2 step:2291 [D loss: 0.231652, acc.: 63.28%] [G loss: 0.309620]\n",
      "epoch:2 step:2292 [D loss: 0.244030, acc.: 56.25%] [G loss: 0.333135]\n",
      "epoch:2 step:2293 [D loss: 0.224957, acc.: 65.62%] [G loss: 0.328455]\n",
      "epoch:2 step:2294 [D loss: 0.251475, acc.: 55.47%] [G loss: 0.341675]\n",
      "epoch:2 step:2295 [D loss: 0.243124, acc.: 56.25%] [G loss: 0.326181]\n",
      "epoch:2 step:2296 [D loss: 0.239201, acc.: 57.03%] [G loss: 0.311549]\n",
      "epoch:2 step:2297 [D loss: 0.239509, acc.: 62.50%] [G loss: 0.326578]\n",
      "epoch:2 step:2298 [D loss: 0.233331, acc.: 60.94%] [G loss: 0.330177]\n",
      "epoch:2 step:2299 [D loss: 0.246259, acc.: 54.69%] [G loss: 0.299905]\n",
      "epoch:2 step:2300 [D loss: 0.228981, acc.: 60.94%] [G loss: 0.345449]\n",
      "epoch:2 step:2301 [D loss: 0.214030, acc.: 63.28%] [G loss: 0.349130]\n",
      "epoch:2 step:2302 [D loss: 0.231177, acc.: 60.16%] [G loss: 0.324722]\n",
      "epoch:2 step:2303 [D loss: 0.216547, acc.: 61.72%] [G loss: 0.358291]\n",
      "epoch:2 step:2304 [D loss: 0.261577, acc.: 51.56%] [G loss: 0.323109]\n",
      "epoch:2 step:2305 [D loss: 0.248092, acc.: 59.38%] [G loss: 0.323256]\n",
      "epoch:2 step:2306 [D loss: 0.220690, acc.: 65.62%] [G loss: 0.342118]\n",
      "epoch:2 step:2307 [D loss: 0.246241, acc.: 61.72%] [G loss: 0.317746]\n",
      "epoch:2 step:2308 [D loss: 0.258959, acc.: 55.47%] [G loss: 0.286627]\n",
      "epoch:2 step:2309 [D loss: 0.243067, acc.: 59.38%] [G loss: 0.335526]\n",
      "epoch:2 step:2310 [D loss: 0.237766, acc.: 58.59%] [G loss: 0.325684]\n",
      "epoch:2 step:2311 [D loss: 0.258528, acc.: 57.81%] [G loss: 0.361474]\n",
      "epoch:2 step:2312 [D loss: 0.237755, acc.: 53.12%] [G loss: 0.342966]\n",
      "epoch:2 step:2313 [D loss: 0.251059, acc.: 56.25%] [G loss: 0.320263]\n",
      "epoch:2 step:2314 [D loss: 0.235891, acc.: 60.94%] [G loss: 0.273868]\n",
      "epoch:2 step:2315 [D loss: 0.221815, acc.: 59.38%] [G loss: 0.314838]\n",
      "epoch:2 step:2316 [D loss: 0.238566, acc.: 58.59%] [G loss: 0.329376]\n",
      "epoch:2 step:2317 [D loss: 0.247988, acc.: 55.47%] [G loss: 0.322534]\n",
      "epoch:2 step:2318 [D loss: 0.231703, acc.: 61.72%] [G loss: 0.316364]\n",
      "epoch:2 step:2319 [D loss: 0.240073, acc.: 58.59%] [G loss: 0.345365]\n",
      "epoch:2 step:2320 [D loss: 0.253671, acc.: 51.56%] [G loss: 0.283274]\n",
      "epoch:2 step:2321 [D loss: 0.244521, acc.: 59.38%] [G loss: 0.297916]\n",
      "epoch:2 step:2322 [D loss: 0.227008, acc.: 64.06%] [G loss: 0.328097]\n",
      "epoch:2 step:2323 [D loss: 0.239720, acc.: 63.28%] [G loss: 0.331479]\n",
      "epoch:2 step:2324 [D loss: 0.231023, acc.: 60.94%] [G loss: 0.310738]\n",
      "epoch:2 step:2325 [D loss: 0.233152, acc.: 57.81%] [G loss: 0.347619]\n",
      "epoch:2 step:2326 [D loss: 0.252600, acc.: 51.56%] [G loss: 0.313314]\n",
      "epoch:2 step:2327 [D loss: 0.257129, acc.: 52.34%] [G loss: 0.328990]\n",
      "epoch:2 step:2328 [D loss: 0.245020, acc.: 53.12%] [G loss: 0.312226]\n",
      "epoch:2 step:2329 [D loss: 0.243241, acc.: 53.91%] [G loss: 0.330049]\n",
      "epoch:2 step:2330 [D loss: 0.226658, acc.: 62.50%] [G loss: 0.332461]\n",
      "epoch:2 step:2331 [D loss: 0.254701, acc.: 50.00%] [G loss: 0.314071]\n",
      "epoch:2 step:2332 [D loss: 0.239679, acc.: 57.03%] [G loss: 0.322836]\n",
      "epoch:2 step:2333 [D loss: 0.253410, acc.: 53.91%] [G loss: 0.343244]\n",
      "epoch:2 step:2334 [D loss: 0.243697, acc.: 60.16%] [G loss: 0.321492]\n",
      "epoch:2 step:2335 [D loss: 0.237552, acc.: 60.94%] [G loss: 0.304749]\n",
      "epoch:2 step:2336 [D loss: 0.254628, acc.: 51.56%] [G loss: 0.345290]\n",
      "epoch:2 step:2337 [D loss: 0.228089, acc.: 60.16%] [G loss: 0.308790]\n",
      "epoch:2 step:2338 [D loss: 0.245051, acc.: 58.59%] [G loss: 0.341647]\n",
      "epoch:2 step:2339 [D loss: 0.261391, acc.: 54.69%] [G loss: 0.336444]\n",
      "epoch:2 step:2340 [D loss: 0.232727, acc.: 64.06%] [G loss: 0.344476]\n",
      "epoch:2 step:2341 [D loss: 0.229949, acc.: 60.94%] [G loss: 0.317024]\n",
      "epoch:2 step:2342 [D loss: 0.241004, acc.: 60.16%] [G loss: 0.341020]\n",
      "epoch:2 step:2343 [D loss: 0.249982, acc.: 57.81%] [G loss: 0.335153]\n",
      "epoch:2 step:2344 [D loss: 0.262256, acc.: 57.03%] [G loss: 0.302266]\n",
      "epoch:2 step:2345 [D loss: 0.239045, acc.: 56.25%] [G loss: 0.309606]\n",
      "epoch:2 step:2346 [D loss: 0.254899, acc.: 57.81%] [G loss: 0.330740]\n",
      "epoch:2 step:2347 [D loss: 0.239279, acc.: 55.47%] [G loss: 0.307241]\n",
      "epoch:2 step:2348 [D loss: 0.246965, acc.: 57.81%] [G loss: 0.296275]\n",
      "epoch:2 step:2349 [D loss: 0.213436, acc.: 68.75%] [G loss: 0.357441]\n",
      "epoch:2 step:2350 [D loss: 0.239511, acc.: 60.94%] [G loss: 0.324336]\n",
      "epoch:2 step:2351 [D loss: 0.238241, acc.: 57.81%] [G loss: 0.331007]\n",
      "epoch:2 step:2352 [D loss: 0.259296, acc.: 50.78%] [G loss: 0.319555]\n",
      "epoch:2 step:2353 [D loss: 0.262945, acc.: 54.69%] [G loss: 0.351695]\n",
      "epoch:2 step:2354 [D loss: 0.251771, acc.: 55.47%] [G loss: 0.316021]\n",
      "epoch:2 step:2355 [D loss: 0.273045, acc.: 48.44%] [G loss: 0.341604]\n",
      "epoch:2 step:2356 [D loss: 0.255309, acc.: 59.38%] [G loss: 0.301519]\n",
      "epoch:2 step:2357 [D loss: 0.243143, acc.: 60.16%] [G loss: 0.342609]\n",
      "epoch:2 step:2358 [D loss: 0.245536, acc.: 55.47%] [G loss: 0.324335]\n",
      "epoch:2 step:2359 [D loss: 0.248197, acc.: 56.25%] [G loss: 0.332308]\n",
      "epoch:2 step:2360 [D loss: 0.238544, acc.: 59.38%] [G loss: 0.299372]\n",
      "epoch:2 step:2361 [D loss: 0.230433, acc.: 64.06%] [G loss: 0.366851]\n",
      "epoch:2 step:2362 [D loss: 0.225920, acc.: 63.28%] [G loss: 0.325162]\n",
      "epoch:2 step:2363 [D loss: 0.245439, acc.: 61.72%] [G loss: 0.339997]\n",
      "epoch:2 step:2364 [D loss: 0.211833, acc.: 65.62%] [G loss: 0.347122]\n",
      "epoch:2 step:2365 [D loss: 0.243136, acc.: 53.91%] [G loss: 0.314215]\n",
      "epoch:2 step:2366 [D loss: 0.242764, acc.: 60.94%] [G loss: 0.340664]\n",
      "epoch:2 step:2367 [D loss: 0.231957, acc.: 60.16%] [G loss: 0.299901]\n",
      "epoch:2 step:2368 [D loss: 0.227020, acc.: 57.81%] [G loss: 0.331489]\n",
      "epoch:2 step:2369 [D loss: 0.248302, acc.: 54.69%] [G loss: 0.331338]\n",
      "epoch:2 step:2370 [D loss: 0.222793, acc.: 64.06%] [G loss: 0.343022]\n",
      "epoch:2 step:2371 [D loss: 0.230652, acc.: 60.94%] [G loss: 0.298513]\n",
      "epoch:2 step:2372 [D loss: 0.224214, acc.: 64.84%] [G loss: 0.315303]\n",
      "epoch:2 step:2373 [D loss: 0.232842, acc.: 61.72%] [G loss: 0.345117]\n",
      "epoch:2 step:2374 [D loss: 0.246797, acc.: 52.34%] [G loss: 0.295545]\n",
      "epoch:2 step:2375 [D loss: 0.232299, acc.: 60.94%] [G loss: 0.279535]\n",
      "epoch:2 step:2376 [D loss: 0.223243, acc.: 62.50%] [G loss: 0.289401]\n",
      "epoch:2 step:2377 [D loss: 0.222282, acc.: 60.94%] [G loss: 0.309868]\n",
      "epoch:2 step:2378 [D loss: 0.239650, acc.: 61.72%] [G loss: 0.327379]\n",
      "epoch:2 step:2379 [D loss: 0.245084, acc.: 59.38%] [G loss: 0.333099]\n",
      "epoch:2 step:2380 [D loss: 0.255786, acc.: 50.00%] [G loss: 0.308435]\n",
      "epoch:2 step:2381 [D loss: 0.224720, acc.: 64.06%] [G loss: 0.339434]\n",
      "epoch:2 step:2382 [D loss: 0.239252, acc.: 57.03%] [G loss: 0.355622]\n",
      "epoch:2 step:2383 [D loss: 0.231931, acc.: 60.94%] [G loss: 0.323334]\n",
      "epoch:2 step:2384 [D loss: 0.210932, acc.: 62.50%] [G loss: 0.302327]\n",
      "epoch:2 step:2385 [D loss: 0.228461, acc.: 64.84%] [G loss: 0.330766]\n",
      "epoch:2 step:2386 [D loss: 0.276375, acc.: 50.00%] [G loss: 0.337796]\n",
      "epoch:2 step:2387 [D loss: 0.239312, acc.: 57.03%] [G loss: 0.311547]\n",
      "epoch:2 step:2388 [D loss: 0.241703, acc.: 58.59%] [G loss: 0.328006]\n",
      "epoch:2 step:2389 [D loss: 0.261624, acc.: 51.56%] [G loss: 0.355156]\n",
      "epoch:2 step:2390 [D loss: 0.248097, acc.: 57.03%] [G loss: 0.372809]\n",
      "epoch:2 step:2391 [D loss: 0.248054, acc.: 57.81%] [G loss: 0.330981]\n",
      "epoch:2 step:2392 [D loss: 0.214162, acc.: 64.84%] [G loss: 0.325898]\n",
      "epoch:2 step:2393 [D loss: 0.216488, acc.: 67.97%] [G loss: 0.338922]\n",
      "epoch:2 step:2394 [D loss: 0.238045, acc.: 60.94%] [G loss: 0.349441]\n",
      "epoch:2 step:2395 [D loss: 0.229978, acc.: 63.28%] [G loss: 0.339549]\n",
      "epoch:2 step:2396 [D loss: 0.231062, acc.: 63.28%] [G loss: 0.368166]\n",
      "epoch:2 step:2397 [D loss: 0.221701, acc.: 60.16%] [G loss: 0.373412]\n",
      "epoch:2 step:2398 [D loss: 0.239634, acc.: 57.03%] [G loss: 0.362766]\n",
      "epoch:2 step:2399 [D loss: 0.260851, acc.: 50.78%] [G loss: 0.328412]\n",
      "epoch:2 step:2400 [D loss: 0.259003, acc.: 56.25%] [G loss: 0.350796]\n",
      "epoch:2 step:2401 [D loss: 0.241184, acc.: 57.81%] [G loss: 0.347283]\n",
      "epoch:2 step:2402 [D loss: 0.252641, acc.: 52.34%] [G loss: 0.295993]\n",
      "epoch:2 step:2403 [D loss: 0.232548, acc.: 59.38%] [G loss: 0.314453]\n",
      "epoch:2 step:2404 [D loss: 0.222721, acc.: 66.41%] [G loss: 0.340007]\n",
      "epoch:2 step:2405 [D loss: 0.234622, acc.: 57.03%] [G loss: 0.355591]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:2 step:2406 [D loss: 0.252478, acc.: 55.47%] [G loss: 0.325367]\n",
      "epoch:2 step:2407 [D loss: 0.234553, acc.: 57.03%] [G loss: 0.331881]\n",
      "epoch:2 step:2408 [D loss: 0.239432, acc.: 57.81%] [G loss: 0.345216]\n",
      "epoch:2 step:2409 [D loss: 0.251847, acc.: 50.78%] [G loss: 0.335285]\n",
      "epoch:2 step:2410 [D loss: 0.222782, acc.: 66.41%] [G loss: 0.352292]\n",
      "epoch:2 step:2411 [D loss: 0.225903, acc.: 57.03%] [G loss: 0.356403]\n",
      "epoch:2 step:2412 [D loss: 0.274304, acc.: 47.66%] [G loss: 0.342105]\n",
      "epoch:2 step:2413 [D loss: 0.248786, acc.: 53.12%] [G loss: 0.341199]\n",
      "epoch:2 step:2414 [D loss: 0.219704, acc.: 68.75%] [G loss: 0.330099]\n",
      "epoch:2 step:2415 [D loss: 0.232087, acc.: 60.16%] [G loss: 0.351017]\n",
      "epoch:2 step:2416 [D loss: 0.225622, acc.: 59.38%] [G loss: 0.322015]\n",
      "epoch:2 step:2417 [D loss: 0.253941, acc.: 59.38%] [G loss: 0.340957]\n",
      "epoch:2 step:2418 [D loss: 0.239362, acc.: 61.72%] [G loss: 0.296440]\n",
      "epoch:2 step:2419 [D loss: 0.254194, acc.: 53.91%] [G loss: 0.320098]\n",
      "epoch:2 step:2420 [D loss: 0.238905, acc.: 63.28%] [G loss: 0.333804]\n",
      "epoch:2 step:2421 [D loss: 0.231655, acc.: 57.81%] [G loss: 0.341499]\n",
      "epoch:2 step:2422 [D loss: 0.219402, acc.: 67.19%] [G loss: 0.323633]\n",
      "epoch:2 step:2423 [D loss: 0.256511, acc.: 55.47%] [G loss: 0.311394]\n",
      "epoch:2 step:2424 [D loss: 0.220300, acc.: 60.94%] [G loss: 0.311515]\n",
      "epoch:2 step:2425 [D loss: 0.271067, acc.: 50.00%] [G loss: 0.312882]\n",
      "epoch:2 step:2426 [D loss: 0.253541, acc.: 53.12%] [G loss: 0.343204]\n",
      "epoch:2 step:2427 [D loss: 0.227607, acc.: 63.28%] [G loss: 0.343520]\n",
      "epoch:2 step:2428 [D loss: 0.241605, acc.: 60.94%] [G loss: 0.313190]\n",
      "epoch:2 step:2429 [D loss: 0.234603, acc.: 57.81%] [G loss: 0.300228]\n",
      "epoch:2 step:2430 [D loss: 0.246499, acc.: 51.56%] [G loss: 0.334992]\n",
      "epoch:2 step:2431 [D loss: 0.235923, acc.: 53.12%] [G loss: 0.290036]\n",
      "epoch:2 step:2432 [D loss: 0.255015, acc.: 54.69%] [G loss: 0.356403]\n",
      "epoch:2 step:2433 [D loss: 0.232561, acc.: 60.16%] [G loss: 0.344287]\n",
      "epoch:2 step:2434 [D loss: 0.261035, acc.: 53.12%] [G loss: 0.288669]\n",
      "epoch:2 step:2435 [D loss: 0.240298, acc.: 58.59%] [G loss: 0.293685]\n",
      "epoch:2 step:2436 [D loss: 0.268997, acc.: 53.12%] [G loss: 0.306859]\n",
      "epoch:2 step:2437 [D loss: 0.224366, acc.: 63.28%] [G loss: 0.304767]\n",
      "epoch:2 step:2438 [D loss: 0.235298, acc.: 60.16%] [G loss: 0.336908]\n",
      "epoch:2 step:2439 [D loss: 0.243290, acc.: 57.81%] [G loss: 0.302835]\n",
      "epoch:2 step:2440 [D loss: 0.255562, acc.: 51.56%] [G loss: 0.324772]\n",
      "epoch:2 step:2441 [D loss: 0.227403, acc.: 61.72%] [G loss: 0.337719]\n",
      "epoch:2 step:2442 [D loss: 0.275580, acc.: 52.34%] [G loss: 0.312592]\n",
      "epoch:2 step:2443 [D loss: 0.216126, acc.: 67.97%] [G loss: 0.304264]\n",
      "epoch:2 step:2444 [D loss: 0.264871, acc.: 50.78%] [G loss: 0.372235]\n",
      "epoch:2 step:2445 [D loss: 0.220873, acc.: 63.28%] [G loss: 0.335737]\n",
      "epoch:2 step:2446 [D loss: 0.246513, acc.: 57.81%] [G loss: 0.347055]\n",
      "epoch:2 step:2447 [D loss: 0.261696, acc.: 48.44%] [G loss: 0.302372]\n",
      "epoch:2 step:2448 [D loss: 0.249664, acc.: 58.59%] [G loss: 0.358103]\n",
      "epoch:2 step:2449 [D loss: 0.223138, acc.: 60.16%] [G loss: 0.345565]\n",
      "epoch:2 step:2450 [D loss: 0.230760, acc.: 63.28%] [G loss: 0.341980]\n",
      "epoch:2 step:2451 [D loss: 0.235114, acc.: 59.38%] [G loss: 0.316146]\n",
      "epoch:2 step:2452 [D loss: 0.226658, acc.: 59.38%] [G loss: 0.310938]\n",
      "epoch:2 step:2453 [D loss: 0.244565, acc.: 57.03%] [G loss: 0.328554]\n",
      "epoch:2 step:2454 [D loss: 0.225957, acc.: 62.50%] [G loss: 0.311615]\n",
      "epoch:2 step:2455 [D loss: 0.245353, acc.: 57.81%] [G loss: 0.348676]\n",
      "epoch:2 step:2456 [D loss: 0.251949, acc.: 53.91%] [G loss: 0.354820]\n",
      "epoch:2 step:2457 [D loss: 0.246352, acc.: 58.59%] [G loss: 0.314782]\n",
      "epoch:2 step:2458 [D loss: 0.245129, acc.: 59.38%] [G loss: 0.335600]\n",
      "epoch:2 step:2459 [D loss: 0.224561, acc.: 60.16%] [G loss: 0.325883]\n",
      "epoch:2 step:2460 [D loss: 0.224938, acc.: 58.59%] [G loss: 0.350178]\n",
      "epoch:2 step:2461 [D loss: 0.235417, acc.: 62.50%] [G loss: 0.335710]\n",
      "epoch:2 step:2462 [D loss: 0.247992, acc.: 54.69%] [G loss: 0.361959]\n",
      "epoch:2 step:2463 [D loss: 0.250270, acc.: 53.91%] [G loss: 0.304541]\n",
      "epoch:2 step:2464 [D loss: 0.232968, acc.: 61.72%] [G loss: 0.368063]\n",
      "epoch:2 step:2465 [D loss: 0.237704, acc.: 59.38%] [G loss: 0.302408]\n",
      "epoch:2 step:2466 [D loss: 0.247871, acc.: 53.91%] [G loss: 0.308976]\n",
      "epoch:2 step:2467 [D loss: 0.255368, acc.: 54.69%] [G loss: 0.310201]\n",
      "epoch:2 step:2468 [D loss: 0.225457, acc.: 61.72%] [G loss: 0.371307]\n",
      "epoch:2 step:2469 [D loss: 0.254583, acc.: 55.47%] [G loss: 0.280299]\n",
      "epoch:2 step:2470 [D loss: 0.220366, acc.: 66.41%] [G loss: 0.315762]\n",
      "epoch:2 step:2471 [D loss: 0.258229, acc.: 52.34%] [G loss: 0.311421]\n",
      "epoch:2 step:2472 [D loss: 0.258767, acc.: 53.12%] [G loss: 0.325590]\n",
      "epoch:2 step:2473 [D loss: 0.239331, acc.: 57.03%] [G loss: 0.324211]\n",
      "epoch:2 step:2474 [D loss: 0.231600, acc.: 62.50%] [G loss: 0.318298]\n",
      "epoch:2 step:2475 [D loss: 0.252608, acc.: 58.59%] [G loss: 0.329884]\n",
      "epoch:2 step:2476 [D loss: 0.225176, acc.: 61.72%] [G loss: 0.314467]\n",
      "epoch:2 step:2477 [D loss: 0.265336, acc.: 50.00%] [G loss: 0.290359]\n",
      "epoch:2 step:2478 [D loss: 0.245229, acc.: 58.59%] [G loss: 0.315375]\n",
      "epoch:2 step:2479 [D loss: 0.236063, acc.: 60.94%] [G loss: 0.297823]\n",
      "epoch:2 step:2480 [D loss: 0.223917, acc.: 61.72%] [G loss: 0.357949]\n",
      "epoch:2 step:2481 [D loss: 0.244375, acc.: 60.94%] [G loss: 0.331458]\n",
      "epoch:2 step:2482 [D loss: 0.233977, acc.: 61.72%] [G loss: 0.303050]\n",
      "epoch:2 step:2483 [D loss: 0.220499, acc.: 61.72%] [G loss: 0.337030]\n",
      "epoch:2 step:2484 [D loss: 0.262588, acc.: 55.47%] [G loss: 0.338106]\n",
      "epoch:2 step:2485 [D loss: 0.231427, acc.: 62.50%] [G loss: 0.312793]\n",
      "epoch:2 step:2486 [D loss: 0.245153, acc.: 57.03%] [G loss: 0.315064]\n",
      "epoch:2 step:2487 [D loss: 0.230601, acc.: 62.50%] [G loss: 0.284196]\n",
      "epoch:2 step:2488 [D loss: 0.240676, acc.: 60.16%] [G loss: 0.331030]\n",
      "epoch:2 step:2489 [D loss: 0.247436, acc.: 63.28%] [G loss: 0.328460]\n",
      "epoch:2 step:2490 [D loss: 0.244353, acc.: 57.03%] [G loss: 0.314084]\n",
      "epoch:2 step:2491 [D loss: 0.259348, acc.: 55.47%] [G loss: 0.359357]\n",
      "epoch:2 step:2492 [D loss: 0.242253, acc.: 57.81%] [G loss: 0.327254]\n",
      "epoch:2 step:2493 [D loss: 0.256456, acc.: 52.34%] [G loss: 0.323013]\n",
      "epoch:2 step:2494 [D loss: 0.243197, acc.: 59.38%] [G loss: 0.321379]\n",
      "epoch:2 step:2495 [D loss: 0.249790, acc.: 54.69%] [G loss: 0.334894]\n",
      "epoch:2 step:2496 [D loss: 0.240116, acc.: 57.81%] [G loss: 0.327100]\n",
      "epoch:2 step:2497 [D loss: 0.241986, acc.: 60.16%] [G loss: 0.288935]\n",
      "epoch:2 step:2498 [D loss: 0.239151, acc.: 60.16%] [G loss: 0.330537]\n",
      "epoch:2 step:2499 [D loss: 0.226110, acc.: 64.06%] [G loss: 0.327570]\n",
      "epoch:2 step:2500 [D loss: 0.247872, acc.: 57.81%] [G loss: 0.338872]\n",
      "epoch:2 step:2501 [D loss: 0.245560, acc.: 57.81%] [G loss: 0.289257]\n",
      "epoch:2 step:2502 [D loss: 0.251385, acc.: 58.59%] [G loss: 0.297320]\n",
      "epoch:2 step:2503 [D loss: 0.216890, acc.: 62.50%] [G loss: 0.385200]\n",
      "epoch:2 step:2504 [D loss: 0.247173, acc.: 57.81%] [G loss: 0.332610]\n",
      "epoch:2 step:2505 [D loss: 0.238573, acc.: 60.94%] [G loss: 0.320975]\n",
      "epoch:2 step:2506 [D loss: 0.263748, acc.: 52.34%] [G loss: 0.310498]\n",
      "epoch:2 step:2507 [D loss: 0.217729, acc.: 67.19%] [G loss: 0.339293]\n",
      "epoch:2 step:2508 [D loss: 0.244499, acc.: 57.03%] [G loss: 0.349044]\n",
      "epoch:2 step:2509 [D loss: 0.242942, acc.: 56.25%] [G loss: 0.306582]\n",
      "epoch:2 step:2510 [D loss: 0.238503, acc.: 62.50%] [G loss: 0.318499]\n",
      "epoch:2 step:2511 [D loss: 0.236670, acc.: 56.25%] [G loss: 0.327096]\n",
      "epoch:2 step:2512 [D loss: 0.232050, acc.: 64.06%] [G loss: 0.305692]\n",
      "epoch:2 step:2513 [D loss: 0.238975, acc.: 58.59%] [G loss: 0.337332]\n",
      "epoch:2 step:2514 [D loss: 0.242829, acc.: 55.47%] [G loss: 0.305306]\n",
      "epoch:2 step:2515 [D loss: 0.241703, acc.: 58.59%] [G loss: 0.339031]\n",
      "epoch:2 step:2516 [D loss: 0.233737, acc.: 61.72%] [G loss: 0.324778]\n",
      "epoch:2 step:2517 [D loss: 0.268492, acc.: 50.00%] [G loss: 0.377082]\n",
      "epoch:2 step:2518 [D loss: 0.248689, acc.: 54.69%] [G loss: 0.337510]\n",
      "epoch:2 step:2519 [D loss: 0.268993, acc.: 49.22%] [G loss: 0.363719]\n",
      "epoch:2 step:2520 [D loss: 0.247818, acc.: 57.81%] [G loss: 0.326986]\n",
      "epoch:2 step:2521 [D loss: 0.254624, acc.: 54.69%] [G loss: 0.298338]\n",
      "epoch:2 step:2522 [D loss: 0.236675, acc.: 57.81%] [G loss: 0.302967]\n",
      "epoch:2 step:2523 [D loss: 0.276634, acc.: 44.53%] [G loss: 0.284398]\n",
      "epoch:2 step:2524 [D loss: 0.235285, acc.: 62.50%] [G loss: 0.316100]\n",
      "epoch:2 step:2525 [D loss: 0.243422, acc.: 60.94%] [G loss: 0.319296]\n",
      "epoch:2 step:2526 [D loss: 0.221185, acc.: 64.06%] [G loss: 0.327487]\n",
      "epoch:2 step:2527 [D loss: 0.231642, acc.: 58.59%] [G loss: 0.322102]\n",
      "epoch:2 step:2528 [D loss: 0.257527, acc.: 57.03%] [G loss: 0.344414]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:2 step:2529 [D loss: 0.246568, acc.: 54.69%] [G loss: 0.360065]\n",
      "epoch:2 step:2530 [D loss: 0.250379, acc.: 55.47%] [G loss: 0.341531]\n",
      "epoch:2 step:2531 [D loss: 0.258524, acc.: 54.69%] [G loss: 0.345710]\n",
      "epoch:2 step:2532 [D loss: 0.263238, acc.: 50.78%] [G loss: 0.323107]\n",
      "epoch:2 step:2533 [D loss: 0.239327, acc.: 58.59%] [G loss: 0.305832]\n",
      "epoch:2 step:2534 [D loss: 0.251693, acc.: 54.69%] [G loss: 0.335205]\n",
      "epoch:2 step:2535 [D loss: 0.256622, acc.: 53.91%] [G loss: 0.315431]\n",
      "epoch:2 step:2536 [D loss: 0.229451, acc.: 59.38%] [G loss: 0.335059]\n",
      "epoch:2 step:2537 [D loss: 0.250100, acc.: 52.34%] [G loss: 0.320771]\n",
      "epoch:2 step:2538 [D loss: 0.260736, acc.: 51.56%] [G loss: 0.308225]\n",
      "epoch:2 step:2539 [D loss: 0.243740, acc.: 55.47%] [G loss: 0.312834]\n",
      "epoch:2 step:2540 [D loss: 0.243915, acc.: 55.47%] [G loss: 0.299009]\n",
      "epoch:2 step:2541 [D loss: 0.227945, acc.: 62.50%] [G loss: 0.302412]\n",
      "epoch:2 step:2542 [D loss: 0.256802, acc.: 53.91%] [G loss: 0.316944]\n",
      "epoch:2 step:2543 [D loss: 0.239432, acc.: 59.38%] [G loss: 0.349128]\n",
      "epoch:2 step:2544 [D loss: 0.246170, acc.: 55.47%] [G loss: 0.330784]\n",
      "epoch:2 step:2545 [D loss: 0.244226, acc.: 57.03%] [G loss: 0.308362]\n",
      "epoch:2 step:2546 [D loss: 0.252329, acc.: 57.81%] [G loss: 0.325909]\n",
      "epoch:2 step:2547 [D loss: 0.239621, acc.: 62.50%] [G loss: 0.359384]\n",
      "epoch:2 step:2548 [D loss: 0.261166, acc.: 54.69%] [G loss: 0.310721]\n",
      "epoch:2 step:2549 [D loss: 0.246099, acc.: 58.59%] [G loss: 0.339506]\n",
      "epoch:2 step:2550 [D loss: 0.231711, acc.: 64.06%] [G loss: 0.320759]\n",
      "epoch:2 step:2551 [D loss: 0.232779, acc.: 55.47%] [G loss: 0.350406]\n",
      "epoch:2 step:2552 [D loss: 0.247958, acc.: 58.59%] [G loss: 0.318500]\n",
      "epoch:2 step:2553 [D loss: 0.232423, acc.: 57.03%] [G loss: 0.379218]\n",
      "epoch:2 step:2554 [D loss: 0.233189, acc.: 64.84%] [G loss: 0.350356]\n",
      "epoch:2 step:2555 [D loss: 0.261246, acc.: 54.69%] [G loss: 0.330068]\n",
      "epoch:2 step:2556 [D loss: 0.251402, acc.: 57.81%] [G loss: 0.319983]\n",
      "epoch:2 step:2557 [D loss: 0.258019, acc.: 50.78%] [G loss: 0.350247]\n",
      "epoch:2 step:2558 [D loss: 0.231747, acc.: 64.84%] [G loss: 0.348027]\n",
      "epoch:2 step:2559 [D loss: 0.225242, acc.: 60.94%] [G loss: 0.353653]\n",
      "epoch:2 step:2560 [D loss: 0.248271, acc.: 55.47%] [G loss: 0.338410]\n",
      "epoch:2 step:2561 [D loss: 0.235500, acc.: 63.28%] [G loss: 0.325098]\n",
      "epoch:2 step:2562 [D loss: 0.244586, acc.: 53.91%] [G loss: 0.300305]\n",
      "epoch:2 step:2563 [D loss: 0.250192, acc.: 53.91%] [G loss: 0.348226]\n",
      "epoch:2 step:2564 [D loss: 0.252035, acc.: 52.34%] [G loss: 0.331193]\n",
      "epoch:2 step:2565 [D loss: 0.255550, acc.: 55.47%] [G loss: 0.310553]\n",
      "epoch:2 step:2566 [D loss: 0.248112, acc.: 57.81%] [G loss: 0.335580]\n",
      "epoch:2 step:2567 [D loss: 0.242748, acc.: 62.50%] [G loss: 0.327278]\n",
      "epoch:2 step:2568 [D loss: 0.222389, acc.: 60.94%] [G loss: 0.318796]\n",
      "epoch:2 step:2569 [D loss: 0.267485, acc.: 52.34%] [G loss: 0.327319]\n",
      "epoch:2 step:2570 [D loss: 0.217254, acc.: 62.50%] [G loss: 0.357538]\n",
      "epoch:2 step:2571 [D loss: 0.247254, acc.: 57.03%] [G loss: 0.290114]\n",
      "epoch:2 step:2572 [D loss: 0.211987, acc.: 64.06%] [G loss: 0.380844]\n",
      "epoch:2 step:2573 [D loss: 0.240762, acc.: 55.47%] [G loss: 0.312210]\n",
      "epoch:2 step:2574 [D loss: 0.252387, acc.: 54.69%] [G loss: 0.328134]\n",
      "epoch:2 step:2575 [D loss: 0.252452, acc.: 56.25%] [G loss: 0.320949]\n",
      "epoch:2 step:2576 [D loss: 0.242522, acc.: 58.59%] [G loss: 0.357240]\n",
      "epoch:2 step:2577 [D loss: 0.242710, acc.: 57.81%] [G loss: 0.301823]\n",
      "epoch:2 step:2578 [D loss: 0.246956, acc.: 53.91%] [G loss: 0.333796]\n",
      "epoch:2 step:2579 [D loss: 0.242117, acc.: 57.03%] [G loss: 0.329838]\n",
      "epoch:2 step:2580 [D loss: 0.254379, acc.: 56.25%] [G loss: 0.327291]\n",
      "epoch:2 step:2581 [D loss: 0.247558, acc.: 54.69%] [G loss: 0.318359]\n",
      "epoch:2 step:2582 [D loss: 0.231665, acc.: 62.50%] [G loss: 0.368782]\n",
      "epoch:2 step:2583 [D loss: 0.253700, acc.: 53.91%] [G loss: 0.350193]\n",
      "epoch:2 step:2584 [D loss: 0.237880, acc.: 60.16%] [G loss: 0.342787]\n",
      "epoch:2 step:2585 [D loss: 0.231090, acc.: 61.72%] [G loss: 0.328792]\n",
      "epoch:2 step:2586 [D loss: 0.238942, acc.: 63.28%] [G loss: 0.353810]\n",
      "epoch:2 step:2587 [D loss: 0.242584, acc.: 52.34%] [G loss: 0.315093]\n",
      "epoch:2 step:2588 [D loss: 0.219140, acc.: 67.19%] [G loss: 0.329839]\n",
      "epoch:2 step:2589 [D loss: 0.263837, acc.: 49.22%] [G loss: 0.337616]\n",
      "epoch:2 step:2590 [D loss: 0.238258, acc.: 64.84%] [G loss: 0.347220]\n",
      "epoch:2 step:2591 [D loss: 0.233871, acc.: 63.28%] [G loss: 0.354749]\n",
      "epoch:2 step:2592 [D loss: 0.237235, acc.: 61.72%] [G loss: 0.297044]\n",
      "epoch:2 step:2593 [D loss: 0.241244, acc.: 56.25%] [G loss: 0.313913]\n",
      "epoch:2 step:2594 [D loss: 0.232293, acc.: 60.94%] [G loss: 0.303570]\n",
      "epoch:2 step:2595 [D loss: 0.245396, acc.: 58.59%] [G loss: 0.302736]\n",
      "epoch:2 step:2596 [D loss: 0.239668, acc.: 63.28%] [G loss: 0.355119]\n",
      "epoch:2 step:2597 [D loss: 0.253983, acc.: 53.12%] [G loss: 0.346545]\n",
      "epoch:2 step:2598 [D loss: 0.251124, acc.: 57.81%] [G loss: 0.352489]\n",
      "epoch:2 step:2599 [D loss: 0.238248, acc.: 64.06%] [G loss: 0.326924]\n",
      "epoch:2 step:2600 [D loss: 0.224942, acc.: 66.41%] [G loss: 0.310819]\n",
      "epoch:2 step:2601 [D loss: 0.249324, acc.: 55.47%] [G loss: 0.327059]\n",
      "epoch:2 step:2602 [D loss: 0.226802, acc.: 60.16%] [G loss: 0.338371]\n",
      "epoch:2 step:2603 [D loss: 0.257851, acc.: 52.34%] [G loss: 0.336318]\n",
      "epoch:2 step:2604 [D loss: 0.233860, acc.: 64.84%] [G loss: 0.322737]\n",
      "epoch:2 step:2605 [D loss: 0.240901, acc.: 57.03%] [G loss: 0.370401]\n",
      "epoch:2 step:2606 [D loss: 0.247915, acc.: 57.81%] [G loss: 0.330233]\n",
      "epoch:2 step:2607 [D loss: 0.222645, acc.: 58.59%] [G loss: 0.354610]\n",
      "epoch:2 step:2608 [D loss: 0.229056, acc.: 66.41%] [G loss: 0.333869]\n",
      "epoch:2 step:2609 [D loss: 0.247217, acc.: 54.69%] [G loss: 0.332050]\n",
      "epoch:2 step:2610 [D loss: 0.244659, acc.: 58.59%] [G loss: 0.327496]\n",
      "epoch:2 step:2611 [D loss: 0.242269, acc.: 62.50%] [G loss: 0.333931]\n",
      "epoch:2 step:2612 [D loss: 0.254255, acc.: 49.22%] [G loss: 0.327823]\n",
      "epoch:2 step:2613 [D loss: 0.252620, acc.: 53.12%] [G loss: 0.358053]\n",
      "epoch:2 step:2614 [D loss: 0.257942, acc.: 52.34%] [G loss: 0.308998]\n",
      "epoch:2 step:2615 [D loss: 0.260111, acc.: 50.78%] [G loss: 0.292344]\n",
      "epoch:2 step:2616 [D loss: 0.233595, acc.: 59.38%] [G loss: 0.309461]\n",
      "epoch:2 step:2617 [D loss: 0.246143, acc.: 59.38%] [G loss: 0.329465]\n",
      "epoch:2 step:2618 [D loss: 0.260864, acc.: 52.34%] [G loss: 0.295753]\n",
      "epoch:2 step:2619 [D loss: 0.248145, acc.: 55.47%] [G loss: 0.303920]\n",
      "epoch:2 step:2620 [D loss: 0.229663, acc.: 60.94%] [G loss: 0.368725]\n",
      "epoch:2 step:2621 [D loss: 0.241480, acc.: 59.38%] [G loss: 0.322956]\n",
      "epoch:2 step:2622 [D loss: 0.215869, acc.: 65.62%] [G loss: 0.340334]\n",
      "epoch:2 step:2623 [D loss: 0.249421, acc.: 59.38%] [G loss: 0.341191]\n",
      "epoch:2 step:2624 [D loss: 0.282186, acc.: 50.00%] [G loss: 0.313763]\n",
      "epoch:2 step:2625 [D loss: 0.267012, acc.: 50.00%] [G loss: 0.270612]\n",
      "epoch:2 step:2626 [D loss: 0.216523, acc.: 60.94%] [G loss: 0.347901]\n",
      "epoch:2 step:2627 [D loss: 0.253114, acc.: 57.81%] [G loss: 0.313659]\n",
      "epoch:2 step:2628 [D loss: 0.243427, acc.: 57.03%] [G loss: 0.312581]\n",
      "epoch:2 step:2629 [D loss: 0.237901, acc.: 61.72%] [G loss: 0.310324]\n",
      "epoch:2 step:2630 [D loss: 0.238405, acc.: 55.47%] [G loss: 0.320132]\n",
      "epoch:2 step:2631 [D loss: 0.223362, acc.: 57.81%] [G loss: 0.306691]\n",
      "epoch:2 step:2632 [D loss: 0.244129, acc.: 56.25%] [G loss: 0.341153]\n",
      "epoch:2 step:2633 [D loss: 0.233620, acc.: 60.94%] [G loss: 0.323316]\n",
      "epoch:2 step:2634 [D loss: 0.258242, acc.: 53.12%] [G loss: 0.318641]\n",
      "epoch:2 step:2635 [D loss: 0.243315, acc.: 57.03%] [G loss: 0.309814]\n",
      "epoch:2 step:2636 [D loss: 0.240195, acc.: 57.81%] [G loss: 0.359371]\n",
      "epoch:2 step:2637 [D loss: 0.245566, acc.: 56.25%] [G loss: 0.289615]\n",
      "epoch:2 step:2638 [D loss: 0.238959, acc.: 58.59%] [G loss: 0.286968]\n",
      "epoch:2 step:2639 [D loss: 0.224600, acc.: 65.62%] [G loss: 0.310640]\n",
      "epoch:2 step:2640 [D loss: 0.251504, acc.: 56.25%] [G loss: 0.323672]\n",
      "epoch:2 step:2641 [D loss: 0.242611, acc.: 57.03%] [G loss: 0.297396]\n",
      "epoch:2 step:2642 [D loss: 0.237925, acc.: 58.59%] [G loss: 0.293412]\n",
      "epoch:2 step:2643 [D loss: 0.261564, acc.: 56.25%] [G loss: 0.307771]\n",
      "epoch:2 step:2644 [D loss: 0.247045, acc.: 52.34%] [G loss: 0.324331]\n",
      "epoch:2 step:2645 [D loss: 0.236133, acc.: 63.28%] [G loss: 0.323604]\n",
      "epoch:2 step:2646 [D loss: 0.241845, acc.: 54.69%] [G loss: 0.341163]\n",
      "epoch:2 step:2647 [D loss: 0.236479, acc.: 62.50%] [G loss: 0.318878]\n",
      "epoch:2 step:2648 [D loss: 0.217724, acc.: 65.62%] [G loss: 0.317493]\n",
      "epoch:2 step:2649 [D loss: 0.220426, acc.: 67.97%] [G loss: 0.324389]\n",
      "epoch:2 step:2650 [D loss: 0.224738, acc.: 60.94%] [G loss: 0.310752]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:2 step:2651 [D loss: 0.256219, acc.: 53.91%] [G loss: 0.309588]\n",
      "epoch:2 step:2652 [D loss: 0.241447, acc.: 57.03%] [G loss: 0.354909]\n",
      "epoch:2 step:2653 [D loss: 0.244467, acc.: 57.81%] [G loss: 0.281342]\n",
      "epoch:2 step:2654 [D loss: 0.250854, acc.: 53.91%] [G loss: 0.314421]\n",
      "epoch:2 step:2655 [D loss: 0.258709, acc.: 54.69%] [G loss: 0.296207]\n",
      "epoch:2 step:2656 [D loss: 0.234323, acc.: 59.38%] [G loss: 0.307342]\n",
      "epoch:2 step:2657 [D loss: 0.258632, acc.: 51.56%] [G loss: 0.343564]\n",
      "epoch:2 step:2658 [D loss: 0.232149, acc.: 57.03%] [G loss: 0.317908]\n",
      "epoch:2 step:2659 [D loss: 0.249835, acc.: 53.91%] [G loss: 0.310941]\n",
      "epoch:2 step:2660 [D loss: 0.236779, acc.: 61.72%] [G loss: 0.323804]\n",
      "epoch:2 step:2661 [D loss: 0.218067, acc.: 67.97%] [G loss: 0.312536]\n",
      "epoch:2 step:2662 [D loss: 0.247899, acc.: 55.47%] [G loss: 0.319986]\n",
      "epoch:2 step:2663 [D loss: 0.252389, acc.: 59.38%] [G loss: 0.311882]\n",
      "epoch:2 step:2664 [D loss: 0.248002, acc.: 55.47%] [G loss: 0.322099]\n",
      "epoch:2 step:2665 [D loss: 0.254357, acc.: 52.34%] [G loss: 0.319410]\n",
      "epoch:2 step:2666 [D loss: 0.218188, acc.: 64.84%] [G loss: 0.311588]\n",
      "epoch:2 step:2667 [D loss: 0.266673, acc.: 47.66%] [G loss: 0.292946]\n",
      "epoch:2 step:2668 [D loss: 0.246593, acc.: 64.06%] [G loss: 0.304383]\n",
      "epoch:2 step:2669 [D loss: 0.236521, acc.: 58.59%] [G loss: 0.307131]\n",
      "epoch:2 step:2670 [D loss: 0.218609, acc.: 64.84%] [G loss: 0.308450]\n",
      "epoch:2 step:2671 [D loss: 0.262804, acc.: 52.34%] [G loss: 0.320853]\n",
      "epoch:2 step:2672 [D loss: 0.237710, acc.: 61.72%] [G loss: 0.351034]\n",
      "epoch:2 step:2673 [D loss: 0.254457, acc.: 54.69%] [G loss: 0.327502]\n",
      "epoch:2 step:2674 [D loss: 0.229569, acc.: 63.28%] [G loss: 0.363319]\n",
      "epoch:2 step:2675 [D loss: 0.209421, acc.: 64.06%] [G loss: 0.356535]\n",
      "epoch:2 step:2676 [D loss: 0.264387, acc.: 50.00%] [G loss: 0.299660]\n",
      "epoch:2 step:2677 [D loss: 0.237685, acc.: 58.59%] [G loss: 0.333595]\n",
      "epoch:2 step:2678 [D loss: 0.246563, acc.: 56.25%] [G loss: 0.319588]\n",
      "epoch:2 step:2679 [D loss: 0.244482, acc.: 54.69%] [G loss: 0.316199]\n",
      "epoch:2 step:2680 [D loss: 0.231650, acc.: 54.69%] [G loss: 0.297314]\n",
      "epoch:2 step:2681 [D loss: 0.236665, acc.: 57.81%] [G loss: 0.330843]\n",
      "epoch:2 step:2682 [D loss: 0.228608, acc.: 64.06%] [G loss: 0.319971]\n",
      "epoch:2 step:2683 [D loss: 0.252396, acc.: 55.47%] [G loss: 0.293278]\n",
      "epoch:2 step:2684 [D loss: 0.248916, acc.: 56.25%] [G loss: 0.310712]\n",
      "epoch:2 step:2685 [D loss: 0.253658, acc.: 56.25%] [G loss: 0.323474]\n",
      "epoch:2 step:2686 [D loss: 0.206953, acc.: 67.19%] [G loss: 0.332721]\n",
      "epoch:2 step:2687 [D loss: 0.251471, acc.: 59.38%] [G loss: 0.341321]\n",
      "epoch:2 step:2688 [D loss: 0.233652, acc.: 57.81%] [G loss: 0.387083]\n",
      "epoch:2 step:2689 [D loss: 0.229385, acc.: 60.16%] [G loss: 0.345526]\n",
      "epoch:2 step:2690 [D loss: 0.230619, acc.: 64.06%] [G loss: 0.339344]\n",
      "epoch:2 step:2691 [D loss: 0.234582, acc.: 60.94%] [G loss: 0.323995]\n",
      "epoch:2 step:2692 [D loss: 0.223560, acc.: 60.16%] [G loss: 0.318295]\n",
      "epoch:2 step:2693 [D loss: 0.233301, acc.: 58.59%] [G loss: 0.299009]\n",
      "epoch:2 step:2694 [D loss: 0.235572, acc.: 64.06%] [G loss: 0.315693]\n",
      "epoch:2 step:2695 [D loss: 0.252485, acc.: 57.03%] [G loss: 0.323529]\n",
      "epoch:2 step:2696 [D loss: 0.273803, acc.: 44.53%] [G loss: 0.274938]\n",
      "epoch:2 step:2697 [D loss: 0.226505, acc.: 59.38%] [G loss: 0.332078]\n",
      "epoch:2 step:2698 [D loss: 0.244828, acc.: 57.03%] [G loss: 0.327235]\n",
      "epoch:2 step:2699 [D loss: 0.258102, acc.: 50.78%] [G loss: 0.313123]\n",
      "epoch:2 step:2700 [D loss: 0.248712, acc.: 51.56%] [G loss: 0.299309]\n",
      "epoch:2 step:2701 [D loss: 0.248926, acc.: 59.38%] [G loss: 0.335939]\n",
      "epoch:2 step:2702 [D loss: 0.252379, acc.: 52.34%] [G loss: 0.318795]\n",
      "epoch:2 step:2703 [D loss: 0.264310, acc.: 48.44%] [G loss: 0.333224]\n",
      "epoch:2 step:2704 [D loss: 0.245507, acc.: 57.03%] [G loss: 0.338131]\n",
      "epoch:2 step:2705 [D loss: 0.241865, acc.: 58.59%] [G loss: 0.333722]\n",
      "epoch:2 step:2706 [D loss: 0.238479, acc.: 57.81%] [G loss: 0.366886]\n",
      "epoch:2 step:2707 [D loss: 0.247862, acc.: 52.34%] [G loss: 0.316208]\n",
      "epoch:2 step:2708 [D loss: 0.261093, acc.: 50.78%] [G loss: 0.303111]\n",
      "epoch:2 step:2709 [D loss: 0.254200, acc.: 54.69%] [G loss: 0.316847]\n",
      "epoch:2 step:2710 [D loss: 0.228045, acc.: 64.84%] [G loss: 0.359113]\n",
      "epoch:2 step:2711 [D loss: 0.270140, acc.: 49.22%] [G loss: 0.307140]\n",
      "epoch:2 step:2712 [D loss: 0.216227, acc.: 68.75%] [G loss: 0.341721]\n",
      "epoch:2 step:2713 [D loss: 0.240786, acc.: 58.59%] [G loss: 0.302001]\n",
      "epoch:2 step:2714 [D loss: 0.229614, acc.: 63.28%] [G loss: 0.308139]\n",
      "epoch:2 step:2715 [D loss: 0.254834, acc.: 50.00%] [G loss: 0.302164]\n",
      "epoch:2 step:2716 [D loss: 0.246992, acc.: 51.56%] [G loss: 0.312930]\n",
      "epoch:2 step:2717 [D loss: 0.226422, acc.: 57.81%] [G loss: 0.313739]\n",
      "epoch:2 step:2718 [D loss: 0.250570, acc.: 53.12%] [G loss: 0.324677]\n",
      "epoch:2 step:2719 [D loss: 0.245486, acc.: 56.25%] [G loss: 0.312427]\n",
      "epoch:2 step:2720 [D loss: 0.245351, acc.: 53.12%] [G loss: 0.338784]\n",
      "epoch:2 step:2721 [D loss: 0.245904, acc.: 54.69%] [G loss: 0.320340]\n",
      "epoch:2 step:2722 [D loss: 0.245475, acc.: 52.34%] [G loss: 0.321695]\n",
      "epoch:2 step:2723 [D loss: 0.241765, acc.: 60.94%] [G loss: 0.339740]\n",
      "epoch:2 step:2724 [D loss: 0.260643, acc.: 60.16%] [G loss: 0.310302]\n",
      "epoch:2 step:2725 [D loss: 0.271371, acc.: 47.66%] [G loss: 0.304441]\n",
      "epoch:2 step:2726 [D loss: 0.232531, acc.: 60.16%] [G loss: 0.325245]\n",
      "epoch:2 step:2727 [D loss: 0.240543, acc.: 54.69%] [G loss: 0.315509]\n",
      "epoch:2 step:2728 [D loss: 0.230419, acc.: 64.06%] [G loss: 0.297176]\n",
      "epoch:2 step:2729 [D loss: 0.272340, acc.: 49.22%] [G loss: 0.307870]\n",
      "epoch:2 step:2730 [D loss: 0.226399, acc.: 61.72%] [G loss: 0.346202]\n",
      "epoch:2 step:2731 [D loss: 0.251758, acc.: 50.00%] [G loss: 0.327869]\n",
      "epoch:2 step:2732 [D loss: 0.249919, acc.: 56.25%] [G loss: 0.343169]\n",
      "epoch:2 step:2733 [D loss: 0.232411, acc.: 64.84%] [G loss: 0.301258]\n",
      "epoch:2 step:2734 [D loss: 0.224487, acc.: 67.97%] [G loss: 0.309950]\n",
      "epoch:2 step:2735 [D loss: 0.248445, acc.: 54.69%] [G loss: 0.323954]\n",
      "epoch:2 step:2736 [D loss: 0.217985, acc.: 65.62%] [G loss: 0.324819]\n",
      "epoch:2 step:2737 [D loss: 0.263666, acc.: 54.69%] [G loss: 0.335236]\n",
      "epoch:2 step:2738 [D loss: 0.253165, acc.: 54.69%] [G loss: 0.366456]\n",
      "epoch:2 step:2739 [D loss: 0.253513, acc.: 50.78%] [G loss: 0.331038]\n",
      "epoch:2 step:2740 [D loss: 0.247762, acc.: 59.38%] [G loss: 0.344147]\n",
      "epoch:2 step:2741 [D loss: 0.240732, acc.: 62.50%] [G loss: 0.336586]\n",
      "epoch:2 step:2742 [D loss: 0.224996, acc.: 60.94%] [G loss: 0.336679]\n",
      "epoch:2 step:2743 [D loss: 0.206462, acc.: 69.53%] [G loss: 0.364473]\n",
      "epoch:2 step:2744 [D loss: 0.243518, acc.: 53.91%] [G loss: 0.338657]\n",
      "epoch:2 step:2745 [D loss: 0.229742, acc.: 60.16%] [G loss: 0.313495]\n",
      "epoch:2 step:2746 [D loss: 0.240972, acc.: 56.25%] [G loss: 0.356946]\n",
      "epoch:2 step:2747 [D loss: 0.234293, acc.: 61.72%] [G loss: 0.313123]\n",
      "epoch:2 step:2748 [D loss: 0.249617, acc.: 55.47%] [G loss: 0.320482]\n",
      "epoch:2 step:2749 [D loss: 0.234130, acc.: 55.47%] [G loss: 0.326714]\n",
      "epoch:2 step:2750 [D loss: 0.263072, acc.: 52.34%] [G loss: 0.348394]\n",
      "epoch:2 step:2751 [D loss: 0.232670, acc.: 60.94%] [G loss: 0.322549]\n",
      "epoch:2 step:2752 [D loss: 0.245804, acc.: 57.03%] [G loss: 0.310960]\n",
      "epoch:2 step:2753 [D loss: 0.239626, acc.: 60.94%] [G loss: 0.283828]\n",
      "epoch:2 step:2754 [D loss: 0.239644, acc.: 56.25%] [G loss: 0.307041]\n",
      "epoch:2 step:2755 [D loss: 0.247826, acc.: 57.03%] [G loss: 0.337366]\n",
      "epoch:2 step:2756 [D loss: 0.230800, acc.: 58.59%] [G loss: 0.323158]\n",
      "epoch:2 step:2757 [D loss: 0.253951, acc.: 50.78%] [G loss: 0.315692]\n",
      "epoch:2 step:2758 [D loss: 0.240614, acc.: 59.38%] [G loss: 0.314269]\n",
      "epoch:2 step:2759 [D loss: 0.252857, acc.: 49.22%] [G loss: 0.353686]\n",
      "epoch:2 step:2760 [D loss: 0.247586, acc.: 59.38%] [G loss: 0.338715]\n",
      "epoch:2 step:2761 [D loss: 0.236844, acc.: 57.03%] [G loss: 0.312108]\n",
      "epoch:2 step:2762 [D loss: 0.236612, acc.: 60.16%] [G loss: 0.326368]\n",
      "epoch:2 step:2763 [D loss: 0.263813, acc.: 48.44%] [G loss: 0.345559]\n",
      "epoch:2 step:2764 [D loss: 0.271793, acc.: 50.00%] [G loss: 0.309853]\n",
      "epoch:2 step:2765 [D loss: 0.248497, acc.: 57.81%] [G loss: 0.326498]\n",
      "epoch:2 step:2766 [D loss: 0.252971, acc.: 54.69%] [G loss: 0.334235]\n",
      "epoch:2 step:2767 [D loss: 0.233684, acc.: 61.72%] [G loss: 0.308026]\n",
      "epoch:2 step:2768 [D loss: 0.237640, acc.: 60.94%] [G loss: 0.353869]\n",
      "epoch:2 step:2769 [D loss: 0.235047, acc.: 64.84%] [G loss: 0.319188]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:2 step:2770 [D loss: 0.256285, acc.: 50.78%] [G loss: 0.336087]\n",
      "epoch:2 step:2771 [D loss: 0.227830, acc.: 60.94%] [G loss: 0.312917]\n",
      "epoch:2 step:2772 [D loss: 0.219253, acc.: 62.50%] [G loss: 0.309968]\n",
      "epoch:2 step:2773 [D loss: 0.233464, acc.: 58.59%] [G loss: 0.347431]\n",
      "epoch:2 step:2774 [D loss: 0.232872, acc.: 63.28%] [G loss: 0.341028]\n",
      "epoch:2 step:2775 [D loss: 0.253719, acc.: 57.03%] [G loss: 0.303984]\n",
      "epoch:2 step:2776 [D loss: 0.234424, acc.: 60.16%] [G loss: 0.344895]\n",
      "epoch:2 step:2777 [D loss: 0.228152, acc.: 66.41%] [G loss: 0.308632]\n",
      "epoch:2 step:2778 [D loss: 0.206711, acc.: 66.41%] [G loss: 0.316554]\n",
      "epoch:2 step:2779 [D loss: 0.247328, acc.: 59.38%] [G loss: 0.328924]\n",
      "epoch:2 step:2780 [D loss: 0.238465, acc.: 57.03%] [G loss: 0.322080]\n",
      "epoch:2 step:2781 [D loss: 0.228899, acc.: 64.06%] [G loss: 0.292304]\n",
      "epoch:2 step:2782 [D loss: 0.248373, acc.: 57.81%] [G loss: 0.346218]\n",
      "epoch:2 step:2783 [D loss: 0.239105, acc.: 58.59%] [G loss: 0.353870]\n",
      "epoch:2 step:2784 [D loss: 0.238060, acc.: 60.16%] [G loss: 0.348760]\n",
      "epoch:2 step:2785 [D loss: 0.226217, acc.: 63.28%] [G loss: 0.309315]\n",
      "epoch:2 step:2786 [D loss: 0.249432, acc.: 57.03%] [G loss: 0.301054]\n",
      "epoch:2 step:2787 [D loss: 0.234273, acc.: 60.16%] [G loss: 0.318651]\n",
      "epoch:2 step:2788 [D loss: 0.247799, acc.: 55.47%] [G loss: 0.294261]\n",
      "epoch:2 step:2789 [D loss: 0.243909, acc.: 60.16%] [G loss: 0.342478]\n",
      "epoch:2 step:2790 [D loss: 0.235956, acc.: 60.16%] [G loss: 0.321282]\n",
      "epoch:2 step:2791 [D loss: 0.247952, acc.: 57.03%] [G loss: 0.341735]\n",
      "epoch:2 step:2792 [D loss: 0.281922, acc.: 47.66%] [G loss: 0.285907]\n",
      "epoch:2 step:2793 [D loss: 0.216060, acc.: 71.09%] [G loss: 0.310782]\n",
      "epoch:2 step:2794 [D loss: 0.243639, acc.: 53.12%] [G loss: 0.322380]\n",
      "epoch:2 step:2795 [D loss: 0.227137, acc.: 64.06%] [G loss: 0.329776]\n",
      "epoch:2 step:2796 [D loss: 0.242629, acc.: 57.81%] [G loss: 0.336793]\n",
      "epoch:2 step:2797 [D loss: 0.229564, acc.: 62.50%] [G loss: 0.329189]\n",
      "epoch:2 step:2798 [D loss: 0.251603, acc.: 52.34%] [G loss: 0.344900]\n",
      "epoch:2 step:2799 [D loss: 0.251175, acc.: 53.91%] [G loss: 0.333934]\n",
      "epoch:2 step:2800 [D loss: 0.248630, acc.: 55.47%] [G loss: 0.295222]\n",
      "epoch:2 step:2801 [D loss: 0.232879, acc.: 61.72%] [G loss: 0.293837]\n",
      "epoch:2 step:2802 [D loss: 0.233263, acc.: 60.16%] [G loss: 0.314717]\n",
      "epoch:2 step:2803 [D loss: 0.232881, acc.: 61.72%] [G loss: 0.338042]\n",
      "epoch:2 step:2804 [D loss: 0.257712, acc.: 61.72%] [G loss: 0.288155]\n",
      "epoch:2 step:2805 [D loss: 0.257888, acc.: 48.44%] [G loss: 0.331328]\n",
      "epoch:2 step:2806 [D loss: 0.242475, acc.: 57.03%] [G loss: 0.301942]\n",
      "epoch:2 step:2807 [D loss: 0.260607, acc.: 54.69%] [G loss: 0.303904]\n",
      "epoch:2 step:2808 [D loss: 0.245975, acc.: 59.38%] [G loss: 0.312397]\n",
      "epoch:2 step:2809 [D loss: 0.255934, acc.: 54.69%] [G loss: 0.306669]\n",
      "epoch:2 step:2810 [D loss: 0.220056, acc.: 66.41%] [G loss: 0.293844]\n",
      "epoch:2 step:2811 [D loss: 0.247660, acc.: 53.12%] [G loss: 0.344994]\n",
      "epoch:3 step:2812 [D loss: 0.234724, acc.: 59.38%] [G loss: 0.322991]\n",
      "epoch:3 step:2813 [D loss: 0.262788, acc.: 52.34%] [G loss: 0.300476]\n",
      "epoch:3 step:2814 [D loss: 0.238279, acc.: 57.81%] [G loss: 0.324188]\n",
      "epoch:3 step:2815 [D loss: 0.249268, acc.: 51.56%] [G loss: 0.305495]\n",
      "epoch:3 step:2816 [D loss: 0.242623, acc.: 58.59%] [G loss: 0.303280]\n",
      "epoch:3 step:2817 [D loss: 0.247762, acc.: 57.03%] [G loss: 0.349742]\n",
      "epoch:3 step:2818 [D loss: 0.246865, acc.: 55.47%] [G loss: 0.338415]\n",
      "epoch:3 step:2819 [D loss: 0.244823, acc.: 51.56%] [G loss: 0.308400]\n",
      "epoch:3 step:2820 [D loss: 0.237235, acc.: 57.81%] [G loss: 0.298835]\n",
      "epoch:3 step:2821 [D loss: 0.235775, acc.: 57.81%] [G loss: 0.305334]\n",
      "epoch:3 step:2822 [D loss: 0.232158, acc.: 60.16%] [G loss: 0.325758]\n",
      "epoch:3 step:2823 [D loss: 0.243015, acc.: 59.38%] [G loss: 0.313497]\n",
      "epoch:3 step:2824 [D loss: 0.235796, acc.: 64.06%] [G loss: 0.299455]\n",
      "epoch:3 step:2825 [D loss: 0.231881, acc.: 57.03%] [G loss: 0.318719]\n",
      "epoch:3 step:2826 [D loss: 0.238232, acc.: 54.69%] [G loss: 0.321547]\n",
      "epoch:3 step:2827 [D loss: 0.219829, acc.: 64.06%] [G loss: 0.350106]\n",
      "epoch:3 step:2828 [D loss: 0.235886, acc.: 63.28%] [G loss: 0.311675]\n",
      "epoch:3 step:2829 [D loss: 0.251635, acc.: 52.34%] [G loss: 0.334275]\n",
      "epoch:3 step:2830 [D loss: 0.223787, acc.: 64.06%] [G loss: 0.332323]\n",
      "epoch:3 step:2831 [D loss: 0.219231, acc.: 64.84%] [G loss: 0.342450]\n",
      "epoch:3 step:2832 [D loss: 0.247913, acc.: 50.78%] [G loss: 0.312321]\n",
      "epoch:3 step:2833 [D loss: 0.258277, acc.: 54.69%] [G loss: 0.290268]\n",
      "epoch:3 step:2834 [D loss: 0.250567, acc.: 56.25%] [G loss: 0.306636]\n",
      "epoch:3 step:2835 [D loss: 0.263626, acc.: 53.91%] [G loss: 0.330848]\n",
      "epoch:3 step:2836 [D loss: 0.257734, acc.: 52.34%] [G loss: 0.310752]\n",
      "epoch:3 step:2837 [D loss: 0.222009, acc.: 64.84%] [G loss: 0.358675]\n",
      "epoch:3 step:2838 [D loss: 0.233778, acc.: 57.03%] [G loss: 0.321844]\n",
      "epoch:3 step:2839 [D loss: 0.252301, acc.: 47.66%] [G loss: 0.348515]\n",
      "epoch:3 step:2840 [D loss: 0.239918, acc.: 59.38%] [G loss: 0.336513]\n",
      "epoch:3 step:2841 [D loss: 0.242221, acc.: 57.03%] [G loss: 0.345228]\n",
      "epoch:3 step:2842 [D loss: 0.253749, acc.: 52.34%] [G loss: 0.342323]\n",
      "epoch:3 step:2843 [D loss: 0.236180, acc.: 58.59%] [G loss: 0.325810]\n",
      "epoch:3 step:2844 [D loss: 0.248431, acc.: 57.81%] [G loss: 0.341064]\n",
      "epoch:3 step:2845 [D loss: 0.239709, acc.: 56.25%] [G loss: 0.302780]\n",
      "epoch:3 step:2846 [D loss: 0.236417, acc.: 64.06%] [G loss: 0.330952]\n",
      "epoch:3 step:2847 [D loss: 0.236737, acc.: 60.16%] [G loss: 0.320377]\n",
      "epoch:3 step:2848 [D loss: 0.244551, acc.: 50.78%] [G loss: 0.346184]\n",
      "epoch:3 step:2849 [D loss: 0.252929, acc.: 56.25%] [G loss: 0.353459]\n",
      "epoch:3 step:2850 [D loss: 0.238941, acc.: 58.59%] [G loss: 0.329548]\n",
      "epoch:3 step:2851 [D loss: 0.244612, acc.: 57.03%] [G loss: 0.292972]\n",
      "epoch:3 step:2852 [D loss: 0.224318, acc.: 63.28%] [G loss: 0.320066]\n",
      "epoch:3 step:2853 [D loss: 0.224960, acc.: 63.28%] [G loss: 0.360455]\n",
      "epoch:3 step:2854 [D loss: 0.239263, acc.: 53.91%] [G loss: 0.311195]\n",
      "epoch:3 step:2855 [D loss: 0.247973, acc.: 56.25%] [G loss: 0.375921]\n",
      "epoch:3 step:2856 [D loss: 0.225846, acc.: 61.72%] [G loss: 0.326238]\n",
      "epoch:3 step:2857 [D loss: 0.259163, acc.: 52.34%] [G loss: 0.306556]\n",
      "epoch:3 step:2858 [D loss: 0.248568, acc.: 55.47%] [G loss: 0.326144]\n",
      "epoch:3 step:2859 [D loss: 0.220112, acc.: 64.84%] [G loss: 0.300372]\n",
      "epoch:3 step:2860 [D loss: 0.239060, acc.: 57.03%] [G loss: 0.335514]\n",
      "epoch:3 step:2861 [D loss: 0.235605, acc.: 60.94%] [G loss: 0.325862]\n",
      "epoch:3 step:2862 [D loss: 0.267832, acc.: 51.56%] [G loss: 0.296281]\n",
      "epoch:3 step:2863 [D loss: 0.242797, acc.: 53.12%] [G loss: 0.329160]\n",
      "epoch:3 step:2864 [D loss: 0.247519, acc.: 60.94%] [G loss: 0.353069]\n",
      "epoch:3 step:2865 [D loss: 0.238387, acc.: 60.94%] [G loss: 0.309219]\n",
      "epoch:3 step:2866 [D loss: 0.255109, acc.: 55.47%] [G loss: 0.314224]\n",
      "epoch:3 step:2867 [D loss: 0.250404, acc.: 50.00%] [G loss: 0.292091]\n",
      "epoch:3 step:2868 [D loss: 0.241195, acc.: 57.03%] [G loss: 0.304273]\n",
      "epoch:3 step:2869 [D loss: 0.254175, acc.: 47.66%] [G loss: 0.296143]\n",
      "epoch:3 step:2870 [D loss: 0.271449, acc.: 53.12%] [G loss: 0.293171]\n",
      "epoch:3 step:2871 [D loss: 0.229348, acc.: 63.28%] [G loss: 0.334151]\n",
      "epoch:3 step:2872 [D loss: 0.258383, acc.: 49.22%] [G loss: 0.331603]\n",
      "epoch:3 step:2873 [D loss: 0.240729, acc.: 59.38%] [G loss: 0.305802]\n",
      "epoch:3 step:2874 [D loss: 0.232903, acc.: 61.72%] [G loss: 0.305194]\n",
      "epoch:3 step:2875 [D loss: 0.236377, acc.: 58.59%] [G loss: 0.302410]\n",
      "epoch:3 step:2876 [D loss: 0.234844, acc.: 58.59%] [G loss: 0.334549]\n",
      "epoch:3 step:2877 [D loss: 0.228831, acc.: 60.94%] [G loss: 0.317850]\n",
      "epoch:3 step:2878 [D loss: 0.229698, acc.: 58.59%] [G loss: 0.308241]\n",
      "epoch:3 step:2879 [D loss: 0.259709, acc.: 51.56%] [G loss: 0.304947]\n",
      "epoch:3 step:2880 [D loss: 0.237916, acc.: 57.03%] [G loss: 0.316989]\n",
      "epoch:3 step:2881 [D loss: 0.253607, acc.: 53.91%] [G loss: 0.310921]\n",
      "epoch:3 step:2882 [D loss: 0.230542, acc.: 60.94%] [G loss: 0.342316]\n",
      "epoch:3 step:2883 [D loss: 0.225529, acc.: 65.62%] [G loss: 0.319696]\n",
      "epoch:3 step:2884 [D loss: 0.221491, acc.: 62.50%] [G loss: 0.350392]\n",
      "epoch:3 step:2885 [D loss: 0.250568, acc.: 52.34%] [G loss: 0.320852]\n",
      "epoch:3 step:2886 [D loss: 0.244905, acc.: 54.69%] [G loss: 0.312003]\n",
      "epoch:3 step:2887 [D loss: 0.238167, acc.: 59.38%] [G loss: 0.315041]\n",
      "epoch:3 step:2888 [D loss: 0.231966, acc.: 63.28%] [G loss: 0.316178]\n",
      "epoch:3 step:2889 [D loss: 0.245321, acc.: 55.47%] [G loss: 0.328191]\n",
      "epoch:3 step:2890 [D loss: 0.261648, acc.: 54.69%] [G loss: 0.320011]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:3 step:2891 [D loss: 0.242317, acc.: 55.47%] [G loss: 0.314223]\n",
      "epoch:3 step:2892 [D loss: 0.235750, acc.: 60.16%] [G loss: 0.324289]\n",
      "epoch:3 step:2893 [D loss: 0.235466, acc.: 57.03%] [G loss: 0.340854]\n",
      "epoch:3 step:2894 [D loss: 0.241841, acc.: 57.81%] [G loss: 0.358606]\n",
      "epoch:3 step:2895 [D loss: 0.257082, acc.: 51.56%] [G loss: 0.315276]\n",
      "epoch:3 step:2896 [D loss: 0.234178, acc.: 59.38%] [G loss: 0.312052]\n",
      "epoch:3 step:2897 [D loss: 0.245872, acc.: 57.03%] [G loss: 0.328372]\n",
      "epoch:3 step:2898 [D loss: 0.259545, acc.: 53.91%] [G loss: 0.317488]\n",
      "epoch:3 step:2899 [D loss: 0.230649, acc.: 64.06%] [G loss: 0.347101]\n",
      "epoch:3 step:2900 [D loss: 0.255988, acc.: 53.12%] [G loss: 0.316458]\n",
      "epoch:3 step:2901 [D loss: 0.243922, acc.: 54.69%] [G loss: 0.326754]\n",
      "epoch:3 step:2902 [D loss: 0.256463, acc.: 52.34%] [G loss: 0.297399]\n",
      "epoch:3 step:2903 [D loss: 0.228810, acc.: 61.72%] [G loss: 0.304011]\n",
      "epoch:3 step:2904 [D loss: 0.247656, acc.: 57.81%] [G loss: 0.308007]\n",
      "epoch:3 step:2905 [D loss: 0.233641, acc.: 59.38%] [G loss: 0.334399]\n",
      "epoch:3 step:2906 [D loss: 0.241907, acc.: 62.50%] [G loss: 0.314509]\n",
      "epoch:3 step:2907 [D loss: 0.237424, acc.: 64.06%] [G loss: 0.332677]\n",
      "epoch:3 step:2908 [D loss: 0.248951, acc.: 55.47%] [G loss: 0.302139]\n",
      "epoch:3 step:2909 [D loss: 0.241492, acc.: 50.00%] [G loss: 0.327533]\n",
      "epoch:3 step:2910 [D loss: 0.224155, acc.: 65.62%] [G loss: 0.356177]\n",
      "epoch:3 step:2911 [D loss: 0.253407, acc.: 57.03%] [G loss: 0.292980]\n",
      "epoch:3 step:2912 [D loss: 0.248124, acc.: 53.12%] [G loss: 0.296520]\n",
      "epoch:3 step:2913 [D loss: 0.249257, acc.: 56.25%] [G loss: 0.300832]\n",
      "epoch:3 step:2914 [D loss: 0.234765, acc.: 57.81%] [G loss: 0.332968]\n",
      "epoch:3 step:2915 [D loss: 0.241240, acc.: 59.38%] [G loss: 0.358876]\n",
      "epoch:3 step:2916 [D loss: 0.238557, acc.: 62.50%] [G loss: 0.321545]\n",
      "epoch:3 step:2917 [D loss: 0.250750, acc.: 51.56%] [G loss: 0.341613]\n",
      "epoch:3 step:2918 [D loss: 0.224839, acc.: 60.94%] [G loss: 0.309963]\n",
      "epoch:3 step:2919 [D loss: 0.233671, acc.: 60.94%] [G loss: 0.321692]\n",
      "epoch:3 step:2920 [D loss: 0.227524, acc.: 65.62%] [G loss: 0.359784]\n",
      "epoch:3 step:2921 [D loss: 0.277725, acc.: 44.53%] [G loss: 0.340883]\n",
      "epoch:3 step:2922 [D loss: 0.245699, acc.: 55.47%] [G loss: 0.303331]\n",
      "epoch:3 step:2923 [D loss: 0.254685, acc.: 54.69%] [G loss: 0.312181]\n",
      "epoch:3 step:2924 [D loss: 0.240515, acc.: 56.25%] [G loss: 0.305994]\n",
      "epoch:3 step:2925 [D loss: 0.252578, acc.: 53.12%] [G loss: 0.305862]\n",
      "epoch:3 step:2926 [D loss: 0.277283, acc.: 51.56%] [G loss: 0.319236]\n",
      "epoch:3 step:2927 [D loss: 0.267062, acc.: 48.44%] [G loss: 0.309853]\n",
      "epoch:3 step:2928 [D loss: 0.244343, acc.: 55.47%] [G loss: 0.299045]\n",
      "epoch:3 step:2929 [D loss: 0.225982, acc.: 57.81%] [G loss: 0.315869]\n",
      "epoch:3 step:2930 [D loss: 0.236266, acc.: 65.62%] [G loss: 0.296911]\n",
      "epoch:3 step:2931 [D loss: 0.244879, acc.: 57.81%] [G loss: 0.304450]\n",
      "epoch:3 step:2932 [D loss: 0.244277, acc.: 59.38%] [G loss: 0.352714]\n",
      "epoch:3 step:2933 [D loss: 0.250912, acc.: 56.25%] [G loss: 0.288305]\n",
      "epoch:3 step:2934 [D loss: 0.241526, acc.: 58.59%] [G loss: 0.287298]\n",
      "epoch:3 step:2935 [D loss: 0.247710, acc.: 55.47%] [G loss: 0.348157]\n",
      "epoch:3 step:2936 [D loss: 0.231561, acc.: 57.81%] [G loss: 0.296115]\n",
      "epoch:3 step:2937 [D loss: 0.249144, acc.: 55.47%] [G loss: 0.284756]\n",
      "epoch:3 step:2938 [D loss: 0.240986, acc.: 57.81%] [G loss: 0.317783]\n",
      "epoch:3 step:2939 [D loss: 0.237215, acc.: 60.94%] [G loss: 0.331587]\n",
      "epoch:3 step:2940 [D loss: 0.254071, acc.: 52.34%] [G loss: 0.308224]\n",
      "epoch:3 step:2941 [D loss: 0.246070, acc.: 60.16%] [G loss: 0.311513]\n",
      "epoch:3 step:2942 [D loss: 0.233464, acc.: 59.38%] [G loss: 0.337888]\n",
      "epoch:3 step:2943 [D loss: 0.249824, acc.: 52.34%] [G loss: 0.337106]\n",
      "epoch:3 step:2944 [D loss: 0.235277, acc.: 57.03%] [G loss: 0.308771]\n",
      "epoch:3 step:2945 [D loss: 0.253009, acc.: 52.34%] [G loss: 0.354421]\n",
      "epoch:3 step:2946 [D loss: 0.237465, acc.: 61.72%] [G loss: 0.347855]\n",
      "epoch:3 step:2947 [D loss: 0.250166, acc.: 53.91%] [G loss: 0.332126]\n",
      "epoch:3 step:2948 [D loss: 0.232962, acc.: 63.28%] [G loss: 0.356053]\n",
      "epoch:3 step:2949 [D loss: 0.237974, acc.: 57.81%] [G loss: 0.356779]\n",
      "epoch:3 step:2950 [D loss: 0.227494, acc.: 60.94%] [G loss: 0.305223]\n",
      "epoch:3 step:2951 [D loss: 0.229055, acc.: 59.38%] [G loss: 0.353556]\n",
      "epoch:3 step:2952 [D loss: 0.232032, acc.: 61.72%] [G loss: 0.321992]\n",
      "epoch:3 step:2953 [D loss: 0.225852, acc.: 60.94%] [G loss: 0.331637]\n",
      "epoch:3 step:2954 [D loss: 0.245384, acc.: 53.91%] [G loss: 0.316584]\n",
      "epoch:3 step:2955 [D loss: 0.234597, acc.: 60.94%] [G loss: 0.331567]\n",
      "epoch:3 step:2956 [D loss: 0.266807, acc.: 50.78%] [G loss: 0.321153]\n",
      "epoch:3 step:2957 [D loss: 0.246281, acc.: 55.47%] [G loss: 0.354307]\n",
      "epoch:3 step:2958 [D loss: 0.238027, acc.: 60.94%] [G loss: 0.334038]\n",
      "epoch:3 step:2959 [D loss: 0.249096, acc.: 50.78%] [G loss: 0.343391]\n",
      "epoch:3 step:2960 [D loss: 0.259502, acc.: 54.69%] [G loss: 0.330429]\n",
      "epoch:3 step:2961 [D loss: 0.240768, acc.: 59.38%] [G loss: 0.303500]\n",
      "epoch:3 step:2962 [D loss: 0.247604, acc.: 56.25%] [G loss: 0.326890]\n",
      "epoch:3 step:2963 [D loss: 0.214717, acc.: 67.19%] [G loss: 0.314746]\n",
      "epoch:3 step:2964 [D loss: 0.253910, acc.: 53.91%] [G loss: 0.318437]\n",
      "epoch:3 step:2965 [D loss: 0.242694, acc.: 57.81%] [G loss: 0.288172]\n",
      "epoch:3 step:2966 [D loss: 0.233555, acc.: 57.81%] [G loss: 0.271066]\n",
      "epoch:3 step:2967 [D loss: 0.247313, acc.: 54.69%] [G loss: 0.301523]\n",
      "epoch:3 step:2968 [D loss: 0.251813, acc.: 60.16%] [G loss: 0.283796]\n",
      "epoch:3 step:2969 [D loss: 0.246016, acc.: 57.03%] [G loss: 0.319413]\n",
      "epoch:3 step:2970 [D loss: 0.238794, acc.: 62.50%] [G loss: 0.308644]\n",
      "epoch:3 step:2971 [D loss: 0.250792, acc.: 56.25%] [G loss: 0.306962]\n",
      "epoch:3 step:2972 [D loss: 0.236940, acc.: 58.59%] [G loss: 0.298565]\n",
      "epoch:3 step:2973 [D loss: 0.251486, acc.: 56.25%] [G loss: 0.340901]\n",
      "epoch:3 step:2974 [D loss: 0.215270, acc.: 68.75%] [G loss: 0.373037]\n",
      "epoch:3 step:2975 [D loss: 0.236000, acc.: 55.47%] [G loss: 0.313559]\n",
      "epoch:3 step:2976 [D loss: 0.238816, acc.: 57.81%] [G loss: 0.304764]\n",
      "epoch:3 step:2977 [D loss: 0.211871, acc.: 68.75%] [G loss: 0.343301]\n",
      "epoch:3 step:2978 [D loss: 0.241249, acc.: 60.16%] [G loss: 0.300504]\n",
      "epoch:3 step:2979 [D loss: 0.249160, acc.: 57.81%] [G loss: 0.329502]\n",
      "epoch:3 step:2980 [D loss: 0.266294, acc.: 51.56%] [G loss: 0.318543]\n",
      "epoch:3 step:2981 [D loss: 0.264423, acc.: 50.78%] [G loss: 0.305873]\n",
      "epoch:3 step:2982 [D loss: 0.249252, acc.: 56.25%] [G loss: 0.325685]\n",
      "epoch:3 step:2983 [D loss: 0.240186, acc.: 57.81%] [G loss: 0.315245]\n",
      "epoch:3 step:2984 [D loss: 0.236022, acc.: 61.72%] [G loss: 0.324394]\n",
      "epoch:3 step:2985 [D loss: 0.253285, acc.: 57.81%] [G loss: 0.327914]\n",
      "epoch:3 step:2986 [D loss: 0.230580, acc.: 64.06%] [G loss: 0.336649]\n",
      "epoch:3 step:2987 [D loss: 0.261542, acc.: 48.44%] [G loss: 0.303745]\n",
      "epoch:3 step:2988 [D loss: 0.220023, acc.: 64.06%] [G loss: 0.291094]\n",
      "epoch:3 step:2989 [D loss: 0.268435, acc.: 50.00%] [G loss: 0.286947]\n",
      "epoch:3 step:2990 [D loss: 0.223068, acc.: 63.28%] [G loss: 0.308108]\n",
      "epoch:3 step:2991 [D loss: 0.261750, acc.: 54.69%] [G loss: 0.277498]\n",
      "epoch:3 step:2992 [D loss: 0.250428, acc.: 53.91%] [G loss: 0.342742]\n",
      "epoch:3 step:2993 [D loss: 0.242173, acc.: 59.38%] [G loss: 0.306238]\n",
      "epoch:3 step:2994 [D loss: 0.228540, acc.: 62.50%] [G loss: 0.308115]\n",
      "epoch:3 step:2995 [D loss: 0.233282, acc.: 58.59%] [G loss: 0.325204]\n",
      "epoch:3 step:2996 [D loss: 0.253998, acc.: 57.03%] [G loss: 0.287150]\n",
      "epoch:3 step:2997 [D loss: 0.241361, acc.: 64.06%] [G loss: 0.352169]\n",
      "epoch:3 step:2998 [D loss: 0.246319, acc.: 58.59%] [G loss: 0.374098]\n",
      "epoch:3 step:2999 [D loss: 0.239270, acc.: 57.03%] [G loss: 0.294584]\n",
      "epoch:3 step:3000 [D loss: 0.254127, acc.: 54.69%] [G loss: 0.342014]\n",
      "epoch:3 step:3001 [D loss: 0.244756, acc.: 56.25%] [G loss: 0.327654]\n",
      "epoch:3 step:3002 [D loss: 0.228830, acc.: 58.59%] [G loss: 0.314143]\n",
      "epoch:3 step:3003 [D loss: 0.244637, acc.: 56.25%] [G loss: 0.308227]\n",
      "epoch:3 step:3004 [D loss: 0.235225, acc.: 60.94%] [G loss: 0.364936]\n",
      "epoch:3 step:3005 [D loss: 0.267548, acc.: 50.78%] [G loss: 0.320790]\n",
      "epoch:3 step:3006 [D loss: 0.247564, acc.: 53.91%] [G loss: 0.308761]\n",
      "epoch:3 step:3007 [D loss: 0.214854, acc.: 67.19%] [G loss: 0.313042]\n",
      "epoch:3 step:3008 [D loss: 0.237324, acc.: 58.59%] [G loss: 0.295965]\n",
      "epoch:3 step:3009 [D loss: 0.238130, acc.: 57.03%] [G loss: 0.315252]\n",
      "epoch:3 step:3010 [D loss: 0.232095, acc.: 60.94%] [G loss: 0.335618]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:3 step:3011 [D loss: 0.241255, acc.: 55.47%] [G loss: 0.352082]\n",
      "epoch:3 step:3012 [D loss: 0.242802, acc.: 60.94%] [G loss: 0.318257]\n",
      "epoch:3 step:3013 [D loss: 0.239401, acc.: 56.25%] [G loss: 0.323431]\n",
      "epoch:3 step:3014 [D loss: 0.250801, acc.: 58.59%] [G loss: 0.346805]\n",
      "epoch:3 step:3015 [D loss: 0.230953, acc.: 62.50%] [G loss: 0.295963]\n",
      "epoch:3 step:3016 [D loss: 0.218329, acc.: 66.41%] [G loss: 0.323356]\n",
      "epoch:3 step:3017 [D loss: 0.249189, acc.: 54.69%] [G loss: 0.286681]\n",
      "epoch:3 step:3018 [D loss: 0.234633, acc.: 54.69%] [G loss: 0.321394]\n",
      "epoch:3 step:3019 [D loss: 0.228083, acc.: 57.03%] [G loss: 0.299641]\n",
      "epoch:3 step:3020 [D loss: 0.269558, acc.: 44.53%] [G loss: 0.302879]\n",
      "epoch:3 step:3021 [D loss: 0.226685, acc.: 63.28%] [G loss: 0.324153]\n",
      "epoch:3 step:3022 [D loss: 0.253016, acc.: 52.34%] [G loss: 0.352578]\n",
      "epoch:3 step:3023 [D loss: 0.263967, acc.: 50.00%] [G loss: 0.303783]\n",
      "epoch:3 step:3024 [D loss: 0.269611, acc.: 52.34%] [G loss: 0.278731]\n",
      "epoch:3 step:3025 [D loss: 0.263734, acc.: 49.22%] [G loss: 0.343934]\n",
      "epoch:3 step:3026 [D loss: 0.235882, acc.: 53.12%] [G loss: 0.310623]\n",
      "epoch:3 step:3027 [D loss: 0.236567, acc.: 60.16%] [G loss: 0.330757]\n",
      "epoch:3 step:3028 [D loss: 0.225576, acc.: 64.06%] [G loss: 0.317339]\n",
      "epoch:3 step:3029 [D loss: 0.245723, acc.: 57.81%] [G loss: 0.314104]\n",
      "epoch:3 step:3030 [D loss: 0.245342, acc.: 57.81%] [G loss: 0.313885]\n",
      "epoch:3 step:3031 [D loss: 0.222493, acc.: 61.72%] [G loss: 0.330122]\n",
      "epoch:3 step:3032 [D loss: 0.238333, acc.: 60.94%] [G loss: 0.321441]\n",
      "epoch:3 step:3033 [D loss: 0.243577, acc.: 53.91%] [G loss: 0.310584]\n",
      "epoch:3 step:3034 [D loss: 0.245870, acc.: 60.94%] [G loss: 0.339104]\n",
      "epoch:3 step:3035 [D loss: 0.232520, acc.: 59.38%] [G loss: 0.303406]\n",
      "epoch:3 step:3036 [D loss: 0.240692, acc.: 57.03%] [G loss: 0.314930]\n",
      "epoch:3 step:3037 [D loss: 0.243006, acc.: 57.81%] [G loss: 0.316059]\n",
      "epoch:3 step:3038 [D loss: 0.241532, acc.: 59.38%] [G loss: 0.303112]\n",
      "epoch:3 step:3039 [D loss: 0.236386, acc.: 64.06%] [G loss: 0.279303]\n",
      "epoch:3 step:3040 [D loss: 0.229296, acc.: 63.28%] [G loss: 0.316759]\n",
      "epoch:3 step:3041 [D loss: 0.244039, acc.: 57.03%] [G loss: 0.339753]\n",
      "epoch:3 step:3042 [D loss: 0.218322, acc.: 65.62%] [G loss: 0.347449]\n",
      "epoch:3 step:3043 [D loss: 0.253527, acc.: 54.69%] [G loss: 0.318636]\n",
      "epoch:3 step:3044 [D loss: 0.243590, acc.: 55.47%] [G loss: 0.348889]\n",
      "epoch:3 step:3045 [D loss: 0.214069, acc.: 67.19%] [G loss: 0.378977]\n",
      "epoch:3 step:3046 [D loss: 0.249460, acc.: 55.47%] [G loss: 0.298493]\n",
      "epoch:3 step:3047 [D loss: 0.245021, acc.: 57.81%] [G loss: 0.323848]\n",
      "epoch:3 step:3048 [D loss: 0.261586, acc.: 53.12%] [G loss: 0.317371]\n",
      "epoch:3 step:3049 [D loss: 0.223277, acc.: 65.62%] [G loss: 0.298088]\n",
      "epoch:3 step:3050 [D loss: 0.247724, acc.: 53.91%] [G loss: 0.304889]\n",
      "epoch:3 step:3051 [D loss: 0.254053, acc.: 53.12%] [G loss: 0.305472]\n",
      "epoch:3 step:3052 [D loss: 0.247412, acc.: 57.81%] [G loss: 0.330503]\n",
      "epoch:3 step:3053 [D loss: 0.265664, acc.: 53.91%] [G loss: 0.303103]\n",
      "epoch:3 step:3054 [D loss: 0.233878, acc.: 60.94%] [G loss: 0.358010]\n",
      "epoch:3 step:3055 [D loss: 0.242324, acc.: 54.69%] [G loss: 0.289162]\n",
      "epoch:3 step:3056 [D loss: 0.247883, acc.: 53.12%] [G loss: 0.333597]\n",
      "epoch:3 step:3057 [D loss: 0.239798, acc.: 60.94%] [G loss: 0.312691]\n",
      "epoch:3 step:3058 [D loss: 0.221925, acc.: 62.50%] [G loss: 0.323731]\n",
      "epoch:3 step:3059 [D loss: 0.224878, acc.: 61.72%] [G loss: 0.324106]\n",
      "epoch:3 step:3060 [D loss: 0.261753, acc.: 51.56%] [G loss: 0.329201]\n",
      "epoch:3 step:3061 [D loss: 0.252357, acc.: 51.56%] [G loss: 0.325333]\n",
      "epoch:3 step:3062 [D loss: 0.253536, acc.: 48.44%] [G loss: 0.336059]\n",
      "epoch:3 step:3063 [D loss: 0.248796, acc.: 56.25%] [G loss: 0.292375]\n",
      "epoch:3 step:3064 [D loss: 0.235035, acc.: 63.28%] [G loss: 0.310422]\n",
      "epoch:3 step:3065 [D loss: 0.241898, acc.: 56.25%] [G loss: 0.300412]\n",
      "epoch:3 step:3066 [D loss: 0.226641, acc.: 64.84%] [G loss: 0.327337]\n",
      "epoch:3 step:3067 [D loss: 0.228251, acc.: 58.59%] [G loss: 0.330987]\n",
      "epoch:3 step:3068 [D loss: 0.251636, acc.: 55.47%] [G loss: 0.266729]\n",
      "epoch:3 step:3069 [D loss: 0.218725, acc.: 64.06%] [G loss: 0.320213]\n",
      "epoch:3 step:3070 [D loss: 0.232437, acc.: 60.16%] [G loss: 0.302926]\n",
      "epoch:3 step:3071 [D loss: 0.240353, acc.: 55.47%] [G loss: 0.334468]\n",
      "epoch:3 step:3072 [D loss: 0.203259, acc.: 73.44%] [G loss: 0.307944]\n",
      "epoch:3 step:3073 [D loss: 0.256360, acc.: 50.00%] [G loss: 0.296979]\n",
      "epoch:3 step:3074 [D loss: 0.241589, acc.: 55.47%] [G loss: 0.324814]\n",
      "epoch:3 step:3075 [D loss: 0.235853, acc.: 57.81%] [G loss: 0.308327]\n",
      "epoch:3 step:3076 [D loss: 0.267234, acc.: 51.56%] [G loss: 0.268509]\n",
      "epoch:3 step:3077 [D loss: 0.265068, acc.: 53.12%] [G loss: 0.307954]\n",
      "epoch:3 step:3078 [D loss: 0.264590, acc.: 53.12%] [G loss: 0.283996]\n",
      "epoch:3 step:3079 [D loss: 0.249792, acc.: 52.34%] [G loss: 0.308842]\n",
      "epoch:3 step:3080 [D loss: 0.253072, acc.: 50.78%] [G loss: 0.320034]\n",
      "epoch:3 step:3081 [D loss: 0.242208, acc.: 57.03%] [G loss: 0.310523]\n",
      "epoch:3 step:3082 [D loss: 0.241621, acc.: 57.81%] [G loss: 0.322855]\n",
      "epoch:3 step:3083 [D loss: 0.239546, acc.: 58.59%] [G loss: 0.327145]\n",
      "epoch:3 step:3084 [D loss: 0.242571, acc.: 59.38%] [G loss: 0.257550]\n",
      "epoch:3 step:3085 [D loss: 0.241596, acc.: 60.16%] [G loss: 0.325512]\n",
      "epoch:3 step:3086 [D loss: 0.269693, acc.: 46.88%] [G loss: 0.291600]\n",
      "epoch:3 step:3087 [D loss: 0.255300, acc.: 53.91%] [G loss: 0.322770]\n",
      "epoch:3 step:3088 [D loss: 0.245915, acc.: 57.03%] [G loss: 0.284022]\n",
      "epoch:3 step:3089 [D loss: 0.254134, acc.: 55.47%] [G loss: 0.302812]\n",
      "epoch:3 step:3090 [D loss: 0.245481, acc.: 56.25%] [G loss: 0.280144]\n",
      "epoch:3 step:3091 [D loss: 0.246553, acc.: 55.47%] [G loss: 0.297966]\n",
      "epoch:3 step:3092 [D loss: 0.249156, acc.: 55.47%] [G loss: 0.305937]\n",
      "epoch:3 step:3093 [D loss: 0.244040, acc.: 61.72%] [G loss: 0.274484]\n",
      "epoch:3 step:3094 [D loss: 0.244557, acc.: 56.25%] [G loss: 0.292695]\n",
      "epoch:3 step:3095 [D loss: 0.252290, acc.: 53.91%] [G loss: 0.305725]\n",
      "epoch:3 step:3096 [D loss: 0.254529, acc.: 54.69%] [G loss: 0.319285]\n",
      "epoch:3 step:3097 [D loss: 0.238173, acc.: 57.03%] [G loss: 0.309659]\n",
      "epoch:3 step:3098 [D loss: 0.230905, acc.: 63.28%] [G loss: 0.315041]\n",
      "epoch:3 step:3099 [D loss: 0.248497, acc.: 54.69%] [G loss: 0.309563]\n",
      "epoch:3 step:3100 [D loss: 0.248219, acc.: 54.69%] [G loss: 0.360858]\n",
      "epoch:3 step:3101 [D loss: 0.251949, acc.: 54.69%] [G loss: 0.302960]\n",
      "epoch:3 step:3102 [D loss: 0.262853, acc.: 53.91%] [G loss: 0.282283]\n",
      "epoch:3 step:3103 [D loss: 0.227872, acc.: 64.06%] [G loss: 0.323636]\n",
      "epoch:3 step:3104 [D loss: 0.227223, acc.: 60.16%] [G loss: 0.321010]\n",
      "epoch:3 step:3105 [D loss: 0.234374, acc.: 59.38%] [G loss: 0.331229]\n",
      "epoch:3 step:3106 [D loss: 0.251834, acc.: 55.47%] [G loss: 0.300766]\n",
      "epoch:3 step:3107 [D loss: 0.251699, acc.: 53.12%] [G loss: 0.317196]\n",
      "epoch:3 step:3108 [D loss: 0.239308, acc.: 56.25%] [G loss: 0.317985]\n",
      "epoch:3 step:3109 [D loss: 0.251769, acc.: 50.00%] [G loss: 0.339137]\n",
      "epoch:3 step:3110 [D loss: 0.260334, acc.: 50.00%] [G loss: 0.284305]\n",
      "epoch:3 step:3111 [D loss: 0.248905, acc.: 56.25%] [G loss: 0.346231]\n",
      "epoch:3 step:3112 [D loss: 0.242604, acc.: 55.47%] [G loss: 0.318496]\n",
      "epoch:3 step:3113 [D loss: 0.238024, acc.: 62.50%] [G loss: 0.360322]\n",
      "epoch:3 step:3114 [D loss: 0.224236, acc.: 60.16%] [G loss: 0.332418]\n",
      "epoch:3 step:3115 [D loss: 0.218712, acc.: 67.19%] [G loss: 0.329846]\n",
      "epoch:3 step:3116 [D loss: 0.238992, acc.: 59.38%] [G loss: 0.303463]\n",
      "epoch:3 step:3117 [D loss: 0.232309, acc.: 59.38%] [G loss: 0.307993]\n",
      "epoch:3 step:3118 [D loss: 0.248557, acc.: 55.47%] [G loss: 0.323096]\n",
      "epoch:3 step:3119 [D loss: 0.247084, acc.: 55.47%] [G loss: 0.312046]\n",
      "epoch:3 step:3120 [D loss: 0.244224, acc.: 58.59%] [G loss: 0.344041]\n",
      "epoch:3 step:3121 [D loss: 0.258221, acc.: 57.03%] [G loss: 0.295553]\n",
      "epoch:3 step:3122 [D loss: 0.250043, acc.: 54.69%] [G loss: 0.275912]\n",
      "epoch:3 step:3123 [D loss: 0.254301, acc.: 53.12%] [G loss: 0.307581]\n",
      "epoch:3 step:3124 [D loss: 0.258343, acc.: 50.00%] [G loss: 0.314606]\n",
      "epoch:3 step:3125 [D loss: 0.244500, acc.: 54.69%] [G loss: 0.316352]\n",
      "epoch:3 step:3126 [D loss: 0.226934, acc.: 61.72%] [G loss: 0.320403]\n",
      "epoch:3 step:3127 [D loss: 0.253507, acc.: 54.69%] [G loss: 0.303978]\n",
      "epoch:3 step:3128 [D loss: 0.252514, acc.: 53.91%] [G loss: 0.284104]\n",
      "epoch:3 step:3129 [D loss: 0.276377, acc.: 49.22%] [G loss: 0.281309]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:3 step:3130 [D loss: 0.254977, acc.: 54.69%] [G loss: 0.303794]\n",
      "epoch:3 step:3131 [D loss: 0.233605, acc.: 66.41%] [G loss: 0.323274]\n",
      "epoch:3 step:3132 [D loss: 0.227701, acc.: 61.72%] [G loss: 0.325825]\n",
      "epoch:3 step:3133 [D loss: 0.247175, acc.: 55.47%] [G loss: 0.292408]\n",
      "epoch:3 step:3134 [D loss: 0.240646, acc.: 59.38%] [G loss: 0.328075]\n",
      "epoch:3 step:3135 [D loss: 0.258286, acc.: 52.34%] [G loss: 0.303860]\n",
      "epoch:3 step:3136 [D loss: 0.222928, acc.: 64.84%] [G loss: 0.320746]\n",
      "epoch:3 step:3137 [D loss: 0.264422, acc.: 49.22%] [G loss: 0.313018]\n",
      "epoch:3 step:3138 [D loss: 0.249020, acc.: 53.91%] [G loss: 0.305927]\n",
      "epoch:3 step:3139 [D loss: 0.246599, acc.: 57.81%] [G loss: 0.308228]\n",
      "epoch:3 step:3140 [D loss: 0.252601, acc.: 53.12%] [G loss: 0.321937]\n",
      "epoch:3 step:3141 [D loss: 0.232525, acc.: 60.16%] [G loss: 0.331540]\n",
      "epoch:3 step:3142 [D loss: 0.237383, acc.: 60.94%] [G loss: 0.377665]\n",
      "epoch:3 step:3143 [D loss: 0.239986, acc.: 57.03%] [G loss: 0.311934]\n",
      "epoch:3 step:3144 [D loss: 0.239766, acc.: 57.03%] [G loss: 0.340481]\n",
      "epoch:3 step:3145 [D loss: 0.254332, acc.: 52.34%] [G loss: 0.323127]\n",
      "epoch:3 step:3146 [D loss: 0.259074, acc.: 46.09%] [G loss: 0.333057]\n",
      "epoch:3 step:3147 [D loss: 0.220885, acc.: 57.81%] [G loss: 0.354792]\n",
      "epoch:3 step:3148 [D loss: 0.245451, acc.: 57.81%] [G loss: 0.314800]\n",
      "epoch:3 step:3149 [D loss: 0.250503, acc.: 52.34%] [G loss: 0.299051]\n",
      "epoch:3 step:3150 [D loss: 0.229495, acc.: 62.50%] [G loss: 0.316050]\n",
      "epoch:3 step:3151 [D loss: 0.226068, acc.: 63.28%] [G loss: 0.345125]\n",
      "epoch:3 step:3152 [D loss: 0.248615, acc.: 54.69%] [G loss: 0.302464]\n",
      "epoch:3 step:3153 [D loss: 0.236882, acc.: 59.38%] [G loss: 0.311023]\n",
      "epoch:3 step:3154 [D loss: 0.244841, acc.: 61.72%] [G loss: 0.331599]\n",
      "epoch:3 step:3155 [D loss: 0.226092, acc.: 61.72%] [G loss: 0.318698]\n",
      "epoch:3 step:3156 [D loss: 0.253160, acc.: 53.12%] [G loss: 0.327081]\n",
      "epoch:3 step:3157 [D loss: 0.260897, acc.: 48.44%] [G loss: 0.302257]\n",
      "epoch:3 step:3158 [D loss: 0.216984, acc.: 67.97%] [G loss: 0.333076]\n",
      "epoch:3 step:3159 [D loss: 0.224094, acc.: 63.28%] [G loss: 0.314061]\n",
      "epoch:3 step:3160 [D loss: 0.251465, acc.: 53.12%] [G loss: 0.313383]\n",
      "epoch:3 step:3161 [D loss: 0.249722, acc.: 57.03%] [G loss: 0.308044]\n",
      "epoch:3 step:3162 [D loss: 0.252326, acc.: 55.47%] [G loss: 0.303778]\n",
      "epoch:3 step:3163 [D loss: 0.249329, acc.: 56.25%] [G loss: 0.299303]\n",
      "epoch:3 step:3164 [D loss: 0.240990, acc.: 61.72%] [G loss: 0.316098]\n",
      "epoch:3 step:3165 [D loss: 0.245795, acc.: 59.38%] [G loss: 0.305840]\n",
      "epoch:3 step:3166 [D loss: 0.245646, acc.: 57.03%] [G loss: 0.307128]\n",
      "epoch:3 step:3167 [D loss: 0.232754, acc.: 61.72%] [G loss: 0.339966]\n",
      "epoch:3 step:3168 [D loss: 0.252157, acc.: 54.69%] [G loss: 0.297014]\n",
      "epoch:3 step:3169 [D loss: 0.230702, acc.: 60.94%] [G loss: 0.299849]\n",
      "epoch:3 step:3170 [D loss: 0.249435, acc.: 53.91%] [G loss: 0.307335]\n",
      "epoch:3 step:3171 [D loss: 0.233840, acc.: 58.59%] [G loss: 0.296375]\n",
      "epoch:3 step:3172 [D loss: 0.255691, acc.: 55.47%] [G loss: 0.308583]\n",
      "epoch:3 step:3173 [D loss: 0.226864, acc.: 64.06%] [G loss: 0.307679]\n",
      "epoch:3 step:3174 [D loss: 0.241803, acc.: 59.38%] [G loss: 0.347013]\n",
      "epoch:3 step:3175 [D loss: 0.227396, acc.: 62.50%] [G loss: 0.325628]\n",
      "epoch:3 step:3176 [D loss: 0.242354, acc.: 59.38%] [G loss: 0.297767]\n",
      "epoch:3 step:3177 [D loss: 0.225333, acc.: 64.06%] [G loss: 0.321741]\n",
      "epoch:3 step:3178 [D loss: 0.255400, acc.: 56.25%] [G loss: 0.314327]\n",
      "epoch:3 step:3179 [D loss: 0.265708, acc.: 48.44%] [G loss: 0.301701]\n",
      "epoch:3 step:3180 [D loss: 0.241195, acc.: 57.03%] [G loss: 0.304090]\n",
      "epoch:3 step:3181 [D loss: 0.227511, acc.: 60.94%] [G loss: 0.352542]\n",
      "epoch:3 step:3182 [D loss: 0.253498, acc.: 55.47%] [G loss: 0.311846]\n",
      "epoch:3 step:3183 [D loss: 0.263521, acc.: 53.91%] [G loss: 0.298644]\n",
      "epoch:3 step:3184 [D loss: 0.232305, acc.: 64.84%] [G loss: 0.339483]\n",
      "epoch:3 step:3185 [D loss: 0.246410, acc.: 60.16%] [G loss: 0.328520]\n",
      "epoch:3 step:3186 [D loss: 0.253319, acc.: 59.38%] [G loss: 0.304466]\n",
      "epoch:3 step:3187 [D loss: 0.253959, acc.: 53.91%] [G loss: 0.306833]\n",
      "epoch:3 step:3188 [D loss: 0.253993, acc.: 53.12%] [G loss: 0.295541]\n",
      "epoch:3 step:3189 [D loss: 0.249559, acc.: 54.69%] [G loss: 0.342730]\n",
      "epoch:3 step:3190 [D loss: 0.261181, acc.: 50.00%] [G loss: 0.285402]\n",
      "epoch:3 step:3191 [D loss: 0.238809, acc.: 57.03%] [G loss: 0.312792]\n",
      "epoch:3 step:3192 [D loss: 0.229111, acc.: 61.72%] [G loss: 0.322259]\n",
      "epoch:3 step:3193 [D loss: 0.255579, acc.: 50.78%] [G loss: 0.297842]\n",
      "epoch:3 step:3194 [D loss: 0.245746, acc.: 53.12%] [G loss: 0.322373]\n",
      "epoch:3 step:3195 [D loss: 0.233041, acc.: 57.81%] [G loss: 0.311986]\n",
      "epoch:3 step:3196 [D loss: 0.262304, acc.: 50.78%] [G loss: 0.312698]\n",
      "epoch:3 step:3197 [D loss: 0.240438, acc.: 64.06%] [G loss: 0.304305]\n",
      "epoch:3 step:3198 [D loss: 0.249419, acc.: 54.69%] [G loss: 0.318631]\n",
      "epoch:3 step:3199 [D loss: 0.259595, acc.: 53.12%] [G loss: 0.307101]\n",
      "epoch:3 step:3200 [D loss: 0.240088, acc.: 59.38%] [G loss: 0.295587]\n",
      "epoch:3 step:3201 [D loss: 0.231911, acc.: 60.16%] [G loss: 0.333744]\n",
      "epoch:3 step:3202 [D loss: 0.244978, acc.: 56.25%] [G loss: 0.300451]\n",
      "epoch:3 step:3203 [D loss: 0.238299, acc.: 60.16%] [G loss: 0.323450]\n",
      "epoch:3 step:3204 [D loss: 0.250336, acc.: 53.91%] [G loss: 0.323802]\n",
      "epoch:3 step:3205 [D loss: 0.237422, acc.: 56.25%] [G loss: 0.316300]\n",
      "epoch:3 step:3206 [D loss: 0.249451, acc.: 57.03%] [G loss: 0.316384]\n",
      "epoch:3 step:3207 [D loss: 0.239193, acc.: 57.81%] [G loss: 0.310879]\n",
      "epoch:3 step:3208 [D loss: 0.259752, acc.: 50.78%] [G loss: 0.339717]\n",
      "epoch:3 step:3209 [D loss: 0.237558, acc.: 60.94%] [G loss: 0.321309]\n",
      "epoch:3 step:3210 [D loss: 0.241119, acc.: 59.38%] [G loss: 0.294587]\n",
      "epoch:3 step:3211 [D loss: 0.229984, acc.: 59.38%] [G loss: 0.336420]\n",
      "epoch:3 step:3212 [D loss: 0.241271, acc.: 56.25%] [G loss: 0.309362]\n",
      "epoch:3 step:3213 [D loss: 0.230274, acc.: 62.50%] [G loss: 0.334926]\n",
      "epoch:3 step:3214 [D loss: 0.235520, acc.: 60.94%] [G loss: 0.287593]\n",
      "epoch:3 step:3215 [D loss: 0.244219, acc.: 55.47%] [G loss: 0.299321]\n",
      "epoch:3 step:3216 [D loss: 0.242371, acc.: 57.81%] [G loss: 0.321193]\n",
      "epoch:3 step:3217 [D loss: 0.224630, acc.: 63.28%] [G loss: 0.344731]\n",
      "epoch:3 step:3218 [D loss: 0.242655, acc.: 56.25%] [G loss: 0.325498]\n",
      "epoch:3 step:3219 [D loss: 0.241455, acc.: 59.38%] [G loss: 0.313176]\n",
      "epoch:3 step:3220 [D loss: 0.250625, acc.: 53.91%] [G loss: 0.317356]\n",
      "epoch:3 step:3221 [D loss: 0.276911, acc.: 47.66%] [G loss: 0.303721]\n",
      "epoch:3 step:3222 [D loss: 0.240418, acc.: 53.12%] [G loss: 0.312875]\n",
      "epoch:3 step:3223 [D loss: 0.224492, acc.: 61.72%] [G loss: 0.310660]\n",
      "epoch:3 step:3224 [D loss: 0.236891, acc.: 60.16%] [G loss: 0.304188]\n",
      "epoch:3 step:3225 [D loss: 0.229621, acc.: 63.28%] [G loss: 0.348374]\n",
      "epoch:3 step:3226 [D loss: 0.249765, acc.: 53.12%] [G loss: 0.327964]\n",
      "epoch:3 step:3227 [D loss: 0.241168, acc.: 58.59%] [G loss: 0.320577]\n",
      "epoch:3 step:3228 [D loss: 0.230517, acc.: 64.06%] [G loss: 0.319638]\n",
      "epoch:3 step:3229 [D loss: 0.245343, acc.: 58.59%] [G loss: 0.321974]\n",
      "epoch:3 step:3230 [D loss: 0.251856, acc.: 57.03%] [G loss: 0.291466]\n",
      "epoch:3 step:3231 [D loss: 0.236405, acc.: 57.03%] [G loss: 0.313847]\n",
      "epoch:3 step:3232 [D loss: 0.254683, acc.: 53.12%] [G loss: 0.332612]\n",
      "epoch:3 step:3233 [D loss: 0.250523, acc.: 52.34%] [G loss: 0.317349]\n",
      "epoch:3 step:3234 [D loss: 0.257277, acc.: 50.00%] [G loss: 0.291423]\n",
      "epoch:3 step:3235 [D loss: 0.226375, acc.: 60.94%] [G loss: 0.327257]\n",
      "epoch:3 step:3236 [D loss: 0.260103, acc.: 51.56%] [G loss: 0.317653]\n",
      "epoch:3 step:3237 [D loss: 0.252681, acc.: 55.47%] [G loss: 0.314323]\n",
      "epoch:3 step:3238 [D loss: 0.259488, acc.: 51.56%] [G loss: 0.293849]\n",
      "epoch:3 step:3239 [D loss: 0.239267, acc.: 61.72%] [G loss: 0.335739]\n",
      "epoch:3 step:3240 [D loss: 0.260460, acc.: 55.47%] [G loss: 0.296271]\n",
      "epoch:3 step:3241 [D loss: 0.223696, acc.: 68.75%] [G loss: 0.329201]\n",
      "epoch:3 step:3242 [D loss: 0.233995, acc.: 60.16%] [G loss: 0.338469]\n",
      "epoch:3 step:3243 [D loss: 0.254729, acc.: 57.03%] [G loss: 0.292078]\n",
      "epoch:3 step:3244 [D loss: 0.233400, acc.: 58.59%] [G loss: 0.303741]\n",
      "epoch:3 step:3245 [D loss: 0.263909, acc.: 52.34%] [G loss: 0.329845]\n",
      "epoch:3 step:3246 [D loss: 0.237712, acc.: 58.59%] [G loss: 0.322366]\n",
      "epoch:3 step:3247 [D loss: 0.247702, acc.: 54.69%] [G loss: 0.330126]\n",
      "epoch:3 step:3248 [D loss: 0.249370, acc.: 59.38%] [G loss: 0.315798]\n",
      "epoch:3 step:3249 [D loss: 0.238955, acc.: 55.47%] [G loss: 0.289912]\n",
      "epoch:3 step:3250 [D loss: 0.269569, acc.: 51.56%] [G loss: 0.317664]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:3 step:3251 [D loss: 0.236834, acc.: 56.25%] [G loss: 0.296099]\n",
      "epoch:3 step:3252 [D loss: 0.216513, acc.: 64.06%] [G loss: 0.312729]\n",
      "epoch:3 step:3253 [D loss: 0.248990, acc.: 54.69%] [G loss: 0.297951]\n",
      "epoch:3 step:3254 [D loss: 0.233817, acc.: 57.81%] [G loss: 0.310074]\n",
      "epoch:3 step:3255 [D loss: 0.236694, acc.: 56.25%] [G loss: 0.304849]\n",
      "epoch:3 step:3256 [D loss: 0.237935, acc.: 57.03%] [G loss: 0.283782]\n",
      "epoch:3 step:3257 [D loss: 0.254562, acc.: 53.12%] [G loss: 0.311727]\n",
      "epoch:3 step:3258 [D loss: 0.260077, acc.: 53.12%] [G loss: 0.260170]\n",
      "epoch:3 step:3259 [D loss: 0.234791, acc.: 52.34%] [G loss: 0.317554]\n",
      "epoch:3 step:3260 [D loss: 0.241603, acc.: 57.81%] [G loss: 0.300340]\n",
      "epoch:3 step:3261 [D loss: 0.248062, acc.: 54.69%] [G loss: 0.301303]\n",
      "epoch:3 step:3262 [D loss: 0.242507, acc.: 57.81%] [G loss: 0.318426]\n",
      "epoch:3 step:3263 [D loss: 0.255297, acc.: 52.34%] [G loss: 0.296946]\n",
      "epoch:3 step:3264 [D loss: 0.245595, acc.: 56.25%] [G loss: 0.284844]\n",
      "epoch:3 step:3265 [D loss: 0.241552, acc.: 56.25%] [G loss: 0.277391]\n",
      "epoch:3 step:3266 [D loss: 0.232852, acc.: 67.19%] [G loss: 0.310168]\n",
      "epoch:3 step:3267 [D loss: 0.231521, acc.: 55.47%] [G loss: 0.326016]\n",
      "epoch:3 step:3268 [D loss: 0.237750, acc.: 60.16%] [G loss: 0.283531]\n",
      "epoch:3 step:3269 [D loss: 0.255020, acc.: 54.69%] [G loss: 0.327773]\n",
      "epoch:3 step:3270 [D loss: 0.247356, acc.: 56.25%] [G loss: 0.338386]\n",
      "epoch:3 step:3271 [D loss: 0.226647, acc.: 64.84%] [G loss: 0.308482]\n",
      "epoch:3 step:3272 [D loss: 0.261740, acc.: 49.22%] [G loss: 0.309894]\n",
      "epoch:3 step:3273 [D loss: 0.249668, acc.: 52.34%] [G loss: 0.313451]\n",
      "epoch:3 step:3274 [D loss: 0.248880, acc.: 53.91%] [G loss: 0.292002]\n",
      "epoch:3 step:3275 [D loss: 0.248512, acc.: 50.78%] [G loss: 0.300558]\n",
      "epoch:3 step:3276 [D loss: 0.236497, acc.: 60.94%] [G loss: 0.318847]\n",
      "epoch:3 step:3277 [D loss: 0.257014, acc.: 51.56%] [G loss: 0.285773]\n",
      "epoch:3 step:3278 [D loss: 0.235552, acc.: 57.81%] [G loss: 0.317883]\n",
      "epoch:3 step:3279 [D loss: 0.252758, acc.: 51.56%] [G loss: 0.290298]\n",
      "epoch:3 step:3280 [D loss: 0.250078, acc.: 57.03%] [G loss: 0.301515]\n",
      "epoch:3 step:3281 [D loss: 0.246357, acc.: 57.03%] [G loss: 0.275605]\n",
      "epoch:3 step:3282 [D loss: 0.246416, acc.: 57.81%] [G loss: 0.285122]\n",
      "epoch:3 step:3283 [D loss: 0.237864, acc.: 57.81%] [G loss: 0.308196]\n",
      "epoch:3 step:3284 [D loss: 0.255687, acc.: 53.91%] [G loss: 0.284141]\n",
      "epoch:3 step:3285 [D loss: 0.249631, acc.: 58.59%] [G loss: 0.314725]\n",
      "epoch:3 step:3286 [D loss: 0.222731, acc.: 64.06%] [G loss: 0.293184]\n",
      "epoch:3 step:3287 [D loss: 0.256804, acc.: 55.47%] [G loss: 0.311752]\n",
      "epoch:3 step:3288 [D loss: 0.251148, acc.: 51.56%] [G loss: 0.342207]\n",
      "epoch:3 step:3289 [D loss: 0.217602, acc.: 63.28%] [G loss: 0.329237]\n",
      "epoch:3 step:3290 [D loss: 0.246371, acc.: 51.56%] [G loss: 0.318932]\n",
      "epoch:3 step:3291 [D loss: 0.256465, acc.: 49.22%] [G loss: 0.275493]\n",
      "epoch:3 step:3292 [D loss: 0.248684, acc.: 52.34%] [G loss: 0.325354]\n",
      "epoch:3 step:3293 [D loss: 0.242149, acc.: 56.25%] [G loss: 0.297015]\n",
      "epoch:3 step:3294 [D loss: 0.237645, acc.: 61.72%] [G loss: 0.311544]\n",
      "epoch:3 step:3295 [D loss: 0.219904, acc.: 64.06%] [G loss: 0.306164]\n",
      "epoch:3 step:3296 [D loss: 0.246917, acc.: 53.12%] [G loss: 0.325206]\n",
      "epoch:3 step:3297 [D loss: 0.227802, acc.: 60.16%] [G loss: 0.337594]\n",
      "epoch:3 step:3298 [D loss: 0.232492, acc.: 64.84%] [G loss: 0.287342]\n",
      "epoch:3 step:3299 [D loss: 0.243726, acc.: 55.47%] [G loss: 0.315277]\n",
      "epoch:3 step:3300 [D loss: 0.271755, acc.: 50.78%] [G loss: 0.281274]\n",
      "epoch:3 step:3301 [D loss: 0.238045, acc.: 58.59%] [G loss: 0.321310]\n",
      "epoch:3 step:3302 [D loss: 0.257255, acc.: 45.31%] [G loss: 0.338479]\n",
      "epoch:3 step:3303 [D loss: 0.240425, acc.: 60.16%] [G loss: 0.332675]\n",
      "epoch:3 step:3304 [D loss: 0.263768, acc.: 49.22%] [G loss: 0.324280]\n",
      "epoch:3 step:3305 [D loss: 0.234853, acc.: 57.03%] [G loss: 0.327946]\n",
      "epoch:3 step:3306 [D loss: 0.241845, acc.: 59.38%] [G loss: 0.307947]\n",
      "epoch:3 step:3307 [D loss: 0.247016, acc.: 53.91%] [G loss: 0.327483]\n",
      "epoch:3 step:3308 [D loss: 0.255209, acc.: 56.25%] [G loss: 0.352875]\n",
      "epoch:3 step:3309 [D loss: 0.247300, acc.: 57.03%] [G loss: 0.317169]\n",
      "epoch:3 step:3310 [D loss: 0.220568, acc.: 64.84%] [G loss: 0.310050]\n",
      "epoch:3 step:3311 [D loss: 0.248245, acc.: 49.22%] [G loss: 0.301804]\n",
      "epoch:3 step:3312 [D loss: 0.240236, acc.: 58.59%] [G loss: 0.311266]\n",
      "epoch:3 step:3313 [D loss: 0.236076, acc.: 62.50%] [G loss: 0.349234]\n",
      "epoch:3 step:3314 [D loss: 0.247266, acc.: 62.50%] [G loss: 0.311176]\n",
      "epoch:3 step:3315 [D loss: 0.274788, acc.: 50.00%] [G loss: 0.291049]\n",
      "epoch:3 step:3316 [D loss: 0.267174, acc.: 53.91%] [G loss: 0.307221]\n",
      "epoch:3 step:3317 [D loss: 0.250151, acc.: 53.91%] [G loss: 0.336194]\n",
      "epoch:3 step:3318 [D loss: 0.257153, acc.: 54.69%] [G loss: 0.304870]\n",
      "epoch:3 step:3319 [D loss: 0.244922, acc.: 58.59%] [G loss: 0.287239]\n",
      "epoch:3 step:3320 [D loss: 0.239824, acc.: 59.38%] [G loss: 0.323837]\n",
      "epoch:3 step:3321 [D loss: 0.231227, acc.: 65.62%] [G loss: 0.288994]\n",
      "epoch:3 step:3322 [D loss: 0.261236, acc.: 54.69%] [G loss: 0.304357]\n",
      "epoch:3 step:3323 [D loss: 0.242800, acc.: 57.03%] [G loss: 0.288156]\n",
      "epoch:3 step:3324 [D loss: 0.232661, acc.: 57.81%] [G loss: 0.317798]\n",
      "epoch:3 step:3325 [D loss: 0.264623, acc.: 50.78%] [G loss: 0.285645]\n",
      "epoch:3 step:3326 [D loss: 0.241011, acc.: 60.16%] [G loss: 0.323995]\n",
      "epoch:3 step:3327 [D loss: 0.256090, acc.: 45.31%] [G loss: 0.292640]\n",
      "epoch:3 step:3328 [D loss: 0.257187, acc.: 54.69%] [G loss: 0.289961]\n",
      "epoch:3 step:3329 [D loss: 0.251848, acc.: 58.59%] [G loss: 0.315753]\n",
      "epoch:3 step:3330 [D loss: 0.232266, acc.: 58.59%] [G loss: 0.312263]\n",
      "epoch:3 step:3331 [D loss: 0.234682, acc.: 60.16%] [G loss: 0.305757]\n",
      "epoch:3 step:3332 [D loss: 0.249656, acc.: 57.03%] [G loss: 0.306896]\n",
      "epoch:3 step:3333 [D loss: 0.233364, acc.: 57.03%] [G loss: 0.302111]\n",
      "epoch:3 step:3334 [D loss: 0.236721, acc.: 55.47%] [G loss: 0.303039]\n",
      "epoch:3 step:3335 [D loss: 0.250423, acc.: 57.03%] [G loss: 0.280488]\n",
      "epoch:3 step:3336 [D loss: 0.265028, acc.: 52.34%] [G loss: 0.307939]\n",
      "epoch:3 step:3337 [D loss: 0.241904, acc.: 59.38%] [G loss: 0.321965]\n",
      "epoch:3 step:3338 [D loss: 0.233982, acc.: 58.59%] [G loss: 0.318842]\n",
      "epoch:3 step:3339 [D loss: 0.264527, acc.: 49.22%] [G loss: 0.306906]\n",
      "epoch:3 step:3340 [D loss: 0.249743, acc.: 53.91%] [G loss: 0.317083]\n",
      "epoch:3 step:3341 [D loss: 0.219384, acc.: 67.97%] [G loss: 0.318620]\n",
      "epoch:3 step:3342 [D loss: 0.242465, acc.: 57.03%] [G loss: 0.320484]\n",
      "epoch:3 step:3343 [D loss: 0.239134, acc.: 60.94%] [G loss: 0.352930]\n",
      "epoch:3 step:3344 [D loss: 0.231453, acc.: 60.16%] [G loss: 0.317865]\n",
      "epoch:3 step:3345 [D loss: 0.237336, acc.: 53.91%] [G loss: 0.314192]\n",
      "epoch:3 step:3346 [D loss: 0.252798, acc.: 58.59%] [G loss: 0.331643]\n",
      "epoch:3 step:3347 [D loss: 0.265032, acc.: 50.00%] [G loss: 0.306610]\n",
      "epoch:3 step:3348 [D loss: 0.244808, acc.: 56.25%] [G loss: 0.311096]\n",
      "epoch:3 step:3349 [D loss: 0.261435, acc.: 50.00%] [G loss: 0.287439]\n",
      "epoch:3 step:3350 [D loss: 0.233882, acc.: 64.06%] [G loss: 0.303449]\n",
      "epoch:3 step:3351 [D loss: 0.249453, acc.: 55.47%] [G loss: 0.310672]\n",
      "epoch:3 step:3352 [D loss: 0.245077, acc.: 58.59%] [G loss: 0.297289]\n",
      "epoch:3 step:3353 [D loss: 0.251837, acc.: 52.34%] [G loss: 0.333730]\n",
      "epoch:3 step:3354 [D loss: 0.252623, acc.: 54.69%] [G loss: 0.325159]\n",
      "epoch:3 step:3355 [D loss: 0.226120, acc.: 65.62%] [G loss: 0.331101]\n",
      "epoch:3 step:3356 [D loss: 0.256789, acc.: 53.12%] [G loss: 0.285884]\n",
      "epoch:3 step:3357 [D loss: 0.246501, acc.: 54.69%] [G loss: 0.302268]\n",
      "epoch:3 step:3358 [D loss: 0.253177, acc.: 53.12%] [G loss: 0.301536]\n",
      "epoch:3 step:3359 [D loss: 0.246095, acc.: 53.12%] [G loss: 0.323941]\n",
      "epoch:3 step:3360 [D loss: 0.257518, acc.: 53.12%] [G loss: 0.323949]\n",
      "epoch:3 step:3361 [D loss: 0.229864, acc.: 62.50%] [G loss: 0.329095]\n",
      "epoch:3 step:3362 [D loss: 0.234934, acc.: 64.84%] [G loss: 0.328996]\n",
      "epoch:3 step:3363 [D loss: 0.236313, acc.: 56.25%] [G loss: 0.320933]\n",
      "epoch:3 step:3364 [D loss: 0.238479, acc.: 61.72%] [G loss: 0.341512]\n",
      "epoch:3 step:3365 [D loss: 0.258323, acc.: 53.12%] [G loss: 0.308591]\n",
      "epoch:3 step:3366 [D loss: 0.245720, acc.: 52.34%] [G loss: 0.275031]\n",
      "epoch:3 step:3367 [D loss: 0.241767, acc.: 55.47%] [G loss: 0.330927]\n",
      "epoch:3 step:3368 [D loss: 0.233050, acc.: 63.28%] [G loss: 0.298588]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:3 step:3369 [D loss: 0.228602, acc.: 62.50%] [G loss: 0.308249]\n",
      "epoch:3 step:3370 [D loss: 0.246786, acc.: 60.94%] [G loss: 0.282841]\n",
      "epoch:3 step:3371 [D loss: 0.231444, acc.: 57.81%] [G loss: 0.317959]\n",
      "epoch:3 step:3372 [D loss: 0.232160, acc.: 58.59%] [G loss: 0.323102]\n",
      "epoch:3 step:3373 [D loss: 0.239349, acc.: 60.16%] [G loss: 0.319630]\n",
      "epoch:3 step:3374 [D loss: 0.236867, acc.: 61.72%] [G loss: 0.306857]\n",
      "epoch:3 step:3375 [D loss: 0.206795, acc.: 71.88%] [G loss: 0.302639]\n",
      "epoch:3 step:3376 [D loss: 0.243591, acc.: 54.69%] [G loss: 0.297654]\n",
      "epoch:3 step:3377 [D loss: 0.260531, acc.: 53.91%] [G loss: 0.306768]\n",
      "epoch:3 step:3378 [D loss: 0.234090, acc.: 60.94%] [G loss: 0.306013]\n",
      "epoch:3 step:3379 [D loss: 0.243557, acc.: 59.38%] [G loss: 0.318781]\n",
      "epoch:3 step:3380 [D loss: 0.232352, acc.: 64.84%] [G loss: 0.297642]\n",
      "epoch:3 step:3381 [D loss: 0.240835, acc.: 62.50%] [G loss: 0.335591]\n",
      "epoch:3 step:3382 [D loss: 0.228214, acc.: 59.38%] [G loss: 0.301867]\n",
      "epoch:3 step:3383 [D loss: 0.218804, acc.: 65.62%] [G loss: 0.333525]\n",
      "epoch:3 step:3384 [D loss: 0.258317, acc.: 51.56%] [G loss: 0.316219]\n",
      "epoch:3 step:3385 [D loss: 0.234538, acc.: 62.50%] [G loss: 0.308737]\n",
      "epoch:3 step:3386 [D loss: 0.255608, acc.: 57.81%] [G loss: 0.324604]\n",
      "epoch:3 step:3387 [D loss: 0.251279, acc.: 55.47%] [G loss: 0.326061]\n",
      "epoch:3 step:3388 [D loss: 0.254020, acc.: 55.47%] [G loss: 0.333747]\n",
      "epoch:3 step:3389 [D loss: 0.238574, acc.: 57.81%] [G loss: 0.320580]\n",
      "epoch:3 step:3390 [D loss: 0.250321, acc.: 57.81%] [G loss: 0.319580]\n",
      "epoch:3 step:3391 [D loss: 0.229336, acc.: 58.59%] [G loss: 0.279666]\n",
      "epoch:3 step:3392 [D loss: 0.252658, acc.: 52.34%] [G loss: 0.280923]\n",
      "epoch:3 step:3393 [D loss: 0.241761, acc.: 58.59%] [G loss: 0.313010]\n",
      "epoch:3 step:3394 [D loss: 0.241265, acc.: 58.59%] [G loss: 0.296420]\n",
      "epoch:3 step:3395 [D loss: 0.234112, acc.: 63.28%] [G loss: 0.290109]\n",
      "epoch:3 step:3396 [D loss: 0.263402, acc.: 49.22%] [G loss: 0.308491]\n",
      "epoch:3 step:3397 [D loss: 0.249529, acc.: 52.34%] [G loss: 0.299382]\n",
      "epoch:3 step:3398 [D loss: 0.232509, acc.: 59.38%] [G loss: 0.320102]\n",
      "epoch:3 step:3399 [D loss: 0.265589, acc.: 50.78%] [G loss: 0.285330]\n",
      "epoch:3 step:3400 [D loss: 0.234873, acc.: 57.03%] [G loss: 0.285421]\n",
      "epoch:3 step:3401 [D loss: 0.254480, acc.: 53.91%] [G loss: 0.304072]\n",
      "epoch:3 step:3402 [D loss: 0.215830, acc.: 67.97%] [G loss: 0.306501]\n",
      "epoch:3 step:3403 [D loss: 0.235321, acc.: 57.03%] [G loss: 0.344045]\n",
      "epoch:3 step:3404 [D loss: 0.276667, acc.: 47.66%] [G loss: 0.258203]\n",
      "epoch:3 step:3405 [D loss: 0.241318, acc.: 58.59%] [G loss: 0.311596]\n",
      "epoch:3 step:3406 [D loss: 0.264164, acc.: 50.78%] [G loss: 0.309442]\n",
      "epoch:3 step:3407 [D loss: 0.252664, acc.: 53.91%] [G loss: 0.316294]\n",
      "epoch:3 step:3408 [D loss: 0.240186, acc.: 53.91%] [G loss: 0.315455]\n",
      "epoch:3 step:3409 [D loss: 0.247872, acc.: 56.25%] [G loss: 0.312914]\n",
      "epoch:3 step:3410 [D loss: 0.240549, acc.: 60.94%] [G loss: 0.321998]\n",
      "epoch:3 step:3411 [D loss: 0.235966, acc.: 59.38%] [G loss: 0.326857]\n",
      "epoch:3 step:3412 [D loss: 0.249702, acc.: 54.69%] [G loss: 0.288095]\n",
      "epoch:3 step:3413 [D loss: 0.225142, acc.: 62.50%] [G loss: 0.295022]\n",
      "epoch:3 step:3414 [D loss: 0.256774, acc.: 53.12%] [G loss: 0.295465]\n",
      "epoch:3 step:3415 [D loss: 0.244270, acc.: 49.22%] [G loss: 0.300159]\n",
      "epoch:3 step:3416 [D loss: 0.230732, acc.: 65.62%] [G loss: 0.326168]\n",
      "epoch:3 step:3417 [D loss: 0.242017, acc.: 54.69%] [G loss: 0.311546]\n",
      "epoch:3 step:3418 [D loss: 0.254834, acc.: 51.56%] [G loss: 0.283317]\n",
      "epoch:3 step:3419 [D loss: 0.243631, acc.: 58.59%] [G loss: 0.291761]\n",
      "epoch:3 step:3420 [D loss: 0.243108, acc.: 54.69%] [G loss: 0.312762]\n",
      "epoch:3 step:3421 [D loss: 0.237818, acc.: 60.16%] [G loss: 0.279401]\n",
      "epoch:3 step:3422 [D loss: 0.266744, acc.: 53.12%] [G loss: 0.317905]\n",
      "epoch:3 step:3423 [D loss: 0.247625, acc.: 54.69%] [G loss: 0.311758]\n",
      "epoch:3 step:3424 [D loss: 0.234862, acc.: 61.72%] [G loss: 0.314635]\n",
      "epoch:3 step:3425 [D loss: 0.237470, acc.: 54.69%] [G loss: 0.327936]\n",
      "epoch:3 step:3426 [D loss: 0.234714, acc.: 57.81%] [G loss: 0.331863]\n",
      "epoch:3 step:3427 [D loss: 0.256190, acc.: 55.47%] [G loss: 0.298291]\n",
      "epoch:3 step:3428 [D loss: 0.239449, acc.: 57.81%] [G loss: 0.309854]\n",
      "epoch:3 step:3429 [D loss: 0.253632, acc.: 54.69%] [G loss: 0.330187]\n",
      "epoch:3 step:3430 [D loss: 0.274992, acc.: 49.22%] [G loss: 0.317570]\n",
      "epoch:3 step:3431 [D loss: 0.249779, acc.: 54.69%] [G loss: 0.281389]\n",
      "epoch:3 step:3432 [D loss: 0.269544, acc.: 47.66%] [G loss: 0.318235]\n",
      "epoch:3 step:3433 [D loss: 0.241244, acc.: 62.50%] [G loss: 0.329604]\n",
      "epoch:3 step:3434 [D loss: 0.248284, acc.: 50.00%] [G loss: 0.278832]\n",
      "epoch:3 step:3435 [D loss: 0.232670, acc.: 61.72%] [G loss: 0.307179]\n",
      "epoch:3 step:3436 [D loss: 0.239608, acc.: 59.38%] [G loss: 0.295235]\n",
      "epoch:3 step:3437 [D loss: 0.254631, acc.: 50.78%] [G loss: 0.310735]\n",
      "epoch:3 step:3438 [D loss: 0.229394, acc.: 59.38%] [G loss: 0.314261]\n",
      "epoch:3 step:3439 [D loss: 0.248744, acc.: 56.25%] [G loss: 0.317282]\n",
      "epoch:3 step:3440 [D loss: 0.239372, acc.: 54.69%] [G loss: 0.305441]\n",
      "epoch:3 step:3441 [D loss: 0.239848, acc.: 58.59%] [G loss: 0.298082]\n",
      "epoch:3 step:3442 [D loss: 0.240641, acc.: 55.47%] [G loss: 0.335380]\n",
      "epoch:3 step:3443 [D loss: 0.233161, acc.: 59.38%] [G loss: 0.330169]\n",
      "epoch:3 step:3444 [D loss: 0.233792, acc.: 59.38%] [G loss: 0.317088]\n",
      "epoch:3 step:3445 [D loss: 0.246403, acc.: 53.12%] [G loss: 0.346119]\n",
      "epoch:3 step:3446 [D loss: 0.246355, acc.: 54.69%] [G loss: 0.313942]\n",
      "epoch:3 step:3447 [D loss: 0.237209, acc.: 62.50%] [G loss: 0.331544]\n",
      "epoch:3 step:3448 [D loss: 0.242543, acc.: 60.94%] [G loss: 0.332464]\n",
      "epoch:3 step:3449 [D loss: 0.246941, acc.: 54.69%] [G loss: 0.336660]\n",
      "epoch:3 step:3450 [D loss: 0.247967, acc.: 50.00%] [G loss: 0.316222]\n",
      "epoch:3 step:3451 [D loss: 0.257619, acc.: 50.00%] [G loss: 0.320392]\n",
      "epoch:3 step:3452 [D loss: 0.236755, acc.: 53.91%] [G loss: 0.310320]\n",
      "epoch:3 step:3453 [D loss: 0.237436, acc.: 53.12%] [G loss: 0.323031]\n",
      "epoch:3 step:3454 [D loss: 0.237228, acc.: 60.94%] [G loss: 0.331872]\n",
      "epoch:3 step:3455 [D loss: 0.246827, acc.: 56.25%] [G loss: 0.301041]\n",
      "epoch:3 step:3456 [D loss: 0.236388, acc.: 55.47%] [G loss: 0.321551]\n",
      "epoch:3 step:3457 [D loss: 0.275142, acc.: 48.44%] [G loss: 0.310200]\n",
      "epoch:3 step:3458 [D loss: 0.252134, acc.: 55.47%] [G loss: 0.318621]\n",
      "epoch:3 step:3459 [D loss: 0.269588, acc.: 48.44%] [G loss: 0.308736]\n",
      "epoch:3 step:3460 [D loss: 0.250013, acc.: 47.66%] [G loss: 0.300430]\n",
      "epoch:3 step:3461 [D loss: 0.259751, acc.: 55.47%] [G loss: 0.299491]\n",
      "epoch:3 step:3462 [D loss: 0.261128, acc.: 51.56%] [G loss: 0.288858]\n",
      "epoch:3 step:3463 [D loss: 0.238594, acc.: 59.38%] [G loss: 0.307928]\n",
      "epoch:3 step:3464 [D loss: 0.245116, acc.: 57.03%] [G loss: 0.304732]\n",
      "epoch:3 step:3465 [D loss: 0.244795, acc.: 54.69%] [G loss: 0.274791]\n",
      "epoch:3 step:3466 [D loss: 0.254766, acc.: 52.34%] [G loss: 0.324325]\n",
      "epoch:3 step:3467 [D loss: 0.249281, acc.: 54.69%] [G loss: 0.297813]\n",
      "epoch:3 step:3468 [D loss: 0.277057, acc.: 48.44%] [G loss: 0.296041]\n",
      "epoch:3 step:3469 [D loss: 0.246141, acc.: 55.47%] [G loss: 0.345728]\n",
      "epoch:3 step:3470 [D loss: 0.251004, acc.: 57.81%] [G loss: 0.283722]\n",
      "epoch:3 step:3471 [D loss: 0.254027, acc.: 53.12%] [G loss: 0.307783]\n",
      "epoch:3 step:3472 [D loss: 0.236165, acc.: 58.59%] [G loss: 0.356636]\n",
      "epoch:3 step:3473 [D loss: 0.264695, acc.: 46.09%] [G loss: 0.307006]\n",
      "epoch:3 step:3474 [D loss: 0.250712, acc.: 54.69%] [G loss: 0.306170]\n",
      "epoch:3 step:3475 [D loss: 0.220853, acc.: 64.06%] [G loss: 0.339260]\n",
      "epoch:3 step:3476 [D loss: 0.229054, acc.: 64.84%] [G loss: 0.308006]\n",
      "epoch:3 step:3477 [D loss: 0.237429, acc.: 57.81%] [G loss: 0.309118]\n",
      "epoch:3 step:3478 [D loss: 0.237032, acc.: 62.50%] [G loss: 0.312105]\n",
      "epoch:3 step:3479 [D loss: 0.264455, acc.: 44.53%] [G loss: 0.284599]\n",
      "epoch:3 step:3480 [D loss: 0.243418, acc.: 55.47%] [G loss: 0.356973]\n",
      "epoch:3 step:3481 [D loss: 0.221203, acc.: 61.72%] [G loss: 0.297168]\n",
      "epoch:3 step:3482 [D loss: 0.255173, acc.: 55.47%] [G loss: 0.275404]\n",
      "epoch:3 step:3483 [D loss: 0.235232, acc.: 57.81%] [G loss: 0.294065]\n",
      "epoch:3 step:3484 [D loss: 0.230464, acc.: 59.38%] [G loss: 0.316124]\n",
      "epoch:3 step:3485 [D loss: 0.245486, acc.: 56.25%] [G loss: 0.306874]\n",
      "epoch:3 step:3486 [D loss: 0.235595, acc.: 57.81%] [G loss: 0.334362]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:3 step:3487 [D loss: 0.251685, acc.: 53.91%] [G loss: 0.305615]\n",
      "epoch:3 step:3488 [D loss: 0.245683, acc.: 56.25%] [G loss: 0.330418]\n",
      "epoch:3 step:3489 [D loss: 0.247344, acc.: 52.34%] [G loss: 0.322826]\n",
      "epoch:3 step:3490 [D loss: 0.254788, acc.: 57.81%] [G loss: 0.299576]\n",
      "epoch:3 step:3491 [D loss: 0.256733, acc.: 52.34%] [G loss: 0.320701]\n",
      "epoch:3 step:3492 [D loss: 0.243336, acc.: 58.59%] [G loss: 0.317746]\n",
      "epoch:3 step:3493 [D loss: 0.234121, acc.: 57.03%] [G loss: 0.297944]\n",
      "epoch:3 step:3494 [D loss: 0.232666, acc.: 58.59%] [G loss: 0.306599]\n",
      "epoch:3 step:3495 [D loss: 0.234945, acc.: 59.38%] [G loss: 0.302313]\n",
      "epoch:3 step:3496 [D loss: 0.254381, acc.: 55.47%] [G loss: 0.347927]\n",
      "epoch:3 step:3497 [D loss: 0.239739, acc.: 59.38%] [G loss: 0.329812]\n",
      "epoch:3 step:3498 [D loss: 0.235662, acc.: 54.69%] [G loss: 0.304823]\n",
      "epoch:3 step:3499 [D loss: 0.236594, acc.: 60.94%] [G loss: 0.304849]\n",
      "epoch:3 step:3500 [D loss: 0.242320, acc.: 60.94%] [G loss: 0.308432]\n",
      "epoch:3 step:3501 [D loss: 0.247805, acc.: 53.91%] [G loss: 0.295871]\n",
      "epoch:3 step:3502 [D loss: 0.214919, acc.: 64.84%] [G loss: 0.306531]\n",
      "epoch:3 step:3503 [D loss: 0.240187, acc.: 55.47%] [G loss: 0.317091]\n",
      "epoch:3 step:3504 [D loss: 0.258169, acc.: 54.69%] [G loss: 0.264683]\n",
      "epoch:3 step:3505 [D loss: 0.231276, acc.: 60.94%] [G loss: 0.294776]\n",
      "epoch:3 step:3506 [D loss: 0.235942, acc.: 59.38%] [G loss: 0.319722]\n",
      "epoch:3 step:3507 [D loss: 0.246722, acc.: 51.56%] [G loss: 0.311303]\n",
      "epoch:3 step:3508 [D loss: 0.250204, acc.: 55.47%] [G loss: 0.262400]\n",
      "epoch:3 step:3509 [D loss: 0.233307, acc.: 58.59%] [G loss: 0.333502]\n",
      "epoch:3 step:3510 [D loss: 0.219844, acc.: 66.41%] [G loss: 0.342404]\n",
      "epoch:3 step:3511 [D loss: 0.224503, acc.: 58.59%] [G loss: 0.321470]\n",
      "epoch:3 step:3512 [D loss: 0.225880, acc.: 59.38%] [G loss: 0.299665]\n",
      "epoch:3 step:3513 [D loss: 0.235746, acc.: 56.25%] [G loss: 0.292847]\n",
      "epoch:3 step:3514 [D loss: 0.237437, acc.: 59.38%] [G loss: 0.292942]\n",
      "epoch:3 step:3515 [D loss: 0.255414, acc.: 51.56%] [G loss: 0.353147]\n",
      "epoch:3 step:3516 [D loss: 0.254523, acc.: 54.69%] [G loss: 0.298399]\n",
      "epoch:3 step:3517 [D loss: 0.262738, acc.: 52.34%] [G loss: 0.285858]\n",
      "epoch:3 step:3518 [D loss: 0.252124, acc.: 52.34%] [G loss: 0.331650]\n",
      "epoch:3 step:3519 [D loss: 0.227649, acc.: 60.94%] [G loss: 0.343527]\n",
      "epoch:3 step:3520 [D loss: 0.258716, acc.: 54.69%] [G loss: 0.307176]\n",
      "epoch:3 step:3521 [D loss: 0.247106, acc.: 56.25%] [G loss: 0.277367]\n",
      "epoch:3 step:3522 [D loss: 0.236315, acc.: 59.38%] [G loss: 0.306921]\n",
      "epoch:3 step:3523 [D loss: 0.255170, acc.: 53.91%] [G loss: 0.275319]\n",
      "epoch:3 step:3524 [D loss: 0.233500, acc.: 59.38%] [G loss: 0.294738]\n",
      "epoch:3 step:3525 [D loss: 0.234294, acc.: 60.94%] [G loss: 0.333245]\n",
      "epoch:3 step:3526 [D loss: 0.244434, acc.: 57.81%] [G loss: 0.305308]\n",
      "epoch:3 step:3527 [D loss: 0.228798, acc.: 61.72%] [G loss: 0.323242]\n",
      "epoch:3 step:3528 [D loss: 0.233546, acc.: 57.81%] [G loss: 0.329471]\n",
      "epoch:3 step:3529 [D loss: 0.227088, acc.: 64.84%] [G loss: 0.342462]\n",
      "epoch:3 step:3530 [D loss: 0.248951, acc.: 54.69%] [G loss: 0.295427]\n",
      "epoch:3 step:3531 [D loss: 0.244739, acc.: 55.47%] [G loss: 0.347083]\n",
      "epoch:3 step:3532 [D loss: 0.235858, acc.: 62.50%] [G loss: 0.367935]\n",
      "epoch:3 step:3533 [D loss: 0.210113, acc.: 67.19%] [G loss: 0.322764]\n",
      "epoch:3 step:3534 [D loss: 0.227218, acc.: 64.84%] [G loss: 0.346680]\n",
      "epoch:3 step:3535 [D loss: 0.235110, acc.: 60.94%] [G loss: 0.310165]\n",
      "epoch:3 step:3536 [D loss: 0.221862, acc.: 67.97%] [G loss: 0.354307]\n",
      "epoch:3 step:3537 [D loss: 0.242256, acc.: 54.69%] [G loss: 0.323186]\n",
      "epoch:3 step:3538 [D loss: 0.254088, acc.: 48.44%] [G loss: 0.329051]\n",
      "epoch:3 step:3539 [D loss: 0.254646, acc.: 53.12%] [G loss: 0.318702]\n",
      "epoch:3 step:3540 [D loss: 0.252715, acc.: 57.03%] [G loss: 0.295262]\n",
      "epoch:3 step:3541 [D loss: 0.246051, acc.: 56.25%] [G loss: 0.331296]\n",
      "epoch:3 step:3542 [D loss: 0.249675, acc.: 54.69%] [G loss: 0.275847]\n",
      "epoch:3 step:3543 [D loss: 0.265097, acc.: 50.78%] [G loss: 0.274860]\n",
      "epoch:3 step:3544 [D loss: 0.256055, acc.: 53.12%] [G loss: 0.283400]\n",
      "epoch:3 step:3545 [D loss: 0.242984, acc.: 58.59%] [G loss: 0.302925]\n",
      "epoch:3 step:3546 [D loss: 0.241294, acc.: 56.25%] [G loss: 0.305633]\n",
      "epoch:3 step:3547 [D loss: 0.242112, acc.: 60.94%] [G loss: 0.333278]\n",
      "epoch:3 step:3548 [D loss: 0.271465, acc.: 53.12%] [G loss: 0.302131]\n",
      "epoch:3 step:3549 [D loss: 0.227703, acc.: 64.06%] [G loss: 0.300821]\n",
      "epoch:3 step:3550 [D loss: 0.239074, acc.: 55.47%] [G loss: 0.323840]\n",
      "epoch:3 step:3551 [D loss: 0.234490, acc.: 60.16%] [G loss: 0.314051]\n",
      "epoch:3 step:3552 [D loss: 0.248181, acc.: 58.59%] [G loss: 0.327273]\n",
      "epoch:3 step:3553 [D loss: 0.227412, acc.: 60.94%] [G loss: 0.275322]\n",
      "epoch:3 step:3554 [D loss: 0.262360, acc.: 49.22%] [G loss: 0.315603]\n",
      "epoch:3 step:3555 [D loss: 0.232595, acc.: 56.25%] [G loss: 0.344989]\n",
      "epoch:3 step:3556 [D loss: 0.257682, acc.: 53.12%] [G loss: 0.295513]\n",
      "epoch:3 step:3557 [D loss: 0.235463, acc.: 58.59%] [G loss: 0.298880]\n",
      "epoch:3 step:3558 [D loss: 0.233805, acc.: 54.69%] [G loss: 0.342689]\n",
      "epoch:3 step:3559 [D loss: 0.239212, acc.: 62.50%] [G loss: 0.348782]\n",
      "epoch:3 step:3560 [D loss: 0.249941, acc.: 53.12%] [G loss: 0.321884]\n",
      "epoch:3 step:3561 [D loss: 0.239510, acc.: 64.06%] [G loss: 0.289351]\n",
      "epoch:3 step:3562 [D loss: 0.269267, acc.: 50.00%] [G loss: 0.298417]\n",
      "epoch:3 step:3563 [D loss: 0.243804, acc.: 57.81%] [G loss: 0.345842]\n",
      "epoch:3 step:3564 [D loss: 0.231219, acc.: 60.94%] [G loss: 0.297499]\n",
      "epoch:3 step:3565 [D loss: 0.251336, acc.: 54.69%] [G loss: 0.301802]\n",
      "epoch:3 step:3566 [D loss: 0.230937, acc.: 58.59%] [G loss: 0.305348]\n",
      "epoch:3 step:3567 [D loss: 0.237220, acc.: 52.34%] [G loss: 0.282791]\n",
      "epoch:3 step:3568 [D loss: 0.257325, acc.: 51.56%] [G loss: 0.309986]\n",
      "epoch:3 step:3569 [D loss: 0.237610, acc.: 60.16%] [G loss: 0.308267]\n",
      "epoch:3 step:3570 [D loss: 0.249149, acc.: 53.12%] [G loss: 0.303639]\n",
      "epoch:3 step:3571 [D loss: 0.252238, acc.: 56.25%] [G loss: 0.351842]\n",
      "epoch:3 step:3572 [D loss: 0.223473, acc.: 68.75%] [G loss: 0.358467]\n",
      "epoch:3 step:3573 [D loss: 0.258544, acc.: 48.44%] [G loss: 0.329956]\n",
      "epoch:3 step:3574 [D loss: 0.266239, acc.: 49.22%] [G loss: 0.287330]\n",
      "epoch:3 step:3575 [D loss: 0.254067, acc.: 55.47%] [G loss: 0.340673]\n",
      "epoch:3 step:3576 [D loss: 0.231673, acc.: 60.16%] [G loss: 0.335859]\n",
      "epoch:3 step:3577 [D loss: 0.253431, acc.: 51.56%] [G loss: 0.307250]\n",
      "epoch:3 step:3578 [D loss: 0.243223, acc.: 55.47%] [G loss: 0.290173]\n",
      "epoch:3 step:3579 [D loss: 0.245775, acc.: 56.25%] [G loss: 0.297407]\n",
      "epoch:3 step:3580 [D loss: 0.235313, acc.: 60.16%] [G loss: 0.302089]\n",
      "epoch:3 step:3581 [D loss: 0.245013, acc.: 56.25%] [G loss: 0.264739]\n",
      "epoch:3 step:3582 [D loss: 0.249344, acc.: 53.12%] [G loss: 0.274623]\n",
      "epoch:3 step:3583 [D loss: 0.230098, acc.: 61.72%] [G loss: 0.322304]\n",
      "epoch:3 step:3584 [D loss: 0.245746, acc.: 57.03%] [G loss: 0.317633]\n",
      "epoch:3 step:3585 [D loss: 0.234245, acc.: 60.16%] [G loss: 0.297092]\n",
      "epoch:3 step:3586 [D loss: 0.238857, acc.: 59.38%] [G loss: 0.320100]\n",
      "epoch:3 step:3587 [D loss: 0.248667, acc.: 54.69%] [G loss: 0.296752]\n",
      "epoch:3 step:3588 [D loss: 0.245635, acc.: 59.38%] [G loss: 0.313182]\n",
      "epoch:3 step:3589 [D loss: 0.243197, acc.: 51.56%] [G loss: 0.302798]\n",
      "epoch:3 step:3590 [D loss: 0.253978, acc.: 53.12%] [G loss: 0.272228]\n",
      "epoch:3 step:3591 [D loss: 0.246948, acc.: 57.81%] [G loss: 0.292596]\n",
      "epoch:3 step:3592 [D loss: 0.235935, acc.: 56.25%] [G loss: 0.327716]\n",
      "epoch:3 step:3593 [D loss: 0.227537, acc.: 63.28%] [G loss: 0.305576]\n",
      "epoch:3 step:3594 [D loss: 0.248906, acc.: 55.47%] [G loss: 0.305120]\n",
      "epoch:3 step:3595 [D loss: 0.238668, acc.: 57.03%] [G loss: 0.273521]\n",
      "epoch:3 step:3596 [D loss: 0.229473, acc.: 60.94%] [G loss: 0.293166]\n",
      "epoch:3 step:3597 [D loss: 0.242477, acc.: 59.38%] [G loss: 0.292964]\n",
      "epoch:3 step:3598 [D loss: 0.238325, acc.: 60.16%] [G loss: 0.315924]\n",
      "epoch:3 step:3599 [D loss: 0.241583, acc.: 55.47%] [G loss: 0.316089]\n",
      "epoch:3 step:3600 [D loss: 0.259797, acc.: 50.00%] [G loss: 0.298185]\n",
      "epoch:3 step:3601 [D loss: 0.224708, acc.: 56.25%] [G loss: 0.291983]\n",
      "epoch:3 step:3602 [D loss: 0.227324, acc.: 60.94%] [G loss: 0.350477]\n",
      "epoch:3 step:3603 [D loss: 0.247480, acc.: 56.25%] [G loss: 0.279992]\n",
      "epoch:3 step:3604 [D loss: 0.239363, acc.: 57.03%] [G loss: 0.323804]\n",
      "epoch:3 step:3605 [D loss: 0.219352, acc.: 60.94%] [G loss: 0.297751]\n",
      "epoch:3 step:3606 [D loss: 0.243757, acc.: 57.03%] [G loss: 0.332667]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:3 step:3607 [D loss: 0.246390, acc.: 57.03%] [G loss: 0.311064]\n",
      "epoch:3 step:3608 [D loss: 0.240568, acc.: 57.03%] [G loss: 0.299628]\n",
      "epoch:3 step:3609 [D loss: 0.248841, acc.: 53.12%] [G loss: 0.296262]\n",
      "epoch:3 step:3610 [D loss: 0.254639, acc.: 53.12%] [G loss: 0.318145]\n",
      "epoch:3 step:3611 [D loss: 0.269421, acc.: 51.56%] [G loss: 0.289423]\n",
      "epoch:3 step:3612 [D loss: 0.231783, acc.: 60.94%] [G loss: 0.325634]\n",
      "epoch:3 step:3613 [D loss: 0.230920, acc.: 58.59%] [G loss: 0.304367]\n",
      "epoch:3 step:3614 [D loss: 0.238123, acc.: 60.94%] [G loss: 0.301009]\n",
      "epoch:3 step:3615 [D loss: 0.253842, acc.: 51.56%] [G loss: 0.307400]\n",
      "epoch:3 step:3616 [D loss: 0.215185, acc.: 66.41%] [G loss: 0.285841]\n",
      "epoch:3 step:3617 [D loss: 0.254632, acc.: 53.12%] [G loss: 0.313318]\n",
      "epoch:3 step:3618 [D loss: 0.244605, acc.: 59.38%] [G loss: 0.273773]\n",
      "epoch:3 step:3619 [D loss: 0.239951, acc.: 54.69%] [G loss: 0.297327]\n",
      "epoch:3 step:3620 [D loss: 0.259350, acc.: 53.12%] [G loss: 0.311041]\n",
      "epoch:3 step:3621 [D loss: 0.242938, acc.: 57.03%] [G loss: 0.314973]\n",
      "epoch:3 step:3622 [D loss: 0.250771, acc.: 53.91%] [G loss: 0.327800]\n",
      "epoch:3 step:3623 [D loss: 0.234366, acc.: 60.94%] [G loss: 0.346168]\n",
      "epoch:3 step:3624 [D loss: 0.225307, acc.: 59.38%] [G loss: 0.351027]\n",
      "epoch:3 step:3625 [D loss: 0.249637, acc.: 56.25%] [G loss: 0.319400]\n",
      "epoch:3 step:3626 [D loss: 0.237755, acc.: 61.72%] [G loss: 0.325929]\n",
      "epoch:3 step:3627 [D loss: 0.210851, acc.: 69.53%] [G loss: 0.307514]\n",
      "epoch:3 step:3628 [D loss: 0.227513, acc.: 65.62%] [G loss: 0.314485]\n",
      "epoch:3 step:3629 [D loss: 0.274336, acc.: 46.88%] [G loss: 0.304821]\n",
      "epoch:3 step:3630 [D loss: 0.243737, acc.: 57.81%] [G loss: 0.333580]\n",
      "epoch:3 step:3631 [D loss: 0.227671, acc.: 60.16%] [G loss: 0.346627]\n",
      "epoch:3 step:3632 [D loss: 0.264681, acc.: 50.78%] [G loss: 0.292808]\n",
      "epoch:3 step:3633 [D loss: 0.244764, acc.: 54.69%] [G loss: 0.334508]\n",
      "epoch:3 step:3634 [D loss: 0.254247, acc.: 59.38%] [G loss: 0.326604]\n",
      "epoch:3 step:3635 [D loss: 0.223268, acc.: 62.50%] [G loss: 0.338357]\n",
      "epoch:3 step:3636 [D loss: 0.239821, acc.: 59.38%] [G loss: 0.325420]\n",
      "epoch:3 step:3637 [D loss: 0.244411, acc.: 60.94%] [G loss: 0.286278]\n",
      "epoch:3 step:3638 [D loss: 0.230330, acc.: 64.06%] [G loss: 0.325063]\n",
      "epoch:3 step:3639 [D loss: 0.272551, acc.: 50.00%] [G loss: 0.292166]\n",
      "epoch:3 step:3640 [D loss: 0.261530, acc.: 51.56%] [G loss: 0.291936]\n",
      "epoch:3 step:3641 [D loss: 0.241104, acc.: 57.03%] [G loss: 0.345599]\n",
      "epoch:3 step:3642 [D loss: 0.258741, acc.: 53.91%] [G loss: 0.275596]\n",
      "epoch:3 step:3643 [D loss: 0.231730, acc.: 59.38%] [G loss: 0.306779]\n",
      "epoch:3 step:3644 [D loss: 0.258585, acc.: 52.34%] [G loss: 0.332014]\n",
      "epoch:3 step:3645 [D loss: 0.254850, acc.: 52.34%] [G loss: 0.345239]\n",
      "epoch:3 step:3646 [D loss: 0.237684, acc.: 61.72%] [G loss: 0.317708]\n",
      "epoch:3 step:3647 [D loss: 0.239663, acc.: 59.38%] [G loss: 0.294906]\n",
      "epoch:3 step:3648 [D loss: 0.243971, acc.: 61.72%] [G loss: 0.279815]\n",
      "epoch:3 step:3649 [D loss: 0.250571, acc.: 59.38%] [G loss: 0.321721]\n",
      "epoch:3 step:3650 [D loss: 0.255725, acc.: 46.88%] [G loss: 0.288185]\n",
      "epoch:3 step:3651 [D loss: 0.243474, acc.: 57.03%] [G loss: 0.315850]\n",
      "epoch:3 step:3652 [D loss: 0.241885, acc.: 53.12%] [G loss: 0.309738]\n",
      "epoch:3 step:3653 [D loss: 0.261235, acc.: 55.47%] [G loss: 0.279094]\n",
      "epoch:3 step:3654 [D loss: 0.236078, acc.: 60.16%] [G loss: 0.328939]\n",
      "epoch:3 step:3655 [D loss: 0.252813, acc.: 52.34%] [G loss: 0.335644]\n",
      "epoch:3 step:3656 [D loss: 0.243374, acc.: 56.25%] [G loss: 0.299587]\n",
      "epoch:3 step:3657 [D loss: 0.238130, acc.: 60.16%] [G loss: 0.316635]\n",
      "epoch:3 step:3658 [D loss: 0.246334, acc.: 57.81%] [G loss: 0.295366]\n",
      "epoch:3 step:3659 [D loss: 0.244844, acc.: 60.16%] [G loss: 0.310944]\n",
      "epoch:3 step:3660 [D loss: 0.245901, acc.: 50.78%] [G loss: 0.323963]\n",
      "epoch:3 step:3661 [D loss: 0.236533, acc.: 60.94%] [G loss: 0.334990]\n",
      "epoch:3 step:3662 [D loss: 0.263170, acc.: 51.56%] [G loss: 0.292895]\n",
      "epoch:3 step:3663 [D loss: 0.226489, acc.: 64.84%] [G loss: 0.326533]\n",
      "epoch:3 step:3664 [D loss: 0.231588, acc.: 60.94%] [G loss: 0.281517]\n",
      "epoch:3 step:3665 [D loss: 0.239781, acc.: 58.59%] [G loss: 0.311346]\n",
      "epoch:3 step:3666 [D loss: 0.268215, acc.: 49.22%] [G loss: 0.283189]\n",
      "epoch:3 step:3667 [D loss: 0.219097, acc.: 60.16%] [G loss: 0.303269]\n",
      "epoch:3 step:3668 [D loss: 0.244304, acc.: 57.81%] [G loss: 0.314204]\n",
      "epoch:3 step:3669 [D loss: 0.250372, acc.: 59.38%] [G loss: 0.306036]\n",
      "epoch:3 step:3670 [D loss: 0.232882, acc.: 64.84%] [G loss: 0.322677]\n",
      "epoch:3 step:3671 [D loss: 0.234688, acc.: 60.16%] [G loss: 0.281912]\n",
      "epoch:3 step:3672 [D loss: 0.252935, acc.: 53.91%] [G loss: 0.282301]\n",
      "epoch:3 step:3673 [D loss: 0.247327, acc.: 57.03%] [G loss: 0.311884]\n",
      "epoch:3 step:3674 [D loss: 0.248012, acc.: 52.34%] [G loss: 0.297378]\n",
      "epoch:3 step:3675 [D loss: 0.266131, acc.: 49.22%] [G loss: 0.336005]\n",
      "epoch:3 step:3676 [D loss: 0.255580, acc.: 50.78%] [G loss: 0.311646]\n",
      "epoch:3 step:3677 [D loss: 0.234356, acc.: 55.47%] [G loss: 0.339758]\n",
      "epoch:3 step:3678 [D loss: 0.260633, acc.: 50.78%] [G loss: 0.310018]\n",
      "epoch:3 step:3679 [D loss: 0.226270, acc.: 60.94%] [G loss: 0.298894]\n",
      "epoch:3 step:3680 [D loss: 0.245420, acc.: 53.91%] [G loss: 0.319924]\n",
      "epoch:3 step:3681 [D loss: 0.227067, acc.: 64.06%] [G loss: 0.326216]\n",
      "epoch:3 step:3682 [D loss: 0.252903, acc.: 53.12%] [G loss: 0.295138]\n",
      "epoch:3 step:3683 [D loss: 0.281589, acc.: 48.44%] [G loss: 0.267058]\n",
      "epoch:3 step:3684 [D loss: 0.237715, acc.: 61.72%] [G loss: 0.306681]\n",
      "epoch:3 step:3685 [D loss: 0.247751, acc.: 57.81%] [G loss: 0.324291]\n",
      "epoch:3 step:3686 [D loss: 0.223235, acc.: 60.94%] [G loss: 0.346576]\n",
      "epoch:3 step:3687 [D loss: 0.259146, acc.: 50.78%] [G loss: 0.351187]\n",
      "epoch:3 step:3688 [D loss: 0.233476, acc.: 60.16%] [G loss: 0.305639]\n",
      "epoch:3 step:3689 [D loss: 0.253863, acc.: 51.56%] [G loss: 0.336562]\n",
      "epoch:3 step:3690 [D loss: 0.227351, acc.: 68.75%] [G loss: 0.312671]\n",
      "epoch:3 step:3691 [D loss: 0.230832, acc.: 62.50%] [G loss: 0.317669]\n",
      "epoch:3 step:3692 [D loss: 0.236487, acc.: 60.94%] [G loss: 0.319394]\n",
      "epoch:3 step:3693 [D loss: 0.238891, acc.: 63.28%] [G loss: 0.317390]\n",
      "epoch:3 step:3694 [D loss: 0.237746, acc.: 61.72%] [G loss: 0.309167]\n",
      "epoch:3 step:3695 [D loss: 0.231585, acc.: 59.38%] [G loss: 0.310358]\n",
      "epoch:3 step:3696 [D loss: 0.259094, acc.: 53.12%] [G loss: 0.296937]\n",
      "epoch:3 step:3697 [D loss: 0.253296, acc.: 55.47%] [G loss: 0.344160]\n",
      "epoch:3 step:3698 [D loss: 0.236645, acc.: 60.94%] [G loss: 0.333682]\n",
      "epoch:3 step:3699 [D loss: 0.238364, acc.: 60.16%] [G loss: 0.281667]\n",
      "epoch:3 step:3700 [D loss: 0.250678, acc.: 57.03%] [G loss: 0.294867]\n",
      "epoch:3 step:3701 [D loss: 0.225744, acc.: 64.84%] [G loss: 0.308618]\n",
      "epoch:3 step:3702 [D loss: 0.256261, acc.: 50.00%] [G loss: 0.322862]\n",
      "epoch:3 step:3703 [D loss: 0.243773, acc.: 58.59%] [G loss: 0.295640]\n",
      "epoch:3 step:3704 [D loss: 0.249810, acc.: 57.81%] [G loss: 0.322068]\n",
      "epoch:3 step:3705 [D loss: 0.250087, acc.: 58.59%] [G loss: 0.301595]\n",
      "epoch:3 step:3706 [D loss: 0.235612, acc.: 61.72%] [G loss: 0.321372]\n",
      "epoch:3 step:3707 [D loss: 0.237579, acc.: 57.03%] [G loss: 0.311007]\n",
      "epoch:3 step:3708 [D loss: 0.229363, acc.: 61.72%] [G loss: 0.308414]\n",
      "epoch:3 step:3709 [D loss: 0.245191, acc.: 53.91%] [G loss: 0.297088]\n",
      "epoch:3 step:3710 [D loss: 0.246143, acc.: 59.38%] [G loss: 0.328079]\n",
      "epoch:3 step:3711 [D loss: 0.235567, acc.: 64.06%] [G loss: 0.297936]\n",
      "epoch:3 step:3712 [D loss: 0.249864, acc.: 54.69%] [G loss: 0.328831]\n",
      "epoch:3 step:3713 [D loss: 0.245858, acc.: 58.59%] [G loss: 0.306737]\n",
      "epoch:3 step:3714 [D loss: 0.240358, acc.: 56.25%] [G loss: 0.291610]\n",
      "epoch:3 step:3715 [D loss: 0.231357, acc.: 63.28%] [G loss: 0.285330]\n",
      "epoch:3 step:3716 [D loss: 0.242170, acc.: 64.06%] [G loss: 0.348843]\n",
      "epoch:3 step:3717 [D loss: 0.229864, acc.: 57.81%] [G loss: 0.319367]\n",
      "epoch:3 step:3718 [D loss: 0.238037, acc.: 57.81%] [G loss: 0.320846]\n",
      "epoch:3 step:3719 [D loss: 0.249435, acc.: 54.69%] [G loss: 0.314913]\n",
      "epoch:3 step:3720 [D loss: 0.244808, acc.: 56.25%] [G loss: 0.298973]\n",
      "epoch:3 step:3721 [D loss: 0.247229, acc.: 58.59%] [G loss: 0.306818]\n",
      "epoch:3 step:3722 [D loss: 0.255253, acc.: 54.69%] [G loss: 0.333017]\n",
      "epoch:3 step:3723 [D loss: 0.254574, acc.: 57.81%] [G loss: 0.316488]\n",
      "epoch:3 step:3724 [D loss: 0.254448, acc.: 53.12%] [G loss: 0.324157]\n",
      "epoch:3 step:3725 [D loss: 0.237995, acc.: 56.25%] [G loss: 0.314517]\n",
      "epoch:3 step:3726 [D loss: 0.246653, acc.: 54.69%] [G loss: 0.307769]\n",
      "epoch:3 step:3727 [D loss: 0.246914, acc.: 57.81%] [G loss: 0.274564]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:3 step:3728 [D loss: 0.254714, acc.: 53.91%] [G loss: 0.297649]\n",
      "epoch:3 step:3729 [D loss: 0.250419, acc.: 57.03%] [G loss: 0.350744]\n",
      "epoch:3 step:3730 [D loss: 0.223568, acc.: 64.84%] [G loss: 0.306297]\n",
      "epoch:3 step:3731 [D loss: 0.261453, acc.: 49.22%] [G loss: 0.301172]\n",
      "epoch:3 step:3732 [D loss: 0.262708, acc.: 47.66%] [G loss: 0.281259]\n",
      "epoch:3 step:3733 [D loss: 0.236085, acc.: 62.50%] [G loss: 0.310629]\n",
      "epoch:3 step:3734 [D loss: 0.252664, acc.: 55.47%] [G loss: 0.311878]\n",
      "epoch:3 step:3735 [D loss: 0.243023, acc.: 54.69%] [G loss: 0.297390]\n",
      "epoch:3 step:3736 [D loss: 0.223463, acc.: 61.72%] [G loss: 0.319863]\n",
      "epoch:3 step:3737 [D loss: 0.235396, acc.: 59.38%] [G loss: 0.293660]\n",
      "epoch:3 step:3738 [D loss: 0.255536, acc.: 55.47%] [G loss: 0.298107]\n",
      "epoch:3 step:3739 [D loss: 0.238417, acc.: 63.28%] [G loss: 0.312415]\n",
      "epoch:3 step:3740 [D loss: 0.232091, acc.: 63.28%] [G loss: 0.346956]\n",
      "epoch:3 step:3741 [D loss: 0.239187, acc.: 55.47%] [G loss: 0.296220]\n",
      "epoch:3 step:3742 [D loss: 0.231866, acc.: 60.94%] [G loss: 0.325626]\n",
      "epoch:3 step:3743 [D loss: 0.223497, acc.: 64.06%] [G loss: 0.335031]\n",
      "epoch:3 step:3744 [D loss: 0.242680, acc.: 58.59%] [G loss: 0.325946]\n",
      "epoch:3 step:3745 [D loss: 0.223922, acc.: 65.62%] [G loss: 0.330537]\n",
      "epoch:3 step:3746 [D loss: 0.233324, acc.: 60.94%] [G loss: 0.328758]\n",
      "epoch:3 step:3747 [D loss: 0.233434, acc.: 60.16%] [G loss: 0.292439]\n",
      "epoch:3 step:3748 [D loss: 0.246587, acc.: 59.38%] [G loss: 0.316541]\n",
      "epoch:4 step:3749 [D loss: 0.262243, acc.: 52.34%] [G loss: 0.303685]\n",
      "epoch:4 step:3750 [D loss: 0.259349, acc.: 52.34%] [G loss: 0.323723]\n",
      "epoch:4 step:3751 [D loss: 0.262230, acc.: 52.34%] [G loss: 0.301081]\n",
      "epoch:4 step:3752 [D loss: 0.263033, acc.: 48.44%] [G loss: 0.306130]\n",
      "epoch:4 step:3753 [D loss: 0.228191, acc.: 65.62%] [G loss: 0.349626]\n",
      "epoch:4 step:3754 [D loss: 0.273464, acc.: 44.53%] [G loss: 0.287477]\n",
      "epoch:4 step:3755 [D loss: 0.237125, acc.: 60.94%] [G loss: 0.293914]\n",
      "epoch:4 step:3756 [D loss: 0.224573, acc.: 67.19%] [G loss: 0.302905]\n",
      "epoch:4 step:3757 [D loss: 0.230567, acc.: 64.06%] [G loss: 0.288453]\n",
      "epoch:4 step:3758 [D loss: 0.243935, acc.: 57.81%] [G loss: 0.324518]\n",
      "epoch:4 step:3759 [D loss: 0.242078, acc.: 52.34%] [G loss: 0.273246]\n",
      "epoch:4 step:3760 [D loss: 0.247734, acc.: 57.81%] [G loss: 0.332683]\n",
      "epoch:4 step:3761 [D loss: 0.234510, acc.: 57.81%] [G loss: 0.344531]\n",
      "epoch:4 step:3762 [D loss: 0.234173, acc.: 60.94%] [G loss: 0.304203]\n",
      "epoch:4 step:3763 [D loss: 0.251646, acc.: 57.81%] [G loss: 0.306827]\n",
      "epoch:4 step:3764 [D loss: 0.244864, acc.: 60.94%] [G loss: 0.298324]\n",
      "epoch:4 step:3765 [D loss: 0.248820, acc.: 61.72%] [G loss: 0.308745]\n",
      "epoch:4 step:3766 [D loss: 0.238001, acc.: 60.94%] [G loss: 0.320304]\n",
      "epoch:4 step:3767 [D loss: 0.255058, acc.: 58.59%] [G loss: 0.346141]\n",
      "epoch:4 step:3768 [D loss: 0.250437, acc.: 53.12%] [G loss: 0.322946]\n",
      "epoch:4 step:3769 [D loss: 0.244417, acc.: 57.03%] [G loss: 0.284214]\n",
      "epoch:4 step:3770 [D loss: 0.233845, acc.: 58.59%] [G loss: 0.302807]\n",
      "epoch:4 step:3771 [D loss: 0.247271, acc.: 54.69%] [G loss: 0.294163]\n",
      "epoch:4 step:3772 [D loss: 0.238431, acc.: 57.81%] [G loss: 0.293658]\n",
      "epoch:4 step:3773 [D loss: 0.237573, acc.: 58.59%] [G loss: 0.284483]\n",
      "epoch:4 step:3774 [D loss: 0.218652, acc.: 64.06%] [G loss: 0.323160]\n",
      "epoch:4 step:3775 [D loss: 0.259596, acc.: 50.00%] [G loss: 0.317046]\n",
      "epoch:4 step:3776 [D loss: 0.227893, acc.: 62.50%] [G loss: 0.316289]\n",
      "epoch:4 step:3777 [D loss: 0.253396, acc.: 57.03%] [G loss: 0.304273]\n",
      "epoch:4 step:3778 [D loss: 0.231131, acc.: 64.84%] [G loss: 0.325947]\n",
      "epoch:4 step:3779 [D loss: 0.264680, acc.: 46.09%] [G loss: 0.308866]\n",
      "epoch:4 step:3780 [D loss: 0.230242, acc.: 62.50%] [G loss: 0.301441]\n",
      "epoch:4 step:3781 [D loss: 0.233662, acc.: 61.72%] [G loss: 0.276059]\n",
      "epoch:4 step:3782 [D loss: 0.266072, acc.: 48.44%] [G loss: 0.281334]\n",
      "epoch:4 step:3783 [D loss: 0.258000, acc.: 50.78%] [G loss: 0.253479]\n",
      "epoch:4 step:3784 [D loss: 0.225803, acc.: 64.84%] [G loss: 0.310276]\n",
      "epoch:4 step:3785 [D loss: 0.236263, acc.: 56.25%] [G loss: 0.304175]\n",
      "epoch:4 step:3786 [D loss: 0.258418, acc.: 48.44%] [G loss: 0.311450]\n",
      "epoch:4 step:3787 [D loss: 0.239269, acc.: 56.25%] [G loss: 0.268202]\n",
      "epoch:4 step:3788 [D loss: 0.242316, acc.: 55.47%] [G loss: 0.312307]\n",
      "epoch:4 step:3789 [D loss: 0.239854, acc.: 60.16%] [G loss: 0.313570]\n",
      "epoch:4 step:3790 [D loss: 0.246372, acc.: 57.81%] [G loss: 0.316795]\n",
      "epoch:4 step:3791 [D loss: 0.230513, acc.: 61.72%] [G loss: 0.340326]\n",
      "epoch:4 step:3792 [D loss: 0.252998, acc.: 47.66%] [G loss: 0.310334]\n",
      "epoch:4 step:3793 [D loss: 0.233044, acc.: 60.16%] [G loss: 0.310871]\n",
      "epoch:4 step:3794 [D loss: 0.240161, acc.: 59.38%] [G loss: 0.291546]\n",
      "epoch:4 step:3795 [D loss: 0.252412, acc.: 46.88%] [G loss: 0.293130]\n",
      "epoch:4 step:3796 [D loss: 0.272393, acc.: 44.53%] [G loss: 0.282122]\n",
      "epoch:4 step:3797 [D loss: 0.245622, acc.: 60.16%] [G loss: 0.309307]\n",
      "epoch:4 step:3798 [D loss: 0.242930, acc.: 58.59%] [G loss: 0.312125]\n",
      "epoch:4 step:3799 [D loss: 0.238788, acc.: 58.59%] [G loss: 0.304032]\n",
      "epoch:4 step:3800 [D loss: 0.239894, acc.: 60.16%] [G loss: 0.299998]\n",
      "epoch:4 step:3801 [D loss: 0.237724, acc.: 57.03%] [G loss: 0.336185]\n",
      "epoch:4 step:3802 [D loss: 0.261820, acc.: 51.56%] [G loss: 0.277627]\n",
      "epoch:4 step:3803 [D loss: 0.249539, acc.: 60.16%] [G loss: 0.308378]\n",
      "epoch:4 step:3804 [D loss: 0.241786, acc.: 60.16%] [G loss: 0.329274]\n",
      "epoch:4 step:3805 [D loss: 0.259138, acc.: 51.56%] [G loss: 0.308592]\n",
      "epoch:4 step:3806 [D loss: 0.237716, acc.: 58.59%] [G loss: 0.295574]\n",
      "epoch:4 step:3807 [D loss: 0.237175, acc.: 60.16%] [G loss: 0.283535]\n",
      "epoch:4 step:3808 [D loss: 0.233428, acc.: 60.94%] [G loss: 0.317686]\n",
      "epoch:4 step:3809 [D loss: 0.241673, acc.: 58.59%] [G loss: 0.319378]\n",
      "epoch:4 step:3810 [D loss: 0.245819, acc.: 60.16%] [G loss: 0.314523]\n",
      "epoch:4 step:3811 [D loss: 0.217095, acc.: 70.31%] [G loss: 0.306192]\n",
      "epoch:4 step:3812 [D loss: 0.244185, acc.: 57.81%] [G loss: 0.310780]\n",
      "epoch:4 step:3813 [D loss: 0.223775, acc.: 66.41%] [G loss: 0.326882]\n",
      "epoch:4 step:3814 [D loss: 0.267061, acc.: 49.22%] [G loss: 0.288046]\n",
      "epoch:4 step:3815 [D loss: 0.267983, acc.: 46.09%] [G loss: 0.283968]\n",
      "epoch:4 step:3816 [D loss: 0.227813, acc.: 64.06%] [G loss: 0.286762]\n",
      "epoch:4 step:3817 [D loss: 0.235629, acc.: 59.38%] [G loss: 0.287397]\n",
      "epoch:4 step:3818 [D loss: 0.244584, acc.: 53.12%] [G loss: 0.307740]\n",
      "epoch:4 step:3819 [D loss: 0.248641, acc.: 57.03%] [G loss: 0.296524]\n",
      "epoch:4 step:3820 [D loss: 0.238999, acc.: 60.94%] [G loss: 0.331650]\n",
      "epoch:4 step:3821 [D loss: 0.249533, acc.: 55.47%] [G loss: 0.305837]\n",
      "epoch:4 step:3822 [D loss: 0.251835, acc.: 51.56%] [G loss: 0.312475]\n",
      "epoch:4 step:3823 [D loss: 0.247155, acc.: 54.69%] [G loss: 0.311072]\n",
      "epoch:4 step:3824 [D loss: 0.250737, acc.: 51.56%] [G loss: 0.310426]\n",
      "epoch:4 step:3825 [D loss: 0.255135, acc.: 50.78%] [G loss: 0.315239]\n",
      "epoch:4 step:3826 [D loss: 0.236076, acc.: 61.72%] [G loss: 0.313782]\n",
      "epoch:4 step:3827 [D loss: 0.265240, acc.: 49.22%] [G loss: 0.335965]\n",
      "epoch:4 step:3828 [D loss: 0.236377, acc.: 56.25%] [G loss: 0.336974]\n",
      "epoch:4 step:3829 [D loss: 0.227381, acc.: 61.72%] [G loss: 0.326901]\n",
      "epoch:4 step:3830 [D loss: 0.258772, acc.: 53.12%] [G loss: 0.301296]\n",
      "epoch:4 step:3831 [D loss: 0.251803, acc.: 57.81%] [G loss: 0.311813]\n",
      "epoch:4 step:3832 [D loss: 0.240297, acc.: 62.50%] [G loss: 0.308080]\n",
      "epoch:4 step:3833 [D loss: 0.224606, acc.: 64.06%] [G loss: 0.333962]\n",
      "epoch:4 step:3834 [D loss: 0.226251, acc.: 67.97%] [G loss: 0.306793]\n",
      "epoch:4 step:3835 [D loss: 0.251635, acc.: 51.56%] [G loss: 0.316075]\n",
      "epoch:4 step:3836 [D loss: 0.244179, acc.: 61.72%] [G loss: 0.297079]\n",
      "epoch:4 step:3837 [D loss: 0.253195, acc.: 53.12%] [G loss: 0.282179]\n",
      "epoch:4 step:3838 [D loss: 0.222818, acc.: 62.50%] [G loss: 0.279537]\n",
      "epoch:4 step:3839 [D loss: 0.258018, acc.: 55.47%] [G loss: 0.304465]\n",
      "epoch:4 step:3840 [D loss: 0.232196, acc.: 61.72%] [G loss: 0.327342]\n",
      "epoch:4 step:3841 [D loss: 0.236407, acc.: 59.38%] [G loss: 0.309106]\n",
      "epoch:4 step:3842 [D loss: 0.245775, acc.: 53.91%] [G loss: 0.281215]\n",
      "epoch:4 step:3843 [D loss: 0.245684, acc.: 57.03%] [G loss: 0.323402]\n",
      "epoch:4 step:3844 [D loss: 0.250994, acc.: 59.38%] [G loss: 0.303402]\n",
      "epoch:4 step:3845 [D loss: 0.250592, acc.: 51.56%] [G loss: 0.304995]\n",
      "epoch:4 step:3846 [D loss: 0.257908, acc.: 53.12%] [G loss: 0.295307]\n",
      "epoch:4 step:3847 [D loss: 0.264675, acc.: 53.12%] [G loss: 0.336130]\n",
      "epoch:4 step:3848 [D loss: 0.244525, acc.: 55.47%] [G loss: 0.304316]\n",
      "epoch:4 step:3849 [D loss: 0.243068, acc.: 57.81%] [G loss: 0.301283]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:4 step:3850 [D loss: 0.257909, acc.: 49.22%] [G loss: 0.330203]\n",
      "epoch:4 step:3851 [D loss: 0.241758, acc.: 56.25%] [G loss: 0.281934]\n",
      "epoch:4 step:3852 [D loss: 0.244477, acc.: 58.59%] [G loss: 0.328061]\n",
      "epoch:4 step:3853 [D loss: 0.234915, acc.: 61.72%] [G loss: 0.306268]\n",
      "epoch:4 step:3854 [D loss: 0.241065, acc.: 57.81%] [G loss: 0.323013]\n",
      "epoch:4 step:3855 [D loss: 0.237597, acc.: 57.81%] [G loss: 0.330749]\n",
      "epoch:4 step:3856 [D loss: 0.245533, acc.: 52.34%] [G loss: 0.330401]\n",
      "epoch:4 step:3857 [D loss: 0.258870, acc.: 54.69%] [G loss: 0.337283]\n",
      "epoch:4 step:3858 [D loss: 0.235260, acc.: 57.81%] [G loss: 0.324651]\n",
      "epoch:4 step:3859 [D loss: 0.228257, acc.: 63.28%] [G loss: 0.311768]\n",
      "epoch:4 step:3860 [D loss: 0.234870, acc.: 63.28%] [G loss: 0.295969]\n",
      "epoch:4 step:3861 [D loss: 0.235127, acc.: 64.06%] [G loss: 0.306704]\n",
      "epoch:4 step:3862 [D loss: 0.251191, acc.: 58.59%] [G loss: 0.295806]\n",
      "epoch:4 step:3863 [D loss: 0.253915, acc.: 51.56%] [G loss: 0.271751]\n",
      "epoch:4 step:3864 [D loss: 0.245465, acc.: 56.25%] [G loss: 0.335245]\n",
      "epoch:4 step:3865 [D loss: 0.258734, acc.: 54.69%] [G loss: 0.290883]\n",
      "epoch:4 step:3866 [D loss: 0.242598, acc.: 54.69%] [G loss: 0.314802]\n",
      "epoch:4 step:3867 [D loss: 0.241480, acc.: 58.59%] [G loss: 0.281980]\n",
      "epoch:4 step:3868 [D loss: 0.239873, acc.: 64.84%] [G loss: 0.312684]\n",
      "epoch:4 step:3869 [D loss: 0.231318, acc.: 61.72%] [G loss: 0.296203]\n",
      "epoch:4 step:3870 [D loss: 0.257406, acc.: 53.12%] [G loss: 0.307755]\n",
      "epoch:4 step:3871 [D loss: 0.243031, acc.: 57.81%] [G loss: 0.324426]\n",
      "epoch:4 step:3872 [D loss: 0.251501, acc.: 56.25%] [G loss: 0.306033]\n",
      "epoch:4 step:3873 [D loss: 0.223886, acc.: 64.84%] [G loss: 0.317508]\n",
      "epoch:4 step:3874 [D loss: 0.243270, acc.: 57.03%] [G loss: 0.293372]\n",
      "epoch:4 step:3875 [D loss: 0.244135, acc.: 55.47%] [G loss: 0.297857]\n",
      "epoch:4 step:3876 [D loss: 0.248602, acc.: 52.34%] [G loss: 0.274988]\n",
      "epoch:4 step:3877 [D loss: 0.244878, acc.: 58.59%] [G loss: 0.329904]\n",
      "epoch:4 step:3878 [D loss: 0.244967, acc.: 64.84%] [G loss: 0.308824]\n",
      "epoch:4 step:3879 [D loss: 0.221092, acc.: 67.19%] [G loss: 0.297720]\n",
      "epoch:4 step:3880 [D loss: 0.271026, acc.: 48.44%] [G loss: 0.326206]\n",
      "epoch:4 step:3881 [D loss: 0.234501, acc.: 63.28%] [G loss: 0.314887]\n",
      "epoch:4 step:3882 [D loss: 0.263114, acc.: 50.00%] [G loss: 0.318771]\n",
      "epoch:4 step:3883 [D loss: 0.245246, acc.: 57.81%] [G loss: 0.342055]\n",
      "epoch:4 step:3884 [D loss: 0.257381, acc.: 48.44%] [G loss: 0.289007]\n",
      "epoch:4 step:3885 [D loss: 0.236502, acc.: 63.28%] [G loss: 0.292496]\n",
      "epoch:4 step:3886 [D loss: 0.257775, acc.: 55.47%] [G loss: 0.316321]\n",
      "epoch:4 step:3887 [D loss: 0.240170, acc.: 62.50%] [G loss: 0.302001]\n",
      "epoch:4 step:3888 [D loss: 0.239721, acc.: 57.81%] [G loss: 0.289765]\n",
      "epoch:4 step:3889 [D loss: 0.242082, acc.: 57.03%] [G loss: 0.332304]\n",
      "epoch:4 step:3890 [D loss: 0.248278, acc.: 57.03%] [G loss: 0.332449]\n",
      "epoch:4 step:3891 [D loss: 0.258534, acc.: 49.22%] [G loss: 0.293365]\n",
      "epoch:4 step:3892 [D loss: 0.254406, acc.: 54.69%] [G loss: 0.315673]\n",
      "epoch:4 step:3893 [D loss: 0.243442, acc.: 57.03%] [G loss: 0.313175]\n",
      "epoch:4 step:3894 [D loss: 0.235632, acc.: 61.72%] [G loss: 0.305687]\n",
      "epoch:4 step:3895 [D loss: 0.239688, acc.: 59.38%] [G loss: 0.327765]\n",
      "epoch:4 step:3896 [D loss: 0.257244, acc.: 50.00%] [G loss: 0.286681]\n",
      "epoch:4 step:3897 [D loss: 0.237100, acc.: 59.38%] [G loss: 0.303091]\n",
      "epoch:4 step:3898 [D loss: 0.244815, acc.: 56.25%] [G loss: 0.312031]\n",
      "epoch:4 step:3899 [D loss: 0.251689, acc.: 53.12%] [G loss: 0.291853]\n",
      "epoch:4 step:3900 [D loss: 0.243050, acc.: 55.47%] [G loss: 0.270938]\n",
      "epoch:4 step:3901 [D loss: 0.243762, acc.: 57.03%] [G loss: 0.289513]\n",
      "epoch:4 step:3902 [D loss: 0.246227, acc.: 60.16%] [G loss: 0.288764]\n",
      "epoch:4 step:3903 [D loss: 0.237343, acc.: 58.59%] [G loss: 0.302717]\n",
      "epoch:4 step:3904 [D loss: 0.230062, acc.: 60.16%] [G loss: 0.292024]\n",
      "epoch:4 step:3905 [D loss: 0.244409, acc.: 60.16%] [G loss: 0.293213]\n",
      "epoch:4 step:3906 [D loss: 0.247872, acc.: 55.47%] [G loss: 0.312734]\n",
      "epoch:4 step:3907 [D loss: 0.240473, acc.: 60.94%] [G loss: 0.323841]\n",
      "epoch:4 step:3908 [D loss: 0.256362, acc.: 53.91%] [G loss: 0.279446]\n",
      "epoch:4 step:3909 [D loss: 0.265195, acc.: 53.91%] [G loss: 0.281596]\n",
      "epoch:4 step:3910 [D loss: 0.245051, acc.: 58.59%] [G loss: 0.311179]\n",
      "epoch:4 step:3911 [D loss: 0.246044, acc.: 60.94%] [G loss: 0.343640]\n",
      "epoch:4 step:3912 [D loss: 0.264278, acc.: 50.00%] [G loss: 0.291189]\n",
      "epoch:4 step:3913 [D loss: 0.228247, acc.: 61.72%] [G loss: 0.309554]\n",
      "epoch:4 step:3914 [D loss: 0.251185, acc.: 49.22%] [G loss: 0.328068]\n",
      "epoch:4 step:3915 [D loss: 0.242276, acc.: 56.25%] [G loss: 0.291867]\n",
      "epoch:4 step:3916 [D loss: 0.244757, acc.: 57.03%] [G loss: 0.308206]\n",
      "epoch:4 step:3917 [D loss: 0.275434, acc.: 42.97%] [G loss: 0.289465]\n",
      "epoch:4 step:3918 [D loss: 0.234718, acc.: 60.94%] [G loss: 0.313068]\n",
      "epoch:4 step:3919 [D loss: 0.224438, acc.: 60.94%] [G loss: 0.310451]\n",
      "epoch:4 step:3920 [D loss: 0.232366, acc.: 60.16%] [G loss: 0.320068]\n",
      "epoch:4 step:3921 [D loss: 0.236381, acc.: 60.16%] [G loss: 0.319417]\n",
      "epoch:4 step:3922 [D loss: 0.260430, acc.: 50.78%] [G loss: 0.285542]\n",
      "epoch:4 step:3923 [D loss: 0.236453, acc.: 58.59%] [G loss: 0.301370]\n",
      "epoch:4 step:3924 [D loss: 0.245797, acc.: 58.59%] [G loss: 0.331543]\n",
      "epoch:4 step:3925 [D loss: 0.237199, acc.: 55.47%] [G loss: 0.309399]\n",
      "epoch:4 step:3926 [D loss: 0.260363, acc.: 50.78%] [G loss: 0.339476]\n",
      "epoch:4 step:3927 [D loss: 0.245294, acc.: 58.59%] [G loss: 0.327415]\n",
      "epoch:4 step:3928 [D loss: 0.239172, acc.: 57.03%] [G loss: 0.311216]\n",
      "epoch:4 step:3929 [D loss: 0.257536, acc.: 53.91%] [G loss: 0.335686]\n",
      "epoch:4 step:3930 [D loss: 0.246637, acc.: 53.12%] [G loss: 0.309356]\n",
      "epoch:4 step:3931 [D loss: 0.240604, acc.: 60.16%] [G loss: 0.297537]\n",
      "epoch:4 step:3932 [D loss: 0.267504, acc.: 48.44%] [G loss: 0.299304]\n",
      "epoch:4 step:3933 [D loss: 0.258790, acc.: 50.78%] [G loss: 0.306796]\n",
      "epoch:4 step:3934 [D loss: 0.245824, acc.: 57.81%] [G loss: 0.268221]\n",
      "epoch:4 step:3935 [D loss: 0.242852, acc.: 59.38%] [G loss: 0.313154]\n",
      "epoch:4 step:3936 [D loss: 0.229559, acc.: 64.06%] [G loss: 0.339049]\n",
      "epoch:4 step:3937 [D loss: 0.253482, acc.: 54.69%] [G loss: 0.291076]\n",
      "epoch:4 step:3938 [D loss: 0.240727, acc.: 60.16%] [G loss: 0.324397]\n",
      "epoch:4 step:3939 [D loss: 0.236289, acc.: 58.59%] [G loss: 0.304746]\n",
      "epoch:4 step:3940 [D loss: 0.247461, acc.: 57.03%] [G loss: 0.305062]\n",
      "epoch:4 step:3941 [D loss: 0.257119, acc.: 55.47%] [G loss: 0.318957]\n",
      "epoch:4 step:3942 [D loss: 0.250056, acc.: 53.12%] [G loss: 0.303360]\n",
      "epoch:4 step:3943 [D loss: 0.253614, acc.: 55.47%] [G loss: 0.298393]\n",
      "epoch:4 step:3944 [D loss: 0.237963, acc.: 53.91%] [G loss: 0.319600]\n",
      "epoch:4 step:3945 [D loss: 0.242911, acc.: 57.81%] [G loss: 0.311273]\n",
      "epoch:4 step:3946 [D loss: 0.233032, acc.: 63.28%] [G loss: 0.295242]\n",
      "epoch:4 step:3947 [D loss: 0.248143, acc.: 55.47%] [G loss: 0.297800]\n",
      "epoch:4 step:3948 [D loss: 0.240546, acc.: 62.50%] [G loss: 0.315299]\n",
      "epoch:4 step:3949 [D loss: 0.242955, acc.: 51.56%] [G loss: 0.293326]\n",
      "epoch:4 step:3950 [D loss: 0.220817, acc.: 63.28%] [G loss: 0.289705]\n",
      "epoch:4 step:3951 [D loss: 0.229368, acc.: 60.94%] [G loss: 0.328275]\n",
      "epoch:4 step:3952 [D loss: 0.227817, acc.: 60.16%] [G loss: 0.303119]\n",
      "epoch:4 step:3953 [D loss: 0.251113, acc.: 52.34%] [G loss: 0.297164]\n",
      "epoch:4 step:3954 [D loss: 0.267161, acc.: 50.78%] [G loss: 0.282763]\n",
      "epoch:4 step:3955 [D loss: 0.240141, acc.: 62.50%] [G loss: 0.305364]\n",
      "epoch:4 step:3956 [D loss: 0.220033, acc.: 65.62%] [G loss: 0.291564]\n",
      "epoch:4 step:3957 [D loss: 0.271481, acc.: 48.44%] [G loss: 0.275060]\n",
      "epoch:4 step:3958 [D loss: 0.249818, acc.: 53.91%] [G loss: 0.327612]\n",
      "epoch:4 step:3959 [D loss: 0.225734, acc.: 70.31%] [G loss: 0.319425]\n",
      "epoch:4 step:3960 [D loss: 0.232990, acc.: 60.94%] [G loss: 0.308774]\n",
      "epoch:4 step:3961 [D loss: 0.241527, acc.: 56.25%] [G loss: 0.315496]\n",
      "epoch:4 step:3962 [D loss: 0.250624, acc.: 53.12%] [G loss: 0.281580]\n",
      "epoch:4 step:3963 [D loss: 0.246366, acc.: 53.91%] [G loss: 0.307659]\n",
      "epoch:4 step:3964 [D loss: 0.226354, acc.: 65.62%] [G loss: 0.295228]\n",
      "epoch:4 step:3965 [D loss: 0.249076, acc.: 57.81%] [G loss: 0.336691]\n",
      "epoch:4 step:3966 [D loss: 0.257958, acc.: 53.91%] [G loss: 0.350598]\n",
      "epoch:4 step:3967 [D loss: 0.257487, acc.: 50.78%] [G loss: 0.305295]\n",
      "epoch:4 step:3968 [D loss: 0.242452, acc.: 58.59%] [G loss: 0.295796]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:4 step:3969 [D loss: 0.233780, acc.: 60.16%] [G loss: 0.297341]\n",
      "epoch:4 step:3970 [D loss: 0.235041, acc.: 60.16%] [G loss: 0.301727]\n",
      "epoch:4 step:3971 [D loss: 0.265198, acc.: 49.22%] [G loss: 0.293793]\n",
      "epoch:4 step:3972 [D loss: 0.221987, acc.: 67.97%] [G loss: 0.323180]\n",
      "epoch:4 step:3973 [D loss: 0.231801, acc.: 58.59%] [G loss: 0.310882]\n",
      "epoch:4 step:3974 [D loss: 0.241865, acc.: 62.50%] [G loss: 0.284545]\n",
      "epoch:4 step:3975 [D loss: 0.230149, acc.: 61.72%] [G loss: 0.304133]\n",
      "epoch:4 step:3976 [D loss: 0.244545, acc.: 57.81%] [G loss: 0.315631]\n",
      "epoch:4 step:3977 [D loss: 0.257816, acc.: 50.78%] [G loss: 0.261744]\n",
      "epoch:4 step:3978 [D loss: 0.233136, acc.: 58.59%] [G loss: 0.281333]\n",
      "epoch:4 step:3979 [D loss: 0.237548, acc.: 60.16%] [G loss: 0.314562]\n",
      "epoch:4 step:3980 [D loss: 0.264796, acc.: 48.44%] [G loss: 0.300589]\n",
      "epoch:4 step:3981 [D loss: 0.232965, acc.: 64.06%] [G loss: 0.341030]\n",
      "epoch:4 step:3982 [D loss: 0.243302, acc.: 56.25%] [G loss: 0.331394]\n",
      "epoch:4 step:3983 [D loss: 0.246583, acc.: 56.25%] [G loss: 0.321480]\n",
      "epoch:4 step:3984 [D loss: 0.225985, acc.: 58.59%] [G loss: 0.322024]\n",
      "epoch:4 step:3985 [D loss: 0.226797, acc.: 62.50%] [G loss: 0.282638]\n",
      "epoch:4 step:3986 [D loss: 0.239022, acc.: 58.59%] [G loss: 0.291314]\n",
      "epoch:4 step:3987 [D loss: 0.231430, acc.: 58.59%] [G loss: 0.291580]\n",
      "epoch:4 step:3988 [D loss: 0.247310, acc.: 56.25%] [G loss: 0.271220]\n",
      "epoch:4 step:3989 [D loss: 0.256434, acc.: 49.22%] [G loss: 0.312860]\n",
      "epoch:4 step:3990 [D loss: 0.262363, acc.: 46.09%] [G loss: 0.296285]\n",
      "epoch:4 step:3991 [D loss: 0.251382, acc.: 56.25%] [G loss: 0.316217]\n",
      "epoch:4 step:3992 [D loss: 0.236350, acc.: 60.94%] [G loss: 0.289805]\n",
      "epoch:4 step:3993 [D loss: 0.238798, acc.: 57.81%] [G loss: 0.271586]\n",
      "epoch:4 step:3994 [D loss: 0.250137, acc.: 55.47%] [G loss: 0.284158]\n",
      "epoch:4 step:3995 [D loss: 0.245000, acc.: 54.69%] [G loss: 0.322682]\n",
      "epoch:4 step:3996 [D loss: 0.249424, acc.: 53.91%] [G loss: 0.300160]\n",
      "epoch:4 step:3997 [D loss: 0.254806, acc.: 50.78%] [G loss: 0.303460]\n",
      "epoch:4 step:3998 [D loss: 0.257998, acc.: 53.12%] [G loss: 0.304378]\n",
      "epoch:4 step:3999 [D loss: 0.229269, acc.: 58.59%] [G loss: 0.270838]\n",
      "epoch:4 step:4000 [D loss: 0.218390, acc.: 71.09%] [G loss: 0.332381]\n",
      "epoch:4 step:4001 [D loss: 0.233340, acc.: 60.16%] [G loss: 0.314540]\n",
      "epoch:4 step:4002 [D loss: 0.261123, acc.: 53.12%] [G loss: 0.284760]\n",
      "epoch:4 step:4003 [D loss: 0.247980, acc.: 51.56%] [G loss: 0.285146]\n",
      "epoch:4 step:4004 [D loss: 0.242905, acc.: 58.59%] [G loss: 0.292348]\n",
      "epoch:4 step:4005 [D loss: 0.231845, acc.: 60.94%] [G loss: 0.283907]\n",
      "epoch:4 step:4006 [D loss: 0.241338, acc.: 61.72%] [G loss: 0.292016]\n",
      "epoch:4 step:4007 [D loss: 0.241684, acc.: 56.25%] [G loss: 0.293295]\n",
      "epoch:4 step:4008 [D loss: 0.236868, acc.: 60.16%] [G loss: 0.323293]\n",
      "epoch:4 step:4009 [D loss: 0.242577, acc.: 55.47%] [G loss: 0.324764]\n",
      "epoch:4 step:4010 [D loss: 0.257014, acc.: 54.69%] [G loss: 0.308169]\n",
      "epoch:4 step:4011 [D loss: 0.255888, acc.: 52.34%] [G loss: 0.323564]\n",
      "epoch:4 step:4012 [D loss: 0.239658, acc.: 61.72%] [G loss: 0.305321]\n",
      "epoch:4 step:4013 [D loss: 0.240707, acc.: 58.59%] [G loss: 0.287328]\n",
      "epoch:4 step:4014 [D loss: 0.275625, acc.: 50.78%] [G loss: 0.282233]\n",
      "epoch:4 step:4015 [D loss: 0.244965, acc.: 55.47%] [G loss: 0.280121]\n",
      "epoch:4 step:4016 [D loss: 0.226068, acc.: 64.06%] [G loss: 0.360708]\n",
      "epoch:4 step:4017 [D loss: 0.238875, acc.: 60.16%] [G loss: 0.303324]\n",
      "epoch:4 step:4018 [D loss: 0.225852, acc.: 66.41%] [G loss: 0.315502]\n",
      "epoch:4 step:4019 [D loss: 0.243360, acc.: 57.03%] [G loss: 0.283150]\n",
      "epoch:4 step:4020 [D loss: 0.249249, acc.: 53.12%] [G loss: 0.308376]\n",
      "epoch:4 step:4021 [D loss: 0.245961, acc.: 52.34%] [G loss: 0.311878]\n",
      "epoch:4 step:4022 [D loss: 0.251892, acc.: 53.12%] [G loss: 0.319023]\n",
      "epoch:4 step:4023 [D loss: 0.249235, acc.: 56.25%] [G loss: 0.328682]\n",
      "epoch:4 step:4024 [D loss: 0.266833, acc.: 55.47%] [G loss: 0.295937]\n",
      "epoch:4 step:4025 [D loss: 0.233901, acc.: 61.72%] [G loss: 0.312225]\n",
      "epoch:4 step:4026 [D loss: 0.261727, acc.: 54.69%] [G loss: 0.302441]\n",
      "epoch:4 step:4027 [D loss: 0.241408, acc.: 59.38%] [G loss: 0.313747]\n",
      "epoch:4 step:4028 [D loss: 0.230922, acc.: 58.59%] [G loss: 0.310486]\n",
      "epoch:4 step:4029 [D loss: 0.250085, acc.: 61.72%] [G loss: 0.327958]\n",
      "epoch:4 step:4030 [D loss: 0.248468, acc.: 56.25%] [G loss: 0.295220]\n",
      "epoch:4 step:4031 [D loss: 0.244011, acc.: 57.03%] [G loss: 0.287689]\n",
      "epoch:4 step:4032 [D loss: 0.241637, acc.: 57.81%] [G loss: 0.305479]\n",
      "epoch:4 step:4033 [D loss: 0.219620, acc.: 60.94%] [G loss: 0.321435]\n",
      "epoch:4 step:4034 [D loss: 0.232148, acc.: 63.28%] [G loss: 0.294152]\n",
      "epoch:4 step:4035 [D loss: 0.225007, acc.: 63.28%] [G loss: 0.284269]\n",
      "epoch:4 step:4036 [D loss: 0.234579, acc.: 53.12%] [G loss: 0.331420]\n",
      "epoch:4 step:4037 [D loss: 0.256332, acc.: 51.56%] [G loss: 0.300061]\n",
      "epoch:4 step:4038 [D loss: 0.236384, acc.: 57.81%] [G loss: 0.301710]\n",
      "epoch:4 step:4039 [D loss: 0.235507, acc.: 57.81%] [G loss: 0.356101]\n",
      "epoch:4 step:4040 [D loss: 0.251019, acc.: 57.03%] [G loss: 0.307211]\n",
      "epoch:4 step:4041 [D loss: 0.256285, acc.: 51.56%] [G loss: 0.289830]\n",
      "epoch:4 step:4042 [D loss: 0.239038, acc.: 57.81%] [G loss: 0.310573]\n",
      "epoch:4 step:4043 [D loss: 0.245983, acc.: 52.34%] [G loss: 0.310596]\n",
      "epoch:4 step:4044 [D loss: 0.235752, acc.: 57.03%] [G loss: 0.309577]\n",
      "epoch:4 step:4045 [D loss: 0.251391, acc.: 53.91%] [G loss: 0.287174]\n",
      "epoch:4 step:4046 [D loss: 0.253456, acc.: 57.03%] [G loss: 0.299289]\n",
      "epoch:4 step:4047 [D loss: 0.254741, acc.: 53.12%] [G loss: 0.303970]\n",
      "epoch:4 step:4048 [D loss: 0.245622, acc.: 53.91%] [G loss: 0.322508]\n",
      "epoch:4 step:4049 [D loss: 0.248630, acc.: 53.12%] [G loss: 0.317884]\n",
      "epoch:4 step:4050 [D loss: 0.220285, acc.: 61.72%] [G loss: 0.319739]\n",
      "epoch:4 step:4051 [D loss: 0.247740, acc.: 54.69%] [G loss: 0.318222]\n",
      "epoch:4 step:4052 [D loss: 0.244789, acc.: 53.91%] [G loss: 0.321994]\n",
      "epoch:4 step:4053 [D loss: 0.239705, acc.: 60.94%] [G loss: 0.327840]\n",
      "epoch:4 step:4054 [D loss: 0.234771, acc.: 57.81%] [G loss: 0.318922]\n",
      "epoch:4 step:4055 [D loss: 0.238690, acc.: 60.94%] [G loss: 0.317965]\n",
      "epoch:4 step:4056 [D loss: 0.233615, acc.: 57.81%] [G loss: 0.348419]\n",
      "epoch:4 step:4057 [D loss: 0.234508, acc.: 57.81%] [G loss: 0.323661]\n",
      "epoch:4 step:4058 [D loss: 0.260578, acc.: 49.22%] [G loss: 0.310444]\n",
      "epoch:4 step:4059 [D loss: 0.262633, acc.: 51.56%] [G loss: 0.312513]\n",
      "epoch:4 step:4060 [D loss: 0.252931, acc.: 56.25%] [G loss: 0.331113]\n",
      "epoch:4 step:4061 [D loss: 0.237839, acc.: 57.03%] [G loss: 0.319723]\n",
      "epoch:4 step:4062 [D loss: 0.248952, acc.: 53.91%] [G loss: 0.299473]\n",
      "epoch:4 step:4063 [D loss: 0.230980, acc.: 61.72%] [G loss: 0.310240]\n",
      "epoch:4 step:4064 [D loss: 0.257826, acc.: 54.69%] [G loss: 0.299073]\n",
      "epoch:4 step:4065 [D loss: 0.241863, acc.: 60.16%] [G loss: 0.310960]\n",
      "epoch:4 step:4066 [D loss: 0.246752, acc.: 60.94%] [G loss: 0.307113]\n",
      "epoch:4 step:4067 [D loss: 0.247970, acc.: 51.56%] [G loss: 0.326166]\n",
      "epoch:4 step:4068 [D loss: 0.250653, acc.: 50.78%] [G loss: 0.300933]\n",
      "epoch:4 step:4069 [D loss: 0.265691, acc.: 53.91%] [G loss: 0.316997]\n",
      "epoch:4 step:4070 [D loss: 0.248207, acc.: 57.03%] [G loss: 0.317038]\n",
      "epoch:4 step:4071 [D loss: 0.268935, acc.: 46.09%] [G loss: 0.284800]\n",
      "epoch:4 step:4072 [D loss: 0.247717, acc.: 54.69%] [G loss: 0.293386]\n",
      "epoch:4 step:4073 [D loss: 0.250311, acc.: 53.91%] [G loss: 0.337108]\n",
      "epoch:4 step:4074 [D loss: 0.249852, acc.: 54.69%] [G loss: 0.313009]\n",
      "epoch:4 step:4075 [D loss: 0.241675, acc.: 59.38%] [G loss: 0.301522]\n",
      "epoch:4 step:4076 [D loss: 0.225979, acc.: 64.06%] [G loss: 0.323430]\n",
      "epoch:4 step:4077 [D loss: 0.258204, acc.: 50.00%] [G loss: 0.287821]\n",
      "epoch:4 step:4078 [D loss: 0.260287, acc.: 53.12%] [G loss: 0.255595]\n",
      "epoch:4 step:4079 [D loss: 0.227582, acc.: 64.84%] [G loss: 0.334882]\n",
      "epoch:4 step:4080 [D loss: 0.232615, acc.: 60.16%] [G loss: 0.317146]\n",
      "epoch:4 step:4081 [D loss: 0.257294, acc.: 47.66%] [G loss: 0.318897]\n",
      "epoch:4 step:4082 [D loss: 0.244816, acc.: 60.16%] [G loss: 0.288017]\n",
      "epoch:4 step:4083 [D loss: 0.255107, acc.: 57.03%] [G loss: 0.317841]\n",
      "epoch:4 step:4084 [D loss: 0.220605, acc.: 62.50%] [G loss: 0.288011]\n",
      "epoch:4 step:4085 [D loss: 0.238285, acc.: 56.25%] [G loss: 0.290389]\n",
      "epoch:4 step:4086 [D loss: 0.240872, acc.: 55.47%] [G loss: 0.306961]\n",
      "epoch:4 step:4087 [D loss: 0.258151, acc.: 52.34%] [G loss: 0.293025]\n",
      "epoch:4 step:4088 [D loss: 0.228725, acc.: 65.62%] [G loss: 0.307067]\n",
      "epoch:4 step:4089 [D loss: 0.251923, acc.: 53.12%] [G loss: 0.313585]\n",
      "epoch:4 step:4090 [D loss: 0.240479, acc.: 59.38%] [G loss: 0.315506]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:4 step:4091 [D loss: 0.245954, acc.: 55.47%] [G loss: 0.321564]\n",
      "epoch:4 step:4092 [D loss: 0.230567, acc.: 63.28%] [G loss: 0.306302]\n",
      "epoch:4 step:4093 [D loss: 0.256928, acc.: 51.56%] [G loss: 0.302868]\n",
      "epoch:4 step:4094 [D loss: 0.230204, acc.: 61.72%] [G loss: 0.285633]\n",
      "epoch:4 step:4095 [D loss: 0.240128, acc.: 53.91%] [G loss: 0.313232]\n",
      "epoch:4 step:4096 [D loss: 0.237205, acc.: 57.81%] [G loss: 0.316449]\n",
      "epoch:4 step:4097 [D loss: 0.240514, acc.: 56.25%] [G loss: 0.328444]\n",
      "epoch:4 step:4098 [D loss: 0.234106, acc.: 56.25%] [G loss: 0.299291]\n",
      "epoch:4 step:4099 [D loss: 0.247599, acc.: 55.47%] [G loss: 0.323789]\n",
      "epoch:4 step:4100 [D loss: 0.258669, acc.: 53.12%] [G loss: 0.324427]\n",
      "epoch:4 step:4101 [D loss: 0.249774, acc.: 54.69%] [G loss: 0.315562]\n",
      "epoch:4 step:4102 [D loss: 0.245325, acc.: 57.03%] [G loss: 0.329239]\n",
      "epoch:4 step:4103 [D loss: 0.260938, acc.: 51.56%] [G loss: 0.302318]\n",
      "epoch:4 step:4104 [D loss: 0.237782, acc.: 58.59%] [G loss: 0.297162]\n",
      "epoch:4 step:4105 [D loss: 0.254340, acc.: 51.56%] [G loss: 0.318398]\n",
      "epoch:4 step:4106 [D loss: 0.222064, acc.: 67.97%] [G loss: 0.300675]\n",
      "epoch:4 step:4107 [D loss: 0.244332, acc.: 52.34%] [G loss: 0.281544]\n",
      "epoch:4 step:4108 [D loss: 0.225042, acc.: 64.06%] [G loss: 0.319832]\n",
      "epoch:4 step:4109 [D loss: 0.229658, acc.: 64.84%] [G loss: 0.328316]\n",
      "epoch:4 step:4110 [D loss: 0.262891, acc.: 50.00%] [G loss: 0.309227]\n",
      "epoch:4 step:4111 [D loss: 0.242853, acc.: 59.38%] [G loss: 0.317435]\n",
      "epoch:4 step:4112 [D loss: 0.238746, acc.: 57.81%] [G loss: 0.305265]\n",
      "epoch:4 step:4113 [D loss: 0.240131, acc.: 57.03%] [G loss: 0.313160]\n",
      "epoch:4 step:4114 [D loss: 0.229533, acc.: 60.94%] [G loss: 0.308040]\n",
      "epoch:4 step:4115 [D loss: 0.241146, acc.: 58.59%] [G loss: 0.337688]\n",
      "epoch:4 step:4116 [D loss: 0.267916, acc.: 50.78%] [G loss: 0.283565]\n",
      "epoch:4 step:4117 [D loss: 0.247953, acc.: 57.03%] [G loss: 0.324737]\n",
      "epoch:4 step:4118 [D loss: 0.258782, acc.: 53.91%] [G loss: 0.316599]\n",
      "epoch:4 step:4119 [D loss: 0.230178, acc.: 57.03%] [G loss: 0.324197]\n",
      "epoch:4 step:4120 [D loss: 0.248947, acc.: 60.16%] [G loss: 0.316611]\n",
      "epoch:4 step:4121 [D loss: 0.247332, acc.: 55.47%] [G loss: 0.290803]\n",
      "epoch:4 step:4122 [D loss: 0.251925, acc.: 53.12%] [G loss: 0.340266]\n",
      "epoch:4 step:4123 [D loss: 0.256440, acc.: 50.78%] [G loss: 0.306117]\n",
      "epoch:4 step:4124 [D loss: 0.253312, acc.: 55.47%] [G loss: 0.308322]\n",
      "epoch:4 step:4125 [D loss: 0.252058, acc.: 53.91%] [G loss: 0.306955]\n",
      "epoch:4 step:4126 [D loss: 0.249942, acc.: 55.47%] [G loss: 0.316760]\n",
      "epoch:4 step:4127 [D loss: 0.266727, acc.: 52.34%] [G loss: 0.305427]\n",
      "epoch:4 step:4128 [D loss: 0.257313, acc.: 55.47%] [G loss: 0.313289]\n",
      "epoch:4 step:4129 [D loss: 0.227735, acc.: 60.94%] [G loss: 0.302486]\n",
      "epoch:4 step:4130 [D loss: 0.217201, acc.: 67.19%] [G loss: 0.305207]\n",
      "epoch:4 step:4131 [D loss: 0.256026, acc.: 53.12%] [G loss: 0.291322]\n",
      "epoch:4 step:4132 [D loss: 0.267589, acc.: 46.88%] [G loss: 0.327259]\n",
      "epoch:4 step:4133 [D loss: 0.229493, acc.: 64.84%] [G loss: 0.309397]\n",
      "epoch:4 step:4134 [D loss: 0.246615, acc.: 57.81%] [G loss: 0.304522]\n",
      "epoch:4 step:4135 [D loss: 0.239206, acc.: 62.50%] [G loss: 0.315740]\n",
      "epoch:4 step:4136 [D loss: 0.245168, acc.: 60.16%] [G loss: 0.310346]\n",
      "epoch:4 step:4137 [D loss: 0.235156, acc.: 62.50%] [G loss: 0.310575]\n",
      "epoch:4 step:4138 [D loss: 0.224939, acc.: 60.94%] [G loss: 0.317412]\n",
      "epoch:4 step:4139 [D loss: 0.233512, acc.: 64.84%] [G loss: 0.338383]\n",
      "epoch:4 step:4140 [D loss: 0.240904, acc.: 53.91%] [G loss: 0.277916]\n",
      "epoch:4 step:4141 [D loss: 0.258553, acc.: 52.34%] [G loss: 0.308163]\n",
      "epoch:4 step:4142 [D loss: 0.238042, acc.: 64.06%] [G loss: 0.328183]\n",
      "epoch:4 step:4143 [D loss: 0.232530, acc.: 58.59%] [G loss: 0.307014]\n",
      "epoch:4 step:4144 [D loss: 0.224844, acc.: 67.19%] [G loss: 0.315617]\n",
      "epoch:4 step:4145 [D loss: 0.252260, acc.: 60.94%] [G loss: 0.328979]\n",
      "epoch:4 step:4146 [D loss: 0.269641, acc.: 47.66%] [G loss: 0.307207]\n",
      "epoch:4 step:4147 [D loss: 0.227950, acc.: 57.81%] [G loss: 0.316537]\n",
      "epoch:4 step:4148 [D loss: 0.224971, acc.: 60.16%] [G loss: 0.348661]\n",
      "epoch:4 step:4149 [D loss: 0.239511, acc.: 61.72%] [G loss: 0.309779]\n",
      "epoch:4 step:4150 [D loss: 0.244043, acc.: 57.03%] [G loss: 0.342743]\n",
      "epoch:4 step:4151 [D loss: 0.224970, acc.: 61.72%] [G loss: 0.294884]\n",
      "epoch:4 step:4152 [D loss: 0.242934, acc.: 53.12%] [G loss: 0.298913]\n",
      "epoch:4 step:4153 [D loss: 0.254217, acc.: 53.91%] [G loss: 0.313363]\n",
      "epoch:4 step:4154 [D loss: 0.230339, acc.: 61.72%] [G loss: 0.346305]\n",
      "epoch:4 step:4155 [D loss: 0.251233, acc.: 53.91%] [G loss: 0.327313]\n",
      "epoch:4 step:4156 [D loss: 0.229001, acc.: 62.50%] [G loss: 0.296501]\n",
      "epoch:4 step:4157 [D loss: 0.243608, acc.: 57.03%] [G loss: 0.296384]\n",
      "epoch:4 step:4158 [D loss: 0.248363, acc.: 55.47%] [G loss: 0.335152]\n",
      "epoch:4 step:4159 [D loss: 0.252810, acc.: 55.47%] [G loss: 0.307275]\n",
      "epoch:4 step:4160 [D loss: 0.231947, acc.: 60.94%] [G loss: 0.290861]\n",
      "epoch:4 step:4161 [D loss: 0.263054, acc.: 53.91%] [G loss: 0.302406]\n",
      "epoch:4 step:4162 [D loss: 0.249731, acc.: 58.59%] [G loss: 0.295044]\n",
      "epoch:4 step:4163 [D loss: 0.240371, acc.: 60.94%] [G loss: 0.302053]\n",
      "epoch:4 step:4164 [D loss: 0.239221, acc.: 60.94%] [G loss: 0.296340]\n",
      "epoch:4 step:4165 [D loss: 0.259851, acc.: 53.12%] [G loss: 0.318996]\n",
      "epoch:4 step:4166 [D loss: 0.246432, acc.: 58.59%] [G loss: 0.318868]\n",
      "epoch:4 step:4167 [D loss: 0.244556, acc.: 60.16%] [G loss: 0.320636]\n",
      "epoch:4 step:4168 [D loss: 0.229039, acc.: 60.16%] [G loss: 0.280481]\n",
      "epoch:4 step:4169 [D loss: 0.237207, acc.: 56.25%] [G loss: 0.298800]\n",
      "epoch:4 step:4170 [D loss: 0.227278, acc.: 64.06%] [G loss: 0.338342]\n",
      "epoch:4 step:4171 [D loss: 0.246401, acc.: 54.69%] [G loss: 0.277981]\n",
      "epoch:4 step:4172 [D loss: 0.228528, acc.: 62.50%] [G loss: 0.311414]\n",
      "epoch:4 step:4173 [D loss: 0.247257, acc.: 54.69%] [G loss: 0.307892]\n",
      "epoch:4 step:4174 [D loss: 0.247949, acc.: 56.25%] [G loss: 0.328687]\n",
      "epoch:4 step:4175 [D loss: 0.260931, acc.: 50.00%] [G loss: 0.287227]\n",
      "epoch:4 step:4176 [D loss: 0.249886, acc.: 55.47%] [G loss: 0.306363]\n",
      "epoch:4 step:4177 [D loss: 0.255462, acc.: 50.78%] [G loss: 0.334839]\n",
      "epoch:4 step:4178 [D loss: 0.255872, acc.: 53.12%] [G loss: 0.283945]\n",
      "epoch:4 step:4179 [D loss: 0.252379, acc.: 53.12%] [G loss: 0.310658]\n",
      "epoch:4 step:4180 [D loss: 0.241650, acc.: 61.72%] [G loss: 0.302113]\n",
      "epoch:4 step:4181 [D loss: 0.235921, acc.: 58.59%] [G loss: 0.330263]\n",
      "epoch:4 step:4182 [D loss: 0.264379, acc.: 49.22%] [G loss: 0.306062]\n",
      "epoch:4 step:4183 [D loss: 0.251710, acc.: 55.47%] [G loss: 0.310062]\n",
      "epoch:4 step:4184 [D loss: 0.237932, acc.: 57.81%] [G loss: 0.306193]\n",
      "epoch:4 step:4185 [D loss: 0.255694, acc.: 56.25%] [G loss: 0.278337]\n",
      "epoch:4 step:4186 [D loss: 0.243754, acc.: 57.03%] [G loss: 0.317418]\n",
      "epoch:4 step:4187 [D loss: 0.250514, acc.: 53.12%] [G loss: 0.304660]\n",
      "epoch:4 step:4188 [D loss: 0.238643, acc.: 60.16%] [G loss: 0.290896]\n",
      "epoch:4 step:4189 [D loss: 0.245323, acc.: 54.69%] [G loss: 0.329664]\n",
      "epoch:4 step:4190 [D loss: 0.244368, acc.: 59.38%] [G loss: 0.284531]\n",
      "epoch:4 step:4191 [D loss: 0.233815, acc.: 56.25%] [G loss: 0.280951]\n",
      "epoch:4 step:4192 [D loss: 0.254457, acc.: 54.69%] [G loss: 0.279647]\n",
      "epoch:4 step:4193 [D loss: 0.242635, acc.: 57.03%] [G loss: 0.282149]\n",
      "epoch:4 step:4194 [D loss: 0.247247, acc.: 57.03%] [G loss: 0.328559]\n",
      "epoch:4 step:4195 [D loss: 0.226481, acc.: 64.06%] [G loss: 0.291991]\n",
      "epoch:4 step:4196 [D loss: 0.246088, acc.: 56.25%] [G loss: 0.302430]\n",
      "epoch:4 step:4197 [D loss: 0.251352, acc.: 55.47%] [G loss: 0.295600]\n",
      "epoch:4 step:4198 [D loss: 0.243975, acc.: 57.03%] [G loss: 0.290372]\n",
      "epoch:4 step:4199 [D loss: 0.241858, acc.: 56.25%] [G loss: 0.313756]\n",
      "epoch:4 step:4200 [D loss: 0.244493, acc.: 53.91%] [G loss: 0.309160]\n",
      "epoch:4 step:4201 [D loss: 0.237114, acc.: 59.38%] [G loss: 0.307157]\n",
      "epoch:4 step:4202 [D loss: 0.248589, acc.: 53.12%] [G loss: 0.298447]\n",
      "epoch:4 step:4203 [D loss: 0.231382, acc.: 60.94%] [G loss: 0.317866]\n",
      "epoch:4 step:4204 [D loss: 0.249954, acc.: 53.12%] [G loss: 0.292859]\n",
      "epoch:4 step:4205 [D loss: 0.246499, acc.: 52.34%] [G loss: 0.307675]\n",
      "epoch:4 step:4206 [D loss: 0.235098, acc.: 60.16%] [G loss: 0.309835]\n",
      "epoch:4 step:4207 [D loss: 0.237638, acc.: 57.81%] [G loss: 0.310036]\n",
      "epoch:4 step:4208 [D loss: 0.242284, acc.: 54.69%] [G loss: 0.316311]\n",
      "epoch:4 step:4209 [D loss: 0.235528, acc.: 59.38%] [G loss: 0.323067]\n",
      "epoch:4 step:4210 [D loss: 0.249146, acc.: 53.12%] [G loss: 0.316962]\n",
      "epoch:4 step:4211 [D loss: 0.242707, acc.: 57.81%] [G loss: 0.305826]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:4 step:4212 [D loss: 0.234273, acc.: 53.91%] [G loss: 0.303203]\n",
      "epoch:4 step:4213 [D loss: 0.249732, acc.: 54.69%] [G loss: 0.295838]\n",
      "epoch:4 step:4214 [D loss: 0.246014, acc.: 57.81%] [G loss: 0.309777]\n",
      "epoch:4 step:4215 [D loss: 0.258150, acc.: 55.47%] [G loss: 0.319249]\n",
      "epoch:4 step:4216 [D loss: 0.238397, acc.: 60.94%] [G loss: 0.304087]\n",
      "epoch:4 step:4217 [D loss: 0.249535, acc.: 52.34%] [G loss: 0.324958]\n",
      "epoch:4 step:4218 [D loss: 0.264127, acc.: 51.56%] [G loss: 0.311147]\n",
      "epoch:4 step:4219 [D loss: 0.233495, acc.: 60.16%] [G loss: 0.302186]\n",
      "epoch:4 step:4220 [D loss: 0.254866, acc.: 60.16%] [G loss: 0.319730]\n",
      "epoch:4 step:4221 [D loss: 0.253125, acc.: 52.34%] [G loss: 0.292890]\n",
      "epoch:4 step:4222 [D loss: 0.250875, acc.: 58.59%] [G loss: 0.320756]\n",
      "epoch:4 step:4223 [D loss: 0.233462, acc.: 61.72%] [G loss: 0.284865]\n",
      "epoch:4 step:4224 [D loss: 0.266670, acc.: 44.53%] [G loss: 0.291370]\n",
      "epoch:4 step:4225 [D loss: 0.258367, acc.: 46.88%] [G loss: 0.298531]\n",
      "epoch:4 step:4226 [D loss: 0.240845, acc.: 57.03%] [G loss: 0.326357]\n",
      "epoch:4 step:4227 [D loss: 0.229454, acc.: 62.50%] [G loss: 0.318791]\n",
      "epoch:4 step:4228 [D loss: 0.234274, acc.: 58.59%] [G loss: 0.310864]\n",
      "epoch:4 step:4229 [D loss: 0.257054, acc.: 51.56%] [G loss: 0.310154]\n",
      "epoch:4 step:4230 [D loss: 0.234329, acc.: 60.16%] [G loss: 0.339237]\n",
      "epoch:4 step:4231 [D loss: 0.255054, acc.: 53.91%] [G loss: 0.355967]\n",
      "epoch:4 step:4232 [D loss: 0.246343, acc.: 51.56%] [G loss: 0.298406]\n",
      "epoch:4 step:4233 [D loss: 0.242798, acc.: 56.25%] [G loss: 0.307914]\n",
      "epoch:4 step:4234 [D loss: 0.234152, acc.: 65.62%] [G loss: 0.292129]\n",
      "epoch:4 step:4235 [D loss: 0.240937, acc.: 58.59%] [G loss: 0.334378]\n",
      "epoch:4 step:4236 [D loss: 0.238015, acc.: 59.38%] [G loss: 0.322770]\n",
      "epoch:4 step:4237 [D loss: 0.268313, acc.: 49.22%] [G loss: 0.313989]\n",
      "epoch:4 step:4238 [D loss: 0.235401, acc.: 57.81%] [G loss: 0.338248]\n",
      "epoch:4 step:4239 [D loss: 0.246619, acc.: 57.03%] [G loss: 0.299523]\n",
      "epoch:4 step:4240 [D loss: 0.255918, acc.: 52.34%] [G loss: 0.304795]\n",
      "epoch:4 step:4241 [D loss: 0.248306, acc.: 57.03%] [G loss: 0.290314]\n",
      "epoch:4 step:4242 [D loss: 0.243710, acc.: 57.81%] [G loss: 0.315816]\n",
      "epoch:4 step:4243 [D loss: 0.269633, acc.: 46.09%] [G loss: 0.314578]\n",
      "epoch:4 step:4244 [D loss: 0.245987, acc.: 53.12%] [G loss: 0.306742]\n",
      "epoch:4 step:4245 [D loss: 0.257050, acc.: 48.44%] [G loss: 0.309650]\n",
      "epoch:4 step:4246 [D loss: 0.234523, acc.: 58.59%] [G loss: 0.336838]\n",
      "epoch:4 step:4247 [D loss: 0.220483, acc.: 66.41%] [G loss: 0.301698]\n",
      "epoch:4 step:4248 [D loss: 0.245145, acc.: 53.12%] [G loss: 0.316171]\n",
      "epoch:4 step:4249 [D loss: 0.241721, acc.: 60.16%] [G loss: 0.304555]\n",
      "epoch:4 step:4250 [D loss: 0.253530, acc.: 54.69%] [G loss: 0.293787]\n",
      "epoch:4 step:4251 [D loss: 0.249800, acc.: 54.69%] [G loss: 0.311808]\n",
      "epoch:4 step:4252 [D loss: 0.247925, acc.: 54.69%] [G loss: 0.316043]\n",
      "epoch:4 step:4253 [D loss: 0.248137, acc.: 55.47%] [G loss: 0.292758]\n",
      "epoch:4 step:4254 [D loss: 0.246450, acc.: 54.69%] [G loss: 0.325176]\n",
      "epoch:4 step:4255 [D loss: 0.249315, acc.: 55.47%] [G loss: 0.317463]\n",
      "epoch:4 step:4256 [D loss: 0.219532, acc.: 64.06%] [G loss: 0.342885]\n",
      "epoch:4 step:4257 [D loss: 0.240831, acc.: 60.16%] [G loss: 0.343499]\n",
      "epoch:4 step:4258 [D loss: 0.234914, acc.: 56.25%] [G loss: 0.323687]\n",
      "epoch:4 step:4259 [D loss: 0.254033, acc.: 57.81%] [G loss: 0.296252]\n",
      "epoch:4 step:4260 [D loss: 0.248961, acc.: 57.81%] [G loss: 0.291697]\n",
      "epoch:4 step:4261 [D loss: 0.255010, acc.: 51.56%] [G loss: 0.305952]\n",
      "epoch:4 step:4262 [D loss: 0.229125, acc.: 62.50%] [G loss: 0.312163]\n",
      "epoch:4 step:4263 [D loss: 0.247872, acc.: 60.16%] [G loss: 0.310243]\n",
      "epoch:4 step:4264 [D loss: 0.255119, acc.: 55.47%] [G loss: 0.278597]\n",
      "epoch:4 step:4265 [D loss: 0.222094, acc.: 66.41%] [G loss: 0.314870]\n",
      "epoch:4 step:4266 [D loss: 0.236370, acc.: 60.94%] [G loss: 0.319009]\n",
      "epoch:4 step:4267 [D loss: 0.243404, acc.: 60.94%] [G loss: 0.313602]\n",
      "epoch:4 step:4268 [D loss: 0.232097, acc.: 67.19%] [G loss: 0.346385]\n",
      "epoch:4 step:4269 [D loss: 0.241662, acc.: 53.91%] [G loss: 0.294547]\n",
      "epoch:4 step:4270 [D loss: 0.238935, acc.: 60.16%] [G loss: 0.312885]\n",
      "epoch:4 step:4271 [D loss: 0.221150, acc.: 67.97%] [G loss: 0.314377]\n",
      "epoch:4 step:4272 [D loss: 0.245612, acc.: 54.69%] [G loss: 0.292511]\n",
      "epoch:4 step:4273 [D loss: 0.232444, acc.: 61.72%] [G loss: 0.311068]\n",
      "epoch:4 step:4274 [D loss: 0.256558, acc.: 50.78%] [G loss: 0.316541]\n",
      "epoch:4 step:4275 [D loss: 0.248452, acc.: 55.47%] [G loss: 0.297381]\n",
      "epoch:4 step:4276 [D loss: 0.251312, acc.: 60.16%] [G loss: 0.290023]\n",
      "epoch:4 step:4277 [D loss: 0.234701, acc.: 56.25%] [G loss: 0.320181]\n",
      "epoch:4 step:4278 [D loss: 0.235874, acc.: 60.16%] [G loss: 0.327295]\n",
      "epoch:4 step:4279 [D loss: 0.245886, acc.: 52.34%] [G loss: 0.279774]\n",
      "epoch:4 step:4280 [D loss: 0.262525, acc.: 51.56%] [G loss: 0.306703]\n",
      "epoch:4 step:4281 [D loss: 0.254290, acc.: 50.78%] [G loss: 0.305834]\n",
      "epoch:4 step:4282 [D loss: 0.241704, acc.: 56.25%] [G loss: 0.266115]\n",
      "epoch:4 step:4283 [D loss: 0.241019, acc.: 60.94%] [G loss: 0.286078]\n",
      "epoch:4 step:4284 [D loss: 0.254100, acc.: 53.91%] [G loss: 0.300483]\n",
      "epoch:4 step:4285 [D loss: 0.280322, acc.: 42.97%] [G loss: 0.289246]\n",
      "epoch:4 step:4286 [D loss: 0.250143, acc.: 54.69%] [G loss: 0.313096]\n",
      "epoch:4 step:4287 [D loss: 0.247401, acc.: 53.91%] [G loss: 0.298799]\n",
      "epoch:4 step:4288 [D loss: 0.243370, acc.: 56.25%] [G loss: 0.321293]\n",
      "epoch:4 step:4289 [D loss: 0.220321, acc.: 67.19%] [G loss: 0.303939]\n",
      "epoch:4 step:4290 [D loss: 0.252082, acc.: 53.12%] [G loss: 0.284772]\n",
      "epoch:4 step:4291 [D loss: 0.230055, acc.: 60.94%] [G loss: 0.319352]\n",
      "epoch:4 step:4292 [D loss: 0.239464, acc.: 55.47%] [G loss: 0.303663]\n",
      "epoch:4 step:4293 [D loss: 0.244529, acc.: 57.81%] [G loss: 0.312427]\n",
      "epoch:4 step:4294 [D loss: 0.238062, acc.: 59.38%] [G loss: 0.328197]\n",
      "epoch:4 step:4295 [D loss: 0.252463, acc.: 56.25%] [G loss: 0.294177]\n",
      "epoch:4 step:4296 [D loss: 0.237805, acc.: 60.94%] [G loss: 0.315546]\n",
      "epoch:4 step:4297 [D loss: 0.243265, acc.: 57.03%] [G loss: 0.290117]\n",
      "epoch:4 step:4298 [D loss: 0.242545, acc.: 56.25%] [G loss: 0.291065]\n",
      "epoch:4 step:4299 [D loss: 0.231921, acc.: 60.16%] [G loss: 0.312423]\n",
      "epoch:4 step:4300 [D loss: 0.235428, acc.: 57.81%] [G loss: 0.283037]\n",
      "epoch:4 step:4301 [D loss: 0.236106, acc.: 53.12%] [G loss: 0.298373]\n",
      "epoch:4 step:4302 [D loss: 0.248266, acc.: 55.47%] [G loss: 0.297888]\n",
      "epoch:4 step:4303 [D loss: 0.257048, acc.: 48.44%] [G loss: 0.329599]\n",
      "epoch:4 step:4304 [D loss: 0.255603, acc.: 53.12%] [G loss: 0.307506]\n",
      "epoch:4 step:4305 [D loss: 0.238650, acc.: 60.16%] [G loss: 0.328925]\n",
      "epoch:4 step:4306 [D loss: 0.250945, acc.: 56.25%] [G loss: 0.301146]\n",
      "epoch:4 step:4307 [D loss: 0.224534, acc.: 64.06%] [G loss: 0.357239]\n",
      "epoch:4 step:4308 [D loss: 0.254739, acc.: 50.78%] [G loss: 0.303334]\n",
      "epoch:4 step:4309 [D loss: 0.253033, acc.: 52.34%] [G loss: 0.300386]\n",
      "epoch:4 step:4310 [D loss: 0.240447, acc.: 59.38%] [G loss: 0.329957]\n",
      "epoch:4 step:4311 [D loss: 0.248142, acc.: 59.38%] [G loss: 0.322552]\n",
      "epoch:4 step:4312 [D loss: 0.227537, acc.: 57.03%] [G loss: 0.295059]\n",
      "epoch:4 step:4313 [D loss: 0.234933, acc.: 64.06%] [G loss: 0.301157]\n",
      "epoch:4 step:4314 [D loss: 0.243747, acc.: 57.03%] [G loss: 0.312917]\n",
      "epoch:4 step:4315 [D loss: 0.238176, acc.: 59.38%] [G loss: 0.302794]\n",
      "epoch:4 step:4316 [D loss: 0.260366, acc.: 52.34%] [G loss: 0.308617]\n",
      "epoch:4 step:4317 [D loss: 0.238915, acc.: 60.16%] [G loss: 0.272828]\n",
      "epoch:4 step:4318 [D loss: 0.261689, acc.: 50.00%] [G loss: 0.318526]\n",
      "epoch:4 step:4319 [D loss: 0.228321, acc.: 60.94%] [G loss: 0.315589]\n",
      "epoch:4 step:4320 [D loss: 0.229934, acc.: 61.72%] [G loss: 0.299593]\n",
      "epoch:4 step:4321 [D loss: 0.247561, acc.: 60.16%] [G loss: 0.305053]\n",
      "epoch:4 step:4322 [D loss: 0.237369, acc.: 60.94%] [G loss: 0.306199]\n",
      "epoch:4 step:4323 [D loss: 0.248317, acc.: 55.47%] [G loss: 0.289183]\n",
      "epoch:4 step:4324 [D loss: 0.244425, acc.: 53.91%] [G loss: 0.302213]\n",
      "epoch:4 step:4325 [D loss: 0.249022, acc.: 58.59%] [G loss: 0.297823]\n",
      "epoch:4 step:4326 [D loss: 0.222164, acc.: 67.19%] [G loss: 0.314241]\n",
      "epoch:4 step:4327 [D loss: 0.250535, acc.: 55.47%] [G loss: 0.302426]\n",
      "epoch:4 step:4328 [D loss: 0.243245, acc.: 57.03%] [G loss: 0.298468]\n",
      "epoch:4 step:4329 [D loss: 0.251856, acc.: 56.25%] [G loss: 0.315237]\n",
      "epoch:4 step:4330 [D loss: 0.255748, acc.: 50.00%] [G loss: 0.290790]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:4 step:4331 [D loss: 0.236002, acc.: 57.03%] [G loss: 0.274662]\n",
      "epoch:4 step:4332 [D loss: 0.242652, acc.: 56.25%] [G loss: 0.321814]\n",
      "epoch:4 step:4333 [D loss: 0.248581, acc.: 57.03%] [G loss: 0.323161]\n",
      "epoch:4 step:4334 [D loss: 0.220728, acc.: 68.75%] [G loss: 0.295753]\n",
      "epoch:4 step:4335 [D loss: 0.223269, acc.: 67.19%] [G loss: 0.326436]\n",
      "epoch:4 step:4336 [D loss: 0.254302, acc.: 53.91%] [G loss: 0.275876]\n",
      "epoch:4 step:4337 [D loss: 0.239633, acc.: 64.06%] [G loss: 0.337774]\n",
      "epoch:4 step:4338 [D loss: 0.234789, acc.: 59.38%] [G loss: 0.286251]\n",
      "epoch:4 step:4339 [D loss: 0.227626, acc.: 62.50%] [G loss: 0.301473]\n",
      "epoch:4 step:4340 [D loss: 0.260694, acc.: 50.00%] [G loss: 0.290993]\n",
      "epoch:4 step:4341 [D loss: 0.245548, acc.: 51.56%] [G loss: 0.291797]\n",
      "epoch:4 step:4342 [D loss: 0.244307, acc.: 57.03%] [G loss: 0.297911]\n",
      "epoch:4 step:4343 [D loss: 0.254548, acc.: 52.34%] [G loss: 0.295715]\n",
      "epoch:4 step:4344 [D loss: 0.240258, acc.: 59.38%] [G loss: 0.318579]\n",
      "epoch:4 step:4345 [D loss: 0.237095, acc.: 56.25%] [G loss: 0.283893]\n",
      "epoch:4 step:4346 [D loss: 0.255828, acc.: 48.44%] [G loss: 0.290011]\n",
      "epoch:4 step:4347 [D loss: 0.258007, acc.: 50.00%] [G loss: 0.299100]\n",
      "epoch:4 step:4348 [D loss: 0.240175, acc.: 56.25%] [G loss: 0.323476]\n",
      "epoch:4 step:4349 [D loss: 0.225687, acc.: 67.19%] [G loss: 0.320389]\n",
      "epoch:4 step:4350 [D loss: 0.235173, acc.: 60.16%] [G loss: 0.313001]\n",
      "epoch:4 step:4351 [D loss: 0.245884, acc.: 59.38%] [G loss: 0.315648]\n",
      "epoch:4 step:4352 [D loss: 0.263469, acc.: 47.66%] [G loss: 0.321318]\n",
      "epoch:4 step:4353 [D loss: 0.259360, acc.: 48.44%] [G loss: 0.308481]\n",
      "epoch:4 step:4354 [D loss: 0.239038, acc.: 57.03%] [G loss: 0.291505]\n",
      "epoch:4 step:4355 [D loss: 0.253091, acc.: 49.22%] [G loss: 0.301076]\n",
      "epoch:4 step:4356 [D loss: 0.229448, acc.: 60.94%] [G loss: 0.293389]\n",
      "epoch:4 step:4357 [D loss: 0.221643, acc.: 62.50%] [G loss: 0.296675]\n",
      "epoch:4 step:4358 [D loss: 0.242665, acc.: 54.69%] [G loss: 0.310592]\n",
      "epoch:4 step:4359 [D loss: 0.241155, acc.: 58.59%] [G loss: 0.327770]\n",
      "epoch:4 step:4360 [D loss: 0.242499, acc.: 55.47%] [G loss: 0.303988]\n",
      "epoch:4 step:4361 [D loss: 0.233543, acc.: 61.72%] [G loss: 0.333758]\n",
      "epoch:4 step:4362 [D loss: 0.235254, acc.: 54.69%] [G loss: 0.304832]\n",
      "epoch:4 step:4363 [D loss: 0.231801, acc.: 60.16%] [G loss: 0.320805]\n",
      "epoch:4 step:4364 [D loss: 0.262933, acc.: 50.00%] [G loss: 0.280955]\n",
      "epoch:4 step:4365 [D loss: 0.244116, acc.: 60.16%] [G loss: 0.333182]\n",
      "epoch:4 step:4366 [D loss: 0.238584, acc.: 60.16%] [G loss: 0.310459]\n",
      "epoch:4 step:4367 [D loss: 0.238157, acc.: 58.59%] [G loss: 0.278061]\n",
      "epoch:4 step:4368 [D loss: 0.249866, acc.: 53.91%] [G loss: 0.331164]\n",
      "epoch:4 step:4369 [D loss: 0.235326, acc.: 57.81%] [G loss: 0.313059]\n",
      "epoch:4 step:4370 [D loss: 0.240298, acc.: 54.69%] [G loss: 0.308106]\n",
      "epoch:4 step:4371 [D loss: 0.237945, acc.: 56.25%] [G loss: 0.281925]\n",
      "epoch:4 step:4372 [D loss: 0.253442, acc.: 56.25%] [G loss: 0.293776]\n",
      "epoch:4 step:4373 [D loss: 0.215388, acc.: 64.84%] [G loss: 0.322891]\n",
      "epoch:4 step:4374 [D loss: 0.245336, acc.: 60.94%] [G loss: 0.306826]\n",
      "epoch:4 step:4375 [D loss: 0.232956, acc.: 60.16%] [G loss: 0.307231]\n",
      "epoch:4 step:4376 [D loss: 0.269345, acc.: 47.66%] [G loss: 0.272071]\n",
      "epoch:4 step:4377 [D loss: 0.250294, acc.: 55.47%] [G loss: 0.326790]\n",
      "epoch:4 step:4378 [D loss: 0.248860, acc.: 59.38%] [G loss: 0.327942]\n",
      "epoch:4 step:4379 [D loss: 0.226692, acc.: 64.06%] [G loss: 0.298966]\n",
      "epoch:4 step:4380 [D loss: 0.228381, acc.: 64.06%] [G loss: 0.337424]\n",
      "epoch:4 step:4381 [D loss: 0.229470, acc.: 64.84%] [G loss: 0.295246]\n",
      "epoch:4 step:4382 [D loss: 0.241571, acc.: 62.50%] [G loss: 0.271181]\n",
      "epoch:4 step:4383 [D loss: 0.246298, acc.: 57.81%] [G loss: 0.309153]\n",
      "epoch:4 step:4384 [D loss: 0.240131, acc.: 55.47%] [G loss: 0.299888]\n",
      "epoch:4 step:4385 [D loss: 0.253747, acc.: 50.00%] [G loss: 0.309688]\n",
      "epoch:4 step:4386 [D loss: 0.241677, acc.: 57.81%] [G loss: 0.302589]\n",
      "epoch:4 step:4387 [D loss: 0.258269, acc.: 50.00%] [G loss: 0.298503]\n",
      "epoch:4 step:4388 [D loss: 0.252181, acc.: 56.25%] [G loss: 0.301929]\n",
      "epoch:4 step:4389 [D loss: 0.239532, acc.: 57.03%] [G loss: 0.354777]\n",
      "epoch:4 step:4390 [D loss: 0.240975, acc.: 58.59%] [G loss: 0.312335]\n",
      "epoch:4 step:4391 [D loss: 0.252164, acc.: 57.03%] [G loss: 0.286254]\n",
      "epoch:4 step:4392 [D loss: 0.227239, acc.: 60.94%] [G loss: 0.290446]\n",
      "epoch:4 step:4393 [D loss: 0.252870, acc.: 57.03%] [G loss: 0.282721]\n",
      "epoch:4 step:4394 [D loss: 0.244073, acc.: 57.03%] [G loss: 0.278897]\n",
      "epoch:4 step:4395 [D loss: 0.244817, acc.: 56.25%] [G loss: 0.289005]\n",
      "epoch:4 step:4396 [D loss: 0.234467, acc.: 55.47%] [G loss: 0.299029]\n",
      "epoch:4 step:4397 [D loss: 0.243358, acc.: 54.69%] [G loss: 0.276847]\n",
      "epoch:4 step:4398 [D loss: 0.255411, acc.: 50.78%] [G loss: 0.309197]\n",
      "epoch:4 step:4399 [D loss: 0.244749, acc.: 50.00%] [G loss: 0.307152]\n",
      "epoch:4 step:4400 [D loss: 0.237809, acc.: 60.16%] [G loss: 0.292837]\n",
      "epoch:4 step:4401 [D loss: 0.240984, acc.: 61.72%] [G loss: 0.321602]\n",
      "epoch:4 step:4402 [D loss: 0.236256, acc.: 57.03%] [G loss: 0.305487]\n",
      "epoch:4 step:4403 [D loss: 0.244270, acc.: 51.56%] [G loss: 0.339420]\n",
      "epoch:4 step:4404 [D loss: 0.238623, acc.: 62.50%] [G loss: 0.307969]\n",
      "epoch:4 step:4405 [D loss: 0.264464, acc.: 49.22%] [G loss: 0.309311]\n",
      "epoch:4 step:4406 [D loss: 0.243575, acc.: 55.47%] [G loss: 0.317388]\n",
      "epoch:4 step:4407 [D loss: 0.251853, acc.: 53.91%] [G loss: 0.308824]\n",
      "epoch:4 step:4408 [D loss: 0.227080, acc.: 64.06%] [G loss: 0.340894]\n",
      "epoch:4 step:4409 [D loss: 0.237618, acc.: 63.28%] [G loss: 0.303117]\n",
      "epoch:4 step:4410 [D loss: 0.232552, acc.: 59.38%] [G loss: 0.324018]\n",
      "epoch:4 step:4411 [D loss: 0.246558, acc.: 52.34%] [G loss: 0.320356]\n",
      "epoch:4 step:4412 [D loss: 0.231097, acc.: 60.94%] [G loss: 0.304033]\n",
      "epoch:4 step:4413 [D loss: 0.249024, acc.: 53.12%] [G loss: 0.309622]\n",
      "epoch:4 step:4414 [D loss: 0.229197, acc.: 58.59%] [G loss: 0.297146]\n",
      "epoch:4 step:4415 [D loss: 0.253973, acc.: 52.34%] [G loss: 0.313308]\n",
      "epoch:4 step:4416 [D loss: 0.244004, acc.: 57.03%] [G loss: 0.330346]\n",
      "epoch:4 step:4417 [D loss: 0.253661, acc.: 55.47%] [G loss: 0.298789]\n",
      "epoch:4 step:4418 [D loss: 0.253943, acc.: 52.34%] [G loss: 0.322867]\n",
      "epoch:4 step:4419 [D loss: 0.225339, acc.: 67.19%] [G loss: 0.318126]\n",
      "epoch:4 step:4420 [D loss: 0.254444, acc.: 57.03%] [G loss: 0.308437]\n",
      "epoch:4 step:4421 [D loss: 0.245238, acc.: 53.91%] [G loss: 0.293921]\n",
      "epoch:4 step:4422 [D loss: 0.247172, acc.: 53.12%] [G loss: 0.280553]\n",
      "epoch:4 step:4423 [D loss: 0.214036, acc.: 67.97%] [G loss: 0.327129]\n",
      "epoch:4 step:4424 [D loss: 0.243607, acc.: 57.81%] [G loss: 0.278587]\n",
      "epoch:4 step:4425 [D loss: 0.240142, acc.: 61.72%] [G loss: 0.314670]\n",
      "epoch:4 step:4426 [D loss: 0.232822, acc.: 61.72%] [G loss: 0.336312]\n",
      "epoch:4 step:4427 [D loss: 0.247220, acc.: 60.16%] [G loss: 0.268374]\n",
      "epoch:4 step:4428 [D loss: 0.239236, acc.: 55.47%] [G loss: 0.311258]\n",
      "epoch:4 step:4429 [D loss: 0.254090, acc.: 53.91%] [G loss: 0.293625]\n",
      "epoch:4 step:4430 [D loss: 0.240031, acc.: 59.38%] [G loss: 0.297964]\n",
      "epoch:4 step:4431 [D loss: 0.236841, acc.: 63.28%] [G loss: 0.292438]\n",
      "epoch:4 step:4432 [D loss: 0.241351, acc.: 57.81%] [G loss: 0.280721]\n",
      "epoch:4 step:4433 [D loss: 0.255654, acc.: 53.12%] [G loss: 0.299732]\n",
      "epoch:4 step:4434 [D loss: 0.250508, acc.: 53.91%] [G loss: 0.328270]\n",
      "epoch:4 step:4435 [D loss: 0.238032, acc.: 60.16%] [G loss: 0.326278]\n",
      "epoch:4 step:4436 [D loss: 0.255430, acc.: 50.78%] [G loss: 0.298014]\n",
      "epoch:4 step:4437 [D loss: 0.238472, acc.: 57.81%] [G loss: 0.311557]\n",
      "epoch:4 step:4438 [D loss: 0.236840, acc.: 57.03%] [G loss: 0.310971]\n",
      "epoch:4 step:4439 [D loss: 0.236944, acc.: 57.81%] [G loss: 0.297842]\n",
      "epoch:4 step:4440 [D loss: 0.235268, acc.: 61.72%] [G loss: 0.271413]\n",
      "epoch:4 step:4441 [D loss: 0.249397, acc.: 55.47%] [G loss: 0.310096]\n",
      "epoch:4 step:4442 [D loss: 0.255853, acc.: 50.78%] [G loss: 0.301829]\n",
      "epoch:4 step:4443 [D loss: 0.216031, acc.: 66.41%] [G loss: 0.327979]\n",
      "epoch:4 step:4444 [D loss: 0.225837, acc.: 62.50%] [G loss: 0.288959]\n",
      "epoch:4 step:4445 [D loss: 0.252469, acc.: 53.91%] [G loss: 0.303377]\n",
      "epoch:4 step:4446 [D loss: 0.239312, acc.: 56.25%] [G loss: 0.305702]\n",
      "epoch:4 step:4447 [D loss: 0.242529, acc.: 53.91%] [G loss: 0.336178]\n",
      "epoch:4 step:4448 [D loss: 0.237139, acc.: 56.25%] [G loss: 0.330855]\n",
      "epoch:4 step:4449 [D loss: 0.223582, acc.: 62.50%] [G loss: 0.315092]\n",
      "epoch:4 step:4450 [D loss: 0.221386, acc.: 63.28%] [G loss: 0.317542]\n",
      "epoch:4 step:4451 [D loss: 0.253522, acc.: 51.56%] [G loss: 0.329725]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:4 step:4452 [D loss: 0.232106, acc.: 64.84%] [G loss: 0.298583]\n",
      "epoch:4 step:4453 [D loss: 0.228424, acc.: 64.06%] [G loss: 0.310787]\n",
      "epoch:4 step:4454 [D loss: 0.238280, acc.: 55.47%] [G loss: 0.357591]\n",
      "epoch:4 step:4455 [D loss: 0.242902, acc.: 56.25%] [G loss: 0.328502]\n",
      "epoch:4 step:4456 [D loss: 0.228667, acc.: 66.41%] [G loss: 0.274867]\n",
      "epoch:4 step:4457 [D loss: 0.258372, acc.: 49.22%] [G loss: 0.278152]\n",
      "epoch:4 step:4458 [D loss: 0.233756, acc.: 57.81%] [G loss: 0.319943]\n",
      "epoch:4 step:4459 [D loss: 0.238963, acc.: 52.34%] [G loss: 0.284303]\n",
      "epoch:4 step:4460 [D loss: 0.237549, acc.: 60.94%] [G loss: 0.323959]\n",
      "epoch:4 step:4461 [D loss: 0.223539, acc.: 67.19%] [G loss: 0.312116]\n",
      "epoch:4 step:4462 [D loss: 0.260043, acc.: 52.34%] [G loss: 0.307157]\n",
      "epoch:4 step:4463 [D loss: 0.242233, acc.: 57.03%] [G loss: 0.302321]\n",
      "epoch:4 step:4464 [D loss: 0.245489, acc.: 59.38%] [G loss: 0.309450]\n",
      "epoch:4 step:4465 [D loss: 0.243383, acc.: 55.47%] [G loss: 0.309580]\n",
      "epoch:4 step:4466 [D loss: 0.237566, acc.: 59.38%] [G loss: 0.307394]\n",
      "epoch:4 step:4467 [D loss: 0.246155, acc.: 53.12%] [G loss: 0.323785]\n",
      "epoch:4 step:4468 [D loss: 0.241185, acc.: 53.91%] [G loss: 0.327926]\n",
      "epoch:4 step:4469 [D loss: 0.255360, acc.: 53.91%] [G loss: 0.303126]\n",
      "epoch:4 step:4470 [D loss: 0.257613, acc.: 54.69%] [G loss: 0.322591]\n",
      "epoch:4 step:4471 [D loss: 0.245766, acc.: 54.69%] [G loss: 0.338384]\n",
      "epoch:4 step:4472 [D loss: 0.229855, acc.: 59.38%] [G loss: 0.296056]\n",
      "epoch:4 step:4473 [D loss: 0.250056, acc.: 56.25%] [G loss: 0.282549]\n",
      "epoch:4 step:4474 [D loss: 0.239779, acc.: 60.16%] [G loss: 0.317752]\n",
      "epoch:4 step:4475 [D loss: 0.238287, acc.: 56.25%] [G loss: 0.302477]\n",
      "epoch:4 step:4476 [D loss: 0.247670, acc.: 60.16%] [G loss: 0.298680]\n",
      "epoch:4 step:4477 [D loss: 0.239422, acc.: 58.59%] [G loss: 0.318370]\n",
      "epoch:4 step:4478 [D loss: 0.271342, acc.: 48.44%] [G loss: 0.281235]\n",
      "epoch:4 step:4479 [D loss: 0.231238, acc.: 58.59%] [G loss: 0.312945]\n",
      "epoch:4 step:4480 [D loss: 0.242388, acc.: 59.38%] [G loss: 0.309832]\n",
      "epoch:4 step:4481 [D loss: 0.260001, acc.: 50.78%] [G loss: 0.302488]\n",
      "epoch:4 step:4482 [D loss: 0.248276, acc.: 57.81%] [G loss: 0.306525]\n",
      "epoch:4 step:4483 [D loss: 0.242429, acc.: 57.03%] [G loss: 0.302323]\n",
      "epoch:4 step:4484 [D loss: 0.238691, acc.: 59.38%] [G loss: 0.292395]\n",
      "epoch:4 step:4485 [D loss: 0.256904, acc.: 53.91%] [G loss: 0.281783]\n",
      "epoch:4 step:4486 [D loss: 0.251384, acc.: 54.69%] [G loss: 0.306360]\n",
      "epoch:4 step:4487 [D loss: 0.236553, acc.: 59.38%] [G loss: 0.322419]\n",
      "epoch:4 step:4488 [D loss: 0.247036, acc.: 56.25%] [G loss: 0.325056]\n",
      "epoch:4 step:4489 [D loss: 0.217458, acc.: 64.06%] [G loss: 0.299335]\n",
      "epoch:4 step:4490 [D loss: 0.239773, acc.: 57.03%] [G loss: 0.283309]\n",
      "epoch:4 step:4491 [D loss: 0.227104, acc.: 62.50%] [G loss: 0.286108]\n",
      "epoch:4 step:4492 [D loss: 0.238152, acc.: 60.94%] [G loss: 0.327310]\n",
      "epoch:4 step:4493 [D loss: 0.239979, acc.: 58.59%] [G loss: 0.322077]\n",
      "epoch:4 step:4494 [D loss: 0.244236, acc.: 54.69%] [G loss: 0.329453]\n",
      "epoch:4 step:4495 [D loss: 0.258553, acc.: 50.78%] [G loss: 0.295147]\n",
      "epoch:4 step:4496 [D loss: 0.231795, acc.: 61.72%] [G loss: 0.304618]\n",
      "epoch:4 step:4497 [D loss: 0.244393, acc.: 54.69%] [G loss: 0.346726]\n",
      "epoch:4 step:4498 [D loss: 0.227292, acc.: 60.16%] [G loss: 0.332006]\n",
      "epoch:4 step:4499 [D loss: 0.239313, acc.: 55.47%] [G loss: 0.299093]\n",
      "epoch:4 step:4500 [D loss: 0.246884, acc.: 53.12%] [G loss: 0.304902]\n",
      "epoch:4 step:4501 [D loss: 0.240506, acc.: 58.59%] [G loss: 0.341179]\n",
      "epoch:4 step:4502 [D loss: 0.245524, acc.: 60.94%] [G loss: 0.320245]\n",
      "epoch:4 step:4503 [D loss: 0.238525, acc.: 64.06%] [G loss: 0.281451]\n",
      "epoch:4 step:4504 [D loss: 0.241161, acc.: 60.16%] [G loss: 0.308239]\n",
      "epoch:4 step:4505 [D loss: 0.243901, acc.: 57.81%] [G loss: 0.274509]\n",
      "epoch:4 step:4506 [D loss: 0.240030, acc.: 62.50%] [G loss: 0.312143]\n",
      "epoch:4 step:4507 [D loss: 0.246780, acc.: 57.81%] [G loss: 0.319973]\n",
      "epoch:4 step:4508 [D loss: 0.259958, acc.: 48.44%] [G loss: 0.278539]\n",
      "epoch:4 step:4509 [D loss: 0.248090, acc.: 54.69%] [G loss: 0.305887]\n",
      "epoch:4 step:4510 [D loss: 0.241451, acc.: 52.34%] [G loss: 0.301275]\n",
      "epoch:4 step:4511 [D loss: 0.241942, acc.: 59.38%] [G loss: 0.275306]\n",
      "epoch:4 step:4512 [D loss: 0.257517, acc.: 52.34%] [G loss: 0.282293]\n",
      "epoch:4 step:4513 [D loss: 0.228257, acc.: 62.50%] [G loss: 0.329164]\n",
      "epoch:4 step:4514 [D loss: 0.252272, acc.: 49.22%] [G loss: 0.309934]\n",
      "epoch:4 step:4515 [D loss: 0.241766, acc.: 57.81%] [G loss: 0.297654]\n",
      "epoch:4 step:4516 [D loss: 0.234730, acc.: 57.03%] [G loss: 0.298727]\n",
      "epoch:4 step:4517 [D loss: 0.258796, acc.: 48.44%] [G loss: 0.318413]\n",
      "epoch:4 step:4518 [D loss: 0.257482, acc.: 53.91%] [G loss: 0.287847]\n",
      "epoch:4 step:4519 [D loss: 0.245757, acc.: 53.91%] [G loss: 0.304379]\n",
      "epoch:4 step:4520 [D loss: 0.247569, acc.: 57.03%] [G loss: 0.285618]\n",
      "epoch:4 step:4521 [D loss: 0.228299, acc.: 61.72%] [G loss: 0.299433]\n",
      "epoch:4 step:4522 [D loss: 0.238556, acc.: 59.38%] [G loss: 0.309613]\n",
      "epoch:4 step:4523 [D loss: 0.248289, acc.: 53.12%] [G loss: 0.307826]\n",
      "epoch:4 step:4524 [D loss: 0.269438, acc.: 44.53%] [G loss: 0.288905]\n",
      "epoch:4 step:4525 [D loss: 0.253305, acc.: 52.34%] [G loss: 0.342937]\n",
      "epoch:4 step:4526 [D loss: 0.272922, acc.: 53.91%] [G loss: 0.286868]\n",
      "epoch:4 step:4527 [D loss: 0.237122, acc.: 54.69%] [G loss: 0.298163]\n",
      "epoch:4 step:4528 [D loss: 0.265869, acc.: 49.22%] [G loss: 0.288043]\n",
      "epoch:4 step:4529 [D loss: 0.250194, acc.: 55.47%] [G loss: 0.300459]\n",
      "epoch:4 step:4530 [D loss: 0.256488, acc.: 52.34%] [G loss: 0.278331]\n",
      "epoch:4 step:4531 [D loss: 0.248563, acc.: 52.34%] [G loss: 0.298769]\n",
      "epoch:4 step:4532 [D loss: 0.225034, acc.: 64.84%] [G loss: 0.296128]\n",
      "epoch:4 step:4533 [D loss: 0.251000, acc.: 52.34%] [G loss: 0.287247]\n",
      "epoch:4 step:4534 [D loss: 0.265733, acc.: 44.53%] [G loss: 0.289501]\n",
      "epoch:4 step:4535 [D loss: 0.251994, acc.: 54.69%] [G loss: 0.294379]\n",
      "epoch:4 step:4536 [D loss: 0.238235, acc.: 60.16%] [G loss: 0.311908]\n",
      "epoch:4 step:4537 [D loss: 0.241575, acc.: 53.91%] [G loss: 0.304580]\n",
      "epoch:4 step:4538 [D loss: 0.231184, acc.: 55.47%] [G loss: 0.289751]\n",
      "epoch:4 step:4539 [D loss: 0.251318, acc.: 50.78%] [G loss: 0.288320]\n",
      "epoch:4 step:4540 [D loss: 0.233100, acc.: 63.28%] [G loss: 0.309099]\n",
      "epoch:4 step:4541 [D loss: 0.240331, acc.: 51.56%] [G loss: 0.293653]\n",
      "epoch:4 step:4542 [D loss: 0.231808, acc.: 62.50%] [G loss: 0.307249]\n",
      "epoch:4 step:4543 [D loss: 0.228136, acc.: 62.50%] [G loss: 0.277745]\n",
      "epoch:4 step:4544 [D loss: 0.253142, acc.: 51.56%] [G loss: 0.298566]\n",
      "epoch:4 step:4545 [D loss: 0.263078, acc.: 48.44%] [G loss: 0.300419]\n",
      "epoch:4 step:4546 [D loss: 0.261691, acc.: 47.66%] [G loss: 0.302182]\n",
      "epoch:4 step:4547 [D loss: 0.237177, acc.: 60.94%] [G loss: 0.329001]\n",
      "epoch:4 step:4548 [D loss: 0.246481, acc.: 55.47%] [G loss: 0.307243]\n",
      "epoch:4 step:4549 [D loss: 0.229431, acc.: 61.72%] [G loss: 0.306107]\n",
      "epoch:4 step:4550 [D loss: 0.255850, acc.: 54.69%] [G loss: 0.277799]\n",
      "epoch:4 step:4551 [D loss: 0.239831, acc.: 60.16%] [G loss: 0.304122]\n",
      "epoch:4 step:4552 [D loss: 0.240014, acc.: 59.38%] [G loss: 0.284263]\n",
      "epoch:4 step:4553 [D loss: 0.244237, acc.: 54.69%] [G loss: 0.294181]\n",
      "epoch:4 step:4554 [D loss: 0.246278, acc.: 59.38%] [G loss: 0.285921]\n",
      "epoch:4 step:4555 [D loss: 0.234779, acc.: 59.38%] [G loss: 0.288977]\n",
      "epoch:4 step:4556 [D loss: 0.241984, acc.: 57.81%] [G loss: 0.275424]\n",
      "epoch:4 step:4557 [D loss: 0.239925, acc.: 58.59%] [G loss: 0.304916]\n",
      "epoch:4 step:4558 [D loss: 0.252791, acc.: 53.12%] [G loss: 0.275434]\n",
      "epoch:4 step:4559 [D loss: 0.253369, acc.: 51.56%] [G loss: 0.266953]\n",
      "epoch:4 step:4560 [D loss: 0.236636, acc.: 60.94%] [G loss: 0.329529]\n",
      "epoch:4 step:4561 [D loss: 0.245671, acc.: 50.78%] [G loss: 0.327380]\n",
      "epoch:4 step:4562 [D loss: 0.263443, acc.: 50.00%] [G loss: 0.312446]\n",
      "epoch:4 step:4563 [D loss: 0.235794, acc.: 56.25%] [G loss: 0.326280]\n",
      "epoch:4 step:4564 [D loss: 0.243160, acc.: 52.34%] [G loss: 0.306850]\n",
      "epoch:4 step:4565 [D loss: 0.256510, acc.: 57.81%] [G loss: 0.302841]\n",
      "epoch:4 step:4566 [D loss: 0.229778, acc.: 64.84%] [G loss: 0.306089]\n",
      "epoch:4 step:4567 [D loss: 0.235534, acc.: 55.47%] [G loss: 0.287269]\n",
      "epoch:4 step:4568 [D loss: 0.219809, acc.: 66.41%] [G loss: 0.315168]\n",
      "epoch:4 step:4569 [D loss: 0.261633, acc.: 53.12%] [G loss: 0.291267]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:4 step:4570 [D loss: 0.259073, acc.: 50.78%] [G loss: 0.295039]\n",
      "epoch:4 step:4571 [D loss: 0.263728, acc.: 47.66%] [G loss: 0.285313]\n",
      "epoch:4 step:4572 [D loss: 0.242294, acc.: 58.59%] [G loss: 0.324863]\n",
      "epoch:4 step:4573 [D loss: 0.230293, acc.: 64.84%] [G loss: 0.300223]\n",
      "epoch:4 step:4574 [D loss: 0.230449, acc.: 68.75%] [G loss: 0.318521]\n",
      "epoch:4 step:4575 [D loss: 0.266054, acc.: 53.12%] [G loss: 0.284977]\n",
      "epoch:4 step:4576 [D loss: 0.243682, acc.: 56.25%] [G loss: 0.321709]\n",
      "epoch:4 step:4577 [D loss: 0.244431, acc.: 52.34%] [G loss: 0.309344]\n",
      "epoch:4 step:4578 [D loss: 0.254354, acc.: 50.78%] [G loss: 0.292393]\n",
      "epoch:4 step:4579 [D loss: 0.249088, acc.: 54.69%] [G loss: 0.311432]\n",
      "epoch:4 step:4580 [D loss: 0.246068, acc.: 54.69%] [G loss: 0.303345]\n",
      "epoch:4 step:4581 [D loss: 0.245703, acc.: 58.59%] [G loss: 0.349620]\n",
      "epoch:4 step:4582 [D loss: 0.264810, acc.: 45.31%] [G loss: 0.310664]\n",
      "epoch:4 step:4583 [D loss: 0.258108, acc.: 53.91%] [G loss: 0.283289]\n",
      "epoch:4 step:4584 [D loss: 0.243667, acc.: 57.03%] [G loss: 0.304466]\n",
      "epoch:4 step:4585 [D loss: 0.224008, acc.: 60.16%] [G loss: 0.311615]\n",
      "epoch:4 step:4586 [D loss: 0.233814, acc.: 62.50%] [G loss: 0.287416]\n",
      "epoch:4 step:4587 [D loss: 0.262832, acc.: 53.12%] [G loss: 0.299104]\n",
      "epoch:4 step:4588 [D loss: 0.239570, acc.: 58.59%] [G loss: 0.289704]\n",
      "epoch:4 step:4589 [D loss: 0.236229, acc.: 64.06%] [G loss: 0.306804]\n",
      "epoch:4 step:4590 [D loss: 0.259192, acc.: 55.47%] [G loss: 0.310483]\n",
      "epoch:4 step:4591 [D loss: 0.260749, acc.: 47.66%] [G loss: 0.325612]\n",
      "epoch:4 step:4592 [D loss: 0.243262, acc.: 53.12%] [G loss: 0.305698]\n",
      "epoch:4 step:4593 [D loss: 0.251531, acc.: 57.03%] [G loss: 0.306143]\n",
      "epoch:4 step:4594 [D loss: 0.242563, acc.: 53.91%] [G loss: 0.305409]\n",
      "epoch:4 step:4595 [D loss: 0.226765, acc.: 66.41%] [G loss: 0.315494]\n",
      "epoch:4 step:4596 [D loss: 0.235134, acc.: 63.28%] [G loss: 0.283626]\n",
      "epoch:4 step:4597 [D loss: 0.231881, acc.: 61.72%] [G loss: 0.305975]\n",
      "epoch:4 step:4598 [D loss: 0.251996, acc.: 53.12%] [G loss: 0.307249]\n",
      "epoch:4 step:4599 [D loss: 0.245224, acc.: 60.16%] [G loss: 0.282618]\n",
      "epoch:4 step:4600 [D loss: 0.241279, acc.: 57.81%] [G loss: 0.309538]\n",
      "epoch:4 step:4601 [D loss: 0.248607, acc.: 54.69%] [G loss: 0.282010]\n",
      "epoch:4 step:4602 [D loss: 0.230005, acc.: 63.28%] [G loss: 0.321541]\n",
      "epoch:4 step:4603 [D loss: 0.259889, acc.: 50.78%] [G loss: 0.327338]\n",
      "epoch:4 step:4604 [D loss: 0.238521, acc.: 61.72%] [G loss: 0.289768]\n",
      "epoch:4 step:4605 [D loss: 0.245291, acc.: 57.03%] [G loss: 0.314137]\n",
      "epoch:4 step:4606 [D loss: 0.233998, acc.: 59.38%] [G loss: 0.293537]\n",
      "epoch:4 step:4607 [D loss: 0.270110, acc.: 49.22%] [G loss: 0.291967]\n",
      "epoch:4 step:4608 [D loss: 0.241813, acc.: 58.59%] [G loss: 0.291826]\n",
      "epoch:4 step:4609 [D loss: 0.233032, acc.: 65.62%] [G loss: 0.311963]\n",
      "epoch:4 step:4610 [D loss: 0.259243, acc.: 52.34%] [G loss: 0.286548]\n",
      "epoch:4 step:4611 [D loss: 0.240372, acc.: 55.47%] [G loss: 0.308211]\n",
      "epoch:4 step:4612 [D loss: 0.235400, acc.: 61.72%] [G loss: 0.324137]\n",
      "epoch:4 step:4613 [D loss: 0.228901, acc.: 67.97%] [G loss: 0.285388]\n",
      "epoch:4 step:4614 [D loss: 0.247261, acc.: 54.69%] [G loss: 0.275761]\n",
      "epoch:4 step:4615 [D loss: 0.243307, acc.: 57.03%] [G loss: 0.317632]\n",
      "epoch:4 step:4616 [D loss: 0.225451, acc.: 60.16%] [G loss: 0.297711]\n",
      "epoch:4 step:4617 [D loss: 0.235560, acc.: 56.25%] [G loss: 0.308861]\n",
      "epoch:4 step:4618 [D loss: 0.232899, acc.: 60.94%] [G loss: 0.312568]\n",
      "epoch:4 step:4619 [D loss: 0.251203, acc.: 55.47%] [G loss: 0.311130]\n",
      "epoch:4 step:4620 [D loss: 0.263632, acc.: 49.22%] [G loss: 0.287126]\n",
      "epoch:4 step:4621 [D loss: 0.245401, acc.: 53.91%] [G loss: 0.316117]\n",
      "epoch:4 step:4622 [D loss: 0.254959, acc.: 55.47%] [G loss: 0.317416]\n",
      "epoch:4 step:4623 [D loss: 0.224495, acc.: 60.94%] [G loss: 0.336875]\n",
      "epoch:4 step:4624 [D loss: 0.249299, acc.: 59.38%] [G loss: 0.295382]\n",
      "epoch:4 step:4625 [D loss: 0.237496, acc.: 60.16%] [G loss: 0.312643]\n",
      "epoch:4 step:4626 [D loss: 0.237094, acc.: 58.59%] [G loss: 0.288948]\n",
      "epoch:4 step:4627 [D loss: 0.254538, acc.: 57.03%] [G loss: 0.285985]\n",
      "epoch:4 step:4628 [D loss: 0.233631, acc.: 66.41%] [G loss: 0.318419]\n",
      "epoch:4 step:4629 [D loss: 0.238922, acc.: 59.38%] [G loss: 0.310630]\n",
      "epoch:4 step:4630 [D loss: 0.235043, acc.: 57.81%] [G loss: 0.311809]\n",
      "epoch:4 step:4631 [D loss: 0.234051, acc.: 54.69%] [G loss: 0.342725]\n",
      "epoch:4 step:4632 [D loss: 0.238496, acc.: 54.69%] [G loss: 0.273186]\n",
      "epoch:4 step:4633 [D loss: 0.232081, acc.: 58.59%] [G loss: 0.299202]\n",
      "epoch:4 step:4634 [D loss: 0.233398, acc.: 60.94%] [G loss: 0.326487]\n",
      "epoch:4 step:4635 [D loss: 0.237165, acc.: 60.16%] [G loss: 0.309134]\n",
      "epoch:4 step:4636 [D loss: 0.246704, acc.: 54.69%] [G loss: 0.318772]\n",
      "epoch:4 step:4637 [D loss: 0.253956, acc.: 51.56%] [G loss: 0.296926]\n",
      "epoch:4 step:4638 [D loss: 0.232607, acc.: 60.94%] [G loss: 0.303776]\n",
      "epoch:4 step:4639 [D loss: 0.250651, acc.: 57.03%] [G loss: 0.320339]\n",
      "epoch:4 step:4640 [D loss: 0.249445, acc.: 56.25%] [G loss: 0.296789]\n",
      "epoch:4 step:4641 [D loss: 0.259058, acc.: 51.56%] [G loss: 0.307115]\n",
      "epoch:4 step:4642 [D loss: 0.259370, acc.: 56.25%] [G loss: 0.293028]\n",
      "epoch:4 step:4643 [D loss: 0.234048, acc.: 57.03%] [G loss: 0.313652]\n",
      "epoch:4 step:4644 [D loss: 0.264733, acc.: 50.78%] [G loss: 0.318580]\n",
      "epoch:4 step:4645 [D loss: 0.243716, acc.: 59.38%] [G loss: 0.311176]\n",
      "epoch:4 step:4646 [D loss: 0.214282, acc.: 65.62%] [G loss: 0.323427]\n",
      "epoch:4 step:4647 [D loss: 0.270613, acc.: 45.31%] [G loss: 0.283272]\n",
      "epoch:4 step:4648 [D loss: 0.240304, acc.: 59.38%] [G loss: 0.300247]\n",
      "epoch:4 step:4649 [D loss: 0.245612, acc.: 54.69%] [G loss: 0.287000]\n",
      "epoch:4 step:4650 [D loss: 0.249601, acc.: 57.81%] [G loss: 0.316721]\n",
      "epoch:4 step:4651 [D loss: 0.217823, acc.: 65.62%] [G loss: 0.306310]\n",
      "epoch:4 step:4652 [D loss: 0.249585, acc.: 58.59%] [G loss: 0.292037]\n",
      "epoch:4 step:4653 [D loss: 0.249989, acc.: 51.56%] [G loss: 0.269649]\n",
      "epoch:4 step:4654 [D loss: 0.235326, acc.: 56.25%] [G loss: 0.302072]\n",
      "epoch:4 step:4655 [D loss: 0.233420, acc.: 58.59%] [G loss: 0.319365]\n",
      "epoch:4 step:4656 [D loss: 0.240497, acc.: 58.59%] [G loss: 0.314801]\n",
      "epoch:4 step:4657 [D loss: 0.243499, acc.: 54.69%] [G loss: 0.310462]\n",
      "epoch:4 step:4658 [D loss: 0.255588, acc.: 54.69%] [G loss: 0.295292]\n",
      "epoch:4 step:4659 [D loss: 0.235684, acc.: 60.16%] [G loss: 0.301031]\n",
      "epoch:4 step:4660 [D loss: 0.241633, acc.: 51.56%] [G loss: 0.302962]\n",
      "epoch:4 step:4661 [D loss: 0.236413, acc.: 58.59%] [G loss: 0.302867]\n",
      "epoch:4 step:4662 [D loss: 0.259409, acc.: 44.53%] [G loss: 0.279503]\n",
      "epoch:4 step:4663 [D loss: 0.225531, acc.: 67.97%] [G loss: 0.306397]\n",
      "epoch:4 step:4664 [D loss: 0.235057, acc.: 59.38%] [G loss: 0.327481]\n",
      "epoch:4 step:4665 [D loss: 0.237646, acc.: 60.94%] [G loss: 0.292818]\n",
      "epoch:4 step:4666 [D loss: 0.262161, acc.: 50.00%] [G loss: 0.320991]\n",
      "epoch:4 step:4667 [D loss: 0.239474, acc.: 59.38%] [G loss: 0.298749]\n",
      "epoch:4 step:4668 [D loss: 0.247606, acc.: 54.69%] [G loss: 0.284749]\n",
      "epoch:4 step:4669 [D loss: 0.250022, acc.: 53.12%] [G loss: 0.291912]\n",
      "epoch:4 step:4670 [D loss: 0.235896, acc.: 57.81%] [G loss: 0.327172]\n",
      "epoch:4 step:4671 [D loss: 0.232086, acc.: 57.03%] [G loss: 0.315111]\n",
      "epoch:4 step:4672 [D loss: 0.242837, acc.: 55.47%] [G loss: 0.289802]\n",
      "epoch:4 step:4673 [D loss: 0.259000, acc.: 52.34%] [G loss: 0.301437]\n",
      "epoch:4 step:4674 [D loss: 0.246942, acc.: 57.03%] [G loss: 0.299528]\n",
      "epoch:4 step:4675 [D loss: 0.269063, acc.: 50.78%] [G loss: 0.311030]\n",
      "epoch:4 step:4676 [D loss: 0.238799, acc.: 56.25%] [G loss: 0.296447]\n",
      "epoch:4 step:4677 [D loss: 0.224068, acc.: 64.06%] [G loss: 0.305049]\n",
      "epoch:4 step:4678 [D loss: 0.229045, acc.: 60.16%] [G loss: 0.314907]\n",
      "epoch:4 step:4679 [D loss: 0.245277, acc.: 58.59%] [G loss: 0.314256]\n",
      "epoch:4 step:4680 [D loss: 0.244558, acc.: 58.59%] [G loss: 0.324238]\n",
      "epoch:4 step:4681 [D loss: 0.232659, acc.: 62.50%] [G loss: 0.328583]\n",
      "epoch:4 step:4682 [D loss: 0.256858, acc.: 52.34%] [G loss: 0.316287]\n",
      "epoch:4 step:4683 [D loss: 0.230769, acc.: 57.81%] [G loss: 0.339332]\n",
      "epoch:4 step:4684 [D loss: 0.251621, acc.: 54.69%] [G loss: 0.336885]\n",
      "epoch:4 step:4685 [D loss: 0.242641, acc.: 59.38%] [G loss: 0.326862]\n",
      "epoch:5 step:4686 [D loss: 0.242592, acc.: 54.69%] [G loss: 0.289353]\n",
      "epoch:5 step:4687 [D loss: 0.255346, acc.: 52.34%] [G loss: 0.323534]\n",
      "epoch:5 step:4688 [D loss: 0.242321, acc.: 57.03%] [G loss: 0.301615]\n",
      "epoch:5 step:4689 [D loss: 0.281732, acc.: 40.62%] [G loss: 0.274274]\n",
      "epoch:5 step:4690 [D loss: 0.237678, acc.: 60.16%] [G loss: 0.320711]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:5 step:4691 [D loss: 0.258267, acc.: 55.47%] [G loss: 0.342841]\n",
      "epoch:5 step:4692 [D loss: 0.249760, acc.: 53.12%] [G loss: 0.306486]\n",
      "epoch:5 step:4693 [D loss: 0.229589, acc.: 64.84%] [G loss: 0.283934]\n",
      "epoch:5 step:4694 [D loss: 0.239756, acc.: 56.25%] [G loss: 0.316569]\n",
      "epoch:5 step:4695 [D loss: 0.231436, acc.: 63.28%] [G loss: 0.332217]\n",
      "epoch:5 step:4696 [D loss: 0.231679, acc.: 64.84%] [G loss: 0.286374]\n",
      "epoch:5 step:4697 [D loss: 0.257391, acc.: 52.34%] [G loss: 0.338674]\n",
      "epoch:5 step:4698 [D loss: 0.235385, acc.: 60.16%] [G loss: 0.345102]\n",
      "epoch:5 step:4699 [D loss: 0.258132, acc.: 47.66%] [G loss: 0.293950]\n",
      "epoch:5 step:4700 [D loss: 0.228416, acc.: 66.41%] [G loss: 0.303102]\n",
      "epoch:5 step:4701 [D loss: 0.243453, acc.: 56.25%] [G loss: 0.299171]\n",
      "epoch:5 step:4702 [D loss: 0.235479, acc.: 57.81%] [G loss: 0.285733]\n",
      "epoch:5 step:4703 [D loss: 0.220899, acc.: 65.62%] [G loss: 0.302942]\n",
      "epoch:5 step:4704 [D loss: 0.247939, acc.: 53.12%] [G loss: 0.312210]\n",
      "epoch:5 step:4705 [D loss: 0.260235, acc.: 48.44%] [G loss: 0.274980]\n",
      "epoch:5 step:4706 [D loss: 0.262710, acc.: 45.31%] [G loss: 0.289968]\n",
      "epoch:5 step:4707 [D loss: 0.249617, acc.: 58.59%] [G loss: 0.302108]\n",
      "epoch:5 step:4708 [D loss: 0.250367, acc.: 50.00%] [G loss: 0.280973]\n",
      "epoch:5 step:4709 [D loss: 0.249427, acc.: 52.34%] [G loss: 0.277505]\n",
      "epoch:5 step:4710 [D loss: 0.252431, acc.: 54.69%] [G loss: 0.302895]\n",
      "epoch:5 step:4711 [D loss: 0.243742, acc.: 50.78%] [G loss: 0.285530]\n",
      "epoch:5 step:4712 [D loss: 0.233835, acc.: 55.47%] [G loss: 0.297085]\n",
      "epoch:5 step:4713 [D loss: 0.235490, acc.: 64.06%] [G loss: 0.303267]\n",
      "epoch:5 step:4714 [D loss: 0.251755, acc.: 57.81%] [G loss: 0.309322]\n",
      "epoch:5 step:4715 [D loss: 0.246669, acc.: 53.12%] [G loss: 0.317121]\n",
      "epoch:5 step:4716 [D loss: 0.255342, acc.: 56.25%] [G loss: 0.286238]\n",
      "epoch:5 step:4717 [D loss: 0.261648, acc.: 52.34%] [G loss: 0.300771]\n",
      "epoch:5 step:4718 [D loss: 0.237046, acc.: 58.59%] [G loss: 0.298933]\n",
      "epoch:5 step:4719 [D loss: 0.251847, acc.: 53.91%] [G loss: 0.298024]\n",
      "epoch:5 step:4720 [D loss: 0.249711, acc.: 53.91%] [G loss: 0.308993]\n",
      "epoch:5 step:4721 [D loss: 0.228630, acc.: 69.53%] [G loss: 0.305279]\n",
      "epoch:5 step:4722 [D loss: 0.241268, acc.: 61.72%] [G loss: 0.302408]\n",
      "epoch:5 step:4723 [D loss: 0.243048, acc.: 58.59%] [G loss: 0.290805]\n",
      "epoch:5 step:4724 [D loss: 0.251720, acc.: 54.69%] [G loss: 0.279708]\n",
      "epoch:5 step:4725 [D loss: 0.238429, acc.: 60.16%] [G loss: 0.309230]\n",
      "epoch:5 step:4726 [D loss: 0.246694, acc.: 52.34%] [G loss: 0.326391]\n",
      "epoch:5 step:4727 [D loss: 0.219432, acc.: 66.41%] [G loss: 0.313944]\n",
      "epoch:5 step:4728 [D loss: 0.244172, acc.: 57.81%] [G loss: 0.293980]\n",
      "epoch:5 step:4729 [D loss: 0.244036, acc.: 56.25%] [G loss: 0.328372]\n",
      "epoch:5 step:4730 [D loss: 0.256901, acc.: 51.56%] [G loss: 0.314915]\n",
      "epoch:5 step:4731 [D loss: 0.242600, acc.: 56.25%] [G loss: 0.309325]\n",
      "epoch:5 step:4732 [D loss: 0.258563, acc.: 51.56%] [G loss: 0.281533]\n",
      "epoch:5 step:4733 [D loss: 0.228463, acc.: 66.41%] [G loss: 0.297047]\n",
      "epoch:5 step:4734 [D loss: 0.231089, acc.: 66.41%] [G loss: 0.322652]\n",
      "epoch:5 step:4735 [D loss: 0.242827, acc.: 60.16%] [G loss: 0.295050]\n",
      "epoch:5 step:4736 [D loss: 0.235587, acc.: 60.16%] [G loss: 0.289674]\n",
      "epoch:5 step:4737 [D loss: 0.243321, acc.: 57.03%] [G loss: 0.304778]\n",
      "epoch:5 step:4738 [D loss: 0.261423, acc.: 51.56%] [G loss: 0.295799]\n",
      "epoch:5 step:4739 [D loss: 0.247206, acc.: 54.69%] [G loss: 0.328527]\n",
      "epoch:5 step:4740 [D loss: 0.246738, acc.: 56.25%] [G loss: 0.336537]\n",
      "epoch:5 step:4741 [D loss: 0.260852, acc.: 53.12%] [G loss: 0.300865]\n",
      "epoch:5 step:4742 [D loss: 0.236529, acc.: 60.94%] [G loss: 0.337302]\n",
      "epoch:5 step:4743 [D loss: 0.251224, acc.: 54.69%] [G loss: 0.325304]\n",
      "epoch:5 step:4744 [D loss: 0.240295, acc.: 52.34%] [G loss: 0.331773]\n",
      "epoch:5 step:4745 [D loss: 0.239149, acc.: 57.03%] [G loss: 0.303051]\n",
      "epoch:5 step:4746 [D loss: 0.248330, acc.: 52.34%] [G loss: 0.303604]\n",
      "epoch:5 step:4747 [D loss: 0.251059, acc.: 51.56%] [G loss: 0.297944]\n",
      "epoch:5 step:4748 [D loss: 0.245538, acc.: 56.25%] [G loss: 0.283366]\n",
      "epoch:5 step:4749 [D loss: 0.234852, acc.: 57.81%] [G loss: 0.323599]\n",
      "epoch:5 step:4750 [D loss: 0.232505, acc.: 64.06%] [G loss: 0.298559]\n",
      "epoch:5 step:4751 [D loss: 0.257779, acc.: 52.34%] [G loss: 0.337251]\n",
      "epoch:5 step:4752 [D loss: 0.243591, acc.: 53.12%] [G loss: 0.309924]\n",
      "epoch:5 step:4753 [D loss: 0.233512, acc.: 60.16%] [G loss: 0.288846]\n",
      "epoch:5 step:4754 [D loss: 0.257831, acc.: 50.78%] [G loss: 0.312974]\n",
      "epoch:5 step:4755 [D loss: 0.246939, acc.: 54.69%] [G loss: 0.335775]\n",
      "epoch:5 step:4756 [D loss: 0.259507, acc.: 46.88%] [G loss: 0.300108]\n",
      "epoch:5 step:4757 [D loss: 0.227241, acc.: 59.38%] [G loss: 0.312875]\n",
      "epoch:5 step:4758 [D loss: 0.241648, acc.: 60.94%] [G loss: 0.307880]\n",
      "epoch:5 step:4759 [D loss: 0.256656, acc.: 53.12%] [G loss: 0.321546]\n",
      "epoch:5 step:4760 [D loss: 0.240199, acc.: 59.38%] [G loss: 0.291605]\n",
      "epoch:5 step:4761 [D loss: 0.249169, acc.: 56.25%] [G loss: 0.290733]\n",
      "epoch:5 step:4762 [D loss: 0.245003, acc.: 56.25%] [G loss: 0.311937]\n",
      "epoch:5 step:4763 [D loss: 0.237653, acc.: 62.50%] [G loss: 0.289179]\n",
      "epoch:5 step:4764 [D loss: 0.256851, acc.: 47.66%] [G loss: 0.267829]\n",
      "epoch:5 step:4765 [D loss: 0.231965, acc.: 59.38%] [G loss: 0.306960]\n",
      "epoch:5 step:4766 [D loss: 0.251443, acc.: 56.25%] [G loss: 0.311618]\n",
      "epoch:5 step:4767 [D loss: 0.245088, acc.: 55.47%] [G loss: 0.286923]\n",
      "epoch:5 step:4768 [D loss: 0.240578, acc.: 56.25%] [G loss: 0.300450]\n",
      "epoch:5 step:4769 [D loss: 0.244865, acc.: 55.47%] [G loss: 0.311351]\n",
      "epoch:5 step:4770 [D loss: 0.259538, acc.: 45.31%] [G loss: 0.323638]\n",
      "epoch:5 step:4771 [D loss: 0.235594, acc.: 61.72%] [G loss: 0.314790]\n",
      "epoch:5 step:4772 [D loss: 0.233784, acc.: 61.72%] [G loss: 0.299053]\n",
      "epoch:5 step:4773 [D loss: 0.232727, acc.: 60.94%] [G loss: 0.315260]\n",
      "epoch:5 step:4774 [D loss: 0.250289, acc.: 56.25%] [G loss: 0.268961]\n",
      "epoch:5 step:4775 [D loss: 0.235396, acc.: 62.50%] [G loss: 0.308186]\n",
      "epoch:5 step:4776 [D loss: 0.254542, acc.: 54.69%] [G loss: 0.315854]\n",
      "epoch:5 step:4777 [D loss: 0.246461, acc.: 60.16%] [G loss: 0.311891]\n",
      "epoch:5 step:4778 [D loss: 0.268532, acc.: 48.44%] [G loss: 0.277691]\n",
      "epoch:5 step:4779 [D loss: 0.232249, acc.: 67.19%] [G loss: 0.330930]\n",
      "epoch:5 step:4780 [D loss: 0.242247, acc.: 58.59%] [G loss: 0.300427]\n",
      "epoch:5 step:4781 [D loss: 0.238027, acc.: 57.81%] [G loss: 0.314043]\n",
      "epoch:5 step:4782 [D loss: 0.241644, acc.: 60.16%] [G loss: 0.280949]\n",
      "epoch:5 step:4783 [D loss: 0.245626, acc.: 57.81%] [G loss: 0.315425]\n",
      "epoch:5 step:4784 [D loss: 0.242196, acc.: 59.38%] [G loss: 0.313525]\n",
      "epoch:5 step:4785 [D loss: 0.247100, acc.: 56.25%] [G loss: 0.340314]\n",
      "epoch:5 step:4786 [D loss: 0.228874, acc.: 61.72%] [G loss: 0.306853]\n",
      "epoch:5 step:4787 [D loss: 0.247993, acc.: 56.25%] [G loss: 0.318021]\n",
      "epoch:5 step:4788 [D loss: 0.232360, acc.: 67.97%] [G loss: 0.315675]\n",
      "epoch:5 step:4789 [D loss: 0.235247, acc.: 55.47%] [G loss: 0.341294]\n",
      "epoch:5 step:4790 [D loss: 0.238540, acc.: 58.59%] [G loss: 0.307228]\n",
      "epoch:5 step:4791 [D loss: 0.223315, acc.: 61.72%] [G loss: 0.322315]\n",
      "epoch:5 step:4792 [D loss: 0.248298, acc.: 55.47%] [G loss: 0.311323]\n",
      "epoch:5 step:4793 [D loss: 0.232356, acc.: 63.28%] [G loss: 0.327457]\n",
      "epoch:5 step:4794 [D loss: 0.258864, acc.: 49.22%] [G loss: 0.287774]\n",
      "epoch:5 step:4795 [D loss: 0.253218, acc.: 50.00%] [G loss: 0.290897]\n",
      "epoch:5 step:4796 [D loss: 0.237405, acc.: 64.06%] [G loss: 0.298692]\n",
      "epoch:5 step:4797 [D loss: 0.241735, acc.: 58.59%] [G loss: 0.326854]\n",
      "epoch:5 step:4798 [D loss: 0.235567, acc.: 55.47%] [G loss: 0.276995]\n",
      "epoch:5 step:4799 [D loss: 0.247353, acc.: 57.03%] [G loss: 0.298840]\n",
      "epoch:5 step:4800 [D loss: 0.252092, acc.: 53.91%] [G loss: 0.328257]\n",
      "epoch:5 step:4801 [D loss: 0.239082, acc.: 62.50%] [G loss: 0.309566]\n",
      "epoch:5 step:4802 [D loss: 0.253935, acc.: 53.91%] [G loss: 0.306439]\n",
      "epoch:5 step:4803 [D loss: 0.251927, acc.: 51.56%] [G loss: 0.279518]\n",
      "epoch:5 step:4804 [D loss: 0.254623, acc.: 51.56%] [G loss: 0.304074]\n",
      "epoch:5 step:4805 [D loss: 0.269741, acc.: 46.09%] [G loss: 0.345473]\n",
      "epoch:5 step:4806 [D loss: 0.242431, acc.: 60.16%] [G loss: 0.292334]\n",
      "epoch:5 step:4807 [D loss: 0.257133, acc.: 51.56%] [G loss: 0.277859]\n",
      "epoch:5 step:4808 [D loss: 0.249635, acc.: 55.47%] [G loss: 0.276869]\n",
      "epoch:5 step:4809 [D loss: 0.257946, acc.: 49.22%] [G loss: 0.290765]\n",
      "epoch:5 step:4810 [D loss: 0.240528, acc.: 60.16%] [G loss: 0.321771]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:5 step:4811 [D loss: 0.243410, acc.: 57.81%] [G loss: 0.310324]\n",
      "epoch:5 step:4812 [D loss: 0.226603, acc.: 66.41%] [G loss: 0.324167]\n",
      "epoch:5 step:4813 [D loss: 0.258428, acc.: 53.12%] [G loss: 0.308846]\n",
      "epoch:5 step:4814 [D loss: 0.240952, acc.: 57.81%] [G loss: 0.299103]\n",
      "epoch:5 step:4815 [D loss: 0.248445, acc.: 57.03%] [G loss: 0.314801]\n",
      "epoch:5 step:4816 [D loss: 0.257043, acc.: 50.00%] [G loss: 0.304148]\n",
      "epoch:5 step:4817 [D loss: 0.250278, acc.: 57.81%] [G loss: 0.296139]\n",
      "epoch:5 step:4818 [D loss: 0.243006, acc.: 58.59%] [G loss: 0.322353]\n",
      "epoch:5 step:4819 [D loss: 0.236229, acc.: 64.06%] [G loss: 0.295463]\n",
      "epoch:5 step:4820 [D loss: 0.253364, acc.: 54.69%] [G loss: 0.274323]\n",
      "epoch:5 step:4821 [D loss: 0.254664, acc.: 57.03%] [G loss: 0.302061]\n",
      "epoch:5 step:4822 [D loss: 0.225422, acc.: 64.84%] [G loss: 0.336397]\n",
      "epoch:5 step:4823 [D loss: 0.241468, acc.: 59.38%] [G loss: 0.309065]\n",
      "epoch:5 step:4824 [D loss: 0.260414, acc.: 50.00%] [G loss: 0.347971]\n",
      "epoch:5 step:4825 [D loss: 0.242122, acc.: 57.03%] [G loss: 0.313607]\n",
      "epoch:5 step:4826 [D loss: 0.246858, acc.: 57.03%] [G loss: 0.312751]\n",
      "epoch:5 step:4827 [D loss: 0.229769, acc.: 63.28%] [G loss: 0.306340]\n",
      "epoch:5 step:4828 [D loss: 0.245523, acc.: 52.34%] [G loss: 0.318990]\n",
      "epoch:5 step:4829 [D loss: 0.254015, acc.: 56.25%] [G loss: 0.310403]\n",
      "epoch:5 step:4830 [D loss: 0.241314, acc.: 59.38%] [G loss: 0.299086]\n",
      "epoch:5 step:4831 [D loss: 0.241894, acc.: 56.25%] [G loss: 0.305632]\n",
      "epoch:5 step:4832 [D loss: 0.241936, acc.: 55.47%] [G loss: 0.325604]\n",
      "epoch:5 step:4833 [D loss: 0.246233, acc.: 54.69%] [G loss: 0.308785]\n",
      "epoch:5 step:4834 [D loss: 0.254538, acc.: 52.34%] [G loss: 0.303977]\n",
      "epoch:5 step:4835 [D loss: 0.239447, acc.: 58.59%] [G loss: 0.305786]\n",
      "epoch:5 step:4836 [D loss: 0.254248, acc.: 55.47%] [G loss: 0.284738]\n",
      "epoch:5 step:4837 [D loss: 0.262398, acc.: 53.12%] [G loss: 0.318552]\n",
      "epoch:5 step:4838 [D loss: 0.240388, acc.: 59.38%] [G loss: 0.313494]\n",
      "epoch:5 step:4839 [D loss: 0.261056, acc.: 51.56%] [G loss: 0.312062]\n",
      "epoch:5 step:4840 [D loss: 0.235514, acc.: 60.16%] [G loss: 0.298758]\n",
      "epoch:5 step:4841 [D loss: 0.238760, acc.: 58.59%] [G loss: 0.293748]\n",
      "epoch:5 step:4842 [D loss: 0.245658, acc.: 57.03%] [G loss: 0.298837]\n",
      "epoch:5 step:4843 [D loss: 0.236000, acc.: 58.59%] [G loss: 0.278227]\n",
      "epoch:5 step:4844 [D loss: 0.248191, acc.: 53.91%] [G loss: 0.298354]\n",
      "epoch:5 step:4845 [D loss: 0.217996, acc.: 66.41%] [G loss: 0.306264]\n",
      "epoch:5 step:4846 [D loss: 0.232991, acc.: 64.06%] [G loss: 0.307471]\n",
      "epoch:5 step:4847 [D loss: 0.237799, acc.: 62.50%] [G loss: 0.318968]\n",
      "epoch:5 step:4848 [D loss: 0.252973, acc.: 57.03%] [G loss: 0.321680]\n",
      "epoch:5 step:4849 [D loss: 0.254171, acc.: 50.00%] [G loss: 0.292712]\n",
      "epoch:5 step:4850 [D loss: 0.253129, acc.: 54.69%] [G loss: 0.312461]\n",
      "epoch:5 step:4851 [D loss: 0.247181, acc.: 57.03%] [G loss: 0.312736]\n",
      "epoch:5 step:4852 [D loss: 0.242811, acc.: 56.25%] [G loss: 0.290940]\n",
      "epoch:5 step:4853 [D loss: 0.252246, acc.: 56.25%] [G loss: 0.301482]\n",
      "epoch:5 step:4854 [D loss: 0.260896, acc.: 50.00%] [G loss: 0.315894]\n",
      "epoch:5 step:4855 [D loss: 0.251616, acc.: 56.25%] [G loss: 0.293400]\n",
      "epoch:5 step:4856 [D loss: 0.236411, acc.: 60.94%] [G loss: 0.303678]\n",
      "epoch:5 step:4857 [D loss: 0.232029, acc.: 62.50%] [G loss: 0.301940]\n",
      "epoch:5 step:4858 [D loss: 0.249499, acc.: 53.91%] [G loss: 0.325751]\n",
      "epoch:5 step:4859 [D loss: 0.252236, acc.: 50.00%] [G loss: 0.312850]\n",
      "epoch:5 step:4860 [D loss: 0.257192, acc.: 51.56%] [G loss: 0.297857]\n",
      "epoch:5 step:4861 [D loss: 0.243799, acc.: 60.94%] [G loss: 0.318103]\n",
      "epoch:5 step:4862 [D loss: 0.241028, acc.: 57.03%] [G loss: 0.297799]\n",
      "epoch:5 step:4863 [D loss: 0.242017, acc.: 61.72%] [G loss: 0.289293]\n",
      "epoch:5 step:4864 [D loss: 0.245115, acc.: 57.81%] [G loss: 0.299421]\n",
      "epoch:5 step:4865 [D loss: 0.247855, acc.: 55.47%] [G loss: 0.301773]\n",
      "epoch:5 step:4866 [D loss: 0.261345, acc.: 52.34%] [G loss: 0.304847]\n",
      "epoch:5 step:4867 [D loss: 0.237447, acc.: 57.03%] [G loss: 0.282394]\n",
      "epoch:5 step:4868 [D loss: 0.245388, acc.: 53.12%] [G loss: 0.294789]\n",
      "epoch:5 step:4869 [D loss: 0.277099, acc.: 47.66%] [G loss: 0.302052]\n",
      "epoch:5 step:4870 [D loss: 0.262140, acc.: 46.09%] [G loss: 0.302662]\n",
      "epoch:5 step:4871 [D loss: 0.237705, acc.: 57.81%] [G loss: 0.312869]\n",
      "epoch:5 step:4872 [D loss: 0.239144, acc.: 57.03%] [G loss: 0.303379]\n",
      "epoch:5 step:4873 [D loss: 0.262935, acc.: 49.22%] [G loss: 0.293815]\n",
      "epoch:5 step:4874 [D loss: 0.241466, acc.: 55.47%] [G loss: 0.329864]\n",
      "epoch:5 step:4875 [D loss: 0.248083, acc.: 54.69%] [G loss: 0.300976]\n",
      "epoch:5 step:4876 [D loss: 0.237422, acc.: 55.47%] [G loss: 0.297590]\n",
      "epoch:5 step:4877 [D loss: 0.243224, acc.: 55.47%] [G loss: 0.303923]\n",
      "epoch:5 step:4878 [D loss: 0.244747, acc.: 53.91%] [G loss: 0.316034]\n",
      "epoch:5 step:4879 [D loss: 0.237457, acc.: 57.81%] [G loss: 0.294372]\n",
      "epoch:5 step:4880 [D loss: 0.252499, acc.: 55.47%] [G loss: 0.297948]\n",
      "epoch:5 step:4881 [D loss: 0.237576, acc.: 59.38%] [G loss: 0.320461]\n",
      "epoch:5 step:4882 [D loss: 0.247913, acc.: 57.81%] [G loss: 0.296319]\n",
      "epoch:5 step:4883 [D loss: 0.242834, acc.: 53.12%] [G loss: 0.290763]\n",
      "epoch:5 step:4884 [D loss: 0.230220, acc.: 59.38%] [G loss: 0.303430]\n",
      "epoch:5 step:4885 [D loss: 0.229103, acc.: 61.72%] [G loss: 0.300586]\n",
      "epoch:5 step:4886 [D loss: 0.245062, acc.: 58.59%] [G loss: 0.275578]\n",
      "epoch:5 step:4887 [D loss: 0.242056, acc.: 56.25%] [G loss: 0.286788]\n",
      "epoch:5 step:4888 [D loss: 0.233992, acc.: 58.59%] [G loss: 0.305707]\n",
      "epoch:5 step:4889 [D loss: 0.251611, acc.: 56.25%] [G loss: 0.285669]\n",
      "epoch:5 step:4890 [D loss: 0.229905, acc.: 62.50%] [G loss: 0.298061]\n",
      "epoch:5 step:4891 [D loss: 0.249086, acc.: 57.81%] [G loss: 0.317774]\n",
      "epoch:5 step:4892 [D loss: 0.233938, acc.: 60.94%] [G loss: 0.304665]\n",
      "epoch:5 step:4893 [D loss: 0.235778, acc.: 59.38%] [G loss: 0.316479]\n",
      "epoch:5 step:4894 [D loss: 0.250149, acc.: 54.69%] [G loss: 0.303479]\n",
      "epoch:5 step:4895 [D loss: 0.238576, acc.: 57.81%] [G loss: 0.290267]\n",
      "epoch:5 step:4896 [D loss: 0.241850, acc.: 57.81%] [G loss: 0.292736]\n",
      "epoch:5 step:4897 [D loss: 0.228737, acc.: 63.28%] [G loss: 0.321122]\n",
      "epoch:5 step:4898 [D loss: 0.255791, acc.: 53.12%] [G loss: 0.282427]\n",
      "epoch:5 step:4899 [D loss: 0.260104, acc.: 47.66%] [G loss: 0.328063]\n",
      "epoch:5 step:4900 [D loss: 0.243852, acc.: 50.00%] [G loss: 0.308238]\n",
      "epoch:5 step:4901 [D loss: 0.235950, acc.: 63.28%] [G loss: 0.307160]\n",
      "epoch:5 step:4902 [D loss: 0.235354, acc.: 64.06%] [G loss: 0.295496]\n",
      "epoch:5 step:4903 [D loss: 0.270140, acc.: 47.66%] [G loss: 0.272343]\n",
      "epoch:5 step:4904 [D loss: 0.252871, acc.: 57.03%] [G loss: 0.298566]\n",
      "epoch:5 step:4905 [D loss: 0.217537, acc.: 64.84%] [G loss: 0.304058]\n",
      "epoch:5 step:4906 [D loss: 0.244015, acc.: 59.38%] [G loss: 0.295098]\n",
      "epoch:5 step:4907 [D loss: 0.254756, acc.: 49.22%] [G loss: 0.283417]\n",
      "epoch:5 step:4908 [D loss: 0.227598, acc.: 59.38%] [G loss: 0.317253]\n",
      "epoch:5 step:4909 [D loss: 0.248038, acc.: 54.69%] [G loss: 0.292220]\n",
      "epoch:5 step:4910 [D loss: 0.244421, acc.: 53.12%] [G loss: 0.290170]\n",
      "epoch:5 step:4911 [D loss: 0.252912, acc.: 54.69%] [G loss: 0.292024]\n",
      "epoch:5 step:4912 [D loss: 0.242496, acc.: 55.47%] [G loss: 0.295597]\n",
      "epoch:5 step:4913 [D loss: 0.226563, acc.: 66.41%] [G loss: 0.315547]\n",
      "epoch:5 step:4914 [D loss: 0.240620, acc.: 61.72%] [G loss: 0.320236]\n",
      "epoch:5 step:4915 [D loss: 0.243218, acc.: 55.47%] [G loss: 0.312911]\n",
      "epoch:5 step:4916 [D loss: 0.233653, acc.: 59.38%] [G loss: 0.274067]\n",
      "epoch:5 step:4917 [D loss: 0.247459, acc.: 53.91%] [G loss: 0.307567]\n",
      "epoch:5 step:4918 [D loss: 0.234437, acc.: 57.81%] [G loss: 0.310508]\n",
      "epoch:5 step:4919 [D loss: 0.263217, acc.: 52.34%] [G loss: 0.300636]\n",
      "epoch:5 step:4920 [D loss: 0.255018, acc.: 53.12%] [G loss: 0.309420]\n",
      "epoch:5 step:4921 [D loss: 0.234028, acc.: 60.16%] [G loss: 0.313453]\n",
      "epoch:5 step:4922 [D loss: 0.246004, acc.: 55.47%] [G loss: 0.308346]\n",
      "epoch:5 step:4923 [D loss: 0.276698, acc.: 44.53%] [G loss: 0.269453]\n",
      "epoch:5 step:4924 [D loss: 0.251685, acc.: 56.25%] [G loss: 0.312851]\n",
      "epoch:5 step:4925 [D loss: 0.237008, acc.: 61.72%] [G loss: 0.297669]\n",
      "epoch:5 step:4926 [D loss: 0.245311, acc.: 60.16%] [G loss: 0.284765]\n",
      "epoch:5 step:4927 [D loss: 0.239502, acc.: 62.50%] [G loss: 0.299215]\n",
      "epoch:5 step:4928 [D loss: 0.254424, acc.: 54.69%] [G loss: 0.319076]\n",
      "epoch:5 step:4929 [D loss: 0.252248, acc.: 53.12%] [G loss: 0.293755]\n",
      "epoch:5 step:4930 [D loss: 0.244827, acc.: 58.59%] [G loss: 0.319030]\n",
      "epoch:5 step:4931 [D loss: 0.253211, acc.: 54.69%] [G loss: 0.305214]\n",
      "epoch:5 step:4932 [D loss: 0.239208, acc.: 57.81%] [G loss: 0.279454]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:5 step:4933 [D loss: 0.258630, acc.: 51.56%] [G loss: 0.292531]\n",
      "epoch:5 step:4934 [D loss: 0.247177, acc.: 57.03%] [G loss: 0.297891]\n",
      "epoch:5 step:4935 [D loss: 0.250875, acc.: 54.69%] [G loss: 0.299560]\n",
      "epoch:5 step:4936 [D loss: 0.254170, acc.: 52.34%] [G loss: 0.312073]\n",
      "epoch:5 step:4937 [D loss: 0.231303, acc.: 60.94%] [G loss: 0.285285]\n",
      "epoch:5 step:4938 [D loss: 0.249221, acc.: 53.12%] [G loss: 0.309289]\n",
      "epoch:5 step:4939 [D loss: 0.240649, acc.: 56.25%] [G loss: 0.290939]\n",
      "epoch:5 step:4940 [D loss: 0.230159, acc.: 67.19%] [G loss: 0.335802]\n",
      "epoch:5 step:4941 [D loss: 0.234187, acc.: 57.81%] [G loss: 0.292467]\n",
      "epoch:5 step:4942 [D loss: 0.241490, acc.: 57.03%] [G loss: 0.312228]\n",
      "epoch:5 step:4943 [D loss: 0.253970, acc.: 53.12%] [G loss: 0.317191]\n",
      "epoch:5 step:4944 [D loss: 0.231706, acc.: 67.97%] [G loss: 0.326789]\n",
      "epoch:5 step:4945 [D loss: 0.239394, acc.: 61.72%] [G loss: 0.321173]\n",
      "epoch:5 step:4946 [D loss: 0.253297, acc.: 48.44%] [G loss: 0.306866]\n",
      "epoch:5 step:4947 [D loss: 0.233280, acc.: 64.84%] [G loss: 0.333986]\n",
      "epoch:5 step:4948 [D loss: 0.275012, acc.: 48.44%] [G loss: 0.282844]\n",
      "epoch:5 step:4949 [D loss: 0.239634, acc.: 59.38%] [G loss: 0.323964]\n",
      "epoch:5 step:4950 [D loss: 0.233569, acc.: 61.72%] [G loss: 0.314356]\n",
      "epoch:5 step:4951 [D loss: 0.246990, acc.: 57.81%] [G loss: 0.290852]\n",
      "epoch:5 step:4952 [D loss: 0.233339, acc.: 60.94%] [G loss: 0.320438]\n",
      "epoch:5 step:4953 [D loss: 0.242499, acc.: 53.91%] [G loss: 0.295478]\n",
      "epoch:5 step:4954 [D loss: 0.249613, acc.: 55.47%] [G loss: 0.332495]\n",
      "epoch:5 step:4955 [D loss: 0.225362, acc.: 59.38%] [G loss: 0.303948]\n",
      "epoch:5 step:4956 [D loss: 0.243469, acc.: 54.69%] [G loss: 0.303096]\n",
      "epoch:5 step:4957 [D loss: 0.232713, acc.: 62.50%] [G loss: 0.288532]\n",
      "epoch:5 step:4958 [D loss: 0.247936, acc.: 57.03%] [G loss: 0.279376]\n",
      "epoch:5 step:4959 [D loss: 0.222554, acc.: 64.84%] [G loss: 0.316778]\n",
      "epoch:5 step:4960 [D loss: 0.261877, acc.: 53.12%] [G loss: 0.311962]\n",
      "epoch:5 step:4961 [D loss: 0.254356, acc.: 50.78%] [G loss: 0.326330]\n",
      "epoch:5 step:4962 [D loss: 0.239254, acc.: 59.38%] [G loss: 0.299471]\n",
      "epoch:5 step:4963 [D loss: 0.277840, acc.: 46.09%] [G loss: 0.267156]\n",
      "epoch:5 step:4964 [D loss: 0.264238, acc.: 52.34%] [G loss: 0.315039]\n",
      "epoch:5 step:4965 [D loss: 0.242737, acc.: 57.03%] [G loss: 0.304950]\n",
      "epoch:5 step:4966 [D loss: 0.237836, acc.: 60.94%] [G loss: 0.292241]\n",
      "epoch:5 step:4967 [D loss: 0.233727, acc.: 65.62%] [G loss: 0.306987]\n",
      "epoch:5 step:4968 [D loss: 0.235260, acc.: 59.38%] [G loss: 0.314918]\n",
      "epoch:5 step:4969 [D loss: 0.243816, acc.: 58.59%] [G loss: 0.286482]\n",
      "epoch:5 step:4970 [D loss: 0.245674, acc.: 55.47%] [G loss: 0.306159]\n",
      "epoch:5 step:4971 [D loss: 0.236524, acc.: 60.16%] [G loss: 0.296800]\n",
      "epoch:5 step:4972 [D loss: 0.252446, acc.: 50.78%] [G loss: 0.289423]\n",
      "epoch:5 step:4973 [D loss: 0.230048, acc.: 61.72%] [G loss: 0.302500]\n",
      "epoch:5 step:4974 [D loss: 0.249825, acc.: 55.47%] [G loss: 0.277547]\n",
      "epoch:5 step:4975 [D loss: 0.244099, acc.: 55.47%] [G loss: 0.291093]\n",
      "epoch:5 step:4976 [D loss: 0.242840, acc.: 55.47%] [G loss: 0.323311]\n",
      "epoch:5 step:4977 [D loss: 0.256712, acc.: 50.78%] [G loss: 0.304026]\n",
      "epoch:5 step:4978 [D loss: 0.248037, acc.: 52.34%] [G loss: 0.296606]\n",
      "epoch:5 step:4979 [D loss: 0.258511, acc.: 50.00%] [G loss: 0.307109]\n",
      "epoch:5 step:4980 [D loss: 0.252364, acc.: 57.81%] [G loss: 0.295810]\n",
      "epoch:5 step:4981 [D loss: 0.230463, acc.: 60.16%] [G loss: 0.308563]\n",
      "epoch:5 step:4982 [D loss: 0.226990, acc.: 60.94%] [G loss: 0.298902]\n",
      "epoch:5 step:4983 [D loss: 0.252941, acc.: 51.56%] [G loss: 0.290800]\n",
      "epoch:5 step:4984 [D loss: 0.244268, acc.: 58.59%] [G loss: 0.269171]\n",
      "epoch:5 step:4985 [D loss: 0.249722, acc.: 54.69%] [G loss: 0.303234]\n",
      "epoch:5 step:4986 [D loss: 0.235926, acc.: 60.16%] [G loss: 0.309985]\n",
      "epoch:5 step:4987 [D loss: 0.235171, acc.: 60.16%] [G loss: 0.314799]\n",
      "epoch:5 step:4988 [D loss: 0.247088, acc.: 59.38%] [G loss: 0.316154]\n",
      "epoch:5 step:4989 [D loss: 0.254135, acc.: 51.56%] [G loss: 0.274983]\n",
      "epoch:5 step:4990 [D loss: 0.221708, acc.: 67.19%] [G loss: 0.304499]\n",
      "epoch:5 step:4991 [D loss: 0.242064, acc.: 57.81%] [G loss: 0.315647]\n",
      "epoch:5 step:4992 [D loss: 0.259231, acc.: 50.78%] [G loss: 0.307150]\n",
      "epoch:5 step:4993 [D loss: 0.240328, acc.: 57.81%] [G loss: 0.291086]\n",
      "epoch:5 step:4994 [D loss: 0.239013, acc.: 61.72%] [G loss: 0.307378]\n",
      "epoch:5 step:4995 [D loss: 0.258625, acc.: 54.69%] [G loss: 0.324281]\n",
      "epoch:5 step:4996 [D loss: 0.231392, acc.: 60.94%] [G loss: 0.329677]\n",
      "epoch:5 step:4997 [D loss: 0.254692, acc.: 55.47%] [G loss: 0.335676]\n",
      "epoch:5 step:4998 [D loss: 0.247221, acc.: 57.03%] [G loss: 0.281420]\n",
      "epoch:5 step:4999 [D loss: 0.232333, acc.: 60.94%] [G loss: 0.292367]\n",
      "epoch:5 step:5000 [D loss: 0.232522, acc.: 62.50%] [G loss: 0.306804]\n",
      "epoch:5 step:5001 [D loss: 0.274235, acc.: 49.22%] [G loss: 0.295166]\n",
      "epoch:5 step:5002 [D loss: 0.265656, acc.: 46.88%] [G loss: 0.329944]\n",
      "epoch:5 step:5003 [D loss: 0.244989, acc.: 59.38%] [G loss: 0.295832]\n",
      "epoch:5 step:5004 [D loss: 0.230970, acc.: 60.16%] [G loss: 0.320791]\n",
      "epoch:5 step:5005 [D loss: 0.241769, acc.: 58.59%] [G loss: 0.304390]\n",
      "epoch:5 step:5006 [D loss: 0.246134, acc.: 55.47%] [G loss: 0.337988]\n",
      "epoch:5 step:5007 [D loss: 0.243216, acc.: 56.25%] [G loss: 0.315161]\n",
      "epoch:5 step:5008 [D loss: 0.239442, acc.: 60.94%] [G loss: 0.314613]\n",
      "epoch:5 step:5009 [D loss: 0.249852, acc.: 53.12%] [G loss: 0.277806]\n",
      "epoch:5 step:5010 [D loss: 0.220167, acc.: 67.97%] [G loss: 0.298784]\n",
      "epoch:5 step:5011 [D loss: 0.243535, acc.: 57.81%] [G loss: 0.301182]\n",
      "epoch:5 step:5012 [D loss: 0.254219, acc.: 50.78%] [G loss: 0.284125]\n",
      "epoch:5 step:5013 [D loss: 0.249862, acc.: 56.25%] [G loss: 0.320869]\n",
      "epoch:5 step:5014 [D loss: 0.244741, acc.: 55.47%] [G loss: 0.317149]\n",
      "epoch:5 step:5015 [D loss: 0.253574, acc.: 53.12%] [G loss: 0.307165]\n",
      "epoch:5 step:5016 [D loss: 0.238827, acc.: 59.38%] [G loss: 0.283761]\n",
      "epoch:5 step:5017 [D loss: 0.236783, acc.: 62.50%] [G loss: 0.315655]\n",
      "epoch:5 step:5018 [D loss: 0.247699, acc.: 52.34%] [G loss: 0.302842]\n",
      "epoch:5 step:5019 [D loss: 0.245387, acc.: 55.47%] [G loss: 0.281220]\n",
      "epoch:5 step:5020 [D loss: 0.252405, acc.: 61.72%] [G loss: 0.280792]\n",
      "epoch:5 step:5021 [D loss: 0.229574, acc.: 60.16%] [G loss: 0.317400]\n",
      "epoch:5 step:5022 [D loss: 0.228252, acc.: 62.50%] [G loss: 0.314487]\n",
      "epoch:5 step:5023 [D loss: 0.247386, acc.: 55.47%] [G loss: 0.298439]\n",
      "epoch:5 step:5024 [D loss: 0.240090, acc.: 57.03%] [G loss: 0.286767]\n",
      "epoch:5 step:5025 [D loss: 0.233518, acc.: 60.94%] [G loss: 0.331350]\n",
      "epoch:5 step:5026 [D loss: 0.227575, acc.: 64.84%] [G loss: 0.347262]\n",
      "epoch:5 step:5027 [D loss: 0.249951, acc.: 50.78%] [G loss: 0.274215]\n",
      "epoch:5 step:5028 [D loss: 0.225679, acc.: 60.16%] [G loss: 0.294166]\n",
      "epoch:5 step:5029 [D loss: 0.238887, acc.: 58.59%] [G loss: 0.315572]\n",
      "epoch:5 step:5030 [D loss: 0.236583, acc.: 58.59%] [G loss: 0.319349]\n",
      "epoch:5 step:5031 [D loss: 0.264262, acc.: 51.56%] [G loss: 0.294689]\n",
      "epoch:5 step:5032 [D loss: 0.240001, acc.: 57.81%] [G loss: 0.300534]\n",
      "epoch:5 step:5033 [D loss: 0.242013, acc.: 57.81%] [G loss: 0.300488]\n",
      "epoch:5 step:5034 [D loss: 0.237841, acc.: 60.16%] [G loss: 0.330460]\n",
      "epoch:5 step:5035 [D loss: 0.229769, acc.: 60.94%] [G loss: 0.312529]\n",
      "epoch:5 step:5036 [D loss: 0.251611, acc.: 57.03%] [G loss: 0.312512]\n",
      "epoch:5 step:5037 [D loss: 0.237747, acc.: 56.25%] [G loss: 0.283856]\n",
      "epoch:5 step:5038 [D loss: 0.240918, acc.: 52.34%] [G loss: 0.305850]\n",
      "epoch:5 step:5039 [D loss: 0.240270, acc.: 65.62%] [G loss: 0.319125]\n",
      "epoch:5 step:5040 [D loss: 0.240259, acc.: 58.59%] [G loss: 0.273396]\n",
      "epoch:5 step:5041 [D loss: 0.230509, acc.: 66.41%] [G loss: 0.281854]\n",
      "epoch:5 step:5042 [D loss: 0.246750, acc.: 55.47%] [G loss: 0.281077]\n",
      "epoch:5 step:5043 [D loss: 0.238869, acc.: 57.81%] [G loss: 0.306769]\n",
      "epoch:5 step:5044 [D loss: 0.248540, acc.: 60.94%] [G loss: 0.311400]\n",
      "epoch:5 step:5045 [D loss: 0.233448, acc.: 56.25%] [G loss: 0.281642]\n",
      "epoch:5 step:5046 [D loss: 0.228396, acc.: 63.28%] [G loss: 0.306456]\n",
      "epoch:5 step:5047 [D loss: 0.236263, acc.: 56.25%] [G loss: 0.303571]\n",
      "epoch:5 step:5048 [D loss: 0.229208, acc.: 64.84%] [G loss: 0.306196]\n",
      "epoch:5 step:5049 [D loss: 0.244649, acc.: 49.22%] [G loss: 0.272114]\n",
      "epoch:5 step:5050 [D loss: 0.244163, acc.: 58.59%] [G loss: 0.309756]\n",
      "epoch:5 step:5051 [D loss: 0.252915, acc.: 54.69%] [G loss: 0.305009]\n",
      "epoch:5 step:5052 [D loss: 0.246700, acc.: 54.69%] [G loss: 0.284348]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:5 step:5053 [D loss: 0.258848, acc.: 53.91%] [G loss: 0.306300]\n",
      "epoch:5 step:5054 [D loss: 0.243969, acc.: 53.12%] [G loss: 0.308320]\n",
      "epoch:5 step:5055 [D loss: 0.251391, acc.: 54.69%] [G loss: 0.285545]\n",
      "epoch:5 step:5056 [D loss: 0.249233, acc.: 57.03%] [G loss: 0.285985]\n",
      "epoch:5 step:5057 [D loss: 0.238992, acc.: 60.16%] [G loss: 0.311273]\n",
      "epoch:5 step:5058 [D loss: 0.253514, acc.: 52.34%] [G loss: 0.295920]\n",
      "epoch:5 step:5059 [D loss: 0.241648, acc.: 58.59%] [G loss: 0.304449]\n",
      "epoch:5 step:5060 [D loss: 0.248515, acc.: 50.00%] [G loss: 0.307909]\n",
      "epoch:5 step:5061 [D loss: 0.252939, acc.: 49.22%] [G loss: 0.308164]\n",
      "epoch:5 step:5062 [D loss: 0.242604, acc.: 54.69%] [G loss: 0.319590]\n",
      "epoch:5 step:5063 [D loss: 0.250741, acc.: 53.91%] [G loss: 0.282665]\n",
      "epoch:5 step:5064 [D loss: 0.245523, acc.: 57.81%] [G loss: 0.305008]\n",
      "epoch:5 step:5065 [D loss: 0.235533, acc.: 61.72%] [G loss: 0.308025]\n",
      "epoch:5 step:5066 [D loss: 0.228415, acc.: 66.41%] [G loss: 0.281625]\n",
      "epoch:5 step:5067 [D loss: 0.252486, acc.: 54.69%] [G loss: 0.269696]\n",
      "epoch:5 step:5068 [D loss: 0.253855, acc.: 53.12%] [G loss: 0.295810]\n",
      "epoch:5 step:5069 [D loss: 0.244893, acc.: 56.25%] [G loss: 0.300358]\n",
      "epoch:5 step:5070 [D loss: 0.271965, acc.: 44.53%] [G loss: 0.276085]\n",
      "epoch:5 step:5071 [D loss: 0.245907, acc.: 55.47%] [G loss: 0.294796]\n",
      "epoch:5 step:5072 [D loss: 0.228887, acc.: 57.81%] [G loss: 0.314678]\n",
      "epoch:5 step:5073 [D loss: 0.252729, acc.: 56.25%] [G loss: 0.306252]\n",
      "epoch:5 step:5074 [D loss: 0.245644, acc.: 54.69%] [G loss: 0.281150]\n",
      "epoch:5 step:5075 [D loss: 0.237185, acc.: 54.69%] [G loss: 0.284752]\n",
      "epoch:5 step:5076 [D loss: 0.241245, acc.: 60.94%] [G loss: 0.317069]\n",
      "epoch:5 step:5077 [D loss: 0.242910, acc.: 53.12%] [G loss: 0.303837]\n",
      "epoch:5 step:5078 [D loss: 0.244391, acc.: 60.94%] [G loss: 0.324796]\n",
      "epoch:5 step:5079 [D loss: 0.242391, acc.: 54.69%] [G loss: 0.316275]\n",
      "epoch:5 step:5080 [D loss: 0.234144, acc.: 61.72%] [G loss: 0.296628]\n",
      "epoch:5 step:5081 [D loss: 0.246064, acc.: 53.12%] [G loss: 0.322304]\n",
      "epoch:5 step:5082 [D loss: 0.250566, acc.: 57.03%] [G loss: 0.305471]\n",
      "epoch:5 step:5083 [D loss: 0.236478, acc.: 57.81%] [G loss: 0.322975]\n",
      "epoch:5 step:5084 [D loss: 0.220540, acc.: 69.53%] [G loss: 0.322001]\n",
      "epoch:5 step:5085 [D loss: 0.241739, acc.: 60.16%] [G loss: 0.302747]\n",
      "epoch:5 step:5086 [D loss: 0.233452, acc.: 57.81%] [G loss: 0.317076]\n",
      "epoch:5 step:5087 [D loss: 0.211034, acc.: 66.41%] [G loss: 0.299718]\n",
      "epoch:5 step:5088 [D loss: 0.246450, acc.: 55.47%] [G loss: 0.296937]\n",
      "epoch:5 step:5089 [D loss: 0.265804, acc.: 50.00%] [G loss: 0.332575]\n",
      "epoch:5 step:5090 [D loss: 0.256694, acc.: 53.12%] [G loss: 0.308816]\n",
      "epoch:5 step:5091 [D loss: 0.250025, acc.: 53.91%] [G loss: 0.285694]\n",
      "epoch:5 step:5092 [D loss: 0.237631, acc.: 60.94%] [G loss: 0.303449]\n",
      "epoch:5 step:5093 [D loss: 0.248760, acc.: 53.91%] [G loss: 0.295514]\n",
      "epoch:5 step:5094 [D loss: 0.247050, acc.: 58.59%] [G loss: 0.279808]\n",
      "epoch:5 step:5095 [D loss: 0.263987, acc.: 47.66%] [G loss: 0.293328]\n",
      "epoch:5 step:5096 [D loss: 0.251033, acc.: 53.12%] [G loss: 0.267776]\n",
      "epoch:5 step:5097 [D loss: 0.244623, acc.: 53.12%] [G loss: 0.281758]\n",
      "epoch:5 step:5098 [D loss: 0.245980, acc.: 53.12%] [G loss: 0.296510]\n",
      "epoch:5 step:5099 [D loss: 0.247317, acc.: 57.81%] [G loss: 0.299168]\n",
      "epoch:5 step:5100 [D loss: 0.253361, acc.: 54.69%] [G loss: 0.278464]\n",
      "epoch:5 step:5101 [D loss: 0.244577, acc.: 57.81%] [G loss: 0.305149]\n",
      "epoch:5 step:5102 [D loss: 0.241108, acc.: 56.25%] [G loss: 0.300875]\n",
      "epoch:5 step:5103 [D loss: 0.246402, acc.: 57.81%] [G loss: 0.315981]\n",
      "epoch:5 step:5104 [D loss: 0.242799, acc.: 64.06%] [G loss: 0.309327]\n",
      "epoch:5 step:5105 [D loss: 0.250888, acc.: 48.44%] [G loss: 0.284003]\n",
      "epoch:5 step:5106 [D loss: 0.244952, acc.: 57.81%] [G loss: 0.297580]\n",
      "epoch:5 step:5107 [D loss: 0.235734, acc.: 60.94%] [G loss: 0.278025]\n",
      "epoch:5 step:5108 [D loss: 0.225977, acc.: 60.94%] [G loss: 0.349457]\n",
      "epoch:5 step:5109 [D loss: 0.227755, acc.: 60.16%] [G loss: 0.305455]\n",
      "epoch:5 step:5110 [D loss: 0.238080, acc.: 61.72%] [G loss: 0.311996]\n",
      "epoch:5 step:5111 [D loss: 0.250515, acc.: 57.81%] [G loss: 0.308209]\n",
      "epoch:5 step:5112 [D loss: 0.252251, acc.: 53.91%] [G loss: 0.284110]\n",
      "epoch:5 step:5113 [D loss: 0.248453, acc.: 56.25%] [G loss: 0.290844]\n",
      "epoch:5 step:5114 [D loss: 0.241127, acc.: 57.81%] [G loss: 0.293303]\n",
      "epoch:5 step:5115 [D loss: 0.257847, acc.: 51.56%] [G loss: 0.310620]\n",
      "epoch:5 step:5116 [D loss: 0.254948, acc.: 50.78%] [G loss: 0.291079]\n",
      "epoch:5 step:5117 [D loss: 0.251916, acc.: 53.12%] [G loss: 0.284183]\n",
      "epoch:5 step:5118 [D loss: 0.243577, acc.: 60.16%] [G loss: 0.307287]\n",
      "epoch:5 step:5119 [D loss: 0.249984, acc.: 58.59%] [G loss: 0.303904]\n",
      "epoch:5 step:5120 [D loss: 0.245287, acc.: 58.59%] [G loss: 0.291053]\n",
      "epoch:5 step:5121 [D loss: 0.269296, acc.: 50.78%] [G loss: 0.290207]\n",
      "epoch:5 step:5122 [D loss: 0.252887, acc.: 53.91%] [G loss: 0.273603]\n",
      "epoch:5 step:5123 [D loss: 0.236929, acc.: 60.16%] [G loss: 0.279871]\n",
      "epoch:5 step:5124 [D loss: 0.245268, acc.: 58.59%] [G loss: 0.290642]\n",
      "epoch:5 step:5125 [D loss: 0.241634, acc.: 51.56%] [G loss: 0.310161]\n",
      "epoch:5 step:5126 [D loss: 0.235376, acc.: 58.59%] [G loss: 0.320040]\n",
      "epoch:5 step:5127 [D loss: 0.249507, acc.: 53.12%] [G loss: 0.336021]\n",
      "epoch:5 step:5128 [D loss: 0.246653, acc.: 58.59%] [G loss: 0.290042]\n",
      "epoch:5 step:5129 [D loss: 0.251757, acc.: 50.78%] [G loss: 0.319653]\n",
      "epoch:5 step:5130 [D loss: 0.250975, acc.: 53.12%] [G loss: 0.275161]\n",
      "epoch:5 step:5131 [D loss: 0.245618, acc.: 54.69%] [G loss: 0.319675]\n",
      "epoch:5 step:5132 [D loss: 0.220052, acc.: 67.19%] [G loss: 0.333880]\n",
      "epoch:5 step:5133 [D loss: 0.247089, acc.: 56.25%] [G loss: 0.294852]\n",
      "epoch:5 step:5134 [D loss: 0.230201, acc.: 64.06%] [G loss: 0.324394]\n",
      "epoch:5 step:5135 [D loss: 0.258578, acc.: 51.56%] [G loss: 0.284219]\n",
      "epoch:5 step:5136 [D loss: 0.227746, acc.: 63.28%] [G loss: 0.314467]\n",
      "epoch:5 step:5137 [D loss: 0.266122, acc.: 50.78%] [G loss: 0.306946]\n",
      "epoch:5 step:5138 [D loss: 0.239418, acc.: 57.03%] [G loss: 0.305628]\n",
      "epoch:5 step:5139 [D loss: 0.245776, acc.: 58.59%] [G loss: 0.312849]\n",
      "epoch:5 step:5140 [D loss: 0.244769, acc.: 54.69%] [G loss: 0.338236]\n",
      "epoch:5 step:5141 [D loss: 0.224835, acc.: 62.50%] [G loss: 0.331598]\n",
      "epoch:5 step:5142 [D loss: 0.238012, acc.: 56.25%] [G loss: 0.320748]\n",
      "epoch:5 step:5143 [D loss: 0.243211, acc.: 56.25%] [G loss: 0.315174]\n",
      "epoch:5 step:5144 [D loss: 0.232898, acc.: 57.81%] [G loss: 0.315469]\n",
      "epoch:5 step:5145 [D loss: 0.227577, acc.: 59.38%] [G loss: 0.321759]\n",
      "epoch:5 step:5146 [D loss: 0.226268, acc.: 61.72%] [G loss: 0.297800]\n",
      "epoch:5 step:5147 [D loss: 0.247369, acc.: 57.81%] [G loss: 0.304531]\n",
      "epoch:5 step:5148 [D loss: 0.258875, acc.: 49.22%] [G loss: 0.310134]\n",
      "epoch:5 step:5149 [D loss: 0.253729, acc.: 57.03%] [G loss: 0.301056]\n",
      "epoch:5 step:5150 [D loss: 0.235968, acc.: 56.25%] [G loss: 0.280742]\n",
      "epoch:5 step:5151 [D loss: 0.245060, acc.: 59.38%] [G loss: 0.290483]\n",
      "epoch:5 step:5152 [D loss: 0.239694, acc.: 55.47%] [G loss: 0.300849]\n",
      "epoch:5 step:5153 [D loss: 0.261364, acc.: 51.56%] [G loss: 0.290308]\n",
      "epoch:5 step:5154 [D loss: 0.235796, acc.: 60.16%] [G loss: 0.293470]\n",
      "epoch:5 step:5155 [D loss: 0.260884, acc.: 50.00%] [G loss: 0.281030]\n",
      "epoch:5 step:5156 [D loss: 0.258379, acc.: 49.22%] [G loss: 0.299520]\n",
      "epoch:5 step:5157 [D loss: 0.235383, acc.: 61.72%] [G loss: 0.327125]\n",
      "epoch:5 step:5158 [D loss: 0.242932, acc.: 55.47%] [G loss: 0.291759]\n",
      "epoch:5 step:5159 [D loss: 0.221993, acc.: 63.28%] [G loss: 0.306142]\n",
      "epoch:5 step:5160 [D loss: 0.232767, acc.: 61.72%] [G loss: 0.293258]\n",
      "epoch:5 step:5161 [D loss: 0.252465, acc.: 51.56%] [G loss: 0.298296]\n",
      "epoch:5 step:5162 [D loss: 0.263431, acc.: 46.09%] [G loss: 0.290910]\n",
      "epoch:5 step:5163 [D loss: 0.246487, acc.: 57.03%] [G loss: 0.316509]\n",
      "epoch:5 step:5164 [D loss: 0.237562, acc.: 64.06%] [G loss: 0.323725]\n",
      "epoch:5 step:5165 [D loss: 0.248096, acc.: 56.25%] [G loss: 0.284284]\n",
      "epoch:5 step:5166 [D loss: 0.256673, acc.: 54.69%] [G loss: 0.314787]\n",
      "epoch:5 step:5167 [D loss: 0.244016, acc.: 57.81%] [G loss: 0.287682]\n",
      "epoch:5 step:5168 [D loss: 0.258182, acc.: 48.44%] [G loss: 0.302562]\n",
      "epoch:5 step:5169 [D loss: 0.225375, acc.: 64.06%] [G loss: 0.298885]\n",
      "epoch:5 step:5170 [D loss: 0.247035, acc.: 54.69%] [G loss: 0.297954]\n",
      "epoch:5 step:5171 [D loss: 0.233703, acc.: 62.50%] [G loss: 0.281067]\n",
      "epoch:5 step:5172 [D loss: 0.254315, acc.: 56.25%] [G loss: 0.280475]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:5 step:5173 [D loss: 0.251326, acc.: 53.91%] [G loss: 0.294764]\n",
      "epoch:5 step:5174 [D loss: 0.255107, acc.: 52.34%] [G loss: 0.316434]\n",
      "epoch:5 step:5175 [D loss: 0.237023, acc.: 64.84%] [G loss: 0.326274]\n",
      "epoch:5 step:5176 [D loss: 0.235473, acc.: 59.38%] [G loss: 0.329103]\n",
      "epoch:5 step:5177 [D loss: 0.261670, acc.: 46.88%] [G loss: 0.301088]\n",
      "epoch:5 step:5178 [D loss: 0.247455, acc.: 60.94%] [G loss: 0.290080]\n",
      "epoch:5 step:5179 [D loss: 0.244954, acc.: 61.72%] [G loss: 0.295197]\n",
      "epoch:5 step:5180 [D loss: 0.242465, acc.: 57.03%] [G loss: 0.305083]\n",
      "epoch:5 step:5181 [D loss: 0.241739, acc.: 57.03%] [G loss: 0.319857]\n",
      "epoch:5 step:5182 [D loss: 0.245523, acc.: 53.12%] [G loss: 0.278182]\n",
      "epoch:5 step:5183 [D loss: 0.240439, acc.: 60.94%] [G loss: 0.302242]\n",
      "epoch:5 step:5184 [D loss: 0.231716, acc.: 60.16%] [G loss: 0.305681]\n",
      "epoch:5 step:5185 [D loss: 0.235073, acc.: 59.38%] [G loss: 0.322592]\n",
      "epoch:5 step:5186 [D loss: 0.227240, acc.: 63.28%] [G loss: 0.335296]\n",
      "epoch:5 step:5187 [D loss: 0.224889, acc.: 61.72%] [G loss: 0.292487]\n",
      "epoch:5 step:5188 [D loss: 0.230917, acc.: 57.81%] [G loss: 0.312420]\n",
      "epoch:5 step:5189 [D loss: 0.242065, acc.: 60.94%] [G loss: 0.298873]\n",
      "epoch:5 step:5190 [D loss: 0.234962, acc.: 59.38%] [G loss: 0.292809]\n",
      "epoch:5 step:5191 [D loss: 0.248683, acc.: 57.03%] [G loss: 0.292646]\n",
      "epoch:5 step:5192 [D loss: 0.239601, acc.: 61.72%] [G loss: 0.281047]\n",
      "epoch:5 step:5193 [D loss: 0.241206, acc.: 56.25%] [G loss: 0.310435]\n",
      "epoch:5 step:5194 [D loss: 0.229963, acc.: 60.16%] [G loss: 0.289830]\n",
      "epoch:5 step:5195 [D loss: 0.236233, acc.: 56.25%] [G loss: 0.311304]\n",
      "epoch:5 step:5196 [D loss: 0.233245, acc.: 59.38%] [G loss: 0.347921]\n",
      "epoch:5 step:5197 [D loss: 0.246930, acc.: 56.25%] [G loss: 0.299311]\n",
      "epoch:5 step:5198 [D loss: 0.253462, acc.: 53.12%] [G loss: 0.315113]\n",
      "epoch:5 step:5199 [D loss: 0.249834, acc.: 54.69%] [G loss: 0.314402]\n",
      "epoch:5 step:5200 [D loss: 0.247598, acc.: 55.47%] [G loss: 0.307996]\n",
      "epoch:5 step:5201 [D loss: 0.252708, acc.: 53.12%] [G loss: 0.308151]\n",
      "epoch:5 step:5202 [D loss: 0.250002, acc.: 56.25%] [G loss: 0.292613]\n",
      "epoch:5 step:5203 [D loss: 0.238614, acc.: 58.59%] [G loss: 0.337427]\n",
      "epoch:5 step:5204 [D loss: 0.240545, acc.: 55.47%] [G loss: 0.315071]\n",
      "epoch:5 step:5205 [D loss: 0.229969, acc.: 64.84%] [G loss: 0.302204]\n",
      "epoch:5 step:5206 [D loss: 0.240138, acc.: 60.94%] [G loss: 0.299608]\n",
      "epoch:5 step:5207 [D loss: 0.240125, acc.: 57.81%] [G loss: 0.311313]\n",
      "epoch:5 step:5208 [D loss: 0.235674, acc.: 58.59%] [G loss: 0.317628]\n",
      "epoch:5 step:5209 [D loss: 0.248105, acc.: 55.47%] [G loss: 0.299417]\n",
      "epoch:5 step:5210 [D loss: 0.239619, acc.: 60.16%] [G loss: 0.306600]\n",
      "epoch:5 step:5211 [D loss: 0.254974, acc.: 50.78%] [G loss: 0.290153]\n",
      "epoch:5 step:5212 [D loss: 0.262773, acc.: 50.00%] [G loss: 0.289012]\n",
      "epoch:5 step:5213 [D loss: 0.251430, acc.: 56.25%] [G loss: 0.295559]\n",
      "epoch:5 step:5214 [D loss: 0.254674, acc.: 50.00%] [G loss: 0.312501]\n",
      "epoch:5 step:5215 [D loss: 0.226861, acc.: 65.62%] [G loss: 0.311827]\n",
      "epoch:5 step:5216 [D loss: 0.236972, acc.: 60.94%] [G loss: 0.342591]\n",
      "epoch:5 step:5217 [D loss: 0.257054, acc.: 52.34%] [G loss: 0.301262]\n",
      "epoch:5 step:5218 [D loss: 0.265124, acc.: 50.78%] [G loss: 0.317600]\n",
      "epoch:5 step:5219 [D loss: 0.254006, acc.: 50.78%] [G loss: 0.308580]\n",
      "epoch:5 step:5220 [D loss: 0.240517, acc.: 57.03%] [G loss: 0.316305]\n",
      "epoch:5 step:5221 [D loss: 0.249509, acc.: 53.12%] [G loss: 0.297026]\n",
      "epoch:5 step:5222 [D loss: 0.246191, acc.: 53.12%] [G loss: 0.326561]\n",
      "epoch:5 step:5223 [D loss: 0.236393, acc.: 60.16%] [G loss: 0.283807]\n",
      "epoch:5 step:5224 [D loss: 0.238417, acc.: 58.59%] [G loss: 0.329454]\n",
      "epoch:5 step:5225 [D loss: 0.225331, acc.: 60.94%] [G loss: 0.349173]\n",
      "epoch:5 step:5226 [D loss: 0.243115, acc.: 59.38%] [G loss: 0.329849]\n",
      "epoch:5 step:5227 [D loss: 0.239176, acc.: 57.03%] [G loss: 0.317809]\n",
      "epoch:5 step:5228 [D loss: 0.242593, acc.: 55.47%] [G loss: 0.316117]\n",
      "epoch:5 step:5229 [D loss: 0.249642, acc.: 51.56%] [G loss: 0.310783]\n",
      "epoch:5 step:5230 [D loss: 0.241402, acc.: 54.69%] [G loss: 0.307271]\n",
      "epoch:5 step:5231 [D loss: 0.237638, acc.: 59.38%] [G loss: 0.312461]\n",
      "epoch:5 step:5232 [D loss: 0.244837, acc.: 58.59%] [G loss: 0.316624]\n",
      "epoch:5 step:5233 [D loss: 0.239054, acc.: 57.81%] [G loss: 0.322889]\n",
      "epoch:5 step:5234 [D loss: 0.233751, acc.: 58.59%] [G loss: 0.309326]\n",
      "epoch:5 step:5235 [D loss: 0.240839, acc.: 57.81%] [G loss: 0.318402]\n",
      "epoch:5 step:5236 [D loss: 0.236473, acc.: 57.81%] [G loss: 0.321938]\n",
      "epoch:5 step:5237 [D loss: 0.225336, acc.: 67.19%] [G loss: 0.290413]\n",
      "epoch:5 step:5238 [D loss: 0.237004, acc.: 60.16%] [G loss: 0.303360]\n",
      "epoch:5 step:5239 [D loss: 0.232933, acc.: 61.72%] [G loss: 0.310692]\n",
      "epoch:5 step:5240 [D loss: 0.247207, acc.: 57.03%] [G loss: 0.282119]\n",
      "epoch:5 step:5241 [D loss: 0.224284, acc.: 64.84%] [G loss: 0.297415]\n",
      "epoch:5 step:5242 [D loss: 0.226145, acc.: 62.50%] [G loss: 0.295193]\n",
      "epoch:5 step:5243 [D loss: 0.243838, acc.: 61.72%] [G loss: 0.292744]\n",
      "epoch:5 step:5244 [D loss: 0.246286, acc.: 54.69%] [G loss: 0.276083]\n",
      "epoch:5 step:5245 [D loss: 0.245851, acc.: 53.91%] [G loss: 0.337120]\n",
      "epoch:5 step:5246 [D loss: 0.242043, acc.: 57.03%] [G loss: 0.295103]\n",
      "epoch:5 step:5247 [D loss: 0.262371, acc.: 49.22%] [G loss: 0.289961]\n",
      "epoch:5 step:5248 [D loss: 0.251015, acc.: 51.56%] [G loss: 0.287833]\n",
      "epoch:5 step:5249 [D loss: 0.244570, acc.: 58.59%] [G loss: 0.286797]\n",
      "epoch:5 step:5250 [D loss: 0.247304, acc.: 51.56%] [G loss: 0.297824]\n",
      "epoch:5 step:5251 [D loss: 0.240000, acc.: 62.50%] [G loss: 0.302177]\n",
      "epoch:5 step:5252 [D loss: 0.245787, acc.: 57.03%] [G loss: 0.288434]\n",
      "epoch:5 step:5253 [D loss: 0.232430, acc.: 54.69%] [G loss: 0.330118]\n",
      "epoch:5 step:5254 [D loss: 0.238811, acc.: 56.25%] [G loss: 0.296297]\n",
      "epoch:5 step:5255 [D loss: 0.242125, acc.: 54.69%] [G loss: 0.291710]\n",
      "epoch:5 step:5256 [D loss: 0.254192, acc.: 46.09%] [G loss: 0.270269]\n",
      "epoch:5 step:5257 [D loss: 0.224775, acc.: 61.72%] [G loss: 0.317116]\n",
      "epoch:5 step:5258 [D loss: 0.255442, acc.: 53.12%] [G loss: 0.297973]\n",
      "epoch:5 step:5259 [D loss: 0.230373, acc.: 59.38%] [G loss: 0.318340]\n",
      "epoch:5 step:5260 [D loss: 0.246300, acc.: 58.59%] [G loss: 0.309884]\n",
      "epoch:5 step:5261 [D loss: 0.236805, acc.: 57.03%] [G loss: 0.301581]\n",
      "epoch:5 step:5262 [D loss: 0.238790, acc.: 60.16%] [G loss: 0.293497]\n",
      "epoch:5 step:5263 [D loss: 0.252870, acc.: 53.91%] [G loss: 0.286658]\n",
      "epoch:5 step:5264 [D loss: 0.251183, acc.: 56.25%] [G loss: 0.313766]\n",
      "epoch:5 step:5265 [D loss: 0.253932, acc.: 57.81%] [G loss: 0.266515]\n",
      "epoch:5 step:5266 [D loss: 0.236013, acc.: 58.59%] [G loss: 0.300286]\n",
      "epoch:5 step:5267 [D loss: 0.236420, acc.: 59.38%] [G loss: 0.325774]\n",
      "epoch:5 step:5268 [D loss: 0.242035, acc.: 54.69%] [G loss: 0.291764]\n",
      "epoch:5 step:5269 [D loss: 0.261362, acc.: 43.75%] [G loss: 0.297804]\n",
      "epoch:5 step:5270 [D loss: 0.253582, acc.: 55.47%] [G loss: 0.276224]\n",
      "epoch:5 step:5271 [D loss: 0.249706, acc.: 55.47%] [G loss: 0.278490]\n",
      "epoch:5 step:5272 [D loss: 0.238659, acc.: 60.16%] [G loss: 0.268554]\n",
      "epoch:5 step:5273 [D loss: 0.240828, acc.: 59.38%] [G loss: 0.299480]\n",
      "epoch:5 step:5274 [D loss: 0.254130, acc.: 55.47%] [G loss: 0.289812]\n",
      "epoch:5 step:5275 [D loss: 0.249905, acc.: 54.69%] [G loss: 0.325257]\n",
      "epoch:5 step:5276 [D loss: 0.247427, acc.: 57.03%] [G loss: 0.303173]\n",
      "epoch:5 step:5277 [D loss: 0.253978, acc.: 50.78%] [G loss: 0.316929]\n",
      "epoch:5 step:5278 [D loss: 0.257915, acc.: 51.56%] [G loss: 0.311029]\n",
      "epoch:5 step:5279 [D loss: 0.227116, acc.: 64.84%] [G loss: 0.319813]\n",
      "epoch:5 step:5280 [D loss: 0.245237, acc.: 55.47%] [G loss: 0.296577]\n",
      "epoch:5 step:5281 [D loss: 0.239372, acc.: 57.03%] [G loss: 0.306892]\n",
      "epoch:5 step:5282 [D loss: 0.257471, acc.: 56.25%] [G loss: 0.283186]\n",
      "epoch:5 step:5283 [D loss: 0.246969, acc.: 50.78%] [G loss: 0.277946]\n",
      "epoch:5 step:5284 [D loss: 0.244262, acc.: 57.81%] [G loss: 0.279099]\n",
      "epoch:5 step:5285 [D loss: 0.234942, acc.: 60.94%] [G loss: 0.298282]\n",
      "epoch:5 step:5286 [D loss: 0.252507, acc.: 53.12%] [G loss: 0.308061]\n",
      "epoch:5 step:5287 [D loss: 0.244034, acc.: 55.47%] [G loss: 0.316302]\n",
      "epoch:5 step:5288 [D loss: 0.239694, acc.: 54.69%] [G loss: 0.304344]\n",
      "epoch:5 step:5289 [D loss: 0.233099, acc.: 55.47%] [G loss: 0.281391]\n",
      "epoch:5 step:5290 [D loss: 0.242388, acc.: 50.78%] [G loss: 0.270482]\n",
      "epoch:5 step:5291 [D loss: 0.245683, acc.: 55.47%] [G loss: 0.320472]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:5 step:5292 [D loss: 0.244736, acc.: 56.25%] [G loss: 0.297874]\n",
      "epoch:5 step:5293 [D loss: 0.233794, acc.: 62.50%] [G loss: 0.308587]\n",
      "epoch:5 step:5294 [D loss: 0.233077, acc.: 60.94%] [G loss: 0.308507]\n",
      "epoch:5 step:5295 [D loss: 0.223082, acc.: 62.50%] [G loss: 0.329111]\n",
      "epoch:5 step:5296 [D loss: 0.238170, acc.: 57.03%] [G loss: 0.311795]\n",
      "epoch:5 step:5297 [D loss: 0.242170, acc.: 56.25%] [G loss: 0.286815]\n",
      "epoch:5 step:5298 [D loss: 0.231409, acc.: 59.38%] [G loss: 0.298142]\n",
      "epoch:5 step:5299 [D loss: 0.245223, acc.: 53.91%] [G loss: 0.312960]\n",
      "epoch:5 step:5300 [D loss: 0.241717, acc.: 57.03%] [G loss: 0.273159]\n",
      "epoch:5 step:5301 [D loss: 0.237997, acc.: 61.72%] [G loss: 0.296206]\n",
      "epoch:5 step:5302 [D loss: 0.238670, acc.: 55.47%] [G loss: 0.309336]\n",
      "epoch:5 step:5303 [D loss: 0.253429, acc.: 50.78%] [G loss: 0.304862]\n",
      "epoch:5 step:5304 [D loss: 0.233165, acc.: 60.16%] [G loss: 0.311967]\n",
      "epoch:5 step:5305 [D loss: 0.250337, acc.: 50.78%] [G loss: 0.292877]\n",
      "epoch:5 step:5306 [D loss: 0.253367, acc.: 47.66%] [G loss: 0.269315]\n",
      "epoch:5 step:5307 [D loss: 0.232625, acc.: 62.50%] [G loss: 0.334034]\n",
      "epoch:5 step:5308 [D loss: 0.250812, acc.: 53.12%] [G loss: 0.268938]\n",
      "epoch:5 step:5309 [D loss: 0.235191, acc.: 64.06%] [G loss: 0.333158]\n",
      "epoch:5 step:5310 [D loss: 0.258054, acc.: 53.91%] [G loss: 0.302174]\n",
      "epoch:5 step:5311 [D loss: 0.256746, acc.: 50.78%] [G loss: 0.273572]\n",
      "epoch:5 step:5312 [D loss: 0.241171, acc.: 54.69%] [G loss: 0.302085]\n",
      "epoch:5 step:5313 [D loss: 0.253278, acc.: 56.25%] [G loss: 0.312167]\n",
      "epoch:5 step:5314 [D loss: 0.239965, acc.: 57.81%] [G loss: 0.286896]\n",
      "epoch:5 step:5315 [D loss: 0.249758, acc.: 56.25%] [G loss: 0.329316]\n",
      "epoch:5 step:5316 [D loss: 0.231568, acc.: 63.28%] [G loss: 0.296381]\n",
      "epoch:5 step:5317 [D loss: 0.244489, acc.: 58.59%] [G loss: 0.306101]\n",
      "epoch:5 step:5318 [D loss: 0.260108, acc.: 46.88%] [G loss: 0.311617]\n",
      "epoch:5 step:5319 [D loss: 0.237831, acc.: 62.50%] [G loss: 0.311799]\n",
      "epoch:5 step:5320 [D loss: 0.237316, acc.: 54.69%] [G loss: 0.307616]\n",
      "epoch:5 step:5321 [D loss: 0.253274, acc.: 55.47%] [G loss: 0.312592]\n",
      "epoch:5 step:5322 [D loss: 0.231930, acc.: 57.81%] [G loss: 0.305803]\n",
      "epoch:5 step:5323 [D loss: 0.226801, acc.: 64.84%] [G loss: 0.328660]\n",
      "epoch:5 step:5324 [D loss: 0.256803, acc.: 53.91%] [G loss: 0.334238]\n",
      "epoch:5 step:5325 [D loss: 0.215297, acc.: 64.84%] [G loss: 0.320020]\n",
      "epoch:5 step:5326 [D loss: 0.241385, acc.: 56.25%] [G loss: 0.294465]\n",
      "epoch:5 step:5327 [D loss: 0.250641, acc.: 55.47%] [G loss: 0.307304]\n",
      "epoch:5 step:5328 [D loss: 0.240795, acc.: 62.50%] [G loss: 0.320163]\n",
      "epoch:5 step:5329 [D loss: 0.238838, acc.: 58.59%] [G loss: 0.300873]\n",
      "epoch:5 step:5330 [D loss: 0.255559, acc.: 49.22%] [G loss: 0.318458]\n",
      "epoch:5 step:5331 [D loss: 0.240768, acc.: 60.94%] [G loss: 0.292509]\n",
      "epoch:5 step:5332 [D loss: 0.250625, acc.: 58.59%] [G loss: 0.316416]\n",
      "epoch:5 step:5333 [D loss: 0.250184, acc.: 51.56%] [G loss: 0.312416]\n",
      "epoch:5 step:5334 [D loss: 0.256801, acc.: 54.69%] [G loss: 0.291680]\n",
      "epoch:5 step:5335 [D loss: 0.254403, acc.: 51.56%] [G loss: 0.272969]\n",
      "epoch:5 step:5336 [D loss: 0.234382, acc.: 58.59%] [G loss: 0.312023]\n",
      "epoch:5 step:5337 [D loss: 0.241678, acc.: 57.03%] [G loss: 0.311446]\n",
      "epoch:5 step:5338 [D loss: 0.239104, acc.: 57.81%] [G loss: 0.275783]\n",
      "epoch:5 step:5339 [D loss: 0.243957, acc.: 57.03%] [G loss: 0.296600]\n",
      "epoch:5 step:5340 [D loss: 0.241562, acc.: 59.38%] [G loss: 0.304894]\n",
      "epoch:5 step:5341 [D loss: 0.249729, acc.: 56.25%] [G loss: 0.298049]\n",
      "epoch:5 step:5342 [D loss: 0.239664, acc.: 61.72%] [G loss: 0.288833]\n",
      "epoch:5 step:5343 [D loss: 0.251743, acc.: 55.47%] [G loss: 0.280830]\n",
      "epoch:5 step:5344 [D loss: 0.249400, acc.: 53.12%] [G loss: 0.300598]\n",
      "epoch:5 step:5345 [D loss: 0.252530, acc.: 52.34%] [G loss: 0.281493]\n",
      "epoch:5 step:5346 [D loss: 0.252355, acc.: 56.25%] [G loss: 0.306062]\n",
      "epoch:5 step:5347 [D loss: 0.235637, acc.: 57.03%] [G loss: 0.321346]\n",
      "epoch:5 step:5348 [D loss: 0.252463, acc.: 52.34%] [G loss: 0.289087]\n",
      "epoch:5 step:5349 [D loss: 0.235012, acc.: 58.59%] [G loss: 0.312215]\n",
      "epoch:5 step:5350 [D loss: 0.231665, acc.: 54.69%] [G loss: 0.319285]\n",
      "epoch:5 step:5351 [D loss: 0.224084, acc.: 60.94%] [G loss: 0.289982]\n",
      "epoch:5 step:5352 [D loss: 0.232819, acc.: 58.59%] [G loss: 0.300543]\n",
      "epoch:5 step:5353 [D loss: 0.232505, acc.: 59.38%] [G loss: 0.301575]\n",
      "epoch:5 step:5354 [D loss: 0.243136, acc.: 57.81%] [G loss: 0.281441]\n",
      "epoch:5 step:5355 [D loss: 0.220912, acc.: 65.62%] [G loss: 0.295385]\n",
      "epoch:5 step:5356 [D loss: 0.257569, acc.: 53.91%] [G loss: 0.330020]\n",
      "epoch:5 step:5357 [D loss: 0.244732, acc.: 57.81%] [G loss: 0.289847]\n",
      "epoch:5 step:5358 [D loss: 0.235136, acc.: 59.38%] [G loss: 0.311210]\n",
      "epoch:5 step:5359 [D loss: 0.237249, acc.: 62.50%] [G loss: 0.287118]\n",
      "epoch:5 step:5360 [D loss: 0.226475, acc.: 60.16%] [G loss: 0.288877]\n",
      "epoch:5 step:5361 [D loss: 0.257200, acc.: 50.00%] [G loss: 0.291753]\n",
      "epoch:5 step:5362 [D loss: 0.240703, acc.: 60.94%] [G loss: 0.318804]\n",
      "epoch:5 step:5363 [D loss: 0.241883, acc.: 57.03%] [G loss: 0.313595]\n",
      "epoch:5 step:5364 [D loss: 0.247492, acc.: 56.25%] [G loss: 0.287852]\n",
      "epoch:5 step:5365 [D loss: 0.244760, acc.: 60.94%] [G loss: 0.285519]\n",
      "epoch:5 step:5366 [D loss: 0.242961, acc.: 58.59%] [G loss: 0.304369]\n",
      "epoch:5 step:5367 [D loss: 0.240294, acc.: 52.34%] [G loss: 0.296104]\n",
      "epoch:5 step:5368 [D loss: 0.244963, acc.: 56.25%] [G loss: 0.282254]\n",
      "epoch:5 step:5369 [D loss: 0.240039, acc.: 57.03%] [G loss: 0.279958]\n",
      "epoch:5 step:5370 [D loss: 0.233052, acc.: 61.72%] [G loss: 0.302205]\n",
      "epoch:5 step:5371 [D loss: 0.244025, acc.: 57.81%] [G loss: 0.284932]\n",
      "epoch:5 step:5372 [D loss: 0.245883, acc.: 60.16%] [G loss: 0.283203]\n",
      "epoch:5 step:5373 [D loss: 0.238862, acc.: 61.72%] [G loss: 0.322770]\n",
      "epoch:5 step:5374 [D loss: 0.259268, acc.: 46.09%] [G loss: 0.256562]\n",
      "epoch:5 step:5375 [D loss: 0.259305, acc.: 50.00%] [G loss: 0.292625]\n",
      "epoch:5 step:5376 [D loss: 0.245775, acc.: 53.12%] [G loss: 0.294624]\n",
      "epoch:5 step:5377 [D loss: 0.236233, acc.: 60.94%] [G loss: 0.302168]\n",
      "epoch:5 step:5378 [D loss: 0.235927, acc.: 61.72%] [G loss: 0.293092]\n",
      "epoch:5 step:5379 [D loss: 0.248712, acc.: 58.59%] [G loss: 0.299663]\n",
      "epoch:5 step:5380 [D loss: 0.226004, acc.: 68.75%] [G loss: 0.287556]\n",
      "epoch:5 step:5381 [D loss: 0.240879, acc.: 57.81%] [G loss: 0.321347]\n",
      "epoch:5 step:5382 [D loss: 0.254399, acc.: 52.34%] [G loss: 0.285829]\n",
      "epoch:5 step:5383 [D loss: 0.258598, acc.: 48.44%] [G loss: 0.298086]\n",
      "epoch:5 step:5384 [D loss: 0.266994, acc.: 51.56%] [G loss: 0.306935]\n",
      "epoch:5 step:5385 [D loss: 0.231624, acc.: 61.72%] [G loss: 0.314327]\n",
      "epoch:5 step:5386 [D loss: 0.238406, acc.: 61.72%] [G loss: 0.287180]\n",
      "epoch:5 step:5387 [D loss: 0.234003, acc.: 55.47%] [G loss: 0.295461]\n",
      "epoch:5 step:5388 [D loss: 0.224105, acc.: 63.28%] [G loss: 0.316542]\n",
      "epoch:5 step:5389 [D loss: 0.247254, acc.: 56.25%] [G loss: 0.313408]\n",
      "epoch:5 step:5390 [D loss: 0.229045, acc.: 63.28%] [G loss: 0.318316]\n",
      "epoch:5 step:5391 [D loss: 0.259903, acc.: 48.44%] [G loss: 0.302865]\n",
      "epoch:5 step:5392 [D loss: 0.241189, acc.: 57.81%] [G loss: 0.297066]\n",
      "epoch:5 step:5393 [D loss: 0.231667, acc.: 60.94%] [G loss: 0.296286]\n",
      "epoch:5 step:5394 [D loss: 0.274256, acc.: 50.78%] [G loss: 0.299877]\n",
      "epoch:5 step:5395 [D loss: 0.227474, acc.: 66.41%] [G loss: 0.274662]\n",
      "epoch:5 step:5396 [D loss: 0.243638, acc.: 58.59%] [G loss: 0.284154]\n",
      "epoch:5 step:5397 [D loss: 0.232381, acc.: 57.81%] [G loss: 0.317929]\n",
      "epoch:5 step:5398 [D loss: 0.219759, acc.: 64.06%] [G loss: 0.305899]\n",
      "epoch:5 step:5399 [D loss: 0.254298, acc.: 51.56%] [G loss: 0.293985]\n",
      "epoch:5 step:5400 [D loss: 0.235516, acc.: 60.94%] [G loss: 0.318733]\n",
      "epoch:5 step:5401 [D loss: 0.233011, acc.: 62.50%] [G loss: 0.321149]\n",
      "epoch:5 step:5402 [D loss: 0.241350, acc.: 60.94%] [G loss: 0.322659]\n",
      "epoch:5 step:5403 [D loss: 0.234393, acc.: 59.38%] [G loss: 0.295186]\n",
      "epoch:5 step:5404 [D loss: 0.277585, acc.: 48.44%] [G loss: 0.282529]\n",
      "epoch:5 step:5405 [D loss: 0.238252, acc.: 62.50%] [G loss: 0.293737]\n",
      "epoch:5 step:5406 [D loss: 0.257786, acc.: 50.00%] [G loss: 0.253830]\n",
      "epoch:5 step:5407 [D loss: 0.240295, acc.: 56.25%] [G loss: 0.303403]\n",
      "epoch:5 step:5408 [D loss: 0.243901, acc.: 54.69%] [G loss: 0.329788]\n",
      "epoch:5 step:5409 [D loss: 0.230245, acc.: 60.94%] [G loss: 0.319542]\n",
      "epoch:5 step:5410 [D loss: 0.262659, acc.: 56.25%] [G loss: 0.276728]\n",
      "epoch:5 step:5411 [D loss: 0.234010, acc.: 62.50%] [G loss: 0.289042]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:5 step:5412 [D loss: 0.253975, acc.: 57.03%] [G loss: 0.280572]\n",
      "epoch:5 step:5413 [D loss: 0.234771, acc.: 57.03%] [G loss: 0.281185]\n",
      "epoch:5 step:5414 [D loss: 0.245379, acc.: 57.81%] [G loss: 0.318176]\n",
      "epoch:5 step:5415 [D loss: 0.248503, acc.: 58.59%] [G loss: 0.287715]\n",
      "epoch:5 step:5416 [D loss: 0.255857, acc.: 53.12%] [G loss: 0.252206]\n",
      "epoch:5 step:5417 [D loss: 0.254935, acc.: 50.00%] [G loss: 0.291593]\n",
      "epoch:5 step:5418 [D loss: 0.250608, acc.: 52.34%] [G loss: 0.328204]\n",
      "epoch:5 step:5419 [D loss: 0.242656, acc.: 59.38%] [G loss: 0.311863]\n",
      "epoch:5 step:5420 [D loss: 0.226971, acc.: 60.94%] [G loss: 0.301201]\n",
      "epoch:5 step:5421 [D loss: 0.250229, acc.: 52.34%] [G loss: 0.327979]\n",
      "epoch:5 step:5422 [D loss: 0.243565, acc.: 56.25%] [G loss: 0.316786]\n",
      "epoch:5 step:5423 [D loss: 0.260923, acc.: 50.78%] [G loss: 0.307071]\n",
      "epoch:5 step:5424 [D loss: 0.232754, acc.: 57.81%] [G loss: 0.332931]\n",
      "epoch:5 step:5425 [D loss: 0.237966, acc.: 59.38%] [G loss: 0.282419]\n",
      "epoch:5 step:5426 [D loss: 0.241224, acc.: 57.03%] [G loss: 0.304472]\n",
      "epoch:5 step:5427 [D loss: 0.253295, acc.: 51.56%] [G loss: 0.303969]\n",
      "epoch:5 step:5428 [D loss: 0.255392, acc.: 54.69%] [G loss: 0.308770]\n",
      "epoch:5 step:5429 [D loss: 0.245197, acc.: 53.12%] [G loss: 0.310189]\n",
      "epoch:5 step:5430 [D loss: 0.238386, acc.: 64.06%] [G loss: 0.304589]\n",
      "epoch:5 step:5431 [D loss: 0.232005, acc.: 61.72%] [G loss: 0.299769]\n",
      "epoch:5 step:5432 [D loss: 0.234379, acc.: 58.59%] [G loss: 0.314424]\n",
      "epoch:5 step:5433 [D loss: 0.236057, acc.: 60.16%] [G loss: 0.315784]\n",
      "epoch:5 step:5434 [D loss: 0.233863, acc.: 61.72%] [G loss: 0.300375]\n",
      "epoch:5 step:5435 [D loss: 0.224135, acc.: 64.06%] [G loss: 0.325065]\n",
      "epoch:5 step:5436 [D loss: 0.234635, acc.: 61.72%] [G loss: 0.313828]\n",
      "epoch:5 step:5437 [D loss: 0.239946, acc.: 52.34%] [G loss: 0.296986]\n",
      "epoch:5 step:5438 [D loss: 0.232827, acc.: 60.94%] [G loss: 0.290921]\n",
      "epoch:5 step:5439 [D loss: 0.242234, acc.: 56.25%] [G loss: 0.297337]\n",
      "epoch:5 step:5440 [D loss: 0.255171, acc.: 52.34%] [G loss: 0.289203]\n",
      "epoch:5 step:5441 [D loss: 0.251871, acc.: 53.91%] [G loss: 0.314559]\n",
      "epoch:5 step:5442 [D loss: 0.236818, acc.: 60.16%] [G loss: 0.328492]\n",
      "epoch:5 step:5443 [D loss: 0.245638, acc.: 57.81%] [G loss: 0.315116]\n",
      "epoch:5 step:5444 [D loss: 0.240489, acc.: 54.69%] [G loss: 0.296224]\n",
      "epoch:5 step:5445 [D loss: 0.232673, acc.: 62.50%] [G loss: 0.309759]\n",
      "epoch:5 step:5446 [D loss: 0.253075, acc.: 55.47%] [G loss: 0.322281]\n",
      "epoch:5 step:5447 [D loss: 0.241432, acc.: 62.50%] [G loss: 0.311517]\n",
      "epoch:5 step:5448 [D loss: 0.256037, acc.: 49.22%] [G loss: 0.309809]\n",
      "epoch:5 step:5449 [D loss: 0.248680, acc.: 54.69%] [G loss: 0.302535]\n",
      "epoch:5 step:5450 [D loss: 0.244767, acc.: 56.25%] [G loss: 0.320430]\n",
      "epoch:5 step:5451 [D loss: 0.228863, acc.: 62.50%] [G loss: 0.311648]\n",
      "epoch:5 step:5452 [D loss: 0.247128, acc.: 53.91%] [G loss: 0.300032]\n",
      "epoch:5 step:5453 [D loss: 0.243602, acc.: 60.16%] [G loss: 0.307093]\n",
      "epoch:5 step:5454 [D loss: 0.268826, acc.: 50.00%] [G loss: 0.301818]\n",
      "epoch:5 step:5455 [D loss: 0.234723, acc.: 55.47%] [G loss: 0.263851]\n",
      "epoch:5 step:5456 [D loss: 0.247208, acc.: 57.03%] [G loss: 0.306036]\n",
      "epoch:5 step:5457 [D loss: 0.232596, acc.: 57.03%] [G loss: 0.327108]\n",
      "epoch:5 step:5458 [D loss: 0.245029, acc.: 55.47%] [G loss: 0.281989]\n",
      "epoch:5 step:5459 [D loss: 0.251232, acc.: 54.69%] [G loss: 0.315695]\n",
      "epoch:5 step:5460 [D loss: 0.229855, acc.: 59.38%] [G loss: 0.312938]\n",
      "epoch:5 step:5461 [D loss: 0.251005, acc.: 55.47%] [G loss: 0.291131]\n",
      "epoch:5 step:5462 [D loss: 0.241000, acc.: 59.38%] [G loss: 0.282798]\n",
      "epoch:5 step:5463 [D loss: 0.243131, acc.: 57.03%] [G loss: 0.312931]\n",
      "epoch:5 step:5464 [D loss: 0.222655, acc.: 61.72%] [G loss: 0.308594]\n",
      "epoch:5 step:5465 [D loss: 0.268460, acc.: 53.12%] [G loss: 0.292317]\n",
      "epoch:5 step:5466 [D loss: 0.226868, acc.: 60.16%] [G loss: 0.325009]\n",
      "epoch:5 step:5467 [D loss: 0.236396, acc.: 61.72%] [G loss: 0.281226]\n",
      "epoch:5 step:5468 [D loss: 0.239799, acc.: 53.12%] [G loss: 0.289789]\n",
      "epoch:5 step:5469 [D loss: 0.262949, acc.: 48.44%] [G loss: 0.284853]\n",
      "epoch:5 step:5470 [D loss: 0.258034, acc.: 53.12%] [G loss: 0.296621]\n",
      "epoch:5 step:5471 [D loss: 0.239079, acc.: 57.81%] [G loss: 0.289669]\n",
      "epoch:5 step:5472 [D loss: 0.237301, acc.: 60.94%] [G loss: 0.307329]\n",
      "epoch:5 step:5473 [D loss: 0.254869, acc.: 56.25%] [G loss: 0.298533]\n",
      "epoch:5 step:5474 [D loss: 0.249264, acc.: 55.47%] [G loss: 0.324397]\n",
      "epoch:5 step:5475 [D loss: 0.246869, acc.: 53.91%] [G loss: 0.287097]\n",
      "epoch:5 step:5476 [D loss: 0.241956, acc.: 56.25%] [G loss: 0.292593]\n",
      "epoch:5 step:5477 [D loss: 0.245415, acc.: 55.47%] [G loss: 0.286463]\n",
      "epoch:5 step:5478 [D loss: 0.235897, acc.: 57.03%] [G loss: 0.289109]\n",
      "epoch:5 step:5479 [D loss: 0.238179, acc.: 57.81%] [G loss: 0.307293]\n",
      "epoch:5 step:5480 [D loss: 0.240770, acc.: 55.47%] [G loss: 0.294141]\n",
      "epoch:5 step:5481 [D loss: 0.252334, acc.: 49.22%] [G loss: 0.308964]\n",
      "epoch:5 step:5482 [D loss: 0.249561, acc.: 50.78%] [G loss: 0.308888]\n",
      "epoch:5 step:5483 [D loss: 0.261286, acc.: 52.34%] [G loss: 0.288642]\n",
      "epoch:5 step:5484 [D loss: 0.249499, acc.: 50.78%] [G loss: 0.281683]\n",
      "epoch:5 step:5485 [D loss: 0.235623, acc.: 60.94%] [G loss: 0.296284]\n",
      "epoch:5 step:5486 [D loss: 0.220010, acc.: 65.62%] [G loss: 0.303231]\n",
      "epoch:5 step:5487 [D loss: 0.260212, acc.: 53.12%] [G loss: 0.291218]\n",
      "epoch:5 step:5488 [D loss: 0.234544, acc.: 57.03%] [G loss: 0.300960]\n",
      "epoch:5 step:5489 [D loss: 0.243065, acc.: 60.94%] [G loss: 0.291892]\n",
      "epoch:5 step:5490 [D loss: 0.254007, acc.: 52.34%] [G loss: 0.297923]\n",
      "epoch:5 step:5491 [D loss: 0.232631, acc.: 60.94%] [G loss: 0.299464]\n",
      "epoch:5 step:5492 [D loss: 0.250976, acc.: 54.69%] [G loss: 0.289005]\n",
      "epoch:5 step:5493 [D loss: 0.235203, acc.: 56.25%] [G loss: 0.307386]\n",
      "epoch:5 step:5494 [D loss: 0.254305, acc.: 50.78%] [G loss: 0.318425]\n",
      "epoch:5 step:5495 [D loss: 0.244418, acc.: 60.16%] [G loss: 0.292245]\n",
      "epoch:5 step:5496 [D loss: 0.260531, acc.: 52.34%] [G loss: 0.282315]\n",
      "epoch:5 step:5497 [D loss: 0.254618, acc.: 56.25%] [G loss: 0.289122]\n",
      "epoch:5 step:5498 [D loss: 0.241470, acc.: 57.81%] [G loss: 0.331969]\n",
      "epoch:5 step:5499 [D loss: 0.243724, acc.: 58.59%] [G loss: 0.320098]\n",
      "epoch:5 step:5500 [D loss: 0.256328, acc.: 51.56%] [G loss: 0.282682]\n",
      "epoch:5 step:5501 [D loss: 0.236610, acc.: 58.59%] [G loss: 0.314290]\n",
      "epoch:5 step:5502 [D loss: 0.270808, acc.: 46.88%] [G loss: 0.315931]\n",
      "epoch:5 step:5503 [D loss: 0.241575, acc.: 59.38%] [G loss: 0.294205]\n",
      "epoch:5 step:5504 [D loss: 0.234512, acc.: 57.81%] [G loss: 0.310134]\n",
      "epoch:5 step:5505 [D loss: 0.259784, acc.: 46.88%] [G loss: 0.274716]\n",
      "epoch:5 step:5506 [D loss: 0.244409, acc.: 57.81%] [G loss: 0.297450]\n",
      "epoch:5 step:5507 [D loss: 0.243608, acc.: 57.81%] [G loss: 0.305892]\n",
      "epoch:5 step:5508 [D loss: 0.248357, acc.: 56.25%] [G loss: 0.282588]\n",
      "epoch:5 step:5509 [D loss: 0.252650, acc.: 54.69%] [G loss: 0.265241]\n",
      "epoch:5 step:5510 [D loss: 0.237789, acc.: 55.47%] [G loss: 0.279244]\n",
      "epoch:5 step:5511 [D loss: 0.217004, acc.: 65.62%] [G loss: 0.309631]\n",
      "epoch:5 step:5512 [D loss: 0.239073, acc.: 61.72%] [G loss: 0.317475]\n",
      "epoch:5 step:5513 [D loss: 0.253534, acc.: 51.56%] [G loss: 0.288175]\n",
      "epoch:5 step:5514 [D loss: 0.229933, acc.: 62.50%] [G loss: 0.298537]\n",
      "epoch:5 step:5515 [D loss: 0.233795, acc.: 57.03%] [G loss: 0.328616]\n",
      "epoch:5 step:5516 [D loss: 0.237583, acc.: 58.59%] [G loss: 0.326554]\n",
      "epoch:5 step:5517 [D loss: 0.242842, acc.: 54.69%] [G loss: 0.312204]\n",
      "epoch:5 step:5518 [D loss: 0.255037, acc.: 50.78%] [G loss: 0.309051]\n",
      "epoch:5 step:5519 [D loss: 0.246603, acc.: 57.03%] [G loss: 0.320310]\n",
      "epoch:5 step:5520 [D loss: 0.238663, acc.: 55.47%] [G loss: 0.294169]\n",
      "epoch:5 step:5521 [D loss: 0.264069, acc.: 50.78%] [G loss: 0.299846]\n",
      "epoch:5 step:5522 [D loss: 0.247816, acc.: 52.34%] [G loss: 0.293810]\n",
      "epoch:5 step:5523 [D loss: 0.243263, acc.: 59.38%] [G loss: 0.278962]\n",
      "epoch:5 step:5524 [D loss: 0.248829, acc.: 54.69%] [G loss: 0.279123]\n",
      "epoch:5 step:5525 [D loss: 0.226188, acc.: 64.06%] [G loss: 0.306974]\n",
      "epoch:5 step:5526 [D loss: 0.239211, acc.: 57.03%] [G loss: 0.295642]\n",
      "epoch:5 step:5527 [D loss: 0.242920, acc.: 54.69%] [G loss: 0.309282]\n",
      "epoch:5 step:5528 [D loss: 0.230452, acc.: 59.38%] [G loss: 0.284775]\n",
      "epoch:5 step:5529 [D loss: 0.259117, acc.: 49.22%] [G loss: 0.302092]\n",
      "epoch:5 step:5530 [D loss: 0.230637, acc.: 59.38%] [G loss: 0.280964]\n",
      "epoch:5 step:5531 [D loss: 0.255988, acc.: 47.66%] [G loss: 0.293148]\n",
      "epoch:5 step:5532 [D loss: 0.233701, acc.: 62.50%] [G loss: 0.303122]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:5 step:5533 [D loss: 0.233021, acc.: 59.38%] [G loss: 0.315341]\n",
      "epoch:5 step:5534 [D loss: 0.259892, acc.: 48.44%] [G loss: 0.317979]\n",
      "epoch:5 step:5535 [D loss: 0.229351, acc.: 60.94%] [G loss: 0.309917]\n",
      "epoch:5 step:5536 [D loss: 0.250199, acc.: 50.78%] [G loss: 0.307292]\n",
      "epoch:5 step:5537 [D loss: 0.222671, acc.: 61.72%] [G loss: 0.322679]\n",
      "epoch:5 step:5538 [D loss: 0.228740, acc.: 61.72%] [G loss: 0.309051]\n",
      "epoch:5 step:5539 [D loss: 0.236510, acc.: 61.72%] [G loss: 0.309918]\n",
      "epoch:5 step:5540 [D loss: 0.242779, acc.: 57.03%] [G loss: 0.306220]\n",
      "epoch:5 step:5541 [D loss: 0.221678, acc.: 65.62%] [G loss: 0.294370]\n",
      "epoch:5 step:5542 [D loss: 0.271670, acc.: 45.31%] [G loss: 0.266358]\n",
      "epoch:5 step:5543 [D loss: 0.242269, acc.: 60.94%] [G loss: 0.287942]\n",
      "epoch:5 step:5544 [D loss: 0.237186, acc.: 55.47%] [G loss: 0.301030]\n",
      "epoch:5 step:5545 [D loss: 0.244679, acc.: 56.25%] [G loss: 0.310919]\n",
      "epoch:5 step:5546 [D loss: 0.254554, acc.: 55.47%] [G loss: 0.335138]\n",
      "epoch:5 step:5547 [D loss: 0.242252, acc.: 55.47%] [G loss: 0.269178]\n",
      "epoch:5 step:5548 [D loss: 0.238151, acc.: 60.16%] [G loss: 0.278534]\n",
      "epoch:5 step:5549 [D loss: 0.251507, acc.: 54.69%] [G loss: 0.274615]\n",
      "epoch:5 step:5550 [D loss: 0.234130, acc.: 61.72%] [G loss: 0.279599]\n",
      "epoch:5 step:5551 [D loss: 0.220410, acc.: 65.62%] [G loss: 0.299934]\n",
      "epoch:5 step:5552 [D loss: 0.253800, acc.: 49.22%] [G loss: 0.283186]\n",
      "epoch:5 step:5553 [D loss: 0.236932, acc.: 57.81%] [G loss: 0.294529]\n",
      "epoch:5 step:5554 [D loss: 0.247177, acc.: 53.91%] [G loss: 0.281185]\n",
      "epoch:5 step:5555 [D loss: 0.246145, acc.: 54.69%] [G loss: 0.302271]\n",
      "epoch:5 step:5556 [D loss: 0.215283, acc.: 68.75%] [G loss: 0.330353]\n",
      "epoch:5 step:5557 [D loss: 0.265628, acc.: 51.56%] [G loss: 0.293257]\n",
      "epoch:5 step:5558 [D loss: 0.229146, acc.: 64.84%] [G loss: 0.288984]\n",
      "epoch:5 step:5559 [D loss: 0.244722, acc.: 57.03%] [G loss: 0.308405]\n",
      "epoch:5 step:5560 [D loss: 0.240311, acc.: 57.03%] [G loss: 0.320328]\n",
      "epoch:5 step:5561 [D loss: 0.241235, acc.: 59.38%] [G loss: 0.311906]\n",
      "epoch:5 step:5562 [D loss: 0.248027, acc.: 59.38%] [G loss: 0.329084]\n",
      "epoch:5 step:5563 [D loss: 0.242606, acc.: 56.25%] [G loss: 0.298376]\n",
      "epoch:5 step:5564 [D loss: 0.255300, acc.: 50.00%] [G loss: 0.286216]\n",
      "epoch:5 step:5565 [D loss: 0.239639, acc.: 61.72%] [G loss: 0.275617]\n",
      "epoch:5 step:5566 [D loss: 0.240373, acc.: 58.59%] [G loss: 0.333987]\n",
      "epoch:5 step:5567 [D loss: 0.237182, acc.: 58.59%] [G loss: 0.291126]\n",
      "epoch:5 step:5568 [D loss: 0.241671, acc.: 53.12%] [G loss: 0.279417]\n",
      "epoch:5 step:5569 [D loss: 0.230516, acc.: 67.97%] [G loss: 0.293336]\n",
      "epoch:5 step:5570 [D loss: 0.245753, acc.: 51.56%] [G loss: 0.303619]\n",
      "epoch:5 step:5571 [D loss: 0.257018, acc.: 52.34%] [G loss: 0.297265]\n",
      "epoch:5 step:5572 [D loss: 0.247610, acc.: 58.59%] [G loss: 0.299745]\n",
      "epoch:5 step:5573 [D loss: 0.251581, acc.: 49.22%] [G loss: 0.293222]\n",
      "epoch:5 step:5574 [D loss: 0.252879, acc.: 54.69%] [G loss: 0.291524]\n",
      "epoch:5 step:5575 [D loss: 0.242559, acc.: 56.25%] [G loss: 0.282106]\n",
      "epoch:5 step:5576 [D loss: 0.250650, acc.: 52.34%] [G loss: 0.300874]\n",
      "epoch:5 step:5577 [D loss: 0.237039, acc.: 58.59%] [G loss: 0.281898]\n",
      "epoch:5 step:5578 [D loss: 0.254621, acc.: 55.47%] [G loss: 0.308379]\n",
      "epoch:5 step:5579 [D loss: 0.259952, acc.: 47.66%] [G loss: 0.283941]\n",
      "epoch:5 step:5580 [D loss: 0.240352, acc.: 56.25%] [G loss: 0.279864]\n",
      "epoch:5 step:5581 [D loss: 0.230720, acc.: 62.50%] [G loss: 0.291399]\n",
      "epoch:5 step:5582 [D loss: 0.259332, acc.: 51.56%] [G loss: 0.296394]\n",
      "epoch:5 step:5583 [D loss: 0.225767, acc.: 64.84%] [G loss: 0.295915]\n",
      "epoch:5 step:5584 [D loss: 0.253058, acc.: 54.69%] [G loss: 0.294549]\n",
      "epoch:5 step:5585 [D loss: 0.222031, acc.: 66.41%] [G loss: 0.314448]\n",
      "epoch:5 step:5586 [D loss: 0.246637, acc.: 56.25%] [G loss: 0.314298]\n",
      "epoch:5 step:5587 [D loss: 0.233430, acc.: 63.28%] [G loss: 0.283670]\n",
      "epoch:5 step:5588 [D loss: 0.242989, acc.: 60.16%] [G loss: 0.322582]\n",
      "epoch:5 step:5589 [D loss: 0.233354, acc.: 57.03%] [G loss: 0.313742]\n",
      "epoch:5 step:5590 [D loss: 0.240595, acc.: 59.38%] [G loss: 0.303101]\n",
      "epoch:5 step:5591 [D loss: 0.238128, acc.: 60.94%] [G loss: 0.300933]\n",
      "epoch:5 step:5592 [D loss: 0.258148, acc.: 53.91%] [G loss: 0.311738]\n",
      "epoch:5 step:5593 [D loss: 0.251703, acc.: 56.25%] [G loss: 0.289500]\n",
      "epoch:5 step:5594 [D loss: 0.249186, acc.: 51.56%] [G loss: 0.293360]\n",
      "epoch:5 step:5595 [D loss: 0.249888, acc.: 57.81%] [G loss: 0.296937]\n",
      "epoch:5 step:5596 [D loss: 0.226110, acc.: 64.06%] [G loss: 0.287137]\n",
      "epoch:5 step:5597 [D loss: 0.254321, acc.: 55.47%] [G loss: 0.297017]\n",
      "epoch:5 step:5598 [D loss: 0.242676, acc.: 53.91%] [G loss: 0.320192]\n",
      "epoch:5 step:5599 [D loss: 0.234496, acc.: 64.84%] [G loss: 0.307796]\n",
      "epoch:5 step:5600 [D loss: 0.246428, acc.: 57.81%] [G loss: 0.314159]\n",
      "epoch:5 step:5601 [D loss: 0.250111, acc.: 56.25%] [G loss: 0.302094]\n",
      "epoch:5 step:5602 [D loss: 0.258980, acc.: 48.44%] [G loss: 0.279388]\n",
      "epoch:5 step:5603 [D loss: 0.249279, acc.: 56.25%] [G loss: 0.299327]\n",
      "epoch:5 step:5604 [D loss: 0.252953, acc.: 52.34%] [G loss: 0.310156]\n",
      "epoch:5 step:5605 [D loss: 0.237342, acc.: 59.38%] [G loss: 0.317697]\n",
      "epoch:5 step:5606 [D loss: 0.242197, acc.: 57.81%] [G loss: 0.267291]\n",
      "epoch:5 step:5607 [D loss: 0.251210, acc.: 54.69%] [G loss: 0.280997]\n",
      "epoch:5 step:5608 [D loss: 0.247247, acc.: 53.91%] [G loss: 0.310653]\n",
      "epoch:5 step:5609 [D loss: 0.240524, acc.: 61.72%] [G loss: 0.296319]\n",
      "epoch:5 step:5610 [D loss: 0.242412, acc.: 57.03%] [G loss: 0.307689]\n",
      "epoch:5 step:5611 [D loss: 0.236620, acc.: 60.16%] [G loss: 0.321161]\n",
      "epoch:5 step:5612 [D loss: 0.250902, acc.: 59.38%] [G loss: 0.317665]\n",
      "epoch:5 step:5613 [D loss: 0.219602, acc.: 67.97%] [G loss: 0.290211]\n",
      "epoch:5 step:5614 [D loss: 0.243851, acc.: 55.47%] [G loss: 0.296761]\n",
      "epoch:5 step:5615 [D loss: 0.230461, acc.: 63.28%] [G loss: 0.302403]\n",
      "epoch:5 step:5616 [D loss: 0.225309, acc.: 64.06%] [G loss: 0.310333]\n",
      "epoch:5 step:5617 [D loss: 0.227127, acc.: 61.72%] [G loss: 0.310069]\n",
      "epoch:5 step:5618 [D loss: 0.256585, acc.: 52.34%] [G loss: 0.306645]\n",
      "epoch:5 step:5619 [D loss: 0.236565, acc.: 61.72%] [G loss: 0.303846]\n",
      "epoch:5 step:5620 [D loss: 0.239749, acc.: 59.38%] [G loss: 0.324129]\n",
      "epoch:5 step:5621 [D loss: 0.248108, acc.: 51.56%] [G loss: 0.295107]\n",
      "epoch:5 step:5622 [D loss: 0.221684, acc.: 66.41%] [G loss: 0.321996]\n",
      "epoch:6 step:5623 [D loss: 0.245473, acc.: 57.81%] [G loss: 0.312488]\n",
      "epoch:6 step:5624 [D loss: 0.263958, acc.: 50.00%] [G loss: 0.291310]\n",
      "epoch:6 step:5625 [D loss: 0.240615, acc.: 57.81%] [G loss: 0.301725]\n",
      "epoch:6 step:5626 [D loss: 0.246990, acc.: 50.78%] [G loss: 0.290643]\n",
      "epoch:6 step:5627 [D loss: 0.234083, acc.: 60.16%] [G loss: 0.298080]\n",
      "epoch:6 step:5628 [D loss: 0.257512, acc.: 57.03%] [G loss: 0.320339]\n",
      "epoch:6 step:5629 [D loss: 0.242512, acc.: 55.47%] [G loss: 0.297634]\n",
      "epoch:6 step:5630 [D loss: 0.226631, acc.: 64.84%] [G loss: 0.274366]\n",
      "epoch:6 step:5631 [D loss: 0.231840, acc.: 66.41%] [G loss: 0.324214]\n",
      "epoch:6 step:5632 [D loss: 0.252666, acc.: 53.12%] [G loss: 0.275058]\n",
      "epoch:6 step:5633 [D loss: 0.235829, acc.: 60.16%] [G loss: 0.320790]\n",
      "epoch:6 step:5634 [D loss: 0.256357, acc.: 51.56%] [G loss: 0.299149]\n",
      "epoch:6 step:5635 [D loss: 0.237821, acc.: 57.81%] [G loss: 0.299448]\n",
      "epoch:6 step:5636 [D loss: 0.228209, acc.: 65.62%] [G loss: 0.299477]\n",
      "epoch:6 step:5637 [D loss: 0.224097, acc.: 60.94%] [G loss: 0.319116]\n",
      "epoch:6 step:5638 [D loss: 0.246896, acc.: 60.16%] [G loss: 0.302152]\n",
      "epoch:6 step:5639 [D loss: 0.239632, acc.: 60.94%] [G loss: 0.306980]\n",
      "epoch:6 step:5640 [D loss: 0.253153, acc.: 53.91%] [G loss: 0.299618]\n",
      "epoch:6 step:5641 [D loss: 0.230833, acc.: 61.72%] [G loss: 0.311976]\n",
      "epoch:6 step:5642 [D loss: 0.246151, acc.: 55.47%] [G loss: 0.301904]\n",
      "epoch:6 step:5643 [D loss: 0.266261, acc.: 50.78%] [G loss: 0.318511]\n",
      "epoch:6 step:5644 [D loss: 0.235653, acc.: 58.59%] [G loss: 0.296000]\n",
      "epoch:6 step:5645 [D loss: 0.272162, acc.: 47.66%] [G loss: 0.295543]\n",
      "epoch:6 step:5646 [D loss: 0.249224, acc.: 49.22%] [G loss: 0.303317]\n",
      "epoch:6 step:5647 [D loss: 0.241094, acc.: 58.59%] [G loss: 0.300154]\n",
      "epoch:6 step:5648 [D loss: 0.229969, acc.: 64.06%] [G loss: 0.319834]\n",
      "epoch:6 step:5649 [D loss: 0.245246, acc.: 56.25%] [G loss: 0.261274]\n",
      "epoch:6 step:5650 [D loss: 0.241744, acc.: 57.03%] [G loss: 0.282974]\n",
      "epoch:6 step:5651 [D loss: 0.257067, acc.: 48.44%] [G loss: 0.315605]\n",
      "epoch:6 step:5652 [D loss: 0.230227, acc.: 60.16%] [G loss: 0.271278]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:6 step:5653 [D loss: 0.251991, acc.: 48.44%] [G loss: 0.283081]\n",
      "epoch:6 step:5654 [D loss: 0.235282, acc.: 57.81%] [G loss: 0.287860]\n",
      "epoch:6 step:5655 [D loss: 0.219137, acc.: 64.06%] [G loss: 0.284329]\n",
      "epoch:6 step:5656 [D loss: 0.239114, acc.: 57.03%] [G loss: 0.286657]\n",
      "epoch:6 step:5657 [D loss: 0.238895, acc.: 59.38%] [G loss: 0.292241]\n",
      "epoch:6 step:5658 [D loss: 0.239923, acc.: 53.91%] [G loss: 0.299407]\n",
      "epoch:6 step:5659 [D loss: 0.230935, acc.: 59.38%] [G loss: 0.296900]\n",
      "epoch:6 step:5660 [D loss: 0.254185, acc.: 50.78%] [G loss: 0.283443]\n",
      "epoch:6 step:5661 [D loss: 0.257034, acc.: 49.22%] [G loss: 0.286838]\n",
      "epoch:6 step:5662 [D loss: 0.248245, acc.: 57.81%] [G loss: 0.324657]\n",
      "epoch:6 step:5663 [D loss: 0.227563, acc.: 60.94%] [G loss: 0.309776]\n",
      "epoch:6 step:5664 [D loss: 0.239647, acc.: 63.28%] [G loss: 0.318273]\n",
      "epoch:6 step:5665 [D loss: 0.258022, acc.: 49.22%] [G loss: 0.314289]\n",
      "epoch:6 step:5666 [D loss: 0.259345, acc.: 52.34%] [G loss: 0.293640]\n",
      "epoch:6 step:5667 [D loss: 0.252549, acc.: 52.34%] [G loss: 0.311430]\n",
      "epoch:6 step:5668 [D loss: 0.247424, acc.: 50.78%] [G loss: 0.304243]\n",
      "epoch:6 step:5669 [D loss: 0.235655, acc.: 64.84%] [G loss: 0.324083]\n",
      "epoch:6 step:5670 [D loss: 0.243521, acc.: 54.69%] [G loss: 0.292162]\n",
      "epoch:6 step:5671 [D loss: 0.246079, acc.: 52.34%] [G loss: 0.309505]\n",
      "epoch:6 step:5672 [D loss: 0.244899, acc.: 50.78%] [G loss: 0.312456]\n",
      "epoch:6 step:5673 [D loss: 0.241462, acc.: 57.03%] [G loss: 0.300974]\n",
      "epoch:6 step:5674 [D loss: 0.245659, acc.: 56.25%] [G loss: 0.284802]\n",
      "epoch:6 step:5675 [D loss: 0.245989, acc.: 57.81%] [G loss: 0.308714]\n",
      "epoch:6 step:5676 [D loss: 0.253798, acc.: 52.34%] [G loss: 0.309291]\n",
      "epoch:6 step:5677 [D loss: 0.256774, acc.: 53.12%] [G loss: 0.300735]\n",
      "epoch:6 step:5678 [D loss: 0.233603, acc.: 63.28%] [G loss: 0.305181]\n",
      "epoch:6 step:5679 [D loss: 0.238280, acc.: 59.38%] [G loss: 0.295356]\n",
      "epoch:6 step:5680 [D loss: 0.247879, acc.: 60.94%] [G loss: 0.294019]\n",
      "epoch:6 step:5681 [D loss: 0.226353, acc.: 60.94%] [G loss: 0.296237]\n",
      "epoch:6 step:5682 [D loss: 0.250122, acc.: 49.22%] [G loss: 0.275853]\n",
      "epoch:6 step:5683 [D loss: 0.224181, acc.: 60.16%] [G loss: 0.299803]\n",
      "epoch:6 step:5684 [D loss: 0.246742, acc.: 52.34%] [G loss: 0.312247]\n",
      "epoch:6 step:5685 [D loss: 0.228477, acc.: 56.25%] [G loss: 0.323299]\n",
      "epoch:6 step:5686 [D loss: 0.240117, acc.: 57.03%] [G loss: 0.347697]\n",
      "epoch:6 step:5687 [D loss: 0.241138, acc.: 57.81%] [G loss: 0.301892]\n",
      "epoch:6 step:5688 [D loss: 0.251411, acc.: 54.69%] [G loss: 0.311980]\n",
      "epoch:6 step:5689 [D loss: 0.242389, acc.: 56.25%] [G loss: 0.313105]\n",
      "epoch:6 step:5690 [D loss: 0.250518, acc.: 54.69%] [G loss: 0.317346]\n",
      "epoch:6 step:5691 [D loss: 0.253014, acc.: 53.12%] [G loss: 0.300328]\n",
      "epoch:6 step:5692 [D loss: 0.248409, acc.: 54.69%] [G loss: 0.310849]\n",
      "epoch:6 step:5693 [D loss: 0.250971, acc.: 53.12%] [G loss: 0.314955]\n",
      "epoch:6 step:5694 [D loss: 0.233795, acc.: 60.16%] [G loss: 0.313487]\n",
      "epoch:6 step:5695 [D loss: 0.240399, acc.: 57.03%] [G loss: 0.308523]\n",
      "epoch:6 step:5696 [D loss: 0.241820, acc.: 53.91%] [G loss: 0.328153]\n",
      "epoch:6 step:5697 [D loss: 0.250877, acc.: 53.91%] [G loss: 0.302304]\n",
      "epoch:6 step:5698 [D loss: 0.250930, acc.: 50.78%] [G loss: 0.297841]\n",
      "epoch:6 step:5699 [D loss: 0.237597, acc.: 61.72%] [G loss: 0.314736]\n",
      "epoch:6 step:5700 [D loss: 0.239453, acc.: 53.91%] [G loss: 0.304887]\n",
      "epoch:6 step:5701 [D loss: 0.262022, acc.: 52.34%] [G loss: 0.332495]\n",
      "epoch:6 step:5702 [D loss: 0.226269, acc.: 63.28%] [G loss: 0.309263]\n",
      "epoch:6 step:5703 [D loss: 0.231432, acc.: 60.94%] [G loss: 0.280830]\n",
      "epoch:6 step:5704 [D loss: 0.229993, acc.: 56.25%] [G loss: 0.315799]\n",
      "epoch:6 step:5705 [D loss: 0.231222, acc.: 63.28%] [G loss: 0.293491]\n",
      "epoch:6 step:5706 [D loss: 0.278333, acc.: 41.41%] [G loss: 0.269191]\n",
      "epoch:6 step:5707 [D loss: 0.246737, acc.: 51.56%] [G loss: 0.289536]\n",
      "epoch:6 step:5708 [D loss: 0.248851, acc.: 55.47%] [G loss: 0.327882]\n",
      "epoch:6 step:5709 [D loss: 0.250756, acc.: 48.44%] [G loss: 0.339914]\n",
      "epoch:6 step:5710 [D loss: 0.262573, acc.: 45.31%] [G loss: 0.267720]\n",
      "epoch:6 step:5711 [D loss: 0.266660, acc.: 50.78%] [G loss: 0.285892]\n",
      "epoch:6 step:5712 [D loss: 0.252375, acc.: 58.59%] [G loss: 0.305697]\n",
      "epoch:6 step:5713 [D loss: 0.246248, acc.: 58.59%] [G loss: 0.294906]\n",
      "epoch:6 step:5714 [D loss: 0.250299, acc.: 56.25%] [G loss: 0.297776]\n",
      "epoch:6 step:5715 [D loss: 0.247829, acc.: 62.50%] [G loss: 0.307426]\n",
      "epoch:6 step:5716 [D loss: 0.231075, acc.: 57.81%] [G loss: 0.312690]\n",
      "epoch:6 step:5717 [D loss: 0.245143, acc.: 54.69%] [G loss: 0.270569]\n",
      "epoch:6 step:5718 [D loss: 0.252841, acc.: 53.91%] [G loss: 0.302508]\n",
      "epoch:6 step:5719 [D loss: 0.249637, acc.: 54.69%] [G loss: 0.268519]\n",
      "epoch:6 step:5720 [D loss: 0.245107, acc.: 53.12%] [G loss: 0.288967]\n",
      "epoch:6 step:5721 [D loss: 0.240601, acc.: 64.06%] [G loss: 0.303943]\n",
      "epoch:6 step:5722 [D loss: 0.254212, acc.: 54.69%] [G loss: 0.270057]\n",
      "epoch:6 step:5723 [D loss: 0.240866, acc.: 57.81%] [G loss: 0.315466]\n",
      "epoch:6 step:5724 [D loss: 0.243931, acc.: 55.47%] [G loss: 0.317235]\n",
      "epoch:6 step:5725 [D loss: 0.249500, acc.: 52.34%] [G loss: 0.291603]\n",
      "epoch:6 step:5726 [D loss: 0.235413, acc.: 63.28%] [G loss: 0.303318]\n",
      "epoch:6 step:5727 [D loss: 0.231958, acc.: 61.72%] [G loss: 0.317562]\n",
      "epoch:6 step:5728 [D loss: 0.241372, acc.: 62.50%] [G loss: 0.278009]\n",
      "epoch:6 step:5729 [D loss: 0.234215, acc.: 58.59%] [G loss: 0.290256]\n",
      "epoch:6 step:5730 [D loss: 0.249570, acc.: 57.81%] [G loss: 0.294869]\n",
      "epoch:6 step:5731 [D loss: 0.239109, acc.: 56.25%] [G loss: 0.309995]\n",
      "epoch:6 step:5732 [D loss: 0.256823, acc.: 52.34%] [G loss: 0.309076]\n",
      "epoch:6 step:5733 [D loss: 0.233985, acc.: 61.72%] [G loss: 0.318367]\n",
      "epoch:6 step:5734 [D loss: 0.237977, acc.: 63.28%] [G loss: 0.296183]\n",
      "epoch:6 step:5735 [D loss: 0.252235, acc.: 53.12%] [G loss: 0.303881]\n",
      "epoch:6 step:5736 [D loss: 0.244333, acc.: 56.25%] [G loss: 0.287600]\n",
      "epoch:6 step:5737 [D loss: 0.251463, acc.: 56.25%] [G loss: 0.310378]\n",
      "epoch:6 step:5738 [D loss: 0.257386, acc.: 52.34%] [G loss: 0.302916]\n",
      "epoch:6 step:5739 [D loss: 0.245829, acc.: 56.25%] [G loss: 0.321380]\n",
      "epoch:6 step:5740 [D loss: 0.230323, acc.: 64.06%] [G loss: 0.317077]\n",
      "epoch:6 step:5741 [D loss: 0.255555, acc.: 59.38%] [G loss: 0.292708]\n",
      "epoch:6 step:5742 [D loss: 0.250193, acc.: 51.56%] [G loss: 0.314136]\n",
      "epoch:6 step:5743 [D loss: 0.253623, acc.: 53.12%] [G loss: 0.286358]\n",
      "epoch:6 step:5744 [D loss: 0.248182, acc.: 57.81%] [G loss: 0.287707]\n",
      "epoch:6 step:5745 [D loss: 0.238666, acc.: 60.94%] [G loss: 0.287549]\n",
      "epoch:6 step:5746 [D loss: 0.253528, acc.: 48.44%] [G loss: 0.341515]\n",
      "epoch:6 step:5747 [D loss: 0.253295, acc.: 53.91%] [G loss: 0.288980]\n",
      "epoch:6 step:5748 [D loss: 0.246613, acc.: 59.38%] [G loss: 0.308568]\n",
      "epoch:6 step:5749 [D loss: 0.239739, acc.: 55.47%] [G loss: 0.314077]\n",
      "epoch:6 step:5750 [D loss: 0.227661, acc.: 62.50%] [G loss: 0.323605]\n",
      "epoch:6 step:5751 [D loss: 0.235308, acc.: 59.38%] [G loss: 0.337956]\n",
      "epoch:6 step:5752 [D loss: 0.259528, acc.: 57.81%] [G loss: 0.312248]\n",
      "epoch:6 step:5753 [D loss: 0.256177, acc.: 58.59%] [G loss: 0.283093]\n",
      "epoch:6 step:5754 [D loss: 0.260103, acc.: 52.34%] [G loss: 0.288838]\n",
      "epoch:6 step:5755 [D loss: 0.222907, acc.: 67.97%] [G loss: 0.284932]\n",
      "epoch:6 step:5756 [D loss: 0.252242, acc.: 53.12%] [G loss: 0.307169]\n",
      "epoch:6 step:5757 [D loss: 0.248623, acc.: 52.34%] [G loss: 0.277525]\n",
      "epoch:6 step:5758 [D loss: 0.238972, acc.: 56.25%] [G loss: 0.277313]\n",
      "epoch:6 step:5759 [D loss: 0.237781, acc.: 53.91%] [G loss: 0.283413]\n",
      "epoch:6 step:5760 [D loss: 0.254832, acc.: 56.25%] [G loss: 0.304111]\n",
      "epoch:6 step:5761 [D loss: 0.252405, acc.: 55.47%] [G loss: 0.296349]\n",
      "epoch:6 step:5762 [D loss: 0.229164, acc.: 60.94%] [G loss: 0.283852]\n",
      "epoch:6 step:5763 [D loss: 0.256399, acc.: 50.00%] [G loss: 0.304585]\n",
      "epoch:6 step:5764 [D loss: 0.232082, acc.: 60.94%] [G loss: 0.319925]\n",
      "epoch:6 step:5765 [D loss: 0.230748, acc.: 64.84%] [G loss: 0.288514]\n",
      "epoch:6 step:5766 [D loss: 0.263434, acc.: 52.34%] [G loss: 0.307985]\n",
      "epoch:6 step:5767 [D loss: 0.234841, acc.: 57.81%] [G loss: 0.321365]\n",
      "epoch:6 step:5768 [D loss: 0.245407, acc.: 52.34%] [G loss: 0.297083]\n",
      "epoch:6 step:5769 [D loss: 0.232644, acc.: 62.50%] [G loss: 0.326745]\n",
      "epoch:6 step:5770 [D loss: 0.239412, acc.: 62.50%] [G loss: 0.296647]\n",
      "epoch:6 step:5771 [D loss: 0.250106, acc.: 49.22%] [G loss: 0.292549]\n",
      "epoch:6 step:5772 [D loss: 0.259960, acc.: 52.34%] [G loss: 0.317725]\n",
      "epoch:6 step:5773 [D loss: 0.242762, acc.: 58.59%] [G loss: 0.292902]\n",
      "epoch:6 step:5774 [D loss: 0.233407, acc.: 58.59%] [G loss: 0.306279]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:6 step:5775 [D loss: 0.252966, acc.: 57.03%] [G loss: 0.284318]\n",
      "epoch:6 step:5776 [D loss: 0.248334, acc.: 53.91%] [G loss: 0.302676]\n",
      "epoch:6 step:5777 [D loss: 0.240837, acc.: 61.72%] [G loss: 0.291255]\n",
      "epoch:6 step:5778 [D loss: 0.257013, acc.: 53.12%] [G loss: 0.276091]\n",
      "epoch:6 step:5779 [D loss: 0.244434, acc.: 57.81%] [G loss: 0.285131]\n",
      "epoch:6 step:5780 [D loss: 0.229100, acc.: 65.62%] [G loss: 0.308497]\n",
      "epoch:6 step:5781 [D loss: 0.238029, acc.: 57.03%] [G loss: 0.274302]\n",
      "epoch:6 step:5782 [D loss: 0.254105, acc.: 58.59%] [G loss: 0.285387]\n",
      "epoch:6 step:5783 [D loss: 0.236479, acc.: 60.94%] [G loss: 0.309060]\n",
      "epoch:6 step:5784 [D loss: 0.250867, acc.: 57.03%] [G loss: 0.302486]\n",
      "epoch:6 step:5785 [D loss: 0.241652, acc.: 57.03%] [G loss: 0.310250]\n",
      "epoch:6 step:5786 [D loss: 0.236302, acc.: 64.84%] [G loss: 0.280668]\n",
      "epoch:6 step:5787 [D loss: 0.237981, acc.: 59.38%] [G loss: 0.299720]\n",
      "epoch:6 step:5788 [D loss: 0.230022, acc.: 64.84%] [G loss: 0.316309]\n",
      "epoch:6 step:5789 [D loss: 0.236207, acc.: 63.28%] [G loss: 0.295721]\n",
      "epoch:6 step:5790 [D loss: 0.224997, acc.: 60.94%] [G loss: 0.290040]\n",
      "epoch:6 step:5791 [D loss: 0.255139, acc.: 53.91%] [G loss: 0.327372]\n",
      "epoch:6 step:5792 [D loss: 0.245431, acc.: 59.38%] [G loss: 0.307431]\n",
      "epoch:6 step:5793 [D loss: 0.245935, acc.: 50.00%] [G loss: 0.313635]\n",
      "epoch:6 step:5794 [D loss: 0.231027, acc.: 61.72%] [G loss: 0.318523]\n",
      "epoch:6 step:5795 [D loss: 0.246196, acc.: 53.91%] [G loss: 0.295695]\n",
      "epoch:6 step:5796 [D loss: 0.239892, acc.: 57.81%] [G loss: 0.288837]\n",
      "epoch:6 step:5797 [D loss: 0.245527, acc.: 50.78%] [G loss: 0.300216]\n",
      "epoch:6 step:5798 [D loss: 0.247391, acc.: 60.16%] [G loss: 0.279089]\n",
      "epoch:6 step:5799 [D loss: 0.217590, acc.: 59.38%] [G loss: 0.316338]\n",
      "epoch:6 step:5800 [D loss: 0.238617, acc.: 58.59%] [G loss: 0.287250]\n",
      "epoch:6 step:5801 [D loss: 0.257356, acc.: 49.22%] [G loss: 0.293314]\n",
      "epoch:6 step:5802 [D loss: 0.254883, acc.: 50.78%] [G loss: 0.323119]\n",
      "epoch:6 step:5803 [D loss: 0.256558, acc.: 53.91%] [G loss: 0.291713]\n",
      "epoch:6 step:5804 [D loss: 0.229041, acc.: 64.06%] [G loss: 0.326400]\n",
      "epoch:6 step:5805 [D loss: 0.256661, acc.: 54.69%] [G loss: 0.287008]\n",
      "epoch:6 step:5806 [D loss: 0.230831, acc.: 61.72%] [G loss: 0.281244]\n",
      "epoch:6 step:5807 [D loss: 0.250478, acc.: 54.69%] [G loss: 0.307008]\n",
      "epoch:6 step:5808 [D loss: 0.248345, acc.: 54.69%] [G loss: 0.296821]\n",
      "epoch:6 step:5809 [D loss: 0.245265, acc.: 56.25%] [G loss: 0.308085]\n",
      "epoch:6 step:5810 [D loss: 0.233546, acc.: 57.81%] [G loss: 0.311940]\n",
      "epoch:6 step:5811 [D loss: 0.241843, acc.: 53.12%] [G loss: 0.301554]\n",
      "epoch:6 step:5812 [D loss: 0.239272, acc.: 58.59%] [G loss: 0.281540]\n",
      "epoch:6 step:5813 [D loss: 0.248225, acc.: 54.69%] [G loss: 0.299558]\n",
      "epoch:6 step:5814 [D loss: 0.228506, acc.: 60.94%] [G loss: 0.326672]\n",
      "epoch:6 step:5815 [D loss: 0.248774, acc.: 57.81%] [G loss: 0.286223]\n",
      "epoch:6 step:5816 [D loss: 0.247503, acc.: 57.81%] [G loss: 0.286350]\n",
      "epoch:6 step:5817 [D loss: 0.235198, acc.: 60.94%] [G loss: 0.309262]\n",
      "epoch:6 step:5818 [D loss: 0.248370, acc.: 51.56%] [G loss: 0.302659]\n",
      "epoch:6 step:5819 [D loss: 0.226195, acc.: 64.84%] [G loss: 0.304836]\n",
      "epoch:6 step:5820 [D loss: 0.237814, acc.: 57.03%] [G loss: 0.264495]\n",
      "epoch:6 step:5821 [D loss: 0.234816, acc.: 61.72%] [G loss: 0.309664]\n",
      "epoch:6 step:5822 [D loss: 0.255372, acc.: 55.47%] [G loss: 0.291869]\n",
      "epoch:6 step:5823 [D loss: 0.227496, acc.: 63.28%] [G loss: 0.312519]\n",
      "epoch:6 step:5824 [D loss: 0.233619, acc.: 61.72%] [G loss: 0.289160]\n",
      "epoch:6 step:5825 [D loss: 0.249202, acc.: 53.91%] [G loss: 0.313126]\n",
      "epoch:6 step:5826 [D loss: 0.234777, acc.: 57.81%] [G loss: 0.334580]\n",
      "epoch:6 step:5827 [D loss: 0.252123, acc.: 53.91%] [G loss: 0.273697]\n",
      "epoch:6 step:5828 [D loss: 0.250751, acc.: 53.91%] [G loss: 0.296476]\n",
      "epoch:6 step:5829 [D loss: 0.234265, acc.: 54.69%] [G loss: 0.339813]\n",
      "epoch:6 step:5830 [D loss: 0.235745, acc.: 57.81%] [G loss: 0.306981]\n",
      "epoch:6 step:5831 [D loss: 0.221039, acc.: 67.19%] [G loss: 0.330181]\n",
      "epoch:6 step:5832 [D loss: 0.241784, acc.: 57.81%] [G loss: 0.294774]\n",
      "epoch:6 step:5833 [D loss: 0.235477, acc.: 59.38%] [G loss: 0.316435]\n",
      "epoch:6 step:5834 [D loss: 0.229808, acc.: 60.16%] [G loss: 0.302257]\n",
      "epoch:6 step:5835 [D loss: 0.252034, acc.: 51.56%] [G loss: 0.308565]\n",
      "epoch:6 step:5836 [D loss: 0.262474, acc.: 52.34%] [G loss: 0.308866]\n",
      "epoch:6 step:5837 [D loss: 0.238968, acc.: 60.16%] [G loss: 0.301264]\n",
      "epoch:6 step:5838 [D loss: 0.254215, acc.: 52.34%] [G loss: 0.287180]\n",
      "epoch:6 step:5839 [D loss: 0.240450, acc.: 60.16%] [G loss: 0.282777]\n",
      "epoch:6 step:5840 [D loss: 0.257111, acc.: 53.91%] [G loss: 0.317071]\n",
      "epoch:6 step:5841 [D loss: 0.268120, acc.: 46.88%] [G loss: 0.304959]\n",
      "epoch:6 step:5842 [D loss: 0.234819, acc.: 58.59%] [G loss: 0.313449]\n",
      "epoch:6 step:5843 [D loss: 0.231780, acc.: 58.59%] [G loss: 0.315124]\n",
      "epoch:6 step:5844 [D loss: 0.244930, acc.: 59.38%] [G loss: 0.296477]\n",
      "epoch:6 step:5845 [D loss: 0.242271, acc.: 56.25%] [G loss: 0.323497]\n",
      "epoch:6 step:5846 [D loss: 0.251718, acc.: 52.34%] [G loss: 0.301781]\n",
      "epoch:6 step:5847 [D loss: 0.260925, acc.: 50.78%] [G loss: 0.323001]\n",
      "epoch:6 step:5848 [D loss: 0.247959, acc.: 57.81%] [G loss: 0.285520]\n",
      "epoch:6 step:5849 [D loss: 0.266024, acc.: 42.97%] [G loss: 0.290400]\n",
      "epoch:6 step:5850 [D loss: 0.238137, acc.: 56.25%] [G loss: 0.294365]\n",
      "epoch:6 step:5851 [D loss: 0.226363, acc.: 68.75%] [G loss: 0.272222]\n",
      "epoch:6 step:5852 [D loss: 0.248144, acc.: 54.69%] [G loss: 0.301855]\n",
      "epoch:6 step:5853 [D loss: 0.249387, acc.: 58.59%] [G loss: 0.301208]\n",
      "epoch:6 step:5854 [D loss: 0.241096, acc.: 57.81%] [G loss: 0.295148]\n",
      "epoch:6 step:5855 [D loss: 0.229429, acc.: 64.84%] [G loss: 0.304598]\n",
      "epoch:6 step:5856 [D loss: 0.255292, acc.: 49.22%] [G loss: 0.298031]\n",
      "epoch:6 step:5857 [D loss: 0.235451, acc.: 58.59%] [G loss: 0.310882]\n",
      "epoch:6 step:5858 [D loss: 0.251884, acc.: 51.56%] [G loss: 0.311521]\n",
      "epoch:6 step:5859 [D loss: 0.248948, acc.: 53.12%] [G loss: 0.312297]\n",
      "epoch:6 step:5860 [D loss: 0.229465, acc.: 63.28%] [G loss: 0.306379]\n",
      "epoch:6 step:5861 [D loss: 0.233607, acc.: 61.72%] [G loss: 0.300879]\n",
      "epoch:6 step:5862 [D loss: 0.243209, acc.: 56.25%] [G loss: 0.335851]\n",
      "epoch:6 step:5863 [D loss: 0.263123, acc.: 49.22%] [G loss: 0.319145]\n",
      "epoch:6 step:5864 [D loss: 0.234669, acc.: 57.03%] [G loss: 0.291703]\n",
      "epoch:6 step:5865 [D loss: 0.260191, acc.: 52.34%] [G loss: 0.283952]\n",
      "epoch:6 step:5866 [D loss: 0.239337, acc.: 60.16%] [G loss: 0.278468]\n",
      "epoch:6 step:5867 [D loss: 0.270761, acc.: 42.97%] [G loss: 0.289252]\n",
      "epoch:6 step:5868 [D loss: 0.245342, acc.: 60.94%] [G loss: 0.265412]\n",
      "epoch:6 step:5869 [D loss: 0.240125, acc.: 58.59%] [G loss: 0.285442]\n",
      "epoch:6 step:5870 [D loss: 0.242158, acc.: 57.81%] [G loss: 0.299355]\n",
      "epoch:6 step:5871 [D loss: 0.247795, acc.: 57.81%] [G loss: 0.305818]\n",
      "epoch:6 step:5872 [D loss: 0.235143, acc.: 60.94%] [G loss: 0.304973]\n",
      "epoch:6 step:5873 [D loss: 0.266258, acc.: 53.12%] [G loss: 0.287857]\n",
      "epoch:6 step:5874 [D loss: 0.229719, acc.: 64.84%] [G loss: 0.294924]\n",
      "epoch:6 step:5875 [D loss: 0.240618, acc.: 60.16%] [G loss: 0.277767]\n",
      "epoch:6 step:5876 [D loss: 0.255509, acc.: 50.78%] [G loss: 0.273825]\n",
      "epoch:6 step:5877 [D loss: 0.248290, acc.: 57.03%] [G loss: 0.295737]\n",
      "epoch:6 step:5878 [D loss: 0.239613, acc.: 58.59%] [G loss: 0.306161]\n",
      "epoch:6 step:5879 [D loss: 0.239421, acc.: 56.25%] [G loss: 0.275721]\n",
      "epoch:6 step:5880 [D loss: 0.241874, acc.: 58.59%] [G loss: 0.269865]\n",
      "epoch:6 step:5881 [D loss: 0.234646, acc.: 57.03%] [G loss: 0.295910]\n",
      "epoch:6 step:5882 [D loss: 0.246980, acc.: 53.12%] [G loss: 0.280536]\n",
      "epoch:6 step:5883 [D loss: 0.236038, acc.: 58.59%] [G loss: 0.324900]\n",
      "epoch:6 step:5884 [D loss: 0.227809, acc.: 64.06%] [G loss: 0.329431]\n",
      "epoch:6 step:5885 [D loss: 0.242364, acc.: 59.38%] [G loss: 0.294418]\n",
      "epoch:6 step:5886 [D loss: 0.262736, acc.: 53.12%] [G loss: 0.313985]\n",
      "epoch:6 step:5887 [D loss: 0.244965, acc.: 58.59%] [G loss: 0.302192]\n",
      "epoch:6 step:5888 [D loss: 0.224549, acc.: 64.84%] [G loss: 0.308964]\n",
      "epoch:6 step:5889 [D loss: 0.247454, acc.: 51.56%] [G loss: 0.281194]\n",
      "epoch:6 step:5890 [D loss: 0.228105, acc.: 63.28%] [G loss: 0.315334]\n",
      "epoch:6 step:5891 [D loss: 0.239807, acc.: 60.16%] [G loss: 0.301697]\n",
      "epoch:6 step:5892 [D loss: 0.241034, acc.: 56.25%] [G loss: 0.326727]\n",
      "epoch:6 step:5893 [D loss: 0.244421, acc.: 55.47%] [G loss: 0.290979]\n",
      "epoch:6 step:5894 [D loss: 0.243051, acc.: 57.03%] [G loss: 0.293248]\n",
      "epoch:6 step:5895 [D loss: 0.235875, acc.: 57.03%] [G loss: 0.314030]\n",
      "epoch:6 step:5896 [D loss: 0.251959, acc.: 50.78%] [G loss: 0.269738]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:6 step:5897 [D loss: 0.239045, acc.: 57.81%] [G loss: 0.318637]\n",
      "epoch:6 step:5898 [D loss: 0.249952, acc.: 55.47%] [G loss: 0.285478]\n",
      "epoch:6 step:5899 [D loss: 0.232633, acc.: 57.81%] [G loss: 0.286341]\n",
      "epoch:6 step:5900 [D loss: 0.247759, acc.: 57.03%] [G loss: 0.316815]\n",
      "epoch:6 step:5901 [D loss: 0.244634, acc.: 55.47%] [G loss: 0.304813]\n",
      "epoch:6 step:5902 [D loss: 0.235192, acc.: 60.94%] [G loss: 0.327719]\n",
      "epoch:6 step:5903 [D loss: 0.233517, acc.: 61.72%] [G loss: 0.324904]\n",
      "epoch:6 step:5904 [D loss: 0.243779, acc.: 60.94%] [G loss: 0.294688]\n",
      "epoch:6 step:5905 [D loss: 0.244125, acc.: 60.16%] [G loss: 0.275074]\n",
      "epoch:6 step:5906 [D loss: 0.238092, acc.: 55.47%] [G loss: 0.300646]\n",
      "epoch:6 step:5907 [D loss: 0.260135, acc.: 50.00%] [G loss: 0.272734]\n",
      "epoch:6 step:5908 [D loss: 0.236169, acc.: 60.16%] [G loss: 0.300179]\n",
      "epoch:6 step:5909 [D loss: 0.232070, acc.: 61.72%] [G loss: 0.302012]\n",
      "epoch:6 step:5910 [D loss: 0.236183, acc.: 63.28%] [G loss: 0.307561]\n",
      "epoch:6 step:5911 [D loss: 0.220509, acc.: 65.62%] [G loss: 0.303925]\n",
      "epoch:6 step:5912 [D loss: 0.244093, acc.: 57.03%] [G loss: 0.303345]\n",
      "epoch:6 step:5913 [D loss: 0.237125, acc.: 61.72%] [G loss: 0.308185]\n",
      "epoch:6 step:5914 [D loss: 0.255405, acc.: 51.56%] [G loss: 0.299965]\n",
      "epoch:6 step:5915 [D loss: 0.236175, acc.: 64.84%] [G loss: 0.316648]\n",
      "epoch:6 step:5916 [D loss: 0.239938, acc.: 56.25%] [G loss: 0.307162]\n",
      "epoch:6 step:5917 [D loss: 0.230398, acc.: 60.16%] [G loss: 0.299140]\n",
      "epoch:6 step:5918 [D loss: 0.256417, acc.: 55.47%] [G loss: 0.279091]\n",
      "epoch:6 step:5919 [D loss: 0.239640, acc.: 60.94%] [G loss: 0.321443]\n",
      "epoch:6 step:5920 [D loss: 0.246391, acc.: 57.81%] [G loss: 0.280712]\n",
      "epoch:6 step:5921 [D loss: 0.241545, acc.: 57.03%] [G loss: 0.332066]\n",
      "epoch:6 step:5922 [D loss: 0.233851, acc.: 62.50%] [G loss: 0.326717]\n",
      "epoch:6 step:5923 [D loss: 0.246867, acc.: 57.81%] [G loss: 0.301724]\n",
      "epoch:6 step:5924 [D loss: 0.261624, acc.: 50.00%] [G loss: 0.309893]\n",
      "epoch:6 step:5925 [D loss: 0.246021, acc.: 60.94%] [G loss: 0.312918]\n",
      "epoch:6 step:5926 [D loss: 0.245638, acc.: 57.81%] [G loss: 0.307144]\n",
      "epoch:6 step:5927 [D loss: 0.246872, acc.: 55.47%] [G loss: 0.296581]\n",
      "epoch:6 step:5928 [D loss: 0.243359, acc.: 57.81%] [G loss: 0.288851]\n",
      "epoch:6 step:5929 [D loss: 0.232573, acc.: 63.28%] [G loss: 0.327239]\n",
      "epoch:6 step:5930 [D loss: 0.232281, acc.: 61.72%] [G loss: 0.316848]\n",
      "epoch:6 step:5931 [D loss: 0.237446, acc.: 63.28%] [G loss: 0.284882]\n",
      "epoch:6 step:5932 [D loss: 0.254044, acc.: 53.91%] [G loss: 0.276537]\n",
      "epoch:6 step:5933 [D loss: 0.236067, acc.: 57.03%] [G loss: 0.300960]\n",
      "epoch:6 step:5934 [D loss: 0.255084, acc.: 53.91%] [G loss: 0.274888]\n",
      "epoch:6 step:5935 [D loss: 0.265981, acc.: 50.78%] [G loss: 0.295900]\n",
      "epoch:6 step:5936 [D loss: 0.232633, acc.: 61.72%] [G loss: 0.276819]\n",
      "epoch:6 step:5937 [D loss: 0.258323, acc.: 51.56%] [G loss: 0.286686]\n",
      "epoch:6 step:5938 [D loss: 0.233628, acc.: 63.28%] [G loss: 0.288983]\n",
      "epoch:6 step:5939 [D loss: 0.240826, acc.: 60.16%] [G loss: 0.274223]\n",
      "epoch:6 step:5940 [D loss: 0.235600, acc.: 58.59%] [G loss: 0.280826]\n",
      "epoch:6 step:5941 [D loss: 0.258438, acc.: 54.69%] [G loss: 0.277321]\n",
      "epoch:6 step:5942 [D loss: 0.249424, acc.: 56.25%] [G loss: 0.294714]\n",
      "epoch:6 step:5943 [D loss: 0.235577, acc.: 63.28%] [G loss: 0.322307]\n",
      "epoch:6 step:5944 [D loss: 0.254124, acc.: 50.78%] [G loss: 0.300610]\n",
      "epoch:6 step:5945 [D loss: 0.253646, acc.: 53.91%] [G loss: 0.305733]\n",
      "epoch:6 step:5946 [D loss: 0.240020, acc.: 54.69%] [G loss: 0.331608]\n",
      "epoch:6 step:5947 [D loss: 0.240897, acc.: 53.91%] [G loss: 0.290010]\n",
      "epoch:6 step:5948 [D loss: 0.253791, acc.: 52.34%] [G loss: 0.303316]\n",
      "epoch:6 step:5949 [D loss: 0.247622, acc.: 50.00%] [G loss: 0.296683]\n",
      "epoch:6 step:5950 [D loss: 0.250191, acc.: 50.78%] [G loss: 0.294107]\n",
      "epoch:6 step:5951 [D loss: 0.241512, acc.: 55.47%] [G loss: 0.303978]\n",
      "epoch:6 step:5952 [D loss: 0.247194, acc.: 57.81%] [G loss: 0.272760]\n",
      "epoch:6 step:5953 [D loss: 0.232992, acc.: 63.28%] [G loss: 0.300865]\n",
      "epoch:6 step:5954 [D loss: 0.236322, acc.: 60.16%] [G loss: 0.301571]\n",
      "epoch:6 step:5955 [D loss: 0.239680, acc.: 56.25%] [G loss: 0.289342]\n",
      "epoch:6 step:5956 [D loss: 0.244886, acc.: 55.47%] [G loss: 0.309524]\n",
      "epoch:6 step:5957 [D loss: 0.242847, acc.: 55.47%] [G loss: 0.297216]\n",
      "epoch:6 step:5958 [D loss: 0.248083, acc.: 59.38%] [G loss: 0.280570]\n",
      "epoch:6 step:5959 [D loss: 0.235470, acc.: 60.16%] [G loss: 0.326863]\n",
      "epoch:6 step:5960 [D loss: 0.254160, acc.: 54.69%] [G loss: 0.297598]\n",
      "epoch:6 step:5961 [D loss: 0.225302, acc.: 66.41%] [G loss: 0.312477]\n",
      "epoch:6 step:5962 [D loss: 0.239415, acc.: 58.59%] [G loss: 0.296432]\n",
      "epoch:6 step:5963 [D loss: 0.241397, acc.: 59.38%] [G loss: 0.297111]\n",
      "epoch:6 step:5964 [D loss: 0.237791, acc.: 58.59%] [G loss: 0.296673]\n",
      "epoch:6 step:5965 [D loss: 0.255711, acc.: 55.47%] [G loss: 0.310218]\n",
      "epoch:6 step:5966 [D loss: 0.238911, acc.: 53.12%] [G loss: 0.302945]\n",
      "epoch:6 step:5967 [D loss: 0.248183, acc.: 56.25%] [G loss: 0.303524]\n",
      "epoch:6 step:5968 [D loss: 0.255443, acc.: 47.66%] [G loss: 0.281365]\n",
      "epoch:6 step:5969 [D loss: 0.244956, acc.: 52.34%] [G loss: 0.291965]\n",
      "epoch:6 step:5970 [D loss: 0.230914, acc.: 60.16%] [G loss: 0.332313]\n",
      "epoch:6 step:5971 [D loss: 0.246632, acc.: 52.34%] [G loss: 0.308855]\n",
      "epoch:6 step:5972 [D loss: 0.252860, acc.: 51.56%] [G loss: 0.301167]\n",
      "epoch:6 step:5973 [D loss: 0.243943, acc.: 63.28%] [G loss: 0.308710]\n",
      "epoch:6 step:5974 [D loss: 0.251180, acc.: 56.25%] [G loss: 0.288270]\n",
      "epoch:6 step:5975 [D loss: 0.236451, acc.: 61.72%] [G loss: 0.312257]\n",
      "epoch:6 step:5976 [D loss: 0.253601, acc.: 54.69%] [G loss: 0.278154]\n",
      "epoch:6 step:5977 [D loss: 0.240796, acc.: 60.94%] [G loss: 0.285779]\n",
      "epoch:6 step:5978 [D loss: 0.246972, acc.: 58.59%] [G loss: 0.291776]\n",
      "epoch:6 step:5979 [D loss: 0.232617, acc.: 59.38%] [G loss: 0.321978]\n",
      "epoch:6 step:5980 [D loss: 0.236034, acc.: 58.59%] [G loss: 0.277597]\n",
      "epoch:6 step:5981 [D loss: 0.239623, acc.: 55.47%] [G loss: 0.298487]\n",
      "epoch:6 step:5982 [D loss: 0.241279, acc.: 57.81%] [G loss: 0.288438]\n",
      "epoch:6 step:5983 [D loss: 0.226163, acc.: 62.50%] [G loss: 0.316582]\n",
      "epoch:6 step:5984 [D loss: 0.226164, acc.: 67.19%] [G loss: 0.328974]\n",
      "epoch:6 step:5985 [D loss: 0.236050, acc.: 58.59%] [G loss: 0.307094]\n",
      "epoch:6 step:5986 [D loss: 0.237920, acc.: 57.03%] [G loss: 0.293353]\n",
      "epoch:6 step:5987 [D loss: 0.239295, acc.: 58.59%] [G loss: 0.320548]\n",
      "epoch:6 step:5988 [D loss: 0.246356, acc.: 58.59%] [G loss: 0.295031]\n",
      "epoch:6 step:5989 [D loss: 0.244318, acc.: 55.47%] [G loss: 0.311577]\n",
      "epoch:6 step:5990 [D loss: 0.225310, acc.: 64.84%] [G loss: 0.305524]\n",
      "epoch:6 step:5991 [D loss: 0.246970, acc.: 53.12%] [G loss: 0.289183]\n",
      "epoch:6 step:5992 [D loss: 0.268859, acc.: 52.34%] [G loss: 0.281142]\n",
      "epoch:6 step:5993 [D loss: 0.229891, acc.: 61.72%] [G loss: 0.313281]\n",
      "epoch:6 step:5994 [D loss: 0.249813, acc.: 53.91%] [G loss: 0.324455]\n",
      "epoch:6 step:5995 [D loss: 0.245800, acc.: 54.69%] [G loss: 0.330844]\n",
      "epoch:6 step:5996 [D loss: 0.249236, acc.: 57.81%] [G loss: 0.299930]\n",
      "epoch:6 step:5997 [D loss: 0.252228, acc.: 51.56%] [G loss: 0.338800]\n",
      "epoch:6 step:5998 [D loss: 0.257394, acc.: 51.56%] [G loss: 0.322386]\n",
      "epoch:6 step:5999 [D loss: 0.243038, acc.: 53.91%] [G loss: 0.321202]\n",
      "epoch:6 step:6000 [D loss: 0.241915, acc.: 60.16%] [G loss: 0.294360]\n",
      "epoch:6 step:6001 [D loss: 0.257840, acc.: 51.56%] [G loss: 0.278224]\n",
      "epoch:6 step:6002 [D loss: 0.236457, acc.: 59.38%] [G loss: 0.298071]\n",
      "epoch:6 step:6003 [D loss: 0.257234, acc.: 51.56%] [G loss: 0.272555]\n",
      "epoch:6 step:6004 [D loss: 0.243529, acc.: 55.47%] [G loss: 0.283468]\n",
      "epoch:6 step:6005 [D loss: 0.259879, acc.: 51.56%] [G loss: 0.304873]\n",
      "epoch:6 step:6006 [D loss: 0.251068, acc.: 53.12%] [G loss: 0.312374]\n",
      "epoch:6 step:6007 [D loss: 0.222454, acc.: 63.28%] [G loss: 0.301736]\n",
      "epoch:6 step:6008 [D loss: 0.249601, acc.: 53.91%] [G loss: 0.286951]\n",
      "epoch:6 step:6009 [D loss: 0.257434, acc.: 50.78%] [G loss: 0.303683]\n",
      "epoch:6 step:6010 [D loss: 0.244563, acc.: 51.56%] [G loss: 0.303214]\n",
      "epoch:6 step:6011 [D loss: 0.243673, acc.: 50.00%] [G loss: 0.305058]\n",
      "epoch:6 step:6012 [D loss: 0.237783, acc.: 62.50%] [G loss: 0.283615]\n",
      "epoch:6 step:6013 [D loss: 0.237922, acc.: 58.59%] [G loss: 0.296119]\n",
      "epoch:6 step:6014 [D loss: 0.254322, acc.: 52.34%] [G loss: 0.305381]\n",
      "epoch:6 step:6015 [D loss: 0.244347, acc.: 55.47%] [G loss: 0.301354]\n",
      "epoch:6 step:6016 [D loss: 0.243641, acc.: 64.06%] [G loss: 0.296940]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:6 step:6017 [D loss: 0.243958, acc.: 57.03%] [G loss: 0.305856]\n",
      "epoch:6 step:6018 [D loss: 0.246231, acc.: 50.00%] [G loss: 0.294797]\n",
      "epoch:6 step:6019 [D loss: 0.255500, acc.: 50.78%] [G loss: 0.329649]\n",
      "epoch:6 step:6020 [D loss: 0.245973, acc.: 55.47%] [G loss: 0.311571]\n",
      "epoch:6 step:6021 [D loss: 0.234354, acc.: 59.38%] [G loss: 0.308580]\n",
      "epoch:6 step:6022 [D loss: 0.256566, acc.: 52.34%] [G loss: 0.309602]\n",
      "epoch:6 step:6023 [D loss: 0.260660, acc.: 53.91%] [G loss: 0.293807]\n",
      "epoch:6 step:6024 [D loss: 0.231969, acc.: 58.59%] [G loss: 0.290307]\n",
      "epoch:6 step:6025 [D loss: 0.229944, acc.: 61.72%] [G loss: 0.311937]\n",
      "epoch:6 step:6026 [D loss: 0.233009, acc.: 65.62%] [G loss: 0.311333]\n",
      "epoch:6 step:6027 [D loss: 0.239895, acc.: 60.16%] [G loss: 0.294368]\n",
      "epoch:6 step:6028 [D loss: 0.232705, acc.: 62.50%] [G loss: 0.312922]\n",
      "epoch:6 step:6029 [D loss: 0.258038, acc.: 48.44%] [G loss: 0.298485]\n",
      "epoch:6 step:6030 [D loss: 0.256929, acc.: 51.56%] [G loss: 0.303119]\n",
      "epoch:6 step:6031 [D loss: 0.229986, acc.: 60.94%] [G loss: 0.328808]\n",
      "epoch:6 step:6032 [D loss: 0.243872, acc.: 57.03%] [G loss: 0.289644]\n",
      "epoch:6 step:6033 [D loss: 0.255728, acc.: 53.12%] [G loss: 0.294875]\n",
      "epoch:6 step:6034 [D loss: 0.254111, acc.: 56.25%] [G loss: 0.304836]\n",
      "epoch:6 step:6035 [D loss: 0.253522, acc.: 57.03%] [G loss: 0.309304]\n",
      "epoch:6 step:6036 [D loss: 0.242799, acc.: 57.03%] [G loss: 0.348449]\n",
      "epoch:6 step:6037 [D loss: 0.238853, acc.: 57.81%] [G loss: 0.276687]\n",
      "epoch:6 step:6038 [D loss: 0.243827, acc.: 53.91%] [G loss: 0.256516]\n",
      "epoch:6 step:6039 [D loss: 0.252983, acc.: 54.69%] [G loss: 0.304669]\n",
      "epoch:6 step:6040 [D loss: 0.238640, acc.: 55.47%] [G loss: 0.302525]\n",
      "epoch:6 step:6041 [D loss: 0.238210, acc.: 62.50%] [G loss: 0.305052]\n",
      "epoch:6 step:6042 [D loss: 0.227430, acc.: 65.62%] [G loss: 0.268863]\n",
      "epoch:6 step:6043 [D loss: 0.248324, acc.: 51.56%] [G loss: 0.293124]\n",
      "epoch:6 step:6044 [D loss: 0.240237, acc.: 58.59%] [G loss: 0.315545]\n",
      "epoch:6 step:6045 [D loss: 0.249422, acc.: 57.03%] [G loss: 0.321566]\n",
      "epoch:6 step:6046 [D loss: 0.230466, acc.: 57.03%] [G loss: 0.289511]\n",
      "epoch:6 step:6047 [D loss: 0.244786, acc.: 56.25%] [G loss: 0.295012]\n",
      "epoch:6 step:6048 [D loss: 0.233802, acc.: 59.38%] [G loss: 0.304293]\n",
      "epoch:6 step:6049 [D loss: 0.254979, acc.: 52.34%] [G loss: 0.277028]\n",
      "epoch:6 step:6050 [D loss: 0.244595, acc.: 60.16%] [G loss: 0.302843]\n",
      "epoch:6 step:6051 [D loss: 0.237460, acc.: 58.59%] [G loss: 0.277991]\n",
      "epoch:6 step:6052 [D loss: 0.252484, acc.: 51.56%] [G loss: 0.299176]\n",
      "epoch:6 step:6053 [D loss: 0.243949, acc.: 56.25%] [G loss: 0.326328]\n",
      "epoch:6 step:6054 [D loss: 0.213024, acc.: 67.97%] [G loss: 0.312678]\n",
      "epoch:6 step:6055 [D loss: 0.229310, acc.: 62.50%] [G loss: 0.310135]\n",
      "epoch:6 step:6056 [D loss: 0.245906, acc.: 50.78%] [G loss: 0.274826]\n",
      "epoch:6 step:6057 [D loss: 0.241751, acc.: 52.34%] [G loss: 0.307039]\n",
      "epoch:6 step:6058 [D loss: 0.249016, acc.: 54.69%] [G loss: 0.291295]\n",
      "epoch:6 step:6059 [D loss: 0.227992, acc.: 61.72%] [G loss: 0.286972]\n",
      "epoch:6 step:6060 [D loss: 0.257735, acc.: 46.09%] [G loss: 0.311468]\n",
      "epoch:6 step:6061 [D loss: 0.239920, acc.: 57.81%] [G loss: 0.299650]\n",
      "epoch:6 step:6062 [D loss: 0.224269, acc.: 64.84%] [G loss: 0.307332]\n",
      "epoch:6 step:6063 [D loss: 0.247976, acc.: 53.91%] [G loss: 0.316654]\n",
      "epoch:6 step:6064 [D loss: 0.242100, acc.: 55.47%] [G loss: 0.281638]\n",
      "epoch:6 step:6065 [D loss: 0.245982, acc.: 53.12%] [G loss: 0.286112]\n",
      "epoch:6 step:6066 [D loss: 0.231726, acc.: 63.28%] [G loss: 0.320117]\n",
      "epoch:6 step:6067 [D loss: 0.240987, acc.: 59.38%] [G loss: 0.326007]\n",
      "epoch:6 step:6068 [D loss: 0.253208, acc.: 54.69%] [G loss: 0.289160]\n",
      "epoch:6 step:6069 [D loss: 0.233522, acc.: 57.03%] [G loss: 0.300616]\n",
      "epoch:6 step:6070 [D loss: 0.250427, acc.: 52.34%] [G loss: 0.294936]\n",
      "epoch:6 step:6071 [D loss: 0.238878, acc.: 60.94%] [G loss: 0.274894]\n",
      "epoch:6 step:6072 [D loss: 0.258641, acc.: 51.56%] [G loss: 0.309699]\n",
      "epoch:6 step:6073 [D loss: 0.231749, acc.: 59.38%] [G loss: 0.307250]\n",
      "epoch:6 step:6074 [D loss: 0.238206, acc.: 59.38%] [G loss: 0.300446]\n",
      "epoch:6 step:6075 [D loss: 0.228508, acc.: 62.50%] [G loss: 0.301154]\n",
      "epoch:6 step:6076 [D loss: 0.242137, acc.: 57.81%] [G loss: 0.309558]\n",
      "epoch:6 step:6077 [D loss: 0.232523, acc.: 61.72%] [G loss: 0.315190]\n",
      "epoch:6 step:6078 [D loss: 0.236679, acc.: 61.72%] [G loss: 0.302611]\n",
      "epoch:6 step:6079 [D loss: 0.244492, acc.: 59.38%] [G loss: 0.315266]\n",
      "epoch:6 step:6080 [D loss: 0.234402, acc.: 62.50%] [G loss: 0.321146]\n",
      "epoch:6 step:6081 [D loss: 0.223130, acc.: 66.41%] [G loss: 0.298951]\n",
      "epoch:6 step:6082 [D loss: 0.246776, acc.: 54.69%] [G loss: 0.306114]\n",
      "epoch:6 step:6083 [D loss: 0.261640, acc.: 45.31%] [G loss: 0.298996]\n",
      "epoch:6 step:6084 [D loss: 0.235383, acc.: 59.38%] [G loss: 0.257593]\n",
      "epoch:6 step:6085 [D loss: 0.274756, acc.: 49.22%] [G loss: 0.260747]\n",
      "epoch:6 step:6086 [D loss: 0.230564, acc.: 61.72%] [G loss: 0.291211]\n",
      "epoch:6 step:6087 [D loss: 0.235123, acc.: 62.50%] [G loss: 0.311105]\n",
      "epoch:6 step:6088 [D loss: 0.237641, acc.: 57.81%] [G loss: 0.282903]\n",
      "epoch:6 step:6089 [D loss: 0.238457, acc.: 57.03%] [G loss: 0.271546]\n",
      "epoch:6 step:6090 [D loss: 0.244222, acc.: 59.38%] [G loss: 0.299946]\n",
      "epoch:6 step:6091 [D loss: 0.232135, acc.: 63.28%] [G loss: 0.289685]\n",
      "epoch:6 step:6092 [D loss: 0.254065, acc.: 52.34%] [G loss: 0.267468]\n",
      "epoch:6 step:6093 [D loss: 0.248114, acc.: 55.47%] [G loss: 0.261288]\n",
      "epoch:6 step:6094 [D loss: 0.256273, acc.: 60.94%] [G loss: 0.263776]\n",
      "epoch:6 step:6095 [D loss: 0.241029, acc.: 57.03%] [G loss: 0.299896]\n",
      "epoch:6 step:6096 [D loss: 0.241618, acc.: 58.59%] [G loss: 0.302908]\n",
      "epoch:6 step:6097 [D loss: 0.249397, acc.: 57.03%] [G loss: 0.299863]\n",
      "epoch:6 step:6098 [D loss: 0.248343, acc.: 51.56%] [G loss: 0.295298]\n",
      "epoch:6 step:6099 [D loss: 0.256294, acc.: 54.69%] [G loss: 0.301713]\n",
      "epoch:6 step:6100 [D loss: 0.242437, acc.: 61.72%] [G loss: 0.295861]\n",
      "epoch:6 step:6101 [D loss: 0.249624, acc.: 52.34%] [G loss: 0.293158]\n",
      "epoch:6 step:6102 [D loss: 0.232144, acc.: 64.06%] [G loss: 0.313870]\n",
      "epoch:6 step:6103 [D loss: 0.249658, acc.: 53.12%] [G loss: 0.288435]\n",
      "epoch:6 step:6104 [D loss: 0.236103, acc.: 58.59%] [G loss: 0.311111]\n",
      "epoch:6 step:6105 [D loss: 0.256822, acc.: 50.00%] [G loss: 0.302194]\n",
      "epoch:6 step:6106 [D loss: 0.243487, acc.: 54.69%] [G loss: 0.325293]\n",
      "epoch:6 step:6107 [D loss: 0.241257, acc.: 60.16%] [G loss: 0.314759]\n",
      "epoch:6 step:6108 [D loss: 0.229096, acc.: 63.28%] [G loss: 0.317865]\n",
      "epoch:6 step:6109 [D loss: 0.251940, acc.: 49.22%] [G loss: 0.303048]\n",
      "epoch:6 step:6110 [D loss: 0.221625, acc.: 65.62%] [G loss: 0.300078]\n",
      "epoch:6 step:6111 [D loss: 0.250931, acc.: 55.47%] [G loss: 0.290463]\n",
      "epoch:6 step:6112 [D loss: 0.238002, acc.: 60.16%] [G loss: 0.322410]\n",
      "epoch:6 step:6113 [D loss: 0.239682, acc.: 57.03%] [G loss: 0.301504]\n",
      "epoch:6 step:6114 [D loss: 0.233657, acc.: 59.38%] [G loss: 0.304337]\n",
      "epoch:6 step:6115 [D loss: 0.243820, acc.: 59.38%] [G loss: 0.290517]\n",
      "epoch:6 step:6116 [D loss: 0.244338, acc.: 60.16%] [G loss: 0.328247]\n",
      "epoch:6 step:6117 [D loss: 0.256808, acc.: 48.44%] [G loss: 0.304207]\n",
      "epoch:6 step:6118 [D loss: 0.239417, acc.: 55.47%] [G loss: 0.318512]\n",
      "epoch:6 step:6119 [D loss: 0.250671, acc.: 52.34%] [G loss: 0.289130]\n",
      "epoch:6 step:6120 [D loss: 0.231527, acc.: 62.50%] [G loss: 0.321217]\n",
      "epoch:6 step:6121 [D loss: 0.244760, acc.: 57.03%] [G loss: 0.309158]\n",
      "epoch:6 step:6122 [D loss: 0.260657, acc.: 55.47%] [G loss: 0.287730]\n",
      "epoch:6 step:6123 [D loss: 0.229419, acc.: 61.72%] [G loss: 0.296534]\n",
      "epoch:6 step:6124 [D loss: 0.245086, acc.: 57.03%] [G loss: 0.325576]\n",
      "epoch:6 step:6125 [D loss: 0.236213, acc.: 60.16%] [G loss: 0.275946]\n",
      "epoch:6 step:6126 [D loss: 0.233274, acc.: 59.38%] [G loss: 0.319018]\n",
      "epoch:6 step:6127 [D loss: 0.237184, acc.: 57.81%] [G loss: 0.303142]\n",
      "epoch:6 step:6128 [D loss: 0.238229, acc.: 59.38%] [G loss: 0.289230]\n",
      "epoch:6 step:6129 [D loss: 0.245922, acc.: 56.25%] [G loss: 0.297448]\n",
      "epoch:6 step:6130 [D loss: 0.238549, acc.: 55.47%] [G loss: 0.313222]\n",
      "epoch:6 step:6131 [D loss: 0.245232, acc.: 56.25%] [G loss: 0.280977]\n",
      "epoch:6 step:6132 [D loss: 0.243271, acc.: 57.81%] [G loss: 0.307483]\n",
      "epoch:6 step:6133 [D loss: 0.229526, acc.: 61.72%] [G loss: 0.307152]\n",
      "epoch:6 step:6134 [D loss: 0.238303, acc.: 58.59%] [G loss: 0.336521]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:6 step:6135 [D loss: 0.237888, acc.: 56.25%] [G loss: 0.304825]\n",
      "epoch:6 step:6136 [D loss: 0.241515, acc.: 55.47%] [G loss: 0.299078]\n",
      "epoch:6 step:6137 [D loss: 0.247964, acc.: 50.78%] [G loss: 0.310015]\n",
      "epoch:6 step:6138 [D loss: 0.237896, acc.: 60.94%] [G loss: 0.306880]\n",
      "epoch:6 step:6139 [D loss: 0.230931, acc.: 60.16%] [G loss: 0.311440]\n",
      "epoch:6 step:6140 [D loss: 0.241322, acc.: 57.03%] [G loss: 0.314287]\n",
      "epoch:6 step:6141 [D loss: 0.239930, acc.: 60.94%] [G loss: 0.272135]\n",
      "epoch:6 step:6142 [D loss: 0.243071, acc.: 56.25%] [G loss: 0.332566]\n",
      "epoch:6 step:6143 [D loss: 0.251590, acc.: 50.78%] [G loss: 0.305939]\n",
      "epoch:6 step:6144 [D loss: 0.239865, acc.: 57.81%] [G loss: 0.322520]\n",
      "epoch:6 step:6145 [D loss: 0.239026, acc.: 58.59%] [G loss: 0.303825]\n",
      "epoch:6 step:6146 [D loss: 0.244475, acc.: 56.25%] [G loss: 0.288667]\n",
      "epoch:6 step:6147 [D loss: 0.241073, acc.: 58.59%] [G loss: 0.326138]\n",
      "epoch:6 step:6148 [D loss: 0.252637, acc.: 52.34%] [G loss: 0.301715]\n",
      "epoch:6 step:6149 [D loss: 0.259370, acc.: 51.56%] [G loss: 0.305306]\n",
      "epoch:6 step:6150 [D loss: 0.230517, acc.: 64.06%] [G loss: 0.303433]\n",
      "epoch:6 step:6151 [D loss: 0.243777, acc.: 55.47%] [G loss: 0.323148]\n",
      "epoch:6 step:6152 [D loss: 0.239790, acc.: 54.69%] [G loss: 0.306092]\n",
      "epoch:6 step:6153 [D loss: 0.251739, acc.: 53.91%] [G loss: 0.306379]\n",
      "epoch:6 step:6154 [D loss: 0.256419, acc.: 53.91%] [G loss: 0.292749]\n",
      "epoch:6 step:6155 [D loss: 0.255069, acc.: 55.47%] [G loss: 0.312612]\n",
      "epoch:6 step:6156 [D loss: 0.254752, acc.: 52.34%] [G loss: 0.289311]\n",
      "epoch:6 step:6157 [D loss: 0.239929, acc.: 58.59%] [G loss: 0.343750]\n",
      "epoch:6 step:6158 [D loss: 0.248001, acc.: 55.47%] [G loss: 0.309640]\n",
      "epoch:6 step:6159 [D loss: 0.246116, acc.: 54.69%] [G loss: 0.314243]\n",
      "epoch:6 step:6160 [D loss: 0.236372, acc.: 56.25%] [G loss: 0.298749]\n",
      "epoch:6 step:6161 [D loss: 0.236553, acc.: 57.03%] [G loss: 0.285907]\n",
      "epoch:6 step:6162 [D loss: 0.237672, acc.: 54.69%] [G loss: 0.322605]\n",
      "epoch:6 step:6163 [D loss: 0.251800, acc.: 52.34%] [G loss: 0.291540]\n",
      "epoch:6 step:6164 [D loss: 0.220852, acc.: 64.06%] [G loss: 0.344278]\n",
      "epoch:6 step:6165 [D loss: 0.244764, acc.: 51.56%] [G loss: 0.279452]\n",
      "epoch:6 step:6166 [D loss: 0.235674, acc.: 57.81%] [G loss: 0.289226]\n",
      "epoch:6 step:6167 [D loss: 0.238490, acc.: 59.38%] [G loss: 0.319529]\n",
      "epoch:6 step:6168 [D loss: 0.234791, acc.: 63.28%] [G loss: 0.296952]\n",
      "epoch:6 step:6169 [D loss: 0.246285, acc.: 55.47%] [G loss: 0.299605]\n",
      "epoch:6 step:6170 [D loss: 0.259544, acc.: 53.91%] [G loss: 0.288449]\n",
      "epoch:6 step:6171 [D loss: 0.232135, acc.: 68.75%] [G loss: 0.280994]\n",
      "epoch:6 step:6172 [D loss: 0.238183, acc.: 60.94%] [G loss: 0.301076]\n",
      "epoch:6 step:6173 [D loss: 0.261214, acc.: 48.44%] [G loss: 0.310347]\n",
      "epoch:6 step:6174 [D loss: 0.248360, acc.: 57.81%] [G loss: 0.302392]\n",
      "epoch:6 step:6175 [D loss: 0.247019, acc.: 49.22%] [G loss: 0.303784]\n",
      "epoch:6 step:6176 [D loss: 0.236302, acc.: 58.59%] [G loss: 0.305972]\n",
      "epoch:6 step:6177 [D loss: 0.242173, acc.: 57.03%] [G loss: 0.325266]\n",
      "epoch:6 step:6178 [D loss: 0.263652, acc.: 50.78%] [G loss: 0.303410]\n",
      "epoch:6 step:6179 [D loss: 0.238150, acc.: 57.03%] [G loss: 0.296252]\n",
      "epoch:6 step:6180 [D loss: 0.248480, acc.: 54.69%] [G loss: 0.308029]\n",
      "epoch:6 step:6181 [D loss: 0.239144, acc.: 58.59%] [G loss: 0.299669]\n",
      "epoch:6 step:6182 [D loss: 0.254024, acc.: 52.34%] [G loss: 0.304758]\n",
      "epoch:6 step:6183 [D loss: 0.250937, acc.: 53.91%] [G loss: 0.280183]\n",
      "epoch:6 step:6184 [D loss: 0.249529, acc.: 53.91%] [G loss: 0.307747]\n",
      "epoch:6 step:6185 [D loss: 0.243502, acc.: 58.59%] [G loss: 0.296287]\n",
      "epoch:6 step:6186 [D loss: 0.237427, acc.: 59.38%] [G loss: 0.304873]\n",
      "epoch:6 step:6187 [D loss: 0.250730, acc.: 57.03%] [G loss: 0.294249]\n",
      "epoch:6 step:6188 [D loss: 0.251983, acc.: 54.69%] [G loss: 0.316492]\n",
      "epoch:6 step:6189 [D loss: 0.248303, acc.: 53.91%] [G loss: 0.277838]\n",
      "epoch:6 step:6190 [D loss: 0.239152, acc.: 61.72%] [G loss: 0.304945]\n",
      "epoch:6 step:6191 [D loss: 0.240968, acc.: 60.16%] [G loss: 0.338500]\n",
      "epoch:6 step:6192 [D loss: 0.246354, acc.: 50.00%] [G loss: 0.310367]\n",
      "epoch:6 step:6193 [D loss: 0.254292, acc.: 49.22%] [G loss: 0.302372]\n",
      "epoch:6 step:6194 [D loss: 0.221068, acc.: 66.41%] [G loss: 0.301427]\n",
      "epoch:6 step:6195 [D loss: 0.242713, acc.: 58.59%] [G loss: 0.335775]\n",
      "epoch:6 step:6196 [D loss: 0.252958, acc.: 50.00%] [G loss: 0.302944]\n",
      "epoch:6 step:6197 [D loss: 0.261731, acc.: 54.69%] [G loss: 0.305637]\n",
      "epoch:6 step:6198 [D loss: 0.233651, acc.: 61.72%] [G loss: 0.321524]\n",
      "epoch:6 step:6199 [D loss: 0.242853, acc.: 53.12%] [G loss: 0.281026]\n",
      "epoch:6 step:6200 [D loss: 0.234634, acc.: 57.81%] [G loss: 0.323919]\n",
      "epoch:6 step:6201 [D loss: 0.244035, acc.: 57.03%] [G loss: 0.288529]\n",
      "epoch:6 step:6202 [D loss: 0.252145, acc.: 53.12%] [G loss: 0.301111]\n",
      "epoch:6 step:6203 [D loss: 0.231562, acc.: 60.16%] [G loss: 0.319215]\n",
      "epoch:6 step:6204 [D loss: 0.232940, acc.: 60.94%] [G loss: 0.330138]\n",
      "epoch:6 step:6205 [D loss: 0.228913, acc.: 61.72%] [G loss: 0.283987]\n",
      "epoch:6 step:6206 [D loss: 0.249638, acc.: 57.03%] [G loss: 0.307795]\n",
      "epoch:6 step:6207 [D loss: 0.257800, acc.: 49.22%] [G loss: 0.295875]\n",
      "epoch:6 step:6208 [D loss: 0.238510, acc.: 58.59%] [G loss: 0.291841]\n",
      "epoch:6 step:6209 [D loss: 0.249670, acc.: 57.03%] [G loss: 0.301338]\n",
      "epoch:6 step:6210 [D loss: 0.253713, acc.: 54.69%] [G loss: 0.299082]\n",
      "epoch:6 step:6211 [D loss: 0.247670, acc.: 60.16%] [G loss: 0.289050]\n",
      "epoch:6 step:6212 [D loss: 0.253674, acc.: 50.78%] [G loss: 0.260942]\n",
      "epoch:6 step:6213 [D loss: 0.241607, acc.: 59.38%] [G loss: 0.281892]\n",
      "epoch:6 step:6214 [D loss: 0.249093, acc.: 53.12%] [G loss: 0.297869]\n",
      "epoch:6 step:6215 [D loss: 0.250219, acc.: 58.59%] [G loss: 0.287840]\n",
      "epoch:6 step:6216 [D loss: 0.241639, acc.: 55.47%] [G loss: 0.277345]\n",
      "epoch:6 step:6217 [D loss: 0.242120, acc.: 55.47%] [G loss: 0.300200]\n",
      "epoch:6 step:6218 [D loss: 0.242920, acc.: 57.03%] [G loss: 0.285940]\n",
      "epoch:6 step:6219 [D loss: 0.248370, acc.: 55.47%] [G loss: 0.277776]\n",
      "epoch:6 step:6220 [D loss: 0.226705, acc.: 61.72%] [G loss: 0.298055]\n",
      "epoch:6 step:6221 [D loss: 0.227531, acc.: 61.72%] [G loss: 0.288249]\n",
      "epoch:6 step:6222 [D loss: 0.245266, acc.: 53.91%] [G loss: 0.322880]\n",
      "epoch:6 step:6223 [D loss: 0.244714, acc.: 57.03%] [G loss: 0.299211]\n",
      "epoch:6 step:6224 [D loss: 0.241421, acc.: 55.47%] [G loss: 0.287972]\n",
      "epoch:6 step:6225 [D loss: 0.242360, acc.: 56.25%] [G loss: 0.319450]\n",
      "epoch:6 step:6226 [D loss: 0.223919, acc.: 65.62%] [G loss: 0.313901]\n",
      "epoch:6 step:6227 [D loss: 0.236356, acc.: 60.16%] [G loss: 0.309717]\n",
      "epoch:6 step:6228 [D loss: 0.235882, acc.: 62.50%] [G loss: 0.284910]\n",
      "epoch:6 step:6229 [D loss: 0.242032, acc.: 58.59%] [G loss: 0.260929]\n",
      "epoch:6 step:6230 [D loss: 0.246064, acc.: 55.47%] [G loss: 0.278272]\n",
      "epoch:6 step:6231 [D loss: 0.230926, acc.: 60.94%] [G loss: 0.307132]\n",
      "epoch:6 step:6232 [D loss: 0.252338, acc.: 53.91%] [G loss: 0.280791]\n",
      "epoch:6 step:6233 [D loss: 0.237906, acc.: 60.16%] [G loss: 0.325452]\n",
      "epoch:6 step:6234 [D loss: 0.246118, acc.: 55.47%] [G loss: 0.315800]\n",
      "epoch:6 step:6235 [D loss: 0.256294, acc.: 54.69%] [G loss: 0.294609]\n",
      "epoch:6 step:6236 [D loss: 0.250284, acc.: 60.16%] [G loss: 0.322866]\n",
      "epoch:6 step:6237 [D loss: 0.230273, acc.: 56.25%] [G loss: 0.320533]\n",
      "epoch:6 step:6238 [D loss: 0.234910, acc.: 57.81%] [G loss: 0.293963]\n",
      "epoch:6 step:6239 [D loss: 0.249570, acc.: 53.91%] [G loss: 0.297197]\n",
      "epoch:6 step:6240 [D loss: 0.247166, acc.: 53.91%] [G loss: 0.295125]\n",
      "epoch:6 step:6241 [D loss: 0.244808, acc.: 56.25%] [G loss: 0.296076]\n",
      "epoch:6 step:6242 [D loss: 0.268650, acc.: 42.97%] [G loss: 0.283586]\n",
      "epoch:6 step:6243 [D loss: 0.251745, acc.: 60.16%] [G loss: 0.289339]\n",
      "epoch:6 step:6244 [D loss: 0.245273, acc.: 57.81%] [G loss: 0.321737]\n",
      "epoch:6 step:6245 [D loss: 0.239680, acc.: 59.38%] [G loss: 0.302966]\n",
      "epoch:6 step:6246 [D loss: 0.233353, acc.: 57.81%] [G loss: 0.329392]\n",
      "epoch:6 step:6247 [D loss: 0.246899, acc.: 52.34%] [G loss: 0.297511]\n",
      "epoch:6 step:6248 [D loss: 0.257116, acc.: 51.56%] [G loss: 0.292128]\n",
      "epoch:6 step:6249 [D loss: 0.227461, acc.: 62.50%] [G loss: 0.304324]\n",
      "epoch:6 step:6250 [D loss: 0.242473, acc.: 61.72%] [G loss: 0.300386]\n",
      "epoch:6 step:6251 [D loss: 0.234196, acc.: 57.81%] [G loss: 0.302058]\n",
      "epoch:6 step:6252 [D loss: 0.243690, acc.: 57.03%] [G loss: 0.289075]\n",
      "epoch:6 step:6253 [D loss: 0.235147, acc.: 57.03%] [G loss: 0.304134]\n",
      "epoch:6 step:6254 [D loss: 0.247331, acc.: 51.56%] [G loss: 0.291959]\n",
      "epoch:6 step:6255 [D loss: 0.237820, acc.: 54.69%] [G loss: 0.304434]\n",
      "epoch:6 step:6256 [D loss: 0.243987, acc.: 59.38%] [G loss: 0.308004]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:6 step:6257 [D loss: 0.247473, acc.: 56.25%] [G loss: 0.286644]\n",
      "epoch:6 step:6258 [D loss: 0.258570, acc.: 53.12%] [G loss: 0.281277]\n",
      "epoch:6 step:6259 [D loss: 0.238784, acc.: 57.03%] [G loss: 0.334085]\n",
      "epoch:6 step:6260 [D loss: 0.228756, acc.: 62.50%] [G loss: 0.303648]\n",
      "epoch:6 step:6261 [D loss: 0.256428, acc.: 48.44%] [G loss: 0.315699]\n",
      "epoch:6 step:6262 [D loss: 0.243260, acc.: 60.16%] [G loss: 0.290470]\n",
      "epoch:6 step:6263 [D loss: 0.223636, acc.: 61.72%] [G loss: 0.279325]\n",
      "epoch:6 step:6264 [D loss: 0.250929, acc.: 52.34%] [G loss: 0.289647]\n",
      "epoch:6 step:6265 [D loss: 0.246814, acc.: 60.16%] [G loss: 0.307371]\n",
      "epoch:6 step:6266 [D loss: 0.240822, acc.: 57.03%] [G loss: 0.291367]\n",
      "epoch:6 step:6267 [D loss: 0.258177, acc.: 48.44%] [G loss: 0.275670]\n",
      "epoch:6 step:6268 [D loss: 0.244873, acc.: 55.47%] [G loss: 0.321485]\n",
      "epoch:6 step:6269 [D loss: 0.252651, acc.: 55.47%] [G loss: 0.290138]\n",
      "epoch:6 step:6270 [D loss: 0.240235, acc.: 54.69%] [G loss: 0.309877]\n",
      "epoch:6 step:6271 [D loss: 0.252463, acc.: 58.59%] [G loss: 0.297657]\n",
      "epoch:6 step:6272 [D loss: 0.239211, acc.: 60.16%] [G loss: 0.294326]\n",
      "epoch:6 step:6273 [D loss: 0.250342, acc.: 52.34%] [G loss: 0.288361]\n",
      "epoch:6 step:6274 [D loss: 0.238301, acc.: 61.72%] [G loss: 0.317232]\n",
      "epoch:6 step:6275 [D loss: 0.228541, acc.: 64.06%] [G loss: 0.307035]\n",
      "epoch:6 step:6276 [D loss: 0.241849, acc.: 58.59%] [G loss: 0.315323]\n",
      "epoch:6 step:6277 [D loss: 0.240266, acc.: 60.94%] [G loss: 0.280090]\n",
      "epoch:6 step:6278 [D loss: 0.244138, acc.: 57.81%] [G loss: 0.317237]\n",
      "epoch:6 step:6279 [D loss: 0.257791, acc.: 50.00%] [G loss: 0.291501]\n",
      "epoch:6 step:6280 [D loss: 0.241425, acc.: 62.50%] [G loss: 0.315445]\n",
      "epoch:6 step:6281 [D loss: 0.244999, acc.: 54.69%] [G loss: 0.283733]\n",
      "epoch:6 step:6282 [D loss: 0.240658, acc.: 61.72%] [G loss: 0.302537]\n",
      "epoch:6 step:6283 [D loss: 0.248370, acc.: 53.91%] [G loss: 0.284657]\n",
      "epoch:6 step:6284 [D loss: 0.240202, acc.: 60.94%] [G loss: 0.298516]\n",
      "epoch:6 step:6285 [D loss: 0.245406, acc.: 59.38%] [G loss: 0.288755]\n",
      "epoch:6 step:6286 [D loss: 0.232608, acc.: 64.84%] [G loss: 0.316480]\n",
      "epoch:6 step:6287 [D loss: 0.236579, acc.: 54.69%] [G loss: 0.294207]\n",
      "epoch:6 step:6288 [D loss: 0.244885, acc.: 59.38%] [G loss: 0.296590]\n",
      "epoch:6 step:6289 [D loss: 0.253910, acc.: 57.03%] [G loss: 0.307682]\n",
      "epoch:6 step:6290 [D loss: 0.235805, acc.: 59.38%] [G loss: 0.281273]\n",
      "epoch:6 step:6291 [D loss: 0.224057, acc.: 62.50%] [G loss: 0.303357]\n",
      "epoch:6 step:6292 [D loss: 0.238365, acc.: 60.16%] [G loss: 0.265300]\n",
      "epoch:6 step:6293 [D loss: 0.246454, acc.: 57.81%] [G loss: 0.303259]\n",
      "epoch:6 step:6294 [D loss: 0.254611, acc.: 53.12%] [G loss: 0.279580]\n",
      "epoch:6 step:6295 [D loss: 0.246048, acc.: 51.56%] [G loss: 0.286478]\n",
      "epoch:6 step:6296 [D loss: 0.234473, acc.: 60.16%] [G loss: 0.291931]\n",
      "epoch:6 step:6297 [D loss: 0.235284, acc.: 57.81%] [G loss: 0.297135]\n",
      "epoch:6 step:6298 [D loss: 0.236951, acc.: 60.16%] [G loss: 0.307633]\n",
      "epoch:6 step:6299 [D loss: 0.235906, acc.: 54.69%] [G loss: 0.310858]\n",
      "epoch:6 step:6300 [D loss: 0.251065, acc.: 56.25%] [G loss: 0.317039]\n",
      "epoch:6 step:6301 [D loss: 0.244354, acc.: 58.59%] [G loss: 0.282590]\n",
      "epoch:6 step:6302 [D loss: 0.239334, acc.: 57.81%] [G loss: 0.308176]\n",
      "epoch:6 step:6303 [D loss: 0.250445, acc.: 53.12%] [G loss: 0.288863]\n",
      "epoch:6 step:6304 [D loss: 0.237794, acc.: 61.72%] [G loss: 0.290764]\n",
      "epoch:6 step:6305 [D loss: 0.229991, acc.: 60.94%] [G loss: 0.323410]\n",
      "epoch:6 step:6306 [D loss: 0.255214, acc.: 53.12%] [G loss: 0.290210]\n",
      "epoch:6 step:6307 [D loss: 0.232436, acc.: 61.72%] [G loss: 0.303111]\n",
      "epoch:6 step:6308 [D loss: 0.255973, acc.: 51.56%] [G loss: 0.301179]\n",
      "epoch:6 step:6309 [D loss: 0.236634, acc.: 55.47%] [G loss: 0.309161]\n",
      "epoch:6 step:6310 [D loss: 0.233598, acc.: 56.25%] [G loss: 0.300790]\n",
      "epoch:6 step:6311 [D loss: 0.253947, acc.: 50.00%] [G loss: 0.311156]\n",
      "epoch:6 step:6312 [D loss: 0.255084, acc.: 48.44%] [G loss: 0.297816]\n",
      "epoch:6 step:6313 [D loss: 0.247887, acc.: 55.47%] [G loss: 0.297851]\n",
      "epoch:6 step:6314 [D loss: 0.240007, acc.: 64.06%] [G loss: 0.270756]\n",
      "epoch:6 step:6315 [D loss: 0.240804, acc.: 57.81%] [G loss: 0.295085]\n",
      "epoch:6 step:6316 [D loss: 0.278681, acc.: 47.66%] [G loss: 0.283639]\n",
      "epoch:6 step:6317 [D loss: 0.240157, acc.: 60.94%] [G loss: 0.285908]\n",
      "epoch:6 step:6318 [D loss: 0.234637, acc.: 64.84%] [G loss: 0.282517]\n",
      "epoch:6 step:6319 [D loss: 0.233435, acc.: 60.94%] [G loss: 0.291111]\n",
      "epoch:6 step:6320 [D loss: 0.235501, acc.: 58.59%] [G loss: 0.289428]\n",
      "epoch:6 step:6321 [D loss: 0.256596, acc.: 48.44%] [G loss: 0.329019]\n",
      "epoch:6 step:6322 [D loss: 0.243123, acc.: 53.91%] [G loss: 0.307233]\n",
      "epoch:6 step:6323 [D loss: 0.238090, acc.: 63.28%] [G loss: 0.306604]\n",
      "epoch:6 step:6324 [D loss: 0.240366, acc.: 54.69%] [G loss: 0.304884]\n",
      "epoch:6 step:6325 [D loss: 0.226942, acc.: 65.62%] [G loss: 0.301940]\n",
      "epoch:6 step:6326 [D loss: 0.237844, acc.: 58.59%] [G loss: 0.288572]\n",
      "epoch:6 step:6327 [D loss: 0.257427, acc.: 50.00%] [G loss: 0.253796]\n",
      "epoch:6 step:6328 [D loss: 0.227896, acc.: 63.28%] [G loss: 0.307477]\n",
      "epoch:6 step:6329 [D loss: 0.240510, acc.: 63.28%] [G loss: 0.287480]\n",
      "epoch:6 step:6330 [D loss: 0.250831, acc.: 60.16%] [G loss: 0.280308]\n",
      "epoch:6 step:6331 [D loss: 0.242584, acc.: 56.25%] [G loss: 0.301565]\n",
      "epoch:6 step:6332 [D loss: 0.251075, acc.: 59.38%] [G loss: 0.310826]\n",
      "epoch:6 step:6333 [D loss: 0.239175, acc.: 59.38%] [G loss: 0.292167]\n",
      "epoch:6 step:6334 [D loss: 0.238322, acc.: 58.59%] [G loss: 0.307059]\n",
      "epoch:6 step:6335 [D loss: 0.228120, acc.: 64.06%] [G loss: 0.312967]\n",
      "epoch:6 step:6336 [D loss: 0.244172, acc.: 59.38%] [G loss: 0.314228]\n",
      "epoch:6 step:6337 [D loss: 0.246019, acc.: 56.25%] [G loss: 0.305666]\n",
      "epoch:6 step:6338 [D loss: 0.248879, acc.: 55.47%] [G loss: 0.278387]\n",
      "epoch:6 step:6339 [D loss: 0.239697, acc.: 65.62%] [G loss: 0.287727]\n",
      "epoch:6 step:6340 [D loss: 0.246138, acc.: 55.47%] [G loss: 0.288950]\n",
      "epoch:6 step:6341 [D loss: 0.259465, acc.: 51.56%] [G loss: 0.303990]\n",
      "epoch:6 step:6342 [D loss: 0.233561, acc.: 60.16%] [G loss: 0.328180]\n",
      "epoch:6 step:6343 [D loss: 0.241004, acc.: 57.03%] [G loss: 0.282589]\n",
      "epoch:6 step:6344 [D loss: 0.226690, acc.: 66.41%] [G loss: 0.317964]\n",
      "epoch:6 step:6345 [D loss: 0.249446, acc.: 56.25%] [G loss: 0.307502]\n",
      "epoch:6 step:6346 [D loss: 0.244532, acc.: 58.59%] [G loss: 0.302977]\n",
      "epoch:6 step:6347 [D loss: 0.239295, acc.: 58.59%] [G loss: 0.296740]\n",
      "epoch:6 step:6348 [D loss: 0.251937, acc.: 51.56%] [G loss: 0.301921]\n",
      "epoch:6 step:6349 [D loss: 0.240293, acc.: 59.38%] [G loss: 0.294033]\n",
      "epoch:6 step:6350 [D loss: 0.239624, acc.: 57.03%] [G loss: 0.310878]\n",
      "epoch:6 step:6351 [D loss: 0.256231, acc.: 46.09%] [G loss: 0.309347]\n",
      "epoch:6 step:6352 [D loss: 0.264600, acc.: 49.22%] [G loss: 0.312726]\n",
      "epoch:6 step:6353 [D loss: 0.249129, acc.: 58.59%] [G loss: 0.312759]\n",
      "epoch:6 step:6354 [D loss: 0.246122, acc.: 54.69%] [G loss: 0.304238]\n",
      "epoch:6 step:6355 [D loss: 0.236687, acc.: 62.50%] [G loss: 0.322438]\n",
      "epoch:6 step:6356 [D loss: 0.250253, acc.: 53.91%] [G loss: 0.304601]\n",
      "epoch:6 step:6357 [D loss: 0.257335, acc.: 52.34%] [G loss: 0.307755]\n",
      "epoch:6 step:6358 [D loss: 0.261760, acc.: 48.44%] [G loss: 0.326590]\n",
      "epoch:6 step:6359 [D loss: 0.222136, acc.: 66.41%] [G loss: 0.311777]\n",
      "epoch:6 step:6360 [D loss: 0.244864, acc.: 57.03%] [G loss: 0.302850]\n",
      "epoch:6 step:6361 [D loss: 0.240163, acc.: 60.94%] [G loss: 0.290008]\n",
      "epoch:6 step:6362 [D loss: 0.244143, acc.: 58.59%] [G loss: 0.278338]\n",
      "epoch:6 step:6363 [D loss: 0.250218, acc.: 55.47%] [G loss: 0.304669]\n",
      "epoch:6 step:6364 [D loss: 0.250687, acc.: 54.69%] [G loss: 0.305560]\n",
      "epoch:6 step:6365 [D loss: 0.249442, acc.: 55.47%] [G loss: 0.308229]\n",
      "epoch:6 step:6366 [D loss: 0.250962, acc.: 57.03%] [G loss: 0.295112]\n",
      "epoch:6 step:6367 [D loss: 0.249070, acc.: 53.12%] [G loss: 0.299001]\n",
      "epoch:6 step:6368 [D loss: 0.229922, acc.: 62.50%] [G loss: 0.318076]\n",
      "epoch:6 step:6369 [D loss: 0.249628, acc.: 52.34%] [G loss: 0.301073]\n",
      "epoch:6 step:6370 [D loss: 0.243006, acc.: 56.25%] [G loss: 0.317593]\n",
      "epoch:6 step:6371 [D loss: 0.233388, acc.: 60.94%] [G loss: 0.305782]\n",
      "epoch:6 step:6372 [D loss: 0.243897, acc.: 57.03%] [G loss: 0.299842]\n",
      "epoch:6 step:6373 [D loss: 0.233499, acc.: 57.03%] [G loss: 0.302137]\n",
      "epoch:6 step:6374 [D loss: 0.250800, acc.: 51.56%] [G loss: 0.299515]\n",
      "epoch:6 step:6375 [D loss: 0.237470, acc.: 57.81%] [G loss: 0.309036]\n",
      "epoch:6 step:6376 [D loss: 0.249817, acc.: 52.34%] [G loss: 0.297559]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:6 step:6377 [D loss: 0.221602, acc.: 68.75%] [G loss: 0.295696]\n",
      "epoch:6 step:6378 [D loss: 0.242825, acc.: 50.78%] [G loss: 0.310930]\n",
      "epoch:6 step:6379 [D loss: 0.247041, acc.: 53.91%] [G loss: 0.287735]\n",
      "epoch:6 step:6380 [D loss: 0.253056, acc.: 52.34%] [G loss: 0.297113]\n",
      "epoch:6 step:6381 [D loss: 0.236548, acc.: 53.91%] [G loss: 0.308276]\n",
      "epoch:6 step:6382 [D loss: 0.227691, acc.: 61.72%] [G loss: 0.289751]\n",
      "epoch:6 step:6383 [D loss: 0.240088, acc.: 57.81%] [G loss: 0.268076]\n",
      "epoch:6 step:6384 [D loss: 0.258693, acc.: 47.66%] [G loss: 0.301736]\n",
      "epoch:6 step:6385 [D loss: 0.225684, acc.: 70.31%] [G loss: 0.320275]\n",
      "epoch:6 step:6386 [D loss: 0.242425, acc.: 57.81%] [G loss: 0.298036]\n",
      "epoch:6 step:6387 [D loss: 0.240216, acc.: 61.72%] [G loss: 0.294653]\n",
      "epoch:6 step:6388 [D loss: 0.246538, acc.: 57.03%] [G loss: 0.311493]\n",
      "epoch:6 step:6389 [D loss: 0.239132, acc.: 59.38%] [G loss: 0.300087]\n",
      "epoch:6 step:6390 [D loss: 0.238240, acc.: 59.38%] [G loss: 0.293442]\n",
      "epoch:6 step:6391 [D loss: 0.233248, acc.: 57.03%] [G loss: 0.292408]\n",
      "epoch:6 step:6392 [D loss: 0.245771, acc.: 57.81%] [G loss: 0.298670]\n",
      "epoch:6 step:6393 [D loss: 0.235603, acc.: 60.94%] [G loss: 0.301324]\n",
      "epoch:6 step:6394 [D loss: 0.238481, acc.: 53.91%] [G loss: 0.288934]\n",
      "epoch:6 step:6395 [D loss: 0.254640, acc.: 56.25%] [G loss: 0.268869]\n",
      "epoch:6 step:6396 [D loss: 0.241856, acc.: 62.50%] [G loss: 0.307463]\n",
      "epoch:6 step:6397 [D loss: 0.242455, acc.: 56.25%] [G loss: 0.323187]\n",
      "epoch:6 step:6398 [D loss: 0.253197, acc.: 53.91%] [G loss: 0.288851]\n",
      "epoch:6 step:6399 [D loss: 0.247287, acc.: 51.56%] [G loss: 0.301221]\n",
      "epoch:6 step:6400 [D loss: 0.231342, acc.: 60.94%] [G loss: 0.324597]\n",
      "epoch:6 step:6401 [D loss: 0.221750, acc.: 64.84%] [G loss: 0.323687]\n",
      "epoch:6 step:6402 [D loss: 0.259086, acc.: 53.12%] [G loss: 0.304134]\n",
      "epoch:6 step:6403 [D loss: 0.246894, acc.: 61.72%] [G loss: 0.341359]\n",
      "epoch:6 step:6404 [D loss: 0.237762, acc.: 57.81%] [G loss: 0.309936]\n",
      "epoch:6 step:6405 [D loss: 0.250721, acc.: 55.47%] [G loss: 0.283191]\n",
      "epoch:6 step:6406 [D loss: 0.238574, acc.: 57.81%] [G loss: 0.296821]\n",
      "epoch:6 step:6407 [D loss: 0.247887, acc.: 52.34%] [G loss: 0.292971]\n",
      "epoch:6 step:6408 [D loss: 0.252724, acc.: 53.12%] [G loss: 0.281914]\n",
      "epoch:6 step:6409 [D loss: 0.232111, acc.: 61.72%] [G loss: 0.307963]\n",
      "epoch:6 step:6410 [D loss: 0.238861, acc.: 60.94%] [G loss: 0.301402]\n",
      "epoch:6 step:6411 [D loss: 0.243081, acc.: 52.34%] [G loss: 0.297623]\n",
      "epoch:6 step:6412 [D loss: 0.242655, acc.: 57.03%] [G loss: 0.296990]\n",
      "epoch:6 step:6413 [D loss: 0.253089, acc.: 48.44%] [G loss: 0.311031]\n",
      "epoch:6 step:6414 [D loss: 0.231680, acc.: 61.72%] [G loss: 0.301843]\n",
      "epoch:6 step:6415 [D loss: 0.243479, acc.: 56.25%] [G loss: 0.292034]\n",
      "epoch:6 step:6416 [D loss: 0.248520, acc.: 56.25%] [G loss: 0.298076]\n",
      "epoch:6 step:6417 [D loss: 0.234043, acc.: 60.16%] [G loss: 0.301098]\n",
      "epoch:6 step:6418 [D loss: 0.247382, acc.: 59.38%] [G loss: 0.294931]\n",
      "epoch:6 step:6419 [D loss: 0.241189, acc.: 60.94%] [G loss: 0.313498]\n",
      "epoch:6 step:6420 [D loss: 0.237741, acc.: 62.50%] [G loss: 0.308927]\n",
      "epoch:6 step:6421 [D loss: 0.236053, acc.: 59.38%] [G loss: 0.290306]\n",
      "epoch:6 step:6422 [D loss: 0.249642, acc.: 52.34%] [G loss: 0.310663]\n",
      "epoch:6 step:6423 [D loss: 0.231928, acc.: 56.25%] [G loss: 0.299731]\n",
      "epoch:6 step:6424 [D loss: 0.242695, acc.: 57.81%] [G loss: 0.317021]\n",
      "epoch:6 step:6425 [D loss: 0.263461, acc.: 47.66%] [G loss: 0.293793]\n",
      "epoch:6 step:6426 [D loss: 0.232868, acc.: 62.50%] [G loss: 0.290089]\n",
      "epoch:6 step:6427 [D loss: 0.252098, acc.: 53.91%] [G loss: 0.293783]\n",
      "epoch:6 step:6428 [D loss: 0.252496, acc.: 54.69%] [G loss: 0.314005]\n",
      "epoch:6 step:6429 [D loss: 0.239462, acc.: 63.28%] [G loss: 0.294587]\n",
      "epoch:6 step:6430 [D loss: 0.232640, acc.: 65.62%] [G loss: 0.280793]\n",
      "epoch:6 step:6431 [D loss: 0.234898, acc.: 57.81%] [G loss: 0.327515]\n",
      "epoch:6 step:6432 [D loss: 0.219599, acc.: 67.97%] [G loss: 0.322477]\n",
      "epoch:6 step:6433 [D loss: 0.231103, acc.: 62.50%] [G loss: 0.300277]\n",
      "epoch:6 step:6434 [D loss: 0.248854, acc.: 55.47%] [G loss: 0.297225]\n",
      "epoch:6 step:6435 [D loss: 0.259434, acc.: 46.88%] [G loss: 0.297581]\n",
      "epoch:6 step:6436 [D loss: 0.229487, acc.: 65.62%] [G loss: 0.297697]\n",
      "epoch:6 step:6437 [D loss: 0.230528, acc.: 59.38%] [G loss: 0.284134]\n",
      "epoch:6 step:6438 [D loss: 0.228438, acc.: 60.94%] [G loss: 0.316364]\n",
      "epoch:6 step:6439 [D loss: 0.231709, acc.: 60.16%] [G loss: 0.303188]\n",
      "epoch:6 step:6440 [D loss: 0.240751, acc.: 53.91%] [G loss: 0.292603]\n",
      "epoch:6 step:6441 [D loss: 0.241373, acc.: 55.47%] [G loss: 0.305411]\n",
      "epoch:6 step:6442 [D loss: 0.242857, acc.: 49.22%] [G loss: 0.294748]\n",
      "epoch:6 step:6443 [D loss: 0.251766, acc.: 50.78%] [G loss: 0.303395]\n",
      "epoch:6 step:6444 [D loss: 0.253201, acc.: 53.12%] [G loss: 0.294198]\n",
      "epoch:6 step:6445 [D loss: 0.251779, acc.: 56.25%] [G loss: 0.290263]\n",
      "epoch:6 step:6446 [D loss: 0.236477, acc.: 59.38%] [G loss: 0.308544]\n",
      "epoch:6 step:6447 [D loss: 0.236822, acc.: 57.03%] [G loss: 0.319607]\n",
      "epoch:6 step:6448 [D loss: 0.248049, acc.: 53.12%] [G loss: 0.286651]\n",
      "epoch:6 step:6449 [D loss: 0.262436, acc.: 47.66%] [G loss: 0.260566]\n",
      "epoch:6 step:6450 [D loss: 0.236113, acc.: 60.16%] [G loss: 0.280989]\n",
      "epoch:6 step:6451 [D loss: 0.241911, acc.: 54.69%] [G loss: 0.295261]\n",
      "epoch:6 step:6452 [D loss: 0.233055, acc.: 60.16%] [G loss: 0.298523]\n",
      "epoch:6 step:6453 [D loss: 0.264314, acc.: 50.00%] [G loss: 0.283733]\n",
      "epoch:6 step:6454 [D loss: 0.234594, acc.: 53.91%] [G loss: 0.300030]\n",
      "epoch:6 step:6455 [D loss: 0.247420, acc.: 56.25%] [G loss: 0.276659]\n",
      "epoch:6 step:6456 [D loss: 0.257481, acc.: 50.78%] [G loss: 0.292756]\n",
      "epoch:6 step:6457 [D loss: 0.251536, acc.: 55.47%] [G loss: 0.252871]\n",
      "epoch:6 step:6458 [D loss: 0.260643, acc.: 53.12%] [G loss: 0.283580]\n",
      "epoch:6 step:6459 [D loss: 0.239544, acc.: 57.81%] [G loss: 0.308732]\n",
      "epoch:6 step:6460 [D loss: 0.247133, acc.: 56.25%] [G loss: 0.321213]\n",
      "epoch:6 step:6461 [D loss: 0.264334, acc.: 46.09%] [G loss: 0.297875]\n",
      "epoch:6 step:6462 [D loss: 0.254151, acc.: 52.34%] [G loss: 0.268854]\n",
      "epoch:6 step:6463 [D loss: 0.248763, acc.: 58.59%] [G loss: 0.289040]\n",
      "epoch:6 step:6464 [D loss: 0.240477, acc.: 59.38%] [G loss: 0.296705]\n",
      "epoch:6 step:6465 [D loss: 0.242209, acc.: 57.03%] [G loss: 0.289954]\n",
      "epoch:6 step:6466 [D loss: 0.232411, acc.: 57.81%] [G loss: 0.302158]\n",
      "epoch:6 step:6467 [D loss: 0.234934, acc.: 60.16%] [G loss: 0.307259]\n",
      "epoch:6 step:6468 [D loss: 0.224323, acc.: 64.06%] [G loss: 0.303682]\n",
      "epoch:6 step:6469 [D loss: 0.236386, acc.: 62.50%] [G loss: 0.303442]\n",
      "epoch:6 step:6470 [D loss: 0.243614, acc.: 58.59%] [G loss: 0.277538]\n",
      "epoch:6 step:6471 [D loss: 0.252120, acc.: 56.25%] [G loss: 0.296289]\n",
      "epoch:6 step:6472 [D loss: 0.228289, acc.: 60.94%] [G loss: 0.309116]\n",
      "epoch:6 step:6473 [D loss: 0.247114, acc.: 61.72%] [G loss: 0.321820]\n",
      "epoch:6 step:6474 [D loss: 0.230279, acc.: 62.50%] [G loss: 0.276837]\n",
      "epoch:6 step:6475 [D loss: 0.232852, acc.: 57.81%] [G loss: 0.298018]\n",
      "epoch:6 step:6476 [D loss: 0.248657, acc.: 53.91%] [G loss: 0.282854]\n",
      "epoch:6 step:6477 [D loss: 0.242191, acc.: 63.28%] [G loss: 0.289600]\n",
      "epoch:6 step:6478 [D loss: 0.237733, acc.: 57.03%] [G loss: 0.288304]\n",
      "epoch:6 step:6479 [D loss: 0.248988, acc.: 60.94%] [G loss: 0.290417]\n",
      "epoch:6 step:6480 [D loss: 0.267885, acc.: 45.31%] [G loss: 0.284004]\n",
      "epoch:6 step:6481 [D loss: 0.245823, acc.: 56.25%] [G loss: 0.287420]\n",
      "epoch:6 step:6482 [D loss: 0.253018, acc.: 54.69%] [G loss: 0.313957]\n",
      "epoch:6 step:6483 [D loss: 0.230628, acc.: 67.19%] [G loss: 0.286226]\n",
      "epoch:6 step:6484 [D loss: 0.256783, acc.: 49.22%] [G loss: 0.294165]\n",
      "epoch:6 step:6485 [D loss: 0.252020, acc.: 54.69%] [G loss: 0.305075]\n",
      "epoch:6 step:6486 [D loss: 0.239440, acc.: 59.38%] [G loss: 0.286644]\n",
      "epoch:6 step:6487 [D loss: 0.256995, acc.: 50.78%] [G loss: 0.338400]\n",
      "epoch:6 step:6488 [D loss: 0.241187, acc.: 60.94%] [G loss: 0.301549]\n",
      "epoch:6 step:6489 [D loss: 0.249071, acc.: 55.47%] [G loss: 0.294298]\n",
      "epoch:6 step:6490 [D loss: 0.244132, acc.: 57.81%] [G loss: 0.288396]\n",
      "epoch:6 step:6491 [D loss: 0.223153, acc.: 66.41%] [G loss: 0.296673]\n",
      "epoch:6 step:6492 [D loss: 0.236227, acc.: 57.81%] [G loss: 0.291342]\n",
      "epoch:6 step:6493 [D loss: 0.239184, acc.: 58.59%] [G loss: 0.313103]\n",
      "epoch:6 step:6494 [D loss: 0.265056, acc.: 55.47%] [G loss: 0.299597]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:6 step:6495 [D loss: 0.244669, acc.: 58.59%] [G loss: 0.295141]\n",
      "epoch:6 step:6496 [D loss: 0.249836, acc.: 55.47%] [G loss: 0.296477]\n",
      "epoch:6 step:6497 [D loss: 0.237286, acc.: 59.38%] [G loss: 0.301325]\n",
      "epoch:6 step:6498 [D loss: 0.239631, acc.: 61.72%] [G loss: 0.301732]\n",
      "epoch:6 step:6499 [D loss: 0.241068, acc.: 56.25%] [G loss: 0.313183]\n",
      "epoch:6 step:6500 [D loss: 0.255520, acc.: 48.44%] [G loss: 0.281874]\n",
      "epoch:6 step:6501 [D loss: 0.234445, acc.: 60.94%] [G loss: 0.304094]\n",
      "epoch:6 step:6502 [D loss: 0.242672, acc.: 60.94%] [G loss: 0.331724]\n",
      "epoch:6 step:6503 [D loss: 0.256230, acc.: 50.00%] [G loss: 0.291394]\n",
      "epoch:6 step:6504 [D loss: 0.224264, acc.: 64.06%] [G loss: 0.308759]\n",
      "epoch:6 step:6505 [D loss: 0.239477, acc.: 57.03%] [G loss: 0.307270]\n",
      "epoch:6 step:6506 [D loss: 0.237022, acc.: 58.59%] [G loss: 0.308154]\n",
      "epoch:6 step:6507 [D loss: 0.239012, acc.: 59.38%] [G loss: 0.306031]\n",
      "epoch:6 step:6508 [D loss: 0.242363, acc.: 53.12%] [G loss: 0.298846]\n",
      "epoch:6 step:6509 [D loss: 0.239616, acc.: 61.72%] [G loss: 0.299491]\n",
      "epoch:6 step:6510 [D loss: 0.244901, acc.: 55.47%] [G loss: 0.297341]\n",
      "epoch:6 step:6511 [D loss: 0.238765, acc.: 59.38%] [G loss: 0.306492]\n",
      "epoch:6 step:6512 [D loss: 0.249298, acc.: 54.69%] [G loss: 0.297595]\n",
      "epoch:6 step:6513 [D loss: 0.269363, acc.: 46.09%] [G loss: 0.320553]\n",
      "epoch:6 step:6514 [D loss: 0.246107, acc.: 57.03%] [G loss: 0.306736]\n",
      "epoch:6 step:6515 [D loss: 0.235969, acc.: 59.38%] [G loss: 0.299281]\n",
      "epoch:6 step:6516 [D loss: 0.260675, acc.: 46.88%] [G loss: 0.285309]\n",
      "epoch:6 step:6517 [D loss: 0.221459, acc.: 60.94%] [G loss: 0.337347]\n",
      "epoch:6 step:6518 [D loss: 0.243591, acc.: 55.47%] [G loss: 0.309814]\n",
      "epoch:6 step:6519 [D loss: 0.239873, acc.: 53.91%] [G loss: 0.316539]\n",
      "epoch:6 step:6520 [D loss: 0.220269, acc.: 64.06%] [G loss: 0.298343]\n",
      "epoch:6 step:6521 [D loss: 0.260832, acc.: 47.66%] [G loss: 0.288236]\n",
      "epoch:6 step:6522 [D loss: 0.248614, acc.: 52.34%] [G loss: 0.311147]\n",
      "epoch:6 step:6523 [D loss: 0.244484, acc.: 58.59%] [G loss: 0.279136]\n",
      "epoch:6 step:6524 [D loss: 0.244009, acc.: 56.25%] [G loss: 0.304038]\n",
      "epoch:6 step:6525 [D loss: 0.223616, acc.: 65.62%] [G loss: 0.309108]\n",
      "epoch:6 step:6526 [D loss: 0.245684, acc.: 56.25%] [G loss: 0.328155]\n",
      "epoch:6 step:6527 [D loss: 0.229004, acc.: 62.50%] [G loss: 0.340944]\n",
      "epoch:6 step:6528 [D loss: 0.245427, acc.: 53.91%] [G loss: 0.282514]\n",
      "epoch:6 step:6529 [D loss: 0.238192, acc.: 62.50%] [G loss: 0.285357]\n",
      "epoch:6 step:6530 [D loss: 0.247954, acc.: 54.69%] [G loss: 0.285414]\n",
      "epoch:6 step:6531 [D loss: 0.232855, acc.: 58.59%] [G loss: 0.304608]\n",
      "epoch:6 step:6532 [D loss: 0.249868, acc.: 52.34%] [G loss: 0.283148]\n",
      "epoch:6 step:6533 [D loss: 0.240611, acc.: 54.69%] [G loss: 0.316056]\n",
      "epoch:6 step:6534 [D loss: 0.233476, acc.: 58.59%] [G loss: 0.282304]\n",
      "epoch:6 step:6535 [D loss: 0.231865, acc.: 60.94%] [G loss: 0.287350]\n",
      "epoch:6 step:6536 [D loss: 0.251453, acc.: 51.56%] [G loss: 0.306658]\n",
      "epoch:6 step:6537 [D loss: 0.242028, acc.: 57.81%] [G loss: 0.298924]\n",
      "epoch:6 step:6538 [D loss: 0.236888, acc.: 59.38%] [G loss: 0.291983]\n",
      "epoch:6 step:6539 [D loss: 0.233582, acc.: 58.59%] [G loss: 0.293035]\n",
      "epoch:6 step:6540 [D loss: 0.239589, acc.: 57.81%] [G loss: 0.318750]\n",
      "epoch:6 step:6541 [D loss: 0.226373, acc.: 64.84%] [G loss: 0.307613]\n",
      "epoch:6 step:6542 [D loss: 0.236593, acc.: 57.03%] [G loss: 0.293005]\n",
      "epoch:6 step:6543 [D loss: 0.244136, acc.: 55.47%] [G loss: 0.280921]\n",
      "epoch:6 step:6544 [D loss: 0.232345, acc.: 59.38%] [G loss: 0.315753]\n",
      "epoch:6 step:6545 [D loss: 0.238266, acc.: 54.69%] [G loss: 0.302767]\n",
      "epoch:6 step:6546 [D loss: 0.246951, acc.: 56.25%] [G loss: 0.289018]\n",
      "epoch:6 step:6547 [D loss: 0.249018, acc.: 58.59%] [G loss: 0.294806]\n",
      "epoch:6 step:6548 [D loss: 0.241962, acc.: 53.91%] [G loss: 0.287042]\n",
      "epoch:6 step:6549 [D loss: 0.240603, acc.: 55.47%] [G loss: 0.316870]\n",
      "epoch:6 step:6550 [D loss: 0.229455, acc.: 58.59%] [G loss: 0.287421]\n",
      "epoch:6 step:6551 [D loss: 0.247407, acc.: 57.03%] [G loss: 0.283267]\n",
      "epoch:6 step:6552 [D loss: 0.234621, acc.: 57.81%] [G loss: 0.304666]\n",
      "epoch:6 step:6553 [D loss: 0.263713, acc.: 50.00%] [G loss: 0.291812]\n",
      "epoch:6 step:6554 [D loss: 0.235687, acc.: 60.94%] [G loss: 0.319966]\n",
      "epoch:6 step:6555 [D loss: 0.256720, acc.: 47.66%] [G loss: 0.296720]\n",
      "epoch:6 step:6556 [D loss: 0.241645, acc.: 53.91%] [G loss: 0.294020]\n",
      "epoch:6 step:6557 [D loss: 0.223315, acc.: 62.50%] [G loss: 0.289861]\n",
      "epoch:6 step:6558 [D loss: 0.234915, acc.: 59.38%] [G loss: 0.290841]\n",
      "epoch:6 step:6559 [D loss: 0.231994, acc.: 65.62%] [G loss: 0.295995]\n",
      "epoch:7 step:6560 [D loss: 0.243298, acc.: 57.03%] [G loss: 0.290823]\n",
      "epoch:7 step:6561 [D loss: 0.261992, acc.: 53.12%] [G loss: 0.324410]\n",
      "epoch:7 step:6562 [D loss: 0.242872, acc.: 58.59%] [G loss: 0.299699]\n",
      "epoch:7 step:6563 [D loss: 0.238521, acc.: 60.94%] [G loss: 0.309004]\n",
      "epoch:7 step:6564 [D loss: 0.241733, acc.: 60.94%] [G loss: 0.290561]\n",
      "epoch:7 step:6565 [D loss: 0.245629, acc.: 55.47%] [G loss: 0.275860]\n",
      "epoch:7 step:6566 [D loss: 0.254529, acc.: 53.12%] [G loss: 0.298786]\n",
      "epoch:7 step:6567 [D loss: 0.230815, acc.: 57.81%] [G loss: 0.325350]\n",
      "epoch:7 step:6568 [D loss: 0.237103, acc.: 58.59%] [G loss: 0.280167]\n",
      "epoch:7 step:6569 [D loss: 0.238259, acc.: 57.81%] [G loss: 0.312686]\n",
      "epoch:7 step:6570 [D loss: 0.250821, acc.: 52.34%] [G loss: 0.269120]\n",
      "epoch:7 step:6571 [D loss: 0.242931, acc.: 60.16%] [G loss: 0.291867]\n",
      "epoch:7 step:6572 [D loss: 0.230103, acc.: 63.28%] [G loss: 0.292875]\n",
      "epoch:7 step:6573 [D loss: 0.254529, acc.: 49.22%] [G loss: 0.303420]\n",
      "epoch:7 step:6574 [D loss: 0.224640, acc.: 64.06%] [G loss: 0.296885]\n",
      "epoch:7 step:6575 [D loss: 0.242034, acc.: 56.25%] [G loss: 0.319530]\n",
      "epoch:7 step:6576 [D loss: 0.224558, acc.: 64.06%] [G loss: 0.302129]\n",
      "epoch:7 step:6577 [D loss: 0.257742, acc.: 44.53%] [G loss: 0.270321]\n",
      "epoch:7 step:6578 [D loss: 0.237634, acc.: 58.59%] [G loss: 0.304890]\n",
      "epoch:7 step:6579 [D loss: 0.224615, acc.: 65.62%] [G loss: 0.318697]\n",
      "epoch:7 step:6580 [D loss: 0.243053, acc.: 57.81%] [G loss: 0.284946]\n",
      "epoch:7 step:6581 [D loss: 0.248168, acc.: 57.03%] [G loss: 0.294822]\n",
      "epoch:7 step:6582 [D loss: 0.246215, acc.: 57.81%] [G loss: 0.279008]\n",
      "epoch:7 step:6583 [D loss: 0.217553, acc.: 68.75%] [G loss: 0.340513]\n",
      "epoch:7 step:6584 [D loss: 0.240074, acc.: 57.81%] [G loss: 0.277148]\n",
      "epoch:7 step:6585 [D loss: 0.228107, acc.: 64.06%] [G loss: 0.290679]\n",
      "epoch:7 step:6586 [D loss: 0.237443, acc.: 57.03%] [G loss: 0.285621]\n",
      "epoch:7 step:6587 [D loss: 0.251201, acc.: 56.25%] [G loss: 0.282451]\n",
      "epoch:7 step:6588 [D loss: 0.239133, acc.: 59.38%] [G loss: 0.277344]\n",
      "epoch:7 step:6589 [D loss: 0.244460, acc.: 55.47%] [G loss: 0.318876]\n",
      "epoch:7 step:6590 [D loss: 0.258117, acc.: 46.09%] [G loss: 0.267517]\n",
      "epoch:7 step:6591 [D loss: 0.237260, acc.: 57.03%] [G loss: 0.278200]\n",
      "epoch:7 step:6592 [D loss: 0.238776, acc.: 60.16%] [G loss: 0.284488]\n",
      "epoch:7 step:6593 [D loss: 0.240312, acc.: 54.69%] [G loss: 0.263959]\n",
      "epoch:7 step:6594 [D loss: 0.243438, acc.: 57.03%] [G loss: 0.301931]\n",
      "epoch:7 step:6595 [D loss: 0.243013, acc.: 58.59%] [G loss: 0.286008]\n",
      "epoch:7 step:6596 [D loss: 0.232704, acc.: 59.38%] [G loss: 0.294442]\n",
      "epoch:7 step:6597 [D loss: 0.236446, acc.: 57.03%] [G loss: 0.278354]\n",
      "epoch:7 step:6598 [D loss: 0.243292, acc.: 58.59%] [G loss: 0.295229]\n",
      "epoch:7 step:6599 [D loss: 0.259581, acc.: 52.34%] [G loss: 0.315475]\n",
      "epoch:7 step:6600 [D loss: 0.230416, acc.: 61.72%] [G loss: 0.292841]\n",
      "epoch:7 step:6601 [D loss: 0.235853, acc.: 57.81%] [G loss: 0.305021]\n",
      "epoch:7 step:6602 [D loss: 0.230468, acc.: 64.06%] [G loss: 0.282644]\n",
      "epoch:7 step:6603 [D loss: 0.243834, acc.: 57.03%] [G loss: 0.304379]\n",
      "epoch:7 step:6604 [D loss: 0.252206, acc.: 53.12%] [G loss: 0.300271]\n",
      "epoch:7 step:6605 [D loss: 0.259437, acc.: 53.12%] [G loss: 0.300236]\n",
      "epoch:7 step:6606 [D loss: 0.249697, acc.: 53.91%] [G loss: 0.317291]\n",
      "epoch:7 step:6607 [D loss: 0.243871, acc.: 57.03%] [G loss: 0.300007]\n",
      "epoch:7 step:6608 [D loss: 0.255084, acc.: 51.56%] [G loss: 0.311367]\n",
      "epoch:7 step:6609 [D loss: 0.253533, acc.: 52.34%] [G loss: 0.313611]\n",
      "epoch:7 step:6610 [D loss: 0.230497, acc.: 63.28%] [G loss: 0.306497]\n",
      "epoch:7 step:6611 [D loss: 0.238924, acc.: 54.69%] [G loss: 0.335180]\n",
      "epoch:7 step:6612 [D loss: 0.248117, acc.: 55.47%] [G loss: 0.319360]\n",
      "epoch:7 step:6613 [D loss: 0.255486, acc.: 57.03%] [G loss: 0.302042]\n",
      "epoch:7 step:6614 [D loss: 0.256482, acc.: 50.78%] [G loss: 0.316236]\n",
      "epoch:7 step:6615 [D loss: 0.249152, acc.: 51.56%] [G loss: 0.322960]\n",
      "epoch:7 step:6616 [D loss: 0.251653, acc.: 51.56%] [G loss: 0.282950]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:7 step:6617 [D loss: 0.236494, acc.: 60.16%] [G loss: 0.301884]\n",
      "epoch:7 step:6618 [D loss: 0.226762, acc.: 61.72%] [G loss: 0.316635]\n",
      "epoch:7 step:6619 [D loss: 0.208353, acc.: 75.78%] [G loss: 0.323598]\n",
      "epoch:7 step:6620 [D loss: 0.243919, acc.: 59.38%] [G loss: 0.331293]\n",
      "epoch:7 step:6621 [D loss: 0.243042, acc.: 57.81%] [G loss: 0.293886]\n",
      "epoch:7 step:6622 [D loss: 0.236724, acc.: 55.47%] [G loss: 0.310570]\n",
      "epoch:7 step:6623 [D loss: 0.230687, acc.: 66.41%] [G loss: 0.303181]\n",
      "epoch:7 step:6624 [D loss: 0.248947, acc.: 53.12%] [G loss: 0.302056]\n",
      "epoch:7 step:6625 [D loss: 0.250703, acc.: 55.47%] [G loss: 0.305233]\n",
      "epoch:7 step:6626 [D loss: 0.249543, acc.: 50.00%] [G loss: 0.303023]\n",
      "epoch:7 step:6627 [D loss: 0.239206, acc.: 58.59%] [G loss: 0.312105]\n",
      "epoch:7 step:6628 [D loss: 0.240770, acc.: 59.38%] [G loss: 0.297010]\n",
      "epoch:7 step:6629 [D loss: 0.262218, acc.: 50.78%] [G loss: 0.288131]\n",
      "epoch:7 step:6630 [D loss: 0.236413, acc.: 52.34%] [G loss: 0.314461]\n",
      "epoch:7 step:6631 [D loss: 0.247038, acc.: 56.25%] [G loss: 0.283527]\n",
      "epoch:7 step:6632 [D loss: 0.234244, acc.: 59.38%] [G loss: 0.280960]\n",
      "epoch:7 step:6633 [D loss: 0.251257, acc.: 50.78%] [G loss: 0.297987]\n",
      "epoch:7 step:6634 [D loss: 0.244362, acc.: 58.59%] [G loss: 0.306970]\n",
      "epoch:7 step:6635 [D loss: 0.233791, acc.: 62.50%] [G loss: 0.285143]\n",
      "epoch:7 step:6636 [D loss: 0.258104, acc.: 49.22%] [G loss: 0.263584]\n",
      "epoch:7 step:6637 [D loss: 0.244462, acc.: 58.59%] [G loss: 0.299751]\n",
      "epoch:7 step:6638 [D loss: 0.248290, acc.: 53.91%] [G loss: 0.309204]\n",
      "epoch:7 step:6639 [D loss: 0.238915, acc.: 59.38%] [G loss: 0.301752]\n",
      "epoch:7 step:6640 [D loss: 0.242836, acc.: 56.25%] [G loss: 0.287384]\n",
      "epoch:7 step:6641 [D loss: 0.239177, acc.: 59.38%] [G loss: 0.320945]\n",
      "epoch:7 step:6642 [D loss: 0.234212, acc.: 60.94%] [G loss: 0.290603]\n",
      "epoch:7 step:6643 [D loss: 0.247400, acc.: 54.69%] [G loss: 0.290613]\n",
      "epoch:7 step:6644 [D loss: 0.259341, acc.: 49.22%] [G loss: 0.272237]\n",
      "epoch:7 step:6645 [D loss: 0.245902, acc.: 58.59%] [G loss: 0.281238]\n",
      "epoch:7 step:6646 [D loss: 0.249615, acc.: 53.12%] [G loss: 0.280192]\n",
      "epoch:7 step:6647 [D loss: 0.248403, acc.: 54.69%] [G loss: 0.295427]\n",
      "epoch:7 step:6648 [D loss: 0.232017, acc.: 65.62%] [G loss: 0.297914]\n",
      "epoch:7 step:6649 [D loss: 0.243658, acc.: 57.81%] [G loss: 0.312037]\n",
      "epoch:7 step:6650 [D loss: 0.246740, acc.: 57.81%] [G loss: 0.307721]\n",
      "epoch:7 step:6651 [D loss: 0.240590, acc.: 54.69%] [G loss: 0.323137]\n",
      "epoch:7 step:6652 [D loss: 0.234838, acc.: 61.72%] [G loss: 0.290586]\n",
      "epoch:7 step:6653 [D loss: 0.232377, acc.: 60.94%] [G loss: 0.312375]\n",
      "epoch:7 step:6654 [D loss: 0.247347, acc.: 56.25%] [G loss: 0.266154]\n",
      "epoch:7 step:6655 [D loss: 0.256247, acc.: 58.59%] [G loss: 0.301798]\n",
      "epoch:7 step:6656 [D loss: 0.251062, acc.: 54.69%] [G loss: 0.312294]\n",
      "epoch:7 step:6657 [D loss: 0.240856, acc.: 54.69%] [G loss: 0.311246]\n",
      "epoch:7 step:6658 [D loss: 0.248604, acc.: 53.12%] [G loss: 0.299483]\n",
      "epoch:7 step:6659 [D loss: 0.257218, acc.: 45.31%] [G loss: 0.323600]\n",
      "epoch:7 step:6660 [D loss: 0.262710, acc.: 46.88%] [G loss: 0.288482]\n",
      "epoch:7 step:6661 [D loss: 0.237236, acc.: 59.38%] [G loss: 0.316397]\n",
      "epoch:7 step:6662 [D loss: 0.254569, acc.: 48.44%] [G loss: 0.309300]\n",
      "epoch:7 step:6663 [D loss: 0.250020, acc.: 49.22%] [G loss: 0.296573]\n",
      "epoch:7 step:6664 [D loss: 0.240572, acc.: 59.38%] [G loss: 0.323904]\n",
      "epoch:7 step:6665 [D loss: 0.255448, acc.: 50.78%] [G loss: 0.282290]\n",
      "epoch:7 step:6666 [D loss: 0.237696, acc.: 60.94%] [G loss: 0.308166]\n",
      "epoch:7 step:6667 [D loss: 0.233894, acc.: 63.28%] [G loss: 0.295154]\n",
      "epoch:7 step:6668 [D loss: 0.239298, acc.: 55.47%] [G loss: 0.301201]\n",
      "epoch:7 step:6669 [D loss: 0.248360, acc.: 56.25%] [G loss: 0.307625]\n",
      "epoch:7 step:6670 [D loss: 0.245864, acc.: 53.91%] [G loss: 0.298125]\n",
      "epoch:7 step:6671 [D loss: 0.238474, acc.: 59.38%] [G loss: 0.298856]\n",
      "epoch:7 step:6672 [D loss: 0.260373, acc.: 45.31%] [G loss: 0.312059]\n",
      "epoch:7 step:6673 [D loss: 0.244604, acc.: 56.25%] [G loss: 0.297742]\n",
      "epoch:7 step:6674 [D loss: 0.240445, acc.: 56.25%] [G loss: 0.303378]\n",
      "epoch:7 step:6675 [D loss: 0.257576, acc.: 53.91%] [G loss: 0.281329]\n",
      "epoch:7 step:6676 [D loss: 0.248283, acc.: 60.94%] [G loss: 0.312494]\n",
      "epoch:7 step:6677 [D loss: 0.237699, acc.: 54.69%] [G loss: 0.293143]\n",
      "epoch:7 step:6678 [D loss: 0.237230, acc.: 60.16%] [G loss: 0.302659]\n",
      "epoch:7 step:6679 [D loss: 0.255507, acc.: 49.22%] [G loss: 0.273221]\n",
      "epoch:7 step:6680 [D loss: 0.249235, acc.: 53.91%] [G loss: 0.276530]\n",
      "epoch:7 step:6681 [D loss: 0.269640, acc.: 47.66%] [G loss: 0.309950]\n",
      "epoch:7 step:6682 [D loss: 0.247668, acc.: 53.12%] [G loss: 0.301759]\n",
      "epoch:7 step:6683 [D loss: 0.240216, acc.: 61.72%] [G loss: 0.293398]\n",
      "epoch:7 step:6684 [D loss: 0.234444, acc.: 60.94%] [G loss: 0.311768]\n",
      "epoch:7 step:6685 [D loss: 0.255023, acc.: 52.34%] [G loss: 0.306221]\n",
      "epoch:7 step:6686 [D loss: 0.243733, acc.: 55.47%] [G loss: 0.287833]\n",
      "epoch:7 step:6687 [D loss: 0.235124, acc.: 57.81%] [G loss: 0.321408]\n",
      "epoch:7 step:6688 [D loss: 0.250521, acc.: 51.56%] [G loss: 0.282095]\n",
      "epoch:7 step:6689 [D loss: 0.237876, acc.: 60.94%] [G loss: 0.281585]\n",
      "epoch:7 step:6690 [D loss: 0.250962, acc.: 55.47%] [G loss: 0.287589]\n",
      "epoch:7 step:6691 [D loss: 0.242245, acc.: 57.81%] [G loss: 0.303219]\n",
      "epoch:7 step:6692 [D loss: 0.243005, acc.: 53.91%] [G loss: 0.296855]\n",
      "epoch:7 step:6693 [D loss: 0.253743, acc.: 51.56%] [G loss: 0.303750]\n",
      "epoch:7 step:6694 [D loss: 0.251905, acc.: 57.03%] [G loss: 0.317539]\n",
      "epoch:7 step:6695 [D loss: 0.263963, acc.: 50.00%] [G loss: 0.309343]\n",
      "epoch:7 step:6696 [D loss: 0.247723, acc.: 51.56%] [G loss: 0.303604]\n",
      "epoch:7 step:6697 [D loss: 0.246792, acc.: 57.03%] [G loss: 0.285783]\n",
      "epoch:7 step:6698 [D loss: 0.234942, acc.: 60.94%] [G loss: 0.290635]\n",
      "epoch:7 step:6699 [D loss: 0.246637, acc.: 54.69%] [G loss: 0.284250]\n",
      "epoch:7 step:6700 [D loss: 0.249482, acc.: 53.91%] [G loss: 0.317580]\n",
      "epoch:7 step:6701 [D loss: 0.243090, acc.: 57.81%] [G loss: 0.294459]\n",
      "epoch:7 step:6702 [D loss: 0.241770, acc.: 53.91%] [G loss: 0.319899]\n",
      "epoch:7 step:6703 [D loss: 0.260787, acc.: 49.22%] [G loss: 0.267189]\n",
      "epoch:7 step:6704 [D loss: 0.242476, acc.: 56.25%] [G loss: 0.305334]\n",
      "epoch:7 step:6705 [D loss: 0.236288, acc.: 54.69%] [G loss: 0.331268]\n",
      "epoch:7 step:6706 [D loss: 0.238919, acc.: 58.59%] [G loss: 0.314461]\n",
      "epoch:7 step:6707 [D loss: 0.243223, acc.: 52.34%] [G loss: 0.304679]\n",
      "epoch:7 step:6708 [D loss: 0.241141, acc.: 60.94%] [G loss: 0.307469]\n",
      "epoch:7 step:6709 [D loss: 0.231030, acc.: 59.38%] [G loss: 0.316245]\n",
      "epoch:7 step:6710 [D loss: 0.259758, acc.: 57.03%] [G loss: 0.334671]\n",
      "epoch:7 step:6711 [D loss: 0.239917, acc.: 56.25%] [G loss: 0.285908]\n",
      "epoch:7 step:6712 [D loss: 0.244299, acc.: 53.12%] [G loss: 0.291605]\n",
      "epoch:7 step:6713 [D loss: 0.256668, acc.: 49.22%] [G loss: 0.292129]\n",
      "epoch:7 step:6714 [D loss: 0.262509, acc.: 51.56%] [G loss: 0.286345]\n",
      "epoch:7 step:6715 [D loss: 0.237426, acc.: 57.81%] [G loss: 0.276547]\n",
      "epoch:7 step:6716 [D loss: 0.251718, acc.: 56.25%] [G loss: 0.292006]\n",
      "epoch:7 step:6717 [D loss: 0.234222, acc.: 60.94%] [G loss: 0.277427]\n",
      "epoch:7 step:6718 [D loss: 0.226537, acc.: 63.28%] [G loss: 0.292823]\n",
      "epoch:7 step:6719 [D loss: 0.249085, acc.: 53.12%] [G loss: 0.286413]\n",
      "epoch:7 step:6720 [D loss: 0.234104, acc.: 52.34%] [G loss: 0.270728]\n",
      "epoch:7 step:6721 [D loss: 0.253661, acc.: 52.34%] [G loss: 0.294235]\n",
      "epoch:7 step:6722 [D loss: 0.245815, acc.: 59.38%] [G loss: 0.286149]\n",
      "epoch:7 step:6723 [D loss: 0.240030, acc.: 59.38%] [G loss: 0.330994]\n",
      "epoch:7 step:6724 [D loss: 0.262288, acc.: 44.53%] [G loss: 0.321203]\n",
      "epoch:7 step:6725 [D loss: 0.238100, acc.: 61.72%] [G loss: 0.292542]\n",
      "epoch:7 step:6726 [D loss: 0.238124, acc.: 57.81%] [G loss: 0.282188]\n",
      "epoch:7 step:6727 [D loss: 0.247411, acc.: 53.91%] [G loss: 0.295632]\n",
      "epoch:7 step:6728 [D loss: 0.255521, acc.: 48.44%] [G loss: 0.279571]\n",
      "epoch:7 step:6729 [D loss: 0.256128, acc.: 50.78%] [G loss: 0.275156]\n",
      "epoch:7 step:6730 [D loss: 0.239995, acc.: 58.59%] [G loss: 0.286316]\n",
      "epoch:7 step:6731 [D loss: 0.218072, acc.: 65.62%] [G loss: 0.301591]\n",
      "epoch:7 step:6732 [D loss: 0.258159, acc.: 50.00%] [G loss: 0.307569]\n",
      "epoch:7 step:6733 [D loss: 0.242848, acc.: 60.16%] [G loss: 0.299979]\n",
      "epoch:7 step:6734 [D loss: 0.264166, acc.: 50.78%] [G loss: 0.300527]\n",
      "epoch:7 step:6735 [D loss: 0.238505, acc.: 61.72%] [G loss: 0.290997]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:7 step:6736 [D loss: 0.230675, acc.: 60.94%] [G loss: 0.303302]\n",
      "epoch:7 step:6737 [D loss: 0.239802, acc.: 57.03%] [G loss: 0.314302]\n",
      "epoch:7 step:6738 [D loss: 0.257812, acc.: 55.47%] [G loss: 0.303132]\n",
      "epoch:7 step:6739 [D loss: 0.253828, acc.: 50.78%] [G loss: 0.299765]\n",
      "epoch:7 step:6740 [D loss: 0.243525, acc.: 58.59%] [G loss: 0.253079]\n",
      "epoch:7 step:6741 [D loss: 0.235934, acc.: 65.62%] [G loss: 0.310204]\n",
      "epoch:7 step:6742 [D loss: 0.262346, acc.: 53.12%] [G loss: 0.287557]\n",
      "epoch:7 step:6743 [D loss: 0.246082, acc.: 58.59%] [G loss: 0.308042]\n",
      "epoch:7 step:6744 [D loss: 0.252815, acc.: 53.12%] [G loss: 0.322702]\n",
      "epoch:7 step:6745 [D loss: 0.244735, acc.: 56.25%] [G loss: 0.261341]\n",
      "epoch:7 step:6746 [D loss: 0.228603, acc.: 66.41%] [G loss: 0.301211]\n",
      "epoch:7 step:6747 [D loss: 0.230825, acc.: 60.94%] [G loss: 0.292688]\n",
      "epoch:7 step:6748 [D loss: 0.243139, acc.: 56.25%] [G loss: 0.279050]\n",
      "epoch:7 step:6749 [D loss: 0.247196, acc.: 57.81%] [G loss: 0.305400]\n",
      "epoch:7 step:6750 [D loss: 0.239013, acc.: 57.03%] [G loss: 0.310330]\n",
      "epoch:7 step:6751 [D loss: 0.242737, acc.: 57.81%] [G loss: 0.301144]\n",
      "epoch:7 step:6752 [D loss: 0.248097, acc.: 54.69%] [G loss: 0.305711]\n",
      "epoch:7 step:6753 [D loss: 0.238132, acc.: 57.03%] [G loss: 0.263717]\n",
      "epoch:7 step:6754 [D loss: 0.247082, acc.: 49.22%] [G loss: 0.285345]\n",
      "epoch:7 step:6755 [D loss: 0.250423, acc.: 54.69%] [G loss: 0.317532]\n",
      "epoch:7 step:6756 [D loss: 0.243585, acc.: 51.56%] [G loss: 0.303743]\n",
      "epoch:7 step:6757 [D loss: 0.244511, acc.: 58.59%] [G loss: 0.290626]\n",
      "epoch:7 step:6758 [D loss: 0.232265, acc.: 61.72%] [G loss: 0.328134]\n",
      "epoch:7 step:6759 [D loss: 0.227065, acc.: 58.59%] [G loss: 0.306146]\n",
      "epoch:7 step:6760 [D loss: 0.245599, acc.: 56.25%] [G loss: 0.305010]\n",
      "epoch:7 step:6761 [D loss: 0.233726, acc.: 60.94%] [G loss: 0.313552]\n",
      "epoch:7 step:6762 [D loss: 0.242730, acc.: 54.69%] [G loss: 0.289992]\n",
      "epoch:7 step:6763 [D loss: 0.244179, acc.: 53.91%] [G loss: 0.299943]\n",
      "epoch:7 step:6764 [D loss: 0.228245, acc.: 67.19%] [G loss: 0.291807]\n",
      "epoch:7 step:6765 [D loss: 0.253241, acc.: 48.44%] [G loss: 0.288446]\n",
      "epoch:7 step:6766 [D loss: 0.248939, acc.: 57.03%] [G loss: 0.285970]\n",
      "epoch:7 step:6767 [D loss: 0.249688, acc.: 53.91%] [G loss: 0.287124]\n",
      "epoch:7 step:6768 [D loss: 0.247496, acc.: 55.47%] [G loss: 0.294230]\n",
      "epoch:7 step:6769 [D loss: 0.239177, acc.: 59.38%] [G loss: 0.292704]\n",
      "epoch:7 step:6770 [D loss: 0.234119, acc.: 58.59%] [G loss: 0.311807]\n",
      "epoch:7 step:6771 [D loss: 0.244209, acc.: 57.03%] [G loss: 0.304809]\n",
      "epoch:7 step:6772 [D loss: 0.246621, acc.: 53.91%] [G loss: 0.278740]\n",
      "epoch:7 step:6773 [D loss: 0.241788, acc.: 57.81%] [G loss: 0.312452]\n",
      "epoch:7 step:6774 [D loss: 0.241919, acc.: 51.56%] [G loss: 0.314378]\n",
      "epoch:7 step:6775 [D loss: 0.232957, acc.: 59.38%] [G loss: 0.305950]\n",
      "epoch:7 step:6776 [D loss: 0.224145, acc.: 64.06%] [G loss: 0.312359]\n",
      "epoch:7 step:6777 [D loss: 0.265757, acc.: 53.12%] [G loss: 0.294714]\n",
      "epoch:7 step:6778 [D loss: 0.250572, acc.: 54.69%] [G loss: 0.319812]\n",
      "epoch:7 step:6779 [D loss: 0.240070, acc.: 60.16%] [G loss: 0.294401]\n",
      "epoch:7 step:6780 [D loss: 0.224734, acc.: 60.94%] [G loss: 0.318514]\n",
      "epoch:7 step:6781 [D loss: 0.255149, acc.: 54.69%] [G loss: 0.304131]\n",
      "epoch:7 step:6782 [D loss: 0.258884, acc.: 53.12%] [G loss: 0.324140]\n",
      "epoch:7 step:6783 [D loss: 0.238994, acc.: 57.03%] [G loss: 0.287322]\n",
      "epoch:7 step:6784 [D loss: 0.240177, acc.: 57.03%] [G loss: 0.314845]\n",
      "epoch:7 step:6785 [D loss: 0.238518, acc.: 64.06%] [G loss: 0.323750]\n",
      "epoch:7 step:6786 [D loss: 0.251572, acc.: 54.69%] [G loss: 0.307084]\n",
      "epoch:7 step:6787 [D loss: 0.236208, acc.: 58.59%] [G loss: 0.292674]\n",
      "epoch:7 step:6788 [D loss: 0.244394, acc.: 60.16%] [G loss: 0.292346]\n",
      "epoch:7 step:6789 [D loss: 0.249600, acc.: 57.81%] [G loss: 0.295629]\n",
      "epoch:7 step:6790 [D loss: 0.239173, acc.: 57.81%] [G loss: 0.301962]\n",
      "epoch:7 step:6791 [D loss: 0.230859, acc.: 61.72%] [G loss: 0.302794]\n",
      "epoch:7 step:6792 [D loss: 0.249649, acc.: 54.69%] [G loss: 0.292477]\n",
      "epoch:7 step:6793 [D loss: 0.248993, acc.: 53.91%] [G loss: 0.286682]\n",
      "epoch:7 step:6794 [D loss: 0.235596, acc.: 56.25%] [G loss: 0.316175]\n",
      "epoch:7 step:6795 [D loss: 0.236260, acc.: 63.28%] [G loss: 0.306130]\n",
      "epoch:7 step:6796 [D loss: 0.247449, acc.: 57.81%] [G loss: 0.310416]\n",
      "epoch:7 step:6797 [D loss: 0.239826, acc.: 60.16%] [G loss: 0.285896]\n",
      "epoch:7 step:6798 [D loss: 0.242775, acc.: 57.81%] [G loss: 0.314074]\n",
      "epoch:7 step:6799 [D loss: 0.242587, acc.: 59.38%] [G loss: 0.307758]\n",
      "epoch:7 step:6800 [D loss: 0.235173, acc.: 57.03%] [G loss: 0.299749]\n",
      "epoch:7 step:6801 [D loss: 0.263778, acc.: 52.34%] [G loss: 0.286980]\n",
      "epoch:7 step:6802 [D loss: 0.236926, acc.: 61.72%] [G loss: 0.277866]\n",
      "epoch:7 step:6803 [D loss: 0.236494, acc.: 57.03%] [G loss: 0.278575]\n",
      "epoch:7 step:6804 [D loss: 0.243394, acc.: 56.25%] [G loss: 0.293470]\n",
      "epoch:7 step:6805 [D loss: 0.244267, acc.: 53.91%] [G loss: 0.304294]\n",
      "epoch:7 step:6806 [D loss: 0.254130, acc.: 50.78%] [G loss: 0.270029]\n",
      "epoch:7 step:6807 [D loss: 0.240812, acc.: 59.38%] [G loss: 0.304904]\n",
      "epoch:7 step:6808 [D loss: 0.241649, acc.: 57.03%] [G loss: 0.274461]\n",
      "epoch:7 step:6809 [D loss: 0.235787, acc.: 62.50%] [G loss: 0.308854]\n",
      "epoch:7 step:6810 [D loss: 0.238685, acc.: 57.03%] [G loss: 0.307540]\n",
      "epoch:7 step:6811 [D loss: 0.237124, acc.: 63.28%] [G loss: 0.269897]\n",
      "epoch:7 step:6812 [D loss: 0.230811, acc.: 59.38%] [G loss: 0.323269]\n",
      "epoch:7 step:6813 [D loss: 0.242440, acc.: 60.16%] [G loss: 0.295136]\n",
      "epoch:7 step:6814 [D loss: 0.239972, acc.: 56.25%] [G loss: 0.297297]\n",
      "epoch:7 step:6815 [D loss: 0.241047, acc.: 59.38%] [G loss: 0.306296]\n",
      "epoch:7 step:6816 [D loss: 0.225777, acc.: 60.16%] [G loss: 0.314083]\n",
      "epoch:7 step:6817 [D loss: 0.263393, acc.: 46.09%] [G loss: 0.269239]\n",
      "epoch:7 step:6818 [D loss: 0.258543, acc.: 48.44%] [G loss: 0.301903]\n",
      "epoch:7 step:6819 [D loss: 0.244482, acc.: 53.91%] [G loss: 0.295680]\n",
      "epoch:7 step:6820 [D loss: 0.243039, acc.: 53.12%] [G loss: 0.302703]\n",
      "epoch:7 step:6821 [D loss: 0.246031, acc.: 54.69%] [G loss: 0.297121]\n",
      "epoch:7 step:6822 [D loss: 0.238090, acc.: 58.59%] [G loss: 0.326201]\n",
      "epoch:7 step:6823 [D loss: 0.236169, acc.: 62.50%] [G loss: 0.287123]\n",
      "epoch:7 step:6824 [D loss: 0.255645, acc.: 52.34%] [G loss: 0.309399]\n",
      "epoch:7 step:6825 [D loss: 0.248865, acc.: 60.94%] [G loss: 0.309907]\n",
      "epoch:7 step:6826 [D loss: 0.235430, acc.: 61.72%] [G loss: 0.288428]\n",
      "epoch:7 step:6827 [D loss: 0.228140, acc.: 60.94%] [G loss: 0.325540]\n",
      "epoch:7 step:6828 [D loss: 0.246854, acc.: 57.03%] [G loss: 0.286431]\n",
      "epoch:7 step:6829 [D loss: 0.253316, acc.: 50.78%] [G loss: 0.294558]\n",
      "epoch:7 step:6830 [D loss: 0.229969, acc.: 60.94%] [G loss: 0.290261]\n",
      "epoch:7 step:6831 [D loss: 0.229665, acc.: 62.50%] [G loss: 0.310907]\n",
      "epoch:7 step:6832 [D loss: 0.237257, acc.: 60.16%] [G loss: 0.305583]\n",
      "epoch:7 step:6833 [D loss: 0.242934, acc.: 56.25%] [G loss: 0.309411]\n",
      "epoch:7 step:6834 [D loss: 0.235729, acc.: 61.72%] [G loss: 0.298781]\n",
      "epoch:7 step:6835 [D loss: 0.260981, acc.: 46.88%] [G loss: 0.298311]\n",
      "epoch:7 step:6836 [D loss: 0.232695, acc.: 62.50%] [G loss: 0.312822]\n",
      "epoch:7 step:6837 [D loss: 0.241211, acc.: 59.38%] [G loss: 0.304081]\n",
      "epoch:7 step:6838 [D loss: 0.249110, acc.: 56.25%] [G loss: 0.316042]\n",
      "epoch:7 step:6839 [D loss: 0.229823, acc.: 60.94%] [G loss: 0.286364]\n",
      "epoch:7 step:6840 [D loss: 0.246966, acc.: 50.78%] [G loss: 0.301204]\n",
      "epoch:7 step:6841 [D loss: 0.242650, acc.: 50.78%] [G loss: 0.280614]\n",
      "epoch:7 step:6842 [D loss: 0.256853, acc.: 53.91%] [G loss: 0.305810]\n",
      "epoch:7 step:6843 [D loss: 0.232523, acc.: 57.81%] [G loss: 0.302518]\n",
      "epoch:7 step:6844 [D loss: 0.257465, acc.: 50.78%] [G loss: 0.303713]\n",
      "epoch:7 step:6845 [D loss: 0.225190, acc.: 64.06%] [G loss: 0.285428]\n",
      "epoch:7 step:6846 [D loss: 0.255446, acc.: 56.25%] [G loss: 0.282254]\n",
      "epoch:7 step:6847 [D loss: 0.228329, acc.: 60.16%] [G loss: 0.275451]\n",
      "epoch:7 step:6848 [D loss: 0.244053, acc.: 57.03%] [G loss: 0.308729]\n",
      "epoch:7 step:6849 [D loss: 0.249883, acc.: 55.47%] [G loss: 0.294789]\n",
      "epoch:7 step:6850 [D loss: 0.242548, acc.: 56.25%] [G loss: 0.293869]\n",
      "epoch:7 step:6851 [D loss: 0.250155, acc.: 51.56%] [G loss: 0.305975]\n",
      "epoch:7 step:6852 [D loss: 0.242732, acc.: 60.16%] [G loss: 0.264273]\n",
      "epoch:7 step:6853 [D loss: 0.249353, acc.: 51.56%] [G loss: 0.283179]\n",
      "epoch:7 step:6854 [D loss: 0.227829, acc.: 62.50%] [G loss: 0.318099]\n",
      "epoch:7 step:6855 [D loss: 0.248260, acc.: 53.91%] [G loss: 0.286540]\n",
      "epoch:7 step:6856 [D loss: 0.234998, acc.: 66.41%] [G loss: 0.299684]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:7 step:6857 [D loss: 0.250511, acc.: 53.12%] [G loss: 0.312812]\n",
      "epoch:7 step:6858 [D loss: 0.245662, acc.: 54.69%] [G loss: 0.291917]\n",
      "epoch:7 step:6859 [D loss: 0.233067, acc.: 60.16%] [G loss: 0.298336]\n",
      "epoch:7 step:6860 [D loss: 0.257422, acc.: 50.00%] [G loss: 0.314704]\n",
      "epoch:7 step:6861 [D loss: 0.243437, acc.: 55.47%] [G loss: 0.288623]\n",
      "epoch:7 step:6862 [D loss: 0.249449, acc.: 54.69%] [G loss: 0.319214]\n",
      "epoch:7 step:6863 [D loss: 0.239815, acc.: 56.25%] [G loss: 0.296268]\n",
      "epoch:7 step:6864 [D loss: 0.238234, acc.: 65.62%] [G loss: 0.308200]\n",
      "epoch:7 step:6865 [D loss: 0.242222, acc.: 50.00%] [G loss: 0.287563]\n",
      "epoch:7 step:6866 [D loss: 0.240469, acc.: 57.81%] [G loss: 0.296454]\n",
      "epoch:7 step:6867 [D loss: 0.246645, acc.: 54.69%] [G loss: 0.283928]\n",
      "epoch:7 step:6868 [D loss: 0.233585, acc.: 59.38%] [G loss: 0.282998]\n",
      "epoch:7 step:6869 [D loss: 0.235150, acc.: 66.41%] [G loss: 0.303708]\n",
      "epoch:7 step:6870 [D loss: 0.245379, acc.: 51.56%] [G loss: 0.307172]\n",
      "epoch:7 step:6871 [D loss: 0.252625, acc.: 57.03%] [G loss: 0.302694]\n",
      "epoch:7 step:6872 [D loss: 0.233442, acc.: 62.50%] [G loss: 0.300109]\n",
      "epoch:7 step:6873 [D loss: 0.255790, acc.: 48.44%] [G loss: 0.284570]\n",
      "epoch:7 step:6874 [D loss: 0.247516, acc.: 50.00%] [G loss: 0.271794]\n",
      "epoch:7 step:6875 [D loss: 0.247517, acc.: 56.25%] [G loss: 0.322722]\n",
      "epoch:7 step:6876 [D loss: 0.235822, acc.: 57.81%] [G loss: 0.299938]\n",
      "epoch:7 step:6877 [D loss: 0.240965, acc.: 55.47%] [G loss: 0.292760]\n",
      "epoch:7 step:6878 [D loss: 0.225029, acc.: 67.19%] [G loss: 0.292684]\n",
      "epoch:7 step:6879 [D loss: 0.243082, acc.: 57.03%] [G loss: 0.319633]\n",
      "epoch:7 step:6880 [D loss: 0.226435, acc.: 69.53%] [G loss: 0.287613]\n",
      "epoch:7 step:6881 [D loss: 0.261522, acc.: 42.97%] [G loss: 0.297461]\n",
      "epoch:7 step:6882 [D loss: 0.248084, acc.: 56.25%] [G loss: 0.292587]\n",
      "epoch:7 step:6883 [D loss: 0.242741, acc.: 50.78%] [G loss: 0.307627]\n",
      "epoch:7 step:6884 [D loss: 0.241022, acc.: 60.16%] [G loss: 0.309395]\n",
      "epoch:7 step:6885 [D loss: 0.252726, acc.: 53.12%] [G loss: 0.299925]\n",
      "epoch:7 step:6886 [D loss: 0.237326, acc.: 54.69%] [G loss: 0.279628]\n",
      "epoch:7 step:6887 [D loss: 0.239029, acc.: 56.25%] [G loss: 0.277670]\n",
      "epoch:7 step:6888 [D loss: 0.254485, acc.: 57.03%] [G loss: 0.303763]\n",
      "epoch:7 step:6889 [D loss: 0.234428, acc.: 61.72%] [G loss: 0.275531]\n",
      "epoch:7 step:6890 [D loss: 0.238420, acc.: 58.59%] [G loss: 0.304264]\n",
      "epoch:7 step:6891 [D loss: 0.231329, acc.: 60.94%] [G loss: 0.313535]\n",
      "epoch:7 step:6892 [D loss: 0.225134, acc.: 64.84%] [G loss: 0.304474]\n",
      "epoch:7 step:6893 [D loss: 0.243165, acc.: 56.25%] [G loss: 0.276404]\n",
      "epoch:7 step:6894 [D loss: 0.240944, acc.: 57.03%] [G loss: 0.294867]\n",
      "epoch:7 step:6895 [D loss: 0.234894, acc.: 65.62%] [G loss: 0.302627]\n",
      "epoch:7 step:6896 [D loss: 0.238506, acc.: 60.94%] [G loss: 0.295393]\n",
      "epoch:7 step:6897 [D loss: 0.250266, acc.: 57.03%] [G loss: 0.279854]\n",
      "epoch:7 step:6898 [D loss: 0.245408, acc.: 57.81%] [G loss: 0.300029]\n",
      "epoch:7 step:6899 [D loss: 0.238959, acc.: 57.81%] [G loss: 0.295087]\n",
      "epoch:7 step:6900 [D loss: 0.244498, acc.: 55.47%] [G loss: 0.303461]\n",
      "epoch:7 step:6901 [D loss: 0.240709, acc.: 58.59%] [G loss: 0.301071]\n",
      "epoch:7 step:6902 [D loss: 0.257898, acc.: 46.88%] [G loss: 0.287813]\n",
      "epoch:7 step:6903 [D loss: 0.216640, acc.: 69.53%] [G loss: 0.273653]\n",
      "epoch:7 step:6904 [D loss: 0.254174, acc.: 57.81%] [G loss: 0.308570]\n",
      "epoch:7 step:6905 [D loss: 0.250287, acc.: 51.56%] [G loss: 0.292744]\n",
      "epoch:7 step:6906 [D loss: 0.253320, acc.: 48.44%] [G loss: 0.284990]\n",
      "epoch:7 step:6907 [D loss: 0.242639, acc.: 58.59%] [G loss: 0.297660]\n",
      "epoch:7 step:6908 [D loss: 0.226197, acc.: 64.84%] [G loss: 0.291860]\n",
      "epoch:7 step:6909 [D loss: 0.249634, acc.: 53.91%] [G loss: 0.306010]\n",
      "epoch:7 step:6910 [D loss: 0.248073, acc.: 55.47%] [G loss: 0.294276]\n",
      "epoch:7 step:6911 [D loss: 0.247746, acc.: 53.12%] [G loss: 0.312839]\n",
      "epoch:7 step:6912 [D loss: 0.254020, acc.: 50.00%] [G loss: 0.267555]\n",
      "epoch:7 step:6913 [D loss: 0.247444, acc.: 53.91%] [G loss: 0.294314]\n",
      "epoch:7 step:6914 [D loss: 0.245823, acc.: 52.34%] [G loss: 0.273861]\n",
      "epoch:7 step:6915 [D loss: 0.255254, acc.: 46.88%] [G loss: 0.295797]\n",
      "epoch:7 step:6916 [D loss: 0.265581, acc.: 50.00%] [G loss: 0.284607]\n",
      "epoch:7 step:6917 [D loss: 0.229629, acc.: 59.38%] [G loss: 0.278123]\n",
      "epoch:7 step:6918 [D loss: 0.250910, acc.: 50.78%] [G loss: 0.274803]\n",
      "epoch:7 step:6919 [D loss: 0.242282, acc.: 57.81%] [G loss: 0.291988]\n",
      "epoch:7 step:6920 [D loss: 0.247018, acc.: 56.25%] [G loss: 0.279055]\n",
      "epoch:7 step:6921 [D loss: 0.239798, acc.: 63.28%] [G loss: 0.291067]\n",
      "epoch:7 step:6922 [D loss: 0.226890, acc.: 62.50%] [G loss: 0.292260]\n",
      "epoch:7 step:6923 [D loss: 0.243642, acc.: 50.78%] [G loss: 0.285079]\n",
      "epoch:7 step:6924 [D loss: 0.236863, acc.: 56.25%] [G loss: 0.306197]\n",
      "epoch:7 step:6925 [D loss: 0.217732, acc.: 67.19%] [G loss: 0.313697]\n",
      "epoch:7 step:6926 [D loss: 0.258532, acc.: 46.09%] [G loss: 0.314434]\n",
      "epoch:7 step:6927 [D loss: 0.232345, acc.: 60.16%] [G loss: 0.316137]\n",
      "epoch:7 step:6928 [D loss: 0.236514, acc.: 61.72%] [G loss: 0.292838]\n",
      "epoch:7 step:6929 [D loss: 0.252537, acc.: 52.34%] [G loss: 0.289937]\n",
      "epoch:7 step:6930 [D loss: 0.259900, acc.: 49.22%] [G loss: 0.276369]\n",
      "epoch:7 step:6931 [D loss: 0.235332, acc.: 59.38%] [G loss: 0.290319]\n",
      "epoch:7 step:6932 [D loss: 0.244494, acc.: 56.25%] [G loss: 0.284217]\n",
      "epoch:7 step:6933 [D loss: 0.255299, acc.: 49.22%] [G loss: 0.294438]\n",
      "epoch:7 step:6934 [D loss: 0.246359, acc.: 56.25%] [G loss: 0.326405]\n",
      "epoch:7 step:6935 [D loss: 0.259767, acc.: 50.00%] [G loss: 0.296102]\n",
      "epoch:7 step:6936 [D loss: 0.247035, acc.: 59.38%] [G loss: 0.317416]\n",
      "epoch:7 step:6937 [D loss: 0.232736, acc.: 60.94%] [G loss: 0.316408]\n",
      "epoch:7 step:6938 [D loss: 0.225340, acc.: 66.41%] [G loss: 0.321501]\n",
      "epoch:7 step:6939 [D loss: 0.239136, acc.: 60.16%] [G loss: 0.309733]\n",
      "epoch:7 step:6940 [D loss: 0.245002, acc.: 53.91%] [G loss: 0.312021]\n",
      "epoch:7 step:6941 [D loss: 0.243335, acc.: 56.25%] [G loss: 0.306176]\n",
      "epoch:7 step:6942 [D loss: 0.248404, acc.: 55.47%] [G loss: 0.326286]\n",
      "epoch:7 step:6943 [D loss: 0.257970, acc.: 52.34%] [G loss: 0.284178]\n",
      "epoch:7 step:6944 [D loss: 0.254778, acc.: 50.78%] [G loss: 0.282898]\n",
      "epoch:7 step:6945 [D loss: 0.248155, acc.: 53.12%] [G loss: 0.310732]\n",
      "epoch:7 step:6946 [D loss: 0.240848, acc.: 60.94%] [G loss: 0.302566]\n",
      "epoch:7 step:6947 [D loss: 0.252864, acc.: 59.38%] [G loss: 0.277710]\n",
      "epoch:7 step:6948 [D loss: 0.234128, acc.: 60.94%] [G loss: 0.331581]\n",
      "epoch:7 step:6949 [D loss: 0.245215, acc.: 54.69%] [G loss: 0.319461]\n",
      "epoch:7 step:6950 [D loss: 0.246458, acc.: 59.38%] [G loss: 0.297944]\n",
      "epoch:7 step:6951 [D loss: 0.233637, acc.: 62.50%] [G loss: 0.289374]\n",
      "epoch:7 step:6952 [D loss: 0.258682, acc.: 49.22%] [G loss: 0.325421]\n",
      "epoch:7 step:6953 [D loss: 0.236538, acc.: 61.72%] [G loss: 0.315072]\n",
      "epoch:7 step:6954 [D loss: 0.239453, acc.: 53.91%] [G loss: 0.303188]\n",
      "epoch:7 step:6955 [D loss: 0.241827, acc.: 57.03%] [G loss: 0.283830]\n",
      "epoch:7 step:6956 [D loss: 0.252128, acc.: 52.34%] [G loss: 0.327643]\n",
      "epoch:7 step:6957 [D loss: 0.258673, acc.: 52.34%] [G loss: 0.292151]\n",
      "epoch:7 step:6958 [D loss: 0.219948, acc.: 67.19%] [G loss: 0.296053]\n",
      "epoch:7 step:6959 [D loss: 0.238189, acc.: 57.81%] [G loss: 0.311243]\n",
      "epoch:7 step:6960 [D loss: 0.253635, acc.: 49.22%] [G loss: 0.303872]\n",
      "epoch:7 step:6961 [D loss: 0.236514, acc.: 58.59%] [G loss: 0.275390]\n",
      "epoch:7 step:6962 [D loss: 0.245992, acc.: 54.69%] [G loss: 0.280209]\n",
      "epoch:7 step:6963 [D loss: 0.251570, acc.: 52.34%] [G loss: 0.308760]\n",
      "epoch:7 step:6964 [D loss: 0.232654, acc.: 64.06%] [G loss: 0.308134]\n",
      "epoch:7 step:6965 [D loss: 0.237457, acc.: 55.47%] [G loss: 0.299995]\n",
      "epoch:7 step:6966 [D loss: 0.251248, acc.: 54.69%] [G loss: 0.302856]\n",
      "epoch:7 step:6967 [D loss: 0.239661, acc.: 60.94%] [G loss: 0.302708]\n",
      "epoch:7 step:6968 [D loss: 0.250889, acc.: 51.56%] [G loss: 0.299793]\n",
      "epoch:7 step:6969 [D loss: 0.251052, acc.: 52.34%] [G loss: 0.298652]\n",
      "epoch:7 step:6970 [D loss: 0.257520, acc.: 53.12%] [G loss: 0.307862]\n",
      "epoch:7 step:6971 [D loss: 0.252620, acc.: 53.91%] [G loss: 0.294318]\n",
      "epoch:7 step:6972 [D loss: 0.255883, acc.: 51.56%] [G loss: 0.283596]\n",
      "epoch:7 step:6973 [D loss: 0.239760, acc.: 62.50%] [G loss: 0.324722]\n",
      "epoch:7 step:6974 [D loss: 0.237697, acc.: 60.16%] [G loss: 0.321845]\n",
      "epoch:7 step:6975 [D loss: 0.245033, acc.: 55.47%] [G loss: 0.293661]\n",
      "epoch:7 step:6976 [D loss: 0.245643, acc.: 58.59%] [G loss: 0.309743]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:7 step:6977 [D loss: 0.249033, acc.: 55.47%] [G loss: 0.271351]\n",
      "epoch:7 step:6978 [D loss: 0.234600, acc.: 57.81%] [G loss: 0.299701]\n",
      "epoch:7 step:6979 [D loss: 0.242264, acc.: 58.59%] [G loss: 0.285548]\n",
      "epoch:7 step:6980 [D loss: 0.247220, acc.: 57.81%] [G loss: 0.290139]\n",
      "epoch:7 step:6981 [D loss: 0.222549, acc.: 66.41%] [G loss: 0.311465]\n",
      "epoch:7 step:6982 [D loss: 0.242394, acc.: 57.03%] [G loss: 0.287549]\n",
      "epoch:7 step:6983 [D loss: 0.233215, acc.: 61.72%] [G loss: 0.279694]\n",
      "epoch:7 step:6984 [D loss: 0.237794, acc.: 62.50%] [G loss: 0.304651]\n",
      "epoch:7 step:6985 [D loss: 0.236039, acc.: 56.25%] [G loss: 0.291382]\n",
      "epoch:7 step:6986 [D loss: 0.239808, acc.: 60.16%] [G loss: 0.329062]\n",
      "epoch:7 step:6987 [D loss: 0.236941, acc.: 63.28%] [G loss: 0.280527]\n",
      "epoch:7 step:6988 [D loss: 0.247940, acc.: 58.59%] [G loss: 0.287507]\n",
      "epoch:7 step:6989 [D loss: 0.241120, acc.: 60.16%] [G loss: 0.300921]\n",
      "epoch:7 step:6990 [D loss: 0.252530, acc.: 54.69%] [G loss: 0.304582]\n",
      "epoch:7 step:6991 [D loss: 0.227130, acc.: 63.28%] [G loss: 0.312941]\n",
      "epoch:7 step:6992 [D loss: 0.242064, acc.: 56.25%] [G loss: 0.326344]\n",
      "epoch:7 step:6993 [D loss: 0.238664, acc.: 60.16%] [G loss: 0.287952]\n",
      "epoch:7 step:6994 [D loss: 0.236442, acc.: 65.62%] [G loss: 0.304529]\n",
      "epoch:7 step:6995 [D loss: 0.233383, acc.: 65.62%] [G loss: 0.308720]\n",
      "epoch:7 step:6996 [D loss: 0.234648, acc.: 62.50%] [G loss: 0.295883]\n",
      "epoch:7 step:6997 [D loss: 0.239158, acc.: 59.38%] [G loss: 0.311020]\n",
      "epoch:7 step:6998 [D loss: 0.254730, acc.: 51.56%] [G loss: 0.282342]\n",
      "epoch:7 step:6999 [D loss: 0.235724, acc.: 60.94%] [G loss: 0.306444]\n",
      "epoch:7 step:7000 [D loss: 0.237352, acc.: 58.59%] [G loss: 0.301852]\n",
      "epoch:7 step:7001 [D loss: 0.251216, acc.: 54.69%] [G loss: 0.312818]\n",
      "epoch:7 step:7002 [D loss: 0.233436, acc.: 63.28%] [G loss: 0.297485]\n",
      "epoch:7 step:7003 [D loss: 0.233033, acc.: 60.16%] [G loss: 0.287538]\n",
      "epoch:7 step:7004 [D loss: 0.242431, acc.: 61.72%] [G loss: 0.285314]\n",
      "epoch:7 step:7005 [D loss: 0.252692, acc.: 57.03%] [G loss: 0.283038]\n",
      "epoch:7 step:7006 [D loss: 0.234750, acc.: 61.72%] [G loss: 0.302164]\n",
      "epoch:7 step:7007 [D loss: 0.234482, acc.: 58.59%] [G loss: 0.295359]\n",
      "epoch:7 step:7008 [D loss: 0.241996, acc.: 56.25%] [G loss: 0.303984]\n",
      "epoch:7 step:7009 [D loss: 0.242104, acc.: 57.03%] [G loss: 0.308883]\n",
      "epoch:7 step:7010 [D loss: 0.238768, acc.: 57.81%] [G loss: 0.291674]\n",
      "epoch:7 step:7011 [D loss: 0.248303, acc.: 55.47%] [G loss: 0.309665]\n",
      "epoch:7 step:7012 [D loss: 0.233559, acc.: 61.72%] [G loss: 0.294579]\n",
      "epoch:7 step:7013 [D loss: 0.238815, acc.: 60.94%] [G loss: 0.302276]\n",
      "epoch:7 step:7014 [D loss: 0.239901, acc.: 62.50%] [G loss: 0.319795]\n",
      "epoch:7 step:7015 [D loss: 0.248792, acc.: 51.56%] [G loss: 0.309092]\n",
      "epoch:7 step:7016 [D loss: 0.250226, acc.: 54.69%] [G loss: 0.297678]\n",
      "epoch:7 step:7017 [D loss: 0.253115, acc.: 52.34%] [G loss: 0.295219]\n",
      "epoch:7 step:7018 [D loss: 0.238697, acc.: 56.25%] [G loss: 0.300489]\n",
      "epoch:7 step:7019 [D loss: 0.254379, acc.: 53.12%] [G loss: 0.289589]\n",
      "epoch:7 step:7020 [D loss: 0.231354, acc.: 60.16%] [G loss: 0.306427]\n",
      "epoch:7 step:7021 [D loss: 0.235894, acc.: 57.03%] [G loss: 0.299879]\n",
      "epoch:7 step:7022 [D loss: 0.240072, acc.: 58.59%] [G loss: 0.288675]\n",
      "epoch:7 step:7023 [D loss: 0.239173, acc.: 55.47%] [G loss: 0.302893]\n",
      "epoch:7 step:7024 [D loss: 0.235037, acc.: 58.59%] [G loss: 0.302659]\n",
      "epoch:7 step:7025 [D loss: 0.241938, acc.: 57.03%] [G loss: 0.323228]\n",
      "epoch:7 step:7026 [D loss: 0.238141, acc.: 57.81%] [G loss: 0.296510]\n",
      "epoch:7 step:7027 [D loss: 0.255968, acc.: 49.22%] [G loss: 0.303763]\n",
      "epoch:7 step:7028 [D loss: 0.235057, acc.: 63.28%] [G loss: 0.316184]\n",
      "epoch:7 step:7029 [D loss: 0.252933, acc.: 57.81%] [G loss: 0.303022]\n",
      "epoch:7 step:7030 [D loss: 0.236249, acc.: 57.81%] [G loss: 0.278142]\n",
      "epoch:7 step:7031 [D loss: 0.230681, acc.: 61.72%] [G loss: 0.305334]\n",
      "epoch:7 step:7032 [D loss: 0.247039, acc.: 54.69%] [G loss: 0.299404]\n",
      "epoch:7 step:7033 [D loss: 0.243888, acc.: 60.16%] [G loss: 0.318267]\n",
      "epoch:7 step:7034 [D loss: 0.223255, acc.: 64.84%] [G loss: 0.308034]\n",
      "epoch:7 step:7035 [D loss: 0.247751, acc.: 55.47%] [G loss: 0.303046]\n",
      "epoch:7 step:7036 [D loss: 0.262260, acc.: 46.88%] [G loss: 0.288930]\n",
      "epoch:7 step:7037 [D loss: 0.241992, acc.: 55.47%] [G loss: 0.309892]\n",
      "epoch:7 step:7038 [D loss: 0.238485, acc.: 62.50%] [G loss: 0.298938]\n",
      "epoch:7 step:7039 [D loss: 0.244897, acc.: 49.22%] [G loss: 0.309756]\n",
      "epoch:7 step:7040 [D loss: 0.252470, acc.: 56.25%] [G loss: 0.270754]\n",
      "epoch:7 step:7041 [D loss: 0.242136, acc.: 57.03%] [G loss: 0.297487]\n",
      "epoch:7 step:7042 [D loss: 0.249833, acc.: 53.91%] [G loss: 0.298422]\n",
      "epoch:7 step:7043 [D loss: 0.237720, acc.: 53.91%] [G loss: 0.296471]\n",
      "epoch:7 step:7044 [D loss: 0.245386, acc.: 54.69%] [G loss: 0.304609]\n",
      "epoch:7 step:7045 [D loss: 0.239671, acc.: 54.69%] [G loss: 0.268104]\n",
      "epoch:7 step:7046 [D loss: 0.235216, acc.: 63.28%] [G loss: 0.307397]\n",
      "epoch:7 step:7047 [D loss: 0.244306, acc.: 57.03%] [G loss: 0.300810]\n",
      "epoch:7 step:7048 [D loss: 0.240954, acc.: 60.94%] [G loss: 0.309712]\n",
      "epoch:7 step:7049 [D loss: 0.228754, acc.: 63.28%] [G loss: 0.307028]\n",
      "epoch:7 step:7050 [D loss: 0.235779, acc.: 57.81%] [G loss: 0.304699]\n",
      "epoch:7 step:7051 [D loss: 0.240326, acc.: 57.03%] [G loss: 0.318283]\n",
      "epoch:7 step:7052 [D loss: 0.262116, acc.: 50.00%] [G loss: 0.292531]\n",
      "epoch:7 step:7053 [D loss: 0.215881, acc.: 67.97%] [G loss: 0.311110]\n",
      "epoch:7 step:7054 [D loss: 0.242562, acc.: 54.69%] [G loss: 0.303248]\n",
      "epoch:7 step:7055 [D loss: 0.245051, acc.: 57.81%] [G loss: 0.306800]\n",
      "epoch:7 step:7056 [D loss: 0.250537, acc.: 53.91%] [G loss: 0.298177]\n",
      "epoch:7 step:7057 [D loss: 0.235295, acc.: 59.38%] [G loss: 0.297425]\n",
      "epoch:7 step:7058 [D loss: 0.241327, acc.: 54.69%] [G loss: 0.298296]\n",
      "epoch:7 step:7059 [D loss: 0.237434, acc.: 58.59%] [G loss: 0.316478]\n",
      "epoch:7 step:7060 [D loss: 0.228159, acc.: 64.84%] [G loss: 0.304505]\n",
      "epoch:7 step:7061 [D loss: 0.230224, acc.: 61.72%] [G loss: 0.291970]\n",
      "epoch:7 step:7062 [D loss: 0.239679, acc.: 59.38%] [G loss: 0.298113]\n",
      "epoch:7 step:7063 [D loss: 0.239454, acc.: 55.47%] [G loss: 0.276743]\n",
      "epoch:7 step:7064 [D loss: 0.244626, acc.: 57.81%] [G loss: 0.308235]\n",
      "epoch:7 step:7065 [D loss: 0.262927, acc.: 48.44%] [G loss: 0.300688]\n",
      "epoch:7 step:7066 [D loss: 0.232800, acc.: 62.50%] [G loss: 0.287941]\n",
      "epoch:7 step:7067 [D loss: 0.223896, acc.: 62.50%] [G loss: 0.287539]\n",
      "epoch:7 step:7068 [D loss: 0.225075, acc.: 64.84%] [G loss: 0.317071]\n",
      "epoch:7 step:7069 [D loss: 0.233992, acc.: 59.38%] [G loss: 0.286706]\n",
      "epoch:7 step:7070 [D loss: 0.267082, acc.: 49.22%] [G loss: 0.311960]\n",
      "epoch:7 step:7071 [D loss: 0.240300, acc.: 60.16%] [G loss: 0.322987]\n",
      "epoch:7 step:7072 [D loss: 0.233669, acc.: 56.25%] [G loss: 0.285239]\n",
      "epoch:7 step:7073 [D loss: 0.240164, acc.: 56.25%] [G loss: 0.304585]\n",
      "epoch:7 step:7074 [D loss: 0.239739, acc.: 58.59%] [G loss: 0.309762]\n",
      "epoch:7 step:7075 [D loss: 0.249362, acc.: 51.56%] [G loss: 0.291704]\n",
      "epoch:7 step:7076 [D loss: 0.235215, acc.: 56.25%] [G loss: 0.317542]\n",
      "epoch:7 step:7077 [D loss: 0.233568, acc.: 57.81%] [G loss: 0.314521]\n",
      "epoch:7 step:7078 [D loss: 0.247662, acc.: 52.34%] [G loss: 0.290540]\n",
      "epoch:7 step:7079 [D loss: 0.242819, acc.: 58.59%] [G loss: 0.267989]\n",
      "epoch:7 step:7080 [D loss: 0.250878, acc.: 56.25%] [G loss: 0.297489]\n",
      "epoch:7 step:7081 [D loss: 0.264042, acc.: 49.22%] [G loss: 0.309975]\n",
      "epoch:7 step:7082 [D loss: 0.253938, acc.: 53.91%] [G loss: 0.291130]\n",
      "epoch:7 step:7083 [D loss: 0.228406, acc.: 59.38%] [G loss: 0.294586]\n",
      "epoch:7 step:7084 [D loss: 0.261474, acc.: 47.66%] [G loss: 0.304528]\n",
      "epoch:7 step:7085 [D loss: 0.248189, acc.: 53.12%] [G loss: 0.315318]\n",
      "epoch:7 step:7086 [D loss: 0.230097, acc.: 57.03%] [G loss: 0.298465]\n",
      "epoch:7 step:7087 [D loss: 0.242824, acc.: 59.38%] [G loss: 0.281498]\n",
      "epoch:7 step:7088 [D loss: 0.247220, acc.: 53.91%] [G loss: 0.306859]\n",
      "epoch:7 step:7089 [D loss: 0.231597, acc.: 59.38%] [G loss: 0.290641]\n",
      "epoch:7 step:7090 [D loss: 0.237758, acc.: 59.38%] [G loss: 0.318240]\n",
      "epoch:7 step:7091 [D loss: 0.248803, acc.: 57.81%] [G loss: 0.282506]\n",
      "epoch:7 step:7092 [D loss: 0.229243, acc.: 59.38%] [G loss: 0.307546]\n",
      "epoch:7 step:7093 [D loss: 0.239106, acc.: 58.59%] [G loss: 0.306742]\n",
      "epoch:7 step:7094 [D loss: 0.244254, acc.: 58.59%] [G loss: 0.306564]\n",
      "epoch:7 step:7095 [D loss: 0.242342, acc.: 58.59%] [G loss: 0.286720]\n",
      "epoch:7 step:7096 [D loss: 0.251443, acc.: 50.00%] [G loss: 0.302609]\n",
      "epoch:7 step:7097 [D loss: 0.238398, acc.: 60.16%] [G loss: 0.291947]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:7 step:7098 [D loss: 0.221103, acc.: 59.38%] [G loss: 0.307691]\n",
      "epoch:7 step:7099 [D loss: 0.242787, acc.: 54.69%] [G loss: 0.262560]\n",
      "epoch:7 step:7100 [D loss: 0.262127, acc.: 53.12%] [G loss: 0.282573]\n",
      "epoch:7 step:7101 [D loss: 0.247405, acc.: 53.12%] [G loss: 0.280911]\n",
      "epoch:7 step:7102 [D loss: 0.252355, acc.: 49.22%] [G loss: 0.286275]\n",
      "epoch:7 step:7103 [D loss: 0.245267, acc.: 57.03%] [G loss: 0.310934]\n",
      "epoch:7 step:7104 [D loss: 0.234933, acc.: 58.59%] [G loss: 0.278824]\n",
      "epoch:7 step:7105 [D loss: 0.235034, acc.: 61.72%] [G loss: 0.300974]\n",
      "epoch:7 step:7106 [D loss: 0.238571, acc.: 54.69%] [G loss: 0.307109]\n",
      "epoch:7 step:7107 [D loss: 0.231286, acc.: 60.16%] [G loss: 0.277494]\n",
      "epoch:7 step:7108 [D loss: 0.242016, acc.: 58.59%] [G loss: 0.309322]\n",
      "epoch:7 step:7109 [D loss: 0.242891, acc.: 56.25%] [G loss: 0.295139]\n",
      "epoch:7 step:7110 [D loss: 0.239959, acc.: 56.25%] [G loss: 0.332110]\n",
      "epoch:7 step:7111 [D loss: 0.250874, acc.: 54.69%] [G loss: 0.295600]\n",
      "epoch:7 step:7112 [D loss: 0.247964, acc.: 53.91%] [G loss: 0.317160]\n",
      "epoch:7 step:7113 [D loss: 0.234582, acc.: 55.47%] [G loss: 0.260433]\n",
      "epoch:7 step:7114 [D loss: 0.232280, acc.: 60.94%] [G loss: 0.304437]\n",
      "epoch:7 step:7115 [D loss: 0.236877, acc.: 60.16%] [G loss: 0.303930]\n",
      "epoch:7 step:7116 [D loss: 0.248955, acc.: 55.47%] [G loss: 0.317348]\n",
      "epoch:7 step:7117 [D loss: 0.242479, acc.: 50.78%] [G loss: 0.309831]\n",
      "epoch:7 step:7118 [D loss: 0.238065, acc.: 58.59%] [G loss: 0.301656]\n",
      "epoch:7 step:7119 [D loss: 0.237021, acc.: 57.81%] [G loss: 0.300668]\n",
      "epoch:7 step:7120 [D loss: 0.261008, acc.: 50.78%] [G loss: 0.305691]\n",
      "epoch:7 step:7121 [D loss: 0.252072, acc.: 54.69%] [G loss: 0.321352]\n",
      "epoch:7 step:7122 [D loss: 0.231301, acc.: 63.28%] [G loss: 0.283283]\n",
      "epoch:7 step:7123 [D loss: 0.227134, acc.: 60.16%] [G loss: 0.282281]\n",
      "epoch:7 step:7124 [D loss: 0.229112, acc.: 56.25%] [G loss: 0.316657]\n",
      "epoch:7 step:7125 [D loss: 0.248112, acc.: 57.03%] [G loss: 0.292149]\n",
      "epoch:7 step:7126 [D loss: 0.248260, acc.: 53.12%] [G loss: 0.287473]\n",
      "epoch:7 step:7127 [D loss: 0.220131, acc.: 61.72%] [G loss: 0.339562]\n",
      "epoch:7 step:7128 [D loss: 0.233702, acc.: 62.50%] [G loss: 0.299828]\n",
      "epoch:7 step:7129 [D loss: 0.243115, acc.: 58.59%] [G loss: 0.304163]\n",
      "epoch:7 step:7130 [D loss: 0.249964, acc.: 57.03%] [G loss: 0.275465]\n",
      "epoch:7 step:7131 [D loss: 0.222201, acc.: 64.84%] [G loss: 0.324651]\n",
      "epoch:7 step:7132 [D loss: 0.242666, acc.: 57.81%] [G loss: 0.281015]\n",
      "epoch:7 step:7133 [D loss: 0.251726, acc.: 50.78%] [G loss: 0.269049]\n",
      "epoch:7 step:7134 [D loss: 0.231878, acc.: 60.16%] [G loss: 0.297179]\n",
      "epoch:7 step:7135 [D loss: 0.242892, acc.: 57.03%] [G loss: 0.317705]\n",
      "epoch:7 step:7136 [D loss: 0.246363, acc.: 50.78%] [G loss: 0.293764]\n",
      "epoch:7 step:7137 [D loss: 0.228196, acc.: 63.28%] [G loss: 0.322509]\n",
      "epoch:7 step:7138 [D loss: 0.247533, acc.: 53.12%] [G loss: 0.286323]\n",
      "epoch:7 step:7139 [D loss: 0.225538, acc.: 60.16%] [G loss: 0.305073]\n",
      "epoch:7 step:7140 [D loss: 0.243749, acc.: 55.47%] [G loss: 0.298158]\n",
      "epoch:7 step:7141 [D loss: 0.230555, acc.: 64.84%] [G loss: 0.300738]\n",
      "epoch:7 step:7142 [D loss: 0.248033, acc.: 56.25%] [G loss: 0.286874]\n",
      "epoch:7 step:7143 [D loss: 0.245946, acc.: 52.34%] [G loss: 0.271620]\n",
      "epoch:7 step:7144 [D loss: 0.249755, acc.: 57.81%] [G loss: 0.291808]\n",
      "epoch:7 step:7145 [D loss: 0.225045, acc.: 67.19%] [G loss: 0.300759]\n",
      "epoch:7 step:7146 [D loss: 0.239672, acc.: 56.25%] [G loss: 0.282636]\n",
      "epoch:7 step:7147 [D loss: 0.254612, acc.: 54.69%] [G loss: 0.274097]\n",
      "epoch:7 step:7148 [D loss: 0.247712, acc.: 54.69%] [G loss: 0.290428]\n",
      "epoch:7 step:7149 [D loss: 0.236402, acc.: 58.59%] [G loss: 0.268918]\n",
      "epoch:7 step:7150 [D loss: 0.250037, acc.: 53.12%] [G loss: 0.318937]\n",
      "epoch:7 step:7151 [D loss: 0.237487, acc.: 54.69%] [G loss: 0.295719]\n",
      "epoch:7 step:7152 [D loss: 0.248744, acc.: 57.81%] [G loss: 0.280338]\n",
      "epoch:7 step:7153 [D loss: 0.257118, acc.: 53.91%] [G loss: 0.299523]\n",
      "epoch:7 step:7154 [D loss: 0.229440, acc.: 60.94%] [G loss: 0.305482]\n",
      "epoch:7 step:7155 [D loss: 0.243176, acc.: 52.34%] [G loss: 0.319448]\n",
      "epoch:7 step:7156 [D loss: 0.241536, acc.: 53.91%] [G loss: 0.316000]\n",
      "epoch:7 step:7157 [D loss: 0.259404, acc.: 47.66%] [G loss: 0.308634]\n",
      "epoch:7 step:7158 [D loss: 0.228878, acc.: 64.84%] [G loss: 0.284662]\n",
      "epoch:7 step:7159 [D loss: 0.241692, acc.: 56.25%] [G loss: 0.309173]\n",
      "epoch:7 step:7160 [D loss: 0.236444, acc.: 59.38%] [G loss: 0.317473]\n",
      "epoch:7 step:7161 [D loss: 0.229103, acc.: 61.72%] [G loss: 0.290216]\n",
      "epoch:7 step:7162 [D loss: 0.252855, acc.: 57.81%] [G loss: 0.296595]\n",
      "epoch:7 step:7163 [D loss: 0.249474, acc.: 55.47%] [G loss: 0.313866]\n",
      "epoch:7 step:7164 [D loss: 0.247180, acc.: 52.34%] [G loss: 0.304447]\n",
      "epoch:7 step:7165 [D loss: 0.259786, acc.: 50.00%] [G loss: 0.295541]\n",
      "epoch:7 step:7166 [D loss: 0.229869, acc.: 64.06%] [G loss: 0.289969]\n",
      "epoch:7 step:7167 [D loss: 0.226474, acc.: 61.72%] [G loss: 0.292434]\n",
      "epoch:7 step:7168 [D loss: 0.229994, acc.: 60.16%] [G loss: 0.288744]\n",
      "epoch:7 step:7169 [D loss: 0.247686, acc.: 53.12%] [G loss: 0.313340]\n",
      "epoch:7 step:7170 [D loss: 0.240416, acc.: 56.25%] [G loss: 0.268053]\n",
      "epoch:7 step:7171 [D loss: 0.250885, acc.: 56.25%] [G loss: 0.286860]\n",
      "epoch:7 step:7172 [D loss: 0.215561, acc.: 64.84%] [G loss: 0.320405]\n",
      "epoch:7 step:7173 [D loss: 0.241865, acc.: 60.16%] [G loss: 0.272779]\n",
      "epoch:7 step:7174 [D loss: 0.229018, acc.: 60.94%] [G loss: 0.284052]\n",
      "epoch:7 step:7175 [D loss: 0.220863, acc.: 64.06%] [G loss: 0.292400]\n",
      "epoch:7 step:7176 [D loss: 0.233812, acc.: 58.59%] [G loss: 0.293043]\n",
      "epoch:7 step:7177 [D loss: 0.240858, acc.: 54.69%] [G loss: 0.301091]\n",
      "epoch:7 step:7178 [D loss: 0.244678, acc.: 55.47%] [G loss: 0.274607]\n",
      "epoch:7 step:7179 [D loss: 0.255633, acc.: 50.78%] [G loss: 0.302899]\n",
      "epoch:7 step:7180 [D loss: 0.246506, acc.: 55.47%] [G loss: 0.297255]\n",
      "epoch:7 step:7181 [D loss: 0.264783, acc.: 54.69%] [G loss: 0.269700]\n",
      "epoch:7 step:7182 [D loss: 0.232703, acc.: 62.50%] [G loss: 0.298868]\n",
      "epoch:7 step:7183 [D loss: 0.246845, acc.: 55.47%] [G loss: 0.301574]\n",
      "epoch:7 step:7184 [D loss: 0.256254, acc.: 46.88%] [G loss: 0.288983]\n",
      "epoch:7 step:7185 [D loss: 0.242137, acc.: 50.78%] [G loss: 0.312231]\n",
      "epoch:7 step:7186 [D loss: 0.250278, acc.: 50.78%] [G loss: 0.288581]\n",
      "epoch:7 step:7187 [D loss: 0.257633, acc.: 49.22%] [G loss: 0.292419]\n",
      "epoch:7 step:7188 [D loss: 0.249972, acc.: 59.38%] [G loss: 0.301024]\n",
      "epoch:7 step:7189 [D loss: 0.253593, acc.: 52.34%] [G loss: 0.308878]\n",
      "epoch:7 step:7190 [D loss: 0.252607, acc.: 57.03%] [G loss: 0.285095]\n",
      "epoch:7 step:7191 [D loss: 0.255131, acc.: 52.34%] [G loss: 0.293593]\n",
      "epoch:7 step:7192 [D loss: 0.243478, acc.: 57.03%] [G loss: 0.293525]\n",
      "epoch:7 step:7193 [D loss: 0.247770, acc.: 50.00%] [G loss: 0.291618]\n",
      "epoch:7 step:7194 [D loss: 0.237503, acc.: 60.16%] [G loss: 0.318931]\n",
      "epoch:7 step:7195 [D loss: 0.235529, acc.: 60.16%] [G loss: 0.310291]\n",
      "epoch:7 step:7196 [D loss: 0.250060, acc.: 57.81%] [G loss: 0.300872]\n",
      "epoch:7 step:7197 [D loss: 0.249651, acc.: 53.91%] [G loss: 0.288049]\n",
      "epoch:7 step:7198 [D loss: 0.260633, acc.: 50.00%] [G loss: 0.308728]\n",
      "epoch:7 step:7199 [D loss: 0.242723, acc.: 53.12%] [G loss: 0.315480]\n",
      "epoch:7 step:7200 [D loss: 0.260026, acc.: 50.78%] [G loss: 0.314500]\n",
      "epoch:7 step:7201 [D loss: 0.233976, acc.: 58.59%] [G loss: 0.305677]\n",
      "epoch:7 step:7202 [D loss: 0.244566, acc.: 54.69%] [G loss: 0.287560]\n",
      "epoch:7 step:7203 [D loss: 0.233609, acc.: 64.84%] [G loss: 0.296496]\n",
      "epoch:7 step:7204 [D loss: 0.248164, acc.: 59.38%] [G loss: 0.293792]\n",
      "epoch:7 step:7205 [D loss: 0.254671, acc.: 54.69%] [G loss: 0.276165]\n",
      "epoch:7 step:7206 [D loss: 0.247136, acc.: 53.12%] [G loss: 0.295213]\n",
      "epoch:7 step:7207 [D loss: 0.244558, acc.: 53.91%] [G loss: 0.329514]\n",
      "epoch:7 step:7208 [D loss: 0.232527, acc.: 60.94%] [G loss: 0.300025]\n",
      "epoch:7 step:7209 [D loss: 0.236932, acc.: 62.50%] [G loss: 0.305759]\n",
      "epoch:7 step:7210 [D loss: 0.248823, acc.: 50.78%] [G loss: 0.310298]\n",
      "epoch:7 step:7211 [D loss: 0.241995, acc.: 54.69%] [G loss: 0.314918]\n",
      "epoch:7 step:7212 [D loss: 0.214440, acc.: 71.09%] [G loss: 0.312848]\n",
      "epoch:7 step:7213 [D loss: 0.234705, acc.: 57.81%] [G loss: 0.268641]\n",
      "epoch:7 step:7214 [D loss: 0.243488, acc.: 53.91%] [G loss: 0.294237]\n",
      "epoch:7 step:7215 [D loss: 0.242834, acc.: 57.81%] [G loss: 0.310150]\n",
      "epoch:7 step:7216 [D loss: 0.228526, acc.: 65.62%] [G loss: 0.291144]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:7 step:7217 [D loss: 0.239008, acc.: 60.94%] [G loss: 0.296630]\n",
      "epoch:7 step:7218 [D loss: 0.242087, acc.: 50.78%] [G loss: 0.316909]\n",
      "epoch:7 step:7219 [D loss: 0.232865, acc.: 57.81%] [G loss: 0.275714]\n",
      "epoch:7 step:7220 [D loss: 0.248982, acc.: 54.69%] [G loss: 0.288220]\n",
      "epoch:7 step:7221 [D loss: 0.239222, acc.: 60.94%] [G loss: 0.291694]\n",
      "epoch:7 step:7222 [D loss: 0.245503, acc.: 50.78%] [G loss: 0.274529]\n",
      "epoch:7 step:7223 [D loss: 0.227806, acc.: 64.06%] [G loss: 0.301202]\n",
      "epoch:7 step:7224 [D loss: 0.243259, acc.: 52.34%] [G loss: 0.287677]\n",
      "epoch:7 step:7225 [D loss: 0.222427, acc.: 66.41%] [G loss: 0.288666]\n",
      "epoch:7 step:7226 [D loss: 0.246818, acc.: 51.56%] [G loss: 0.288428]\n",
      "epoch:7 step:7227 [D loss: 0.243901, acc.: 54.69%] [G loss: 0.290930]\n",
      "epoch:7 step:7228 [D loss: 0.235558, acc.: 57.81%] [G loss: 0.275946]\n",
      "epoch:7 step:7229 [D loss: 0.240421, acc.: 55.47%] [G loss: 0.295078]\n",
      "epoch:7 step:7230 [D loss: 0.246703, acc.: 57.81%] [G loss: 0.249619]\n",
      "epoch:7 step:7231 [D loss: 0.226031, acc.: 65.62%] [G loss: 0.290969]\n",
      "epoch:7 step:7232 [D loss: 0.248306, acc.: 53.12%] [G loss: 0.327305]\n",
      "epoch:7 step:7233 [D loss: 0.225060, acc.: 64.06%] [G loss: 0.300025]\n",
      "epoch:7 step:7234 [D loss: 0.236496, acc.: 61.72%] [G loss: 0.296130]\n",
      "epoch:7 step:7235 [D loss: 0.250497, acc.: 53.12%] [G loss: 0.285640]\n",
      "epoch:7 step:7236 [D loss: 0.238130, acc.: 52.34%] [G loss: 0.310396]\n",
      "epoch:7 step:7237 [D loss: 0.233376, acc.: 57.03%] [G loss: 0.323385]\n",
      "epoch:7 step:7238 [D loss: 0.230811, acc.: 60.94%] [G loss: 0.309732]\n",
      "epoch:7 step:7239 [D loss: 0.253154, acc.: 52.34%] [G loss: 0.287415]\n",
      "epoch:7 step:7240 [D loss: 0.249901, acc.: 50.78%] [G loss: 0.284051]\n",
      "epoch:7 step:7241 [D loss: 0.235188, acc.: 61.72%] [G loss: 0.271901]\n",
      "epoch:7 step:7242 [D loss: 0.241471, acc.: 55.47%] [G loss: 0.267345]\n",
      "epoch:7 step:7243 [D loss: 0.252695, acc.: 50.00%] [G loss: 0.286649]\n",
      "epoch:7 step:7244 [D loss: 0.225847, acc.: 61.72%] [G loss: 0.278591]\n",
      "epoch:7 step:7245 [D loss: 0.240533, acc.: 63.28%] [G loss: 0.294810]\n",
      "epoch:7 step:7246 [D loss: 0.247205, acc.: 53.91%] [G loss: 0.274059]\n",
      "epoch:7 step:7247 [D loss: 0.231163, acc.: 60.94%] [G loss: 0.288295]\n",
      "epoch:7 step:7248 [D loss: 0.231181, acc.: 62.50%] [G loss: 0.292406]\n",
      "epoch:7 step:7249 [D loss: 0.244648, acc.: 52.34%] [G loss: 0.262638]\n",
      "epoch:7 step:7250 [D loss: 0.235613, acc.: 57.03%] [G loss: 0.290072]\n",
      "epoch:7 step:7251 [D loss: 0.243929, acc.: 55.47%] [G loss: 0.293914]\n",
      "epoch:7 step:7252 [D loss: 0.246414, acc.: 56.25%] [G loss: 0.295589]\n",
      "epoch:7 step:7253 [D loss: 0.258518, acc.: 44.53%] [G loss: 0.275526]\n",
      "epoch:7 step:7254 [D loss: 0.228409, acc.: 60.94%] [G loss: 0.322631]\n",
      "epoch:7 step:7255 [D loss: 0.242674, acc.: 57.03%] [G loss: 0.298993]\n",
      "epoch:7 step:7256 [D loss: 0.231000, acc.: 62.50%] [G loss: 0.300318]\n",
      "epoch:7 step:7257 [D loss: 0.238783, acc.: 52.34%] [G loss: 0.309689]\n",
      "epoch:7 step:7258 [D loss: 0.245161, acc.: 57.03%] [G loss: 0.319661]\n",
      "epoch:7 step:7259 [D loss: 0.236794, acc.: 59.38%] [G loss: 0.289353]\n",
      "epoch:7 step:7260 [D loss: 0.219207, acc.: 67.97%] [G loss: 0.300276]\n",
      "epoch:7 step:7261 [D loss: 0.255858, acc.: 52.34%] [G loss: 0.277937]\n",
      "epoch:7 step:7262 [D loss: 0.241044, acc.: 55.47%] [G loss: 0.321006]\n",
      "epoch:7 step:7263 [D loss: 0.260848, acc.: 47.66%] [G loss: 0.277196]\n",
      "epoch:7 step:7264 [D loss: 0.244685, acc.: 55.47%] [G loss: 0.281237]\n",
      "epoch:7 step:7265 [D loss: 0.236453, acc.: 60.94%] [G loss: 0.299450]\n",
      "epoch:7 step:7266 [D loss: 0.241312, acc.: 55.47%] [G loss: 0.330896]\n",
      "epoch:7 step:7267 [D loss: 0.224204, acc.: 66.41%] [G loss: 0.341858]\n",
      "epoch:7 step:7268 [D loss: 0.233122, acc.: 60.16%] [G loss: 0.322726]\n",
      "epoch:7 step:7269 [D loss: 0.225947, acc.: 64.06%] [G loss: 0.297906]\n",
      "epoch:7 step:7270 [D loss: 0.222322, acc.: 65.62%] [G loss: 0.314974]\n",
      "epoch:7 step:7271 [D loss: 0.239609, acc.: 56.25%] [G loss: 0.292226]\n",
      "epoch:7 step:7272 [D loss: 0.247200, acc.: 50.00%] [G loss: 0.308604]\n",
      "epoch:7 step:7273 [D loss: 0.238832, acc.: 59.38%] [G loss: 0.306259]\n",
      "epoch:7 step:7274 [D loss: 0.228836, acc.: 62.50%] [G loss: 0.334537]\n",
      "epoch:7 step:7275 [D loss: 0.226248, acc.: 63.28%] [G loss: 0.300649]\n",
      "epoch:7 step:7276 [D loss: 0.230068, acc.: 56.25%] [G loss: 0.299271]\n",
      "epoch:7 step:7277 [D loss: 0.229355, acc.: 60.94%] [G loss: 0.312280]\n",
      "epoch:7 step:7278 [D loss: 0.232394, acc.: 60.94%] [G loss: 0.319764]\n",
      "epoch:7 step:7279 [D loss: 0.239509, acc.: 61.72%] [G loss: 0.320802]\n",
      "epoch:7 step:7280 [D loss: 0.234670, acc.: 60.94%] [G loss: 0.324520]\n",
      "epoch:7 step:7281 [D loss: 0.256836, acc.: 55.47%] [G loss: 0.313793]\n",
      "epoch:7 step:7282 [D loss: 0.255565, acc.: 53.91%] [G loss: 0.296953]\n",
      "epoch:7 step:7283 [D loss: 0.247812, acc.: 53.12%] [G loss: 0.302801]\n",
      "epoch:7 step:7284 [D loss: 0.233509, acc.: 58.59%] [G loss: 0.296948]\n",
      "epoch:7 step:7285 [D loss: 0.252055, acc.: 52.34%] [G loss: 0.328020]\n",
      "epoch:7 step:7286 [D loss: 0.239543, acc.: 54.69%] [G loss: 0.313132]\n",
      "epoch:7 step:7287 [D loss: 0.237138, acc.: 61.72%] [G loss: 0.347820]\n",
      "epoch:7 step:7288 [D loss: 0.219089, acc.: 66.41%] [G loss: 0.323596]\n",
      "epoch:7 step:7289 [D loss: 0.245293, acc.: 50.78%] [G loss: 0.310850]\n",
      "epoch:7 step:7290 [D loss: 0.231498, acc.: 60.94%] [G loss: 0.321693]\n",
      "epoch:7 step:7291 [D loss: 0.246426, acc.: 53.91%] [G loss: 0.309730]\n",
      "epoch:7 step:7292 [D loss: 0.245918, acc.: 54.69%] [G loss: 0.314838]\n",
      "epoch:7 step:7293 [D loss: 0.222237, acc.: 62.50%] [G loss: 0.320426]\n",
      "epoch:7 step:7294 [D loss: 0.251346, acc.: 53.91%] [G loss: 0.317972]\n",
      "epoch:7 step:7295 [D loss: 0.248279, acc.: 57.03%] [G loss: 0.299826]\n",
      "epoch:7 step:7296 [D loss: 0.248950, acc.: 54.69%] [G loss: 0.292917]\n",
      "epoch:7 step:7297 [D loss: 0.242625, acc.: 54.69%] [G loss: 0.313848]\n",
      "epoch:7 step:7298 [D loss: 0.238118, acc.: 60.94%] [G loss: 0.311992]\n",
      "epoch:7 step:7299 [D loss: 0.233701, acc.: 60.16%] [G loss: 0.287324]\n",
      "epoch:7 step:7300 [D loss: 0.223507, acc.: 64.84%] [G loss: 0.309936]\n",
      "epoch:7 step:7301 [D loss: 0.248925, acc.: 58.59%] [G loss: 0.271795]\n",
      "epoch:7 step:7302 [D loss: 0.234646, acc.: 61.72%] [G loss: 0.282271]\n",
      "epoch:7 step:7303 [D loss: 0.244604, acc.: 60.16%] [G loss: 0.276709]\n",
      "epoch:7 step:7304 [D loss: 0.236515, acc.: 60.94%] [G loss: 0.293919]\n",
      "epoch:7 step:7305 [D loss: 0.247156, acc.: 59.38%] [G loss: 0.303480]\n",
      "epoch:7 step:7306 [D loss: 0.241661, acc.: 57.03%] [G loss: 0.296646]\n",
      "epoch:7 step:7307 [D loss: 0.233114, acc.: 60.94%] [G loss: 0.290494]\n",
      "epoch:7 step:7308 [D loss: 0.237048, acc.: 56.25%] [G loss: 0.299805]\n",
      "epoch:7 step:7309 [D loss: 0.245582, acc.: 58.59%] [G loss: 0.299225]\n",
      "epoch:7 step:7310 [D loss: 0.235933, acc.: 63.28%] [G loss: 0.291688]\n",
      "epoch:7 step:7311 [D loss: 0.242667, acc.: 54.69%] [G loss: 0.281655]\n",
      "epoch:7 step:7312 [D loss: 0.228638, acc.: 70.31%] [G loss: 0.299647]\n",
      "epoch:7 step:7313 [D loss: 0.257408, acc.: 51.56%] [G loss: 0.284924]\n",
      "epoch:7 step:7314 [D loss: 0.247144, acc.: 58.59%] [G loss: 0.318969]\n",
      "epoch:7 step:7315 [D loss: 0.231434, acc.: 63.28%] [G loss: 0.304114]\n",
      "epoch:7 step:7316 [D loss: 0.224070, acc.: 64.06%] [G loss: 0.296936]\n",
      "epoch:7 step:7317 [D loss: 0.242260, acc.: 64.84%] [G loss: 0.299802]\n",
      "epoch:7 step:7318 [D loss: 0.253362, acc.: 53.91%] [G loss: 0.284199]\n",
      "epoch:7 step:7319 [D loss: 0.239942, acc.: 59.38%] [G loss: 0.274149]\n",
      "epoch:7 step:7320 [D loss: 0.246919, acc.: 50.78%] [G loss: 0.295366]\n",
      "epoch:7 step:7321 [D loss: 0.249087, acc.: 53.12%] [G loss: 0.285273]\n",
      "epoch:7 step:7322 [D loss: 0.245464, acc.: 51.56%] [G loss: 0.288748]\n",
      "epoch:7 step:7323 [D loss: 0.250467, acc.: 57.03%] [G loss: 0.299800]\n",
      "epoch:7 step:7324 [D loss: 0.235299, acc.: 57.81%] [G loss: 0.296909]\n",
      "epoch:7 step:7325 [D loss: 0.240343, acc.: 57.81%] [G loss: 0.295444]\n",
      "epoch:7 step:7326 [D loss: 0.232519, acc.: 58.59%] [G loss: 0.260963]\n",
      "epoch:7 step:7327 [D loss: 0.243092, acc.: 56.25%] [G loss: 0.320092]\n",
      "epoch:7 step:7328 [D loss: 0.244813, acc.: 54.69%] [G loss: 0.301125]\n",
      "epoch:7 step:7329 [D loss: 0.230540, acc.: 60.94%] [G loss: 0.272526]\n",
      "epoch:7 step:7330 [D loss: 0.257666, acc.: 50.00%] [G loss: 0.301565]\n",
      "epoch:7 step:7331 [D loss: 0.231165, acc.: 60.94%] [G loss: 0.294868]\n",
      "epoch:7 step:7332 [D loss: 0.254371, acc.: 54.69%] [G loss: 0.285928]\n",
      "epoch:7 step:7333 [D loss: 0.232321, acc.: 60.16%] [G loss: 0.288909]\n",
      "epoch:7 step:7334 [D loss: 0.235194, acc.: 60.94%] [G loss: 0.270921]\n",
      "epoch:7 step:7335 [D loss: 0.258251, acc.: 58.59%] [G loss: 0.293053]\n",
      "epoch:7 step:7336 [D loss: 0.245422, acc.: 52.34%] [G loss: 0.308097]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:7 step:7337 [D loss: 0.249072, acc.: 50.00%] [G loss: 0.329916]\n",
      "epoch:7 step:7338 [D loss: 0.256957, acc.: 53.91%] [G loss: 0.312705]\n",
      "epoch:7 step:7339 [D loss: 0.248072, acc.: 55.47%] [G loss: 0.300838]\n",
      "epoch:7 step:7340 [D loss: 0.244609, acc.: 54.69%] [G loss: 0.306552]\n",
      "epoch:7 step:7341 [D loss: 0.233932, acc.: 60.16%] [G loss: 0.305765]\n",
      "epoch:7 step:7342 [D loss: 0.249249, acc.: 56.25%] [G loss: 0.306824]\n",
      "epoch:7 step:7343 [D loss: 0.233077, acc.: 62.50%] [G loss: 0.279894]\n",
      "epoch:7 step:7344 [D loss: 0.259218, acc.: 53.12%] [G loss: 0.298672]\n",
      "epoch:7 step:7345 [D loss: 0.251618, acc.: 57.03%] [G loss: 0.280109]\n",
      "epoch:7 step:7346 [D loss: 0.230903, acc.: 58.59%] [G loss: 0.299120]\n",
      "epoch:7 step:7347 [D loss: 0.243968, acc.: 59.38%] [G loss: 0.293474]\n",
      "epoch:7 step:7348 [D loss: 0.231250, acc.: 60.94%] [G loss: 0.313889]\n",
      "epoch:7 step:7349 [D loss: 0.243831, acc.: 52.34%] [G loss: 0.279453]\n",
      "epoch:7 step:7350 [D loss: 0.237145, acc.: 57.81%] [G loss: 0.298319]\n",
      "epoch:7 step:7351 [D loss: 0.251393, acc.: 51.56%] [G loss: 0.308316]\n",
      "epoch:7 step:7352 [D loss: 0.245449, acc.: 55.47%] [G loss: 0.313163]\n",
      "epoch:7 step:7353 [D loss: 0.237527, acc.: 55.47%] [G loss: 0.308299]\n",
      "epoch:7 step:7354 [D loss: 0.231303, acc.: 58.59%] [G loss: 0.296680]\n",
      "epoch:7 step:7355 [D loss: 0.231690, acc.: 60.94%] [G loss: 0.330375]\n",
      "epoch:7 step:7356 [D loss: 0.237046, acc.: 59.38%] [G loss: 0.311698]\n",
      "epoch:7 step:7357 [D loss: 0.220594, acc.: 64.06%] [G loss: 0.294839]\n",
      "epoch:7 step:7358 [D loss: 0.245832, acc.: 57.81%] [G loss: 0.305888]\n",
      "epoch:7 step:7359 [D loss: 0.237338, acc.: 60.94%] [G loss: 0.284161]\n",
      "epoch:7 step:7360 [D loss: 0.230131, acc.: 66.41%] [G loss: 0.314571]\n",
      "epoch:7 step:7361 [D loss: 0.235122, acc.: 56.25%] [G loss: 0.319230]\n",
      "epoch:7 step:7362 [D loss: 0.245877, acc.: 55.47%] [G loss: 0.293753]\n",
      "epoch:7 step:7363 [D loss: 0.258012, acc.: 52.34%] [G loss: 0.287674]\n",
      "epoch:7 step:7364 [D loss: 0.245481, acc.: 54.69%] [G loss: 0.298641]\n",
      "epoch:7 step:7365 [D loss: 0.234389, acc.: 58.59%] [G loss: 0.297674]\n",
      "epoch:7 step:7366 [D loss: 0.249418, acc.: 50.00%] [G loss: 0.308987]\n",
      "epoch:7 step:7367 [D loss: 0.228247, acc.: 67.97%] [G loss: 0.298162]\n",
      "epoch:7 step:7368 [D loss: 0.234389, acc.: 62.50%] [G loss: 0.280790]\n",
      "epoch:7 step:7369 [D loss: 0.244978, acc.: 52.34%] [G loss: 0.318684]\n",
      "epoch:7 step:7370 [D loss: 0.232837, acc.: 59.38%] [G loss: 0.299656]\n",
      "epoch:7 step:7371 [D loss: 0.234658, acc.: 59.38%] [G loss: 0.286083]\n",
      "epoch:7 step:7372 [D loss: 0.239624, acc.: 54.69%] [G loss: 0.308945]\n",
      "epoch:7 step:7373 [D loss: 0.247386, acc.: 56.25%] [G loss: 0.289748]\n",
      "epoch:7 step:7374 [D loss: 0.245825, acc.: 53.91%] [G loss: 0.309668]\n",
      "epoch:7 step:7375 [D loss: 0.242728, acc.: 57.81%] [G loss: 0.286844]\n",
      "epoch:7 step:7376 [D loss: 0.245194, acc.: 53.12%] [G loss: 0.282214]\n",
      "epoch:7 step:7377 [D loss: 0.238680, acc.: 57.03%] [G loss: 0.291842]\n",
      "epoch:7 step:7378 [D loss: 0.257125, acc.: 50.78%] [G loss: 0.300285]\n",
      "epoch:7 step:7379 [D loss: 0.248978, acc.: 59.38%] [G loss: 0.310620]\n",
      "epoch:7 step:7380 [D loss: 0.236321, acc.: 61.72%] [G loss: 0.277134]\n",
      "epoch:7 step:7381 [D loss: 0.240093, acc.: 59.38%] [G loss: 0.290391]\n",
      "epoch:7 step:7382 [D loss: 0.237012, acc.: 58.59%] [G loss: 0.275615]\n",
      "epoch:7 step:7383 [D loss: 0.236364, acc.: 59.38%] [G loss: 0.300594]\n",
      "epoch:7 step:7384 [D loss: 0.238736, acc.: 63.28%] [G loss: 0.308185]\n",
      "epoch:7 step:7385 [D loss: 0.225892, acc.: 60.94%] [G loss: 0.298250]\n",
      "epoch:7 step:7386 [D loss: 0.246340, acc.: 55.47%] [G loss: 0.287942]\n",
      "epoch:7 step:7387 [D loss: 0.252370, acc.: 53.12%] [G loss: 0.321102]\n",
      "epoch:7 step:7388 [D loss: 0.249694, acc.: 60.16%] [G loss: 0.304736]\n",
      "epoch:7 step:7389 [D loss: 0.256086, acc.: 48.44%] [G loss: 0.289535]\n",
      "epoch:7 step:7390 [D loss: 0.254838, acc.: 55.47%] [G loss: 0.295305]\n",
      "epoch:7 step:7391 [D loss: 0.251861, acc.: 51.56%] [G loss: 0.297021]\n",
      "epoch:7 step:7392 [D loss: 0.240645, acc.: 57.81%] [G loss: 0.282049]\n",
      "epoch:7 step:7393 [D loss: 0.251916, acc.: 57.03%] [G loss: 0.270920]\n",
      "epoch:7 step:7394 [D loss: 0.256443, acc.: 53.91%] [G loss: 0.268174]\n",
      "epoch:7 step:7395 [D loss: 0.241886, acc.: 58.59%] [G loss: 0.311325]\n",
      "epoch:7 step:7396 [D loss: 0.246334, acc.: 56.25%] [G loss: 0.293649]\n",
      "epoch:7 step:7397 [D loss: 0.249570, acc.: 57.03%] [G loss: 0.304492]\n",
      "epoch:7 step:7398 [D loss: 0.238790, acc.: 55.47%] [G loss: 0.280637]\n",
      "epoch:7 step:7399 [D loss: 0.243087, acc.: 59.38%] [G loss: 0.309232]\n",
      "epoch:7 step:7400 [D loss: 0.249585, acc.: 53.91%] [G loss: 0.290402]\n",
      "epoch:7 step:7401 [D loss: 0.247595, acc.: 53.91%] [G loss: 0.309959]\n",
      "epoch:7 step:7402 [D loss: 0.247661, acc.: 58.59%] [G loss: 0.296916]\n",
      "epoch:7 step:7403 [D loss: 0.238386, acc.: 54.69%] [G loss: 0.274836]\n",
      "epoch:7 step:7404 [D loss: 0.252512, acc.: 49.22%] [G loss: 0.264901]\n",
      "epoch:7 step:7405 [D loss: 0.252574, acc.: 53.91%] [G loss: 0.293209]\n",
      "epoch:7 step:7406 [D loss: 0.252319, acc.: 53.91%] [G loss: 0.302053]\n",
      "epoch:7 step:7407 [D loss: 0.243550, acc.: 60.16%] [G loss: 0.289249]\n",
      "epoch:7 step:7408 [D loss: 0.252051, acc.: 50.00%] [G loss: 0.301929]\n",
      "epoch:7 step:7409 [D loss: 0.249375, acc.: 55.47%] [G loss: 0.292685]\n",
      "epoch:7 step:7410 [D loss: 0.250063, acc.: 53.12%] [G loss: 0.279125]\n",
      "epoch:7 step:7411 [D loss: 0.236950, acc.: 59.38%] [G loss: 0.257610]\n",
      "epoch:7 step:7412 [D loss: 0.229112, acc.: 63.28%] [G loss: 0.290027]\n",
      "epoch:7 step:7413 [D loss: 0.259900, acc.: 50.00%] [G loss: 0.297053]\n",
      "epoch:7 step:7414 [D loss: 0.264049, acc.: 49.22%] [G loss: 0.301103]\n",
      "epoch:7 step:7415 [D loss: 0.222225, acc.: 64.84%] [G loss: 0.316394]\n",
      "epoch:7 step:7416 [D loss: 0.241576, acc.: 55.47%] [G loss: 0.322874]\n",
      "epoch:7 step:7417 [D loss: 0.248449, acc.: 54.69%] [G loss: 0.290246]\n",
      "epoch:7 step:7418 [D loss: 0.236950, acc.: 59.38%] [G loss: 0.302299]\n",
      "epoch:7 step:7419 [D loss: 0.229022, acc.: 59.38%] [G loss: 0.304429]\n",
      "epoch:7 step:7420 [D loss: 0.247745, acc.: 54.69%] [G loss: 0.308366]\n",
      "epoch:7 step:7421 [D loss: 0.252978, acc.: 50.00%] [G loss: 0.298624]\n",
      "epoch:7 step:7422 [D loss: 0.245487, acc.: 53.91%] [G loss: 0.293179]\n",
      "epoch:7 step:7423 [D loss: 0.256863, acc.: 46.88%] [G loss: 0.284173]\n",
      "epoch:7 step:7424 [D loss: 0.236188, acc.: 59.38%] [G loss: 0.289568]\n",
      "epoch:7 step:7425 [D loss: 0.238165, acc.: 59.38%] [G loss: 0.302271]\n",
      "epoch:7 step:7426 [D loss: 0.242743, acc.: 57.81%] [G loss: 0.302779]\n",
      "epoch:7 step:7427 [D loss: 0.247788, acc.: 55.47%] [G loss: 0.280560]\n",
      "epoch:7 step:7428 [D loss: 0.243180, acc.: 54.69%] [G loss: 0.291146]\n",
      "epoch:7 step:7429 [D loss: 0.242969, acc.: 60.94%] [G loss: 0.334927]\n",
      "epoch:7 step:7430 [D loss: 0.241481, acc.: 57.03%] [G loss: 0.327559]\n",
      "epoch:7 step:7431 [D loss: 0.260825, acc.: 50.00%] [G loss: 0.310499]\n",
      "epoch:7 step:7432 [D loss: 0.238896, acc.: 56.25%] [G loss: 0.323284]\n",
      "epoch:7 step:7433 [D loss: 0.256432, acc.: 50.78%] [G loss: 0.311969]\n",
      "epoch:7 step:7434 [D loss: 0.237295, acc.: 60.16%] [G loss: 0.329420]\n",
      "epoch:7 step:7435 [D loss: 0.252154, acc.: 55.47%] [G loss: 0.305131]\n",
      "epoch:7 step:7436 [D loss: 0.237565, acc.: 57.81%] [G loss: 0.308034]\n",
      "epoch:7 step:7437 [D loss: 0.245819, acc.: 60.94%] [G loss: 0.313962]\n",
      "epoch:7 step:7438 [D loss: 0.244524, acc.: 62.50%] [G loss: 0.317146]\n",
      "epoch:7 step:7439 [D loss: 0.232991, acc.: 60.16%] [G loss: 0.305051]\n",
      "epoch:7 step:7440 [D loss: 0.250972, acc.: 57.81%] [G loss: 0.297796]\n",
      "epoch:7 step:7441 [D loss: 0.228987, acc.: 65.62%] [G loss: 0.291593]\n",
      "epoch:7 step:7442 [D loss: 0.240349, acc.: 59.38%] [G loss: 0.305267]\n",
      "epoch:7 step:7443 [D loss: 0.220500, acc.: 59.38%] [G loss: 0.321580]\n",
      "epoch:7 step:7444 [D loss: 0.246151, acc.: 54.69%] [G loss: 0.262987]\n",
      "epoch:7 step:7445 [D loss: 0.241997, acc.: 57.81%] [G loss: 0.288838]\n",
      "epoch:7 step:7446 [D loss: 0.243060, acc.: 55.47%] [G loss: 0.307011]\n",
      "epoch:7 step:7447 [D loss: 0.239974, acc.: 59.38%] [G loss: 0.305628]\n",
      "epoch:7 step:7448 [D loss: 0.247634, acc.: 57.03%] [G loss: 0.298592]\n",
      "epoch:7 step:7449 [D loss: 0.245360, acc.: 60.16%] [G loss: 0.309761]\n",
      "epoch:7 step:7450 [D loss: 0.248520, acc.: 56.25%] [G loss: 0.308463]\n",
      "epoch:7 step:7451 [D loss: 0.252931, acc.: 53.91%] [G loss: 0.297138]\n",
      "epoch:7 step:7452 [D loss: 0.260451, acc.: 51.56%] [G loss: 0.285648]\n",
      "epoch:7 step:7453 [D loss: 0.256337, acc.: 50.00%] [G loss: 0.301327]\n",
      "epoch:7 step:7454 [D loss: 0.245380, acc.: 57.81%] [G loss: 0.282408]\n",
      "epoch:7 step:7455 [D loss: 0.238096, acc.: 57.81%] [G loss: 0.305885]\n",
      "epoch:7 step:7456 [D loss: 0.236954, acc.: 56.25%] [G loss: 0.295293]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:7 step:7457 [D loss: 0.240621, acc.: 54.69%] [G loss: 0.307993]\n",
      "epoch:7 step:7458 [D loss: 0.220644, acc.: 68.75%] [G loss: 0.301844]\n",
      "epoch:7 step:7459 [D loss: 0.252118, acc.: 49.22%] [G loss: 0.292611]\n",
      "epoch:7 step:7460 [D loss: 0.260766, acc.: 49.22%] [G loss: 0.276225]\n",
      "epoch:7 step:7461 [D loss: 0.234934, acc.: 60.16%] [G loss: 0.292406]\n",
      "epoch:7 step:7462 [D loss: 0.227547, acc.: 64.84%] [G loss: 0.279320]\n",
      "epoch:7 step:7463 [D loss: 0.239059, acc.: 60.16%] [G loss: 0.298303]\n",
      "epoch:7 step:7464 [D loss: 0.245745, acc.: 53.12%] [G loss: 0.272924]\n",
      "epoch:7 step:7465 [D loss: 0.233641, acc.: 62.50%] [G loss: 0.299570]\n",
      "epoch:7 step:7466 [D loss: 0.247434, acc.: 52.34%] [G loss: 0.301714]\n",
      "epoch:7 step:7467 [D loss: 0.236890, acc.: 64.06%] [G loss: 0.300580]\n",
      "epoch:7 step:7468 [D loss: 0.248043, acc.: 55.47%] [G loss: 0.311166]\n",
      "epoch:7 step:7469 [D loss: 0.247513, acc.: 52.34%] [G loss: 0.309612]\n",
      "epoch:7 step:7470 [D loss: 0.243165, acc.: 56.25%] [G loss: 0.295958]\n",
      "epoch:7 step:7471 [D loss: 0.249085, acc.: 57.03%] [G loss: 0.307864]\n",
      "epoch:7 step:7472 [D loss: 0.233223, acc.: 59.38%] [G loss: 0.329368]\n",
      "epoch:7 step:7473 [D loss: 0.252464, acc.: 55.47%] [G loss: 0.281639]\n",
      "epoch:7 step:7474 [D loss: 0.272647, acc.: 50.78%] [G loss: 0.281586]\n",
      "epoch:7 step:7475 [D loss: 0.241399, acc.: 57.03%] [G loss: 0.300139]\n",
      "epoch:7 step:7476 [D loss: 0.245722, acc.: 55.47%] [G loss: 0.296796]\n",
      "epoch:7 step:7477 [D loss: 0.244641, acc.: 59.38%] [G loss: 0.304214]\n",
      "epoch:7 step:7478 [D loss: 0.229610, acc.: 62.50%] [G loss: 0.304160]\n",
      "epoch:7 step:7479 [D loss: 0.230497, acc.: 60.16%] [G loss: 0.305939]\n",
      "epoch:7 step:7480 [D loss: 0.247601, acc.: 54.69%] [G loss: 0.298369]\n",
      "epoch:7 step:7481 [D loss: 0.234530, acc.: 57.81%] [G loss: 0.309192]\n",
      "epoch:7 step:7482 [D loss: 0.253408, acc.: 52.34%] [G loss: 0.278357]\n",
      "epoch:7 step:7483 [D loss: 0.225613, acc.: 58.59%] [G loss: 0.297578]\n",
      "epoch:7 step:7484 [D loss: 0.245959, acc.: 60.94%] [G loss: 0.296369]\n",
      "epoch:7 step:7485 [D loss: 0.238167, acc.: 60.94%] [G loss: 0.313590]\n",
      "epoch:7 step:7486 [D loss: 0.245853, acc.: 56.25%] [G loss: 0.282093]\n",
      "epoch:7 step:7487 [D loss: 0.221143, acc.: 67.19%] [G loss: 0.305629]\n",
      "epoch:7 step:7488 [D loss: 0.228484, acc.: 63.28%] [G loss: 0.317807]\n",
      "epoch:7 step:7489 [D loss: 0.247673, acc.: 49.22%] [G loss: 0.289995]\n",
      "epoch:7 step:7490 [D loss: 0.229746, acc.: 62.50%] [G loss: 0.263247]\n",
      "epoch:7 step:7491 [D loss: 0.239937, acc.: 62.50%] [G loss: 0.305454]\n",
      "epoch:7 step:7492 [D loss: 0.230469, acc.: 60.94%] [G loss: 0.314772]\n",
      "epoch:7 step:7493 [D loss: 0.241497, acc.: 54.69%] [G loss: 0.294474]\n",
      "epoch:7 step:7494 [D loss: 0.243465, acc.: 57.03%] [G loss: 0.312128]\n",
      "epoch:7 step:7495 [D loss: 0.241807, acc.: 56.25%] [G loss: 0.285136]\n",
      "epoch:7 step:7496 [D loss: 0.233074, acc.: 59.38%] [G loss: 0.311022]\n",
      "epoch:8 step:7497 [D loss: 0.219743, acc.: 68.75%] [G loss: 0.272819]\n",
      "epoch:8 step:7498 [D loss: 0.248807, acc.: 55.47%] [G loss: 0.280141]\n",
      "epoch:8 step:7499 [D loss: 0.226521, acc.: 64.84%] [G loss: 0.308674]\n",
      "epoch:8 step:7500 [D loss: 0.249905, acc.: 53.91%] [G loss: 0.289452]\n",
      "epoch:8 step:7501 [D loss: 0.246897, acc.: 55.47%] [G loss: 0.304546]\n",
      "epoch:8 step:7502 [D loss: 0.255235, acc.: 49.22%] [G loss: 0.277859]\n",
      "epoch:8 step:7503 [D loss: 0.248137, acc.: 56.25%] [G loss: 0.294020]\n",
      "epoch:8 step:7504 [D loss: 0.242659, acc.: 54.69%] [G loss: 0.303419]\n",
      "epoch:8 step:7505 [D loss: 0.241362, acc.: 56.25%] [G loss: 0.299974]\n",
      "epoch:8 step:7506 [D loss: 0.246505, acc.: 57.03%] [G loss: 0.266333]\n",
      "epoch:8 step:7507 [D loss: 0.230813, acc.: 60.16%] [G loss: 0.302782]\n",
      "epoch:8 step:7508 [D loss: 0.227228, acc.: 61.72%] [G loss: 0.285432]\n",
      "epoch:8 step:7509 [D loss: 0.240515, acc.: 53.91%] [G loss: 0.277998]\n",
      "epoch:8 step:7510 [D loss: 0.240746, acc.: 63.28%] [G loss: 0.302669]\n",
      "epoch:8 step:7511 [D loss: 0.239463, acc.: 56.25%] [G loss: 0.291059]\n",
      "epoch:8 step:7512 [D loss: 0.243580, acc.: 57.03%] [G loss: 0.306561]\n",
      "epoch:8 step:7513 [D loss: 0.253779, acc.: 54.69%] [G loss: 0.293482]\n",
      "epoch:8 step:7514 [D loss: 0.245205, acc.: 52.34%] [G loss: 0.302193]\n",
      "epoch:8 step:7515 [D loss: 0.247280, acc.: 57.03%] [G loss: 0.326695]\n",
      "epoch:8 step:7516 [D loss: 0.235384, acc.: 61.72%] [G loss: 0.316958]\n",
      "epoch:8 step:7517 [D loss: 0.221625, acc.: 66.41%] [G loss: 0.311477]\n",
      "epoch:8 step:7518 [D loss: 0.250871, acc.: 53.12%] [G loss: 0.298472]\n",
      "epoch:8 step:7519 [D loss: 0.226475, acc.: 65.62%] [G loss: 0.324791]\n",
      "epoch:8 step:7520 [D loss: 0.230281, acc.: 61.72%] [G loss: 0.294059]\n",
      "epoch:8 step:7521 [D loss: 0.252083, acc.: 50.78%] [G loss: 0.283991]\n",
      "epoch:8 step:7522 [D loss: 0.268266, acc.: 46.88%] [G loss: 0.292931]\n",
      "epoch:8 step:7523 [D loss: 0.233805, acc.: 60.16%] [G loss: 0.307149]\n",
      "epoch:8 step:7524 [D loss: 0.248872, acc.: 52.34%] [G loss: 0.308510]\n",
      "epoch:8 step:7525 [D loss: 0.243428, acc.: 55.47%] [G loss: 0.304638]\n",
      "epoch:8 step:7526 [D loss: 0.252503, acc.: 57.03%] [G loss: 0.289525]\n",
      "epoch:8 step:7527 [D loss: 0.255594, acc.: 53.12%] [G loss: 0.295698]\n",
      "epoch:8 step:7528 [D loss: 0.238107, acc.: 60.16%] [G loss: 0.294603]\n",
      "epoch:8 step:7529 [D loss: 0.247365, acc.: 53.12%] [G loss: 0.317077]\n",
      "epoch:8 step:7530 [D loss: 0.255754, acc.: 50.78%] [G loss: 0.264575]\n",
      "epoch:8 step:7531 [D loss: 0.236626, acc.: 58.59%] [G loss: 0.301773]\n",
      "epoch:8 step:7532 [D loss: 0.237547, acc.: 60.16%] [G loss: 0.304415]\n",
      "epoch:8 step:7533 [D loss: 0.227766, acc.: 65.62%] [G loss: 0.306299]\n",
      "epoch:8 step:7534 [D loss: 0.247435, acc.: 56.25%] [G loss: 0.295354]\n",
      "epoch:8 step:7535 [D loss: 0.235382, acc.: 64.06%] [G loss: 0.279148]\n",
      "epoch:8 step:7536 [D loss: 0.240028, acc.: 60.94%] [G loss: 0.312674]\n",
      "epoch:8 step:7537 [D loss: 0.231811, acc.: 62.50%] [G loss: 0.303518]\n",
      "epoch:8 step:7538 [D loss: 0.239652, acc.: 53.91%] [G loss: 0.262579]\n",
      "epoch:8 step:7539 [D loss: 0.240336, acc.: 54.69%] [G loss: 0.275233]\n",
      "epoch:8 step:7540 [D loss: 0.220334, acc.: 64.84%] [G loss: 0.340618]\n",
      "epoch:8 step:7541 [D loss: 0.251325, acc.: 53.12%] [G loss: 0.276644]\n",
      "epoch:8 step:7542 [D loss: 0.253294, acc.: 50.00%] [G loss: 0.331059]\n",
      "epoch:8 step:7543 [D loss: 0.240926, acc.: 57.03%] [G loss: 0.322722]\n",
      "epoch:8 step:7544 [D loss: 0.232490, acc.: 57.81%] [G loss: 0.290871]\n",
      "epoch:8 step:7545 [D loss: 0.234649, acc.: 60.94%] [G loss: 0.291718]\n",
      "epoch:8 step:7546 [D loss: 0.236437, acc.: 57.03%] [G loss: 0.295586]\n",
      "epoch:8 step:7547 [D loss: 0.250137, acc.: 52.34%] [G loss: 0.288616]\n",
      "epoch:8 step:7548 [D loss: 0.232000, acc.: 58.59%] [G loss: 0.281844]\n",
      "epoch:8 step:7549 [D loss: 0.241022, acc.: 56.25%] [G loss: 0.301194]\n",
      "epoch:8 step:7550 [D loss: 0.222430, acc.: 66.41%] [G loss: 0.304744]\n",
      "epoch:8 step:7551 [D loss: 0.255355, acc.: 57.03%] [G loss: 0.316510]\n",
      "epoch:8 step:7552 [D loss: 0.245325, acc.: 54.69%] [G loss: 0.310118]\n",
      "epoch:8 step:7553 [D loss: 0.236954, acc.: 61.72%] [G loss: 0.268852]\n",
      "epoch:8 step:7554 [D loss: 0.249084, acc.: 53.91%] [G loss: 0.310564]\n",
      "epoch:8 step:7555 [D loss: 0.246495, acc.: 59.38%] [G loss: 0.269882]\n",
      "epoch:8 step:7556 [D loss: 0.225027, acc.: 67.19%] [G loss: 0.310881]\n",
      "epoch:8 step:7557 [D loss: 0.257469, acc.: 48.44%] [G loss: 0.298313]\n",
      "epoch:8 step:7558 [D loss: 0.223016, acc.: 64.06%] [G loss: 0.320398]\n",
      "epoch:8 step:7559 [D loss: 0.233478, acc.: 59.38%] [G loss: 0.305846]\n",
      "epoch:8 step:7560 [D loss: 0.253363, acc.: 53.12%] [G loss: 0.318266]\n",
      "epoch:8 step:7561 [D loss: 0.238599, acc.: 59.38%] [G loss: 0.309655]\n",
      "epoch:8 step:7562 [D loss: 0.251068, acc.: 53.12%] [G loss: 0.302283]\n",
      "epoch:8 step:7563 [D loss: 0.236941, acc.: 59.38%] [G loss: 0.304014]\n",
      "epoch:8 step:7564 [D loss: 0.238391, acc.: 58.59%] [G loss: 0.309161]\n",
      "epoch:8 step:7565 [D loss: 0.236120, acc.: 60.94%] [G loss: 0.300754]\n",
      "epoch:8 step:7566 [D loss: 0.240257, acc.: 54.69%] [G loss: 0.320589]\n",
      "epoch:8 step:7567 [D loss: 0.261847, acc.: 53.12%] [G loss: 0.310050]\n",
      "epoch:8 step:7568 [D loss: 0.247810, acc.: 52.34%] [G loss: 0.295443]\n",
      "epoch:8 step:7569 [D loss: 0.221158, acc.: 63.28%] [G loss: 0.309054]\n",
      "epoch:8 step:7570 [D loss: 0.256717, acc.: 53.12%] [G loss: 0.312405]\n",
      "epoch:8 step:7571 [D loss: 0.228535, acc.: 61.72%] [G loss: 0.290022]\n",
      "epoch:8 step:7572 [D loss: 0.234758, acc.: 60.16%] [G loss: 0.332564]\n",
      "epoch:8 step:7573 [D loss: 0.243643, acc.: 52.34%] [G loss: 0.309106]\n",
      "epoch:8 step:7574 [D loss: 0.238373, acc.: 58.59%] [G loss: 0.315338]\n",
      "epoch:8 step:7575 [D loss: 0.238666, acc.: 59.38%] [G loss: 0.300901]\n",
      "epoch:8 step:7576 [D loss: 0.227893, acc.: 63.28%] [G loss: 0.306864]\n",
      "epoch:8 step:7577 [D loss: 0.263782, acc.: 46.88%] [G loss: 0.282408]\n",
      "epoch:8 step:7578 [D loss: 0.231172, acc.: 60.94%] [G loss: 0.275309]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:8 step:7579 [D loss: 0.259101, acc.: 50.78%] [G loss: 0.283133]\n",
      "epoch:8 step:7580 [D loss: 0.237746, acc.: 61.72%] [G loss: 0.286123]\n",
      "epoch:8 step:7581 [D loss: 0.233824, acc.: 60.94%] [G loss: 0.299709]\n",
      "epoch:8 step:7582 [D loss: 0.275823, acc.: 50.78%] [G loss: 0.287207]\n",
      "epoch:8 step:7583 [D loss: 0.223642, acc.: 63.28%] [G loss: 0.285628]\n",
      "epoch:8 step:7584 [D loss: 0.224982, acc.: 67.97%] [G loss: 0.293791]\n",
      "epoch:8 step:7585 [D loss: 0.256335, acc.: 53.91%] [G loss: 0.263196]\n",
      "epoch:8 step:7586 [D loss: 0.238032, acc.: 53.91%] [G loss: 0.310576]\n",
      "epoch:8 step:7587 [D loss: 0.237367, acc.: 57.03%] [G loss: 0.291395]\n",
      "epoch:8 step:7588 [D loss: 0.237536, acc.: 60.94%] [G loss: 0.305047]\n",
      "epoch:8 step:7589 [D loss: 0.242304, acc.: 60.94%] [G loss: 0.323883]\n",
      "epoch:8 step:7590 [D loss: 0.252348, acc.: 54.69%] [G loss: 0.304041]\n",
      "epoch:8 step:7591 [D loss: 0.227929, acc.: 60.94%] [G loss: 0.274056]\n",
      "epoch:8 step:7592 [D loss: 0.245488, acc.: 58.59%] [G loss: 0.306560]\n",
      "epoch:8 step:7593 [D loss: 0.250126, acc.: 53.12%] [G loss: 0.320131]\n",
      "epoch:8 step:7594 [D loss: 0.258802, acc.: 49.22%] [G loss: 0.303009]\n",
      "epoch:8 step:7595 [D loss: 0.236167, acc.: 57.81%] [G loss: 0.284485]\n",
      "epoch:8 step:7596 [D loss: 0.243556, acc.: 60.16%] [G loss: 0.298013]\n",
      "epoch:8 step:7597 [D loss: 0.240869, acc.: 56.25%] [G loss: 0.300690]\n",
      "epoch:8 step:7598 [D loss: 0.242783, acc.: 56.25%] [G loss: 0.321586]\n",
      "epoch:8 step:7599 [D loss: 0.246251, acc.: 50.78%] [G loss: 0.336207]\n",
      "epoch:8 step:7600 [D loss: 0.257455, acc.: 52.34%] [G loss: 0.317422]\n",
      "epoch:8 step:7601 [D loss: 0.246358, acc.: 53.12%] [G loss: 0.289227]\n",
      "epoch:8 step:7602 [D loss: 0.237035, acc.: 60.94%] [G loss: 0.283896]\n",
      "epoch:8 step:7603 [D loss: 0.236184, acc.: 63.28%] [G loss: 0.300593]\n",
      "epoch:8 step:7604 [D loss: 0.241105, acc.: 58.59%] [G loss: 0.321847]\n",
      "epoch:8 step:7605 [D loss: 0.229612, acc.: 59.38%] [G loss: 0.307050]\n",
      "epoch:8 step:7606 [D loss: 0.263885, acc.: 46.09%] [G loss: 0.284267]\n",
      "epoch:8 step:7607 [D loss: 0.243534, acc.: 60.16%] [G loss: 0.310556]\n",
      "epoch:8 step:7608 [D loss: 0.243112, acc.: 57.03%] [G loss: 0.283728]\n",
      "epoch:8 step:7609 [D loss: 0.237377, acc.: 60.16%] [G loss: 0.288632]\n",
      "epoch:8 step:7610 [D loss: 0.235654, acc.: 64.06%] [G loss: 0.296356]\n",
      "epoch:8 step:7611 [D loss: 0.261016, acc.: 50.00%] [G loss: 0.296550]\n",
      "epoch:8 step:7612 [D loss: 0.248377, acc.: 56.25%] [G loss: 0.311125]\n",
      "epoch:8 step:7613 [D loss: 0.250869, acc.: 53.12%] [G loss: 0.307605]\n",
      "epoch:8 step:7614 [D loss: 0.237506, acc.: 59.38%] [G loss: 0.269729]\n",
      "epoch:8 step:7615 [D loss: 0.240870, acc.: 53.91%] [G loss: 0.275405]\n",
      "epoch:8 step:7616 [D loss: 0.246948, acc.: 49.22%] [G loss: 0.293916]\n",
      "epoch:8 step:7617 [D loss: 0.243362, acc.: 54.69%] [G loss: 0.300487]\n",
      "epoch:8 step:7618 [D loss: 0.240504, acc.: 54.69%] [G loss: 0.276564]\n",
      "epoch:8 step:7619 [D loss: 0.258163, acc.: 53.12%] [G loss: 0.290373]\n",
      "epoch:8 step:7620 [D loss: 0.238058, acc.: 59.38%] [G loss: 0.277562]\n",
      "epoch:8 step:7621 [D loss: 0.234406, acc.: 63.28%] [G loss: 0.298577]\n",
      "epoch:8 step:7622 [D loss: 0.229655, acc.: 62.50%] [G loss: 0.285848]\n",
      "epoch:8 step:7623 [D loss: 0.239593, acc.: 60.16%] [G loss: 0.295712]\n",
      "epoch:8 step:7624 [D loss: 0.247719, acc.: 57.03%] [G loss: 0.300868]\n",
      "epoch:8 step:7625 [D loss: 0.238933, acc.: 58.59%] [G loss: 0.284016]\n",
      "epoch:8 step:7626 [D loss: 0.244637, acc.: 57.03%] [G loss: 0.272728]\n",
      "epoch:8 step:7627 [D loss: 0.245913, acc.: 59.38%] [G loss: 0.297268]\n",
      "epoch:8 step:7628 [D loss: 0.244797, acc.: 56.25%] [G loss: 0.264121]\n",
      "epoch:8 step:7629 [D loss: 0.247572, acc.: 55.47%] [G loss: 0.269758]\n",
      "epoch:8 step:7630 [D loss: 0.239686, acc.: 61.72%] [G loss: 0.292108]\n",
      "epoch:8 step:7631 [D loss: 0.243706, acc.: 60.16%] [G loss: 0.281578]\n",
      "epoch:8 step:7632 [D loss: 0.230963, acc.: 60.94%] [G loss: 0.299503]\n",
      "epoch:8 step:7633 [D loss: 0.257809, acc.: 50.00%] [G loss: 0.293052]\n",
      "epoch:8 step:7634 [D loss: 0.246167, acc.: 53.91%] [G loss: 0.283439]\n",
      "epoch:8 step:7635 [D loss: 0.246303, acc.: 58.59%] [G loss: 0.277636]\n",
      "epoch:8 step:7636 [D loss: 0.244626, acc.: 50.78%] [G loss: 0.305060]\n",
      "epoch:8 step:7637 [D loss: 0.253427, acc.: 53.91%] [G loss: 0.309799]\n",
      "epoch:8 step:7638 [D loss: 0.225607, acc.: 63.28%] [G loss: 0.299071]\n",
      "epoch:8 step:7639 [D loss: 0.242649, acc.: 59.38%] [G loss: 0.315460]\n",
      "epoch:8 step:7640 [D loss: 0.241062, acc.: 58.59%] [G loss: 0.321446]\n",
      "epoch:8 step:7641 [D loss: 0.245166, acc.: 53.12%] [G loss: 0.311740]\n",
      "epoch:8 step:7642 [D loss: 0.231390, acc.: 64.06%] [G loss: 0.326464]\n",
      "epoch:8 step:7643 [D loss: 0.227005, acc.: 67.19%] [G loss: 0.298401]\n",
      "epoch:8 step:7644 [D loss: 0.233875, acc.: 62.50%] [G loss: 0.304134]\n",
      "epoch:8 step:7645 [D loss: 0.248867, acc.: 54.69%] [G loss: 0.289492]\n",
      "epoch:8 step:7646 [D loss: 0.251827, acc.: 47.66%] [G loss: 0.287431]\n",
      "epoch:8 step:7647 [D loss: 0.251031, acc.: 57.81%] [G loss: 0.300271]\n",
      "epoch:8 step:7648 [D loss: 0.235925, acc.: 57.03%] [G loss: 0.289260]\n",
      "epoch:8 step:7649 [D loss: 0.239264, acc.: 58.59%] [G loss: 0.312276]\n",
      "epoch:8 step:7650 [D loss: 0.244052, acc.: 53.91%] [G loss: 0.298364]\n",
      "epoch:8 step:7651 [D loss: 0.238572, acc.: 57.81%] [G loss: 0.289106]\n",
      "epoch:8 step:7652 [D loss: 0.233263, acc.: 59.38%] [G loss: 0.278697]\n",
      "epoch:8 step:7653 [D loss: 0.234866, acc.: 64.84%] [G loss: 0.300176]\n",
      "epoch:8 step:7654 [D loss: 0.246156, acc.: 55.47%] [G loss: 0.284707]\n",
      "epoch:8 step:7655 [D loss: 0.236274, acc.: 54.69%] [G loss: 0.290340]\n",
      "epoch:8 step:7656 [D loss: 0.253554, acc.: 52.34%] [G loss: 0.299580]\n",
      "epoch:8 step:7657 [D loss: 0.241058, acc.: 61.72%] [G loss: 0.287901]\n",
      "epoch:8 step:7658 [D loss: 0.237653, acc.: 57.03%] [G loss: 0.328548]\n",
      "epoch:8 step:7659 [D loss: 0.235238, acc.: 66.41%] [G loss: 0.315280]\n",
      "epoch:8 step:7660 [D loss: 0.244330, acc.: 57.81%] [G loss: 0.292077]\n",
      "epoch:8 step:7661 [D loss: 0.247666, acc.: 54.69%] [G loss: 0.300190]\n",
      "epoch:8 step:7662 [D loss: 0.255982, acc.: 55.47%] [G loss: 0.278611]\n",
      "epoch:8 step:7663 [D loss: 0.246357, acc.: 55.47%] [G loss: 0.280281]\n",
      "epoch:8 step:7664 [D loss: 0.246323, acc.: 54.69%] [G loss: 0.291673]\n",
      "epoch:8 step:7665 [D loss: 0.235719, acc.: 55.47%] [G loss: 0.308686]\n",
      "epoch:8 step:7666 [D loss: 0.236355, acc.: 56.25%] [G loss: 0.299129]\n",
      "epoch:8 step:7667 [D loss: 0.253405, acc.: 52.34%] [G loss: 0.301326]\n",
      "epoch:8 step:7668 [D loss: 0.223586, acc.: 67.97%] [G loss: 0.329351]\n",
      "epoch:8 step:7669 [D loss: 0.222411, acc.: 65.62%] [G loss: 0.286283]\n",
      "epoch:8 step:7670 [D loss: 0.257826, acc.: 51.56%] [G loss: 0.299256]\n",
      "epoch:8 step:7671 [D loss: 0.242163, acc.: 56.25%] [G loss: 0.314100]\n",
      "epoch:8 step:7672 [D loss: 0.226814, acc.: 60.94%] [G loss: 0.310063]\n",
      "epoch:8 step:7673 [D loss: 0.232015, acc.: 62.50%] [G loss: 0.292904]\n",
      "epoch:8 step:7674 [D loss: 0.247997, acc.: 54.69%] [G loss: 0.302346]\n",
      "epoch:8 step:7675 [D loss: 0.238847, acc.: 57.81%] [G loss: 0.312520]\n",
      "epoch:8 step:7676 [D loss: 0.225248, acc.: 61.72%] [G loss: 0.301997]\n",
      "epoch:8 step:7677 [D loss: 0.264630, acc.: 46.88%] [G loss: 0.301491]\n",
      "epoch:8 step:7678 [D loss: 0.244839, acc.: 52.34%] [G loss: 0.292807]\n",
      "epoch:8 step:7679 [D loss: 0.243981, acc.: 53.91%] [G loss: 0.288953]\n",
      "epoch:8 step:7680 [D loss: 0.253171, acc.: 57.03%] [G loss: 0.292238]\n",
      "epoch:8 step:7681 [D loss: 0.237548, acc.: 56.25%] [G loss: 0.279579]\n",
      "epoch:8 step:7682 [D loss: 0.226838, acc.: 65.62%] [G loss: 0.308839]\n",
      "epoch:8 step:7683 [D loss: 0.221751, acc.: 67.19%] [G loss: 0.312540]\n",
      "epoch:8 step:7684 [D loss: 0.248260, acc.: 55.47%] [G loss: 0.295483]\n",
      "epoch:8 step:7685 [D loss: 0.232150, acc.: 57.81%] [G loss: 0.298077]\n",
      "epoch:8 step:7686 [D loss: 0.246967, acc.: 55.47%] [G loss: 0.290310]\n",
      "epoch:8 step:7687 [D loss: 0.238719, acc.: 58.59%] [G loss: 0.289930]\n",
      "epoch:8 step:7688 [D loss: 0.246676, acc.: 53.12%] [G loss: 0.315628]\n",
      "epoch:8 step:7689 [D loss: 0.235288, acc.: 57.03%] [G loss: 0.304545]\n",
      "epoch:8 step:7690 [D loss: 0.239160, acc.: 61.72%] [G loss: 0.319034]\n",
      "epoch:8 step:7691 [D loss: 0.234154, acc.: 61.72%] [G loss: 0.303017]\n",
      "epoch:8 step:7692 [D loss: 0.246463, acc.: 55.47%] [G loss: 0.293530]\n",
      "epoch:8 step:7693 [D loss: 0.248917, acc.: 53.12%] [G loss: 0.276241]\n",
      "epoch:8 step:7694 [D loss: 0.250196, acc.: 50.78%] [G loss: 0.301895]\n",
      "epoch:8 step:7695 [D loss: 0.248385, acc.: 59.38%] [G loss: 0.295371]\n",
      "epoch:8 step:7696 [D loss: 0.257675, acc.: 46.09%] [G loss: 0.278455]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:8 step:7697 [D loss: 0.249993, acc.: 55.47%] [G loss: 0.286231]\n",
      "epoch:8 step:7698 [D loss: 0.221788, acc.: 57.81%] [G loss: 0.305249]\n",
      "epoch:8 step:7699 [D loss: 0.252242, acc.: 55.47%] [G loss: 0.256197]\n",
      "epoch:8 step:7700 [D loss: 0.226287, acc.: 67.19%] [G loss: 0.296995]\n",
      "epoch:8 step:7701 [D loss: 0.247256, acc.: 57.03%] [G loss: 0.290269]\n",
      "epoch:8 step:7702 [D loss: 0.248720, acc.: 46.88%] [G loss: 0.308279]\n",
      "epoch:8 step:7703 [D loss: 0.231775, acc.: 63.28%] [G loss: 0.326025]\n",
      "epoch:8 step:7704 [D loss: 0.247831, acc.: 55.47%] [G loss: 0.308912]\n",
      "epoch:8 step:7705 [D loss: 0.241928, acc.: 57.03%] [G loss: 0.314024]\n",
      "epoch:8 step:7706 [D loss: 0.235629, acc.: 62.50%] [G loss: 0.303037]\n",
      "epoch:8 step:7707 [D loss: 0.244604, acc.: 56.25%] [G loss: 0.302991]\n",
      "epoch:8 step:7708 [D loss: 0.248514, acc.: 60.16%] [G loss: 0.302252]\n",
      "epoch:8 step:7709 [D loss: 0.247511, acc.: 55.47%] [G loss: 0.293672]\n",
      "epoch:8 step:7710 [D loss: 0.247634, acc.: 57.03%] [G loss: 0.317383]\n",
      "epoch:8 step:7711 [D loss: 0.248828, acc.: 58.59%] [G loss: 0.294496]\n",
      "epoch:8 step:7712 [D loss: 0.245405, acc.: 53.91%] [G loss: 0.315269]\n",
      "epoch:8 step:7713 [D loss: 0.237520, acc.: 57.03%] [G loss: 0.276777]\n",
      "epoch:8 step:7714 [D loss: 0.234869, acc.: 60.94%] [G loss: 0.329569]\n",
      "epoch:8 step:7715 [D loss: 0.239040, acc.: 61.72%] [G loss: 0.283440]\n",
      "epoch:8 step:7716 [D loss: 0.245026, acc.: 54.69%] [G loss: 0.280420]\n",
      "epoch:8 step:7717 [D loss: 0.230548, acc.: 67.97%] [G loss: 0.289712]\n",
      "epoch:8 step:7718 [D loss: 0.233522, acc.: 60.16%] [G loss: 0.288861]\n",
      "epoch:8 step:7719 [D loss: 0.227643, acc.: 58.59%] [G loss: 0.289742]\n",
      "epoch:8 step:7720 [D loss: 0.252185, acc.: 52.34%] [G loss: 0.322482]\n",
      "epoch:8 step:7721 [D loss: 0.237103, acc.: 62.50%] [G loss: 0.302688]\n",
      "epoch:8 step:7722 [D loss: 0.236407, acc.: 59.38%] [G loss: 0.305627]\n",
      "epoch:8 step:7723 [D loss: 0.245322, acc.: 54.69%] [G loss: 0.289028]\n",
      "epoch:8 step:7724 [D loss: 0.236395, acc.: 60.16%] [G loss: 0.289636]\n",
      "epoch:8 step:7725 [D loss: 0.229762, acc.: 59.38%] [G loss: 0.293245]\n",
      "epoch:8 step:7726 [D loss: 0.242463, acc.: 54.69%] [G loss: 0.320957]\n",
      "epoch:8 step:7727 [D loss: 0.236686, acc.: 62.50%] [G loss: 0.277682]\n",
      "epoch:8 step:7728 [D loss: 0.257750, acc.: 50.00%] [G loss: 0.264772]\n",
      "epoch:8 step:7729 [D loss: 0.241041, acc.: 53.91%] [G loss: 0.295531]\n",
      "epoch:8 step:7730 [D loss: 0.241920, acc.: 57.03%] [G loss: 0.293778]\n",
      "epoch:8 step:7731 [D loss: 0.241570, acc.: 55.47%] [G loss: 0.305811]\n",
      "epoch:8 step:7732 [D loss: 0.234983, acc.: 60.16%] [G loss: 0.330457]\n",
      "epoch:8 step:7733 [D loss: 0.237594, acc.: 56.25%] [G loss: 0.293469]\n",
      "epoch:8 step:7734 [D loss: 0.252333, acc.: 54.69%] [G loss: 0.307979]\n",
      "epoch:8 step:7735 [D loss: 0.267311, acc.: 48.44%] [G loss: 0.273205]\n",
      "epoch:8 step:7736 [D loss: 0.251749, acc.: 53.91%] [G loss: 0.290851]\n",
      "epoch:8 step:7737 [D loss: 0.232777, acc.: 61.72%] [G loss: 0.284773]\n",
      "epoch:8 step:7738 [D loss: 0.233998, acc.: 60.16%] [G loss: 0.276443]\n",
      "epoch:8 step:7739 [D loss: 0.236855, acc.: 58.59%] [G loss: 0.302487]\n",
      "epoch:8 step:7740 [D loss: 0.235209, acc.: 60.94%] [G loss: 0.327758]\n",
      "epoch:8 step:7741 [D loss: 0.273242, acc.: 43.75%] [G loss: 0.304956]\n",
      "epoch:8 step:7742 [D loss: 0.235436, acc.: 60.16%] [G loss: 0.303427]\n",
      "epoch:8 step:7743 [D loss: 0.241514, acc.: 57.03%] [G loss: 0.298725]\n",
      "epoch:8 step:7744 [D loss: 0.236913, acc.: 57.03%] [G loss: 0.289976]\n",
      "epoch:8 step:7745 [D loss: 0.234535, acc.: 57.81%] [G loss: 0.300609]\n",
      "epoch:8 step:7746 [D loss: 0.239871, acc.: 57.81%] [G loss: 0.293202]\n",
      "epoch:8 step:7747 [D loss: 0.226806, acc.: 59.38%] [G loss: 0.294570]\n",
      "epoch:8 step:7748 [D loss: 0.227859, acc.: 64.84%] [G loss: 0.320293]\n",
      "epoch:8 step:7749 [D loss: 0.231283, acc.: 60.16%] [G loss: 0.324366]\n",
      "epoch:8 step:7750 [D loss: 0.245708, acc.: 52.34%] [G loss: 0.301749]\n",
      "epoch:8 step:7751 [D loss: 0.242727, acc.: 56.25%] [G loss: 0.305692]\n",
      "epoch:8 step:7752 [D loss: 0.250211, acc.: 55.47%] [G loss: 0.290686]\n",
      "epoch:8 step:7753 [D loss: 0.241157, acc.: 59.38%] [G loss: 0.291865]\n",
      "epoch:8 step:7754 [D loss: 0.252059, acc.: 54.69%] [G loss: 0.306057]\n",
      "epoch:8 step:7755 [D loss: 0.250771, acc.: 55.47%] [G loss: 0.317018]\n",
      "epoch:8 step:7756 [D loss: 0.232349, acc.: 63.28%] [G loss: 0.302141]\n",
      "epoch:8 step:7757 [D loss: 0.235740, acc.: 57.03%] [G loss: 0.293054]\n",
      "epoch:8 step:7758 [D loss: 0.258584, acc.: 53.12%] [G loss: 0.305534]\n",
      "epoch:8 step:7759 [D loss: 0.265479, acc.: 45.31%] [G loss: 0.285581]\n",
      "epoch:8 step:7760 [D loss: 0.237958, acc.: 54.69%] [G loss: 0.297763]\n",
      "epoch:8 step:7761 [D loss: 0.234148, acc.: 60.16%] [G loss: 0.314370]\n",
      "epoch:8 step:7762 [D loss: 0.232752, acc.: 56.25%] [G loss: 0.285913]\n",
      "epoch:8 step:7763 [D loss: 0.232099, acc.: 60.16%] [G loss: 0.298263]\n",
      "epoch:8 step:7764 [D loss: 0.220497, acc.: 67.19%] [G loss: 0.274110]\n",
      "epoch:8 step:7765 [D loss: 0.239855, acc.: 58.59%] [G loss: 0.287001]\n",
      "epoch:8 step:7766 [D loss: 0.251333, acc.: 53.12%] [G loss: 0.281160]\n",
      "epoch:8 step:7767 [D loss: 0.242004, acc.: 59.38%] [G loss: 0.303710]\n",
      "epoch:8 step:7768 [D loss: 0.239062, acc.: 56.25%] [G loss: 0.305184]\n",
      "epoch:8 step:7769 [D loss: 0.232896, acc.: 61.72%] [G loss: 0.321982]\n",
      "epoch:8 step:7770 [D loss: 0.251907, acc.: 51.56%] [G loss: 0.269152]\n",
      "epoch:8 step:7771 [D loss: 0.255764, acc.: 52.34%] [G loss: 0.288020]\n",
      "epoch:8 step:7772 [D loss: 0.250015, acc.: 58.59%] [G loss: 0.303479]\n",
      "epoch:8 step:7773 [D loss: 0.243084, acc.: 55.47%] [G loss: 0.281761]\n",
      "epoch:8 step:7774 [D loss: 0.233121, acc.: 62.50%] [G loss: 0.316343]\n",
      "epoch:8 step:7775 [D loss: 0.258905, acc.: 53.12%] [G loss: 0.288759]\n",
      "epoch:8 step:7776 [D loss: 0.246183, acc.: 56.25%] [G loss: 0.294825]\n",
      "epoch:8 step:7777 [D loss: 0.243426, acc.: 53.91%] [G loss: 0.294029]\n",
      "epoch:8 step:7778 [D loss: 0.245372, acc.: 57.81%] [G loss: 0.305849]\n",
      "epoch:8 step:7779 [D loss: 0.247539, acc.: 50.78%] [G loss: 0.293886]\n",
      "epoch:8 step:7780 [D loss: 0.229964, acc.: 62.50%] [G loss: 0.309137]\n",
      "epoch:8 step:7781 [D loss: 0.232592, acc.: 57.81%] [G loss: 0.314404]\n",
      "epoch:8 step:7782 [D loss: 0.245792, acc.: 57.81%] [G loss: 0.295280]\n",
      "epoch:8 step:7783 [D loss: 0.231971, acc.: 60.94%] [G loss: 0.298936]\n",
      "epoch:8 step:7784 [D loss: 0.232426, acc.: 62.50%] [G loss: 0.300844]\n",
      "epoch:8 step:7785 [D loss: 0.239626, acc.: 60.16%] [G loss: 0.308267]\n",
      "epoch:8 step:7786 [D loss: 0.253621, acc.: 55.47%] [G loss: 0.284906]\n",
      "epoch:8 step:7787 [D loss: 0.230551, acc.: 57.03%] [G loss: 0.321756]\n",
      "epoch:8 step:7788 [D loss: 0.248418, acc.: 55.47%] [G loss: 0.317744]\n",
      "epoch:8 step:7789 [D loss: 0.237759, acc.: 59.38%] [G loss: 0.290887]\n",
      "epoch:8 step:7790 [D loss: 0.259716, acc.: 45.31%] [G loss: 0.300919]\n",
      "epoch:8 step:7791 [D loss: 0.246713, acc.: 54.69%] [G loss: 0.310729]\n",
      "epoch:8 step:7792 [D loss: 0.251397, acc.: 50.78%] [G loss: 0.300386]\n",
      "epoch:8 step:7793 [D loss: 0.244857, acc.: 57.03%] [G loss: 0.301821]\n",
      "epoch:8 step:7794 [D loss: 0.249078, acc.: 56.25%] [G loss: 0.294069]\n",
      "epoch:8 step:7795 [D loss: 0.227606, acc.: 64.84%] [G loss: 0.319743]\n",
      "epoch:8 step:7796 [D loss: 0.237059, acc.: 60.94%] [G loss: 0.310436]\n",
      "epoch:8 step:7797 [D loss: 0.249266, acc.: 57.03%] [G loss: 0.289564]\n",
      "epoch:8 step:7798 [D loss: 0.242187, acc.: 60.16%] [G loss: 0.304940]\n",
      "epoch:8 step:7799 [D loss: 0.250170, acc.: 54.69%] [G loss: 0.311585]\n",
      "epoch:8 step:7800 [D loss: 0.249666, acc.: 56.25%] [G loss: 0.317562]\n",
      "epoch:8 step:7801 [D loss: 0.247017, acc.: 53.91%] [G loss: 0.298891]\n",
      "epoch:8 step:7802 [D loss: 0.241336, acc.: 57.81%] [G loss: 0.286284]\n",
      "epoch:8 step:7803 [D loss: 0.241081, acc.: 55.47%] [G loss: 0.312812]\n",
      "epoch:8 step:7804 [D loss: 0.246257, acc.: 55.47%] [G loss: 0.302592]\n",
      "epoch:8 step:7805 [D loss: 0.230581, acc.: 65.62%] [G loss: 0.294348]\n",
      "epoch:8 step:7806 [D loss: 0.243452, acc.: 53.91%] [G loss: 0.312397]\n",
      "epoch:8 step:7807 [D loss: 0.244611, acc.: 57.81%] [G loss: 0.296150]\n",
      "epoch:8 step:7808 [D loss: 0.270390, acc.: 46.88%] [G loss: 0.276849]\n",
      "epoch:8 step:7809 [D loss: 0.232411, acc.: 60.94%] [G loss: 0.301056]\n",
      "epoch:8 step:7810 [D loss: 0.244586, acc.: 56.25%] [G loss: 0.288910]\n",
      "epoch:8 step:7811 [D loss: 0.241801, acc.: 57.03%] [G loss: 0.284277]\n",
      "epoch:8 step:7812 [D loss: 0.257205, acc.: 48.44%] [G loss: 0.285756]\n",
      "epoch:8 step:7813 [D loss: 0.245045, acc.: 50.78%] [G loss: 0.297460]\n",
      "epoch:8 step:7814 [D loss: 0.256405, acc.: 50.00%] [G loss: 0.302680]\n",
      "epoch:8 step:7815 [D loss: 0.251649, acc.: 54.69%] [G loss: 0.278179]\n",
      "epoch:8 step:7816 [D loss: 0.255985, acc.: 53.91%] [G loss: 0.282592]\n",
      "epoch:8 step:7817 [D loss: 0.245986, acc.: 55.47%] [G loss: 0.265958]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:8 step:7818 [D loss: 0.244794, acc.: 54.69%] [G loss: 0.300861]\n",
      "epoch:8 step:7819 [D loss: 0.250659, acc.: 50.00%] [G loss: 0.272330]\n",
      "epoch:8 step:7820 [D loss: 0.250683, acc.: 53.91%] [G loss: 0.276125]\n",
      "epoch:8 step:7821 [D loss: 0.242851, acc.: 60.16%] [G loss: 0.267130]\n",
      "epoch:8 step:7822 [D loss: 0.253490, acc.: 52.34%] [G loss: 0.285339]\n",
      "epoch:8 step:7823 [D loss: 0.226388, acc.: 60.94%] [G loss: 0.288286]\n",
      "epoch:8 step:7824 [D loss: 0.230944, acc.: 61.72%] [G loss: 0.274497]\n",
      "epoch:8 step:7825 [D loss: 0.230043, acc.: 67.97%] [G loss: 0.302773]\n",
      "epoch:8 step:7826 [D loss: 0.228842, acc.: 60.94%] [G loss: 0.296488]\n",
      "epoch:8 step:7827 [D loss: 0.246272, acc.: 53.91%] [G loss: 0.280783]\n",
      "epoch:8 step:7828 [D loss: 0.233110, acc.: 61.72%] [G loss: 0.299880]\n",
      "epoch:8 step:7829 [D loss: 0.247206, acc.: 53.12%] [G loss: 0.293056]\n",
      "epoch:8 step:7830 [D loss: 0.237433, acc.: 60.16%] [G loss: 0.271949]\n",
      "epoch:8 step:7831 [D loss: 0.242045, acc.: 50.00%] [G loss: 0.278222]\n",
      "epoch:8 step:7832 [D loss: 0.238772, acc.: 57.81%] [G loss: 0.285340]\n",
      "epoch:8 step:7833 [D loss: 0.234855, acc.: 56.25%] [G loss: 0.291689]\n",
      "epoch:8 step:7834 [D loss: 0.233520, acc.: 59.38%] [G loss: 0.290746]\n",
      "epoch:8 step:7835 [D loss: 0.248961, acc.: 52.34%] [G loss: 0.301064]\n",
      "epoch:8 step:7836 [D loss: 0.251300, acc.: 53.91%] [G loss: 0.313955]\n",
      "epoch:8 step:7837 [D loss: 0.246207, acc.: 54.69%] [G loss: 0.301344]\n",
      "epoch:8 step:7838 [D loss: 0.234914, acc.: 55.47%] [G loss: 0.315368]\n",
      "epoch:8 step:7839 [D loss: 0.241628, acc.: 54.69%] [G loss: 0.290547]\n",
      "epoch:8 step:7840 [D loss: 0.242363, acc.: 60.16%] [G loss: 0.309977]\n",
      "epoch:8 step:7841 [D loss: 0.240929, acc.: 60.16%] [G loss: 0.291485]\n",
      "epoch:8 step:7842 [D loss: 0.255200, acc.: 50.00%] [G loss: 0.268942]\n",
      "epoch:8 step:7843 [D loss: 0.249422, acc.: 53.12%] [G loss: 0.278987]\n",
      "epoch:8 step:7844 [D loss: 0.241442, acc.: 53.12%] [G loss: 0.278450]\n",
      "epoch:8 step:7845 [D loss: 0.259753, acc.: 50.78%] [G loss: 0.315715]\n",
      "epoch:8 step:7846 [D loss: 0.259343, acc.: 47.66%] [G loss: 0.287401]\n",
      "epoch:8 step:7847 [D loss: 0.261384, acc.: 50.00%] [G loss: 0.296844]\n",
      "epoch:8 step:7848 [D loss: 0.239156, acc.: 58.59%] [G loss: 0.276117]\n",
      "epoch:8 step:7849 [D loss: 0.226293, acc.: 64.06%] [G loss: 0.327209]\n",
      "epoch:8 step:7850 [D loss: 0.222278, acc.: 66.41%] [G loss: 0.318137]\n",
      "epoch:8 step:7851 [D loss: 0.234687, acc.: 56.25%] [G loss: 0.287893]\n",
      "epoch:8 step:7852 [D loss: 0.238360, acc.: 60.94%] [G loss: 0.303624]\n",
      "epoch:8 step:7853 [D loss: 0.252609, acc.: 51.56%] [G loss: 0.300699]\n",
      "epoch:8 step:7854 [D loss: 0.219808, acc.: 64.06%] [G loss: 0.289231]\n",
      "epoch:8 step:7855 [D loss: 0.258278, acc.: 53.91%] [G loss: 0.296175]\n",
      "epoch:8 step:7856 [D loss: 0.235090, acc.: 59.38%] [G loss: 0.270924]\n",
      "epoch:8 step:7857 [D loss: 0.240718, acc.: 58.59%] [G loss: 0.271539]\n",
      "epoch:8 step:7858 [D loss: 0.234623, acc.: 63.28%] [G loss: 0.285908]\n",
      "epoch:8 step:7859 [D loss: 0.243010, acc.: 59.38%] [G loss: 0.287982]\n",
      "epoch:8 step:7860 [D loss: 0.231897, acc.: 63.28%] [G loss: 0.274225]\n",
      "epoch:8 step:7861 [D loss: 0.239971, acc.: 60.16%] [G loss: 0.293134]\n",
      "epoch:8 step:7862 [D loss: 0.243036, acc.: 55.47%] [G loss: 0.305091]\n",
      "epoch:8 step:7863 [D loss: 0.257776, acc.: 46.88%] [G loss: 0.266056]\n",
      "epoch:8 step:7864 [D loss: 0.237441, acc.: 58.59%] [G loss: 0.312184]\n",
      "epoch:8 step:7865 [D loss: 0.245934, acc.: 53.12%] [G loss: 0.308967]\n",
      "epoch:8 step:7866 [D loss: 0.244488, acc.: 59.38%] [G loss: 0.284029]\n",
      "epoch:8 step:7867 [D loss: 0.235478, acc.: 59.38%] [G loss: 0.291221]\n",
      "epoch:8 step:7868 [D loss: 0.244945, acc.: 54.69%] [G loss: 0.274627]\n",
      "epoch:8 step:7869 [D loss: 0.229586, acc.: 61.72%] [G loss: 0.295472]\n",
      "epoch:8 step:7870 [D loss: 0.250396, acc.: 57.03%] [G loss: 0.300287]\n",
      "epoch:8 step:7871 [D loss: 0.239965, acc.: 56.25%] [G loss: 0.312392]\n",
      "epoch:8 step:7872 [D loss: 0.250544, acc.: 54.69%] [G loss: 0.302730]\n",
      "epoch:8 step:7873 [D loss: 0.256663, acc.: 53.91%] [G loss: 0.262806]\n",
      "epoch:8 step:7874 [D loss: 0.250222, acc.: 52.34%] [G loss: 0.327830]\n",
      "epoch:8 step:7875 [D loss: 0.234038, acc.: 60.94%] [G loss: 0.265526]\n",
      "epoch:8 step:7876 [D loss: 0.249460, acc.: 52.34%] [G loss: 0.294028]\n",
      "epoch:8 step:7877 [D loss: 0.241472, acc.: 65.62%] [G loss: 0.294193]\n",
      "epoch:8 step:7878 [D loss: 0.248260, acc.: 57.03%] [G loss: 0.292236]\n",
      "epoch:8 step:7879 [D loss: 0.240374, acc.: 61.72%] [G loss: 0.308528]\n",
      "epoch:8 step:7880 [D loss: 0.244882, acc.: 52.34%] [G loss: 0.292829]\n",
      "epoch:8 step:7881 [D loss: 0.239946, acc.: 56.25%] [G loss: 0.294115]\n",
      "epoch:8 step:7882 [D loss: 0.250704, acc.: 47.66%] [G loss: 0.249282]\n",
      "epoch:8 step:7883 [D loss: 0.243406, acc.: 55.47%] [G loss: 0.283644]\n",
      "epoch:8 step:7884 [D loss: 0.241547, acc.: 50.78%] [G loss: 0.296216]\n",
      "epoch:8 step:7885 [D loss: 0.235740, acc.: 57.03%] [G loss: 0.300846]\n",
      "epoch:8 step:7886 [D loss: 0.252060, acc.: 58.59%] [G loss: 0.283995]\n",
      "epoch:8 step:7887 [D loss: 0.248554, acc.: 53.91%] [G loss: 0.334906]\n",
      "epoch:8 step:7888 [D loss: 0.253272, acc.: 56.25%] [G loss: 0.284072]\n",
      "epoch:8 step:7889 [D loss: 0.229858, acc.: 62.50%] [G loss: 0.295333]\n",
      "epoch:8 step:7890 [D loss: 0.232412, acc.: 64.06%] [G loss: 0.278525]\n",
      "epoch:8 step:7891 [D loss: 0.227637, acc.: 67.19%] [G loss: 0.308292]\n",
      "epoch:8 step:7892 [D loss: 0.235307, acc.: 60.16%] [G loss: 0.275421]\n",
      "epoch:8 step:7893 [D loss: 0.257633, acc.: 46.88%] [G loss: 0.328150]\n",
      "epoch:8 step:7894 [D loss: 0.225810, acc.: 58.59%] [G loss: 0.290646]\n",
      "epoch:8 step:7895 [D loss: 0.226842, acc.: 61.72%] [G loss: 0.300501]\n",
      "epoch:8 step:7896 [D loss: 0.224382, acc.: 64.06%] [G loss: 0.291219]\n",
      "epoch:8 step:7897 [D loss: 0.224591, acc.: 62.50%] [G loss: 0.320143]\n",
      "epoch:8 step:7898 [D loss: 0.226751, acc.: 64.84%] [G loss: 0.301859]\n",
      "epoch:8 step:7899 [D loss: 0.239581, acc.: 52.34%] [G loss: 0.285565]\n",
      "epoch:8 step:7900 [D loss: 0.233429, acc.: 57.81%] [G loss: 0.289378]\n",
      "epoch:8 step:7901 [D loss: 0.224940, acc.: 63.28%] [G loss: 0.282469]\n",
      "epoch:8 step:7902 [D loss: 0.223130, acc.: 65.62%] [G loss: 0.278884]\n",
      "epoch:8 step:7903 [D loss: 0.245937, acc.: 57.81%] [G loss: 0.281093]\n",
      "epoch:8 step:7904 [D loss: 0.235057, acc.: 63.28%] [G loss: 0.263651]\n",
      "epoch:8 step:7905 [D loss: 0.243320, acc.: 55.47%] [G loss: 0.303464]\n",
      "epoch:8 step:7906 [D loss: 0.238263, acc.: 57.81%] [G loss: 0.283661]\n",
      "epoch:8 step:7907 [D loss: 0.230217, acc.: 62.50%] [G loss: 0.313687]\n",
      "epoch:8 step:7908 [D loss: 0.244584, acc.: 53.91%] [G loss: 0.291986]\n",
      "epoch:8 step:7909 [D loss: 0.240629, acc.: 52.34%] [G loss: 0.289999]\n",
      "epoch:8 step:7910 [D loss: 0.254830, acc.: 54.69%] [G loss: 0.298125]\n",
      "epoch:8 step:7911 [D loss: 0.227345, acc.: 60.16%] [G loss: 0.330611]\n",
      "epoch:8 step:7912 [D loss: 0.250066, acc.: 50.78%] [G loss: 0.283243]\n",
      "epoch:8 step:7913 [D loss: 0.248449, acc.: 48.44%] [G loss: 0.299098]\n",
      "epoch:8 step:7914 [D loss: 0.234851, acc.: 59.38%] [G loss: 0.294936]\n",
      "epoch:8 step:7915 [D loss: 0.247706, acc.: 51.56%] [G loss: 0.307594]\n",
      "epoch:8 step:7916 [D loss: 0.229411, acc.: 60.16%] [G loss: 0.293834]\n",
      "epoch:8 step:7917 [D loss: 0.244577, acc.: 53.91%] [G loss: 0.305693]\n",
      "epoch:8 step:7918 [D loss: 0.234671, acc.: 63.28%] [G loss: 0.293624]\n",
      "epoch:8 step:7919 [D loss: 0.240313, acc.: 66.41%] [G loss: 0.272073]\n",
      "epoch:8 step:7920 [D loss: 0.243014, acc.: 55.47%] [G loss: 0.294877]\n",
      "epoch:8 step:7921 [D loss: 0.240549, acc.: 60.94%] [G loss: 0.282966]\n",
      "epoch:8 step:7922 [D loss: 0.236122, acc.: 60.94%] [G loss: 0.285990]\n",
      "epoch:8 step:7923 [D loss: 0.248310, acc.: 56.25%] [G loss: 0.282322]\n",
      "epoch:8 step:7924 [D loss: 0.249283, acc.: 56.25%] [G loss: 0.304514]\n",
      "epoch:8 step:7925 [D loss: 0.240748, acc.: 60.94%] [G loss: 0.292243]\n",
      "epoch:8 step:7926 [D loss: 0.225213, acc.: 62.50%] [G loss: 0.323780]\n",
      "epoch:8 step:7927 [D loss: 0.248367, acc.: 52.34%] [G loss: 0.272088]\n",
      "epoch:8 step:7928 [D loss: 0.248202, acc.: 56.25%] [G loss: 0.266712]\n",
      "epoch:8 step:7929 [D loss: 0.239858, acc.: 58.59%] [G loss: 0.333560]\n",
      "epoch:8 step:7930 [D loss: 0.239390, acc.: 60.94%] [G loss: 0.307869]\n",
      "epoch:8 step:7931 [D loss: 0.256617, acc.: 59.38%] [G loss: 0.294877]\n",
      "epoch:8 step:7932 [D loss: 0.259848, acc.: 50.78%] [G loss: 0.303791]\n",
      "epoch:8 step:7933 [D loss: 0.239670, acc.: 58.59%] [G loss: 0.297773]\n",
      "epoch:8 step:7934 [D loss: 0.254716, acc.: 54.69%] [G loss: 0.260561]\n",
      "epoch:8 step:7935 [D loss: 0.248350, acc.: 50.78%] [G loss: 0.288737]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:8 step:7936 [D loss: 0.248442, acc.: 52.34%] [G loss: 0.286321]\n",
      "epoch:8 step:7937 [D loss: 0.243084, acc.: 57.81%] [G loss: 0.292387]\n",
      "epoch:8 step:7938 [D loss: 0.257095, acc.: 51.56%] [G loss: 0.289622]\n",
      "epoch:8 step:7939 [D loss: 0.247882, acc.: 53.12%] [G loss: 0.304624]\n",
      "epoch:8 step:7940 [D loss: 0.222884, acc.: 69.53%] [G loss: 0.306638]\n",
      "epoch:8 step:7941 [D loss: 0.226821, acc.: 63.28%] [G loss: 0.304008]\n",
      "epoch:8 step:7942 [D loss: 0.259797, acc.: 49.22%] [G loss: 0.283020]\n",
      "epoch:8 step:7943 [D loss: 0.240102, acc.: 58.59%] [G loss: 0.309998]\n",
      "epoch:8 step:7944 [D loss: 0.243245, acc.: 58.59%] [G loss: 0.287943]\n",
      "epoch:8 step:7945 [D loss: 0.219251, acc.: 64.06%] [G loss: 0.293476]\n",
      "epoch:8 step:7946 [D loss: 0.256560, acc.: 50.78%] [G loss: 0.288324]\n",
      "epoch:8 step:7947 [D loss: 0.235583, acc.: 57.03%] [G loss: 0.290121]\n",
      "epoch:8 step:7948 [D loss: 0.242202, acc.: 56.25%] [G loss: 0.267268]\n",
      "epoch:8 step:7949 [D loss: 0.236034, acc.: 57.03%] [G loss: 0.298432]\n",
      "epoch:8 step:7950 [D loss: 0.231271, acc.: 62.50%] [G loss: 0.280093]\n",
      "epoch:8 step:7951 [D loss: 0.262356, acc.: 47.66%] [G loss: 0.292389]\n",
      "epoch:8 step:7952 [D loss: 0.250165, acc.: 55.47%] [G loss: 0.303438]\n",
      "epoch:8 step:7953 [D loss: 0.254363, acc.: 49.22%] [G loss: 0.286858]\n",
      "epoch:8 step:7954 [D loss: 0.242339, acc.: 52.34%] [G loss: 0.311353]\n",
      "epoch:8 step:7955 [D loss: 0.235844, acc.: 57.81%] [G loss: 0.282093]\n",
      "epoch:8 step:7956 [D loss: 0.237761, acc.: 57.81%] [G loss: 0.297291]\n",
      "epoch:8 step:7957 [D loss: 0.246754, acc.: 58.59%] [G loss: 0.288797]\n",
      "epoch:8 step:7958 [D loss: 0.229343, acc.: 60.94%] [G loss: 0.291371]\n",
      "epoch:8 step:7959 [D loss: 0.242616, acc.: 57.03%] [G loss: 0.321412]\n",
      "epoch:8 step:7960 [D loss: 0.237163, acc.: 60.94%] [G loss: 0.308033]\n",
      "epoch:8 step:7961 [D loss: 0.238804, acc.: 54.69%] [G loss: 0.323546]\n",
      "epoch:8 step:7962 [D loss: 0.238816, acc.: 59.38%] [G loss: 0.301916]\n",
      "epoch:8 step:7963 [D loss: 0.231736, acc.: 61.72%] [G loss: 0.288528]\n",
      "epoch:8 step:7964 [D loss: 0.258010, acc.: 53.12%] [G loss: 0.304496]\n",
      "epoch:8 step:7965 [D loss: 0.246038, acc.: 55.47%] [G loss: 0.291601]\n",
      "epoch:8 step:7966 [D loss: 0.251375, acc.: 55.47%] [G loss: 0.307078]\n",
      "epoch:8 step:7967 [D loss: 0.250014, acc.: 55.47%] [G loss: 0.292511]\n",
      "epoch:8 step:7968 [D loss: 0.245122, acc.: 60.16%] [G loss: 0.295294]\n",
      "epoch:8 step:7969 [D loss: 0.251059, acc.: 59.38%] [G loss: 0.296469]\n",
      "epoch:8 step:7970 [D loss: 0.227856, acc.: 63.28%] [G loss: 0.331111]\n",
      "epoch:8 step:7971 [D loss: 0.252333, acc.: 54.69%] [G loss: 0.275453]\n",
      "epoch:8 step:7972 [D loss: 0.230761, acc.: 63.28%] [G loss: 0.332978]\n",
      "epoch:8 step:7973 [D loss: 0.250169, acc.: 46.09%] [G loss: 0.323883]\n",
      "epoch:8 step:7974 [D loss: 0.220922, acc.: 64.06%] [G loss: 0.300258]\n",
      "epoch:8 step:7975 [D loss: 0.237137, acc.: 58.59%] [G loss: 0.313839]\n",
      "epoch:8 step:7976 [D loss: 0.237086, acc.: 60.16%] [G loss: 0.310927]\n",
      "epoch:8 step:7977 [D loss: 0.248337, acc.: 55.47%] [G loss: 0.284854]\n",
      "epoch:8 step:7978 [D loss: 0.253629, acc.: 57.03%] [G loss: 0.309611]\n",
      "epoch:8 step:7979 [D loss: 0.243930, acc.: 58.59%] [G loss: 0.300044]\n",
      "epoch:8 step:7980 [D loss: 0.229041, acc.: 61.72%] [G loss: 0.299234]\n",
      "epoch:8 step:7981 [D loss: 0.242584, acc.: 53.91%] [G loss: 0.298515]\n",
      "epoch:8 step:7982 [D loss: 0.254746, acc.: 51.56%] [G loss: 0.295256]\n",
      "epoch:8 step:7983 [D loss: 0.235653, acc.: 63.28%] [G loss: 0.314691]\n",
      "epoch:8 step:7984 [D loss: 0.232667, acc.: 60.16%] [G loss: 0.300831]\n",
      "epoch:8 step:7985 [D loss: 0.258857, acc.: 45.31%] [G loss: 0.276435]\n",
      "epoch:8 step:7986 [D loss: 0.233974, acc.: 57.03%] [G loss: 0.318472]\n",
      "epoch:8 step:7987 [D loss: 0.234698, acc.: 59.38%] [G loss: 0.304706]\n",
      "epoch:8 step:7988 [D loss: 0.240532, acc.: 59.38%] [G loss: 0.306028]\n",
      "epoch:8 step:7989 [D loss: 0.248662, acc.: 50.00%] [G loss: 0.288609]\n",
      "epoch:8 step:7990 [D loss: 0.229942, acc.: 57.81%] [G loss: 0.293422]\n",
      "epoch:8 step:7991 [D loss: 0.256226, acc.: 53.12%] [G loss: 0.308190]\n",
      "epoch:8 step:7992 [D loss: 0.249860, acc.: 56.25%] [G loss: 0.290508]\n",
      "epoch:8 step:7993 [D loss: 0.243945, acc.: 55.47%] [G loss: 0.282307]\n",
      "epoch:8 step:7994 [D loss: 0.235646, acc.: 55.47%] [G loss: 0.292026]\n",
      "epoch:8 step:7995 [D loss: 0.238536, acc.: 57.03%] [G loss: 0.285033]\n",
      "epoch:8 step:7996 [D loss: 0.255334, acc.: 52.34%] [G loss: 0.301176]\n",
      "epoch:8 step:7997 [D loss: 0.230644, acc.: 61.72%] [G loss: 0.278132]\n",
      "epoch:8 step:7998 [D loss: 0.236020, acc.: 60.16%] [G loss: 0.297816]\n",
      "epoch:8 step:7999 [D loss: 0.239520, acc.: 53.91%] [G loss: 0.306257]\n",
      "epoch:8 step:8000 [D loss: 0.239985, acc.: 57.81%] [G loss: 0.303491]\n",
      "epoch:8 step:8001 [D loss: 0.245954, acc.: 60.16%] [G loss: 0.297631]\n",
      "epoch:8 step:8002 [D loss: 0.242248, acc.: 55.47%] [G loss: 0.284973]\n",
      "epoch:8 step:8003 [D loss: 0.249526, acc.: 55.47%] [G loss: 0.294302]\n",
      "epoch:8 step:8004 [D loss: 0.238739, acc.: 58.59%] [G loss: 0.311512]\n",
      "epoch:8 step:8005 [D loss: 0.247749, acc.: 53.12%] [G loss: 0.325066]\n",
      "epoch:8 step:8006 [D loss: 0.227977, acc.: 63.28%] [G loss: 0.288066]\n",
      "epoch:8 step:8007 [D loss: 0.243970, acc.: 55.47%] [G loss: 0.295793]\n",
      "epoch:8 step:8008 [D loss: 0.249048, acc.: 59.38%] [G loss: 0.282379]\n",
      "epoch:8 step:8009 [D loss: 0.226195, acc.: 64.84%] [G loss: 0.323471]\n",
      "epoch:8 step:8010 [D loss: 0.240918, acc.: 56.25%] [G loss: 0.300450]\n",
      "epoch:8 step:8011 [D loss: 0.222313, acc.: 67.19%] [G loss: 0.330954]\n",
      "epoch:8 step:8012 [D loss: 0.238594, acc.: 57.03%] [G loss: 0.314684]\n",
      "epoch:8 step:8013 [D loss: 0.235264, acc.: 60.16%] [G loss: 0.290757]\n",
      "epoch:8 step:8014 [D loss: 0.236660, acc.: 57.03%] [G loss: 0.288418]\n",
      "epoch:8 step:8015 [D loss: 0.222182, acc.: 71.09%] [G loss: 0.301679]\n",
      "epoch:8 step:8016 [D loss: 0.253811, acc.: 46.09%] [G loss: 0.308009]\n",
      "epoch:8 step:8017 [D loss: 0.246796, acc.: 57.81%] [G loss: 0.300425]\n",
      "epoch:8 step:8018 [D loss: 0.232911, acc.: 59.38%] [G loss: 0.302777]\n",
      "epoch:8 step:8019 [D loss: 0.238561, acc.: 57.03%] [G loss: 0.295221]\n",
      "epoch:8 step:8020 [D loss: 0.231974, acc.: 62.50%] [G loss: 0.289347]\n",
      "epoch:8 step:8021 [D loss: 0.244591, acc.: 52.34%] [G loss: 0.292542]\n",
      "epoch:8 step:8022 [D loss: 0.243922, acc.: 57.03%] [G loss: 0.298647]\n",
      "epoch:8 step:8023 [D loss: 0.235661, acc.: 58.59%] [G loss: 0.320254]\n",
      "epoch:8 step:8024 [D loss: 0.243898, acc.: 57.03%] [G loss: 0.307159]\n",
      "epoch:8 step:8025 [D loss: 0.231492, acc.: 64.84%] [G loss: 0.309972]\n",
      "epoch:8 step:8026 [D loss: 0.225372, acc.: 67.19%] [G loss: 0.288049]\n",
      "epoch:8 step:8027 [D loss: 0.232912, acc.: 59.38%] [G loss: 0.284347]\n",
      "epoch:8 step:8028 [D loss: 0.244525, acc.: 60.94%] [G loss: 0.307878]\n",
      "epoch:8 step:8029 [D loss: 0.232702, acc.: 59.38%] [G loss: 0.323938]\n",
      "epoch:8 step:8030 [D loss: 0.242928, acc.: 54.69%] [G loss: 0.292435]\n",
      "epoch:8 step:8031 [D loss: 0.259779, acc.: 46.09%] [G loss: 0.273415]\n",
      "epoch:8 step:8032 [D loss: 0.221981, acc.: 64.84%] [G loss: 0.282505]\n",
      "epoch:8 step:8033 [D loss: 0.230795, acc.: 62.50%] [G loss: 0.312349]\n",
      "epoch:8 step:8034 [D loss: 0.240284, acc.: 60.16%] [G loss: 0.300482]\n",
      "epoch:8 step:8035 [D loss: 0.221983, acc.: 61.72%] [G loss: 0.334993]\n",
      "epoch:8 step:8036 [D loss: 0.212501, acc.: 67.97%] [G loss: 0.321312]\n",
      "epoch:8 step:8037 [D loss: 0.232709, acc.: 64.84%] [G loss: 0.308724]\n",
      "epoch:8 step:8038 [D loss: 0.236248, acc.: 60.94%] [G loss: 0.277337]\n",
      "epoch:8 step:8039 [D loss: 0.254256, acc.: 52.34%] [G loss: 0.343397]\n",
      "epoch:8 step:8040 [D loss: 0.241026, acc.: 59.38%] [G loss: 0.296174]\n",
      "epoch:8 step:8041 [D loss: 0.227530, acc.: 65.62%] [G loss: 0.308744]\n",
      "epoch:8 step:8042 [D loss: 0.250721, acc.: 52.34%] [G loss: 0.277878]\n",
      "epoch:8 step:8043 [D loss: 0.230928, acc.: 60.94%] [G loss: 0.315738]\n",
      "epoch:8 step:8044 [D loss: 0.238626, acc.: 64.06%] [G loss: 0.282175]\n",
      "epoch:8 step:8045 [D loss: 0.236936, acc.: 60.16%] [G loss: 0.317545]\n",
      "epoch:8 step:8046 [D loss: 0.238413, acc.: 57.81%] [G loss: 0.284999]\n",
      "epoch:8 step:8047 [D loss: 0.239064, acc.: 64.06%] [G loss: 0.302772]\n",
      "epoch:8 step:8048 [D loss: 0.238799, acc.: 59.38%] [G loss: 0.277014]\n",
      "epoch:8 step:8049 [D loss: 0.235637, acc.: 62.50%] [G loss: 0.297236]\n",
      "epoch:8 step:8050 [D loss: 0.239298, acc.: 58.59%] [G loss: 0.300056]\n",
      "epoch:8 step:8051 [D loss: 0.251719, acc.: 52.34%] [G loss: 0.304966]\n",
      "epoch:8 step:8052 [D loss: 0.255161, acc.: 56.25%] [G loss: 0.304697]\n",
      "epoch:8 step:8053 [D loss: 0.231063, acc.: 64.84%] [G loss: 0.300381]\n",
      "epoch:8 step:8054 [D loss: 0.242909, acc.: 53.91%] [G loss: 0.316177]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:8 step:8055 [D loss: 0.249067, acc.: 59.38%] [G loss: 0.291710]\n",
      "epoch:8 step:8056 [D loss: 0.231456, acc.: 60.94%] [G loss: 0.288083]\n",
      "epoch:8 step:8057 [D loss: 0.253565, acc.: 51.56%] [G loss: 0.294530]\n",
      "epoch:8 step:8058 [D loss: 0.245459, acc.: 51.56%] [G loss: 0.289860]\n",
      "epoch:8 step:8059 [D loss: 0.245726, acc.: 57.81%] [G loss: 0.301635]\n",
      "epoch:8 step:8060 [D loss: 0.236417, acc.: 58.59%] [G loss: 0.273234]\n",
      "epoch:8 step:8061 [D loss: 0.243774, acc.: 61.72%] [G loss: 0.291511]\n",
      "epoch:8 step:8062 [D loss: 0.246586, acc.: 53.91%] [G loss: 0.301767]\n",
      "epoch:8 step:8063 [D loss: 0.267331, acc.: 43.75%] [G loss: 0.275483]\n",
      "epoch:8 step:8064 [D loss: 0.242748, acc.: 53.91%] [G loss: 0.310575]\n",
      "epoch:8 step:8065 [D loss: 0.245015, acc.: 55.47%] [G loss: 0.277428]\n",
      "epoch:8 step:8066 [D loss: 0.250971, acc.: 52.34%] [G loss: 0.302163]\n",
      "epoch:8 step:8067 [D loss: 0.240536, acc.: 58.59%] [G loss: 0.325538]\n",
      "epoch:8 step:8068 [D loss: 0.227409, acc.: 64.84%] [G loss: 0.316094]\n",
      "epoch:8 step:8069 [D loss: 0.240667, acc.: 61.72%] [G loss: 0.293405]\n",
      "epoch:8 step:8070 [D loss: 0.236194, acc.: 58.59%] [G loss: 0.294122]\n",
      "epoch:8 step:8071 [D loss: 0.231540, acc.: 61.72%] [G loss: 0.316456]\n",
      "epoch:8 step:8072 [D loss: 0.239398, acc.: 57.03%] [G loss: 0.278224]\n",
      "epoch:8 step:8073 [D loss: 0.231188, acc.: 64.06%] [G loss: 0.304609]\n",
      "epoch:8 step:8074 [D loss: 0.241626, acc.: 57.81%] [G loss: 0.284171]\n",
      "epoch:8 step:8075 [D loss: 0.241763, acc.: 66.41%] [G loss: 0.312858]\n",
      "epoch:8 step:8076 [D loss: 0.245492, acc.: 58.59%] [G loss: 0.304595]\n",
      "epoch:8 step:8077 [D loss: 0.240473, acc.: 58.59%] [G loss: 0.301205]\n",
      "epoch:8 step:8078 [D loss: 0.224244, acc.: 66.41%] [G loss: 0.306435]\n",
      "epoch:8 step:8079 [D loss: 0.221656, acc.: 67.97%] [G loss: 0.281088]\n",
      "epoch:8 step:8080 [D loss: 0.233531, acc.: 61.72%] [G loss: 0.314178]\n",
      "epoch:8 step:8081 [D loss: 0.233706, acc.: 57.81%] [G loss: 0.335004]\n",
      "epoch:8 step:8082 [D loss: 0.233101, acc.: 57.81%] [G loss: 0.299298]\n",
      "epoch:8 step:8083 [D loss: 0.244114, acc.: 57.03%] [G loss: 0.309554]\n",
      "epoch:8 step:8084 [D loss: 0.251445, acc.: 51.56%] [G loss: 0.316644]\n",
      "epoch:8 step:8085 [D loss: 0.231118, acc.: 61.72%] [G loss: 0.292806]\n",
      "epoch:8 step:8086 [D loss: 0.237500, acc.: 56.25%] [G loss: 0.291371]\n",
      "epoch:8 step:8087 [D loss: 0.250146, acc.: 50.78%] [G loss: 0.279809]\n",
      "epoch:8 step:8088 [D loss: 0.253177, acc.: 54.69%] [G loss: 0.305776]\n",
      "epoch:8 step:8089 [D loss: 0.239059, acc.: 56.25%] [G loss: 0.282649]\n",
      "epoch:8 step:8090 [D loss: 0.232377, acc.: 62.50%] [G loss: 0.323892]\n",
      "epoch:8 step:8091 [D loss: 0.250200, acc.: 53.91%] [G loss: 0.312956]\n",
      "epoch:8 step:8092 [D loss: 0.223139, acc.: 65.62%] [G loss: 0.297182]\n",
      "epoch:8 step:8093 [D loss: 0.243010, acc.: 57.03%] [G loss: 0.305561]\n",
      "epoch:8 step:8094 [D loss: 0.236348, acc.: 60.94%] [G loss: 0.316919]\n",
      "epoch:8 step:8095 [D loss: 0.245587, acc.: 52.34%] [G loss: 0.279699]\n",
      "epoch:8 step:8096 [D loss: 0.237964, acc.: 55.47%] [G loss: 0.305460]\n",
      "epoch:8 step:8097 [D loss: 0.249238, acc.: 51.56%] [G loss: 0.341380]\n",
      "epoch:8 step:8098 [D loss: 0.234578, acc.: 62.50%] [G loss: 0.314485]\n",
      "epoch:8 step:8099 [D loss: 0.250665, acc.: 47.66%] [G loss: 0.315546]\n",
      "epoch:8 step:8100 [D loss: 0.260426, acc.: 48.44%] [G loss: 0.297197]\n",
      "epoch:8 step:8101 [D loss: 0.239545, acc.: 55.47%] [G loss: 0.286562]\n",
      "epoch:8 step:8102 [D loss: 0.251474, acc.: 53.12%] [G loss: 0.289933]\n",
      "epoch:8 step:8103 [D loss: 0.238362, acc.: 60.16%] [G loss: 0.323385]\n",
      "epoch:8 step:8104 [D loss: 0.243799, acc.: 57.03%] [G loss: 0.314519]\n",
      "epoch:8 step:8105 [D loss: 0.240975, acc.: 57.81%] [G loss: 0.285918]\n",
      "epoch:8 step:8106 [D loss: 0.239192, acc.: 56.25%] [G loss: 0.296215]\n",
      "epoch:8 step:8107 [D loss: 0.244447, acc.: 60.16%] [G loss: 0.304261]\n",
      "epoch:8 step:8108 [D loss: 0.240344, acc.: 54.69%] [G loss: 0.320214]\n",
      "epoch:8 step:8109 [D loss: 0.232255, acc.: 60.94%] [G loss: 0.314212]\n",
      "epoch:8 step:8110 [D loss: 0.232366, acc.: 60.94%] [G loss: 0.313696]\n",
      "epoch:8 step:8111 [D loss: 0.243855, acc.: 57.81%] [G loss: 0.299874]\n",
      "epoch:8 step:8112 [D loss: 0.233462, acc.: 60.94%] [G loss: 0.288315]\n",
      "epoch:8 step:8113 [D loss: 0.257198, acc.: 50.00%] [G loss: 0.316418]\n",
      "epoch:8 step:8114 [D loss: 0.226198, acc.: 61.72%] [G loss: 0.324364]\n",
      "epoch:8 step:8115 [D loss: 0.234324, acc.: 58.59%] [G loss: 0.327127]\n",
      "epoch:8 step:8116 [D loss: 0.241833, acc.: 56.25%] [G loss: 0.307326]\n",
      "epoch:8 step:8117 [D loss: 0.233196, acc.: 60.16%] [G loss: 0.298552]\n",
      "epoch:8 step:8118 [D loss: 0.248638, acc.: 53.12%] [G loss: 0.311371]\n",
      "epoch:8 step:8119 [D loss: 0.247665, acc.: 57.81%] [G loss: 0.298433]\n",
      "epoch:8 step:8120 [D loss: 0.246601, acc.: 53.91%] [G loss: 0.291725]\n",
      "epoch:8 step:8121 [D loss: 0.240301, acc.: 60.16%] [G loss: 0.318124]\n",
      "epoch:8 step:8122 [D loss: 0.232444, acc.: 61.72%] [G loss: 0.277968]\n",
      "epoch:8 step:8123 [D loss: 0.220948, acc.: 64.06%] [G loss: 0.316136]\n",
      "epoch:8 step:8124 [D loss: 0.243049, acc.: 55.47%] [G loss: 0.323859]\n",
      "epoch:8 step:8125 [D loss: 0.226106, acc.: 60.16%] [G loss: 0.319547]\n",
      "epoch:8 step:8126 [D loss: 0.250171, acc.: 55.47%] [G loss: 0.296221]\n",
      "epoch:8 step:8127 [D loss: 0.220091, acc.: 65.62%] [G loss: 0.307162]\n",
      "epoch:8 step:8128 [D loss: 0.246708, acc.: 53.12%] [G loss: 0.296613]\n",
      "epoch:8 step:8129 [D loss: 0.247051, acc.: 51.56%] [G loss: 0.299372]\n",
      "epoch:8 step:8130 [D loss: 0.238343, acc.: 60.16%] [G loss: 0.298235]\n",
      "epoch:8 step:8131 [D loss: 0.245034, acc.: 55.47%] [G loss: 0.297628]\n",
      "epoch:8 step:8132 [D loss: 0.234665, acc.: 60.16%] [G loss: 0.305563]\n",
      "epoch:8 step:8133 [D loss: 0.228080, acc.: 66.41%] [G loss: 0.304081]\n",
      "epoch:8 step:8134 [D loss: 0.235632, acc.: 60.94%] [G loss: 0.313090]\n",
      "epoch:8 step:8135 [D loss: 0.250834, acc.: 46.88%] [G loss: 0.300818]\n",
      "epoch:8 step:8136 [D loss: 0.253935, acc.: 53.91%] [G loss: 0.305307]\n",
      "epoch:8 step:8137 [D loss: 0.240871, acc.: 57.03%] [G loss: 0.295011]\n",
      "epoch:8 step:8138 [D loss: 0.233067, acc.: 60.94%] [G loss: 0.311353]\n",
      "epoch:8 step:8139 [D loss: 0.247078, acc.: 54.69%] [G loss: 0.292666]\n",
      "epoch:8 step:8140 [D loss: 0.253580, acc.: 55.47%] [G loss: 0.288999]\n",
      "epoch:8 step:8141 [D loss: 0.243729, acc.: 53.91%] [G loss: 0.311246]\n",
      "epoch:8 step:8142 [D loss: 0.240634, acc.: 50.00%] [G loss: 0.297232]\n",
      "epoch:8 step:8143 [D loss: 0.250662, acc.: 53.91%] [G loss: 0.278960]\n",
      "epoch:8 step:8144 [D loss: 0.244121, acc.: 54.69%] [G loss: 0.313159]\n",
      "epoch:8 step:8145 [D loss: 0.247598, acc.: 57.03%] [G loss: 0.286615]\n",
      "epoch:8 step:8146 [D loss: 0.235716, acc.: 57.03%] [G loss: 0.313966]\n",
      "epoch:8 step:8147 [D loss: 0.229272, acc.: 58.59%] [G loss: 0.298577]\n",
      "epoch:8 step:8148 [D loss: 0.240830, acc.: 57.81%] [G loss: 0.288375]\n",
      "epoch:8 step:8149 [D loss: 0.241052, acc.: 55.47%] [G loss: 0.272623]\n",
      "epoch:8 step:8150 [D loss: 0.226232, acc.: 61.72%] [G loss: 0.306893]\n",
      "epoch:8 step:8151 [D loss: 0.252398, acc.: 53.91%] [G loss: 0.261554]\n",
      "epoch:8 step:8152 [D loss: 0.213663, acc.: 67.19%] [G loss: 0.296745]\n",
      "epoch:8 step:8153 [D loss: 0.256828, acc.: 49.22%] [G loss: 0.290366]\n",
      "epoch:8 step:8154 [D loss: 0.242285, acc.: 54.69%] [G loss: 0.272691]\n",
      "epoch:8 step:8155 [D loss: 0.237264, acc.: 57.03%] [G loss: 0.319408]\n",
      "epoch:8 step:8156 [D loss: 0.233209, acc.: 62.50%] [G loss: 0.294949]\n",
      "epoch:8 step:8157 [D loss: 0.230551, acc.: 62.50%] [G loss: 0.299200]\n",
      "epoch:8 step:8158 [D loss: 0.236150, acc.: 62.50%] [G loss: 0.293391]\n",
      "epoch:8 step:8159 [D loss: 0.242506, acc.: 57.81%] [G loss: 0.275418]\n",
      "epoch:8 step:8160 [D loss: 0.234267, acc.: 57.81%] [G loss: 0.318399]\n",
      "epoch:8 step:8161 [D loss: 0.250482, acc.: 53.12%] [G loss: 0.318276]\n",
      "epoch:8 step:8162 [D loss: 0.247061, acc.: 55.47%] [G loss: 0.314414]\n",
      "epoch:8 step:8163 [D loss: 0.260119, acc.: 51.56%] [G loss: 0.295319]\n",
      "epoch:8 step:8164 [D loss: 0.236553, acc.: 57.03%] [G loss: 0.293239]\n",
      "epoch:8 step:8165 [D loss: 0.235609, acc.: 57.81%] [G loss: 0.282669]\n",
      "epoch:8 step:8166 [D loss: 0.233672, acc.: 60.16%] [G loss: 0.304112]\n",
      "epoch:8 step:8167 [D loss: 0.255522, acc.: 56.25%] [G loss: 0.275533]\n",
      "epoch:8 step:8168 [D loss: 0.224349, acc.: 63.28%] [G loss: 0.312459]\n",
      "epoch:8 step:8169 [D loss: 0.251889, acc.: 55.47%] [G loss: 0.313295]\n",
      "epoch:8 step:8170 [D loss: 0.234597, acc.: 59.38%] [G loss: 0.298993]\n",
      "epoch:8 step:8171 [D loss: 0.258490, acc.: 50.00%] [G loss: 0.277305]\n",
      "epoch:8 step:8172 [D loss: 0.246608, acc.: 57.03%] [G loss: 0.307188]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:8 step:8173 [D loss: 0.246041, acc.: 57.03%] [G loss: 0.301099]\n",
      "epoch:8 step:8174 [D loss: 0.234823, acc.: 57.03%] [G loss: 0.303583]\n",
      "epoch:8 step:8175 [D loss: 0.245989, acc.: 54.69%] [G loss: 0.320648]\n",
      "epoch:8 step:8176 [D loss: 0.237989, acc.: 54.69%] [G loss: 0.308268]\n",
      "epoch:8 step:8177 [D loss: 0.256028, acc.: 50.00%] [G loss: 0.289173]\n",
      "epoch:8 step:8178 [D loss: 0.236972, acc.: 57.81%] [G loss: 0.289625]\n",
      "epoch:8 step:8179 [D loss: 0.237305, acc.: 61.72%] [G loss: 0.294826]\n",
      "epoch:8 step:8180 [D loss: 0.240652, acc.: 57.81%] [G loss: 0.294841]\n",
      "epoch:8 step:8181 [D loss: 0.236946, acc.: 60.16%] [G loss: 0.324197]\n",
      "epoch:8 step:8182 [D loss: 0.257973, acc.: 54.69%] [G loss: 0.283284]\n",
      "epoch:8 step:8183 [D loss: 0.251818, acc.: 57.03%] [G loss: 0.277747]\n",
      "epoch:8 step:8184 [D loss: 0.240093, acc.: 60.16%] [G loss: 0.320489]\n",
      "epoch:8 step:8185 [D loss: 0.236213, acc.: 59.38%] [G loss: 0.289826]\n",
      "epoch:8 step:8186 [D loss: 0.247973, acc.: 56.25%] [G loss: 0.299136]\n",
      "epoch:8 step:8187 [D loss: 0.255440, acc.: 47.66%] [G loss: 0.303833]\n",
      "epoch:8 step:8188 [D loss: 0.250747, acc.: 54.69%] [G loss: 0.308882]\n",
      "epoch:8 step:8189 [D loss: 0.256426, acc.: 53.12%] [G loss: 0.289621]\n",
      "epoch:8 step:8190 [D loss: 0.237457, acc.: 57.81%] [G loss: 0.285281]\n",
      "epoch:8 step:8191 [D loss: 0.242825, acc.: 60.94%] [G loss: 0.292503]\n",
      "epoch:8 step:8192 [D loss: 0.231492, acc.: 60.16%] [G loss: 0.314008]\n",
      "epoch:8 step:8193 [D loss: 0.244786, acc.: 57.03%] [G loss: 0.303603]\n",
      "epoch:8 step:8194 [D loss: 0.245695, acc.: 53.12%] [G loss: 0.291887]\n",
      "epoch:8 step:8195 [D loss: 0.249213, acc.: 57.81%] [G loss: 0.289430]\n",
      "epoch:8 step:8196 [D loss: 0.240322, acc.: 57.81%] [G loss: 0.308919]\n",
      "epoch:8 step:8197 [D loss: 0.217276, acc.: 67.19%] [G loss: 0.284308]\n",
      "epoch:8 step:8198 [D loss: 0.243994, acc.: 55.47%] [G loss: 0.278314]\n",
      "epoch:8 step:8199 [D loss: 0.226270, acc.: 68.75%] [G loss: 0.292124]\n",
      "epoch:8 step:8200 [D loss: 0.257764, acc.: 53.91%] [G loss: 0.281157]\n",
      "epoch:8 step:8201 [D loss: 0.251998, acc.: 56.25%] [G loss: 0.287341]\n",
      "epoch:8 step:8202 [D loss: 0.254386, acc.: 51.56%] [G loss: 0.307284]\n",
      "epoch:8 step:8203 [D loss: 0.229583, acc.: 60.94%] [G loss: 0.296090]\n",
      "epoch:8 step:8204 [D loss: 0.244633, acc.: 56.25%] [G loss: 0.284697]\n",
      "epoch:8 step:8205 [D loss: 0.269025, acc.: 51.56%] [G loss: 0.279126]\n",
      "epoch:8 step:8206 [D loss: 0.237527, acc.: 58.59%] [G loss: 0.287968]\n",
      "epoch:8 step:8207 [D loss: 0.235312, acc.: 56.25%] [G loss: 0.285593]\n",
      "epoch:8 step:8208 [D loss: 0.248321, acc.: 56.25%] [G loss: 0.298665]\n",
      "epoch:8 step:8209 [D loss: 0.245447, acc.: 57.81%] [G loss: 0.287251]\n",
      "epoch:8 step:8210 [D loss: 0.263970, acc.: 46.88%] [G loss: 0.278695]\n",
      "epoch:8 step:8211 [D loss: 0.245473, acc.: 51.56%] [G loss: 0.325379]\n",
      "epoch:8 step:8212 [D loss: 0.232224, acc.: 60.16%] [G loss: 0.311387]\n",
      "epoch:8 step:8213 [D loss: 0.236015, acc.: 56.25%] [G loss: 0.285510]\n",
      "epoch:8 step:8214 [D loss: 0.225507, acc.: 62.50%] [G loss: 0.306799]\n",
      "epoch:8 step:8215 [D loss: 0.242777, acc.: 60.16%] [G loss: 0.305427]\n",
      "epoch:8 step:8216 [D loss: 0.251295, acc.: 57.03%] [G loss: 0.297891]\n",
      "epoch:8 step:8217 [D loss: 0.232574, acc.: 60.16%] [G loss: 0.307009]\n",
      "epoch:8 step:8218 [D loss: 0.242858, acc.: 59.38%] [G loss: 0.282010]\n",
      "epoch:8 step:8219 [D loss: 0.247765, acc.: 55.47%] [G loss: 0.308299]\n",
      "epoch:8 step:8220 [D loss: 0.250309, acc.: 53.12%] [G loss: 0.307363]\n",
      "epoch:8 step:8221 [D loss: 0.232489, acc.: 59.38%] [G loss: 0.296760]\n",
      "epoch:8 step:8222 [D loss: 0.260485, acc.: 49.22%] [G loss: 0.294585]\n",
      "epoch:8 step:8223 [D loss: 0.241845, acc.: 53.12%] [G loss: 0.287755]\n",
      "epoch:8 step:8224 [D loss: 0.238885, acc.: 57.81%] [G loss: 0.297014]\n",
      "epoch:8 step:8225 [D loss: 0.243852, acc.: 53.91%] [G loss: 0.283629]\n",
      "epoch:8 step:8226 [D loss: 0.249774, acc.: 50.78%] [G loss: 0.282918]\n",
      "epoch:8 step:8227 [D loss: 0.252774, acc.: 56.25%] [G loss: 0.318282]\n",
      "epoch:8 step:8228 [D loss: 0.243884, acc.: 55.47%] [G loss: 0.294025]\n",
      "epoch:8 step:8229 [D loss: 0.256966, acc.: 46.88%] [G loss: 0.281644]\n",
      "epoch:8 step:8230 [D loss: 0.235025, acc.: 57.81%] [G loss: 0.283337]\n",
      "epoch:8 step:8231 [D loss: 0.252373, acc.: 51.56%] [G loss: 0.298980]\n",
      "epoch:8 step:8232 [D loss: 0.242037, acc.: 60.94%] [G loss: 0.294934]\n",
      "epoch:8 step:8233 [D loss: 0.259122, acc.: 45.31%] [G loss: 0.295322]\n",
      "epoch:8 step:8234 [D loss: 0.254481, acc.: 52.34%] [G loss: 0.327888]\n",
      "epoch:8 step:8235 [D loss: 0.237348, acc.: 60.16%] [G loss: 0.296695]\n",
      "epoch:8 step:8236 [D loss: 0.242240, acc.: 60.94%] [G loss: 0.287557]\n",
      "epoch:8 step:8237 [D loss: 0.244133, acc.: 57.03%] [G loss: 0.316387]\n",
      "epoch:8 step:8238 [D loss: 0.236946, acc.: 60.94%] [G loss: 0.291154]\n",
      "epoch:8 step:8239 [D loss: 0.258808, acc.: 53.12%] [G loss: 0.295591]\n",
      "epoch:8 step:8240 [D loss: 0.241371, acc.: 57.81%] [G loss: 0.308863]\n",
      "epoch:8 step:8241 [D loss: 0.263054, acc.: 51.56%] [G loss: 0.306468]\n",
      "epoch:8 step:8242 [D loss: 0.245313, acc.: 58.59%] [G loss: 0.295895]\n",
      "epoch:8 step:8243 [D loss: 0.237188, acc.: 57.03%] [G loss: 0.287650]\n",
      "epoch:8 step:8244 [D loss: 0.248819, acc.: 57.03%] [G loss: 0.307263]\n",
      "epoch:8 step:8245 [D loss: 0.233123, acc.: 62.50%] [G loss: 0.299118]\n",
      "epoch:8 step:8246 [D loss: 0.242398, acc.: 60.94%] [G loss: 0.311777]\n",
      "epoch:8 step:8247 [D loss: 0.225150, acc.: 67.19%] [G loss: 0.279778]\n",
      "epoch:8 step:8248 [D loss: 0.243740, acc.: 57.03%] [G loss: 0.279589]\n",
      "epoch:8 step:8249 [D loss: 0.251002, acc.: 54.69%] [G loss: 0.294429]\n",
      "epoch:8 step:8250 [D loss: 0.238632, acc.: 60.94%] [G loss: 0.306758]\n",
      "epoch:8 step:8251 [D loss: 0.235073, acc.: 57.81%] [G loss: 0.290256]\n",
      "epoch:8 step:8252 [D loss: 0.241333, acc.: 59.38%] [G loss: 0.289363]\n",
      "epoch:8 step:8253 [D loss: 0.230695, acc.: 60.16%] [G loss: 0.296297]\n",
      "epoch:8 step:8254 [D loss: 0.238053, acc.: 58.59%] [G loss: 0.299408]\n",
      "epoch:8 step:8255 [D loss: 0.241490, acc.: 57.03%] [G loss: 0.305188]\n",
      "epoch:8 step:8256 [D loss: 0.230725, acc.: 62.50%] [G loss: 0.294431]\n",
      "epoch:8 step:8257 [D loss: 0.247831, acc.: 50.78%] [G loss: 0.320733]\n",
      "epoch:8 step:8258 [D loss: 0.249428, acc.: 55.47%] [G loss: 0.303590]\n",
      "epoch:8 step:8259 [D loss: 0.233789, acc.: 59.38%] [G loss: 0.299494]\n",
      "epoch:8 step:8260 [D loss: 0.240906, acc.: 57.81%] [G loss: 0.289178]\n",
      "epoch:8 step:8261 [D loss: 0.241569, acc.: 57.03%] [G loss: 0.296260]\n",
      "epoch:8 step:8262 [D loss: 0.225342, acc.: 63.28%] [G loss: 0.321444]\n",
      "epoch:8 step:8263 [D loss: 0.240929, acc.: 54.69%] [G loss: 0.315071]\n",
      "epoch:8 step:8264 [D loss: 0.245531, acc.: 56.25%] [G loss: 0.306316]\n",
      "epoch:8 step:8265 [D loss: 0.232494, acc.: 64.06%] [G loss: 0.310137]\n",
      "epoch:8 step:8266 [D loss: 0.247223, acc.: 59.38%] [G loss: 0.294540]\n",
      "epoch:8 step:8267 [D loss: 0.248326, acc.: 54.69%] [G loss: 0.279572]\n",
      "epoch:8 step:8268 [D loss: 0.237008, acc.: 60.94%] [G loss: 0.261925]\n",
      "epoch:8 step:8269 [D loss: 0.254592, acc.: 50.00%] [G loss: 0.307853]\n",
      "epoch:8 step:8270 [D loss: 0.238317, acc.: 60.94%] [G loss: 0.300026]\n",
      "epoch:8 step:8271 [D loss: 0.247215, acc.: 54.69%] [G loss: 0.321230]\n",
      "epoch:8 step:8272 [D loss: 0.244643, acc.: 58.59%] [G loss: 0.277454]\n",
      "epoch:8 step:8273 [D loss: 0.239820, acc.: 56.25%] [G loss: 0.302237]\n",
      "epoch:8 step:8274 [D loss: 0.248529, acc.: 52.34%] [G loss: 0.267375]\n",
      "epoch:8 step:8275 [D loss: 0.236704, acc.: 60.94%] [G loss: 0.286549]\n",
      "epoch:8 step:8276 [D loss: 0.253446, acc.: 50.78%] [G loss: 0.284772]\n",
      "epoch:8 step:8277 [D loss: 0.251914, acc.: 55.47%] [G loss: 0.297461]\n",
      "epoch:8 step:8278 [D loss: 0.247022, acc.: 53.12%] [G loss: 0.279684]\n",
      "epoch:8 step:8279 [D loss: 0.242898, acc.: 54.69%] [G loss: 0.308560]\n",
      "epoch:8 step:8280 [D loss: 0.223434, acc.: 61.72%] [G loss: 0.276961]\n",
      "epoch:8 step:8281 [D loss: 0.240869, acc.: 61.72%] [G loss: 0.281978]\n",
      "epoch:8 step:8282 [D loss: 0.232803, acc.: 60.94%] [G loss: 0.311524]\n",
      "epoch:8 step:8283 [D loss: 0.229016, acc.: 64.84%] [G loss: 0.304491]\n",
      "epoch:8 step:8284 [D loss: 0.237961, acc.: 54.69%] [G loss: 0.310565]\n",
      "epoch:8 step:8285 [D loss: 0.224671, acc.: 65.62%] [G loss: 0.311303]\n",
      "epoch:8 step:8286 [D loss: 0.244216, acc.: 54.69%] [G loss: 0.291746]\n",
      "epoch:8 step:8287 [D loss: 0.229879, acc.: 57.81%] [G loss: 0.309370]\n",
      "epoch:8 step:8288 [D loss: 0.239894, acc.: 58.59%] [G loss: 0.297932]\n",
      "epoch:8 step:8289 [D loss: 0.229555, acc.: 62.50%] [G loss: 0.315160]\n",
      "epoch:8 step:8290 [D loss: 0.257878, acc.: 50.78%] [G loss: 0.320610]\n",
      "epoch:8 step:8291 [D loss: 0.239552, acc.: 54.69%] [G loss: 0.277895]\n",
      "epoch:8 step:8292 [D loss: 0.251117, acc.: 50.00%] [G loss: 0.256288]\n",
      "epoch:8 step:8293 [D loss: 0.234995, acc.: 60.16%] [G loss: 0.334254]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:8 step:8294 [D loss: 0.238146, acc.: 60.94%] [G loss: 0.289355]\n",
      "epoch:8 step:8295 [D loss: 0.241133, acc.: 60.94%] [G loss: 0.272752]\n",
      "epoch:8 step:8296 [D loss: 0.223765, acc.: 62.50%] [G loss: 0.300923]\n",
      "epoch:8 step:8297 [D loss: 0.237487, acc.: 55.47%] [G loss: 0.305055]\n",
      "epoch:8 step:8298 [D loss: 0.239709, acc.: 62.50%] [G loss: 0.280344]\n",
      "epoch:8 step:8299 [D loss: 0.250700, acc.: 52.34%] [G loss: 0.262940]\n",
      "epoch:8 step:8300 [D loss: 0.240927, acc.: 55.47%] [G loss: 0.297758]\n",
      "epoch:8 step:8301 [D loss: 0.230322, acc.: 57.81%] [G loss: 0.292653]\n",
      "epoch:8 step:8302 [D loss: 0.234562, acc.: 60.16%] [G loss: 0.293475]\n",
      "epoch:8 step:8303 [D loss: 0.235378, acc.: 61.72%] [G loss: 0.293164]\n",
      "epoch:8 step:8304 [D loss: 0.229579, acc.: 60.16%] [G loss: 0.291123]\n",
      "epoch:8 step:8305 [D loss: 0.236587, acc.: 57.81%] [G loss: 0.299854]\n",
      "epoch:8 step:8306 [D loss: 0.249156, acc.: 57.03%] [G loss: 0.275263]\n",
      "epoch:8 step:8307 [D loss: 0.242407, acc.: 55.47%] [G loss: 0.309509]\n",
      "epoch:8 step:8308 [D loss: 0.233011, acc.: 64.06%] [G loss: 0.297289]\n",
      "epoch:8 step:8309 [D loss: 0.242857, acc.: 60.16%] [G loss: 0.309532]\n",
      "epoch:8 step:8310 [D loss: 0.241531, acc.: 57.81%] [G loss: 0.318682]\n",
      "epoch:8 step:8311 [D loss: 0.261400, acc.: 50.78%] [G loss: 0.303982]\n",
      "epoch:8 step:8312 [D loss: 0.237431, acc.: 58.59%] [G loss: 0.327793]\n",
      "epoch:8 step:8313 [D loss: 0.237929, acc.: 67.97%] [G loss: 0.318883]\n",
      "epoch:8 step:8314 [D loss: 0.240929, acc.: 54.69%] [G loss: 0.294024]\n",
      "epoch:8 step:8315 [D loss: 0.245278, acc.: 60.16%] [G loss: 0.284540]\n",
      "epoch:8 step:8316 [D loss: 0.257933, acc.: 48.44%] [G loss: 0.287190]\n",
      "epoch:8 step:8317 [D loss: 0.265167, acc.: 55.47%] [G loss: 0.284029]\n",
      "epoch:8 step:8318 [D loss: 0.239160, acc.: 57.03%] [G loss: 0.335140]\n",
      "epoch:8 step:8319 [D loss: 0.252355, acc.: 51.56%] [G loss: 0.295749]\n",
      "epoch:8 step:8320 [D loss: 0.250493, acc.: 49.22%] [G loss: 0.304466]\n",
      "epoch:8 step:8321 [D loss: 0.236264, acc.: 60.16%] [G loss: 0.310996]\n",
      "epoch:8 step:8322 [D loss: 0.241452, acc.: 57.03%] [G loss: 0.306475]\n",
      "epoch:8 step:8323 [D loss: 0.244287, acc.: 54.69%] [G loss: 0.306003]\n",
      "epoch:8 step:8324 [D loss: 0.245233, acc.: 54.69%] [G loss: 0.315693]\n",
      "epoch:8 step:8325 [D loss: 0.235962, acc.: 63.28%] [G loss: 0.305045]\n",
      "epoch:8 step:8326 [D loss: 0.247329, acc.: 54.69%] [G loss: 0.316539]\n",
      "epoch:8 step:8327 [D loss: 0.236815, acc.: 57.81%] [G loss: 0.275305]\n",
      "epoch:8 step:8328 [D loss: 0.217974, acc.: 67.97%] [G loss: 0.280071]\n",
      "epoch:8 step:8329 [D loss: 0.234647, acc.: 61.72%] [G loss: 0.305545]\n",
      "epoch:8 step:8330 [D loss: 0.259702, acc.: 53.91%] [G loss: 0.322481]\n",
      "epoch:8 step:8331 [D loss: 0.250336, acc.: 56.25%] [G loss: 0.273421]\n",
      "epoch:8 step:8332 [D loss: 0.241083, acc.: 55.47%] [G loss: 0.295280]\n",
      "epoch:8 step:8333 [D loss: 0.247082, acc.: 57.81%] [G loss: 0.294756]\n",
      "epoch:8 step:8334 [D loss: 0.244171, acc.: 54.69%] [G loss: 0.275526]\n",
      "epoch:8 step:8335 [D loss: 0.251988, acc.: 54.69%] [G loss: 0.290901]\n",
      "epoch:8 step:8336 [D loss: 0.235319, acc.: 56.25%] [G loss: 0.306262]\n",
      "epoch:8 step:8337 [D loss: 0.233204, acc.: 57.81%] [G loss: 0.278539]\n",
      "epoch:8 step:8338 [D loss: 0.258972, acc.: 52.34%] [G loss: 0.294755]\n",
      "epoch:8 step:8339 [D loss: 0.255745, acc.: 51.56%] [G loss: 0.285467]\n",
      "epoch:8 step:8340 [D loss: 0.238733, acc.: 57.03%] [G loss: 0.297611]\n",
      "epoch:8 step:8341 [D loss: 0.240984, acc.: 59.38%] [G loss: 0.292374]\n",
      "epoch:8 step:8342 [D loss: 0.257726, acc.: 53.91%] [G loss: 0.335990]\n",
      "epoch:8 step:8343 [D loss: 0.235831, acc.: 62.50%] [G loss: 0.315394]\n",
      "epoch:8 step:8344 [D loss: 0.239694, acc.: 61.72%] [G loss: 0.300850]\n",
      "epoch:8 step:8345 [D loss: 0.246541, acc.: 53.12%] [G loss: 0.316259]\n",
      "epoch:8 step:8346 [D loss: 0.259949, acc.: 50.78%] [G loss: 0.324252]\n",
      "epoch:8 step:8347 [D loss: 0.249351, acc.: 57.03%] [G loss: 0.307335]\n",
      "epoch:8 step:8348 [D loss: 0.244446, acc.: 51.56%] [G loss: 0.293520]\n",
      "epoch:8 step:8349 [D loss: 0.230367, acc.: 64.06%] [G loss: 0.304694]\n",
      "epoch:8 step:8350 [D loss: 0.238493, acc.: 58.59%] [G loss: 0.265269]\n",
      "epoch:8 step:8351 [D loss: 0.251765, acc.: 57.03%] [G loss: 0.268559]\n",
      "epoch:8 step:8352 [D loss: 0.218275, acc.: 67.19%] [G loss: 0.316758]\n",
      "epoch:8 step:8353 [D loss: 0.252762, acc.: 48.44%] [G loss: 0.297798]\n",
      "epoch:8 step:8354 [D loss: 0.242073, acc.: 55.47%] [G loss: 0.285462]\n",
      "epoch:8 step:8355 [D loss: 0.239499, acc.: 60.16%] [G loss: 0.295412]\n",
      "epoch:8 step:8356 [D loss: 0.228305, acc.: 63.28%] [G loss: 0.326826]\n",
      "epoch:8 step:8357 [D loss: 0.240603, acc.: 57.03%] [G loss: 0.299152]\n",
      "epoch:8 step:8358 [D loss: 0.245159, acc.: 57.03%] [G loss: 0.306976]\n",
      "epoch:8 step:8359 [D loss: 0.238689, acc.: 59.38%] [G loss: 0.306188]\n",
      "epoch:8 step:8360 [D loss: 0.241981, acc.: 59.38%] [G loss: 0.272102]\n",
      "epoch:8 step:8361 [D loss: 0.250336, acc.: 53.12%] [G loss: 0.319492]\n",
      "epoch:8 step:8362 [D loss: 0.226944, acc.: 66.41%] [G loss: 0.315820]\n",
      "epoch:8 step:8363 [D loss: 0.220068, acc.: 69.53%] [G loss: 0.299307]\n",
      "epoch:8 step:8364 [D loss: 0.249616, acc.: 53.12%] [G loss: 0.272585]\n",
      "epoch:8 step:8365 [D loss: 0.234556, acc.: 59.38%] [G loss: 0.281607]\n",
      "epoch:8 step:8366 [D loss: 0.228155, acc.: 60.94%] [G loss: 0.300254]\n",
      "epoch:8 step:8367 [D loss: 0.253877, acc.: 47.66%] [G loss: 0.276939]\n",
      "epoch:8 step:8368 [D loss: 0.247288, acc.: 60.94%] [G loss: 0.286000]\n",
      "epoch:8 step:8369 [D loss: 0.227116, acc.: 64.84%] [G loss: 0.301678]\n",
      "epoch:8 step:8370 [D loss: 0.240234, acc.: 51.56%] [G loss: 0.322932]\n",
      "epoch:8 step:8371 [D loss: 0.222624, acc.: 64.84%] [G loss: 0.302256]\n",
      "epoch:8 step:8372 [D loss: 0.250614, acc.: 57.81%] [G loss: 0.316220]\n",
      "epoch:8 step:8373 [D loss: 0.257192, acc.: 47.66%] [G loss: 0.297805]\n",
      "epoch:8 step:8374 [D loss: 0.240425, acc.: 53.91%] [G loss: 0.312802]\n",
      "epoch:8 step:8375 [D loss: 0.244349, acc.: 57.81%] [G loss: 0.303239]\n",
      "epoch:8 step:8376 [D loss: 0.242085, acc.: 57.03%] [G loss: 0.288712]\n",
      "epoch:8 step:8377 [D loss: 0.244263, acc.: 58.59%] [G loss: 0.274668]\n",
      "epoch:8 step:8378 [D loss: 0.233320, acc.: 55.47%] [G loss: 0.279073]\n",
      "epoch:8 step:8379 [D loss: 0.251753, acc.: 56.25%] [G loss: 0.298948]\n",
      "epoch:8 step:8380 [D loss: 0.227075, acc.: 61.72%] [G loss: 0.306236]\n",
      "epoch:8 step:8381 [D loss: 0.232628, acc.: 57.81%] [G loss: 0.283283]\n",
      "epoch:8 step:8382 [D loss: 0.245119, acc.: 56.25%] [G loss: 0.317504]\n",
      "epoch:8 step:8383 [D loss: 0.239197, acc.: 60.16%] [G loss: 0.302238]\n",
      "epoch:8 step:8384 [D loss: 0.243565, acc.: 59.38%] [G loss: 0.301894]\n",
      "epoch:8 step:8385 [D loss: 0.230091, acc.: 60.16%] [G loss: 0.298980]\n",
      "epoch:8 step:8386 [D loss: 0.238668, acc.: 60.94%] [G loss: 0.283677]\n",
      "epoch:8 step:8387 [D loss: 0.237398, acc.: 60.16%] [G loss: 0.315148]\n",
      "epoch:8 step:8388 [D loss: 0.243795, acc.: 58.59%] [G loss: 0.273337]\n",
      "epoch:8 step:8389 [D loss: 0.254462, acc.: 50.78%] [G loss: 0.288549]\n",
      "epoch:8 step:8390 [D loss: 0.255484, acc.: 49.22%] [G loss: 0.284251]\n",
      "epoch:8 step:8391 [D loss: 0.240940, acc.: 53.91%] [G loss: 0.301153]\n",
      "epoch:8 step:8392 [D loss: 0.248667, acc.: 50.00%] [G loss: 0.292997]\n",
      "epoch:8 step:8393 [D loss: 0.240717, acc.: 58.59%] [G loss: 0.309991]\n",
      "epoch:8 step:8394 [D loss: 0.240778, acc.: 57.03%] [G loss: 0.306066]\n",
      "epoch:8 step:8395 [D loss: 0.247693, acc.: 58.59%] [G loss: 0.326763]\n",
      "epoch:8 step:8396 [D loss: 0.237465, acc.: 63.28%] [G loss: 0.310154]\n",
      "epoch:8 step:8397 [D loss: 0.235792, acc.: 59.38%] [G loss: 0.301890]\n",
      "epoch:8 step:8398 [D loss: 0.239223, acc.: 59.38%] [G loss: 0.291223]\n",
      "epoch:8 step:8399 [D loss: 0.227958, acc.: 61.72%] [G loss: 0.285199]\n",
      "epoch:8 step:8400 [D loss: 0.241444, acc.: 57.03%] [G loss: 0.309101]\n",
      "epoch:8 step:8401 [D loss: 0.253617, acc.: 48.44%] [G loss: 0.280466]\n",
      "epoch:8 step:8402 [D loss: 0.246166, acc.: 53.91%] [G loss: 0.298024]\n",
      "epoch:8 step:8403 [D loss: 0.243054, acc.: 57.03%] [G loss: 0.303243]\n",
      "epoch:8 step:8404 [D loss: 0.243904, acc.: 58.59%] [G loss: 0.270658]\n",
      "epoch:8 step:8405 [D loss: 0.253306, acc.: 57.81%] [G loss: 0.287745]\n",
      "epoch:8 step:8406 [D loss: 0.250432, acc.: 54.69%] [G loss: 0.292032]\n",
      "epoch:8 step:8407 [D loss: 0.233302, acc.: 60.94%] [G loss: 0.291504]\n",
      "epoch:8 step:8408 [D loss: 0.234821, acc.: 65.62%] [G loss: 0.283264]\n",
      "epoch:8 step:8409 [D loss: 0.233879, acc.: 59.38%] [G loss: 0.276130]\n",
      "epoch:8 step:8410 [D loss: 0.240051, acc.: 57.81%] [G loss: 0.296842]\n",
      "epoch:8 step:8411 [D loss: 0.246707, acc.: 57.03%] [G loss: 0.287917]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:8 step:8412 [D loss: 0.230863, acc.: 58.59%] [G loss: 0.273634]\n",
      "epoch:8 step:8413 [D loss: 0.227861, acc.: 63.28%] [G loss: 0.337062]\n",
      "epoch:8 step:8414 [D loss: 0.247684, acc.: 57.81%] [G loss: 0.275982]\n",
      "epoch:8 step:8415 [D loss: 0.236116, acc.: 59.38%] [G loss: 0.281895]\n",
      "epoch:8 step:8416 [D loss: 0.243099, acc.: 57.81%] [G loss: 0.281119]\n",
      "epoch:8 step:8417 [D loss: 0.247516, acc.: 54.69%] [G loss: 0.300797]\n",
      "epoch:8 step:8418 [D loss: 0.250667, acc.: 56.25%] [G loss: 0.292171]\n",
      "epoch:8 step:8419 [D loss: 0.246524, acc.: 48.44%] [G loss: 0.293564]\n",
      "epoch:8 step:8420 [D loss: 0.233247, acc.: 60.16%] [G loss: 0.300392]\n",
      "epoch:8 step:8421 [D loss: 0.244258, acc.: 60.16%] [G loss: 0.292848]\n",
      "epoch:8 step:8422 [D loss: 0.245670, acc.: 60.94%] [G loss: 0.318326]\n",
      "epoch:8 step:8423 [D loss: 0.253183, acc.: 51.56%] [G loss: 0.296254]\n",
      "epoch:8 step:8424 [D loss: 0.241333, acc.: 56.25%] [G loss: 0.300486]\n",
      "epoch:8 step:8425 [D loss: 0.250714, acc.: 53.91%] [G loss: 0.300947]\n",
      "epoch:8 step:8426 [D loss: 0.228305, acc.: 59.38%] [G loss: 0.301629]\n",
      "epoch:8 step:8427 [D loss: 0.221281, acc.: 66.41%] [G loss: 0.293930]\n",
      "epoch:8 step:8428 [D loss: 0.237425, acc.: 55.47%] [G loss: 0.292165]\n",
      "epoch:8 step:8429 [D loss: 0.249019, acc.: 56.25%] [G loss: 0.296382]\n",
      "epoch:8 step:8430 [D loss: 0.228634, acc.: 61.72%] [G loss: 0.310901]\n",
      "epoch:8 step:8431 [D loss: 0.238790, acc.: 55.47%] [G loss: 0.301328]\n",
      "epoch:8 step:8432 [D loss: 0.245720, acc.: 57.03%] [G loss: 0.286296]\n",
      "epoch:8 step:8433 [D loss: 0.246507, acc.: 53.91%] [G loss: 0.312250]\n",
      "epoch:9 step:8434 [D loss: 0.249379, acc.: 53.12%] [G loss: 0.284314]\n",
      "epoch:9 step:8435 [D loss: 0.258101, acc.: 50.00%] [G loss: 0.294653]\n",
      "epoch:9 step:8436 [D loss: 0.233260, acc.: 60.16%] [G loss: 0.280026]\n",
      "epoch:9 step:8437 [D loss: 0.235182, acc.: 59.38%] [G loss: 0.303427]\n",
      "epoch:9 step:8438 [D loss: 0.256910, acc.: 46.09%] [G loss: 0.272683]\n",
      "epoch:9 step:8439 [D loss: 0.260261, acc.: 52.34%] [G loss: 0.320473]\n",
      "epoch:9 step:8440 [D loss: 0.257411, acc.: 55.47%] [G loss: 0.274301]\n",
      "epoch:9 step:8441 [D loss: 0.255554, acc.: 51.56%] [G loss: 0.298423]\n",
      "epoch:9 step:8442 [D loss: 0.232026, acc.: 61.72%] [G loss: 0.285113]\n",
      "epoch:9 step:8443 [D loss: 0.256553, acc.: 55.47%] [G loss: 0.298888]\n",
      "epoch:9 step:8444 [D loss: 0.244537, acc.: 55.47%] [G loss: 0.273004]\n",
      "epoch:9 step:8445 [D loss: 0.237745, acc.: 61.72%] [G loss: 0.270020]\n",
      "epoch:9 step:8446 [D loss: 0.239417, acc.: 60.16%] [G loss: 0.269196]\n",
      "epoch:9 step:8447 [D loss: 0.233079, acc.: 62.50%] [G loss: 0.321611]\n",
      "epoch:9 step:8448 [D loss: 0.243680, acc.: 57.03%] [G loss: 0.284757]\n",
      "epoch:9 step:8449 [D loss: 0.229306, acc.: 61.72%] [G loss: 0.298641]\n",
      "epoch:9 step:8450 [D loss: 0.241392, acc.: 57.03%] [G loss: 0.305102]\n",
      "epoch:9 step:8451 [D loss: 0.237967, acc.: 57.03%] [G loss: 0.300702]\n",
      "epoch:9 step:8452 [D loss: 0.249692, acc.: 60.94%] [G loss: 0.292515]\n",
      "epoch:9 step:8453 [D loss: 0.263852, acc.: 50.00%] [G loss: 0.273011]\n",
      "epoch:9 step:8454 [D loss: 0.246405, acc.: 53.91%] [G loss: 0.276357]\n",
      "epoch:9 step:8455 [D loss: 0.233019, acc.: 58.59%] [G loss: 0.323132]\n",
      "epoch:9 step:8456 [D loss: 0.244465, acc.: 53.91%] [G loss: 0.295540]\n",
      "epoch:9 step:8457 [D loss: 0.235758, acc.: 53.91%] [G loss: 0.317010]\n",
      "epoch:9 step:8458 [D loss: 0.239267, acc.: 60.16%] [G loss: 0.285593]\n",
      "epoch:9 step:8459 [D loss: 0.232035, acc.: 63.28%] [G loss: 0.281323]\n",
      "epoch:9 step:8460 [D loss: 0.252395, acc.: 48.44%] [G loss: 0.270356]\n",
      "epoch:9 step:8461 [D loss: 0.238155, acc.: 60.94%] [G loss: 0.305090]\n",
      "epoch:9 step:8462 [D loss: 0.262657, acc.: 42.19%] [G loss: 0.289913]\n",
      "epoch:9 step:8463 [D loss: 0.230087, acc.: 61.72%] [G loss: 0.299826]\n",
      "epoch:9 step:8464 [D loss: 0.240734, acc.: 57.81%] [G loss: 0.301789]\n",
      "epoch:9 step:8465 [D loss: 0.257903, acc.: 49.22%] [G loss: 0.277225]\n",
      "epoch:9 step:8466 [D loss: 0.241410, acc.: 59.38%] [G loss: 0.293682]\n",
      "epoch:9 step:8467 [D loss: 0.236355, acc.: 57.81%] [G loss: 0.306802]\n",
      "epoch:9 step:8468 [D loss: 0.234402, acc.: 57.03%] [G loss: 0.294271]\n",
      "epoch:9 step:8469 [D loss: 0.219015, acc.: 66.41%] [G loss: 0.325053]\n",
      "epoch:9 step:8470 [D loss: 0.233439, acc.: 59.38%] [G loss: 0.291083]\n",
      "epoch:9 step:8471 [D loss: 0.231571, acc.: 56.25%] [G loss: 0.269936]\n",
      "epoch:9 step:8472 [D loss: 0.238746, acc.: 60.94%] [G loss: 0.279506]\n",
      "epoch:9 step:8473 [D loss: 0.239448, acc.: 56.25%] [G loss: 0.304063]\n",
      "epoch:9 step:8474 [D loss: 0.230728, acc.: 57.81%] [G loss: 0.317119]\n",
      "epoch:9 step:8475 [D loss: 0.233559, acc.: 61.72%] [G loss: 0.301380]\n",
      "epoch:9 step:8476 [D loss: 0.226909, acc.: 60.16%] [G loss: 0.304113]\n",
      "epoch:9 step:8477 [D loss: 0.252997, acc.: 56.25%] [G loss: 0.299730]\n",
      "epoch:9 step:8478 [D loss: 0.247396, acc.: 57.81%] [G loss: 0.295239]\n",
      "epoch:9 step:8479 [D loss: 0.254232, acc.: 53.91%] [G loss: 0.313496]\n",
      "epoch:9 step:8480 [D loss: 0.249698, acc.: 56.25%] [G loss: 0.303585]\n",
      "epoch:9 step:8481 [D loss: 0.235053, acc.: 62.50%] [G loss: 0.286372]\n",
      "epoch:9 step:8482 [D loss: 0.241256, acc.: 55.47%] [G loss: 0.306533]\n",
      "epoch:9 step:8483 [D loss: 0.234499, acc.: 61.72%] [G loss: 0.309873]\n",
      "epoch:9 step:8484 [D loss: 0.235451, acc.: 60.16%] [G loss: 0.301424]\n",
      "epoch:9 step:8485 [D loss: 0.242952, acc.: 59.38%] [G loss: 0.300567]\n",
      "epoch:9 step:8486 [D loss: 0.246675, acc.: 50.00%] [G loss: 0.296597]\n",
      "epoch:9 step:8487 [D loss: 0.231115, acc.: 60.16%] [G loss: 0.289113]\n",
      "epoch:9 step:8488 [D loss: 0.246974, acc.: 54.69%] [G loss: 0.292320]\n",
      "epoch:9 step:8489 [D loss: 0.246462, acc.: 60.16%] [G loss: 0.294938]\n",
      "epoch:9 step:8490 [D loss: 0.233644, acc.: 60.94%] [G loss: 0.312028]\n",
      "epoch:9 step:8491 [D loss: 0.231489, acc.: 53.91%] [G loss: 0.314731]\n",
      "epoch:9 step:8492 [D loss: 0.245198, acc.: 52.34%] [G loss: 0.282259]\n",
      "epoch:9 step:8493 [D loss: 0.252344, acc.: 52.34%] [G loss: 0.297676]\n",
      "epoch:9 step:8494 [D loss: 0.240147, acc.: 59.38%] [G loss: 0.282072]\n",
      "epoch:9 step:8495 [D loss: 0.235089, acc.: 58.59%] [G loss: 0.301065]\n",
      "epoch:9 step:8496 [D loss: 0.234171, acc.: 60.16%] [G loss: 0.318619]\n",
      "epoch:9 step:8497 [D loss: 0.237003, acc.: 57.81%] [G loss: 0.295953]\n",
      "epoch:9 step:8498 [D loss: 0.241678, acc.: 57.03%] [G loss: 0.276193]\n",
      "epoch:9 step:8499 [D loss: 0.253908, acc.: 55.47%] [G loss: 0.286937]\n",
      "epoch:9 step:8500 [D loss: 0.231564, acc.: 61.72%] [G loss: 0.293082]\n",
      "epoch:9 step:8501 [D loss: 0.252540, acc.: 52.34%] [G loss: 0.315143]\n",
      "epoch:9 step:8502 [D loss: 0.238986, acc.: 58.59%] [G loss: 0.276088]\n",
      "epoch:9 step:8503 [D loss: 0.241965, acc.: 53.12%] [G loss: 0.297923]\n",
      "epoch:9 step:8504 [D loss: 0.244299, acc.: 53.91%] [G loss: 0.284042]\n",
      "epoch:9 step:8505 [D loss: 0.245904, acc.: 53.91%] [G loss: 0.306196]\n",
      "epoch:9 step:8506 [D loss: 0.225941, acc.: 65.62%] [G loss: 0.322248]\n",
      "epoch:9 step:8507 [D loss: 0.225833, acc.: 66.41%] [G loss: 0.320936]\n",
      "epoch:9 step:8508 [D loss: 0.232279, acc.: 58.59%] [G loss: 0.284186]\n",
      "epoch:9 step:8509 [D loss: 0.234230, acc.: 60.94%] [G loss: 0.340572]\n",
      "epoch:9 step:8510 [D loss: 0.249463, acc.: 48.44%] [G loss: 0.286040]\n",
      "epoch:9 step:8511 [D loss: 0.242902, acc.: 53.91%] [G loss: 0.316189]\n",
      "epoch:9 step:8512 [D loss: 0.249527, acc.: 57.03%] [G loss: 0.286891]\n",
      "epoch:9 step:8513 [D loss: 0.227549, acc.: 62.50%] [G loss: 0.311454]\n",
      "epoch:9 step:8514 [D loss: 0.245169, acc.: 56.25%] [G loss: 0.286269]\n",
      "epoch:9 step:8515 [D loss: 0.249489, acc.: 51.56%] [G loss: 0.309309]\n",
      "epoch:9 step:8516 [D loss: 0.253611, acc.: 50.78%] [G loss: 0.296803]\n",
      "epoch:9 step:8517 [D loss: 0.230263, acc.: 60.94%] [G loss: 0.308099]\n",
      "epoch:9 step:8518 [D loss: 0.235376, acc.: 57.03%] [G loss: 0.287197]\n",
      "epoch:9 step:8519 [D loss: 0.242081, acc.: 54.69%] [G loss: 0.307544]\n",
      "epoch:9 step:8520 [D loss: 0.249976, acc.: 52.34%] [G loss: 0.277595]\n",
      "epoch:9 step:8521 [D loss: 0.232618, acc.: 65.62%] [G loss: 0.277522]\n",
      "epoch:9 step:8522 [D loss: 0.229810, acc.: 62.50%] [G loss: 0.271724]\n",
      "epoch:9 step:8523 [D loss: 0.231079, acc.: 63.28%] [G loss: 0.302410]\n",
      "epoch:9 step:8524 [D loss: 0.246375, acc.: 52.34%] [G loss: 0.297018]\n",
      "epoch:9 step:8525 [D loss: 0.247567, acc.: 55.47%] [G loss: 0.288783]\n",
      "epoch:9 step:8526 [D loss: 0.251682, acc.: 56.25%] [G loss: 0.281952]\n",
      "epoch:9 step:8527 [D loss: 0.235101, acc.: 57.03%] [G loss: 0.301839]\n",
      "epoch:9 step:8528 [D loss: 0.248788, acc.: 52.34%] [G loss: 0.311796]\n",
      "epoch:9 step:8529 [D loss: 0.220380, acc.: 67.19%] [G loss: 0.324348]\n",
      "epoch:9 step:8530 [D loss: 0.231618, acc.: 60.94%] [G loss: 0.311440]\n",
      "epoch:9 step:8531 [D loss: 0.236267, acc.: 59.38%] [G loss: 0.300817]\n",
      "epoch:9 step:8532 [D loss: 0.253709, acc.: 50.00%] [G loss: 0.289716]\n",
      "epoch:9 step:8533 [D loss: 0.231146, acc.: 63.28%] [G loss: 0.297716]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:9 step:8534 [D loss: 0.243185, acc.: 55.47%] [G loss: 0.298500]\n",
      "epoch:9 step:8535 [D loss: 0.231616, acc.: 67.97%] [G loss: 0.298403]\n",
      "epoch:9 step:8536 [D loss: 0.219306, acc.: 68.75%] [G loss: 0.272207]\n",
      "epoch:9 step:8537 [D loss: 0.262588, acc.: 46.88%] [G loss: 0.311072]\n",
      "epoch:9 step:8538 [D loss: 0.237051, acc.: 59.38%] [G loss: 0.299083]\n",
      "epoch:9 step:8539 [D loss: 0.225455, acc.: 64.84%] [G loss: 0.322089]\n",
      "epoch:9 step:8540 [D loss: 0.244551, acc.: 52.34%] [G loss: 0.275848]\n",
      "epoch:9 step:8541 [D loss: 0.245789, acc.: 57.81%] [G loss: 0.299325]\n",
      "epoch:9 step:8542 [D loss: 0.248950, acc.: 51.56%] [G loss: 0.263666]\n",
      "epoch:9 step:8543 [D loss: 0.241713, acc.: 60.16%] [G loss: 0.304007]\n",
      "epoch:9 step:8544 [D loss: 0.239540, acc.: 59.38%] [G loss: 0.279157]\n",
      "epoch:9 step:8545 [D loss: 0.242662, acc.: 62.50%] [G loss: 0.308168]\n",
      "epoch:9 step:8546 [D loss: 0.249464, acc.: 53.12%] [G loss: 0.299481]\n",
      "epoch:9 step:8547 [D loss: 0.242241, acc.: 54.69%] [G loss: 0.309841]\n",
      "epoch:9 step:8548 [D loss: 0.248832, acc.: 50.78%] [G loss: 0.320087]\n",
      "epoch:9 step:8549 [D loss: 0.250862, acc.: 57.03%] [G loss: 0.289861]\n",
      "epoch:9 step:8550 [D loss: 0.247070, acc.: 55.47%] [G loss: 0.270161]\n",
      "epoch:9 step:8551 [D loss: 0.242281, acc.: 56.25%] [G loss: 0.295146]\n",
      "epoch:9 step:8552 [D loss: 0.248656, acc.: 54.69%] [G loss: 0.300734]\n",
      "epoch:9 step:8553 [D loss: 0.245873, acc.: 56.25%] [G loss: 0.285408]\n",
      "epoch:9 step:8554 [D loss: 0.249645, acc.: 51.56%] [G loss: 0.274435]\n",
      "epoch:9 step:8555 [D loss: 0.244640, acc.: 58.59%] [G loss: 0.308804]\n",
      "epoch:9 step:8556 [D loss: 0.236825, acc.: 58.59%] [G loss: 0.300843]\n",
      "epoch:9 step:8557 [D loss: 0.234907, acc.: 60.94%] [G loss: 0.319398]\n",
      "epoch:9 step:8558 [D loss: 0.241169, acc.: 57.03%] [G loss: 0.303740]\n",
      "epoch:9 step:8559 [D loss: 0.250165, acc.: 57.81%] [G loss: 0.307440]\n",
      "epoch:9 step:8560 [D loss: 0.245881, acc.: 54.69%] [G loss: 0.304879]\n",
      "epoch:9 step:8561 [D loss: 0.236909, acc.: 56.25%] [G loss: 0.309972]\n",
      "epoch:9 step:8562 [D loss: 0.252692, acc.: 54.69%] [G loss: 0.307275]\n",
      "epoch:9 step:8563 [D loss: 0.244468, acc.: 59.38%] [G loss: 0.283732]\n",
      "epoch:9 step:8564 [D loss: 0.237307, acc.: 58.59%] [G loss: 0.305002]\n",
      "epoch:9 step:8565 [D loss: 0.251864, acc.: 53.91%] [G loss: 0.293828]\n",
      "epoch:9 step:8566 [D loss: 0.227064, acc.: 61.72%] [G loss: 0.297150]\n",
      "epoch:9 step:8567 [D loss: 0.236180, acc.: 62.50%] [G loss: 0.296270]\n",
      "epoch:9 step:8568 [D loss: 0.247930, acc.: 61.72%] [G loss: 0.292231]\n",
      "epoch:9 step:8569 [D loss: 0.260423, acc.: 46.88%] [G loss: 0.282851]\n",
      "epoch:9 step:8570 [D loss: 0.243704, acc.: 55.47%] [G loss: 0.306706]\n",
      "epoch:9 step:8571 [D loss: 0.236737, acc.: 56.25%] [G loss: 0.278060]\n",
      "epoch:9 step:8572 [D loss: 0.236169, acc.: 60.16%] [G loss: 0.290417]\n",
      "epoch:9 step:8573 [D loss: 0.240446, acc.: 65.62%] [G loss: 0.306491]\n",
      "epoch:9 step:8574 [D loss: 0.252636, acc.: 49.22%] [G loss: 0.308268]\n",
      "epoch:9 step:8575 [D loss: 0.219140, acc.: 65.62%] [G loss: 0.303057]\n",
      "epoch:9 step:8576 [D loss: 0.243198, acc.: 54.69%] [G loss: 0.303836]\n",
      "epoch:9 step:8577 [D loss: 0.239669, acc.: 58.59%] [G loss: 0.328743]\n",
      "epoch:9 step:8578 [D loss: 0.241150, acc.: 60.16%] [G loss: 0.301108]\n",
      "epoch:9 step:8579 [D loss: 0.249614, acc.: 52.34%] [G loss: 0.281346]\n",
      "epoch:9 step:8580 [D loss: 0.246772, acc.: 56.25%] [G loss: 0.311019]\n",
      "epoch:9 step:8581 [D loss: 0.248637, acc.: 55.47%] [G loss: 0.299251]\n",
      "epoch:9 step:8582 [D loss: 0.258093, acc.: 49.22%] [G loss: 0.290088]\n",
      "epoch:9 step:8583 [D loss: 0.251359, acc.: 53.91%] [G loss: 0.298969]\n",
      "epoch:9 step:8584 [D loss: 0.242619, acc.: 51.56%] [G loss: 0.292830]\n",
      "epoch:9 step:8585 [D loss: 0.251339, acc.: 54.69%] [G loss: 0.283203]\n",
      "epoch:9 step:8586 [D loss: 0.240355, acc.: 59.38%] [G loss: 0.276153]\n",
      "epoch:9 step:8587 [D loss: 0.255244, acc.: 55.47%] [G loss: 0.279114]\n",
      "epoch:9 step:8588 [D loss: 0.252861, acc.: 47.66%] [G loss: 0.267161]\n",
      "epoch:9 step:8589 [D loss: 0.233701, acc.: 63.28%] [G loss: 0.259255]\n",
      "epoch:9 step:8590 [D loss: 0.228817, acc.: 60.94%] [G loss: 0.304766]\n",
      "epoch:9 step:8591 [D loss: 0.249691, acc.: 55.47%] [G loss: 0.268789]\n",
      "epoch:9 step:8592 [D loss: 0.242096, acc.: 56.25%] [G loss: 0.278209]\n",
      "epoch:9 step:8593 [D loss: 0.245184, acc.: 55.47%] [G loss: 0.295775]\n",
      "epoch:9 step:8594 [D loss: 0.252979, acc.: 53.12%] [G loss: 0.318960]\n",
      "epoch:9 step:8595 [D loss: 0.244994, acc.: 57.03%] [G loss: 0.310801]\n",
      "epoch:9 step:8596 [D loss: 0.262783, acc.: 48.44%] [G loss: 0.266782]\n",
      "epoch:9 step:8597 [D loss: 0.248808, acc.: 50.78%] [G loss: 0.305775]\n",
      "epoch:9 step:8598 [D loss: 0.257825, acc.: 50.78%] [G loss: 0.314720]\n",
      "epoch:9 step:8599 [D loss: 0.240950, acc.: 57.81%] [G loss: 0.296569]\n",
      "epoch:9 step:8600 [D loss: 0.254682, acc.: 51.56%] [G loss: 0.293151]\n",
      "epoch:9 step:8601 [D loss: 0.236002, acc.: 57.81%] [G loss: 0.302677]\n",
      "epoch:9 step:8602 [D loss: 0.238184, acc.: 58.59%] [G loss: 0.307149]\n",
      "epoch:9 step:8603 [D loss: 0.249938, acc.: 52.34%] [G loss: 0.295115]\n",
      "epoch:9 step:8604 [D loss: 0.224025, acc.: 67.19%] [G loss: 0.299291]\n",
      "epoch:9 step:8605 [D loss: 0.238947, acc.: 60.16%] [G loss: 0.284386]\n",
      "epoch:9 step:8606 [D loss: 0.234102, acc.: 62.50%] [G loss: 0.300237]\n",
      "epoch:9 step:8607 [D loss: 0.248329, acc.: 53.12%] [G loss: 0.302475]\n",
      "epoch:9 step:8608 [D loss: 0.227849, acc.: 57.81%] [G loss: 0.282745]\n",
      "epoch:9 step:8609 [D loss: 0.235283, acc.: 57.81%] [G loss: 0.306509]\n",
      "epoch:9 step:8610 [D loss: 0.243524, acc.: 53.91%] [G loss: 0.312777]\n",
      "epoch:9 step:8611 [D loss: 0.237204, acc.: 56.25%] [G loss: 0.301698]\n",
      "epoch:9 step:8612 [D loss: 0.259048, acc.: 52.34%] [G loss: 0.313486]\n",
      "epoch:9 step:8613 [D loss: 0.249363, acc.: 56.25%] [G loss: 0.290441]\n",
      "epoch:9 step:8614 [D loss: 0.218929, acc.: 65.62%] [G loss: 0.322282]\n",
      "epoch:9 step:8615 [D loss: 0.237478, acc.: 56.25%] [G loss: 0.336688]\n",
      "epoch:9 step:8616 [D loss: 0.259915, acc.: 46.88%] [G loss: 0.309307]\n",
      "epoch:9 step:8617 [D loss: 0.238017, acc.: 59.38%] [G loss: 0.278626]\n",
      "epoch:9 step:8618 [D loss: 0.248613, acc.: 56.25%] [G loss: 0.319562]\n",
      "epoch:9 step:8619 [D loss: 0.235790, acc.: 56.25%] [G loss: 0.277437]\n",
      "epoch:9 step:8620 [D loss: 0.229215, acc.: 62.50%] [G loss: 0.310462]\n",
      "epoch:9 step:8621 [D loss: 0.254409, acc.: 59.38%] [G loss: 0.292392]\n",
      "epoch:9 step:8622 [D loss: 0.242134, acc.: 58.59%] [G loss: 0.295126]\n",
      "epoch:9 step:8623 [D loss: 0.245136, acc.: 52.34%] [G loss: 0.282454]\n",
      "epoch:9 step:8624 [D loss: 0.226434, acc.: 59.38%] [G loss: 0.278743]\n",
      "epoch:9 step:8625 [D loss: 0.248103, acc.: 50.78%] [G loss: 0.315095]\n",
      "epoch:9 step:8626 [D loss: 0.240323, acc.: 58.59%] [G loss: 0.299914]\n",
      "epoch:9 step:8627 [D loss: 0.232781, acc.: 64.06%] [G loss: 0.304080]\n",
      "epoch:9 step:8628 [D loss: 0.251759, acc.: 54.69%] [G loss: 0.279575]\n",
      "epoch:9 step:8629 [D loss: 0.234262, acc.: 53.12%] [G loss: 0.318906]\n",
      "epoch:9 step:8630 [D loss: 0.247996, acc.: 58.59%] [G loss: 0.310174]\n",
      "epoch:9 step:8631 [D loss: 0.245478, acc.: 57.03%] [G loss: 0.304778]\n",
      "epoch:9 step:8632 [D loss: 0.231979, acc.: 64.84%] [G loss: 0.285053]\n",
      "epoch:9 step:8633 [D loss: 0.252631, acc.: 51.56%] [G loss: 0.291425]\n",
      "epoch:9 step:8634 [D loss: 0.244354, acc.: 57.03%] [G loss: 0.284680]\n",
      "epoch:9 step:8635 [D loss: 0.233621, acc.: 60.16%] [G loss: 0.310987]\n",
      "epoch:9 step:8636 [D loss: 0.239078, acc.: 58.59%] [G loss: 0.322790]\n",
      "epoch:9 step:8637 [D loss: 0.251588, acc.: 54.69%] [G loss: 0.301463]\n",
      "epoch:9 step:8638 [D loss: 0.233577, acc.: 60.16%] [G loss: 0.279522]\n",
      "epoch:9 step:8639 [D loss: 0.254135, acc.: 53.12%] [G loss: 0.289796]\n",
      "epoch:9 step:8640 [D loss: 0.253062, acc.: 50.00%] [G loss: 0.286004]\n",
      "epoch:9 step:8641 [D loss: 0.237962, acc.: 57.81%] [G loss: 0.286498]\n",
      "epoch:9 step:8642 [D loss: 0.250935, acc.: 56.25%] [G loss: 0.316509]\n",
      "epoch:9 step:8643 [D loss: 0.232656, acc.: 62.50%] [G loss: 0.322601]\n",
      "epoch:9 step:8644 [D loss: 0.242198, acc.: 49.22%] [G loss: 0.293275]\n",
      "epoch:9 step:8645 [D loss: 0.232973, acc.: 61.72%] [G loss: 0.302759]\n",
      "epoch:9 step:8646 [D loss: 0.252796, acc.: 53.91%] [G loss: 0.287369]\n",
      "epoch:9 step:8647 [D loss: 0.238511, acc.: 56.25%] [G loss: 0.316344]\n",
      "epoch:9 step:8648 [D loss: 0.249382, acc.: 54.69%] [G loss: 0.290866]\n",
      "epoch:9 step:8649 [D loss: 0.244946, acc.: 66.41%] [G loss: 0.294981]\n",
      "epoch:9 step:8650 [D loss: 0.231163, acc.: 57.81%] [G loss: 0.289119]\n",
      "epoch:9 step:8651 [D loss: 0.246704, acc.: 56.25%] [G loss: 0.292126]\n",
      "epoch:9 step:8652 [D loss: 0.260141, acc.: 49.22%] [G loss: 0.316486]\n",
      "epoch:9 step:8653 [D loss: 0.228091, acc.: 61.72%] [G loss: 0.282364]\n",
      "epoch:9 step:8654 [D loss: 0.247839, acc.: 56.25%] [G loss: 0.270630]\n",
      "epoch:9 step:8655 [D loss: 0.248957, acc.: 50.78%] [G loss: 0.291974]\n",
      "epoch:9 step:8656 [D loss: 0.234968, acc.: 58.59%] [G loss: 0.274096]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:9 step:8657 [D loss: 0.248518, acc.: 54.69%] [G loss: 0.288780]\n",
      "epoch:9 step:8658 [D loss: 0.247647, acc.: 53.91%] [G loss: 0.295431]\n",
      "epoch:9 step:8659 [D loss: 0.240510, acc.: 58.59%] [G loss: 0.296821]\n",
      "epoch:9 step:8660 [D loss: 0.245267, acc.: 57.81%] [G loss: 0.291078]\n",
      "epoch:9 step:8661 [D loss: 0.233648, acc.: 61.72%] [G loss: 0.278274]\n",
      "epoch:9 step:8662 [D loss: 0.235812, acc.: 57.81%] [G loss: 0.281487]\n",
      "epoch:9 step:8663 [D loss: 0.264885, acc.: 50.00%] [G loss: 0.270992]\n",
      "epoch:9 step:8664 [D loss: 0.229805, acc.: 60.94%] [G loss: 0.284149]\n",
      "epoch:9 step:8665 [D loss: 0.252975, acc.: 51.56%] [G loss: 0.304934]\n",
      "epoch:9 step:8666 [D loss: 0.235784, acc.: 59.38%] [G loss: 0.290905]\n",
      "epoch:9 step:8667 [D loss: 0.260741, acc.: 52.34%] [G loss: 0.291514]\n",
      "epoch:9 step:8668 [D loss: 0.228222, acc.: 64.06%] [G loss: 0.296653]\n",
      "epoch:9 step:8669 [D loss: 0.248236, acc.: 57.81%] [G loss: 0.300205]\n",
      "epoch:9 step:8670 [D loss: 0.235700, acc.: 53.91%] [G loss: 0.285926]\n",
      "epoch:9 step:8671 [D loss: 0.245498, acc.: 58.59%] [G loss: 0.308237]\n",
      "epoch:9 step:8672 [D loss: 0.222690, acc.: 60.94%] [G loss: 0.316866]\n",
      "epoch:9 step:8673 [D loss: 0.234627, acc.: 60.16%] [G loss: 0.295678]\n",
      "epoch:9 step:8674 [D loss: 0.242518, acc.: 55.47%] [G loss: 0.290085]\n",
      "epoch:9 step:8675 [D loss: 0.239050, acc.: 61.72%] [G loss: 0.300111]\n",
      "epoch:9 step:8676 [D loss: 0.241095, acc.: 57.81%] [G loss: 0.298650]\n",
      "epoch:9 step:8677 [D loss: 0.245742, acc.: 50.78%] [G loss: 0.310537]\n",
      "epoch:9 step:8678 [D loss: 0.252415, acc.: 59.38%] [G loss: 0.284182]\n",
      "epoch:9 step:8679 [D loss: 0.264116, acc.: 46.88%] [G loss: 0.290595]\n",
      "epoch:9 step:8680 [D loss: 0.241765, acc.: 60.16%] [G loss: 0.288520]\n",
      "epoch:9 step:8681 [D loss: 0.238473, acc.: 57.81%] [G loss: 0.317896]\n",
      "epoch:9 step:8682 [D loss: 0.233278, acc.: 59.38%] [G loss: 0.278360]\n",
      "epoch:9 step:8683 [D loss: 0.243950, acc.: 57.81%] [G loss: 0.314882]\n",
      "epoch:9 step:8684 [D loss: 0.238807, acc.: 57.03%] [G loss: 0.308035]\n",
      "epoch:9 step:8685 [D loss: 0.236129, acc.: 59.38%] [G loss: 0.326333]\n",
      "epoch:9 step:8686 [D loss: 0.241726, acc.: 61.72%] [G loss: 0.300293]\n",
      "epoch:9 step:8687 [D loss: 0.240520, acc.: 52.34%] [G loss: 0.296764]\n",
      "epoch:9 step:8688 [D loss: 0.223990, acc.: 66.41%] [G loss: 0.312253]\n",
      "epoch:9 step:8689 [D loss: 0.230597, acc.: 63.28%] [G loss: 0.297904]\n",
      "epoch:9 step:8690 [D loss: 0.242499, acc.: 56.25%] [G loss: 0.319329]\n",
      "epoch:9 step:8691 [D loss: 0.233556, acc.: 60.94%] [G loss: 0.300203]\n",
      "epoch:9 step:8692 [D loss: 0.243673, acc.: 60.16%] [G loss: 0.274766]\n",
      "epoch:9 step:8693 [D loss: 0.244150, acc.: 52.34%] [G loss: 0.306007]\n",
      "epoch:9 step:8694 [D loss: 0.241551, acc.: 56.25%] [G loss: 0.269133]\n",
      "epoch:9 step:8695 [D loss: 0.247100, acc.: 52.34%] [G loss: 0.313974]\n",
      "epoch:9 step:8696 [D loss: 0.254970, acc.: 55.47%] [G loss: 0.321837]\n",
      "epoch:9 step:8697 [D loss: 0.238071, acc.: 60.16%] [G loss: 0.315841]\n",
      "epoch:9 step:8698 [D loss: 0.242055, acc.: 54.69%] [G loss: 0.306010]\n",
      "epoch:9 step:8699 [D loss: 0.241534, acc.: 54.69%] [G loss: 0.324159]\n",
      "epoch:9 step:8700 [D loss: 0.252336, acc.: 53.91%] [G loss: 0.282843]\n",
      "epoch:9 step:8701 [D loss: 0.221771, acc.: 64.06%] [G loss: 0.283999]\n",
      "epoch:9 step:8702 [D loss: 0.239389, acc.: 57.03%] [G loss: 0.293661]\n",
      "epoch:9 step:8703 [D loss: 0.242889, acc.: 54.69%] [G loss: 0.318421]\n",
      "epoch:9 step:8704 [D loss: 0.243671, acc.: 53.12%] [G loss: 0.313029]\n",
      "epoch:9 step:8705 [D loss: 0.237477, acc.: 57.81%] [G loss: 0.297121]\n",
      "epoch:9 step:8706 [D loss: 0.255230, acc.: 51.56%] [G loss: 0.306343]\n",
      "epoch:9 step:8707 [D loss: 0.226077, acc.: 64.06%] [G loss: 0.314784]\n",
      "epoch:9 step:8708 [D loss: 0.246212, acc.: 60.94%] [G loss: 0.323444]\n",
      "epoch:9 step:8709 [D loss: 0.250432, acc.: 58.59%] [G loss: 0.293379]\n",
      "epoch:9 step:8710 [D loss: 0.234804, acc.: 54.69%] [G loss: 0.292233]\n",
      "epoch:9 step:8711 [D loss: 0.246557, acc.: 53.91%] [G loss: 0.294621]\n",
      "epoch:9 step:8712 [D loss: 0.238833, acc.: 57.03%] [G loss: 0.319080]\n",
      "epoch:9 step:8713 [D loss: 0.249534, acc.: 55.47%] [G loss: 0.289281]\n",
      "epoch:9 step:8714 [D loss: 0.246874, acc.: 58.59%] [G loss: 0.279079]\n",
      "epoch:9 step:8715 [D loss: 0.239461, acc.: 60.94%] [G loss: 0.301664]\n",
      "epoch:9 step:8716 [D loss: 0.238062, acc.: 60.16%] [G loss: 0.291335]\n",
      "epoch:9 step:8717 [D loss: 0.240663, acc.: 57.03%] [G loss: 0.301645]\n",
      "epoch:9 step:8718 [D loss: 0.261657, acc.: 47.66%] [G loss: 0.300508]\n",
      "epoch:9 step:8719 [D loss: 0.238958, acc.: 54.69%] [G loss: 0.322205]\n",
      "epoch:9 step:8720 [D loss: 0.245052, acc.: 54.69%] [G loss: 0.305731]\n",
      "epoch:9 step:8721 [D loss: 0.244003, acc.: 55.47%] [G loss: 0.298141]\n",
      "epoch:9 step:8722 [D loss: 0.239686, acc.: 56.25%] [G loss: 0.282871]\n",
      "epoch:9 step:8723 [D loss: 0.245235, acc.: 54.69%] [G loss: 0.299911]\n",
      "epoch:9 step:8724 [D loss: 0.238266, acc.: 56.25%] [G loss: 0.294250]\n",
      "epoch:9 step:8725 [D loss: 0.263814, acc.: 51.56%] [G loss: 0.294940]\n",
      "epoch:9 step:8726 [D loss: 0.239484, acc.: 57.81%] [G loss: 0.278714]\n",
      "epoch:9 step:8727 [D loss: 0.245514, acc.: 52.34%] [G loss: 0.317289]\n",
      "epoch:9 step:8728 [D loss: 0.242787, acc.: 57.81%] [G loss: 0.294135]\n",
      "epoch:9 step:8729 [D loss: 0.241466, acc.: 55.47%] [G loss: 0.309704]\n",
      "epoch:9 step:8730 [D loss: 0.260043, acc.: 51.56%] [G loss: 0.295783]\n",
      "epoch:9 step:8731 [D loss: 0.240331, acc.: 57.03%] [G loss: 0.322574]\n",
      "epoch:9 step:8732 [D loss: 0.248983, acc.: 56.25%] [G loss: 0.310671]\n",
      "epoch:9 step:8733 [D loss: 0.244531, acc.: 55.47%] [G loss: 0.314875]\n",
      "epoch:9 step:8734 [D loss: 0.255750, acc.: 52.34%] [G loss: 0.310180]\n",
      "epoch:9 step:8735 [D loss: 0.231365, acc.: 61.72%] [G loss: 0.307200]\n",
      "epoch:9 step:8736 [D loss: 0.257076, acc.: 52.34%] [G loss: 0.295073]\n",
      "epoch:9 step:8737 [D loss: 0.253024, acc.: 51.56%] [G loss: 0.314154]\n",
      "epoch:9 step:8738 [D loss: 0.244087, acc.: 53.91%] [G loss: 0.278097]\n",
      "epoch:9 step:8739 [D loss: 0.261948, acc.: 46.09%] [G loss: 0.302508]\n",
      "epoch:9 step:8740 [D loss: 0.233816, acc.: 59.38%] [G loss: 0.305534]\n",
      "epoch:9 step:8741 [D loss: 0.234370, acc.: 58.59%] [G loss: 0.309022]\n",
      "epoch:9 step:8742 [D loss: 0.237732, acc.: 62.50%] [G loss: 0.275057]\n",
      "epoch:9 step:8743 [D loss: 0.239924, acc.: 54.69%] [G loss: 0.289673]\n",
      "epoch:9 step:8744 [D loss: 0.241017, acc.: 55.47%] [G loss: 0.269364]\n",
      "epoch:9 step:8745 [D loss: 0.268321, acc.: 46.09%] [G loss: 0.282396]\n",
      "epoch:9 step:8746 [D loss: 0.242812, acc.: 57.81%] [G loss: 0.294535]\n",
      "epoch:9 step:8747 [D loss: 0.231371, acc.: 64.84%] [G loss: 0.297046]\n",
      "epoch:9 step:8748 [D loss: 0.240676, acc.: 54.69%] [G loss: 0.301081]\n",
      "epoch:9 step:8749 [D loss: 0.250263, acc.: 52.34%] [G loss: 0.289002]\n",
      "epoch:9 step:8750 [D loss: 0.226951, acc.: 66.41%] [G loss: 0.309287]\n",
      "epoch:9 step:8751 [D loss: 0.249959, acc.: 53.12%] [G loss: 0.291923]\n",
      "epoch:9 step:8752 [D loss: 0.234087, acc.: 59.38%] [G loss: 0.295799]\n",
      "epoch:9 step:8753 [D loss: 0.247054, acc.: 48.44%] [G loss: 0.268593]\n",
      "epoch:9 step:8754 [D loss: 0.251823, acc.: 51.56%] [G loss: 0.269415]\n",
      "epoch:9 step:8755 [D loss: 0.249964, acc.: 54.69%] [G loss: 0.288398]\n",
      "epoch:9 step:8756 [D loss: 0.246552, acc.: 56.25%] [G loss: 0.277779]\n",
      "epoch:9 step:8757 [D loss: 0.241535, acc.: 55.47%] [G loss: 0.292472]\n",
      "epoch:9 step:8758 [D loss: 0.227343, acc.: 60.94%] [G loss: 0.298032]\n",
      "epoch:9 step:8759 [D loss: 0.246601, acc.: 53.12%] [G loss: 0.314929]\n",
      "epoch:9 step:8760 [D loss: 0.243159, acc.: 56.25%] [G loss: 0.300296]\n",
      "epoch:9 step:8761 [D loss: 0.225714, acc.: 61.72%] [G loss: 0.313636]\n",
      "epoch:9 step:8762 [D loss: 0.234454, acc.: 57.03%] [G loss: 0.288755]\n",
      "epoch:9 step:8763 [D loss: 0.225971, acc.: 63.28%] [G loss: 0.292073]\n",
      "epoch:9 step:8764 [D loss: 0.239280, acc.: 57.81%] [G loss: 0.308892]\n",
      "epoch:9 step:8765 [D loss: 0.251345, acc.: 57.03%] [G loss: 0.296105]\n",
      "epoch:9 step:8766 [D loss: 0.242600, acc.: 62.50%] [G loss: 0.314637]\n",
      "epoch:9 step:8767 [D loss: 0.238705, acc.: 57.81%] [G loss: 0.273365]\n",
      "epoch:9 step:8768 [D loss: 0.232323, acc.: 54.69%] [G loss: 0.311295]\n",
      "epoch:9 step:8769 [D loss: 0.236768, acc.: 59.38%] [G loss: 0.281297]\n",
      "epoch:9 step:8770 [D loss: 0.243552, acc.: 54.69%] [G loss: 0.286771]\n",
      "epoch:9 step:8771 [D loss: 0.250718, acc.: 53.12%] [G loss: 0.299112]\n",
      "epoch:9 step:8772 [D loss: 0.244789, acc.: 55.47%] [G loss: 0.320876]\n",
      "epoch:9 step:8773 [D loss: 0.227840, acc.: 62.50%] [G loss: 0.288501]\n",
      "epoch:9 step:8774 [D loss: 0.250404, acc.: 50.00%] [G loss: 0.282740]\n",
      "epoch:9 step:8775 [D loss: 0.220980, acc.: 70.31%] [G loss: 0.302608]\n",
      "epoch:9 step:8776 [D loss: 0.227535, acc.: 60.94%] [G loss: 0.304399]\n",
      "epoch:9 step:8777 [D loss: 0.248371, acc.: 54.69%] [G loss: 0.317027]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:9 step:8778 [D loss: 0.242954, acc.: 56.25%] [G loss: 0.268407]\n",
      "epoch:9 step:8779 [D loss: 0.223470, acc.: 68.75%] [G loss: 0.313155]\n",
      "epoch:9 step:8780 [D loss: 0.240082, acc.: 61.72%] [G loss: 0.301110]\n",
      "epoch:9 step:8781 [D loss: 0.219631, acc.: 61.72%] [G loss: 0.277644]\n",
      "epoch:9 step:8782 [D loss: 0.250947, acc.: 55.47%] [G loss: 0.283456]\n",
      "epoch:9 step:8783 [D loss: 0.240420, acc.: 56.25%] [G loss: 0.288314]\n",
      "epoch:9 step:8784 [D loss: 0.245235, acc.: 51.56%] [G loss: 0.290275]\n",
      "epoch:9 step:8785 [D loss: 0.227555, acc.: 63.28%] [G loss: 0.311744]\n",
      "epoch:9 step:8786 [D loss: 0.228853, acc.: 60.94%] [G loss: 0.303539]\n",
      "epoch:9 step:8787 [D loss: 0.232818, acc.: 60.94%] [G loss: 0.290659]\n",
      "epoch:9 step:8788 [D loss: 0.267722, acc.: 47.66%] [G loss: 0.272210]\n",
      "epoch:9 step:8789 [D loss: 0.228601, acc.: 64.84%] [G loss: 0.296397]\n",
      "epoch:9 step:8790 [D loss: 0.253723, acc.: 52.34%] [G loss: 0.285782]\n",
      "epoch:9 step:8791 [D loss: 0.247162, acc.: 58.59%] [G loss: 0.289604]\n",
      "epoch:9 step:8792 [D loss: 0.241596, acc.: 59.38%] [G loss: 0.294833]\n",
      "epoch:9 step:8793 [D loss: 0.230470, acc.: 59.38%] [G loss: 0.297150]\n",
      "epoch:9 step:8794 [D loss: 0.233665, acc.: 61.72%] [G loss: 0.307489]\n",
      "epoch:9 step:8795 [D loss: 0.229336, acc.: 60.94%] [G loss: 0.299788]\n",
      "epoch:9 step:8796 [D loss: 0.243465, acc.: 56.25%] [G loss: 0.310572]\n",
      "epoch:9 step:8797 [D loss: 0.226586, acc.: 64.84%] [G loss: 0.315157]\n",
      "epoch:9 step:8798 [D loss: 0.243898, acc.: 52.34%] [G loss: 0.322760]\n",
      "epoch:9 step:8799 [D loss: 0.240128, acc.: 57.03%] [G loss: 0.301102]\n",
      "epoch:9 step:8800 [D loss: 0.253962, acc.: 54.69%] [G loss: 0.310662]\n",
      "epoch:9 step:8801 [D loss: 0.249310, acc.: 56.25%] [G loss: 0.283892]\n",
      "epoch:9 step:8802 [D loss: 0.248949, acc.: 50.78%] [G loss: 0.293117]\n",
      "epoch:9 step:8803 [D loss: 0.256178, acc.: 51.56%] [G loss: 0.268249]\n",
      "epoch:9 step:8804 [D loss: 0.240729, acc.: 57.81%] [G loss: 0.295515]\n",
      "epoch:9 step:8805 [D loss: 0.244825, acc.: 54.69%] [G loss: 0.291944]\n",
      "epoch:9 step:8806 [D loss: 0.238631, acc.: 52.34%] [G loss: 0.291117]\n",
      "epoch:9 step:8807 [D loss: 0.238883, acc.: 57.81%] [G loss: 0.297023]\n",
      "epoch:9 step:8808 [D loss: 0.242973, acc.: 58.59%] [G loss: 0.274490]\n",
      "epoch:9 step:8809 [D loss: 0.252417, acc.: 57.81%] [G loss: 0.273265]\n",
      "epoch:9 step:8810 [D loss: 0.236006, acc.: 57.81%] [G loss: 0.302527]\n",
      "epoch:9 step:8811 [D loss: 0.250934, acc.: 52.34%] [G loss: 0.303999]\n",
      "epoch:9 step:8812 [D loss: 0.243624, acc.: 55.47%] [G loss: 0.283915]\n",
      "epoch:9 step:8813 [D loss: 0.244443, acc.: 57.03%] [G loss: 0.298116]\n",
      "epoch:9 step:8814 [D loss: 0.224502, acc.: 66.41%] [G loss: 0.299399]\n",
      "epoch:9 step:8815 [D loss: 0.242396, acc.: 53.91%] [G loss: 0.293406]\n",
      "epoch:9 step:8816 [D loss: 0.244215, acc.: 54.69%] [G loss: 0.285963]\n",
      "epoch:9 step:8817 [D loss: 0.241178, acc.: 54.69%] [G loss: 0.304109]\n",
      "epoch:9 step:8818 [D loss: 0.251668, acc.: 52.34%] [G loss: 0.301484]\n",
      "epoch:9 step:8819 [D loss: 0.240559, acc.: 55.47%] [G loss: 0.294006]\n",
      "epoch:9 step:8820 [D loss: 0.248004, acc.: 49.22%] [G loss: 0.302442]\n",
      "epoch:9 step:8821 [D loss: 0.250589, acc.: 53.91%] [G loss: 0.316920]\n",
      "epoch:9 step:8822 [D loss: 0.233763, acc.: 64.06%] [G loss: 0.299845]\n",
      "epoch:9 step:8823 [D loss: 0.231771, acc.: 63.28%] [G loss: 0.292951]\n",
      "epoch:9 step:8824 [D loss: 0.234451, acc.: 57.81%] [G loss: 0.301782]\n",
      "epoch:9 step:8825 [D loss: 0.239486, acc.: 59.38%] [G loss: 0.322931]\n",
      "epoch:9 step:8826 [D loss: 0.239269, acc.: 58.59%] [G loss: 0.301323]\n",
      "epoch:9 step:8827 [D loss: 0.224558, acc.: 69.53%] [G loss: 0.311534]\n",
      "epoch:9 step:8828 [D loss: 0.233270, acc.: 59.38%] [G loss: 0.302977]\n",
      "epoch:9 step:8829 [D loss: 0.239955, acc.: 55.47%] [G loss: 0.306050]\n",
      "epoch:9 step:8830 [D loss: 0.248298, acc.: 55.47%] [G loss: 0.308837]\n",
      "epoch:9 step:8831 [D loss: 0.228480, acc.: 60.94%] [G loss: 0.314286]\n",
      "epoch:9 step:8832 [D loss: 0.226852, acc.: 62.50%] [G loss: 0.301039]\n",
      "epoch:9 step:8833 [D loss: 0.253276, acc.: 50.78%] [G loss: 0.303830]\n",
      "epoch:9 step:8834 [D loss: 0.237755, acc.: 57.03%] [G loss: 0.307458]\n",
      "epoch:9 step:8835 [D loss: 0.249479, acc.: 54.69%] [G loss: 0.298322]\n",
      "epoch:9 step:8836 [D loss: 0.248533, acc.: 53.12%] [G loss: 0.316788]\n",
      "epoch:9 step:8837 [D loss: 0.238487, acc.: 53.91%] [G loss: 0.297774]\n",
      "epoch:9 step:8838 [D loss: 0.245427, acc.: 54.69%] [G loss: 0.291796]\n",
      "epoch:9 step:8839 [D loss: 0.233329, acc.: 62.50%] [G loss: 0.285081]\n",
      "epoch:9 step:8840 [D loss: 0.233366, acc.: 59.38%] [G loss: 0.301230]\n",
      "epoch:9 step:8841 [D loss: 0.252553, acc.: 49.22%] [G loss: 0.282443]\n",
      "epoch:9 step:8842 [D loss: 0.245220, acc.: 56.25%] [G loss: 0.309925]\n",
      "epoch:9 step:8843 [D loss: 0.247552, acc.: 53.12%] [G loss: 0.304462]\n",
      "epoch:9 step:8844 [D loss: 0.241580, acc.: 59.38%] [G loss: 0.292661]\n",
      "epoch:9 step:8845 [D loss: 0.257816, acc.: 50.78%] [G loss: 0.276716]\n",
      "epoch:9 step:8846 [D loss: 0.243878, acc.: 53.91%] [G loss: 0.288737]\n",
      "epoch:9 step:8847 [D loss: 0.247196, acc.: 60.16%] [G loss: 0.295889]\n",
      "epoch:9 step:8848 [D loss: 0.247290, acc.: 56.25%] [G loss: 0.312348]\n",
      "epoch:9 step:8849 [D loss: 0.240193, acc.: 57.81%] [G loss: 0.320796]\n",
      "epoch:9 step:8850 [D loss: 0.234445, acc.: 65.62%] [G loss: 0.302974]\n",
      "epoch:9 step:8851 [D loss: 0.250463, acc.: 56.25%] [G loss: 0.303159]\n",
      "epoch:9 step:8852 [D loss: 0.240947, acc.: 55.47%] [G loss: 0.315384]\n",
      "epoch:9 step:8853 [D loss: 0.219377, acc.: 64.84%] [G loss: 0.315133]\n",
      "epoch:9 step:8854 [D loss: 0.248315, acc.: 58.59%] [G loss: 0.282543]\n",
      "epoch:9 step:8855 [D loss: 0.240442, acc.: 57.81%] [G loss: 0.307005]\n",
      "epoch:9 step:8856 [D loss: 0.223315, acc.: 64.84%] [G loss: 0.308817]\n",
      "epoch:9 step:8857 [D loss: 0.237239, acc.: 57.03%] [G loss: 0.283539]\n",
      "epoch:9 step:8858 [D loss: 0.231300, acc.: 60.16%] [G loss: 0.309728]\n",
      "epoch:9 step:8859 [D loss: 0.227677, acc.: 67.19%] [G loss: 0.297376]\n",
      "epoch:9 step:8860 [D loss: 0.238052, acc.: 59.38%] [G loss: 0.293122]\n",
      "epoch:9 step:8861 [D loss: 0.243347, acc.: 55.47%] [G loss: 0.304830]\n",
      "epoch:9 step:8862 [D loss: 0.246400, acc.: 56.25%] [G loss: 0.290321]\n",
      "epoch:9 step:8863 [D loss: 0.256656, acc.: 54.69%] [G loss: 0.292873]\n",
      "epoch:9 step:8864 [D loss: 0.225064, acc.: 61.72%] [G loss: 0.338929]\n",
      "epoch:9 step:8865 [D loss: 0.235593, acc.: 59.38%] [G loss: 0.292273]\n",
      "epoch:9 step:8866 [D loss: 0.236573, acc.: 64.84%] [G loss: 0.307615]\n",
      "epoch:9 step:8867 [D loss: 0.235925, acc.: 61.72%] [G loss: 0.285468]\n",
      "epoch:9 step:8868 [D loss: 0.230542, acc.: 58.59%] [G loss: 0.312303]\n",
      "epoch:9 step:8869 [D loss: 0.244102, acc.: 57.81%] [G loss: 0.279810]\n",
      "epoch:9 step:8870 [D loss: 0.246706, acc.: 54.69%] [G loss: 0.274148]\n",
      "epoch:9 step:8871 [D loss: 0.231387, acc.: 65.62%] [G loss: 0.322411]\n",
      "epoch:9 step:8872 [D loss: 0.248958, acc.: 53.12%] [G loss: 0.288424]\n",
      "epoch:9 step:8873 [D loss: 0.236517, acc.: 58.59%] [G loss: 0.290911]\n",
      "epoch:9 step:8874 [D loss: 0.232906, acc.: 55.47%] [G loss: 0.311294]\n",
      "epoch:9 step:8875 [D loss: 0.264717, acc.: 51.56%] [G loss: 0.270833]\n",
      "epoch:9 step:8876 [D loss: 0.239210, acc.: 52.34%] [G loss: 0.312690]\n",
      "epoch:9 step:8877 [D loss: 0.229186, acc.: 63.28%] [G loss: 0.310112]\n",
      "epoch:9 step:8878 [D loss: 0.222631, acc.: 71.88%] [G loss: 0.313397]\n",
      "epoch:9 step:8879 [D loss: 0.256535, acc.: 51.56%] [G loss: 0.285190]\n",
      "epoch:9 step:8880 [D loss: 0.229737, acc.: 64.84%] [G loss: 0.283954]\n",
      "epoch:9 step:8881 [D loss: 0.241252, acc.: 58.59%] [G loss: 0.311881]\n",
      "epoch:9 step:8882 [D loss: 0.240464, acc.: 61.72%] [G loss: 0.285757]\n",
      "epoch:9 step:8883 [D loss: 0.245195, acc.: 50.78%] [G loss: 0.318544]\n",
      "epoch:9 step:8884 [D loss: 0.254152, acc.: 48.44%] [G loss: 0.300255]\n",
      "epoch:9 step:8885 [D loss: 0.247470, acc.: 60.16%] [G loss: 0.297148]\n",
      "epoch:9 step:8886 [D loss: 0.224718, acc.: 62.50%] [G loss: 0.296101]\n",
      "epoch:9 step:8887 [D loss: 0.232239, acc.: 63.28%] [G loss: 0.295523]\n",
      "epoch:9 step:8888 [D loss: 0.246499, acc.: 60.94%] [G loss: 0.328834]\n",
      "epoch:9 step:8889 [D loss: 0.230315, acc.: 64.06%] [G loss: 0.294692]\n",
      "epoch:9 step:8890 [D loss: 0.250118, acc.: 53.12%] [G loss: 0.317838]\n",
      "epoch:9 step:8891 [D loss: 0.229207, acc.: 61.72%] [G loss: 0.307160]\n",
      "epoch:9 step:8892 [D loss: 0.252523, acc.: 49.22%] [G loss: 0.306006]\n",
      "epoch:9 step:8893 [D loss: 0.249598, acc.: 53.91%] [G loss: 0.299740]\n",
      "epoch:9 step:8894 [D loss: 0.253918, acc.: 54.69%] [G loss: 0.325099]\n",
      "epoch:9 step:8895 [D loss: 0.230359, acc.: 55.47%] [G loss: 0.298564]\n",
      "epoch:9 step:8896 [D loss: 0.253080, acc.: 51.56%] [G loss: 0.287589]\n",
      "epoch:9 step:8897 [D loss: 0.257878, acc.: 46.09%] [G loss: 0.293628]\n",
      "epoch:9 step:8898 [D loss: 0.237912, acc.: 59.38%] [G loss: 0.283607]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:9 step:8899 [D loss: 0.242131, acc.: 57.81%] [G loss: 0.315380]\n",
      "epoch:9 step:8900 [D loss: 0.236199, acc.: 61.72%] [G loss: 0.296536]\n",
      "epoch:9 step:8901 [D loss: 0.232565, acc.: 59.38%] [G loss: 0.307617]\n",
      "epoch:9 step:8902 [D loss: 0.250455, acc.: 47.66%] [G loss: 0.319198]\n",
      "epoch:9 step:8903 [D loss: 0.259978, acc.: 49.22%] [G loss: 0.294796]\n",
      "epoch:9 step:8904 [D loss: 0.232265, acc.: 57.81%] [G loss: 0.285602]\n",
      "epoch:9 step:8905 [D loss: 0.231747, acc.: 58.59%] [G loss: 0.314946]\n",
      "epoch:9 step:8906 [D loss: 0.249520, acc.: 53.12%] [G loss: 0.288338]\n",
      "epoch:9 step:8907 [D loss: 0.222857, acc.: 65.62%] [G loss: 0.325966]\n",
      "epoch:9 step:8908 [D loss: 0.233692, acc.: 58.59%] [G loss: 0.274790]\n",
      "epoch:9 step:8909 [D loss: 0.235605, acc.: 55.47%] [G loss: 0.290748]\n",
      "epoch:9 step:8910 [D loss: 0.255258, acc.: 49.22%] [G loss: 0.302003]\n",
      "epoch:9 step:8911 [D loss: 0.237111, acc.: 59.38%] [G loss: 0.295980]\n",
      "epoch:9 step:8912 [D loss: 0.242483, acc.: 60.94%] [G loss: 0.299131]\n",
      "epoch:9 step:8913 [D loss: 0.225743, acc.: 66.41%] [G loss: 0.333082]\n",
      "epoch:9 step:8914 [D loss: 0.228206, acc.: 60.16%] [G loss: 0.304967]\n",
      "epoch:9 step:8915 [D loss: 0.219943, acc.: 64.84%] [G loss: 0.295912]\n",
      "epoch:9 step:8916 [D loss: 0.233065, acc.: 60.16%] [G loss: 0.281549]\n",
      "epoch:9 step:8917 [D loss: 0.239341, acc.: 60.94%] [G loss: 0.300533]\n",
      "epoch:9 step:8918 [D loss: 0.253392, acc.: 51.56%] [G loss: 0.293807]\n",
      "epoch:9 step:8919 [D loss: 0.239047, acc.: 53.91%] [G loss: 0.279332]\n",
      "epoch:9 step:8920 [D loss: 0.227374, acc.: 60.94%] [G loss: 0.289437]\n",
      "epoch:9 step:8921 [D loss: 0.225762, acc.: 64.84%] [G loss: 0.289900]\n",
      "epoch:9 step:8922 [D loss: 0.247599, acc.: 57.81%] [G loss: 0.281573]\n",
      "epoch:9 step:8923 [D loss: 0.253114, acc.: 58.59%] [G loss: 0.273712]\n",
      "epoch:9 step:8924 [D loss: 0.225014, acc.: 64.06%] [G loss: 0.294446]\n",
      "epoch:9 step:8925 [D loss: 0.237466, acc.: 53.91%] [G loss: 0.301514]\n",
      "epoch:9 step:8926 [D loss: 0.218633, acc.: 58.59%] [G loss: 0.318515]\n",
      "epoch:9 step:8927 [D loss: 0.231640, acc.: 66.41%] [G loss: 0.283747]\n",
      "epoch:9 step:8928 [D loss: 0.251046, acc.: 50.00%] [G loss: 0.299967]\n",
      "epoch:9 step:8929 [D loss: 0.241300, acc.: 56.25%] [G loss: 0.297235]\n",
      "epoch:9 step:8930 [D loss: 0.238260, acc.: 60.94%] [G loss: 0.327177]\n",
      "epoch:9 step:8931 [D loss: 0.234321, acc.: 63.28%] [G loss: 0.315192]\n",
      "epoch:9 step:8932 [D loss: 0.253529, acc.: 52.34%] [G loss: 0.315599]\n",
      "epoch:9 step:8933 [D loss: 0.244719, acc.: 58.59%] [G loss: 0.294137]\n",
      "epoch:9 step:8934 [D loss: 0.226814, acc.: 60.94%] [G loss: 0.312068]\n",
      "epoch:9 step:8935 [D loss: 0.237675, acc.: 57.03%] [G loss: 0.305851]\n",
      "epoch:9 step:8936 [D loss: 0.238987, acc.: 57.03%] [G loss: 0.299477]\n",
      "epoch:9 step:8937 [D loss: 0.237870, acc.: 55.47%] [G loss: 0.301744]\n",
      "epoch:9 step:8938 [D loss: 0.241836, acc.: 58.59%] [G loss: 0.301111]\n",
      "epoch:9 step:8939 [D loss: 0.238445, acc.: 55.47%] [G loss: 0.290227]\n",
      "epoch:9 step:8940 [D loss: 0.240586, acc.: 56.25%] [G loss: 0.295416]\n",
      "epoch:9 step:8941 [D loss: 0.230733, acc.: 58.59%] [G loss: 0.297500]\n",
      "epoch:9 step:8942 [D loss: 0.234878, acc.: 58.59%] [G loss: 0.306391]\n",
      "epoch:9 step:8943 [D loss: 0.247798, acc.: 53.12%] [G loss: 0.285664]\n",
      "epoch:9 step:8944 [D loss: 0.238614, acc.: 60.16%] [G loss: 0.308561]\n",
      "epoch:9 step:8945 [D loss: 0.234442, acc.: 60.16%] [G loss: 0.309546]\n",
      "epoch:9 step:8946 [D loss: 0.230773, acc.: 61.72%] [G loss: 0.319435]\n",
      "epoch:9 step:8947 [D loss: 0.235721, acc.: 62.50%] [G loss: 0.326039]\n",
      "epoch:9 step:8948 [D loss: 0.233223, acc.: 59.38%] [G loss: 0.303004]\n",
      "epoch:9 step:8949 [D loss: 0.229505, acc.: 64.06%] [G loss: 0.287511]\n",
      "epoch:9 step:8950 [D loss: 0.250000, acc.: 53.91%] [G loss: 0.292695]\n",
      "epoch:9 step:8951 [D loss: 0.232860, acc.: 62.50%] [G loss: 0.278785]\n",
      "epoch:9 step:8952 [D loss: 0.252177, acc.: 57.03%] [G loss: 0.325199]\n",
      "epoch:9 step:8953 [D loss: 0.237880, acc.: 54.69%] [G loss: 0.304834]\n",
      "epoch:9 step:8954 [D loss: 0.228447, acc.: 61.72%] [G loss: 0.299361]\n",
      "epoch:9 step:8955 [D loss: 0.240248, acc.: 57.03%] [G loss: 0.301394]\n",
      "epoch:9 step:8956 [D loss: 0.217714, acc.: 67.19%] [G loss: 0.310260]\n",
      "epoch:9 step:8957 [D loss: 0.238118, acc.: 59.38%] [G loss: 0.303249]\n",
      "epoch:9 step:8958 [D loss: 0.228324, acc.: 61.72%] [G loss: 0.298466]\n",
      "epoch:9 step:8959 [D loss: 0.240418, acc.: 54.69%] [G loss: 0.297685]\n",
      "epoch:9 step:8960 [D loss: 0.234535, acc.: 55.47%] [G loss: 0.303982]\n",
      "epoch:9 step:8961 [D loss: 0.242616, acc.: 60.94%] [G loss: 0.308173]\n",
      "epoch:9 step:8962 [D loss: 0.227856, acc.: 60.16%] [G loss: 0.328256]\n",
      "epoch:9 step:8963 [D loss: 0.246442, acc.: 53.91%] [G loss: 0.313093]\n",
      "epoch:9 step:8964 [D loss: 0.260270, acc.: 50.00%] [G loss: 0.289448]\n",
      "epoch:9 step:8965 [D loss: 0.239027, acc.: 55.47%] [G loss: 0.314737]\n",
      "epoch:9 step:8966 [D loss: 0.243903, acc.: 54.69%] [G loss: 0.299907]\n",
      "epoch:9 step:8967 [D loss: 0.250140, acc.: 51.56%] [G loss: 0.302347]\n",
      "epoch:9 step:8968 [D loss: 0.246732, acc.: 52.34%] [G loss: 0.312903]\n",
      "epoch:9 step:8969 [D loss: 0.250456, acc.: 52.34%] [G loss: 0.305530]\n",
      "epoch:9 step:8970 [D loss: 0.248323, acc.: 50.78%] [G loss: 0.287522]\n",
      "epoch:9 step:8971 [D loss: 0.258198, acc.: 43.75%] [G loss: 0.314004]\n",
      "epoch:9 step:8972 [D loss: 0.240870, acc.: 54.69%] [G loss: 0.301906]\n",
      "epoch:9 step:8973 [D loss: 0.232917, acc.: 58.59%] [G loss: 0.284564]\n",
      "epoch:9 step:8974 [D loss: 0.237565, acc.: 57.03%] [G loss: 0.303018]\n",
      "epoch:9 step:8975 [D loss: 0.254023, acc.: 55.47%] [G loss: 0.292572]\n",
      "epoch:9 step:8976 [D loss: 0.239891, acc.: 53.91%] [G loss: 0.328926]\n",
      "epoch:9 step:8977 [D loss: 0.222728, acc.: 61.72%] [G loss: 0.305782]\n",
      "epoch:9 step:8978 [D loss: 0.234206, acc.: 62.50%] [G loss: 0.288955]\n",
      "epoch:9 step:8979 [D loss: 0.244020, acc.: 56.25%] [G loss: 0.294872]\n",
      "epoch:9 step:8980 [D loss: 0.231846, acc.: 56.25%] [G loss: 0.295141]\n",
      "epoch:9 step:8981 [D loss: 0.260484, acc.: 52.34%] [G loss: 0.303285]\n",
      "epoch:9 step:8982 [D loss: 0.233149, acc.: 64.06%] [G loss: 0.300386]\n",
      "epoch:9 step:8983 [D loss: 0.229548, acc.: 63.28%] [G loss: 0.282052]\n",
      "epoch:9 step:8984 [D loss: 0.250219, acc.: 50.00%] [G loss: 0.322790]\n",
      "epoch:9 step:8985 [D loss: 0.241383, acc.: 60.16%] [G loss: 0.303536]\n",
      "epoch:9 step:8986 [D loss: 0.253643, acc.: 51.56%] [G loss: 0.306782]\n",
      "epoch:9 step:8987 [D loss: 0.246314, acc.: 57.81%] [G loss: 0.316583]\n",
      "epoch:9 step:8988 [D loss: 0.246082, acc.: 50.78%] [G loss: 0.308335]\n",
      "epoch:9 step:8989 [D loss: 0.245609, acc.: 54.69%] [G loss: 0.306976]\n",
      "epoch:9 step:8990 [D loss: 0.245783, acc.: 53.12%] [G loss: 0.310283]\n",
      "epoch:9 step:8991 [D loss: 0.233499, acc.: 60.94%] [G loss: 0.336837]\n",
      "epoch:9 step:8992 [D loss: 0.221151, acc.: 66.41%] [G loss: 0.309368]\n",
      "epoch:9 step:8993 [D loss: 0.261250, acc.: 54.69%] [G loss: 0.313483]\n",
      "epoch:9 step:8994 [D loss: 0.241879, acc.: 54.69%] [G loss: 0.298169]\n",
      "epoch:9 step:8995 [D loss: 0.236093, acc.: 57.03%] [G loss: 0.313783]\n",
      "epoch:9 step:8996 [D loss: 0.229520, acc.: 62.50%] [G loss: 0.301125]\n",
      "epoch:9 step:8997 [D loss: 0.227886, acc.: 62.50%] [G loss: 0.287993]\n",
      "epoch:9 step:8998 [D loss: 0.228574, acc.: 67.19%] [G loss: 0.321373]\n",
      "epoch:9 step:8999 [D loss: 0.238940, acc.: 57.03%] [G loss: 0.293496]\n",
      "epoch:9 step:9000 [D loss: 0.242277, acc.: 57.03%] [G loss: 0.271637]\n",
      "epoch:9 step:9001 [D loss: 0.231875, acc.: 59.38%] [G loss: 0.276284]\n",
      "epoch:9 step:9002 [D loss: 0.235813, acc.: 60.94%] [G loss: 0.296977]\n",
      "epoch:9 step:9003 [D loss: 0.222890, acc.: 67.19%] [G loss: 0.303927]\n",
      "epoch:9 step:9004 [D loss: 0.227938, acc.: 63.28%] [G loss: 0.300166]\n",
      "epoch:9 step:9005 [D loss: 0.229179, acc.: 62.50%] [G loss: 0.298166]\n",
      "epoch:9 step:9006 [D loss: 0.267532, acc.: 48.44%] [G loss: 0.307553]\n",
      "epoch:9 step:9007 [D loss: 0.245504, acc.: 60.94%] [G loss: 0.281338]\n",
      "epoch:9 step:9008 [D loss: 0.257399, acc.: 50.00%] [G loss: 0.273063]\n",
      "epoch:9 step:9009 [D loss: 0.239854, acc.: 56.25%] [G loss: 0.275939]\n",
      "epoch:9 step:9010 [D loss: 0.241927, acc.: 60.16%] [G loss: 0.273702]\n",
      "epoch:9 step:9011 [D loss: 0.244888, acc.: 57.81%] [G loss: 0.316717]\n",
      "epoch:9 step:9012 [D loss: 0.239443, acc.: 60.94%] [G loss: 0.282049]\n",
      "epoch:9 step:9013 [D loss: 0.234495, acc.: 58.59%] [G loss: 0.300431]\n",
      "epoch:9 step:9014 [D loss: 0.233413, acc.: 59.38%] [G loss: 0.290590]\n",
      "epoch:9 step:9015 [D loss: 0.238251, acc.: 62.50%] [G loss: 0.312330]\n",
      "epoch:9 step:9016 [D loss: 0.243252, acc.: 57.81%] [G loss: 0.276174]\n",
      "epoch:9 step:9017 [D loss: 0.249964, acc.: 58.59%] [G loss: 0.325466]\n",
      "epoch:9 step:9018 [D loss: 0.243023, acc.: 54.69%] [G loss: 0.281177]\n",
      "epoch:9 step:9019 [D loss: 0.241795, acc.: 57.81%] [G loss: 0.293466]\n",
      "epoch:9 step:9020 [D loss: 0.243278, acc.: 59.38%] [G loss: 0.292423]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:9 step:9021 [D loss: 0.244563, acc.: 58.59%] [G loss: 0.285996]\n",
      "epoch:9 step:9022 [D loss: 0.243088, acc.: 53.91%] [G loss: 0.294946]\n",
      "epoch:9 step:9023 [D loss: 0.244295, acc.: 54.69%] [G loss: 0.287402]\n",
      "epoch:9 step:9024 [D loss: 0.240724, acc.: 58.59%] [G loss: 0.299861]\n",
      "epoch:9 step:9025 [D loss: 0.254295, acc.: 55.47%] [G loss: 0.289337]\n",
      "epoch:9 step:9026 [D loss: 0.259058, acc.: 53.91%] [G loss: 0.308075]\n",
      "epoch:9 step:9027 [D loss: 0.224057, acc.: 60.16%] [G loss: 0.300218]\n",
      "epoch:9 step:9028 [D loss: 0.249997, acc.: 53.91%] [G loss: 0.289396]\n",
      "epoch:9 step:9029 [D loss: 0.226486, acc.: 58.59%] [G loss: 0.304236]\n",
      "epoch:9 step:9030 [D loss: 0.225354, acc.: 61.72%] [G loss: 0.300873]\n",
      "epoch:9 step:9031 [D loss: 0.239547, acc.: 59.38%] [G loss: 0.308759]\n",
      "epoch:9 step:9032 [D loss: 0.245742, acc.: 59.38%] [G loss: 0.310365]\n",
      "epoch:9 step:9033 [D loss: 0.228094, acc.: 64.06%] [G loss: 0.296814]\n",
      "epoch:9 step:9034 [D loss: 0.251946, acc.: 53.12%] [G loss: 0.304181]\n",
      "epoch:9 step:9035 [D loss: 0.232691, acc.: 60.16%] [G loss: 0.305882]\n",
      "epoch:9 step:9036 [D loss: 0.240897, acc.: 56.25%] [G loss: 0.287069]\n",
      "epoch:9 step:9037 [D loss: 0.242756, acc.: 51.56%] [G loss: 0.284405]\n",
      "epoch:9 step:9038 [D loss: 0.249355, acc.: 52.34%] [G loss: 0.287379]\n",
      "epoch:9 step:9039 [D loss: 0.265819, acc.: 47.66%] [G loss: 0.282653]\n",
      "epoch:9 step:9040 [D loss: 0.251253, acc.: 56.25%] [G loss: 0.292226]\n",
      "epoch:9 step:9041 [D loss: 0.227994, acc.: 61.72%] [G loss: 0.307261]\n",
      "epoch:9 step:9042 [D loss: 0.225758, acc.: 65.62%] [G loss: 0.326674]\n",
      "epoch:9 step:9043 [D loss: 0.240617, acc.: 51.56%] [G loss: 0.293674]\n",
      "epoch:9 step:9044 [D loss: 0.245073, acc.: 52.34%] [G loss: 0.306594]\n",
      "epoch:9 step:9045 [D loss: 0.250194, acc.: 54.69%] [G loss: 0.291143]\n",
      "epoch:9 step:9046 [D loss: 0.238485, acc.: 56.25%] [G loss: 0.294959]\n",
      "epoch:9 step:9047 [D loss: 0.239764, acc.: 55.47%] [G loss: 0.326054]\n",
      "epoch:9 step:9048 [D loss: 0.233757, acc.: 58.59%] [G loss: 0.305708]\n",
      "epoch:9 step:9049 [D loss: 0.232506, acc.: 60.94%] [G loss: 0.289173]\n",
      "epoch:9 step:9050 [D loss: 0.228942, acc.: 63.28%] [G loss: 0.294381]\n",
      "epoch:9 step:9051 [D loss: 0.246246, acc.: 58.59%] [G loss: 0.308596]\n",
      "epoch:9 step:9052 [D loss: 0.234006, acc.: 63.28%] [G loss: 0.303044]\n",
      "epoch:9 step:9053 [D loss: 0.251346, acc.: 52.34%] [G loss: 0.277254]\n",
      "epoch:9 step:9054 [D loss: 0.235709, acc.: 59.38%] [G loss: 0.281133]\n",
      "epoch:9 step:9055 [D loss: 0.254432, acc.: 52.34%] [G loss: 0.280736]\n",
      "epoch:9 step:9056 [D loss: 0.239342, acc.: 56.25%] [G loss: 0.304803]\n",
      "epoch:9 step:9057 [D loss: 0.237530, acc.: 54.69%] [G loss: 0.282794]\n",
      "epoch:9 step:9058 [D loss: 0.239891, acc.: 55.47%] [G loss: 0.293371]\n",
      "epoch:9 step:9059 [D loss: 0.256872, acc.: 50.78%] [G loss: 0.284872]\n",
      "epoch:9 step:9060 [D loss: 0.242538, acc.: 56.25%] [G loss: 0.281111]\n",
      "epoch:9 step:9061 [D loss: 0.237346, acc.: 57.81%] [G loss: 0.322930]\n",
      "epoch:9 step:9062 [D loss: 0.222416, acc.: 63.28%] [G loss: 0.307726]\n",
      "epoch:9 step:9063 [D loss: 0.246378, acc.: 53.91%] [G loss: 0.281382]\n",
      "epoch:9 step:9064 [D loss: 0.232242, acc.: 59.38%] [G loss: 0.284256]\n",
      "epoch:9 step:9065 [D loss: 0.246094, acc.: 52.34%] [G loss: 0.287567]\n",
      "epoch:9 step:9066 [D loss: 0.245077, acc.: 57.03%] [G loss: 0.293234]\n",
      "epoch:9 step:9067 [D loss: 0.240666, acc.: 56.25%] [G loss: 0.292461]\n",
      "epoch:9 step:9068 [D loss: 0.235107, acc.: 60.16%] [G loss: 0.314466]\n",
      "epoch:9 step:9069 [D loss: 0.242041, acc.: 60.16%] [G loss: 0.280586]\n",
      "epoch:9 step:9070 [D loss: 0.240479, acc.: 57.81%] [G loss: 0.298040]\n",
      "epoch:9 step:9071 [D loss: 0.250185, acc.: 57.03%] [G loss: 0.305348]\n",
      "epoch:9 step:9072 [D loss: 0.250459, acc.: 54.69%] [G loss: 0.285656]\n",
      "epoch:9 step:9073 [D loss: 0.253183, acc.: 51.56%] [G loss: 0.287173]\n",
      "epoch:9 step:9074 [D loss: 0.233520, acc.: 65.62%] [G loss: 0.295938]\n",
      "epoch:9 step:9075 [D loss: 0.251106, acc.: 55.47%] [G loss: 0.318179]\n",
      "epoch:9 step:9076 [D loss: 0.233411, acc.: 61.72%] [G loss: 0.279335]\n",
      "epoch:9 step:9077 [D loss: 0.236385, acc.: 53.12%] [G loss: 0.299374]\n",
      "epoch:9 step:9078 [D loss: 0.241654, acc.: 57.81%] [G loss: 0.296616]\n",
      "epoch:9 step:9079 [D loss: 0.237441, acc.: 61.72%] [G loss: 0.304150]\n",
      "epoch:9 step:9080 [D loss: 0.235883, acc.: 62.50%] [G loss: 0.299943]\n",
      "epoch:9 step:9081 [D loss: 0.243375, acc.: 61.72%] [G loss: 0.313691]\n",
      "epoch:9 step:9082 [D loss: 0.244297, acc.: 53.12%] [G loss: 0.303895]\n",
      "epoch:9 step:9083 [D loss: 0.224332, acc.: 66.41%] [G loss: 0.280911]\n",
      "epoch:9 step:9084 [D loss: 0.258450, acc.: 50.78%] [G loss: 0.299970]\n",
      "epoch:9 step:9085 [D loss: 0.235704, acc.: 60.16%] [G loss: 0.301653]\n",
      "epoch:9 step:9086 [D loss: 0.238243, acc.: 52.34%] [G loss: 0.294760]\n",
      "epoch:9 step:9087 [D loss: 0.231918, acc.: 62.50%] [G loss: 0.298660]\n",
      "epoch:9 step:9088 [D loss: 0.243073, acc.: 54.69%] [G loss: 0.284386]\n",
      "epoch:9 step:9089 [D loss: 0.242907, acc.: 57.03%] [G loss: 0.264950]\n",
      "epoch:9 step:9090 [D loss: 0.240929, acc.: 54.69%] [G loss: 0.275088]\n",
      "epoch:9 step:9091 [D loss: 0.246210, acc.: 54.69%] [G loss: 0.300321]\n",
      "epoch:9 step:9092 [D loss: 0.247870, acc.: 53.12%] [G loss: 0.284209]\n",
      "epoch:9 step:9093 [D loss: 0.219171, acc.: 62.50%] [G loss: 0.305643]\n",
      "epoch:9 step:9094 [D loss: 0.253735, acc.: 50.00%] [G loss: 0.307186]\n",
      "epoch:9 step:9095 [D loss: 0.243131, acc.: 56.25%] [G loss: 0.306426]\n",
      "epoch:9 step:9096 [D loss: 0.243013, acc.: 58.59%] [G loss: 0.295089]\n",
      "epoch:9 step:9097 [D loss: 0.236385, acc.: 62.50%] [G loss: 0.280752]\n",
      "epoch:9 step:9098 [D loss: 0.234087, acc.: 58.59%] [G loss: 0.284501]\n",
      "epoch:9 step:9099 [D loss: 0.230306, acc.: 64.06%] [G loss: 0.283141]\n",
      "epoch:9 step:9100 [D loss: 0.237888, acc.: 59.38%] [G loss: 0.294989]\n",
      "epoch:9 step:9101 [D loss: 0.238000, acc.: 60.16%] [G loss: 0.296038]\n",
      "epoch:9 step:9102 [D loss: 0.249516, acc.: 51.56%] [G loss: 0.281577]\n",
      "epoch:9 step:9103 [D loss: 0.245994, acc.: 51.56%] [G loss: 0.293994]\n",
      "epoch:9 step:9104 [D loss: 0.236991, acc.: 58.59%] [G loss: 0.291830]\n",
      "epoch:9 step:9105 [D loss: 0.241709, acc.: 66.41%] [G loss: 0.320820]\n",
      "epoch:9 step:9106 [D loss: 0.247509, acc.: 53.91%] [G loss: 0.295895]\n",
      "epoch:9 step:9107 [D loss: 0.230435, acc.: 64.84%] [G loss: 0.326825]\n",
      "epoch:9 step:9108 [D loss: 0.241087, acc.: 64.06%] [G loss: 0.284539]\n",
      "epoch:9 step:9109 [D loss: 0.228613, acc.: 57.03%] [G loss: 0.313778]\n",
      "epoch:9 step:9110 [D loss: 0.237453, acc.: 59.38%] [G loss: 0.298152]\n",
      "epoch:9 step:9111 [D loss: 0.234810, acc.: 59.38%] [G loss: 0.296332]\n",
      "epoch:9 step:9112 [D loss: 0.247027, acc.: 47.66%] [G loss: 0.325712]\n",
      "epoch:9 step:9113 [D loss: 0.244583, acc.: 56.25%] [G loss: 0.322039]\n",
      "epoch:9 step:9114 [D loss: 0.248173, acc.: 60.16%] [G loss: 0.296296]\n",
      "epoch:9 step:9115 [D loss: 0.232640, acc.: 63.28%] [G loss: 0.316397]\n",
      "epoch:9 step:9116 [D loss: 0.271000, acc.: 50.78%] [G loss: 0.291477]\n",
      "epoch:9 step:9117 [D loss: 0.229680, acc.: 62.50%] [G loss: 0.302077]\n",
      "epoch:9 step:9118 [D loss: 0.259347, acc.: 50.00%] [G loss: 0.309954]\n",
      "epoch:9 step:9119 [D loss: 0.248118, acc.: 58.59%] [G loss: 0.283239]\n",
      "epoch:9 step:9120 [D loss: 0.230077, acc.: 59.38%] [G loss: 0.312577]\n",
      "epoch:9 step:9121 [D loss: 0.242122, acc.: 54.69%] [G loss: 0.287387]\n",
      "epoch:9 step:9122 [D loss: 0.241872, acc.: 55.47%] [G loss: 0.303927]\n",
      "epoch:9 step:9123 [D loss: 0.244127, acc.: 53.12%] [G loss: 0.301332]\n",
      "epoch:9 step:9124 [D loss: 0.247145, acc.: 60.16%] [G loss: 0.308051]\n",
      "epoch:9 step:9125 [D loss: 0.225225, acc.: 60.94%] [G loss: 0.314437]\n",
      "epoch:9 step:9126 [D loss: 0.235069, acc.: 63.28%] [G loss: 0.311190]\n",
      "epoch:9 step:9127 [D loss: 0.249321, acc.: 52.34%] [G loss: 0.292149]\n",
      "epoch:9 step:9128 [D loss: 0.236940, acc.: 56.25%] [G loss: 0.270566]\n",
      "epoch:9 step:9129 [D loss: 0.257309, acc.: 50.00%] [G loss: 0.297391]\n",
      "epoch:9 step:9130 [D loss: 0.230355, acc.: 60.94%] [G loss: 0.285625]\n",
      "epoch:9 step:9131 [D loss: 0.240480, acc.: 59.38%] [G loss: 0.309205]\n",
      "epoch:9 step:9132 [D loss: 0.222251, acc.: 66.41%] [G loss: 0.302695]\n",
      "epoch:9 step:9133 [D loss: 0.239328, acc.: 55.47%] [G loss: 0.300874]\n",
      "epoch:9 step:9134 [D loss: 0.250045, acc.: 55.47%] [G loss: 0.283461]\n",
      "epoch:9 step:9135 [D loss: 0.234441, acc.: 57.03%] [G loss: 0.311168]\n",
      "epoch:9 step:9136 [D loss: 0.236655, acc.: 60.16%] [G loss: 0.316113]\n",
      "epoch:9 step:9137 [D loss: 0.244931, acc.: 57.81%] [G loss: 0.306692]\n",
      "epoch:9 step:9138 [D loss: 0.240968, acc.: 59.38%] [G loss: 0.300432]\n",
      "epoch:9 step:9139 [D loss: 0.264255, acc.: 46.88%] [G loss: 0.290460]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:9 step:9140 [D loss: 0.250591, acc.: 57.03%] [G loss: 0.305554]\n",
      "epoch:9 step:9141 [D loss: 0.226324, acc.: 61.72%] [G loss: 0.305376]\n",
      "epoch:9 step:9142 [D loss: 0.258236, acc.: 53.12%] [G loss: 0.270828]\n",
      "epoch:9 step:9143 [D loss: 0.251068, acc.: 56.25%] [G loss: 0.287937]\n",
      "epoch:9 step:9144 [D loss: 0.238766, acc.: 57.81%] [G loss: 0.295831]\n",
      "epoch:9 step:9145 [D loss: 0.243289, acc.: 57.81%] [G loss: 0.290252]\n",
      "epoch:9 step:9146 [D loss: 0.236275, acc.: 60.94%] [G loss: 0.291739]\n",
      "epoch:9 step:9147 [D loss: 0.235832, acc.: 60.16%] [G loss: 0.301014]\n",
      "epoch:9 step:9148 [D loss: 0.243867, acc.: 55.47%] [G loss: 0.326891]\n",
      "epoch:9 step:9149 [D loss: 0.230040, acc.: 64.06%] [G loss: 0.306491]\n",
      "epoch:9 step:9150 [D loss: 0.236225, acc.: 58.59%] [G loss: 0.300473]\n",
      "epoch:9 step:9151 [D loss: 0.248720, acc.: 52.34%] [G loss: 0.309304]\n",
      "epoch:9 step:9152 [D loss: 0.239201, acc.: 58.59%] [G loss: 0.329462]\n",
      "epoch:9 step:9153 [D loss: 0.236271, acc.: 57.81%] [G loss: 0.304754]\n",
      "epoch:9 step:9154 [D loss: 0.226006, acc.: 66.41%] [G loss: 0.304167]\n",
      "epoch:9 step:9155 [D loss: 0.242816, acc.: 55.47%] [G loss: 0.315838]\n",
      "epoch:9 step:9156 [D loss: 0.242553, acc.: 58.59%] [G loss: 0.290099]\n",
      "epoch:9 step:9157 [D loss: 0.244262, acc.: 52.34%] [G loss: 0.312954]\n",
      "epoch:9 step:9158 [D loss: 0.234177, acc.: 62.50%] [G loss: 0.292974]\n",
      "epoch:9 step:9159 [D loss: 0.235534, acc.: 58.59%] [G loss: 0.290571]\n",
      "epoch:9 step:9160 [D loss: 0.237292, acc.: 57.03%] [G loss: 0.304424]\n",
      "epoch:9 step:9161 [D loss: 0.232674, acc.: 64.84%] [G loss: 0.275787]\n",
      "epoch:9 step:9162 [D loss: 0.253020, acc.: 46.09%] [G loss: 0.312875]\n",
      "epoch:9 step:9163 [D loss: 0.223630, acc.: 60.16%] [G loss: 0.292420]\n",
      "epoch:9 step:9164 [D loss: 0.235069, acc.: 59.38%] [G loss: 0.299217]\n",
      "epoch:9 step:9165 [D loss: 0.259646, acc.: 49.22%] [G loss: 0.285130]\n",
      "epoch:9 step:9166 [D loss: 0.222642, acc.: 64.06%] [G loss: 0.310790]\n",
      "epoch:9 step:9167 [D loss: 0.233674, acc.: 59.38%] [G loss: 0.307751]\n",
      "epoch:9 step:9168 [D loss: 0.244040, acc.: 54.69%] [G loss: 0.288967]\n",
      "epoch:9 step:9169 [D loss: 0.242464, acc.: 57.03%] [G loss: 0.302379]\n",
      "epoch:9 step:9170 [D loss: 0.229868, acc.: 61.72%] [G loss: 0.311760]\n",
      "epoch:9 step:9171 [D loss: 0.246497, acc.: 53.12%] [G loss: 0.280391]\n",
      "epoch:9 step:9172 [D loss: 0.244091, acc.: 54.69%] [G loss: 0.317939]\n",
      "epoch:9 step:9173 [D loss: 0.258139, acc.: 46.09%] [G loss: 0.279335]\n",
      "epoch:9 step:9174 [D loss: 0.222418, acc.: 67.97%] [G loss: 0.294493]\n",
      "epoch:9 step:9175 [D loss: 0.243408, acc.: 60.16%] [G loss: 0.287045]\n",
      "epoch:9 step:9176 [D loss: 0.243721, acc.: 53.12%] [G loss: 0.295752]\n",
      "epoch:9 step:9177 [D loss: 0.253763, acc.: 53.91%] [G loss: 0.278005]\n",
      "epoch:9 step:9178 [D loss: 0.241382, acc.: 58.59%] [G loss: 0.283093]\n",
      "epoch:9 step:9179 [D loss: 0.236234, acc.: 59.38%] [G loss: 0.300203]\n",
      "epoch:9 step:9180 [D loss: 0.251695, acc.: 53.91%] [G loss: 0.260529]\n",
      "epoch:9 step:9181 [D loss: 0.234746, acc.: 60.94%] [G loss: 0.302878]\n",
      "epoch:9 step:9182 [D loss: 0.238788, acc.: 59.38%] [G loss: 0.293613]\n",
      "epoch:9 step:9183 [D loss: 0.249761, acc.: 53.91%] [G loss: 0.310066]\n",
      "epoch:9 step:9184 [D loss: 0.233989, acc.: 59.38%] [G loss: 0.301976]\n",
      "epoch:9 step:9185 [D loss: 0.246135, acc.: 50.78%] [G loss: 0.292034]\n",
      "epoch:9 step:9186 [D loss: 0.244344, acc.: 55.47%] [G loss: 0.294165]\n",
      "epoch:9 step:9187 [D loss: 0.243441, acc.: 56.25%] [G loss: 0.293086]\n",
      "epoch:9 step:9188 [D loss: 0.230794, acc.: 65.62%] [G loss: 0.291462]\n",
      "epoch:9 step:9189 [D loss: 0.235578, acc.: 59.38%] [G loss: 0.291332]\n",
      "epoch:9 step:9190 [D loss: 0.243027, acc.: 59.38%] [G loss: 0.288250]\n",
      "epoch:9 step:9191 [D loss: 0.235754, acc.: 57.81%] [G loss: 0.291198]\n",
      "epoch:9 step:9192 [D loss: 0.227478, acc.: 65.62%] [G loss: 0.307487]\n",
      "epoch:9 step:9193 [D loss: 0.228540, acc.: 63.28%] [G loss: 0.275457]\n",
      "epoch:9 step:9194 [D loss: 0.245209, acc.: 52.34%] [G loss: 0.303138]\n",
      "epoch:9 step:9195 [D loss: 0.261043, acc.: 50.78%] [G loss: 0.271676]\n",
      "epoch:9 step:9196 [D loss: 0.219008, acc.: 64.06%] [G loss: 0.252872]\n",
      "epoch:9 step:9197 [D loss: 0.248397, acc.: 56.25%] [G loss: 0.283384]\n",
      "epoch:9 step:9198 [D loss: 0.244873, acc.: 53.91%] [G loss: 0.277508]\n",
      "epoch:9 step:9199 [D loss: 0.256347, acc.: 53.12%] [G loss: 0.282470]\n",
      "epoch:9 step:9200 [D loss: 0.258542, acc.: 51.56%] [G loss: 0.267889]\n",
      "epoch:9 step:9201 [D loss: 0.223864, acc.: 60.94%] [G loss: 0.289602]\n",
      "epoch:9 step:9202 [D loss: 0.238402, acc.: 57.03%] [G loss: 0.290221]\n",
      "epoch:9 step:9203 [D loss: 0.241022, acc.: 61.72%] [G loss: 0.316160]\n",
      "epoch:9 step:9204 [D loss: 0.241556, acc.: 53.12%] [G loss: 0.294355]\n",
      "epoch:9 step:9205 [D loss: 0.230807, acc.: 64.84%] [G loss: 0.321489]\n",
      "epoch:9 step:9206 [D loss: 0.246226, acc.: 52.34%] [G loss: 0.292793]\n",
      "epoch:9 step:9207 [D loss: 0.242477, acc.: 63.28%] [G loss: 0.277193]\n",
      "epoch:9 step:9208 [D loss: 0.228577, acc.: 64.06%] [G loss: 0.311236]\n",
      "epoch:9 step:9209 [D loss: 0.251605, acc.: 57.03%] [G loss: 0.282306]\n",
      "epoch:9 step:9210 [D loss: 0.232024, acc.: 61.72%] [G loss: 0.291198]\n",
      "epoch:9 step:9211 [D loss: 0.249718, acc.: 56.25%] [G loss: 0.328642]\n",
      "epoch:9 step:9212 [D loss: 0.249494, acc.: 56.25%] [G loss: 0.298035]\n",
      "epoch:9 step:9213 [D loss: 0.252793, acc.: 57.81%] [G loss: 0.322784]\n",
      "epoch:9 step:9214 [D loss: 0.258256, acc.: 53.12%] [G loss: 0.284071]\n",
      "epoch:9 step:9215 [D loss: 0.242990, acc.: 56.25%] [G loss: 0.298221]\n",
      "epoch:9 step:9216 [D loss: 0.241288, acc.: 62.50%] [G loss: 0.282917]\n",
      "epoch:9 step:9217 [D loss: 0.233408, acc.: 57.81%] [G loss: 0.314179]\n",
      "epoch:9 step:9218 [D loss: 0.253942, acc.: 55.47%] [G loss: 0.293822]\n",
      "epoch:9 step:9219 [D loss: 0.257332, acc.: 46.88%] [G loss: 0.279369]\n",
      "epoch:9 step:9220 [D loss: 0.229982, acc.: 58.59%] [G loss: 0.320372]\n",
      "epoch:9 step:9221 [D loss: 0.245016, acc.: 60.16%] [G loss: 0.316775]\n",
      "epoch:9 step:9222 [D loss: 0.233105, acc.: 56.25%] [G loss: 0.295876]\n",
      "epoch:9 step:9223 [D loss: 0.238745, acc.: 53.91%] [G loss: 0.329843]\n",
      "epoch:9 step:9224 [D loss: 0.251891, acc.: 51.56%] [G loss: 0.302801]\n",
      "epoch:9 step:9225 [D loss: 0.228725, acc.: 65.62%] [G loss: 0.300243]\n",
      "epoch:9 step:9226 [D loss: 0.257457, acc.: 50.00%] [G loss: 0.298972]\n",
      "epoch:9 step:9227 [D loss: 0.242176, acc.: 57.81%] [G loss: 0.313529]\n",
      "epoch:9 step:9228 [D loss: 0.237009, acc.: 55.47%] [G loss: 0.294838]\n",
      "epoch:9 step:9229 [D loss: 0.237435, acc.: 57.03%] [G loss: 0.311468]\n",
      "epoch:9 step:9230 [D loss: 0.239701, acc.: 51.56%] [G loss: 0.298888]\n",
      "epoch:9 step:9231 [D loss: 0.227325, acc.: 66.41%] [G loss: 0.297853]\n",
      "epoch:9 step:9232 [D loss: 0.238273, acc.: 61.72%] [G loss: 0.307867]\n",
      "epoch:9 step:9233 [D loss: 0.244931, acc.: 58.59%] [G loss: 0.320400]\n",
      "epoch:9 step:9234 [D loss: 0.230988, acc.: 62.50%] [G loss: 0.287650]\n",
      "epoch:9 step:9235 [D loss: 0.238725, acc.: 58.59%] [G loss: 0.305209]\n",
      "epoch:9 step:9236 [D loss: 0.249476, acc.: 53.91%] [G loss: 0.279775]\n",
      "epoch:9 step:9237 [D loss: 0.234941, acc.: 63.28%] [G loss: 0.271378]\n",
      "epoch:9 step:9238 [D loss: 0.246116, acc.: 57.03%] [G loss: 0.262059]\n",
      "epoch:9 step:9239 [D loss: 0.249610, acc.: 56.25%] [G loss: 0.301177]\n",
      "epoch:9 step:9240 [D loss: 0.239626, acc.: 60.16%] [G loss: 0.277353]\n",
      "epoch:9 step:9241 [D loss: 0.241403, acc.: 57.03%] [G loss: 0.320613]\n",
      "epoch:9 step:9242 [D loss: 0.238700, acc.: 58.59%] [G loss: 0.266658]\n",
      "epoch:9 step:9243 [D loss: 0.240351, acc.: 60.16%] [G loss: 0.294145]\n",
      "epoch:9 step:9244 [D loss: 0.226795, acc.: 62.50%] [G loss: 0.323058]\n",
      "epoch:9 step:9245 [D loss: 0.242572, acc.: 60.16%] [G loss: 0.275762]\n",
      "epoch:9 step:9246 [D loss: 0.235873, acc.: 59.38%] [G loss: 0.298279]\n",
      "epoch:9 step:9247 [D loss: 0.239000, acc.: 58.59%] [G loss: 0.301189]\n",
      "epoch:9 step:9248 [D loss: 0.254428, acc.: 55.47%] [G loss: 0.271526]\n",
      "epoch:9 step:9249 [D loss: 0.234255, acc.: 58.59%] [G loss: 0.270216]\n",
      "epoch:9 step:9250 [D loss: 0.242669, acc.: 57.81%] [G loss: 0.295301]\n",
      "epoch:9 step:9251 [D loss: 0.247402, acc.: 54.69%] [G loss: 0.272875]\n",
      "epoch:9 step:9252 [D loss: 0.234051, acc.: 60.94%] [G loss: 0.294713]\n",
      "epoch:9 step:9253 [D loss: 0.243850, acc.: 57.03%] [G loss: 0.304752]\n",
      "epoch:9 step:9254 [D loss: 0.251929, acc.: 51.56%] [G loss: 0.302548]\n",
      "epoch:9 step:9255 [D loss: 0.243157, acc.: 53.12%] [G loss: 0.310120]\n",
      "epoch:9 step:9256 [D loss: 0.246317, acc.: 56.25%] [G loss: 0.271226]\n",
      "epoch:9 step:9257 [D loss: 0.224277, acc.: 63.28%] [G loss: 0.296461]\n",
      "epoch:9 step:9258 [D loss: 0.256271, acc.: 50.00%] [G loss: 0.272682]\n",
      "epoch:9 step:9259 [D loss: 0.230856, acc.: 64.84%] [G loss: 0.297783]\n",
      "epoch:9 step:9260 [D loss: 0.246248, acc.: 57.81%] [G loss: 0.263414]\n",
      "epoch:9 step:9261 [D loss: 0.256247, acc.: 54.69%] [G loss: 0.262325]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:9 step:9262 [D loss: 0.251556, acc.: 54.69%] [G loss: 0.319297]\n",
      "epoch:9 step:9263 [D loss: 0.230009, acc.: 63.28%] [G loss: 0.307969]\n",
      "epoch:9 step:9264 [D loss: 0.257745, acc.: 51.56%] [G loss: 0.291919]\n",
      "epoch:9 step:9265 [D loss: 0.233916, acc.: 60.94%] [G loss: 0.276948]\n",
      "epoch:9 step:9266 [D loss: 0.234914, acc.: 58.59%] [G loss: 0.309403]\n",
      "epoch:9 step:9267 [D loss: 0.249396, acc.: 58.59%] [G loss: 0.306221]\n",
      "epoch:9 step:9268 [D loss: 0.242608, acc.: 60.16%] [G loss: 0.322431]\n",
      "epoch:9 step:9269 [D loss: 0.255295, acc.: 53.12%] [G loss: 0.277866]\n",
      "epoch:9 step:9270 [D loss: 0.247783, acc.: 51.56%] [G loss: 0.285476]\n",
      "epoch:9 step:9271 [D loss: 0.251623, acc.: 56.25%] [G loss: 0.298023]\n",
      "epoch:9 step:9272 [D loss: 0.248684, acc.: 53.91%] [G loss: 0.287037]\n",
      "epoch:9 step:9273 [D loss: 0.245486, acc.: 55.47%] [G loss: 0.301148]\n",
      "epoch:9 step:9274 [D loss: 0.243198, acc.: 57.81%] [G loss: 0.297745]\n",
      "epoch:9 step:9275 [D loss: 0.242825, acc.: 56.25%] [G loss: 0.325539]\n",
      "epoch:9 step:9276 [D loss: 0.243588, acc.: 57.81%] [G loss: 0.298378]\n",
      "epoch:9 step:9277 [D loss: 0.254391, acc.: 53.12%] [G loss: 0.289978]\n",
      "epoch:9 step:9278 [D loss: 0.234079, acc.: 57.81%] [G loss: 0.309503]\n",
      "epoch:9 step:9279 [D loss: 0.232774, acc.: 53.91%] [G loss: 0.287064]\n",
      "epoch:9 step:9280 [D loss: 0.236520, acc.: 59.38%] [G loss: 0.304626]\n",
      "epoch:9 step:9281 [D loss: 0.241839, acc.: 58.59%] [G loss: 0.294286]\n",
      "epoch:9 step:9282 [D loss: 0.232163, acc.: 58.59%] [G loss: 0.299366]\n",
      "epoch:9 step:9283 [D loss: 0.245201, acc.: 57.03%] [G loss: 0.294947]\n",
      "epoch:9 step:9284 [D loss: 0.239558, acc.: 57.81%] [G loss: 0.307485]\n",
      "epoch:9 step:9285 [D loss: 0.222615, acc.: 64.84%] [G loss: 0.288817]\n",
      "epoch:9 step:9286 [D loss: 0.223937, acc.: 62.50%] [G loss: 0.307828]\n",
      "epoch:9 step:9287 [D loss: 0.258469, acc.: 50.00%] [G loss: 0.291717]\n",
      "epoch:9 step:9288 [D loss: 0.246062, acc.: 58.59%] [G loss: 0.326640]\n",
      "epoch:9 step:9289 [D loss: 0.250103, acc.: 57.03%] [G loss: 0.290827]\n",
      "epoch:9 step:9290 [D loss: 0.252494, acc.: 51.56%] [G loss: 0.297585]\n",
      "epoch:9 step:9291 [D loss: 0.232111, acc.: 58.59%] [G loss: 0.291954]\n",
      "epoch:9 step:9292 [D loss: 0.239084, acc.: 57.81%] [G loss: 0.271142]\n",
      "epoch:9 step:9293 [D loss: 0.239750, acc.: 53.91%] [G loss: 0.276995]\n",
      "epoch:9 step:9294 [D loss: 0.241292, acc.: 56.25%] [G loss: 0.329197]\n",
      "epoch:9 step:9295 [D loss: 0.265752, acc.: 46.88%] [G loss: 0.286205]\n",
      "epoch:9 step:9296 [D loss: 0.245086, acc.: 53.12%] [G loss: 0.259030]\n",
      "epoch:9 step:9297 [D loss: 0.249663, acc.: 49.22%] [G loss: 0.281012]\n",
      "epoch:9 step:9298 [D loss: 0.236140, acc.: 53.12%] [G loss: 0.293669]\n",
      "epoch:9 step:9299 [D loss: 0.230176, acc.: 61.72%] [G loss: 0.306575]\n",
      "epoch:9 step:9300 [D loss: 0.243033, acc.: 58.59%] [G loss: 0.299689]\n",
      "epoch:9 step:9301 [D loss: 0.245051, acc.: 55.47%] [G loss: 0.314722]\n",
      "epoch:9 step:9302 [D loss: 0.241397, acc.: 62.50%] [G loss: 0.307015]\n",
      "epoch:9 step:9303 [D loss: 0.224795, acc.: 62.50%] [G loss: 0.315708]\n",
      "epoch:9 step:9304 [D loss: 0.248471, acc.: 52.34%] [G loss: 0.297811]\n",
      "epoch:9 step:9305 [D loss: 0.265939, acc.: 44.53%] [G loss: 0.305093]\n",
      "epoch:9 step:9306 [D loss: 0.229035, acc.: 60.16%] [G loss: 0.303794]\n",
      "epoch:9 step:9307 [D loss: 0.236338, acc.: 57.03%] [G loss: 0.303608]\n",
      "epoch:9 step:9308 [D loss: 0.231417, acc.: 59.38%] [G loss: 0.299893]\n",
      "epoch:9 step:9309 [D loss: 0.259178, acc.: 49.22%] [G loss: 0.298159]\n",
      "epoch:9 step:9310 [D loss: 0.237791, acc.: 63.28%] [G loss: 0.311939]\n",
      "epoch:9 step:9311 [D loss: 0.245958, acc.: 58.59%] [G loss: 0.301258]\n",
      "epoch:9 step:9312 [D loss: 0.251677, acc.: 52.34%] [G loss: 0.329591]\n",
      "epoch:9 step:9313 [D loss: 0.238504, acc.: 58.59%] [G loss: 0.332534]\n",
      "epoch:9 step:9314 [D loss: 0.238994, acc.: 57.03%] [G loss: 0.275828]\n",
      "epoch:9 step:9315 [D loss: 0.214724, acc.: 67.97%] [G loss: 0.328556]\n",
      "epoch:9 step:9316 [D loss: 0.246265, acc.: 53.91%] [G loss: 0.301868]\n",
      "epoch:9 step:9317 [D loss: 0.227520, acc.: 60.94%] [G loss: 0.308308]\n",
      "epoch:9 step:9318 [D loss: 0.233263, acc.: 60.94%] [G loss: 0.293922]\n",
      "epoch:9 step:9319 [D loss: 0.225217, acc.: 64.84%] [G loss: 0.308144]\n",
      "epoch:9 step:9320 [D loss: 0.232384, acc.: 57.81%] [G loss: 0.296095]\n",
      "epoch:9 step:9321 [D loss: 0.239319, acc.: 58.59%] [G loss: 0.331182]\n",
      "epoch:9 step:9322 [D loss: 0.233946, acc.: 63.28%] [G loss: 0.289048]\n",
      "epoch:9 step:9323 [D loss: 0.238209, acc.: 61.72%] [G loss: 0.305286]\n",
      "epoch:9 step:9324 [D loss: 0.237241, acc.: 57.81%] [G loss: 0.336764]\n",
      "epoch:9 step:9325 [D loss: 0.238760, acc.: 56.25%] [G loss: 0.305827]\n",
      "epoch:9 step:9326 [D loss: 0.252220, acc.: 52.34%] [G loss: 0.313683]\n",
      "epoch:9 step:9327 [D loss: 0.241138, acc.: 60.16%] [G loss: 0.296406]\n",
      "epoch:9 step:9328 [D loss: 0.232941, acc.: 64.84%] [G loss: 0.302669]\n",
      "epoch:9 step:9329 [D loss: 0.225313, acc.: 63.28%] [G loss: 0.311033]\n",
      "epoch:9 step:9330 [D loss: 0.242392, acc.: 53.91%] [G loss: 0.310578]\n",
      "epoch:9 step:9331 [D loss: 0.232521, acc.: 59.38%] [G loss: 0.321540]\n",
      "epoch:9 step:9332 [D loss: 0.244336, acc.: 57.03%] [G loss: 0.282823]\n",
      "epoch:9 step:9333 [D loss: 0.217943, acc.: 67.19%] [G loss: 0.314805]\n",
      "epoch:9 step:9334 [D loss: 0.237499, acc.: 58.59%] [G loss: 0.294678]\n",
      "epoch:9 step:9335 [D loss: 0.228313, acc.: 63.28%] [G loss: 0.308735]\n",
      "epoch:9 step:9336 [D loss: 0.240676, acc.: 56.25%] [G loss: 0.288946]\n",
      "epoch:9 step:9337 [D loss: 0.234560, acc.: 59.38%] [G loss: 0.320483]\n",
      "epoch:9 step:9338 [D loss: 0.241785, acc.: 58.59%] [G loss: 0.304723]\n",
      "epoch:9 step:9339 [D loss: 0.239394, acc.: 59.38%] [G loss: 0.303081]\n",
      "epoch:9 step:9340 [D loss: 0.256463, acc.: 47.66%] [G loss: 0.272155]\n",
      "epoch:9 step:9341 [D loss: 0.252892, acc.: 50.00%] [G loss: 0.290907]\n",
      "epoch:9 step:9342 [D loss: 0.248636, acc.: 54.69%] [G loss: 0.291565]\n",
      "epoch:9 step:9343 [D loss: 0.232703, acc.: 62.50%] [G loss: 0.295805]\n",
      "epoch:9 step:9344 [D loss: 0.241551, acc.: 55.47%] [G loss: 0.293680]\n",
      "epoch:9 step:9345 [D loss: 0.251502, acc.: 52.34%] [G loss: 0.323427]\n",
      "epoch:9 step:9346 [D loss: 0.246262, acc.: 57.81%] [G loss: 0.264795]\n",
      "epoch:9 step:9347 [D loss: 0.235993, acc.: 64.84%] [G loss: 0.304384]\n",
      "epoch:9 step:9348 [D loss: 0.242991, acc.: 57.03%] [G loss: 0.276744]\n",
      "epoch:9 step:9349 [D loss: 0.249878, acc.: 50.78%] [G loss: 0.293387]\n",
      "epoch:9 step:9350 [D loss: 0.239858, acc.: 58.59%] [G loss: 0.295570]\n",
      "epoch:9 step:9351 [D loss: 0.219239, acc.: 66.41%] [G loss: 0.279641]\n",
      "epoch:9 step:9352 [D loss: 0.240798, acc.: 59.38%] [G loss: 0.301507]\n",
      "epoch:9 step:9353 [D loss: 0.251781, acc.: 53.12%] [G loss: 0.288950]\n",
      "epoch:9 step:9354 [D loss: 0.241822, acc.: 63.28%] [G loss: 0.303717]\n",
      "epoch:9 step:9355 [D loss: 0.221748, acc.: 65.62%] [G loss: 0.316542]\n",
      "epoch:9 step:9356 [D loss: 0.249453, acc.: 51.56%] [G loss: 0.308057]\n",
      "epoch:9 step:9357 [D loss: 0.254291, acc.: 54.69%] [G loss: 0.303604]\n",
      "epoch:9 step:9358 [D loss: 0.249701, acc.: 53.91%] [G loss: 0.304891]\n",
      "epoch:9 step:9359 [D loss: 0.236913, acc.: 60.16%] [G loss: 0.331393]\n",
      "epoch:9 step:9360 [D loss: 0.248828, acc.: 59.38%] [G loss: 0.326389]\n",
      "epoch:9 step:9361 [D loss: 0.256276, acc.: 51.56%] [G loss: 0.288958]\n",
      "epoch:9 step:9362 [D loss: 0.243685, acc.: 53.12%] [G loss: 0.301673]\n",
      "epoch:9 step:9363 [D loss: 0.233318, acc.: 60.94%] [G loss: 0.287066]\n",
      "epoch:9 step:9364 [D loss: 0.250425, acc.: 51.56%] [G loss: 0.314527]\n",
      "epoch:9 step:9365 [D loss: 0.251974, acc.: 52.34%] [G loss: 0.319795]\n",
      "epoch:9 step:9366 [D loss: 0.243914, acc.: 57.81%] [G loss: 0.268768]\n",
      "epoch:9 step:9367 [D loss: 0.228868, acc.: 64.06%] [G loss: 0.316474]\n",
      "epoch:9 step:9368 [D loss: 0.245690, acc.: 53.91%] [G loss: 0.298337]\n",
      "epoch:9 step:9369 [D loss: 0.236986, acc.: 57.81%] [G loss: 0.282361]\n",
      "epoch:9 step:9370 [D loss: 0.249472, acc.: 52.34%] [G loss: 0.319305]\n",
      "epoch:10 step:9371 [D loss: 0.235757, acc.: 60.94%] [G loss: 0.304951]\n",
      "epoch:10 step:9372 [D loss: 0.232538, acc.: 59.38%] [G loss: 0.325197]\n",
      "epoch:10 step:9373 [D loss: 0.239671, acc.: 55.47%] [G loss: 0.303947]\n",
      "epoch:10 step:9374 [D loss: 0.228716, acc.: 67.97%] [G loss: 0.308532]\n",
      "epoch:10 step:9375 [D loss: 0.258741, acc.: 55.47%] [G loss: 0.297987]\n",
      "epoch:10 step:9376 [D loss: 0.250203, acc.: 60.94%] [G loss: 0.291426]\n",
      "epoch:10 step:9377 [D loss: 0.238011, acc.: 61.72%] [G loss: 0.325887]\n",
      "epoch:10 step:9378 [D loss: 0.241790, acc.: 58.59%] [G loss: 0.292403]\n",
      "epoch:10 step:9379 [D loss: 0.233333, acc.: 57.81%] [G loss: 0.312377]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:10 step:9380 [D loss: 0.263741, acc.: 46.09%] [G loss: 0.294871]\n",
      "epoch:10 step:9381 [D loss: 0.233219, acc.: 58.59%] [G loss: 0.310756]\n",
      "epoch:10 step:9382 [D loss: 0.238394, acc.: 57.03%] [G loss: 0.279420]\n",
      "epoch:10 step:9383 [D loss: 0.233552, acc.: 57.03%] [G loss: 0.311562]\n",
      "epoch:10 step:9384 [D loss: 0.224103, acc.: 66.41%] [G loss: 0.315088]\n",
      "epoch:10 step:9385 [D loss: 0.236569, acc.: 57.81%] [G loss: 0.308367]\n",
      "epoch:10 step:9386 [D loss: 0.242067, acc.: 59.38%] [G loss: 0.283041]\n",
      "epoch:10 step:9387 [D loss: 0.253750, acc.: 54.69%] [G loss: 0.276049]\n",
      "epoch:10 step:9388 [D loss: 0.250327, acc.: 48.44%] [G loss: 0.296271]\n",
      "epoch:10 step:9389 [D loss: 0.245782, acc.: 57.03%] [G loss: 0.268081]\n",
      "epoch:10 step:9390 [D loss: 0.239556, acc.: 58.59%] [G loss: 0.280707]\n",
      "epoch:10 step:9391 [D loss: 0.222124, acc.: 66.41%] [G loss: 0.306201]\n",
      "epoch:10 step:9392 [D loss: 0.254879, acc.: 52.34%] [G loss: 0.279433]\n",
      "epoch:10 step:9393 [D loss: 0.252226, acc.: 56.25%] [G loss: 0.292163]\n",
      "epoch:10 step:9394 [D loss: 0.231771, acc.: 59.38%] [G loss: 0.307123]\n",
      "epoch:10 step:9395 [D loss: 0.236722, acc.: 64.06%] [G loss: 0.296349]\n",
      "epoch:10 step:9396 [D loss: 0.249281, acc.: 56.25%] [G loss: 0.289072]\n",
      "epoch:10 step:9397 [D loss: 0.224940, acc.: 68.75%] [G loss: 0.299259]\n",
      "epoch:10 step:9398 [D loss: 0.233916, acc.: 64.06%] [G loss: 0.274858]\n",
      "epoch:10 step:9399 [D loss: 0.255518, acc.: 53.91%] [G loss: 0.300809]\n",
      "epoch:10 step:9400 [D loss: 0.254634, acc.: 53.91%] [G loss: 0.263655]\n",
      "epoch:10 step:9401 [D loss: 0.240139, acc.: 60.16%] [G loss: 0.309738]\n",
      "epoch:10 step:9402 [D loss: 0.236958, acc.: 58.59%] [G loss: 0.303888]\n",
      "epoch:10 step:9403 [D loss: 0.228943, acc.: 61.72%] [G loss: 0.291783]\n",
      "epoch:10 step:9404 [D loss: 0.248230, acc.: 53.91%] [G loss: 0.309233]\n",
      "epoch:10 step:9405 [D loss: 0.237773, acc.: 60.94%] [G loss: 0.310569]\n",
      "epoch:10 step:9406 [D loss: 0.238402, acc.: 57.81%] [G loss: 0.309117]\n",
      "epoch:10 step:9407 [D loss: 0.256740, acc.: 51.56%] [G loss: 0.281964]\n",
      "epoch:10 step:9408 [D loss: 0.239427, acc.: 57.03%] [G loss: 0.294963]\n",
      "epoch:10 step:9409 [D loss: 0.249795, acc.: 56.25%] [G loss: 0.282232]\n",
      "epoch:10 step:9410 [D loss: 0.255755, acc.: 50.78%] [G loss: 0.252979]\n",
      "epoch:10 step:9411 [D loss: 0.228680, acc.: 57.03%] [G loss: 0.318591]\n",
      "epoch:10 step:9412 [D loss: 0.242076, acc.: 62.50%] [G loss: 0.319100]\n",
      "epoch:10 step:9413 [D loss: 0.245622, acc.: 54.69%] [G loss: 0.265575]\n",
      "epoch:10 step:9414 [D loss: 0.252168, acc.: 48.44%] [G loss: 0.289088]\n",
      "epoch:10 step:9415 [D loss: 0.240640, acc.: 58.59%] [G loss: 0.295353]\n",
      "epoch:10 step:9416 [D loss: 0.266285, acc.: 47.66%] [G loss: 0.279716]\n",
      "epoch:10 step:9417 [D loss: 0.213288, acc.: 74.22%] [G loss: 0.280439]\n",
      "epoch:10 step:9418 [D loss: 0.240471, acc.: 53.12%] [G loss: 0.287943]\n",
      "epoch:10 step:9419 [D loss: 0.264312, acc.: 48.44%] [G loss: 0.289258]\n",
      "epoch:10 step:9420 [D loss: 0.231510, acc.: 60.94%] [G loss: 0.295035]\n",
      "epoch:10 step:9421 [D loss: 0.244214, acc.: 57.03%] [G loss: 0.295421]\n",
      "epoch:10 step:9422 [D loss: 0.244603, acc.: 61.72%] [G loss: 0.281146]\n",
      "epoch:10 step:9423 [D loss: 0.251059, acc.: 52.34%] [G loss: 0.291980]\n",
      "epoch:10 step:9424 [D loss: 0.236253, acc.: 52.34%] [G loss: 0.281587]\n",
      "epoch:10 step:9425 [D loss: 0.246410, acc.: 54.69%] [G loss: 0.294182]\n",
      "epoch:10 step:9426 [D loss: 0.271438, acc.: 42.97%] [G loss: 0.305278]\n",
      "epoch:10 step:9427 [D loss: 0.238893, acc.: 59.38%] [G loss: 0.314960]\n",
      "epoch:10 step:9428 [D loss: 0.245396, acc.: 57.81%] [G loss: 0.292549]\n",
      "epoch:10 step:9429 [D loss: 0.236377, acc.: 58.59%] [G loss: 0.306603]\n",
      "epoch:10 step:9430 [D loss: 0.222846, acc.: 67.97%] [G loss: 0.297487]\n",
      "epoch:10 step:9431 [D loss: 0.240273, acc.: 57.03%] [G loss: 0.324355]\n",
      "epoch:10 step:9432 [D loss: 0.259740, acc.: 47.66%] [G loss: 0.297319]\n",
      "epoch:10 step:9433 [D loss: 0.222562, acc.: 65.62%] [G loss: 0.315886]\n",
      "epoch:10 step:9434 [D loss: 0.248885, acc.: 49.22%] [G loss: 0.313463]\n",
      "epoch:10 step:9435 [D loss: 0.238757, acc.: 60.16%] [G loss: 0.298232]\n",
      "epoch:10 step:9436 [D loss: 0.236062, acc.: 58.59%] [G loss: 0.291820]\n",
      "epoch:10 step:9437 [D loss: 0.247770, acc.: 53.91%] [G loss: 0.312861]\n",
      "epoch:10 step:9438 [D loss: 0.241830, acc.: 60.16%] [G loss: 0.313525]\n",
      "epoch:10 step:9439 [D loss: 0.232577, acc.: 60.94%] [G loss: 0.312947]\n",
      "epoch:10 step:9440 [D loss: 0.250045, acc.: 53.12%] [G loss: 0.317644]\n",
      "epoch:10 step:9441 [D loss: 0.235887, acc.: 58.59%] [G loss: 0.296836]\n",
      "epoch:10 step:9442 [D loss: 0.232330, acc.: 63.28%] [G loss: 0.305032]\n",
      "epoch:10 step:9443 [D loss: 0.238500, acc.: 56.25%] [G loss: 0.306943]\n",
      "epoch:10 step:9444 [D loss: 0.236602, acc.: 54.69%] [G loss: 0.296029]\n",
      "epoch:10 step:9445 [D loss: 0.239086, acc.: 56.25%] [G loss: 0.307938]\n",
      "epoch:10 step:9446 [D loss: 0.219694, acc.: 64.84%] [G loss: 0.311621]\n",
      "epoch:10 step:9447 [D loss: 0.249556, acc.: 54.69%] [G loss: 0.299861]\n",
      "epoch:10 step:9448 [D loss: 0.243809, acc.: 57.81%] [G loss: 0.298670]\n",
      "epoch:10 step:9449 [D loss: 0.246326, acc.: 53.91%] [G loss: 0.295275]\n",
      "epoch:10 step:9450 [D loss: 0.240312, acc.: 64.06%] [G loss: 0.324111]\n",
      "epoch:10 step:9451 [D loss: 0.235282, acc.: 60.16%] [G loss: 0.293969]\n",
      "epoch:10 step:9452 [D loss: 0.231592, acc.: 59.38%] [G loss: 0.314320]\n",
      "epoch:10 step:9453 [D loss: 0.246297, acc.: 60.94%] [G loss: 0.296601]\n",
      "epoch:10 step:9454 [D loss: 0.246235, acc.: 56.25%] [G loss: 0.324859]\n",
      "epoch:10 step:9455 [D loss: 0.240179, acc.: 57.03%] [G loss: 0.287221]\n",
      "epoch:10 step:9456 [D loss: 0.244486, acc.: 50.00%] [G loss: 0.310000]\n",
      "epoch:10 step:9457 [D loss: 0.235920, acc.: 57.81%] [G loss: 0.287164]\n",
      "epoch:10 step:9458 [D loss: 0.252065, acc.: 57.03%] [G loss: 0.288295]\n",
      "epoch:10 step:9459 [D loss: 0.242811, acc.: 60.16%] [G loss: 0.298634]\n",
      "epoch:10 step:9460 [D loss: 0.246036, acc.: 55.47%] [G loss: 0.314620]\n",
      "epoch:10 step:9461 [D loss: 0.233252, acc.: 58.59%] [G loss: 0.307262]\n",
      "epoch:10 step:9462 [D loss: 0.250212, acc.: 53.91%] [G loss: 0.291570]\n",
      "epoch:10 step:9463 [D loss: 0.228997, acc.: 65.62%] [G loss: 0.284999]\n",
      "epoch:10 step:9464 [D loss: 0.225137, acc.: 67.97%] [G loss: 0.287822]\n",
      "epoch:10 step:9465 [D loss: 0.242048, acc.: 57.03%] [G loss: 0.260550]\n",
      "epoch:10 step:9466 [D loss: 0.231300, acc.: 60.94%] [G loss: 0.292502]\n",
      "epoch:10 step:9467 [D loss: 0.252288, acc.: 50.00%] [G loss: 0.276603]\n",
      "epoch:10 step:9468 [D loss: 0.233602, acc.: 61.72%] [G loss: 0.308345]\n",
      "epoch:10 step:9469 [D loss: 0.253195, acc.: 50.78%] [G loss: 0.296788]\n",
      "epoch:10 step:9470 [D loss: 0.243511, acc.: 57.03%] [G loss: 0.312143]\n",
      "epoch:10 step:9471 [D loss: 0.235229, acc.: 62.50%] [G loss: 0.287868]\n",
      "epoch:10 step:9472 [D loss: 0.243809, acc.: 57.03%] [G loss: 0.289048]\n",
      "epoch:10 step:9473 [D loss: 0.238204, acc.: 59.38%] [G loss: 0.277685]\n",
      "epoch:10 step:9474 [D loss: 0.251315, acc.: 53.12%] [G loss: 0.311437]\n",
      "epoch:10 step:9475 [D loss: 0.239320, acc.: 57.03%] [G loss: 0.292071]\n",
      "epoch:10 step:9476 [D loss: 0.237597, acc.: 53.91%] [G loss: 0.311234]\n",
      "epoch:10 step:9477 [D loss: 0.245967, acc.: 60.16%] [G loss: 0.274732]\n",
      "epoch:10 step:9478 [D loss: 0.241781, acc.: 57.81%] [G loss: 0.286048]\n",
      "epoch:10 step:9479 [D loss: 0.237200, acc.: 62.50%] [G loss: 0.305686]\n",
      "epoch:10 step:9480 [D loss: 0.240148, acc.: 62.50%] [G loss: 0.295477]\n",
      "epoch:10 step:9481 [D loss: 0.233944, acc.: 60.16%] [G loss: 0.295204]\n",
      "epoch:10 step:9482 [D loss: 0.237987, acc.: 59.38%] [G loss: 0.292916]\n",
      "epoch:10 step:9483 [D loss: 0.251654, acc.: 50.00%] [G loss: 0.318839]\n",
      "epoch:10 step:9484 [D loss: 0.238759, acc.: 56.25%] [G loss: 0.277075]\n",
      "epoch:10 step:9485 [D loss: 0.252323, acc.: 53.91%] [G loss: 0.275360]\n",
      "epoch:10 step:9486 [D loss: 0.235762, acc.: 60.94%] [G loss: 0.309546]\n",
      "epoch:10 step:9487 [D loss: 0.259306, acc.: 53.91%] [G loss: 0.277724]\n",
      "epoch:10 step:9488 [D loss: 0.246500, acc.: 57.81%] [G loss: 0.293422]\n",
      "epoch:10 step:9489 [D loss: 0.228317, acc.: 64.84%] [G loss: 0.306366]\n",
      "epoch:10 step:9490 [D loss: 0.248277, acc.: 58.59%] [G loss: 0.299819]\n",
      "epoch:10 step:9491 [D loss: 0.258836, acc.: 48.44%] [G loss: 0.302640]\n",
      "epoch:10 step:9492 [D loss: 0.240172, acc.: 56.25%] [G loss: 0.298934]\n",
      "epoch:10 step:9493 [D loss: 0.248124, acc.: 53.12%] [G loss: 0.319520]\n",
      "epoch:10 step:9494 [D loss: 0.258137, acc.: 53.12%] [G loss: 0.271790]\n",
      "epoch:10 step:9495 [D loss: 0.248334, acc.: 52.34%] [G loss: 0.292926]\n",
      "epoch:10 step:9496 [D loss: 0.245108, acc.: 53.12%] [G loss: 0.283288]\n",
      "epoch:10 step:9497 [D loss: 0.236951, acc.: 59.38%] [G loss: 0.292482]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:10 step:9498 [D loss: 0.229569, acc.: 63.28%] [G loss: 0.294045]\n",
      "epoch:10 step:9499 [D loss: 0.246992, acc.: 57.81%] [G loss: 0.267442]\n",
      "epoch:10 step:9500 [D loss: 0.226697, acc.: 68.75%] [G loss: 0.300258]\n",
      "epoch:10 step:9501 [D loss: 0.238532, acc.: 58.59%] [G loss: 0.306416]\n",
      "epoch:10 step:9502 [D loss: 0.247019, acc.: 56.25%] [G loss: 0.266622]\n",
      "epoch:10 step:9503 [D loss: 0.236233, acc.: 59.38%] [G loss: 0.309241]\n",
      "epoch:10 step:9504 [D loss: 0.246975, acc.: 56.25%] [G loss: 0.301904]\n",
      "epoch:10 step:9505 [D loss: 0.230342, acc.: 58.59%] [G loss: 0.318950]\n",
      "epoch:10 step:9506 [D loss: 0.232691, acc.: 62.50%] [G loss: 0.302200]\n",
      "epoch:10 step:9507 [D loss: 0.220101, acc.: 66.41%] [G loss: 0.294662]\n",
      "epoch:10 step:9508 [D loss: 0.236424, acc.: 59.38%] [G loss: 0.293101]\n",
      "epoch:10 step:9509 [D loss: 0.247541, acc.: 54.69%] [G loss: 0.277677]\n",
      "epoch:10 step:9510 [D loss: 0.250416, acc.: 59.38%] [G loss: 0.311650]\n",
      "epoch:10 step:9511 [D loss: 0.251014, acc.: 56.25%] [G loss: 0.321684]\n",
      "epoch:10 step:9512 [D loss: 0.246553, acc.: 53.12%] [G loss: 0.281706]\n",
      "epoch:10 step:9513 [D loss: 0.226384, acc.: 57.03%] [G loss: 0.291249]\n",
      "epoch:10 step:9514 [D loss: 0.241023, acc.: 54.69%] [G loss: 0.297421]\n",
      "epoch:10 step:9515 [D loss: 0.245288, acc.: 53.91%] [G loss: 0.304321]\n",
      "epoch:10 step:9516 [D loss: 0.230775, acc.: 60.94%] [G loss: 0.302945]\n",
      "epoch:10 step:9517 [D loss: 0.221036, acc.: 64.84%] [G loss: 0.292672]\n",
      "epoch:10 step:9518 [D loss: 0.240256, acc.: 57.81%] [G loss: 0.269407]\n",
      "epoch:10 step:9519 [D loss: 0.239929, acc.: 57.03%] [G loss: 0.319621]\n",
      "epoch:10 step:9520 [D loss: 0.238953, acc.: 52.34%] [G loss: 0.330031]\n",
      "epoch:10 step:9521 [D loss: 0.239842, acc.: 58.59%] [G loss: 0.293885]\n",
      "epoch:10 step:9522 [D loss: 0.246145, acc.: 56.25%] [G loss: 0.294069]\n",
      "epoch:10 step:9523 [D loss: 0.224077, acc.: 65.62%] [G loss: 0.307580]\n",
      "epoch:10 step:9524 [D loss: 0.246383, acc.: 57.03%] [G loss: 0.280921]\n",
      "epoch:10 step:9525 [D loss: 0.253806, acc.: 51.56%] [G loss: 0.291441]\n",
      "epoch:10 step:9526 [D loss: 0.243836, acc.: 55.47%] [G loss: 0.300985]\n",
      "epoch:10 step:9527 [D loss: 0.235486, acc.: 59.38%] [G loss: 0.286917]\n",
      "epoch:10 step:9528 [D loss: 0.236487, acc.: 63.28%] [G loss: 0.308983]\n",
      "epoch:10 step:9529 [D loss: 0.241351, acc.: 54.69%] [G loss: 0.293382]\n",
      "epoch:10 step:9530 [D loss: 0.244893, acc.: 54.69%] [G loss: 0.309051]\n",
      "epoch:10 step:9531 [D loss: 0.232865, acc.: 61.72%] [G loss: 0.309907]\n",
      "epoch:10 step:9532 [D loss: 0.261995, acc.: 55.47%] [G loss: 0.284313]\n",
      "epoch:10 step:9533 [D loss: 0.246076, acc.: 55.47%] [G loss: 0.303079]\n",
      "epoch:10 step:9534 [D loss: 0.238308, acc.: 56.25%] [G loss: 0.320658]\n",
      "epoch:10 step:9535 [D loss: 0.262435, acc.: 50.78%] [G loss: 0.286470]\n",
      "epoch:10 step:9536 [D loss: 0.237081, acc.: 62.50%] [G loss: 0.297695]\n",
      "epoch:10 step:9537 [D loss: 0.238922, acc.: 54.69%] [G loss: 0.331442]\n",
      "epoch:10 step:9538 [D loss: 0.229910, acc.: 62.50%] [G loss: 0.299579]\n",
      "epoch:10 step:9539 [D loss: 0.230175, acc.: 62.50%] [G loss: 0.306239]\n",
      "epoch:10 step:9540 [D loss: 0.252552, acc.: 47.66%] [G loss: 0.304731]\n",
      "epoch:10 step:9541 [D loss: 0.253417, acc.: 46.88%] [G loss: 0.298835]\n",
      "epoch:10 step:9542 [D loss: 0.245423, acc.: 55.47%] [G loss: 0.297243]\n",
      "epoch:10 step:9543 [D loss: 0.228761, acc.: 66.41%] [G loss: 0.279513]\n",
      "epoch:10 step:9544 [D loss: 0.233918, acc.: 62.50%] [G loss: 0.288611]\n",
      "epoch:10 step:9545 [D loss: 0.253746, acc.: 54.69%] [G loss: 0.284564]\n",
      "epoch:10 step:9546 [D loss: 0.234969, acc.: 58.59%] [G loss: 0.278417]\n",
      "epoch:10 step:9547 [D loss: 0.243498, acc.: 59.38%] [G loss: 0.276999]\n",
      "epoch:10 step:9548 [D loss: 0.243750, acc.: 61.72%] [G loss: 0.315813]\n",
      "epoch:10 step:9549 [D loss: 0.234326, acc.: 60.16%] [G loss: 0.303501]\n",
      "epoch:10 step:9550 [D loss: 0.253464, acc.: 54.69%] [G loss: 0.272531]\n",
      "epoch:10 step:9551 [D loss: 0.253540, acc.: 49.22%] [G loss: 0.310281]\n",
      "epoch:10 step:9552 [D loss: 0.229603, acc.: 64.84%] [G loss: 0.274112]\n",
      "epoch:10 step:9553 [D loss: 0.246439, acc.: 50.00%] [G loss: 0.298535]\n",
      "epoch:10 step:9554 [D loss: 0.230958, acc.: 64.06%] [G loss: 0.306807]\n",
      "epoch:10 step:9555 [D loss: 0.256353, acc.: 56.25%] [G loss: 0.289463]\n",
      "epoch:10 step:9556 [D loss: 0.242555, acc.: 58.59%] [G loss: 0.292265]\n",
      "epoch:10 step:9557 [D loss: 0.212418, acc.: 68.75%] [G loss: 0.316663]\n",
      "epoch:10 step:9558 [D loss: 0.234730, acc.: 60.16%] [G loss: 0.308656]\n",
      "epoch:10 step:9559 [D loss: 0.247666, acc.: 55.47%] [G loss: 0.297705]\n",
      "epoch:10 step:9560 [D loss: 0.236876, acc.: 56.25%] [G loss: 0.295744]\n",
      "epoch:10 step:9561 [D loss: 0.238586, acc.: 61.72%] [G loss: 0.294355]\n",
      "epoch:10 step:9562 [D loss: 0.238090, acc.: 58.59%] [G loss: 0.301078]\n",
      "epoch:10 step:9563 [D loss: 0.240243, acc.: 53.91%] [G loss: 0.302659]\n",
      "epoch:10 step:9564 [D loss: 0.243006, acc.: 58.59%] [G loss: 0.285385]\n",
      "epoch:10 step:9565 [D loss: 0.218781, acc.: 67.97%] [G loss: 0.309190]\n",
      "epoch:10 step:9566 [D loss: 0.229888, acc.: 61.72%] [G loss: 0.313402]\n",
      "epoch:10 step:9567 [D loss: 0.242250, acc.: 56.25%] [G loss: 0.299543]\n",
      "epoch:10 step:9568 [D loss: 0.252688, acc.: 50.78%] [G loss: 0.307938]\n",
      "epoch:10 step:9569 [D loss: 0.232898, acc.: 65.62%] [G loss: 0.304823]\n",
      "epoch:10 step:9570 [D loss: 0.233722, acc.: 60.94%] [G loss: 0.311899]\n",
      "epoch:10 step:9571 [D loss: 0.236969, acc.: 58.59%] [G loss: 0.288666]\n",
      "epoch:10 step:9572 [D loss: 0.230631, acc.: 64.84%] [G loss: 0.281754]\n",
      "epoch:10 step:9573 [D loss: 0.238547, acc.: 54.69%] [G loss: 0.296013]\n",
      "epoch:10 step:9574 [D loss: 0.229094, acc.: 55.47%] [G loss: 0.301168]\n",
      "epoch:10 step:9575 [D loss: 0.248416, acc.: 58.59%] [G loss: 0.302443]\n",
      "epoch:10 step:9576 [D loss: 0.237486, acc.: 61.72%] [G loss: 0.323685]\n",
      "epoch:10 step:9577 [D loss: 0.249032, acc.: 57.81%] [G loss: 0.296811]\n",
      "epoch:10 step:9578 [D loss: 0.220191, acc.: 62.50%] [G loss: 0.294558]\n",
      "epoch:10 step:9579 [D loss: 0.256856, acc.: 52.34%] [G loss: 0.296728]\n",
      "epoch:10 step:9580 [D loss: 0.247290, acc.: 54.69%] [G loss: 0.295861]\n",
      "epoch:10 step:9581 [D loss: 0.239727, acc.: 58.59%] [G loss: 0.299459]\n",
      "epoch:10 step:9582 [D loss: 0.251456, acc.: 52.34%] [G loss: 0.283742]\n",
      "epoch:10 step:9583 [D loss: 0.253581, acc.: 46.09%] [G loss: 0.302222]\n",
      "epoch:10 step:9584 [D loss: 0.253201, acc.: 52.34%] [G loss: 0.293120]\n",
      "epoch:10 step:9585 [D loss: 0.271484, acc.: 45.31%] [G loss: 0.287186]\n",
      "epoch:10 step:9586 [D loss: 0.235606, acc.: 57.81%] [G loss: 0.297921]\n",
      "epoch:10 step:9587 [D loss: 0.226033, acc.: 61.72%] [G loss: 0.283643]\n",
      "epoch:10 step:9588 [D loss: 0.252722, acc.: 54.69%] [G loss: 0.293854]\n",
      "epoch:10 step:9589 [D loss: 0.243350, acc.: 52.34%] [G loss: 0.300458]\n",
      "epoch:10 step:9590 [D loss: 0.230734, acc.: 64.06%] [G loss: 0.306307]\n",
      "epoch:10 step:9591 [D loss: 0.251149, acc.: 54.69%] [G loss: 0.293785]\n",
      "epoch:10 step:9592 [D loss: 0.240709, acc.: 59.38%] [G loss: 0.310353]\n",
      "epoch:10 step:9593 [D loss: 0.239621, acc.: 60.94%] [G loss: 0.308232]\n",
      "epoch:10 step:9594 [D loss: 0.246560, acc.: 55.47%] [G loss: 0.285078]\n",
      "epoch:10 step:9595 [D loss: 0.235555, acc.: 59.38%] [G loss: 0.303863]\n",
      "epoch:10 step:9596 [D loss: 0.250143, acc.: 48.44%] [G loss: 0.315281]\n",
      "epoch:10 step:9597 [D loss: 0.245670, acc.: 57.03%] [G loss: 0.309492]\n",
      "epoch:10 step:9598 [D loss: 0.242249, acc.: 57.03%] [G loss: 0.297269]\n",
      "epoch:10 step:9599 [D loss: 0.230512, acc.: 60.16%] [G loss: 0.314436]\n",
      "epoch:10 step:9600 [D loss: 0.251186, acc.: 52.34%] [G loss: 0.309969]\n",
      "epoch:10 step:9601 [D loss: 0.246851, acc.: 52.34%] [G loss: 0.317878]\n",
      "epoch:10 step:9602 [D loss: 0.239916, acc.: 58.59%] [G loss: 0.293471]\n",
      "epoch:10 step:9603 [D loss: 0.240874, acc.: 53.12%] [G loss: 0.299918]\n",
      "epoch:10 step:9604 [D loss: 0.244955, acc.: 53.91%] [G loss: 0.279664]\n",
      "epoch:10 step:9605 [D loss: 0.249984, acc.: 55.47%] [G loss: 0.330826]\n",
      "epoch:10 step:9606 [D loss: 0.229300, acc.: 61.72%] [G loss: 0.309664]\n",
      "epoch:10 step:9607 [D loss: 0.253351, acc.: 51.56%] [G loss: 0.288494]\n",
      "epoch:10 step:9608 [D loss: 0.250690, acc.: 52.34%] [G loss: 0.292050]\n",
      "epoch:10 step:9609 [D loss: 0.220031, acc.: 68.75%] [G loss: 0.326397]\n",
      "epoch:10 step:9610 [D loss: 0.242441, acc.: 57.03%] [G loss: 0.321707]\n",
      "epoch:10 step:9611 [D loss: 0.215154, acc.: 71.88%] [G loss: 0.336219]\n",
      "epoch:10 step:9612 [D loss: 0.236950, acc.: 59.38%] [G loss: 0.292601]\n",
      "epoch:10 step:9613 [D loss: 0.247332, acc.: 53.91%] [G loss: 0.285425]\n",
      "epoch:10 step:9614 [D loss: 0.240439, acc.: 60.16%] [G loss: 0.293481]\n",
      "epoch:10 step:9615 [D loss: 0.232264, acc.: 60.94%] [G loss: 0.300463]\n",
      "epoch:10 step:9616 [D loss: 0.246957, acc.: 56.25%] [G loss: 0.292503]\n",
      "epoch:10 step:9617 [D loss: 0.243523, acc.: 57.81%] [G loss: 0.305190]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:10 step:9618 [D loss: 0.229035, acc.: 57.81%] [G loss: 0.316174]\n",
      "epoch:10 step:9619 [D loss: 0.246034, acc.: 53.91%] [G loss: 0.276596]\n",
      "epoch:10 step:9620 [D loss: 0.261254, acc.: 49.22%] [G loss: 0.279080]\n",
      "epoch:10 step:9621 [D loss: 0.225420, acc.: 62.50%] [G loss: 0.325769]\n",
      "epoch:10 step:9622 [D loss: 0.234840, acc.: 57.81%] [G loss: 0.300607]\n",
      "epoch:10 step:9623 [D loss: 0.230514, acc.: 67.19%] [G loss: 0.326147]\n",
      "epoch:10 step:9624 [D loss: 0.245391, acc.: 57.03%] [G loss: 0.295013]\n",
      "epoch:10 step:9625 [D loss: 0.254484, acc.: 53.12%] [G loss: 0.302245]\n",
      "epoch:10 step:9626 [D loss: 0.240846, acc.: 57.81%] [G loss: 0.304748]\n",
      "epoch:10 step:9627 [D loss: 0.233275, acc.: 62.50%] [G loss: 0.294077]\n",
      "epoch:10 step:9628 [D loss: 0.266501, acc.: 50.00%] [G loss: 0.284684]\n",
      "epoch:10 step:9629 [D loss: 0.237103, acc.: 60.16%] [G loss: 0.306521]\n",
      "epoch:10 step:9630 [D loss: 0.252208, acc.: 53.91%] [G loss: 0.313157]\n",
      "epoch:10 step:9631 [D loss: 0.249506, acc.: 50.78%] [G loss: 0.293817]\n",
      "epoch:10 step:9632 [D loss: 0.248150, acc.: 56.25%] [G loss: 0.297443]\n",
      "epoch:10 step:9633 [D loss: 0.250626, acc.: 55.47%] [G loss: 0.282134]\n",
      "epoch:10 step:9634 [D loss: 0.242540, acc.: 54.69%] [G loss: 0.288311]\n",
      "epoch:10 step:9635 [D loss: 0.235879, acc.: 60.94%] [G loss: 0.280925]\n",
      "epoch:10 step:9636 [D loss: 0.237772, acc.: 54.69%] [G loss: 0.324434]\n",
      "epoch:10 step:9637 [D loss: 0.236839, acc.: 58.59%] [G loss: 0.284396]\n",
      "epoch:10 step:9638 [D loss: 0.239906, acc.: 57.81%] [G loss: 0.276187]\n",
      "epoch:10 step:9639 [D loss: 0.240487, acc.: 58.59%] [G loss: 0.310773]\n",
      "epoch:10 step:9640 [D loss: 0.238142, acc.: 57.03%] [G loss: 0.303162]\n",
      "epoch:10 step:9641 [D loss: 0.247494, acc.: 57.81%] [G loss: 0.315047]\n",
      "epoch:10 step:9642 [D loss: 0.247533, acc.: 57.81%] [G loss: 0.297809]\n",
      "epoch:10 step:9643 [D loss: 0.255213, acc.: 54.69%] [G loss: 0.296118]\n",
      "epoch:10 step:9644 [D loss: 0.235213, acc.: 55.47%] [G loss: 0.314253]\n",
      "epoch:10 step:9645 [D loss: 0.237623, acc.: 61.72%] [G loss: 0.323029]\n",
      "epoch:10 step:9646 [D loss: 0.232061, acc.: 60.16%] [G loss: 0.312737]\n",
      "epoch:10 step:9647 [D loss: 0.238439, acc.: 54.69%] [G loss: 0.295032]\n",
      "epoch:10 step:9648 [D loss: 0.249782, acc.: 57.81%] [G loss: 0.313675]\n",
      "epoch:10 step:9649 [D loss: 0.246714, acc.: 55.47%] [G loss: 0.276145]\n",
      "epoch:10 step:9650 [D loss: 0.251906, acc.: 54.69%] [G loss: 0.271524]\n",
      "epoch:10 step:9651 [D loss: 0.218629, acc.: 65.62%] [G loss: 0.310519]\n",
      "epoch:10 step:9652 [D loss: 0.251817, acc.: 53.12%] [G loss: 0.295243]\n",
      "epoch:10 step:9653 [D loss: 0.216427, acc.: 68.75%] [G loss: 0.310685]\n",
      "epoch:10 step:9654 [D loss: 0.235270, acc.: 67.19%] [G loss: 0.289732]\n",
      "epoch:10 step:9655 [D loss: 0.253830, acc.: 48.44%] [G loss: 0.309507]\n",
      "epoch:10 step:9656 [D loss: 0.239745, acc.: 60.94%] [G loss: 0.296869]\n",
      "epoch:10 step:9657 [D loss: 0.242544, acc.: 60.94%] [G loss: 0.280899]\n",
      "epoch:10 step:9658 [D loss: 0.254593, acc.: 53.91%] [G loss: 0.275914]\n",
      "epoch:10 step:9659 [D loss: 0.244554, acc.: 52.34%] [G loss: 0.302779]\n",
      "epoch:10 step:9660 [D loss: 0.233417, acc.: 60.16%] [G loss: 0.292088]\n",
      "epoch:10 step:9661 [D loss: 0.245089, acc.: 57.03%] [G loss: 0.315100]\n",
      "epoch:10 step:9662 [D loss: 0.250599, acc.: 55.47%] [G loss: 0.289249]\n",
      "epoch:10 step:9663 [D loss: 0.242542, acc.: 60.94%] [G loss: 0.287639]\n",
      "epoch:10 step:9664 [D loss: 0.246589, acc.: 47.66%] [G loss: 0.299619]\n",
      "epoch:10 step:9665 [D loss: 0.244623, acc.: 57.81%] [G loss: 0.284462]\n",
      "epoch:10 step:9666 [D loss: 0.237799, acc.: 64.06%] [G loss: 0.294485]\n",
      "epoch:10 step:9667 [D loss: 0.247725, acc.: 53.12%] [G loss: 0.282922]\n",
      "epoch:10 step:9668 [D loss: 0.248058, acc.: 58.59%] [G loss: 0.306831]\n",
      "epoch:10 step:9669 [D loss: 0.253406, acc.: 51.56%] [G loss: 0.272528]\n",
      "epoch:10 step:9670 [D loss: 0.256786, acc.: 46.09%] [G loss: 0.266421]\n",
      "epoch:10 step:9671 [D loss: 0.226674, acc.: 64.84%] [G loss: 0.305985]\n",
      "epoch:10 step:9672 [D loss: 0.238902, acc.: 60.94%] [G loss: 0.295328]\n",
      "epoch:10 step:9673 [D loss: 0.253770, acc.: 49.22%] [G loss: 0.275022]\n",
      "epoch:10 step:9674 [D loss: 0.233129, acc.: 61.72%] [G loss: 0.305621]\n",
      "epoch:10 step:9675 [D loss: 0.241773, acc.: 60.94%] [G loss: 0.302056]\n",
      "epoch:10 step:9676 [D loss: 0.240213, acc.: 56.25%] [G loss: 0.311136]\n",
      "epoch:10 step:9677 [D loss: 0.244356, acc.: 59.38%] [G loss: 0.271958]\n",
      "epoch:10 step:9678 [D loss: 0.232463, acc.: 60.94%] [G loss: 0.317815]\n",
      "epoch:10 step:9679 [D loss: 0.219095, acc.: 65.62%] [G loss: 0.282467]\n",
      "epoch:10 step:9680 [D loss: 0.260416, acc.: 48.44%] [G loss: 0.280327]\n",
      "epoch:10 step:9681 [D loss: 0.251397, acc.: 53.91%] [G loss: 0.325491]\n",
      "epoch:10 step:9682 [D loss: 0.242085, acc.: 53.12%] [G loss: 0.286627]\n",
      "epoch:10 step:9683 [D loss: 0.252209, acc.: 52.34%] [G loss: 0.293803]\n",
      "epoch:10 step:9684 [D loss: 0.238667, acc.: 60.16%] [G loss: 0.292818]\n",
      "epoch:10 step:9685 [D loss: 0.249495, acc.: 54.69%] [G loss: 0.300556]\n",
      "epoch:10 step:9686 [D loss: 0.246988, acc.: 53.91%] [G loss: 0.289756]\n",
      "epoch:10 step:9687 [D loss: 0.227255, acc.: 61.72%] [G loss: 0.310016]\n",
      "epoch:10 step:9688 [D loss: 0.264291, acc.: 51.56%] [G loss: 0.311767]\n",
      "epoch:10 step:9689 [D loss: 0.254877, acc.: 51.56%] [G loss: 0.269051]\n",
      "epoch:10 step:9690 [D loss: 0.246112, acc.: 57.03%] [G loss: 0.299492]\n",
      "epoch:10 step:9691 [D loss: 0.243812, acc.: 59.38%] [G loss: 0.314381]\n",
      "epoch:10 step:9692 [D loss: 0.248077, acc.: 57.03%] [G loss: 0.293333]\n",
      "epoch:10 step:9693 [D loss: 0.246452, acc.: 58.59%] [G loss: 0.315080]\n",
      "epoch:10 step:9694 [D loss: 0.235639, acc.: 57.81%] [G loss: 0.289528]\n",
      "epoch:10 step:9695 [D loss: 0.224249, acc.: 62.50%] [G loss: 0.298082]\n",
      "epoch:10 step:9696 [D loss: 0.238617, acc.: 60.16%] [G loss: 0.322136]\n",
      "epoch:10 step:9697 [D loss: 0.235118, acc.: 60.94%] [G loss: 0.307561]\n",
      "epoch:10 step:9698 [D loss: 0.235323, acc.: 56.25%] [G loss: 0.320036]\n",
      "epoch:10 step:9699 [D loss: 0.232841, acc.: 65.62%] [G loss: 0.280451]\n",
      "epoch:10 step:9700 [D loss: 0.227262, acc.: 65.62%] [G loss: 0.298558]\n",
      "epoch:10 step:9701 [D loss: 0.242632, acc.: 55.47%] [G loss: 0.320293]\n",
      "epoch:10 step:9702 [D loss: 0.225938, acc.: 63.28%] [G loss: 0.320612]\n",
      "epoch:10 step:9703 [D loss: 0.253820, acc.: 54.69%] [G loss: 0.299265]\n",
      "epoch:10 step:9704 [D loss: 0.223286, acc.: 67.19%] [G loss: 0.311023]\n",
      "epoch:10 step:9705 [D loss: 0.241806, acc.: 55.47%] [G loss: 0.303838]\n",
      "epoch:10 step:9706 [D loss: 0.230988, acc.: 62.50%] [G loss: 0.284510]\n",
      "epoch:10 step:9707 [D loss: 0.226879, acc.: 61.72%] [G loss: 0.299753]\n",
      "epoch:10 step:9708 [D loss: 0.236285, acc.: 58.59%] [G loss: 0.299010]\n",
      "epoch:10 step:9709 [D loss: 0.257402, acc.: 53.91%] [G loss: 0.295401]\n",
      "epoch:10 step:9710 [D loss: 0.231563, acc.: 60.94%] [G loss: 0.309004]\n",
      "epoch:10 step:9711 [D loss: 0.238580, acc.: 56.25%] [G loss: 0.283074]\n",
      "epoch:10 step:9712 [D loss: 0.231625, acc.: 59.38%] [G loss: 0.301819]\n",
      "epoch:10 step:9713 [D loss: 0.233614, acc.: 58.59%] [G loss: 0.312568]\n",
      "epoch:10 step:9714 [D loss: 0.258121, acc.: 49.22%] [G loss: 0.294441]\n",
      "epoch:10 step:9715 [D loss: 0.241509, acc.: 56.25%] [G loss: 0.285561]\n",
      "epoch:10 step:9716 [D loss: 0.255349, acc.: 48.44%] [G loss: 0.282120]\n",
      "epoch:10 step:9717 [D loss: 0.244825, acc.: 57.81%] [G loss: 0.276738]\n",
      "epoch:10 step:9718 [D loss: 0.244320, acc.: 57.03%] [G loss: 0.298846]\n",
      "epoch:10 step:9719 [D loss: 0.218738, acc.: 64.84%] [G loss: 0.292496]\n",
      "epoch:10 step:9720 [D loss: 0.247743, acc.: 59.38%] [G loss: 0.288368]\n",
      "epoch:10 step:9721 [D loss: 0.242822, acc.: 57.81%] [G loss: 0.304318]\n",
      "epoch:10 step:9722 [D loss: 0.255364, acc.: 53.12%] [G loss: 0.297856]\n",
      "epoch:10 step:9723 [D loss: 0.231956, acc.: 62.50%] [G loss: 0.310592]\n",
      "epoch:10 step:9724 [D loss: 0.247484, acc.: 57.03%] [G loss: 0.283545]\n",
      "epoch:10 step:9725 [D loss: 0.219260, acc.: 71.09%] [G loss: 0.307666]\n",
      "epoch:10 step:9726 [D loss: 0.245510, acc.: 50.00%] [G loss: 0.293945]\n",
      "epoch:10 step:9727 [D loss: 0.244890, acc.: 60.94%] [G loss: 0.296648]\n",
      "epoch:10 step:9728 [D loss: 0.252598, acc.: 52.34%] [G loss: 0.271073]\n",
      "epoch:10 step:9729 [D loss: 0.255217, acc.: 54.69%] [G loss: 0.276737]\n",
      "epoch:10 step:9730 [D loss: 0.233894, acc.: 57.81%] [G loss: 0.303823]\n",
      "epoch:10 step:9731 [D loss: 0.239956, acc.: 60.16%] [G loss: 0.307603]\n",
      "epoch:10 step:9732 [D loss: 0.237825, acc.: 59.38%] [G loss: 0.319085]\n",
      "epoch:10 step:9733 [D loss: 0.250827, acc.: 52.34%] [G loss: 0.268166]\n",
      "epoch:10 step:9734 [D loss: 0.214724, acc.: 66.41%] [G loss: 0.303016]\n",
      "epoch:10 step:9735 [D loss: 0.240672, acc.: 58.59%] [G loss: 0.309590]\n",
      "epoch:10 step:9736 [D loss: 0.242857, acc.: 58.59%] [G loss: 0.293360]\n",
      "epoch:10 step:9737 [D loss: 0.238464, acc.: 60.16%] [G loss: 0.288091]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:10 step:9738 [D loss: 0.238496, acc.: 52.34%] [G loss: 0.282568]\n",
      "epoch:10 step:9739 [D loss: 0.250135, acc.: 53.91%] [G loss: 0.288816]\n",
      "epoch:10 step:9740 [D loss: 0.240204, acc.: 56.25%] [G loss: 0.286511]\n",
      "epoch:10 step:9741 [D loss: 0.232018, acc.: 61.72%] [G loss: 0.295206]\n",
      "epoch:10 step:9742 [D loss: 0.238335, acc.: 59.38%] [G loss: 0.296499]\n",
      "epoch:10 step:9743 [D loss: 0.239221, acc.: 60.94%] [G loss: 0.322286]\n",
      "epoch:10 step:9744 [D loss: 0.235862, acc.: 59.38%] [G loss: 0.327806]\n",
      "epoch:10 step:9745 [D loss: 0.254193, acc.: 47.66%] [G loss: 0.277868]\n",
      "epoch:10 step:9746 [D loss: 0.256209, acc.: 53.12%] [G loss: 0.265197]\n",
      "epoch:10 step:9747 [D loss: 0.241870, acc.: 55.47%] [G loss: 0.281466]\n",
      "epoch:10 step:9748 [D loss: 0.239137, acc.: 58.59%] [G loss: 0.284105]\n",
      "epoch:10 step:9749 [D loss: 0.245633, acc.: 51.56%] [G loss: 0.297455]\n",
      "epoch:10 step:9750 [D loss: 0.230539, acc.: 61.72%] [G loss: 0.310600]\n",
      "epoch:10 step:9751 [D loss: 0.242975, acc.: 57.81%] [G loss: 0.299985]\n",
      "epoch:10 step:9752 [D loss: 0.231681, acc.: 56.25%] [G loss: 0.298231]\n",
      "epoch:10 step:9753 [D loss: 0.233631, acc.: 61.72%] [G loss: 0.309295]\n",
      "epoch:10 step:9754 [D loss: 0.225086, acc.: 64.84%] [G loss: 0.297424]\n",
      "epoch:10 step:9755 [D loss: 0.237673, acc.: 54.69%] [G loss: 0.303426]\n",
      "epoch:10 step:9756 [D loss: 0.248763, acc.: 56.25%] [G loss: 0.287839]\n",
      "epoch:10 step:9757 [D loss: 0.261503, acc.: 51.56%] [G loss: 0.296682]\n",
      "epoch:10 step:9758 [D loss: 0.253268, acc.: 55.47%] [G loss: 0.291803]\n",
      "epoch:10 step:9759 [D loss: 0.237891, acc.: 54.69%] [G loss: 0.302663]\n",
      "epoch:10 step:9760 [D loss: 0.239056, acc.: 55.47%] [G loss: 0.301347]\n",
      "epoch:10 step:9761 [D loss: 0.226206, acc.: 63.28%] [G loss: 0.307420]\n",
      "epoch:10 step:9762 [D loss: 0.237527, acc.: 61.72%] [G loss: 0.290973]\n",
      "epoch:10 step:9763 [D loss: 0.237448, acc.: 56.25%] [G loss: 0.293656]\n",
      "epoch:10 step:9764 [D loss: 0.250900, acc.: 54.69%] [G loss: 0.341786]\n",
      "epoch:10 step:9765 [D loss: 0.227000, acc.: 60.94%] [G loss: 0.306923]\n",
      "epoch:10 step:9766 [D loss: 0.229290, acc.: 62.50%] [G loss: 0.281631]\n",
      "epoch:10 step:9767 [D loss: 0.236458, acc.: 60.16%] [G loss: 0.330066]\n",
      "epoch:10 step:9768 [D loss: 0.229897, acc.: 58.59%] [G loss: 0.308172]\n",
      "epoch:10 step:9769 [D loss: 0.226096, acc.: 60.16%] [G loss: 0.301131]\n",
      "epoch:10 step:9770 [D loss: 0.256099, acc.: 55.47%] [G loss: 0.312689]\n",
      "epoch:10 step:9771 [D loss: 0.239955, acc.: 60.94%] [G loss: 0.306013]\n",
      "epoch:10 step:9772 [D loss: 0.230242, acc.: 64.84%] [G loss: 0.303298]\n",
      "epoch:10 step:9773 [D loss: 0.242096, acc.: 61.72%] [G loss: 0.286013]\n",
      "epoch:10 step:9774 [D loss: 0.257359, acc.: 55.47%] [G loss: 0.316738]\n",
      "epoch:10 step:9775 [D loss: 0.229066, acc.: 57.81%] [G loss: 0.304252]\n",
      "epoch:10 step:9776 [D loss: 0.230332, acc.: 60.94%] [G loss: 0.314897]\n",
      "epoch:10 step:9777 [D loss: 0.236629, acc.: 60.94%] [G loss: 0.329725]\n",
      "epoch:10 step:9778 [D loss: 0.242919, acc.: 53.91%] [G loss: 0.285077]\n",
      "epoch:10 step:9779 [D loss: 0.224993, acc.: 59.38%] [G loss: 0.310754]\n",
      "epoch:10 step:9780 [D loss: 0.251736, acc.: 53.12%] [G loss: 0.290194]\n",
      "epoch:10 step:9781 [D loss: 0.252849, acc.: 49.22%] [G loss: 0.325647]\n",
      "epoch:10 step:9782 [D loss: 0.228854, acc.: 60.16%] [G loss: 0.298178]\n",
      "epoch:10 step:9783 [D loss: 0.256062, acc.: 53.91%] [G loss: 0.280099]\n",
      "epoch:10 step:9784 [D loss: 0.234459, acc.: 60.16%] [G loss: 0.291403]\n",
      "epoch:10 step:9785 [D loss: 0.236486, acc.: 60.16%] [G loss: 0.302581]\n",
      "epoch:10 step:9786 [D loss: 0.249641, acc.: 57.03%] [G loss: 0.278364]\n",
      "epoch:10 step:9787 [D loss: 0.229703, acc.: 63.28%] [G loss: 0.285853]\n",
      "epoch:10 step:9788 [D loss: 0.258225, acc.: 50.00%] [G loss: 0.296305]\n",
      "epoch:10 step:9789 [D loss: 0.229626, acc.: 64.84%] [G loss: 0.323351]\n",
      "epoch:10 step:9790 [D loss: 0.246633, acc.: 51.56%] [G loss: 0.271746]\n",
      "epoch:10 step:9791 [D loss: 0.251565, acc.: 52.34%] [G loss: 0.276045]\n",
      "epoch:10 step:9792 [D loss: 0.234917, acc.: 59.38%] [G loss: 0.292183]\n",
      "epoch:10 step:9793 [D loss: 0.238586, acc.: 62.50%] [G loss: 0.281695]\n",
      "epoch:10 step:9794 [D loss: 0.235701, acc.: 57.81%] [G loss: 0.301833]\n",
      "epoch:10 step:9795 [D loss: 0.252146, acc.: 50.78%] [G loss: 0.289237]\n",
      "epoch:10 step:9796 [D loss: 0.278507, acc.: 44.53%] [G loss: 0.285606]\n",
      "epoch:10 step:9797 [D loss: 0.227237, acc.: 64.84%] [G loss: 0.303628]\n",
      "epoch:10 step:9798 [D loss: 0.247723, acc.: 52.34%] [G loss: 0.282862]\n",
      "epoch:10 step:9799 [D loss: 0.256206, acc.: 52.34%] [G loss: 0.283285]\n",
      "epoch:10 step:9800 [D loss: 0.234238, acc.: 61.72%] [G loss: 0.280949]\n",
      "epoch:10 step:9801 [D loss: 0.230148, acc.: 62.50%] [G loss: 0.311909]\n",
      "epoch:10 step:9802 [D loss: 0.240052, acc.: 57.81%] [G loss: 0.259785]\n",
      "epoch:10 step:9803 [D loss: 0.242118, acc.: 57.81%] [G loss: 0.316329]\n",
      "epoch:10 step:9804 [D loss: 0.252094, acc.: 54.69%] [G loss: 0.304308]\n",
      "epoch:10 step:9805 [D loss: 0.233280, acc.: 60.16%] [G loss: 0.286146]\n",
      "epoch:10 step:9806 [D loss: 0.242809, acc.: 57.03%] [G loss: 0.285549]\n",
      "epoch:10 step:9807 [D loss: 0.245121, acc.: 53.12%] [G loss: 0.316871]\n",
      "epoch:10 step:9808 [D loss: 0.263148, acc.: 50.78%] [G loss: 0.287163]\n",
      "epoch:10 step:9809 [D loss: 0.234094, acc.: 64.06%] [G loss: 0.320068]\n",
      "epoch:10 step:9810 [D loss: 0.222247, acc.: 65.62%] [G loss: 0.297186]\n",
      "epoch:10 step:9811 [D loss: 0.225783, acc.: 63.28%] [G loss: 0.323131]\n",
      "epoch:10 step:9812 [D loss: 0.241452, acc.: 58.59%] [G loss: 0.308357]\n",
      "epoch:10 step:9813 [D loss: 0.248093, acc.: 53.12%] [G loss: 0.300623]\n",
      "epoch:10 step:9814 [D loss: 0.239890, acc.: 58.59%] [G loss: 0.287047]\n",
      "epoch:10 step:9815 [D loss: 0.234694, acc.: 59.38%] [G loss: 0.299322]\n",
      "epoch:10 step:9816 [D loss: 0.239262, acc.: 60.94%] [G loss: 0.306547]\n",
      "epoch:10 step:9817 [D loss: 0.239497, acc.: 56.25%] [G loss: 0.321281]\n",
      "epoch:10 step:9818 [D loss: 0.247659, acc.: 57.03%] [G loss: 0.290808]\n",
      "epoch:10 step:9819 [D loss: 0.234262, acc.: 59.38%] [G loss: 0.310263]\n",
      "epoch:10 step:9820 [D loss: 0.240051, acc.: 62.50%] [G loss: 0.304040]\n",
      "epoch:10 step:9821 [D loss: 0.221865, acc.: 70.31%] [G loss: 0.315435]\n",
      "epoch:10 step:9822 [D loss: 0.249045, acc.: 54.69%] [G loss: 0.294679]\n",
      "epoch:10 step:9823 [D loss: 0.239129, acc.: 59.38%] [G loss: 0.284953]\n",
      "epoch:10 step:9824 [D loss: 0.251745, acc.: 55.47%] [G loss: 0.296017]\n",
      "epoch:10 step:9825 [D loss: 0.227557, acc.: 62.50%] [G loss: 0.296935]\n",
      "epoch:10 step:9826 [D loss: 0.263298, acc.: 45.31%] [G loss: 0.277865]\n",
      "epoch:10 step:9827 [D loss: 0.223575, acc.: 60.16%] [G loss: 0.300571]\n",
      "epoch:10 step:9828 [D loss: 0.258853, acc.: 52.34%] [G loss: 0.314091]\n",
      "epoch:10 step:9829 [D loss: 0.243979, acc.: 55.47%] [G loss: 0.308324]\n",
      "epoch:10 step:9830 [D loss: 0.233460, acc.: 63.28%] [G loss: 0.292681]\n",
      "epoch:10 step:9831 [D loss: 0.242747, acc.: 59.38%] [G loss: 0.273281]\n",
      "epoch:10 step:9832 [D loss: 0.254209, acc.: 50.00%] [G loss: 0.307491]\n",
      "epoch:10 step:9833 [D loss: 0.236975, acc.: 59.38%] [G loss: 0.303947]\n",
      "epoch:10 step:9834 [D loss: 0.237878, acc.: 58.59%] [G loss: 0.307136]\n",
      "epoch:10 step:9835 [D loss: 0.260476, acc.: 53.12%] [G loss: 0.274356]\n",
      "epoch:10 step:9836 [D loss: 0.254226, acc.: 54.69%] [G loss: 0.282314]\n",
      "epoch:10 step:9837 [D loss: 0.240960, acc.: 57.81%] [G loss: 0.285681]\n",
      "epoch:10 step:9838 [D loss: 0.239085, acc.: 56.25%] [G loss: 0.277053]\n",
      "epoch:10 step:9839 [D loss: 0.247444, acc.: 53.91%] [G loss: 0.294978]\n",
      "epoch:10 step:9840 [D loss: 0.260155, acc.: 50.00%] [G loss: 0.313579]\n",
      "epoch:10 step:9841 [D loss: 0.235612, acc.: 58.59%] [G loss: 0.278039]\n",
      "epoch:10 step:9842 [D loss: 0.246416, acc.: 52.34%] [G loss: 0.279756]\n",
      "epoch:10 step:9843 [D loss: 0.248071, acc.: 56.25%] [G loss: 0.265960]\n",
      "epoch:10 step:9844 [D loss: 0.242125, acc.: 54.69%] [G loss: 0.299626]\n",
      "epoch:10 step:9845 [D loss: 0.234148, acc.: 59.38%] [G loss: 0.327908]\n",
      "epoch:10 step:9846 [D loss: 0.220977, acc.: 68.75%] [G loss: 0.315964]\n",
      "epoch:10 step:9847 [D loss: 0.248434, acc.: 54.69%] [G loss: 0.299510]\n",
      "epoch:10 step:9848 [D loss: 0.240372, acc.: 59.38%] [G loss: 0.307986]\n",
      "epoch:10 step:9849 [D loss: 0.254160, acc.: 54.69%] [G loss: 0.289799]\n",
      "epoch:10 step:9850 [D loss: 0.250720, acc.: 57.03%] [G loss: 0.299752]\n",
      "epoch:10 step:9851 [D loss: 0.244950, acc.: 57.81%] [G loss: 0.299964]\n",
      "epoch:10 step:9852 [D loss: 0.238209, acc.: 57.03%] [G loss: 0.287507]\n",
      "epoch:10 step:9853 [D loss: 0.246718, acc.: 61.72%] [G loss: 0.329416]\n",
      "epoch:10 step:9854 [D loss: 0.236425, acc.: 65.62%] [G loss: 0.320605]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:10 step:9855 [D loss: 0.257542, acc.: 50.00%] [G loss: 0.291723]\n",
      "epoch:10 step:9856 [D loss: 0.242001, acc.: 60.94%] [G loss: 0.294512]\n",
      "epoch:10 step:9857 [D loss: 0.244333, acc.: 50.00%] [G loss: 0.292744]\n",
      "epoch:10 step:9858 [D loss: 0.234489, acc.: 66.41%] [G loss: 0.308677]\n",
      "epoch:10 step:9859 [D loss: 0.251974, acc.: 51.56%] [G loss: 0.298524]\n",
      "epoch:10 step:9860 [D loss: 0.218755, acc.: 70.31%] [G loss: 0.303837]\n",
      "epoch:10 step:9861 [D loss: 0.235835, acc.: 57.03%] [G loss: 0.296263]\n",
      "epoch:10 step:9862 [D loss: 0.242101, acc.: 60.16%] [G loss: 0.291427]\n",
      "epoch:10 step:9863 [D loss: 0.251117, acc.: 55.47%] [G loss: 0.295444]\n",
      "epoch:10 step:9864 [D loss: 0.227170, acc.: 66.41%] [G loss: 0.305168]\n",
      "epoch:10 step:9865 [D loss: 0.237690, acc.: 59.38%] [G loss: 0.307794]\n",
      "epoch:10 step:9866 [D loss: 0.233959, acc.: 62.50%] [G loss: 0.295888]\n",
      "epoch:10 step:9867 [D loss: 0.245106, acc.: 57.03%] [G loss: 0.293410]\n",
      "epoch:10 step:9868 [D loss: 0.231705, acc.: 56.25%] [G loss: 0.329164]\n",
      "epoch:10 step:9869 [D loss: 0.236532, acc.: 62.50%] [G loss: 0.308370]\n",
      "epoch:10 step:9870 [D loss: 0.237561, acc.: 57.81%] [G loss: 0.299032]\n",
      "epoch:10 step:9871 [D loss: 0.243446, acc.: 56.25%] [G loss: 0.312638]\n",
      "epoch:10 step:9872 [D loss: 0.228323, acc.: 64.06%] [G loss: 0.288928]\n",
      "epoch:10 step:9873 [D loss: 0.229670, acc.: 64.84%] [G loss: 0.297887]\n",
      "epoch:10 step:9874 [D loss: 0.239376, acc.: 59.38%] [G loss: 0.291927]\n",
      "epoch:10 step:9875 [D loss: 0.237613, acc.: 58.59%] [G loss: 0.319634]\n",
      "epoch:10 step:9876 [D loss: 0.245845, acc.: 56.25%] [G loss: 0.297983]\n",
      "epoch:10 step:9877 [D loss: 0.242874, acc.: 56.25%] [G loss: 0.301301]\n",
      "epoch:10 step:9878 [D loss: 0.244120, acc.: 55.47%] [G loss: 0.294238]\n",
      "epoch:10 step:9879 [D loss: 0.236296, acc.: 59.38%] [G loss: 0.340093]\n",
      "epoch:10 step:9880 [D loss: 0.236333, acc.: 60.94%] [G loss: 0.293174]\n",
      "epoch:10 step:9881 [D loss: 0.238615, acc.: 59.38%] [G loss: 0.305281]\n",
      "epoch:10 step:9882 [D loss: 0.223015, acc.: 60.16%] [G loss: 0.297609]\n",
      "epoch:10 step:9883 [D loss: 0.233212, acc.: 63.28%] [G loss: 0.312700]\n",
      "epoch:10 step:9884 [D loss: 0.246265, acc.: 53.91%] [G loss: 0.286377]\n",
      "epoch:10 step:9885 [D loss: 0.240045, acc.: 57.81%] [G loss: 0.296159]\n",
      "epoch:10 step:9886 [D loss: 0.239974, acc.: 60.94%] [G loss: 0.291329]\n",
      "epoch:10 step:9887 [D loss: 0.252571, acc.: 54.69%] [G loss: 0.302787]\n",
      "epoch:10 step:9888 [D loss: 0.240075, acc.: 63.28%] [G loss: 0.290575]\n",
      "epoch:10 step:9889 [D loss: 0.246752, acc.: 53.12%] [G loss: 0.288288]\n",
      "epoch:10 step:9890 [D loss: 0.227477, acc.: 64.84%] [G loss: 0.297769]\n",
      "epoch:10 step:9891 [D loss: 0.251124, acc.: 50.00%] [G loss: 0.285528]\n",
      "epoch:10 step:9892 [D loss: 0.232965, acc.: 54.69%] [G loss: 0.290284]\n",
      "epoch:10 step:9893 [D loss: 0.224102, acc.: 66.41%] [G loss: 0.289397]\n",
      "epoch:10 step:9894 [D loss: 0.236273, acc.: 60.94%] [G loss: 0.306130]\n",
      "epoch:10 step:9895 [D loss: 0.240724, acc.: 60.16%] [G loss: 0.295559]\n",
      "epoch:10 step:9896 [D loss: 0.253488, acc.: 53.91%] [G loss: 0.305971]\n",
      "epoch:10 step:9897 [D loss: 0.235767, acc.: 62.50%] [G loss: 0.292915]\n",
      "epoch:10 step:9898 [D loss: 0.241854, acc.: 58.59%] [G loss: 0.298103]\n",
      "epoch:10 step:9899 [D loss: 0.239071, acc.: 58.59%] [G loss: 0.308857]\n",
      "epoch:10 step:9900 [D loss: 0.238707, acc.: 57.03%] [G loss: 0.298104]\n",
      "epoch:10 step:9901 [D loss: 0.253288, acc.: 53.12%] [G loss: 0.306650]\n",
      "epoch:10 step:9902 [D loss: 0.251241, acc.: 55.47%] [G loss: 0.289820]\n",
      "epoch:10 step:9903 [D loss: 0.248875, acc.: 54.69%] [G loss: 0.286096]\n",
      "epoch:10 step:9904 [D loss: 0.257160, acc.: 49.22%] [G loss: 0.307234]\n",
      "epoch:10 step:9905 [D loss: 0.234267, acc.: 65.62%] [G loss: 0.295900]\n",
      "epoch:10 step:9906 [D loss: 0.250362, acc.: 47.66%] [G loss: 0.291947]\n",
      "epoch:10 step:9907 [D loss: 0.234702, acc.: 60.94%] [G loss: 0.320930]\n",
      "epoch:10 step:9908 [D loss: 0.270856, acc.: 46.88%] [G loss: 0.304989]\n",
      "epoch:10 step:9909 [D loss: 0.232776, acc.: 60.16%] [G loss: 0.320509]\n",
      "epoch:10 step:9910 [D loss: 0.245794, acc.: 54.69%] [G loss: 0.300966]\n",
      "epoch:10 step:9911 [D loss: 0.221661, acc.: 70.31%] [G loss: 0.302738]\n",
      "epoch:10 step:9912 [D loss: 0.247600, acc.: 57.81%] [G loss: 0.301133]\n",
      "epoch:10 step:9913 [D loss: 0.229980, acc.: 64.06%] [G loss: 0.307816]\n",
      "epoch:10 step:9914 [D loss: 0.245727, acc.: 54.69%] [G loss: 0.309889]\n",
      "epoch:10 step:9915 [D loss: 0.231804, acc.: 62.50%] [G loss: 0.324931]\n",
      "epoch:10 step:9916 [D loss: 0.240989, acc.: 57.81%] [G loss: 0.316873]\n",
      "epoch:10 step:9917 [D loss: 0.253169, acc.: 53.91%] [G loss: 0.289061]\n",
      "epoch:10 step:9918 [D loss: 0.259916, acc.: 50.00%] [G loss: 0.300683]\n",
      "epoch:10 step:9919 [D loss: 0.238018, acc.: 60.94%] [G loss: 0.293908]\n",
      "epoch:10 step:9920 [D loss: 0.219486, acc.: 70.31%] [G loss: 0.310850]\n",
      "epoch:10 step:9921 [D loss: 0.238052, acc.: 57.81%] [G loss: 0.303875]\n",
      "epoch:10 step:9922 [D loss: 0.244421, acc.: 62.50%] [G loss: 0.295657]\n",
      "epoch:10 step:9923 [D loss: 0.238576, acc.: 59.38%] [G loss: 0.301882]\n",
      "epoch:10 step:9924 [D loss: 0.256918, acc.: 54.69%] [G loss: 0.301353]\n",
      "epoch:10 step:9925 [D loss: 0.254740, acc.: 51.56%] [G loss: 0.312880]\n",
      "epoch:10 step:9926 [D loss: 0.230990, acc.: 57.81%] [G loss: 0.318086]\n",
      "epoch:10 step:9927 [D loss: 0.238709, acc.: 62.50%] [G loss: 0.323577]\n",
      "epoch:10 step:9928 [D loss: 0.231570, acc.: 63.28%] [G loss: 0.321164]\n",
      "epoch:10 step:9929 [D loss: 0.229450, acc.: 62.50%] [G loss: 0.292633]\n",
      "epoch:10 step:9930 [D loss: 0.239484, acc.: 52.34%] [G loss: 0.288567]\n",
      "epoch:10 step:9931 [D loss: 0.234188, acc.: 60.94%] [G loss: 0.294701]\n",
      "epoch:10 step:9932 [D loss: 0.246855, acc.: 57.81%] [G loss: 0.298208]\n",
      "epoch:10 step:9933 [D loss: 0.237773, acc.: 62.50%] [G loss: 0.283060]\n",
      "epoch:10 step:9934 [D loss: 0.225279, acc.: 66.41%] [G loss: 0.312397]\n",
      "epoch:10 step:9935 [D loss: 0.238882, acc.: 58.59%] [G loss: 0.303672]\n",
      "epoch:10 step:9936 [D loss: 0.239179, acc.: 55.47%] [G loss: 0.304253]\n",
      "epoch:10 step:9937 [D loss: 0.239517, acc.: 53.12%] [G loss: 0.297305]\n",
      "epoch:10 step:9938 [D loss: 0.259562, acc.: 55.47%] [G loss: 0.285783]\n",
      "epoch:10 step:9939 [D loss: 0.237704, acc.: 58.59%] [G loss: 0.273317]\n",
      "epoch:10 step:9940 [D loss: 0.236970, acc.: 59.38%] [G loss: 0.310433]\n",
      "epoch:10 step:9941 [D loss: 0.223864, acc.: 63.28%] [G loss: 0.294857]\n",
      "epoch:10 step:9942 [D loss: 0.237508, acc.: 60.16%] [G loss: 0.286436]\n",
      "epoch:10 step:9943 [D loss: 0.243272, acc.: 57.81%] [G loss: 0.279462]\n",
      "epoch:10 step:9944 [D loss: 0.244044, acc.: 60.16%] [G loss: 0.293679]\n",
      "epoch:10 step:9945 [D loss: 0.246318, acc.: 53.12%] [G loss: 0.310972]\n",
      "epoch:10 step:9946 [D loss: 0.226556, acc.: 64.84%] [G loss: 0.314232]\n",
      "epoch:10 step:9947 [D loss: 0.239045, acc.: 60.16%] [G loss: 0.287213]\n",
      "epoch:10 step:9948 [D loss: 0.252669, acc.: 50.00%] [G loss: 0.328713]\n",
      "epoch:10 step:9949 [D loss: 0.249998, acc.: 56.25%] [G loss: 0.303790]\n",
      "epoch:10 step:9950 [D loss: 0.232815, acc.: 61.72%] [G loss: 0.277858]\n",
      "epoch:10 step:9951 [D loss: 0.237781, acc.: 60.16%] [G loss: 0.296192]\n",
      "epoch:10 step:9952 [D loss: 0.231676, acc.: 60.94%] [G loss: 0.280986]\n",
      "epoch:10 step:9953 [D loss: 0.238920, acc.: 60.16%] [G loss: 0.274080]\n",
      "epoch:10 step:9954 [D loss: 0.250703, acc.: 50.00%] [G loss: 0.276232]\n",
      "epoch:10 step:9955 [D loss: 0.227690, acc.: 60.16%] [G loss: 0.282210]\n",
      "epoch:10 step:9956 [D loss: 0.247730, acc.: 54.69%] [G loss: 0.299231]\n",
      "epoch:10 step:9957 [D loss: 0.244509, acc.: 56.25%] [G loss: 0.277533]\n",
      "epoch:10 step:9958 [D loss: 0.260668, acc.: 49.22%] [G loss: 0.294841]\n",
      "epoch:10 step:9959 [D loss: 0.249430, acc.: 56.25%] [G loss: 0.283793]\n",
      "epoch:10 step:9960 [D loss: 0.237772, acc.: 60.94%] [G loss: 0.296113]\n",
      "epoch:10 step:9961 [D loss: 0.231933, acc.: 60.94%] [G loss: 0.297271]\n",
      "epoch:10 step:9962 [D loss: 0.258296, acc.: 48.44%] [G loss: 0.285897]\n",
      "epoch:10 step:9963 [D loss: 0.247997, acc.: 54.69%] [G loss: 0.285855]\n",
      "epoch:10 step:9964 [D loss: 0.232725, acc.: 60.16%] [G loss: 0.295000]\n",
      "epoch:10 step:9965 [D loss: 0.220136, acc.: 64.84%] [G loss: 0.285542]\n",
      "epoch:10 step:9966 [D loss: 0.236036, acc.: 61.72%] [G loss: 0.317990]\n",
      "epoch:10 step:9967 [D loss: 0.222810, acc.: 65.62%] [G loss: 0.314616]\n",
      "epoch:10 step:9968 [D loss: 0.236689, acc.: 57.03%] [G loss: 0.270582]\n",
      "epoch:10 step:9969 [D loss: 0.214020, acc.: 63.28%] [G loss: 0.300163]\n",
      "epoch:10 step:9970 [D loss: 0.242653, acc.: 51.56%] [G loss: 0.286513]\n",
      "epoch:10 step:9971 [D loss: 0.239113, acc.: 57.03%] [G loss: 0.321682]\n",
      "epoch:10 step:9972 [D loss: 0.258102, acc.: 52.34%] [G loss: 0.276546]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:10 step:9973 [D loss: 0.258788, acc.: 44.53%] [G loss: 0.289149]\n",
      "epoch:10 step:9974 [D loss: 0.241143, acc.: 53.91%] [G loss: 0.323428]\n",
      "epoch:10 step:9975 [D loss: 0.248859, acc.: 51.56%] [G loss: 0.304366]\n",
      "epoch:10 step:9976 [D loss: 0.239732, acc.: 56.25%] [G loss: 0.294457]\n",
      "epoch:10 step:9977 [D loss: 0.236238, acc.: 58.59%] [G loss: 0.292823]\n",
      "epoch:10 step:9978 [D loss: 0.240864, acc.: 54.69%] [G loss: 0.289601]\n",
      "epoch:10 step:9979 [D loss: 0.233152, acc.: 63.28%] [G loss: 0.315945]\n",
      "epoch:10 step:9980 [D loss: 0.245305, acc.: 52.34%] [G loss: 0.332315]\n",
      "epoch:10 step:9981 [D loss: 0.242721, acc.: 53.12%] [G loss: 0.298375]\n",
      "epoch:10 step:9982 [D loss: 0.252968, acc.: 51.56%] [G loss: 0.297143]\n",
      "epoch:10 step:9983 [D loss: 0.250998, acc.: 53.91%] [G loss: 0.299497]\n",
      "epoch:10 step:9984 [D loss: 0.247332, acc.: 52.34%] [G loss: 0.309024]\n",
      "epoch:10 step:9985 [D loss: 0.258983, acc.: 46.09%] [G loss: 0.283868]\n",
      "epoch:10 step:9986 [D loss: 0.230874, acc.: 57.03%] [G loss: 0.319253]\n",
      "epoch:10 step:9987 [D loss: 0.247660, acc.: 54.69%] [G loss: 0.294090]\n",
      "epoch:10 step:9988 [D loss: 0.225477, acc.: 64.84%] [G loss: 0.315214]\n",
      "epoch:10 step:9989 [D loss: 0.229962, acc.: 61.72%] [G loss: 0.304353]\n",
      "epoch:10 step:9990 [D loss: 0.251143, acc.: 56.25%] [G loss: 0.275861]\n",
      "epoch:10 step:9991 [D loss: 0.257032, acc.: 53.12%] [G loss: 0.275764]\n",
      "epoch:10 step:9992 [D loss: 0.230581, acc.: 60.16%] [G loss: 0.303177]\n",
      "epoch:10 step:9993 [D loss: 0.244776, acc.: 57.03%] [G loss: 0.298366]\n",
      "epoch:10 step:9994 [D loss: 0.229633, acc.: 62.50%] [G loss: 0.273740]\n",
      "epoch:10 step:9995 [D loss: 0.229173, acc.: 62.50%] [G loss: 0.287347]\n",
      "epoch:10 step:9996 [D loss: 0.239054, acc.: 54.69%] [G loss: 0.300270]\n",
      "epoch:10 step:9997 [D loss: 0.218622, acc.: 71.09%] [G loss: 0.290858]\n",
      "epoch:10 step:9998 [D loss: 0.246239, acc.: 54.69%] [G loss: 0.309879]\n",
      "epoch:10 step:9999 [D loss: 0.235721, acc.: 59.38%] [G loss: 0.291013]\n",
      "epoch:10 step:10000 [D loss: 0.245542, acc.: 57.81%] [G loss: 0.313328]\n",
      "epoch:10 step:10001 [D loss: 0.233954, acc.: 60.94%] [G loss: 0.303168]\n",
      "epoch:10 step:10002 [D loss: 0.252637, acc.: 50.78%] [G loss: 0.294017]\n",
      "epoch:10 step:10003 [D loss: 0.245656, acc.: 57.03%] [G loss: 0.289744]\n",
      "epoch:10 step:10004 [D loss: 0.251772, acc.: 57.03%] [G loss: 0.338326]\n",
      "epoch:10 step:10005 [D loss: 0.234643, acc.: 60.16%] [G loss: 0.304519]\n",
      "epoch:10 step:10006 [D loss: 0.240358, acc.: 57.03%] [G loss: 0.322006]\n",
      "epoch:10 step:10007 [D loss: 0.233529, acc.: 65.62%] [G loss: 0.275595]\n",
      "epoch:10 step:10008 [D loss: 0.237132, acc.: 60.16%] [G loss: 0.303063]\n",
      "epoch:10 step:10009 [D loss: 0.245394, acc.: 53.91%] [G loss: 0.300171]\n",
      "epoch:10 step:10010 [D loss: 0.215704, acc.: 59.38%] [G loss: 0.302959]\n",
      "epoch:10 step:10011 [D loss: 0.243362, acc.: 56.25%] [G loss: 0.280204]\n",
      "epoch:10 step:10012 [D loss: 0.240400, acc.: 57.03%] [G loss: 0.297765]\n",
      "epoch:10 step:10013 [D loss: 0.245500, acc.: 59.38%] [G loss: 0.320328]\n",
      "epoch:10 step:10014 [D loss: 0.246251, acc.: 53.91%] [G loss: 0.285485]\n",
      "epoch:10 step:10015 [D loss: 0.249955, acc.: 53.12%] [G loss: 0.270264]\n",
      "epoch:10 step:10016 [D loss: 0.243789, acc.: 57.03%] [G loss: 0.285059]\n",
      "epoch:10 step:10017 [D loss: 0.247695, acc.: 53.12%] [G loss: 0.288772]\n",
      "epoch:10 step:10018 [D loss: 0.241350, acc.: 57.03%] [G loss: 0.285942]\n",
      "epoch:10 step:10019 [D loss: 0.251415, acc.: 53.91%] [G loss: 0.272993]\n",
      "epoch:10 step:10020 [D loss: 0.234022, acc.: 60.16%] [G loss: 0.291520]\n",
      "epoch:10 step:10021 [D loss: 0.228405, acc.: 62.50%] [G loss: 0.278222]\n",
      "epoch:10 step:10022 [D loss: 0.245593, acc.: 52.34%] [G loss: 0.260043]\n",
      "epoch:10 step:10023 [D loss: 0.231615, acc.: 59.38%] [G loss: 0.296615]\n",
      "epoch:10 step:10024 [D loss: 0.243643, acc.: 52.34%] [G loss: 0.301830]\n",
      "epoch:10 step:10025 [D loss: 0.239458, acc.: 54.69%] [G loss: 0.293279]\n",
      "epoch:10 step:10026 [D loss: 0.236632, acc.: 59.38%] [G loss: 0.309749]\n",
      "epoch:10 step:10027 [D loss: 0.241795, acc.: 59.38%] [G loss: 0.289371]\n",
      "epoch:10 step:10028 [D loss: 0.226995, acc.: 63.28%] [G loss: 0.317624]\n",
      "epoch:10 step:10029 [D loss: 0.254996, acc.: 50.00%] [G loss: 0.291782]\n",
      "epoch:10 step:10030 [D loss: 0.239868, acc.: 60.16%] [G loss: 0.273517]\n",
      "epoch:10 step:10031 [D loss: 0.246388, acc.: 53.91%] [G loss: 0.277606]\n",
      "epoch:10 step:10032 [D loss: 0.242289, acc.: 60.94%] [G loss: 0.304661]\n",
      "epoch:10 step:10033 [D loss: 0.251343, acc.: 50.00%] [G loss: 0.288412]\n",
      "epoch:10 step:10034 [D loss: 0.241096, acc.: 57.81%] [G loss: 0.272827]\n",
      "epoch:10 step:10035 [D loss: 0.234415, acc.: 57.03%] [G loss: 0.303347]\n",
      "epoch:10 step:10036 [D loss: 0.248681, acc.: 52.34%] [G loss: 0.294452]\n",
      "epoch:10 step:10037 [D loss: 0.238721, acc.: 57.81%] [G loss: 0.292188]\n",
      "epoch:10 step:10038 [D loss: 0.222569, acc.: 67.97%] [G loss: 0.302969]\n",
      "epoch:10 step:10039 [D loss: 0.225631, acc.: 65.62%] [G loss: 0.281310]\n",
      "epoch:10 step:10040 [D loss: 0.256001, acc.: 52.34%] [G loss: 0.281578]\n",
      "epoch:10 step:10041 [D loss: 0.246873, acc.: 54.69%] [G loss: 0.303216]\n",
      "epoch:10 step:10042 [D loss: 0.238534, acc.: 60.16%] [G loss: 0.291111]\n",
      "epoch:10 step:10043 [D loss: 0.249819, acc.: 55.47%] [G loss: 0.298998]\n",
      "epoch:10 step:10044 [D loss: 0.252048, acc.: 50.00%] [G loss: 0.284486]\n",
      "epoch:10 step:10045 [D loss: 0.252718, acc.: 51.56%] [G loss: 0.305282]\n",
      "epoch:10 step:10046 [D loss: 0.229892, acc.: 62.50%] [G loss: 0.312510]\n",
      "epoch:10 step:10047 [D loss: 0.239425, acc.: 58.59%] [G loss: 0.290087]\n",
      "epoch:10 step:10048 [D loss: 0.243323, acc.: 56.25%] [G loss: 0.298840]\n",
      "epoch:10 step:10049 [D loss: 0.227899, acc.: 59.38%] [G loss: 0.317812]\n",
      "epoch:10 step:10050 [D loss: 0.246598, acc.: 55.47%] [G loss: 0.301207]\n",
      "epoch:10 step:10051 [D loss: 0.228071, acc.: 64.06%] [G loss: 0.304622]\n",
      "epoch:10 step:10052 [D loss: 0.239865, acc.: 60.94%] [G loss: 0.289724]\n",
      "epoch:10 step:10053 [D loss: 0.242484, acc.: 56.25%] [G loss: 0.292777]\n",
      "epoch:10 step:10054 [D loss: 0.243981, acc.: 53.12%] [G loss: 0.285945]\n",
      "epoch:10 step:10055 [D loss: 0.234076, acc.: 58.59%] [G loss: 0.287606]\n",
      "epoch:10 step:10056 [D loss: 0.251881, acc.: 48.44%] [G loss: 0.279060]\n",
      "epoch:10 step:10057 [D loss: 0.234682, acc.: 62.50%] [G loss: 0.305016]\n",
      "epoch:10 step:10058 [D loss: 0.247899, acc.: 59.38%] [G loss: 0.299262]\n",
      "epoch:10 step:10059 [D loss: 0.237512, acc.: 60.16%] [G loss: 0.320841]\n",
      "epoch:10 step:10060 [D loss: 0.242429, acc.: 58.59%] [G loss: 0.307816]\n",
      "epoch:10 step:10061 [D loss: 0.236550, acc.: 62.50%] [G loss: 0.293581]\n",
      "epoch:10 step:10062 [D loss: 0.251968, acc.: 52.34%] [G loss: 0.295562]\n",
      "epoch:10 step:10063 [D loss: 0.235318, acc.: 60.16%] [G loss: 0.315823]\n",
      "epoch:10 step:10064 [D loss: 0.247647, acc.: 57.81%] [G loss: 0.287193]\n",
      "epoch:10 step:10065 [D loss: 0.252434, acc.: 53.12%] [G loss: 0.272807]\n",
      "epoch:10 step:10066 [D loss: 0.237386, acc.: 57.03%] [G loss: 0.315189]\n",
      "epoch:10 step:10067 [D loss: 0.233457, acc.: 60.16%] [G loss: 0.292652]\n",
      "epoch:10 step:10068 [D loss: 0.241833, acc.: 58.59%] [G loss: 0.275326]\n",
      "epoch:10 step:10069 [D loss: 0.227720, acc.: 63.28%] [G loss: 0.296492]\n",
      "epoch:10 step:10070 [D loss: 0.229996, acc.: 61.72%] [G loss: 0.299692]\n",
      "epoch:10 step:10071 [D loss: 0.247184, acc.: 57.81%] [G loss: 0.299066]\n",
      "epoch:10 step:10072 [D loss: 0.232531, acc.: 57.81%] [G loss: 0.299219]\n",
      "epoch:10 step:10073 [D loss: 0.237109, acc.: 54.69%] [G loss: 0.305101]\n",
      "epoch:10 step:10074 [D loss: 0.235681, acc.: 60.94%] [G loss: 0.334058]\n",
      "epoch:10 step:10075 [D loss: 0.235972, acc.: 55.47%] [G loss: 0.329738]\n",
      "epoch:10 step:10076 [D loss: 0.247200, acc.: 56.25%] [G loss: 0.292604]\n",
      "epoch:10 step:10077 [D loss: 0.232710, acc.: 57.03%] [G loss: 0.307281]\n",
      "epoch:10 step:10078 [D loss: 0.251928, acc.: 54.69%] [G loss: 0.271430]\n",
      "epoch:10 step:10079 [D loss: 0.239569, acc.: 59.38%] [G loss: 0.312152]\n",
      "epoch:10 step:10080 [D loss: 0.248158, acc.: 56.25%] [G loss: 0.271110]\n",
      "epoch:10 step:10081 [D loss: 0.236007, acc.: 57.81%] [G loss: 0.280430]\n",
      "epoch:10 step:10082 [D loss: 0.250304, acc.: 52.34%] [G loss: 0.280106]\n",
      "epoch:10 step:10083 [D loss: 0.222568, acc.: 61.72%] [G loss: 0.319752]\n",
      "epoch:10 step:10084 [D loss: 0.250230, acc.: 48.44%] [G loss: 0.272898]\n",
      "epoch:10 step:10085 [D loss: 0.235379, acc.: 59.38%] [G loss: 0.284290]\n",
      "epoch:10 step:10086 [D loss: 0.236954, acc.: 58.59%] [G loss: 0.266721]\n",
      "epoch:10 step:10087 [D loss: 0.243972, acc.: 58.59%] [G loss: 0.296859]\n",
      "epoch:10 step:10088 [D loss: 0.228303, acc.: 62.50%] [G loss: 0.317561]\n",
      "epoch:10 step:10089 [D loss: 0.243015, acc.: 54.69%] [G loss: 0.282806]\n",
      "epoch:10 step:10090 [D loss: 0.265293, acc.: 48.44%] [G loss: 0.297611]\n",
      "epoch:10 step:10091 [D loss: 0.241349, acc.: 56.25%] [G loss: 0.299268]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:10 step:10092 [D loss: 0.255088, acc.: 50.78%] [G loss: 0.290714]\n",
      "epoch:10 step:10093 [D loss: 0.245198, acc.: 57.03%] [G loss: 0.302557]\n",
      "epoch:10 step:10094 [D loss: 0.240272, acc.: 57.03%] [G loss: 0.300796]\n",
      "epoch:10 step:10095 [D loss: 0.248017, acc.: 53.91%] [G loss: 0.312785]\n",
      "epoch:10 step:10096 [D loss: 0.248784, acc.: 51.56%] [G loss: 0.298624]\n",
      "epoch:10 step:10097 [D loss: 0.245218, acc.: 55.47%] [G loss: 0.308246]\n",
      "epoch:10 step:10098 [D loss: 0.238379, acc.: 57.03%] [G loss: 0.306842]\n",
      "epoch:10 step:10099 [D loss: 0.255379, acc.: 55.47%] [G loss: 0.277132]\n",
      "epoch:10 step:10100 [D loss: 0.246779, acc.: 52.34%] [G loss: 0.294303]\n",
      "epoch:10 step:10101 [D loss: 0.234119, acc.: 55.47%] [G loss: 0.297688]\n",
      "epoch:10 step:10102 [D loss: 0.228728, acc.: 66.41%] [G loss: 0.305938]\n",
      "epoch:10 step:10103 [D loss: 0.263040, acc.: 49.22%] [G loss: 0.314881]\n",
      "epoch:10 step:10104 [D loss: 0.237094, acc.: 57.81%] [G loss: 0.307814]\n",
      "epoch:10 step:10105 [D loss: 0.228377, acc.: 59.38%] [G loss: 0.329049]\n",
      "epoch:10 step:10106 [D loss: 0.234119, acc.: 60.94%] [G loss: 0.308482]\n",
      "epoch:10 step:10107 [D loss: 0.231498, acc.: 60.94%] [G loss: 0.295804]\n",
      "epoch:10 step:10108 [D loss: 0.241284, acc.: 63.28%] [G loss: 0.313657]\n",
      "epoch:10 step:10109 [D loss: 0.252815, acc.: 50.00%] [G loss: 0.320119]\n",
      "epoch:10 step:10110 [D loss: 0.234330, acc.: 57.81%] [G loss: 0.313062]\n",
      "epoch:10 step:10111 [D loss: 0.239355, acc.: 62.50%] [G loss: 0.284295]\n",
      "epoch:10 step:10112 [D loss: 0.230648, acc.: 61.72%] [G loss: 0.307701]\n",
      "epoch:10 step:10113 [D loss: 0.240791, acc.: 60.16%] [G loss: 0.278217]\n",
      "epoch:10 step:10114 [D loss: 0.226836, acc.: 62.50%] [G loss: 0.312750]\n",
      "epoch:10 step:10115 [D loss: 0.243933, acc.: 57.81%] [G loss: 0.302475]\n",
      "epoch:10 step:10116 [D loss: 0.240329, acc.: 57.03%] [G loss: 0.319869]\n",
      "epoch:10 step:10117 [D loss: 0.231407, acc.: 60.94%] [G loss: 0.290314]\n",
      "epoch:10 step:10118 [D loss: 0.231282, acc.: 64.06%] [G loss: 0.313138]\n",
      "epoch:10 step:10119 [D loss: 0.247588, acc.: 57.03%] [G loss: 0.288280]\n",
      "epoch:10 step:10120 [D loss: 0.237708, acc.: 57.81%] [G loss: 0.301263]\n",
      "epoch:10 step:10121 [D loss: 0.254812, acc.: 54.69%] [G loss: 0.294856]\n",
      "epoch:10 step:10122 [D loss: 0.246856, acc.: 55.47%] [G loss: 0.298478]\n",
      "epoch:10 step:10123 [D loss: 0.231181, acc.: 60.94%] [G loss: 0.287278]\n",
      "epoch:10 step:10124 [D loss: 0.233072, acc.: 60.16%] [G loss: 0.291095]\n",
      "epoch:10 step:10125 [D loss: 0.222890, acc.: 60.94%] [G loss: 0.302852]\n",
      "epoch:10 step:10126 [D loss: 0.251281, acc.: 53.12%] [G loss: 0.291064]\n",
      "epoch:10 step:10127 [D loss: 0.237266, acc.: 60.16%] [G loss: 0.287210]\n",
      "epoch:10 step:10128 [D loss: 0.235083, acc.: 62.50%] [G loss: 0.312772]\n",
      "epoch:10 step:10129 [D loss: 0.248655, acc.: 53.91%] [G loss: 0.293928]\n",
      "epoch:10 step:10130 [D loss: 0.229105, acc.: 60.94%] [G loss: 0.298680]\n",
      "epoch:10 step:10131 [D loss: 0.235144, acc.: 58.59%] [G loss: 0.312398]\n",
      "epoch:10 step:10132 [D loss: 0.238702, acc.: 57.81%] [G loss: 0.287193]\n",
      "epoch:10 step:10133 [D loss: 0.245370, acc.: 53.91%] [G loss: 0.271786]\n",
      "epoch:10 step:10134 [D loss: 0.245429, acc.: 58.59%] [G loss: 0.295871]\n",
      "epoch:10 step:10135 [D loss: 0.249691, acc.: 52.34%] [G loss: 0.292752]\n",
      "epoch:10 step:10136 [D loss: 0.235558, acc.: 54.69%] [G loss: 0.317445]\n",
      "epoch:10 step:10137 [D loss: 0.250374, acc.: 55.47%] [G loss: 0.292972]\n",
      "epoch:10 step:10138 [D loss: 0.229906, acc.: 64.06%] [G loss: 0.326910]\n",
      "epoch:10 step:10139 [D loss: 0.241691, acc.: 57.03%] [G loss: 0.295018]\n",
      "epoch:10 step:10140 [D loss: 0.230257, acc.: 60.16%] [G loss: 0.312852]\n",
      "epoch:10 step:10141 [D loss: 0.253539, acc.: 53.12%] [G loss: 0.287337]\n",
      "epoch:10 step:10142 [D loss: 0.226975, acc.: 66.41%] [G loss: 0.291018]\n",
      "epoch:10 step:10143 [D loss: 0.238884, acc.: 53.91%] [G loss: 0.300984]\n",
      "epoch:10 step:10144 [D loss: 0.239037, acc.: 61.72%] [G loss: 0.260215]\n",
      "epoch:10 step:10145 [D loss: 0.242501, acc.: 54.69%] [G loss: 0.289399]\n",
      "epoch:10 step:10146 [D loss: 0.232434, acc.: 58.59%] [G loss: 0.286685]\n",
      "epoch:10 step:10147 [D loss: 0.232185, acc.: 56.25%] [G loss: 0.299222]\n",
      "epoch:10 step:10148 [D loss: 0.248970, acc.: 52.34%] [G loss: 0.301388]\n",
      "epoch:10 step:10149 [D loss: 0.237407, acc.: 56.25%] [G loss: 0.314478]\n",
      "epoch:10 step:10150 [D loss: 0.259649, acc.: 50.78%] [G loss: 0.284864]\n",
      "epoch:10 step:10151 [D loss: 0.252644, acc.: 52.34%] [G loss: 0.275882]\n",
      "epoch:10 step:10152 [D loss: 0.238623, acc.: 60.16%] [G loss: 0.305185]\n",
      "epoch:10 step:10153 [D loss: 0.243368, acc.: 56.25%] [G loss: 0.310260]\n",
      "epoch:10 step:10154 [D loss: 0.249484, acc.: 49.22%] [G loss: 0.283531]\n",
      "epoch:10 step:10155 [D loss: 0.244036, acc.: 57.03%] [G loss: 0.295885]\n",
      "epoch:10 step:10156 [D loss: 0.235613, acc.: 54.69%] [G loss: 0.304971]\n",
      "epoch:10 step:10157 [D loss: 0.229111, acc.: 57.81%] [G loss: 0.284904]\n",
      "epoch:10 step:10158 [D loss: 0.233290, acc.: 60.16%] [G loss: 0.314564]\n",
      "epoch:10 step:10159 [D loss: 0.240942, acc.: 58.59%] [G loss: 0.310690]\n",
      "epoch:10 step:10160 [D loss: 0.257258, acc.: 55.47%] [G loss: 0.282994]\n",
      "epoch:10 step:10161 [D loss: 0.242888, acc.: 54.69%] [G loss: 0.323475]\n",
      "epoch:10 step:10162 [D loss: 0.247304, acc.: 56.25%] [G loss: 0.316902]\n",
      "epoch:10 step:10163 [D loss: 0.257987, acc.: 50.78%] [G loss: 0.332355]\n",
      "epoch:10 step:10164 [D loss: 0.244492, acc.: 55.47%] [G loss: 0.299354]\n",
      "epoch:10 step:10165 [D loss: 0.236341, acc.: 57.81%] [G loss: 0.301101]\n",
      "epoch:10 step:10166 [D loss: 0.235362, acc.: 57.03%] [G loss: 0.304599]\n",
      "epoch:10 step:10167 [D loss: 0.232936, acc.: 60.94%] [G loss: 0.306117]\n",
      "epoch:10 step:10168 [D loss: 0.235706, acc.: 57.03%] [G loss: 0.307028]\n",
      "epoch:10 step:10169 [D loss: 0.248135, acc.: 57.81%] [G loss: 0.306377]\n",
      "epoch:10 step:10170 [D loss: 0.262914, acc.: 53.91%] [G loss: 0.302080]\n",
      "epoch:10 step:10171 [D loss: 0.237598, acc.: 59.38%] [G loss: 0.308019]\n",
      "epoch:10 step:10172 [D loss: 0.236820, acc.: 60.94%] [G loss: 0.304539]\n",
      "epoch:10 step:10173 [D loss: 0.231726, acc.: 57.81%] [G loss: 0.283772]\n",
      "epoch:10 step:10174 [D loss: 0.249038, acc.: 53.91%] [G loss: 0.281811]\n",
      "epoch:10 step:10175 [D loss: 0.250327, acc.: 48.44%] [G loss: 0.297900]\n",
      "epoch:10 step:10176 [D loss: 0.235494, acc.: 55.47%] [G loss: 0.300226]\n",
      "epoch:10 step:10177 [D loss: 0.236357, acc.: 57.03%] [G loss: 0.310689]\n",
      "epoch:10 step:10178 [D loss: 0.231842, acc.: 64.84%] [G loss: 0.291403]\n",
      "epoch:10 step:10179 [D loss: 0.239592, acc.: 60.94%] [G loss: 0.302703]\n",
      "epoch:10 step:10180 [D loss: 0.235919, acc.: 61.72%] [G loss: 0.320770]\n",
      "epoch:10 step:10181 [D loss: 0.254833, acc.: 55.47%] [G loss: 0.327434]\n",
      "epoch:10 step:10182 [D loss: 0.230341, acc.: 60.94%] [G loss: 0.308060]\n",
      "epoch:10 step:10183 [D loss: 0.249527, acc.: 53.91%] [G loss: 0.294468]\n",
      "epoch:10 step:10184 [D loss: 0.246463, acc.: 54.69%] [G loss: 0.279326]\n",
      "epoch:10 step:10185 [D loss: 0.229978, acc.: 60.16%] [G loss: 0.289613]\n",
      "epoch:10 step:10186 [D loss: 0.233299, acc.: 60.16%] [G loss: 0.292886]\n",
      "epoch:10 step:10187 [D loss: 0.223940, acc.: 64.06%] [G loss: 0.289874]\n",
      "epoch:10 step:10188 [D loss: 0.247583, acc.: 55.47%] [G loss: 0.283732]\n",
      "epoch:10 step:10189 [D loss: 0.232250, acc.: 58.59%] [G loss: 0.320981]\n",
      "epoch:10 step:10190 [D loss: 0.256837, acc.: 47.66%] [G loss: 0.266949]\n",
      "epoch:10 step:10191 [D loss: 0.234014, acc.: 62.50%] [G loss: 0.289117]\n",
      "epoch:10 step:10192 [D loss: 0.239473, acc.: 54.69%] [G loss: 0.289072]\n",
      "epoch:10 step:10193 [D loss: 0.257542, acc.: 52.34%] [G loss: 0.282366]\n",
      "epoch:10 step:10194 [D loss: 0.242145, acc.: 54.69%] [G loss: 0.300941]\n",
      "epoch:10 step:10195 [D loss: 0.227040, acc.: 67.97%] [G loss: 0.304540]\n",
      "epoch:10 step:10196 [D loss: 0.229674, acc.: 60.94%] [G loss: 0.303549]\n",
      "epoch:10 step:10197 [D loss: 0.236760, acc.: 57.03%] [G loss: 0.268554]\n",
      "epoch:10 step:10198 [D loss: 0.238943, acc.: 57.81%] [G loss: 0.308531]\n",
      "epoch:10 step:10199 [D loss: 0.263298, acc.: 43.75%] [G loss: 0.282254]\n",
      "epoch:10 step:10200 [D loss: 0.248854, acc.: 55.47%] [G loss: 0.274095]\n",
      "epoch:10 step:10201 [D loss: 0.238335, acc.: 62.50%] [G loss: 0.301002]\n",
      "epoch:10 step:10202 [D loss: 0.226792, acc.: 62.50%] [G loss: 0.294556]\n",
      "epoch:10 step:10203 [D loss: 0.236739, acc.: 58.59%] [G loss: 0.294824]\n",
      "epoch:10 step:10204 [D loss: 0.244042, acc.: 54.69%] [G loss: 0.289674]\n",
      "epoch:10 step:10205 [D loss: 0.240125, acc.: 53.91%] [G loss: 0.304583]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:10 step:10206 [D loss: 0.253386, acc.: 50.78%] [G loss: 0.306207]\n",
      "epoch:10 step:10207 [D loss: 0.232392, acc.: 62.50%] [G loss: 0.308396]\n",
      "epoch:10 step:10208 [D loss: 0.249239, acc.: 57.81%] [G loss: 0.284545]\n",
      "epoch:10 step:10209 [D loss: 0.261232, acc.: 50.78%] [G loss: 0.310175]\n",
      "epoch:10 step:10210 [D loss: 0.261947, acc.: 48.44%] [G loss: 0.274503]\n",
      "epoch:10 step:10211 [D loss: 0.240064, acc.: 58.59%] [G loss: 0.308625]\n",
      "epoch:10 step:10212 [D loss: 0.245759, acc.: 50.78%] [G loss: 0.269109]\n",
      "epoch:10 step:10213 [D loss: 0.258955, acc.: 53.12%] [G loss: 0.304126]\n",
      "epoch:10 step:10214 [D loss: 0.248520, acc.: 54.69%] [G loss: 0.297298]\n",
      "epoch:10 step:10215 [D loss: 0.242875, acc.: 60.94%] [G loss: 0.295311]\n",
      "epoch:10 step:10216 [D loss: 0.243308, acc.: 56.25%] [G loss: 0.294746]\n",
      "epoch:10 step:10217 [D loss: 0.240533, acc.: 56.25%] [G loss: 0.298681]\n",
      "epoch:10 step:10218 [D loss: 0.246704, acc.: 60.16%] [G loss: 0.296782]\n",
      "epoch:10 step:10219 [D loss: 0.259731, acc.: 53.12%] [G loss: 0.335046]\n",
      "epoch:10 step:10220 [D loss: 0.248055, acc.: 49.22%] [G loss: 0.288029]\n",
      "epoch:10 step:10221 [D loss: 0.255277, acc.: 50.78%] [G loss: 0.291286]\n",
      "epoch:10 step:10222 [D loss: 0.212205, acc.: 64.06%] [G loss: 0.358651]\n",
      "epoch:10 step:10223 [D loss: 0.253844, acc.: 50.00%] [G loss: 0.300602]\n",
      "epoch:10 step:10224 [D loss: 0.229444, acc.: 62.50%] [G loss: 0.303548]\n",
      "epoch:10 step:10225 [D loss: 0.243221, acc.: 53.12%] [G loss: 0.298047]\n",
      "epoch:10 step:10226 [D loss: 0.216566, acc.: 65.62%] [G loss: 0.303081]\n",
      "epoch:10 step:10227 [D loss: 0.229128, acc.: 63.28%] [G loss: 0.305547]\n",
      "epoch:10 step:10228 [D loss: 0.244141, acc.: 57.03%] [G loss: 0.293055]\n",
      "epoch:10 step:10229 [D loss: 0.246064, acc.: 58.59%] [G loss: 0.263057]\n",
      "epoch:10 step:10230 [D loss: 0.250424, acc.: 54.69%] [G loss: 0.278183]\n",
      "epoch:10 step:10231 [D loss: 0.239056, acc.: 57.81%] [G loss: 0.305563]\n",
      "epoch:10 step:10232 [D loss: 0.253104, acc.: 51.56%] [G loss: 0.291959]\n",
      "epoch:10 step:10233 [D loss: 0.251630, acc.: 57.81%] [G loss: 0.279467]\n",
      "epoch:10 step:10234 [D loss: 0.247567, acc.: 53.12%] [G loss: 0.272985]\n",
      "epoch:10 step:10235 [D loss: 0.251689, acc.: 50.78%] [G loss: 0.294452]\n",
      "epoch:10 step:10236 [D loss: 0.237851, acc.: 60.16%] [G loss: 0.323089]\n",
      "epoch:10 step:10237 [D loss: 0.247005, acc.: 53.12%] [G loss: 0.314951]\n",
      "epoch:10 step:10238 [D loss: 0.229075, acc.: 65.62%] [G loss: 0.308596]\n",
      "epoch:10 step:10239 [D loss: 0.233679, acc.: 59.38%] [G loss: 0.299419]\n",
      "epoch:10 step:10240 [D loss: 0.266987, acc.: 47.66%] [G loss: 0.300138]\n",
      "epoch:10 step:10241 [D loss: 0.236311, acc.: 57.03%] [G loss: 0.312347]\n",
      "epoch:10 step:10242 [D loss: 0.236352, acc.: 61.72%] [G loss: 0.301583]\n",
      "epoch:10 step:10243 [D loss: 0.245844, acc.: 60.94%] [G loss: 0.305003]\n",
      "epoch:10 step:10244 [D loss: 0.237348, acc.: 60.94%] [G loss: 0.303176]\n",
      "epoch:10 step:10245 [D loss: 0.241876, acc.: 60.16%] [G loss: 0.280465]\n",
      "epoch:10 step:10246 [D loss: 0.244502, acc.: 62.50%] [G loss: 0.293051]\n",
      "epoch:10 step:10247 [D loss: 0.253343, acc.: 55.47%] [G loss: 0.282293]\n",
      "epoch:10 step:10248 [D loss: 0.246185, acc.: 57.81%] [G loss: 0.288007]\n",
      "epoch:10 step:10249 [D loss: 0.228833, acc.: 60.94%] [G loss: 0.296742]\n",
      "epoch:10 step:10250 [D loss: 0.241421, acc.: 59.38%] [G loss: 0.289494]\n",
      "epoch:10 step:10251 [D loss: 0.256885, acc.: 52.34%] [G loss: 0.302024]\n",
      "epoch:10 step:10252 [D loss: 0.240652, acc.: 59.38%] [G loss: 0.300302]\n",
      "epoch:10 step:10253 [D loss: 0.250024, acc.: 54.69%] [G loss: 0.289532]\n",
      "epoch:10 step:10254 [D loss: 0.252589, acc.: 52.34%] [G loss: 0.332755]\n",
      "epoch:10 step:10255 [D loss: 0.233730, acc.: 55.47%] [G loss: 0.276983]\n",
      "epoch:10 step:10256 [D loss: 0.245579, acc.: 58.59%] [G loss: 0.329046]\n",
      "epoch:10 step:10257 [D loss: 0.243631, acc.: 53.12%] [G loss: 0.286856]\n",
      "epoch:10 step:10258 [D loss: 0.227129, acc.: 64.06%] [G loss: 0.310602]\n",
      "epoch:10 step:10259 [D loss: 0.266834, acc.: 43.75%] [G loss: 0.309440]\n",
      "epoch:10 step:10260 [D loss: 0.245156, acc.: 55.47%] [G loss: 0.298539]\n",
      "epoch:10 step:10261 [D loss: 0.240409, acc.: 60.94%] [G loss: 0.290891]\n",
      "epoch:10 step:10262 [D loss: 0.242837, acc.: 57.03%] [G loss: 0.304551]\n",
      "epoch:10 step:10263 [D loss: 0.249473, acc.: 57.81%] [G loss: 0.323262]\n",
      "epoch:10 step:10264 [D loss: 0.241682, acc.: 58.59%] [G loss: 0.296229]\n",
      "epoch:10 step:10265 [D loss: 0.231025, acc.: 62.50%] [G loss: 0.316058]\n",
      "epoch:10 step:10266 [D loss: 0.239309, acc.: 58.59%] [G loss: 0.319031]\n",
      "epoch:10 step:10267 [D loss: 0.248961, acc.: 51.56%] [G loss: 0.313115]\n",
      "epoch:10 step:10268 [D loss: 0.242916, acc.: 54.69%] [G loss: 0.304148]\n",
      "epoch:10 step:10269 [D loss: 0.252460, acc.: 55.47%] [G loss: 0.300173]\n",
      "epoch:10 step:10270 [D loss: 0.233559, acc.: 63.28%] [G loss: 0.298845]\n",
      "epoch:10 step:10271 [D loss: 0.250398, acc.: 53.91%] [G loss: 0.279832]\n",
      "epoch:10 step:10272 [D loss: 0.243801, acc.: 53.91%] [G loss: 0.305792]\n",
      "epoch:10 step:10273 [D loss: 0.232870, acc.: 60.16%] [G loss: 0.325432]\n",
      "epoch:10 step:10274 [D loss: 0.223922, acc.: 59.38%] [G loss: 0.333909]\n",
      "epoch:10 step:10275 [D loss: 0.241249, acc.: 56.25%] [G loss: 0.277869]\n",
      "epoch:10 step:10276 [D loss: 0.223956, acc.: 64.06%] [G loss: 0.308664]\n",
      "epoch:10 step:10277 [D loss: 0.237401, acc.: 60.94%] [G loss: 0.273275]\n",
      "epoch:10 step:10278 [D loss: 0.256982, acc.: 53.12%] [G loss: 0.301460]\n",
      "epoch:10 step:10279 [D loss: 0.256844, acc.: 50.00%] [G loss: 0.291296]\n",
      "epoch:10 step:10280 [D loss: 0.238118, acc.: 63.28%] [G loss: 0.304305]\n",
      "epoch:10 step:10281 [D loss: 0.244824, acc.: 53.91%] [G loss: 0.303390]\n",
      "epoch:10 step:10282 [D loss: 0.245484, acc.: 61.72%] [G loss: 0.307910]\n",
      "epoch:10 step:10283 [D loss: 0.224838, acc.: 59.38%] [G loss: 0.326143]\n",
      "epoch:10 step:10284 [D loss: 0.241946, acc.: 55.47%] [G loss: 0.285732]\n",
      "epoch:10 step:10285 [D loss: 0.226041, acc.: 61.72%] [G loss: 0.285691]\n",
      "epoch:10 step:10286 [D loss: 0.246285, acc.: 53.91%] [G loss: 0.268669]\n",
      "epoch:10 step:10287 [D loss: 0.227383, acc.: 61.72%] [G loss: 0.291423]\n",
      "epoch:10 step:10288 [D loss: 0.232747, acc.: 59.38%] [G loss: 0.269414]\n",
      "epoch:10 step:10289 [D loss: 0.226242, acc.: 67.19%] [G loss: 0.300098]\n",
      "epoch:10 step:10290 [D loss: 0.231544, acc.: 61.72%] [G loss: 0.305916]\n",
      "epoch:10 step:10291 [D loss: 0.241967, acc.: 58.59%] [G loss: 0.304130]\n",
      "epoch:10 step:10292 [D loss: 0.242769, acc.: 63.28%] [G loss: 0.323596]\n",
      "epoch:10 step:10293 [D loss: 0.256002, acc.: 51.56%] [G loss: 0.293265]\n",
      "epoch:10 step:10294 [D loss: 0.241153, acc.: 59.38%] [G loss: 0.298826]\n",
      "epoch:10 step:10295 [D loss: 0.249922, acc.: 53.12%] [G loss: 0.281888]\n",
      "epoch:10 step:10296 [D loss: 0.235839, acc.: 57.81%] [G loss: 0.298498]\n",
      "epoch:10 step:10297 [D loss: 0.248989, acc.: 53.91%] [G loss: 0.307956]\n",
      "epoch:10 step:10298 [D loss: 0.240579, acc.: 56.25%] [G loss: 0.298349]\n",
      "epoch:10 step:10299 [D loss: 0.250146, acc.: 55.47%] [G loss: 0.293921]\n",
      "epoch:10 step:10300 [D loss: 0.234996, acc.: 61.72%] [G loss: 0.297093]\n",
      "epoch:10 step:10301 [D loss: 0.245885, acc.: 50.78%] [G loss: 0.301444]\n",
      "epoch:10 step:10302 [D loss: 0.240188, acc.: 61.72%] [G loss: 0.299811]\n",
      "epoch:10 step:10303 [D loss: 0.233183, acc.: 67.97%] [G loss: 0.274763]\n",
      "epoch:10 step:10304 [D loss: 0.248843, acc.: 50.78%] [G loss: 0.298885]\n",
      "epoch:10 step:10305 [D loss: 0.252214, acc.: 50.00%] [G loss: 0.282015]\n",
      "epoch:10 step:10306 [D loss: 0.244232, acc.: 58.59%] [G loss: 0.297648]\n",
      "epoch:10 step:10307 [D loss: 0.235017, acc.: 59.38%] [G loss: 0.306221]\n",
      "epoch:11 step:10308 [D loss: 0.236311, acc.: 57.81%] [G loss: 0.283974]\n",
      "epoch:11 step:10309 [D loss: 0.259968, acc.: 50.78%] [G loss: 0.276308]\n",
      "epoch:11 step:10310 [D loss: 0.242589, acc.: 55.47%] [G loss: 0.297656]\n",
      "epoch:11 step:10311 [D loss: 0.219807, acc.: 62.50%] [G loss: 0.322268]\n",
      "epoch:11 step:10312 [D loss: 0.260415, acc.: 50.00%] [G loss: 0.285482]\n",
      "epoch:11 step:10313 [D loss: 0.253696, acc.: 55.47%] [G loss: 0.284025]\n",
      "epoch:11 step:10314 [D loss: 0.252467, acc.: 54.69%] [G loss: 0.289823]\n",
      "epoch:11 step:10315 [D loss: 0.223643, acc.: 61.72%] [G loss: 0.301137]\n",
      "epoch:11 step:10316 [D loss: 0.226450, acc.: 67.97%] [G loss: 0.293982]\n",
      "epoch:11 step:10317 [D loss: 0.231056, acc.: 60.16%] [G loss: 0.296493]\n",
      "epoch:11 step:10318 [D loss: 0.249379, acc.: 50.78%] [G loss: 0.268304]\n",
      "epoch:11 step:10319 [D loss: 0.239906, acc.: 54.69%] [G loss: 0.302107]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:11 step:10320 [D loss: 0.232828, acc.: 63.28%] [G loss: 0.312113]\n",
      "epoch:11 step:10321 [D loss: 0.259815, acc.: 50.00%] [G loss: 0.299295]\n",
      "epoch:11 step:10322 [D loss: 0.241671, acc.: 57.81%] [G loss: 0.297222]\n",
      "epoch:11 step:10323 [D loss: 0.231109, acc.: 57.03%] [G loss: 0.320109]\n",
      "epoch:11 step:10324 [D loss: 0.225755, acc.: 64.06%] [G loss: 0.292088]\n",
      "epoch:11 step:10325 [D loss: 0.227870, acc.: 66.41%] [G loss: 0.300120]\n",
      "epoch:11 step:10326 [D loss: 0.241551, acc.: 58.59%] [G loss: 0.312999]\n",
      "epoch:11 step:10327 [D loss: 0.235426, acc.: 59.38%] [G loss: 0.293692]\n",
      "epoch:11 step:10328 [D loss: 0.253981, acc.: 49.22%] [G loss: 0.314544]\n",
      "epoch:11 step:10329 [D loss: 0.251945, acc.: 53.91%] [G loss: 0.294390]\n",
      "epoch:11 step:10330 [D loss: 0.241845, acc.: 59.38%] [G loss: 0.300868]\n",
      "epoch:11 step:10331 [D loss: 0.234891, acc.: 63.28%] [G loss: 0.290029]\n",
      "epoch:11 step:10332 [D loss: 0.238833, acc.: 57.81%] [G loss: 0.287350]\n",
      "epoch:11 step:10333 [D loss: 0.227632, acc.: 64.06%] [G loss: 0.293725]\n",
      "epoch:11 step:10334 [D loss: 0.232565, acc.: 62.50%] [G loss: 0.301096]\n",
      "epoch:11 step:10335 [D loss: 0.232719, acc.: 63.28%] [G loss: 0.308025]\n",
      "epoch:11 step:10336 [D loss: 0.242187, acc.: 60.94%] [G loss: 0.336939]\n",
      "epoch:11 step:10337 [D loss: 0.255541, acc.: 53.91%] [G loss: 0.301052]\n",
      "epoch:11 step:10338 [D loss: 0.250728, acc.: 52.34%] [G loss: 0.304074]\n",
      "epoch:11 step:10339 [D loss: 0.215947, acc.: 65.62%] [G loss: 0.311069]\n",
      "epoch:11 step:10340 [D loss: 0.236662, acc.: 61.72%] [G loss: 0.325226]\n",
      "epoch:11 step:10341 [D loss: 0.238997, acc.: 61.72%] [G loss: 0.294037]\n",
      "epoch:11 step:10342 [D loss: 0.231845, acc.: 61.72%] [G loss: 0.288761]\n",
      "epoch:11 step:10343 [D loss: 0.224125, acc.: 71.09%] [G loss: 0.327068]\n",
      "epoch:11 step:10344 [D loss: 0.227408, acc.: 60.16%] [G loss: 0.279448]\n",
      "epoch:11 step:10345 [D loss: 0.244054, acc.: 57.03%] [G loss: 0.305666]\n",
      "epoch:11 step:10346 [D loss: 0.242073, acc.: 56.25%] [G loss: 0.297707]\n",
      "epoch:11 step:10347 [D loss: 0.244497, acc.: 57.81%] [G loss: 0.286284]\n",
      "epoch:11 step:10348 [D loss: 0.231545, acc.: 60.94%] [G loss: 0.279888]\n",
      "epoch:11 step:10349 [D loss: 0.250856, acc.: 49.22%] [G loss: 0.262048]\n",
      "epoch:11 step:10350 [D loss: 0.244930, acc.: 56.25%] [G loss: 0.282398]\n",
      "epoch:11 step:10351 [D loss: 0.242146, acc.: 56.25%] [G loss: 0.277830]\n",
      "epoch:11 step:10352 [D loss: 0.263420, acc.: 51.56%] [G loss: 0.299354]\n",
      "epoch:11 step:10353 [D loss: 0.244190, acc.: 56.25%] [G loss: 0.273474]\n",
      "epoch:11 step:10354 [D loss: 0.236876, acc.: 60.16%] [G loss: 0.296910]\n",
      "epoch:11 step:10355 [D loss: 0.235957, acc.: 62.50%] [G loss: 0.294108]\n",
      "epoch:11 step:10356 [D loss: 0.235935, acc.: 60.94%] [G loss: 0.319361]\n",
      "epoch:11 step:10357 [D loss: 0.229800, acc.: 61.72%] [G loss: 0.300150]\n",
      "epoch:11 step:10358 [D loss: 0.227145, acc.: 63.28%] [G loss: 0.296297]\n",
      "epoch:11 step:10359 [D loss: 0.246318, acc.: 55.47%] [G loss: 0.287091]\n",
      "epoch:11 step:10360 [D loss: 0.220598, acc.: 64.84%] [G loss: 0.316318]\n",
      "epoch:11 step:10361 [D loss: 0.228619, acc.: 60.94%] [G loss: 0.307527]\n",
      "epoch:11 step:10362 [D loss: 0.260635, acc.: 52.34%] [G loss: 0.267073]\n",
      "epoch:11 step:10363 [D loss: 0.234293, acc.: 59.38%] [G loss: 0.330104]\n",
      "epoch:11 step:10364 [D loss: 0.244938, acc.: 59.38%] [G loss: 0.321834]\n",
      "epoch:11 step:10365 [D loss: 0.247683, acc.: 57.03%] [G loss: 0.277120]\n",
      "epoch:11 step:10366 [D loss: 0.245427, acc.: 60.16%] [G loss: 0.306537]\n",
      "epoch:11 step:10367 [D loss: 0.236823, acc.: 57.03%] [G loss: 0.280479]\n",
      "epoch:11 step:10368 [D loss: 0.244468, acc.: 49.22%] [G loss: 0.273397]\n",
      "epoch:11 step:10369 [D loss: 0.255298, acc.: 50.78%] [G loss: 0.309706]\n",
      "epoch:11 step:10370 [D loss: 0.220729, acc.: 65.62%] [G loss: 0.312929]\n",
      "epoch:11 step:10371 [D loss: 0.242494, acc.: 54.69%] [G loss: 0.305502]\n",
      "epoch:11 step:10372 [D loss: 0.234117, acc.: 56.25%] [G loss: 0.290962]\n",
      "epoch:11 step:10373 [D loss: 0.238225, acc.: 60.94%] [G loss: 0.310863]\n",
      "epoch:11 step:10374 [D loss: 0.240971, acc.: 56.25%] [G loss: 0.283797]\n",
      "epoch:11 step:10375 [D loss: 0.233519, acc.: 60.94%] [G loss: 0.304594]\n",
      "epoch:11 step:10376 [D loss: 0.228798, acc.: 63.28%] [G loss: 0.316345]\n",
      "epoch:11 step:10377 [D loss: 0.240875, acc.: 56.25%] [G loss: 0.303618]\n",
      "epoch:11 step:10378 [D loss: 0.234299, acc.: 58.59%] [G loss: 0.311083]\n",
      "epoch:11 step:10379 [D loss: 0.222671, acc.: 66.41%] [G loss: 0.313894]\n",
      "epoch:11 step:10380 [D loss: 0.249353, acc.: 57.03%] [G loss: 0.288102]\n",
      "epoch:11 step:10381 [D loss: 0.240388, acc.: 55.47%] [G loss: 0.313524]\n",
      "epoch:11 step:10382 [D loss: 0.238127, acc.: 60.94%] [G loss: 0.294521]\n",
      "epoch:11 step:10383 [D loss: 0.249736, acc.: 58.59%] [G loss: 0.286903]\n",
      "epoch:11 step:10384 [D loss: 0.242648, acc.: 53.91%] [G loss: 0.289372]\n",
      "epoch:11 step:10385 [D loss: 0.228115, acc.: 61.72%] [G loss: 0.292538]\n",
      "epoch:11 step:10386 [D loss: 0.247474, acc.: 57.81%] [G loss: 0.306758]\n",
      "epoch:11 step:10387 [D loss: 0.238400, acc.: 57.03%] [G loss: 0.291805]\n",
      "epoch:11 step:10388 [D loss: 0.233340, acc.: 61.72%] [G loss: 0.283516]\n",
      "epoch:11 step:10389 [D loss: 0.223093, acc.: 63.28%] [G loss: 0.296815]\n",
      "epoch:11 step:10390 [D loss: 0.244016, acc.: 60.94%] [G loss: 0.291117]\n",
      "epoch:11 step:10391 [D loss: 0.227218, acc.: 63.28%] [G loss: 0.333240]\n",
      "epoch:11 step:10392 [D loss: 0.229217, acc.: 67.19%] [G loss: 0.289203]\n",
      "epoch:11 step:10393 [D loss: 0.245306, acc.: 53.91%] [G loss: 0.294621]\n",
      "epoch:11 step:10394 [D loss: 0.232584, acc.: 60.16%] [G loss: 0.316658]\n",
      "epoch:11 step:10395 [D loss: 0.226575, acc.: 66.41%] [G loss: 0.296293]\n",
      "epoch:11 step:10396 [D loss: 0.231628, acc.: 57.81%] [G loss: 0.324990]\n",
      "epoch:11 step:10397 [D loss: 0.225290, acc.: 62.50%] [G loss: 0.300397]\n",
      "epoch:11 step:10398 [D loss: 0.238343, acc.: 57.81%] [G loss: 0.304864]\n",
      "epoch:11 step:10399 [D loss: 0.241485, acc.: 51.56%] [G loss: 0.301045]\n",
      "epoch:11 step:10400 [D loss: 0.229502, acc.: 57.81%] [G loss: 0.303029]\n",
      "epoch:11 step:10401 [D loss: 0.239488, acc.: 56.25%] [G loss: 0.312629]\n",
      "epoch:11 step:10402 [D loss: 0.239486, acc.: 54.69%] [G loss: 0.291781]\n",
      "epoch:11 step:10403 [D loss: 0.236569, acc.: 56.25%] [G loss: 0.283456]\n",
      "epoch:11 step:10404 [D loss: 0.250921, acc.: 53.12%] [G loss: 0.317585]\n",
      "epoch:11 step:10405 [D loss: 0.233803, acc.: 56.25%] [G loss: 0.301308]\n",
      "epoch:11 step:10406 [D loss: 0.259953, acc.: 53.91%] [G loss: 0.281730]\n",
      "epoch:11 step:10407 [D loss: 0.233456, acc.: 60.94%] [G loss: 0.300589]\n",
      "epoch:11 step:10408 [D loss: 0.232874, acc.: 58.59%] [G loss: 0.312776]\n",
      "epoch:11 step:10409 [D loss: 0.233339, acc.: 60.94%] [G loss: 0.290654]\n",
      "epoch:11 step:10410 [D loss: 0.236246, acc.: 60.16%] [G loss: 0.304706]\n",
      "epoch:11 step:10411 [D loss: 0.250217, acc.: 53.91%] [G loss: 0.303230]\n",
      "epoch:11 step:10412 [D loss: 0.243811, acc.: 56.25%] [G loss: 0.306236]\n",
      "epoch:11 step:10413 [D loss: 0.234841, acc.: 63.28%] [G loss: 0.318592]\n",
      "epoch:11 step:10414 [D loss: 0.219521, acc.: 71.09%] [G loss: 0.304930]\n",
      "epoch:11 step:10415 [D loss: 0.229857, acc.: 63.28%] [G loss: 0.324408]\n",
      "epoch:11 step:10416 [D loss: 0.223899, acc.: 68.75%] [G loss: 0.291455]\n",
      "epoch:11 step:10417 [D loss: 0.249792, acc.: 57.81%] [G loss: 0.291333]\n",
      "epoch:11 step:10418 [D loss: 0.248028, acc.: 60.16%] [G loss: 0.315656]\n",
      "epoch:11 step:10419 [D loss: 0.234849, acc.: 58.59%] [G loss: 0.277479]\n",
      "epoch:11 step:10420 [D loss: 0.249371, acc.: 50.78%] [G loss: 0.309032]\n",
      "epoch:11 step:10421 [D loss: 0.225566, acc.: 64.06%] [G loss: 0.291708]\n",
      "epoch:11 step:10422 [D loss: 0.232580, acc.: 63.28%] [G loss: 0.309200]\n",
      "epoch:11 step:10423 [D loss: 0.234626, acc.: 57.81%] [G loss: 0.316872]\n",
      "epoch:11 step:10424 [D loss: 0.238723, acc.: 56.25%] [G loss: 0.304814]\n",
      "epoch:11 step:10425 [D loss: 0.256201, acc.: 55.47%] [G loss: 0.309086]\n",
      "epoch:11 step:10426 [D loss: 0.249264, acc.: 52.34%] [G loss: 0.307709]\n",
      "epoch:11 step:10427 [D loss: 0.274817, acc.: 46.88%] [G loss: 0.284098]\n",
      "epoch:11 step:10428 [D loss: 0.250497, acc.: 51.56%] [G loss: 0.275001]\n",
      "epoch:11 step:10429 [D loss: 0.243096, acc.: 57.03%] [G loss: 0.293366]\n",
      "epoch:11 step:10430 [D loss: 0.238991, acc.: 59.38%] [G loss: 0.295533]\n",
      "epoch:11 step:10431 [D loss: 0.253874, acc.: 49.22%] [G loss: 0.260368]\n",
      "epoch:11 step:10432 [D loss: 0.248271, acc.: 56.25%] [G loss: 0.288423]\n",
      "epoch:11 step:10433 [D loss: 0.239250, acc.: 58.59%] [G loss: 0.300538]\n",
      "epoch:11 step:10434 [D loss: 0.256035, acc.: 55.47%] [G loss: 0.284855]\n",
      "epoch:11 step:10435 [D loss: 0.235842, acc.: 59.38%] [G loss: 0.304071]\n",
      "epoch:11 step:10436 [D loss: 0.240897, acc.: 58.59%] [G loss: 0.303937]\n",
      "epoch:11 step:10437 [D loss: 0.236192, acc.: 57.03%] [G loss: 0.298368]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:11 step:10438 [D loss: 0.239174, acc.: 57.03%] [G loss: 0.316442]\n",
      "epoch:11 step:10439 [D loss: 0.244830, acc.: 51.56%] [G loss: 0.302177]\n",
      "epoch:11 step:10440 [D loss: 0.233704, acc.: 60.94%] [G loss: 0.303702]\n",
      "epoch:11 step:10441 [D loss: 0.240414, acc.: 54.69%] [G loss: 0.272653]\n",
      "epoch:11 step:10442 [D loss: 0.235718, acc.: 60.16%] [G loss: 0.307029]\n",
      "epoch:11 step:10443 [D loss: 0.242359, acc.: 58.59%] [G loss: 0.301497]\n",
      "epoch:11 step:10444 [D loss: 0.233759, acc.: 60.16%] [G loss: 0.284723]\n",
      "epoch:11 step:10445 [D loss: 0.221682, acc.: 65.62%] [G loss: 0.293436]\n",
      "epoch:11 step:10446 [D loss: 0.235536, acc.: 60.16%] [G loss: 0.319873]\n",
      "epoch:11 step:10447 [D loss: 0.250699, acc.: 56.25%] [G loss: 0.289312]\n",
      "epoch:11 step:10448 [D loss: 0.233443, acc.: 56.25%] [G loss: 0.301548]\n",
      "epoch:11 step:10449 [D loss: 0.222101, acc.: 64.84%] [G loss: 0.310643]\n",
      "epoch:11 step:10450 [D loss: 0.247298, acc.: 57.03%] [G loss: 0.277430]\n",
      "epoch:11 step:10451 [D loss: 0.243728, acc.: 57.81%] [G loss: 0.296487]\n",
      "epoch:11 step:10452 [D loss: 0.236173, acc.: 58.59%] [G loss: 0.270862]\n",
      "epoch:11 step:10453 [D loss: 0.244470, acc.: 57.03%] [G loss: 0.290589]\n",
      "epoch:11 step:10454 [D loss: 0.239921, acc.: 55.47%] [G loss: 0.300307]\n",
      "epoch:11 step:10455 [D loss: 0.249943, acc.: 53.91%] [G loss: 0.278058]\n",
      "epoch:11 step:10456 [D loss: 0.230887, acc.: 60.16%] [G loss: 0.316268]\n",
      "epoch:11 step:10457 [D loss: 0.258356, acc.: 53.12%] [G loss: 0.273700]\n",
      "epoch:11 step:10458 [D loss: 0.238135, acc.: 60.16%] [G loss: 0.287191]\n",
      "epoch:11 step:10459 [D loss: 0.246994, acc.: 54.69%] [G loss: 0.300940]\n",
      "epoch:11 step:10460 [D loss: 0.240267, acc.: 62.50%] [G loss: 0.297206]\n",
      "epoch:11 step:10461 [D loss: 0.235203, acc.: 62.50%] [G loss: 0.277740]\n",
      "epoch:11 step:10462 [D loss: 0.251405, acc.: 50.00%] [G loss: 0.298562]\n",
      "epoch:11 step:10463 [D loss: 0.239699, acc.: 53.91%] [G loss: 0.286932]\n",
      "epoch:11 step:10464 [D loss: 0.252759, acc.: 50.78%] [G loss: 0.269935]\n",
      "epoch:11 step:10465 [D loss: 0.224393, acc.: 65.62%] [G loss: 0.301928]\n",
      "epoch:11 step:10466 [D loss: 0.233968, acc.: 61.72%] [G loss: 0.302066]\n",
      "epoch:11 step:10467 [D loss: 0.230161, acc.: 65.62%] [G loss: 0.310017]\n",
      "epoch:11 step:10468 [D loss: 0.223194, acc.: 69.53%] [G loss: 0.287647]\n",
      "epoch:11 step:10469 [D loss: 0.230423, acc.: 53.91%] [G loss: 0.305254]\n",
      "epoch:11 step:10470 [D loss: 0.256238, acc.: 47.66%] [G loss: 0.276690]\n",
      "epoch:11 step:10471 [D loss: 0.227012, acc.: 62.50%] [G loss: 0.292429]\n",
      "epoch:11 step:10472 [D loss: 0.245826, acc.: 57.81%] [G loss: 0.310763]\n",
      "epoch:11 step:10473 [D loss: 0.241144, acc.: 58.59%] [G loss: 0.304579]\n",
      "epoch:11 step:10474 [D loss: 0.225008, acc.: 63.28%] [G loss: 0.293865]\n",
      "epoch:11 step:10475 [D loss: 0.252450, acc.: 53.12%] [G loss: 0.294200]\n",
      "epoch:11 step:10476 [D loss: 0.251934, acc.: 50.78%] [G loss: 0.290991]\n",
      "epoch:11 step:10477 [D loss: 0.231659, acc.: 65.62%] [G loss: 0.321375]\n",
      "epoch:11 step:10478 [D loss: 0.247432, acc.: 56.25%] [G loss: 0.313766]\n",
      "epoch:11 step:10479 [D loss: 0.214789, acc.: 70.31%] [G loss: 0.310344]\n",
      "epoch:11 step:10480 [D loss: 0.238365, acc.: 60.94%] [G loss: 0.314578]\n",
      "epoch:11 step:10481 [D loss: 0.240020, acc.: 57.03%] [G loss: 0.316855]\n",
      "epoch:11 step:10482 [D loss: 0.243314, acc.: 56.25%] [G loss: 0.310312]\n",
      "epoch:11 step:10483 [D loss: 0.236921, acc.: 57.03%] [G loss: 0.317493]\n",
      "epoch:11 step:10484 [D loss: 0.233276, acc.: 57.03%] [G loss: 0.287639]\n",
      "epoch:11 step:10485 [D loss: 0.263252, acc.: 50.00%] [G loss: 0.294238]\n",
      "epoch:11 step:10486 [D loss: 0.240550, acc.: 63.28%] [G loss: 0.291013]\n",
      "epoch:11 step:10487 [D loss: 0.252108, acc.: 52.34%] [G loss: 0.307923]\n",
      "epoch:11 step:10488 [D loss: 0.252614, acc.: 57.81%] [G loss: 0.303401]\n",
      "epoch:11 step:10489 [D loss: 0.240105, acc.: 55.47%] [G loss: 0.320005]\n",
      "epoch:11 step:10490 [D loss: 0.235204, acc.: 58.59%] [G loss: 0.314737]\n",
      "epoch:11 step:10491 [D loss: 0.235655, acc.: 61.72%] [G loss: 0.310647]\n",
      "epoch:11 step:10492 [D loss: 0.237126, acc.: 57.03%] [G loss: 0.289305]\n",
      "epoch:11 step:10493 [D loss: 0.236647, acc.: 60.16%] [G loss: 0.261944]\n",
      "epoch:11 step:10494 [D loss: 0.234717, acc.: 63.28%] [G loss: 0.300946]\n",
      "epoch:11 step:10495 [D loss: 0.228774, acc.: 64.06%] [G loss: 0.320369]\n",
      "epoch:11 step:10496 [D loss: 0.224559, acc.: 58.59%] [G loss: 0.317145]\n",
      "epoch:11 step:10497 [D loss: 0.253539, acc.: 48.44%] [G loss: 0.285990]\n",
      "epoch:11 step:10498 [D loss: 0.250524, acc.: 56.25%] [G loss: 0.298986]\n",
      "epoch:11 step:10499 [D loss: 0.245755, acc.: 59.38%] [G loss: 0.298506]\n",
      "epoch:11 step:10500 [D loss: 0.248070, acc.: 55.47%] [G loss: 0.288544]\n",
      "epoch:11 step:10501 [D loss: 0.243714, acc.: 57.81%] [G loss: 0.294678]\n",
      "epoch:11 step:10502 [D loss: 0.237829, acc.: 55.47%] [G loss: 0.294412]\n",
      "epoch:11 step:10503 [D loss: 0.256072, acc.: 54.69%] [G loss: 0.309799]\n",
      "epoch:11 step:10504 [D loss: 0.237964, acc.: 53.91%] [G loss: 0.285511]\n",
      "epoch:11 step:10505 [D loss: 0.261450, acc.: 50.00%] [G loss: 0.295401]\n",
      "epoch:11 step:10506 [D loss: 0.237469, acc.: 55.47%] [G loss: 0.285121]\n",
      "epoch:11 step:10507 [D loss: 0.239995, acc.: 63.28%] [G loss: 0.299837]\n",
      "epoch:11 step:10508 [D loss: 0.239517, acc.: 60.94%] [G loss: 0.266440]\n",
      "epoch:11 step:10509 [D loss: 0.241751, acc.: 53.91%] [G loss: 0.314786]\n",
      "epoch:11 step:10510 [D loss: 0.219478, acc.: 70.31%] [G loss: 0.314615]\n",
      "epoch:11 step:10511 [D loss: 0.242725, acc.: 57.03%] [G loss: 0.272050]\n",
      "epoch:11 step:10512 [D loss: 0.258054, acc.: 53.91%] [G loss: 0.282442]\n",
      "epoch:11 step:10513 [D loss: 0.247044, acc.: 63.28%] [G loss: 0.314620]\n",
      "epoch:11 step:10514 [D loss: 0.221186, acc.: 67.97%] [G loss: 0.326663]\n",
      "epoch:11 step:10515 [D loss: 0.228373, acc.: 64.06%] [G loss: 0.310623]\n",
      "epoch:11 step:10516 [D loss: 0.245045, acc.: 52.34%] [G loss: 0.308074]\n",
      "epoch:11 step:10517 [D loss: 0.220693, acc.: 64.06%] [G loss: 0.300312]\n",
      "epoch:11 step:10518 [D loss: 0.253929, acc.: 56.25%] [G loss: 0.304599]\n",
      "epoch:11 step:10519 [D loss: 0.254560, acc.: 57.03%] [G loss: 0.317582]\n",
      "epoch:11 step:10520 [D loss: 0.239794, acc.: 60.94%] [G loss: 0.303354]\n",
      "epoch:11 step:10521 [D loss: 0.256966, acc.: 53.91%] [G loss: 0.306208]\n",
      "epoch:11 step:10522 [D loss: 0.237399, acc.: 62.50%] [G loss: 0.290568]\n",
      "epoch:11 step:10523 [D loss: 0.249069, acc.: 53.12%] [G loss: 0.272066]\n",
      "epoch:11 step:10524 [D loss: 0.234719, acc.: 64.84%] [G loss: 0.276701]\n",
      "epoch:11 step:10525 [D loss: 0.249747, acc.: 54.69%] [G loss: 0.279326]\n",
      "epoch:11 step:10526 [D loss: 0.243276, acc.: 55.47%] [G loss: 0.292009]\n",
      "epoch:11 step:10527 [D loss: 0.238570, acc.: 59.38%] [G loss: 0.325819]\n",
      "epoch:11 step:10528 [D loss: 0.255116, acc.: 51.56%] [G loss: 0.280866]\n",
      "epoch:11 step:10529 [D loss: 0.249612, acc.: 53.91%] [G loss: 0.280178]\n",
      "epoch:11 step:10530 [D loss: 0.225993, acc.: 58.59%] [G loss: 0.310990]\n",
      "epoch:11 step:10531 [D loss: 0.240022, acc.: 57.03%] [G loss: 0.289890]\n",
      "epoch:11 step:10532 [D loss: 0.238650, acc.: 60.94%] [G loss: 0.295090]\n",
      "epoch:11 step:10533 [D loss: 0.245939, acc.: 54.69%] [G loss: 0.280758]\n",
      "epoch:11 step:10534 [D loss: 0.234504, acc.: 62.50%] [G loss: 0.294092]\n",
      "epoch:11 step:10535 [D loss: 0.236954, acc.: 60.16%] [G loss: 0.290037]\n",
      "epoch:11 step:10536 [D loss: 0.236693, acc.: 59.38%] [G loss: 0.305659]\n",
      "epoch:11 step:10537 [D loss: 0.235321, acc.: 61.72%] [G loss: 0.301471]\n",
      "epoch:11 step:10538 [D loss: 0.241694, acc.: 57.81%] [G loss: 0.276878]\n",
      "epoch:11 step:10539 [D loss: 0.258992, acc.: 53.91%] [G loss: 0.281042]\n",
      "epoch:11 step:10540 [D loss: 0.252530, acc.: 54.69%] [G loss: 0.308662]\n",
      "epoch:11 step:10541 [D loss: 0.262588, acc.: 47.66%] [G loss: 0.281310]\n",
      "epoch:11 step:10542 [D loss: 0.246780, acc.: 54.69%] [G loss: 0.309158]\n",
      "epoch:11 step:10543 [D loss: 0.247829, acc.: 53.12%] [G loss: 0.286578]\n",
      "epoch:11 step:10544 [D loss: 0.244183, acc.: 48.44%] [G loss: 0.287808]\n",
      "epoch:11 step:10545 [D loss: 0.247793, acc.: 53.12%] [G loss: 0.283200]\n",
      "epoch:11 step:10546 [D loss: 0.246956, acc.: 56.25%] [G loss: 0.274203]\n",
      "epoch:11 step:10547 [D loss: 0.240223, acc.: 57.81%] [G loss: 0.303156]\n",
      "epoch:11 step:10548 [D loss: 0.241887, acc.: 53.12%] [G loss: 0.292327]\n",
      "epoch:11 step:10549 [D loss: 0.255812, acc.: 52.34%] [G loss: 0.298284]\n",
      "epoch:11 step:10550 [D loss: 0.248318, acc.: 55.47%] [G loss: 0.314074]\n",
      "epoch:11 step:10551 [D loss: 0.249110, acc.: 57.03%] [G loss: 0.309800]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:11 step:10552 [D loss: 0.244753, acc.: 55.47%] [G loss: 0.303994]\n",
      "epoch:11 step:10553 [D loss: 0.256405, acc.: 51.56%] [G loss: 0.282616]\n",
      "epoch:11 step:10554 [D loss: 0.234023, acc.: 61.72%] [G loss: 0.300925]\n",
      "epoch:11 step:10555 [D loss: 0.246205, acc.: 53.12%] [G loss: 0.314292]\n",
      "epoch:11 step:10556 [D loss: 0.249616, acc.: 56.25%] [G loss: 0.331729]\n",
      "epoch:11 step:10557 [D loss: 0.232690, acc.: 61.72%] [G loss: 0.287365]\n",
      "epoch:11 step:10558 [D loss: 0.245401, acc.: 57.81%] [G loss: 0.289961]\n",
      "epoch:11 step:10559 [D loss: 0.239641, acc.: 60.94%] [G loss: 0.292744]\n",
      "epoch:11 step:10560 [D loss: 0.254263, acc.: 50.78%] [G loss: 0.284323]\n",
      "epoch:11 step:10561 [D loss: 0.247854, acc.: 58.59%] [G loss: 0.287641]\n",
      "epoch:11 step:10562 [D loss: 0.225711, acc.: 60.16%] [G loss: 0.291795]\n",
      "epoch:11 step:10563 [D loss: 0.237363, acc.: 59.38%] [G loss: 0.290358]\n",
      "epoch:11 step:10564 [D loss: 0.239514, acc.: 53.91%] [G loss: 0.267385]\n",
      "epoch:11 step:10565 [D loss: 0.251944, acc.: 51.56%] [G loss: 0.285447]\n",
      "epoch:11 step:10566 [D loss: 0.244365, acc.: 53.91%] [G loss: 0.285582]\n",
      "epoch:11 step:10567 [D loss: 0.241550, acc.: 57.81%] [G loss: 0.295423]\n",
      "epoch:11 step:10568 [D loss: 0.240678, acc.: 53.12%] [G loss: 0.296700]\n",
      "epoch:11 step:10569 [D loss: 0.260840, acc.: 53.91%] [G loss: 0.301145]\n",
      "epoch:11 step:10570 [D loss: 0.238023, acc.: 63.28%] [G loss: 0.330907]\n",
      "epoch:11 step:10571 [D loss: 0.224529, acc.: 65.62%] [G loss: 0.308275]\n",
      "epoch:11 step:10572 [D loss: 0.236725, acc.: 57.03%] [G loss: 0.305496]\n",
      "epoch:11 step:10573 [D loss: 0.235934, acc.: 60.94%] [G loss: 0.293472]\n",
      "epoch:11 step:10574 [D loss: 0.234822, acc.: 59.38%] [G loss: 0.303763]\n",
      "epoch:11 step:10575 [D loss: 0.232612, acc.: 59.38%] [G loss: 0.297113]\n",
      "epoch:11 step:10576 [D loss: 0.230498, acc.: 63.28%] [G loss: 0.283977]\n",
      "epoch:11 step:10577 [D loss: 0.234278, acc.: 54.69%] [G loss: 0.305923]\n",
      "epoch:11 step:10578 [D loss: 0.235983, acc.: 64.06%] [G loss: 0.285232]\n",
      "epoch:11 step:10579 [D loss: 0.237125, acc.: 61.72%] [G loss: 0.287349]\n",
      "epoch:11 step:10580 [D loss: 0.224396, acc.: 64.84%] [G loss: 0.307898]\n",
      "epoch:11 step:10581 [D loss: 0.224682, acc.: 63.28%] [G loss: 0.327057]\n",
      "epoch:11 step:10582 [D loss: 0.250139, acc.: 54.69%] [G loss: 0.294727]\n",
      "epoch:11 step:10583 [D loss: 0.257131, acc.: 49.22%] [G loss: 0.291467]\n",
      "epoch:11 step:10584 [D loss: 0.237758, acc.: 56.25%] [G loss: 0.285636]\n",
      "epoch:11 step:10585 [D loss: 0.255483, acc.: 48.44%] [G loss: 0.299578]\n",
      "epoch:11 step:10586 [D loss: 0.242775, acc.: 56.25%] [G loss: 0.279715]\n",
      "epoch:11 step:10587 [D loss: 0.243857, acc.: 50.78%] [G loss: 0.279534]\n",
      "epoch:11 step:10588 [D loss: 0.241167, acc.: 58.59%] [G loss: 0.276667]\n",
      "epoch:11 step:10589 [D loss: 0.245020, acc.: 58.59%] [G loss: 0.281076]\n",
      "epoch:11 step:10590 [D loss: 0.254006, acc.: 48.44%] [G loss: 0.274561]\n",
      "epoch:11 step:10591 [D loss: 0.250087, acc.: 50.78%] [G loss: 0.283872]\n",
      "epoch:11 step:10592 [D loss: 0.238167, acc.: 56.25%] [G loss: 0.313024]\n",
      "epoch:11 step:10593 [D loss: 0.246730, acc.: 54.69%] [G loss: 0.309429]\n",
      "epoch:11 step:10594 [D loss: 0.243236, acc.: 58.59%] [G loss: 0.317788]\n",
      "epoch:11 step:10595 [D loss: 0.237478, acc.: 61.72%] [G loss: 0.286534]\n",
      "epoch:11 step:10596 [D loss: 0.252790, acc.: 52.34%] [G loss: 0.306332]\n",
      "epoch:11 step:10597 [D loss: 0.247693, acc.: 54.69%] [G loss: 0.296118]\n",
      "epoch:11 step:10598 [D loss: 0.251021, acc.: 51.56%] [G loss: 0.303977]\n",
      "epoch:11 step:10599 [D loss: 0.232291, acc.: 60.94%] [G loss: 0.308533]\n",
      "epoch:11 step:10600 [D loss: 0.234286, acc.: 59.38%] [G loss: 0.322679]\n",
      "epoch:11 step:10601 [D loss: 0.228279, acc.: 64.84%] [G loss: 0.308310]\n",
      "epoch:11 step:10602 [D loss: 0.247589, acc.: 53.91%] [G loss: 0.285787]\n",
      "epoch:11 step:10603 [D loss: 0.220466, acc.: 61.72%] [G loss: 0.293410]\n",
      "epoch:11 step:10604 [D loss: 0.242824, acc.: 54.69%] [G loss: 0.297749]\n",
      "epoch:11 step:10605 [D loss: 0.247995, acc.: 54.69%] [G loss: 0.298335]\n",
      "epoch:11 step:10606 [D loss: 0.241960, acc.: 56.25%] [G loss: 0.302890]\n",
      "epoch:11 step:10607 [D loss: 0.247728, acc.: 55.47%] [G loss: 0.294837]\n",
      "epoch:11 step:10608 [D loss: 0.251671, acc.: 50.78%] [G loss: 0.310937]\n",
      "epoch:11 step:10609 [D loss: 0.250849, acc.: 53.91%] [G loss: 0.288902]\n",
      "epoch:11 step:10610 [D loss: 0.241373, acc.: 55.47%] [G loss: 0.307482]\n",
      "epoch:11 step:10611 [D loss: 0.226217, acc.: 61.72%] [G loss: 0.309177]\n",
      "epoch:11 step:10612 [D loss: 0.232044, acc.: 61.72%] [G loss: 0.312195]\n",
      "epoch:11 step:10613 [D loss: 0.240349, acc.: 57.03%] [G loss: 0.275773]\n",
      "epoch:11 step:10614 [D loss: 0.258418, acc.: 49.22%] [G loss: 0.258187]\n",
      "epoch:11 step:10615 [D loss: 0.237384, acc.: 58.59%] [G loss: 0.310826]\n",
      "epoch:11 step:10616 [D loss: 0.223513, acc.: 62.50%] [G loss: 0.290415]\n",
      "epoch:11 step:10617 [D loss: 0.247447, acc.: 57.03%] [G loss: 0.313547]\n",
      "epoch:11 step:10618 [D loss: 0.253130, acc.: 51.56%] [G loss: 0.268774]\n",
      "epoch:11 step:10619 [D loss: 0.252963, acc.: 49.22%] [G loss: 0.329158]\n",
      "epoch:11 step:10620 [D loss: 0.235525, acc.: 64.06%] [G loss: 0.303569]\n",
      "epoch:11 step:10621 [D loss: 0.233173, acc.: 61.72%] [G loss: 0.306356]\n",
      "epoch:11 step:10622 [D loss: 0.245738, acc.: 56.25%] [G loss: 0.316303]\n",
      "epoch:11 step:10623 [D loss: 0.245754, acc.: 55.47%] [G loss: 0.291785]\n",
      "epoch:11 step:10624 [D loss: 0.227953, acc.: 63.28%] [G loss: 0.324795]\n",
      "epoch:11 step:10625 [D loss: 0.242706, acc.: 55.47%] [G loss: 0.283383]\n",
      "epoch:11 step:10626 [D loss: 0.238759, acc.: 57.03%] [G loss: 0.291728]\n",
      "epoch:11 step:10627 [D loss: 0.247826, acc.: 55.47%] [G loss: 0.285047]\n",
      "epoch:11 step:10628 [D loss: 0.257594, acc.: 54.69%] [G loss: 0.304139]\n",
      "epoch:11 step:10629 [D loss: 0.260338, acc.: 52.34%] [G loss: 0.285788]\n",
      "epoch:11 step:10630 [D loss: 0.244892, acc.: 54.69%] [G loss: 0.286201]\n",
      "epoch:11 step:10631 [D loss: 0.245402, acc.: 53.91%] [G loss: 0.282041]\n",
      "epoch:11 step:10632 [D loss: 0.240026, acc.: 60.16%] [G loss: 0.284538]\n",
      "epoch:11 step:10633 [D loss: 0.243027, acc.: 57.81%] [G loss: 0.331391]\n",
      "epoch:11 step:10634 [D loss: 0.239018, acc.: 56.25%] [G loss: 0.292810]\n",
      "epoch:11 step:10635 [D loss: 0.229443, acc.: 60.94%] [G loss: 0.278517]\n",
      "epoch:11 step:10636 [D loss: 0.219648, acc.: 65.62%] [G loss: 0.282325]\n",
      "epoch:11 step:10637 [D loss: 0.240597, acc.: 53.91%] [G loss: 0.294432]\n",
      "epoch:11 step:10638 [D loss: 0.227219, acc.: 58.59%] [G loss: 0.296996]\n",
      "epoch:11 step:10639 [D loss: 0.220741, acc.: 64.84%] [G loss: 0.293507]\n",
      "epoch:11 step:10640 [D loss: 0.259979, acc.: 49.22%] [G loss: 0.287349]\n",
      "epoch:11 step:10641 [D loss: 0.229197, acc.: 65.62%] [G loss: 0.303472]\n",
      "epoch:11 step:10642 [D loss: 0.233003, acc.: 60.16%] [G loss: 0.301895]\n",
      "epoch:11 step:10643 [D loss: 0.237395, acc.: 60.94%] [G loss: 0.292656]\n",
      "epoch:11 step:10644 [D loss: 0.254834, acc.: 53.91%] [G loss: 0.293258]\n",
      "epoch:11 step:10645 [D loss: 0.236009, acc.: 62.50%] [G loss: 0.286750]\n",
      "epoch:11 step:10646 [D loss: 0.234317, acc.: 58.59%] [G loss: 0.309685]\n",
      "epoch:11 step:10647 [D loss: 0.228001, acc.: 64.84%] [G loss: 0.279307]\n",
      "epoch:11 step:10648 [D loss: 0.239544, acc.: 59.38%] [G loss: 0.297279]\n",
      "epoch:11 step:10649 [D loss: 0.234697, acc.: 60.16%] [G loss: 0.300821]\n",
      "epoch:11 step:10650 [D loss: 0.242993, acc.: 55.47%] [G loss: 0.316289]\n",
      "epoch:11 step:10651 [D loss: 0.250553, acc.: 53.91%] [G loss: 0.266173]\n",
      "epoch:11 step:10652 [D loss: 0.230571, acc.: 62.50%] [G loss: 0.316323]\n",
      "epoch:11 step:10653 [D loss: 0.246683, acc.: 56.25%] [G loss: 0.297109]\n",
      "epoch:11 step:10654 [D loss: 0.241722, acc.: 58.59%] [G loss: 0.296572]\n",
      "epoch:11 step:10655 [D loss: 0.254153, acc.: 56.25%] [G loss: 0.288441]\n",
      "epoch:11 step:10656 [D loss: 0.226336, acc.: 61.72%] [G loss: 0.315827]\n",
      "epoch:11 step:10657 [D loss: 0.253359, acc.: 53.12%] [G loss: 0.294067]\n",
      "epoch:11 step:10658 [D loss: 0.232665, acc.: 64.06%] [G loss: 0.309134]\n",
      "epoch:11 step:10659 [D loss: 0.234863, acc.: 60.94%] [G loss: 0.300169]\n",
      "epoch:11 step:10660 [D loss: 0.219884, acc.: 71.09%] [G loss: 0.308307]\n",
      "epoch:11 step:10661 [D loss: 0.238306, acc.: 58.59%] [G loss: 0.298958]\n",
      "epoch:11 step:10662 [D loss: 0.232147, acc.: 60.94%] [G loss: 0.300116]\n",
      "epoch:11 step:10663 [D loss: 0.227006, acc.: 66.41%] [G loss: 0.280154]\n",
      "epoch:11 step:10664 [D loss: 0.245156, acc.: 60.94%] [G loss: 0.312871]\n",
      "epoch:11 step:10665 [D loss: 0.228799, acc.: 58.59%] [G loss: 0.287872]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:11 step:10666 [D loss: 0.256326, acc.: 55.47%] [G loss: 0.256578]\n",
      "epoch:11 step:10667 [D loss: 0.236193, acc.: 57.81%] [G loss: 0.279833]\n",
      "epoch:11 step:10668 [D loss: 0.254755, acc.: 54.69%] [G loss: 0.274746]\n",
      "epoch:11 step:10669 [D loss: 0.249255, acc.: 54.69%] [G loss: 0.283961]\n",
      "epoch:11 step:10670 [D loss: 0.255914, acc.: 51.56%] [G loss: 0.292453]\n",
      "epoch:11 step:10671 [D loss: 0.246441, acc.: 54.69%] [G loss: 0.316468]\n",
      "epoch:11 step:10672 [D loss: 0.248710, acc.: 50.78%] [G loss: 0.308788]\n",
      "epoch:11 step:10673 [D loss: 0.228623, acc.: 65.62%] [G loss: 0.299177]\n",
      "epoch:11 step:10674 [D loss: 0.235303, acc.: 55.47%] [G loss: 0.307575]\n",
      "epoch:11 step:10675 [D loss: 0.238229, acc.: 58.59%] [G loss: 0.315494]\n",
      "epoch:11 step:10676 [D loss: 0.223826, acc.: 64.84%] [G loss: 0.298464]\n",
      "epoch:11 step:10677 [D loss: 0.243896, acc.: 54.69%] [G loss: 0.311061]\n",
      "epoch:11 step:10678 [D loss: 0.240246, acc.: 57.03%] [G loss: 0.290715]\n",
      "epoch:11 step:10679 [D loss: 0.245238, acc.: 56.25%] [G loss: 0.301343]\n",
      "epoch:11 step:10680 [D loss: 0.254603, acc.: 49.22%] [G loss: 0.266897]\n",
      "epoch:11 step:10681 [D loss: 0.250883, acc.: 54.69%] [G loss: 0.299388]\n",
      "epoch:11 step:10682 [D loss: 0.260967, acc.: 48.44%] [G loss: 0.314225]\n",
      "epoch:11 step:10683 [D loss: 0.270244, acc.: 46.88%] [G loss: 0.267473]\n",
      "epoch:11 step:10684 [D loss: 0.248956, acc.: 53.12%] [G loss: 0.277272]\n",
      "epoch:11 step:10685 [D loss: 0.261050, acc.: 46.88%] [G loss: 0.294565]\n",
      "epoch:11 step:10686 [D loss: 0.253795, acc.: 48.44%] [G loss: 0.289812]\n",
      "epoch:11 step:10687 [D loss: 0.243190, acc.: 54.69%] [G loss: 0.273127]\n",
      "epoch:11 step:10688 [D loss: 0.241423, acc.: 53.12%] [G loss: 0.317235]\n",
      "epoch:11 step:10689 [D loss: 0.227775, acc.: 60.16%] [G loss: 0.278788]\n",
      "epoch:11 step:10690 [D loss: 0.227537, acc.: 60.94%] [G loss: 0.295955]\n",
      "epoch:11 step:10691 [D loss: 0.241734, acc.: 54.69%] [G loss: 0.307185]\n",
      "epoch:11 step:10692 [D loss: 0.232562, acc.: 64.06%] [G loss: 0.316134]\n",
      "epoch:11 step:10693 [D loss: 0.235085, acc.: 58.59%] [G loss: 0.301750]\n",
      "epoch:11 step:10694 [D loss: 0.232085, acc.: 63.28%] [G loss: 0.315020]\n",
      "epoch:11 step:10695 [D loss: 0.258197, acc.: 50.00%] [G loss: 0.279957]\n",
      "epoch:11 step:10696 [D loss: 0.241996, acc.: 59.38%] [G loss: 0.318451]\n",
      "epoch:11 step:10697 [D loss: 0.238203, acc.: 57.81%] [G loss: 0.272372]\n",
      "epoch:11 step:10698 [D loss: 0.249918, acc.: 50.00%] [G loss: 0.297258]\n",
      "epoch:11 step:10699 [D loss: 0.235612, acc.: 55.47%] [G loss: 0.318362]\n",
      "epoch:11 step:10700 [D loss: 0.246132, acc.: 51.56%] [G loss: 0.333429]\n",
      "epoch:11 step:10701 [D loss: 0.226958, acc.: 67.19%] [G loss: 0.292377]\n",
      "epoch:11 step:10702 [D loss: 0.240728, acc.: 58.59%] [G loss: 0.308778]\n",
      "epoch:11 step:10703 [D loss: 0.236998, acc.: 57.81%] [G loss: 0.313091]\n",
      "epoch:11 step:10704 [D loss: 0.250284, acc.: 55.47%] [G loss: 0.299958]\n",
      "epoch:11 step:10705 [D loss: 0.233364, acc.: 57.81%] [G loss: 0.269031]\n",
      "epoch:11 step:10706 [D loss: 0.226796, acc.: 64.06%] [G loss: 0.301843]\n",
      "epoch:11 step:10707 [D loss: 0.220439, acc.: 64.06%] [G loss: 0.334799]\n",
      "epoch:11 step:10708 [D loss: 0.246207, acc.: 54.69%] [G loss: 0.279550]\n",
      "epoch:11 step:10709 [D loss: 0.225686, acc.: 65.62%] [G loss: 0.315431]\n",
      "epoch:11 step:10710 [D loss: 0.253683, acc.: 54.69%] [G loss: 0.328219]\n",
      "epoch:11 step:10711 [D loss: 0.240774, acc.: 53.91%] [G loss: 0.305173]\n",
      "epoch:11 step:10712 [D loss: 0.240313, acc.: 54.69%] [G loss: 0.284840]\n",
      "epoch:11 step:10713 [D loss: 0.236420, acc.: 59.38%] [G loss: 0.286503]\n",
      "epoch:11 step:10714 [D loss: 0.246723, acc.: 58.59%] [G loss: 0.331617]\n",
      "epoch:11 step:10715 [D loss: 0.236569, acc.: 57.81%] [G loss: 0.299586]\n",
      "epoch:11 step:10716 [D loss: 0.244809, acc.: 53.12%] [G loss: 0.300345]\n",
      "epoch:11 step:10717 [D loss: 0.246494, acc.: 60.16%] [G loss: 0.311358]\n",
      "epoch:11 step:10718 [D loss: 0.233014, acc.: 60.16%] [G loss: 0.285692]\n",
      "epoch:11 step:10719 [D loss: 0.224326, acc.: 64.06%] [G loss: 0.300714]\n",
      "epoch:11 step:10720 [D loss: 0.256551, acc.: 54.69%] [G loss: 0.306660]\n",
      "epoch:11 step:10721 [D loss: 0.235791, acc.: 63.28%] [G loss: 0.305939]\n",
      "epoch:11 step:10722 [D loss: 0.244441, acc.: 58.59%] [G loss: 0.282369]\n",
      "epoch:11 step:10723 [D loss: 0.234473, acc.: 58.59%] [G loss: 0.282316]\n",
      "epoch:11 step:10724 [D loss: 0.250587, acc.: 52.34%] [G loss: 0.314113]\n",
      "epoch:11 step:10725 [D loss: 0.262834, acc.: 51.56%] [G loss: 0.288350]\n",
      "epoch:11 step:10726 [D loss: 0.239610, acc.: 61.72%] [G loss: 0.318146]\n",
      "epoch:11 step:10727 [D loss: 0.237436, acc.: 54.69%] [G loss: 0.277249]\n",
      "epoch:11 step:10728 [D loss: 0.230092, acc.: 60.94%] [G loss: 0.296913]\n",
      "epoch:11 step:10729 [D loss: 0.228871, acc.: 57.03%] [G loss: 0.301646]\n",
      "epoch:11 step:10730 [D loss: 0.244300, acc.: 57.03%] [G loss: 0.289373]\n",
      "epoch:11 step:10731 [D loss: 0.238468, acc.: 64.84%] [G loss: 0.286187]\n",
      "epoch:11 step:10732 [D loss: 0.245723, acc.: 56.25%] [G loss: 0.305400]\n",
      "epoch:11 step:10733 [D loss: 0.242856, acc.: 58.59%] [G loss: 0.311876]\n",
      "epoch:11 step:10734 [D loss: 0.244374, acc.: 54.69%] [G loss: 0.317816]\n",
      "epoch:11 step:10735 [D loss: 0.245430, acc.: 57.81%] [G loss: 0.304248]\n",
      "epoch:11 step:10736 [D loss: 0.226261, acc.: 58.59%] [G loss: 0.286690]\n",
      "epoch:11 step:10737 [D loss: 0.248028, acc.: 53.91%] [G loss: 0.288357]\n",
      "epoch:11 step:10738 [D loss: 0.231385, acc.: 65.62%] [G loss: 0.293629]\n",
      "epoch:11 step:10739 [D loss: 0.238989, acc.: 55.47%] [G loss: 0.293746]\n",
      "epoch:11 step:10740 [D loss: 0.234535, acc.: 60.94%] [G loss: 0.302512]\n",
      "epoch:11 step:10741 [D loss: 0.245295, acc.: 56.25%] [G loss: 0.313866]\n",
      "epoch:11 step:10742 [D loss: 0.233190, acc.: 64.84%] [G loss: 0.298977]\n",
      "epoch:11 step:10743 [D loss: 0.245173, acc.: 55.47%] [G loss: 0.280909]\n",
      "epoch:11 step:10744 [D loss: 0.236412, acc.: 60.94%] [G loss: 0.309286]\n",
      "epoch:11 step:10745 [D loss: 0.232885, acc.: 62.50%] [G loss: 0.306482]\n",
      "epoch:11 step:10746 [D loss: 0.255663, acc.: 51.56%] [G loss: 0.273746]\n",
      "epoch:11 step:10747 [D loss: 0.220122, acc.: 67.97%] [G loss: 0.287815]\n",
      "epoch:11 step:10748 [D loss: 0.238779, acc.: 55.47%] [G loss: 0.292374]\n",
      "epoch:11 step:10749 [D loss: 0.250698, acc.: 54.69%] [G loss: 0.295115]\n",
      "epoch:11 step:10750 [D loss: 0.249359, acc.: 53.91%] [G loss: 0.304450]\n",
      "epoch:11 step:10751 [D loss: 0.227729, acc.: 64.06%] [G loss: 0.309820]\n",
      "epoch:11 step:10752 [D loss: 0.240841, acc.: 62.50%] [G loss: 0.307809]\n",
      "epoch:11 step:10753 [D loss: 0.247851, acc.: 51.56%] [G loss: 0.321898]\n",
      "epoch:11 step:10754 [D loss: 0.213608, acc.: 65.62%] [G loss: 0.315315]\n",
      "epoch:11 step:10755 [D loss: 0.244806, acc.: 53.12%] [G loss: 0.279105]\n",
      "epoch:11 step:10756 [D loss: 0.247460, acc.: 50.00%] [G loss: 0.302716]\n",
      "epoch:11 step:10757 [D loss: 0.234898, acc.: 60.94%] [G loss: 0.296418]\n",
      "epoch:11 step:10758 [D loss: 0.245371, acc.: 57.81%] [G loss: 0.293699]\n",
      "epoch:11 step:10759 [D loss: 0.227743, acc.: 59.38%] [G loss: 0.295941]\n",
      "epoch:11 step:10760 [D loss: 0.235557, acc.: 66.41%] [G loss: 0.301706]\n",
      "epoch:11 step:10761 [D loss: 0.234536, acc.: 59.38%] [G loss: 0.292887]\n",
      "epoch:11 step:10762 [D loss: 0.239619, acc.: 62.50%] [G loss: 0.324015]\n",
      "epoch:11 step:10763 [D loss: 0.239542, acc.: 57.81%] [G loss: 0.299797]\n",
      "epoch:11 step:10764 [D loss: 0.231335, acc.: 60.94%] [G loss: 0.318517]\n",
      "epoch:11 step:10765 [D loss: 0.256158, acc.: 52.34%] [G loss: 0.304198]\n",
      "epoch:11 step:10766 [D loss: 0.242684, acc.: 58.59%] [G loss: 0.300934]\n",
      "epoch:11 step:10767 [D loss: 0.249679, acc.: 54.69%] [G loss: 0.292335]\n",
      "epoch:11 step:10768 [D loss: 0.257607, acc.: 48.44%] [G loss: 0.301309]\n",
      "epoch:11 step:10769 [D loss: 0.245697, acc.: 57.03%] [G loss: 0.303943]\n",
      "epoch:11 step:10770 [D loss: 0.241203, acc.: 57.81%] [G loss: 0.302704]\n",
      "epoch:11 step:10771 [D loss: 0.235618, acc.: 57.81%] [G loss: 0.308918]\n",
      "epoch:11 step:10772 [D loss: 0.255223, acc.: 50.78%] [G loss: 0.271305]\n",
      "epoch:11 step:10773 [D loss: 0.236135, acc.: 57.03%] [G loss: 0.289075]\n",
      "epoch:11 step:10774 [D loss: 0.251006, acc.: 54.69%] [G loss: 0.291103]\n",
      "epoch:11 step:10775 [D loss: 0.237572, acc.: 57.03%] [G loss: 0.321957]\n",
      "epoch:11 step:10776 [D loss: 0.240559, acc.: 57.03%] [G loss: 0.316583]\n",
      "epoch:11 step:10777 [D loss: 0.254248, acc.: 53.91%] [G loss: 0.296129]\n",
      "epoch:11 step:10778 [D loss: 0.242664, acc.: 60.94%] [G loss: 0.274479]\n",
      "epoch:11 step:10779 [D loss: 0.235382, acc.: 59.38%] [G loss: 0.313311]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:11 step:10780 [D loss: 0.244377, acc.: 59.38%] [G loss: 0.267015]\n",
      "epoch:11 step:10781 [D loss: 0.231595, acc.: 60.94%] [G loss: 0.312129]\n",
      "epoch:11 step:10782 [D loss: 0.222651, acc.: 67.19%] [G loss: 0.284633]\n",
      "epoch:11 step:10783 [D loss: 0.248312, acc.: 52.34%] [G loss: 0.273444]\n",
      "epoch:11 step:10784 [D loss: 0.239549, acc.: 56.25%] [G loss: 0.310468]\n",
      "epoch:11 step:10785 [D loss: 0.230253, acc.: 60.94%] [G loss: 0.298609]\n",
      "epoch:11 step:10786 [D loss: 0.240089, acc.: 53.12%] [G loss: 0.304525]\n",
      "epoch:11 step:10787 [D loss: 0.235047, acc.: 60.94%] [G loss: 0.309257]\n",
      "epoch:11 step:10788 [D loss: 0.250356, acc.: 54.69%] [G loss: 0.299127]\n",
      "epoch:11 step:10789 [D loss: 0.240209, acc.: 56.25%] [G loss: 0.313339]\n",
      "epoch:11 step:10790 [D loss: 0.249452, acc.: 56.25%] [G loss: 0.308985]\n",
      "epoch:11 step:10791 [D loss: 0.242061, acc.: 56.25%] [G loss: 0.303366]\n",
      "epoch:11 step:10792 [D loss: 0.237432, acc.: 57.03%] [G loss: 0.323489]\n",
      "epoch:11 step:10793 [D loss: 0.236802, acc.: 57.03%] [G loss: 0.291382]\n",
      "epoch:11 step:10794 [D loss: 0.243909, acc.: 58.59%] [G loss: 0.297037]\n",
      "epoch:11 step:10795 [D loss: 0.229854, acc.: 60.94%] [G loss: 0.294334]\n",
      "epoch:11 step:10796 [D loss: 0.244309, acc.: 56.25%] [G loss: 0.321536]\n",
      "epoch:11 step:10797 [D loss: 0.236566, acc.: 57.03%] [G loss: 0.304584]\n",
      "epoch:11 step:10798 [D loss: 0.241802, acc.: 55.47%] [G loss: 0.303081]\n",
      "epoch:11 step:10799 [D loss: 0.235047, acc.: 57.81%] [G loss: 0.293301]\n",
      "epoch:11 step:10800 [D loss: 0.216006, acc.: 70.31%] [G loss: 0.301659]\n",
      "epoch:11 step:10801 [D loss: 0.228914, acc.: 63.28%] [G loss: 0.294392]\n",
      "epoch:11 step:10802 [D loss: 0.253463, acc.: 53.91%] [G loss: 0.300028]\n",
      "epoch:11 step:10803 [D loss: 0.258150, acc.: 46.88%] [G loss: 0.306825]\n",
      "epoch:11 step:10804 [D loss: 0.242200, acc.: 53.91%] [G loss: 0.327305]\n",
      "epoch:11 step:10805 [D loss: 0.241020, acc.: 57.03%] [G loss: 0.294537]\n",
      "epoch:11 step:10806 [D loss: 0.224647, acc.: 64.84%] [G loss: 0.321211]\n",
      "epoch:11 step:10807 [D loss: 0.227381, acc.: 64.84%] [G loss: 0.317504]\n",
      "epoch:11 step:10808 [D loss: 0.245869, acc.: 53.91%] [G loss: 0.298014]\n",
      "epoch:11 step:10809 [D loss: 0.242257, acc.: 56.25%] [G loss: 0.298967]\n",
      "epoch:11 step:10810 [D loss: 0.225328, acc.: 64.06%] [G loss: 0.296321]\n",
      "epoch:11 step:10811 [D loss: 0.236387, acc.: 54.69%] [G loss: 0.306955]\n",
      "epoch:11 step:10812 [D loss: 0.229566, acc.: 61.72%] [G loss: 0.311132]\n",
      "epoch:11 step:10813 [D loss: 0.213682, acc.: 71.09%] [G loss: 0.312075]\n",
      "epoch:11 step:10814 [D loss: 0.230511, acc.: 58.59%] [G loss: 0.301379]\n",
      "epoch:11 step:10815 [D loss: 0.258085, acc.: 50.00%] [G loss: 0.307619]\n",
      "epoch:11 step:10816 [D loss: 0.231948, acc.: 61.72%] [G loss: 0.299398]\n",
      "epoch:11 step:10817 [D loss: 0.232494, acc.: 62.50%] [G loss: 0.313989]\n",
      "epoch:11 step:10818 [D loss: 0.247257, acc.: 53.91%] [G loss: 0.265528]\n",
      "epoch:11 step:10819 [D loss: 0.221888, acc.: 61.72%] [G loss: 0.291201]\n",
      "epoch:11 step:10820 [D loss: 0.255985, acc.: 50.00%] [G loss: 0.295620]\n",
      "epoch:11 step:10821 [D loss: 0.244144, acc.: 54.69%] [G loss: 0.303341]\n",
      "epoch:11 step:10822 [D loss: 0.229970, acc.: 61.72%] [G loss: 0.326529]\n",
      "epoch:11 step:10823 [D loss: 0.243857, acc.: 50.00%] [G loss: 0.317104]\n",
      "epoch:11 step:10824 [D loss: 0.244832, acc.: 62.50%] [G loss: 0.291733]\n",
      "epoch:11 step:10825 [D loss: 0.253773, acc.: 55.47%] [G loss: 0.280671]\n",
      "epoch:11 step:10826 [D loss: 0.238218, acc.: 59.38%] [G loss: 0.268077]\n",
      "epoch:11 step:10827 [D loss: 0.245096, acc.: 50.78%] [G loss: 0.307091]\n",
      "epoch:11 step:10828 [D loss: 0.229286, acc.: 62.50%] [G loss: 0.306249]\n",
      "epoch:11 step:10829 [D loss: 0.241058, acc.: 50.78%] [G loss: 0.301099]\n",
      "epoch:11 step:10830 [D loss: 0.248958, acc.: 57.81%] [G loss: 0.285654]\n",
      "epoch:11 step:10831 [D loss: 0.233265, acc.: 58.59%] [G loss: 0.318949]\n",
      "epoch:11 step:10832 [D loss: 0.237360, acc.: 59.38%] [G loss: 0.293004]\n",
      "epoch:11 step:10833 [D loss: 0.237073, acc.: 57.81%] [G loss: 0.306029]\n",
      "epoch:11 step:10834 [D loss: 0.241666, acc.: 57.81%] [G loss: 0.331934]\n",
      "epoch:11 step:10835 [D loss: 0.239720, acc.: 56.25%] [G loss: 0.307087]\n",
      "epoch:11 step:10836 [D loss: 0.250742, acc.: 57.81%] [G loss: 0.297756]\n",
      "epoch:11 step:10837 [D loss: 0.243126, acc.: 56.25%] [G loss: 0.317634]\n",
      "epoch:11 step:10838 [D loss: 0.254560, acc.: 54.69%] [G loss: 0.304365]\n",
      "epoch:11 step:10839 [D loss: 0.259520, acc.: 56.25%] [G loss: 0.307397]\n",
      "epoch:11 step:10840 [D loss: 0.241774, acc.: 56.25%] [G loss: 0.272799]\n",
      "epoch:11 step:10841 [D loss: 0.240849, acc.: 59.38%] [G loss: 0.298780]\n",
      "epoch:11 step:10842 [D loss: 0.237073, acc.: 56.25%] [G loss: 0.326665]\n",
      "epoch:11 step:10843 [D loss: 0.230836, acc.: 60.94%] [G loss: 0.320319]\n",
      "epoch:11 step:10844 [D loss: 0.261086, acc.: 48.44%] [G loss: 0.278757]\n",
      "epoch:11 step:10845 [D loss: 0.250010, acc.: 57.03%] [G loss: 0.294000]\n",
      "epoch:11 step:10846 [D loss: 0.246321, acc.: 56.25%] [G loss: 0.308756]\n",
      "epoch:11 step:10847 [D loss: 0.242255, acc.: 55.47%] [G loss: 0.295952]\n",
      "epoch:11 step:10848 [D loss: 0.243516, acc.: 52.34%] [G loss: 0.302557]\n",
      "epoch:11 step:10849 [D loss: 0.249511, acc.: 55.47%] [G loss: 0.285412]\n",
      "epoch:11 step:10850 [D loss: 0.247272, acc.: 50.78%] [G loss: 0.303733]\n",
      "epoch:11 step:10851 [D loss: 0.233425, acc.: 63.28%] [G loss: 0.301995]\n",
      "epoch:11 step:10852 [D loss: 0.242184, acc.: 55.47%] [G loss: 0.304539]\n",
      "epoch:11 step:10853 [D loss: 0.234148, acc.: 57.81%] [G loss: 0.328598]\n",
      "epoch:11 step:10854 [D loss: 0.244812, acc.: 52.34%] [G loss: 0.299726]\n",
      "epoch:11 step:10855 [D loss: 0.241042, acc.: 57.03%] [G loss: 0.318906]\n",
      "epoch:11 step:10856 [D loss: 0.237943, acc.: 53.91%] [G loss: 0.301129]\n",
      "epoch:11 step:10857 [D loss: 0.237673, acc.: 57.81%] [G loss: 0.296529]\n",
      "epoch:11 step:10858 [D loss: 0.245520, acc.: 53.12%] [G loss: 0.303857]\n",
      "epoch:11 step:10859 [D loss: 0.249082, acc.: 51.56%] [G loss: 0.300444]\n",
      "epoch:11 step:10860 [D loss: 0.250200, acc.: 52.34%] [G loss: 0.280942]\n",
      "epoch:11 step:10861 [D loss: 0.235041, acc.: 57.03%] [G loss: 0.295978]\n",
      "epoch:11 step:10862 [D loss: 0.240881, acc.: 59.38%] [G loss: 0.287936]\n",
      "epoch:11 step:10863 [D loss: 0.246590, acc.: 59.38%] [G loss: 0.285834]\n",
      "epoch:11 step:10864 [D loss: 0.245786, acc.: 57.03%] [G loss: 0.320256]\n",
      "epoch:11 step:10865 [D loss: 0.254040, acc.: 52.34%] [G loss: 0.285590]\n",
      "epoch:11 step:10866 [D loss: 0.249688, acc.: 53.91%] [G loss: 0.305613]\n",
      "epoch:11 step:10867 [D loss: 0.240736, acc.: 59.38%] [G loss: 0.300509]\n",
      "epoch:11 step:10868 [D loss: 0.252799, acc.: 55.47%] [G loss: 0.290159]\n",
      "epoch:11 step:10869 [D loss: 0.241322, acc.: 58.59%] [G loss: 0.293071]\n",
      "epoch:11 step:10870 [D loss: 0.245367, acc.: 53.91%] [G loss: 0.278699]\n",
      "epoch:11 step:10871 [D loss: 0.233785, acc.: 63.28%] [G loss: 0.291172]\n",
      "epoch:11 step:10872 [D loss: 0.232612, acc.: 60.94%] [G loss: 0.308499]\n",
      "epoch:11 step:10873 [D loss: 0.237224, acc.: 60.94%] [G loss: 0.297049]\n",
      "epoch:11 step:10874 [D loss: 0.237975, acc.: 57.81%] [G loss: 0.312178]\n",
      "epoch:11 step:10875 [D loss: 0.256809, acc.: 52.34%] [G loss: 0.310445]\n",
      "epoch:11 step:10876 [D loss: 0.238269, acc.: 54.69%] [G loss: 0.281768]\n",
      "epoch:11 step:10877 [D loss: 0.238293, acc.: 57.03%] [G loss: 0.315734]\n",
      "epoch:11 step:10878 [D loss: 0.244663, acc.: 56.25%] [G loss: 0.285870]\n",
      "epoch:11 step:10879 [D loss: 0.222111, acc.: 60.94%] [G loss: 0.297065]\n",
      "epoch:11 step:10880 [D loss: 0.256830, acc.: 46.88%] [G loss: 0.323214]\n",
      "epoch:11 step:10881 [D loss: 0.244758, acc.: 53.12%] [G loss: 0.284867]\n",
      "epoch:11 step:10882 [D loss: 0.241432, acc.: 53.91%] [G loss: 0.322145]\n",
      "epoch:11 step:10883 [D loss: 0.253147, acc.: 61.72%] [G loss: 0.308538]\n",
      "epoch:11 step:10884 [D loss: 0.241206, acc.: 57.03%] [G loss: 0.324317]\n",
      "epoch:11 step:10885 [D loss: 0.240687, acc.: 57.81%] [G loss: 0.342998]\n",
      "epoch:11 step:10886 [D loss: 0.239164, acc.: 57.03%] [G loss: 0.317505]\n",
      "epoch:11 step:10887 [D loss: 0.241984, acc.: 55.47%] [G loss: 0.286052]\n",
      "epoch:11 step:10888 [D loss: 0.256009, acc.: 53.91%] [G loss: 0.331199]\n",
      "epoch:11 step:10889 [D loss: 0.251039, acc.: 55.47%] [G loss: 0.279247]\n",
      "epoch:11 step:10890 [D loss: 0.247938, acc.: 57.03%] [G loss: 0.309841]\n",
      "epoch:11 step:10891 [D loss: 0.250821, acc.: 53.12%] [G loss: 0.289718]\n",
      "epoch:11 step:10892 [D loss: 0.248847, acc.: 55.47%] [G loss: 0.308437]\n",
      "epoch:11 step:10893 [D loss: 0.242516, acc.: 62.50%] [G loss: 0.299077]\n",
      "epoch:11 step:10894 [D loss: 0.242865, acc.: 56.25%] [G loss: 0.300429]\n",
      "epoch:11 step:10895 [D loss: 0.224954, acc.: 62.50%] [G loss: 0.303089]\n",
      "epoch:11 step:10896 [D loss: 0.249804, acc.: 51.56%] [G loss: 0.298830]\n",
      "epoch:11 step:10897 [D loss: 0.236635, acc.: 57.81%] [G loss: 0.294166]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:11 step:10898 [D loss: 0.233383, acc.: 61.72%] [G loss: 0.297191]\n",
      "epoch:11 step:10899 [D loss: 0.248444, acc.: 51.56%] [G loss: 0.283942]\n",
      "epoch:11 step:10900 [D loss: 0.251992, acc.: 54.69%] [G loss: 0.293970]\n",
      "epoch:11 step:10901 [D loss: 0.232874, acc.: 56.25%] [G loss: 0.294553]\n",
      "epoch:11 step:10902 [D loss: 0.243771, acc.: 54.69%] [G loss: 0.292288]\n",
      "epoch:11 step:10903 [D loss: 0.226565, acc.: 63.28%] [G loss: 0.327383]\n",
      "epoch:11 step:10904 [D loss: 0.240743, acc.: 60.16%] [G loss: 0.316767]\n",
      "epoch:11 step:10905 [D loss: 0.232667, acc.: 60.94%] [G loss: 0.290404]\n",
      "epoch:11 step:10906 [D loss: 0.228610, acc.: 60.16%] [G loss: 0.295491]\n",
      "epoch:11 step:10907 [D loss: 0.222641, acc.: 64.84%] [G loss: 0.296487]\n",
      "epoch:11 step:10908 [D loss: 0.272345, acc.: 46.88%] [G loss: 0.291870]\n",
      "epoch:11 step:10909 [D loss: 0.228258, acc.: 61.72%] [G loss: 0.292250]\n",
      "epoch:11 step:10910 [D loss: 0.247628, acc.: 51.56%] [G loss: 0.317965]\n",
      "epoch:11 step:10911 [D loss: 0.230407, acc.: 58.59%] [G loss: 0.295309]\n",
      "epoch:11 step:10912 [D loss: 0.248649, acc.: 57.81%] [G loss: 0.283956]\n",
      "epoch:11 step:10913 [D loss: 0.240953, acc.: 59.38%] [G loss: 0.298438]\n",
      "epoch:11 step:10914 [D loss: 0.228399, acc.: 58.59%] [G loss: 0.283460]\n",
      "epoch:11 step:10915 [D loss: 0.235795, acc.: 57.81%] [G loss: 0.289116]\n",
      "epoch:11 step:10916 [D loss: 0.230476, acc.: 64.06%] [G loss: 0.320360]\n",
      "epoch:11 step:10917 [D loss: 0.243406, acc.: 53.12%] [G loss: 0.299387]\n",
      "epoch:11 step:10918 [D loss: 0.243703, acc.: 60.16%] [G loss: 0.287015]\n",
      "epoch:11 step:10919 [D loss: 0.244087, acc.: 52.34%] [G loss: 0.312885]\n",
      "epoch:11 step:10920 [D loss: 0.224688, acc.: 64.06%] [G loss: 0.287464]\n",
      "epoch:11 step:10921 [D loss: 0.234213, acc.: 57.81%] [G loss: 0.286493]\n",
      "epoch:11 step:10922 [D loss: 0.234767, acc.: 59.38%] [G loss: 0.287543]\n",
      "epoch:11 step:10923 [D loss: 0.223352, acc.: 65.62%] [G loss: 0.334024]\n",
      "epoch:11 step:10924 [D loss: 0.234726, acc.: 53.12%] [G loss: 0.316785]\n",
      "epoch:11 step:10925 [D loss: 0.235829, acc.: 59.38%] [G loss: 0.310482]\n",
      "epoch:11 step:10926 [D loss: 0.235959, acc.: 60.94%] [G loss: 0.319002]\n",
      "epoch:11 step:10927 [D loss: 0.238296, acc.: 60.94%] [G loss: 0.302874]\n",
      "epoch:11 step:10928 [D loss: 0.238618, acc.: 59.38%] [G loss: 0.286595]\n",
      "epoch:11 step:10929 [D loss: 0.233481, acc.: 58.59%] [G loss: 0.308225]\n",
      "epoch:11 step:10930 [D loss: 0.232655, acc.: 61.72%] [G loss: 0.299002]\n",
      "epoch:11 step:10931 [D loss: 0.236980, acc.: 56.25%] [G loss: 0.314966]\n",
      "epoch:11 step:10932 [D loss: 0.240350, acc.: 56.25%] [G loss: 0.290230]\n",
      "epoch:11 step:10933 [D loss: 0.229835, acc.: 60.94%] [G loss: 0.295574]\n",
      "epoch:11 step:10934 [D loss: 0.234666, acc.: 61.72%] [G loss: 0.292040]\n",
      "epoch:11 step:10935 [D loss: 0.240320, acc.: 57.03%] [G loss: 0.313721]\n",
      "epoch:11 step:10936 [D loss: 0.238776, acc.: 59.38%] [G loss: 0.268687]\n",
      "epoch:11 step:10937 [D loss: 0.233932, acc.: 53.91%] [G loss: 0.293664]\n",
      "epoch:11 step:10938 [D loss: 0.233459, acc.: 63.28%] [G loss: 0.277949]\n",
      "epoch:11 step:10939 [D loss: 0.230980, acc.: 58.59%] [G loss: 0.308033]\n",
      "epoch:11 step:10940 [D loss: 0.242058, acc.: 61.72%] [G loss: 0.296263]\n",
      "epoch:11 step:10941 [D loss: 0.229737, acc.: 58.59%] [G loss: 0.315346]\n",
      "epoch:11 step:10942 [D loss: 0.224600, acc.: 62.50%] [G loss: 0.281421]\n",
      "epoch:11 step:10943 [D loss: 0.228385, acc.: 58.59%] [G loss: 0.313048]\n",
      "epoch:11 step:10944 [D loss: 0.258953, acc.: 53.91%] [G loss: 0.311237]\n",
      "epoch:11 step:10945 [D loss: 0.237085, acc.: 57.03%] [G loss: 0.284131]\n",
      "epoch:11 step:10946 [D loss: 0.273388, acc.: 46.88%] [G loss: 0.291935]\n",
      "epoch:11 step:10947 [D loss: 0.222753, acc.: 64.84%] [G loss: 0.302139]\n",
      "epoch:11 step:10948 [D loss: 0.234661, acc.: 61.72%] [G loss: 0.312112]\n",
      "epoch:11 step:10949 [D loss: 0.244965, acc.: 59.38%] [G loss: 0.322234]\n",
      "epoch:11 step:10950 [D loss: 0.252746, acc.: 56.25%] [G loss: 0.285206]\n",
      "epoch:11 step:10951 [D loss: 0.222072, acc.: 67.19%] [G loss: 0.307777]\n",
      "epoch:11 step:10952 [D loss: 0.236436, acc.: 57.81%] [G loss: 0.291748]\n",
      "epoch:11 step:10953 [D loss: 0.246216, acc.: 57.03%] [G loss: 0.303654]\n",
      "epoch:11 step:10954 [D loss: 0.232013, acc.: 60.16%] [G loss: 0.284868]\n",
      "epoch:11 step:10955 [D loss: 0.234420, acc.: 57.03%] [G loss: 0.323789]\n",
      "epoch:11 step:10956 [D loss: 0.236147, acc.: 59.38%] [G loss: 0.312572]\n",
      "epoch:11 step:10957 [D loss: 0.240365, acc.: 60.16%] [G loss: 0.298407]\n",
      "epoch:11 step:10958 [D loss: 0.230501, acc.: 58.59%] [G loss: 0.283082]\n",
      "epoch:11 step:10959 [D loss: 0.232489, acc.: 60.16%] [G loss: 0.305380]\n",
      "epoch:11 step:10960 [D loss: 0.218969, acc.: 69.53%] [G loss: 0.290400]\n",
      "epoch:11 step:10961 [D loss: 0.232003, acc.: 59.38%] [G loss: 0.309593]\n",
      "epoch:11 step:10962 [D loss: 0.242585, acc.: 54.69%] [G loss: 0.297034]\n",
      "epoch:11 step:10963 [D loss: 0.243403, acc.: 57.81%] [G loss: 0.312664]\n",
      "epoch:11 step:10964 [D loss: 0.234085, acc.: 59.38%] [G loss: 0.322370]\n",
      "epoch:11 step:10965 [D loss: 0.260535, acc.: 50.00%] [G loss: 0.299308]\n",
      "epoch:11 step:10966 [D loss: 0.247852, acc.: 52.34%] [G loss: 0.288058]\n",
      "epoch:11 step:10967 [D loss: 0.216707, acc.: 65.62%] [G loss: 0.319883]\n",
      "epoch:11 step:10968 [D loss: 0.236193, acc.: 60.94%] [G loss: 0.303792]\n",
      "epoch:11 step:10969 [D loss: 0.227261, acc.: 62.50%] [G loss: 0.291547]\n",
      "epoch:11 step:10970 [D loss: 0.244094, acc.: 51.56%] [G loss: 0.297979]\n",
      "epoch:11 step:10971 [D loss: 0.246596, acc.: 58.59%] [G loss: 0.282292]\n",
      "epoch:11 step:10972 [D loss: 0.228831, acc.: 60.16%] [G loss: 0.296070]\n",
      "epoch:11 step:10973 [D loss: 0.238975, acc.: 57.03%] [G loss: 0.287886]\n",
      "epoch:11 step:10974 [D loss: 0.245828, acc.: 59.38%] [G loss: 0.283478]\n",
      "epoch:11 step:10975 [D loss: 0.233157, acc.: 64.06%] [G loss: 0.308846]\n",
      "epoch:11 step:10976 [D loss: 0.251225, acc.: 52.34%] [G loss: 0.265994]\n",
      "epoch:11 step:10977 [D loss: 0.230440, acc.: 56.25%] [G loss: 0.292620]\n",
      "epoch:11 step:10978 [D loss: 0.244438, acc.: 53.12%] [G loss: 0.334178]\n",
      "epoch:11 step:10979 [D loss: 0.229967, acc.: 61.72%] [G loss: 0.324538]\n",
      "epoch:11 step:10980 [D loss: 0.241243, acc.: 60.94%] [G loss: 0.308370]\n",
      "epoch:11 step:10981 [D loss: 0.232391, acc.: 63.28%] [G loss: 0.268203]\n",
      "epoch:11 step:10982 [D loss: 0.219965, acc.: 67.19%] [G loss: 0.304536]\n",
      "epoch:11 step:10983 [D loss: 0.230162, acc.: 58.59%] [G loss: 0.311217]\n",
      "epoch:11 step:10984 [D loss: 0.249108, acc.: 52.34%] [G loss: 0.283502]\n",
      "epoch:11 step:10985 [D loss: 0.244925, acc.: 56.25%] [G loss: 0.302806]\n",
      "epoch:11 step:10986 [D loss: 0.241361, acc.: 59.38%] [G loss: 0.281865]\n",
      "epoch:11 step:10987 [D loss: 0.261130, acc.: 51.56%] [G loss: 0.290676]\n",
      "epoch:11 step:10988 [D loss: 0.251207, acc.: 57.03%] [G loss: 0.303097]\n",
      "epoch:11 step:10989 [D loss: 0.232455, acc.: 59.38%] [G loss: 0.319533]\n",
      "epoch:11 step:10990 [D loss: 0.261168, acc.: 49.22%] [G loss: 0.301088]\n",
      "epoch:11 step:10991 [D loss: 0.240181, acc.: 58.59%] [G loss: 0.317060]\n",
      "epoch:11 step:10992 [D loss: 0.240106, acc.: 60.94%] [G loss: 0.330775]\n",
      "epoch:11 step:10993 [D loss: 0.231210, acc.: 61.72%] [G loss: 0.301732]\n",
      "epoch:11 step:10994 [D loss: 0.215058, acc.: 61.72%] [G loss: 0.303192]\n",
      "epoch:11 step:10995 [D loss: 0.238581, acc.: 60.16%] [G loss: 0.286908]\n",
      "epoch:11 step:10996 [D loss: 0.238374, acc.: 60.16%] [G loss: 0.294313]\n",
      "epoch:11 step:10997 [D loss: 0.245963, acc.: 53.12%] [G loss: 0.282391]\n",
      "epoch:11 step:10998 [D loss: 0.240964, acc.: 61.72%] [G loss: 0.303950]\n",
      "epoch:11 step:10999 [D loss: 0.248343, acc.: 58.59%] [G loss: 0.305819]\n",
      "epoch:11 step:11000 [D loss: 0.233515, acc.: 55.47%] [G loss: 0.297792]\n",
      "epoch:11 step:11001 [D loss: 0.237741, acc.: 60.94%] [G loss: 0.321332]\n",
      "epoch:11 step:11002 [D loss: 0.234723, acc.: 62.50%] [G loss: 0.298468]\n",
      "epoch:11 step:11003 [D loss: 0.236161, acc.: 59.38%] [G loss: 0.313822]\n",
      "epoch:11 step:11004 [D loss: 0.238301, acc.: 59.38%] [G loss: 0.318127]\n",
      "epoch:11 step:11005 [D loss: 0.208398, acc.: 67.97%] [G loss: 0.326784]\n",
      "epoch:11 step:11006 [D loss: 0.223128, acc.: 64.06%] [G loss: 0.303101]\n",
      "epoch:11 step:11007 [D loss: 0.233532, acc.: 60.16%] [G loss: 0.276214]\n",
      "epoch:11 step:11008 [D loss: 0.241012, acc.: 62.50%] [G loss: 0.301704]\n",
      "epoch:11 step:11009 [D loss: 0.214784, acc.: 67.19%] [G loss: 0.300329]\n",
      "epoch:11 step:11010 [D loss: 0.241614, acc.: 57.03%] [G loss: 0.315554]\n",
      "epoch:11 step:11011 [D loss: 0.251858, acc.: 57.03%] [G loss: 0.305108]\n",
      "epoch:11 step:11012 [D loss: 0.237323, acc.: 58.59%] [G loss: 0.288967]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:11 step:11013 [D loss: 0.234669, acc.: 61.72%] [G loss: 0.298336]\n",
      "epoch:11 step:11014 [D loss: 0.229458, acc.: 60.94%] [G loss: 0.290564]\n",
      "epoch:11 step:11015 [D loss: 0.237727, acc.: 57.81%] [G loss: 0.298331]\n",
      "epoch:11 step:11016 [D loss: 0.253045, acc.: 53.12%] [G loss: 0.280033]\n",
      "epoch:11 step:11017 [D loss: 0.238974, acc.: 63.28%] [G loss: 0.311847]\n",
      "epoch:11 step:11018 [D loss: 0.248961, acc.: 55.47%] [G loss: 0.311166]\n",
      "epoch:11 step:11019 [D loss: 0.247994, acc.: 58.59%] [G loss: 0.313469]\n",
      "epoch:11 step:11020 [D loss: 0.239252, acc.: 57.81%] [G loss: 0.288794]\n",
      "epoch:11 step:11021 [D loss: 0.241684, acc.: 53.91%] [G loss: 0.292388]\n",
      "epoch:11 step:11022 [D loss: 0.248597, acc.: 52.34%] [G loss: 0.260942]\n",
      "epoch:11 step:11023 [D loss: 0.228440, acc.: 61.72%] [G loss: 0.314323]\n",
      "epoch:11 step:11024 [D loss: 0.245321, acc.: 57.81%] [G loss: 0.290661]\n",
      "epoch:11 step:11025 [D loss: 0.229424, acc.: 60.16%] [G loss: 0.305203]\n",
      "epoch:11 step:11026 [D loss: 0.245525, acc.: 59.38%] [G loss: 0.283600]\n",
      "epoch:11 step:11027 [D loss: 0.250035, acc.: 56.25%] [G loss: 0.306183]\n",
      "epoch:11 step:11028 [D loss: 0.244770, acc.: 61.72%] [G loss: 0.275531]\n",
      "epoch:11 step:11029 [D loss: 0.248554, acc.: 58.59%] [G loss: 0.296730]\n",
      "epoch:11 step:11030 [D loss: 0.241955, acc.: 54.69%] [G loss: 0.326120]\n",
      "epoch:11 step:11031 [D loss: 0.258972, acc.: 50.78%] [G loss: 0.296623]\n",
      "epoch:11 step:11032 [D loss: 0.239729, acc.: 56.25%] [G loss: 0.270065]\n",
      "epoch:11 step:11033 [D loss: 0.256876, acc.: 50.78%] [G loss: 0.311799]\n",
      "epoch:11 step:11034 [D loss: 0.229141, acc.: 63.28%] [G loss: 0.304302]\n",
      "epoch:11 step:11035 [D loss: 0.242352, acc.: 55.47%] [G loss: 0.283535]\n",
      "epoch:11 step:11036 [D loss: 0.237643, acc.: 63.28%] [G loss: 0.300348]\n",
      "epoch:11 step:11037 [D loss: 0.238383, acc.: 59.38%] [G loss: 0.307478]\n",
      "epoch:11 step:11038 [D loss: 0.239694, acc.: 58.59%] [G loss: 0.296820]\n",
      "epoch:11 step:11039 [D loss: 0.239401, acc.: 60.16%] [G loss: 0.279805]\n",
      "epoch:11 step:11040 [D loss: 0.242747, acc.: 56.25%] [G loss: 0.306497]\n",
      "epoch:11 step:11041 [D loss: 0.229237, acc.: 62.50%] [G loss: 0.298871]\n",
      "epoch:11 step:11042 [D loss: 0.231654, acc.: 53.12%] [G loss: 0.320649]\n",
      "epoch:11 step:11043 [D loss: 0.228994, acc.: 68.75%] [G loss: 0.321368]\n",
      "epoch:11 step:11044 [D loss: 0.248237, acc.: 54.69%] [G loss: 0.284242]\n",
      "epoch:11 step:11045 [D loss: 0.254792, acc.: 50.78%] [G loss: 0.334059]\n",
      "epoch:11 step:11046 [D loss: 0.250479, acc.: 49.22%] [G loss: 0.272635]\n",
      "epoch:11 step:11047 [D loss: 0.232973, acc.: 64.84%] [G loss: 0.301904]\n",
      "epoch:11 step:11048 [D loss: 0.250793, acc.: 53.91%] [G loss: 0.297077]\n",
      "epoch:11 step:11049 [D loss: 0.247673, acc.: 52.34%] [G loss: 0.307160]\n",
      "epoch:11 step:11050 [D loss: 0.241353, acc.: 57.81%] [G loss: 0.299819]\n",
      "epoch:11 step:11051 [D loss: 0.254806, acc.: 51.56%] [G loss: 0.292381]\n",
      "epoch:11 step:11052 [D loss: 0.243777, acc.: 58.59%] [G loss: 0.304722]\n",
      "epoch:11 step:11053 [D loss: 0.219205, acc.: 68.75%] [G loss: 0.284637]\n",
      "epoch:11 step:11054 [D loss: 0.238082, acc.: 58.59%] [G loss: 0.299073]\n",
      "epoch:11 step:11055 [D loss: 0.230792, acc.: 57.81%] [G loss: 0.295464]\n",
      "epoch:11 step:11056 [D loss: 0.244507, acc.: 60.16%] [G loss: 0.289637]\n",
      "epoch:11 step:11057 [D loss: 0.246871, acc.: 55.47%] [G loss: 0.309953]\n",
      "epoch:11 step:11058 [D loss: 0.228702, acc.: 60.94%] [G loss: 0.301981]\n",
      "epoch:11 step:11059 [D loss: 0.248009, acc.: 54.69%] [G loss: 0.267369]\n",
      "epoch:11 step:11060 [D loss: 0.246695, acc.: 53.12%] [G loss: 0.288212]\n",
      "epoch:11 step:11061 [D loss: 0.225916, acc.: 64.84%] [G loss: 0.307972]\n",
      "epoch:11 step:11062 [D loss: 0.234634, acc.: 60.16%] [G loss: 0.302586]\n",
      "epoch:11 step:11063 [D loss: 0.249468, acc.: 56.25%] [G loss: 0.285442]\n",
      "epoch:11 step:11064 [D loss: 0.251961, acc.: 51.56%] [G loss: 0.297923]\n",
      "epoch:11 step:11065 [D loss: 0.242709, acc.: 61.72%] [G loss: 0.282148]\n",
      "epoch:11 step:11066 [D loss: 0.253728, acc.: 55.47%] [G loss: 0.270369]\n",
      "epoch:11 step:11067 [D loss: 0.238515, acc.: 63.28%] [G loss: 0.283213]\n",
      "epoch:11 step:11068 [D loss: 0.245344, acc.: 57.81%] [G loss: 0.254368]\n",
      "epoch:11 step:11069 [D loss: 0.237585, acc.: 59.38%] [G loss: 0.283385]\n",
      "epoch:11 step:11070 [D loss: 0.226587, acc.: 63.28%] [G loss: 0.306444]\n",
      "epoch:11 step:11071 [D loss: 0.241708, acc.: 57.03%] [G loss: 0.309819]\n",
      "epoch:11 step:11072 [D loss: 0.250058, acc.: 50.00%] [G loss: 0.301231]\n",
      "epoch:11 step:11073 [D loss: 0.238104, acc.: 57.03%] [G loss: 0.299404]\n",
      "epoch:11 step:11074 [D loss: 0.239725, acc.: 57.03%] [G loss: 0.293057]\n",
      "epoch:11 step:11075 [D loss: 0.232881, acc.: 60.94%] [G loss: 0.325928]\n",
      "epoch:11 step:11076 [D loss: 0.234739, acc.: 59.38%] [G loss: 0.294236]\n",
      "epoch:11 step:11077 [D loss: 0.237405, acc.: 62.50%] [G loss: 0.293854]\n",
      "epoch:11 step:11078 [D loss: 0.245476, acc.: 51.56%] [G loss: 0.334205]\n",
      "epoch:11 step:11079 [D loss: 0.232315, acc.: 60.94%] [G loss: 0.293513]\n",
      "epoch:11 step:11080 [D loss: 0.229739, acc.: 62.50%] [G loss: 0.319684]\n",
      "epoch:11 step:11081 [D loss: 0.241598, acc.: 58.59%] [G loss: 0.304713]\n",
      "epoch:11 step:11082 [D loss: 0.249503, acc.: 58.59%] [G loss: 0.313642]\n",
      "epoch:11 step:11083 [D loss: 0.238959, acc.: 56.25%] [G loss: 0.310370]\n",
      "epoch:11 step:11084 [D loss: 0.225482, acc.: 63.28%] [G loss: 0.304178]\n",
      "epoch:11 step:11085 [D loss: 0.241102, acc.: 54.69%] [G loss: 0.318186]\n",
      "epoch:11 step:11086 [D loss: 0.237917, acc.: 61.72%] [G loss: 0.295063]\n",
      "epoch:11 step:11087 [D loss: 0.249201, acc.: 54.69%] [G loss: 0.294176]\n",
      "epoch:11 step:11088 [D loss: 0.228703, acc.: 59.38%] [G loss: 0.327871]\n",
      "epoch:11 step:11089 [D loss: 0.262104, acc.: 51.56%] [G loss: 0.295515]\n",
      "epoch:11 step:11090 [D loss: 0.259311, acc.: 49.22%] [G loss: 0.279116]\n",
      "epoch:11 step:11091 [D loss: 0.259253, acc.: 49.22%] [G loss: 0.306974]\n",
      "epoch:11 step:11092 [D loss: 0.236513, acc.: 55.47%] [G loss: 0.279163]\n",
      "epoch:11 step:11093 [D loss: 0.242823, acc.: 56.25%] [G loss: 0.309671]\n",
      "epoch:11 step:11094 [D loss: 0.221653, acc.: 59.38%] [G loss: 0.314685]\n",
      "epoch:11 step:11095 [D loss: 0.241992, acc.: 57.81%] [G loss: 0.273748]\n",
      "epoch:11 step:11096 [D loss: 0.225547, acc.: 61.72%] [G loss: 0.323927]\n",
      "epoch:11 step:11097 [D loss: 0.238835, acc.: 57.03%] [G loss: 0.281865]\n",
      "epoch:11 step:11098 [D loss: 0.237435, acc.: 56.25%] [G loss: 0.345549]\n",
      "epoch:11 step:11099 [D loss: 0.258977, acc.: 50.78%] [G loss: 0.307708]\n",
      "epoch:11 step:11100 [D loss: 0.224637, acc.: 68.75%] [G loss: 0.310916]\n",
      "epoch:11 step:11101 [D loss: 0.240887, acc.: 57.03%] [G loss: 0.312100]\n",
      "epoch:11 step:11102 [D loss: 0.219537, acc.: 66.41%] [G loss: 0.326978]\n",
      "epoch:11 step:11103 [D loss: 0.252851, acc.: 57.81%] [G loss: 0.315271]\n",
      "epoch:11 step:11104 [D loss: 0.244216, acc.: 58.59%] [G loss: 0.289117]\n",
      "epoch:11 step:11105 [D loss: 0.235424, acc.: 60.94%] [G loss: 0.291973]\n",
      "epoch:11 step:11106 [D loss: 0.239396, acc.: 58.59%] [G loss: 0.308906]\n",
      "epoch:11 step:11107 [D loss: 0.249961, acc.: 52.34%] [G loss: 0.302122]\n",
      "epoch:11 step:11108 [D loss: 0.231254, acc.: 60.16%] [G loss: 0.276684]\n",
      "epoch:11 step:11109 [D loss: 0.246653, acc.: 53.91%] [G loss: 0.268414]\n",
      "epoch:11 step:11110 [D loss: 0.237664, acc.: 59.38%] [G loss: 0.301660]\n",
      "epoch:11 step:11111 [D loss: 0.248482, acc.: 55.47%] [G loss: 0.290018]\n",
      "epoch:11 step:11112 [D loss: 0.234848, acc.: 57.81%] [G loss: 0.309028]\n",
      "epoch:11 step:11113 [D loss: 0.236674, acc.: 58.59%] [G loss: 0.307670]\n",
      "epoch:11 step:11114 [D loss: 0.227024, acc.: 60.94%] [G loss: 0.314871]\n",
      "epoch:11 step:11115 [D loss: 0.225957, acc.: 64.06%] [G loss: 0.283108]\n",
      "epoch:11 step:11116 [D loss: 0.238020, acc.: 57.81%] [G loss: 0.299674]\n",
      "epoch:11 step:11117 [D loss: 0.224767, acc.: 63.28%] [G loss: 0.292079]\n",
      "epoch:11 step:11118 [D loss: 0.232114, acc.: 64.06%] [G loss: 0.284632]\n",
      "epoch:11 step:11119 [D loss: 0.233654, acc.: 60.16%] [G loss: 0.271923]\n",
      "epoch:11 step:11120 [D loss: 0.232972, acc.: 63.28%] [G loss: 0.316720]\n",
      "epoch:11 step:11121 [D loss: 0.245058, acc.: 52.34%] [G loss: 0.320586]\n",
      "epoch:11 step:11122 [D loss: 0.247802, acc.: 59.38%] [G loss: 0.269788]\n",
      "epoch:11 step:11123 [D loss: 0.241922, acc.: 59.38%] [G loss: 0.302305]\n",
      "epoch:11 step:11124 [D loss: 0.237108, acc.: 63.28%] [G loss: 0.301963]\n",
      "epoch:11 step:11125 [D loss: 0.229806, acc.: 66.41%] [G loss: 0.275045]\n",
      "epoch:11 step:11126 [D loss: 0.231896, acc.: 62.50%] [G loss: 0.280829]\n",
      "epoch:11 step:11127 [D loss: 0.242993, acc.: 55.47%] [G loss: 0.271417]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:11 step:11128 [D loss: 0.251220, acc.: 46.09%] [G loss: 0.288102]\n",
      "epoch:11 step:11129 [D loss: 0.244422, acc.: 57.03%] [G loss: 0.303514]\n",
      "epoch:11 step:11130 [D loss: 0.251949, acc.: 54.69%] [G loss: 0.275350]\n",
      "epoch:11 step:11131 [D loss: 0.257230, acc.: 50.78%] [G loss: 0.284376]\n",
      "epoch:11 step:11132 [D loss: 0.240760, acc.: 55.47%] [G loss: 0.319274]\n",
      "epoch:11 step:11133 [D loss: 0.236794, acc.: 57.81%] [G loss: 0.290181]\n",
      "epoch:11 step:11134 [D loss: 0.242807, acc.: 60.16%] [G loss: 0.277127]\n",
      "epoch:11 step:11135 [D loss: 0.238902, acc.: 60.94%] [G loss: 0.306223]\n",
      "epoch:11 step:11136 [D loss: 0.237491, acc.: 60.16%] [G loss: 0.276191]\n",
      "epoch:11 step:11137 [D loss: 0.242386, acc.: 55.47%] [G loss: 0.287450]\n",
      "epoch:11 step:11138 [D loss: 0.255171, acc.: 50.78%] [G loss: 0.279874]\n",
      "epoch:11 step:11139 [D loss: 0.233178, acc.: 63.28%] [G loss: 0.314804]\n",
      "epoch:11 step:11140 [D loss: 0.257699, acc.: 57.03%] [G loss: 0.251366]\n",
      "epoch:11 step:11141 [D loss: 0.251072, acc.: 50.00%] [G loss: 0.301852]\n",
      "epoch:11 step:11142 [D loss: 0.247485, acc.: 53.91%] [G loss: 0.268939]\n",
      "epoch:11 step:11143 [D loss: 0.251428, acc.: 52.34%] [G loss: 0.279428]\n",
      "epoch:11 step:11144 [D loss: 0.245536, acc.: 59.38%] [G loss: 0.296576]\n",
      "epoch:11 step:11145 [D loss: 0.256188, acc.: 51.56%] [G loss: 0.273111]\n",
      "epoch:11 step:11146 [D loss: 0.251140, acc.: 51.56%] [G loss: 0.279624]\n",
      "epoch:11 step:11147 [D loss: 0.235771, acc.: 64.84%] [G loss: 0.316111]\n",
      "epoch:11 step:11148 [D loss: 0.233356, acc.: 58.59%] [G loss: 0.292029]\n",
      "epoch:11 step:11149 [D loss: 0.246245, acc.: 57.03%] [G loss: 0.284258]\n",
      "epoch:11 step:11150 [D loss: 0.237755, acc.: 61.72%] [G loss: 0.292082]\n",
      "epoch:11 step:11151 [D loss: 0.243188, acc.: 54.69%] [G loss: 0.295079]\n",
      "epoch:11 step:11152 [D loss: 0.251364, acc.: 55.47%] [G loss: 0.301112]\n",
      "epoch:11 step:11153 [D loss: 0.255415, acc.: 45.31%] [G loss: 0.288293]\n",
      "epoch:11 step:11154 [D loss: 0.236140, acc.: 59.38%] [G loss: 0.288766]\n",
      "epoch:11 step:11155 [D loss: 0.243723, acc.: 57.03%] [G loss: 0.315876]\n",
      "epoch:11 step:11156 [D loss: 0.244330, acc.: 56.25%] [G loss: 0.293302]\n",
      "epoch:11 step:11157 [D loss: 0.228546, acc.: 64.06%] [G loss: 0.314996]\n",
      "epoch:11 step:11158 [D loss: 0.246808, acc.: 57.03%] [G loss: 0.300193]\n",
      "epoch:11 step:11159 [D loss: 0.244506, acc.: 52.34%] [G loss: 0.282103]\n",
      "epoch:11 step:11160 [D loss: 0.225913, acc.: 60.16%] [G loss: 0.299139]\n",
      "epoch:11 step:11161 [D loss: 0.239449, acc.: 57.03%] [G loss: 0.301441]\n",
      "epoch:11 step:11162 [D loss: 0.243929, acc.: 61.72%] [G loss: 0.305153]\n",
      "epoch:11 step:11163 [D loss: 0.223266, acc.: 61.72%] [G loss: 0.309839]\n",
      "epoch:11 step:11164 [D loss: 0.267603, acc.: 46.09%] [G loss: 0.316640]\n",
      "epoch:11 step:11165 [D loss: 0.236362, acc.: 60.16%] [G loss: 0.299036]\n",
      "epoch:11 step:11166 [D loss: 0.246279, acc.: 62.50%] [G loss: 0.288521]\n",
      "epoch:11 step:11167 [D loss: 0.240994, acc.: 57.81%] [G loss: 0.278037]\n",
      "epoch:11 step:11168 [D loss: 0.244646, acc.: 57.03%] [G loss: 0.294664]\n",
      "epoch:11 step:11169 [D loss: 0.243469, acc.: 57.03%] [G loss: 0.304498]\n",
      "epoch:11 step:11170 [D loss: 0.223502, acc.: 60.94%] [G loss: 0.286715]\n",
      "epoch:11 step:11171 [D loss: 0.254722, acc.: 51.56%] [G loss: 0.289020]\n",
      "epoch:11 step:11172 [D loss: 0.243432, acc.: 57.81%] [G loss: 0.310537]\n",
      "epoch:11 step:11173 [D loss: 0.243201, acc.: 54.69%] [G loss: 0.295643]\n",
      "epoch:11 step:11174 [D loss: 0.236833, acc.: 59.38%] [G loss: 0.308433]\n",
      "epoch:11 step:11175 [D loss: 0.242681, acc.: 55.47%] [G loss: 0.318842]\n",
      "epoch:11 step:11176 [D loss: 0.240784, acc.: 61.72%] [G loss: 0.285936]\n",
      "epoch:11 step:11177 [D loss: 0.236017, acc.: 60.94%] [G loss: 0.304393]\n",
      "epoch:11 step:11178 [D loss: 0.230867, acc.: 58.59%] [G loss: 0.317381]\n",
      "epoch:11 step:11179 [D loss: 0.239197, acc.: 60.16%] [G loss: 0.301541]\n",
      "epoch:11 step:11180 [D loss: 0.232951, acc.: 59.38%] [G loss: 0.285146]\n",
      "epoch:11 step:11181 [D loss: 0.238119, acc.: 58.59%] [G loss: 0.299546]\n",
      "epoch:11 step:11182 [D loss: 0.232238, acc.: 60.94%] [G loss: 0.309372]\n",
      "epoch:11 step:11183 [D loss: 0.236937, acc.: 64.84%] [G loss: 0.307710]\n",
      "epoch:11 step:11184 [D loss: 0.245372, acc.: 58.59%] [G loss: 0.278929]\n",
      "epoch:11 step:11185 [D loss: 0.245037, acc.: 55.47%] [G loss: 0.327635]\n",
      "epoch:11 step:11186 [D loss: 0.240948, acc.: 55.47%] [G loss: 0.288442]\n",
      "epoch:11 step:11187 [D loss: 0.243015, acc.: 57.03%] [G loss: 0.290942]\n",
      "epoch:11 step:11188 [D loss: 0.252744, acc.: 45.31%] [G loss: 0.275511]\n",
      "epoch:11 step:11189 [D loss: 0.217814, acc.: 64.06%] [G loss: 0.308690]\n",
      "epoch:11 step:11190 [D loss: 0.248578, acc.: 54.69%] [G loss: 0.275294]\n",
      "epoch:11 step:11191 [D loss: 0.248869, acc.: 56.25%] [G loss: 0.299930]\n",
      "epoch:11 step:11192 [D loss: 0.237701, acc.: 58.59%] [G loss: 0.309875]\n",
      "epoch:11 step:11193 [D loss: 0.235307, acc.: 67.19%] [G loss: 0.291209]\n",
      "epoch:11 step:11194 [D loss: 0.222985, acc.: 60.16%] [G loss: 0.304577]\n",
      "epoch:11 step:11195 [D loss: 0.239533, acc.: 60.94%] [G loss: 0.307934]\n",
      "epoch:11 step:11196 [D loss: 0.230583, acc.: 60.16%] [G loss: 0.306799]\n",
      "epoch:11 step:11197 [D loss: 0.232927, acc.: 62.50%] [G loss: 0.310666]\n",
      "epoch:11 step:11198 [D loss: 0.253587, acc.: 52.34%] [G loss: 0.292724]\n",
      "epoch:11 step:11199 [D loss: 0.239494, acc.: 60.16%] [G loss: 0.268902]\n",
      "epoch:11 step:11200 [D loss: 0.232704, acc.: 61.72%] [G loss: 0.285614]\n",
      "epoch:11 step:11201 [D loss: 0.238665, acc.: 62.50%] [G loss: 0.310269]\n",
      "epoch:11 step:11202 [D loss: 0.246872, acc.: 56.25%] [G loss: 0.310950]\n",
      "epoch:11 step:11203 [D loss: 0.249633, acc.: 53.91%] [G loss: 0.292227]\n",
      "epoch:11 step:11204 [D loss: 0.249629, acc.: 57.03%] [G loss: 0.285219]\n",
      "epoch:11 step:11205 [D loss: 0.227502, acc.: 64.84%] [G loss: 0.298260]\n",
      "epoch:11 step:11206 [D loss: 0.247223, acc.: 51.56%] [G loss: 0.302772]\n",
      "epoch:11 step:11207 [D loss: 0.249159, acc.: 55.47%] [G loss: 0.318517]\n",
      "epoch:11 step:11208 [D loss: 0.241303, acc.: 57.03%] [G loss: 0.313356]\n",
      "epoch:11 step:11209 [D loss: 0.236463, acc.: 57.03%] [G loss: 0.302600]\n",
      "epoch:11 step:11210 [D loss: 0.244397, acc.: 58.59%] [G loss: 0.294772]\n",
      "epoch:11 step:11211 [D loss: 0.237118, acc.: 61.72%] [G loss: 0.334921]\n",
      "epoch:11 step:11212 [D loss: 0.244017, acc.: 54.69%] [G loss: 0.305815]\n",
      "epoch:11 step:11213 [D loss: 0.239319, acc.: 61.72%] [G loss: 0.284023]\n",
      "epoch:11 step:11214 [D loss: 0.248773, acc.: 54.69%] [G loss: 0.297261]\n",
      "epoch:11 step:11215 [D loss: 0.234443, acc.: 59.38%] [G loss: 0.295180]\n",
      "epoch:11 step:11216 [D loss: 0.244468, acc.: 58.59%] [G loss: 0.276833]\n",
      "epoch:11 step:11217 [D loss: 0.247768, acc.: 55.47%] [G loss: 0.304292]\n",
      "epoch:11 step:11218 [D loss: 0.226870, acc.: 65.62%] [G loss: 0.315573]\n",
      "epoch:11 step:11219 [D loss: 0.249789, acc.: 54.69%] [G loss: 0.317861]\n",
      "epoch:11 step:11220 [D loss: 0.235945, acc.: 60.16%] [G loss: 0.297458]\n",
      "epoch:11 step:11221 [D loss: 0.255715, acc.: 50.00%] [G loss: 0.289209]\n",
      "epoch:11 step:11222 [D loss: 0.240265, acc.: 58.59%] [G loss: 0.291701]\n",
      "epoch:11 step:11223 [D loss: 0.239295, acc.: 57.81%] [G loss: 0.280989]\n",
      "epoch:11 step:11224 [D loss: 0.237775, acc.: 60.94%] [G loss: 0.315860]\n",
      "epoch:11 step:11225 [D loss: 0.239323, acc.: 56.25%] [G loss: 0.287018]\n",
      "epoch:11 step:11226 [D loss: 0.224889, acc.: 63.28%] [G loss: 0.323984]\n",
      "epoch:11 step:11227 [D loss: 0.239676, acc.: 57.03%] [G loss: 0.300034]\n",
      "epoch:11 step:11228 [D loss: 0.231586, acc.: 62.50%] [G loss: 0.323501]\n",
      "epoch:11 step:11229 [D loss: 0.227565, acc.: 66.41%] [G loss: 0.283306]\n",
      "epoch:11 step:11230 [D loss: 0.268337, acc.: 48.44%] [G loss: 0.297610]\n",
      "epoch:11 step:11231 [D loss: 0.236054, acc.: 59.38%] [G loss: 0.293752]\n",
      "epoch:11 step:11232 [D loss: 0.235068, acc.: 58.59%] [G loss: 0.305529]\n",
      "epoch:11 step:11233 [D loss: 0.231622, acc.: 61.72%] [G loss: 0.304419]\n",
      "epoch:11 step:11234 [D loss: 0.249909, acc.: 54.69%] [G loss: 0.278277]\n",
      "epoch:11 step:11235 [D loss: 0.225879, acc.: 58.59%] [G loss: 0.306406]\n",
      "epoch:11 step:11236 [D loss: 0.258051, acc.: 49.22%] [G loss: 0.296446]\n",
      "epoch:11 step:11237 [D loss: 0.245832, acc.: 47.66%] [G loss: 0.293708]\n",
      "epoch:11 step:11238 [D loss: 0.247951, acc.: 57.03%] [G loss: 0.277905]\n",
      "epoch:11 step:11239 [D loss: 0.251733, acc.: 57.81%] [G loss: 0.299089]\n",
      "epoch:11 step:11240 [D loss: 0.243706, acc.: 56.25%] [G loss: 0.296818]\n",
      "epoch:11 step:11241 [D loss: 0.230835, acc.: 64.06%] [G loss: 0.305694]\n",
      "epoch:11 step:11242 [D loss: 0.226181, acc.: 61.72%] [G loss: 0.318469]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:11 step:11243 [D loss: 0.248933, acc.: 54.69%] [G loss: 0.279140]\n",
      "epoch:11 step:11244 [D loss: 0.237219, acc.: 56.25%] [G loss: 0.338827]\n",
      "epoch:12 step:11245 [D loss: 0.251764, acc.: 54.69%] [G loss: 0.332460]\n",
      "epoch:12 step:11246 [D loss: 0.236067, acc.: 61.72%] [G loss: 0.287538]\n",
      "epoch:12 step:11247 [D loss: 0.245767, acc.: 57.03%] [G loss: 0.293062]\n",
      "epoch:12 step:11248 [D loss: 0.230594, acc.: 66.41%] [G loss: 0.295041]\n",
      "epoch:12 step:11249 [D loss: 0.248824, acc.: 52.34%] [G loss: 0.307561]\n",
      "epoch:12 step:11250 [D loss: 0.263410, acc.: 45.31%] [G loss: 0.301451]\n",
      "epoch:12 step:11251 [D loss: 0.263180, acc.: 50.00%] [G loss: 0.263791]\n",
      "epoch:12 step:11252 [D loss: 0.232126, acc.: 60.94%] [G loss: 0.285046]\n",
      "epoch:12 step:11253 [D loss: 0.234405, acc.: 60.94%] [G loss: 0.313209]\n",
      "epoch:12 step:11254 [D loss: 0.248054, acc.: 55.47%] [G loss: 0.298660]\n",
      "epoch:12 step:11255 [D loss: 0.238997, acc.: 60.16%] [G loss: 0.279801]\n",
      "epoch:12 step:11256 [D loss: 0.247666, acc.: 53.91%] [G loss: 0.307895]\n",
      "epoch:12 step:11257 [D loss: 0.251777, acc.: 53.12%] [G loss: 0.289474]\n",
      "epoch:12 step:11258 [D loss: 0.222290, acc.: 68.75%] [G loss: 0.287968]\n",
      "epoch:12 step:11259 [D loss: 0.239465, acc.: 57.81%] [G loss: 0.294233]\n",
      "epoch:12 step:11260 [D loss: 0.233612, acc.: 58.59%] [G loss: 0.281144]\n",
      "epoch:12 step:11261 [D loss: 0.238500, acc.: 60.16%] [G loss: 0.321370]\n",
      "epoch:12 step:11262 [D loss: 0.256539, acc.: 49.22%] [G loss: 0.280987]\n",
      "epoch:12 step:11263 [D loss: 0.250439, acc.: 58.59%] [G loss: 0.296799]\n",
      "epoch:12 step:11264 [D loss: 0.239584, acc.: 57.81%] [G loss: 0.268561]\n",
      "epoch:12 step:11265 [D loss: 0.243566, acc.: 59.38%] [G loss: 0.326432]\n",
      "epoch:12 step:11266 [D loss: 0.249724, acc.: 57.03%] [G loss: 0.298940]\n",
      "epoch:12 step:11267 [D loss: 0.251527, acc.: 50.00%] [G loss: 0.334322]\n",
      "epoch:12 step:11268 [D loss: 0.229475, acc.: 56.25%] [G loss: 0.290757]\n",
      "epoch:12 step:11269 [D loss: 0.240886, acc.: 57.81%] [G loss: 0.290140]\n",
      "epoch:12 step:11270 [D loss: 0.246028, acc.: 56.25%] [G loss: 0.290437]\n",
      "epoch:12 step:11271 [D loss: 0.235218, acc.: 64.06%] [G loss: 0.298061]\n",
      "epoch:12 step:11272 [D loss: 0.243340, acc.: 51.56%] [G loss: 0.299830]\n",
      "epoch:12 step:11273 [D loss: 0.247086, acc.: 57.03%] [G loss: 0.302529]\n",
      "epoch:12 step:11274 [D loss: 0.241143, acc.: 55.47%] [G loss: 0.285614]\n",
      "epoch:12 step:11275 [D loss: 0.235985, acc.: 60.16%] [G loss: 0.278947]\n",
      "epoch:12 step:11276 [D loss: 0.255585, acc.: 51.56%] [G loss: 0.276337]\n",
      "epoch:12 step:11277 [D loss: 0.240893, acc.: 57.81%] [G loss: 0.309154]\n",
      "epoch:12 step:11278 [D loss: 0.220839, acc.: 64.06%] [G loss: 0.313022]\n",
      "epoch:12 step:11279 [D loss: 0.229030, acc.: 60.94%] [G loss: 0.296130]\n",
      "epoch:12 step:11280 [D loss: 0.236357, acc.: 60.94%] [G loss: 0.307346]\n",
      "epoch:12 step:11281 [D loss: 0.231022, acc.: 64.06%] [G loss: 0.298694]\n",
      "epoch:12 step:11282 [D loss: 0.239744, acc.: 57.03%] [G loss: 0.295561]\n",
      "epoch:12 step:11283 [D loss: 0.231010, acc.: 63.28%] [G loss: 0.303455]\n",
      "epoch:12 step:11284 [D loss: 0.244797, acc.: 54.69%] [G loss: 0.273973]\n",
      "epoch:12 step:11285 [D loss: 0.230284, acc.: 66.41%] [G loss: 0.318919]\n",
      "epoch:12 step:11286 [D loss: 0.232310, acc.: 58.59%] [G loss: 0.308853]\n",
      "epoch:12 step:11287 [D loss: 0.235824, acc.: 57.81%] [G loss: 0.309503]\n",
      "epoch:12 step:11288 [D loss: 0.230744, acc.: 59.38%] [G loss: 0.276380]\n",
      "epoch:12 step:11289 [D loss: 0.252353, acc.: 55.47%] [G loss: 0.303498]\n",
      "epoch:12 step:11290 [D loss: 0.235963, acc.: 61.72%] [G loss: 0.277541]\n",
      "epoch:12 step:11291 [D loss: 0.263336, acc.: 50.78%] [G loss: 0.275253]\n",
      "epoch:12 step:11292 [D loss: 0.236678, acc.: 64.06%] [G loss: 0.312145]\n",
      "epoch:12 step:11293 [D loss: 0.233986, acc.: 59.38%] [G loss: 0.285194]\n",
      "epoch:12 step:11294 [D loss: 0.233738, acc.: 60.94%] [G loss: 0.306074]\n",
      "epoch:12 step:11295 [D loss: 0.238576, acc.: 59.38%] [G loss: 0.267353]\n",
      "epoch:12 step:11296 [D loss: 0.222368, acc.: 67.19%] [G loss: 0.279006]\n",
      "epoch:12 step:11297 [D loss: 0.233857, acc.: 56.25%] [G loss: 0.338699]\n",
      "epoch:12 step:11298 [D loss: 0.234329, acc.: 62.50%] [G loss: 0.287872]\n",
      "epoch:12 step:11299 [D loss: 0.230713, acc.: 62.50%] [G loss: 0.312485]\n",
      "epoch:12 step:11300 [D loss: 0.246925, acc.: 56.25%] [G loss: 0.295020]\n",
      "epoch:12 step:11301 [D loss: 0.251819, acc.: 53.12%] [G loss: 0.297300]\n",
      "epoch:12 step:11302 [D loss: 0.229681, acc.: 64.06%] [G loss: 0.296597]\n",
      "epoch:12 step:11303 [D loss: 0.229365, acc.: 57.81%] [G loss: 0.284931]\n",
      "epoch:12 step:11304 [D loss: 0.235144, acc.: 62.50%] [G loss: 0.287175]\n",
      "epoch:12 step:11305 [D loss: 0.239633, acc.: 56.25%] [G loss: 0.301076]\n",
      "epoch:12 step:11306 [D loss: 0.244667, acc.: 57.03%] [G loss: 0.316094]\n",
      "epoch:12 step:11307 [D loss: 0.247339, acc.: 51.56%] [G loss: 0.287842]\n",
      "epoch:12 step:11308 [D loss: 0.244076, acc.: 56.25%] [G loss: 0.288841]\n",
      "epoch:12 step:11309 [D loss: 0.228623, acc.: 65.62%] [G loss: 0.293776]\n",
      "epoch:12 step:11310 [D loss: 0.250211, acc.: 54.69%] [G loss: 0.313364]\n",
      "epoch:12 step:11311 [D loss: 0.245197, acc.: 56.25%] [G loss: 0.318173]\n",
      "epoch:12 step:11312 [D loss: 0.231695, acc.: 62.50%] [G loss: 0.292657]\n",
      "epoch:12 step:11313 [D loss: 0.251934, acc.: 53.12%] [G loss: 0.298589]\n",
      "epoch:12 step:11314 [D loss: 0.240174, acc.: 56.25%] [G loss: 0.294915]\n",
      "epoch:12 step:11315 [D loss: 0.242676, acc.: 58.59%] [G loss: 0.285841]\n",
      "epoch:12 step:11316 [D loss: 0.234270, acc.: 59.38%] [G loss: 0.294358]\n",
      "epoch:12 step:11317 [D loss: 0.238580, acc.: 56.25%] [G loss: 0.290796]\n",
      "epoch:12 step:11318 [D loss: 0.233161, acc.: 63.28%] [G loss: 0.292219]\n",
      "epoch:12 step:11319 [D loss: 0.239762, acc.: 58.59%] [G loss: 0.301174]\n",
      "epoch:12 step:11320 [D loss: 0.241145, acc.: 60.16%] [G loss: 0.301492]\n",
      "epoch:12 step:11321 [D loss: 0.233558, acc.: 58.59%] [G loss: 0.317899]\n",
      "epoch:12 step:11322 [D loss: 0.229200, acc.: 62.50%] [G loss: 0.289041]\n",
      "epoch:12 step:11323 [D loss: 0.225263, acc.: 60.94%] [G loss: 0.286881]\n",
      "epoch:12 step:11324 [D loss: 0.234756, acc.: 57.81%] [G loss: 0.283796]\n",
      "epoch:12 step:11325 [D loss: 0.266311, acc.: 43.75%] [G loss: 0.299069]\n",
      "epoch:12 step:11326 [D loss: 0.233087, acc.: 58.59%] [G loss: 0.269362]\n",
      "epoch:12 step:11327 [D loss: 0.248392, acc.: 57.81%] [G loss: 0.309854]\n",
      "epoch:12 step:11328 [D loss: 0.248682, acc.: 52.34%] [G loss: 0.279605]\n",
      "epoch:12 step:11329 [D loss: 0.250052, acc.: 52.34%] [G loss: 0.316489]\n",
      "epoch:12 step:11330 [D loss: 0.256730, acc.: 53.91%] [G loss: 0.264849]\n",
      "epoch:12 step:11331 [D loss: 0.241020, acc.: 60.94%] [G loss: 0.301582]\n",
      "epoch:12 step:11332 [D loss: 0.235349, acc.: 61.72%] [G loss: 0.308462]\n",
      "epoch:12 step:11333 [D loss: 0.251444, acc.: 53.91%] [G loss: 0.271369]\n",
      "epoch:12 step:11334 [D loss: 0.230186, acc.: 64.06%] [G loss: 0.292588]\n",
      "epoch:12 step:11335 [D loss: 0.247710, acc.: 58.59%] [G loss: 0.275248]\n",
      "epoch:12 step:11336 [D loss: 0.241304, acc.: 56.25%] [G loss: 0.268029]\n",
      "epoch:12 step:11337 [D loss: 0.248055, acc.: 55.47%] [G loss: 0.278060]\n",
      "epoch:12 step:11338 [D loss: 0.215102, acc.: 66.41%] [G loss: 0.310843]\n",
      "epoch:12 step:11339 [D loss: 0.223468, acc.: 64.84%] [G loss: 0.312277]\n",
      "epoch:12 step:11340 [D loss: 0.229886, acc.: 61.72%] [G loss: 0.315643]\n",
      "epoch:12 step:11341 [D loss: 0.243686, acc.: 58.59%] [G loss: 0.294335]\n",
      "epoch:12 step:11342 [D loss: 0.229166, acc.: 63.28%] [G loss: 0.292852]\n",
      "epoch:12 step:11343 [D loss: 0.251116, acc.: 57.03%] [G loss: 0.280410]\n",
      "epoch:12 step:11344 [D loss: 0.265449, acc.: 49.22%] [G loss: 0.302685]\n",
      "epoch:12 step:11345 [D loss: 0.222664, acc.: 67.97%] [G loss: 0.309912]\n",
      "epoch:12 step:11346 [D loss: 0.247899, acc.: 53.12%] [G loss: 0.284501]\n",
      "epoch:12 step:11347 [D loss: 0.214941, acc.: 65.62%] [G loss: 0.319023]\n",
      "epoch:12 step:11348 [D loss: 0.247401, acc.: 60.16%] [G loss: 0.295349]\n",
      "epoch:12 step:11349 [D loss: 0.243296, acc.: 57.03%] [G loss: 0.292209]\n",
      "epoch:12 step:11350 [D loss: 0.242112, acc.: 57.81%] [G loss: 0.295126]\n",
      "epoch:12 step:11351 [D loss: 0.232424, acc.: 65.62%] [G loss: 0.270422]\n",
      "epoch:12 step:11352 [D loss: 0.240028, acc.: 57.03%] [G loss: 0.297713]\n",
      "epoch:12 step:11353 [D loss: 0.249935, acc.: 57.81%] [G loss: 0.290039]\n",
      "epoch:12 step:11354 [D loss: 0.234395, acc.: 58.59%] [G loss: 0.314076]\n",
      "epoch:12 step:11355 [D loss: 0.246321, acc.: 53.91%] [G loss: 0.301560]\n",
      "epoch:12 step:11356 [D loss: 0.230062, acc.: 62.50%] [G loss: 0.320932]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:12 step:11357 [D loss: 0.257403, acc.: 51.56%] [G loss: 0.273792]\n",
      "epoch:12 step:11358 [D loss: 0.229229, acc.: 64.06%] [G loss: 0.296553]\n",
      "epoch:12 step:11359 [D loss: 0.241533, acc.: 66.41%] [G loss: 0.316932]\n",
      "epoch:12 step:11360 [D loss: 0.239031, acc.: 58.59%] [G loss: 0.289592]\n",
      "epoch:12 step:11361 [D loss: 0.234198, acc.: 60.94%] [G loss: 0.311243]\n",
      "epoch:12 step:11362 [D loss: 0.224748, acc.: 69.53%] [G loss: 0.289861]\n",
      "epoch:12 step:11363 [D loss: 0.235209, acc.: 58.59%] [G loss: 0.280115]\n",
      "epoch:12 step:11364 [D loss: 0.257429, acc.: 53.91%] [G loss: 0.296453]\n",
      "epoch:12 step:11365 [D loss: 0.255661, acc.: 53.91%] [G loss: 0.282873]\n",
      "epoch:12 step:11366 [D loss: 0.253036, acc.: 52.34%] [G loss: 0.282029]\n",
      "epoch:12 step:11367 [D loss: 0.256180, acc.: 51.56%] [G loss: 0.302337]\n",
      "epoch:12 step:11368 [D loss: 0.231723, acc.: 58.59%] [G loss: 0.308175]\n",
      "epoch:12 step:11369 [D loss: 0.234246, acc.: 61.72%] [G loss: 0.319675]\n",
      "epoch:12 step:11370 [D loss: 0.222716, acc.: 67.19%] [G loss: 0.289086]\n",
      "epoch:12 step:11371 [D loss: 0.256157, acc.: 52.34%] [G loss: 0.264811]\n",
      "epoch:12 step:11372 [D loss: 0.236982, acc.: 60.16%] [G loss: 0.294752]\n",
      "epoch:12 step:11373 [D loss: 0.238242, acc.: 52.34%] [G loss: 0.319831]\n",
      "epoch:12 step:11374 [D loss: 0.224765, acc.: 66.41%] [G loss: 0.293666]\n",
      "epoch:12 step:11375 [D loss: 0.241053, acc.: 58.59%] [G loss: 0.308512]\n",
      "epoch:12 step:11376 [D loss: 0.251632, acc.: 53.91%] [G loss: 0.290530]\n",
      "epoch:12 step:11377 [D loss: 0.230804, acc.: 60.94%] [G loss: 0.303721]\n",
      "epoch:12 step:11378 [D loss: 0.245699, acc.: 52.34%] [G loss: 0.299255]\n",
      "epoch:12 step:11379 [D loss: 0.249522, acc.: 58.59%] [G loss: 0.327451]\n",
      "epoch:12 step:11380 [D loss: 0.246121, acc.: 52.34%] [G loss: 0.319758]\n",
      "epoch:12 step:11381 [D loss: 0.241609, acc.: 62.50%] [G loss: 0.304900]\n",
      "epoch:12 step:11382 [D loss: 0.233213, acc.: 60.16%] [G loss: 0.279063]\n",
      "epoch:12 step:11383 [D loss: 0.220354, acc.: 63.28%] [G loss: 0.305865]\n",
      "epoch:12 step:11384 [D loss: 0.248010, acc.: 53.91%] [G loss: 0.295510]\n",
      "epoch:12 step:11385 [D loss: 0.257175, acc.: 47.66%] [G loss: 0.300512]\n",
      "epoch:12 step:11386 [D loss: 0.242344, acc.: 64.06%] [G loss: 0.295503]\n",
      "epoch:12 step:11387 [D loss: 0.242657, acc.: 52.34%] [G loss: 0.298909]\n",
      "epoch:12 step:11388 [D loss: 0.245070, acc.: 54.69%] [G loss: 0.276978]\n",
      "epoch:12 step:11389 [D loss: 0.235103, acc.: 57.03%] [G loss: 0.317189]\n",
      "epoch:12 step:11390 [D loss: 0.240796, acc.: 56.25%] [G loss: 0.275812]\n",
      "epoch:12 step:11391 [D loss: 0.251864, acc.: 53.12%] [G loss: 0.284756]\n",
      "epoch:12 step:11392 [D loss: 0.222656, acc.: 62.50%] [G loss: 0.293548]\n",
      "epoch:12 step:11393 [D loss: 0.256375, acc.: 50.00%] [G loss: 0.290017]\n",
      "epoch:12 step:11394 [D loss: 0.244039, acc.: 49.22%] [G loss: 0.294406]\n",
      "epoch:12 step:11395 [D loss: 0.257262, acc.: 52.34%] [G loss: 0.283152]\n",
      "epoch:12 step:11396 [D loss: 0.236038, acc.: 60.16%] [G loss: 0.323736]\n",
      "epoch:12 step:11397 [D loss: 0.254737, acc.: 49.22%] [G loss: 0.290610]\n",
      "epoch:12 step:11398 [D loss: 0.237948, acc.: 59.38%] [G loss: 0.282513]\n",
      "epoch:12 step:11399 [D loss: 0.256707, acc.: 51.56%] [G loss: 0.277494]\n",
      "epoch:12 step:11400 [D loss: 0.252190, acc.: 53.12%] [G loss: 0.305654]\n",
      "epoch:12 step:11401 [D loss: 0.235522, acc.: 64.06%] [G loss: 0.316993]\n",
      "epoch:12 step:11402 [D loss: 0.240494, acc.: 58.59%] [G loss: 0.319705]\n",
      "epoch:12 step:11403 [D loss: 0.231850, acc.: 60.94%] [G loss: 0.281411]\n",
      "epoch:12 step:11404 [D loss: 0.238480, acc.: 57.03%] [G loss: 0.294382]\n",
      "epoch:12 step:11405 [D loss: 0.238018, acc.: 56.25%] [G loss: 0.305799]\n",
      "epoch:12 step:11406 [D loss: 0.241632, acc.: 57.03%] [G loss: 0.283064]\n",
      "epoch:12 step:11407 [D loss: 0.256468, acc.: 53.12%] [G loss: 0.321489]\n",
      "epoch:12 step:11408 [D loss: 0.239771, acc.: 57.03%] [G loss: 0.282634]\n",
      "epoch:12 step:11409 [D loss: 0.257667, acc.: 53.12%] [G loss: 0.296561]\n",
      "epoch:12 step:11410 [D loss: 0.231224, acc.: 62.50%] [G loss: 0.283394]\n",
      "epoch:12 step:11411 [D loss: 0.234331, acc.: 60.16%] [G loss: 0.298958]\n",
      "epoch:12 step:11412 [D loss: 0.238986, acc.: 57.81%] [G loss: 0.301618]\n",
      "epoch:12 step:11413 [D loss: 0.250987, acc.: 56.25%] [G loss: 0.300207]\n",
      "epoch:12 step:11414 [D loss: 0.213862, acc.: 69.53%] [G loss: 0.303179]\n",
      "epoch:12 step:11415 [D loss: 0.240250, acc.: 57.03%] [G loss: 0.301210]\n",
      "epoch:12 step:11416 [D loss: 0.226868, acc.: 65.62%] [G loss: 0.305066]\n",
      "epoch:12 step:11417 [D loss: 0.243769, acc.: 54.69%] [G loss: 0.311913]\n",
      "epoch:12 step:11418 [D loss: 0.232590, acc.: 57.81%] [G loss: 0.312830]\n",
      "epoch:12 step:11419 [D loss: 0.232795, acc.: 61.72%] [G loss: 0.314111]\n",
      "epoch:12 step:11420 [D loss: 0.233798, acc.: 64.06%] [G loss: 0.304671]\n",
      "epoch:12 step:11421 [D loss: 0.207276, acc.: 68.75%] [G loss: 0.310894]\n",
      "epoch:12 step:11422 [D loss: 0.253349, acc.: 53.12%] [G loss: 0.281281]\n",
      "epoch:12 step:11423 [D loss: 0.251538, acc.: 53.91%] [G loss: 0.310377]\n",
      "epoch:12 step:11424 [D loss: 0.242145, acc.: 55.47%] [G loss: 0.300276]\n",
      "epoch:12 step:11425 [D loss: 0.242805, acc.: 57.03%] [G loss: 0.276854]\n",
      "epoch:12 step:11426 [D loss: 0.242856, acc.: 53.12%] [G loss: 0.320339]\n",
      "epoch:12 step:11427 [D loss: 0.247582, acc.: 53.12%] [G loss: 0.298448]\n",
      "epoch:12 step:11428 [D loss: 0.261981, acc.: 48.44%] [G loss: 0.283205]\n",
      "epoch:12 step:11429 [D loss: 0.251855, acc.: 52.34%] [G loss: 0.313603]\n",
      "epoch:12 step:11430 [D loss: 0.243771, acc.: 56.25%] [G loss: 0.301292]\n",
      "epoch:12 step:11431 [D loss: 0.212361, acc.: 71.09%] [G loss: 0.321063]\n",
      "epoch:12 step:11432 [D loss: 0.236826, acc.: 60.16%] [G loss: 0.291002]\n",
      "epoch:12 step:11433 [D loss: 0.246667, acc.: 53.12%] [G loss: 0.313521]\n",
      "epoch:12 step:11434 [D loss: 0.234219, acc.: 61.72%] [G loss: 0.298928]\n",
      "epoch:12 step:11435 [D loss: 0.239678, acc.: 60.16%] [G loss: 0.310153]\n",
      "epoch:12 step:11436 [D loss: 0.227943, acc.: 67.19%] [G loss: 0.307633]\n",
      "epoch:12 step:11437 [D loss: 0.244514, acc.: 57.03%] [G loss: 0.315046]\n",
      "epoch:12 step:11438 [D loss: 0.242112, acc.: 60.16%] [G loss: 0.300505]\n",
      "epoch:12 step:11439 [D loss: 0.241150, acc.: 57.03%] [G loss: 0.286691]\n",
      "epoch:12 step:11440 [D loss: 0.246229, acc.: 56.25%] [G loss: 0.283549]\n",
      "epoch:12 step:11441 [D loss: 0.220443, acc.: 63.28%] [G loss: 0.302998]\n",
      "epoch:12 step:11442 [D loss: 0.241292, acc.: 62.50%] [G loss: 0.319358]\n",
      "epoch:12 step:11443 [D loss: 0.251181, acc.: 51.56%] [G loss: 0.299695]\n",
      "epoch:12 step:11444 [D loss: 0.259042, acc.: 50.00%] [G loss: 0.273798]\n",
      "epoch:12 step:11445 [D loss: 0.232020, acc.: 62.50%] [G loss: 0.327616]\n",
      "epoch:12 step:11446 [D loss: 0.229897, acc.: 64.84%] [G loss: 0.291967]\n",
      "epoch:12 step:11447 [D loss: 0.245729, acc.: 59.38%] [G loss: 0.288449]\n",
      "epoch:12 step:11448 [D loss: 0.238344, acc.: 58.59%] [G loss: 0.291010]\n",
      "epoch:12 step:11449 [D loss: 0.253690, acc.: 52.34%] [G loss: 0.276191]\n",
      "epoch:12 step:11450 [D loss: 0.242920, acc.: 57.81%] [G loss: 0.305065]\n",
      "epoch:12 step:11451 [D loss: 0.232233, acc.: 57.03%] [G loss: 0.286716]\n",
      "epoch:12 step:11452 [D loss: 0.225356, acc.: 67.19%] [G loss: 0.300542]\n",
      "epoch:12 step:11453 [D loss: 0.235376, acc.: 61.72%] [G loss: 0.309821]\n",
      "epoch:12 step:11454 [D loss: 0.231101, acc.: 61.72%] [G loss: 0.290608]\n",
      "epoch:12 step:11455 [D loss: 0.221112, acc.: 64.84%] [G loss: 0.319357]\n",
      "epoch:12 step:11456 [D loss: 0.237284, acc.: 58.59%] [G loss: 0.286004]\n",
      "epoch:12 step:11457 [D loss: 0.231657, acc.: 59.38%] [G loss: 0.316721]\n",
      "epoch:12 step:11458 [D loss: 0.247715, acc.: 51.56%] [G loss: 0.292559]\n",
      "epoch:12 step:11459 [D loss: 0.236924, acc.: 62.50%] [G loss: 0.284177]\n",
      "epoch:12 step:11460 [D loss: 0.234750, acc.: 59.38%] [G loss: 0.308521]\n",
      "epoch:12 step:11461 [D loss: 0.218542, acc.: 68.75%] [G loss: 0.332238]\n",
      "epoch:12 step:11462 [D loss: 0.242313, acc.: 60.94%] [G loss: 0.295359]\n",
      "epoch:12 step:11463 [D loss: 0.244923, acc.: 57.03%] [G loss: 0.287198]\n",
      "epoch:12 step:11464 [D loss: 0.245325, acc.: 54.69%] [G loss: 0.309444]\n",
      "epoch:12 step:11465 [D loss: 0.214917, acc.: 71.88%] [G loss: 0.296640]\n",
      "epoch:12 step:11466 [D loss: 0.244411, acc.: 55.47%] [G loss: 0.304837]\n",
      "epoch:12 step:11467 [D loss: 0.240862, acc.: 59.38%] [G loss: 0.314760]\n",
      "epoch:12 step:11468 [D loss: 0.231588, acc.: 57.81%] [G loss: 0.294814]\n",
      "epoch:12 step:11469 [D loss: 0.231294, acc.: 60.94%] [G loss: 0.323155]\n",
      "epoch:12 step:11470 [D loss: 0.234589, acc.: 61.72%] [G loss: 0.286401]\n",
      "epoch:12 step:11471 [D loss: 0.234780, acc.: 62.50%] [G loss: 0.296339]\n",
      "epoch:12 step:11472 [D loss: 0.227059, acc.: 64.06%] [G loss: 0.316732]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:12 step:11473 [D loss: 0.244379, acc.: 57.03%] [G loss: 0.304639]\n",
      "epoch:12 step:11474 [D loss: 0.247926, acc.: 53.12%] [G loss: 0.292279]\n",
      "epoch:12 step:11475 [D loss: 0.241446, acc.: 56.25%] [G loss: 0.297838]\n",
      "epoch:12 step:11476 [D loss: 0.244806, acc.: 55.47%] [G loss: 0.300150]\n",
      "epoch:12 step:11477 [D loss: 0.249968, acc.: 55.47%] [G loss: 0.279893]\n",
      "epoch:12 step:11478 [D loss: 0.236316, acc.: 58.59%] [G loss: 0.304411]\n",
      "epoch:12 step:11479 [D loss: 0.229679, acc.: 64.84%] [G loss: 0.304939]\n",
      "epoch:12 step:11480 [D loss: 0.240135, acc.: 53.12%] [G loss: 0.300643]\n",
      "epoch:12 step:11481 [D loss: 0.228933, acc.: 64.06%] [G loss: 0.309474]\n",
      "epoch:12 step:11482 [D loss: 0.238652, acc.: 61.72%] [G loss: 0.276881]\n",
      "epoch:12 step:11483 [D loss: 0.241159, acc.: 57.81%] [G loss: 0.316193]\n",
      "epoch:12 step:11484 [D loss: 0.241059, acc.: 60.94%] [G loss: 0.286484]\n",
      "epoch:12 step:11485 [D loss: 0.250879, acc.: 51.56%] [G loss: 0.299467]\n",
      "epoch:12 step:11486 [D loss: 0.229910, acc.: 63.28%] [G loss: 0.290763]\n",
      "epoch:12 step:11487 [D loss: 0.237889, acc.: 60.16%] [G loss: 0.270710]\n",
      "epoch:12 step:11488 [D loss: 0.234690, acc.: 60.16%] [G loss: 0.286643]\n",
      "epoch:12 step:11489 [D loss: 0.264731, acc.: 43.75%] [G loss: 0.300175]\n",
      "epoch:12 step:11490 [D loss: 0.237159, acc.: 59.38%] [G loss: 0.336684]\n",
      "epoch:12 step:11491 [D loss: 0.243005, acc.: 53.91%] [G loss: 0.282505]\n",
      "epoch:12 step:11492 [D loss: 0.239952, acc.: 54.69%] [G loss: 0.287317]\n",
      "epoch:12 step:11493 [D loss: 0.253480, acc.: 50.78%] [G loss: 0.302952]\n",
      "epoch:12 step:11494 [D loss: 0.258664, acc.: 46.09%] [G loss: 0.308948]\n",
      "epoch:12 step:11495 [D loss: 0.231867, acc.: 62.50%] [G loss: 0.333894]\n",
      "epoch:12 step:11496 [D loss: 0.230958, acc.: 62.50%] [G loss: 0.294463]\n",
      "epoch:12 step:11497 [D loss: 0.243067, acc.: 54.69%] [G loss: 0.302015]\n",
      "epoch:12 step:11498 [D loss: 0.248584, acc.: 54.69%] [G loss: 0.320316]\n",
      "epoch:12 step:11499 [D loss: 0.237901, acc.: 54.69%] [G loss: 0.307864]\n",
      "epoch:12 step:11500 [D loss: 0.236708, acc.: 62.50%] [G loss: 0.309245]\n",
      "epoch:12 step:11501 [D loss: 0.238329, acc.: 64.06%] [G loss: 0.278180]\n",
      "epoch:12 step:11502 [D loss: 0.232355, acc.: 63.28%] [G loss: 0.304473]\n",
      "epoch:12 step:11503 [D loss: 0.245400, acc.: 56.25%] [G loss: 0.295152]\n",
      "epoch:12 step:11504 [D loss: 0.243365, acc.: 51.56%] [G loss: 0.294112]\n",
      "epoch:12 step:11505 [D loss: 0.221116, acc.: 67.97%] [G loss: 0.314536]\n",
      "epoch:12 step:11506 [D loss: 0.256326, acc.: 51.56%] [G loss: 0.301888]\n",
      "epoch:12 step:11507 [D loss: 0.246843, acc.: 58.59%] [G loss: 0.289908]\n",
      "epoch:12 step:11508 [D loss: 0.245601, acc.: 57.81%] [G loss: 0.288380]\n",
      "epoch:12 step:11509 [D loss: 0.239484, acc.: 59.38%] [G loss: 0.309692]\n",
      "epoch:12 step:11510 [D loss: 0.246048, acc.: 56.25%] [G loss: 0.283900]\n",
      "epoch:12 step:11511 [D loss: 0.235666, acc.: 62.50%] [G loss: 0.297193]\n",
      "epoch:12 step:11512 [D loss: 0.236961, acc.: 57.03%] [G loss: 0.310568]\n",
      "epoch:12 step:11513 [D loss: 0.235940, acc.: 60.94%] [G loss: 0.299701]\n",
      "epoch:12 step:11514 [D loss: 0.241508, acc.: 55.47%] [G loss: 0.310810]\n",
      "epoch:12 step:11515 [D loss: 0.229558, acc.: 66.41%] [G loss: 0.311688]\n",
      "epoch:12 step:11516 [D loss: 0.247040, acc.: 59.38%] [G loss: 0.272741]\n",
      "epoch:12 step:11517 [D loss: 0.240012, acc.: 55.47%] [G loss: 0.287234]\n",
      "epoch:12 step:11518 [D loss: 0.257598, acc.: 50.78%] [G loss: 0.311771]\n",
      "epoch:12 step:11519 [D loss: 0.249388, acc.: 60.16%] [G loss: 0.298595]\n",
      "epoch:12 step:11520 [D loss: 0.242995, acc.: 60.16%] [G loss: 0.293152]\n",
      "epoch:12 step:11521 [D loss: 0.251572, acc.: 56.25%] [G loss: 0.313678]\n",
      "epoch:12 step:11522 [D loss: 0.252308, acc.: 54.69%] [G loss: 0.292415]\n",
      "epoch:12 step:11523 [D loss: 0.238535, acc.: 56.25%] [G loss: 0.273411]\n",
      "epoch:12 step:11524 [D loss: 0.249475, acc.: 53.12%] [G loss: 0.304829]\n",
      "epoch:12 step:11525 [D loss: 0.226079, acc.: 64.06%] [G loss: 0.289747]\n",
      "epoch:12 step:11526 [D loss: 0.246402, acc.: 57.81%] [G loss: 0.279434]\n",
      "epoch:12 step:11527 [D loss: 0.217052, acc.: 61.72%] [G loss: 0.326382]\n",
      "epoch:12 step:11528 [D loss: 0.241250, acc.: 55.47%] [G loss: 0.322758]\n",
      "epoch:12 step:11529 [D loss: 0.235901, acc.: 61.72%] [G loss: 0.298927]\n",
      "epoch:12 step:11530 [D loss: 0.226238, acc.: 67.19%] [G loss: 0.309105]\n",
      "epoch:12 step:11531 [D loss: 0.243986, acc.: 54.69%] [G loss: 0.315961]\n",
      "epoch:12 step:11532 [D loss: 0.222625, acc.: 65.62%] [G loss: 0.320133]\n",
      "epoch:12 step:11533 [D loss: 0.223233, acc.: 64.84%] [G loss: 0.313831]\n",
      "epoch:12 step:11534 [D loss: 0.230853, acc.: 63.28%] [G loss: 0.287011]\n",
      "epoch:12 step:11535 [D loss: 0.240572, acc.: 57.03%] [G loss: 0.321135]\n",
      "epoch:12 step:11536 [D loss: 0.249213, acc.: 55.47%] [G loss: 0.309836]\n",
      "epoch:12 step:11537 [D loss: 0.256150, acc.: 54.69%] [G loss: 0.298874]\n",
      "epoch:12 step:11538 [D loss: 0.238065, acc.: 53.12%] [G loss: 0.290295]\n",
      "epoch:12 step:11539 [D loss: 0.234569, acc.: 58.59%] [G loss: 0.312111]\n",
      "epoch:12 step:11540 [D loss: 0.234985, acc.: 57.03%] [G loss: 0.286464]\n",
      "epoch:12 step:11541 [D loss: 0.238252, acc.: 57.81%] [G loss: 0.303607]\n",
      "epoch:12 step:11542 [D loss: 0.263155, acc.: 50.00%] [G loss: 0.332230]\n",
      "epoch:12 step:11543 [D loss: 0.258959, acc.: 52.34%] [G loss: 0.313738]\n",
      "epoch:12 step:11544 [D loss: 0.239314, acc.: 55.47%] [G loss: 0.291778]\n",
      "epoch:12 step:11545 [D loss: 0.248048, acc.: 50.78%] [G loss: 0.323342]\n",
      "epoch:12 step:11546 [D loss: 0.229529, acc.: 67.97%] [G loss: 0.292936]\n",
      "epoch:12 step:11547 [D loss: 0.251663, acc.: 50.78%] [G loss: 0.278742]\n",
      "epoch:12 step:11548 [D loss: 0.219705, acc.: 64.06%] [G loss: 0.286769]\n",
      "epoch:12 step:11549 [D loss: 0.251145, acc.: 49.22%] [G loss: 0.292444]\n",
      "epoch:12 step:11550 [D loss: 0.236929, acc.: 61.72%] [G loss: 0.300987]\n",
      "epoch:12 step:11551 [D loss: 0.242189, acc.: 52.34%] [G loss: 0.298857]\n",
      "epoch:12 step:11552 [D loss: 0.239683, acc.: 60.94%] [G loss: 0.300047]\n",
      "epoch:12 step:11553 [D loss: 0.233994, acc.: 56.25%] [G loss: 0.297119]\n",
      "epoch:12 step:11554 [D loss: 0.232990, acc.: 59.38%] [G loss: 0.296796]\n",
      "epoch:12 step:11555 [D loss: 0.232569, acc.: 58.59%] [G loss: 0.329176]\n",
      "epoch:12 step:11556 [D loss: 0.237498, acc.: 60.94%] [G loss: 0.295115]\n",
      "epoch:12 step:11557 [D loss: 0.236568, acc.: 60.94%] [G loss: 0.312965]\n",
      "epoch:12 step:11558 [D loss: 0.229853, acc.: 64.84%] [G loss: 0.295070]\n",
      "epoch:12 step:11559 [D loss: 0.245250, acc.: 57.03%] [G loss: 0.300912]\n",
      "epoch:12 step:11560 [D loss: 0.272745, acc.: 51.56%] [G loss: 0.276859]\n",
      "epoch:12 step:11561 [D loss: 0.231070, acc.: 61.72%] [G loss: 0.306483]\n",
      "epoch:12 step:11562 [D loss: 0.248276, acc.: 54.69%] [G loss: 0.294165]\n",
      "epoch:12 step:11563 [D loss: 0.244514, acc.: 54.69%] [G loss: 0.284957]\n",
      "epoch:12 step:11564 [D loss: 0.239679, acc.: 60.16%] [G loss: 0.278002]\n",
      "epoch:12 step:11565 [D loss: 0.239489, acc.: 59.38%] [G loss: 0.311228]\n",
      "epoch:12 step:11566 [D loss: 0.235844, acc.: 60.16%] [G loss: 0.305786]\n",
      "epoch:12 step:11567 [D loss: 0.241704, acc.: 57.03%] [G loss: 0.267664]\n",
      "epoch:12 step:11568 [D loss: 0.248970, acc.: 56.25%] [G loss: 0.274622]\n",
      "epoch:12 step:11569 [D loss: 0.236227, acc.: 60.16%] [G loss: 0.303739]\n",
      "epoch:12 step:11570 [D loss: 0.262040, acc.: 47.66%] [G loss: 0.267426]\n",
      "epoch:12 step:11571 [D loss: 0.223297, acc.: 64.06%] [G loss: 0.307981]\n",
      "epoch:12 step:11572 [D loss: 0.239858, acc.: 57.81%] [G loss: 0.275901]\n",
      "epoch:12 step:11573 [D loss: 0.251960, acc.: 53.12%] [G loss: 0.287923]\n",
      "epoch:12 step:11574 [D loss: 0.236624, acc.: 57.03%] [G loss: 0.279122]\n",
      "epoch:12 step:11575 [D loss: 0.244099, acc.: 58.59%] [G loss: 0.307397]\n",
      "epoch:12 step:11576 [D loss: 0.235132, acc.: 58.59%] [G loss: 0.323277]\n",
      "epoch:12 step:11577 [D loss: 0.255759, acc.: 47.66%] [G loss: 0.288892]\n",
      "epoch:12 step:11578 [D loss: 0.241814, acc.: 55.47%] [G loss: 0.294651]\n",
      "epoch:12 step:11579 [D loss: 0.250319, acc.: 53.12%] [G loss: 0.286503]\n",
      "epoch:12 step:11580 [D loss: 0.227671, acc.: 60.16%] [G loss: 0.262738]\n",
      "epoch:12 step:11581 [D loss: 0.230100, acc.: 60.94%] [G loss: 0.300262]\n",
      "epoch:12 step:11582 [D loss: 0.235902, acc.: 61.72%] [G loss: 0.298979]\n",
      "epoch:12 step:11583 [D loss: 0.227772, acc.: 65.62%] [G loss: 0.288668]\n",
      "epoch:12 step:11584 [D loss: 0.238886, acc.: 55.47%] [G loss: 0.304130]\n",
      "epoch:12 step:11585 [D loss: 0.260151, acc.: 49.22%] [G loss: 0.289060]\n",
      "epoch:12 step:11586 [D loss: 0.222813, acc.: 64.84%] [G loss: 0.297081]\n",
      "epoch:12 step:11587 [D loss: 0.247313, acc.: 53.12%] [G loss: 0.333754]\n",
      "epoch:12 step:11588 [D loss: 0.234310, acc.: 60.16%] [G loss: 0.317401]\n",
      "epoch:12 step:11589 [D loss: 0.236575, acc.: 57.81%] [G loss: 0.315979]\n",
      "epoch:12 step:11590 [D loss: 0.251968, acc.: 57.81%] [G loss: 0.295044]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:12 step:11591 [D loss: 0.238851, acc.: 60.16%] [G loss: 0.294345]\n",
      "epoch:12 step:11592 [D loss: 0.239177, acc.: 58.59%] [G loss: 0.294026]\n",
      "epoch:12 step:11593 [D loss: 0.233145, acc.: 60.94%] [G loss: 0.291190]\n",
      "epoch:12 step:11594 [D loss: 0.243649, acc.: 57.03%] [G loss: 0.285642]\n",
      "epoch:12 step:11595 [D loss: 0.239601, acc.: 56.25%] [G loss: 0.306371]\n",
      "epoch:12 step:11596 [D loss: 0.240732, acc.: 53.12%] [G loss: 0.307599]\n",
      "epoch:12 step:11597 [D loss: 0.229145, acc.: 61.72%] [G loss: 0.313857]\n",
      "epoch:12 step:11598 [D loss: 0.249222, acc.: 53.91%] [G loss: 0.291078]\n",
      "epoch:12 step:11599 [D loss: 0.240261, acc.: 59.38%] [G loss: 0.310796]\n",
      "epoch:12 step:11600 [D loss: 0.245191, acc.: 53.91%] [G loss: 0.304501]\n",
      "epoch:12 step:11601 [D loss: 0.236825, acc.: 58.59%] [G loss: 0.316124]\n",
      "epoch:12 step:11602 [D loss: 0.230283, acc.: 60.94%] [G loss: 0.318580]\n",
      "epoch:12 step:11603 [D loss: 0.241232, acc.: 59.38%] [G loss: 0.311749]\n",
      "epoch:12 step:11604 [D loss: 0.234798, acc.: 62.50%] [G loss: 0.309126]\n",
      "epoch:12 step:11605 [D loss: 0.228258, acc.: 67.19%] [G loss: 0.277616]\n",
      "epoch:12 step:11606 [D loss: 0.240354, acc.: 57.03%] [G loss: 0.310529]\n",
      "epoch:12 step:11607 [D loss: 0.239047, acc.: 66.41%] [G loss: 0.287155]\n",
      "epoch:12 step:11608 [D loss: 0.223635, acc.: 66.41%] [G loss: 0.301128]\n",
      "epoch:12 step:11609 [D loss: 0.233128, acc.: 55.47%] [G loss: 0.319898]\n",
      "epoch:12 step:11610 [D loss: 0.232301, acc.: 54.69%] [G loss: 0.302173]\n",
      "epoch:12 step:11611 [D loss: 0.249139, acc.: 54.69%] [G loss: 0.289164]\n",
      "epoch:12 step:11612 [D loss: 0.236212, acc.: 64.84%] [G loss: 0.308997]\n",
      "epoch:12 step:11613 [D loss: 0.225576, acc.: 64.06%] [G loss: 0.344639]\n",
      "epoch:12 step:11614 [D loss: 0.226820, acc.: 66.41%] [G loss: 0.309926]\n",
      "epoch:12 step:11615 [D loss: 0.245993, acc.: 57.03%] [G loss: 0.296883]\n",
      "epoch:12 step:11616 [D loss: 0.228777, acc.: 64.84%] [G loss: 0.312460]\n",
      "epoch:12 step:11617 [D loss: 0.241908, acc.: 53.12%] [G loss: 0.285656]\n",
      "epoch:12 step:11618 [D loss: 0.253201, acc.: 53.91%] [G loss: 0.290767]\n",
      "epoch:12 step:11619 [D loss: 0.234620, acc.: 56.25%] [G loss: 0.339342]\n",
      "epoch:12 step:11620 [D loss: 0.258683, acc.: 50.78%] [G loss: 0.304308]\n",
      "epoch:12 step:11621 [D loss: 0.256849, acc.: 50.00%] [G loss: 0.281064]\n",
      "epoch:12 step:11622 [D loss: 0.248752, acc.: 51.56%] [G loss: 0.291945]\n",
      "epoch:12 step:11623 [D loss: 0.234705, acc.: 66.41%] [G loss: 0.269572]\n",
      "epoch:12 step:11624 [D loss: 0.244040, acc.: 57.03%] [G loss: 0.288625]\n",
      "epoch:12 step:11625 [D loss: 0.238899, acc.: 55.47%] [G loss: 0.302613]\n",
      "epoch:12 step:11626 [D loss: 0.250927, acc.: 52.34%] [G loss: 0.292001]\n",
      "epoch:12 step:11627 [D loss: 0.237180, acc.: 57.81%] [G loss: 0.296322]\n",
      "epoch:12 step:11628 [D loss: 0.234440, acc.: 62.50%] [G loss: 0.312278]\n",
      "epoch:12 step:11629 [D loss: 0.241443, acc.: 55.47%] [G loss: 0.321224]\n",
      "epoch:12 step:11630 [D loss: 0.239423, acc.: 58.59%] [G loss: 0.318690]\n",
      "epoch:12 step:11631 [D loss: 0.245072, acc.: 50.78%] [G loss: 0.277287]\n",
      "epoch:12 step:11632 [D loss: 0.229816, acc.: 59.38%] [G loss: 0.276302]\n",
      "epoch:12 step:11633 [D loss: 0.252876, acc.: 51.56%] [G loss: 0.302996]\n",
      "epoch:12 step:11634 [D loss: 0.221952, acc.: 61.72%] [G loss: 0.315279]\n",
      "epoch:12 step:11635 [D loss: 0.229222, acc.: 61.72%] [G loss: 0.261094]\n",
      "epoch:12 step:11636 [D loss: 0.228971, acc.: 61.72%] [G loss: 0.309417]\n",
      "epoch:12 step:11637 [D loss: 0.244049, acc.: 59.38%] [G loss: 0.275901]\n",
      "epoch:12 step:11638 [D loss: 0.234004, acc.: 64.84%] [G loss: 0.263415]\n",
      "epoch:12 step:11639 [D loss: 0.237730, acc.: 59.38%] [G loss: 0.331268]\n",
      "epoch:12 step:11640 [D loss: 0.252196, acc.: 56.25%] [G loss: 0.294228]\n",
      "epoch:12 step:11641 [D loss: 0.240456, acc.: 54.69%] [G loss: 0.312948]\n",
      "epoch:12 step:11642 [D loss: 0.247824, acc.: 57.03%] [G loss: 0.284581]\n",
      "epoch:12 step:11643 [D loss: 0.228975, acc.: 61.72%] [G loss: 0.264132]\n",
      "epoch:12 step:11644 [D loss: 0.254734, acc.: 57.81%] [G loss: 0.293126]\n",
      "epoch:12 step:11645 [D loss: 0.224827, acc.: 67.97%] [G loss: 0.307085]\n",
      "epoch:12 step:11646 [D loss: 0.233408, acc.: 57.81%] [G loss: 0.286054]\n",
      "epoch:12 step:11647 [D loss: 0.245330, acc.: 55.47%] [G loss: 0.300754]\n",
      "epoch:12 step:11648 [D loss: 0.244482, acc.: 57.81%] [G loss: 0.294687]\n",
      "epoch:12 step:11649 [D loss: 0.248669, acc.: 53.12%] [G loss: 0.286911]\n",
      "epoch:12 step:11650 [D loss: 0.258277, acc.: 51.56%] [G loss: 0.272196]\n",
      "epoch:12 step:11651 [D loss: 0.238607, acc.: 56.25%] [G loss: 0.315993]\n",
      "epoch:12 step:11652 [D loss: 0.247808, acc.: 56.25%] [G loss: 0.280103]\n",
      "epoch:12 step:11653 [D loss: 0.244989, acc.: 52.34%] [G loss: 0.314375]\n",
      "epoch:12 step:11654 [D loss: 0.248379, acc.: 53.12%] [G loss: 0.269111]\n",
      "epoch:12 step:11655 [D loss: 0.241021, acc.: 57.81%] [G loss: 0.301028]\n",
      "epoch:12 step:11656 [D loss: 0.247140, acc.: 55.47%] [G loss: 0.293877]\n",
      "epoch:12 step:11657 [D loss: 0.234821, acc.: 57.81%] [G loss: 0.308962]\n",
      "epoch:12 step:11658 [D loss: 0.257175, acc.: 49.22%] [G loss: 0.306150]\n",
      "epoch:12 step:11659 [D loss: 0.237833, acc.: 58.59%] [G loss: 0.318729]\n",
      "epoch:12 step:11660 [D loss: 0.240072, acc.: 59.38%] [G loss: 0.278380]\n",
      "epoch:12 step:11661 [D loss: 0.242217, acc.: 56.25%] [G loss: 0.297186]\n",
      "epoch:12 step:11662 [D loss: 0.242108, acc.: 56.25%] [G loss: 0.275019]\n",
      "epoch:12 step:11663 [D loss: 0.243147, acc.: 53.12%] [G loss: 0.308494]\n",
      "epoch:12 step:11664 [D loss: 0.225852, acc.: 62.50%] [G loss: 0.309496]\n",
      "epoch:12 step:11665 [D loss: 0.245862, acc.: 55.47%] [G loss: 0.273562]\n",
      "epoch:12 step:11666 [D loss: 0.227794, acc.: 63.28%] [G loss: 0.341733]\n",
      "epoch:12 step:11667 [D loss: 0.238767, acc.: 59.38%] [G loss: 0.318102]\n",
      "epoch:12 step:11668 [D loss: 0.243086, acc.: 57.81%] [G loss: 0.292172]\n",
      "epoch:12 step:11669 [D loss: 0.221867, acc.: 64.06%] [G loss: 0.337502]\n",
      "epoch:12 step:11670 [D loss: 0.250012, acc.: 46.88%] [G loss: 0.296549]\n",
      "epoch:12 step:11671 [D loss: 0.232413, acc.: 57.81%] [G loss: 0.295602]\n",
      "epoch:12 step:11672 [D loss: 0.249116, acc.: 55.47%] [G loss: 0.280351]\n",
      "epoch:12 step:11673 [D loss: 0.249949, acc.: 52.34%] [G loss: 0.308759]\n",
      "epoch:12 step:11674 [D loss: 0.239721, acc.: 61.72%] [G loss: 0.292870]\n",
      "epoch:12 step:11675 [D loss: 0.232231, acc.: 61.72%] [G loss: 0.317959]\n",
      "epoch:12 step:11676 [D loss: 0.248922, acc.: 58.59%] [G loss: 0.318136]\n",
      "epoch:12 step:11677 [D loss: 0.256393, acc.: 51.56%] [G loss: 0.296897]\n",
      "epoch:12 step:11678 [D loss: 0.247496, acc.: 57.03%] [G loss: 0.283812]\n",
      "epoch:12 step:11679 [D loss: 0.231102, acc.: 64.84%] [G loss: 0.320066]\n",
      "epoch:12 step:11680 [D loss: 0.236212, acc.: 57.03%] [G loss: 0.286367]\n",
      "epoch:12 step:11681 [D loss: 0.238416, acc.: 60.94%] [G loss: 0.295359]\n",
      "epoch:12 step:11682 [D loss: 0.241777, acc.: 62.50%] [G loss: 0.303769]\n",
      "epoch:12 step:11683 [D loss: 0.239590, acc.: 57.03%] [G loss: 0.318974]\n",
      "epoch:12 step:11684 [D loss: 0.229948, acc.: 63.28%] [G loss: 0.294738]\n",
      "epoch:12 step:11685 [D loss: 0.229264, acc.: 62.50%] [G loss: 0.348856]\n",
      "epoch:12 step:11686 [D loss: 0.236175, acc.: 61.72%] [G loss: 0.293665]\n",
      "epoch:12 step:11687 [D loss: 0.247434, acc.: 55.47%] [G loss: 0.296536]\n",
      "epoch:12 step:11688 [D loss: 0.234392, acc.: 58.59%] [G loss: 0.299566]\n",
      "epoch:12 step:11689 [D loss: 0.215578, acc.: 65.62%] [G loss: 0.326942]\n",
      "epoch:12 step:11690 [D loss: 0.240460, acc.: 56.25%] [G loss: 0.288452]\n",
      "epoch:12 step:11691 [D loss: 0.225122, acc.: 64.06%] [G loss: 0.290508]\n",
      "epoch:12 step:11692 [D loss: 0.246169, acc.: 56.25%] [G loss: 0.291645]\n",
      "epoch:12 step:11693 [D loss: 0.221675, acc.: 65.62%] [G loss: 0.284056]\n",
      "epoch:12 step:11694 [D loss: 0.231886, acc.: 64.84%] [G loss: 0.289094]\n",
      "epoch:12 step:11695 [D loss: 0.245675, acc.: 57.03%] [G loss: 0.306069]\n",
      "epoch:12 step:11696 [D loss: 0.250118, acc.: 53.12%] [G loss: 0.313742]\n",
      "epoch:12 step:11697 [D loss: 0.236547, acc.: 57.03%] [G loss: 0.320962]\n",
      "epoch:12 step:11698 [D loss: 0.234126, acc.: 58.59%] [G loss: 0.325346]\n",
      "epoch:12 step:11699 [D loss: 0.223432, acc.: 62.50%] [G loss: 0.298814]\n",
      "epoch:12 step:11700 [D loss: 0.251635, acc.: 56.25%] [G loss: 0.325931]\n",
      "epoch:12 step:11701 [D loss: 0.264976, acc.: 53.12%] [G loss: 0.294650]\n",
      "epoch:12 step:11702 [D loss: 0.243832, acc.: 58.59%] [G loss: 0.321691]\n",
      "epoch:12 step:11703 [D loss: 0.237800, acc.: 62.50%] [G loss: 0.305131]\n",
      "epoch:12 step:11704 [D loss: 0.250199, acc.: 54.69%] [G loss: 0.282042]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:12 step:11705 [D loss: 0.257568, acc.: 53.12%] [G loss: 0.293771]\n",
      "epoch:12 step:11706 [D loss: 0.258517, acc.: 51.56%] [G loss: 0.289254]\n",
      "epoch:12 step:11707 [D loss: 0.241548, acc.: 55.47%] [G loss: 0.306758]\n",
      "epoch:12 step:11708 [D loss: 0.242809, acc.: 57.03%] [G loss: 0.289999]\n",
      "epoch:12 step:11709 [D loss: 0.234185, acc.: 61.72%] [G loss: 0.320932]\n",
      "epoch:12 step:11710 [D loss: 0.234912, acc.: 59.38%] [G loss: 0.299793]\n",
      "epoch:12 step:11711 [D loss: 0.239004, acc.: 59.38%] [G loss: 0.302417]\n",
      "epoch:12 step:11712 [D loss: 0.227883, acc.: 66.41%] [G loss: 0.295643]\n",
      "epoch:12 step:11713 [D loss: 0.240426, acc.: 60.94%] [G loss: 0.254930]\n",
      "epoch:12 step:11714 [D loss: 0.238033, acc.: 60.16%] [G loss: 0.287852]\n",
      "epoch:12 step:11715 [D loss: 0.238862, acc.: 52.34%] [G loss: 0.283808]\n",
      "epoch:12 step:11716 [D loss: 0.247528, acc.: 57.03%] [G loss: 0.296412]\n",
      "epoch:12 step:11717 [D loss: 0.236444, acc.: 59.38%] [G loss: 0.291839]\n",
      "epoch:12 step:11718 [D loss: 0.242666, acc.: 53.12%] [G loss: 0.284185]\n",
      "epoch:12 step:11719 [D loss: 0.219902, acc.: 63.28%] [G loss: 0.283578]\n",
      "epoch:12 step:11720 [D loss: 0.230371, acc.: 61.72%] [G loss: 0.316529]\n",
      "epoch:12 step:11721 [D loss: 0.232088, acc.: 60.94%] [G loss: 0.297159]\n",
      "epoch:12 step:11722 [D loss: 0.233308, acc.: 60.94%] [G loss: 0.293081]\n",
      "epoch:12 step:11723 [D loss: 0.236237, acc.: 55.47%] [G loss: 0.317765]\n",
      "epoch:12 step:11724 [D loss: 0.228944, acc.: 63.28%] [G loss: 0.301882]\n",
      "epoch:12 step:11725 [D loss: 0.253431, acc.: 52.34%] [G loss: 0.271004]\n",
      "epoch:12 step:11726 [D loss: 0.247398, acc.: 56.25%] [G loss: 0.304136]\n",
      "epoch:12 step:11727 [D loss: 0.228710, acc.: 67.19%] [G loss: 0.300681]\n",
      "epoch:12 step:11728 [D loss: 0.234813, acc.: 57.81%] [G loss: 0.333285]\n",
      "epoch:12 step:11729 [D loss: 0.241564, acc.: 56.25%] [G loss: 0.303282]\n",
      "epoch:12 step:11730 [D loss: 0.234868, acc.: 59.38%] [G loss: 0.321706]\n",
      "epoch:12 step:11731 [D loss: 0.229446, acc.: 64.06%] [G loss: 0.288030]\n",
      "epoch:12 step:11732 [D loss: 0.234296, acc.: 59.38%] [G loss: 0.301489]\n",
      "epoch:12 step:11733 [D loss: 0.237251, acc.: 58.59%] [G loss: 0.296975]\n",
      "epoch:12 step:11734 [D loss: 0.236307, acc.: 57.03%] [G loss: 0.284638]\n",
      "epoch:12 step:11735 [D loss: 0.244496, acc.: 54.69%] [G loss: 0.290284]\n",
      "epoch:12 step:11736 [D loss: 0.253634, acc.: 51.56%] [G loss: 0.297147]\n",
      "epoch:12 step:11737 [D loss: 0.230863, acc.: 60.94%] [G loss: 0.300792]\n",
      "epoch:12 step:11738 [D loss: 0.240013, acc.: 58.59%] [G loss: 0.296366]\n",
      "epoch:12 step:11739 [D loss: 0.260943, acc.: 50.00%] [G loss: 0.292551]\n",
      "epoch:12 step:11740 [D loss: 0.245185, acc.: 57.03%] [G loss: 0.309021]\n",
      "epoch:12 step:11741 [D loss: 0.220689, acc.: 62.50%] [G loss: 0.334858]\n",
      "epoch:12 step:11742 [D loss: 0.237372, acc.: 59.38%] [G loss: 0.296579]\n",
      "epoch:12 step:11743 [D loss: 0.232680, acc.: 64.06%] [G loss: 0.295922]\n",
      "epoch:12 step:11744 [D loss: 0.236819, acc.: 59.38%] [G loss: 0.290354]\n",
      "epoch:12 step:11745 [D loss: 0.225478, acc.: 58.59%] [G loss: 0.311248]\n",
      "epoch:12 step:11746 [D loss: 0.231318, acc.: 59.38%] [G loss: 0.300469]\n",
      "epoch:12 step:11747 [D loss: 0.224155, acc.: 63.28%] [G loss: 0.300211]\n",
      "epoch:12 step:11748 [D loss: 0.248137, acc.: 54.69%] [G loss: 0.313269]\n",
      "epoch:12 step:11749 [D loss: 0.215042, acc.: 68.75%] [G loss: 0.297784]\n",
      "epoch:12 step:11750 [D loss: 0.239823, acc.: 60.16%] [G loss: 0.296156]\n",
      "epoch:12 step:11751 [D loss: 0.253607, acc.: 52.34%] [G loss: 0.288706]\n",
      "epoch:12 step:11752 [D loss: 0.234608, acc.: 57.03%] [G loss: 0.315102]\n",
      "epoch:12 step:11753 [D loss: 0.224194, acc.: 60.16%] [G loss: 0.313267]\n",
      "epoch:12 step:11754 [D loss: 0.235383, acc.: 57.03%] [G loss: 0.294729]\n",
      "epoch:12 step:11755 [D loss: 0.238211, acc.: 57.81%] [G loss: 0.314610]\n",
      "epoch:12 step:11756 [D loss: 0.240256, acc.: 56.25%] [G loss: 0.310006]\n",
      "epoch:12 step:11757 [D loss: 0.236597, acc.: 57.03%] [G loss: 0.305040]\n",
      "epoch:12 step:11758 [D loss: 0.246110, acc.: 53.91%] [G loss: 0.307089]\n",
      "epoch:12 step:11759 [D loss: 0.249823, acc.: 56.25%] [G loss: 0.306446]\n",
      "epoch:12 step:11760 [D loss: 0.248414, acc.: 55.47%] [G loss: 0.298669]\n",
      "epoch:12 step:11761 [D loss: 0.236776, acc.: 59.38%] [G loss: 0.329096]\n",
      "epoch:12 step:11762 [D loss: 0.240313, acc.: 60.16%] [G loss: 0.326732]\n",
      "epoch:12 step:11763 [D loss: 0.250017, acc.: 53.91%] [G loss: 0.321268]\n",
      "epoch:12 step:11764 [D loss: 0.241229, acc.: 57.81%] [G loss: 0.307087]\n",
      "epoch:12 step:11765 [D loss: 0.233680, acc.: 57.81%] [G loss: 0.282806]\n",
      "epoch:12 step:11766 [D loss: 0.248805, acc.: 58.59%] [G loss: 0.292081]\n",
      "epoch:12 step:11767 [D loss: 0.237366, acc.: 55.47%] [G loss: 0.299538]\n",
      "epoch:12 step:11768 [D loss: 0.241666, acc.: 55.47%] [G loss: 0.309114]\n",
      "epoch:12 step:11769 [D loss: 0.251547, acc.: 53.91%] [G loss: 0.298152]\n",
      "epoch:12 step:11770 [D loss: 0.233579, acc.: 60.94%] [G loss: 0.301054]\n",
      "epoch:12 step:11771 [D loss: 0.224674, acc.: 64.06%] [G loss: 0.283092]\n",
      "epoch:12 step:11772 [D loss: 0.234663, acc.: 61.72%] [G loss: 0.295549]\n",
      "epoch:12 step:11773 [D loss: 0.245607, acc.: 53.12%] [G loss: 0.295226]\n",
      "epoch:12 step:11774 [D loss: 0.252706, acc.: 53.91%] [G loss: 0.289796]\n",
      "epoch:12 step:11775 [D loss: 0.234740, acc.: 56.25%] [G loss: 0.318035]\n",
      "epoch:12 step:11776 [D loss: 0.234425, acc.: 60.16%] [G loss: 0.301353]\n",
      "epoch:12 step:11777 [D loss: 0.232381, acc.: 60.16%] [G loss: 0.320460]\n",
      "epoch:12 step:11778 [D loss: 0.239946, acc.: 57.81%] [G loss: 0.311712]\n",
      "epoch:12 step:11779 [D loss: 0.239863, acc.: 53.91%] [G loss: 0.290009]\n",
      "epoch:12 step:11780 [D loss: 0.239491, acc.: 54.69%] [G loss: 0.305021]\n",
      "epoch:12 step:11781 [D loss: 0.250034, acc.: 53.91%] [G loss: 0.324939]\n",
      "epoch:12 step:11782 [D loss: 0.229446, acc.: 60.16%] [G loss: 0.283205]\n",
      "epoch:12 step:11783 [D loss: 0.234124, acc.: 64.84%] [G loss: 0.304610]\n",
      "epoch:12 step:11784 [D loss: 0.241324, acc.: 58.59%] [G loss: 0.281120]\n",
      "epoch:12 step:11785 [D loss: 0.231988, acc.: 64.06%] [G loss: 0.330867]\n",
      "epoch:12 step:11786 [D loss: 0.251701, acc.: 53.12%] [G loss: 0.285943]\n",
      "epoch:12 step:11787 [D loss: 0.230003, acc.: 60.94%] [G loss: 0.297635]\n",
      "epoch:12 step:11788 [D loss: 0.243197, acc.: 60.16%] [G loss: 0.296056]\n",
      "epoch:12 step:11789 [D loss: 0.226657, acc.: 62.50%] [G loss: 0.303049]\n",
      "epoch:12 step:11790 [D loss: 0.241667, acc.: 56.25%] [G loss: 0.301869]\n",
      "epoch:12 step:11791 [D loss: 0.247524, acc.: 52.34%] [G loss: 0.322133]\n",
      "epoch:12 step:11792 [D loss: 0.239938, acc.: 57.81%] [G loss: 0.302178]\n",
      "epoch:12 step:11793 [D loss: 0.234627, acc.: 58.59%] [G loss: 0.310016]\n",
      "epoch:12 step:11794 [D loss: 0.253486, acc.: 52.34%] [G loss: 0.296528]\n",
      "epoch:12 step:11795 [D loss: 0.238386, acc.: 58.59%] [G loss: 0.322008]\n",
      "epoch:12 step:11796 [D loss: 0.237131, acc.: 59.38%] [G loss: 0.316360]\n",
      "epoch:12 step:11797 [D loss: 0.251882, acc.: 53.91%] [G loss: 0.314413]\n",
      "epoch:12 step:11798 [D loss: 0.228785, acc.: 64.06%] [G loss: 0.334238]\n",
      "epoch:12 step:11799 [D loss: 0.257764, acc.: 54.69%] [G loss: 0.302690]\n",
      "epoch:12 step:11800 [D loss: 0.231227, acc.: 64.06%] [G loss: 0.296542]\n",
      "epoch:12 step:11801 [D loss: 0.229393, acc.: 61.72%] [G loss: 0.301073]\n",
      "epoch:12 step:11802 [D loss: 0.248026, acc.: 50.00%] [G loss: 0.302093]\n",
      "epoch:12 step:11803 [D loss: 0.238950, acc.: 53.91%] [G loss: 0.288436]\n",
      "epoch:12 step:11804 [D loss: 0.248826, acc.: 52.34%] [G loss: 0.295366]\n",
      "epoch:12 step:11805 [D loss: 0.234337, acc.: 62.50%] [G loss: 0.328682]\n",
      "epoch:12 step:11806 [D loss: 0.225710, acc.: 62.50%] [G loss: 0.306421]\n",
      "epoch:12 step:11807 [D loss: 0.242929, acc.: 59.38%] [G loss: 0.294945]\n",
      "epoch:12 step:11808 [D loss: 0.220673, acc.: 63.28%] [G loss: 0.327696]\n",
      "epoch:12 step:11809 [D loss: 0.225207, acc.: 61.72%] [G loss: 0.327644]\n",
      "epoch:12 step:11810 [D loss: 0.244065, acc.: 54.69%] [G loss: 0.307754]\n",
      "epoch:12 step:11811 [D loss: 0.248639, acc.: 57.03%] [G loss: 0.280548]\n",
      "epoch:12 step:11812 [D loss: 0.248963, acc.: 53.12%] [G loss: 0.298896]\n",
      "epoch:12 step:11813 [D loss: 0.227847, acc.: 60.16%] [G loss: 0.311227]\n",
      "epoch:12 step:11814 [D loss: 0.251393, acc.: 50.78%] [G loss: 0.286091]\n",
      "epoch:12 step:11815 [D loss: 0.244411, acc.: 53.12%] [G loss: 0.280664]\n",
      "epoch:12 step:11816 [D loss: 0.238421, acc.: 60.94%] [G loss: 0.290858]\n",
      "epoch:12 step:11817 [D loss: 0.250848, acc.: 57.81%] [G loss: 0.295056]\n",
      "epoch:12 step:11818 [D loss: 0.236710, acc.: 60.94%] [G loss: 0.317478]\n",
      "epoch:12 step:11819 [D loss: 0.237383, acc.: 57.81%] [G loss: 0.326949]\n",
      "epoch:12 step:11820 [D loss: 0.220896, acc.: 65.62%] [G loss: 0.303318]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:12 step:11821 [D loss: 0.251592, acc.: 51.56%] [G loss: 0.311684]\n",
      "epoch:12 step:11822 [D loss: 0.225957, acc.: 66.41%] [G loss: 0.315695]\n",
      "epoch:12 step:11823 [D loss: 0.262658, acc.: 49.22%] [G loss: 0.305290]\n",
      "epoch:12 step:11824 [D loss: 0.244926, acc.: 57.03%] [G loss: 0.278055]\n",
      "epoch:12 step:11825 [D loss: 0.246624, acc.: 56.25%] [G loss: 0.313829]\n",
      "epoch:12 step:11826 [D loss: 0.234346, acc.: 59.38%] [G loss: 0.311138]\n",
      "epoch:12 step:11827 [D loss: 0.241960, acc.: 61.72%] [G loss: 0.302830]\n",
      "epoch:12 step:11828 [D loss: 0.238979, acc.: 59.38%] [G loss: 0.283919]\n",
      "epoch:12 step:11829 [D loss: 0.236621, acc.: 62.50%] [G loss: 0.312113]\n",
      "epoch:12 step:11830 [D loss: 0.231007, acc.: 59.38%] [G loss: 0.308643]\n",
      "epoch:12 step:11831 [D loss: 0.250603, acc.: 50.78%] [G loss: 0.291989]\n",
      "epoch:12 step:11832 [D loss: 0.233138, acc.: 59.38%] [G loss: 0.318659]\n",
      "epoch:12 step:11833 [D loss: 0.232715, acc.: 61.72%] [G loss: 0.334666]\n",
      "epoch:12 step:11834 [D loss: 0.258495, acc.: 48.44%] [G loss: 0.276228]\n",
      "epoch:12 step:11835 [D loss: 0.226424, acc.: 63.28%] [G loss: 0.300140]\n",
      "epoch:12 step:11836 [D loss: 0.233141, acc.: 58.59%] [G loss: 0.311237]\n",
      "epoch:12 step:11837 [D loss: 0.244023, acc.: 61.72%] [G loss: 0.310143]\n",
      "epoch:12 step:11838 [D loss: 0.232473, acc.: 56.25%] [G loss: 0.277749]\n",
      "epoch:12 step:11839 [D loss: 0.256789, acc.: 51.56%] [G loss: 0.287881]\n",
      "epoch:12 step:11840 [D loss: 0.235452, acc.: 62.50%] [G loss: 0.312274]\n",
      "epoch:12 step:11841 [D loss: 0.246521, acc.: 53.12%] [G loss: 0.299125]\n",
      "epoch:12 step:11842 [D loss: 0.255226, acc.: 54.69%] [G loss: 0.315445]\n",
      "epoch:12 step:11843 [D loss: 0.236802, acc.: 53.91%] [G loss: 0.307127]\n",
      "epoch:12 step:11844 [D loss: 0.229106, acc.: 61.72%] [G loss: 0.310930]\n",
      "epoch:12 step:11845 [D loss: 0.237928, acc.: 61.72%] [G loss: 0.307996]\n",
      "epoch:12 step:11846 [D loss: 0.237292, acc.: 56.25%] [G loss: 0.285236]\n",
      "epoch:12 step:11847 [D loss: 0.248680, acc.: 52.34%] [G loss: 0.309618]\n",
      "epoch:12 step:11848 [D loss: 0.248931, acc.: 58.59%] [G loss: 0.294218]\n",
      "epoch:12 step:11849 [D loss: 0.244704, acc.: 57.81%] [G loss: 0.288397]\n",
      "epoch:12 step:11850 [D loss: 0.244643, acc.: 53.91%] [G loss: 0.302221]\n",
      "epoch:12 step:11851 [D loss: 0.228660, acc.: 59.38%] [G loss: 0.302652]\n",
      "epoch:12 step:11852 [D loss: 0.245863, acc.: 53.12%] [G loss: 0.334267]\n",
      "epoch:12 step:11853 [D loss: 0.237904, acc.: 57.81%] [G loss: 0.296329]\n",
      "epoch:12 step:11854 [D loss: 0.213217, acc.: 64.06%] [G loss: 0.317651]\n",
      "epoch:12 step:11855 [D loss: 0.231745, acc.: 58.59%] [G loss: 0.292469]\n",
      "epoch:12 step:11856 [D loss: 0.228515, acc.: 64.06%] [G loss: 0.292303]\n",
      "epoch:12 step:11857 [D loss: 0.218126, acc.: 66.41%] [G loss: 0.307654]\n",
      "epoch:12 step:11858 [D loss: 0.231611, acc.: 59.38%] [G loss: 0.324175]\n",
      "epoch:12 step:11859 [D loss: 0.230798, acc.: 65.62%] [G loss: 0.322069]\n",
      "epoch:12 step:11860 [D loss: 0.234169, acc.: 64.06%] [G loss: 0.303706]\n",
      "epoch:12 step:11861 [D loss: 0.227847, acc.: 64.06%] [G loss: 0.305102]\n",
      "epoch:12 step:11862 [D loss: 0.240693, acc.: 60.16%] [G loss: 0.289173]\n",
      "epoch:12 step:11863 [D loss: 0.247534, acc.: 55.47%] [G loss: 0.292707]\n",
      "epoch:12 step:11864 [D loss: 0.233750, acc.: 58.59%] [G loss: 0.310962]\n",
      "epoch:12 step:11865 [D loss: 0.239589, acc.: 58.59%] [G loss: 0.307051]\n",
      "epoch:12 step:11866 [D loss: 0.241629, acc.: 58.59%] [G loss: 0.290440]\n",
      "epoch:12 step:11867 [D loss: 0.222807, acc.: 62.50%] [G loss: 0.302147]\n",
      "epoch:12 step:11868 [D loss: 0.243039, acc.: 58.59%] [G loss: 0.318579]\n",
      "epoch:12 step:11869 [D loss: 0.238705, acc.: 57.03%] [G loss: 0.300773]\n",
      "epoch:12 step:11870 [D loss: 0.220991, acc.: 65.62%] [G loss: 0.284209]\n",
      "epoch:12 step:11871 [D loss: 0.239106, acc.: 57.03%] [G loss: 0.313804]\n",
      "epoch:12 step:11872 [D loss: 0.241662, acc.: 57.81%] [G loss: 0.307038]\n",
      "epoch:12 step:11873 [D loss: 0.238918, acc.: 53.12%] [G loss: 0.296128]\n",
      "epoch:12 step:11874 [D loss: 0.239497, acc.: 60.94%] [G loss: 0.296813]\n",
      "epoch:12 step:11875 [D loss: 0.234468, acc.: 62.50%] [G loss: 0.280798]\n",
      "epoch:12 step:11876 [D loss: 0.242401, acc.: 57.81%] [G loss: 0.276325]\n",
      "epoch:12 step:11877 [D loss: 0.240315, acc.: 55.47%] [G loss: 0.330172]\n",
      "epoch:12 step:11878 [D loss: 0.254587, acc.: 50.78%] [G loss: 0.276219]\n",
      "epoch:12 step:11879 [D loss: 0.242518, acc.: 56.25%] [G loss: 0.301095]\n",
      "epoch:12 step:11880 [D loss: 0.234905, acc.: 60.16%] [G loss: 0.299204]\n",
      "epoch:12 step:11881 [D loss: 0.232312, acc.: 60.94%] [G loss: 0.298321]\n",
      "epoch:12 step:11882 [D loss: 0.231752, acc.: 60.94%] [G loss: 0.330875]\n",
      "epoch:12 step:11883 [D loss: 0.254366, acc.: 50.00%] [G loss: 0.300615]\n",
      "epoch:12 step:11884 [D loss: 0.234337, acc.: 56.25%] [G loss: 0.311674]\n",
      "epoch:12 step:11885 [D loss: 0.226071, acc.: 59.38%] [G loss: 0.305254]\n",
      "epoch:12 step:11886 [D loss: 0.232982, acc.: 59.38%] [G loss: 0.306313]\n",
      "epoch:12 step:11887 [D loss: 0.261447, acc.: 53.12%] [G loss: 0.288707]\n",
      "epoch:12 step:11888 [D loss: 0.245374, acc.: 53.12%] [G loss: 0.307638]\n",
      "epoch:12 step:11889 [D loss: 0.242628, acc.: 56.25%] [G loss: 0.300276]\n",
      "epoch:12 step:11890 [D loss: 0.248051, acc.: 58.59%] [G loss: 0.326332]\n",
      "epoch:12 step:11891 [D loss: 0.240270, acc.: 56.25%] [G loss: 0.277258]\n",
      "epoch:12 step:11892 [D loss: 0.238640, acc.: 60.16%] [G loss: 0.304767]\n",
      "epoch:12 step:11893 [D loss: 0.248970, acc.: 53.12%] [G loss: 0.315765]\n",
      "epoch:12 step:11894 [D loss: 0.230397, acc.: 64.06%] [G loss: 0.305038]\n",
      "epoch:12 step:11895 [D loss: 0.261954, acc.: 55.47%] [G loss: 0.265317]\n",
      "epoch:12 step:11896 [D loss: 0.244006, acc.: 55.47%] [G loss: 0.297139]\n",
      "epoch:12 step:11897 [D loss: 0.245543, acc.: 57.81%] [G loss: 0.317760]\n",
      "epoch:12 step:11898 [D loss: 0.246945, acc.: 51.56%] [G loss: 0.291610]\n",
      "epoch:12 step:11899 [D loss: 0.243571, acc.: 53.12%] [G loss: 0.291112]\n",
      "epoch:12 step:11900 [D loss: 0.243785, acc.: 57.81%] [G loss: 0.268341]\n",
      "epoch:12 step:11901 [D loss: 0.247151, acc.: 54.69%] [G loss: 0.275261]\n",
      "epoch:12 step:11902 [D loss: 0.239347, acc.: 60.94%] [G loss: 0.307258]\n",
      "epoch:12 step:11903 [D loss: 0.257940, acc.: 49.22%] [G loss: 0.261026]\n",
      "epoch:12 step:11904 [D loss: 0.239769, acc.: 58.59%] [G loss: 0.281325]\n",
      "epoch:12 step:11905 [D loss: 0.252263, acc.: 55.47%] [G loss: 0.295327]\n",
      "epoch:12 step:11906 [D loss: 0.237099, acc.: 58.59%] [G loss: 0.323411]\n",
      "epoch:12 step:11907 [D loss: 0.260448, acc.: 51.56%] [G loss: 0.302233]\n",
      "epoch:12 step:11908 [D loss: 0.223307, acc.: 62.50%] [G loss: 0.300364]\n",
      "epoch:12 step:11909 [D loss: 0.234483, acc.: 58.59%] [G loss: 0.273751]\n",
      "epoch:12 step:11910 [D loss: 0.258322, acc.: 51.56%] [G loss: 0.304289]\n",
      "epoch:12 step:11911 [D loss: 0.236451, acc.: 60.94%] [G loss: 0.287893]\n",
      "epoch:12 step:11912 [D loss: 0.234600, acc.: 60.16%] [G loss: 0.277483]\n",
      "epoch:12 step:11913 [D loss: 0.247265, acc.: 55.47%] [G loss: 0.281315]\n",
      "epoch:12 step:11914 [D loss: 0.244583, acc.: 57.81%] [G loss: 0.305873]\n",
      "epoch:12 step:11915 [D loss: 0.251313, acc.: 52.34%] [G loss: 0.281049]\n",
      "epoch:12 step:11916 [D loss: 0.246886, acc.: 53.91%] [G loss: 0.275911]\n",
      "epoch:12 step:11917 [D loss: 0.232804, acc.: 62.50%] [G loss: 0.300783]\n",
      "epoch:12 step:11918 [D loss: 0.227895, acc.: 62.50%] [G loss: 0.309998]\n",
      "epoch:12 step:11919 [D loss: 0.249185, acc.: 51.56%] [G loss: 0.288211]\n",
      "epoch:12 step:11920 [D loss: 0.248961, acc.: 52.34%] [G loss: 0.274711]\n",
      "epoch:12 step:11921 [D loss: 0.241899, acc.: 55.47%] [G loss: 0.327423]\n",
      "epoch:12 step:11922 [D loss: 0.228245, acc.: 62.50%] [G loss: 0.311227]\n",
      "epoch:12 step:11923 [D loss: 0.234459, acc.: 62.50%] [G loss: 0.264953]\n",
      "epoch:12 step:11924 [D loss: 0.225469, acc.: 61.72%] [G loss: 0.338275]\n",
      "epoch:12 step:11925 [D loss: 0.240472, acc.: 53.12%] [G loss: 0.287292]\n",
      "epoch:12 step:11926 [D loss: 0.252100, acc.: 54.69%] [G loss: 0.267921]\n",
      "epoch:12 step:11927 [D loss: 0.248098, acc.: 53.91%] [G loss: 0.297160]\n",
      "epoch:12 step:11928 [D loss: 0.235474, acc.: 59.38%] [G loss: 0.294243]\n",
      "epoch:12 step:11929 [D loss: 0.254794, acc.: 48.44%] [G loss: 0.282941]\n",
      "epoch:12 step:11930 [D loss: 0.222066, acc.: 64.84%] [G loss: 0.305547]\n",
      "epoch:12 step:11931 [D loss: 0.237337, acc.: 59.38%] [G loss: 0.301994]\n",
      "epoch:12 step:11932 [D loss: 0.233758, acc.: 57.03%] [G loss: 0.311952]\n",
      "epoch:12 step:11933 [D loss: 0.236735, acc.: 55.47%] [G loss: 0.326395]\n",
      "epoch:12 step:11934 [D loss: 0.243676, acc.: 56.25%] [G loss: 0.296136]\n",
      "epoch:12 step:11935 [D loss: 0.261353, acc.: 53.12%] [G loss: 0.274081]\n",
      "epoch:12 step:11936 [D loss: 0.237240, acc.: 58.59%] [G loss: 0.300799]\n",
      "epoch:12 step:11937 [D loss: 0.244194, acc.: 56.25%] [G loss: 0.305319]\n",
      "epoch:12 step:11938 [D loss: 0.250640, acc.: 53.91%] [G loss: 0.293054]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:12 step:11939 [D loss: 0.242269, acc.: 54.69%] [G loss: 0.311165]\n",
      "epoch:12 step:11940 [D loss: 0.242352, acc.: 55.47%] [G loss: 0.316596]\n",
      "epoch:12 step:11941 [D loss: 0.252065, acc.: 48.44%] [G loss: 0.319963]\n",
      "epoch:12 step:11942 [D loss: 0.236895, acc.: 59.38%] [G loss: 0.296579]\n",
      "epoch:12 step:11943 [D loss: 0.244695, acc.: 48.44%] [G loss: 0.316613]\n",
      "epoch:12 step:11944 [D loss: 0.248505, acc.: 50.78%] [G loss: 0.298888]\n",
      "epoch:12 step:11945 [D loss: 0.229652, acc.: 60.94%] [G loss: 0.292873]\n",
      "epoch:12 step:11946 [D loss: 0.239952, acc.: 53.12%] [G loss: 0.304352]\n",
      "epoch:12 step:11947 [D loss: 0.247493, acc.: 53.91%] [G loss: 0.310898]\n",
      "epoch:12 step:11948 [D loss: 0.226546, acc.: 64.06%] [G loss: 0.308953]\n",
      "epoch:12 step:11949 [D loss: 0.230040, acc.: 61.72%] [G loss: 0.308540]\n",
      "epoch:12 step:11950 [D loss: 0.266539, acc.: 50.00%] [G loss: 0.316634]\n",
      "epoch:12 step:11951 [D loss: 0.224865, acc.: 64.06%] [G loss: 0.318080]\n",
      "epoch:12 step:11952 [D loss: 0.221081, acc.: 62.50%] [G loss: 0.320080]\n",
      "epoch:12 step:11953 [D loss: 0.254492, acc.: 53.91%] [G loss: 0.280530]\n",
      "epoch:12 step:11954 [D loss: 0.243057, acc.: 58.59%] [G loss: 0.288398]\n",
      "epoch:12 step:11955 [D loss: 0.225896, acc.: 64.06%] [G loss: 0.307922]\n",
      "epoch:12 step:11956 [D loss: 0.225225, acc.: 64.06%] [G loss: 0.329502]\n",
      "epoch:12 step:11957 [D loss: 0.240442, acc.: 59.38%] [G loss: 0.303595]\n",
      "epoch:12 step:11958 [D loss: 0.232663, acc.: 61.72%] [G loss: 0.295741]\n",
      "epoch:12 step:11959 [D loss: 0.246239, acc.: 56.25%] [G loss: 0.291404]\n",
      "epoch:12 step:11960 [D loss: 0.230432, acc.: 59.38%] [G loss: 0.296587]\n",
      "epoch:12 step:11961 [D loss: 0.245907, acc.: 53.12%] [G loss: 0.299333]\n",
      "epoch:12 step:11962 [D loss: 0.223706, acc.: 64.06%] [G loss: 0.313203]\n",
      "epoch:12 step:11963 [D loss: 0.253945, acc.: 50.78%] [G loss: 0.312626]\n",
      "epoch:12 step:11964 [D loss: 0.251793, acc.: 50.78%] [G loss: 0.292750]\n",
      "epoch:12 step:11965 [D loss: 0.246691, acc.: 53.12%] [G loss: 0.281531]\n",
      "epoch:12 step:11966 [D loss: 0.252602, acc.: 51.56%] [G loss: 0.320633]\n",
      "epoch:12 step:11967 [D loss: 0.252143, acc.: 53.12%] [G loss: 0.271624]\n",
      "epoch:12 step:11968 [D loss: 0.243694, acc.: 57.81%] [G loss: 0.301884]\n",
      "epoch:12 step:11969 [D loss: 0.245359, acc.: 53.91%] [G loss: 0.292235]\n",
      "epoch:12 step:11970 [D loss: 0.259095, acc.: 49.22%] [G loss: 0.297579]\n",
      "epoch:12 step:11971 [D loss: 0.241931, acc.: 56.25%] [G loss: 0.281606]\n",
      "epoch:12 step:11972 [D loss: 0.228778, acc.: 61.72%] [G loss: 0.292674]\n",
      "epoch:12 step:11973 [D loss: 0.239826, acc.: 57.81%] [G loss: 0.294469]\n",
      "epoch:12 step:11974 [D loss: 0.232779, acc.: 56.25%] [G loss: 0.301890]\n",
      "epoch:12 step:11975 [D loss: 0.241822, acc.: 57.81%] [G loss: 0.309115]\n",
      "epoch:12 step:11976 [D loss: 0.242022, acc.: 56.25%] [G loss: 0.308375]\n",
      "epoch:12 step:11977 [D loss: 0.258285, acc.: 57.03%] [G loss: 0.301179]\n",
      "epoch:12 step:11978 [D loss: 0.231084, acc.: 60.16%] [G loss: 0.291482]\n",
      "epoch:12 step:11979 [D loss: 0.226889, acc.: 65.62%] [G loss: 0.315520]\n",
      "epoch:12 step:11980 [D loss: 0.236647, acc.: 57.03%] [G loss: 0.307032]\n",
      "epoch:12 step:11981 [D loss: 0.241593, acc.: 60.16%] [G loss: 0.277688]\n",
      "epoch:12 step:11982 [D loss: 0.258976, acc.: 51.56%] [G loss: 0.315251]\n",
      "epoch:12 step:11983 [D loss: 0.252755, acc.: 50.78%] [G loss: 0.286096]\n",
      "epoch:12 step:11984 [D loss: 0.250303, acc.: 53.91%] [G loss: 0.304536]\n",
      "epoch:12 step:11985 [D loss: 0.247426, acc.: 58.59%] [G loss: 0.280563]\n",
      "epoch:12 step:11986 [D loss: 0.232043, acc.: 59.38%] [G loss: 0.323370]\n",
      "epoch:12 step:11987 [D loss: 0.261835, acc.: 50.00%] [G loss: 0.290954]\n",
      "epoch:12 step:11988 [D loss: 0.225587, acc.: 64.06%] [G loss: 0.285634]\n",
      "epoch:12 step:11989 [D loss: 0.239351, acc.: 60.16%] [G loss: 0.286544]\n",
      "epoch:12 step:11990 [D loss: 0.241060, acc.: 55.47%] [G loss: 0.293114]\n",
      "epoch:12 step:11991 [D loss: 0.234317, acc.: 58.59%] [G loss: 0.302326]\n",
      "epoch:12 step:11992 [D loss: 0.225093, acc.: 67.19%] [G loss: 0.280477]\n",
      "epoch:12 step:11993 [D loss: 0.240254, acc.: 54.69%] [G loss: 0.284600]\n",
      "epoch:12 step:11994 [D loss: 0.238287, acc.: 60.16%] [G loss: 0.299074]\n",
      "epoch:12 step:11995 [D loss: 0.251344, acc.: 58.59%] [G loss: 0.291391]\n",
      "epoch:12 step:11996 [D loss: 0.239687, acc.: 64.06%] [G loss: 0.303443]\n",
      "epoch:12 step:11997 [D loss: 0.239761, acc.: 58.59%] [G loss: 0.300100]\n",
      "epoch:12 step:11998 [D loss: 0.251370, acc.: 52.34%] [G loss: 0.278167]\n",
      "epoch:12 step:11999 [D loss: 0.244517, acc.: 56.25%] [G loss: 0.246266]\n",
      "epoch:12 step:12000 [D loss: 0.230307, acc.: 59.38%] [G loss: 0.292954]\n",
      "epoch:12 step:12001 [D loss: 0.231837, acc.: 61.72%] [G loss: 0.335656]\n",
      "epoch:12 step:12002 [D loss: 0.234921, acc.: 60.16%] [G loss: 0.312719]\n",
      "epoch:12 step:12003 [D loss: 0.242270, acc.: 60.16%] [G loss: 0.299529]\n",
      "epoch:12 step:12004 [D loss: 0.232016, acc.: 59.38%] [G loss: 0.281536]\n",
      "epoch:12 step:12005 [D loss: 0.246288, acc.: 54.69%] [G loss: 0.291132]\n",
      "epoch:12 step:12006 [D loss: 0.242796, acc.: 58.59%] [G loss: 0.316952]\n",
      "epoch:12 step:12007 [D loss: 0.229298, acc.: 64.84%] [G loss: 0.307305]\n",
      "epoch:12 step:12008 [D loss: 0.239553, acc.: 57.81%] [G loss: 0.292391]\n",
      "epoch:12 step:12009 [D loss: 0.250924, acc.: 57.03%] [G loss: 0.303124]\n",
      "epoch:12 step:12010 [D loss: 0.234730, acc.: 63.28%] [G loss: 0.286355]\n",
      "epoch:12 step:12011 [D loss: 0.225323, acc.: 64.84%] [G loss: 0.316914]\n",
      "epoch:12 step:12012 [D loss: 0.250347, acc.: 53.91%] [G loss: 0.296348]\n",
      "epoch:12 step:12013 [D loss: 0.236100, acc.: 60.16%] [G loss: 0.299839]\n",
      "epoch:12 step:12014 [D loss: 0.236941, acc.: 58.59%] [G loss: 0.297026]\n",
      "epoch:12 step:12015 [D loss: 0.239141, acc.: 57.03%] [G loss: 0.313827]\n",
      "epoch:12 step:12016 [D loss: 0.252032, acc.: 53.12%] [G loss: 0.302573]\n",
      "epoch:12 step:12017 [D loss: 0.260211, acc.: 47.66%] [G loss: 0.288352]\n",
      "epoch:12 step:12018 [D loss: 0.241524, acc.: 59.38%] [G loss: 0.296972]\n",
      "epoch:12 step:12019 [D loss: 0.242924, acc.: 56.25%] [G loss: 0.270439]\n",
      "epoch:12 step:12020 [D loss: 0.241953, acc.: 60.94%] [G loss: 0.282143]\n",
      "epoch:12 step:12021 [D loss: 0.237907, acc.: 56.25%] [G loss: 0.314394]\n",
      "epoch:12 step:12022 [D loss: 0.234455, acc.: 56.25%] [G loss: 0.309962]\n",
      "epoch:12 step:12023 [D loss: 0.231769, acc.: 58.59%] [G loss: 0.312102]\n",
      "epoch:12 step:12024 [D loss: 0.251531, acc.: 57.03%] [G loss: 0.286927]\n",
      "epoch:12 step:12025 [D loss: 0.228474, acc.: 60.16%] [G loss: 0.323261]\n",
      "epoch:12 step:12026 [D loss: 0.245383, acc.: 59.38%] [G loss: 0.290968]\n",
      "epoch:12 step:12027 [D loss: 0.260074, acc.: 46.88%] [G loss: 0.300461]\n",
      "epoch:12 step:12028 [D loss: 0.237331, acc.: 60.16%] [G loss: 0.307650]\n",
      "epoch:12 step:12029 [D loss: 0.248558, acc.: 55.47%] [G loss: 0.274198]\n",
      "epoch:12 step:12030 [D loss: 0.237616, acc.: 58.59%] [G loss: 0.296592]\n",
      "epoch:12 step:12031 [D loss: 0.236733, acc.: 55.47%] [G loss: 0.292260]\n",
      "epoch:12 step:12032 [D loss: 0.240431, acc.: 57.03%] [G loss: 0.286248]\n",
      "epoch:12 step:12033 [D loss: 0.229934, acc.: 64.84%] [G loss: 0.274364]\n",
      "epoch:12 step:12034 [D loss: 0.236837, acc.: 57.81%] [G loss: 0.319342]\n",
      "epoch:12 step:12035 [D loss: 0.237846, acc.: 56.25%] [G loss: 0.315940]\n",
      "epoch:12 step:12036 [D loss: 0.244902, acc.: 59.38%] [G loss: 0.295949]\n",
      "epoch:12 step:12037 [D loss: 0.248561, acc.: 52.34%] [G loss: 0.295937]\n",
      "epoch:12 step:12038 [D loss: 0.234811, acc.: 57.81%] [G loss: 0.285792]\n",
      "epoch:12 step:12039 [D loss: 0.226801, acc.: 62.50%] [G loss: 0.290775]\n",
      "epoch:12 step:12040 [D loss: 0.235055, acc.: 59.38%] [G loss: 0.302837]\n",
      "epoch:12 step:12041 [D loss: 0.252188, acc.: 55.47%] [G loss: 0.309758]\n",
      "epoch:12 step:12042 [D loss: 0.225883, acc.: 64.84%] [G loss: 0.292162]\n",
      "epoch:12 step:12043 [D loss: 0.222675, acc.: 66.41%] [G loss: 0.321768]\n",
      "epoch:12 step:12044 [D loss: 0.233961, acc.: 58.59%] [G loss: 0.301475]\n",
      "epoch:12 step:12045 [D loss: 0.240876, acc.: 55.47%] [G loss: 0.307863]\n",
      "epoch:12 step:12046 [D loss: 0.254521, acc.: 50.00%] [G loss: 0.288565]\n",
      "epoch:12 step:12047 [D loss: 0.235614, acc.: 58.59%] [G loss: 0.302679]\n",
      "epoch:12 step:12048 [D loss: 0.244510, acc.: 57.03%] [G loss: 0.302168]\n",
      "epoch:12 step:12049 [D loss: 0.224617, acc.: 61.72%] [G loss: 0.308107]\n",
      "epoch:12 step:12050 [D loss: 0.214987, acc.: 67.19%] [G loss: 0.293555]\n",
      "epoch:12 step:12051 [D loss: 0.246225, acc.: 60.16%] [G loss: 0.306096]\n",
      "epoch:12 step:12052 [D loss: 0.214966, acc.: 67.97%] [G loss: 0.293909]\n",
      "epoch:12 step:12053 [D loss: 0.220498, acc.: 65.62%] [G loss: 0.307687]\n",
      "epoch:12 step:12054 [D loss: 0.238729, acc.: 57.81%] [G loss: 0.277637]\n",
      "epoch:12 step:12055 [D loss: 0.250583, acc.: 54.69%] [G loss: 0.276393]\n",
      "epoch:12 step:12056 [D loss: 0.231534, acc.: 62.50%] [G loss: 0.299295]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:12 step:12057 [D loss: 0.256694, acc.: 50.78%] [G loss: 0.268126]\n",
      "epoch:12 step:12058 [D loss: 0.234041, acc.: 58.59%] [G loss: 0.285856]\n",
      "epoch:12 step:12059 [D loss: 0.234216, acc.: 59.38%] [G loss: 0.316548]\n",
      "epoch:12 step:12060 [D loss: 0.232219, acc.: 65.62%] [G loss: 0.293063]\n",
      "epoch:12 step:12061 [D loss: 0.258428, acc.: 48.44%] [G loss: 0.293225]\n",
      "epoch:12 step:12062 [D loss: 0.231087, acc.: 58.59%] [G loss: 0.291959]\n",
      "epoch:12 step:12063 [D loss: 0.236735, acc.: 58.59%] [G loss: 0.312039]\n",
      "epoch:12 step:12064 [D loss: 0.249293, acc.: 55.47%] [G loss: 0.282400]\n",
      "epoch:12 step:12065 [D loss: 0.246868, acc.: 55.47%] [G loss: 0.289434]\n",
      "epoch:12 step:12066 [D loss: 0.234667, acc.: 60.16%] [G loss: 0.291259]\n",
      "epoch:12 step:12067 [D loss: 0.249519, acc.: 56.25%] [G loss: 0.333565]\n",
      "epoch:12 step:12068 [D loss: 0.222948, acc.: 64.06%] [G loss: 0.296043]\n",
      "epoch:12 step:12069 [D loss: 0.255506, acc.: 51.56%] [G loss: 0.298009]\n",
      "epoch:12 step:12070 [D loss: 0.241126, acc.: 54.69%] [G loss: 0.263119]\n",
      "epoch:12 step:12071 [D loss: 0.234782, acc.: 60.94%] [G loss: 0.286162]\n",
      "epoch:12 step:12072 [D loss: 0.259153, acc.: 52.34%] [G loss: 0.320704]\n",
      "epoch:12 step:12073 [D loss: 0.235611, acc.: 58.59%] [G loss: 0.292741]\n",
      "epoch:12 step:12074 [D loss: 0.233165, acc.: 57.81%] [G loss: 0.310691]\n",
      "epoch:12 step:12075 [D loss: 0.256818, acc.: 51.56%] [G loss: 0.286618]\n",
      "epoch:12 step:12076 [D loss: 0.251393, acc.: 48.44%] [G loss: 0.267827]\n",
      "epoch:12 step:12077 [D loss: 0.234731, acc.: 59.38%] [G loss: 0.302746]\n",
      "epoch:12 step:12078 [D loss: 0.232042, acc.: 62.50%] [G loss: 0.282247]\n",
      "epoch:12 step:12079 [D loss: 0.245407, acc.: 54.69%] [G loss: 0.278596]\n",
      "epoch:12 step:12080 [D loss: 0.257390, acc.: 53.12%] [G loss: 0.313564]\n",
      "epoch:12 step:12081 [D loss: 0.245927, acc.: 56.25%] [G loss: 0.271294]\n",
      "epoch:12 step:12082 [D loss: 0.252478, acc.: 55.47%] [G loss: 0.280206]\n",
      "epoch:12 step:12083 [D loss: 0.239185, acc.: 60.16%] [G loss: 0.296871]\n",
      "epoch:12 step:12084 [D loss: 0.246804, acc.: 57.03%] [G loss: 0.324013]\n",
      "epoch:12 step:12085 [D loss: 0.218071, acc.: 64.06%] [G loss: 0.297099]\n",
      "epoch:12 step:12086 [D loss: 0.257446, acc.: 53.12%] [G loss: 0.273997]\n",
      "epoch:12 step:12087 [D loss: 0.241338, acc.: 62.50%] [G loss: 0.293825]\n",
      "epoch:12 step:12088 [D loss: 0.234641, acc.: 59.38%] [G loss: 0.303703]\n",
      "epoch:12 step:12089 [D loss: 0.226269, acc.: 64.84%] [G loss: 0.293153]\n",
      "epoch:12 step:12090 [D loss: 0.242527, acc.: 52.34%] [G loss: 0.293559]\n",
      "epoch:12 step:12091 [D loss: 0.247703, acc.: 52.34%] [G loss: 0.271789]\n",
      "epoch:12 step:12092 [D loss: 0.232305, acc.: 57.81%] [G loss: 0.281787]\n",
      "epoch:12 step:12093 [D loss: 0.232991, acc.: 65.62%] [G loss: 0.316914]\n",
      "epoch:12 step:12094 [D loss: 0.222908, acc.: 66.41%] [G loss: 0.307923]\n",
      "epoch:12 step:12095 [D loss: 0.226444, acc.: 61.72%] [G loss: 0.300706]\n",
      "epoch:12 step:12096 [D loss: 0.240352, acc.: 57.03%] [G loss: 0.309748]\n",
      "epoch:12 step:12097 [D loss: 0.235495, acc.: 58.59%] [G loss: 0.282429]\n",
      "epoch:12 step:12098 [D loss: 0.229167, acc.: 60.16%] [G loss: 0.312710]\n",
      "epoch:12 step:12099 [D loss: 0.260783, acc.: 46.88%] [G loss: 0.286348]\n",
      "epoch:12 step:12100 [D loss: 0.235275, acc.: 60.16%] [G loss: 0.302928]\n",
      "epoch:12 step:12101 [D loss: 0.251155, acc.: 53.12%] [G loss: 0.319557]\n",
      "epoch:12 step:12102 [D loss: 0.242095, acc.: 57.03%] [G loss: 0.294181]\n",
      "epoch:12 step:12103 [D loss: 0.247036, acc.: 61.72%] [G loss: 0.299914]\n",
      "epoch:12 step:12104 [D loss: 0.239973, acc.: 60.16%] [G loss: 0.288182]\n",
      "epoch:12 step:12105 [D loss: 0.238998, acc.: 57.03%] [G loss: 0.317431]\n",
      "epoch:12 step:12106 [D loss: 0.256528, acc.: 57.03%] [G loss: 0.311904]\n",
      "epoch:12 step:12107 [D loss: 0.236785, acc.: 53.12%] [G loss: 0.302879]\n",
      "epoch:12 step:12108 [D loss: 0.233139, acc.: 65.62%] [G loss: 0.327608]\n",
      "epoch:12 step:12109 [D loss: 0.235736, acc.: 57.81%] [G loss: 0.313952]\n",
      "epoch:12 step:12110 [D loss: 0.232599, acc.: 60.94%] [G loss: 0.298655]\n",
      "epoch:12 step:12111 [D loss: 0.246493, acc.: 58.59%] [G loss: 0.291626]\n",
      "epoch:12 step:12112 [D loss: 0.232006, acc.: 60.16%] [G loss: 0.274923]\n",
      "epoch:12 step:12113 [D loss: 0.222765, acc.: 64.84%] [G loss: 0.304554]\n",
      "epoch:12 step:12114 [D loss: 0.242458, acc.: 57.03%] [G loss: 0.303342]\n",
      "epoch:12 step:12115 [D loss: 0.233595, acc.: 56.25%] [G loss: 0.307343]\n",
      "epoch:12 step:12116 [D loss: 0.238611, acc.: 60.16%] [G loss: 0.285979]\n",
      "epoch:12 step:12117 [D loss: 0.225052, acc.: 60.16%] [G loss: 0.294424]\n",
      "epoch:12 step:12118 [D loss: 0.235128, acc.: 62.50%] [G loss: 0.287826]\n",
      "epoch:12 step:12119 [D loss: 0.222339, acc.: 67.97%] [G loss: 0.310413]\n",
      "epoch:12 step:12120 [D loss: 0.233022, acc.: 58.59%] [G loss: 0.327908]\n",
      "epoch:12 step:12121 [D loss: 0.241838, acc.: 58.59%] [G loss: 0.309313]\n",
      "epoch:12 step:12122 [D loss: 0.254502, acc.: 56.25%] [G loss: 0.293068]\n",
      "epoch:12 step:12123 [D loss: 0.286356, acc.: 39.06%] [G loss: 0.260202]\n",
      "epoch:12 step:12124 [D loss: 0.241170, acc.: 55.47%] [G loss: 0.296709]\n",
      "epoch:12 step:12125 [D loss: 0.226933, acc.: 62.50%] [G loss: 0.313725]\n",
      "epoch:12 step:12126 [D loss: 0.231933, acc.: 62.50%] [G loss: 0.305242]\n",
      "epoch:12 step:12127 [D loss: 0.242611, acc.: 57.03%] [G loss: 0.275774]\n",
      "epoch:12 step:12128 [D loss: 0.251925, acc.: 49.22%] [G loss: 0.289866]\n",
      "epoch:12 step:12129 [D loss: 0.250104, acc.: 57.03%] [G loss: 0.303400]\n",
      "epoch:12 step:12130 [D loss: 0.225290, acc.: 64.84%] [G loss: 0.314893]\n",
      "epoch:12 step:12131 [D loss: 0.241377, acc.: 53.12%] [G loss: 0.284803]\n",
      "epoch:12 step:12132 [D loss: 0.232573, acc.: 60.16%] [G loss: 0.288608]\n",
      "epoch:12 step:12133 [D loss: 0.240570, acc.: 57.81%] [G loss: 0.297268]\n",
      "epoch:12 step:12134 [D loss: 0.238881, acc.: 54.69%] [G loss: 0.298160]\n",
      "epoch:12 step:12135 [D loss: 0.256609, acc.: 50.78%] [G loss: 0.319891]\n",
      "epoch:12 step:12136 [D loss: 0.238932, acc.: 60.94%] [G loss: 0.295138]\n",
      "epoch:12 step:12137 [D loss: 0.246022, acc.: 57.81%] [G loss: 0.296674]\n",
      "epoch:12 step:12138 [D loss: 0.250203, acc.: 53.12%] [G loss: 0.280890]\n",
      "epoch:12 step:12139 [D loss: 0.229033, acc.: 65.62%] [G loss: 0.285831]\n",
      "epoch:12 step:12140 [D loss: 0.228835, acc.: 60.16%] [G loss: 0.311670]\n",
      "epoch:12 step:12141 [D loss: 0.252653, acc.: 57.03%] [G loss: 0.307835]\n",
      "epoch:12 step:12142 [D loss: 0.234551, acc.: 57.81%] [G loss: 0.324817]\n",
      "epoch:12 step:12143 [D loss: 0.247478, acc.: 62.50%] [G loss: 0.304235]\n",
      "epoch:12 step:12144 [D loss: 0.248094, acc.: 58.59%] [G loss: 0.296796]\n",
      "epoch:12 step:12145 [D loss: 0.227981, acc.: 64.84%] [G loss: 0.312251]\n",
      "epoch:12 step:12146 [D loss: 0.250631, acc.: 51.56%] [G loss: 0.308470]\n",
      "epoch:12 step:12147 [D loss: 0.230257, acc.: 64.84%] [G loss: 0.311900]\n",
      "epoch:12 step:12148 [D loss: 0.228581, acc.: 61.72%] [G loss: 0.300061]\n",
      "epoch:12 step:12149 [D loss: 0.239573, acc.: 59.38%] [G loss: 0.312179]\n",
      "epoch:12 step:12150 [D loss: 0.230813, acc.: 58.59%] [G loss: 0.293607]\n",
      "epoch:12 step:12151 [D loss: 0.227236, acc.: 62.50%] [G loss: 0.316644]\n",
      "epoch:12 step:12152 [D loss: 0.265622, acc.: 46.09%] [G loss: 0.296381]\n",
      "epoch:12 step:12153 [D loss: 0.248184, acc.: 56.25%] [G loss: 0.282517]\n",
      "epoch:12 step:12154 [D loss: 0.244024, acc.: 57.03%] [G loss: 0.275189]\n",
      "epoch:12 step:12155 [D loss: 0.231375, acc.: 58.59%] [G loss: 0.283232]\n",
      "epoch:12 step:12156 [D loss: 0.248381, acc.: 53.91%] [G loss: 0.298976]\n",
      "epoch:12 step:12157 [D loss: 0.225319, acc.: 65.62%] [G loss: 0.297910]\n",
      "epoch:12 step:12158 [D loss: 0.247955, acc.: 54.69%] [G loss: 0.299840]\n",
      "epoch:12 step:12159 [D loss: 0.242141, acc.: 56.25%] [G loss: 0.278898]\n",
      "epoch:12 step:12160 [D loss: 0.243132, acc.: 57.81%] [G loss: 0.279806]\n",
      "epoch:12 step:12161 [D loss: 0.225336, acc.: 63.28%] [G loss: 0.291108]\n",
      "epoch:12 step:12162 [D loss: 0.246892, acc.: 55.47%] [G loss: 0.303011]\n",
      "epoch:12 step:12163 [D loss: 0.243140, acc.: 57.03%] [G loss: 0.270223]\n",
      "epoch:12 step:12164 [D loss: 0.240182, acc.: 58.59%] [G loss: 0.305257]\n",
      "epoch:12 step:12165 [D loss: 0.244839, acc.: 51.56%] [G loss: 0.285436]\n",
      "epoch:12 step:12166 [D loss: 0.232658, acc.: 62.50%] [G loss: 0.293487]\n",
      "epoch:12 step:12167 [D loss: 0.237171, acc.: 60.94%] [G loss: 0.303596]\n",
      "epoch:12 step:12168 [D loss: 0.225420, acc.: 62.50%] [G loss: 0.299005]\n",
      "epoch:12 step:12169 [D loss: 0.246103, acc.: 53.91%] [G loss: 0.284922]\n",
      "epoch:12 step:12170 [D loss: 0.230375, acc.: 61.72%] [G loss: 0.296262]\n",
      "epoch:12 step:12171 [D loss: 0.239325, acc.: 54.69%] [G loss: 0.309847]\n",
      "epoch:12 step:12172 [D loss: 0.224698, acc.: 65.62%] [G loss: 0.292170]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:12 step:12173 [D loss: 0.240563, acc.: 57.03%] [G loss: 0.274280]\n",
      "epoch:12 step:12174 [D loss: 0.243986, acc.: 58.59%] [G loss: 0.303720]\n",
      "epoch:12 step:12175 [D loss: 0.241807, acc.: 58.59%] [G loss: 0.294501]\n",
      "epoch:12 step:12176 [D loss: 0.240513, acc.: 56.25%] [G loss: 0.291270]\n",
      "epoch:12 step:12177 [D loss: 0.264274, acc.: 52.34%] [G loss: 0.288523]\n",
      "epoch:12 step:12178 [D loss: 0.257210, acc.: 53.12%] [G loss: 0.281760]\n",
      "epoch:12 step:12179 [D loss: 0.232057, acc.: 60.94%] [G loss: 0.312202]\n",
      "epoch:12 step:12180 [D loss: 0.232069, acc.: 61.72%] [G loss: 0.290998]\n",
      "epoch:12 step:12181 [D loss: 0.232213, acc.: 58.59%] [G loss: 0.318088]\n",
      "epoch:13 step:12182 [D loss: 0.245628, acc.: 55.47%] [G loss: 0.301860]\n",
      "epoch:13 step:12183 [D loss: 0.254514, acc.: 56.25%] [G loss: 0.277413]\n",
      "epoch:13 step:12184 [D loss: 0.231301, acc.: 61.72%] [G loss: 0.310787]\n",
      "epoch:13 step:12185 [D loss: 0.218451, acc.: 66.41%] [G loss: 0.311149]\n",
      "epoch:13 step:12186 [D loss: 0.238655, acc.: 60.16%] [G loss: 0.297445]\n",
      "epoch:13 step:12187 [D loss: 0.247026, acc.: 57.03%] [G loss: 0.294627]\n",
      "epoch:13 step:12188 [D loss: 0.245211, acc.: 56.25%] [G loss: 0.322068]\n",
      "epoch:13 step:12189 [D loss: 0.241948, acc.: 62.50%] [G loss: 0.289825]\n",
      "epoch:13 step:12190 [D loss: 0.252490, acc.: 49.22%] [G loss: 0.296716]\n",
      "epoch:13 step:12191 [D loss: 0.256667, acc.: 58.59%] [G loss: 0.312051]\n",
      "epoch:13 step:12192 [D loss: 0.218957, acc.: 66.41%] [G loss: 0.311734]\n",
      "epoch:13 step:12193 [D loss: 0.236675, acc.: 61.72%] [G loss: 0.297365]\n",
      "epoch:13 step:12194 [D loss: 0.237473, acc.: 56.25%] [G loss: 0.299284]\n",
      "epoch:13 step:12195 [D loss: 0.258678, acc.: 49.22%] [G loss: 0.288446]\n",
      "epoch:13 step:12196 [D loss: 0.230033, acc.: 64.06%] [G loss: 0.302089]\n",
      "epoch:13 step:12197 [D loss: 0.244454, acc.: 54.69%] [G loss: 0.284247]\n",
      "epoch:13 step:12198 [D loss: 0.235966, acc.: 61.72%] [G loss: 0.287949]\n",
      "epoch:13 step:12199 [D loss: 0.244204, acc.: 57.81%] [G loss: 0.307163]\n",
      "epoch:13 step:12200 [D loss: 0.241678, acc.: 59.38%] [G loss: 0.277326]\n",
      "epoch:13 step:12201 [D loss: 0.234172, acc.: 55.47%] [G loss: 0.284290]\n",
      "epoch:13 step:12202 [D loss: 0.229301, acc.: 60.94%] [G loss: 0.291427]\n",
      "epoch:13 step:12203 [D loss: 0.227714, acc.: 64.06%] [G loss: 0.293249]\n",
      "epoch:13 step:12204 [D loss: 0.250949, acc.: 54.69%] [G loss: 0.291923]\n",
      "epoch:13 step:12205 [D loss: 0.243057, acc.: 56.25%] [G loss: 0.297247]\n",
      "epoch:13 step:12206 [D loss: 0.235765, acc.: 59.38%] [G loss: 0.312282]\n",
      "epoch:13 step:12207 [D loss: 0.225737, acc.: 64.06%] [G loss: 0.288901]\n",
      "epoch:13 step:12208 [D loss: 0.230592, acc.: 60.94%] [G loss: 0.308799]\n",
      "epoch:13 step:12209 [D loss: 0.240018, acc.: 58.59%] [G loss: 0.290954]\n",
      "epoch:13 step:12210 [D loss: 0.254241, acc.: 50.78%] [G loss: 0.283648]\n",
      "epoch:13 step:12211 [D loss: 0.231510, acc.: 60.16%] [G loss: 0.277158]\n",
      "epoch:13 step:12212 [D loss: 0.239378, acc.: 56.25%] [G loss: 0.288805]\n",
      "epoch:13 step:12213 [D loss: 0.233856, acc.: 58.59%] [G loss: 0.300691]\n",
      "epoch:13 step:12214 [D loss: 0.235252, acc.: 59.38%] [G loss: 0.298389]\n",
      "epoch:13 step:12215 [D loss: 0.254838, acc.: 51.56%] [G loss: 0.293459]\n",
      "epoch:13 step:12216 [D loss: 0.230592, acc.: 62.50%] [G loss: 0.308073]\n",
      "epoch:13 step:12217 [D loss: 0.225663, acc.: 67.19%] [G loss: 0.275188]\n",
      "epoch:13 step:12218 [D loss: 0.243851, acc.: 57.81%] [G loss: 0.299962]\n",
      "epoch:13 step:12219 [D loss: 0.251835, acc.: 54.69%] [G loss: 0.288996]\n",
      "epoch:13 step:12220 [D loss: 0.220796, acc.: 67.19%] [G loss: 0.321555]\n",
      "epoch:13 step:12221 [D loss: 0.247938, acc.: 57.81%] [G loss: 0.309887]\n",
      "epoch:13 step:12222 [D loss: 0.229062, acc.: 60.16%] [G loss: 0.311805]\n",
      "epoch:13 step:12223 [D loss: 0.245660, acc.: 50.78%] [G loss: 0.276572]\n",
      "epoch:13 step:12224 [D loss: 0.242088, acc.: 60.16%] [G loss: 0.300182]\n",
      "epoch:13 step:12225 [D loss: 0.237538, acc.: 64.84%] [G loss: 0.298263]\n",
      "epoch:13 step:12226 [D loss: 0.234871, acc.: 59.38%] [G loss: 0.305691]\n",
      "epoch:13 step:12227 [D loss: 0.246097, acc.: 57.03%] [G loss: 0.298511]\n",
      "epoch:13 step:12228 [D loss: 0.236208, acc.: 58.59%] [G loss: 0.289377]\n",
      "epoch:13 step:12229 [D loss: 0.237445, acc.: 59.38%] [G loss: 0.291426]\n",
      "epoch:13 step:12230 [D loss: 0.228472, acc.: 65.62%] [G loss: 0.321904]\n",
      "epoch:13 step:12231 [D loss: 0.236333, acc.: 60.94%] [G loss: 0.326759]\n",
      "epoch:13 step:12232 [D loss: 0.248258, acc.: 53.12%] [G loss: 0.315917]\n",
      "epoch:13 step:12233 [D loss: 0.234715, acc.: 57.03%] [G loss: 0.304297]\n",
      "epoch:13 step:12234 [D loss: 0.232694, acc.: 57.03%] [G loss: 0.278401]\n",
      "epoch:13 step:12235 [D loss: 0.231437, acc.: 67.19%] [G loss: 0.323377]\n",
      "epoch:13 step:12236 [D loss: 0.236646, acc.: 60.94%] [G loss: 0.294124]\n",
      "epoch:13 step:12237 [D loss: 0.244588, acc.: 50.00%] [G loss: 0.306223]\n",
      "epoch:13 step:12238 [D loss: 0.249558, acc.: 51.56%] [G loss: 0.296122]\n",
      "epoch:13 step:12239 [D loss: 0.244390, acc.: 55.47%] [G loss: 0.322310]\n",
      "epoch:13 step:12240 [D loss: 0.237478, acc.: 58.59%] [G loss: 0.298895]\n",
      "epoch:13 step:12241 [D loss: 0.232845, acc.: 58.59%] [G loss: 0.314245]\n",
      "epoch:13 step:12242 [D loss: 0.241678, acc.: 57.81%] [G loss: 0.304554]\n",
      "epoch:13 step:12243 [D loss: 0.227700, acc.: 54.69%] [G loss: 0.319440]\n",
      "epoch:13 step:12244 [D loss: 0.240131, acc.: 52.34%] [G loss: 0.292020]\n",
      "epoch:13 step:12245 [D loss: 0.233803, acc.: 60.16%] [G loss: 0.305533]\n",
      "epoch:13 step:12246 [D loss: 0.233851, acc.: 60.94%] [G loss: 0.285772]\n",
      "epoch:13 step:12247 [D loss: 0.260358, acc.: 50.00%] [G loss: 0.302368]\n",
      "epoch:13 step:12248 [D loss: 0.231822, acc.: 62.50%] [G loss: 0.290598]\n",
      "epoch:13 step:12249 [D loss: 0.229791, acc.: 64.84%] [G loss: 0.284217]\n",
      "epoch:13 step:12250 [D loss: 0.241242, acc.: 57.03%] [G loss: 0.293845]\n",
      "epoch:13 step:12251 [D loss: 0.238965, acc.: 55.47%] [G loss: 0.297400]\n",
      "epoch:13 step:12252 [D loss: 0.238421, acc.: 59.38%] [G loss: 0.297523]\n",
      "epoch:13 step:12253 [D loss: 0.245468, acc.: 57.03%] [G loss: 0.295581]\n",
      "epoch:13 step:12254 [D loss: 0.233948, acc.: 56.25%] [G loss: 0.321648]\n",
      "epoch:13 step:12255 [D loss: 0.224620, acc.: 67.19%] [G loss: 0.301989]\n",
      "epoch:13 step:12256 [D loss: 0.244633, acc.: 56.25%] [G loss: 0.287847]\n",
      "epoch:13 step:12257 [D loss: 0.229926, acc.: 61.72%] [G loss: 0.314430]\n",
      "epoch:13 step:12258 [D loss: 0.268361, acc.: 49.22%] [G loss: 0.297847]\n",
      "epoch:13 step:12259 [D loss: 0.251486, acc.: 52.34%] [G loss: 0.302904]\n",
      "epoch:13 step:12260 [D loss: 0.236677, acc.: 57.03%] [G loss: 0.311233]\n",
      "epoch:13 step:12261 [D loss: 0.232601, acc.: 60.16%] [G loss: 0.298975]\n",
      "epoch:13 step:12262 [D loss: 0.248957, acc.: 53.12%] [G loss: 0.306357]\n",
      "epoch:13 step:12263 [D loss: 0.251731, acc.: 55.47%] [G loss: 0.279583]\n",
      "epoch:13 step:12264 [D loss: 0.241800, acc.: 57.81%] [G loss: 0.308397]\n",
      "epoch:13 step:12265 [D loss: 0.245388, acc.: 57.03%] [G loss: 0.292680]\n",
      "epoch:13 step:12266 [D loss: 0.230391, acc.: 57.81%] [G loss: 0.309686]\n",
      "epoch:13 step:12267 [D loss: 0.241268, acc.: 54.69%] [G loss: 0.313518]\n",
      "epoch:13 step:12268 [D loss: 0.240431, acc.: 54.69%] [G loss: 0.294246]\n",
      "epoch:13 step:12269 [D loss: 0.228681, acc.: 59.38%] [G loss: 0.315418]\n",
      "epoch:13 step:12270 [D loss: 0.235605, acc.: 61.72%] [G loss: 0.281917]\n",
      "epoch:13 step:12271 [D loss: 0.222445, acc.: 61.72%] [G loss: 0.314252]\n",
      "epoch:13 step:12272 [D loss: 0.242416, acc.: 59.38%] [G loss: 0.295242]\n",
      "epoch:13 step:12273 [D loss: 0.237670, acc.: 61.72%] [G loss: 0.315677]\n",
      "epoch:13 step:12274 [D loss: 0.246183, acc.: 54.69%] [G loss: 0.289828]\n",
      "epoch:13 step:12275 [D loss: 0.266776, acc.: 50.00%] [G loss: 0.303697]\n",
      "epoch:13 step:12276 [D loss: 0.239112, acc.: 61.72%] [G loss: 0.306884]\n",
      "epoch:13 step:12277 [D loss: 0.241414, acc.: 58.59%] [G loss: 0.278595]\n",
      "epoch:13 step:12278 [D loss: 0.242948, acc.: 54.69%] [G loss: 0.290193]\n",
      "epoch:13 step:12279 [D loss: 0.235497, acc.: 57.81%] [G loss: 0.291914]\n",
      "epoch:13 step:12280 [D loss: 0.250532, acc.: 49.22%] [G loss: 0.291568]\n",
      "epoch:13 step:12281 [D loss: 0.271920, acc.: 42.19%] [G loss: 0.292268]\n",
      "epoch:13 step:12282 [D loss: 0.230717, acc.: 64.06%] [G loss: 0.311471]\n",
      "epoch:13 step:12283 [D loss: 0.232695, acc.: 60.16%] [G loss: 0.293898]\n",
      "epoch:13 step:12284 [D loss: 0.237738, acc.: 57.81%] [G loss: 0.316011]\n",
      "epoch:13 step:12285 [D loss: 0.238863, acc.: 57.81%] [G loss: 0.283785]\n",
      "epoch:13 step:12286 [D loss: 0.232426, acc.: 64.06%] [G loss: 0.309637]\n",
      "epoch:13 step:12287 [D loss: 0.234708, acc.: 60.94%] [G loss: 0.323188]\n",
      "epoch:13 step:12288 [D loss: 0.241479, acc.: 57.03%] [G loss: 0.282018]\n",
      "epoch:13 step:12289 [D loss: 0.233267, acc.: 58.59%] [G loss: 0.301528]\n",
      "epoch:13 step:12290 [D loss: 0.247405, acc.: 49.22%] [G loss: 0.303111]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:13 step:12291 [D loss: 0.245291, acc.: 51.56%] [G loss: 0.295262]\n",
      "epoch:13 step:12292 [D loss: 0.246830, acc.: 56.25%] [G loss: 0.307600]\n",
      "epoch:13 step:12293 [D loss: 0.232328, acc.: 59.38%] [G loss: 0.290296]\n",
      "epoch:13 step:12294 [D loss: 0.241077, acc.: 58.59%] [G loss: 0.312002]\n",
      "epoch:13 step:12295 [D loss: 0.218060, acc.: 67.97%] [G loss: 0.308149]\n",
      "epoch:13 step:12296 [D loss: 0.244463, acc.: 56.25%] [G loss: 0.307815]\n",
      "epoch:13 step:12297 [D loss: 0.246807, acc.: 53.12%] [G loss: 0.292382]\n",
      "epoch:13 step:12298 [D loss: 0.244590, acc.: 56.25%] [G loss: 0.288231]\n",
      "epoch:13 step:12299 [D loss: 0.243903, acc.: 57.81%] [G loss: 0.295065]\n",
      "epoch:13 step:12300 [D loss: 0.246151, acc.: 52.34%] [G loss: 0.285843]\n",
      "epoch:13 step:12301 [D loss: 0.257681, acc.: 50.00%] [G loss: 0.292079]\n",
      "epoch:13 step:12302 [D loss: 0.246742, acc.: 53.12%] [G loss: 0.294898]\n",
      "epoch:13 step:12303 [D loss: 0.248379, acc.: 54.69%] [G loss: 0.292805]\n",
      "epoch:13 step:12304 [D loss: 0.236556, acc.: 61.72%] [G loss: 0.287203]\n",
      "epoch:13 step:12305 [D loss: 0.235036, acc.: 59.38%] [G loss: 0.290789]\n",
      "epoch:13 step:12306 [D loss: 0.228277, acc.: 66.41%] [G loss: 0.317265]\n",
      "epoch:13 step:12307 [D loss: 0.233542, acc.: 59.38%] [G loss: 0.297993]\n",
      "epoch:13 step:12308 [D loss: 0.234678, acc.: 59.38%] [G loss: 0.306058]\n",
      "epoch:13 step:12309 [D loss: 0.245391, acc.: 52.34%] [G loss: 0.312654]\n",
      "epoch:13 step:12310 [D loss: 0.245977, acc.: 54.69%] [G loss: 0.250599]\n",
      "epoch:13 step:12311 [D loss: 0.232004, acc.: 57.81%] [G loss: 0.317592]\n",
      "epoch:13 step:12312 [D loss: 0.237227, acc.: 60.94%] [G loss: 0.284555]\n",
      "epoch:13 step:12313 [D loss: 0.227372, acc.: 64.06%] [G loss: 0.308419]\n",
      "epoch:13 step:12314 [D loss: 0.242038, acc.: 57.03%] [G loss: 0.273236]\n",
      "epoch:13 step:12315 [D loss: 0.251605, acc.: 51.56%] [G loss: 0.272832]\n",
      "epoch:13 step:12316 [D loss: 0.233707, acc.: 59.38%] [G loss: 0.296496]\n",
      "epoch:13 step:12317 [D loss: 0.254948, acc.: 49.22%] [G loss: 0.321683]\n",
      "epoch:13 step:12318 [D loss: 0.240728, acc.: 59.38%] [G loss: 0.285469]\n",
      "epoch:13 step:12319 [D loss: 0.237604, acc.: 57.81%] [G loss: 0.271022]\n",
      "epoch:13 step:12320 [D loss: 0.232995, acc.: 62.50%] [G loss: 0.305767]\n",
      "epoch:13 step:12321 [D loss: 0.254747, acc.: 50.78%] [G loss: 0.313611]\n",
      "epoch:13 step:12322 [D loss: 0.266730, acc.: 47.66%] [G loss: 0.265912]\n",
      "epoch:13 step:12323 [D loss: 0.230745, acc.: 59.38%] [G loss: 0.269119]\n",
      "epoch:13 step:12324 [D loss: 0.237313, acc.: 60.16%] [G loss: 0.302159]\n",
      "epoch:13 step:12325 [D loss: 0.251292, acc.: 54.69%] [G loss: 0.295045]\n",
      "epoch:13 step:12326 [D loss: 0.259763, acc.: 53.12%] [G loss: 0.292788]\n",
      "epoch:13 step:12327 [D loss: 0.225908, acc.: 64.84%] [G loss: 0.295395]\n",
      "epoch:13 step:12328 [D loss: 0.241659, acc.: 59.38%] [G loss: 0.305630]\n",
      "epoch:13 step:12329 [D loss: 0.231168, acc.: 64.84%] [G loss: 0.292743]\n",
      "epoch:13 step:12330 [D loss: 0.245383, acc.: 57.03%] [G loss: 0.311948]\n",
      "epoch:13 step:12331 [D loss: 0.226712, acc.: 61.72%] [G loss: 0.312524]\n",
      "epoch:13 step:12332 [D loss: 0.233783, acc.: 60.94%] [G loss: 0.304694]\n",
      "epoch:13 step:12333 [D loss: 0.238198, acc.: 57.03%] [G loss: 0.288245]\n",
      "epoch:13 step:12334 [D loss: 0.231116, acc.: 60.16%] [G loss: 0.282584]\n",
      "epoch:13 step:12335 [D loss: 0.251102, acc.: 50.78%] [G loss: 0.285768]\n",
      "epoch:13 step:12336 [D loss: 0.246349, acc.: 53.12%] [G loss: 0.283247]\n",
      "epoch:13 step:12337 [D loss: 0.253517, acc.: 53.91%] [G loss: 0.296314]\n",
      "epoch:13 step:12338 [D loss: 0.233364, acc.: 60.94%] [G loss: 0.278244]\n",
      "epoch:13 step:12339 [D loss: 0.240568, acc.: 56.25%] [G loss: 0.328039]\n",
      "epoch:13 step:12340 [D loss: 0.238819, acc.: 51.56%] [G loss: 0.310213]\n",
      "epoch:13 step:12341 [D loss: 0.226297, acc.: 64.84%] [G loss: 0.310896]\n",
      "epoch:13 step:12342 [D loss: 0.243676, acc.: 58.59%] [G loss: 0.311299]\n",
      "epoch:13 step:12343 [D loss: 0.235150, acc.: 62.50%] [G loss: 0.322017]\n",
      "epoch:13 step:12344 [D loss: 0.263363, acc.: 44.53%] [G loss: 0.300606]\n",
      "epoch:13 step:12345 [D loss: 0.236026, acc.: 57.03%] [G loss: 0.287086]\n",
      "epoch:13 step:12346 [D loss: 0.236429, acc.: 59.38%] [G loss: 0.300152]\n",
      "epoch:13 step:12347 [D loss: 0.228903, acc.: 64.06%] [G loss: 0.291711]\n",
      "epoch:13 step:12348 [D loss: 0.230407, acc.: 63.28%] [G loss: 0.311199]\n",
      "epoch:13 step:12349 [D loss: 0.245377, acc.: 52.34%] [G loss: 0.304541]\n",
      "epoch:13 step:12350 [D loss: 0.244221, acc.: 57.03%] [G loss: 0.289586]\n",
      "epoch:13 step:12351 [D loss: 0.238611, acc.: 60.94%] [G loss: 0.306991]\n",
      "epoch:13 step:12352 [D loss: 0.230857, acc.: 61.72%] [G loss: 0.319153]\n",
      "epoch:13 step:12353 [D loss: 0.236460, acc.: 59.38%] [G loss: 0.315137]\n",
      "epoch:13 step:12354 [D loss: 0.240873, acc.: 57.03%] [G loss: 0.297920]\n",
      "epoch:13 step:12355 [D loss: 0.217732, acc.: 68.75%] [G loss: 0.328641]\n",
      "epoch:13 step:12356 [D loss: 0.245740, acc.: 60.16%] [G loss: 0.290625]\n",
      "epoch:13 step:12357 [D loss: 0.236093, acc.: 60.94%] [G loss: 0.301053]\n",
      "epoch:13 step:12358 [D loss: 0.237103, acc.: 57.03%] [G loss: 0.279927]\n",
      "epoch:13 step:12359 [D loss: 0.222645, acc.: 60.16%] [G loss: 0.323848]\n",
      "epoch:13 step:12360 [D loss: 0.249014, acc.: 50.78%] [G loss: 0.310863]\n",
      "epoch:13 step:12361 [D loss: 0.235060, acc.: 63.28%] [G loss: 0.285533]\n",
      "epoch:13 step:12362 [D loss: 0.246223, acc.: 55.47%] [G loss: 0.290766]\n",
      "epoch:13 step:12363 [D loss: 0.239596, acc.: 58.59%] [G loss: 0.294355]\n",
      "epoch:13 step:12364 [D loss: 0.240221, acc.: 55.47%] [G loss: 0.313483]\n",
      "epoch:13 step:12365 [D loss: 0.224476, acc.: 63.28%] [G loss: 0.304784]\n",
      "epoch:13 step:12366 [D loss: 0.251721, acc.: 52.34%] [G loss: 0.281684]\n",
      "epoch:13 step:12367 [D loss: 0.238317, acc.: 65.62%] [G loss: 0.302517]\n",
      "epoch:13 step:12368 [D loss: 0.228341, acc.: 60.94%] [G loss: 0.344656]\n",
      "epoch:13 step:12369 [D loss: 0.249445, acc.: 50.00%] [G loss: 0.323058]\n",
      "epoch:13 step:12370 [D loss: 0.246474, acc.: 53.12%] [G loss: 0.324019]\n",
      "epoch:13 step:12371 [D loss: 0.249613, acc.: 57.81%] [G loss: 0.287045]\n",
      "epoch:13 step:12372 [D loss: 0.255228, acc.: 49.22%] [G loss: 0.303220]\n",
      "epoch:13 step:12373 [D loss: 0.234578, acc.: 60.94%] [G loss: 0.322757]\n",
      "epoch:13 step:12374 [D loss: 0.247631, acc.: 51.56%] [G loss: 0.283764]\n",
      "epoch:13 step:12375 [D loss: 0.233197, acc.: 59.38%] [G loss: 0.296803]\n",
      "epoch:13 step:12376 [D loss: 0.252186, acc.: 51.56%] [G loss: 0.315473]\n",
      "epoch:13 step:12377 [D loss: 0.241730, acc.: 57.03%] [G loss: 0.278341]\n",
      "epoch:13 step:12378 [D loss: 0.239871, acc.: 58.59%] [G loss: 0.284779]\n",
      "epoch:13 step:12379 [D loss: 0.238129, acc.: 57.03%] [G loss: 0.289497]\n",
      "epoch:13 step:12380 [D loss: 0.246248, acc.: 53.91%] [G loss: 0.311416]\n",
      "epoch:13 step:12381 [D loss: 0.249441, acc.: 57.03%] [G loss: 0.287702]\n",
      "epoch:13 step:12382 [D loss: 0.235519, acc.: 60.94%] [G loss: 0.288394]\n",
      "epoch:13 step:12383 [D loss: 0.238491, acc.: 55.47%] [G loss: 0.338038]\n",
      "epoch:13 step:12384 [D loss: 0.241280, acc.: 57.81%] [G loss: 0.288032]\n",
      "epoch:13 step:12385 [D loss: 0.232602, acc.: 64.84%] [G loss: 0.292872]\n",
      "epoch:13 step:12386 [D loss: 0.227942, acc.: 64.06%] [G loss: 0.282114]\n",
      "epoch:13 step:12387 [D loss: 0.252197, acc.: 50.00%] [G loss: 0.311328]\n",
      "epoch:13 step:12388 [D loss: 0.226801, acc.: 61.72%] [G loss: 0.294453]\n",
      "epoch:13 step:12389 [D loss: 0.247933, acc.: 56.25%] [G loss: 0.296550]\n",
      "epoch:13 step:12390 [D loss: 0.238961, acc.: 56.25%] [G loss: 0.302673]\n",
      "epoch:13 step:12391 [D loss: 0.244192, acc.: 59.38%] [G loss: 0.304290]\n",
      "epoch:13 step:12392 [D loss: 0.247498, acc.: 57.03%] [G loss: 0.288753]\n",
      "epoch:13 step:12393 [D loss: 0.259420, acc.: 55.47%] [G loss: 0.275814]\n",
      "epoch:13 step:12394 [D loss: 0.231511, acc.: 65.62%] [G loss: 0.290226]\n",
      "epoch:13 step:12395 [D loss: 0.243055, acc.: 56.25%] [G loss: 0.314345]\n",
      "epoch:13 step:12396 [D loss: 0.234064, acc.: 60.94%] [G loss: 0.304347]\n",
      "epoch:13 step:12397 [D loss: 0.233668, acc.: 59.38%] [G loss: 0.308525]\n",
      "epoch:13 step:12398 [D loss: 0.245646, acc.: 55.47%] [G loss: 0.288420]\n",
      "epoch:13 step:12399 [D loss: 0.256555, acc.: 54.69%] [G loss: 0.310938]\n",
      "epoch:13 step:12400 [D loss: 0.276288, acc.: 43.75%] [G loss: 0.255658]\n",
      "epoch:13 step:12401 [D loss: 0.244813, acc.: 54.69%] [G loss: 0.303085]\n",
      "epoch:13 step:12402 [D loss: 0.234473, acc.: 55.47%] [G loss: 0.342074]\n",
      "epoch:13 step:12403 [D loss: 0.247024, acc.: 52.34%] [G loss: 0.312062]\n",
      "epoch:13 step:12404 [D loss: 0.225395, acc.: 60.16%] [G loss: 0.309388]\n",
      "epoch:13 step:12405 [D loss: 0.242837, acc.: 52.34%] [G loss: 0.280396]\n",
      "epoch:13 step:12406 [D loss: 0.254828, acc.: 50.00%] [G loss: 0.284862]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:13 step:12407 [D loss: 0.237806, acc.: 57.81%] [G loss: 0.315087]\n",
      "epoch:13 step:12408 [D loss: 0.245369, acc.: 57.03%] [G loss: 0.287937]\n",
      "epoch:13 step:12409 [D loss: 0.238609, acc.: 53.12%] [G loss: 0.276211]\n",
      "epoch:13 step:12410 [D loss: 0.249292, acc.: 50.78%] [G loss: 0.298136]\n",
      "epoch:13 step:12411 [D loss: 0.233995, acc.: 60.16%] [G loss: 0.300014]\n",
      "epoch:13 step:12412 [D loss: 0.217450, acc.: 66.41%] [G loss: 0.309001]\n",
      "epoch:13 step:12413 [D loss: 0.243574, acc.: 54.69%] [G loss: 0.297144]\n",
      "epoch:13 step:12414 [D loss: 0.238111, acc.: 58.59%] [G loss: 0.297850]\n",
      "epoch:13 step:12415 [D loss: 0.246430, acc.: 52.34%] [G loss: 0.275118]\n",
      "epoch:13 step:12416 [D loss: 0.251238, acc.: 60.16%] [G loss: 0.287385]\n",
      "epoch:13 step:12417 [D loss: 0.252613, acc.: 51.56%] [G loss: 0.287310]\n",
      "epoch:13 step:12418 [D loss: 0.248290, acc.: 53.91%] [G loss: 0.338691]\n",
      "epoch:13 step:12419 [D loss: 0.231081, acc.: 60.16%] [G loss: 0.339533]\n",
      "epoch:13 step:12420 [D loss: 0.243051, acc.: 56.25%] [G loss: 0.303120]\n",
      "epoch:13 step:12421 [D loss: 0.250258, acc.: 51.56%] [G loss: 0.303975]\n",
      "epoch:13 step:12422 [D loss: 0.229450, acc.: 57.81%] [G loss: 0.310497]\n",
      "epoch:13 step:12423 [D loss: 0.253717, acc.: 53.12%] [G loss: 0.309374]\n",
      "epoch:13 step:12424 [D loss: 0.242914, acc.: 53.12%] [G loss: 0.306811]\n",
      "epoch:13 step:12425 [D loss: 0.241990, acc.: 57.03%] [G loss: 0.287314]\n",
      "epoch:13 step:12426 [D loss: 0.227779, acc.: 62.50%] [G loss: 0.297759]\n",
      "epoch:13 step:12427 [D loss: 0.225435, acc.: 64.06%] [G loss: 0.301107]\n",
      "epoch:13 step:12428 [D loss: 0.245444, acc.: 57.03%] [G loss: 0.321597]\n",
      "epoch:13 step:12429 [D loss: 0.226618, acc.: 65.62%] [G loss: 0.291202]\n",
      "epoch:13 step:12430 [D loss: 0.242984, acc.: 54.69%] [G loss: 0.308802]\n",
      "epoch:13 step:12431 [D loss: 0.232216, acc.: 58.59%] [G loss: 0.288082]\n",
      "epoch:13 step:12432 [D loss: 0.227542, acc.: 60.94%] [G loss: 0.303903]\n",
      "epoch:13 step:12433 [D loss: 0.231134, acc.: 56.25%] [G loss: 0.298665]\n",
      "epoch:13 step:12434 [D loss: 0.234257, acc.: 57.03%] [G loss: 0.301590]\n",
      "epoch:13 step:12435 [D loss: 0.247442, acc.: 53.12%] [G loss: 0.307946]\n",
      "epoch:13 step:12436 [D loss: 0.237718, acc.: 53.12%] [G loss: 0.306068]\n",
      "epoch:13 step:12437 [D loss: 0.245610, acc.: 53.91%] [G loss: 0.289262]\n",
      "epoch:13 step:12438 [D loss: 0.236395, acc.: 59.38%] [G loss: 0.315788]\n",
      "epoch:13 step:12439 [D loss: 0.242717, acc.: 59.38%] [G loss: 0.286254]\n",
      "epoch:13 step:12440 [D loss: 0.253356, acc.: 54.69%] [G loss: 0.263504]\n",
      "epoch:13 step:12441 [D loss: 0.243047, acc.: 60.94%] [G loss: 0.318648]\n",
      "epoch:13 step:12442 [D loss: 0.229085, acc.: 63.28%] [G loss: 0.298646]\n",
      "epoch:13 step:12443 [D loss: 0.253159, acc.: 50.00%] [G loss: 0.304876]\n",
      "epoch:13 step:12444 [D loss: 0.259497, acc.: 49.22%] [G loss: 0.293075]\n",
      "epoch:13 step:12445 [D loss: 0.249451, acc.: 56.25%] [G loss: 0.297998]\n",
      "epoch:13 step:12446 [D loss: 0.235274, acc.: 58.59%] [G loss: 0.292576]\n",
      "epoch:13 step:12447 [D loss: 0.255504, acc.: 55.47%] [G loss: 0.311450]\n",
      "epoch:13 step:12448 [D loss: 0.242646, acc.: 53.91%] [G loss: 0.306033]\n",
      "epoch:13 step:12449 [D loss: 0.232978, acc.: 55.47%] [G loss: 0.294361]\n",
      "epoch:13 step:12450 [D loss: 0.257924, acc.: 49.22%] [G loss: 0.296766]\n",
      "epoch:13 step:12451 [D loss: 0.235625, acc.: 61.72%] [G loss: 0.312632]\n",
      "epoch:13 step:12452 [D loss: 0.236031, acc.: 60.16%] [G loss: 0.306847]\n",
      "epoch:13 step:12453 [D loss: 0.228659, acc.: 63.28%] [G loss: 0.280920]\n",
      "epoch:13 step:12454 [D loss: 0.250912, acc.: 55.47%] [G loss: 0.301571]\n",
      "epoch:13 step:12455 [D loss: 0.228824, acc.: 64.06%] [G loss: 0.300353]\n",
      "epoch:13 step:12456 [D loss: 0.243463, acc.: 59.38%] [G loss: 0.301804]\n",
      "epoch:13 step:12457 [D loss: 0.262500, acc.: 46.09%] [G loss: 0.288282]\n",
      "epoch:13 step:12458 [D loss: 0.239560, acc.: 57.03%] [G loss: 0.295855]\n",
      "epoch:13 step:12459 [D loss: 0.261542, acc.: 52.34%] [G loss: 0.298002]\n",
      "epoch:13 step:12460 [D loss: 0.239128, acc.: 53.12%] [G loss: 0.319299]\n",
      "epoch:13 step:12461 [D loss: 0.260017, acc.: 50.78%] [G loss: 0.277198]\n",
      "epoch:13 step:12462 [D loss: 0.258479, acc.: 50.00%] [G loss: 0.272154]\n",
      "epoch:13 step:12463 [D loss: 0.246875, acc.: 58.59%] [G loss: 0.285003]\n",
      "epoch:13 step:12464 [D loss: 0.229958, acc.: 57.81%] [G loss: 0.285720]\n",
      "epoch:13 step:12465 [D loss: 0.242345, acc.: 53.91%] [G loss: 0.305529]\n",
      "epoch:13 step:12466 [D loss: 0.240958, acc.: 54.69%] [G loss: 0.286741]\n",
      "epoch:13 step:12467 [D loss: 0.220649, acc.: 64.06%] [G loss: 0.277146]\n",
      "epoch:13 step:12468 [D loss: 0.247321, acc.: 53.12%] [G loss: 0.296734]\n",
      "epoch:13 step:12469 [D loss: 0.260453, acc.: 52.34%] [G loss: 0.301537]\n",
      "epoch:13 step:12470 [D loss: 0.230915, acc.: 60.16%] [G loss: 0.306225]\n",
      "epoch:13 step:12471 [D loss: 0.241426, acc.: 59.38%] [G loss: 0.322806]\n",
      "epoch:13 step:12472 [D loss: 0.253103, acc.: 54.69%] [G loss: 0.285623]\n",
      "epoch:13 step:12473 [D loss: 0.229054, acc.: 64.06%] [G loss: 0.294809]\n",
      "epoch:13 step:12474 [D loss: 0.247047, acc.: 56.25%] [G loss: 0.308694]\n",
      "epoch:13 step:12475 [D loss: 0.232569, acc.: 59.38%] [G loss: 0.274049]\n",
      "epoch:13 step:12476 [D loss: 0.257805, acc.: 57.03%] [G loss: 0.293912]\n",
      "epoch:13 step:12477 [D loss: 0.255495, acc.: 52.34%] [G loss: 0.304456]\n",
      "epoch:13 step:12478 [D loss: 0.237256, acc.: 64.06%] [G loss: 0.280403]\n",
      "epoch:13 step:12479 [D loss: 0.263578, acc.: 50.00%] [G loss: 0.316928]\n",
      "epoch:13 step:12480 [D loss: 0.267914, acc.: 50.78%] [G loss: 0.316136]\n",
      "epoch:13 step:12481 [D loss: 0.232408, acc.: 59.38%] [G loss: 0.297928]\n",
      "epoch:13 step:12482 [D loss: 0.242838, acc.: 60.94%] [G loss: 0.315980]\n",
      "epoch:13 step:12483 [D loss: 0.242506, acc.: 54.69%] [G loss: 0.322964]\n",
      "epoch:13 step:12484 [D loss: 0.257129, acc.: 52.34%] [G loss: 0.281868]\n",
      "epoch:13 step:12485 [D loss: 0.228540, acc.: 64.84%] [G loss: 0.313025]\n",
      "epoch:13 step:12486 [D loss: 0.251054, acc.: 50.78%] [G loss: 0.312567]\n",
      "epoch:13 step:12487 [D loss: 0.240052, acc.: 58.59%] [G loss: 0.293734]\n",
      "epoch:13 step:12488 [D loss: 0.241471, acc.: 59.38%] [G loss: 0.289911]\n",
      "epoch:13 step:12489 [D loss: 0.243963, acc.: 53.12%] [G loss: 0.284705]\n",
      "epoch:13 step:12490 [D loss: 0.238694, acc.: 55.47%] [G loss: 0.293744]\n",
      "epoch:13 step:12491 [D loss: 0.261012, acc.: 46.88%] [G loss: 0.292127]\n",
      "epoch:13 step:12492 [D loss: 0.242597, acc.: 55.47%] [G loss: 0.260106]\n",
      "epoch:13 step:12493 [D loss: 0.243786, acc.: 55.47%] [G loss: 0.298248]\n",
      "epoch:13 step:12494 [D loss: 0.241902, acc.: 56.25%] [G loss: 0.296068]\n",
      "epoch:13 step:12495 [D loss: 0.238214, acc.: 60.16%] [G loss: 0.324412]\n",
      "epoch:13 step:12496 [D loss: 0.237750, acc.: 57.03%] [G loss: 0.276223]\n",
      "epoch:13 step:12497 [D loss: 0.239561, acc.: 58.59%] [G loss: 0.292978]\n",
      "epoch:13 step:12498 [D loss: 0.230264, acc.: 64.84%] [G loss: 0.309361]\n",
      "epoch:13 step:12499 [D loss: 0.252012, acc.: 50.78%] [G loss: 0.301011]\n",
      "epoch:13 step:12500 [D loss: 0.237324, acc.: 60.94%] [G loss: 0.274987]\n",
      "epoch:13 step:12501 [D loss: 0.223263, acc.: 65.62%] [G loss: 0.286797]\n",
      "epoch:13 step:12502 [D loss: 0.225621, acc.: 61.72%] [G loss: 0.300086]\n",
      "epoch:13 step:12503 [D loss: 0.260323, acc.: 53.91%] [G loss: 0.271309]\n",
      "epoch:13 step:12504 [D loss: 0.228716, acc.: 60.94%] [G loss: 0.326191]\n",
      "epoch:13 step:12505 [D loss: 0.249370, acc.: 53.12%] [G loss: 0.313326]\n",
      "epoch:13 step:12506 [D loss: 0.230032, acc.: 62.50%] [G loss: 0.310488]\n",
      "epoch:13 step:12507 [D loss: 0.232026, acc.: 57.81%] [G loss: 0.302481]\n",
      "epoch:13 step:12508 [D loss: 0.239612, acc.: 56.25%] [G loss: 0.313768]\n",
      "epoch:13 step:12509 [D loss: 0.240199, acc.: 57.03%] [G loss: 0.305926]\n",
      "epoch:13 step:12510 [D loss: 0.245017, acc.: 53.91%] [G loss: 0.282639]\n",
      "epoch:13 step:12511 [D loss: 0.229313, acc.: 62.50%] [G loss: 0.300299]\n",
      "epoch:13 step:12512 [D loss: 0.237447, acc.: 62.50%] [G loss: 0.295794]\n",
      "epoch:13 step:12513 [D loss: 0.231707, acc.: 61.72%] [G loss: 0.311055]\n",
      "epoch:13 step:12514 [D loss: 0.252986, acc.: 50.00%] [G loss: 0.286619]\n",
      "epoch:13 step:12515 [D loss: 0.231992, acc.: 65.62%] [G loss: 0.279889]\n",
      "epoch:13 step:12516 [D loss: 0.232077, acc.: 61.72%] [G loss: 0.304048]\n",
      "epoch:13 step:12517 [D loss: 0.236147, acc.: 64.84%] [G loss: 0.275554]\n",
      "epoch:13 step:12518 [D loss: 0.238875, acc.: 57.03%] [G loss: 0.303203]\n",
      "epoch:13 step:12519 [D loss: 0.243786, acc.: 57.81%] [G loss: 0.286853]\n",
      "epoch:13 step:12520 [D loss: 0.253929, acc.: 53.12%] [G loss: 0.299988]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:13 step:12521 [D loss: 0.257333, acc.: 53.91%] [G loss: 0.271132]\n",
      "epoch:13 step:12522 [D loss: 0.242399, acc.: 60.16%] [G loss: 0.296439]\n",
      "epoch:13 step:12523 [D loss: 0.259019, acc.: 50.00%] [G loss: 0.310875]\n",
      "epoch:13 step:12524 [D loss: 0.254087, acc.: 52.34%] [G loss: 0.310279]\n",
      "epoch:13 step:12525 [D loss: 0.234152, acc.: 58.59%] [G loss: 0.316047]\n",
      "epoch:13 step:12526 [D loss: 0.253944, acc.: 57.03%] [G loss: 0.289944]\n",
      "epoch:13 step:12527 [D loss: 0.250898, acc.: 53.12%] [G loss: 0.301752]\n",
      "epoch:13 step:12528 [D loss: 0.224327, acc.: 61.72%] [G loss: 0.292875]\n",
      "epoch:13 step:12529 [D loss: 0.246299, acc.: 56.25%] [G loss: 0.302725]\n",
      "epoch:13 step:12530 [D loss: 0.233882, acc.: 62.50%] [G loss: 0.322055]\n",
      "epoch:13 step:12531 [D loss: 0.240641, acc.: 54.69%] [G loss: 0.300430]\n",
      "epoch:13 step:12532 [D loss: 0.246249, acc.: 55.47%] [G loss: 0.260420]\n",
      "epoch:13 step:12533 [D loss: 0.233140, acc.: 54.69%] [G loss: 0.262633]\n",
      "epoch:13 step:12534 [D loss: 0.252631, acc.: 51.56%] [G loss: 0.273891]\n",
      "epoch:13 step:12535 [D loss: 0.235877, acc.: 53.91%] [G loss: 0.308262]\n",
      "epoch:13 step:12536 [D loss: 0.243205, acc.: 55.47%] [G loss: 0.269699]\n",
      "epoch:13 step:12537 [D loss: 0.241652, acc.: 54.69%] [G loss: 0.267326]\n",
      "epoch:13 step:12538 [D loss: 0.229740, acc.: 62.50%] [G loss: 0.317591]\n",
      "epoch:13 step:12539 [D loss: 0.245683, acc.: 56.25%] [G loss: 0.268897]\n",
      "epoch:13 step:12540 [D loss: 0.230988, acc.: 62.50%] [G loss: 0.286359]\n",
      "epoch:13 step:12541 [D loss: 0.215963, acc.: 66.41%] [G loss: 0.304632]\n",
      "epoch:13 step:12542 [D loss: 0.232620, acc.: 61.72%] [G loss: 0.271479]\n",
      "epoch:13 step:12543 [D loss: 0.232112, acc.: 58.59%] [G loss: 0.309047]\n",
      "epoch:13 step:12544 [D loss: 0.242858, acc.: 57.81%] [G loss: 0.300989]\n",
      "epoch:13 step:12545 [D loss: 0.235217, acc.: 58.59%] [G loss: 0.264963]\n",
      "epoch:13 step:12546 [D loss: 0.242873, acc.: 57.03%] [G loss: 0.326647]\n",
      "epoch:13 step:12547 [D loss: 0.236412, acc.: 64.06%] [G loss: 0.320545]\n",
      "epoch:13 step:12548 [D loss: 0.226453, acc.: 66.41%] [G loss: 0.321365]\n",
      "epoch:13 step:12549 [D loss: 0.223388, acc.: 61.72%] [G loss: 0.292738]\n",
      "epoch:13 step:12550 [D loss: 0.240551, acc.: 60.16%] [G loss: 0.295343]\n",
      "epoch:13 step:12551 [D loss: 0.242284, acc.: 56.25%] [G loss: 0.268522]\n",
      "epoch:13 step:12552 [D loss: 0.244971, acc.: 56.25%] [G loss: 0.272179]\n",
      "epoch:13 step:12553 [D loss: 0.218352, acc.: 66.41%] [G loss: 0.296323]\n",
      "epoch:13 step:12554 [D loss: 0.236707, acc.: 53.91%] [G loss: 0.281363]\n",
      "epoch:13 step:12555 [D loss: 0.246571, acc.: 55.47%] [G loss: 0.279618]\n",
      "epoch:13 step:12556 [D loss: 0.239967, acc.: 58.59%] [G loss: 0.297524]\n",
      "epoch:13 step:12557 [D loss: 0.260687, acc.: 50.00%] [G loss: 0.294119]\n",
      "epoch:13 step:12558 [D loss: 0.227611, acc.: 60.16%] [G loss: 0.301578]\n",
      "epoch:13 step:12559 [D loss: 0.249579, acc.: 54.69%] [G loss: 0.281110]\n",
      "epoch:13 step:12560 [D loss: 0.228720, acc.: 62.50%] [G loss: 0.329835]\n",
      "epoch:13 step:12561 [D loss: 0.248350, acc.: 60.16%] [G loss: 0.298890]\n",
      "epoch:13 step:12562 [D loss: 0.248702, acc.: 56.25%] [G loss: 0.283260]\n",
      "epoch:13 step:12563 [D loss: 0.243314, acc.: 59.38%] [G loss: 0.275820]\n",
      "epoch:13 step:12564 [D loss: 0.215668, acc.: 66.41%] [G loss: 0.297699]\n",
      "epoch:13 step:12565 [D loss: 0.246966, acc.: 53.12%] [G loss: 0.288692]\n",
      "epoch:13 step:12566 [D loss: 0.240870, acc.: 56.25%] [G loss: 0.290959]\n",
      "epoch:13 step:12567 [D loss: 0.250858, acc.: 53.91%] [G loss: 0.278664]\n",
      "epoch:13 step:12568 [D loss: 0.233917, acc.: 57.03%] [G loss: 0.261033]\n",
      "epoch:13 step:12569 [D loss: 0.231850, acc.: 60.94%] [G loss: 0.276696]\n",
      "epoch:13 step:12570 [D loss: 0.256594, acc.: 53.12%] [G loss: 0.302237]\n",
      "epoch:13 step:12571 [D loss: 0.248606, acc.: 55.47%] [G loss: 0.308937]\n",
      "epoch:13 step:12572 [D loss: 0.234099, acc.: 62.50%] [G loss: 0.296233]\n",
      "epoch:13 step:12573 [D loss: 0.227776, acc.: 60.94%] [G loss: 0.311124]\n",
      "epoch:13 step:12574 [D loss: 0.240382, acc.: 56.25%] [G loss: 0.286737]\n",
      "epoch:13 step:12575 [D loss: 0.231397, acc.: 62.50%] [G loss: 0.339864]\n",
      "epoch:13 step:12576 [D loss: 0.248321, acc.: 55.47%] [G loss: 0.297344]\n",
      "epoch:13 step:12577 [D loss: 0.251759, acc.: 53.12%] [G loss: 0.306556]\n",
      "epoch:13 step:12578 [D loss: 0.246386, acc.: 55.47%] [G loss: 0.301485]\n",
      "epoch:13 step:12579 [D loss: 0.240380, acc.: 55.47%] [G loss: 0.323622]\n",
      "epoch:13 step:12580 [D loss: 0.235192, acc.: 66.41%] [G loss: 0.306554]\n",
      "epoch:13 step:12581 [D loss: 0.234510, acc.: 62.50%] [G loss: 0.276310]\n",
      "epoch:13 step:12582 [D loss: 0.244362, acc.: 53.91%] [G loss: 0.322115]\n",
      "epoch:13 step:12583 [D loss: 0.230533, acc.: 60.16%] [G loss: 0.317018]\n",
      "epoch:13 step:12584 [D loss: 0.230462, acc.: 57.81%] [G loss: 0.301316]\n",
      "epoch:13 step:12585 [D loss: 0.240044, acc.: 55.47%] [G loss: 0.316824]\n",
      "epoch:13 step:12586 [D loss: 0.227172, acc.: 60.94%] [G loss: 0.306913]\n",
      "epoch:13 step:12587 [D loss: 0.231291, acc.: 60.16%] [G loss: 0.295638]\n",
      "epoch:13 step:12588 [D loss: 0.227181, acc.: 60.94%] [G loss: 0.290284]\n",
      "epoch:13 step:12589 [D loss: 0.242113, acc.: 56.25%] [G loss: 0.298015]\n",
      "epoch:13 step:12590 [D loss: 0.246885, acc.: 62.50%] [G loss: 0.296429]\n",
      "epoch:13 step:12591 [D loss: 0.243408, acc.: 57.81%] [G loss: 0.303263]\n",
      "epoch:13 step:12592 [D loss: 0.233040, acc.: 57.81%] [G loss: 0.308463]\n",
      "epoch:13 step:12593 [D loss: 0.229848, acc.: 56.25%] [G loss: 0.323606]\n",
      "epoch:13 step:12594 [D loss: 0.258058, acc.: 51.56%] [G loss: 0.300047]\n",
      "epoch:13 step:12595 [D loss: 0.249216, acc.: 59.38%] [G loss: 0.282258]\n",
      "epoch:13 step:12596 [D loss: 0.235585, acc.: 60.94%] [G loss: 0.332555]\n",
      "epoch:13 step:12597 [D loss: 0.235391, acc.: 59.38%] [G loss: 0.301511]\n",
      "epoch:13 step:12598 [D loss: 0.228528, acc.: 59.38%] [G loss: 0.321241]\n",
      "epoch:13 step:12599 [D loss: 0.249766, acc.: 53.12%] [G loss: 0.305399]\n",
      "epoch:13 step:12600 [D loss: 0.232291, acc.: 62.50%] [G loss: 0.266828]\n",
      "epoch:13 step:12601 [D loss: 0.231269, acc.: 62.50%] [G loss: 0.293031]\n",
      "epoch:13 step:12602 [D loss: 0.258312, acc.: 50.00%] [G loss: 0.311550]\n",
      "epoch:13 step:12603 [D loss: 0.237749, acc.: 60.16%] [G loss: 0.317550]\n",
      "epoch:13 step:12604 [D loss: 0.244410, acc.: 60.16%] [G loss: 0.288910]\n",
      "epoch:13 step:12605 [D loss: 0.238945, acc.: 56.25%] [G loss: 0.301675]\n",
      "epoch:13 step:12606 [D loss: 0.251273, acc.: 54.69%] [G loss: 0.262323]\n",
      "epoch:13 step:12607 [D loss: 0.242508, acc.: 59.38%] [G loss: 0.288664]\n",
      "epoch:13 step:12608 [D loss: 0.244388, acc.: 53.12%] [G loss: 0.313500]\n",
      "epoch:13 step:12609 [D loss: 0.243849, acc.: 55.47%] [G loss: 0.292850]\n",
      "epoch:13 step:12610 [D loss: 0.238194, acc.: 59.38%] [G loss: 0.320746]\n",
      "epoch:13 step:12611 [D loss: 0.246138, acc.: 55.47%] [G loss: 0.283909]\n",
      "epoch:13 step:12612 [D loss: 0.236287, acc.: 59.38%] [G loss: 0.309879]\n",
      "epoch:13 step:12613 [D loss: 0.243646, acc.: 52.34%] [G loss: 0.297987]\n",
      "epoch:13 step:12614 [D loss: 0.240645, acc.: 60.16%] [G loss: 0.292138]\n",
      "epoch:13 step:12615 [D loss: 0.231148, acc.: 64.84%] [G loss: 0.300572]\n",
      "epoch:13 step:12616 [D loss: 0.227374, acc.: 60.94%] [G loss: 0.293776]\n",
      "epoch:13 step:12617 [D loss: 0.247029, acc.: 53.12%] [G loss: 0.311679]\n",
      "epoch:13 step:12618 [D loss: 0.252357, acc.: 56.25%] [G loss: 0.291477]\n",
      "epoch:13 step:12619 [D loss: 0.249151, acc.: 53.91%] [G loss: 0.300209]\n",
      "epoch:13 step:12620 [D loss: 0.257238, acc.: 55.47%] [G loss: 0.293726]\n",
      "epoch:13 step:12621 [D loss: 0.243151, acc.: 50.78%] [G loss: 0.294395]\n",
      "epoch:13 step:12622 [D loss: 0.227170, acc.: 64.06%] [G loss: 0.285447]\n",
      "epoch:13 step:12623 [D loss: 0.252239, acc.: 53.91%] [G loss: 0.283227]\n",
      "epoch:13 step:12624 [D loss: 0.211248, acc.: 67.97%] [G loss: 0.312502]\n",
      "epoch:13 step:12625 [D loss: 0.242551, acc.: 55.47%] [G loss: 0.278271]\n",
      "epoch:13 step:12626 [D loss: 0.229404, acc.: 63.28%] [G loss: 0.308407]\n",
      "epoch:13 step:12627 [D loss: 0.269399, acc.: 47.66%] [G loss: 0.301459]\n",
      "epoch:13 step:12628 [D loss: 0.243736, acc.: 58.59%] [G loss: 0.336572]\n",
      "epoch:13 step:12629 [D loss: 0.236871, acc.: 53.12%] [G loss: 0.295102]\n",
      "epoch:13 step:12630 [D loss: 0.236069, acc.: 61.72%] [G loss: 0.289670]\n",
      "epoch:13 step:12631 [D loss: 0.248146, acc.: 52.34%] [G loss: 0.289109]\n",
      "epoch:13 step:12632 [D loss: 0.229762, acc.: 57.03%] [G loss: 0.283784]\n",
      "epoch:13 step:12633 [D loss: 0.241431, acc.: 60.16%] [G loss: 0.285703]\n",
      "epoch:13 step:12634 [D loss: 0.240551, acc.: 57.81%] [G loss: 0.286598]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:13 step:12635 [D loss: 0.226774, acc.: 62.50%] [G loss: 0.330792]\n",
      "epoch:13 step:12636 [D loss: 0.235868, acc.: 58.59%] [G loss: 0.318931]\n",
      "epoch:13 step:12637 [D loss: 0.239032, acc.: 58.59%] [G loss: 0.296847]\n",
      "epoch:13 step:12638 [D loss: 0.244455, acc.: 52.34%] [G loss: 0.301028]\n",
      "epoch:13 step:12639 [D loss: 0.248300, acc.: 57.81%] [G loss: 0.288122]\n",
      "epoch:13 step:12640 [D loss: 0.234657, acc.: 58.59%] [G loss: 0.315924]\n",
      "epoch:13 step:12641 [D loss: 0.210410, acc.: 68.75%] [G loss: 0.308391]\n",
      "epoch:13 step:12642 [D loss: 0.232921, acc.: 60.16%] [G loss: 0.328506]\n",
      "epoch:13 step:12643 [D loss: 0.246156, acc.: 57.03%] [G loss: 0.291729]\n",
      "epoch:13 step:12644 [D loss: 0.226189, acc.: 64.84%] [G loss: 0.305191]\n",
      "epoch:13 step:12645 [D loss: 0.233376, acc.: 57.81%] [G loss: 0.294658]\n",
      "epoch:13 step:12646 [D loss: 0.249389, acc.: 50.78%] [G loss: 0.331996]\n",
      "epoch:13 step:12647 [D loss: 0.264094, acc.: 44.53%] [G loss: 0.290777]\n",
      "epoch:13 step:12648 [D loss: 0.230852, acc.: 63.28%] [G loss: 0.311951]\n",
      "epoch:13 step:12649 [D loss: 0.220006, acc.: 64.84%] [G loss: 0.289567]\n",
      "epoch:13 step:12650 [D loss: 0.242314, acc.: 56.25%] [G loss: 0.301338]\n",
      "epoch:13 step:12651 [D loss: 0.252450, acc.: 47.66%] [G loss: 0.294794]\n",
      "epoch:13 step:12652 [D loss: 0.255092, acc.: 48.44%] [G loss: 0.288855]\n",
      "epoch:13 step:12653 [D loss: 0.261761, acc.: 46.09%] [G loss: 0.282159]\n",
      "epoch:13 step:12654 [D loss: 0.238639, acc.: 55.47%] [G loss: 0.302054]\n",
      "epoch:13 step:12655 [D loss: 0.240568, acc.: 60.16%] [G loss: 0.280960]\n",
      "epoch:13 step:12656 [D loss: 0.221481, acc.: 64.06%] [G loss: 0.303822]\n",
      "epoch:13 step:12657 [D loss: 0.248587, acc.: 54.69%] [G loss: 0.292792]\n",
      "epoch:13 step:12658 [D loss: 0.228355, acc.: 61.72%] [G loss: 0.326148]\n",
      "epoch:13 step:12659 [D loss: 0.233043, acc.: 61.72%] [G loss: 0.271390]\n",
      "epoch:13 step:12660 [D loss: 0.234348, acc.: 61.72%] [G loss: 0.305453]\n",
      "epoch:13 step:12661 [D loss: 0.244736, acc.: 56.25%] [G loss: 0.268919]\n",
      "epoch:13 step:12662 [D loss: 0.239059, acc.: 59.38%] [G loss: 0.318243]\n",
      "epoch:13 step:12663 [D loss: 0.230514, acc.: 64.06%] [G loss: 0.309874]\n",
      "epoch:13 step:12664 [D loss: 0.249456, acc.: 57.03%] [G loss: 0.280465]\n",
      "epoch:13 step:12665 [D loss: 0.252249, acc.: 55.47%] [G loss: 0.274457]\n",
      "epoch:13 step:12666 [D loss: 0.245116, acc.: 55.47%] [G loss: 0.287875]\n",
      "epoch:13 step:12667 [D loss: 0.237510, acc.: 54.69%] [G loss: 0.315564]\n",
      "epoch:13 step:12668 [D loss: 0.243365, acc.: 60.16%] [G loss: 0.278416]\n",
      "epoch:13 step:12669 [D loss: 0.235752, acc.: 57.03%] [G loss: 0.290661]\n",
      "epoch:13 step:12670 [D loss: 0.247017, acc.: 60.94%] [G loss: 0.324734]\n",
      "epoch:13 step:12671 [D loss: 0.245671, acc.: 55.47%] [G loss: 0.293005]\n",
      "epoch:13 step:12672 [D loss: 0.240870, acc.: 58.59%] [G loss: 0.282681]\n",
      "epoch:13 step:12673 [D loss: 0.261153, acc.: 46.09%] [G loss: 0.299705]\n",
      "epoch:13 step:12674 [D loss: 0.232241, acc.: 58.59%] [G loss: 0.274225]\n",
      "epoch:13 step:12675 [D loss: 0.252708, acc.: 57.03%] [G loss: 0.307259]\n",
      "epoch:13 step:12676 [D loss: 0.230379, acc.: 59.38%] [G loss: 0.304188]\n",
      "epoch:13 step:12677 [D loss: 0.226152, acc.: 67.97%] [G loss: 0.308982]\n",
      "epoch:13 step:12678 [D loss: 0.242299, acc.: 58.59%] [G loss: 0.311469]\n",
      "epoch:13 step:12679 [D loss: 0.241015, acc.: 57.81%] [G loss: 0.300326]\n",
      "epoch:13 step:12680 [D loss: 0.220568, acc.: 66.41%] [G loss: 0.304395]\n",
      "epoch:13 step:12681 [D loss: 0.242046, acc.: 57.81%] [G loss: 0.267350]\n",
      "epoch:13 step:12682 [D loss: 0.254999, acc.: 49.22%] [G loss: 0.302008]\n",
      "epoch:13 step:12683 [D loss: 0.229149, acc.: 64.06%] [G loss: 0.303017]\n",
      "epoch:13 step:12684 [D loss: 0.241512, acc.: 52.34%] [G loss: 0.278187]\n",
      "epoch:13 step:12685 [D loss: 0.255772, acc.: 55.47%] [G loss: 0.306090]\n",
      "epoch:13 step:12686 [D loss: 0.230520, acc.: 65.62%] [G loss: 0.313803]\n",
      "epoch:13 step:12687 [D loss: 0.235084, acc.: 55.47%] [G loss: 0.316939]\n",
      "epoch:13 step:12688 [D loss: 0.240707, acc.: 55.47%] [G loss: 0.281512]\n",
      "epoch:13 step:12689 [D loss: 0.228854, acc.: 63.28%] [G loss: 0.312378]\n",
      "epoch:13 step:12690 [D loss: 0.247482, acc.: 56.25%] [G loss: 0.259692]\n",
      "epoch:13 step:12691 [D loss: 0.241640, acc.: 60.94%] [G loss: 0.277666]\n",
      "epoch:13 step:12692 [D loss: 0.240522, acc.: 63.28%] [G loss: 0.317990]\n",
      "epoch:13 step:12693 [D loss: 0.241511, acc.: 59.38%] [G loss: 0.318157]\n",
      "epoch:13 step:12694 [D loss: 0.248681, acc.: 57.81%] [G loss: 0.292411]\n",
      "epoch:13 step:12695 [D loss: 0.259133, acc.: 54.69%] [G loss: 0.302216]\n",
      "epoch:13 step:12696 [D loss: 0.239433, acc.: 57.81%] [G loss: 0.288695]\n",
      "epoch:13 step:12697 [D loss: 0.226013, acc.: 62.50%] [G loss: 0.308040]\n",
      "epoch:13 step:12698 [D loss: 0.231986, acc.: 62.50%] [G loss: 0.311154]\n",
      "epoch:13 step:12699 [D loss: 0.240838, acc.: 61.72%] [G loss: 0.327834]\n",
      "epoch:13 step:12700 [D loss: 0.220898, acc.: 61.72%] [G loss: 0.309599]\n",
      "epoch:13 step:12701 [D loss: 0.237610, acc.: 61.72%] [G loss: 0.322127]\n",
      "epoch:13 step:12702 [D loss: 0.253630, acc.: 52.34%] [G loss: 0.325682]\n",
      "epoch:13 step:12703 [D loss: 0.233978, acc.: 63.28%] [G loss: 0.311003]\n",
      "epoch:13 step:12704 [D loss: 0.245358, acc.: 51.56%] [G loss: 0.279747]\n",
      "epoch:13 step:12705 [D loss: 0.227478, acc.: 62.50%] [G loss: 0.281408]\n",
      "epoch:13 step:12706 [D loss: 0.245535, acc.: 52.34%] [G loss: 0.310368]\n",
      "epoch:13 step:12707 [D loss: 0.256376, acc.: 53.12%] [G loss: 0.315730]\n",
      "epoch:13 step:12708 [D loss: 0.238115, acc.: 59.38%] [G loss: 0.307932]\n",
      "epoch:13 step:12709 [D loss: 0.216291, acc.: 63.28%] [G loss: 0.317399]\n",
      "epoch:13 step:12710 [D loss: 0.238382, acc.: 57.81%] [G loss: 0.267991]\n",
      "epoch:13 step:12711 [D loss: 0.223722, acc.: 61.72%] [G loss: 0.292634]\n",
      "epoch:13 step:12712 [D loss: 0.245552, acc.: 57.03%] [G loss: 0.320607]\n",
      "epoch:13 step:12713 [D loss: 0.220795, acc.: 69.53%] [G loss: 0.311254]\n",
      "epoch:13 step:12714 [D loss: 0.250356, acc.: 55.47%] [G loss: 0.304992]\n",
      "epoch:13 step:12715 [D loss: 0.242331, acc.: 54.69%] [G loss: 0.293210]\n",
      "epoch:13 step:12716 [D loss: 0.242776, acc.: 53.12%] [G loss: 0.303850]\n",
      "epoch:13 step:12717 [D loss: 0.252867, acc.: 49.22%] [G loss: 0.299373]\n",
      "epoch:13 step:12718 [D loss: 0.245268, acc.: 55.47%] [G loss: 0.299584]\n",
      "epoch:13 step:12719 [D loss: 0.238695, acc.: 58.59%] [G loss: 0.283458]\n",
      "epoch:13 step:12720 [D loss: 0.222522, acc.: 60.94%] [G loss: 0.309632]\n",
      "epoch:13 step:12721 [D loss: 0.221062, acc.: 67.19%] [G loss: 0.277258]\n",
      "epoch:13 step:12722 [D loss: 0.226928, acc.: 64.06%] [G loss: 0.326646]\n",
      "epoch:13 step:12723 [D loss: 0.232706, acc.: 61.72%] [G loss: 0.305826]\n",
      "epoch:13 step:12724 [D loss: 0.226497, acc.: 62.50%] [G loss: 0.291514]\n",
      "epoch:13 step:12725 [D loss: 0.262944, acc.: 52.34%] [G loss: 0.324410]\n",
      "epoch:13 step:12726 [D loss: 0.234522, acc.: 60.94%] [G loss: 0.315993]\n",
      "epoch:13 step:12727 [D loss: 0.232706, acc.: 60.94%] [G loss: 0.327165]\n",
      "epoch:13 step:12728 [D loss: 0.246215, acc.: 51.56%] [G loss: 0.271710]\n",
      "epoch:13 step:12729 [D loss: 0.253470, acc.: 57.03%] [G loss: 0.294301]\n",
      "epoch:13 step:12730 [D loss: 0.235416, acc.: 54.69%] [G loss: 0.283498]\n",
      "epoch:13 step:12731 [D loss: 0.230549, acc.: 60.16%] [G loss: 0.285766]\n",
      "epoch:13 step:12732 [D loss: 0.248557, acc.: 56.25%] [G loss: 0.296637]\n",
      "epoch:13 step:12733 [D loss: 0.247123, acc.: 58.59%] [G loss: 0.284952]\n",
      "epoch:13 step:12734 [D loss: 0.242909, acc.: 60.94%] [G loss: 0.304204]\n",
      "epoch:13 step:12735 [D loss: 0.241833, acc.: 57.03%] [G loss: 0.283918]\n",
      "epoch:13 step:12736 [D loss: 0.250461, acc.: 49.22%] [G loss: 0.303899]\n",
      "epoch:13 step:12737 [D loss: 0.241048, acc.: 53.12%] [G loss: 0.302458]\n",
      "epoch:13 step:12738 [D loss: 0.241704, acc.: 57.81%] [G loss: 0.275578]\n",
      "epoch:13 step:12739 [D loss: 0.247397, acc.: 52.34%] [G loss: 0.295054]\n",
      "epoch:13 step:12740 [D loss: 0.239518, acc.: 54.69%] [G loss: 0.298120]\n",
      "epoch:13 step:12741 [D loss: 0.252450, acc.: 53.12%] [G loss: 0.288437]\n",
      "epoch:13 step:12742 [D loss: 0.240671, acc.: 60.16%] [G loss: 0.296271]\n",
      "epoch:13 step:12743 [D loss: 0.241222, acc.: 57.03%] [G loss: 0.299740]\n",
      "epoch:13 step:12744 [D loss: 0.245638, acc.: 54.69%] [G loss: 0.289040]\n",
      "epoch:13 step:12745 [D loss: 0.231829, acc.: 61.72%] [G loss: 0.296114]\n",
      "epoch:13 step:12746 [D loss: 0.232053, acc.: 60.94%] [G loss: 0.288835]\n",
      "epoch:13 step:12747 [D loss: 0.239450, acc.: 56.25%] [G loss: 0.280791]\n",
      "epoch:13 step:12748 [D loss: 0.234492, acc.: 59.38%] [G loss: 0.296056]\n",
      "epoch:13 step:12749 [D loss: 0.245942, acc.: 54.69%] [G loss: 0.324439]\n",
      "epoch:13 step:12750 [D loss: 0.244529, acc.: 53.91%] [G loss: 0.308823]\n",
      "epoch:13 step:12751 [D loss: 0.231948, acc.: 59.38%] [G loss: 0.339024]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:13 step:12752 [D loss: 0.233652, acc.: 62.50%] [G loss: 0.319993]\n",
      "epoch:13 step:12753 [D loss: 0.234906, acc.: 64.06%] [G loss: 0.298751]\n",
      "epoch:13 step:12754 [D loss: 0.244508, acc.: 56.25%] [G loss: 0.292776]\n",
      "epoch:13 step:12755 [D loss: 0.222417, acc.: 64.06%] [G loss: 0.297012]\n",
      "epoch:13 step:12756 [D loss: 0.239397, acc.: 51.56%] [G loss: 0.325372]\n",
      "epoch:13 step:12757 [D loss: 0.213545, acc.: 73.44%] [G loss: 0.320185]\n",
      "epoch:13 step:12758 [D loss: 0.239837, acc.: 57.81%] [G loss: 0.304847]\n",
      "epoch:13 step:12759 [D loss: 0.251891, acc.: 57.81%] [G loss: 0.306604]\n",
      "epoch:13 step:12760 [D loss: 0.245357, acc.: 59.38%] [G loss: 0.300497]\n",
      "epoch:13 step:12761 [D loss: 0.253171, acc.: 50.78%] [G loss: 0.298088]\n",
      "epoch:13 step:12762 [D loss: 0.234126, acc.: 58.59%] [G loss: 0.280714]\n",
      "epoch:13 step:12763 [D loss: 0.247281, acc.: 62.50%] [G loss: 0.298059]\n",
      "epoch:13 step:12764 [D loss: 0.250735, acc.: 58.59%] [G loss: 0.296994]\n",
      "epoch:13 step:12765 [D loss: 0.236204, acc.: 61.72%] [G loss: 0.304364]\n",
      "epoch:13 step:12766 [D loss: 0.234397, acc.: 57.81%] [G loss: 0.289982]\n",
      "epoch:13 step:12767 [D loss: 0.247452, acc.: 50.78%] [G loss: 0.250346]\n",
      "epoch:13 step:12768 [D loss: 0.230925, acc.: 58.59%] [G loss: 0.301765]\n",
      "epoch:13 step:12769 [D loss: 0.234709, acc.: 58.59%] [G loss: 0.294948]\n",
      "epoch:13 step:12770 [D loss: 0.238793, acc.: 58.59%] [G loss: 0.311630]\n",
      "epoch:13 step:12771 [D loss: 0.242866, acc.: 53.12%] [G loss: 0.262769]\n",
      "epoch:13 step:12772 [D loss: 0.232728, acc.: 59.38%] [G loss: 0.289662]\n",
      "epoch:13 step:12773 [D loss: 0.248686, acc.: 55.47%] [G loss: 0.284477]\n",
      "epoch:13 step:12774 [D loss: 0.242315, acc.: 54.69%] [G loss: 0.292148]\n",
      "epoch:13 step:12775 [D loss: 0.236084, acc.: 57.03%] [G loss: 0.272644]\n",
      "epoch:13 step:12776 [D loss: 0.242541, acc.: 56.25%] [G loss: 0.309238]\n",
      "epoch:13 step:12777 [D loss: 0.233885, acc.: 63.28%] [G loss: 0.306036]\n",
      "epoch:13 step:12778 [D loss: 0.238246, acc.: 62.50%] [G loss: 0.306179]\n",
      "epoch:13 step:12779 [D loss: 0.241741, acc.: 56.25%] [G loss: 0.310837]\n",
      "epoch:13 step:12780 [D loss: 0.227004, acc.: 64.06%] [G loss: 0.305952]\n",
      "epoch:13 step:12781 [D loss: 0.252229, acc.: 52.34%] [G loss: 0.323886]\n",
      "epoch:13 step:12782 [D loss: 0.253801, acc.: 54.69%] [G loss: 0.310554]\n",
      "epoch:13 step:12783 [D loss: 0.227691, acc.: 64.84%] [G loss: 0.287883]\n",
      "epoch:13 step:12784 [D loss: 0.237051, acc.: 60.94%] [G loss: 0.319484]\n",
      "epoch:13 step:12785 [D loss: 0.255347, acc.: 52.34%] [G loss: 0.284904]\n",
      "epoch:13 step:12786 [D loss: 0.236827, acc.: 58.59%] [G loss: 0.302509]\n",
      "epoch:13 step:12787 [D loss: 0.242550, acc.: 60.16%] [G loss: 0.311370]\n",
      "epoch:13 step:12788 [D loss: 0.230817, acc.: 57.03%] [G loss: 0.324269]\n",
      "epoch:13 step:12789 [D loss: 0.230674, acc.: 64.06%] [G loss: 0.326171]\n",
      "epoch:13 step:12790 [D loss: 0.239013, acc.: 60.94%] [G loss: 0.303837]\n",
      "epoch:13 step:12791 [D loss: 0.235586, acc.: 59.38%] [G loss: 0.308615]\n",
      "epoch:13 step:12792 [D loss: 0.236178, acc.: 57.03%] [G loss: 0.292570]\n",
      "epoch:13 step:12793 [D loss: 0.233768, acc.: 60.94%] [G loss: 0.296731]\n",
      "epoch:13 step:12794 [D loss: 0.233492, acc.: 63.28%] [G loss: 0.319391]\n",
      "epoch:13 step:12795 [D loss: 0.240838, acc.: 57.81%] [G loss: 0.311564]\n",
      "epoch:13 step:12796 [D loss: 0.230822, acc.: 57.03%] [G loss: 0.314897]\n",
      "epoch:13 step:12797 [D loss: 0.243565, acc.: 56.25%] [G loss: 0.298782]\n",
      "epoch:13 step:12798 [D loss: 0.256918, acc.: 50.00%] [G loss: 0.317472]\n",
      "epoch:13 step:12799 [D loss: 0.242778, acc.: 55.47%] [G loss: 0.290533]\n",
      "epoch:13 step:12800 [D loss: 0.258969, acc.: 52.34%] [G loss: 0.267613]\n",
      "epoch:13 step:12801 [D loss: 0.254025, acc.: 51.56%] [G loss: 0.320982]\n",
      "epoch:13 step:12802 [D loss: 0.245033, acc.: 59.38%] [G loss: 0.306299]\n",
      "epoch:13 step:12803 [D loss: 0.244407, acc.: 55.47%] [G loss: 0.295717]\n",
      "epoch:13 step:12804 [D loss: 0.229963, acc.: 62.50%] [G loss: 0.316109]\n",
      "epoch:13 step:12805 [D loss: 0.246380, acc.: 56.25%] [G loss: 0.301914]\n",
      "epoch:13 step:12806 [D loss: 0.236565, acc.: 57.03%] [G loss: 0.294189]\n",
      "epoch:13 step:12807 [D loss: 0.238333, acc.: 57.81%] [G loss: 0.304953]\n",
      "epoch:13 step:12808 [D loss: 0.249227, acc.: 57.81%] [G loss: 0.284306]\n",
      "epoch:13 step:12809 [D loss: 0.252432, acc.: 51.56%] [G loss: 0.311474]\n",
      "epoch:13 step:12810 [D loss: 0.242508, acc.: 59.38%] [G loss: 0.271215]\n",
      "epoch:13 step:12811 [D loss: 0.238028, acc.: 62.50%] [G loss: 0.302249]\n",
      "epoch:13 step:12812 [D loss: 0.246493, acc.: 54.69%] [G loss: 0.288536]\n",
      "epoch:13 step:12813 [D loss: 0.233029, acc.: 59.38%] [G loss: 0.293030]\n",
      "epoch:13 step:12814 [D loss: 0.247221, acc.: 56.25%] [G loss: 0.297857]\n",
      "epoch:13 step:12815 [D loss: 0.229599, acc.: 67.97%] [G loss: 0.278442]\n",
      "epoch:13 step:12816 [D loss: 0.222953, acc.: 63.28%] [G loss: 0.292571]\n",
      "epoch:13 step:12817 [D loss: 0.245754, acc.: 53.91%] [G loss: 0.310260]\n",
      "epoch:13 step:12818 [D loss: 0.253616, acc.: 51.56%] [G loss: 0.294884]\n",
      "epoch:13 step:12819 [D loss: 0.250728, acc.: 60.94%] [G loss: 0.285938]\n",
      "epoch:13 step:12820 [D loss: 0.243159, acc.: 57.81%] [G loss: 0.301629]\n",
      "epoch:13 step:12821 [D loss: 0.226599, acc.: 64.06%] [G loss: 0.287377]\n",
      "epoch:13 step:12822 [D loss: 0.227518, acc.: 60.16%] [G loss: 0.314222]\n",
      "epoch:13 step:12823 [D loss: 0.244419, acc.: 57.03%] [G loss: 0.304700]\n",
      "epoch:13 step:12824 [D loss: 0.256317, acc.: 50.78%] [G loss: 0.295842]\n",
      "epoch:13 step:12825 [D loss: 0.245961, acc.: 52.34%] [G loss: 0.300077]\n",
      "epoch:13 step:12826 [D loss: 0.238163, acc.: 59.38%] [G loss: 0.291897]\n",
      "epoch:13 step:12827 [D loss: 0.241532, acc.: 56.25%] [G loss: 0.312205]\n",
      "epoch:13 step:12828 [D loss: 0.240008, acc.: 59.38%] [G loss: 0.274541]\n",
      "epoch:13 step:12829 [D loss: 0.235009, acc.: 61.72%] [G loss: 0.317278]\n",
      "epoch:13 step:12830 [D loss: 0.239703, acc.: 60.94%] [G loss: 0.302762]\n",
      "epoch:13 step:12831 [D loss: 0.243086, acc.: 56.25%] [G loss: 0.302919]\n",
      "epoch:13 step:12832 [D loss: 0.238131, acc.: 56.25%] [G loss: 0.282539]\n",
      "epoch:13 step:12833 [D loss: 0.235256, acc.: 58.59%] [G loss: 0.296139]\n",
      "epoch:13 step:12834 [D loss: 0.235247, acc.: 61.72%] [G loss: 0.323833]\n",
      "epoch:13 step:12835 [D loss: 0.223177, acc.: 60.16%] [G loss: 0.287140]\n",
      "epoch:13 step:12836 [D loss: 0.235035, acc.: 65.62%] [G loss: 0.321931]\n",
      "epoch:13 step:12837 [D loss: 0.250444, acc.: 54.69%] [G loss: 0.300908]\n",
      "epoch:13 step:12838 [D loss: 0.254865, acc.: 50.00%] [G loss: 0.303268]\n",
      "epoch:13 step:12839 [D loss: 0.242696, acc.: 51.56%] [G loss: 0.292806]\n",
      "epoch:13 step:12840 [D loss: 0.238915, acc.: 56.25%] [G loss: 0.289504]\n",
      "epoch:13 step:12841 [D loss: 0.247762, acc.: 55.47%] [G loss: 0.284099]\n",
      "epoch:13 step:12842 [D loss: 0.221358, acc.: 64.84%] [G loss: 0.315104]\n",
      "epoch:13 step:12843 [D loss: 0.227288, acc.: 69.53%] [G loss: 0.316563]\n",
      "epoch:13 step:12844 [D loss: 0.237254, acc.: 61.72%] [G loss: 0.310580]\n",
      "epoch:13 step:12845 [D loss: 0.256824, acc.: 50.00%] [G loss: 0.311809]\n",
      "epoch:13 step:12846 [D loss: 0.235653, acc.: 57.81%] [G loss: 0.273877]\n",
      "epoch:13 step:12847 [D loss: 0.244582, acc.: 60.16%] [G loss: 0.286419]\n",
      "epoch:13 step:12848 [D loss: 0.227062, acc.: 60.94%] [G loss: 0.316553]\n",
      "epoch:13 step:12849 [D loss: 0.242509, acc.: 57.03%] [G loss: 0.291732]\n",
      "epoch:13 step:12850 [D loss: 0.234455, acc.: 59.38%] [G loss: 0.295033]\n",
      "epoch:13 step:12851 [D loss: 0.239478, acc.: 59.38%] [G loss: 0.285290]\n",
      "epoch:13 step:12852 [D loss: 0.250763, acc.: 57.03%] [G loss: 0.297600]\n",
      "epoch:13 step:12853 [D loss: 0.239172, acc.: 57.81%] [G loss: 0.299266]\n",
      "epoch:13 step:12854 [D loss: 0.245964, acc.: 54.69%] [G loss: 0.335396]\n",
      "epoch:13 step:12855 [D loss: 0.245038, acc.: 58.59%] [G loss: 0.309466]\n",
      "epoch:13 step:12856 [D loss: 0.228108, acc.: 62.50%] [G loss: 0.306550]\n",
      "epoch:13 step:12857 [D loss: 0.243798, acc.: 55.47%] [G loss: 0.280396]\n",
      "epoch:13 step:12858 [D loss: 0.226654, acc.: 60.94%] [G loss: 0.293557]\n",
      "epoch:13 step:12859 [D loss: 0.234757, acc.: 59.38%] [G loss: 0.291884]\n",
      "epoch:13 step:12860 [D loss: 0.239176, acc.: 54.69%] [G loss: 0.318227]\n",
      "epoch:13 step:12861 [D loss: 0.242405, acc.: 53.91%] [G loss: 0.281196]\n",
      "epoch:13 step:12862 [D loss: 0.249384, acc.: 52.34%] [G loss: 0.307041]\n",
      "epoch:13 step:12863 [D loss: 0.229816, acc.: 61.72%] [G loss: 0.286310]\n",
      "epoch:13 step:12864 [D loss: 0.246121, acc.: 57.03%] [G loss: 0.304435]\n",
      "epoch:13 step:12865 [D loss: 0.243979, acc.: 56.25%] [G loss: 0.292984]\n",
      "epoch:13 step:12866 [D loss: 0.234776, acc.: 59.38%] [G loss: 0.288532]\n",
      "epoch:13 step:12867 [D loss: 0.234100, acc.: 62.50%] [G loss: 0.312380]\n",
      "epoch:13 step:12868 [D loss: 0.241502, acc.: 58.59%] [G loss: 0.292785]\n",
      "epoch:13 step:12869 [D loss: 0.230449, acc.: 58.59%] [G loss: 0.300101]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:13 step:12870 [D loss: 0.240969, acc.: 60.16%] [G loss: 0.275784]\n",
      "epoch:13 step:12871 [D loss: 0.230373, acc.: 65.62%] [G loss: 0.298350]\n",
      "epoch:13 step:12872 [D loss: 0.235268, acc.: 62.50%] [G loss: 0.285146]\n",
      "epoch:13 step:12873 [D loss: 0.249192, acc.: 51.56%] [G loss: 0.293458]\n",
      "epoch:13 step:12874 [D loss: 0.252493, acc.: 53.12%] [G loss: 0.279423]\n",
      "epoch:13 step:12875 [D loss: 0.226602, acc.: 61.72%] [G loss: 0.300903]\n",
      "epoch:13 step:12876 [D loss: 0.225380, acc.: 67.19%] [G loss: 0.298232]\n",
      "epoch:13 step:12877 [D loss: 0.249813, acc.: 58.59%] [G loss: 0.292629]\n",
      "epoch:13 step:12878 [D loss: 0.254683, acc.: 51.56%] [G loss: 0.289638]\n",
      "epoch:13 step:12879 [D loss: 0.245903, acc.: 60.16%] [G loss: 0.305376]\n",
      "epoch:13 step:12880 [D loss: 0.258093, acc.: 50.78%] [G loss: 0.274406]\n",
      "epoch:13 step:12881 [D loss: 0.229173, acc.: 63.28%] [G loss: 0.304929]\n",
      "epoch:13 step:12882 [D loss: 0.250208, acc.: 60.16%] [G loss: 0.297670]\n",
      "epoch:13 step:12883 [D loss: 0.230158, acc.: 60.94%] [G loss: 0.304154]\n",
      "epoch:13 step:12884 [D loss: 0.261144, acc.: 52.34%] [G loss: 0.270478]\n",
      "epoch:13 step:12885 [D loss: 0.271560, acc.: 46.88%] [G loss: 0.304218]\n",
      "epoch:13 step:12886 [D loss: 0.230565, acc.: 66.41%] [G loss: 0.286359]\n",
      "epoch:13 step:12887 [D loss: 0.249343, acc.: 51.56%] [G loss: 0.308619]\n",
      "epoch:13 step:12888 [D loss: 0.230405, acc.: 60.94%] [G loss: 0.307195]\n",
      "epoch:13 step:12889 [D loss: 0.240997, acc.: 58.59%] [G loss: 0.304320]\n",
      "epoch:13 step:12890 [D loss: 0.252050, acc.: 53.12%] [G loss: 0.274092]\n",
      "epoch:13 step:12891 [D loss: 0.239464, acc.: 54.69%] [G loss: 0.294766]\n",
      "epoch:13 step:12892 [D loss: 0.221827, acc.: 67.19%] [G loss: 0.281680]\n",
      "epoch:13 step:12893 [D loss: 0.243791, acc.: 53.91%] [G loss: 0.294799]\n",
      "epoch:13 step:12894 [D loss: 0.232776, acc.: 57.81%] [G loss: 0.319337]\n",
      "epoch:13 step:12895 [D loss: 0.250125, acc.: 53.12%] [G loss: 0.286681]\n",
      "epoch:13 step:12896 [D loss: 0.254993, acc.: 49.22%] [G loss: 0.277208]\n",
      "epoch:13 step:12897 [D loss: 0.255602, acc.: 52.34%] [G loss: 0.304981]\n",
      "epoch:13 step:12898 [D loss: 0.244610, acc.: 56.25%] [G loss: 0.299496]\n",
      "epoch:13 step:12899 [D loss: 0.230864, acc.: 62.50%] [G loss: 0.304733]\n",
      "epoch:13 step:12900 [D loss: 0.248999, acc.: 53.91%] [G loss: 0.291043]\n",
      "epoch:13 step:12901 [D loss: 0.257466, acc.: 51.56%] [G loss: 0.285203]\n",
      "epoch:13 step:12902 [D loss: 0.243250, acc.: 53.91%] [G loss: 0.287833]\n",
      "epoch:13 step:12903 [D loss: 0.250105, acc.: 52.34%] [G loss: 0.302214]\n",
      "epoch:13 step:12904 [D loss: 0.238314, acc.: 60.16%] [G loss: 0.310786]\n",
      "epoch:13 step:12905 [D loss: 0.244139, acc.: 53.91%] [G loss: 0.317051]\n",
      "epoch:13 step:12906 [D loss: 0.239710, acc.: 59.38%] [G loss: 0.299297]\n",
      "epoch:13 step:12907 [D loss: 0.254679, acc.: 49.22%] [G loss: 0.290417]\n",
      "epoch:13 step:12908 [D loss: 0.239910, acc.: 58.59%] [G loss: 0.316350]\n",
      "epoch:13 step:12909 [D loss: 0.245368, acc.: 55.47%] [G loss: 0.283865]\n",
      "epoch:13 step:12910 [D loss: 0.231712, acc.: 64.06%] [G loss: 0.292185]\n",
      "epoch:13 step:12911 [D loss: 0.246565, acc.: 57.03%] [G loss: 0.283038]\n",
      "epoch:13 step:12912 [D loss: 0.238466, acc.: 58.59%] [G loss: 0.281530]\n",
      "epoch:13 step:12913 [D loss: 0.241578, acc.: 57.81%] [G loss: 0.293856]\n",
      "epoch:13 step:12914 [D loss: 0.242541, acc.: 54.69%] [G loss: 0.308494]\n",
      "epoch:13 step:12915 [D loss: 0.234585, acc.: 64.84%] [G loss: 0.297081]\n",
      "epoch:13 step:12916 [D loss: 0.246479, acc.: 58.59%] [G loss: 0.294178]\n",
      "epoch:13 step:12917 [D loss: 0.251467, acc.: 54.69%] [G loss: 0.270748]\n",
      "epoch:13 step:12918 [D loss: 0.240839, acc.: 53.91%] [G loss: 0.278099]\n",
      "epoch:13 step:12919 [D loss: 0.238127, acc.: 58.59%] [G loss: 0.313794]\n",
      "epoch:13 step:12920 [D loss: 0.254320, acc.: 55.47%] [G loss: 0.296799]\n",
      "epoch:13 step:12921 [D loss: 0.234535, acc.: 59.38%] [G loss: 0.309661]\n",
      "epoch:13 step:12922 [D loss: 0.242102, acc.: 60.16%] [G loss: 0.265657]\n",
      "epoch:13 step:12923 [D loss: 0.245630, acc.: 55.47%] [G loss: 0.284926]\n",
      "epoch:13 step:12924 [D loss: 0.253092, acc.: 56.25%] [G loss: 0.322911]\n",
      "epoch:13 step:12925 [D loss: 0.235231, acc.: 61.72%] [G loss: 0.319480]\n",
      "epoch:13 step:12926 [D loss: 0.243734, acc.: 57.81%] [G loss: 0.308190]\n",
      "epoch:13 step:12927 [D loss: 0.240212, acc.: 56.25%] [G loss: 0.285150]\n",
      "epoch:13 step:12928 [D loss: 0.249190, acc.: 58.59%] [G loss: 0.322567]\n",
      "epoch:13 step:12929 [D loss: 0.237433, acc.: 62.50%] [G loss: 0.296263]\n",
      "epoch:13 step:12930 [D loss: 0.226190, acc.: 59.38%] [G loss: 0.324200]\n",
      "epoch:13 step:12931 [D loss: 0.239733, acc.: 59.38%] [G loss: 0.300897]\n",
      "epoch:13 step:12932 [D loss: 0.233311, acc.: 58.59%] [G loss: 0.294397]\n",
      "epoch:13 step:12933 [D loss: 0.254805, acc.: 52.34%] [G loss: 0.302060]\n",
      "epoch:13 step:12934 [D loss: 0.240616, acc.: 53.91%] [G loss: 0.290324]\n",
      "epoch:13 step:12935 [D loss: 0.250996, acc.: 52.34%] [G loss: 0.310772]\n",
      "epoch:13 step:12936 [D loss: 0.234679, acc.: 62.50%] [G loss: 0.314157]\n",
      "epoch:13 step:12937 [D loss: 0.238785, acc.: 57.03%] [G loss: 0.297460]\n",
      "epoch:13 step:12938 [D loss: 0.231963, acc.: 60.94%] [G loss: 0.312146]\n",
      "epoch:13 step:12939 [D loss: 0.230365, acc.: 57.03%] [G loss: 0.312549]\n",
      "epoch:13 step:12940 [D loss: 0.242200, acc.: 57.03%] [G loss: 0.285585]\n",
      "epoch:13 step:12941 [D loss: 0.231581, acc.: 60.16%] [G loss: 0.315191]\n",
      "epoch:13 step:12942 [D loss: 0.239671, acc.: 62.50%] [G loss: 0.296747]\n",
      "epoch:13 step:12943 [D loss: 0.222301, acc.: 62.50%] [G loss: 0.314221]\n",
      "epoch:13 step:12944 [D loss: 0.238148, acc.: 58.59%] [G loss: 0.278483]\n",
      "epoch:13 step:12945 [D loss: 0.239305, acc.: 57.81%] [G loss: 0.311871]\n",
      "epoch:13 step:12946 [D loss: 0.240700, acc.: 56.25%] [G loss: 0.289507]\n",
      "epoch:13 step:12947 [D loss: 0.244860, acc.: 61.72%] [G loss: 0.302778]\n",
      "epoch:13 step:12948 [D loss: 0.233641, acc.: 57.03%] [G loss: 0.327826]\n",
      "epoch:13 step:12949 [D loss: 0.244531, acc.: 55.47%] [G loss: 0.295479]\n",
      "epoch:13 step:12950 [D loss: 0.233674, acc.: 60.16%] [G loss: 0.312352]\n",
      "epoch:13 step:12951 [D loss: 0.246741, acc.: 50.78%] [G loss: 0.297206]\n",
      "epoch:13 step:12952 [D loss: 0.248156, acc.: 56.25%] [G loss: 0.283734]\n",
      "epoch:13 step:12953 [D loss: 0.230378, acc.: 63.28%] [G loss: 0.304417]\n",
      "epoch:13 step:12954 [D loss: 0.262722, acc.: 53.12%] [G loss: 0.323175]\n",
      "epoch:13 step:12955 [D loss: 0.244999, acc.: 64.84%] [G loss: 0.318491]\n",
      "epoch:13 step:12956 [D loss: 0.247567, acc.: 52.34%] [G loss: 0.293149]\n",
      "epoch:13 step:12957 [D loss: 0.231332, acc.: 59.38%] [G loss: 0.302303]\n",
      "epoch:13 step:12958 [D loss: 0.227080, acc.: 61.72%] [G loss: 0.313713]\n",
      "epoch:13 step:12959 [D loss: 0.247377, acc.: 64.84%] [G loss: 0.322418]\n",
      "epoch:13 step:12960 [D loss: 0.235810, acc.: 58.59%] [G loss: 0.311644]\n",
      "epoch:13 step:12961 [D loss: 0.247571, acc.: 53.91%] [G loss: 0.294447]\n",
      "epoch:13 step:12962 [D loss: 0.236305, acc.: 61.72%] [G loss: 0.312055]\n",
      "epoch:13 step:12963 [D loss: 0.241721, acc.: 53.91%] [G loss: 0.296017]\n",
      "epoch:13 step:12964 [D loss: 0.248640, acc.: 58.59%] [G loss: 0.304115]\n",
      "epoch:13 step:12965 [D loss: 0.246529, acc.: 49.22%] [G loss: 0.289476]\n",
      "epoch:13 step:12966 [D loss: 0.255436, acc.: 50.78%] [G loss: 0.289532]\n",
      "epoch:13 step:12967 [D loss: 0.244295, acc.: 53.91%] [G loss: 0.293443]\n",
      "epoch:13 step:12968 [D loss: 0.244100, acc.: 57.03%] [G loss: 0.271395]\n",
      "epoch:13 step:12969 [D loss: 0.233624, acc.: 62.50%] [G loss: 0.311637]\n",
      "epoch:13 step:12970 [D loss: 0.246663, acc.: 53.12%] [G loss: 0.308607]\n",
      "epoch:13 step:12971 [D loss: 0.238478, acc.: 59.38%] [G loss: 0.314234]\n",
      "epoch:13 step:12972 [D loss: 0.231813, acc.: 60.16%] [G loss: 0.293355]\n",
      "epoch:13 step:12973 [D loss: 0.253087, acc.: 52.34%] [G loss: 0.276714]\n",
      "epoch:13 step:12974 [D loss: 0.253687, acc.: 53.91%] [G loss: 0.315965]\n",
      "epoch:13 step:12975 [D loss: 0.230191, acc.: 61.72%] [G loss: 0.288229]\n",
      "epoch:13 step:12976 [D loss: 0.237786, acc.: 56.25%] [G loss: 0.304383]\n",
      "epoch:13 step:12977 [D loss: 0.233211, acc.: 60.94%] [G loss: 0.267467]\n",
      "epoch:13 step:12978 [D loss: 0.244398, acc.: 57.03%] [G loss: 0.280711]\n",
      "epoch:13 step:12979 [D loss: 0.241121, acc.: 60.16%] [G loss: 0.298066]\n",
      "epoch:13 step:12980 [D loss: 0.245670, acc.: 52.34%] [G loss: 0.283289]\n",
      "epoch:13 step:12981 [D loss: 0.247699, acc.: 56.25%] [G loss: 0.298560]\n",
      "epoch:13 step:12982 [D loss: 0.246773, acc.: 53.12%] [G loss: 0.320770]\n",
      "epoch:13 step:12983 [D loss: 0.254331, acc.: 52.34%] [G loss: 0.302017]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:13 step:12984 [D loss: 0.244647, acc.: 53.91%] [G loss: 0.282128]\n",
      "epoch:13 step:12985 [D loss: 0.246224, acc.: 54.69%] [G loss: 0.318474]\n",
      "epoch:13 step:12986 [D loss: 0.245152, acc.: 54.69%] [G loss: 0.304367]\n",
      "epoch:13 step:12987 [D loss: 0.244010, acc.: 60.94%] [G loss: 0.280029]\n",
      "epoch:13 step:12988 [D loss: 0.241653, acc.: 58.59%] [G loss: 0.313908]\n",
      "epoch:13 step:12989 [D loss: 0.238068, acc.: 62.50%] [G loss: 0.285256]\n",
      "epoch:13 step:12990 [D loss: 0.233457, acc.: 64.06%] [G loss: 0.266822]\n",
      "epoch:13 step:12991 [D loss: 0.231585, acc.: 64.06%] [G loss: 0.297640]\n",
      "epoch:13 step:12992 [D loss: 0.236666, acc.: 64.84%] [G loss: 0.273247]\n",
      "epoch:13 step:12993 [D loss: 0.241917, acc.: 52.34%] [G loss: 0.293237]\n",
      "epoch:13 step:12994 [D loss: 0.238052, acc.: 65.62%] [G loss: 0.311029]\n",
      "epoch:13 step:12995 [D loss: 0.244270, acc.: 56.25%] [G loss: 0.281443]\n",
      "epoch:13 step:12996 [D loss: 0.243989, acc.: 56.25%] [G loss: 0.267447]\n",
      "epoch:13 step:12997 [D loss: 0.236212, acc.: 62.50%] [G loss: 0.312281]\n",
      "epoch:13 step:12998 [D loss: 0.262263, acc.: 49.22%] [G loss: 0.305990]\n",
      "epoch:13 step:12999 [D loss: 0.235633, acc.: 60.16%] [G loss: 0.317405]\n",
      "epoch:13 step:13000 [D loss: 0.247291, acc.: 53.91%] [G loss: 0.277950]\n",
      "epoch:13 step:13001 [D loss: 0.252516, acc.: 58.59%] [G loss: 0.287257]\n",
      "epoch:13 step:13002 [D loss: 0.234598, acc.: 62.50%] [G loss: 0.290650]\n",
      "epoch:13 step:13003 [D loss: 0.243165, acc.: 53.91%] [G loss: 0.307046]\n",
      "epoch:13 step:13004 [D loss: 0.243146, acc.: 58.59%] [G loss: 0.303508]\n",
      "epoch:13 step:13005 [D loss: 0.245217, acc.: 60.16%] [G loss: 0.298887]\n",
      "epoch:13 step:13006 [D loss: 0.252250, acc.: 50.78%] [G loss: 0.308514]\n",
      "epoch:13 step:13007 [D loss: 0.237986, acc.: 58.59%] [G loss: 0.284451]\n",
      "epoch:13 step:13008 [D loss: 0.245634, acc.: 57.81%] [G loss: 0.285719]\n",
      "epoch:13 step:13009 [D loss: 0.250041, acc.: 55.47%] [G loss: 0.273896]\n",
      "epoch:13 step:13010 [D loss: 0.232530, acc.: 58.59%] [G loss: 0.305509]\n",
      "epoch:13 step:13011 [D loss: 0.245723, acc.: 55.47%] [G loss: 0.278265]\n",
      "epoch:13 step:13012 [D loss: 0.256464, acc.: 47.66%] [G loss: 0.319258]\n",
      "epoch:13 step:13013 [D loss: 0.237630, acc.: 63.28%] [G loss: 0.281748]\n",
      "epoch:13 step:13014 [D loss: 0.227153, acc.: 65.62%] [G loss: 0.296338]\n",
      "epoch:13 step:13015 [D loss: 0.252377, acc.: 51.56%] [G loss: 0.279371]\n",
      "epoch:13 step:13016 [D loss: 0.250641, acc.: 53.91%] [G loss: 0.310599]\n",
      "epoch:13 step:13017 [D loss: 0.253344, acc.: 53.91%] [G loss: 0.293497]\n",
      "epoch:13 step:13018 [D loss: 0.238270, acc.: 60.16%] [G loss: 0.304979]\n",
      "epoch:13 step:13019 [D loss: 0.245337, acc.: 57.03%] [G loss: 0.314002]\n",
      "epoch:13 step:13020 [D loss: 0.240231, acc.: 60.16%] [G loss: 0.294780]\n",
      "epoch:13 step:13021 [D loss: 0.253777, acc.: 53.91%] [G loss: 0.307420]\n",
      "epoch:13 step:13022 [D loss: 0.251233, acc.: 58.59%] [G loss: 0.309031]\n",
      "epoch:13 step:13023 [D loss: 0.264050, acc.: 46.09%] [G loss: 0.281144]\n",
      "epoch:13 step:13024 [D loss: 0.246036, acc.: 48.44%] [G loss: 0.296468]\n",
      "epoch:13 step:13025 [D loss: 0.258518, acc.: 51.56%] [G loss: 0.314000]\n",
      "epoch:13 step:13026 [D loss: 0.258808, acc.: 49.22%] [G loss: 0.298056]\n",
      "epoch:13 step:13027 [D loss: 0.258748, acc.: 56.25%] [G loss: 0.295203]\n",
      "epoch:13 step:13028 [D loss: 0.234922, acc.: 57.03%] [G loss: 0.300172]\n",
      "epoch:13 step:13029 [D loss: 0.235585, acc.: 59.38%] [G loss: 0.277183]\n",
      "epoch:13 step:13030 [D loss: 0.241487, acc.: 57.03%] [G loss: 0.307045]\n",
      "epoch:13 step:13031 [D loss: 0.224905, acc.: 67.97%] [G loss: 0.315080]\n",
      "epoch:13 step:13032 [D loss: 0.242834, acc.: 59.38%] [G loss: 0.272910]\n",
      "epoch:13 step:13033 [D loss: 0.240163, acc.: 59.38%] [G loss: 0.295030]\n",
      "epoch:13 step:13034 [D loss: 0.217104, acc.: 65.62%] [G loss: 0.287095]\n",
      "epoch:13 step:13035 [D loss: 0.230634, acc.: 62.50%] [G loss: 0.303121]\n",
      "epoch:13 step:13036 [D loss: 0.245646, acc.: 55.47%] [G loss: 0.288068]\n",
      "epoch:13 step:13037 [D loss: 0.240325, acc.: 59.38%] [G loss: 0.294471]\n",
      "epoch:13 step:13038 [D loss: 0.259688, acc.: 50.00%] [G loss: 0.286953]\n",
      "epoch:13 step:13039 [D loss: 0.244717, acc.: 60.94%] [G loss: 0.304253]\n",
      "epoch:13 step:13040 [D loss: 0.240806, acc.: 57.81%] [G loss: 0.295710]\n",
      "epoch:13 step:13041 [D loss: 0.240265, acc.: 60.94%] [G loss: 0.283898]\n",
      "epoch:13 step:13042 [D loss: 0.228857, acc.: 62.50%] [G loss: 0.321940]\n",
      "epoch:13 step:13043 [D loss: 0.255501, acc.: 53.12%] [G loss: 0.295606]\n",
      "epoch:13 step:13044 [D loss: 0.244411, acc.: 54.69%] [G loss: 0.325609]\n",
      "epoch:13 step:13045 [D loss: 0.255769, acc.: 50.78%] [G loss: 0.295812]\n",
      "epoch:13 step:13046 [D loss: 0.242233, acc.: 58.59%] [G loss: 0.286448]\n",
      "epoch:13 step:13047 [D loss: 0.231787, acc.: 62.50%] [G loss: 0.324165]\n",
      "epoch:13 step:13048 [D loss: 0.235193, acc.: 60.94%] [G loss: 0.306364]\n",
      "epoch:13 step:13049 [D loss: 0.241357, acc.: 58.59%] [G loss: 0.307222]\n",
      "epoch:13 step:13050 [D loss: 0.231650, acc.: 64.06%] [G loss: 0.318695]\n",
      "epoch:13 step:13051 [D loss: 0.246465, acc.: 58.59%] [G loss: 0.301557]\n",
      "epoch:13 step:13052 [D loss: 0.234297, acc.: 61.72%] [G loss: 0.292815]\n",
      "epoch:13 step:13053 [D loss: 0.247129, acc.: 57.03%] [G loss: 0.299351]\n",
      "epoch:13 step:13054 [D loss: 0.223663, acc.: 64.06%] [G loss: 0.293291]\n",
      "epoch:13 step:13055 [D loss: 0.250817, acc.: 51.56%] [G loss: 0.287997]\n",
      "epoch:13 step:13056 [D loss: 0.235923, acc.: 59.38%] [G loss: 0.305245]\n",
      "epoch:13 step:13057 [D loss: 0.231472, acc.: 63.28%] [G loss: 0.302117]\n",
      "epoch:13 step:13058 [D loss: 0.235574, acc.: 59.38%] [G loss: 0.317883]\n",
      "epoch:13 step:13059 [D loss: 0.254898, acc.: 54.69%] [G loss: 0.291823]\n",
      "epoch:13 step:13060 [D loss: 0.248231, acc.: 51.56%] [G loss: 0.289030]\n",
      "epoch:13 step:13061 [D loss: 0.238638, acc.: 63.28%] [G loss: 0.293957]\n",
      "epoch:13 step:13062 [D loss: 0.245444, acc.: 60.94%] [G loss: 0.283280]\n",
      "epoch:13 step:13063 [D loss: 0.232168, acc.: 63.28%] [G loss: 0.276680]\n",
      "epoch:13 step:13064 [D loss: 0.236482, acc.: 59.38%] [G loss: 0.306270]\n",
      "epoch:13 step:13065 [D loss: 0.235745, acc.: 59.38%] [G loss: 0.310934]\n",
      "epoch:13 step:13066 [D loss: 0.254615, acc.: 50.00%] [G loss: 0.295347]\n",
      "epoch:13 step:13067 [D loss: 0.243144, acc.: 57.81%] [G loss: 0.307347]\n",
      "epoch:13 step:13068 [D loss: 0.216765, acc.: 69.53%] [G loss: 0.331487]\n",
      "epoch:13 step:13069 [D loss: 0.260891, acc.: 51.56%] [G loss: 0.286300]\n",
      "epoch:13 step:13070 [D loss: 0.249794, acc.: 51.56%] [G loss: 0.305076]\n",
      "epoch:13 step:13071 [D loss: 0.243321, acc.: 57.03%] [G loss: 0.285976]\n",
      "epoch:13 step:13072 [D loss: 0.252468, acc.: 54.69%] [G loss: 0.285906]\n",
      "epoch:13 step:13073 [D loss: 0.248628, acc.: 60.16%] [G loss: 0.299693]\n",
      "epoch:13 step:13074 [D loss: 0.255590, acc.: 50.78%] [G loss: 0.313102]\n",
      "epoch:13 step:13075 [D loss: 0.242358, acc.: 55.47%] [G loss: 0.305292]\n",
      "epoch:13 step:13076 [D loss: 0.245600, acc.: 57.81%] [G loss: 0.298547]\n",
      "epoch:13 step:13077 [D loss: 0.233262, acc.: 60.94%] [G loss: 0.294951]\n",
      "epoch:13 step:13078 [D loss: 0.233142, acc.: 57.03%] [G loss: 0.309723]\n",
      "epoch:13 step:13079 [D loss: 0.234290, acc.: 59.38%] [G loss: 0.288949]\n",
      "epoch:13 step:13080 [D loss: 0.243134, acc.: 55.47%] [G loss: 0.322059]\n",
      "epoch:13 step:13081 [D loss: 0.221453, acc.: 65.62%] [G loss: 0.285066]\n",
      "epoch:13 step:13082 [D loss: 0.242218, acc.: 55.47%] [G loss: 0.312360]\n",
      "epoch:13 step:13083 [D loss: 0.242889, acc.: 55.47%] [G loss: 0.266775]\n",
      "epoch:13 step:13084 [D loss: 0.239201, acc.: 60.16%] [G loss: 0.305259]\n",
      "epoch:13 step:13085 [D loss: 0.226453, acc.: 63.28%] [G loss: 0.309030]\n",
      "epoch:13 step:13086 [D loss: 0.248872, acc.: 55.47%] [G loss: 0.287963]\n",
      "epoch:13 step:13087 [D loss: 0.233634, acc.: 63.28%] [G loss: 0.285431]\n",
      "epoch:13 step:13088 [D loss: 0.231531, acc.: 62.50%] [G loss: 0.280529]\n",
      "epoch:13 step:13089 [D loss: 0.251588, acc.: 51.56%] [G loss: 0.315806]\n",
      "epoch:13 step:13090 [D loss: 0.244501, acc.: 56.25%] [G loss: 0.297981]\n",
      "epoch:13 step:13091 [D loss: 0.234493, acc.: 58.59%] [G loss: 0.313895]\n",
      "epoch:13 step:13092 [D loss: 0.239397, acc.: 57.81%] [G loss: 0.297293]\n",
      "epoch:13 step:13093 [D loss: 0.262182, acc.: 48.44%] [G loss: 0.277173]\n",
      "epoch:13 step:13094 [D loss: 0.228017, acc.: 62.50%] [G loss: 0.333774]\n",
      "epoch:13 step:13095 [D loss: 0.254721, acc.: 50.78%] [G loss: 0.288628]\n",
      "epoch:13 step:13096 [D loss: 0.252904, acc.: 50.78%] [G loss: 0.287028]\n",
      "epoch:13 step:13097 [D loss: 0.241176, acc.: 60.16%] [G loss: 0.307570]\n",
      "epoch:13 step:13098 [D loss: 0.244981, acc.: 57.03%] [G loss: 0.321893]\n",
      "epoch:13 step:13099 [D loss: 0.248721, acc.: 56.25%] [G loss: 0.292043]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:13 step:13100 [D loss: 0.254885, acc.: 50.78%] [G loss: 0.294262]\n",
      "epoch:13 step:13101 [D loss: 0.234970, acc.: 63.28%] [G loss: 0.323028]\n",
      "epoch:13 step:13102 [D loss: 0.259816, acc.: 50.78%] [G loss: 0.287927]\n",
      "epoch:13 step:13103 [D loss: 0.233019, acc.: 59.38%] [G loss: 0.321668]\n",
      "epoch:13 step:13104 [D loss: 0.252341, acc.: 54.69%] [G loss: 0.272340]\n",
      "epoch:13 step:13105 [D loss: 0.254063, acc.: 53.91%] [G loss: 0.287131]\n",
      "epoch:13 step:13106 [D loss: 0.247240, acc.: 55.47%] [G loss: 0.291969]\n",
      "epoch:13 step:13107 [D loss: 0.223118, acc.: 64.84%] [G loss: 0.312965]\n",
      "epoch:13 step:13108 [D loss: 0.238265, acc.: 56.25%] [G loss: 0.329346]\n",
      "epoch:13 step:13109 [D loss: 0.228525, acc.: 61.72%] [G loss: 0.308636]\n",
      "epoch:13 step:13110 [D loss: 0.240451, acc.: 57.81%] [G loss: 0.266560]\n",
      "epoch:13 step:13111 [D loss: 0.233334, acc.: 56.25%] [G loss: 0.295372]\n",
      "epoch:13 step:13112 [D loss: 0.236887, acc.: 59.38%] [G loss: 0.316703]\n",
      "epoch:13 step:13113 [D loss: 0.239607, acc.: 59.38%] [G loss: 0.278983]\n",
      "epoch:13 step:13114 [D loss: 0.242613, acc.: 55.47%] [G loss: 0.287838]\n",
      "epoch:13 step:13115 [D loss: 0.248097, acc.: 53.91%] [G loss: 0.301005]\n",
      "epoch:13 step:13116 [D loss: 0.235371, acc.: 61.72%] [G loss: 0.291044]\n",
      "epoch:13 step:13117 [D loss: 0.229836, acc.: 58.59%] [G loss: 0.267297]\n",
      "epoch:13 step:13118 [D loss: 0.257585, acc.: 50.00%] [G loss: 0.279641]\n",
      "epoch:14 step:13119 [D loss: 0.229037, acc.: 57.03%] [G loss: 0.308809]\n",
      "epoch:14 step:13120 [D loss: 0.243062, acc.: 56.25%] [G loss: 0.320290]\n",
      "epoch:14 step:13121 [D loss: 0.252577, acc.: 53.12%] [G loss: 0.299291]\n",
      "epoch:14 step:13122 [D loss: 0.249209, acc.: 56.25%] [G loss: 0.307517]\n",
      "epoch:14 step:13123 [D loss: 0.242797, acc.: 51.56%] [G loss: 0.309167]\n",
      "epoch:14 step:13124 [D loss: 0.242784, acc.: 55.47%] [G loss: 0.338130]\n",
      "epoch:14 step:13125 [D loss: 0.231380, acc.: 62.50%] [G loss: 0.324416]\n",
      "epoch:14 step:13126 [D loss: 0.225618, acc.: 65.62%] [G loss: 0.288531]\n",
      "epoch:14 step:13127 [D loss: 0.232738, acc.: 60.94%] [G loss: 0.303822]\n",
      "epoch:14 step:13128 [D loss: 0.242979, acc.: 59.38%] [G loss: 0.292194]\n",
      "epoch:14 step:13129 [D loss: 0.228576, acc.: 64.06%] [G loss: 0.279583]\n",
      "epoch:14 step:13130 [D loss: 0.226037, acc.: 64.84%] [G loss: 0.286806]\n",
      "epoch:14 step:13131 [D loss: 0.236488, acc.: 59.38%] [G loss: 0.311675]\n",
      "epoch:14 step:13132 [D loss: 0.239128, acc.: 55.47%] [G loss: 0.286864]\n",
      "epoch:14 step:13133 [D loss: 0.230177, acc.: 60.16%] [G loss: 0.298727]\n",
      "epoch:14 step:13134 [D loss: 0.240774, acc.: 57.03%] [G loss: 0.260558]\n",
      "epoch:14 step:13135 [D loss: 0.234223, acc.: 62.50%] [G loss: 0.298236]\n",
      "epoch:14 step:13136 [D loss: 0.250222, acc.: 51.56%] [G loss: 0.283370]\n",
      "epoch:14 step:13137 [D loss: 0.245748, acc.: 57.81%] [G loss: 0.312448]\n",
      "epoch:14 step:13138 [D loss: 0.252510, acc.: 50.00%] [G loss: 0.281209]\n",
      "epoch:14 step:13139 [D loss: 0.256321, acc.: 53.91%] [G loss: 0.302030]\n",
      "epoch:14 step:13140 [D loss: 0.238103, acc.: 57.81%] [G loss: 0.283552]\n",
      "epoch:14 step:13141 [D loss: 0.250943, acc.: 50.78%] [G loss: 0.291985]\n",
      "epoch:14 step:13142 [D loss: 0.237759, acc.: 57.03%] [G loss: 0.295994]\n",
      "epoch:14 step:13143 [D loss: 0.235111, acc.: 59.38%] [G loss: 0.303615]\n",
      "epoch:14 step:13144 [D loss: 0.251862, acc.: 55.47%] [G loss: 0.285310]\n",
      "epoch:14 step:13145 [D loss: 0.234950, acc.: 61.72%] [G loss: 0.286330]\n",
      "epoch:14 step:13146 [D loss: 0.231370, acc.: 60.16%] [G loss: 0.288107]\n",
      "epoch:14 step:13147 [D loss: 0.250009, acc.: 53.12%] [G loss: 0.293995]\n",
      "epoch:14 step:13148 [D loss: 0.243032, acc.: 58.59%] [G loss: 0.296746]\n",
      "epoch:14 step:13149 [D loss: 0.237929, acc.: 58.59%] [G loss: 0.341142]\n",
      "epoch:14 step:13150 [D loss: 0.234562, acc.: 61.72%] [G loss: 0.275123]\n",
      "epoch:14 step:13151 [D loss: 0.240681, acc.: 60.16%] [G loss: 0.286079]\n",
      "epoch:14 step:13152 [D loss: 0.235951, acc.: 55.47%] [G loss: 0.283789]\n",
      "epoch:14 step:13153 [D loss: 0.226370, acc.: 61.72%] [G loss: 0.311556]\n",
      "epoch:14 step:13154 [D loss: 0.226652, acc.: 60.94%] [G loss: 0.289647]\n",
      "epoch:14 step:13155 [D loss: 0.225742, acc.: 64.06%] [G loss: 0.290111]\n",
      "epoch:14 step:13156 [D loss: 0.235438, acc.: 57.03%] [G loss: 0.286545]\n",
      "epoch:14 step:13157 [D loss: 0.230656, acc.: 60.94%] [G loss: 0.324239]\n",
      "epoch:14 step:13158 [D loss: 0.232980, acc.: 60.16%] [G loss: 0.304526]\n",
      "epoch:14 step:13159 [D loss: 0.219237, acc.: 66.41%] [G loss: 0.293499]\n",
      "epoch:14 step:13160 [D loss: 0.244893, acc.: 57.03%] [G loss: 0.288498]\n",
      "epoch:14 step:13161 [D loss: 0.236418, acc.: 54.69%] [G loss: 0.304588]\n",
      "epoch:14 step:13162 [D loss: 0.244124, acc.: 53.91%] [G loss: 0.296646]\n",
      "epoch:14 step:13163 [D loss: 0.223012, acc.: 67.97%] [G loss: 0.286674]\n",
      "epoch:14 step:13164 [D loss: 0.233171, acc.: 57.81%] [G loss: 0.318699]\n",
      "epoch:14 step:13165 [D loss: 0.255470, acc.: 51.56%] [G loss: 0.277664]\n",
      "epoch:14 step:13166 [D loss: 0.235397, acc.: 57.81%] [G loss: 0.285506]\n",
      "epoch:14 step:13167 [D loss: 0.235261, acc.: 59.38%] [G loss: 0.288330]\n",
      "epoch:14 step:13168 [D loss: 0.223330, acc.: 67.19%] [G loss: 0.287137]\n",
      "epoch:14 step:13169 [D loss: 0.244529, acc.: 57.03%] [G loss: 0.300258]\n",
      "epoch:14 step:13170 [D loss: 0.230937, acc.: 58.59%] [G loss: 0.321528]\n",
      "epoch:14 step:13171 [D loss: 0.222611, acc.: 64.84%] [G loss: 0.284464]\n",
      "epoch:14 step:13172 [D loss: 0.243186, acc.: 60.16%] [G loss: 0.293741]\n",
      "epoch:14 step:13173 [D loss: 0.239845, acc.: 57.81%] [G loss: 0.303039]\n",
      "epoch:14 step:13174 [D loss: 0.230917, acc.: 63.28%] [G loss: 0.296303]\n",
      "epoch:14 step:13175 [D loss: 0.245087, acc.: 53.12%] [G loss: 0.271584]\n",
      "epoch:14 step:13176 [D loss: 0.226256, acc.: 64.06%] [G loss: 0.310925]\n",
      "epoch:14 step:13177 [D loss: 0.234343, acc.: 62.50%] [G loss: 0.287149]\n",
      "epoch:14 step:13178 [D loss: 0.237147, acc.: 57.81%] [G loss: 0.289026]\n",
      "epoch:14 step:13179 [D loss: 0.243718, acc.: 54.69%] [G loss: 0.290447]\n",
      "epoch:14 step:13180 [D loss: 0.258646, acc.: 51.56%] [G loss: 0.268051]\n",
      "epoch:14 step:13181 [D loss: 0.248178, acc.: 52.34%] [G loss: 0.311460]\n",
      "epoch:14 step:13182 [D loss: 0.235083, acc.: 60.16%] [G loss: 0.295928]\n",
      "epoch:14 step:13183 [D loss: 0.236250, acc.: 60.16%] [G loss: 0.309453]\n",
      "epoch:14 step:13184 [D loss: 0.231002, acc.: 55.47%] [G loss: 0.308971]\n",
      "epoch:14 step:13185 [D loss: 0.256533, acc.: 49.22%] [G loss: 0.260931]\n",
      "epoch:14 step:13186 [D loss: 0.233107, acc.: 63.28%] [G loss: 0.305836]\n",
      "epoch:14 step:13187 [D loss: 0.238386, acc.: 51.56%] [G loss: 0.294493]\n",
      "epoch:14 step:13188 [D loss: 0.234532, acc.: 60.16%] [G loss: 0.306810]\n",
      "epoch:14 step:13189 [D loss: 0.243188, acc.: 56.25%] [G loss: 0.302984]\n",
      "epoch:14 step:13190 [D loss: 0.245787, acc.: 57.03%] [G loss: 0.320555]\n",
      "epoch:14 step:13191 [D loss: 0.252236, acc.: 56.25%] [G loss: 0.293087]\n",
      "epoch:14 step:13192 [D loss: 0.215536, acc.: 62.50%] [G loss: 0.297973]\n",
      "epoch:14 step:13193 [D loss: 0.232230, acc.: 64.84%] [G loss: 0.300108]\n",
      "epoch:14 step:13194 [D loss: 0.243302, acc.: 54.69%] [G loss: 0.322287]\n",
      "epoch:14 step:13195 [D loss: 0.250715, acc.: 51.56%] [G loss: 0.301954]\n",
      "epoch:14 step:13196 [D loss: 0.232555, acc.: 64.06%] [G loss: 0.305135]\n",
      "epoch:14 step:13197 [D loss: 0.241989, acc.: 58.59%] [G loss: 0.310611]\n",
      "epoch:14 step:13198 [D loss: 0.243930, acc.: 56.25%] [G loss: 0.311717]\n",
      "epoch:14 step:13199 [D loss: 0.245720, acc.: 56.25%] [G loss: 0.282019]\n",
      "epoch:14 step:13200 [D loss: 0.226325, acc.: 63.28%] [G loss: 0.312393]\n",
      "epoch:14 step:13201 [D loss: 0.229710, acc.: 60.16%] [G loss: 0.309514]\n",
      "epoch:14 step:13202 [D loss: 0.238520, acc.: 53.91%] [G loss: 0.313012]\n",
      "epoch:14 step:13203 [D loss: 0.242993, acc.: 58.59%] [G loss: 0.304477]\n",
      "epoch:14 step:13204 [D loss: 0.232289, acc.: 63.28%] [G loss: 0.286429]\n",
      "epoch:14 step:13205 [D loss: 0.232716, acc.: 60.16%] [G loss: 0.295239]\n",
      "epoch:14 step:13206 [D loss: 0.226366, acc.: 60.94%] [G loss: 0.305891]\n",
      "epoch:14 step:13207 [D loss: 0.243377, acc.: 57.81%] [G loss: 0.289988]\n",
      "epoch:14 step:13208 [D loss: 0.242366, acc.: 60.94%] [G loss: 0.315279]\n",
      "epoch:14 step:13209 [D loss: 0.238183, acc.: 57.03%] [G loss: 0.318967]\n",
      "epoch:14 step:13210 [D loss: 0.234726, acc.: 56.25%] [G loss: 0.314467]\n",
      "epoch:14 step:13211 [D loss: 0.234557, acc.: 59.38%] [G loss: 0.312406]\n",
      "epoch:14 step:13212 [D loss: 0.238886, acc.: 60.16%] [G loss: 0.325445]\n",
      "epoch:14 step:13213 [D loss: 0.248335, acc.: 48.44%] [G loss: 0.305399]\n",
      "epoch:14 step:13214 [D loss: 0.231982, acc.: 58.59%] [G loss: 0.294942]\n",
      "epoch:14 step:13215 [D loss: 0.244422, acc.: 55.47%] [G loss: 0.277340]\n",
      "epoch:14 step:13216 [D loss: 0.242201, acc.: 55.47%] [G loss: 0.299022]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:14 step:13217 [D loss: 0.245607, acc.: 60.94%] [G loss: 0.298546]\n",
      "epoch:14 step:13218 [D loss: 0.220799, acc.: 65.62%] [G loss: 0.289015]\n",
      "epoch:14 step:13219 [D loss: 0.240297, acc.: 60.16%] [G loss: 0.293432]\n",
      "epoch:14 step:13220 [D loss: 0.242602, acc.: 56.25%] [G loss: 0.293549]\n",
      "epoch:14 step:13221 [D loss: 0.217043, acc.: 67.97%] [G loss: 0.305268]\n",
      "epoch:14 step:13222 [D loss: 0.250604, acc.: 53.12%] [G loss: 0.286664]\n",
      "epoch:14 step:13223 [D loss: 0.231327, acc.: 65.62%] [G loss: 0.310283]\n",
      "epoch:14 step:13224 [D loss: 0.234412, acc.: 60.94%] [G loss: 0.301100]\n",
      "epoch:14 step:13225 [D loss: 0.237184, acc.: 60.94%] [G loss: 0.312612]\n",
      "epoch:14 step:13226 [D loss: 0.239217, acc.: 52.34%] [G loss: 0.314910]\n",
      "epoch:14 step:13227 [D loss: 0.239110, acc.: 57.81%] [G loss: 0.303281]\n",
      "epoch:14 step:13228 [D loss: 0.256809, acc.: 51.56%] [G loss: 0.300806]\n",
      "epoch:14 step:13229 [D loss: 0.236234, acc.: 61.72%] [G loss: 0.287952]\n",
      "epoch:14 step:13230 [D loss: 0.243931, acc.: 53.91%] [G loss: 0.293814]\n",
      "epoch:14 step:13231 [D loss: 0.241488, acc.: 63.28%] [G loss: 0.333141]\n",
      "epoch:14 step:13232 [D loss: 0.242750, acc.: 60.94%] [G loss: 0.287710]\n",
      "epoch:14 step:13233 [D loss: 0.249889, acc.: 59.38%] [G loss: 0.289695]\n",
      "epoch:14 step:13234 [D loss: 0.257056, acc.: 58.59%] [G loss: 0.322639]\n",
      "epoch:14 step:13235 [D loss: 0.249468, acc.: 58.59%] [G loss: 0.282931]\n",
      "epoch:14 step:13236 [D loss: 0.261225, acc.: 48.44%] [G loss: 0.308356]\n",
      "epoch:14 step:13237 [D loss: 0.242307, acc.: 57.03%] [G loss: 0.303106]\n",
      "epoch:14 step:13238 [D loss: 0.248443, acc.: 52.34%] [G loss: 0.282975]\n",
      "epoch:14 step:13239 [D loss: 0.244604, acc.: 53.91%] [G loss: 0.291748]\n",
      "epoch:14 step:13240 [D loss: 0.245674, acc.: 55.47%] [G loss: 0.282017]\n",
      "epoch:14 step:13241 [D loss: 0.237360, acc.: 53.91%] [G loss: 0.282835]\n",
      "epoch:14 step:13242 [D loss: 0.236018, acc.: 63.28%] [G loss: 0.286965]\n",
      "epoch:14 step:13243 [D loss: 0.224596, acc.: 66.41%] [G loss: 0.288417]\n",
      "epoch:14 step:13244 [D loss: 0.238935, acc.: 64.06%] [G loss: 0.285709]\n",
      "epoch:14 step:13245 [D loss: 0.266748, acc.: 51.56%] [G loss: 0.272352]\n",
      "epoch:14 step:13246 [D loss: 0.231236, acc.: 61.72%] [G loss: 0.312936]\n",
      "epoch:14 step:13247 [D loss: 0.242150, acc.: 59.38%] [G loss: 0.288713]\n",
      "epoch:14 step:13248 [D loss: 0.235135, acc.: 63.28%] [G loss: 0.300632]\n",
      "epoch:14 step:13249 [D loss: 0.239570, acc.: 55.47%] [G loss: 0.280349]\n",
      "epoch:14 step:13250 [D loss: 0.238349, acc.: 62.50%] [G loss: 0.309739]\n",
      "epoch:14 step:13251 [D loss: 0.248700, acc.: 54.69%] [G loss: 0.292516]\n",
      "epoch:14 step:13252 [D loss: 0.242838, acc.: 56.25%] [G loss: 0.284783]\n",
      "epoch:14 step:13253 [D loss: 0.234507, acc.: 56.25%] [G loss: 0.302861]\n",
      "epoch:14 step:13254 [D loss: 0.264482, acc.: 46.09%] [G loss: 0.270460]\n",
      "epoch:14 step:13255 [D loss: 0.223298, acc.: 62.50%] [G loss: 0.295467]\n",
      "epoch:14 step:13256 [D loss: 0.268472, acc.: 46.09%] [G loss: 0.289550]\n",
      "epoch:14 step:13257 [D loss: 0.230056, acc.: 67.19%] [G loss: 0.311958]\n",
      "epoch:14 step:13258 [D loss: 0.252262, acc.: 57.03%] [G loss: 0.337234]\n",
      "epoch:14 step:13259 [D loss: 0.244215, acc.: 53.91%] [G loss: 0.288209]\n",
      "epoch:14 step:13260 [D loss: 0.233376, acc.: 59.38%] [G loss: 0.280065]\n",
      "epoch:14 step:13261 [D loss: 0.243500, acc.: 55.47%] [G loss: 0.303386]\n",
      "epoch:14 step:13262 [D loss: 0.247037, acc.: 56.25%] [G loss: 0.290097]\n",
      "epoch:14 step:13263 [D loss: 0.234078, acc.: 60.94%] [G loss: 0.314553]\n",
      "epoch:14 step:13264 [D loss: 0.250235, acc.: 56.25%] [G loss: 0.315168]\n",
      "epoch:14 step:13265 [D loss: 0.225739, acc.: 62.50%] [G loss: 0.306627]\n",
      "epoch:14 step:13266 [D loss: 0.234984, acc.: 63.28%] [G loss: 0.289973]\n",
      "epoch:14 step:13267 [D loss: 0.239399, acc.: 60.16%] [G loss: 0.298865]\n",
      "epoch:14 step:13268 [D loss: 0.223564, acc.: 62.50%] [G loss: 0.312520]\n",
      "epoch:14 step:13269 [D loss: 0.231799, acc.: 60.16%] [G loss: 0.323671]\n",
      "epoch:14 step:13270 [D loss: 0.238668, acc.: 60.16%] [G loss: 0.322397]\n",
      "epoch:14 step:13271 [D loss: 0.232253, acc.: 57.03%] [G loss: 0.323763]\n",
      "epoch:14 step:13272 [D loss: 0.247099, acc.: 56.25%] [G loss: 0.294941]\n",
      "epoch:14 step:13273 [D loss: 0.238814, acc.: 53.91%] [G loss: 0.306847]\n",
      "epoch:14 step:13274 [D loss: 0.224099, acc.: 68.75%] [G loss: 0.300720]\n",
      "epoch:14 step:13275 [D loss: 0.238803, acc.: 60.16%] [G loss: 0.296332]\n",
      "epoch:14 step:13276 [D loss: 0.241959, acc.: 54.69%] [G loss: 0.326442]\n",
      "epoch:14 step:13277 [D loss: 0.235461, acc.: 64.06%] [G loss: 0.304168]\n",
      "epoch:14 step:13278 [D loss: 0.238511, acc.: 57.03%] [G loss: 0.273996]\n",
      "epoch:14 step:13279 [D loss: 0.216215, acc.: 63.28%] [G loss: 0.314597]\n",
      "epoch:14 step:13280 [D loss: 0.235097, acc.: 60.94%] [G loss: 0.295019]\n",
      "epoch:14 step:13281 [D loss: 0.228834, acc.: 60.94%] [G loss: 0.311509]\n",
      "epoch:14 step:13282 [D loss: 0.220112, acc.: 68.75%] [G loss: 0.309666]\n",
      "epoch:14 step:13283 [D loss: 0.255227, acc.: 48.44%] [G loss: 0.294687]\n",
      "epoch:14 step:13284 [D loss: 0.263084, acc.: 47.66%] [G loss: 0.303234]\n",
      "epoch:14 step:13285 [D loss: 0.240855, acc.: 59.38%] [G loss: 0.306291]\n",
      "epoch:14 step:13286 [D loss: 0.236490, acc.: 60.94%] [G loss: 0.316640]\n",
      "epoch:14 step:13287 [D loss: 0.233293, acc.: 62.50%] [G loss: 0.299271]\n",
      "epoch:14 step:13288 [D loss: 0.229327, acc.: 57.81%] [G loss: 0.306066]\n",
      "epoch:14 step:13289 [D loss: 0.243201, acc.: 59.38%] [G loss: 0.291264]\n",
      "epoch:14 step:13290 [D loss: 0.219390, acc.: 64.84%] [G loss: 0.337438]\n",
      "epoch:14 step:13291 [D loss: 0.239678, acc.: 62.50%] [G loss: 0.293014]\n",
      "epoch:14 step:13292 [D loss: 0.232169, acc.: 60.16%] [G loss: 0.314032]\n",
      "epoch:14 step:13293 [D loss: 0.230866, acc.: 61.72%] [G loss: 0.312888]\n",
      "epoch:14 step:13294 [D loss: 0.232447, acc.: 60.16%] [G loss: 0.294356]\n",
      "epoch:14 step:13295 [D loss: 0.240990, acc.: 56.25%] [G loss: 0.273379]\n",
      "epoch:14 step:13296 [D loss: 0.241597, acc.: 52.34%] [G loss: 0.329050]\n",
      "epoch:14 step:13297 [D loss: 0.237482, acc.: 59.38%] [G loss: 0.309753]\n",
      "epoch:14 step:13298 [D loss: 0.229998, acc.: 63.28%] [G loss: 0.304151]\n",
      "epoch:14 step:13299 [D loss: 0.231444, acc.: 66.41%] [G loss: 0.303219]\n",
      "epoch:14 step:13300 [D loss: 0.236142, acc.: 60.94%] [G loss: 0.299562]\n",
      "epoch:14 step:13301 [D loss: 0.251391, acc.: 53.91%] [G loss: 0.332504]\n",
      "epoch:14 step:13302 [D loss: 0.234758, acc.: 62.50%] [G loss: 0.292349]\n",
      "epoch:14 step:13303 [D loss: 0.232918, acc.: 60.16%] [G loss: 0.308519]\n",
      "epoch:14 step:13304 [D loss: 0.233667, acc.: 62.50%] [G loss: 0.312631]\n",
      "epoch:14 step:13305 [D loss: 0.229534, acc.: 61.72%] [G loss: 0.294847]\n",
      "epoch:14 step:13306 [D loss: 0.241992, acc.: 60.16%] [G loss: 0.321333]\n",
      "epoch:14 step:13307 [D loss: 0.231186, acc.: 60.94%] [G loss: 0.327251]\n",
      "epoch:14 step:13308 [D loss: 0.257855, acc.: 53.12%] [G loss: 0.298699]\n",
      "epoch:14 step:13309 [D loss: 0.225440, acc.: 64.06%] [G loss: 0.318331]\n",
      "epoch:14 step:13310 [D loss: 0.232498, acc.: 62.50%] [G loss: 0.320940]\n",
      "epoch:14 step:13311 [D loss: 0.232575, acc.: 59.38%] [G loss: 0.311395]\n",
      "epoch:14 step:13312 [D loss: 0.244969, acc.: 57.03%] [G loss: 0.296261]\n",
      "epoch:14 step:13313 [D loss: 0.227261, acc.: 67.19%] [G loss: 0.322901]\n",
      "epoch:14 step:13314 [D loss: 0.239380, acc.: 58.59%] [G loss: 0.315414]\n",
      "epoch:14 step:13315 [D loss: 0.237370, acc.: 58.59%] [G loss: 0.294272]\n",
      "epoch:14 step:13316 [D loss: 0.244092, acc.: 55.47%] [G loss: 0.300574]\n",
      "epoch:14 step:13317 [D loss: 0.222879, acc.: 66.41%] [G loss: 0.285971]\n",
      "epoch:14 step:13318 [D loss: 0.253236, acc.: 52.34%] [G loss: 0.300628]\n",
      "epoch:14 step:13319 [D loss: 0.253306, acc.: 53.12%] [G loss: 0.289612]\n",
      "epoch:14 step:13320 [D loss: 0.227075, acc.: 67.19%] [G loss: 0.286557]\n",
      "epoch:14 step:13321 [D loss: 0.234393, acc.: 58.59%] [G loss: 0.304612]\n",
      "epoch:14 step:13322 [D loss: 0.249004, acc.: 51.56%] [G loss: 0.271941]\n",
      "epoch:14 step:13323 [D loss: 0.238172, acc.: 60.16%] [G loss: 0.292307]\n",
      "epoch:14 step:13324 [D loss: 0.252116, acc.: 48.44%] [G loss: 0.293189]\n",
      "epoch:14 step:13325 [D loss: 0.231436, acc.: 60.16%] [G loss: 0.318462]\n",
      "epoch:14 step:13326 [D loss: 0.249100, acc.: 51.56%] [G loss: 0.295710]\n",
      "epoch:14 step:13327 [D loss: 0.236470, acc.: 59.38%] [G loss: 0.286300]\n",
      "epoch:14 step:13328 [D loss: 0.221609, acc.: 64.84%] [G loss: 0.311451]\n",
      "epoch:14 step:13329 [D loss: 0.232034, acc.: 62.50%] [G loss: 0.324585]\n",
      "epoch:14 step:13330 [D loss: 0.252785, acc.: 54.69%] [G loss: 0.321246]\n",
      "epoch:14 step:13331 [D loss: 0.238665, acc.: 61.72%] [G loss: 0.286889]\n",
      "epoch:14 step:13332 [D loss: 0.240829, acc.: 57.81%] [G loss: 0.314596]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:14 step:13333 [D loss: 0.241110, acc.: 62.50%] [G loss: 0.290100]\n",
      "epoch:14 step:13334 [D loss: 0.233431, acc.: 58.59%] [G loss: 0.294764]\n",
      "epoch:14 step:13335 [D loss: 0.208125, acc.: 69.53%] [G loss: 0.316739]\n",
      "epoch:14 step:13336 [D loss: 0.232321, acc.: 66.41%] [G loss: 0.303563]\n",
      "epoch:14 step:13337 [D loss: 0.243275, acc.: 57.03%] [G loss: 0.280192]\n",
      "epoch:14 step:13338 [D loss: 0.247692, acc.: 51.56%] [G loss: 0.268437]\n",
      "epoch:14 step:13339 [D loss: 0.223749, acc.: 65.62%] [G loss: 0.281295]\n",
      "epoch:14 step:13340 [D loss: 0.244819, acc.: 56.25%] [G loss: 0.340352]\n",
      "epoch:14 step:13341 [D loss: 0.232342, acc.: 59.38%] [G loss: 0.277067]\n",
      "epoch:14 step:13342 [D loss: 0.248534, acc.: 56.25%] [G loss: 0.314755]\n",
      "epoch:14 step:13343 [D loss: 0.240699, acc.: 58.59%] [G loss: 0.296419]\n",
      "epoch:14 step:13344 [D loss: 0.243114, acc.: 61.72%] [G loss: 0.327974]\n",
      "epoch:14 step:13345 [D loss: 0.238686, acc.: 57.03%] [G loss: 0.310672]\n",
      "epoch:14 step:13346 [D loss: 0.248426, acc.: 57.81%] [G loss: 0.299484]\n",
      "epoch:14 step:13347 [D loss: 0.244166, acc.: 58.59%] [G loss: 0.321733]\n",
      "epoch:14 step:13348 [D loss: 0.239062, acc.: 58.59%] [G loss: 0.329843]\n",
      "epoch:14 step:13349 [D loss: 0.243083, acc.: 57.81%] [G loss: 0.311971]\n",
      "epoch:14 step:13350 [D loss: 0.240080, acc.: 58.59%] [G loss: 0.281096]\n",
      "epoch:14 step:13351 [D loss: 0.259369, acc.: 49.22%] [G loss: 0.282882]\n",
      "epoch:14 step:13352 [D loss: 0.242527, acc.: 58.59%] [G loss: 0.312540]\n",
      "epoch:14 step:13353 [D loss: 0.241670, acc.: 57.81%] [G loss: 0.294390]\n",
      "epoch:14 step:13354 [D loss: 0.235223, acc.: 64.06%] [G loss: 0.272950]\n",
      "epoch:14 step:13355 [D loss: 0.239681, acc.: 56.25%] [G loss: 0.288526]\n",
      "epoch:14 step:13356 [D loss: 0.243167, acc.: 53.12%] [G loss: 0.305324]\n",
      "epoch:14 step:13357 [D loss: 0.252002, acc.: 48.44%] [G loss: 0.286099]\n",
      "epoch:14 step:13358 [D loss: 0.244536, acc.: 53.91%] [G loss: 0.261409]\n",
      "epoch:14 step:13359 [D loss: 0.235085, acc.: 63.28%] [G loss: 0.301521]\n",
      "epoch:14 step:13360 [D loss: 0.240737, acc.: 57.81%] [G loss: 0.290621]\n",
      "epoch:14 step:13361 [D loss: 0.241807, acc.: 56.25%] [G loss: 0.312326]\n",
      "epoch:14 step:13362 [D loss: 0.242110, acc.: 59.38%] [G loss: 0.298190]\n",
      "epoch:14 step:13363 [D loss: 0.237783, acc.: 59.38%] [G loss: 0.298025]\n",
      "epoch:14 step:13364 [D loss: 0.227851, acc.: 65.62%] [G loss: 0.298439]\n",
      "epoch:14 step:13365 [D loss: 0.231847, acc.: 58.59%] [G loss: 0.290295]\n",
      "epoch:14 step:13366 [D loss: 0.217678, acc.: 66.41%] [G loss: 0.284898]\n",
      "epoch:14 step:13367 [D loss: 0.222694, acc.: 62.50%] [G loss: 0.332677]\n",
      "epoch:14 step:13368 [D loss: 0.244964, acc.: 51.56%] [G loss: 0.294963]\n",
      "epoch:14 step:13369 [D loss: 0.231398, acc.: 60.94%] [G loss: 0.311113]\n",
      "epoch:14 step:13370 [D loss: 0.231570, acc.: 60.16%] [G loss: 0.310546]\n",
      "epoch:14 step:13371 [D loss: 0.243085, acc.: 61.72%] [G loss: 0.299281]\n",
      "epoch:14 step:13372 [D loss: 0.248936, acc.: 54.69%] [G loss: 0.272599]\n",
      "epoch:14 step:13373 [D loss: 0.251056, acc.: 47.66%] [G loss: 0.312733]\n",
      "epoch:14 step:13374 [D loss: 0.252422, acc.: 54.69%] [G loss: 0.313024]\n",
      "epoch:14 step:13375 [D loss: 0.225120, acc.: 62.50%] [G loss: 0.303683]\n",
      "epoch:14 step:13376 [D loss: 0.245385, acc.: 57.03%] [G loss: 0.310906]\n",
      "epoch:14 step:13377 [D loss: 0.238460, acc.: 60.16%] [G loss: 0.272035]\n",
      "epoch:14 step:13378 [D loss: 0.245659, acc.: 57.81%] [G loss: 0.302389]\n",
      "epoch:14 step:13379 [D loss: 0.235626, acc.: 60.94%] [G loss: 0.288136]\n",
      "epoch:14 step:13380 [D loss: 0.227634, acc.: 59.38%] [G loss: 0.286316]\n",
      "epoch:14 step:13381 [D loss: 0.242740, acc.: 57.81%] [G loss: 0.280672]\n",
      "epoch:14 step:13382 [D loss: 0.230221, acc.: 63.28%] [G loss: 0.309677]\n",
      "epoch:14 step:13383 [D loss: 0.233196, acc.: 59.38%] [G loss: 0.318344]\n",
      "epoch:14 step:13384 [D loss: 0.217911, acc.: 63.28%] [G loss: 0.272094]\n",
      "epoch:14 step:13385 [D loss: 0.240299, acc.: 57.81%] [G loss: 0.301987]\n",
      "epoch:14 step:13386 [D loss: 0.233772, acc.: 57.81%] [G loss: 0.319623]\n",
      "epoch:14 step:13387 [D loss: 0.242333, acc.: 57.81%] [G loss: 0.328269]\n",
      "epoch:14 step:13388 [D loss: 0.245608, acc.: 60.16%] [G loss: 0.262939]\n",
      "epoch:14 step:13389 [D loss: 0.227193, acc.: 63.28%] [G loss: 0.303244]\n",
      "epoch:14 step:13390 [D loss: 0.230206, acc.: 60.94%] [G loss: 0.314507]\n",
      "epoch:14 step:13391 [D loss: 0.226704, acc.: 64.84%] [G loss: 0.327128]\n",
      "epoch:14 step:13392 [D loss: 0.240774, acc.: 57.03%] [G loss: 0.310441]\n",
      "epoch:14 step:13393 [D loss: 0.232574, acc.: 59.38%] [G loss: 0.346413]\n",
      "epoch:14 step:13394 [D loss: 0.251824, acc.: 49.22%] [G loss: 0.324871]\n",
      "epoch:14 step:13395 [D loss: 0.251707, acc.: 51.56%] [G loss: 0.268750]\n",
      "epoch:14 step:13396 [D loss: 0.225136, acc.: 62.50%] [G loss: 0.344639]\n",
      "epoch:14 step:13397 [D loss: 0.233757, acc.: 60.16%] [G loss: 0.296378]\n",
      "epoch:14 step:13398 [D loss: 0.249974, acc.: 53.91%] [G loss: 0.282812]\n",
      "epoch:14 step:13399 [D loss: 0.221408, acc.: 66.41%] [G loss: 0.321544]\n",
      "epoch:14 step:13400 [D loss: 0.227896, acc.: 59.38%] [G loss: 0.305384]\n",
      "epoch:14 step:13401 [D loss: 0.260611, acc.: 49.22%] [G loss: 0.295341]\n",
      "epoch:14 step:13402 [D loss: 0.257526, acc.: 53.12%] [G loss: 0.311896]\n",
      "epoch:14 step:13403 [D loss: 0.261192, acc.: 53.91%] [G loss: 0.288895]\n",
      "epoch:14 step:13404 [D loss: 0.244245, acc.: 53.12%] [G loss: 0.300256]\n",
      "epoch:14 step:13405 [D loss: 0.252339, acc.: 58.59%] [G loss: 0.281735]\n",
      "epoch:14 step:13406 [D loss: 0.244129, acc.: 60.94%] [G loss: 0.304409]\n",
      "epoch:14 step:13407 [D loss: 0.226797, acc.: 63.28%] [G loss: 0.326442]\n",
      "epoch:14 step:13408 [D loss: 0.249050, acc.: 52.34%] [G loss: 0.293949]\n",
      "epoch:14 step:13409 [D loss: 0.233477, acc.: 60.94%] [G loss: 0.305879]\n",
      "epoch:14 step:13410 [D loss: 0.243221, acc.: 55.47%] [G loss: 0.300256]\n",
      "epoch:14 step:13411 [D loss: 0.228329, acc.: 63.28%] [G loss: 0.323851]\n",
      "epoch:14 step:13412 [D loss: 0.263586, acc.: 46.88%] [G loss: 0.261020]\n",
      "epoch:14 step:13413 [D loss: 0.233869, acc.: 60.94%] [G loss: 0.270684]\n",
      "epoch:14 step:13414 [D loss: 0.237894, acc.: 60.94%] [G loss: 0.290905]\n",
      "epoch:14 step:13415 [D loss: 0.219197, acc.: 66.41%] [G loss: 0.310031]\n",
      "epoch:14 step:13416 [D loss: 0.234334, acc.: 64.84%] [G loss: 0.271995]\n",
      "epoch:14 step:13417 [D loss: 0.240408, acc.: 57.03%] [G loss: 0.288803]\n",
      "epoch:14 step:13418 [D loss: 0.235716, acc.: 57.03%] [G loss: 0.299037]\n",
      "epoch:14 step:13419 [D loss: 0.243471, acc.: 59.38%] [G loss: 0.274539]\n",
      "epoch:14 step:13420 [D loss: 0.242066, acc.: 55.47%] [G loss: 0.293073]\n",
      "epoch:14 step:13421 [D loss: 0.261934, acc.: 50.78%] [G loss: 0.291017]\n",
      "epoch:14 step:13422 [D loss: 0.220922, acc.: 66.41%] [G loss: 0.295195]\n",
      "epoch:14 step:13423 [D loss: 0.256804, acc.: 50.78%] [G loss: 0.305992]\n",
      "epoch:14 step:13424 [D loss: 0.227198, acc.: 62.50%] [G loss: 0.325657]\n",
      "epoch:14 step:13425 [D loss: 0.235167, acc.: 58.59%] [G loss: 0.297261]\n",
      "epoch:14 step:13426 [D loss: 0.245426, acc.: 54.69%] [G loss: 0.297709]\n",
      "epoch:14 step:13427 [D loss: 0.235507, acc.: 57.03%] [G loss: 0.343450]\n",
      "epoch:14 step:13428 [D loss: 0.250826, acc.: 57.03%] [G loss: 0.279598]\n",
      "epoch:14 step:13429 [D loss: 0.242336, acc.: 52.34%] [G loss: 0.323192]\n",
      "epoch:14 step:13430 [D loss: 0.242042, acc.: 58.59%] [G loss: 0.315258]\n",
      "epoch:14 step:13431 [D loss: 0.235790, acc.: 63.28%] [G loss: 0.296759]\n",
      "epoch:14 step:13432 [D loss: 0.235950, acc.: 55.47%] [G loss: 0.305040]\n",
      "epoch:14 step:13433 [D loss: 0.238076, acc.: 62.50%] [G loss: 0.249997]\n",
      "epoch:14 step:13434 [D loss: 0.266654, acc.: 53.12%] [G loss: 0.292364]\n",
      "epoch:14 step:13435 [D loss: 0.251617, acc.: 57.03%] [G loss: 0.291867]\n",
      "epoch:14 step:13436 [D loss: 0.252127, acc.: 50.78%] [G loss: 0.342243]\n",
      "epoch:14 step:13437 [D loss: 0.247977, acc.: 60.94%] [G loss: 0.289110]\n",
      "epoch:14 step:13438 [D loss: 0.234492, acc.: 60.94%] [G loss: 0.280892]\n",
      "epoch:14 step:13439 [D loss: 0.236868, acc.: 58.59%] [G loss: 0.283683]\n",
      "epoch:14 step:13440 [D loss: 0.241779, acc.: 50.00%] [G loss: 0.300971]\n",
      "epoch:14 step:13441 [D loss: 0.251028, acc.: 54.69%] [G loss: 0.254838]\n",
      "epoch:14 step:13442 [D loss: 0.238839, acc.: 55.47%] [G loss: 0.318071]\n",
      "epoch:14 step:13443 [D loss: 0.246026, acc.: 57.03%] [G loss: 0.292361]\n",
      "epoch:14 step:13444 [D loss: 0.253091, acc.: 56.25%] [G loss: 0.311293]\n",
      "epoch:14 step:13445 [D loss: 0.231780, acc.: 57.81%] [G loss: 0.284570]\n",
      "epoch:14 step:13446 [D loss: 0.233904, acc.: 58.59%] [G loss: 0.273622]\n",
      "epoch:14 step:13447 [D loss: 0.247072, acc.: 51.56%] [G loss: 0.299243]\n",
      "epoch:14 step:13448 [D loss: 0.238826, acc.: 55.47%] [G loss: 0.292702]\n",
      "epoch:14 step:13449 [D loss: 0.250589, acc.: 53.91%] [G loss: 0.307033]\n",
      "epoch:14 step:13450 [D loss: 0.232970, acc.: 59.38%] [G loss: 0.295677]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:14 step:13451 [D loss: 0.244364, acc.: 53.12%] [G loss: 0.291633]\n",
      "epoch:14 step:13452 [D loss: 0.224304, acc.: 63.28%] [G loss: 0.339629]\n",
      "epoch:14 step:13453 [D loss: 0.243863, acc.: 53.91%] [G loss: 0.274532]\n",
      "epoch:14 step:13454 [D loss: 0.238682, acc.: 60.16%] [G loss: 0.291725]\n",
      "epoch:14 step:13455 [D loss: 0.243450, acc.: 57.81%] [G loss: 0.335510]\n",
      "epoch:14 step:13456 [D loss: 0.239737, acc.: 53.91%] [G loss: 0.299502]\n",
      "epoch:14 step:13457 [D loss: 0.243722, acc.: 52.34%] [G loss: 0.273105]\n",
      "epoch:14 step:13458 [D loss: 0.257581, acc.: 50.78%] [G loss: 0.260028]\n",
      "epoch:14 step:13459 [D loss: 0.245716, acc.: 55.47%] [G loss: 0.318282]\n",
      "epoch:14 step:13460 [D loss: 0.247611, acc.: 53.91%] [G loss: 0.302047]\n",
      "epoch:14 step:13461 [D loss: 0.243074, acc.: 61.72%] [G loss: 0.286923]\n",
      "epoch:14 step:13462 [D loss: 0.245783, acc.: 54.69%] [G loss: 0.305461]\n",
      "epoch:14 step:13463 [D loss: 0.237307, acc.: 58.59%] [G loss: 0.271958]\n",
      "epoch:14 step:13464 [D loss: 0.255152, acc.: 53.12%] [G loss: 0.266159]\n",
      "epoch:14 step:13465 [D loss: 0.246566, acc.: 54.69%] [G loss: 0.298695]\n",
      "epoch:14 step:13466 [D loss: 0.259810, acc.: 52.34%] [G loss: 0.275264]\n",
      "epoch:14 step:13467 [D loss: 0.237665, acc.: 58.59%] [G loss: 0.293379]\n",
      "epoch:14 step:13468 [D loss: 0.239230, acc.: 58.59%] [G loss: 0.273892]\n",
      "epoch:14 step:13469 [D loss: 0.239873, acc.: 63.28%] [G loss: 0.322607]\n",
      "epoch:14 step:13470 [D loss: 0.239521, acc.: 58.59%] [G loss: 0.314536]\n",
      "epoch:14 step:13471 [D loss: 0.238014, acc.: 60.16%] [G loss: 0.289513]\n",
      "epoch:14 step:13472 [D loss: 0.249028, acc.: 60.94%] [G loss: 0.286734]\n",
      "epoch:14 step:13473 [D loss: 0.243452, acc.: 57.81%] [G loss: 0.285951]\n",
      "epoch:14 step:13474 [D loss: 0.227071, acc.: 60.94%] [G loss: 0.274193]\n",
      "epoch:14 step:13475 [D loss: 0.251240, acc.: 53.91%] [G loss: 0.289201]\n",
      "epoch:14 step:13476 [D loss: 0.249467, acc.: 54.69%] [G loss: 0.299208]\n",
      "epoch:14 step:13477 [D loss: 0.240196, acc.: 60.94%] [G loss: 0.278429]\n",
      "epoch:14 step:13478 [D loss: 0.229820, acc.: 62.50%] [G loss: 0.327467]\n",
      "epoch:14 step:13479 [D loss: 0.251647, acc.: 52.34%] [G loss: 0.290099]\n",
      "epoch:14 step:13480 [D loss: 0.247374, acc.: 56.25%] [G loss: 0.294689]\n",
      "epoch:14 step:13481 [D loss: 0.237450, acc.: 57.81%] [G loss: 0.310921]\n",
      "epoch:14 step:13482 [D loss: 0.239399, acc.: 59.38%] [G loss: 0.303793]\n",
      "epoch:14 step:13483 [D loss: 0.244940, acc.: 61.72%] [G loss: 0.299098]\n",
      "epoch:14 step:13484 [D loss: 0.228610, acc.: 62.50%] [G loss: 0.274215]\n",
      "epoch:14 step:13485 [D loss: 0.227473, acc.: 65.62%] [G loss: 0.278662]\n",
      "epoch:14 step:13486 [D loss: 0.228861, acc.: 64.06%] [G loss: 0.315148]\n",
      "epoch:14 step:13487 [D loss: 0.254652, acc.: 50.00%] [G loss: 0.310274]\n",
      "epoch:14 step:13488 [D loss: 0.250893, acc.: 52.34%] [G loss: 0.297081]\n",
      "epoch:14 step:13489 [D loss: 0.239481, acc.: 60.16%] [G loss: 0.269936]\n",
      "epoch:14 step:13490 [D loss: 0.217912, acc.: 64.06%] [G loss: 0.305196]\n",
      "epoch:14 step:13491 [D loss: 0.241398, acc.: 53.12%] [G loss: 0.309498]\n",
      "epoch:14 step:13492 [D loss: 0.254460, acc.: 48.44%] [G loss: 0.291513]\n",
      "epoch:14 step:13493 [D loss: 0.238841, acc.: 57.81%] [G loss: 0.302816]\n",
      "epoch:14 step:13494 [D loss: 0.266810, acc.: 47.66%] [G loss: 0.277701]\n",
      "epoch:14 step:13495 [D loss: 0.241900, acc.: 51.56%] [G loss: 0.277750]\n",
      "epoch:14 step:13496 [D loss: 0.220310, acc.: 63.28%] [G loss: 0.299937]\n",
      "epoch:14 step:13497 [D loss: 0.245434, acc.: 53.91%] [G loss: 0.294476]\n",
      "epoch:14 step:13498 [D loss: 0.230499, acc.: 64.84%] [G loss: 0.304990]\n",
      "epoch:14 step:13499 [D loss: 0.249338, acc.: 53.12%] [G loss: 0.291597]\n",
      "epoch:14 step:13500 [D loss: 0.251383, acc.: 53.12%] [G loss: 0.262328]\n",
      "epoch:14 step:13501 [D loss: 0.242856, acc.: 56.25%] [G loss: 0.317809]\n",
      "epoch:14 step:13502 [D loss: 0.233588, acc.: 59.38%] [G loss: 0.291575]\n",
      "epoch:14 step:13503 [D loss: 0.259410, acc.: 47.66%] [G loss: 0.319156]\n",
      "epoch:14 step:13504 [D loss: 0.236217, acc.: 60.16%] [G loss: 0.287524]\n",
      "epoch:14 step:13505 [D loss: 0.235065, acc.: 62.50%] [G loss: 0.328502]\n",
      "epoch:14 step:13506 [D loss: 0.253542, acc.: 52.34%] [G loss: 0.270400]\n",
      "epoch:14 step:13507 [D loss: 0.268265, acc.: 52.34%] [G loss: 0.285806]\n",
      "epoch:14 step:13508 [D loss: 0.236445, acc.: 61.72%] [G loss: 0.300422]\n",
      "epoch:14 step:13509 [D loss: 0.225942, acc.: 67.97%] [G loss: 0.321187]\n",
      "epoch:14 step:13510 [D loss: 0.239080, acc.: 58.59%] [G loss: 0.281397]\n",
      "epoch:14 step:13511 [D loss: 0.234245, acc.: 57.81%] [G loss: 0.315584]\n",
      "epoch:14 step:13512 [D loss: 0.240676, acc.: 57.03%] [G loss: 0.309106]\n",
      "epoch:14 step:13513 [D loss: 0.233907, acc.: 63.28%] [G loss: 0.284130]\n",
      "epoch:14 step:13514 [D loss: 0.244746, acc.: 49.22%] [G loss: 0.294550]\n",
      "epoch:14 step:13515 [D loss: 0.254738, acc.: 50.78%] [G loss: 0.245550]\n",
      "epoch:14 step:13516 [D loss: 0.247516, acc.: 57.03%] [G loss: 0.311197]\n",
      "epoch:14 step:13517 [D loss: 0.222382, acc.: 65.62%] [G loss: 0.298036]\n",
      "epoch:14 step:13518 [D loss: 0.230440, acc.: 59.38%] [G loss: 0.293376]\n",
      "epoch:14 step:13519 [D loss: 0.239749, acc.: 55.47%] [G loss: 0.299577]\n",
      "epoch:14 step:13520 [D loss: 0.230794, acc.: 63.28%] [G loss: 0.336468]\n",
      "epoch:14 step:13521 [D loss: 0.246941, acc.: 57.81%] [G loss: 0.283002]\n",
      "epoch:14 step:13522 [D loss: 0.229009, acc.: 60.94%] [G loss: 0.287338]\n",
      "epoch:14 step:13523 [D loss: 0.242103, acc.: 54.69%] [G loss: 0.305578]\n",
      "epoch:14 step:13524 [D loss: 0.239290, acc.: 57.81%] [G loss: 0.281982]\n",
      "epoch:14 step:13525 [D loss: 0.238071, acc.: 60.16%] [G loss: 0.290163]\n",
      "epoch:14 step:13526 [D loss: 0.250543, acc.: 52.34%] [G loss: 0.271495]\n",
      "epoch:14 step:13527 [D loss: 0.235425, acc.: 58.59%] [G loss: 0.293812]\n",
      "epoch:14 step:13528 [D loss: 0.231295, acc.: 57.03%] [G loss: 0.298577]\n",
      "epoch:14 step:13529 [D loss: 0.237850, acc.: 61.72%] [G loss: 0.288923]\n",
      "epoch:14 step:13530 [D loss: 0.231748, acc.: 60.94%] [G loss: 0.295005]\n",
      "epoch:14 step:13531 [D loss: 0.249024, acc.: 53.12%] [G loss: 0.284973]\n",
      "epoch:14 step:13532 [D loss: 0.237175, acc.: 50.78%] [G loss: 0.283149]\n",
      "epoch:14 step:13533 [D loss: 0.250471, acc.: 51.56%] [G loss: 0.309296]\n",
      "epoch:14 step:13534 [D loss: 0.221495, acc.: 64.84%] [G loss: 0.301275]\n",
      "epoch:14 step:13535 [D loss: 0.264376, acc.: 44.53%] [G loss: 0.296830]\n",
      "epoch:14 step:13536 [D loss: 0.248916, acc.: 50.00%] [G loss: 0.307275]\n",
      "epoch:14 step:13537 [D loss: 0.226892, acc.: 62.50%] [G loss: 0.316559]\n",
      "epoch:14 step:13538 [D loss: 0.229209, acc.: 63.28%] [G loss: 0.279675]\n",
      "epoch:14 step:13539 [D loss: 0.237001, acc.: 59.38%] [G loss: 0.292601]\n",
      "epoch:14 step:13540 [D loss: 0.239416, acc.: 58.59%] [G loss: 0.279669]\n",
      "epoch:14 step:13541 [D loss: 0.251210, acc.: 48.44%] [G loss: 0.290325]\n",
      "epoch:14 step:13542 [D loss: 0.239174, acc.: 62.50%] [G loss: 0.297753]\n",
      "epoch:14 step:13543 [D loss: 0.253498, acc.: 50.78%] [G loss: 0.324742]\n",
      "epoch:14 step:13544 [D loss: 0.243315, acc.: 57.03%] [G loss: 0.282935]\n",
      "epoch:14 step:13545 [D loss: 0.241366, acc.: 53.91%] [G loss: 0.292487]\n",
      "epoch:14 step:13546 [D loss: 0.242749, acc.: 60.16%] [G loss: 0.315949]\n",
      "epoch:14 step:13547 [D loss: 0.243608, acc.: 63.28%] [G loss: 0.279555]\n",
      "epoch:14 step:13548 [D loss: 0.251616, acc.: 58.59%] [G loss: 0.291146]\n",
      "epoch:14 step:13549 [D loss: 0.247707, acc.: 52.34%] [G loss: 0.308237]\n",
      "epoch:14 step:13550 [D loss: 0.248911, acc.: 53.91%] [G loss: 0.290623]\n",
      "epoch:14 step:13551 [D loss: 0.246480, acc.: 55.47%] [G loss: 0.312979]\n",
      "epoch:14 step:13552 [D loss: 0.219640, acc.: 71.09%] [G loss: 0.296637]\n",
      "epoch:14 step:13553 [D loss: 0.217327, acc.: 74.22%] [G loss: 0.285248]\n",
      "epoch:14 step:13554 [D loss: 0.245265, acc.: 52.34%] [G loss: 0.306951]\n",
      "epoch:14 step:13555 [D loss: 0.250981, acc.: 50.78%] [G loss: 0.307140]\n",
      "epoch:14 step:13556 [D loss: 0.239297, acc.: 60.94%] [G loss: 0.279371]\n",
      "epoch:14 step:13557 [D loss: 0.231305, acc.: 61.72%] [G loss: 0.283869]\n",
      "epoch:14 step:13558 [D loss: 0.244299, acc.: 53.12%] [G loss: 0.274536]\n",
      "epoch:14 step:13559 [D loss: 0.229007, acc.: 64.84%] [G loss: 0.303403]\n",
      "epoch:14 step:13560 [D loss: 0.244131, acc.: 58.59%] [G loss: 0.296925]\n",
      "epoch:14 step:13561 [D loss: 0.225986, acc.: 61.72%] [G loss: 0.295124]\n",
      "epoch:14 step:13562 [D loss: 0.237234, acc.: 59.38%] [G loss: 0.298596]\n",
      "epoch:14 step:13563 [D loss: 0.239872, acc.: 58.59%] [G loss: 0.293693]\n",
      "epoch:14 step:13564 [D loss: 0.250725, acc.: 56.25%] [G loss: 0.301324]\n",
      "epoch:14 step:13565 [D loss: 0.240266, acc.: 58.59%] [G loss: 0.314767]\n",
      "epoch:14 step:13566 [D loss: 0.240983, acc.: 60.94%] [G loss: 0.327627]\n",
      "epoch:14 step:13567 [D loss: 0.258121, acc.: 46.88%] [G loss: 0.300457]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:14 step:13568 [D loss: 0.223150, acc.: 64.06%] [G loss: 0.307520]\n",
      "epoch:14 step:13569 [D loss: 0.224795, acc.: 62.50%] [G loss: 0.293801]\n",
      "epoch:14 step:13570 [D loss: 0.227998, acc.: 59.38%] [G loss: 0.282649]\n",
      "epoch:14 step:13571 [D loss: 0.229801, acc.: 61.72%] [G loss: 0.326730]\n",
      "epoch:14 step:13572 [D loss: 0.224041, acc.: 65.62%] [G loss: 0.282663]\n",
      "epoch:14 step:13573 [D loss: 0.244523, acc.: 57.81%] [G loss: 0.292605]\n",
      "epoch:14 step:13574 [D loss: 0.241536, acc.: 57.81%] [G loss: 0.275334]\n",
      "epoch:14 step:13575 [D loss: 0.244197, acc.: 54.69%] [G loss: 0.330319]\n",
      "epoch:14 step:13576 [D loss: 0.246908, acc.: 56.25%] [G loss: 0.285192]\n",
      "epoch:14 step:13577 [D loss: 0.230832, acc.: 59.38%] [G loss: 0.316359]\n",
      "epoch:14 step:13578 [D loss: 0.261521, acc.: 47.66%] [G loss: 0.283277]\n",
      "epoch:14 step:13579 [D loss: 0.246261, acc.: 53.91%] [G loss: 0.296028]\n",
      "epoch:14 step:13580 [D loss: 0.257140, acc.: 46.09%] [G loss: 0.297125]\n",
      "epoch:14 step:13581 [D loss: 0.246046, acc.: 57.03%] [G loss: 0.283756]\n",
      "epoch:14 step:13582 [D loss: 0.236747, acc.: 53.91%] [G loss: 0.279522]\n",
      "epoch:14 step:13583 [D loss: 0.256162, acc.: 50.00%] [G loss: 0.291551]\n",
      "epoch:14 step:13584 [D loss: 0.232550, acc.: 57.03%] [G loss: 0.302302]\n",
      "epoch:14 step:13585 [D loss: 0.221647, acc.: 66.41%] [G loss: 0.305484]\n",
      "epoch:14 step:13586 [D loss: 0.247748, acc.: 54.69%] [G loss: 0.265111]\n",
      "epoch:14 step:13587 [D loss: 0.236999, acc.: 61.72%] [G loss: 0.285955]\n",
      "epoch:14 step:13588 [D loss: 0.245370, acc.: 60.16%] [G loss: 0.296555]\n",
      "epoch:14 step:13589 [D loss: 0.233374, acc.: 64.06%] [G loss: 0.272368]\n",
      "epoch:14 step:13590 [D loss: 0.253899, acc.: 54.69%] [G loss: 0.277459]\n",
      "epoch:14 step:13591 [D loss: 0.254338, acc.: 50.00%] [G loss: 0.287055]\n",
      "epoch:14 step:13592 [D loss: 0.222739, acc.: 60.94%] [G loss: 0.316282]\n",
      "epoch:14 step:13593 [D loss: 0.229899, acc.: 61.72%] [G loss: 0.318397]\n",
      "epoch:14 step:13594 [D loss: 0.227145, acc.: 61.72%] [G loss: 0.280168]\n",
      "epoch:14 step:13595 [D loss: 0.240933, acc.: 57.03%] [G loss: 0.283378]\n",
      "epoch:14 step:13596 [D loss: 0.246686, acc.: 60.16%] [G loss: 0.281386]\n",
      "epoch:14 step:13597 [D loss: 0.238434, acc.: 57.81%] [G loss: 0.289954]\n",
      "epoch:14 step:13598 [D loss: 0.229602, acc.: 60.16%] [G loss: 0.305152]\n",
      "epoch:14 step:13599 [D loss: 0.237017, acc.: 61.72%] [G loss: 0.308980]\n",
      "epoch:14 step:13600 [D loss: 0.229170, acc.: 62.50%] [G loss: 0.300487]\n",
      "epoch:14 step:13601 [D loss: 0.238600, acc.: 63.28%] [G loss: 0.282271]\n",
      "epoch:14 step:13602 [D loss: 0.242045, acc.: 55.47%] [G loss: 0.288185]\n",
      "epoch:14 step:13603 [D loss: 0.244223, acc.: 51.56%] [G loss: 0.297571]\n",
      "epoch:14 step:13604 [D loss: 0.221224, acc.: 65.62%] [G loss: 0.308251]\n",
      "epoch:14 step:13605 [D loss: 0.240283, acc.: 53.12%] [G loss: 0.286129]\n",
      "epoch:14 step:13606 [D loss: 0.219411, acc.: 64.06%] [G loss: 0.296837]\n",
      "epoch:14 step:13607 [D loss: 0.251789, acc.: 50.00%] [G loss: 0.293617]\n",
      "epoch:14 step:13608 [D loss: 0.221712, acc.: 65.62%] [G loss: 0.299353]\n",
      "epoch:14 step:13609 [D loss: 0.229614, acc.: 65.62%] [G loss: 0.312731]\n",
      "epoch:14 step:13610 [D loss: 0.249182, acc.: 53.91%] [G loss: 0.285359]\n",
      "epoch:14 step:13611 [D loss: 0.253463, acc.: 56.25%] [G loss: 0.305199]\n",
      "epoch:14 step:13612 [D loss: 0.230712, acc.: 59.38%] [G loss: 0.304947]\n",
      "epoch:14 step:13613 [D loss: 0.247941, acc.: 52.34%] [G loss: 0.290622]\n",
      "epoch:14 step:13614 [D loss: 0.252834, acc.: 51.56%] [G loss: 0.323380]\n",
      "epoch:14 step:13615 [D loss: 0.256473, acc.: 52.34%] [G loss: 0.320752]\n",
      "epoch:14 step:13616 [D loss: 0.237458, acc.: 57.81%] [G loss: 0.297168]\n",
      "epoch:14 step:13617 [D loss: 0.252808, acc.: 50.00%] [G loss: 0.280779]\n",
      "epoch:14 step:13618 [D loss: 0.235852, acc.: 57.03%] [G loss: 0.296327]\n",
      "epoch:14 step:13619 [D loss: 0.231420, acc.: 65.62%] [G loss: 0.339247]\n",
      "epoch:14 step:13620 [D loss: 0.238994, acc.: 55.47%] [G loss: 0.289350]\n",
      "epoch:14 step:13621 [D loss: 0.217320, acc.: 67.19%] [G loss: 0.328787]\n",
      "epoch:14 step:13622 [D loss: 0.260261, acc.: 49.22%] [G loss: 0.319793]\n",
      "epoch:14 step:13623 [D loss: 0.228601, acc.: 64.84%] [G loss: 0.266467]\n",
      "epoch:14 step:13624 [D loss: 0.255731, acc.: 51.56%] [G loss: 0.284638]\n",
      "epoch:14 step:13625 [D loss: 0.241088, acc.: 59.38%] [G loss: 0.302710]\n",
      "epoch:14 step:13626 [D loss: 0.230331, acc.: 62.50%] [G loss: 0.310694]\n",
      "epoch:14 step:13627 [D loss: 0.230028, acc.: 60.94%] [G loss: 0.308368]\n",
      "epoch:14 step:13628 [D loss: 0.242608, acc.: 55.47%] [G loss: 0.288732]\n",
      "epoch:14 step:13629 [D loss: 0.233730, acc.: 58.59%] [G loss: 0.299933]\n",
      "epoch:14 step:13630 [D loss: 0.249283, acc.: 53.12%] [G loss: 0.301669]\n",
      "epoch:14 step:13631 [D loss: 0.249151, acc.: 55.47%] [G loss: 0.302405]\n",
      "epoch:14 step:13632 [D loss: 0.236546, acc.: 59.38%] [G loss: 0.318720]\n",
      "epoch:14 step:13633 [D loss: 0.241156, acc.: 53.12%] [G loss: 0.315214]\n",
      "epoch:14 step:13634 [D loss: 0.246984, acc.: 60.16%] [G loss: 0.315220]\n",
      "epoch:14 step:13635 [D loss: 0.238222, acc.: 57.81%] [G loss: 0.323307]\n",
      "epoch:14 step:13636 [D loss: 0.258850, acc.: 51.56%] [G loss: 0.276895]\n",
      "epoch:14 step:13637 [D loss: 0.228502, acc.: 60.16%] [G loss: 0.328661]\n",
      "epoch:14 step:13638 [D loss: 0.240564, acc.: 55.47%] [G loss: 0.267855]\n",
      "epoch:14 step:13639 [D loss: 0.238654, acc.: 60.16%] [G loss: 0.299537]\n",
      "epoch:14 step:13640 [D loss: 0.223660, acc.: 65.62%] [G loss: 0.307717]\n",
      "epoch:14 step:13641 [D loss: 0.233060, acc.: 64.06%] [G loss: 0.295266]\n",
      "epoch:14 step:13642 [D loss: 0.229298, acc.: 60.94%] [G loss: 0.310150]\n",
      "epoch:14 step:13643 [D loss: 0.232814, acc.: 63.28%] [G loss: 0.314985]\n",
      "epoch:14 step:13644 [D loss: 0.240589, acc.: 58.59%] [G loss: 0.302446]\n",
      "epoch:14 step:13645 [D loss: 0.236969, acc.: 60.94%] [G loss: 0.320118]\n",
      "epoch:14 step:13646 [D loss: 0.243371, acc.: 53.91%] [G loss: 0.289268]\n",
      "epoch:14 step:13647 [D loss: 0.257148, acc.: 48.44%] [G loss: 0.294180]\n",
      "epoch:14 step:13648 [D loss: 0.230197, acc.: 59.38%] [G loss: 0.318593]\n",
      "epoch:14 step:13649 [D loss: 0.234118, acc.: 59.38%] [G loss: 0.295223]\n",
      "epoch:14 step:13650 [D loss: 0.238726, acc.: 59.38%] [G loss: 0.303078]\n",
      "epoch:14 step:13651 [D loss: 0.238281, acc.: 59.38%] [G loss: 0.303449]\n",
      "epoch:14 step:13652 [D loss: 0.247376, acc.: 53.91%] [G loss: 0.307425]\n",
      "epoch:14 step:13653 [D loss: 0.245297, acc.: 57.03%] [G loss: 0.343884]\n",
      "epoch:14 step:13654 [D loss: 0.253461, acc.: 54.69%] [G loss: 0.332597]\n",
      "epoch:14 step:13655 [D loss: 0.245553, acc.: 57.81%] [G loss: 0.283029]\n",
      "epoch:14 step:13656 [D loss: 0.231120, acc.: 57.03%] [G loss: 0.291745]\n",
      "epoch:14 step:13657 [D loss: 0.241028, acc.: 50.00%] [G loss: 0.287449]\n",
      "epoch:14 step:13658 [D loss: 0.220329, acc.: 65.62%] [G loss: 0.307618]\n",
      "epoch:14 step:13659 [D loss: 0.233385, acc.: 54.69%] [G loss: 0.304671]\n",
      "epoch:14 step:13660 [D loss: 0.255968, acc.: 51.56%] [G loss: 0.266881]\n",
      "epoch:14 step:13661 [D loss: 0.241844, acc.: 58.59%] [G loss: 0.294182]\n",
      "epoch:14 step:13662 [D loss: 0.243488, acc.: 60.16%] [G loss: 0.271722]\n",
      "epoch:14 step:13663 [D loss: 0.237306, acc.: 59.38%] [G loss: 0.303152]\n",
      "epoch:14 step:13664 [D loss: 0.223709, acc.: 60.94%] [G loss: 0.277406]\n",
      "epoch:14 step:13665 [D loss: 0.221075, acc.: 66.41%] [G loss: 0.303511]\n",
      "epoch:14 step:13666 [D loss: 0.254999, acc.: 55.47%] [G loss: 0.279697]\n",
      "epoch:14 step:13667 [D loss: 0.247968, acc.: 56.25%] [G loss: 0.301342]\n",
      "epoch:14 step:13668 [D loss: 0.219789, acc.: 64.84%] [G loss: 0.303383]\n",
      "epoch:14 step:13669 [D loss: 0.247542, acc.: 56.25%] [G loss: 0.270839]\n",
      "epoch:14 step:13670 [D loss: 0.265142, acc.: 51.56%] [G loss: 0.264319]\n",
      "epoch:14 step:13671 [D loss: 0.242571, acc.: 63.28%] [G loss: 0.262137]\n",
      "epoch:14 step:13672 [D loss: 0.242293, acc.: 54.69%] [G loss: 0.295824]\n",
      "epoch:14 step:13673 [D loss: 0.237509, acc.: 57.03%] [G loss: 0.318999]\n",
      "epoch:14 step:13674 [D loss: 0.234689, acc.: 59.38%] [G loss: 0.294178]\n",
      "epoch:14 step:13675 [D loss: 0.220033, acc.: 64.84%] [G loss: 0.337508]\n",
      "epoch:14 step:13676 [D loss: 0.240418, acc.: 57.03%] [G loss: 0.272751]\n",
      "epoch:14 step:13677 [D loss: 0.235130, acc.: 59.38%] [G loss: 0.317968]\n",
      "epoch:14 step:13678 [D loss: 0.246857, acc.: 59.38%] [G loss: 0.295933]\n",
      "epoch:14 step:13679 [D loss: 0.242362, acc.: 59.38%] [G loss: 0.280976]\n",
      "epoch:14 step:13680 [D loss: 0.245945, acc.: 53.91%] [G loss: 0.294329]\n",
      "epoch:14 step:13681 [D loss: 0.234315, acc.: 59.38%] [G loss: 0.301404]\n",
      "epoch:14 step:13682 [D loss: 0.225430, acc.: 60.94%] [G loss: 0.279463]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:14 step:13683 [D loss: 0.223945, acc.: 60.16%] [G loss: 0.312990]\n",
      "epoch:14 step:13684 [D loss: 0.241749, acc.: 54.69%] [G loss: 0.300793]\n",
      "epoch:14 step:13685 [D loss: 0.255739, acc.: 56.25%] [G loss: 0.290257]\n",
      "epoch:14 step:13686 [D loss: 0.253037, acc.: 53.91%] [G loss: 0.292212]\n",
      "epoch:14 step:13687 [D loss: 0.223553, acc.: 64.06%] [G loss: 0.315286]\n",
      "epoch:14 step:13688 [D loss: 0.241402, acc.: 58.59%] [G loss: 0.283841]\n",
      "epoch:14 step:13689 [D loss: 0.235640, acc.: 56.25%] [G loss: 0.325589]\n",
      "epoch:14 step:13690 [D loss: 0.218348, acc.: 66.41%] [G loss: 0.291057]\n",
      "epoch:14 step:13691 [D loss: 0.248097, acc.: 55.47%] [G loss: 0.301674]\n",
      "epoch:14 step:13692 [D loss: 0.244760, acc.: 54.69%] [G loss: 0.285067]\n",
      "epoch:14 step:13693 [D loss: 0.245368, acc.: 56.25%] [G loss: 0.297243]\n",
      "epoch:14 step:13694 [D loss: 0.233968, acc.: 54.69%] [G loss: 0.296840]\n",
      "epoch:14 step:13695 [D loss: 0.248677, acc.: 53.91%] [G loss: 0.312727]\n",
      "epoch:14 step:13696 [D loss: 0.228956, acc.: 61.72%] [G loss: 0.315723]\n",
      "epoch:14 step:13697 [D loss: 0.241864, acc.: 56.25%] [G loss: 0.291753]\n",
      "epoch:14 step:13698 [D loss: 0.253203, acc.: 51.56%] [G loss: 0.309238]\n",
      "epoch:14 step:13699 [D loss: 0.235173, acc.: 53.91%] [G loss: 0.309717]\n",
      "epoch:14 step:13700 [D loss: 0.235170, acc.: 57.81%] [G loss: 0.312434]\n",
      "epoch:14 step:13701 [D loss: 0.235786, acc.: 58.59%] [G loss: 0.285466]\n",
      "epoch:14 step:13702 [D loss: 0.244456, acc.: 57.81%] [G loss: 0.277397]\n",
      "epoch:14 step:13703 [D loss: 0.244258, acc.: 57.81%] [G loss: 0.276239]\n",
      "epoch:14 step:13704 [D loss: 0.231208, acc.: 61.72%] [G loss: 0.316688]\n",
      "epoch:14 step:13705 [D loss: 0.262087, acc.: 52.34%] [G loss: 0.296472]\n",
      "epoch:14 step:13706 [D loss: 0.251320, acc.: 55.47%] [G loss: 0.285551]\n",
      "epoch:14 step:13707 [D loss: 0.229015, acc.: 58.59%] [G loss: 0.317414]\n",
      "epoch:14 step:13708 [D loss: 0.230591, acc.: 59.38%] [G loss: 0.311713]\n",
      "epoch:14 step:13709 [D loss: 0.242444, acc.: 52.34%] [G loss: 0.292944]\n",
      "epoch:14 step:13710 [D loss: 0.242628, acc.: 59.38%] [G loss: 0.280522]\n",
      "epoch:14 step:13711 [D loss: 0.241990, acc.: 60.94%] [G loss: 0.285241]\n",
      "epoch:14 step:13712 [D loss: 0.247034, acc.: 56.25%] [G loss: 0.277858]\n",
      "epoch:14 step:13713 [D loss: 0.244168, acc.: 58.59%] [G loss: 0.269203]\n",
      "epoch:14 step:13714 [D loss: 0.235143, acc.: 63.28%] [G loss: 0.304066]\n",
      "epoch:14 step:13715 [D loss: 0.231211, acc.: 55.47%] [G loss: 0.346570]\n",
      "epoch:14 step:13716 [D loss: 0.240152, acc.: 53.91%] [G loss: 0.306303]\n",
      "epoch:14 step:13717 [D loss: 0.233175, acc.: 61.72%] [G loss: 0.287302]\n",
      "epoch:14 step:13718 [D loss: 0.236218, acc.: 59.38%] [G loss: 0.286521]\n",
      "epoch:14 step:13719 [D loss: 0.276057, acc.: 47.66%] [G loss: 0.313990]\n",
      "epoch:14 step:13720 [D loss: 0.238417, acc.: 53.12%] [G loss: 0.321002]\n",
      "epoch:14 step:13721 [D loss: 0.243580, acc.: 57.81%] [G loss: 0.292148]\n",
      "epoch:14 step:13722 [D loss: 0.241166, acc.: 57.81%] [G loss: 0.303688]\n",
      "epoch:14 step:13723 [D loss: 0.232000, acc.: 62.50%] [G loss: 0.288152]\n",
      "epoch:14 step:13724 [D loss: 0.239044, acc.: 60.16%] [G loss: 0.277650]\n",
      "epoch:14 step:13725 [D loss: 0.226171, acc.: 61.72%] [G loss: 0.292536]\n",
      "epoch:14 step:13726 [D loss: 0.236582, acc.: 59.38%] [G loss: 0.281094]\n",
      "epoch:14 step:13727 [D loss: 0.228194, acc.: 61.72%] [G loss: 0.304214]\n",
      "epoch:14 step:13728 [D loss: 0.243992, acc.: 60.94%] [G loss: 0.289131]\n",
      "epoch:14 step:13729 [D loss: 0.238530, acc.: 55.47%] [G loss: 0.279083]\n",
      "epoch:14 step:13730 [D loss: 0.236229, acc.: 63.28%] [G loss: 0.324850]\n",
      "epoch:14 step:13731 [D loss: 0.230453, acc.: 58.59%] [G loss: 0.310439]\n",
      "epoch:14 step:13732 [D loss: 0.249847, acc.: 53.91%] [G loss: 0.315237]\n",
      "epoch:14 step:13733 [D loss: 0.239800, acc.: 54.69%] [G loss: 0.303648]\n",
      "epoch:14 step:13734 [D loss: 0.238241, acc.: 58.59%] [G loss: 0.336899]\n",
      "epoch:14 step:13735 [D loss: 0.244984, acc.: 60.16%] [G loss: 0.272973]\n",
      "epoch:14 step:13736 [D loss: 0.235133, acc.: 58.59%] [G loss: 0.295464]\n",
      "epoch:14 step:13737 [D loss: 0.252444, acc.: 48.44%] [G loss: 0.292057]\n",
      "epoch:14 step:13738 [D loss: 0.265738, acc.: 50.00%] [G loss: 0.282058]\n",
      "epoch:14 step:13739 [D loss: 0.266581, acc.: 50.00%] [G loss: 0.263888]\n",
      "epoch:14 step:13740 [D loss: 0.248137, acc.: 59.38%] [G loss: 0.276770]\n",
      "epoch:14 step:13741 [D loss: 0.237045, acc.: 57.81%] [G loss: 0.307867]\n",
      "epoch:14 step:13742 [D loss: 0.244330, acc.: 53.91%] [G loss: 0.294343]\n",
      "epoch:14 step:13743 [D loss: 0.235101, acc.: 58.59%] [G loss: 0.315073]\n",
      "epoch:14 step:13744 [D loss: 0.227264, acc.: 64.06%] [G loss: 0.306568]\n",
      "epoch:14 step:13745 [D loss: 0.239249, acc.: 59.38%] [G loss: 0.292750]\n",
      "epoch:14 step:13746 [D loss: 0.240604, acc.: 57.81%] [G loss: 0.286913]\n",
      "epoch:14 step:13747 [D loss: 0.239087, acc.: 57.81%] [G loss: 0.282532]\n",
      "epoch:14 step:13748 [D loss: 0.238597, acc.: 56.25%] [G loss: 0.296280]\n",
      "epoch:14 step:13749 [D loss: 0.224464, acc.: 64.06%] [G loss: 0.300236]\n",
      "epoch:14 step:13750 [D loss: 0.244135, acc.: 53.91%] [G loss: 0.284570]\n",
      "epoch:14 step:13751 [D loss: 0.246148, acc.: 54.69%] [G loss: 0.264637]\n",
      "epoch:14 step:13752 [D loss: 0.236729, acc.: 57.03%] [G loss: 0.314664]\n",
      "epoch:14 step:13753 [D loss: 0.233797, acc.: 58.59%] [G loss: 0.307324]\n",
      "epoch:14 step:13754 [D loss: 0.244260, acc.: 54.69%] [G loss: 0.297035]\n",
      "epoch:14 step:13755 [D loss: 0.227792, acc.: 63.28%] [G loss: 0.310380]\n",
      "epoch:14 step:13756 [D loss: 0.238100, acc.: 58.59%] [G loss: 0.308915]\n",
      "epoch:14 step:13757 [D loss: 0.258227, acc.: 55.47%] [G loss: 0.313786]\n",
      "epoch:14 step:13758 [D loss: 0.232689, acc.: 60.16%] [G loss: 0.321803]\n",
      "epoch:14 step:13759 [D loss: 0.236198, acc.: 58.59%] [G loss: 0.291153]\n",
      "epoch:14 step:13760 [D loss: 0.260388, acc.: 50.78%] [G loss: 0.279260]\n",
      "epoch:14 step:13761 [D loss: 0.250870, acc.: 57.03%] [G loss: 0.293115]\n",
      "epoch:14 step:13762 [D loss: 0.219722, acc.: 67.97%] [G loss: 0.321496]\n",
      "epoch:14 step:13763 [D loss: 0.244474, acc.: 57.03%] [G loss: 0.281039]\n",
      "epoch:14 step:13764 [D loss: 0.235079, acc.: 59.38%] [G loss: 0.336078]\n",
      "epoch:14 step:13765 [D loss: 0.251652, acc.: 54.69%] [G loss: 0.308898]\n",
      "epoch:14 step:13766 [D loss: 0.229211, acc.: 63.28%] [G loss: 0.285747]\n",
      "epoch:14 step:13767 [D loss: 0.234934, acc.: 57.03%] [G loss: 0.277679]\n",
      "epoch:14 step:13768 [D loss: 0.235963, acc.: 58.59%] [G loss: 0.269428]\n",
      "epoch:14 step:13769 [D loss: 0.232538, acc.: 61.72%] [G loss: 0.288196]\n",
      "epoch:14 step:13770 [D loss: 0.247911, acc.: 56.25%] [G loss: 0.288937]\n",
      "epoch:14 step:13771 [D loss: 0.225968, acc.: 63.28%] [G loss: 0.290439]\n",
      "epoch:14 step:13772 [D loss: 0.208537, acc.: 72.66%] [G loss: 0.322430]\n",
      "epoch:14 step:13773 [D loss: 0.219537, acc.: 67.19%] [G loss: 0.287635]\n",
      "epoch:14 step:13774 [D loss: 0.223749, acc.: 64.06%] [G loss: 0.294828]\n",
      "epoch:14 step:13775 [D loss: 0.237952, acc.: 63.28%] [G loss: 0.311930]\n",
      "epoch:14 step:13776 [D loss: 0.239136, acc.: 57.81%] [G loss: 0.307893]\n",
      "epoch:14 step:13777 [D loss: 0.242859, acc.: 55.47%] [G loss: 0.305115]\n",
      "epoch:14 step:13778 [D loss: 0.244434, acc.: 54.69%] [G loss: 0.287671]\n",
      "epoch:14 step:13779 [D loss: 0.226192, acc.: 61.72%] [G loss: 0.288001]\n",
      "epoch:14 step:13780 [D loss: 0.243611, acc.: 55.47%] [G loss: 0.267296]\n",
      "epoch:14 step:13781 [D loss: 0.229644, acc.: 60.16%] [G loss: 0.305599]\n",
      "epoch:14 step:13782 [D loss: 0.219569, acc.: 66.41%] [G loss: 0.276474]\n",
      "epoch:14 step:13783 [D loss: 0.252149, acc.: 48.44%] [G loss: 0.313238]\n",
      "epoch:14 step:13784 [D loss: 0.229342, acc.: 59.38%] [G loss: 0.289285]\n",
      "epoch:14 step:13785 [D loss: 0.246589, acc.: 57.81%] [G loss: 0.293583]\n",
      "epoch:14 step:13786 [D loss: 0.255111, acc.: 50.00%] [G loss: 0.284895]\n",
      "epoch:14 step:13787 [D loss: 0.230730, acc.: 62.50%] [G loss: 0.314878]\n",
      "epoch:14 step:13788 [D loss: 0.229281, acc.: 60.16%] [G loss: 0.306997]\n",
      "epoch:14 step:13789 [D loss: 0.244901, acc.: 55.47%] [G loss: 0.301527]\n",
      "epoch:14 step:13790 [D loss: 0.250389, acc.: 55.47%] [G loss: 0.303810]\n",
      "epoch:14 step:13791 [D loss: 0.254229, acc.: 49.22%] [G loss: 0.276909]\n",
      "epoch:14 step:13792 [D loss: 0.220301, acc.: 64.84%] [G loss: 0.322107]\n",
      "epoch:14 step:13793 [D loss: 0.253016, acc.: 56.25%] [G loss: 0.264508]\n",
      "epoch:14 step:13794 [D loss: 0.230106, acc.: 63.28%] [G loss: 0.306560]\n",
      "epoch:14 step:13795 [D loss: 0.249958, acc.: 54.69%] [G loss: 0.291448]\n",
      "epoch:14 step:13796 [D loss: 0.241248, acc.: 58.59%] [G loss: 0.322176]\n",
      "epoch:14 step:13797 [D loss: 0.230402, acc.: 63.28%] [G loss: 0.300295]\n",
      "epoch:14 step:13798 [D loss: 0.243288, acc.: 59.38%] [G loss: 0.302103]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:14 step:13799 [D loss: 0.243932, acc.: 53.91%] [G loss: 0.287436]\n",
      "epoch:14 step:13800 [D loss: 0.229344, acc.: 66.41%] [G loss: 0.286541]\n",
      "epoch:14 step:13801 [D loss: 0.248300, acc.: 50.78%] [G loss: 0.294076]\n",
      "epoch:14 step:13802 [D loss: 0.248086, acc.: 51.56%] [G loss: 0.296315]\n",
      "epoch:14 step:13803 [D loss: 0.239626, acc.: 57.81%] [G loss: 0.301767]\n",
      "epoch:14 step:13804 [D loss: 0.239879, acc.: 60.94%] [G loss: 0.270064]\n",
      "epoch:14 step:13805 [D loss: 0.253716, acc.: 52.34%] [G loss: 0.290259]\n",
      "epoch:14 step:13806 [D loss: 0.243050, acc.: 56.25%] [G loss: 0.306616]\n",
      "epoch:14 step:13807 [D loss: 0.233702, acc.: 57.03%] [G loss: 0.311431]\n",
      "epoch:14 step:13808 [D loss: 0.240044, acc.: 55.47%] [G loss: 0.286729]\n",
      "epoch:14 step:13809 [D loss: 0.225026, acc.: 65.62%] [G loss: 0.312407]\n",
      "epoch:14 step:13810 [D loss: 0.252653, acc.: 50.00%] [G loss: 0.305028]\n",
      "epoch:14 step:13811 [D loss: 0.225993, acc.: 63.28%] [G loss: 0.328128]\n",
      "epoch:14 step:13812 [D loss: 0.235938, acc.: 57.03%] [G loss: 0.309619]\n",
      "epoch:14 step:13813 [D loss: 0.231982, acc.: 64.06%] [G loss: 0.278249]\n",
      "epoch:14 step:13814 [D loss: 0.224666, acc.: 62.50%] [G loss: 0.313313]\n",
      "epoch:14 step:13815 [D loss: 0.234569, acc.: 60.94%] [G loss: 0.311454]\n",
      "epoch:14 step:13816 [D loss: 0.252095, acc.: 53.91%] [G loss: 0.307288]\n",
      "epoch:14 step:13817 [D loss: 0.249453, acc.: 53.12%] [G loss: 0.304717]\n",
      "epoch:14 step:13818 [D loss: 0.241778, acc.: 60.16%] [G loss: 0.287890]\n",
      "epoch:14 step:13819 [D loss: 0.242072, acc.: 56.25%] [G loss: 0.283708]\n",
      "epoch:14 step:13820 [D loss: 0.225176, acc.: 65.62%] [G loss: 0.322670]\n",
      "epoch:14 step:13821 [D loss: 0.247773, acc.: 50.78%] [G loss: 0.289413]\n",
      "epoch:14 step:13822 [D loss: 0.252327, acc.: 48.44%] [G loss: 0.312330]\n",
      "epoch:14 step:13823 [D loss: 0.236919, acc.: 55.47%] [G loss: 0.309508]\n",
      "epoch:14 step:13824 [D loss: 0.247275, acc.: 55.47%] [G loss: 0.313953]\n",
      "epoch:14 step:13825 [D loss: 0.245848, acc.: 47.66%] [G loss: 0.316514]\n",
      "epoch:14 step:13826 [D loss: 0.243818, acc.: 57.03%] [G loss: 0.280724]\n",
      "epoch:14 step:13827 [D loss: 0.243739, acc.: 54.69%] [G loss: 0.301974]\n",
      "epoch:14 step:13828 [D loss: 0.226245, acc.: 62.50%] [G loss: 0.300972]\n",
      "epoch:14 step:13829 [D loss: 0.224892, acc.: 60.16%] [G loss: 0.286043]\n",
      "epoch:14 step:13830 [D loss: 0.236895, acc.: 62.50%] [G loss: 0.300982]\n",
      "epoch:14 step:13831 [D loss: 0.244073, acc.: 52.34%] [G loss: 0.294268]\n",
      "epoch:14 step:13832 [D loss: 0.241925, acc.: 60.16%] [G loss: 0.310345]\n",
      "epoch:14 step:13833 [D loss: 0.259307, acc.: 49.22%] [G loss: 0.320017]\n",
      "epoch:14 step:13834 [D loss: 0.234059, acc.: 60.94%] [G loss: 0.315205]\n",
      "epoch:14 step:13835 [D loss: 0.231946, acc.: 63.28%] [G loss: 0.321535]\n",
      "epoch:14 step:13836 [D loss: 0.236065, acc.: 57.03%] [G loss: 0.305634]\n",
      "epoch:14 step:13837 [D loss: 0.255184, acc.: 50.00%] [G loss: 0.295441]\n",
      "epoch:14 step:13838 [D loss: 0.246911, acc.: 55.47%] [G loss: 0.324107]\n",
      "epoch:14 step:13839 [D loss: 0.240457, acc.: 58.59%] [G loss: 0.330123]\n",
      "epoch:14 step:13840 [D loss: 0.240908, acc.: 57.03%] [G loss: 0.329720]\n",
      "epoch:14 step:13841 [D loss: 0.240063, acc.: 57.03%] [G loss: 0.310753]\n",
      "epoch:14 step:13842 [D loss: 0.238860, acc.: 60.16%] [G loss: 0.331290]\n",
      "epoch:14 step:13843 [D loss: 0.248164, acc.: 52.34%] [G loss: 0.311742]\n",
      "epoch:14 step:13844 [D loss: 0.242809, acc.: 59.38%] [G loss: 0.312560]\n",
      "epoch:14 step:13845 [D loss: 0.245701, acc.: 57.03%] [G loss: 0.322763]\n",
      "epoch:14 step:13846 [D loss: 0.235921, acc.: 60.16%] [G loss: 0.310936]\n",
      "epoch:14 step:13847 [D loss: 0.226087, acc.: 62.50%] [G loss: 0.310425]\n",
      "epoch:14 step:13848 [D loss: 0.237444, acc.: 59.38%] [G loss: 0.310897]\n",
      "epoch:14 step:13849 [D loss: 0.236171, acc.: 61.72%] [G loss: 0.319871]\n",
      "epoch:14 step:13850 [D loss: 0.251239, acc.: 53.12%] [G loss: 0.306211]\n",
      "epoch:14 step:13851 [D loss: 0.250181, acc.: 51.56%] [G loss: 0.281673]\n",
      "epoch:14 step:13852 [D loss: 0.239391, acc.: 60.16%] [G loss: 0.284869]\n",
      "epoch:14 step:13853 [D loss: 0.249029, acc.: 60.16%] [G loss: 0.302588]\n",
      "epoch:14 step:13854 [D loss: 0.231145, acc.: 63.28%] [G loss: 0.321777]\n",
      "epoch:14 step:13855 [D loss: 0.242619, acc.: 56.25%] [G loss: 0.308637]\n",
      "epoch:14 step:13856 [D loss: 0.244816, acc.: 53.12%] [G loss: 0.313488]\n",
      "epoch:14 step:13857 [D loss: 0.241802, acc.: 57.03%] [G loss: 0.290234]\n",
      "epoch:14 step:13858 [D loss: 0.233342, acc.: 59.38%] [G loss: 0.301880]\n",
      "epoch:14 step:13859 [D loss: 0.233042, acc.: 62.50%] [G loss: 0.302306]\n",
      "epoch:14 step:13860 [D loss: 0.232305, acc.: 60.94%] [G loss: 0.291432]\n",
      "epoch:14 step:13861 [D loss: 0.244065, acc.: 55.47%] [G loss: 0.300593]\n",
      "epoch:14 step:13862 [D loss: 0.236989, acc.: 59.38%] [G loss: 0.315146]\n",
      "epoch:14 step:13863 [D loss: 0.242959, acc.: 57.03%] [G loss: 0.280610]\n",
      "epoch:14 step:13864 [D loss: 0.239037, acc.: 59.38%] [G loss: 0.313574]\n",
      "epoch:14 step:13865 [D loss: 0.248655, acc.: 57.03%] [G loss: 0.284723]\n",
      "epoch:14 step:13866 [D loss: 0.214368, acc.: 71.09%] [G loss: 0.280683]\n",
      "epoch:14 step:13867 [D loss: 0.252497, acc.: 49.22%] [G loss: 0.299677]\n",
      "epoch:14 step:13868 [D loss: 0.238038, acc.: 54.69%] [G loss: 0.278402]\n",
      "epoch:14 step:13869 [D loss: 0.236712, acc.: 59.38%] [G loss: 0.330248]\n",
      "epoch:14 step:13870 [D loss: 0.252720, acc.: 51.56%] [G loss: 0.301348]\n",
      "epoch:14 step:13871 [D loss: 0.249198, acc.: 56.25%] [G loss: 0.298932]\n",
      "epoch:14 step:13872 [D loss: 0.243459, acc.: 59.38%] [G loss: 0.305005]\n",
      "epoch:14 step:13873 [D loss: 0.244028, acc.: 57.03%] [G loss: 0.292629]\n",
      "epoch:14 step:13874 [D loss: 0.238788, acc.: 60.94%] [G loss: 0.300284]\n",
      "epoch:14 step:13875 [D loss: 0.240200, acc.: 52.34%] [G loss: 0.275361]\n",
      "epoch:14 step:13876 [D loss: 0.244822, acc.: 54.69%] [G loss: 0.298549]\n",
      "epoch:14 step:13877 [D loss: 0.240483, acc.: 59.38%] [G loss: 0.299554]\n",
      "epoch:14 step:13878 [D loss: 0.232001, acc.: 59.38%] [G loss: 0.304911]\n",
      "epoch:14 step:13879 [D loss: 0.250394, acc.: 52.34%] [G loss: 0.306580]\n",
      "epoch:14 step:13880 [D loss: 0.245050, acc.: 57.03%] [G loss: 0.296934]\n",
      "epoch:14 step:13881 [D loss: 0.228568, acc.: 63.28%] [G loss: 0.332443]\n",
      "epoch:14 step:13882 [D loss: 0.240889, acc.: 60.16%] [G loss: 0.291894]\n",
      "epoch:14 step:13883 [D loss: 0.237964, acc.: 60.16%] [G loss: 0.299659]\n",
      "epoch:14 step:13884 [D loss: 0.239400, acc.: 62.50%] [G loss: 0.292951]\n",
      "epoch:14 step:13885 [D loss: 0.236304, acc.: 59.38%] [G loss: 0.321374]\n",
      "epoch:14 step:13886 [D loss: 0.244078, acc.: 59.38%] [G loss: 0.291236]\n",
      "epoch:14 step:13887 [D loss: 0.234703, acc.: 63.28%] [G loss: 0.287242]\n",
      "epoch:14 step:13888 [D loss: 0.234614, acc.: 64.06%] [G loss: 0.306554]\n",
      "epoch:14 step:13889 [D loss: 0.251358, acc.: 57.03%] [G loss: 0.283118]\n",
      "epoch:14 step:13890 [D loss: 0.240242, acc.: 57.03%] [G loss: 0.299597]\n",
      "epoch:14 step:13891 [D loss: 0.244871, acc.: 56.25%] [G loss: 0.299142]\n",
      "epoch:14 step:13892 [D loss: 0.240955, acc.: 61.72%] [G loss: 0.304731]\n",
      "epoch:14 step:13893 [D loss: 0.228219, acc.: 64.06%] [G loss: 0.303850]\n",
      "epoch:14 step:13894 [D loss: 0.225769, acc.: 62.50%] [G loss: 0.281797]\n",
      "epoch:14 step:13895 [D loss: 0.249438, acc.: 55.47%] [G loss: 0.294943]\n",
      "epoch:14 step:13896 [D loss: 0.228497, acc.: 61.72%] [G loss: 0.294967]\n",
      "epoch:14 step:13897 [D loss: 0.232410, acc.: 60.16%] [G loss: 0.313740]\n",
      "epoch:14 step:13898 [D loss: 0.230901, acc.: 61.72%] [G loss: 0.298624]\n",
      "epoch:14 step:13899 [D loss: 0.233788, acc.: 65.62%] [G loss: 0.285977]\n",
      "epoch:14 step:13900 [D loss: 0.253661, acc.: 48.44%] [G loss: 0.286144]\n",
      "epoch:14 step:13901 [D loss: 0.227927, acc.: 62.50%] [G loss: 0.297831]\n",
      "epoch:14 step:13902 [D loss: 0.246364, acc.: 54.69%] [G loss: 0.285132]\n",
      "epoch:14 step:13903 [D loss: 0.240656, acc.: 60.16%] [G loss: 0.299014]\n",
      "epoch:14 step:13904 [D loss: 0.233804, acc.: 61.72%] [G loss: 0.301866]\n",
      "epoch:14 step:13905 [D loss: 0.232836, acc.: 60.94%] [G loss: 0.314465]\n",
      "epoch:14 step:13906 [D loss: 0.239089, acc.: 63.28%] [G loss: 0.295548]\n",
      "epoch:14 step:13907 [D loss: 0.230269, acc.: 64.06%] [G loss: 0.282555]\n",
      "epoch:14 step:13908 [D loss: 0.221433, acc.: 67.97%] [G loss: 0.308030]\n",
      "epoch:14 step:13909 [D loss: 0.240710, acc.: 56.25%] [G loss: 0.302791]\n",
      "epoch:14 step:13910 [D loss: 0.249244, acc.: 56.25%] [G loss: 0.289371]\n",
      "epoch:14 step:13911 [D loss: 0.242972, acc.: 57.81%] [G loss: 0.294069]\n",
      "epoch:14 step:13912 [D loss: 0.247070, acc.: 55.47%] [G loss: 0.312448]\n",
      "epoch:14 step:13913 [D loss: 0.230601, acc.: 62.50%] [G loss: 0.297336]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:14 step:13914 [D loss: 0.245200, acc.: 57.03%] [G loss: 0.276171]\n",
      "epoch:14 step:13915 [D loss: 0.231135, acc.: 63.28%] [G loss: 0.285405]\n",
      "epoch:14 step:13916 [D loss: 0.239896, acc.: 54.69%] [G loss: 0.306970]\n",
      "epoch:14 step:13917 [D loss: 0.243468, acc.: 52.34%] [G loss: 0.315212]\n",
      "epoch:14 step:13918 [D loss: 0.243480, acc.: 52.34%] [G loss: 0.285142]\n",
      "epoch:14 step:13919 [D loss: 0.249914, acc.: 57.81%] [G loss: 0.311016]\n",
      "epoch:14 step:13920 [D loss: 0.259287, acc.: 52.34%] [G loss: 0.286357]\n",
      "epoch:14 step:13921 [D loss: 0.251050, acc.: 46.88%] [G loss: 0.291897]\n",
      "epoch:14 step:13922 [D loss: 0.237694, acc.: 60.94%] [G loss: 0.310816]\n",
      "epoch:14 step:13923 [D loss: 0.242303, acc.: 56.25%] [G loss: 0.313026]\n",
      "epoch:14 step:13924 [D loss: 0.230680, acc.: 58.59%] [G loss: 0.286980]\n",
      "epoch:14 step:13925 [D loss: 0.238256, acc.: 58.59%] [G loss: 0.282875]\n",
      "epoch:14 step:13926 [D loss: 0.241465, acc.: 55.47%] [G loss: 0.311089]\n",
      "epoch:14 step:13927 [D loss: 0.246414, acc.: 57.03%] [G loss: 0.307613]\n",
      "epoch:14 step:13928 [D loss: 0.226288, acc.: 64.84%] [G loss: 0.315646]\n",
      "epoch:14 step:13929 [D loss: 0.239811, acc.: 61.72%] [G loss: 0.288617]\n",
      "epoch:14 step:13930 [D loss: 0.235856, acc.: 60.16%] [G loss: 0.315882]\n",
      "epoch:14 step:13931 [D loss: 0.235568, acc.: 60.94%] [G loss: 0.297232]\n",
      "epoch:14 step:13932 [D loss: 0.255257, acc.: 49.22%] [G loss: 0.310597]\n",
      "epoch:14 step:13933 [D loss: 0.248164, acc.: 52.34%] [G loss: 0.302270]\n",
      "epoch:14 step:13934 [D loss: 0.238794, acc.: 56.25%] [G loss: 0.291791]\n",
      "epoch:14 step:13935 [D loss: 0.254215, acc.: 56.25%] [G loss: 0.277173]\n",
      "epoch:14 step:13936 [D loss: 0.250593, acc.: 53.12%] [G loss: 0.289574]\n",
      "epoch:14 step:13937 [D loss: 0.227457, acc.: 65.62%] [G loss: 0.295149]\n",
      "epoch:14 step:13938 [D loss: 0.246206, acc.: 54.69%] [G loss: 0.277764]\n",
      "epoch:14 step:13939 [D loss: 0.231042, acc.: 62.50%] [G loss: 0.296158]\n",
      "epoch:14 step:13940 [D loss: 0.235412, acc.: 60.94%] [G loss: 0.290635]\n",
      "epoch:14 step:13941 [D loss: 0.258671, acc.: 51.56%] [G loss: 0.287047]\n",
      "epoch:14 step:13942 [D loss: 0.234021, acc.: 59.38%] [G loss: 0.283452]\n",
      "epoch:14 step:13943 [D loss: 0.231587, acc.: 57.81%] [G loss: 0.297378]\n",
      "epoch:14 step:13944 [D loss: 0.246542, acc.: 59.38%] [G loss: 0.307844]\n",
      "epoch:14 step:13945 [D loss: 0.234218, acc.: 64.06%] [G loss: 0.313643]\n",
      "epoch:14 step:13946 [D loss: 0.260346, acc.: 50.00%] [G loss: 0.269009]\n",
      "epoch:14 step:13947 [D loss: 0.232681, acc.: 63.28%] [G loss: 0.305273]\n",
      "epoch:14 step:13948 [D loss: 0.236979, acc.: 58.59%] [G loss: 0.275310]\n",
      "epoch:14 step:13949 [D loss: 0.245436, acc.: 59.38%] [G loss: 0.286559]\n",
      "epoch:14 step:13950 [D loss: 0.266474, acc.: 50.00%] [G loss: 0.299475]\n",
      "epoch:14 step:13951 [D loss: 0.244644, acc.: 57.03%] [G loss: 0.298592]\n",
      "epoch:14 step:13952 [D loss: 0.236745, acc.: 62.50%] [G loss: 0.280462]\n",
      "epoch:14 step:13953 [D loss: 0.237343, acc.: 58.59%] [G loss: 0.306219]\n",
      "epoch:14 step:13954 [D loss: 0.249444, acc.: 57.03%] [G loss: 0.278239]\n",
      "epoch:14 step:13955 [D loss: 0.257333, acc.: 51.56%] [G loss: 0.281097]\n",
      "epoch:14 step:13956 [D loss: 0.250464, acc.: 50.78%] [G loss: 0.303025]\n",
      "epoch:14 step:13957 [D loss: 0.246314, acc.: 56.25%] [G loss: 0.309757]\n",
      "epoch:14 step:13958 [D loss: 0.234499, acc.: 56.25%] [G loss: 0.261823]\n",
      "epoch:14 step:13959 [D loss: 0.242912, acc.: 54.69%] [G loss: 0.302241]\n",
      "epoch:14 step:13960 [D loss: 0.252872, acc.: 52.34%] [G loss: 0.334782]\n",
      "epoch:14 step:13961 [D loss: 0.239523, acc.: 57.81%] [G loss: 0.314453]\n",
      "epoch:14 step:13962 [D loss: 0.255666, acc.: 55.47%] [G loss: 0.297321]\n",
      "epoch:14 step:13963 [D loss: 0.242785, acc.: 58.59%] [G loss: 0.279473]\n",
      "epoch:14 step:13964 [D loss: 0.245629, acc.: 53.12%] [G loss: 0.285997]\n",
      "epoch:14 step:13965 [D loss: 0.235344, acc.: 60.16%] [G loss: 0.274450]\n",
      "epoch:14 step:13966 [D loss: 0.238599, acc.: 62.50%] [G loss: 0.292263]\n",
      "epoch:14 step:13967 [D loss: 0.247455, acc.: 51.56%] [G loss: 0.304684]\n",
      "epoch:14 step:13968 [D loss: 0.242691, acc.: 51.56%] [G loss: 0.301104]\n",
      "epoch:14 step:13969 [D loss: 0.246508, acc.: 54.69%] [G loss: 0.301397]\n",
      "epoch:14 step:13970 [D loss: 0.229499, acc.: 61.72%] [G loss: 0.294771]\n",
      "epoch:14 step:13971 [D loss: 0.225182, acc.: 67.19%] [G loss: 0.301159]\n",
      "epoch:14 step:13972 [D loss: 0.233994, acc.: 57.81%] [G loss: 0.317030]\n",
      "epoch:14 step:13973 [D loss: 0.250244, acc.: 55.47%] [G loss: 0.309424]\n",
      "epoch:14 step:13974 [D loss: 0.215074, acc.: 71.09%] [G loss: 0.304327]\n",
      "epoch:14 step:13975 [D loss: 0.244748, acc.: 55.47%] [G loss: 0.308380]\n",
      "epoch:14 step:13976 [D loss: 0.217529, acc.: 65.62%] [G loss: 0.297462]\n",
      "epoch:14 step:13977 [D loss: 0.249078, acc.: 54.69%] [G loss: 0.303165]\n",
      "epoch:14 step:13978 [D loss: 0.242885, acc.: 59.38%] [G loss: 0.283220]\n",
      "epoch:14 step:13979 [D loss: 0.246519, acc.: 57.81%] [G loss: 0.298266]\n",
      "epoch:14 step:13980 [D loss: 0.261507, acc.: 48.44%] [G loss: 0.264591]\n",
      "epoch:14 step:13981 [D loss: 0.226184, acc.: 64.06%] [G loss: 0.293236]\n",
      "epoch:14 step:13982 [D loss: 0.260418, acc.: 50.78%] [G loss: 0.297418]\n",
      "epoch:14 step:13983 [D loss: 0.244494, acc.: 58.59%] [G loss: 0.300728]\n",
      "epoch:14 step:13984 [D loss: 0.226620, acc.: 62.50%] [G loss: 0.301034]\n",
      "epoch:14 step:13985 [D loss: 0.245711, acc.: 56.25%] [G loss: 0.291530]\n",
      "epoch:14 step:13986 [D loss: 0.231870, acc.: 57.81%] [G loss: 0.326415]\n",
      "epoch:14 step:13987 [D loss: 0.220230, acc.: 64.84%] [G loss: 0.315132]\n",
      "epoch:14 step:13988 [D loss: 0.235708, acc.: 59.38%] [G loss: 0.287260]\n",
      "epoch:14 step:13989 [D loss: 0.224171, acc.: 60.16%] [G loss: 0.286072]\n",
      "epoch:14 step:13990 [D loss: 0.258151, acc.: 50.78%] [G loss: 0.306695]\n",
      "epoch:14 step:13991 [D loss: 0.246915, acc.: 54.69%] [G loss: 0.304674]\n",
      "epoch:14 step:13992 [D loss: 0.228328, acc.: 60.16%] [G loss: 0.270501]\n",
      "epoch:14 step:13993 [D loss: 0.235513, acc.: 59.38%] [G loss: 0.310977]\n",
      "epoch:14 step:13994 [D loss: 0.237648, acc.: 59.38%] [G loss: 0.320904]\n",
      "epoch:14 step:13995 [D loss: 0.228142, acc.: 62.50%] [G loss: 0.306411]\n",
      "epoch:14 step:13996 [D loss: 0.239821, acc.: 57.03%] [G loss: 0.312632]\n",
      "epoch:14 step:13997 [D loss: 0.232060, acc.: 60.16%] [G loss: 0.318004]\n",
      "epoch:14 step:13998 [D loss: 0.253227, acc.: 51.56%] [G loss: 0.301046]\n",
      "epoch:14 step:13999 [D loss: 0.229633, acc.: 62.50%] [G loss: 0.319832]\n",
      "epoch:14 step:14000 [D loss: 0.226606, acc.: 60.94%] [G loss: 0.289722]\n",
      "epoch:14 step:14001 [D loss: 0.236863, acc.: 57.81%] [G loss: 0.317150]\n",
      "epoch:14 step:14002 [D loss: 0.238237, acc.: 56.25%] [G loss: 0.323144]\n",
      "epoch:14 step:14003 [D loss: 0.232288, acc.: 63.28%] [G loss: 0.302757]\n",
      "epoch:14 step:14004 [D loss: 0.243648, acc.: 50.78%] [G loss: 0.298005]\n",
      "epoch:14 step:14005 [D loss: 0.244195, acc.: 57.03%] [G loss: 0.313750]\n",
      "epoch:14 step:14006 [D loss: 0.250624, acc.: 58.59%] [G loss: 0.311846]\n",
      "epoch:14 step:14007 [D loss: 0.246954, acc.: 53.12%] [G loss: 0.342278]\n",
      "epoch:14 step:14008 [D loss: 0.258241, acc.: 49.22%] [G loss: 0.307669]\n",
      "epoch:14 step:14009 [D loss: 0.241660, acc.: 60.94%] [G loss: 0.321245]\n",
      "epoch:14 step:14010 [D loss: 0.235608, acc.: 64.06%] [G loss: 0.279886]\n",
      "epoch:14 step:14011 [D loss: 0.243788, acc.: 58.59%] [G loss: 0.300118]\n",
      "epoch:14 step:14012 [D loss: 0.249704, acc.: 57.03%] [G loss: 0.303372]\n",
      "epoch:14 step:14013 [D loss: 0.227676, acc.: 64.84%] [G loss: 0.299846]\n",
      "epoch:14 step:14014 [D loss: 0.225497, acc.: 67.19%] [G loss: 0.295920]\n",
      "epoch:14 step:14015 [D loss: 0.216414, acc.: 64.84%] [G loss: 0.307524]\n",
      "epoch:14 step:14016 [D loss: 0.237663, acc.: 64.84%] [G loss: 0.269915]\n",
      "epoch:14 step:14017 [D loss: 0.248291, acc.: 51.56%] [G loss: 0.265680]\n",
      "epoch:14 step:14018 [D loss: 0.227968, acc.: 66.41%] [G loss: 0.288471]\n",
      "epoch:14 step:14019 [D loss: 0.254084, acc.: 52.34%] [G loss: 0.290209]\n",
      "epoch:14 step:14020 [D loss: 0.254453, acc.: 52.34%] [G loss: 0.298118]\n",
      "epoch:14 step:14021 [D loss: 0.227100, acc.: 57.03%] [G loss: 0.302429]\n",
      "epoch:14 step:14022 [D loss: 0.233838, acc.: 57.81%] [G loss: 0.333975]\n",
      "epoch:14 step:14023 [D loss: 0.221198, acc.: 68.75%] [G loss: 0.319307]\n",
      "epoch:14 step:14024 [D loss: 0.237337, acc.: 59.38%] [G loss: 0.301410]\n",
      "epoch:14 step:14025 [D loss: 0.239451, acc.: 56.25%] [G loss: 0.311114]\n",
      "epoch:14 step:14026 [D loss: 0.250573, acc.: 53.91%] [G loss: 0.273417]\n",
      "epoch:14 step:14027 [D loss: 0.251430, acc.: 53.12%] [G loss: 0.289676]\n",
      "epoch:14 step:14028 [D loss: 0.257095, acc.: 53.91%] [G loss: 0.281653]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:14 step:14029 [D loss: 0.255142, acc.: 48.44%] [G loss: 0.301698]\n",
      "epoch:14 step:14030 [D loss: 0.256828, acc.: 52.34%] [G loss: 0.300383]\n",
      "epoch:14 step:14031 [D loss: 0.237796, acc.: 55.47%] [G loss: 0.311284]\n",
      "epoch:14 step:14032 [D loss: 0.236550, acc.: 58.59%] [G loss: 0.301560]\n",
      "epoch:14 step:14033 [D loss: 0.257002, acc.: 52.34%] [G loss: 0.274823]\n",
      "epoch:14 step:14034 [D loss: 0.231305, acc.: 60.16%] [G loss: 0.303581]\n",
      "epoch:14 step:14035 [D loss: 0.229057, acc.: 60.94%] [G loss: 0.306435]\n",
      "epoch:14 step:14036 [D loss: 0.231831, acc.: 62.50%] [G loss: 0.314663]\n",
      "epoch:14 step:14037 [D loss: 0.249638, acc.: 53.12%] [G loss: 0.294922]\n",
      "epoch:14 step:14038 [D loss: 0.244684, acc.: 54.69%] [G loss: 0.272698]\n",
      "epoch:14 step:14039 [D loss: 0.231510, acc.: 62.50%] [G loss: 0.293957]\n",
      "epoch:14 step:14040 [D loss: 0.242588, acc.: 57.03%] [G loss: 0.306186]\n",
      "epoch:14 step:14041 [D loss: 0.231822, acc.: 57.81%] [G loss: 0.321707]\n",
      "epoch:14 step:14042 [D loss: 0.243700, acc.: 53.91%] [G loss: 0.311288]\n",
      "epoch:14 step:14043 [D loss: 0.238214, acc.: 60.94%] [G loss: 0.296205]\n",
      "epoch:14 step:14044 [D loss: 0.245666, acc.: 58.59%] [G loss: 0.312123]\n",
      "epoch:14 step:14045 [D loss: 0.243096, acc.: 55.47%] [G loss: 0.294314]\n",
      "epoch:14 step:14046 [D loss: 0.243652, acc.: 57.81%] [G loss: 0.289912]\n",
      "epoch:14 step:14047 [D loss: 0.243082, acc.: 64.06%] [G loss: 0.295043]\n",
      "epoch:14 step:14048 [D loss: 0.236332, acc.: 61.72%] [G loss: 0.302837]\n",
      "epoch:14 step:14049 [D loss: 0.240434, acc.: 60.16%] [G loss: 0.282141]\n",
      "epoch:14 step:14050 [D loss: 0.244810, acc.: 55.47%] [G loss: 0.303939]\n",
      "epoch:14 step:14051 [D loss: 0.249030, acc.: 53.12%] [G loss: 0.307396]\n",
      "epoch:14 step:14052 [D loss: 0.234190, acc.: 58.59%] [G loss: 0.313179]\n",
      "epoch:14 step:14053 [D loss: 0.230636, acc.: 60.16%] [G loss: 0.319895]\n",
      "epoch:14 step:14054 [D loss: 0.234470, acc.: 54.69%] [G loss: 0.289896]\n",
      "epoch:14 step:14055 [D loss: 0.233005, acc.: 60.16%] [G loss: 0.319352]\n",
      "epoch:15 step:14056 [D loss: 0.240571, acc.: 59.38%] [G loss: 0.308275]\n",
      "epoch:15 step:14057 [D loss: 0.221372, acc.: 64.84%] [G loss: 0.322315]\n",
      "epoch:15 step:14058 [D loss: 0.231245, acc.: 61.72%] [G loss: 0.301133]\n",
      "epoch:15 step:14059 [D loss: 0.229128, acc.: 62.50%] [G loss: 0.291719]\n",
      "epoch:15 step:14060 [D loss: 0.254259, acc.: 55.47%] [G loss: 0.295031]\n",
      "epoch:15 step:14061 [D loss: 0.257027, acc.: 51.56%] [G loss: 0.309732]\n",
      "epoch:15 step:14062 [D loss: 0.236963, acc.: 57.03%] [G loss: 0.322962]\n",
      "epoch:15 step:14063 [D loss: 0.250181, acc.: 50.78%] [G loss: 0.294974]\n",
      "epoch:15 step:14064 [D loss: 0.239764, acc.: 57.03%] [G loss: 0.314582]\n",
      "epoch:15 step:14065 [D loss: 0.237565, acc.: 59.38%] [G loss: 0.320298]\n",
      "epoch:15 step:14066 [D loss: 0.233288, acc.: 60.94%] [G loss: 0.303255]\n",
      "epoch:15 step:14067 [D loss: 0.229694, acc.: 59.38%] [G loss: 0.306248]\n",
      "epoch:15 step:14068 [D loss: 0.241499, acc.: 57.03%] [G loss: 0.309298]\n",
      "epoch:15 step:14069 [D loss: 0.232282, acc.: 61.72%] [G loss: 0.294407]\n",
      "epoch:15 step:14070 [D loss: 0.234890, acc.: 62.50%] [G loss: 0.262058]\n",
      "epoch:15 step:14071 [D loss: 0.251768, acc.: 51.56%] [G loss: 0.279428]\n",
      "epoch:15 step:14072 [D loss: 0.224167, acc.: 59.38%] [G loss: 0.301833]\n",
      "epoch:15 step:14073 [D loss: 0.236616, acc.: 60.16%] [G loss: 0.295944]\n",
      "epoch:15 step:14074 [D loss: 0.244776, acc.: 54.69%] [G loss: 0.276581]\n",
      "epoch:15 step:14075 [D loss: 0.227196, acc.: 66.41%] [G loss: 0.296014]\n",
      "epoch:15 step:14076 [D loss: 0.228484, acc.: 60.94%] [G loss: 0.290227]\n",
      "epoch:15 step:14077 [D loss: 0.236197, acc.: 55.47%] [G loss: 0.303474]\n",
      "epoch:15 step:14078 [D loss: 0.247180, acc.: 55.47%] [G loss: 0.281274]\n",
      "epoch:15 step:14079 [D loss: 0.219649, acc.: 69.53%] [G loss: 0.308563]\n",
      "epoch:15 step:14080 [D loss: 0.232830, acc.: 60.94%] [G loss: 0.293066]\n",
      "epoch:15 step:14081 [D loss: 0.253094, acc.: 50.00%] [G loss: 0.291655]\n",
      "epoch:15 step:14082 [D loss: 0.262727, acc.: 52.34%] [G loss: 0.262855]\n",
      "epoch:15 step:14083 [D loss: 0.227785, acc.: 64.06%] [G loss: 0.292148]\n",
      "epoch:15 step:14084 [D loss: 0.260704, acc.: 54.69%] [G loss: 0.314570]\n",
      "epoch:15 step:14085 [D loss: 0.238808, acc.: 59.38%] [G loss: 0.282136]\n",
      "epoch:15 step:14086 [D loss: 0.261415, acc.: 51.56%] [G loss: 0.253196]\n",
      "epoch:15 step:14087 [D loss: 0.252361, acc.: 53.91%] [G loss: 0.251823]\n",
      "epoch:15 step:14088 [D loss: 0.232565, acc.: 54.69%] [G loss: 0.344377]\n",
      "epoch:15 step:14089 [D loss: 0.232837, acc.: 60.94%] [G loss: 0.296861]\n",
      "epoch:15 step:14090 [D loss: 0.237661, acc.: 62.50%] [G loss: 0.305176]\n",
      "epoch:15 step:14091 [D loss: 0.220441, acc.: 59.38%] [G loss: 0.321081]\n",
      "epoch:15 step:14092 [D loss: 0.241904, acc.: 57.03%] [G loss: 0.317103]\n",
      "epoch:15 step:14093 [D loss: 0.254564, acc.: 49.22%] [G loss: 0.278839]\n",
      "epoch:15 step:14094 [D loss: 0.246950, acc.: 50.00%] [G loss: 0.306673]\n",
      "epoch:15 step:14095 [D loss: 0.239328, acc.: 56.25%] [G loss: 0.325168]\n",
      "epoch:15 step:14096 [D loss: 0.224273, acc.: 60.94%] [G loss: 0.268129]\n",
      "epoch:15 step:14097 [D loss: 0.241744, acc.: 57.81%] [G loss: 0.284904]\n",
      "epoch:15 step:14098 [D loss: 0.234030, acc.: 62.50%] [G loss: 0.305894]\n",
      "epoch:15 step:14099 [D loss: 0.226048, acc.: 63.28%] [G loss: 0.323628]\n",
      "epoch:15 step:14100 [D loss: 0.222391, acc.: 62.50%] [G loss: 0.303238]\n",
      "epoch:15 step:14101 [D loss: 0.251942, acc.: 53.91%] [G loss: 0.265782]\n",
      "epoch:15 step:14102 [D loss: 0.245071, acc.: 57.81%] [G loss: 0.319384]\n",
      "epoch:15 step:14103 [D loss: 0.240726, acc.: 55.47%] [G loss: 0.303925]\n",
      "epoch:15 step:14104 [D loss: 0.240791, acc.: 53.91%] [G loss: 0.296507]\n",
      "epoch:15 step:14105 [D loss: 0.230833, acc.: 61.72%] [G loss: 0.294920]\n",
      "epoch:15 step:14106 [D loss: 0.239004, acc.: 56.25%] [G loss: 0.291441]\n",
      "epoch:15 step:14107 [D loss: 0.254547, acc.: 53.12%] [G loss: 0.284340]\n",
      "epoch:15 step:14108 [D loss: 0.245354, acc.: 53.91%] [G loss: 0.297737]\n",
      "epoch:15 step:14109 [D loss: 0.247480, acc.: 53.12%] [G loss: 0.277452]\n",
      "epoch:15 step:14110 [D loss: 0.246010, acc.: 52.34%] [G loss: 0.285287]\n",
      "epoch:15 step:14111 [D loss: 0.224570, acc.: 62.50%] [G loss: 0.306842]\n",
      "epoch:15 step:14112 [D loss: 0.252591, acc.: 57.03%] [G loss: 0.290427]\n",
      "epoch:15 step:14113 [D loss: 0.250297, acc.: 57.03%] [G loss: 0.245253]\n",
      "epoch:15 step:14114 [D loss: 0.256053, acc.: 49.22%] [G loss: 0.307625]\n",
      "epoch:15 step:14115 [D loss: 0.240721, acc.: 57.03%] [G loss: 0.303103]\n",
      "epoch:15 step:14116 [D loss: 0.251279, acc.: 53.12%] [G loss: 0.277855]\n",
      "epoch:15 step:14117 [D loss: 0.256820, acc.: 50.78%] [G loss: 0.282598]\n",
      "epoch:15 step:14118 [D loss: 0.219678, acc.: 64.06%] [G loss: 0.302172]\n",
      "epoch:15 step:14119 [D loss: 0.241105, acc.: 57.81%] [G loss: 0.310014]\n",
      "epoch:15 step:14120 [D loss: 0.223981, acc.: 65.62%] [G loss: 0.312501]\n",
      "epoch:15 step:14121 [D loss: 0.247068, acc.: 54.69%] [G loss: 0.302655]\n",
      "epoch:15 step:14122 [D loss: 0.244238, acc.: 57.03%] [G loss: 0.311583]\n",
      "epoch:15 step:14123 [D loss: 0.234608, acc.: 60.16%] [G loss: 0.291358]\n",
      "epoch:15 step:14124 [D loss: 0.233225, acc.: 60.16%] [G loss: 0.303065]\n",
      "epoch:15 step:14125 [D loss: 0.221850, acc.: 63.28%] [G loss: 0.274485]\n",
      "epoch:15 step:14126 [D loss: 0.229361, acc.: 64.84%] [G loss: 0.307390]\n",
      "epoch:15 step:14127 [D loss: 0.250736, acc.: 54.69%] [G loss: 0.285666]\n",
      "epoch:15 step:14128 [D loss: 0.236370, acc.: 58.59%] [G loss: 0.294686]\n",
      "epoch:15 step:14129 [D loss: 0.217670, acc.: 64.84%] [G loss: 0.317866]\n",
      "epoch:15 step:14130 [D loss: 0.233583, acc.: 56.25%] [G loss: 0.283016]\n",
      "epoch:15 step:14131 [D loss: 0.244275, acc.: 53.12%] [G loss: 0.286633]\n",
      "epoch:15 step:14132 [D loss: 0.256476, acc.: 53.12%] [G loss: 0.291336]\n",
      "epoch:15 step:14133 [D loss: 0.238424, acc.: 55.47%] [G loss: 0.321545]\n",
      "epoch:15 step:14134 [D loss: 0.244343, acc.: 62.50%] [G loss: 0.314853]\n",
      "epoch:15 step:14135 [D loss: 0.240866, acc.: 57.03%] [G loss: 0.305800]\n",
      "epoch:15 step:14136 [D loss: 0.234972, acc.: 57.81%] [G loss: 0.277751]\n",
      "epoch:15 step:14137 [D loss: 0.227184, acc.: 67.97%] [G loss: 0.312800]\n",
      "epoch:15 step:14138 [D loss: 0.243246, acc.: 52.34%] [G loss: 0.306701]\n",
      "epoch:15 step:14139 [D loss: 0.226562, acc.: 58.59%] [G loss: 0.287172]\n",
      "epoch:15 step:14140 [D loss: 0.243446, acc.: 55.47%] [G loss: 0.307668]\n",
      "epoch:15 step:14141 [D loss: 0.249269, acc.: 51.56%] [G loss: 0.309386]\n",
      "epoch:15 step:14142 [D loss: 0.250305, acc.: 53.12%] [G loss: 0.317379]\n",
      "epoch:15 step:14143 [D loss: 0.235206, acc.: 57.81%] [G loss: 0.314675]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:15 step:14144 [D loss: 0.253285, acc.: 50.00%] [G loss: 0.309280]\n",
      "epoch:15 step:14145 [D loss: 0.240417, acc.: 57.03%] [G loss: 0.298332]\n",
      "epoch:15 step:14146 [D loss: 0.235766, acc.: 60.16%] [G loss: 0.294321]\n",
      "epoch:15 step:14147 [D loss: 0.238752, acc.: 56.25%] [G loss: 0.295069]\n",
      "epoch:15 step:14148 [D loss: 0.225560, acc.: 64.06%] [G loss: 0.300527]\n",
      "epoch:15 step:14149 [D loss: 0.241039, acc.: 53.91%] [G loss: 0.310151]\n",
      "epoch:15 step:14150 [D loss: 0.237402, acc.: 60.94%] [G loss: 0.288249]\n",
      "epoch:15 step:14151 [D loss: 0.250855, acc.: 52.34%] [G loss: 0.304901]\n",
      "epoch:15 step:14152 [D loss: 0.253329, acc.: 52.34%] [G loss: 0.313262]\n",
      "epoch:15 step:14153 [D loss: 0.216513, acc.: 65.62%] [G loss: 0.333842]\n",
      "epoch:15 step:14154 [D loss: 0.239582, acc.: 59.38%] [G loss: 0.303215]\n",
      "epoch:15 step:14155 [D loss: 0.228080, acc.: 58.59%] [G loss: 0.321553]\n",
      "epoch:15 step:14156 [D loss: 0.239110, acc.: 60.94%] [G loss: 0.302549]\n",
      "epoch:15 step:14157 [D loss: 0.255503, acc.: 53.91%] [G loss: 0.316144]\n",
      "epoch:15 step:14158 [D loss: 0.229951, acc.: 61.72%] [G loss: 0.300824]\n",
      "epoch:15 step:14159 [D loss: 0.239114, acc.: 60.94%] [G loss: 0.303746]\n",
      "epoch:15 step:14160 [D loss: 0.242598, acc.: 57.03%] [G loss: 0.292760]\n",
      "epoch:15 step:14161 [D loss: 0.245649, acc.: 52.34%] [G loss: 0.294222]\n",
      "epoch:15 step:14162 [D loss: 0.242366, acc.: 60.16%] [G loss: 0.288742]\n",
      "epoch:15 step:14163 [D loss: 0.233112, acc.: 57.81%] [G loss: 0.304040]\n",
      "epoch:15 step:14164 [D loss: 0.235850, acc.: 58.59%] [G loss: 0.308343]\n",
      "epoch:15 step:14165 [D loss: 0.256250, acc.: 52.34%] [G loss: 0.298065]\n",
      "epoch:15 step:14166 [D loss: 0.240504, acc.: 63.28%] [G loss: 0.290572]\n",
      "epoch:15 step:14167 [D loss: 0.239540, acc.: 60.94%] [G loss: 0.281472]\n",
      "epoch:15 step:14168 [D loss: 0.252246, acc.: 55.47%] [G loss: 0.288469]\n",
      "epoch:15 step:14169 [D loss: 0.245853, acc.: 56.25%] [G loss: 0.333264]\n",
      "epoch:15 step:14170 [D loss: 0.240306, acc.: 55.47%] [G loss: 0.291532]\n",
      "epoch:15 step:14171 [D loss: 0.224142, acc.: 61.72%] [G loss: 0.295853]\n",
      "epoch:15 step:14172 [D loss: 0.238112, acc.: 53.91%] [G loss: 0.280581]\n",
      "epoch:15 step:14173 [D loss: 0.248204, acc.: 55.47%] [G loss: 0.297410]\n",
      "epoch:15 step:14174 [D loss: 0.245249, acc.: 54.69%] [G loss: 0.312293]\n",
      "epoch:15 step:14175 [D loss: 0.253541, acc.: 53.91%] [G loss: 0.295946]\n",
      "epoch:15 step:14176 [D loss: 0.245142, acc.: 57.03%] [G loss: 0.291225]\n",
      "epoch:15 step:14177 [D loss: 0.239143, acc.: 53.12%] [G loss: 0.292688]\n",
      "epoch:15 step:14178 [D loss: 0.243113, acc.: 53.12%] [G loss: 0.274518]\n",
      "epoch:15 step:14179 [D loss: 0.245080, acc.: 52.34%] [G loss: 0.292051]\n",
      "epoch:15 step:14180 [D loss: 0.241161, acc.: 55.47%] [G loss: 0.320104]\n",
      "epoch:15 step:14181 [D loss: 0.228575, acc.: 62.50%] [G loss: 0.304781]\n",
      "epoch:15 step:14182 [D loss: 0.226704, acc.: 64.84%] [G loss: 0.295578]\n",
      "epoch:15 step:14183 [D loss: 0.244501, acc.: 54.69%] [G loss: 0.277251]\n",
      "epoch:15 step:14184 [D loss: 0.225368, acc.: 61.72%] [G loss: 0.312948]\n",
      "epoch:15 step:14185 [D loss: 0.235420, acc.: 62.50%] [G loss: 0.304967]\n",
      "epoch:15 step:14186 [D loss: 0.236319, acc.: 63.28%] [G loss: 0.305219]\n",
      "epoch:15 step:14187 [D loss: 0.236143, acc.: 59.38%] [G loss: 0.316454]\n",
      "epoch:15 step:14188 [D loss: 0.238212, acc.: 59.38%] [G loss: 0.287664]\n",
      "epoch:15 step:14189 [D loss: 0.235078, acc.: 61.72%] [G loss: 0.293770]\n",
      "epoch:15 step:14190 [D loss: 0.232368, acc.: 57.81%] [G loss: 0.278561]\n",
      "epoch:15 step:14191 [D loss: 0.241999, acc.: 57.03%] [G loss: 0.319945]\n",
      "epoch:15 step:14192 [D loss: 0.218545, acc.: 67.19%] [G loss: 0.338100]\n",
      "epoch:15 step:14193 [D loss: 0.232695, acc.: 60.94%] [G loss: 0.299809]\n",
      "epoch:15 step:14194 [D loss: 0.255456, acc.: 52.34%] [G loss: 0.301121]\n",
      "epoch:15 step:14195 [D loss: 0.235737, acc.: 61.72%] [G loss: 0.282882]\n",
      "epoch:15 step:14196 [D loss: 0.260086, acc.: 46.88%] [G loss: 0.296750]\n",
      "epoch:15 step:14197 [D loss: 0.221492, acc.: 65.62%] [G loss: 0.284632]\n",
      "epoch:15 step:14198 [D loss: 0.241120, acc.: 58.59%] [G loss: 0.280775]\n",
      "epoch:15 step:14199 [D loss: 0.247567, acc.: 57.81%] [G loss: 0.302385]\n",
      "epoch:15 step:14200 [D loss: 0.230442, acc.: 64.06%] [G loss: 0.308765]\n",
      "epoch:15 step:14201 [D loss: 0.233638, acc.: 63.28%] [G loss: 0.309574]\n",
      "epoch:15 step:14202 [D loss: 0.238161, acc.: 65.62%] [G loss: 0.320188]\n",
      "epoch:15 step:14203 [D loss: 0.226524, acc.: 64.84%] [G loss: 0.312074]\n",
      "epoch:15 step:14204 [D loss: 0.247448, acc.: 50.78%] [G loss: 0.287793]\n",
      "epoch:15 step:14205 [D loss: 0.229466, acc.: 62.50%] [G loss: 0.305516]\n",
      "epoch:15 step:14206 [D loss: 0.234239, acc.: 57.03%] [G loss: 0.305477]\n",
      "epoch:15 step:14207 [D loss: 0.239364, acc.: 62.50%] [G loss: 0.314897]\n",
      "epoch:15 step:14208 [D loss: 0.251366, acc.: 56.25%] [G loss: 0.295440]\n",
      "epoch:15 step:14209 [D loss: 0.269969, acc.: 42.19%] [G loss: 0.283046]\n",
      "epoch:15 step:14210 [D loss: 0.236459, acc.: 60.94%] [G loss: 0.300636]\n",
      "epoch:15 step:14211 [D loss: 0.239536, acc.: 58.59%] [G loss: 0.269770]\n",
      "epoch:15 step:14212 [D loss: 0.235929, acc.: 60.16%] [G loss: 0.298904]\n",
      "epoch:15 step:14213 [D loss: 0.227924, acc.: 61.72%] [G loss: 0.301461]\n",
      "epoch:15 step:14214 [D loss: 0.244970, acc.: 53.91%] [G loss: 0.310574]\n",
      "epoch:15 step:14215 [D loss: 0.260631, acc.: 51.56%] [G loss: 0.284835]\n",
      "epoch:15 step:14216 [D loss: 0.231673, acc.: 60.16%] [G loss: 0.293612]\n",
      "epoch:15 step:14217 [D loss: 0.245369, acc.: 53.91%] [G loss: 0.294300]\n",
      "epoch:15 step:14218 [D loss: 0.239972, acc.: 60.16%] [G loss: 0.304066]\n",
      "epoch:15 step:14219 [D loss: 0.236883, acc.: 64.06%] [G loss: 0.299902]\n",
      "epoch:15 step:14220 [D loss: 0.240222, acc.: 53.91%] [G loss: 0.320160]\n",
      "epoch:15 step:14221 [D loss: 0.244365, acc.: 57.03%] [G loss: 0.300898]\n",
      "epoch:15 step:14222 [D loss: 0.239063, acc.: 54.69%] [G loss: 0.296807]\n",
      "epoch:15 step:14223 [D loss: 0.263662, acc.: 46.09%] [G loss: 0.281094]\n",
      "epoch:15 step:14224 [D loss: 0.233862, acc.: 64.84%] [G loss: 0.299988]\n",
      "epoch:15 step:14225 [D loss: 0.255741, acc.: 50.00%] [G loss: 0.268956]\n",
      "epoch:15 step:14226 [D loss: 0.214410, acc.: 67.19%] [G loss: 0.307972]\n",
      "epoch:15 step:14227 [D loss: 0.231636, acc.: 62.50%] [G loss: 0.294350]\n",
      "epoch:15 step:14228 [D loss: 0.242281, acc.: 53.91%] [G loss: 0.293758]\n",
      "epoch:15 step:14229 [D loss: 0.239857, acc.: 53.12%] [G loss: 0.300097]\n",
      "epoch:15 step:14230 [D loss: 0.262176, acc.: 50.78%] [G loss: 0.301909]\n",
      "epoch:15 step:14231 [D loss: 0.238261, acc.: 59.38%] [G loss: 0.288704]\n",
      "epoch:15 step:14232 [D loss: 0.225275, acc.: 60.16%] [G loss: 0.291110]\n",
      "epoch:15 step:14233 [D loss: 0.236232, acc.: 55.47%] [G loss: 0.298242]\n",
      "epoch:15 step:14234 [D loss: 0.244134, acc.: 59.38%] [G loss: 0.311890]\n",
      "epoch:15 step:14235 [D loss: 0.240199, acc.: 54.69%] [G loss: 0.302156]\n",
      "epoch:15 step:14236 [D loss: 0.241186, acc.: 55.47%] [G loss: 0.326238]\n",
      "epoch:15 step:14237 [D loss: 0.229819, acc.: 64.84%] [G loss: 0.326884]\n",
      "epoch:15 step:14238 [D loss: 0.240883, acc.: 63.28%] [G loss: 0.313098]\n",
      "epoch:15 step:14239 [D loss: 0.242255, acc.: 60.16%] [G loss: 0.312229]\n",
      "epoch:15 step:14240 [D loss: 0.256054, acc.: 52.34%] [G loss: 0.316277]\n",
      "epoch:15 step:14241 [D loss: 0.220947, acc.: 66.41%] [G loss: 0.291965]\n",
      "epoch:15 step:14242 [D loss: 0.231517, acc.: 57.03%] [G loss: 0.294836]\n",
      "epoch:15 step:14243 [D loss: 0.253051, acc.: 53.12%] [G loss: 0.312206]\n",
      "epoch:15 step:14244 [D loss: 0.240737, acc.: 57.81%] [G loss: 0.311341]\n",
      "epoch:15 step:14245 [D loss: 0.253079, acc.: 53.12%] [G loss: 0.318511]\n",
      "epoch:15 step:14246 [D loss: 0.239172, acc.: 53.91%] [G loss: 0.311036]\n",
      "epoch:15 step:14247 [D loss: 0.241091, acc.: 59.38%] [G loss: 0.299967]\n",
      "epoch:15 step:14248 [D loss: 0.226535, acc.: 60.94%] [G loss: 0.290828]\n",
      "epoch:15 step:14249 [D loss: 0.242913, acc.: 54.69%] [G loss: 0.288910]\n",
      "epoch:15 step:14250 [D loss: 0.238226, acc.: 55.47%] [G loss: 0.298406]\n",
      "epoch:15 step:14251 [D loss: 0.236121, acc.: 57.03%] [G loss: 0.327152]\n",
      "epoch:15 step:14252 [D loss: 0.252669, acc.: 49.22%] [G loss: 0.306699]\n",
      "epoch:15 step:14253 [D loss: 0.249154, acc.: 57.03%] [G loss: 0.302508]\n",
      "epoch:15 step:14254 [D loss: 0.221897, acc.: 66.41%] [G loss: 0.289908]\n",
      "epoch:15 step:14255 [D loss: 0.242742, acc.: 57.03%] [G loss: 0.303852]\n",
      "epoch:15 step:14256 [D loss: 0.216164, acc.: 67.19%] [G loss: 0.309597]\n",
      "epoch:15 step:14257 [D loss: 0.227735, acc.: 61.72%] [G loss: 0.323826]\n",
      "epoch:15 step:14258 [D loss: 0.252776, acc.: 55.47%] [G loss: 0.309345]\n",
      "epoch:15 step:14259 [D loss: 0.236345, acc.: 61.72%] [G loss: 0.322131]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:15 step:14260 [D loss: 0.240303, acc.: 57.03%] [G loss: 0.292499]\n",
      "epoch:15 step:14261 [D loss: 0.238639, acc.: 54.69%] [G loss: 0.324856]\n",
      "epoch:15 step:14262 [D loss: 0.240918, acc.: 57.03%] [G loss: 0.302022]\n",
      "epoch:15 step:14263 [D loss: 0.231009, acc.: 64.84%] [G loss: 0.328325]\n",
      "epoch:15 step:14264 [D loss: 0.238622, acc.: 56.25%] [G loss: 0.306683]\n",
      "epoch:15 step:14265 [D loss: 0.237213, acc.: 63.28%] [G loss: 0.301857]\n",
      "epoch:15 step:14266 [D loss: 0.240430, acc.: 55.47%] [G loss: 0.304518]\n",
      "epoch:15 step:14267 [D loss: 0.234818, acc.: 64.06%] [G loss: 0.312722]\n",
      "epoch:15 step:14268 [D loss: 0.246071, acc.: 56.25%] [G loss: 0.300385]\n",
      "epoch:15 step:14269 [D loss: 0.252397, acc.: 55.47%] [G loss: 0.278778]\n",
      "epoch:15 step:14270 [D loss: 0.231044, acc.: 61.72%] [G loss: 0.309756]\n",
      "epoch:15 step:14271 [D loss: 0.240744, acc.: 60.94%] [G loss: 0.298434]\n",
      "epoch:15 step:14272 [D loss: 0.226985, acc.: 60.94%] [G loss: 0.297188]\n",
      "epoch:15 step:14273 [D loss: 0.233578, acc.: 59.38%] [G loss: 0.300109]\n",
      "epoch:15 step:14274 [D loss: 0.261462, acc.: 51.56%] [G loss: 0.303571]\n",
      "epoch:15 step:14275 [D loss: 0.242851, acc.: 57.81%] [G loss: 0.293411]\n",
      "epoch:15 step:14276 [D loss: 0.249814, acc.: 57.81%] [G loss: 0.282253]\n",
      "epoch:15 step:14277 [D loss: 0.260716, acc.: 51.56%] [G loss: 0.300927]\n",
      "epoch:15 step:14278 [D loss: 0.246965, acc.: 60.16%] [G loss: 0.293318]\n",
      "epoch:15 step:14279 [D loss: 0.243409, acc.: 58.59%] [G loss: 0.269527]\n",
      "epoch:15 step:14280 [D loss: 0.248707, acc.: 55.47%] [G loss: 0.283053]\n",
      "epoch:15 step:14281 [D loss: 0.243521, acc.: 53.91%] [G loss: 0.303845]\n",
      "epoch:15 step:14282 [D loss: 0.249755, acc.: 54.69%] [G loss: 0.296087]\n",
      "epoch:15 step:14283 [D loss: 0.232389, acc.: 60.16%] [G loss: 0.285014]\n",
      "epoch:15 step:14284 [D loss: 0.252691, acc.: 52.34%] [G loss: 0.313112]\n",
      "epoch:15 step:14285 [D loss: 0.239290, acc.: 57.03%] [G loss: 0.312831]\n",
      "epoch:15 step:14286 [D loss: 0.230357, acc.: 63.28%] [G loss: 0.298616]\n",
      "epoch:15 step:14287 [D loss: 0.242512, acc.: 56.25%] [G loss: 0.295514]\n",
      "epoch:15 step:14288 [D loss: 0.232042, acc.: 61.72%] [G loss: 0.318918]\n",
      "epoch:15 step:14289 [D loss: 0.247714, acc.: 55.47%] [G loss: 0.286776]\n",
      "epoch:15 step:14290 [D loss: 0.243600, acc.: 53.12%] [G loss: 0.285825]\n",
      "epoch:15 step:14291 [D loss: 0.249963, acc.: 54.69%] [G loss: 0.293594]\n",
      "epoch:15 step:14292 [D loss: 0.250780, acc.: 52.34%] [G loss: 0.310024]\n",
      "epoch:15 step:14293 [D loss: 0.249967, acc.: 54.69%] [G loss: 0.306014]\n",
      "epoch:15 step:14294 [D loss: 0.249077, acc.: 57.81%] [G loss: 0.296890]\n",
      "epoch:15 step:14295 [D loss: 0.234634, acc.: 57.03%] [G loss: 0.301248]\n",
      "epoch:15 step:14296 [D loss: 0.247916, acc.: 55.47%] [G loss: 0.294034]\n",
      "epoch:15 step:14297 [D loss: 0.231597, acc.: 61.72%] [G loss: 0.309661]\n",
      "epoch:15 step:14298 [D loss: 0.235720, acc.: 55.47%] [G loss: 0.293867]\n",
      "epoch:15 step:14299 [D loss: 0.243965, acc.: 56.25%] [G loss: 0.290391]\n",
      "epoch:15 step:14300 [D loss: 0.238320, acc.: 52.34%] [G loss: 0.312976]\n",
      "epoch:15 step:14301 [D loss: 0.231174, acc.: 66.41%] [G loss: 0.310758]\n",
      "epoch:15 step:14302 [D loss: 0.233872, acc.: 60.94%] [G loss: 0.294957]\n",
      "epoch:15 step:14303 [D loss: 0.245088, acc.: 57.81%] [G loss: 0.299314]\n",
      "epoch:15 step:14304 [D loss: 0.234213, acc.: 60.16%] [G loss: 0.279669]\n",
      "epoch:15 step:14305 [D loss: 0.241077, acc.: 56.25%] [G loss: 0.273842]\n",
      "epoch:15 step:14306 [D loss: 0.242834, acc.: 58.59%] [G loss: 0.294846]\n",
      "epoch:15 step:14307 [D loss: 0.233462, acc.: 59.38%] [G loss: 0.304335]\n",
      "epoch:15 step:14308 [D loss: 0.228403, acc.: 61.72%] [G loss: 0.285816]\n",
      "epoch:15 step:14309 [D loss: 0.251829, acc.: 47.66%] [G loss: 0.317680]\n",
      "epoch:15 step:14310 [D loss: 0.230632, acc.: 59.38%] [G loss: 0.266966]\n",
      "epoch:15 step:14311 [D loss: 0.235452, acc.: 62.50%] [G loss: 0.292396]\n",
      "epoch:15 step:14312 [D loss: 0.221643, acc.: 66.41%] [G loss: 0.297181]\n",
      "epoch:15 step:14313 [D loss: 0.248144, acc.: 51.56%] [G loss: 0.303381]\n",
      "epoch:15 step:14314 [D loss: 0.228448, acc.: 60.16%] [G loss: 0.315713]\n",
      "epoch:15 step:14315 [D loss: 0.244356, acc.: 53.12%] [G loss: 0.310568]\n",
      "epoch:15 step:14316 [D loss: 0.243258, acc.: 56.25%] [G loss: 0.286147]\n",
      "epoch:15 step:14317 [D loss: 0.251275, acc.: 58.59%] [G loss: 0.282029]\n",
      "epoch:15 step:14318 [D loss: 0.242642, acc.: 56.25%] [G loss: 0.281996]\n",
      "epoch:15 step:14319 [D loss: 0.242636, acc.: 62.50%] [G loss: 0.307186]\n",
      "epoch:15 step:14320 [D loss: 0.240789, acc.: 56.25%] [G loss: 0.297473]\n",
      "epoch:15 step:14321 [D loss: 0.247826, acc.: 57.03%] [G loss: 0.318064]\n",
      "epoch:15 step:14322 [D loss: 0.229849, acc.: 65.62%] [G loss: 0.303717]\n",
      "epoch:15 step:14323 [D loss: 0.233034, acc.: 57.81%] [G loss: 0.303156]\n",
      "epoch:15 step:14324 [D loss: 0.243707, acc.: 53.12%] [G loss: 0.329667]\n",
      "epoch:15 step:14325 [D loss: 0.228606, acc.: 64.84%] [G loss: 0.299173]\n",
      "epoch:15 step:14326 [D loss: 0.257549, acc.: 45.31%] [G loss: 0.303117]\n",
      "epoch:15 step:14327 [D loss: 0.238106, acc.: 61.72%] [G loss: 0.304994]\n",
      "epoch:15 step:14328 [D loss: 0.247694, acc.: 54.69%] [G loss: 0.316136]\n",
      "epoch:15 step:14329 [D loss: 0.248618, acc.: 45.31%] [G loss: 0.291350]\n",
      "epoch:15 step:14330 [D loss: 0.261617, acc.: 50.00%] [G loss: 0.310982]\n",
      "epoch:15 step:14331 [D loss: 0.227109, acc.: 64.84%] [G loss: 0.312520]\n",
      "epoch:15 step:14332 [D loss: 0.240162, acc.: 56.25%] [G loss: 0.317271]\n",
      "epoch:15 step:14333 [D loss: 0.244052, acc.: 60.16%] [G loss: 0.310206]\n",
      "epoch:15 step:14334 [D loss: 0.237087, acc.: 55.47%] [G loss: 0.306287]\n",
      "epoch:15 step:14335 [D loss: 0.251974, acc.: 52.34%] [G loss: 0.308694]\n",
      "epoch:15 step:14336 [D loss: 0.230552, acc.: 63.28%] [G loss: 0.290708]\n",
      "epoch:15 step:14337 [D loss: 0.232667, acc.: 59.38%] [G loss: 0.335100]\n",
      "epoch:15 step:14338 [D loss: 0.239828, acc.: 56.25%] [G loss: 0.322892]\n",
      "epoch:15 step:14339 [D loss: 0.229483, acc.: 63.28%] [G loss: 0.318497]\n",
      "epoch:15 step:14340 [D loss: 0.239581, acc.: 60.16%] [G loss: 0.295619]\n",
      "epoch:15 step:14341 [D loss: 0.242787, acc.: 53.91%] [G loss: 0.324024]\n",
      "epoch:15 step:14342 [D loss: 0.248654, acc.: 53.91%] [G loss: 0.279934]\n",
      "epoch:15 step:14343 [D loss: 0.244340, acc.: 53.12%] [G loss: 0.300100]\n",
      "epoch:15 step:14344 [D loss: 0.252481, acc.: 51.56%] [G loss: 0.313244]\n",
      "epoch:15 step:14345 [D loss: 0.241887, acc.: 56.25%] [G loss: 0.333599]\n",
      "epoch:15 step:14346 [D loss: 0.226821, acc.: 60.16%] [G loss: 0.308877]\n",
      "epoch:15 step:14347 [D loss: 0.235837, acc.: 58.59%] [G loss: 0.295638]\n",
      "epoch:15 step:14348 [D loss: 0.241893, acc.: 53.91%] [G loss: 0.312468]\n",
      "epoch:15 step:14349 [D loss: 0.254223, acc.: 50.00%] [G loss: 0.291026]\n",
      "epoch:15 step:14350 [D loss: 0.248479, acc.: 58.59%] [G loss: 0.267920]\n",
      "epoch:15 step:14351 [D loss: 0.221789, acc.: 67.19%] [G loss: 0.306481]\n",
      "epoch:15 step:14352 [D loss: 0.230052, acc.: 62.50%] [G loss: 0.294914]\n",
      "epoch:15 step:14353 [D loss: 0.227645, acc.: 63.28%] [G loss: 0.323667]\n",
      "epoch:15 step:14354 [D loss: 0.245414, acc.: 53.91%] [G loss: 0.302222]\n",
      "epoch:15 step:14355 [D loss: 0.252478, acc.: 55.47%] [G loss: 0.281143]\n",
      "epoch:15 step:14356 [D loss: 0.247858, acc.: 56.25%] [G loss: 0.299937]\n",
      "epoch:15 step:14357 [D loss: 0.239976, acc.: 59.38%] [G loss: 0.283919]\n",
      "epoch:15 step:14358 [D loss: 0.257607, acc.: 52.34%] [G loss: 0.317608]\n",
      "epoch:15 step:14359 [D loss: 0.245565, acc.: 60.94%] [G loss: 0.304987]\n",
      "epoch:15 step:14360 [D loss: 0.250341, acc.: 57.81%] [G loss: 0.301121]\n",
      "epoch:15 step:14361 [D loss: 0.222133, acc.: 67.97%] [G loss: 0.284608]\n",
      "epoch:15 step:14362 [D loss: 0.248707, acc.: 52.34%] [G loss: 0.302914]\n",
      "epoch:15 step:14363 [D loss: 0.232367, acc.: 58.59%] [G loss: 0.278106]\n",
      "epoch:15 step:14364 [D loss: 0.226363, acc.: 63.28%] [G loss: 0.314762]\n",
      "epoch:15 step:14365 [D loss: 0.258784, acc.: 52.34%] [G loss: 0.317618]\n",
      "epoch:15 step:14366 [D loss: 0.227147, acc.: 64.06%] [G loss: 0.328877]\n",
      "epoch:15 step:14367 [D loss: 0.249976, acc.: 59.38%] [G loss: 0.305240]\n",
      "epoch:15 step:14368 [D loss: 0.235383, acc.: 57.03%] [G loss: 0.310895]\n",
      "epoch:15 step:14369 [D loss: 0.241218, acc.: 57.03%] [G loss: 0.287671]\n",
      "epoch:15 step:14370 [D loss: 0.246933, acc.: 57.81%] [G loss: 0.272937]\n",
      "epoch:15 step:14371 [D loss: 0.240059, acc.: 58.59%] [G loss: 0.312283]\n",
      "epoch:15 step:14372 [D loss: 0.240826, acc.: 57.81%] [G loss: 0.324666]\n",
      "epoch:15 step:14373 [D loss: 0.239299, acc.: 61.72%] [G loss: 0.298376]\n",
      "epoch:15 step:14374 [D loss: 0.247773, acc.: 57.03%] [G loss: 0.295812]\n",
      "epoch:15 step:14375 [D loss: 0.250727, acc.: 52.34%] [G loss: 0.300865]\n",
      "epoch:15 step:14376 [D loss: 0.229070, acc.: 61.72%] [G loss: 0.304991]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:15 step:14377 [D loss: 0.244181, acc.: 54.69%] [G loss: 0.319536]\n",
      "epoch:15 step:14378 [D loss: 0.246476, acc.: 53.12%] [G loss: 0.304597]\n",
      "epoch:15 step:14379 [D loss: 0.247584, acc.: 49.22%] [G loss: 0.267621]\n",
      "epoch:15 step:14380 [D loss: 0.223058, acc.: 65.62%] [G loss: 0.316408]\n",
      "epoch:15 step:14381 [D loss: 0.233660, acc.: 65.62%] [G loss: 0.285293]\n",
      "epoch:15 step:14382 [D loss: 0.247732, acc.: 62.50%] [G loss: 0.308805]\n",
      "epoch:15 step:14383 [D loss: 0.235697, acc.: 60.16%] [G loss: 0.288887]\n",
      "epoch:15 step:14384 [D loss: 0.254740, acc.: 52.34%] [G loss: 0.290352]\n",
      "epoch:15 step:14385 [D loss: 0.238571, acc.: 59.38%] [G loss: 0.269966]\n",
      "epoch:15 step:14386 [D loss: 0.214875, acc.: 67.19%] [G loss: 0.325808]\n",
      "epoch:15 step:14387 [D loss: 0.250613, acc.: 57.03%] [G loss: 0.302969]\n",
      "epoch:15 step:14388 [D loss: 0.244941, acc.: 55.47%] [G loss: 0.289286]\n",
      "epoch:15 step:14389 [D loss: 0.235858, acc.: 60.16%] [G loss: 0.291238]\n",
      "epoch:15 step:14390 [D loss: 0.237701, acc.: 57.81%] [G loss: 0.293178]\n",
      "epoch:15 step:14391 [D loss: 0.229528, acc.: 61.72%] [G loss: 0.293779]\n",
      "epoch:15 step:14392 [D loss: 0.242309, acc.: 57.81%] [G loss: 0.305848]\n",
      "epoch:15 step:14393 [D loss: 0.233652, acc.: 59.38%] [G loss: 0.282286]\n",
      "epoch:15 step:14394 [D loss: 0.238124, acc.: 64.06%] [G loss: 0.297793]\n",
      "epoch:15 step:14395 [D loss: 0.228790, acc.: 61.72%] [G loss: 0.322787]\n",
      "epoch:15 step:14396 [D loss: 0.252156, acc.: 52.34%] [G loss: 0.290968]\n",
      "epoch:15 step:14397 [D loss: 0.251547, acc.: 54.69%] [G loss: 0.295139]\n",
      "epoch:15 step:14398 [D loss: 0.231876, acc.: 60.94%] [G loss: 0.304127]\n",
      "epoch:15 step:14399 [D loss: 0.240281, acc.: 60.94%] [G loss: 0.319661]\n",
      "epoch:15 step:14400 [D loss: 0.234390, acc.: 58.59%] [G loss: 0.310599]\n",
      "epoch:15 step:14401 [D loss: 0.235449, acc.: 59.38%] [G loss: 0.290871]\n",
      "epoch:15 step:14402 [D loss: 0.246581, acc.: 52.34%] [G loss: 0.287256]\n",
      "epoch:15 step:14403 [D loss: 0.243658, acc.: 55.47%] [G loss: 0.288162]\n",
      "epoch:15 step:14404 [D loss: 0.229643, acc.: 62.50%] [G loss: 0.310697]\n",
      "epoch:15 step:14405 [D loss: 0.254200, acc.: 54.69%] [G loss: 0.293058]\n",
      "epoch:15 step:14406 [D loss: 0.248652, acc.: 52.34%] [G loss: 0.279781]\n",
      "epoch:15 step:14407 [D loss: 0.259979, acc.: 48.44%] [G loss: 0.284973]\n",
      "epoch:15 step:14408 [D loss: 0.257302, acc.: 55.47%] [G loss: 0.255199]\n",
      "epoch:15 step:14409 [D loss: 0.246107, acc.: 55.47%] [G loss: 0.313019]\n",
      "epoch:15 step:14410 [D loss: 0.237668, acc.: 57.81%] [G loss: 0.269191]\n",
      "epoch:15 step:14411 [D loss: 0.238504, acc.: 60.16%] [G loss: 0.314335]\n",
      "epoch:15 step:14412 [D loss: 0.236747, acc.: 57.81%] [G loss: 0.298120]\n",
      "epoch:15 step:14413 [D loss: 0.235031, acc.: 60.16%] [G loss: 0.306812]\n",
      "epoch:15 step:14414 [D loss: 0.233463, acc.: 56.25%] [G loss: 0.282173]\n",
      "epoch:15 step:14415 [D loss: 0.240126, acc.: 57.81%] [G loss: 0.301889]\n",
      "epoch:15 step:14416 [D loss: 0.238567, acc.: 58.59%] [G loss: 0.320736]\n",
      "epoch:15 step:14417 [D loss: 0.238140, acc.: 53.91%] [G loss: 0.300716]\n",
      "epoch:15 step:14418 [D loss: 0.245386, acc.: 57.81%] [G loss: 0.311561]\n",
      "epoch:15 step:14419 [D loss: 0.244951, acc.: 55.47%] [G loss: 0.308255]\n",
      "epoch:15 step:14420 [D loss: 0.238581, acc.: 63.28%] [G loss: 0.315274]\n",
      "epoch:15 step:14421 [D loss: 0.224634, acc.: 64.84%] [G loss: 0.296985]\n",
      "epoch:15 step:14422 [D loss: 0.248819, acc.: 53.12%] [G loss: 0.306526]\n",
      "epoch:15 step:14423 [D loss: 0.236944, acc.: 55.47%] [G loss: 0.308324]\n",
      "epoch:15 step:14424 [D loss: 0.237434, acc.: 57.03%] [G loss: 0.318608]\n",
      "epoch:15 step:14425 [D loss: 0.233460, acc.: 58.59%] [G loss: 0.299012]\n",
      "epoch:15 step:14426 [D loss: 0.235105, acc.: 57.03%] [G loss: 0.340101]\n",
      "epoch:15 step:14427 [D loss: 0.227939, acc.: 60.94%] [G loss: 0.297188]\n",
      "epoch:15 step:14428 [D loss: 0.230630, acc.: 60.94%] [G loss: 0.313375]\n",
      "epoch:15 step:14429 [D loss: 0.238926, acc.: 57.81%] [G loss: 0.312308]\n",
      "epoch:15 step:14430 [D loss: 0.235230, acc.: 58.59%] [G loss: 0.286192]\n",
      "epoch:15 step:14431 [D loss: 0.247377, acc.: 53.12%] [G loss: 0.287448]\n",
      "epoch:15 step:14432 [D loss: 0.232017, acc.: 62.50%] [G loss: 0.329623]\n",
      "epoch:15 step:14433 [D loss: 0.227311, acc.: 64.06%] [G loss: 0.316039]\n",
      "epoch:15 step:14434 [D loss: 0.246912, acc.: 57.81%] [G loss: 0.299036]\n",
      "epoch:15 step:14435 [D loss: 0.239044, acc.: 57.03%] [G loss: 0.274842]\n",
      "epoch:15 step:14436 [D loss: 0.255188, acc.: 54.69%] [G loss: 0.344501]\n",
      "epoch:15 step:14437 [D loss: 0.242119, acc.: 53.91%] [G loss: 0.288444]\n",
      "epoch:15 step:14438 [D loss: 0.230206, acc.: 64.06%] [G loss: 0.273598]\n",
      "epoch:15 step:14439 [D loss: 0.250842, acc.: 53.91%] [G loss: 0.285595]\n",
      "epoch:15 step:14440 [D loss: 0.222973, acc.: 66.41%] [G loss: 0.318823]\n",
      "epoch:15 step:14441 [D loss: 0.234009, acc.: 54.69%] [G loss: 0.321392]\n",
      "epoch:15 step:14442 [D loss: 0.246501, acc.: 57.81%] [G loss: 0.290735]\n",
      "epoch:15 step:14443 [D loss: 0.241408, acc.: 58.59%] [G loss: 0.308246]\n",
      "epoch:15 step:14444 [D loss: 0.242636, acc.: 58.59%] [G loss: 0.299150]\n",
      "epoch:15 step:14445 [D loss: 0.247103, acc.: 57.81%] [G loss: 0.275821]\n",
      "epoch:15 step:14446 [D loss: 0.251466, acc.: 56.25%] [G loss: 0.302666]\n",
      "epoch:15 step:14447 [D loss: 0.216805, acc.: 68.75%] [G loss: 0.302650]\n",
      "epoch:15 step:14448 [D loss: 0.247574, acc.: 50.78%] [G loss: 0.281474]\n",
      "epoch:15 step:14449 [D loss: 0.252062, acc.: 55.47%] [G loss: 0.302789]\n",
      "epoch:15 step:14450 [D loss: 0.235556, acc.: 60.94%] [G loss: 0.294012]\n",
      "epoch:15 step:14451 [D loss: 0.239081, acc.: 57.81%] [G loss: 0.278675]\n",
      "epoch:15 step:14452 [D loss: 0.249723, acc.: 50.78%] [G loss: 0.293317]\n",
      "epoch:15 step:14453 [D loss: 0.248260, acc.: 53.12%] [G loss: 0.304035]\n",
      "epoch:15 step:14454 [D loss: 0.221585, acc.: 65.62%] [G loss: 0.305048]\n",
      "epoch:15 step:14455 [D loss: 0.238815, acc.: 56.25%] [G loss: 0.287880]\n",
      "epoch:15 step:14456 [D loss: 0.238623, acc.: 57.03%] [G loss: 0.283928]\n",
      "epoch:15 step:14457 [D loss: 0.242781, acc.: 60.94%] [G loss: 0.293667]\n",
      "epoch:15 step:14458 [D loss: 0.247889, acc.: 55.47%] [G loss: 0.298263]\n",
      "epoch:15 step:14459 [D loss: 0.260610, acc.: 53.12%] [G loss: 0.290470]\n",
      "epoch:15 step:14460 [D loss: 0.239172, acc.: 58.59%] [G loss: 0.280521]\n",
      "epoch:15 step:14461 [D loss: 0.248310, acc.: 56.25%] [G loss: 0.282494]\n",
      "epoch:15 step:14462 [D loss: 0.242697, acc.: 58.59%] [G loss: 0.317564]\n",
      "epoch:15 step:14463 [D loss: 0.235776, acc.: 62.50%] [G loss: 0.303532]\n",
      "epoch:15 step:14464 [D loss: 0.228122, acc.: 65.62%] [G loss: 0.302768]\n",
      "epoch:15 step:14465 [D loss: 0.244749, acc.: 56.25%] [G loss: 0.316798]\n",
      "epoch:15 step:14466 [D loss: 0.240954, acc.: 54.69%] [G loss: 0.270173]\n",
      "epoch:15 step:14467 [D loss: 0.249823, acc.: 52.34%] [G loss: 0.298979]\n",
      "epoch:15 step:14468 [D loss: 0.254084, acc.: 52.34%] [G loss: 0.321239]\n",
      "epoch:15 step:14469 [D loss: 0.255670, acc.: 52.34%] [G loss: 0.319657]\n",
      "epoch:15 step:14470 [D loss: 0.240018, acc.: 55.47%] [G loss: 0.270115]\n",
      "epoch:15 step:14471 [D loss: 0.236088, acc.: 61.72%] [G loss: 0.270541]\n",
      "epoch:15 step:14472 [D loss: 0.245882, acc.: 56.25%] [G loss: 0.287072]\n",
      "epoch:15 step:14473 [D loss: 0.255409, acc.: 53.91%] [G loss: 0.283876]\n",
      "epoch:15 step:14474 [D loss: 0.237076, acc.: 58.59%] [G loss: 0.286439]\n",
      "epoch:15 step:14475 [D loss: 0.229487, acc.: 57.03%] [G loss: 0.327932]\n",
      "epoch:15 step:14476 [D loss: 0.237293, acc.: 54.69%] [G loss: 0.310082]\n",
      "epoch:15 step:14477 [D loss: 0.250797, acc.: 55.47%] [G loss: 0.285229]\n",
      "epoch:15 step:14478 [D loss: 0.243539, acc.: 57.03%] [G loss: 0.318439]\n",
      "epoch:15 step:14479 [D loss: 0.228879, acc.: 61.72%] [G loss: 0.312220]\n",
      "epoch:15 step:14480 [D loss: 0.236251, acc.: 61.72%] [G loss: 0.299187]\n",
      "epoch:15 step:14481 [D loss: 0.234868, acc.: 62.50%] [G loss: 0.298222]\n",
      "epoch:15 step:14482 [D loss: 0.240804, acc.: 60.94%] [G loss: 0.307335]\n",
      "epoch:15 step:14483 [D loss: 0.254404, acc.: 57.03%] [G loss: 0.279938]\n",
      "epoch:15 step:14484 [D loss: 0.231966, acc.: 58.59%] [G loss: 0.309312]\n",
      "epoch:15 step:14485 [D loss: 0.240412, acc.: 60.94%] [G loss: 0.291675]\n",
      "epoch:15 step:14486 [D loss: 0.231191, acc.: 58.59%] [G loss: 0.308014]\n",
      "epoch:15 step:14487 [D loss: 0.245122, acc.: 54.69%] [G loss: 0.288947]\n",
      "epoch:15 step:14488 [D loss: 0.255031, acc.: 55.47%] [G loss: 0.295505]\n",
      "epoch:15 step:14489 [D loss: 0.241769, acc.: 57.81%] [G loss: 0.311384]\n",
      "epoch:15 step:14490 [D loss: 0.228723, acc.: 62.50%] [G loss: 0.284301]\n",
      "epoch:15 step:14491 [D loss: 0.245149, acc.: 54.69%] [G loss: 0.293055]\n",
      "epoch:15 step:14492 [D loss: 0.238110, acc.: 58.59%] [G loss: 0.334934]\n",
      "epoch:15 step:14493 [D loss: 0.252405, acc.: 53.12%] [G loss: 0.307293]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:15 step:14494 [D loss: 0.250858, acc.: 53.91%] [G loss: 0.299059]\n",
      "epoch:15 step:14495 [D loss: 0.240217, acc.: 59.38%] [G loss: 0.301670]\n",
      "epoch:15 step:14496 [D loss: 0.242276, acc.: 62.50%] [G loss: 0.302799]\n",
      "epoch:15 step:14497 [D loss: 0.245628, acc.: 55.47%] [G loss: 0.271963]\n",
      "epoch:15 step:14498 [D loss: 0.244266, acc.: 57.81%] [G loss: 0.299750]\n",
      "epoch:15 step:14499 [D loss: 0.236644, acc.: 58.59%] [G loss: 0.304427]\n",
      "epoch:15 step:14500 [D loss: 0.225414, acc.: 62.50%] [G loss: 0.299316]\n",
      "epoch:15 step:14501 [D loss: 0.241839, acc.: 54.69%] [G loss: 0.301307]\n",
      "epoch:15 step:14502 [D loss: 0.225180, acc.: 64.06%] [G loss: 0.285506]\n",
      "epoch:15 step:14503 [D loss: 0.246465, acc.: 55.47%] [G loss: 0.312998]\n",
      "epoch:15 step:14504 [D loss: 0.228901, acc.: 62.50%] [G loss: 0.302922]\n",
      "epoch:15 step:14505 [D loss: 0.232275, acc.: 64.06%] [G loss: 0.294531]\n",
      "epoch:15 step:14506 [D loss: 0.237287, acc.: 56.25%] [G loss: 0.297430]\n",
      "epoch:15 step:14507 [D loss: 0.235160, acc.: 60.16%] [G loss: 0.315933]\n",
      "epoch:15 step:14508 [D loss: 0.225896, acc.: 64.06%] [G loss: 0.315172]\n",
      "epoch:15 step:14509 [D loss: 0.232581, acc.: 66.41%] [G loss: 0.307046]\n",
      "epoch:15 step:14510 [D loss: 0.233329, acc.: 57.03%] [G loss: 0.310431]\n",
      "epoch:15 step:14511 [D loss: 0.222932, acc.: 65.62%] [G loss: 0.314440]\n",
      "epoch:15 step:14512 [D loss: 0.244897, acc.: 53.91%] [G loss: 0.283836]\n",
      "epoch:15 step:14513 [D loss: 0.235080, acc.: 59.38%] [G loss: 0.303232]\n",
      "epoch:15 step:14514 [D loss: 0.226033, acc.: 61.72%] [G loss: 0.301117]\n",
      "epoch:15 step:14515 [D loss: 0.237484, acc.: 57.81%] [G loss: 0.311867]\n",
      "epoch:15 step:14516 [D loss: 0.244970, acc.: 53.91%] [G loss: 0.279450]\n",
      "epoch:15 step:14517 [D loss: 0.254853, acc.: 51.56%] [G loss: 0.307681]\n",
      "epoch:15 step:14518 [D loss: 0.248840, acc.: 57.03%] [G loss: 0.315136]\n",
      "epoch:15 step:14519 [D loss: 0.229428, acc.: 64.84%] [G loss: 0.301516]\n",
      "epoch:15 step:14520 [D loss: 0.239006, acc.: 54.69%] [G loss: 0.276936]\n",
      "epoch:15 step:14521 [D loss: 0.250564, acc.: 57.03%] [G loss: 0.294257]\n",
      "epoch:15 step:14522 [D loss: 0.247752, acc.: 56.25%] [G loss: 0.290730]\n",
      "epoch:15 step:14523 [D loss: 0.231457, acc.: 57.03%] [G loss: 0.300952]\n",
      "epoch:15 step:14524 [D loss: 0.251181, acc.: 54.69%] [G loss: 0.308415]\n",
      "epoch:15 step:14525 [D loss: 0.263319, acc.: 47.66%] [G loss: 0.276667]\n",
      "epoch:15 step:14526 [D loss: 0.239655, acc.: 58.59%] [G loss: 0.285800]\n",
      "epoch:15 step:14527 [D loss: 0.251074, acc.: 53.91%] [G loss: 0.290878]\n",
      "epoch:15 step:14528 [D loss: 0.249240, acc.: 59.38%] [G loss: 0.309472]\n",
      "epoch:15 step:14529 [D loss: 0.233200, acc.: 64.06%] [G loss: 0.299408]\n",
      "epoch:15 step:14530 [D loss: 0.225824, acc.: 63.28%] [G loss: 0.305369]\n",
      "epoch:15 step:14531 [D loss: 0.258878, acc.: 46.88%] [G loss: 0.281829]\n",
      "epoch:15 step:14532 [D loss: 0.235606, acc.: 58.59%] [G loss: 0.280147]\n",
      "epoch:15 step:14533 [D loss: 0.219224, acc.: 67.19%] [G loss: 0.324050]\n",
      "epoch:15 step:14534 [D loss: 0.248121, acc.: 56.25%] [G loss: 0.303364]\n",
      "epoch:15 step:14535 [D loss: 0.263331, acc.: 50.78%] [G loss: 0.305077]\n",
      "epoch:15 step:14536 [D loss: 0.242237, acc.: 55.47%] [G loss: 0.300962]\n",
      "epoch:15 step:14537 [D loss: 0.235311, acc.: 58.59%] [G loss: 0.294067]\n",
      "epoch:15 step:14538 [D loss: 0.239095, acc.: 60.16%] [G loss: 0.305293]\n",
      "epoch:15 step:14539 [D loss: 0.242262, acc.: 59.38%] [G loss: 0.307792]\n",
      "epoch:15 step:14540 [D loss: 0.231814, acc.: 62.50%] [G loss: 0.280576]\n",
      "epoch:15 step:14541 [D loss: 0.228042, acc.: 67.19%] [G loss: 0.309233]\n",
      "epoch:15 step:14542 [D loss: 0.225633, acc.: 67.19%] [G loss: 0.290866]\n",
      "epoch:15 step:14543 [D loss: 0.247204, acc.: 58.59%] [G loss: 0.298585]\n",
      "epoch:15 step:14544 [D loss: 0.232778, acc.: 58.59%] [G loss: 0.293637]\n",
      "epoch:15 step:14545 [D loss: 0.225757, acc.: 65.62%] [G loss: 0.291383]\n",
      "epoch:15 step:14546 [D loss: 0.236490, acc.: 60.16%] [G loss: 0.288770]\n",
      "epoch:15 step:14547 [D loss: 0.237277, acc.: 60.94%] [G loss: 0.309353]\n",
      "epoch:15 step:14548 [D loss: 0.220097, acc.: 64.06%] [G loss: 0.290798]\n",
      "epoch:15 step:14549 [D loss: 0.231759, acc.: 63.28%] [G loss: 0.304348]\n",
      "epoch:15 step:14550 [D loss: 0.247138, acc.: 60.16%] [G loss: 0.311796]\n",
      "epoch:15 step:14551 [D loss: 0.229679, acc.: 64.06%] [G loss: 0.309071]\n",
      "epoch:15 step:14552 [D loss: 0.217111, acc.: 61.72%] [G loss: 0.298629]\n",
      "epoch:15 step:14553 [D loss: 0.249463, acc.: 54.69%] [G loss: 0.288840]\n",
      "epoch:15 step:14554 [D loss: 0.236757, acc.: 60.16%] [G loss: 0.307419]\n",
      "epoch:15 step:14555 [D loss: 0.246811, acc.: 50.00%] [G loss: 0.283033]\n",
      "epoch:15 step:14556 [D loss: 0.228383, acc.: 64.06%] [G loss: 0.311220]\n",
      "epoch:15 step:14557 [D loss: 0.247777, acc.: 58.59%] [G loss: 0.313657]\n",
      "epoch:15 step:14558 [D loss: 0.244232, acc.: 56.25%] [G loss: 0.287799]\n",
      "epoch:15 step:14559 [D loss: 0.231595, acc.: 59.38%] [G loss: 0.286967]\n",
      "epoch:15 step:14560 [D loss: 0.237641, acc.: 60.94%] [G loss: 0.305654]\n",
      "epoch:15 step:14561 [D loss: 0.238451, acc.: 56.25%] [G loss: 0.315760]\n",
      "epoch:15 step:14562 [D loss: 0.233681, acc.: 60.16%] [G loss: 0.309944]\n",
      "epoch:15 step:14563 [D loss: 0.240389, acc.: 55.47%] [G loss: 0.286890]\n",
      "epoch:15 step:14564 [D loss: 0.240080, acc.: 58.59%] [G loss: 0.305684]\n",
      "epoch:15 step:14565 [D loss: 0.229359, acc.: 64.84%] [G loss: 0.319810]\n",
      "epoch:15 step:14566 [D loss: 0.233069, acc.: 59.38%] [G loss: 0.321329]\n",
      "epoch:15 step:14567 [D loss: 0.218377, acc.: 67.97%] [G loss: 0.318094]\n",
      "epoch:15 step:14568 [D loss: 0.241600, acc.: 60.16%] [G loss: 0.296521]\n",
      "epoch:15 step:14569 [D loss: 0.264375, acc.: 46.88%] [G loss: 0.307268]\n",
      "epoch:15 step:14570 [D loss: 0.242561, acc.: 60.16%] [G loss: 0.304606]\n",
      "epoch:15 step:14571 [D loss: 0.237748, acc.: 60.16%] [G loss: 0.294023]\n",
      "epoch:15 step:14572 [D loss: 0.234663, acc.: 56.25%] [G loss: 0.306140]\n",
      "epoch:15 step:14573 [D loss: 0.241663, acc.: 61.72%] [G loss: 0.322065]\n",
      "epoch:15 step:14574 [D loss: 0.247446, acc.: 53.91%] [G loss: 0.318187]\n",
      "epoch:15 step:14575 [D loss: 0.231526, acc.: 65.62%] [G loss: 0.310996]\n",
      "epoch:15 step:14576 [D loss: 0.249325, acc.: 57.03%] [G loss: 0.312141]\n",
      "epoch:15 step:14577 [D loss: 0.253664, acc.: 53.91%] [G loss: 0.301179]\n",
      "epoch:15 step:14578 [D loss: 0.228804, acc.: 60.94%] [G loss: 0.283781]\n",
      "epoch:15 step:14579 [D loss: 0.236754, acc.: 57.03%] [G loss: 0.310863]\n",
      "epoch:15 step:14580 [D loss: 0.243404, acc.: 57.03%] [G loss: 0.298906]\n",
      "epoch:15 step:14581 [D loss: 0.238913, acc.: 56.25%] [G loss: 0.294969]\n",
      "epoch:15 step:14582 [D loss: 0.238865, acc.: 58.59%] [G loss: 0.296710]\n",
      "epoch:15 step:14583 [D loss: 0.240180, acc.: 55.47%] [G loss: 0.283510]\n",
      "epoch:15 step:14584 [D loss: 0.228502, acc.: 64.84%] [G loss: 0.293872]\n",
      "epoch:15 step:14585 [D loss: 0.251143, acc.: 50.00%] [G loss: 0.279709]\n",
      "epoch:15 step:14586 [D loss: 0.241094, acc.: 56.25%] [G loss: 0.271971]\n",
      "epoch:15 step:14587 [D loss: 0.248835, acc.: 52.34%] [G loss: 0.287113]\n",
      "epoch:15 step:14588 [D loss: 0.247650, acc.: 59.38%] [G loss: 0.305972]\n",
      "epoch:15 step:14589 [D loss: 0.241812, acc.: 60.94%] [G loss: 0.270809]\n",
      "epoch:15 step:14590 [D loss: 0.248810, acc.: 57.81%] [G loss: 0.299448]\n",
      "epoch:15 step:14591 [D loss: 0.234619, acc.: 63.28%] [G loss: 0.289430]\n",
      "epoch:15 step:14592 [D loss: 0.255945, acc.: 52.34%] [G loss: 0.307269]\n",
      "epoch:15 step:14593 [D loss: 0.220938, acc.: 64.06%] [G loss: 0.290085]\n",
      "epoch:15 step:14594 [D loss: 0.237277, acc.: 63.28%] [G loss: 0.311786]\n",
      "epoch:15 step:14595 [D loss: 0.231637, acc.: 62.50%] [G loss: 0.293662]\n",
      "epoch:15 step:14596 [D loss: 0.223315, acc.: 67.97%] [G loss: 0.289188]\n",
      "epoch:15 step:14597 [D loss: 0.236179, acc.: 58.59%] [G loss: 0.297900]\n",
      "epoch:15 step:14598 [D loss: 0.230924, acc.: 64.06%] [G loss: 0.280850]\n",
      "epoch:15 step:14599 [D loss: 0.240541, acc.: 59.38%] [G loss: 0.278516]\n",
      "epoch:15 step:14600 [D loss: 0.240192, acc.: 56.25%] [G loss: 0.282836]\n",
      "epoch:15 step:14601 [D loss: 0.242209, acc.: 59.38%] [G loss: 0.328218]\n",
      "epoch:15 step:14602 [D loss: 0.256832, acc.: 55.47%] [G loss: 0.286702]\n",
      "epoch:15 step:14603 [D loss: 0.253144, acc.: 51.56%] [G loss: 0.311542]\n",
      "epoch:15 step:14604 [D loss: 0.242941, acc.: 58.59%] [G loss: 0.297792]\n",
      "epoch:15 step:14605 [D loss: 0.248321, acc.: 57.03%] [G loss: 0.290269]\n",
      "epoch:15 step:14606 [D loss: 0.230691, acc.: 60.16%] [G loss: 0.308441]\n",
      "epoch:15 step:14607 [D loss: 0.248067, acc.: 52.34%] [G loss: 0.271955]\n",
      "epoch:15 step:14608 [D loss: 0.272669, acc.: 46.88%] [G loss: 0.316199]\n",
      "epoch:15 step:14609 [D loss: 0.219198, acc.: 67.97%] [G loss: 0.318591]\n",
      "epoch:15 step:14610 [D loss: 0.237350, acc.: 53.12%] [G loss: 0.309824]\n",
      "epoch:15 step:14611 [D loss: 0.254818, acc.: 53.12%] [G loss: 0.275707]\n",
      "epoch:15 step:14612 [D loss: 0.237075, acc.: 60.16%] [G loss: 0.307331]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:15 step:14613 [D loss: 0.242617, acc.: 57.03%] [G loss: 0.286476]\n",
      "epoch:15 step:14614 [D loss: 0.245807, acc.: 55.47%] [G loss: 0.308644]\n",
      "epoch:15 step:14615 [D loss: 0.244246, acc.: 48.44%] [G loss: 0.273639]\n",
      "epoch:15 step:14616 [D loss: 0.235520, acc.: 58.59%] [G loss: 0.305808]\n",
      "epoch:15 step:14617 [D loss: 0.251023, acc.: 56.25%] [G loss: 0.290110]\n",
      "epoch:15 step:14618 [D loss: 0.225677, acc.: 68.75%] [G loss: 0.300523]\n",
      "epoch:15 step:14619 [D loss: 0.231139, acc.: 60.16%] [G loss: 0.296881]\n",
      "epoch:15 step:14620 [D loss: 0.240579, acc.: 55.47%] [G loss: 0.334746]\n",
      "epoch:15 step:14621 [D loss: 0.238976, acc.: 57.03%] [G loss: 0.261465]\n",
      "epoch:15 step:14622 [D loss: 0.239574, acc.: 53.12%] [G loss: 0.290187]\n",
      "epoch:15 step:14623 [D loss: 0.254282, acc.: 53.91%] [G loss: 0.296998]\n",
      "epoch:15 step:14624 [D loss: 0.234899, acc.: 56.25%] [G loss: 0.314983]\n",
      "epoch:15 step:14625 [D loss: 0.263604, acc.: 48.44%] [G loss: 0.287946]\n",
      "epoch:15 step:14626 [D loss: 0.233659, acc.: 63.28%] [G loss: 0.326279]\n",
      "epoch:15 step:14627 [D loss: 0.231535, acc.: 65.62%] [G loss: 0.274736]\n",
      "epoch:15 step:14628 [D loss: 0.239072, acc.: 64.06%] [G loss: 0.321123]\n",
      "epoch:15 step:14629 [D loss: 0.254788, acc.: 55.47%] [G loss: 0.279477]\n",
      "epoch:15 step:14630 [D loss: 0.259180, acc.: 53.12%] [G loss: 0.298357]\n",
      "epoch:15 step:14631 [D loss: 0.230198, acc.: 62.50%] [G loss: 0.309396]\n",
      "epoch:15 step:14632 [D loss: 0.244412, acc.: 53.12%] [G loss: 0.308070]\n",
      "epoch:15 step:14633 [D loss: 0.226545, acc.: 67.19%] [G loss: 0.301265]\n",
      "epoch:15 step:14634 [D loss: 0.253763, acc.: 48.44%] [G loss: 0.266061]\n",
      "epoch:15 step:14635 [D loss: 0.251965, acc.: 55.47%] [G loss: 0.301396]\n",
      "epoch:15 step:14636 [D loss: 0.236138, acc.: 60.16%] [G loss: 0.308147]\n",
      "epoch:15 step:14637 [D loss: 0.240161, acc.: 58.59%] [G loss: 0.305077]\n",
      "epoch:15 step:14638 [D loss: 0.231431, acc.: 59.38%] [G loss: 0.293198]\n",
      "epoch:15 step:14639 [D loss: 0.253944, acc.: 53.12%] [G loss: 0.282386]\n",
      "epoch:15 step:14640 [D loss: 0.234981, acc.: 60.16%] [G loss: 0.306585]\n",
      "epoch:15 step:14641 [D loss: 0.236404, acc.: 63.28%] [G loss: 0.309672]\n",
      "epoch:15 step:14642 [D loss: 0.238682, acc.: 58.59%] [G loss: 0.276730]\n",
      "epoch:15 step:14643 [D loss: 0.250301, acc.: 52.34%] [G loss: 0.293609]\n",
      "epoch:15 step:14644 [D loss: 0.221608, acc.: 64.06%] [G loss: 0.320537]\n",
      "epoch:15 step:14645 [D loss: 0.221540, acc.: 66.41%] [G loss: 0.305452]\n",
      "epoch:15 step:14646 [D loss: 0.222410, acc.: 67.97%] [G loss: 0.294812]\n",
      "epoch:15 step:14647 [D loss: 0.242936, acc.: 54.69%] [G loss: 0.295541]\n",
      "epoch:15 step:14648 [D loss: 0.250478, acc.: 49.22%] [G loss: 0.285957]\n",
      "epoch:15 step:14649 [D loss: 0.224276, acc.: 64.06%] [G loss: 0.328960]\n",
      "epoch:15 step:14650 [D loss: 0.250617, acc.: 55.47%] [G loss: 0.313138]\n",
      "epoch:15 step:14651 [D loss: 0.224523, acc.: 63.28%] [G loss: 0.323195]\n",
      "epoch:15 step:14652 [D loss: 0.237820, acc.: 57.81%] [G loss: 0.299180]\n",
      "epoch:15 step:14653 [D loss: 0.236857, acc.: 57.81%] [G loss: 0.299673]\n",
      "epoch:15 step:14654 [D loss: 0.236693, acc.: 60.94%] [G loss: 0.290077]\n",
      "epoch:15 step:14655 [D loss: 0.244192, acc.: 57.03%] [G loss: 0.305905]\n",
      "epoch:15 step:14656 [D loss: 0.227872, acc.: 59.38%] [G loss: 0.304397]\n",
      "epoch:15 step:14657 [D loss: 0.220242, acc.: 63.28%] [G loss: 0.282235]\n",
      "epoch:15 step:14658 [D loss: 0.223992, acc.: 63.28%] [G loss: 0.311904]\n",
      "epoch:15 step:14659 [D loss: 0.243751, acc.: 56.25%] [G loss: 0.306222]\n",
      "epoch:15 step:14660 [D loss: 0.234927, acc.: 60.94%] [G loss: 0.279273]\n",
      "epoch:15 step:14661 [D loss: 0.236424, acc.: 57.03%] [G loss: 0.304341]\n",
      "epoch:15 step:14662 [D loss: 0.238636, acc.: 57.81%] [G loss: 0.286985]\n",
      "epoch:15 step:14663 [D loss: 0.237762, acc.: 60.16%] [G loss: 0.286545]\n",
      "epoch:15 step:14664 [D loss: 0.245457, acc.: 57.03%] [G loss: 0.270899]\n",
      "epoch:15 step:14665 [D loss: 0.231298, acc.: 63.28%] [G loss: 0.332748]\n",
      "epoch:15 step:14666 [D loss: 0.248462, acc.: 51.56%] [G loss: 0.319729]\n",
      "epoch:15 step:14667 [D loss: 0.223382, acc.: 64.84%] [G loss: 0.309701]\n",
      "epoch:15 step:14668 [D loss: 0.234548, acc.: 58.59%] [G loss: 0.318708]\n",
      "epoch:15 step:14669 [D loss: 0.230765, acc.: 61.72%] [G loss: 0.295066]\n",
      "epoch:15 step:14670 [D loss: 0.233711, acc.: 60.94%] [G loss: 0.264428]\n",
      "epoch:15 step:14671 [D loss: 0.233745, acc.: 59.38%] [G loss: 0.273398]\n",
      "epoch:15 step:14672 [D loss: 0.245111, acc.: 53.12%] [G loss: 0.284367]\n",
      "epoch:15 step:14673 [D loss: 0.233688, acc.: 60.16%] [G loss: 0.273520]\n",
      "epoch:15 step:14674 [D loss: 0.251333, acc.: 55.47%] [G loss: 0.281351]\n",
      "epoch:15 step:14675 [D loss: 0.246889, acc.: 50.78%] [G loss: 0.290798]\n",
      "epoch:15 step:14676 [D loss: 0.237045, acc.: 57.81%] [G loss: 0.301508]\n",
      "epoch:15 step:14677 [D loss: 0.232977, acc.: 64.06%] [G loss: 0.285449]\n",
      "epoch:15 step:14678 [D loss: 0.247185, acc.: 59.38%] [G loss: 0.308579]\n",
      "epoch:15 step:14679 [D loss: 0.243858, acc.: 57.03%] [G loss: 0.284269]\n",
      "epoch:15 step:14680 [D loss: 0.238927, acc.: 57.81%] [G loss: 0.309118]\n",
      "epoch:15 step:14681 [D loss: 0.230991, acc.: 59.38%] [G loss: 0.323020]\n",
      "epoch:15 step:14682 [D loss: 0.227287, acc.: 60.16%] [G loss: 0.302058]\n",
      "epoch:15 step:14683 [D loss: 0.241066, acc.: 55.47%] [G loss: 0.302976]\n",
      "epoch:15 step:14684 [D loss: 0.238775, acc.: 58.59%] [G loss: 0.296363]\n",
      "epoch:15 step:14685 [D loss: 0.228546, acc.: 61.72%] [G loss: 0.300671]\n",
      "epoch:15 step:14686 [D loss: 0.223798, acc.: 65.62%] [G loss: 0.278218]\n",
      "epoch:15 step:14687 [D loss: 0.230219, acc.: 59.38%] [G loss: 0.296544]\n",
      "epoch:15 step:14688 [D loss: 0.235620, acc.: 57.81%] [G loss: 0.282531]\n",
      "epoch:15 step:14689 [D loss: 0.223353, acc.: 60.16%] [G loss: 0.288766]\n",
      "epoch:15 step:14690 [D loss: 0.225401, acc.: 61.72%] [G loss: 0.292346]\n",
      "epoch:15 step:14691 [D loss: 0.217599, acc.: 66.41%] [G loss: 0.303774]\n",
      "epoch:15 step:14692 [D loss: 0.224901, acc.: 61.72%] [G loss: 0.301856]\n",
      "epoch:15 step:14693 [D loss: 0.248769, acc.: 54.69%] [G loss: 0.280260]\n",
      "epoch:15 step:14694 [D loss: 0.245061, acc.: 57.03%] [G loss: 0.318009]\n",
      "epoch:15 step:14695 [D loss: 0.230987, acc.: 60.16%] [G loss: 0.294288]\n",
      "epoch:15 step:14696 [D loss: 0.250004, acc.: 52.34%] [G loss: 0.279372]\n",
      "epoch:15 step:14697 [D loss: 0.235415, acc.: 59.38%] [G loss: 0.300326]\n",
      "epoch:15 step:14698 [D loss: 0.241517, acc.: 56.25%] [G loss: 0.333394]\n",
      "epoch:15 step:14699 [D loss: 0.244972, acc.: 54.69%] [G loss: 0.287217]\n",
      "epoch:15 step:14700 [D loss: 0.236442, acc.: 56.25%] [G loss: 0.313484]\n",
      "epoch:15 step:14701 [D loss: 0.247094, acc.: 57.03%] [G loss: 0.299641]\n",
      "epoch:15 step:14702 [D loss: 0.240329, acc.: 60.16%] [G loss: 0.308807]\n",
      "epoch:15 step:14703 [D loss: 0.231256, acc.: 60.16%] [G loss: 0.320900]\n",
      "epoch:15 step:14704 [D loss: 0.237619, acc.: 56.25%] [G loss: 0.319748]\n",
      "epoch:15 step:14705 [D loss: 0.246376, acc.: 51.56%] [G loss: 0.287958]\n",
      "epoch:15 step:14706 [D loss: 0.235199, acc.: 62.50%] [G loss: 0.306393]\n",
      "epoch:15 step:14707 [D loss: 0.237273, acc.: 60.94%] [G loss: 0.286588]\n",
      "epoch:15 step:14708 [D loss: 0.222988, acc.: 67.19%] [G loss: 0.294321]\n",
      "epoch:15 step:14709 [D loss: 0.235967, acc.: 60.94%] [G loss: 0.291712]\n",
      "epoch:15 step:14710 [D loss: 0.225760, acc.: 63.28%] [G loss: 0.335505]\n",
      "epoch:15 step:14711 [D loss: 0.235095, acc.: 60.16%] [G loss: 0.298691]\n",
      "epoch:15 step:14712 [D loss: 0.245381, acc.: 49.22%] [G loss: 0.300314]\n",
      "epoch:15 step:14713 [D loss: 0.243915, acc.: 57.81%] [G loss: 0.302139]\n",
      "epoch:15 step:14714 [D loss: 0.241445, acc.: 57.03%] [G loss: 0.296867]\n",
      "epoch:15 step:14715 [D loss: 0.236421, acc.: 62.50%] [G loss: 0.291087]\n",
      "epoch:15 step:14716 [D loss: 0.238492, acc.: 53.91%] [G loss: 0.295810]\n",
      "epoch:15 step:14717 [D loss: 0.240797, acc.: 54.69%] [G loss: 0.313189]\n",
      "epoch:15 step:14718 [D loss: 0.243755, acc.: 52.34%] [G loss: 0.285468]\n",
      "epoch:15 step:14719 [D loss: 0.224691, acc.: 60.16%] [G loss: 0.297403]\n",
      "epoch:15 step:14720 [D loss: 0.247809, acc.: 57.81%] [G loss: 0.266207]\n",
      "epoch:15 step:14721 [D loss: 0.238063, acc.: 59.38%] [G loss: 0.301245]\n",
      "epoch:15 step:14722 [D loss: 0.231695, acc.: 58.59%] [G loss: 0.313372]\n",
      "epoch:15 step:14723 [D loss: 0.241315, acc.: 59.38%] [G loss: 0.300506]\n",
      "epoch:15 step:14724 [D loss: 0.250387, acc.: 53.12%] [G loss: 0.298053]\n",
      "epoch:15 step:14725 [D loss: 0.248810, acc.: 52.34%] [G loss: 0.293155]\n",
      "epoch:15 step:14726 [D loss: 0.226170, acc.: 60.16%] [G loss: 0.301105]\n",
      "epoch:15 step:14727 [D loss: 0.230501, acc.: 61.72%] [G loss: 0.279334]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:15 step:14728 [D loss: 0.256363, acc.: 57.81%] [G loss: 0.298932]\n",
      "epoch:15 step:14729 [D loss: 0.238114, acc.: 60.16%] [G loss: 0.317849]\n",
      "epoch:15 step:14730 [D loss: 0.247285, acc.: 59.38%] [G loss: 0.294842]\n",
      "epoch:15 step:14731 [D loss: 0.232608, acc.: 60.16%] [G loss: 0.326413]\n",
      "epoch:15 step:14732 [D loss: 0.241105, acc.: 56.25%] [G loss: 0.306067]\n",
      "epoch:15 step:14733 [D loss: 0.235235, acc.: 59.38%] [G loss: 0.321749]\n",
      "epoch:15 step:14734 [D loss: 0.252975, acc.: 51.56%] [G loss: 0.304933]\n",
      "epoch:15 step:14735 [D loss: 0.247929, acc.: 53.12%] [G loss: 0.291670]\n",
      "epoch:15 step:14736 [D loss: 0.228944, acc.: 57.03%] [G loss: 0.306691]\n",
      "epoch:15 step:14737 [D loss: 0.237859, acc.: 62.50%] [G loss: 0.338402]\n",
      "epoch:15 step:14738 [D loss: 0.238815, acc.: 59.38%] [G loss: 0.291392]\n",
      "epoch:15 step:14739 [D loss: 0.223780, acc.: 67.19%] [G loss: 0.323423]\n",
      "epoch:15 step:14740 [D loss: 0.243360, acc.: 53.91%] [G loss: 0.277596]\n",
      "epoch:15 step:14741 [D loss: 0.214894, acc.: 64.84%] [G loss: 0.310682]\n",
      "epoch:15 step:14742 [D loss: 0.247665, acc.: 57.03%] [G loss: 0.308029]\n",
      "epoch:15 step:14743 [D loss: 0.225871, acc.: 60.94%] [G loss: 0.333443]\n",
      "epoch:15 step:14744 [D loss: 0.237986, acc.: 59.38%] [G loss: 0.287140]\n",
      "epoch:15 step:14745 [D loss: 0.240143, acc.: 57.81%] [G loss: 0.297100]\n",
      "epoch:15 step:14746 [D loss: 0.223923, acc.: 68.75%] [G loss: 0.294951]\n",
      "epoch:15 step:14747 [D loss: 0.229533, acc.: 57.81%] [G loss: 0.291382]\n",
      "epoch:15 step:14748 [D loss: 0.235182, acc.: 57.03%] [G loss: 0.315488]\n",
      "epoch:15 step:14749 [D loss: 0.246563, acc.: 57.03%] [G loss: 0.296851]\n",
      "epoch:15 step:14750 [D loss: 0.240745, acc.: 57.03%] [G loss: 0.301329]\n",
      "epoch:15 step:14751 [D loss: 0.240037, acc.: 59.38%] [G loss: 0.300889]\n",
      "epoch:15 step:14752 [D loss: 0.231393, acc.: 60.16%] [G loss: 0.309540]\n",
      "epoch:15 step:14753 [D loss: 0.229803, acc.: 66.41%] [G loss: 0.291359]\n",
      "epoch:15 step:14754 [D loss: 0.234062, acc.: 60.16%] [G loss: 0.309090]\n",
      "epoch:15 step:14755 [D loss: 0.230738, acc.: 64.06%] [G loss: 0.308319]\n",
      "epoch:15 step:14756 [D loss: 0.235970, acc.: 58.59%] [G loss: 0.263221]\n",
      "epoch:15 step:14757 [D loss: 0.225844, acc.: 62.50%] [G loss: 0.306092]\n",
      "epoch:15 step:14758 [D loss: 0.246649, acc.: 55.47%] [G loss: 0.287842]\n",
      "epoch:15 step:14759 [D loss: 0.235303, acc.: 60.16%] [G loss: 0.303476]\n",
      "epoch:15 step:14760 [D loss: 0.246801, acc.: 56.25%] [G loss: 0.296843]\n",
      "epoch:15 step:14761 [D loss: 0.243267, acc.: 52.34%] [G loss: 0.327420]\n",
      "epoch:15 step:14762 [D loss: 0.231227, acc.: 60.94%] [G loss: 0.341353]\n",
      "epoch:15 step:14763 [D loss: 0.238711, acc.: 56.25%] [G loss: 0.298990]\n",
      "epoch:15 step:14764 [D loss: 0.246772, acc.: 60.94%] [G loss: 0.314839]\n",
      "epoch:15 step:14765 [D loss: 0.258252, acc.: 49.22%] [G loss: 0.307880]\n",
      "epoch:15 step:14766 [D loss: 0.238603, acc.: 57.81%] [G loss: 0.291649]\n",
      "epoch:15 step:14767 [D loss: 0.238657, acc.: 57.81%] [G loss: 0.275695]\n",
      "epoch:15 step:14768 [D loss: 0.228267, acc.: 60.94%] [G loss: 0.291202]\n",
      "epoch:15 step:14769 [D loss: 0.243238, acc.: 60.16%] [G loss: 0.301329]\n",
      "epoch:15 step:14770 [D loss: 0.238472, acc.: 57.81%] [G loss: 0.305453]\n",
      "epoch:15 step:14771 [D loss: 0.239526, acc.: 53.12%] [G loss: 0.279594]\n",
      "epoch:15 step:14772 [D loss: 0.232958, acc.: 61.72%] [G loss: 0.289551]\n",
      "epoch:15 step:14773 [D loss: 0.237620, acc.: 57.03%] [G loss: 0.301643]\n",
      "epoch:15 step:14774 [D loss: 0.258594, acc.: 47.66%] [G loss: 0.290719]\n",
      "epoch:15 step:14775 [D loss: 0.257846, acc.: 48.44%] [G loss: 0.276933]\n",
      "epoch:15 step:14776 [D loss: 0.251780, acc.: 54.69%] [G loss: 0.306163]\n",
      "epoch:15 step:14777 [D loss: 0.246108, acc.: 59.38%] [G loss: 0.315211]\n",
      "epoch:15 step:14778 [D loss: 0.214574, acc.: 67.19%] [G loss: 0.294201]\n",
      "epoch:15 step:14779 [D loss: 0.245214, acc.: 58.59%] [G loss: 0.301633]\n",
      "epoch:15 step:14780 [D loss: 0.222121, acc.: 61.72%] [G loss: 0.294730]\n",
      "epoch:15 step:14781 [D loss: 0.252938, acc.: 55.47%] [G loss: 0.316935]\n",
      "epoch:15 step:14782 [D loss: 0.243377, acc.: 56.25%] [G loss: 0.299619]\n",
      "epoch:15 step:14783 [D loss: 0.248204, acc.: 57.03%] [G loss: 0.294016]\n",
      "epoch:15 step:14784 [D loss: 0.222195, acc.: 62.50%] [G loss: 0.294017]\n",
      "epoch:15 step:14785 [D loss: 0.259215, acc.: 50.78%] [G loss: 0.305370]\n",
      "epoch:15 step:14786 [D loss: 0.226714, acc.: 64.06%] [G loss: 0.326525]\n",
      "epoch:15 step:14787 [D loss: 0.238281, acc.: 54.69%] [G loss: 0.304408]\n",
      "epoch:15 step:14788 [D loss: 0.247793, acc.: 53.12%] [G loss: 0.286573]\n",
      "epoch:15 step:14789 [D loss: 0.233166, acc.: 59.38%] [G loss: 0.292878]\n",
      "epoch:15 step:14790 [D loss: 0.239709, acc.: 60.16%] [G loss: 0.308516]\n",
      "epoch:15 step:14791 [D loss: 0.221815, acc.: 64.84%] [G loss: 0.311339]\n",
      "epoch:15 step:14792 [D loss: 0.236729, acc.: 60.94%] [G loss: 0.319563]\n",
      "epoch:15 step:14793 [D loss: 0.251336, acc.: 56.25%] [G loss: 0.310705]\n",
      "epoch:15 step:14794 [D loss: 0.230435, acc.: 63.28%] [G loss: 0.333254]\n",
      "epoch:15 step:14795 [D loss: 0.231655, acc.: 60.94%] [G loss: 0.317947]\n",
      "epoch:15 step:14796 [D loss: 0.251383, acc.: 56.25%] [G loss: 0.286073]\n",
      "epoch:15 step:14797 [D loss: 0.240550, acc.: 54.69%] [G loss: 0.309648]\n",
      "epoch:15 step:14798 [D loss: 0.239492, acc.: 58.59%] [G loss: 0.305435]\n",
      "epoch:15 step:14799 [D loss: 0.251962, acc.: 52.34%] [G loss: 0.270626]\n",
      "epoch:15 step:14800 [D loss: 0.252705, acc.: 50.78%] [G loss: 0.308407]\n",
      "epoch:15 step:14801 [D loss: 0.232134, acc.: 58.59%] [G loss: 0.306664]\n",
      "epoch:15 step:14802 [D loss: 0.219109, acc.: 62.50%] [G loss: 0.295604]\n",
      "epoch:15 step:14803 [D loss: 0.225949, acc.: 67.19%] [G loss: 0.302334]\n",
      "epoch:15 step:14804 [D loss: 0.255050, acc.: 53.91%] [G loss: 0.292820]\n",
      "epoch:15 step:14805 [D loss: 0.254684, acc.: 54.69%] [G loss: 0.321418]\n",
      "epoch:15 step:14806 [D loss: 0.223839, acc.: 65.62%] [G loss: 0.291943]\n",
      "epoch:15 step:14807 [D loss: 0.254514, acc.: 50.00%] [G loss: 0.296410]\n",
      "epoch:15 step:14808 [D loss: 0.246493, acc.: 54.69%] [G loss: 0.296938]\n",
      "epoch:15 step:14809 [D loss: 0.234015, acc.: 56.25%] [G loss: 0.321614]\n",
      "epoch:15 step:14810 [D loss: 0.252373, acc.: 48.44%] [G loss: 0.276964]\n",
      "epoch:15 step:14811 [D loss: 0.238071, acc.: 59.38%] [G loss: 0.285473]\n",
      "epoch:15 step:14812 [D loss: 0.244377, acc.: 58.59%] [G loss: 0.306572]\n",
      "epoch:15 step:14813 [D loss: 0.247785, acc.: 56.25%] [G loss: 0.315483]\n",
      "epoch:15 step:14814 [D loss: 0.240496, acc.: 58.59%] [G loss: 0.290941]\n",
      "epoch:15 step:14815 [D loss: 0.242341, acc.: 56.25%] [G loss: 0.315290]\n",
      "epoch:15 step:14816 [D loss: 0.226366, acc.: 62.50%] [G loss: 0.331963]\n",
      "epoch:15 step:14817 [D loss: 0.233540, acc.: 58.59%] [G loss: 0.304344]\n",
      "epoch:15 step:14818 [D loss: 0.227478, acc.: 59.38%] [G loss: 0.295658]\n",
      "epoch:15 step:14819 [D loss: 0.236912, acc.: 55.47%] [G loss: 0.316286]\n",
      "epoch:15 step:14820 [D loss: 0.243350, acc.: 60.16%] [G loss: 0.293582]\n",
      "epoch:15 step:14821 [D loss: 0.241882, acc.: 56.25%] [G loss: 0.287401]\n",
      "epoch:15 step:14822 [D loss: 0.237203, acc.: 59.38%] [G loss: 0.316012]\n",
      "epoch:15 step:14823 [D loss: 0.239623, acc.: 60.16%] [G loss: 0.289262]\n",
      "epoch:15 step:14824 [D loss: 0.239911, acc.: 57.81%] [G loss: 0.315644]\n",
      "epoch:15 step:14825 [D loss: 0.242771, acc.: 53.91%] [G loss: 0.287949]\n",
      "epoch:15 step:14826 [D loss: 0.242363, acc.: 59.38%] [G loss: 0.278223]\n",
      "epoch:15 step:14827 [D loss: 0.233131, acc.: 66.41%] [G loss: 0.284605]\n",
      "epoch:15 step:14828 [D loss: 0.248714, acc.: 57.03%] [G loss: 0.293544]\n",
      "epoch:15 step:14829 [D loss: 0.218940, acc.: 65.62%] [G loss: 0.285619]\n",
      "epoch:15 step:14830 [D loss: 0.236222, acc.: 57.81%] [G loss: 0.292486]\n",
      "epoch:15 step:14831 [D loss: 0.238010, acc.: 59.38%] [G loss: 0.287886]\n",
      "epoch:15 step:14832 [D loss: 0.236821, acc.: 60.16%] [G loss: 0.294796]\n",
      "epoch:15 step:14833 [D loss: 0.252727, acc.: 52.34%] [G loss: 0.291664]\n",
      "epoch:15 step:14834 [D loss: 0.240844, acc.: 54.69%] [G loss: 0.307367]\n",
      "epoch:15 step:14835 [D loss: 0.231191, acc.: 59.38%] [G loss: 0.302725]\n",
      "epoch:15 step:14836 [D loss: 0.242164, acc.: 57.81%] [G loss: 0.335912]\n",
      "epoch:15 step:14837 [D loss: 0.233967, acc.: 58.59%] [G loss: 0.276566]\n",
      "epoch:15 step:14838 [D loss: 0.256738, acc.: 53.91%] [G loss: 0.298335]\n",
      "epoch:15 step:14839 [D loss: 0.256882, acc.: 53.91%] [G loss: 0.287216]\n",
      "epoch:15 step:14840 [D loss: 0.229139, acc.: 64.06%] [G loss: 0.313375]\n",
      "epoch:15 step:14841 [D loss: 0.249059, acc.: 54.69%] [G loss: 0.297900]\n",
      "epoch:15 step:14842 [D loss: 0.251046, acc.: 50.78%] [G loss: 0.275452]\n",
      "epoch:15 step:14843 [D loss: 0.245744, acc.: 54.69%] [G loss: 0.259847]\n",
      "epoch:15 step:14844 [D loss: 0.230714, acc.: 64.84%] [G loss: 0.275124]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:15 step:14845 [D loss: 0.239465, acc.: 58.59%] [G loss: 0.291350]\n",
      "epoch:15 step:14846 [D loss: 0.238650, acc.: 57.03%] [G loss: 0.304443]\n",
      "epoch:15 step:14847 [D loss: 0.237197, acc.: 59.38%] [G loss: 0.301638]\n",
      "epoch:15 step:14848 [D loss: 0.232106, acc.: 64.84%] [G loss: 0.290053]\n",
      "epoch:15 step:14849 [D loss: 0.227130, acc.: 61.72%] [G loss: 0.283306]\n",
      "epoch:15 step:14850 [D loss: 0.232623, acc.: 62.50%] [G loss: 0.313102]\n",
      "epoch:15 step:14851 [D loss: 0.242889, acc.: 55.47%] [G loss: 0.310697]\n",
      "epoch:15 step:14852 [D loss: 0.248132, acc.: 55.47%] [G loss: 0.292039]\n",
      "epoch:15 step:14853 [D loss: 0.237102, acc.: 61.72%] [G loss: 0.277193]\n",
      "epoch:15 step:14854 [D loss: 0.230155, acc.: 58.59%] [G loss: 0.281887]\n",
      "epoch:15 step:14855 [D loss: 0.246404, acc.: 60.16%] [G loss: 0.273515]\n",
      "epoch:15 step:14856 [D loss: 0.246593, acc.: 58.59%] [G loss: 0.317174]\n",
      "epoch:15 step:14857 [D loss: 0.250466, acc.: 53.12%] [G loss: 0.282475]\n",
      "epoch:15 step:14858 [D loss: 0.252887, acc.: 51.56%] [G loss: 0.267880]\n",
      "epoch:15 step:14859 [D loss: 0.235200, acc.: 60.94%] [G loss: 0.312327]\n",
      "epoch:15 step:14860 [D loss: 0.238752, acc.: 55.47%] [G loss: 0.301661]\n",
      "epoch:15 step:14861 [D loss: 0.235910, acc.: 57.81%] [G loss: 0.292507]\n",
      "epoch:15 step:14862 [D loss: 0.235998, acc.: 58.59%] [G loss: 0.280818]\n",
      "epoch:15 step:14863 [D loss: 0.238521, acc.: 59.38%] [G loss: 0.305587]\n",
      "epoch:15 step:14864 [D loss: 0.231663, acc.: 63.28%] [G loss: 0.304568]\n",
      "epoch:15 step:14865 [D loss: 0.243783, acc.: 53.12%] [G loss: 0.310243]\n",
      "epoch:15 step:14866 [D loss: 0.243492, acc.: 57.81%] [G loss: 0.335123]\n",
      "epoch:15 step:14867 [D loss: 0.229976, acc.: 63.28%] [G loss: 0.291924]\n",
      "epoch:15 step:14868 [D loss: 0.243159, acc.: 58.59%] [G loss: 0.316132]\n",
      "epoch:15 step:14869 [D loss: 0.238996, acc.: 56.25%] [G loss: 0.288941]\n",
      "epoch:15 step:14870 [D loss: 0.242370, acc.: 55.47%] [G loss: 0.316691]\n",
      "epoch:15 step:14871 [D loss: 0.230215, acc.: 62.50%] [G loss: 0.281249]\n",
      "epoch:15 step:14872 [D loss: 0.237458, acc.: 56.25%] [G loss: 0.302646]\n",
      "epoch:15 step:14873 [D loss: 0.230592, acc.: 58.59%] [G loss: 0.329631]\n",
      "epoch:15 step:14874 [D loss: 0.245541, acc.: 53.12%] [G loss: 0.317264]\n",
      "epoch:15 step:14875 [D loss: 0.235918, acc.: 64.84%] [G loss: 0.313483]\n",
      "epoch:15 step:14876 [D loss: 0.250348, acc.: 56.25%] [G loss: 0.303596]\n",
      "epoch:15 step:14877 [D loss: 0.232812, acc.: 60.16%] [G loss: 0.285123]\n",
      "epoch:15 step:14878 [D loss: 0.257576, acc.: 50.78%] [G loss: 0.331991]\n",
      "epoch:15 step:14879 [D loss: 0.231438, acc.: 62.50%] [G loss: 0.336153]\n",
      "epoch:15 step:14880 [D loss: 0.234003, acc.: 62.50%] [G loss: 0.316765]\n",
      "epoch:15 step:14881 [D loss: 0.223015, acc.: 60.94%] [G loss: 0.317589]\n",
      "epoch:15 step:14882 [D loss: 0.236676, acc.: 58.59%] [G loss: 0.281986]\n",
      "epoch:15 step:14883 [D loss: 0.250999, acc.: 50.00%] [G loss: 0.321438]\n",
      "epoch:15 step:14884 [D loss: 0.253970, acc.: 54.69%] [G loss: 0.281542]\n",
      "epoch:15 step:14885 [D loss: 0.219640, acc.: 64.06%] [G loss: 0.298522]\n",
      "epoch:15 step:14886 [D loss: 0.236090, acc.: 60.16%] [G loss: 0.292831]\n",
      "epoch:15 step:14887 [D loss: 0.226349, acc.: 65.62%] [G loss: 0.322620]\n",
      "epoch:15 step:14888 [D loss: 0.250167, acc.: 56.25%] [G loss: 0.281563]\n",
      "epoch:15 step:14889 [D loss: 0.258310, acc.: 53.12%] [G loss: 0.286868]\n",
      "epoch:15 step:14890 [D loss: 0.235296, acc.: 59.38%] [G loss: 0.290437]\n",
      "epoch:15 step:14891 [D loss: 0.227067, acc.: 60.16%] [G loss: 0.295086]\n",
      "epoch:15 step:14892 [D loss: 0.240430, acc.: 59.38%] [G loss: 0.314323]\n",
      "epoch:15 step:14893 [D loss: 0.248192, acc.: 57.03%] [G loss: 0.292453]\n",
      "epoch:15 step:14894 [D loss: 0.229489, acc.: 65.62%] [G loss: 0.298088]\n",
      "epoch:15 step:14895 [D loss: 0.231391, acc.: 59.38%] [G loss: 0.307727]\n",
      "epoch:15 step:14896 [D loss: 0.239661, acc.: 57.03%] [G loss: 0.324908]\n",
      "epoch:15 step:14897 [D loss: 0.235109, acc.: 60.16%] [G loss: 0.295546]\n",
      "epoch:15 step:14898 [D loss: 0.238052, acc.: 59.38%] [G loss: 0.275412]\n",
      "epoch:15 step:14899 [D loss: 0.237624, acc.: 53.12%] [G loss: 0.307242]\n",
      "epoch:15 step:14900 [D loss: 0.240708, acc.: 55.47%] [G loss: 0.297993]\n",
      "epoch:15 step:14901 [D loss: 0.253313, acc.: 53.91%] [G loss: 0.273064]\n",
      "epoch:15 step:14902 [D loss: 0.223995, acc.: 63.28%] [G loss: 0.287178]\n",
      "epoch:15 step:14903 [D loss: 0.253273, acc.: 56.25%] [G loss: 0.285818]\n",
      "epoch:15 step:14904 [D loss: 0.248455, acc.: 55.47%] [G loss: 0.324403]\n",
      "epoch:15 step:14905 [D loss: 0.249576, acc.: 56.25%] [G loss: 0.278237]\n",
      "epoch:15 step:14906 [D loss: 0.247414, acc.: 56.25%] [G loss: 0.285986]\n",
      "epoch:15 step:14907 [D loss: 0.257387, acc.: 47.66%] [G loss: 0.256364]\n",
      "epoch:15 step:14908 [D loss: 0.229503, acc.: 63.28%] [G loss: 0.307638]\n",
      "epoch:15 step:14909 [D loss: 0.238548, acc.: 57.81%] [G loss: 0.289253]\n",
      "epoch:15 step:14910 [D loss: 0.227563, acc.: 64.84%] [G loss: 0.294305]\n",
      "epoch:15 step:14911 [D loss: 0.237174, acc.: 61.72%] [G loss: 0.304611]\n",
      "epoch:15 step:14912 [D loss: 0.240471, acc.: 56.25%] [G loss: 0.302724]\n",
      "epoch:15 step:14913 [D loss: 0.247131, acc.: 50.00%] [G loss: 0.309339]\n",
      "epoch:15 step:14914 [D loss: 0.234059, acc.: 60.94%] [G loss: 0.282751]\n",
      "epoch:15 step:14915 [D loss: 0.238226, acc.: 59.38%] [G loss: 0.278217]\n",
      "epoch:15 step:14916 [D loss: 0.245845, acc.: 59.38%] [G loss: 0.311011]\n",
      "epoch:15 step:14917 [D loss: 0.238629, acc.: 55.47%] [G loss: 0.293205]\n",
      "epoch:15 step:14918 [D loss: 0.240047, acc.: 62.50%] [G loss: 0.318747]\n",
      "epoch:15 step:14919 [D loss: 0.236538, acc.: 59.38%] [G loss: 0.309111]\n",
      "epoch:15 step:14920 [D loss: 0.254715, acc.: 55.47%] [G loss: 0.306350]\n",
      "epoch:15 step:14921 [D loss: 0.228307, acc.: 62.50%] [G loss: 0.323141]\n",
      "epoch:15 step:14922 [D loss: 0.251990, acc.: 55.47%] [G loss: 0.277864]\n",
      "epoch:15 step:14923 [D loss: 0.221300, acc.: 62.50%] [G loss: 0.327846]\n",
      "epoch:15 step:14924 [D loss: 0.259678, acc.: 53.91%] [G loss: 0.285113]\n",
      "epoch:15 step:14925 [D loss: 0.252496, acc.: 51.56%] [G loss: 0.305603]\n",
      "epoch:15 step:14926 [D loss: 0.230544, acc.: 65.62%] [G loss: 0.309828]\n",
      "epoch:15 step:14927 [D loss: 0.240049, acc.: 60.16%] [G loss: 0.285741]\n",
      "epoch:15 step:14928 [D loss: 0.227273, acc.: 61.72%] [G loss: 0.324530]\n",
      "epoch:15 step:14929 [D loss: 0.234484, acc.: 60.94%] [G loss: 0.297931]\n",
      "epoch:15 step:14930 [D loss: 0.254144, acc.: 53.12%] [G loss: 0.292205]\n",
      "epoch:15 step:14931 [D loss: 0.235387, acc.: 63.28%] [G loss: 0.310763]\n",
      "epoch:15 step:14932 [D loss: 0.236089, acc.: 57.03%] [G loss: 0.311280]\n",
      "epoch:15 step:14933 [D loss: 0.247157, acc.: 53.91%] [G loss: 0.295685]\n",
      "epoch:15 step:14934 [D loss: 0.229143, acc.: 58.59%] [G loss: 0.285099]\n",
      "epoch:15 step:14935 [D loss: 0.240619, acc.: 57.81%] [G loss: 0.308286]\n",
      "epoch:15 step:14936 [D loss: 0.237048, acc.: 57.81%] [G loss: 0.308163]\n",
      "epoch:15 step:14937 [D loss: 0.232831, acc.: 57.03%] [G loss: 0.315721]\n",
      "epoch:15 step:14938 [D loss: 0.244659, acc.: 60.16%] [G loss: 0.292051]\n",
      "epoch:15 step:14939 [D loss: 0.227339, acc.: 62.50%] [G loss: 0.307858]\n",
      "epoch:15 step:14940 [D loss: 0.246085, acc.: 53.91%] [G loss: 0.298335]\n",
      "epoch:15 step:14941 [D loss: 0.237373, acc.: 58.59%] [G loss: 0.290587]\n",
      "epoch:15 step:14942 [D loss: 0.227638, acc.: 64.06%] [G loss: 0.317415]\n",
      "epoch:15 step:14943 [D loss: 0.247261, acc.: 58.59%] [G loss: 0.293103]\n",
      "epoch:15 step:14944 [D loss: 0.243251, acc.: 56.25%] [G loss: 0.310758]\n",
      "epoch:15 step:14945 [D loss: 0.234426, acc.: 60.16%] [G loss: 0.320077]\n",
      "epoch:15 step:14946 [D loss: 0.243060, acc.: 56.25%] [G loss: 0.331535]\n",
      "epoch:15 step:14947 [D loss: 0.253371, acc.: 57.81%] [G loss: 0.329869]\n",
      "epoch:15 step:14948 [D loss: 0.222314, acc.: 64.06%] [G loss: 0.329157]\n",
      "epoch:15 step:14949 [D loss: 0.251267, acc.: 56.25%] [G loss: 0.315275]\n",
      "epoch:15 step:14950 [D loss: 0.227731, acc.: 65.62%] [G loss: 0.300922]\n",
      "epoch:15 step:14951 [D loss: 0.235893, acc.: 60.16%] [G loss: 0.306509]\n",
      "epoch:15 step:14952 [D loss: 0.227309, acc.: 67.19%] [G loss: 0.309547]\n",
      "epoch:15 step:14953 [D loss: 0.224047, acc.: 60.16%] [G loss: 0.289412]\n",
      "epoch:15 step:14954 [D loss: 0.241252, acc.: 60.16%] [G loss: 0.307640]\n",
      "epoch:15 step:14955 [D loss: 0.224090, acc.: 66.41%] [G loss: 0.318478]\n",
      "epoch:15 step:14956 [D loss: 0.248047, acc.: 57.03%] [G loss: 0.302531]\n",
      "epoch:15 step:14957 [D loss: 0.244092, acc.: 58.59%] [G loss: 0.308810]\n",
      "epoch:15 step:14958 [D loss: 0.234507, acc.: 60.94%] [G loss: 0.307150]\n",
      "epoch:15 step:14959 [D loss: 0.249296, acc.: 53.12%] [G loss: 0.285701]\n",
      "epoch:15 step:14960 [D loss: 0.225855, acc.: 60.16%] [G loss: 0.318213]\n",
      "epoch:15 step:14961 [D loss: 0.241607, acc.: 55.47%] [G loss: 0.300608]\n",
      "epoch:15 step:14962 [D loss: 0.264612, acc.: 50.00%] [G loss: 0.315731]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:15 step:14963 [D loss: 0.262339, acc.: 49.22%] [G loss: 0.284319]\n",
      "epoch:15 step:14964 [D loss: 0.240656, acc.: 60.94%] [G loss: 0.287855]\n",
      "epoch:15 step:14965 [D loss: 0.233900, acc.: 60.94%] [G loss: 0.262229]\n",
      "epoch:15 step:14966 [D loss: 0.236484, acc.: 58.59%] [G loss: 0.286374]\n",
      "epoch:15 step:14967 [D loss: 0.246034, acc.: 52.34%] [G loss: 0.303127]\n",
      "epoch:15 step:14968 [D loss: 0.239272, acc.: 60.94%] [G loss: 0.304423]\n",
      "epoch:15 step:14969 [D loss: 0.227443, acc.: 64.06%] [G loss: 0.282796]\n",
      "epoch:15 step:14970 [D loss: 0.233386, acc.: 57.81%] [G loss: 0.288541]\n",
      "epoch:15 step:14971 [D loss: 0.234217, acc.: 59.38%] [G loss: 0.300041]\n",
      "epoch:15 step:14972 [D loss: 0.237015, acc.: 60.94%] [G loss: 0.325643]\n",
      "epoch:15 step:14973 [D loss: 0.224627, acc.: 66.41%] [G loss: 0.345661]\n",
      "epoch:15 step:14974 [D loss: 0.244918, acc.: 57.81%] [G loss: 0.298302]\n",
      "epoch:15 step:14975 [D loss: 0.227659, acc.: 62.50%] [G loss: 0.327457]\n",
      "epoch:15 step:14976 [D loss: 0.271166, acc.: 43.75%] [G loss: 0.294172]\n",
      "epoch:15 step:14977 [D loss: 0.241081, acc.: 62.50%] [G loss: 0.276919]\n",
      "epoch:15 step:14978 [D loss: 0.244690, acc.: 54.69%] [G loss: 0.313509]\n",
      "epoch:15 step:14979 [D loss: 0.242735, acc.: 57.81%] [G loss: 0.271959]\n",
      "epoch:15 step:14980 [D loss: 0.232604, acc.: 62.50%] [G loss: 0.347815]\n",
      "epoch:15 step:14981 [D loss: 0.233761, acc.: 57.81%] [G loss: 0.339360]\n",
      "epoch:15 step:14982 [D loss: 0.230435, acc.: 64.84%] [G loss: 0.341737]\n",
      "epoch:15 step:14983 [D loss: 0.220812, acc.: 63.28%] [G loss: 0.326402]\n",
      "epoch:15 step:14984 [D loss: 0.241100, acc.: 58.59%] [G loss: 0.302136]\n",
      "epoch:15 step:14985 [D loss: 0.230858, acc.: 62.50%] [G loss: 0.291197]\n",
      "epoch:15 step:14986 [D loss: 0.246774, acc.: 58.59%] [G loss: 0.306983]\n",
      "epoch:15 step:14987 [D loss: 0.250623, acc.: 53.91%] [G loss: 0.295289]\n",
      "epoch:15 step:14988 [D loss: 0.248700, acc.: 54.69%] [G loss: 0.317339]\n",
      "epoch:15 step:14989 [D loss: 0.221873, acc.: 66.41%] [G loss: 0.288885]\n",
      "epoch:15 step:14990 [D loss: 0.220156, acc.: 66.41%] [G loss: 0.314675]\n",
      "epoch:15 step:14991 [D loss: 0.230886, acc.: 57.03%] [G loss: 0.310453]\n",
      "epoch:15 step:14992 [D loss: 0.243699, acc.: 56.25%] [G loss: 0.302508]\n",
      "epoch:16 step:14993 [D loss: 0.247458, acc.: 58.59%] [G loss: 0.305874]\n",
      "epoch:16 step:14994 [D loss: 0.232529, acc.: 60.16%] [G loss: 0.322422]\n",
      "epoch:16 step:14995 [D loss: 0.226914, acc.: 66.41%] [G loss: 0.290766]\n",
      "epoch:16 step:14996 [D loss: 0.222961, acc.: 65.62%] [G loss: 0.299685]\n",
      "epoch:16 step:14997 [D loss: 0.246757, acc.: 57.03%] [G loss: 0.288506]\n",
      "epoch:16 step:14998 [D loss: 0.251411, acc.: 52.34%] [G loss: 0.266386]\n",
      "epoch:16 step:14999 [D loss: 0.244277, acc.: 55.47%] [G loss: 0.281044]\n",
      "epoch:16 step:15000 [D loss: 0.234775, acc.: 60.94%] [G loss: 0.281587]\n",
      "epoch:16 step:15001 [D loss: 0.231061, acc.: 60.94%] [G loss: 0.306985]\n",
      "epoch:16 step:15002 [D loss: 0.253604, acc.: 53.91%] [G loss: 0.294583]\n",
      "epoch:16 step:15003 [D loss: 0.222037, acc.: 60.16%] [G loss: 0.309898]\n",
      "epoch:16 step:15004 [D loss: 0.229514, acc.: 59.38%] [G loss: 0.276354]\n",
      "epoch:16 step:15005 [D loss: 0.212303, acc.: 69.53%] [G loss: 0.317235]\n",
      "epoch:16 step:15006 [D loss: 0.241213, acc.: 57.03%] [G loss: 0.298151]\n",
      "epoch:16 step:15007 [D loss: 0.233968, acc.: 65.62%] [G loss: 0.311486]\n",
      "epoch:16 step:15008 [D loss: 0.239957, acc.: 56.25%] [G loss: 0.272376]\n",
      "epoch:16 step:15009 [D loss: 0.240904, acc.: 59.38%] [G loss: 0.295744]\n",
      "epoch:16 step:15010 [D loss: 0.239768, acc.: 55.47%] [G loss: 0.294953]\n",
      "epoch:16 step:15011 [D loss: 0.265873, acc.: 46.88%] [G loss: 0.281691]\n",
      "epoch:16 step:15012 [D loss: 0.229960, acc.: 60.94%] [G loss: 0.305534]\n",
      "epoch:16 step:15013 [D loss: 0.223707, acc.: 65.62%] [G loss: 0.280722]\n",
      "epoch:16 step:15014 [D loss: 0.227006, acc.: 62.50%] [G loss: 0.305784]\n",
      "epoch:16 step:15015 [D loss: 0.249998, acc.: 52.34%] [G loss: 0.298336]\n",
      "epoch:16 step:15016 [D loss: 0.233835, acc.: 57.03%] [G loss: 0.298887]\n",
      "epoch:16 step:15017 [D loss: 0.243112, acc.: 57.81%] [G loss: 0.312030]\n",
      "epoch:16 step:15018 [D loss: 0.235349, acc.: 60.94%] [G loss: 0.296063]\n",
      "epoch:16 step:15019 [D loss: 0.235160, acc.: 56.25%] [G loss: 0.285626]\n",
      "epoch:16 step:15020 [D loss: 0.244539, acc.: 57.81%] [G loss: 0.285053]\n",
      "epoch:16 step:15021 [D loss: 0.239772, acc.: 59.38%] [G loss: 0.295038]\n",
      "epoch:16 step:15022 [D loss: 0.244466, acc.: 59.38%] [G loss: 0.290450]\n",
      "epoch:16 step:15023 [D loss: 0.220602, acc.: 65.62%] [G loss: 0.307058]\n",
      "epoch:16 step:15024 [D loss: 0.224125, acc.: 64.84%] [G loss: 0.322259]\n",
      "epoch:16 step:15025 [D loss: 0.236724, acc.: 55.47%] [G loss: 0.318950]\n",
      "epoch:16 step:15026 [D loss: 0.233052, acc.: 61.72%] [G loss: 0.309022]\n",
      "epoch:16 step:15027 [D loss: 0.233836, acc.: 65.62%] [G loss: 0.323901]\n",
      "epoch:16 step:15028 [D loss: 0.254753, acc.: 51.56%] [G loss: 0.287933]\n",
      "epoch:16 step:15029 [D loss: 0.227008, acc.: 68.75%] [G loss: 0.311577]\n",
      "epoch:16 step:15030 [D loss: 0.237344, acc.: 61.72%] [G loss: 0.309265]\n",
      "epoch:16 step:15031 [D loss: 0.228420, acc.: 64.84%] [G loss: 0.307119]\n",
      "epoch:16 step:15032 [D loss: 0.239822, acc.: 53.91%] [G loss: 0.322816]\n",
      "epoch:16 step:15033 [D loss: 0.227093, acc.: 61.72%] [G loss: 0.312432]\n",
      "epoch:16 step:15034 [D loss: 0.238432, acc.: 55.47%] [G loss: 0.332998]\n",
      "epoch:16 step:15035 [D loss: 0.216283, acc.: 64.06%] [G loss: 0.296641]\n",
      "epoch:16 step:15036 [D loss: 0.241825, acc.: 57.03%] [G loss: 0.299089]\n",
      "epoch:16 step:15037 [D loss: 0.253446, acc.: 51.56%] [G loss: 0.292572]\n",
      "epoch:16 step:15038 [D loss: 0.232637, acc.: 62.50%] [G loss: 0.292343]\n",
      "epoch:16 step:15039 [D loss: 0.244974, acc.: 51.56%] [G loss: 0.302007]\n",
      "epoch:16 step:15040 [D loss: 0.233883, acc.: 54.69%] [G loss: 0.296902]\n",
      "epoch:16 step:15041 [D loss: 0.238573, acc.: 58.59%] [G loss: 0.289328]\n",
      "epoch:16 step:15042 [D loss: 0.230122, acc.: 61.72%] [G loss: 0.274580]\n",
      "epoch:16 step:15043 [D loss: 0.220104, acc.: 62.50%] [G loss: 0.286579]\n",
      "epoch:16 step:15044 [D loss: 0.239012, acc.: 60.16%] [G loss: 0.298110]\n",
      "epoch:16 step:15045 [D loss: 0.243476, acc.: 55.47%] [G loss: 0.291582]\n",
      "epoch:16 step:15046 [D loss: 0.227457, acc.: 57.81%] [G loss: 0.292199]\n",
      "epoch:16 step:15047 [D loss: 0.219945, acc.: 67.19%] [G loss: 0.312071]\n",
      "epoch:16 step:15048 [D loss: 0.224927, acc.: 61.72%] [G loss: 0.310021]\n",
      "epoch:16 step:15049 [D loss: 0.236686, acc.: 60.94%] [G loss: 0.297333]\n",
      "epoch:16 step:15050 [D loss: 0.243309, acc.: 56.25%] [G loss: 0.279516]\n",
      "epoch:16 step:15051 [D loss: 0.244217, acc.: 57.81%] [G loss: 0.302964]\n",
      "epoch:16 step:15052 [D loss: 0.220977, acc.: 66.41%] [G loss: 0.323333]\n",
      "epoch:16 step:15053 [D loss: 0.244754, acc.: 57.03%] [G loss: 0.310800]\n",
      "epoch:16 step:15054 [D loss: 0.238311, acc.: 57.03%] [G loss: 0.299889]\n",
      "epoch:16 step:15055 [D loss: 0.230279, acc.: 63.28%] [G loss: 0.290441]\n",
      "epoch:16 step:15056 [D loss: 0.242593, acc.: 57.81%] [G loss: 0.306349]\n",
      "epoch:16 step:15057 [D loss: 0.246126, acc.: 55.47%] [G loss: 0.308962]\n",
      "epoch:16 step:15058 [D loss: 0.230264, acc.: 60.16%] [G loss: 0.290895]\n",
      "epoch:16 step:15059 [D loss: 0.229324, acc.: 62.50%] [G loss: 0.274995]\n",
      "epoch:16 step:15060 [D loss: 0.238219, acc.: 59.38%] [G loss: 0.312793]\n",
      "epoch:16 step:15061 [D loss: 0.243402, acc.: 59.38%] [G loss: 0.317131]\n",
      "epoch:16 step:15062 [D loss: 0.235401, acc.: 57.81%] [G loss: 0.293169]\n",
      "epoch:16 step:15063 [D loss: 0.228624, acc.: 67.19%] [G loss: 0.298921]\n",
      "epoch:16 step:15064 [D loss: 0.246500, acc.: 53.12%] [G loss: 0.305314]\n",
      "epoch:16 step:15065 [D loss: 0.229772, acc.: 60.94%] [G loss: 0.309948]\n",
      "epoch:16 step:15066 [D loss: 0.248216, acc.: 50.78%] [G loss: 0.289753]\n",
      "epoch:16 step:15067 [D loss: 0.234748, acc.: 56.25%] [G loss: 0.272030]\n",
      "epoch:16 step:15068 [D loss: 0.244487, acc.: 62.50%] [G loss: 0.311249]\n",
      "epoch:16 step:15069 [D loss: 0.260852, acc.: 50.00%] [G loss: 0.283299]\n",
      "epoch:16 step:15070 [D loss: 0.255919, acc.: 50.00%] [G loss: 0.302219]\n",
      "epoch:16 step:15071 [D loss: 0.240647, acc.: 53.91%] [G loss: 0.295154]\n",
      "epoch:16 step:15072 [D loss: 0.248465, acc.: 59.38%] [G loss: 0.308094]\n",
      "epoch:16 step:15073 [D loss: 0.238491, acc.: 57.03%] [G loss: 0.292042]\n",
      "epoch:16 step:15074 [D loss: 0.229057, acc.: 62.50%] [G loss: 0.325353]\n",
      "epoch:16 step:15075 [D loss: 0.237945, acc.: 60.94%] [G loss: 0.321041]\n",
      "epoch:16 step:15076 [D loss: 0.239866, acc.: 57.81%] [G loss: 0.265365]\n",
      "epoch:16 step:15077 [D loss: 0.223197, acc.: 71.09%] [G loss: 0.317977]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:16 step:15078 [D loss: 0.230995, acc.: 58.59%] [G loss: 0.313719]\n",
      "epoch:16 step:15079 [D loss: 0.242689, acc.: 57.81%] [G loss: 0.295624]\n",
      "epoch:16 step:15080 [D loss: 0.235602, acc.: 57.81%] [G loss: 0.302437]\n",
      "epoch:16 step:15081 [D loss: 0.241503, acc.: 60.94%] [G loss: 0.307993]\n",
      "epoch:16 step:15082 [D loss: 0.241910, acc.: 52.34%] [G loss: 0.293136]\n",
      "epoch:16 step:15083 [D loss: 0.228387, acc.: 62.50%] [G loss: 0.321168]\n",
      "epoch:16 step:15084 [D loss: 0.220508, acc.: 59.38%] [G loss: 0.318839]\n",
      "epoch:16 step:15085 [D loss: 0.230478, acc.: 57.81%] [G loss: 0.298067]\n",
      "epoch:16 step:15086 [D loss: 0.225149, acc.: 64.06%] [G loss: 0.325469]\n",
      "epoch:16 step:15087 [D loss: 0.249426, acc.: 53.91%] [G loss: 0.289062]\n",
      "epoch:16 step:15088 [D loss: 0.223153, acc.: 64.06%] [G loss: 0.282730]\n",
      "epoch:16 step:15089 [D loss: 0.253399, acc.: 59.38%] [G loss: 0.265096]\n",
      "epoch:16 step:15090 [D loss: 0.232050, acc.: 64.06%] [G loss: 0.289902]\n",
      "epoch:16 step:15091 [D loss: 0.246293, acc.: 60.94%] [G loss: 0.292401]\n",
      "epoch:16 step:15092 [D loss: 0.241680, acc.: 57.03%] [G loss: 0.321199]\n",
      "epoch:16 step:15093 [D loss: 0.238887, acc.: 57.03%] [G loss: 0.311130]\n",
      "epoch:16 step:15094 [D loss: 0.246397, acc.: 57.03%] [G loss: 0.293319]\n",
      "epoch:16 step:15095 [D loss: 0.231782, acc.: 62.50%] [G loss: 0.325156]\n",
      "epoch:16 step:15096 [D loss: 0.244127, acc.: 56.25%] [G loss: 0.273586]\n",
      "epoch:16 step:15097 [D loss: 0.242652, acc.: 58.59%] [G loss: 0.307270]\n",
      "epoch:16 step:15098 [D loss: 0.239311, acc.: 58.59%] [G loss: 0.306572]\n",
      "epoch:16 step:15099 [D loss: 0.238350, acc.: 61.72%] [G loss: 0.306438]\n",
      "epoch:16 step:15100 [D loss: 0.228280, acc.: 64.06%] [G loss: 0.318028]\n",
      "epoch:16 step:15101 [D loss: 0.224997, acc.: 61.72%] [G loss: 0.303282]\n",
      "epoch:16 step:15102 [D loss: 0.244317, acc.: 60.94%] [G loss: 0.297431]\n",
      "epoch:16 step:15103 [D loss: 0.229088, acc.: 60.16%] [G loss: 0.298046]\n",
      "epoch:16 step:15104 [D loss: 0.246233, acc.: 56.25%] [G loss: 0.291800]\n",
      "epoch:16 step:15105 [D loss: 0.238531, acc.: 59.38%] [G loss: 0.305478]\n",
      "epoch:16 step:15106 [D loss: 0.233372, acc.: 57.03%] [G loss: 0.308767]\n",
      "epoch:16 step:15107 [D loss: 0.238583, acc.: 58.59%] [G loss: 0.321379]\n",
      "epoch:16 step:15108 [D loss: 0.235641, acc.: 63.28%] [G loss: 0.284671]\n",
      "epoch:16 step:15109 [D loss: 0.227179, acc.: 60.16%] [G loss: 0.285221]\n",
      "epoch:16 step:15110 [D loss: 0.226982, acc.: 62.50%] [G loss: 0.289660]\n",
      "epoch:16 step:15111 [D loss: 0.246831, acc.: 56.25%] [G loss: 0.312520]\n",
      "epoch:16 step:15112 [D loss: 0.257956, acc.: 50.78%] [G loss: 0.285594]\n",
      "epoch:16 step:15113 [D loss: 0.235634, acc.: 56.25%] [G loss: 0.306516]\n",
      "epoch:16 step:15114 [D loss: 0.250300, acc.: 57.81%] [G loss: 0.277705]\n",
      "epoch:16 step:15115 [D loss: 0.231945, acc.: 61.72%] [G loss: 0.292436]\n",
      "epoch:16 step:15116 [D loss: 0.215553, acc.: 70.31%] [G loss: 0.311470]\n",
      "epoch:16 step:15117 [D loss: 0.251093, acc.: 56.25%] [G loss: 0.286127]\n",
      "epoch:16 step:15118 [D loss: 0.249952, acc.: 53.12%] [G loss: 0.325890]\n",
      "epoch:16 step:15119 [D loss: 0.238121, acc.: 60.16%] [G loss: 0.274577]\n",
      "epoch:16 step:15120 [D loss: 0.241484, acc.: 52.34%] [G loss: 0.308986]\n",
      "epoch:16 step:15121 [D loss: 0.226782, acc.: 60.94%] [G loss: 0.315420]\n",
      "epoch:16 step:15122 [D loss: 0.230212, acc.: 60.16%] [G loss: 0.298283]\n",
      "epoch:16 step:15123 [D loss: 0.235275, acc.: 62.50%] [G loss: 0.313083]\n",
      "epoch:16 step:15124 [D loss: 0.248853, acc.: 53.12%] [G loss: 0.312851]\n",
      "epoch:16 step:15125 [D loss: 0.235832, acc.: 59.38%] [G loss: 0.291675]\n",
      "epoch:16 step:15126 [D loss: 0.240635, acc.: 54.69%] [G loss: 0.300268]\n",
      "epoch:16 step:15127 [D loss: 0.237399, acc.: 58.59%] [G loss: 0.284306]\n",
      "epoch:16 step:15128 [D loss: 0.250172, acc.: 50.78%] [G loss: 0.268709]\n",
      "epoch:16 step:15129 [D loss: 0.234903, acc.: 64.84%] [G loss: 0.318718]\n",
      "epoch:16 step:15130 [D loss: 0.237859, acc.: 62.50%] [G loss: 0.291695]\n",
      "epoch:16 step:15131 [D loss: 0.242976, acc.: 53.91%] [G loss: 0.312598]\n",
      "epoch:16 step:15132 [D loss: 0.233056, acc.: 60.16%] [G loss: 0.326147]\n",
      "epoch:16 step:15133 [D loss: 0.252176, acc.: 51.56%] [G loss: 0.294469]\n",
      "epoch:16 step:15134 [D loss: 0.244417, acc.: 59.38%] [G loss: 0.296148]\n",
      "epoch:16 step:15135 [D loss: 0.248360, acc.: 57.81%] [G loss: 0.296288]\n",
      "epoch:16 step:15136 [D loss: 0.256266, acc.: 48.44%] [G loss: 0.310139]\n",
      "epoch:16 step:15137 [D loss: 0.251956, acc.: 53.91%] [G loss: 0.299402]\n",
      "epoch:16 step:15138 [D loss: 0.230233, acc.: 65.62%] [G loss: 0.306624]\n",
      "epoch:16 step:15139 [D loss: 0.218913, acc.: 67.19%] [G loss: 0.321220]\n",
      "epoch:16 step:15140 [D loss: 0.235018, acc.: 60.16%] [G loss: 0.291406]\n",
      "epoch:16 step:15141 [D loss: 0.246127, acc.: 64.06%] [G loss: 0.323149]\n",
      "epoch:16 step:15142 [D loss: 0.240575, acc.: 58.59%] [G loss: 0.296780]\n",
      "epoch:16 step:15143 [D loss: 0.243786, acc.: 54.69%] [G loss: 0.280334]\n",
      "epoch:16 step:15144 [D loss: 0.240066, acc.: 56.25%] [G loss: 0.296391]\n",
      "epoch:16 step:15145 [D loss: 0.235917, acc.: 58.59%] [G loss: 0.294073]\n",
      "epoch:16 step:15146 [D loss: 0.242774, acc.: 58.59%] [G loss: 0.283567]\n",
      "epoch:16 step:15147 [D loss: 0.238249, acc.: 62.50%] [G loss: 0.283658]\n",
      "epoch:16 step:15148 [D loss: 0.235108, acc.: 57.81%] [G loss: 0.303238]\n",
      "epoch:16 step:15149 [D loss: 0.247259, acc.: 53.91%] [G loss: 0.313963]\n",
      "epoch:16 step:15150 [D loss: 0.240182, acc.: 57.03%] [G loss: 0.280052]\n",
      "epoch:16 step:15151 [D loss: 0.231456, acc.: 62.50%] [G loss: 0.300104]\n",
      "epoch:16 step:15152 [D loss: 0.231893, acc.: 60.94%] [G loss: 0.331089]\n",
      "epoch:16 step:15153 [D loss: 0.259164, acc.: 52.34%] [G loss: 0.302008]\n",
      "epoch:16 step:15154 [D loss: 0.239435, acc.: 57.03%] [G loss: 0.287682]\n",
      "epoch:16 step:15155 [D loss: 0.248951, acc.: 61.72%] [G loss: 0.292442]\n",
      "epoch:16 step:15156 [D loss: 0.236112, acc.: 58.59%] [G loss: 0.274408]\n",
      "epoch:16 step:15157 [D loss: 0.246846, acc.: 57.81%] [G loss: 0.284975]\n",
      "epoch:16 step:15158 [D loss: 0.250633, acc.: 53.12%] [G loss: 0.333177]\n",
      "epoch:16 step:15159 [D loss: 0.232080, acc.: 60.16%] [G loss: 0.291127]\n",
      "epoch:16 step:15160 [D loss: 0.236365, acc.: 52.34%] [G loss: 0.290532]\n",
      "epoch:16 step:15161 [D loss: 0.237669, acc.: 56.25%] [G loss: 0.312291]\n",
      "epoch:16 step:15162 [D loss: 0.253462, acc.: 53.12%] [G loss: 0.330004]\n",
      "epoch:16 step:15163 [D loss: 0.234074, acc.: 64.06%] [G loss: 0.325273]\n",
      "epoch:16 step:15164 [D loss: 0.223136, acc.: 65.62%] [G loss: 0.294819]\n",
      "epoch:16 step:15165 [D loss: 0.234007, acc.: 59.38%] [G loss: 0.294040]\n",
      "epoch:16 step:15166 [D loss: 0.226343, acc.: 60.94%] [G loss: 0.296972]\n",
      "epoch:16 step:15167 [D loss: 0.243431, acc.: 58.59%] [G loss: 0.310337]\n",
      "epoch:16 step:15168 [D loss: 0.244873, acc.: 53.91%] [G loss: 0.293916]\n",
      "epoch:16 step:15169 [D loss: 0.213666, acc.: 71.09%] [G loss: 0.319127]\n",
      "epoch:16 step:15170 [D loss: 0.234846, acc.: 57.03%] [G loss: 0.291880]\n",
      "epoch:16 step:15171 [D loss: 0.243208, acc.: 59.38%] [G loss: 0.281762]\n",
      "epoch:16 step:15172 [D loss: 0.259908, acc.: 51.56%] [G loss: 0.274068]\n",
      "epoch:16 step:15173 [D loss: 0.247934, acc.: 53.91%] [G loss: 0.269230]\n",
      "epoch:16 step:15174 [D loss: 0.223905, acc.: 62.50%] [G loss: 0.292826]\n",
      "epoch:16 step:15175 [D loss: 0.260154, acc.: 47.66%] [G loss: 0.312052]\n",
      "epoch:16 step:15176 [D loss: 0.256621, acc.: 55.47%] [G loss: 0.295412]\n",
      "epoch:16 step:15177 [D loss: 0.259966, acc.: 47.66%] [G loss: 0.317746]\n",
      "epoch:16 step:15178 [D loss: 0.232082, acc.: 60.94%] [G loss: 0.316224]\n",
      "epoch:16 step:15179 [D loss: 0.243045, acc.: 60.16%] [G loss: 0.321316]\n",
      "epoch:16 step:15180 [D loss: 0.247855, acc.: 58.59%] [G loss: 0.308913]\n",
      "epoch:16 step:15181 [D loss: 0.238481, acc.: 60.94%] [G loss: 0.306208]\n",
      "epoch:16 step:15182 [D loss: 0.224325, acc.: 64.06%] [G loss: 0.306819]\n",
      "epoch:16 step:15183 [D loss: 0.237866, acc.: 63.28%] [G loss: 0.311161]\n",
      "epoch:16 step:15184 [D loss: 0.234420, acc.: 60.16%] [G loss: 0.310164]\n",
      "epoch:16 step:15185 [D loss: 0.251487, acc.: 50.00%] [G loss: 0.287335]\n",
      "epoch:16 step:15186 [D loss: 0.249116, acc.: 50.78%] [G loss: 0.264891]\n",
      "epoch:16 step:15187 [D loss: 0.219256, acc.: 66.41%] [G loss: 0.294674]\n",
      "epoch:16 step:15188 [D loss: 0.239039, acc.: 54.69%] [G loss: 0.319969]\n",
      "epoch:16 step:15189 [D loss: 0.234024, acc.: 60.16%] [G loss: 0.279821]\n",
      "epoch:16 step:15190 [D loss: 0.239526, acc.: 59.38%] [G loss: 0.282867]\n",
      "epoch:16 step:15191 [D loss: 0.228397, acc.: 63.28%] [G loss: 0.304476]\n",
      "epoch:16 step:15192 [D loss: 0.240214, acc.: 62.50%] [G loss: 0.275573]\n",
      "epoch:16 step:15193 [D loss: 0.241575, acc.: 55.47%] [G loss: 0.291378]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:16 step:15194 [D loss: 0.230010, acc.: 62.50%] [G loss: 0.298379]\n",
      "epoch:16 step:15195 [D loss: 0.262240, acc.: 50.78%] [G loss: 0.315541]\n",
      "epoch:16 step:15196 [D loss: 0.228630, acc.: 64.84%] [G loss: 0.291106]\n",
      "epoch:16 step:15197 [D loss: 0.245865, acc.: 56.25%] [G loss: 0.319175]\n",
      "epoch:16 step:15198 [D loss: 0.233759, acc.: 60.16%] [G loss: 0.295029]\n",
      "epoch:16 step:15199 [D loss: 0.237506, acc.: 60.16%] [G loss: 0.302227]\n",
      "epoch:16 step:15200 [D loss: 0.243558, acc.: 53.91%] [G loss: 0.293259]\n",
      "epoch:16 step:15201 [D loss: 0.224268, acc.: 63.28%] [G loss: 0.313482]\n",
      "epoch:16 step:15202 [D loss: 0.235840, acc.: 61.72%] [G loss: 0.274294]\n",
      "epoch:16 step:15203 [D loss: 0.243239, acc.: 60.94%] [G loss: 0.308425]\n",
      "epoch:16 step:15204 [D loss: 0.232529, acc.: 60.16%] [G loss: 0.283236]\n",
      "epoch:16 step:15205 [D loss: 0.219925, acc.: 67.97%] [G loss: 0.281150]\n",
      "epoch:16 step:15206 [D loss: 0.253565, acc.: 51.56%] [G loss: 0.283917]\n",
      "epoch:16 step:15207 [D loss: 0.221005, acc.: 63.28%] [G loss: 0.312168]\n",
      "epoch:16 step:15208 [D loss: 0.241998, acc.: 54.69%] [G loss: 0.300821]\n",
      "epoch:16 step:15209 [D loss: 0.241158, acc.: 55.47%] [G loss: 0.293142]\n",
      "epoch:16 step:15210 [D loss: 0.237380, acc.: 55.47%] [G loss: 0.270717]\n",
      "epoch:16 step:15211 [D loss: 0.242638, acc.: 57.03%] [G loss: 0.281511]\n",
      "epoch:16 step:15212 [D loss: 0.241973, acc.: 55.47%] [G loss: 0.300773]\n",
      "epoch:16 step:15213 [D loss: 0.234007, acc.: 62.50%] [G loss: 0.308450]\n",
      "epoch:16 step:15214 [D loss: 0.237430, acc.: 60.94%] [G loss: 0.304726]\n",
      "epoch:16 step:15215 [D loss: 0.251069, acc.: 53.91%] [G loss: 0.272255]\n",
      "epoch:16 step:15216 [D loss: 0.258211, acc.: 43.75%] [G loss: 0.313705]\n",
      "epoch:16 step:15217 [D loss: 0.239284, acc.: 51.56%] [G loss: 0.284983]\n",
      "epoch:16 step:15218 [D loss: 0.244692, acc.: 58.59%] [G loss: 0.289829]\n",
      "epoch:16 step:15219 [D loss: 0.244237, acc.: 58.59%] [G loss: 0.294216]\n",
      "epoch:16 step:15220 [D loss: 0.252440, acc.: 53.12%] [G loss: 0.290302]\n",
      "epoch:16 step:15221 [D loss: 0.248133, acc.: 52.34%] [G loss: 0.323561]\n",
      "epoch:16 step:15222 [D loss: 0.246650, acc.: 53.12%] [G loss: 0.282485]\n",
      "epoch:16 step:15223 [D loss: 0.254597, acc.: 51.56%] [G loss: 0.287017]\n",
      "epoch:16 step:15224 [D loss: 0.236368, acc.: 57.03%] [G loss: 0.299005]\n",
      "epoch:16 step:15225 [D loss: 0.254656, acc.: 56.25%] [G loss: 0.276580]\n",
      "epoch:16 step:15226 [D loss: 0.241536, acc.: 60.94%] [G loss: 0.282732]\n",
      "epoch:16 step:15227 [D loss: 0.232023, acc.: 57.03%] [G loss: 0.290263]\n",
      "epoch:16 step:15228 [D loss: 0.224823, acc.: 67.19%] [G loss: 0.279452]\n",
      "epoch:16 step:15229 [D loss: 0.249866, acc.: 49.22%] [G loss: 0.292515]\n",
      "epoch:16 step:15230 [D loss: 0.236024, acc.: 60.16%] [G loss: 0.279593]\n",
      "epoch:16 step:15231 [D loss: 0.242013, acc.: 59.38%] [G loss: 0.321774]\n",
      "epoch:16 step:15232 [D loss: 0.232002, acc.: 65.62%] [G loss: 0.306849]\n",
      "epoch:16 step:15233 [D loss: 0.230435, acc.: 64.06%] [G loss: 0.328518]\n",
      "epoch:16 step:15234 [D loss: 0.249850, acc.: 54.69%] [G loss: 0.303819]\n",
      "epoch:16 step:15235 [D loss: 0.245598, acc.: 56.25%] [G loss: 0.267999]\n",
      "epoch:16 step:15236 [D loss: 0.244513, acc.: 56.25%] [G loss: 0.304728]\n",
      "epoch:16 step:15237 [D loss: 0.243438, acc.: 50.78%] [G loss: 0.278861]\n",
      "epoch:16 step:15238 [D loss: 0.242346, acc.: 57.81%] [G loss: 0.282969]\n",
      "epoch:16 step:15239 [D loss: 0.241797, acc.: 57.03%] [G loss: 0.293897]\n",
      "epoch:16 step:15240 [D loss: 0.241346, acc.: 61.72%] [G loss: 0.295651]\n",
      "epoch:16 step:15241 [D loss: 0.251353, acc.: 53.91%] [G loss: 0.295661]\n",
      "epoch:16 step:15242 [D loss: 0.235965, acc.: 56.25%] [G loss: 0.267841]\n",
      "epoch:16 step:15243 [D loss: 0.238110, acc.: 58.59%] [G loss: 0.317152]\n",
      "epoch:16 step:15244 [D loss: 0.247676, acc.: 51.56%] [G loss: 0.288878]\n",
      "epoch:16 step:15245 [D loss: 0.246263, acc.: 57.03%] [G loss: 0.290827]\n",
      "epoch:16 step:15246 [D loss: 0.247492, acc.: 58.59%] [G loss: 0.295785]\n",
      "epoch:16 step:15247 [D loss: 0.231946, acc.: 56.25%] [G loss: 0.326666]\n",
      "epoch:16 step:15248 [D loss: 0.233191, acc.: 61.72%] [G loss: 0.323670]\n",
      "epoch:16 step:15249 [D loss: 0.245947, acc.: 57.81%] [G loss: 0.283616]\n",
      "epoch:16 step:15250 [D loss: 0.244919, acc.: 58.59%] [G loss: 0.307145]\n",
      "epoch:16 step:15251 [D loss: 0.231163, acc.: 62.50%] [G loss: 0.329727]\n",
      "epoch:16 step:15252 [D loss: 0.248678, acc.: 54.69%] [G loss: 0.304043]\n",
      "epoch:16 step:15253 [D loss: 0.229336, acc.: 64.84%] [G loss: 0.327428]\n",
      "epoch:16 step:15254 [D loss: 0.235083, acc.: 63.28%] [G loss: 0.319939]\n",
      "epoch:16 step:15255 [D loss: 0.226084, acc.: 62.50%] [G loss: 0.327696]\n",
      "epoch:16 step:15256 [D loss: 0.249292, acc.: 56.25%] [G loss: 0.293360]\n",
      "epoch:16 step:15257 [D loss: 0.239569, acc.: 58.59%] [G loss: 0.305401]\n",
      "epoch:16 step:15258 [D loss: 0.246373, acc.: 49.22%] [G loss: 0.298849]\n",
      "epoch:16 step:15259 [D loss: 0.236857, acc.: 64.06%] [G loss: 0.287616]\n",
      "epoch:16 step:15260 [D loss: 0.244593, acc.: 52.34%] [G loss: 0.298138]\n",
      "epoch:16 step:15261 [D loss: 0.224216, acc.: 56.25%] [G loss: 0.321812]\n",
      "epoch:16 step:15262 [D loss: 0.247949, acc.: 52.34%] [G loss: 0.320118]\n",
      "epoch:16 step:15263 [D loss: 0.249100, acc.: 57.81%] [G loss: 0.275601]\n",
      "epoch:16 step:15264 [D loss: 0.229113, acc.: 59.38%] [G loss: 0.289192]\n",
      "epoch:16 step:15265 [D loss: 0.258572, acc.: 52.34%] [G loss: 0.276670]\n",
      "epoch:16 step:15266 [D loss: 0.233075, acc.: 57.81%] [G loss: 0.289010]\n",
      "epoch:16 step:15267 [D loss: 0.259276, acc.: 46.09%] [G loss: 0.299038]\n",
      "epoch:16 step:15268 [D loss: 0.233711, acc.: 64.06%] [G loss: 0.324078]\n",
      "epoch:16 step:15269 [D loss: 0.238655, acc.: 57.81%] [G loss: 0.294683]\n",
      "epoch:16 step:15270 [D loss: 0.230030, acc.: 59.38%] [G loss: 0.294045]\n",
      "epoch:16 step:15271 [D loss: 0.226472, acc.: 65.62%] [G loss: 0.307061]\n",
      "epoch:16 step:15272 [D loss: 0.221435, acc.: 65.62%] [G loss: 0.291076]\n",
      "epoch:16 step:15273 [D loss: 0.237404, acc.: 59.38%] [G loss: 0.291748]\n",
      "epoch:16 step:15274 [D loss: 0.238413, acc.: 53.91%] [G loss: 0.304014]\n",
      "epoch:16 step:15275 [D loss: 0.226118, acc.: 57.81%] [G loss: 0.304957]\n",
      "epoch:16 step:15276 [D loss: 0.222994, acc.: 61.72%] [G loss: 0.334713]\n",
      "epoch:16 step:15277 [D loss: 0.246026, acc.: 53.12%] [G loss: 0.321604]\n",
      "epoch:16 step:15278 [D loss: 0.242491, acc.: 59.38%] [G loss: 0.310606]\n",
      "epoch:16 step:15279 [D loss: 0.222269, acc.: 69.53%] [G loss: 0.306131]\n",
      "epoch:16 step:15280 [D loss: 0.242639, acc.: 58.59%] [G loss: 0.290514]\n",
      "epoch:16 step:15281 [D loss: 0.249620, acc.: 50.00%] [G loss: 0.307077]\n",
      "epoch:16 step:15282 [D loss: 0.259326, acc.: 50.00%] [G loss: 0.284667]\n",
      "epoch:16 step:15283 [D loss: 0.257197, acc.: 53.91%] [G loss: 0.297143]\n",
      "epoch:16 step:15284 [D loss: 0.245463, acc.: 61.72%] [G loss: 0.321669]\n",
      "epoch:16 step:15285 [D loss: 0.246404, acc.: 54.69%] [G loss: 0.282150]\n",
      "epoch:16 step:15286 [D loss: 0.237920, acc.: 59.38%] [G loss: 0.312567]\n",
      "epoch:16 step:15287 [D loss: 0.229896, acc.: 57.81%] [G loss: 0.313847]\n",
      "epoch:16 step:15288 [D loss: 0.228107, acc.: 60.94%] [G loss: 0.282216]\n",
      "epoch:16 step:15289 [D loss: 0.244772, acc.: 58.59%] [G loss: 0.302399]\n",
      "epoch:16 step:15290 [D loss: 0.235956, acc.: 59.38%] [G loss: 0.280411]\n",
      "epoch:16 step:15291 [D loss: 0.242654, acc.: 58.59%] [G loss: 0.299855]\n",
      "epoch:16 step:15292 [D loss: 0.223807, acc.: 67.19%] [G loss: 0.288470]\n",
      "epoch:16 step:15293 [D loss: 0.230659, acc.: 56.25%] [G loss: 0.310141]\n",
      "epoch:16 step:15294 [D loss: 0.249756, acc.: 54.69%] [G loss: 0.282192]\n",
      "epoch:16 step:15295 [D loss: 0.226316, acc.: 62.50%] [G loss: 0.306180]\n",
      "epoch:16 step:15296 [D loss: 0.247527, acc.: 53.91%] [G loss: 0.302162]\n",
      "epoch:16 step:15297 [D loss: 0.258193, acc.: 58.59%] [G loss: 0.276488]\n",
      "epoch:16 step:15298 [D loss: 0.229632, acc.: 60.94%] [G loss: 0.302254]\n",
      "epoch:16 step:15299 [D loss: 0.262566, acc.: 51.56%] [G loss: 0.270549]\n",
      "epoch:16 step:15300 [D loss: 0.247239, acc.: 56.25%] [G loss: 0.287163]\n",
      "epoch:16 step:15301 [D loss: 0.232116, acc.: 52.34%] [G loss: 0.295865]\n",
      "epoch:16 step:15302 [D loss: 0.261842, acc.: 47.66%] [G loss: 0.267163]\n",
      "epoch:16 step:15303 [D loss: 0.241256, acc.: 52.34%] [G loss: 0.301734]\n",
      "epoch:16 step:15304 [D loss: 0.238194, acc.: 51.56%] [G loss: 0.285961]\n",
      "epoch:16 step:15305 [D loss: 0.269142, acc.: 48.44%] [G loss: 0.288742]\n",
      "epoch:16 step:15306 [D loss: 0.231335, acc.: 60.16%] [G loss: 0.304534]\n",
      "epoch:16 step:15307 [D loss: 0.230155, acc.: 59.38%] [G loss: 0.320066]\n",
      "epoch:16 step:15308 [D loss: 0.238855, acc.: 61.72%] [G loss: 0.303820]\n",
      "epoch:16 step:15309 [D loss: 0.234724, acc.: 57.81%] [G loss: 0.298009]\n",
      "epoch:16 step:15310 [D loss: 0.239300, acc.: 59.38%] [G loss: 0.304621]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:16 step:15311 [D loss: 0.226483, acc.: 60.94%] [G loss: 0.295740]\n",
      "epoch:16 step:15312 [D loss: 0.234074, acc.: 58.59%] [G loss: 0.307655]\n",
      "epoch:16 step:15313 [D loss: 0.248088, acc.: 54.69%] [G loss: 0.328049]\n",
      "epoch:16 step:15314 [D loss: 0.257404, acc.: 50.00%] [G loss: 0.291839]\n",
      "epoch:16 step:15315 [D loss: 0.236028, acc.: 53.12%] [G loss: 0.316544]\n",
      "epoch:16 step:15316 [D loss: 0.226449, acc.: 59.38%] [G loss: 0.319423]\n",
      "epoch:16 step:15317 [D loss: 0.239496, acc.: 57.03%] [G loss: 0.286330]\n",
      "epoch:16 step:15318 [D loss: 0.233944, acc.: 60.16%] [G loss: 0.288172]\n",
      "epoch:16 step:15319 [D loss: 0.251333, acc.: 53.12%] [G loss: 0.278968]\n",
      "epoch:16 step:15320 [D loss: 0.219836, acc.: 67.19%] [G loss: 0.298105]\n",
      "epoch:16 step:15321 [D loss: 0.232787, acc.: 63.28%] [G loss: 0.311837]\n",
      "epoch:16 step:15322 [D loss: 0.252390, acc.: 51.56%] [G loss: 0.337429]\n",
      "epoch:16 step:15323 [D loss: 0.230901, acc.: 57.03%] [G loss: 0.282369]\n",
      "epoch:16 step:15324 [D loss: 0.240990, acc.: 57.81%] [G loss: 0.298653]\n",
      "epoch:16 step:15325 [D loss: 0.248878, acc.: 52.34%] [G loss: 0.287116]\n",
      "epoch:16 step:15326 [D loss: 0.225574, acc.: 62.50%] [G loss: 0.301411]\n",
      "epoch:16 step:15327 [D loss: 0.233237, acc.: 59.38%] [G loss: 0.320831]\n",
      "epoch:16 step:15328 [D loss: 0.241919, acc.: 54.69%] [G loss: 0.312304]\n",
      "epoch:16 step:15329 [D loss: 0.225001, acc.: 65.62%] [G loss: 0.298458]\n",
      "epoch:16 step:15330 [D loss: 0.231390, acc.: 59.38%] [G loss: 0.303171]\n",
      "epoch:16 step:15331 [D loss: 0.224447, acc.: 63.28%] [G loss: 0.294787]\n",
      "epoch:16 step:15332 [D loss: 0.241900, acc.: 57.81%] [G loss: 0.275071]\n",
      "epoch:16 step:15333 [D loss: 0.255567, acc.: 50.00%] [G loss: 0.287447]\n",
      "epoch:16 step:15334 [D loss: 0.232741, acc.: 65.62%] [G loss: 0.296499]\n",
      "epoch:16 step:15335 [D loss: 0.238214, acc.: 60.94%] [G loss: 0.306924]\n",
      "epoch:16 step:15336 [D loss: 0.238662, acc.: 57.81%] [G loss: 0.290793]\n",
      "epoch:16 step:15337 [D loss: 0.220379, acc.: 66.41%] [G loss: 0.308639]\n",
      "epoch:16 step:15338 [D loss: 0.251372, acc.: 53.91%] [G loss: 0.332293]\n",
      "epoch:16 step:15339 [D loss: 0.242847, acc.: 60.16%] [G loss: 0.303655]\n",
      "epoch:16 step:15340 [D loss: 0.248859, acc.: 57.81%] [G loss: 0.283977]\n",
      "epoch:16 step:15341 [D loss: 0.246705, acc.: 53.91%] [G loss: 0.291153]\n",
      "epoch:16 step:15342 [D loss: 0.234203, acc.: 60.16%] [G loss: 0.322393]\n",
      "epoch:16 step:15343 [D loss: 0.245809, acc.: 57.03%] [G loss: 0.296441]\n",
      "epoch:16 step:15344 [D loss: 0.248401, acc.: 54.69%] [G loss: 0.306670]\n",
      "epoch:16 step:15345 [D loss: 0.226661, acc.: 61.72%] [G loss: 0.313169]\n",
      "epoch:16 step:15346 [D loss: 0.230796, acc.: 62.50%] [G loss: 0.306461]\n",
      "epoch:16 step:15347 [D loss: 0.244041, acc.: 55.47%] [G loss: 0.295806]\n",
      "epoch:16 step:15348 [D loss: 0.240890, acc.: 60.16%] [G loss: 0.276291]\n",
      "epoch:16 step:15349 [D loss: 0.232479, acc.: 63.28%] [G loss: 0.307026]\n",
      "epoch:16 step:15350 [D loss: 0.241190, acc.: 57.81%] [G loss: 0.313479]\n",
      "epoch:16 step:15351 [D loss: 0.241907, acc.: 55.47%] [G loss: 0.297826]\n",
      "epoch:16 step:15352 [D loss: 0.245003, acc.: 56.25%] [G loss: 0.316873]\n",
      "epoch:16 step:15353 [D loss: 0.246718, acc.: 57.03%] [G loss: 0.293117]\n",
      "epoch:16 step:15354 [D loss: 0.239729, acc.: 53.91%] [G loss: 0.310908]\n",
      "epoch:16 step:15355 [D loss: 0.242225, acc.: 57.03%] [G loss: 0.290680]\n",
      "epoch:16 step:15356 [D loss: 0.224530, acc.: 62.50%] [G loss: 0.317493]\n",
      "epoch:16 step:15357 [D loss: 0.238078, acc.: 60.94%] [G loss: 0.312030]\n",
      "epoch:16 step:15358 [D loss: 0.240809, acc.: 58.59%] [G loss: 0.317552]\n",
      "epoch:16 step:15359 [D loss: 0.233575, acc.: 62.50%] [G loss: 0.313283]\n",
      "epoch:16 step:15360 [D loss: 0.244564, acc.: 58.59%] [G loss: 0.293374]\n",
      "epoch:16 step:15361 [D loss: 0.260971, acc.: 49.22%] [G loss: 0.331532]\n",
      "epoch:16 step:15362 [D loss: 0.245309, acc.: 56.25%] [G loss: 0.351124]\n",
      "epoch:16 step:15363 [D loss: 0.245856, acc.: 58.59%] [G loss: 0.305663]\n",
      "epoch:16 step:15364 [D loss: 0.217820, acc.: 66.41%] [G loss: 0.314026]\n",
      "epoch:16 step:15365 [D loss: 0.229716, acc.: 63.28%] [G loss: 0.316518]\n",
      "epoch:16 step:15366 [D loss: 0.242217, acc.: 56.25%] [G loss: 0.316605]\n",
      "epoch:16 step:15367 [D loss: 0.235849, acc.: 65.62%] [G loss: 0.297618]\n",
      "epoch:16 step:15368 [D loss: 0.266131, acc.: 45.31%] [G loss: 0.301855]\n",
      "epoch:16 step:15369 [D loss: 0.227735, acc.: 64.84%] [G loss: 0.298056]\n",
      "epoch:16 step:15370 [D loss: 0.235428, acc.: 54.69%] [G loss: 0.323512]\n",
      "epoch:16 step:15371 [D loss: 0.238884, acc.: 59.38%] [G loss: 0.298155]\n",
      "epoch:16 step:15372 [D loss: 0.248048, acc.: 57.81%] [G loss: 0.289780]\n",
      "epoch:16 step:15373 [D loss: 0.241120, acc.: 57.81%] [G loss: 0.299899]\n",
      "epoch:16 step:15374 [D loss: 0.227590, acc.: 63.28%] [G loss: 0.333981]\n",
      "epoch:16 step:15375 [D loss: 0.232254, acc.: 61.72%] [G loss: 0.303201]\n",
      "epoch:16 step:15376 [D loss: 0.242462, acc.: 52.34%] [G loss: 0.302974]\n",
      "epoch:16 step:15377 [D loss: 0.234408, acc.: 58.59%] [G loss: 0.288564]\n",
      "epoch:16 step:15378 [D loss: 0.240103, acc.: 58.59%] [G loss: 0.285071]\n",
      "epoch:16 step:15379 [D loss: 0.230961, acc.: 60.16%] [G loss: 0.289762]\n",
      "epoch:16 step:15380 [D loss: 0.239196, acc.: 57.03%] [G loss: 0.308609]\n",
      "epoch:16 step:15381 [D loss: 0.234236, acc.: 61.72%] [G loss: 0.296364]\n",
      "epoch:16 step:15382 [D loss: 0.244586, acc.: 53.12%] [G loss: 0.284308]\n",
      "epoch:16 step:15383 [D loss: 0.242932, acc.: 61.72%] [G loss: 0.281378]\n",
      "epoch:16 step:15384 [D loss: 0.227629, acc.: 60.94%] [G loss: 0.312111]\n",
      "epoch:16 step:15385 [D loss: 0.249364, acc.: 53.91%] [G loss: 0.297192]\n",
      "epoch:16 step:15386 [D loss: 0.239738, acc.: 58.59%] [G loss: 0.315340]\n",
      "epoch:16 step:15387 [D loss: 0.236793, acc.: 57.81%] [G loss: 0.311461]\n",
      "epoch:16 step:15388 [D loss: 0.234522, acc.: 60.16%] [G loss: 0.300713]\n",
      "epoch:16 step:15389 [D loss: 0.254671, acc.: 53.12%] [G loss: 0.328037]\n",
      "epoch:16 step:15390 [D loss: 0.247262, acc.: 54.69%] [G loss: 0.314427]\n",
      "epoch:16 step:15391 [D loss: 0.236511, acc.: 57.81%] [G loss: 0.323469]\n",
      "epoch:16 step:15392 [D loss: 0.231444, acc.: 61.72%] [G loss: 0.293386]\n",
      "epoch:16 step:15393 [D loss: 0.235713, acc.: 57.81%] [G loss: 0.298726]\n",
      "epoch:16 step:15394 [D loss: 0.232073, acc.: 54.69%] [G loss: 0.301433]\n",
      "epoch:16 step:15395 [D loss: 0.244453, acc.: 59.38%] [G loss: 0.323571]\n",
      "epoch:16 step:15396 [D loss: 0.244125, acc.: 55.47%] [G loss: 0.291989]\n",
      "epoch:16 step:15397 [D loss: 0.230682, acc.: 61.72%] [G loss: 0.312780]\n",
      "epoch:16 step:15398 [D loss: 0.249847, acc.: 55.47%] [G loss: 0.284952]\n",
      "epoch:16 step:15399 [D loss: 0.233081, acc.: 64.06%] [G loss: 0.282173]\n",
      "epoch:16 step:15400 [D loss: 0.241732, acc.: 58.59%] [G loss: 0.308254]\n",
      "epoch:16 step:15401 [D loss: 0.246897, acc.: 56.25%] [G loss: 0.313633]\n",
      "epoch:16 step:15402 [D loss: 0.262040, acc.: 51.56%] [G loss: 0.346031]\n",
      "epoch:16 step:15403 [D loss: 0.248805, acc.: 54.69%] [G loss: 0.273756]\n",
      "epoch:16 step:15404 [D loss: 0.220335, acc.: 70.31%] [G loss: 0.284940]\n",
      "epoch:16 step:15405 [D loss: 0.232302, acc.: 56.25%] [G loss: 0.331119]\n",
      "epoch:16 step:15406 [D loss: 0.239249, acc.: 58.59%] [G loss: 0.315411]\n",
      "epoch:16 step:15407 [D loss: 0.242498, acc.: 54.69%] [G loss: 0.273268]\n",
      "epoch:16 step:15408 [D loss: 0.233215, acc.: 58.59%] [G loss: 0.308807]\n",
      "epoch:16 step:15409 [D loss: 0.243434, acc.: 54.69%] [G loss: 0.325261]\n",
      "epoch:16 step:15410 [D loss: 0.239036, acc.: 59.38%] [G loss: 0.305209]\n",
      "epoch:16 step:15411 [D loss: 0.240461, acc.: 56.25%] [G loss: 0.295078]\n",
      "epoch:16 step:15412 [D loss: 0.227219, acc.: 64.84%] [G loss: 0.304162]\n",
      "epoch:16 step:15413 [D loss: 0.217078, acc.: 63.28%] [G loss: 0.308278]\n",
      "epoch:16 step:15414 [D loss: 0.234901, acc.: 64.06%] [G loss: 0.289043]\n",
      "epoch:16 step:15415 [D loss: 0.240898, acc.: 59.38%] [G loss: 0.316207]\n",
      "epoch:16 step:15416 [D loss: 0.231396, acc.: 63.28%] [G loss: 0.277247]\n",
      "epoch:16 step:15417 [D loss: 0.252107, acc.: 54.69%] [G loss: 0.271382]\n",
      "epoch:16 step:15418 [D loss: 0.226946, acc.: 63.28%] [G loss: 0.293715]\n",
      "epoch:16 step:15419 [D loss: 0.246456, acc.: 55.47%] [G loss: 0.292014]\n",
      "epoch:16 step:15420 [D loss: 0.237266, acc.: 58.59%] [G loss: 0.290782]\n",
      "epoch:16 step:15421 [D loss: 0.240736, acc.: 57.03%] [G loss: 0.288813]\n",
      "epoch:16 step:15422 [D loss: 0.236221, acc.: 55.47%] [G loss: 0.325230]\n",
      "epoch:16 step:15423 [D loss: 0.237338, acc.: 58.59%] [G loss: 0.313204]\n",
      "epoch:16 step:15424 [D loss: 0.234100, acc.: 59.38%] [G loss: 0.297399]\n",
      "epoch:16 step:15425 [D loss: 0.241411, acc.: 60.16%] [G loss: 0.280492]\n",
      "epoch:16 step:15426 [D loss: 0.232877, acc.: 61.72%] [G loss: 0.296996]\n",
      "epoch:16 step:15427 [D loss: 0.232846, acc.: 55.47%] [G loss: 0.299941]\n",
      "epoch:16 step:15428 [D loss: 0.251041, acc.: 54.69%] [G loss: 0.278000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:16 step:15429 [D loss: 0.234565, acc.: 57.81%] [G loss: 0.352831]\n",
      "epoch:16 step:15430 [D loss: 0.236863, acc.: 58.59%] [G loss: 0.309745]\n",
      "epoch:16 step:15431 [D loss: 0.234290, acc.: 56.25%] [G loss: 0.270997]\n",
      "epoch:16 step:15432 [D loss: 0.244150, acc.: 53.12%] [G loss: 0.328337]\n",
      "epoch:16 step:15433 [D loss: 0.247371, acc.: 55.47%] [G loss: 0.292786]\n",
      "epoch:16 step:15434 [D loss: 0.249390, acc.: 52.34%] [G loss: 0.290568]\n",
      "epoch:16 step:15435 [D loss: 0.225404, acc.: 65.62%] [G loss: 0.293181]\n",
      "epoch:16 step:15436 [D loss: 0.236738, acc.: 59.38%] [G loss: 0.291577]\n",
      "epoch:16 step:15437 [D loss: 0.239078, acc.: 59.38%] [G loss: 0.290388]\n",
      "epoch:16 step:15438 [D loss: 0.242478, acc.: 54.69%] [G loss: 0.312709]\n",
      "epoch:16 step:15439 [D loss: 0.223807, acc.: 64.06%] [G loss: 0.287489]\n",
      "epoch:16 step:15440 [D loss: 0.254650, acc.: 56.25%] [G loss: 0.324847]\n",
      "epoch:16 step:15441 [D loss: 0.261340, acc.: 50.00%] [G loss: 0.276892]\n",
      "epoch:16 step:15442 [D loss: 0.243442, acc.: 57.03%] [G loss: 0.281230]\n",
      "epoch:16 step:15443 [D loss: 0.246313, acc.: 57.03%] [G loss: 0.294259]\n",
      "epoch:16 step:15444 [D loss: 0.230828, acc.: 64.84%] [G loss: 0.304060]\n",
      "epoch:16 step:15445 [D loss: 0.248364, acc.: 52.34%] [G loss: 0.292160]\n",
      "epoch:16 step:15446 [D loss: 0.223717, acc.: 61.72%] [G loss: 0.302509]\n",
      "epoch:16 step:15447 [D loss: 0.248146, acc.: 57.03%] [G loss: 0.304873]\n",
      "epoch:16 step:15448 [D loss: 0.242455, acc.: 58.59%] [G loss: 0.292274]\n",
      "epoch:16 step:15449 [D loss: 0.237935, acc.: 57.81%] [G loss: 0.329741]\n",
      "epoch:16 step:15450 [D loss: 0.240394, acc.: 56.25%] [G loss: 0.295719]\n",
      "epoch:16 step:15451 [D loss: 0.233177, acc.: 57.03%] [G loss: 0.306708]\n",
      "epoch:16 step:15452 [D loss: 0.238542, acc.: 59.38%] [G loss: 0.330157]\n",
      "epoch:16 step:15453 [D loss: 0.232231, acc.: 60.16%] [G loss: 0.305159]\n",
      "epoch:16 step:15454 [D loss: 0.254493, acc.: 51.56%] [G loss: 0.282863]\n",
      "epoch:16 step:15455 [D loss: 0.251421, acc.: 58.59%] [G loss: 0.281116]\n",
      "epoch:16 step:15456 [D loss: 0.241479, acc.: 58.59%] [G loss: 0.298657]\n",
      "epoch:16 step:15457 [D loss: 0.226676, acc.: 62.50%] [G loss: 0.298728]\n",
      "epoch:16 step:15458 [D loss: 0.225396, acc.: 67.19%] [G loss: 0.312469]\n",
      "epoch:16 step:15459 [D loss: 0.221495, acc.: 68.75%] [G loss: 0.307573]\n",
      "epoch:16 step:15460 [D loss: 0.238115, acc.: 53.91%] [G loss: 0.285974]\n",
      "epoch:16 step:15461 [D loss: 0.247815, acc.: 57.81%] [G loss: 0.279692]\n",
      "epoch:16 step:15462 [D loss: 0.258111, acc.: 48.44%] [G loss: 0.289608]\n",
      "epoch:16 step:15463 [D loss: 0.235396, acc.: 60.94%] [G loss: 0.289526]\n",
      "epoch:16 step:15464 [D loss: 0.258091, acc.: 55.47%] [G loss: 0.326808]\n",
      "epoch:16 step:15465 [D loss: 0.227136, acc.: 62.50%] [G loss: 0.286665]\n",
      "epoch:16 step:15466 [D loss: 0.218603, acc.: 67.19%] [G loss: 0.301699]\n",
      "epoch:16 step:15467 [D loss: 0.234522, acc.: 60.94%] [G loss: 0.307426]\n",
      "epoch:16 step:15468 [D loss: 0.210791, acc.: 66.41%] [G loss: 0.305401]\n",
      "epoch:16 step:15469 [D loss: 0.243348, acc.: 55.47%] [G loss: 0.298677]\n",
      "epoch:16 step:15470 [D loss: 0.238786, acc.: 57.81%] [G loss: 0.311506]\n",
      "epoch:16 step:15471 [D loss: 0.247743, acc.: 50.78%] [G loss: 0.279391]\n",
      "epoch:16 step:15472 [D loss: 0.255798, acc.: 50.78%] [G loss: 0.286394]\n",
      "epoch:16 step:15473 [D loss: 0.250248, acc.: 47.66%] [G loss: 0.309878]\n",
      "epoch:16 step:15474 [D loss: 0.226690, acc.: 64.84%] [G loss: 0.297359]\n",
      "epoch:16 step:15475 [D loss: 0.231060, acc.: 60.94%] [G loss: 0.308836]\n",
      "epoch:16 step:15476 [D loss: 0.234220, acc.: 57.81%] [G loss: 0.290793]\n",
      "epoch:16 step:15477 [D loss: 0.236829, acc.: 56.25%] [G loss: 0.269032]\n",
      "epoch:16 step:15478 [D loss: 0.234765, acc.: 57.81%] [G loss: 0.283384]\n",
      "epoch:16 step:15479 [D loss: 0.242646, acc.: 59.38%] [G loss: 0.329185]\n",
      "epoch:16 step:15480 [D loss: 0.215451, acc.: 66.41%] [G loss: 0.289275]\n",
      "epoch:16 step:15481 [D loss: 0.240579, acc.: 59.38%] [G loss: 0.302386]\n",
      "epoch:16 step:15482 [D loss: 0.219175, acc.: 62.50%] [G loss: 0.315351]\n",
      "epoch:16 step:15483 [D loss: 0.211471, acc.: 67.97%] [G loss: 0.325858]\n",
      "epoch:16 step:15484 [D loss: 0.225645, acc.: 64.84%] [G loss: 0.310010]\n",
      "epoch:16 step:15485 [D loss: 0.244269, acc.: 59.38%] [G loss: 0.325309]\n",
      "epoch:16 step:15486 [D loss: 0.238200, acc.: 55.47%] [G loss: 0.309130]\n",
      "epoch:16 step:15487 [D loss: 0.240876, acc.: 56.25%] [G loss: 0.306415]\n",
      "epoch:16 step:15488 [D loss: 0.239971, acc.: 57.03%] [G loss: 0.304179]\n",
      "epoch:16 step:15489 [D loss: 0.255822, acc.: 56.25%] [G loss: 0.290716]\n",
      "epoch:16 step:15490 [D loss: 0.235085, acc.: 57.03%] [G loss: 0.292528]\n",
      "epoch:16 step:15491 [D loss: 0.270340, acc.: 50.00%] [G loss: 0.297269]\n",
      "epoch:16 step:15492 [D loss: 0.254769, acc.: 53.12%] [G loss: 0.277204]\n",
      "epoch:16 step:15493 [D loss: 0.224844, acc.: 63.28%] [G loss: 0.286246]\n",
      "epoch:16 step:15494 [D loss: 0.248402, acc.: 57.81%] [G loss: 0.302654]\n",
      "epoch:16 step:15495 [D loss: 0.231516, acc.: 61.72%] [G loss: 0.312006]\n",
      "epoch:16 step:15496 [D loss: 0.236959, acc.: 60.94%] [G loss: 0.326112]\n",
      "epoch:16 step:15497 [D loss: 0.248592, acc.: 60.16%] [G loss: 0.291195]\n",
      "epoch:16 step:15498 [D loss: 0.248195, acc.: 53.12%] [G loss: 0.317594]\n",
      "epoch:16 step:15499 [D loss: 0.243803, acc.: 55.47%] [G loss: 0.313264]\n",
      "epoch:16 step:15500 [D loss: 0.259226, acc.: 50.78%] [G loss: 0.317751]\n",
      "epoch:16 step:15501 [D loss: 0.248067, acc.: 53.12%] [G loss: 0.326226]\n",
      "epoch:16 step:15502 [D loss: 0.239932, acc.: 58.59%] [G loss: 0.320349]\n",
      "epoch:16 step:15503 [D loss: 0.223248, acc.: 57.03%] [G loss: 0.332289]\n",
      "epoch:16 step:15504 [D loss: 0.243830, acc.: 52.34%] [G loss: 0.325249]\n",
      "epoch:16 step:15505 [D loss: 0.231498, acc.: 64.06%] [G loss: 0.310915]\n",
      "epoch:16 step:15506 [D loss: 0.250304, acc.: 51.56%] [G loss: 0.305082]\n",
      "epoch:16 step:15507 [D loss: 0.225225, acc.: 60.16%] [G loss: 0.330624]\n",
      "epoch:16 step:15508 [D loss: 0.270246, acc.: 47.66%] [G loss: 0.296506]\n",
      "epoch:16 step:15509 [D loss: 0.256590, acc.: 57.03%] [G loss: 0.285391]\n",
      "epoch:16 step:15510 [D loss: 0.222799, acc.: 62.50%] [G loss: 0.307978]\n",
      "epoch:16 step:15511 [D loss: 0.237585, acc.: 60.16%] [G loss: 0.318427]\n",
      "epoch:16 step:15512 [D loss: 0.232280, acc.: 60.16%] [G loss: 0.302996]\n",
      "epoch:16 step:15513 [D loss: 0.227741, acc.: 63.28%] [G loss: 0.325340]\n",
      "epoch:16 step:15514 [D loss: 0.248937, acc.: 53.12%] [G loss: 0.302436]\n",
      "epoch:16 step:15515 [D loss: 0.234324, acc.: 60.94%] [G loss: 0.280850]\n",
      "epoch:16 step:15516 [D loss: 0.238867, acc.: 60.16%] [G loss: 0.315843]\n",
      "epoch:16 step:15517 [D loss: 0.240055, acc.: 60.16%] [G loss: 0.331559]\n",
      "epoch:16 step:15518 [D loss: 0.242238, acc.: 56.25%] [G loss: 0.297908]\n",
      "epoch:16 step:15519 [D loss: 0.228700, acc.: 64.06%] [G loss: 0.317624]\n",
      "epoch:16 step:15520 [D loss: 0.248767, acc.: 53.12%] [G loss: 0.322199]\n",
      "epoch:16 step:15521 [D loss: 0.217273, acc.: 63.28%] [G loss: 0.316313]\n",
      "epoch:16 step:15522 [D loss: 0.239503, acc.: 61.72%] [G loss: 0.314698]\n",
      "epoch:16 step:15523 [D loss: 0.233720, acc.: 61.72%] [G loss: 0.281852]\n",
      "epoch:16 step:15524 [D loss: 0.245045, acc.: 51.56%] [G loss: 0.283772]\n",
      "epoch:16 step:15525 [D loss: 0.240471, acc.: 57.81%] [G loss: 0.288465]\n",
      "epoch:16 step:15526 [D loss: 0.257111, acc.: 54.69%] [G loss: 0.293700]\n",
      "epoch:16 step:15527 [D loss: 0.237952, acc.: 54.69%] [G loss: 0.302719]\n",
      "epoch:16 step:15528 [D loss: 0.227944, acc.: 60.94%] [G loss: 0.314104]\n",
      "epoch:16 step:15529 [D loss: 0.233604, acc.: 60.16%] [G loss: 0.282769]\n",
      "epoch:16 step:15530 [D loss: 0.235240, acc.: 54.69%] [G loss: 0.293771]\n",
      "epoch:16 step:15531 [D loss: 0.246821, acc.: 53.91%] [G loss: 0.290561]\n",
      "epoch:16 step:15532 [D loss: 0.236060, acc.: 59.38%] [G loss: 0.313946]\n",
      "epoch:16 step:15533 [D loss: 0.246096, acc.: 58.59%] [G loss: 0.310775]\n",
      "epoch:16 step:15534 [D loss: 0.249048, acc.: 59.38%] [G loss: 0.308754]\n",
      "epoch:16 step:15535 [D loss: 0.242457, acc.: 60.94%] [G loss: 0.290151]\n",
      "epoch:16 step:15536 [D loss: 0.251000, acc.: 57.81%] [G loss: 0.288085]\n",
      "epoch:16 step:15537 [D loss: 0.225824, acc.: 64.06%] [G loss: 0.302695]\n",
      "epoch:16 step:15538 [D loss: 0.229470, acc.: 65.62%] [G loss: 0.296452]\n",
      "epoch:16 step:15539 [D loss: 0.249820, acc.: 57.81%] [G loss: 0.322346]\n",
      "epoch:16 step:15540 [D loss: 0.241694, acc.: 58.59%] [G loss: 0.298659]\n",
      "epoch:16 step:15541 [D loss: 0.233927, acc.: 64.06%] [G loss: 0.323711]\n",
      "epoch:16 step:15542 [D loss: 0.242695, acc.: 57.81%] [G loss: 0.309793]\n",
      "epoch:16 step:15543 [D loss: 0.244719, acc.: 58.59%] [G loss: 0.306461]\n",
      "epoch:16 step:15544 [D loss: 0.265074, acc.: 46.88%] [G loss: 0.304543]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:16 step:15545 [D loss: 0.234254, acc.: 61.72%] [G loss: 0.310984]\n",
      "epoch:16 step:15546 [D loss: 0.228283, acc.: 62.50%] [G loss: 0.310874]\n",
      "epoch:16 step:15547 [D loss: 0.219227, acc.: 71.09%] [G loss: 0.277614]\n",
      "epoch:16 step:15548 [D loss: 0.233071, acc.: 62.50%] [G loss: 0.296097]\n",
      "epoch:16 step:15549 [D loss: 0.234129, acc.: 61.72%] [G loss: 0.311500]\n",
      "epoch:16 step:15550 [D loss: 0.250185, acc.: 53.12%] [G loss: 0.304277]\n",
      "epoch:16 step:15551 [D loss: 0.240306, acc.: 58.59%] [G loss: 0.297715]\n",
      "epoch:16 step:15552 [D loss: 0.225980, acc.: 63.28%] [G loss: 0.311461]\n",
      "epoch:16 step:15553 [D loss: 0.243430, acc.: 57.03%] [G loss: 0.299958]\n",
      "epoch:16 step:15554 [D loss: 0.241371, acc.: 56.25%] [G loss: 0.313881]\n",
      "epoch:16 step:15555 [D loss: 0.243493, acc.: 59.38%] [G loss: 0.280507]\n",
      "epoch:16 step:15556 [D loss: 0.245340, acc.: 58.59%] [G loss: 0.315601]\n",
      "epoch:16 step:15557 [D loss: 0.237775, acc.: 57.03%] [G loss: 0.315456]\n",
      "epoch:16 step:15558 [D loss: 0.236032, acc.: 62.50%] [G loss: 0.300716]\n",
      "epoch:16 step:15559 [D loss: 0.228621, acc.: 62.50%] [G loss: 0.300333]\n",
      "epoch:16 step:15560 [D loss: 0.241264, acc.: 52.34%] [G loss: 0.299618]\n",
      "epoch:16 step:15561 [D loss: 0.260178, acc.: 50.78%] [G loss: 0.287690]\n",
      "epoch:16 step:15562 [D loss: 0.241864, acc.: 53.91%] [G loss: 0.306054]\n",
      "epoch:16 step:15563 [D loss: 0.241119, acc.: 60.16%] [G loss: 0.281228]\n",
      "epoch:16 step:15564 [D loss: 0.233078, acc.: 64.84%] [G loss: 0.298508]\n",
      "epoch:16 step:15565 [D loss: 0.243862, acc.: 59.38%] [G loss: 0.314413]\n",
      "epoch:16 step:15566 [D loss: 0.248643, acc.: 54.69%] [G loss: 0.331199]\n",
      "epoch:16 step:15567 [D loss: 0.236791, acc.: 58.59%] [G loss: 0.314555]\n",
      "epoch:16 step:15568 [D loss: 0.220574, acc.: 64.84%] [G loss: 0.293139]\n",
      "epoch:16 step:15569 [D loss: 0.242802, acc.: 56.25%] [G loss: 0.323048]\n",
      "epoch:16 step:15570 [D loss: 0.234548, acc.: 56.25%] [G loss: 0.276735]\n",
      "epoch:16 step:15571 [D loss: 0.225438, acc.: 60.94%] [G loss: 0.342339]\n",
      "epoch:16 step:15572 [D loss: 0.222880, acc.: 65.62%] [G loss: 0.301926]\n",
      "epoch:16 step:15573 [D loss: 0.238375, acc.: 61.72%] [G loss: 0.314826]\n",
      "epoch:16 step:15574 [D loss: 0.239895, acc.: 63.28%] [G loss: 0.319659]\n",
      "epoch:16 step:15575 [D loss: 0.231241, acc.: 64.06%] [G loss: 0.305773]\n",
      "epoch:16 step:15576 [D loss: 0.234014, acc.: 60.16%] [G loss: 0.292691]\n",
      "epoch:16 step:15577 [D loss: 0.246018, acc.: 52.34%] [G loss: 0.274668]\n",
      "epoch:16 step:15578 [D loss: 0.235706, acc.: 54.69%] [G loss: 0.320932]\n",
      "epoch:16 step:15579 [D loss: 0.255631, acc.: 49.22%] [G loss: 0.288884]\n",
      "epoch:16 step:15580 [D loss: 0.232382, acc.: 60.94%] [G loss: 0.297544]\n",
      "epoch:16 step:15581 [D loss: 0.239464, acc.: 62.50%] [G loss: 0.315690]\n",
      "epoch:16 step:15582 [D loss: 0.228211, acc.: 64.06%] [G loss: 0.303446]\n",
      "epoch:16 step:15583 [D loss: 0.220920, acc.: 63.28%] [G loss: 0.309378]\n",
      "epoch:16 step:15584 [D loss: 0.250476, acc.: 51.56%] [G loss: 0.287649]\n",
      "epoch:16 step:15585 [D loss: 0.253116, acc.: 51.56%] [G loss: 0.300692]\n",
      "epoch:16 step:15586 [D loss: 0.218784, acc.: 70.31%] [G loss: 0.330835]\n",
      "epoch:16 step:15587 [D loss: 0.247377, acc.: 56.25%] [G loss: 0.312772]\n",
      "epoch:16 step:15588 [D loss: 0.222168, acc.: 64.84%] [G loss: 0.321435]\n",
      "epoch:16 step:15589 [D loss: 0.262063, acc.: 50.00%] [G loss: 0.297610]\n",
      "epoch:16 step:15590 [D loss: 0.235753, acc.: 57.81%] [G loss: 0.296512]\n",
      "epoch:16 step:15591 [D loss: 0.231255, acc.: 59.38%] [G loss: 0.321944]\n",
      "epoch:16 step:15592 [D loss: 0.243022, acc.: 56.25%] [G loss: 0.313527]\n",
      "epoch:16 step:15593 [D loss: 0.235689, acc.: 60.94%] [G loss: 0.303177]\n",
      "epoch:16 step:15594 [D loss: 0.222821, acc.: 60.16%] [G loss: 0.313810]\n",
      "epoch:16 step:15595 [D loss: 0.242890, acc.: 49.22%] [G loss: 0.327217]\n",
      "epoch:16 step:15596 [D loss: 0.234891, acc.: 56.25%] [G loss: 0.292458]\n",
      "epoch:16 step:15597 [D loss: 0.251216, acc.: 53.12%] [G loss: 0.295737]\n",
      "epoch:16 step:15598 [D loss: 0.242502, acc.: 56.25%] [G loss: 0.324474]\n",
      "epoch:16 step:15599 [D loss: 0.255515, acc.: 49.22%] [G loss: 0.301935]\n",
      "epoch:16 step:15600 [D loss: 0.239802, acc.: 54.69%] [G loss: 0.311503]\n",
      "epoch:16 step:15601 [D loss: 0.228198, acc.: 60.94%] [G loss: 0.304503]\n",
      "epoch:16 step:15602 [D loss: 0.238574, acc.: 57.03%] [G loss: 0.301884]\n",
      "epoch:16 step:15603 [D loss: 0.213588, acc.: 64.06%] [G loss: 0.295301]\n",
      "epoch:16 step:15604 [D loss: 0.241680, acc.: 52.34%] [G loss: 0.299608]\n",
      "epoch:16 step:15605 [D loss: 0.237249, acc.: 62.50%] [G loss: 0.318803]\n",
      "epoch:16 step:15606 [D loss: 0.250841, acc.: 53.91%] [G loss: 0.298045]\n",
      "epoch:16 step:15607 [D loss: 0.255586, acc.: 50.00%] [G loss: 0.278296]\n",
      "epoch:16 step:15608 [D loss: 0.242798, acc.: 56.25%] [G loss: 0.311068]\n",
      "epoch:16 step:15609 [D loss: 0.230091, acc.: 65.62%] [G loss: 0.317299]\n",
      "epoch:16 step:15610 [D loss: 0.214114, acc.: 67.19%] [G loss: 0.329450]\n",
      "epoch:16 step:15611 [D loss: 0.243662, acc.: 57.03%] [G loss: 0.298558]\n",
      "epoch:16 step:15612 [D loss: 0.240684, acc.: 56.25%] [G loss: 0.273972]\n",
      "epoch:16 step:15613 [D loss: 0.236038, acc.: 60.16%] [G loss: 0.285903]\n",
      "epoch:16 step:15614 [D loss: 0.235976, acc.: 61.72%] [G loss: 0.305242]\n",
      "epoch:16 step:15615 [D loss: 0.248340, acc.: 54.69%] [G loss: 0.287083]\n",
      "epoch:16 step:15616 [D loss: 0.241747, acc.: 52.34%] [G loss: 0.288279]\n",
      "epoch:16 step:15617 [D loss: 0.218747, acc.: 66.41%] [G loss: 0.284103]\n",
      "epoch:16 step:15618 [D loss: 0.233825, acc.: 58.59%] [G loss: 0.305540]\n",
      "epoch:16 step:15619 [D loss: 0.235843, acc.: 57.03%] [G loss: 0.302127]\n",
      "epoch:16 step:15620 [D loss: 0.250124, acc.: 56.25%] [G loss: 0.305735]\n",
      "epoch:16 step:15621 [D loss: 0.233766, acc.: 57.81%] [G loss: 0.317930]\n",
      "epoch:16 step:15622 [D loss: 0.254799, acc.: 50.00%] [G loss: 0.273191]\n",
      "epoch:16 step:15623 [D loss: 0.236947, acc.: 62.50%] [G loss: 0.289243]\n",
      "epoch:16 step:15624 [D loss: 0.241681, acc.: 57.03%] [G loss: 0.301316]\n",
      "epoch:16 step:15625 [D loss: 0.219775, acc.: 68.75%] [G loss: 0.310400]\n",
      "epoch:16 step:15626 [D loss: 0.234284, acc.: 60.94%] [G loss: 0.325975]\n",
      "epoch:16 step:15627 [D loss: 0.226299, acc.: 67.19%] [G loss: 0.278048]\n",
      "epoch:16 step:15628 [D loss: 0.239654, acc.: 63.28%] [G loss: 0.301021]\n",
      "epoch:16 step:15629 [D loss: 0.235943, acc.: 60.94%] [G loss: 0.295714]\n",
      "epoch:16 step:15630 [D loss: 0.255489, acc.: 47.66%] [G loss: 0.282399]\n",
      "epoch:16 step:15631 [D loss: 0.253884, acc.: 48.44%] [G loss: 0.272516]\n",
      "epoch:16 step:15632 [D loss: 0.223521, acc.: 67.19%] [G loss: 0.290637]\n",
      "epoch:16 step:15633 [D loss: 0.239889, acc.: 60.94%] [G loss: 0.312127]\n",
      "epoch:16 step:15634 [D loss: 0.236704, acc.: 60.16%] [G loss: 0.304713]\n",
      "epoch:16 step:15635 [D loss: 0.256466, acc.: 53.91%] [G loss: 0.298194]\n",
      "epoch:16 step:15636 [D loss: 0.234419, acc.: 61.72%] [G loss: 0.326248]\n",
      "epoch:16 step:15637 [D loss: 0.232864, acc.: 61.72%] [G loss: 0.314791]\n",
      "epoch:16 step:15638 [D loss: 0.241644, acc.: 60.94%] [G loss: 0.343527]\n",
      "epoch:16 step:15639 [D loss: 0.233878, acc.: 60.16%] [G loss: 0.318354]\n",
      "epoch:16 step:15640 [D loss: 0.236145, acc.: 59.38%] [G loss: 0.308468]\n",
      "epoch:16 step:15641 [D loss: 0.242554, acc.: 59.38%] [G loss: 0.279772]\n",
      "epoch:16 step:15642 [D loss: 0.235174, acc.: 55.47%] [G loss: 0.317379]\n",
      "epoch:16 step:15643 [D loss: 0.252624, acc.: 57.03%] [G loss: 0.298445]\n",
      "epoch:16 step:15644 [D loss: 0.232797, acc.: 62.50%] [G loss: 0.262648]\n",
      "epoch:16 step:15645 [D loss: 0.253415, acc.: 57.03%] [G loss: 0.259780]\n",
      "epoch:16 step:15646 [D loss: 0.245409, acc.: 57.81%] [G loss: 0.298779]\n",
      "epoch:16 step:15647 [D loss: 0.264845, acc.: 46.88%] [G loss: 0.286395]\n",
      "epoch:16 step:15648 [D loss: 0.242806, acc.: 54.69%] [G loss: 0.295659]\n",
      "epoch:16 step:15649 [D loss: 0.226023, acc.: 61.72%] [G loss: 0.310931]\n",
      "epoch:16 step:15650 [D loss: 0.239931, acc.: 60.16%] [G loss: 0.310163]\n",
      "epoch:16 step:15651 [D loss: 0.243908, acc.: 55.47%] [G loss: 0.289348]\n",
      "epoch:16 step:15652 [D loss: 0.231149, acc.: 57.81%] [G loss: 0.299627]\n",
      "epoch:16 step:15653 [D loss: 0.232006, acc.: 60.94%] [G loss: 0.323443]\n",
      "epoch:16 step:15654 [D loss: 0.233381, acc.: 64.84%] [G loss: 0.284475]\n",
      "epoch:16 step:15655 [D loss: 0.242064, acc.: 54.69%] [G loss: 0.280555]\n",
      "epoch:16 step:15656 [D loss: 0.221672, acc.: 64.84%] [G loss: 0.279017]\n",
      "epoch:16 step:15657 [D loss: 0.237398, acc.: 60.94%] [G loss: 0.284365]\n",
      "epoch:16 step:15658 [D loss: 0.236690, acc.: 53.91%] [G loss: 0.307796]\n",
      "epoch:16 step:15659 [D loss: 0.251024, acc.: 54.69%] [G loss: 0.291704]\n",
      "epoch:16 step:15660 [D loss: 0.235197, acc.: 60.16%] [G loss: 0.311730]\n",
      "epoch:16 step:15661 [D loss: 0.240423, acc.: 60.94%] [G loss: 0.326018]\n",
      "epoch:16 step:15662 [D loss: 0.252138, acc.: 49.22%] [G loss: 0.296387]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:16 step:15663 [D loss: 0.236775, acc.: 56.25%] [G loss: 0.294860]\n",
      "epoch:16 step:15664 [D loss: 0.236617, acc.: 59.38%] [G loss: 0.326663]\n",
      "epoch:16 step:15665 [D loss: 0.231035, acc.: 60.16%] [G loss: 0.294042]\n",
      "epoch:16 step:15666 [D loss: 0.233254, acc.: 60.94%] [G loss: 0.310186]\n",
      "epoch:16 step:15667 [D loss: 0.254014, acc.: 57.03%] [G loss: 0.299114]\n",
      "epoch:16 step:15668 [D loss: 0.241485, acc.: 62.50%] [G loss: 0.281397]\n",
      "epoch:16 step:15669 [D loss: 0.253388, acc.: 54.69%] [G loss: 0.279518]\n",
      "epoch:16 step:15670 [D loss: 0.238249, acc.: 58.59%] [G loss: 0.283924]\n",
      "epoch:16 step:15671 [D loss: 0.245404, acc.: 57.81%] [G loss: 0.291631]\n",
      "epoch:16 step:15672 [D loss: 0.257105, acc.: 55.47%] [G loss: 0.292753]\n",
      "epoch:16 step:15673 [D loss: 0.238783, acc.: 57.81%] [G loss: 0.343809]\n",
      "epoch:16 step:15674 [D loss: 0.234868, acc.: 57.81%] [G loss: 0.290544]\n",
      "epoch:16 step:15675 [D loss: 0.238138, acc.: 61.72%] [G loss: 0.308748]\n",
      "epoch:16 step:15676 [D loss: 0.239604, acc.: 59.38%] [G loss: 0.323942]\n",
      "epoch:16 step:15677 [D loss: 0.249873, acc.: 53.12%] [G loss: 0.303635]\n",
      "epoch:16 step:15678 [D loss: 0.245064, acc.: 58.59%] [G loss: 0.316400]\n",
      "epoch:16 step:15679 [D loss: 0.218556, acc.: 61.72%] [G loss: 0.288422]\n",
      "epoch:16 step:15680 [D loss: 0.241050, acc.: 52.34%] [G loss: 0.300788]\n",
      "epoch:16 step:15681 [D loss: 0.243056, acc.: 49.22%] [G loss: 0.338595]\n",
      "epoch:16 step:15682 [D loss: 0.221135, acc.: 67.19%] [G loss: 0.290432]\n",
      "epoch:16 step:15683 [D loss: 0.237667, acc.: 61.72%] [G loss: 0.300438]\n",
      "epoch:16 step:15684 [D loss: 0.237055, acc.: 60.16%] [G loss: 0.328548]\n",
      "epoch:16 step:15685 [D loss: 0.238196, acc.: 62.50%] [G loss: 0.297347]\n",
      "epoch:16 step:15686 [D loss: 0.255889, acc.: 48.44%] [G loss: 0.298372]\n",
      "epoch:16 step:15687 [D loss: 0.232404, acc.: 57.81%] [G loss: 0.329756]\n",
      "epoch:16 step:15688 [D loss: 0.214189, acc.: 70.31%] [G loss: 0.340416]\n",
      "epoch:16 step:15689 [D loss: 0.250495, acc.: 53.12%] [G loss: 0.298703]\n",
      "epoch:16 step:15690 [D loss: 0.246850, acc.: 56.25%] [G loss: 0.292056]\n",
      "epoch:16 step:15691 [D loss: 0.262659, acc.: 46.09%] [G loss: 0.313050]\n",
      "epoch:16 step:15692 [D loss: 0.235667, acc.: 57.81%] [G loss: 0.292676]\n",
      "epoch:16 step:15693 [D loss: 0.233375, acc.: 60.16%] [G loss: 0.324402]\n",
      "epoch:16 step:15694 [D loss: 0.241452, acc.: 57.81%] [G loss: 0.303073]\n",
      "epoch:16 step:15695 [D loss: 0.243433, acc.: 58.59%] [G loss: 0.296392]\n",
      "epoch:16 step:15696 [D loss: 0.260949, acc.: 51.56%] [G loss: 0.313911]\n",
      "epoch:16 step:15697 [D loss: 0.239260, acc.: 60.94%] [G loss: 0.314582]\n",
      "epoch:16 step:15698 [D loss: 0.229171, acc.: 61.72%] [G loss: 0.299067]\n",
      "epoch:16 step:15699 [D loss: 0.218017, acc.: 64.84%] [G loss: 0.294377]\n",
      "epoch:16 step:15700 [D loss: 0.243015, acc.: 57.81%] [G loss: 0.305693]\n",
      "epoch:16 step:15701 [D loss: 0.256134, acc.: 58.59%] [G loss: 0.308388]\n",
      "epoch:16 step:15702 [D loss: 0.238967, acc.: 57.81%] [G loss: 0.270501]\n",
      "epoch:16 step:15703 [D loss: 0.228587, acc.: 62.50%] [G loss: 0.300699]\n",
      "epoch:16 step:15704 [D loss: 0.215538, acc.: 70.31%] [G loss: 0.288059]\n",
      "epoch:16 step:15705 [D loss: 0.228440, acc.: 60.94%] [G loss: 0.311324]\n",
      "epoch:16 step:15706 [D loss: 0.236425, acc.: 61.72%] [G loss: 0.292154]\n",
      "epoch:16 step:15707 [D loss: 0.245832, acc.: 55.47%] [G loss: 0.313644]\n",
      "epoch:16 step:15708 [D loss: 0.237931, acc.: 62.50%] [G loss: 0.295606]\n",
      "epoch:16 step:15709 [D loss: 0.235294, acc.: 60.16%] [G loss: 0.274079]\n",
      "epoch:16 step:15710 [D loss: 0.217306, acc.: 60.94%] [G loss: 0.302678]\n",
      "epoch:16 step:15711 [D loss: 0.248701, acc.: 53.91%] [G loss: 0.331948]\n",
      "epoch:16 step:15712 [D loss: 0.247868, acc.: 53.91%] [G loss: 0.303842]\n",
      "epoch:16 step:15713 [D loss: 0.222578, acc.: 65.62%] [G loss: 0.312449]\n",
      "epoch:16 step:15714 [D loss: 0.240039, acc.: 61.72%] [G loss: 0.292247]\n",
      "epoch:16 step:15715 [D loss: 0.224478, acc.: 60.94%] [G loss: 0.321977]\n",
      "epoch:16 step:15716 [D loss: 0.236903, acc.: 60.94%] [G loss: 0.302368]\n",
      "epoch:16 step:15717 [D loss: 0.229079, acc.: 60.94%] [G loss: 0.318196]\n",
      "epoch:16 step:15718 [D loss: 0.253888, acc.: 52.34%] [G loss: 0.297148]\n",
      "epoch:16 step:15719 [D loss: 0.229865, acc.: 65.62%] [G loss: 0.303351]\n",
      "epoch:16 step:15720 [D loss: 0.243122, acc.: 64.06%] [G loss: 0.292909]\n",
      "epoch:16 step:15721 [D loss: 0.236091, acc.: 60.16%] [G loss: 0.295320]\n",
      "epoch:16 step:15722 [D loss: 0.233352, acc.: 57.81%] [G loss: 0.316816]\n",
      "epoch:16 step:15723 [D loss: 0.246036, acc.: 52.34%] [G loss: 0.294671]\n",
      "epoch:16 step:15724 [D loss: 0.230408, acc.: 62.50%] [G loss: 0.289938]\n",
      "epoch:16 step:15725 [D loss: 0.236819, acc.: 57.03%] [G loss: 0.314098]\n",
      "epoch:16 step:15726 [D loss: 0.251593, acc.: 56.25%] [G loss: 0.295133]\n",
      "epoch:16 step:15727 [D loss: 0.233080, acc.: 60.94%] [G loss: 0.279452]\n",
      "epoch:16 step:15728 [D loss: 0.247970, acc.: 57.03%] [G loss: 0.300639]\n",
      "epoch:16 step:15729 [D loss: 0.223654, acc.: 64.06%] [G loss: 0.290627]\n",
      "epoch:16 step:15730 [D loss: 0.266525, acc.: 50.00%] [G loss: 0.296730]\n",
      "epoch:16 step:15731 [D loss: 0.272966, acc.: 45.31%] [G loss: 0.266227]\n",
      "epoch:16 step:15732 [D loss: 0.255534, acc.: 53.91%] [G loss: 0.304125]\n",
      "epoch:16 step:15733 [D loss: 0.247713, acc.: 57.81%] [G loss: 0.276967]\n",
      "epoch:16 step:15734 [D loss: 0.242523, acc.: 55.47%] [G loss: 0.289808]\n",
      "epoch:16 step:15735 [D loss: 0.250848, acc.: 53.12%] [G loss: 0.311486]\n",
      "epoch:16 step:15736 [D loss: 0.223769, acc.: 62.50%] [G loss: 0.290603]\n",
      "epoch:16 step:15737 [D loss: 0.247333, acc.: 57.81%] [G loss: 0.315951]\n",
      "epoch:16 step:15738 [D loss: 0.227254, acc.: 64.84%] [G loss: 0.283929]\n",
      "epoch:16 step:15739 [D loss: 0.231547, acc.: 62.50%] [G loss: 0.327380]\n",
      "epoch:16 step:15740 [D loss: 0.236848, acc.: 59.38%] [G loss: 0.314582]\n",
      "epoch:16 step:15741 [D loss: 0.241467, acc.: 60.94%] [G loss: 0.282483]\n",
      "epoch:16 step:15742 [D loss: 0.232863, acc.: 57.81%] [G loss: 0.299345]\n",
      "epoch:16 step:15743 [D loss: 0.225225, acc.: 61.72%] [G loss: 0.318331]\n",
      "epoch:16 step:15744 [D loss: 0.249999, acc.: 52.34%] [G loss: 0.308456]\n",
      "epoch:16 step:15745 [D loss: 0.238320, acc.: 56.25%] [G loss: 0.308578]\n",
      "epoch:16 step:15746 [D loss: 0.248352, acc.: 52.34%] [G loss: 0.285394]\n",
      "epoch:16 step:15747 [D loss: 0.216341, acc.: 62.50%] [G loss: 0.298194]\n",
      "epoch:16 step:15748 [D loss: 0.241419, acc.: 55.47%] [G loss: 0.282790]\n",
      "epoch:16 step:15749 [D loss: 0.232494, acc.: 62.50%] [G loss: 0.311907]\n",
      "epoch:16 step:15750 [D loss: 0.245777, acc.: 53.12%] [G loss: 0.323096]\n",
      "epoch:16 step:15751 [D loss: 0.225537, acc.: 66.41%] [G loss: 0.291401]\n",
      "epoch:16 step:15752 [D loss: 0.248952, acc.: 54.69%] [G loss: 0.292685]\n",
      "epoch:16 step:15753 [D loss: 0.239138, acc.: 61.72%] [G loss: 0.293926]\n",
      "epoch:16 step:15754 [D loss: 0.249739, acc.: 53.91%] [G loss: 0.261177]\n",
      "epoch:16 step:15755 [D loss: 0.249918, acc.: 52.34%] [G loss: 0.301793]\n",
      "epoch:16 step:15756 [D loss: 0.242198, acc.: 58.59%] [G loss: 0.292646]\n",
      "epoch:16 step:15757 [D loss: 0.248214, acc.: 57.03%] [G loss: 0.276627]\n",
      "epoch:16 step:15758 [D loss: 0.254433, acc.: 52.34%] [G loss: 0.293362]\n",
      "epoch:16 step:15759 [D loss: 0.231711, acc.: 59.38%] [G loss: 0.317841]\n",
      "epoch:16 step:15760 [D loss: 0.240701, acc.: 59.38%] [G loss: 0.284508]\n",
      "epoch:16 step:15761 [D loss: 0.255488, acc.: 50.78%] [G loss: 0.298197]\n",
      "epoch:16 step:15762 [D loss: 0.233624, acc.: 57.81%] [G loss: 0.314795]\n",
      "epoch:16 step:15763 [D loss: 0.232232, acc.: 62.50%] [G loss: 0.285797]\n",
      "epoch:16 step:15764 [D loss: 0.239130, acc.: 60.94%] [G loss: 0.272561]\n",
      "epoch:16 step:15765 [D loss: 0.230673, acc.: 64.06%] [G loss: 0.327722]\n",
      "epoch:16 step:15766 [D loss: 0.238039, acc.: 64.06%] [G loss: 0.303972]\n",
      "epoch:16 step:15767 [D loss: 0.235118, acc.: 59.38%] [G loss: 0.278102]\n",
      "epoch:16 step:15768 [D loss: 0.237791, acc.: 62.50%] [G loss: 0.282698]\n",
      "epoch:16 step:15769 [D loss: 0.229810, acc.: 60.16%] [G loss: 0.290605]\n",
      "epoch:16 step:15770 [D loss: 0.239886, acc.: 61.72%] [G loss: 0.327062]\n",
      "epoch:16 step:15771 [D loss: 0.241448, acc.: 57.03%] [G loss: 0.314190]\n",
      "epoch:16 step:15772 [D loss: 0.235860, acc.: 55.47%] [G loss: 0.286883]\n",
      "epoch:16 step:15773 [D loss: 0.245884, acc.: 55.47%] [G loss: 0.313012]\n",
      "epoch:16 step:15774 [D loss: 0.228376, acc.: 63.28%] [G loss: 0.333736]\n",
      "epoch:16 step:15775 [D loss: 0.244783, acc.: 57.81%] [G loss: 0.306239]\n",
      "epoch:16 step:15776 [D loss: 0.252034, acc.: 50.00%] [G loss: 0.301533]\n",
      "epoch:16 step:15777 [D loss: 0.238911, acc.: 57.03%] [G loss: 0.341862]\n",
      "epoch:16 step:15778 [D loss: 0.239640, acc.: 55.47%] [G loss: 0.299965]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:16 step:15779 [D loss: 0.242029, acc.: 56.25%] [G loss: 0.317790]\n",
      "epoch:16 step:15780 [D loss: 0.250682, acc.: 52.34%] [G loss: 0.291065]\n",
      "epoch:16 step:15781 [D loss: 0.230463, acc.: 57.81%] [G loss: 0.300968]\n",
      "epoch:16 step:15782 [D loss: 0.246908, acc.: 57.03%] [G loss: 0.298397]\n",
      "epoch:16 step:15783 [D loss: 0.243274, acc.: 54.69%] [G loss: 0.291527]\n",
      "epoch:16 step:15784 [D loss: 0.219618, acc.: 63.28%] [G loss: 0.325546]\n",
      "epoch:16 step:15785 [D loss: 0.253797, acc.: 52.34%] [G loss: 0.319407]\n",
      "epoch:16 step:15786 [D loss: 0.239636, acc.: 63.28%] [G loss: 0.304569]\n",
      "epoch:16 step:15787 [D loss: 0.249472, acc.: 56.25%] [G loss: 0.271894]\n",
      "epoch:16 step:15788 [D loss: 0.242723, acc.: 58.59%] [G loss: 0.302663]\n",
      "epoch:16 step:15789 [D loss: 0.261607, acc.: 51.56%] [G loss: 0.310683]\n",
      "epoch:16 step:15790 [D loss: 0.241175, acc.: 57.81%] [G loss: 0.273220]\n",
      "epoch:16 step:15791 [D loss: 0.260474, acc.: 47.66%] [G loss: 0.286332]\n",
      "epoch:16 step:15792 [D loss: 0.230813, acc.: 61.72%] [G loss: 0.313202]\n",
      "epoch:16 step:15793 [D loss: 0.239016, acc.: 54.69%] [G loss: 0.294978]\n",
      "epoch:16 step:15794 [D loss: 0.238061, acc.: 60.16%] [G loss: 0.291386]\n",
      "epoch:16 step:15795 [D loss: 0.235585, acc.: 60.94%] [G loss: 0.322691]\n",
      "epoch:16 step:15796 [D loss: 0.242640, acc.: 56.25%] [G loss: 0.289130]\n",
      "epoch:16 step:15797 [D loss: 0.241993, acc.: 58.59%] [G loss: 0.295416]\n",
      "epoch:16 step:15798 [D loss: 0.234015, acc.: 61.72%] [G loss: 0.297524]\n",
      "epoch:16 step:15799 [D loss: 0.247340, acc.: 54.69%] [G loss: 0.281818]\n",
      "epoch:16 step:15800 [D loss: 0.229847, acc.: 61.72%] [G loss: 0.306689]\n",
      "epoch:16 step:15801 [D loss: 0.233623, acc.: 57.03%] [G loss: 0.298854]\n",
      "epoch:16 step:15802 [D loss: 0.227660, acc.: 64.84%] [G loss: 0.290560]\n",
      "epoch:16 step:15803 [D loss: 0.224401, acc.: 66.41%] [G loss: 0.287280]\n",
      "epoch:16 step:15804 [D loss: 0.238027, acc.: 57.81%] [G loss: 0.314076]\n",
      "epoch:16 step:15805 [D loss: 0.227801, acc.: 63.28%] [G loss: 0.314644]\n",
      "epoch:16 step:15806 [D loss: 0.245287, acc.: 59.38%] [G loss: 0.287713]\n",
      "epoch:16 step:15807 [D loss: 0.248228, acc.: 53.91%] [G loss: 0.290225]\n",
      "epoch:16 step:15808 [D loss: 0.223802, acc.: 65.62%] [G loss: 0.294666]\n",
      "epoch:16 step:15809 [D loss: 0.237994, acc.: 62.50%] [G loss: 0.305424]\n",
      "epoch:16 step:15810 [D loss: 0.234437, acc.: 56.25%] [G loss: 0.298754]\n",
      "epoch:16 step:15811 [D loss: 0.234714, acc.: 65.62%] [G loss: 0.286362]\n",
      "epoch:16 step:15812 [D loss: 0.247170, acc.: 57.03%] [G loss: 0.292136]\n",
      "epoch:16 step:15813 [D loss: 0.230591, acc.: 59.38%] [G loss: 0.291769]\n",
      "epoch:16 step:15814 [D loss: 0.229215, acc.: 67.97%] [G loss: 0.297686]\n",
      "epoch:16 step:15815 [D loss: 0.244578, acc.: 54.69%] [G loss: 0.281409]\n",
      "epoch:16 step:15816 [D loss: 0.245360, acc.: 60.94%] [G loss: 0.286545]\n",
      "epoch:16 step:15817 [D loss: 0.218923, acc.: 64.84%] [G loss: 0.297004]\n",
      "epoch:16 step:15818 [D loss: 0.245137, acc.: 57.81%] [G loss: 0.292656]\n",
      "epoch:16 step:15819 [D loss: 0.239074, acc.: 59.38%] [G loss: 0.303527]\n",
      "epoch:16 step:15820 [D loss: 0.253461, acc.: 51.56%] [G loss: 0.294535]\n",
      "epoch:16 step:15821 [D loss: 0.252206, acc.: 55.47%] [G loss: 0.281663]\n",
      "epoch:16 step:15822 [D loss: 0.237657, acc.: 57.03%] [G loss: 0.285204]\n",
      "epoch:16 step:15823 [D loss: 0.239643, acc.: 57.81%] [G loss: 0.322448]\n",
      "epoch:16 step:15824 [D loss: 0.226810, acc.: 65.62%] [G loss: 0.345882]\n",
      "epoch:16 step:15825 [D loss: 0.232498, acc.: 64.06%] [G loss: 0.301980]\n",
      "epoch:16 step:15826 [D loss: 0.240735, acc.: 57.81%] [G loss: 0.304672]\n",
      "epoch:16 step:15827 [D loss: 0.249874, acc.: 55.47%] [G loss: 0.307354]\n",
      "epoch:16 step:15828 [D loss: 0.241802, acc.: 56.25%] [G loss: 0.265320]\n",
      "epoch:16 step:15829 [D loss: 0.248612, acc.: 54.69%] [G loss: 0.293351]\n",
      "epoch:16 step:15830 [D loss: 0.241775, acc.: 56.25%] [G loss: 0.293805]\n",
      "epoch:16 step:15831 [D loss: 0.241622, acc.: 60.16%] [G loss: 0.294675]\n",
      "epoch:16 step:15832 [D loss: 0.246402, acc.: 55.47%] [G loss: 0.281642]\n",
      "epoch:16 step:15833 [D loss: 0.249231, acc.: 59.38%] [G loss: 0.316710]\n",
      "epoch:16 step:15834 [D loss: 0.250950, acc.: 57.03%] [G loss: 0.283742]\n",
      "epoch:16 step:15835 [D loss: 0.234244, acc.: 57.81%] [G loss: 0.299959]\n",
      "epoch:16 step:15836 [D loss: 0.226369, acc.: 64.84%] [G loss: 0.294164]\n",
      "epoch:16 step:15837 [D loss: 0.235071, acc.: 64.84%] [G loss: 0.290296]\n",
      "epoch:16 step:15838 [D loss: 0.251718, acc.: 48.44%] [G loss: 0.300320]\n",
      "epoch:16 step:15839 [D loss: 0.231813, acc.: 61.72%] [G loss: 0.313175]\n",
      "epoch:16 step:15840 [D loss: 0.240725, acc.: 56.25%] [G loss: 0.306036]\n",
      "epoch:16 step:15841 [D loss: 0.238871, acc.: 61.72%] [G loss: 0.283823]\n",
      "epoch:16 step:15842 [D loss: 0.224906, acc.: 64.06%] [G loss: 0.309487]\n",
      "epoch:16 step:15843 [D loss: 0.251242, acc.: 55.47%] [G loss: 0.307447]\n",
      "epoch:16 step:15844 [D loss: 0.259107, acc.: 52.34%] [G loss: 0.311831]\n",
      "epoch:16 step:15845 [D loss: 0.234462, acc.: 57.81%] [G loss: 0.309879]\n",
      "epoch:16 step:15846 [D loss: 0.224743, acc.: 64.06%] [G loss: 0.326577]\n",
      "epoch:16 step:15847 [D loss: 0.258462, acc.: 53.12%] [G loss: 0.292738]\n",
      "epoch:16 step:15848 [D loss: 0.218311, acc.: 70.31%] [G loss: 0.306396]\n",
      "epoch:16 step:15849 [D loss: 0.235944, acc.: 64.06%] [G loss: 0.287631]\n",
      "epoch:16 step:15850 [D loss: 0.225395, acc.: 57.81%] [G loss: 0.312828]\n",
      "epoch:16 step:15851 [D loss: 0.243159, acc.: 52.34%] [G loss: 0.286625]\n",
      "epoch:16 step:15852 [D loss: 0.221500, acc.: 67.97%] [G loss: 0.290039]\n",
      "epoch:16 step:15853 [D loss: 0.225063, acc.: 60.16%] [G loss: 0.313925]\n",
      "epoch:16 step:15854 [D loss: 0.232899, acc.: 59.38%] [G loss: 0.319882]\n",
      "epoch:16 step:15855 [D loss: 0.250023, acc.: 53.12%] [G loss: 0.303225]\n",
      "epoch:16 step:15856 [D loss: 0.239084, acc.: 55.47%] [G loss: 0.297738]\n",
      "epoch:16 step:15857 [D loss: 0.238853, acc.: 62.50%] [G loss: 0.304204]\n",
      "epoch:16 step:15858 [D loss: 0.253854, acc.: 51.56%] [G loss: 0.318708]\n",
      "epoch:16 step:15859 [D loss: 0.258654, acc.: 52.34%] [G loss: 0.288055]\n",
      "epoch:16 step:15860 [D loss: 0.227129, acc.: 59.38%] [G loss: 0.291288]\n",
      "epoch:16 step:15861 [D loss: 0.242679, acc.: 54.69%] [G loss: 0.306673]\n",
      "epoch:16 step:15862 [D loss: 0.235627, acc.: 64.84%] [G loss: 0.313798]\n",
      "epoch:16 step:15863 [D loss: 0.233153, acc.: 57.81%] [G loss: 0.288714]\n",
      "epoch:16 step:15864 [D loss: 0.250684, acc.: 57.03%] [G loss: 0.312997]\n",
      "epoch:16 step:15865 [D loss: 0.220349, acc.: 64.06%] [G loss: 0.312839]\n",
      "epoch:16 step:15866 [D loss: 0.238904, acc.: 56.25%] [G loss: 0.318648]\n",
      "epoch:16 step:15867 [D loss: 0.235701, acc.: 62.50%] [G loss: 0.321365]\n",
      "epoch:16 step:15868 [D loss: 0.248874, acc.: 53.12%] [G loss: 0.300494]\n",
      "epoch:16 step:15869 [D loss: 0.243293, acc.: 50.00%] [G loss: 0.281514]\n",
      "epoch:16 step:15870 [D loss: 0.243207, acc.: 57.81%] [G loss: 0.324567]\n",
      "epoch:16 step:15871 [D loss: 0.234163, acc.: 62.50%] [G loss: 0.295350]\n",
      "epoch:16 step:15872 [D loss: 0.242023, acc.: 56.25%] [G loss: 0.318287]\n",
      "epoch:16 step:15873 [D loss: 0.239041, acc.: 58.59%] [G loss: 0.307297]\n",
      "epoch:16 step:15874 [D loss: 0.210174, acc.: 66.41%] [G loss: 0.301639]\n",
      "epoch:16 step:15875 [D loss: 0.241833, acc.: 57.03%] [G loss: 0.313920]\n",
      "epoch:16 step:15876 [D loss: 0.237199, acc.: 56.25%] [G loss: 0.332480]\n",
      "epoch:16 step:15877 [D loss: 0.231209, acc.: 60.16%] [G loss: 0.306755]\n",
      "epoch:16 step:15878 [D loss: 0.226095, acc.: 61.72%] [G loss: 0.321564]\n",
      "epoch:16 step:15879 [D loss: 0.234362, acc.: 60.94%] [G loss: 0.291719]\n",
      "epoch:16 step:15880 [D loss: 0.251674, acc.: 54.69%] [G loss: 0.317009]\n",
      "epoch:16 step:15881 [D loss: 0.225158, acc.: 67.19%] [G loss: 0.347354]\n",
      "epoch:16 step:15882 [D loss: 0.228491, acc.: 62.50%] [G loss: 0.306057]\n",
      "epoch:16 step:15883 [D loss: 0.263135, acc.: 50.00%] [G loss: 0.290499]\n",
      "epoch:16 step:15884 [D loss: 0.221563, acc.: 62.50%] [G loss: 0.324777]\n",
      "epoch:16 step:15885 [D loss: 0.230636, acc.: 60.16%] [G loss: 0.311319]\n",
      "epoch:16 step:15886 [D loss: 0.237659, acc.: 60.94%] [G loss: 0.343324]\n",
      "epoch:16 step:15887 [D loss: 0.244678, acc.: 55.47%] [G loss: 0.305059]\n",
      "epoch:16 step:15888 [D loss: 0.243630, acc.: 54.69%] [G loss: 0.312807]\n",
      "epoch:16 step:15889 [D loss: 0.234237, acc.: 60.16%] [G loss: 0.308593]\n",
      "epoch:16 step:15890 [D loss: 0.239612, acc.: 60.16%] [G loss: 0.300300]\n",
      "epoch:16 step:15891 [D loss: 0.247908, acc.: 55.47%] [G loss: 0.293621]\n",
      "epoch:16 step:15892 [D loss: 0.228727, acc.: 61.72%] [G loss: 0.293770]\n",
      "epoch:16 step:15893 [D loss: 0.247118, acc.: 55.47%] [G loss: 0.313418]\n",
      "epoch:16 step:15894 [D loss: 0.254847, acc.: 53.91%] [G loss: 0.270361]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:16 step:15895 [D loss: 0.248506, acc.: 55.47%] [G loss: 0.303196]\n",
      "epoch:16 step:15896 [D loss: 0.234746, acc.: 59.38%] [G loss: 0.281814]\n",
      "epoch:16 step:15897 [D loss: 0.256837, acc.: 53.91%] [G loss: 0.302991]\n",
      "epoch:16 step:15898 [D loss: 0.246193, acc.: 60.16%] [G loss: 0.284913]\n",
      "epoch:16 step:15899 [D loss: 0.235097, acc.: 62.50%] [G loss: 0.316587]\n",
      "epoch:16 step:15900 [D loss: 0.244330, acc.: 57.03%] [G loss: 0.312902]\n",
      "epoch:16 step:15901 [D loss: 0.244242, acc.: 54.69%] [G loss: 0.292722]\n",
      "epoch:16 step:15902 [D loss: 0.259792, acc.: 48.44%] [G loss: 0.316060]\n",
      "epoch:16 step:15903 [D loss: 0.248636, acc.: 55.47%] [G loss: 0.297051]\n",
      "epoch:16 step:15904 [D loss: 0.266084, acc.: 48.44%] [G loss: 0.289680]\n",
      "epoch:16 step:15905 [D loss: 0.239703, acc.: 55.47%] [G loss: 0.312513]\n",
      "epoch:16 step:15906 [D loss: 0.232707, acc.: 63.28%] [G loss: 0.314679]\n",
      "epoch:16 step:15907 [D loss: 0.243274, acc.: 59.38%] [G loss: 0.287171]\n",
      "epoch:16 step:15908 [D loss: 0.233159, acc.: 64.06%] [G loss: 0.282778]\n",
      "epoch:16 step:15909 [D loss: 0.240820, acc.: 59.38%] [G loss: 0.293287]\n",
      "epoch:16 step:15910 [D loss: 0.231773, acc.: 57.81%] [G loss: 0.309080]\n",
      "epoch:16 step:15911 [D loss: 0.249037, acc.: 58.59%] [G loss: 0.275861]\n",
      "epoch:16 step:15912 [D loss: 0.225646, acc.: 61.72%] [G loss: 0.298326]\n",
      "epoch:16 step:15913 [D loss: 0.234534, acc.: 61.72%] [G loss: 0.307012]\n",
      "epoch:16 step:15914 [D loss: 0.231680, acc.: 63.28%] [G loss: 0.318155]\n",
      "epoch:16 step:15915 [D loss: 0.254038, acc.: 50.78%] [G loss: 0.278728]\n",
      "epoch:16 step:15916 [D loss: 0.230069, acc.: 60.16%] [G loss: 0.299305]\n",
      "epoch:16 step:15917 [D loss: 0.235150, acc.: 56.25%] [G loss: 0.315199]\n",
      "epoch:16 step:15918 [D loss: 0.240341, acc.: 56.25%] [G loss: 0.277980]\n",
      "epoch:16 step:15919 [D loss: 0.232445, acc.: 57.81%] [G loss: 0.311620]\n",
      "epoch:16 step:15920 [D loss: 0.248148, acc.: 53.12%] [G loss: 0.299663]\n",
      "epoch:16 step:15921 [D loss: 0.229631, acc.: 58.59%] [G loss: 0.322347]\n",
      "epoch:16 step:15922 [D loss: 0.240659, acc.: 52.34%] [G loss: 0.308416]\n",
      "epoch:16 step:15923 [D loss: 0.236469, acc.: 58.59%] [G loss: 0.315296]\n",
      "epoch:16 step:15924 [D loss: 0.240254, acc.: 57.81%] [G loss: 0.307854]\n",
      "epoch:16 step:15925 [D loss: 0.259741, acc.: 47.66%] [G loss: 0.312772]\n",
      "epoch:16 step:15926 [D loss: 0.230532, acc.: 64.84%] [G loss: 0.334426]\n",
      "epoch:16 step:15927 [D loss: 0.227111, acc.: 61.72%] [G loss: 0.305581]\n",
      "epoch:16 step:15928 [D loss: 0.235594, acc.: 60.94%] [G loss: 0.281315]\n",
      "epoch:16 step:15929 [D loss: 0.231751, acc.: 61.72%] [G loss: 0.296155]\n",
      "epoch:17 step:15930 [D loss: 0.239061, acc.: 57.81%] [G loss: 0.307335]\n",
      "epoch:17 step:15931 [D loss: 0.248571, acc.: 53.91%] [G loss: 0.303755]\n",
      "epoch:17 step:15932 [D loss: 0.250960, acc.: 57.03%] [G loss: 0.298808]\n",
      "epoch:17 step:15933 [D loss: 0.222268, acc.: 65.62%] [G loss: 0.289455]\n",
      "epoch:17 step:15934 [D loss: 0.247546, acc.: 57.03%] [G loss: 0.320530]\n",
      "epoch:17 step:15935 [D loss: 0.254256, acc.: 56.25%] [G loss: 0.304120]\n",
      "epoch:17 step:15936 [D loss: 0.234791, acc.: 61.72%] [G loss: 0.308387]\n",
      "epoch:17 step:15937 [D loss: 0.248786, acc.: 54.69%] [G loss: 0.310734]\n",
      "epoch:17 step:15938 [D loss: 0.234805, acc.: 57.81%] [G loss: 0.305855]\n",
      "epoch:17 step:15939 [D loss: 0.244056, acc.: 56.25%] [G loss: 0.309454]\n",
      "epoch:17 step:15940 [D loss: 0.245492, acc.: 53.12%] [G loss: 0.287508]\n",
      "epoch:17 step:15941 [D loss: 0.240474, acc.: 60.16%] [G loss: 0.283572]\n",
      "epoch:17 step:15942 [D loss: 0.222359, acc.: 70.31%] [G loss: 0.332512]\n",
      "epoch:17 step:15943 [D loss: 0.246696, acc.: 57.03%] [G loss: 0.292940]\n",
      "epoch:17 step:15944 [D loss: 0.234981, acc.: 59.38%] [G loss: 0.281802]\n",
      "epoch:17 step:15945 [D loss: 0.230911, acc.: 60.16%] [G loss: 0.327023]\n",
      "epoch:17 step:15946 [D loss: 0.217041, acc.: 67.97%] [G loss: 0.320193]\n",
      "epoch:17 step:15947 [D loss: 0.243179, acc.: 53.91%] [G loss: 0.278162]\n",
      "epoch:17 step:15948 [D loss: 0.252323, acc.: 54.69%] [G loss: 0.291719]\n",
      "epoch:17 step:15949 [D loss: 0.240572, acc.: 53.12%] [G loss: 0.290644]\n",
      "epoch:17 step:15950 [D loss: 0.243620, acc.: 59.38%] [G loss: 0.310448]\n",
      "epoch:17 step:15951 [D loss: 0.227642, acc.: 60.16%] [G loss: 0.316101]\n",
      "epoch:17 step:15952 [D loss: 0.229485, acc.: 62.50%] [G loss: 0.296809]\n",
      "epoch:17 step:15953 [D loss: 0.230193, acc.: 62.50%] [G loss: 0.281333]\n",
      "epoch:17 step:15954 [D loss: 0.240864, acc.: 58.59%] [G loss: 0.284581]\n",
      "epoch:17 step:15955 [D loss: 0.244739, acc.: 60.16%] [G loss: 0.316123]\n",
      "epoch:17 step:15956 [D loss: 0.248070, acc.: 53.12%] [G loss: 0.303747]\n",
      "epoch:17 step:15957 [D loss: 0.235141, acc.: 57.81%] [G loss: 0.313132]\n",
      "epoch:17 step:15958 [D loss: 0.240144, acc.: 60.16%] [G loss: 0.314021]\n",
      "epoch:17 step:15959 [D loss: 0.221646, acc.: 64.84%] [G loss: 0.331023]\n",
      "epoch:17 step:15960 [D loss: 0.241671, acc.: 56.25%] [G loss: 0.303001]\n",
      "epoch:17 step:15961 [D loss: 0.235134, acc.: 61.72%] [G loss: 0.280217]\n",
      "epoch:17 step:15962 [D loss: 0.232323, acc.: 60.94%] [G loss: 0.300350]\n",
      "epoch:17 step:15963 [D loss: 0.241583, acc.: 53.12%] [G loss: 0.320874]\n",
      "epoch:17 step:15964 [D loss: 0.227771, acc.: 64.84%] [G loss: 0.299783]\n",
      "epoch:17 step:15965 [D loss: 0.246103, acc.: 58.59%] [G loss: 0.310897]\n",
      "epoch:17 step:15966 [D loss: 0.222796, acc.: 62.50%] [G loss: 0.281119]\n",
      "epoch:17 step:15967 [D loss: 0.241275, acc.: 53.12%] [G loss: 0.326248]\n",
      "epoch:17 step:15968 [D loss: 0.232425, acc.: 62.50%] [G loss: 0.297258]\n",
      "epoch:17 step:15969 [D loss: 0.237701, acc.: 64.84%] [G loss: 0.309756]\n",
      "epoch:17 step:15970 [D loss: 0.251079, acc.: 55.47%] [G loss: 0.294331]\n",
      "epoch:17 step:15971 [D loss: 0.261814, acc.: 49.22%] [G loss: 0.308640]\n",
      "epoch:17 step:15972 [D loss: 0.239981, acc.: 60.16%] [G loss: 0.302793]\n",
      "epoch:17 step:15973 [D loss: 0.217909, acc.: 69.53%] [G loss: 0.311433]\n",
      "epoch:17 step:15974 [D loss: 0.238109, acc.: 58.59%] [G loss: 0.308897]\n",
      "epoch:17 step:15975 [D loss: 0.257578, acc.: 50.00%] [G loss: 0.294612]\n",
      "epoch:17 step:15976 [D loss: 0.254992, acc.: 50.00%] [G loss: 0.317769]\n",
      "epoch:17 step:15977 [D loss: 0.237776, acc.: 55.47%] [G loss: 0.307339]\n",
      "epoch:17 step:15978 [D loss: 0.235842, acc.: 63.28%] [G loss: 0.314829]\n",
      "epoch:17 step:15979 [D loss: 0.221234, acc.: 61.72%] [G loss: 0.308301]\n",
      "epoch:17 step:15980 [D loss: 0.256304, acc.: 50.00%] [G loss: 0.304807]\n",
      "epoch:17 step:15981 [D loss: 0.222694, acc.: 64.06%] [G loss: 0.304631]\n",
      "epoch:17 step:15982 [D loss: 0.220891, acc.: 64.84%] [G loss: 0.321857]\n",
      "epoch:17 step:15983 [D loss: 0.224115, acc.: 61.72%] [G loss: 0.284064]\n",
      "epoch:17 step:15984 [D loss: 0.258103, acc.: 49.22%] [G loss: 0.323258]\n",
      "epoch:17 step:15985 [D loss: 0.243638, acc.: 57.03%] [G loss: 0.311757]\n",
      "epoch:17 step:15986 [D loss: 0.243679, acc.: 54.69%] [G loss: 0.273212]\n",
      "epoch:17 step:15987 [D loss: 0.229091, acc.: 61.72%] [G loss: 0.345427]\n",
      "epoch:17 step:15988 [D loss: 0.262473, acc.: 50.00%] [G loss: 0.306612]\n",
      "epoch:17 step:15989 [D loss: 0.219739, acc.: 67.97%] [G loss: 0.299468]\n",
      "epoch:17 step:15990 [D loss: 0.257053, acc.: 52.34%] [G loss: 0.306412]\n",
      "epoch:17 step:15991 [D loss: 0.247228, acc.: 48.44%] [G loss: 0.301306]\n",
      "epoch:17 step:15992 [D loss: 0.240465, acc.: 56.25%] [G loss: 0.292883]\n",
      "epoch:17 step:15993 [D loss: 0.241260, acc.: 54.69%] [G loss: 0.311335]\n",
      "epoch:17 step:15994 [D loss: 0.229592, acc.: 61.72%] [G loss: 0.305183]\n",
      "epoch:17 step:15995 [D loss: 0.241023, acc.: 57.81%] [G loss: 0.286820]\n",
      "epoch:17 step:15996 [D loss: 0.232410, acc.: 57.81%] [G loss: 0.287251]\n",
      "epoch:17 step:15997 [D loss: 0.245835, acc.: 53.91%] [G loss: 0.297455]\n",
      "epoch:17 step:15998 [D loss: 0.227936, acc.: 61.72%] [G loss: 0.293086]\n",
      "epoch:17 step:15999 [D loss: 0.242073, acc.: 59.38%] [G loss: 0.305534]\n",
      "epoch:17 step:16000 [D loss: 0.254500, acc.: 52.34%] [G loss: 0.299232]\n",
      "epoch:17 step:16001 [D loss: 0.238239, acc.: 55.47%] [G loss: 0.311442]\n",
      "epoch:17 step:16002 [D loss: 0.222760, acc.: 64.84%] [G loss: 0.307977]\n",
      "epoch:17 step:16003 [D loss: 0.230457, acc.: 57.81%] [G loss: 0.335161]\n",
      "epoch:17 step:16004 [D loss: 0.230462, acc.: 62.50%] [G loss: 0.306810]\n",
      "epoch:17 step:16005 [D loss: 0.235656, acc.: 57.03%] [G loss: 0.290245]\n",
      "epoch:17 step:16006 [D loss: 0.247509, acc.: 58.59%] [G loss: 0.305639]\n",
      "epoch:17 step:16007 [D loss: 0.240268, acc.: 57.03%] [G loss: 0.297005]\n",
      "epoch:17 step:16008 [D loss: 0.235143, acc.: 56.25%] [G loss: 0.340793]\n",
      "epoch:17 step:16009 [D loss: 0.236969, acc.: 58.59%] [G loss: 0.320470]\n",
      "epoch:17 step:16010 [D loss: 0.230887, acc.: 61.72%] [G loss: 0.289710]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:17 step:16011 [D loss: 0.240431, acc.: 52.34%] [G loss: 0.301159]\n",
      "epoch:17 step:16012 [D loss: 0.229801, acc.: 62.50%] [G loss: 0.330221]\n",
      "epoch:17 step:16013 [D loss: 0.223998, acc.: 64.84%] [G loss: 0.309199]\n",
      "epoch:17 step:16014 [D loss: 0.241137, acc.: 56.25%] [G loss: 0.304607]\n",
      "epoch:17 step:16015 [D loss: 0.240734, acc.: 55.47%] [G loss: 0.263226]\n",
      "epoch:17 step:16016 [D loss: 0.250165, acc.: 51.56%] [G loss: 0.303560]\n",
      "epoch:17 step:16017 [D loss: 0.247943, acc.: 51.56%] [G loss: 0.297423]\n",
      "epoch:17 step:16018 [D loss: 0.222833, acc.: 66.41%] [G loss: 0.291035]\n",
      "epoch:17 step:16019 [D loss: 0.212320, acc.: 68.75%] [G loss: 0.274654]\n",
      "epoch:17 step:16020 [D loss: 0.242965, acc.: 57.03%] [G loss: 0.289837]\n",
      "epoch:17 step:16021 [D loss: 0.235913, acc.: 60.16%] [G loss: 0.298521]\n",
      "epoch:17 step:16022 [D loss: 0.238984, acc.: 60.16%] [G loss: 0.297164]\n",
      "epoch:17 step:16023 [D loss: 0.239421, acc.: 59.38%] [G loss: 0.326413]\n",
      "epoch:17 step:16024 [D loss: 0.242035, acc.: 56.25%] [G loss: 0.285189]\n",
      "epoch:17 step:16025 [D loss: 0.240333, acc.: 56.25%] [G loss: 0.307824]\n",
      "epoch:17 step:16026 [D loss: 0.242005, acc.: 61.72%] [G loss: 0.312978]\n",
      "epoch:17 step:16027 [D loss: 0.234728, acc.: 56.25%] [G loss: 0.315912]\n",
      "epoch:17 step:16028 [D loss: 0.228907, acc.: 60.94%] [G loss: 0.335949]\n",
      "epoch:17 step:16029 [D loss: 0.232643, acc.: 61.72%] [G loss: 0.279036]\n",
      "epoch:17 step:16030 [D loss: 0.225928, acc.: 61.72%] [G loss: 0.312837]\n",
      "epoch:17 step:16031 [D loss: 0.256620, acc.: 53.12%] [G loss: 0.285751]\n",
      "epoch:17 step:16032 [D loss: 0.217060, acc.: 62.50%] [G loss: 0.328795]\n",
      "epoch:17 step:16033 [D loss: 0.243722, acc.: 62.50%] [G loss: 0.313071]\n",
      "epoch:17 step:16034 [D loss: 0.240440, acc.: 58.59%] [G loss: 0.283249]\n",
      "epoch:17 step:16035 [D loss: 0.245254, acc.: 54.69%] [G loss: 0.316523]\n",
      "epoch:17 step:16036 [D loss: 0.234153, acc.: 57.81%] [G loss: 0.303995]\n",
      "epoch:17 step:16037 [D loss: 0.237574, acc.: 62.50%] [G loss: 0.322744]\n",
      "epoch:17 step:16038 [D loss: 0.214840, acc.: 69.53%] [G loss: 0.295975]\n",
      "epoch:17 step:16039 [D loss: 0.236259, acc.: 57.03%] [G loss: 0.312471]\n",
      "epoch:17 step:16040 [D loss: 0.248677, acc.: 58.59%] [G loss: 0.315283]\n",
      "epoch:17 step:16041 [D loss: 0.237969, acc.: 58.59%] [G loss: 0.278218]\n",
      "epoch:17 step:16042 [D loss: 0.249318, acc.: 53.12%] [G loss: 0.329290]\n",
      "epoch:17 step:16043 [D loss: 0.212099, acc.: 64.06%] [G loss: 0.315430]\n",
      "epoch:17 step:16044 [D loss: 0.260328, acc.: 50.78%] [G loss: 0.299251]\n",
      "epoch:17 step:16045 [D loss: 0.235550, acc.: 57.81%] [G loss: 0.276781]\n",
      "epoch:17 step:16046 [D loss: 0.246210, acc.: 58.59%] [G loss: 0.302844]\n",
      "epoch:17 step:16047 [D loss: 0.233463, acc.: 64.84%] [G loss: 0.313779]\n",
      "epoch:17 step:16048 [D loss: 0.242218, acc.: 57.81%] [G loss: 0.287855]\n",
      "epoch:17 step:16049 [D loss: 0.241332, acc.: 62.50%] [G loss: 0.318285]\n",
      "epoch:17 step:16050 [D loss: 0.226727, acc.: 63.28%] [G loss: 0.293415]\n",
      "epoch:17 step:16051 [D loss: 0.235747, acc.: 57.81%] [G loss: 0.308887]\n",
      "epoch:17 step:16052 [D loss: 0.213844, acc.: 67.19%] [G loss: 0.283378]\n",
      "epoch:17 step:16053 [D loss: 0.238462, acc.: 54.69%] [G loss: 0.285564]\n",
      "epoch:17 step:16054 [D loss: 0.253454, acc.: 51.56%] [G loss: 0.305288]\n",
      "epoch:17 step:16055 [D loss: 0.248323, acc.: 55.47%] [G loss: 0.309863]\n",
      "epoch:17 step:16056 [D loss: 0.242860, acc.: 54.69%] [G loss: 0.316232]\n",
      "epoch:17 step:16057 [D loss: 0.246255, acc.: 56.25%] [G loss: 0.298362]\n",
      "epoch:17 step:16058 [D loss: 0.256729, acc.: 47.66%] [G loss: 0.282144]\n",
      "epoch:17 step:16059 [D loss: 0.246553, acc.: 53.91%] [G loss: 0.308984]\n",
      "epoch:17 step:16060 [D loss: 0.236091, acc.: 62.50%] [G loss: 0.286273]\n",
      "epoch:17 step:16061 [D loss: 0.240003, acc.: 57.03%] [G loss: 0.292849]\n",
      "epoch:17 step:16062 [D loss: 0.237885, acc.: 64.84%] [G loss: 0.284408]\n",
      "epoch:17 step:16063 [D loss: 0.251907, acc.: 53.12%] [G loss: 0.294686]\n",
      "epoch:17 step:16064 [D loss: 0.228460, acc.: 57.03%] [G loss: 0.305140]\n",
      "epoch:17 step:16065 [D loss: 0.256123, acc.: 53.12%] [G loss: 0.313904]\n",
      "epoch:17 step:16066 [D loss: 0.239644, acc.: 56.25%] [G loss: 0.304776]\n",
      "epoch:17 step:16067 [D loss: 0.228597, acc.: 58.59%] [G loss: 0.303540]\n",
      "epoch:17 step:16068 [D loss: 0.245664, acc.: 57.03%] [G loss: 0.293704]\n",
      "epoch:17 step:16069 [D loss: 0.222379, acc.: 62.50%] [G loss: 0.307451]\n",
      "epoch:17 step:16070 [D loss: 0.269788, acc.: 48.44%] [G loss: 0.297056]\n",
      "epoch:17 step:16071 [D loss: 0.233182, acc.: 63.28%] [G loss: 0.283828]\n",
      "epoch:17 step:16072 [D loss: 0.227079, acc.: 61.72%] [G loss: 0.296585]\n",
      "epoch:17 step:16073 [D loss: 0.240582, acc.: 59.38%] [G loss: 0.306344]\n",
      "epoch:17 step:16074 [D loss: 0.236867, acc.: 63.28%] [G loss: 0.310703]\n",
      "epoch:17 step:16075 [D loss: 0.227543, acc.: 65.62%] [G loss: 0.297057]\n",
      "epoch:17 step:16076 [D loss: 0.233030, acc.: 60.16%] [G loss: 0.285072]\n",
      "epoch:17 step:16077 [D loss: 0.249581, acc.: 57.03%] [G loss: 0.278857]\n",
      "epoch:17 step:16078 [D loss: 0.247356, acc.: 58.59%] [G loss: 0.319716]\n",
      "epoch:17 step:16079 [D loss: 0.236346, acc.: 60.94%] [G loss: 0.287759]\n",
      "epoch:17 step:16080 [D loss: 0.224357, acc.: 58.59%] [G loss: 0.322086]\n",
      "epoch:17 step:16081 [D loss: 0.234582, acc.: 60.16%] [G loss: 0.297056]\n",
      "epoch:17 step:16082 [D loss: 0.235318, acc.: 59.38%] [G loss: 0.338153]\n",
      "epoch:17 step:16083 [D loss: 0.247773, acc.: 57.03%] [G loss: 0.315215]\n",
      "epoch:17 step:16084 [D loss: 0.259631, acc.: 50.00%] [G loss: 0.297862]\n",
      "epoch:17 step:16085 [D loss: 0.248611, acc.: 49.22%] [G loss: 0.294720]\n",
      "epoch:17 step:16086 [D loss: 0.240051, acc.: 59.38%] [G loss: 0.276436]\n",
      "epoch:17 step:16087 [D loss: 0.230470, acc.: 60.94%] [G loss: 0.273207]\n",
      "epoch:17 step:16088 [D loss: 0.217002, acc.: 64.06%] [G loss: 0.288074]\n",
      "epoch:17 step:16089 [D loss: 0.243007, acc.: 57.03%] [G loss: 0.318737]\n",
      "epoch:17 step:16090 [D loss: 0.252934, acc.: 53.12%] [G loss: 0.290713]\n",
      "epoch:17 step:16091 [D loss: 0.229699, acc.: 64.06%] [G loss: 0.290033]\n",
      "epoch:17 step:16092 [D loss: 0.232518, acc.: 60.16%] [G loss: 0.300570]\n",
      "epoch:17 step:16093 [D loss: 0.223346, acc.: 63.28%] [G loss: 0.300565]\n",
      "epoch:17 step:16094 [D loss: 0.247174, acc.: 53.12%] [G loss: 0.317003]\n",
      "epoch:17 step:16095 [D loss: 0.213968, acc.: 69.53%] [G loss: 0.340884]\n",
      "epoch:17 step:16096 [D loss: 0.242711, acc.: 61.72%] [G loss: 0.288862]\n",
      "epoch:17 step:16097 [D loss: 0.230269, acc.: 60.16%] [G loss: 0.299760]\n",
      "epoch:17 step:16098 [D loss: 0.245578, acc.: 58.59%] [G loss: 0.286406]\n",
      "epoch:17 step:16099 [D loss: 0.245621, acc.: 60.94%] [G loss: 0.305270]\n",
      "epoch:17 step:16100 [D loss: 0.243455, acc.: 61.72%] [G loss: 0.294095]\n",
      "epoch:17 step:16101 [D loss: 0.215798, acc.: 67.19%] [G loss: 0.332446]\n",
      "epoch:17 step:16102 [D loss: 0.241423, acc.: 54.69%] [G loss: 0.273283]\n",
      "epoch:17 step:16103 [D loss: 0.247996, acc.: 52.34%] [G loss: 0.312388]\n",
      "epoch:17 step:16104 [D loss: 0.258366, acc.: 54.69%] [G loss: 0.329096]\n",
      "epoch:17 step:16105 [D loss: 0.234316, acc.: 63.28%] [G loss: 0.288016]\n",
      "epoch:17 step:16106 [D loss: 0.228789, acc.: 66.41%] [G loss: 0.317787]\n",
      "epoch:17 step:16107 [D loss: 0.243151, acc.: 53.91%] [G loss: 0.302919]\n",
      "epoch:17 step:16108 [D loss: 0.261639, acc.: 53.12%] [G loss: 0.314227]\n",
      "epoch:17 step:16109 [D loss: 0.232073, acc.: 60.16%] [G loss: 0.266196]\n",
      "epoch:17 step:16110 [D loss: 0.242119, acc.: 63.28%] [G loss: 0.285312]\n",
      "epoch:17 step:16111 [D loss: 0.229594, acc.: 66.41%] [G loss: 0.286180]\n",
      "epoch:17 step:16112 [D loss: 0.229476, acc.: 58.59%] [G loss: 0.299043]\n",
      "epoch:17 step:16113 [D loss: 0.237782, acc.: 55.47%] [G loss: 0.304955]\n",
      "epoch:17 step:16114 [D loss: 0.245574, acc.: 59.38%] [G loss: 0.307876]\n",
      "epoch:17 step:16115 [D loss: 0.237947, acc.: 56.25%] [G loss: 0.324015]\n",
      "epoch:17 step:16116 [D loss: 0.230351, acc.: 61.72%] [G loss: 0.272946]\n",
      "epoch:17 step:16117 [D loss: 0.237926, acc.: 59.38%] [G loss: 0.299893]\n",
      "epoch:17 step:16118 [D loss: 0.221272, acc.: 65.62%] [G loss: 0.330103]\n",
      "epoch:17 step:16119 [D loss: 0.242725, acc.: 53.12%] [G loss: 0.305559]\n",
      "epoch:17 step:16120 [D loss: 0.230699, acc.: 59.38%] [G loss: 0.291312]\n",
      "epoch:17 step:16121 [D loss: 0.242855, acc.: 57.03%] [G loss: 0.296358]\n",
      "epoch:17 step:16122 [D loss: 0.237576, acc.: 60.16%] [G loss: 0.312525]\n",
      "epoch:17 step:16123 [D loss: 0.248491, acc.: 57.81%] [G loss: 0.308503]\n",
      "epoch:17 step:16124 [D loss: 0.234274, acc.: 65.62%] [G loss: 0.290920]\n",
      "epoch:17 step:16125 [D loss: 0.249625, acc.: 57.03%] [G loss: 0.278659]\n",
      "epoch:17 step:16126 [D loss: 0.234904, acc.: 58.59%] [G loss: 0.280979]\n",
      "epoch:17 step:16127 [D loss: 0.237884, acc.: 55.47%] [G loss: 0.299219]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:17 step:16128 [D loss: 0.238301, acc.: 58.59%] [G loss: 0.303598]\n",
      "epoch:17 step:16129 [D loss: 0.261883, acc.: 51.56%] [G loss: 0.262293]\n",
      "epoch:17 step:16130 [D loss: 0.244619, acc.: 61.72%] [G loss: 0.310294]\n",
      "epoch:17 step:16131 [D loss: 0.224754, acc.: 64.84%] [G loss: 0.286660]\n",
      "epoch:17 step:16132 [D loss: 0.240048, acc.: 53.12%] [G loss: 0.278103]\n",
      "epoch:17 step:16133 [D loss: 0.238008, acc.: 60.94%] [G loss: 0.302960]\n",
      "epoch:17 step:16134 [D loss: 0.235284, acc.: 58.59%] [G loss: 0.284117]\n",
      "epoch:17 step:16135 [D loss: 0.226544, acc.: 64.06%] [G loss: 0.295232]\n",
      "epoch:17 step:16136 [D loss: 0.242099, acc.: 60.94%] [G loss: 0.311121]\n",
      "epoch:17 step:16137 [D loss: 0.238779, acc.: 57.03%] [G loss: 0.318414]\n",
      "epoch:17 step:16138 [D loss: 0.243646, acc.: 52.34%] [G loss: 0.306603]\n",
      "epoch:17 step:16139 [D loss: 0.248723, acc.: 57.03%] [G loss: 0.326780]\n",
      "epoch:17 step:16140 [D loss: 0.245500, acc.: 53.91%] [G loss: 0.323027]\n",
      "epoch:17 step:16141 [D loss: 0.234081, acc.: 61.72%] [G loss: 0.286253]\n",
      "epoch:17 step:16142 [D loss: 0.236032, acc.: 57.81%] [G loss: 0.301230]\n",
      "epoch:17 step:16143 [D loss: 0.255750, acc.: 53.12%] [G loss: 0.313447]\n",
      "epoch:17 step:16144 [D loss: 0.249715, acc.: 56.25%] [G loss: 0.290521]\n",
      "epoch:17 step:16145 [D loss: 0.237767, acc.: 53.91%] [G loss: 0.297063]\n",
      "epoch:17 step:16146 [D loss: 0.218080, acc.: 69.53%] [G loss: 0.293780]\n",
      "epoch:17 step:16147 [D loss: 0.237368, acc.: 59.38%] [G loss: 0.318083]\n",
      "epoch:17 step:16148 [D loss: 0.260657, acc.: 49.22%] [G loss: 0.327028]\n",
      "epoch:17 step:16149 [D loss: 0.230453, acc.: 60.16%] [G loss: 0.326524]\n",
      "epoch:17 step:16150 [D loss: 0.240710, acc.: 58.59%] [G loss: 0.286058]\n",
      "epoch:17 step:16151 [D loss: 0.224608, acc.: 60.94%] [G loss: 0.287788]\n",
      "epoch:17 step:16152 [D loss: 0.237533, acc.: 60.94%] [G loss: 0.309736]\n",
      "epoch:17 step:16153 [D loss: 0.237208, acc.: 61.72%] [G loss: 0.300783]\n",
      "epoch:17 step:16154 [D loss: 0.264567, acc.: 46.88%] [G loss: 0.294233]\n",
      "epoch:17 step:16155 [D loss: 0.235613, acc.: 61.72%] [G loss: 0.306376]\n",
      "epoch:17 step:16156 [D loss: 0.242253, acc.: 51.56%] [G loss: 0.306713]\n",
      "epoch:17 step:16157 [D loss: 0.236716, acc.: 57.81%] [G loss: 0.295012]\n",
      "epoch:17 step:16158 [D loss: 0.232817, acc.: 64.06%] [G loss: 0.305859]\n",
      "epoch:17 step:16159 [D loss: 0.241031, acc.: 57.81%] [G loss: 0.291986]\n",
      "epoch:17 step:16160 [D loss: 0.222596, acc.: 65.62%] [G loss: 0.297362]\n",
      "epoch:17 step:16161 [D loss: 0.247480, acc.: 58.59%] [G loss: 0.279571]\n",
      "epoch:17 step:16162 [D loss: 0.232886, acc.: 59.38%] [G loss: 0.318235]\n",
      "epoch:17 step:16163 [D loss: 0.229019, acc.: 59.38%] [G loss: 0.303013]\n",
      "epoch:17 step:16164 [D loss: 0.235960, acc.: 57.81%] [G loss: 0.315079]\n",
      "epoch:17 step:16165 [D loss: 0.231618, acc.: 62.50%] [G loss: 0.264751]\n",
      "epoch:17 step:16166 [D loss: 0.252839, acc.: 53.12%] [G loss: 0.301251]\n",
      "epoch:17 step:16167 [D loss: 0.233511, acc.: 57.81%] [G loss: 0.290871]\n",
      "epoch:17 step:16168 [D loss: 0.228479, acc.: 59.38%] [G loss: 0.303625]\n",
      "epoch:17 step:16169 [D loss: 0.249386, acc.: 53.12%] [G loss: 0.328450]\n",
      "epoch:17 step:16170 [D loss: 0.224741, acc.: 68.75%] [G loss: 0.305135]\n",
      "epoch:17 step:16171 [D loss: 0.238427, acc.: 54.69%] [G loss: 0.310450]\n",
      "epoch:17 step:16172 [D loss: 0.247597, acc.: 57.03%] [G loss: 0.286898]\n",
      "epoch:17 step:16173 [D loss: 0.236245, acc.: 58.59%] [G loss: 0.316276]\n",
      "epoch:17 step:16174 [D loss: 0.250963, acc.: 54.69%] [G loss: 0.316004]\n",
      "epoch:17 step:16175 [D loss: 0.233118, acc.: 64.06%] [G loss: 0.288019]\n",
      "epoch:17 step:16176 [D loss: 0.240874, acc.: 58.59%] [G loss: 0.312670]\n",
      "epoch:17 step:16177 [D loss: 0.228507, acc.: 59.38%] [G loss: 0.303772]\n",
      "epoch:17 step:16178 [D loss: 0.238728, acc.: 60.16%] [G loss: 0.331725]\n",
      "epoch:17 step:16179 [D loss: 0.236580, acc.: 59.38%] [G loss: 0.324837]\n",
      "epoch:17 step:16180 [D loss: 0.240924, acc.: 57.81%] [G loss: 0.304767]\n",
      "epoch:17 step:16181 [D loss: 0.226997, acc.: 60.16%] [G loss: 0.312161]\n",
      "epoch:17 step:16182 [D loss: 0.240092, acc.: 55.47%] [G loss: 0.312416]\n",
      "epoch:17 step:16183 [D loss: 0.259490, acc.: 49.22%] [G loss: 0.296593]\n",
      "epoch:17 step:16184 [D loss: 0.228294, acc.: 60.16%] [G loss: 0.329205]\n",
      "epoch:17 step:16185 [D loss: 0.212731, acc.: 68.75%] [G loss: 0.274227]\n",
      "epoch:17 step:16186 [D loss: 0.246572, acc.: 56.25%] [G loss: 0.299695]\n",
      "epoch:17 step:16187 [D loss: 0.241000, acc.: 54.69%] [G loss: 0.303186]\n",
      "epoch:17 step:16188 [D loss: 0.249701, acc.: 51.56%] [G loss: 0.311209]\n",
      "epoch:17 step:16189 [D loss: 0.244777, acc.: 53.12%] [G loss: 0.306676]\n",
      "epoch:17 step:16190 [D loss: 0.246466, acc.: 57.03%] [G loss: 0.309628]\n",
      "epoch:17 step:16191 [D loss: 0.241181, acc.: 54.69%] [G loss: 0.323683]\n",
      "epoch:17 step:16192 [D loss: 0.262592, acc.: 47.66%] [G loss: 0.295681]\n",
      "epoch:17 step:16193 [D loss: 0.248745, acc.: 54.69%] [G loss: 0.303296]\n",
      "epoch:17 step:16194 [D loss: 0.217722, acc.: 67.97%] [G loss: 0.315425]\n",
      "epoch:17 step:16195 [D loss: 0.226527, acc.: 62.50%] [G loss: 0.307102]\n",
      "epoch:17 step:16196 [D loss: 0.220633, acc.: 60.16%] [G loss: 0.306147]\n",
      "epoch:17 step:16197 [D loss: 0.234813, acc.: 66.41%] [G loss: 0.322582]\n",
      "epoch:17 step:16198 [D loss: 0.239643, acc.: 59.38%] [G loss: 0.307266]\n",
      "epoch:17 step:16199 [D loss: 0.225064, acc.: 64.84%] [G loss: 0.312130]\n",
      "epoch:17 step:16200 [D loss: 0.240982, acc.: 58.59%] [G loss: 0.282426]\n",
      "epoch:17 step:16201 [D loss: 0.218184, acc.: 60.94%] [G loss: 0.295401]\n",
      "epoch:17 step:16202 [D loss: 0.224226, acc.: 64.06%] [G loss: 0.314216]\n",
      "epoch:17 step:16203 [D loss: 0.243773, acc.: 51.56%] [G loss: 0.319268]\n",
      "epoch:17 step:16204 [D loss: 0.249220, acc.: 50.78%] [G loss: 0.326197]\n",
      "epoch:17 step:16205 [D loss: 0.251031, acc.: 55.47%] [G loss: 0.297987]\n",
      "epoch:17 step:16206 [D loss: 0.224460, acc.: 67.19%] [G loss: 0.326303]\n",
      "epoch:17 step:16207 [D loss: 0.230421, acc.: 60.16%] [G loss: 0.295166]\n",
      "epoch:17 step:16208 [D loss: 0.258630, acc.: 52.34%] [G loss: 0.295959]\n",
      "epoch:17 step:16209 [D loss: 0.239082, acc.: 59.38%] [G loss: 0.295931]\n",
      "epoch:17 step:16210 [D loss: 0.245083, acc.: 54.69%] [G loss: 0.290849]\n",
      "epoch:17 step:16211 [D loss: 0.250870, acc.: 53.12%] [G loss: 0.285110]\n",
      "epoch:17 step:16212 [D loss: 0.239932, acc.: 58.59%] [G loss: 0.315054]\n",
      "epoch:17 step:16213 [D loss: 0.262215, acc.: 48.44%] [G loss: 0.284685]\n",
      "epoch:17 step:16214 [D loss: 0.225513, acc.: 60.16%] [G loss: 0.308002]\n",
      "epoch:17 step:16215 [D loss: 0.230657, acc.: 61.72%] [G loss: 0.320078]\n",
      "epoch:17 step:16216 [D loss: 0.229004, acc.: 62.50%] [G loss: 0.326367]\n",
      "epoch:17 step:16217 [D loss: 0.240563, acc.: 58.59%] [G loss: 0.287652]\n",
      "epoch:17 step:16218 [D loss: 0.227483, acc.: 60.16%] [G loss: 0.319682]\n",
      "epoch:17 step:16219 [D loss: 0.222699, acc.: 66.41%] [G loss: 0.321486]\n",
      "epoch:17 step:16220 [D loss: 0.260279, acc.: 50.78%] [G loss: 0.288834]\n",
      "epoch:17 step:16221 [D loss: 0.255623, acc.: 50.78%] [G loss: 0.309143]\n",
      "epoch:17 step:16222 [D loss: 0.240507, acc.: 60.16%] [G loss: 0.308312]\n",
      "epoch:17 step:16223 [D loss: 0.245054, acc.: 57.03%] [G loss: 0.287855]\n",
      "epoch:17 step:16224 [D loss: 0.251017, acc.: 50.00%] [G loss: 0.329097]\n",
      "epoch:17 step:16225 [D loss: 0.250202, acc.: 50.00%] [G loss: 0.285748]\n",
      "epoch:17 step:16226 [D loss: 0.254053, acc.: 51.56%] [G loss: 0.298798]\n",
      "epoch:17 step:16227 [D loss: 0.252245, acc.: 57.03%] [G loss: 0.306437]\n",
      "epoch:17 step:16228 [D loss: 0.255126, acc.: 54.69%] [G loss: 0.292010]\n",
      "epoch:17 step:16229 [D loss: 0.228851, acc.: 63.28%] [G loss: 0.331522]\n",
      "epoch:17 step:16230 [D loss: 0.234540, acc.: 63.28%] [G loss: 0.290624]\n",
      "epoch:17 step:16231 [D loss: 0.235500, acc.: 60.94%] [G loss: 0.296602]\n",
      "epoch:17 step:16232 [D loss: 0.227253, acc.: 59.38%] [G loss: 0.318273]\n",
      "epoch:17 step:16233 [D loss: 0.236926, acc.: 57.03%] [G loss: 0.288670]\n",
      "epoch:17 step:16234 [D loss: 0.216353, acc.: 67.97%] [G loss: 0.326625]\n",
      "epoch:17 step:16235 [D loss: 0.230263, acc.: 60.94%] [G loss: 0.310651]\n",
      "epoch:17 step:16236 [D loss: 0.239852, acc.: 57.81%] [G loss: 0.277579]\n",
      "epoch:17 step:16237 [D loss: 0.224375, acc.: 61.72%] [G loss: 0.331596]\n",
      "epoch:17 step:16238 [D loss: 0.243274, acc.: 53.12%] [G loss: 0.302774]\n",
      "epoch:17 step:16239 [D loss: 0.240311, acc.: 59.38%] [G loss: 0.323518]\n",
      "epoch:17 step:16240 [D loss: 0.240297, acc.: 56.25%] [G loss: 0.336198]\n",
      "epoch:17 step:16241 [D loss: 0.261049, acc.: 52.34%] [G loss: 0.319045]\n",
      "epoch:17 step:16242 [D loss: 0.216669, acc.: 66.41%] [G loss: 0.333379]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:17 step:16243 [D loss: 0.238070, acc.: 63.28%] [G loss: 0.289564]\n",
      "epoch:17 step:16244 [D loss: 0.232032, acc.: 61.72%] [G loss: 0.302025]\n",
      "epoch:17 step:16245 [D loss: 0.251689, acc.: 52.34%] [G loss: 0.291732]\n",
      "epoch:17 step:16246 [D loss: 0.238053, acc.: 60.94%] [G loss: 0.316512]\n",
      "epoch:17 step:16247 [D loss: 0.236211, acc.: 62.50%] [G loss: 0.297020]\n",
      "epoch:17 step:16248 [D loss: 0.234985, acc.: 60.94%] [G loss: 0.304333]\n",
      "epoch:17 step:16249 [D loss: 0.253947, acc.: 53.91%] [G loss: 0.306776]\n",
      "epoch:17 step:16250 [D loss: 0.244579, acc.: 59.38%] [G loss: 0.304670]\n",
      "epoch:17 step:16251 [D loss: 0.228993, acc.: 57.81%] [G loss: 0.294072]\n",
      "epoch:17 step:16252 [D loss: 0.239841, acc.: 53.12%] [G loss: 0.280060]\n",
      "epoch:17 step:16253 [D loss: 0.246104, acc.: 50.78%] [G loss: 0.274526]\n",
      "epoch:17 step:16254 [D loss: 0.228261, acc.: 59.38%] [G loss: 0.323582]\n",
      "epoch:17 step:16255 [D loss: 0.253855, acc.: 45.31%] [G loss: 0.314569]\n",
      "epoch:17 step:16256 [D loss: 0.240788, acc.: 57.81%] [G loss: 0.290157]\n",
      "epoch:17 step:16257 [D loss: 0.235253, acc.: 63.28%] [G loss: 0.281979]\n",
      "epoch:17 step:16258 [D loss: 0.256084, acc.: 49.22%] [G loss: 0.295429]\n",
      "epoch:17 step:16259 [D loss: 0.246676, acc.: 53.91%] [G loss: 0.326347]\n",
      "epoch:17 step:16260 [D loss: 0.226728, acc.: 61.72%] [G loss: 0.320311]\n",
      "epoch:17 step:16261 [D loss: 0.234154, acc.: 58.59%] [G loss: 0.299810]\n",
      "epoch:17 step:16262 [D loss: 0.241819, acc.: 57.03%] [G loss: 0.299974]\n",
      "epoch:17 step:16263 [D loss: 0.230570, acc.: 60.16%] [G loss: 0.298002]\n",
      "epoch:17 step:16264 [D loss: 0.247334, acc.: 54.69%] [G loss: 0.290038]\n",
      "epoch:17 step:16265 [D loss: 0.223084, acc.: 66.41%] [G loss: 0.302761]\n",
      "epoch:17 step:16266 [D loss: 0.230574, acc.: 67.19%] [G loss: 0.318995]\n",
      "epoch:17 step:16267 [D loss: 0.230639, acc.: 56.25%] [G loss: 0.338711]\n",
      "epoch:17 step:16268 [D loss: 0.226256, acc.: 67.97%] [G loss: 0.305541]\n",
      "epoch:17 step:16269 [D loss: 0.244591, acc.: 59.38%] [G loss: 0.312240]\n",
      "epoch:17 step:16270 [D loss: 0.247768, acc.: 53.91%] [G loss: 0.266916]\n",
      "epoch:17 step:16271 [D loss: 0.242309, acc.: 60.16%] [G loss: 0.326811]\n",
      "epoch:17 step:16272 [D loss: 0.252039, acc.: 56.25%] [G loss: 0.292354]\n",
      "epoch:17 step:16273 [D loss: 0.240317, acc.: 58.59%] [G loss: 0.275827]\n",
      "epoch:17 step:16274 [D loss: 0.236532, acc.: 56.25%] [G loss: 0.306783]\n",
      "epoch:17 step:16275 [D loss: 0.245091, acc.: 55.47%] [G loss: 0.315497]\n",
      "epoch:17 step:16276 [D loss: 0.234691, acc.: 60.16%] [G loss: 0.280453]\n",
      "epoch:17 step:16277 [D loss: 0.246319, acc.: 54.69%] [G loss: 0.291156]\n",
      "epoch:17 step:16278 [D loss: 0.227878, acc.: 67.19%] [G loss: 0.299496]\n",
      "epoch:17 step:16279 [D loss: 0.250298, acc.: 53.91%] [G loss: 0.298453]\n",
      "epoch:17 step:16280 [D loss: 0.231859, acc.: 63.28%] [G loss: 0.296338]\n",
      "epoch:17 step:16281 [D loss: 0.240176, acc.: 63.28%] [G loss: 0.298323]\n",
      "epoch:17 step:16282 [D loss: 0.259645, acc.: 50.00%] [G loss: 0.311052]\n",
      "epoch:17 step:16283 [D loss: 0.241666, acc.: 55.47%] [G loss: 0.311378]\n",
      "epoch:17 step:16284 [D loss: 0.232006, acc.: 64.84%] [G loss: 0.309347]\n",
      "epoch:17 step:16285 [D loss: 0.229135, acc.: 58.59%] [G loss: 0.333907]\n",
      "epoch:17 step:16286 [D loss: 0.226068, acc.: 63.28%] [G loss: 0.318674]\n",
      "epoch:17 step:16287 [D loss: 0.232702, acc.: 58.59%] [G loss: 0.301093]\n",
      "epoch:17 step:16288 [D loss: 0.244520, acc.: 55.47%] [G loss: 0.322691]\n",
      "epoch:17 step:16289 [D loss: 0.231445, acc.: 57.81%] [G loss: 0.295275]\n",
      "epoch:17 step:16290 [D loss: 0.223440, acc.: 67.97%] [G loss: 0.322456]\n",
      "epoch:17 step:16291 [D loss: 0.245707, acc.: 57.03%] [G loss: 0.320842]\n",
      "epoch:17 step:16292 [D loss: 0.239667, acc.: 64.84%] [G loss: 0.292408]\n",
      "epoch:17 step:16293 [D loss: 0.263150, acc.: 49.22%] [G loss: 0.291125]\n",
      "epoch:17 step:16294 [D loss: 0.242958, acc.: 57.81%] [G loss: 0.297843]\n",
      "epoch:17 step:16295 [D loss: 0.216677, acc.: 69.53%] [G loss: 0.319551]\n",
      "epoch:17 step:16296 [D loss: 0.236463, acc.: 64.06%] [G loss: 0.289882]\n",
      "epoch:17 step:16297 [D loss: 0.246041, acc.: 56.25%] [G loss: 0.294172]\n",
      "epoch:17 step:16298 [D loss: 0.251688, acc.: 57.03%] [G loss: 0.296470]\n",
      "epoch:17 step:16299 [D loss: 0.247685, acc.: 54.69%] [G loss: 0.293903]\n",
      "epoch:17 step:16300 [D loss: 0.222068, acc.: 62.50%] [G loss: 0.312768]\n",
      "epoch:17 step:16301 [D loss: 0.251953, acc.: 53.91%] [G loss: 0.299537]\n",
      "epoch:17 step:16302 [D loss: 0.239370, acc.: 58.59%] [G loss: 0.302950]\n",
      "epoch:17 step:16303 [D loss: 0.235571, acc.: 63.28%] [G loss: 0.298504]\n",
      "epoch:17 step:16304 [D loss: 0.239483, acc.: 57.03%] [G loss: 0.294747]\n",
      "epoch:17 step:16305 [D loss: 0.262402, acc.: 52.34%] [G loss: 0.316961]\n",
      "epoch:17 step:16306 [D loss: 0.230670, acc.: 59.38%] [G loss: 0.298988]\n",
      "epoch:17 step:16307 [D loss: 0.243369, acc.: 58.59%] [G loss: 0.286170]\n",
      "epoch:17 step:16308 [D loss: 0.250441, acc.: 50.78%] [G loss: 0.294186]\n",
      "epoch:17 step:16309 [D loss: 0.212449, acc.: 71.09%] [G loss: 0.284574]\n",
      "epoch:17 step:16310 [D loss: 0.241346, acc.: 56.25%] [G loss: 0.286530]\n",
      "epoch:17 step:16311 [D loss: 0.242862, acc.: 57.03%] [G loss: 0.328598]\n",
      "epoch:17 step:16312 [D loss: 0.234085, acc.: 57.81%] [G loss: 0.316929]\n",
      "epoch:17 step:16313 [D loss: 0.235489, acc.: 62.50%] [G loss: 0.284052]\n",
      "epoch:17 step:16314 [D loss: 0.237805, acc.: 57.81%] [G loss: 0.319765]\n",
      "epoch:17 step:16315 [D loss: 0.258533, acc.: 57.81%] [G loss: 0.320167]\n",
      "epoch:17 step:16316 [D loss: 0.237236, acc.: 54.69%] [G loss: 0.291856]\n",
      "epoch:17 step:16317 [D loss: 0.235377, acc.: 59.38%] [G loss: 0.300683]\n",
      "epoch:17 step:16318 [D loss: 0.236734, acc.: 60.94%] [G loss: 0.278650]\n",
      "epoch:17 step:16319 [D loss: 0.236059, acc.: 57.81%] [G loss: 0.307765]\n",
      "epoch:17 step:16320 [D loss: 0.252786, acc.: 53.91%] [G loss: 0.269834]\n",
      "epoch:17 step:16321 [D loss: 0.224567, acc.: 62.50%] [G loss: 0.307182]\n",
      "epoch:17 step:16322 [D loss: 0.252564, acc.: 50.00%] [G loss: 0.282907]\n",
      "epoch:17 step:16323 [D loss: 0.232779, acc.: 58.59%] [G loss: 0.314945]\n",
      "epoch:17 step:16324 [D loss: 0.229709, acc.: 63.28%] [G loss: 0.281603]\n",
      "epoch:17 step:16325 [D loss: 0.249036, acc.: 60.94%] [G loss: 0.335595]\n",
      "epoch:17 step:16326 [D loss: 0.244473, acc.: 57.81%] [G loss: 0.291795]\n",
      "epoch:17 step:16327 [D loss: 0.233921, acc.: 58.59%] [G loss: 0.294871]\n",
      "epoch:17 step:16328 [D loss: 0.240082, acc.: 55.47%] [G loss: 0.311030]\n",
      "epoch:17 step:16329 [D loss: 0.231912, acc.: 60.94%] [G loss: 0.302362]\n",
      "epoch:17 step:16330 [D loss: 0.235401, acc.: 58.59%] [G loss: 0.307308]\n",
      "epoch:17 step:16331 [D loss: 0.225211, acc.: 64.84%] [G loss: 0.316403]\n",
      "epoch:17 step:16332 [D loss: 0.242454, acc.: 53.91%] [G loss: 0.316862]\n",
      "epoch:17 step:16333 [D loss: 0.257973, acc.: 52.34%] [G loss: 0.281612]\n",
      "epoch:17 step:16334 [D loss: 0.218884, acc.: 65.62%] [G loss: 0.337862]\n",
      "epoch:17 step:16335 [D loss: 0.242263, acc.: 57.81%] [G loss: 0.300550]\n",
      "epoch:17 step:16336 [D loss: 0.262680, acc.: 50.78%] [G loss: 0.308007]\n",
      "epoch:17 step:16337 [D loss: 0.229978, acc.: 61.72%] [G loss: 0.297336]\n",
      "epoch:17 step:16338 [D loss: 0.245578, acc.: 57.03%] [G loss: 0.309612]\n",
      "epoch:17 step:16339 [D loss: 0.235185, acc.: 56.25%] [G loss: 0.302091]\n",
      "epoch:17 step:16340 [D loss: 0.253633, acc.: 50.78%] [G loss: 0.290441]\n",
      "epoch:17 step:16341 [D loss: 0.246244, acc.: 55.47%] [G loss: 0.330334]\n",
      "epoch:17 step:16342 [D loss: 0.232377, acc.: 64.06%] [G loss: 0.290692]\n",
      "epoch:17 step:16343 [D loss: 0.223803, acc.: 63.28%] [G loss: 0.323725]\n",
      "epoch:17 step:16344 [D loss: 0.243183, acc.: 57.81%] [G loss: 0.291443]\n",
      "epoch:17 step:16345 [D loss: 0.221179, acc.: 65.62%] [G loss: 0.298766]\n",
      "epoch:17 step:16346 [D loss: 0.233267, acc.: 57.03%] [G loss: 0.297354]\n",
      "epoch:17 step:16347 [D loss: 0.243287, acc.: 53.91%] [G loss: 0.293274]\n",
      "epoch:17 step:16348 [D loss: 0.224564, acc.: 64.84%] [G loss: 0.312228]\n",
      "epoch:17 step:16349 [D loss: 0.236010, acc.: 62.50%] [G loss: 0.283157]\n",
      "epoch:17 step:16350 [D loss: 0.218973, acc.: 70.31%] [G loss: 0.293738]\n",
      "epoch:17 step:16351 [D loss: 0.229928, acc.: 60.16%] [G loss: 0.298313]\n",
      "epoch:17 step:16352 [D loss: 0.229660, acc.: 60.16%] [G loss: 0.320242]\n",
      "epoch:17 step:16353 [D loss: 0.234859, acc.: 56.25%] [G loss: 0.297807]\n",
      "epoch:17 step:16354 [D loss: 0.226603, acc.: 65.62%] [G loss: 0.300976]\n",
      "epoch:17 step:16355 [D loss: 0.250151, acc.: 56.25%] [G loss: 0.291818]\n",
      "epoch:17 step:16356 [D loss: 0.228937, acc.: 61.72%] [G loss: 0.294057]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:17 step:16357 [D loss: 0.229382, acc.: 64.06%] [G loss: 0.321030]\n",
      "epoch:17 step:16358 [D loss: 0.261326, acc.: 50.00%] [G loss: 0.312814]\n",
      "epoch:17 step:16359 [D loss: 0.231277, acc.: 53.91%] [G loss: 0.292172]\n",
      "epoch:17 step:16360 [D loss: 0.259423, acc.: 51.56%] [G loss: 0.293566]\n",
      "epoch:17 step:16361 [D loss: 0.241252, acc.: 57.03%] [G loss: 0.302521]\n",
      "epoch:17 step:16362 [D loss: 0.236782, acc.: 57.81%] [G loss: 0.292301]\n",
      "epoch:17 step:16363 [D loss: 0.235253, acc.: 53.91%] [G loss: 0.280435]\n",
      "epoch:17 step:16364 [D loss: 0.223763, acc.: 62.50%] [G loss: 0.296546]\n",
      "epoch:17 step:16365 [D loss: 0.243593, acc.: 54.69%] [G loss: 0.280884]\n",
      "epoch:17 step:16366 [D loss: 0.243167, acc.: 58.59%] [G loss: 0.294069]\n",
      "epoch:17 step:16367 [D loss: 0.234240, acc.: 57.81%] [G loss: 0.317544]\n",
      "epoch:17 step:16368 [D loss: 0.239999, acc.: 51.56%] [G loss: 0.326210]\n",
      "epoch:17 step:16369 [D loss: 0.233246, acc.: 60.16%] [G loss: 0.285183]\n",
      "epoch:17 step:16370 [D loss: 0.236688, acc.: 60.94%] [G loss: 0.322712]\n",
      "epoch:17 step:16371 [D loss: 0.251576, acc.: 52.34%] [G loss: 0.309973]\n",
      "epoch:17 step:16372 [D loss: 0.243570, acc.: 53.91%] [G loss: 0.293234]\n",
      "epoch:17 step:16373 [D loss: 0.229060, acc.: 60.16%] [G loss: 0.305201]\n",
      "epoch:17 step:16374 [D loss: 0.210637, acc.: 67.19%] [G loss: 0.296878]\n",
      "epoch:17 step:16375 [D loss: 0.245076, acc.: 60.16%] [G loss: 0.317602]\n",
      "epoch:17 step:16376 [D loss: 0.250035, acc.: 56.25%] [G loss: 0.289432]\n",
      "epoch:17 step:16377 [D loss: 0.269386, acc.: 50.78%] [G loss: 0.292125]\n",
      "epoch:17 step:16378 [D loss: 0.235764, acc.: 56.25%] [G loss: 0.310121]\n",
      "epoch:17 step:16379 [D loss: 0.233814, acc.: 64.84%] [G loss: 0.304638]\n",
      "epoch:17 step:16380 [D loss: 0.244112, acc.: 55.47%] [G loss: 0.303876]\n",
      "epoch:17 step:16381 [D loss: 0.236946, acc.: 59.38%] [G loss: 0.297520]\n",
      "epoch:17 step:16382 [D loss: 0.223886, acc.: 66.41%] [G loss: 0.302958]\n",
      "epoch:17 step:16383 [D loss: 0.223252, acc.: 64.84%] [G loss: 0.302073]\n",
      "epoch:17 step:16384 [D loss: 0.253694, acc.: 54.69%] [G loss: 0.301766]\n",
      "epoch:17 step:16385 [D loss: 0.222953, acc.: 63.28%] [G loss: 0.306012]\n",
      "epoch:17 step:16386 [D loss: 0.245922, acc.: 58.59%] [G loss: 0.316978]\n",
      "epoch:17 step:16387 [D loss: 0.265889, acc.: 46.88%] [G loss: 0.270835]\n",
      "epoch:17 step:16388 [D loss: 0.225252, acc.: 63.28%] [G loss: 0.281421]\n",
      "epoch:17 step:16389 [D loss: 0.233174, acc.: 60.94%] [G loss: 0.299029]\n",
      "epoch:17 step:16390 [D loss: 0.253425, acc.: 59.38%] [G loss: 0.315200]\n",
      "epoch:17 step:16391 [D loss: 0.241573, acc.: 55.47%] [G loss: 0.305356]\n",
      "epoch:17 step:16392 [D loss: 0.248720, acc.: 53.12%] [G loss: 0.300844]\n",
      "epoch:17 step:16393 [D loss: 0.248638, acc.: 51.56%] [G loss: 0.298341]\n",
      "epoch:17 step:16394 [D loss: 0.244717, acc.: 60.16%] [G loss: 0.306583]\n",
      "epoch:17 step:16395 [D loss: 0.243887, acc.: 58.59%] [G loss: 0.318071]\n",
      "epoch:17 step:16396 [D loss: 0.228357, acc.: 61.72%] [G loss: 0.313528]\n",
      "epoch:17 step:16397 [D loss: 0.246783, acc.: 57.81%] [G loss: 0.269922]\n",
      "epoch:17 step:16398 [D loss: 0.237200, acc.: 62.50%] [G loss: 0.300297]\n",
      "epoch:17 step:16399 [D loss: 0.243819, acc.: 57.03%] [G loss: 0.280699]\n",
      "epoch:17 step:16400 [D loss: 0.242728, acc.: 58.59%] [G loss: 0.298832]\n",
      "epoch:17 step:16401 [D loss: 0.235738, acc.: 58.59%] [G loss: 0.276274]\n",
      "epoch:17 step:16402 [D loss: 0.236597, acc.: 57.81%] [G loss: 0.297574]\n",
      "epoch:17 step:16403 [D loss: 0.238954, acc.: 60.16%] [G loss: 0.318059]\n",
      "epoch:17 step:16404 [D loss: 0.238091, acc.: 59.38%] [G loss: 0.300184]\n",
      "epoch:17 step:16405 [D loss: 0.227441, acc.: 60.94%] [G loss: 0.338388]\n",
      "epoch:17 step:16406 [D loss: 0.249525, acc.: 53.12%] [G loss: 0.305613]\n",
      "epoch:17 step:16407 [D loss: 0.240751, acc.: 61.72%] [G loss: 0.313435]\n",
      "epoch:17 step:16408 [D loss: 0.237857, acc.: 60.16%] [G loss: 0.253856]\n",
      "epoch:17 step:16409 [D loss: 0.252007, acc.: 52.34%] [G loss: 0.291672]\n",
      "epoch:17 step:16410 [D loss: 0.255045, acc.: 49.22%] [G loss: 0.276995]\n",
      "epoch:17 step:16411 [D loss: 0.252343, acc.: 55.47%] [G loss: 0.296984]\n",
      "epoch:17 step:16412 [D loss: 0.242846, acc.: 61.72%] [G loss: 0.294432]\n",
      "epoch:17 step:16413 [D loss: 0.245150, acc.: 57.03%] [G loss: 0.279436]\n",
      "epoch:17 step:16414 [D loss: 0.223970, acc.: 61.72%] [G loss: 0.309855]\n",
      "epoch:17 step:16415 [D loss: 0.218062, acc.: 64.06%] [G loss: 0.322936]\n",
      "epoch:17 step:16416 [D loss: 0.232543, acc.: 60.16%] [G loss: 0.293305]\n",
      "epoch:17 step:16417 [D loss: 0.228520, acc.: 63.28%] [G loss: 0.293685]\n",
      "epoch:17 step:16418 [D loss: 0.251073, acc.: 54.69%] [G loss: 0.270631]\n",
      "epoch:17 step:16419 [D loss: 0.230202, acc.: 59.38%] [G loss: 0.336789]\n",
      "epoch:17 step:16420 [D loss: 0.256267, acc.: 50.78%] [G loss: 0.279713]\n",
      "epoch:17 step:16421 [D loss: 0.240529, acc.: 59.38%] [G loss: 0.308539]\n",
      "epoch:17 step:16422 [D loss: 0.238579, acc.: 60.16%] [G loss: 0.321216]\n",
      "epoch:17 step:16423 [D loss: 0.243832, acc.: 60.94%] [G loss: 0.309807]\n",
      "epoch:17 step:16424 [D loss: 0.232685, acc.: 57.81%] [G loss: 0.318140]\n",
      "epoch:17 step:16425 [D loss: 0.238770, acc.: 55.47%] [G loss: 0.313978]\n",
      "epoch:17 step:16426 [D loss: 0.229194, acc.: 57.81%] [G loss: 0.318180]\n",
      "epoch:17 step:16427 [D loss: 0.233528, acc.: 62.50%] [G loss: 0.312478]\n",
      "epoch:17 step:16428 [D loss: 0.249167, acc.: 57.81%] [G loss: 0.304499]\n",
      "epoch:17 step:16429 [D loss: 0.259508, acc.: 48.44%] [G loss: 0.283602]\n",
      "epoch:17 step:16430 [D loss: 0.229964, acc.: 64.06%] [G loss: 0.286821]\n",
      "epoch:17 step:16431 [D loss: 0.241833, acc.: 57.03%] [G loss: 0.310790]\n",
      "epoch:17 step:16432 [D loss: 0.253280, acc.: 46.88%] [G loss: 0.315080]\n",
      "epoch:17 step:16433 [D loss: 0.227465, acc.: 65.62%] [G loss: 0.302355]\n",
      "epoch:17 step:16434 [D loss: 0.239505, acc.: 54.69%] [G loss: 0.293631]\n",
      "epoch:17 step:16435 [D loss: 0.254270, acc.: 53.12%] [G loss: 0.286782]\n",
      "epoch:17 step:16436 [D loss: 0.235669, acc.: 58.59%] [G loss: 0.310365]\n",
      "epoch:17 step:16437 [D loss: 0.265678, acc.: 50.00%] [G loss: 0.296254]\n",
      "epoch:17 step:16438 [D loss: 0.222337, acc.: 66.41%] [G loss: 0.313235]\n",
      "epoch:17 step:16439 [D loss: 0.231936, acc.: 64.84%] [G loss: 0.298354]\n",
      "epoch:17 step:16440 [D loss: 0.241132, acc.: 57.81%] [G loss: 0.290411]\n",
      "epoch:17 step:16441 [D loss: 0.228008, acc.: 62.50%] [G loss: 0.328950]\n",
      "epoch:17 step:16442 [D loss: 0.241798, acc.: 57.81%] [G loss: 0.277522]\n",
      "epoch:17 step:16443 [D loss: 0.239576, acc.: 59.38%] [G loss: 0.299446]\n",
      "epoch:17 step:16444 [D loss: 0.241908, acc.: 58.59%] [G loss: 0.318622]\n",
      "epoch:17 step:16445 [D loss: 0.240927, acc.: 57.81%] [G loss: 0.309879]\n",
      "epoch:17 step:16446 [D loss: 0.247536, acc.: 53.91%] [G loss: 0.298717]\n",
      "epoch:17 step:16447 [D loss: 0.254370, acc.: 53.91%] [G loss: 0.316262]\n",
      "epoch:17 step:16448 [D loss: 0.231461, acc.: 59.38%] [G loss: 0.282256]\n",
      "epoch:17 step:16449 [D loss: 0.240965, acc.: 60.16%] [G loss: 0.290395]\n",
      "epoch:17 step:16450 [D loss: 0.241577, acc.: 54.69%] [G loss: 0.315493]\n",
      "epoch:17 step:16451 [D loss: 0.250870, acc.: 50.00%] [G loss: 0.320822]\n",
      "epoch:17 step:16452 [D loss: 0.226163, acc.: 63.28%] [G loss: 0.284848]\n",
      "epoch:17 step:16453 [D loss: 0.231037, acc.: 57.81%] [G loss: 0.304224]\n",
      "epoch:17 step:16454 [D loss: 0.230741, acc.: 59.38%] [G loss: 0.326309]\n",
      "epoch:17 step:16455 [D loss: 0.233606, acc.: 62.50%] [G loss: 0.308140]\n",
      "epoch:17 step:16456 [D loss: 0.243935, acc.: 56.25%] [G loss: 0.303520]\n",
      "epoch:17 step:16457 [D loss: 0.258584, acc.: 53.12%] [G loss: 0.305513]\n",
      "epoch:17 step:16458 [D loss: 0.225305, acc.: 66.41%] [G loss: 0.320634]\n",
      "epoch:17 step:16459 [D loss: 0.249926, acc.: 60.16%] [G loss: 0.307499]\n",
      "epoch:17 step:16460 [D loss: 0.243598, acc.: 56.25%] [G loss: 0.317379]\n",
      "epoch:17 step:16461 [D loss: 0.234977, acc.: 60.94%] [G loss: 0.314182]\n",
      "epoch:17 step:16462 [D loss: 0.260548, acc.: 53.91%] [G loss: 0.308766]\n",
      "epoch:17 step:16463 [D loss: 0.249668, acc.: 56.25%] [G loss: 0.298806]\n",
      "epoch:17 step:16464 [D loss: 0.234507, acc.: 53.12%] [G loss: 0.318926]\n",
      "epoch:17 step:16465 [D loss: 0.258404, acc.: 47.66%] [G loss: 0.284449]\n",
      "epoch:17 step:16466 [D loss: 0.238526, acc.: 57.03%] [G loss: 0.290387]\n",
      "epoch:17 step:16467 [D loss: 0.244474, acc.: 59.38%] [G loss: 0.310190]\n",
      "epoch:17 step:16468 [D loss: 0.237970, acc.: 60.16%] [G loss: 0.298148]\n",
      "epoch:17 step:16469 [D loss: 0.226056, acc.: 64.06%] [G loss: 0.286581]\n",
      "epoch:17 step:16470 [D loss: 0.229698, acc.: 64.06%] [G loss: 0.321860]\n",
      "epoch:17 step:16471 [D loss: 0.229881, acc.: 57.81%] [G loss: 0.324377]\n",
      "epoch:17 step:16472 [D loss: 0.233251, acc.: 60.16%] [G loss: 0.294864]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:17 step:16473 [D loss: 0.249688, acc.: 50.00%] [G loss: 0.288056]\n",
      "epoch:17 step:16474 [D loss: 0.245583, acc.: 62.50%] [G loss: 0.283385]\n",
      "epoch:17 step:16475 [D loss: 0.232635, acc.: 63.28%] [G loss: 0.284826]\n",
      "epoch:17 step:16476 [D loss: 0.246906, acc.: 52.34%] [G loss: 0.290911]\n",
      "epoch:17 step:16477 [D loss: 0.243200, acc.: 54.69%] [G loss: 0.320006]\n",
      "epoch:17 step:16478 [D loss: 0.237042, acc.: 62.50%] [G loss: 0.310474]\n",
      "epoch:17 step:16479 [D loss: 0.236748, acc.: 57.81%] [G loss: 0.317740]\n",
      "epoch:17 step:16480 [D loss: 0.241413, acc.: 53.91%] [G loss: 0.329117]\n",
      "epoch:17 step:16481 [D loss: 0.240792, acc.: 64.06%] [G loss: 0.320787]\n",
      "epoch:17 step:16482 [D loss: 0.235917, acc.: 59.38%] [G loss: 0.284815]\n",
      "epoch:17 step:16483 [D loss: 0.239187, acc.: 57.03%] [G loss: 0.301304]\n",
      "epoch:17 step:16484 [D loss: 0.238842, acc.: 56.25%] [G loss: 0.320371]\n",
      "epoch:17 step:16485 [D loss: 0.236339, acc.: 55.47%] [G loss: 0.295103]\n",
      "epoch:17 step:16486 [D loss: 0.244038, acc.: 58.59%] [G loss: 0.304793]\n",
      "epoch:17 step:16487 [D loss: 0.230223, acc.: 60.94%] [G loss: 0.305618]\n",
      "epoch:17 step:16488 [D loss: 0.217567, acc.: 69.53%] [G loss: 0.322186]\n",
      "epoch:17 step:16489 [D loss: 0.244199, acc.: 62.50%] [G loss: 0.293525]\n",
      "epoch:17 step:16490 [D loss: 0.233906, acc.: 57.03%] [G loss: 0.297751]\n",
      "epoch:17 step:16491 [D loss: 0.239185, acc.: 60.94%] [G loss: 0.302961]\n",
      "epoch:17 step:16492 [D loss: 0.239767, acc.: 54.69%] [G loss: 0.294256]\n",
      "epoch:17 step:16493 [D loss: 0.245030, acc.: 59.38%] [G loss: 0.328017]\n",
      "epoch:17 step:16494 [D loss: 0.236577, acc.: 57.81%] [G loss: 0.328135]\n",
      "epoch:17 step:16495 [D loss: 0.234029, acc.: 57.81%] [G loss: 0.279895]\n",
      "epoch:17 step:16496 [D loss: 0.238621, acc.: 60.94%] [G loss: 0.275676]\n",
      "epoch:17 step:16497 [D loss: 0.244591, acc.: 58.59%] [G loss: 0.289579]\n",
      "epoch:17 step:16498 [D loss: 0.225973, acc.: 61.72%] [G loss: 0.299363]\n",
      "epoch:17 step:16499 [D loss: 0.228363, acc.: 59.38%] [G loss: 0.340139]\n",
      "epoch:17 step:16500 [D loss: 0.234844, acc.: 61.72%] [G loss: 0.269603]\n",
      "epoch:17 step:16501 [D loss: 0.242343, acc.: 59.38%] [G loss: 0.292795]\n",
      "epoch:17 step:16502 [D loss: 0.262341, acc.: 52.34%] [G loss: 0.308600]\n",
      "epoch:17 step:16503 [D loss: 0.245645, acc.: 53.91%] [G loss: 0.310522]\n",
      "epoch:17 step:16504 [D loss: 0.246047, acc.: 56.25%] [G loss: 0.294759]\n",
      "epoch:17 step:16505 [D loss: 0.241215, acc.: 60.94%] [G loss: 0.287191]\n",
      "epoch:17 step:16506 [D loss: 0.246320, acc.: 57.03%] [G loss: 0.285888]\n",
      "epoch:17 step:16507 [D loss: 0.229970, acc.: 57.81%] [G loss: 0.294479]\n",
      "epoch:17 step:16508 [D loss: 0.241924, acc.: 58.59%] [G loss: 0.303742]\n",
      "epoch:17 step:16509 [D loss: 0.245330, acc.: 52.34%] [G loss: 0.302086]\n",
      "epoch:17 step:16510 [D loss: 0.234668, acc.: 61.72%] [G loss: 0.318430]\n",
      "epoch:17 step:16511 [D loss: 0.236236, acc.: 57.81%] [G loss: 0.310455]\n",
      "epoch:17 step:16512 [D loss: 0.238006, acc.: 57.81%] [G loss: 0.294187]\n",
      "epoch:17 step:16513 [D loss: 0.236420, acc.: 59.38%] [G loss: 0.300293]\n",
      "epoch:17 step:16514 [D loss: 0.236598, acc.: 54.69%] [G loss: 0.308930]\n",
      "epoch:17 step:16515 [D loss: 0.236693, acc.: 55.47%] [G loss: 0.324028]\n",
      "epoch:17 step:16516 [D loss: 0.239940, acc.: 54.69%] [G loss: 0.267500]\n",
      "epoch:17 step:16517 [D loss: 0.228528, acc.: 60.94%] [G loss: 0.322050]\n",
      "epoch:17 step:16518 [D loss: 0.237346, acc.: 57.03%] [G loss: 0.317308]\n",
      "epoch:17 step:16519 [D loss: 0.230486, acc.: 57.81%] [G loss: 0.308487]\n",
      "epoch:17 step:16520 [D loss: 0.238774, acc.: 57.03%] [G loss: 0.324364]\n",
      "epoch:17 step:16521 [D loss: 0.236174, acc.: 57.81%] [G loss: 0.319445]\n",
      "epoch:17 step:16522 [D loss: 0.244364, acc.: 60.94%] [G loss: 0.303768]\n",
      "epoch:17 step:16523 [D loss: 0.217280, acc.: 66.41%] [G loss: 0.299435]\n",
      "epoch:17 step:16524 [D loss: 0.236128, acc.: 64.84%] [G loss: 0.306315]\n",
      "epoch:17 step:16525 [D loss: 0.232018, acc.: 56.25%] [G loss: 0.302846]\n",
      "epoch:17 step:16526 [D loss: 0.239341, acc.: 60.94%] [G loss: 0.312565]\n",
      "epoch:17 step:16527 [D loss: 0.241893, acc.: 57.03%] [G loss: 0.291362]\n",
      "epoch:17 step:16528 [D loss: 0.223697, acc.: 67.97%] [G loss: 0.328044]\n",
      "epoch:17 step:16529 [D loss: 0.243247, acc.: 56.25%] [G loss: 0.295697]\n",
      "epoch:17 step:16530 [D loss: 0.259226, acc.: 51.56%] [G loss: 0.303980]\n",
      "epoch:17 step:16531 [D loss: 0.233275, acc.: 61.72%] [G loss: 0.306100]\n",
      "epoch:17 step:16532 [D loss: 0.226735, acc.: 67.19%] [G loss: 0.318773]\n",
      "epoch:17 step:16533 [D loss: 0.238042, acc.: 59.38%] [G loss: 0.274399]\n",
      "epoch:17 step:16534 [D loss: 0.236358, acc.: 61.72%] [G loss: 0.290954]\n",
      "epoch:17 step:16535 [D loss: 0.250765, acc.: 51.56%] [G loss: 0.287175]\n",
      "epoch:17 step:16536 [D loss: 0.221570, acc.: 67.19%] [G loss: 0.296175]\n",
      "epoch:17 step:16537 [D loss: 0.227383, acc.: 64.06%] [G loss: 0.270052]\n",
      "epoch:17 step:16538 [D loss: 0.233914, acc.: 60.16%] [G loss: 0.303309]\n",
      "epoch:17 step:16539 [D loss: 0.227208, acc.: 68.75%] [G loss: 0.308738]\n",
      "epoch:17 step:16540 [D loss: 0.242046, acc.: 55.47%] [G loss: 0.287647]\n",
      "epoch:17 step:16541 [D loss: 0.241680, acc.: 53.12%] [G loss: 0.293489]\n",
      "epoch:17 step:16542 [D loss: 0.254093, acc.: 54.69%] [G loss: 0.280555]\n",
      "epoch:17 step:16543 [D loss: 0.241236, acc.: 57.03%] [G loss: 0.312972]\n",
      "epoch:17 step:16544 [D loss: 0.228217, acc.: 64.06%] [G loss: 0.311665]\n",
      "epoch:17 step:16545 [D loss: 0.242106, acc.: 57.81%] [G loss: 0.279654]\n",
      "epoch:17 step:16546 [D loss: 0.229058, acc.: 60.16%] [G loss: 0.316016]\n",
      "epoch:17 step:16547 [D loss: 0.242084, acc.: 58.59%] [G loss: 0.301811]\n",
      "epoch:17 step:16548 [D loss: 0.247880, acc.: 53.91%] [G loss: 0.309102]\n",
      "epoch:17 step:16549 [D loss: 0.248887, acc.: 50.78%] [G loss: 0.314774]\n",
      "epoch:17 step:16550 [D loss: 0.242093, acc.: 58.59%] [G loss: 0.275121]\n",
      "epoch:17 step:16551 [D loss: 0.252398, acc.: 53.91%] [G loss: 0.294467]\n",
      "epoch:17 step:16552 [D loss: 0.247036, acc.: 54.69%] [G loss: 0.328645]\n",
      "epoch:17 step:16553 [D loss: 0.251576, acc.: 52.34%] [G loss: 0.295339]\n",
      "epoch:17 step:16554 [D loss: 0.215930, acc.: 67.97%] [G loss: 0.281096]\n",
      "epoch:17 step:16555 [D loss: 0.241674, acc.: 53.12%] [G loss: 0.294434]\n",
      "epoch:17 step:16556 [D loss: 0.236843, acc.: 60.16%] [G loss: 0.304792]\n",
      "epoch:17 step:16557 [D loss: 0.253832, acc.: 50.78%] [G loss: 0.303345]\n",
      "epoch:17 step:16558 [D loss: 0.237807, acc.: 53.12%] [G loss: 0.305331]\n",
      "epoch:17 step:16559 [D loss: 0.236544, acc.: 54.69%] [G loss: 0.330798]\n",
      "epoch:17 step:16560 [D loss: 0.233275, acc.: 62.50%] [G loss: 0.307864]\n",
      "epoch:17 step:16561 [D loss: 0.251408, acc.: 52.34%] [G loss: 0.303194]\n",
      "epoch:17 step:16562 [D loss: 0.233166, acc.: 61.72%] [G loss: 0.298917]\n",
      "epoch:17 step:16563 [D loss: 0.227379, acc.: 65.62%] [G loss: 0.316893]\n",
      "epoch:17 step:16564 [D loss: 0.239878, acc.: 57.03%] [G loss: 0.319235]\n",
      "epoch:17 step:16565 [D loss: 0.231168, acc.: 60.16%] [G loss: 0.297454]\n",
      "epoch:17 step:16566 [D loss: 0.238507, acc.: 58.59%] [G loss: 0.294061]\n",
      "epoch:17 step:16567 [D loss: 0.227719, acc.: 67.19%] [G loss: 0.311711]\n",
      "epoch:17 step:16568 [D loss: 0.233039, acc.: 58.59%] [G loss: 0.287871]\n",
      "epoch:17 step:16569 [D loss: 0.234267, acc.: 61.72%] [G loss: 0.275953]\n",
      "epoch:17 step:16570 [D loss: 0.228682, acc.: 57.81%] [G loss: 0.270829]\n",
      "epoch:17 step:16571 [D loss: 0.235424, acc.: 59.38%] [G loss: 0.328774]\n",
      "epoch:17 step:16572 [D loss: 0.233103, acc.: 60.16%] [G loss: 0.286286]\n",
      "epoch:17 step:16573 [D loss: 0.216855, acc.: 61.72%] [G loss: 0.308089]\n",
      "epoch:17 step:16574 [D loss: 0.235643, acc.: 65.62%] [G loss: 0.307005]\n",
      "epoch:17 step:16575 [D loss: 0.239587, acc.: 57.03%] [G loss: 0.307940]\n",
      "epoch:17 step:16576 [D loss: 0.237089, acc.: 55.47%] [G loss: 0.273328]\n",
      "epoch:17 step:16577 [D loss: 0.217509, acc.: 68.75%] [G loss: 0.304035]\n",
      "epoch:17 step:16578 [D loss: 0.227390, acc.: 63.28%] [G loss: 0.321218]\n",
      "epoch:17 step:16579 [D loss: 0.253805, acc.: 54.69%] [G loss: 0.305585]\n",
      "epoch:17 step:16580 [D loss: 0.238855, acc.: 63.28%] [G loss: 0.296260]\n",
      "epoch:17 step:16581 [D loss: 0.233129, acc.: 59.38%] [G loss: 0.286359]\n",
      "epoch:17 step:16582 [D loss: 0.253417, acc.: 55.47%] [G loss: 0.268498]\n",
      "epoch:17 step:16583 [D loss: 0.217831, acc.: 64.06%] [G loss: 0.315982]\n",
      "epoch:17 step:16584 [D loss: 0.254828, acc.: 49.22%] [G loss: 0.271569]\n",
      "epoch:17 step:16585 [D loss: 0.244688, acc.: 57.03%] [G loss: 0.295874]\n",
      "epoch:17 step:16586 [D loss: 0.241062, acc.: 56.25%] [G loss: 0.317732]\n",
      "epoch:17 step:16587 [D loss: 0.246257, acc.: 54.69%] [G loss: 0.305773]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:17 step:16588 [D loss: 0.240636, acc.: 57.03%] [G loss: 0.299938]\n",
      "epoch:17 step:16589 [D loss: 0.256663, acc.: 51.56%] [G loss: 0.311114]\n",
      "epoch:17 step:16590 [D loss: 0.245644, acc.: 55.47%] [G loss: 0.294017]\n",
      "epoch:17 step:16591 [D loss: 0.259110, acc.: 50.00%] [G loss: 0.300703]\n",
      "epoch:17 step:16592 [D loss: 0.232040, acc.: 62.50%] [G loss: 0.294112]\n",
      "epoch:17 step:16593 [D loss: 0.228319, acc.: 62.50%] [G loss: 0.298370]\n",
      "epoch:17 step:16594 [D loss: 0.241656, acc.: 61.72%] [G loss: 0.305572]\n",
      "epoch:17 step:16595 [D loss: 0.249548, acc.: 53.91%] [G loss: 0.284388]\n",
      "epoch:17 step:16596 [D loss: 0.260408, acc.: 50.00%] [G loss: 0.312131]\n",
      "epoch:17 step:16597 [D loss: 0.256212, acc.: 50.78%] [G loss: 0.304111]\n",
      "epoch:17 step:16598 [D loss: 0.208374, acc.: 72.66%] [G loss: 0.315979]\n",
      "epoch:17 step:16599 [D loss: 0.233642, acc.: 59.38%] [G loss: 0.308734]\n",
      "epoch:17 step:16600 [D loss: 0.239865, acc.: 55.47%] [G loss: 0.305801]\n",
      "epoch:17 step:16601 [D loss: 0.224419, acc.: 60.16%] [G loss: 0.311169]\n",
      "epoch:17 step:16602 [D loss: 0.234050, acc.: 61.72%] [G loss: 0.304967]\n",
      "epoch:17 step:16603 [D loss: 0.225370, acc.: 65.62%] [G loss: 0.315500]\n",
      "epoch:17 step:16604 [D loss: 0.240522, acc.: 60.16%] [G loss: 0.306260]\n",
      "epoch:17 step:16605 [D loss: 0.255137, acc.: 50.00%] [G loss: 0.300325]\n",
      "epoch:17 step:16606 [D loss: 0.249670, acc.: 60.16%] [G loss: 0.301359]\n",
      "epoch:17 step:16607 [D loss: 0.241896, acc.: 60.94%] [G loss: 0.291913]\n",
      "epoch:17 step:16608 [D loss: 0.258839, acc.: 50.00%] [G loss: 0.268516]\n",
      "epoch:17 step:16609 [D loss: 0.241256, acc.: 62.50%] [G loss: 0.306096]\n",
      "epoch:17 step:16610 [D loss: 0.226878, acc.: 62.50%] [G loss: 0.306534]\n",
      "epoch:17 step:16611 [D loss: 0.233575, acc.: 59.38%] [G loss: 0.301741]\n",
      "epoch:17 step:16612 [D loss: 0.241612, acc.: 57.81%] [G loss: 0.301911]\n",
      "epoch:17 step:16613 [D loss: 0.242789, acc.: 51.56%] [G loss: 0.295655]\n",
      "epoch:17 step:16614 [D loss: 0.253833, acc.: 54.69%] [G loss: 0.294653]\n",
      "epoch:17 step:16615 [D loss: 0.226095, acc.: 60.94%] [G loss: 0.283188]\n",
      "epoch:17 step:16616 [D loss: 0.236764, acc.: 53.91%] [G loss: 0.321131]\n",
      "epoch:17 step:16617 [D loss: 0.244710, acc.: 54.69%] [G loss: 0.283114]\n",
      "epoch:17 step:16618 [D loss: 0.255542, acc.: 49.22%] [G loss: 0.305538]\n",
      "epoch:17 step:16619 [D loss: 0.229236, acc.: 62.50%] [G loss: 0.303609]\n",
      "epoch:17 step:16620 [D loss: 0.230610, acc.: 59.38%] [G loss: 0.298847]\n",
      "epoch:17 step:16621 [D loss: 0.233007, acc.: 53.91%] [G loss: 0.298135]\n",
      "epoch:17 step:16622 [D loss: 0.247027, acc.: 59.38%] [G loss: 0.309152]\n",
      "epoch:17 step:16623 [D loss: 0.234477, acc.: 59.38%] [G loss: 0.303464]\n",
      "epoch:17 step:16624 [D loss: 0.246318, acc.: 53.91%] [G loss: 0.291111]\n",
      "epoch:17 step:16625 [D loss: 0.230092, acc.: 62.50%] [G loss: 0.308017]\n",
      "epoch:17 step:16626 [D loss: 0.234989, acc.: 57.81%] [G loss: 0.304508]\n",
      "epoch:17 step:16627 [D loss: 0.236588, acc.: 59.38%] [G loss: 0.287741]\n",
      "epoch:17 step:16628 [D loss: 0.229041, acc.: 64.06%] [G loss: 0.298365]\n",
      "epoch:17 step:16629 [D loss: 0.253211, acc.: 53.12%] [G loss: 0.270833]\n",
      "epoch:17 step:16630 [D loss: 0.226949, acc.: 63.28%] [G loss: 0.314754]\n",
      "epoch:17 step:16631 [D loss: 0.238137, acc.: 54.69%] [G loss: 0.292716]\n",
      "epoch:17 step:16632 [D loss: 0.239691, acc.: 57.81%] [G loss: 0.333552]\n",
      "epoch:17 step:16633 [D loss: 0.236304, acc.: 53.12%] [G loss: 0.312540]\n",
      "epoch:17 step:16634 [D loss: 0.240143, acc.: 61.72%] [G loss: 0.293218]\n",
      "epoch:17 step:16635 [D loss: 0.250751, acc.: 59.38%] [G loss: 0.279898]\n",
      "epoch:17 step:16636 [D loss: 0.242938, acc.: 55.47%] [G loss: 0.271292]\n",
      "epoch:17 step:16637 [D loss: 0.244627, acc.: 55.47%] [G loss: 0.300675]\n",
      "epoch:17 step:16638 [D loss: 0.249039, acc.: 49.22%] [G loss: 0.320613]\n",
      "epoch:17 step:16639 [D loss: 0.221894, acc.: 65.62%] [G loss: 0.302256]\n",
      "epoch:17 step:16640 [D loss: 0.254398, acc.: 51.56%] [G loss: 0.262058]\n",
      "epoch:17 step:16641 [D loss: 0.232282, acc.: 57.81%] [G loss: 0.304166]\n",
      "epoch:17 step:16642 [D loss: 0.241407, acc.: 57.81%] [G loss: 0.300594]\n",
      "epoch:17 step:16643 [D loss: 0.236672, acc.: 60.16%] [G loss: 0.311064]\n",
      "epoch:17 step:16644 [D loss: 0.235034, acc.: 62.50%] [G loss: 0.315503]\n",
      "epoch:17 step:16645 [D loss: 0.220012, acc.: 64.06%] [G loss: 0.294898]\n",
      "epoch:17 step:16646 [D loss: 0.247277, acc.: 57.03%] [G loss: 0.282462]\n",
      "epoch:17 step:16647 [D loss: 0.236262, acc.: 60.16%] [G loss: 0.306510]\n",
      "epoch:17 step:16648 [D loss: 0.232444, acc.: 60.94%] [G loss: 0.297894]\n",
      "epoch:17 step:16649 [D loss: 0.253825, acc.: 52.34%] [G loss: 0.306566]\n",
      "epoch:17 step:16650 [D loss: 0.237304, acc.: 57.03%] [G loss: 0.285770]\n",
      "epoch:17 step:16651 [D loss: 0.243917, acc.: 64.84%] [G loss: 0.320808]\n",
      "epoch:17 step:16652 [D loss: 0.242175, acc.: 61.72%] [G loss: 0.314657]\n",
      "epoch:17 step:16653 [D loss: 0.227243, acc.: 63.28%] [G loss: 0.304670]\n",
      "epoch:17 step:16654 [D loss: 0.238275, acc.: 57.03%] [G loss: 0.297354]\n",
      "epoch:17 step:16655 [D loss: 0.251071, acc.: 50.78%] [G loss: 0.328338]\n",
      "epoch:17 step:16656 [D loss: 0.239729, acc.: 55.47%] [G loss: 0.317932]\n",
      "epoch:17 step:16657 [D loss: 0.238574, acc.: 58.59%] [G loss: 0.321659]\n",
      "epoch:17 step:16658 [D loss: 0.220939, acc.: 64.84%] [G loss: 0.311413]\n",
      "epoch:17 step:16659 [D loss: 0.257956, acc.: 50.00%] [G loss: 0.282669]\n",
      "epoch:17 step:16660 [D loss: 0.250512, acc.: 56.25%] [G loss: 0.294476]\n",
      "epoch:17 step:16661 [D loss: 0.242445, acc.: 56.25%] [G loss: 0.302548]\n",
      "epoch:17 step:16662 [D loss: 0.237114, acc.: 57.81%] [G loss: 0.313913]\n",
      "epoch:17 step:16663 [D loss: 0.224904, acc.: 68.75%] [G loss: 0.306689]\n",
      "epoch:17 step:16664 [D loss: 0.249034, acc.: 55.47%] [G loss: 0.296865]\n",
      "epoch:17 step:16665 [D loss: 0.246984, acc.: 54.69%] [G loss: 0.312629]\n",
      "epoch:17 step:16666 [D loss: 0.234592, acc.: 54.69%] [G loss: 0.307882]\n",
      "epoch:17 step:16667 [D loss: 0.262125, acc.: 46.09%] [G loss: 0.325508]\n",
      "epoch:17 step:16668 [D loss: 0.233629, acc.: 60.16%] [G loss: 0.287216]\n",
      "epoch:17 step:16669 [D loss: 0.239214, acc.: 60.94%] [G loss: 0.323417]\n",
      "epoch:17 step:16670 [D loss: 0.240797, acc.: 64.06%] [G loss: 0.324173]\n",
      "epoch:17 step:16671 [D loss: 0.231538, acc.: 64.06%] [G loss: 0.304216]\n",
      "epoch:17 step:16672 [D loss: 0.243218, acc.: 58.59%] [G loss: 0.290148]\n",
      "epoch:17 step:16673 [D loss: 0.238582, acc.: 53.91%] [G loss: 0.311046]\n",
      "epoch:17 step:16674 [D loss: 0.235398, acc.: 56.25%] [G loss: 0.288378]\n",
      "epoch:17 step:16675 [D loss: 0.235786, acc.: 60.16%] [G loss: 0.318846]\n",
      "epoch:17 step:16676 [D loss: 0.230816, acc.: 60.94%] [G loss: 0.286072]\n",
      "epoch:17 step:16677 [D loss: 0.226811, acc.: 61.72%] [G loss: 0.289614]\n",
      "epoch:17 step:16678 [D loss: 0.241644, acc.: 54.69%] [G loss: 0.291887]\n",
      "epoch:17 step:16679 [D loss: 0.217151, acc.: 63.28%] [G loss: 0.336981]\n",
      "epoch:17 step:16680 [D loss: 0.220975, acc.: 64.84%] [G loss: 0.331346]\n",
      "epoch:17 step:16681 [D loss: 0.236606, acc.: 59.38%] [G loss: 0.321832]\n",
      "epoch:17 step:16682 [D loss: 0.228643, acc.: 60.94%] [G loss: 0.311727]\n",
      "epoch:17 step:16683 [D loss: 0.246045, acc.: 57.81%] [G loss: 0.302730]\n",
      "epoch:17 step:16684 [D loss: 0.241042, acc.: 57.03%] [G loss: 0.332571]\n",
      "epoch:17 step:16685 [D loss: 0.257931, acc.: 52.34%] [G loss: 0.283593]\n",
      "epoch:17 step:16686 [D loss: 0.235122, acc.: 59.38%] [G loss: 0.284463]\n",
      "epoch:17 step:16687 [D loss: 0.249983, acc.: 55.47%] [G loss: 0.294023]\n",
      "epoch:17 step:16688 [D loss: 0.228926, acc.: 54.69%] [G loss: 0.307054]\n",
      "epoch:17 step:16689 [D loss: 0.241592, acc.: 61.72%] [G loss: 0.291571]\n",
      "epoch:17 step:16690 [D loss: 0.221652, acc.: 64.06%] [G loss: 0.283938]\n",
      "epoch:17 step:16691 [D loss: 0.235901, acc.: 60.94%] [G loss: 0.332022]\n",
      "epoch:17 step:16692 [D loss: 0.224947, acc.: 65.62%] [G loss: 0.304764]\n",
      "epoch:17 step:16693 [D loss: 0.247148, acc.: 55.47%] [G loss: 0.295002]\n",
      "epoch:17 step:16694 [D loss: 0.231118, acc.: 61.72%] [G loss: 0.307962]\n",
      "epoch:17 step:16695 [D loss: 0.231210, acc.: 64.84%] [G loss: 0.279869]\n",
      "epoch:17 step:16696 [D loss: 0.246138, acc.: 57.81%] [G loss: 0.326768]\n",
      "epoch:17 step:16697 [D loss: 0.234284, acc.: 58.59%] [G loss: 0.312013]\n",
      "epoch:17 step:16698 [D loss: 0.246730, acc.: 54.69%] [G loss: 0.304917]\n",
      "epoch:17 step:16699 [D loss: 0.236653, acc.: 59.38%] [G loss: 0.314958]\n",
      "epoch:17 step:16700 [D loss: 0.237441, acc.: 56.25%] [G loss: 0.305376]\n",
      "epoch:17 step:16701 [D loss: 0.261069, acc.: 48.44%] [G loss: 0.285498]\n",
      "epoch:17 step:16702 [D loss: 0.248385, acc.: 56.25%] [G loss: 0.293962]\n",
      "epoch:17 step:16703 [D loss: 0.242172, acc.: 59.38%] [G loss: 0.292883]\n",
      "epoch:17 step:16704 [D loss: 0.230662, acc.: 63.28%] [G loss: 0.314439]\n",
      "epoch:17 step:16705 [D loss: 0.242135, acc.: 59.38%] [G loss: 0.296513]\n",
      "epoch:17 step:16706 [D loss: 0.233563, acc.: 59.38%] [G loss: 0.319305]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:17 step:16707 [D loss: 0.240625, acc.: 58.59%] [G loss: 0.298673]\n",
      "epoch:17 step:16708 [D loss: 0.215284, acc.: 71.09%] [G loss: 0.299475]\n",
      "epoch:17 step:16709 [D loss: 0.238401, acc.: 60.94%] [G loss: 0.310266]\n",
      "epoch:17 step:16710 [D loss: 0.234917, acc.: 60.94%] [G loss: 0.321445]\n",
      "epoch:17 step:16711 [D loss: 0.229702, acc.: 59.38%] [G loss: 0.312636]\n",
      "epoch:17 step:16712 [D loss: 0.238668, acc.: 60.16%] [G loss: 0.306918]\n",
      "epoch:17 step:16713 [D loss: 0.247436, acc.: 57.03%] [G loss: 0.308421]\n",
      "epoch:17 step:16714 [D loss: 0.241541, acc.: 55.47%] [G loss: 0.283128]\n",
      "epoch:17 step:16715 [D loss: 0.229694, acc.: 60.94%] [G loss: 0.287492]\n",
      "epoch:17 step:16716 [D loss: 0.227332, acc.: 63.28%] [G loss: 0.292174]\n",
      "epoch:17 step:16717 [D loss: 0.246756, acc.: 57.03%] [G loss: 0.318160]\n",
      "epoch:17 step:16718 [D loss: 0.239752, acc.: 60.94%] [G loss: 0.290354]\n",
      "epoch:17 step:16719 [D loss: 0.236470, acc.: 57.03%] [G loss: 0.302179]\n",
      "epoch:17 step:16720 [D loss: 0.257014, acc.: 53.12%] [G loss: 0.281754]\n",
      "epoch:17 step:16721 [D loss: 0.246731, acc.: 53.91%] [G loss: 0.306985]\n",
      "epoch:17 step:16722 [D loss: 0.244686, acc.: 60.16%] [G loss: 0.277780]\n",
      "epoch:17 step:16723 [D loss: 0.240453, acc.: 56.25%] [G loss: 0.283641]\n",
      "epoch:17 step:16724 [D loss: 0.236718, acc.: 60.94%] [G loss: 0.289097]\n",
      "epoch:17 step:16725 [D loss: 0.239298, acc.: 57.03%] [G loss: 0.306148]\n",
      "epoch:17 step:16726 [D loss: 0.258395, acc.: 50.78%] [G loss: 0.300916]\n",
      "epoch:17 step:16727 [D loss: 0.241565, acc.: 57.81%] [G loss: 0.310086]\n",
      "epoch:17 step:16728 [D loss: 0.239131, acc.: 52.34%] [G loss: 0.321161]\n",
      "epoch:17 step:16729 [D loss: 0.230245, acc.: 62.50%] [G loss: 0.304880]\n",
      "epoch:17 step:16730 [D loss: 0.236752, acc.: 54.69%] [G loss: 0.295844]\n",
      "epoch:17 step:16731 [D loss: 0.256598, acc.: 55.47%] [G loss: 0.291246]\n",
      "epoch:17 step:16732 [D loss: 0.230218, acc.: 57.03%] [G loss: 0.309874]\n",
      "epoch:17 step:16733 [D loss: 0.234844, acc.: 62.50%] [G loss: 0.308687]\n",
      "epoch:17 step:16734 [D loss: 0.232265, acc.: 59.38%] [G loss: 0.287996]\n",
      "epoch:17 step:16735 [D loss: 0.249387, acc.: 57.81%] [G loss: 0.303681]\n",
      "epoch:17 step:16736 [D loss: 0.245564, acc.: 53.91%] [G loss: 0.309964]\n",
      "epoch:17 step:16737 [D loss: 0.241797, acc.: 54.69%] [G loss: 0.327008]\n",
      "epoch:17 step:16738 [D loss: 0.231743, acc.: 60.16%] [G loss: 0.329970]\n",
      "epoch:17 step:16739 [D loss: 0.253047, acc.: 54.69%] [G loss: 0.274768]\n",
      "epoch:17 step:16740 [D loss: 0.241105, acc.: 53.12%] [G loss: 0.310283]\n",
      "epoch:17 step:16741 [D loss: 0.237427, acc.: 55.47%] [G loss: 0.295507]\n",
      "epoch:17 step:16742 [D loss: 0.236328, acc.: 60.16%] [G loss: 0.279589]\n",
      "epoch:17 step:16743 [D loss: 0.240301, acc.: 60.94%] [G loss: 0.319087]\n",
      "epoch:17 step:16744 [D loss: 0.246976, acc.: 52.34%] [G loss: 0.276428]\n",
      "epoch:17 step:16745 [D loss: 0.210533, acc.: 71.09%] [G loss: 0.329800]\n",
      "epoch:17 step:16746 [D loss: 0.251381, acc.: 48.44%] [G loss: 0.309397]\n",
      "epoch:17 step:16747 [D loss: 0.240360, acc.: 51.56%] [G loss: 0.300126]\n",
      "epoch:17 step:16748 [D loss: 0.223088, acc.: 63.28%] [G loss: 0.296524]\n",
      "epoch:17 step:16749 [D loss: 0.251760, acc.: 51.56%] [G loss: 0.306670]\n",
      "epoch:17 step:16750 [D loss: 0.239553, acc.: 51.56%] [G loss: 0.306748]\n",
      "epoch:17 step:16751 [D loss: 0.224901, acc.: 65.62%] [G loss: 0.322002]\n",
      "epoch:17 step:16752 [D loss: 0.244639, acc.: 59.38%] [G loss: 0.302907]\n",
      "epoch:17 step:16753 [D loss: 0.234882, acc.: 56.25%] [G loss: 0.298275]\n",
      "epoch:17 step:16754 [D loss: 0.252536, acc.: 53.12%] [G loss: 0.281193]\n",
      "epoch:17 step:16755 [D loss: 0.250731, acc.: 57.03%] [G loss: 0.287360]\n",
      "epoch:17 step:16756 [D loss: 0.226067, acc.: 55.47%] [G loss: 0.304002]\n",
      "epoch:17 step:16757 [D loss: 0.250273, acc.: 56.25%] [G loss: 0.294379]\n",
      "epoch:17 step:16758 [D loss: 0.215920, acc.: 69.53%] [G loss: 0.326066]\n",
      "epoch:17 step:16759 [D loss: 0.228240, acc.: 67.97%] [G loss: 0.307444]\n",
      "epoch:17 step:16760 [D loss: 0.256016, acc.: 51.56%] [G loss: 0.290641]\n",
      "epoch:17 step:16761 [D loss: 0.247795, acc.: 52.34%] [G loss: 0.293094]\n",
      "epoch:17 step:16762 [D loss: 0.224249, acc.: 68.75%] [G loss: 0.292490]\n",
      "epoch:17 step:16763 [D loss: 0.256646, acc.: 51.56%] [G loss: 0.309287]\n",
      "epoch:17 step:16764 [D loss: 0.242394, acc.: 56.25%] [G loss: 0.321532]\n",
      "epoch:17 step:16765 [D loss: 0.225721, acc.: 65.62%] [G loss: 0.306137]\n",
      "epoch:17 step:16766 [D loss: 0.237512, acc.: 58.59%] [G loss: 0.297090]\n",
      "epoch:17 step:16767 [D loss: 0.243252, acc.: 60.94%] [G loss: 0.288510]\n",
      "epoch:17 step:16768 [D loss: 0.237643, acc.: 61.72%] [G loss: 0.283811]\n",
      "epoch:17 step:16769 [D loss: 0.242788, acc.: 54.69%] [G loss: 0.303797]\n",
      "epoch:17 step:16770 [D loss: 0.229930, acc.: 62.50%] [G loss: 0.299182]\n",
      "epoch:17 step:16771 [D loss: 0.237616, acc.: 57.03%] [G loss: 0.276720]\n",
      "epoch:17 step:16772 [D loss: 0.238616, acc.: 59.38%] [G loss: 0.306616]\n",
      "epoch:17 step:16773 [D loss: 0.253371, acc.: 52.34%] [G loss: 0.322954]\n",
      "epoch:17 step:16774 [D loss: 0.250162, acc.: 50.78%] [G loss: 0.301573]\n",
      "epoch:17 step:16775 [D loss: 0.243500, acc.: 56.25%] [G loss: 0.280203]\n",
      "epoch:17 step:16776 [D loss: 0.224668, acc.: 64.06%] [G loss: 0.303101]\n",
      "epoch:17 step:16777 [D loss: 0.232719, acc.: 60.16%] [G loss: 0.297129]\n",
      "epoch:17 step:16778 [D loss: 0.237980, acc.: 57.81%] [G loss: 0.306714]\n",
      "epoch:17 step:16779 [D loss: 0.233839, acc.: 60.16%] [G loss: 0.301981]\n",
      "epoch:17 step:16780 [D loss: 0.244155, acc.: 56.25%] [G loss: 0.293894]\n",
      "epoch:17 step:16781 [D loss: 0.228389, acc.: 63.28%] [G loss: 0.293388]\n",
      "epoch:17 step:16782 [D loss: 0.225228, acc.: 64.84%] [G loss: 0.287182]\n",
      "epoch:17 step:16783 [D loss: 0.237196, acc.: 59.38%] [G loss: 0.299751]\n",
      "epoch:17 step:16784 [D loss: 0.237576, acc.: 57.03%] [G loss: 0.290147]\n",
      "epoch:17 step:16785 [D loss: 0.248008, acc.: 51.56%] [G loss: 0.315159]\n",
      "epoch:17 step:16786 [D loss: 0.246757, acc.: 54.69%] [G loss: 0.268379]\n",
      "epoch:17 step:16787 [D loss: 0.234524, acc.: 54.69%] [G loss: 0.303201]\n",
      "epoch:17 step:16788 [D loss: 0.238147, acc.: 54.69%] [G loss: 0.339133]\n",
      "epoch:17 step:16789 [D loss: 0.238548, acc.: 61.72%] [G loss: 0.307775]\n",
      "epoch:17 step:16790 [D loss: 0.228015, acc.: 65.62%] [G loss: 0.314192]\n",
      "epoch:17 step:16791 [D loss: 0.238020, acc.: 55.47%] [G loss: 0.284414]\n",
      "epoch:17 step:16792 [D loss: 0.231811, acc.: 63.28%] [G loss: 0.327637]\n",
      "epoch:17 step:16793 [D loss: 0.241684, acc.: 53.12%] [G loss: 0.282303]\n",
      "epoch:17 step:16794 [D loss: 0.232419, acc.: 63.28%] [G loss: 0.293802]\n",
      "epoch:17 step:16795 [D loss: 0.247649, acc.: 57.81%] [G loss: 0.332601]\n",
      "epoch:17 step:16796 [D loss: 0.241378, acc.: 57.03%] [G loss: 0.299265]\n",
      "epoch:17 step:16797 [D loss: 0.224483, acc.: 61.72%] [G loss: 0.306183]\n",
      "epoch:17 step:16798 [D loss: 0.231292, acc.: 60.94%] [G loss: 0.286716]\n",
      "epoch:17 step:16799 [D loss: 0.241696, acc.: 57.03%] [G loss: 0.315732]\n",
      "epoch:17 step:16800 [D loss: 0.241018, acc.: 60.94%] [G loss: 0.319760]\n",
      "epoch:17 step:16801 [D loss: 0.224893, acc.: 59.38%] [G loss: 0.313968]\n",
      "epoch:17 step:16802 [D loss: 0.260419, acc.: 55.47%] [G loss: 0.304287]\n",
      "epoch:17 step:16803 [D loss: 0.238205, acc.: 54.69%] [G loss: 0.313481]\n",
      "epoch:17 step:16804 [D loss: 0.215468, acc.: 69.53%] [G loss: 0.291463]\n",
      "epoch:17 step:16805 [D loss: 0.242993, acc.: 57.03%] [G loss: 0.332292]\n",
      "epoch:17 step:16806 [D loss: 0.224233, acc.: 61.72%] [G loss: 0.314720]\n",
      "epoch:17 step:16807 [D loss: 0.247940, acc.: 53.12%] [G loss: 0.285929]\n",
      "epoch:17 step:16808 [D loss: 0.248123, acc.: 55.47%] [G loss: 0.286046]\n",
      "epoch:17 step:16809 [D loss: 0.229991, acc.: 61.72%] [G loss: 0.312282]\n",
      "epoch:17 step:16810 [D loss: 0.245407, acc.: 53.12%] [G loss: 0.307342]\n",
      "epoch:17 step:16811 [D loss: 0.233121, acc.: 57.81%] [G loss: 0.269769]\n",
      "epoch:17 step:16812 [D loss: 0.244834, acc.: 56.25%] [G loss: 0.315536]\n",
      "epoch:17 step:16813 [D loss: 0.240351, acc.: 58.59%] [G loss: 0.318828]\n",
      "epoch:17 step:16814 [D loss: 0.246176, acc.: 56.25%] [G loss: 0.315450]\n",
      "epoch:17 step:16815 [D loss: 0.243268, acc.: 52.34%] [G loss: 0.307471]\n",
      "epoch:17 step:16816 [D loss: 0.240766, acc.: 56.25%] [G loss: 0.272381]\n",
      "epoch:17 step:16817 [D loss: 0.234750, acc.: 53.91%] [G loss: 0.292717]\n",
      "epoch:17 step:16818 [D loss: 0.226815, acc.: 58.59%] [G loss: 0.292212]\n",
      "epoch:17 step:16819 [D loss: 0.229804, acc.: 62.50%] [G loss: 0.296580]\n",
      "epoch:17 step:16820 [D loss: 0.252973, acc.: 51.56%] [G loss: 0.300030]\n",
      "epoch:17 step:16821 [D loss: 0.238960, acc.: 56.25%] [G loss: 0.322453]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:17 step:16822 [D loss: 0.258903, acc.: 45.31%] [G loss: 0.293732]\n",
      "epoch:17 step:16823 [D loss: 0.249873, acc.: 53.91%] [G loss: 0.302910]\n",
      "epoch:17 step:16824 [D loss: 0.245559, acc.: 55.47%] [G loss: 0.323406]\n",
      "epoch:17 step:16825 [D loss: 0.232662, acc.: 64.06%] [G loss: 0.298617]\n",
      "epoch:17 step:16826 [D loss: 0.239172, acc.: 56.25%] [G loss: 0.308269]\n",
      "epoch:17 step:16827 [D loss: 0.240779, acc.: 60.16%] [G loss: 0.302134]\n",
      "epoch:17 step:16828 [D loss: 0.234128, acc.: 60.16%] [G loss: 0.333785]\n",
      "epoch:17 step:16829 [D loss: 0.210633, acc.: 69.53%] [G loss: 0.318521]\n",
      "epoch:17 step:16830 [D loss: 0.261086, acc.: 51.56%] [G loss: 0.323937]\n",
      "epoch:17 step:16831 [D loss: 0.241770, acc.: 58.59%] [G loss: 0.287412]\n",
      "epoch:17 step:16832 [D loss: 0.239441, acc.: 59.38%] [G loss: 0.303118]\n",
      "epoch:17 step:16833 [D loss: 0.238499, acc.: 60.94%] [G loss: 0.281539]\n",
      "epoch:17 step:16834 [D loss: 0.232816, acc.: 65.62%] [G loss: 0.327048]\n",
      "epoch:17 step:16835 [D loss: 0.250506, acc.: 53.91%] [G loss: 0.299935]\n",
      "epoch:17 step:16836 [D loss: 0.225168, acc.: 62.50%] [G loss: 0.299990]\n",
      "epoch:17 step:16837 [D loss: 0.235307, acc.: 54.69%] [G loss: 0.321790]\n",
      "epoch:17 step:16838 [D loss: 0.245680, acc.: 59.38%] [G loss: 0.284631]\n",
      "epoch:17 step:16839 [D loss: 0.236396, acc.: 53.91%] [G loss: 0.291599]\n",
      "epoch:17 step:16840 [D loss: 0.228367, acc.: 61.72%] [G loss: 0.314328]\n",
      "epoch:17 step:16841 [D loss: 0.241553, acc.: 60.16%] [G loss: 0.303146]\n",
      "epoch:17 step:16842 [D loss: 0.241266, acc.: 57.81%] [G loss: 0.299599]\n",
      "epoch:17 step:16843 [D loss: 0.236813, acc.: 59.38%] [G loss: 0.309009]\n",
      "epoch:17 step:16844 [D loss: 0.228711, acc.: 64.06%] [G loss: 0.308542]\n",
      "epoch:17 step:16845 [D loss: 0.234686, acc.: 61.72%] [G loss: 0.298534]\n",
      "epoch:17 step:16846 [D loss: 0.220532, acc.: 70.31%] [G loss: 0.298327]\n",
      "epoch:17 step:16847 [D loss: 0.231667, acc.: 59.38%] [G loss: 0.298336]\n",
      "epoch:17 step:16848 [D loss: 0.249108, acc.: 51.56%] [G loss: 0.281865]\n",
      "epoch:17 step:16849 [D loss: 0.239059, acc.: 59.38%] [G loss: 0.295563]\n",
      "epoch:17 step:16850 [D loss: 0.270793, acc.: 52.34%] [G loss: 0.305579]\n",
      "epoch:17 step:16851 [D loss: 0.230624, acc.: 61.72%] [G loss: 0.305090]\n",
      "epoch:17 step:16852 [D loss: 0.240599, acc.: 63.28%] [G loss: 0.322763]\n",
      "epoch:17 step:16853 [D loss: 0.242367, acc.: 60.16%] [G loss: 0.289012]\n",
      "epoch:17 step:16854 [D loss: 0.255359, acc.: 53.91%] [G loss: 0.313133]\n",
      "epoch:17 step:16855 [D loss: 0.222452, acc.: 68.75%] [G loss: 0.317787]\n",
      "epoch:17 step:16856 [D loss: 0.258863, acc.: 47.66%] [G loss: 0.311146]\n",
      "epoch:17 step:16857 [D loss: 0.219981, acc.: 66.41%] [G loss: 0.269529]\n",
      "epoch:17 step:16858 [D loss: 0.237366, acc.: 62.50%] [G loss: 0.307173]\n",
      "epoch:17 step:16859 [D loss: 0.252578, acc.: 47.66%] [G loss: 0.301049]\n",
      "epoch:17 step:16860 [D loss: 0.250072, acc.: 59.38%] [G loss: 0.304522]\n",
      "epoch:17 step:16861 [D loss: 0.244633, acc.: 53.91%] [G loss: 0.333839]\n",
      "epoch:17 step:16862 [D loss: 0.253841, acc.: 51.56%] [G loss: 0.311933]\n",
      "epoch:17 step:16863 [D loss: 0.241250, acc.: 55.47%] [G loss: 0.273220]\n",
      "epoch:17 step:16864 [D loss: 0.238553, acc.: 55.47%] [G loss: 0.308217]\n",
      "epoch:17 step:16865 [D loss: 0.239925, acc.: 60.94%] [G loss: 0.303797]\n",
      "epoch:17 step:16866 [D loss: 0.248170, acc.: 52.34%] [G loss: 0.295862]\n",
      "epoch:18 step:16867 [D loss: 0.244618, acc.: 62.50%] [G loss: 0.304276]\n",
      "epoch:18 step:16868 [D loss: 0.240494, acc.: 54.69%] [G loss: 0.326243]\n",
      "epoch:18 step:16869 [D loss: 0.254271, acc.: 55.47%] [G loss: 0.299993]\n",
      "epoch:18 step:16870 [D loss: 0.234213, acc.: 53.12%] [G loss: 0.291655]\n",
      "epoch:18 step:16871 [D loss: 0.237828, acc.: 64.06%] [G loss: 0.294837]\n",
      "epoch:18 step:16872 [D loss: 0.245191, acc.: 57.81%] [G loss: 0.317475]\n",
      "epoch:18 step:16873 [D loss: 0.246063, acc.: 53.91%] [G loss: 0.303619]\n",
      "epoch:18 step:16874 [D loss: 0.247074, acc.: 56.25%] [G loss: 0.282862]\n",
      "epoch:18 step:16875 [D loss: 0.225619, acc.: 62.50%] [G loss: 0.298225]\n",
      "epoch:18 step:16876 [D loss: 0.253181, acc.: 52.34%] [G loss: 0.271171]\n",
      "epoch:18 step:16877 [D loss: 0.225934, acc.: 70.31%] [G loss: 0.302285]\n",
      "epoch:18 step:16878 [D loss: 0.232248, acc.: 61.72%] [G loss: 0.289627]\n",
      "epoch:18 step:16879 [D loss: 0.223072, acc.: 64.84%] [G loss: 0.316514]\n",
      "epoch:18 step:16880 [D loss: 0.241953, acc.: 50.78%] [G loss: 0.285192]\n",
      "epoch:18 step:16881 [D loss: 0.217265, acc.: 69.53%] [G loss: 0.291182]\n",
      "epoch:18 step:16882 [D loss: 0.237601, acc.: 60.16%] [G loss: 0.296523]\n",
      "epoch:18 step:16883 [D loss: 0.244564, acc.: 57.03%] [G loss: 0.276147]\n",
      "epoch:18 step:16884 [D loss: 0.232586, acc.: 57.81%] [G loss: 0.287688]\n",
      "epoch:18 step:16885 [D loss: 0.263815, acc.: 51.56%] [G loss: 0.282902]\n",
      "epoch:18 step:16886 [D loss: 0.229990, acc.: 53.91%] [G loss: 0.304098]\n",
      "epoch:18 step:16887 [D loss: 0.243651, acc.: 57.81%] [G loss: 0.306555]\n",
      "epoch:18 step:16888 [D loss: 0.239883, acc.: 54.69%] [G loss: 0.298767]\n",
      "epoch:18 step:16889 [D loss: 0.238726, acc.: 57.81%] [G loss: 0.289236]\n",
      "epoch:18 step:16890 [D loss: 0.225144, acc.: 63.28%] [G loss: 0.288625]\n",
      "epoch:18 step:16891 [D loss: 0.243492, acc.: 60.16%] [G loss: 0.277324]\n",
      "epoch:18 step:16892 [D loss: 0.239406, acc.: 57.81%] [G loss: 0.308751]\n",
      "epoch:18 step:16893 [D loss: 0.221151, acc.: 61.72%] [G loss: 0.328008]\n",
      "epoch:18 step:16894 [D loss: 0.250059, acc.: 55.47%] [G loss: 0.297679]\n",
      "epoch:18 step:16895 [D loss: 0.241256, acc.: 53.91%] [G loss: 0.278841]\n",
      "epoch:18 step:16896 [D loss: 0.253834, acc.: 56.25%] [G loss: 0.288555]\n",
      "epoch:18 step:16897 [D loss: 0.238054, acc.: 63.28%] [G loss: 0.290674]\n",
      "epoch:18 step:16898 [D loss: 0.218262, acc.: 65.62%] [G loss: 0.299576]\n",
      "epoch:18 step:16899 [D loss: 0.215400, acc.: 67.19%] [G loss: 0.305306]\n",
      "epoch:18 step:16900 [D loss: 0.234766, acc.: 59.38%] [G loss: 0.266902]\n",
      "epoch:18 step:16901 [D loss: 0.236481, acc.: 55.47%] [G loss: 0.338734]\n",
      "epoch:18 step:16902 [D loss: 0.238667, acc.: 61.72%] [G loss: 0.313931]\n",
      "epoch:18 step:16903 [D loss: 0.225720, acc.: 64.06%] [G loss: 0.301476]\n",
      "epoch:18 step:16904 [D loss: 0.240516, acc.: 60.94%] [G loss: 0.320559]\n",
      "epoch:18 step:16905 [D loss: 0.239366, acc.: 58.59%] [G loss: 0.286855]\n",
      "epoch:18 step:16906 [D loss: 0.226517, acc.: 65.62%] [G loss: 0.321174]\n",
      "epoch:18 step:16907 [D loss: 0.238695, acc.: 57.03%] [G loss: 0.310057]\n",
      "epoch:18 step:16908 [D loss: 0.242826, acc.: 57.81%] [G loss: 0.297032]\n",
      "epoch:18 step:16909 [D loss: 0.250054, acc.: 53.91%] [G loss: 0.280189]\n",
      "epoch:18 step:16910 [D loss: 0.249236, acc.: 52.34%] [G loss: 0.287707]\n",
      "epoch:18 step:16911 [D loss: 0.255124, acc.: 57.03%] [G loss: 0.286488]\n",
      "epoch:18 step:16912 [D loss: 0.236652, acc.: 57.03%] [G loss: 0.300257]\n",
      "epoch:18 step:16913 [D loss: 0.249990, acc.: 53.91%] [G loss: 0.315411]\n",
      "epoch:18 step:16914 [D loss: 0.242735, acc.: 56.25%] [G loss: 0.273305]\n",
      "epoch:18 step:16915 [D loss: 0.243823, acc.: 54.69%] [G loss: 0.257582]\n",
      "epoch:18 step:16916 [D loss: 0.227739, acc.: 60.94%] [G loss: 0.304528]\n",
      "epoch:18 step:16917 [D loss: 0.243102, acc.: 54.69%] [G loss: 0.302007]\n",
      "epoch:18 step:16918 [D loss: 0.241553, acc.: 58.59%] [G loss: 0.321013]\n",
      "epoch:18 step:16919 [D loss: 0.234447, acc.: 55.47%] [G loss: 0.319161]\n",
      "epoch:18 step:16920 [D loss: 0.232512, acc.: 60.94%] [G loss: 0.329491]\n",
      "epoch:18 step:16921 [D loss: 0.244257, acc.: 57.03%] [G loss: 0.314020]\n",
      "epoch:18 step:16922 [D loss: 0.239818, acc.: 60.16%] [G loss: 0.309029]\n",
      "epoch:18 step:16923 [D loss: 0.230301, acc.: 62.50%] [G loss: 0.298340]\n",
      "epoch:18 step:16924 [D loss: 0.261747, acc.: 56.25%] [G loss: 0.299843]\n",
      "epoch:18 step:16925 [D loss: 0.225662, acc.: 60.94%] [G loss: 0.291775]\n",
      "epoch:18 step:16926 [D loss: 0.224957, acc.: 63.28%] [G loss: 0.295538]\n",
      "epoch:18 step:16927 [D loss: 0.238986, acc.: 57.81%] [G loss: 0.293787]\n",
      "epoch:18 step:16928 [D loss: 0.247995, acc.: 56.25%] [G loss: 0.302235]\n",
      "epoch:18 step:16929 [D loss: 0.242622, acc.: 53.91%] [G loss: 0.302112]\n",
      "epoch:18 step:16930 [D loss: 0.261107, acc.: 46.09%] [G loss: 0.280998]\n",
      "epoch:18 step:16931 [D loss: 0.249303, acc.: 54.69%] [G loss: 0.293611]\n",
      "epoch:18 step:16932 [D loss: 0.263623, acc.: 48.44%] [G loss: 0.306622]\n",
      "epoch:18 step:16933 [D loss: 0.236847, acc.: 62.50%] [G loss: 0.304367]\n",
      "epoch:18 step:16934 [D loss: 0.237777, acc.: 57.03%] [G loss: 0.297498]\n",
      "epoch:18 step:16935 [D loss: 0.258239, acc.: 54.69%] [G loss: 0.299612]\n",
      "epoch:18 step:16936 [D loss: 0.243208, acc.: 57.03%] [G loss: 0.273127]\n",
      "epoch:18 step:16937 [D loss: 0.252712, acc.: 52.34%] [G loss: 0.270123]\n",
      "epoch:18 step:16938 [D loss: 0.246965, acc.: 57.81%] [G loss: 0.309871]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:18 step:16939 [D loss: 0.251161, acc.: 51.56%] [G loss: 0.299778]\n",
      "epoch:18 step:16940 [D loss: 0.238485, acc.: 52.34%] [G loss: 0.296510]\n",
      "epoch:18 step:16941 [D loss: 0.254110, acc.: 53.12%] [G loss: 0.299236]\n",
      "epoch:18 step:16942 [D loss: 0.233036, acc.: 62.50%] [G loss: 0.294751]\n",
      "epoch:18 step:16943 [D loss: 0.249303, acc.: 54.69%] [G loss: 0.292175]\n",
      "epoch:18 step:16944 [D loss: 0.241179, acc.: 60.16%] [G loss: 0.303639]\n",
      "epoch:18 step:16945 [D loss: 0.236491, acc.: 64.06%] [G loss: 0.310971]\n",
      "epoch:18 step:16946 [D loss: 0.227509, acc.: 59.38%] [G loss: 0.286792]\n",
      "epoch:18 step:16947 [D loss: 0.234982, acc.: 60.16%] [G loss: 0.302129]\n",
      "epoch:18 step:16948 [D loss: 0.225861, acc.: 65.62%] [G loss: 0.315896]\n",
      "epoch:18 step:16949 [D loss: 0.259116, acc.: 54.69%] [G loss: 0.297546]\n",
      "epoch:18 step:16950 [D loss: 0.234989, acc.: 62.50%] [G loss: 0.282926]\n",
      "epoch:18 step:16951 [D loss: 0.222544, acc.: 67.97%] [G loss: 0.315246]\n",
      "epoch:18 step:16952 [D loss: 0.253353, acc.: 54.69%] [G loss: 0.285805]\n",
      "epoch:18 step:16953 [D loss: 0.242283, acc.: 57.03%] [G loss: 0.298203]\n",
      "epoch:18 step:16954 [D loss: 0.236241, acc.: 58.59%] [G loss: 0.294365]\n",
      "epoch:18 step:16955 [D loss: 0.263233, acc.: 48.44%] [G loss: 0.294966]\n",
      "epoch:18 step:16956 [D loss: 0.235820, acc.: 63.28%] [G loss: 0.335422]\n",
      "epoch:18 step:16957 [D loss: 0.243725, acc.: 57.03%] [G loss: 0.288653]\n",
      "epoch:18 step:16958 [D loss: 0.229288, acc.: 64.06%] [G loss: 0.321437]\n",
      "epoch:18 step:16959 [D loss: 0.225957, acc.: 62.50%] [G loss: 0.318181]\n",
      "epoch:18 step:16960 [D loss: 0.244288, acc.: 59.38%] [G loss: 0.298190]\n",
      "epoch:18 step:16961 [D loss: 0.242655, acc.: 57.81%] [G loss: 0.307966]\n",
      "epoch:18 step:16962 [D loss: 0.230047, acc.: 60.94%] [G loss: 0.324245]\n",
      "epoch:18 step:16963 [D loss: 0.261537, acc.: 50.00%] [G loss: 0.294703]\n",
      "epoch:18 step:16964 [D loss: 0.240531, acc.: 57.03%] [G loss: 0.309901]\n",
      "epoch:18 step:16965 [D loss: 0.256996, acc.: 56.25%] [G loss: 0.299497]\n",
      "epoch:18 step:16966 [D loss: 0.262420, acc.: 49.22%] [G loss: 0.308850]\n",
      "epoch:18 step:16967 [D loss: 0.230341, acc.: 61.72%] [G loss: 0.293387]\n",
      "epoch:18 step:16968 [D loss: 0.227341, acc.: 67.19%] [G loss: 0.299556]\n",
      "epoch:18 step:16969 [D loss: 0.226642, acc.: 64.84%] [G loss: 0.319147]\n",
      "epoch:18 step:16970 [D loss: 0.229288, acc.: 62.50%] [G loss: 0.329386]\n",
      "epoch:18 step:16971 [D loss: 0.234070, acc.: 61.72%] [G loss: 0.321049]\n",
      "epoch:18 step:16972 [D loss: 0.238241, acc.: 60.94%] [G loss: 0.281110]\n",
      "epoch:18 step:16973 [D loss: 0.227880, acc.: 62.50%] [G loss: 0.307426]\n",
      "epoch:18 step:16974 [D loss: 0.238353, acc.: 61.72%] [G loss: 0.306141]\n",
      "epoch:18 step:16975 [D loss: 0.263884, acc.: 45.31%] [G loss: 0.295950]\n",
      "epoch:18 step:16976 [D loss: 0.247165, acc.: 51.56%] [G loss: 0.284025]\n",
      "epoch:18 step:16977 [D loss: 0.248187, acc.: 52.34%] [G loss: 0.305312]\n",
      "epoch:18 step:16978 [D loss: 0.245636, acc.: 54.69%] [G loss: 0.305523]\n",
      "epoch:18 step:16979 [D loss: 0.249268, acc.: 56.25%] [G loss: 0.305785]\n",
      "epoch:18 step:16980 [D loss: 0.218780, acc.: 70.31%] [G loss: 0.306293]\n",
      "epoch:18 step:16981 [D loss: 0.240781, acc.: 57.03%] [G loss: 0.306606]\n",
      "epoch:18 step:16982 [D loss: 0.247430, acc.: 57.03%] [G loss: 0.301006]\n",
      "epoch:18 step:16983 [D loss: 0.244266, acc.: 52.34%] [G loss: 0.301374]\n",
      "epoch:18 step:16984 [D loss: 0.235313, acc.: 57.81%] [G loss: 0.309848]\n",
      "epoch:18 step:16985 [D loss: 0.238151, acc.: 62.50%] [G loss: 0.289054]\n",
      "epoch:18 step:16986 [D loss: 0.241283, acc.: 57.81%] [G loss: 0.282877]\n",
      "epoch:18 step:16987 [D loss: 0.244523, acc.: 53.91%] [G loss: 0.309252]\n",
      "epoch:18 step:16988 [D loss: 0.244635, acc.: 60.16%] [G loss: 0.292973]\n",
      "epoch:18 step:16989 [D loss: 0.243718, acc.: 57.03%] [G loss: 0.262169]\n",
      "epoch:18 step:16990 [D loss: 0.242131, acc.: 54.69%] [G loss: 0.282233]\n",
      "epoch:18 step:16991 [D loss: 0.222075, acc.: 67.97%] [G loss: 0.303053]\n",
      "epoch:18 step:16992 [D loss: 0.243752, acc.: 57.81%] [G loss: 0.278043]\n",
      "epoch:18 step:16993 [D loss: 0.243627, acc.: 54.69%] [G loss: 0.306096]\n",
      "epoch:18 step:16994 [D loss: 0.229423, acc.: 62.50%] [G loss: 0.324506]\n",
      "epoch:18 step:16995 [D loss: 0.233197, acc.: 60.16%] [G loss: 0.295967]\n",
      "epoch:18 step:16996 [D loss: 0.229700, acc.: 62.50%] [G loss: 0.280910]\n",
      "epoch:18 step:16997 [D loss: 0.232314, acc.: 59.38%] [G loss: 0.298964]\n",
      "epoch:18 step:16998 [D loss: 0.235626, acc.: 60.16%] [G loss: 0.305608]\n",
      "epoch:18 step:16999 [D loss: 0.235035, acc.: 56.25%] [G loss: 0.308182]\n",
      "epoch:18 step:17000 [D loss: 0.235994, acc.: 57.03%] [G loss: 0.292832]\n",
      "epoch:18 step:17001 [D loss: 0.240770, acc.: 55.47%] [G loss: 0.294562]\n",
      "epoch:18 step:17002 [D loss: 0.244321, acc.: 57.81%] [G loss: 0.310648]\n",
      "epoch:18 step:17003 [D loss: 0.240005, acc.: 57.81%] [G loss: 0.284234]\n",
      "epoch:18 step:17004 [D loss: 0.230349, acc.: 63.28%] [G loss: 0.294897]\n",
      "epoch:18 step:17005 [D loss: 0.246774, acc.: 54.69%] [G loss: 0.301658]\n",
      "epoch:18 step:17006 [D loss: 0.237653, acc.: 58.59%] [G loss: 0.310767]\n",
      "epoch:18 step:17007 [D loss: 0.251022, acc.: 54.69%] [G loss: 0.275841]\n",
      "epoch:18 step:17008 [D loss: 0.246529, acc.: 56.25%] [G loss: 0.294110]\n",
      "epoch:18 step:17009 [D loss: 0.251505, acc.: 52.34%] [G loss: 0.322088]\n",
      "epoch:18 step:17010 [D loss: 0.254870, acc.: 53.12%] [G loss: 0.292134]\n",
      "epoch:18 step:17011 [D loss: 0.241092, acc.: 58.59%] [G loss: 0.283359]\n",
      "epoch:18 step:17012 [D loss: 0.239609, acc.: 57.81%] [G loss: 0.270944]\n",
      "epoch:18 step:17013 [D loss: 0.217937, acc.: 64.84%] [G loss: 0.336668]\n",
      "epoch:18 step:17014 [D loss: 0.238980, acc.: 60.94%] [G loss: 0.285571]\n",
      "epoch:18 step:17015 [D loss: 0.227327, acc.: 67.19%] [G loss: 0.285770]\n",
      "epoch:18 step:17016 [D loss: 0.240883, acc.: 58.59%] [G loss: 0.304121]\n",
      "epoch:18 step:17017 [D loss: 0.232383, acc.: 64.06%] [G loss: 0.338233]\n",
      "epoch:18 step:17018 [D loss: 0.237832, acc.: 64.84%] [G loss: 0.300049]\n",
      "epoch:18 step:17019 [D loss: 0.221423, acc.: 69.53%] [G loss: 0.282531]\n",
      "epoch:18 step:17020 [D loss: 0.233752, acc.: 58.59%] [G loss: 0.308319]\n",
      "epoch:18 step:17021 [D loss: 0.243019, acc.: 56.25%] [G loss: 0.270779]\n",
      "epoch:18 step:17022 [D loss: 0.233148, acc.: 61.72%] [G loss: 0.303439]\n",
      "epoch:18 step:17023 [D loss: 0.245246, acc.: 57.03%] [G loss: 0.297994]\n",
      "epoch:18 step:17024 [D loss: 0.231279, acc.: 58.59%] [G loss: 0.289458]\n",
      "epoch:18 step:17025 [D loss: 0.211908, acc.: 65.62%] [G loss: 0.298105]\n",
      "epoch:18 step:17026 [D loss: 0.220306, acc.: 65.62%] [G loss: 0.316225]\n",
      "epoch:18 step:17027 [D loss: 0.237687, acc.: 54.69%] [G loss: 0.300973]\n",
      "epoch:18 step:17028 [D loss: 0.239549, acc.: 61.72%] [G loss: 0.306211]\n",
      "epoch:18 step:17029 [D loss: 0.241172, acc.: 57.03%] [G loss: 0.310116]\n",
      "epoch:18 step:17030 [D loss: 0.240666, acc.: 54.69%] [G loss: 0.297619]\n",
      "epoch:18 step:17031 [D loss: 0.240690, acc.: 54.69%] [G loss: 0.314507]\n",
      "epoch:18 step:17032 [D loss: 0.253440, acc.: 53.91%] [G loss: 0.324160]\n",
      "epoch:18 step:17033 [D loss: 0.255231, acc.: 53.12%] [G loss: 0.316059]\n",
      "epoch:18 step:17034 [D loss: 0.241385, acc.: 61.72%] [G loss: 0.317692]\n",
      "epoch:18 step:17035 [D loss: 0.235076, acc.: 61.72%] [G loss: 0.310704]\n",
      "epoch:18 step:17036 [D loss: 0.243921, acc.: 57.81%] [G loss: 0.309437]\n",
      "epoch:18 step:17037 [D loss: 0.253363, acc.: 54.69%] [G loss: 0.300151]\n",
      "epoch:18 step:17038 [D loss: 0.218759, acc.: 60.94%] [G loss: 0.281786]\n",
      "epoch:18 step:17039 [D loss: 0.243660, acc.: 58.59%] [G loss: 0.308911]\n",
      "epoch:18 step:17040 [D loss: 0.213791, acc.: 68.75%] [G loss: 0.336811]\n",
      "epoch:18 step:17041 [D loss: 0.266974, acc.: 47.66%] [G loss: 0.296714]\n",
      "epoch:18 step:17042 [D loss: 0.241874, acc.: 59.38%] [G loss: 0.291124]\n",
      "epoch:18 step:17043 [D loss: 0.227230, acc.: 63.28%] [G loss: 0.295103]\n",
      "epoch:18 step:17044 [D loss: 0.230906, acc.: 60.16%] [G loss: 0.299061]\n",
      "epoch:18 step:17045 [D loss: 0.237524, acc.: 65.62%] [G loss: 0.278322]\n",
      "epoch:18 step:17046 [D loss: 0.230086, acc.: 60.94%] [G loss: 0.314475]\n",
      "epoch:18 step:17047 [D loss: 0.238869, acc.: 54.69%] [G loss: 0.279357]\n",
      "epoch:18 step:17048 [D loss: 0.227800, acc.: 64.84%] [G loss: 0.316206]\n",
      "epoch:18 step:17049 [D loss: 0.240821, acc.: 58.59%] [G loss: 0.285548]\n",
      "epoch:18 step:17050 [D loss: 0.241855, acc.: 53.91%] [G loss: 0.319642]\n",
      "epoch:18 step:17051 [D loss: 0.256407, acc.: 50.78%] [G loss: 0.300604]\n",
      "epoch:18 step:17052 [D loss: 0.240050, acc.: 58.59%] [G loss: 0.285504]\n",
      "epoch:18 step:17053 [D loss: 0.228421, acc.: 60.16%] [G loss: 0.295894]\n",
      "epoch:18 step:17054 [D loss: 0.234448, acc.: 54.69%] [G loss: 0.304998]\n",
      "epoch:18 step:17055 [D loss: 0.232789, acc.: 60.16%] [G loss: 0.339545]\n",
      "epoch:18 step:17056 [D loss: 0.243310, acc.: 57.81%] [G loss: 0.309665]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:18 step:17057 [D loss: 0.229768, acc.: 58.59%] [G loss: 0.288631]\n",
      "epoch:18 step:17058 [D loss: 0.231735, acc.: 54.69%] [G loss: 0.310827]\n",
      "epoch:18 step:17059 [D loss: 0.223095, acc.: 64.06%] [G loss: 0.310695]\n",
      "epoch:18 step:17060 [D loss: 0.244471, acc.: 60.94%] [G loss: 0.296149]\n",
      "epoch:18 step:17061 [D loss: 0.229880, acc.: 57.81%] [G loss: 0.340083]\n",
      "epoch:18 step:17062 [D loss: 0.254075, acc.: 51.56%] [G loss: 0.303939]\n",
      "epoch:18 step:17063 [D loss: 0.212901, acc.: 65.62%] [G loss: 0.299205]\n",
      "epoch:18 step:17064 [D loss: 0.234435, acc.: 58.59%] [G loss: 0.291998]\n",
      "epoch:18 step:17065 [D loss: 0.246711, acc.: 58.59%] [G loss: 0.275595]\n",
      "epoch:18 step:17066 [D loss: 0.238777, acc.: 59.38%] [G loss: 0.318311]\n",
      "epoch:18 step:17067 [D loss: 0.239785, acc.: 55.47%] [G loss: 0.286982]\n",
      "epoch:18 step:17068 [D loss: 0.222230, acc.: 62.50%] [G loss: 0.304257]\n",
      "epoch:18 step:17069 [D loss: 0.229691, acc.: 59.38%] [G loss: 0.277312]\n",
      "epoch:18 step:17070 [D loss: 0.248305, acc.: 57.03%] [G loss: 0.309812]\n",
      "epoch:18 step:17071 [D loss: 0.237262, acc.: 61.72%] [G loss: 0.303723]\n",
      "epoch:18 step:17072 [D loss: 0.244048, acc.: 57.03%] [G loss: 0.289474]\n",
      "epoch:18 step:17073 [D loss: 0.248333, acc.: 57.81%] [G loss: 0.277215]\n",
      "epoch:18 step:17074 [D loss: 0.235111, acc.: 60.16%] [G loss: 0.295620]\n",
      "epoch:18 step:17075 [D loss: 0.252299, acc.: 57.03%] [G loss: 0.318771]\n",
      "epoch:18 step:17076 [D loss: 0.224632, acc.: 62.50%] [G loss: 0.282456]\n",
      "epoch:18 step:17077 [D loss: 0.229542, acc.: 60.16%] [G loss: 0.326152]\n",
      "epoch:18 step:17078 [D loss: 0.224671, acc.: 64.84%] [G loss: 0.342679]\n",
      "epoch:18 step:17079 [D loss: 0.233679, acc.: 58.59%] [G loss: 0.312166]\n",
      "epoch:18 step:17080 [D loss: 0.257571, acc.: 53.91%] [G loss: 0.295292]\n",
      "epoch:18 step:17081 [D loss: 0.246332, acc.: 58.59%] [G loss: 0.289255]\n",
      "epoch:18 step:17082 [D loss: 0.232303, acc.: 58.59%] [G loss: 0.306791]\n",
      "epoch:18 step:17083 [D loss: 0.219258, acc.: 65.62%] [G loss: 0.302610]\n",
      "epoch:18 step:17084 [D loss: 0.243838, acc.: 56.25%] [G loss: 0.308180]\n",
      "epoch:18 step:17085 [D loss: 0.255583, acc.: 52.34%] [G loss: 0.262373]\n",
      "epoch:18 step:17086 [D loss: 0.229858, acc.: 62.50%] [G loss: 0.297061]\n",
      "epoch:18 step:17087 [D loss: 0.242987, acc.: 53.12%] [G loss: 0.300442]\n",
      "epoch:18 step:17088 [D loss: 0.247915, acc.: 53.12%] [G loss: 0.303626]\n",
      "epoch:18 step:17089 [D loss: 0.244826, acc.: 54.69%] [G loss: 0.293810]\n",
      "epoch:18 step:17090 [D loss: 0.253569, acc.: 53.91%] [G loss: 0.323703]\n",
      "epoch:18 step:17091 [D loss: 0.236665, acc.: 56.25%] [G loss: 0.298283]\n",
      "epoch:18 step:17092 [D loss: 0.221236, acc.: 67.97%] [G loss: 0.310161]\n",
      "epoch:18 step:17093 [D loss: 0.251109, acc.: 50.00%] [G loss: 0.315754]\n",
      "epoch:18 step:17094 [D loss: 0.242695, acc.: 54.69%] [G loss: 0.298278]\n",
      "epoch:18 step:17095 [D loss: 0.245216, acc.: 56.25%] [G loss: 0.311307]\n",
      "epoch:18 step:17096 [D loss: 0.244752, acc.: 57.81%] [G loss: 0.311519]\n",
      "epoch:18 step:17097 [D loss: 0.249032, acc.: 55.47%] [G loss: 0.306330]\n",
      "epoch:18 step:17098 [D loss: 0.258678, acc.: 53.91%] [G loss: 0.289630]\n",
      "epoch:18 step:17099 [D loss: 0.258556, acc.: 53.91%] [G loss: 0.313992]\n",
      "epoch:18 step:17100 [D loss: 0.245399, acc.: 58.59%] [G loss: 0.302809]\n",
      "epoch:18 step:17101 [D loss: 0.246127, acc.: 58.59%] [G loss: 0.294919]\n",
      "epoch:18 step:17102 [D loss: 0.221517, acc.: 61.72%] [G loss: 0.312867]\n",
      "epoch:18 step:17103 [D loss: 0.243173, acc.: 60.94%] [G loss: 0.307135]\n",
      "epoch:18 step:17104 [D loss: 0.252063, acc.: 54.69%] [G loss: 0.311486]\n",
      "epoch:18 step:17105 [D loss: 0.238770, acc.: 57.03%] [G loss: 0.307959]\n",
      "epoch:18 step:17106 [D loss: 0.231412, acc.: 60.94%] [G loss: 0.277079]\n",
      "epoch:18 step:17107 [D loss: 0.255537, acc.: 52.34%] [G loss: 0.315816]\n",
      "epoch:18 step:17108 [D loss: 0.235704, acc.: 60.16%] [G loss: 0.296807]\n",
      "epoch:18 step:17109 [D loss: 0.239100, acc.: 60.94%] [G loss: 0.309648]\n",
      "epoch:18 step:17110 [D loss: 0.240308, acc.: 55.47%] [G loss: 0.331205]\n",
      "epoch:18 step:17111 [D loss: 0.231110, acc.: 59.38%] [G loss: 0.308215]\n",
      "epoch:18 step:17112 [D loss: 0.234307, acc.: 58.59%] [G loss: 0.321180]\n",
      "epoch:18 step:17113 [D loss: 0.246371, acc.: 53.12%] [G loss: 0.276005]\n",
      "epoch:18 step:17114 [D loss: 0.248161, acc.: 51.56%] [G loss: 0.309289]\n",
      "epoch:18 step:17115 [D loss: 0.234974, acc.: 60.94%] [G loss: 0.327307]\n",
      "epoch:18 step:17116 [D loss: 0.231022, acc.: 62.50%] [G loss: 0.323629]\n",
      "epoch:18 step:17117 [D loss: 0.235782, acc.: 59.38%] [G loss: 0.313450]\n",
      "epoch:18 step:17118 [D loss: 0.230927, acc.: 60.94%] [G loss: 0.265980]\n",
      "epoch:18 step:17119 [D loss: 0.227648, acc.: 64.84%] [G loss: 0.297593]\n",
      "epoch:18 step:17120 [D loss: 0.259392, acc.: 50.78%] [G loss: 0.287729]\n",
      "epoch:18 step:17121 [D loss: 0.222464, acc.: 67.19%] [G loss: 0.316042]\n",
      "epoch:18 step:17122 [D loss: 0.237950, acc.: 61.72%] [G loss: 0.313692]\n",
      "epoch:18 step:17123 [D loss: 0.227936, acc.: 60.94%] [G loss: 0.310046]\n",
      "epoch:18 step:17124 [D loss: 0.234333, acc.: 62.50%] [G loss: 0.285323]\n",
      "epoch:18 step:17125 [D loss: 0.244259, acc.: 53.91%] [G loss: 0.326473]\n",
      "epoch:18 step:17126 [D loss: 0.250505, acc.: 55.47%] [G loss: 0.332610]\n",
      "epoch:18 step:17127 [D loss: 0.227964, acc.: 63.28%] [G loss: 0.318931]\n",
      "epoch:18 step:17128 [D loss: 0.242968, acc.: 57.81%] [G loss: 0.330934]\n",
      "epoch:18 step:17129 [D loss: 0.245859, acc.: 58.59%] [G loss: 0.330939]\n",
      "epoch:18 step:17130 [D loss: 0.248930, acc.: 47.66%] [G loss: 0.277986]\n",
      "epoch:18 step:17131 [D loss: 0.245770, acc.: 54.69%] [G loss: 0.288021]\n",
      "epoch:18 step:17132 [D loss: 0.245483, acc.: 57.03%] [G loss: 0.291400]\n",
      "epoch:18 step:17133 [D loss: 0.228595, acc.: 61.72%] [G loss: 0.281037]\n",
      "epoch:18 step:17134 [D loss: 0.235184, acc.: 60.94%] [G loss: 0.317972]\n",
      "epoch:18 step:17135 [D loss: 0.238066, acc.: 56.25%] [G loss: 0.299006]\n",
      "epoch:18 step:17136 [D loss: 0.242167, acc.: 57.81%] [G loss: 0.293834]\n",
      "epoch:18 step:17137 [D loss: 0.235244, acc.: 60.16%] [G loss: 0.294127]\n",
      "epoch:18 step:17138 [D loss: 0.259271, acc.: 50.00%] [G loss: 0.284723]\n",
      "epoch:18 step:17139 [D loss: 0.237644, acc.: 60.94%] [G loss: 0.327216]\n",
      "epoch:18 step:17140 [D loss: 0.245263, acc.: 58.59%] [G loss: 0.283654]\n",
      "epoch:18 step:17141 [D loss: 0.272699, acc.: 50.78%] [G loss: 0.277333]\n",
      "epoch:18 step:17142 [D loss: 0.237715, acc.: 57.81%] [G loss: 0.334812]\n",
      "epoch:18 step:17143 [D loss: 0.231127, acc.: 59.38%] [G loss: 0.321298]\n",
      "epoch:18 step:17144 [D loss: 0.243140, acc.: 53.12%] [G loss: 0.318604]\n",
      "epoch:18 step:17145 [D loss: 0.229691, acc.: 61.72%] [G loss: 0.310353]\n",
      "epoch:18 step:17146 [D loss: 0.225637, acc.: 62.50%] [G loss: 0.311373]\n",
      "epoch:18 step:17147 [D loss: 0.234587, acc.: 57.03%] [G loss: 0.304308]\n",
      "epoch:18 step:17148 [D loss: 0.235448, acc.: 57.81%] [G loss: 0.288273]\n",
      "epoch:18 step:17149 [D loss: 0.220322, acc.: 64.84%] [G loss: 0.307544]\n",
      "epoch:18 step:17150 [D loss: 0.248917, acc.: 58.59%] [G loss: 0.285397]\n",
      "epoch:18 step:17151 [D loss: 0.238432, acc.: 60.94%] [G loss: 0.280450]\n",
      "epoch:18 step:17152 [D loss: 0.254448, acc.: 42.19%] [G loss: 0.307517]\n",
      "epoch:18 step:17153 [D loss: 0.234881, acc.: 63.28%] [G loss: 0.299713]\n",
      "epoch:18 step:17154 [D loss: 0.225075, acc.: 65.62%] [G loss: 0.317175]\n",
      "epoch:18 step:17155 [D loss: 0.243208, acc.: 59.38%] [G loss: 0.280685]\n",
      "epoch:18 step:17156 [D loss: 0.237160, acc.: 60.94%] [G loss: 0.322402]\n",
      "epoch:18 step:17157 [D loss: 0.252102, acc.: 58.59%] [G loss: 0.279776]\n",
      "epoch:18 step:17158 [D loss: 0.256529, acc.: 51.56%] [G loss: 0.320855]\n",
      "epoch:18 step:17159 [D loss: 0.244570, acc.: 52.34%] [G loss: 0.290718]\n",
      "epoch:18 step:17160 [D loss: 0.243578, acc.: 55.47%] [G loss: 0.286801]\n",
      "epoch:18 step:17161 [D loss: 0.240714, acc.: 61.72%] [G loss: 0.296702]\n",
      "epoch:18 step:17162 [D loss: 0.239084, acc.: 57.03%] [G loss: 0.301882]\n",
      "epoch:18 step:17163 [D loss: 0.239331, acc.: 58.59%] [G loss: 0.314883]\n",
      "epoch:18 step:17164 [D loss: 0.232062, acc.: 64.84%] [G loss: 0.304337]\n",
      "epoch:18 step:17165 [D loss: 0.246701, acc.: 56.25%] [G loss: 0.302884]\n",
      "epoch:18 step:17166 [D loss: 0.246190, acc.: 57.03%] [G loss: 0.287282]\n",
      "epoch:18 step:17167 [D loss: 0.236022, acc.: 59.38%] [G loss: 0.306827]\n",
      "epoch:18 step:17168 [D loss: 0.241369, acc.: 58.59%] [G loss: 0.281308]\n",
      "epoch:18 step:17169 [D loss: 0.251678, acc.: 53.12%] [G loss: 0.292486]\n",
      "epoch:18 step:17170 [D loss: 0.226716, acc.: 61.72%] [G loss: 0.290540]\n",
      "epoch:18 step:17171 [D loss: 0.237484, acc.: 60.94%] [G loss: 0.317479]\n",
      "epoch:18 step:17172 [D loss: 0.236811, acc.: 60.94%] [G loss: 0.309603]\n",
      "epoch:18 step:17173 [D loss: 0.246585, acc.: 55.47%] [G loss: 0.306161]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:18 step:17174 [D loss: 0.235550, acc.: 60.16%] [G loss: 0.319820]\n",
      "epoch:18 step:17175 [D loss: 0.236045, acc.: 59.38%] [G loss: 0.295022]\n",
      "epoch:18 step:17176 [D loss: 0.222313, acc.: 62.50%] [G loss: 0.308109]\n",
      "epoch:18 step:17177 [D loss: 0.247473, acc.: 55.47%] [G loss: 0.303315]\n",
      "epoch:18 step:17178 [D loss: 0.248792, acc.: 47.66%] [G loss: 0.302456]\n",
      "epoch:18 step:17179 [D loss: 0.240266, acc.: 63.28%] [G loss: 0.289034]\n",
      "epoch:18 step:17180 [D loss: 0.240424, acc.: 57.03%] [G loss: 0.312694]\n",
      "epoch:18 step:17181 [D loss: 0.253397, acc.: 50.00%] [G loss: 0.298409]\n",
      "epoch:18 step:17182 [D loss: 0.233340, acc.: 61.72%] [G loss: 0.320920]\n",
      "epoch:18 step:17183 [D loss: 0.219799, acc.: 64.84%] [G loss: 0.332102]\n",
      "epoch:18 step:17184 [D loss: 0.230582, acc.: 59.38%] [G loss: 0.320047]\n",
      "epoch:18 step:17185 [D loss: 0.262244, acc.: 50.78%] [G loss: 0.278202]\n",
      "epoch:18 step:17186 [D loss: 0.238024, acc.: 56.25%] [G loss: 0.305087]\n",
      "epoch:18 step:17187 [D loss: 0.262627, acc.: 47.66%] [G loss: 0.310702]\n",
      "epoch:18 step:17188 [D loss: 0.255294, acc.: 53.91%] [G loss: 0.268354]\n",
      "epoch:18 step:17189 [D loss: 0.245671, acc.: 55.47%] [G loss: 0.296575]\n",
      "epoch:18 step:17190 [D loss: 0.235681, acc.: 64.84%] [G loss: 0.294463]\n",
      "epoch:18 step:17191 [D loss: 0.229368, acc.: 64.06%] [G loss: 0.289194]\n",
      "epoch:18 step:17192 [D loss: 0.231447, acc.: 61.72%] [G loss: 0.295220]\n",
      "epoch:18 step:17193 [D loss: 0.236684, acc.: 59.38%] [G loss: 0.311578]\n",
      "epoch:18 step:17194 [D loss: 0.240775, acc.: 59.38%] [G loss: 0.295034]\n",
      "epoch:18 step:17195 [D loss: 0.217841, acc.: 67.19%] [G loss: 0.320852]\n",
      "epoch:18 step:17196 [D loss: 0.238387, acc.: 56.25%] [G loss: 0.293076]\n",
      "epoch:18 step:17197 [D loss: 0.225778, acc.: 68.75%] [G loss: 0.300948]\n",
      "epoch:18 step:17198 [D loss: 0.239740, acc.: 57.81%] [G loss: 0.283533]\n",
      "epoch:18 step:17199 [D loss: 0.230639, acc.: 61.72%] [G loss: 0.298219]\n",
      "epoch:18 step:17200 [D loss: 0.229036, acc.: 65.62%] [G loss: 0.273768]\n",
      "epoch:18 step:17201 [D loss: 0.251244, acc.: 51.56%] [G loss: 0.325057]\n",
      "epoch:18 step:17202 [D loss: 0.240295, acc.: 58.59%] [G loss: 0.316990]\n",
      "epoch:18 step:17203 [D loss: 0.237077, acc.: 61.72%] [G loss: 0.284492]\n",
      "epoch:18 step:17204 [D loss: 0.233356, acc.: 66.41%] [G loss: 0.321722]\n",
      "epoch:18 step:17205 [D loss: 0.247214, acc.: 50.78%] [G loss: 0.275869]\n",
      "epoch:18 step:17206 [D loss: 0.229373, acc.: 59.38%] [G loss: 0.297847]\n",
      "epoch:18 step:17207 [D loss: 0.247760, acc.: 55.47%] [G loss: 0.289525]\n",
      "epoch:18 step:17208 [D loss: 0.238001, acc.: 62.50%] [G loss: 0.301612]\n",
      "epoch:18 step:17209 [D loss: 0.248393, acc.: 53.91%] [G loss: 0.324186]\n",
      "epoch:18 step:17210 [D loss: 0.266300, acc.: 42.19%] [G loss: 0.304540]\n",
      "epoch:18 step:17211 [D loss: 0.237561, acc.: 57.03%] [G loss: 0.268103]\n",
      "epoch:18 step:17212 [D loss: 0.255347, acc.: 51.56%] [G loss: 0.288314]\n",
      "epoch:18 step:17213 [D loss: 0.227909, acc.: 61.72%] [G loss: 0.308401]\n",
      "epoch:18 step:17214 [D loss: 0.244684, acc.: 54.69%] [G loss: 0.267138]\n",
      "epoch:18 step:17215 [D loss: 0.234832, acc.: 60.16%] [G loss: 0.286871]\n",
      "epoch:18 step:17216 [D loss: 0.232825, acc.: 57.03%] [G loss: 0.282802]\n",
      "epoch:18 step:17217 [D loss: 0.223267, acc.: 64.84%] [G loss: 0.301078]\n",
      "epoch:18 step:17218 [D loss: 0.249014, acc.: 57.03%] [G loss: 0.280682]\n",
      "epoch:18 step:17219 [D loss: 0.228328, acc.: 60.16%] [G loss: 0.318294]\n",
      "epoch:18 step:17220 [D loss: 0.240224, acc.: 59.38%] [G loss: 0.289466]\n",
      "epoch:18 step:17221 [D loss: 0.223473, acc.: 69.53%] [G loss: 0.336904]\n",
      "epoch:18 step:17222 [D loss: 0.226973, acc.: 61.72%] [G loss: 0.340729]\n",
      "epoch:18 step:17223 [D loss: 0.252284, acc.: 55.47%] [G loss: 0.317422]\n",
      "epoch:18 step:17224 [D loss: 0.238985, acc.: 59.38%] [G loss: 0.286278]\n",
      "epoch:18 step:17225 [D loss: 0.223184, acc.: 60.16%] [G loss: 0.305490]\n",
      "epoch:18 step:17226 [D loss: 0.235372, acc.: 61.72%] [G loss: 0.300799]\n",
      "epoch:18 step:17227 [D loss: 0.226939, acc.: 62.50%] [G loss: 0.316282]\n",
      "epoch:18 step:17228 [D loss: 0.243349, acc.: 62.50%] [G loss: 0.306996]\n",
      "epoch:18 step:17229 [D loss: 0.245822, acc.: 55.47%] [G loss: 0.321840]\n",
      "epoch:18 step:17230 [D loss: 0.245555, acc.: 57.81%] [G loss: 0.282034]\n",
      "epoch:18 step:17231 [D loss: 0.236467, acc.: 61.72%] [G loss: 0.299444]\n",
      "epoch:18 step:17232 [D loss: 0.225322, acc.: 60.94%] [G loss: 0.324547]\n",
      "epoch:18 step:17233 [D loss: 0.237011, acc.: 61.72%] [G loss: 0.308119]\n",
      "epoch:18 step:17234 [D loss: 0.234902, acc.: 57.81%] [G loss: 0.339525]\n",
      "epoch:18 step:17235 [D loss: 0.248406, acc.: 55.47%] [G loss: 0.281848]\n",
      "epoch:18 step:17236 [D loss: 0.252554, acc.: 55.47%] [G loss: 0.286913]\n",
      "epoch:18 step:17237 [D loss: 0.240964, acc.: 52.34%] [G loss: 0.298587]\n",
      "epoch:18 step:17238 [D loss: 0.230701, acc.: 64.06%] [G loss: 0.304973]\n",
      "epoch:18 step:17239 [D loss: 0.264059, acc.: 51.56%] [G loss: 0.293950]\n",
      "epoch:18 step:17240 [D loss: 0.253603, acc.: 54.69%] [G loss: 0.292566]\n",
      "epoch:18 step:17241 [D loss: 0.251667, acc.: 54.69%] [G loss: 0.295687]\n",
      "epoch:18 step:17242 [D loss: 0.250940, acc.: 53.12%] [G loss: 0.300095]\n",
      "epoch:18 step:17243 [D loss: 0.234616, acc.: 61.72%] [G loss: 0.302249]\n",
      "epoch:18 step:17244 [D loss: 0.240119, acc.: 60.16%] [G loss: 0.300200]\n",
      "epoch:18 step:17245 [D loss: 0.242719, acc.: 58.59%] [G loss: 0.293748]\n",
      "epoch:18 step:17246 [D loss: 0.220493, acc.: 63.28%] [G loss: 0.311056]\n",
      "epoch:18 step:17247 [D loss: 0.250379, acc.: 54.69%] [G loss: 0.336836]\n",
      "epoch:18 step:17248 [D loss: 0.249084, acc.: 53.12%] [G loss: 0.300895]\n",
      "epoch:18 step:17249 [D loss: 0.231423, acc.: 62.50%] [G loss: 0.317253]\n",
      "epoch:18 step:17250 [D loss: 0.246779, acc.: 58.59%] [G loss: 0.296729]\n",
      "epoch:18 step:17251 [D loss: 0.239555, acc.: 58.59%] [G loss: 0.320889]\n",
      "epoch:18 step:17252 [D loss: 0.235745, acc.: 62.50%] [G loss: 0.318518]\n",
      "epoch:18 step:17253 [D loss: 0.228005, acc.: 62.50%] [G loss: 0.328885]\n",
      "epoch:18 step:17254 [D loss: 0.239769, acc.: 56.25%] [G loss: 0.312291]\n",
      "epoch:18 step:17255 [D loss: 0.233852, acc.: 66.41%] [G loss: 0.325575]\n",
      "epoch:18 step:17256 [D loss: 0.242099, acc.: 57.03%] [G loss: 0.320876]\n",
      "epoch:18 step:17257 [D loss: 0.244123, acc.: 53.12%] [G loss: 0.318901]\n",
      "epoch:18 step:17258 [D loss: 0.237396, acc.: 62.50%] [G loss: 0.303852]\n",
      "epoch:18 step:17259 [D loss: 0.231832, acc.: 59.38%] [G loss: 0.314156]\n",
      "epoch:18 step:17260 [D loss: 0.226973, acc.: 60.16%] [G loss: 0.291345]\n",
      "epoch:18 step:17261 [D loss: 0.214472, acc.: 66.41%] [G loss: 0.310359]\n",
      "epoch:18 step:17262 [D loss: 0.237523, acc.: 64.84%] [G loss: 0.295769]\n",
      "epoch:18 step:17263 [D loss: 0.244279, acc.: 54.69%] [G loss: 0.278256]\n",
      "epoch:18 step:17264 [D loss: 0.242394, acc.: 60.94%] [G loss: 0.291066]\n",
      "epoch:18 step:17265 [D loss: 0.234096, acc.: 63.28%] [G loss: 0.280938]\n",
      "epoch:18 step:17266 [D loss: 0.248280, acc.: 58.59%] [G loss: 0.301852]\n",
      "epoch:18 step:17267 [D loss: 0.217023, acc.: 69.53%] [G loss: 0.324130]\n",
      "epoch:18 step:17268 [D loss: 0.230644, acc.: 59.38%] [G loss: 0.295840]\n",
      "epoch:18 step:17269 [D loss: 0.237683, acc.: 60.94%] [G loss: 0.309051]\n",
      "epoch:18 step:17270 [D loss: 0.249579, acc.: 53.91%] [G loss: 0.306080]\n",
      "epoch:18 step:17271 [D loss: 0.245323, acc.: 51.56%] [G loss: 0.348813]\n",
      "epoch:18 step:17272 [D loss: 0.240991, acc.: 54.69%] [G loss: 0.321306]\n",
      "epoch:18 step:17273 [D loss: 0.242561, acc.: 58.59%] [G loss: 0.301811]\n",
      "epoch:18 step:17274 [D loss: 0.217496, acc.: 64.06%] [G loss: 0.321809]\n",
      "epoch:18 step:17275 [D loss: 0.219864, acc.: 64.06%] [G loss: 0.293014]\n",
      "epoch:18 step:17276 [D loss: 0.235054, acc.: 60.94%] [G loss: 0.297464]\n",
      "epoch:18 step:17277 [D loss: 0.235502, acc.: 60.16%] [G loss: 0.300209]\n",
      "epoch:18 step:17278 [D loss: 0.253594, acc.: 51.56%] [G loss: 0.315777]\n",
      "epoch:18 step:17279 [D loss: 0.232969, acc.: 60.16%] [G loss: 0.298934]\n",
      "epoch:18 step:17280 [D loss: 0.214829, acc.: 63.28%] [G loss: 0.310434]\n",
      "epoch:18 step:17281 [D loss: 0.248902, acc.: 53.91%] [G loss: 0.301888]\n",
      "epoch:18 step:17282 [D loss: 0.242476, acc.: 56.25%] [G loss: 0.274099]\n",
      "epoch:18 step:17283 [D loss: 0.236069, acc.: 57.81%] [G loss: 0.316236]\n",
      "epoch:18 step:17284 [D loss: 0.259671, acc.: 50.00%] [G loss: 0.316410]\n",
      "epoch:18 step:17285 [D loss: 0.238785, acc.: 59.38%] [G loss: 0.311359]\n",
      "epoch:18 step:17286 [D loss: 0.241785, acc.: 54.69%] [G loss: 0.272649]\n",
      "epoch:18 step:17287 [D loss: 0.229896, acc.: 64.06%] [G loss: 0.341184]\n",
      "epoch:18 step:17288 [D loss: 0.251268, acc.: 55.47%] [G loss: 0.292789]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:18 step:17289 [D loss: 0.221684, acc.: 65.62%] [G loss: 0.323735]\n",
      "epoch:18 step:17290 [D loss: 0.229435, acc.: 60.94%] [G loss: 0.316842]\n",
      "epoch:18 step:17291 [D loss: 0.238546, acc.: 55.47%] [G loss: 0.286132]\n",
      "epoch:18 step:17292 [D loss: 0.230763, acc.: 62.50%] [G loss: 0.313820]\n",
      "epoch:18 step:17293 [D loss: 0.246702, acc.: 53.91%] [G loss: 0.314373]\n",
      "epoch:18 step:17294 [D loss: 0.232880, acc.: 57.03%] [G loss: 0.313326]\n",
      "epoch:18 step:17295 [D loss: 0.260507, acc.: 53.12%] [G loss: 0.284533]\n",
      "epoch:18 step:17296 [D loss: 0.229100, acc.: 57.03%] [G loss: 0.289070]\n",
      "epoch:18 step:17297 [D loss: 0.230108, acc.: 61.72%] [G loss: 0.295574]\n",
      "epoch:18 step:17298 [D loss: 0.238707, acc.: 59.38%] [G loss: 0.298494]\n",
      "epoch:18 step:17299 [D loss: 0.232119, acc.: 55.47%] [G loss: 0.302333]\n",
      "epoch:18 step:17300 [D loss: 0.243889, acc.: 60.16%] [G loss: 0.307115]\n",
      "epoch:18 step:17301 [D loss: 0.242334, acc.: 56.25%] [G loss: 0.311708]\n",
      "epoch:18 step:17302 [D loss: 0.234893, acc.: 57.81%] [G loss: 0.293740]\n",
      "epoch:18 step:17303 [D loss: 0.240269, acc.: 53.12%] [G loss: 0.281726]\n",
      "epoch:18 step:17304 [D loss: 0.238877, acc.: 55.47%] [G loss: 0.311001]\n",
      "epoch:18 step:17305 [D loss: 0.248927, acc.: 55.47%] [G loss: 0.307560]\n",
      "epoch:18 step:17306 [D loss: 0.254506, acc.: 55.47%] [G loss: 0.297145]\n",
      "epoch:18 step:17307 [D loss: 0.240461, acc.: 56.25%] [G loss: 0.279972]\n",
      "epoch:18 step:17308 [D loss: 0.251693, acc.: 53.12%] [G loss: 0.310711]\n",
      "epoch:18 step:17309 [D loss: 0.236111, acc.: 61.72%] [G loss: 0.299345]\n",
      "epoch:18 step:17310 [D loss: 0.241995, acc.: 61.72%] [G loss: 0.322596]\n",
      "epoch:18 step:17311 [D loss: 0.243178, acc.: 60.94%] [G loss: 0.302449]\n",
      "epoch:18 step:17312 [D loss: 0.241702, acc.: 55.47%] [G loss: 0.322424]\n",
      "epoch:18 step:17313 [D loss: 0.259598, acc.: 50.00%] [G loss: 0.313760]\n",
      "epoch:18 step:17314 [D loss: 0.239889, acc.: 56.25%] [G loss: 0.290670]\n",
      "epoch:18 step:17315 [D loss: 0.254965, acc.: 52.34%] [G loss: 0.322313]\n",
      "epoch:18 step:17316 [D loss: 0.240612, acc.: 58.59%] [G loss: 0.305173]\n",
      "epoch:18 step:17317 [D loss: 0.242054, acc.: 55.47%] [G loss: 0.312786]\n",
      "epoch:18 step:17318 [D loss: 0.241265, acc.: 58.59%] [G loss: 0.299598]\n",
      "epoch:18 step:17319 [D loss: 0.258607, acc.: 43.75%] [G loss: 0.288246]\n",
      "epoch:18 step:17320 [D loss: 0.234626, acc.: 59.38%] [G loss: 0.318724]\n",
      "epoch:18 step:17321 [D loss: 0.240361, acc.: 51.56%] [G loss: 0.266458]\n",
      "epoch:18 step:17322 [D loss: 0.242336, acc.: 56.25%] [G loss: 0.281891]\n",
      "epoch:18 step:17323 [D loss: 0.229310, acc.: 61.72%] [G loss: 0.305117]\n",
      "epoch:18 step:17324 [D loss: 0.233901, acc.: 59.38%] [G loss: 0.316746]\n",
      "epoch:18 step:17325 [D loss: 0.234600, acc.: 64.06%] [G loss: 0.315600]\n",
      "epoch:18 step:17326 [D loss: 0.240974, acc.: 53.91%] [G loss: 0.313321]\n",
      "epoch:18 step:17327 [D loss: 0.250211, acc.: 50.78%] [G loss: 0.290351]\n",
      "epoch:18 step:17328 [D loss: 0.247108, acc.: 52.34%] [G loss: 0.295478]\n",
      "epoch:18 step:17329 [D loss: 0.232934, acc.: 57.03%] [G loss: 0.313821]\n",
      "epoch:18 step:17330 [D loss: 0.247988, acc.: 61.72%] [G loss: 0.286395]\n",
      "epoch:18 step:17331 [D loss: 0.255636, acc.: 50.00%] [G loss: 0.296138]\n",
      "epoch:18 step:17332 [D loss: 0.249832, acc.: 51.56%] [G loss: 0.291918]\n",
      "epoch:18 step:17333 [D loss: 0.228563, acc.: 65.62%] [G loss: 0.285004]\n",
      "epoch:18 step:17334 [D loss: 0.239306, acc.: 52.34%] [G loss: 0.311097]\n",
      "epoch:18 step:17335 [D loss: 0.239606, acc.: 55.47%] [G loss: 0.294423]\n",
      "epoch:18 step:17336 [D loss: 0.242873, acc.: 54.69%] [G loss: 0.274960]\n",
      "epoch:18 step:17337 [D loss: 0.253770, acc.: 50.78%] [G loss: 0.299302]\n",
      "epoch:18 step:17338 [D loss: 0.242692, acc.: 64.84%] [G loss: 0.303184]\n",
      "epoch:18 step:17339 [D loss: 0.252004, acc.: 51.56%] [G loss: 0.275736]\n",
      "epoch:18 step:17340 [D loss: 0.223974, acc.: 60.94%] [G loss: 0.315427]\n",
      "epoch:18 step:17341 [D loss: 0.238882, acc.: 53.12%] [G loss: 0.285047]\n",
      "epoch:18 step:17342 [D loss: 0.231094, acc.: 62.50%] [G loss: 0.287812]\n",
      "epoch:18 step:17343 [D loss: 0.253604, acc.: 53.12%] [G loss: 0.282785]\n",
      "epoch:18 step:17344 [D loss: 0.246868, acc.: 55.47%] [G loss: 0.298146]\n",
      "epoch:18 step:17345 [D loss: 0.257764, acc.: 51.56%] [G loss: 0.306984]\n",
      "epoch:18 step:17346 [D loss: 0.249331, acc.: 53.91%] [G loss: 0.301542]\n",
      "epoch:18 step:17347 [D loss: 0.239194, acc.: 60.16%] [G loss: 0.308778]\n",
      "epoch:18 step:17348 [D loss: 0.254165, acc.: 48.44%] [G loss: 0.291904]\n",
      "epoch:18 step:17349 [D loss: 0.234640, acc.: 60.16%] [G loss: 0.303424]\n",
      "epoch:18 step:17350 [D loss: 0.222766, acc.: 62.50%] [G loss: 0.284988]\n",
      "epoch:18 step:17351 [D loss: 0.270437, acc.: 53.91%] [G loss: 0.287954]\n",
      "epoch:18 step:17352 [D loss: 0.222070, acc.: 65.62%] [G loss: 0.307319]\n",
      "epoch:18 step:17353 [D loss: 0.244928, acc.: 58.59%] [G loss: 0.286691]\n",
      "epoch:18 step:17354 [D loss: 0.220668, acc.: 68.75%] [G loss: 0.275960]\n",
      "epoch:18 step:17355 [D loss: 0.245349, acc.: 54.69%] [G loss: 0.285577]\n",
      "epoch:18 step:17356 [D loss: 0.230666, acc.: 61.72%] [G loss: 0.321174]\n",
      "epoch:18 step:17357 [D loss: 0.258371, acc.: 48.44%] [G loss: 0.283214]\n",
      "epoch:18 step:17358 [D loss: 0.252008, acc.: 51.56%] [G loss: 0.310584]\n",
      "epoch:18 step:17359 [D loss: 0.247384, acc.: 54.69%] [G loss: 0.292908]\n",
      "epoch:18 step:17360 [D loss: 0.228324, acc.: 60.16%] [G loss: 0.314414]\n",
      "epoch:18 step:17361 [D loss: 0.232107, acc.: 64.84%] [G loss: 0.336269]\n",
      "epoch:18 step:17362 [D loss: 0.227544, acc.: 64.06%] [G loss: 0.298362]\n",
      "epoch:18 step:17363 [D loss: 0.237151, acc.: 54.69%] [G loss: 0.306668]\n",
      "epoch:18 step:17364 [D loss: 0.242275, acc.: 57.81%] [G loss: 0.315095]\n",
      "epoch:18 step:17365 [D loss: 0.227024, acc.: 59.38%] [G loss: 0.310378]\n",
      "epoch:18 step:17366 [D loss: 0.228436, acc.: 59.38%] [G loss: 0.323636]\n",
      "epoch:18 step:17367 [D loss: 0.219277, acc.: 62.50%] [G loss: 0.310707]\n",
      "epoch:18 step:17368 [D loss: 0.230284, acc.: 60.16%] [G loss: 0.323578]\n",
      "epoch:18 step:17369 [D loss: 0.232465, acc.: 62.50%] [G loss: 0.287288]\n",
      "epoch:18 step:17370 [D loss: 0.224087, acc.: 60.94%] [G loss: 0.335711]\n",
      "epoch:18 step:17371 [D loss: 0.223775, acc.: 66.41%] [G loss: 0.293335]\n",
      "epoch:18 step:17372 [D loss: 0.227209, acc.: 66.41%] [G loss: 0.296694]\n",
      "epoch:18 step:17373 [D loss: 0.242526, acc.: 57.03%] [G loss: 0.308217]\n",
      "epoch:18 step:17374 [D loss: 0.220165, acc.: 67.19%] [G loss: 0.328602]\n",
      "epoch:18 step:17375 [D loss: 0.246158, acc.: 58.59%] [G loss: 0.313527]\n",
      "epoch:18 step:17376 [D loss: 0.227503, acc.: 66.41%] [G loss: 0.338109]\n",
      "epoch:18 step:17377 [D loss: 0.235725, acc.: 60.16%] [G loss: 0.334505]\n",
      "epoch:18 step:17378 [D loss: 0.224535, acc.: 61.72%] [G loss: 0.336569]\n",
      "epoch:18 step:17379 [D loss: 0.250488, acc.: 55.47%] [G loss: 0.323616]\n",
      "epoch:18 step:17380 [D loss: 0.245263, acc.: 52.34%] [G loss: 0.304309]\n",
      "epoch:18 step:17381 [D loss: 0.255650, acc.: 53.91%] [G loss: 0.288540]\n",
      "epoch:18 step:17382 [D loss: 0.246244, acc.: 57.81%] [G loss: 0.264199]\n",
      "epoch:18 step:17383 [D loss: 0.239232, acc.: 60.16%] [G loss: 0.272391]\n",
      "epoch:18 step:17384 [D loss: 0.218427, acc.: 64.84%] [G loss: 0.318262]\n",
      "epoch:18 step:17385 [D loss: 0.240197, acc.: 58.59%] [G loss: 0.304975]\n",
      "epoch:18 step:17386 [D loss: 0.232266, acc.: 59.38%] [G loss: 0.306642]\n",
      "epoch:18 step:17387 [D loss: 0.256106, acc.: 56.25%] [G loss: 0.307994]\n",
      "epoch:18 step:17388 [D loss: 0.245121, acc.: 55.47%] [G loss: 0.274128]\n",
      "epoch:18 step:17389 [D loss: 0.258523, acc.: 53.91%] [G loss: 0.284027]\n",
      "epoch:18 step:17390 [D loss: 0.243825, acc.: 57.03%] [G loss: 0.286113]\n",
      "epoch:18 step:17391 [D loss: 0.245195, acc.: 57.81%] [G loss: 0.309906]\n",
      "epoch:18 step:17392 [D loss: 0.250323, acc.: 56.25%] [G loss: 0.254974]\n",
      "epoch:18 step:17393 [D loss: 0.253089, acc.: 47.66%] [G loss: 0.264259]\n",
      "epoch:18 step:17394 [D loss: 0.238409, acc.: 57.81%] [G loss: 0.318552]\n",
      "epoch:18 step:17395 [D loss: 0.247987, acc.: 53.12%] [G loss: 0.307540]\n",
      "epoch:18 step:17396 [D loss: 0.249987, acc.: 56.25%] [G loss: 0.284323]\n",
      "epoch:18 step:17397 [D loss: 0.240858, acc.: 57.03%] [G loss: 0.323063]\n",
      "epoch:18 step:17398 [D loss: 0.233889, acc.: 61.72%] [G loss: 0.312313]\n",
      "epoch:18 step:17399 [D loss: 0.233020, acc.: 65.62%] [G loss: 0.290776]\n",
      "epoch:18 step:17400 [D loss: 0.243203, acc.: 56.25%] [G loss: 0.303863]\n",
      "epoch:18 step:17401 [D loss: 0.229246, acc.: 58.59%] [G loss: 0.269424]\n",
      "epoch:18 step:17402 [D loss: 0.250937, acc.: 53.91%] [G loss: 0.306497]\n",
      "epoch:18 step:17403 [D loss: 0.233336, acc.: 60.16%] [G loss: 0.288801]\n",
      "epoch:18 step:17404 [D loss: 0.237976, acc.: 59.38%] [G loss: 0.304244]\n",
      "epoch:18 step:17405 [D loss: 0.224718, acc.: 59.38%] [G loss: 0.316495]\n",
      "epoch:18 step:17406 [D loss: 0.237622, acc.: 60.16%] [G loss: 0.297092]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:18 step:17407 [D loss: 0.243938, acc.: 60.94%] [G loss: 0.262677]\n",
      "epoch:18 step:17408 [D loss: 0.240799, acc.: 56.25%] [G loss: 0.318607]\n",
      "epoch:18 step:17409 [D loss: 0.236885, acc.: 55.47%] [G loss: 0.305764]\n",
      "epoch:18 step:17410 [D loss: 0.238312, acc.: 58.59%] [G loss: 0.309243]\n",
      "epoch:18 step:17411 [D loss: 0.239072, acc.: 58.59%] [G loss: 0.293658]\n",
      "epoch:18 step:17412 [D loss: 0.249248, acc.: 52.34%] [G loss: 0.299012]\n",
      "epoch:18 step:17413 [D loss: 0.242732, acc.: 51.56%] [G loss: 0.298209]\n",
      "epoch:18 step:17414 [D loss: 0.264223, acc.: 45.31%] [G loss: 0.302253]\n",
      "epoch:18 step:17415 [D loss: 0.237190, acc.: 60.16%] [G loss: 0.272548]\n",
      "epoch:18 step:17416 [D loss: 0.236908, acc.: 52.34%] [G loss: 0.297712]\n",
      "epoch:18 step:17417 [D loss: 0.236616, acc.: 54.69%] [G loss: 0.295015]\n",
      "epoch:18 step:17418 [D loss: 0.240728, acc.: 59.38%] [G loss: 0.312066]\n",
      "epoch:18 step:17419 [D loss: 0.233258, acc.: 60.16%] [G loss: 0.303221]\n",
      "epoch:18 step:17420 [D loss: 0.240493, acc.: 54.69%] [G loss: 0.289906]\n",
      "epoch:18 step:17421 [D loss: 0.239119, acc.: 58.59%] [G loss: 0.289340]\n",
      "epoch:18 step:17422 [D loss: 0.255806, acc.: 49.22%] [G loss: 0.275356]\n",
      "epoch:18 step:17423 [D loss: 0.241930, acc.: 55.47%] [G loss: 0.306780]\n",
      "epoch:18 step:17424 [D loss: 0.245859, acc.: 57.03%] [G loss: 0.297789]\n",
      "epoch:18 step:17425 [D loss: 0.247040, acc.: 52.34%] [G loss: 0.301697]\n",
      "epoch:18 step:17426 [D loss: 0.237506, acc.: 54.69%] [G loss: 0.305806]\n",
      "epoch:18 step:17427 [D loss: 0.240792, acc.: 61.72%] [G loss: 0.271377]\n",
      "epoch:18 step:17428 [D loss: 0.245516, acc.: 55.47%] [G loss: 0.277558]\n",
      "epoch:18 step:17429 [D loss: 0.229028, acc.: 63.28%] [G loss: 0.287405]\n",
      "epoch:18 step:17430 [D loss: 0.227497, acc.: 59.38%] [G loss: 0.268976]\n",
      "epoch:18 step:17431 [D loss: 0.233375, acc.: 60.94%] [G loss: 0.307423]\n",
      "epoch:18 step:17432 [D loss: 0.223785, acc.: 66.41%] [G loss: 0.309729]\n",
      "epoch:18 step:17433 [D loss: 0.244881, acc.: 60.94%] [G loss: 0.269503]\n",
      "epoch:18 step:17434 [D loss: 0.238879, acc.: 60.94%] [G loss: 0.289526]\n",
      "epoch:18 step:17435 [D loss: 0.251227, acc.: 55.47%] [G loss: 0.287763]\n",
      "epoch:18 step:17436 [D loss: 0.229284, acc.: 66.41%] [G loss: 0.308209]\n",
      "epoch:18 step:17437 [D loss: 0.230148, acc.: 59.38%] [G loss: 0.284943]\n",
      "epoch:18 step:17438 [D loss: 0.221866, acc.: 64.06%] [G loss: 0.333047]\n",
      "epoch:18 step:17439 [D loss: 0.252017, acc.: 52.34%] [G loss: 0.295432]\n",
      "epoch:18 step:17440 [D loss: 0.237489, acc.: 58.59%] [G loss: 0.313950]\n",
      "epoch:18 step:17441 [D loss: 0.252526, acc.: 51.56%] [G loss: 0.315204]\n",
      "epoch:18 step:17442 [D loss: 0.224794, acc.: 67.97%] [G loss: 0.330547]\n",
      "epoch:18 step:17443 [D loss: 0.227458, acc.: 64.84%] [G loss: 0.327669]\n",
      "epoch:18 step:17444 [D loss: 0.237126, acc.: 60.16%] [G loss: 0.317765]\n",
      "epoch:18 step:17445 [D loss: 0.246734, acc.: 47.66%] [G loss: 0.290681]\n",
      "epoch:18 step:17446 [D loss: 0.248119, acc.: 57.81%] [G loss: 0.303096]\n",
      "epoch:18 step:17447 [D loss: 0.233808, acc.: 58.59%] [G loss: 0.301133]\n",
      "epoch:18 step:17448 [D loss: 0.241177, acc.: 57.81%] [G loss: 0.339187]\n",
      "epoch:18 step:17449 [D loss: 0.254133, acc.: 53.91%] [G loss: 0.324149]\n",
      "epoch:18 step:17450 [D loss: 0.235872, acc.: 58.59%] [G loss: 0.321005]\n",
      "epoch:18 step:17451 [D loss: 0.226260, acc.: 62.50%] [G loss: 0.312516]\n",
      "epoch:18 step:17452 [D loss: 0.246736, acc.: 59.38%] [G loss: 0.299377]\n",
      "epoch:18 step:17453 [D loss: 0.235826, acc.: 56.25%] [G loss: 0.308438]\n",
      "epoch:18 step:17454 [D loss: 0.238323, acc.: 54.69%] [G loss: 0.332379]\n",
      "epoch:18 step:17455 [D loss: 0.244922, acc.: 54.69%] [G loss: 0.328042]\n",
      "epoch:18 step:17456 [D loss: 0.238298, acc.: 55.47%] [G loss: 0.315679]\n",
      "epoch:18 step:17457 [D loss: 0.255744, acc.: 51.56%] [G loss: 0.311697]\n",
      "epoch:18 step:17458 [D loss: 0.223058, acc.: 64.84%] [G loss: 0.293614]\n",
      "epoch:18 step:17459 [D loss: 0.258195, acc.: 50.78%] [G loss: 0.295016]\n",
      "epoch:18 step:17460 [D loss: 0.236467, acc.: 57.03%] [G loss: 0.295129]\n",
      "epoch:18 step:17461 [D loss: 0.240618, acc.: 59.38%] [G loss: 0.315381]\n",
      "epoch:18 step:17462 [D loss: 0.239189, acc.: 55.47%] [G loss: 0.318001]\n",
      "epoch:18 step:17463 [D loss: 0.240686, acc.: 58.59%] [G loss: 0.349284]\n",
      "epoch:18 step:17464 [D loss: 0.247518, acc.: 58.59%] [G loss: 0.307366]\n",
      "epoch:18 step:17465 [D loss: 0.246293, acc.: 50.78%] [G loss: 0.280795]\n",
      "epoch:18 step:17466 [D loss: 0.245084, acc.: 57.03%] [G loss: 0.282818]\n",
      "epoch:18 step:17467 [D loss: 0.245167, acc.: 52.34%] [G loss: 0.332201]\n",
      "epoch:18 step:17468 [D loss: 0.221488, acc.: 63.28%] [G loss: 0.309315]\n",
      "epoch:18 step:17469 [D loss: 0.245138, acc.: 57.03%] [G loss: 0.288101]\n",
      "epoch:18 step:17470 [D loss: 0.239716, acc.: 60.16%] [G loss: 0.274475]\n",
      "epoch:18 step:17471 [D loss: 0.245107, acc.: 54.69%] [G loss: 0.301216]\n",
      "epoch:18 step:17472 [D loss: 0.241774, acc.: 53.12%] [G loss: 0.309028]\n",
      "epoch:18 step:17473 [D loss: 0.247572, acc.: 51.56%] [G loss: 0.315300]\n",
      "epoch:18 step:17474 [D loss: 0.250412, acc.: 56.25%] [G loss: 0.294802]\n",
      "epoch:18 step:17475 [D loss: 0.244575, acc.: 54.69%] [G loss: 0.285740]\n",
      "epoch:18 step:17476 [D loss: 0.225512, acc.: 61.72%] [G loss: 0.320007]\n",
      "epoch:18 step:17477 [D loss: 0.237397, acc.: 57.03%] [G loss: 0.319115]\n",
      "epoch:18 step:17478 [D loss: 0.243145, acc.: 54.69%] [G loss: 0.305725]\n",
      "epoch:18 step:17479 [D loss: 0.249762, acc.: 51.56%] [G loss: 0.308561]\n",
      "epoch:18 step:17480 [D loss: 0.248112, acc.: 52.34%] [G loss: 0.295566]\n",
      "epoch:18 step:17481 [D loss: 0.238037, acc.: 60.16%] [G loss: 0.312370]\n",
      "epoch:18 step:17482 [D loss: 0.249401, acc.: 53.91%] [G loss: 0.298301]\n",
      "epoch:18 step:17483 [D loss: 0.234932, acc.: 56.25%] [G loss: 0.284531]\n",
      "epoch:18 step:17484 [D loss: 0.238180, acc.: 57.03%] [G loss: 0.306338]\n",
      "epoch:18 step:17485 [D loss: 0.254547, acc.: 55.47%] [G loss: 0.329169]\n",
      "epoch:18 step:17486 [D loss: 0.233473, acc.: 56.25%] [G loss: 0.289185]\n",
      "epoch:18 step:17487 [D loss: 0.241016, acc.: 57.81%] [G loss: 0.318836]\n",
      "epoch:18 step:17488 [D loss: 0.218202, acc.: 66.41%] [G loss: 0.301675]\n",
      "epoch:18 step:17489 [D loss: 0.221064, acc.: 60.94%] [G loss: 0.315769]\n",
      "epoch:18 step:17490 [D loss: 0.245839, acc.: 50.00%] [G loss: 0.306222]\n",
      "epoch:18 step:17491 [D loss: 0.209589, acc.: 70.31%] [G loss: 0.313127]\n",
      "epoch:18 step:17492 [D loss: 0.235196, acc.: 53.12%] [G loss: 0.327547]\n",
      "epoch:18 step:17493 [D loss: 0.227648, acc.: 66.41%] [G loss: 0.289778]\n",
      "epoch:18 step:17494 [D loss: 0.237307, acc.: 59.38%] [G loss: 0.284484]\n",
      "epoch:18 step:17495 [D loss: 0.223156, acc.: 65.62%] [G loss: 0.283242]\n",
      "epoch:18 step:17496 [D loss: 0.240006, acc.: 55.47%] [G loss: 0.299097]\n",
      "epoch:18 step:17497 [D loss: 0.232231, acc.: 59.38%] [G loss: 0.307793]\n",
      "epoch:18 step:17498 [D loss: 0.267967, acc.: 50.78%] [G loss: 0.267433]\n",
      "epoch:18 step:17499 [D loss: 0.217532, acc.: 67.97%] [G loss: 0.309231]\n",
      "epoch:18 step:17500 [D loss: 0.236284, acc.: 62.50%] [G loss: 0.312524]\n",
      "epoch:18 step:17501 [D loss: 0.233522, acc.: 62.50%] [G loss: 0.314563]\n",
      "epoch:18 step:17502 [D loss: 0.228518, acc.: 65.62%] [G loss: 0.273748]\n",
      "epoch:18 step:17503 [D loss: 0.237158, acc.: 57.81%] [G loss: 0.295690]\n",
      "epoch:18 step:17504 [D loss: 0.251143, acc.: 57.03%] [G loss: 0.292878]\n",
      "epoch:18 step:17505 [D loss: 0.237223, acc.: 60.94%] [G loss: 0.298418]\n",
      "epoch:18 step:17506 [D loss: 0.245626, acc.: 55.47%] [G loss: 0.290971]\n",
      "epoch:18 step:17507 [D loss: 0.245459, acc.: 54.69%] [G loss: 0.330229]\n",
      "epoch:18 step:17508 [D loss: 0.237896, acc.: 57.81%] [G loss: 0.326671]\n",
      "epoch:18 step:17509 [D loss: 0.255379, acc.: 55.47%] [G loss: 0.290348]\n",
      "epoch:18 step:17510 [D loss: 0.233486, acc.: 60.16%] [G loss: 0.327305]\n",
      "epoch:18 step:17511 [D loss: 0.245197, acc.: 54.69%] [G loss: 0.312550]\n",
      "epoch:18 step:17512 [D loss: 0.243535, acc.: 58.59%] [G loss: 0.285266]\n",
      "epoch:18 step:17513 [D loss: 0.253635, acc.: 57.81%] [G loss: 0.281700]\n",
      "epoch:18 step:17514 [D loss: 0.236818, acc.: 60.94%] [G loss: 0.286647]\n",
      "epoch:18 step:17515 [D loss: 0.243661, acc.: 55.47%] [G loss: 0.322808]\n",
      "epoch:18 step:17516 [D loss: 0.242769, acc.: 61.72%] [G loss: 0.278217]\n",
      "epoch:18 step:17517 [D loss: 0.234427, acc.: 60.94%] [G loss: 0.328781]\n",
      "epoch:18 step:17518 [D loss: 0.224453, acc.: 61.72%] [G loss: 0.314407]\n",
      "epoch:18 step:17519 [D loss: 0.248300, acc.: 53.91%] [G loss: 0.285682]\n",
      "epoch:18 step:17520 [D loss: 0.226087, acc.: 60.94%] [G loss: 0.299940]\n",
      "epoch:18 step:17521 [D loss: 0.247084, acc.: 53.91%] [G loss: 0.295319]\n",
      "epoch:18 step:17522 [D loss: 0.219259, acc.: 68.75%] [G loss: 0.329854]\n",
      "epoch:18 step:17523 [D loss: 0.238259, acc.: 57.03%] [G loss: 0.304828]\n",
      "epoch:18 step:17524 [D loss: 0.236770, acc.: 59.38%] [G loss: 0.312440]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:18 step:17525 [D loss: 0.242645, acc.: 55.47%] [G loss: 0.284227]\n",
      "epoch:18 step:17526 [D loss: 0.228601, acc.: 60.16%] [G loss: 0.305185]\n",
      "epoch:18 step:17527 [D loss: 0.232805, acc.: 54.69%] [G loss: 0.295624]\n",
      "epoch:18 step:17528 [D loss: 0.246558, acc.: 53.91%] [G loss: 0.294868]\n",
      "epoch:18 step:17529 [D loss: 0.240407, acc.: 60.16%] [G loss: 0.285342]\n",
      "epoch:18 step:17530 [D loss: 0.230157, acc.: 61.72%] [G loss: 0.296821]\n",
      "epoch:18 step:17531 [D loss: 0.230844, acc.: 60.16%] [G loss: 0.326765]\n",
      "epoch:18 step:17532 [D loss: 0.227287, acc.: 65.62%] [G loss: 0.280676]\n",
      "epoch:18 step:17533 [D loss: 0.234574, acc.: 59.38%] [G loss: 0.307624]\n",
      "epoch:18 step:17534 [D loss: 0.230397, acc.: 58.59%] [G loss: 0.298076]\n",
      "epoch:18 step:17535 [D loss: 0.232560, acc.: 60.94%] [G loss: 0.302737]\n",
      "epoch:18 step:17536 [D loss: 0.248103, acc.: 53.91%] [G loss: 0.305145]\n",
      "epoch:18 step:17537 [D loss: 0.234188, acc.: 54.69%] [G loss: 0.296419]\n",
      "epoch:18 step:17538 [D loss: 0.242978, acc.: 58.59%] [G loss: 0.293305]\n",
      "epoch:18 step:17539 [D loss: 0.240073, acc.: 59.38%] [G loss: 0.317049]\n",
      "epoch:18 step:17540 [D loss: 0.239583, acc.: 57.03%] [G loss: 0.315523]\n",
      "epoch:18 step:17541 [D loss: 0.235983, acc.: 56.25%] [G loss: 0.330940]\n",
      "epoch:18 step:17542 [D loss: 0.227760, acc.: 60.94%] [G loss: 0.278252]\n",
      "epoch:18 step:17543 [D loss: 0.229035, acc.: 66.41%] [G loss: 0.327465]\n",
      "epoch:18 step:17544 [D loss: 0.243006, acc.: 57.81%] [G loss: 0.290047]\n",
      "epoch:18 step:17545 [D loss: 0.238684, acc.: 56.25%] [G loss: 0.301919]\n",
      "epoch:18 step:17546 [D loss: 0.245281, acc.: 56.25%] [G loss: 0.297164]\n",
      "epoch:18 step:17547 [D loss: 0.222700, acc.: 63.28%] [G loss: 0.341264]\n",
      "epoch:18 step:17548 [D loss: 0.239014, acc.: 56.25%] [G loss: 0.280413]\n",
      "epoch:18 step:17549 [D loss: 0.241964, acc.: 59.38%] [G loss: 0.304793]\n",
      "epoch:18 step:17550 [D loss: 0.233833, acc.: 64.84%] [G loss: 0.306252]\n",
      "epoch:18 step:17551 [D loss: 0.236511, acc.: 60.94%] [G loss: 0.304234]\n",
      "epoch:18 step:17552 [D loss: 0.229503, acc.: 60.16%] [G loss: 0.318386]\n",
      "epoch:18 step:17553 [D loss: 0.236854, acc.: 61.72%] [G loss: 0.320772]\n",
      "epoch:18 step:17554 [D loss: 0.232793, acc.: 62.50%] [G loss: 0.295284]\n",
      "epoch:18 step:17555 [D loss: 0.246710, acc.: 56.25%] [G loss: 0.318043]\n",
      "epoch:18 step:17556 [D loss: 0.242582, acc.: 57.03%] [G loss: 0.302085]\n",
      "epoch:18 step:17557 [D loss: 0.229247, acc.: 62.50%] [G loss: 0.317771]\n",
      "epoch:18 step:17558 [D loss: 0.232655, acc.: 63.28%] [G loss: 0.296360]\n",
      "epoch:18 step:17559 [D loss: 0.233845, acc.: 59.38%] [G loss: 0.304754]\n",
      "epoch:18 step:17560 [D loss: 0.238654, acc.: 57.03%] [G loss: 0.280837]\n",
      "epoch:18 step:17561 [D loss: 0.234988, acc.: 58.59%] [G loss: 0.286999]\n",
      "epoch:18 step:17562 [D loss: 0.233104, acc.: 60.16%] [G loss: 0.315424]\n",
      "epoch:18 step:17563 [D loss: 0.220111, acc.: 63.28%] [G loss: 0.309434]\n",
      "epoch:18 step:17564 [D loss: 0.241884, acc.: 56.25%] [G loss: 0.324502]\n",
      "epoch:18 step:17565 [D loss: 0.250820, acc.: 52.34%] [G loss: 0.301054]\n",
      "epoch:18 step:17566 [D loss: 0.249701, acc.: 57.03%] [G loss: 0.308443]\n",
      "epoch:18 step:17567 [D loss: 0.232265, acc.: 62.50%] [G loss: 0.280542]\n",
      "epoch:18 step:17568 [D loss: 0.232680, acc.: 56.25%] [G loss: 0.297577]\n",
      "epoch:18 step:17569 [D loss: 0.251201, acc.: 53.91%] [G loss: 0.291906]\n",
      "epoch:18 step:17570 [D loss: 0.256508, acc.: 50.00%] [G loss: 0.294293]\n",
      "epoch:18 step:17571 [D loss: 0.245758, acc.: 47.66%] [G loss: 0.300182]\n",
      "epoch:18 step:17572 [D loss: 0.246244, acc.: 53.91%] [G loss: 0.319334]\n",
      "epoch:18 step:17573 [D loss: 0.242224, acc.: 57.03%] [G loss: 0.304005]\n",
      "epoch:18 step:17574 [D loss: 0.227876, acc.: 65.62%] [G loss: 0.303687]\n",
      "epoch:18 step:17575 [D loss: 0.241763, acc.: 57.03%] [G loss: 0.308429]\n",
      "epoch:18 step:17576 [D loss: 0.222703, acc.: 66.41%] [G loss: 0.305481]\n",
      "epoch:18 step:17577 [D loss: 0.232665, acc.: 57.81%] [G loss: 0.328346]\n",
      "epoch:18 step:17578 [D loss: 0.243362, acc.: 57.03%] [G loss: 0.295950]\n",
      "epoch:18 step:17579 [D loss: 0.239683, acc.: 56.25%] [G loss: 0.300147]\n",
      "epoch:18 step:17580 [D loss: 0.242808, acc.: 54.69%] [G loss: 0.308396]\n",
      "epoch:18 step:17581 [D loss: 0.261579, acc.: 46.88%] [G loss: 0.279344]\n",
      "epoch:18 step:17582 [D loss: 0.233373, acc.: 64.84%] [G loss: 0.300511]\n",
      "epoch:18 step:17583 [D loss: 0.249427, acc.: 52.34%] [G loss: 0.311270]\n",
      "epoch:18 step:17584 [D loss: 0.224413, acc.: 66.41%] [G loss: 0.312155]\n",
      "epoch:18 step:17585 [D loss: 0.236647, acc.: 62.50%] [G loss: 0.284631]\n",
      "epoch:18 step:17586 [D loss: 0.248587, acc.: 57.81%] [G loss: 0.287395]\n",
      "epoch:18 step:17587 [D loss: 0.238077, acc.: 56.25%] [G loss: 0.307191]\n",
      "epoch:18 step:17588 [D loss: 0.241061, acc.: 62.50%] [G loss: 0.305039]\n",
      "epoch:18 step:17589 [D loss: 0.244959, acc.: 57.81%] [G loss: 0.318839]\n",
      "epoch:18 step:17590 [D loss: 0.236137, acc.: 60.16%] [G loss: 0.308471]\n",
      "epoch:18 step:17591 [D loss: 0.246070, acc.: 57.03%] [G loss: 0.298483]\n",
      "epoch:18 step:17592 [D loss: 0.254194, acc.: 50.00%] [G loss: 0.285875]\n",
      "epoch:18 step:17593 [D loss: 0.238210, acc.: 63.28%] [G loss: 0.329457]\n",
      "epoch:18 step:17594 [D loss: 0.246795, acc.: 55.47%] [G loss: 0.311244]\n",
      "epoch:18 step:17595 [D loss: 0.242224, acc.: 57.81%] [G loss: 0.308539]\n",
      "epoch:18 step:17596 [D loss: 0.250450, acc.: 57.03%] [G loss: 0.309599]\n",
      "epoch:18 step:17597 [D loss: 0.239596, acc.: 60.16%] [G loss: 0.290157]\n",
      "epoch:18 step:17598 [D loss: 0.260002, acc.: 49.22%] [G loss: 0.303234]\n",
      "epoch:18 step:17599 [D loss: 0.233031, acc.: 58.59%] [G loss: 0.306386]\n",
      "epoch:18 step:17600 [D loss: 0.232866, acc.: 60.94%] [G loss: 0.318065]\n",
      "epoch:18 step:17601 [D loss: 0.236434, acc.: 57.81%] [G loss: 0.313058]\n",
      "epoch:18 step:17602 [D loss: 0.230749, acc.: 55.47%] [G loss: 0.322613]\n",
      "epoch:18 step:17603 [D loss: 0.255177, acc.: 53.91%] [G loss: 0.283623]\n",
      "epoch:18 step:17604 [D loss: 0.267025, acc.: 46.09%] [G loss: 0.291671]\n",
      "epoch:18 step:17605 [D loss: 0.235749, acc.: 62.50%] [G loss: 0.307052]\n",
      "epoch:18 step:17606 [D loss: 0.234928, acc.: 59.38%] [G loss: 0.296392]\n",
      "epoch:18 step:17607 [D loss: 0.226621, acc.: 61.72%] [G loss: 0.292621]\n",
      "epoch:18 step:17608 [D loss: 0.246709, acc.: 52.34%] [G loss: 0.277902]\n",
      "epoch:18 step:17609 [D loss: 0.233435, acc.: 64.06%] [G loss: 0.315426]\n",
      "epoch:18 step:17610 [D loss: 0.236391, acc.: 64.06%] [G loss: 0.303711]\n",
      "epoch:18 step:17611 [D loss: 0.250308, acc.: 56.25%] [G loss: 0.315594]\n",
      "epoch:18 step:17612 [D loss: 0.238882, acc.: 55.47%] [G loss: 0.299265]\n",
      "epoch:18 step:17613 [D loss: 0.232814, acc.: 64.06%] [G loss: 0.305810]\n",
      "epoch:18 step:17614 [D loss: 0.238368, acc.: 59.38%] [G loss: 0.302362]\n",
      "epoch:18 step:17615 [D loss: 0.235723, acc.: 59.38%] [G loss: 0.327457]\n",
      "epoch:18 step:17616 [D loss: 0.241080, acc.: 61.72%] [G loss: 0.304608]\n",
      "epoch:18 step:17617 [D loss: 0.237231, acc.: 61.72%] [G loss: 0.289786]\n",
      "epoch:18 step:17618 [D loss: 0.245828, acc.: 56.25%] [G loss: 0.304968]\n",
      "epoch:18 step:17619 [D loss: 0.233144, acc.: 63.28%] [G loss: 0.300748]\n",
      "epoch:18 step:17620 [D loss: 0.259479, acc.: 50.00%] [G loss: 0.290658]\n",
      "epoch:18 step:17621 [D loss: 0.239692, acc.: 57.03%] [G loss: 0.292064]\n",
      "epoch:18 step:17622 [D loss: 0.223147, acc.: 64.06%] [G loss: 0.305994]\n",
      "epoch:18 step:17623 [D loss: 0.239323, acc.: 57.03%] [G loss: 0.293506]\n",
      "epoch:18 step:17624 [D loss: 0.230160, acc.: 60.16%] [G loss: 0.319304]\n",
      "epoch:18 step:17625 [D loss: 0.232678, acc.: 64.06%] [G loss: 0.277337]\n",
      "epoch:18 step:17626 [D loss: 0.223480, acc.: 64.84%] [G loss: 0.296468]\n",
      "epoch:18 step:17627 [D loss: 0.240741, acc.: 58.59%] [G loss: 0.298322]\n",
      "epoch:18 step:17628 [D loss: 0.251833, acc.: 54.69%] [G loss: 0.293880]\n",
      "epoch:18 step:17629 [D loss: 0.247374, acc.: 55.47%] [G loss: 0.295469]\n",
      "epoch:18 step:17630 [D loss: 0.233043, acc.: 64.84%] [G loss: 0.313013]\n",
      "epoch:18 step:17631 [D loss: 0.243692, acc.: 53.91%] [G loss: 0.334242]\n",
      "epoch:18 step:17632 [D loss: 0.226683, acc.: 59.38%] [G loss: 0.312216]\n",
      "epoch:18 step:17633 [D loss: 0.239857, acc.: 60.16%] [G loss: 0.315437]\n",
      "epoch:18 step:17634 [D loss: 0.232042, acc.: 59.38%] [G loss: 0.304174]\n",
      "epoch:18 step:17635 [D loss: 0.240159, acc.: 60.16%] [G loss: 0.302402]\n",
      "epoch:18 step:17636 [D loss: 0.240126, acc.: 57.03%] [G loss: 0.314157]\n",
      "epoch:18 step:17637 [D loss: 0.242446, acc.: 57.81%] [G loss: 0.279748]\n",
      "epoch:18 step:17638 [D loss: 0.228338, acc.: 60.94%] [G loss: 0.290100]\n",
      "epoch:18 step:17639 [D loss: 0.242623, acc.: 57.81%] [G loss: 0.285571]\n",
      "epoch:18 step:17640 [D loss: 0.237030, acc.: 57.81%] [G loss: 0.289805]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:18 step:17641 [D loss: 0.226022, acc.: 66.41%] [G loss: 0.310838]\n",
      "epoch:18 step:17642 [D loss: 0.241644, acc.: 56.25%] [G loss: 0.304572]\n",
      "epoch:18 step:17643 [D loss: 0.236754, acc.: 58.59%] [G loss: 0.316702]\n",
      "epoch:18 step:17644 [D loss: 0.242103, acc.: 54.69%] [G loss: 0.310778]\n",
      "epoch:18 step:17645 [D loss: 0.234158, acc.: 60.16%] [G loss: 0.324064]\n",
      "epoch:18 step:17646 [D loss: 0.268509, acc.: 47.66%] [G loss: 0.279575]\n",
      "epoch:18 step:17647 [D loss: 0.227086, acc.: 64.06%] [G loss: 0.300771]\n",
      "epoch:18 step:17648 [D loss: 0.233789, acc.: 58.59%] [G loss: 0.315227]\n",
      "epoch:18 step:17649 [D loss: 0.245353, acc.: 55.47%] [G loss: 0.293841]\n",
      "epoch:18 step:17650 [D loss: 0.240727, acc.: 57.81%] [G loss: 0.330952]\n",
      "epoch:18 step:17651 [D loss: 0.246425, acc.: 58.59%] [G loss: 0.291580]\n",
      "epoch:18 step:17652 [D loss: 0.239680, acc.: 53.12%] [G loss: 0.318621]\n",
      "epoch:18 step:17653 [D loss: 0.246426, acc.: 52.34%] [G loss: 0.298005]\n",
      "epoch:18 step:17654 [D loss: 0.243513, acc.: 52.34%] [G loss: 0.280611]\n",
      "epoch:18 step:17655 [D loss: 0.225501, acc.: 67.19%] [G loss: 0.310356]\n",
      "epoch:18 step:17656 [D loss: 0.230566, acc.: 59.38%] [G loss: 0.296899]\n",
      "epoch:18 step:17657 [D loss: 0.239943, acc.: 55.47%] [G loss: 0.288037]\n",
      "epoch:18 step:17658 [D loss: 0.249077, acc.: 53.91%] [G loss: 0.304691]\n",
      "epoch:18 step:17659 [D loss: 0.229373, acc.: 65.62%] [G loss: 0.294215]\n",
      "epoch:18 step:17660 [D loss: 0.246017, acc.: 53.91%] [G loss: 0.298761]\n",
      "epoch:18 step:17661 [D loss: 0.248700, acc.: 51.56%] [G loss: 0.304235]\n",
      "epoch:18 step:17662 [D loss: 0.239700, acc.: 57.81%] [G loss: 0.306400]\n",
      "epoch:18 step:17663 [D loss: 0.219901, acc.: 65.62%] [G loss: 0.296458]\n",
      "epoch:18 step:17664 [D loss: 0.245014, acc.: 60.94%] [G loss: 0.324385]\n",
      "epoch:18 step:17665 [D loss: 0.230020, acc.: 60.16%] [G loss: 0.329143]\n",
      "epoch:18 step:17666 [D loss: 0.230599, acc.: 58.59%] [G loss: 0.310328]\n",
      "epoch:18 step:17667 [D loss: 0.244278, acc.: 54.69%] [G loss: 0.298071]\n",
      "epoch:18 step:17668 [D loss: 0.248742, acc.: 55.47%] [G loss: 0.297978]\n",
      "epoch:18 step:17669 [D loss: 0.256709, acc.: 53.12%] [G loss: 0.322951]\n",
      "epoch:18 step:17670 [D loss: 0.252845, acc.: 53.12%] [G loss: 0.315166]\n",
      "epoch:18 step:17671 [D loss: 0.242997, acc.: 55.47%] [G loss: 0.312466]\n",
      "epoch:18 step:17672 [D loss: 0.234387, acc.: 60.16%] [G loss: 0.302461]\n",
      "epoch:18 step:17673 [D loss: 0.237504, acc.: 55.47%] [G loss: 0.317084]\n",
      "epoch:18 step:17674 [D loss: 0.244685, acc.: 60.16%] [G loss: 0.290817]\n",
      "epoch:18 step:17675 [D loss: 0.263477, acc.: 52.34%] [G loss: 0.298788]\n",
      "epoch:18 step:17676 [D loss: 0.233548, acc.: 64.06%] [G loss: 0.308332]\n",
      "epoch:18 step:17677 [D loss: 0.225694, acc.: 62.50%] [G loss: 0.314526]\n",
      "epoch:18 step:17678 [D loss: 0.247644, acc.: 57.81%] [G loss: 0.292723]\n",
      "epoch:18 step:17679 [D loss: 0.243670, acc.: 54.69%] [G loss: 0.310021]\n",
      "epoch:18 step:17680 [D loss: 0.244680, acc.: 61.72%] [G loss: 0.290616]\n",
      "epoch:18 step:17681 [D loss: 0.237293, acc.: 57.81%] [G loss: 0.293576]\n",
      "epoch:18 step:17682 [D loss: 0.236742, acc.: 57.81%] [G loss: 0.303229]\n",
      "epoch:18 step:17683 [D loss: 0.247125, acc.: 52.34%] [G loss: 0.298766]\n",
      "epoch:18 step:17684 [D loss: 0.229505, acc.: 63.28%] [G loss: 0.313442]\n",
      "epoch:18 step:17685 [D loss: 0.237998, acc.: 59.38%] [G loss: 0.301068]\n",
      "epoch:18 step:17686 [D loss: 0.228315, acc.: 65.62%] [G loss: 0.292192]\n",
      "epoch:18 step:17687 [D loss: 0.240961, acc.: 55.47%] [G loss: 0.300125]\n",
      "epoch:18 step:17688 [D loss: 0.219957, acc.: 65.62%] [G loss: 0.293775]\n",
      "epoch:18 step:17689 [D loss: 0.224053, acc.: 63.28%] [G loss: 0.280092]\n",
      "epoch:18 step:17690 [D loss: 0.243251, acc.: 54.69%] [G loss: 0.288126]\n",
      "epoch:18 step:17691 [D loss: 0.249105, acc.: 52.34%] [G loss: 0.288187]\n",
      "epoch:18 step:17692 [D loss: 0.249493, acc.: 53.12%] [G loss: 0.277473]\n",
      "epoch:18 step:17693 [D loss: 0.239766, acc.: 57.03%] [G loss: 0.286026]\n",
      "epoch:18 step:17694 [D loss: 0.241414, acc.: 58.59%] [G loss: 0.305288]\n",
      "epoch:18 step:17695 [D loss: 0.254888, acc.: 51.56%] [G loss: 0.281039]\n",
      "epoch:18 step:17696 [D loss: 0.239302, acc.: 60.94%] [G loss: 0.286807]\n",
      "epoch:18 step:17697 [D loss: 0.244913, acc.: 55.47%] [G loss: 0.295728]\n",
      "epoch:18 step:17698 [D loss: 0.223741, acc.: 64.06%] [G loss: 0.291533]\n",
      "epoch:18 step:17699 [D loss: 0.249021, acc.: 51.56%] [G loss: 0.281678]\n",
      "epoch:18 step:17700 [D loss: 0.244961, acc.: 56.25%] [G loss: 0.314288]\n",
      "epoch:18 step:17701 [D loss: 0.251323, acc.: 59.38%] [G loss: 0.322386]\n",
      "epoch:18 step:17702 [D loss: 0.249736, acc.: 53.91%] [G loss: 0.283074]\n",
      "epoch:18 step:17703 [D loss: 0.234296, acc.: 56.25%] [G loss: 0.282744]\n",
      "epoch:18 step:17704 [D loss: 0.248939, acc.: 53.91%] [G loss: 0.339894]\n",
      "epoch:18 step:17705 [D loss: 0.243685, acc.: 57.81%] [G loss: 0.320422]\n",
      "epoch:18 step:17706 [D loss: 0.224537, acc.: 59.38%] [G loss: 0.317203]\n",
      "epoch:18 step:17707 [D loss: 0.242517, acc.: 59.38%] [G loss: 0.301704]\n",
      "epoch:18 step:17708 [D loss: 0.242602, acc.: 53.91%] [G loss: 0.324081]\n",
      "epoch:18 step:17709 [D loss: 0.248326, acc.: 55.47%] [G loss: 0.286046]\n",
      "epoch:18 step:17710 [D loss: 0.244373, acc.: 54.69%] [G loss: 0.286973]\n",
      "epoch:18 step:17711 [D loss: 0.244151, acc.: 57.81%] [G loss: 0.308962]\n",
      "epoch:18 step:17712 [D loss: 0.246664, acc.: 58.59%] [G loss: 0.294396]\n",
      "epoch:18 step:17713 [D loss: 0.242682, acc.: 57.03%] [G loss: 0.312855]\n",
      "epoch:18 step:17714 [D loss: 0.237428, acc.: 58.59%] [G loss: 0.299681]\n",
      "epoch:18 step:17715 [D loss: 0.224368, acc.: 63.28%] [G loss: 0.282552]\n",
      "epoch:18 step:17716 [D loss: 0.244490, acc.: 57.03%] [G loss: 0.312874]\n",
      "epoch:18 step:17717 [D loss: 0.255185, acc.: 50.78%] [G loss: 0.306309]\n",
      "epoch:18 step:17718 [D loss: 0.234931, acc.: 60.94%] [G loss: 0.310534]\n",
      "epoch:18 step:17719 [D loss: 0.227311, acc.: 60.94%] [G loss: 0.314325]\n",
      "epoch:18 step:17720 [D loss: 0.237538, acc.: 57.81%] [G loss: 0.283056]\n",
      "epoch:18 step:17721 [D loss: 0.244067, acc.: 57.03%] [G loss: 0.298848]\n",
      "epoch:18 step:17722 [D loss: 0.222137, acc.: 67.97%] [G loss: 0.288528]\n",
      "epoch:18 step:17723 [D loss: 0.233900, acc.: 60.16%] [G loss: 0.321979]\n",
      "epoch:18 step:17724 [D loss: 0.229013, acc.: 63.28%] [G loss: 0.310345]\n",
      "epoch:18 step:17725 [D loss: 0.245659, acc.: 54.69%] [G loss: 0.305056]\n",
      "epoch:18 step:17726 [D loss: 0.237208, acc.: 60.16%] [G loss: 0.285239]\n",
      "epoch:18 step:17727 [D loss: 0.223920, acc.: 67.19%] [G loss: 0.289188]\n",
      "epoch:18 step:17728 [D loss: 0.229347, acc.: 60.16%] [G loss: 0.310621]\n",
      "epoch:18 step:17729 [D loss: 0.253230, acc.: 53.12%] [G loss: 0.325084]\n",
      "epoch:18 step:17730 [D loss: 0.254195, acc.: 58.59%] [G loss: 0.277940]\n",
      "epoch:18 step:17731 [D loss: 0.247220, acc.: 55.47%] [G loss: 0.293078]\n",
      "epoch:18 step:17732 [D loss: 0.235108, acc.: 57.81%] [G loss: 0.306419]\n",
      "epoch:18 step:17733 [D loss: 0.258913, acc.: 50.78%] [G loss: 0.266752]\n",
      "epoch:18 step:17734 [D loss: 0.214682, acc.: 67.19%] [G loss: 0.309399]\n",
      "epoch:18 step:17735 [D loss: 0.231421, acc.: 60.94%] [G loss: 0.298615]\n",
      "epoch:18 step:17736 [D loss: 0.234716, acc.: 59.38%] [G loss: 0.321192]\n",
      "epoch:18 step:17737 [D loss: 0.248183, acc.: 55.47%] [G loss: 0.290002]\n",
      "epoch:18 step:17738 [D loss: 0.235073, acc.: 61.72%] [G loss: 0.309591]\n",
      "epoch:18 step:17739 [D loss: 0.229490, acc.: 63.28%] [G loss: 0.308921]\n",
      "epoch:18 step:17740 [D loss: 0.237089, acc.: 60.16%] [G loss: 0.329084]\n",
      "epoch:18 step:17741 [D loss: 0.227856, acc.: 62.50%] [G loss: 0.304561]\n",
      "epoch:18 step:17742 [D loss: 0.240762, acc.: 59.38%] [G loss: 0.314809]\n",
      "epoch:18 step:17743 [D loss: 0.227755, acc.: 64.84%] [G loss: 0.319722]\n",
      "epoch:18 step:17744 [D loss: 0.252623, acc.: 50.00%] [G loss: 0.278579]\n",
      "epoch:18 step:17745 [D loss: 0.231612, acc.: 63.28%] [G loss: 0.277760]\n",
      "epoch:18 step:17746 [D loss: 0.246515, acc.: 52.34%] [G loss: 0.292301]\n",
      "epoch:18 step:17747 [D loss: 0.227739, acc.: 57.03%] [G loss: 0.289940]\n",
      "epoch:18 step:17748 [D loss: 0.233345, acc.: 55.47%] [G loss: 0.326837]\n",
      "epoch:18 step:17749 [D loss: 0.239919, acc.: 61.72%] [G loss: 0.315937]\n",
      "epoch:18 step:17750 [D loss: 0.222181, acc.: 64.84%] [G loss: 0.314270]\n",
      "epoch:18 step:17751 [D loss: 0.248938, acc.: 59.38%] [G loss: 0.301653]\n",
      "epoch:18 step:17752 [D loss: 0.234591, acc.: 54.69%] [G loss: 0.300080]\n",
      "epoch:18 step:17753 [D loss: 0.233463, acc.: 59.38%] [G loss: 0.283002]\n",
      "epoch:18 step:17754 [D loss: 0.239935, acc.: 56.25%] [G loss: 0.312711]\n",
      "epoch:18 step:17755 [D loss: 0.243604, acc.: 57.81%] [G loss: 0.302444]\n",
      "epoch:18 step:17756 [D loss: 0.238080, acc.: 56.25%] [G loss: 0.312105]\n",
      "epoch:18 step:17757 [D loss: 0.244411, acc.: 57.81%] [G loss: 0.323764]\n",
      "epoch:18 step:17758 [D loss: 0.244301, acc.: 57.03%] [G loss: 0.290284]\n",
      "epoch:18 step:17759 [D loss: 0.239684, acc.: 58.59%] [G loss: 0.311041]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:18 step:17760 [D loss: 0.239837, acc.: 61.72%] [G loss: 0.289169]\n",
      "epoch:18 step:17761 [D loss: 0.243161, acc.: 57.03%] [G loss: 0.303275]\n",
      "epoch:18 step:17762 [D loss: 0.229601, acc.: 65.62%] [G loss: 0.341228]\n",
      "epoch:18 step:17763 [D loss: 0.234342, acc.: 58.59%] [G loss: 0.319024]\n",
      "epoch:18 step:17764 [D loss: 0.234361, acc.: 60.16%] [G loss: 0.316685]\n",
      "epoch:18 step:17765 [D loss: 0.231172, acc.: 57.03%] [G loss: 0.307076]\n",
      "epoch:18 step:17766 [D loss: 0.243553, acc.: 56.25%] [G loss: 0.319636]\n",
      "epoch:18 step:17767 [D loss: 0.243975, acc.: 60.16%] [G loss: 0.292399]\n",
      "epoch:18 step:17768 [D loss: 0.237889, acc.: 57.03%] [G loss: 0.296420]\n",
      "epoch:18 step:17769 [D loss: 0.231016, acc.: 61.72%] [G loss: 0.290759]\n",
      "epoch:18 step:17770 [D loss: 0.229458, acc.: 64.84%] [G loss: 0.304097]\n",
      "epoch:18 step:17771 [D loss: 0.244106, acc.: 52.34%] [G loss: 0.304600]\n",
      "epoch:18 step:17772 [D loss: 0.217085, acc.: 61.72%] [G loss: 0.313778]\n",
      "epoch:18 step:17773 [D loss: 0.237003, acc.: 59.38%] [G loss: 0.279200]\n",
      "epoch:18 step:17774 [D loss: 0.261284, acc.: 42.97%] [G loss: 0.264834]\n",
      "epoch:18 step:17775 [D loss: 0.263949, acc.: 50.00%] [G loss: 0.310407]\n",
      "epoch:18 step:17776 [D loss: 0.242376, acc.: 59.38%] [G loss: 0.317994]\n",
      "epoch:18 step:17777 [D loss: 0.230990, acc.: 63.28%] [G loss: 0.296299]\n",
      "epoch:18 step:17778 [D loss: 0.242294, acc.: 57.81%] [G loss: 0.269823]\n",
      "epoch:18 step:17779 [D loss: 0.232280, acc.: 60.94%] [G loss: 0.297634]\n",
      "epoch:18 step:17780 [D loss: 0.217357, acc.: 63.28%] [G loss: 0.286134]\n",
      "epoch:18 step:17781 [D loss: 0.254638, acc.: 52.34%] [G loss: 0.298290]\n",
      "epoch:18 step:17782 [D loss: 0.244805, acc.: 57.03%] [G loss: 0.305417]\n",
      "epoch:18 step:17783 [D loss: 0.246374, acc.: 56.25%] [G loss: 0.317922]\n",
      "epoch:18 step:17784 [D loss: 0.238532, acc.: 59.38%] [G loss: 0.283104]\n",
      "epoch:18 step:17785 [D loss: 0.231943, acc.: 56.25%] [G loss: 0.298173]\n",
      "epoch:18 step:17786 [D loss: 0.240708, acc.: 57.03%] [G loss: 0.293883]\n",
      "epoch:18 step:17787 [D loss: 0.236197, acc.: 53.91%] [G loss: 0.301166]\n",
      "epoch:18 step:17788 [D loss: 0.225639, acc.: 61.72%] [G loss: 0.309913]\n",
      "epoch:18 step:17789 [D loss: 0.236976, acc.: 63.28%] [G loss: 0.311414]\n",
      "epoch:18 step:17790 [D loss: 0.237620, acc.: 54.69%] [G loss: 0.281893]\n",
      "epoch:18 step:17791 [D loss: 0.240913, acc.: 56.25%] [G loss: 0.300077]\n",
      "epoch:18 step:17792 [D loss: 0.240005, acc.: 56.25%] [G loss: 0.269293]\n",
      "epoch:18 step:17793 [D loss: 0.237852, acc.: 57.03%] [G loss: 0.276420]\n",
      "epoch:18 step:17794 [D loss: 0.244521, acc.: 53.12%] [G loss: 0.305918]\n",
      "epoch:18 step:17795 [D loss: 0.247294, acc.: 63.28%] [G loss: 0.298800]\n",
      "epoch:18 step:17796 [D loss: 0.214855, acc.: 67.97%] [G loss: 0.323951]\n",
      "epoch:18 step:17797 [D loss: 0.249352, acc.: 58.59%] [G loss: 0.294551]\n",
      "epoch:18 step:17798 [D loss: 0.239047, acc.: 60.94%] [G loss: 0.282053]\n",
      "epoch:18 step:17799 [D loss: 0.263299, acc.: 50.78%] [G loss: 0.296213]\n",
      "epoch:18 step:17800 [D loss: 0.248455, acc.: 54.69%] [G loss: 0.299324]\n",
      "epoch:18 step:17801 [D loss: 0.251495, acc.: 55.47%] [G loss: 0.280766]\n",
      "epoch:18 step:17802 [D loss: 0.223461, acc.: 65.62%] [G loss: 0.303660]\n",
      "epoch:18 step:17803 [D loss: 0.239312, acc.: 56.25%] [G loss: 0.324527]\n",
      "epoch:19 step:17804 [D loss: 0.237154, acc.: 57.03%] [G loss: 0.327735]\n",
      "epoch:19 step:17805 [D loss: 0.253574, acc.: 53.12%] [G loss: 0.315517]\n",
      "epoch:19 step:17806 [D loss: 0.221235, acc.: 64.06%] [G loss: 0.313038]\n",
      "epoch:19 step:17807 [D loss: 0.235386, acc.: 66.41%] [G loss: 0.288379]\n",
      "epoch:19 step:17808 [D loss: 0.240286, acc.: 57.81%] [G loss: 0.302286]\n",
      "epoch:19 step:17809 [D loss: 0.257318, acc.: 50.00%] [G loss: 0.295503]\n",
      "epoch:19 step:17810 [D loss: 0.243417, acc.: 58.59%] [G loss: 0.314043]\n",
      "epoch:19 step:17811 [D loss: 0.245683, acc.: 57.81%] [G loss: 0.292076]\n",
      "epoch:19 step:17812 [D loss: 0.236672, acc.: 59.38%] [G loss: 0.295208]\n",
      "epoch:19 step:17813 [D loss: 0.251963, acc.: 53.12%] [G loss: 0.322370]\n",
      "epoch:19 step:17814 [D loss: 0.231769, acc.: 56.25%] [G loss: 0.274404]\n",
      "epoch:19 step:17815 [D loss: 0.234000, acc.: 60.16%] [G loss: 0.301486]\n",
      "epoch:19 step:17816 [D loss: 0.242923, acc.: 54.69%] [G loss: 0.285932]\n",
      "epoch:19 step:17817 [D loss: 0.243675, acc.: 59.38%] [G loss: 0.287686]\n",
      "epoch:19 step:17818 [D loss: 0.223482, acc.: 63.28%] [G loss: 0.289773]\n",
      "epoch:19 step:17819 [D loss: 0.222842, acc.: 68.75%] [G loss: 0.298167]\n",
      "epoch:19 step:17820 [D loss: 0.236264, acc.: 62.50%] [G loss: 0.307101]\n",
      "epoch:19 step:17821 [D loss: 0.234347, acc.: 61.72%] [G loss: 0.295757]\n",
      "epoch:19 step:17822 [D loss: 0.253248, acc.: 57.81%] [G loss: 0.289549]\n",
      "epoch:19 step:17823 [D loss: 0.229790, acc.: 58.59%] [G loss: 0.341957]\n",
      "epoch:19 step:17824 [D loss: 0.233580, acc.: 57.81%] [G loss: 0.326765]\n",
      "epoch:19 step:17825 [D loss: 0.236615, acc.: 61.72%] [G loss: 0.328472]\n",
      "epoch:19 step:17826 [D loss: 0.242612, acc.: 56.25%] [G loss: 0.301556]\n",
      "epoch:19 step:17827 [D loss: 0.246839, acc.: 52.34%] [G loss: 0.291546]\n",
      "epoch:19 step:17828 [D loss: 0.236659, acc.: 53.91%] [G loss: 0.308090]\n",
      "epoch:19 step:17829 [D loss: 0.244135, acc.: 60.94%] [G loss: 0.293037]\n",
      "epoch:19 step:17830 [D loss: 0.241564, acc.: 59.38%] [G loss: 0.318008]\n",
      "epoch:19 step:17831 [D loss: 0.240139, acc.: 56.25%] [G loss: 0.298407]\n",
      "epoch:19 step:17832 [D loss: 0.243799, acc.: 53.91%] [G loss: 0.311436]\n",
      "epoch:19 step:17833 [D loss: 0.240220, acc.: 63.28%] [G loss: 0.319943]\n",
      "epoch:19 step:17834 [D loss: 0.242117, acc.: 55.47%] [G loss: 0.297225]\n",
      "epoch:19 step:17835 [D loss: 0.239924, acc.: 57.03%] [G loss: 0.301747]\n",
      "epoch:19 step:17836 [D loss: 0.237449, acc.: 61.72%] [G loss: 0.302312]\n",
      "epoch:19 step:17837 [D loss: 0.229020, acc.: 61.72%] [G loss: 0.276325]\n",
      "epoch:19 step:17838 [D loss: 0.225610, acc.: 62.50%] [G loss: 0.309251]\n",
      "epoch:19 step:17839 [D loss: 0.230245, acc.: 62.50%] [G loss: 0.295767]\n",
      "epoch:19 step:17840 [D loss: 0.219828, acc.: 67.19%] [G loss: 0.297718]\n",
      "epoch:19 step:17841 [D loss: 0.233982, acc.: 59.38%] [G loss: 0.284733]\n",
      "epoch:19 step:17842 [D loss: 0.239015, acc.: 56.25%] [G loss: 0.268085]\n",
      "epoch:19 step:17843 [D loss: 0.227589, acc.: 60.94%] [G loss: 0.273764]\n",
      "epoch:19 step:17844 [D loss: 0.226377, acc.: 66.41%] [G loss: 0.307820]\n",
      "epoch:19 step:17845 [D loss: 0.240769, acc.: 57.03%] [G loss: 0.317594]\n",
      "epoch:19 step:17846 [D loss: 0.229812, acc.: 64.06%] [G loss: 0.312235]\n",
      "epoch:19 step:17847 [D loss: 0.244454, acc.: 56.25%] [G loss: 0.304121]\n",
      "epoch:19 step:17848 [D loss: 0.243227, acc.: 58.59%] [G loss: 0.311692]\n",
      "epoch:19 step:17849 [D loss: 0.253795, acc.: 54.69%] [G loss: 0.323317]\n",
      "epoch:19 step:17850 [D loss: 0.220696, acc.: 64.84%] [G loss: 0.315392]\n",
      "epoch:19 step:17851 [D loss: 0.231566, acc.: 58.59%] [G loss: 0.293089]\n",
      "epoch:19 step:17852 [D loss: 0.248213, acc.: 53.12%] [G loss: 0.328761]\n",
      "epoch:19 step:17853 [D loss: 0.244911, acc.: 54.69%] [G loss: 0.309328]\n",
      "epoch:19 step:17854 [D loss: 0.230695, acc.: 58.59%] [G loss: 0.308431]\n",
      "epoch:19 step:17855 [D loss: 0.237555, acc.: 57.03%] [G loss: 0.307635]\n",
      "epoch:19 step:17856 [D loss: 0.226237, acc.: 59.38%] [G loss: 0.325736]\n",
      "epoch:19 step:17857 [D loss: 0.249618, acc.: 54.69%] [G loss: 0.308428]\n",
      "epoch:19 step:17858 [D loss: 0.237453, acc.: 59.38%] [G loss: 0.282085]\n",
      "epoch:19 step:17859 [D loss: 0.239509, acc.: 64.84%] [G loss: 0.332174]\n",
      "epoch:19 step:17860 [D loss: 0.230907, acc.: 64.84%] [G loss: 0.297011]\n",
      "epoch:19 step:17861 [D loss: 0.242509, acc.: 57.81%] [G loss: 0.318068]\n",
      "epoch:19 step:17862 [D loss: 0.235141, acc.: 61.72%] [G loss: 0.295841]\n",
      "epoch:19 step:17863 [D loss: 0.225792, acc.: 65.62%] [G loss: 0.321974]\n",
      "epoch:19 step:17864 [D loss: 0.243340, acc.: 53.91%] [G loss: 0.297409]\n",
      "epoch:19 step:17865 [D loss: 0.231097, acc.: 63.28%] [G loss: 0.276768]\n",
      "epoch:19 step:17866 [D loss: 0.236249, acc.: 62.50%] [G loss: 0.313440]\n",
      "epoch:19 step:17867 [D loss: 0.254453, acc.: 51.56%] [G loss: 0.290587]\n",
      "epoch:19 step:17868 [D loss: 0.232191, acc.: 59.38%] [G loss: 0.291720]\n",
      "epoch:19 step:17869 [D loss: 0.232376, acc.: 54.69%] [G loss: 0.299509]\n",
      "epoch:19 step:17870 [D loss: 0.237227, acc.: 59.38%] [G loss: 0.321057]\n",
      "epoch:19 step:17871 [D loss: 0.239299, acc.: 58.59%] [G loss: 0.293811]\n",
      "epoch:19 step:17872 [D loss: 0.218204, acc.: 69.53%] [G loss: 0.334360]\n",
      "epoch:19 step:17873 [D loss: 0.243371, acc.: 57.03%] [G loss: 0.273103]\n",
      "epoch:19 step:17874 [D loss: 0.233494, acc.: 64.84%] [G loss: 0.286039]\n",
      "epoch:19 step:17875 [D loss: 0.234791, acc.: 57.03%] [G loss: 0.298211]\n",
      "epoch:19 step:17876 [D loss: 0.234798, acc.: 56.25%] [G loss: 0.286969]\n",
      "epoch:19 step:17877 [D loss: 0.235236, acc.: 59.38%] [G loss: 0.290699]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:19 step:17878 [D loss: 0.252243, acc.: 53.12%] [G loss: 0.295295]\n",
      "epoch:19 step:17879 [D loss: 0.234707, acc.: 59.38%] [G loss: 0.305696]\n",
      "epoch:19 step:17880 [D loss: 0.245614, acc.: 55.47%] [G loss: 0.317729]\n",
      "epoch:19 step:17881 [D loss: 0.258317, acc.: 51.56%] [G loss: 0.315565]\n",
      "epoch:19 step:17882 [D loss: 0.249748, acc.: 54.69%] [G loss: 0.303912]\n",
      "epoch:19 step:17883 [D loss: 0.224521, acc.: 65.62%] [G loss: 0.284156]\n",
      "epoch:19 step:17884 [D loss: 0.242112, acc.: 55.47%] [G loss: 0.291021]\n",
      "epoch:19 step:17885 [D loss: 0.227552, acc.: 67.19%] [G loss: 0.310453]\n",
      "epoch:19 step:17886 [D loss: 0.255821, acc.: 52.34%] [G loss: 0.325890]\n",
      "epoch:19 step:17887 [D loss: 0.250494, acc.: 53.91%] [G loss: 0.311830]\n",
      "epoch:19 step:17888 [D loss: 0.238574, acc.: 60.16%] [G loss: 0.275063]\n",
      "epoch:19 step:17889 [D loss: 0.234443, acc.: 62.50%] [G loss: 0.298338]\n",
      "epoch:19 step:17890 [D loss: 0.255941, acc.: 52.34%] [G loss: 0.282838]\n",
      "epoch:19 step:17891 [D loss: 0.251398, acc.: 53.12%] [G loss: 0.307949]\n",
      "epoch:19 step:17892 [D loss: 0.239157, acc.: 55.47%] [G loss: 0.304266]\n",
      "epoch:19 step:17893 [D loss: 0.242574, acc.: 56.25%] [G loss: 0.306336]\n",
      "epoch:19 step:17894 [D loss: 0.236208, acc.: 55.47%] [G loss: 0.310328]\n",
      "epoch:19 step:17895 [D loss: 0.233905, acc.: 63.28%] [G loss: 0.302747]\n",
      "epoch:19 step:17896 [D loss: 0.234472, acc.: 61.72%] [G loss: 0.316627]\n",
      "epoch:19 step:17897 [D loss: 0.227739, acc.: 60.94%] [G loss: 0.329894]\n",
      "epoch:19 step:17898 [D loss: 0.242749, acc.: 60.16%] [G loss: 0.313340]\n",
      "epoch:19 step:17899 [D loss: 0.224482, acc.: 64.06%] [G loss: 0.319811]\n",
      "epoch:19 step:17900 [D loss: 0.240699, acc.: 59.38%] [G loss: 0.275810]\n",
      "epoch:19 step:17901 [D loss: 0.234430, acc.: 53.91%] [G loss: 0.301397]\n",
      "epoch:19 step:17902 [D loss: 0.246354, acc.: 56.25%] [G loss: 0.279986]\n",
      "epoch:19 step:17903 [D loss: 0.249836, acc.: 52.34%] [G loss: 0.320213]\n",
      "epoch:19 step:17904 [D loss: 0.236931, acc.: 64.84%] [G loss: 0.307211]\n",
      "epoch:19 step:17905 [D loss: 0.254980, acc.: 49.22%] [G loss: 0.297389]\n",
      "epoch:19 step:17906 [D loss: 0.226402, acc.: 59.38%] [G loss: 0.318442]\n",
      "epoch:19 step:17907 [D loss: 0.232711, acc.: 60.16%] [G loss: 0.312855]\n",
      "epoch:19 step:17908 [D loss: 0.232570, acc.: 61.72%] [G loss: 0.300110]\n",
      "epoch:19 step:17909 [D loss: 0.230822, acc.: 62.50%] [G loss: 0.302783]\n",
      "epoch:19 step:17910 [D loss: 0.223514, acc.: 67.19%] [G loss: 0.292232]\n",
      "epoch:19 step:17911 [D loss: 0.230360, acc.: 63.28%] [G loss: 0.320001]\n",
      "epoch:19 step:17912 [D loss: 0.229810, acc.: 60.16%] [G loss: 0.292247]\n",
      "epoch:19 step:17913 [D loss: 0.243766, acc.: 53.91%] [G loss: 0.301522]\n",
      "epoch:19 step:17914 [D loss: 0.242981, acc.: 62.50%] [G loss: 0.314511]\n",
      "epoch:19 step:17915 [D loss: 0.243441, acc.: 53.91%] [G loss: 0.303257]\n",
      "epoch:19 step:17916 [D loss: 0.238217, acc.: 60.94%] [G loss: 0.274264]\n",
      "epoch:19 step:17917 [D loss: 0.249193, acc.: 51.56%] [G loss: 0.287046]\n",
      "epoch:19 step:17918 [D loss: 0.229520, acc.: 62.50%] [G loss: 0.295700]\n",
      "epoch:19 step:17919 [D loss: 0.246564, acc.: 57.03%] [G loss: 0.287382]\n",
      "epoch:19 step:17920 [D loss: 0.226805, acc.: 60.16%] [G loss: 0.321479]\n",
      "epoch:19 step:17921 [D loss: 0.244617, acc.: 55.47%] [G loss: 0.296017]\n",
      "epoch:19 step:17922 [D loss: 0.248603, acc.: 57.81%] [G loss: 0.304483]\n",
      "epoch:19 step:17923 [D loss: 0.235751, acc.: 60.94%] [G loss: 0.307625]\n",
      "epoch:19 step:17924 [D loss: 0.228747, acc.: 61.72%] [G loss: 0.288514]\n",
      "epoch:19 step:17925 [D loss: 0.257602, acc.: 53.12%] [G loss: 0.292393]\n",
      "epoch:19 step:17926 [D loss: 0.223199, acc.: 59.38%] [G loss: 0.292117]\n",
      "epoch:19 step:17927 [D loss: 0.235041, acc.: 59.38%] [G loss: 0.288727]\n",
      "epoch:19 step:17928 [D loss: 0.236105, acc.: 59.38%] [G loss: 0.299460]\n",
      "epoch:19 step:17929 [D loss: 0.248746, acc.: 56.25%] [G loss: 0.291868]\n",
      "epoch:19 step:17930 [D loss: 0.227902, acc.: 60.94%] [G loss: 0.320736]\n",
      "epoch:19 step:17931 [D loss: 0.229802, acc.: 61.72%] [G loss: 0.290572]\n",
      "epoch:19 step:17932 [D loss: 0.255857, acc.: 53.12%] [G loss: 0.303177]\n",
      "epoch:19 step:17933 [D loss: 0.229847, acc.: 63.28%] [G loss: 0.311014]\n",
      "epoch:19 step:17934 [D loss: 0.223330, acc.: 64.06%] [G loss: 0.340240]\n",
      "epoch:19 step:17935 [D loss: 0.238275, acc.: 57.03%] [G loss: 0.284483]\n",
      "epoch:19 step:17936 [D loss: 0.225560, acc.: 59.38%] [G loss: 0.338413]\n",
      "epoch:19 step:17937 [D loss: 0.232158, acc.: 66.41%] [G loss: 0.293973]\n",
      "epoch:19 step:17938 [D loss: 0.238606, acc.: 57.03%] [G loss: 0.282808]\n",
      "epoch:19 step:17939 [D loss: 0.271268, acc.: 49.22%] [G loss: 0.275969]\n",
      "epoch:19 step:17940 [D loss: 0.239796, acc.: 57.81%] [G loss: 0.311137]\n",
      "epoch:19 step:17941 [D loss: 0.230349, acc.: 61.72%] [G loss: 0.312555]\n",
      "epoch:19 step:17942 [D loss: 0.248292, acc.: 53.91%] [G loss: 0.278533]\n",
      "epoch:19 step:17943 [D loss: 0.237328, acc.: 57.81%] [G loss: 0.273727]\n",
      "epoch:19 step:17944 [D loss: 0.245654, acc.: 55.47%] [G loss: 0.299594]\n",
      "epoch:19 step:17945 [D loss: 0.257144, acc.: 54.69%] [G loss: 0.272015]\n",
      "epoch:19 step:17946 [D loss: 0.226555, acc.: 59.38%] [G loss: 0.304166]\n",
      "epoch:19 step:17947 [D loss: 0.255881, acc.: 51.56%] [G loss: 0.302246]\n",
      "epoch:19 step:17948 [D loss: 0.229149, acc.: 66.41%] [G loss: 0.298077]\n",
      "epoch:19 step:17949 [D loss: 0.254884, acc.: 50.78%] [G loss: 0.308937]\n",
      "epoch:19 step:17950 [D loss: 0.257190, acc.: 54.69%] [G loss: 0.299931]\n",
      "epoch:19 step:17951 [D loss: 0.233465, acc.: 60.16%] [G loss: 0.316260]\n",
      "epoch:19 step:17952 [D loss: 0.231123, acc.: 62.50%] [G loss: 0.316614]\n",
      "epoch:19 step:17953 [D loss: 0.229705, acc.: 64.84%] [G loss: 0.307077]\n",
      "epoch:19 step:17954 [D loss: 0.235713, acc.: 62.50%] [G loss: 0.312477]\n",
      "epoch:19 step:17955 [D loss: 0.218672, acc.: 64.84%] [G loss: 0.323397]\n",
      "epoch:19 step:17956 [D loss: 0.243505, acc.: 52.34%] [G loss: 0.293461]\n",
      "epoch:19 step:17957 [D loss: 0.243463, acc.: 51.56%] [G loss: 0.300681]\n",
      "epoch:19 step:17958 [D loss: 0.253031, acc.: 53.91%] [G loss: 0.278247]\n",
      "epoch:19 step:17959 [D loss: 0.241241, acc.: 58.59%] [G loss: 0.295022]\n",
      "epoch:19 step:17960 [D loss: 0.229166, acc.: 59.38%] [G loss: 0.318306]\n",
      "epoch:19 step:17961 [D loss: 0.226226, acc.: 59.38%] [G loss: 0.303372]\n",
      "epoch:19 step:17962 [D loss: 0.248084, acc.: 50.78%] [G loss: 0.278416]\n",
      "epoch:19 step:17963 [D loss: 0.218595, acc.: 64.06%] [G loss: 0.333894]\n",
      "epoch:19 step:17964 [D loss: 0.251765, acc.: 55.47%] [G loss: 0.285806]\n",
      "epoch:19 step:17965 [D loss: 0.237085, acc.: 53.91%] [G loss: 0.306581]\n",
      "epoch:19 step:17966 [D loss: 0.240177, acc.: 57.81%] [G loss: 0.315820]\n",
      "epoch:19 step:17967 [D loss: 0.228423, acc.: 64.84%] [G loss: 0.292610]\n",
      "epoch:19 step:17968 [D loss: 0.240595, acc.: 53.12%] [G loss: 0.326334]\n",
      "epoch:19 step:17969 [D loss: 0.241561, acc.: 54.69%] [G loss: 0.306533]\n",
      "epoch:19 step:17970 [D loss: 0.233058, acc.: 60.94%] [G loss: 0.289384]\n",
      "epoch:19 step:17971 [D loss: 0.228521, acc.: 67.97%] [G loss: 0.294656]\n",
      "epoch:19 step:17972 [D loss: 0.233803, acc.: 59.38%] [G loss: 0.333877]\n",
      "epoch:19 step:17973 [D loss: 0.229844, acc.: 62.50%] [G loss: 0.293987]\n",
      "epoch:19 step:17974 [D loss: 0.235778, acc.: 55.47%] [G loss: 0.277479]\n",
      "epoch:19 step:17975 [D loss: 0.227470, acc.: 63.28%] [G loss: 0.301225]\n",
      "epoch:19 step:17976 [D loss: 0.241058, acc.: 61.72%] [G loss: 0.330557]\n",
      "epoch:19 step:17977 [D loss: 0.225498, acc.: 59.38%] [G loss: 0.346468]\n",
      "epoch:19 step:17978 [D loss: 0.231607, acc.: 60.16%] [G loss: 0.302074]\n",
      "epoch:19 step:17979 [D loss: 0.234599, acc.: 56.25%] [G loss: 0.323029]\n",
      "epoch:19 step:17980 [D loss: 0.248950, acc.: 55.47%] [G loss: 0.325115]\n",
      "epoch:19 step:17981 [D loss: 0.235262, acc.: 62.50%] [G loss: 0.294500]\n",
      "epoch:19 step:17982 [D loss: 0.254762, acc.: 52.34%] [G loss: 0.300069]\n",
      "epoch:19 step:17983 [D loss: 0.249528, acc.: 58.59%] [G loss: 0.300040]\n",
      "epoch:19 step:17984 [D loss: 0.225716, acc.: 60.94%] [G loss: 0.321926]\n",
      "epoch:19 step:17985 [D loss: 0.215086, acc.: 60.16%] [G loss: 0.306692]\n",
      "epoch:19 step:17986 [D loss: 0.237735, acc.: 60.16%] [G loss: 0.295215]\n",
      "epoch:19 step:17987 [D loss: 0.251206, acc.: 56.25%] [G loss: 0.284414]\n",
      "epoch:19 step:17988 [D loss: 0.236858, acc.: 57.81%] [G loss: 0.321842]\n",
      "epoch:19 step:17989 [D loss: 0.211401, acc.: 71.09%] [G loss: 0.316764]\n",
      "epoch:19 step:17990 [D loss: 0.224715, acc.: 66.41%] [G loss: 0.338890]\n",
      "epoch:19 step:17991 [D loss: 0.244036, acc.: 54.69%] [G loss: 0.311415]\n",
      "epoch:19 step:17992 [D loss: 0.246994, acc.: 58.59%] [G loss: 0.300190]\n",
      "epoch:19 step:17993 [D loss: 0.240113, acc.: 57.81%] [G loss: 0.267445]\n",
      "epoch:19 step:17994 [D loss: 0.235726, acc.: 62.50%] [G loss: 0.293174]\n",
      "epoch:19 step:17995 [D loss: 0.239279, acc.: 60.94%] [G loss: 0.301019]\n",
      "epoch:19 step:17996 [D loss: 0.249821, acc.: 56.25%] [G loss: 0.292935]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:19 step:17997 [D loss: 0.247957, acc.: 57.03%] [G loss: 0.301697]\n",
      "epoch:19 step:17998 [D loss: 0.228760, acc.: 65.62%] [G loss: 0.289189]\n",
      "epoch:19 step:17999 [D loss: 0.242572, acc.: 55.47%] [G loss: 0.302979]\n",
      "epoch:19 step:18000 [D loss: 0.241104, acc.: 58.59%] [G loss: 0.300485]\n",
      "epoch:19 step:18001 [D loss: 0.215604, acc.: 64.84%] [G loss: 0.298058]\n",
      "epoch:19 step:18002 [D loss: 0.228039, acc.: 62.50%] [G loss: 0.294818]\n",
      "epoch:19 step:18003 [D loss: 0.242754, acc.: 61.72%] [G loss: 0.288246]\n",
      "epoch:19 step:18004 [D loss: 0.209573, acc.: 71.88%] [G loss: 0.312167]\n",
      "epoch:19 step:18005 [D loss: 0.231195, acc.: 57.81%] [G loss: 0.326491]\n",
      "epoch:19 step:18006 [D loss: 0.242819, acc.: 57.03%] [G loss: 0.317710]\n",
      "epoch:19 step:18007 [D loss: 0.230197, acc.: 62.50%] [G loss: 0.309717]\n",
      "epoch:19 step:18008 [D loss: 0.238378, acc.: 59.38%] [G loss: 0.308365]\n",
      "epoch:19 step:18009 [D loss: 0.237283, acc.: 54.69%] [G loss: 0.302198]\n",
      "epoch:19 step:18010 [D loss: 0.238598, acc.: 55.47%] [G loss: 0.307766]\n",
      "epoch:19 step:18011 [D loss: 0.238230, acc.: 59.38%] [G loss: 0.301708]\n",
      "epoch:19 step:18012 [D loss: 0.237507, acc.: 63.28%] [G loss: 0.299026]\n",
      "epoch:19 step:18013 [D loss: 0.234247, acc.: 64.84%] [G loss: 0.326378]\n",
      "epoch:19 step:18014 [D loss: 0.248535, acc.: 55.47%] [G loss: 0.287739]\n",
      "epoch:19 step:18015 [D loss: 0.235871, acc.: 55.47%] [G loss: 0.316245]\n",
      "epoch:19 step:18016 [D loss: 0.250371, acc.: 61.72%] [G loss: 0.277856]\n",
      "epoch:19 step:18017 [D loss: 0.239001, acc.: 58.59%] [G loss: 0.279892]\n",
      "epoch:19 step:18018 [D loss: 0.235028, acc.: 56.25%] [G loss: 0.308877]\n",
      "epoch:19 step:18019 [D loss: 0.249115, acc.: 55.47%] [G loss: 0.288998]\n",
      "epoch:19 step:18020 [D loss: 0.236648, acc.: 62.50%] [G loss: 0.308783]\n",
      "epoch:19 step:18021 [D loss: 0.244962, acc.: 57.03%] [G loss: 0.299298]\n",
      "epoch:19 step:18022 [D loss: 0.248244, acc.: 57.81%] [G loss: 0.331772]\n",
      "epoch:19 step:18023 [D loss: 0.232875, acc.: 60.16%] [G loss: 0.306737]\n",
      "epoch:19 step:18024 [D loss: 0.259103, acc.: 52.34%] [G loss: 0.317941]\n",
      "epoch:19 step:18025 [D loss: 0.237889, acc.: 54.69%] [G loss: 0.295936]\n",
      "epoch:19 step:18026 [D loss: 0.223524, acc.: 63.28%] [G loss: 0.318658]\n",
      "epoch:19 step:18027 [D loss: 0.243332, acc.: 54.69%] [G loss: 0.312182]\n",
      "epoch:19 step:18028 [D loss: 0.219194, acc.: 61.72%] [G loss: 0.308586]\n",
      "epoch:19 step:18029 [D loss: 0.239345, acc.: 57.81%] [G loss: 0.318619]\n",
      "epoch:19 step:18030 [D loss: 0.233362, acc.: 57.03%] [G loss: 0.297340]\n",
      "epoch:19 step:18031 [D loss: 0.235178, acc.: 61.72%] [G loss: 0.303208]\n",
      "epoch:19 step:18032 [D loss: 0.220201, acc.: 61.72%] [G loss: 0.305390]\n",
      "epoch:19 step:18033 [D loss: 0.249050, acc.: 55.47%] [G loss: 0.295270]\n",
      "epoch:19 step:18034 [D loss: 0.250681, acc.: 56.25%] [G loss: 0.304360]\n",
      "epoch:19 step:18035 [D loss: 0.229734, acc.: 64.06%] [G loss: 0.287229]\n",
      "epoch:19 step:18036 [D loss: 0.243017, acc.: 57.03%] [G loss: 0.280642]\n",
      "epoch:19 step:18037 [D loss: 0.234982, acc.: 60.16%] [G loss: 0.328266]\n",
      "epoch:19 step:18038 [D loss: 0.234858, acc.: 57.81%] [G loss: 0.283712]\n",
      "epoch:19 step:18039 [D loss: 0.241054, acc.: 53.12%] [G loss: 0.307937]\n",
      "epoch:19 step:18040 [D loss: 0.229900, acc.: 61.72%] [G loss: 0.340121]\n",
      "epoch:19 step:18041 [D loss: 0.239488, acc.: 60.94%] [G loss: 0.285571]\n",
      "epoch:19 step:18042 [D loss: 0.236802, acc.: 58.59%] [G loss: 0.310240]\n",
      "epoch:19 step:18043 [D loss: 0.223528, acc.: 64.06%] [G loss: 0.305409]\n",
      "epoch:19 step:18044 [D loss: 0.242502, acc.: 54.69%] [G loss: 0.288030]\n",
      "epoch:19 step:18045 [D loss: 0.253824, acc.: 53.91%] [G loss: 0.287287]\n",
      "epoch:19 step:18046 [D loss: 0.240279, acc.: 57.03%] [G loss: 0.317250]\n",
      "epoch:19 step:18047 [D loss: 0.218568, acc.: 60.94%] [G loss: 0.315703]\n",
      "epoch:19 step:18048 [D loss: 0.237056, acc.: 60.94%] [G loss: 0.270824]\n",
      "epoch:19 step:18049 [D loss: 0.246434, acc.: 53.91%] [G loss: 0.307648]\n",
      "epoch:19 step:18050 [D loss: 0.239396, acc.: 50.00%] [G loss: 0.281732]\n",
      "epoch:19 step:18051 [D loss: 0.236872, acc.: 54.69%] [G loss: 0.284483]\n",
      "epoch:19 step:18052 [D loss: 0.231893, acc.: 63.28%] [G loss: 0.303154]\n",
      "epoch:19 step:18053 [D loss: 0.246187, acc.: 59.38%] [G loss: 0.302939]\n",
      "epoch:19 step:18054 [D loss: 0.253902, acc.: 50.78%] [G loss: 0.315084]\n",
      "epoch:19 step:18055 [D loss: 0.229169, acc.: 60.94%] [G loss: 0.309657]\n",
      "epoch:19 step:18056 [D loss: 0.229506, acc.: 62.50%] [G loss: 0.316073]\n",
      "epoch:19 step:18057 [D loss: 0.220668, acc.: 66.41%] [G loss: 0.305729]\n",
      "epoch:19 step:18058 [D loss: 0.255321, acc.: 53.91%] [G loss: 0.289061]\n",
      "epoch:19 step:18059 [D loss: 0.236453, acc.: 59.38%] [G loss: 0.304175]\n",
      "epoch:19 step:18060 [D loss: 0.226325, acc.: 60.94%] [G loss: 0.298570]\n",
      "epoch:19 step:18061 [D loss: 0.243230, acc.: 55.47%] [G loss: 0.305442]\n",
      "epoch:19 step:18062 [D loss: 0.239631, acc.: 57.81%] [G loss: 0.302922]\n",
      "epoch:19 step:18063 [D loss: 0.250290, acc.: 55.47%] [G loss: 0.306891]\n",
      "epoch:19 step:18064 [D loss: 0.238667, acc.: 56.25%] [G loss: 0.291307]\n",
      "epoch:19 step:18065 [D loss: 0.240070, acc.: 58.59%] [G loss: 0.304046]\n",
      "epoch:19 step:18066 [D loss: 0.239441, acc.: 53.12%] [G loss: 0.306770]\n",
      "epoch:19 step:18067 [D loss: 0.256232, acc.: 50.78%] [G loss: 0.291737]\n",
      "epoch:19 step:18068 [D loss: 0.249006, acc.: 61.72%] [G loss: 0.285093]\n",
      "epoch:19 step:18069 [D loss: 0.241292, acc.: 60.16%] [G loss: 0.311901]\n",
      "epoch:19 step:18070 [D loss: 0.224857, acc.: 63.28%] [G loss: 0.323925]\n",
      "epoch:19 step:18071 [D loss: 0.240532, acc.: 58.59%] [G loss: 0.321374]\n",
      "epoch:19 step:18072 [D loss: 0.253597, acc.: 48.44%] [G loss: 0.292200]\n",
      "epoch:19 step:18073 [D loss: 0.266575, acc.: 46.09%] [G loss: 0.292729]\n",
      "epoch:19 step:18074 [D loss: 0.235842, acc.: 56.25%] [G loss: 0.321671]\n",
      "epoch:19 step:18075 [D loss: 0.246407, acc.: 55.47%] [G loss: 0.309652]\n",
      "epoch:19 step:18076 [D loss: 0.246261, acc.: 58.59%] [G loss: 0.287206]\n",
      "epoch:19 step:18077 [D loss: 0.249264, acc.: 53.91%] [G loss: 0.294879]\n",
      "epoch:19 step:18078 [D loss: 0.249091, acc.: 53.91%] [G loss: 0.317344]\n",
      "epoch:19 step:18079 [D loss: 0.250561, acc.: 54.69%] [G loss: 0.296590]\n",
      "epoch:19 step:18080 [D loss: 0.238843, acc.: 59.38%] [G loss: 0.311732]\n",
      "epoch:19 step:18081 [D loss: 0.232381, acc.: 61.72%] [G loss: 0.295546]\n",
      "epoch:19 step:18082 [D loss: 0.242401, acc.: 57.03%] [G loss: 0.311491]\n",
      "epoch:19 step:18083 [D loss: 0.260086, acc.: 53.12%] [G loss: 0.294622]\n",
      "epoch:19 step:18084 [D loss: 0.232446, acc.: 57.81%] [G loss: 0.312607]\n",
      "epoch:19 step:18085 [D loss: 0.238891, acc.: 59.38%] [G loss: 0.322553]\n",
      "epoch:19 step:18086 [D loss: 0.212476, acc.: 64.84%] [G loss: 0.321741]\n",
      "epoch:19 step:18087 [D loss: 0.232615, acc.: 58.59%] [G loss: 0.297990]\n",
      "epoch:19 step:18088 [D loss: 0.225655, acc.: 61.72%] [G loss: 0.313174]\n",
      "epoch:19 step:18089 [D loss: 0.217870, acc.: 62.50%] [G loss: 0.293839]\n",
      "epoch:19 step:18090 [D loss: 0.224508, acc.: 66.41%] [G loss: 0.306703]\n",
      "epoch:19 step:18091 [D loss: 0.217682, acc.: 65.62%] [G loss: 0.280646]\n",
      "epoch:19 step:18092 [D loss: 0.255155, acc.: 53.12%] [G loss: 0.313549]\n",
      "epoch:19 step:18093 [D loss: 0.227422, acc.: 60.94%] [G loss: 0.332694]\n",
      "epoch:19 step:18094 [D loss: 0.250591, acc.: 52.34%] [G loss: 0.279783]\n",
      "epoch:19 step:18095 [D loss: 0.248542, acc.: 56.25%] [G loss: 0.284680]\n",
      "epoch:19 step:18096 [D loss: 0.241229, acc.: 63.28%] [G loss: 0.309336]\n",
      "epoch:19 step:18097 [D loss: 0.239604, acc.: 54.69%] [G loss: 0.289051]\n",
      "epoch:19 step:18098 [D loss: 0.224011, acc.: 60.94%] [G loss: 0.325949]\n",
      "epoch:19 step:18099 [D loss: 0.261727, acc.: 50.00%] [G loss: 0.272082]\n",
      "epoch:19 step:18100 [D loss: 0.224491, acc.: 60.16%] [G loss: 0.291549]\n",
      "epoch:19 step:18101 [D loss: 0.244252, acc.: 57.03%] [G loss: 0.309746]\n",
      "epoch:19 step:18102 [D loss: 0.245129, acc.: 60.16%] [G loss: 0.312238]\n",
      "epoch:19 step:18103 [D loss: 0.244791, acc.: 55.47%] [G loss: 0.304346]\n",
      "epoch:19 step:18104 [D loss: 0.241390, acc.: 54.69%] [G loss: 0.294491]\n",
      "epoch:19 step:18105 [D loss: 0.250023, acc.: 58.59%] [G loss: 0.270192]\n",
      "epoch:19 step:18106 [D loss: 0.242965, acc.: 55.47%] [G loss: 0.302088]\n",
      "epoch:19 step:18107 [D loss: 0.247697, acc.: 53.91%] [G loss: 0.284250]\n",
      "epoch:19 step:18108 [D loss: 0.245965, acc.: 55.47%] [G loss: 0.295320]\n",
      "epoch:19 step:18109 [D loss: 0.219849, acc.: 60.94%] [G loss: 0.310939]\n",
      "epoch:19 step:18110 [D loss: 0.242814, acc.: 56.25%] [G loss: 0.303574]\n",
      "epoch:19 step:18111 [D loss: 0.244937, acc.: 57.03%] [G loss: 0.296822]\n",
      "epoch:19 step:18112 [D loss: 0.241142, acc.: 60.94%] [G loss: 0.318784]\n",
      "epoch:19 step:18113 [D loss: 0.243326, acc.: 56.25%] [G loss: 0.321630]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:19 step:18114 [D loss: 0.237097, acc.: 57.03%] [G loss: 0.323428]\n",
      "epoch:19 step:18115 [D loss: 0.236647, acc.: 62.50%] [G loss: 0.292537]\n",
      "epoch:19 step:18116 [D loss: 0.245169, acc.: 60.16%] [G loss: 0.302682]\n",
      "epoch:19 step:18117 [D loss: 0.229496, acc.: 63.28%] [G loss: 0.311399]\n",
      "epoch:19 step:18118 [D loss: 0.249176, acc.: 57.03%] [G loss: 0.322527]\n",
      "epoch:19 step:18119 [D loss: 0.241674, acc.: 53.91%] [G loss: 0.299693]\n",
      "epoch:19 step:18120 [D loss: 0.230198, acc.: 64.84%] [G loss: 0.289943]\n",
      "epoch:19 step:18121 [D loss: 0.250671, acc.: 53.12%] [G loss: 0.283327]\n",
      "epoch:19 step:18122 [D loss: 0.245582, acc.: 57.03%] [G loss: 0.295775]\n",
      "epoch:19 step:18123 [D loss: 0.228319, acc.: 64.84%] [G loss: 0.288994]\n",
      "epoch:19 step:18124 [D loss: 0.216604, acc.: 68.75%] [G loss: 0.310715]\n",
      "epoch:19 step:18125 [D loss: 0.249151, acc.: 61.72%] [G loss: 0.307214]\n",
      "epoch:19 step:18126 [D loss: 0.254037, acc.: 52.34%] [G loss: 0.278603]\n",
      "epoch:19 step:18127 [D loss: 0.227756, acc.: 60.16%] [G loss: 0.298869]\n",
      "epoch:19 step:18128 [D loss: 0.230325, acc.: 60.94%] [G loss: 0.311665]\n",
      "epoch:19 step:18129 [D loss: 0.240448, acc.: 59.38%] [G loss: 0.287596]\n",
      "epoch:19 step:18130 [D loss: 0.260355, acc.: 50.78%] [G loss: 0.300617]\n",
      "epoch:19 step:18131 [D loss: 0.220727, acc.: 58.59%] [G loss: 0.321508]\n",
      "epoch:19 step:18132 [D loss: 0.235400, acc.: 64.84%] [G loss: 0.303238]\n",
      "epoch:19 step:18133 [D loss: 0.264903, acc.: 50.00%] [G loss: 0.275254]\n",
      "epoch:19 step:18134 [D loss: 0.230245, acc.: 57.03%] [G loss: 0.281797]\n",
      "epoch:19 step:18135 [D loss: 0.218974, acc.: 67.97%] [G loss: 0.333857]\n",
      "epoch:19 step:18136 [D loss: 0.255420, acc.: 52.34%] [G loss: 0.299278]\n",
      "epoch:19 step:18137 [D loss: 0.229467, acc.: 64.84%] [G loss: 0.331106]\n",
      "epoch:19 step:18138 [D loss: 0.251034, acc.: 53.12%] [G loss: 0.296559]\n",
      "epoch:19 step:18139 [D loss: 0.231367, acc.: 60.94%] [G loss: 0.279175]\n",
      "epoch:19 step:18140 [D loss: 0.240918, acc.: 60.16%] [G loss: 0.322477]\n",
      "epoch:19 step:18141 [D loss: 0.223193, acc.: 63.28%] [G loss: 0.308194]\n",
      "epoch:19 step:18142 [D loss: 0.238059, acc.: 60.94%] [G loss: 0.305709]\n",
      "epoch:19 step:18143 [D loss: 0.248107, acc.: 53.12%] [G loss: 0.308572]\n",
      "epoch:19 step:18144 [D loss: 0.250031, acc.: 58.59%] [G loss: 0.309951]\n",
      "epoch:19 step:18145 [D loss: 0.225620, acc.: 62.50%] [G loss: 0.310115]\n",
      "epoch:19 step:18146 [D loss: 0.225397, acc.: 65.62%] [G loss: 0.323121]\n",
      "epoch:19 step:18147 [D loss: 0.228480, acc.: 59.38%] [G loss: 0.297971]\n",
      "epoch:19 step:18148 [D loss: 0.226681, acc.: 63.28%] [G loss: 0.303650]\n",
      "epoch:19 step:18149 [D loss: 0.242509, acc.: 57.81%] [G loss: 0.288314]\n",
      "epoch:19 step:18150 [D loss: 0.238760, acc.: 59.38%] [G loss: 0.307359]\n",
      "epoch:19 step:18151 [D loss: 0.244194, acc.: 57.03%] [G loss: 0.275458]\n",
      "epoch:19 step:18152 [D loss: 0.235616, acc.: 58.59%] [G loss: 0.298858]\n",
      "epoch:19 step:18153 [D loss: 0.240080, acc.: 57.03%] [G loss: 0.307536]\n",
      "epoch:19 step:18154 [D loss: 0.230177, acc.: 59.38%] [G loss: 0.287896]\n",
      "epoch:19 step:18155 [D loss: 0.246637, acc.: 57.03%] [G loss: 0.286116]\n",
      "epoch:19 step:18156 [D loss: 0.240904, acc.: 58.59%] [G loss: 0.290139]\n",
      "epoch:19 step:18157 [D loss: 0.241464, acc.: 57.81%] [G loss: 0.304866]\n",
      "epoch:19 step:18158 [D loss: 0.233048, acc.: 57.81%] [G loss: 0.306842]\n",
      "epoch:19 step:18159 [D loss: 0.215601, acc.: 67.97%] [G loss: 0.303112]\n",
      "epoch:19 step:18160 [D loss: 0.263167, acc.: 49.22%] [G loss: 0.294908]\n",
      "epoch:19 step:18161 [D loss: 0.255468, acc.: 48.44%] [G loss: 0.280129]\n",
      "epoch:19 step:18162 [D loss: 0.224204, acc.: 64.84%] [G loss: 0.306236]\n",
      "epoch:19 step:18163 [D loss: 0.239395, acc.: 61.72%] [G loss: 0.295174]\n",
      "epoch:19 step:18164 [D loss: 0.213637, acc.: 69.53%] [G loss: 0.307314]\n",
      "epoch:19 step:18165 [D loss: 0.237532, acc.: 55.47%] [G loss: 0.298019]\n",
      "epoch:19 step:18166 [D loss: 0.233337, acc.: 65.62%] [G loss: 0.301627]\n",
      "epoch:19 step:18167 [D loss: 0.242928, acc.: 59.38%] [G loss: 0.302125]\n",
      "epoch:19 step:18168 [D loss: 0.242069, acc.: 59.38%] [G loss: 0.282838]\n",
      "epoch:19 step:18169 [D loss: 0.229293, acc.: 64.06%] [G loss: 0.309359]\n",
      "epoch:19 step:18170 [D loss: 0.254443, acc.: 54.69%] [G loss: 0.285717]\n",
      "epoch:19 step:18171 [D loss: 0.250497, acc.: 53.12%] [G loss: 0.310627]\n",
      "epoch:19 step:18172 [D loss: 0.241635, acc.: 53.91%] [G loss: 0.282729]\n",
      "epoch:19 step:18173 [D loss: 0.243284, acc.: 54.69%] [G loss: 0.312164]\n",
      "epoch:19 step:18174 [D loss: 0.220453, acc.: 65.62%] [G loss: 0.317964]\n",
      "epoch:19 step:18175 [D loss: 0.228268, acc.: 57.81%] [G loss: 0.323327]\n",
      "epoch:19 step:18176 [D loss: 0.247410, acc.: 58.59%] [G loss: 0.296658]\n",
      "epoch:19 step:18177 [D loss: 0.248397, acc.: 50.78%] [G loss: 0.314377]\n",
      "epoch:19 step:18178 [D loss: 0.249413, acc.: 53.91%] [G loss: 0.307969]\n",
      "epoch:19 step:18179 [D loss: 0.246170, acc.: 56.25%] [G loss: 0.305712]\n",
      "epoch:19 step:18180 [D loss: 0.223202, acc.: 60.94%] [G loss: 0.298530]\n",
      "epoch:19 step:18181 [D loss: 0.237962, acc.: 59.38%] [G loss: 0.304892]\n",
      "epoch:19 step:18182 [D loss: 0.242778, acc.: 57.03%] [G loss: 0.287803]\n",
      "epoch:19 step:18183 [D loss: 0.246799, acc.: 55.47%] [G loss: 0.309116]\n",
      "epoch:19 step:18184 [D loss: 0.260519, acc.: 49.22%] [G loss: 0.279171]\n",
      "epoch:19 step:18185 [D loss: 0.239493, acc.: 55.47%] [G loss: 0.288201]\n",
      "epoch:19 step:18186 [D loss: 0.243252, acc.: 55.47%] [G loss: 0.291919]\n",
      "epoch:19 step:18187 [D loss: 0.237990, acc.: 56.25%] [G loss: 0.313704]\n",
      "epoch:19 step:18188 [D loss: 0.240572, acc.: 58.59%] [G loss: 0.318919]\n",
      "epoch:19 step:18189 [D loss: 0.242972, acc.: 53.91%] [G loss: 0.293203]\n",
      "epoch:19 step:18190 [D loss: 0.224742, acc.: 64.84%] [G loss: 0.312145]\n",
      "epoch:19 step:18191 [D loss: 0.229760, acc.: 62.50%] [G loss: 0.314817]\n",
      "epoch:19 step:18192 [D loss: 0.234146, acc.: 60.94%] [G loss: 0.298035]\n",
      "epoch:19 step:18193 [D loss: 0.242109, acc.: 59.38%] [G loss: 0.304470]\n",
      "epoch:19 step:18194 [D loss: 0.232262, acc.: 64.06%] [G loss: 0.312786]\n",
      "epoch:19 step:18195 [D loss: 0.245659, acc.: 57.81%] [G loss: 0.310117]\n",
      "epoch:19 step:18196 [D loss: 0.233678, acc.: 63.28%] [G loss: 0.299025]\n",
      "epoch:19 step:18197 [D loss: 0.233653, acc.: 58.59%] [G loss: 0.312878]\n",
      "epoch:19 step:18198 [D loss: 0.238039, acc.: 63.28%] [G loss: 0.309552]\n",
      "epoch:19 step:18199 [D loss: 0.252702, acc.: 50.78%] [G loss: 0.301008]\n",
      "epoch:19 step:18200 [D loss: 0.226447, acc.: 61.72%] [G loss: 0.290516]\n",
      "epoch:19 step:18201 [D loss: 0.239112, acc.: 58.59%] [G loss: 0.304741]\n",
      "epoch:19 step:18202 [D loss: 0.240166, acc.: 60.94%] [G loss: 0.308160]\n",
      "epoch:19 step:18203 [D loss: 0.221239, acc.: 64.06%] [G loss: 0.286248]\n",
      "epoch:19 step:18204 [D loss: 0.220351, acc.: 65.62%] [G loss: 0.322310]\n",
      "epoch:19 step:18205 [D loss: 0.235301, acc.: 65.62%] [G loss: 0.279666]\n",
      "epoch:19 step:18206 [D loss: 0.257376, acc.: 51.56%] [G loss: 0.327739]\n",
      "epoch:19 step:18207 [D loss: 0.237627, acc.: 57.81%] [G loss: 0.280717]\n",
      "epoch:19 step:18208 [D loss: 0.232063, acc.: 60.16%] [G loss: 0.306635]\n",
      "epoch:19 step:18209 [D loss: 0.226246, acc.: 64.84%] [G loss: 0.297970]\n",
      "epoch:19 step:18210 [D loss: 0.227684, acc.: 65.62%] [G loss: 0.332533]\n",
      "epoch:19 step:18211 [D loss: 0.238456, acc.: 57.03%] [G loss: 0.303701]\n",
      "epoch:19 step:18212 [D loss: 0.250166, acc.: 53.91%] [G loss: 0.295712]\n",
      "epoch:19 step:18213 [D loss: 0.253794, acc.: 50.78%] [G loss: 0.302545]\n",
      "epoch:19 step:18214 [D loss: 0.233130, acc.: 57.81%] [G loss: 0.293182]\n",
      "epoch:19 step:18215 [D loss: 0.237347, acc.: 59.38%] [G loss: 0.310497]\n",
      "epoch:19 step:18216 [D loss: 0.253931, acc.: 56.25%] [G loss: 0.290802]\n",
      "epoch:19 step:18217 [D loss: 0.242827, acc.: 57.81%] [G loss: 0.306042]\n",
      "epoch:19 step:18218 [D loss: 0.234317, acc.: 64.84%] [G loss: 0.318584]\n",
      "epoch:19 step:18219 [D loss: 0.232340, acc.: 56.25%] [G loss: 0.285408]\n",
      "epoch:19 step:18220 [D loss: 0.259896, acc.: 47.66%] [G loss: 0.305044]\n",
      "epoch:19 step:18221 [D loss: 0.247193, acc.: 55.47%] [G loss: 0.314285]\n",
      "epoch:19 step:18222 [D loss: 0.231921, acc.: 59.38%] [G loss: 0.320820]\n",
      "epoch:19 step:18223 [D loss: 0.233733, acc.: 63.28%] [G loss: 0.292094]\n",
      "epoch:19 step:18224 [D loss: 0.237190, acc.: 55.47%] [G loss: 0.300155]\n",
      "epoch:19 step:18225 [D loss: 0.245331, acc.: 54.69%] [G loss: 0.304573]\n",
      "epoch:19 step:18226 [D loss: 0.229999, acc.: 57.03%] [G loss: 0.292939]\n",
      "epoch:19 step:18227 [D loss: 0.260426, acc.: 53.91%] [G loss: 0.283050]\n",
      "epoch:19 step:18228 [D loss: 0.241699, acc.: 53.91%] [G loss: 0.294955]\n",
      "epoch:19 step:18229 [D loss: 0.256191, acc.: 53.91%] [G loss: 0.289635]\n",
      "epoch:19 step:18230 [D loss: 0.245370, acc.: 57.03%] [G loss: 0.318830]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:19 step:18231 [D loss: 0.239030, acc.: 62.50%] [G loss: 0.324305]\n",
      "epoch:19 step:18232 [D loss: 0.244016, acc.: 53.91%] [G loss: 0.303901]\n",
      "epoch:19 step:18233 [D loss: 0.242326, acc.: 57.03%] [G loss: 0.265057]\n",
      "epoch:19 step:18234 [D loss: 0.239680, acc.: 57.03%] [G loss: 0.315466]\n",
      "epoch:19 step:18235 [D loss: 0.244197, acc.: 59.38%] [G loss: 0.276143]\n",
      "epoch:19 step:18236 [D loss: 0.241464, acc.: 60.94%] [G loss: 0.294483]\n",
      "epoch:19 step:18237 [D loss: 0.232341, acc.: 58.59%] [G loss: 0.265364]\n",
      "epoch:19 step:18238 [D loss: 0.254959, acc.: 52.34%] [G loss: 0.289424]\n",
      "epoch:19 step:18239 [D loss: 0.234591, acc.: 57.03%] [G loss: 0.307483]\n",
      "epoch:19 step:18240 [D loss: 0.226742, acc.: 63.28%] [G loss: 0.325978]\n",
      "epoch:19 step:18241 [D loss: 0.253684, acc.: 50.00%] [G loss: 0.285832]\n",
      "epoch:19 step:18242 [D loss: 0.245888, acc.: 50.78%] [G loss: 0.293150]\n",
      "epoch:19 step:18243 [D loss: 0.238633, acc.: 55.47%] [G loss: 0.291013]\n",
      "epoch:19 step:18244 [D loss: 0.243564, acc.: 62.50%] [G loss: 0.295032]\n",
      "epoch:19 step:18245 [D loss: 0.243926, acc.: 59.38%] [G loss: 0.291146]\n",
      "epoch:19 step:18246 [D loss: 0.237640, acc.: 57.81%] [G loss: 0.338661]\n",
      "epoch:19 step:18247 [D loss: 0.242169, acc.: 57.81%] [G loss: 0.293134]\n",
      "epoch:19 step:18248 [D loss: 0.225857, acc.: 63.28%] [G loss: 0.307819]\n",
      "epoch:19 step:18249 [D loss: 0.231210, acc.: 60.16%] [G loss: 0.323028]\n",
      "epoch:19 step:18250 [D loss: 0.223976, acc.: 64.84%] [G loss: 0.305485]\n",
      "epoch:19 step:18251 [D loss: 0.233642, acc.: 58.59%] [G loss: 0.298484]\n",
      "epoch:19 step:18252 [D loss: 0.256982, acc.: 55.47%] [G loss: 0.289045]\n",
      "epoch:19 step:18253 [D loss: 0.234045, acc.: 58.59%] [G loss: 0.266779]\n",
      "epoch:19 step:18254 [D loss: 0.234530, acc.: 58.59%] [G loss: 0.302752]\n",
      "epoch:19 step:18255 [D loss: 0.234604, acc.: 59.38%] [G loss: 0.300850]\n",
      "epoch:19 step:18256 [D loss: 0.229713, acc.: 60.16%] [G loss: 0.309599]\n",
      "epoch:19 step:18257 [D loss: 0.259204, acc.: 48.44%] [G loss: 0.297772]\n",
      "epoch:19 step:18258 [D loss: 0.224522, acc.: 64.06%] [G loss: 0.307678]\n",
      "epoch:19 step:18259 [D loss: 0.244277, acc.: 62.50%] [G loss: 0.302994]\n",
      "epoch:19 step:18260 [D loss: 0.229432, acc.: 63.28%] [G loss: 0.298269]\n",
      "epoch:19 step:18261 [D loss: 0.234455, acc.: 59.38%] [G loss: 0.276449]\n",
      "epoch:19 step:18262 [D loss: 0.240401, acc.: 56.25%] [G loss: 0.294014]\n",
      "epoch:19 step:18263 [D loss: 0.236883, acc.: 56.25%] [G loss: 0.295749]\n",
      "epoch:19 step:18264 [D loss: 0.248420, acc.: 54.69%] [G loss: 0.265808]\n",
      "epoch:19 step:18265 [D loss: 0.239024, acc.: 58.59%] [G loss: 0.271180]\n",
      "epoch:19 step:18266 [D loss: 0.231545, acc.: 61.72%] [G loss: 0.282129]\n",
      "epoch:19 step:18267 [D loss: 0.232355, acc.: 67.97%] [G loss: 0.324541]\n",
      "epoch:19 step:18268 [D loss: 0.234601, acc.: 63.28%] [G loss: 0.308267]\n",
      "epoch:19 step:18269 [D loss: 0.236746, acc.: 57.81%] [G loss: 0.284939]\n",
      "epoch:19 step:18270 [D loss: 0.243992, acc.: 61.72%] [G loss: 0.276431]\n",
      "epoch:19 step:18271 [D loss: 0.231526, acc.: 60.94%] [G loss: 0.291893]\n",
      "epoch:19 step:18272 [D loss: 0.259149, acc.: 48.44%] [G loss: 0.291898]\n",
      "epoch:19 step:18273 [D loss: 0.235706, acc.: 57.03%] [G loss: 0.290376]\n",
      "epoch:19 step:18274 [D loss: 0.239108, acc.: 57.81%] [G loss: 0.318941]\n",
      "epoch:19 step:18275 [D loss: 0.237444, acc.: 61.72%] [G loss: 0.317020]\n",
      "epoch:19 step:18276 [D loss: 0.217608, acc.: 68.75%] [G loss: 0.290161]\n",
      "epoch:19 step:18277 [D loss: 0.231750, acc.: 57.81%] [G loss: 0.307815]\n",
      "epoch:19 step:18278 [D loss: 0.246515, acc.: 57.03%] [G loss: 0.317474]\n",
      "epoch:19 step:18279 [D loss: 0.231204, acc.: 59.38%] [G loss: 0.283839]\n",
      "epoch:19 step:18280 [D loss: 0.240765, acc.: 59.38%] [G loss: 0.279478]\n",
      "epoch:19 step:18281 [D loss: 0.237244, acc.: 61.72%] [G loss: 0.301484]\n",
      "epoch:19 step:18282 [D loss: 0.231294, acc.: 57.81%] [G loss: 0.315108]\n",
      "epoch:19 step:18283 [D loss: 0.234262, acc.: 58.59%] [G loss: 0.295919]\n",
      "epoch:19 step:18284 [D loss: 0.242806, acc.: 57.81%] [G loss: 0.294377]\n",
      "epoch:19 step:18285 [D loss: 0.235796, acc.: 57.81%] [G loss: 0.315521]\n",
      "epoch:19 step:18286 [D loss: 0.224519, acc.: 63.28%] [G loss: 0.318445]\n",
      "epoch:19 step:18287 [D loss: 0.236418, acc.: 56.25%] [G loss: 0.271311]\n",
      "epoch:19 step:18288 [D loss: 0.235600, acc.: 58.59%] [G loss: 0.288358]\n",
      "epoch:19 step:18289 [D loss: 0.243806, acc.: 55.47%] [G loss: 0.303879]\n",
      "epoch:19 step:18290 [D loss: 0.214482, acc.: 68.75%] [G loss: 0.303110]\n",
      "epoch:19 step:18291 [D loss: 0.222090, acc.: 63.28%] [G loss: 0.319435]\n",
      "epoch:19 step:18292 [D loss: 0.219464, acc.: 67.97%] [G loss: 0.302007]\n",
      "epoch:19 step:18293 [D loss: 0.239013, acc.: 56.25%] [G loss: 0.301117]\n",
      "epoch:19 step:18294 [D loss: 0.224332, acc.: 66.41%] [G loss: 0.300446]\n",
      "epoch:19 step:18295 [D loss: 0.238391, acc.: 50.78%] [G loss: 0.285493]\n",
      "epoch:19 step:18296 [D loss: 0.225757, acc.: 61.72%] [G loss: 0.294689]\n",
      "epoch:19 step:18297 [D loss: 0.245774, acc.: 59.38%] [G loss: 0.339464]\n",
      "epoch:19 step:18298 [D loss: 0.246321, acc.: 52.34%] [G loss: 0.314428]\n",
      "epoch:19 step:18299 [D loss: 0.241737, acc.: 53.91%] [G loss: 0.333948]\n",
      "epoch:19 step:18300 [D loss: 0.253043, acc.: 53.12%] [G loss: 0.315840]\n",
      "epoch:19 step:18301 [D loss: 0.230394, acc.: 57.03%] [G loss: 0.305005]\n",
      "epoch:19 step:18302 [D loss: 0.250673, acc.: 50.00%] [G loss: 0.304973]\n",
      "epoch:19 step:18303 [D loss: 0.247153, acc.: 55.47%] [G loss: 0.298504]\n",
      "epoch:19 step:18304 [D loss: 0.239477, acc.: 59.38%] [G loss: 0.310936]\n",
      "epoch:19 step:18305 [D loss: 0.236860, acc.: 57.81%] [G loss: 0.307681]\n",
      "epoch:19 step:18306 [D loss: 0.237164, acc.: 58.59%] [G loss: 0.288350]\n",
      "epoch:19 step:18307 [D loss: 0.251003, acc.: 57.03%] [G loss: 0.281686]\n",
      "epoch:19 step:18308 [D loss: 0.242053, acc.: 58.59%] [G loss: 0.311367]\n",
      "epoch:19 step:18309 [D loss: 0.229321, acc.: 60.16%] [G loss: 0.308154]\n",
      "epoch:19 step:18310 [D loss: 0.232032, acc.: 60.16%] [G loss: 0.305510]\n",
      "epoch:19 step:18311 [D loss: 0.245407, acc.: 56.25%] [G loss: 0.286634]\n",
      "epoch:19 step:18312 [D loss: 0.252626, acc.: 51.56%] [G loss: 0.314409]\n",
      "epoch:19 step:18313 [D loss: 0.252666, acc.: 51.56%] [G loss: 0.279918]\n",
      "epoch:19 step:18314 [D loss: 0.240665, acc.: 64.84%] [G loss: 0.331352]\n",
      "epoch:19 step:18315 [D loss: 0.235013, acc.: 58.59%] [G loss: 0.320772]\n",
      "epoch:19 step:18316 [D loss: 0.238725, acc.: 57.03%] [G loss: 0.310586]\n",
      "epoch:19 step:18317 [D loss: 0.243079, acc.: 55.47%] [G loss: 0.309214]\n",
      "epoch:19 step:18318 [D loss: 0.244364, acc.: 47.66%] [G loss: 0.299828]\n",
      "epoch:19 step:18319 [D loss: 0.247207, acc.: 52.34%] [G loss: 0.303137]\n",
      "epoch:19 step:18320 [D loss: 0.237956, acc.: 64.84%] [G loss: 0.318413]\n",
      "epoch:19 step:18321 [D loss: 0.254797, acc.: 47.66%] [G loss: 0.306836]\n",
      "epoch:19 step:18322 [D loss: 0.239213, acc.: 54.69%] [G loss: 0.313133]\n",
      "epoch:19 step:18323 [D loss: 0.250877, acc.: 56.25%] [G loss: 0.273051]\n",
      "epoch:19 step:18324 [D loss: 0.239022, acc.: 62.50%] [G loss: 0.302453]\n",
      "epoch:19 step:18325 [D loss: 0.254605, acc.: 50.00%] [G loss: 0.292551]\n",
      "epoch:19 step:18326 [D loss: 0.239761, acc.: 56.25%] [G loss: 0.287147]\n",
      "epoch:19 step:18327 [D loss: 0.230688, acc.: 63.28%] [G loss: 0.281116]\n",
      "epoch:19 step:18328 [D loss: 0.243540, acc.: 53.91%] [G loss: 0.317876]\n",
      "epoch:19 step:18329 [D loss: 0.236773, acc.: 60.16%] [G loss: 0.300360]\n",
      "epoch:19 step:18330 [D loss: 0.247430, acc.: 50.00%] [G loss: 0.275383]\n",
      "epoch:19 step:18331 [D loss: 0.241649, acc.: 64.06%] [G loss: 0.276023]\n",
      "epoch:19 step:18332 [D loss: 0.242329, acc.: 56.25%] [G loss: 0.288764]\n",
      "epoch:19 step:18333 [D loss: 0.258998, acc.: 50.78%] [G loss: 0.298943]\n",
      "epoch:19 step:18334 [D loss: 0.233695, acc.: 60.94%] [G loss: 0.289324]\n",
      "epoch:19 step:18335 [D loss: 0.246083, acc.: 52.34%] [G loss: 0.295596]\n",
      "epoch:19 step:18336 [D loss: 0.246187, acc.: 57.81%] [G loss: 0.307036]\n",
      "epoch:19 step:18337 [D loss: 0.236876, acc.: 56.25%] [G loss: 0.318709]\n",
      "epoch:19 step:18338 [D loss: 0.222913, acc.: 64.06%] [G loss: 0.297765]\n",
      "epoch:19 step:18339 [D loss: 0.257271, acc.: 48.44%] [G loss: 0.305730]\n",
      "epoch:19 step:18340 [D loss: 0.243010, acc.: 56.25%] [G loss: 0.320769]\n",
      "epoch:19 step:18341 [D loss: 0.241347, acc.: 60.94%] [G loss: 0.295230]\n",
      "epoch:19 step:18342 [D loss: 0.247174, acc.: 53.12%] [G loss: 0.277332]\n",
      "epoch:19 step:18343 [D loss: 0.228131, acc.: 63.28%] [G loss: 0.312441]\n",
      "epoch:19 step:18344 [D loss: 0.222607, acc.: 64.84%] [G loss: 0.308589]\n",
      "epoch:19 step:18345 [D loss: 0.233365, acc.: 64.06%] [G loss: 0.293038]\n",
      "epoch:19 step:18346 [D loss: 0.233575, acc.: 57.81%] [G loss: 0.305852]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:19 step:18347 [D loss: 0.248536, acc.: 53.12%] [G loss: 0.311153]\n",
      "epoch:19 step:18348 [D loss: 0.235376, acc.: 57.03%] [G loss: 0.286583]\n",
      "epoch:19 step:18349 [D loss: 0.242946, acc.: 59.38%] [G loss: 0.301920]\n",
      "epoch:19 step:18350 [D loss: 0.245005, acc.: 57.81%] [G loss: 0.294744]\n",
      "epoch:19 step:18351 [D loss: 0.241201, acc.: 57.03%] [G loss: 0.290429]\n",
      "epoch:19 step:18352 [D loss: 0.235498, acc.: 60.16%] [G loss: 0.303854]\n",
      "epoch:19 step:18353 [D loss: 0.244021, acc.: 61.72%] [G loss: 0.305758]\n",
      "epoch:19 step:18354 [D loss: 0.240063, acc.: 59.38%] [G loss: 0.311294]\n",
      "epoch:19 step:18355 [D loss: 0.241915, acc.: 56.25%] [G loss: 0.311096]\n",
      "epoch:19 step:18356 [D loss: 0.233329, acc.: 58.59%] [G loss: 0.311931]\n",
      "epoch:19 step:18357 [D loss: 0.232427, acc.: 60.16%] [G loss: 0.312128]\n",
      "epoch:19 step:18358 [D loss: 0.230649, acc.: 58.59%] [G loss: 0.306362]\n",
      "epoch:19 step:18359 [D loss: 0.242809, acc.: 53.91%] [G loss: 0.294878]\n",
      "epoch:19 step:18360 [D loss: 0.232514, acc.: 65.62%] [G loss: 0.314530]\n",
      "epoch:19 step:18361 [D loss: 0.239362, acc.: 57.81%] [G loss: 0.314135]\n",
      "epoch:19 step:18362 [D loss: 0.237140, acc.: 57.03%] [G loss: 0.282590]\n",
      "epoch:19 step:18363 [D loss: 0.252171, acc.: 52.34%] [G loss: 0.260195]\n",
      "epoch:19 step:18364 [D loss: 0.237466, acc.: 57.03%] [G loss: 0.294684]\n",
      "epoch:19 step:18365 [D loss: 0.237816, acc.: 56.25%] [G loss: 0.304095]\n",
      "epoch:19 step:18366 [D loss: 0.242278, acc.: 60.94%] [G loss: 0.276412]\n",
      "epoch:19 step:18367 [D loss: 0.240765, acc.: 57.81%] [G loss: 0.279911]\n",
      "epoch:19 step:18368 [D loss: 0.236085, acc.: 64.84%] [G loss: 0.297798]\n",
      "epoch:19 step:18369 [D loss: 0.258067, acc.: 48.44%] [G loss: 0.268033]\n",
      "epoch:19 step:18370 [D loss: 0.235122, acc.: 56.25%] [G loss: 0.291214]\n",
      "epoch:19 step:18371 [D loss: 0.235844, acc.: 59.38%] [G loss: 0.288952]\n",
      "epoch:19 step:18372 [D loss: 0.236258, acc.: 54.69%] [G loss: 0.330634]\n",
      "epoch:19 step:18373 [D loss: 0.244574, acc.: 53.91%] [G loss: 0.318775]\n",
      "epoch:19 step:18374 [D loss: 0.218077, acc.: 67.19%] [G loss: 0.321917]\n",
      "epoch:19 step:18375 [D loss: 0.220372, acc.: 67.97%] [G loss: 0.288133]\n",
      "epoch:19 step:18376 [D loss: 0.250321, acc.: 59.38%] [G loss: 0.295235]\n",
      "epoch:19 step:18377 [D loss: 0.255081, acc.: 55.47%] [G loss: 0.305612]\n",
      "epoch:19 step:18378 [D loss: 0.253392, acc.: 54.69%] [G loss: 0.301516]\n",
      "epoch:19 step:18379 [D loss: 0.213334, acc.: 66.41%] [G loss: 0.329902]\n",
      "epoch:19 step:18380 [D loss: 0.237395, acc.: 60.94%] [G loss: 0.316214]\n",
      "epoch:19 step:18381 [D loss: 0.228490, acc.: 60.94%] [G loss: 0.313777]\n",
      "epoch:19 step:18382 [D loss: 0.236743, acc.: 55.47%] [G loss: 0.314514]\n",
      "epoch:19 step:18383 [D loss: 0.227150, acc.: 64.06%] [G loss: 0.290772]\n",
      "epoch:19 step:18384 [D loss: 0.243655, acc.: 60.16%] [G loss: 0.313708]\n",
      "epoch:19 step:18385 [D loss: 0.254991, acc.: 54.69%] [G loss: 0.282604]\n",
      "epoch:19 step:18386 [D loss: 0.224901, acc.: 58.59%] [G loss: 0.349412]\n",
      "epoch:19 step:18387 [D loss: 0.252447, acc.: 53.91%] [G loss: 0.279351]\n",
      "epoch:19 step:18388 [D loss: 0.256562, acc.: 50.78%] [G loss: 0.310310]\n",
      "epoch:19 step:18389 [D loss: 0.225995, acc.: 64.84%] [G loss: 0.292351]\n",
      "epoch:19 step:18390 [D loss: 0.239374, acc.: 60.16%] [G loss: 0.322773]\n",
      "epoch:19 step:18391 [D loss: 0.224990, acc.: 65.62%] [G loss: 0.297652]\n",
      "epoch:19 step:18392 [D loss: 0.246284, acc.: 53.12%] [G loss: 0.300831]\n",
      "epoch:19 step:18393 [D loss: 0.228825, acc.: 60.94%] [G loss: 0.301706]\n",
      "epoch:19 step:18394 [D loss: 0.247527, acc.: 60.16%] [G loss: 0.299247]\n",
      "epoch:19 step:18395 [D loss: 0.237142, acc.: 56.25%] [G loss: 0.294750]\n",
      "epoch:19 step:18396 [D loss: 0.238089, acc.: 55.47%] [G loss: 0.277610]\n",
      "epoch:19 step:18397 [D loss: 0.224968, acc.: 64.06%] [G loss: 0.325160]\n",
      "epoch:19 step:18398 [D loss: 0.241635, acc.: 55.47%] [G loss: 0.282138]\n",
      "epoch:19 step:18399 [D loss: 0.234318, acc.: 57.81%] [G loss: 0.310687]\n",
      "epoch:19 step:18400 [D loss: 0.241277, acc.: 57.81%] [G loss: 0.311118]\n",
      "epoch:19 step:18401 [D loss: 0.219652, acc.: 64.06%] [G loss: 0.310328]\n",
      "epoch:19 step:18402 [D loss: 0.217544, acc.: 65.62%] [G loss: 0.265199]\n",
      "epoch:19 step:18403 [D loss: 0.236163, acc.: 53.91%] [G loss: 0.308111]\n",
      "epoch:19 step:18404 [D loss: 0.237096, acc.: 60.94%] [G loss: 0.289568]\n",
      "epoch:19 step:18405 [D loss: 0.222812, acc.: 63.28%] [G loss: 0.305122]\n",
      "epoch:19 step:18406 [D loss: 0.238432, acc.: 57.03%] [G loss: 0.321324]\n",
      "epoch:19 step:18407 [D loss: 0.225522, acc.: 64.84%] [G loss: 0.285199]\n",
      "epoch:19 step:18408 [D loss: 0.248765, acc.: 53.91%] [G loss: 0.322702]\n",
      "epoch:19 step:18409 [D loss: 0.255077, acc.: 52.34%] [G loss: 0.272402]\n",
      "epoch:19 step:18410 [D loss: 0.230925, acc.: 60.16%] [G loss: 0.309833]\n",
      "epoch:19 step:18411 [D loss: 0.236103, acc.: 63.28%] [G loss: 0.305202]\n",
      "epoch:19 step:18412 [D loss: 0.226969, acc.: 64.84%] [G loss: 0.279511]\n",
      "epoch:19 step:18413 [D loss: 0.218767, acc.: 62.50%] [G loss: 0.316440]\n",
      "epoch:19 step:18414 [D loss: 0.224714, acc.: 65.62%] [G loss: 0.275963]\n",
      "epoch:19 step:18415 [D loss: 0.259505, acc.: 55.47%] [G loss: 0.285417]\n",
      "epoch:19 step:18416 [D loss: 0.227995, acc.: 62.50%] [G loss: 0.299728]\n",
      "epoch:19 step:18417 [D loss: 0.268423, acc.: 49.22%] [G loss: 0.298235]\n",
      "epoch:19 step:18418 [D loss: 0.231369, acc.: 63.28%] [G loss: 0.290084]\n",
      "epoch:19 step:18419 [D loss: 0.249275, acc.: 53.12%] [G loss: 0.278190]\n",
      "epoch:19 step:18420 [D loss: 0.243596, acc.: 53.12%] [G loss: 0.295941]\n",
      "epoch:19 step:18421 [D loss: 0.246541, acc.: 53.12%] [G loss: 0.292742]\n",
      "epoch:19 step:18422 [D loss: 0.244995, acc.: 60.16%] [G loss: 0.305853]\n",
      "epoch:19 step:18423 [D loss: 0.245561, acc.: 53.91%] [G loss: 0.286494]\n",
      "epoch:19 step:18424 [D loss: 0.244396, acc.: 62.50%] [G loss: 0.308606]\n",
      "epoch:19 step:18425 [D loss: 0.245738, acc.: 59.38%] [G loss: 0.307895]\n",
      "epoch:19 step:18426 [D loss: 0.217697, acc.: 63.28%] [G loss: 0.321417]\n",
      "epoch:19 step:18427 [D loss: 0.235065, acc.: 57.03%] [G loss: 0.285163]\n",
      "epoch:19 step:18428 [D loss: 0.241142, acc.: 54.69%] [G loss: 0.286939]\n",
      "epoch:19 step:18429 [D loss: 0.223715, acc.: 63.28%] [G loss: 0.305535]\n",
      "epoch:19 step:18430 [D loss: 0.233418, acc.: 55.47%] [G loss: 0.326136]\n",
      "epoch:19 step:18431 [D loss: 0.238487, acc.: 60.16%] [G loss: 0.323159]\n",
      "epoch:19 step:18432 [D loss: 0.237951, acc.: 56.25%] [G loss: 0.313334]\n",
      "epoch:19 step:18433 [D loss: 0.236991, acc.: 57.81%] [G loss: 0.300704]\n",
      "epoch:19 step:18434 [D loss: 0.243257, acc.: 53.91%] [G loss: 0.304195]\n",
      "epoch:19 step:18435 [D loss: 0.240292, acc.: 61.72%] [G loss: 0.287109]\n",
      "epoch:19 step:18436 [D loss: 0.228390, acc.: 64.06%] [G loss: 0.303645]\n",
      "epoch:19 step:18437 [D loss: 0.256041, acc.: 51.56%] [G loss: 0.289393]\n",
      "epoch:19 step:18438 [D loss: 0.246409, acc.: 56.25%] [G loss: 0.274893]\n",
      "epoch:19 step:18439 [D loss: 0.233934, acc.: 58.59%] [G loss: 0.292350]\n",
      "epoch:19 step:18440 [D loss: 0.237021, acc.: 59.38%] [G loss: 0.315503]\n",
      "epoch:19 step:18441 [D loss: 0.243574, acc.: 57.03%] [G loss: 0.301281]\n",
      "epoch:19 step:18442 [D loss: 0.250643, acc.: 52.34%] [G loss: 0.290463]\n",
      "epoch:19 step:18443 [D loss: 0.234382, acc.: 59.38%] [G loss: 0.277901]\n",
      "epoch:19 step:18444 [D loss: 0.247280, acc.: 54.69%] [G loss: 0.304948]\n",
      "epoch:19 step:18445 [D loss: 0.251696, acc.: 50.00%] [G loss: 0.289380]\n",
      "epoch:19 step:18446 [D loss: 0.234235, acc.: 60.16%] [G loss: 0.318106]\n",
      "epoch:19 step:18447 [D loss: 0.241879, acc.: 57.81%] [G loss: 0.291608]\n",
      "epoch:19 step:18448 [D loss: 0.237715, acc.: 58.59%] [G loss: 0.285342]\n",
      "epoch:19 step:18449 [D loss: 0.256532, acc.: 50.00%] [G loss: 0.281482]\n",
      "epoch:19 step:18450 [D loss: 0.241056, acc.: 55.47%] [G loss: 0.304996]\n",
      "epoch:19 step:18451 [D loss: 0.237076, acc.: 55.47%] [G loss: 0.276168]\n",
      "epoch:19 step:18452 [D loss: 0.233904, acc.: 58.59%] [G loss: 0.297685]\n",
      "epoch:19 step:18453 [D loss: 0.239889, acc.: 60.94%] [G loss: 0.320648]\n",
      "epoch:19 step:18454 [D loss: 0.230106, acc.: 60.16%] [G loss: 0.325439]\n",
      "epoch:19 step:18455 [D loss: 0.230363, acc.: 61.72%] [G loss: 0.298087]\n",
      "epoch:19 step:18456 [D loss: 0.237794, acc.: 59.38%] [G loss: 0.290377]\n",
      "epoch:19 step:18457 [D loss: 0.233526, acc.: 60.16%] [G loss: 0.305792]\n",
      "epoch:19 step:18458 [D loss: 0.232268, acc.: 61.72%] [G loss: 0.313617]\n",
      "epoch:19 step:18459 [D loss: 0.248084, acc.: 56.25%] [G loss: 0.319874]\n",
      "epoch:19 step:18460 [D loss: 0.252531, acc.: 52.34%] [G loss: 0.276446]\n",
      "epoch:19 step:18461 [D loss: 0.260307, acc.: 49.22%] [G loss: 0.301264]\n",
      "epoch:19 step:18462 [D loss: 0.256537, acc.: 51.56%] [G loss: 0.286638]\n",
      "epoch:19 step:18463 [D loss: 0.251350, acc.: 57.03%] [G loss: 0.286734]\n",
      "epoch:19 step:18464 [D loss: 0.226296, acc.: 65.62%] [G loss: 0.292137]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:19 step:18465 [D loss: 0.237288, acc.: 57.81%] [G loss: 0.307007]\n",
      "epoch:19 step:18466 [D loss: 0.237053, acc.: 59.38%] [G loss: 0.299684]\n",
      "epoch:19 step:18467 [D loss: 0.223776, acc.: 65.62%] [G loss: 0.312853]\n",
      "epoch:19 step:18468 [D loss: 0.235658, acc.: 56.25%] [G loss: 0.294770]\n",
      "epoch:19 step:18469 [D loss: 0.237479, acc.: 57.81%] [G loss: 0.276541]\n",
      "epoch:19 step:18470 [D loss: 0.254085, acc.: 54.69%] [G loss: 0.279035]\n",
      "epoch:19 step:18471 [D loss: 0.226476, acc.: 66.41%] [G loss: 0.305995]\n",
      "epoch:19 step:18472 [D loss: 0.236660, acc.: 60.16%] [G loss: 0.305433]\n",
      "epoch:19 step:18473 [D loss: 0.230795, acc.: 61.72%] [G loss: 0.315961]\n",
      "epoch:19 step:18474 [D loss: 0.253056, acc.: 56.25%] [G loss: 0.293839]\n",
      "epoch:19 step:18475 [D loss: 0.223395, acc.: 60.16%] [G loss: 0.306125]\n",
      "epoch:19 step:18476 [D loss: 0.256575, acc.: 53.91%] [G loss: 0.295263]\n",
      "epoch:19 step:18477 [D loss: 0.247047, acc.: 50.00%] [G loss: 0.311373]\n",
      "epoch:19 step:18478 [D loss: 0.240800, acc.: 59.38%] [G loss: 0.280799]\n",
      "epoch:19 step:18479 [D loss: 0.225623, acc.: 62.50%] [G loss: 0.303156]\n",
      "epoch:19 step:18480 [D loss: 0.248475, acc.: 56.25%] [G loss: 0.345826]\n",
      "epoch:19 step:18481 [D loss: 0.233929, acc.: 58.59%] [G loss: 0.311742]\n",
      "epoch:19 step:18482 [D loss: 0.238124, acc.: 59.38%] [G loss: 0.298045]\n",
      "epoch:19 step:18483 [D loss: 0.253183, acc.: 51.56%] [G loss: 0.315919]\n",
      "epoch:19 step:18484 [D loss: 0.238571, acc.: 61.72%] [G loss: 0.325730]\n",
      "epoch:19 step:18485 [D loss: 0.227995, acc.: 63.28%] [G loss: 0.310312]\n",
      "epoch:19 step:18486 [D loss: 0.256134, acc.: 48.44%] [G loss: 0.295713]\n",
      "epoch:19 step:18487 [D loss: 0.227517, acc.: 62.50%] [G loss: 0.305128]\n",
      "epoch:19 step:18488 [D loss: 0.242508, acc.: 59.38%] [G loss: 0.293729]\n",
      "epoch:19 step:18489 [D loss: 0.225922, acc.: 64.06%] [G loss: 0.295643]\n",
      "epoch:19 step:18490 [D loss: 0.240286, acc.: 61.72%] [G loss: 0.287524]\n",
      "epoch:19 step:18491 [D loss: 0.244172, acc.: 51.56%] [G loss: 0.294103]\n",
      "epoch:19 step:18492 [D loss: 0.256459, acc.: 49.22%] [G loss: 0.291245]\n",
      "epoch:19 step:18493 [D loss: 0.256151, acc.: 58.59%] [G loss: 0.314307]\n",
      "epoch:19 step:18494 [D loss: 0.222616, acc.: 64.84%] [G loss: 0.322939]\n",
      "epoch:19 step:18495 [D loss: 0.244620, acc.: 60.94%] [G loss: 0.296874]\n",
      "epoch:19 step:18496 [D loss: 0.255337, acc.: 51.56%] [G loss: 0.313758]\n",
      "epoch:19 step:18497 [D loss: 0.238303, acc.: 62.50%] [G loss: 0.301169]\n",
      "epoch:19 step:18498 [D loss: 0.228303, acc.: 63.28%] [G loss: 0.310831]\n",
      "epoch:19 step:18499 [D loss: 0.235933, acc.: 59.38%] [G loss: 0.302408]\n",
      "epoch:19 step:18500 [D loss: 0.242772, acc.: 60.94%] [G loss: 0.327019]\n",
      "epoch:19 step:18501 [D loss: 0.243107, acc.: 54.69%] [G loss: 0.307757]\n",
      "epoch:19 step:18502 [D loss: 0.233416, acc.: 61.72%] [G loss: 0.313413]\n",
      "epoch:19 step:18503 [D loss: 0.232763, acc.: 60.16%] [G loss: 0.312527]\n",
      "epoch:19 step:18504 [D loss: 0.240390, acc.: 60.94%] [G loss: 0.293677]\n",
      "epoch:19 step:18505 [D loss: 0.240487, acc.: 61.72%] [G loss: 0.303765]\n",
      "epoch:19 step:18506 [D loss: 0.228272, acc.: 66.41%] [G loss: 0.285823]\n",
      "epoch:19 step:18507 [D loss: 0.239554, acc.: 55.47%] [G loss: 0.302225]\n",
      "epoch:19 step:18508 [D loss: 0.250370, acc.: 53.91%] [G loss: 0.328922]\n",
      "epoch:19 step:18509 [D loss: 0.245058, acc.: 57.81%] [G loss: 0.302330]\n",
      "epoch:19 step:18510 [D loss: 0.231928, acc.: 58.59%] [G loss: 0.332173]\n",
      "epoch:19 step:18511 [D loss: 0.230266, acc.: 61.72%] [G loss: 0.317008]\n",
      "epoch:19 step:18512 [D loss: 0.235027, acc.: 57.03%] [G loss: 0.288259]\n",
      "epoch:19 step:18513 [D loss: 0.220533, acc.: 61.72%] [G loss: 0.326629]\n",
      "epoch:19 step:18514 [D loss: 0.244992, acc.: 58.59%] [G loss: 0.296590]\n",
      "epoch:19 step:18515 [D loss: 0.233323, acc.: 60.16%] [G loss: 0.292603]\n",
      "epoch:19 step:18516 [D loss: 0.229205, acc.: 63.28%] [G loss: 0.286139]\n",
      "epoch:19 step:18517 [D loss: 0.250046, acc.: 52.34%] [G loss: 0.322539]\n",
      "epoch:19 step:18518 [D loss: 0.269475, acc.: 45.31%] [G loss: 0.305819]\n",
      "epoch:19 step:18519 [D loss: 0.248185, acc.: 52.34%] [G loss: 0.290339]\n",
      "epoch:19 step:18520 [D loss: 0.244088, acc.: 54.69%] [G loss: 0.333389]\n",
      "epoch:19 step:18521 [D loss: 0.226032, acc.: 63.28%] [G loss: 0.292493]\n",
      "epoch:19 step:18522 [D loss: 0.250010, acc.: 51.56%] [G loss: 0.288073]\n",
      "epoch:19 step:18523 [D loss: 0.253843, acc.: 57.81%] [G loss: 0.321815]\n",
      "epoch:19 step:18524 [D loss: 0.232017, acc.: 65.62%] [G loss: 0.310596]\n",
      "epoch:19 step:18525 [D loss: 0.238501, acc.: 60.16%] [G loss: 0.310854]\n",
      "epoch:19 step:18526 [D loss: 0.256761, acc.: 50.78%] [G loss: 0.303915]\n",
      "epoch:19 step:18527 [D loss: 0.242919, acc.: 60.16%] [G loss: 0.343615]\n",
      "epoch:19 step:18528 [D loss: 0.217736, acc.: 66.41%] [G loss: 0.328326]\n",
      "epoch:19 step:18529 [D loss: 0.247613, acc.: 54.69%] [G loss: 0.300102]\n",
      "epoch:19 step:18530 [D loss: 0.235127, acc.: 60.16%] [G loss: 0.341698]\n",
      "epoch:19 step:18531 [D loss: 0.241375, acc.: 59.38%] [G loss: 0.288536]\n",
      "epoch:19 step:18532 [D loss: 0.246524, acc.: 58.59%] [G loss: 0.298501]\n",
      "epoch:19 step:18533 [D loss: 0.246081, acc.: 60.16%] [G loss: 0.293780]\n",
      "epoch:19 step:18534 [D loss: 0.240719, acc.: 56.25%] [G loss: 0.300700]\n",
      "epoch:19 step:18535 [D loss: 0.241756, acc.: 60.94%] [G loss: 0.293561]\n",
      "epoch:19 step:18536 [D loss: 0.222639, acc.: 64.06%] [G loss: 0.299327]\n",
      "epoch:19 step:18537 [D loss: 0.248277, acc.: 55.47%] [G loss: 0.308673]\n",
      "epoch:19 step:18538 [D loss: 0.238147, acc.: 60.16%] [G loss: 0.315636]\n",
      "epoch:19 step:18539 [D loss: 0.234029, acc.: 59.38%] [G loss: 0.307834]\n",
      "epoch:19 step:18540 [D loss: 0.227136, acc.: 61.72%] [G loss: 0.303252]\n",
      "epoch:19 step:18541 [D loss: 0.253799, acc.: 57.03%] [G loss: 0.337783]\n",
      "epoch:19 step:18542 [D loss: 0.263405, acc.: 49.22%] [G loss: 0.316720]\n",
      "epoch:19 step:18543 [D loss: 0.237072, acc.: 59.38%] [G loss: 0.328912]\n",
      "epoch:19 step:18544 [D loss: 0.231386, acc.: 58.59%] [G loss: 0.281412]\n",
      "epoch:19 step:18545 [D loss: 0.235367, acc.: 64.84%] [G loss: 0.297161]\n",
      "epoch:19 step:18546 [D loss: 0.237503, acc.: 58.59%] [G loss: 0.318108]\n",
      "epoch:19 step:18547 [D loss: 0.227513, acc.: 58.59%] [G loss: 0.314903]\n",
      "epoch:19 step:18548 [D loss: 0.241094, acc.: 55.47%] [G loss: 0.313457]\n",
      "epoch:19 step:18549 [D loss: 0.224459, acc.: 63.28%] [G loss: 0.340107]\n",
      "epoch:19 step:18550 [D loss: 0.220296, acc.: 66.41%] [G loss: 0.324081]\n",
      "epoch:19 step:18551 [D loss: 0.229226, acc.: 62.50%] [G loss: 0.315742]\n",
      "epoch:19 step:18552 [D loss: 0.245129, acc.: 52.34%] [G loss: 0.304819]\n",
      "epoch:19 step:18553 [D loss: 0.234696, acc.: 59.38%] [G loss: 0.288582]\n",
      "epoch:19 step:18554 [D loss: 0.230178, acc.: 60.16%] [G loss: 0.312360]\n",
      "epoch:19 step:18555 [D loss: 0.239663, acc.: 58.59%] [G loss: 0.303354]\n",
      "epoch:19 step:18556 [D loss: 0.237242, acc.: 57.03%] [G loss: 0.305979]\n",
      "epoch:19 step:18557 [D loss: 0.212862, acc.: 66.41%] [G loss: 0.334294]\n",
      "epoch:19 step:18558 [D loss: 0.239576, acc.: 57.81%] [G loss: 0.316673]\n",
      "epoch:19 step:18559 [D loss: 0.238508, acc.: 52.34%] [G loss: 0.290554]\n",
      "epoch:19 step:18560 [D loss: 0.234290, acc.: 63.28%] [G loss: 0.294231]\n",
      "epoch:19 step:18561 [D loss: 0.238908, acc.: 60.16%] [G loss: 0.313105]\n",
      "epoch:19 step:18562 [D loss: 0.237265, acc.: 59.38%] [G loss: 0.319311]\n",
      "epoch:19 step:18563 [D loss: 0.224770, acc.: 57.03%] [G loss: 0.273983]\n",
      "epoch:19 step:18564 [D loss: 0.244474, acc.: 53.12%] [G loss: 0.297129]\n",
      "epoch:19 step:18565 [D loss: 0.238222, acc.: 61.72%] [G loss: 0.309019]\n",
      "epoch:19 step:18566 [D loss: 0.243063, acc.: 55.47%] [G loss: 0.290172]\n",
      "epoch:19 step:18567 [D loss: 0.229948, acc.: 59.38%] [G loss: 0.296514]\n",
      "epoch:19 step:18568 [D loss: 0.235874, acc.: 57.03%] [G loss: 0.294206]\n",
      "epoch:19 step:18569 [D loss: 0.239249, acc.: 54.69%] [G loss: 0.299743]\n",
      "epoch:19 step:18570 [D loss: 0.234708, acc.: 57.81%] [G loss: 0.296508]\n",
      "epoch:19 step:18571 [D loss: 0.238651, acc.: 58.59%] [G loss: 0.316079]\n",
      "epoch:19 step:18572 [D loss: 0.243648, acc.: 58.59%] [G loss: 0.304469]\n",
      "epoch:19 step:18573 [D loss: 0.229757, acc.: 61.72%] [G loss: 0.313463]\n",
      "epoch:19 step:18574 [D loss: 0.223764, acc.: 65.62%] [G loss: 0.319155]\n",
      "epoch:19 step:18575 [D loss: 0.231182, acc.: 58.59%] [G loss: 0.308753]\n",
      "epoch:19 step:18576 [D loss: 0.267312, acc.: 54.69%] [G loss: 0.292063]\n",
      "epoch:19 step:18577 [D loss: 0.230690, acc.: 64.84%] [G loss: 0.286462]\n",
      "epoch:19 step:18578 [D loss: 0.237334, acc.: 59.38%] [G loss: 0.303183]\n",
      "epoch:19 step:18579 [D loss: 0.229322, acc.: 62.50%] [G loss: 0.295670]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:19 step:18580 [D loss: 0.229973, acc.: 60.94%] [G loss: 0.305608]\n",
      "epoch:19 step:18581 [D loss: 0.219402, acc.: 67.97%] [G loss: 0.328842]\n",
      "epoch:19 step:18582 [D loss: 0.249459, acc.: 58.59%] [G loss: 0.287359]\n",
      "epoch:19 step:18583 [D loss: 0.225700, acc.: 63.28%] [G loss: 0.301315]\n",
      "epoch:19 step:18584 [D loss: 0.232041, acc.: 59.38%] [G loss: 0.281082]\n",
      "epoch:19 step:18585 [D loss: 0.238798, acc.: 57.81%] [G loss: 0.275125]\n",
      "epoch:19 step:18586 [D loss: 0.249532, acc.: 57.81%] [G loss: 0.261462]\n",
      "epoch:19 step:18587 [D loss: 0.235289, acc.: 60.16%] [G loss: 0.294730]\n",
      "epoch:19 step:18588 [D loss: 0.248054, acc.: 55.47%] [G loss: 0.319453]\n",
      "epoch:19 step:18589 [D loss: 0.250151, acc.: 56.25%] [G loss: 0.285858]\n",
      "epoch:19 step:18590 [D loss: 0.225777, acc.: 65.62%] [G loss: 0.275776]\n",
      "epoch:19 step:18591 [D loss: 0.241917, acc.: 57.03%] [G loss: 0.292201]\n",
      "epoch:19 step:18592 [D loss: 0.232720, acc.: 59.38%] [G loss: 0.295002]\n",
      "epoch:19 step:18593 [D loss: 0.239506, acc.: 60.16%] [G loss: 0.298794]\n",
      "epoch:19 step:18594 [D loss: 0.269510, acc.: 47.66%] [G loss: 0.280772]\n",
      "epoch:19 step:18595 [D loss: 0.218274, acc.: 71.09%] [G loss: 0.319237]\n",
      "epoch:19 step:18596 [D loss: 0.228175, acc.: 64.06%] [G loss: 0.310706]\n",
      "epoch:19 step:18597 [D loss: 0.233679, acc.: 60.94%] [G loss: 0.276802]\n",
      "epoch:19 step:18598 [D loss: 0.245935, acc.: 61.72%] [G loss: 0.299548]\n",
      "epoch:19 step:18599 [D loss: 0.229885, acc.: 64.06%] [G loss: 0.275401]\n",
      "epoch:19 step:18600 [D loss: 0.253483, acc.: 53.12%] [G loss: 0.293781]\n",
      "epoch:19 step:18601 [D loss: 0.235923, acc.: 61.72%] [G loss: 0.318992]\n",
      "epoch:19 step:18602 [D loss: 0.240730, acc.: 57.81%] [G loss: 0.312595]\n",
      "epoch:19 step:18603 [D loss: 0.245870, acc.: 57.03%] [G loss: 0.306374]\n",
      "epoch:19 step:18604 [D loss: 0.234191, acc.: 60.94%] [G loss: 0.298727]\n",
      "epoch:19 step:18605 [D loss: 0.246545, acc.: 60.16%] [G loss: 0.318606]\n",
      "epoch:19 step:18606 [D loss: 0.240715, acc.: 55.47%] [G loss: 0.278160]\n",
      "epoch:19 step:18607 [D loss: 0.243718, acc.: 57.03%] [G loss: 0.288353]\n",
      "epoch:19 step:18608 [D loss: 0.257756, acc.: 53.12%] [G loss: 0.291961]\n",
      "epoch:19 step:18609 [D loss: 0.250472, acc.: 56.25%] [G loss: 0.330936]\n",
      "epoch:19 step:18610 [D loss: 0.235529, acc.: 59.38%] [G loss: 0.296170]\n",
      "epoch:19 step:18611 [D loss: 0.237798, acc.: 61.72%] [G loss: 0.314027]\n",
      "epoch:19 step:18612 [D loss: 0.231277, acc.: 63.28%] [G loss: 0.310863]\n",
      "epoch:19 step:18613 [D loss: 0.250246, acc.: 57.03%] [G loss: 0.294093]\n",
      "epoch:19 step:18614 [D loss: 0.235128, acc.: 61.72%] [G loss: 0.316454]\n",
      "epoch:19 step:18615 [D loss: 0.227868, acc.: 60.94%] [G loss: 0.281296]\n",
      "epoch:19 step:18616 [D loss: 0.218661, acc.: 64.06%] [G loss: 0.282759]\n",
      "epoch:19 step:18617 [D loss: 0.233386, acc.: 62.50%] [G loss: 0.338054]\n",
      "epoch:19 step:18618 [D loss: 0.219527, acc.: 67.19%] [G loss: 0.328469]\n",
      "epoch:19 step:18619 [D loss: 0.232991, acc.: 53.91%] [G loss: 0.341109]\n",
      "epoch:19 step:18620 [D loss: 0.249717, acc.: 53.91%] [G loss: 0.320764]\n",
      "epoch:19 step:18621 [D loss: 0.226016, acc.: 66.41%] [G loss: 0.313179]\n",
      "epoch:19 step:18622 [D loss: 0.230241, acc.: 57.03%] [G loss: 0.317790]\n",
      "epoch:19 step:18623 [D loss: 0.236935, acc.: 61.72%] [G loss: 0.294069]\n",
      "epoch:19 step:18624 [D loss: 0.251469, acc.: 57.03%] [G loss: 0.292907]\n",
      "epoch:19 step:18625 [D loss: 0.243805, acc.: 58.59%] [G loss: 0.292107]\n",
      "epoch:19 step:18626 [D loss: 0.237768, acc.: 57.81%] [G loss: 0.289150]\n",
      "epoch:19 step:18627 [D loss: 0.224535, acc.: 64.06%] [G loss: 0.309173]\n",
      "epoch:19 step:18628 [D loss: 0.239318, acc.: 59.38%] [G loss: 0.311648]\n",
      "epoch:19 step:18629 [D loss: 0.227289, acc.: 61.72%] [G loss: 0.312137]\n",
      "epoch:19 step:18630 [D loss: 0.242302, acc.: 50.78%] [G loss: 0.347766]\n",
      "epoch:19 step:18631 [D loss: 0.236612, acc.: 50.78%] [G loss: 0.317139]\n",
      "epoch:19 step:18632 [D loss: 0.229897, acc.: 62.50%] [G loss: 0.293039]\n",
      "epoch:19 step:18633 [D loss: 0.243169, acc.: 53.91%] [G loss: 0.289052]\n",
      "epoch:19 step:18634 [D loss: 0.242274, acc.: 54.69%] [G loss: 0.315499]\n",
      "epoch:19 step:18635 [D loss: 0.247109, acc.: 53.91%] [G loss: 0.298423]\n",
      "epoch:19 step:18636 [D loss: 0.235544, acc.: 60.16%] [G loss: 0.316261]\n",
      "epoch:19 step:18637 [D loss: 0.226120, acc.: 65.62%] [G loss: 0.303934]\n",
      "epoch:19 step:18638 [D loss: 0.224954, acc.: 64.84%] [G loss: 0.314660]\n",
      "epoch:19 step:18639 [D loss: 0.222207, acc.: 64.84%] [G loss: 0.320570]\n",
      "epoch:19 step:18640 [D loss: 0.239555, acc.: 58.59%] [G loss: 0.304538]\n",
      "epoch:19 step:18641 [D loss: 0.249310, acc.: 51.56%] [G loss: 0.292622]\n",
      "epoch:19 step:18642 [D loss: 0.236374, acc.: 60.16%] [G loss: 0.313915]\n",
      "epoch:19 step:18643 [D loss: 0.236296, acc.: 56.25%] [G loss: 0.288231]\n",
      "epoch:19 step:18644 [D loss: 0.244477, acc.: 57.03%] [G loss: 0.346121]\n",
      "epoch:19 step:18645 [D loss: 0.233835, acc.: 59.38%] [G loss: 0.284121]\n",
      "epoch:19 step:18646 [D loss: 0.256186, acc.: 52.34%] [G loss: 0.327814]\n",
      "epoch:19 step:18647 [D loss: 0.243501, acc.: 56.25%] [G loss: 0.305903]\n",
      "epoch:19 step:18648 [D loss: 0.245786, acc.: 50.78%] [G loss: 0.306982]\n",
      "epoch:19 step:18649 [D loss: 0.254489, acc.: 57.03%] [G loss: 0.334321]\n",
      "epoch:19 step:18650 [D loss: 0.216430, acc.: 67.97%] [G loss: 0.336291]\n",
      "epoch:19 step:18651 [D loss: 0.247458, acc.: 55.47%] [G loss: 0.310615]\n",
      "epoch:19 step:18652 [D loss: 0.226201, acc.: 60.94%] [G loss: 0.313275]\n",
      "epoch:19 step:18653 [D loss: 0.260472, acc.: 52.34%] [G loss: 0.285208]\n",
      "epoch:19 step:18654 [D loss: 0.255147, acc.: 51.56%] [G loss: 0.302811]\n",
      "epoch:19 step:18655 [D loss: 0.237221, acc.: 64.06%] [G loss: 0.312091]\n",
      "epoch:19 step:18656 [D loss: 0.225663, acc.: 68.75%] [G loss: 0.339492]\n",
      "epoch:19 step:18657 [D loss: 0.222161, acc.: 67.97%] [G loss: 0.327188]\n",
      "epoch:19 step:18658 [D loss: 0.250225, acc.: 60.94%] [G loss: 0.322966]\n",
      "epoch:19 step:18659 [D loss: 0.217026, acc.: 61.72%] [G loss: 0.351515]\n",
      "epoch:19 step:18660 [D loss: 0.241326, acc.: 56.25%] [G loss: 0.291547]\n",
      "epoch:19 step:18661 [D loss: 0.235754, acc.: 64.84%] [G loss: 0.327530]\n",
      "epoch:19 step:18662 [D loss: 0.242719, acc.: 55.47%] [G loss: 0.311726]\n",
      "epoch:19 step:18663 [D loss: 0.223287, acc.: 62.50%] [G loss: 0.323242]\n",
      "epoch:19 step:18664 [D loss: 0.244121, acc.: 62.50%] [G loss: 0.289998]\n",
      "epoch:19 step:18665 [D loss: 0.251188, acc.: 49.22%] [G loss: 0.291250]\n",
      "epoch:19 step:18666 [D loss: 0.225576, acc.: 66.41%] [G loss: 0.309346]\n",
      "epoch:19 step:18667 [D loss: 0.244049, acc.: 57.03%] [G loss: 0.307689]\n",
      "epoch:19 step:18668 [D loss: 0.244475, acc.: 57.03%] [G loss: 0.315937]\n",
      "epoch:19 step:18669 [D loss: 0.252249, acc.: 51.56%] [G loss: 0.297427]\n",
      "epoch:19 step:18670 [D loss: 0.232493, acc.: 63.28%] [G loss: 0.308209]\n",
      "epoch:19 step:18671 [D loss: 0.245685, acc.: 56.25%] [G loss: 0.286728]\n",
      "epoch:19 step:18672 [D loss: 0.241422, acc.: 54.69%] [G loss: 0.290422]\n",
      "epoch:19 step:18673 [D loss: 0.248155, acc.: 50.78%] [G loss: 0.313987]\n",
      "epoch:19 step:18674 [D loss: 0.251698, acc.: 58.59%] [G loss: 0.305356]\n",
      "epoch:19 step:18675 [D loss: 0.246376, acc.: 52.34%] [G loss: 0.287733]\n",
      "epoch:19 step:18676 [D loss: 0.219255, acc.: 63.28%] [G loss: 0.284839]\n",
      "epoch:19 step:18677 [D loss: 0.221239, acc.: 64.84%] [G loss: 0.293487]\n",
      "epoch:19 step:18678 [D loss: 0.254246, acc.: 52.34%] [G loss: 0.294721]\n",
      "epoch:19 step:18679 [D loss: 0.247317, acc.: 53.91%] [G loss: 0.307837]\n",
      "epoch:19 step:18680 [D loss: 0.231164, acc.: 57.81%] [G loss: 0.308877]\n",
      "epoch:19 step:18681 [D loss: 0.260839, acc.: 49.22%] [G loss: 0.300496]\n",
      "epoch:19 step:18682 [D loss: 0.245664, acc.: 53.12%] [G loss: 0.310936]\n",
      "epoch:19 step:18683 [D loss: 0.232980, acc.: 60.16%] [G loss: 0.294825]\n",
      "epoch:19 step:18684 [D loss: 0.230450, acc.: 64.06%] [G loss: 0.306921]\n",
      "epoch:19 step:18685 [D loss: 0.214943, acc.: 69.53%] [G loss: 0.288448]\n",
      "epoch:19 step:18686 [D loss: 0.247757, acc.: 58.59%] [G loss: 0.313902]\n",
      "epoch:19 step:18687 [D loss: 0.223336, acc.: 64.84%] [G loss: 0.282184]\n",
      "epoch:19 step:18688 [D loss: 0.232113, acc.: 61.72%] [G loss: 0.322842]\n",
      "epoch:19 step:18689 [D loss: 0.239261, acc.: 58.59%] [G loss: 0.305068]\n",
      "epoch:19 step:18690 [D loss: 0.248803, acc.: 55.47%] [G loss: 0.294092]\n",
      "epoch:19 step:18691 [D loss: 0.232415, acc.: 61.72%] [G loss: 0.301535]\n",
      "epoch:19 step:18692 [D loss: 0.234335, acc.: 56.25%] [G loss: 0.332309]\n",
      "epoch:19 step:18693 [D loss: 0.231469, acc.: 58.59%] [G loss: 0.322512]\n",
      "epoch:19 step:18694 [D loss: 0.240133, acc.: 58.59%] [G loss: 0.295868]\n",
      "epoch:19 step:18695 [D loss: 0.267300, acc.: 46.88%] [G loss: 0.274103]\n",
      "epoch:19 step:18696 [D loss: 0.250053, acc.: 55.47%] [G loss: 0.320522]\n",
      "epoch:19 step:18697 [D loss: 0.246179, acc.: 53.12%] [G loss: 0.321883]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:19 step:18698 [D loss: 0.234860, acc.: 58.59%] [G loss: 0.291333]\n",
      "epoch:19 step:18699 [D loss: 0.247414, acc.: 57.03%] [G loss: 0.283428]\n",
      "epoch:19 step:18700 [D loss: 0.221903, acc.: 64.06%] [G loss: 0.312544]\n",
      "epoch:19 step:18701 [D loss: 0.244735, acc.: 55.47%] [G loss: 0.303718]\n",
      "epoch:19 step:18702 [D loss: 0.237800, acc.: 53.12%] [G loss: 0.291234]\n",
      "epoch:19 step:18703 [D loss: 0.258195, acc.: 50.78%] [G loss: 0.291479]\n",
      "epoch:19 step:18704 [D loss: 0.243130, acc.: 57.03%] [G loss: 0.282120]\n",
      "epoch:19 step:18705 [D loss: 0.259994, acc.: 46.88%] [G loss: 0.266634]\n",
      "epoch:19 step:18706 [D loss: 0.231674, acc.: 60.16%] [G loss: 0.327731]\n",
      "epoch:19 step:18707 [D loss: 0.221777, acc.: 64.06%] [G loss: 0.326935]\n",
      "epoch:19 step:18708 [D loss: 0.243376, acc.: 56.25%] [G loss: 0.336627]\n",
      "epoch:19 step:18709 [D loss: 0.230045, acc.: 62.50%] [G loss: 0.273937]\n",
      "epoch:19 step:18710 [D loss: 0.258622, acc.: 52.34%] [G loss: 0.303781]\n",
      "epoch:19 step:18711 [D loss: 0.248657, acc.: 53.12%] [G loss: 0.314239]\n",
      "epoch:19 step:18712 [D loss: 0.254167, acc.: 52.34%] [G loss: 0.293857]\n",
      "epoch:19 step:18713 [D loss: 0.231915, acc.: 59.38%] [G loss: 0.306602]\n",
      "epoch:19 step:18714 [D loss: 0.233690, acc.: 55.47%] [G loss: 0.321017]\n",
      "epoch:19 step:18715 [D loss: 0.252800, acc.: 57.03%] [G loss: 0.309551]\n",
      "epoch:19 step:18716 [D loss: 0.225172, acc.: 70.31%] [G loss: 0.303477]\n",
      "epoch:19 step:18717 [D loss: 0.240065, acc.: 58.59%] [G loss: 0.299689]\n",
      "epoch:19 step:18718 [D loss: 0.255925, acc.: 53.12%] [G loss: 0.268279]\n",
      "epoch:19 step:18719 [D loss: 0.247087, acc.: 56.25%] [G loss: 0.313595]\n",
      "epoch:19 step:18720 [D loss: 0.204180, acc.: 67.97%] [G loss: 0.315006]\n",
      "epoch:19 step:18721 [D loss: 0.260366, acc.: 50.00%] [G loss: 0.302952]\n",
      "epoch:19 step:18722 [D loss: 0.254109, acc.: 57.81%] [G loss: 0.324098]\n",
      "epoch:19 step:18723 [D loss: 0.231199, acc.: 62.50%] [G loss: 0.320312]\n",
      "epoch:19 step:18724 [D loss: 0.234706, acc.: 61.72%] [G loss: 0.297120]\n",
      "epoch:19 step:18725 [D loss: 0.240791, acc.: 57.03%] [G loss: 0.262561]\n",
      "epoch:19 step:18726 [D loss: 0.255454, acc.: 56.25%] [G loss: 0.277358]\n",
      "epoch:19 step:18727 [D loss: 0.241332, acc.: 53.91%] [G loss: 0.326587]\n",
      "epoch:19 step:18728 [D loss: 0.225853, acc.: 58.59%] [G loss: 0.319031]\n",
      "epoch:19 step:18729 [D loss: 0.235050, acc.: 59.38%] [G loss: 0.311315]\n",
      "epoch:19 step:18730 [D loss: 0.253393, acc.: 57.03%] [G loss: 0.263584]\n",
      "epoch:19 step:18731 [D loss: 0.242607, acc.: 60.94%] [G loss: 0.313109]\n",
      "epoch:19 step:18732 [D loss: 0.217984, acc.: 64.06%] [G loss: 0.288973]\n",
      "epoch:19 step:18733 [D loss: 0.243031, acc.: 57.81%] [G loss: 0.290026]\n",
      "epoch:19 step:18734 [D loss: 0.246937, acc.: 60.94%] [G loss: 0.319549]\n",
      "epoch:19 step:18735 [D loss: 0.242380, acc.: 55.47%] [G loss: 0.289387]\n",
      "epoch:19 step:18736 [D loss: 0.239428, acc.: 57.03%] [G loss: 0.282006]\n",
      "epoch:19 step:18737 [D loss: 0.241065, acc.: 54.69%] [G loss: 0.296298]\n",
      "epoch:19 step:18738 [D loss: 0.245419, acc.: 52.34%] [G loss: 0.320563]\n",
      "epoch:19 step:18739 [D loss: 0.234781, acc.: 60.94%] [G loss: 0.320587]\n",
      "epoch:19 step:18740 [D loss: 0.236537, acc.: 57.81%] [G loss: 0.308790]\n",
      "epoch:20 step:18741 [D loss: 0.248580, acc.: 57.03%] [G loss: 0.290277]\n",
      "epoch:20 step:18742 [D loss: 0.235444, acc.: 60.16%] [G loss: 0.305207]\n",
      "epoch:20 step:18743 [D loss: 0.240858, acc.: 59.38%] [G loss: 0.314202]\n",
      "epoch:20 step:18744 [D loss: 0.221806, acc.: 62.50%] [G loss: 0.330168]\n",
      "epoch:20 step:18745 [D loss: 0.252913, acc.: 51.56%] [G loss: 0.288208]\n",
      "epoch:20 step:18746 [D loss: 0.244182, acc.: 55.47%] [G loss: 0.279797]\n",
      "epoch:20 step:18747 [D loss: 0.237226, acc.: 59.38%] [G loss: 0.298048]\n",
      "epoch:20 step:18748 [D loss: 0.225633, acc.: 64.06%] [G loss: 0.316789]\n",
      "epoch:20 step:18749 [D loss: 0.234825, acc.: 54.69%] [G loss: 0.306720]\n",
      "epoch:20 step:18750 [D loss: 0.248808, acc.: 51.56%] [G loss: 0.263687]\n",
      "epoch:20 step:18751 [D loss: 0.240343, acc.: 54.69%] [G loss: 0.312324]\n",
      "epoch:20 step:18752 [D loss: 0.249148, acc.: 60.16%] [G loss: 0.315274]\n",
      "epoch:20 step:18753 [D loss: 0.239706, acc.: 56.25%] [G loss: 0.301679]\n",
      "epoch:20 step:18754 [D loss: 0.234044, acc.: 64.84%] [G loss: 0.272460]\n",
      "epoch:20 step:18755 [D loss: 0.226877, acc.: 61.72%] [G loss: 0.335383]\n",
      "epoch:20 step:18756 [D loss: 0.240231, acc.: 58.59%] [G loss: 0.308287]\n",
      "epoch:20 step:18757 [D loss: 0.229009, acc.: 57.81%] [G loss: 0.302973]\n",
      "epoch:20 step:18758 [D loss: 0.226999, acc.: 60.94%] [G loss: 0.299088]\n",
      "epoch:20 step:18759 [D loss: 0.250972, acc.: 52.34%] [G loss: 0.318947]\n",
      "epoch:20 step:18760 [D loss: 0.235471, acc.: 63.28%] [G loss: 0.291335]\n",
      "epoch:20 step:18761 [D loss: 0.241101, acc.: 60.94%] [G loss: 0.312863]\n",
      "epoch:20 step:18762 [D loss: 0.249157, acc.: 56.25%] [G loss: 0.320651]\n",
      "epoch:20 step:18763 [D loss: 0.258141, acc.: 51.56%] [G loss: 0.297928]\n",
      "epoch:20 step:18764 [D loss: 0.240720, acc.: 54.69%] [G loss: 0.278554]\n",
      "epoch:20 step:18765 [D loss: 0.253866, acc.: 55.47%] [G loss: 0.298852]\n",
      "epoch:20 step:18766 [D loss: 0.236642, acc.: 58.59%] [G loss: 0.360016]\n",
      "epoch:20 step:18767 [D loss: 0.244275, acc.: 57.81%] [G loss: 0.291028]\n",
      "epoch:20 step:18768 [D loss: 0.241978, acc.: 61.72%] [G loss: 0.326324]\n",
      "epoch:20 step:18769 [D loss: 0.249537, acc.: 50.78%] [G loss: 0.303449]\n",
      "epoch:20 step:18770 [D loss: 0.248057, acc.: 53.91%] [G loss: 0.275032]\n",
      "epoch:20 step:18771 [D loss: 0.235353, acc.: 58.59%] [G loss: 0.306848]\n",
      "epoch:20 step:18772 [D loss: 0.228284, acc.: 61.72%] [G loss: 0.298108]\n",
      "epoch:20 step:18773 [D loss: 0.239872, acc.: 60.16%] [G loss: 0.300766]\n",
      "epoch:20 step:18774 [D loss: 0.229654, acc.: 62.50%] [G loss: 0.295155]\n",
      "epoch:20 step:18775 [D loss: 0.239933, acc.: 60.94%] [G loss: 0.305436]\n",
      "epoch:20 step:18776 [D loss: 0.226256, acc.: 64.06%] [G loss: 0.319067]\n",
      "epoch:20 step:18777 [D loss: 0.246214, acc.: 58.59%] [G loss: 0.325441]\n",
      "epoch:20 step:18778 [D loss: 0.255429, acc.: 53.91%] [G loss: 0.302883]\n",
      "epoch:20 step:18779 [D loss: 0.233933, acc.: 64.06%] [G loss: 0.305645]\n",
      "epoch:20 step:18780 [D loss: 0.260330, acc.: 46.09%] [G loss: 0.295369]\n",
      "epoch:20 step:18781 [D loss: 0.229350, acc.: 57.03%] [G loss: 0.308984]\n",
      "epoch:20 step:18782 [D loss: 0.232174, acc.: 61.72%] [G loss: 0.344009]\n",
      "epoch:20 step:18783 [D loss: 0.243514, acc.: 53.12%] [G loss: 0.309166]\n",
      "epoch:20 step:18784 [D loss: 0.232126, acc.: 60.16%] [G loss: 0.320725]\n",
      "epoch:20 step:18785 [D loss: 0.233997, acc.: 60.16%] [G loss: 0.313066]\n",
      "epoch:20 step:18786 [D loss: 0.224996, acc.: 58.59%] [G loss: 0.300600]\n",
      "epoch:20 step:18787 [D loss: 0.243472, acc.: 56.25%] [G loss: 0.308935]\n",
      "epoch:20 step:18788 [D loss: 0.231485, acc.: 56.25%] [G loss: 0.291652]\n",
      "epoch:20 step:18789 [D loss: 0.232778, acc.: 64.06%] [G loss: 0.309119]\n",
      "epoch:20 step:18790 [D loss: 0.216503, acc.: 65.62%] [G loss: 0.315551]\n",
      "epoch:20 step:18791 [D loss: 0.232480, acc.: 63.28%] [G loss: 0.317651]\n",
      "epoch:20 step:18792 [D loss: 0.244981, acc.: 57.81%] [G loss: 0.293248]\n",
      "epoch:20 step:18793 [D loss: 0.226410, acc.: 65.62%] [G loss: 0.253874]\n",
      "epoch:20 step:18794 [D loss: 0.216760, acc.: 63.28%] [G loss: 0.295771]\n",
      "epoch:20 step:18795 [D loss: 0.243002, acc.: 62.50%] [G loss: 0.305985]\n",
      "epoch:20 step:18796 [D loss: 0.237241, acc.: 57.81%] [G loss: 0.286754]\n",
      "epoch:20 step:18797 [D loss: 0.234476, acc.: 66.41%] [G loss: 0.312029]\n",
      "epoch:20 step:18798 [D loss: 0.258510, acc.: 54.69%] [G loss: 0.283592]\n",
      "epoch:20 step:18799 [D loss: 0.228347, acc.: 65.62%] [G loss: 0.319748]\n",
      "epoch:20 step:18800 [D loss: 0.242568, acc.: 54.69%] [G loss: 0.305489]\n",
      "epoch:20 step:18801 [D loss: 0.247066, acc.: 59.38%] [G loss: 0.272405]\n",
      "epoch:20 step:18802 [D loss: 0.256205, acc.: 56.25%] [G loss: 0.321500]\n",
      "epoch:20 step:18803 [D loss: 0.230978, acc.: 62.50%] [G loss: 0.354187]\n",
      "epoch:20 step:18804 [D loss: 0.252804, acc.: 55.47%] [G loss: 0.298210]\n",
      "epoch:20 step:18805 [D loss: 0.241193, acc.: 57.03%] [G loss: 0.298407]\n",
      "epoch:20 step:18806 [D loss: 0.243867, acc.: 57.03%] [G loss: 0.303502]\n",
      "epoch:20 step:18807 [D loss: 0.239079, acc.: 60.94%] [G loss: 0.283880]\n",
      "epoch:20 step:18808 [D loss: 0.248145, acc.: 54.69%] [G loss: 0.306489]\n",
      "epoch:20 step:18809 [D loss: 0.256983, acc.: 49.22%] [G loss: 0.304563]\n",
      "epoch:20 step:18810 [D loss: 0.227197, acc.: 62.50%] [G loss: 0.324678]\n",
      "epoch:20 step:18811 [D loss: 0.230917, acc.: 60.16%] [G loss: 0.317498]\n",
      "epoch:20 step:18812 [D loss: 0.243590, acc.: 63.28%] [G loss: 0.309285]\n",
      "epoch:20 step:18813 [D loss: 0.252355, acc.: 50.00%] [G loss: 0.318622]\n",
      "epoch:20 step:18814 [D loss: 0.244613, acc.: 54.69%] [G loss: 0.295698]\n",
      "epoch:20 step:18815 [D loss: 0.237886, acc.: 54.69%] [G loss: 0.316385]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:20 step:18816 [D loss: 0.236243, acc.: 52.34%] [G loss: 0.329083]\n",
      "epoch:20 step:18817 [D loss: 0.244703, acc.: 58.59%] [G loss: 0.300897]\n",
      "epoch:20 step:18818 [D loss: 0.222304, acc.: 65.62%] [G loss: 0.313740]\n",
      "epoch:20 step:18819 [D loss: 0.228424, acc.: 58.59%] [G loss: 0.315163]\n",
      "epoch:20 step:18820 [D loss: 0.227128, acc.: 62.50%] [G loss: 0.341199]\n",
      "epoch:20 step:18821 [D loss: 0.246919, acc.: 57.81%] [G loss: 0.296621]\n",
      "epoch:20 step:18822 [D loss: 0.239680, acc.: 57.03%] [G loss: 0.307683]\n",
      "epoch:20 step:18823 [D loss: 0.251390, acc.: 52.34%] [G loss: 0.301820]\n",
      "epoch:20 step:18824 [D loss: 0.245295, acc.: 56.25%] [G loss: 0.264883]\n",
      "epoch:20 step:18825 [D loss: 0.234042, acc.: 58.59%] [G loss: 0.306156]\n",
      "epoch:20 step:18826 [D loss: 0.249991, acc.: 53.12%] [G loss: 0.307691]\n",
      "epoch:20 step:18827 [D loss: 0.236170, acc.: 55.47%] [G loss: 0.287951]\n",
      "epoch:20 step:18828 [D loss: 0.233303, acc.: 61.72%] [G loss: 0.330015]\n",
      "epoch:20 step:18829 [D loss: 0.250643, acc.: 57.81%] [G loss: 0.312272]\n",
      "epoch:20 step:18830 [D loss: 0.237847, acc.: 57.81%] [G loss: 0.330159]\n",
      "epoch:20 step:18831 [D loss: 0.242656, acc.: 64.84%] [G loss: 0.315032]\n",
      "epoch:20 step:18832 [D loss: 0.233824, acc.: 60.16%] [G loss: 0.316777]\n",
      "epoch:20 step:18833 [D loss: 0.237449, acc.: 58.59%] [G loss: 0.321018]\n",
      "epoch:20 step:18834 [D loss: 0.233595, acc.: 64.06%] [G loss: 0.319015]\n",
      "epoch:20 step:18835 [D loss: 0.244697, acc.: 53.91%] [G loss: 0.294143]\n",
      "epoch:20 step:18836 [D loss: 0.239231, acc.: 56.25%] [G loss: 0.316163]\n",
      "epoch:20 step:18837 [D loss: 0.255985, acc.: 53.91%] [G loss: 0.318605]\n",
      "epoch:20 step:18838 [D loss: 0.242363, acc.: 52.34%] [G loss: 0.294250]\n",
      "epoch:20 step:18839 [D loss: 0.250212, acc.: 62.50%] [G loss: 0.300086]\n",
      "epoch:20 step:18840 [D loss: 0.254226, acc.: 56.25%] [G loss: 0.307481]\n",
      "epoch:20 step:18841 [D loss: 0.218430, acc.: 70.31%] [G loss: 0.305483]\n",
      "epoch:20 step:18842 [D loss: 0.234573, acc.: 59.38%] [G loss: 0.303837]\n",
      "epoch:20 step:18843 [D loss: 0.235870, acc.: 59.38%] [G loss: 0.288983]\n",
      "epoch:20 step:18844 [D loss: 0.248127, acc.: 54.69%] [G loss: 0.303085]\n",
      "epoch:20 step:18845 [D loss: 0.242004, acc.: 59.38%] [G loss: 0.307295]\n",
      "epoch:20 step:18846 [D loss: 0.231633, acc.: 58.59%] [G loss: 0.310732]\n",
      "epoch:20 step:18847 [D loss: 0.268605, acc.: 53.12%] [G loss: 0.309997]\n",
      "epoch:20 step:18848 [D loss: 0.243716, acc.: 65.62%] [G loss: 0.324325]\n",
      "epoch:20 step:18849 [D loss: 0.235334, acc.: 62.50%] [G loss: 0.298443]\n",
      "epoch:20 step:18850 [D loss: 0.239694, acc.: 55.47%] [G loss: 0.298184]\n",
      "epoch:20 step:18851 [D loss: 0.230398, acc.: 60.16%] [G loss: 0.314179]\n",
      "epoch:20 step:18852 [D loss: 0.231878, acc.: 64.06%] [G loss: 0.303859]\n",
      "epoch:20 step:18853 [D loss: 0.272431, acc.: 46.09%] [G loss: 0.290377]\n",
      "epoch:20 step:18854 [D loss: 0.226575, acc.: 61.72%] [G loss: 0.296156]\n",
      "epoch:20 step:18855 [D loss: 0.248839, acc.: 54.69%] [G loss: 0.283572]\n",
      "epoch:20 step:18856 [D loss: 0.243703, acc.: 60.16%] [G loss: 0.283676]\n",
      "epoch:20 step:18857 [D loss: 0.239533, acc.: 54.69%] [G loss: 0.321729]\n",
      "epoch:20 step:18858 [D loss: 0.233389, acc.: 58.59%] [G loss: 0.314028]\n",
      "epoch:20 step:18859 [D loss: 0.234921, acc.: 61.72%] [G loss: 0.303431]\n",
      "epoch:20 step:18860 [D loss: 0.229644, acc.: 64.06%] [G loss: 0.305777]\n",
      "epoch:20 step:18861 [D loss: 0.236462, acc.: 58.59%] [G loss: 0.287822]\n",
      "epoch:20 step:18862 [D loss: 0.239319, acc.: 59.38%] [G loss: 0.311252]\n",
      "epoch:20 step:18863 [D loss: 0.224412, acc.: 60.16%] [G loss: 0.304489]\n",
      "epoch:20 step:18864 [D loss: 0.234461, acc.: 56.25%] [G loss: 0.345641]\n",
      "epoch:20 step:18865 [D loss: 0.241013, acc.: 63.28%] [G loss: 0.310444]\n",
      "epoch:20 step:18866 [D loss: 0.245470, acc.: 58.59%] [G loss: 0.296269]\n",
      "epoch:20 step:18867 [D loss: 0.236548, acc.: 64.06%] [G loss: 0.318105]\n",
      "epoch:20 step:18868 [D loss: 0.230934, acc.: 60.16%] [G loss: 0.293544]\n",
      "epoch:20 step:18869 [D loss: 0.236480, acc.: 59.38%] [G loss: 0.288924]\n",
      "epoch:20 step:18870 [D loss: 0.241794, acc.: 58.59%] [G loss: 0.287275]\n",
      "epoch:20 step:18871 [D loss: 0.244739, acc.: 53.12%] [G loss: 0.304094]\n",
      "epoch:20 step:18872 [D loss: 0.264357, acc.: 50.00%] [G loss: 0.289914]\n",
      "epoch:20 step:18873 [D loss: 0.232067, acc.: 58.59%] [G loss: 0.308700]\n",
      "epoch:20 step:18874 [D loss: 0.231202, acc.: 62.50%] [G loss: 0.323304]\n",
      "epoch:20 step:18875 [D loss: 0.258484, acc.: 52.34%] [G loss: 0.297857]\n",
      "epoch:20 step:18876 [D loss: 0.250539, acc.: 53.91%] [G loss: 0.315023]\n",
      "epoch:20 step:18877 [D loss: 0.231785, acc.: 61.72%] [G loss: 0.304108]\n",
      "epoch:20 step:18878 [D loss: 0.239694, acc.: 57.81%] [G loss: 0.316285]\n",
      "epoch:20 step:18879 [D loss: 0.234232, acc.: 61.72%] [G loss: 0.298402]\n",
      "epoch:20 step:18880 [D loss: 0.244406, acc.: 60.94%] [G loss: 0.312661]\n",
      "epoch:20 step:18881 [D loss: 0.254745, acc.: 52.34%] [G loss: 0.302696]\n",
      "epoch:20 step:18882 [D loss: 0.219329, acc.: 67.19%] [G loss: 0.287628]\n",
      "epoch:20 step:18883 [D loss: 0.246984, acc.: 57.03%] [G loss: 0.300319]\n",
      "epoch:20 step:18884 [D loss: 0.245591, acc.: 53.91%] [G loss: 0.296479]\n",
      "epoch:20 step:18885 [D loss: 0.259267, acc.: 50.00%] [G loss: 0.285608]\n",
      "epoch:20 step:18886 [D loss: 0.235312, acc.: 62.50%] [G loss: 0.301661]\n",
      "epoch:20 step:18887 [D loss: 0.231175, acc.: 63.28%] [G loss: 0.286736]\n",
      "epoch:20 step:18888 [D loss: 0.215227, acc.: 71.09%] [G loss: 0.339872]\n",
      "epoch:20 step:18889 [D loss: 0.240566, acc.: 57.81%] [G loss: 0.305490]\n",
      "epoch:20 step:18890 [D loss: 0.239245, acc.: 60.94%] [G loss: 0.307174]\n",
      "epoch:20 step:18891 [D loss: 0.262834, acc.: 51.56%] [G loss: 0.311161]\n",
      "epoch:20 step:18892 [D loss: 0.251908, acc.: 50.00%] [G loss: 0.317419]\n",
      "epoch:20 step:18893 [D loss: 0.226936, acc.: 65.62%] [G loss: 0.281198]\n",
      "epoch:20 step:18894 [D loss: 0.227590, acc.: 62.50%] [G loss: 0.292026]\n",
      "epoch:20 step:18895 [D loss: 0.232674, acc.: 60.16%] [G loss: 0.275502]\n",
      "epoch:20 step:18896 [D loss: 0.238662, acc.: 60.16%] [G loss: 0.281233]\n",
      "epoch:20 step:18897 [D loss: 0.238714, acc.: 60.16%] [G loss: 0.294516]\n",
      "epoch:20 step:18898 [D loss: 0.241243, acc.: 54.69%] [G loss: 0.294981]\n",
      "epoch:20 step:18899 [D loss: 0.228434, acc.: 60.16%] [G loss: 0.300030]\n",
      "epoch:20 step:18900 [D loss: 0.222807, acc.: 64.84%] [G loss: 0.284161]\n",
      "epoch:20 step:18901 [D loss: 0.247601, acc.: 55.47%] [G loss: 0.309357]\n",
      "epoch:20 step:18902 [D loss: 0.242622, acc.: 55.47%] [G loss: 0.280940]\n",
      "epoch:20 step:18903 [D loss: 0.240475, acc.: 57.03%] [G loss: 0.300557]\n",
      "epoch:20 step:18904 [D loss: 0.242866, acc.: 62.50%] [G loss: 0.292490]\n",
      "epoch:20 step:18905 [D loss: 0.236568, acc.: 56.25%] [G loss: 0.288880]\n",
      "epoch:20 step:18906 [D loss: 0.230536, acc.: 60.16%] [G loss: 0.299664]\n",
      "epoch:20 step:18907 [D loss: 0.228980, acc.: 63.28%] [G loss: 0.291193]\n",
      "epoch:20 step:18908 [D loss: 0.231030, acc.: 61.72%] [G loss: 0.301385]\n",
      "epoch:20 step:18909 [D loss: 0.233410, acc.: 54.69%] [G loss: 0.320801]\n",
      "epoch:20 step:18910 [D loss: 0.243642, acc.: 57.03%] [G loss: 0.302166]\n",
      "epoch:20 step:18911 [D loss: 0.236377, acc.: 58.59%] [G loss: 0.283479]\n",
      "epoch:20 step:18912 [D loss: 0.236390, acc.: 58.59%] [G loss: 0.285349]\n",
      "epoch:20 step:18913 [D loss: 0.241180, acc.: 59.38%] [G loss: 0.306294]\n",
      "epoch:20 step:18914 [D loss: 0.231423, acc.: 60.94%] [G loss: 0.325063]\n",
      "epoch:20 step:18915 [D loss: 0.264883, acc.: 53.12%] [G loss: 0.298196]\n",
      "epoch:20 step:18916 [D loss: 0.228845, acc.: 62.50%] [G loss: 0.287254]\n",
      "epoch:20 step:18917 [D loss: 0.249536, acc.: 56.25%] [G loss: 0.309386]\n",
      "epoch:20 step:18918 [D loss: 0.233620, acc.: 56.25%] [G loss: 0.319793]\n",
      "epoch:20 step:18919 [D loss: 0.254461, acc.: 48.44%] [G loss: 0.299234]\n",
      "epoch:20 step:18920 [D loss: 0.224802, acc.: 67.19%] [G loss: 0.296994]\n",
      "epoch:20 step:18921 [D loss: 0.244569, acc.: 57.03%] [G loss: 0.304634]\n",
      "epoch:20 step:18922 [D loss: 0.220353, acc.: 63.28%] [G loss: 0.319017]\n",
      "epoch:20 step:18923 [D loss: 0.214377, acc.: 67.19%] [G loss: 0.330863]\n",
      "epoch:20 step:18924 [D loss: 0.233407, acc.: 58.59%] [G loss: 0.285904]\n",
      "epoch:20 step:18925 [D loss: 0.259206, acc.: 55.47%] [G loss: 0.314035]\n",
      "epoch:20 step:18926 [D loss: 0.249170, acc.: 56.25%] [G loss: 0.334008]\n",
      "epoch:20 step:18927 [D loss: 0.231214, acc.: 63.28%] [G loss: 0.298030]\n",
      "epoch:20 step:18928 [D loss: 0.255332, acc.: 51.56%] [G loss: 0.302198]\n",
      "epoch:20 step:18929 [D loss: 0.238924, acc.: 57.03%] [G loss: 0.306482]\n",
      "epoch:20 step:18930 [D loss: 0.243717, acc.: 51.56%] [G loss: 0.295897]\n",
      "epoch:20 step:18931 [D loss: 0.240713, acc.: 54.69%] [G loss: 0.320128]\n",
      "epoch:20 step:18932 [D loss: 0.216618, acc.: 69.53%] [G loss: 0.305507]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:20 step:18933 [D loss: 0.237655, acc.: 54.69%] [G loss: 0.314705]\n",
      "epoch:20 step:18934 [D loss: 0.224957, acc.: 60.16%] [G loss: 0.309837]\n",
      "epoch:20 step:18935 [D loss: 0.254394, acc.: 50.00%] [G loss: 0.289567]\n",
      "epoch:20 step:18936 [D loss: 0.232100, acc.: 60.94%] [G loss: 0.298571]\n",
      "epoch:20 step:18937 [D loss: 0.221011, acc.: 68.75%] [G loss: 0.292482]\n",
      "epoch:20 step:18938 [D loss: 0.226705, acc.: 59.38%] [G loss: 0.315929]\n",
      "epoch:20 step:18939 [D loss: 0.237372, acc.: 57.03%] [G loss: 0.294283]\n",
      "epoch:20 step:18940 [D loss: 0.238079, acc.: 61.72%] [G loss: 0.300726]\n",
      "epoch:20 step:18941 [D loss: 0.221411, acc.: 63.28%] [G loss: 0.331375]\n",
      "epoch:20 step:18942 [D loss: 0.232516, acc.: 62.50%] [G loss: 0.300183]\n",
      "epoch:20 step:18943 [D loss: 0.236155, acc.: 60.94%] [G loss: 0.310444]\n",
      "epoch:20 step:18944 [D loss: 0.234987, acc.: 63.28%] [G loss: 0.285817]\n",
      "epoch:20 step:18945 [D loss: 0.244558, acc.: 54.69%] [G loss: 0.295885]\n",
      "epoch:20 step:18946 [D loss: 0.239292, acc.: 59.38%] [G loss: 0.269995]\n",
      "epoch:20 step:18947 [D loss: 0.235631, acc.: 59.38%] [G loss: 0.284602]\n",
      "epoch:20 step:18948 [D loss: 0.237680, acc.: 60.94%] [G loss: 0.321137]\n",
      "epoch:20 step:18949 [D loss: 0.247950, acc.: 58.59%] [G loss: 0.289776]\n",
      "epoch:20 step:18950 [D loss: 0.215473, acc.: 64.06%] [G loss: 0.337319]\n",
      "epoch:20 step:18951 [D loss: 0.224212, acc.: 61.72%] [G loss: 0.315213]\n",
      "epoch:20 step:18952 [D loss: 0.235426, acc.: 60.94%] [G loss: 0.278110]\n",
      "epoch:20 step:18953 [D loss: 0.236319, acc.: 58.59%] [G loss: 0.304281]\n",
      "epoch:20 step:18954 [D loss: 0.236847, acc.: 57.03%] [G loss: 0.284018]\n",
      "epoch:20 step:18955 [D loss: 0.249254, acc.: 56.25%] [G loss: 0.290456]\n",
      "epoch:20 step:18956 [D loss: 0.235805, acc.: 59.38%] [G loss: 0.286337]\n",
      "epoch:20 step:18957 [D loss: 0.251344, acc.: 57.03%] [G loss: 0.310130]\n",
      "epoch:20 step:18958 [D loss: 0.249084, acc.: 52.34%] [G loss: 0.308741]\n",
      "epoch:20 step:18959 [D loss: 0.235851, acc.: 61.72%] [G loss: 0.296674]\n",
      "epoch:20 step:18960 [D loss: 0.234967, acc.: 60.16%] [G loss: 0.293010]\n",
      "epoch:20 step:18961 [D loss: 0.229516, acc.: 59.38%] [G loss: 0.289856]\n",
      "epoch:20 step:18962 [D loss: 0.248501, acc.: 54.69%] [G loss: 0.306670]\n",
      "epoch:20 step:18963 [D loss: 0.255878, acc.: 52.34%] [G loss: 0.289718]\n",
      "epoch:20 step:18964 [D loss: 0.230975, acc.: 60.94%] [G loss: 0.320282]\n",
      "epoch:20 step:18965 [D loss: 0.254806, acc.: 56.25%] [G loss: 0.276415]\n",
      "epoch:20 step:18966 [D loss: 0.240974, acc.: 57.81%] [G loss: 0.303357]\n",
      "epoch:20 step:18967 [D loss: 0.240950, acc.: 56.25%] [G loss: 0.283423]\n",
      "epoch:20 step:18968 [D loss: 0.241313, acc.: 56.25%] [G loss: 0.285575]\n",
      "epoch:20 step:18969 [D loss: 0.239890, acc.: 60.16%] [G loss: 0.301952]\n",
      "epoch:20 step:18970 [D loss: 0.248000, acc.: 52.34%] [G loss: 0.301954]\n",
      "epoch:20 step:18971 [D loss: 0.224148, acc.: 63.28%] [G loss: 0.324842]\n",
      "epoch:20 step:18972 [D loss: 0.240798, acc.: 56.25%] [G loss: 0.307940]\n",
      "epoch:20 step:18973 [D loss: 0.240732, acc.: 57.81%] [G loss: 0.303464]\n",
      "epoch:20 step:18974 [D loss: 0.229168, acc.: 63.28%] [G loss: 0.329770]\n",
      "epoch:20 step:18975 [D loss: 0.224828, acc.: 61.72%] [G loss: 0.295347]\n",
      "epoch:20 step:18976 [D loss: 0.233395, acc.: 60.94%] [G loss: 0.295142]\n",
      "epoch:20 step:18977 [D loss: 0.239286, acc.: 57.81%] [G loss: 0.316988]\n",
      "epoch:20 step:18978 [D loss: 0.229059, acc.: 60.94%] [G loss: 0.294225]\n",
      "epoch:20 step:18979 [D loss: 0.237137, acc.: 62.50%] [G loss: 0.304229]\n",
      "epoch:20 step:18980 [D loss: 0.233772, acc.: 57.81%] [G loss: 0.294647]\n",
      "epoch:20 step:18981 [D loss: 0.238475, acc.: 60.94%] [G loss: 0.310806]\n",
      "epoch:20 step:18982 [D loss: 0.235709, acc.: 58.59%] [G loss: 0.288311]\n",
      "epoch:20 step:18983 [D loss: 0.257685, acc.: 52.34%] [G loss: 0.290547]\n",
      "epoch:20 step:18984 [D loss: 0.263555, acc.: 50.78%] [G loss: 0.276068]\n",
      "epoch:20 step:18985 [D loss: 0.247844, acc.: 54.69%] [G loss: 0.298926]\n",
      "epoch:20 step:18986 [D loss: 0.228137, acc.: 59.38%] [G loss: 0.312051]\n",
      "epoch:20 step:18987 [D loss: 0.239250, acc.: 59.38%] [G loss: 0.312539]\n",
      "epoch:20 step:18988 [D loss: 0.228016, acc.: 64.84%] [G loss: 0.329916]\n",
      "epoch:20 step:18989 [D loss: 0.251215, acc.: 54.69%] [G loss: 0.276173]\n",
      "epoch:20 step:18990 [D loss: 0.245805, acc.: 55.47%] [G loss: 0.283959]\n",
      "epoch:20 step:18991 [D loss: 0.238884, acc.: 58.59%] [G loss: 0.302832]\n",
      "epoch:20 step:18992 [D loss: 0.229722, acc.: 61.72%] [G loss: 0.318197]\n",
      "epoch:20 step:18993 [D loss: 0.242693, acc.: 57.03%] [G loss: 0.299157]\n",
      "epoch:20 step:18994 [D loss: 0.255434, acc.: 52.34%] [G loss: 0.296327]\n",
      "epoch:20 step:18995 [D loss: 0.223421, acc.: 66.41%] [G loss: 0.319446]\n",
      "epoch:20 step:18996 [D loss: 0.230277, acc.: 57.81%] [G loss: 0.302921]\n",
      "epoch:20 step:18997 [D loss: 0.245837, acc.: 60.16%] [G loss: 0.317858]\n",
      "epoch:20 step:18998 [D loss: 0.246410, acc.: 60.16%] [G loss: 0.302488]\n",
      "epoch:20 step:18999 [D loss: 0.256764, acc.: 51.56%] [G loss: 0.291178]\n",
      "epoch:20 step:19000 [D loss: 0.242078, acc.: 56.25%] [G loss: 0.293709]\n",
      "epoch:20 step:19001 [D loss: 0.233691, acc.: 64.06%] [G loss: 0.317801]\n",
      "epoch:20 step:19002 [D loss: 0.251171, acc.: 56.25%] [G loss: 0.290577]\n",
      "epoch:20 step:19003 [D loss: 0.236204, acc.: 63.28%] [G loss: 0.311233]\n",
      "epoch:20 step:19004 [D loss: 0.245061, acc.: 54.69%] [G loss: 0.297995]\n",
      "epoch:20 step:19005 [D loss: 0.240372, acc.: 60.16%] [G loss: 0.322377]\n",
      "epoch:20 step:19006 [D loss: 0.237357, acc.: 60.94%] [G loss: 0.293299]\n",
      "epoch:20 step:19007 [D loss: 0.235791, acc.: 57.03%] [G loss: 0.318696]\n",
      "epoch:20 step:19008 [D loss: 0.235361, acc.: 63.28%] [G loss: 0.335059]\n",
      "epoch:20 step:19009 [D loss: 0.205877, acc.: 69.53%] [G loss: 0.323702]\n",
      "epoch:20 step:19010 [D loss: 0.240747, acc.: 57.03%] [G loss: 0.329238]\n",
      "epoch:20 step:19011 [D loss: 0.243169, acc.: 50.78%] [G loss: 0.321727]\n",
      "epoch:20 step:19012 [D loss: 0.250575, acc.: 55.47%] [G loss: 0.288504]\n",
      "epoch:20 step:19013 [D loss: 0.235079, acc.: 61.72%] [G loss: 0.292217]\n",
      "epoch:20 step:19014 [D loss: 0.229303, acc.: 65.62%] [G loss: 0.302705]\n",
      "epoch:20 step:19015 [D loss: 0.245598, acc.: 53.91%] [G loss: 0.296231]\n",
      "epoch:20 step:19016 [D loss: 0.243142, acc.: 53.91%] [G loss: 0.293891]\n",
      "epoch:20 step:19017 [D loss: 0.231110, acc.: 56.25%] [G loss: 0.322238]\n",
      "epoch:20 step:19018 [D loss: 0.252616, acc.: 52.34%] [G loss: 0.320481]\n",
      "epoch:20 step:19019 [D loss: 0.232600, acc.: 59.38%] [G loss: 0.279901]\n",
      "epoch:20 step:19020 [D loss: 0.263774, acc.: 48.44%] [G loss: 0.294871]\n",
      "epoch:20 step:19021 [D loss: 0.239427, acc.: 59.38%] [G loss: 0.295350]\n",
      "epoch:20 step:19022 [D loss: 0.225687, acc.: 58.59%] [G loss: 0.277079]\n",
      "epoch:20 step:19023 [D loss: 0.246087, acc.: 54.69%] [G loss: 0.301951]\n",
      "epoch:20 step:19024 [D loss: 0.227100, acc.: 65.62%] [G loss: 0.290044]\n",
      "epoch:20 step:19025 [D loss: 0.230539, acc.: 64.84%] [G loss: 0.304692]\n",
      "epoch:20 step:19026 [D loss: 0.217779, acc.: 69.53%] [G loss: 0.334154]\n",
      "epoch:20 step:19027 [D loss: 0.242299, acc.: 55.47%] [G loss: 0.310321]\n",
      "epoch:20 step:19028 [D loss: 0.242754, acc.: 59.38%] [G loss: 0.306445]\n",
      "epoch:20 step:19029 [D loss: 0.241208, acc.: 61.72%] [G loss: 0.317838]\n",
      "epoch:20 step:19030 [D loss: 0.240974, acc.: 59.38%] [G loss: 0.315711]\n",
      "epoch:20 step:19031 [D loss: 0.251442, acc.: 55.47%] [G loss: 0.280813]\n",
      "epoch:20 step:19032 [D loss: 0.245335, acc.: 57.03%] [G loss: 0.292761]\n",
      "epoch:20 step:19033 [D loss: 0.258937, acc.: 51.56%] [G loss: 0.302795]\n",
      "epoch:20 step:19034 [D loss: 0.248979, acc.: 56.25%] [G loss: 0.311249]\n",
      "epoch:20 step:19035 [D loss: 0.222224, acc.: 62.50%] [G loss: 0.317290]\n",
      "epoch:20 step:19036 [D loss: 0.239944, acc.: 60.16%] [G loss: 0.322980]\n",
      "epoch:20 step:19037 [D loss: 0.237795, acc.: 50.78%] [G loss: 0.297337]\n",
      "epoch:20 step:19038 [D loss: 0.250754, acc.: 52.34%] [G loss: 0.314070]\n",
      "epoch:20 step:19039 [D loss: 0.245947, acc.: 53.91%] [G loss: 0.280102]\n",
      "epoch:20 step:19040 [D loss: 0.234414, acc.: 60.94%] [G loss: 0.307640]\n",
      "epoch:20 step:19041 [D loss: 0.245241, acc.: 57.81%] [G loss: 0.297215]\n",
      "epoch:20 step:19042 [D loss: 0.242240, acc.: 53.91%] [G loss: 0.317012]\n",
      "epoch:20 step:19043 [D loss: 0.259529, acc.: 49.22%] [G loss: 0.285317]\n",
      "epoch:20 step:19044 [D loss: 0.224610, acc.: 62.50%] [G loss: 0.312937]\n",
      "epoch:20 step:19045 [D loss: 0.240334, acc.: 63.28%] [G loss: 0.314810]\n",
      "epoch:20 step:19046 [D loss: 0.240888, acc.: 55.47%] [G loss: 0.309636]\n",
      "epoch:20 step:19047 [D loss: 0.240750, acc.: 56.25%] [G loss: 0.306470]\n",
      "epoch:20 step:19048 [D loss: 0.239272, acc.: 57.03%] [G loss: 0.263860]\n",
      "epoch:20 step:19049 [D loss: 0.219304, acc.: 65.62%] [G loss: 0.308544]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:20 step:19050 [D loss: 0.233608, acc.: 60.16%] [G loss: 0.313997]\n",
      "epoch:20 step:19051 [D loss: 0.241888, acc.: 52.34%] [G loss: 0.311736]\n",
      "epoch:20 step:19052 [D loss: 0.233490, acc.: 57.03%] [G loss: 0.311507]\n",
      "epoch:20 step:19053 [D loss: 0.229670, acc.: 61.72%] [G loss: 0.282705]\n",
      "epoch:20 step:19054 [D loss: 0.238516, acc.: 58.59%] [G loss: 0.299573]\n",
      "epoch:20 step:19055 [D loss: 0.237382, acc.: 58.59%] [G loss: 0.276932]\n",
      "epoch:20 step:19056 [D loss: 0.246976, acc.: 57.81%] [G loss: 0.308840]\n",
      "epoch:20 step:19057 [D loss: 0.239111, acc.: 57.03%] [G loss: 0.302204]\n",
      "epoch:20 step:19058 [D loss: 0.238573, acc.: 58.59%] [G loss: 0.292564]\n",
      "epoch:20 step:19059 [D loss: 0.237717, acc.: 57.81%] [G loss: 0.304666]\n",
      "epoch:20 step:19060 [D loss: 0.257596, acc.: 50.78%] [G loss: 0.315344]\n",
      "epoch:20 step:19061 [D loss: 0.242626, acc.: 62.50%] [G loss: 0.299869]\n",
      "epoch:20 step:19062 [D loss: 0.254152, acc.: 50.78%] [G loss: 0.304119]\n",
      "epoch:20 step:19063 [D loss: 0.239333, acc.: 55.47%] [G loss: 0.302896]\n",
      "epoch:20 step:19064 [D loss: 0.231123, acc.: 63.28%] [G loss: 0.280589]\n",
      "epoch:20 step:19065 [D loss: 0.245366, acc.: 53.12%] [G loss: 0.263905]\n",
      "epoch:20 step:19066 [D loss: 0.241194, acc.: 58.59%] [G loss: 0.318020]\n",
      "epoch:20 step:19067 [D loss: 0.257258, acc.: 51.56%] [G loss: 0.286624]\n",
      "epoch:20 step:19068 [D loss: 0.236535, acc.: 60.16%] [G loss: 0.345614]\n",
      "epoch:20 step:19069 [D loss: 0.248089, acc.: 53.12%] [G loss: 0.321166]\n",
      "epoch:20 step:19070 [D loss: 0.238179, acc.: 61.72%] [G loss: 0.289961]\n",
      "epoch:20 step:19071 [D loss: 0.232349, acc.: 60.94%] [G loss: 0.334610]\n",
      "epoch:20 step:19072 [D loss: 0.233026, acc.: 58.59%] [G loss: 0.301338]\n",
      "epoch:20 step:19073 [D loss: 0.235522, acc.: 60.94%] [G loss: 0.297396]\n",
      "epoch:20 step:19074 [D loss: 0.237840, acc.: 59.38%] [G loss: 0.309079]\n",
      "epoch:20 step:19075 [D loss: 0.251637, acc.: 59.38%] [G loss: 0.296176]\n",
      "epoch:20 step:19076 [D loss: 0.230197, acc.: 60.94%] [G loss: 0.278446]\n",
      "epoch:20 step:19077 [D loss: 0.260206, acc.: 54.69%] [G loss: 0.304888]\n",
      "epoch:20 step:19078 [D loss: 0.239387, acc.: 60.16%] [G loss: 0.311974]\n",
      "epoch:20 step:19079 [D loss: 0.241164, acc.: 60.16%] [G loss: 0.314890]\n",
      "epoch:20 step:19080 [D loss: 0.243662, acc.: 57.81%] [G loss: 0.312441]\n",
      "epoch:20 step:19081 [D loss: 0.236323, acc.: 57.03%] [G loss: 0.293124]\n",
      "epoch:20 step:19082 [D loss: 0.246911, acc.: 56.25%] [G loss: 0.266479]\n",
      "epoch:20 step:19083 [D loss: 0.247279, acc.: 50.78%] [G loss: 0.307051]\n",
      "epoch:20 step:19084 [D loss: 0.243223, acc.: 59.38%] [G loss: 0.312630]\n",
      "epoch:20 step:19085 [D loss: 0.226185, acc.: 62.50%] [G loss: 0.318940]\n",
      "epoch:20 step:19086 [D loss: 0.243380, acc.: 56.25%] [G loss: 0.318055]\n",
      "epoch:20 step:19087 [D loss: 0.242307, acc.: 60.94%] [G loss: 0.288859]\n",
      "epoch:20 step:19088 [D loss: 0.234032, acc.: 58.59%] [G loss: 0.283042]\n",
      "epoch:20 step:19089 [D loss: 0.229102, acc.: 67.19%] [G loss: 0.305285]\n",
      "epoch:20 step:19090 [D loss: 0.252879, acc.: 49.22%] [G loss: 0.288957]\n",
      "epoch:20 step:19091 [D loss: 0.242859, acc.: 55.47%] [G loss: 0.301590]\n",
      "epoch:20 step:19092 [D loss: 0.239742, acc.: 54.69%] [G loss: 0.291843]\n",
      "epoch:20 step:19093 [D loss: 0.237934, acc.: 58.59%] [G loss: 0.313597]\n",
      "epoch:20 step:19094 [D loss: 0.236090, acc.: 59.38%] [G loss: 0.289761]\n",
      "epoch:20 step:19095 [D loss: 0.238406, acc.: 56.25%] [G loss: 0.278204]\n",
      "epoch:20 step:19096 [D loss: 0.229088, acc.: 63.28%] [G loss: 0.305256]\n",
      "epoch:20 step:19097 [D loss: 0.247535, acc.: 55.47%] [G loss: 0.308215]\n",
      "epoch:20 step:19098 [D loss: 0.237117, acc.: 54.69%] [G loss: 0.323850]\n",
      "epoch:20 step:19099 [D loss: 0.254276, acc.: 51.56%] [G loss: 0.290989]\n",
      "epoch:20 step:19100 [D loss: 0.235613, acc.: 57.03%] [G loss: 0.284345]\n",
      "epoch:20 step:19101 [D loss: 0.249041, acc.: 51.56%] [G loss: 0.332200]\n",
      "epoch:20 step:19102 [D loss: 0.246802, acc.: 58.59%] [G loss: 0.302786]\n",
      "epoch:20 step:19103 [D loss: 0.241891, acc.: 56.25%] [G loss: 0.309001]\n",
      "epoch:20 step:19104 [D loss: 0.239328, acc.: 63.28%] [G loss: 0.291281]\n",
      "epoch:20 step:19105 [D loss: 0.232927, acc.: 58.59%] [G loss: 0.307595]\n",
      "epoch:20 step:19106 [D loss: 0.252437, acc.: 53.12%] [G loss: 0.289364]\n",
      "epoch:20 step:19107 [D loss: 0.228136, acc.: 58.59%] [G loss: 0.329618]\n",
      "epoch:20 step:19108 [D loss: 0.239103, acc.: 60.16%] [G loss: 0.307671]\n",
      "epoch:20 step:19109 [D loss: 0.243002, acc.: 53.12%] [G loss: 0.300605]\n",
      "epoch:20 step:19110 [D loss: 0.244391, acc.: 56.25%] [G loss: 0.295126]\n",
      "epoch:20 step:19111 [D loss: 0.245872, acc.: 58.59%] [G loss: 0.288345]\n",
      "epoch:20 step:19112 [D loss: 0.240764, acc.: 60.94%] [G loss: 0.285394]\n",
      "epoch:20 step:19113 [D loss: 0.234140, acc.: 64.06%] [G loss: 0.299130]\n",
      "epoch:20 step:19114 [D loss: 0.263733, acc.: 48.44%] [G loss: 0.295748]\n",
      "epoch:20 step:19115 [D loss: 0.226505, acc.: 62.50%] [G loss: 0.333691]\n",
      "epoch:20 step:19116 [D loss: 0.234513, acc.: 64.84%] [G loss: 0.290611]\n",
      "epoch:20 step:19117 [D loss: 0.236101, acc.: 57.03%] [G loss: 0.302143]\n",
      "epoch:20 step:19118 [D loss: 0.241030, acc.: 60.94%] [G loss: 0.308183]\n",
      "epoch:20 step:19119 [D loss: 0.249557, acc.: 52.34%] [G loss: 0.278731]\n",
      "epoch:20 step:19120 [D loss: 0.232757, acc.: 61.72%] [G loss: 0.293466]\n",
      "epoch:20 step:19121 [D loss: 0.244489, acc.: 53.91%] [G loss: 0.290184]\n",
      "epoch:20 step:19122 [D loss: 0.238029, acc.: 58.59%] [G loss: 0.300698]\n",
      "epoch:20 step:19123 [D loss: 0.254021, acc.: 50.78%] [G loss: 0.298225]\n",
      "epoch:20 step:19124 [D loss: 0.229374, acc.: 67.19%] [G loss: 0.297426]\n",
      "epoch:20 step:19125 [D loss: 0.236071, acc.: 57.81%] [G loss: 0.288831]\n",
      "epoch:20 step:19126 [D loss: 0.237646, acc.: 62.50%] [G loss: 0.314919]\n",
      "epoch:20 step:19127 [D loss: 0.245683, acc.: 53.91%] [G loss: 0.290297]\n",
      "epoch:20 step:19128 [D loss: 0.238006, acc.: 60.94%] [G loss: 0.311969]\n",
      "epoch:20 step:19129 [D loss: 0.228410, acc.: 56.25%] [G loss: 0.331215]\n",
      "epoch:20 step:19130 [D loss: 0.230095, acc.: 65.62%] [G loss: 0.313433]\n",
      "epoch:20 step:19131 [D loss: 0.240304, acc.: 58.59%] [G loss: 0.314022]\n",
      "epoch:20 step:19132 [D loss: 0.228973, acc.: 59.38%] [G loss: 0.299946]\n",
      "epoch:20 step:19133 [D loss: 0.226730, acc.: 61.72%] [G loss: 0.301086]\n",
      "epoch:20 step:19134 [D loss: 0.235135, acc.: 63.28%] [G loss: 0.311234]\n",
      "epoch:20 step:19135 [D loss: 0.212943, acc.: 67.97%] [G loss: 0.316888]\n",
      "epoch:20 step:19136 [D loss: 0.226516, acc.: 61.72%] [G loss: 0.303180]\n",
      "epoch:20 step:19137 [D loss: 0.254017, acc.: 56.25%] [G loss: 0.332677]\n",
      "epoch:20 step:19138 [D loss: 0.237450, acc.: 57.03%] [G loss: 0.301798]\n",
      "epoch:20 step:19139 [D loss: 0.233068, acc.: 60.94%] [G loss: 0.306497]\n",
      "epoch:20 step:19140 [D loss: 0.241732, acc.: 59.38%] [G loss: 0.282382]\n",
      "epoch:20 step:19141 [D loss: 0.236404, acc.: 57.81%] [G loss: 0.276489]\n",
      "epoch:20 step:19142 [D loss: 0.225204, acc.: 67.19%] [G loss: 0.299368]\n",
      "epoch:20 step:19143 [D loss: 0.258736, acc.: 48.44%] [G loss: 0.289295]\n",
      "epoch:20 step:19144 [D loss: 0.236775, acc.: 58.59%] [G loss: 0.283784]\n",
      "epoch:20 step:19145 [D loss: 0.245813, acc.: 57.03%] [G loss: 0.277017]\n",
      "epoch:20 step:19146 [D loss: 0.221992, acc.: 60.16%] [G loss: 0.290126]\n",
      "epoch:20 step:19147 [D loss: 0.217299, acc.: 64.06%] [G loss: 0.281025]\n",
      "epoch:20 step:19148 [D loss: 0.239516, acc.: 60.16%] [G loss: 0.310659]\n",
      "epoch:20 step:19149 [D loss: 0.244992, acc.: 58.59%] [G loss: 0.297070]\n",
      "epoch:20 step:19150 [D loss: 0.245683, acc.: 51.56%] [G loss: 0.321615]\n",
      "epoch:20 step:19151 [D loss: 0.235549, acc.: 60.94%] [G loss: 0.295341]\n",
      "epoch:20 step:19152 [D loss: 0.258943, acc.: 52.34%] [G loss: 0.312175]\n",
      "epoch:20 step:19153 [D loss: 0.246721, acc.: 56.25%] [G loss: 0.297802]\n",
      "epoch:20 step:19154 [D loss: 0.238481, acc.: 57.03%] [G loss: 0.295263]\n",
      "epoch:20 step:19155 [D loss: 0.249677, acc.: 58.59%] [G loss: 0.280799]\n",
      "epoch:20 step:19156 [D loss: 0.222589, acc.: 64.84%] [G loss: 0.327694]\n",
      "epoch:20 step:19157 [D loss: 0.236043, acc.: 59.38%] [G loss: 0.283372]\n",
      "epoch:20 step:19158 [D loss: 0.246385, acc.: 56.25%] [G loss: 0.301146]\n",
      "epoch:20 step:19159 [D loss: 0.235266, acc.: 61.72%] [G loss: 0.323466]\n",
      "epoch:20 step:19160 [D loss: 0.239657, acc.: 60.16%] [G loss: 0.316155]\n",
      "epoch:20 step:19161 [D loss: 0.246291, acc.: 57.03%] [G loss: 0.289262]\n",
      "epoch:20 step:19162 [D loss: 0.231335, acc.: 62.50%] [G loss: 0.294369]\n",
      "epoch:20 step:19163 [D loss: 0.237691, acc.: 56.25%] [G loss: 0.292867]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:20 step:19164 [D loss: 0.217909, acc.: 68.75%] [G loss: 0.289898]\n",
      "epoch:20 step:19165 [D loss: 0.240078, acc.: 56.25%] [G loss: 0.325141]\n",
      "epoch:20 step:19166 [D loss: 0.247073, acc.: 55.47%] [G loss: 0.308507]\n",
      "epoch:20 step:19167 [D loss: 0.261453, acc.: 57.81%] [G loss: 0.293307]\n",
      "epoch:20 step:19168 [D loss: 0.223249, acc.: 60.16%] [G loss: 0.326052]\n",
      "epoch:20 step:19169 [D loss: 0.258419, acc.: 50.00%] [G loss: 0.298251]\n",
      "epoch:20 step:19170 [D loss: 0.236492, acc.: 60.16%] [G loss: 0.307138]\n",
      "epoch:20 step:19171 [D loss: 0.241157, acc.: 56.25%] [G loss: 0.280284]\n",
      "epoch:20 step:19172 [D loss: 0.229440, acc.: 62.50%] [G loss: 0.286648]\n",
      "epoch:20 step:19173 [D loss: 0.253891, acc.: 53.12%] [G loss: 0.305538]\n",
      "epoch:20 step:19174 [D loss: 0.248627, acc.: 56.25%] [G loss: 0.293543]\n",
      "epoch:20 step:19175 [D loss: 0.232746, acc.: 57.03%] [G loss: 0.278408]\n",
      "epoch:20 step:19176 [D loss: 0.241503, acc.: 62.50%] [G loss: 0.300391]\n",
      "epoch:20 step:19177 [D loss: 0.223808, acc.: 64.06%] [G loss: 0.333132]\n",
      "epoch:20 step:19178 [D loss: 0.259702, acc.: 53.91%] [G loss: 0.291992]\n",
      "epoch:20 step:19179 [D loss: 0.246295, acc.: 56.25%] [G loss: 0.291390]\n",
      "epoch:20 step:19180 [D loss: 0.224728, acc.: 64.06%] [G loss: 0.282647]\n",
      "epoch:20 step:19181 [D loss: 0.234063, acc.: 57.81%] [G loss: 0.331122]\n",
      "epoch:20 step:19182 [D loss: 0.250398, acc.: 54.69%] [G loss: 0.307495]\n",
      "epoch:20 step:19183 [D loss: 0.245910, acc.: 57.03%] [G loss: 0.292226]\n",
      "epoch:20 step:19184 [D loss: 0.245360, acc.: 55.47%] [G loss: 0.287516]\n",
      "epoch:20 step:19185 [D loss: 0.227870, acc.: 57.81%] [G loss: 0.299602]\n",
      "epoch:20 step:19186 [D loss: 0.235811, acc.: 55.47%] [G loss: 0.296050]\n",
      "epoch:20 step:19187 [D loss: 0.228871, acc.: 65.62%] [G loss: 0.307362]\n",
      "epoch:20 step:19188 [D loss: 0.234583, acc.: 62.50%] [G loss: 0.317534]\n",
      "epoch:20 step:19189 [D loss: 0.234835, acc.: 59.38%] [G loss: 0.322120]\n",
      "epoch:20 step:19190 [D loss: 0.234601, acc.: 64.84%] [G loss: 0.311647]\n",
      "epoch:20 step:19191 [D loss: 0.227967, acc.: 60.94%] [G loss: 0.300216]\n",
      "epoch:20 step:19192 [D loss: 0.230945, acc.: 61.72%] [G loss: 0.283539]\n",
      "epoch:20 step:19193 [D loss: 0.237683, acc.: 57.03%] [G loss: 0.290594]\n",
      "epoch:20 step:19194 [D loss: 0.214914, acc.: 65.62%] [G loss: 0.301524]\n",
      "epoch:20 step:19195 [D loss: 0.253372, acc.: 53.91%] [G loss: 0.335633]\n",
      "epoch:20 step:19196 [D loss: 0.232089, acc.: 64.84%] [G loss: 0.291496]\n",
      "epoch:20 step:19197 [D loss: 0.239558, acc.: 53.91%] [G loss: 0.321261]\n",
      "epoch:20 step:19198 [D loss: 0.237196, acc.: 60.94%] [G loss: 0.302367]\n",
      "epoch:20 step:19199 [D loss: 0.235097, acc.: 63.28%] [G loss: 0.290188]\n",
      "epoch:20 step:19200 [D loss: 0.244654, acc.: 57.03%] [G loss: 0.313287]\n",
      "epoch:20 step:19201 [D loss: 0.254808, acc.: 50.00%] [G loss: 0.299076]\n",
      "epoch:20 step:19202 [D loss: 0.241557, acc.: 60.16%] [G loss: 0.285004]\n",
      "epoch:20 step:19203 [D loss: 0.233394, acc.: 57.81%] [G loss: 0.283580]\n",
      "epoch:20 step:19204 [D loss: 0.251785, acc.: 53.91%] [G loss: 0.329368]\n",
      "epoch:20 step:19205 [D loss: 0.234885, acc.: 58.59%] [G loss: 0.306729]\n",
      "epoch:20 step:19206 [D loss: 0.236259, acc.: 57.81%] [G loss: 0.322726]\n",
      "epoch:20 step:19207 [D loss: 0.232109, acc.: 57.81%] [G loss: 0.312626]\n",
      "epoch:20 step:19208 [D loss: 0.247847, acc.: 53.91%] [G loss: 0.255617]\n",
      "epoch:20 step:19209 [D loss: 0.230607, acc.: 62.50%] [G loss: 0.290543]\n",
      "epoch:20 step:19210 [D loss: 0.259622, acc.: 52.34%] [G loss: 0.300417]\n",
      "epoch:20 step:19211 [D loss: 0.229719, acc.: 62.50%] [G loss: 0.307429]\n",
      "epoch:20 step:19212 [D loss: 0.249498, acc.: 53.91%] [G loss: 0.310184]\n",
      "epoch:20 step:19213 [D loss: 0.219346, acc.: 66.41%] [G loss: 0.315295]\n",
      "epoch:20 step:19214 [D loss: 0.221031, acc.: 65.62%] [G loss: 0.309114]\n",
      "epoch:20 step:19215 [D loss: 0.236640, acc.: 60.16%] [G loss: 0.318206]\n",
      "epoch:20 step:19216 [D loss: 0.230808, acc.: 60.16%] [G loss: 0.324258]\n",
      "epoch:20 step:19217 [D loss: 0.251375, acc.: 56.25%] [G loss: 0.283443]\n",
      "epoch:20 step:19218 [D loss: 0.235310, acc.: 60.16%] [G loss: 0.296923]\n",
      "epoch:20 step:19219 [D loss: 0.256626, acc.: 50.78%] [G loss: 0.276533]\n",
      "epoch:20 step:19220 [D loss: 0.237917, acc.: 57.03%] [G loss: 0.281533]\n",
      "epoch:20 step:19221 [D loss: 0.240992, acc.: 62.50%] [G loss: 0.316656]\n",
      "epoch:20 step:19222 [D loss: 0.242043, acc.: 55.47%] [G loss: 0.299786]\n",
      "epoch:20 step:19223 [D loss: 0.251838, acc.: 57.81%] [G loss: 0.284933]\n",
      "epoch:20 step:19224 [D loss: 0.235605, acc.: 62.50%] [G loss: 0.276963]\n",
      "epoch:20 step:19225 [D loss: 0.235269, acc.: 59.38%] [G loss: 0.304133]\n",
      "epoch:20 step:19226 [D loss: 0.208397, acc.: 71.09%] [G loss: 0.318772]\n",
      "epoch:20 step:19227 [D loss: 0.237578, acc.: 57.81%] [G loss: 0.310256]\n",
      "epoch:20 step:19228 [D loss: 0.226366, acc.: 64.84%] [G loss: 0.312776]\n",
      "epoch:20 step:19229 [D loss: 0.245893, acc.: 56.25%] [G loss: 0.307670]\n",
      "epoch:20 step:19230 [D loss: 0.246954, acc.: 54.69%] [G loss: 0.321767]\n",
      "epoch:20 step:19231 [D loss: 0.239336, acc.: 52.34%] [G loss: 0.301744]\n",
      "epoch:20 step:19232 [D loss: 0.255909, acc.: 51.56%] [G loss: 0.298281]\n",
      "epoch:20 step:19233 [D loss: 0.225658, acc.: 64.84%] [G loss: 0.299115]\n",
      "epoch:20 step:19234 [D loss: 0.221754, acc.: 66.41%] [G loss: 0.297148]\n",
      "epoch:20 step:19235 [D loss: 0.243222, acc.: 55.47%] [G loss: 0.295141]\n",
      "epoch:20 step:19236 [D loss: 0.243229, acc.: 58.59%] [G loss: 0.324769]\n",
      "epoch:20 step:19237 [D loss: 0.226965, acc.: 60.16%] [G loss: 0.324096]\n",
      "epoch:20 step:19238 [D loss: 0.232868, acc.: 60.94%] [G loss: 0.323435]\n",
      "epoch:20 step:19239 [D loss: 0.232556, acc.: 63.28%] [G loss: 0.320621]\n",
      "epoch:20 step:19240 [D loss: 0.259877, acc.: 50.00%] [G loss: 0.311956]\n",
      "epoch:20 step:19241 [D loss: 0.239043, acc.: 59.38%] [G loss: 0.319210]\n",
      "epoch:20 step:19242 [D loss: 0.221102, acc.: 59.38%] [G loss: 0.309076]\n",
      "epoch:20 step:19243 [D loss: 0.227157, acc.: 64.06%] [G loss: 0.317713]\n",
      "epoch:20 step:19244 [D loss: 0.238361, acc.: 61.72%] [G loss: 0.310429]\n",
      "epoch:20 step:19245 [D loss: 0.257644, acc.: 50.78%] [G loss: 0.302229]\n",
      "epoch:20 step:19246 [D loss: 0.232439, acc.: 64.06%] [G loss: 0.325052]\n",
      "epoch:20 step:19247 [D loss: 0.236901, acc.: 60.16%] [G loss: 0.299113]\n",
      "epoch:20 step:19248 [D loss: 0.242820, acc.: 57.81%] [G loss: 0.306310]\n",
      "epoch:20 step:19249 [D loss: 0.231744, acc.: 64.06%] [G loss: 0.309477]\n",
      "epoch:20 step:19250 [D loss: 0.227853, acc.: 62.50%] [G loss: 0.297398]\n",
      "epoch:20 step:19251 [D loss: 0.253014, acc.: 55.47%] [G loss: 0.321474]\n",
      "epoch:20 step:19252 [D loss: 0.233790, acc.: 66.41%] [G loss: 0.310396]\n",
      "epoch:20 step:19253 [D loss: 0.226103, acc.: 60.16%] [G loss: 0.278207]\n",
      "epoch:20 step:19254 [D loss: 0.227505, acc.: 60.94%] [G loss: 0.316549]\n",
      "epoch:20 step:19255 [D loss: 0.247109, acc.: 50.78%] [G loss: 0.322248]\n",
      "epoch:20 step:19256 [D loss: 0.238269, acc.: 60.94%] [G loss: 0.289629]\n",
      "epoch:20 step:19257 [D loss: 0.246986, acc.: 54.69%] [G loss: 0.311599]\n",
      "epoch:20 step:19258 [D loss: 0.248612, acc.: 56.25%] [G loss: 0.295894]\n",
      "epoch:20 step:19259 [D loss: 0.228796, acc.: 64.84%] [G loss: 0.319695]\n",
      "epoch:20 step:19260 [D loss: 0.232301, acc.: 60.94%] [G loss: 0.309686]\n",
      "epoch:20 step:19261 [D loss: 0.247403, acc.: 57.03%] [G loss: 0.309337]\n",
      "epoch:20 step:19262 [D loss: 0.240556, acc.: 57.03%] [G loss: 0.316451]\n",
      "epoch:20 step:19263 [D loss: 0.219284, acc.: 65.62%] [G loss: 0.311151]\n",
      "epoch:20 step:19264 [D loss: 0.216874, acc.: 64.84%] [G loss: 0.293258]\n",
      "epoch:20 step:19265 [D loss: 0.229798, acc.: 64.06%] [G loss: 0.312884]\n",
      "epoch:20 step:19266 [D loss: 0.249263, acc.: 51.56%] [G loss: 0.321125]\n",
      "epoch:20 step:19267 [D loss: 0.250955, acc.: 56.25%] [G loss: 0.291219]\n",
      "epoch:20 step:19268 [D loss: 0.231247, acc.: 64.84%] [G loss: 0.315822]\n",
      "epoch:20 step:19269 [D loss: 0.229681, acc.: 62.50%] [G loss: 0.296268]\n",
      "epoch:20 step:19270 [D loss: 0.247016, acc.: 57.03%] [G loss: 0.253624]\n",
      "epoch:20 step:19271 [D loss: 0.229278, acc.: 66.41%] [G loss: 0.274045]\n",
      "epoch:20 step:19272 [D loss: 0.233513, acc.: 59.38%] [G loss: 0.284864]\n",
      "epoch:20 step:19273 [D loss: 0.238698, acc.: 61.72%] [G loss: 0.312846]\n",
      "epoch:20 step:19274 [D loss: 0.240390, acc.: 53.91%] [G loss: 0.307939]\n",
      "epoch:20 step:19275 [D loss: 0.249372, acc.: 53.91%] [G loss: 0.303169]\n",
      "epoch:20 step:19276 [D loss: 0.234256, acc.: 58.59%] [G loss: 0.309969]\n",
      "epoch:20 step:19277 [D loss: 0.236159, acc.: 59.38%] [G loss: 0.329067]\n",
      "epoch:20 step:19278 [D loss: 0.278203, acc.: 46.09%] [G loss: 0.315707]\n",
      "epoch:20 step:19279 [D loss: 0.216710, acc.: 63.28%] [G loss: 0.307259]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:20 step:19280 [D loss: 0.242088, acc.: 59.38%] [G loss: 0.339995]\n",
      "epoch:20 step:19281 [D loss: 0.235247, acc.: 62.50%] [G loss: 0.298593]\n",
      "epoch:20 step:19282 [D loss: 0.222657, acc.: 66.41%] [G loss: 0.288473]\n",
      "epoch:20 step:19283 [D loss: 0.267017, acc.: 45.31%] [G loss: 0.293615]\n",
      "epoch:20 step:19284 [D loss: 0.245672, acc.: 57.03%] [G loss: 0.289807]\n",
      "epoch:20 step:19285 [D loss: 0.215821, acc.: 62.50%] [G loss: 0.304360]\n",
      "epoch:20 step:19286 [D loss: 0.252548, acc.: 53.91%] [G loss: 0.342643]\n",
      "epoch:20 step:19287 [D loss: 0.240255, acc.: 53.12%] [G loss: 0.312806]\n",
      "epoch:20 step:19288 [D loss: 0.252679, acc.: 53.12%] [G loss: 0.269674]\n",
      "epoch:20 step:19289 [D loss: 0.262558, acc.: 53.12%] [G loss: 0.294429]\n",
      "epoch:20 step:19290 [D loss: 0.256127, acc.: 49.22%] [G loss: 0.310724]\n",
      "epoch:20 step:19291 [D loss: 0.243024, acc.: 57.03%] [G loss: 0.313999]\n",
      "epoch:20 step:19292 [D loss: 0.249247, acc.: 53.12%] [G loss: 0.288397]\n",
      "epoch:20 step:19293 [D loss: 0.236591, acc.: 60.94%] [G loss: 0.312356]\n",
      "epoch:20 step:19294 [D loss: 0.248606, acc.: 57.81%] [G loss: 0.299911]\n",
      "epoch:20 step:19295 [D loss: 0.230049, acc.: 58.59%] [G loss: 0.318647]\n",
      "epoch:20 step:19296 [D loss: 0.246056, acc.: 58.59%] [G loss: 0.276832]\n",
      "epoch:20 step:19297 [D loss: 0.230748, acc.: 65.62%] [G loss: 0.275355]\n",
      "epoch:20 step:19298 [D loss: 0.237976, acc.: 61.72%] [G loss: 0.304354]\n",
      "epoch:20 step:19299 [D loss: 0.237325, acc.: 60.94%] [G loss: 0.311332]\n",
      "epoch:20 step:19300 [D loss: 0.228600, acc.: 62.50%] [G loss: 0.294227]\n",
      "epoch:20 step:19301 [D loss: 0.244377, acc.: 60.94%] [G loss: 0.305220]\n",
      "epoch:20 step:19302 [D loss: 0.235013, acc.: 57.03%] [G loss: 0.282011]\n",
      "epoch:20 step:19303 [D loss: 0.230288, acc.: 64.06%] [G loss: 0.323127]\n",
      "epoch:20 step:19304 [D loss: 0.225640, acc.: 59.38%] [G loss: 0.320013]\n",
      "epoch:20 step:19305 [D loss: 0.242287, acc.: 55.47%] [G loss: 0.298705]\n",
      "epoch:20 step:19306 [D loss: 0.240552, acc.: 58.59%] [G loss: 0.335969]\n",
      "epoch:20 step:19307 [D loss: 0.252900, acc.: 57.03%] [G loss: 0.319987]\n",
      "epoch:20 step:19308 [D loss: 0.228303, acc.: 58.59%] [G loss: 0.313327]\n",
      "epoch:20 step:19309 [D loss: 0.229459, acc.: 60.94%] [G loss: 0.343253]\n",
      "epoch:20 step:19310 [D loss: 0.224831, acc.: 62.50%] [G loss: 0.311140]\n",
      "epoch:20 step:19311 [D loss: 0.234640, acc.: 60.16%] [G loss: 0.309169]\n",
      "epoch:20 step:19312 [D loss: 0.224441, acc.: 59.38%] [G loss: 0.287235]\n",
      "epoch:20 step:19313 [D loss: 0.261843, acc.: 46.88%] [G loss: 0.259889]\n",
      "epoch:20 step:19314 [D loss: 0.231214, acc.: 59.38%] [G loss: 0.325077]\n",
      "epoch:20 step:19315 [D loss: 0.232759, acc.: 61.72%] [G loss: 0.326611]\n",
      "epoch:20 step:19316 [D loss: 0.242030, acc.: 59.38%] [G loss: 0.285724]\n",
      "epoch:20 step:19317 [D loss: 0.238331, acc.: 54.69%] [G loss: 0.302192]\n",
      "epoch:20 step:19318 [D loss: 0.235620, acc.: 60.16%] [G loss: 0.310781]\n",
      "epoch:20 step:19319 [D loss: 0.246621, acc.: 53.91%] [G loss: 0.311895]\n",
      "epoch:20 step:19320 [D loss: 0.242120, acc.: 57.81%] [G loss: 0.287244]\n",
      "epoch:20 step:19321 [D loss: 0.225866, acc.: 65.62%] [G loss: 0.318578]\n",
      "epoch:20 step:19322 [D loss: 0.236023, acc.: 60.16%] [G loss: 0.288720]\n",
      "epoch:20 step:19323 [D loss: 0.234429, acc.: 58.59%] [G loss: 0.308019]\n",
      "epoch:20 step:19324 [D loss: 0.241571, acc.: 60.16%] [G loss: 0.274128]\n",
      "epoch:20 step:19325 [D loss: 0.236694, acc.: 59.38%] [G loss: 0.307616]\n",
      "epoch:20 step:19326 [D loss: 0.248058, acc.: 55.47%] [G loss: 0.306011]\n",
      "epoch:20 step:19327 [D loss: 0.239862, acc.: 58.59%] [G loss: 0.299614]\n",
      "epoch:20 step:19328 [D loss: 0.227738, acc.: 62.50%] [G loss: 0.338242]\n",
      "epoch:20 step:19329 [D loss: 0.231637, acc.: 59.38%] [G loss: 0.317452]\n",
      "epoch:20 step:19330 [D loss: 0.242483, acc.: 55.47%] [G loss: 0.304437]\n",
      "epoch:20 step:19331 [D loss: 0.226839, acc.: 63.28%] [G loss: 0.337172]\n",
      "epoch:20 step:19332 [D loss: 0.233419, acc.: 60.16%] [G loss: 0.310682]\n",
      "epoch:20 step:19333 [D loss: 0.257400, acc.: 50.78%] [G loss: 0.303830]\n",
      "epoch:20 step:19334 [D loss: 0.231151, acc.: 66.41%] [G loss: 0.303808]\n",
      "epoch:20 step:19335 [D loss: 0.249541, acc.: 55.47%] [G loss: 0.290774]\n",
      "epoch:20 step:19336 [D loss: 0.224729, acc.: 66.41%] [G loss: 0.305189]\n",
      "epoch:20 step:19337 [D loss: 0.226409, acc.: 63.28%] [G loss: 0.314461]\n",
      "epoch:20 step:19338 [D loss: 0.239985, acc.: 58.59%] [G loss: 0.294613]\n",
      "epoch:20 step:19339 [D loss: 0.229052, acc.: 60.16%] [G loss: 0.280210]\n",
      "epoch:20 step:19340 [D loss: 0.233711, acc.: 58.59%] [G loss: 0.306497]\n",
      "epoch:20 step:19341 [D loss: 0.259239, acc.: 55.47%] [G loss: 0.295419]\n",
      "epoch:20 step:19342 [D loss: 0.211028, acc.: 67.97%] [G loss: 0.321360]\n",
      "epoch:20 step:19343 [D loss: 0.252030, acc.: 56.25%] [G loss: 0.277947]\n",
      "epoch:20 step:19344 [D loss: 0.253451, acc.: 54.69%] [G loss: 0.275304]\n",
      "epoch:20 step:19345 [D loss: 0.242143, acc.: 57.81%] [G loss: 0.286560]\n",
      "epoch:20 step:19346 [D loss: 0.239116, acc.: 56.25%] [G loss: 0.278092]\n",
      "epoch:20 step:19347 [D loss: 0.230429, acc.: 63.28%] [G loss: 0.327394]\n",
      "epoch:20 step:19348 [D loss: 0.247809, acc.: 50.78%] [G loss: 0.292771]\n",
      "epoch:20 step:19349 [D loss: 0.215771, acc.: 67.19%] [G loss: 0.290814]\n",
      "epoch:20 step:19350 [D loss: 0.247754, acc.: 50.00%] [G loss: 0.310608]\n",
      "epoch:20 step:19351 [D loss: 0.251431, acc.: 56.25%] [G loss: 0.300444]\n",
      "epoch:20 step:19352 [D loss: 0.227372, acc.: 60.16%] [G loss: 0.325052]\n",
      "epoch:20 step:19353 [D loss: 0.238416, acc.: 59.38%] [G loss: 0.299617]\n",
      "epoch:20 step:19354 [D loss: 0.242281, acc.: 55.47%] [G loss: 0.284188]\n",
      "epoch:20 step:19355 [D loss: 0.234202, acc.: 64.84%] [G loss: 0.281251]\n",
      "epoch:20 step:19356 [D loss: 0.215255, acc.: 69.53%] [G loss: 0.342585]\n",
      "epoch:20 step:19357 [D loss: 0.248358, acc.: 57.03%] [G loss: 0.294967]\n",
      "epoch:20 step:19358 [D loss: 0.234786, acc.: 64.84%] [G loss: 0.292004]\n",
      "epoch:20 step:19359 [D loss: 0.250130, acc.: 53.91%] [G loss: 0.318974]\n",
      "epoch:20 step:19360 [D loss: 0.239664, acc.: 53.91%] [G loss: 0.307620]\n",
      "epoch:20 step:19361 [D loss: 0.238976, acc.: 57.03%] [G loss: 0.299129]\n",
      "epoch:20 step:19362 [D loss: 0.250215, acc.: 53.91%] [G loss: 0.290318]\n",
      "epoch:20 step:19363 [D loss: 0.218423, acc.: 68.75%] [G loss: 0.314282]\n",
      "epoch:20 step:19364 [D loss: 0.257177, acc.: 53.12%] [G loss: 0.281506]\n",
      "epoch:20 step:19365 [D loss: 0.225565, acc.: 65.62%] [G loss: 0.295516]\n",
      "epoch:20 step:19366 [D loss: 0.250902, acc.: 50.78%] [G loss: 0.278690]\n",
      "epoch:20 step:19367 [D loss: 0.224788, acc.: 64.06%] [G loss: 0.318642]\n",
      "epoch:20 step:19368 [D loss: 0.236168, acc.: 57.03%] [G loss: 0.299089]\n",
      "epoch:20 step:19369 [D loss: 0.228444, acc.: 67.97%] [G loss: 0.316038]\n",
      "epoch:20 step:19370 [D loss: 0.252324, acc.: 56.25%] [G loss: 0.291998]\n",
      "epoch:20 step:19371 [D loss: 0.222385, acc.: 59.38%] [G loss: 0.294073]\n",
      "epoch:20 step:19372 [D loss: 0.218986, acc.: 69.53%] [G loss: 0.274611]\n",
      "epoch:20 step:19373 [D loss: 0.242682, acc.: 57.03%] [G loss: 0.300745]\n",
      "epoch:20 step:19374 [D loss: 0.225304, acc.: 62.50%] [G loss: 0.320478]\n",
      "epoch:20 step:19375 [D loss: 0.223272, acc.: 60.94%] [G loss: 0.309177]\n",
      "epoch:20 step:19376 [D loss: 0.234856, acc.: 62.50%] [G loss: 0.269922]\n",
      "epoch:20 step:19377 [D loss: 0.224707, acc.: 57.81%] [G loss: 0.326624]\n",
      "epoch:20 step:19378 [D loss: 0.240756, acc.: 54.69%] [G loss: 0.310627]\n",
      "epoch:20 step:19379 [D loss: 0.250886, acc.: 55.47%] [G loss: 0.311505]\n",
      "epoch:20 step:19380 [D loss: 0.240094, acc.: 55.47%] [G loss: 0.304507]\n",
      "epoch:20 step:19381 [D loss: 0.240096, acc.: 56.25%] [G loss: 0.314460]\n",
      "epoch:20 step:19382 [D loss: 0.258035, acc.: 45.31%] [G loss: 0.301060]\n",
      "epoch:20 step:19383 [D loss: 0.263255, acc.: 50.00%] [G loss: 0.321117]\n",
      "epoch:20 step:19384 [D loss: 0.247060, acc.: 53.91%] [G loss: 0.301429]\n",
      "epoch:20 step:19385 [D loss: 0.242204, acc.: 57.03%] [G loss: 0.304913]\n",
      "epoch:20 step:19386 [D loss: 0.235292, acc.: 57.81%] [G loss: 0.288026]\n",
      "epoch:20 step:19387 [D loss: 0.231614, acc.: 64.06%] [G loss: 0.315416]\n",
      "epoch:20 step:19388 [D loss: 0.233040, acc.: 57.81%] [G loss: 0.319354]\n",
      "epoch:20 step:19389 [D loss: 0.250437, acc.: 54.69%] [G loss: 0.273574]\n",
      "epoch:20 step:19390 [D loss: 0.228636, acc.: 63.28%] [G loss: 0.313956]\n",
      "epoch:20 step:19391 [D loss: 0.257452, acc.: 51.56%] [G loss: 0.290486]\n",
      "epoch:20 step:19392 [D loss: 0.236495, acc.: 59.38%] [G loss: 0.310719]\n",
      "epoch:20 step:19393 [D loss: 0.247559, acc.: 52.34%] [G loss: 0.319466]\n",
      "epoch:20 step:19394 [D loss: 0.238057, acc.: 57.81%] [G loss: 0.306434]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:20 step:19395 [D loss: 0.236110, acc.: 60.16%] [G loss: 0.300962]\n",
      "epoch:20 step:19396 [D loss: 0.230479, acc.: 56.25%] [G loss: 0.307844]\n",
      "epoch:20 step:19397 [D loss: 0.230188, acc.: 60.94%] [G loss: 0.337713]\n",
      "epoch:20 step:19398 [D loss: 0.252946, acc.: 57.81%] [G loss: 0.287943]\n",
      "epoch:20 step:19399 [D loss: 0.232378, acc.: 54.69%] [G loss: 0.306089]\n",
      "epoch:20 step:19400 [D loss: 0.235039, acc.: 59.38%] [G loss: 0.298147]\n",
      "epoch:20 step:19401 [D loss: 0.237944, acc.: 57.81%] [G loss: 0.296062]\n",
      "epoch:20 step:19402 [D loss: 0.241139, acc.: 56.25%] [G loss: 0.288757]\n",
      "epoch:20 step:19403 [D loss: 0.261869, acc.: 51.56%] [G loss: 0.303608]\n",
      "epoch:20 step:19404 [D loss: 0.237472, acc.: 59.38%] [G loss: 0.293417]\n",
      "epoch:20 step:19405 [D loss: 0.239594, acc.: 59.38%] [G loss: 0.314287]\n",
      "epoch:20 step:19406 [D loss: 0.221784, acc.: 64.84%] [G loss: 0.304861]\n",
      "epoch:20 step:19407 [D loss: 0.227187, acc.: 64.06%] [G loss: 0.293672]\n",
      "epoch:20 step:19408 [D loss: 0.243709, acc.: 60.16%] [G loss: 0.303242]\n",
      "epoch:20 step:19409 [D loss: 0.224779, acc.: 63.28%] [G loss: 0.319365]\n",
      "epoch:20 step:19410 [D loss: 0.242008, acc.: 57.81%] [G loss: 0.289441]\n",
      "epoch:20 step:19411 [D loss: 0.239955, acc.: 57.03%] [G loss: 0.287055]\n",
      "epoch:20 step:19412 [D loss: 0.220898, acc.: 66.41%] [G loss: 0.313339]\n",
      "epoch:20 step:19413 [D loss: 0.236647, acc.: 61.72%] [G loss: 0.309399]\n",
      "epoch:20 step:19414 [D loss: 0.244706, acc.: 60.16%] [G loss: 0.302664]\n",
      "epoch:20 step:19415 [D loss: 0.243684, acc.: 60.16%] [G loss: 0.275525]\n",
      "epoch:20 step:19416 [D loss: 0.247013, acc.: 59.38%] [G loss: 0.296981]\n",
      "epoch:20 step:19417 [D loss: 0.253247, acc.: 51.56%] [G loss: 0.291748]\n",
      "epoch:20 step:19418 [D loss: 0.260121, acc.: 50.78%] [G loss: 0.273266]\n",
      "epoch:20 step:19419 [D loss: 0.229222, acc.: 61.72%] [G loss: 0.282218]\n",
      "epoch:20 step:19420 [D loss: 0.248657, acc.: 56.25%] [G loss: 0.317892]\n",
      "epoch:20 step:19421 [D loss: 0.230937, acc.: 57.81%] [G loss: 0.290972]\n",
      "epoch:20 step:19422 [D loss: 0.244157, acc.: 56.25%] [G loss: 0.280758]\n",
      "epoch:20 step:19423 [D loss: 0.242940, acc.: 58.59%] [G loss: 0.325655]\n",
      "epoch:20 step:19424 [D loss: 0.233362, acc.: 62.50%] [G loss: 0.278722]\n",
      "epoch:20 step:19425 [D loss: 0.234454, acc.: 60.94%] [G loss: 0.288172]\n",
      "epoch:20 step:19426 [D loss: 0.242203, acc.: 57.03%] [G loss: 0.296331]\n",
      "epoch:20 step:19427 [D loss: 0.253377, acc.: 57.03%] [G loss: 0.288872]\n",
      "epoch:20 step:19428 [D loss: 0.243436, acc.: 57.81%] [G loss: 0.282455]\n",
      "epoch:20 step:19429 [D loss: 0.246188, acc.: 55.47%] [G loss: 0.307474]\n",
      "epoch:20 step:19430 [D loss: 0.247967, acc.: 51.56%] [G loss: 0.278100]\n",
      "epoch:20 step:19431 [D loss: 0.229103, acc.: 57.81%] [G loss: 0.310306]\n",
      "epoch:20 step:19432 [D loss: 0.235765, acc.: 63.28%] [G loss: 0.277862]\n",
      "epoch:20 step:19433 [D loss: 0.239622, acc.: 53.12%] [G loss: 0.300598]\n",
      "epoch:20 step:19434 [D loss: 0.238648, acc.: 57.03%] [G loss: 0.300003]\n",
      "epoch:20 step:19435 [D loss: 0.238091, acc.: 59.38%] [G loss: 0.315345]\n",
      "epoch:20 step:19436 [D loss: 0.233895, acc.: 60.16%] [G loss: 0.321809]\n",
      "epoch:20 step:19437 [D loss: 0.253026, acc.: 52.34%] [G loss: 0.291992]\n",
      "epoch:20 step:19438 [D loss: 0.245959, acc.: 58.59%] [G loss: 0.295065]\n",
      "epoch:20 step:19439 [D loss: 0.223682, acc.: 66.41%] [G loss: 0.325634]\n",
      "epoch:20 step:19440 [D loss: 0.236412, acc.: 61.72%] [G loss: 0.286793]\n",
      "epoch:20 step:19441 [D loss: 0.224843, acc.: 67.19%] [G loss: 0.293109]\n",
      "epoch:20 step:19442 [D loss: 0.224997, acc.: 62.50%] [G loss: 0.330629]\n",
      "epoch:20 step:19443 [D loss: 0.247718, acc.: 56.25%] [G loss: 0.292998]\n",
      "epoch:20 step:19444 [D loss: 0.233114, acc.: 62.50%] [G loss: 0.286917]\n",
      "epoch:20 step:19445 [D loss: 0.228180, acc.: 61.72%] [G loss: 0.292789]\n",
      "epoch:20 step:19446 [D loss: 0.229180, acc.: 61.72%] [G loss: 0.296290]\n",
      "epoch:20 step:19447 [D loss: 0.230438, acc.: 61.72%] [G loss: 0.317234]\n",
      "epoch:20 step:19448 [D loss: 0.236991, acc.: 60.94%] [G loss: 0.301059]\n",
      "epoch:20 step:19449 [D loss: 0.252935, acc.: 55.47%] [G loss: 0.309616]\n",
      "epoch:20 step:19450 [D loss: 0.244657, acc.: 55.47%] [G loss: 0.302856]\n",
      "epoch:20 step:19451 [D loss: 0.234120, acc.: 62.50%] [G loss: 0.318550]\n",
      "epoch:20 step:19452 [D loss: 0.238610, acc.: 57.81%] [G loss: 0.312838]\n",
      "epoch:20 step:19453 [D loss: 0.233648, acc.: 58.59%] [G loss: 0.316538]\n",
      "epoch:20 step:19454 [D loss: 0.253209, acc.: 53.12%] [G loss: 0.296953]\n",
      "epoch:20 step:19455 [D loss: 0.244549, acc.: 52.34%] [G loss: 0.346089]\n",
      "epoch:20 step:19456 [D loss: 0.220149, acc.: 64.06%] [G loss: 0.303135]\n",
      "epoch:20 step:19457 [D loss: 0.243143, acc.: 57.81%] [G loss: 0.309255]\n",
      "epoch:20 step:19458 [D loss: 0.217537, acc.: 64.06%] [G loss: 0.307232]\n",
      "epoch:20 step:19459 [D loss: 0.234554, acc.: 56.25%] [G loss: 0.334179]\n",
      "epoch:20 step:19460 [D loss: 0.241888, acc.: 50.00%] [G loss: 0.312018]\n",
      "epoch:20 step:19461 [D loss: 0.230124, acc.: 62.50%] [G loss: 0.308300]\n",
      "epoch:20 step:19462 [D loss: 0.234676, acc.: 56.25%] [G loss: 0.322239]\n",
      "epoch:20 step:19463 [D loss: 0.259344, acc.: 47.66%] [G loss: 0.289277]\n",
      "epoch:20 step:19464 [D loss: 0.247605, acc.: 50.00%] [G loss: 0.285463]\n",
      "epoch:20 step:19465 [D loss: 0.232201, acc.: 65.62%] [G loss: 0.298367]\n",
      "epoch:20 step:19466 [D loss: 0.231287, acc.: 64.84%] [G loss: 0.319640]\n",
      "epoch:20 step:19467 [D loss: 0.230457, acc.: 62.50%] [G loss: 0.318643]\n",
      "epoch:20 step:19468 [D loss: 0.249508, acc.: 56.25%] [G loss: 0.289523]\n",
      "epoch:20 step:19469 [D loss: 0.235407, acc.: 60.16%] [G loss: 0.286734]\n",
      "epoch:20 step:19470 [D loss: 0.244136, acc.: 56.25%] [G loss: 0.314724]\n",
      "epoch:20 step:19471 [D loss: 0.258745, acc.: 52.34%] [G loss: 0.275421]\n",
      "epoch:20 step:19472 [D loss: 0.228626, acc.: 60.16%] [G loss: 0.306291]\n",
      "epoch:20 step:19473 [D loss: 0.247563, acc.: 54.69%] [G loss: 0.298996]\n",
      "epoch:20 step:19474 [D loss: 0.241997, acc.: 57.03%] [G loss: 0.289308]\n",
      "epoch:20 step:19475 [D loss: 0.243061, acc.: 56.25%] [G loss: 0.316067]\n",
      "epoch:20 step:19476 [D loss: 0.259149, acc.: 53.91%] [G loss: 0.286290]\n",
      "epoch:20 step:19477 [D loss: 0.248900, acc.: 50.78%] [G loss: 0.304165]\n",
      "epoch:20 step:19478 [D loss: 0.237771, acc.: 53.12%] [G loss: 0.304822]\n",
      "epoch:20 step:19479 [D loss: 0.257450, acc.: 57.03%] [G loss: 0.296221]\n",
      "epoch:20 step:19480 [D loss: 0.248248, acc.: 55.47%] [G loss: 0.287595]\n",
      "epoch:20 step:19481 [D loss: 0.248928, acc.: 52.34%] [G loss: 0.305574]\n",
      "epoch:20 step:19482 [D loss: 0.228289, acc.: 62.50%] [G loss: 0.280926]\n",
      "epoch:20 step:19483 [D loss: 0.254725, acc.: 55.47%] [G loss: 0.257600]\n",
      "epoch:20 step:19484 [D loss: 0.242197, acc.: 59.38%] [G loss: 0.306407]\n",
      "epoch:20 step:19485 [D loss: 0.247923, acc.: 57.03%] [G loss: 0.288427]\n",
      "epoch:20 step:19486 [D loss: 0.232947, acc.: 62.50%] [G loss: 0.298062]\n",
      "epoch:20 step:19487 [D loss: 0.245856, acc.: 54.69%] [G loss: 0.288647]\n",
      "epoch:20 step:19488 [D loss: 0.239858, acc.: 59.38%] [G loss: 0.285812]\n",
      "epoch:20 step:19489 [D loss: 0.247411, acc.: 55.47%] [G loss: 0.307134]\n",
      "epoch:20 step:19490 [D loss: 0.233054, acc.: 56.25%] [G loss: 0.307615]\n",
      "epoch:20 step:19491 [D loss: 0.225601, acc.: 59.38%] [G loss: 0.310296]\n",
      "epoch:20 step:19492 [D loss: 0.249112, acc.: 57.81%] [G loss: 0.297317]\n",
      "epoch:20 step:19493 [D loss: 0.236121, acc.: 64.06%] [G loss: 0.294778]\n",
      "epoch:20 step:19494 [D loss: 0.232806, acc.: 58.59%] [G loss: 0.299563]\n",
      "epoch:20 step:19495 [D loss: 0.239109, acc.: 57.81%] [G loss: 0.284368]\n",
      "epoch:20 step:19496 [D loss: 0.235395, acc.: 61.72%] [G loss: 0.294543]\n",
      "epoch:20 step:19497 [D loss: 0.226574, acc.: 68.75%] [G loss: 0.294392]\n",
      "epoch:20 step:19498 [D loss: 0.221455, acc.: 71.09%] [G loss: 0.286363]\n",
      "epoch:20 step:19499 [D loss: 0.234098, acc.: 59.38%] [G loss: 0.328852]\n",
      "epoch:20 step:19500 [D loss: 0.239659, acc.: 57.81%] [G loss: 0.300861]\n",
      "epoch:20 step:19501 [D loss: 0.237832, acc.: 59.38%] [G loss: 0.295603]\n",
      "epoch:20 step:19502 [D loss: 0.241111, acc.: 57.81%] [G loss: 0.316243]\n",
      "epoch:20 step:19503 [D loss: 0.219058, acc.: 67.97%] [G loss: 0.295947]\n",
      "epoch:20 step:19504 [D loss: 0.236126, acc.: 64.06%] [G loss: 0.308959]\n",
      "epoch:20 step:19505 [D loss: 0.232954, acc.: 60.16%] [G loss: 0.302380]\n",
      "epoch:20 step:19506 [D loss: 0.253452, acc.: 53.91%] [G loss: 0.288684]\n",
      "epoch:20 step:19507 [D loss: 0.251029, acc.: 53.91%] [G loss: 0.292936]\n",
      "epoch:20 step:19508 [D loss: 0.240683, acc.: 58.59%] [G loss: 0.316062]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:20 step:19509 [D loss: 0.237714, acc.: 52.34%] [G loss: 0.298322]\n",
      "epoch:20 step:19510 [D loss: 0.234010, acc.: 60.94%] [G loss: 0.323217]\n",
      "epoch:20 step:19511 [D loss: 0.252499, acc.: 51.56%] [G loss: 0.289525]\n",
      "epoch:20 step:19512 [D loss: 0.229879, acc.: 61.72%] [G loss: 0.309062]\n",
      "epoch:20 step:19513 [D loss: 0.253805, acc.: 55.47%] [G loss: 0.294160]\n",
      "epoch:20 step:19514 [D loss: 0.245988, acc.: 54.69%] [G loss: 0.326846]\n",
      "epoch:20 step:19515 [D loss: 0.246032, acc.: 56.25%] [G loss: 0.284880]\n",
      "epoch:20 step:19516 [D loss: 0.234901, acc.: 60.94%] [G loss: 0.303612]\n",
      "epoch:20 step:19517 [D loss: 0.242769, acc.: 54.69%] [G loss: 0.305514]\n",
      "epoch:20 step:19518 [D loss: 0.247998, acc.: 55.47%] [G loss: 0.289188]\n",
      "epoch:20 step:19519 [D loss: 0.240777, acc.: 54.69%] [G loss: 0.292222]\n",
      "epoch:20 step:19520 [D loss: 0.228584, acc.: 60.16%] [G loss: 0.300107]\n",
      "epoch:20 step:19521 [D loss: 0.253150, acc.: 45.31%] [G loss: 0.312501]\n",
      "epoch:20 step:19522 [D loss: 0.230690, acc.: 62.50%] [G loss: 0.304148]\n",
      "epoch:20 step:19523 [D loss: 0.242346, acc.: 60.16%] [G loss: 0.309644]\n",
      "epoch:20 step:19524 [D loss: 0.241213, acc.: 57.81%] [G loss: 0.316300]\n",
      "epoch:20 step:19525 [D loss: 0.244414, acc.: 57.03%] [G loss: 0.298359]\n",
      "epoch:20 step:19526 [D loss: 0.237467, acc.: 57.03%] [G loss: 0.305660]\n",
      "epoch:20 step:19527 [D loss: 0.232246, acc.: 55.47%] [G loss: 0.300974]\n",
      "epoch:20 step:19528 [D loss: 0.268423, acc.: 48.44%] [G loss: 0.297620]\n",
      "epoch:20 step:19529 [D loss: 0.249198, acc.: 54.69%] [G loss: 0.278298]\n",
      "epoch:20 step:19530 [D loss: 0.239630, acc.: 59.38%] [G loss: 0.307101]\n",
      "epoch:20 step:19531 [D loss: 0.251360, acc.: 55.47%] [G loss: 0.298249]\n",
      "epoch:20 step:19532 [D loss: 0.249019, acc.: 54.69%] [G loss: 0.287153]\n",
      "epoch:20 step:19533 [D loss: 0.246183, acc.: 54.69%] [G loss: 0.316148]\n",
      "epoch:20 step:19534 [D loss: 0.232278, acc.: 63.28%] [G loss: 0.277384]\n",
      "epoch:20 step:19535 [D loss: 0.240539, acc.: 60.94%] [G loss: 0.291047]\n",
      "epoch:20 step:19536 [D loss: 0.255944, acc.: 48.44%] [G loss: 0.311854]\n",
      "epoch:20 step:19537 [D loss: 0.236430, acc.: 59.38%] [G loss: 0.309282]\n",
      "epoch:20 step:19538 [D loss: 0.228695, acc.: 67.19%] [G loss: 0.286787]\n",
      "epoch:20 step:19539 [D loss: 0.229871, acc.: 63.28%] [G loss: 0.301851]\n",
      "epoch:20 step:19540 [D loss: 0.235920, acc.: 60.94%] [G loss: 0.329301]\n",
      "epoch:20 step:19541 [D loss: 0.241349, acc.: 56.25%] [G loss: 0.284151]\n",
      "epoch:20 step:19542 [D loss: 0.241450, acc.: 57.03%] [G loss: 0.317005]\n",
      "epoch:20 step:19543 [D loss: 0.247226, acc.: 52.34%] [G loss: 0.311585]\n",
      "epoch:20 step:19544 [D loss: 0.253296, acc.: 54.69%] [G loss: 0.292608]\n",
      "epoch:20 step:19545 [D loss: 0.250623, acc.: 54.69%] [G loss: 0.303658]\n",
      "epoch:20 step:19546 [D loss: 0.243503, acc.: 58.59%] [G loss: 0.301081]\n",
      "epoch:20 step:19547 [D loss: 0.246534, acc.: 49.22%] [G loss: 0.278064]\n",
      "epoch:20 step:19548 [D loss: 0.252455, acc.: 50.00%] [G loss: 0.315048]\n",
      "epoch:20 step:19549 [D loss: 0.238392, acc.: 64.84%] [G loss: 0.316508]\n",
      "epoch:20 step:19550 [D loss: 0.233454, acc.: 59.38%] [G loss: 0.282656]\n",
      "epoch:20 step:19551 [D loss: 0.236953, acc.: 59.38%] [G loss: 0.298855]\n",
      "epoch:20 step:19552 [D loss: 0.236572, acc.: 62.50%] [G loss: 0.316563]\n",
      "epoch:20 step:19553 [D loss: 0.241551, acc.: 60.16%] [G loss: 0.299616]\n",
      "epoch:20 step:19554 [D loss: 0.233322, acc.: 62.50%] [G loss: 0.306835]\n",
      "epoch:20 step:19555 [D loss: 0.250474, acc.: 55.47%] [G loss: 0.302293]\n",
      "epoch:20 step:19556 [D loss: 0.223660, acc.: 67.19%] [G loss: 0.304231]\n",
      "epoch:20 step:19557 [D loss: 0.227634, acc.: 61.72%] [G loss: 0.283424]\n",
      "epoch:20 step:19558 [D loss: 0.244594, acc.: 55.47%] [G loss: 0.289884]\n",
      "epoch:20 step:19559 [D loss: 0.241068, acc.: 61.72%] [G loss: 0.291697]\n",
      "epoch:20 step:19560 [D loss: 0.238241, acc.: 59.38%] [G loss: 0.288736]\n",
      "epoch:20 step:19561 [D loss: 0.231285, acc.: 61.72%] [G loss: 0.278491]\n",
      "epoch:20 step:19562 [D loss: 0.230375, acc.: 59.38%] [G loss: 0.315159]\n",
      "epoch:20 step:19563 [D loss: 0.246043, acc.: 57.03%] [G loss: 0.326840]\n",
      "epoch:20 step:19564 [D loss: 0.250297, acc.: 52.34%] [G loss: 0.275217]\n",
      "epoch:20 step:19565 [D loss: 0.229420, acc.: 58.59%] [G loss: 0.317895]\n",
      "epoch:20 step:19566 [D loss: 0.241216, acc.: 60.94%] [G loss: 0.294582]\n",
      "epoch:20 step:19567 [D loss: 0.240153, acc.: 60.94%] [G loss: 0.309273]\n",
      "epoch:20 step:19568 [D loss: 0.252195, acc.: 50.00%] [G loss: 0.310158]\n",
      "epoch:20 step:19569 [D loss: 0.230208, acc.: 58.59%] [G loss: 0.293036]\n",
      "epoch:20 step:19570 [D loss: 0.227766, acc.: 67.97%] [G loss: 0.315572]\n",
      "epoch:20 step:19571 [D loss: 0.246366, acc.: 52.34%] [G loss: 0.279788]\n",
      "epoch:20 step:19572 [D loss: 0.240199, acc.: 54.69%] [G loss: 0.290759]\n",
      "epoch:20 step:19573 [D loss: 0.233122, acc.: 60.94%] [G loss: 0.302338]\n",
      "epoch:20 step:19574 [D loss: 0.241062, acc.: 58.59%] [G loss: 0.304373]\n",
      "epoch:20 step:19575 [D loss: 0.252007, acc.: 53.91%] [G loss: 0.313625]\n",
      "epoch:20 step:19576 [D loss: 0.254604, acc.: 53.91%] [G loss: 0.319045]\n",
      "epoch:20 step:19577 [D loss: 0.245117, acc.: 52.34%] [G loss: 0.310443]\n",
      "epoch:20 step:19578 [D loss: 0.244700, acc.: 53.91%] [G loss: 0.338996]\n",
      "epoch:20 step:19579 [D loss: 0.249081, acc.: 52.34%] [G loss: 0.303633]\n",
      "epoch:20 step:19580 [D loss: 0.235062, acc.: 54.69%] [G loss: 0.295420]\n",
      "epoch:20 step:19581 [D loss: 0.233543, acc.: 61.72%] [G loss: 0.331680]\n",
      "epoch:20 step:19582 [D loss: 0.233394, acc.: 60.94%] [G loss: 0.304941]\n",
      "epoch:20 step:19583 [D loss: 0.246126, acc.: 50.00%] [G loss: 0.289055]\n",
      "epoch:20 step:19584 [D loss: 0.259469, acc.: 51.56%] [G loss: 0.264830]\n",
      "epoch:20 step:19585 [D loss: 0.255976, acc.: 50.78%] [G loss: 0.301854]\n",
      "epoch:20 step:19586 [D loss: 0.251749, acc.: 50.78%] [G loss: 0.309956]\n",
      "epoch:20 step:19587 [D loss: 0.232502, acc.: 57.81%] [G loss: 0.316934]\n",
      "epoch:20 step:19588 [D loss: 0.235284, acc.: 61.72%] [G loss: 0.304998]\n",
      "epoch:20 step:19589 [D loss: 0.228544, acc.: 60.16%] [G loss: 0.292882]\n",
      "epoch:20 step:19590 [D loss: 0.245282, acc.: 56.25%] [G loss: 0.305399]\n",
      "epoch:20 step:19591 [D loss: 0.237257, acc.: 60.94%] [G loss: 0.308650]\n",
      "epoch:20 step:19592 [D loss: 0.238220, acc.: 62.50%] [G loss: 0.304271]\n",
      "epoch:20 step:19593 [D loss: 0.233949, acc.: 64.06%] [G loss: 0.292750]\n",
      "epoch:20 step:19594 [D loss: 0.240688, acc.: 60.16%] [G loss: 0.306143]\n",
      "epoch:20 step:19595 [D loss: 0.254562, acc.: 53.12%] [G loss: 0.305442]\n",
      "epoch:20 step:19596 [D loss: 0.235334, acc.: 57.81%] [G loss: 0.307372]\n",
      "epoch:20 step:19597 [D loss: 0.232869, acc.: 62.50%] [G loss: 0.292018]\n",
      "epoch:20 step:19598 [D loss: 0.221284, acc.: 60.94%] [G loss: 0.317709]\n",
      "epoch:20 step:19599 [D loss: 0.229486, acc.: 64.06%] [G loss: 0.320246]\n",
      "epoch:20 step:19600 [D loss: 0.232670, acc.: 59.38%] [G loss: 0.300490]\n",
      "epoch:20 step:19601 [D loss: 0.233800, acc.: 63.28%] [G loss: 0.316676]\n",
      "epoch:20 step:19602 [D loss: 0.244150, acc.: 56.25%] [G loss: 0.288100]\n",
      "epoch:20 step:19603 [D loss: 0.254067, acc.: 56.25%] [G loss: 0.304825]\n",
      "epoch:20 step:19604 [D loss: 0.242329, acc.: 52.34%] [G loss: 0.307401]\n",
      "epoch:20 step:19605 [D loss: 0.216656, acc.: 62.50%] [G loss: 0.350963]\n",
      "epoch:20 step:19606 [D loss: 0.226643, acc.: 65.62%] [G loss: 0.290729]\n",
      "epoch:20 step:19607 [D loss: 0.239748, acc.: 64.84%] [G loss: 0.313392]\n",
      "epoch:20 step:19608 [D loss: 0.237861, acc.: 57.03%] [G loss: 0.300200]\n",
      "epoch:20 step:19609 [D loss: 0.228770, acc.: 65.62%] [G loss: 0.292690]\n",
      "epoch:20 step:19610 [D loss: 0.242843, acc.: 60.94%] [G loss: 0.333778]\n",
      "epoch:20 step:19611 [D loss: 0.241528, acc.: 60.16%] [G loss: 0.294046]\n",
      "epoch:20 step:19612 [D loss: 0.247213, acc.: 50.00%] [G loss: 0.297433]\n",
      "epoch:20 step:19613 [D loss: 0.234586, acc.: 60.94%] [G loss: 0.319166]\n",
      "epoch:20 step:19614 [D loss: 0.230313, acc.: 58.59%] [G loss: 0.305595]\n",
      "epoch:20 step:19615 [D loss: 0.227162, acc.: 58.59%] [G loss: 0.298467]\n",
      "epoch:20 step:19616 [D loss: 0.245301, acc.: 54.69%] [G loss: 0.281378]\n",
      "epoch:20 step:19617 [D loss: 0.253829, acc.: 53.91%] [G loss: 0.299543]\n",
      "epoch:20 step:19618 [D loss: 0.234993, acc.: 63.28%] [G loss: 0.303090]\n",
      "epoch:20 step:19619 [D loss: 0.257663, acc.: 48.44%] [G loss: 0.294765]\n",
      "epoch:20 step:19620 [D loss: 0.225437, acc.: 65.62%] [G loss: 0.315744]\n",
      "epoch:20 step:19621 [D loss: 0.250067, acc.: 52.34%] [G loss: 0.291060]\n",
      "epoch:20 step:19622 [D loss: 0.230405, acc.: 60.94%] [G loss: 0.317951]\n",
      "epoch:20 step:19623 [D loss: 0.235380, acc.: 60.16%] [G loss: 0.323789]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:20 step:19624 [D loss: 0.236534, acc.: 62.50%] [G loss: 0.290302]\n",
      "epoch:20 step:19625 [D loss: 0.246642, acc.: 53.91%] [G loss: 0.323013]\n",
      "epoch:20 step:19626 [D loss: 0.247990, acc.: 50.78%] [G loss: 0.300698]\n",
      "epoch:20 step:19627 [D loss: 0.250074, acc.: 57.03%] [G loss: 0.296203]\n",
      "epoch:20 step:19628 [D loss: 0.259020, acc.: 53.12%] [G loss: 0.306757]\n",
      "epoch:20 step:19629 [D loss: 0.257582, acc.: 46.09%] [G loss: 0.305662]\n",
      "epoch:20 step:19630 [D loss: 0.230463, acc.: 60.16%] [G loss: 0.314226]\n",
      "epoch:20 step:19631 [D loss: 0.234359, acc.: 63.28%] [G loss: 0.325747]\n",
      "epoch:20 step:19632 [D loss: 0.242675, acc.: 57.81%] [G loss: 0.280615]\n",
      "epoch:20 step:19633 [D loss: 0.244344, acc.: 60.16%] [G loss: 0.278947]\n",
      "epoch:20 step:19634 [D loss: 0.241447, acc.: 55.47%] [G loss: 0.292995]\n",
      "epoch:20 step:19635 [D loss: 0.231819, acc.: 60.94%] [G loss: 0.293591]\n",
      "epoch:20 step:19636 [D loss: 0.219195, acc.: 66.41%] [G loss: 0.304041]\n",
      "epoch:20 step:19637 [D loss: 0.226480, acc.: 66.41%] [G loss: 0.305630]\n",
      "epoch:20 step:19638 [D loss: 0.232761, acc.: 57.81%] [G loss: 0.315344]\n",
      "epoch:20 step:19639 [D loss: 0.237426, acc.: 60.94%] [G loss: 0.331060]\n",
      "epoch:20 step:19640 [D loss: 0.250063, acc.: 57.81%] [G loss: 0.300141]\n",
      "epoch:20 step:19641 [D loss: 0.239868, acc.: 60.16%] [G loss: 0.326031]\n",
      "epoch:20 step:19642 [D loss: 0.247186, acc.: 55.47%] [G loss: 0.312656]\n",
      "epoch:20 step:19643 [D loss: 0.230510, acc.: 65.62%] [G loss: 0.308696]\n",
      "epoch:20 step:19644 [D loss: 0.249954, acc.: 53.91%] [G loss: 0.327514]\n",
      "epoch:20 step:19645 [D loss: 0.241843, acc.: 56.25%] [G loss: 0.346089]\n",
      "epoch:20 step:19646 [D loss: 0.246312, acc.: 52.34%] [G loss: 0.292242]\n",
      "epoch:20 step:19647 [D loss: 0.233447, acc.: 59.38%] [G loss: 0.293885]\n",
      "epoch:20 step:19648 [D loss: 0.228032, acc.: 61.72%] [G loss: 0.324524]\n",
      "epoch:20 step:19649 [D loss: 0.264757, acc.: 48.44%] [G loss: 0.294588]\n",
      "epoch:20 step:19650 [D loss: 0.248457, acc.: 57.81%] [G loss: 0.285866]\n",
      "epoch:20 step:19651 [D loss: 0.247025, acc.: 54.69%] [G loss: 0.299845]\n",
      "epoch:20 step:19652 [D loss: 0.237650, acc.: 55.47%] [G loss: 0.318184]\n",
      "epoch:20 step:19653 [D loss: 0.232659, acc.: 63.28%] [G loss: 0.288108]\n",
      "epoch:20 step:19654 [D loss: 0.222999, acc.: 66.41%] [G loss: 0.288282]\n",
      "epoch:20 step:19655 [D loss: 0.239718, acc.: 57.03%] [G loss: 0.293811]\n",
      "epoch:20 step:19656 [D loss: 0.238606, acc.: 56.25%] [G loss: 0.312326]\n",
      "epoch:20 step:19657 [D loss: 0.254424, acc.: 57.03%] [G loss: 0.264377]\n",
      "epoch:20 step:19658 [D loss: 0.237428, acc.: 53.12%] [G loss: 0.266823]\n",
      "epoch:20 step:19659 [D loss: 0.236706, acc.: 57.81%] [G loss: 0.302302]\n",
      "epoch:20 step:19660 [D loss: 0.241618, acc.: 60.16%] [G loss: 0.300120]\n",
      "epoch:20 step:19661 [D loss: 0.233397, acc.: 53.12%] [G loss: 0.316857]\n",
      "epoch:20 step:19662 [D loss: 0.232598, acc.: 57.03%] [G loss: 0.317333]\n",
      "epoch:20 step:19663 [D loss: 0.245453, acc.: 53.12%] [G loss: 0.306073]\n",
      "epoch:20 step:19664 [D loss: 0.244654, acc.: 57.03%] [G loss: 0.314860]\n",
      "epoch:20 step:19665 [D loss: 0.243096, acc.: 56.25%] [G loss: 0.300024]\n",
      "epoch:20 step:19666 [D loss: 0.230597, acc.: 62.50%] [G loss: 0.286518]\n",
      "epoch:20 step:19667 [D loss: 0.238581, acc.: 54.69%] [G loss: 0.298786]\n",
      "epoch:20 step:19668 [D loss: 0.256205, acc.: 50.00%] [G loss: 0.295523]\n",
      "epoch:20 step:19669 [D loss: 0.246989, acc.: 53.91%] [G loss: 0.307339]\n",
      "epoch:20 step:19670 [D loss: 0.258717, acc.: 55.47%] [G loss: 0.331702]\n",
      "epoch:20 step:19671 [D loss: 0.240021, acc.: 56.25%] [G loss: 0.290364]\n",
      "epoch:20 step:19672 [D loss: 0.230246, acc.: 58.59%] [G loss: 0.315923]\n",
      "epoch:20 step:19673 [D loss: 0.256401, acc.: 51.56%] [G loss: 0.268883]\n",
      "epoch:20 step:19674 [D loss: 0.230859, acc.: 59.38%] [G loss: 0.302880]\n",
      "epoch:20 step:19675 [D loss: 0.216344, acc.: 65.62%] [G loss: 0.299798]\n",
      "epoch:20 step:19676 [D loss: 0.241206, acc.: 58.59%] [G loss: 0.301829]\n",
      "epoch:20 step:19677 [D loss: 0.238476, acc.: 60.94%] [G loss: 0.265757]\n",
      "epoch:21 step:19678 [D loss: 0.249186, acc.: 57.03%] [G loss: 0.274413]\n",
      "epoch:21 step:19679 [D loss: 0.252184, acc.: 55.47%] [G loss: 0.289565]\n",
      "epoch:21 step:19680 [D loss: 0.236264, acc.: 60.94%] [G loss: 0.296371]\n",
      "epoch:21 step:19681 [D loss: 0.245146, acc.: 57.03%] [G loss: 0.313720]\n",
      "epoch:21 step:19682 [D loss: 0.237294, acc.: 59.38%] [G loss: 0.296850]\n",
      "epoch:21 step:19683 [D loss: 0.239769, acc.: 54.69%] [G loss: 0.277153]\n",
      "epoch:21 step:19684 [D loss: 0.236315, acc.: 60.16%] [G loss: 0.301469]\n",
      "epoch:21 step:19685 [D loss: 0.225468, acc.: 59.38%] [G loss: 0.291318]\n",
      "epoch:21 step:19686 [D loss: 0.217249, acc.: 68.75%] [G loss: 0.300625]\n",
      "epoch:21 step:19687 [D loss: 0.227761, acc.: 64.06%] [G loss: 0.310067]\n",
      "epoch:21 step:19688 [D loss: 0.247734, acc.: 50.78%] [G loss: 0.314797]\n",
      "epoch:21 step:19689 [D loss: 0.234961, acc.: 63.28%] [G loss: 0.295430]\n",
      "epoch:21 step:19690 [D loss: 0.232703, acc.: 62.50%] [G loss: 0.304195]\n",
      "epoch:21 step:19691 [D loss: 0.243902, acc.: 52.34%] [G loss: 0.287790]\n",
      "epoch:21 step:19692 [D loss: 0.223079, acc.: 61.72%] [G loss: 0.358690]\n",
      "epoch:21 step:19693 [D loss: 0.237234, acc.: 54.69%] [G loss: 0.284135]\n",
      "epoch:21 step:19694 [D loss: 0.244268, acc.: 58.59%] [G loss: 0.274822]\n",
      "epoch:21 step:19695 [D loss: 0.213539, acc.: 68.75%] [G loss: 0.306034]\n",
      "epoch:21 step:19696 [D loss: 0.238568, acc.: 60.16%] [G loss: 0.305544]\n",
      "epoch:21 step:19697 [D loss: 0.245101, acc.: 57.03%] [G loss: 0.322672]\n",
      "epoch:21 step:19698 [D loss: 0.234585, acc.: 63.28%] [G loss: 0.262307]\n",
      "epoch:21 step:19699 [D loss: 0.234371, acc.: 58.59%] [G loss: 0.300399]\n",
      "epoch:21 step:19700 [D loss: 0.233061, acc.: 61.72%] [G loss: 0.293905]\n",
      "epoch:21 step:19701 [D loss: 0.216332, acc.: 63.28%] [G loss: 0.319101]\n",
      "epoch:21 step:19702 [D loss: 0.252487, acc.: 52.34%] [G loss: 0.304021]\n",
      "epoch:21 step:19703 [D loss: 0.230942, acc.: 62.50%] [G loss: 0.323882]\n",
      "epoch:21 step:19704 [D loss: 0.246933, acc.: 52.34%] [G loss: 0.308170]\n",
      "epoch:21 step:19705 [D loss: 0.223452, acc.: 64.84%] [G loss: 0.307151]\n",
      "epoch:21 step:19706 [D loss: 0.247942, acc.: 57.03%] [G loss: 0.307088]\n",
      "epoch:21 step:19707 [D loss: 0.215114, acc.: 66.41%] [G loss: 0.308351]\n",
      "epoch:21 step:19708 [D loss: 0.235578, acc.: 61.72%] [G loss: 0.298879]\n",
      "epoch:21 step:19709 [D loss: 0.237335, acc.: 57.03%] [G loss: 0.299806]\n",
      "epoch:21 step:19710 [D loss: 0.245953, acc.: 62.50%] [G loss: 0.283411]\n",
      "epoch:21 step:19711 [D loss: 0.241569, acc.: 58.59%] [G loss: 0.300506]\n",
      "epoch:21 step:19712 [D loss: 0.242085, acc.: 55.47%] [G loss: 0.286473]\n",
      "epoch:21 step:19713 [D loss: 0.236433, acc.: 60.94%] [G loss: 0.311365]\n",
      "epoch:21 step:19714 [D loss: 0.238250, acc.: 62.50%] [G loss: 0.294681]\n",
      "epoch:21 step:19715 [D loss: 0.244026, acc.: 57.81%] [G loss: 0.311161]\n",
      "epoch:21 step:19716 [D loss: 0.246238, acc.: 53.91%] [G loss: 0.315719]\n",
      "epoch:21 step:19717 [D loss: 0.229558, acc.: 57.81%] [G loss: 0.282978]\n",
      "epoch:21 step:19718 [D loss: 0.230738, acc.: 59.38%] [G loss: 0.275165]\n",
      "epoch:21 step:19719 [D loss: 0.248241, acc.: 53.91%] [G loss: 0.319052]\n",
      "epoch:21 step:19720 [D loss: 0.242862, acc.: 60.94%] [G loss: 0.289538]\n",
      "epoch:21 step:19721 [D loss: 0.234868, acc.: 60.94%] [G loss: 0.308774]\n",
      "epoch:21 step:19722 [D loss: 0.238522, acc.: 57.03%] [G loss: 0.317721]\n",
      "epoch:21 step:19723 [D loss: 0.250043, acc.: 54.69%] [G loss: 0.294743]\n",
      "epoch:21 step:19724 [D loss: 0.251714, acc.: 53.91%] [G loss: 0.257862]\n",
      "epoch:21 step:19725 [D loss: 0.241778, acc.: 56.25%] [G loss: 0.294469]\n",
      "epoch:21 step:19726 [D loss: 0.235672, acc.: 60.16%] [G loss: 0.348393]\n",
      "epoch:21 step:19727 [D loss: 0.249450, acc.: 56.25%] [G loss: 0.298807]\n",
      "epoch:21 step:19728 [D loss: 0.250482, acc.: 55.47%] [G loss: 0.322154]\n",
      "epoch:21 step:19729 [D loss: 0.237760, acc.: 57.81%] [G loss: 0.305553]\n",
      "epoch:21 step:19730 [D loss: 0.232370, acc.: 60.16%] [G loss: 0.319774]\n",
      "epoch:21 step:19731 [D loss: 0.228233, acc.: 60.16%] [G loss: 0.310583]\n",
      "epoch:21 step:19732 [D loss: 0.254369, acc.: 54.69%] [G loss: 0.284106]\n",
      "epoch:21 step:19733 [D loss: 0.253647, acc.: 51.56%] [G loss: 0.282916]\n",
      "epoch:21 step:19734 [D loss: 0.248391, acc.: 53.91%] [G loss: 0.292388]\n",
      "epoch:21 step:19735 [D loss: 0.241235, acc.: 61.72%] [G loss: 0.301579]\n",
      "epoch:21 step:19736 [D loss: 0.226035, acc.: 57.81%] [G loss: 0.334851]\n",
      "epoch:21 step:19737 [D loss: 0.229798, acc.: 64.84%] [G loss: 0.322023]\n",
      "epoch:21 step:19738 [D loss: 0.235030, acc.: 58.59%] [G loss: 0.309619]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:21 step:19739 [D loss: 0.245655, acc.: 52.34%] [G loss: 0.287433]\n",
      "epoch:21 step:19740 [D loss: 0.231259, acc.: 67.19%] [G loss: 0.286840]\n",
      "epoch:21 step:19741 [D loss: 0.246457, acc.: 57.03%] [G loss: 0.295390]\n",
      "epoch:21 step:19742 [D loss: 0.237740, acc.: 59.38%] [G loss: 0.288033]\n",
      "epoch:21 step:19743 [D loss: 0.230274, acc.: 61.72%] [G loss: 0.321291]\n",
      "epoch:21 step:19744 [D loss: 0.248873, acc.: 50.78%] [G loss: 0.278711]\n",
      "epoch:21 step:19745 [D loss: 0.243644, acc.: 57.03%] [G loss: 0.317908]\n",
      "epoch:21 step:19746 [D loss: 0.239287, acc.: 60.16%] [G loss: 0.310535]\n",
      "epoch:21 step:19747 [D loss: 0.243932, acc.: 61.72%] [G loss: 0.300084]\n",
      "epoch:21 step:19748 [D loss: 0.227799, acc.: 60.16%] [G loss: 0.288962]\n",
      "epoch:21 step:19749 [D loss: 0.229097, acc.: 60.94%] [G loss: 0.312231]\n",
      "epoch:21 step:19750 [D loss: 0.225888, acc.: 65.62%] [G loss: 0.289267]\n",
      "epoch:21 step:19751 [D loss: 0.232102, acc.: 67.19%] [G loss: 0.323436]\n",
      "epoch:21 step:19752 [D loss: 0.242165, acc.: 53.91%] [G loss: 0.296669]\n",
      "epoch:21 step:19753 [D loss: 0.236473, acc.: 57.81%] [G loss: 0.315827]\n",
      "epoch:21 step:19754 [D loss: 0.252808, acc.: 48.44%] [G loss: 0.321920]\n",
      "epoch:21 step:19755 [D loss: 0.237614, acc.: 61.72%] [G loss: 0.329845]\n",
      "epoch:21 step:19756 [D loss: 0.261586, acc.: 47.66%] [G loss: 0.301488]\n",
      "epoch:21 step:19757 [D loss: 0.246789, acc.: 57.81%] [G loss: 0.293338]\n",
      "epoch:21 step:19758 [D loss: 0.235047, acc.: 59.38%] [G loss: 0.294137]\n",
      "epoch:21 step:19759 [D loss: 0.229290, acc.: 63.28%] [G loss: 0.281296]\n",
      "epoch:21 step:19760 [D loss: 0.242543, acc.: 57.03%] [G loss: 0.319388]\n",
      "epoch:21 step:19761 [D loss: 0.233385, acc.: 62.50%] [G loss: 0.335470]\n",
      "epoch:21 step:19762 [D loss: 0.235544, acc.: 57.81%] [G loss: 0.305014]\n",
      "epoch:21 step:19763 [D loss: 0.251360, acc.: 57.03%] [G loss: 0.307799]\n",
      "epoch:21 step:19764 [D loss: 0.237586, acc.: 62.50%] [G loss: 0.314465]\n",
      "epoch:21 step:19765 [D loss: 0.251791, acc.: 53.91%] [G loss: 0.305727]\n",
      "epoch:21 step:19766 [D loss: 0.240783, acc.: 50.78%] [G loss: 0.278424]\n",
      "epoch:21 step:19767 [D loss: 0.254664, acc.: 55.47%] [G loss: 0.271884]\n",
      "epoch:21 step:19768 [D loss: 0.212807, acc.: 73.44%] [G loss: 0.332057]\n",
      "epoch:21 step:19769 [D loss: 0.242792, acc.: 53.91%] [G loss: 0.286392]\n",
      "epoch:21 step:19770 [D loss: 0.232824, acc.: 58.59%] [G loss: 0.314451]\n",
      "epoch:21 step:19771 [D loss: 0.210719, acc.: 68.75%] [G loss: 0.311170]\n",
      "epoch:21 step:19772 [D loss: 0.242553, acc.: 59.38%] [G loss: 0.277265]\n",
      "epoch:21 step:19773 [D loss: 0.242030, acc.: 58.59%] [G loss: 0.294017]\n",
      "epoch:21 step:19774 [D loss: 0.243202, acc.: 58.59%] [G loss: 0.345404]\n",
      "epoch:21 step:19775 [D loss: 0.238446, acc.: 61.72%] [G loss: 0.283549]\n",
      "epoch:21 step:19776 [D loss: 0.242716, acc.: 57.03%] [G loss: 0.312931]\n",
      "epoch:21 step:19777 [D loss: 0.247479, acc.: 54.69%] [G loss: 0.283374]\n",
      "epoch:21 step:19778 [D loss: 0.229819, acc.: 63.28%] [G loss: 0.330083]\n",
      "epoch:21 step:19779 [D loss: 0.244855, acc.: 57.81%] [G loss: 0.293456]\n",
      "epoch:21 step:19780 [D loss: 0.228811, acc.: 58.59%] [G loss: 0.289936]\n",
      "epoch:21 step:19781 [D loss: 0.244960, acc.: 60.94%] [G loss: 0.288207]\n",
      "epoch:21 step:19782 [D loss: 0.246454, acc.: 58.59%] [G loss: 0.310524]\n",
      "epoch:21 step:19783 [D loss: 0.223210, acc.: 65.62%] [G loss: 0.328361]\n",
      "epoch:21 step:19784 [D loss: 0.225812, acc.: 63.28%] [G loss: 0.309823]\n",
      "epoch:21 step:19785 [D loss: 0.246277, acc.: 59.38%] [G loss: 0.309187]\n",
      "epoch:21 step:19786 [D loss: 0.237803, acc.: 58.59%] [G loss: 0.291151]\n",
      "epoch:21 step:19787 [D loss: 0.266212, acc.: 48.44%] [G loss: 0.288327]\n",
      "epoch:21 step:19788 [D loss: 0.248622, acc.: 49.22%] [G loss: 0.305629]\n",
      "epoch:21 step:19789 [D loss: 0.253888, acc.: 53.12%] [G loss: 0.278478]\n",
      "epoch:21 step:19790 [D loss: 0.235671, acc.: 59.38%] [G loss: 0.296531]\n",
      "epoch:21 step:19791 [D loss: 0.228890, acc.: 57.81%] [G loss: 0.306197]\n",
      "epoch:21 step:19792 [D loss: 0.243705, acc.: 57.03%] [G loss: 0.293844]\n",
      "epoch:21 step:19793 [D loss: 0.231478, acc.: 57.03%] [G loss: 0.316657]\n",
      "epoch:21 step:19794 [D loss: 0.256266, acc.: 46.88%] [G loss: 0.301598]\n",
      "epoch:21 step:19795 [D loss: 0.240146, acc.: 55.47%] [G loss: 0.333043]\n",
      "epoch:21 step:19796 [D loss: 0.215301, acc.: 67.97%] [G loss: 0.312504]\n",
      "epoch:21 step:19797 [D loss: 0.246002, acc.: 53.91%] [G loss: 0.291831]\n",
      "epoch:21 step:19798 [D loss: 0.248073, acc.: 52.34%] [G loss: 0.298467]\n",
      "epoch:21 step:19799 [D loss: 0.244596, acc.: 59.38%] [G loss: 0.298870]\n",
      "epoch:21 step:19800 [D loss: 0.237428, acc.: 57.03%] [G loss: 0.282894]\n",
      "epoch:21 step:19801 [D loss: 0.232581, acc.: 57.03%] [G loss: 0.292615]\n",
      "epoch:21 step:19802 [D loss: 0.244353, acc.: 57.81%] [G loss: 0.295734]\n",
      "epoch:21 step:19803 [D loss: 0.248777, acc.: 56.25%] [G loss: 0.308229]\n",
      "epoch:21 step:19804 [D loss: 0.218065, acc.: 64.06%] [G loss: 0.316742]\n",
      "epoch:21 step:19805 [D loss: 0.242235, acc.: 55.47%] [G loss: 0.314512]\n",
      "epoch:21 step:19806 [D loss: 0.224922, acc.: 60.16%] [G loss: 0.320439]\n",
      "epoch:21 step:19807 [D loss: 0.236618, acc.: 56.25%] [G loss: 0.312357]\n",
      "epoch:21 step:19808 [D loss: 0.236478, acc.: 60.94%] [G loss: 0.306095]\n",
      "epoch:21 step:19809 [D loss: 0.238240, acc.: 56.25%] [G loss: 0.318162]\n",
      "epoch:21 step:19810 [D loss: 0.234067, acc.: 58.59%] [G loss: 0.297230]\n",
      "epoch:21 step:19811 [D loss: 0.236609, acc.: 60.94%] [G loss: 0.285027]\n",
      "epoch:21 step:19812 [D loss: 0.238011, acc.: 62.50%] [G loss: 0.319129]\n",
      "epoch:21 step:19813 [D loss: 0.244005, acc.: 58.59%] [G loss: 0.307496]\n",
      "epoch:21 step:19814 [D loss: 0.236038, acc.: 60.16%] [G loss: 0.327859]\n",
      "epoch:21 step:19815 [D loss: 0.247966, acc.: 55.47%] [G loss: 0.261713]\n",
      "epoch:21 step:19816 [D loss: 0.225834, acc.: 62.50%] [G loss: 0.291995]\n",
      "epoch:21 step:19817 [D loss: 0.243475, acc.: 60.94%] [G loss: 0.314111]\n",
      "epoch:21 step:19818 [D loss: 0.244197, acc.: 53.91%] [G loss: 0.338747]\n",
      "epoch:21 step:19819 [D loss: 0.249105, acc.: 54.69%] [G loss: 0.294603]\n",
      "epoch:21 step:19820 [D loss: 0.223758, acc.: 61.72%] [G loss: 0.316224]\n",
      "epoch:21 step:19821 [D loss: 0.243976, acc.: 57.03%] [G loss: 0.308594]\n",
      "epoch:21 step:19822 [D loss: 0.242225, acc.: 58.59%] [G loss: 0.296731]\n",
      "epoch:21 step:19823 [D loss: 0.245000, acc.: 54.69%] [G loss: 0.304457]\n",
      "epoch:21 step:19824 [D loss: 0.224605, acc.: 58.59%] [G loss: 0.303720]\n",
      "epoch:21 step:19825 [D loss: 0.239892, acc.: 58.59%] [G loss: 0.312467]\n",
      "epoch:21 step:19826 [D loss: 0.247251, acc.: 56.25%] [G loss: 0.321461]\n",
      "epoch:21 step:19827 [D loss: 0.239298, acc.: 54.69%] [G loss: 0.295809]\n",
      "epoch:21 step:19828 [D loss: 0.250041, acc.: 59.38%] [G loss: 0.340857]\n",
      "epoch:21 step:19829 [D loss: 0.234722, acc.: 59.38%] [G loss: 0.288515]\n",
      "epoch:21 step:19830 [D loss: 0.238571, acc.: 56.25%] [G loss: 0.309392]\n",
      "epoch:21 step:19831 [D loss: 0.241198, acc.: 55.47%] [G loss: 0.334217]\n",
      "epoch:21 step:19832 [D loss: 0.239829, acc.: 58.59%] [G loss: 0.304223]\n",
      "epoch:21 step:19833 [D loss: 0.231596, acc.: 64.06%] [G loss: 0.301172]\n",
      "epoch:21 step:19834 [D loss: 0.237596, acc.: 55.47%] [G loss: 0.314697]\n",
      "epoch:21 step:19835 [D loss: 0.221562, acc.: 64.06%] [G loss: 0.295227]\n",
      "epoch:21 step:19836 [D loss: 0.249722, acc.: 53.91%] [G loss: 0.299543]\n",
      "epoch:21 step:19837 [D loss: 0.240534, acc.: 57.03%] [G loss: 0.286703]\n",
      "epoch:21 step:19838 [D loss: 0.229873, acc.: 60.94%] [G loss: 0.317338]\n",
      "epoch:21 step:19839 [D loss: 0.236663, acc.: 54.69%] [G loss: 0.330106]\n",
      "epoch:21 step:19840 [D loss: 0.244697, acc.: 60.94%] [G loss: 0.305786]\n",
      "epoch:21 step:19841 [D loss: 0.248806, acc.: 51.56%] [G loss: 0.300640]\n",
      "epoch:21 step:19842 [D loss: 0.220570, acc.: 64.06%] [G loss: 0.301200]\n",
      "epoch:21 step:19843 [D loss: 0.222212, acc.: 62.50%] [G loss: 0.309563]\n",
      "epoch:21 step:19844 [D loss: 0.228815, acc.: 65.62%] [G loss: 0.270758]\n",
      "epoch:21 step:19845 [D loss: 0.242554, acc.: 57.81%] [G loss: 0.296941]\n",
      "epoch:21 step:19846 [D loss: 0.242143, acc.: 60.16%] [G loss: 0.299758]\n",
      "epoch:21 step:19847 [D loss: 0.247732, acc.: 57.03%] [G loss: 0.296030]\n",
      "epoch:21 step:19848 [D loss: 0.231135, acc.: 56.25%] [G loss: 0.309757]\n",
      "epoch:21 step:19849 [D loss: 0.222544, acc.: 62.50%] [G loss: 0.280112]\n",
      "epoch:21 step:19850 [D loss: 0.247039, acc.: 51.56%] [G loss: 0.275155]\n",
      "epoch:21 step:19851 [D loss: 0.235835, acc.: 59.38%] [G loss: 0.301442]\n",
      "epoch:21 step:19852 [D loss: 0.246451, acc.: 56.25%] [G loss: 0.296485]\n",
      "epoch:21 step:19853 [D loss: 0.222914, acc.: 64.84%] [G loss: 0.345179]\n",
      "epoch:21 step:19854 [D loss: 0.236982, acc.: 64.06%] [G loss: 0.295480]\n",
      "epoch:21 step:19855 [D loss: 0.248607, acc.: 54.69%] [G loss: 0.312740]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:21 step:19856 [D loss: 0.247752, acc.: 53.12%] [G loss: 0.281680]\n",
      "epoch:21 step:19857 [D loss: 0.231073, acc.: 62.50%] [G loss: 0.277650]\n",
      "epoch:21 step:19858 [D loss: 0.240125, acc.: 57.81%] [G loss: 0.285291]\n",
      "epoch:21 step:19859 [D loss: 0.222886, acc.: 59.38%] [G loss: 0.290864]\n",
      "epoch:21 step:19860 [D loss: 0.241317, acc.: 59.38%] [G loss: 0.305616]\n",
      "epoch:21 step:19861 [D loss: 0.231854, acc.: 60.94%] [G loss: 0.335166]\n",
      "epoch:21 step:19862 [D loss: 0.234656, acc.: 58.59%] [G loss: 0.283219]\n",
      "epoch:21 step:19863 [D loss: 0.239815, acc.: 57.81%] [G loss: 0.317336]\n",
      "epoch:21 step:19864 [D loss: 0.244250, acc.: 53.12%] [G loss: 0.322341]\n",
      "epoch:21 step:19865 [D loss: 0.238940, acc.: 57.81%] [G loss: 0.311328]\n",
      "epoch:21 step:19866 [D loss: 0.242291, acc.: 58.59%] [G loss: 0.309046]\n",
      "epoch:21 step:19867 [D loss: 0.230396, acc.: 57.03%] [G loss: 0.329295]\n",
      "epoch:21 step:19868 [D loss: 0.226432, acc.: 62.50%] [G loss: 0.327493]\n",
      "epoch:21 step:19869 [D loss: 0.248961, acc.: 50.78%] [G loss: 0.333498]\n",
      "epoch:21 step:19870 [D loss: 0.239929, acc.: 56.25%] [G loss: 0.300733]\n",
      "epoch:21 step:19871 [D loss: 0.237768, acc.: 57.81%] [G loss: 0.317236]\n",
      "epoch:21 step:19872 [D loss: 0.225270, acc.: 64.06%] [G loss: 0.337816]\n",
      "epoch:21 step:19873 [D loss: 0.242045, acc.: 53.91%] [G loss: 0.298260]\n",
      "epoch:21 step:19874 [D loss: 0.236198, acc.: 64.84%] [G loss: 0.313151]\n",
      "epoch:21 step:19875 [D loss: 0.244620, acc.: 55.47%] [G loss: 0.359256]\n",
      "epoch:21 step:19876 [D loss: 0.262149, acc.: 49.22%] [G loss: 0.300979]\n",
      "epoch:21 step:19877 [D loss: 0.235671, acc.: 58.59%] [G loss: 0.320146]\n",
      "epoch:21 step:19878 [D loss: 0.232230, acc.: 61.72%] [G loss: 0.307790]\n",
      "epoch:21 step:19879 [D loss: 0.245523, acc.: 57.81%] [G loss: 0.285309]\n",
      "epoch:21 step:19880 [D loss: 0.219671, acc.: 66.41%] [G loss: 0.307194]\n",
      "epoch:21 step:19881 [D loss: 0.232674, acc.: 56.25%] [G loss: 0.288003]\n",
      "epoch:21 step:19882 [D loss: 0.246150, acc.: 59.38%] [G loss: 0.306437]\n",
      "epoch:21 step:19883 [D loss: 0.239449, acc.: 59.38%] [G loss: 0.324961]\n",
      "epoch:21 step:19884 [D loss: 0.240779, acc.: 57.81%] [G loss: 0.318550]\n",
      "epoch:21 step:19885 [D loss: 0.234926, acc.: 53.91%] [G loss: 0.347198]\n",
      "epoch:21 step:19886 [D loss: 0.227956, acc.: 64.06%] [G loss: 0.291503]\n",
      "epoch:21 step:19887 [D loss: 0.227890, acc.: 57.81%] [G loss: 0.300522]\n",
      "epoch:21 step:19888 [D loss: 0.240349, acc.: 55.47%] [G loss: 0.301807]\n",
      "epoch:21 step:19889 [D loss: 0.236702, acc.: 62.50%] [G loss: 0.322622]\n",
      "epoch:21 step:19890 [D loss: 0.251650, acc.: 50.00%] [G loss: 0.303120]\n",
      "epoch:21 step:19891 [D loss: 0.258429, acc.: 48.44%] [G loss: 0.326234]\n",
      "epoch:21 step:19892 [D loss: 0.253375, acc.: 54.69%] [G loss: 0.294009]\n",
      "epoch:21 step:19893 [D loss: 0.238485, acc.: 60.16%] [G loss: 0.289785]\n",
      "epoch:21 step:19894 [D loss: 0.246001, acc.: 51.56%] [G loss: 0.285021]\n",
      "epoch:21 step:19895 [D loss: 0.241399, acc.: 57.03%] [G loss: 0.316940]\n",
      "epoch:21 step:19896 [D loss: 0.237276, acc.: 56.25%] [G loss: 0.278703]\n",
      "epoch:21 step:19897 [D loss: 0.245845, acc.: 54.69%] [G loss: 0.281863]\n",
      "epoch:21 step:19898 [D loss: 0.226881, acc.: 60.16%] [G loss: 0.323011]\n",
      "epoch:21 step:19899 [D loss: 0.237504, acc.: 58.59%] [G loss: 0.290339]\n",
      "epoch:21 step:19900 [D loss: 0.236053, acc.: 60.16%] [G loss: 0.337789]\n",
      "epoch:21 step:19901 [D loss: 0.229925, acc.: 62.50%] [G loss: 0.308591]\n",
      "epoch:21 step:19902 [D loss: 0.250269, acc.: 53.12%] [G loss: 0.270329]\n",
      "epoch:21 step:19903 [D loss: 0.244514, acc.: 53.91%] [G loss: 0.304980]\n",
      "epoch:21 step:19904 [D loss: 0.250661, acc.: 51.56%] [G loss: 0.283080]\n",
      "epoch:21 step:19905 [D loss: 0.249067, acc.: 57.81%] [G loss: 0.330895]\n",
      "epoch:21 step:19906 [D loss: 0.234435, acc.: 59.38%] [G loss: 0.309914]\n",
      "epoch:21 step:19907 [D loss: 0.246339, acc.: 54.69%] [G loss: 0.295202]\n",
      "epoch:21 step:19908 [D loss: 0.234314, acc.: 63.28%] [G loss: 0.294716]\n",
      "epoch:21 step:19909 [D loss: 0.260500, acc.: 50.00%] [G loss: 0.310193]\n",
      "epoch:21 step:19910 [D loss: 0.248676, acc.: 60.94%] [G loss: 0.291527]\n",
      "epoch:21 step:19911 [D loss: 0.230443, acc.: 64.06%] [G loss: 0.305729]\n",
      "epoch:21 step:19912 [D loss: 0.233340, acc.: 64.84%] [G loss: 0.282349]\n",
      "epoch:21 step:19913 [D loss: 0.256863, acc.: 53.91%] [G loss: 0.293248]\n",
      "epoch:21 step:19914 [D loss: 0.220022, acc.: 67.97%] [G loss: 0.296013]\n",
      "epoch:21 step:19915 [D loss: 0.239483, acc.: 57.81%] [G loss: 0.300439]\n",
      "epoch:21 step:19916 [D loss: 0.249456, acc.: 53.12%] [G loss: 0.299503]\n",
      "epoch:21 step:19917 [D loss: 0.234181, acc.: 58.59%] [G loss: 0.306923]\n",
      "epoch:21 step:19918 [D loss: 0.264627, acc.: 46.09%] [G loss: 0.317962]\n",
      "epoch:21 step:19919 [D loss: 0.254966, acc.: 55.47%] [G loss: 0.283647]\n",
      "epoch:21 step:19920 [D loss: 0.266063, acc.: 47.66%] [G loss: 0.279217]\n",
      "epoch:21 step:19921 [D loss: 0.231592, acc.: 61.72%] [G loss: 0.287030]\n",
      "epoch:21 step:19922 [D loss: 0.244542, acc.: 53.12%] [G loss: 0.293602]\n",
      "epoch:21 step:19923 [D loss: 0.231905, acc.: 61.72%] [G loss: 0.311318]\n",
      "epoch:21 step:19924 [D loss: 0.244384, acc.: 56.25%] [G loss: 0.305769]\n",
      "epoch:21 step:19925 [D loss: 0.212049, acc.: 63.28%] [G loss: 0.351466]\n",
      "epoch:21 step:19926 [D loss: 0.252358, acc.: 50.00%] [G loss: 0.313615]\n",
      "epoch:21 step:19927 [D loss: 0.229516, acc.: 60.94%] [G loss: 0.300025]\n",
      "epoch:21 step:19928 [D loss: 0.233950, acc.: 60.16%] [G loss: 0.293883]\n",
      "epoch:21 step:19929 [D loss: 0.227584, acc.: 62.50%] [G loss: 0.285194]\n",
      "epoch:21 step:19930 [D loss: 0.220202, acc.: 64.06%] [G loss: 0.315958]\n",
      "epoch:21 step:19931 [D loss: 0.249741, acc.: 52.34%] [G loss: 0.288064]\n",
      "epoch:21 step:19932 [D loss: 0.242160, acc.: 50.78%] [G loss: 0.322713]\n",
      "epoch:21 step:19933 [D loss: 0.236833, acc.: 60.94%] [G loss: 0.282895]\n",
      "epoch:21 step:19934 [D loss: 0.233005, acc.: 64.06%] [G loss: 0.292631]\n",
      "epoch:21 step:19935 [D loss: 0.232502, acc.: 58.59%] [G loss: 0.295714]\n",
      "epoch:21 step:19936 [D loss: 0.238381, acc.: 57.81%] [G loss: 0.308366]\n",
      "epoch:21 step:19937 [D loss: 0.233624, acc.: 62.50%] [G loss: 0.313180]\n",
      "epoch:21 step:19938 [D loss: 0.237794, acc.: 58.59%] [G loss: 0.289224]\n",
      "epoch:21 step:19939 [D loss: 0.238638, acc.: 60.94%] [G loss: 0.333684]\n",
      "epoch:21 step:19940 [D loss: 0.259150, acc.: 48.44%] [G loss: 0.305298]\n",
      "epoch:21 step:19941 [D loss: 0.266703, acc.: 50.78%] [G loss: 0.313460]\n",
      "epoch:21 step:19942 [D loss: 0.249244, acc.: 53.12%] [G loss: 0.300832]\n",
      "epoch:21 step:19943 [D loss: 0.234028, acc.: 65.62%] [G loss: 0.280087]\n",
      "epoch:21 step:19944 [D loss: 0.226622, acc.: 64.84%] [G loss: 0.302337]\n",
      "epoch:21 step:19945 [D loss: 0.244820, acc.: 61.72%] [G loss: 0.318562]\n",
      "epoch:21 step:19946 [D loss: 0.222757, acc.: 65.62%] [G loss: 0.307399]\n",
      "epoch:21 step:19947 [D loss: 0.251515, acc.: 55.47%] [G loss: 0.305158]\n",
      "epoch:21 step:19948 [D loss: 0.244977, acc.: 57.81%] [G loss: 0.278261]\n",
      "epoch:21 step:19949 [D loss: 0.239588, acc.: 56.25%] [G loss: 0.334567]\n",
      "epoch:21 step:19950 [D loss: 0.243492, acc.: 52.34%] [G loss: 0.310331]\n",
      "epoch:21 step:19951 [D loss: 0.254026, acc.: 53.12%] [G loss: 0.314472]\n",
      "epoch:21 step:19952 [D loss: 0.254020, acc.: 57.81%] [G loss: 0.286557]\n",
      "epoch:21 step:19953 [D loss: 0.250127, acc.: 54.69%] [G loss: 0.305979]\n",
      "epoch:21 step:19954 [D loss: 0.240710, acc.: 56.25%] [G loss: 0.292639]\n",
      "epoch:21 step:19955 [D loss: 0.248295, acc.: 53.12%] [G loss: 0.296729]\n",
      "epoch:21 step:19956 [D loss: 0.249587, acc.: 54.69%] [G loss: 0.284205]\n",
      "epoch:21 step:19957 [D loss: 0.240002, acc.: 61.72%] [G loss: 0.302789]\n",
      "epoch:21 step:19958 [D loss: 0.221006, acc.: 62.50%] [G loss: 0.288771]\n",
      "epoch:21 step:19959 [D loss: 0.220288, acc.: 63.28%] [G loss: 0.307436]\n",
      "epoch:21 step:19960 [D loss: 0.245407, acc.: 60.94%] [G loss: 0.295382]\n",
      "epoch:21 step:19961 [D loss: 0.240751, acc.: 57.81%] [G loss: 0.331721]\n",
      "epoch:21 step:19962 [D loss: 0.229451, acc.: 62.50%] [G loss: 0.308247]\n",
      "epoch:21 step:19963 [D loss: 0.236402, acc.: 55.47%] [G loss: 0.295000]\n",
      "epoch:21 step:19964 [D loss: 0.223712, acc.: 65.62%] [G loss: 0.323239]\n",
      "epoch:21 step:19965 [D loss: 0.236303, acc.: 63.28%] [G loss: 0.298135]\n",
      "epoch:21 step:19966 [D loss: 0.233219, acc.: 60.94%] [G loss: 0.274659]\n",
      "epoch:21 step:19967 [D loss: 0.227276, acc.: 61.72%] [G loss: 0.304685]\n",
      "epoch:21 step:19968 [D loss: 0.255355, acc.: 54.69%] [G loss: 0.284470]\n",
      "epoch:21 step:19969 [D loss: 0.244318, acc.: 57.81%] [G loss: 0.303018]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:21 step:19970 [D loss: 0.235103, acc.: 61.72%] [G loss: 0.299083]\n",
      "epoch:21 step:19971 [D loss: 0.220892, acc.: 64.84%] [G loss: 0.332678]\n",
      "epoch:21 step:19972 [D loss: 0.254148, acc.: 54.69%] [G loss: 0.292331]\n",
      "epoch:21 step:19973 [D loss: 0.240088, acc.: 52.34%] [G loss: 0.326971]\n",
      "epoch:21 step:19974 [D loss: 0.230574, acc.: 61.72%] [G loss: 0.304140]\n",
      "epoch:21 step:19975 [D loss: 0.237967, acc.: 61.72%] [G loss: 0.293663]\n",
      "epoch:21 step:19976 [D loss: 0.231999, acc.: 62.50%] [G loss: 0.317640]\n",
      "epoch:21 step:19977 [D loss: 0.244201, acc.: 58.59%] [G loss: 0.297116]\n",
      "epoch:21 step:19978 [D loss: 0.235819, acc.: 60.94%] [G loss: 0.298694]\n",
      "epoch:21 step:19979 [D loss: 0.246047, acc.: 55.47%] [G loss: 0.284196]\n",
      "epoch:21 step:19980 [D loss: 0.243804, acc.: 56.25%] [G loss: 0.289267]\n",
      "epoch:21 step:19981 [D loss: 0.225678, acc.: 64.06%] [G loss: 0.330226]\n",
      "epoch:21 step:19982 [D loss: 0.233162, acc.: 59.38%] [G loss: 0.306001]\n",
      "epoch:21 step:19983 [D loss: 0.221942, acc.: 68.75%] [G loss: 0.317629]\n",
      "epoch:21 step:19984 [D loss: 0.252502, acc.: 53.91%] [G loss: 0.268402]\n",
      "epoch:21 step:19985 [D loss: 0.236851, acc.: 55.47%] [G loss: 0.319261]\n",
      "epoch:21 step:19986 [D loss: 0.254692, acc.: 47.66%] [G loss: 0.295625]\n",
      "epoch:21 step:19987 [D loss: 0.262786, acc.: 50.78%] [G loss: 0.260182]\n",
      "epoch:21 step:19988 [D loss: 0.238960, acc.: 58.59%] [G loss: 0.294207]\n",
      "epoch:21 step:19989 [D loss: 0.246082, acc.: 51.56%] [G loss: 0.309197]\n",
      "epoch:21 step:19990 [D loss: 0.234908, acc.: 65.62%] [G loss: 0.305934]\n",
      "epoch:21 step:19991 [D loss: 0.244390, acc.: 54.69%] [G loss: 0.279808]\n",
      "epoch:21 step:19992 [D loss: 0.237076, acc.: 62.50%] [G loss: 0.317049]\n",
      "epoch:21 step:19993 [D loss: 0.232276, acc.: 60.16%] [G loss: 0.282426]\n",
      "epoch:21 step:19994 [D loss: 0.231291, acc.: 63.28%] [G loss: 0.296853]\n",
      "epoch:21 step:19995 [D loss: 0.238889, acc.: 61.72%] [G loss: 0.286828]\n",
      "epoch:21 step:19996 [D loss: 0.225418, acc.: 59.38%] [G loss: 0.284059]\n",
      "epoch:21 step:19997 [D loss: 0.238324, acc.: 59.38%] [G loss: 0.266796]\n",
      "epoch:21 step:19998 [D loss: 0.235607, acc.: 58.59%] [G loss: 0.296806]\n",
      "epoch:21 step:19999 [D loss: 0.223134, acc.: 68.75%] [G loss: 0.298231]\n",
      "epoch:21 step:20000 [D loss: 0.236689, acc.: 53.91%] [G loss: 0.304905]\n",
      "epoch:21 step:20001 [D loss: 0.252472, acc.: 53.91%] [G loss: 0.315243]\n",
      "epoch:21 step:20002 [D loss: 0.222847, acc.: 64.06%] [G loss: 0.285743]\n",
      "epoch:21 step:20003 [D loss: 0.244030, acc.: 57.03%] [G loss: 0.280058]\n",
      "epoch:21 step:20004 [D loss: 0.231125, acc.: 60.94%] [G loss: 0.313087]\n",
      "epoch:21 step:20005 [D loss: 0.221281, acc.: 59.38%] [G loss: 0.302649]\n",
      "epoch:21 step:20006 [D loss: 0.228658, acc.: 61.72%] [G loss: 0.284188]\n",
      "epoch:21 step:20007 [D loss: 0.232535, acc.: 53.91%] [G loss: 0.276227]\n",
      "epoch:21 step:20008 [D loss: 0.236923, acc.: 61.72%] [G loss: 0.297197]\n",
      "epoch:21 step:20009 [D loss: 0.230305, acc.: 62.50%] [G loss: 0.271320]\n",
      "epoch:21 step:20010 [D loss: 0.229028, acc.: 64.84%] [G loss: 0.284897]\n",
      "epoch:21 step:20011 [D loss: 0.229323, acc.: 62.50%] [G loss: 0.311695]\n",
      "epoch:21 step:20012 [D loss: 0.238849, acc.: 57.81%] [G loss: 0.277893]\n",
      "epoch:21 step:20013 [D loss: 0.226673, acc.: 60.16%] [G loss: 0.318600]\n",
      "epoch:21 step:20014 [D loss: 0.243449, acc.: 56.25%] [G loss: 0.288018]\n",
      "epoch:21 step:20015 [D loss: 0.208806, acc.: 63.28%] [G loss: 0.309955]\n",
      "epoch:21 step:20016 [D loss: 0.214318, acc.: 66.41%] [G loss: 0.309372]\n",
      "epoch:21 step:20017 [D loss: 0.240548, acc.: 54.69%] [G loss: 0.290034]\n",
      "epoch:21 step:20018 [D loss: 0.240903, acc.: 55.47%] [G loss: 0.323494]\n",
      "epoch:21 step:20019 [D loss: 0.250942, acc.: 52.34%] [G loss: 0.304530]\n",
      "epoch:21 step:20020 [D loss: 0.256494, acc.: 47.66%] [G loss: 0.297150]\n",
      "epoch:21 step:20021 [D loss: 0.236724, acc.: 59.38%] [G loss: 0.280523]\n",
      "epoch:21 step:20022 [D loss: 0.232216, acc.: 62.50%] [G loss: 0.318326]\n",
      "epoch:21 step:20023 [D loss: 0.245293, acc.: 57.03%] [G loss: 0.297343]\n",
      "epoch:21 step:20024 [D loss: 0.233981, acc.: 64.06%] [G loss: 0.271524]\n",
      "epoch:21 step:20025 [D loss: 0.255853, acc.: 53.12%] [G loss: 0.293729]\n",
      "epoch:21 step:20026 [D loss: 0.235931, acc.: 61.72%] [G loss: 0.314042]\n",
      "epoch:21 step:20027 [D loss: 0.243106, acc.: 53.12%] [G loss: 0.329637]\n",
      "epoch:21 step:20028 [D loss: 0.239178, acc.: 53.91%] [G loss: 0.293726]\n",
      "epoch:21 step:20029 [D loss: 0.235523, acc.: 54.69%] [G loss: 0.288169]\n",
      "epoch:21 step:20030 [D loss: 0.225391, acc.: 67.97%] [G loss: 0.326603]\n",
      "epoch:21 step:20031 [D loss: 0.242348, acc.: 60.94%] [G loss: 0.286551]\n",
      "epoch:21 step:20032 [D loss: 0.252434, acc.: 53.12%] [G loss: 0.300767]\n",
      "epoch:21 step:20033 [D loss: 0.226859, acc.: 67.19%] [G loss: 0.309851]\n",
      "epoch:21 step:20034 [D loss: 0.225283, acc.: 64.84%] [G loss: 0.305509]\n",
      "epoch:21 step:20035 [D loss: 0.236464, acc.: 57.81%] [G loss: 0.276320]\n",
      "epoch:21 step:20036 [D loss: 0.237429, acc.: 55.47%] [G loss: 0.295836]\n",
      "epoch:21 step:20037 [D loss: 0.220725, acc.: 67.19%] [G loss: 0.339812]\n",
      "epoch:21 step:20038 [D loss: 0.239907, acc.: 60.16%] [G loss: 0.303514]\n",
      "epoch:21 step:20039 [D loss: 0.240446, acc.: 57.03%] [G loss: 0.321818]\n",
      "epoch:21 step:20040 [D loss: 0.237918, acc.: 60.94%] [G loss: 0.307245]\n",
      "epoch:21 step:20041 [D loss: 0.237210, acc.: 58.59%] [G loss: 0.293954]\n",
      "epoch:21 step:20042 [D loss: 0.241280, acc.: 58.59%] [G loss: 0.312661]\n",
      "epoch:21 step:20043 [D loss: 0.228293, acc.: 64.84%] [G loss: 0.316031]\n",
      "epoch:21 step:20044 [D loss: 0.249031, acc.: 55.47%] [G loss: 0.322369]\n",
      "epoch:21 step:20045 [D loss: 0.252275, acc.: 52.34%] [G loss: 0.321765]\n",
      "epoch:21 step:20046 [D loss: 0.245940, acc.: 60.16%] [G loss: 0.300463]\n",
      "epoch:21 step:20047 [D loss: 0.240889, acc.: 58.59%] [G loss: 0.308801]\n",
      "epoch:21 step:20048 [D loss: 0.248837, acc.: 54.69%] [G loss: 0.294249]\n",
      "epoch:21 step:20049 [D loss: 0.244580, acc.: 56.25%] [G loss: 0.319345]\n",
      "epoch:21 step:20050 [D loss: 0.215425, acc.: 67.19%] [G loss: 0.305614]\n",
      "epoch:21 step:20051 [D loss: 0.247673, acc.: 55.47%] [G loss: 0.334444]\n",
      "epoch:21 step:20052 [D loss: 0.230627, acc.: 57.03%] [G loss: 0.298905]\n",
      "epoch:21 step:20053 [D loss: 0.253586, acc.: 52.34%] [G loss: 0.312821]\n",
      "epoch:21 step:20054 [D loss: 0.237499, acc.: 64.84%] [G loss: 0.303276]\n",
      "epoch:21 step:20055 [D loss: 0.230648, acc.: 57.81%] [G loss: 0.298233]\n",
      "epoch:21 step:20056 [D loss: 0.249532, acc.: 51.56%] [G loss: 0.304462]\n",
      "epoch:21 step:20057 [D loss: 0.249427, acc.: 54.69%] [G loss: 0.288271]\n",
      "epoch:21 step:20058 [D loss: 0.238728, acc.: 61.72%] [G loss: 0.294231]\n",
      "epoch:21 step:20059 [D loss: 0.216930, acc.: 67.97%] [G loss: 0.290411]\n",
      "epoch:21 step:20060 [D loss: 0.229678, acc.: 62.50%] [G loss: 0.307665]\n",
      "epoch:21 step:20061 [D loss: 0.229598, acc.: 61.72%] [G loss: 0.345665]\n",
      "epoch:21 step:20062 [D loss: 0.235338, acc.: 62.50%] [G loss: 0.284944]\n",
      "epoch:21 step:20063 [D loss: 0.231833, acc.: 60.16%] [G loss: 0.286617]\n",
      "epoch:21 step:20064 [D loss: 0.243627, acc.: 57.81%] [G loss: 0.325816]\n",
      "epoch:21 step:20065 [D loss: 0.247277, acc.: 57.03%] [G loss: 0.315969]\n",
      "epoch:21 step:20066 [D loss: 0.234197, acc.: 60.94%] [G loss: 0.263231]\n",
      "epoch:21 step:20067 [D loss: 0.240280, acc.: 57.03%] [G loss: 0.293346]\n",
      "epoch:21 step:20068 [D loss: 0.246243, acc.: 53.12%] [G loss: 0.299893]\n",
      "epoch:21 step:20069 [D loss: 0.252308, acc.: 53.91%] [G loss: 0.303263]\n",
      "epoch:21 step:20070 [D loss: 0.250385, acc.: 54.69%] [G loss: 0.303072]\n",
      "epoch:21 step:20071 [D loss: 0.240174, acc.: 57.81%] [G loss: 0.304225]\n",
      "epoch:21 step:20072 [D loss: 0.230514, acc.: 60.94%] [G loss: 0.327283]\n",
      "epoch:21 step:20073 [D loss: 0.243556, acc.: 60.16%] [G loss: 0.305429]\n",
      "epoch:21 step:20074 [D loss: 0.233969, acc.: 60.16%] [G loss: 0.320678]\n",
      "epoch:21 step:20075 [D loss: 0.229615, acc.: 58.59%] [G loss: 0.333237]\n",
      "epoch:21 step:20076 [D loss: 0.237264, acc.: 58.59%] [G loss: 0.314573]\n",
      "epoch:21 step:20077 [D loss: 0.238162, acc.: 60.94%] [G loss: 0.331816]\n",
      "epoch:21 step:20078 [D loss: 0.234786, acc.: 61.72%] [G loss: 0.305326]\n",
      "epoch:21 step:20079 [D loss: 0.228355, acc.: 60.94%] [G loss: 0.316793]\n",
      "epoch:21 step:20080 [D loss: 0.249993, acc.: 53.12%] [G loss: 0.315375]\n",
      "epoch:21 step:20081 [D loss: 0.230501, acc.: 61.72%] [G loss: 0.276810]\n",
      "epoch:21 step:20082 [D loss: 0.229154, acc.: 57.03%] [G loss: 0.289895]\n",
      "epoch:21 step:20083 [D loss: 0.253252, acc.: 53.12%] [G loss: 0.303230]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:21 step:20084 [D loss: 0.255505, acc.: 55.47%] [G loss: 0.303744]\n",
      "epoch:21 step:20085 [D loss: 0.223341, acc.: 64.06%] [G loss: 0.319313]\n",
      "epoch:21 step:20086 [D loss: 0.236968, acc.: 56.25%] [G loss: 0.305612]\n",
      "epoch:21 step:20087 [D loss: 0.237147, acc.: 58.59%] [G loss: 0.310549]\n",
      "epoch:21 step:20088 [D loss: 0.258444, acc.: 50.78%] [G loss: 0.283066]\n",
      "epoch:21 step:20089 [D loss: 0.268174, acc.: 47.66%] [G loss: 0.301784]\n",
      "epoch:21 step:20090 [D loss: 0.258073, acc.: 52.34%] [G loss: 0.283132]\n",
      "epoch:21 step:20091 [D loss: 0.243401, acc.: 58.59%] [G loss: 0.311352]\n",
      "epoch:21 step:20092 [D loss: 0.262374, acc.: 52.34%] [G loss: 0.316721]\n",
      "epoch:21 step:20093 [D loss: 0.226449, acc.: 60.94%] [G loss: 0.296414]\n",
      "epoch:21 step:20094 [D loss: 0.248732, acc.: 52.34%] [G loss: 0.304563]\n",
      "epoch:21 step:20095 [D loss: 0.252020, acc.: 54.69%] [G loss: 0.313188]\n",
      "epoch:21 step:20096 [D loss: 0.235480, acc.: 60.94%] [G loss: 0.314060]\n",
      "epoch:21 step:20097 [D loss: 0.248590, acc.: 53.12%] [G loss: 0.327065]\n",
      "epoch:21 step:20098 [D loss: 0.239485, acc.: 61.72%] [G loss: 0.315010]\n",
      "epoch:21 step:20099 [D loss: 0.222274, acc.: 65.62%] [G loss: 0.321106]\n",
      "epoch:21 step:20100 [D loss: 0.232280, acc.: 54.69%] [G loss: 0.307617]\n",
      "epoch:21 step:20101 [D loss: 0.248048, acc.: 55.47%] [G loss: 0.309454]\n",
      "epoch:21 step:20102 [D loss: 0.258668, acc.: 50.78%] [G loss: 0.297083]\n",
      "epoch:21 step:20103 [D loss: 0.230464, acc.: 64.06%] [G loss: 0.305892]\n",
      "epoch:21 step:20104 [D loss: 0.240072, acc.: 57.03%] [G loss: 0.271041]\n",
      "epoch:21 step:20105 [D loss: 0.234552, acc.: 56.25%] [G loss: 0.289309]\n",
      "epoch:21 step:20106 [D loss: 0.265502, acc.: 51.56%] [G loss: 0.292007]\n",
      "epoch:21 step:20107 [D loss: 0.244985, acc.: 50.78%] [G loss: 0.314592]\n",
      "epoch:21 step:20108 [D loss: 0.226698, acc.: 61.72%] [G loss: 0.314921]\n",
      "epoch:21 step:20109 [D loss: 0.206617, acc.: 69.53%] [G loss: 0.318247]\n",
      "epoch:21 step:20110 [D loss: 0.234348, acc.: 60.16%] [G loss: 0.280892]\n",
      "epoch:21 step:20111 [D loss: 0.235932, acc.: 60.16%] [G loss: 0.302547]\n",
      "epoch:21 step:20112 [D loss: 0.254421, acc.: 51.56%] [G loss: 0.299536]\n",
      "epoch:21 step:20113 [D loss: 0.248779, acc.: 56.25%] [G loss: 0.319143]\n",
      "epoch:21 step:20114 [D loss: 0.252192, acc.: 47.66%] [G loss: 0.301673]\n",
      "epoch:21 step:20115 [D loss: 0.247567, acc.: 54.69%] [G loss: 0.284780]\n",
      "epoch:21 step:20116 [D loss: 0.235119, acc.: 60.16%] [G loss: 0.317586]\n",
      "epoch:21 step:20117 [D loss: 0.219089, acc.: 65.62%] [G loss: 0.299968]\n",
      "epoch:21 step:20118 [D loss: 0.231581, acc.: 60.94%] [G loss: 0.291885]\n",
      "epoch:21 step:20119 [D loss: 0.236174, acc.: 60.94%] [G loss: 0.291273]\n",
      "epoch:21 step:20120 [D loss: 0.231534, acc.: 58.59%] [G loss: 0.286386]\n",
      "epoch:21 step:20121 [D loss: 0.256801, acc.: 52.34%] [G loss: 0.298892]\n",
      "epoch:21 step:20122 [D loss: 0.233249, acc.: 63.28%] [G loss: 0.310473]\n",
      "epoch:21 step:20123 [D loss: 0.254119, acc.: 53.12%] [G loss: 0.295845]\n",
      "epoch:21 step:20124 [D loss: 0.242188, acc.: 57.03%] [G loss: 0.312881]\n",
      "epoch:21 step:20125 [D loss: 0.246864, acc.: 56.25%] [G loss: 0.285363]\n",
      "epoch:21 step:20126 [D loss: 0.221189, acc.: 63.28%] [G loss: 0.314424]\n",
      "epoch:21 step:20127 [D loss: 0.238557, acc.: 53.12%] [G loss: 0.324010]\n",
      "epoch:21 step:20128 [D loss: 0.225850, acc.: 59.38%] [G loss: 0.365495]\n",
      "epoch:21 step:20129 [D loss: 0.252430, acc.: 57.03%] [G loss: 0.306972]\n",
      "epoch:21 step:20130 [D loss: 0.227984, acc.: 62.50%] [G loss: 0.325729]\n",
      "epoch:21 step:20131 [D loss: 0.228659, acc.: 62.50%] [G loss: 0.327114]\n",
      "epoch:21 step:20132 [D loss: 0.224746, acc.: 64.06%] [G loss: 0.294746]\n",
      "epoch:21 step:20133 [D loss: 0.236279, acc.: 58.59%] [G loss: 0.331945]\n",
      "epoch:21 step:20134 [D loss: 0.237549, acc.: 60.94%] [G loss: 0.322057]\n",
      "epoch:21 step:20135 [D loss: 0.229955, acc.: 58.59%] [G loss: 0.292341]\n",
      "epoch:21 step:20136 [D loss: 0.243307, acc.: 55.47%] [G loss: 0.326075]\n",
      "epoch:21 step:20137 [D loss: 0.271531, acc.: 46.88%] [G loss: 0.294956]\n",
      "epoch:21 step:20138 [D loss: 0.235445, acc.: 59.38%] [G loss: 0.300739]\n",
      "epoch:21 step:20139 [D loss: 0.247944, acc.: 50.78%] [G loss: 0.297361]\n",
      "epoch:21 step:20140 [D loss: 0.223638, acc.: 64.84%] [G loss: 0.295469]\n",
      "epoch:21 step:20141 [D loss: 0.254907, acc.: 46.88%] [G loss: 0.281601]\n",
      "epoch:21 step:20142 [D loss: 0.255908, acc.: 51.56%] [G loss: 0.304370]\n",
      "epoch:21 step:20143 [D loss: 0.243738, acc.: 50.78%] [G loss: 0.313901]\n",
      "epoch:21 step:20144 [D loss: 0.238724, acc.: 59.38%] [G loss: 0.311671]\n",
      "epoch:21 step:20145 [D loss: 0.204383, acc.: 73.44%] [G loss: 0.319163]\n",
      "epoch:21 step:20146 [D loss: 0.234320, acc.: 59.38%] [G loss: 0.309789]\n",
      "epoch:21 step:20147 [D loss: 0.248353, acc.: 56.25%] [G loss: 0.309699]\n",
      "epoch:21 step:20148 [D loss: 0.261927, acc.: 50.00%] [G loss: 0.296737]\n",
      "epoch:21 step:20149 [D loss: 0.255906, acc.: 49.22%] [G loss: 0.316263]\n",
      "epoch:21 step:20150 [D loss: 0.248249, acc.: 53.91%] [G loss: 0.320380]\n",
      "epoch:21 step:20151 [D loss: 0.231040, acc.: 62.50%] [G loss: 0.319877]\n",
      "epoch:21 step:20152 [D loss: 0.225227, acc.: 58.59%] [G loss: 0.320216]\n",
      "epoch:21 step:20153 [D loss: 0.231707, acc.: 64.06%] [G loss: 0.301642]\n",
      "epoch:21 step:20154 [D loss: 0.232381, acc.: 55.47%] [G loss: 0.331927]\n",
      "epoch:21 step:20155 [D loss: 0.246432, acc.: 60.16%] [G loss: 0.287870]\n",
      "epoch:21 step:20156 [D loss: 0.225938, acc.: 64.06%] [G loss: 0.322067]\n",
      "epoch:21 step:20157 [D loss: 0.255104, acc.: 55.47%] [G loss: 0.273528]\n",
      "epoch:21 step:20158 [D loss: 0.232691, acc.: 59.38%] [G loss: 0.297279]\n",
      "epoch:21 step:20159 [D loss: 0.227067, acc.: 62.50%] [G loss: 0.283431]\n",
      "epoch:21 step:20160 [D loss: 0.243935, acc.: 60.94%] [G loss: 0.303912]\n",
      "epoch:21 step:20161 [D loss: 0.230276, acc.: 59.38%] [G loss: 0.307567]\n",
      "epoch:21 step:20162 [D loss: 0.229416, acc.: 64.84%] [G loss: 0.331598]\n",
      "epoch:21 step:20163 [D loss: 0.245383, acc.: 56.25%] [G loss: 0.317622]\n",
      "epoch:21 step:20164 [D loss: 0.226878, acc.: 63.28%] [G loss: 0.320640]\n",
      "epoch:21 step:20165 [D loss: 0.232854, acc.: 56.25%] [G loss: 0.308319]\n",
      "epoch:21 step:20166 [D loss: 0.248151, acc.: 58.59%] [G loss: 0.288426]\n",
      "epoch:21 step:20167 [D loss: 0.225495, acc.: 63.28%] [G loss: 0.292203]\n",
      "epoch:21 step:20168 [D loss: 0.226691, acc.: 63.28%] [G loss: 0.290016]\n",
      "epoch:21 step:20169 [D loss: 0.235754, acc.: 56.25%] [G loss: 0.327624]\n",
      "epoch:21 step:20170 [D loss: 0.226436, acc.: 63.28%] [G loss: 0.319882]\n",
      "epoch:21 step:20171 [D loss: 0.212892, acc.: 64.84%] [G loss: 0.299087]\n",
      "epoch:21 step:20172 [D loss: 0.227390, acc.: 62.50%] [G loss: 0.291823]\n",
      "epoch:21 step:20173 [D loss: 0.247318, acc.: 52.34%] [G loss: 0.281590]\n",
      "epoch:21 step:20174 [D loss: 0.241032, acc.: 57.81%] [G loss: 0.305714]\n",
      "epoch:21 step:20175 [D loss: 0.249275, acc.: 52.34%] [G loss: 0.307251]\n",
      "epoch:21 step:20176 [D loss: 0.231006, acc.: 63.28%] [G loss: 0.299326]\n",
      "epoch:21 step:20177 [D loss: 0.246187, acc.: 53.91%] [G loss: 0.300113]\n",
      "epoch:21 step:20178 [D loss: 0.229164, acc.: 64.84%] [G loss: 0.279427]\n",
      "epoch:21 step:20179 [D loss: 0.220145, acc.: 69.53%] [G loss: 0.306788]\n",
      "epoch:21 step:20180 [D loss: 0.236452, acc.: 60.16%] [G loss: 0.296816]\n",
      "epoch:21 step:20181 [D loss: 0.245619, acc.: 53.91%] [G loss: 0.305276]\n",
      "epoch:21 step:20182 [D loss: 0.219798, acc.: 63.28%] [G loss: 0.296024]\n",
      "epoch:21 step:20183 [D loss: 0.235646, acc.: 60.16%] [G loss: 0.300372]\n",
      "epoch:21 step:20184 [D loss: 0.252640, acc.: 57.81%] [G loss: 0.298984]\n",
      "epoch:21 step:20185 [D loss: 0.237325, acc.: 57.81%] [G loss: 0.309791]\n",
      "epoch:21 step:20186 [D loss: 0.249080, acc.: 56.25%] [G loss: 0.300734]\n",
      "epoch:21 step:20187 [D loss: 0.237511, acc.: 56.25%] [G loss: 0.311607]\n",
      "epoch:21 step:20188 [D loss: 0.241035, acc.: 57.81%] [G loss: 0.284896]\n",
      "epoch:21 step:20189 [D loss: 0.238879, acc.: 56.25%] [G loss: 0.261459]\n",
      "epoch:21 step:20190 [D loss: 0.231990, acc.: 61.72%] [G loss: 0.296429]\n",
      "epoch:21 step:20191 [D loss: 0.235702, acc.: 60.94%] [G loss: 0.345474]\n",
      "epoch:21 step:20192 [D loss: 0.250340, acc.: 54.69%] [G loss: 0.287396]\n",
      "epoch:21 step:20193 [D loss: 0.234563, acc.: 59.38%] [G loss: 0.297073]\n",
      "epoch:21 step:20194 [D loss: 0.253181, acc.: 50.00%] [G loss: 0.300793]\n",
      "epoch:21 step:20195 [D loss: 0.250077, acc.: 53.12%] [G loss: 0.303365]\n",
      "epoch:21 step:20196 [D loss: 0.235206, acc.: 54.69%] [G loss: 0.290969]\n",
      "epoch:21 step:20197 [D loss: 0.217425, acc.: 63.28%] [G loss: 0.322998]\n",
      "epoch:21 step:20198 [D loss: 0.256064, acc.: 52.34%] [G loss: 0.292888]\n",
      "epoch:21 step:20199 [D loss: 0.245163, acc.: 57.03%] [G loss: 0.313628]\n",
      "epoch:21 step:20200 [D loss: 0.231697, acc.: 63.28%] [G loss: 0.312679]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:21 step:20201 [D loss: 0.235542, acc.: 57.81%] [G loss: 0.310444]\n",
      "epoch:21 step:20202 [D loss: 0.252150, acc.: 56.25%] [G loss: 0.305560]\n",
      "epoch:21 step:20203 [D loss: 0.238125, acc.: 60.16%] [G loss: 0.313496]\n",
      "epoch:21 step:20204 [D loss: 0.235599, acc.: 57.81%] [G loss: 0.315023]\n",
      "epoch:21 step:20205 [D loss: 0.249257, acc.: 49.22%] [G loss: 0.305339]\n",
      "epoch:21 step:20206 [D loss: 0.219588, acc.: 68.75%] [G loss: 0.318625]\n",
      "epoch:21 step:20207 [D loss: 0.243583, acc.: 58.59%] [G loss: 0.300604]\n",
      "epoch:21 step:20208 [D loss: 0.237013, acc.: 56.25%] [G loss: 0.289699]\n",
      "epoch:21 step:20209 [D loss: 0.255433, acc.: 50.00%] [G loss: 0.299282]\n",
      "epoch:21 step:20210 [D loss: 0.237257, acc.: 60.16%] [G loss: 0.314333]\n",
      "epoch:21 step:20211 [D loss: 0.238468, acc.: 58.59%] [G loss: 0.304620]\n",
      "epoch:21 step:20212 [D loss: 0.256217, acc.: 50.78%] [G loss: 0.296166]\n",
      "epoch:21 step:20213 [D loss: 0.242050, acc.: 53.91%] [G loss: 0.328247]\n",
      "epoch:21 step:20214 [D loss: 0.235762, acc.: 64.84%] [G loss: 0.295360]\n",
      "epoch:21 step:20215 [D loss: 0.253285, acc.: 55.47%] [G loss: 0.317564]\n",
      "epoch:21 step:20216 [D loss: 0.220524, acc.: 65.62%] [G loss: 0.283790]\n",
      "epoch:21 step:20217 [D loss: 0.216976, acc.: 66.41%] [G loss: 0.292850]\n",
      "epoch:21 step:20218 [D loss: 0.234081, acc.: 62.50%] [G loss: 0.300328]\n",
      "epoch:21 step:20219 [D loss: 0.236352, acc.: 60.16%] [G loss: 0.287567]\n",
      "epoch:21 step:20220 [D loss: 0.240170, acc.: 56.25%] [G loss: 0.266396]\n",
      "epoch:21 step:20221 [D loss: 0.243102, acc.: 58.59%] [G loss: 0.300647]\n",
      "epoch:21 step:20222 [D loss: 0.246935, acc.: 56.25%] [G loss: 0.304950]\n",
      "epoch:21 step:20223 [D loss: 0.239439, acc.: 57.81%] [G loss: 0.276882]\n",
      "epoch:21 step:20224 [D loss: 0.245291, acc.: 53.91%] [G loss: 0.314053]\n",
      "epoch:21 step:20225 [D loss: 0.249953, acc.: 53.12%] [G loss: 0.310995]\n",
      "epoch:21 step:20226 [D loss: 0.246505, acc.: 55.47%] [G loss: 0.323486]\n",
      "epoch:21 step:20227 [D loss: 0.229564, acc.: 59.38%] [G loss: 0.282545]\n",
      "epoch:21 step:20228 [D loss: 0.235471, acc.: 57.81%] [G loss: 0.281017]\n",
      "epoch:21 step:20229 [D loss: 0.252091, acc.: 51.56%] [G loss: 0.304017]\n",
      "epoch:21 step:20230 [D loss: 0.240950, acc.: 57.81%] [G loss: 0.291351]\n",
      "epoch:21 step:20231 [D loss: 0.238539, acc.: 60.94%] [G loss: 0.301100]\n",
      "epoch:21 step:20232 [D loss: 0.229604, acc.: 62.50%] [G loss: 0.297169]\n",
      "epoch:21 step:20233 [D loss: 0.228499, acc.: 62.50%] [G loss: 0.307712]\n",
      "epoch:21 step:20234 [D loss: 0.245225, acc.: 55.47%] [G loss: 0.305331]\n",
      "epoch:21 step:20235 [D loss: 0.243779, acc.: 59.38%] [G loss: 0.283248]\n",
      "epoch:21 step:20236 [D loss: 0.248275, acc.: 53.12%] [G loss: 0.290479]\n",
      "epoch:21 step:20237 [D loss: 0.244642, acc.: 57.81%] [G loss: 0.265924]\n",
      "epoch:21 step:20238 [D loss: 0.234659, acc.: 57.81%] [G loss: 0.295185]\n",
      "epoch:21 step:20239 [D loss: 0.220775, acc.: 65.62%] [G loss: 0.302069]\n",
      "epoch:21 step:20240 [D loss: 0.246760, acc.: 56.25%] [G loss: 0.300345]\n",
      "epoch:21 step:20241 [D loss: 0.224424, acc.: 64.06%] [G loss: 0.281269]\n",
      "epoch:21 step:20242 [D loss: 0.251902, acc.: 54.69%] [G loss: 0.280038]\n",
      "epoch:21 step:20243 [D loss: 0.237428, acc.: 59.38%] [G loss: 0.287500]\n",
      "epoch:21 step:20244 [D loss: 0.235182, acc.: 62.50%] [G loss: 0.323463]\n",
      "epoch:21 step:20245 [D loss: 0.241741, acc.: 57.03%] [G loss: 0.302967]\n",
      "epoch:21 step:20246 [D loss: 0.228446, acc.: 61.72%] [G loss: 0.301061]\n",
      "epoch:21 step:20247 [D loss: 0.252193, acc.: 54.69%] [G loss: 0.306451]\n",
      "epoch:21 step:20248 [D loss: 0.236240, acc.: 60.16%] [G loss: 0.317238]\n",
      "epoch:21 step:20249 [D loss: 0.215331, acc.: 64.06%] [G loss: 0.309120]\n",
      "epoch:21 step:20250 [D loss: 0.255518, acc.: 52.34%] [G loss: 0.311257]\n",
      "epoch:21 step:20251 [D loss: 0.248675, acc.: 52.34%] [G loss: 0.282872]\n",
      "epoch:21 step:20252 [D loss: 0.224858, acc.: 66.41%] [G loss: 0.324453]\n",
      "epoch:21 step:20253 [D loss: 0.239933, acc.: 53.91%] [G loss: 0.295071]\n",
      "epoch:21 step:20254 [D loss: 0.236808, acc.: 59.38%] [G loss: 0.298753]\n",
      "epoch:21 step:20255 [D loss: 0.225006, acc.: 66.41%] [G loss: 0.295865]\n",
      "epoch:21 step:20256 [D loss: 0.244614, acc.: 60.16%] [G loss: 0.289871]\n",
      "epoch:21 step:20257 [D loss: 0.232307, acc.: 61.72%] [G loss: 0.296557]\n",
      "epoch:21 step:20258 [D loss: 0.243679, acc.: 63.28%] [G loss: 0.293675]\n",
      "epoch:21 step:20259 [D loss: 0.241149, acc.: 54.69%] [G loss: 0.313260]\n",
      "epoch:21 step:20260 [D loss: 0.241269, acc.: 54.69%] [G loss: 0.294401]\n",
      "epoch:21 step:20261 [D loss: 0.229875, acc.: 62.50%] [G loss: 0.293499]\n",
      "epoch:21 step:20262 [D loss: 0.251341, acc.: 50.00%] [G loss: 0.283221]\n",
      "epoch:21 step:20263 [D loss: 0.223874, acc.: 62.50%] [G loss: 0.317075]\n",
      "epoch:21 step:20264 [D loss: 0.226298, acc.: 56.25%] [G loss: 0.279040]\n",
      "epoch:21 step:20265 [D loss: 0.261625, acc.: 47.66%] [G loss: 0.292847]\n",
      "epoch:21 step:20266 [D loss: 0.237658, acc.: 63.28%] [G loss: 0.309453]\n",
      "epoch:21 step:20267 [D loss: 0.232284, acc.: 61.72%] [G loss: 0.299976]\n",
      "epoch:21 step:20268 [D loss: 0.220891, acc.: 66.41%] [G loss: 0.297250]\n",
      "epoch:21 step:20269 [D loss: 0.231702, acc.: 57.81%] [G loss: 0.282718]\n",
      "epoch:21 step:20270 [D loss: 0.260989, acc.: 50.00%] [G loss: 0.311949]\n",
      "epoch:21 step:20271 [D loss: 0.242819, acc.: 55.47%] [G loss: 0.292996]\n",
      "epoch:21 step:20272 [D loss: 0.237879, acc.: 60.94%] [G loss: 0.317696]\n",
      "epoch:21 step:20273 [D loss: 0.215973, acc.: 67.97%] [G loss: 0.319741]\n",
      "epoch:21 step:20274 [D loss: 0.239367, acc.: 57.03%] [G loss: 0.282535]\n",
      "epoch:21 step:20275 [D loss: 0.229809, acc.: 60.16%] [G loss: 0.334511]\n",
      "epoch:21 step:20276 [D loss: 0.239555, acc.: 55.47%] [G loss: 0.317340]\n",
      "epoch:21 step:20277 [D loss: 0.227470, acc.: 62.50%] [G loss: 0.311425]\n",
      "epoch:21 step:20278 [D loss: 0.261009, acc.: 54.69%] [G loss: 0.298386]\n",
      "epoch:21 step:20279 [D loss: 0.231934, acc.: 62.50%] [G loss: 0.317734]\n",
      "epoch:21 step:20280 [D loss: 0.257099, acc.: 53.12%] [G loss: 0.337366]\n",
      "epoch:21 step:20281 [D loss: 0.246863, acc.: 54.69%] [G loss: 0.308781]\n",
      "epoch:21 step:20282 [D loss: 0.234642, acc.: 59.38%] [G loss: 0.305291]\n",
      "epoch:21 step:20283 [D loss: 0.233063, acc.: 60.16%] [G loss: 0.332281]\n",
      "epoch:21 step:20284 [D loss: 0.236929, acc.: 53.91%] [G loss: 0.330262]\n",
      "epoch:21 step:20285 [D loss: 0.237771, acc.: 59.38%] [G loss: 0.331710]\n",
      "epoch:21 step:20286 [D loss: 0.230205, acc.: 62.50%] [G loss: 0.288658]\n",
      "epoch:21 step:20287 [D loss: 0.244724, acc.: 57.81%] [G loss: 0.306221]\n",
      "epoch:21 step:20288 [D loss: 0.220302, acc.: 71.09%] [G loss: 0.295722]\n",
      "epoch:21 step:20289 [D loss: 0.220840, acc.: 64.84%] [G loss: 0.291477]\n",
      "epoch:21 step:20290 [D loss: 0.258560, acc.: 53.91%] [G loss: 0.296638]\n",
      "epoch:21 step:20291 [D loss: 0.245201, acc.: 56.25%] [G loss: 0.311062]\n",
      "epoch:21 step:20292 [D loss: 0.230635, acc.: 62.50%] [G loss: 0.341968]\n",
      "epoch:21 step:20293 [D loss: 0.215538, acc.: 67.19%] [G loss: 0.309478]\n",
      "epoch:21 step:20294 [D loss: 0.241529, acc.: 58.59%] [G loss: 0.280824]\n",
      "epoch:21 step:20295 [D loss: 0.241656, acc.: 53.12%] [G loss: 0.303521]\n",
      "epoch:21 step:20296 [D loss: 0.245530, acc.: 59.38%] [G loss: 0.299333]\n",
      "epoch:21 step:20297 [D loss: 0.239732, acc.: 60.16%] [G loss: 0.310631]\n",
      "epoch:21 step:20298 [D loss: 0.249757, acc.: 52.34%] [G loss: 0.285740]\n",
      "epoch:21 step:20299 [D loss: 0.260014, acc.: 50.00%] [G loss: 0.285362]\n",
      "epoch:21 step:20300 [D loss: 0.248659, acc.: 56.25%] [G loss: 0.289542]\n",
      "epoch:21 step:20301 [D loss: 0.234880, acc.: 53.91%] [G loss: 0.309350]\n",
      "epoch:21 step:20302 [D loss: 0.229660, acc.: 60.94%] [G loss: 0.312157]\n",
      "epoch:21 step:20303 [D loss: 0.233009, acc.: 56.25%] [G loss: 0.296097]\n",
      "epoch:21 step:20304 [D loss: 0.221295, acc.: 64.84%] [G loss: 0.278435]\n",
      "epoch:21 step:20305 [D loss: 0.244152, acc.: 60.94%] [G loss: 0.304736]\n",
      "epoch:21 step:20306 [D loss: 0.246408, acc.: 56.25%] [G loss: 0.308414]\n",
      "epoch:21 step:20307 [D loss: 0.248916, acc.: 54.69%] [G loss: 0.280636]\n",
      "epoch:21 step:20308 [D loss: 0.232941, acc.: 59.38%] [G loss: 0.298415]\n",
      "epoch:21 step:20309 [D loss: 0.234373, acc.: 57.03%] [G loss: 0.273340]\n",
      "epoch:21 step:20310 [D loss: 0.247593, acc.: 57.03%] [G loss: 0.304701]\n",
      "epoch:21 step:20311 [D loss: 0.232867, acc.: 60.94%] [G loss: 0.332901]\n",
      "epoch:21 step:20312 [D loss: 0.238299, acc.: 60.16%] [G loss: 0.307209]\n",
      "epoch:21 step:20313 [D loss: 0.248801, acc.: 56.25%] [G loss: 0.306755]\n",
      "epoch:21 step:20314 [D loss: 0.222770, acc.: 64.84%] [G loss: 0.337131]\n",
      "epoch:21 step:20315 [D loss: 0.250119, acc.: 53.91%] [G loss: 0.321827]\n",
      "epoch:21 step:20316 [D loss: 0.238769, acc.: 56.25%] [G loss: 0.305816]\n",
      "epoch:21 step:20317 [D loss: 0.236445, acc.: 61.72%] [G loss: 0.296018]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:21 step:20318 [D loss: 0.239975, acc.: 55.47%] [G loss: 0.313008]\n",
      "epoch:21 step:20319 [D loss: 0.240961, acc.: 57.03%] [G loss: 0.282207]\n",
      "epoch:21 step:20320 [D loss: 0.246882, acc.: 54.69%] [G loss: 0.309268]\n",
      "epoch:21 step:20321 [D loss: 0.231785, acc.: 62.50%] [G loss: 0.316493]\n",
      "epoch:21 step:20322 [D loss: 0.224513, acc.: 64.84%] [G loss: 0.339364]\n",
      "epoch:21 step:20323 [D loss: 0.226085, acc.: 62.50%] [G loss: 0.308782]\n",
      "epoch:21 step:20324 [D loss: 0.216199, acc.: 64.06%] [G loss: 0.331927]\n",
      "epoch:21 step:20325 [D loss: 0.243970, acc.: 57.81%] [G loss: 0.321957]\n",
      "epoch:21 step:20326 [D loss: 0.243459, acc.: 54.69%] [G loss: 0.313745]\n",
      "epoch:21 step:20327 [D loss: 0.255874, acc.: 52.34%] [G loss: 0.309581]\n",
      "epoch:21 step:20328 [D loss: 0.261364, acc.: 48.44%] [G loss: 0.313435]\n",
      "epoch:21 step:20329 [D loss: 0.226791, acc.: 64.84%] [G loss: 0.314639]\n",
      "epoch:21 step:20330 [D loss: 0.232540, acc.: 53.91%] [G loss: 0.287112]\n",
      "epoch:21 step:20331 [D loss: 0.243156, acc.: 54.69%] [G loss: 0.306732]\n",
      "epoch:21 step:20332 [D loss: 0.253620, acc.: 53.12%] [G loss: 0.298177]\n",
      "epoch:21 step:20333 [D loss: 0.225804, acc.: 66.41%] [G loss: 0.304310]\n",
      "epoch:21 step:20334 [D loss: 0.243194, acc.: 58.59%] [G loss: 0.287648]\n",
      "epoch:21 step:20335 [D loss: 0.252003, acc.: 52.34%] [G loss: 0.273336]\n",
      "epoch:21 step:20336 [D loss: 0.240460, acc.: 59.38%] [G loss: 0.279858]\n",
      "epoch:21 step:20337 [D loss: 0.241939, acc.: 53.12%] [G loss: 0.341620]\n",
      "epoch:21 step:20338 [D loss: 0.243661, acc.: 59.38%] [G loss: 0.309908]\n",
      "epoch:21 step:20339 [D loss: 0.231146, acc.: 60.94%] [G loss: 0.307863]\n",
      "epoch:21 step:20340 [D loss: 0.226073, acc.: 62.50%] [G loss: 0.296092]\n",
      "epoch:21 step:20341 [D loss: 0.221385, acc.: 64.84%] [G loss: 0.314534]\n",
      "epoch:21 step:20342 [D loss: 0.248163, acc.: 54.69%] [G loss: 0.291489]\n",
      "epoch:21 step:20343 [D loss: 0.236865, acc.: 56.25%] [G loss: 0.296820]\n",
      "epoch:21 step:20344 [D loss: 0.241792, acc.: 61.72%] [G loss: 0.324398]\n",
      "epoch:21 step:20345 [D loss: 0.234274, acc.: 58.59%] [G loss: 0.292840]\n",
      "epoch:21 step:20346 [D loss: 0.232116, acc.: 58.59%] [G loss: 0.307320]\n",
      "epoch:21 step:20347 [D loss: 0.236842, acc.: 60.94%] [G loss: 0.305048]\n",
      "epoch:21 step:20348 [D loss: 0.239314, acc.: 63.28%] [G loss: 0.321430]\n",
      "epoch:21 step:20349 [D loss: 0.244682, acc.: 57.81%] [G loss: 0.277330]\n",
      "epoch:21 step:20350 [D loss: 0.244219, acc.: 53.12%] [G loss: 0.303314]\n",
      "epoch:21 step:20351 [D loss: 0.243925, acc.: 58.59%] [G loss: 0.310508]\n",
      "epoch:21 step:20352 [D loss: 0.246521, acc.: 53.91%] [G loss: 0.334347]\n",
      "epoch:21 step:20353 [D loss: 0.224884, acc.: 62.50%] [G loss: 0.321831]\n",
      "epoch:21 step:20354 [D loss: 0.236033, acc.: 57.81%] [G loss: 0.306402]\n",
      "epoch:21 step:20355 [D loss: 0.250285, acc.: 54.69%] [G loss: 0.330443]\n",
      "epoch:21 step:20356 [D loss: 0.259892, acc.: 53.91%] [G loss: 0.287013]\n",
      "epoch:21 step:20357 [D loss: 0.217005, acc.: 61.72%] [G loss: 0.322127]\n",
      "epoch:21 step:20358 [D loss: 0.239840, acc.: 56.25%] [G loss: 0.313104]\n",
      "epoch:21 step:20359 [D loss: 0.237514, acc.: 60.94%] [G loss: 0.315863]\n",
      "epoch:21 step:20360 [D loss: 0.265474, acc.: 46.88%] [G loss: 0.290131]\n",
      "epoch:21 step:20361 [D loss: 0.247918, acc.: 54.69%] [G loss: 0.316164]\n",
      "epoch:21 step:20362 [D loss: 0.259487, acc.: 50.00%] [G loss: 0.336282]\n",
      "epoch:21 step:20363 [D loss: 0.230158, acc.: 61.72%] [G loss: 0.278892]\n",
      "epoch:21 step:20364 [D loss: 0.228151, acc.: 64.06%] [G loss: 0.290110]\n",
      "epoch:21 step:20365 [D loss: 0.242013, acc.: 55.47%] [G loss: 0.290454]\n",
      "epoch:21 step:20366 [D loss: 0.237461, acc.: 62.50%] [G loss: 0.311422]\n",
      "epoch:21 step:20367 [D loss: 0.242534, acc.: 57.03%] [G loss: 0.298290]\n",
      "epoch:21 step:20368 [D loss: 0.249716, acc.: 54.69%] [G loss: 0.277781]\n",
      "epoch:21 step:20369 [D loss: 0.231165, acc.: 64.06%] [G loss: 0.304974]\n",
      "epoch:21 step:20370 [D loss: 0.239340, acc.: 57.03%] [G loss: 0.305426]\n",
      "epoch:21 step:20371 [D loss: 0.236628, acc.: 58.59%] [G loss: 0.307463]\n",
      "epoch:21 step:20372 [D loss: 0.217344, acc.: 64.06%] [G loss: 0.298970]\n",
      "epoch:21 step:20373 [D loss: 0.246895, acc.: 55.47%] [G loss: 0.302251]\n",
      "epoch:21 step:20374 [D loss: 0.237972, acc.: 61.72%] [G loss: 0.290958]\n",
      "epoch:21 step:20375 [D loss: 0.245925, acc.: 52.34%] [G loss: 0.329452]\n",
      "epoch:21 step:20376 [D loss: 0.249101, acc.: 52.34%] [G loss: 0.297436]\n",
      "epoch:21 step:20377 [D loss: 0.238109, acc.: 58.59%] [G loss: 0.314615]\n",
      "epoch:21 step:20378 [D loss: 0.241537, acc.: 54.69%] [G loss: 0.302852]\n",
      "epoch:21 step:20379 [D loss: 0.236957, acc.: 56.25%] [G loss: 0.282806]\n",
      "epoch:21 step:20380 [D loss: 0.236152, acc.: 53.91%] [G loss: 0.329372]\n",
      "epoch:21 step:20381 [D loss: 0.236600, acc.: 60.16%] [G loss: 0.301371]\n",
      "epoch:21 step:20382 [D loss: 0.232640, acc.: 55.47%] [G loss: 0.309422]\n",
      "epoch:21 step:20383 [D loss: 0.224249, acc.: 60.16%] [G loss: 0.303594]\n",
      "epoch:21 step:20384 [D loss: 0.231999, acc.: 62.50%] [G loss: 0.333695]\n",
      "epoch:21 step:20385 [D loss: 0.231469, acc.: 60.94%] [G loss: 0.310789]\n",
      "epoch:21 step:20386 [D loss: 0.263056, acc.: 52.34%] [G loss: 0.292858]\n",
      "epoch:21 step:20387 [D loss: 0.244720, acc.: 56.25%] [G loss: 0.304206]\n",
      "epoch:21 step:20388 [D loss: 0.230546, acc.: 59.38%] [G loss: 0.319902]\n",
      "epoch:21 step:20389 [D loss: 0.226192, acc.: 64.06%] [G loss: 0.327074]\n",
      "epoch:21 step:20390 [D loss: 0.249233, acc.: 53.12%] [G loss: 0.310617]\n",
      "epoch:21 step:20391 [D loss: 0.239511, acc.: 57.81%] [G loss: 0.304532]\n",
      "epoch:21 step:20392 [D loss: 0.235034, acc.: 62.50%] [G loss: 0.318428]\n",
      "epoch:21 step:20393 [D loss: 0.224029, acc.: 64.06%] [G loss: 0.312387]\n",
      "epoch:21 step:20394 [D loss: 0.224180, acc.: 59.38%] [G loss: 0.290046]\n",
      "epoch:21 step:20395 [D loss: 0.229231, acc.: 58.59%] [G loss: 0.302179]\n",
      "epoch:21 step:20396 [D loss: 0.255960, acc.: 51.56%] [G loss: 0.289296]\n",
      "epoch:21 step:20397 [D loss: 0.245658, acc.: 57.81%] [G loss: 0.285030]\n",
      "epoch:21 step:20398 [D loss: 0.228562, acc.: 60.94%] [G loss: 0.335235]\n",
      "epoch:21 step:20399 [D loss: 0.233646, acc.: 62.50%] [G loss: 0.317373]\n",
      "epoch:21 step:20400 [D loss: 0.225998, acc.: 60.94%] [G loss: 0.310124]\n",
      "epoch:21 step:20401 [D loss: 0.232876, acc.: 61.72%] [G loss: 0.298174]\n",
      "epoch:21 step:20402 [D loss: 0.222690, acc.: 65.62%] [G loss: 0.318323]\n",
      "epoch:21 step:20403 [D loss: 0.230003, acc.: 58.59%] [G loss: 0.312137]\n",
      "epoch:21 step:20404 [D loss: 0.222222, acc.: 62.50%] [G loss: 0.290944]\n",
      "epoch:21 step:20405 [D loss: 0.226830, acc.: 62.50%] [G loss: 0.316231]\n",
      "epoch:21 step:20406 [D loss: 0.257648, acc.: 48.44%] [G loss: 0.304606]\n",
      "epoch:21 step:20407 [D loss: 0.234677, acc.: 60.16%] [G loss: 0.289869]\n",
      "epoch:21 step:20408 [D loss: 0.217634, acc.: 64.84%] [G loss: 0.324933]\n",
      "epoch:21 step:20409 [D loss: 0.231840, acc.: 58.59%] [G loss: 0.297790]\n",
      "epoch:21 step:20410 [D loss: 0.227314, acc.: 64.06%] [G loss: 0.306027]\n",
      "epoch:21 step:20411 [D loss: 0.223186, acc.: 62.50%] [G loss: 0.302735]\n",
      "epoch:21 step:20412 [D loss: 0.230709, acc.: 63.28%] [G loss: 0.290862]\n",
      "epoch:21 step:20413 [D loss: 0.227117, acc.: 63.28%] [G loss: 0.337971]\n",
      "epoch:21 step:20414 [D loss: 0.240075, acc.: 57.03%] [G loss: 0.281510]\n",
      "epoch:21 step:20415 [D loss: 0.253769, acc.: 58.59%] [G loss: 0.327936]\n",
      "epoch:21 step:20416 [D loss: 0.236993, acc.: 57.81%] [G loss: 0.318607]\n",
      "epoch:21 step:20417 [D loss: 0.249543, acc.: 57.81%] [G loss: 0.297013]\n",
      "epoch:21 step:20418 [D loss: 0.243455, acc.: 58.59%] [G loss: 0.316372]\n",
      "epoch:21 step:20419 [D loss: 0.229352, acc.: 62.50%] [G loss: 0.300053]\n",
      "epoch:21 step:20420 [D loss: 0.244507, acc.: 55.47%] [G loss: 0.307996]\n",
      "epoch:21 step:20421 [D loss: 0.238307, acc.: 59.38%] [G loss: 0.302623]\n",
      "epoch:21 step:20422 [D loss: 0.255438, acc.: 52.34%] [G loss: 0.311147]\n",
      "epoch:21 step:20423 [D loss: 0.234990, acc.: 61.72%] [G loss: 0.312561]\n",
      "epoch:21 step:20424 [D loss: 0.232333, acc.: 62.50%] [G loss: 0.285634]\n",
      "epoch:21 step:20425 [D loss: 0.219251, acc.: 65.62%] [G loss: 0.277312]\n",
      "epoch:21 step:20426 [D loss: 0.232928, acc.: 64.06%] [G loss: 0.298743]\n",
      "epoch:21 step:20427 [D loss: 0.258870, acc.: 52.34%] [G loss: 0.282694]\n",
      "epoch:21 step:20428 [D loss: 0.228537, acc.: 59.38%] [G loss: 0.279942]\n",
      "epoch:21 step:20429 [D loss: 0.227224, acc.: 59.38%] [G loss: 0.298015]\n",
      "epoch:21 step:20430 [D loss: 0.241365, acc.: 60.16%] [G loss: 0.324766]\n",
      "epoch:21 step:20431 [D loss: 0.223391, acc.: 61.72%] [G loss: 0.293975]\n",
      "epoch:21 step:20432 [D loss: 0.229534, acc.: 57.03%] [G loss: 0.300048]\n",
      "epoch:21 step:20433 [D loss: 0.246663, acc.: 59.38%] [G loss: 0.279262]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:21 step:20434 [D loss: 0.241892, acc.: 57.81%] [G loss: 0.295028]\n",
      "epoch:21 step:20435 [D loss: 0.246049, acc.: 50.78%] [G loss: 0.328457]\n",
      "epoch:21 step:20436 [D loss: 0.244155, acc.: 56.25%] [G loss: 0.300968]\n",
      "epoch:21 step:20437 [D loss: 0.222123, acc.: 64.84%] [G loss: 0.292085]\n",
      "epoch:21 step:20438 [D loss: 0.251684, acc.: 55.47%] [G loss: 0.263343]\n",
      "epoch:21 step:20439 [D loss: 0.252954, acc.: 50.78%] [G loss: 0.287110]\n",
      "epoch:21 step:20440 [D loss: 0.238647, acc.: 60.16%] [G loss: 0.275873]\n",
      "epoch:21 step:20441 [D loss: 0.235637, acc.: 59.38%] [G loss: 0.310441]\n",
      "epoch:21 step:20442 [D loss: 0.238973, acc.: 60.94%] [G loss: 0.300956]\n",
      "epoch:21 step:20443 [D loss: 0.227603, acc.: 60.94%] [G loss: 0.285849]\n",
      "epoch:21 step:20444 [D loss: 0.236155, acc.: 55.47%] [G loss: 0.334027]\n",
      "epoch:21 step:20445 [D loss: 0.250363, acc.: 52.34%] [G loss: 0.326958]\n",
      "epoch:21 step:20446 [D loss: 0.239376, acc.: 57.81%] [G loss: 0.305128]\n",
      "epoch:21 step:20447 [D loss: 0.231361, acc.: 59.38%] [G loss: 0.285733]\n",
      "epoch:21 step:20448 [D loss: 0.245868, acc.: 54.69%] [G loss: 0.289354]\n",
      "epoch:21 step:20449 [D loss: 0.229616, acc.: 65.62%] [G loss: 0.303789]\n",
      "epoch:21 step:20450 [D loss: 0.250117, acc.: 58.59%] [G loss: 0.307707]\n",
      "epoch:21 step:20451 [D loss: 0.226754, acc.: 61.72%] [G loss: 0.288886]\n",
      "epoch:21 step:20452 [D loss: 0.225686, acc.: 62.50%] [G loss: 0.319603]\n",
      "epoch:21 step:20453 [D loss: 0.235763, acc.: 60.16%] [G loss: 0.306981]\n",
      "epoch:21 step:20454 [D loss: 0.230435, acc.: 64.84%] [G loss: 0.305144]\n",
      "epoch:21 step:20455 [D loss: 0.233718, acc.: 66.41%] [G loss: 0.305336]\n",
      "epoch:21 step:20456 [D loss: 0.231568, acc.: 64.06%] [G loss: 0.289659]\n",
      "epoch:21 step:20457 [D loss: 0.231588, acc.: 64.06%] [G loss: 0.295680]\n",
      "epoch:21 step:20458 [D loss: 0.240554, acc.: 57.81%] [G loss: 0.296297]\n",
      "epoch:21 step:20459 [D loss: 0.231283, acc.: 63.28%] [G loss: 0.318047]\n",
      "epoch:21 step:20460 [D loss: 0.264378, acc.: 46.88%] [G loss: 0.310039]\n",
      "epoch:21 step:20461 [D loss: 0.235802, acc.: 63.28%] [G loss: 0.304427]\n",
      "epoch:21 step:20462 [D loss: 0.236623, acc.: 53.91%] [G loss: 0.320057]\n",
      "epoch:21 step:20463 [D loss: 0.258524, acc.: 50.00%] [G loss: 0.266887]\n",
      "epoch:21 step:20464 [D loss: 0.246459, acc.: 54.69%] [G loss: 0.301548]\n",
      "epoch:21 step:20465 [D loss: 0.235102, acc.: 56.25%] [G loss: 0.317109]\n",
      "epoch:21 step:20466 [D loss: 0.235310, acc.: 55.47%] [G loss: 0.295634]\n",
      "epoch:21 step:20467 [D loss: 0.230026, acc.: 61.72%] [G loss: 0.318469]\n",
      "epoch:21 step:20468 [D loss: 0.234713, acc.: 60.94%] [G loss: 0.298839]\n",
      "epoch:21 step:20469 [D loss: 0.232565, acc.: 57.81%] [G loss: 0.289624]\n",
      "epoch:21 step:20470 [D loss: 0.239380, acc.: 60.94%] [G loss: 0.294022]\n",
      "epoch:21 step:20471 [D loss: 0.256938, acc.: 54.69%] [G loss: 0.305790]\n",
      "epoch:21 step:20472 [D loss: 0.220305, acc.: 64.06%] [G loss: 0.300069]\n",
      "epoch:21 step:20473 [D loss: 0.242385, acc.: 55.47%] [G loss: 0.310668]\n",
      "epoch:21 step:20474 [D loss: 0.242913, acc.: 53.91%] [G loss: 0.325296]\n",
      "epoch:21 step:20475 [D loss: 0.235125, acc.: 60.16%] [G loss: 0.294130]\n",
      "epoch:21 step:20476 [D loss: 0.225760, acc.: 65.62%] [G loss: 0.327837]\n",
      "epoch:21 step:20477 [D loss: 0.255458, acc.: 53.12%] [G loss: 0.298309]\n",
      "epoch:21 step:20478 [D loss: 0.227558, acc.: 62.50%] [G loss: 0.289963]\n",
      "epoch:21 step:20479 [D loss: 0.236817, acc.: 62.50%] [G loss: 0.277375]\n",
      "epoch:21 step:20480 [D loss: 0.245005, acc.: 53.91%] [G loss: 0.294815]\n",
      "epoch:21 step:20481 [D loss: 0.239520, acc.: 54.69%] [G loss: 0.299368]\n",
      "epoch:21 step:20482 [D loss: 0.235819, acc.: 56.25%] [G loss: 0.308008]\n",
      "epoch:21 step:20483 [D loss: 0.241570, acc.: 55.47%] [G loss: 0.324704]\n",
      "epoch:21 step:20484 [D loss: 0.242836, acc.: 56.25%] [G loss: 0.310616]\n",
      "epoch:21 step:20485 [D loss: 0.223369, acc.: 65.62%] [G loss: 0.303265]\n",
      "epoch:21 step:20486 [D loss: 0.236524, acc.: 62.50%] [G loss: 0.319613]\n",
      "epoch:21 step:20487 [D loss: 0.234642, acc.: 60.16%] [G loss: 0.276928]\n",
      "epoch:21 step:20488 [D loss: 0.230321, acc.: 63.28%] [G loss: 0.287988]\n",
      "epoch:21 step:20489 [D loss: 0.239687, acc.: 59.38%] [G loss: 0.302085]\n",
      "epoch:21 step:20490 [D loss: 0.233464, acc.: 60.16%] [G loss: 0.276413]\n",
      "epoch:21 step:20491 [D loss: 0.237548, acc.: 57.81%] [G loss: 0.300252]\n",
      "epoch:21 step:20492 [D loss: 0.235794, acc.: 63.28%] [G loss: 0.270560]\n",
      "epoch:21 step:20493 [D loss: 0.211722, acc.: 69.53%] [G loss: 0.315738]\n",
      "epoch:21 step:20494 [D loss: 0.220556, acc.: 67.97%] [G loss: 0.278505]\n",
      "epoch:21 step:20495 [D loss: 0.241443, acc.: 55.47%] [G loss: 0.297216]\n",
      "epoch:21 step:20496 [D loss: 0.231990, acc.: 59.38%] [G loss: 0.319684]\n",
      "epoch:21 step:20497 [D loss: 0.233483, acc.: 66.41%] [G loss: 0.308498]\n",
      "epoch:21 step:20498 [D loss: 0.247320, acc.: 54.69%] [G loss: 0.293582]\n",
      "epoch:21 step:20499 [D loss: 0.258363, acc.: 50.78%] [G loss: 0.266954]\n",
      "epoch:21 step:20500 [D loss: 0.249489, acc.: 50.78%] [G loss: 0.301175]\n",
      "epoch:21 step:20501 [D loss: 0.244421, acc.: 54.69%] [G loss: 0.275261]\n",
      "epoch:21 step:20502 [D loss: 0.249609, acc.: 57.81%] [G loss: 0.304280]\n",
      "epoch:21 step:20503 [D loss: 0.245354, acc.: 58.59%] [G loss: 0.321268]\n",
      "epoch:21 step:20504 [D loss: 0.250590, acc.: 56.25%] [G loss: 0.334617]\n",
      "epoch:21 step:20505 [D loss: 0.251040, acc.: 58.59%] [G loss: 0.289183]\n",
      "epoch:21 step:20506 [D loss: 0.246795, acc.: 54.69%] [G loss: 0.324508]\n",
      "epoch:21 step:20507 [D loss: 0.247746, acc.: 57.81%] [G loss: 0.301483]\n",
      "epoch:21 step:20508 [D loss: 0.253136, acc.: 58.59%] [G loss: 0.311837]\n",
      "epoch:21 step:20509 [D loss: 0.236627, acc.: 60.94%] [G loss: 0.295313]\n",
      "epoch:21 step:20510 [D loss: 0.222347, acc.: 63.28%] [G loss: 0.289013]\n",
      "epoch:21 step:20511 [D loss: 0.260663, acc.: 47.66%] [G loss: 0.296031]\n",
      "epoch:21 step:20512 [D loss: 0.241820, acc.: 59.38%] [G loss: 0.319067]\n",
      "epoch:21 step:20513 [D loss: 0.259088, acc.: 49.22%] [G loss: 0.278424]\n",
      "epoch:21 step:20514 [D loss: 0.240741, acc.: 56.25%] [G loss: 0.286764]\n",
      "epoch:21 step:20515 [D loss: 0.240826, acc.: 56.25%] [G loss: 0.328435]\n",
      "epoch:21 step:20516 [D loss: 0.240149, acc.: 59.38%] [G loss: 0.323164]\n",
      "epoch:21 step:20517 [D loss: 0.239086, acc.: 58.59%] [G loss: 0.300744]\n",
      "epoch:21 step:20518 [D loss: 0.232634, acc.: 59.38%] [G loss: 0.314908]\n",
      "epoch:21 step:20519 [D loss: 0.255486, acc.: 46.09%] [G loss: 0.265199]\n",
      "epoch:21 step:20520 [D loss: 0.255728, acc.: 53.91%] [G loss: 0.307136]\n",
      "epoch:21 step:20521 [D loss: 0.261230, acc.: 47.66%] [G loss: 0.313680]\n",
      "epoch:21 step:20522 [D loss: 0.237159, acc.: 55.47%] [G loss: 0.317175]\n",
      "epoch:21 step:20523 [D loss: 0.241856, acc.: 55.47%] [G loss: 0.318126]\n",
      "epoch:21 step:20524 [D loss: 0.243993, acc.: 60.16%] [G loss: 0.293060]\n",
      "epoch:21 step:20525 [D loss: 0.229245, acc.: 61.72%] [G loss: 0.287845]\n",
      "epoch:21 step:20526 [D loss: 0.253091, acc.: 52.34%] [G loss: 0.323885]\n",
      "epoch:21 step:20527 [D loss: 0.235178, acc.: 62.50%] [G loss: 0.283364]\n",
      "epoch:21 step:20528 [D loss: 0.245974, acc.: 57.03%] [G loss: 0.308860]\n",
      "epoch:21 step:20529 [D loss: 0.254233, acc.: 51.56%] [G loss: 0.295820]\n",
      "epoch:21 step:20530 [D loss: 0.237867, acc.: 61.72%] [G loss: 0.332990]\n",
      "epoch:21 step:20531 [D loss: 0.240664, acc.: 55.47%] [G loss: 0.325591]\n",
      "epoch:21 step:20532 [D loss: 0.255384, acc.: 55.47%] [G loss: 0.306452]\n",
      "epoch:21 step:20533 [D loss: 0.235668, acc.: 60.16%] [G loss: 0.292366]\n",
      "epoch:21 step:20534 [D loss: 0.242785, acc.: 62.50%] [G loss: 0.326641]\n",
      "epoch:21 step:20535 [D loss: 0.238159, acc.: 57.81%] [G loss: 0.333048]\n",
      "epoch:21 step:20536 [D loss: 0.230616, acc.: 63.28%] [G loss: 0.308952]\n",
      "epoch:21 step:20537 [D loss: 0.253490, acc.: 60.16%] [G loss: 0.284153]\n",
      "epoch:21 step:20538 [D loss: 0.232353, acc.: 58.59%] [G loss: 0.308463]\n",
      "epoch:21 step:20539 [D loss: 0.253931, acc.: 53.91%] [G loss: 0.302715]\n",
      "epoch:21 step:20540 [D loss: 0.235013, acc.: 60.94%] [G loss: 0.303024]\n",
      "epoch:21 step:20541 [D loss: 0.236822, acc.: 56.25%] [G loss: 0.294234]\n",
      "epoch:21 step:20542 [D loss: 0.230409, acc.: 59.38%] [G loss: 0.311990]\n",
      "epoch:21 step:20543 [D loss: 0.239118, acc.: 57.81%] [G loss: 0.299427]\n",
      "epoch:21 step:20544 [D loss: 0.261312, acc.: 50.78%] [G loss: 0.313049]\n",
      "epoch:21 step:20545 [D loss: 0.232482, acc.: 63.28%] [G loss: 0.312424]\n",
      "epoch:21 step:20546 [D loss: 0.229996, acc.: 61.72%] [G loss: 0.293550]\n",
      "epoch:21 step:20547 [D loss: 0.239269, acc.: 60.94%] [G loss: 0.305636]\n",
      "epoch:21 step:20548 [D loss: 0.243195, acc.: 58.59%] [G loss: 0.309386]\n",
      "epoch:21 step:20549 [D loss: 0.249842, acc.: 49.22%] [G loss: 0.303325]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:21 step:20550 [D loss: 0.212206, acc.: 67.97%] [G loss: 0.295578]\n",
      "epoch:21 step:20551 [D loss: 0.238273, acc.: 56.25%] [G loss: 0.296694]\n",
      "epoch:21 step:20552 [D loss: 0.219012, acc.: 66.41%] [G loss: 0.316916]\n",
      "epoch:21 step:20553 [D loss: 0.234172, acc.: 60.94%] [G loss: 0.313606]\n",
      "epoch:21 step:20554 [D loss: 0.258757, acc.: 54.69%] [G loss: 0.306986]\n",
      "epoch:21 step:20555 [D loss: 0.239237, acc.: 59.38%] [G loss: 0.337051]\n",
      "epoch:21 step:20556 [D loss: 0.241312, acc.: 57.81%] [G loss: 0.313610]\n",
      "epoch:21 step:20557 [D loss: 0.249608, acc.: 54.69%] [G loss: 0.308969]\n",
      "epoch:21 step:20558 [D loss: 0.246890, acc.: 52.34%] [G loss: 0.315211]\n",
      "epoch:21 step:20559 [D loss: 0.238871, acc.: 53.91%] [G loss: 0.290803]\n",
      "epoch:21 step:20560 [D loss: 0.250102, acc.: 53.12%] [G loss: 0.310137]\n",
      "epoch:21 step:20561 [D loss: 0.220783, acc.: 65.62%] [G loss: 0.329070]\n",
      "epoch:21 step:20562 [D loss: 0.235826, acc.: 64.06%] [G loss: 0.305890]\n",
      "epoch:21 step:20563 [D loss: 0.251620, acc.: 53.12%] [G loss: 0.285243]\n",
      "epoch:21 step:20564 [D loss: 0.242183, acc.: 55.47%] [G loss: 0.310811]\n",
      "epoch:21 step:20565 [D loss: 0.235324, acc.: 64.84%] [G loss: 0.319119]\n",
      "epoch:21 step:20566 [D loss: 0.253137, acc.: 53.12%] [G loss: 0.320324]\n",
      "epoch:21 step:20567 [D loss: 0.229852, acc.: 59.38%] [G loss: 0.311581]\n",
      "epoch:21 step:20568 [D loss: 0.248511, acc.: 53.91%] [G loss: 0.312577]\n",
      "epoch:21 step:20569 [D loss: 0.245349, acc.: 60.94%] [G loss: 0.308249]\n",
      "epoch:21 step:20570 [D loss: 0.233199, acc.: 64.84%] [G loss: 0.296865]\n",
      "epoch:21 step:20571 [D loss: 0.246537, acc.: 58.59%] [G loss: 0.301095]\n",
      "epoch:21 step:20572 [D loss: 0.252649, acc.: 55.47%] [G loss: 0.315672]\n",
      "epoch:21 step:20573 [D loss: 0.228696, acc.: 62.50%] [G loss: 0.296104]\n",
      "epoch:21 step:20574 [D loss: 0.236994, acc.: 64.84%] [G loss: 0.305691]\n",
      "epoch:21 step:20575 [D loss: 0.221232, acc.: 64.06%] [G loss: 0.334994]\n",
      "epoch:21 step:20576 [D loss: 0.226371, acc.: 60.16%] [G loss: 0.305644]\n",
      "epoch:21 step:20577 [D loss: 0.217388, acc.: 67.97%] [G loss: 0.310785]\n",
      "epoch:21 step:20578 [D loss: 0.261239, acc.: 48.44%] [G loss: 0.325414]\n",
      "epoch:21 step:20579 [D loss: 0.232441, acc.: 60.94%] [G loss: 0.296706]\n",
      "epoch:21 step:20580 [D loss: 0.232801, acc.: 60.16%] [G loss: 0.324229]\n",
      "epoch:21 step:20581 [D loss: 0.233595, acc.: 60.94%] [G loss: 0.312599]\n",
      "epoch:21 step:20582 [D loss: 0.240364, acc.: 59.38%] [G loss: 0.315339]\n",
      "epoch:21 step:20583 [D loss: 0.249148, acc.: 56.25%] [G loss: 0.311605]\n",
      "epoch:21 step:20584 [D loss: 0.236624, acc.: 59.38%] [G loss: 0.310712]\n",
      "epoch:21 step:20585 [D loss: 0.252577, acc.: 51.56%] [G loss: 0.320220]\n",
      "epoch:21 step:20586 [D loss: 0.237099, acc.: 59.38%] [G loss: 0.290512]\n",
      "epoch:21 step:20587 [D loss: 0.237218, acc.: 63.28%] [G loss: 0.303432]\n",
      "epoch:21 step:20588 [D loss: 0.242079, acc.: 56.25%] [G loss: 0.301322]\n",
      "epoch:21 step:20589 [D loss: 0.252751, acc.: 49.22%] [G loss: 0.314121]\n",
      "epoch:21 step:20590 [D loss: 0.234437, acc.: 61.72%] [G loss: 0.286627]\n",
      "epoch:21 step:20591 [D loss: 0.227927, acc.: 63.28%] [G loss: 0.301112]\n",
      "epoch:21 step:20592 [D loss: 0.230659, acc.: 57.81%] [G loss: 0.317261]\n",
      "epoch:21 step:20593 [D loss: 0.241867, acc.: 57.81%] [G loss: 0.308866]\n",
      "epoch:21 step:20594 [D loss: 0.230409, acc.: 61.72%] [G loss: 0.276678]\n",
      "epoch:21 step:20595 [D loss: 0.230962, acc.: 67.97%] [G loss: 0.344472]\n",
      "epoch:21 step:20596 [D loss: 0.251626, acc.: 50.78%] [G loss: 0.318811]\n",
      "epoch:21 step:20597 [D loss: 0.246357, acc.: 53.12%] [G loss: 0.298085]\n",
      "epoch:21 step:20598 [D loss: 0.248771, acc.: 60.16%] [G loss: 0.314353]\n",
      "epoch:21 step:20599 [D loss: 0.256711, acc.: 51.56%] [G loss: 0.304005]\n",
      "epoch:21 step:20600 [D loss: 0.228815, acc.: 67.97%] [G loss: 0.327666]\n",
      "epoch:21 step:20601 [D loss: 0.248758, acc.: 53.91%] [G loss: 0.299953]\n",
      "epoch:21 step:20602 [D loss: 0.254213, acc.: 52.34%] [G loss: 0.287049]\n",
      "epoch:21 step:20603 [D loss: 0.251988, acc.: 54.69%] [G loss: 0.290064]\n",
      "epoch:21 step:20604 [D loss: 0.245408, acc.: 55.47%] [G loss: 0.296017]\n",
      "epoch:21 step:20605 [D loss: 0.224388, acc.: 62.50%] [G loss: 0.319740]\n",
      "epoch:21 step:20606 [D loss: 0.233380, acc.: 58.59%] [G loss: 0.320312]\n",
      "epoch:21 step:20607 [D loss: 0.255893, acc.: 50.78%] [G loss: 0.307274]\n",
      "epoch:21 step:20608 [D loss: 0.230173, acc.: 62.50%] [G loss: 0.293305]\n",
      "epoch:21 step:20609 [D loss: 0.235762, acc.: 58.59%] [G loss: 0.304169]\n",
      "epoch:21 step:20610 [D loss: 0.249817, acc.: 53.91%] [G loss: 0.300875]\n",
      "epoch:21 step:20611 [D loss: 0.254405, acc.: 50.00%] [G loss: 0.286686]\n",
      "epoch:21 step:20612 [D loss: 0.232118, acc.: 58.59%] [G loss: 0.318571]\n",
      "epoch:21 step:20613 [D loss: 0.254632, acc.: 52.34%] [G loss: 0.311758]\n",
      "epoch:21 step:20614 [D loss: 0.243455, acc.: 60.94%] [G loss: 0.298285]\n",
      "epoch:22 step:20615 [D loss: 0.270872, acc.: 43.75%] [G loss: 0.303454]\n",
      "epoch:22 step:20616 [D loss: 0.247154, acc.: 57.03%] [G loss: 0.290336]\n",
      "epoch:22 step:20617 [D loss: 0.229980, acc.: 61.72%] [G loss: 0.302517]\n",
      "epoch:22 step:20618 [D loss: 0.235770, acc.: 60.16%] [G loss: 0.322180]\n",
      "epoch:22 step:20619 [D loss: 0.249441, acc.: 55.47%] [G loss: 0.284740]\n",
      "epoch:22 step:20620 [D loss: 0.239141, acc.: 58.59%] [G loss: 0.285831]\n",
      "epoch:22 step:20621 [D loss: 0.254472, acc.: 50.00%] [G loss: 0.296519]\n",
      "epoch:22 step:20622 [D loss: 0.249813, acc.: 52.34%] [G loss: 0.307501]\n",
      "epoch:22 step:20623 [D loss: 0.225511, acc.: 63.28%] [G loss: 0.296097]\n",
      "epoch:22 step:20624 [D loss: 0.250421, acc.: 53.12%] [G loss: 0.303805]\n",
      "epoch:22 step:20625 [D loss: 0.219640, acc.: 68.75%] [G loss: 0.316490]\n",
      "epoch:22 step:20626 [D loss: 0.234863, acc.: 60.16%] [G loss: 0.309732]\n",
      "epoch:22 step:20627 [D loss: 0.235001, acc.: 59.38%] [G loss: 0.292925]\n",
      "epoch:22 step:20628 [D loss: 0.245520, acc.: 54.69%] [G loss: 0.317122]\n",
      "epoch:22 step:20629 [D loss: 0.248882, acc.: 53.91%] [G loss: 0.290157]\n",
      "epoch:22 step:20630 [D loss: 0.227340, acc.: 65.62%] [G loss: 0.285445]\n",
      "epoch:22 step:20631 [D loss: 0.218971, acc.: 63.28%] [G loss: 0.305803]\n",
      "epoch:22 step:20632 [D loss: 0.254336, acc.: 53.12%] [G loss: 0.288505]\n",
      "epoch:22 step:20633 [D loss: 0.244044, acc.: 57.81%] [G loss: 0.296160]\n",
      "epoch:22 step:20634 [D loss: 0.258202, acc.: 54.69%] [G loss: 0.322036]\n",
      "epoch:22 step:20635 [D loss: 0.231678, acc.: 58.59%] [G loss: 0.306057]\n",
      "epoch:22 step:20636 [D loss: 0.232910, acc.: 58.59%] [G loss: 0.286035]\n",
      "epoch:22 step:20637 [D loss: 0.238025, acc.: 58.59%] [G loss: 0.315665]\n",
      "epoch:22 step:20638 [D loss: 0.227050, acc.: 60.16%] [G loss: 0.275752]\n",
      "epoch:22 step:20639 [D loss: 0.235819, acc.: 57.81%] [G loss: 0.295938]\n",
      "epoch:22 step:20640 [D loss: 0.236089, acc.: 58.59%] [G loss: 0.288654]\n",
      "epoch:22 step:20641 [D loss: 0.238231, acc.: 59.38%] [G loss: 0.305745]\n",
      "epoch:22 step:20642 [D loss: 0.241448, acc.: 57.81%] [G loss: 0.285564]\n",
      "epoch:22 step:20643 [D loss: 0.244070, acc.: 60.16%] [G loss: 0.306498]\n",
      "epoch:22 step:20644 [D loss: 0.213880, acc.: 67.97%] [G loss: 0.307897]\n",
      "epoch:22 step:20645 [D loss: 0.243647, acc.: 55.47%] [G loss: 0.284898]\n",
      "epoch:22 step:20646 [D loss: 0.234570, acc.: 61.72%] [G loss: 0.307134]\n",
      "epoch:22 step:20647 [D loss: 0.244196, acc.: 52.34%] [G loss: 0.296860]\n",
      "epoch:22 step:20648 [D loss: 0.251330, acc.: 50.00%] [G loss: 0.294852]\n",
      "epoch:22 step:20649 [D loss: 0.238780, acc.: 58.59%] [G loss: 0.305678]\n",
      "epoch:22 step:20650 [D loss: 0.253070, acc.: 55.47%] [G loss: 0.319306]\n",
      "epoch:22 step:20651 [D loss: 0.238470, acc.: 62.50%] [G loss: 0.297336]\n",
      "epoch:22 step:20652 [D loss: 0.230939, acc.: 60.16%] [G loss: 0.281329]\n",
      "epoch:22 step:20653 [D loss: 0.234208, acc.: 59.38%] [G loss: 0.307983]\n",
      "epoch:22 step:20654 [D loss: 0.223684, acc.: 67.97%] [G loss: 0.305192]\n",
      "epoch:22 step:20655 [D loss: 0.249664, acc.: 54.69%] [G loss: 0.291156]\n",
      "epoch:22 step:20656 [D loss: 0.243660, acc.: 64.06%] [G loss: 0.308192]\n",
      "epoch:22 step:20657 [D loss: 0.251927, acc.: 55.47%] [G loss: 0.304737]\n",
      "epoch:22 step:20658 [D loss: 0.227622, acc.: 66.41%] [G loss: 0.318308]\n",
      "epoch:22 step:20659 [D loss: 0.252641, acc.: 57.81%] [G loss: 0.304432]\n",
      "epoch:22 step:20660 [D loss: 0.245134, acc.: 51.56%] [G loss: 0.300163]\n",
      "epoch:22 step:20661 [D loss: 0.256879, acc.: 54.69%] [G loss: 0.324333]\n",
      "epoch:22 step:20662 [D loss: 0.237751, acc.: 59.38%] [G loss: 0.310465]\n",
      "epoch:22 step:20663 [D loss: 0.230839, acc.: 66.41%] [G loss: 0.286382]\n",
      "epoch:22 step:20664 [D loss: 0.224788, acc.: 69.53%] [G loss: 0.320135]\n",
      "epoch:22 step:20665 [D loss: 0.231082, acc.: 65.62%] [G loss: 0.305343]\n",
      "epoch:22 step:20666 [D loss: 0.219273, acc.: 66.41%] [G loss: 0.292214]\n",
      "epoch:22 step:20667 [D loss: 0.246252, acc.: 50.78%] [G loss: 0.283684]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:22 step:20668 [D loss: 0.226619, acc.: 66.41%] [G loss: 0.298906]\n",
      "epoch:22 step:20669 [D loss: 0.242861, acc.: 57.81%] [G loss: 0.296513]\n",
      "epoch:22 step:20670 [D loss: 0.232312, acc.: 58.59%] [G loss: 0.318218]\n",
      "epoch:22 step:20671 [D loss: 0.242051, acc.: 57.81%] [G loss: 0.304507]\n",
      "epoch:22 step:20672 [D loss: 0.231389, acc.: 60.94%] [G loss: 0.312634]\n",
      "epoch:22 step:20673 [D loss: 0.207619, acc.: 72.66%] [G loss: 0.298609]\n",
      "epoch:22 step:20674 [D loss: 0.227638, acc.: 63.28%] [G loss: 0.289948]\n",
      "epoch:22 step:20675 [D loss: 0.236424, acc.: 59.38%] [G loss: 0.310881]\n",
      "epoch:22 step:20676 [D loss: 0.252209, acc.: 56.25%] [G loss: 0.290468]\n",
      "epoch:22 step:20677 [D loss: 0.236297, acc.: 56.25%] [G loss: 0.288257]\n",
      "epoch:22 step:20678 [D loss: 0.244247, acc.: 56.25%] [G loss: 0.285948]\n",
      "epoch:22 step:20679 [D loss: 0.238373, acc.: 54.69%] [G loss: 0.291109]\n",
      "epoch:22 step:20680 [D loss: 0.253846, acc.: 56.25%] [G loss: 0.294701]\n",
      "epoch:22 step:20681 [D loss: 0.217154, acc.: 66.41%] [G loss: 0.308042]\n",
      "epoch:22 step:20682 [D loss: 0.230081, acc.: 62.50%] [G loss: 0.297929]\n",
      "epoch:22 step:20683 [D loss: 0.220209, acc.: 64.84%] [G loss: 0.328044]\n",
      "epoch:22 step:20684 [D loss: 0.246292, acc.: 54.69%] [G loss: 0.320865]\n",
      "epoch:22 step:20685 [D loss: 0.231929, acc.: 57.03%] [G loss: 0.308525]\n",
      "epoch:22 step:20686 [D loss: 0.249624, acc.: 58.59%] [G loss: 0.314593]\n",
      "epoch:22 step:20687 [D loss: 0.252630, acc.: 55.47%] [G loss: 0.329719]\n",
      "epoch:22 step:20688 [D loss: 0.223013, acc.: 64.06%] [G loss: 0.321543]\n",
      "epoch:22 step:20689 [D loss: 0.246380, acc.: 61.72%] [G loss: 0.314956]\n",
      "epoch:22 step:20690 [D loss: 0.222472, acc.: 64.84%] [G loss: 0.308205]\n",
      "epoch:22 step:20691 [D loss: 0.244217, acc.: 53.91%] [G loss: 0.304100]\n",
      "epoch:22 step:20692 [D loss: 0.244503, acc.: 57.03%] [G loss: 0.291132]\n",
      "epoch:22 step:20693 [D loss: 0.236029, acc.: 60.16%] [G loss: 0.283206]\n",
      "epoch:22 step:20694 [D loss: 0.242477, acc.: 57.03%] [G loss: 0.300414]\n",
      "epoch:22 step:20695 [D loss: 0.238866, acc.: 60.94%] [G loss: 0.313146]\n",
      "epoch:22 step:20696 [D loss: 0.227070, acc.: 57.03%] [G loss: 0.287632]\n",
      "epoch:22 step:20697 [D loss: 0.262110, acc.: 53.91%] [G loss: 0.270976]\n",
      "epoch:22 step:20698 [D loss: 0.249412, acc.: 48.44%] [G loss: 0.309470]\n",
      "epoch:22 step:20699 [D loss: 0.235236, acc.: 57.03%] [G loss: 0.277303]\n",
      "epoch:22 step:20700 [D loss: 0.233725, acc.: 60.16%] [G loss: 0.296325]\n",
      "epoch:22 step:20701 [D loss: 0.227621, acc.: 65.62%] [G loss: 0.307815]\n",
      "epoch:22 step:20702 [D loss: 0.248074, acc.: 48.44%] [G loss: 0.296684]\n",
      "epoch:22 step:20703 [D loss: 0.233758, acc.: 59.38%] [G loss: 0.328894]\n",
      "epoch:22 step:20704 [D loss: 0.227862, acc.: 63.28%] [G loss: 0.311461]\n",
      "epoch:22 step:20705 [D loss: 0.249830, acc.: 54.69%] [G loss: 0.286446]\n",
      "epoch:22 step:20706 [D loss: 0.229324, acc.: 61.72%] [G loss: 0.297220]\n",
      "epoch:22 step:20707 [D loss: 0.230142, acc.: 57.81%] [G loss: 0.296096]\n",
      "epoch:22 step:20708 [D loss: 0.234196, acc.: 53.91%] [G loss: 0.288394]\n",
      "epoch:22 step:20709 [D loss: 0.241127, acc.: 57.81%] [G loss: 0.328308]\n",
      "epoch:22 step:20710 [D loss: 0.245538, acc.: 59.38%] [G loss: 0.309341]\n",
      "epoch:22 step:20711 [D loss: 0.243514, acc.: 57.81%] [G loss: 0.276259]\n",
      "epoch:22 step:20712 [D loss: 0.234206, acc.: 61.72%] [G loss: 0.297811]\n",
      "epoch:22 step:20713 [D loss: 0.229001, acc.: 61.72%] [G loss: 0.301915]\n",
      "epoch:22 step:20714 [D loss: 0.223509, acc.: 61.72%] [G loss: 0.286712]\n",
      "epoch:22 step:20715 [D loss: 0.234859, acc.: 56.25%] [G loss: 0.298937]\n",
      "epoch:22 step:20716 [D loss: 0.236416, acc.: 59.38%] [G loss: 0.310522]\n",
      "epoch:22 step:20717 [D loss: 0.238467, acc.: 61.72%] [G loss: 0.291446]\n",
      "epoch:22 step:20718 [D loss: 0.236245, acc.: 60.94%] [G loss: 0.300670]\n",
      "epoch:22 step:20719 [D loss: 0.230691, acc.: 66.41%] [G loss: 0.327067]\n",
      "epoch:22 step:20720 [D loss: 0.246003, acc.: 53.91%] [G loss: 0.294713]\n",
      "epoch:22 step:20721 [D loss: 0.251316, acc.: 53.12%] [G loss: 0.272428]\n",
      "epoch:22 step:20722 [D loss: 0.219360, acc.: 63.28%] [G loss: 0.310083]\n",
      "epoch:22 step:20723 [D loss: 0.240084, acc.: 59.38%] [G loss: 0.295076]\n",
      "epoch:22 step:20724 [D loss: 0.246029, acc.: 53.12%] [G loss: 0.290474]\n",
      "epoch:22 step:20725 [D loss: 0.257276, acc.: 53.91%] [G loss: 0.306519]\n",
      "epoch:22 step:20726 [D loss: 0.252697, acc.: 56.25%] [G loss: 0.276756]\n",
      "epoch:22 step:20727 [D loss: 0.252407, acc.: 52.34%] [G loss: 0.290182]\n",
      "epoch:22 step:20728 [D loss: 0.222268, acc.: 65.62%] [G loss: 0.350405]\n",
      "epoch:22 step:20729 [D loss: 0.239434, acc.: 63.28%] [G loss: 0.316104]\n",
      "epoch:22 step:20730 [D loss: 0.252467, acc.: 52.34%] [G loss: 0.316424]\n",
      "epoch:22 step:20731 [D loss: 0.245314, acc.: 55.47%] [G loss: 0.324479]\n",
      "epoch:22 step:20732 [D loss: 0.234588, acc.: 59.38%] [G loss: 0.318247]\n",
      "epoch:22 step:20733 [D loss: 0.241462, acc.: 60.94%] [G loss: 0.303090]\n",
      "epoch:22 step:20734 [D loss: 0.238256, acc.: 63.28%] [G loss: 0.293821]\n",
      "epoch:22 step:20735 [D loss: 0.241563, acc.: 53.91%] [G loss: 0.309494]\n",
      "epoch:22 step:20736 [D loss: 0.241669, acc.: 60.16%] [G loss: 0.315188]\n",
      "epoch:22 step:20737 [D loss: 0.227239, acc.: 67.97%] [G loss: 0.269035]\n",
      "epoch:22 step:20738 [D loss: 0.248979, acc.: 53.12%] [G loss: 0.298038]\n",
      "epoch:22 step:20739 [D loss: 0.248481, acc.: 57.03%] [G loss: 0.291869]\n",
      "epoch:22 step:20740 [D loss: 0.247622, acc.: 60.94%] [G loss: 0.297014]\n",
      "epoch:22 step:20741 [D loss: 0.253227, acc.: 50.78%] [G loss: 0.292178]\n",
      "epoch:22 step:20742 [D loss: 0.233722, acc.: 58.59%] [G loss: 0.317358]\n",
      "epoch:22 step:20743 [D loss: 0.237436, acc.: 59.38%] [G loss: 0.269796]\n",
      "epoch:22 step:20744 [D loss: 0.244773, acc.: 53.91%] [G loss: 0.312211]\n",
      "epoch:22 step:20745 [D loss: 0.230553, acc.: 58.59%] [G loss: 0.293574]\n",
      "epoch:22 step:20746 [D loss: 0.231724, acc.: 57.81%] [G loss: 0.304115]\n",
      "epoch:22 step:20747 [D loss: 0.228583, acc.: 62.50%] [G loss: 0.302004]\n",
      "epoch:22 step:20748 [D loss: 0.246601, acc.: 50.00%] [G loss: 0.271585]\n",
      "epoch:22 step:20749 [D loss: 0.223310, acc.: 61.72%] [G loss: 0.299066]\n",
      "epoch:22 step:20750 [D loss: 0.251294, acc.: 53.91%] [G loss: 0.313781]\n",
      "epoch:22 step:20751 [D loss: 0.237254, acc.: 58.59%] [G loss: 0.312420]\n",
      "epoch:22 step:20752 [D loss: 0.240171, acc.: 55.47%] [G loss: 0.280409]\n",
      "epoch:22 step:20753 [D loss: 0.231360, acc.: 60.16%] [G loss: 0.287340]\n",
      "epoch:22 step:20754 [D loss: 0.249205, acc.: 51.56%] [G loss: 0.313225]\n",
      "epoch:22 step:20755 [D loss: 0.235649, acc.: 65.62%] [G loss: 0.303642]\n",
      "epoch:22 step:20756 [D loss: 0.228057, acc.: 61.72%] [G loss: 0.288285]\n",
      "epoch:22 step:20757 [D loss: 0.234004, acc.: 57.03%] [G loss: 0.304474]\n",
      "epoch:22 step:20758 [D loss: 0.236502, acc.: 62.50%] [G loss: 0.326396]\n",
      "epoch:22 step:20759 [D loss: 0.239080, acc.: 57.03%] [G loss: 0.299747]\n",
      "epoch:22 step:20760 [D loss: 0.241590, acc.: 57.81%] [G loss: 0.312582]\n",
      "epoch:22 step:20761 [D loss: 0.243257, acc.: 53.91%] [G loss: 0.305378]\n",
      "epoch:22 step:20762 [D loss: 0.237144, acc.: 57.03%] [G loss: 0.297484]\n",
      "epoch:22 step:20763 [D loss: 0.238159, acc.: 58.59%] [G loss: 0.315420]\n",
      "epoch:22 step:20764 [D loss: 0.222210, acc.: 66.41%] [G loss: 0.310124]\n",
      "epoch:22 step:20765 [D loss: 0.249211, acc.: 52.34%] [G loss: 0.313861]\n",
      "epoch:22 step:20766 [D loss: 0.222673, acc.: 64.84%] [G loss: 0.339867]\n",
      "epoch:22 step:20767 [D loss: 0.242374, acc.: 52.34%] [G loss: 0.304820]\n",
      "epoch:22 step:20768 [D loss: 0.246668, acc.: 48.44%] [G loss: 0.311216]\n",
      "epoch:22 step:20769 [D loss: 0.239757, acc.: 56.25%] [G loss: 0.281836]\n",
      "epoch:22 step:20770 [D loss: 0.237398, acc.: 57.03%] [G loss: 0.284318]\n",
      "epoch:22 step:20771 [D loss: 0.238131, acc.: 61.72%] [G loss: 0.304087]\n",
      "epoch:22 step:20772 [D loss: 0.224839, acc.: 60.94%] [G loss: 0.287408]\n",
      "epoch:22 step:20773 [D loss: 0.233258, acc.: 58.59%] [G loss: 0.312182]\n",
      "epoch:22 step:20774 [D loss: 0.238306, acc.: 61.72%] [G loss: 0.304878]\n",
      "epoch:22 step:20775 [D loss: 0.225615, acc.: 65.62%] [G loss: 0.322181]\n",
      "epoch:22 step:20776 [D loss: 0.228571, acc.: 61.72%] [G loss: 0.299014]\n",
      "epoch:22 step:20777 [D loss: 0.236490, acc.: 54.69%] [G loss: 0.326283]\n",
      "epoch:22 step:20778 [D loss: 0.239479, acc.: 58.59%] [G loss: 0.319313]\n",
      "epoch:22 step:20779 [D loss: 0.260394, acc.: 46.09%] [G loss: 0.273141]\n",
      "epoch:22 step:20780 [D loss: 0.241368, acc.: 61.72%] [G loss: 0.275875]\n",
      "epoch:22 step:20781 [D loss: 0.222403, acc.: 61.72%] [G loss: 0.321499]\n",
      "epoch:22 step:20782 [D loss: 0.248594, acc.: 50.78%] [G loss: 0.301198]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:22 step:20783 [D loss: 0.236449, acc.: 60.16%] [G loss: 0.306025]\n",
      "epoch:22 step:20784 [D loss: 0.232510, acc.: 58.59%] [G loss: 0.304745]\n",
      "epoch:22 step:20785 [D loss: 0.243959, acc.: 51.56%] [G loss: 0.313806]\n",
      "epoch:22 step:20786 [D loss: 0.230613, acc.: 65.62%] [G loss: 0.301489]\n",
      "epoch:22 step:20787 [D loss: 0.240524, acc.: 58.59%] [G loss: 0.312823]\n",
      "epoch:22 step:20788 [D loss: 0.220858, acc.: 61.72%] [G loss: 0.312891]\n",
      "epoch:22 step:20789 [D loss: 0.258550, acc.: 47.66%] [G loss: 0.318275]\n",
      "epoch:22 step:20790 [D loss: 0.249247, acc.: 46.88%] [G loss: 0.329558]\n",
      "epoch:22 step:20791 [D loss: 0.233884, acc.: 58.59%] [G loss: 0.302901]\n",
      "epoch:22 step:20792 [D loss: 0.222616, acc.: 64.84%] [G loss: 0.301599]\n",
      "epoch:22 step:20793 [D loss: 0.232477, acc.: 62.50%] [G loss: 0.310185]\n",
      "epoch:22 step:20794 [D loss: 0.240332, acc.: 60.16%] [G loss: 0.292443]\n",
      "epoch:22 step:20795 [D loss: 0.229069, acc.: 63.28%] [G loss: 0.321646]\n",
      "epoch:22 step:20796 [D loss: 0.245517, acc.: 56.25%] [G loss: 0.318918]\n",
      "epoch:22 step:20797 [D loss: 0.244573, acc.: 58.59%] [G loss: 0.292810]\n",
      "epoch:22 step:20798 [D loss: 0.234872, acc.: 57.03%] [G loss: 0.307118]\n",
      "epoch:22 step:20799 [D loss: 0.259349, acc.: 50.00%] [G loss: 0.307648]\n",
      "epoch:22 step:20800 [D loss: 0.238563, acc.: 59.38%] [G loss: 0.318374]\n",
      "epoch:22 step:20801 [D loss: 0.235332, acc.: 60.94%] [G loss: 0.316010]\n",
      "epoch:22 step:20802 [D loss: 0.262065, acc.: 53.91%] [G loss: 0.297276]\n",
      "epoch:22 step:20803 [D loss: 0.240214, acc.: 57.03%] [G loss: 0.297328]\n",
      "epoch:22 step:20804 [D loss: 0.255729, acc.: 56.25%] [G loss: 0.290955]\n",
      "epoch:22 step:20805 [D loss: 0.222850, acc.: 64.06%] [G loss: 0.278641]\n",
      "epoch:22 step:20806 [D loss: 0.226206, acc.: 64.84%] [G loss: 0.302132]\n",
      "epoch:22 step:20807 [D loss: 0.227279, acc.: 62.50%] [G loss: 0.300879]\n",
      "epoch:22 step:20808 [D loss: 0.241166, acc.: 62.50%] [G loss: 0.303079]\n",
      "epoch:22 step:20809 [D loss: 0.237757, acc.: 60.94%] [G loss: 0.341646]\n",
      "epoch:22 step:20810 [D loss: 0.232227, acc.: 63.28%] [G loss: 0.293939]\n",
      "epoch:22 step:20811 [D loss: 0.222185, acc.: 68.75%] [G loss: 0.318123]\n",
      "epoch:22 step:20812 [D loss: 0.245798, acc.: 58.59%] [G loss: 0.288105]\n",
      "epoch:22 step:20813 [D loss: 0.233308, acc.: 59.38%] [G loss: 0.305752]\n",
      "epoch:22 step:20814 [D loss: 0.245985, acc.: 54.69%] [G loss: 0.290791]\n",
      "epoch:22 step:20815 [D loss: 0.216966, acc.: 64.84%] [G loss: 0.287903]\n",
      "epoch:22 step:20816 [D loss: 0.244944, acc.: 54.69%] [G loss: 0.303828]\n",
      "epoch:22 step:20817 [D loss: 0.239400, acc.: 62.50%] [G loss: 0.310256]\n",
      "epoch:22 step:20818 [D loss: 0.220434, acc.: 65.62%] [G loss: 0.336692]\n",
      "epoch:22 step:20819 [D loss: 0.238344, acc.: 60.16%] [G loss: 0.297838]\n",
      "epoch:22 step:20820 [D loss: 0.236161, acc.: 58.59%] [G loss: 0.300394]\n",
      "epoch:22 step:20821 [D loss: 0.246846, acc.: 52.34%] [G loss: 0.302485]\n",
      "epoch:22 step:20822 [D loss: 0.252362, acc.: 50.00%] [G loss: 0.288656]\n",
      "epoch:22 step:20823 [D loss: 0.246760, acc.: 53.91%] [G loss: 0.315703]\n",
      "epoch:22 step:20824 [D loss: 0.226893, acc.: 65.62%] [G loss: 0.293178]\n",
      "epoch:22 step:20825 [D loss: 0.235078, acc.: 61.72%] [G loss: 0.310389]\n",
      "epoch:22 step:20826 [D loss: 0.242315, acc.: 61.72%] [G loss: 0.301739]\n",
      "epoch:22 step:20827 [D loss: 0.238785, acc.: 57.03%] [G loss: 0.307504]\n",
      "epoch:22 step:20828 [D loss: 0.243425, acc.: 58.59%] [G loss: 0.294495]\n",
      "epoch:22 step:20829 [D loss: 0.238968, acc.: 58.59%] [G loss: 0.328416]\n",
      "epoch:22 step:20830 [D loss: 0.235354, acc.: 56.25%] [G loss: 0.300274]\n",
      "epoch:22 step:20831 [D loss: 0.197804, acc.: 69.53%] [G loss: 0.323278]\n",
      "epoch:22 step:20832 [D loss: 0.249582, acc.: 57.03%] [G loss: 0.327682]\n",
      "epoch:22 step:20833 [D loss: 0.243352, acc.: 56.25%] [G loss: 0.285238]\n",
      "epoch:22 step:20834 [D loss: 0.232378, acc.: 60.94%] [G loss: 0.313683]\n",
      "epoch:22 step:20835 [D loss: 0.245345, acc.: 58.59%] [G loss: 0.295228]\n",
      "epoch:22 step:20836 [D loss: 0.242745, acc.: 60.16%] [G loss: 0.277202]\n",
      "epoch:22 step:20837 [D loss: 0.256742, acc.: 53.91%] [G loss: 0.289165]\n",
      "epoch:22 step:20838 [D loss: 0.219512, acc.: 64.84%] [G loss: 0.346523]\n",
      "epoch:22 step:20839 [D loss: 0.230926, acc.: 59.38%] [G loss: 0.311965]\n",
      "epoch:22 step:20840 [D loss: 0.242717, acc.: 57.03%] [G loss: 0.286596]\n",
      "epoch:22 step:20841 [D loss: 0.228345, acc.: 57.03%] [G loss: 0.322452]\n",
      "epoch:22 step:20842 [D loss: 0.239205, acc.: 56.25%] [G loss: 0.314530]\n",
      "epoch:22 step:20843 [D loss: 0.224557, acc.: 61.72%] [G loss: 0.291559]\n",
      "epoch:22 step:20844 [D loss: 0.241968, acc.: 61.72%] [G loss: 0.340526]\n",
      "epoch:22 step:20845 [D loss: 0.233734, acc.: 59.38%] [G loss: 0.292397]\n",
      "epoch:22 step:20846 [D loss: 0.249805, acc.: 53.12%] [G loss: 0.314384]\n",
      "epoch:22 step:20847 [D loss: 0.252893, acc.: 51.56%] [G loss: 0.286244]\n",
      "epoch:22 step:20848 [D loss: 0.231159, acc.: 62.50%] [G loss: 0.338077]\n",
      "epoch:22 step:20849 [D loss: 0.227452, acc.: 62.50%] [G loss: 0.307392]\n",
      "epoch:22 step:20850 [D loss: 0.244508, acc.: 60.16%] [G loss: 0.314118]\n",
      "epoch:22 step:20851 [D loss: 0.246088, acc.: 53.91%] [G loss: 0.320634]\n",
      "epoch:22 step:20852 [D loss: 0.253661, acc.: 52.34%] [G loss: 0.309197]\n",
      "epoch:22 step:20853 [D loss: 0.234203, acc.: 62.50%] [G loss: 0.321806]\n",
      "epoch:22 step:20854 [D loss: 0.233299, acc.: 60.94%] [G loss: 0.320040]\n",
      "epoch:22 step:20855 [D loss: 0.243925, acc.: 60.16%] [G loss: 0.294231]\n",
      "epoch:22 step:20856 [D loss: 0.238155, acc.: 57.81%] [G loss: 0.293559]\n",
      "epoch:22 step:20857 [D loss: 0.256075, acc.: 49.22%] [G loss: 0.282117]\n",
      "epoch:22 step:20858 [D loss: 0.247626, acc.: 55.47%] [G loss: 0.291191]\n",
      "epoch:22 step:20859 [D loss: 0.247597, acc.: 54.69%] [G loss: 0.299156]\n",
      "epoch:22 step:20860 [D loss: 0.231635, acc.: 64.06%] [G loss: 0.314494]\n",
      "epoch:22 step:20861 [D loss: 0.217973, acc.: 62.50%] [G loss: 0.303240]\n",
      "epoch:22 step:20862 [D loss: 0.249162, acc.: 50.78%] [G loss: 0.314633]\n",
      "epoch:22 step:20863 [D loss: 0.240411, acc.: 59.38%] [G loss: 0.274203]\n",
      "epoch:22 step:20864 [D loss: 0.223961, acc.: 62.50%] [G loss: 0.349522]\n",
      "epoch:22 step:20865 [D loss: 0.240603, acc.: 58.59%] [G loss: 0.282621]\n",
      "epoch:22 step:20866 [D loss: 0.243343, acc.: 56.25%] [G loss: 0.306963]\n",
      "epoch:22 step:20867 [D loss: 0.230082, acc.: 64.84%] [G loss: 0.272185]\n",
      "epoch:22 step:20868 [D loss: 0.253154, acc.: 53.12%] [G loss: 0.337253]\n",
      "epoch:22 step:20869 [D loss: 0.234923, acc.: 57.81%] [G loss: 0.320516]\n",
      "epoch:22 step:20870 [D loss: 0.224501, acc.: 61.72%] [G loss: 0.304322]\n",
      "epoch:22 step:20871 [D loss: 0.254510, acc.: 60.94%] [G loss: 0.299678]\n",
      "epoch:22 step:20872 [D loss: 0.225840, acc.: 66.41%] [G loss: 0.321279]\n",
      "epoch:22 step:20873 [D loss: 0.243158, acc.: 54.69%] [G loss: 0.317145]\n",
      "epoch:22 step:20874 [D loss: 0.229612, acc.: 59.38%] [G loss: 0.300842]\n",
      "epoch:22 step:20875 [D loss: 0.237299, acc.: 56.25%] [G loss: 0.314043]\n",
      "epoch:22 step:20876 [D loss: 0.242627, acc.: 58.59%] [G loss: 0.299251]\n",
      "epoch:22 step:20877 [D loss: 0.246105, acc.: 52.34%] [G loss: 0.310405]\n",
      "epoch:22 step:20878 [D loss: 0.243008, acc.: 55.47%] [G loss: 0.321357]\n",
      "epoch:22 step:20879 [D loss: 0.237703, acc.: 57.81%] [G loss: 0.291577]\n",
      "epoch:22 step:20880 [D loss: 0.232932, acc.: 56.25%] [G loss: 0.303594]\n",
      "epoch:22 step:20881 [D loss: 0.240967, acc.: 51.56%] [G loss: 0.285726]\n",
      "epoch:22 step:20882 [D loss: 0.236232, acc.: 60.16%] [G loss: 0.296401]\n",
      "epoch:22 step:20883 [D loss: 0.238346, acc.: 63.28%] [G loss: 0.332072]\n",
      "epoch:22 step:20884 [D loss: 0.243367, acc.: 54.69%] [G loss: 0.285281]\n",
      "epoch:22 step:20885 [D loss: 0.244269, acc.: 53.12%] [G loss: 0.328008]\n",
      "epoch:22 step:20886 [D loss: 0.224550, acc.: 66.41%] [G loss: 0.276805]\n",
      "epoch:22 step:20887 [D loss: 0.250345, acc.: 49.22%] [G loss: 0.289539]\n",
      "epoch:22 step:20888 [D loss: 0.240727, acc.: 57.81%] [G loss: 0.297526]\n",
      "epoch:22 step:20889 [D loss: 0.237480, acc.: 60.16%] [G loss: 0.302822]\n",
      "epoch:22 step:20890 [D loss: 0.244582, acc.: 58.59%] [G loss: 0.309900]\n",
      "epoch:22 step:20891 [D loss: 0.247922, acc.: 56.25%] [G loss: 0.350614]\n",
      "epoch:22 step:20892 [D loss: 0.234915, acc.: 55.47%] [G loss: 0.332098]\n",
      "epoch:22 step:20893 [D loss: 0.239447, acc.: 56.25%] [G loss: 0.287863]\n",
      "epoch:22 step:20894 [D loss: 0.251002, acc.: 54.69%] [G loss: 0.300115]\n",
      "epoch:22 step:20895 [D loss: 0.244097, acc.: 57.81%] [G loss: 0.285847]\n",
      "epoch:22 step:20896 [D loss: 0.231112, acc.: 54.69%] [G loss: 0.297192]\n",
      "epoch:22 step:20897 [D loss: 0.232385, acc.: 57.81%] [G loss: 0.271848]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:22 step:20898 [D loss: 0.241887, acc.: 64.84%] [G loss: 0.291437]\n",
      "epoch:22 step:20899 [D loss: 0.235817, acc.: 60.94%] [G loss: 0.306417]\n",
      "epoch:22 step:20900 [D loss: 0.241675, acc.: 57.81%] [G loss: 0.319876]\n",
      "epoch:22 step:20901 [D loss: 0.244399, acc.: 54.69%] [G loss: 0.266189]\n",
      "epoch:22 step:20902 [D loss: 0.239555, acc.: 57.81%] [G loss: 0.295119]\n",
      "epoch:22 step:20903 [D loss: 0.225934, acc.: 62.50%] [G loss: 0.331364]\n",
      "epoch:22 step:20904 [D loss: 0.246893, acc.: 59.38%] [G loss: 0.307060]\n",
      "epoch:22 step:20905 [D loss: 0.230712, acc.: 61.72%] [G loss: 0.296888]\n",
      "epoch:22 step:20906 [D loss: 0.227861, acc.: 64.06%] [G loss: 0.337278]\n",
      "epoch:22 step:20907 [D loss: 0.230650, acc.: 64.84%] [G loss: 0.297342]\n",
      "epoch:22 step:20908 [D loss: 0.235472, acc.: 60.94%] [G loss: 0.310458]\n",
      "epoch:22 step:20909 [D loss: 0.258367, acc.: 48.44%] [G loss: 0.286553]\n",
      "epoch:22 step:20910 [D loss: 0.229452, acc.: 61.72%] [G loss: 0.329827]\n",
      "epoch:22 step:20911 [D loss: 0.240973, acc.: 56.25%] [G loss: 0.327578]\n",
      "epoch:22 step:20912 [D loss: 0.244272, acc.: 61.72%] [G loss: 0.299103]\n",
      "epoch:22 step:20913 [D loss: 0.231736, acc.: 62.50%] [G loss: 0.314699]\n",
      "epoch:22 step:20914 [D loss: 0.247176, acc.: 54.69%] [G loss: 0.288181]\n",
      "epoch:22 step:20915 [D loss: 0.241663, acc.: 60.16%] [G loss: 0.304602]\n",
      "epoch:22 step:20916 [D loss: 0.216025, acc.: 65.62%] [G loss: 0.286382]\n",
      "epoch:22 step:20917 [D loss: 0.243594, acc.: 58.59%] [G loss: 0.319664]\n",
      "epoch:22 step:20918 [D loss: 0.235819, acc.: 59.38%] [G loss: 0.299061]\n",
      "epoch:22 step:20919 [D loss: 0.246352, acc.: 56.25%] [G loss: 0.304418]\n",
      "epoch:22 step:20920 [D loss: 0.223768, acc.: 63.28%] [G loss: 0.277960]\n",
      "epoch:22 step:20921 [D loss: 0.239973, acc.: 54.69%] [G loss: 0.296178]\n",
      "epoch:22 step:20922 [D loss: 0.243326, acc.: 53.91%] [G loss: 0.290162]\n",
      "epoch:22 step:20923 [D loss: 0.223399, acc.: 64.06%] [G loss: 0.325432]\n",
      "epoch:22 step:20924 [D loss: 0.238973, acc.: 59.38%] [G loss: 0.273800]\n",
      "epoch:22 step:20925 [D loss: 0.241462, acc.: 58.59%] [G loss: 0.309442]\n",
      "epoch:22 step:20926 [D loss: 0.264156, acc.: 46.88%] [G loss: 0.304504]\n",
      "epoch:22 step:20927 [D loss: 0.242824, acc.: 54.69%] [G loss: 0.291974]\n",
      "epoch:22 step:20928 [D loss: 0.225487, acc.: 62.50%] [G loss: 0.298447]\n",
      "epoch:22 step:20929 [D loss: 0.244610, acc.: 51.56%] [G loss: 0.293351]\n",
      "epoch:22 step:20930 [D loss: 0.237755, acc.: 55.47%] [G loss: 0.305373]\n",
      "epoch:22 step:20931 [D loss: 0.237446, acc.: 59.38%] [G loss: 0.321523]\n",
      "epoch:22 step:20932 [D loss: 0.252188, acc.: 56.25%] [G loss: 0.275979]\n",
      "epoch:22 step:20933 [D loss: 0.222825, acc.: 63.28%] [G loss: 0.296352]\n",
      "epoch:22 step:20934 [D loss: 0.250046, acc.: 52.34%] [G loss: 0.309726]\n",
      "epoch:22 step:20935 [D loss: 0.251424, acc.: 56.25%] [G loss: 0.304105]\n",
      "epoch:22 step:20936 [D loss: 0.253244, acc.: 56.25%] [G loss: 0.287630]\n",
      "epoch:22 step:20937 [D loss: 0.238797, acc.: 59.38%] [G loss: 0.299710]\n",
      "epoch:22 step:20938 [D loss: 0.246698, acc.: 54.69%] [G loss: 0.279718]\n",
      "epoch:22 step:20939 [D loss: 0.227443, acc.: 62.50%] [G loss: 0.282713]\n",
      "epoch:22 step:20940 [D loss: 0.253454, acc.: 53.91%] [G loss: 0.279428]\n",
      "epoch:22 step:20941 [D loss: 0.224676, acc.: 60.94%] [G loss: 0.342445]\n",
      "epoch:22 step:20942 [D loss: 0.236365, acc.: 55.47%] [G loss: 0.322302]\n",
      "epoch:22 step:20943 [D loss: 0.226291, acc.: 62.50%] [G loss: 0.288802]\n",
      "epoch:22 step:20944 [D loss: 0.255981, acc.: 50.78%] [G loss: 0.295837]\n",
      "epoch:22 step:20945 [D loss: 0.236345, acc.: 60.16%] [G loss: 0.290876]\n",
      "epoch:22 step:20946 [D loss: 0.248157, acc.: 59.38%] [G loss: 0.267449]\n",
      "epoch:22 step:20947 [D loss: 0.236357, acc.: 57.03%] [G loss: 0.283465]\n",
      "epoch:22 step:20948 [D loss: 0.238301, acc.: 59.38%] [G loss: 0.310030]\n",
      "epoch:22 step:20949 [D loss: 0.231531, acc.: 67.97%] [G loss: 0.310419]\n",
      "epoch:22 step:20950 [D loss: 0.212885, acc.: 68.75%] [G loss: 0.315611]\n",
      "epoch:22 step:20951 [D loss: 0.235912, acc.: 58.59%] [G loss: 0.288721]\n",
      "epoch:22 step:20952 [D loss: 0.239512, acc.: 56.25%] [G loss: 0.277075]\n",
      "epoch:22 step:20953 [D loss: 0.231134, acc.: 64.06%] [G loss: 0.306673]\n",
      "epoch:22 step:20954 [D loss: 0.250813, acc.: 55.47%] [G loss: 0.296470]\n",
      "epoch:22 step:20955 [D loss: 0.235351, acc.: 57.81%] [G loss: 0.335706]\n",
      "epoch:22 step:20956 [D loss: 0.240155, acc.: 57.03%] [G loss: 0.295837]\n",
      "epoch:22 step:20957 [D loss: 0.251054, acc.: 55.47%] [G loss: 0.289846]\n",
      "epoch:22 step:20958 [D loss: 0.237070, acc.: 59.38%] [G loss: 0.288421]\n",
      "epoch:22 step:20959 [D loss: 0.231622, acc.: 64.06%] [G loss: 0.274370]\n",
      "epoch:22 step:20960 [D loss: 0.249760, acc.: 56.25%] [G loss: 0.301473]\n",
      "epoch:22 step:20961 [D loss: 0.232384, acc.: 60.94%] [G loss: 0.280793]\n",
      "epoch:22 step:20962 [D loss: 0.249568, acc.: 57.81%] [G loss: 0.292799]\n",
      "epoch:22 step:20963 [D loss: 0.244838, acc.: 55.47%] [G loss: 0.295580]\n",
      "epoch:22 step:20964 [D loss: 0.235279, acc.: 57.81%] [G loss: 0.289916]\n",
      "epoch:22 step:20965 [D loss: 0.223718, acc.: 63.28%] [G loss: 0.290567]\n",
      "epoch:22 step:20966 [D loss: 0.229684, acc.: 62.50%] [G loss: 0.306808]\n",
      "epoch:22 step:20967 [D loss: 0.230352, acc.: 61.72%] [G loss: 0.325653]\n",
      "epoch:22 step:20968 [D loss: 0.234776, acc.: 55.47%] [G loss: 0.317089]\n",
      "epoch:22 step:20969 [D loss: 0.237690, acc.: 58.59%] [G loss: 0.274148]\n",
      "epoch:22 step:20970 [D loss: 0.240385, acc.: 55.47%] [G loss: 0.319174]\n",
      "epoch:22 step:20971 [D loss: 0.248557, acc.: 51.56%] [G loss: 0.284395]\n",
      "epoch:22 step:20972 [D loss: 0.243653, acc.: 60.16%] [G loss: 0.308267]\n",
      "epoch:22 step:20973 [D loss: 0.235402, acc.: 57.81%] [G loss: 0.308538]\n",
      "epoch:22 step:20974 [D loss: 0.216624, acc.: 68.75%] [G loss: 0.296877]\n",
      "epoch:22 step:20975 [D loss: 0.225886, acc.: 67.19%] [G loss: 0.348131]\n",
      "epoch:22 step:20976 [D loss: 0.237351, acc.: 59.38%] [G loss: 0.302623]\n",
      "epoch:22 step:20977 [D loss: 0.238136, acc.: 57.03%] [G loss: 0.317704]\n",
      "epoch:22 step:20978 [D loss: 0.239311, acc.: 56.25%] [G loss: 0.292086]\n",
      "epoch:22 step:20979 [D loss: 0.245668, acc.: 57.81%] [G loss: 0.308532]\n",
      "epoch:22 step:20980 [D loss: 0.227924, acc.: 59.38%] [G loss: 0.313622]\n",
      "epoch:22 step:20981 [D loss: 0.259640, acc.: 54.69%] [G loss: 0.295076]\n",
      "epoch:22 step:20982 [D loss: 0.220974, acc.: 67.19%] [G loss: 0.343298]\n",
      "epoch:22 step:20983 [D loss: 0.242827, acc.: 57.03%] [G loss: 0.286198]\n",
      "epoch:22 step:20984 [D loss: 0.216938, acc.: 62.50%] [G loss: 0.330695]\n",
      "epoch:22 step:20985 [D loss: 0.246059, acc.: 54.69%] [G loss: 0.291792]\n",
      "epoch:22 step:20986 [D loss: 0.244967, acc.: 54.69%] [G loss: 0.299477]\n",
      "epoch:22 step:20987 [D loss: 0.221838, acc.: 60.16%] [G loss: 0.312825]\n",
      "epoch:22 step:20988 [D loss: 0.244048, acc.: 53.12%] [G loss: 0.320719]\n",
      "epoch:22 step:20989 [D loss: 0.245619, acc.: 60.94%] [G loss: 0.295474]\n",
      "epoch:22 step:20990 [D loss: 0.259245, acc.: 53.91%] [G loss: 0.300375]\n",
      "epoch:22 step:20991 [D loss: 0.240895, acc.: 57.81%] [G loss: 0.278131]\n",
      "epoch:22 step:20992 [D loss: 0.247571, acc.: 54.69%] [G loss: 0.278571]\n",
      "epoch:22 step:20993 [D loss: 0.219569, acc.: 63.28%] [G loss: 0.322574]\n",
      "epoch:22 step:20994 [D loss: 0.247245, acc.: 56.25%] [G loss: 0.301973]\n",
      "epoch:22 step:20995 [D loss: 0.237221, acc.: 57.03%] [G loss: 0.310892]\n",
      "epoch:22 step:20996 [D loss: 0.244819, acc.: 59.38%] [G loss: 0.286175]\n",
      "epoch:22 step:20997 [D loss: 0.230978, acc.: 60.94%] [G loss: 0.309020]\n",
      "epoch:22 step:20998 [D loss: 0.238838, acc.: 58.59%] [G loss: 0.300766]\n",
      "epoch:22 step:20999 [D loss: 0.243913, acc.: 53.12%] [G loss: 0.304844]\n",
      "epoch:22 step:21000 [D loss: 0.234813, acc.: 57.81%] [G loss: 0.306025]\n",
      "epoch:22 step:21001 [D loss: 0.224952, acc.: 62.50%] [G loss: 0.280785]\n",
      "epoch:22 step:21002 [D loss: 0.237211, acc.: 59.38%] [G loss: 0.295956]\n",
      "epoch:22 step:21003 [D loss: 0.230608, acc.: 60.16%] [G loss: 0.296590]\n",
      "epoch:22 step:21004 [D loss: 0.229130, acc.: 63.28%] [G loss: 0.320999]\n",
      "epoch:22 step:21005 [D loss: 0.245186, acc.: 57.03%] [G loss: 0.306102]\n",
      "epoch:22 step:21006 [D loss: 0.240345, acc.: 60.16%] [G loss: 0.306064]\n",
      "epoch:22 step:21007 [D loss: 0.237532, acc.: 57.03%] [G loss: 0.327729]\n",
      "epoch:22 step:21008 [D loss: 0.224948, acc.: 57.03%] [G loss: 0.292347]\n",
      "epoch:22 step:21009 [D loss: 0.227095, acc.: 62.50%] [G loss: 0.279659]\n",
      "epoch:22 step:21010 [D loss: 0.223782, acc.: 65.62%] [G loss: 0.317950]\n",
      "epoch:22 step:21011 [D loss: 0.238134, acc.: 57.03%] [G loss: 0.320078]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:22 step:21012 [D loss: 0.240448, acc.: 55.47%] [G loss: 0.291115]\n",
      "epoch:22 step:21013 [D loss: 0.229352, acc.: 63.28%] [G loss: 0.313019]\n",
      "epoch:22 step:21014 [D loss: 0.259331, acc.: 50.78%] [G loss: 0.267146]\n",
      "epoch:22 step:21015 [D loss: 0.239458, acc.: 54.69%] [G loss: 0.272154]\n",
      "epoch:22 step:21016 [D loss: 0.236958, acc.: 63.28%] [G loss: 0.297765]\n",
      "epoch:22 step:21017 [D loss: 0.226051, acc.: 60.16%] [G loss: 0.326546]\n",
      "epoch:22 step:21018 [D loss: 0.240366, acc.: 60.94%] [G loss: 0.297461]\n",
      "epoch:22 step:21019 [D loss: 0.245405, acc.: 53.91%] [G loss: 0.317240]\n",
      "epoch:22 step:21020 [D loss: 0.228228, acc.: 62.50%] [G loss: 0.288844]\n",
      "epoch:22 step:21021 [D loss: 0.231336, acc.: 67.19%] [G loss: 0.307752]\n",
      "epoch:22 step:21022 [D loss: 0.235127, acc.: 61.72%] [G loss: 0.291463]\n",
      "epoch:22 step:21023 [D loss: 0.246462, acc.: 53.91%] [G loss: 0.304429]\n",
      "epoch:22 step:21024 [D loss: 0.242170, acc.: 55.47%] [G loss: 0.303306]\n",
      "epoch:22 step:21025 [D loss: 0.240575, acc.: 57.81%] [G loss: 0.313383]\n",
      "epoch:22 step:21026 [D loss: 0.241341, acc.: 63.28%] [G loss: 0.296213]\n",
      "epoch:22 step:21027 [D loss: 0.235645, acc.: 64.06%] [G loss: 0.325468]\n",
      "epoch:22 step:21028 [D loss: 0.231763, acc.: 60.16%] [G loss: 0.289705]\n",
      "epoch:22 step:21029 [D loss: 0.235131, acc.: 63.28%] [G loss: 0.325623]\n",
      "epoch:22 step:21030 [D loss: 0.239162, acc.: 63.28%] [G loss: 0.297561]\n",
      "epoch:22 step:21031 [D loss: 0.225688, acc.: 63.28%] [G loss: 0.275869]\n",
      "epoch:22 step:21032 [D loss: 0.237031, acc.: 61.72%] [G loss: 0.318543]\n",
      "epoch:22 step:21033 [D loss: 0.237680, acc.: 60.16%] [G loss: 0.291721]\n",
      "epoch:22 step:21034 [D loss: 0.226136, acc.: 64.06%] [G loss: 0.305502]\n",
      "epoch:22 step:21035 [D loss: 0.219829, acc.: 66.41%] [G loss: 0.298294]\n",
      "epoch:22 step:21036 [D loss: 0.226252, acc.: 61.72%] [G loss: 0.275361]\n",
      "epoch:22 step:21037 [D loss: 0.259954, acc.: 54.69%] [G loss: 0.281994]\n",
      "epoch:22 step:21038 [D loss: 0.232444, acc.: 61.72%] [G loss: 0.272843]\n",
      "epoch:22 step:21039 [D loss: 0.243891, acc.: 58.59%] [G loss: 0.287058]\n",
      "epoch:22 step:21040 [D loss: 0.251613, acc.: 53.12%] [G loss: 0.318980]\n",
      "epoch:22 step:21041 [D loss: 0.255716, acc.: 53.12%] [G loss: 0.308864]\n",
      "epoch:22 step:21042 [D loss: 0.235148, acc.: 64.84%] [G loss: 0.278859]\n",
      "epoch:22 step:21043 [D loss: 0.243365, acc.: 54.69%] [G loss: 0.320787]\n",
      "epoch:22 step:21044 [D loss: 0.259551, acc.: 48.44%] [G loss: 0.307196]\n",
      "epoch:22 step:21045 [D loss: 0.232786, acc.: 65.62%] [G loss: 0.318172]\n",
      "epoch:22 step:21046 [D loss: 0.234654, acc.: 62.50%] [G loss: 0.305544]\n",
      "epoch:22 step:21047 [D loss: 0.248127, acc.: 57.81%] [G loss: 0.314714]\n",
      "epoch:22 step:21048 [D loss: 0.248284, acc.: 53.91%] [G loss: 0.304692]\n",
      "epoch:22 step:21049 [D loss: 0.223504, acc.: 63.28%] [G loss: 0.266544]\n",
      "epoch:22 step:21050 [D loss: 0.225576, acc.: 63.28%] [G loss: 0.317159]\n",
      "epoch:22 step:21051 [D loss: 0.252238, acc.: 53.12%] [G loss: 0.305437]\n",
      "epoch:22 step:21052 [D loss: 0.230097, acc.: 62.50%] [G loss: 0.305893]\n",
      "epoch:22 step:21053 [D loss: 0.226376, acc.: 64.84%] [G loss: 0.319379]\n",
      "epoch:22 step:21054 [D loss: 0.242419, acc.: 57.03%] [G loss: 0.275767]\n",
      "epoch:22 step:21055 [D loss: 0.252008, acc.: 53.91%] [G loss: 0.283689]\n",
      "epoch:22 step:21056 [D loss: 0.236214, acc.: 61.72%] [G loss: 0.314865]\n",
      "epoch:22 step:21057 [D loss: 0.233524, acc.: 62.50%] [G loss: 0.316173]\n",
      "epoch:22 step:21058 [D loss: 0.243811, acc.: 55.47%] [G loss: 0.297683]\n",
      "epoch:22 step:21059 [D loss: 0.239542, acc.: 61.72%] [G loss: 0.289604]\n",
      "epoch:22 step:21060 [D loss: 0.239419, acc.: 56.25%] [G loss: 0.314652]\n",
      "epoch:22 step:21061 [D loss: 0.234412, acc.: 57.03%] [G loss: 0.274900]\n",
      "epoch:22 step:21062 [D loss: 0.232711, acc.: 61.72%] [G loss: 0.316261]\n",
      "epoch:22 step:21063 [D loss: 0.225544, acc.: 64.06%] [G loss: 0.334875]\n",
      "epoch:22 step:21064 [D loss: 0.254081, acc.: 54.69%] [G loss: 0.309119]\n",
      "epoch:22 step:21065 [D loss: 0.245827, acc.: 57.03%] [G loss: 0.296118]\n",
      "epoch:22 step:21066 [D loss: 0.232479, acc.: 59.38%] [G loss: 0.296484]\n",
      "epoch:22 step:21067 [D loss: 0.224117, acc.: 62.50%] [G loss: 0.306272]\n",
      "epoch:22 step:21068 [D loss: 0.232741, acc.: 65.62%] [G loss: 0.276204]\n",
      "epoch:22 step:21069 [D loss: 0.231873, acc.: 60.94%] [G loss: 0.324245]\n",
      "epoch:22 step:21070 [D loss: 0.260330, acc.: 56.25%] [G loss: 0.296588]\n",
      "epoch:22 step:21071 [D loss: 0.240595, acc.: 60.94%] [G loss: 0.291903]\n",
      "epoch:22 step:21072 [D loss: 0.231846, acc.: 55.47%] [G loss: 0.274433]\n",
      "epoch:22 step:21073 [D loss: 0.222607, acc.: 60.94%] [G loss: 0.272448]\n",
      "epoch:22 step:21074 [D loss: 0.237097, acc.: 60.16%] [G loss: 0.291934]\n",
      "epoch:22 step:21075 [D loss: 0.251053, acc.: 53.91%] [G loss: 0.310865]\n",
      "epoch:22 step:21076 [D loss: 0.253490, acc.: 51.56%] [G loss: 0.286443]\n",
      "epoch:22 step:21077 [D loss: 0.237300, acc.: 56.25%] [G loss: 0.314111]\n",
      "epoch:22 step:21078 [D loss: 0.254068, acc.: 49.22%] [G loss: 0.294698]\n",
      "epoch:22 step:21079 [D loss: 0.252844, acc.: 50.78%] [G loss: 0.298456]\n",
      "epoch:22 step:21080 [D loss: 0.236134, acc.: 59.38%] [G loss: 0.307673]\n",
      "epoch:22 step:21081 [D loss: 0.222904, acc.: 64.84%] [G loss: 0.312108]\n",
      "epoch:22 step:21082 [D loss: 0.235865, acc.: 63.28%] [G loss: 0.298042]\n",
      "epoch:22 step:21083 [D loss: 0.247853, acc.: 53.91%] [G loss: 0.293017]\n",
      "epoch:22 step:21084 [D loss: 0.259896, acc.: 50.00%] [G loss: 0.311782]\n",
      "epoch:22 step:21085 [D loss: 0.237513, acc.: 60.94%] [G loss: 0.332710]\n",
      "epoch:22 step:21086 [D loss: 0.224566, acc.: 64.84%] [G loss: 0.292899]\n",
      "epoch:22 step:21087 [D loss: 0.238725, acc.: 59.38%] [G loss: 0.285264]\n",
      "epoch:22 step:21088 [D loss: 0.230537, acc.: 67.19%] [G loss: 0.303544]\n",
      "epoch:22 step:21089 [D loss: 0.257921, acc.: 50.00%] [G loss: 0.306137]\n",
      "epoch:22 step:21090 [D loss: 0.232972, acc.: 53.91%] [G loss: 0.297580]\n",
      "epoch:22 step:21091 [D loss: 0.242311, acc.: 57.03%] [G loss: 0.312713]\n",
      "epoch:22 step:21092 [D loss: 0.237140, acc.: 55.47%] [G loss: 0.282872]\n",
      "epoch:22 step:21093 [D loss: 0.243302, acc.: 53.91%] [G loss: 0.303547]\n",
      "epoch:22 step:21094 [D loss: 0.252168, acc.: 54.69%] [G loss: 0.307628]\n",
      "epoch:22 step:21095 [D loss: 0.243428, acc.: 54.69%] [G loss: 0.296010]\n",
      "epoch:22 step:21096 [D loss: 0.239545, acc.: 57.03%] [G loss: 0.319176]\n",
      "epoch:22 step:21097 [D loss: 0.263849, acc.: 55.47%] [G loss: 0.319522]\n",
      "epoch:22 step:21098 [D loss: 0.227779, acc.: 62.50%] [G loss: 0.317341]\n",
      "epoch:22 step:21099 [D loss: 0.246150, acc.: 55.47%] [G loss: 0.309014]\n",
      "epoch:22 step:21100 [D loss: 0.224206, acc.: 63.28%] [G loss: 0.283806]\n",
      "epoch:22 step:21101 [D loss: 0.236319, acc.: 61.72%] [G loss: 0.273591]\n",
      "epoch:22 step:21102 [D loss: 0.235033, acc.: 57.03%] [G loss: 0.297385]\n",
      "epoch:22 step:21103 [D loss: 0.241516, acc.: 61.72%] [G loss: 0.333512]\n",
      "epoch:22 step:21104 [D loss: 0.246771, acc.: 53.12%] [G loss: 0.317333]\n",
      "epoch:22 step:21105 [D loss: 0.232507, acc.: 60.94%] [G loss: 0.283664]\n",
      "epoch:22 step:21106 [D loss: 0.252922, acc.: 53.91%] [G loss: 0.285444]\n",
      "epoch:22 step:21107 [D loss: 0.230304, acc.: 58.59%] [G loss: 0.309824]\n",
      "epoch:22 step:21108 [D loss: 0.234588, acc.: 63.28%] [G loss: 0.301513]\n",
      "epoch:22 step:21109 [D loss: 0.248592, acc.: 56.25%] [G loss: 0.290997]\n",
      "epoch:22 step:21110 [D loss: 0.232823, acc.: 61.72%] [G loss: 0.297079]\n",
      "epoch:22 step:21111 [D loss: 0.244444, acc.: 59.38%] [G loss: 0.310656]\n",
      "epoch:22 step:21112 [D loss: 0.227719, acc.: 61.72%] [G loss: 0.322991]\n",
      "epoch:22 step:21113 [D loss: 0.238346, acc.: 59.38%] [G loss: 0.297395]\n",
      "epoch:22 step:21114 [D loss: 0.253889, acc.: 58.59%] [G loss: 0.280786]\n",
      "epoch:22 step:21115 [D loss: 0.239435, acc.: 59.38%] [G loss: 0.295194]\n",
      "epoch:22 step:21116 [D loss: 0.230962, acc.: 61.72%] [G loss: 0.305718]\n",
      "epoch:22 step:21117 [D loss: 0.229866, acc.: 61.72%] [G loss: 0.311447]\n",
      "epoch:22 step:21118 [D loss: 0.252085, acc.: 53.91%] [G loss: 0.316324]\n",
      "epoch:22 step:21119 [D loss: 0.246745, acc.: 53.91%] [G loss: 0.272030]\n",
      "epoch:22 step:21120 [D loss: 0.242440, acc.: 53.91%] [G loss: 0.285904]\n",
      "epoch:22 step:21121 [D loss: 0.233416, acc.: 60.16%] [G loss: 0.326935]\n",
      "epoch:22 step:21122 [D loss: 0.252691, acc.: 50.78%] [G loss: 0.302740]\n",
      "epoch:22 step:21123 [D loss: 0.238457, acc.: 59.38%] [G loss: 0.295189]\n",
      "epoch:22 step:21124 [D loss: 0.235853, acc.: 55.47%] [G loss: 0.307232]\n",
      "epoch:22 step:21125 [D loss: 0.224621, acc.: 64.84%] [G loss: 0.279706]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:22 step:21126 [D loss: 0.226708, acc.: 67.97%] [G loss: 0.284009]\n",
      "epoch:22 step:21127 [D loss: 0.245620, acc.: 56.25%] [G loss: 0.322019]\n",
      "epoch:22 step:21128 [D loss: 0.241001, acc.: 57.03%] [G loss: 0.294944]\n",
      "epoch:22 step:21129 [D loss: 0.255565, acc.: 55.47%] [G loss: 0.296531]\n",
      "epoch:22 step:21130 [D loss: 0.232533, acc.: 64.06%] [G loss: 0.320099]\n",
      "epoch:22 step:21131 [D loss: 0.247116, acc.: 52.34%] [G loss: 0.288637]\n",
      "epoch:22 step:21132 [D loss: 0.236818, acc.: 53.91%] [G loss: 0.300234]\n",
      "epoch:22 step:21133 [D loss: 0.236679, acc.: 60.16%] [G loss: 0.320444]\n",
      "epoch:22 step:21134 [D loss: 0.241427, acc.: 53.91%] [G loss: 0.286458]\n",
      "epoch:22 step:21135 [D loss: 0.230948, acc.: 61.72%] [G loss: 0.301449]\n",
      "epoch:22 step:21136 [D loss: 0.255316, acc.: 50.78%] [G loss: 0.337482]\n",
      "epoch:22 step:21137 [D loss: 0.238903, acc.: 59.38%] [G loss: 0.292350]\n",
      "epoch:22 step:21138 [D loss: 0.239635, acc.: 64.06%] [G loss: 0.323149]\n",
      "epoch:22 step:21139 [D loss: 0.243886, acc.: 56.25%] [G loss: 0.322968]\n",
      "epoch:22 step:21140 [D loss: 0.236765, acc.: 57.03%] [G loss: 0.322731]\n",
      "epoch:22 step:21141 [D loss: 0.234106, acc.: 59.38%] [G loss: 0.325765]\n",
      "epoch:22 step:21142 [D loss: 0.229970, acc.: 62.50%] [G loss: 0.318019]\n",
      "epoch:22 step:21143 [D loss: 0.239275, acc.: 61.72%] [G loss: 0.296169]\n",
      "epoch:22 step:21144 [D loss: 0.229750, acc.: 61.72%] [G loss: 0.299165]\n",
      "epoch:22 step:21145 [D loss: 0.229888, acc.: 60.94%] [G loss: 0.306345]\n",
      "epoch:22 step:21146 [D loss: 0.242850, acc.: 56.25%] [G loss: 0.284020]\n",
      "epoch:22 step:21147 [D loss: 0.251013, acc.: 53.12%] [G loss: 0.306866]\n",
      "epoch:22 step:21148 [D loss: 0.250809, acc.: 55.47%] [G loss: 0.306135]\n",
      "epoch:22 step:21149 [D loss: 0.228168, acc.: 59.38%] [G loss: 0.307488]\n",
      "epoch:22 step:21150 [D loss: 0.245510, acc.: 57.81%] [G loss: 0.295763]\n",
      "epoch:22 step:21151 [D loss: 0.248576, acc.: 53.91%] [G loss: 0.306399]\n",
      "epoch:22 step:21152 [D loss: 0.243351, acc.: 54.69%] [G loss: 0.323647]\n",
      "epoch:22 step:21153 [D loss: 0.223620, acc.: 64.06%] [G loss: 0.330550]\n",
      "epoch:22 step:21154 [D loss: 0.215816, acc.: 64.84%] [G loss: 0.318509]\n",
      "epoch:22 step:21155 [D loss: 0.241711, acc.: 63.28%] [G loss: 0.289300]\n",
      "epoch:22 step:21156 [D loss: 0.253639, acc.: 51.56%] [G loss: 0.296304]\n",
      "epoch:22 step:21157 [D loss: 0.233583, acc.: 60.94%] [G loss: 0.322749]\n",
      "epoch:22 step:21158 [D loss: 0.228349, acc.: 58.59%] [G loss: 0.314694]\n",
      "epoch:22 step:21159 [D loss: 0.242862, acc.: 53.12%] [G loss: 0.300787]\n",
      "epoch:22 step:21160 [D loss: 0.257381, acc.: 51.56%] [G loss: 0.276703]\n",
      "epoch:22 step:21161 [D loss: 0.244918, acc.: 53.91%] [G loss: 0.293270]\n",
      "epoch:22 step:21162 [D loss: 0.239310, acc.: 57.81%] [G loss: 0.276129]\n",
      "epoch:22 step:21163 [D loss: 0.240586, acc.: 57.81%] [G loss: 0.273345]\n",
      "epoch:22 step:21164 [D loss: 0.239033, acc.: 56.25%] [G loss: 0.314732]\n",
      "epoch:22 step:21165 [D loss: 0.242965, acc.: 59.38%] [G loss: 0.295365]\n",
      "epoch:22 step:21166 [D loss: 0.236083, acc.: 63.28%] [G loss: 0.283650]\n",
      "epoch:22 step:21167 [D loss: 0.246619, acc.: 57.03%] [G loss: 0.289227]\n",
      "epoch:22 step:21168 [D loss: 0.248320, acc.: 53.12%] [G loss: 0.323309]\n",
      "epoch:22 step:21169 [D loss: 0.218093, acc.: 67.19%] [G loss: 0.299463]\n",
      "epoch:22 step:21170 [D loss: 0.256562, acc.: 52.34%] [G loss: 0.291169]\n",
      "epoch:22 step:21171 [D loss: 0.228010, acc.: 64.06%] [G loss: 0.274739]\n",
      "epoch:22 step:21172 [D loss: 0.231424, acc.: 58.59%] [G loss: 0.287416]\n",
      "epoch:22 step:21173 [D loss: 0.253420, acc.: 52.34%] [G loss: 0.306652]\n",
      "epoch:22 step:21174 [D loss: 0.240288, acc.: 56.25%] [G loss: 0.308193]\n",
      "epoch:22 step:21175 [D loss: 0.252862, acc.: 50.78%] [G loss: 0.307323]\n",
      "epoch:22 step:21176 [D loss: 0.235060, acc.: 59.38%] [G loss: 0.314072]\n",
      "epoch:22 step:21177 [D loss: 0.248599, acc.: 56.25%] [G loss: 0.284487]\n",
      "epoch:22 step:21178 [D loss: 0.235679, acc.: 58.59%] [G loss: 0.314211]\n",
      "epoch:22 step:21179 [D loss: 0.246127, acc.: 63.28%] [G loss: 0.321573]\n",
      "epoch:22 step:21180 [D loss: 0.230872, acc.: 56.25%] [G loss: 0.338521]\n",
      "epoch:22 step:21181 [D loss: 0.238621, acc.: 60.16%] [G loss: 0.338385]\n",
      "epoch:22 step:21182 [D loss: 0.239664, acc.: 53.91%] [G loss: 0.307404]\n",
      "epoch:22 step:21183 [D loss: 0.251404, acc.: 54.69%] [G loss: 0.297097]\n",
      "epoch:22 step:21184 [D loss: 0.237579, acc.: 59.38%] [G loss: 0.306026]\n",
      "epoch:22 step:21185 [D loss: 0.227586, acc.: 64.06%] [G loss: 0.305447]\n",
      "epoch:22 step:21186 [D loss: 0.208157, acc.: 60.94%] [G loss: 0.341519]\n",
      "epoch:22 step:21187 [D loss: 0.267715, acc.: 50.00%] [G loss: 0.310059]\n",
      "epoch:22 step:21188 [D loss: 0.244295, acc.: 51.56%] [G loss: 0.308117]\n",
      "epoch:22 step:21189 [D loss: 0.247030, acc.: 56.25%] [G loss: 0.298917]\n",
      "epoch:22 step:21190 [D loss: 0.229311, acc.: 64.06%] [G loss: 0.265438]\n",
      "epoch:22 step:21191 [D loss: 0.241103, acc.: 54.69%] [G loss: 0.291653]\n",
      "epoch:22 step:21192 [D loss: 0.228474, acc.: 62.50%] [G loss: 0.310541]\n",
      "epoch:22 step:21193 [D loss: 0.235918, acc.: 60.16%] [G loss: 0.308028]\n",
      "epoch:22 step:21194 [D loss: 0.252592, acc.: 48.44%] [G loss: 0.315869]\n",
      "epoch:22 step:21195 [D loss: 0.228034, acc.: 60.94%] [G loss: 0.316321]\n",
      "epoch:22 step:21196 [D loss: 0.230053, acc.: 60.94%] [G loss: 0.298318]\n",
      "epoch:22 step:21197 [D loss: 0.227075, acc.: 62.50%] [G loss: 0.290837]\n",
      "epoch:22 step:21198 [D loss: 0.250869, acc.: 56.25%] [G loss: 0.294607]\n",
      "epoch:22 step:21199 [D loss: 0.238112, acc.: 58.59%] [G loss: 0.288854]\n",
      "epoch:22 step:21200 [D loss: 0.245342, acc.: 54.69%] [G loss: 0.333345]\n",
      "epoch:22 step:21201 [D loss: 0.229700, acc.: 60.16%] [G loss: 0.296814]\n",
      "epoch:22 step:21202 [D loss: 0.250348, acc.: 55.47%] [G loss: 0.303281]\n",
      "epoch:22 step:21203 [D loss: 0.235905, acc.: 60.16%] [G loss: 0.303209]\n",
      "epoch:22 step:21204 [D loss: 0.251150, acc.: 57.81%] [G loss: 0.292548]\n",
      "epoch:22 step:21205 [D loss: 0.230379, acc.: 60.94%] [G loss: 0.322987]\n",
      "epoch:22 step:21206 [D loss: 0.243016, acc.: 61.72%] [G loss: 0.278032]\n",
      "epoch:22 step:21207 [D loss: 0.235262, acc.: 61.72%] [G loss: 0.294460]\n",
      "epoch:22 step:21208 [D loss: 0.238651, acc.: 61.72%] [G loss: 0.287475]\n",
      "epoch:22 step:21209 [D loss: 0.230676, acc.: 62.50%] [G loss: 0.300849]\n",
      "epoch:22 step:21210 [D loss: 0.239498, acc.: 62.50%] [G loss: 0.300134]\n",
      "epoch:22 step:21211 [D loss: 0.249980, acc.: 53.91%] [G loss: 0.308867]\n",
      "epoch:22 step:21212 [D loss: 0.223387, acc.: 62.50%] [G loss: 0.358705]\n",
      "epoch:22 step:21213 [D loss: 0.220465, acc.: 64.84%] [G loss: 0.287602]\n",
      "epoch:22 step:21214 [D loss: 0.242444, acc.: 57.81%] [G loss: 0.334795]\n",
      "epoch:22 step:21215 [D loss: 0.248954, acc.: 57.03%] [G loss: 0.300816]\n",
      "epoch:22 step:21216 [D loss: 0.237434, acc.: 59.38%] [G loss: 0.277001]\n",
      "epoch:22 step:21217 [D loss: 0.251753, acc.: 54.69%] [G loss: 0.312477]\n",
      "epoch:22 step:21218 [D loss: 0.234372, acc.: 60.94%] [G loss: 0.331457]\n",
      "epoch:22 step:21219 [D loss: 0.254235, acc.: 50.78%] [G loss: 0.300945]\n",
      "epoch:22 step:21220 [D loss: 0.239591, acc.: 60.16%] [G loss: 0.334214]\n",
      "epoch:22 step:21221 [D loss: 0.242614, acc.: 57.81%] [G loss: 0.306928]\n",
      "epoch:22 step:21222 [D loss: 0.233777, acc.: 58.59%] [G loss: 0.287665]\n",
      "epoch:22 step:21223 [D loss: 0.228062, acc.: 64.84%] [G loss: 0.320848]\n",
      "epoch:22 step:21224 [D loss: 0.234587, acc.: 60.16%] [G loss: 0.317248]\n",
      "epoch:22 step:21225 [D loss: 0.220821, acc.: 67.19%] [G loss: 0.296451]\n",
      "epoch:22 step:21226 [D loss: 0.217813, acc.: 68.75%] [G loss: 0.272770]\n",
      "epoch:22 step:21227 [D loss: 0.232851, acc.: 60.94%] [G loss: 0.313158]\n",
      "epoch:22 step:21228 [D loss: 0.221808, acc.: 64.06%] [G loss: 0.300400]\n",
      "epoch:22 step:21229 [D loss: 0.229735, acc.: 65.62%] [G loss: 0.321857]\n",
      "epoch:22 step:21230 [D loss: 0.225262, acc.: 64.06%] [G loss: 0.291479]\n",
      "epoch:22 step:21231 [D loss: 0.221300, acc.: 64.06%] [G loss: 0.312126]\n",
      "epoch:22 step:21232 [D loss: 0.232980, acc.: 58.59%] [G loss: 0.308683]\n",
      "epoch:22 step:21233 [D loss: 0.242642, acc.: 52.34%] [G loss: 0.315293]\n",
      "epoch:22 step:21234 [D loss: 0.244108, acc.: 58.59%] [G loss: 0.277170]\n",
      "epoch:22 step:21235 [D loss: 0.246357, acc.: 54.69%] [G loss: 0.277829]\n",
      "epoch:22 step:21236 [D loss: 0.242038, acc.: 57.03%] [G loss: 0.286745]\n",
      "epoch:22 step:21237 [D loss: 0.236144, acc.: 64.06%] [G loss: 0.303220]\n",
      "epoch:22 step:21238 [D loss: 0.244868, acc.: 58.59%] [G loss: 0.303050]\n",
      "epoch:22 step:21239 [D loss: 0.240304, acc.: 60.94%] [G loss: 0.295183]\n",
      "epoch:22 step:21240 [D loss: 0.228485, acc.: 62.50%] [G loss: 0.297015]\n",
      "epoch:22 step:21241 [D loss: 0.235536, acc.: 60.16%] [G loss: 0.311238]\n",
      "epoch:22 step:21242 [D loss: 0.253596, acc.: 50.78%] [G loss: 0.308393]\n",
      "epoch:22 step:21243 [D loss: 0.231484, acc.: 59.38%] [G loss: 0.287337]\n",
      "epoch:22 step:21244 [D loss: 0.251032, acc.: 57.03%] [G loss: 0.290210]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:22 step:21245 [D loss: 0.239570, acc.: 53.91%] [G loss: 0.276562]\n",
      "epoch:22 step:21246 [D loss: 0.232045, acc.: 60.16%] [G loss: 0.329233]\n",
      "epoch:22 step:21247 [D loss: 0.229480, acc.: 65.62%] [G loss: 0.304994]\n",
      "epoch:22 step:21248 [D loss: 0.206789, acc.: 67.19%] [G loss: 0.336013]\n",
      "epoch:22 step:21249 [D loss: 0.246085, acc.: 57.03%] [G loss: 0.300507]\n",
      "epoch:22 step:21250 [D loss: 0.236015, acc.: 58.59%] [G loss: 0.295674]\n",
      "epoch:22 step:21251 [D loss: 0.225361, acc.: 61.72%] [G loss: 0.306729]\n",
      "epoch:22 step:21252 [D loss: 0.246034, acc.: 58.59%] [G loss: 0.328208]\n",
      "epoch:22 step:21253 [D loss: 0.242284, acc.: 64.06%] [G loss: 0.314182]\n",
      "epoch:22 step:21254 [D loss: 0.244797, acc.: 59.38%] [G loss: 0.328433]\n",
      "epoch:22 step:21255 [D loss: 0.222373, acc.: 61.72%] [G loss: 0.309523]\n",
      "epoch:22 step:21256 [D loss: 0.223613, acc.: 60.94%] [G loss: 0.286400]\n",
      "epoch:22 step:21257 [D loss: 0.256899, acc.: 48.44%] [G loss: 0.293271]\n",
      "epoch:22 step:21258 [D loss: 0.235609, acc.: 59.38%] [G loss: 0.305123]\n",
      "epoch:22 step:21259 [D loss: 0.230478, acc.: 57.81%] [G loss: 0.308162]\n",
      "epoch:22 step:21260 [D loss: 0.241948, acc.: 55.47%] [G loss: 0.294977]\n",
      "epoch:22 step:21261 [D loss: 0.236528, acc.: 59.38%] [G loss: 0.316152]\n",
      "epoch:22 step:21262 [D loss: 0.231863, acc.: 64.84%] [G loss: 0.290258]\n",
      "epoch:22 step:21263 [D loss: 0.223816, acc.: 63.28%] [G loss: 0.304099]\n",
      "epoch:22 step:21264 [D loss: 0.232686, acc.: 60.94%] [G loss: 0.325561]\n",
      "epoch:22 step:21265 [D loss: 0.221224, acc.: 64.84%] [G loss: 0.323151]\n",
      "epoch:22 step:21266 [D loss: 0.235016, acc.: 61.72%] [G loss: 0.284474]\n",
      "epoch:22 step:21267 [D loss: 0.222065, acc.: 64.06%] [G loss: 0.306570]\n",
      "epoch:22 step:21268 [D loss: 0.240361, acc.: 51.56%] [G loss: 0.315117]\n",
      "epoch:22 step:21269 [D loss: 0.257799, acc.: 53.91%] [G loss: 0.338471]\n",
      "epoch:22 step:21270 [D loss: 0.222145, acc.: 64.06%] [G loss: 0.307156]\n",
      "epoch:22 step:21271 [D loss: 0.245529, acc.: 50.00%] [G loss: 0.298610]\n",
      "epoch:22 step:21272 [D loss: 0.256633, acc.: 47.66%] [G loss: 0.283331]\n",
      "epoch:22 step:21273 [D loss: 0.236444, acc.: 60.94%] [G loss: 0.311085]\n",
      "epoch:22 step:21274 [D loss: 0.221838, acc.: 60.94%] [G loss: 0.334271]\n",
      "epoch:22 step:21275 [D loss: 0.225616, acc.: 61.72%] [G loss: 0.289018]\n",
      "epoch:22 step:21276 [D loss: 0.246593, acc.: 57.03%] [G loss: 0.289877]\n",
      "epoch:22 step:21277 [D loss: 0.242124, acc.: 58.59%] [G loss: 0.286777]\n",
      "epoch:22 step:21278 [D loss: 0.245497, acc.: 54.69%] [G loss: 0.312138]\n",
      "epoch:22 step:21279 [D loss: 0.256501, acc.: 47.66%] [G loss: 0.329842]\n",
      "epoch:22 step:21280 [D loss: 0.241891, acc.: 55.47%] [G loss: 0.286119]\n",
      "epoch:22 step:21281 [D loss: 0.235614, acc.: 64.06%] [G loss: 0.302444]\n",
      "epoch:22 step:21282 [D loss: 0.235717, acc.: 57.03%] [G loss: 0.261067]\n",
      "epoch:22 step:21283 [D loss: 0.232086, acc.: 63.28%] [G loss: 0.298376]\n",
      "epoch:22 step:21284 [D loss: 0.239084, acc.: 59.38%] [G loss: 0.308270]\n",
      "epoch:22 step:21285 [D loss: 0.256844, acc.: 48.44%] [G loss: 0.300370]\n",
      "epoch:22 step:21286 [D loss: 0.231673, acc.: 62.50%] [G loss: 0.305495]\n",
      "epoch:22 step:21287 [D loss: 0.248413, acc.: 55.47%] [G loss: 0.267244]\n",
      "epoch:22 step:21288 [D loss: 0.243031, acc.: 57.03%] [G loss: 0.282004]\n",
      "epoch:22 step:21289 [D loss: 0.241642, acc.: 52.34%] [G loss: 0.316145]\n",
      "epoch:22 step:21290 [D loss: 0.233306, acc.: 58.59%] [G loss: 0.303236]\n",
      "epoch:22 step:21291 [D loss: 0.226159, acc.: 61.72%] [G loss: 0.293071]\n",
      "epoch:22 step:21292 [D loss: 0.222619, acc.: 61.72%] [G loss: 0.285101]\n",
      "epoch:22 step:21293 [D loss: 0.251340, acc.: 53.91%] [G loss: 0.282451]\n",
      "epoch:22 step:21294 [D loss: 0.229458, acc.: 60.94%] [G loss: 0.311929]\n",
      "epoch:22 step:21295 [D loss: 0.252454, acc.: 56.25%] [G loss: 0.272836]\n",
      "epoch:22 step:21296 [D loss: 0.239360, acc.: 57.03%] [G loss: 0.311346]\n",
      "epoch:22 step:21297 [D loss: 0.239569, acc.: 60.16%] [G loss: 0.318952]\n",
      "epoch:22 step:21298 [D loss: 0.253131, acc.: 53.12%] [G loss: 0.311238]\n",
      "epoch:22 step:21299 [D loss: 0.247927, acc.: 55.47%] [G loss: 0.280544]\n",
      "epoch:22 step:21300 [D loss: 0.242227, acc.: 53.91%] [G loss: 0.308747]\n",
      "epoch:22 step:21301 [D loss: 0.250812, acc.: 53.12%] [G loss: 0.291571]\n",
      "epoch:22 step:21302 [D loss: 0.246329, acc.: 55.47%] [G loss: 0.292021]\n",
      "epoch:22 step:21303 [D loss: 0.246516, acc.: 53.12%] [G loss: 0.307941]\n",
      "epoch:22 step:21304 [D loss: 0.224378, acc.: 61.72%] [G loss: 0.319980]\n",
      "epoch:22 step:21305 [D loss: 0.238815, acc.: 58.59%] [G loss: 0.310280]\n",
      "epoch:22 step:21306 [D loss: 0.238756, acc.: 57.81%] [G loss: 0.316810]\n",
      "epoch:22 step:21307 [D loss: 0.244505, acc.: 51.56%] [G loss: 0.309181]\n",
      "epoch:22 step:21308 [D loss: 0.245569, acc.: 54.69%] [G loss: 0.289892]\n",
      "epoch:22 step:21309 [D loss: 0.259058, acc.: 50.00%] [G loss: 0.299671]\n",
      "epoch:22 step:21310 [D loss: 0.235419, acc.: 57.03%] [G loss: 0.279968]\n",
      "epoch:22 step:21311 [D loss: 0.246922, acc.: 54.69%] [G loss: 0.307216]\n",
      "epoch:22 step:21312 [D loss: 0.252781, acc.: 53.12%] [G loss: 0.297392]\n",
      "epoch:22 step:21313 [D loss: 0.240368, acc.: 58.59%] [G loss: 0.300356]\n",
      "epoch:22 step:21314 [D loss: 0.230814, acc.: 57.03%] [G loss: 0.321321]\n",
      "epoch:22 step:21315 [D loss: 0.235193, acc.: 62.50%] [G loss: 0.307959]\n",
      "epoch:22 step:21316 [D loss: 0.222347, acc.: 60.94%] [G loss: 0.296905]\n",
      "epoch:22 step:21317 [D loss: 0.250235, acc.: 50.00%] [G loss: 0.272437]\n",
      "epoch:22 step:21318 [D loss: 0.219221, acc.: 67.19%] [G loss: 0.314150]\n",
      "epoch:22 step:21319 [D loss: 0.256166, acc.: 50.00%] [G loss: 0.307337]\n",
      "epoch:22 step:21320 [D loss: 0.248036, acc.: 54.69%] [G loss: 0.289753]\n",
      "epoch:22 step:21321 [D loss: 0.228060, acc.: 64.84%] [G loss: 0.322623]\n",
      "epoch:22 step:21322 [D loss: 0.226505, acc.: 64.06%] [G loss: 0.302237]\n",
      "epoch:22 step:21323 [D loss: 0.254559, acc.: 53.12%] [G loss: 0.279752]\n",
      "epoch:22 step:21324 [D loss: 0.231654, acc.: 68.75%] [G loss: 0.284739]\n",
      "epoch:22 step:21325 [D loss: 0.235858, acc.: 60.94%] [G loss: 0.297021]\n",
      "epoch:22 step:21326 [D loss: 0.227215, acc.: 59.38%] [G loss: 0.357983]\n",
      "epoch:22 step:21327 [D loss: 0.233969, acc.: 60.16%] [G loss: 0.307235]\n",
      "epoch:22 step:21328 [D loss: 0.241756, acc.: 59.38%] [G loss: 0.308977]\n",
      "epoch:22 step:21329 [D loss: 0.249923, acc.: 52.34%] [G loss: 0.282113]\n",
      "epoch:22 step:21330 [D loss: 0.237325, acc.: 60.16%] [G loss: 0.317447]\n",
      "epoch:22 step:21331 [D loss: 0.244995, acc.: 55.47%] [G loss: 0.301423]\n",
      "epoch:22 step:21332 [D loss: 0.241207, acc.: 57.03%] [G loss: 0.277995]\n",
      "epoch:22 step:21333 [D loss: 0.249362, acc.: 58.59%] [G loss: 0.320425]\n",
      "epoch:22 step:21334 [D loss: 0.246253, acc.: 60.16%] [G loss: 0.284885]\n",
      "epoch:22 step:21335 [D loss: 0.236633, acc.: 56.25%] [G loss: 0.334421]\n",
      "epoch:22 step:21336 [D loss: 0.235989, acc.: 59.38%] [G loss: 0.305413]\n",
      "epoch:22 step:21337 [D loss: 0.231474, acc.: 62.50%] [G loss: 0.302051]\n",
      "epoch:22 step:21338 [D loss: 0.247897, acc.: 53.12%] [G loss: 0.314678]\n",
      "epoch:22 step:21339 [D loss: 0.246769, acc.: 58.59%] [G loss: 0.319286]\n",
      "epoch:22 step:21340 [D loss: 0.244629, acc.: 57.03%] [G loss: 0.295676]\n",
      "epoch:22 step:21341 [D loss: 0.222498, acc.: 64.84%] [G loss: 0.312294]\n",
      "epoch:22 step:21342 [D loss: 0.254389, acc.: 48.44%] [G loss: 0.289561]\n",
      "epoch:22 step:21343 [D loss: 0.248649, acc.: 58.59%] [G loss: 0.296440]\n",
      "epoch:22 step:21344 [D loss: 0.242126, acc.: 57.81%] [G loss: 0.309659]\n",
      "epoch:22 step:21345 [D loss: 0.247469, acc.: 56.25%] [G loss: 0.313037]\n",
      "epoch:22 step:21346 [D loss: 0.245435, acc.: 54.69%] [G loss: 0.323063]\n",
      "epoch:22 step:21347 [D loss: 0.259485, acc.: 52.34%] [G loss: 0.292464]\n",
      "epoch:22 step:21348 [D loss: 0.238030, acc.: 64.06%] [G loss: 0.295472]\n",
      "epoch:22 step:21349 [D loss: 0.242770, acc.: 49.22%] [G loss: 0.319277]\n",
      "epoch:22 step:21350 [D loss: 0.243346, acc.: 54.69%] [G loss: 0.300060]\n",
      "epoch:22 step:21351 [D loss: 0.232597, acc.: 63.28%] [G loss: 0.293008]\n",
      "epoch:22 step:21352 [D loss: 0.263903, acc.: 50.00%] [G loss: 0.280716]\n",
      "epoch:22 step:21353 [D loss: 0.236873, acc.: 57.03%] [G loss: 0.302897]\n",
      "epoch:22 step:21354 [D loss: 0.236901, acc.: 57.81%] [G loss: 0.302600]\n",
      "epoch:22 step:21355 [D loss: 0.241390, acc.: 53.91%] [G loss: 0.305149]\n",
      "epoch:22 step:21356 [D loss: 0.245361, acc.: 58.59%] [G loss: 0.289584]\n",
      "epoch:22 step:21357 [D loss: 0.252785, acc.: 57.03%] [G loss: 0.310131]\n",
      "epoch:22 step:21358 [D loss: 0.250473, acc.: 55.47%] [G loss: 0.278556]\n",
      "epoch:22 step:21359 [D loss: 0.220559, acc.: 69.53%] [G loss: 0.307515]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:22 step:21360 [D loss: 0.246191, acc.: 57.03%] [G loss: 0.289612]\n",
      "epoch:22 step:21361 [D loss: 0.237573, acc.: 59.38%] [G loss: 0.298121]\n",
      "epoch:22 step:21362 [D loss: 0.258332, acc.: 50.78%] [G loss: 0.286465]\n",
      "epoch:22 step:21363 [D loss: 0.251215, acc.: 56.25%] [G loss: 0.305361]\n",
      "epoch:22 step:21364 [D loss: 0.232934, acc.: 60.94%] [G loss: 0.301472]\n",
      "epoch:22 step:21365 [D loss: 0.246493, acc.: 51.56%] [G loss: 0.281715]\n",
      "epoch:22 step:21366 [D loss: 0.245556, acc.: 58.59%] [G loss: 0.254522]\n",
      "epoch:22 step:21367 [D loss: 0.237289, acc.: 60.16%] [G loss: 0.333373]\n",
      "epoch:22 step:21368 [D loss: 0.235627, acc.: 60.94%] [G loss: 0.330809]\n",
      "epoch:22 step:21369 [D loss: 0.260222, acc.: 50.78%] [G loss: 0.299170]\n",
      "epoch:22 step:21370 [D loss: 0.247940, acc.: 61.72%] [G loss: 0.292156]\n",
      "epoch:22 step:21371 [D loss: 0.244040, acc.: 56.25%] [G loss: 0.293934]\n",
      "epoch:22 step:21372 [D loss: 0.237490, acc.: 60.16%] [G loss: 0.283926]\n",
      "epoch:22 step:21373 [D loss: 0.254003, acc.: 51.56%] [G loss: 0.299393]\n",
      "epoch:22 step:21374 [D loss: 0.248174, acc.: 54.69%] [G loss: 0.299310]\n",
      "epoch:22 step:21375 [D loss: 0.249359, acc.: 48.44%] [G loss: 0.293525]\n",
      "epoch:22 step:21376 [D loss: 0.227504, acc.: 64.84%] [G loss: 0.304581]\n",
      "epoch:22 step:21377 [D loss: 0.242563, acc.: 59.38%] [G loss: 0.289169]\n",
      "epoch:22 step:21378 [D loss: 0.247159, acc.: 56.25%] [G loss: 0.300038]\n",
      "epoch:22 step:21379 [D loss: 0.246269, acc.: 58.59%] [G loss: 0.286793]\n",
      "epoch:22 step:21380 [D loss: 0.244142, acc.: 57.81%] [G loss: 0.310289]\n",
      "epoch:22 step:21381 [D loss: 0.251421, acc.: 53.91%] [G loss: 0.323594]\n",
      "epoch:22 step:21382 [D loss: 0.236415, acc.: 57.03%] [G loss: 0.290622]\n",
      "epoch:22 step:21383 [D loss: 0.242213, acc.: 53.91%] [G loss: 0.303624]\n",
      "epoch:22 step:21384 [D loss: 0.214373, acc.: 67.19%] [G loss: 0.321176]\n",
      "epoch:22 step:21385 [D loss: 0.246461, acc.: 52.34%] [G loss: 0.302207]\n",
      "epoch:22 step:21386 [D loss: 0.250999, acc.: 50.00%] [G loss: 0.303553]\n",
      "epoch:22 step:21387 [D loss: 0.242823, acc.: 54.69%] [G loss: 0.317332]\n",
      "epoch:22 step:21388 [D loss: 0.240172, acc.: 53.12%] [G loss: 0.297390]\n",
      "epoch:22 step:21389 [D loss: 0.244474, acc.: 53.12%] [G loss: 0.280246]\n",
      "epoch:22 step:21390 [D loss: 0.226997, acc.: 61.72%] [G loss: 0.312929]\n",
      "epoch:22 step:21391 [D loss: 0.245267, acc.: 55.47%] [G loss: 0.262242]\n",
      "epoch:22 step:21392 [D loss: 0.245572, acc.: 60.94%] [G loss: 0.290960]\n",
      "epoch:22 step:21393 [D loss: 0.225947, acc.: 59.38%] [G loss: 0.292697]\n",
      "epoch:22 step:21394 [D loss: 0.248651, acc.: 53.12%] [G loss: 0.312804]\n",
      "epoch:22 step:21395 [D loss: 0.237824, acc.: 60.16%] [G loss: 0.292669]\n",
      "epoch:22 step:21396 [D loss: 0.230301, acc.: 58.59%] [G loss: 0.301610]\n",
      "epoch:22 step:21397 [D loss: 0.225000, acc.: 63.28%] [G loss: 0.314737]\n",
      "epoch:22 step:21398 [D loss: 0.233950, acc.: 61.72%] [G loss: 0.300499]\n",
      "epoch:22 step:21399 [D loss: 0.233782, acc.: 57.03%] [G loss: 0.324509]\n",
      "epoch:22 step:21400 [D loss: 0.234198, acc.: 59.38%] [G loss: 0.335721]\n",
      "epoch:22 step:21401 [D loss: 0.222567, acc.: 64.06%] [G loss: 0.317086]\n",
      "epoch:22 step:21402 [D loss: 0.242889, acc.: 54.69%] [G loss: 0.323881]\n",
      "epoch:22 step:21403 [D loss: 0.249304, acc.: 54.69%] [G loss: 0.321790]\n",
      "epoch:22 step:21404 [D loss: 0.235931, acc.: 56.25%] [G loss: 0.302010]\n",
      "epoch:22 step:21405 [D loss: 0.236878, acc.: 64.84%] [G loss: 0.315716]\n",
      "epoch:22 step:21406 [D loss: 0.239071, acc.: 56.25%] [G loss: 0.284138]\n",
      "epoch:22 step:21407 [D loss: 0.228065, acc.: 64.84%] [G loss: 0.306019]\n",
      "epoch:22 step:21408 [D loss: 0.228795, acc.: 65.62%] [G loss: 0.331545]\n",
      "epoch:22 step:21409 [D loss: 0.225280, acc.: 61.72%] [G loss: 0.293141]\n",
      "epoch:22 step:21410 [D loss: 0.236032, acc.: 57.03%] [G loss: 0.277367]\n",
      "epoch:22 step:21411 [D loss: 0.224653, acc.: 62.50%] [G loss: 0.327056]\n",
      "epoch:22 step:21412 [D loss: 0.256901, acc.: 52.34%] [G loss: 0.306895]\n",
      "epoch:22 step:21413 [D loss: 0.255117, acc.: 50.78%] [G loss: 0.268407]\n",
      "epoch:22 step:21414 [D loss: 0.241434, acc.: 55.47%] [G loss: 0.302076]\n",
      "epoch:22 step:21415 [D loss: 0.237500, acc.: 60.94%] [G loss: 0.282487]\n",
      "epoch:22 step:21416 [D loss: 0.241141, acc.: 54.69%] [G loss: 0.344242]\n",
      "epoch:22 step:21417 [D loss: 0.232588, acc.: 60.16%] [G loss: 0.334820]\n",
      "epoch:22 step:21418 [D loss: 0.242330, acc.: 55.47%] [G loss: 0.305448]\n",
      "epoch:22 step:21419 [D loss: 0.229967, acc.: 60.94%] [G loss: 0.303038]\n",
      "epoch:22 step:21420 [D loss: 0.226837, acc.: 60.94%] [G loss: 0.304649]\n",
      "epoch:22 step:21421 [D loss: 0.237330, acc.: 52.34%] [G loss: 0.310493]\n",
      "epoch:22 step:21422 [D loss: 0.242698, acc.: 59.38%] [G loss: 0.309935]\n",
      "epoch:22 step:21423 [D loss: 0.230481, acc.: 63.28%] [G loss: 0.279890]\n",
      "epoch:22 step:21424 [D loss: 0.264220, acc.: 48.44%] [G loss: 0.270631]\n",
      "epoch:22 step:21425 [D loss: 0.259941, acc.: 47.66%] [G loss: 0.290005]\n",
      "epoch:22 step:21426 [D loss: 0.237264, acc.: 59.38%] [G loss: 0.316712]\n",
      "epoch:22 step:21427 [D loss: 0.228240, acc.: 64.84%] [G loss: 0.285046]\n",
      "epoch:22 step:21428 [D loss: 0.236201, acc.: 57.03%] [G loss: 0.286948]\n",
      "epoch:22 step:21429 [D loss: 0.234643, acc.: 54.69%] [G loss: 0.298464]\n",
      "epoch:22 step:21430 [D loss: 0.226917, acc.: 63.28%] [G loss: 0.311983]\n",
      "epoch:22 step:21431 [D loss: 0.237931, acc.: 55.47%] [G loss: 0.320000]\n",
      "epoch:22 step:21432 [D loss: 0.237155, acc.: 61.72%] [G loss: 0.266243]\n",
      "epoch:22 step:21433 [D loss: 0.240654, acc.: 57.03%] [G loss: 0.308708]\n",
      "epoch:22 step:21434 [D loss: 0.239868, acc.: 60.16%] [G loss: 0.306842]\n",
      "epoch:22 step:21435 [D loss: 0.240320, acc.: 60.16%] [G loss: 0.296846]\n",
      "epoch:22 step:21436 [D loss: 0.237536, acc.: 57.81%] [G loss: 0.329384]\n",
      "epoch:22 step:21437 [D loss: 0.238841, acc.: 61.72%] [G loss: 0.308297]\n",
      "epoch:22 step:21438 [D loss: 0.238220, acc.: 57.81%] [G loss: 0.300235]\n",
      "epoch:22 step:21439 [D loss: 0.233189, acc.: 63.28%] [G loss: 0.287552]\n",
      "epoch:22 step:21440 [D loss: 0.236843, acc.: 57.03%] [G loss: 0.321498]\n",
      "epoch:22 step:21441 [D loss: 0.240304, acc.: 57.03%] [G loss: 0.308999]\n",
      "epoch:22 step:21442 [D loss: 0.245448, acc.: 53.12%] [G loss: 0.310673]\n",
      "epoch:22 step:21443 [D loss: 0.236707, acc.: 57.03%] [G loss: 0.304685]\n",
      "epoch:22 step:21444 [D loss: 0.244132, acc.: 57.03%] [G loss: 0.295043]\n",
      "epoch:22 step:21445 [D loss: 0.252476, acc.: 57.03%] [G loss: 0.314156]\n",
      "epoch:22 step:21446 [D loss: 0.235474, acc.: 64.06%] [G loss: 0.282205]\n",
      "epoch:22 step:21447 [D loss: 0.230946, acc.: 57.03%] [G loss: 0.331397]\n",
      "epoch:22 step:21448 [D loss: 0.250972, acc.: 55.47%] [G loss: 0.278582]\n",
      "epoch:22 step:21449 [D loss: 0.237835, acc.: 60.16%] [G loss: 0.316224]\n",
      "epoch:22 step:21450 [D loss: 0.233362, acc.: 60.94%] [G loss: 0.319283]\n",
      "epoch:22 step:21451 [D loss: 0.238970, acc.: 57.81%] [G loss: 0.279497]\n",
      "epoch:22 step:21452 [D loss: 0.232660, acc.: 64.06%] [G loss: 0.267010]\n",
      "epoch:22 step:21453 [D loss: 0.255973, acc.: 52.34%] [G loss: 0.285624]\n",
      "epoch:22 step:21454 [D loss: 0.221360, acc.: 64.06%] [G loss: 0.330523]\n",
      "epoch:22 step:21455 [D loss: 0.225775, acc.: 67.97%] [G loss: 0.262527]\n",
      "epoch:22 step:21456 [D loss: 0.254184, acc.: 53.91%] [G loss: 0.316072]\n",
      "epoch:22 step:21457 [D loss: 0.247856, acc.: 56.25%] [G loss: 0.284164]\n",
      "epoch:22 step:21458 [D loss: 0.249593, acc.: 56.25%] [G loss: 0.315426]\n",
      "epoch:22 step:21459 [D loss: 0.244743, acc.: 56.25%] [G loss: 0.301776]\n",
      "epoch:22 step:21460 [D loss: 0.253632, acc.: 50.00%] [G loss: 0.290304]\n",
      "epoch:22 step:21461 [D loss: 0.238003, acc.: 57.81%] [G loss: 0.309391]\n",
      "epoch:22 step:21462 [D loss: 0.227483, acc.: 63.28%] [G loss: 0.283763]\n",
      "epoch:22 step:21463 [D loss: 0.239916, acc.: 59.38%] [G loss: 0.324001]\n",
      "epoch:22 step:21464 [D loss: 0.224232, acc.: 64.06%] [G loss: 0.307408]\n",
      "epoch:22 step:21465 [D loss: 0.254181, acc.: 48.44%] [G loss: 0.303479]\n",
      "epoch:22 step:21466 [D loss: 0.238219, acc.: 57.81%] [G loss: 0.309031]\n",
      "epoch:22 step:21467 [D loss: 0.240264, acc.: 62.50%] [G loss: 0.286280]\n",
      "epoch:22 step:21468 [D loss: 0.230081, acc.: 64.06%] [G loss: 0.307321]\n",
      "epoch:22 step:21469 [D loss: 0.243844, acc.: 57.03%] [G loss: 0.304313]\n",
      "epoch:22 step:21470 [D loss: 0.227802, acc.: 63.28%] [G loss: 0.300369]\n",
      "epoch:22 step:21471 [D loss: 0.247664, acc.: 53.91%] [G loss: 0.297967]\n",
      "epoch:22 step:21472 [D loss: 0.238497, acc.: 60.16%] [G loss: 0.302924]\n",
      "epoch:22 step:21473 [D loss: 0.246209, acc.: 55.47%] [G loss: 0.255596]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:22 step:21474 [D loss: 0.237597, acc.: 63.28%] [G loss: 0.292946]\n",
      "epoch:22 step:21475 [D loss: 0.232325, acc.: 59.38%] [G loss: 0.324002]\n",
      "epoch:22 step:21476 [D loss: 0.242465, acc.: 57.03%] [G loss: 0.310109]\n",
      "epoch:22 step:21477 [D loss: 0.244282, acc.: 54.69%] [G loss: 0.320285]\n",
      "epoch:22 step:21478 [D loss: 0.231636, acc.: 62.50%] [G loss: 0.329623]\n",
      "epoch:22 step:21479 [D loss: 0.234273, acc.: 61.72%] [G loss: 0.274228]\n",
      "epoch:22 step:21480 [D loss: 0.255218, acc.: 50.78%] [G loss: 0.280271]\n",
      "epoch:22 step:21481 [D loss: 0.251488, acc.: 55.47%] [G loss: 0.287232]\n",
      "epoch:22 step:21482 [D loss: 0.229669, acc.: 61.72%] [G loss: 0.300000]\n",
      "epoch:22 step:21483 [D loss: 0.227622, acc.: 64.06%] [G loss: 0.288604]\n",
      "epoch:22 step:21484 [D loss: 0.226015, acc.: 60.94%] [G loss: 0.296458]\n",
      "epoch:22 step:21485 [D loss: 0.224799, acc.: 64.06%] [G loss: 0.313841]\n",
      "epoch:22 step:21486 [D loss: 0.240011, acc.: 55.47%] [G loss: 0.302070]\n",
      "epoch:22 step:21487 [D loss: 0.228489, acc.: 60.16%] [G loss: 0.294820]\n",
      "epoch:22 step:21488 [D loss: 0.220410, acc.: 64.84%] [G loss: 0.338852]\n",
      "epoch:22 step:21489 [D loss: 0.235482, acc.: 61.72%] [G loss: 0.283386]\n",
      "epoch:22 step:21490 [D loss: 0.250746, acc.: 51.56%] [G loss: 0.286682]\n",
      "epoch:22 step:21491 [D loss: 0.231488, acc.: 58.59%] [G loss: 0.340375]\n",
      "epoch:22 step:21492 [D loss: 0.251689, acc.: 53.91%] [G loss: 0.278113]\n",
      "epoch:22 step:21493 [D loss: 0.251194, acc.: 53.91%] [G loss: 0.324062]\n",
      "epoch:22 step:21494 [D loss: 0.227215, acc.: 58.59%] [G loss: 0.313979]\n",
      "epoch:22 step:21495 [D loss: 0.253965, acc.: 49.22%] [G loss: 0.304793]\n",
      "epoch:22 step:21496 [D loss: 0.250988, acc.: 50.78%] [G loss: 0.304555]\n",
      "epoch:22 step:21497 [D loss: 0.235373, acc.: 63.28%] [G loss: 0.324308]\n",
      "epoch:22 step:21498 [D loss: 0.226322, acc.: 60.16%] [G loss: 0.300667]\n",
      "epoch:22 step:21499 [D loss: 0.240757, acc.: 56.25%] [G loss: 0.310170]\n",
      "epoch:22 step:21500 [D loss: 0.237809, acc.: 56.25%] [G loss: 0.314009]\n",
      "epoch:22 step:21501 [D loss: 0.235722, acc.: 60.94%] [G loss: 0.300385]\n",
      "epoch:22 step:21502 [D loss: 0.241878, acc.: 60.94%] [G loss: 0.322842]\n",
      "epoch:22 step:21503 [D loss: 0.249400, acc.: 53.91%] [G loss: 0.305383]\n",
      "epoch:22 step:21504 [D loss: 0.252380, acc.: 51.56%] [G loss: 0.326644]\n",
      "epoch:22 step:21505 [D loss: 0.270955, acc.: 50.00%] [G loss: 0.263694]\n",
      "epoch:22 step:21506 [D loss: 0.247218, acc.: 53.12%] [G loss: 0.304605]\n",
      "epoch:22 step:21507 [D loss: 0.237688, acc.: 59.38%] [G loss: 0.301150]\n",
      "epoch:22 step:21508 [D loss: 0.249451, acc.: 53.12%] [G loss: 0.302713]\n",
      "epoch:22 step:21509 [D loss: 0.227759, acc.: 69.53%] [G loss: 0.298334]\n",
      "epoch:22 step:21510 [D loss: 0.234411, acc.: 56.25%] [G loss: 0.340183]\n",
      "epoch:22 step:21511 [D loss: 0.243692, acc.: 55.47%] [G loss: 0.315419]\n",
      "epoch:22 step:21512 [D loss: 0.222737, acc.: 64.06%] [G loss: 0.293736]\n",
      "epoch:22 step:21513 [D loss: 0.257841, acc.: 54.69%] [G loss: 0.287063]\n",
      "epoch:22 step:21514 [D loss: 0.235494, acc.: 59.38%] [G loss: 0.290554]\n",
      "epoch:22 step:21515 [D loss: 0.255158, acc.: 58.59%] [G loss: 0.278321]\n",
      "epoch:22 step:21516 [D loss: 0.243365, acc.: 56.25%] [G loss: 0.291792]\n",
      "epoch:22 step:21517 [D loss: 0.235736, acc.: 60.94%] [G loss: 0.320171]\n",
      "epoch:22 step:21518 [D loss: 0.233751, acc.: 60.94%] [G loss: 0.283654]\n",
      "epoch:22 step:21519 [D loss: 0.224223, acc.: 60.94%] [G loss: 0.318988]\n",
      "epoch:22 step:21520 [D loss: 0.229546, acc.: 59.38%] [G loss: 0.288271]\n",
      "epoch:22 step:21521 [D loss: 0.237199, acc.: 55.47%] [G loss: 0.307868]\n",
      "epoch:22 step:21522 [D loss: 0.268059, acc.: 49.22%] [G loss: 0.293640]\n",
      "epoch:22 step:21523 [D loss: 0.241204, acc.: 60.94%] [G loss: 0.296542]\n",
      "epoch:22 step:21524 [D loss: 0.238085, acc.: 62.50%] [G loss: 0.322362]\n",
      "epoch:22 step:21525 [D loss: 0.233021, acc.: 62.50%] [G loss: 0.291975]\n",
      "epoch:22 step:21526 [D loss: 0.229330, acc.: 58.59%] [G loss: 0.307081]\n",
      "epoch:22 step:21527 [D loss: 0.251357, acc.: 50.78%] [G loss: 0.264362]\n",
      "epoch:22 step:21528 [D loss: 0.223352, acc.: 63.28%] [G loss: 0.325723]\n",
      "epoch:22 step:21529 [D loss: 0.250245, acc.: 50.00%] [G loss: 0.277039]\n",
      "epoch:22 step:21530 [D loss: 0.235580, acc.: 59.38%] [G loss: 0.318982]\n",
      "epoch:22 step:21531 [D loss: 0.248215, acc.: 53.91%] [G loss: 0.298524]\n",
      "epoch:22 step:21532 [D loss: 0.239403, acc.: 63.28%] [G loss: 0.292970]\n",
      "epoch:22 step:21533 [D loss: 0.221955, acc.: 59.38%] [G loss: 0.329368]\n",
      "epoch:22 step:21534 [D loss: 0.246897, acc.: 55.47%] [G loss: 0.290122]\n",
      "epoch:22 step:21535 [D loss: 0.229602, acc.: 64.06%] [G loss: 0.319242]\n",
      "epoch:22 step:21536 [D loss: 0.238593, acc.: 60.94%] [G loss: 0.317473]\n",
      "epoch:22 step:21537 [D loss: 0.250138, acc.: 54.69%] [G loss: 0.317781]\n",
      "epoch:22 step:21538 [D loss: 0.236075, acc.: 56.25%] [G loss: 0.305910]\n",
      "epoch:22 step:21539 [D loss: 0.238412, acc.: 61.72%] [G loss: 0.263901]\n",
      "epoch:22 step:21540 [D loss: 0.237844, acc.: 61.72%] [G loss: 0.327552]\n",
      "epoch:22 step:21541 [D loss: 0.239783, acc.: 63.28%] [G loss: 0.299630]\n",
      "epoch:22 step:21542 [D loss: 0.235742, acc.: 60.94%] [G loss: 0.277397]\n",
      "epoch:22 step:21543 [D loss: 0.236521, acc.: 59.38%] [G loss: 0.276843]\n",
      "epoch:22 step:21544 [D loss: 0.232778, acc.: 63.28%] [G loss: 0.293928]\n",
      "epoch:22 step:21545 [D loss: 0.251864, acc.: 53.91%] [G loss: 0.303063]\n",
      "epoch:22 step:21546 [D loss: 0.240715, acc.: 59.38%] [G loss: 0.295812]\n",
      "epoch:22 step:21547 [D loss: 0.225736, acc.: 58.59%] [G loss: 0.306349]\n",
      "epoch:22 step:21548 [D loss: 0.235646, acc.: 60.94%] [G loss: 0.291851]\n",
      "epoch:22 step:21549 [D loss: 0.230011, acc.: 65.62%] [G loss: 0.311678]\n",
      "epoch:22 step:21550 [D loss: 0.239212, acc.: 58.59%] [G loss: 0.282798]\n",
      "epoch:22 step:21551 [D loss: 0.244640, acc.: 56.25%] [G loss: 0.292419]\n",
      "epoch:23 step:21552 [D loss: 0.240811, acc.: 56.25%] [G loss: 0.295864]\n",
      "epoch:23 step:21553 [D loss: 0.246301, acc.: 55.47%] [G loss: 0.278927]\n",
      "epoch:23 step:21554 [D loss: 0.237407, acc.: 63.28%] [G loss: 0.300654]\n",
      "epoch:23 step:21555 [D loss: 0.249102, acc.: 56.25%] [G loss: 0.289322]\n",
      "epoch:23 step:21556 [D loss: 0.246865, acc.: 56.25%] [G loss: 0.274045]\n",
      "epoch:23 step:21557 [D loss: 0.250200, acc.: 56.25%] [G loss: 0.317352]\n",
      "epoch:23 step:21558 [D loss: 0.244778, acc.: 53.91%] [G loss: 0.306451]\n",
      "epoch:23 step:21559 [D loss: 0.225849, acc.: 64.06%] [G loss: 0.295924]\n",
      "epoch:23 step:21560 [D loss: 0.243803, acc.: 53.91%] [G loss: 0.273937]\n",
      "epoch:23 step:21561 [D loss: 0.247125, acc.: 54.69%] [G loss: 0.276171]\n",
      "epoch:23 step:21562 [D loss: 0.237952, acc.: 60.16%] [G loss: 0.293242]\n",
      "epoch:23 step:21563 [D loss: 0.241543, acc.: 57.81%] [G loss: 0.305800]\n",
      "epoch:23 step:21564 [D loss: 0.239843, acc.: 59.38%] [G loss: 0.306637]\n",
      "epoch:23 step:21565 [D loss: 0.233802, acc.: 64.84%] [G loss: 0.305477]\n",
      "epoch:23 step:21566 [D loss: 0.227995, acc.: 60.16%] [G loss: 0.283685]\n",
      "epoch:23 step:21567 [D loss: 0.236973, acc.: 54.69%] [G loss: 0.313599]\n",
      "epoch:23 step:21568 [D loss: 0.239111, acc.: 57.03%] [G loss: 0.316190]\n",
      "epoch:23 step:21569 [D loss: 0.232769, acc.: 57.03%] [G loss: 0.295928]\n",
      "epoch:23 step:21570 [D loss: 0.227668, acc.: 65.62%] [G loss: 0.327925]\n",
      "epoch:23 step:21571 [D loss: 0.240483, acc.: 55.47%] [G loss: 0.331109]\n",
      "epoch:23 step:21572 [D loss: 0.235298, acc.: 57.81%] [G loss: 0.317721]\n",
      "epoch:23 step:21573 [D loss: 0.228530, acc.: 64.06%] [G loss: 0.328350]\n",
      "epoch:23 step:21574 [D loss: 0.231469, acc.: 59.38%] [G loss: 0.308588]\n",
      "epoch:23 step:21575 [D loss: 0.215037, acc.: 64.84%] [G loss: 0.329751]\n",
      "epoch:23 step:21576 [D loss: 0.230074, acc.: 64.84%] [G loss: 0.303494]\n",
      "epoch:23 step:21577 [D loss: 0.230090, acc.: 60.94%] [G loss: 0.325279]\n",
      "epoch:23 step:21578 [D loss: 0.232590, acc.: 61.72%] [G loss: 0.285855]\n",
      "epoch:23 step:21579 [D loss: 0.238053, acc.: 62.50%] [G loss: 0.277077]\n",
      "epoch:23 step:21580 [D loss: 0.246242, acc.: 53.91%] [G loss: 0.302269]\n",
      "epoch:23 step:21581 [D loss: 0.237783, acc.: 64.06%] [G loss: 0.326672]\n",
      "epoch:23 step:21582 [D loss: 0.237019, acc.: 60.16%] [G loss: 0.311246]\n",
      "epoch:23 step:21583 [D loss: 0.224449, acc.: 64.06%] [G loss: 0.306506]\n",
      "epoch:23 step:21584 [D loss: 0.248515, acc.: 59.38%] [G loss: 0.326308]\n",
      "epoch:23 step:21585 [D loss: 0.240910, acc.: 55.47%] [G loss: 0.340990]\n",
      "epoch:23 step:21586 [D loss: 0.226180, acc.: 64.06%] [G loss: 0.298929]\n",
      "epoch:23 step:21587 [D loss: 0.242714, acc.: 57.81%] [G loss: 0.324458]\n",
      "epoch:23 step:21588 [D loss: 0.255689, acc.: 53.91%] [G loss: 0.331143]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:23 step:21589 [D loss: 0.245483, acc.: 56.25%] [G loss: 0.317623]\n",
      "epoch:23 step:21590 [D loss: 0.251529, acc.: 53.12%] [G loss: 0.336886]\n",
      "epoch:23 step:21591 [D loss: 0.245220, acc.: 56.25%] [G loss: 0.294314]\n",
      "epoch:23 step:21592 [D loss: 0.234331, acc.: 53.91%] [G loss: 0.332719]\n",
      "epoch:23 step:21593 [D loss: 0.243997, acc.: 53.91%] [G loss: 0.332399]\n",
      "epoch:23 step:21594 [D loss: 0.233596, acc.: 61.72%] [G loss: 0.315173]\n",
      "epoch:23 step:21595 [D loss: 0.239866, acc.: 57.81%] [G loss: 0.318109]\n",
      "epoch:23 step:21596 [D loss: 0.236385, acc.: 56.25%] [G loss: 0.288864]\n",
      "epoch:23 step:21597 [D loss: 0.257455, acc.: 46.09%] [G loss: 0.323028]\n",
      "epoch:23 step:21598 [D loss: 0.240371, acc.: 53.91%] [G loss: 0.317490]\n",
      "epoch:23 step:21599 [D loss: 0.250609, acc.: 56.25%] [G loss: 0.293313]\n",
      "epoch:23 step:21600 [D loss: 0.229563, acc.: 63.28%] [G loss: 0.319247]\n",
      "epoch:23 step:21601 [D loss: 0.231253, acc.: 61.72%] [G loss: 0.315205]\n",
      "epoch:23 step:21602 [D loss: 0.237058, acc.: 61.72%] [G loss: 0.307444]\n",
      "epoch:23 step:21603 [D loss: 0.242132, acc.: 56.25%] [G loss: 0.285590]\n",
      "epoch:23 step:21604 [D loss: 0.237011, acc.: 57.81%] [G loss: 0.301235]\n",
      "epoch:23 step:21605 [D loss: 0.220019, acc.: 67.19%] [G loss: 0.331693]\n",
      "epoch:23 step:21606 [D loss: 0.222936, acc.: 66.41%] [G loss: 0.320137]\n",
      "epoch:23 step:21607 [D loss: 0.228024, acc.: 63.28%] [G loss: 0.311367]\n",
      "epoch:23 step:21608 [D loss: 0.257100, acc.: 50.78%] [G loss: 0.330247]\n",
      "epoch:23 step:21609 [D loss: 0.233633, acc.: 58.59%] [G loss: 0.301953]\n",
      "epoch:23 step:21610 [D loss: 0.228379, acc.: 68.75%] [G loss: 0.291200]\n",
      "epoch:23 step:21611 [D loss: 0.241007, acc.: 59.38%] [G loss: 0.321076]\n",
      "epoch:23 step:21612 [D loss: 0.235631, acc.: 56.25%] [G loss: 0.319997]\n",
      "epoch:23 step:21613 [D loss: 0.249059, acc.: 56.25%] [G loss: 0.293590]\n",
      "epoch:23 step:21614 [D loss: 0.231342, acc.: 59.38%] [G loss: 0.332589]\n",
      "epoch:23 step:21615 [D loss: 0.244314, acc.: 60.16%] [G loss: 0.287794]\n",
      "epoch:23 step:21616 [D loss: 0.229304, acc.: 63.28%] [G loss: 0.283005]\n",
      "epoch:23 step:21617 [D loss: 0.261943, acc.: 51.56%] [G loss: 0.292143]\n",
      "epoch:23 step:21618 [D loss: 0.253344, acc.: 58.59%] [G loss: 0.316748]\n",
      "epoch:23 step:21619 [D loss: 0.234692, acc.: 60.94%] [G loss: 0.280081]\n",
      "epoch:23 step:21620 [D loss: 0.229992, acc.: 62.50%] [G loss: 0.323022]\n",
      "epoch:23 step:21621 [D loss: 0.230080, acc.: 60.16%] [G loss: 0.303536]\n",
      "epoch:23 step:21622 [D loss: 0.240113, acc.: 63.28%] [G loss: 0.285119]\n",
      "epoch:23 step:21623 [D loss: 0.229276, acc.: 63.28%] [G loss: 0.284873]\n",
      "epoch:23 step:21624 [D loss: 0.232825, acc.: 58.59%] [G loss: 0.315418]\n",
      "epoch:23 step:21625 [D loss: 0.233975, acc.: 57.81%] [G loss: 0.336650]\n",
      "epoch:23 step:21626 [D loss: 0.236533, acc.: 60.16%] [G loss: 0.314595]\n",
      "epoch:23 step:21627 [D loss: 0.237636, acc.: 58.59%] [G loss: 0.331776]\n",
      "epoch:23 step:21628 [D loss: 0.252907, acc.: 51.56%] [G loss: 0.312130]\n",
      "epoch:23 step:21629 [D loss: 0.250715, acc.: 54.69%] [G loss: 0.318377]\n",
      "epoch:23 step:21630 [D loss: 0.223450, acc.: 67.19%] [G loss: 0.293148]\n",
      "epoch:23 step:21631 [D loss: 0.232253, acc.: 56.25%] [G loss: 0.319462]\n",
      "epoch:23 step:21632 [D loss: 0.219249, acc.: 64.06%] [G loss: 0.290143]\n",
      "epoch:23 step:21633 [D loss: 0.253920, acc.: 48.44%] [G loss: 0.281372]\n",
      "epoch:23 step:21634 [D loss: 0.254569, acc.: 53.91%] [G loss: 0.289926]\n",
      "epoch:23 step:21635 [D loss: 0.246115, acc.: 59.38%] [G loss: 0.268926]\n",
      "epoch:23 step:21636 [D loss: 0.243404, acc.: 53.91%] [G loss: 0.271524]\n",
      "epoch:23 step:21637 [D loss: 0.243738, acc.: 55.47%] [G loss: 0.320574]\n",
      "epoch:23 step:21638 [D loss: 0.236818, acc.: 59.38%] [G loss: 0.306658]\n",
      "epoch:23 step:21639 [D loss: 0.245609, acc.: 50.78%] [G loss: 0.261367]\n",
      "epoch:23 step:21640 [D loss: 0.243799, acc.: 57.03%] [G loss: 0.306395]\n",
      "epoch:23 step:21641 [D loss: 0.243768, acc.: 51.56%] [G loss: 0.316335]\n",
      "epoch:23 step:21642 [D loss: 0.255641, acc.: 44.53%] [G loss: 0.298444]\n",
      "epoch:23 step:21643 [D loss: 0.222968, acc.: 65.62%] [G loss: 0.292710]\n",
      "epoch:23 step:21644 [D loss: 0.235662, acc.: 60.94%] [G loss: 0.314302]\n",
      "epoch:23 step:21645 [D loss: 0.245176, acc.: 56.25%] [G loss: 0.332701]\n",
      "epoch:23 step:21646 [D loss: 0.257663, acc.: 56.25%] [G loss: 0.292614]\n",
      "epoch:23 step:21647 [D loss: 0.243679, acc.: 55.47%] [G loss: 0.343031]\n",
      "epoch:23 step:21648 [D loss: 0.240650, acc.: 58.59%] [G loss: 0.290040]\n",
      "epoch:23 step:21649 [D loss: 0.230486, acc.: 58.59%] [G loss: 0.306403]\n",
      "epoch:23 step:21650 [D loss: 0.242138, acc.: 53.91%] [G loss: 0.293537]\n",
      "epoch:23 step:21651 [D loss: 0.232328, acc.: 63.28%] [G loss: 0.292429]\n",
      "epoch:23 step:21652 [D loss: 0.245785, acc.: 57.81%] [G loss: 0.309881]\n",
      "epoch:23 step:21653 [D loss: 0.247286, acc.: 60.94%] [G loss: 0.332432]\n",
      "epoch:23 step:21654 [D loss: 0.232143, acc.: 59.38%] [G loss: 0.276542]\n",
      "epoch:23 step:21655 [D loss: 0.249473, acc.: 58.59%] [G loss: 0.295852]\n",
      "epoch:23 step:21656 [D loss: 0.236151, acc.: 58.59%] [G loss: 0.334568]\n",
      "epoch:23 step:21657 [D loss: 0.231958, acc.: 66.41%] [G loss: 0.306387]\n",
      "epoch:23 step:21658 [D loss: 0.236766, acc.: 61.72%] [G loss: 0.302876]\n",
      "epoch:23 step:21659 [D loss: 0.241532, acc.: 57.03%] [G loss: 0.310873]\n",
      "epoch:23 step:21660 [D loss: 0.222236, acc.: 64.06%] [G loss: 0.316134]\n",
      "epoch:23 step:21661 [D loss: 0.251574, acc.: 54.69%] [G loss: 0.310354]\n",
      "epoch:23 step:21662 [D loss: 0.239035, acc.: 55.47%] [G loss: 0.293667]\n",
      "epoch:23 step:21663 [D loss: 0.248932, acc.: 51.56%] [G loss: 0.285361]\n",
      "epoch:23 step:21664 [D loss: 0.235172, acc.: 57.81%] [G loss: 0.278042]\n",
      "epoch:23 step:21665 [D loss: 0.240018, acc.: 60.16%] [G loss: 0.288366]\n",
      "epoch:23 step:21666 [D loss: 0.249048, acc.: 55.47%] [G loss: 0.282677]\n",
      "epoch:23 step:21667 [D loss: 0.259203, acc.: 56.25%] [G loss: 0.290466]\n",
      "epoch:23 step:21668 [D loss: 0.248415, acc.: 53.91%] [G loss: 0.270950]\n",
      "epoch:23 step:21669 [D loss: 0.244858, acc.: 57.03%] [G loss: 0.291179]\n",
      "epoch:23 step:21670 [D loss: 0.233639, acc.: 62.50%] [G loss: 0.301348]\n",
      "epoch:23 step:21671 [D loss: 0.248238, acc.: 51.56%] [G loss: 0.286869]\n",
      "epoch:23 step:21672 [D loss: 0.221594, acc.: 62.50%] [G loss: 0.300050]\n",
      "epoch:23 step:21673 [D loss: 0.247636, acc.: 56.25%] [G loss: 0.299813]\n",
      "epoch:23 step:21674 [D loss: 0.252356, acc.: 50.78%] [G loss: 0.285141]\n",
      "epoch:23 step:21675 [D loss: 0.238059, acc.: 60.94%] [G loss: 0.336040]\n",
      "epoch:23 step:21676 [D loss: 0.249384, acc.: 58.59%] [G loss: 0.295309]\n",
      "epoch:23 step:21677 [D loss: 0.239457, acc.: 57.03%] [G loss: 0.309844]\n",
      "epoch:23 step:21678 [D loss: 0.236807, acc.: 60.94%] [G loss: 0.297329]\n",
      "epoch:23 step:21679 [D loss: 0.228193, acc.: 64.06%] [G loss: 0.339138]\n",
      "epoch:23 step:21680 [D loss: 0.241646, acc.: 59.38%] [G loss: 0.309728]\n",
      "epoch:23 step:21681 [D loss: 0.219936, acc.: 67.19%] [G loss: 0.295697]\n",
      "epoch:23 step:21682 [D loss: 0.233948, acc.: 61.72%] [G loss: 0.323707]\n",
      "epoch:23 step:21683 [D loss: 0.238859, acc.: 63.28%] [G loss: 0.299777]\n",
      "epoch:23 step:21684 [D loss: 0.236450, acc.: 60.94%] [G loss: 0.331049]\n",
      "epoch:23 step:21685 [D loss: 0.251131, acc.: 56.25%] [G loss: 0.290422]\n",
      "epoch:23 step:21686 [D loss: 0.228290, acc.: 64.06%] [G loss: 0.304961]\n",
      "epoch:23 step:21687 [D loss: 0.253762, acc.: 52.34%] [G loss: 0.331236]\n",
      "epoch:23 step:21688 [D loss: 0.236932, acc.: 60.16%] [G loss: 0.300670]\n",
      "epoch:23 step:21689 [D loss: 0.246161, acc.: 57.03%] [G loss: 0.312010]\n",
      "epoch:23 step:21690 [D loss: 0.237622, acc.: 60.16%] [G loss: 0.321359]\n",
      "epoch:23 step:21691 [D loss: 0.252511, acc.: 45.31%] [G loss: 0.304423]\n",
      "epoch:23 step:21692 [D loss: 0.253741, acc.: 49.22%] [G loss: 0.293072]\n",
      "epoch:23 step:21693 [D loss: 0.234984, acc.: 59.38%] [G loss: 0.285369]\n",
      "epoch:23 step:21694 [D loss: 0.247800, acc.: 57.81%] [G loss: 0.302724]\n",
      "epoch:23 step:21695 [D loss: 0.263528, acc.: 49.22%] [G loss: 0.269010]\n",
      "epoch:23 step:21696 [D loss: 0.245417, acc.: 56.25%] [G loss: 0.301209]\n",
      "epoch:23 step:21697 [D loss: 0.239435, acc.: 60.94%] [G loss: 0.281531]\n",
      "epoch:23 step:21698 [D loss: 0.230757, acc.: 65.62%] [G loss: 0.293127]\n",
      "epoch:23 step:21699 [D loss: 0.226938, acc.: 64.84%] [G loss: 0.278237]\n",
      "epoch:23 step:21700 [D loss: 0.247045, acc.: 59.38%] [G loss: 0.290418]\n",
      "epoch:23 step:21701 [D loss: 0.242912, acc.: 56.25%] [G loss: 0.282824]\n",
      "epoch:23 step:21702 [D loss: 0.243782, acc.: 57.81%] [G loss: 0.277349]\n",
      "epoch:23 step:21703 [D loss: 0.224906, acc.: 62.50%] [G loss: 0.314177]\n",
      "epoch:23 step:21704 [D loss: 0.230566, acc.: 60.94%] [G loss: 0.288253]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:23 step:21705 [D loss: 0.248343, acc.: 53.91%] [G loss: 0.287203]\n",
      "epoch:23 step:21706 [D loss: 0.236575, acc.: 60.16%] [G loss: 0.303860]\n",
      "epoch:23 step:21707 [D loss: 0.234560, acc.: 60.94%] [G loss: 0.293009]\n",
      "epoch:23 step:21708 [D loss: 0.237762, acc.: 59.38%] [G loss: 0.266506]\n",
      "epoch:23 step:21709 [D loss: 0.225140, acc.: 63.28%] [G loss: 0.318664]\n",
      "epoch:23 step:21710 [D loss: 0.226369, acc.: 64.06%] [G loss: 0.316394]\n",
      "epoch:23 step:21711 [D loss: 0.221753, acc.: 61.72%] [G loss: 0.291035]\n",
      "epoch:23 step:21712 [D loss: 0.253631, acc.: 52.34%] [G loss: 0.288046]\n",
      "epoch:23 step:21713 [D loss: 0.259437, acc.: 50.00%] [G loss: 0.301472]\n",
      "epoch:23 step:21714 [D loss: 0.252077, acc.: 55.47%] [G loss: 0.307975]\n",
      "epoch:23 step:21715 [D loss: 0.214445, acc.: 68.75%] [G loss: 0.307142]\n",
      "epoch:23 step:21716 [D loss: 0.239064, acc.: 55.47%] [G loss: 0.315259]\n",
      "epoch:23 step:21717 [D loss: 0.257022, acc.: 55.47%] [G loss: 0.299658]\n",
      "epoch:23 step:21718 [D loss: 0.242227, acc.: 57.03%] [G loss: 0.274205]\n",
      "epoch:23 step:21719 [D loss: 0.248275, acc.: 56.25%] [G loss: 0.308014]\n",
      "epoch:23 step:21720 [D loss: 0.243053, acc.: 57.81%] [G loss: 0.318016]\n",
      "epoch:23 step:21721 [D loss: 0.240311, acc.: 61.72%] [G loss: 0.304649]\n",
      "epoch:23 step:21722 [D loss: 0.233055, acc.: 58.59%] [G loss: 0.303855]\n",
      "epoch:23 step:21723 [D loss: 0.232060, acc.: 57.81%] [G loss: 0.289890]\n",
      "epoch:23 step:21724 [D loss: 0.247437, acc.: 50.00%] [G loss: 0.317357]\n",
      "epoch:23 step:21725 [D loss: 0.256485, acc.: 53.12%] [G loss: 0.307063]\n",
      "epoch:23 step:21726 [D loss: 0.237950, acc.: 57.03%] [G loss: 0.302330]\n",
      "epoch:23 step:21727 [D loss: 0.252399, acc.: 54.69%] [G loss: 0.301760]\n",
      "epoch:23 step:21728 [D loss: 0.223047, acc.: 67.19%] [G loss: 0.326707]\n",
      "epoch:23 step:21729 [D loss: 0.241165, acc.: 58.59%] [G loss: 0.294137]\n",
      "epoch:23 step:21730 [D loss: 0.239106, acc.: 54.69%] [G loss: 0.301719]\n",
      "epoch:23 step:21731 [D loss: 0.230603, acc.: 65.62%] [G loss: 0.310586]\n",
      "epoch:23 step:21732 [D loss: 0.237646, acc.: 59.38%] [G loss: 0.310624]\n",
      "epoch:23 step:21733 [D loss: 0.228625, acc.: 65.62%] [G loss: 0.285939]\n",
      "epoch:23 step:21734 [D loss: 0.242966, acc.: 59.38%] [G loss: 0.310103]\n",
      "epoch:23 step:21735 [D loss: 0.247720, acc.: 56.25%] [G loss: 0.310982]\n",
      "epoch:23 step:21736 [D loss: 0.232698, acc.: 60.16%] [G loss: 0.296475]\n",
      "epoch:23 step:21737 [D loss: 0.240923, acc.: 62.50%] [G loss: 0.296617]\n",
      "epoch:23 step:21738 [D loss: 0.208573, acc.: 69.53%] [G loss: 0.307442]\n",
      "epoch:23 step:21739 [D loss: 0.246280, acc.: 53.91%] [G loss: 0.289621]\n",
      "epoch:23 step:21740 [D loss: 0.236447, acc.: 61.72%] [G loss: 0.300120]\n",
      "epoch:23 step:21741 [D loss: 0.242526, acc.: 54.69%] [G loss: 0.318333]\n",
      "epoch:23 step:21742 [D loss: 0.215601, acc.: 60.94%] [G loss: 0.297920]\n",
      "epoch:23 step:21743 [D loss: 0.221347, acc.: 62.50%] [G loss: 0.314718]\n",
      "epoch:23 step:21744 [D loss: 0.242959, acc.: 53.91%] [G loss: 0.303057]\n",
      "epoch:23 step:21745 [D loss: 0.243726, acc.: 53.91%] [G loss: 0.285181]\n",
      "epoch:23 step:21746 [D loss: 0.254233, acc.: 53.12%] [G loss: 0.316253]\n",
      "epoch:23 step:21747 [D loss: 0.247110, acc.: 55.47%] [G loss: 0.301664]\n",
      "epoch:23 step:21748 [D loss: 0.234126, acc.: 57.81%] [G loss: 0.306366]\n",
      "epoch:23 step:21749 [D loss: 0.229284, acc.: 67.97%] [G loss: 0.311439]\n",
      "epoch:23 step:21750 [D loss: 0.241779, acc.: 59.38%] [G loss: 0.289150]\n",
      "epoch:23 step:21751 [D loss: 0.246751, acc.: 60.16%] [G loss: 0.303995]\n",
      "epoch:23 step:21752 [D loss: 0.227359, acc.: 60.94%] [G loss: 0.302506]\n",
      "epoch:23 step:21753 [D loss: 0.228849, acc.: 62.50%] [G loss: 0.346478]\n",
      "epoch:23 step:21754 [D loss: 0.229408, acc.: 65.62%] [G loss: 0.301058]\n",
      "epoch:23 step:21755 [D loss: 0.225316, acc.: 63.28%] [G loss: 0.310383]\n",
      "epoch:23 step:21756 [D loss: 0.222983, acc.: 62.50%] [G loss: 0.312759]\n",
      "epoch:23 step:21757 [D loss: 0.239350, acc.: 58.59%] [G loss: 0.298803]\n",
      "epoch:23 step:21758 [D loss: 0.235268, acc.: 62.50%] [G loss: 0.282646]\n",
      "epoch:23 step:21759 [D loss: 0.230229, acc.: 62.50%] [G loss: 0.316191]\n",
      "epoch:23 step:21760 [D loss: 0.243975, acc.: 57.03%] [G loss: 0.319999]\n",
      "epoch:23 step:21761 [D loss: 0.248222, acc.: 55.47%] [G loss: 0.311059]\n",
      "epoch:23 step:21762 [D loss: 0.236817, acc.: 63.28%] [G loss: 0.297789]\n",
      "epoch:23 step:21763 [D loss: 0.229618, acc.: 58.59%] [G loss: 0.312034]\n",
      "epoch:23 step:21764 [D loss: 0.238189, acc.: 57.03%] [G loss: 0.331867]\n",
      "epoch:23 step:21765 [D loss: 0.252385, acc.: 51.56%] [G loss: 0.310783]\n",
      "epoch:23 step:21766 [D loss: 0.255265, acc.: 55.47%] [G loss: 0.331081]\n",
      "epoch:23 step:21767 [D loss: 0.254827, acc.: 47.66%] [G loss: 0.291875]\n",
      "epoch:23 step:21768 [D loss: 0.234474, acc.: 60.16%] [G loss: 0.306254]\n",
      "epoch:23 step:21769 [D loss: 0.232448, acc.: 60.94%] [G loss: 0.297227]\n",
      "epoch:23 step:21770 [D loss: 0.234880, acc.: 60.16%] [G loss: 0.324894]\n",
      "epoch:23 step:21771 [D loss: 0.231435, acc.: 61.72%] [G loss: 0.296867]\n",
      "epoch:23 step:21772 [D loss: 0.216437, acc.: 68.75%] [G loss: 0.292888]\n",
      "epoch:23 step:21773 [D loss: 0.237697, acc.: 57.03%] [G loss: 0.278790]\n",
      "epoch:23 step:21774 [D loss: 0.241767, acc.: 58.59%] [G loss: 0.306374]\n",
      "epoch:23 step:21775 [D loss: 0.232977, acc.: 62.50%] [G loss: 0.287537]\n",
      "epoch:23 step:21776 [D loss: 0.240029, acc.: 56.25%] [G loss: 0.285531]\n",
      "epoch:23 step:21777 [D loss: 0.237803, acc.: 58.59%] [G loss: 0.348416]\n",
      "epoch:23 step:21778 [D loss: 0.237494, acc.: 59.38%] [G loss: 0.308247]\n",
      "epoch:23 step:21779 [D loss: 0.235133, acc.: 59.38%] [G loss: 0.302678]\n",
      "epoch:23 step:21780 [D loss: 0.222782, acc.: 67.19%] [G loss: 0.293365]\n",
      "epoch:23 step:21781 [D loss: 0.249628, acc.: 57.03%] [G loss: 0.298832]\n",
      "epoch:23 step:21782 [D loss: 0.246992, acc.: 53.91%] [G loss: 0.275184]\n",
      "epoch:23 step:21783 [D loss: 0.249690, acc.: 54.69%] [G loss: 0.312465]\n",
      "epoch:23 step:21784 [D loss: 0.244636, acc.: 51.56%] [G loss: 0.307436]\n",
      "epoch:23 step:21785 [D loss: 0.242774, acc.: 57.03%] [G loss: 0.308549]\n",
      "epoch:23 step:21786 [D loss: 0.241364, acc.: 57.81%] [G loss: 0.274948]\n",
      "epoch:23 step:21787 [D loss: 0.225874, acc.: 62.50%] [G loss: 0.289157]\n",
      "epoch:23 step:21788 [D loss: 0.236685, acc.: 59.38%] [G loss: 0.315930]\n",
      "epoch:23 step:21789 [D loss: 0.241997, acc.: 54.69%] [G loss: 0.292198]\n",
      "epoch:23 step:21790 [D loss: 0.234457, acc.: 57.03%] [G loss: 0.306384]\n",
      "epoch:23 step:21791 [D loss: 0.245121, acc.: 58.59%] [G loss: 0.297951]\n",
      "epoch:23 step:21792 [D loss: 0.243125, acc.: 55.47%] [G loss: 0.276204]\n",
      "epoch:23 step:21793 [D loss: 0.242065, acc.: 52.34%] [G loss: 0.309913]\n",
      "epoch:23 step:21794 [D loss: 0.249565, acc.: 55.47%] [G loss: 0.320755]\n",
      "epoch:23 step:21795 [D loss: 0.244344, acc.: 57.81%] [G loss: 0.309371]\n",
      "epoch:23 step:21796 [D loss: 0.246742, acc.: 54.69%] [G loss: 0.303854]\n",
      "epoch:23 step:21797 [D loss: 0.235326, acc.: 64.84%] [G loss: 0.307625]\n",
      "epoch:23 step:21798 [D loss: 0.248502, acc.: 60.94%] [G loss: 0.296723]\n",
      "epoch:23 step:21799 [D loss: 0.232675, acc.: 63.28%] [G loss: 0.314939]\n",
      "epoch:23 step:21800 [D loss: 0.244555, acc.: 53.12%] [G loss: 0.289800]\n",
      "epoch:23 step:21801 [D loss: 0.233223, acc.: 56.25%] [G loss: 0.291019]\n",
      "epoch:23 step:21802 [D loss: 0.247595, acc.: 55.47%] [G loss: 0.309969]\n",
      "epoch:23 step:21803 [D loss: 0.228377, acc.: 63.28%] [G loss: 0.312061]\n",
      "epoch:23 step:21804 [D loss: 0.240761, acc.: 53.12%] [G loss: 0.315310]\n",
      "epoch:23 step:21805 [D loss: 0.236130, acc.: 60.94%] [G loss: 0.298494]\n",
      "epoch:23 step:21806 [D loss: 0.234828, acc.: 62.50%] [G loss: 0.313665]\n",
      "epoch:23 step:21807 [D loss: 0.219899, acc.: 68.75%] [G loss: 0.313138]\n",
      "epoch:23 step:21808 [D loss: 0.241050, acc.: 58.59%] [G loss: 0.285915]\n",
      "epoch:23 step:21809 [D loss: 0.238158, acc.: 57.03%] [G loss: 0.296554]\n",
      "epoch:23 step:21810 [D loss: 0.241703, acc.: 60.16%] [G loss: 0.289475]\n",
      "epoch:23 step:21811 [D loss: 0.245712, acc.: 57.03%] [G loss: 0.285434]\n",
      "epoch:23 step:21812 [D loss: 0.224409, acc.: 62.50%] [G loss: 0.336494]\n",
      "epoch:23 step:21813 [D loss: 0.249823, acc.: 55.47%] [G loss: 0.323689]\n",
      "epoch:23 step:21814 [D loss: 0.241674, acc.: 57.81%] [G loss: 0.324195]\n",
      "epoch:23 step:21815 [D loss: 0.240319, acc.: 60.16%] [G loss: 0.287929]\n",
      "epoch:23 step:21816 [D loss: 0.236393, acc.: 57.81%] [G loss: 0.305380]\n",
      "epoch:23 step:21817 [D loss: 0.233403, acc.: 59.38%] [G loss: 0.306633]\n",
      "epoch:23 step:21818 [D loss: 0.253286, acc.: 47.66%] [G loss: 0.283101]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:23 step:21819 [D loss: 0.222848, acc.: 65.62%] [G loss: 0.341975]\n",
      "epoch:23 step:21820 [D loss: 0.244644, acc.: 51.56%] [G loss: 0.289622]\n",
      "epoch:23 step:21821 [D loss: 0.242136, acc.: 57.03%] [G loss: 0.322173]\n",
      "epoch:23 step:21822 [D loss: 0.241651, acc.: 55.47%] [G loss: 0.335982]\n",
      "epoch:23 step:21823 [D loss: 0.244570, acc.: 58.59%] [G loss: 0.313220]\n",
      "epoch:23 step:21824 [D loss: 0.239163, acc.: 53.91%] [G loss: 0.300450]\n",
      "epoch:23 step:21825 [D loss: 0.233815, acc.: 63.28%] [G loss: 0.333100]\n",
      "epoch:23 step:21826 [D loss: 0.254903, acc.: 47.66%] [G loss: 0.314395]\n",
      "epoch:23 step:21827 [D loss: 0.245995, acc.: 54.69%] [G loss: 0.297331]\n",
      "epoch:23 step:21828 [D loss: 0.227707, acc.: 57.03%] [G loss: 0.307109]\n",
      "epoch:23 step:21829 [D loss: 0.244329, acc.: 53.12%] [G loss: 0.312362]\n",
      "epoch:23 step:21830 [D loss: 0.234974, acc.: 58.59%] [G loss: 0.305568]\n",
      "epoch:23 step:21831 [D loss: 0.244249, acc.: 61.72%] [G loss: 0.300615]\n",
      "epoch:23 step:21832 [D loss: 0.245482, acc.: 57.03%] [G loss: 0.308658]\n",
      "epoch:23 step:21833 [D loss: 0.244092, acc.: 57.03%] [G loss: 0.278652]\n",
      "epoch:23 step:21834 [D loss: 0.236764, acc.: 59.38%] [G loss: 0.305119]\n",
      "epoch:23 step:21835 [D loss: 0.258822, acc.: 51.56%] [G loss: 0.301335]\n",
      "epoch:23 step:21836 [D loss: 0.246565, acc.: 56.25%] [G loss: 0.281611]\n",
      "epoch:23 step:21837 [D loss: 0.221932, acc.: 62.50%] [G loss: 0.312583]\n",
      "epoch:23 step:21838 [D loss: 0.243358, acc.: 58.59%] [G loss: 0.263481]\n",
      "epoch:23 step:21839 [D loss: 0.240460, acc.: 61.72%] [G loss: 0.311297]\n",
      "epoch:23 step:21840 [D loss: 0.249449, acc.: 56.25%] [G loss: 0.299527]\n",
      "epoch:23 step:21841 [D loss: 0.238161, acc.: 53.91%] [G loss: 0.315264]\n",
      "epoch:23 step:21842 [D loss: 0.231532, acc.: 64.06%] [G loss: 0.299774]\n",
      "epoch:23 step:21843 [D loss: 0.257218, acc.: 53.12%] [G loss: 0.309241]\n",
      "epoch:23 step:21844 [D loss: 0.246058, acc.: 51.56%] [G loss: 0.304383]\n",
      "epoch:23 step:21845 [D loss: 0.241173, acc.: 54.69%] [G loss: 0.303507]\n",
      "epoch:23 step:21846 [D loss: 0.222076, acc.: 67.97%] [G loss: 0.312537]\n",
      "epoch:23 step:21847 [D loss: 0.238304, acc.: 58.59%] [G loss: 0.305046]\n",
      "epoch:23 step:21848 [D loss: 0.241775, acc.: 55.47%] [G loss: 0.307373]\n",
      "epoch:23 step:21849 [D loss: 0.258495, acc.: 49.22%] [G loss: 0.330434]\n",
      "epoch:23 step:21850 [D loss: 0.246598, acc.: 58.59%] [G loss: 0.325516]\n",
      "epoch:23 step:21851 [D loss: 0.228525, acc.: 64.06%] [G loss: 0.336304]\n",
      "epoch:23 step:21852 [D loss: 0.241341, acc.: 56.25%] [G loss: 0.312974]\n",
      "epoch:23 step:21853 [D loss: 0.244117, acc.: 58.59%] [G loss: 0.310823]\n",
      "epoch:23 step:21854 [D loss: 0.240502, acc.: 61.72%] [G loss: 0.296138]\n",
      "epoch:23 step:21855 [D loss: 0.248185, acc.: 55.47%] [G loss: 0.320699]\n",
      "epoch:23 step:21856 [D loss: 0.232308, acc.: 64.06%] [G loss: 0.272328]\n",
      "epoch:23 step:21857 [D loss: 0.236791, acc.: 56.25%] [G loss: 0.327827]\n",
      "epoch:23 step:21858 [D loss: 0.239088, acc.: 55.47%] [G loss: 0.279234]\n",
      "epoch:23 step:21859 [D loss: 0.243870, acc.: 63.28%] [G loss: 0.313581]\n",
      "epoch:23 step:21860 [D loss: 0.226729, acc.: 63.28%] [G loss: 0.306978]\n",
      "epoch:23 step:21861 [D loss: 0.230120, acc.: 60.16%] [G loss: 0.296739]\n",
      "epoch:23 step:21862 [D loss: 0.246848, acc.: 51.56%] [G loss: 0.308114]\n",
      "epoch:23 step:21863 [D loss: 0.261019, acc.: 47.66%] [G loss: 0.293395]\n",
      "epoch:23 step:21864 [D loss: 0.244938, acc.: 56.25%] [G loss: 0.321902]\n",
      "epoch:23 step:21865 [D loss: 0.217791, acc.: 69.53%] [G loss: 0.298241]\n",
      "epoch:23 step:21866 [D loss: 0.242895, acc.: 57.03%] [G loss: 0.317679]\n",
      "epoch:23 step:21867 [D loss: 0.239978, acc.: 56.25%] [G loss: 0.301282]\n",
      "epoch:23 step:21868 [D loss: 0.230231, acc.: 66.41%] [G loss: 0.281805]\n",
      "epoch:23 step:21869 [D loss: 0.214879, acc.: 64.84%] [G loss: 0.313365]\n",
      "epoch:23 step:21870 [D loss: 0.246470, acc.: 57.03%] [G loss: 0.299988]\n",
      "epoch:23 step:21871 [D loss: 0.236116, acc.: 60.16%] [G loss: 0.299348]\n",
      "epoch:23 step:21872 [D loss: 0.247142, acc.: 56.25%] [G loss: 0.286366]\n",
      "epoch:23 step:21873 [D loss: 0.255198, acc.: 53.91%] [G loss: 0.293556]\n",
      "epoch:23 step:21874 [D loss: 0.246995, acc.: 57.81%] [G loss: 0.324871]\n",
      "epoch:23 step:21875 [D loss: 0.242621, acc.: 58.59%] [G loss: 0.250539]\n",
      "epoch:23 step:21876 [D loss: 0.243468, acc.: 55.47%] [G loss: 0.274819]\n",
      "epoch:23 step:21877 [D loss: 0.231223, acc.: 66.41%] [G loss: 0.284219]\n",
      "epoch:23 step:21878 [D loss: 0.240371, acc.: 59.38%] [G loss: 0.282014]\n",
      "epoch:23 step:21879 [D loss: 0.236429, acc.: 60.94%] [G loss: 0.309774]\n",
      "epoch:23 step:21880 [D loss: 0.236556, acc.: 60.94%] [G loss: 0.323249]\n",
      "epoch:23 step:21881 [D loss: 0.252351, acc.: 53.91%] [G loss: 0.303781]\n",
      "epoch:23 step:21882 [D loss: 0.236444, acc.: 62.50%] [G loss: 0.303761]\n",
      "epoch:23 step:21883 [D loss: 0.236437, acc.: 56.25%] [G loss: 0.288588]\n",
      "epoch:23 step:21884 [D loss: 0.235074, acc.: 59.38%] [G loss: 0.286818]\n",
      "epoch:23 step:21885 [D loss: 0.245549, acc.: 57.03%] [G loss: 0.295713]\n",
      "epoch:23 step:21886 [D loss: 0.244106, acc.: 63.28%] [G loss: 0.326822]\n",
      "epoch:23 step:21887 [D loss: 0.234911, acc.: 61.72%] [G loss: 0.287358]\n",
      "epoch:23 step:21888 [D loss: 0.236486, acc.: 60.16%] [G loss: 0.287436]\n",
      "epoch:23 step:21889 [D loss: 0.232474, acc.: 59.38%] [G loss: 0.297286]\n",
      "epoch:23 step:21890 [D loss: 0.231685, acc.: 60.16%] [G loss: 0.314183]\n",
      "epoch:23 step:21891 [D loss: 0.217375, acc.: 67.97%] [G loss: 0.319286]\n",
      "epoch:23 step:21892 [D loss: 0.234659, acc.: 59.38%] [G loss: 0.294621]\n",
      "epoch:23 step:21893 [D loss: 0.266799, acc.: 49.22%] [G loss: 0.301766]\n",
      "epoch:23 step:21894 [D loss: 0.242902, acc.: 59.38%] [G loss: 0.320760]\n",
      "epoch:23 step:21895 [D loss: 0.236207, acc.: 61.72%] [G loss: 0.309434]\n",
      "epoch:23 step:21896 [D loss: 0.235135, acc.: 60.94%] [G loss: 0.321606]\n",
      "epoch:23 step:21897 [D loss: 0.229719, acc.: 60.16%] [G loss: 0.311270]\n",
      "epoch:23 step:21898 [D loss: 0.226312, acc.: 60.16%] [G loss: 0.294471]\n",
      "epoch:23 step:21899 [D loss: 0.239625, acc.: 58.59%] [G loss: 0.289710]\n",
      "epoch:23 step:21900 [D loss: 0.236655, acc.: 60.16%] [G loss: 0.321618]\n",
      "epoch:23 step:21901 [D loss: 0.245494, acc.: 57.81%] [G loss: 0.331926]\n",
      "epoch:23 step:21902 [D loss: 0.236462, acc.: 60.16%] [G loss: 0.312564]\n",
      "epoch:23 step:21903 [D loss: 0.249933, acc.: 56.25%] [G loss: 0.279242]\n",
      "epoch:23 step:21904 [D loss: 0.227176, acc.: 61.72%] [G loss: 0.305999]\n",
      "epoch:23 step:21905 [D loss: 0.233622, acc.: 63.28%] [G loss: 0.310347]\n",
      "epoch:23 step:21906 [D loss: 0.266038, acc.: 47.66%] [G loss: 0.323062]\n",
      "epoch:23 step:21907 [D loss: 0.247018, acc.: 52.34%] [G loss: 0.294860]\n",
      "epoch:23 step:21908 [D loss: 0.240601, acc.: 50.78%] [G loss: 0.290321]\n",
      "epoch:23 step:21909 [D loss: 0.238729, acc.: 60.16%] [G loss: 0.271195]\n",
      "epoch:23 step:21910 [D loss: 0.254447, acc.: 54.69%] [G loss: 0.305998]\n",
      "epoch:23 step:21911 [D loss: 0.215266, acc.: 70.31%] [G loss: 0.325775]\n",
      "epoch:23 step:21912 [D loss: 0.240184, acc.: 54.69%] [G loss: 0.327399]\n",
      "epoch:23 step:21913 [D loss: 0.255567, acc.: 53.91%] [G loss: 0.306200]\n",
      "epoch:23 step:21914 [D loss: 0.246496, acc.: 55.47%] [G loss: 0.295714]\n",
      "epoch:23 step:21915 [D loss: 0.242117, acc.: 60.16%] [G loss: 0.346106]\n",
      "epoch:23 step:21916 [D loss: 0.231448, acc.: 60.16%] [G loss: 0.314261]\n",
      "epoch:23 step:21917 [D loss: 0.236685, acc.: 60.16%] [G loss: 0.297490]\n",
      "epoch:23 step:21918 [D loss: 0.243373, acc.: 57.03%] [G loss: 0.306891]\n",
      "epoch:23 step:21919 [D loss: 0.245753, acc.: 53.91%] [G loss: 0.310995]\n",
      "epoch:23 step:21920 [D loss: 0.225888, acc.: 67.97%] [G loss: 0.285404]\n",
      "epoch:23 step:21921 [D loss: 0.245819, acc.: 53.12%] [G loss: 0.319088]\n",
      "epoch:23 step:21922 [D loss: 0.248975, acc.: 53.91%] [G loss: 0.310573]\n",
      "epoch:23 step:21923 [D loss: 0.230855, acc.: 57.81%] [G loss: 0.310739]\n",
      "epoch:23 step:21924 [D loss: 0.238874, acc.: 56.25%] [G loss: 0.302571]\n",
      "epoch:23 step:21925 [D loss: 0.233463, acc.: 55.47%] [G loss: 0.309130]\n",
      "epoch:23 step:21926 [D loss: 0.234923, acc.: 60.94%] [G loss: 0.303046]\n",
      "epoch:23 step:21927 [D loss: 0.225098, acc.: 63.28%] [G loss: 0.323375]\n",
      "epoch:23 step:21928 [D loss: 0.221894, acc.: 65.62%] [G loss: 0.302578]\n",
      "epoch:23 step:21929 [D loss: 0.240527, acc.: 56.25%] [G loss: 0.296216]\n",
      "epoch:23 step:21930 [D loss: 0.249301, acc.: 56.25%] [G loss: 0.302283]\n",
      "epoch:23 step:21931 [D loss: 0.240520, acc.: 54.69%] [G loss: 0.300548]\n",
      "epoch:23 step:21932 [D loss: 0.232344, acc.: 60.94%] [G loss: 0.302060]\n",
      "epoch:23 step:21933 [D loss: 0.242314, acc.: 58.59%] [G loss: 0.290119]\n",
      "epoch:23 step:21934 [D loss: 0.254256, acc.: 57.03%] [G loss: 0.293068]\n",
      "epoch:23 step:21935 [D loss: 0.241902, acc.: 60.16%] [G loss: 0.307555]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:23 step:21936 [D loss: 0.248754, acc.: 56.25%] [G loss: 0.312780]\n",
      "epoch:23 step:21937 [D loss: 0.239835, acc.: 57.03%] [G loss: 0.317708]\n",
      "epoch:23 step:21938 [D loss: 0.230505, acc.: 63.28%] [G loss: 0.321814]\n",
      "epoch:23 step:21939 [D loss: 0.242052, acc.: 60.94%] [G loss: 0.267954]\n",
      "epoch:23 step:21940 [D loss: 0.216963, acc.: 69.53%] [G loss: 0.318905]\n",
      "epoch:23 step:21941 [D loss: 0.234004, acc.: 56.25%] [G loss: 0.298544]\n",
      "epoch:23 step:21942 [D loss: 0.244488, acc.: 57.03%] [G loss: 0.307736]\n",
      "epoch:23 step:21943 [D loss: 0.244477, acc.: 52.34%] [G loss: 0.315559]\n",
      "epoch:23 step:21944 [D loss: 0.230178, acc.: 62.50%] [G loss: 0.314752]\n",
      "epoch:23 step:21945 [D loss: 0.239155, acc.: 60.94%] [G loss: 0.298846]\n",
      "epoch:23 step:21946 [D loss: 0.236165, acc.: 57.03%] [G loss: 0.295438]\n",
      "epoch:23 step:21947 [D loss: 0.238540, acc.: 61.72%] [G loss: 0.317549]\n",
      "epoch:23 step:21948 [D loss: 0.246541, acc.: 50.78%] [G loss: 0.321155]\n",
      "epoch:23 step:21949 [D loss: 0.261989, acc.: 46.88%] [G loss: 0.278824]\n",
      "epoch:23 step:21950 [D loss: 0.226861, acc.: 65.62%] [G loss: 0.318791]\n",
      "epoch:23 step:21951 [D loss: 0.226183, acc.: 60.94%] [G loss: 0.318501]\n",
      "epoch:23 step:21952 [D loss: 0.234108, acc.: 64.84%] [G loss: 0.304433]\n",
      "epoch:23 step:21953 [D loss: 0.231412, acc.: 60.94%] [G loss: 0.297807]\n",
      "epoch:23 step:21954 [D loss: 0.247543, acc.: 57.03%] [G loss: 0.298357]\n",
      "epoch:23 step:21955 [D loss: 0.242720, acc.: 60.94%] [G loss: 0.295043]\n",
      "epoch:23 step:21956 [D loss: 0.245546, acc.: 56.25%] [G loss: 0.321941]\n",
      "epoch:23 step:21957 [D loss: 0.227181, acc.: 65.62%] [G loss: 0.323809]\n",
      "epoch:23 step:21958 [D loss: 0.234301, acc.: 60.94%] [G loss: 0.302935]\n",
      "epoch:23 step:21959 [D loss: 0.241415, acc.: 55.47%] [G loss: 0.270401]\n",
      "epoch:23 step:21960 [D loss: 0.228917, acc.: 61.72%] [G loss: 0.318367]\n",
      "epoch:23 step:21961 [D loss: 0.237918, acc.: 60.16%] [G loss: 0.277361]\n",
      "epoch:23 step:21962 [D loss: 0.256603, acc.: 51.56%] [G loss: 0.299669]\n",
      "epoch:23 step:21963 [D loss: 0.247403, acc.: 55.47%] [G loss: 0.284865]\n",
      "epoch:23 step:21964 [D loss: 0.246951, acc.: 58.59%] [G loss: 0.273993]\n",
      "epoch:23 step:21965 [D loss: 0.247763, acc.: 57.03%] [G loss: 0.297500]\n",
      "epoch:23 step:21966 [D loss: 0.247158, acc.: 52.34%] [G loss: 0.289865]\n",
      "epoch:23 step:21967 [D loss: 0.244798, acc.: 50.78%] [G loss: 0.280871]\n",
      "epoch:23 step:21968 [D loss: 0.245995, acc.: 64.84%] [G loss: 0.305665]\n",
      "epoch:23 step:21969 [D loss: 0.251632, acc.: 53.91%] [G loss: 0.279668]\n",
      "epoch:23 step:21970 [D loss: 0.235351, acc.: 57.81%] [G loss: 0.312651]\n",
      "epoch:23 step:21971 [D loss: 0.215713, acc.: 64.84%] [G loss: 0.285626]\n",
      "epoch:23 step:21972 [D loss: 0.246635, acc.: 53.91%] [G loss: 0.270525]\n",
      "epoch:23 step:21973 [D loss: 0.234431, acc.: 56.25%] [G loss: 0.305289]\n",
      "epoch:23 step:21974 [D loss: 0.241860, acc.: 57.03%] [G loss: 0.313899]\n",
      "epoch:23 step:21975 [D loss: 0.236810, acc.: 60.94%] [G loss: 0.315416]\n",
      "epoch:23 step:21976 [D loss: 0.244520, acc.: 53.91%] [G loss: 0.308456]\n",
      "epoch:23 step:21977 [D loss: 0.261409, acc.: 51.56%] [G loss: 0.289650]\n",
      "epoch:23 step:21978 [D loss: 0.240426, acc.: 53.12%] [G loss: 0.294749]\n",
      "epoch:23 step:21979 [D loss: 0.232110, acc.: 60.16%] [G loss: 0.307602]\n",
      "epoch:23 step:21980 [D loss: 0.235245, acc.: 60.16%] [G loss: 0.311643]\n",
      "epoch:23 step:21981 [D loss: 0.256224, acc.: 53.91%] [G loss: 0.296376]\n",
      "epoch:23 step:21982 [D loss: 0.241727, acc.: 53.12%] [G loss: 0.307926]\n",
      "epoch:23 step:21983 [D loss: 0.211780, acc.: 70.31%] [G loss: 0.297623]\n",
      "epoch:23 step:21984 [D loss: 0.235697, acc.: 57.03%] [G loss: 0.315966]\n",
      "epoch:23 step:21985 [D loss: 0.253567, acc.: 51.56%] [G loss: 0.290962]\n",
      "epoch:23 step:21986 [D loss: 0.242214, acc.: 58.59%] [G loss: 0.273078]\n",
      "epoch:23 step:21987 [D loss: 0.243094, acc.: 57.81%] [G loss: 0.317504]\n",
      "epoch:23 step:21988 [D loss: 0.228061, acc.: 60.94%] [G loss: 0.301937]\n",
      "epoch:23 step:21989 [D loss: 0.243001, acc.: 59.38%] [G loss: 0.325518]\n",
      "epoch:23 step:21990 [D loss: 0.262100, acc.: 47.66%] [G loss: 0.301754]\n",
      "epoch:23 step:21991 [D loss: 0.240716, acc.: 54.69%] [G loss: 0.277042]\n",
      "epoch:23 step:21992 [D loss: 0.247657, acc.: 53.12%] [G loss: 0.315163]\n",
      "epoch:23 step:21993 [D loss: 0.238218, acc.: 58.59%] [G loss: 0.304054]\n",
      "epoch:23 step:21994 [D loss: 0.227519, acc.: 62.50%] [G loss: 0.284979]\n",
      "epoch:23 step:21995 [D loss: 0.231708, acc.: 60.16%] [G loss: 0.315736]\n",
      "epoch:23 step:21996 [D loss: 0.218713, acc.: 66.41%] [G loss: 0.320915]\n",
      "epoch:23 step:21997 [D loss: 0.257288, acc.: 54.69%] [G loss: 0.291278]\n",
      "epoch:23 step:21998 [D loss: 0.236050, acc.: 56.25%] [G loss: 0.336997]\n",
      "epoch:23 step:21999 [D loss: 0.241816, acc.: 57.03%] [G loss: 0.295053]\n",
      "epoch:23 step:22000 [D loss: 0.237369, acc.: 60.94%] [G loss: 0.296167]\n",
      "epoch:23 step:22001 [D loss: 0.245839, acc.: 58.59%] [G loss: 0.300440]\n",
      "epoch:23 step:22002 [D loss: 0.212537, acc.: 68.75%] [G loss: 0.338888]\n",
      "epoch:23 step:22003 [D loss: 0.231213, acc.: 58.59%] [G loss: 0.308365]\n",
      "epoch:23 step:22004 [D loss: 0.228945, acc.: 62.50%] [G loss: 0.294802]\n",
      "epoch:23 step:22005 [D loss: 0.228269, acc.: 59.38%] [G loss: 0.272242]\n",
      "epoch:23 step:22006 [D loss: 0.224307, acc.: 67.97%] [G loss: 0.314672]\n",
      "epoch:23 step:22007 [D loss: 0.254678, acc.: 53.91%] [G loss: 0.310863]\n",
      "epoch:23 step:22008 [D loss: 0.253700, acc.: 55.47%] [G loss: 0.287807]\n",
      "epoch:23 step:22009 [D loss: 0.242725, acc.: 57.03%] [G loss: 0.284822]\n",
      "epoch:23 step:22010 [D loss: 0.225992, acc.: 66.41%] [G loss: 0.314242]\n",
      "epoch:23 step:22011 [D loss: 0.232985, acc.: 62.50%] [G loss: 0.322152]\n",
      "epoch:23 step:22012 [D loss: 0.229901, acc.: 60.16%] [G loss: 0.316752]\n",
      "epoch:23 step:22013 [D loss: 0.237198, acc.: 57.81%] [G loss: 0.282257]\n",
      "epoch:23 step:22014 [D loss: 0.247691, acc.: 56.25%] [G loss: 0.310882]\n",
      "epoch:23 step:22015 [D loss: 0.245134, acc.: 53.12%] [G loss: 0.291641]\n",
      "epoch:23 step:22016 [D loss: 0.240490, acc.: 55.47%] [G loss: 0.296354]\n",
      "epoch:23 step:22017 [D loss: 0.226442, acc.: 64.84%] [G loss: 0.281872]\n",
      "epoch:23 step:22018 [D loss: 0.229158, acc.: 65.62%] [G loss: 0.303597]\n",
      "epoch:23 step:22019 [D loss: 0.257011, acc.: 54.69%] [G loss: 0.288491]\n",
      "epoch:23 step:22020 [D loss: 0.241446, acc.: 60.16%] [G loss: 0.312180]\n",
      "epoch:23 step:22021 [D loss: 0.232662, acc.: 60.16%] [G loss: 0.277313]\n",
      "epoch:23 step:22022 [D loss: 0.224870, acc.: 64.06%] [G loss: 0.299205]\n",
      "epoch:23 step:22023 [D loss: 0.235890, acc.: 60.94%] [G loss: 0.292107]\n",
      "epoch:23 step:22024 [D loss: 0.249442, acc.: 55.47%] [G loss: 0.284108]\n",
      "epoch:23 step:22025 [D loss: 0.239220, acc.: 54.69%] [G loss: 0.293545]\n",
      "epoch:23 step:22026 [D loss: 0.251375, acc.: 54.69%] [G loss: 0.282064]\n",
      "epoch:23 step:22027 [D loss: 0.237574, acc.: 58.59%] [G loss: 0.272862]\n",
      "epoch:23 step:22028 [D loss: 0.243393, acc.: 58.59%] [G loss: 0.304854]\n",
      "epoch:23 step:22029 [D loss: 0.237036, acc.: 60.16%] [G loss: 0.303721]\n",
      "epoch:23 step:22030 [D loss: 0.235763, acc.: 63.28%] [G loss: 0.300068]\n",
      "epoch:23 step:22031 [D loss: 0.233725, acc.: 57.03%] [G loss: 0.307058]\n",
      "epoch:23 step:22032 [D loss: 0.245816, acc.: 54.69%] [G loss: 0.307272]\n",
      "epoch:23 step:22033 [D loss: 0.238465, acc.: 57.03%] [G loss: 0.288402]\n",
      "epoch:23 step:22034 [D loss: 0.240720, acc.: 54.69%] [G loss: 0.317856]\n",
      "epoch:23 step:22035 [D loss: 0.229317, acc.: 64.06%] [G loss: 0.287867]\n",
      "epoch:23 step:22036 [D loss: 0.245786, acc.: 53.91%] [G loss: 0.297419]\n",
      "epoch:23 step:22037 [D loss: 0.204571, acc.: 70.31%] [G loss: 0.319058]\n",
      "epoch:23 step:22038 [D loss: 0.253771, acc.: 57.81%] [G loss: 0.313234]\n",
      "epoch:23 step:22039 [D loss: 0.233455, acc.: 57.03%] [G loss: 0.322296]\n",
      "epoch:23 step:22040 [D loss: 0.241803, acc.: 57.03%] [G loss: 0.306490]\n",
      "epoch:23 step:22041 [D loss: 0.228596, acc.: 57.81%] [G loss: 0.292423]\n",
      "epoch:23 step:22042 [D loss: 0.253899, acc.: 51.56%] [G loss: 0.291763]\n",
      "epoch:23 step:22043 [D loss: 0.252974, acc.: 52.34%] [G loss: 0.293123]\n",
      "epoch:23 step:22044 [D loss: 0.235823, acc.: 66.41%] [G loss: 0.293698]\n",
      "epoch:23 step:22045 [D loss: 0.249240, acc.: 55.47%] [G loss: 0.303457]\n",
      "epoch:23 step:22046 [D loss: 0.229189, acc.: 62.50%] [G loss: 0.297327]\n",
      "epoch:23 step:22047 [D loss: 0.251805, acc.: 49.22%] [G loss: 0.291075]\n",
      "epoch:23 step:22048 [D loss: 0.234382, acc.: 60.16%] [G loss: 0.292579]\n",
      "epoch:23 step:22049 [D loss: 0.233401, acc.: 58.59%] [G loss: 0.319722]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:23 step:22050 [D loss: 0.219208, acc.: 67.19%] [G loss: 0.344169]\n",
      "epoch:23 step:22051 [D loss: 0.249518, acc.: 59.38%] [G loss: 0.313431]\n",
      "epoch:23 step:22052 [D loss: 0.238738, acc.: 58.59%] [G loss: 0.296443]\n",
      "epoch:23 step:22053 [D loss: 0.233821, acc.: 64.06%] [G loss: 0.289097]\n",
      "epoch:23 step:22054 [D loss: 0.237438, acc.: 61.72%] [G loss: 0.277282]\n",
      "epoch:23 step:22055 [D loss: 0.228598, acc.: 64.84%] [G loss: 0.273981]\n",
      "epoch:23 step:22056 [D loss: 0.239206, acc.: 57.81%] [G loss: 0.285162]\n",
      "epoch:23 step:22057 [D loss: 0.246586, acc.: 57.81%] [G loss: 0.270985]\n",
      "epoch:23 step:22058 [D loss: 0.270864, acc.: 42.97%] [G loss: 0.268178]\n",
      "epoch:23 step:22059 [D loss: 0.237016, acc.: 58.59%] [G loss: 0.306988]\n",
      "epoch:23 step:22060 [D loss: 0.214114, acc.: 64.84%] [G loss: 0.316510]\n",
      "epoch:23 step:22061 [D loss: 0.243305, acc.: 60.94%] [G loss: 0.312380]\n",
      "epoch:23 step:22062 [D loss: 0.215472, acc.: 67.19%] [G loss: 0.303395]\n",
      "epoch:23 step:22063 [D loss: 0.238073, acc.: 55.47%] [G loss: 0.300194]\n",
      "epoch:23 step:22064 [D loss: 0.236662, acc.: 61.72%] [G loss: 0.302359]\n",
      "epoch:23 step:22065 [D loss: 0.247589, acc.: 53.12%] [G loss: 0.294141]\n",
      "epoch:23 step:22066 [D loss: 0.219279, acc.: 64.06%] [G loss: 0.299291]\n",
      "epoch:23 step:22067 [D loss: 0.230913, acc.: 65.62%] [G loss: 0.332590]\n",
      "epoch:23 step:22068 [D loss: 0.230886, acc.: 63.28%] [G loss: 0.310820]\n",
      "epoch:23 step:22069 [D loss: 0.249988, acc.: 53.12%] [G loss: 0.284088]\n",
      "epoch:23 step:22070 [D loss: 0.242319, acc.: 57.03%] [G loss: 0.306380]\n",
      "epoch:23 step:22071 [D loss: 0.232918, acc.: 59.38%] [G loss: 0.309848]\n",
      "epoch:23 step:22072 [D loss: 0.241208, acc.: 59.38%] [G loss: 0.325941]\n",
      "epoch:23 step:22073 [D loss: 0.242353, acc.: 56.25%] [G loss: 0.290962]\n",
      "epoch:23 step:22074 [D loss: 0.256157, acc.: 52.34%] [G loss: 0.287423]\n",
      "epoch:23 step:22075 [D loss: 0.225766, acc.: 60.94%] [G loss: 0.322878]\n",
      "epoch:23 step:22076 [D loss: 0.239890, acc.: 56.25%] [G loss: 0.287550]\n",
      "epoch:23 step:22077 [D loss: 0.209142, acc.: 70.31%] [G loss: 0.330445]\n",
      "epoch:23 step:22078 [D loss: 0.242478, acc.: 57.81%] [G loss: 0.311919]\n",
      "epoch:23 step:22079 [D loss: 0.238213, acc.: 59.38%] [G loss: 0.307900]\n",
      "epoch:23 step:22080 [D loss: 0.228402, acc.: 64.06%] [G loss: 0.327209]\n",
      "epoch:23 step:22081 [D loss: 0.230853, acc.: 57.03%] [G loss: 0.320882]\n",
      "epoch:23 step:22082 [D loss: 0.226694, acc.: 61.72%] [G loss: 0.288426]\n",
      "epoch:23 step:22083 [D loss: 0.237041, acc.: 56.25%] [G loss: 0.320388]\n",
      "epoch:23 step:22084 [D loss: 0.236695, acc.: 53.12%] [G loss: 0.304238]\n",
      "epoch:23 step:22085 [D loss: 0.259931, acc.: 49.22%] [G loss: 0.312403]\n",
      "epoch:23 step:22086 [D loss: 0.247680, acc.: 57.81%] [G loss: 0.313049]\n",
      "epoch:23 step:22087 [D loss: 0.246024, acc.: 52.34%] [G loss: 0.310743]\n",
      "epoch:23 step:22088 [D loss: 0.232580, acc.: 58.59%] [G loss: 0.328465]\n",
      "epoch:23 step:22089 [D loss: 0.245586, acc.: 56.25%] [G loss: 0.295214]\n",
      "epoch:23 step:22090 [D loss: 0.216926, acc.: 64.84%] [G loss: 0.302735]\n",
      "epoch:23 step:22091 [D loss: 0.231379, acc.: 57.03%] [G loss: 0.291754]\n",
      "epoch:23 step:22092 [D loss: 0.227319, acc.: 67.97%] [G loss: 0.326127]\n",
      "epoch:23 step:22093 [D loss: 0.234259, acc.: 61.72%] [G loss: 0.315783]\n",
      "epoch:23 step:22094 [D loss: 0.225376, acc.: 58.59%] [G loss: 0.278065]\n",
      "epoch:23 step:22095 [D loss: 0.246185, acc.: 56.25%] [G loss: 0.297840]\n",
      "epoch:23 step:22096 [D loss: 0.223593, acc.: 64.84%] [G loss: 0.324050]\n",
      "epoch:23 step:22097 [D loss: 0.240609, acc.: 55.47%] [G loss: 0.313930]\n",
      "epoch:23 step:22098 [D loss: 0.253103, acc.: 55.47%] [G loss: 0.304777]\n",
      "epoch:23 step:22099 [D loss: 0.249519, acc.: 56.25%] [G loss: 0.323980]\n",
      "epoch:23 step:22100 [D loss: 0.232285, acc.: 59.38%] [G loss: 0.328203]\n",
      "epoch:23 step:22101 [D loss: 0.236933, acc.: 55.47%] [G loss: 0.330228]\n",
      "epoch:23 step:22102 [D loss: 0.249344, acc.: 57.03%] [G loss: 0.322632]\n",
      "epoch:23 step:22103 [D loss: 0.258162, acc.: 56.25%] [G loss: 0.285755]\n",
      "epoch:23 step:22104 [D loss: 0.239705, acc.: 60.94%] [G loss: 0.294311]\n",
      "epoch:23 step:22105 [D loss: 0.239005, acc.: 61.72%] [G loss: 0.322238]\n",
      "epoch:23 step:22106 [D loss: 0.224445, acc.: 61.72%] [G loss: 0.321803]\n",
      "epoch:23 step:22107 [D loss: 0.242739, acc.: 55.47%] [G loss: 0.287282]\n",
      "epoch:23 step:22108 [D loss: 0.233280, acc.: 58.59%] [G loss: 0.324093]\n",
      "epoch:23 step:22109 [D loss: 0.253706, acc.: 57.81%] [G loss: 0.309365]\n",
      "epoch:23 step:22110 [D loss: 0.244658, acc.: 56.25%] [G loss: 0.285896]\n",
      "epoch:23 step:22111 [D loss: 0.253722, acc.: 51.56%] [G loss: 0.282090]\n",
      "epoch:23 step:22112 [D loss: 0.251068, acc.: 50.00%] [G loss: 0.298566]\n",
      "epoch:23 step:22113 [D loss: 0.249065, acc.: 56.25%] [G loss: 0.285848]\n",
      "epoch:23 step:22114 [D loss: 0.230878, acc.: 62.50%] [G loss: 0.320920]\n",
      "epoch:23 step:22115 [D loss: 0.233562, acc.: 60.94%] [G loss: 0.303007]\n",
      "epoch:23 step:22116 [D loss: 0.237617, acc.: 59.38%] [G loss: 0.308724]\n",
      "epoch:23 step:22117 [D loss: 0.232651, acc.: 58.59%] [G loss: 0.336391]\n",
      "epoch:23 step:22118 [D loss: 0.238150, acc.: 64.06%] [G loss: 0.302442]\n",
      "epoch:23 step:22119 [D loss: 0.232187, acc.: 57.81%] [G loss: 0.318165]\n",
      "epoch:23 step:22120 [D loss: 0.231529, acc.: 67.97%] [G loss: 0.289887]\n",
      "epoch:23 step:22121 [D loss: 0.229077, acc.: 63.28%] [G loss: 0.297296]\n",
      "epoch:23 step:22122 [D loss: 0.248796, acc.: 54.69%] [G loss: 0.305129]\n",
      "epoch:23 step:22123 [D loss: 0.225422, acc.: 66.41%] [G loss: 0.306792]\n",
      "epoch:23 step:22124 [D loss: 0.240789, acc.: 63.28%] [G loss: 0.302689]\n",
      "epoch:23 step:22125 [D loss: 0.228009, acc.: 58.59%] [G loss: 0.299302]\n",
      "epoch:23 step:22126 [D loss: 0.237965, acc.: 54.69%] [G loss: 0.277847]\n",
      "epoch:23 step:22127 [D loss: 0.227031, acc.: 60.94%] [G loss: 0.322340]\n",
      "epoch:23 step:22128 [D loss: 0.225834, acc.: 63.28%] [G loss: 0.322385]\n",
      "epoch:23 step:22129 [D loss: 0.249401, acc.: 51.56%] [G loss: 0.294902]\n",
      "epoch:23 step:22130 [D loss: 0.235799, acc.: 58.59%] [G loss: 0.320649]\n",
      "epoch:23 step:22131 [D loss: 0.259847, acc.: 48.44%] [G loss: 0.290379]\n",
      "epoch:23 step:22132 [D loss: 0.224152, acc.: 58.59%] [G loss: 0.317428]\n",
      "epoch:23 step:22133 [D loss: 0.242924, acc.: 57.81%] [G loss: 0.284973]\n",
      "epoch:23 step:22134 [D loss: 0.234230, acc.: 60.94%] [G loss: 0.320807]\n",
      "epoch:23 step:22135 [D loss: 0.231073, acc.: 60.16%] [G loss: 0.298522]\n",
      "epoch:23 step:22136 [D loss: 0.243547, acc.: 56.25%] [G loss: 0.318071]\n",
      "epoch:23 step:22137 [D loss: 0.236014, acc.: 59.38%] [G loss: 0.306219]\n",
      "epoch:23 step:22138 [D loss: 0.220976, acc.: 65.62%] [G loss: 0.300439]\n",
      "epoch:23 step:22139 [D loss: 0.271215, acc.: 42.97%] [G loss: 0.299159]\n",
      "epoch:23 step:22140 [D loss: 0.238227, acc.: 61.72%] [G loss: 0.313823]\n",
      "epoch:23 step:22141 [D loss: 0.238884, acc.: 58.59%] [G loss: 0.304825]\n",
      "epoch:23 step:22142 [D loss: 0.232588, acc.: 64.06%] [G loss: 0.279207]\n",
      "epoch:23 step:22143 [D loss: 0.250416, acc.: 52.34%] [G loss: 0.292626]\n",
      "epoch:23 step:22144 [D loss: 0.238123, acc.: 60.16%] [G loss: 0.308157]\n",
      "epoch:23 step:22145 [D loss: 0.208549, acc.: 67.19%] [G loss: 0.291081]\n",
      "epoch:23 step:22146 [D loss: 0.221287, acc.: 64.84%] [G loss: 0.299313]\n",
      "epoch:23 step:22147 [D loss: 0.243536, acc.: 56.25%] [G loss: 0.275894]\n",
      "epoch:23 step:22148 [D loss: 0.258994, acc.: 50.78%] [G loss: 0.311099]\n",
      "epoch:23 step:22149 [D loss: 0.242227, acc.: 56.25%] [G loss: 0.291339]\n",
      "epoch:23 step:22150 [D loss: 0.241341, acc.: 51.56%] [G loss: 0.269751]\n",
      "epoch:23 step:22151 [D loss: 0.240718, acc.: 57.03%] [G loss: 0.298491]\n",
      "epoch:23 step:22152 [D loss: 0.220067, acc.: 65.62%] [G loss: 0.307573]\n",
      "epoch:23 step:22153 [D loss: 0.225704, acc.: 64.06%] [G loss: 0.317954]\n",
      "epoch:23 step:22154 [D loss: 0.226926, acc.: 60.94%] [G loss: 0.315310]\n",
      "epoch:23 step:22155 [D loss: 0.255865, acc.: 53.12%] [G loss: 0.314719]\n",
      "epoch:23 step:22156 [D loss: 0.247293, acc.: 55.47%] [G loss: 0.262107]\n",
      "epoch:23 step:22157 [D loss: 0.255493, acc.: 52.34%] [G loss: 0.288254]\n",
      "epoch:23 step:22158 [D loss: 0.251356, acc.: 53.91%] [G loss: 0.309777]\n",
      "epoch:23 step:22159 [D loss: 0.239080, acc.: 60.94%] [G loss: 0.277874]\n",
      "epoch:23 step:22160 [D loss: 0.240091, acc.: 57.03%] [G loss: 0.290515]\n",
      "epoch:23 step:22161 [D loss: 0.229159, acc.: 57.81%] [G loss: 0.295065]\n",
      "epoch:23 step:22162 [D loss: 0.237090, acc.: 58.59%] [G loss: 0.302930]\n",
      "epoch:23 step:22163 [D loss: 0.259900, acc.: 53.91%] [G loss: 0.267381]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:23 step:22164 [D loss: 0.230785, acc.: 63.28%] [G loss: 0.292304]\n",
      "epoch:23 step:22165 [D loss: 0.242013, acc.: 60.94%] [G loss: 0.308541]\n",
      "epoch:23 step:22166 [D loss: 0.263174, acc.: 42.97%] [G loss: 0.274905]\n",
      "epoch:23 step:22167 [D loss: 0.228710, acc.: 61.72%] [G loss: 0.312322]\n",
      "epoch:23 step:22168 [D loss: 0.229231, acc.: 65.62%] [G loss: 0.301164]\n",
      "epoch:23 step:22169 [D loss: 0.235537, acc.: 56.25%] [G loss: 0.309042]\n",
      "epoch:23 step:22170 [D loss: 0.234217, acc.: 57.03%] [G loss: 0.309134]\n",
      "epoch:23 step:22171 [D loss: 0.236526, acc.: 57.03%] [G loss: 0.319169]\n",
      "epoch:23 step:22172 [D loss: 0.268768, acc.: 46.09%] [G loss: 0.266769]\n",
      "epoch:23 step:22173 [D loss: 0.243152, acc.: 55.47%] [G loss: 0.296957]\n",
      "epoch:23 step:22174 [D loss: 0.232979, acc.: 65.62%] [G loss: 0.309328]\n",
      "epoch:23 step:22175 [D loss: 0.247317, acc.: 53.91%] [G loss: 0.302143]\n",
      "epoch:23 step:22176 [D loss: 0.250709, acc.: 55.47%] [G loss: 0.288902]\n",
      "epoch:23 step:22177 [D loss: 0.236155, acc.: 61.72%] [G loss: 0.321130]\n",
      "epoch:23 step:22178 [D loss: 0.237744, acc.: 60.16%] [G loss: 0.305458]\n",
      "epoch:23 step:22179 [D loss: 0.235762, acc.: 56.25%] [G loss: 0.283446]\n",
      "epoch:23 step:22180 [D loss: 0.246642, acc.: 52.34%] [G loss: 0.324180]\n",
      "epoch:23 step:22181 [D loss: 0.227956, acc.: 63.28%] [G loss: 0.291804]\n",
      "epoch:23 step:22182 [D loss: 0.236619, acc.: 56.25%] [G loss: 0.307079]\n",
      "epoch:23 step:22183 [D loss: 0.245119, acc.: 59.38%] [G loss: 0.325602]\n",
      "epoch:23 step:22184 [D loss: 0.240500, acc.: 54.69%] [G loss: 0.298802]\n",
      "epoch:23 step:22185 [D loss: 0.240212, acc.: 54.69%] [G loss: 0.312170]\n",
      "epoch:23 step:22186 [D loss: 0.251935, acc.: 52.34%] [G loss: 0.316117]\n",
      "epoch:23 step:22187 [D loss: 0.231470, acc.: 63.28%] [G loss: 0.318263]\n",
      "epoch:23 step:22188 [D loss: 0.219461, acc.: 65.62%] [G loss: 0.274153]\n",
      "epoch:23 step:22189 [D loss: 0.245029, acc.: 57.03%] [G loss: 0.304752]\n",
      "epoch:23 step:22190 [D loss: 0.255232, acc.: 56.25%] [G loss: 0.313760]\n",
      "epoch:23 step:22191 [D loss: 0.229608, acc.: 62.50%] [G loss: 0.304607]\n",
      "epoch:23 step:22192 [D loss: 0.234739, acc.: 61.72%] [G loss: 0.313585]\n",
      "epoch:23 step:22193 [D loss: 0.249590, acc.: 55.47%] [G loss: 0.316233]\n",
      "epoch:23 step:22194 [D loss: 0.260643, acc.: 48.44%] [G loss: 0.315529]\n",
      "epoch:23 step:22195 [D loss: 0.243793, acc.: 56.25%] [G loss: 0.287129]\n",
      "epoch:23 step:22196 [D loss: 0.238173, acc.: 59.38%] [G loss: 0.302601]\n",
      "epoch:23 step:22197 [D loss: 0.251376, acc.: 54.69%] [G loss: 0.292890]\n",
      "epoch:23 step:22198 [D loss: 0.242692, acc.: 56.25%] [G loss: 0.307006]\n",
      "epoch:23 step:22199 [D loss: 0.258103, acc.: 51.56%] [G loss: 0.280886]\n",
      "epoch:23 step:22200 [D loss: 0.243563, acc.: 61.72%] [G loss: 0.301727]\n",
      "epoch:23 step:22201 [D loss: 0.228324, acc.: 61.72%] [G loss: 0.292503]\n",
      "epoch:23 step:22202 [D loss: 0.238532, acc.: 57.03%] [G loss: 0.298800]\n",
      "epoch:23 step:22203 [D loss: 0.244853, acc.: 54.69%] [G loss: 0.302406]\n",
      "epoch:23 step:22204 [D loss: 0.246039, acc.: 55.47%] [G loss: 0.294373]\n",
      "epoch:23 step:22205 [D loss: 0.216129, acc.: 66.41%] [G loss: 0.320586]\n",
      "epoch:23 step:22206 [D loss: 0.238365, acc.: 53.12%] [G loss: 0.314816]\n",
      "epoch:23 step:22207 [D loss: 0.240745, acc.: 60.94%] [G loss: 0.287013]\n",
      "epoch:23 step:22208 [D loss: 0.233214, acc.: 60.16%] [G loss: 0.303940]\n",
      "epoch:23 step:22209 [D loss: 0.263569, acc.: 43.75%] [G loss: 0.304766]\n",
      "epoch:23 step:22210 [D loss: 0.254167, acc.: 54.69%] [G loss: 0.328927]\n",
      "epoch:23 step:22211 [D loss: 0.236182, acc.: 56.25%] [G loss: 0.282671]\n",
      "epoch:23 step:22212 [D loss: 0.243211, acc.: 56.25%] [G loss: 0.317478]\n",
      "epoch:23 step:22213 [D loss: 0.250997, acc.: 53.91%] [G loss: 0.339877]\n",
      "epoch:23 step:22214 [D loss: 0.235344, acc.: 54.69%] [G loss: 0.317144]\n",
      "epoch:23 step:22215 [D loss: 0.259014, acc.: 51.56%] [G loss: 0.319352]\n",
      "epoch:23 step:22216 [D loss: 0.238376, acc.: 60.16%] [G loss: 0.302477]\n",
      "epoch:23 step:22217 [D loss: 0.216697, acc.: 68.75%] [G loss: 0.324562]\n",
      "epoch:23 step:22218 [D loss: 0.228186, acc.: 59.38%] [G loss: 0.313137]\n",
      "epoch:23 step:22219 [D loss: 0.261981, acc.: 50.00%] [G loss: 0.279848]\n",
      "epoch:23 step:22220 [D loss: 0.216152, acc.: 67.97%] [G loss: 0.330896]\n",
      "epoch:23 step:22221 [D loss: 0.228624, acc.: 61.72%] [G loss: 0.321329]\n",
      "epoch:23 step:22222 [D loss: 0.236386, acc.: 60.16%] [G loss: 0.327820]\n",
      "epoch:23 step:22223 [D loss: 0.248348, acc.: 50.00%] [G loss: 0.306019]\n",
      "epoch:23 step:22224 [D loss: 0.258340, acc.: 50.78%] [G loss: 0.278798]\n",
      "epoch:23 step:22225 [D loss: 0.232756, acc.: 63.28%] [G loss: 0.339940]\n",
      "epoch:23 step:22226 [D loss: 0.251605, acc.: 52.34%] [G loss: 0.290962]\n",
      "epoch:23 step:22227 [D loss: 0.227484, acc.: 62.50%] [G loss: 0.313708]\n",
      "epoch:23 step:22228 [D loss: 0.231787, acc.: 64.06%] [G loss: 0.328426]\n",
      "epoch:23 step:22229 [D loss: 0.229162, acc.: 67.97%] [G loss: 0.305488]\n",
      "epoch:23 step:22230 [D loss: 0.240447, acc.: 55.47%] [G loss: 0.302900]\n",
      "epoch:23 step:22231 [D loss: 0.241981, acc.: 59.38%] [G loss: 0.296041]\n",
      "epoch:23 step:22232 [D loss: 0.245338, acc.: 57.03%] [G loss: 0.304842]\n",
      "epoch:23 step:22233 [D loss: 0.247165, acc.: 57.03%] [G loss: 0.299893]\n",
      "epoch:23 step:22234 [D loss: 0.257371, acc.: 53.91%] [G loss: 0.289399]\n",
      "epoch:23 step:22235 [D loss: 0.228924, acc.: 57.03%] [G loss: 0.333417]\n",
      "epoch:23 step:22236 [D loss: 0.251073, acc.: 52.34%] [G loss: 0.283043]\n",
      "epoch:23 step:22237 [D loss: 0.245610, acc.: 54.69%] [G loss: 0.336308]\n",
      "epoch:23 step:22238 [D loss: 0.228131, acc.: 64.84%] [G loss: 0.316997]\n",
      "epoch:23 step:22239 [D loss: 0.221609, acc.: 69.53%] [G loss: 0.287874]\n",
      "epoch:23 step:22240 [D loss: 0.245898, acc.: 60.94%] [G loss: 0.296377]\n",
      "epoch:23 step:22241 [D loss: 0.243726, acc.: 56.25%] [G loss: 0.321597]\n",
      "epoch:23 step:22242 [D loss: 0.224668, acc.: 59.38%] [G loss: 0.290411]\n",
      "epoch:23 step:22243 [D loss: 0.246382, acc.: 62.50%] [G loss: 0.293811]\n",
      "epoch:23 step:22244 [D loss: 0.229304, acc.: 64.06%] [G loss: 0.285679]\n",
      "epoch:23 step:22245 [D loss: 0.246502, acc.: 57.03%] [G loss: 0.292878]\n",
      "epoch:23 step:22246 [D loss: 0.250308, acc.: 54.69%] [G loss: 0.292959]\n",
      "epoch:23 step:22247 [D loss: 0.239226, acc.: 55.47%] [G loss: 0.284197]\n",
      "epoch:23 step:22248 [D loss: 0.236250, acc.: 64.06%] [G loss: 0.293414]\n",
      "epoch:23 step:22249 [D loss: 0.239097, acc.: 57.03%] [G loss: 0.307765]\n",
      "epoch:23 step:22250 [D loss: 0.228679, acc.: 60.94%] [G loss: 0.292765]\n",
      "epoch:23 step:22251 [D loss: 0.229081, acc.: 58.59%] [G loss: 0.313527]\n",
      "epoch:23 step:22252 [D loss: 0.250086, acc.: 60.94%] [G loss: 0.291318]\n",
      "epoch:23 step:22253 [D loss: 0.228088, acc.: 59.38%] [G loss: 0.310897]\n",
      "epoch:23 step:22254 [D loss: 0.222113, acc.: 66.41%] [G loss: 0.309555]\n",
      "epoch:23 step:22255 [D loss: 0.242286, acc.: 60.94%] [G loss: 0.298381]\n",
      "epoch:23 step:22256 [D loss: 0.222928, acc.: 63.28%] [G loss: 0.292802]\n",
      "epoch:23 step:22257 [D loss: 0.243485, acc.: 53.12%] [G loss: 0.295934]\n",
      "epoch:23 step:22258 [D loss: 0.234715, acc.: 60.94%] [G loss: 0.294145]\n",
      "epoch:23 step:22259 [D loss: 0.244022, acc.: 58.59%] [G loss: 0.290928]\n",
      "epoch:23 step:22260 [D loss: 0.242055, acc.: 57.03%] [G loss: 0.305590]\n",
      "epoch:23 step:22261 [D loss: 0.242625, acc.: 58.59%] [G loss: 0.296803]\n",
      "epoch:23 step:22262 [D loss: 0.243326, acc.: 57.81%] [G loss: 0.309380]\n",
      "epoch:23 step:22263 [D loss: 0.244414, acc.: 57.03%] [G loss: 0.277833]\n",
      "epoch:23 step:22264 [D loss: 0.249966, acc.: 53.91%] [G loss: 0.284899]\n",
      "epoch:23 step:22265 [D loss: 0.252007, acc.: 53.12%] [G loss: 0.321012]\n",
      "epoch:23 step:22266 [D loss: 0.251908, acc.: 57.81%] [G loss: 0.290695]\n",
      "epoch:23 step:22267 [D loss: 0.249558, acc.: 55.47%] [G loss: 0.293663]\n",
      "epoch:23 step:22268 [D loss: 0.256052, acc.: 53.12%] [G loss: 0.314977]\n",
      "epoch:23 step:22269 [D loss: 0.204754, acc.: 67.97%] [G loss: 0.309824]\n",
      "epoch:23 step:22270 [D loss: 0.232963, acc.: 62.50%] [G loss: 0.351227]\n",
      "epoch:23 step:22271 [D loss: 0.241897, acc.: 57.03%] [G loss: 0.319232]\n",
      "epoch:23 step:22272 [D loss: 0.216824, acc.: 63.28%] [G loss: 0.296824]\n",
      "epoch:23 step:22273 [D loss: 0.243643, acc.: 60.16%] [G loss: 0.301816]\n",
      "epoch:23 step:22274 [D loss: 0.237869, acc.: 59.38%] [G loss: 0.289941]\n",
      "epoch:23 step:22275 [D loss: 0.232221, acc.: 60.16%] [G loss: 0.312789]\n",
      "epoch:23 step:22276 [D loss: 0.245661, acc.: 53.91%] [G loss: 0.321067]\n",
      "epoch:23 step:22277 [D loss: 0.241956, acc.: 57.03%] [G loss: 0.290397]\n",
      "epoch:23 step:22278 [D loss: 0.226472, acc.: 64.84%] [G loss: 0.322865]\n",
      "epoch:23 step:22279 [D loss: 0.234763, acc.: 62.50%] [G loss: 0.308191]\n",
      "epoch:23 step:22280 [D loss: 0.242198, acc.: 53.91%] [G loss: 0.282717]\n",
      "epoch:23 step:22281 [D loss: 0.240964, acc.: 57.81%] [G loss: 0.300938]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:23 step:22282 [D loss: 0.233320, acc.: 64.84%] [G loss: 0.303118]\n",
      "epoch:23 step:22283 [D loss: 0.228155, acc.: 63.28%] [G loss: 0.335384]\n",
      "epoch:23 step:22284 [D loss: 0.233256, acc.: 67.97%] [G loss: 0.322338]\n",
      "epoch:23 step:22285 [D loss: 0.247118, acc.: 53.91%] [G loss: 0.296575]\n",
      "epoch:23 step:22286 [D loss: 0.221211, acc.: 65.62%] [G loss: 0.337626]\n",
      "epoch:23 step:22287 [D loss: 0.248030, acc.: 50.78%] [G loss: 0.310760]\n",
      "epoch:23 step:22288 [D loss: 0.234933, acc.: 57.03%] [G loss: 0.320125]\n",
      "epoch:23 step:22289 [D loss: 0.234109, acc.: 62.50%] [G loss: 0.302758]\n",
      "epoch:23 step:22290 [D loss: 0.240921, acc.: 53.91%] [G loss: 0.295058]\n",
      "epoch:23 step:22291 [D loss: 0.226127, acc.: 66.41%] [G loss: 0.317203]\n",
      "epoch:23 step:22292 [D loss: 0.235249, acc.: 60.16%] [G loss: 0.312356]\n",
      "epoch:23 step:22293 [D loss: 0.230993, acc.: 58.59%] [G loss: 0.332135]\n",
      "epoch:23 step:22294 [D loss: 0.232909, acc.: 57.03%] [G loss: 0.315857]\n",
      "epoch:23 step:22295 [D loss: 0.215869, acc.: 64.06%] [G loss: 0.343230]\n",
      "epoch:23 step:22296 [D loss: 0.256205, acc.: 53.12%] [G loss: 0.290040]\n",
      "epoch:23 step:22297 [D loss: 0.255057, acc.: 53.12%] [G loss: 0.324798]\n",
      "epoch:23 step:22298 [D loss: 0.225622, acc.: 57.03%] [G loss: 0.334739]\n",
      "epoch:23 step:22299 [D loss: 0.243973, acc.: 53.12%] [G loss: 0.356756]\n",
      "epoch:23 step:22300 [D loss: 0.225306, acc.: 67.19%] [G loss: 0.289966]\n",
      "epoch:23 step:22301 [D loss: 0.243341, acc.: 57.03%] [G loss: 0.292352]\n",
      "epoch:23 step:22302 [D loss: 0.216273, acc.: 69.53%] [G loss: 0.284683]\n",
      "epoch:23 step:22303 [D loss: 0.230605, acc.: 60.94%] [G loss: 0.320660]\n",
      "epoch:23 step:22304 [D loss: 0.227993, acc.: 60.16%] [G loss: 0.296608]\n",
      "epoch:23 step:22305 [D loss: 0.225494, acc.: 64.06%] [G loss: 0.332067]\n",
      "epoch:23 step:22306 [D loss: 0.245791, acc.: 60.16%] [G loss: 0.289029]\n",
      "epoch:23 step:22307 [D loss: 0.239983, acc.: 60.16%] [G loss: 0.301144]\n",
      "epoch:23 step:22308 [D loss: 0.227807, acc.: 60.16%] [G loss: 0.286547]\n",
      "epoch:23 step:22309 [D loss: 0.247453, acc.: 56.25%] [G loss: 0.316089]\n",
      "epoch:23 step:22310 [D loss: 0.241265, acc.: 53.91%] [G loss: 0.296784]\n",
      "epoch:23 step:22311 [D loss: 0.225686, acc.: 70.31%] [G loss: 0.324714]\n",
      "epoch:23 step:22312 [D loss: 0.262755, acc.: 51.56%] [G loss: 0.259266]\n",
      "epoch:23 step:22313 [D loss: 0.237091, acc.: 54.69%] [G loss: 0.314283]\n",
      "epoch:23 step:22314 [D loss: 0.235624, acc.: 61.72%] [G loss: 0.302955]\n",
      "epoch:23 step:22315 [D loss: 0.229982, acc.: 62.50%] [G loss: 0.311802]\n",
      "epoch:23 step:22316 [D loss: 0.223655, acc.: 67.97%] [G loss: 0.290164]\n",
      "epoch:23 step:22317 [D loss: 0.244896, acc.: 53.91%] [G loss: 0.306137]\n",
      "epoch:23 step:22318 [D loss: 0.239494, acc.: 52.34%] [G loss: 0.276363]\n",
      "epoch:23 step:22319 [D loss: 0.241632, acc.: 56.25%] [G loss: 0.296372]\n",
      "epoch:23 step:22320 [D loss: 0.231049, acc.: 60.16%] [G loss: 0.316053]\n",
      "epoch:23 step:22321 [D loss: 0.254663, acc.: 54.69%] [G loss: 0.263458]\n",
      "epoch:23 step:22322 [D loss: 0.229690, acc.: 59.38%] [G loss: 0.297440]\n",
      "epoch:23 step:22323 [D loss: 0.246034, acc.: 59.38%] [G loss: 0.287799]\n",
      "epoch:23 step:22324 [D loss: 0.254154, acc.: 53.12%] [G loss: 0.304031]\n",
      "epoch:23 step:22325 [D loss: 0.247404, acc.: 56.25%] [G loss: 0.319495]\n",
      "epoch:23 step:22326 [D loss: 0.232645, acc.: 63.28%] [G loss: 0.293497]\n",
      "epoch:23 step:22327 [D loss: 0.231113, acc.: 62.50%] [G loss: 0.270803]\n",
      "epoch:23 step:22328 [D loss: 0.253208, acc.: 50.78%] [G loss: 0.301929]\n",
      "epoch:23 step:22329 [D loss: 0.232334, acc.: 62.50%] [G loss: 0.330670]\n",
      "epoch:23 step:22330 [D loss: 0.240016, acc.: 59.38%] [G loss: 0.289723]\n",
      "epoch:23 step:22331 [D loss: 0.246653, acc.: 55.47%] [G loss: 0.295280]\n",
      "epoch:23 step:22332 [D loss: 0.218915, acc.: 67.97%] [G loss: 0.289817]\n",
      "epoch:23 step:22333 [D loss: 0.226566, acc.: 66.41%] [G loss: 0.315083]\n",
      "epoch:23 step:22334 [D loss: 0.260004, acc.: 52.34%] [G loss: 0.274473]\n",
      "epoch:23 step:22335 [D loss: 0.236534, acc.: 57.81%] [G loss: 0.303219]\n",
      "epoch:23 step:22336 [D loss: 0.226734, acc.: 64.06%] [G loss: 0.342437]\n",
      "epoch:23 step:22337 [D loss: 0.242742, acc.: 55.47%] [G loss: 0.314086]\n",
      "epoch:23 step:22338 [D loss: 0.247871, acc.: 59.38%] [G loss: 0.269849]\n",
      "epoch:23 step:22339 [D loss: 0.260484, acc.: 47.66%] [G loss: 0.306402]\n",
      "epoch:23 step:22340 [D loss: 0.233382, acc.: 58.59%] [G loss: 0.283601]\n",
      "epoch:23 step:22341 [D loss: 0.236097, acc.: 58.59%] [G loss: 0.289203]\n",
      "epoch:23 step:22342 [D loss: 0.230921, acc.: 62.50%] [G loss: 0.314875]\n",
      "epoch:23 step:22343 [D loss: 0.246519, acc.: 54.69%] [G loss: 0.319738]\n",
      "epoch:23 step:22344 [D loss: 0.238046, acc.: 62.50%] [G loss: 0.298454]\n",
      "epoch:23 step:22345 [D loss: 0.231842, acc.: 60.16%] [G loss: 0.316685]\n",
      "epoch:23 step:22346 [D loss: 0.228373, acc.: 58.59%] [G loss: 0.329414]\n",
      "epoch:23 step:22347 [D loss: 0.226404, acc.: 56.25%] [G loss: 0.338005]\n",
      "epoch:23 step:22348 [D loss: 0.236118, acc.: 56.25%] [G loss: 0.326036]\n",
      "epoch:23 step:22349 [D loss: 0.254505, acc.: 50.78%] [G loss: 0.308358]\n",
      "epoch:23 step:22350 [D loss: 0.251856, acc.: 55.47%] [G loss: 0.293319]\n",
      "epoch:23 step:22351 [D loss: 0.245741, acc.: 60.16%] [G loss: 0.278439]\n",
      "epoch:23 step:22352 [D loss: 0.220355, acc.: 70.31%] [G loss: 0.304572]\n",
      "epoch:23 step:22353 [D loss: 0.247364, acc.: 58.59%] [G loss: 0.286759]\n",
      "epoch:23 step:22354 [D loss: 0.245450, acc.: 57.03%] [G loss: 0.300164]\n",
      "epoch:23 step:22355 [D loss: 0.238473, acc.: 59.38%] [G loss: 0.310394]\n",
      "epoch:23 step:22356 [D loss: 0.224088, acc.: 64.84%] [G loss: 0.292629]\n",
      "epoch:23 step:22357 [D loss: 0.243654, acc.: 55.47%] [G loss: 0.318025]\n",
      "epoch:23 step:22358 [D loss: 0.234979, acc.: 64.06%] [G loss: 0.304625]\n",
      "epoch:23 step:22359 [D loss: 0.221019, acc.: 65.62%] [G loss: 0.302994]\n",
      "epoch:23 step:22360 [D loss: 0.233894, acc.: 61.72%] [G loss: 0.297733]\n",
      "epoch:23 step:22361 [D loss: 0.235791, acc.: 58.59%] [G loss: 0.286443]\n",
      "epoch:23 step:22362 [D loss: 0.233174, acc.: 63.28%] [G loss: 0.332562]\n",
      "epoch:23 step:22363 [D loss: 0.229770, acc.: 64.84%] [G loss: 0.283625]\n",
      "epoch:23 step:22364 [D loss: 0.236309, acc.: 58.59%] [G loss: 0.306041]\n",
      "epoch:23 step:22365 [D loss: 0.235121, acc.: 60.16%] [G loss: 0.314670]\n",
      "epoch:23 step:22366 [D loss: 0.224778, acc.: 65.62%] [G loss: 0.301784]\n",
      "epoch:23 step:22367 [D loss: 0.225151, acc.: 62.50%] [G loss: 0.283698]\n",
      "epoch:23 step:22368 [D loss: 0.254490, acc.: 59.38%] [G loss: 0.314630]\n",
      "epoch:23 step:22369 [D loss: 0.229905, acc.: 63.28%] [G loss: 0.286318]\n",
      "epoch:23 step:22370 [D loss: 0.266227, acc.: 49.22%] [G loss: 0.291879]\n",
      "epoch:23 step:22371 [D loss: 0.248985, acc.: 49.22%] [G loss: 0.295276]\n",
      "epoch:23 step:22372 [D loss: 0.249303, acc.: 53.91%] [G loss: 0.309048]\n",
      "epoch:23 step:22373 [D loss: 0.249832, acc.: 57.81%] [G loss: 0.302767]\n",
      "epoch:23 step:22374 [D loss: 0.231530, acc.: 62.50%] [G loss: 0.313262]\n",
      "epoch:23 step:22375 [D loss: 0.233911, acc.: 56.25%] [G loss: 0.297171]\n",
      "epoch:23 step:22376 [D loss: 0.227879, acc.: 59.38%] [G loss: 0.289553]\n",
      "epoch:23 step:22377 [D loss: 0.235100, acc.: 55.47%] [G loss: 0.325876]\n",
      "epoch:23 step:22378 [D loss: 0.237504, acc.: 59.38%] [G loss: 0.307166]\n",
      "epoch:23 step:22379 [D loss: 0.230333, acc.: 58.59%] [G loss: 0.317668]\n",
      "epoch:23 step:22380 [D loss: 0.237160, acc.: 55.47%] [G loss: 0.305749]\n",
      "epoch:23 step:22381 [D loss: 0.233206, acc.: 60.94%] [G loss: 0.312004]\n",
      "epoch:23 step:22382 [D loss: 0.242779, acc.: 53.91%] [G loss: 0.291754]\n",
      "epoch:23 step:22383 [D loss: 0.234003, acc.: 62.50%] [G loss: 0.316853]\n",
      "epoch:23 step:22384 [D loss: 0.225830, acc.: 62.50%] [G loss: 0.289388]\n",
      "epoch:23 step:22385 [D loss: 0.249306, acc.: 53.12%] [G loss: 0.276842]\n",
      "epoch:23 step:22386 [D loss: 0.242555, acc.: 59.38%] [G loss: 0.306340]\n",
      "epoch:23 step:22387 [D loss: 0.232619, acc.: 58.59%] [G loss: 0.303954]\n",
      "epoch:23 step:22388 [D loss: 0.223358, acc.: 64.84%] [G loss: 0.320335]\n",
      "epoch:23 step:22389 [D loss: 0.256872, acc.: 54.69%] [G loss: 0.277542]\n",
      "epoch:23 step:22390 [D loss: 0.241234, acc.: 55.47%] [G loss: 0.300393]\n",
      "epoch:23 step:22391 [D loss: 0.237737, acc.: 57.03%] [G loss: 0.290367]\n",
      "epoch:23 step:22392 [D loss: 0.238865, acc.: 57.03%] [G loss: 0.300253]\n",
      "epoch:23 step:22393 [D loss: 0.247954, acc.: 59.38%] [G loss: 0.298019]\n",
      "epoch:23 step:22394 [D loss: 0.234568, acc.: 59.38%] [G loss: 0.323167]\n",
      "epoch:23 step:22395 [D loss: 0.259995, acc.: 55.47%] [G loss: 0.311775]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:23 step:22396 [D loss: 0.248674, acc.: 53.91%] [G loss: 0.288346]\n",
      "epoch:23 step:22397 [D loss: 0.253501, acc.: 57.81%] [G loss: 0.293580]\n",
      "epoch:23 step:22398 [D loss: 0.224600, acc.: 60.94%] [G loss: 0.319439]\n",
      "epoch:23 step:22399 [D loss: 0.239806, acc.: 57.03%] [G loss: 0.296544]\n",
      "epoch:23 step:22400 [D loss: 0.238240, acc.: 53.12%] [G loss: 0.324026]\n",
      "epoch:23 step:22401 [D loss: 0.230049, acc.: 64.06%] [G loss: 0.303425]\n",
      "epoch:23 step:22402 [D loss: 0.259270, acc.: 53.12%] [G loss: 0.275172]\n",
      "epoch:23 step:22403 [D loss: 0.237749, acc.: 57.03%] [G loss: 0.310431]\n",
      "epoch:23 step:22404 [D loss: 0.212010, acc.: 65.62%] [G loss: 0.313827]\n",
      "epoch:23 step:22405 [D loss: 0.241760, acc.: 55.47%] [G loss: 0.304154]\n",
      "epoch:23 step:22406 [D loss: 0.266048, acc.: 48.44%] [G loss: 0.304822]\n",
      "epoch:23 step:22407 [D loss: 0.222753, acc.: 61.72%] [G loss: 0.305167]\n",
      "epoch:23 step:22408 [D loss: 0.256684, acc.: 49.22%] [G loss: 0.309545]\n",
      "epoch:23 step:22409 [D loss: 0.244887, acc.: 53.12%] [G loss: 0.301365]\n",
      "epoch:23 step:22410 [D loss: 0.257342, acc.: 49.22%] [G loss: 0.312874]\n",
      "epoch:23 step:22411 [D loss: 0.235182, acc.: 61.72%] [G loss: 0.302153]\n",
      "epoch:23 step:22412 [D loss: 0.235528, acc.: 58.59%] [G loss: 0.295623]\n",
      "epoch:23 step:22413 [D loss: 0.252880, acc.: 53.91%] [G loss: 0.309090]\n",
      "epoch:23 step:22414 [D loss: 0.262912, acc.: 50.78%] [G loss: 0.293997]\n",
      "epoch:23 step:22415 [D loss: 0.227778, acc.: 61.72%] [G loss: 0.303723]\n",
      "epoch:23 step:22416 [D loss: 0.243938, acc.: 60.16%] [G loss: 0.292873]\n",
      "epoch:23 step:22417 [D loss: 0.235690, acc.: 58.59%] [G loss: 0.282787]\n",
      "epoch:23 step:22418 [D loss: 0.274246, acc.: 44.53%] [G loss: 0.269366]\n",
      "epoch:23 step:22419 [D loss: 0.221889, acc.: 67.19%] [G loss: 0.307315]\n",
      "epoch:23 step:22420 [D loss: 0.234863, acc.: 58.59%] [G loss: 0.276370]\n",
      "epoch:23 step:22421 [D loss: 0.237565, acc.: 57.81%] [G loss: 0.312288]\n",
      "epoch:23 step:22422 [D loss: 0.236792, acc.: 59.38%] [G loss: 0.308574]\n",
      "epoch:23 step:22423 [D loss: 0.234854, acc.: 60.16%] [G loss: 0.310769]\n",
      "epoch:23 step:22424 [D loss: 0.224951, acc.: 63.28%] [G loss: 0.327748]\n",
      "epoch:23 step:22425 [D loss: 0.232736, acc.: 67.19%] [G loss: 0.326977]\n",
      "epoch:23 step:22426 [D loss: 0.219443, acc.: 64.06%] [G loss: 0.316029]\n",
      "epoch:23 step:22427 [D loss: 0.232823, acc.: 58.59%] [G loss: 0.299448]\n",
      "epoch:23 step:22428 [D loss: 0.238241, acc.: 58.59%] [G loss: 0.312117]\n",
      "epoch:23 step:22429 [D loss: 0.235107, acc.: 60.94%] [G loss: 0.309125]\n",
      "epoch:23 step:22430 [D loss: 0.221494, acc.: 67.19%] [G loss: 0.304828]\n",
      "epoch:23 step:22431 [D loss: 0.248375, acc.: 58.59%] [G loss: 0.301744]\n",
      "epoch:23 step:22432 [D loss: 0.239571, acc.: 57.03%] [G loss: 0.328693]\n",
      "epoch:23 step:22433 [D loss: 0.242187, acc.: 56.25%] [G loss: 0.301653]\n",
      "epoch:23 step:22434 [D loss: 0.237563, acc.: 61.72%] [G loss: 0.306838]\n",
      "epoch:23 step:22435 [D loss: 0.232032, acc.: 56.25%] [G loss: 0.305496]\n",
      "epoch:23 step:22436 [D loss: 0.229982, acc.: 62.50%] [G loss: 0.290082]\n",
      "epoch:23 step:22437 [D loss: 0.230746, acc.: 60.94%] [G loss: 0.291724]\n",
      "epoch:23 step:22438 [D loss: 0.242645, acc.: 60.16%] [G loss: 0.302627]\n",
      "epoch:23 step:22439 [D loss: 0.233823, acc.: 58.59%] [G loss: 0.297818]\n",
      "epoch:23 step:22440 [D loss: 0.231415, acc.: 61.72%] [G loss: 0.313269]\n",
      "epoch:23 step:22441 [D loss: 0.242667, acc.: 57.03%] [G loss: 0.309592]\n",
      "epoch:23 step:22442 [D loss: 0.258976, acc.: 52.34%] [G loss: 0.280792]\n",
      "epoch:23 step:22443 [D loss: 0.240216, acc.: 57.03%] [G loss: 0.296457]\n",
      "epoch:23 step:22444 [D loss: 0.241198, acc.: 57.81%] [G loss: 0.320521]\n",
      "epoch:23 step:22445 [D loss: 0.246575, acc.: 57.81%] [G loss: 0.292917]\n",
      "epoch:23 step:22446 [D loss: 0.248134, acc.: 53.91%] [G loss: 0.296847]\n",
      "epoch:23 step:22447 [D loss: 0.218862, acc.: 61.72%] [G loss: 0.290327]\n",
      "epoch:23 step:22448 [D loss: 0.230905, acc.: 64.84%] [G loss: 0.297563]\n",
      "epoch:23 step:22449 [D loss: 0.229252, acc.: 64.06%] [G loss: 0.302854]\n",
      "epoch:23 step:22450 [D loss: 0.267776, acc.: 49.22%] [G loss: 0.301217]\n",
      "epoch:23 step:22451 [D loss: 0.234956, acc.: 64.06%] [G loss: 0.295735]\n",
      "epoch:23 step:22452 [D loss: 0.244371, acc.: 60.16%] [G loss: 0.311108]\n",
      "epoch:23 step:22453 [D loss: 0.241128, acc.: 61.72%] [G loss: 0.342178]\n",
      "epoch:23 step:22454 [D loss: 0.229948, acc.: 67.97%] [G loss: 0.300880]\n",
      "epoch:23 step:22455 [D loss: 0.226291, acc.: 61.72%] [G loss: 0.291566]\n",
      "epoch:23 step:22456 [D loss: 0.255373, acc.: 48.44%] [G loss: 0.306530]\n",
      "epoch:23 step:22457 [D loss: 0.254666, acc.: 51.56%] [G loss: 0.297839]\n",
      "epoch:23 step:22458 [D loss: 0.253228, acc.: 53.12%] [G loss: 0.302283]\n",
      "epoch:23 step:22459 [D loss: 0.254491, acc.: 50.78%] [G loss: 0.291456]\n",
      "epoch:23 step:22460 [D loss: 0.256543, acc.: 53.12%] [G loss: 0.318036]\n",
      "epoch:23 step:22461 [D loss: 0.256238, acc.: 53.91%] [G loss: 0.305114]\n",
      "epoch:23 step:22462 [D loss: 0.232439, acc.: 58.59%] [G loss: 0.318619]\n",
      "epoch:23 step:22463 [D loss: 0.249697, acc.: 53.12%] [G loss: 0.282088]\n",
      "epoch:23 step:22464 [D loss: 0.234694, acc.: 60.94%] [G loss: 0.308449]\n",
      "epoch:23 step:22465 [D loss: 0.242961, acc.: 52.34%] [G loss: 0.281506]\n",
      "epoch:23 step:22466 [D loss: 0.233936, acc.: 60.16%] [G loss: 0.302669]\n",
      "epoch:23 step:22467 [D loss: 0.225450, acc.: 63.28%] [G loss: 0.328355]\n",
      "epoch:23 step:22468 [D loss: 0.223792, acc.: 64.84%] [G loss: 0.299058]\n",
      "epoch:23 step:22469 [D loss: 0.235951, acc.: 59.38%] [G loss: 0.317749]\n",
      "epoch:23 step:22470 [D loss: 0.244419, acc.: 53.91%] [G loss: 0.293494]\n",
      "epoch:23 step:22471 [D loss: 0.250683, acc.: 52.34%] [G loss: 0.301939]\n",
      "epoch:23 step:22472 [D loss: 0.235636, acc.: 57.81%] [G loss: 0.286196]\n",
      "epoch:23 step:22473 [D loss: 0.239478, acc.: 57.81%] [G loss: 0.296061]\n",
      "epoch:23 step:22474 [D loss: 0.241511, acc.: 58.59%] [G loss: 0.345438]\n",
      "epoch:23 step:22475 [D loss: 0.239136, acc.: 52.34%] [G loss: 0.313146]\n",
      "epoch:23 step:22476 [D loss: 0.238795, acc.: 57.81%] [G loss: 0.281632]\n",
      "epoch:23 step:22477 [D loss: 0.241416, acc.: 60.16%] [G loss: 0.281398]\n",
      "epoch:23 step:22478 [D loss: 0.236099, acc.: 60.16%] [G loss: 0.295651]\n",
      "epoch:23 step:22479 [D loss: 0.237740, acc.: 65.62%] [G loss: 0.303314]\n",
      "epoch:23 step:22480 [D loss: 0.233191, acc.: 60.16%] [G loss: 0.313959]\n",
      "epoch:23 step:22481 [D loss: 0.235518, acc.: 61.72%] [G loss: 0.295491]\n",
      "epoch:23 step:22482 [D loss: 0.222157, acc.: 69.53%] [G loss: 0.320260]\n",
      "epoch:23 step:22483 [D loss: 0.242705, acc.: 57.03%] [G loss: 0.279858]\n",
      "epoch:23 step:22484 [D loss: 0.242107, acc.: 57.03%] [G loss: 0.294309]\n",
      "epoch:23 step:22485 [D loss: 0.234983, acc.: 61.72%] [G loss: 0.314288]\n",
      "epoch:23 step:22486 [D loss: 0.250768, acc.: 54.69%] [G loss: 0.309773]\n",
      "epoch:23 step:22487 [D loss: 0.230982, acc.: 64.84%] [G loss: 0.290537]\n",
      "epoch:23 step:22488 [D loss: 0.258761, acc.: 54.69%] [G loss: 0.275771]\n",
      "epoch:24 step:22489 [D loss: 0.223499, acc.: 63.28%] [G loss: 0.318200]\n",
      "epoch:24 step:22490 [D loss: 0.249236, acc.: 58.59%] [G loss: 0.316190]\n",
      "epoch:24 step:22491 [D loss: 0.245018, acc.: 50.00%] [G loss: 0.271751]\n",
      "epoch:24 step:22492 [D loss: 0.229056, acc.: 62.50%] [G loss: 0.305077]\n",
      "epoch:24 step:22493 [D loss: 0.253448, acc.: 54.69%] [G loss: 0.297473]\n",
      "epoch:24 step:22494 [D loss: 0.250283, acc.: 53.91%] [G loss: 0.301302]\n",
      "epoch:24 step:22495 [D loss: 0.254973, acc.: 55.47%] [G loss: 0.299289]\n",
      "epoch:24 step:22496 [D loss: 0.232620, acc.: 57.81%] [G loss: 0.281249]\n",
      "epoch:24 step:22497 [D loss: 0.241674, acc.: 57.81%] [G loss: 0.319856]\n",
      "epoch:24 step:22498 [D loss: 0.256785, acc.: 54.69%] [G loss: 0.284447]\n",
      "epoch:24 step:22499 [D loss: 0.237337, acc.: 60.16%] [G loss: 0.303867]\n",
      "epoch:24 step:22500 [D loss: 0.247933, acc.: 58.59%] [G loss: 0.286394]\n",
      "epoch:24 step:22501 [D loss: 0.238712, acc.: 60.16%] [G loss: 0.308616]\n",
      "epoch:24 step:22502 [D loss: 0.236989, acc.: 57.03%] [G loss: 0.298232]\n",
      "epoch:24 step:22503 [D loss: 0.235976, acc.: 60.94%] [G loss: 0.291125]\n",
      "epoch:24 step:22504 [D loss: 0.246398, acc.: 55.47%] [G loss: 0.308580]\n",
      "epoch:24 step:22505 [D loss: 0.226609, acc.: 60.16%] [G loss: 0.331146]\n",
      "epoch:24 step:22506 [D loss: 0.252524, acc.: 57.81%] [G loss: 0.318172]\n",
      "epoch:24 step:22507 [D loss: 0.250120, acc.: 50.00%] [G loss: 0.299610]\n",
      "epoch:24 step:22508 [D loss: 0.245767, acc.: 57.03%] [G loss: 0.296063]\n",
      "epoch:24 step:22509 [D loss: 0.233531, acc.: 60.16%] [G loss: 0.287203]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:24 step:22510 [D loss: 0.230033, acc.: 59.38%] [G loss: 0.294228]\n",
      "epoch:24 step:22511 [D loss: 0.246167, acc.: 58.59%] [G loss: 0.273744]\n",
      "epoch:24 step:22512 [D loss: 0.223767, acc.: 65.62%] [G loss: 0.296142]\n",
      "epoch:24 step:22513 [D loss: 0.237059, acc.: 59.38%] [G loss: 0.267178]\n",
      "epoch:24 step:22514 [D loss: 0.237405, acc.: 52.34%] [G loss: 0.294726]\n",
      "epoch:24 step:22515 [D loss: 0.227381, acc.: 64.06%] [G loss: 0.272874]\n",
      "epoch:24 step:22516 [D loss: 0.237855, acc.: 54.69%] [G loss: 0.297971]\n",
      "epoch:24 step:22517 [D loss: 0.245237, acc.: 50.00%] [G loss: 0.284937]\n",
      "epoch:24 step:22518 [D loss: 0.238494, acc.: 57.03%] [G loss: 0.302558]\n",
      "epoch:24 step:22519 [D loss: 0.240033, acc.: 55.47%] [G loss: 0.308364]\n",
      "epoch:24 step:22520 [D loss: 0.226677, acc.: 63.28%] [G loss: 0.305933]\n",
      "epoch:24 step:22521 [D loss: 0.249557, acc.: 51.56%] [G loss: 0.342417]\n",
      "epoch:24 step:22522 [D loss: 0.232359, acc.: 57.03%] [G loss: 0.311725]\n",
      "epoch:24 step:22523 [D loss: 0.225153, acc.: 64.06%] [G loss: 0.309245]\n",
      "epoch:24 step:22524 [D loss: 0.238553, acc.: 59.38%] [G loss: 0.294525]\n",
      "epoch:24 step:22525 [D loss: 0.235395, acc.: 59.38%] [G loss: 0.280562]\n",
      "epoch:24 step:22526 [D loss: 0.234096, acc.: 59.38%] [G loss: 0.310509]\n",
      "epoch:24 step:22527 [D loss: 0.231807, acc.: 56.25%] [G loss: 0.301888]\n",
      "epoch:24 step:22528 [D loss: 0.247046, acc.: 56.25%] [G loss: 0.319808]\n",
      "epoch:24 step:22529 [D loss: 0.242163, acc.: 57.03%] [G loss: 0.298808]\n",
      "epoch:24 step:22530 [D loss: 0.235597, acc.: 55.47%] [G loss: 0.324547]\n",
      "epoch:24 step:22531 [D loss: 0.228364, acc.: 65.62%] [G loss: 0.304019]\n",
      "epoch:24 step:22532 [D loss: 0.220166, acc.: 64.06%] [G loss: 0.311998]\n",
      "epoch:24 step:22533 [D loss: 0.243126, acc.: 50.00%] [G loss: 0.318809]\n",
      "epoch:24 step:22534 [D loss: 0.248366, acc.: 53.91%] [G loss: 0.330911]\n",
      "epoch:24 step:22535 [D loss: 0.235368, acc.: 58.59%] [G loss: 0.316316]\n",
      "epoch:24 step:22536 [D loss: 0.240831, acc.: 52.34%] [G loss: 0.312720]\n",
      "epoch:24 step:22537 [D loss: 0.230445, acc.: 64.06%] [G loss: 0.305180]\n",
      "epoch:24 step:22538 [D loss: 0.247873, acc.: 56.25%] [G loss: 0.311453]\n",
      "epoch:24 step:22539 [D loss: 0.239662, acc.: 60.16%] [G loss: 0.280956]\n",
      "epoch:24 step:22540 [D loss: 0.232024, acc.: 64.06%] [G loss: 0.250652]\n",
      "epoch:24 step:22541 [D loss: 0.251798, acc.: 46.88%] [G loss: 0.315786]\n",
      "epoch:24 step:22542 [D loss: 0.218757, acc.: 65.62%] [G loss: 0.308010]\n",
      "epoch:24 step:22543 [D loss: 0.231375, acc.: 63.28%] [G loss: 0.267999]\n",
      "epoch:24 step:22544 [D loss: 0.251597, acc.: 57.03%] [G loss: 0.283748]\n",
      "epoch:24 step:22545 [D loss: 0.235387, acc.: 60.16%] [G loss: 0.327298]\n",
      "epoch:24 step:22546 [D loss: 0.252612, acc.: 50.00%] [G loss: 0.296350]\n",
      "epoch:24 step:22547 [D loss: 0.246166, acc.: 53.91%] [G loss: 0.286126]\n",
      "epoch:24 step:22548 [D loss: 0.225122, acc.: 62.50%] [G loss: 0.298017]\n",
      "epoch:24 step:22549 [D loss: 0.233999, acc.: 60.16%] [G loss: 0.319688]\n",
      "epoch:24 step:22550 [D loss: 0.230451, acc.: 58.59%] [G loss: 0.313233]\n",
      "epoch:24 step:22551 [D loss: 0.234579, acc.: 60.94%] [G loss: 0.297892]\n",
      "epoch:24 step:22552 [D loss: 0.235572, acc.: 60.16%] [G loss: 0.294690]\n",
      "epoch:24 step:22553 [D loss: 0.224817, acc.: 64.84%] [G loss: 0.289590]\n",
      "epoch:24 step:22554 [D loss: 0.271460, acc.: 50.78%] [G loss: 0.281285]\n",
      "epoch:24 step:22555 [D loss: 0.257790, acc.: 55.47%] [G loss: 0.298826]\n",
      "epoch:24 step:22556 [D loss: 0.241698, acc.: 56.25%] [G loss: 0.311653]\n",
      "epoch:24 step:22557 [D loss: 0.246693, acc.: 58.59%] [G loss: 0.296983]\n",
      "epoch:24 step:22558 [D loss: 0.240907, acc.: 58.59%] [G loss: 0.294799]\n",
      "epoch:24 step:22559 [D loss: 0.240663, acc.: 54.69%] [G loss: 0.307051]\n",
      "epoch:24 step:22560 [D loss: 0.230477, acc.: 61.72%] [G loss: 0.304988]\n",
      "epoch:24 step:22561 [D loss: 0.245902, acc.: 55.47%] [G loss: 0.283689]\n",
      "epoch:24 step:22562 [D loss: 0.220027, acc.: 63.28%] [G loss: 0.302489]\n",
      "epoch:24 step:22563 [D loss: 0.244757, acc.: 57.81%] [G loss: 0.278550]\n",
      "epoch:24 step:22564 [D loss: 0.226270, acc.: 57.81%] [G loss: 0.335419]\n",
      "epoch:24 step:22565 [D loss: 0.235530, acc.: 59.38%] [G loss: 0.313015]\n",
      "epoch:24 step:22566 [D loss: 0.221884, acc.: 63.28%] [G loss: 0.310831]\n",
      "epoch:24 step:22567 [D loss: 0.242740, acc.: 58.59%] [G loss: 0.304426]\n",
      "epoch:24 step:22568 [D loss: 0.244791, acc.: 58.59%] [G loss: 0.308048]\n",
      "epoch:24 step:22569 [D loss: 0.246389, acc.: 53.91%] [G loss: 0.287630]\n",
      "epoch:24 step:22570 [D loss: 0.233200, acc.: 61.72%] [G loss: 0.301698]\n",
      "epoch:24 step:22571 [D loss: 0.243970, acc.: 55.47%] [G loss: 0.312040]\n",
      "epoch:24 step:22572 [D loss: 0.248911, acc.: 52.34%] [G loss: 0.318074]\n",
      "epoch:24 step:22573 [D loss: 0.244493, acc.: 51.56%] [G loss: 0.291050]\n",
      "epoch:24 step:22574 [D loss: 0.238852, acc.: 61.72%] [G loss: 0.304763]\n",
      "epoch:24 step:22575 [D loss: 0.233367, acc.: 63.28%] [G loss: 0.306889]\n",
      "epoch:24 step:22576 [D loss: 0.260288, acc.: 47.66%] [G loss: 0.327937]\n",
      "epoch:24 step:22577 [D loss: 0.237296, acc.: 64.06%] [G loss: 0.320850]\n",
      "epoch:24 step:22578 [D loss: 0.232501, acc.: 64.06%] [G loss: 0.279348]\n",
      "epoch:24 step:22579 [D loss: 0.229903, acc.: 57.81%] [G loss: 0.281605]\n",
      "epoch:24 step:22580 [D loss: 0.233570, acc.: 59.38%] [G loss: 0.293128]\n",
      "epoch:24 step:22581 [D loss: 0.237199, acc.: 59.38%] [G loss: 0.293524]\n",
      "epoch:24 step:22582 [D loss: 0.230736, acc.: 60.94%] [G loss: 0.291540]\n",
      "epoch:24 step:22583 [D loss: 0.255018, acc.: 51.56%] [G loss: 0.308304]\n",
      "epoch:24 step:22584 [D loss: 0.224589, acc.: 63.28%] [G loss: 0.292958]\n",
      "epoch:24 step:22585 [D loss: 0.239633, acc.: 60.94%] [G loss: 0.313838]\n",
      "epoch:24 step:22586 [D loss: 0.236077, acc.: 64.06%] [G loss: 0.307039]\n",
      "epoch:24 step:22587 [D loss: 0.248367, acc.: 53.91%] [G loss: 0.287315]\n",
      "epoch:24 step:22588 [D loss: 0.235927, acc.: 61.72%] [G loss: 0.307276]\n",
      "epoch:24 step:22589 [D loss: 0.240480, acc.: 53.12%] [G loss: 0.291387]\n",
      "epoch:24 step:22590 [D loss: 0.263890, acc.: 45.31%] [G loss: 0.311909]\n",
      "epoch:24 step:22591 [D loss: 0.228803, acc.: 64.06%] [G loss: 0.293792]\n",
      "epoch:24 step:22592 [D loss: 0.230521, acc.: 61.72%] [G loss: 0.314383]\n",
      "epoch:24 step:22593 [D loss: 0.229037, acc.: 60.16%] [G loss: 0.315142]\n",
      "epoch:24 step:22594 [D loss: 0.233441, acc.: 59.38%] [G loss: 0.300206]\n",
      "epoch:24 step:22595 [D loss: 0.220258, acc.: 68.75%] [G loss: 0.315693]\n",
      "epoch:24 step:22596 [D loss: 0.233447, acc.: 60.16%] [G loss: 0.313464]\n",
      "epoch:24 step:22597 [D loss: 0.252522, acc.: 51.56%] [G loss: 0.293758]\n",
      "epoch:24 step:22598 [D loss: 0.260445, acc.: 46.09%] [G loss: 0.291789]\n",
      "epoch:24 step:22599 [D loss: 0.232188, acc.: 60.94%] [G loss: 0.277822]\n",
      "epoch:24 step:22600 [D loss: 0.228311, acc.: 67.19%] [G loss: 0.310423]\n",
      "epoch:24 step:22601 [D loss: 0.219273, acc.: 70.31%] [G loss: 0.305786]\n",
      "epoch:24 step:22602 [D loss: 0.232808, acc.: 59.38%] [G loss: 0.316051]\n",
      "epoch:24 step:22603 [D loss: 0.250279, acc.: 57.03%] [G loss: 0.307929]\n",
      "epoch:24 step:22604 [D loss: 0.229346, acc.: 67.19%] [G loss: 0.311308]\n",
      "epoch:24 step:22605 [D loss: 0.230976, acc.: 58.59%] [G loss: 0.300757]\n",
      "epoch:24 step:22606 [D loss: 0.232703, acc.: 64.06%] [G loss: 0.308369]\n",
      "epoch:24 step:22607 [D loss: 0.242404, acc.: 56.25%] [G loss: 0.300805]\n",
      "epoch:24 step:22608 [D loss: 0.246086, acc.: 49.22%] [G loss: 0.324551]\n",
      "epoch:24 step:22609 [D loss: 0.235531, acc.: 60.16%] [G loss: 0.308365]\n",
      "epoch:24 step:22610 [D loss: 0.234482, acc.: 60.94%] [G loss: 0.314577]\n",
      "epoch:24 step:22611 [D loss: 0.231719, acc.: 56.25%] [G loss: 0.321116]\n",
      "epoch:24 step:22612 [D loss: 0.242385, acc.: 54.69%] [G loss: 0.284611]\n",
      "epoch:24 step:22613 [D loss: 0.233807, acc.: 59.38%] [G loss: 0.306026]\n",
      "epoch:24 step:22614 [D loss: 0.243076, acc.: 60.94%] [G loss: 0.295760]\n",
      "epoch:24 step:22615 [D loss: 0.235324, acc.: 60.94%] [G loss: 0.320594]\n",
      "epoch:24 step:22616 [D loss: 0.230681, acc.: 57.81%] [G loss: 0.298023]\n",
      "epoch:24 step:22617 [D loss: 0.217335, acc.: 67.19%] [G loss: 0.315727]\n",
      "epoch:24 step:22618 [D loss: 0.238675, acc.: 58.59%] [G loss: 0.299202]\n",
      "epoch:24 step:22619 [D loss: 0.237168, acc.: 57.81%] [G loss: 0.299517]\n",
      "epoch:24 step:22620 [D loss: 0.236504, acc.: 58.59%] [G loss: 0.302603]\n",
      "epoch:24 step:22621 [D loss: 0.241627, acc.: 65.62%] [G loss: 0.323053]\n",
      "epoch:24 step:22622 [D loss: 0.245012, acc.: 59.38%] [G loss: 0.305200]\n",
      "epoch:24 step:22623 [D loss: 0.234989, acc.: 55.47%] [G loss: 0.288039]\n",
      "epoch:24 step:22624 [D loss: 0.251232, acc.: 51.56%] [G loss: 0.285122]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:24 step:22625 [D loss: 0.250593, acc.: 52.34%] [G loss: 0.286120]\n",
      "epoch:24 step:22626 [D loss: 0.240610, acc.: 61.72%] [G loss: 0.291381]\n",
      "epoch:24 step:22627 [D loss: 0.231887, acc.: 60.94%] [G loss: 0.268640]\n",
      "epoch:24 step:22628 [D loss: 0.241118, acc.: 58.59%] [G loss: 0.309433]\n",
      "epoch:24 step:22629 [D loss: 0.259827, acc.: 50.00%] [G loss: 0.303326]\n",
      "epoch:24 step:22630 [D loss: 0.241947, acc.: 59.38%] [G loss: 0.290347]\n",
      "epoch:24 step:22631 [D loss: 0.237831, acc.: 61.72%] [G loss: 0.295115]\n",
      "epoch:24 step:22632 [D loss: 0.238698, acc.: 64.84%] [G loss: 0.286355]\n",
      "epoch:24 step:22633 [D loss: 0.232520, acc.: 58.59%] [G loss: 0.301834]\n",
      "epoch:24 step:22634 [D loss: 0.228882, acc.: 63.28%] [G loss: 0.310914]\n",
      "epoch:24 step:22635 [D loss: 0.246227, acc.: 60.94%] [G loss: 0.338731]\n",
      "epoch:24 step:22636 [D loss: 0.216476, acc.: 65.62%] [G loss: 0.322546]\n",
      "epoch:24 step:22637 [D loss: 0.234793, acc.: 58.59%] [G loss: 0.295099]\n",
      "epoch:24 step:22638 [D loss: 0.222734, acc.: 65.62%] [G loss: 0.317807]\n",
      "epoch:24 step:22639 [D loss: 0.252663, acc.: 53.91%] [G loss: 0.303744]\n",
      "epoch:24 step:22640 [D loss: 0.251495, acc.: 51.56%] [G loss: 0.277923]\n",
      "epoch:24 step:22641 [D loss: 0.231404, acc.: 59.38%] [G loss: 0.307449]\n",
      "epoch:24 step:22642 [D loss: 0.231366, acc.: 59.38%] [G loss: 0.289462]\n",
      "epoch:24 step:22643 [D loss: 0.239443, acc.: 60.16%] [G loss: 0.320488]\n",
      "epoch:24 step:22644 [D loss: 0.241169, acc.: 55.47%] [G loss: 0.299818]\n",
      "epoch:24 step:22645 [D loss: 0.231286, acc.: 59.38%] [G loss: 0.284901]\n",
      "epoch:24 step:22646 [D loss: 0.223903, acc.: 61.72%] [G loss: 0.315946]\n",
      "epoch:24 step:22647 [D loss: 0.218111, acc.: 63.28%] [G loss: 0.321718]\n",
      "epoch:24 step:22648 [D loss: 0.224461, acc.: 60.16%] [G loss: 0.287778]\n",
      "epoch:24 step:22649 [D loss: 0.234037, acc.: 60.94%] [G loss: 0.283177]\n",
      "epoch:24 step:22650 [D loss: 0.241962, acc.: 59.38%] [G loss: 0.302333]\n",
      "epoch:24 step:22651 [D loss: 0.219652, acc.: 65.62%] [G loss: 0.310464]\n",
      "epoch:24 step:22652 [D loss: 0.226815, acc.: 60.94%] [G loss: 0.302072]\n",
      "epoch:24 step:22653 [D loss: 0.251883, acc.: 58.59%] [G loss: 0.291709]\n",
      "epoch:24 step:22654 [D loss: 0.234196, acc.: 60.16%] [G loss: 0.317321]\n",
      "epoch:24 step:22655 [D loss: 0.234214, acc.: 59.38%] [G loss: 0.293027]\n",
      "epoch:24 step:22656 [D loss: 0.222060, acc.: 67.19%] [G loss: 0.302047]\n",
      "epoch:24 step:22657 [D loss: 0.238029, acc.: 57.03%] [G loss: 0.320199]\n",
      "epoch:24 step:22658 [D loss: 0.239667, acc.: 53.12%] [G loss: 0.274748]\n",
      "epoch:24 step:22659 [D loss: 0.251378, acc.: 53.91%] [G loss: 0.282278]\n",
      "epoch:24 step:22660 [D loss: 0.237904, acc.: 55.47%] [G loss: 0.294481]\n",
      "epoch:24 step:22661 [D loss: 0.232065, acc.: 60.16%] [G loss: 0.301282]\n",
      "epoch:24 step:22662 [D loss: 0.236699, acc.: 61.72%] [G loss: 0.308315]\n",
      "epoch:24 step:22663 [D loss: 0.239448, acc.: 57.81%] [G loss: 0.315626]\n",
      "epoch:24 step:22664 [D loss: 0.239191, acc.: 61.72%] [G loss: 0.304566]\n",
      "epoch:24 step:22665 [D loss: 0.229842, acc.: 59.38%] [G loss: 0.290567]\n",
      "epoch:24 step:22666 [D loss: 0.240216, acc.: 58.59%] [G loss: 0.308819]\n",
      "epoch:24 step:22667 [D loss: 0.243738, acc.: 56.25%] [G loss: 0.269249]\n",
      "epoch:24 step:22668 [D loss: 0.229183, acc.: 57.81%] [G loss: 0.274473]\n",
      "epoch:24 step:22669 [D loss: 0.233261, acc.: 57.03%] [G loss: 0.294954]\n",
      "epoch:24 step:22670 [D loss: 0.244647, acc.: 56.25%] [G loss: 0.265538]\n",
      "epoch:24 step:22671 [D loss: 0.227156, acc.: 60.94%] [G loss: 0.281816]\n",
      "epoch:24 step:22672 [D loss: 0.238872, acc.: 61.72%] [G loss: 0.291726]\n",
      "epoch:24 step:22673 [D loss: 0.232505, acc.: 60.94%] [G loss: 0.334700]\n",
      "epoch:24 step:22674 [D loss: 0.223574, acc.: 67.19%] [G loss: 0.309231]\n",
      "epoch:24 step:22675 [D loss: 0.231569, acc.: 61.72%] [G loss: 0.307123]\n",
      "epoch:24 step:22676 [D loss: 0.244967, acc.: 56.25%] [G loss: 0.286740]\n",
      "epoch:24 step:22677 [D loss: 0.248524, acc.: 58.59%] [G loss: 0.286818]\n",
      "epoch:24 step:22678 [D loss: 0.244814, acc.: 53.91%] [G loss: 0.291698]\n",
      "epoch:24 step:22679 [D loss: 0.243910, acc.: 59.38%] [G loss: 0.286873]\n",
      "epoch:24 step:22680 [D loss: 0.232641, acc.: 59.38%] [G loss: 0.306947]\n",
      "epoch:24 step:22681 [D loss: 0.227294, acc.: 61.72%] [G loss: 0.325061]\n",
      "epoch:24 step:22682 [D loss: 0.235307, acc.: 61.72%] [G loss: 0.303188]\n",
      "epoch:24 step:22683 [D loss: 0.228824, acc.: 62.50%] [G loss: 0.270069]\n",
      "epoch:24 step:22684 [D loss: 0.225044, acc.: 61.72%] [G loss: 0.321444]\n",
      "epoch:24 step:22685 [D loss: 0.237058, acc.: 58.59%] [G loss: 0.328632]\n",
      "epoch:24 step:22686 [D loss: 0.223674, acc.: 65.62%] [G loss: 0.305519]\n",
      "epoch:24 step:22687 [D loss: 0.230251, acc.: 63.28%] [G loss: 0.286146]\n",
      "epoch:24 step:22688 [D loss: 0.251549, acc.: 56.25%] [G loss: 0.268822]\n",
      "epoch:24 step:22689 [D loss: 0.227449, acc.: 62.50%] [G loss: 0.312786]\n",
      "epoch:24 step:22690 [D loss: 0.237122, acc.: 60.16%] [G loss: 0.262003]\n",
      "epoch:24 step:22691 [D loss: 0.226280, acc.: 60.16%] [G loss: 0.299780]\n",
      "epoch:24 step:22692 [D loss: 0.230144, acc.: 60.16%] [G loss: 0.289321]\n",
      "epoch:24 step:22693 [D loss: 0.218070, acc.: 68.75%] [G loss: 0.301911]\n",
      "epoch:24 step:22694 [D loss: 0.253224, acc.: 54.69%] [G loss: 0.320520]\n",
      "epoch:24 step:22695 [D loss: 0.221153, acc.: 62.50%] [G loss: 0.313348]\n",
      "epoch:24 step:22696 [D loss: 0.238446, acc.: 60.94%] [G loss: 0.276041]\n",
      "epoch:24 step:22697 [D loss: 0.243657, acc.: 58.59%] [G loss: 0.300677]\n",
      "epoch:24 step:22698 [D loss: 0.223129, acc.: 62.50%] [G loss: 0.286675]\n",
      "epoch:24 step:22699 [D loss: 0.219191, acc.: 63.28%] [G loss: 0.304047]\n",
      "epoch:24 step:22700 [D loss: 0.223884, acc.: 66.41%] [G loss: 0.290904]\n",
      "epoch:24 step:22701 [D loss: 0.226051, acc.: 61.72%] [G loss: 0.296794]\n",
      "epoch:24 step:22702 [D loss: 0.228297, acc.: 60.94%] [G loss: 0.314687]\n",
      "epoch:24 step:22703 [D loss: 0.260028, acc.: 57.03%] [G loss: 0.302476]\n",
      "epoch:24 step:22704 [D loss: 0.244336, acc.: 58.59%] [G loss: 0.293273]\n",
      "epoch:24 step:22705 [D loss: 0.216800, acc.: 67.97%] [G loss: 0.330584]\n",
      "epoch:24 step:22706 [D loss: 0.236204, acc.: 59.38%] [G loss: 0.286625]\n",
      "epoch:24 step:22707 [D loss: 0.247390, acc.: 57.81%] [G loss: 0.296316]\n",
      "epoch:24 step:22708 [D loss: 0.231693, acc.: 59.38%] [G loss: 0.276746]\n",
      "epoch:24 step:22709 [D loss: 0.248762, acc.: 55.47%] [G loss: 0.266157]\n",
      "epoch:24 step:22710 [D loss: 0.234267, acc.: 60.16%] [G loss: 0.303606]\n",
      "epoch:24 step:22711 [D loss: 0.233419, acc.: 59.38%] [G loss: 0.313552]\n",
      "epoch:24 step:22712 [D loss: 0.236402, acc.: 62.50%] [G loss: 0.294161]\n",
      "epoch:24 step:22713 [D loss: 0.228882, acc.: 61.72%] [G loss: 0.292236]\n",
      "epoch:24 step:22714 [D loss: 0.228887, acc.: 56.25%] [G loss: 0.296392]\n",
      "epoch:24 step:22715 [D loss: 0.241050, acc.: 55.47%] [G loss: 0.289047]\n",
      "epoch:24 step:22716 [D loss: 0.238508, acc.: 58.59%] [G loss: 0.299591]\n",
      "epoch:24 step:22717 [D loss: 0.251368, acc.: 52.34%] [G loss: 0.292495]\n",
      "epoch:24 step:22718 [D loss: 0.253436, acc.: 51.56%] [G loss: 0.285662]\n",
      "epoch:24 step:22719 [D loss: 0.232429, acc.: 61.72%] [G loss: 0.302759]\n",
      "epoch:24 step:22720 [D loss: 0.232439, acc.: 62.50%] [G loss: 0.287501]\n",
      "epoch:24 step:22721 [D loss: 0.237236, acc.: 61.72%] [G loss: 0.288880]\n",
      "epoch:24 step:22722 [D loss: 0.240692, acc.: 50.78%] [G loss: 0.295130]\n",
      "epoch:24 step:22723 [D loss: 0.244164, acc.: 60.94%] [G loss: 0.315186]\n",
      "epoch:24 step:22724 [D loss: 0.229885, acc.: 62.50%] [G loss: 0.300949]\n",
      "epoch:24 step:22725 [D loss: 0.245529, acc.: 56.25%] [G loss: 0.302746]\n",
      "epoch:24 step:22726 [D loss: 0.243880, acc.: 62.50%] [G loss: 0.311774]\n",
      "epoch:24 step:22727 [D loss: 0.227726, acc.: 58.59%] [G loss: 0.304043]\n",
      "epoch:24 step:22728 [D loss: 0.229248, acc.: 63.28%] [G loss: 0.257870]\n",
      "epoch:24 step:22729 [D loss: 0.225678, acc.: 65.62%] [G loss: 0.282425]\n",
      "epoch:24 step:22730 [D loss: 0.218122, acc.: 66.41%] [G loss: 0.286051]\n",
      "epoch:24 step:22731 [D loss: 0.251184, acc.: 59.38%] [G loss: 0.320862]\n",
      "epoch:24 step:22732 [D loss: 0.237022, acc.: 57.81%] [G loss: 0.288794]\n",
      "epoch:24 step:22733 [D loss: 0.229248, acc.: 63.28%] [G loss: 0.308734]\n",
      "epoch:24 step:22734 [D loss: 0.246790, acc.: 52.34%] [G loss: 0.287869]\n",
      "epoch:24 step:22735 [D loss: 0.245299, acc.: 56.25%] [G loss: 0.319607]\n",
      "epoch:24 step:22736 [D loss: 0.231051, acc.: 58.59%] [G loss: 0.277173]\n",
      "epoch:24 step:22737 [D loss: 0.237112, acc.: 57.81%] [G loss: 0.298018]\n",
      "epoch:24 step:22738 [D loss: 0.238092, acc.: 54.69%] [G loss: 0.271711]\n",
      "epoch:24 step:22739 [D loss: 0.244253, acc.: 53.12%] [G loss: 0.314832]\n",
      "epoch:24 step:22740 [D loss: 0.226441, acc.: 61.72%] [G loss: 0.305561]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:24 step:22741 [D loss: 0.237285, acc.: 55.47%] [G loss: 0.313511]\n",
      "epoch:24 step:22742 [D loss: 0.221845, acc.: 65.62%] [G loss: 0.295241]\n",
      "epoch:24 step:22743 [D loss: 0.219060, acc.: 66.41%] [G loss: 0.337301]\n",
      "epoch:24 step:22744 [D loss: 0.231063, acc.: 55.47%] [G loss: 0.304772]\n",
      "epoch:24 step:22745 [D loss: 0.243203, acc.: 55.47%] [G loss: 0.314425]\n",
      "epoch:24 step:22746 [D loss: 0.223018, acc.: 64.84%] [G loss: 0.311144]\n",
      "epoch:24 step:22747 [D loss: 0.234237, acc.: 60.94%] [G loss: 0.292955]\n",
      "epoch:24 step:22748 [D loss: 0.245336, acc.: 55.47%] [G loss: 0.283316]\n",
      "epoch:24 step:22749 [D loss: 0.241966, acc.: 57.03%] [G loss: 0.283280]\n",
      "epoch:24 step:22750 [D loss: 0.238863, acc.: 57.03%] [G loss: 0.330628]\n",
      "epoch:24 step:22751 [D loss: 0.248466, acc.: 54.69%] [G loss: 0.298224]\n",
      "epoch:24 step:22752 [D loss: 0.260802, acc.: 49.22%] [G loss: 0.314458]\n",
      "epoch:24 step:22753 [D loss: 0.242306, acc.: 57.81%] [G loss: 0.296521]\n",
      "epoch:24 step:22754 [D loss: 0.228222, acc.: 61.72%] [G loss: 0.286599]\n",
      "epoch:24 step:22755 [D loss: 0.223902, acc.: 67.19%] [G loss: 0.285749]\n",
      "epoch:24 step:22756 [D loss: 0.224634, acc.: 64.06%] [G loss: 0.340075]\n",
      "epoch:24 step:22757 [D loss: 0.241270, acc.: 58.59%] [G loss: 0.304221]\n",
      "epoch:24 step:22758 [D loss: 0.230168, acc.: 62.50%] [G loss: 0.295239]\n",
      "epoch:24 step:22759 [D loss: 0.231715, acc.: 62.50%] [G loss: 0.323975]\n",
      "epoch:24 step:22760 [D loss: 0.236505, acc.: 56.25%] [G loss: 0.314740]\n",
      "epoch:24 step:22761 [D loss: 0.259866, acc.: 54.69%] [G loss: 0.305320]\n",
      "epoch:24 step:22762 [D loss: 0.245694, acc.: 58.59%] [G loss: 0.299742]\n",
      "epoch:24 step:22763 [D loss: 0.249859, acc.: 57.81%] [G loss: 0.317306]\n",
      "epoch:24 step:22764 [D loss: 0.245403, acc.: 55.47%] [G loss: 0.321414]\n",
      "epoch:24 step:22765 [D loss: 0.237134, acc.: 61.72%] [G loss: 0.299960]\n",
      "epoch:24 step:22766 [D loss: 0.245825, acc.: 53.91%] [G loss: 0.313153]\n",
      "epoch:24 step:22767 [D loss: 0.241623, acc.: 57.03%] [G loss: 0.360854]\n",
      "epoch:24 step:22768 [D loss: 0.237999, acc.: 54.69%] [G loss: 0.296461]\n",
      "epoch:24 step:22769 [D loss: 0.248738, acc.: 52.34%] [G loss: 0.296318]\n",
      "epoch:24 step:22770 [D loss: 0.236111, acc.: 58.59%] [G loss: 0.327142]\n",
      "epoch:24 step:22771 [D loss: 0.240928, acc.: 55.47%] [G loss: 0.294091]\n",
      "epoch:24 step:22772 [D loss: 0.233372, acc.: 65.62%] [G loss: 0.302463]\n",
      "epoch:24 step:22773 [D loss: 0.233877, acc.: 60.94%] [G loss: 0.328377]\n",
      "epoch:24 step:22774 [D loss: 0.228548, acc.: 60.94%] [G loss: 0.305444]\n",
      "epoch:24 step:22775 [D loss: 0.241330, acc.: 54.69%] [G loss: 0.290076]\n",
      "epoch:24 step:22776 [D loss: 0.226068, acc.: 64.84%] [G loss: 0.320896]\n",
      "epoch:24 step:22777 [D loss: 0.241853, acc.: 57.81%] [G loss: 0.302404]\n",
      "epoch:24 step:22778 [D loss: 0.247229, acc.: 53.91%] [G loss: 0.290810]\n",
      "epoch:24 step:22779 [D loss: 0.232894, acc.: 58.59%] [G loss: 0.281635]\n",
      "epoch:24 step:22780 [D loss: 0.250681, acc.: 55.47%] [G loss: 0.333878]\n",
      "epoch:24 step:22781 [D loss: 0.237718, acc.: 60.16%] [G loss: 0.323150]\n",
      "epoch:24 step:22782 [D loss: 0.255833, acc.: 52.34%] [G loss: 0.300317]\n",
      "epoch:24 step:22783 [D loss: 0.238255, acc.: 57.81%] [G loss: 0.282271]\n",
      "epoch:24 step:22784 [D loss: 0.252234, acc.: 53.91%] [G loss: 0.296448]\n",
      "epoch:24 step:22785 [D loss: 0.228865, acc.: 57.03%] [G loss: 0.283057]\n",
      "epoch:24 step:22786 [D loss: 0.253986, acc.: 53.12%] [G loss: 0.307785]\n",
      "epoch:24 step:22787 [D loss: 0.256907, acc.: 52.34%] [G loss: 0.302962]\n",
      "epoch:24 step:22788 [D loss: 0.250258, acc.: 58.59%] [G loss: 0.302648]\n",
      "epoch:24 step:22789 [D loss: 0.235013, acc.: 60.16%] [G loss: 0.321286]\n",
      "epoch:24 step:22790 [D loss: 0.225525, acc.: 58.59%] [G loss: 0.309392]\n",
      "epoch:24 step:22791 [D loss: 0.235198, acc.: 62.50%] [G loss: 0.322654]\n",
      "epoch:24 step:22792 [D loss: 0.236138, acc.: 60.16%] [G loss: 0.306607]\n",
      "epoch:24 step:22793 [D loss: 0.231767, acc.: 59.38%] [G loss: 0.279689]\n",
      "epoch:24 step:22794 [D loss: 0.232519, acc.: 56.25%] [G loss: 0.316658]\n",
      "epoch:24 step:22795 [D loss: 0.231675, acc.: 63.28%] [G loss: 0.294724]\n",
      "epoch:24 step:22796 [D loss: 0.248833, acc.: 51.56%] [G loss: 0.307546]\n",
      "epoch:24 step:22797 [D loss: 0.255947, acc.: 52.34%] [G loss: 0.301598]\n",
      "epoch:24 step:22798 [D loss: 0.236895, acc.: 60.16%] [G loss: 0.320404]\n",
      "epoch:24 step:22799 [D loss: 0.235242, acc.: 57.81%] [G loss: 0.334692]\n",
      "epoch:24 step:22800 [D loss: 0.266131, acc.: 52.34%] [G loss: 0.300432]\n",
      "epoch:24 step:22801 [D loss: 0.250255, acc.: 50.78%] [G loss: 0.327501]\n",
      "epoch:24 step:22802 [D loss: 0.244825, acc.: 58.59%] [G loss: 0.312156]\n",
      "epoch:24 step:22803 [D loss: 0.246366, acc.: 53.12%] [G loss: 0.331046]\n",
      "epoch:24 step:22804 [D loss: 0.240042, acc.: 60.16%] [G loss: 0.285374]\n",
      "epoch:24 step:22805 [D loss: 0.252336, acc.: 50.00%] [G loss: 0.262856]\n",
      "epoch:24 step:22806 [D loss: 0.247123, acc.: 58.59%] [G loss: 0.332524]\n",
      "epoch:24 step:22807 [D loss: 0.248372, acc.: 56.25%] [G loss: 0.307520]\n",
      "epoch:24 step:22808 [D loss: 0.258961, acc.: 50.78%] [G loss: 0.282829]\n",
      "epoch:24 step:22809 [D loss: 0.231145, acc.: 62.50%] [G loss: 0.304171]\n",
      "epoch:24 step:22810 [D loss: 0.249942, acc.: 52.34%] [G loss: 0.304372]\n",
      "epoch:24 step:22811 [D loss: 0.227363, acc.: 60.16%] [G loss: 0.324683]\n",
      "epoch:24 step:22812 [D loss: 0.236943, acc.: 64.06%] [G loss: 0.320669]\n",
      "epoch:24 step:22813 [D loss: 0.245917, acc.: 52.34%] [G loss: 0.301587]\n",
      "epoch:24 step:22814 [D loss: 0.238087, acc.: 59.38%] [G loss: 0.285920]\n",
      "epoch:24 step:22815 [D loss: 0.231090, acc.: 60.94%] [G loss: 0.334451]\n",
      "epoch:24 step:22816 [D loss: 0.227140, acc.: 65.62%] [G loss: 0.300282]\n",
      "epoch:24 step:22817 [D loss: 0.238971, acc.: 60.16%] [G loss: 0.299000]\n",
      "epoch:24 step:22818 [D loss: 0.244142, acc.: 55.47%] [G loss: 0.301702]\n",
      "epoch:24 step:22819 [D loss: 0.225807, acc.: 66.41%] [G loss: 0.310300]\n",
      "epoch:24 step:22820 [D loss: 0.234051, acc.: 60.16%] [G loss: 0.324570]\n",
      "epoch:24 step:22821 [D loss: 0.260739, acc.: 49.22%] [G loss: 0.295666]\n",
      "epoch:24 step:22822 [D loss: 0.237685, acc.: 60.94%] [G loss: 0.269258]\n",
      "epoch:24 step:22823 [D loss: 0.242521, acc.: 58.59%] [G loss: 0.337927]\n",
      "epoch:24 step:22824 [D loss: 0.255977, acc.: 51.56%] [G loss: 0.304566]\n",
      "epoch:24 step:22825 [D loss: 0.245716, acc.: 50.78%] [G loss: 0.323700]\n",
      "epoch:24 step:22826 [D loss: 0.253423, acc.: 54.69%] [G loss: 0.320433]\n",
      "epoch:24 step:22827 [D loss: 0.228385, acc.: 64.84%] [G loss: 0.315624]\n",
      "epoch:24 step:22828 [D loss: 0.223534, acc.: 63.28%] [G loss: 0.328898]\n",
      "epoch:24 step:22829 [D loss: 0.241622, acc.: 57.03%] [G loss: 0.317003]\n",
      "epoch:24 step:22830 [D loss: 0.227243, acc.: 63.28%] [G loss: 0.330237]\n",
      "epoch:24 step:22831 [D loss: 0.238352, acc.: 60.16%] [G loss: 0.315967]\n",
      "epoch:24 step:22832 [D loss: 0.248360, acc.: 57.81%] [G loss: 0.310273]\n",
      "epoch:24 step:22833 [D loss: 0.243420, acc.: 53.12%] [G loss: 0.290211]\n",
      "epoch:24 step:22834 [D loss: 0.229925, acc.: 67.19%] [G loss: 0.303891]\n",
      "epoch:24 step:22835 [D loss: 0.229736, acc.: 62.50%] [G loss: 0.300323]\n",
      "epoch:24 step:22836 [D loss: 0.237840, acc.: 57.03%] [G loss: 0.296367]\n",
      "epoch:24 step:22837 [D loss: 0.241201, acc.: 53.91%] [G loss: 0.292821]\n",
      "epoch:24 step:22838 [D loss: 0.243841, acc.: 63.28%] [G loss: 0.265469]\n",
      "epoch:24 step:22839 [D loss: 0.243363, acc.: 58.59%] [G loss: 0.285853]\n",
      "epoch:24 step:22840 [D loss: 0.240900, acc.: 62.50%] [G loss: 0.297018]\n",
      "epoch:24 step:22841 [D loss: 0.237220, acc.: 60.94%] [G loss: 0.312006]\n",
      "epoch:24 step:22842 [D loss: 0.231239, acc.: 60.94%] [G loss: 0.287028]\n",
      "epoch:24 step:22843 [D loss: 0.224108, acc.: 61.72%] [G loss: 0.296945]\n",
      "epoch:24 step:22844 [D loss: 0.238698, acc.: 60.16%] [G loss: 0.285641]\n",
      "epoch:24 step:22845 [D loss: 0.249375, acc.: 57.81%] [G loss: 0.284760]\n",
      "epoch:24 step:22846 [D loss: 0.239962, acc.: 61.72%] [G loss: 0.305249]\n",
      "epoch:24 step:22847 [D loss: 0.250751, acc.: 53.12%] [G loss: 0.295027]\n",
      "epoch:24 step:22848 [D loss: 0.227897, acc.: 62.50%] [G loss: 0.323170]\n",
      "epoch:24 step:22849 [D loss: 0.246696, acc.: 58.59%] [G loss: 0.310500]\n",
      "epoch:24 step:22850 [D loss: 0.249269, acc.: 51.56%] [G loss: 0.275639]\n",
      "epoch:24 step:22851 [D loss: 0.227628, acc.: 62.50%] [G loss: 0.307154]\n",
      "epoch:24 step:22852 [D loss: 0.229311, acc.: 62.50%] [G loss: 0.318616]\n",
      "epoch:24 step:22853 [D loss: 0.233168, acc.: 58.59%] [G loss: 0.311768]\n",
      "epoch:24 step:22854 [D loss: 0.224247, acc.: 64.84%] [G loss: 0.298179]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:24 step:22855 [D loss: 0.238853, acc.: 56.25%] [G loss: 0.329306]\n",
      "epoch:24 step:22856 [D loss: 0.240989, acc.: 60.16%] [G loss: 0.294256]\n",
      "epoch:24 step:22857 [D loss: 0.241346, acc.: 57.03%] [G loss: 0.297022]\n",
      "epoch:24 step:22858 [D loss: 0.236944, acc.: 55.47%] [G loss: 0.316963]\n",
      "epoch:24 step:22859 [D loss: 0.229841, acc.: 63.28%] [G loss: 0.345672]\n",
      "epoch:24 step:22860 [D loss: 0.235307, acc.: 59.38%] [G loss: 0.342221]\n",
      "epoch:24 step:22861 [D loss: 0.228810, acc.: 61.72%] [G loss: 0.296303]\n",
      "epoch:24 step:22862 [D loss: 0.249409, acc.: 57.81%] [G loss: 0.298917]\n",
      "epoch:24 step:22863 [D loss: 0.256316, acc.: 54.69%] [G loss: 0.289936]\n",
      "epoch:24 step:22864 [D loss: 0.246902, acc.: 53.12%] [G loss: 0.302259]\n",
      "epoch:24 step:22865 [D loss: 0.238948, acc.: 58.59%] [G loss: 0.337685]\n",
      "epoch:24 step:22866 [D loss: 0.240563, acc.: 60.16%] [G loss: 0.296171]\n",
      "epoch:24 step:22867 [D loss: 0.230484, acc.: 64.06%] [G loss: 0.284352]\n",
      "epoch:24 step:22868 [D loss: 0.239853, acc.: 59.38%] [G loss: 0.295240]\n",
      "epoch:24 step:22869 [D loss: 0.234917, acc.: 60.16%] [G loss: 0.278849]\n",
      "epoch:24 step:22870 [D loss: 0.244582, acc.: 54.69%] [G loss: 0.308358]\n",
      "epoch:24 step:22871 [D loss: 0.230190, acc.: 60.94%] [G loss: 0.293498]\n",
      "epoch:24 step:22872 [D loss: 0.240262, acc.: 60.16%] [G loss: 0.282657]\n",
      "epoch:24 step:22873 [D loss: 0.248919, acc.: 53.12%] [G loss: 0.310652]\n",
      "epoch:24 step:22874 [D loss: 0.242793, acc.: 54.69%] [G loss: 0.291674]\n",
      "epoch:24 step:22875 [D loss: 0.243129, acc.: 54.69%] [G loss: 0.300620]\n",
      "epoch:24 step:22876 [D loss: 0.252934, acc.: 57.81%] [G loss: 0.302849]\n",
      "epoch:24 step:22877 [D loss: 0.236048, acc.: 57.03%] [G loss: 0.311438]\n",
      "epoch:24 step:22878 [D loss: 0.238511, acc.: 57.03%] [G loss: 0.281047]\n",
      "epoch:24 step:22879 [D loss: 0.227056, acc.: 62.50%] [G loss: 0.326770]\n",
      "epoch:24 step:22880 [D loss: 0.239566, acc.: 60.16%] [G loss: 0.330049]\n",
      "epoch:24 step:22881 [D loss: 0.250420, acc.: 57.03%] [G loss: 0.310549]\n",
      "epoch:24 step:22882 [D loss: 0.251267, acc.: 53.12%] [G loss: 0.281165]\n",
      "epoch:24 step:22883 [D loss: 0.242884, acc.: 53.12%] [G loss: 0.325356]\n",
      "epoch:24 step:22884 [D loss: 0.239218, acc.: 59.38%] [G loss: 0.326532]\n",
      "epoch:24 step:22885 [D loss: 0.237658, acc.: 62.50%] [G loss: 0.308648]\n",
      "epoch:24 step:22886 [D loss: 0.250982, acc.: 50.00%] [G loss: 0.287922]\n",
      "epoch:24 step:22887 [D loss: 0.228153, acc.: 60.94%] [G loss: 0.312883]\n",
      "epoch:24 step:22888 [D loss: 0.245475, acc.: 56.25%] [G loss: 0.312351]\n",
      "epoch:24 step:22889 [D loss: 0.225896, acc.: 62.50%] [G loss: 0.328462]\n",
      "epoch:24 step:22890 [D loss: 0.219554, acc.: 63.28%] [G loss: 0.304186]\n",
      "epoch:24 step:22891 [D loss: 0.244225, acc.: 55.47%] [G loss: 0.314137]\n",
      "epoch:24 step:22892 [D loss: 0.234442, acc.: 60.16%] [G loss: 0.316943]\n",
      "epoch:24 step:22893 [D loss: 0.224312, acc.: 60.94%] [G loss: 0.307169]\n",
      "epoch:24 step:22894 [D loss: 0.221610, acc.: 67.97%] [G loss: 0.320179]\n",
      "epoch:24 step:22895 [D loss: 0.237783, acc.: 59.38%] [G loss: 0.300951]\n",
      "epoch:24 step:22896 [D loss: 0.218025, acc.: 63.28%] [G loss: 0.310901]\n",
      "epoch:24 step:22897 [D loss: 0.240041, acc.: 56.25%] [G loss: 0.294806]\n",
      "epoch:24 step:22898 [D loss: 0.236169, acc.: 63.28%] [G loss: 0.298848]\n",
      "epoch:24 step:22899 [D loss: 0.236033, acc.: 58.59%] [G loss: 0.301549]\n",
      "epoch:24 step:22900 [D loss: 0.246559, acc.: 53.91%] [G loss: 0.312764]\n",
      "epoch:24 step:22901 [D loss: 0.230611, acc.: 64.84%] [G loss: 0.293200]\n",
      "epoch:24 step:22902 [D loss: 0.228972, acc.: 62.50%] [G loss: 0.323064]\n",
      "epoch:24 step:22903 [D loss: 0.262722, acc.: 49.22%] [G loss: 0.271774]\n",
      "epoch:24 step:22904 [D loss: 0.245216, acc.: 58.59%] [G loss: 0.338185]\n",
      "epoch:24 step:22905 [D loss: 0.244658, acc.: 56.25%] [G loss: 0.300824]\n",
      "epoch:24 step:22906 [D loss: 0.238814, acc.: 60.94%] [G loss: 0.331381]\n",
      "epoch:24 step:22907 [D loss: 0.233174, acc.: 60.94%] [G loss: 0.308789]\n",
      "epoch:24 step:22908 [D loss: 0.229227, acc.: 64.84%] [G loss: 0.289491]\n",
      "epoch:24 step:22909 [D loss: 0.243188, acc.: 60.16%] [G loss: 0.285755]\n",
      "epoch:24 step:22910 [D loss: 0.238298, acc.: 55.47%] [G loss: 0.311347]\n",
      "epoch:24 step:22911 [D loss: 0.235828, acc.: 55.47%] [G loss: 0.300915]\n",
      "epoch:24 step:22912 [D loss: 0.223105, acc.: 69.53%] [G loss: 0.297894]\n",
      "epoch:24 step:22913 [D loss: 0.239761, acc.: 57.81%] [G loss: 0.293456]\n",
      "epoch:24 step:22914 [D loss: 0.253248, acc.: 55.47%] [G loss: 0.305509]\n",
      "epoch:24 step:22915 [D loss: 0.226003, acc.: 62.50%] [G loss: 0.341223]\n",
      "epoch:24 step:22916 [D loss: 0.226502, acc.: 58.59%] [G loss: 0.337995]\n",
      "epoch:24 step:22917 [D loss: 0.239341, acc.: 55.47%] [G loss: 0.317909]\n",
      "epoch:24 step:22918 [D loss: 0.238218, acc.: 57.03%] [G loss: 0.328590]\n",
      "epoch:24 step:22919 [D loss: 0.234013, acc.: 60.94%] [G loss: 0.305077]\n",
      "epoch:24 step:22920 [D loss: 0.232998, acc.: 64.84%] [G loss: 0.309179]\n",
      "epoch:24 step:22921 [D loss: 0.235545, acc.: 56.25%] [G loss: 0.297515]\n",
      "epoch:24 step:22922 [D loss: 0.246958, acc.: 55.47%] [G loss: 0.326165]\n",
      "epoch:24 step:22923 [D loss: 0.241108, acc.: 57.03%] [G loss: 0.293397]\n",
      "epoch:24 step:22924 [D loss: 0.223596, acc.: 60.94%] [G loss: 0.327228]\n",
      "epoch:24 step:22925 [D loss: 0.230545, acc.: 61.72%] [G loss: 0.310296]\n",
      "epoch:24 step:22926 [D loss: 0.243278, acc.: 58.59%] [G loss: 0.299280]\n",
      "epoch:24 step:22927 [D loss: 0.239699, acc.: 57.03%] [G loss: 0.306391]\n",
      "epoch:24 step:22928 [D loss: 0.236368, acc.: 60.94%] [G loss: 0.300762]\n",
      "epoch:24 step:22929 [D loss: 0.236712, acc.: 60.16%] [G loss: 0.286323]\n",
      "epoch:24 step:22930 [D loss: 0.259240, acc.: 47.66%] [G loss: 0.291716]\n",
      "epoch:24 step:22931 [D loss: 0.243644, acc.: 54.69%] [G loss: 0.312618]\n",
      "epoch:24 step:22932 [D loss: 0.242784, acc.: 57.81%] [G loss: 0.305771]\n",
      "epoch:24 step:22933 [D loss: 0.228907, acc.: 67.19%] [G loss: 0.305567]\n",
      "epoch:24 step:22934 [D loss: 0.263526, acc.: 53.91%] [G loss: 0.311719]\n",
      "epoch:24 step:22935 [D loss: 0.237824, acc.: 60.94%] [G loss: 0.285837]\n",
      "epoch:24 step:22936 [D loss: 0.238019, acc.: 58.59%] [G loss: 0.305144]\n",
      "epoch:24 step:22937 [D loss: 0.244925, acc.: 57.03%] [G loss: 0.314861]\n",
      "epoch:24 step:22938 [D loss: 0.260095, acc.: 50.78%] [G loss: 0.305924]\n",
      "epoch:24 step:22939 [D loss: 0.235917, acc.: 57.03%] [G loss: 0.340882]\n",
      "epoch:24 step:22940 [D loss: 0.256547, acc.: 56.25%] [G loss: 0.304552]\n",
      "epoch:24 step:22941 [D loss: 0.234114, acc.: 61.72%] [G loss: 0.306679]\n",
      "epoch:24 step:22942 [D loss: 0.239163, acc.: 57.81%] [G loss: 0.277114]\n",
      "epoch:24 step:22943 [D loss: 0.250826, acc.: 53.91%] [G loss: 0.299643]\n",
      "epoch:24 step:22944 [D loss: 0.237481, acc.: 57.03%] [G loss: 0.292949]\n",
      "epoch:24 step:22945 [D loss: 0.244324, acc.: 51.56%] [G loss: 0.325176]\n",
      "epoch:24 step:22946 [D loss: 0.239289, acc.: 59.38%] [G loss: 0.310416]\n",
      "epoch:24 step:22947 [D loss: 0.241473, acc.: 57.03%] [G loss: 0.288286]\n",
      "epoch:24 step:22948 [D loss: 0.237113, acc.: 57.03%] [G loss: 0.321275]\n",
      "epoch:24 step:22949 [D loss: 0.234616, acc.: 57.03%] [G loss: 0.312696]\n",
      "epoch:24 step:22950 [D loss: 0.256798, acc.: 57.03%] [G loss: 0.309840]\n",
      "epoch:24 step:22951 [D loss: 0.248823, acc.: 52.34%] [G loss: 0.293415]\n",
      "epoch:24 step:22952 [D loss: 0.234879, acc.: 61.72%] [G loss: 0.312449]\n",
      "epoch:24 step:22953 [D loss: 0.253129, acc.: 50.78%] [G loss: 0.287224]\n",
      "epoch:24 step:22954 [D loss: 0.224792, acc.: 60.94%] [G loss: 0.323473]\n",
      "epoch:24 step:22955 [D loss: 0.260739, acc.: 53.91%] [G loss: 0.294556]\n",
      "epoch:24 step:22956 [D loss: 0.245946, acc.: 53.91%] [G loss: 0.282718]\n",
      "epoch:24 step:22957 [D loss: 0.230127, acc.: 64.84%] [G loss: 0.276156]\n",
      "epoch:24 step:22958 [D loss: 0.243013, acc.: 53.91%] [G loss: 0.330060]\n",
      "epoch:24 step:22959 [D loss: 0.238853, acc.: 58.59%] [G loss: 0.305339]\n",
      "epoch:24 step:22960 [D loss: 0.253525, acc.: 50.78%] [G loss: 0.309218]\n",
      "epoch:24 step:22961 [D loss: 0.236780, acc.: 55.47%] [G loss: 0.286746]\n",
      "epoch:24 step:22962 [D loss: 0.235167, acc.: 61.72%] [G loss: 0.300132]\n",
      "epoch:24 step:22963 [D loss: 0.253923, acc.: 51.56%] [G loss: 0.283885]\n",
      "epoch:24 step:22964 [D loss: 0.242149, acc.: 52.34%] [G loss: 0.298552]\n",
      "epoch:24 step:22965 [D loss: 0.251936, acc.: 53.12%] [G loss: 0.285559]\n",
      "epoch:24 step:22966 [D loss: 0.249046, acc.: 59.38%] [G loss: 0.292231]\n",
      "epoch:24 step:22967 [D loss: 0.233274, acc.: 61.72%] [G loss: 0.320999]\n",
      "epoch:24 step:22968 [D loss: 0.247159, acc.: 53.91%] [G loss: 0.289880]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:24 step:22969 [D loss: 0.229048, acc.: 63.28%] [G loss: 0.307968]\n",
      "epoch:24 step:22970 [D loss: 0.230879, acc.: 63.28%] [G loss: 0.313536]\n",
      "epoch:24 step:22971 [D loss: 0.240263, acc.: 57.03%] [G loss: 0.311992]\n",
      "epoch:24 step:22972 [D loss: 0.230789, acc.: 64.84%] [G loss: 0.309055]\n",
      "epoch:24 step:22973 [D loss: 0.256681, acc.: 53.91%] [G loss: 0.280023]\n",
      "epoch:24 step:22974 [D loss: 0.234515, acc.: 63.28%] [G loss: 0.301601]\n",
      "epoch:24 step:22975 [D loss: 0.246712, acc.: 53.91%] [G loss: 0.289369]\n",
      "epoch:24 step:22976 [D loss: 0.214344, acc.: 67.97%] [G loss: 0.308469]\n",
      "epoch:24 step:22977 [D loss: 0.240775, acc.: 57.81%] [G loss: 0.307357]\n",
      "epoch:24 step:22978 [D loss: 0.223327, acc.: 65.62%] [G loss: 0.314169]\n",
      "epoch:24 step:22979 [D loss: 0.247071, acc.: 54.69%] [G loss: 0.301087]\n",
      "epoch:24 step:22980 [D loss: 0.237639, acc.: 59.38%] [G loss: 0.315576]\n",
      "epoch:24 step:22981 [D loss: 0.238537, acc.: 57.03%] [G loss: 0.308473]\n",
      "epoch:24 step:22982 [D loss: 0.219946, acc.: 63.28%] [G loss: 0.338148]\n",
      "epoch:24 step:22983 [D loss: 0.245827, acc.: 53.91%] [G loss: 0.287265]\n",
      "epoch:24 step:22984 [D loss: 0.221164, acc.: 64.06%] [G loss: 0.353983]\n",
      "epoch:24 step:22985 [D loss: 0.235997, acc.: 57.81%] [G loss: 0.306084]\n",
      "epoch:24 step:22986 [D loss: 0.223761, acc.: 60.94%] [G loss: 0.314901]\n",
      "epoch:24 step:22987 [D loss: 0.229165, acc.: 59.38%] [G loss: 0.316563]\n",
      "epoch:24 step:22988 [D loss: 0.234380, acc.: 55.47%] [G loss: 0.300947]\n",
      "epoch:24 step:22989 [D loss: 0.235184, acc.: 56.25%] [G loss: 0.293433]\n",
      "epoch:24 step:22990 [D loss: 0.226314, acc.: 64.84%] [G loss: 0.312893]\n",
      "epoch:24 step:22991 [D loss: 0.238959, acc.: 62.50%] [G loss: 0.291226]\n",
      "epoch:24 step:22992 [D loss: 0.240071, acc.: 58.59%] [G loss: 0.317215]\n",
      "epoch:24 step:22993 [D loss: 0.238813, acc.: 56.25%] [G loss: 0.309208]\n",
      "epoch:24 step:22994 [D loss: 0.236011, acc.: 62.50%] [G loss: 0.304295]\n",
      "epoch:24 step:22995 [D loss: 0.234992, acc.: 56.25%] [G loss: 0.294702]\n",
      "epoch:24 step:22996 [D loss: 0.238526, acc.: 57.81%] [G loss: 0.316421]\n",
      "epoch:24 step:22997 [D loss: 0.239803, acc.: 59.38%] [G loss: 0.315267]\n",
      "epoch:24 step:22998 [D loss: 0.242068, acc.: 59.38%] [G loss: 0.303422]\n",
      "epoch:24 step:22999 [D loss: 0.227455, acc.: 65.62%] [G loss: 0.278741]\n",
      "epoch:24 step:23000 [D loss: 0.239187, acc.: 60.94%] [G loss: 0.298602]\n",
      "epoch:24 step:23001 [D loss: 0.220097, acc.: 64.06%] [G loss: 0.304786]\n",
      "epoch:24 step:23002 [D loss: 0.239359, acc.: 60.94%] [G loss: 0.299641]\n",
      "epoch:24 step:23003 [D loss: 0.253151, acc.: 53.91%] [G loss: 0.307313]\n",
      "epoch:24 step:23004 [D loss: 0.238836, acc.: 58.59%] [G loss: 0.309652]\n",
      "epoch:24 step:23005 [D loss: 0.227588, acc.: 61.72%] [G loss: 0.318154]\n",
      "epoch:24 step:23006 [D loss: 0.226970, acc.: 58.59%] [G loss: 0.321105]\n",
      "epoch:24 step:23007 [D loss: 0.240002, acc.: 64.06%] [G loss: 0.304581]\n",
      "epoch:24 step:23008 [D loss: 0.233742, acc.: 63.28%] [G loss: 0.317492]\n",
      "epoch:24 step:23009 [D loss: 0.230732, acc.: 62.50%] [G loss: 0.309370]\n",
      "epoch:24 step:23010 [D loss: 0.232835, acc.: 59.38%] [G loss: 0.303804]\n",
      "epoch:24 step:23011 [D loss: 0.246120, acc.: 54.69%] [G loss: 0.302210]\n",
      "epoch:24 step:23012 [D loss: 0.237890, acc.: 60.94%] [G loss: 0.311136]\n",
      "epoch:24 step:23013 [D loss: 0.225168, acc.: 64.06%] [G loss: 0.306179]\n",
      "epoch:24 step:23014 [D loss: 0.225161, acc.: 62.50%] [G loss: 0.311493]\n",
      "epoch:24 step:23015 [D loss: 0.243742, acc.: 57.81%] [G loss: 0.331208]\n",
      "epoch:24 step:23016 [D loss: 0.226987, acc.: 63.28%] [G loss: 0.324173]\n",
      "epoch:24 step:23017 [D loss: 0.244512, acc.: 53.12%] [G loss: 0.306273]\n",
      "epoch:24 step:23018 [D loss: 0.222571, acc.: 61.72%] [G loss: 0.282584]\n",
      "epoch:24 step:23019 [D loss: 0.223120, acc.: 70.31%] [G loss: 0.304540]\n",
      "epoch:24 step:23020 [D loss: 0.247753, acc.: 51.56%] [G loss: 0.303532]\n",
      "epoch:24 step:23021 [D loss: 0.242873, acc.: 54.69%] [G loss: 0.323055]\n",
      "epoch:24 step:23022 [D loss: 0.244621, acc.: 55.47%] [G loss: 0.279336]\n",
      "epoch:24 step:23023 [D loss: 0.224166, acc.: 61.72%] [G loss: 0.346284]\n",
      "epoch:24 step:23024 [D loss: 0.250402, acc.: 50.78%] [G loss: 0.345094]\n",
      "epoch:24 step:23025 [D loss: 0.239156, acc.: 60.94%] [G loss: 0.323701]\n",
      "epoch:24 step:23026 [D loss: 0.240208, acc.: 64.06%] [G loss: 0.324138]\n",
      "epoch:24 step:23027 [D loss: 0.216749, acc.: 64.06%] [G loss: 0.328027]\n",
      "epoch:24 step:23028 [D loss: 0.224260, acc.: 62.50%] [G loss: 0.310659]\n",
      "epoch:24 step:23029 [D loss: 0.234626, acc.: 59.38%] [G loss: 0.282232]\n",
      "epoch:24 step:23030 [D loss: 0.237071, acc.: 59.38%] [G loss: 0.282294]\n",
      "epoch:24 step:23031 [D loss: 0.237035, acc.: 60.94%] [G loss: 0.321618]\n",
      "epoch:24 step:23032 [D loss: 0.237208, acc.: 54.69%] [G loss: 0.322154]\n",
      "epoch:24 step:23033 [D loss: 0.255361, acc.: 52.34%] [G loss: 0.314011]\n",
      "epoch:24 step:23034 [D loss: 0.236711, acc.: 61.72%] [G loss: 0.309040]\n",
      "epoch:24 step:23035 [D loss: 0.245331, acc.: 56.25%] [G loss: 0.318119]\n",
      "epoch:24 step:23036 [D loss: 0.237555, acc.: 64.06%] [G loss: 0.295922]\n",
      "epoch:24 step:23037 [D loss: 0.239606, acc.: 57.81%] [G loss: 0.305510]\n",
      "epoch:24 step:23038 [D loss: 0.247498, acc.: 56.25%] [G loss: 0.282403]\n",
      "epoch:24 step:23039 [D loss: 0.218622, acc.: 64.84%] [G loss: 0.333999]\n",
      "epoch:24 step:23040 [D loss: 0.264433, acc.: 53.91%] [G loss: 0.321389]\n",
      "epoch:24 step:23041 [D loss: 0.222913, acc.: 65.62%] [G loss: 0.330509]\n",
      "epoch:24 step:23042 [D loss: 0.233689, acc.: 58.59%] [G loss: 0.307641]\n",
      "epoch:24 step:23043 [D loss: 0.235802, acc.: 64.84%] [G loss: 0.306865]\n",
      "epoch:24 step:23044 [D loss: 0.238954, acc.: 57.03%] [G loss: 0.340201]\n",
      "epoch:24 step:23045 [D loss: 0.248432, acc.: 59.38%] [G loss: 0.269249]\n",
      "epoch:24 step:23046 [D loss: 0.240953, acc.: 56.25%] [G loss: 0.310044]\n",
      "epoch:24 step:23047 [D loss: 0.234293, acc.: 62.50%] [G loss: 0.273544]\n",
      "epoch:24 step:23048 [D loss: 0.235686, acc.: 60.94%] [G loss: 0.327949]\n",
      "epoch:24 step:23049 [D loss: 0.240799, acc.: 57.81%] [G loss: 0.302295]\n",
      "epoch:24 step:23050 [D loss: 0.229248, acc.: 62.50%] [G loss: 0.316465]\n",
      "epoch:24 step:23051 [D loss: 0.244143, acc.: 57.03%] [G loss: 0.299601]\n",
      "epoch:24 step:23052 [D loss: 0.235684, acc.: 57.03%] [G loss: 0.336283]\n",
      "epoch:24 step:23053 [D loss: 0.230068, acc.: 61.72%] [G loss: 0.296012]\n",
      "epoch:24 step:23054 [D loss: 0.229756, acc.: 60.94%] [G loss: 0.307338]\n",
      "epoch:24 step:23055 [D loss: 0.252539, acc.: 57.03%] [G loss: 0.300334]\n",
      "epoch:24 step:23056 [D loss: 0.241636, acc.: 59.38%] [G loss: 0.301959]\n",
      "epoch:24 step:23057 [D loss: 0.241619, acc.: 60.16%] [G loss: 0.313307]\n",
      "epoch:24 step:23058 [D loss: 0.231305, acc.: 60.16%] [G loss: 0.309370]\n",
      "epoch:24 step:23059 [D loss: 0.249418, acc.: 56.25%] [G loss: 0.291920]\n",
      "epoch:24 step:23060 [D loss: 0.217541, acc.: 67.97%] [G loss: 0.297565]\n",
      "epoch:24 step:23061 [D loss: 0.254751, acc.: 50.00%] [G loss: 0.304642]\n",
      "epoch:24 step:23062 [D loss: 0.241813, acc.: 61.72%] [G loss: 0.312363]\n",
      "epoch:24 step:23063 [D loss: 0.251372, acc.: 55.47%] [G loss: 0.272734]\n",
      "epoch:24 step:23064 [D loss: 0.237000, acc.: 62.50%] [G loss: 0.311954]\n",
      "epoch:24 step:23065 [D loss: 0.242526, acc.: 58.59%] [G loss: 0.294825]\n",
      "epoch:24 step:23066 [D loss: 0.237116, acc.: 64.84%] [G loss: 0.336473]\n",
      "epoch:24 step:23067 [D loss: 0.239204, acc.: 55.47%] [G loss: 0.315236]\n",
      "epoch:24 step:23068 [D loss: 0.242052, acc.: 57.81%] [G loss: 0.317070]\n",
      "epoch:24 step:23069 [D loss: 0.242363, acc.: 61.72%] [G loss: 0.291954]\n",
      "epoch:24 step:23070 [D loss: 0.233371, acc.: 63.28%] [G loss: 0.313426]\n",
      "epoch:24 step:23071 [D loss: 0.228377, acc.: 61.72%] [G loss: 0.310779]\n",
      "epoch:24 step:23072 [D loss: 0.232991, acc.: 57.81%] [G loss: 0.310501]\n",
      "epoch:24 step:23073 [D loss: 0.234789, acc.: 59.38%] [G loss: 0.305614]\n",
      "epoch:24 step:23074 [D loss: 0.221951, acc.: 60.94%] [G loss: 0.317411]\n",
      "epoch:24 step:23075 [D loss: 0.223722, acc.: 62.50%] [G loss: 0.333354]\n",
      "epoch:24 step:23076 [D loss: 0.225073, acc.: 67.97%] [G loss: 0.336329]\n",
      "epoch:24 step:23077 [D loss: 0.247462, acc.: 56.25%] [G loss: 0.282198]\n",
      "epoch:24 step:23078 [D loss: 0.232896, acc.: 63.28%] [G loss: 0.284351]\n",
      "epoch:24 step:23079 [D loss: 0.245479, acc.: 56.25%] [G loss: 0.303476]\n",
      "epoch:24 step:23080 [D loss: 0.240336, acc.: 54.69%] [G loss: 0.301650]\n",
      "epoch:24 step:23081 [D loss: 0.261132, acc.: 53.91%] [G loss: 0.276709]\n",
      "epoch:24 step:23082 [D loss: 0.244992, acc.: 57.03%] [G loss: 0.319346]\n",
      "epoch:24 step:23083 [D loss: 0.239584, acc.: 61.72%] [G loss: 0.289656]\n",
      "epoch:24 step:23084 [D loss: 0.248731, acc.: 56.25%] [G loss: 0.310679]\n",
      "epoch:24 step:23085 [D loss: 0.259398, acc.: 54.69%] [G loss: 0.305207]\n",
      "epoch:24 step:23086 [D loss: 0.240718, acc.: 52.34%] [G loss: 0.306426]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:24 step:23087 [D loss: 0.257316, acc.: 52.34%] [G loss: 0.301990]\n",
      "epoch:24 step:23088 [D loss: 0.215073, acc.: 64.06%] [G loss: 0.340644]\n",
      "epoch:24 step:23089 [D loss: 0.239888, acc.: 57.03%] [G loss: 0.288653]\n",
      "epoch:24 step:23090 [D loss: 0.251505, acc.: 50.78%] [G loss: 0.286438]\n",
      "epoch:24 step:23091 [D loss: 0.233465, acc.: 57.03%] [G loss: 0.307569]\n",
      "epoch:24 step:23092 [D loss: 0.233267, acc.: 59.38%] [G loss: 0.293534]\n",
      "epoch:24 step:23093 [D loss: 0.239122, acc.: 60.16%] [G loss: 0.272116]\n",
      "epoch:24 step:23094 [D loss: 0.243293, acc.: 52.34%] [G loss: 0.311581]\n",
      "epoch:24 step:23095 [D loss: 0.240617, acc.: 55.47%] [G loss: 0.324216]\n",
      "epoch:24 step:23096 [D loss: 0.241098, acc.: 54.69%] [G loss: 0.308672]\n",
      "epoch:24 step:23097 [D loss: 0.226442, acc.: 66.41%] [G loss: 0.304011]\n",
      "epoch:24 step:23098 [D loss: 0.254469, acc.: 50.78%] [G loss: 0.300125]\n",
      "epoch:24 step:23099 [D loss: 0.251665, acc.: 53.91%] [G loss: 0.301925]\n",
      "epoch:24 step:23100 [D loss: 0.235146, acc.: 62.50%] [G loss: 0.312864]\n",
      "epoch:24 step:23101 [D loss: 0.238308, acc.: 56.25%] [G loss: 0.296579]\n",
      "epoch:24 step:23102 [D loss: 0.254837, acc.: 56.25%] [G loss: 0.298828]\n",
      "epoch:24 step:23103 [D loss: 0.255292, acc.: 51.56%] [G loss: 0.298988]\n",
      "epoch:24 step:23104 [D loss: 0.215626, acc.: 67.19%] [G loss: 0.309503]\n",
      "epoch:24 step:23105 [D loss: 0.242943, acc.: 56.25%] [G loss: 0.300057]\n",
      "epoch:24 step:23106 [D loss: 0.237628, acc.: 60.16%] [G loss: 0.291092]\n",
      "epoch:24 step:23107 [D loss: 0.248579, acc.: 53.91%] [G loss: 0.303487]\n",
      "epoch:24 step:23108 [D loss: 0.234969, acc.: 57.81%] [G loss: 0.330846]\n",
      "epoch:24 step:23109 [D loss: 0.262112, acc.: 49.22%] [G loss: 0.327031]\n",
      "epoch:24 step:23110 [D loss: 0.248490, acc.: 59.38%] [G loss: 0.310586]\n",
      "epoch:24 step:23111 [D loss: 0.247783, acc.: 56.25%] [G loss: 0.289429]\n",
      "epoch:24 step:23112 [D loss: 0.250487, acc.: 51.56%] [G loss: 0.300309]\n",
      "epoch:24 step:23113 [D loss: 0.236224, acc.: 57.03%] [G loss: 0.276726]\n",
      "epoch:24 step:23114 [D loss: 0.225984, acc.: 70.31%] [G loss: 0.281596]\n",
      "epoch:24 step:23115 [D loss: 0.226750, acc.: 61.72%] [G loss: 0.343203]\n",
      "epoch:24 step:23116 [D loss: 0.247947, acc.: 53.91%] [G loss: 0.309061]\n",
      "epoch:24 step:23117 [D loss: 0.262780, acc.: 53.91%] [G loss: 0.311275]\n",
      "epoch:24 step:23118 [D loss: 0.242326, acc.: 56.25%] [G loss: 0.307721]\n",
      "epoch:24 step:23119 [D loss: 0.222573, acc.: 65.62%] [G loss: 0.287173]\n",
      "epoch:24 step:23120 [D loss: 0.249275, acc.: 54.69%] [G loss: 0.321000]\n",
      "epoch:24 step:23121 [D loss: 0.243105, acc.: 57.81%] [G loss: 0.279988]\n",
      "epoch:24 step:23122 [D loss: 0.225090, acc.: 60.16%] [G loss: 0.326241]\n",
      "epoch:24 step:23123 [D loss: 0.232499, acc.: 60.16%] [G loss: 0.305282]\n",
      "epoch:24 step:23124 [D loss: 0.241728, acc.: 60.16%] [G loss: 0.277481]\n",
      "epoch:24 step:23125 [D loss: 0.240467, acc.: 59.38%] [G loss: 0.291001]\n",
      "epoch:24 step:23126 [D loss: 0.236035, acc.: 63.28%] [G loss: 0.295155]\n",
      "epoch:24 step:23127 [D loss: 0.246204, acc.: 51.56%] [G loss: 0.300300]\n",
      "epoch:24 step:23128 [D loss: 0.224337, acc.: 63.28%] [G loss: 0.340225]\n",
      "epoch:24 step:23129 [D loss: 0.235001, acc.: 60.94%] [G loss: 0.334027]\n",
      "epoch:24 step:23130 [D loss: 0.237072, acc.: 58.59%] [G loss: 0.325828]\n",
      "epoch:24 step:23131 [D loss: 0.254379, acc.: 50.00%] [G loss: 0.307890]\n",
      "epoch:24 step:23132 [D loss: 0.240418, acc.: 55.47%] [G loss: 0.274774]\n",
      "epoch:24 step:23133 [D loss: 0.240487, acc.: 60.94%] [G loss: 0.311277]\n",
      "epoch:24 step:23134 [D loss: 0.257891, acc.: 49.22%] [G loss: 0.294880]\n",
      "epoch:24 step:23135 [D loss: 0.232551, acc.: 57.81%] [G loss: 0.305560]\n",
      "epoch:24 step:23136 [D loss: 0.233094, acc.: 59.38%] [G loss: 0.308401]\n",
      "epoch:24 step:23137 [D loss: 0.240620, acc.: 60.16%] [G loss: 0.311869]\n",
      "epoch:24 step:23138 [D loss: 0.221320, acc.: 66.41%] [G loss: 0.275758]\n",
      "epoch:24 step:23139 [D loss: 0.248177, acc.: 55.47%] [G loss: 0.292788]\n",
      "epoch:24 step:23140 [D loss: 0.227606, acc.: 62.50%] [G loss: 0.291996]\n",
      "epoch:24 step:23141 [D loss: 0.237959, acc.: 61.72%] [G loss: 0.308339]\n",
      "epoch:24 step:23142 [D loss: 0.236152, acc.: 61.72%] [G loss: 0.291944]\n",
      "epoch:24 step:23143 [D loss: 0.245275, acc.: 51.56%] [G loss: 0.292246]\n",
      "epoch:24 step:23144 [D loss: 0.248864, acc.: 57.81%] [G loss: 0.306289]\n",
      "epoch:24 step:23145 [D loss: 0.232071, acc.: 60.16%] [G loss: 0.295012]\n",
      "epoch:24 step:23146 [D loss: 0.227661, acc.: 58.59%] [G loss: 0.302051]\n",
      "epoch:24 step:23147 [D loss: 0.226931, acc.: 63.28%] [G loss: 0.282480]\n",
      "epoch:24 step:23148 [D loss: 0.246891, acc.: 56.25%] [G loss: 0.296602]\n",
      "epoch:24 step:23149 [D loss: 0.237813, acc.: 57.81%] [G loss: 0.313217]\n",
      "epoch:24 step:23150 [D loss: 0.264616, acc.: 53.91%] [G loss: 0.274850]\n",
      "epoch:24 step:23151 [D loss: 0.239799, acc.: 63.28%] [G loss: 0.277969]\n",
      "epoch:24 step:23152 [D loss: 0.243167, acc.: 57.03%] [G loss: 0.288780]\n",
      "epoch:24 step:23153 [D loss: 0.246091, acc.: 55.47%] [G loss: 0.291067]\n",
      "epoch:24 step:23154 [D loss: 0.225848, acc.: 66.41%] [G loss: 0.298851]\n",
      "epoch:24 step:23155 [D loss: 0.257819, acc.: 53.91%] [G loss: 0.291044]\n",
      "epoch:24 step:23156 [D loss: 0.240735, acc.: 62.50%] [G loss: 0.270557]\n",
      "epoch:24 step:23157 [D loss: 0.245030, acc.: 58.59%] [G loss: 0.293665]\n",
      "epoch:24 step:23158 [D loss: 0.228469, acc.: 60.94%] [G loss: 0.292454]\n",
      "epoch:24 step:23159 [D loss: 0.244935, acc.: 53.12%] [G loss: 0.318107]\n",
      "epoch:24 step:23160 [D loss: 0.240976, acc.: 57.81%] [G loss: 0.300248]\n",
      "epoch:24 step:23161 [D loss: 0.233199, acc.: 56.25%] [G loss: 0.290020]\n",
      "epoch:24 step:23162 [D loss: 0.233855, acc.: 60.94%] [G loss: 0.254328]\n",
      "epoch:24 step:23163 [D loss: 0.235974, acc.: 61.72%] [G loss: 0.313921]\n",
      "epoch:24 step:23164 [D loss: 0.236883, acc.: 58.59%] [G loss: 0.314991]\n",
      "epoch:24 step:23165 [D loss: 0.231661, acc.: 63.28%] [G loss: 0.292026]\n",
      "epoch:24 step:23166 [D loss: 0.242848, acc.: 55.47%] [G loss: 0.277818]\n",
      "epoch:24 step:23167 [D loss: 0.230271, acc.: 64.06%] [G loss: 0.302254]\n",
      "epoch:24 step:23168 [D loss: 0.229191, acc.: 63.28%] [G loss: 0.345818]\n",
      "epoch:24 step:23169 [D loss: 0.247546, acc.: 52.34%] [G loss: 0.281377]\n",
      "epoch:24 step:23170 [D loss: 0.238202, acc.: 57.81%] [G loss: 0.292061]\n",
      "epoch:24 step:23171 [D loss: 0.248239, acc.: 56.25%] [G loss: 0.312731]\n",
      "epoch:24 step:23172 [D loss: 0.248754, acc.: 57.81%] [G loss: 0.283666]\n",
      "epoch:24 step:23173 [D loss: 0.226997, acc.: 67.97%] [G loss: 0.310349]\n",
      "epoch:24 step:23174 [D loss: 0.247441, acc.: 52.34%] [G loss: 0.269683]\n",
      "epoch:24 step:23175 [D loss: 0.238409, acc.: 56.25%] [G loss: 0.304888]\n",
      "epoch:24 step:23176 [D loss: 0.239266, acc.: 55.47%] [G loss: 0.305583]\n",
      "epoch:24 step:23177 [D loss: 0.249667, acc.: 53.12%] [G loss: 0.289542]\n",
      "epoch:24 step:23178 [D loss: 0.238363, acc.: 55.47%] [G loss: 0.300175]\n",
      "epoch:24 step:23179 [D loss: 0.227256, acc.: 64.06%] [G loss: 0.306973]\n",
      "epoch:24 step:23180 [D loss: 0.232227, acc.: 63.28%] [G loss: 0.313703]\n",
      "epoch:24 step:23181 [D loss: 0.233013, acc.: 64.06%] [G loss: 0.267539]\n",
      "epoch:24 step:23182 [D loss: 0.229481, acc.: 69.53%] [G loss: 0.305207]\n",
      "epoch:24 step:23183 [D loss: 0.243322, acc.: 57.81%] [G loss: 0.295143]\n",
      "epoch:24 step:23184 [D loss: 0.242188, acc.: 53.12%] [G loss: 0.300893]\n",
      "epoch:24 step:23185 [D loss: 0.224778, acc.: 70.31%] [G loss: 0.295125]\n",
      "epoch:24 step:23186 [D loss: 0.241028, acc.: 57.81%] [G loss: 0.272027]\n",
      "epoch:24 step:23187 [D loss: 0.236406, acc.: 58.59%] [G loss: 0.288266]\n",
      "epoch:24 step:23188 [D loss: 0.244693, acc.: 50.78%] [G loss: 0.315779]\n",
      "epoch:24 step:23189 [D loss: 0.224883, acc.: 62.50%] [G loss: 0.300263]\n",
      "epoch:24 step:23190 [D loss: 0.232220, acc.: 62.50%] [G loss: 0.331324]\n",
      "epoch:24 step:23191 [D loss: 0.240390, acc.: 56.25%] [G loss: 0.292582]\n",
      "epoch:24 step:23192 [D loss: 0.232272, acc.: 60.16%] [G loss: 0.289523]\n",
      "epoch:24 step:23193 [D loss: 0.230205, acc.: 64.06%] [G loss: 0.299838]\n",
      "epoch:24 step:23194 [D loss: 0.244077, acc.: 58.59%] [G loss: 0.311988]\n",
      "epoch:24 step:23195 [D loss: 0.217142, acc.: 65.62%] [G loss: 0.307277]\n",
      "epoch:24 step:23196 [D loss: 0.231682, acc.: 63.28%] [G loss: 0.305271]\n",
      "epoch:24 step:23197 [D loss: 0.232991, acc.: 55.47%] [G loss: 0.301426]\n",
      "epoch:24 step:23198 [D loss: 0.239087, acc.: 59.38%] [G loss: 0.295142]\n",
      "epoch:24 step:23199 [D loss: 0.245780, acc.: 57.03%] [G loss: 0.312255]\n",
      "epoch:24 step:23200 [D loss: 0.223164, acc.: 62.50%] [G loss: 0.294196]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:24 step:23201 [D loss: 0.246960, acc.: 53.91%] [G loss: 0.295430]\n",
      "epoch:24 step:23202 [D loss: 0.246239, acc.: 57.81%] [G loss: 0.327991]\n",
      "epoch:24 step:23203 [D loss: 0.232352, acc.: 59.38%] [G loss: 0.296777]\n",
      "epoch:24 step:23204 [D loss: 0.232064, acc.: 62.50%] [G loss: 0.328001]\n",
      "epoch:24 step:23205 [D loss: 0.223703, acc.: 63.28%] [G loss: 0.306763]\n",
      "epoch:24 step:23206 [D loss: 0.221173, acc.: 64.06%] [G loss: 0.322631]\n",
      "epoch:24 step:23207 [D loss: 0.247767, acc.: 57.03%] [G loss: 0.288109]\n",
      "epoch:24 step:23208 [D loss: 0.251917, acc.: 55.47%] [G loss: 0.312501]\n",
      "epoch:24 step:23209 [D loss: 0.223808, acc.: 67.97%] [G loss: 0.308611]\n",
      "epoch:24 step:23210 [D loss: 0.236021, acc.: 58.59%] [G loss: 0.294493]\n",
      "epoch:24 step:23211 [D loss: 0.232611, acc.: 61.72%] [G loss: 0.315424]\n",
      "epoch:24 step:23212 [D loss: 0.229989, acc.: 63.28%] [G loss: 0.313988]\n",
      "epoch:24 step:23213 [D loss: 0.239933, acc.: 57.03%] [G loss: 0.277726]\n",
      "epoch:24 step:23214 [D loss: 0.236523, acc.: 59.38%] [G loss: 0.287225]\n",
      "epoch:24 step:23215 [D loss: 0.227504, acc.: 64.84%] [G loss: 0.294383]\n",
      "epoch:24 step:23216 [D loss: 0.250118, acc.: 55.47%] [G loss: 0.326532]\n",
      "epoch:24 step:23217 [D loss: 0.256142, acc.: 56.25%] [G loss: 0.302388]\n",
      "epoch:24 step:23218 [D loss: 0.243511, acc.: 53.91%] [G loss: 0.327654]\n",
      "epoch:24 step:23219 [D loss: 0.233008, acc.: 61.72%] [G loss: 0.310185]\n",
      "epoch:24 step:23220 [D loss: 0.238940, acc.: 57.03%] [G loss: 0.308538]\n",
      "epoch:24 step:23221 [D loss: 0.221573, acc.: 67.19%] [G loss: 0.300876]\n",
      "epoch:24 step:23222 [D loss: 0.256146, acc.: 51.56%] [G loss: 0.305762]\n",
      "epoch:24 step:23223 [D loss: 0.243267, acc.: 52.34%] [G loss: 0.303887]\n",
      "epoch:24 step:23224 [D loss: 0.247773, acc.: 50.78%] [G loss: 0.306322]\n",
      "epoch:24 step:23225 [D loss: 0.246264, acc.: 54.69%] [G loss: 0.336812]\n",
      "epoch:24 step:23226 [D loss: 0.244433, acc.: 52.34%] [G loss: 0.319363]\n",
      "epoch:24 step:23227 [D loss: 0.245272, acc.: 57.81%] [G loss: 0.304774]\n",
      "epoch:24 step:23228 [D loss: 0.251910, acc.: 57.81%] [G loss: 0.285410]\n",
      "epoch:24 step:23229 [D loss: 0.231789, acc.: 60.94%] [G loss: 0.267882]\n",
      "epoch:24 step:23230 [D loss: 0.248352, acc.: 53.91%] [G loss: 0.304089]\n",
      "epoch:24 step:23231 [D loss: 0.224505, acc.: 57.81%] [G loss: 0.315724]\n",
      "epoch:24 step:23232 [D loss: 0.226389, acc.: 64.06%] [G loss: 0.304430]\n",
      "epoch:24 step:23233 [D loss: 0.235360, acc.: 58.59%] [G loss: 0.308007]\n",
      "epoch:24 step:23234 [D loss: 0.219502, acc.: 60.94%] [G loss: 0.303634]\n",
      "epoch:24 step:23235 [D loss: 0.246546, acc.: 54.69%] [G loss: 0.279400]\n",
      "epoch:24 step:23236 [D loss: 0.222703, acc.: 59.38%] [G loss: 0.316494]\n",
      "epoch:24 step:23237 [D loss: 0.251661, acc.: 54.69%] [G loss: 0.302763]\n",
      "epoch:24 step:23238 [D loss: 0.219886, acc.: 65.62%] [G loss: 0.326303]\n",
      "epoch:24 step:23239 [D loss: 0.234395, acc.: 63.28%] [G loss: 0.290860]\n",
      "epoch:24 step:23240 [D loss: 0.248497, acc.: 51.56%] [G loss: 0.288980]\n",
      "epoch:24 step:23241 [D loss: 0.233534, acc.: 55.47%] [G loss: 0.312508]\n",
      "epoch:24 step:23242 [D loss: 0.243180, acc.: 57.81%] [G loss: 0.292899]\n",
      "epoch:24 step:23243 [D loss: 0.257204, acc.: 50.78%] [G loss: 0.287492]\n",
      "epoch:24 step:23244 [D loss: 0.242997, acc.: 54.69%] [G loss: 0.294848]\n",
      "epoch:24 step:23245 [D loss: 0.227667, acc.: 65.62%] [G loss: 0.294454]\n",
      "epoch:24 step:23246 [D loss: 0.241769, acc.: 53.91%] [G loss: 0.294865]\n",
      "epoch:24 step:23247 [D loss: 0.222323, acc.: 64.84%] [G loss: 0.311846]\n",
      "epoch:24 step:23248 [D loss: 0.223638, acc.: 60.94%] [G loss: 0.324448]\n",
      "epoch:24 step:23249 [D loss: 0.239757, acc.: 60.94%] [G loss: 0.322365]\n",
      "epoch:24 step:23250 [D loss: 0.237405, acc.: 53.12%] [G loss: 0.310575]\n",
      "epoch:24 step:23251 [D loss: 0.214120, acc.: 68.75%] [G loss: 0.304859]\n",
      "epoch:24 step:23252 [D loss: 0.245572, acc.: 57.03%] [G loss: 0.295583]\n",
      "epoch:24 step:23253 [D loss: 0.237253, acc.: 61.72%] [G loss: 0.330773]\n",
      "epoch:24 step:23254 [D loss: 0.251866, acc.: 50.78%] [G loss: 0.294787]\n",
      "epoch:24 step:23255 [D loss: 0.230945, acc.: 66.41%] [G loss: 0.298273]\n",
      "epoch:24 step:23256 [D loss: 0.229816, acc.: 63.28%] [G loss: 0.299350]\n",
      "epoch:24 step:23257 [D loss: 0.244278, acc.: 48.44%] [G loss: 0.282033]\n",
      "epoch:24 step:23258 [D loss: 0.252769, acc.: 53.91%] [G loss: 0.314713]\n",
      "epoch:24 step:23259 [D loss: 0.243053, acc.: 54.69%] [G loss: 0.320647]\n",
      "epoch:24 step:23260 [D loss: 0.239738, acc.: 64.84%] [G loss: 0.288864]\n",
      "epoch:24 step:23261 [D loss: 0.249256, acc.: 53.12%] [G loss: 0.281261]\n",
      "epoch:24 step:23262 [D loss: 0.216686, acc.: 63.28%] [G loss: 0.324689]\n",
      "epoch:24 step:23263 [D loss: 0.243197, acc.: 53.91%] [G loss: 0.295639]\n",
      "epoch:24 step:23264 [D loss: 0.233635, acc.: 60.94%] [G loss: 0.302436]\n",
      "epoch:24 step:23265 [D loss: 0.220199, acc.: 67.97%] [G loss: 0.329233]\n",
      "epoch:24 step:23266 [D loss: 0.238971, acc.: 53.12%] [G loss: 0.306949]\n",
      "epoch:24 step:23267 [D loss: 0.259288, acc.: 51.56%] [G loss: 0.267091]\n",
      "epoch:24 step:23268 [D loss: 0.253704, acc.: 52.34%] [G loss: 0.321833]\n",
      "epoch:24 step:23269 [D loss: 0.225152, acc.: 64.06%] [G loss: 0.295672]\n",
      "epoch:24 step:23270 [D loss: 0.247383, acc.: 55.47%] [G loss: 0.267049]\n",
      "epoch:24 step:23271 [D loss: 0.229302, acc.: 63.28%] [G loss: 0.328089]\n",
      "epoch:24 step:23272 [D loss: 0.232380, acc.: 64.06%] [G loss: 0.296692]\n",
      "epoch:24 step:23273 [D loss: 0.234035, acc.: 57.03%] [G loss: 0.281627]\n",
      "epoch:24 step:23274 [D loss: 0.235254, acc.: 60.94%] [G loss: 0.274351]\n",
      "epoch:24 step:23275 [D loss: 0.248916, acc.: 55.47%] [G loss: 0.312531]\n",
      "epoch:24 step:23276 [D loss: 0.249809, acc.: 53.12%] [G loss: 0.279717]\n",
      "epoch:24 step:23277 [D loss: 0.241482, acc.: 53.12%] [G loss: 0.307768]\n",
      "epoch:24 step:23278 [D loss: 0.241229, acc.: 60.94%] [G loss: 0.302528]\n",
      "epoch:24 step:23279 [D loss: 0.223363, acc.: 69.53%] [G loss: 0.299580]\n",
      "epoch:24 step:23280 [D loss: 0.246178, acc.: 57.03%] [G loss: 0.315896]\n",
      "epoch:24 step:23281 [D loss: 0.234328, acc.: 59.38%] [G loss: 0.297382]\n",
      "epoch:24 step:23282 [D loss: 0.237699, acc.: 60.16%] [G loss: 0.296836]\n",
      "epoch:24 step:23283 [D loss: 0.258267, acc.: 53.91%] [G loss: 0.325040]\n",
      "epoch:24 step:23284 [D loss: 0.238429, acc.: 62.50%] [G loss: 0.303233]\n",
      "epoch:24 step:23285 [D loss: 0.231910, acc.: 62.50%] [G loss: 0.286088]\n",
      "epoch:24 step:23286 [D loss: 0.219538, acc.: 64.84%] [G loss: 0.289192]\n",
      "epoch:24 step:23287 [D loss: 0.232555, acc.: 64.84%] [G loss: 0.294053]\n",
      "epoch:24 step:23288 [D loss: 0.228653, acc.: 64.84%] [G loss: 0.281124]\n",
      "epoch:24 step:23289 [D loss: 0.244076, acc.: 55.47%] [G loss: 0.303497]\n",
      "epoch:24 step:23290 [D loss: 0.252286, acc.: 53.91%] [G loss: 0.294344]\n",
      "epoch:24 step:23291 [D loss: 0.248307, acc.: 59.38%] [G loss: 0.300031]\n",
      "epoch:24 step:23292 [D loss: 0.244619, acc.: 52.34%] [G loss: 0.277389]\n",
      "epoch:24 step:23293 [D loss: 0.220981, acc.: 68.75%] [G loss: 0.305400]\n",
      "epoch:24 step:23294 [D loss: 0.244118, acc.: 57.03%] [G loss: 0.285662]\n",
      "epoch:24 step:23295 [D loss: 0.244364, acc.: 59.38%] [G loss: 0.301478]\n",
      "epoch:24 step:23296 [D loss: 0.241743, acc.: 58.59%] [G loss: 0.288674]\n",
      "epoch:24 step:23297 [D loss: 0.235384, acc.: 57.03%] [G loss: 0.298260]\n",
      "epoch:24 step:23298 [D loss: 0.253100, acc.: 52.34%] [G loss: 0.316967]\n",
      "epoch:24 step:23299 [D loss: 0.228756, acc.: 59.38%] [G loss: 0.322247]\n",
      "epoch:24 step:23300 [D loss: 0.225030, acc.: 68.75%] [G loss: 0.313188]\n",
      "epoch:24 step:23301 [D loss: 0.228180, acc.: 61.72%] [G loss: 0.313962]\n",
      "epoch:24 step:23302 [D loss: 0.240007, acc.: 57.81%] [G loss: 0.290772]\n",
      "epoch:24 step:23303 [D loss: 0.236817, acc.: 58.59%] [G loss: 0.309968]\n",
      "epoch:24 step:23304 [D loss: 0.225148, acc.: 57.81%] [G loss: 0.295773]\n",
      "epoch:24 step:23305 [D loss: 0.250270, acc.: 52.34%] [G loss: 0.302835]\n",
      "epoch:24 step:23306 [D loss: 0.231926, acc.: 59.38%] [G loss: 0.315528]\n",
      "epoch:24 step:23307 [D loss: 0.222385, acc.: 66.41%] [G loss: 0.290778]\n",
      "epoch:24 step:23308 [D loss: 0.235081, acc.: 60.94%] [G loss: 0.274861]\n",
      "epoch:24 step:23309 [D loss: 0.241579, acc.: 60.16%] [G loss: 0.289919]\n",
      "epoch:24 step:23310 [D loss: 0.235796, acc.: 64.06%] [G loss: 0.345528]\n",
      "epoch:24 step:23311 [D loss: 0.238447, acc.: 57.03%] [G loss: 0.315282]\n",
      "epoch:24 step:23312 [D loss: 0.245966, acc.: 54.69%] [G loss: 0.294599]\n",
      "epoch:24 step:23313 [D loss: 0.231059, acc.: 60.16%] [G loss: 0.289000]\n",
      "epoch:24 step:23314 [D loss: 0.243509, acc.: 54.69%] [G loss: 0.279007]\n",
      "epoch:24 step:23315 [D loss: 0.227342, acc.: 63.28%] [G loss: 0.348634]\n",
      "epoch:24 step:23316 [D loss: 0.241063, acc.: 58.59%] [G loss: 0.298672]\n",
      "epoch:24 step:23317 [D loss: 0.243260, acc.: 58.59%] [G loss: 0.308542]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:24 step:23318 [D loss: 0.248697, acc.: 59.38%] [G loss: 0.281105]\n",
      "epoch:24 step:23319 [D loss: 0.252613, acc.: 59.38%] [G loss: 0.277224]\n",
      "epoch:24 step:23320 [D loss: 0.249630, acc.: 51.56%] [G loss: 0.296618]\n",
      "epoch:24 step:23321 [D loss: 0.245068, acc.: 58.59%] [G loss: 0.271437]\n",
      "epoch:24 step:23322 [D loss: 0.261956, acc.: 48.44%] [G loss: 0.320021]\n",
      "epoch:24 step:23323 [D loss: 0.238495, acc.: 56.25%] [G loss: 0.272256]\n",
      "epoch:24 step:23324 [D loss: 0.229033, acc.: 63.28%] [G loss: 0.311658]\n",
      "epoch:24 step:23325 [D loss: 0.207733, acc.: 69.53%] [G loss: 0.344665]\n",
      "epoch:24 step:23326 [D loss: 0.237816, acc.: 57.81%] [G loss: 0.308192]\n",
      "epoch:24 step:23327 [D loss: 0.228472, acc.: 57.03%] [G loss: 0.311816]\n",
      "epoch:24 step:23328 [D loss: 0.225856, acc.: 64.84%] [G loss: 0.286607]\n",
      "epoch:24 step:23329 [D loss: 0.240775, acc.: 63.28%] [G loss: 0.286563]\n",
      "epoch:24 step:23330 [D loss: 0.248402, acc.: 55.47%] [G loss: 0.293975]\n",
      "epoch:24 step:23331 [D loss: 0.245171, acc.: 53.12%] [G loss: 0.329370]\n",
      "epoch:24 step:23332 [D loss: 0.234417, acc.: 58.59%] [G loss: 0.285378]\n",
      "epoch:24 step:23333 [D loss: 0.251642, acc.: 53.12%] [G loss: 0.282432]\n",
      "epoch:24 step:23334 [D loss: 0.246166, acc.: 58.59%] [G loss: 0.286406]\n",
      "epoch:24 step:23335 [D loss: 0.237476, acc.: 55.47%] [G loss: 0.296685]\n",
      "epoch:24 step:23336 [D loss: 0.225577, acc.: 62.50%] [G loss: 0.316905]\n",
      "epoch:24 step:23337 [D loss: 0.237691, acc.: 57.03%] [G loss: 0.325768]\n",
      "epoch:24 step:23338 [D loss: 0.228854, acc.: 62.50%] [G loss: 0.312090]\n",
      "epoch:24 step:23339 [D loss: 0.239476, acc.: 54.69%] [G loss: 0.333279]\n",
      "epoch:24 step:23340 [D loss: 0.236998, acc.: 56.25%] [G loss: 0.299815]\n",
      "epoch:24 step:23341 [D loss: 0.215182, acc.: 68.75%] [G loss: 0.312227]\n",
      "epoch:24 step:23342 [D loss: 0.241713, acc.: 56.25%] [G loss: 0.329019]\n",
      "epoch:24 step:23343 [D loss: 0.246824, acc.: 54.69%] [G loss: 0.301819]\n",
      "epoch:24 step:23344 [D loss: 0.224532, acc.: 60.16%] [G loss: 0.316486]\n",
      "epoch:24 step:23345 [D loss: 0.249388, acc.: 58.59%] [G loss: 0.308983]\n",
      "epoch:24 step:23346 [D loss: 0.242481, acc.: 57.03%] [G loss: 0.278737]\n",
      "epoch:24 step:23347 [D loss: 0.236649, acc.: 59.38%] [G loss: 0.304448]\n",
      "epoch:24 step:23348 [D loss: 0.253197, acc.: 57.03%] [G loss: 0.347381]\n",
      "epoch:24 step:23349 [D loss: 0.235997, acc.: 59.38%] [G loss: 0.278766]\n",
      "epoch:24 step:23350 [D loss: 0.262200, acc.: 52.34%] [G loss: 0.287875]\n",
      "epoch:24 step:23351 [D loss: 0.236880, acc.: 57.81%] [G loss: 0.290652]\n",
      "epoch:24 step:23352 [D loss: 0.233693, acc.: 62.50%] [G loss: 0.300316]\n",
      "epoch:24 step:23353 [D loss: 0.220590, acc.: 64.84%] [G loss: 0.302411]\n",
      "epoch:24 step:23354 [D loss: 0.235502, acc.: 57.03%] [G loss: 0.309847]\n",
      "epoch:24 step:23355 [D loss: 0.227235, acc.: 62.50%] [G loss: 0.314760]\n",
      "epoch:24 step:23356 [D loss: 0.247523, acc.: 55.47%] [G loss: 0.301216]\n",
      "epoch:24 step:23357 [D loss: 0.230951, acc.: 60.94%] [G loss: 0.321406]\n",
      "epoch:24 step:23358 [D loss: 0.234156, acc.: 57.81%] [G loss: 0.342011]\n",
      "epoch:24 step:23359 [D loss: 0.245581, acc.: 52.34%] [G loss: 0.311281]\n",
      "epoch:24 step:23360 [D loss: 0.243416, acc.: 55.47%] [G loss: 0.308973]\n",
      "epoch:24 step:23361 [D loss: 0.229229, acc.: 61.72%] [G loss: 0.313976]\n",
      "epoch:24 step:23362 [D loss: 0.221666, acc.: 69.53%] [G loss: 0.317232]\n",
      "epoch:24 step:23363 [D loss: 0.238335, acc.: 59.38%] [G loss: 0.307707]\n",
      "epoch:24 step:23364 [D loss: 0.231540, acc.: 58.59%] [G loss: 0.317752]\n",
      "epoch:24 step:23365 [D loss: 0.228133, acc.: 63.28%] [G loss: 0.288707]\n",
      "epoch:24 step:23366 [D loss: 0.235728, acc.: 60.94%] [G loss: 0.278372]\n",
      "epoch:24 step:23367 [D loss: 0.237332, acc.: 60.16%] [G loss: 0.316813]\n",
      "epoch:24 step:23368 [D loss: 0.247850, acc.: 55.47%] [G loss: 0.273081]\n",
      "epoch:24 step:23369 [D loss: 0.227721, acc.: 61.72%] [G loss: 0.296010]\n",
      "epoch:24 step:23370 [D loss: 0.230022, acc.: 60.16%] [G loss: 0.304333]\n",
      "epoch:24 step:23371 [D loss: 0.227776, acc.: 66.41%] [G loss: 0.282174]\n",
      "epoch:24 step:23372 [D loss: 0.228652, acc.: 64.84%] [G loss: 0.301818]\n",
      "epoch:24 step:23373 [D loss: 0.240777, acc.: 61.72%] [G loss: 0.293212]\n",
      "epoch:24 step:23374 [D loss: 0.238417, acc.: 60.16%] [G loss: 0.328536]\n",
      "epoch:24 step:23375 [D loss: 0.262399, acc.: 49.22%] [G loss: 0.279442]\n",
      "epoch:24 step:23376 [D loss: 0.237497, acc.: 60.16%] [G loss: 0.317090]\n",
      "epoch:24 step:23377 [D loss: 0.237072, acc.: 57.81%] [G loss: 0.305169]\n",
      "epoch:24 step:23378 [D loss: 0.216800, acc.: 64.84%] [G loss: 0.329765]\n",
      "epoch:24 step:23379 [D loss: 0.236049, acc.: 61.72%] [G loss: 0.289459]\n",
      "epoch:24 step:23380 [D loss: 0.256006, acc.: 49.22%] [G loss: 0.306846]\n",
      "epoch:24 step:23381 [D loss: 0.226760, acc.: 60.16%] [G loss: 0.306960]\n",
      "epoch:24 step:23382 [D loss: 0.231180, acc.: 63.28%] [G loss: 0.314232]\n",
      "epoch:24 step:23383 [D loss: 0.240694, acc.: 53.91%] [G loss: 0.306193]\n",
      "epoch:24 step:23384 [D loss: 0.239013, acc.: 60.94%] [G loss: 0.286318]\n",
      "epoch:24 step:23385 [D loss: 0.245161, acc.: 57.03%] [G loss: 0.306230]\n",
      "epoch:24 step:23386 [D loss: 0.223232, acc.: 62.50%] [G loss: 0.296349]\n",
      "epoch:24 step:23387 [D loss: 0.221188, acc.: 65.62%] [G loss: 0.269120]\n",
      "epoch:24 step:23388 [D loss: 0.240295, acc.: 55.47%] [G loss: 0.313579]\n",
      "epoch:24 step:23389 [D loss: 0.253222, acc.: 51.56%] [G loss: 0.277116]\n",
      "epoch:24 step:23390 [D loss: 0.230147, acc.: 64.06%] [G loss: 0.296844]\n",
      "epoch:24 step:23391 [D loss: 0.232642, acc.: 62.50%] [G loss: 0.277978]\n",
      "epoch:24 step:23392 [D loss: 0.208478, acc.: 72.66%] [G loss: 0.296581]\n",
      "epoch:24 step:23393 [D loss: 0.229949, acc.: 65.62%] [G loss: 0.301750]\n",
      "epoch:24 step:23394 [D loss: 0.241802, acc.: 58.59%] [G loss: 0.300697]\n",
      "epoch:24 step:23395 [D loss: 0.231413, acc.: 60.94%] [G loss: 0.302571]\n",
      "epoch:24 step:23396 [D loss: 0.269214, acc.: 53.12%] [G loss: 0.305096]\n",
      "epoch:24 step:23397 [D loss: 0.246635, acc.: 50.00%] [G loss: 0.289575]\n",
      "epoch:24 step:23398 [D loss: 0.218858, acc.: 69.53%] [G loss: 0.298067]\n",
      "epoch:24 step:23399 [D loss: 0.230814, acc.: 64.06%] [G loss: 0.328747]\n",
      "epoch:24 step:23400 [D loss: 0.227820, acc.: 63.28%] [G loss: 0.304763]\n",
      "epoch:24 step:23401 [D loss: 0.233982, acc.: 57.03%] [G loss: 0.294753]\n",
      "epoch:24 step:23402 [D loss: 0.229636, acc.: 64.84%] [G loss: 0.285636]\n",
      "epoch:24 step:23403 [D loss: 0.233309, acc.: 62.50%] [G loss: 0.315759]\n",
      "epoch:24 step:23404 [D loss: 0.216127, acc.: 67.19%] [G loss: 0.312231]\n",
      "epoch:24 step:23405 [D loss: 0.232177, acc.: 61.72%] [G loss: 0.279655]\n",
      "epoch:24 step:23406 [D loss: 0.243188, acc.: 57.81%] [G loss: 0.288774]\n",
      "epoch:24 step:23407 [D loss: 0.238061, acc.: 57.81%] [G loss: 0.298285]\n",
      "epoch:24 step:23408 [D loss: 0.218317, acc.: 64.84%] [G loss: 0.323262]\n",
      "epoch:24 step:23409 [D loss: 0.222391, acc.: 60.94%] [G loss: 0.308850]\n",
      "epoch:24 step:23410 [D loss: 0.256929, acc.: 50.78%] [G loss: 0.307408]\n",
      "epoch:24 step:23411 [D loss: 0.258390, acc.: 52.34%] [G loss: 0.303072]\n",
      "epoch:24 step:23412 [D loss: 0.250736, acc.: 54.69%] [G loss: 0.267335]\n",
      "epoch:24 step:23413 [D loss: 0.241432, acc.: 57.81%] [G loss: 0.307527]\n",
      "epoch:24 step:23414 [D loss: 0.240922, acc.: 62.50%] [G loss: 0.292927]\n",
      "epoch:24 step:23415 [D loss: 0.256877, acc.: 51.56%] [G loss: 0.295054]\n",
      "epoch:24 step:23416 [D loss: 0.238496, acc.: 57.03%] [G loss: 0.317275]\n",
      "epoch:24 step:23417 [D loss: 0.242312, acc.: 59.38%] [G loss: 0.313027]\n",
      "epoch:24 step:23418 [D loss: 0.243576, acc.: 59.38%] [G loss: 0.321951]\n",
      "epoch:24 step:23419 [D loss: 0.255126, acc.: 52.34%] [G loss: 0.260620]\n",
      "epoch:24 step:23420 [D loss: 0.241082, acc.: 55.47%] [G loss: 0.308831]\n",
      "epoch:24 step:23421 [D loss: 0.252077, acc.: 54.69%] [G loss: 0.299852]\n",
      "epoch:24 step:23422 [D loss: 0.218499, acc.: 65.62%] [G loss: 0.320596]\n",
      "epoch:24 step:23423 [D loss: 0.230718, acc.: 59.38%] [G loss: 0.309641]\n",
      "epoch:24 step:23424 [D loss: 0.241032, acc.: 57.81%] [G loss: 0.290429]\n",
      "epoch:24 step:23425 [D loss: 0.227259, acc.: 61.72%] [G loss: 0.328856]\n",
      "epoch:25 step:23426 [D loss: 0.230289, acc.: 59.38%] [G loss: 0.310260]\n",
      "epoch:25 step:23427 [D loss: 0.236468, acc.: 56.25%] [G loss: 0.300558]\n",
      "epoch:25 step:23428 [D loss: 0.228626, acc.: 65.62%] [G loss: 0.292969]\n",
      "epoch:25 step:23429 [D loss: 0.243047, acc.: 59.38%] [G loss: 0.287531]\n",
      "epoch:25 step:23430 [D loss: 0.249632, acc.: 55.47%] [G loss: 0.330779]\n",
      "epoch:25 step:23431 [D loss: 0.267209, acc.: 43.75%] [G loss: 0.292324]\n",
      "epoch:25 step:23432 [D loss: 0.254564, acc.: 53.91%] [G loss: 0.292307]\n",
      "epoch:25 step:23433 [D loss: 0.243324, acc.: 56.25%] [G loss: 0.294573]\n",
      "epoch:25 step:23434 [D loss: 0.226861, acc.: 63.28%] [G loss: 0.295730]\n",
      "epoch:25 step:23435 [D loss: 0.232327, acc.: 61.72%] [G loss: 0.306717]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:25 step:23436 [D loss: 0.229252, acc.: 60.94%] [G loss: 0.269312]\n",
      "epoch:25 step:23437 [D loss: 0.225408, acc.: 58.59%] [G loss: 0.311560]\n",
      "epoch:25 step:23438 [D loss: 0.250587, acc.: 53.91%] [G loss: 0.302174]\n",
      "epoch:25 step:23439 [D loss: 0.231789, acc.: 60.16%] [G loss: 0.301064]\n",
      "epoch:25 step:23440 [D loss: 0.238644, acc.: 58.59%] [G loss: 0.297544]\n",
      "epoch:25 step:23441 [D loss: 0.241413, acc.: 60.94%] [G loss: 0.295266]\n",
      "epoch:25 step:23442 [D loss: 0.239888, acc.: 52.34%] [G loss: 0.282392]\n",
      "epoch:25 step:23443 [D loss: 0.232572, acc.: 66.41%] [G loss: 0.300608]\n",
      "epoch:25 step:23444 [D loss: 0.258022, acc.: 50.00%] [G loss: 0.302686]\n",
      "epoch:25 step:23445 [D loss: 0.233281, acc.: 59.38%] [G loss: 0.299902]\n",
      "epoch:25 step:23446 [D loss: 0.240238, acc.: 57.03%] [G loss: 0.313795]\n",
      "epoch:25 step:23447 [D loss: 0.255673, acc.: 49.22%] [G loss: 0.313833]\n",
      "epoch:25 step:23448 [D loss: 0.251023, acc.: 55.47%] [G loss: 0.301604]\n",
      "epoch:25 step:23449 [D loss: 0.231511, acc.: 62.50%] [G loss: 0.289892]\n",
      "epoch:25 step:23450 [D loss: 0.237237, acc.: 59.38%] [G loss: 0.310694]\n",
      "epoch:25 step:23451 [D loss: 0.235507, acc.: 60.16%] [G loss: 0.306657]\n",
      "epoch:25 step:23452 [D loss: 0.250053, acc.: 56.25%] [G loss: 0.308458]\n",
      "epoch:25 step:23453 [D loss: 0.256211, acc.: 52.34%] [G loss: 0.296969]\n",
      "epoch:25 step:23454 [D loss: 0.238732, acc.: 60.94%] [G loss: 0.290346]\n",
      "epoch:25 step:23455 [D loss: 0.240644, acc.: 60.94%] [G loss: 0.307821]\n",
      "epoch:25 step:23456 [D loss: 0.245354, acc.: 60.16%] [G loss: 0.295464]\n",
      "epoch:25 step:23457 [D loss: 0.243211, acc.: 55.47%] [G loss: 0.303557]\n",
      "epoch:25 step:23458 [D loss: 0.242165, acc.: 55.47%] [G loss: 0.285381]\n",
      "epoch:25 step:23459 [D loss: 0.258288, acc.: 51.56%] [G loss: 0.293951]\n",
      "epoch:25 step:23460 [D loss: 0.234025, acc.: 65.62%] [G loss: 0.314266]\n",
      "epoch:25 step:23461 [D loss: 0.227298, acc.: 61.72%] [G loss: 0.305562]\n",
      "epoch:25 step:23462 [D loss: 0.253634, acc.: 52.34%] [G loss: 0.304819]\n",
      "epoch:25 step:23463 [D loss: 0.233938, acc.: 60.94%] [G loss: 0.314059]\n",
      "epoch:25 step:23464 [D loss: 0.225599, acc.: 62.50%] [G loss: 0.279634]\n",
      "epoch:25 step:23465 [D loss: 0.229928, acc.: 60.94%] [G loss: 0.302574]\n",
      "epoch:25 step:23466 [D loss: 0.235179, acc.: 61.72%] [G loss: 0.312161]\n",
      "epoch:25 step:23467 [D loss: 0.242836, acc.: 57.81%] [G loss: 0.283152]\n",
      "epoch:25 step:23468 [D loss: 0.219404, acc.: 62.50%] [G loss: 0.330105]\n",
      "epoch:25 step:23469 [D loss: 0.249081, acc.: 56.25%] [G loss: 0.314541]\n",
      "epoch:25 step:23470 [D loss: 0.233477, acc.: 56.25%] [G loss: 0.313556]\n",
      "epoch:25 step:23471 [D loss: 0.254458, acc.: 52.34%] [G loss: 0.294430]\n",
      "epoch:25 step:23472 [D loss: 0.237811, acc.: 57.81%] [G loss: 0.304330]\n",
      "epoch:25 step:23473 [D loss: 0.251426, acc.: 52.34%] [G loss: 0.304857]\n",
      "epoch:25 step:23474 [D loss: 0.253277, acc.: 51.56%] [G loss: 0.293923]\n",
      "epoch:25 step:23475 [D loss: 0.232015, acc.: 59.38%] [G loss: 0.301908]\n",
      "epoch:25 step:23476 [D loss: 0.232360, acc.: 61.72%] [G loss: 0.303551]\n",
      "epoch:25 step:23477 [D loss: 0.233474, acc.: 57.81%] [G loss: 0.298182]\n",
      "epoch:25 step:23478 [D loss: 0.228506, acc.: 66.41%] [G loss: 0.293393]\n",
      "epoch:25 step:23479 [D loss: 0.236545, acc.: 64.06%] [G loss: 0.316933]\n",
      "epoch:25 step:23480 [D loss: 0.231524, acc.: 60.94%] [G loss: 0.282263]\n",
      "epoch:25 step:23481 [D loss: 0.253575, acc.: 51.56%] [G loss: 0.285748]\n",
      "epoch:25 step:23482 [D loss: 0.225733, acc.: 61.72%] [G loss: 0.288283]\n",
      "epoch:25 step:23483 [D loss: 0.243340, acc.: 56.25%] [G loss: 0.298152]\n",
      "epoch:25 step:23484 [D loss: 0.226669, acc.: 60.94%] [G loss: 0.300034]\n",
      "epoch:25 step:23485 [D loss: 0.247803, acc.: 56.25%] [G loss: 0.260302]\n",
      "epoch:25 step:23486 [D loss: 0.248894, acc.: 53.12%] [G loss: 0.306262]\n",
      "epoch:25 step:23487 [D loss: 0.246058, acc.: 55.47%] [G loss: 0.295689]\n",
      "epoch:25 step:23488 [D loss: 0.227673, acc.: 57.81%] [G loss: 0.291561]\n",
      "epoch:25 step:23489 [D loss: 0.228627, acc.: 64.06%] [G loss: 0.327031]\n",
      "epoch:25 step:23490 [D loss: 0.233497, acc.: 63.28%] [G loss: 0.306453]\n",
      "epoch:25 step:23491 [D loss: 0.235152, acc.: 60.94%] [G loss: 0.300107]\n",
      "epoch:25 step:23492 [D loss: 0.236517, acc.: 60.94%] [G loss: 0.293291]\n",
      "epoch:25 step:23493 [D loss: 0.240232, acc.: 59.38%] [G loss: 0.329321]\n",
      "epoch:25 step:23494 [D loss: 0.240508, acc.: 57.03%] [G loss: 0.306576]\n",
      "epoch:25 step:23495 [D loss: 0.236461, acc.: 52.34%] [G loss: 0.325630]\n",
      "epoch:25 step:23496 [D loss: 0.237064, acc.: 59.38%] [G loss: 0.285652]\n",
      "epoch:25 step:23497 [D loss: 0.242576, acc.: 56.25%] [G loss: 0.310305]\n",
      "epoch:25 step:23498 [D loss: 0.234062, acc.: 59.38%] [G loss: 0.304677]\n",
      "epoch:25 step:23499 [D loss: 0.238087, acc.: 60.16%] [G loss: 0.300680]\n",
      "epoch:25 step:23500 [D loss: 0.222236, acc.: 60.16%] [G loss: 0.321209]\n",
      "epoch:25 step:23501 [D loss: 0.233657, acc.: 57.03%] [G loss: 0.306054]\n",
      "epoch:25 step:23502 [D loss: 0.244073, acc.: 55.47%] [G loss: 0.319618]\n",
      "epoch:25 step:23503 [D loss: 0.229399, acc.: 60.16%] [G loss: 0.305699]\n",
      "epoch:25 step:23504 [D loss: 0.235261, acc.: 59.38%] [G loss: 0.294182]\n",
      "epoch:25 step:23505 [D loss: 0.252091, acc.: 55.47%] [G loss: 0.300296]\n",
      "epoch:25 step:23506 [D loss: 0.252765, acc.: 49.22%] [G loss: 0.310235]\n",
      "epoch:25 step:23507 [D loss: 0.244083, acc.: 57.81%] [G loss: 0.283751]\n",
      "epoch:25 step:23508 [D loss: 0.238830, acc.: 53.91%] [G loss: 0.314925]\n",
      "epoch:25 step:23509 [D loss: 0.233040, acc.: 58.59%] [G loss: 0.317695]\n",
      "epoch:25 step:23510 [D loss: 0.219071, acc.: 65.62%] [G loss: 0.299832]\n",
      "epoch:25 step:23511 [D loss: 0.250667, acc.: 56.25%] [G loss: 0.320954]\n",
      "epoch:25 step:23512 [D loss: 0.234912, acc.: 64.06%] [G loss: 0.294343]\n",
      "epoch:25 step:23513 [D loss: 0.252809, acc.: 52.34%] [G loss: 0.275217]\n",
      "epoch:25 step:23514 [D loss: 0.258224, acc.: 50.00%] [G loss: 0.293162]\n",
      "epoch:25 step:23515 [D loss: 0.244261, acc.: 54.69%] [G loss: 0.309664]\n",
      "epoch:25 step:23516 [D loss: 0.233111, acc.: 57.03%] [G loss: 0.303563]\n",
      "epoch:25 step:23517 [D loss: 0.247703, acc.: 53.12%] [G loss: 0.322479]\n",
      "epoch:25 step:23518 [D loss: 0.243599, acc.: 56.25%] [G loss: 0.313980]\n",
      "epoch:25 step:23519 [D loss: 0.214413, acc.: 73.44%] [G loss: 0.314260]\n",
      "epoch:25 step:23520 [D loss: 0.238526, acc.: 59.38%] [G loss: 0.319470]\n",
      "epoch:25 step:23521 [D loss: 0.243171, acc.: 57.03%] [G loss: 0.299697]\n",
      "epoch:25 step:23522 [D loss: 0.245837, acc.: 57.03%] [G loss: 0.283958]\n",
      "epoch:25 step:23523 [D loss: 0.236402, acc.: 57.03%] [G loss: 0.344615]\n",
      "epoch:25 step:23524 [D loss: 0.244973, acc.: 61.72%] [G loss: 0.337954]\n",
      "epoch:25 step:23525 [D loss: 0.235796, acc.: 59.38%] [G loss: 0.294586]\n",
      "epoch:25 step:23526 [D loss: 0.238903, acc.: 54.69%] [G loss: 0.319874]\n",
      "epoch:25 step:23527 [D loss: 0.235046, acc.: 57.03%] [G loss: 0.307937]\n",
      "epoch:25 step:23528 [D loss: 0.242056, acc.: 60.94%] [G loss: 0.341666]\n",
      "epoch:25 step:23529 [D loss: 0.243046, acc.: 57.81%] [G loss: 0.286718]\n",
      "epoch:25 step:23530 [D loss: 0.229319, acc.: 65.62%] [G loss: 0.293876]\n",
      "epoch:25 step:23531 [D loss: 0.257103, acc.: 53.91%] [G loss: 0.317232]\n",
      "epoch:25 step:23532 [D loss: 0.234702, acc.: 57.03%] [G loss: 0.280882]\n",
      "epoch:25 step:23533 [D loss: 0.235663, acc.: 59.38%] [G loss: 0.314350]\n",
      "epoch:25 step:23534 [D loss: 0.220450, acc.: 64.84%] [G loss: 0.324624]\n",
      "epoch:25 step:23535 [D loss: 0.231355, acc.: 61.72%] [G loss: 0.319642]\n",
      "epoch:25 step:23536 [D loss: 0.226868, acc.: 61.72%] [G loss: 0.311931]\n",
      "epoch:25 step:23537 [D loss: 0.232408, acc.: 63.28%] [G loss: 0.298079]\n",
      "epoch:25 step:23538 [D loss: 0.238053, acc.: 57.81%] [G loss: 0.271217]\n",
      "epoch:25 step:23539 [D loss: 0.239281, acc.: 60.94%] [G loss: 0.292211]\n",
      "epoch:25 step:23540 [D loss: 0.234155, acc.: 64.06%] [G loss: 0.308114]\n",
      "epoch:25 step:23541 [D loss: 0.249292, acc.: 55.47%] [G loss: 0.264312]\n",
      "epoch:25 step:23542 [D loss: 0.242856, acc.: 53.12%] [G loss: 0.298773]\n",
      "epoch:25 step:23543 [D loss: 0.236033, acc.: 63.28%] [G loss: 0.316401]\n",
      "epoch:25 step:23544 [D loss: 0.238908, acc.: 57.81%] [G loss: 0.305732]\n",
      "epoch:25 step:23545 [D loss: 0.259849, acc.: 51.56%] [G loss: 0.292985]\n",
      "epoch:25 step:23546 [D loss: 0.248173, acc.: 54.69%] [G loss: 0.279817]\n",
      "epoch:25 step:23547 [D loss: 0.256930, acc.: 50.00%] [G loss: 0.302689]\n",
      "epoch:25 step:23548 [D loss: 0.230057, acc.: 62.50%] [G loss: 0.291595]\n",
      "epoch:25 step:23549 [D loss: 0.227578, acc.: 60.16%] [G loss: 0.297076]\n",
      "epoch:25 step:23550 [D loss: 0.237575, acc.: 57.03%] [G loss: 0.282996]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:25 step:23551 [D loss: 0.251118, acc.: 56.25%] [G loss: 0.313551]\n",
      "epoch:25 step:23552 [D loss: 0.258530, acc.: 50.78%] [G loss: 0.265270]\n",
      "epoch:25 step:23553 [D loss: 0.252295, acc.: 58.59%] [G loss: 0.292654]\n",
      "epoch:25 step:23554 [D loss: 0.227561, acc.: 64.06%] [G loss: 0.310664]\n",
      "epoch:25 step:23555 [D loss: 0.234632, acc.: 62.50%] [G loss: 0.307821]\n",
      "epoch:25 step:23556 [D loss: 0.242510, acc.: 57.81%] [G loss: 0.305595]\n",
      "epoch:25 step:23557 [D loss: 0.239155, acc.: 60.16%] [G loss: 0.309804]\n",
      "epoch:25 step:23558 [D loss: 0.236179, acc.: 61.72%] [G loss: 0.279527]\n",
      "epoch:25 step:23559 [D loss: 0.259358, acc.: 57.03%] [G loss: 0.284238]\n",
      "epoch:25 step:23560 [D loss: 0.254390, acc.: 50.78%] [G loss: 0.290919]\n",
      "epoch:25 step:23561 [D loss: 0.235708, acc.: 60.94%] [G loss: 0.319542]\n",
      "epoch:25 step:23562 [D loss: 0.250395, acc.: 59.38%] [G loss: 0.295029]\n",
      "epoch:25 step:23563 [D loss: 0.226675, acc.: 61.72%] [G loss: 0.281765]\n",
      "epoch:25 step:23564 [D loss: 0.249707, acc.: 50.78%] [G loss: 0.308672]\n",
      "epoch:25 step:23565 [D loss: 0.239333, acc.: 61.72%] [G loss: 0.299622]\n",
      "epoch:25 step:23566 [D loss: 0.252089, acc.: 56.25%] [G loss: 0.308315]\n",
      "epoch:25 step:23567 [D loss: 0.236405, acc.: 58.59%] [G loss: 0.289819]\n",
      "epoch:25 step:23568 [D loss: 0.231717, acc.: 57.81%] [G loss: 0.313571]\n",
      "epoch:25 step:23569 [D loss: 0.235168, acc.: 60.94%] [G loss: 0.285196]\n",
      "epoch:25 step:23570 [D loss: 0.245243, acc.: 60.16%] [G loss: 0.289772]\n",
      "epoch:25 step:23571 [D loss: 0.238491, acc.: 58.59%] [G loss: 0.270300]\n",
      "epoch:25 step:23572 [D loss: 0.202275, acc.: 75.78%] [G loss: 0.332636]\n",
      "epoch:25 step:23573 [D loss: 0.240174, acc.: 59.38%] [G loss: 0.297376]\n",
      "epoch:25 step:23574 [D loss: 0.228079, acc.: 63.28%] [G loss: 0.297061]\n",
      "epoch:25 step:23575 [D loss: 0.240268, acc.: 57.81%] [G loss: 0.321085]\n",
      "epoch:25 step:23576 [D loss: 0.247809, acc.: 53.91%] [G loss: 0.316632]\n",
      "epoch:25 step:23577 [D loss: 0.222830, acc.: 67.19%] [G loss: 0.295399]\n",
      "epoch:25 step:23578 [D loss: 0.253258, acc.: 53.91%] [G loss: 0.301565]\n",
      "epoch:25 step:23579 [D loss: 0.254321, acc.: 56.25%] [G loss: 0.301946]\n",
      "epoch:25 step:23580 [D loss: 0.246804, acc.: 55.47%] [G loss: 0.285440]\n",
      "epoch:25 step:23581 [D loss: 0.227096, acc.: 63.28%] [G loss: 0.289766]\n",
      "epoch:25 step:23582 [D loss: 0.240395, acc.: 59.38%] [G loss: 0.313317]\n",
      "epoch:25 step:23583 [D loss: 0.242057, acc.: 52.34%] [G loss: 0.297691]\n",
      "epoch:25 step:23584 [D loss: 0.239564, acc.: 59.38%] [G loss: 0.290014]\n",
      "epoch:25 step:23585 [D loss: 0.229448, acc.: 60.16%] [G loss: 0.284797]\n",
      "epoch:25 step:23586 [D loss: 0.252111, acc.: 57.81%] [G loss: 0.277653]\n",
      "epoch:25 step:23587 [D loss: 0.239096, acc.: 59.38%] [G loss: 0.299603]\n",
      "epoch:25 step:23588 [D loss: 0.258058, acc.: 49.22%] [G loss: 0.302471]\n",
      "epoch:25 step:23589 [D loss: 0.241706, acc.: 58.59%] [G loss: 0.303242]\n",
      "epoch:25 step:23590 [D loss: 0.234063, acc.: 60.16%] [G loss: 0.297038]\n",
      "epoch:25 step:23591 [D loss: 0.240572, acc.: 58.59%] [G loss: 0.287163]\n",
      "epoch:25 step:23592 [D loss: 0.257485, acc.: 55.47%] [G loss: 0.286629]\n",
      "epoch:25 step:23593 [D loss: 0.234333, acc.: 56.25%] [G loss: 0.309647]\n",
      "epoch:25 step:23594 [D loss: 0.252979, acc.: 50.78%] [G loss: 0.298940]\n",
      "epoch:25 step:23595 [D loss: 0.232819, acc.: 60.94%] [G loss: 0.306849]\n",
      "epoch:25 step:23596 [D loss: 0.236182, acc.: 60.94%] [G loss: 0.320373]\n",
      "epoch:25 step:23597 [D loss: 0.227254, acc.: 60.94%] [G loss: 0.309857]\n",
      "epoch:25 step:23598 [D loss: 0.229368, acc.: 59.38%] [G loss: 0.335132]\n",
      "epoch:25 step:23599 [D loss: 0.235219, acc.: 57.81%] [G loss: 0.321251]\n",
      "epoch:25 step:23600 [D loss: 0.226309, acc.: 64.84%] [G loss: 0.348666]\n",
      "epoch:25 step:23601 [D loss: 0.243922, acc.: 56.25%] [G loss: 0.286271]\n",
      "epoch:25 step:23602 [D loss: 0.238356, acc.: 64.06%] [G loss: 0.285502]\n",
      "epoch:25 step:23603 [D loss: 0.243129, acc.: 57.81%] [G loss: 0.304340]\n",
      "epoch:25 step:23604 [D loss: 0.235750, acc.: 60.16%] [G loss: 0.319031]\n",
      "epoch:25 step:23605 [D loss: 0.209980, acc.: 66.41%] [G loss: 0.300816]\n",
      "epoch:25 step:23606 [D loss: 0.229581, acc.: 61.72%] [G loss: 0.306690]\n",
      "epoch:25 step:23607 [D loss: 0.227034, acc.: 64.84%] [G loss: 0.329759]\n",
      "epoch:25 step:23608 [D loss: 0.251954, acc.: 46.88%] [G loss: 0.322409]\n",
      "epoch:25 step:23609 [D loss: 0.240638, acc.: 59.38%] [G loss: 0.318953]\n",
      "epoch:25 step:23610 [D loss: 0.235057, acc.: 57.81%] [G loss: 0.329273]\n",
      "epoch:25 step:23611 [D loss: 0.245394, acc.: 57.03%] [G loss: 0.297968]\n",
      "epoch:25 step:23612 [D loss: 0.240583, acc.: 58.59%] [G loss: 0.337830]\n",
      "epoch:25 step:23613 [D loss: 0.245942, acc.: 57.81%] [G loss: 0.344270]\n",
      "epoch:25 step:23614 [D loss: 0.222606, acc.: 66.41%] [G loss: 0.318527]\n",
      "epoch:25 step:23615 [D loss: 0.255660, acc.: 51.56%] [G loss: 0.296839]\n",
      "epoch:25 step:23616 [D loss: 0.243231, acc.: 50.78%] [G loss: 0.305304]\n",
      "epoch:25 step:23617 [D loss: 0.223267, acc.: 64.84%] [G loss: 0.330079]\n",
      "epoch:25 step:23618 [D loss: 0.253200, acc.: 50.78%] [G loss: 0.284065]\n",
      "epoch:25 step:23619 [D loss: 0.255932, acc.: 57.03%] [G loss: 0.293441]\n",
      "epoch:25 step:23620 [D loss: 0.240562, acc.: 53.91%] [G loss: 0.308515]\n",
      "epoch:25 step:23621 [D loss: 0.255171, acc.: 50.78%] [G loss: 0.276382]\n",
      "epoch:25 step:23622 [D loss: 0.230427, acc.: 64.06%] [G loss: 0.308675]\n",
      "epoch:25 step:23623 [D loss: 0.232732, acc.: 55.47%] [G loss: 0.295086]\n",
      "epoch:25 step:23624 [D loss: 0.257878, acc.: 55.47%] [G loss: 0.279665]\n",
      "epoch:25 step:23625 [D loss: 0.239608, acc.: 57.81%] [G loss: 0.273090]\n",
      "epoch:25 step:23626 [D loss: 0.212603, acc.: 69.53%] [G loss: 0.326519]\n",
      "epoch:25 step:23627 [D loss: 0.238535, acc.: 58.59%] [G loss: 0.299977]\n",
      "epoch:25 step:23628 [D loss: 0.242201, acc.: 52.34%] [G loss: 0.300628]\n",
      "epoch:25 step:23629 [D loss: 0.227320, acc.: 64.84%] [G loss: 0.302532]\n",
      "epoch:25 step:23630 [D loss: 0.240470, acc.: 62.50%] [G loss: 0.311281]\n",
      "epoch:25 step:23631 [D loss: 0.228808, acc.: 64.84%] [G loss: 0.283394]\n",
      "epoch:25 step:23632 [D loss: 0.247659, acc.: 59.38%] [G loss: 0.289062]\n",
      "epoch:25 step:23633 [D loss: 0.236422, acc.: 60.94%] [G loss: 0.297075]\n",
      "epoch:25 step:23634 [D loss: 0.250513, acc.: 50.78%] [G loss: 0.300126]\n",
      "epoch:25 step:23635 [D loss: 0.234640, acc.: 60.16%] [G loss: 0.295480]\n",
      "epoch:25 step:23636 [D loss: 0.218290, acc.: 64.06%] [G loss: 0.310762]\n",
      "epoch:25 step:23637 [D loss: 0.233881, acc.: 60.16%] [G loss: 0.324562]\n",
      "epoch:25 step:23638 [D loss: 0.231986, acc.: 61.72%] [G loss: 0.302804]\n",
      "epoch:25 step:23639 [D loss: 0.239464, acc.: 60.94%] [G loss: 0.301405]\n",
      "epoch:25 step:23640 [D loss: 0.254500, acc.: 55.47%] [G loss: 0.296696]\n",
      "epoch:25 step:23641 [D loss: 0.232315, acc.: 67.97%] [G loss: 0.292650]\n",
      "epoch:25 step:23642 [D loss: 0.219404, acc.: 63.28%] [G loss: 0.298741]\n",
      "epoch:25 step:23643 [D loss: 0.244255, acc.: 59.38%] [G loss: 0.283786]\n",
      "epoch:25 step:23644 [D loss: 0.226710, acc.: 61.72%] [G loss: 0.341272]\n",
      "epoch:25 step:23645 [D loss: 0.246020, acc.: 54.69%] [G loss: 0.291059]\n",
      "epoch:25 step:23646 [D loss: 0.220654, acc.: 67.97%] [G loss: 0.290241]\n",
      "epoch:25 step:23647 [D loss: 0.255342, acc.: 54.69%] [G loss: 0.314506]\n",
      "epoch:25 step:23648 [D loss: 0.214916, acc.: 67.97%] [G loss: 0.333949]\n",
      "epoch:25 step:23649 [D loss: 0.240184, acc.: 59.38%] [G loss: 0.311016]\n",
      "epoch:25 step:23650 [D loss: 0.242062, acc.: 53.91%] [G loss: 0.282761]\n",
      "epoch:25 step:23651 [D loss: 0.247352, acc.: 52.34%] [G loss: 0.290729]\n",
      "epoch:25 step:23652 [D loss: 0.230140, acc.: 59.38%] [G loss: 0.325244]\n",
      "epoch:25 step:23653 [D loss: 0.248332, acc.: 54.69%] [G loss: 0.300866]\n",
      "epoch:25 step:23654 [D loss: 0.246649, acc.: 56.25%] [G loss: 0.297755]\n",
      "epoch:25 step:23655 [D loss: 0.238408, acc.: 60.94%] [G loss: 0.314571]\n",
      "epoch:25 step:23656 [D loss: 0.241367, acc.: 57.81%] [G loss: 0.312045]\n",
      "epoch:25 step:23657 [D loss: 0.228532, acc.: 60.16%] [G loss: 0.293183]\n",
      "epoch:25 step:23658 [D loss: 0.242515, acc.: 60.16%] [G loss: 0.332861]\n",
      "epoch:25 step:23659 [D loss: 0.237687, acc.: 60.16%] [G loss: 0.321172]\n",
      "epoch:25 step:23660 [D loss: 0.236901, acc.: 57.81%] [G loss: 0.292580]\n",
      "epoch:25 step:23661 [D loss: 0.231029, acc.: 63.28%] [G loss: 0.314069]\n",
      "epoch:25 step:23662 [D loss: 0.224462, acc.: 62.50%] [G loss: 0.289665]\n",
      "epoch:25 step:23663 [D loss: 0.264466, acc.: 50.00%] [G loss: 0.297476]\n",
      "epoch:25 step:23664 [D loss: 0.239879, acc.: 59.38%] [G loss: 0.288549]\n",
      "epoch:25 step:23665 [D loss: 0.251560, acc.: 54.69%] [G loss: 0.302787]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:25 step:23666 [D loss: 0.226854, acc.: 58.59%] [G loss: 0.304485]\n",
      "epoch:25 step:23667 [D loss: 0.258268, acc.: 54.69%] [G loss: 0.289351]\n",
      "epoch:25 step:23668 [D loss: 0.224382, acc.: 60.94%] [G loss: 0.266478]\n",
      "epoch:25 step:23669 [D loss: 0.233558, acc.: 59.38%] [G loss: 0.297382]\n",
      "epoch:25 step:23670 [D loss: 0.237210, acc.: 60.94%] [G loss: 0.303394]\n",
      "epoch:25 step:23671 [D loss: 0.248701, acc.: 61.72%] [G loss: 0.297200]\n",
      "epoch:25 step:23672 [D loss: 0.237963, acc.: 57.81%] [G loss: 0.319432]\n",
      "epoch:25 step:23673 [D loss: 0.254516, acc.: 50.00%] [G loss: 0.300136]\n",
      "epoch:25 step:23674 [D loss: 0.238735, acc.: 60.16%] [G loss: 0.300997]\n",
      "epoch:25 step:23675 [D loss: 0.240762, acc.: 55.47%] [G loss: 0.321976]\n",
      "epoch:25 step:23676 [D loss: 0.240019, acc.: 57.03%] [G loss: 0.292494]\n",
      "epoch:25 step:23677 [D loss: 0.235219, acc.: 56.25%] [G loss: 0.295495]\n",
      "epoch:25 step:23678 [D loss: 0.264513, acc.: 53.91%] [G loss: 0.291454]\n",
      "epoch:25 step:23679 [D loss: 0.244819, acc.: 60.16%] [G loss: 0.323328]\n",
      "epoch:25 step:23680 [D loss: 0.251761, acc.: 48.44%] [G loss: 0.276027]\n",
      "epoch:25 step:23681 [D loss: 0.239809, acc.: 60.16%] [G loss: 0.330511]\n",
      "epoch:25 step:23682 [D loss: 0.232337, acc.: 64.84%] [G loss: 0.310616]\n",
      "epoch:25 step:23683 [D loss: 0.245689, acc.: 52.34%] [G loss: 0.285618]\n",
      "epoch:25 step:23684 [D loss: 0.248239, acc.: 54.69%] [G loss: 0.256570]\n",
      "epoch:25 step:23685 [D loss: 0.262398, acc.: 50.00%] [G loss: 0.281943]\n",
      "epoch:25 step:23686 [D loss: 0.237183, acc.: 60.16%] [G loss: 0.270805]\n",
      "epoch:25 step:23687 [D loss: 0.221636, acc.: 65.62%] [G loss: 0.322864]\n",
      "epoch:25 step:23688 [D loss: 0.244401, acc.: 53.12%] [G loss: 0.300748]\n",
      "epoch:25 step:23689 [D loss: 0.229756, acc.: 62.50%] [G loss: 0.325458]\n",
      "epoch:25 step:23690 [D loss: 0.255740, acc.: 57.03%] [G loss: 0.284893]\n",
      "epoch:25 step:23691 [D loss: 0.229771, acc.: 63.28%] [G loss: 0.306475]\n",
      "epoch:25 step:23692 [D loss: 0.248253, acc.: 51.56%] [G loss: 0.296193]\n",
      "epoch:25 step:23693 [D loss: 0.232926, acc.: 59.38%] [G loss: 0.321960]\n",
      "epoch:25 step:23694 [D loss: 0.245417, acc.: 60.94%] [G loss: 0.329245]\n",
      "epoch:25 step:23695 [D loss: 0.239697, acc.: 59.38%] [G loss: 0.324630]\n",
      "epoch:25 step:23696 [D loss: 0.235419, acc.: 57.03%] [G loss: 0.306349]\n",
      "epoch:25 step:23697 [D loss: 0.235934, acc.: 59.38%] [G loss: 0.303573]\n",
      "epoch:25 step:23698 [D loss: 0.252096, acc.: 55.47%] [G loss: 0.299821]\n",
      "epoch:25 step:23699 [D loss: 0.224561, acc.: 69.53%] [G loss: 0.336185]\n",
      "epoch:25 step:23700 [D loss: 0.232803, acc.: 60.94%] [G loss: 0.317259]\n",
      "epoch:25 step:23701 [D loss: 0.240716, acc.: 59.38%] [G loss: 0.278861]\n",
      "epoch:25 step:23702 [D loss: 0.243647, acc.: 57.81%] [G loss: 0.320070]\n",
      "epoch:25 step:23703 [D loss: 0.242515, acc.: 60.16%] [G loss: 0.297069]\n",
      "epoch:25 step:23704 [D loss: 0.253118, acc.: 54.69%] [G loss: 0.320574]\n",
      "epoch:25 step:23705 [D loss: 0.227740, acc.: 62.50%] [G loss: 0.296291]\n",
      "epoch:25 step:23706 [D loss: 0.235368, acc.: 62.50%] [G loss: 0.290676]\n",
      "epoch:25 step:23707 [D loss: 0.249164, acc.: 54.69%] [G loss: 0.302426]\n",
      "epoch:25 step:23708 [D loss: 0.229499, acc.: 60.94%] [G loss: 0.325951]\n",
      "epoch:25 step:23709 [D loss: 0.236551, acc.: 56.25%] [G loss: 0.313868]\n",
      "epoch:25 step:23710 [D loss: 0.250995, acc.: 54.69%] [G loss: 0.288382]\n",
      "epoch:25 step:23711 [D loss: 0.245604, acc.: 61.72%] [G loss: 0.326304]\n",
      "epoch:25 step:23712 [D loss: 0.231162, acc.: 61.72%] [G loss: 0.294053]\n",
      "epoch:25 step:23713 [D loss: 0.252017, acc.: 53.91%] [G loss: 0.296411]\n",
      "epoch:25 step:23714 [D loss: 0.236699, acc.: 56.25%] [G loss: 0.306227]\n",
      "epoch:25 step:23715 [D loss: 0.231859, acc.: 62.50%] [G loss: 0.294554]\n",
      "epoch:25 step:23716 [D loss: 0.245294, acc.: 53.12%] [G loss: 0.300152]\n",
      "epoch:25 step:23717 [D loss: 0.228729, acc.: 60.16%] [G loss: 0.304006]\n",
      "epoch:25 step:23718 [D loss: 0.246336, acc.: 55.47%] [G loss: 0.319821]\n",
      "epoch:25 step:23719 [D loss: 0.228449, acc.: 59.38%] [G loss: 0.287497]\n",
      "epoch:25 step:23720 [D loss: 0.246789, acc.: 56.25%] [G loss: 0.342634]\n",
      "epoch:25 step:23721 [D loss: 0.225162, acc.: 61.72%] [G loss: 0.317836]\n",
      "epoch:25 step:23722 [D loss: 0.238385, acc.: 61.72%] [G loss: 0.305922]\n",
      "epoch:25 step:23723 [D loss: 0.242927, acc.: 57.03%] [G loss: 0.306763]\n",
      "epoch:25 step:23724 [D loss: 0.248480, acc.: 57.03%] [G loss: 0.306864]\n",
      "epoch:25 step:23725 [D loss: 0.254817, acc.: 53.12%] [G loss: 0.312032]\n",
      "epoch:25 step:23726 [D loss: 0.249749, acc.: 56.25%] [G loss: 0.294732]\n",
      "epoch:25 step:23727 [D loss: 0.240455, acc.: 59.38%] [G loss: 0.298135]\n",
      "epoch:25 step:23728 [D loss: 0.257275, acc.: 51.56%] [G loss: 0.280444]\n",
      "epoch:25 step:23729 [D loss: 0.238652, acc.: 55.47%] [G loss: 0.313179]\n",
      "epoch:25 step:23730 [D loss: 0.261517, acc.: 49.22%] [G loss: 0.279906]\n",
      "epoch:25 step:23731 [D loss: 0.236667, acc.: 62.50%] [G loss: 0.289538]\n",
      "epoch:25 step:23732 [D loss: 0.248517, acc.: 57.81%] [G loss: 0.311074]\n",
      "epoch:25 step:23733 [D loss: 0.236456, acc.: 57.81%] [G loss: 0.291713]\n",
      "epoch:25 step:23734 [D loss: 0.230000, acc.: 62.50%] [G loss: 0.315048]\n",
      "epoch:25 step:23735 [D loss: 0.240877, acc.: 58.59%] [G loss: 0.296622]\n",
      "epoch:25 step:23736 [D loss: 0.240277, acc.: 60.16%] [G loss: 0.303142]\n",
      "epoch:25 step:23737 [D loss: 0.253648, acc.: 50.00%] [G loss: 0.316705]\n",
      "epoch:25 step:23738 [D loss: 0.250980, acc.: 56.25%] [G loss: 0.283369]\n",
      "epoch:25 step:23739 [D loss: 0.231496, acc.: 60.16%] [G loss: 0.300388]\n",
      "epoch:25 step:23740 [D loss: 0.252422, acc.: 53.91%] [G loss: 0.321822]\n",
      "epoch:25 step:23741 [D loss: 0.231577, acc.: 57.03%] [G loss: 0.283353]\n",
      "epoch:25 step:23742 [D loss: 0.235917, acc.: 60.16%] [G loss: 0.310149]\n",
      "epoch:25 step:23743 [D loss: 0.246725, acc.: 53.12%] [G loss: 0.287540]\n",
      "epoch:25 step:23744 [D loss: 0.252263, acc.: 52.34%] [G loss: 0.326806]\n",
      "epoch:25 step:23745 [D loss: 0.237440, acc.: 60.16%] [G loss: 0.313916]\n",
      "epoch:25 step:23746 [D loss: 0.232678, acc.: 59.38%] [G loss: 0.317940]\n",
      "epoch:25 step:23747 [D loss: 0.254060, acc.: 48.44%] [G loss: 0.306706]\n",
      "epoch:25 step:23748 [D loss: 0.236017, acc.: 62.50%] [G loss: 0.316637]\n",
      "epoch:25 step:23749 [D loss: 0.235531, acc.: 57.81%] [G loss: 0.306276]\n",
      "epoch:25 step:23750 [D loss: 0.222649, acc.: 64.06%] [G loss: 0.334577]\n",
      "epoch:25 step:23751 [D loss: 0.232365, acc.: 62.50%] [G loss: 0.296282]\n",
      "epoch:25 step:23752 [D loss: 0.233967, acc.: 57.81%] [G loss: 0.292821]\n",
      "epoch:25 step:23753 [D loss: 0.224090, acc.: 64.06%] [G loss: 0.302566]\n",
      "epoch:25 step:23754 [D loss: 0.238143, acc.: 57.81%] [G loss: 0.316464]\n",
      "epoch:25 step:23755 [D loss: 0.249291, acc.: 53.12%] [G loss: 0.303904]\n",
      "epoch:25 step:23756 [D loss: 0.243575, acc.: 57.81%] [G loss: 0.281584]\n",
      "epoch:25 step:23757 [D loss: 0.246377, acc.: 60.94%] [G loss: 0.276415]\n",
      "epoch:25 step:23758 [D loss: 0.235311, acc.: 55.47%] [G loss: 0.313808]\n",
      "epoch:25 step:23759 [D loss: 0.212744, acc.: 67.19%] [G loss: 0.299533]\n",
      "epoch:25 step:23760 [D loss: 0.233678, acc.: 62.50%] [G loss: 0.281330]\n",
      "epoch:25 step:23761 [D loss: 0.233275, acc.: 56.25%] [G loss: 0.270355]\n",
      "epoch:25 step:23762 [D loss: 0.246279, acc.: 57.03%] [G loss: 0.291970]\n",
      "epoch:25 step:23763 [D loss: 0.240810, acc.: 61.72%] [G loss: 0.304612]\n",
      "epoch:25 step:23764 [D loss: 0.239844, acc.: 58.59%] [G loss: 0.311787]\n",
      "epoch:25 step:23765 [D loss: 0.243574, acc.: 58.59%] [G loss: 0.333005]\n",
      "epoch:25 step:23766 [D loss: 0.255416, acc.: 52.34%] [G loss: 0.283278]\n",
      "epoch:25 step:23767 [D loss: 0.240751, acc.: 63.28%] [G loss: 0.302218]\n",
      "epoch:25 step:23768 [D loss: 0.234007, acc.: 60.16%] [G loss: 0.310391]\n",
      "epoch:25 step:23769 [D loss: 0.230596, acc.: 64.06%] [G loss: 0.316229]\n",
      "epoch:25 step:23770 [D loss: 0.229110, acc.: 62.50%] [G loss: 0.286373]\n",
      "epoch:25 step:23771 [D loss: 0.253298, acc.: 56.25%] [G loss: 0.265113]\n",
      "epoch:25 step:23772 [D loss: 0.244012, acc.: 55.47%] [G loss: 0.306721]\n",
      "epoch:25 step:23773 [D loss: 0.228777, acc.: 62.50%] [G loss: 0.328955]\n",
      "epoch:25 step:23774 [D loss: 0.249396, acc.: 54.69%] [G loss: 0.331275]\n",
      "epoch:25 step:23775 [D loss: 0.241987, acc.: 53.91%] [G loss: 0.308805]\n",
      "epoch:25 step:23776 [D loss: 0.230398, acc.: 64.84%] [G loss: 0.307301]\n",
      "epoch:25 step:23777 [D loss: 0.231578, acc.: 62.50%] [G loss: 0.336939]\n",
      "epoch:25 step:23778 [D loss: 0.225193, acc.: 63.28%] [G loss: 0.286229]\n",
      "epoch:25 step:23779 [D loss: 0.252029, acc.: 53.12%] [G loss: 0.322802]\n",
      "epoch:25 step:23780 [D loss: 0.229767, acc.: 64.06%] [G loss: 0.289455]\n",
      "epoch:25 step:23781 [D loss: 0.226249, acc.: 63.28%] [G loss: 0.321774]\n",
      "epoch:25 step:23782 [D loss: 0.236854, acc.: 59.38%] [G loss: 0.271832]\n",
      "epoch:25 step:23783 [D loss: 0.252420, acc.: 54.69%] [G loss: 0.314247]\n",
      "epoch:25 step:23784 [D loss: 0.236358, acc.: 61.72%] [G loss: 0.308122]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:25 step:23785 [D loss: 0.229376, acc.: 64.06%] [G loss: 0.312302]\n",
      "epoch:25 step:23786 [D loss: 0.229429, acc.: 59.38%] [G loss: 0.331464]\n",
      "epoch:25 step:23787 [D loss: 0.235139, acc.: 63.28%] [G loss: 0.320088]\n",
      "epoch:25 step:23788 [D loss: 0.226007, acc.: 58.59%] [G loss: 0.326235]\n",
      "epoch:25 step:23789 [D loss: 0.236725, acc.: 61.72%] [G loss: 0.285988]\n",
      "epoch:25 step:23790 [D loss: 0.233927, acc.: 63.28%] [G loss: 0.315317]\n",
      "epoch:25 step:23791 [D loss: 0.233743, acc.: 60.16%] [G loss: 0.307057]\n",
      "epoch:25 step:23792 [D loss: 0.239182, acc.: 58.59%] [G loss: 0.286698]\n",
      "epoch:25 step:23793 [D loss: 0.254479, acc.: 53.91%] [G loss: 0.327530]\n",
      "epoch:25 step:23794 [D loss: 0.238140, acc.: 57.03%] [G loss: 0.289962]\n",
      "epoch:25 step:23795 [D loss: 0.224867, acc.: 62.50%] [G loss: 0.296431]\n",
      "epoch:25 step:23796 [D loss: 0.238716, acc.: 58.59%] [G loss: 0.304659]\n",
      "epoch:25 step:23797 [D loss: 0.229027, acc.: 58.59%] [G loss: 0.334235]\n",
      "epoch:25 step:23798 [D loss: 0.260296, acc.: 53.12%] [G loss: 0.276838]\n",
      "epoch:25 step:23799 [D loss: 0.252806, acc.: 53.12%] [G loss: 0.305042]\n",
      "epoch:25 step:23800 [D loss: 0.229041, acc.: 62.50%] [G loss: 0.319223]\n",
      "epoch:25 step:23801 [D loss: 0.243929, acc.: 58.59%] [G loss: 0.294478]\n",
      "epoch:25 step:23802 [D loss: 0.243086, acc.: 58.59%] [G loss: 0.294046]\n",
      "epoch:25 step:23803 [D loss: 0.208847, acc.: 69.53%] [G loss: 0.320591]\n",
      "epoch:25 step:23804 [D loss: 0.219709, acc.: 64.84%] [G loss: 0.305837]\n",
      "epoch:25 step:23805 [D loss: 0.241351, acc.: 58.59%] [G loss: 0.301611]\n",
      "epoch:25 step:23806 [D loss: 0.221937, acc.: 65.62%] [G loss: 0.322713]\n",
      "epoch:25 step:23807 [D loss: 0.240705, acc.: 57.81%] [G loss: 0.317361]\n",
      "epoch:25 step:23808 [D loss: 0.230947, acc.: 65.62%] [G loss: 0.286022]\n",
      "epoch:25 step:23809 [D loss: 0.246701, acc.: 59.38%] [G loss: 0.295129]\n",
      "epoch:25 step:23810 [D loss: 0.229214, acc.: 61.72%] [G loss: 0.306480]\n",
      "epoch:25 step:23811 [D loss: 0.227332, acc.: 62.50%] [G loss: 0.271815]\n",
      "epoch:25 step:23812 [D loss: 0.227653, acc.: 60.16%] [G loss: 0.285744]\n",
      "epoch:25 step:23813 [D loss: 0.258814, acc.: 50.78%] [G loss: 0.292237]\n",
      "epoch:25 step:23814 [D loss: 0.225977, acc.: 68.75%] [G loss: 0.299864]\n",
      "epoch:25 step:23815 [D loss: 0.239093, acc.: 57.03%] [G loss: 0.305990]\n",
      "epoch:25 step:23816 [D loss: 0.227498, acc.: 62.50%] [G loss: 0.322429]\n",
      "epoch:25 step:23817 [D loss: 0.256599, acc.: 53.91%] [G loss: 0.306406]\n",
      "epoch:25 step:23818 [D loss: 0.240022, acc.: 56.25%] [G loss: 0.298368]\n",
      "epoch:25 step:23819 [D loss: 0.239099, acc.: 60.94%] [G loss: 0.329873]\n",
      "epoch:25 step:23820 [D loss: 0.234619, acc.: 60.16%] [G loss: 0.293506]\n",
      "epoch:25 step:23821 [D loss: 0.230275, acc.: 67.97%] [G loss: 0.311740]\n",
      "epoch:25 step:23822 [D loss: 0.239012, acc.: 59.38%] [G loss: 0.331873]\n",
      "epoch:25 step:23823 [D loss: 0.244933, acc.: 55.47%] [G loss: 0.299902]\n",
      "epoch:25 step:23824 [D loss: 0.227383, acc.: 63.28%] [G loss: 0.310931]\n",
      "epoch:25 step:23825 [D loss: 0.229827, acc.: 62.50%] [G loss: 0.303969]\n",
      "epoch:25 step:23826 [D loss: 0.245837, acc.: 54.69%] [G loss: 0.296218]\n",
      "epoch:25 step:23827 [D loss: 0.234650, acc.: 58.59%] [G loss: 0.311554]\n",
      "epoch:25 step:23828 [D loss: 0.236016, acc.: 58.59%] [G loss: 0.309721]\n",
      "epoch:25 step:23829 [D loss: 0.241019, acc.: 58.59%] [G loss: 0.310085]\n",
      "epoch:25 step:23830 [D loss: 0.228569, acc.: 62.50%] [G loss: 0.307131]\n",
      "epoch:25 step:23831 [D loss: 0.234908, acc.: 62.50%] [G loss: 0.320181]\n",
      "epoch:25 step:23832 [D loss: 0.237189, acc.: 59.38%] [G loss: 0.306454]\n",
      "epoch:25 step:23833 [D loss: 0.233019, acc.: 60.94%] [G loss: 0.288086]\n",
      "epoch:25 step:23834 [D loss: 0.252008, acc.: 53.12%] [G loss: 0.303963]\n",
      "epoch:25 step:23835 [D loss: 0.258503, acc.: 51.56%] [G loss: 0.338118]\n",
      "epoch:25 step:23836 [D loss: 0.260938, acc.: 55.47%] [G loss: 0.289899]\n",
      "epoch:25 step:23837 [D loss: 0.264574, acc.: 45.31%] [G loss: 0.295805]\n",
      "epoch:25 step:23838 [D loss: 0.241988, acc.: 59.38%] [G loss: 0.306701]\n",
      "epoch:25 step:23839 [D loss: 0.243506, acc.: 57.03%] [G loss: 0.298118]\n",
      "epoch:25 step:23840 [D loss: 0.243062, acc.: 56.25%] [G loss: 0.312229]\n",
      "epoch:25 step:23841 [D loss: 0.249333, acc.: 55.47%] [G loss: 0.288444]\n",
      "epoch:25 step:23842 [D loss: 0.227276, acc.: 61.72%] [G loss: 0.313008]\n",
      "epoch:25 step:23843 [D loss: 0.258300, acc.: 57.03%] [G loss: 0.298787]\n",
      "epoch:25 step:23844 [D loss: 0.218871, acc.: 65.62%] [G loss: 0.325941]\n",
      "epoch:25 step:23845 [D loss: 0.237263, acc.: 59.38%] [G loss: 0.305304]\n",
      "epoch:25 step:23846 [D loss: 0.243478, acc.: 57.81%] [G loss: 0.304604]\n",
      "epoch:25 step:23847 [D loss: 0.232016, acc.: 58.59%] [G loss: 0.324346]\n",
      "epoch:25 step:23848 [D loss: 0.233159, acc.: 58.59%] [G loss: 0.288436]\n",
      "epoch:25 step:23849 [D loss: 0.245054, acc.: 54.69%] [G loss: 0.317939]\n",
      "epoch:25 step:23850 [D loss: 0.252890, acc.: 54.69%] [G loss: 0.278523]\n",
      "epoch:25 step:23851 [D loss: 0.241448, acc.: 60.94%] [G loss: 0.317654]\n",
      "epoch:25 step:23852 [D loss: 0.264502, acc.: 50.78%] [G loss: 0.292097]\n",
      "epoch:25 step:23853 [D loss: 0.248709, acc.: 50.78%] [G loss: 0.287544]\n",
      "epoch:25 step:23854 [D loss: 0.249907, acc.: 51.56%] [G loss: 0.271659]\n",
      "epoch:25 step:23855 [D loss: 0.246979, acc.: 60.16%] [G loss: 0.317232]\n",
      "epoch:25 step:23856 [D loss: 0.230893, acc.: 60.94%] [G loss: 0.287783]\n",
      "epoch:25 step:23857 [D loss: 0.226466, acc.: 63.28%] [G loss: 0.303567]\n",
      "epoch:25 step:23858 [D loss: 0.244000, acc.: 53.91%] [G loss: 0.322211]\n",
      "epoch:25 step:23859 [D loss: 0.238052, acc.: 58.59%] [G loss: 0.331597]\n",
      "epoch:25 step:23860 [D loss: 0.235309, acc.: 57.81%] [G loss: 0.324998]\n",
      "epoch:25 step:23861 [D loss: 0.219936, acc.: 67.19%] [G loss: 0.327378]\n",
      "epoch:25 step:23862 [D loss: 0.242754, acc.: 56.25%] [G loss: 0.323992]\n",
      "epoch:25 step:23863 [D loss: 0.242347, acc.: 53.91%] [G loss: 0.323369]\n",
      "epoch:25 step:23864 [D loss: 0.250918, acc.: 55.47%] [G loss: 0.287249]\n",
      "epoch:25 step:23865 [D loss: 0.238594, acc.: 55.47%] [G loss: 0.316654]\n",
      "epoch:25 step:23866 [D loss: 0.247543, acc.: 50.78%] [G loss: 0.303823]\n",
      "epoch:25 step:23867 [D loss: 0.228180, acc.: 61.72%] [G loss: 0.315439]\n",
      "epoch:25 step:23868 [D loss: 0.243693, acc.: 55.47%] [G loss: 0.326400]\n",
      "epoch:25 step:23869 [D loss: 0.238330, acc.: 60.94%] [G loss: 0.303474]\n",
      "epoch:25 step:23870 [D loss: 0.220893, acc.: 64.06%] [G loss: 0.307419]\n",
      "epoch:25 step:23871 [D loss: 0.239972, acc.: 60.94%] [G loss: 0.308562]\n",
      "epoch:25 step:23872 [D loss: 0.236015, acc.: 60.94%] [G loss: 0.308250]\n",
      "epoch:25 step:23873 [D loss: 0.237710, acc.: 55.47%] [G loss: 0.305493]\n",
      "epoch:25 step:23874 [D loss: 0.237143, acc.: 60.16%] [G loss: 0.315317]\n",
      "epoch:25 step:23875 [D loss: 0.234982, acc.: 60.16%] [G loss: 0.311225]\n",
      "epoch:25 step:23876 [D loss: 0.254579, acc.: 49.22%] [G loss: 0.302759]\n",
      "epoch:25 step:23877 [D loss: 0.255665, acc.: 48.44%] [G loss: 0.282402]\n",
      "epoch:25 step:23878 [D loss: 0.235268, acc.: 54.69%] [G loss: 0.280619]\n",
      "epoch:25 step:23879 [D loss: 0.211182, acc.: 64.84%] [G loss: 0.336178]\n",
      "epoch:25 step:23880 [D loss: 0.244392, acc.: 59.38%] [G loss: 0.280032]\n",
      "epoch:25 step:23881 [D loss: 0.228584, acc.: 64.06%] [G loss: 0.314596]\n",
      "epoch:25 step:23882 [D loss: 0.261646, acc.: 51.56%] [G loss: 0.286665]\n",
      "epoch:25 step:23883 [D loss: 0.238631, acc.: 63.28%] [G loss: 0.309762]\n",
      "epoch:25 step:23884 [D loss: 0.234102, acc.: 59.38%] [G loss: 0.304509]\n",
      "epoch:25 step:23885 [D loss: 0.231693, acc.: 60.16%] [G loss: 0.287764]\n",
      "epoch:25 step:23886 [D loss: 0.231701, acc.: 60.94%] [G loss: 0.294104]\n",
      "epoch:25 step:23887 [D loss: 0.239741, acc.: 60.94%] [G loss: 0.309031]\n",
      "epoch:25 step:23888 [D loss: 0.234147, acc.: 59.38%] [G loss: 0.293334]\n",
      "epoch:25 step:23889 [D loss: 0.236289, acc.: 57.03%] [G loss: 0.295392]\n",
      "epoch:25 step:23890 [D loss: 0.246427, acc.: 57.81%] [G loss: 0.326312]\n",
      "epoch:25 step:23891 [D loss: 0.234041, acc.: 58.59%] [G loss: 0.285687]\n",
      "epoch:25 step:23892 [D loss: 0.237033, acc.: 58.59%] [G loss: 0.303636]\n",
      "epoch:25 step:23893 [D loss: 0.237531, acc.: 60.16%] [G loss: 0.277911]\n",
      "epoch:25 step:23894 [D loss: 0.256495, acc.: 48.44%] [G loss: 0.286818]\n",
      "epoch:25 step:23895 [D loss: 0.249341, acc.: 57.81%] [G loss: 0.313065]\n",
      "epoch:25 step:23896 [D loss: 0.234496, acc.: 64.06%] [G loss: 0.288885]\n",
      "epoch:25 step:23897 [D loss: 0.244770, acc.: 63.28%] [G loss: 0.309841]\n",
      "epoch:25 step:23898 [D loss: 0.235768, acc.: 60.16%] [G loss: 0.298635]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:25 step:23899 [D loss: 0.233426, acc.: 59.38%] [G loss: 0.296159]\n",
      "epoch:25 step:23900 [D loss: 0.229455, acc.: 62.50%] [G loss: 0.312600]\n",
      "epoch:25 step:23901 [D loss: 0.242613, acc.: 57.03%] [G loss: 0.266371]\n",
      "epoch:25 step:23902 [D loss: 0.239151, acc.: 59.38%] [G loss: 0.305566]\n",
      "epoch:25 step:23903 [D loss: 0.234318, acc.: 57.03%] [G loss: 0.301219]\n",
      "epoch:25 step:23904 [D loss: 0.241398, acc.: 57.81%] [G loss: 0.291534]\n",
      "epoch:25 step:23905 [D loss: 0.250430, acc.: 55.47%] [G loss: 0.334028]\n",
      "epoch:25 step:23906 [D loss: 0.248432, acc.: 53.91%] [G loss: 0.297121]\n",
      "epoch:25 step:23907 [D loss: 0.238311, acc.: 60.16%] [G loss: 0.317683]\n",
      "epoch:25 step:23908 [D loss: 0.252920, acc.: 56.25%] [G loss: 0.315284]\n",
      "epoch:25 step:23909 [D loss: 0.246440, acc.: 57.03%] [G loss: 0.317568]\n",
      "epoch:25 step:23910 [D loss: 0.229040, acc.: 59.38%] [G loss: 0.298668]\n",
      "epoch:25 step:23911 [D loss: 0.226109, acc.: 68.75%] [G loss: 0.323783]\n",
      "epoch:25 step:23912 [D loss: 0.242196, acc.: 52.34%] [G loss: 0.321251]\n",
      "epoch:25 step:23913 [D loss: 0.212983, acc.: 67.19%] [G loss: 0.292796]\n",
      "epoch:25 step:23914 [D loss: 0.227588, acc.: 64.84%] [G loss: 0.292698]\n",
      "epoch:25 step:23915 [D loss: 0.237578, acc.: 66.41%] [G loss: 0.319296]\n",
      "epoch:25 step:23916 [D loss: 0.240168, acc.: 57.03%] [G loss: 0.291386]\n",
      "epoch:25 step:23917 [D loss: 0.238780, acc.: 63.28%] [G loss: 0.287215]\n",
      "epoch:25 step:23918 [D loss: 0.227151, acc.: 65.62%] [G loss: 0.327361]\n",
      "epoch:25 step:23919 [D loss: 0.231138, acc.: 54.69%] [G loss: 0.331221]\n",
      "epoch:25 step:23920 [D loss: 0.234026, acc.: 60.94%] [G loss: 0.305713]\n",
      "epoch:25 step:23921 [D loss: 0.233116, acc.: 57.03%] [G loss: 0.300052]\n",
      "epoch:25 step:23922 [D loss: 0.253232, acc.: 54.69%] [G loss: 0.290480]\n",
      "epoch:25 step:23923 [D loss: 0.252751, acc.: 53.12%] [G loss: 0.323178]\n",
      "epoch:25 step:23924 [D loss: 0.255893, acc.: 52.34%] [G loss: 0.286977]\n",
      "epoch:25 step:23925 [D loss: 0.245081, acc.: 51.56%] [G loss: 0.294399]\n",
      "epoch:25 step:23926 [D loss: 0.240323, acc.: 58.59%] [G loss: 0.324145]\n",
      "epoch:25 step:23927 [D loss: 0.236488, acc.: 57.03%] [G loss: 0.319739]\n",
      "epoch:25 step:23928 [D loss: 0.233338, acc.: 60.94%] [G loss: 0.301765]\n",
      "epoch:25 step:23929 [D loss: 0.224329, acc.: 64.84%] [G loss: 0.327872]\n",
      "epoch:25 step:23930 [D loss: 0.233107, acc.: 60.16%] [G loss: 0.323034]\n",
      "epoch:25 step:23931 [D loss: 0.227409, acc.: 62.50%] [G loss: 0.295713]\n",
      "epoch:25 step:23932 [D loss: 0.249315, acc.: 55.47%] [G loss: 0.287915]\n",
      "epoch:25 step:23933 [D loss: 0.247219, acc.: 58.59%] [G loss: 0.288365]\n",
      "epoch:25 step:23934 [D loss: 0.230981, acc.: 63.28%] [G loss: 0.286207]\n",
      "epoch:25 step:23935 [D loss: 0.225995, acc.: 62.50%] [G loss: 0.323063]\n",
      "epoch:25 step:23936 [D loss: 0.236399, acc.: 57.81%] [G loss: 0.308148]\n",
      "epoch:25 step:23937 [D loss: 0.240707, acc.: 57.81%] [G loss: 0.325059]\n",
      "epoch:25 step:23938 [D loss: 0.252975, acc.: 55.47%] [G loss: 0.303505]\n",
      "epoch:25 step:23939 [D loss: 0.225240, acc.: 64.84%] [G loss: 0.341909]\n",
      "epoch:25 step:23940 [D loss: 0.247113, acc.: 57.03%] [G loss: 0.286847]\n",
      "epoch:25 step:23941 [D loss: 0.232889, acc.: 60.16%] [G loss: 0.289818]\n",
      "epoch:25 step:23942 [D loss: 0.224861, acc.: 59.38%] [G loss: 0.338504]\n",
      "epoch:25 step:23943 [D loss: 0.235032, acc.: 61.72%] [G loss: 0.320507]\n",
      "epoch:25 step:23944 [D loss: 0.241040, acc.: 54.69%] [G loss: 0.302565]\n",
      "epoch:25 step:23945 [D loss: 0.203673, acc.: 68.75%] [G loss: 0.310138]\n",
      "epoch:25 step:23946 [D loss: 0.251208, acc.: 54.69%] [G loss: 0.311931]\n",
      "epoch:25 step:23947 [D loss: 0.251032, acc.: 58.59%] [G loss: 0.332744]\n",
      "epoch:25 step:23948 [D loss: 0.222869, acc.: 66.41%] [G loss: 0.309853]\n",
      "epoch:25 step:23949 [D loss: 0.239199, acc.: 59.38%] [G loss: 0.310596]\n",
      "epoch:25 step:23950 [D loss: 0.239897, acc.: 58.59%] [G loss: 0.320557]\n",
      "epoch:25 step:23951 [D loss: 0.229938, acc.: 63.28%] [G loss: 0.317724]\n",
      "epoch:25 step:23952 [D loss: 0.252599, acc.: 59.38%] [G loss: 0.314057]\n",
      "epoch:25 step:23953 [D loss: 0.235837, acc.: 60.94%] [G loss: 0.303314]\n",
      "epoch:25 step:23954 [D loss: 0.239802, acc.: 55.47%] [G loss: 0.310155]\n",
      "epoch:25 step:23955 [D loss: 0.238035, acc.: 60.94%] [G loss: 0.298857]\n",
      "epoch:25 step:23956 [D loss: 0.235027, acc.: 56.25%] [G loss: 0.287034]\n",
      "epoch:25 step:23957 [D loss: 0.250998, acc.: 52.34%] [G loss: 0.277244]\n",
      "epoch:25 step:23958 [D loss: 0.234427, acc.: 63.28%] [G loss: 0.305283]\n",
      "epoch:25 step:23959 [D loss: 0.232395, acc.: 60.16%] [G loss: 0.310573]\n",
      "epoch:25 step:23960 [D loss: 0.246849, acc.: 52.34%] [G loss: 0.320647]\n",
      "epoch:25 step:23961 [D loss: 0.248023, acc.: 55.47%] [G loss: 0.279722]\n",
      "epoch:25 step:23962 [D loss: 0.254741, acc.: 54.69%] [G loss: 0.313798]\n",
      "epoch:25 step:23963 [D loss: 0.235312, acc.: 60.94%] [G loss: 0.302946]\n",
      "epoch:25 step:23964 [D loss: 0.240338, acc.: 57.03%] [G loss: 0.299049]\n",
      "epoch:25 step:23965 [D loss: 0.237615, acc.: 60.94%] [G loss: 0.318560]\n",
      "epoch:25 step:23966 [D loss: 0.238742, acc.: 60.94%] [G loss: 0.298364]\n",
      "epoch:25 step:23967 [D loss: 0.231115, acc.: 53.91%] [G loss: 0.332260]\n",
      "epoch:25 step:23968 [D loss: 0.245968, acc.: 60.94%] [G loss: 0.287216]\n",
      "epoch:25 step:23969 [D loss: 0.248015, acc.: 57.81%] [G loss: 0.311556]\n",
      "epoch:25 step:23970 [D loss: 0.249924, acc.: 52.34%] [G loss: 0.311616]\n",
      "epoch:25 step:23971 [D loss: 0.245890, acc.: 57.81%] [G loss: 0.315309]\n",
      "epoch:25 step:23972 [D loss: 0.249260, acc.: 52.34%] [G loss: 0.310013]\n",
      "epoch:25 step:23973 [D loss: 0.245548, acc.: 57.03%] [G loss: 0.337036]\n",
      "epoch:25 step:23974 [D loss: 0.222929, acc.: 65.62%] [G loss: 0.295637]\n",
      "epoch:25 step:23975 [D loss: 0.229841, acc.: 62.50%] [G loss: 0.315306]\n",
      "epoch:25 step:23976 [D loss: 0.252491, acc.: 54.69%] [G loss: 0.325137]\n",
      "epoch:25 step:23977 [D loss: 0.246433, acc.: 57.03%] [G loss: 0.302611]\n",
      "epoch:25 step:23978 [D loss: 0.229741, acc.: 60.94%] [G loss: 0.293679]\n",
      "epoch:25 step:23979 [D loss: 0.240801, acc.: 58.59%] [G loss: 0.312920]\n",
      "epoch:25 step:23980 [D loss: 0.224730, acc.: 63.28%] [G loss: 0.317412]\n",
      "epoch:25 step:23981 [D loss: 0.240651, acc.: 57.03%] [G loss: 0.307541]\n",
      "epoch:25 step:23982 [D loss: 0.232444, acc.: 57.03%] [G loss: 0.332620]\n",
      "epoch:25 step:23983 [D loss: 0.233908, acc.: 56.25%] [G loss: 0.317684]\n",
      "epoch:25 step:23984 [D loss: 0.239505, acc.: 56.25%] [G loss: 0.319198]\n",
      "epoch:25 step:23985 [D loss: 0.225141, acc.: 63.28%] [G loss: 0.338961]\n",
      "epoch:25 step:23986 [D loss: 0.259427, acc.: 50.78%] [G loss: 0.280437]\n",
      "epoch:25 step:23987 [D loss: 0.227725, acc.: 63.28%] [G loss: 0.319700]\n",
      "epoch:25 step:23988 [D loss: 0.232837, acc.: 65.62%] [G loss: 0.286644]\n",
      "epoch:25 step:23989 [D loss: 0.235786, acc.: 59.38%] [G loss: 0.303209]\n",
      "epoch:25 step:23990 [D loss: 0.239484, acc.: 56.25%] [G loss: 0.305178]\n",
      "epoch:25 step:23991 [D loss: 0.239851, acc.: 56.25%] [G loss: 0.296219]\n",
      "epoch:25 step:23992 [D loss: 0.233776, acc.: 57.03%] [G loss: 0.267359]\n",
      "epoch:25 step:23993 [D loss: 0.235350, acc.: 63.28%] [G loss: 0.337088]\n",
      "epoch:25 step:23994 [D loss: 0.216890, acc.: 64.84%] [G loss: 0.293979]\n",
      "epoch:25 step:23995 [D loss: 0.227617, acc.: 65.62%] [G loss: 0.342338]\n",
      "epoch:25 step:23996 [D loss: 0.239601, acc.: 60.94%] [G loss: 0.295639]\n",
      "epoch:25 step:23997 [D loss: 0.225024, acc.: 67.97%] [G loss: 0.299188]\n",
      "epoch:25 step:23998 [D loss: 0.238214, acc.: 60.16%] [G loss: 0.307117]\n",
      "epoch:25 step:23999 [D loss: 0.229648, acc.: 62.50%] [G loss: 0.317193]\n",
      "epoch:25 step:24000 [D loss: 0.242069, acc.: 62.50%] [G loss: 0.300549]\n",
      "epoch:25 step:24001 [D loss: 0.220235, acc.: 64.84%] [G loss: 0.322904]\n",
      "epoch:25 step:24002 [D loss: 0.224221, acc.: 62.50%] [G loss: 0.310906]\n",
      "epoch:25 step:24003 [D loss: 0.239630, acc.: 63.28%] [G loss: 0.300747]\n",
      "epoch:25 step:24004 [D loss: 0.222034, acc.: 68.75%] [G loss: 0.282956]\n",
      "epoch:25 step:24005 [D loss: 0.234618, acc.: 59.38%] [G loss: 0.315935]\n",
      "epoch:25 step:24006 [D loss: 0.251917, acc.: 55.47%] [G loss: 0.316208]\n",
      "epoch:25 step:24007 [D loss: 0.229513, acc.: 61.72%] [G loss: 0.301484]\n",
      "epoch:25 step:24008 [D loss: 0.216952, acc.: 70.31%] [G loss: 0.331421]\n",
      "epoch:25 step:24009 [D loss: 0.246053, acc.: 54.69%] [G loss: 0.308390]\n",
      "epoch:25 step:24010 [D loss: 0.240106, acc.: 53.12%] [G loss: 0.299470]\n",
      "epoch:25 step:24011 [D loss: 0.241309, acc.: 53.12%] [G loss: 0.295392]\n",
      "epoch:25 step:24012 [D loss: 0.256859, acc.: 49.22%] [G loss: 0.283015]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:25 step:24013 [D loss: 0.241368, acc.: 59.38%] [G loss: 0.273000]\n",
      "epoch:25 step:24014 [D loss: 0.264808, acc.: 53.91%] [G loss: 0.278105]\n",
      "epoch:25 step:24015 [D loss: 0.236312, acc.: 59.38%] [G loss: 0.325845]\n",
      "epoch:25 step:24016 [D loss: 0.235449, acc.: 57.81%] [G loss: 0.309979]\n",
      "epoch:25 step:24017 [D loss: 0.216073, acc.: 60.94%] [G loss: 0.308029]\n",
      "epoch:25 step:24018 [D loss: 0.244309, acc.: 52.34%] [G loss: 0.303405]\n",
      "epoch:25 step:24019 [D loss: 0.226837, acc.: 66.41%] [G loss: 0.309808]\n",
      "epoch:25 step:24020 [D loss: 0.244828, acc.: 56.25%] [G loss: 0.290453]\n",
      "epoch:25 step:24021 [D loss: 0.251874, acc.: 49.22%] [G loss: 0.314512]\n",
      "epoch:25 step:24022 [D loss: 0.240375, acc.: 60.16%] [G loss: 0.309781]\n",
      "epoch:25 step:24023 [D loss: 0.225608, acc.: 64.06%] [G loss: 0.286480]\n",
      "epoch:25 step:24024 [D loss: 0.242861, acc.: 57.81%] [G loss: 0.278461]\n",
      "epoch:25 step:24025 [D loss: 0.227512, acc.: 64.84%] [G loss: 0.328793]\n",
      "epoch:25 step:24026 [D loss: 0.246727, acc.: 54.69%] [G loss: 0.317604]\n",
      "epoch:25 step:24027 [D loss: 0.233639, acc.: 57.81%] [G loss: 0.315829]\n",
      "epoch:25 step:24028 [D loss: 0.243358, acc.: 60.16%] [G loss: 0.318174]\n",
      "epoch:25 step:24029 [D loss: 0.247744, acc.: 58.59%] [G loss: 0.313796]\n",
      "epoch:25 step:24030 [D loss: 0.233473, acc.: 56.25%] [G loss: 0.327926]\n",
      "epoch:25 step:24031 [D loss: 0.232159, acc.: 59.38%] [G loss: 0.329233]\n",
      "epoch:25 step:24032 [D loss: 0.253003, acc.: 51.56%] [G loss: 0.310719]\n",
      "epoch:25 step:24033 [D loss: 0.230220, acc.: 59.38%] [G loss: 0.305254]\n",
      "epoch:25 step:24034 [D loss: 0.211702, acc.: 66.41%] [G loss: 0.286926]\n",
      "epoch:25 step:24035 [D loss: 0.230944, acc.: 59.38%] [G loss: 0.320881]\n",
      "epoch:25 step:24036 [D loss: 0.241943, acc.: 63.28%] [G loss: 0.327953]\n",
      "epoch:25 step:24037 [D loss: 0.238136, acc.: 63.28%] [G loss: 0.267767]\n",
      "epoch:25 step:24038 [D loss: 0.241159, acc.: 56.25%] [G loss: 0.305187]\n",
      "epoch:25 step:24039 [D loss: 0.252369, acc.: 54.69%] [G loss: 0.291658]\n",
      "epoch:25 step:24040 [D loss: 0.219968, acc.: 60.94%] [G loss: 0.327597]\n",
      "epoch:25 step:24041 [D loss: 0.230050, acc.: 61.72%] [G loss: 0.335641]\n",
      "epoch:25 step:24042 [D loss: 0.243492, acc.: 61.72%] [G loss: 0.273834]\n",
      "epoch:25 step:24043 [D loss: 0.246732, acc.: 54.69%] [G loss: 0.328467]\n",
      "epoch:25 step:24044 [D loss: 0.250523, acc.: 54.69%] [G loss: 0.344246]\n",
      "epoch:25 step:24045 [D loss: 0.254520, acc.: 51.56%] [G loss: 0.321868]\n",
      "epoch:25 step:24046 [D loss: 0.243022, acc.: 59.38%] [G loss: 0.291334]\n",
      "epoch:25 step:24047 [D loss: 0.247141, acc.: 55.47%] [G loss: 0.309699]\n",
      "epoch:25 step:24048 [D loss: 0.229192, acc.: 64.06%] [G loss: 0.303608]\n",
      "epoch:25 step:24049 [D loss: 0.254339, acc.: 50.78%] [G loss: 0.294111]\n",
      "epoch:25 step:24050 [D loss: 0.236966, acc.: 59.38%] [G loss: 0.311234]\n",
      "epoch:25 step:24051 [D loss: 0.229319, acc.: 59.38%] [G loss: 0.294902]\n",
      "epoch:25 step:24052 [D loss: 0.217087, acc.: 70.31%] [G loss: 0.311000]\n",
      "epoch:25 step:24053 [D loss: 0.239471, acc.: 62.50%] [G loss: 0.291419]\n",
      "epoch:25 step:24054 [D loss: 0.234125, acc.: 59.38%] [G loss: 0.300895]\n",
      "epoch:25 step:24055 [D loss: 0.247460, acc.: 53.91%] [G loss: 0.290337]\n",
      "epoch:25 step:24056 [D loss: 0.222491, acc.: 64.06%] [G loss: 0.277610]\n",
      "epoch:25 step:24057 [D loss: 0.232443, acc.: 60.16%] [G loss: 0.311031]\n",
      "epoch:25 step:24058 [D loss: 0.236690, acc.: 57.81%] [G loss: 0.282547]\n",
      "epoch:25 step:24059 [D loss: 0.228146, acc.: 62.50%] [G loss: 0.320475]\n",
      "epoch:25 step:24060 [D loss: 0.232832, acc.: 64.84%] [G loss: 0.294220]\n",
      "epoch:25 step:24061 [D loss: 0.230458, acc.: 56.25%] [G loss: 0.307288]\n",
      "epoch:25 step:24062 [D loss: 0.240291, acc.: 56.25%] [G loss: 0.279897]\n",
      "epoch:25 step:24063 [D loss: 0.231136, acc.: 56.25%] [G loss: 0.315687]\n",
      "epoch:25 step:24064 [D loss: 0.242668, acc.: 52.34%] [G loss: 0.311044]\n",
      "epoch:25 step:24065 [D loss: 0.249857, acc.: 55.47%] [G loss: 0.322233]\n",
      "epoch:25 step:24066 [D loss: 0.247592, acc.: 53.91%] [G loss: 0.320421]\n",
      "epoch:25 step:24067 [D loss: 0.236077, acc.: 59.38%] [G loss: 0.324042]\n",
      "epoch:25 step:24068 [D loss: 0.254861, acc.: 51.56%] [G loss: 0.317259]\n",
      "epoch:25 step:24069 [D loss: 0.235375, acc.: 59.38%] [G loss: 0.311696]\n",
      "epoch:25 step:24070 [D loss: 0.226978, acc.: 62.50%] [G loss: 0.291265]\n",
      "epoch:25 step:24071 [D loss: 0.253657, acc.: 53.91%] [G loss: 0.324162]\n",
      "epoch:25 step:24072 [D loss: 0.238788, acc.: 58.59%] [G loss: 0.315067]\n",
      "epoch:25 step:24073 [D loss: 0.224168, acc.: 64.06%] [G loss: 0.303460]\n",
      "epoch:25 step:24074 [D loss: 0.222973, acc.: 62.50%] [G loss: 0.306018]\n",
      "epoch:25 step:24075 [D loss: 0.224360, acc.: 62.50%] [G loss: 0.322931]\n",
      "epoch:25 step:24076 [D loss: 0.236147, acc.: 61.72%] [G loss: 0.347629]\n",
      "epoch:25 step:24077 [D loss: 0.246739, acc.: 57.03%] [G loss: 0.273321]\n",
      "epoch:25 step:24078 [D loss: 0.241473, acc.: 53.12%] [G loss: 0.261740]\n",
      "epoch:25 step:24079 [D loss: 0.224778, acc.: 65.62%] [G loss: 0.287782]\n",
      "epoch:25 step:24080 [D loss: 0.244385, acc.: 60.16%] [G loss: 0.317233]\n",
      "epoch:25 step:24081 [D loss: 0.245606, acc.: 58.59%] [G loss: 0.310078]\n",
      "epoch:25 step:24082 [D loss: 0.260381, acc.: 51.56%] [G loss: 0.339016]\n",
      "epoch:25 step:24083 [D loss: 0.245535, acc.: 57.81%] [G loss: 0.348817]\n",
      "epoch:25 step:24084 [D loss: 0.257745, acc.: 52.34%] [G loss: 0.298151]\n",
      "epoch:25 step:24085 [D loss: 0.255257, acc.: 54.69%] [G loss: 0.292401]\n",
      "epoch:25 step:24086 [D loss: 0.238654, acc.: 60.94%] [G loss: 0.313076]\n",
      "epoch:25 step:24087 [D loss: 0.225392, acc.: 64.06%] [G loss: 0.331988]\n",
      "epoch:25 step:24088 [D loss: 0.255911, acc.: 52.34%] [G loss: 0.331085]\n",
      "epoch:25 step:24089 [D loss: 0.240629, acc.: 62.50%] [G loss: 0.322420]\n",
      "epoch:25 step:24090 [D loss: 0.254326, acc.: 49.22%] [G loss: 0.309449]\n",
      "epoch:25 step:24091 [D loss: 0.224823, acc.: 67.19%] [G loss: 0.285607]\n",
      "epoch:25 step:24092 [D loss: 0.233386, acc.: 59.38%] [G loss: 0.290801]\n",
      "epoch:25 step:24093 [D loss: 0.255647, acc.: 51.56%] [G loss: 0.305021]\n",
      "epoch:25 step:24094 [D loss: 0.240244, acc.: 56.25%] [G loss: 0.313270]\n",
      "epoch:25 step:24095 [D loss: 0.228942, acc.: 62.50%] [G loss: 0.309280]\n",
      "epoch:25 step:24096 [D loss: 0.246758, acc.: 59.38%] [G loss: 0.329450]\n",
      "epoch:25 step:24097 [D loss: 0.243688, acc.: 47.66%] [G loss: 0.318165]\n",
      "epoch:25 step:24098 [D loss: 0.233037, acc.: 59.38%] [G loss: 0.316396]\n",
      "epoch:25 step:24099 [D loss: 0.235891, acc.: 63.28%] [G loss: 0.323624]\n",
      "epoch:25 step:24100 [D loss: 0.243277, acc.: 64.84%] [G loss: 0.320285]\n",
      "epoch:25 step:24101 [D loss: 0.253413, acc.: 47.66%] [G loss: 0.285670]\n",
      "epoch:25 step:24102 [D loss: 0.243286, acc.: 57.81%] [G loss: 0.328276]\n",
      "epoch:25 step:24103 [D loss: 0.245665, acc.: 59.38%] [G loss: 0.282259]\n",
      "epoch:25 step:24104 [D loss: 0.236335, acc.: 60.16%] [G loss: 0.299046]\n",
      "epoch:25 step:24105 [D loss: 0.234073, acc.: 57.81%] [G loss: 0.297978]\n",
      "epoch:25 step:24106 [D loss: 0.232058, acc.: 62.50%] [G loss: 0.297037]\n",
      "epoch:25 step:24107 [D loss: 0.220364, acc.: 66.41%] [G loss: 0.303131]\n",
      "epoch:25 step:24108 [D loss: 0.243322, acc.: 55.47%] [G loss: 0.308559]\n",
      "epoch:25 step:24109 [D loss: 0.245798, acc.: 56.25%] [G loss: 0.324157]\n",
      "epoch:25 step:24110 [D loss: 0.247952, acc.: 55.47%] [G loss: 0.305199]\n",
      "epoch:25 step:24111 [D loss: 0.239612, acc.: 54.69%] [G loss: 0.291456]\n",
      "epoch:25 step:24112 [D loss: 0.237795, acc.: 55.47%] [G loss: 0.313577]\n",
      "epoch:25 step:24113 [D loss: 0.243913, acc.: 57.03%] [G loss: 0.301664]\n",
      "epoch:25 step:24114 [D loss: 0.236297, acc.: 56.25%] [G loss: 0.296006]\n",
      "epoch:25 step:24115 [D loss: 0.244497, acc.: 54.69%] [G loss: 0.299742]\n",
      "epoch:25 step:24116 [D loss: 0.250088, acc.: 50.78%] [G loss: 0.310221]\n",
      "epoch:25 step:24117 [D loss: 0.248286, acc.: 50.78%] [G loss: 0.295218]\n",
      "epoch:25 step:24118 [D loss: 0.243201, acc.: 53.91%] [G loss: 0.291578]\n",
      "epoch:25 step:24119 [D loss: 0.236622, acc.: 60.16%] [G loss: 0.285849]\n",
      "epoch:25 step:24120 [D loss: 0.221080, acc.: 65.62%] [G loss: 0.293650]\n",
      "epoch:25 step:24121 [D loss: 0.229608, acc.: 65.62%] [G loss: 0.296164]\n",
      "epoch:25 step:24122 [D loss: 0.248441, acc.: 53.91%] [G loss: 0.302295]\n",
      "epoch:25 step:24123 [D loss: 0.229619, acc.: 56.25%] [G loss: 0.300634]\n",
      "epoch:25 step:24124 [D loss: 0.252742, acc.: 49.22%] [G loss: 0.292513]\n",
      "epoch:25 step:24125 [D loss: 0.243530, acc.: 57.81%] [G loss: 0.312674]\n",
      "epoch:25 step:24126 [D loss: 0.236218, acc.: 60.94%] [G loss: 0.282677]\n",
      "epoch:25 step:24127 [D loss: 0.219217, acc.: 69.53%] [G loss: 0.296252]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:25 step:24128 [D loss: 0.226529, acc.: 62.50%] [G loss: 0.313338]\n",
      "epoch:25 step:24129 [D loss: 0.250163, acc.: 53.12%] [G loss: 0.284935]\n",
      "epoch:25 step:24130 [D loss: 0.222464, acc.: 61.72%] [G loss: 0.307796]\n",
      "epoch:25 step:24131 [D loss: 0.241355, acc.: 57.03%] [G loss: 0.319612]\n",
      "epoch:25 step:24132 [D loss: 0.242013, acc.: 57.03%] [G loss: 0.295636]\n",
      "epoch:25 step:24133 [D loss: 0.236160, acc.: 62.50%] [G loss: 0.299154]\n",
      "epoch:25 step:24134 [D loss: 0.265139, acc.: 50.78%] [G loss: 0.309802]\n",
      "epoch:25 step:24135 [D loss: 0.222163, acc.: 64.06%] [G loss: 0.306956]\n",
      "epoch:25 step:24136 [D loss: 0.236327, acc.: 62.50%] [G loss: 0.320437]\n",
      "epoch:25 step:24137 [D loss: 0.245974, acc.: 56.25%] [G loss: 0.310957]\n",
      "epoch:25 step:24138 [D loss: 0.237021, acc.: 57.81%] [G loss: 0.297740]\n",
      "epoch:25 step:24139 [D loss: 0.237611, acc.: 56.25%] [G loss: 0.293944]\n",
      "epoch:25 step:24140 [D loss: 0.237573, acc.: 61.72%] [G loss: 0.298185]\n",
      "epoch:25 step:24141 [D loss: 0.243578, acc.: 56.25%] [G loss: 0.301055]\n",
      "epoch:25 step:24142 [D loss: 0.232195, acc.: 60.16%] [G loss: 0.302157]\n",
      "epoch:25 step:24143 [D loss: 0.215142, acc.: 64.84%] [G loss: 0.326615]\n",
      "epoch:25 step:24144 [D loss: 0.236187, acc.: 52.34%] [G loss: 0.306130]\n",
      "epoch:25 step:24145 [D loss: 0.237274, acc.: 60.94%] [G loss: 0.293121]\n",
      "epoch:25 step:24146 [D loss: 0.223812, acc.: 60.94%] [G loss: 0.270645]\n",
      "epoch:25 step:24147 [D loss: 0.225284, acc.: 61.72%] [G loss: 0.310217]\n",
      "epoch:25 step:24148 [D loss: 0.248947, acc.: 57.03%] [G loss: 0.313212]\n",
      "epoch:25 step:24149 [D loss: 0.227687, acc.: 64.06%] [G loss: 0.316205]\n",
      "epoch:25 step:24150 [D loss: 0.239795, acc.: 60.94%] [G loss: 0.265357]\n",
      "epoch:25 step:24151 [D loss: 0.238279, acc.: 57.81%] [G loss: 0.300247]\n",
      "epoch:25 step:24152 [D loss: 0.243117, acc.: 55.47%] [G loss: 0.307434]\n",
      "epoch:25 step:24153 [D loss: 0.250099, acc.: 53.91%] [G loss: 0.277451]\n",
      "epoch:25 step:24154 [D loss: 0.252545, acc.: 50.78%] [G loss: 0.289428]\n",
      "epoch:25 step:24155 [D loss: 0.238624, acc.: 56.25%] [G loss: 0.299962]\n",
      "epoch:25 step:24156 [D loss: 0.244525, acc.: 50.78%] [G loss: 0.292919]\n",
      "epoch:25 step:24157 [D loss: 0.228616, acc.: 57.81%] [G loss: 0.300810]\n",
      "epoch:25 step:24158 [D loss: 0.253108, acc.: 51.56%] [G loss: 0.272708]\n",
      "epoch:25 step:24159 [D loss: 0.248057, acc.: 57.81%] [G loss: 0.272382]\n",
      "epoch:25 step:24160 [D loss: 0.230201, acc.: 61.72%] [G loss: 0.290051]\n",
      "epoch:25 step:24161 [D loss: 0.230423, acc.: 60.16%] [G loss: 0.284157]\n",
      "epoch:25 step:24162 [D loss: 0.230786, acc.: 61.72%] [G loss: 0.332992]\n",
      "epoch:25 step:24163 [D loss: 0.251326, acc.: 50.00%] [G loss: 0.311644]\n",
      "epoch:25 step:24164 [D loss: 0.248618, acc.: 53.12%] [G loss: 0.271401]\n",
      "epoch:25 step:24165 [D loss: 0.236496, acc.: 60.94%] [G loss: 0.305426]\n",
      "epoch:25 step:24166 [D loss: 0.256367, acc.: 50.00%] [G loss: 0.294795]\n",
      "epoch:25 step:24167 [D loss: 0.246800, acc.: 56.25%] [G loss: 0.290529]\n",
      "epoch:25 step:24168 [D loss: 0.228353, acc.: 64.06%] [G loss: 0.314739]\n",
      "epoch:25 step:24169 [D loss: 0.236683, acc.: 57.03%] [G loss: 0.310099]\n",
      "epoch:25 step:24170 [D loss: 0.251876, acc.: 51.56%] [G loss: 0.275033]\n",
      "epoch:25 step:24171 [D loss: 0.219605, acc.: 59.38%] [G loss: 0.285740]\n",
      "epoch:25 step:24172 [D loss: 0.248714, acc.: 57.03%] [G loss: 0.313995]\n",
      "epoch:25 step:24173 [D loss: 0.236265, acc.: 62.50%] [G loss: 0.305624]\n",
      "epoch:25 step:24174 [D loss: 0.252130, acc.: 45.31%] [G loss: 0.354839]\n",
      "epoch:25 step:24175 [D loss: 0.251047, acc.: 57.03%] [G loss: 0.310867]\n",
      "epoch:25 step:24176 [D loss: 0.239351, acc.: 58.59%] [G loss: 0.316363]\n",
      "epoch:25 step:24177 [D loss: 0.235434, acc.: 58.59%] [G loss: 0.340813]\n",
      "epoch:25 step:24178 [D loss: 0.236187, acc.: 58.59%] [G loss: 0.289414]\n",
      "epoch:25 step:24179 [D loss: 0.249329, acc.: 53.12%] [G loss: 0.268051]\n",
      "epoch:25 step:24180 [D loss: 0.245270, acc.: 59.38%] [G loss: 0.292482]\n",
      "epoch:25 step:24181 [D loss: 0.250557, acc.: 52.34%] [G loss: 0.303280]\n",
      "epoch:25 step:24182 [D loss: 0.223325, acc.: 67.97%] [G loss: 0.292614]\n",
      "epoch:25 step:24183 [D loss: 0.244213, acc.: 57.81%] [G loss: 0.279153]\n",
      "epoch:25 step:24184 [D loss: 0.240016, acc.: 53.91%] [G loss: 0.284794]\n",
      "epoch:25 step:24185 [D loss: 0.235740, acc.: 57.81%] [G loss: 0.289344]\n",
      "epoch:25 step:24186 [D loss: 0.251833, acc.: 56.25%] [G loss: 0.329072]\n",
      "epoch:25 step:24187 [D loss: 0.248942, acc.: 49.22%] [G loss: 0.279746]\n",
      "epoch:25 step:24188 [D loss: 0.244061, acc.: 57.81%] [G loss: 0.281678]\n",
      "epoch:25 step:24189 [D loss: 0.235912, acc.: 63.28%] [G loss: 0.346985]\n",
      "epoch:25 step:24190 [D loss: 0.255965, acc.: 48.44%] [G loss: 0.319000]\n",
      "epoch:25 step:24191 [D loss: 0.259134, acc.: 46.09%] [G loss: 0.289408]\n",
      "epoch:25 step:24192 [D loss: 0.237321, acc.: 56.25%] [G loss: 0.318210]\n",
      "epoch:25 step:24193 [D loss: 0.217028, acc.: 62.50%] [G loss: 0.299049]\n",
      "epoch:25 step:24194 [D loss: 0.240913, acc.: 56.25%] [G loss: 0.299702]\n",
      "epoch:25 step:24195 [D loss: 0.245030, acc.: 54.69%] [G loss: 0.273022]\n",
      "epoch:25 step:24196 [D loss: 0.227086, acc.: 62.50%] [G loss: 0.311749]\n",
      "epoch:25 step:24197 [D loss: 0.247422, acc.: 57.03%] [G loss: 0.289040]\n",
      "epoch:25 step:24198 [D loss: 0.249449, acc.: 54.69%] [G loss: 0.326573]\n",
      "epoch:25 step:24199 [D loss: 0.237549, acc.: 55.47%] [G loss: 0.285500]\n",
      "epoch:25 step:24200 [D loss: 0.233987, acc.: 61.72%] [G loss: 0.301478]\n",
      "epoch:25 step:24201 [D loss: 0.242298, acc.: 54.69%] [G loss: 0.297061]\n",
      "epoch:25 step:24202 [D loss: 0.228954, acc.: 62.50%] [G loss: 0.301768]\n",
      "epoch:25 step:24203 [D loss: 0.257392, acc.: 50.78%] [G loss: 0.302676]\n",
      "epoch:25 step:24204 [D loss: 0.245937, acc.: 55.47%] [G loss: 0.313656]\n",
      "epoch:25 step:24205 [D loss: 0.229611, acc.: 65.62%] [G loss: 0.307147]\n",
      "epoch:25 step:24206 [D loss: 0.240701, acc.: 60.94%] [G loss: 0.314443]\n",
      "epoch:25 step:24207 [D loss: 0.248537, acc.: 51.56%] [G loss: 0.295302]\n",
      "epoch:25 step:24208 [D loss: 0.228644, acc.: 59.38%] [G loss: 0.314418]\n",
      "epoch:25 step:24209 [D loss: 0.226921, acc.: 64.06%] [G loss: 0.329537]\n",
      "epoch:25 step:24210 [D loss: 0.240148, acc.: 57.81%] [G loss: 0.273472]\n",
      "epoch:25 step:24211 [D loss: 0.248505, acc.: 55.47%] [G loss: 0.297883]\n",
      "epoch:25 step:24212 [D loss: 0.221040, acc.: 68.75%] [G loss: 0.277867]\n",
      "epoch:25 step:24213 [D loss: 0.220872, acc.: 68.75%] [G loss: 0.294022]\n",
      "epoch:25 step:24214 [D loss: 0.227087, acc.: 64.84%] [G loss: 0.310421]\n",
      "epoch:25 step:24215 [D loss: 0.247331, acc.: 54.69%] [G loss: 0.304879]\n",
      "epoch:25 step:24216 [D loss: 0.227426, acc.: 60.16%] [G loss: 0.320736]\n",
      "epoch:25 step:24217 [D loss: 0.250365, acc.: 53.91%] [G loss: 0.316790]\n",
      "epoch:25 step:24218 [D loss: 0.232837, acc.: 59.38%] [G loss: 0.301418]\n",
      "epoch:25 step:24219 [D loss: 0.240272, acc.: 57.81%] [G loss: 0.335504]\n",
      "epoch:25 step:24220 [D loss: 0.234002, acc.: 62.50%] [G loss: 0.297852]\n",
      "epoch:25 step:24221 [D loss: 0.252730, acc.: 53.12%] [G loss: 0.280113]\n",
      "epoch:25 step:24222 [D loss: 0.255464, acc.: 55.47%] [G loss: 0.308200]\n",
      "epoch:25 step:24223 [D loss: 0.235650, acc.: 61.72%] [G loss: 0.281710]\n",
      "epoch:25 step:24224 [D loss: 0.245205, acc.: 55.47%] [G loss: 0.303888]\n",
      "epoch:25 step:24225 [D loss: 0.220402, acc.: 65.62%] [G loss: 0.327407]\n",
      "epoch:25 step:24226 [D loss: 0.220966, acc.: 68.75%] [G loss: 0.312525]\n",
      "epoch:25 step:24227 [D loss: 0.222170, acc.: 61.72%] [G loss: 0.322900]\n",
      "epoch:25 step:24228 [D loss: 0.251003, acc.: 53.91%] [G loss: 0.273646]\n",
      "epoch:25 step:24229 [D loss: 0.249050, acc.: 53.91%] [G loss: 0.275077]\n",
      "epoch:25 step:24230 [D loss: 0.240511, acc.: 60.16%] [G loss: 0.300424]\n",
      "epoch:25 step:24231 [D loss: 0.229109, acc.: 60.94%] [G loss: 0.324386]\n",
      "epoch:25 step:24232 [D loss: 0.220369, acc.: 66.41%] [G loss: 0.294850]\n",
      "epoch:25 step:24233 [D loss: 0.232380, acc.: 57.03%] [G loss: 0.318868]\n",
      "epoch:25 step:24234 [D loss: 0.243127, acc.: 59.38%] [G loss: 0.275858]\n",
      "epoch:25 step:24235 [D loss: 0.245195, acc.: 61.72%] [G loss: 0.308679]\n",
      "epoch:25 step:24236 [D loss: 0.245193, acc.: 53.12%] [G loss: 0.313254]\n",
      "epoch:25 step:24237 [D loss: 0.228553, acc.: 63.28%] [G loss: 0.301152]\n",
      "epoch:25 step:24238 [D loss: 0.245355, acc.: 56.25%] [G loss: 0.309835]\n",
      "epoch:25 step:24239 [D loss: 0.237430, acc.: 62.50%] [G loss: 0.308373]\n",
      "epoch:25 step:24240 [D loss: 0.246434, acc.: 58.59%] [G loss: 0.307596]\n",
      "epoch:25 step:24241 [D loss: 0.231223, acc.: 65.62%] [G loss: 0.313602]\n",
      "epoch:25 step:24242 [D loss: 0.247287, acc.: 56.25%] [G loss: 0.307043]\n",
      "epoch:25 step:24243 [D loss: 0.242130, acc.: 56.25%] [G loss: 0.300299]\n",
      "epoch:25 step:24244 [D loss: 0.241633, acc.: 58.59%] [G loss: 0.283387]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:25 step:24245 [D loss: 0.234246, acc.: 59.38%] [G loss: 0.289916]\n",
      "epoch:25 step:24246 [D loss: 0.233652, acc.: 62.50%] [G loss: 0.288136]\n",
      "epoch:25 step:24247 [D loss: 0.237206, acc.: 58.59%] [G loss: 0.286550]\n",
      "epoch:25 step:24248 [D loss: 0.249706, acc.: 47.66%] [G loss: 0.323269]\n",
      "epoch:25 step:24249 [D loss: 0.223918, acc.: 62.50%] [G loss: 0.259366]\n",
      "epoch:25 step:24250 [D loss: 0.233413, acc.: 58.59%] [G loss: 0.319069]\n",
      "epoch:25 step:24251 [D loss: 0.242269, acc.: 57.03%] [G loss: 0.306021]\n",
      "epoch:25 step:24252 [D loss: 0.248824, acc.: 53.91%] [G loss: 0.304007]\n",
      "epoch:25 step:24253 [D loss: 0.260625, acc.: 52.34%] [G loss: 0.308724]\n",
      "epoch:25 step:24254 [D loss: 0.246347, acc.: 59.38%] [G loss: 0.296504]\n",
      "epoch:25 step:24255 [D loss: 0.246716, acc.: 57.03%] [G loss: 0.290139]\n",
      "epoch:25 step:24256 [D loss: 0.260194, acc.: 49.22%] [G loss: 0.302143]\n",
      "epoch:25 step:24257 [D loss: 0.239513, acc.: 60.94%] [G loss: 0.290374]\n",
      "epoch:25 step:24258 [D loss: 0.248618, acc.: 59.38%] [G loss: 0.303294]\n",
      "epoch:25 step:24259 [D loss: 0.229889, acc.: 59.38%] [G loss: 0.316821]\n",
      "epoch:25 step:24260 [D loss: 0.245717, acc.: 56.25%] [G loss: 0.282578]\n",
      "epoch:25 step:24261 [D loss: 0.261935, acc.: 50.00%] [G loss: 0.274963]\n",
      "epoch:25 step:24262 [D loss: 0.248128, acc.: 50.00%] [G loss: 0.300205]\n",
      "epoch:25 step:24263 [D loss: 0.214947, acc.: 67.19%] [G loss: 0.297282]\n",
      "epoch:25 step:24264 [D loss: 0.215525, acc.: 70.31%] [G loss: 0.342941]\n",
      "epoch:25 step:24265 [D loss: 0.240530, acc.: 56.25%] [G loss: 0.323524]\n",
      "epoch:25 step:24266 [D loss: 0.236874, acc.: 59.38%] [G loss: 0.306423]\n",
      "epoch:25 step:24267 [D loss: 0.250387, acc.: 51.56%] [G loss: 0.323469]\n",
      "epoch:25 step:24268 [D loss: 0.237873, acc.: 57.81%] [G loss: 0.300991]\n",
      "epoch:25 step:24269 [D loss: 0.238522, acc.: 64.84%] [G loss: 0.282153]\n",
      "epoch:25 step:24270 [D loss: 0.255106, acc.: 51.56%] [G loss: 0.282593]\n",
      "epoch:25 step:24271 [D loss: 0.248730, acc.: 52.34%] [G loss: 0.296639]\n",
      "epoch:25 step:24272 [D loss: 0.224778, acc.: 67.19%] [G loss: 0.305742]\n",
      "epoch:25 step:24273 [D loss: 0.240558, acc.: 60.16%] [G loss: 0.292777]\n",
      "epoch:25 step:24274 [D loss: 0.240296, acc.: 56.25%] [G loss: 0.318227]\n",
      "epoch:25 step:24275 [D loss: 0.246187, acc.: 59.38%] [G loss: 0.308673]\n",
      "epoch:25 step:24276 [D loss: 0.244312, acc.: 55.47%] [G loss: 0.300483]\n",
      "epoch:25 step:24277 [D loss: 0.246245, acc.: 53.91%] [G loss: 0.307997]\n",
      "epoch:25 step:24278 [D loss: 0.219811, acc.: 67.97%] [G loss: 0.315857]\n",
      "epoch:25 step:24279 [D loss: 0.228258, acc.: 60.16%] [G loss: 0.296929]\n",
      "epoch:25 step:24280 [D loss: 0.246056, acc.: 59.38%] [G loss: 0.318708]\n",
      "epoch:25 step:24281 [D loss: 0.242471, acc.: 58.59%] [G loss: 0.305860]\n",
      "epoch:25 step:24282 [D loss: 0.263378, acc.: 49.22%] [G loss: 0.310158]\n",
      "epoch:25 step:24283 [D loss: 0.248682, acc.: 57.81%] [G loss: 0.292471]\n",
      "epoch:25 step:24284 [D loss: 0.243766, acc.: 55.47%] [G loss: 0.315068]\n",
      "epoch:25 step:24285 [D loss: 0.247425, acc.: 57.03%] [G loss: 0.315779]\n",
      "epoch:25 step:24286 [D loss: 0.230490, acc.: 65.62%] [G loss: 0.312936]\n",
      "epoch:25 step:24287 [D loss: 0.236451, acc.: 59.38%] [G loss: 0.302572]\n",
      "epoch:25 step:24288 [D loss: 0.238325, acc.: 60.16%] [G loss: 0.306470]\n",
      "epoch:25 step:24289 [D loss: 0.255853, acc.: 52.34%] [G loss: 0.298898]\n",
      "epoch:25 step:24290 [D loss: 0.215749, acc.: 65.62%] [G loss: 0.294626]\n",
      "epoch:25 step:24291 [D loss: 0.235738, acc.: 60.16%] [G loss: 0.311502]\n",
      "epoch:25 step:24292 [D loss: 0.233714, acc.: 64.84%] [G loss: 0.309694]\n",
      "epoch:25 step:24293 [D loss: 0.230484, acc.: 60.94%] [G loss: 0.253437]\n",
      "epoch:25 step:24294 [D loss: 0.251341, acc.: 56.25%] [G loss: 0.306599]\n",
      "epoch:25 step:24295 [D loss: 0.239905, acc.: 55.47%] [G loss: 0.295918]\n",
      "epoch:25 step:24296 [D loss: 0.229784, acc.: 61.72%] [G loss: 0.306812]\n",
      "epoch:25 step:24297 [D loss: 0.240602, acc.: 60.94%] [G loss: 0.289876]\n",
      "epoch:25 step:24298 [D loss: 0.226863, acc.: 62.50%] [G loss: 0.321370]\n",
      "epoch:25 step:24299 [D loss: 0.231096, acc.: 60.94%] [G loss: 0.335673]\n",
      "epoch:25 step:24300 [D loss: 0.226520, acc.: 62.50%] [G loss: 0.293023]\n",
      "epoch:25 step:24301 [D loss: 0.236713, acc.: 59.38%] [G loss: 0.315584]\n",
      "epoch:25 step:24302 [D loss: 0.223365, acc.: 56.25%] [G loss: 0.299188]\n",
      "epoch:25 step:24303 [D loss: 0.229037, acc.: 64.84%] [G loss: 0.282483]\n",
      "epoch:25 step:24304 [D loss: 0.227379, acc.: 61.72%] [G loss: 0.300159]\n",
      "epoch:25 step:24305 [D loss: 0.227489, acc.: 62.50%] [G loss: 0.292182]\n",
      "epoch:25 step:24306 [D loss: 0.243169, acc.: 57.03%] [G loss: 0.317803]\n",
      "epoch:25 step:24307 [D loss: 0.224539, acc.: 60.16%] [G loss: 0.328411]\n",
      "epoch:25 step:24308 [D loss: 0.254177, acc.: 54.69%] [G loss: 0.289133]\n",
      "epoch:25 step:24309 [D loss: 0.239390, acc.: 62.50%] [G loss: 0.323349]\n",
      "epoch:25 step:24310 [D loss: 0.235037, acc.: 62.50%] [G loss: 0.292772]\n",
      "epoch:25 step:24311 [D loss: 0.233446, acc.: 61.72%] [G loss: 0.311337]\n",
      "epoch:25 step:24312 [D loss: 0.210307, acc.: 68.75%] [G loss: 0.311759]\n",
      "epoch:25 step:24313 [D loss: 0.246196, acc.: 60.94%] [G loss: 0.310612]\n",
      "epoch:25 step:24314 [D loss: 0.252843, acc.: 54.69%] [G loss: 0.301257]\n",
      "epoch:25 step:24315 [D loss: 0.251787, acc.: 57.03%] [G loss: 0.317472]\n",
      "epoch:25 step:24316 [D loss: 0.243120, acc.: 53.12%] [G loss: 0.343685]\n",
      "epoch:25 step:24317 [D loss: 0.243193, acc.: 53.91%] [G loss: 0.318374]\n",
      "epoch:25 step:24318 [D loss: 0.261101, acc.: 53.12%] [G loss: 0.324903]\n",
      "epoch:25 step:24319 [D loss: 0.235518, acc.: 58.59%] [G loss: 0.305014]\n",
      "epoch:25 step:24320 [D loss: 0.228641, acc.: 60.94%] [G loss: 0.323056]\n",
      "epoch:25 step:24321 [D loss: 0.246534, acc.: 56.25%] [G loss: 0.320012]\n",
      "epoch:25 step:24322 [D loss: 0.233535, acc.: 61.72%] [G loss: 0.303912]\n",
      "epoch:25 step:24323 [D loss: 0.237546, acc.: 57.81%] [G loss: 0.312538]\n",
      "epoch:25 step:24324 [D loss: 0.246692, acc.: 53.12%] [G loss: 0.314583]\n",
      "epoch:25 step:24325 [D loss: 0.241032, acc.: 58.59%] [G loss: 0.319965]\n",
      "epoch:25 step:24326 [D loss: 0.243174, acc.: 55.47%] [G loss: 0.295154]\n",
      "epoch:25 step:24327 [D loss: 0.249075, acc.: 50.78%] [G loss: 0.283218]\n",
      "epoch:25 step:24328 [D loss: 0.243768, acc.: 58.59%] [G loss: 0.302274]\n",
      "epoch:25 step:24329 [D loss: 0.232232, acc.: 65.62%] [G loss: 0.290317]\n",
      "epoch:25 step:24330 [D loss: 0.249648, acc.: 53.91%] [G loss: 0.304042]\n",
      "epoch:25 step:24331 [D loss: 0.261299, acc.: 48.44%] [G loss: 0.286666]\n",
      "epoch:25 step:24332 [D loss: 0.234876, acc.: 58.59%] [G loss: 0.312192]\n",
      "epoch:25 step:24333 [D loss: 0.268716, acc.: 50.78%] [G loss: 0.286877]\n",
      "epoch:25 step:24334 [D loss: 0.227227, acc.: 64.84%] [G loss: 0.313000]\n",
      "epoch:25 step:24335 [D loss: 0.229193, acc.: 60.94%] [G loss: 0.315162]\n",
      "epoch:25 step:24336 [D loss: 0.250160, acc.: 52.34%] [G loss: 0.311808]\n",
      "epoch:25 step:24337 [D loss: 0.233964, acc.: 64.84%] [G loss: 0.304775]\n",
      "epoch:25 step:24338 [D loss: 0.242442, acc.: 56.25%] [G loss: 0.279130]\n",
      "epoch:25 step:24339 [D loss: 0.240647, acc.: 57.81%] [G loss: 0.301196]\n",
      "epoch:25 step:24340 [D loss: 0.245720, acc.: 52.34%] [G loss: 0.299727]\n",
      "epoch:25 step:24341 [D loss: 0.238262, acc.: 60.94%] [G loss: 0.320024]\n",
      "epoch:25 step:24342 [D loss: 0.233929, acc.: 58.59%] [G loss: 0.298980]\n",
      "epoch:25 step:24343 [D loss: 0.246139, acc.: 53.91%] [G loss: 0.302744]\n",
      "epoch:25 step:24344 [D loss: 0.235305, acc.: 60.16%] [G loss: 0.271800]\n",
      "epoch:25 step:24345 [D loss: 0.243660, acc.: 59.38%] [G loss: 0.278229]\n",
      "epoch:25 step:24346 [D loss: 0.244311, acc.: 62.50%] [G loss: 0.342196]\n",
      "epoch:25 step:24347 [D loss: 0.246565, acc.: 58.59%] [G loss: 0.300120]\n",
      "epoch:25 step:24348 [D loss: 0.238795, acc.: 57.81%] [G loss: 0.302313]\n",
      "epoch:25 step:24349 [D loss: 0.233524, acc.: 59.38%] [G loss: 0.305404]\n",
      "epoch:25 step:24350 [D loss: 0.242348, acc.: 57.03%] [G loss: 0.290842]\n",
      "epoch:25 step:24351 [D loss: 0.239790, acc.: 60.94%] [G loss: 0.314337]\n",
      "epoch:25 step:24352 [D loss: 0.249187, acc.: 56.25%] [G loss: 0.294699]\n",
      "epoch:25 step:24353 [D loss: 0.234070, acc.: 58.59%] [G loss: 0.316248]\n",
      "epoch:25 step:24354 [D loss: 0.229888, acc.: 59.38%] [G loss: 0.313307]\n",
      "epoch:25 step:24355 [D loss: 0.237846, acc.: 59.38%] [G loss: 0.293060]\n",
      "epoch:25 step:24356 [D loss: 0.250478, acc.: 54.69%] [G loss: 0.288454]\n",
      "epoch:25 step:24357 [D loss: 0.253474, acc.: 51.56%] [G loss: 0.306980]\n",
      "epoch:25 step:24358 [D loss: 0.236644, acc.: 61.72%] [G loss: 0.295066]\n",
      "epoch:25 step:24359 [D loss: 0.249551, acc.: 51.56%] [G loss: 0.285626]\n",
      "epoch:25 step:24360 [D loss: 0.237999, acc.: 57.81%] [G loss: 0.296204]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:25 step:24361 [D loss: 0.230357, acc.: 60.16%] [G loss: 0.280720]\n",
      "epoch:25 step:24362 [D loss: 0.256765, acc.: 47.66%] [G loss: 0.273988]\n",
      "epoch:26 step:24363 [D loss: 0.249415, acc.: 54.69%] [G loss: 0.301010]\n",
      "epoch:26 step:24364 [D loss: 0.244076, acc.: 56.25%] [G loss: 0.287915]\n",
      "epoch:26 step:24365 [D loss: 0.242020, acc.: 60.16%] [G loss: 0.286069]\n",
      "epoch:26 step:24366 [D loss: 0.235229, acc.: 60.16%] [G loss: 0.302244]\n",
      "epoch:26 step:24367 [D loss: 0.236206, acc.: 57.03%] [G loss: 0.314067]\n",
      "epoch:26 step:24368 [D loss: 0.253243, acc.: 49.22%] [G loss: 0.289088]\n",
      "epoch:26 step:24369 [D loss: 0.241178, acc.: 53.12%] [G loss: 0.304322]\n",
      "epoch:26 step:24370 [D loss: 0.245496, acc.: 56.25%] [G loss: 0.288332]\n",
      "epoch:26 step:24371 [D loss: 0.221695, acc.: 60.94%] [G loss: 0.294283]\n",
      "epoch:26 step:24372 [D loss: 0.217190, acc.: 69.53%] [G loss: 0.333481]\n",
      "epoch:26 step:24373 [D loss: 0.234094, acc.: 60.94%] [G loss: 0.293977]\n",
      "epoch:26 step:24374 [D loss: 0.244598, acc.: 57.81%] [G loss: 0.283125]\n",
      "epoch:26 step:24375 [D loss: 0.247869, acc.: 57.03%] [G loss: 0.296983]\n",
      "epoch:26 step:24376 [D loss: 0.231746, acc.: 63.28%] [G loss: 0.305916]\n",
      "epoch:26 step:24377 [D loss: 0.237286, acc.: 59.38%] [G loss: 0.317695]\n",
      "epoch:26 step:24378 [D loss: 0.220941, acc.: 64.84%] [G loss: 0.276873]\n",
      "epoch:26 step:24379 [D loss: 0.249163, acc.: 55.47%] [G loss: 0.277015]\n",
      "epoch:26 step:24380 [D loss: 0.236926, acc.: 59.38%] [G loss: 0.297337]\n",
      "epoch:26 step:24381 [D loss: 0.247463, acc.: 60.16%] [G loss: 0.284203]\n",
      "epoch:26 step:24382 [D loss: 0.250805, acc.: 50.00%] [G loss: 0.272783]\n",
      "epoch:26 step:24383 [D loss: 0.248336, acc.: 57.03%] [G loss: 0.300278]\n",
      "epoch:26 step:24384 [D loss: 0.232902, acc.: 57.81%] [G loss: 0.327629]\n",
      "epoch:26 step:24385 [D loss: 0.231839, acc.: 55.47%] [G loss: 0.307214]\n",
      "epoch:26 step:24386 [D loss: 0.230279, acc.: 62.50%] [G loss: 0.324130]\n",
      "epoch:26 step:24387 [D loss: 0.250096, acc.: 57.03%] [G loss: 0.300302]\n",
      "epoch:26 step:24388 [D loss: 0.246341, acc.: 53.91%] [G loss: 0.322196]\n",
      "epoch:26 step:24389 [D loss: 0.253896, acc.: 50.78%] [G loss: 0.307889]\n",
      "epoch:26 step:24390 [D loss: 0.242759, acc.: 61.72%] [G loss: 0.312950]\n",
      "epoch:26 step:24391 [D loss: 0.235814, acc.: 59.38%] [G loss: 0.291202]\n",
      "epoch:26 step:24392 [D loss: 0.238678, acc.: 60.16%] [G loss: 0.302518]\n",
      "epoch:26 step:24393 [D loss: 0.238697, acc.: 55.47%] [G loss: 0.312102]\n",
      "epoch:26 step:24394 [D loss: 0.237918, acc.: 59.38%] [G loss: 0.273908]\n",
      "epoch:26 step:24395 [D loss: 0.245080, acc.: 59.38%] [G loss: 0.306795]\n",
      "epoch:26 step:24396 [D loss: 0.227796, acc.: 64.06%] [G loss: 0.298417]\n",
      "epoch:26 step:24397 [D loss: 0.250407, acc.: 55.47%] [G loss: 0.283596]\n",
      "epoch:26 step:24398 [D loss: 0.234998, acc.: 63.28%] [G loss: 0.286179]\n",
      "epoch:26 step:24399 [D loss: 0.223269, acc.: 64.84%] [G loss: 0.321654]\n",
      "epoch:26 step:24400 [D loss: 0.249212, acc.: 58.59%] [G loss: 0.288992]\n",
      "epoch:26 step:24401 [D loss: 0.232890, acc.: 65.62%] [G loss: 0.296657]\n",
      "epoch:26 step:24402 [D loss: 0.249152, acc.: 51.56%] [G loss: 0.331903]\n",
      "epoch:26 step:24403 [D loss: 0.236167, acc.: 58.59%] [G loss: 0.302031]\n",
      "epoch:26 step:24404 [D loss: 0.240414, acc.: 59.38%] [G loss: 0.325145]\n",
      "epoch:26 step:24405 [D loss: 0.221193, acc.: 67.97%] [G loss: 0.291533]\n",
      "epoch:26 step:24406 [D loss: 0.225088, acc.: 64.06%] [G loss: 0.337500]\n",
      "epoch:26 step:24407 [D loss: 0.237709, acc.: 56.25%] [G loss: 0.282814]\n",
      "epoch:26 step:24408 [D loss: 0.249757, acc.: 55.47%] [G loss: 0.309116]\n",
      "epoch:26 step:24409 [D loss: 0.250109, acc.: 51.56%] [G loss: 0.307901]\n",
      "epoch:26 step:24410 [D loss: 0.227569, acc.: 60.94%] [G loss: 0.312392]\n",
      "epoch:26 step:24411 [D loss: 0.241955, acc.: 63.28%] [G loss: 0.295162]\n",
      "epoch:26 step:24412 [D loss: 0.231327, acc.: 59.38%] [G loss: 0.285913]\n",
      "epoch:26 step:24413 [D loss: 0.234363, acc.: 54.69%] [G loss: 0.303383]\n",
      "epoch:26 step:24414 [D loss: 0.247790, acc.: 52.34%] [G loss: 0.291015]\n",
      "epoch:26 step:24415 [D loss: 0.237002, acc.: 59.38%] [G loss: 0.319173]\n",
      "epoch:26 step:24416 [D loss: 0.223922, acc.: 66.41%] [G loss: 0.316530]\n",
      "epoch:26 step:24417 [D loss: 0.239893, acc.: 56.25%] [G loss: 0.314550]\n",
      "epoch:26 step:24418 [D loss: 0.245806, acc.: 55.47%] [G loss: 0.282312]\n",
      "epoch:26 step:24419 [D loss: 0.221120, acc.: 64.84%] [G loss: 0.311712]\n",
      "epoch:26 step:24420 [D loss: 0.237221, acc.: 61.72%] [G loss: 0.294227]\n",
      "epoch:26 step:24421 [D loss: 0.222455, acc.: 69.53%] [G loss: 0.291470]\n",
      "epoch:26 step:24422 [D loss: 0.239758, acc.: 57.03%] [G loss: 0.293257]\n",
      "epoch:26 step:24423 [D loss: 0.250511, acc.: 49.22%] [G loss: 0.296624]\n",
      "epoch:26 step:24424 [D loss: 0.227798, acc.: 64.06%] [G loss: 0.278886]\n",
      "epoch:26 step:24425 [D loss: 0.245876, acc.: 57.03%] [G loss: 0.298446]\n",
      "epoch:26 step:24426 [D loss: 0.248189, acc.: 52.34%] [G loss: 0.272957]\n",
      "epoch:26 step:24427 [D loss: 0.232530, acc.: 56.25%] [G loss: 0.300162]\n",
      "epoch:26 step:24428 [D loss: 0.240262, acc.: 57.81%] [G loss: 0.268632]\n",
      "epoch:26 step:24429 [D loss: 0.233396, acc.: 57.03%] [G loss: 0.311618]\n",
      "epoch:26 step:24430 [D loss: 0.242434, acc.: 60.16%] [G loss: 0.317055]\n",
      "epoch:26 step:24431 [D loss: 0.236304, acc.: 62.50%] [G loss: 0.306530]\n",
      "epoch:26 step:24432 [D loss: 0.237280, acc.: 61.72%] [G loss: 0.267058]\n",
      "epoch:26 step:24433 [D loss: 0.251238, acc.: 60.94%] [G loss: 0.294523]\n",
      "epoch:26 step:24434 [D loss: 0.252369, acc.: 56.25%] [G loss: 0.294480]\n",
      "epoch:26 step:24435 [D loss: 0.224648, acc.: 61.72%] [G loss: 0.316022]\n",
      "epoch:26 step:24436 [D loss: 0.246301, acc.: 59.38%] [G loss: 0.291915]\n",
      "epoch:26 step:24437 [D loss: 0.239562, acc.: 58.59%] [G loss: 0.317463]\n",
      "epoch:26 step:24438 [D loss: 0.260722, acc.: 48.44%] [G loss: 0.297269]\n",
      "epoch:26 step:24439 [D loss: 0.247823, acc.: 53.12%] [G loss: 0.321560]\n",
      "epoch:26 step:24440 [D loss: 0.249549, acc.: 51.56%] [G loss: 0.289489]\n",
      "epoch:26 step:24441 [D loss: 0.240117, acc.: 56.25%] [G loss: 0.312541]\n",
      "epoch:26 step:24442 [D loss: 0.226893, acc.: 64.06%] [G loss: 0.298353]\n",
      "epoch:26 step:24443 [D loss: 0.247026, acc.: 57.03%] [G loss: 0.318446]\n",
      "epoch:26 step:24444 [D loss: 0.233840, acc.: 57.03%] [G loss: 0.326966]\n",
      "epoch:26 step:24445 [D loss: 0.235737, acc.: 63.28%] [G loss: 0.305311]\n",
      "epoch:26 step:24446 [D loss: 0.238797, acc.: 56.25%] [G loss: 0.288689]\n",
      "epoch:26 step:24447 [D loss: 0.229320, acc.: 63.28%] [G loss: 0.316595]\n",
      "epoch:26 step:24448 [D loss: 0.237249, acc.: 59.38%] [G loss: 0.321538]\n",
      "epoch:26 step:24449 [D loss: 0.246677, acc.: 57.81%] [G loss: 0.273127]\n",
      "epoch:26 step:24450 [D loss: 0.226407, acc.: 63.28%] [G loss: 0.304883]\n",
      "epoch:26 step:24451 [D loss: 0.243919, acc.: 56.25%] [G loss: 0.297224]\n",
      "epoch:26 step:24452 [D loss: 0.229001, acc.: 61.72%] [G loss: 0.304763]\n",
      "epoch:26 step:24453 [D loss: 0.232400, acc.: 61.72%] [G loss: 0.309669]\n",
      "epoch:26 step:24454 [D loss: 0.236183, acc.: 60.16%] [G loss: 0.324428]\n",
      "epoch:26 step:24455 [D loss: 0.236640, acc.: 55.47%] [G loss: 0.325708]\n",
      "epoch:26 step:24456 [D loss: 0.235651, acc.: 60.94%] [G loss: 0.290887]\n",
      "epoch:26 step:24457 [D loss: 0.246112, acc.: 53.91%] [G loss: 0.329320]\n",
      "epoch:26 step:24458 [D loss: 0.240828, acc.: 56.25%] [G loss: 0.351868]\n",
      "epoch:26 step:24459 [D loss: 0.250582, acc.: 50.78%] [G loss: 0.280965]\n",
      "epoch:26 step:24460 [D loss: 0.246185, acc.: 58.59%] [G loss: 0.277396]\n",
      "epoch:26 step:24461 [D loss: 0.235352, acc.: 60.94%] [G loss: 0.287288]\n",
      "epoch:26 step:24462 [D loss: 0.259935, acc.: 53.12%] [G loss: 0.289038]\n",
      "epoch:26 step:24463 [D loss: 0.240726, acc.: 63.28%] [G loss: 0.298992]\n",
      "epoch:26 step:24464 [D loss: 0.250715, acc.: 53.91%] [G loss: 0.283634]\n",
      "epoch:26 step:24465 [D loss: 0.224820, acc.: 68.75%] [G loss: 0.292937]\n",
      "epoch:26 step:24466 [D loss: 0.234646, acc.: 59.38%] [G loss: 0.286741]\n",
      "epoch:26 step:24467 [D loss: 0.238212, acc.: 57.03%] [G loss: 0.295500]\n",
      "epoch:26 step:24468 [D loss: 0.246625, acc.: 56.25%] [G loss: 0.293407]\n",
      "epoch:26 step:24469 [D loss: 0.226372, acc.: 65.62%] [G loss: 0.292509]\n",
      "epoch:26 step:24470 [D loss: 0.227833, acc.: 61.72%] [G loss: 0.326164]\n",
      "epoch:26 step:24471 [D loss: 0.239899, acc.: 58.59%] [G loss: 0.333875]\n",
      "epoch:26 step:24472 [D loss: 0.250374, acc.: 53.12%] [G loss: 0.328033]\n",
      "epoch:26 step:24473 [D loss: 0.255826, acc.: 53.91%] [G loss: 0.273262]\n",
      "epoch:26 step:24474 [D loss: 0.229222, acc.: 61.72%] [G loss: 0.335091]\n",
      "epoch:26 step:24475 [D loss: 0.253004, acc.: 53.91%] [G loss: 0.299024]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:26 step:24476 [D loss: 0.228634, acc.: 62.50%] [G loss: 0.299400]\n",
      "epoch:26 step:24477 [D loss: 0.229161, acc.: 59.38%] [G loss: 0.312511]\n",
      "epoch:26 step:24478 [D loss: 0.240332, acc.: 60.16%] [G loss: 0.288869]\n",
      "epoch:26 step:24479 [D loss: 0.239532, acc.: 56.25%] [G loss: 0.286797]\n",
      "epoch:26 step:24480 [D loss: 0.247858, acc.: 52.34%] [G loss: 0.275652]\n",
      "epoch:26 step:24481 [D loss: 0.246126, acc.: 53.91%] [G loss: 0.304368]\n",
      "epoch:26 step:24482 [D loss: 0.252345, acc.: 54.69%] [G loss: 0.296633]\n",
      "epoch:26 step:24483 [D loss: 0.236497, acc.: 57.81%] [G loss: 0.273347]\n",
      "epoch:26 step:24484 [D loss: 0.226030, acc.: 63.28%] [G loss: 0.304440]\n",
      "epoch:26 step:24485 [D loss: 0.248911, acc.: 53.91%] [G loss: 0.307466]\n",
      "epoch:26 step:24486 [D loss: 0.236924, acc.: 54.69%] [G loss: 0.289127]\n",
      "epoch:26 step:24487 [D loss: 0.235136, acc.: 61.72%] [G loss: 0.308804]\n",
      "epoch:26 step:24488 [D loss: 0.250605, acc.: 51.56%] [G loss: 0.294754]\n",
      "epoch:26 step:24489 [D loss: 0.250083, acc.: 53.91%] [G loss: 0.292835]\n",
      "epoch:26 step:24490 [D loss: 0.230327, acc.: 66.41%] [G loss: 0.317022]\n",
      "epoch:26 step:24491 [D loss: 0.233466, acc.: 63.28%] [G loss: 0.302835]\n",
      "epoch:26 step:24492 [D loss: 0.228282, acc.: 65.62%] [G loss: 0.311715]\n",
      "epoch:26 step:24493 [D loss: 0.226740, acc.: 64.84%] [G loss: 0.322818]\n",
      "epoch:26 step:24494 [D loss: 0.242797, acc.: 53.12%] [G loss: 0.345464]\n",
      "epoch:26 step:24495 [D loss: 0.235501, acc.: 57.81%] [G loss: 0.282030]\n",
      "epoch:26 step:24496 [D loss: 0.240991, acc.: 57.81%] [G loss: 0.296886]\n",
      "epoch:26 step:24497 [D loss: 0.249817, acc.: 52.34%] [G loss: 0.288262]\n",
      "epoch:26 step:24498 [D loss: 0.251241, acc.: 53.91%] [G loss: 0.295468]\n",
      "epoch:26 step:24499 [D loss: 0.230531, acc.: 61.72%] [G loss: 0.323612]\n",
      "epoch:26 step:24500 [D loss: 0.244716, acc.: 57.03%] [G loss: 0.294437]\n",
      "epoch:26 step:24501 [D loss: 0.252044, acc.: 52.34%] [G loss: 0.305635]\n",
      "epoch:26 step:24502 [D loss: 0.270481, acc.: 46.09%] [G loss: 0.301682]\n",
      "epoch:26 step:24503 [D loss: 0.258068, acc.: 51.56%] [G loss: 0.298656]\n",
      "epoch:26 step:24504 [D loss: 0.238169, acc.: 64.06%] [G loss: 0.331576]\n",
      "epoch:26 step:24505 [D loss: 0.233652, acc.: 58.59%] [G loss: 0.319258]\n",
      "epoch:26 step:24506 [D loss: 0.252114, acc.: 51.56%] [G loss: 0.277009]\n",
      "epoch:26 step:24507 [D loss: 0.232130, acc.: 60.16%] [G loss: 0.334332]\n",
      "epoch:26 step:24508 [D loss: 0.234142, acc.: 58.59%] [G loss: 0.274531]\n",
      "epoch:26 step:24509 [D loss: 0.225482, acc.: 64.06%] [G loss: 0.321016]\n",
      "epoch:26 step:24510 [D loss: 0.231135, acc.: 65.62%] [G loss: 0.310286]\n",
      "epoch:26 step:24511 [D loss: 0.235438, acc.: 64.06%] [G loss: 0.323411]\n",
      "epoch:26 step:24512 [D loss: 0.225029, acc.: 66.41%] [G loss: 0.329602]\n",
      "epoch:26 step:24513 [D loss: 0.253382, acc.: 51.56%] [G loss: 0.283204]\n",
      "epoch:26 step:24514 [D loss: 0.244462, acc.: 57.03%] [G loss: 0.295471]\n",
      "epoch:26 step:24515 [D loss: 0.234827, acc.: 57.81%] [G loss: 0.336475]\n",
      "epoch:26 step:24516 [D loss: 0.247475, acc.: 56.25%] [G loss: 0.279615]\n",
      "epoch:26 step:24517 [D loss: 0.246075, acc.: 56.25%] [G loss: 0.277584]\n",
      "epoch:26 step:24518 [D loss: 0.241768, acc.: 57.81%] [G loss: 0.266670]\n",
      "epoch:26 step:24519 [D loss: 0.246829, acc.: 55.47%] [G loss: 0.294115]\n",
      "epoch:26 step:24520 [D loss: 0.232370, acc.: 60.16%] [G loss: 0.290203]\n",
      "epoch:26 step:24521 [D loss: 0.245919, acc.: 55.47%] [G loss: 0.289378]\n",
      "epoch:26 step:24522 [D loss: 0.219899, acc.: 59.38%] [G loss: 0.310067]\n",
      "epoch:26 step:24523 [D loss: 0.259914, acc.: 50.78%] [G loss: 0.292220]\n",
      "epoch:26 step:24524 [D loss: 0.249125, acc.: 53.91%] [G loss: 0.267464]\n",
      "epoch:26 step:24525 [D loss: 0.240741, acc.: 58.59%] [G loss: 0.306925]\n",
      "epoch:26 step:24526 [D loss: 0.238554, acc.: 57.03%] [G loss: 0.296395]\n",
      "epoch:26 step:24527 [D loss: 0.253517, acc.: 50.78%] [G loss: 0.278126]\n",
      "epoch:26 step:24528 [D loss: 0.218646, acc.: 69.53%] [G loss: 0.291129]\n",
      "epoch:26 step:24529 [D loss: 0.231777, acc.: 60.16%] [G loss: 0.312871]\n",
      "epoch:26 step:24530 [D loss: 0.245385, acc.: 58.59%] [G loss: 0.317487]\n",
      "epoch:26 step:24531 [D loss: 0.245589, acc.: 57.81%] [G loss: 0.309686]\n",
      "epoch:26 step:24532 [D loss: 0.241229, acc.: 66.41%] [G loss: 0.321325]\n",
      "epoch:26 step:24533 [D loss: 0.240611, acc.: 53.91%] [G loss: 0.302405]\n",
      "epoch:26 step:24534 [D loss: 0.223076, acc.: 64.84%] [G loss: 0.325133]\n",
      "epoch:26 step:24535 [D loss: 0.226958, acc.: 64.06%] [G loss: 0.319461]\n",
      "epoch:26 step:24536 [D loss: 0.237116, acc.: 54.69%] [G loss: 0.329488]\n",
      "epoch:26 step:24537 [D loss: 0.237007, acc.: 64.06%] [G loss: 0.312702]\n",
      "epoch:26 step:24538 [D loss: 0.233418, acc.: 62.50%] [G loss: 0.294665]\n",
      "epoch:26 step:24539 [D loss: 0.232266, acc.: 65.62%] [G loss: 0.301344]\n",
      "epoch:26 step:24540 [D loss: 0.241036, acc.: 51.56%] [G loss: 0.334245]\n",
      "epoch:26 step:24541 [D loss: 0.230186, acc.: 62.50%] [G loss: 0.315892]\n",
      "epoch:26 step:24542 [D loss: 0.232824, acc.: 58.59%] [G loss: 0.294618]\n",
      "epoch:26 step:24543 [D loss: 0.230750, acc.: 61.72%] [G loss: 0.315917]\n",
      "epoch:26 step:24544 [D loss: 0.236742, acc.: 57.03%] [G loss: 0.291399]\n",
      "epoch:26 step:24545 [D loss: 0.256861, acc.: 55.47%] [G loss: 0.262877]\n",
      "epoch:26 step:24546 [D loss: 0.235963, acc.: 53.91%] [G loss: 0.299493]\n",
      "epoch:26 step:24547 [D loss: 0.234749, acc.: 54.69%] [G loss: 0.306561]\n",
      "epoch:26 step:24548 [D loss: 0.251023, acc.: 54.69%] [G loss: 0.284874]\n",
      "epoch:26 step:24549 [D loss: 0.218072, acc.: 64.84%] [G loss: 0.313381]\n",
      "epoch:26 step:24550 [D loss: 0.244042, acc.: 57.81%] [G loss: 0.288903]\n",
      "epoch:26 step:24551 [D loss: 0.247573, acc.: 57.03%] [G loss: 0.269604]\n",
      "epoch:26 step:24552 [D loss: 0.232635, acc.: 58.59%] [G loss: 0.314676]\n",
      "epoch:26 step:24553 [D loss: 0.243331, acc.: 53.91%] [G loss: 0.296344]\n",
      "epoch:26 step:24554 [D loss: 0.223052, acc.: 63.28%] [G loss: 0.308195]\n",
      "epoch:26 step:24555 [D loss: 0.231101, acc.: 60.16%] [G loss: 0.302774]\n",
      "epoch:26 step:24556 [D loss: 0.253011, acc.: 50.78%] [G loss: 0.316756]\n",
      "epoch:26 step:24557 [D loss: 0.232149, acc.: 57.03%] [G loss: 0.299700]\n",
      "epoch:26 step:24558 [D loss: 0.242724, acc.: 60.16%] [G loss: 0.272872]\n",
      "epoch:26 step:24559 [D loss: 0.246129, acc.: 56.25%] [G loss: 0.275146]\n",
      "epoch:26 step:24560 [D loss: 0.245456, acc.: 54.69%] [G loss: 0.272927]\n",
      "epoch:26 step:24561 [D loss: 0.233158, acc.: 59.38%] [G loss: 0.288026]\n",
      "epoch:26 step:24562 [D loss: 0.240658, acc.: 59.38%] [G loss: 0.284289]\n",
      "epoch:26 step:24563 [D loss: 0.236994, acc.: 59.38%] [G loss: 0.273052]\n",
      "epoch:26 step:24564 [D loss: 0.233405, acc.: 62.50%] [G loss: 0.324426]\n",
      "epoch:26 step:24565 [D loss: 0.255716, acc.: 54.69%] [G loss: 0.305648]\n",
      "epoch:26 step:24566 [D loss: 0.237966, acc.: 59.38%] [G loss: 0.294660]\n",
      "epoch:26 step:24567 [D loss: 0.238624, acc.: 61.72%] [G loss: 0.306294]\n",
      "epoch:26 step:24568 [D loss: 0.247185, acc.: 52.34%] [G loss: 0.292927]\n",
      "epoch:26 step:24569 [D loss: 0.229791, acc.: 65.62%] [G loss: 0.285942]\n",
      "epoch:26 step:24570 [D loss: 0.243002, acc.: 60.94%] [G loss: 0.294308]\n",
      "epoch:26 step:24571 [D loss: 0.222668, acc.: 64.06%] [G loss: 0.290794]\n",
      "epoch:26 step:24572 [D loss: 0.245232, acc.: 57.03%] [G loss: 0.319056]\n",
      "epoch:26 step:24573 [D loss: 0.224576, acc.: 64.84%] [G loss: 0.319255]\n",
      "epoch:26 step:24574 [D loss: 0.244996, acc.: 56.25%] [G loss: 0.304369]\n",
      "epoch:26 step:24575 [D loss: 0.251000, acc.: 55.47%] [G loss: 0.310388]\n",
      "epoch:26 step:24576 [D loss: 0.245566, acc.: 57.81%] [G loss: 0.297434]\n",
      "epoch:26 step:24577 [D loss: 0.247691, acc.: 53.91%] [G loss: 0.309217]\n",
      "epoch:26 step:24578 [D loss: 0.234127, acc.: 59.38%] [G loss: 0.299040]\n",
      "epoch:26 step:24579 [D loss: 0.228901, acc.: 63.28%] [G loss: 0.315458]\n",
      "epoch:26 step:24580 [D loss: 0.235136, acc.: 61.72%] [G loss: 0.308479]\n",
      "epoch:26 step:24581 [D loss: 0.242853, acc.: 60.16%] [G loss: 0.306788]\n",
      "epoch:26 step:24582 [D loss: 0.224501, acc.: 64.84%] [G loss: 0.312631]\n",
      "epoch:26 step:24583 [D loss: 0.233153, acc.: 63.28%] [G loss: 0.313016]\n",
      "epoch:26 step:24584 [D loss: 0.247672, acc.: 56.25%] [G loss: 0.293413]\n",
      "epoch:26 step:24585 [D loss: 0.245211, acc.: 55.47%] [G loss: 0.310043]\n",
      "epoch:26 step:24586 [D loss: 0.237495, acc.: 60.16%] [G loss: 0.305579]\n",
      "epoch:26 step:24587 [D loss: 0.226480, acc.: 63.28%] [G loss: 0.295465]\n",
      "epoch:26 step:24588 [D loss: 0.233398, acc.: 63.28%] [G loss: 0.298221]\n",
      "epoch:26 step:24589 [D loss: 0.235898, acc.: 60.16%] [G loss: 0.293856]\n",
      "epoch:26 step:24590 [D loss: 0.251835, acc.: 53.12%] [G loss: 0.265410]\n",
      "epoch:26 step:24591 [D loss: 0.232510, acc.: 59.38%] [G loss: 0.282625]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:26 step:24592 [D loss: 0.238154, acc.: 57.03%] [G loss: 0.283009]\n",
      "epoch:26 step:24593 [D loss: 0.220022, acc.: 62.50%] [G loss: 0.299901]\n",
      "epoch:26 step:24594 [D loss: 0.250881, acc.: 53.12%] [G loss: 0.274695]\n",
      "epoch:26 step:24595 [D loss: 0.235445, acc.: 61.72%] [G loss: 0.282059]\n",
      "epoch:26 step:24596 [D loss: 0.239464, acc.: 60.16%] [G loss: 0.306768]\n",
      "epoch:26 step:24597 [D loss: 0.234062, acc.: 64.84%] [G loss: 0.293831]\n",
      "epoch:26 step:24598 [D loss: 0.240676, acc.: 57.81%] [G loss: 0.292720]\n",
      "epoch:26 step:24599 [D loss: 0.252699, acc.: 50.78%] [G loss: 0.283850]\n",
      "epoch:26 step:24600 [D loss: 0.235354, acc.: 60.16%] [G loss: 0.346336]\n",
      "epoch:26 step:24601 [D loss: 0.225758, acc.: 60.16%] [G loss: 0.329962]\n",
      "epoch:26 step:24602 [D loss: 0.246207, acc.: 59.38%] [G loss: 0.298732]\n",
      "epoch:26 step:24603 [D loss: 0.229548, acc.: 60.16%] [G loss: 0.305971]\n",
      "epoch:26 step:24604 [D loss: 0.233924, acc.: 62.50%] [G loss: 0.299251]\n",
      "epoch:26 step:24605 [D loss: 0.230909, acc.: 60.94%] [G loss: 0.329401]\n",
      "epoch:26 step:24606 [D loss: 0.252665, acc.: 48.44%] [G loss: 0.260449]\n",
      "epoch:26 step:24607 [D loss: 0.235533, acc.: 64.06%] [G loss: 0.314815]\n",
      "epoch:26 step:24608 [D loss: 0.238237, acc.: 64.06%] [G loss: 0.284574]\n",
      "epoch:26 step:24609 [D loss: 0.230715, acc.: 58.59%] [G loss: 0.313898]\n",
      "epoch:26 step:24610 [D loss: 0.246714, acc.: 53.91%] [G loss: 0.310973]\n",
      "epoch:26 step:24611 [D loss: 0.245780, acc.: 53.12%] [G loss: 0.294069]\n",
      "epoch:26 step:24612 [D loss: 0.238197, acc.: 59.38%] [G loss: 0.300495]\n",
      "epoch:26 step:24613 [D loss: 0.237314, acc.: 60.16%] [G loss: 0.286189]\n",
      "epoch:26 step:24614 [D loss: 0.248122, acc.: 50.00%] [G loss: 0.304055]\n",
      "epoch:26 step:24615 [D loss: 0.236478, acc.: 58.59%] [G loss: 0.313606]\n",
      "epoch:26 step:24616 [D loss: 0.248761, acc.: 54.69%] [G loss: 0.298640]\n",
      "epoch:26 step:24617 [D loss: 0.227922, acc.: 67.19%] [G loss: 0.301615]\n",
      "epoch:26 step:24618 [D loss: 0.237363, acc.: 61.72%] [G loss: 0.334678]\n",
      "epoch:26 step:24619 [D loss: 0.229851, acc.: 61.72%] [G loss: 0.301594]\n",
      "epoch:26 step:24620 [D loss: 0.231372, acc.: 59.38%] [G loss: 0.303098]\n",
      "epoch:26 step:24621 [D loss: 0.232406, acc.: 59.38%] [G loss: 0.305713]\n",
      "epoch:26 step:24622 [D loss: 0.250703, acc.: 55.47%] [G loss: 0.300367]\n",
      "epoch:26 step:24623 [D loss: 0.270002, acc.: 47.66%] [G loss: 0.295537]\n",
      "epoch:26 step:24624 [D loss: 0.259939, acc.: 50.78%] [G loss: 0.281439]\n",
      "epoch:26 step:24625 [D loss: 0.226141, acc.: 67.19%] [G loss: 0.338120]\n",
      "epoch:26 step:24626 [D loss: 0.253864, acc.: 51.56%] [G loss: 0.285921]\n",
      "epoch:26 step:24627 [D loss: 0.247207, acc.: 55.47%] [G loss: 0.323439]\n",
      "epoch:26 step:24628 [D loss: 0.216544, acc.: 61.72%] [G loss: 0.313291]\n",
      "epoch:26 step:24629 [D loss: 0.228646, acc.: 63.28%] [G loss: 0.311036]\n",
      "epoch:26 step:24630 [D loss: 0.243843, acc.: 57.03%] [G loss: 0.333344]\n",
      "epoch:26 step:24631 [D loss: 0.240160, acc.: 61.72%] [G loss: 0.316754]\n",
      "epoch:26 step:24632 [D loss: 0.236412, acc.: 61.72%] [G loss: 0.309013]\n",
      "epoch:26 step:24633 [D loss: 0.238097, acc.: 57.03%] [G loss: 0.310115]\n",
      "epoch:26 step:24634 [D loss: 0.237349, acc.: 54.69%] [G loss: 0.315849]\n",
      "epoch:26 step:24635 [D loss: 0.247041, acc.: 53.91%] [G loss: 0.278642]\n",
      "epoch:26 step:24636 [D loss: 0.242396, acc.: 62.50%] [G loss: 0.298400]\n",
      "epoch:26 step:24637 [D loss: 0.260177, acc.: 53.91%] [G loss: 0.300513]\n",
      "epoch:26 step:24638 [D loss: 0.260014, acc.: 55.47%] [G loss: 0.297298]\n",
      "epoch:26 step:24639 [D loss: 0.231967, acc.: 57.81%] [G loss: 0.311375]\n",
      "epoch:26 step:24640 [D loss: 0.265885, acc.: 46.09%] [G loss: 0.295514]\n",
      "epoch:26 step:24641 [D loss: 0.229471, acc.: 60.94%] [G loss: 0.306764]\n",
      "epoch:26 step:24642 [D loss: 0.234400, acc.: 58.59%] [G loss: 0.348792]\n",
      "epoch:26 step:24643 [D loss: 0.221189, acc.: 69.53%] [G loss: 0.310708]\n",
      "epoch:26 step:24644 [D loss: 0.245470, acc.: 54.69%] [G loss: 0.332007]\n",
      "epoch:26 step:24645 [D loss: 0.235687, acc.: 55.47%] [G loss: 0.275102]\n",
      "epoch:26 step:24646 [D loss: 0.242777, acc.: 54.69%] [G loss: 0.307109]\n",
      "epoch:26 step:24647 [D loss: 0.236157, acc.: 63.28%] [G loss: 0.327343]\n",
      "epoch:26 step:24648 [D loss: 0.239704, acc.: 57.03%] [G loss: 0.290541]\n",
      "epoch:26 step:24649 [D loss: 0.242255, acc.: 59.38%] [G loss: 0.296166]\n",
      "epoch:26 step:24650 [D loss: 0.243695, acc.: 54.69%] [G loss: 0.310879]\n",
      "epoch:26 step:24651 [D loss: 0.240043, acc.: 58.59%] [G loss: 0.326985]\n",
      "epoch:26 step:24652 [D loss: 0.232379, acc.: 56.25%] [G loss: 0.297189]\n",
      "epoch:26 step:24653 [D loss: 0.247237, acc.: 55.47%] [G loss: 0.308359]\n",
      "epoch:26 step:24654 [D loss: 0.236069, acc.: 57.81%] [G loss: 0.309700]\n",
      "epoch:26 step:24655 [D loss: 0.249656, acc.: 55.47%] [G loss: 0.305453]\n",
      "epoch:26 step:24656 [D loss: 0.257156, acc.: 53.12%] [G loss: 0.305039]\n",
      "epoch:26 step:24657 [D loss: 0.240187, acc.: 60.16%] [G loss: 0.282909]\n",
      "epoch:26 step:24658 [D loss: 0.219807, acc.: 60.94%] [G loss: 0.336306]\n",
      "epoch:26 step:24659 [D loss: 0.234016, acc.: 59.38%] [G loss: 0.327368]\n",
      "epoch:26 step:24660 [D loss: 0.229552, acc.: 60.94%] [G loss: 0.319379]\n",
      "epoch:26 step:24661 [D loss: 0.241267, acc.: 53.91%] [G loss: 0.321066]\n",
      "epoch:26 step:24662 [D loss: 0.242901, acc.: 56.25%] [G loss: 0.315900]\n",
      "epoch:26 step:24663 [D loss: 0.254575, acc.: 49.22%] [G loss: 0.324399]\n",
      "epoch:26 step:24664 [D loss: 0.237228, acc.: 55.47%] [G loss: 0.317408]\n",
      "epoch:26 step:24665 [D loss: 0.257667, acc.: 55.47%] [G loss: 0.295404]\n",
      "epoch:26 step:24666 [D loss: 0.235867, acc.: 58.59%] [G loss: 0.306503]\n",
      "epoch:26 step:24667 [D loss: 0.237340, acc.: 58.59%] [G loss: 0.306952]\n",
      "epoch:26 step:24668 [D loss: 0.253728, acc.: 52.34%] [G loss: 0.299297]\n",
      "epoch:26 step:24669 [D loss: 0.220329, acc.: 60.16%] [G loss: 0.314017]\n",
      "epoch:26 step:24670 [D loss: 0.238968, acc.: 63.28%] [G loss: 0.300728]\n",
      "epoch:26 step:24671 [D loss: 0.245933, acc.: 46.88%] [G loss: 0.291980]\n",
      "epoch:26 step:24672 [D loss: 0.232991, acc.: 59.38%] [G loss: 0.333546]\n",
      "epoch:26 step:24673 [D loss: 0.238459, acc.: 56.25%] [G loss: 0.281092]\n",
      "epoch:26 step:24674 [D loss: 0.257939, acc.: 56.25%] [G loss: 0.302296]\n",
      "epoch:26 step:24675 [D loss: 0.242091, acc.: 60.94%] [G loss: 0.301507]\n",
      "epoch:26 step:24676 [D loss: 0.234445, acc.: 58.59%] [G loss: 0.305549]\n",
      "epoch:26 step:24677 [D loss: 0.221689, acc.: 67.97%] [G loss: 0.321220]\n",
      "epoch:26 step:24678 [D loss: 0.257410, acc.: 46.88%] [G loss: 0.300682]\n",
      "epoch:26 step:24679 [D loss: 0.230255, acc.: 64.06%] [G loss: 0.273664]\n",
      "epoch:26 step:24680 [D loss: 0.246921, acc.: 53.91%] [G loss: 0.266093]\n",
      "epoch:26 step:24681 [D loss: 0.245748, acc.: 58.59%] [G loss: 0.281333]\n",
      "epoch:26 step:24682 [D loss: 0.249892, acc.: 50.00%] [G loss: 0.256635]\n",
      "epoch:26 step:24683 [D loss: 0.240174, acc.: 58.59%] [G loss: 0.300929]\n",
      "epoch:26 step:24684 [D loss: 0.243577, acc.: 57.81%] [G loss: 0.296108]\n",
      "epoch:26 step:24685 [D loss: 0.229915, acc.: 65.62%] [G loss: 0.284931]\n",
      "epoch:26 step:24686 [D loss: 0.240132, acc.: 57.03%] [G loss: 0.272249]\n",
      "epoch:26 step:24687 [D loss: 0.248055, acc.: 50.00%] [G loss: 0.307273]\n",
      "epoch:26 step:24688 [D loss: 0.234003, acc.: 59.38%] [G loss: 0.277640]\n",
      "epoch:26 step:24689 [D loss: 0.226860, acc.: 60.16%] [G loss: 0.345758]\n",
      "epoch:26 step:24690 [D loss: 0.234725, acc.: 62.50%] [G loss: 0.291545]\n",
      "epoch:26 step:24691 [D loss: 0.234307, acc.: 61.72%] [G loss: 0.286505]\n",
      "epoch:26 step:24692 [D loss: 0.241302, acc.: 61.72%] [G loss: 0.315026]\n",
      "epoch:26 step:24693 [D loss: 0.222169, acc.: 69.53%] [G loss: 0.298936]\n",
      "epoch:26 step:24694 [D loss: 0.232776, acc.: 59.38%] [G loss: 0.281954]\n",
      "epoch:26 step:24695 [D loss: 0.255781, acc.: 53.91%] [G loss: 0.290120]\n",
      "epoch:26 step:24696 [D loss: 0.238419, acc.: 55.47%] [G loss: 0.332088]\n",
      "epoch:26 step:24697 [D loss: 0.230335, acc.: 59.38%] [G loss: 0.282387]\n",
      "epoch:26 step:24698 [D loss: 0.225109, acc.: 65.62%] [G loss: 0.315360]\n",
      "epoch:26 step:24699 [D loss: 0.247855, acc.: 53.91%] [G loss: 0.308692]\n",
      "epoch:26 step:24700 [D loss: 0.243787, acc.: 54.69%] [G loss: 0.300520]\n",
      "epoch:26 step:24701 [D loss: 0.246507, acc.: 57.81%] [G loss: 0.277746]\n",
      "epoch:26 step:24702 [D loss: 0.224140, acc.: 60.94%] [G loss: 0.298288]\n",
      "epoch:26 step:24703 [D loss: 0.245812, acc.: 58.59%] [G loss: 0.291913]\n",
      "epoch:26 step:24704 [D loss: 0.232565, acc.: 60.16%] [G loss: 0.288765]\n",
      "epoch:26 step:24705 [D loss: 0.247442, acc.: 56.25%] [G loss: 0.304279]\n",
      "epoch:26 step:24706 [D loss: 0.239393, acc.: 56.25%] [G loss: 0.281251]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:26 step:24707 [D loss: 0.218415, acc.: 69.53%] [G loss: 0.301861]\n",
      "epoch:26 step:24708 [D loss: 0.235575, acc.: 60.94%] [G loss: 0.290578]\n",
      "epoch:26 step:24709 [D loss: 0.224075, acc.: 64.06%] [G loss: 0.294571]\n",
      "epoch:26 step:24710 [D loss: 0.255756, acc.: 50.78%] [G loss: 0.281122]\n",
      "epoch:26 step:24711 [D loss: 0.234745, acc.: 57.81%] [G loss: 0.316786]\n",
      "epoch:26 step:24712 [D loss: 0.247126, acc.: 57.03%] [G loss: 0.276119]\n",
      "epoch:26 step:24713 [D loss: 0.232652, acc.: 60.16%] [G loss: 0.266464]\n",
      "epoch:26 step:24714 [D loss: 0.249918, acc.: 56.25%] [G loss: 0.293199]\n",
      "epoch:26 step:24715 [D loss: 0.241898, acc.: 56.25%] [G loss: 0.286223]\n",
      "epoch:26 step:24716 [D loss: 0.251823, acc.: 57.03%] [G loss: 0.290630]\n",
      "epoch:26 step:24717 [D loss: 0.240210, acc.: 57.81%] [G loss: 0.284792]\n",
      "epoch:26 step:24718 [D loss: 0.224210, acc.: 61.72%] [G loss: 0.274051]\n",
      "epoch:26 step:24719 [D loss: 0.245853, acc.: 52.34%] [G loss: 0.324471]\n",
      "epoch:26 step:24720 [D loss: 0.241488, acc.: 57.81%] [G loss: 0.303724]\n",
      "epoch:26 step:24721 [D loss: 0.237051, acc.: 53.12%] [G loss: 0.296940]\n",
      "epoch:26 step:24722 [D loss: 0.225020, acc.: 58.59%] [G loss: 0.278954]\n",
      "epoch:26 step:24723 [D loss: 0.238261, acc.: 57.03%] [G loss: 0.305294]\n",
      "epoch:26 step:24724 [D loss: 0.245308, acc.: 57.03%] [G loss: 0.315726]\n",
      "epoch:26 step:24725 [D loss: 0.245483, acc.: 54.69%] [G loss: 0.346226]\n",
      "epoch:26 step:24726 [D loss: 0.235368, acc.: 59.38%] [G loss: 0.320087]\n",
      "epoch:26 step:24727 [D loss: 0.244131, acc.: 55.47%] [G loss: 0.321208]\n",
      "epoch:26 step:24728 [D loss: 0.245447, acc.: 57.03%] [G loss: 0.313387]\n",
      "epoch:26 step:24729 [D loss: 0.230246, acc.: 63.28%] [G loss: 0.318824]\n",
      "epoch:26 step:24730 [D loss: 0.235980, acc.: 58.59%] [G loss: 0.315102]\n",
      "epoch:26 step:24731 [D loss: 0.244407, acc.: 60.94%] [G loss: 0.311107]\n",
      "epoch:26 step:24732 [D loss: 0.246288, acc.: 57.81%] [G loss: 0.274899]\n",
      "epoch:26 step:24733 [D loss: 0.233510, acc.: 64.06%] [G loss: 0.268029]\n",
      "epoch:26 step:24734 [D loss: 0.259174, acc.: 55.47%] [G loss: 0.259598]\n",
      "epoch:26 step:24735 [D loss: 0.235169, acc.: 60.16%] [G loss: 0.301715]\n",
      "epoch:26 step:24736 [D loss: 0.248917, acc.: 51.56%] [G loss: 0.292257]\n",
      "epoch:26 step:24737 [D loss: 0.243341, acc.: 57.03%] [G loss: 0.307311]\n",
      "epoch:26 step:24738 [D loss: 0.228987, acc.: 59.38%] [G loss: 0.288578]\n",
      "epoch:26 step:24739 [D loss: 0.250924, acc.: 57.03%] [G loss: 0.309992]\n",
      "epoch:26 step:24740 [D loss: 0.253792, acc.: 50.00%] [G loss: 0.320714]\n",
      "epoch:26 step:24741 [D loss: 0.245238, acc.: 56.25%] [G loss: 0.311736]\n",
      "epoch:26 step:24742 [D loss: 0.229300, acc.: 64.06%] [G loss: 0.316710]\n",
      "epoch:26 step:24743 [D loss: 0.240285, acc.: 53.12%] [G loss: 0.311418]\n",
      "epoch:26 step:24744 [D loss: 0.248600, acc.: 56.25%] [G loss: 0.314347]\n",
      "epoch:26 step:24745 [D loss: 0.238292, acc.: 59.38%] [G loss: 0.291464]\n",
      "epoch:26 step:24746 [D loss: 0.235548, acc.: 58.59%] [G loss: 0.303275]\n",
      "epoch:26 step:24747 [D loss: 0.249333, acc.: 58.59%] [G loss: 0.311159]\n",
      "epoch:26 step:24748 [D loss: 0.226207, acc.: 67.19%] [G loss: 0.302922]\n",
      "epoch:26 step:24749 [D loss: 0.259949, acc.: 53.12%] [G loss: 0.307613]\n",
      "epoch:26 step:24750 [D loss: 0.233502, acc.: 59.38%] [G loss: 0.312017]\n",
      "epoch:26 step:24751 [D loss: 0.240860, acc.: 58.59%] [G loss: 0.312634]\n",
      "epoch:26 step:24752 [D loss: 0.249534, acc.: 58.59%] [G loss: 0.294225]\n",
      "epoch:26 step:24753 [D loss: 0.248399, acc.: 57.03%] [G loss: 0.331685]\n",
      "epoch:26 step:24754 [D loss: 0.241533, acc.: 60.16%] [G loss: 0.300666]\n",
      "epoch:26 step:24755 [D loss: 0.245517, acc.: 60.16%] [G loss: 0.294461]\n",
      "epoch:26 step:24756 [D loss: 0.223823, acc.: 67.97%] [G loss: 0.292449]\n",
      "epoch:26 step:24757 [D loss: 0.229049, acc.: 61.72%] [G loss: 0.290994]\n",
      "epoch:26 step:24758 [D loss: 0.230720, acc.: 60.94%] [G loss: 0.289356]\n",
      "epoch:26 step:24759 [D loss: 0.242643, acc.: 54.69%] [G loss: 0.284750]\n",
      "epoch:26 step:24760 [D loss: 0.253843, acc.: 48.44%] [G loss: 0.285277]\n",
      "epoch:26 step:24761 [D loss: 0.229262, acc.: 62.50%] [G loss: 0.277416]\n",
      "epoch:26 step:24762 [D loss: 0.232514, acc.: 56.25%] [G loss: 0.317268]\n",
      "epoch:26 step:24763 [D loss: 0.231030, acc.: 58.59%] [G loss: 0.308586]\n",
      "epoch:26 step:24764 [D loss: 0.257162, acc.: 53.12%] [G loss: 0.285975]\n",
      "epoch:26 step:24765 [D loss: 0.232184, acc.: 59.38%] [G loss: 0.320569]\n",
      "epoch:26 step:24766 [D loss: 0.246282, acc.: 56.25%] [G loss: 0.285328]\n",
      "epoch:26 step:24767 [D loss: 0.235866, acc.: 56.25%] [G loss: 0.323139]\n",
      "epoch:26 step:24768 [D loss: 0.233849, acc.: 59.38%] [G loss: 0.333999]\n",
      "epoch:26 step:24769 [D loss: 0.235144, acc.: 63.28%] [G loss: 0.283654]\n",
      "epoch:26 step:24770 [D loss: 0.230568, acc.: 61.72%] [G loss: 0.296957]\n",
      "epoch:26 step:24771 [D loss: 0.229602, acc.: 58.59%] [G loss: 0.305298]\n",
      "epoch:26 step:24772 [D loss: 0.238821, acc.: 53.12%] [G loss: 0.309858]\n",
      "epoch:26 step:24773 [D loss: 0.234507, acc.: 57.81%] [G loss: 0.302987]\n",
      "epoch:26 step:24774 [D loss: 0.239092, acc.: 57.03%] [G loss: 0.304219]\n",
      "epoch:26 step:24775 [D loss: 0.236390, acc.: 59.38%] [G loss: 0.276565]\n",
      "epoch:26 step:24776 [D loss: 0.224325, acc.: 69.53%] [G loss: 0.314797]\n",
      "epoch:26 step:24777 [D loss: 0.241333, acc.: 58.59%] [G loss: 0.308009]\n",
      "epoch:26 step:24778 [D loss: 0.225765, acc.: 62.50%] [G loss: 0.300002]\n",
      "epoch:26 step:24779 [D loss: 0.244764, acc.: 58.59%] [G loss: 0.310251]\n",
      "epoch:26 step:24780 [D loss: 0.240517, acc.: 58.59%] [G loss: 0.296901]\n",
      "epoch:26 step:24781 [D loss: 0.240470, acc.: 58.59%] [G loss: 0.283768]\n",
      "epoch:26 step:24782 [D loss: 0.233255, acc.: 57.03%] [G loss: 0.299568]\n",
      "epoch:26 step:24783 [D loss: 0.247663, acc.: 57.81%] [G loss: 0.277418]\n",
      "epoch:26 step:24784 [D loss: 0.236600, acc.: 57.81%] [G loss: 0.315226]\n",
      "epoch:26 step:24785 [D loss: 0.226104, acc.: 67.19%] [G loss: 0.294228]\n",
      "epoch:26 step:24786 [D loss: 0.240465, acc.: 57.81%] [G loss: 0.293141]\n",
      "epoch:26 step:24787 [D loss: 0.248131, acc.: 50.00%] [G loss: 0.321109]\n",
      "epoch:26 step:24788 [D loss: 0.238717, acc.: 64.84%] [G loss: 0.329312]\n",
      "epoch:26 step:24789 [D loss: 0.251207, acc.: 54.69%] [G loss: 0.310551]\n",
      "epoch:26 step:24790 [D loss: 0.245516, acc.: 53.91%] [G loss: 0.278820]\n",
      "epoch:26 step:24791 [D loss: 0.273089, acc.: 42.19%] [G loss: 0.302844]\n",
      "epoch:26 step:24792 [D loss: 0.249656, acc.: 52.34%] [G loss: 0.292022]\n",
      "epoch:26 step:24793 [D loss: 0.239245, acc.: 53.12%] [G loss: 0.293905]\n",
      "epoch:26 step:24794 [D loss: 0.243908, acc.: 54.69%] [G loss: 0.304211]\n",
      "epoch:26 step:24795 [D loss: 0.236748, acc.: 57.03%] [G loss: 0.282022]\n",
      "epoch:26 step:24796 [D loss: 0.241809, acc.: 57.81%] [G loss: 0.299007]\n",
      "epoch:26 step:24797 [D loss: 0.240850, acc.: 56.25%] [G loss: 0.271997]\n",
      "epoch:26 step:24798 [D loss: 0.234801, acc.: 58.59%] [G loss: 0.291288]\n",
      "epoch:26 step:24799 [D loss: 0.265412, acc.: 53.12%] [G loss: 0.266595]\n",
      "epoch:26 step:24800 [D loss: 0.241962, acc.: 57.81%] [G loss: 0.326008]\n",
      "epoch:26 step:24801 [D loss: 0.235804, acc.: 56.25%] [G loss: 0.280317]\n",
      "epoch:26 step:24802 [D loss: 0.254787, acc.: 58.59%] [G loss: 0.293607]\n",
      "epoch:26 step:24803 [D loss: 0.239109, acc.: 59.38%] [G loss: 0.308514]\n",
      "epoch:26 step:24804 [D loss: 0.238617, acc.: 58.59%] [G loss: 0.297534]\n",
      "epoch:26 step:24805 [D loss: 0.224806, acc.: 67.97%] [G loss: 0.333675]\n",
      "epoch:26 step:24806 [D loss: 0.243499, acc.: 54.69%] [G loss: 0.295570]\n",
      "epoch:26 step:24807 [D loss: 0.230192, acc.: 64.06%] [G loss: 0.291005]\n",
      "epoch:26 step:24808 [D loss: 0.233536, acc.: 59.38%] [G loss: 0.317878]\n",
      "epoch:26 step:24809 [D loss: 0.244059, acc.: 63.28%] [G loss: 0.325628]\n",
      "epoch:26 step:24810 [D loss: 0.246718, acc.: 57.81%] [G loss: 0.285819]\n",
      "epoch:26 step:24811 [D loss: 0.230618, acc.: 60.16%] [G loss: 0.303085]\n",
      "epoch:26 step:24812 [D loss: 0.253168, acc.: 55.47%] [G loss: 0.307988]\n",
      "epoch:26 step:24813 [D loss: 0.235769, acc.: 60.16%] [G loss: 0.301257]\n",
      "epoch:26 step:24814 [D loss: 0.272737, acc.: 45.31%] [G loss: 0.279622]\n",
      "epoch:26 step:24815 [D loss: 0.239392, acc.: 60.94%] [G loss: 0.300973]\n",
      "epoch:26 step:24816 [D loss: 0.224466, acc.: 69.53%] [G loss: 0.279287]\n",
      "epoch:26 step:24817 [D loss: 0.235448, acc.: 61.72%] [G loss: 0.307044]\n",
      "epoch:26 step:24818 [D loss: 0.239510, acc.: 53.12%] [G loss: 0.307140]\n",
      "epoch:26 step:24819 [D loss: 0.238231, acc.: 56.25%] [G loss: 0.301807]\n",
      "epoch:26 step:24820 [D loss: 0.243174, acc.: 56.25%] [G loss: 0.320124]\n",
      "epoch:26 step:24821 [D loss: 0.229069, acc.: 62.50%] [G loss: 0.306826]\n",
      "epoch:26 step:24822 [D loss: 0.241850, acc.: 55.47%] [G loss: 0.298794]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:26 step:24823 [D loss: 0.245125, acc.: 54.69%] [G loss: 0.281802]\n",
      "epoch:26 step:24824 [D loss: 0.236584, acc.: 61.72%] [G loss: 0.266677]\n",
      "epoch:26 step:24825 [D loss: 0.243830, acc.: 53.12%] [G loss: 0.297969]\n",
      "epoch:26 step:24826 [D loss: 0.232812, acc.: 57.03%] [G loss: 0.303022]\n",
      "epoch:26 step:24827 [D loss: 0.227765, acc.: 67.19%] [G loss: 0.293959]\n",
      "epoch:26 step:24828 [D loss: 0.224334, acc.: 63.28%] [G loss: 0.298404]\n",
      "epoch:26 step:24829 [D loss: 0.228757, acc.: 63.28%] [G loss: 0.293277]\n",
      "epoch:26 step:24830 [D loss: 0.239728, acc.: 54.69%] [G loss: 0.297383]\n",
      "epoch:26 step:24831 [D loss: 0.244337, acc.: 55.47%] [G loss: 0.283499]\n",
      "epoch:26 step:24832 [D loss: 0.244627, acc.: 54.69%] [G loss: 0.296786]\n",
      "epoch:26 step:24833 [D loss: 0.231991, acc.: 60.16%] [G loss: 0.308552]\n",
      "epoch:26 step:24834 [D loss: 0.236172, acc.: 60.16%] [G loss: 0.270817]\n",
      "epoch:26 step:24835 [D loss: 0.250053, acc.: 53.91%] [G loss: 0.298483]\n",
      "epoch:26 step:24836 [D loss: 0.238373, acc.: 55.47%] [G loss: 0.313875]\n",
      "epoch:26 step:24837 [D loss: 0.231876, acc.: 57.81%] [G loss: 0.308722]\n",
      "epoch:26 step:24838 [D loss: 0.228971, acc.: 62.50%] [G loss: 0.285502]\n",
      "epoch:26 step:24839 [D loss: 0.235928, acc.: 59.38%] [G loss: 0.268221]\n",
      "epoch:26 step:24840 [D loss: 0.238004, acc.: 58.59%] [G loss: 0.299955]\n",
      "epoch:26 step:24841 [D loss: 0.239184, acc.: 54.69%] [G loss: 0.293207]\n",
      "epoch:26 step:24842 [D loss: 0.244163, acc.: 53.91%] [G loss: 0.314520]\n",
      "epoch:26 step:24843 [D loss: 0.235815, acc.: 61.72%] [G loss: 0.294087]\n",
      "epoch:26 step:24844 [D loss: 0.239315, acc.: 57.03%] [G loss: 0.275558]\n",
      "epoch:26 step:24845 [D loss: 0.245013, acc.: 58.59%] [G loss: 0.288669]\n",
      "epoch:26 step:24846 [D loss: 0.226475, acc.: 61.72%] [G loss: 0.306789]\n",
      "epoch:26 step:24847 [D loss: 0.251774, acc.: 59.38%] [G loss: 0.306781]\n",
      "epoch:26 step:24848 [D loss: 0.223946, acc.: 62.50%] [G loss: 0.295686]\n",
      "epoch:26 step:24849 [D loss: 0.241892, acc.: 62.50%] [G loss: 0.302640]\n",
      "epoch:26 step:24850 [D loss: 0.222567, acc.: 67.97%] [G loss: 0.304360]\n",
      "epoch:26 step:24851 [D loss: 0.233477, acc.: 57.81%] [G loss: 0.321368]\n",
      "epoch:26 step:24852 [D loss: 0.246399, acc.: 57.03%] [G loss: 0.288905]\n",
      "epoch:26 step:24853 [D loss: 0.237011, acc.: 59.38%] [G loss: 0.307971]\n",
      "epoch:26 step:24854 [D loss: 0.250995, acc.: 53.91%] [G loss: 0.303040]\n",
      "epoch:26 step:24855 [D loss: 0.256677, acc.: 53.12%] [G loss: 0.313891]\n",
      "epoch:26 step:24856 [D loss: 0.218994, acc.: 63.28%] [G loss: 0.294817]\n",
      "epoch:26 step:24857 [D loss: 0.240244, acc.: 55.47%] [G loss: 0.299626]\n",
      "epoch:26 step:24858 [D loss: 0.242569, acc.: 59.38%] [G loss: 0.298973]\n",
      "epoch:26 step:24859 [D loss: 0.249257, acc.: 53.91%] [G loss: 0.271783]\n",
      "epoch:26 step:24860 [D loss: 0.241097, acc.: 60.94%] [G loss: 0.315460]\n",
      "epoch:26 step:24861 [D loss: 0.239084, acc.: 60.16%] [G loss: 0.320304]\n",
      "epoch:26 step:24862 [D loss: 0.248001, acc.: 50.00%] [G loss: 0.298452]\n",
      "epoch:26 step:24863 [D loss: 0.261503, acc.: 53.12%] [G loss: 0.284888]\n",
      "epoch:26 step:24864 [D loss: 0.239441, acc.: 57.81%] [G loss: 0.312166]\n",
      "epoch:26 step:24865 [D loss: 0.229810, acc.: 60.16%] [G loss: 0.292367]\n",
      "epoch:26 step:24866 [D loss: 0.247853, acc.: 55.47%] [G loss: 0.297935]\n",
      "epoch:26 step:24867 [D loss: 0.243496, acc.: 52.34%] [G loss: 0.320389]\n",
      "epoch:26 step:24868 [D loss: 0.251343, acc.: 53.12%] [G loss: 0.287619]\n",
      "epoch:26 step:24869 [D loss: 0.238283, acc.: 61.72%] [G loss: 0.311027]\n",
      "epoch:26 step:24870 [D loss: 0.241633, acc.: 57.81%] [G loss: 0.288129]\n",
      "epoch:26 step:24871 [D loss: 0.238642, acc.: 58.59%] [G loss: 0.312996]\n",
      "epoch:26 step:24872 [D loss: 0.242245, acc.: 55.47%] [G loss: 0.287550]\n",
      "epoch:26 step:24873 [D loss: 0.240642, acc.: 58.59%] [G loss: 0.319591]\n",
      "epoch:26 step:24874 [D loss: 0.210838, acc.: 71.88%] [G loss: 0.321421]\n",
      "epoch:26 step:24875 [D loss: 0.238015, acc.: 60.16%] [G loss: 0.316595]\n",
      "epoch:26 step:24876 [D loss: 0.249488, acc.: 53.12%] [G loss: 0.315622]\n",
      "epoch:26 step:24877 [D loss: 0.225979, acc.: 61.72%] [G loss: 0.286984]\n",
      "epoch:26 step:24878 [D loss: 0.241341, acc.: 59.38%] [G loss: 0.287202]\n",
      "epoch:26 step:24879 [D loss: 0.235080, acc.: 61.72%] [G loss: 0.295904]\n",
      "epoch:26 step:24880 [D loss: 0.235183, acc.: 57.81%] [G loss: 0.307923]\n",
      "epoch:26 step:24881 [D loss: 0.238240, acc.: 53.91%] [G loss: 0.322174]\n",
      "epoch:26 step:24882 [D loss: 0.246922, acc.: 56.25%] [G loss: 0.321365]\n",
      "epoch:26 step:24883 [D loss: 0.248316, acc.: 53.12%] [G loss: 0.318535]\n",
      "epoch:26 step:24884 [D loss: 0.242916, acc.: 57.03%] [G loss: 0.295276]\n",
      "epoch:26 step:24885 [D loss: 0.229272, acc.: 57.81%] [G loss: 0.317386]\n",
      "epoch:26 step:24886 [D loss: 0.221586, acc.: 65.62%] [G loss: 0.307305]\n",
      "epoch:26 step:24887 [D loss: 0.240547, acc.: 61.72%] [G loss: 0.328936]\n",
      "epoch:26 step:24888 [D loss: 0.238721, acc.: 59.38%] [G loss: 0.293395]\n",
      "epoch:26 step:24889 [D loss: 0.240885, acc.: 54.69%] [G loss: 0.305150]\n",
      "epoch:26 step:24890 [D loss: 0.241873, acc.: 58.59%] [G loss: 0.296354]\n",
      "epoch:26 step:24891 [D loss: 0.230483, acc.: 60.16%] [G loss: 0.316123]\n",
      "epoch:26 step:24892 [D loss: 0.244721, acc.: 57.81%] [G loss: 0.287600]\n",
      "epoch:26 step:24893 [D loss: 0.229657, acc.: 58.59%] [G loss: 0.323124]\n",
      "epoch:26 step:24894 [D loss: 0.252068, acc.: 56.25%] [G loss: 0.305014]\n",
      "epoch:26 step:24895 [D loss: 0.237521, acc.: 59.38%] [G loss: 0.307929]\n",
      "epoch:26 step:24896 [D loss: 0.247986, acc.: 57.03%] [G loss: 0.302391]\n",
      "epoch:26 step:24897 [D loss: 0.227302, acc.: 65.62%] [G loss: 0.330105]\n",
      "epoch:26 step:24898 [D loss: 0.258387, acc.: 53.12%] [G loss: 0.291812]\n",
      "epoch:26 step:24899 [D loss: 0.226631, acc.: 64.84%] [G loss: 0.285503]\n",
      "epoch:26 step:24900 [D loss: 0.262936, acc.: 46.88%] [G loss: 0.288354]\n",
      "epoch:26 step:24901 [D loss: 0.245808, acc.: 60.16%] [G loss: 0.323465]\n",
      "epoch:26 step:24902 [D loss: 0.235587, acc.: 60.16%] [G loss: 0.331345]\n",
      "epoch:26 step:24903 [D loss: 0.229314, acc.: 60.16%] [G loss: 0.306387]\n",
      "epoch:26 step:24904 [D loss: 0.235614, acc.: 60.16%] [G loss: 0.321716]\n",
      "epoch:26 step:24905 [D loss: 0.224334, acc.: 68.75%] [G loss: 0.283125]\n",
      "epoch:26 step:24906 [D loss: 0.242921, acc.: 57.81%] [G loss: 0.294803]\n",
      "epoch:26 step:24907 [D loss: 0.237418, acc.: 63.28%] [G loss: 0.302531]\n",
      "epoch:26 step:24908 [D loss: 0.248227, acc.: 53.12%] [G loss: 0.281957]\n",
      "epoch:26 step:24909 [D loss: 0.237700, acc.: 58.59%] [G loss: 0.305747]\n",
      "epoch:26 step:24910 [D loss: 0.248249, acc.: 57.81%] [G loss: 0.305651]\n",
      "epoch:26 step:24911 [D loss: 0.243629, acc.: 55.47%] [G loss: 0.308503]\n",
      "epoch:26 step:24912 [D loss: 0.248662, acc.: 55.47%] [G loss: 0.299465]\n",
      "epoch:26 step:24913 [D loss: 0.244512, acc.: 53.91%] [G loss: 0.278449]\n",
      "epoch:26 step:24914 [D loss: 0.245947, acc.: 57.81%] [G loss: 0.292163]\n",
      "epoch:26 step:24915 [D loss: 0.244393, acc.: 55.47%] [G loss: 0.289021]\n",
      "epoch:26 step:24916 [D loss: 0.233133, acc.: 57.81%] [G loss: 0.315173]\n",
      "epoch:26 step:24917 [D loss: 0.251735, acc.: 55.47%] [G loss: 0.325825]\n",
      "epoch:26 step:24918 [D loss: 0.228713, acc.: 63.28%] [G loss: 0.319155]\n",
      "epoch:26 step:24919 [D loss: 0.232878, acc.: 57.81%] [G loss: 0.314665]\n",
      "epoch:26 step:24920 [D loss: 0.241518, acc.: 56.25%] [G loss: 0.278930]\n",
      "epoch:26 step:24921 [D loss: 0.253048, acc.: 58.59%] [G loss: 0.269184]\n",
      "epoch:26 step:24922 [D loss: 0.244850, acc.: 58.59%] [G loss: 0.299163]\n",
      "epoch:26 step:24923 [D loss: 0.238220, acc.: 60.94%] [G loss: 0.298112]\n",
      "epoch:26 step:24924 [D loss: 0.241571, acc.: 53.91%] [G loss: 0.296725]\n",
      "epoch:26 step:24925 [D loss: 0.237899, acc.: 62.50%] [G loss: 0.315714]\n",
      "epoch:26 step:24926 [D loss: 0.227225, acc.: 64.06%] [G loss: 0.257276]\n",
      "epoch:26 step:24927 [D loss: 0.236241, acc.: 58.59%] [G loss: 0.272818]\n",
      "epoch:26 step:24928 [D loss: 0.245352, acc.: 57.81%] [G loss: 0.293226]\n",
      "epoch:26 step:24929 [D loss: 0.233301, acc.: 61.72%] [G loss: 0.316527]\n",
      "epoch:26 step:24930 [D loss: 0.243486, acc.: 56.25%] [G loss: 0.283076]\n",
      "epoch:26 step:24931 [D loss: 0.257599, acc.: 53.91%] [G loss: 0.292779]\n",
      "epoch:26 step:24932 [D loss: 0.259089, acc.: 56.25%] [G loss: 0.311851]\n",
      "epoch:26 step:24933 [D loss: 0.240955, acc.: 64.06%] [G loss: 0.296345]\n",
      "epoch:26 step:24934 [D loss: 0.233624, acc.: 57.81%] [G loss: 0.304960]\n",
      "epoch:26 step:24935 [D loss: 0.249532, acc.: 53.91%] [G loss: 0.273828]\n",
      "epoch:26 step:24936 [D loss: 0.240094, acc.: 60.94%] [G loss: 0.301198]\n",
      "epoch:26 step:24937 [D loss: 0.250106, acc.: 55.47%] [G loss: 0.323303]\n",
      "epoch:26 step:24938 [D loss: 0.208042, acc.: 67.19%] [G loss: 0.310304]\n",
      "epoch:26 step:24939 [D loss: 0.238536, acc.: 55.47%] [G loss: 0.294687]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:26 step:24940 [D loss: 0.238339, acc.: 62.50%] [G loss: 0.311980]\n",
      "epoch:26 step:24941 [D loss: 0.250115, acc.: 55.47%] [G loss: 0.312771]\n",
      "epoch:26 step:24942 [D loss: 0.244396, acc.: 59.38%] [G loss: 0.315382]\n",
      "epoch:26 step:24943 [D loss: 0.232869, acc.: 62.50%] [G loss: 0.334753]\n",
      "epoch:26 step:24944 [D loss: 0.239942, acc.: 57.03%] [G loss: 0.296106]\n",
      "epoch:26 step:24945 [D loss: 0.239421, acc.: 57.81%] [G loss: 0.318785]\n",
      "epoch:26 step:24946 [D loss: 0.237753, acc.: 60.94%] [G loss: 0.317637]\n",
      "epoch:26 step:24947 [D loss: 0.244949, acc.: 54.69%] [G loss: 0.296897]\n",
      "epoch:26 step:24948 [D loss: 0.227292, acc.: 64.84%] [G loss: 0.310015]\n",
      "epoch:26 step:24949 [D loss: 0.226957, acc.: 63.28%] [G loss: 0.319540]\n",
      "epoch:26 step:24950 [D loss: 0.244874, acc.: 55.47%] [G loss: 0.305830]\n",
      "epoch:26 step:24951 [D loss: 0.240427, acc.: 57.81%] [G loss: 0.320821]\n",
      "epoch:26 step:24952 [D loss: 0.229341, acc.: 59.38%] [G loss: 0.285048]\n",
      "epoch:26 step:24953 [D loss: 0.239132, acc.: 57.03%] [G loss: 0.302355]\n",
      "epoch:26 step:24954 [D loss: 0.243660, acc.: 51.56%] [G loss: 0.336566]\n",
      "epoch:26 step:24955 [D loss: 0.241611, acc.: 61.72%] [G loss: 0.302227]\n",
      "epoch:26 step:24956 [D loss: 0.243231, acc.: 59.38%] [G loss: 0.287898]\n",
      "epoch:26 step:24957 [D loss: 0.249234, acc.: 56.25%] [G loss: 0.262605]\n",
      "epoch:26 step:24958 [D loss: 0.228741, acc.: 60.16%] [G loss: 0.301204]\n",
      "epoch:26 step:24959 [D loss: 0.225359, acc.: 63.28%] [G loss: 0.287901]\n",
      "epoch:26 step:24960 [D loss: 0.244472, acc.: 59.38%] [G loss: 0.284250]\n",
      "epoch:26 step:24961 [D loss: 0.239677, acc.: 63.28%] [G loss: 0.283823]\n",
      "epoch:26 step:24962 [D loss: 0.246212, acc.: 56.25%] [G loss: 0.323529]\n",
      "epoch:26 step:24963 [D loss: 0.246236, acc.: 53.12%] [G loss: 0.287246]\n",
      "epoch:26 step:24964 [D loss: 0.223571, acc.: 67.19%] [G loss: 0.282499]\n",
      "epoch:26 step:24965 [D loss: 0.242050, acc.: 57.03%] [G loss: 0.303637]\n",
      "epoch:26 step:24966 [D loss: 0.242036, acc.: 59.38%] [G loss: 0.309281]\n",
      "epoch:26 step:24967 [D loss: 0.254296, acc.: 50.78%] [G loss: 0.296544]\n",
      "epoch:26 step:24968 [D loss: 0.247990, acc.: 56.25%] [G loss: 0.300809]\n",
      "epoch:26 step:24969 [D loss: 0.233279, acc.: 60.94%] [G loss: 0.269207]\n",
      "epoch:26 step:24970 [D loss: 0.227653, acc.: 60.16%] [G loss: 0.337314]\n",
      "epoch:26 step:24971 [D loss: 0.238654, acc.: 59.38%] [G loss: 0.303051]\n",
      "epoch:26 step:24972 [D loss: 0.237715, acc.: 61.72%] [G loss: 0.281653]\n",
      "epoch:26 step:24973 [D loss: 0.263009, acc.: 51.56%] [G loss: 0.322378]\n",
      "epoch:26 step:24974 [D loss: 0.239416, acc.: 53.91%] [G loss: 0.294616]\n",
      "epoch:26 step:24975 [D loss: 0.232191, acc.: 53.91%] [G loss: 0.297661]\n",
      "epoch:26 step:24976 [D loss: 0.237083, acc.: 58.59%] [G loss: 0.316009]\n",
      "epoch:26 step:24977 [D loss: 0.235137, acc.: 55.47%] [G loss: 0.283090]\n",
      "epoch:26 step:24978 [D loss: 0.231195, acc.: 60.94%] [G loss: 0.279680]\n",
      "epoch:26 step:24979 [D loss: 0.225485, acc.: 63.28%] [G loss: 0.289546]\n",
      "epoch:26 step:24980 [D loss: 0.246368, acc.: 54.69%] [G loss: 0.284589]\n",
      "epoch:26 step:24981 [D loss: 0.257572, acc.: 52.34%] [G loss: 0.320096]\n",
      "epoch:26 step:24982 [D loss: 0.247363, acc.: 57.03%] [G loss: 0.287097]\n",
      "epoch:26 step:24983 [D loss: 0.238629, acc.: 55.47%] [G loss: 0.303161]\n",
      "epoch:26 step:24984 [D loss: 0.239055, acc.: 58.59%] [G loss: 0.317675]\n",
      "epoch:26 step:24985 [D loss: 0.235661, acc.: 57.03%] [G loss: 0.344939]\n",
      "epoch:26 step:24986 [D loss: 0.254867, acc.: 55.47%] [G loss: 0.301791]\n",
      "epoch:26 step:24987 [D loss: 0.233521, acc.: 63.28%] [G loss: 0.312001]\n",
      "epoch:26 step:24988 [D loss: 0.251360, acc.: 54.69%] [G loss: 0.303401]\n",
      "epoch:26 step:24989 [D loss: 0.228059, acc.: 58.59%] [G loss: 0.299410]\n",
      "epoch:26 step:24990 [D loss: 0.266362, acc.: 48.44%] [G loss: 0.288073]\n",
      "epoch:26 step:24991 [D loss: 0.260897, acc.: 50.00%] [G loss: 0.274448]\n",
      "epoch:26 step:24992 [D loss: 0.235510, acc.: 53.91%] [G loss: 0.273112]\n",
      "epoch:26 step:24993 [D loss: 0.234836, acc.: 56.25%] [G loss: 0.290555]\n",
      "epoch:26 step:24994 [D loss: 0.232885, acc.: 53.91%] [G loss: 0.288056]\n",
      "epoch:26 step:24995 [D loss: 0.233240, acc.: 60.16%] [G loss: 0.286999]\n",
      "epoch:26 step:24996 [D loss: 0.244952, acc.: 53.12%] [G loss: 0.279106]\n",
      "epoch:26 step:24997 [D loss: 0.253997, acc.: 60.16%] [G loss: 0.306017]\n",
      "epoch:26 step:24998 [D loss: 0.252715, acc.: 55.47%] [G loss: 0.332975]\n",
      "epoch:26 step:24999 [D loss: 0.224389, acc.: 62.50%] [G loss: 0.311852]\n",
      "epoch:26 step:25000 [D loss: 0.254610, acc.: 53.12%] [G loss: 0.322999]\n",
      "epoch:26 step:25001 [D loss: 0.240588, acc.: 54.69%] [G loss: 0.304776]\n",
      "epoch:26 step:25002 [D loss: 0.239478, acc.: 59.38%] [G loss: 0.291271]\n",
      "epoch:26 step:25003 [D loss: 0.227260, acc.: 61.72%] [G loss: 0.318349]\n",
      "epoch:26 step:25004 [D loss: 0.262841, acc.: 46.88%] [G loss: 0.296113]\n",
      "epoch:26 step:25005 [D loss: 0.258010, acc.: 51.56%] [G loss: 0.287496]\n",
      "epoch:26 step:25006 [D loss: 0.230690, acc.: 54.69%] [G loss: 0.305245]\n",
      "epoch:26 step:25007 [D loss: 0.238721, acc.: 58.59%] [G loss: 0.303211]\n",
      "epoch:26 step:25008 [D loss: 0.243549, acc.: 56.25%] [G loss: 0.303654]\n",
      "epoch:26 step:25009 [D loss: 0.242755, acc.: 57.03%] [G loss: 0.309201]\n",
      "epoch:26 step:25010 [D loss: 0.245554, acc.: 57.03%] [G loss: 0.289434]\n",
      "epoch:26 step:25011 [D loss: 0.233531, acc.: 60.16%] [G loss: 0.319693]\n",
      "epoch:26 step:25012 [D loss: 0.237790, acc.: 63.28%] [G loss: 0.321787]\n",
      "epoch:26 step:25013 [D loss: 0.234418, acc.: 57.81%] [G loss: 0.309657]\n",
      "epoch:26 step:25014 [D loss: 0.224369, acc.: 65.62%] [G loss: 0.342266]\n",
      "epoch:26 step:25015 [D loss: 0.233669, acc.: 57.03%] [G loss: 0.305452]\n",
      "epoch:26 step:25016 [D loss: 0.228901, acc.: 59.38%] [G loss: 0.293962]\n",
      "epoch:26 step:25017 [D loss: 0.228191, acc.: 60.16%] [G loss: 0.310965]\n",
      "epoch:26 step:25018 [D loss: 0.248943, acc.: 56.25%] [G loss: 0.306896]\n",
      "epoch:26 step:25019 [D loss: 0.223834, acc.: 60.16%] [G loss: 0.309479]\n",
      "epoch:26 step:25020 [D loss: 0.251171, acc.: 52.34%] [G loss: 0.312265]\n",
      "epoch:26 step:25021 [D loss: 0.238388, acc.: 57.81%] [G loss: 0.316047]\n",
      "epoch:26 step:25022 [D loss: 0.232395, acc.: 61.72%] [G loss: 0.299598]\n",
      "epoch:26 step:25023 [D loss: 0.244722, acc.: 57.81%] [G loss: 0.295051]\n",
      "epoch:26 step:25024 [D loss: 0.238175, acc.: 56.25%] [G loss: 0.297952]\n",
      "epoch:26 step:25025 [D loss: 0.237033, acc.: 57.81%] [G loss: 0.316558]\n",
      "epoch:26 step:25026 [D loss: 0.247931, acc.: 54.69%] [G loss: 0.307342]\n",
      "epoch:26 step:25027 [D loss: 0.248247, acc.: 54.69%] [G loss: 0.299274]\n",
      "epoch:26 step:25028 [D loss: 0.232643, acc.: 57.81%] [G loss: 0.284727]\n",
      "epoch:26 step:25029 [D loss: 0.262817, acc.: 46.09%] [G loss: 0.294841]\n",
      "epoch:26 step:25030 [D loss: 0.252848, acc.: 51.56%] [G loss: 0.286704]\n",
      "epoch:26 step:25031 [D loss: 0.233203, acc.: 64.06%] [G loss: 0.293265]\n",
      "epoch:26 step:25032 [D loss: 0.242595, acc.: 58.59%] [G loss: 0.306220]\n",
      "epoch:26 step:25033 [D loss: 0.243342, acc.: 62.50%] [G loss: 0.335153]\n",
      "epoch:26 step:25034 [D loss: 0.236626, acc.: 59.38%] [G loss: 0.313334]\n",
      "epoch:26 step:25035 [D loss: 0.245064, acc.: 55.47%] [G loss: 0.291875]\n",
      "epoch:26 step:25036 [D loss: 0.237822, acc.: 62.50%] [G loss: 0.300449]\n",
      "epoch:26 step:25037 [D loss: 0.233342, acc.: 60.16%] [G loss: 0.295365]\n",
      "epoch:26 step:25038 [D loss: 0.243393, acc.: 54.69%] [G loss: 0.300955]\n",
      "epoch:26 step:25039 [D loss: 0.231445, acc.: 62.50%] [G loss: 0.314439]\n",
      "epoch:26 step:25040 [D loss: 0.235817, acc.: 59.38%] [G loss: 0.294025]\n",
      "epoch:26 step:25041 [D loss: 0.240491, acc.: 56.25%] [G loss: 0.295319]\n",
      "epoch:26 step:25042 [D loss: 0.256189, acc.: 49.22%] [G loss: 0.316064]\n",
      "epoch:26 step:25043 [D loss: 0.243688, acc.: 52.34%] [G loss: 0.304686]\n",
      "epoch:26 step:25044 [D loss: 0.237981, acc.: 57.81%] [G loss: 0.292583]\n",
      "epoch:26 step:25045 [D loss: 0.251161, acc.: 49.22%] [G loss: 0.299529]\n",
      "epoch:26 step:25046 [D loss: 0.212108, acc.: 67.19%] [G loss: 0.305574]\n",
      "epoch:26 step:25047 [D loss: 0.228360, acc.: 60.94%] [G loss: 0.323535]\n",
      "epoch:26 step:25048 [D loss: 0.218813, acc.: 65.62%] [G loss: 0.290312]\n",
      "epoch:26 step:25049 [D loss: 0.234240, acc.: 60.16%] [G loss: 0.301429]\n",
      "epoch:26 step:25050 [D loss: 0.241920, acc.: 60.16%] [G loss: 0.283273]\n",
      "epoch:26 step:25051 [D loss: 0.239134, acc.: 57.81%] [G loss: 0.296134]\n",
      "epoch:26 step:25052 [D loss: 0.238809, acc.: 57.81%] [G loss: 0.310173]\n",
      "epoch:26 step:25053 [D loss: 0.231758, acc.: 53.91%] [G loss: 0.299766]\n",
      "epoch:26 step:25054 [D loss: 0.236893, acc.: 60.16%] [G loss: 0.318662]\n",
      "epoch:26 step:25055 [D loss: 0.239189, acc.: 56.25%] [G loss: 0.303470]\n",
      "epoch:26 step:25056 [D loss: 0.235004, acc.: 61.72%] [G loss: 0.322378]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:26 step:25057 [D loss: 0.231438, acc.: 60.94%] [G loss: 0.297677]\n",
      "epoch:26 step:25058 [D loss: 0.250840, acc.: 58.59%] [G loss: 0.308482]\n",
      "epoch:26 step:25059 [D loss: 0.222671, acc.: 65.62%] [G loss: 0.305382]\n",
      "epoch:26 step:25060 [D loss: 0.229550, acc.: 62.50%] [G loss: 0.318392]\n",
      "epoch:26 step:25061 [D loss: 0.235645, acc.: 60.94%] [G loss: 0.288294]\n",
      "epoch:26 step:25062 [D loss: 0.228773, acc.: 62.50%] [G loss: 0.313027]\n",
      "epoch:26 step:25063 [D loss: 0.229312, acc.: 59.38%] [G loss: 0.323350]\n",
      "epoch:26 step:25064 [D loss: 0.236037, acc.: 59.38%] [G loss: 0.321915]\n",
      "epoch:26 step:25065 [D loss: 0.251315, acc.: 53.91%] [G loss: 0.300066]\n",
      "epoch:26 step:25066 [D loss: 0.250288, acc.: 50.78%] [G loss: 0.300099]\n",
      "epoch:26 step:25067 [D loss: 0.245409, acc.: 56.25%] [G loss: 0.303013]\n",
      "epoch:26 step:25068 [D loss: 0.233225, acc.: 63.28%] [G loss: 0.278316]\n",
      "epoch:26 step:25069 [D loss: 0.229236, acc.: 65.62%] [G loss: 0.295823]\n",
      "epoch:26 step:25070 [D loss: 0.240713, acc.: 53.12%] [G loss: 0.289225]\n",
      "epoch:26 step:25071 [D loss: 0.250039, acc.: 53.91%] [G loss: 0.268600]\n",
      "epoch:26 step:25072 [D loss: 0.245942, acc.: 50.00%] [G loss: 0.275853]\n",
      "epoch:26 step:25073 [D loss: 0.236238, acc.: 60.16%] [G loss: 0.326550]\n",
      "epoch:26 step:25074 [D loss: 0.264395, acc.: 53.91%] [G loss: 0.303026]\n",
      "epoch:26 step:25075 [D loss: 0.230033, acc.: 60.16%] [G loss: 0.325979]\n",
      "epoch:26 step:25076 [D loss: 0.236596, acc.: 60.94%] [G loss: 0.303318]\n",
      "epoch:26 step:25077 [D loss: 0.237865, acc.: 59.38%] [G loss: 0.312566]\n",
      "epoch:26 step:25078 [D loss: 0.220897, acc.: 70.31%] [G loss: 0.311391]\n",
      "epoch:26 step:25079 [D loss: 0.213720, acc.: 67.19%] [G loss: 0.326218]\n",
      "epoch:26 step:25080 [D loss: 0.216045, acc.: 65.62%] [G loss: 0.292125]\n",
      "epoch:26 step:25081 [D loss: 0.244191, acc.: 56.25%] [G loss: 0.305450]\n",
      "epoch:26 step:25082 [D loss: 0.246041, acc.: 54.69%] [G loss: 0.279722]\n",
      "epoch:26 step:25083 [D loss: 0.227891, acc.: 60.16%] [G loss: 0.264447]\n",
      "epoch:26 step:25084 [D loss: 0.248880, acc.: 57.81%] [G loss: 0.326361]\n",
      "epoch:26 step:25085 [D loss: 0.241613, acc.: 56.25%] [G loss: 0.317083]\n",
      "epoch:26 step:25086 [D loss: 0.228275, acc.: 66.41%] [G loss: 0.335005]\n",
      "epoch:26 step:25087 [D loss: 0.254113, acc.: 52.34%] [G loss: 0.283661]\n",
      "epoch:26 step:25088 [D loss: 0.265909, acc.: 48.44%] [G loss: 0.299834]\n",
      "epoch:26 step:25089 [D loss: 0.223119, acc.: 60.94%] [G loss: 0.294907]\n",
      "epoch:26 step:25090 [D loss: 0.239615, acc.: 61.72%] [G loss: 0.291233]\n",
      "epoch:26 step:25091 [D loss: 0.247609, acc.: 56.25%] [G loss: 0.283388]\n",
      "epoch:26 step:25092 [D loss: 0.230004, acc.: 60.16%] [G loss: 0.320912]\n",
      "epoch:26 step:25093 [D loss: 0.252334, acc.: 51.56%] [G loss: 0.310439]\n",
      "epoch:26 step:25094 [D loss: 0.252249, acc.: 59.38%] [G loss: 0.293207]\n",
      "epoch:26 step:25095 [D loss: 0.244037, acc.: 53.12%] [G loss: 0.307501]\n",
      "epoch:26 step:25096 [D loss: 0.232360, acc.: 57.03%] [G loss: 0.324687]\n",
      "epoch:26 step:25097 [D loss: 0.236015, acc.: 63.28%] [G loss: 0.293573]\n",
      "epoch:26 step:25098 [D loss: 0.238872, acc.: 57.81%] [G loss: 0.297168]\n",
      "epoch:26 step:25099 [D loss: 0.233993, acc.: 58.59%] [G loss: 0.332030]\n",
      "epoch:26 step:25100 [D loss: 0.252332, acc.: 52.34%] [G loss: 0.308510]\n",
      "epoch:26 step:25101 [D loss: 0.236583, acc.: 58.59%] [G loss: 0.279762]\n",
      "epoch:26 step:25102 [D loss: 0.256447, acc.: 52.34%] [G loss: 0.316746]\n",
      "epoch:26 step:25103 [D loss: 0.253119, acc.: 52.34%] [G loss: 0.278532]\n",
      "epoch:26 step:25104 [D loss: 0.235334, acc.: 60.94%] [G loss: 0.302948]\n",
      "epoch:26 step:25105 [D loss: 0.255319, acc.: 56.25%] [G loss: 0.309130]\n",
      "epoch:26 step:25106 [D loss: 0.260112, acc.: 47.66%] [G loss: 0.288893]\n",
      "epoch:26 step:25107 [D loss: 0.248877, acc.: 54.69%] [G loss: 0.286218]\n",
      "epoch:26 step:25108 [D loss: 0.248647, acc.: 53.12%] [G loss: 0.294952]\n",
      "epoch:26 step:25109 [D loss: 0.247309, acc.: 48.44%] [G loss: 0.293618]\n",
      "epoch:26 step:25110 [D loss: 0.235734, acc.: 64.84%] [G loss: 0.294120]\n",
      "epoch:26 step:25111 [D loss: 0.244108, acc.: 55.47%] [G loss: 0.315911]\n",
      "epoch:26 step:25112 [D loss: 0.225336, acc.: 64.84%] [G loss: 0.308465]\n",
      "epoch:26 step:25113 [D loss: 0.233856, acc.: 60.16%] [G loss: 0.281755]\n",
      "epoch:26 step:25114 [D loss: 0.269936, acc.: 49.22%] [G loss: 0.298427]\n",
      "epoch:26 step:25115 [D loss: 0.246114, acc.: 57.81%] [G loss: 0.331417]\n",
      "epoch:26 step:25116 [D loss: 0.236298, acc.: 57.03%] [G loss: 0.311736]\n",
      "epoch:26 step:25117 [D loss: 0.237516, acc.: 58.59%] [G loss: 0.350808]\n",
      "epoch:26 step:25118 [D loss: 0.235040, acc.: 60.16%] [G loss: 0.301701]\n",
      "epoch:26 step:25119 [D loss: 0.224844, acc.: 61.72%] [G loss: 0.320948]\n",
      "epoch:26 step:25120 [D loss: 0.237725, acc.: 62.50%] [G loss: 0.320896]\n",
      "epoch:26 step:25121 [D loss: 0.229683, acc.: 61.72%] [G loss: 0.284631]\n",
      "epoch:26 step:25122 [D loss: 0.226666, acc.: 60.94%] [G loss: 0.305268]\n",
      "epoch:26 step:25123 [D loss: 0.230052, acc.: 59.38%] [G loss: 0.311870]\n",
      "epoch:26 step:25124 [D loss: 0.240424, acc.: 56.25%] [G loss: 0.305135]\n",
      "epoch:26 step:25125 [D loss: 0.247441, acc.: 56.25%] [G loss: 0.279288]\n",
      "epoch:26 step:25126 [D loss: 0.249135, acc.: 52.34%] [G loss: 0.293925]\n",
      "epoch:26 step:25127 [D loss: 0.243944, acc.: 56.25%] [G loss: 0.322317]\n",
      "epoch:26 step:25128 [D loss: 0.229512, acc.: 57.81%] [G loss: 0.300996]\n",
      "epoch:26 step:25129 [D loss: 0.244153, acc.: 56.25%] [G loss: 0.311397]\n",
      "epoch:26 step:25130 [D loss: 0.240859, acc.: 60.16%] [G loss: 0.293910]\n",
      "epoch:26 step:25131 [D loss: 0.241549, acc.: 63.28%] [G loss: 0.315456]\n",
      "epoch:26 step:25132 [D loss: 0.235687, acc.: 61.72%] [G loss: 0.343950]\n",
      "epoch:26 step:25133 [D loss: 0.224700, acc.: 62.50%] [G loss: 0.322720]\n",
      "epoch:26 step:25134 [D loss: 0.245710, acc.: 56.25%] [G loss: 0.304078]\n",
      "epoch:26 step:25135 [D loss: 0.250044, acc.: 53.91%] [G loss: 0.322530]\n",
      "epoch:26 step:25136 [D loss: 0.236137, acc.: 64.84%] [G loss: 0.318671]\n",
      "epoch:26 step:25137 [D loss: 0.243642, acc.: 58.59%] [G loss: 0.315205]\n",
      "epoch:26 step:25138 [D loss: 0.227304, acc.: 60.94%] [G loss: 0.300126]\n",
      "epoch:26 step:25139 [D loss: 0.240635, acc.: 59.38%] [G loss: 0.295060]\n",
      "epoch:26 step:25140 [D loss: 0.223516, acc.: 64.06%] [G loss: 0.315564]\n",
      "epoch:26 step:25141 [D loss: 0.235617, acc.: 63.28%] [G loss: 0.293643]\n",
      "epoch:26 step:25142 [D loss: 0.246400, acc.: 50.78%] [G loss: 0.309786]\n",
      "epoch:26 step:25143 [D loss: 0.224954, acc.: 67.19%] [G loss: 0.312521]\n",
      "epoch:26 step:25144 [D loss: 0.234339, acc.: 60.94%] [G loss: 0.333939]\n",
      "epoch:26 step:25145 [D loss: 0.245734, acc.: 56.25%] [G loss: 0.288989]\n",
      "epoch:26 step:25146 [D loss: 0.234363, acc.: 60.16%] [G loss: 0.330938]\n",
      "epoch:26 step:25147 [D loss: 0.243786, acc.: 59.38%] [G loss: 0.295174]\n",
      "epoch:26 step:25148 [D loss: 0.242319, acc.: 60.16%] [G loss: 0.282237]\n",
      "epoch:26 step:25149 [D loss: 0.228296, acc.: 58.59%] [G loss: 0.309796]\n",
      "epoch:26 step:25150 [D loss: 0.247676, acc.: 58.59%] [G loss: 0.277607]\n",
      "epoch:26 step:25151 [D loss: 0.224920, acc.: 60.94%] [G loss: 0.323469]\n",
      "epoch:26 step:25152 [D loss: 0.229267, acc.: 63.28%] [G loss: 0.301132]\n",
      "epoch:26 step:25153 [D loss: 0.225603, acc.: 63.28%] [G loss: 0.322633]\n",
      "epoch:26 step:25154 [D loss: 0.238126, acc.: 55.47%] [G loss: 0.303850]\n",
      "epoch:26 step:25155 [D loss: 0.241163, acc.: 53.12%] [G loss: 0.325407]\n",
      "epoch:26 step:25156 [D loss: 0.240274, acc.: 55.47%] [G loss: 0.318609]\n",
      "epoch:26 step:25157 [D loss: 0.234836, acc.: 60.94%] [G loss: 0.282540]\n",
      "epoch:26 step:25158 [D loss: 0.249072, acc.: 54.69%] [G loss: 0.309034]\n",
      "epoch:26 step:25159 [D loss: 0.238061, acc.: 60.16%] [G loss: 0.268349]\n",
      "epoch:26 step:25160 [D loss: 0.229115, acc.: 60.16%] [G loss: 0.293614]\n",
      "epoch:26 step:25161 [D loss: 0.249334, acc.: 51.56%] [G loss: 0.274633]\n",
      "epoch:26 step:25162 [D loss: 0.241354, acc.: 57.81%] [G loss: 0.298780]\n",
      "epoch:26 step:25163 [D loss: 0.235003, acc.: 59.38%] [G loss: 0.287974]\n",
      "epoch:26 step:25164 [D loss: 0.225302, acc.: 60.16%] [G loss: 0.294804]\n",
      "epoch:26 step:25165 [D loss: 0.244594, acc.: 57.03%] [G loss: 0.310389]\n",
      "epoch:26 step:25166 [D loss: 0.236072, acc.: 59.38%] [G loss: 0.299963]\n",
      "epoch:26 step:25167 [D loss: 0.234207, acc.: 56.25%] [G loss: 0.292209]\n",
      "epoch:26 step:25168 [D loss: 0.235798, acc.: 57.81%] [G loss: 0.285489]\n",
      "epoch:26 step:25169 [D loss: 0.250683, acc.: 55.47%] [G loss: 0.306203]\n",
      "epoch:26 step:25170 [D loss: 0.243361, acc.: 56.25%] [G loss: 0.281475]\n",
      "epoch:26 step:25171 [D loss: 0.224104, acc.: 69.53%] [G loss: 0.271116]\n",
      "epoch:26 step:25172 [D loss: 0.227660, acc.: 63.28%] [G loss: 0.316585]\n",
      "epoch:26 step:25173 [D loss: 0.250014, acc.: 54.69%] [G loss: 0.312234]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:26 step:25174 [D loss: 0.231892, acc.: 64.06%] [G loss: 0.307677]\n",
      "epoch:26 step:25175 [D loss: 0.231498, acc.: 59.38%] [G loss: 0.308708]\n",
      "epoch:26 step:25176 [D loss: 0.240415, acc.: 58.59%] [G loss: 0.312531]\n",
      "epoch:26 step:25177 [D loss: 0.249251, acc.: 56.25%] [G loss: 0.290878]\n",
      "epoch:26 step:25178 [D loss: 0.237461, acc.: 60.94%] [G loss: 0.298883]\n",
      "epoch:26 step:25179 [D loss: 0.232462, acc.: 60.16%] [G loss: 0.321814]\n",
      "epoch:26 step:25180 [D loss: 0.246932, acc.: 53.12%] [G loss: 0.299602]\n",
      "epoch:26 step:25181 [D loss: 0.247348, acc.: 57.81%] [G loss: 0.302869]\n",
      "epoch:26 step:25182 [D loss: 0.247309, acc.: 53.12%] [G loss: 0.288960]\n",
      "epoch:26 step:25183 [D loss: 0.258799, acc.: 49.22%] [G loss: 0.296834]\n",
      "epoch:26 step:25184 [D loss: 0.238479, acc.: 57.03%] [G loss: 0.319098]\n",
      "epoch:26 step:25185 [D loss: 0.252142, acc.: 51.56%] [G loss: 0.304263]\n",
      "epoch:26 step:25186 [D loss: 0.233006, acc.: 60.16%] [G loss: 0.292202]\n",
      "epoch:26 step:25187 [D loss: 0.217094, acc.: 64.06%] [G loss: 0.292783]\n",
      "epoch:26 step:25188 [D loss: 0.254716, acc.: 56.25%] [G loss: 0.302050]\n",
      "epoch:26 step:25189 [D loss: 0.231102, acc.: 57.03%] [G loss: 0.323101]\n",
      "epoch:26 step:25190 [D loss: 0.231802, acc.: 63.28%] [G loss: 0.288887]\n",
      "epoch:26 step:25191 [D loss: 0.225416, acc.: 64.06%] [G loss: 0.329887]\n",
      "epoch:26 step:25192 [D loss: 0.238875, acc.: 60.94%] [G loss: 0.305640]\n",
      "epoch:26 step:25193 [D loss: 0.228729, acc.: 61.72%] [G loss: 0.306054]\n",
      "epoch:26 step:25194 [D loss: 0.254996, acc.: 51.56%] [G loss: 0.298531]\n",
      "epoch:26 step:25195 [D loss: 0.253537, acc.: 51.56%] [G loss: 0.271231]\n",
      "epoch:26 step:25196 [D loss: 0.252009, acc.: 55.47%] [G loss: 0.293207]\n",
      "epoch:26 step:25197 [D loss: 0.247002, acc.: 61.72%] [G loss: 0.301755]\n",
      "epoch:26 step:25198 [D loss: 0.238979, acc.: 55.47%] [G loss: 0.311648]\n",
      "epoch:26 step:25199 [D loss: 0.237051, acc.: 56.25%] [G loss: 0.298140]\n",
      "epoch:26 step:25200 [D loss: 0.242385, acc.: 57.81%] [G loss: 0.303982]\n",
      "epoch:26 step:25201 [D loss: 0.243859, acc.: 52.34%] [G loss: 0.286205]\n",
      "epoch:26 step:25202 [D loss: 0.248959, acc.: 57.03%] [G loss: 0.300079]\n",
      "epoch:26 step:25203 [D loss: 0.222363, acc.: 60.94%] [G loss: 0.309524]\n",
      "epoch:26 step:25204 [D loss: 0.255405, acc.: 53.91%] [G loss: 0.329309]\n",
      "epoch:26 step:25205 [D loss: 0.253775, acc.: 53.12%] [G loss: 0.300391]\n",
      "epoch:26 step:25206 [D loss: 0.257051, acc.: 53.12%] [G loss: 0.325263]\n",
      "epoch:26 step:25207 [D loss: 0.242738, acc.: 56.25%] [G loss: 0.308446]\n",
      "epoch:26 step:25208 [D loss: 0.237804, acc.: 59.38%] [G loss: 0.332749]\n",
      "epoch:26 step:25209 [D loss: 0.233318, acc.: 57.03%] [G loss: 0.273493]\n",
      "epoch:26 step:25210 [D loss: 0.244052, acc.: 61.72%] [G loss: 0.284010]\n",
      "epoch:26 step:25211 [D loss: 0.249114, acc.: 53.91%] [G loss: 0.292062]\n",
      "epoch:26 step:25212 [D loss: 0.224357, acc.: 65.62%] [G loss: 0.316884]\n",
      "epoch:26 step:25213 [D loss: 0.258632, acc.: 54.69%] [G loss: 0.302464]\n",
      "epoch:26 step:25214 [D loss: 0.258320, acc.: 54.69%] [G loss: 0.296211]\n",
      "epoch:26 step:25215 [D loss: 0.250829, acc.: 53.91%] [G loss: 0.303102]\n",
      "epoch:26 step:25216 [D loss: 0.241743, acc.: 60.16%] [G loss: 0.291997]\n",
      "epoch:26 step:25217 [D loss: 0.241454, acc.: 59.38%] [G loss: 0.321164]\n",
      "epoch:26 step:25218 [D loss: 0.237072, acc.: 60.16%] [G loss: 0.280006]\n",
      "epoch:26 step:25219 [D loss: 0.236638, acc.: 59.38%] [G loss: 0.315268]\n",
      "epoch:26 step:25220 [D loss: 0.233559, acc.: 57.03%] [G loss: 0.316160]\n",
      "epoch:26 step:25221 [D loss: 0.224852, acc.: 64.84%] [G loss: 0.319730]\n",
      "epoch:26 step:25222 [D loss: 0.261910, acc.: 50.00%] [G loss: 0.310056]\n",
      "epoch:26 step:25223 [D loss: 0.237533, acc.: 51.56%] [G loss: 0.310948]\n",
      "epoch:26 step:25224 [D loss: 0.247861, acc.: 53.91%] [G loss: 0.320297]\n",
      "epoch:26 step:25225 [D loss: 0.239116, acc.: 57.81%] [G loss: 0.314789]\n",
      "epoch:26 step:25226 [D loss: 0.238974, acc.: 59.38%] [G loss: 0.305313]\n",
      "epoch:26 step:25227 [D loss: 0.247994, acc.: 50.78%] [G loss: 0.287784]\n",
      "epoch:26 step:25228 [D loss: 0.238384, acc.: 62.50%] [G loss: 0.307813]\n",
      "epoch:26 step:25229 [D loss: 0.233437, acc.: 64.84%] [G loss: 0.290664]\n",
      "epoch:26 step:25230 [D loss: 0.247609, acc.: 53.12%] [G loss: 0.292118]\n",
      "epoch:26 step:25231 [D loss: 0.237164, acc.: 59.38%] [G loss: 0.304009]\n",
      "epoch:26 step:25232 [D loss: 0.233173, acc.: 63.28%] [G loss: 0.296981]\n",
      "epoch:26 step:25233 [D loss: 0.232197, acc.: 60.94%] [G loss: 0.332466]\n",
      "epoch:26 step:25234 [D loss: 0.253003, acc.: 52.34%] [G loss: 0.321025]\n",
      "epoch:26 step:25235 [D loss: 0.239218, acc.: 57.81%] [G loss: 0.318916]\n",
      "epoch:26 step:25236 [D loss: 0.244998, acc.: 58.59%] [G loss: 0.307959]\n",
      "epoch:26 step:25237 [D loss: 0.229826, acc.: 59.38%] [G loss: 0.298003]\n",
      "epoch:26 step:25238 [D loss: 0.258265, acc.: 48.44%] [G loss: 0.291791]\n",
      "epoch:26 step:25239 [D loss: 0.231292, acc.: 61.72%] [G loss: 0.314229]\n",
      "epoch:26 step:25240 [D loss: 0.239209, acc.: 60.94%] [G loss: 0.312627]\n",
      "epoch:26 step:25241 [D loss: 0.262049, acc.: 47.66%] [G loss: 0.323211]\n",
      "epoch:26 step:25242 [D loss: 0.224503, acc.: 63.28%] [G loss: 0.317741]\n",
      "epoch:26 step:25243 [D loss: 0.248391, acc.: 53.12%] [G loss: 0.292590]\n",
      "epoch:26 step:25244 [D loss: 0.227175, acc.: 58.59%] [G loss: 0.304655]\n",
      "epoch:26 step:25245 [D loss: 0.246192, acc.: 55.47%] [G loss: 0.332986]\n",
      "epoch:26 step:25246 [D loss: 0.234695, acc.: 57.03%] [G loss: 0.284707]\n",
      "epoch:26 step:25247 [D loss: 0.225532, acc.: 57.03%] [G loss: 0.325525]\n",
      "epoch:26 step:25248 [D loss: 0.228767, acc.: 59.38%] [G loss: 0.318365]\n",
      "epoch:26 step:25249 [D loss: 0.227254, acc.: 64.06%] [G loss: 0.321868]\n",
      "epoch:26 step:25250 [D loss: 0.239484, acc.: 64.06%] [G loss: 0.297494]\n",
      "epoch:26 step:25251 [D loss: 0.240200, acc.: 59.38%] [G loss: 0.301451]\n",
      "epoch:26 step:25252 [D loss: 0.240573, acc.: 59.38%] [G loss: 0.312503]\n",
      "epoch:26 step:25253 [D loss: 0.250239, acc.: 53.12%] [G loss: 0.311162]\n",
      "epoch:26 step:25254 [D loss: 0.236083, acc.: 61.72%] [G loss: 0.295126]\n",
      "epoch:26 step:25255 [D loss: 0.238253, acc.: 60.16%] [G loss: 0.299897]\n",
      "epoch:26 step:25256 [D loss: 0.240723, acc.: 60.94%] [G loss: 0.303622]\n",
      "epoch:26 step:25257 [D loss: 0.225706, acc.: 64.84%] [G loss: 0.300318]\n",
      "epoch:26 step:25258 [D loss: 0.224235, acc.: 63.28%] [G loss: 0.293707]\n",
      "epoch:26 step:25259 [D loss: 0.260473, acc.: 48.44%] [G loss: 0.280890]\n",
      "epoch:26 step:25260 [D loss: 0.219189, acc.: 66.41%] [G loss: 0.312633]\n",
      "epoch:26 step:25261 [D loss: 0.245690, acc.: 53.91%] [G loss: 0.312084]\n",
      "epoch:26 step:25262 [D loss: 0.233324, acc.: 58.59%] [G loss: 0.311441]\n",
      "epoch:26 step:25263 [D loss: 0.235742, acc.: 59.38%] [G loss: 0.299212]\n",
      "epoch:26 step:25264 [D loss: 0.238917, acc.: 56.25%] [G loss: 0.291879]\n",
      "epoch:26 step:25265 [D loss: 0.243110, acc.: 60.16%] [G loss: 0.327655]\n",
      "epoch:26 step:25266 [D loss: 0.244994, acc.: 53.91%] [G loss: 0.308590]\n",
      "epoch:26 step:25267 [D loss: 0.235053, acc.: 60.16%] [G loss: 0.304930]\n",
      "epoch:26 step:25268 [D loss: 0.237050, acc.: 57.03%] [G loss: 0.318065]\n",
      "epoch:26 step:25269 [D loss: 0.229776, acc.: 58.59%] [G loss: 0.303631]\n",
      "epoch:26 step:25270 [D loss: 0.254396, acc.: 50.00%] [G loss: 0.260816]\n",
      "epoch:26 step:25271 [D loss: 0.232311, acc.: 63.28%] [G loss: 0.303215]\n",
      "epoch:26 step:25272 [D loss: 0.241956, acc.: 58.59%] [G loss: 0.305030]\n",
      "epoch:26 step:25273 [D loss: 0.241971, acc.: 55.47%] [G loss: 0.301501]\n",
      "epoch:26 step:25274 [D loss: 0.248752, acc.: 55.47%] [G loss: 0.277403]\n",
      "epoch:26 step:25275 [D loss: 0.230258, acc.: 58.59%] [G loss: 0.298043]\n",
      "epoch:26 step:25276 [D loss: 0.238468, acc.: 58.59%] [G loss: 0.288769]\n",
      "epoch:26 step:25277 [D loss: 0.245612, acc.: 55.47%] [G loss: 0.302583]\n",
      "epoch:26 step:25278 [D loss: 0.236549, acc.: 61.72%] [G loss: 0.304754]\n",
      "epoch:26 step:25279 [D loss: 0.253719, acc.: 54.69%] [G loss: 0.316510]\n",
      "epoch:26 step:25280 [D loss: 0.242566, acc.: 56.25%] [G loss: 0.288570]\n",
      "epoch:26 step:25281 [D loss: 0.261075, acc.: 48.44%] [G loss: 0.311049]\n",
      "epoch:26 step:25282 [D loss: 0.237862, acc.: 58.59%] [G loss: 0.318476]\n",
      "epoch:26 step:25283 [D loss: 0.238025, acc.: 59.38%] [G loss: 0.306844]\n",
      "epoch:26 step:25284 [D loss: 0.226447, acc.: 61.72%] [G loss: 0.311250]\n",
      "epoch:26 step:25285 [D loss: 0.219451, acc.: 64.06%] [G loss: 0.328363]\n",
      "epoch:26 step:25286 [D loss: 0.242205, acc.: 57.03%] [G loss: 0.293377]\n",
      "epoch:26 step:25287 [D loss: 0.238934, acc.: 59.38%] [G loss: 0.301037]\n",
      "epoch:26 step:25288 [D loss: 0.226725, acc.: 64.84%] [G loss: 0.305334]\n",
      "epoch:26 step:25289 [D loss: 0.255943, acc.: 53.12%] [G loss: 0.318888]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:26 step:25290 [D loss: 0.229542, acc.: 58.59%] [G loss: 0.315154]\n",
      "epoch:26 step:25291 [D loss: 0.236258, acc.: 58.59%] [G loss: 0.303620]\n",
      "epoch:26 step:25292 [D loss: 0.240528, acc.: 57.81%] [G loss: 0.347578]\n",
      "epoch:26 step:25293 [D loss: 0.226662, acc.: 60.94%] [G loss: 0.306083]\n",
      "epoch:26 step:25294 [D loss: 0.242625, acc.: 59.38%] [G loss: 0.302652]\n",
      "epoch:26 step:25295 [D loss: 0.238328, acc.: 56.25%] [G loss: 0.305972]\n",
      "epoch:26 step:25296 [D loss: 0.236033, acc.: 58.59%] [G loss: 0.290235]\n",
      "epoch:26 step:25297 [D loss: 0.227703, acc.: 58.59%] [G loss: 0.309205]\n",
      "epoch:26 step:25298 [D loss: 0.238304, acc.: 58.59%] [G loss: 0.293624]\n",
      "epoch:26 step:25299 [D loss: 0.266747, acc.: 48.44%] [G loss: 0.293441]\n",
      "epoch:27 step:25300 [D loss: 0.228501, acc.: 60.16%] [G loss: 0.270063]\n",
      "epoch:27 step:25301 [D loss: 0.236318, acc.: 60.94%] [G loss: 0.305975]\n",
      "epoch:27 step:25302 [D loss: 0.236703, acc.: 56.25%] [G loss: 0.345963]\n",
      "epoch:27 step:25303 [D loss: 0.228135, acc.: 61.72%] [G loss: 0.286742]\n",
      "epoch:27 step:25304 [D loss: 0.228997, acc.: 61.72%] [G loss: 0.322794]\n",
      "epoch:27 step:25305 [D loss: 0.238441, acc.: 58.59%] [G loss: 0.319986]\n",
      "epoch:27 step:25306 [D loss: 0.254011, acc.: 57.81%] [G loss: 0.293788]\n",
      "epoch:27 step:25307 [D loss: 0.248119, acc.: 53.91%] [G loss: 0.276228]\n",
      "epoch:27 step:25308 [D loss: 0.237153, acc.: 60.16%] [G loss: 0.293531]\n",
      "epoch:27 step:25309 [D loss: 0.234966, acc.: 58.59%] [G loss: 0.324517]\n",
      "epoch:27 step:25310 [D loss: 0.219430, acc.: 62.50%] [G loss: 0.332849]\n",
      "epoch:27 step:25311 [D loss: 0.233941, acc.: 59.38%] [G loss: 0.266631]\n",
      "epoch:27 step:25312 [D loss: 0.250142, acc.: 55.47%] [G loss: 0.301074]\n",
      "epoch:27 step:25313 [D loss: 0.244611, acc.: 53.91%] [G loss: 0.308962]\n",
      "epoch:27 step:25314 [D loss: 0.240522, acc.: 60.94%] [G loss: 0.293765]\n",
      "epoch:27 step:25315 [D loss: 0.260416, acc.: 50.78%] [G loss: 0.282980]\n",
      "epoch:27 step:25316 [D loss: 0.226938, acc.: 65.62%] [G loss: 0.314365]\n",
      "epoch:27 step:25317 [D loss: 0.258105, acc.: 53.12%] [G loss: 0.310111]\n",
      "epoch:27 step:25318 [D loss: 0.234292, acc.: 60.94%] [G loss: 0.288162]\n",
      "epoch:27 step:25319 [D loss: 0.221881, acc.: 64.06%] [G loss: 0.301076]\n",
      "epoch:27 step:25320 [D loss: 0.233053, acc.: 57.03%] [G loss: 0.271885]\n",
      "epoch:27 step:25321 [D loss: 0.242648, acc.: 59.38%] [G loss: 0.305104]\n",
      "epoch:27 step:25322 [D loss: 0.242593, acc.: 60.16%] [G loss: 0.325380]\n",
      "epoch:27 step:25323 [D loss: 0.230180, acc.: 63.28%] [G loss: 0.274049]\n",
      "epoch:27 step:25324 [D loss: 0.244012, acc.: 55.47%] [G loss: 0.271857]\n",
      "epoch:27 step:25325 [D loss: 0.222874, acc.: 61.72%] [G loss: 0.297705]\n",
      "epoch:27 step:25326 [D loss: 0.222736, acc.: 65.62%] [G loss: 0.314789]\n",
      "epoch:27 step:25327 [D loss: 0.246775, acc.: 52.34%] [G loss: 0.284452]\n",
      "epoch:27 step:25328 [D loss: 0.250995, acc.: 52.34%] [G loss: 0.288673]\n",
      "epoch:27 step:25329 [D loss: 0.264051, acc.: 51.56%] [G loss: 0.274926]\n",
      "epoch:27 step:25330 [D loss: 0.256409, acc.: 57.81%] [G loss: 0.308134]\n",
      "epoch:27 step:25331 [D loss: 0.240220, acc.: 64.84%] [G loss: 0.310199]\n",
      "epoch:27 step:25332 [D loss: 0.232717, acc.: 63.28%] [G loss: 0.296306]\n",
      "epoch:27 step:25333 [D loss: 0.223805, acc.: 62.50%] [G loss: 0.319589]\n",
      "epoch:27 step:25334 [D loss: 0.241842, acc.: 53.91%] [G loss: 0.292485]\n",
      "epoch:27 step:25335 [D loss: 0.235221, acc.: 60.16%] [G loss: 0.310382]\n",
      "epoch:27 step:25336 [D loss: 0.240338, acc.: 59.38%] [G loss: 0.299036]\n",
      "epoch:27 step:25337 [D loss: 0.229638, acc.: 61.72%] [G loss: 0.284532]\n",
      "epoch:27 step:25338 [D loss: 0.247719, acc.: 54.69%] [G loss: 0.274622]\n",
      "epoch:27 step:25339 [D loss: 0.230735, acc.: 64.06%] [G loss: 0.298299]\n",
      "epoch:27 step:25340 [D loss: 0.228323, acc.: 64.06%] [G loss: 0.302587]\n",
      "epoch:27 step:25341 [D loss: 0.229387, acc.: 63.28%] [G loss: 0.296938]\n",
      "epoch:27 step:25342 [D loss: 0.242618, acc.: 51.56%] [G loss: 0.312424]\n",
      "epoch:27 step:25343 [D loss: 0.257080, acc.: 49.22%] [G loss: 0.286205]\n",
      "epoch:27 step:25344 [D loss: 0.223895, acc.: 63.28%] [G loss: 0.326238]\n",
      "epoch:27 step:25345 [D loss: 0.265973, acc.: 47.66%] [G loss: 0.309841]\n",
      "epoch:27 step:25346 [D loss: 0.247573, acc.: 53.91%] [G loss: 0.276648]\n",
      "epoch:27 step:25347 [D loss: 0.238291, acc.: 59.38%] [G loss: 0.298523]\n",
      "epoch:27 step:25348 [D loss: 0.247800, acc.: 57.81%] [G loss: 0.279795]\n",
      "epoch:27 step:25349 [D loss: 0.236156, acc.: 60.16%] [G loss: 0.324725]\n",
      "epoch:27 step:25350 [D loss: 0.231540, acc.: 61.72%] [G loss: 0.286831]\n",
      "epoch:27 step:25351 [D loss: 0.247691, acc.: 56.25%] [G loss: 0.291892]\n",
      "epoch:27 step:25352 [D loss: 0.244818, acc.: 56.25%] [G loss: 0.298083]\n",
      "epoch:27 step:25353 [D loss: 0.226059, acc.: 67.19%] [G loss: 0.277865]\n",
      "epoch:27 step:25354 [D loss: 0.244016, acc.: 53.91%] [G loss: 0.288257]\n",
      "epoch:27 step:25355 [D loss: 0.240076, acc.: 52.34%] [G loss: 0.300429]\n",
      "epoch:27 step:25356 [D loss: 0.250571, acc.: 56.25%] [G loss: 0.313084]\n",
      "epoch:27 step:25357 [D loss: 0.238514, acc.: 60.94%] [G loss: 0.291876]\n",
      "epoch:27 step:25358 [D loss: 0.242476, acc.: 58.59%] [G loss: 0.284900]\n",
      "epoch:27 step:25359 [D loss: 0.226124, acc.: 65.62%] [G loss: 0.303768]\n",
      "epoch:27 step:25360 [D loss: 0.244388, acc.: 53.91%] [G loss: 0.292063]\n",
      "epoch:27 step:25361 [D loss: 0.239163, acc.: 58.59%] [G loss: 0.265432]\n",
      "epoch:27 step:25362 [D loss: 0.234691, acc.: 57.03%] [G loss: 0.294073]\n",
      "epoch:27 step:25363 [D loss: 0.252278, acc.: 52.34%] [G loss: 0.276849]\n",
      "epoch:27 step:25364 [D loss: 0.215879, acc.: 67.97%] [G loss: 0.356722]\n",
      "epoch:27 step:25365 [D loss: 0.245479, acc.: 56.25%] [G loss: 0.292820]\n",
      "epoch:27 step:25366 [D loss: 0.222556, acc.: 60.16%] [G loss: 0.310848]\n",
      "epoch:27 step:25367 [D loss: 0.243098, acc.: 56.25%] [G loss: 0.273479]\n",
      "epoch:27 step:25368 [D loss: 0.224099, acc.: 65.62%] [G loss: 0.298752]\n",
      "epoch:27 step:25369 [D loss: 0.255211, acc.: 51.56%] [G loss: 0.281385]\n",
      "epoch:27 step:25370 [D loss: 0.242590, acc.: 58.59%] [G loss: 0.317182]\n",
      "epoch:27 step:25371 [D loss: 0.228027, acc.: 64.06%] [G loss: 0.271608]\n",
      "epoch:27 step:25372 [D loss: 0.248824, acc.: 57.03%] [G loss: 0.289036]\n",
      "epoch:27 step:25373 [D loss: 0.229233, acc.: 63.28%] [G loss: 0.268469]\n",
      "epoch:27 step:25374 [D loss: 0.236880, acc.: 55.47%] [G loss: 0.293095]\n",
      "epoch:27 step:25375 [D loss: 0.222341, acc.: 62.50%] [G loss: 0.315083]\n",
      "epoch:27 step:25376 [D loss: 0.250435, acc.: 52.34%] [G loss: 0.322348]\n",
      "epoch:27 step:25377 [D loss: 0.249622, acc.: 60.94%] [G loss: 0.310218]\n",
      "epoch:27 step:25378 [D loss: 0.230445, acc.: 57.81%] [G loss: 0.317167]\n",
      "epoch:27 step:25379 [D loss: 0.226403, acc.: 67.19%] [G loss: 0.314207]\n",
      "epoch:27 step:25380 [D loss: 0.250567, acc.: 60.16%] [G loss: 0.289455]\n",
      "epoch:27 step:25381 [D loss: 0.236381, acc.: 63.28%] [G loss: 0.306115]\n",
      "epoch:27 step:25382 [D loss: 0.235489, acc.: 64.06%] [G loss: 0.314819]\n",
      "epoch:27 step:25383 [D loss: 0.258880, acc.: 49.22%] [G loss: 0.288692]\n",
      "epoch:27 step:25384 [D loss: 0.256014, acc.: 49.22%] [G loss: 0.288796]\n",
      "epoch:27 step:25385 [D loss: 0.235159, acc.: 57.81%] [G loss: 0.292715]\n",
      "epoch:27 step:25386 [D loss: 0.253906, acc.: 50.00%] [G loss: 0.300281]\n",
      "epoch:27 step:25387 [D loss: 0.244161, acc.: 53.91%] [G loss: 0.295645]\n",
      "epoch:27 step:25388 [D loss: 0.221023, acc.: 65.62%] [G loss: 0.290452]\n",
      "epoch:27 step:25389 [D loss: 0.228643, acc.: 60.94%] [G loss: 0.296533]\n",
      "epoch:27 step:25390 [D loss: 0.239420, acc.: 60.16%] [G loss: 0.298335]\n",
      "epoch:27 step:25391 [D loss: 0.258062, acc.: 45.31%] [G loss: 0.296694]\n",
      "epoch:27 step:25392 [D loss: 0.238114, acc.: 60.94%] [G loss: 0.352187]\n",
      "epoch:27 step:25393 [D loss: 0.217070, acc.: 65.62%] [G loss: 0.331390]\n",
      "epoch:27 step:25394 [D loss: 0.237463, acc.: 55.47%] [G loss: 0.319303]\n",
      "epoch:27 step:25395 [D loss: 0.269571, acc.: 49.22%] [G loss: 0.274797]\n",
      "epoch:27 step:25396 [D loss: 0.235298, acc.: 61.72%] [G loss: 0.316030]\n",
      "epoch:27 step:25397 [D loss: 0.246534, acc.: 51.56%] [G loss: 0.297855]\n",
      "epoch:27 step:25398 [D loss: 0.231387, acc.: 58.59%] [G loss: 0.328059]\n",
      "epoch:27 step:25399 [D loss: 0.263955, acc.: 51.56%] [G loss: 0.285747]\n",
      "epoch:27 step:25400 [D loss: 0.222863, acc.: 63.28%] [G loss: 0.299064]\n",
      "epoch:27 step:25401 [D loss: 0.254542, acc.: 54.69%] [G loss: 0.281198]\n",
      "epoch:27 step:25402 [D loss: 0.245749, acc.: 54.69%] [G loss: 0.325313]\n",
      "epoch:27 step:25403 [D loss: 0.229834, acc.: 60.16%] [G loss: 0.309177]\n",
      "epoch:27 step:25404 [D loss: 0.249769, acc.: 50.78%] [G loss: 0.305989]\n",
      "epoch:27 step:25405 [D loss: 0.239683, acc.: 57.81%] [G loss: 0.301221]\n",
      "epoch:27 step:25406 [D loss: 0.223456, acc.: 63.28%] [G loss: 0.311705]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:27 step:25407 [D loss: 0.237214, acc.: 57.81%] [G loss: 0.321894]\n",
      "epoch:27 step:25408 [D loss: 0.227856, acc.: 59.38%] [G loss: 0.303950]\n",
      "epoch:27 step:25409 [D loss: 0.257999, acc.: 53.91%] [G loss: 0.285148]\n",
      "epoch:27 step:25410 [D loss: 0.252598, acc.: 54.69%] [G loss: 0.278383]\n",
      "epoch:27 step:25411 [D loss: 0.240241, acc.: 57.03%] [G loss: 0.289024]\n",
      "epoch:27 step:25412 [D loss: 0.234604, acc.: 59.38%] [G loss: 0.300186]\n",
      "epoch:27 step:25413 [D loss: 0.227875, acc.: 57.81%] [G loss: 0.293922]\n",
      "epoch:27 step:25414 [D loss: 0.243959, acc.: 53.12%] [G loss: 0.278405]\n",
      "epoch:27 step:25415 [D loss: 0.262198, acc.: 52.34%] [G loss: 0.281305]\n",
      "epoch:27 step:25416 [D loss: 0.245297, acc.: 53.91%] [G loss: 0.296803]\n",
      "epoch:27 step:25417 [D loss: 0.235499, acc.: 57.03%] [G loss: 0.291814]\n",
      "epoch:27 step:25418 [D loss: 0.229439, acc.: 61.72%] [G loss: 0.312040]\n",
      "epoch:27 step:25419 [D loss: 0.243702, acc.: 53.91%] [G loss: 0.292685]\n",
      "epoch:27 step:25420 [D loss: 0.239852, acc.: 59.38%] [G loss: 0.282573]\n",
      "epoch:27 step:25421 [D loss: 0.253095, acc.: 49.22%] [G loss: 0.297652]\n",
      "epoch:27 step:25422 [D loss: 0.244092, acc.: 57.81%] [G loss: 0.301212]\n",
      "epoch:27 step:25423 [D loss: 0.233902, acc.: 58.59%] [G loss: 0.289600]\n",
      "epoch:27 step:25424 [D loss: 0.237877, acc.: 57.03%] [G loss: 0.289997]\n",
      "epoch:27 step:25425 [D loss: 0.237289, acc.: 60.16%] [G loss: 0.277764]\n",
      "epoch:27 step:25426 [D loss: 0.233236, acc.: 60.94%] [G loss: 0.305101]\n",
      "epoch:27 step:25427 [D loss: 0.252729, acc.: 58.59%] [G loss: 0.305756]\n",
      "epoch:27 step:25428 [D loss: 0.233921, acc.: 59.38%] [G loss: 0.326467]\n",
      "epoch:27 step:25429 [D loss: 0.244332, acc.: 53.12%] [G loss: 0.299923]\n",
      "epoch:27 step:25430 [D loss: 0.237757, acc.: 59.38%] [G loss: 0.308934]\n",
      "epoch:27 step:25431 [D loss: 0.234422, acc.: 59.38%] [G loss: 0.337673]\n",
      "epoch:27 step:25432 [D loss: 0.228353, acc.: 64.84%] [G loss: 0.289061]\n",
      "epoch:27 step:25433 [D loss: 0.238838, acc.: 60.94%] [G loss: 0.302670]\n",
      "epoch:27 step:25434 [D loss: 0.231381, acc.: 64.06%] [G loss: 0.289384]\n",
      "epoch:27 step:25435 [D loss: 0.235657, acc.: 62.50%] [G loss: 0.311010]\n",
      "epoch:27 step:25436 [D loss: 0.236443, acc.: 63.28%] [G loss: 0.327321]\n",
      "epoch:27 step:25437 [D loss: 0.239558, acc.: 55.47%] [G loss: 0.297208]\n",
      "epoch:27 step:25438 [D loss: 0.237747, acc.: 57.81%] [G loss: 0.320245]\n",
      "epoch:27 step:25439 [D loss: 0.233765, acc.: 62.50%] [G loss: 0.336737]\n",
      "epoch:27 step:25440 [D loss: 0.245501, acc.: 55.47%] [G loss: 0.277479]\n",
      "epoch:27 step:25441 [D loss: 0.217415, acc.: 67.97%] [G loss: 0.276553]\n",
      "epoch:27 step:25442 [D loss: 0.245510, acc.: 60.94%] [G loss: 0.297204]\n",
      "epoch:27 step:25443 [D loss: 0.230210, acc.: 61.72%] [G loss: 0.329148]\n",
      "epoch:27 step:25444 [D loss: 0.240317, acc.: 55.47%] [G loss: 0.298183]\n",
      "epoch:27 step:25445 [D loss: 0.242113, acc.: 60.94%] [G loss: 0.294555]\n",
      "epoch:27 step:25446 [D loss: 0.238109, acc.: 60.16%] [G loss: 0.278341]\n",
      "epoch:27 step:25447 [D loss: 0.235262, acc.: 63.28%] [G loss: 0.310853]\n",
      "epoch:27 step:25448 [D loss: 0.239536, acc.: 58.59%] [G loss: 0.288982]\n",
      "epoch:27 step:25449 [D loss: 0.243849, acc.: 56.25%] [G loss: 0.286255]\n",
      "epoch:27 step:25450 [D loss: 0.236825, acc.: 60.94%] [G loss: 0.313828]\n",
      "epoch:27 step:25451 [D loss: 0.255891, acc.: 57.81%] [G loss: 0.290122]\n",
      "epoch:27 step:25452 [D loss: 0.243402, acc.: 57.81%] [G loss: 0.294216]\n",
      "epoch:27 step:25453 [D loss: 0.234557, acc.: 59.38%] [G loss: 0.285201]\n",
      "epoch:27 step:25454 [D loss: 0.231125, acc.: 61.72%] [G loss: 0.304708]\n",
      "epoch:27 step:25455 [D loss: 0.258198, acc.: 55.47%] [G loss: 0.289705]\n",
      "epoch:27 step:25456 [D loss: 0.245922, acc.: 53.91%] [G loss: 0.275226]\n",
      "epoch:27 step:25457 [D loss: 0.231433, acc.: 60.94%] [G loss: 0.268144]\n",
      "epoch:27 step:25458 [D loss: 0.220285, acc.: 58.59%] [G loss: 0.281387]\n",
      "epoch:27 step:25459 [D loss: 0.236739, acc.: 59.38%] [G loss: 0.299391]\n",
      "epoch:27 step:25460 [D loss: 0.235520, acc.: 60.94%] [G loss: 0.292966]\n",
      "epoch:27 step:25461 [D loss: 0.253978, acc.: 48.44%] [G loss: 0.286189]\n",
      "epoch:27 step:25462 [D loss: 0.243625, acc.: 53.91%] [G loss: 0.294534]\n",
      "epoch:27 step:25463 [D loss: 0.223250, acc.: 67.19%] [G loss: 0.315355]\n",
      "epoch:27 step:25464 [D loss: 0.242078, acc.: 60.16%] [G loss: 0.299314]\n",
      "epoch:27 step:25465 [D loss: 0.250255, acc.: 53.12%] [G loss: 0.300467]\n",
      "epoch:27 step:25466 [D loss: 0.242163, acc.: 57.81%] [G loss: 0.303077]\n",
      "epoch:27 step:25467 [D loss: 0.232473, acc.: 62.50%] [G loss: 0.266279]\n",
      "epoch:27 step:25468 [D loss: 0.245160, acc.: 56.25%] [G loss: 0.291390]\n",
      "epoch:27 step:25469 [D loss: 0.243597, acc.: 52.34%] [G loss: 0.281772]\n",
      "epoch:27 step:25470 [D loss: 0.241599, acc.: 56.25%] [G loss: 0.313054]\n",
      "epoch:27 step:25471 [D loss: 0.233603, acc.: 56.25%] [G loss: 0.264315]\n",
      "epoch:27 step:25472 [D loss: 0.242410, acc.: 53.12%] [G loss: 0.264860]\n",
      "epoch:27 step:25473 [D loss: 0.215724, acc.: 69.53%] [G loss: 0.294760]\n",
      "epoch:27 step:25474 [D loss: 0.264372, acc.: 48.44%] [G loss: 0.284407]\n",
      "epoch:27 step:25475 [D loss: 0.247850, acc.: 55.47%] [G loss: 0.313045]\n",
      "epoch:27 step:25476 [D loss: 0.236938, acc.: 62.50%] [G loss: 0.322014]\n",
      "epoch:27 step:25477 [D loss: 0.223705, acc.: 64.06%] [G loss: 0.317455]\n",
      "epoch:27 step:25478 [D loss: 0.237540, acc.: 57.81%] [G loss: 0.308423]\n",
      "epoch:27 step:25479 [D loss: 0.239785, acc.: 57.03%] [G loss: 0.307105]\n",
      "epoch:27 step:25480 [D loss: 0.224768, acc.: 64.84%] [G loss: 0.293277]\n",
      "epoch:27 step:25481 [D loss: 0.245192, acc.: 57.03%] [G loss: 0.326596]\n",
      "epoch:27 step:25482 [D loss: 0.253564, acc.: 53.12%] [G loss: 0.289298]\n",
      "epoch:27 step:25483 [D loss: 0.237397, acc.: 63.28%] [G loss: 0.268393]\n",
      "epoch:27 step:25484 [D loss: 0.228793, acc.: 59.38%] [G loss: 0.299253]\n",
      "epoch:27 step:25485 [D loss: 0.220709, acc.: 67.97%] [G loss: 0.282279]\n",
      "epoch:27 step:25486 [D loss: 0.238351, acc.: 61.72%] [G loss: 0.310699]\n",
      "epoch:27 step:25487 [D loss: 0.275871, acc.: 47.66%] [G loss: 0.291813]\n",
      "epoch:27 step:25488 [D loss: 0.238761, acc.: 59.38%] [G loss: 0.316688]\n",
      "epoch:27 step:25489 [D loss: 0.243157, acc.: 53.12%] [G loss: 0.303042]\n",
      "epoch:27 step:25490 [D loss: 0.258932, acc.: 50.00%] [G loss: 0.314828]\n",
      "epoch:27 step:25491 [D loss: 0.213761, acc.: 68.75%] [G loss: 0.314464]\n",
      "epoch:27 step:25492 [D loss: 0.244320, acc.: 56.25%] [G loss: 0.315277]\n",
      "epoch:27 step:25493 [D loss: 0.248371, acc.: 51.56%] [G loss: 0.297620]\n",
      "epoch:27 step:25494 [D loss: 0.259110, acc.: 48.44%] [G loss: 0.281246]\n",
      "epoch:27 step:25495 [D loss: 0.234863, acc.: 57.81%] [G loss: 0.321045]\n",
      "epoch:27 step:25496 [D loss: 0.218588, acc.: 65.62%] [G loss: 0.314556]\n",
      "epoch:27 step:25497 [D loss: 0.240219, acc.: 57.81%] [G loss: 0.306180]\n",
      "epoch:27 step:25498 [D loss: 0.232388, acc.: 61.72%] [G loss: 0.309582]\n",
      "epoch:27 step:25499 [D loss: 0.238594, acc.: 59.38%] [G loss: 0.291461]\n",
      "epoch:27 step:25500 [D loss: 0.222374, acc.: 61.72%] [G loss: 0.305047]\n",
      "epoch:27 step:25501 [D loss: 0.249633, acc.: 57.03%] [G loss: 0.307248]\n",
      "epoch:27 step:25502 [D loss: 0.248923, acc.: 54.69%] [G loss: 0.322136]\n",
      "epoch:27 step:25503 [D loss: 0.234974, acc.: 59.38%] [G loss: 0.307258]\n",
      "epoch:27 step:25504 [D loss: 0.250447, acc.: 57.81%] [G loss: 0.297246]\n",
      "epoch:27 step:25505 [D loss: 0.260998, acc.: 51.56%] [G loss: 0.294255]\n",
      "epoch:27 step:25506 [D loss: 0.233882, acc.: 59.38%] [G loss: 0.305170]\n",
      "epoch:27 step:25507 [D loss: 0.223148, acc.: 68.75%] [G loss: 0.300126]\n",
      "epoch:27 step:25508 [D loss: 0.240596, acc.: 62.50%] [G loss: 0.336932]\n",
      "epoch:27 step:25509 [D loss: 0.220345, acc.: 66.41%] [G loss: 0.305429]\n",
      "epoch:27 step:25510 [D loss: 0.236518, acc.: 58.59%] [G loss: 0.288786]\n",
      "epoch:27 step:25511 [D loss: 0.257514, acc.: 55.47%] [G loss: 0.285139]\n",
      "epoch:27 step:25512 [D loss: 0.236833, acc.: 61.72%] [G loss: 0.305240]\n",
      "epoch:27 step:25513 [D loss: 0.251633, acc.: 56.25%] [G loss: 0.298057]\n",
      "epoch:27 step:25514 [D loss: 0.241561, acc.: 57.03%] [G loss: 0.307692]\n",
      "epoch:27 step:25515 [D loss: 0.226761, acc.: 62.50%] [G loss: 0.273650]\n",
      "epoch:27 step:25516 [D loss: 0.234692, acc.: 57.03%] [G loss: 0.285050]\n",
      "epoch:27 step:25517 [D loss: 0.228981, acc.: 58.59%] [G loss: 0.332603]\n",
      "epoch:27 step:25518 [D loss: 0.241679, acc.: 58.59%] [G loss: 0.295302]\n",
      "epoch:27 step:25519 [D loss: 0.235246, acc.: 57.81%] [G loss: 0.275802]\n",
      "epoch:27 step:25520 [D loss: 0.223085, acc.: 71.09%] [G loss: 0.300510]\n",
      "epoch:27 step:25521 [D loss: 0.256363, acc.: 52.34%] [G loss: 0.312425]\n",
      "epoch:27 step:25522 [D loss: 0.223059, acc.: 66.41%] [G loss: 0.291285]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:27 step:25523 [D loss: 0.229231, acc.: 61.72%] [G loss: 0.274034]\n",
      "epoch:27 step:25524 [D loss: 0.220135, acc.: 65.62%] [G loss: 0.301135]\n",
      "epoch:27 step:25525 [D loss: 0.229480, acc.: 60.16%] [G loss: 0.289211]\n",
      "epoch:27 step:25526 [D loss: 0.249394, acc.: 55.47%] [G loss: 0.282835]\n",
      "epoch:27 step:25527 [D loss: 0.234503, acc.: 60.16%] [G loss: 0.287346]\n",
      "epoch:27 step:25528 [D loss: 0.241434, acc.: 58.59%] [G loss: 0.326247]\n",
      "epoch:27 step:25529 [D loss: 0.247024, acc.: 56.25%] [G loss: 0.307406]\n",
      "epoch:27 step:25530 [D loss: 0.248056, acc.: 57.03%] [G loss: 0.305739]\n",
      "epoch:27 step:25531 [D loss: 0.256107, acc.: 50.00%] [G loss: 0.286070]\n",
      "epoch:27 step:25532 [D loss: 0.241546, acc.: 57.03%] [G loss: 0.269109]\n",
      "epoch:27 step:25533 [D loss: 0.246620, acc.: 57.03%] [G loss: 0.301004]\n",
      "epoch:27 step:25534 [D loss: 0.254161, acc.: 53.12%] [G loss: 0.268421]\n",
      "epoch:27 step:25535 [D loss: 0.244411, acc.: 56.25%] [G loss: 0.292977]\n",
      "epoch:27 step:25536 [D loss: 0.238717, acc.: 57.03%] [G loss: 0.318174]\n",
      "epoch:27 step:25537 [D loss: 0.244840, acc.: 53.91%] [G loss: 0.293443]\n",
      "epoch:27 step:25538 [D loss: 0.239497, acc.: 61.72%] [G loss: 0.290017]\n",
      "epoch:27 step:25539 [D loss: 0.249609, acc.: 59.38%] [G loss: 0.303607]\n",
      "epoch:27 step:25540 [D loss: 0.232042, acc.: 67.97%] [G loss: 0.288186]\n",
      "epoch:27 step:25541 [D loss: 0.224670, acc.: 62.50%] [G loss: 0.325335]\n",
      "epoch:27 step:25542 [D loss: 0.236364, acc.: 57.03%] [G loss: 0.298810]\n",
      "epoch:27 step:25543 [D loss: 0.246125, acc.: 57.81%] [G loss: 0.282963]\n",
      "epoch:27 step:25544 [D loss: 0.229115, acc.: 64.84%] [G loss: 0.284005]\n",
      "epoch:27 step:25545 [D loss: 0.229961, acc.: 58.59%] [G loss: 0.290580]\n",
      "epoch:27 step:25546 [D loss: 0.229483, acc.: 64.06%] [G loss: 0.297968]\n",
      "epoch:27 step:25547 [D loss: 0.251798, acc.: 53.12%] [G loss: 0.293758]\n",
      "epoch:27 step:25548 [D loss: 0.237855, acc.: 61.72%] [G loss: 0.315807]\n",
      "epoch:27 step:25549 [D loss: 0.253746, acc.: 57.03%] [G loss: 0.284724]\n",
      "epoch:27 step:25550 [D loss: 0.236891, acc.: 62.50%] [G loss: 0.282543]\n",
      "epoch:27 step:25551 [D loss: 0.226566, acc.: 63.28%] [G loss: 0.305562]\n",
      "epoch:27 step:25552 [D loss: 0.240788, acc.: 59.38%] [G loss: 0.294878]\n",
      "epoch:27 step:25553 [D loss: 0.251290, acc.: 52.34%] [G loss: 0.288336]\n",
      "epoch:27 step:25554 [D loss: 0.225193, acc.: 62.50%] [G loss: 0.339031]\n",
      "epoch:27 step:25555 [D loss: 0.234496, acc.: 64.06%] [G loss: 0.299744]\n",
      "epoch:27 step:25556 [D loss: 0.228793, acc.: 65.62%] [G loss: 0.330035]\n",
      "epoch:27 step:25557 [D loss: 0.228959, acc.: 60.94%] [G loss: 0.313657]\n",
      "epoch:27 step:25558 [D loss: 0.233884, acc.: 60.94%] [G loss: 0.299453]\n",
      "epoch:27 step:25559 [D loss: 0.254466, acc.: 53.91%] [G loss: 0.289793]\n",
      "epoch:27 step:25560 [D loss: 0.233414, acc.: 57.81%] [G loss: 0.312338]\n",
      "epoch:27 step:25561 [D loss: 0.258769, acc.: 50.00%] [G loss: 0.293542]\n",
      "epoch:27 step:25562 [D loss: 0.238274, acc.: 59.38%] [G loss: 0.307010]\n",
      "epoch:27 step:25563 [D loss: 0.225596, acc.: 68.75%] [G loss: 0.316369]\n",
      "epoch:27 step:25564 [D loss: 0.247548, acc.: 49.22%] [G loss: 0.292839]\n",
      "epoch:27 step:25565 [D loss: 0.219640, acc.: 64.84%] [G loss: 0.315168]\n",
      "epoch:27 step:25566 [D loss: 0.242960, acc.: 57.81%] [G loss: 0.286744]\n",
      "epoch:27 step:25567 [D loss: 0.233599, acc.: 58.59%] [G loss: 0.294415]\n",
      "epoch:27 step:25568 [D loss: 0.257179, acc.: 53.12%] [G loss: 0.313245]\n",
      "epoch:27 step:25569 [D loss: 0.247504, acc.: 57.03%] [G loss: 0.306687]\n",
      "epoch:27 step:25570 [D loss: 0.226726, acc.: 61.72%] [G loss: 0.302158]\n",
      "epoch:27 step:25571 [D loss: 0.255678, acc.: 55.47%] [G loss: 0.303168]\n",
      "epoch:27 step:25572 [D loss: 0.237950, acc.: 57.81%] [G loss: 0.272708]\n",
      "epoch:27 step:25573 [D loss: 0.229166, acc.: 62.50%] [G loss: 0.306855]\n",
      "epoch:27 step:25574 [D loss: 0.245171, acc.: 53.91%] [G loss: 0.273470]\n",
      "epoch:27 step:25575 [D loss: 0.222968, acc.: 65.62%] [G loss: 0.330583]\n",
      "epoch:27 step:25576 [D loss: 0.236774, acc.: 60.16%] [G loss: 0.309267]\n",
      "epoch:27 step:25577 [D loss: 0.249151, acc.: 56.25%] [G loss: 0.294420]\n",
      "epoch:27 step:25578 [D loss: 0.229195, acc.: 60.94%] [G loss: 0.296530]\n",
      "epoch:27 step:25579 [D loss: 0.240071, acc.: 57.81%] [G loss: 0.268944]\n",
      "epoch:27 step:25580 [D loss: 0.211230, acc.: 70.31%] [G loss: 0.304024]\n",
      "epoch:27 step:25581 [D loss: 0.250436, acc.: 54.69%] [G loss: 0.311324]\n",
      "epoch:27 step:25582 [D loss: 0.233394, acc.: 55.47%] [G loss: 0.318507]\n",
      "epoch:27 step:25583 [D loss: 0.239313, acc.: 53.91%] [G loss: 0.298705]\n",
      "epoch:27 step:25584 [D loss: 0.238425, acc.: 57.81%] [G loss: 0.313390]\n",
      "epoch:27 step:25585 [D loss: 0.257618, acc.: 50.00%] [G loss: 0.284512]\n",
      "epoch:27 step:25586 [D loss: 0.254894, acc.: 50.00%] [G loss: 0.277059]\n",
      "epoch:27 step:25587 [D loss: 0.242777, acc.: 58.59%] [G loss: 0.276756]\n",
      "epoch:27 step:25588 [D loss: 0.225043, acc.: 67.19%] [G loss: 0.305878]\n",
      "epoch:27 step:25589 [D loss: 0.236973, acc.: 61.72%] [G loss: 0.296641]\n",
      "epoch:27 step:25590 [D loss: 0.235834, acc.: 60.16%] [G loss: 0.346890]\n",
      "epoch:27 step:25591 [D loss: 0.252241, acc.: 55.47%] [G loss: 0.305327]\n",
      "epoch:27 step:25592 [D loss: 0.224088, acc.: 56.25%] [G loss: 0.292552]\n",
      "epoch:27 step:25593 [D loss: 0.254833, acc.: 54.69%] [G loss: 0.303049]\n",
      "epoch:27 step:25594 [D loss: 0.242503, acc.: 62.50%] [G loss: 0.301064]\n",
      "epoch:27 step:25595 [D loss: 0.263360, acc.: 43.75%] [G loss: 0.284056]\n",
      "epoch:27 step:25596 [D loss: 0.247704, acc.: 53.12%] [G loss: 0.311096]\n",
      "epoch:27 step:25597 [D loss: 0.264512, acc.: 47.66%] [G loss: 0.273980]\n",
      "epoch:27 step:25598 [D loss: 0.238846, acc.: 56.25%] [G loss: 0.326187]\n",
      "epoch:27 step:25599 [D loss: 0.234889, acc.: 57.81%] [G loss: 0.300485]\n",
      "epoch:27 step:25600 [D loss: 0.226815, acc.: 59.38%] [G loss: 0.315131]\n",
      "epoch:27 step:25601 [D loss: 0.231809, acc.: 64.84%] [G loss: 0.285100]\n",
      "epoch:27 step:25602 [D loss: 0.245341, acc.: 57.81%] [G loss: 0.282148]\n",
      "epoch:27 step:25603 [D loss: 0.230130, acc.: 64.84%] [G loss: 0.292671]\n",
      "epoch:27 step:25604 [D loss: 0.237338, acc.: 52.34%] [G loss: 0.287516]\n",
      "epoch:27 step:25605 [D loss: 0.219590, acc.: 60.16%] [G loss: 0.305833]\n",
      "epoch:27 step:25606 [D loss: 0.227617, acc.: 60.94%] [G loss: 0.339366]\n",
      "epoch:27 step:25607 [D loss: 0.243461, acc.: 58.59%] [G loss: 0.297151]\n",
      "epoch:27 step:25608 [D loss: 0.229505, acc.: 64.84%] [G loss: 0.293119]\n",
      "epoch:27 step:25609 [D loss: 0.228865, acc.: 59.38%] [G loss: 0.300214]\n",
      "epoch:27 step:25610 [D loss: 0.246177, acc.: 57.81%] [G loss: 0.288830]\n",
      "epoch:27 step:25611 [D loss: 0.228377, acc.: 60.94%] [G loss: 0.290203]\n",
      "epoch:27 step:25612 [D loss: 0.234658, acc.: 60.94%] [G loss: 0.317312]\n",
      "epoch:27 step:25613 [D loss: 0.244524, acc.: 57.81%] [G loss: 0.300161]\n",
      "epoch:27 step:25614 [D loss: 0.234818, acc.: 54.69%] [G loss: 0.286674]\n",
      "epoch:27 step:25615 [D loss: 0.269352, acc.: 53.91%] [G loss: 0.283604]\n",
      "epoch:27 step:25616 [D loss: 0.233601, acc.: 63.28%] [G loss: 0.295719]\n",
      "epoch:27 step:25617 [D loss: 0.252195, acc.: 52.34%] [G loss: 0.320334]\n",
      "epoch:27 step:25618 [D loss: 0.242020, acc.: 58.59%] [G loss: 0.308471]\n",
      "epoch:27 step:25619 [D loss: 0.238644, acc.: 59.38%] [G loss: 0.320745]\n",
      "epoch:27 step:25620 [D loss: 0.247807, acc.: 61.72%] [G loss: 0.295791]\n",
      "epoch:27 step:25621 [D loss: 0.251422, acc.: 53.12%] [G loss: 0.329702]\n",
      "epoch:27 step:25622 [D loss: 0.232736, acc.: 62.50%] [G loss: 0.294689]\n",
      "epoch:27 step:25623 [D loss: 0.245375, acc.: 59.38%] [G loss: 0.290822]\n",
      "epoch:27 step:25624 [D loss: 0.228749, acc.: 60.94%] [G loss: 0.300246]\n",
      "epoch:27 step:25625 [D loss: 0.213559, acc.: 67.97%] [G loss: 0.321613]\n",
      "epoch:27 step:25626 [D loss: 0.215067, acc.: 67.97%] [G loss: 0.274089]\n",
      "epoch:27 step:25627 [D loss: 0.240857, acc.: 53.91%] [G loss: 0.287956]\n",
      "epoch:27 step:25628 [D loss: 0.240584, acc.: 51.56%] [G loss: 0.299296]\n",
      "epoch:27 step:25629 [D loss: 0.237645, acc.: 58.59%] [G loss: 0.322906]\n",
      "epoch:27 step:25630 [D loss: 0.227844, acc.: 59.38%] [G loss: 0.307113]\n",
      "epoch:27 step:25631 [D loss: 0.232498, acc.: 59.38%] [G loss: 0.308291]\n",
      "epoch:27 step:25632 [D loss: 0.231031, acc.: 61.72%] [G loss: 0.309145]\n",
      "epoch:27 step:25633 [D loss: 0.246744, acc.: 55.47%] [G loss: 0.288532]\n",
      "epoch:27 step:25634 [D loss: 0.238211, acc.: 57.81%] [G loss: 0.318457]\n",
      "epoch:27 step:25635 [D loss: 0.255544, acc.: 50.00%] [G loss: 0.319827]\n",
      "epoch:27 step:25636 [D loss: 0.231000, acc.: 63.28%] [G loss: 0.307462]\n",
      "epoch:27 step:25637 [D loss: 0.222628, acc.: 63.28%] [G loss: 0.296158]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:27 step:25638 [D loss: 0.240853, acc.: 57.03%] [G loss: 0.299436]\n",
      "epoch:27 step:25639 [D loss: 0.244160, acc.: 60.94%] [G loss: 0.278671]\n",
      "epoch:27 step:25640 [D loss: 0.246486, acc.: 60.16%] [G loss: 0.325081]\n",
      "epoch:27 step:25641 [D loss: 0.233915, acc.: 59.38%] [G loss: 0.349492]\n",
      "epoch:27 step:25642 [D loss: 0.232347, acc.: 63.28%] [G loss: 0.290628]\n",
      "epoch:27 step:25643 [D loss: 0.244092, acc.: 56.25%] [G loss: 0.279234]\n",
      "epoch:27 step:25644 [D loss: 0.232262, acc.: 62.50%] [G loss: 0.302889]\n",
      "epoch:27 step:25645 [D loss: 0.237765, acc.: 60.94%] [G loss: 0.313822]\n",
      "epoch:27 step:25646 [D loss: 0.237438, acc.: 64.84%] [G loss: 0.309079]\n",
      "epoch:27 step:25647 [D loss: 0.237584, acc.: 56.25%] [G loss: 0.290689]\n",
      "epoch:27 step:25648 [D loss: 0.251421, acc.: 58.59%] [G loss: 0.288997]\n",
      "epoch:27 step:25649 [D loss: 0.226628, acc.: 62.50%] [G loss: 0.301469]\n",
      "epoch:27 step:25650 [D loss: 0.248567, acc.: 61.72%] [G loss: 0.297145]\n",
      "epoch:27 step:25651 [D loss: 0.233564, acc.: 60.16%] [G loss: 0.311268]\n",
      "epoch:27 step:25652 [D loss: 0.257193, acc.: 52.34%] [G loss: 0.266256]\n",
      "epoch:27 step:25653 [D loss: 0.240417, acc.: 55.47%] [G loss: 0.315296]\n",
      "epoch:27 step:25654 [D loss: 0.243523, acc.: 60.16%] [G loss: 0.272048]\n",
      "epoch:27 step:25655 [D loss: 0.228927, acc.: 66.41%] [G loss: 0.293490]\n",
      "epoch:27 step:25656 [D loss: 0.247245, acc.: 54.69%] [G loss: 0.273997]\n",
      "epoch:27 step:25657 [D loss: 0.239262, acc.: 53.91%] [G loss: 0.288821]\n",
      "epoch:27 step:25658 [D loss: 0.232651, acc.: 57.81%] [G loss: 0.275410]\n",
      "epoch:27 step:25659 [D loss: 0.234258, acc.: 58.59%] [G loss: 0.286053]\n",
      "epoch:27 step:25660 [D loss: 0.245115, acc.: 59.38%] [G loss: 0.318595]\n",
      "epoch:27 step:25661 [D loss: 0.228660, acc.: 61.72%] [G loss: 0.305519]\n",
      "epoch:27 step:25662 [D loss: 0.241476, acc.: 60.16%] [G loss: 0.300959]\n",
      "epoch:27 step:25663 [D loss: 0.239722, acc.: 57.81%] [G loss: 0.273145]\n",
      "epoch:27 step:25664 [D loss: 0.227431, acc.: 64.06%] [G loss: 0.294073]\n",
      "epoch:27 step:25665 [D loss: 0.234137, acc.: 57.03%] [G loss: 0.338697]\n",
      "epoch:27 step:25666 [D loss: 0.249329, acc.: 52.34%] [G loss: 0.292500]\n",
      "epoch:27 step:25667 [D loss: 0.243272, acc.: 53.91%] [G loss: 0.291394]\n",
      "epoch:27 step:25668 [D loss: 0.228021, acc.: 63.28%] [G loss: 0.322185]\n",
      "epoch:27 step:25669 [D loss: 0.228051, acc.: 64.06%] [G loss: 0.270242]\n",
      "epoch:27 step:25670 [D loss: 0.230514, acc.: 64.06%] [G loss: 0.293462]\n",
      "epoch:27 step:25671 [D loss: 0.241352, acc.: 58.59%] [G loss: 0.316472]\n",
      "epoch:27 step:25672 [D loss: 0.204919, acc.: 67.97%] [G loss: 0.318553]\n",
      "epoch:27 step:25673 [D loss: 0.226416, acc.: 61.72%] [G loss: 0.292686]\n",
      "epoch:27 step:25674 [D loss: 0.243148, acc.: 59.38%] [G loss: 0.279663]\n",
      "epoch:27 step:25675 [D loss: 0.252612, acc.: 55.47%] [G loss: 0.286474]\n",
      "epoch:27 step:25676 [D loss: 0.229271, acc.: 67.97%] [G loss: 0.288998]\n",
      "epoch:27 step:25677 [D loss: 0.241969, acc.: 60.16%] [G loss: 0.299202]\n",
      "epoch:27 step:25678 [D loss: 0.237469, acc.: 60.94%] [G loss: 0.313394]\n",
      "epoch:27 step:25679 [D loss: 0.233689, acc.: 58.59%] [G loss: 0.299044]\n",
      "epoch:27 step:25680 [D loss: 0.236082, acc.: 58.59%] [G loss: 0.297899]\n",
      "epoch:27 step:25681 [D loss: 0.260828, acc.: 50.00%] [G loss: 0.271399]\n",
      "epoch:27 step:25682 [D loss: 0.253319, acc.: 55.47%] [G loss: 0.307460]\n",
      "epoch:27 step:25683 [D loss: 0.236639, acc.: 60.94%] [G loss: 0.335160]\n",
      "epoch:27 step:25684 [D loss: 0.253058, acc.: 55.47%] [G loss: 0.297937]\n",
      "epoch:27 step:25685 [D loss: 0.233001, acc.: 58.59%] [G loss: 0.298815]\n",
      "epoch:27 step:25686 [D loss: 0.229276, acc.: 68.75%] [G loss: 0.337861]\n",
      "epoch:27 step:25687 [D loss: 0.255739, acc.: 53.12%] [G loss: 0.295399]\n",
      "epoch:27 step:25688 [D loss: 0.216930, acc.: 67.19%] [G loss: 0.306536]\n",
      "epoch:27 step:25689 [D loss: 0.249323, acc.: 53.91%] [G loss: 0.309257]\n",
      "epoch:27 step:25690 [D loss: 0.219495, acc.: 65.62%] [G loss: 0.310755]\n",
      "epoch:27 step:25691 [D loss: 0.237349, acc.: 57.81%] [G loss: 0.294776]\n",
      "epoch:27 step:25692 [D loss: 0.223617, acc.: 63.28%] [G loss: 0.310004]\n",
      "epoch:27 step:25693 [D loss: 0.243359, acc.: 60.94%] [G loss: 0.300266]\n",
      "epoch:27 step:25694 [D loss: 0.246277, acc.: 57.81%] [G loss: 0.314089]\n",
      "epoch:27 step:25695 [D loss: 0.235776, acc.: 60.94%] [G loss: 0.325160]\n",
      "epoch:27 step:25696 [D loss: 0.251089, acc.: 51.56%] [G loss: 0.328158]\n",
      "epoch:27 step:25697 [D loss: 0.253614, acc.: 60.16%] [G loss: 0.282861]\n",
      "epoch:27 step:25698 [D loss: 0.239162, acc.: 56.25%] [G loss: 0.302629]\n",
      "epoch:27 step:25699 [D loss: 0.241816, acc.: 54.69%] [G loss: 0.285717]\n",
      "epoch:27 step:25700 [D loss: 0.233803, acc.: 60.16%] [G loss: 0.296893]\n",
      "epoch:27 step:25701 [D loss: 0.245241, acc.: 46.88%] [G loss: 0.301083]\n",
      "epoch:27 step:25702 [D loss: 0.244679, acc.: 57.81%] [G loss: 0.304450]\n",
      "epoch:27 step:25703 [D loss: 0.239532, acc.: 58.59%] [G loss: 0.295244]\n",
      "epoch:27 step:25704 [D loss: 0.237884, acc.: 60.94%] [G loss: 0.319178]\n",
      "epoch:27 step:25705 [D loss: 0.255707, acc.: 56.25%] [G loss: 0.288713]\n",
      "epoch:27 step:25706 [D loss: 0.238603, acc.: 58.59%] [G loss: 0.323252]\n",
      "epoch:27 step:25707 [D loss: 0.231052, acc.: 63.28%] [G loss: 0.285507]\n",
      "epoch:27 step:25708 [D loss: 0.237360, acc.: 62.50%] [G loss: 0.303721]\n",
      "epoch:27 step:25709 [D loss: 0.236589, acc.: 57.81%] [G loss: 0.297236]\n",
      "epoch:27 step:25710 [D loss: 0.238423, acc.: 53.12%] [G loss: 0.307125]\n",
      "epoch:27 step:25711 [D loss: 0.251572, acc.: 53.12%] [G loss: 0.293538]\n",
      "epoch:27 step:25712 [D loss: 0.262232, acc.: 51.56%] [G loss: 0.274779]\n",
      "epoch:27 step:25713 [D loss: 0.253237, acc.: 58.59%] [G loss: 0.326981]\n",
      "epoch:27 step:25714 [D loss: 0.234981, acc.: 62.50%] [G loss: 0.288548]\n",
      "epoch:27 step:25715 [D loss: 0.239186, acc.: 52.34%] [G loss: 0.299313]\n",
      "epoch:27 step:25716 [D loss: 0.233988, acc.: 57.03%] [G loss: 0.304377]\n",
      "epoch:27 step:25717 [D loss: 0.247668, acc.: 53.12%] [G loss: 0.275687]\n",
      "epoch:27 step:25718 [D loss: 0.246047, acc.: 55.47%] [G loss: 0.269635]\n",
      "epoch:27 step:25719 [D loss: 0.246081, acc.: 51.56%] [G loss: 0.305650]\n",
      "epoch:27 step:25720 [D loss: 0.253179, acc.: 56.25%] [G loss: 0.282102]\n",
      "epoch:27 step:25721 [D loss: 0.238380, acc.: 61.72%] [G loss: 0.286210]\n",
      "epoch:27 step:25722 [D loss: 0.230451, acc.: 64.06%] [G loss: 0.298477]\n",
      "epoch:27 step:25723 [D loss: 0.248576, acc.: 57.81%] [G loss: 0.299415]\n",
      "epoch:27 step:25724 [D loss: 0.250915, acc.: 57.81%] [G loss: 0.284175]\n",
      "epoch:27 step:25725 [D loss: 0.254472, acc.: 58.59%] [G loss: 0.312515]\n",
      "epoch:27 step:25726 [D loss: 0.250310, acc.: 53.12%] [G loss: 0.316828]\n",
      "epoch:27 step:25727 [D loss: 0.248424, acc.: 53.91%] [G loss: 0.302811]\n",
      "epoch:27 step:25728 [D loss: 0.231867, acc.: 61.72%] [G loss: 0.313382]\n",
      "epoch:27 step:25729 [D loss: 0.241586, acc.: 57.03%] [G loss: 0.312567]\n",
      "epoch:27 step:25730 [D loss: 0.226065, acc.: 61.72%] [G loss: 0.297238]\n",
      "epoch:27 step:25731 [D loss: 0.237223, acc.: 62.50%] [G loss: 0.298424]\n",
      "epoch:27 step:25732 [D loss: 0.252014, acc.: 53.12%] [G loss: 0.320567]\n",
      "epoch:27 step:25733 [D loss: 0.237206, acc.: 53.12%] [G loss: 0.291118]\n",
      "epoch:27 step:25734 [D loss: 0.243975, acc.: 57.03%] [G loss: 0.310612]\n",
      "epoch:27 step:25735 [D loss: 0.244772, acc.: 54.69%] [G loss: 0.277645]\n",
      "epoch:27 step:25736 [D loss: 0.244671, acc.: 55.47%] [G loss: 0.320662]\n",
      "epoch:27 step:25737 [D loss: 0.233500, acc.: 58.59%] [G loss: 0.316054]\n",
      "epoch:27 step:25738 [D loss: 0.233094, acc.: 61.72%] [G loss: 0.333164]\n",
      "epoch:27 step:25739 [D loss: 0.244693, acc.: 57.03%] [G loss: 0.323813]\n",
      "epoch:27 step:25740 [D loss: 0.258221, acc.: 53.12%] [G loss: 0.298732]\n",
      "epoch:27 step:25741 [D loss: 0.241302, acc.: 61.72%] [G loss: 0.316522]\n",
      "epoch:27 step:25742 [D loss: 0.220648, acc.: 61.72%] [G loss: 0.308813]\n",
      "epoch:27 step:25743 [D loss: 0.240326, acc.: 61.72%] [G loss: 0.301065]\n",
      "epoch:27 step:25744 [D loss: 0.231696, acc.: 59.38%] [G loss: 0.300004]\n",
      "epoch:27 step:25745 [D loss: 0.234060, acc.: 60.16%] [G loss: 0.318290]\n",
      "epoch:27 step:25746 [D loss: 0.229076, acc.: 56.25%] [G loss: 0.283556]\n",
      "epoch:27 step:25747 [D loss: 0.249112, acc.: 53.12%] [G loss: 0.283798]\n",
      "epoch:27 step:25748 [D loss: 0.236187, acc.: 57.81%] [G loss: 0.311043]\n",
      "epoch:27 step:25749 [D loss: 0.244116, acc.: 55.47%] [G loss: 0.323561]\n",
      "epoch:27 step:25750 [D loss: 0.214757, acc.: 66.41%] [G loss: 0.304581]\n",
      "epoch:27 step:25751 [D loss: 0.252470, acc.: 53.91%] [G loss: 0.285240]\n",
      "epoch:27 step:25752 [D loss: 0.227109, acc.: 62.50%] [G loss: 0.331781]\n",
      "epoch:27 step:25753 [D loss: 0.244328, acc.: 60.16%] [G loss: 0.313955]\n",
      "epoch:27 step:25754 [D loss: 0.240274, acc.: 57.03%] [G loss: 0.291366]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:27 step:25755 [D loss: 0.244589, acc.: 53.91%] [G loss: 0.269822]\n",
      "epoch:27 step:25756 [D loss: 0.242203, acc.: 62.50%] [G loss: 0.275716]\n",
      "epoch:27 step:25757 [D loss: 0.234963, acc.: 57.81%] [G loss: 0.287008]\n",
      "epoch:27 step:25758 [D loss: 0.245299, acc.: 55.47%] [G loss: 0.285484]\n",
      "epoch:27 step:25759 [D loss: 0.237355, acc.: 60.16%] [G loss: 0.288836]\n",
      "epoch:27 step:25760 [D loss: 0.242981, acc.: 58.59%] [G loss: 0.298330]\n",
      "epoch:27 step:25761 [D loss: 0.236547, acc.: 60.94%] [G loss: 0.311428]\n",
      "epoch:27 step:25762 [D loss: 0.246166, acc.: 54.69%] [G loss: 0.288444]\n",
      "epoch:27 step:25763 [D loss: 0.231937, acc.: 64.84%] [G loss: 0.335146]\n",
      "epoch:27 step:25764 [D loss: 0.267074, acc.: 51.56%] [G loss: 0.276786]\n",
      "epoch:27 step:25765 [D loss: 0.257079, acc.: 57.03%] [G loss: 0.287077]\n",
      "epoch:27 step:25766 [D loss: 0.246496, acc.: 54.69%] [G loss: 0.312750]\n",
      "epoch:27 step:25767 [D loss: 0.236059, acc.: 63.28%] [G loss: 0.300368]\n",
      "epoch:27 step:25768 [D loss: 0.262671, acc.: 51.56%] [G loss: 0.296710]\n",
      "epoch:27 step:25769 [D loss: 0.254976, acc.: 54.69%] [G loss: 0.281481]\n",
      "epoch:27 step:25770 [D loss: 0.239538, acc.: 57.03%] [G loss: 0.282656]\n",
      "epoch:27 step:25771 [D loss: 0.233056, acc.: 64.84%] [G loss: 0.325608]\n",
      "epoch:27 step:25772 [D loss: 0.244551, acc.: 57.03%] [G loss: 0.317785]\n",
      "epoch:27 step:25773 [D loss: 0.236274, acc.: 56.25%] [G loss: 0.305747]\n",
      "epoch:27 step:25774 [D loss: 0.243003, acc.: 60.94%] [G loss: 0.287254]\n",
      "epoch:27 step:25775 [D loss: 0.244422, acc.: 59.38%] [G loss: 0.276574]\n",
      "epoch:27 step:25776 [D loss: 0.243974, acc.: 58.59%] [G loss: 0.297940]\n",
      "epoch:27 step:25777 [D loss: 0.230032, acc.: 60.94%] [G loss: 0.303245]\n",
      "epoch:27 step:25778 [D loss: 0.255334, acc.: 53.12%] [G loss: 0.322055]\n",
      "epoch:27 step:25779 [D loss: 0.242249, acc.: 53.12%] [G loss: 0.279252]\n",
      "epoch:27 step:25780 [D loss: 0.244087, acc.: 54.69%] [G loss: 0.284877]\n",
      "epoch:27 step:25781 [D loss: 0.236140, acc.: 55.47%] [G loss: 0.296536]\n",
      "epoch:27 step:25782 [D loss: 0.250824, acc.: 57.03%] [G loss: 0.313327]\n",
      "epoch:27 step:25783 [D loss: 0.214068, acc.: 69.53%] [G loss: 0.307405]\n",
      "epoch:27 step:25784 [D loss: 0.256175, acc.: 51.56%] [G loss: 0.315570]\n",
      "epoch:27 step:25785 [D loss: 0.229301, acc.: 63.28%] [G loss: 0.338708]\n",
      "epoch:27 step:25786 [D loss: 0.239057, acc.: 57.03%] [G loss: 0.337470]\n",
      "epoch:27 step:25787 [D loss: 0.248755, acc.: 53.12%] [G loss: 0.301719]\n",
      "epoch:27 step:25788 [D loss: 0.227184, acc.: 64.84%] [G loss: 0.278432]\n",
      "epoch:27 step:25789 [D loss: 0.221403, acc.: 62.50%] [G loss: 0.326347]\n",
      "epoch:27 step:25790 [D loss: 0.239683, acc.: 62.50%] [G loss: 0.310215]\n",
      "epoch:27 step:25791 [D loss: 0.238855, acc.: 60.94%] [G loss: 0.289441]\n",
      "epoch:27 step:25792 [D loss: 0.232730, acc.: 57.81%] [G loss: 0.332285]\n",
      "epoch:27 step:25793 [D loss: 0.231264, acc.: 60.94%] [G loss: 0.312340]\n",
      "epoch:27 step:25794 [D loss: 0.242016, acc.: 58.59%] [G loss: 0.337016]\n",
      "epoch:27 step:25795 [D loss: 0.247296, acc.: 50.78%] [G loss: 0.304043]\n",
      "epoch:27 step:25796 [D loss: 0.240733, acc.: 57.03%] [G loss: 0.296091]\n",
      "epoch:27 step:25797 [D loss: 0.253477, acc.: 48.44%] [G loss: 0.286019]\n",
      "epoch:27 step:25798 [D loss: 0.254753, acc.: 53.12%] [G loss: 0.293552]\n",
      "epoch:27 step:25799 [D loss: 0.236291, acc.: 61.72%] [G loss: 0.287465]\n",
      "epoch:27 step:25800 [D loss: 0.239019, acc.: 58.59%] [G loss: 0.280609]\n",
      "epoch:27 step:25801 [D loss: 0.235522, acc.: 60.94%] [G loss: 0.296291]\n",
      "epoch:27 step:25802 [D loss: 0.227046, acc.: 65.62%] [G loss: 0.319146]\n",
      "epoch:27 step:25803 [D loss: 0.237342, acc.: 59.38%] [G loss: 0.299531]\n",
      "epoch:27 step:25804 [D loss: 0.259031, acc.: 51.56%] [G loss: 0.271415]\n",
      "epoch:27 step:25805 [D loss: 0.259418, acc.: 52.34%] [G loss: 0.329842]\n",
      "epoch:27 step:25806 [D loss: 0.240048, acc.: 56.25%] [G loss: 0.287529]\n",
      "epoch:27 step:25807 [D loss: 0.253934, acc.: 51.56%] [G loss: 0.337370]\n",
      "epoch:27 step:25808 [D loss: 0.229177, acc.: 57.81%] [G loss: 0.285164]\n",
      "epoch:27 step:25809 [D loss: 0.221241, acc.: 62.50%] [G loss: 0.299140]\n",
      "epoch:27 step:25810 [D loss: 0.232866, acc.: 60.16%] [G loss: 0.302819]\n",
      "epoch:27 step:25811 [D loss: 0.233911, acc.: 58.59%] [G loss: 0.317782]\n",
      "epoch:27 step:25812 [D loss: 0.221571, acc.: 66.41%] [G loss: 0.329292]\n",
      "epoch:27 step:25813 [D loss: 0.241834, acc.: 57.81%] [G loss: 0.287803]\n",
      "epoch:27 step:25814 [D loss: 0.220465, acc.: 62.50%] [G loss: 0.293912]\n",
      "epoch:27 step:25815 [D loss: 0.244382, acc.: 57.03%] [G loss: 0.295574]\n",
      "epoch:27 step:25816 [D loss: 0.231564, acc.: 61.72%] [G loss: 0.293610]\n",
      "epoch:27 step:25817 [D loss: 0.226321, acc.: 64.84%] [G loss: 0.288159]\n",
      "epoch:27 step:25818 [D loss: 0.245551, acc.: 54.69%] [G loss: 0.292544]\n",
      "epoch:27 step:25819 [D loss: 0.228125, acc.: 60.16%] [G loss: 0.316895]\n",
      "epoch:27 step:25820 [D loss: 0.242723, acc.: 57.81%] [G loss: 0.298408]\n",
      "epoch:27 step:25821 [D loss: 0.225522, acc.: 62.50%] [G loss: 0.292417]\n",
      "epoch:27 step:25822 [D loss: 0.237240, acc.: 60.16%] [G loss: 0.285766]\n",
      "epoch:27 step:25823 [D loss: 0.218529, acc.: 70.31%] [G loss: 0.333903]\n",
      "epoch:27 step:25824 [D loss: 0.232159, acc.: 58.59%] [G loss: 0.300399]\n",
      "epoch:27 step:25825 [D loss: 0.240977, acc.: 58.59%] [G loss: 0.312732]\n",
      "epoch:27 step:25826 [D loss: 0.253339, acc.: 53.91%] [G loss: 0.301135]\n",
      "epoch:27 step:25827 [D loss: 0.237067, acc.: 57.81%] [G loss: 0.297551]\n",
      "epoch:27 step:25828 [D loss: 0.228211, acc.: 64.06%] [G loss: 0.294120]\n",
      "epoch:27 step:25829 [D loss: 0.233779, acc.: 60.94%] [G loss: 0.301387]\n",
      "epoch:27 step:25830 [D loss: 0.237520, acc.: 62.50%] [G loss: 0.339106]\n",
      "epoch:27 step:25831 [D loss: 0.225373, acc.: 61.72%] [G loss: 0.311784]\n",
      "epoch:27 step:25832 [D loss: 0.231308, acc.: 64.06%] [G loss: 0.302142]\n",
      "epoch:27 step:25833 [D loss: 0.238511, acc.: 57.81%] [G loss: 0.297699]\n",
      "epoch:27 step:25834 [D loss: 0.235987, acc.: 57.03%] [G loss: 0.302064]\n",
      "epoch:27 step:25835 [D loss: 0.243166, acc.: 56.25%] [G loss: 0.293984]\n",
      "epoch:27 step:25836 [D loss: 0.246059, acc.: 59.38%] [G loss: 0.290813]\n",
      "epoch:27 step:25837 [D loss: 0.250899, acc.: 52.34%] [G loss: 0.289960]\n",
      "epoch:27 step:25838 [D loss: 0.234880, acc.: 58.59%] [G loss: 0.299712]\n",
      "epoch:27 step:25839 [D loss: 0.227026, acc.: 63.28%] [G loss: 0.303712]\n",
      "epoch:27 step:25840 [D loss: 0.233207, acc.: 59.38%] [G loss: 0.278304]\n",
      "epoch:27 step:25841 [D loss: 0.227917, acc.: 64.84%] [G loss: 0.315998]\n",
      "epoch:27 step:25842 [D loss: 0.229231, acc.: 63.28%] [G loss: 0.280749]\n",
      "epoch:27 step:25843 [D loss: 0.231637, acc.: 64.84%] [G loss: 0.342554]\n",
      "epoch:27 step:25844 [D loss: 0.239535, acc.: 56.25%] [G loss: 0.309780]\n",
      "epoch:27 step:25845 [D loss: 0.254874, acc.: 53.91%] [G loss: 0.288250]\n",
      "epoch:27 step:25846 [D loss: 0.233904, acc.: 60.16%] [G loss: 0.279074]\n",
      "epoch:27 step:25847 [D loss: 0.259621, acc.: 52.34%] [G loss: 0.308821]\n",
      "epoch:27 step:25848 [D loss: 0.229023, acc.: 64.06%] [G loss: 0.300128]\n",
      "epoch:27 step:25849 [D loss: 0.240829, acc.: 53.12%] [G loss: 0.308330]\n",
      "epoch:27 step:25850 [D loss: 0.248718, acc.: 55.47%] [G loss: 0.308169]\n",
      "epoch:27 step:25851 [D loss: 0.230578, acc.: 59.38%] [G loss: 0.298882]\n",
      "epoch:27 step:25852 [D loss: 0.250690, acc.: 53.12%] [G loss: 0.311354]\n",
      "epoch:27 step:25853 [D loss: 0.246662, acc.: 53.91%] [G loss: 0.293735]\n",
      "epoch:27 step:25854 [D loss: 0.224567, acc.: 65.62%] [G loss: 0.304457]\n",
      "epoch:27 step:25855 [D loss: 0.252494, acc.: 50.00%] [G loss: 0.296546]\n",
      "epoch:27 step:25856 [D loss: 0.230988, acc.: 62.50%] [G loss: 0.340038]\n",
      "epoch:27 step:25857 [D loss: 0.244692, acc.: 51.56%] [G loss: 0.330916]\n",
      "epoch:27 step:25858 [D loss: 0.239635, acc.: 60.94%] [G loss: 0.332556]\n",
      "epoch:27 step:25859 [D loss: 0.229388, acc.: 63.28%] [G loss: 0.298268]\n",
      "epoch:27 step:25860 [D loss: 0.226464, acc.: 67.97%] [G loss: 0.298478]\n",
      "epoch:27 step:25861 [D loss: 0.239906, acc.: 59.38%] [G loss: 0.321363]\n",
      "epoch:27 step:25862 [D loss: 0.246997, acc.: 55.47%] [G loss: 0.296488]\n",
      "epoch:27 step:25863 [D loss: 0.236146, acc.: 56.25%] [G loss: 0.351600]\n",
      "epoch:27 step:25864 [D loss: 0.231929, acc.: 60.94%] [G loss: 0.318540]\n",
      "epoch:27 step:25865 [D loss: 0.235285, acc.: 62.50%] [G loss: 0.281941]\n",
      "epoch:27 step:25866 [D loss: 0.227216, acc.: 62.50%] [G loss: 0.306267]\n",
      "epoch:27 step:25867 [D loss: 0.241953, acc.: 61.72%] [G loss: 0.311527]\n",
      "epoch:27 step:25868 [D loss: 0.230851, acc.: 57.03%] [G loss: 0.285177]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:27 step:25869 [D loss: 0.264258, acc.: 49.22%] [G loss: 0.286639]\n",
      "epoch:27 step:25870 [D loss: 0.231664, acc.: 58.59%] [G loss: 0.304489]\n",
      "epoch:27 step:25871 [D loss: 0.211046, acc.: 67.97%] [G loss: 0.304917]\n",
      "epoch:27 step:25872 [D loss: 0.241487, acc.: 56.25%] [G loss: 0.316837]\n",
      "epoch:27 step:25873 [D loss: 0.215840, acc.: 66.41%] [G loss: 0.306015]\n",
      "epoch:27 step:25874 [D loss: 0.243871, acc.: 56.25%] [G loss: 0.313536]\n",
      "epoch:27 step:25875 [D loss: 0.212248, acc.: 67.19%] [G loss: 0.314725]\n",
      "epoch:27 step:25876 [D loss: 0.223726, acc.: 62.50%] [G loss: 0.347062]\n",
      "epoch:27 step:25877 [D loss: 0.234153, acc.: 61.72%] [G loss: 0.273428]\n",
      "epoch:27 step:25878 [D loss: 0.262373, acc.: 45.31%] [G loss: 0.292048]\n",
      "epoch:27 step:25879 [D loss: 0.229663, acc.: 63.28%] [G loss: 0.307494]\n",
      "epoch:27 step:25880 [D loss: 0.249207, acc.: 53.12%] [G loss: 0.306405]\n",
      "epoch:27 step:25881 [D loss: 0.245258, acc.: 54.69%] [G loss: 0.317676]\n",
      "epoch:27 step:25882 [D loss: 0.242146, acc.: 57.03%] [G loss: 0.299721]\n",
      "epoch:27 step:25883 [D loss: 0.233690, acc.: 60.16%] [G loss: 0.300655]\n",
      "epoch:27 step:25884 [D loss: 0.241425, acc.: 55.47%] [G loss: 0.279324]\n",
      "epoch:27 step:25885 [D loss: 0.231350, acc.: 60.94%] [G loss: 0.287619]\n",
      "epoch:27 step:25886 [D loss: 0.221160, acc.: 67.97%] [G loss: 0.323249]\n",
      "epoch:27 step:25887 [D loss: 0.239142, acc.: 57.03%] [G loss: 0.301373]\n",
      "epoch:27 step:25888 [D loss: 0.254180, acc.: 53.12%] [G loss: 0.281951]\n",
      "epoch:27 step:25889 [D loss: 0.237797, acc.: 55.47%] [G loss: 0.282695]\n",
      "epoch:27 step:25890 [D loss: 0.225923, acc.: 62.50%] [G loss: 0.323921]\n",
      "epoch:27 step:25891 [D loss: 0.238674, acc.: 59.38%] [G loss: 0.303431]\n",
      "epoch:27 step:25892 [D loss: 0.248093, acc.: 57.03%] [G loss: 0.290801]\n",
      "epoch:27 step:25893 [D loss: 0.242076, acc.: 58.59%] [G loss: 0.310057]\n",
      "epoch:27 step:25894 [D loss: 0.241730, acc.: 60.16%] [G loss: 0.301168]\n",
      "epoch:27 step:25895 [D loss: 0.236459, acc.: 61.72%] [G loss: 0.323715]\n",
      "epoch:27 step:25896 [D loss: 0.238423, acc.: 55.47%] [G loss: 0.296206]\n",
      "epoch:27 step:25897 [D loss: 0.227847, acc.: 58.59%] [G loss: 0.308226]\n",
      "epoch:27 step:25898 [D loss: 0.232287, acc.: 62.50%] [G loss: 0.282503]\n",
      "epoch:27 step:25899 [D loss: 0.241415, acc.: 56.25%] [G loss: 0.276001]\n",
      "epoch:27 step:25900 [D loss: 0.256047, acc.: 53.91%] [G loss: 0.316963]\n",
      "epoch:27 step:25901 [D loss: 0.258340, acc.: 53.12%] [G loss: 0.277026]\n",
      "epoch:27 step:25902 [D loss: 0.249703, acc.: 57.03%] [G loss: 0.319564]\n",
      "epoch:27 step:25903 [D loss: 0.240037, acc.: 57.03%] [G loss: 0.288246]\n",
      "epoch:27 step:25904 [D loss: 0.219244, acc.: 67.19%] [G loss: 0.309276]\n",
      "epoch:27 step:25905 [D loss: 0.251821, acc.: 58.59%] [G loss: 0.276458]\n",
      "epoch:27 step:25906 [D loss: 0.226269, acc.: 67.97%] [G loss: 0.293581]\n",
      "epoch:27 step:25907 [D loss: 0.229835, acc.: 62.50%] [G loss: 0.314259]\n",
      "epoch:27 step:25908 [D loss: 0.231790, acc.: 64.84%] [G loss: 0.292219]\n",
      "epoch:27 step:25909 [D loss: 0.235877, acc.: 59.38%] [G loss: 0.304438]\n",
      "epoch:27 step:25910 [D loss: 0.238499, acc.: 57.03%] [G loss: 0.319251]\n",
      "epoch:27 step:25911 [D loss: 0.238407, acc.: 56.25%] [G loss: 0.281364]\n",
      "epoch:27 step:25912 [D loss: 0.239685, acc.: 60.16%] [G loss: 0.318743]\n",
      "epoch:27 step:25913 [D loss: 0.219707, acc.: 67.19%] [G loss: 0.273390]\n",
      "epoch:27 step:25914 [D loss: 0.241275, acc.: 55.47%] [G loss: 0.286912]\n",
      "epoch:27 step:25915 [D loss: 0.223121, acc.: 64.84%] [G loss: 0.304810]\n",
      "epoch:27 step:25916 [D loss: 0.239746, acc.: 61.72%] [G loss: 0.316895]\n",
      "epoch:27 step:25917 [D loss: 0.226686, acc.: 66.41%] [G loss: 0.279306]\n",
      "epoch:27 step:25918 [D loss: 0.234725, acc.: 60.16%] [G loss: 0.282936]\n",
      "epoch:27 step:25919 [D loss: 0.255626, acc.: 50.00%] [G loss: 0.341245]\n",
      "epoch:27 step:25920 [D loss: 0.244992, acc.: 56.25%] [G loss: 0.277290]\n",
      "epoch:27 step:25921 [D loss: 0.249480, acc.: 57.81%] [G loss: 0.304650]\n",
      "epoch:27 step:25922 [D loss: 0.251043, acc.: 55.47%] [G loss: 0.332028]\n",
      "epoch:27 step:25923 [D loss: 0.245627, acc.: 58.59%] [G loss: 0.314294]\n",
      "epoch:27 step:25924 [D loss: 0.229468, acc.: 61.72%] [G loss: 0.320311]\n",
      "epoch:27 step:25925 [D loss: 0.237030, acc.: 57.81%] [G loss: 0.271641]\n",
      "epoch:27 step:25926 [D loss: 0.247927, acc.: 51.56%] [G loss: 0.333504]\n",
      "epoch:27 step:25927 [D loss: 0.238804, acc.: 63.28%] [G loss: 0.307217]\n",
      "epoch:27 step:25928 [D loss: 0.249331, acc.: 56.25%] [G loss: 0.300282]\n",
      "epoch:27 step:25929 [D loss: 0.240259, acc.: 60.16%] [G loss: 0.285053]\n",
      "epoch:27 step:25930 [D loss: 0.235454, acc.: 59.38%] [G loss: 0.308904]\n",
      "epoch:27 step:25931 [D loss: 0.219897, acc.: 66.41%] [G loss: 0.313393]\n",
      "epoch:27 step:25932 [D loss: 0.210687, acc.: 69.53%] [G loss: 0.300504]\n",
      "epoch:27 step:25933 [D loss: 0.230889, acc.: 60.16%] [G loss: 0.300419]\n",
      "epoch:27 step:25934 [D loss: 0.256896, acc.: 46.88%] [G loss: 0.314756]\n",
      "epoch:27 step:25935 [D loss: 0.241404, acc.: 60.16%] [G loss: 0.297845]\n",
      "epoch:27 step:25936 [D loss: 0.227511, acc.: 59.38%] [G loss: 0.302584]\n",
      "epoch:27 step:25937 [D loss: 0.241550, acc.: 56.25%] [G loss: 0.259001]\n",
      "epoch:27 step:25938 [D loss: 0.242985, acc.: 60.94%] [G loss: 0.309718]\n",
      "epoch:27 step:25939 [D loss: 0.231207, acc.: 60.94%] [G loss: 0.325225]\n",
      "epoch:27 step:25940 [D loss: 0.232036, acc.: 60.94%] [G loss: 0.290917]\n",
      "epoch:27 step:25941 [D loss: 0.248299, acc.: 54.69%] [G loss: 0.290388]\n",
      "epoch:27 step:25942 [D loss: 0.245929, acc.: 58.59%] [G loss: 0.313487]\n",
      "epoch:27 step:25943 [D loss: 0.233086, acc.: 60.94%] [G loss: 0.290512]\n",
      "epoch:27 step:25944 [D loss: 0.248190, acc.: 57.03%] [G loss: 0.308999]\n",
      "epoch:27 step:25945 [D loss: 0.243122, acc.: 56.25%] [G loss: 0.279232]\n",
      "epoch:27 step:25946 [D loss: 0.242262, acc.: 54.69%] [G loss: 0.297747]\n",
      "epoch:27 step:25947 [D loss: 0.220908, acc.: 67.19%] [G loss: 0.293736]\n",
      "epoch:27 step:25948 [D loss: 0.235842, acc.: 56.25%] [G loss: 0.301077]\n",
      "epoch:27 step:25949 [D loss: 0.223625, acc.: 65.62%] [G loss: 0.325497]\n",
      "epoch:27 step:25950 [D loss: 0.250994, acc.: 52.34%] [G loss: 0.296819]\n",
      "epoch:27 step:25951 [D loss: 0.243531, acc.: 54.69%] [G loss: 0.290829]\n",
      "epoch:27 step:25952 [D loss: 0.234626, acc.: 58.59%] [G loss: 0.313599]\n",
      "epoch:27 step:25953 [D loss: 0.237050, acc.: 58.59%] [G loss: 0.295301]\n",
      "epoch:27 step:25954 [D loss: 0.237806, acc.: 53.12%] [G loss: 0.328391]\n",
      "epoch:27 step:25955 [D loss: 0.234928, acc.: 60.16%] [G loss: 0.307133]\n",
      "epoch:27 step:25956 [D loss: 0.239163, acc.: 62.50%] [G loss: 0.286506]\n",
      "epoch:27 step:25957 [D loss: 0.232496, acc.: 60.94%] [G loss: 0.272446]\n",
      "epoch:27 step:25958 [D loss: 0.238284, acc.: 61.72%] [G loss: 0.306694]\n",
      "epoch:27 step:25959 [D loss: 0.249354, acc.: 58.59%] [G loss: 0.273106]\n",
      "epoch:27 step:25960 [D loss: 0.233965, acc.: 61.72%] [G loss: 0.294365]\n",
      "epoch:27 step:25961 [D loss: 0.258681, acc.: 53.91%] [G loss: 0.270614]\n",
      "epoch:27 step:25962 [D loss: 0.268674, acc.: 47.66%] [G loss: 0.287608]\n",
      "epoch:27 step:25963 [D loss: 0.229121, acc.: 61.72%] [G loss: 0.310263]\n",
      "epoch:27 step:25964 [D loss: 0.258232, acc.: 47.66%] [G loss: 0.292793]\n",
      "epoch:27 step:25965 [D loss: 0.233889, acc.: 60.94%] [G loss: 0.313343]\n",
      "epoch:27 step:25966 [D loss: 0.227223, acc.: 63.28%] [G loss: 0.312629]\n",
      "epoch:27 step:25967 [D loss: 0.231633, acc.: 57.03%] [G loss: 0.289836]\n",
      "epoch:27 step:25968 [D loss: 0.229286, acc.: 61.72%] [G loss: 0.275241]\n",
      "epoch:27 step:25969 [D loss: 0.249286, acc.: 54.69%] [G loss: 0.311363]\n",
      "epoch:27 step:25970 [D loss: 0.253274, acc.: 53.12%] [G loss: 0.265999]\n",
      "epoch:27 step:25971 [D loss: 0.232753, acc.: 60.94%] [G loss: 0.315967]\n",
      "epoch:27 step:25972 [D loss: 0.261641, acc.: 53.12%] [G loss: 0.311643]\n",
      "epoch:27 step:25973 [D loss: 0.223308, acc.: 67.97%] [G loss: 0.305039]\n",
      "epoch:27 step:25974 [D loss: 0.256810, acc.: 56.25%] [G loss: 0.282228]\n",
      "epoch:27 step:25975 [D loss: 0.250210, acc.: 55.47%] [G loss: 0.271061]\n",
      "epoch:27 step:25976 [D loss: 0.227714, acc.: 58.59%] [G loss: 0.319974]\n",
      "epoch:27 step:25977 [D loss: 0.251909, acc.: 59.38%] [G loss: 0.302552]\n",
      "epoch:27 step:25978 [D loss: 0.244765, acc.: 57.81%] [G loss: 0.265614]\n",
      "epoch:27 step:25979 [D loss: 0.232228, acc.: 60.16%] [G loss: 0.301201]\n",
      "epoch:27 step:25980 [D loss: 0.227995, acc.: 65.62%] [G loss: 0.310424]\n",
      "epoch:27 step:25981 [D loss: 0.231806, acc.: 57.81%] [G loss: 0.289247]\n",
      "epoch:27 step:25982 [D loss: 0.246125, acc.: 55.47%] [G loss: 0.285711]\n",
      "epoch:27 step:25983 [D loss: 0.246982, acc.: 54.69%] [G loss: 0.311085]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:27 step:25984 [D loss: 0.230868, acc.: 67.97%] [G loss: 0.320355]\n",
      "epoch:27 step:25985 [D loss: 0.255195, acc.: 56.25%] [G loss: 0.300481]\n",
      "epoch:27 step:25986 [D loss: 0.225843, acc.: 64.06%] [G loss: 0.356802]\n",
      "epoch:27 step:25987 [D loss: 0.220093, acc.: 69.53%] [G loss: 0.287050]\n",
      "epoch:27 step:25988 [D loss: 0.233871, acc.: 61.72%] [G loss: 0.307838]\n",
      "epoch:27 step:25989 [D loss: 0.231742, acc.: 60.94%] [G loss: 0.304403]\n",
      "epoch:27 step:25990 [D loss: 0.229560, acc.: 63.28%] [G loss: 0.286240]\n",
      "epoch:27 step:25991 [D loss: 0.248755, acc.: 54.69%] [G loss: 0.295971]\n",
      "epoch:27 step:25992 [D loss: 0.242570, acc.: 58.59%] [G loss: 0.294298]\n",
      "epoch:27 step:25993 [D loss: 0.230380, acc.: 61.72%] [G loss: 0.330453]\n",
      "epoch:27 step:25994 [D loss: 0.229126, acc.: 56.25%] [G loss: 0.292410]\n",
      "epoch:27 step:25995 [D loss: 0.225571, acc.: 64.84%] [G loss: 0.288121]\n",
      "epoch:27 step:25996 [D loss: 0.243273, acc.: 53.91%] [G loss: 0.295660]\n",
      "epoch:27 step:25997 [D loss: 0.240150, acc.: 57.81%] [G loss: 0.314314]\n",
      "epoch:27 step:25998 [D loss: 0.251360, acc.: 52.34%] [G loss: 0.280335]\n",
      "epoch:27 step:25999 [D loss: 0.229038, acc.: 63.28%] [G loss: 0.297755]\n",
      "epoch:27 step:26000 [D loss: 0.247460, acc.: 56.25%] [G loss: 0.280454]\n",
      "epoch:27 step:26001 [D loss: 0.231355, acc.: 63.28%] [G loss: 0.293431]\n",
      "epoch:27 step:26002 [D loss: 0.257400, acc.: 57.03%] [G loss: 0.285387]\n",
      "epoch:27 step:26003 [D loss: 0.254464, acc.: 56.25%] [G loss: 0.276988]\n",
      "epoch:27 step:26004 [D loss: 0.247071, acc.: 56.25%] [G loss: 0.315251]\n",
      "epoch:27 step:26005 [D loss: 0.241457, acc.: 58.59%] [G loss: 0.291441]\n",
      "epoch:27 step:26006 [D loss: 0.230619, acc.: 61.72%] [G loss: 0.322359]\n",
      "epoch:27 step:26007 [D loss: 0.240012, acc.: 53.91%] [G loss: 0.320607]\n",
      "epoch:27 step:26008 [D loss: 0.238623, acc.: 60.94%] [G loss: 0.292686]\n",
      "epoch:27 step:26009 [D loss: 0.235393, acc.: 60.16%] [G loss: 0.328700]\n",
      "epoch:27 step:26010 [D loss: 0.242325, acc.: 55.47%] [G loss: 0.308839]\n",
      "epoch:27 step:26011 [D loss: 0.233889, acc.: 62.50%] [G loss: 0.321516]\n",
      "epoch:27 step:26012 [D loss: 0.240495, acc.: 56.25%] [G loss: 0.307819]\n",
      "epoch:27 step:26013 [D loss: 0.251482, acc.: 50.00%] [G loss: 0.295334]\n",
      "epoch:27 step:26014 [D loss: 0.251755, acc.: 53.12%] [G loss: 0.285820]\n",
      "epoch:27 step:26015 [D loss: 0.232195, acc.: 57.81%] [G loss: 0.300462]\n",
      "epoch:27 step:26016 [D loss: 0.240958, acc.: 54.69%] [G loss: 0.311495]\n",
      "epoch:27 step:26017 [D loss: 0.231925, acc.: 63.28%] [G loss: 0.299673]\n",
      "epoch:27 step:26018 [D loss: 0.237711, acc.: 64.06%] [G loss: 0.313663]\n",
      "epoch:27 step:26019 [D loss: 0.252406, acc.: 53.91%] [G loss: 0.286762]\n",
      "epoch:27 step:26020 [D loss: 0.235252, acc.: 60.16%] [G loss: 0.296551]\n",
      "epoch:27 step:26021 [D loss: 0.229690, acc.: 59.38%] [G loss: 0.314052]\n",
      "epoch:27 step:26022 [D loss: 0.217317, acc.: 67.97%] [G loss: 0.320061]\n",
      "epoch:27 step:26023 [D loss: 0.232127, acc.: 58.59%] [G loss: 0.329045]\n",
      "epoch:27 step:26024 [D loss: 0.236787, acc.: 59.38%] [G loss: 0.299194]\n",
      "epoch:27 step:26025 [D loss: 0.246271, acc.: 57.81%] [G loss: 0.323730]\n",
      "epoch:27 step:26026 [D loss: 0.228520, acc.: 60.94%] [G loss: 0.288891]\n",
      "epoch:27 step:26027 [D loss: 0.242261, acc.: 57.81%] [G loss: 0.282972]\n",
      "epoch:27 step:26028 [D loss: 0.240747, acc.: 60.94%] [G loss: 0.289596]\n",
      "epoch:27 step:26029 [D loss: 0.240891, acc.: 54.69%] [G loss: 0.302300]\n",
      "epoch:27 step:26030 [D loss: 0.221635, acc.: 66.41%] [G loss: 0.321453]\n",
      "epoch:27 step:26031 [D loss: 0.240400, acc.: 58.59%] [G loss: 0.305464]\n",
      "epoch:27 step:26032 [D loss: 0.234682, acc.: 63.28%] [G loss: 0.329115]\n",
      "epoch:27 step:26033 [D loss: 0.224920, acc.: 64.06%] [G loss: 0.289985]\n",
      "epoch:27 step:26034 [D loss: 0.232394, acc.: 60.16%] [G loss: 0.309617]\n",
      "epoch:27 step:26035 [D loss: 0.215592, acc.: 69.53%] [G loss: 0.337315]\n",
      "epoch:27 step:26036 [D loss: 0.248888, acc.: 59.38%] [G loss: 0.294593]\n",
      "epoch:27 step:26037 [D loss: 0.244022, acc.: 56.25%] [G loss: 0.294655]\n",
      "epoch:27 step:26038 [D loss: 0.255883, acc.: 51.56%] [G loss: 0.294929]\n",
      "epoch:27 step:26039 [D loss: 0.234787, acc.: 61.72%] [G loss: 0.297468]\n",
      "epoch:27 step:26040 [D loss: 0.232504, acc.: 56.25%] [G loss: 0.310874]\n",
      "epoch:27 step:26041 [D loss: 0.241391, acc.: 57.81%] [G loss: 0.278487]\n",
      "epoch:27 step:26042 [D loss: 0.251623, acc.: 53.91%] [G loss: 0.275947]\n",
      "epoch:27 step:26043 [D loss: 0.225093, acc.: 63.28%] [G loss: 0.285226]\n",
      "epoch:27 step:26044 [D loss: 0.246122, acc.: 54.69%] [G loss: 0.299629]\n",
      "epoch:27 step:26045 [D loss: 0.234747, acc.: 59.38%] [G loss: 0.322981]\n",
      "epoch:27 step:26046 [D loss: 0.236083, acc.: 57.81%] [G loss: 0.313579]\n",
      "epoch:27 step:26047 [D loss: 0.238395, acc.: 58.59%] [G loss: 0.307993]\n",
      "epoch:27 step:26048 [D loss: 0.248333, acc.: 53.91%] [G loss: 0.267965]\n",
      "epoch:27 step:26049 [D loss: 0.250564, acc.: 53.12%] [G loss: 0.294553]\n",
      "epoch:27 step:26050 [D loss: 0.222065, acc.: 64.84%] [G loss: 0.292356]\n",
      "epoch:27 step:26051 [D loss: 0.259451, acc.: 52.34%] [G loss: 0.295557]\n",
      "epoch:27 step:26052 [D loss: 0.249053, acc.: 57.03%] [G loss: 0.321967]\n",
      "epoch:27 step:26053 [D loss: 0.229380, acc.: 61.72%] [G loss: 0.300427]\n",
      "epoch:27 step:26054 [D loss: 0.231227, acc.: 59.38%] [G loss: 0.294297]\n",
      "epoch:27 step:26055 [D loss: 0.251638, acc.: 53.91%] [G loss: 0.279269]\n",
      "epoch:27 step:26056 [D loss: 0.228039, acc.: 61.72%] [G loss: 0.290633]\n",
      "epoch:27 step:26057 [D loss: 0.257079, acc.: 48.44%] [G loss: 0.314077]\n",
      "epoch:27 step:26058 [D loss: 0.227574, acc.: 65.62%] [G loss: 0.299268]\n",
      "epoch:27 step:26059 [D loss: 0.246708, acc.: 59.38%] [G loss: 0.280402]\n",
      "epoch:27 step:26060 [D loss: 0.248606, acc.: 58.59%] [G loss: 0.272780]\n",
      "epoch:27 step:26061 [D loss: 0.237477, acc.: 56.25%] [G loss: 0.291499]\n",
      "epoch:27 step:26062 [D loss: 0.224348, acc.: 65.62%] [G loss: 0.309292]\n",
      "epoch:27 step:26063 [D loss: 0.263601, acc.: 51.56%] [G loss: 0.285108]\n",
      "epoch:27 step:26064 [D loss: 0.238317, acc.: 56.25%] [G loss: 0.313765]\n",
      "epoch:27 step:26065 [D loss: 0.214834, acc.: 67.97%] [G loss: 0.291930]\n",
      "epoch:27 step:26066 [D loss: 0.244235, acc.: 54.69%] [G loss: 0.285419]\n",
      "epoch:27 step:26067 [D loss: 0.232985, acc.: 58.59%] [G loss: 0.307557]\n",
      "epoch:27 step:26068 [D loss: 0.240076, acc.: 55.47%] [G loss: 0.304784]\n",
      "epoch:27 step:26069 [D loss: 0.246417, acc.: 53.91%] [G loss: 0.281716]\n",
      "epoch:27 step:26070 [D loss: 0.224984, acc.: 64.84%] [G loss: 0.330807]\n",
      "epoch:27 step:26071 [D loss: 0.224039, acc.: 65.62%] [G loss: 0.308781]\n",
      "epoch:27 step:26072 [D loss: 0.247356, acc.: 55.47%] [G loss: 0.346879]\n",
      "epoch:27 step:26073 [D loss: 0.236555, acc.: 60.16%] [G loss: 0.307364]\n",
      "epoch:27 step:26074 [D loss: 0.238360, acc.: 58.59%] [G loss: 0.285827]\n",
      "epoch:27 step:26075 [D loss: 0.223258, acc.: 62.50%] [G loss: 0.332145]\n",
      "epoch:27 step:26076 [D loss: 0.249453, acc.: 49.22%] [G loss: 0.274022]\n",
      "epoch:27 step:26077 [D loss: 0.231272, acc.: 60.16%] [G loss: 0.313980]\n",
      "epoch:27 step:26078 [D loss: 0.246255, acc.: 55.47%] [G loss: 0.309828]\n",
      "epoch:27 step:26079 [D loss: 0.250599, acc.: 56.25%] [G loss: 0.299283]\n",
      "epoch:27 step:26080 [D loss: 0.230559, acc.: 63.28%] [G loss: 0.290189]\n",
      "epoch:27 step:26081 [D loss: 0.261113, acc.: 50.78%] [G loss: 0.306682]\n",
      "epoch:27 step:26082 [D loss: 0.257541, acc.: 51.56%] [G loss: 0.275593]\n",
      "epoch:27 step:26083 [D loss: 0.244508, acc.: 51.56%] [G loss: 0.295878]\n",
      "epoch:27 step:26084 [D loss: 0.239830, acc.: 57.81%] [G loss: 0.322129]\n",
      "epoch:27 step:26085 [D loss: 0.250196, acc.: 57.03%] [G loss: 0.288774]\n",
      "epoch:27 step:26086 [D loss: 0.252063, acc.: 50.78%] [G loss: 0.302218]\n",
      "epoch:27 step:26087 [D loss: 0.238508, acc.: 59.38%] [G loss: 0.300419]\n",
      "epoch:27 step:26088 [D loss: 0.225284, acc.: 64.84%] [G loss: 0.301044]\n",
      "epoch:27 step:26089 [D loss: 0.241480, acc.: 58.59%] [G loss: 0.261945]\n",
      "epoch:27 step:26090 [D loss: 0.248107, acc.: 56.25%] [G loss: 0.315619]\n",
      "epoch:27 step:26091 [D loss: 0.228449, acc.: 62.50%] [G loss: 0.343988]\n",
      "epoch:27 step:26092 [D loss: 0.254920, acc.: 50.00%] [G loss: 0.310068]\n",
      "epoch:27 step:26093 [D loss: 0.231331, acc.: 62.50%] [G loss: 0.300369]\n",
      "epoch:27 step:26094 [D loss: 0.239724, acc.: 62.50%] [G loss: 0.313345]\n",
      "epoch:27 step:26095 [D loss: 0.248612, acc.: 53.12%] [G loss: 0.291112]\n",
      "epoch:27 step:26096 [D loss: 0.244544, acc.: 62.50%] [G loss: 0.295753]\n",
      "epoch:27 step:26097 [D loss: 0.247146, acc.: 57.03%] [G loss: 0.295979]\n",
      "epoch:27 step:26098 [D loss: 0.226017, acc.: 63.28%] [G loss: 0.277942]\n",
      "epoch:27 step:26099 [D loss: 0.251754, acc.: 57.03%] [G loss: 0.308786]\n",
      "epoch:27 step:26100 [D loss: 0.231411, acc.: 60.16%] [G loss: 0.304225]\n",
      "epoch:27 step:26101 [D loss: 0.230207, acc.: 61.72%] [G loss: 0.324371]\n",
      "epoch:27 step:26102 [D loss: 0.251199, acc.: 49.22%] [G loss: 0.311898]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:27 step:26103 [D loss: 0.242552, acc.: 57.03%] [G loss: 0.311737]\n",
      "epoch:27 step:26104 [D loss: 0.254290, acc.: 57.81%] [G loss: 0.297830]\n",
      "epoch:27 step:26105 [D loss: 0.233997, acc.: 60.16%] [G loss: 0.290910]\n",
      "epoch:27 step:26106 [D loss: 0.241348, acc.: 60.94%] [G loss: 0.332676]\n",
      "epoch:27 step:26107 [D loss: 0.238328, acc.: 53.12%] [G loss: 0.304105]\n",
      "epoch:27 step:26108 [D loss: 0.259208, acc.: 49.22%] [G loss: 0.280786]\n",
      "epoch:27 step:26109 [D loss: 0.234031, acc.: 63.28%] [G loss: 0.289866]\n",
      "epoch:27 step:26110 [D loss: 0.234565, acc.: 60.94%] [G loss: 0.308860]\n",
      "epoch:27 step:26111 [D loss: 0.241069, acc.: 64.06%] [G loss: 0.291430]\n",
      "epoch:27 step:26112 [D loss: 0.248133, acc.: 55.47%] [G loss: 0.306841]\n",
      "epoch:27 step:26113 [D loss: 0.236717, acc.: 58.59%] [G loss: 0.291698]\n",
      "epoch:27 step:26114 [D loss: 0.247486, acc.: 56.25%] [G loss: 0.264578]\n",
      "epoch:27 step:26115 [D loss: 0.240075, acc.: 56.25%] [G loss: 0.293850]\n",
      "epoch:27 step:26116 [D loss: 0.230128, acc.: 64.06%] [G loss: 0.320602]\n",
      "epoch:27 step:26117 [D loss: 0.244339, acc.: 57.81%] [G loss: 0.305528]\n",
      "epoch:27 step:26118 [D loss: 0.224960, acc.: 64.84%] [G loss: 0.308287]\n",
      "epoch:27 step:26119 [D loss: 0.248690, acc.: 53.91%] [G loss: 0.280065]\n",
      "epoch:27 step:26120 [D loss: 0.257284, acc.: 50.00%] [G loss: 0.315985]\n",
      "epoch:27 step:26121 [D loss: 0.231355, acc.: 60.16%] [G loss: 0.322303]\n",
      "epoch:27 step:26122 [D loss: 0.245984, acc.: 58.59%] [G loss: 0.276656]\n",
      "epoch:27 step:26123 [D loss: 0.233042, acc.: 60.94%] [G loss: 0.304511]\n",
      "epoch:27 step:26124 [D loss: 0.232537, acc.: 61.72%] [G loss: 0.317089]\n",
      "epoch:27 step:26125 [D loss: 0.245632, acc.: 55.47%] [G loss: 0.319015]\n",
      "epoch:27 step:26126 [D loss: 0.229555, acc.: 64.84%] [G loss: 0.318633]\n",
      "epoch:27 step:26127 [D loss: 0.246115, acc.: 52.34%] [G loss: 0.316449]\n",
      "epoch:27 step:26128 [D loss: 0.222616, acc.: 64.84%] [G loss: 0.314047]\n",
      "epoch:27 step:26129 [D loss: 0.228926, acc.: 65.62%] [G loss: 0.315838]\n",
      "epoch:27 step:26130 [D loss: 0.253082, acc.: 49.22%] [G loss: 0.286906]\n",
      "epoch:27 step:26131 [D loss: 0.241635, acc.: 54.69%] [G loss: 0.301871]\n",
      "epoch:27 step:26132 [D loss: 0.229735, acc.: 67.19%] [G loss: 0.309111]\n",
      "epoch:27 step:26133 [D loss: 0.243251, acc.: 59.38%] [G loss: 0.298190]\n",
      "epoch:27 step:26134 [D loss: 0.247881, acc.: 53.12%] [G loss: 0.290023]\n",
      "epoch:27 step:26135 [D loss: 0.244490, acc.: 57.03%] [G loss: 0.298560]\n",
      "epoch:27 step:26136 [D loss: 0.247819, acc.: 51.56%] [G loss: 0.304390]\n",
      "epoch:27 step:26137 [D loss: 0.232312, acc.: 61.72%] [G loss: 0.304882]\n",
      "epoch:27 step:26138 [D loss: 0.253619, acc.: 54.69%] [G loss: 0.286168]\n",
      "epoch:27 step:26139 [D loss: 0.249649, acc.: 50.00%] [G loss: 0.309496]\n",
      "epoch:27 step:26140 [D loss: 0.243406, acc.: 57.03%] [G loss: 0.304004]\n",
      "epoch:27 step:26141 [D loss: 0.253121, acc.: 56.25%] [G loss: 0.270302]\n",
      "epoch:27 step:26142 [D loss: 0.242052, acc.: 58.59%] [G loss: 0.316875]\n",
      "epoch:27 step:26143 [D loss: 0.258924, acc.: 50.78%] [G loss: 0.267573]\n",
      "epoch:27 step:26144 [D loss: 0.221024, acc.: 64.84%] [G loss: 0.304919]\n",
      "epoch:27 step:26145 [D loss: 0.263906, acc.: 51.56%] [G loss: 0.288948]\n",
      "epoch:27 step:26146 [D loss: 0.247681, acc.: 57.81%] [G loss: 0.312999]\n",
      "epoch:27 step:26147 [D loss: 0.247785, acc.: 53.12%] [G loss: 0.289776]\n",
      "epoch:27 step:26148 [D loss: 0.228175, acc.: 61.72%] [G loss: 0.327888]\n",
      "epoch:27 step:26149 [D loss: 0.236645, acc.: 62.50%] [G loss: 0.283686]\n",
      "epoch:27 step:26150 [D loss: 0.263649, acc.: 50.78%] [G loss: 0.305481]\n",
      "epoch:27 step:26151 [D loss: 0.230936, acc.: 64.84%] [G loss: 0.316047]\n",
      "epoch:27 step:26152 [D loss: 0.226089, acc.: 67.97%] [G loss: 0.298427]\n",
      "epoch:27 step:26153 [D loss: 0.246928, acc.: 53.91%] [G loss: 0.301051]\n",
      "epoch:27 step:26154 [D loss: 0.243679, acc.: 53.12%] [G loss: 0.293962]\n",
      "epoch:27 step:26155 [D loss: 0.239831, acc.: 56.25%] [G loss: 0.320740]\n",
      "epoch:27 step:26156 [D loss: 0.239645, acc.: 58.59%] [G loss: 0.295290]\n",
      "epoch:27 step:26157 [D loss: 0.244489, acc.: 57.81%] [G loss: 0.318787]\n",
      "epoch:27 step:26158 [D loss: 0.235624, acc.: 60.94%] [G loss: 0.309125]\n",
      "epoch:27 step:26159 [D loss: 0.228130, acc.: 64.06%] [G loss: 0.305763]\n",
      "epoch:27 step:26160 [D loss: 0.247317, acc.: 55.47%] [G loss: 0.297129]\n",
      "epoch:27 step:26161 [D loss: 0.247440, acc.: 57.81%] [G loss: 0.310421]\n",
      "epoch:27 step:26162 [D loss: 0.250317, acc.: 54.69%] [G loss: 0.286912]\n",
      "epoch:27 step:26163 [D loss: 0.235843, acc.: 56.25%] [G loss: 0.299215]\n",
      "epoch:27 step:26164 [D loss: 0.252270, acc.: 52.34%] [G loss: 0.293847]\n",
      "epoch:27 step:26165 [D loss: 0.233545, acc.: 64.06%] [G loss: 0.329288]\n",
      "epoch:27 step:26166 [D loss: 0.252704, acc.: 53.91%] [G loss: 0.289828]\n",
      "epoch:27 step:26167 [D loss: 0.229815, acc.: 60.16%] [G loss: 0.307639]\n",
      "epoch:27 step:26168 [D loss: 0.229582, acc.: 64.06%] [G loss: 0.338226]\n",
      "epoch:27 step:26169 [D loss: 0.240504, acc.: 60.94%] [G loss: 0.307796]\n",
      "epoch:27 step:26170 [D loss: 0.250493, acc.: 53.91%] [G loss: 0.281858]\n",
      "epoch:27 step:26171 [D loss: 0.254689, acc.: 53.12%] [G loss: 0.314722]\n",
      "epoch:27 step:26172 [D loss: 0.241196, acc.: 57.81%] [G loss: 0.285416]\n",
      "epoch:27 step:26173 [D loss: 0.242949, acc.: 60.94%] [G loss: 0.298271]\n",
      "epoch:27 step:26174 [D loss: 0.236500, acc.: 58.59%] [G loss: 0.277944]\n",
      "epoch:27 step:26175 [D loss: 0.243009, acc.: 57.03%] [G loss: 0.304229]\n",
      "epoch:27 step:26176 [D loss: 0.249851, acc.: 62.50%] [G loss: 0.297809]\n",
      "epoch:27 step:26177 [D loss: 0.244069, acc.: 60.16%] [G loss: 0.317401]\n",
      "epoch:27 step:26178 [D loss: 0.246780, acc.: 58.59%] [G loss: 0.303390]\n",
      "epoch:27 step:26179 [D loss: 0.249237, acc.: 54.69%] [G loss: 0.310485]\n",
      "epoch:27 step:26180 [D loss: 0.241797, acc.: 56.25%] [G loss: 0.265335]\n",
      "epoch:27 step:26181 [D loss: 0.240910, acc.: 57.03%] [G loss: 0.316194]\n",
      "epoch:27 step:26182 [D loss: 0.237413, acc.: 59.38%] [G loss: 0.334696]\n",
      "epoch:27 step:26183 [D loss: 0.234568, acc.: 57.03%] [G loss: 0.309485]\n",
      "epoch:27 step:26184 [D loss: 0.229565, acc.: 64.84%] [G loss: 0.312495]\n",
      "epoch:27 step:26185 [D loss: 0.234933, acc.: 58.59%] [G loss: 0.329203]\n",
      "epoch:27 step:26186 [D loss: 0.249428, acc.: 56.25%] [G loss: 0.289796]\n",
      "epoch:27 step:26187 [D loss: 0.250507, acc.: 50.78%] [G loss: 0.299489]\n",
      "epoch:27 step:26188 [D loss: 0.253151, acc.: 52.34%] [G loss: 0.295564]\n",
      "epoch:27 step:26189 [D loss: 0.245904, acc.: 57.03%] [G loss: 0.339031]\n",
      "epoch:27 step:26190 [D loss: 0.240850, acc.: 57.03%] [G loss: 0.296053]\n",
      "epoch:27 step:26191 [D loss: 0.232818, acc.: 59.38%] [G loss: 0.315366]\n",
      "epoch:27 step:26192 [D loss: 0.234107, acc.: 57.81%] [G loss: 0.296030]\n",
      "epoch:27 step:26193 [D loss: 0.242068, acc.: 54.69%] [G loss: 0.337555]\n",
      "epoch:27 step:26194 [D loss: 0.238362, acc.: 53.91%] [G loss: 0.309426]\n",
      "epoch:27 step:26195 [D loss: 0.239702, acc.: 58.59%] [G loss: 0.296938]\n",
      "epoch:27 step:26196 [D loss: 0.221850, acc.: 64.84%] [G loss: 0.317886]\n",
      "epoch:27 step:26197 [D loss: 0.213739, acc.: 64.06%] [G loss: 0.306162]\n",
      "epoch:27 step:26198 [D loss: 0.237171, acc.: 59.38%] [G loss: 0.293352]\n",
      "epoch:27 step:26199 [D loss: 0.238522, acc.: 57.81%] [G loss: 0.295705]\n",
      "epoch:27 step:26200 [D loss: 0.243605, acc.: 53.12%] [G loss: 0.299152]\n",
      "epoch:27 step:26201 [D loss: 0.234701, acc.: 62.50%] [G loss: 0.327456]\n",
      "epoch:27 step:26202 [D loss: 0.258360, acc.: 52.34%] [G loss: 0.318610]\n",
      "epoch:27 step:26203 [D loss: 0.258133, acc.: 53.12%] [G loss: 0.325163]\n",
      "epoch:27 step:26204 [D loss: 0.242329, acc.: 55.47%] [G loss: 0.292732]\n",
      "epoch:27 step:26205 [D loss: 0.232748, acc.: 62.50%] [G loss: 0.312374]\n",
      "epoch:27 step:26206 [D loss: 0.242313, acc.: 54.69%] [G loss: 0.326010]\n",
      "epoch:27 step:26207 [D loss: 0.225435, acc.: 58.59%] [G loss: 0.330100]\n",
      "epoch:27 step:26208 [D loss: 0.238944, acc.: 60.94%] [G loss: 0.295239]\n",
      "epoch:27 step:26209 [D loss: 0.229010, acc.: 61.72%] [G loss: 0.299851]\n",
      "epoch:27 step:26210 [D loss: 0.238004, acc.: 61.72%] [G loss: 0.307714]\n",
      "epoch:27 step:26211 [D loss: 0.243331, acc.: 53.91%] [G loss: 0.278088]\n",
      "epoch:27 step:26212 [D loss: 0.240520, acc.: 53.91%] [G loss: 0.287317]\n",
      "epoch:27 step:26213 [D loss: 0.254517, acc.: 50.00%] [G loss: 0.289140]\n",
      "epoch:27 step:26214 [D loss: 0.251355, acc.: 59.38%] [G loss: 0.286907]\n",
      "epoch:27 step:26215 [D loss: 0.225113, acc.: 64.06%] [G loss: 0.291416]\n",
      "epoch:27 step:26216 [D loss: 0.224900, acc.: 67.19%] [G loss: 0.301404]\n",
      "epoch:27 step:26217 [D loss: 0.239457, acc.: 57.81%] [G loss: 0.297003]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:27 step:26218 [D loss: 0.233880, acc.: 58.59%] [G loss: 0.267909]\n",
      "epoch:27 step:26219 [D loss: 0.256203, acc.: 52.34%] [G loss: 0.294417]\n",
      "epoch:27 step:26220 [D loss: 0.242596, acc.: 55.47%] [G loss: 0.314395]\n",
      "epoch:27 step:26221 [D loss: 0.264861, acc.: 49.22%] [G loss: 0.284480]\n",
      "epoch:27 step:26222 [D loss: 0.227914, acc.: 60.16%] [G loss: 0.279649]\n",
      "epoch:27 step:26223 [D loss: 0.241790, acc.: 57.03%] [G loss: 0.311110]\n",
      "epoch:27 step:26224 [D loss: 0.248463, acc.: 52.34%] [G loss: 0.290439]\n",
      "epoch:27 step:26225 [D loss: 0.252346, acc.: 48.44%] [G loss: 0.297462]\n",
      "epoch:27 step:26226 [D loss: 0.238626, acc.: 58.59%] [G loss: 0.278133]\n",
      "epoch:27 step:26227 [D loss: 0.232638, acc.: 58.59%] [G loss: 0.299237]\n",
      "epoch:27 step:26228 [D loss: 0.231128, acc.: 63.28%] [G loss: 0.300915]\n",
      "epoch:27 step:26229 [D loss: 0.242401, acc.: 58.59%] [G loss: 0.281999]\n",
      "epoch:27 step:26230 [D loss: 0.233057, acc.: 61.72%] [G loss: 0.328972]\n",
      "epoch:27 step:26231 [D loss: 0.239637, acc.: 57.81%] [G loss: 0.333920]\n",
      "epoch:27 step:26232 [D loss: 0.248648, acc.: 52.34%] [G loss: 0.315637]\n",
      "epoch:27 step:26233 [D loss: 0.247232, acc.: 56.25%] [G loss: 0.311156]\n",
      "epoch:27 step:26234 [D loss: 0.230943, acc.: 59.38%] [G loss: 0.333827]\n",
      "epoch:27 step:26235 [D loss: 0.234671, acc.: 61.72%] [G loss: 0.304709]\n",
      "epoch:27 step:26236 [D loss: 0.231363, acc.: 66.41%] [G loss: 0.293023]\n",
      "epoch:28 step:26237 [D loss: 0.239506, acc.: 61.72%] [G loss: 0.300898]\n",
      "epoch:28 step:26238 [D loss: 0.249577, acc.: 55.47%] [G loss: 0.314724]\n",
      "epoch:28 step:26239 [D loss: 0.233621, acc.: 62.50%] [G loss: 0.280359]\n",
      "epoch:28 step:26240 [D loss: 0.231998, acc.: 58.59%] [G loss: 0.293377]\n",
      "epoch:28 step:26241 [D loss: 0.229124, acc.: 61.72%] [G loss: 0.290873]\n",
      "epoch:28 step:26242 [D loss: 0.246913, acc.: 51.56%] [G loss: 0.315840]\n",
      "epoch:28 step:26243 [D loss: 0.250576, acc.: 50.00%] [G loss: 0.309647]\n",
      "epoch:28 step:26244 [D loss: 0.259998, acc.: 50.78%] [G loss: 0.315509]\n",
      "epoch:28 step:26245 [D loss: 0.232026, acc.: 54.69%] [G loss: 0.291002]\n",
      "epoch:28 step:26246 [D loss: 0.262722, acc.: 53.91%] [G loss: 0.294404]\n",
      "epoch:28 step:26247 [D loss: 0.235086, acc.: 63.28%] [G loss: 0.326113]\n",
      "epoch:28 step:26248 [D loss: 0.222022, acc.: 64.06%] [G loss: 0.299964]\n",
      "epoch:28 step:26249 [D loss: 0.239330, acc.: 59.38%] [G loss: 0.319979]\n",
      "epoch:28 step:26250 [D loss: 0.237705, acc.: 56.25%] [G loss: 0.277960]\n",
      "epoch:28 step:26251 [D loss: 0.238197, acc.: 53.91%] [G loss: 0.293069]\n",
      "epoch:28 step:26252 [D loss: 0.248841, acc.: 57.03%] [G loss: 0.295501]\n",
      "epoch:28 step:26253 [D loss: 0.235939, acc.: 62.50%] [G loss: 0.294416]\n",
      "epoch:28 step:26254 [D loss: 0.224193, acc.: 64.06%] [G loss: 0.325208]\n",
      "epoch:28 step:26255 [D loss: 0.254418, acc.: 48.44%] [G loss: 0.287874]\n",
      "epoch:28 step:26256 [D loss: 0.221664, acc.: 65.62%] [G loss: 0.307420]\n",
      "epoch:28 step:26257 [D loss: 0.245495, acc.: 58.59%] [G loss: 0.298615]\n",
      "epoch:28 step:26258 [D loss: 0.238795, acc.: 57.03%] [G loss: 0.279704]\n",
      "epoch:28 step:26259 [D loss: 0.236102, acc.: 56.25%] [G loss: 0.274707]\n",
      "epoch:28 step:26260 [D loss: 0.229891, acc.: 57.81%] [G loss: 0.305454]\n",
      "epoch:28 step:26261 [D loss: 0.232259, acc.: 58.59%] [G loss: 0.333703]\n",
      "epoch:28 step:26262 [D loss: 0.236077, acc.: 62.50%] [G loss: 0.305292]\n",
      "epoch:28 step:26263 [D loss: 0.226455, acc.: 61.72%] [G loss: 0.314853]\n",
      "epoch:28 step:26264 [D loss: 0.248708, acc.: 53.12%] [G loss: 0.309514]\n",
      "epoch:28 step:26265 [D loss: 0.245323, acc.: 51.56%] [G loss: 0.306452]\n",
      "epoch:28 step:26266 [D loss: 0.258888, acc.: 53.12%] [G loss: 0.275978]\n",
      "epoch:28 step:26267 [D loss: 0.233086, acc.: 60.94%] [G loss: 0.298370]\n",
      "epoch:28 step:26268 [D loss: 0.216180, acc.: 65.62%] [G loss: 0.326196]\n",
      "epoch:28 step:26269 [D loss: 0.233003, acc.: 55.47%] [G loss: 0.302272]\n",
      "epoch:28 step:26270 [D loss: 0.243449, acc.: 56.25%] [G loss: 0.304989]\n",
      "epoch:28 step:26271 [D loss: 0.239653, acc.: 57.03%] [G loss: 0.294922]\n",
      "epoch:28 step:26272 [D loss: 0.249682, acc.: 52.34%] [G loss: 0.263780]\n",
      "epoch:28 step:26273 [D loss: 0.233400, acc.: 60.16%] [G loss: 0.316867]\n",
      "epoch:28 step:26274 [D loss: 0.227004, acc.: 64.06%] [G loss: 0.283609]\n",
      "epoch:28 step:26275 [D loss: 0.252443, acc.: 55.47%] [G loss: 0.303349]\n",
      "epoch:28 step:26276 [D loss: 0.229070, acc.: 60.94%] [G loss: 0.299477]\n",
      "epoch:28 step:26277 [D loss: 0.229263, acc.: 63.28%] [G loss: 0.312481]\n",
      "epoch:28 step:26278 [D loss: 0.233514, acc.: 59.38%] [G loss: 0.286082]\n",
      "epoch:28 step:26279 [D loss: 0.253194, acc.: 55.47%] [G loss: 0.308254]\n",
      "epoch:28 step:26280 [D loss: 0.232021, acc.: 60.16%] [G loss: 0.300594]\n",
      "epoch:28 step:26281 [D loss: 0.247030, acc.: 57.03%] [G loss: 0.291817]\n",
      "epoch:28 step:26282 [D loss: 0.257317, acc.: 51.56%] [G loss: 0.319446]\n",
      "epoch:28 step:26283 [D loss: 0.255769, acc.: 50.78%] [G loss: 0.319862]\n",
      "epoch:28 step:26284 [D loss: 0.227886, acc.: 63.28%] [G loss: 0.321041]\n",
      "epoch:28 step:26285 [D loss: 0.232925, acc.: 63.28%] [G loss: 0.281446]\n",
      "epoch:28 step:26286 [D loss: 0.234943, acc.: 60.94%] [G loss: 0.330688]\n",
      "epoch:28 step:26287 [D loss: 0.249187, acc.: 50.78%] [G loss: 0.295128]\n",
      "epoch:28 step:26288 [D loss: 0.237969, acc.: 57.03%] [G loss: 0.295248]\n",
      "epoch:28 step:26289 [D loss: 0.231001, acc.: 60.16%] [G loss: 0.298921]\n",
      "epoch:28 step:26290 [D loss: 0.243314, acc.: 56.25%] [G loss: 0.313076]\n",
      "epoch:28 step:26291 [D loss: 0.260956, acc.: 51.56%] [G loss: 0.294065]\n",
      "epoch:28 step:26292 [D loss: 0.250573, acc.: 54.69%] [G loss: 0.310244]\n",
      "epoch:28 step:26293 [D loss: 0.238351, acc.: 56.25%] [G loss: 0.291985]\n",
      "epoch:28 step:26294 [D loss: 0.246766, acc.: 55.47%] [G loss: 0.325878]\n",
      "epoch:28 step:26295 [D loss: 0.231976, acc.: 54.69%] [G loss: 0.298760]\n",
      "epoch:28 step:26296 [D loss: 0.231042, acc.: 64.06%] [G loss: 0.299432]\n",
      "epoch:28 step:26297 [D loss: 0.246583, acc.: 55.47%] [G loss: 0.273599]\n",
      "epoch:28 step:26298 [D loss: 0.254244, acc.: 48.44%] [G loss: 0.306419]\n",
      "epoch:28 step:26299 [D loss: 0.232812, acc.: 62.50%] [G loss: 0.305765]\n",
      "epoch:28 step:26300 [D loss: 0.232797, acc.: 60.16%] [G loss: 0.314800]\n",
      "epoch:28 step:26301 [D loss: 0.238992, acc.: 59.38%] [G loss: 0.318889]\n",
      "epoch:28 step:26302 [D loss: 0.242882, acc.: 57.03%] [G loss: 0.296421]\n",
      "epoch:28 step:26303 [D loss: 0.237493, acc.: 56.25%] [G loss: 0.292131]\n",
      "epoch:28 step:26304 [D loss: 0.230500, acc.: 62.50%] [G loss: 0.323669]\n",
      "epoch:28 step:26305 [D loss: 0.233768, acc.: 57.03%] [G loss: 0.359978]\n",
      "epoch:28 step:26306 [D loss: 0.235543, acc.: 62.50%] [G loss: 0.265694]\n",
      "epoch:28 step:26307 [D loss: 0.228073, acc.: 60.16%] [G loss: 0.296068]\n",
      "epoch:28 step:26308 [D loss: 0.237109, acc.: 60.94%] [G loss: 0.327878]\n",
      "epoch:28 step:26309 [D loss: 0.228997, acc.: 62.50%] [G loss: 0.315315]\n",
      "epoch:28 step:26310 [D loss: 0.250576, acc.: 55.47%] [G loss: 0.289017]\n",
      "epoch:28 step:26311 [D loss: 0.248764, acc.: 56.25%] [G loss: 0.280728]\n",
      "epoch:28 step:26312 [D loss: 0.254165, acc.: 53.91%] [G loss: 0.297297]\n",
      "epoch:28 step:26313 [D loss: 0.240796, acc.: 60.94%] [G loss: 0.286208]\n",
      "epoch:28 step:26314 [D loss: 0.223993, acc.: 67.97%] [G loss: 0.278056]\n",
      "epoch:28 step:26315 [D loss: 0.246775, acc.: 57.03%] [G loss: 0.293529]\n",
      "epoch:28 step:26316 [D loss: 0.236492, acc.: 64.84%] [G loss: 0.305982]\n",
      "epoch:28 step:26317 [D loss: 0.231410, acc.: 59.38%] [G loss: 0.293635]\n",
      "epoch:28 step:26318 [D loss: 0.231882, acc.: 59.38%] [G loss: 0.309890]\n",
      "epoch:28 step:26319 [D loss: 0.236643, acc.: 59.38%] [G loss: 0.286999]\n",
      "epoch:28 step:26320 [D loss: 0.232462, acc.: 53.91%] [G loss: 0.294413]\n",
      "epoch:28 step:26321 [D loss: 0.228733, acc.: 61.72%] [G loss: 0.306024]\n",
      "epoch:28 step:26322 [D loss: 0.235757, acc.: 60.16%] [G loss: 0.301113]\n",
      "epoch:28 step:26323 [D loss: 0.251345, acc.: 53.12%] [G loss: 0.299745]\n",
      "epoch:28 step:26324 [D loss: 0.231608, acc.: 59.38%] [G loss: 0.322585]\n",
      "epoch:28 step:26325 [D loss: 0.229483, acc.: 61.72%] [G loss: 0.324759]\n",
      "epoch:28 step:26326 [D loss: 0.234065, acc.: 60.94%] [G loss: 0.279122]\n",
      "epoch:28 step:26327 [D loss: 0.228634, acc.: 63.28%] [G loss: 0.325601]\n",
      "epoch:28 step:26328 [D loss: 0.240095, acc.: 60.16%] [G loss: 0.295005]\n",
      "epoch:28 step:26329 [D loss: 0.223401, acc.: 64.84%] [G loss: 0.330389]\n",
      "epoch:28 step:26330 [D loss: 0.249792, acc.: 55.47%] [G loss: 0.291854]\n",
      "epoch:28 step:26331 [D loss: 0.239880, acc.: 56.25%] [G loss: 0.270979]\n",
      "epoch:28 step:26332 [D loss: 0.234549, acc.: 61.72%] [G loss: 0.300089]\n",
      "epoch:28 step:26333 [D loss: 0.236035, acc.: 57.03%] [G loss: 0.304389]\n",
      "epoch:28 step:26334 [D loss: 0.253381, acc.: 48.44%] [G loss: 0.280379]\n",
      "epoch:28 step:26335 [D loss: 0.249903, acc.: 53.12%] [G loss: 0.297079]\n",
      "epoch:28 step:26336 [D loss: 0.238817, acc.: 56.25%] [G loss: 0.312436]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:28 step:26337 [D loss: 0.225953, acc.: 60.16%] [G loss: 0.293431]\n",
      "epoch:28 step:26338 [D loss: 0.227899, acc.: 61.72%] [G loss: 0.284690]\n",
      "epoch:28 step:26339 [D loss: 0.242800, acc.: 57.81%] [G loss: 0.273915]\n",
      "epoch:28 step:26340 [D loss: 0.230768, acc.: 55.47%] [G loss: 0.318484]\n",
      "epoch:28 step:26341 [D loss: 0.226566, acc.: 60.16%] [G loss: 0.280786]\n",
      "epoch:28 step:26342 [D loss: 0.245151, acc.: 57.03%] [G loss: 0.297898]\n",
      "epoch:28 step:26343 [D loss: 0.232167, acc.: 60.16%] [G loss: 0.302988]\n",
      "epoch:28 step:26344 [D loss: 0.246966, acc.: 57.81%] [G loss: 0.298336]\n",
      "epoch:28 step:26345 [D loss: 0.255636, acc.: 55.47%] [G loss: 0.307199]\n",
      "epoch:28 step:26346 [D loss: 0.244123, acc.: 55.47%] [G loss: 0.285102]\n",
      "epoch:28 step:26347 [D loss: 0.241767, acc.: 59.38%] [G loss: 0.289028]\n",
      "epoch:28 step:26348 [D loss: 0.229076, acc.: 60.16%] [G loss: 0.277579]\n",
      "epoch:28 step:26349 [D loss: 0.217191, acc.: 64.84%] [G loss: 0.277340]\n",
      "epoch:28 step:26350 [D loss: 0.239719, acc.: 55.47%] [G loss: 0.313637]\n",
      "epoch:28 step:26351 [D loss: 0.240787, acc.: 57.81%] [G loss: 0.295278]\n",
      "epoch:28 step:26352 [D loss: 0.254494, acc.: 50.78%] [G loss: 0.292725]\n",
      "epoch:28 step:26353 [D loss: 0.233836, acc.: 60.94%] [G loss: 0.302996]\n",
      "epoch:28 step:26354 [D loss: 0.231876, acc.: 57.81%] [G loss: 0.287313]\n",
      "epoch:28 step:26355 [D loss: 0.225484, acc.: 67.19%] [G loss: 0.283503]\n",
      "epoch:28 step:26356 [D loss: 0.252327, acc.: 56.25%] [G loss: 0.319620]\n",
      "epoch:28 step:26357 [D loss: 0.250543, acc.: 53.12%] [G loss: 0.280057]\n",
      "epoch:28 step:26358 [D loss: 0.244690, acc.: 54.69%] [G loss: 0.283796]\n",
      "epoch:28 step:26359 [D loss: 0.245095, acc.: 55.47%] [G loss: 0.307698]\n",
      "epoch:28 step:26360 [D loss: 0.233672, acc.: 60.94%] [G loss: 0.313071]\n",
      "epoch:28 step:26361 [D loss: 0.246326, acc.: 57.81%] [G loss: 0.299958]\n",
      "epoch:28 step:26362 [D loss: 0.236541, acc.: 59.38%] [G loss: 0.300253]\n",
      "epoch:28 step:26363 [D loss: 0.236361, acc.: 62.50%] [G loss: 0.292669]\n",
      "epoch:28 step:26364 [D loss: 0.241277, acc.: 56.25%] [G loss: 0.278521]\n",
      "epoch:28 step:26365 [D loss: 0.229992, acc.: 62.50%] [G loss: 0.317668]\n",
      "epoch:28 step:26366 [D loss: 0.238743, acc.: 55.47%] [G loss: 0.286140]\n",
      "epoch:28 step:26367 [D loss: 0.237929, acc.: 58.59%] [G loss: 0.326806]\n",
      "epoch:28 step:26368 [D loss: 0.244424, acc.: 60.94%] [G loss: 0.303470]\n",
      "epoch:28 step:26369 [D loss: 0.242876, acc.: 57.81%] [G loss: 0.308323]\n",
      "epoch:28 step:26370 [D loss: 0.223405, acc.: 67.97%] [G loss: 0.316462]\n",
      "epoch:28 step:26371 [D loss: 0.249007, acc.: 57.03%] [G loss: 0.320032]\n",
      "epoch:28 step:26372 [D loss: 0.245666, acc.: 57.03%] [G loss: 0.312950]\n",
      "epoch:28 step:26373 [D loss: 0.249050, acc.: 48.44%] [G loss: 0.297928]\n",
      "epoch:28 step:26374 [D loss: 0.218557, acc.: 68.75%] [G loss: 0.320999]\n",
      "epoch:28 step:26375 [D loss: 0.244233, acc.: 57.03%] [G loss: 0.310413]\n",
      "epoch:28 step:26376 [D loss: 0.240375, acc.: 54.69%] [G loss: 0.291700]\n",
      "epoch:28 step:26377 [D loss: 0.257603, acc.: 48.44%] [G loss: 0.318184]\n",
      "epoch:28 step:26378 [D loss: 0.233146, acc.: 61.72%] [G loss: 0.315998]\n",
      "epoch:28 step:26379 [D loss: 0.247742, acc.: 54.69%] [G loss: 0.319927]\n",
      "epoch:28 step:26380 [D loss: 0.242967, acc.: 56.25%] [G loss: 0.281787]\n",
      "epoch:28 step:26381 [D loss: 0.236945, acc.: 57.03%] [G loss: 0.295985]\n",
      "epoch:28 step:26382 [D loss: 0.229785, acc.: 60.94%] [G loss: 0.304241]\n",
      "epoch:28 step:26383 [D loss: 0.229072, acc.: 59.38%] [G loss: 0.307592]\n",
      "epoch:28 step:26384 [D loss: 0.244998, acc.: 56.25%] [G loss: 0.290721]\n",
      "epoch:28 step:26385 [D loss: 0.239534, acc.: 59.38%] [G loss: 0.319574]\n",
      "epoch:28 step:26386 [D loss: 0.232223, acc.: 60.16%] [G loss: 0.311098]\n",
      "epoch:28 step:26387 [D loss: 0.249261, acc.: 55.47%] [G loss: 0.301163]\n",
      "epoch:28 step:26388 [D loss: 0.256134, acc.: 53.12%] [G loss: 0.318896]\n",
      "epoch:28 step:26389 [D loss: 0.248847, acc.: 54.69%] [G loss: 0.309951]\n",
      "epoch:28 step:26390 [D loss: 0.240322, acc.: 60.16%] [G loss: 0.317080]\n",
      "epoch:28 step:26391 [D loss: 0.245406, acc.: 60.16%] [G loss: 0.293948]\n",
      "epoch:28 step:26392 [D loss: 0.227525, acc.: 62.50%] [G loss: 0.323104]\n",
      "epoch:28 step:26393 [D loss: 0.239023, acc.: 59.38%] [G loss: 0.296859]\n",
      "epoch:28 step:26394 [D loss: 0.233152, acc.: 59.38%] [G loss: 0.294523]\n",
      "epoch:28 step:26395 [D loss: 0.227657, acc.: 63.28%] [G loss: 0.313491]\n",
      "epoch:28 step:26396 [D loss: 0.230844, acc.: 61.72%] [G loss: 0.301417]\n",
      "epoch:28 step:26397 [D loss: 0.249440, acc.: 54.69%] [G loss: 0.318581]\n",
      "epoch:28 step:26398 [D loss: 0.233245, acc.: 61.72%] [G loss: 0.317607]\n",
      "epoch:28 step:26399 [D loss: 0.248331, acc.: 52.34%] [G loss: 0.297557]\n",
      "epoch:28 step:26400 [D loss: 0.228926, acc.: 56.25%] [G loss: 0.293608]\n",
      "epoch:28 step:26401 [D loss: 0.243534, acc.: 60.16%] [G loss: 0.304598]\n",
      "epoch:28 step:26402 [D loss: 0.268028, acc.: 43.75%] [G loss: 0.284724]\n",
      "epoch:28 step:26403 [D loss: 0.204798, acc.: 67.19%] [G loss: 0.302966]\n",
      "epoch:28 step:26404 [D loss: 0.247269, acc.: 56.25%] [G loss: 0.303974]\n",
      "epoch:28 step:26405 [D loss: 0.229749, acc.: 65.62%] [G loss: 0.297957]\n",
      "epoch:28 step:26406 [D loss: 0.224025, acc.: 57.81%] [G loss: 0.307845]\n",
      "epoch:28 step:26407 [D loss: 0.272952, acc.: 47.66%] [G loss: 0.296465]\n",
      "epoch:28 step:26408 [D loss: 0.234037, acc.: 60.16%] [G loss: 0.288079]\n",
      "epoch:28 step:26409 [D loss: 0.251910, acc.: 53.12%] [G loss: 0.334399]\n",
      "epoch:28 step:26410 [D loss: 0.239904, acc.: 55.47%] [G loss: 0.313990]\n",
      "epoch:28 step:26411 [D loss: 0.239611, acc.: 57.81%] [G loss: 0.316440]\n",
      "epoch:28 step:26412 [D loss: 0.252807, acc.: 57.03%] [G loss: 0.270636]\n",
      "epoch:28 step:26413 [D loss: 0.242402, acc.: 53.91%] [G loss: 0.303917]\n",
      "epoch:28 step:26414 [D loss: 0.223847, acc.: 64.84%] [G loss: 0.324742]\n",
      "epoch:28 step:26415 [D loss: 0.224600, acc.: 62.50%] [G loss: 0.290013]\n",
      "epoch:28 step:26416 [D loss: 0.244223, acc.: 56.25%] [G loss: 0.302448]\n",
      "epoch:28 step:26417 [D loss: 0.222280, acc.: 66.41%] [G loss: 0.269132]\n",
      "epoch:28 step:26418 [D loss: 0.247451, acc.: 53.91%] [G loss: 0.302242]\n",
      "epoch:28 step:26419 [D loss: 0.235644, acc.: 61.72%] [G loss: 0.275338]\n",
      "epoch:28 step:26420 [D loss: 0.250719, acc.: 60.16%] [G loss: 0.288636]\n",
      "epoch:28 step:26421 [D loss: 0.229928, acc.: 60.94%] [G loss: 0.328230]\n",
      "epoch:28 step:26422 [D loss: 0.230172, acc.: 60.94%] [G loss: 0.317915]\n",
      "epoch:28 step:26423 [D loss: 0.236888, acc.: 57.81%] [G loss: 0.281318]\n",
      "epoch:28 step:26424 [D loss: 0.249383, acc.: 55.47%] [G loss: 0.282407]\n",
      "epoch:28 step:26425 [D loss: 0.238466, acc.: 57.03%] [G loss: 0.268980]\n",
      "epoch:28 step:26426 [D loss: 0.255872, acc.: 57.81%] [G loss: 0.288252]\n",
      "epoch:28 step:26427 [D loss: 0.234402, acc.: 61.72%] [G loss: 0.286068]\n",
      "epoch:28 step:26428 [D loss: 0.258494, acc.: 56.25%] [G loss: 0.279348]\n",
      "epoch:28 step:26429 [D loss: 0.239013, acc.: 57.03%] [G loss: 0.276679]\n",
      "epoch:28 step:26430 [D loss: 0.250085, acc.: 52.34%] [G loss: 0.303709]\n",
      "epoch:28 step:26431 [D loss: 0.251264, acc.: 58.59%] [G loss: 0.281845]\n",
      "epoch:28 step:26432 [D loss: 0.240533, acc.: 54.69%] [G loss: 0.285596]\n",
      "epoch:28 step:26433 [D loss: 0.239779, acc.: 57.81%] [G loss: 0.312818]\n",
      "epoch:28 step:26434 [D loss: 0.247500, acc.: 50.00%] [G loss: 0.296319]\n",
      "epoch:28 step:26435 [D loss: 0.243443, acc.: 56.25%] [G loss: 0.285857]\n",
      "epoch:28 step:26436 [D loss: 0.251116, acc.: 55.47%] [G loss: 0.308564]\n",
      "epoch:28 step:26437 [D loss: 0.231411, acc.: 58.59%] [G loss: 0.275676]\n",
      "epoch:28 step:26438 [D loss: 0.236382, acc.: 57.03%] [G loss: 0.277970]\n",
      "epoch:28 step:26439 [D loss: 0.233972, acc.: 63.28%] [G loss: 0.290495]\n",
      "epoch:28 step:26440 [D loss: 0.234430, acc.: 57.03%] [G loss: 0.291933]\n",
      "epoch:28 step:26441 [D loss: 0.231655, acc.: 58.59%] [G loss: 0.311832]\n",
      "epoch:28 step:26442 [D loss: 0.244423, acc.: 57.03%] [G loss: 0.283772]\n",
      "epoch:28 step:26443 [D loss: 0.249043, acc.: 53.12%] [G loss: 0.306399]\n",
      "epoch:28 step:26444 [D loss: 0.237833, acc.: 58.59%] [G loss: 0.300566]\n",
      "epoch:28 step:26445 [D loss: 0.254930, acc.: 54.69%] [G loss: 0.286158]\n",
      "epoch:28 step:26446 [D loss: 0.235512, acc.: 61.72%] [G loss: 0.317730]\n",
      "epoch:28 step:26447 [D loss: 0.256859, acc.: 45.31%] [G loss: 0.273449]\n",
      "epoch:28 step:26448 [D loss: 0.243956, acc.: 53.12%] [G loss: 0.317830]\n",
      "epoch:28 step:26449 [D loss: 0.243596, acc.: 53.91%] [G loss: 0.298089]\n",
      "epoch:28 step:26450 [D loss: 0.231349, acc.: 56.25%] [G loss: 0.310632]\n",
      "epoch:28 step:26451 [D loss: 0.235033, acc.: 63.28%] [G loss: 0.328243]\n",
      "epoch:28 step:26452 [D loss: 0.246281, acc.: 57.03%] [G loss: 0.285650]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:28 step:26453 [D loss: 0.225260, acc.: 58.59%] [G loss: 0.291718]\n",
      "epoch:28 step:26454 [D loss: 0.237731, acc.: 59.38%] [G loss: 0.311561]\n",
      "epoch:28 step:26455 [D loss: 0.244465, acc.: 57.03%] [G loss: 0.293804]\n",
      "epoch:28 step:26456 [D loss: 0.249827, acc.: 56.25%] [G loss: 0.313786]\n",
      "epoch:28 step:26457 [D loss: 0.233313, acc.: 59.38%] [G loss: 0.272844]\n",
      "epoch:28 step:26458 [D loss: 0.249699, acc.: 53.12%] [G loss: 0.286837]\n",
      "epoch:28 step:26459 [D loss: 0.213969, acc.: 71.09%] [G loss: 0.289736]\n",
      "epoch:28 step:26460 [D loss: 0.231692, acc.: 62.50%] [G loss: 0.296854]\n",
      "epoch:28 step:26461 [D loss: 0.248222, acc.: 52.34%] [G loss: 0.308417]\n",
      "epoch:28 step:26462 [D loss: 0.239485, acc.: 59.38%] [G loss: 0.303015]\n",
      "epoch:28 step:26463 [D loss: 0.250171, acc.: 57.81%] [G loss: 0.287298]\n",
      "epoch:28 step:26464 [D loss: 0.248554, acc.: 56.25%] [G loss: 0.306207]\n",
      "epoch:28 step:26465 [D loss: 0.228537, acc.: 58.59%] [G loss: 0.271534]\n",
      "epoch:28 step:26466 [D loss: 0.240414, acc.: 57.03%] [G loss: 0.332050]\n",
      "epoch:28 step:26467 [D loss: 0.229764, acc.: 60.94%] [G loss: 0.314289]\n",
      "epoch:28 step:26468 [D loss: 0.257126, acc.: 58.59%] [G loss: 0.321107]\n",
      "epoch:28 step:26469 [D loss: 0.264423, acc.: 43.75%] [G loss: 0.319199]\n",
      "epoch:28 step:26470 [D loss: 0.226419, acc.: 67.19%] [G loss: 0.273649]\n",
      "epoch:28 step:26471 [D loss: 0.241461, acc.: 59.38%] [G loss: 0.321643]\n",
      "epoch:28 step:26472 [D loss: 0.228917, acc.: 64.84%] [G loss: 0.296617]\n",
      "epoch:28 step:26473 [D loss: 0.243392, acc.: 60.16%] [G loss: 0.286286]\n",
      "epoch:28 step:26474 [D loss: 0.222119, acc.: 60.94%] [G loss: 0.324960]\n",
      "epoch:28 step:26475 [D loss: 0.233837, acc.: 58.59%] [G loss: 0.325307]\n",
      "epoch:28 step:26476 [D loss: 0.255810, acc.: 50.78%] [G loss: 0.283744]\n",
      "epoch:28 step:26477 [D loss: 0.232379, acc.: 60.94%] [G loss: 0.283650]\n",
      "epoch:28 step:26478 [D loss: 0.239391, acc.: 62.50%] [G loss: 0.324796]\n",
      "epoch:28 step:26479 [D loss: 0.250938, acc.: 53.12%] [G loss: 0.275834]\n",
      "epoch:28 step:26480 [D loss: 0.248907, acc.: 50.78%] [G loss: 0.286950]\n",
      "epoch:28 step:26481 [D loss: 0.228288, acc.: 67.19%] [G loss: 0.313622]\n",
      "epoch:28 step:26482 [D loss: 0.237049, acc.: 57.03%] [G loss: 0.303535]\n",
      "epoch:28 step:26483 [D loss: 0.239889, acc.: 60.16%] [G loss: 0.292009]\n",
      "epoch:28 step:26484 [D loss: 0.234351, acc.: 59.38%] [G loss: 0.270280]\n",
      "epoch:28 step:26485 [D loss: 0.253795, acc.: 53.12%] [G loss: 0.314720]\n",
      "epoch:28 step:26486 [D loss: 0.245274, acc.: 52.34%] [G loss: 0.298676]\n",
      "epoch:28 step:26487 [D loss: 0.247346, acc.: 54.69%] [G loss: 0.283298]\n",
      "epoch:28 step:26488 [D loss: 0.238478, acc.: 65.62%] [G loss: 0.322509]\n",
      "epoch:28 step:26489 [D loss: 0.244723, acc.: 56.25%] [G loss: 0.297620]\n",
      "epoch:28 step:26490 [D loss: 0.245515, acc.: 57.81%] [G loss: 0.299169]\n",
      "epoch:28 step:26491 [D loss: 0.238421, acc.: 57.81%] [G loss: 0.310986]\n",
      "epoch:28 step:26492 [D loss: 0.238520, acc.: 61.72%] [G loss: 0.327382]\n",
      "epoch:28 step:26493 [D loss: 0.238498, acc.: 62.50%] [G loss: 0.292484]\n",
      "epoch:28 step:26494 [D loss: 0.234252, acc.: 60.94%] [G loss: 0.278049]\n",
      "epoch:28 step:26495 [D loss: 0.247329, acc.: 56.25%] [G loss: 0.276744]\n",
      "epoch:28 step:26496 [D loss: 0.239311, acc.: 55.47%] [G loss: 0.309160]\n",
      "epoch:28 step:26497 [D loss: 0.240834, acc.: 59.38%] [G loss: 0.271024]\n",
      "epoch:28 step:26498 [D loss: 0.250366, acc.: 58.59%] [G loss: 0.281247]\n",
      "epoch:28 step:26499 [D loss: 0.243662, acc.: 54.69%] [G loss: 0.315913]\n",
      "epoch:28 step:26500 [D loss: 0.214795, acc.: 67.19%] [G loss: 0.330764]\n",
      "epoch:28 step:26501 [D loss: 0.240498, acc.: 57.81%] [G loss: 0.289309]\n",
      "epoch:28 step:26502 [D loss: 0.246676, acc.: 63.28%] [G loss: 0.313678]\n",
      "epoch:28 step:26503 [D loss: 0.247718, acc.: 48.44%] [G loss: 0.317024]\n",
      "epoch:28 step:26504 [D loss: 0.243597, acc.: 57.03%] [G loss: 0.301278]\n",
      "epoch:28 step:26505 [D loss: 0.230823, acc.: 63.28%] [G loss: 0.330824]\n",
      "epoch:28 step:26506 [D loss: 0.238333, acc.: 52.34%] [G loss: 0.312621]\n",
      "epoch:28 step:26507 [D loss: 0.224928, acc.: 63.28%] [G loss: 0.313361]\n",
      "epoch:28 step:26508 [D loss: 0.238416, acc.: 59.38%] [G loss: 0.326447]\n",
      "epoch:28 step:26509 [D loss: 0.242186, acc.: 51.56%] [G loss: 0.268217]\n",
      "epoch:28 step:26510 [D loss: 0.253656, acc.: 55.47%] [G loss: 0.306392]\n",
      "epoch:28 step:26511 [D loss: 0.255296, acc.: 49.22%] [G loss: 0.310054]\n",
      "epoch:28 step:26512 [D loss: 0.231343, acc.: 61.72%] [G loss: 0.300595]\n",
      "epoch:28 step:26513 [D loss: 0.226975, acc.: 64.84%] [G loss: 0.298729]\n",
      "epoch:28 step:26514 [D loss: 0.255798, acc.: 51.56%] [G loss: 0.320920]\n",
      "epoch:28 step:26515 [D loss: 0.240620, acc.: 53.12%] [G loss: 0.277532]\n",
      "epoch:28 step:26516 [D loss: 0.241190, acc.: 62.50%] [G loss: 0.301604]\n",
      "epoch:28 step:26517 [D loss: 0.218220, acc.: 64.84%] [G loss: 0.296860]\n",
      "epoch:28 step:26518 [D loss: 0.225905, acc.: 67.97%] [G loss: 0.284062]\n",
      "epoch:28 step:26519 [D loss: 0.222201, acc.: 63.28%] [G loss: 0.323330]\n",
      "epoch:28 step:26520 [D loss: 0.223524, acc.: 65.62%] [G loss: 0.315598]\n",
      "epoch:28 step:26521 [D loss: 0.225533, acc.: 62.50%] [G loss: 0.273132]\n",
      "epoch:28 step:26522 [D loss: 0.252541, acc.: 50.00%] [G loss: 0.272706]\n",
      "epoch:28 step:26523 [D loss: 0.238025, acc.: 60.94%] [G loss: 0.338346]\n",
      "epoch:28 step:26524 [D loss: 0.234771, acc.: 58.59%] [G loss: 0.314076]\n",
      "epoch:28 step:26525 [D loss: 0.238619, acc.: 56.25%] [G loss: 0.312766]\n",
      "epoch:28 step:26526 [D loss: 0.255187, acc.: 57.03%] [G loss: 0.279367]\n",
      "epoch:28 step:26527 [D loss: 0.226069, acc.: 61.72%] [G loss: 0.317785]\n",
      "epoch:28 step:26528 [D loss: 0.229530, acc.: 67.19%] [G loss: 0.332205]\n",
      "epoch:28 step:26529 [D loss: 0.232897, acc.: 60.94%] [G loss: 0.296215]\n",
      "epoch:28 step:26530 [D loss: 0.239632, acc.: 58.59%] [G loss: 0.337688]\n",
      "epoch:28 step:26531 [D loss: 0.239214, acc.: 60.94%] [G loss: 0.332587]\n",
      "epoch:28 step:26532 [D loss: 0.239885, acc.: 57.81%] [G loss: 0.290120]\n",
      "epoch:28 step:26533 [D loss: 0.229780, acc.: 60.16%] [G loss: 0.302435]\n",
      "epoch:28 step:26534 [D loss: 0.238611, acc.: 60.16%] [G loss: 0.292159]\n",
      "epoch:28 step:26535 [D loss: 0.233003, acc.: 57.81%] [G loss: 0.331357]\n",
      "epoch:28 step:26536 [D loss: 0.237778, acc.: 55.47%] [G loss: 0.315569]\n",
      "epoch:28 step:26537 [D loss: 0.263947, acc.: 50.00%] [G loss: 0.264998]\n",
      "epoch:28 step:26538 [D loss: 0.229934, acc.: 63.28%] [G loss: 0.295749]\n",
      "epoch:28 step:26539 [D loss: 0.258599, acc.: 50.00%] [G loss: 0.289815]\n",
      "epoch:28 step:26540 [D loss: 0.230923, acc.: 57.03%] [G loss: 0.287088]\n",
      "epoch:28 step:26541 [D loss: 0.238162, acc.: 57.81%] [G loss: 0.296537]\n",
      "epoch:28 step:26542 [D loss: 0.232063, acc.: 64.06%] [G loss: 0.302301]\n",
      "epoch:28 step:26543 [D loss: 0.235430, acc.: 55.47%] [G loss: 0.297768]\n",
      "epoch:28 step:26544 [D loss: 0.234613, acc.: 57.03%] [G loss: 0.305202]\n",
      "epoch:28 step:26545 [D loss: 0.239940, acc.: 54.69%] [G loss: 0.299854]\n",
      "epoch:28 step:26546 [D loss: 0.210211, acc.: 73.44%] [G loss: 0.322006]\n",
      "epoch:28 step:26547 [D loss: 0.238773, acc.: 55.47%] [G loss: 0.318460]\n",
      "epoch:28 step:26548 [D loss: 0.244970, acc.: 54.69%] [G loss: 0.283568]\n",
      "epoch:28 step:26549 [D loss: 0.244613, acc.: 54.69%] [G loss: 0.284848]\n",
      "epoch:28 step:26550 [D loss: 0.230530, acc.: 54.69%] [G loss: 0.273696]\n",
      "epoch:28 step:26551 [D loss: 0.237283, acc.: 59.38%] [G loss: 0.289246]\n",
      "epoch:28 step:26552 [D loss: 0.239497, acc.: 57.81%] [G loss: 0.298526]\n",
      "epoch:28 step:26553 [D loss: 0.242475, acc.: 56.25%] [G loss: 0.301760]\n",
      "epoch:28 step:26554 [D loss: 0.239044, acc.: 57.03%] [G loss: 0.282140]\n",
      "epoch:28 step:26555 [D loss: 0.248141, acc.: 53.91%] [G loss: 0.299722]\n",
      "epoch:28 step:26556 [D loss: 0.245718, acc.: 53.12%] [G loss: 0.298289]\n",
      "epoch:28 step:26557 [D loss: 0.237091, acc.: 59.38%] [G loss: 0.296444]\n",
      "epoch:28 step:26558 [D loss: 0.252093, acc.: 58.59%] [G loss: 0.290156]\n",
      "epoch:28 step:26559 [D loss: 0.230701, acc.: 59.38%] [G loss: 0.301603]\n",
      "epoch:28 step:26560 [D loss: 0.237968, acc.: 58.59%] [G loss: 0.314435]\n",
      "epoch:28 step:26561 [D loss: 0.229586, acc.: 65.62%] [G loss: 0.309894]\n",
      "epoch:28 step:26562 [D loss: 0.220336, acc.: 65.62%] [G loss: 0.315645]\n",
      "epoch:28 step:26563 [D loss: 0.224195, acc.: 62.50%] [G loss: 0.337296]\n",
      "epoch:28 step:26564 [D loss: 0.246183, acc.: 50.78%] [G loss: 0.268986]\n",
      "epoch:28 step:26565 [D loss: 0.235949, acc.: 61.72%] [G loss: 0.300761]\n",
      "epoch:28 step:26566 [D loss: 0.236366, acc.: 60.16%] [G loss: 0.313009]\n",
      "epoch:28 step:26567 [D loss: 0.236206, acc.: 59.38%] [G loss: 0.310987]\n",
      "epoch:28 step:26568 [D loss: 0.246235, acc.: 57.03%] [G loss: 0.299937]\n",
      "epoch:28 step:26569 [D loss: 0.248082, acc.: 53.91%] [G loss: 0.332497]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:28 step:26570 [D loss: 0.224454, acc.: 60.94%] [G loss: 0.318038]\n",
      "epoch:28 step:26571 [D loss: 0.234370, acc.: 60.16%] [G loss: 0.287229]\n",
      "epoch:28 step:26572 [D loss: 0.231059, acc.: 58.59%] [G loss: 0.266921]\n",
      "epoch:28 step:26573 [D loss: 0.239478, acc.: 54.69%] [G loss: 0.305119]\n",
      "epoch:28 step:26574 [D loss: 0.249088, acc.: 55.47%] [G loss: 0.280056]\n",
      "epoch:28 step:26575 [D loss: 0.256168, acc.: 55.47%] [G loss: 0.309668]\n",
      "epoch:28 step:26576 [D loss: 0.227385, acc.: 61.72%] [G loss: 0.281192]\n",
      "epoch:28 step:26577 [D loss: 0.245560, acc.: 51.56%] [G loss: 0.302297]\n",
      "epoch:28 step:26578 [D loss: 0.235818, acc.: 57.03%] [G loss: 0.320668]\n",
      "epoch:28 step:26579 [D loss: 0.233036, acc.: 60.16%] [G loss: 0.286300]\n",
      "epoch:28 step:26580 [D loss: 0.252075, acc.: 51.56%] [G loss: 0.286501]\n",
      "epoch:28 step:26581 [D loss: 0.245751, acc.: 55.47%] [G loss: 0.289400]\n",
      "epoch:28 step:26582 [D loss: 0.254039, acc.: 53.91%] [G loss: 0.320285]\n",
      "epoch:28 step:26583 [D loss: 0.232945, acc.: 53.12%] [G loss: 0.289218]\n",
      "epoch:28 step:26584 [D loss: 0.232821, acc.: 58.59%] [G loss: 0.291851]\n",
      "epoch:28 step:26585 [D loss: 0.251675, acc.: 52.34%] [G loss: 0.328000]\n",
      "epoch:28 step:26586 [D loss: 0.234238, acc.: 64.06%] [G loss: 0.306633]\n",
      "epoch:28 step:26587 [D loss: 0.235907, acc.: 64.84%] [G loss: 0.267473]\n",
      "epoch:28 step:26588 [D loss: 0.229031, acc.: 64.84%] [G loss: 0.312062]\n",
      "epoch:28 step:26589 [D loss: 0.246422, acc.: 53.91%] [G loss: 0.257918]\n",
      "epoch:28 step:26590 [D loss: 0.255327, acc.: 50.78%] [G loss: 0.305795]\n",
      "epoch:28 step:26591 [D loss: 0.232092, acc.: 61.72%] [G loss: 0.284597]\n",
      "epoch:28 step:26592 [D loss: 0.251200, acc.: 53.12%] [G loss: 0.305835]\n",
      "epoch:28 step:26593 [D loss: 0.255091, acc.: 49.22%] [G loss: 0.306431]\n",
      "epoch:28 step:26594 [D loss: 0.240914, acc.: 57.03%] [G loss: 0.302584]\n",
      "epoch:28 step:26595 [D loss: 0.244806, acc.: 56.25%] [G loss: 0.308874]\n",
      "epoch:28 step:26596 [D loss: 0.234320, acc.: 60.94%] [G loss: 0.304438]\n",
      "epoch:28 step:26597 [D loss: 0.251952, acc.: 47.66%] [G loss: 0.308083]\n",
      "epoch:28 step:26598 [D loss: 0.266143, acc.: 50.78%] [G loss: 0.315485]\n",
      "epoch:28 step:26599 [D loss: 0.230089, acc.: 64.06%] [G loss: 0.291817]\n",
      "epoch:28 step:26600 [D loss: 0.227848, acc.: 64.84%] [G loss: 0.336561]\n",
      "epoch:28 step:26601 [D loss: 0.232306, acc.: 60.94%] [G loss: 0.321963]\n",
      "epoch:28 step:26602 [D loss: 0.241883, acc.: 57.81%] [G loss: 0.305961]\n",
      "epoch:28 step:26603 [D loss: 0.225178, acc.: 63.28%] [G loss: 0.333133]\n",
      "epoch:28 step:26604 [D loss: 0.236878, acc.: 58.59%] [G loss: 0.288913]\n",
      "epoch:28 step:26605 [D loss: 0.225486, acc.: 66.41%] [G loss: 0.285672]\n",
      "epoch:28 step:26606 [D loss: 0.259538, acc.: 48.44%] [G loss: 0.286142]\n",
      "epoch:28 step:26607 [D loss: 0.256160, acc.: 49.22%] [G loss: 0.293398]\n",
      "epoch:28 step:26608 [D loss: 0.237328, acc.: 57.81%] [G loss: 0.267831]\n",
      "epoch:28 step:26609 [D loss: 0.251139, acc.: 55.47%] [G loss: 0.271269]\n",
      "epoch:28 step:26610 [D loss: 0.223399, acc.: 61.72%] [G loss: 0.308515]\n",
      "epoch:28 step:26611 [D loss: 0.248280, acc.: 59.38%] [G loss: 0.302488]\n",
      "epoch:28 step:26612 [D loss: 0.254212, acc.: 54.69%] [G loss: 0.297068]\n",
      "epoch:28 step:26613 [D loss: 0.239875, acc.: 61.72%] [G loss: 0.289659]\n",
      "epoch:28 step:26614 [D loss: 0.253861, acc.: 54.69%] [G loss: 0.304386]\n",
      "epoch:28 step:26615 [D loss: 0.259611, acc.: 51.56%] [G loss: 0.312581]\n",
      "epoch:28 step:26616 [D loss: 0.246541, acc.: 54.69%] [G loss: 0.294971]\n",
      "epoch:28 step:26617 [D loss: 0.237781, acc.: 60.94%] [G loss: 0.308455]\n",
      "epoch:28 step:26618 [D loss: 0.244832, acc.: 58.59%] [G loss: 0.278579]\n",
      "epoch:28 step:26619 [D loss: 0.236740, acc.: 55.47%] [G loss: 0.316460]\n",
      "epoch:28 step:26620 [D loss: 0.222054, acc.: 64.06%] [G loss: 0.297489]\n",
      "epoch:28 step:26621 [D loss: 0.243324, acc.: 59.38%] [G loss: 0.285728]\n",
      "epoch:28 step:26622 [D loss: 0.244036, acc.: 53.12%] [G loss: 0.306338]\n",
      "epoch:28 step:26623 [D loss: 0.227219, acc.: 57.03%] [G loss: 0.282282]\n",
      "epoch:28 step:26624 [D loss: 0.241561, acc.: 57.03%] [G loss: 0.305451]\n",
      "epoch:28 step:26625 [D loss: 0.235711, acc.: 60.16%] [G loss: 0.296450]\n",
      "epoch:28 step:26626 [D loss: 0.248850, acc.: 51.56%] [G loss: 0.267753]\n",
      "epoch:28 step:26627 [D loss: 0.245559, acc.: 57.03%] [G loss: 0.282916]\n",
      "epoch:28 step:26628 [D loss: 0.239811, acc.: 57.81%] [G loss: 0.286382]\n",
      "epoch:28 step:26629 [D loss: 0.231308, acc.: 66.41%] [G loss: 0.294177]\n",
      "epoch:28 step:26630 [D loss: 0.229085, acc.: 55.47%] [G loss: 0.285758]\n",
      "epoch:28 step:26631 [D loss: 0.237792, acc.: 57.03%] [G loss: 0.287722]\n",
      "epoch:28 step:26632 [D loss: 0.246247, acc.: 53.91%] [G loss: 0.293762]\n",
      "epoch:28 step:26633 [D loss: 0.231814, acc.: 57.81%] [G loss: 0.335317]\n",
      "epoch:28 step:26634 [D loss: 0.227605, acc.: 58.59%] [G loss: 0.308091]\n",
      "epoch:28 step:26635 [D loss: 0.238954, acc.: 57.81%] [G loss: 0.290055]\n",
      "epoch:28 step:26636 [D loss: 0.246686, acc.: 56.25%] [G loss: 0.297383]\n",
      "epoch:28 step:26637 [D loss: 0.237374, acc.: 59.38%] [G loss: 0.301498]\n",
      "epoch:28 step:26638 [D loss: 0.236501, acc.: 57.03%] [G loss: 0.312269]\n",
      "epoch:28 step:26639 [D loss: 0.248103, acc.: 58.59%] [G loss: 0.305407]\n",
      "epoch:28 step:26640 [D loss: 0.248734, acc.: 48.44%] [G loss: 0.307270]\n",
      "epoch:28 step:26641 [D loss: 0.241480, acc.: 57.81%] [G loss: 0.286830]\n",
      "epoch:28 step:26642 [D loss: 0.235433, acc.: 56.25%] [G loss: 0.285690]\n",
      "epoch:28 step:26643 [D loss: 0.248531, acc.: 58.59%] [G loss: 0.323046]\n",
      "epoch:28 step:26644 [D loss: 0.220658, acc.: 65.62%] [G loss: 0.302923]\n",
      "epoch:28 step:26645 [D loss: 0.230688, acc.: 62.50%] [G loss: 0.317661]\n",
      "epoch:28 step:26646 [D loss: 0.243098, acc.: 58.59%] [G loss: 0.311278]\n",
      "epoch:28 step:26647 [D loss: 0.230978, acc.: 63.28%] [G loss: 0.292210]\n",
      "epoch:28 step:26648 [D loss: 0.244556, acc.: 57.81%] [G loss: 0.298305]\n",
      "epoch:28 step:26649 [D loss: 0.229881, acc.: 65.62%] [G loss: 0.315406]\n",
      "epoch:28 step:26650 [D loss: 0.232329, acc.: 62.50%] [G loss: 0.314438]\n",
      "epoch:28 step:26651 [D loss: 0.234861, acc.: 62.50%] [G loss: 0.305880]\n",
      "epoch:28 step:26652 [D loss: 0.234150, acc.: 60.16%] [G loss: 0.327820]\n",
      "epoch:28 step:26653 [D loss: 0.239925, acc.: 64.06%] [G loss: 0.309926]\n",
      "epoch:28 step:26654 [D loss: 0.231156, acc.: 61.72%] [G loss: 0.292645]\n",
      "epoch:28 step:26655 [D loss: 0.236230, acc.: 61.72%] [G loss: 0.288601]\n",
      "epoch:28 step:26656 [D loss: 0.232025, acc.: 64.84%] [G loss: 0.313917]\n",
      "epoch:28 step:26657 [D loss: 0.233187, acc.: 60.94%] [G loss: 0.288688]\n",
      "epoch:28 step:26658 [D loss: 0.246197, acc.: 50.78%] [G loss: 0.289188]\n",
      "epoch:28 step:26659 [D loss: 0.246541, acc.: 52.34%] [G loss: 0.305786]\n",
      "epoch:28 step:26660 [D loss: 0.232178, acc.: 59.38%] [G loss: 0.270072]\n",
      "epoch:28 step:26661 [D loss: 0.249292, acc.: 57.81%] [G loss: 0.292231]\n",
      "epoch:28 step:26662 [D loss: 0.234398, acc.: 58.59%] [G loss: 0.287485]\n",
      "epoch:28 step:26663 [D loss: 0.238249, acc.: 62.50%] [G loss: 0.320214]\n",
      "epoch:28 step:26664 [D loss: 0.234792, acc.: 60.94%] [G loss: 0.291967]\n",
      "epoch:28 step:26665 [D loss: 0.249906, acc.: 55.47%] [G loss: 0.324600]\n",
      "epoch:28 step:26666 [D loss: 0.234709, acc.: 58.59%] [G loss: 0.319071]\n",
      "epoch:28 step:26667 [D loss: 0.234399, acc.: 57.81%] [G loss: 0.297467]\n",
      "epoch:28 step:26668 [D loss: 0.239028, acc.: 58.59%] [G loss: 0.277532]\n",
      "epoch:28 step:26669 [D loss: 0.239069, acc.: 59.38%] [G loss: 0.275926]\n",
      "epoch:28 step:26670 [D loss: 0.239510, acc.: 59.38%] [G loss: 0.302363]\n",
      "epoch:28 step:26671 [D loss: 0.228158, acc.: 63.28%] [G loss: 0.306048]\n",
      "epoch:28 step:26672 [D loss: 0.239085, acc.: 57.03%] [G loss: 0.289973]\n",
      "epoch:28 step:26673 [D loss: 0.237489, acc.: 57.81%] [G loss: 0.267411]\n",
      "epoch:28 step:26674 [D loss: 0.251710, acc.: 55.47%] [G loss: 0.309254]\n",
      "epoch:28 step:26675 [D loss: 0.235031, acc.: 60.16%] [G loss: 0.306911]\n",
      "epoch:28 step:26676 [D loss: 0.220841, acc.: 66.41%] [G loss: 0.273524]\n",
      "epoch:28 step:26677 [D loss: 0.244802, acc.: 55.47%] [G loss: 0.304669]\n",
      "epoch:28 step:26678 [D loss: 0.244540, acc.: 60.16%] [G loss: 0.309384]\n",
      "epoch:28 step:26679 [D loss: 0.238737, acc.: 61.72%] [G loss: 0.303457]\n",
      "epoch:28 step:26680 [D loss: 0.237074, acc.: 58.59%] [G loss: 0.302043]\n",
      "epoch:28 step:26681 [D loss: 0.231573, acc.: 60.94%] [G loss: 0.287297]\n",
      "epoch:28 step:26682 [D loss: 0.245409, acc.: 56.25%] [G loss: 0.292555]\n",
      "epoch:28 step:26683 [D loss: 0.230137, acc.: 60.16%] [G loss: 0.305840]\n",
      "epoch:28 step:26684 [D loss: 0.233047, acc.: 56.25%] [G loss: 0.331880]\n",
      "epoch:28 step:26685 [D loss: 0.248348, acc.: 51.56%] [G loss: 0.283802]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:28 step:26686 [D loss: 0.231873, acc.: 57.81%] [G loss: 0.312932]\n",
      "epoch:28 step:26687 [D loss: 0.232161, acc.: 56.25%] [G loss: 0.297458]\n",
      "epoch:28 step:26688 [D loss: 0.251554, acc.: 56.25%] [G loss: 0.308033]\n",
      "epoch:28 step:26689 [D loss: 0.249196, acc.: 58.59%] [G loss: 0.296588]\n",
      "epoch:28 step:26690 [D loss: 0.211404, acc.: 68.75%] [G loss: 0.288058]\n",
      "epoch:28 step:26691 [D loss: 0.240664, acc.: 56.25%] [G loss: 0.294937]\n",
      "epoch:28 step:26692 [D loss: 0.260766, acc.: 57.03%] [G loss: 0.318979]\n",
      "epoch:28 step:26693 [D loss: 0.248407, acc.: 54.69%] [G loss: 0.311835]\n",
      "epoch:28 step:26694 [D loss: 0.234064, acc.: 60.16%] [G loss: 0.315558]\n",
      "epoch:28 step:26695 [D loss: 0.231191, acc.: 63.28%] [G loss: 0.288484]\n",
      "epoch:28 step:26696 [D loss: 0.254758, acc.: 53.12%] [G loss: 0.299674]\n",
      "epoch:28 step:26697 [D loss: 0.256460, acc.: 55.47%] [G loss: 0.319195]\n",
      "epoch:28 step:26698 [D loss: 0.250962, acc.: 53.91%] [G loss: 0.284689]\n",
      "epoch:28 step:26699 [D loss: 0.260130, acc.: 46.09%] [G loss: 0.295341]\n",
      "epoch:28 step:26700 [D loss: 0.250489, acc.: 53.91%] [G loss: 0.325989]\n",
      "epoch:28 step:26701 [D loss: 0.226607, acc.: 63.28%] [G loss: 0.302639]\n",
      "epoch:28 step:26702 [D loss: 0.234242, acc.: 53.91%] [G loss: 0.276807]\n",
      "epoch:28 step:26703 [D loss: 0.225981, acc.: 63.28%] [G loss: 0.292150]\n",
      "epoch:28 step:26704 [D loss: 0.226087, acc.: 60.94%] [G loss: 0.316156]\n",
      "epoch:28 step:26705 [D loss: 0.237437, acc.: 60.16%] [G loss: 0.265083]\n",
      "epoch:28 step:26706 [D loss: 0.249054, acc.: 53.91%] [G loss: 0.318118]\n",
      "epoch:28 step:26707 [D loss: 0.245979, acc.: 51.56%] [G loss: 0.271005]\n",
      "epoch:28 step:26708 [D loss: 0.258503, acc.: 42.97%] [G loss: 0.276025]\n",
      "epoch:28 step:26709 [D loss: 0.248661, acc.: 55.47%] [G loss: 0.295799]\n",
      "epoch:28 step:26710 [D loss: 0.236509, acc.: 58.59%] [G loss: 0.321705]\n",
      "epoch:28 step:26711 [D loss: 0.233439, acc.: 61.72%] [G loss: 0.307948]\n",
      "epoch:28 step:26712 [D loss: 0.229265, acc.: 62.50%] [G loss: 0.315829]\n",
      "epoch:28 step:26713 [D loss: 0.252627, acc.: 49.22%] [G loss: 0.278084]\n",
      "epoch:28 step:26714 [D loss: 0.242827, acc.: 60.94%] [G loss: 0.294503]\n",
      "epoch:28 step:26715 [D loss: 0.244828, acc.: 53.12%] [G loss: 0.304124]\n",
      "epoch:28 step:26716 [D loss: 0.254350, acc.: 52.34%] [G loss: 0.301669]\n",
      "epoch:28 step:26717 [D loss: 0.227067, acc.: 61.72%] [G loss: 0.304886]\n",
      "epoch:28 step:26718 [D loss: 0.225576, acc.: 67.97%] [G loss: 0.306389]\n",
      "epoch:28 step:26719 [D loss: 0.235021, acc.: 62.50%] [G loss: 0.307383]\n",
      "epoch:28 step:26720 [D loss: 0.234001, acc.: 58.59%] [G loss: 0.318612]\n",
      "epoch:28 step:26721 [D loss: 0.244454, acc.: 60.94%] [G loss: 0.325829]\n",
      "epoch:28 step:26722 [D loss: 0.241965, acc.: 57.81%] [G loss: 0.310427]\n",
      "epoch:28 step:26723 [D loss: 0.235019, acc.: 60.16%] [G loss: 0.325253]\n",
      "epoch:28 step:26724 [D loss: 0.229950, acc.: 64.06%] [G loss: 0.278128]\n",
      "epoch:28 step:26725 [D loss: 0.230255, acc.: 64.84%] [G loss: 0.298941]\n",
      "epoch:28 step:26726 [D loss: 0.238258, acc.: 57.81%] [G loss: 0.277506]\n",
      "epoch:28 step:26727 [D loss: 0.250573, acc.: 52.34%] [G loss: 0.275059]\n",
      "epoch:28 step:26728 [D loss: 0.248777, acc.: 52.34%] [G loss: 0.278907]\n",
      "epoch:28 step:26729 [D loss: 0.227739, acc.: 57.81%] [G loss: 0.310529]\n",
      "epoch:28 step:26730 [D loss: 0.226198, acc.: 64.06%] [G loss: 0.331053]\n",
      "epoch:28 step:26731 [D loss: 0.246499, acc.: 53.91%] [G loss: 0.290107]\n",
      "epoch:28 step:26732 [D loss: 0.239030, acc.: 56.25%] [G loss: 0.311529]\n",
      "epoch:28 step:26733 [D loss: 0.239366, acc.: 64.06%] [G loss: 0.313314]\n",
      "epoch:28 step:26734 [D loss: 0.210173, acc.: 65.62%] [G loss: 0.305218]\n",
      "epoch:28 step:26735 [D loss: 0.224731, acc.: 60.16%] [G loss: 0.284635]\n",
      "epoch:28 step:26736 [D loss: 0.251661, acc.: 58.59%] [G loss: 0.305405]\n",
      "epoch:28 step:26737 [D loss: 0.221357, acc.: 63.28%] [G loss: 0.280636]\n",
      "epoch:28 step:26738 [D loss: 0.240846, acc.: 57.81%] [G loss: 0.312702]\n",
      "epoch:28 step:26739 [D loss: 0.250116, acc.: 47.66%] [G loss: 0.288294]\n",
      "epoch:28 step:26740 [D loss: 0.237436, acc.: 60.16%] [G loss: 0.259339]\n",
      "epoch:28 step:26741 [D loss: 0.228246, acc.: 60.94%] [G loss: 0.275122]\n",
      "epoch:28 step:26742 [D loss: 0.232704, acc.: 61.72%] [G loss: 0.294136]\n",
      "epoch:28 step:26743 [D loss: 0.257265, acc.: 52.34%] [G loss: 0.304463]\n",
      "epoch:28 step:26744 [D loss: 0.240988, acc.: 57.81%] [G loss: 0.271488]\n",
      "epoch:28 step:26745 [D loss: 0.244208, acc.: 56.25%] [G loss: 0.301265]\n",
      "epoch:28 step:26746 [D loss: 0.240367, acc.: 53.91%] [G loss: 0.288383]\n",
      "epoch:28 step:26747 [D loss: 0.241197, acc.: 57.03%] [G loss: 0.311796]\n",
      "epoch:28 step:26748 [D loss: 0.242411, acc.: 56.25%] [G loss: 0.329956]\n",
      "epoch:28 step:26749 [D loss: 0.246663, acc.: 53.12%] [G loss: 0.296755]\n",
      "epoch:28 step:26750 [D loss: 0.238735, acc.: 64.84%] [G loss: 0.301184]\n",
      "epoch:28 step:26751 [D loss: 0.256688, acc.: 50.78%] [G loss: 0.276119]\n",
      "epoch:28 step:26752 [D loss: 0.246149, acc.: 57.03%] [G loss: 0.313858]\n",
      "epoch:28 step:26753 [D loss: 0.235072, acc.: 58.59%] [G loss: 0.291947]\n",
      "epoch:28 step:26754 [D loss: 0.236341, acc.: 60.94%] [G loss: 0.272217]\n",
      "epoch:28 step:26755 [D loss: 0.240682, acc.: 57.03%] [G loss: 0.295473]\n",
      "epoch:28 step:26756 [D loss: 0.221388, acc.: 61.72%] [G loss: 0.318365]\n",
      "epoch:28 step:26757 [D loss: 0.232149, acc.: 60.16%] [G loss: 0.319238]\n",
      "epoch:28 step:26758 [D loss: 0.246596, acc.: 50.78%] [G loss: 0.302882]\n",
      "epoch:28 step:26759 [D loss: 0.234466, acc.: 60.16%] [G loss: 0.326807]\n",
      "epoch:28 step:26760 [D loss: 0.236341, acc.: 59.38%] [G loss: 0.290184]\n",
      "epoch:28 step:26761 [D loss: 0.234347, acc.: 67.97%] [G loss: 0.301531]\n",
      "epoch:28 step:26762 [D loss: 0.238856, acc.: 61.72%] [G loss: 0.307865]\n",
      "epoch:28 step:26763 [D loss: 0.242163, acc.: 60.16%] [G loss: 0.321865]\n",
      "epoch:28 step:26764 [D loss: 0.225515, acc.: 60.94%] [G loss: 0.306085]\n",
      "epoch:28 step:26765 [D loss: 0.214602, acc.: 70.31%] [G loss: 0.298354]\n",
      "epoch:28 step:26766 [D loss: 0.233709, acc.: 60.94%] [G loss: 0.298815]\n",
      "epoch:28 step:26767 [D loss: 0.230894, acc.: 60.16%] [G loss: 0.323499]\n",
      "epoch:28 step:26768 [D loss: 0.253801, acc.: 51.56%] [G loss: 0.294217]\n",
      "epoch:28 step:26769 [D loss: 0.241561, acc.: 60.94%] [G loss: 0.335906]\n",
      "epoch:28 step:26770 [D loss: 0.253745, acc.: 54.69%] [G loss: 0.298567]\n",
      "epoch:28 step:26771 [D loss: 0.242901, acc.: 60.16%] [G loss: 0.295548]\n",
      "epoch:28 step:26772 [D loss: 0.231866, acc.: 57.81%] [G loss: 0.295238]\n",
      "epoch:28 step:26773 [D loss: 0.242722, acc.: 57.03%] [G loss: 0.293520]\n",
      "epoch:28 step:26774 [D loss: 0.239120, acc.: 57.81%] [G loss: 0.304159]\n",
      "epoch:28 step:26775 [D loss: 0.237410, acc.: 56.25%] [G loss: 0.329305]\n",
      "epoch:28 step:26776 [D loss: 0.229555, acc.: 64.84%] [G loss: 0.302469]\n",
      "epoch:28 step:26777 [D loss: 0.246655, acc.: 54.69%] [G loss: 0.298753]\n",
      "epoch:28 step:26778 [D loss: 0.251802, acc.: 50.78%] [G loss: 0.259363]\n",
      "epoch:28 step:26779 [D loss: 0.251802, acc.: 57.81%] [G loss: 0.290328]\n",
      "epoch:28 step:26780 [D loss: 0.235378, acc.: 58.59%] [G loss: 0.294784]\n",
      "epoch:28 step:26781 [D loss: 0.222955, acc.: 61.72%] [G loss: 0.309308]\n",
      "epoch:28 step:26782 [D loss: 0.221709, acc.: 66.41%] [G loss: 0.308195]\n",
      "epoch:28 step:26783 [D loss: 0.227038, acc.: 61.72%] [G loss: 0.314003]\n",
      "epoch:28 step:26784 [D loss: 0.238265, acc.: 57.03%] [G loss: 0.303918]\n",
      "epoch:28 step:26785 [D loss: 0.233152, acc.: 67.19%] [G loss: 0.269700]\n",
      "epoch:28 step:26786 [D loss: 0.237627, acc.: 58.59%] [G loss: 0.305833]\n",
      "epoch:28 step:26787 [D loss: 0.225282, acc.: 63.28%] [G loss: 0.292966]\n",
      "epoch:28 step:26788 [D loss: 0.244432, acc.: 54.69%] [G loss: 0.289654]\n",
      "epoch:28 step:26789 [D loss: 0.242928, acc.: 55.47%] [G loss: 0.307429]\n",
      "epoch:28 step:26790 [D loss: 0.249547, acc.: 50.00%] [G loss: 0.287608]\n",
      "epoch:28 step:26791 [D loss: 0.244221, acc.: 53.91%] [G loss: 0.283915]\n",
      "epoch:28 step:26792 [D loss: 0.245276, acc.: 57.81%] [G loss: 0.303287]\n",
      "epoch:28 step:26793 [D loss: 0.236293, acc.: 54.69%] [G loss: 0.308268]\n",
      "epoch:28 step:26794 [D loss: 0.220105, acc.: 65.62%] [G loss: 0.296017]\n",
      "epoch:28 step:26795 [D loss: 0.237636, acc.: 60.94%] [G loss: 0.283014]\n",
      "epoch:28 step:26796 [D loss: 0.243973, acc.: 54.69%] [G loss: 0.302617]\n",
      "epoch:28 step:26797 [D loss: 0.238272, acc.: 61.72%] [G loss: 0.307595]\n",
      "epoch:28 step:26798 [D loss: 0.238878, acc.: 53.91%] [G loss: 0.263903]\n",
      "epoch:28 step:26799 [D loss: 0.236490, acc.: 57.03%] [G loss: 0.301502]\n",
      "epoch:28 step:26800 [D loss: 0.245026, acc.: 55.47%] [G loss: 0.298812]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:28 step:26801 [D loss: 0.220467, acc.: 67.97%] [G loss: 0.299915]\n",
      "epoch:28 step:26802 [D loss: 0.242851, acc.: 54.69%] [G loss: 0.308698]\n",
      "epoch:28 step:26803 [D loss: 0.234777, acc.: 58.59%] [G loss: 0.297008]\n",
      "epoch:28 step:26804 [D loss: 0.251840, acc.: 53.12%] [G loss: 0.300801]\n",
      "epoch:28 step:26805 [D loss: 0.234438, acc.: 60.94%] [G loss: 0.296972]\n",
      "epoch:28 step:26806 [D loss: 0.249515, acc.: 51.56%] [G loss: 0.289038]\n",
      "epoch:28 step:26807 [D loss: 0.240891, acc.: 60.16%] [G loss: 0.302750]\n",
      "epoch:28 step:26808 [D loss: 0.232770, acc.: 60.94%] [G loss: 0.288114]\n",
      "epoch:28 step:26809 [D loss: 0.241768, acc.: 58.59%] [G loss: 0.295837]\n",
      "epoch:28 step:26810 [D loss: 0.241912, acc.: 59.38%] [G loss: 0.282918]\n",
      "epoch:28 step:26811 [D loss: 0.246574, acc.: 55.47%] [G loss: 0.294464]\n",
      "epoch:28 step:26812 [D loss: 0.245050, acc.: 63.28%] [G loss: 0.294770]\n",
      "epoch:28 step:26813 [D loss: 0.227569, acc.: 66.41%] [G loss: 0.340618]\n",
      "epoch:28 step:26814 [D loss: 0.243263, acc.: 51.56%] [G loss: 0.311806]\n",
      "epoch:28 step:26815 [D loss: 0.236032, acc.: 57.03%] [G loss: 0.307067]\n",
      "epoch:28 step:26816 [D loss: 0.245051, acc.: 55.47%] [G loss: 0.297175]\n",
      "epoch:28 step:26817 [D loss: 0.238312, acc.: 61.72%] [G loss: 0.293976]\n",
      "epoch:28 step:26818 [D loss: 0.225152, acc.: 63.28%] [G loss: 0.294358]\n",
      "epoch:28 step:26819 [D loss: 0.249556, acc.: 56.25%] [G loss: 0.295522]\n",
      "epoch:28 step:26820 [D loss: 0.228593, acc.: 60.16%] [G loss: 0.297129]\n",
      "epoch:28 step:26821 [D loss: 0.253147, acc.: 52.34%] [G loss: 0.278544]\n",
      "epoch:28 step:26822 [D loss: 0.228644, acc.: 60.94%] [G loss: 0.273171]\n",
      "epoch:28 step:26823 [D loss: 0.227573, acc.: 61.72%] [G loss: 0.301455]\n",
      "epoch:28 step:26824 [D loss: 0.250180, acc.: 56.25%] [G loss: 0.280760]\n",
      "epoch:28 step:26825 [D loss: 0.257296, acc.: 53.12%] [G loss: 0.287006]\n",
      "epoch:28 step:26826 [D loss: 0.227387, acc.: 66.41%] [G loss: 0.307518]\n",
      "epoch:28 step:26827 [D loss: 0.252892, acc.: 51.56%] [G loss: 0.258420]\n",
      "epoch:28 step:26828 [D loss: 0.244156, acc.: 56.25%] [G loss: 0.279227]\n",
      "epoch:28 step:26829 [D loss: 0.250814, acc.: 48.44%] [G loss: 0.305180]\n",
      "epoch:28 step:26830 [D loss: 0.243322, acc.: 53.12%] [G loss: 0.270398]\n",
      "epoch:28 step:26831 [D loss: 0.234451, acc.: 56.25%] [G loss: 0.282692]\n",
      "epoch:28 step:26832 [D loss: 0.238654, acc.: 60.16%] [G loss: 0.289517]\n",
      "epoch:28 step:26833 [D loss: 0.220686, acc.: 64.84%] [G loss: 0.316343]\n",
      "epoch:28 step:26834 [D loss: 0.247449, acc.: 50.78%] [G loss: 0.280828]\n",
      "epoch:28 step:26835 [D loss: 0.210734, acc.: 73.44%] [G loss: 0.325664]\n",
      "epoch:28 step:26836 [D loss: 0.226998, acc.: 64.84%] [G loss: 0.290729]\n",
      "epoch:28 step:26837 [D loss: 0.228275, acc.: 59.38%] [G loss: 0.290241]\n",
      "epoch:28 step:26838 [D loss: 0.208751, acc.: 69.53%] [G loss: 0.318653]\n",
      "epoch:28 step:26839 [D loss: 0.264695, acc.: 46.09%] [G loss: 0.315579]\n",
      "epoch:28 step:26840 [D loss: 0.235963, acc.: 58.59%] [G loss: 0.308838]\n",
      "epoch:28 step:26841 [D loss: 0.240366, acc.: 57.03%] [G loss: 0.293945]\n",
      "epoch:28 step:26842 [D loss: 0.239335, acc.: 57.03%] [G loss: 0.327929]\n",
      "epoch:28 step:26843 [D loss: 0.228312, acc.: 66.41%] [G loss: 0.289269]\n",
      "epoch:28 step:26844 [D loss: 0.237650, acc.: 61.72%] [G loss: 0.300013]\n",
      "epoch:28 step:26845 [D loss: 0.241104, acc.: 53.12%] [G loss: 0.294772]\n",
      "epoch:28 step:26846 [D loss: 0.232706, acc.: 63.28%] [G loss: 0.303652]\n",
      "epoch:28 step:26847 [D loss: 0.253865, acc.: 57.03%] [G loss: 0.334457]\n",
      "epoch:28 step:26848 [D loss: 0.249737, acc.: 51.56%] [G loss: 0.312326]\n",
      "epoch:28 step:26849 [D loss: 0.222572, acc.: 64.84%] [G loss: 0.286021]\n",
      "epoch:28 step:26850 [D loss: 0.228414, acc.: 59.38%] [G loss: 0.314558]\n",
      "epoch:28 step:26851 [D loss: 0.228488, acc.: 64.84%] [G loss: 0.296584]\n",
      "epoch:28 step:26852 [D loss: 0.246118, acc.: 53.91%] [G loss: 0.280781]\n",
      "epoch:28 step:26853 [D loss: 0.231313, acc.: 56.25%] [G loss: 0.312740]\n",
      "epoch:28 step:26854 [D loss: 0.230526, acc.: 64.84%] [G loss: 0.311717]\n",
      "epoch:28 step:26855 [D loss: 0.241719, acc.: 59.38%] [G loss: 0.305860]\n",
      "epoch:28 step:26856 [D loss: 0.240307, acc.: 60.94%] [G loss: 0.285921]\n",
      "epoch:28 step:26857 [D loss: 0.246727, acc.: 54.69%] [G loss: 0.307403]\n",
      "epoch:28 step:26858 [D loss: 0.214107, acc.: 67.19%] [G loss: 0.300295]\n",
      "epoch:28 step:26859 [D loss: 0.234231, acc.: 61.72%] [G loss: 0.301506]\n",
      "epoch:28 step:26860 [D loss: 0.235757, acc.: 57.03%] [G loss: 0.291440]\n",
      "epoch:28 step:26861 [D loss: 0.241580, acc.: 56.25%] [G loss: 0.271594]\n",
      "epoch:28 step:26862 [D loss: 0.218975, acc.: 64.06%] [G loss: 0.319636]\n",
      "epoch:28 step:26863 [D loss: 0.250971, acc.: 53.91%] [G loss: 0.321939]\n",
      "epoch:28 step:26864 [D loss: 0.243200, acc.: 54.69%] [G loss: 0.307203]\n",
      "epoch:28 step:26865 [D loss: 0.234101, acc.: 60.94%] [G loss: 0.280288]\n",
      "epoch:28 step:26866 [D loss: 0.244217, acc.: 55.47%] [G loss: 0.286438]\n",
      "epoch:28 step:26867 [D loss: 0.237095, acc.: 60.16%] [G loss: 0.318469]\n",
      "epoch:28 step:26868 [D loss: 0.245335, acc.: 52.34%] [G loss: 0.321460]\n",
      "epoch:28 step:26869 [D loss: 0.243774, acc.: 60.16%] [G loss: 0.291646]\n",
      "epoch:28 step:26870 [D loss: 0.228519, acc.: 59.38%] [G loss: 0.303689]\n",
      "epoch:28 step:26871 [D loss: 0.229329, acc.: 63.28%] [G loss: 0.312653]\n",
      "epoch:28 step:26872 [D loss: 0.249757, acc.: 51.56%] [G loss: 0.295080]\n",
      "epoch:28 step:26873 [D loss: 0.221697, acc.: 65.62%] [G loss: 0.307737]\n",
      "epoch:28 step:26874 [D loss: 0.250036, acc.: 58.59%] [G loss: 0.313599]\n",
      "epoch:28 step:26875 [D loss: 0.243225, acc.: 57.81%] [G loss: 0.316743]\n",
      "epoch:28 step:26876 [D loss: 0.244592, acc.: 58.59%] [G loss: 0.302280]\n",
      "epoch:28 step:26877 [D loss: 0.234885, acc.: 55.47%] [G loss: 0.281121]\n",
      "epoch:28 step:26878 [D loss: 0.238022, acc.: 56.25%] [G loss: 0.293461]\n",
      "epoch:28 step:26879 [D loss: 0.237352, acc.: 57.03%] [G loss: 0.345941]\n",
      "epoch:28 step:26880 [D loss: 0.234583, acc.: 61.72%] [G loss: 0.301451]\n",
      "epoch:28 step:26881 [D loss: 0.228681, acc.: 63.28%] [G loss: 0.286785]\n",
      "epoch:28 step:26882 [D loss: 0.247282, acc.: 55.47%] [G loss: 0.319285]\n",
      "epoch:28 step:26883 [D loss: 0.254325, acc.: 53.91%] [G loss: 0.300344]\n",
      "epoch:28 step:26884 [D loss: 0.241551, acc.: 56.25%] [G loss: 0.313110]\n",
      "epoch:28 step:26885 [D loss: 0.252451, acc.: 57.03%] [G loss: 0.296980]\n",
      "epoch:28 step:26886 [D loss: 0.238065, acc.: 60.16%] [G loss: 0.324278]\n",
      "epoch:28 step:26887 [D loss: 0.246737, acc.: 56.25%] [G loss: 0.293827]\n",
      "epoch:28 step:26888 [D loss: 0.244075, acc.: 55.47%] [G loss: 0.288334]\n",
      "epoch:28 step:26889 [D loss: 0.244490, acc.: 58.59%] [G loss: 0.294198]\n",
      "epoch:28 step:26890 [D loss: 0.244063, acc.: 55.47%] [G loss: 0.316237]\n",
      "epoch:28 step:26891 [D loss: 0.242854, acc.: 57.03%] [G loss: 0.313533]\n",
      "epoch:28 step:26892 [D loss: 0.213502, acc.: 68.75%] [G loss: 0.338604]\n",
      "epoch:28 step:26893 [D loss: 0.247061, acc.: 50.00%] [G loss: 0.287781]\n",
      "epoch:28 step:26894 [D loss: 0.262748, acc.: 53.12%] [G loss: 0.313998]\n",
      "epoch:28 step:26895 [D loss: 0.242946, acc.: 54.69%] [G loss: 0.310657]\n",
      "epoch:28 step:26896 [D loss: 0.236169, acc.: 59.38%] [G loss: 0.306870]\n",
      "epoch:28 step:26897 [D loss: 0.226642, acc.: 60.94%] [G loss: 0.305722]\n",
      "epoch:28 step:26898 [D loss: 0.232322, acc.: 61.72%] [G loss: 0.292313]\n",
      "epoch:28 step:26899 [D loss: 0.241851, acc.: 54.69%] [G loss: 0.297569]\n",
      "epoch:28 step:26900 [D loss: 0.250858, acc.: 51.56%] [G loss: 0.287764]\n",
      "epoch:28 step:26901 [D loss: 0.255090, acc.: 51.56%] [G loss: 0.316024]\n",
      "epoch:28 step:26902 [D loss: 0.239422, acc.: 57.03%] [G loss: 0.302179]\n",
      "epoch:28 step:26903 [D loss: 0.239573, acc.: 54.69%] [G loss: 0.302196]\n",
      "epoch:28 step:26904 [D loss: 0.240400, acc.: 59.38%] [G loss: 0.308457]\n",
      "epoch:28 step:26905 [D loss: 0.215726, acc.: 64.84%] [G loss: 0.278278]\n",
      "epoch:28 step:26906 [D loss: 0.223908, acc.: 67.19%] [G loss: 0.305211]\n",
      "epoch:28 step:26907 [D loss: 0.232183, acc.: 59.38%] [G loss: 0.334484]\n",
      "epoch:28 step:26908 [D loss: 0.251354, acc.: 51.56%] [G loss: 0.310950]\n",
      "epoch:28 step:26909 [D loss: 0.266692, acc.: 50.78%] [G loss: 0.305001]\n",
      "epoch:28 step:26910 [D loss: 0.227728, acc.: 57.03%] [G loss: 0.303315]\n",
      "epoch:28 step:26911 [D loss: 0.254283, acc.: 48.44%] [G loss: 0.297073]\n",
      "epoch:28 step:26912 [D loss: 0.239815, acc.: 62.50%] [G loss: 0.293200]\n",
      "epoch:28 step:26913 [D loss: 0.242563, acc.: 53.12%] [G loss: 0.293131]\n",
      "epoch:28 step:26914 [D loss: 0.243821, acc.: 57.03%] [G loss: 0.312540]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:28 step:26915 [D loss: 0.229584, acc.: 60.94%] [G loss: 0.305769]\n",
      "epoch:28 step:26916 [D loss: 0.242867, acc.: 57.03%] [G loss: 0.285564]\n",
      "epoch:28 step:26917 [D loss: 0.226302, acc.: 63.28%] [G loss: 0.299220]\n",
      "epoch:28 step:26918 [D loss: 0.248489, acc.: 58.59%] [G loss: 0.301327]\n",
      "epoch:28 step:26919 [D loss: 0.230775, acc.: 64.84%] [G loss: 0.305270]\n",
      "epoch:28 step:26920 [D loss: 0.225909, acc.: 59.38%] [G loss: 0.276471]\n",
      "epoch:28 step:26921 [D loss: 0.226673, acc.: 64.06%] [G loss: 0.318911]\n",
      "epoch:28 step:26922 [D loss: 0.235518, acc.: 61.72%] [G loss: 0.303519]\n",
      "epoch:28 step:26923 [D loss: 0.233376, acc.: 58.59%] [G loss: 0.297626]\n",
      "epoch:28 step:26924 [D loss: 0.243431, acc.: 53.91%] [G loss: 0.299149]\n",
      "epoch:28 step:26925 [D loss: 0.233569, acc.: 57.81%] [G loss: 0.320066]\n",
      "epoch:28 step:26926 [D loss: 0.248127, acc.: 53.91%] [G loss: 0.277751]\n",
      "epoch:28 step:26927 [D loss: 0.244492, acc.: 56.25%] [G loss: 0.284880]\n",
      "epoch:28 step:26928 [D loss: 0.251891, acc.: 48.44%] [G loss: 0.309546]\n",
      "epoch:28 step:26929 [D loss: 0.239442, acc.: 60.16%] [G loss: 0.291918]\n",
      "epoch:28 step:26930 [D loss: 0.243071, acc.: 57.81%] [G loss: 0.311493]\n",
      "epoch:28 step:26931 [D loss: 0.243932, acc.: 54.69%] [G loss: 0.310133]\n",
      "epoch:28 step:26932 [D loss: 0.236679, acc.: 60.94%] [G loss: 0.298665]\n",
      "epoch:28 step:26933 [D loss: 0.239111, acc.: 60.16%] [G loss: 0.281808]\n",
      "epoch:28 step:26934 [D loss: 0.241641, acc.: 53.12%] [G loss: 0.302031]\n",
      "epoch:28 step:26935 [D loss: 0.228433, acc.: 62.50%] [G loss: 0.284570]\n",
      "epoch:28 step:26936 [D loss: 0.244878, acc.: 53.12%] [G loss: 0.328150]\n",
      "epoch:28 step:26937 [D loss: 0.237489, acc.: 57.81%] [G loss: 0.291184]\n",
      "epoch:28 step:26938 [D loss: 0.234428, acc.: 64.06%] [G loss: 0.305591]\n",
      "epoch:28 step:26939 [D loss: 0.246584, acc.: 57.03%] [G loss: 0.317692]\n",
      "epoch:28 step:26940 [D loss: 0.250571, acc.: 48.44%] [G loss: 0.295393]\n",
      "epoch:28 step:26941 [D loss: 0.218435, acc.: 60.94%] [G loss: 0.329041]\n",
      "epoch:28 step:26942 [D loss: 0.231348, acc.: 64.06%] [G loss: 0.294943]\n",
      "epoch:28 step:26943 [D loss: 0.228720, acc.: 62.50%] [G loss: 0.312824]\n",
      "epoch:28 step:26944 [D loss: 0.253880, acc.: 57.81%] [G loss: 0.300382]\n",
      "epoch:28 step:26945 [D loss: 0.238150, acc.: 61.72%] [G loss: 0.324040]\n",
      "epoch:28 step:26946 [D loss: 0.233007, acc.: 62.50%] [G loss: 0.310057]\n",
      "epoch:28 step:26947 [D loss: 0.247968, acc.: 57.81%] [G loss: 0.319927]\n",
      "epoch:28 step:26948 [D loss: 0.250025, acc.: 57.03%] [G loss: 0.269643]\n",
      "epoch:28 step:26949 [D loss: 0.243396, acc.: 54.69%] [G loss: 0.287433]\n",
      "epoch:28 step:26950 [D loss: 0.250700, acc.: 48.44%] [G loss: 0.315592]\n",
      "epoch:28 step:26951 [D loss: 0.253246, acc.: 57.03%] [G loss: 0.303995]\n",
      "epoch:28 step:26952 [D loss: 0.237216, acc.: 57.81%] [G loss: 0.308243]\n",
      "epoch:28 step:26953 [D loss: 0.244253, acc.: 60.94%] [G loss: 0.309485]\n",
      "epoch:28 step:26954 [D loss: 0.227325, acc.: 60.16%] [G loss: 0.320359]\n",
      "epoch:28 step:26955 [D loss: 0.245860, acc.: 62.50%] [G loss: 0.313635]\n",
      "epoch:28 step:26956 [D loss: 0.238046, acc.: 57.81%] [G loss: 0.289120]\n",
      "epoch:28 step:26957 [D loss: 0.241582, acc.: 63.28%] [G loss: 0.299377]\n",
      "epoch:28 step:26958 [D loss: 0.248692, acc.: 60.16%] [G loss: 0.303599]\n",
      "epoch:28 step:26959 [D loss: 0.244584, acc.: 53.91%] [G loss: 0.316141]\n",
      "epoch:28 step:26960 [D loss: 0.247726, acc.: 56.25%] [G loss: 0.329257]\n",
      "epoch:28 step:26961 [D loss: 0.225253, acc.: 67.19%] [G loss: 0.306600]\n",
      "epoch:28 step:26962 [D loss: 0.253673, acc.: 51.56%] [G loss: 0.292005]\n",
      "epoch:28 step:26963 [D loss: 0.234551, acc.: 60.16%] [G loss: 0.319647]\n",
      "epoch:28 step:26964 [D loss: 0.245840, acc.: 49.22%] [G loss: 0.319810]\n",
      "epoch:28 step:26965 [D loss: 0.250732, acc.: 53.12%] [G loss: 0.299855]\n",
      "epoch:28 step:26966 [D loss: 0.230910, acc.: 61.72%] [G loss: 0.281385]\n",
      "epoch:28 step:26967 [D loss: 0.232050, acc.: 62.50%] [G loss: 0.307868]\n",
      "epoch:28 step:26968 [D loss: 0.246837, acc.: 55.47%] [G loss: 0.318782]\n",
      "epoch:28 step:26969 [D loss: 0.236999, acc.: 57.81%] [G loss: 0.308927]\n",
      "epoch:28 step:26970 [D loss: 0.239391, acc.: 60.94%] [G loss: 0.287630]\n",
      "epoch:28 step:26971 [D loss: 0.239626, acc.: 57.03%] [G loss: 0.291082]\n",
      "epoch:28 step:26972 [D loss: 0.231213, acc.: 59.38%] [G loss: 0.320700]\n",
      "epoch:28 step:26973 [D loss: 0.244215, acc.: 57.03%] [G loss: 0.292772]\n",
      "epoch:28 step:26974 [D loss: 0.244686, acc.: 56.25%] [G loss: 0.316342]\n",
      "epoch:28 step:26975 [D loss: 0.238351, acc.: 57.03%] [G loss: 0.310806]\n",
      "epoch:28 step:26976 [D loss: 0.233661, acc.: 60.94%] [G loss: 0.260442]\n",
      "epoch:28 step:26977 [D loss: 0.227709, acc.: 64.84%] [G loss: 0.282207]\n",
      "epoch:28 step:26978 [D loss: 0.239591, acc.: 57.03%] [G loss: 0.310374]\n",
      "epoch:28 step:26979 [D loss: 0.266610, acc.: 50.00%] [G loss: 0.271838]\n",
      "epoch:28 step:26980 [D loss: 0.237249, acc.: 59.38%] [G loss: 0.315064]\n",
      "epoch:28 step:26981 [D loss: 0.236912, acc.: 59.38%] [G loss: 0.317718]\n",
      "epoch:28 step:26982 [D loss: 0.250218, acc.: 59.38%] [G loss: 0.304929]\n",
      "epoch:28 step:26983 [D loss: 0.254050, acc.: 53.12%] [G loss: 0.268714]\n",
      "epoch:28 step:26984 [D loss: 0.218928, acc.: 64.84%] [G loss: 0.310713]\n",
      "epoch:28 step:26985 [D loss: 0.245119, acc.: 51.56%] [G loss: 0.312608]\n",
      "epoch:28 step:26986 [D loss: 0.220998, acc.: 68.75%] [G loss: 0.298105]\n",
      "epoch:28 step:26987 [D loss: 0.231420, acc.: 60.16%] [G loss: 0.335602]\n",
      "epoch:28 step:26988 [D loss: 0.246589, acc.: 52.34%] [G loss: 0.300769]\n",
      "epoch:28 step:26989 [D loss: 0.254067, acc.: 50.78%] [G loss: 0.314106]\n",
      "epoch:28 step:26990 [D loss: 0.232761, acc.: 63.28%] [G loss: 0.298162]\n",
      "epoch:28 step:26991 [D loss: 0.228101, acc.: 65.62%] [G loss: 0.302305]\n",
      "epoch:28 step:26992 [D loss: 0.256790, acc.: 47.66%] [G loss: 0.305563]\n",
      "epoch:28 step:26993 [D loss: 0.243533, acc.: 57.03%] [G loss: 0.299639]\n",
      "epoch:28 step:26994 [D loss: 0.235364, acc.: 57.81%] [G loss: 0.309156]\n",
      "epoch:28 step:26995 [D loss: 0.235159, acc.: 60.94%] [G loss: 0.308906]\n",
      "epoch:28 step:26996 [D loss: 0.246354, acc.: 55.47%] [G loss: 0.294961]\n",
      "epoch:28 step:26997 [D loss: 0.250498, acc.: 53.12%] [G loss: 0.300880]\n",
      "epoch:28 step:26998 [D loss: 0.240538, acc.: 55.47%] [G loss: 0.291740]\n",
      "epoch:28 step:26999 [D loss: 0.246495, acc.: 54.69%] [G loss: 0.284184]\n",
      "epoch:28 step:27000 [D loss: 0.232503, acc.: 56.25%] [G loss: 0.324401]\n",
      "epoch:28 step:27001 [D loss: 0.242243, acc.: 57.03%] [G loss: 0.299120]\n",
      "epoch:28 step:27002 [D loss: 0.226068, acc.: 59.38%] [G loss: 0.301389]\n",
      "epoch:28 step:27003 [D loss: 0.246132, acc.: 55.47%] [G loss: 0.314875]\n",
      "epoch:28 step:27004 [D loss: 0.228714, acc.: 65.62%] [G loss: 0.303563]\n",
      "epoch:28 step:27005 [D loss: 0.234156, acc.: 57.81%] [G loss: 0.311462]\n",
      "epoch:28 step:27006 [D loss: 0.239746, acc.: 58.59%] [G loss: 0.326149]\n",
      "epoch:28 step:27007 [D loss: 0.220523, acc.: 63.28%] [G loss: 0.355079]\n",
      "epoch:28 step:27008 [D loss: 0.246116, acc.: 58.59%] [G loss: 0.278412]\n",
      "epoch:28 step:27009 [D loss: 0.244487, acc.: 55.47%] [G loss: 0.331463]\n",
      "epoch:28 step:27010 [D loss: 0.234323, acc.: 64.06%] [G loss: 0.278653]\n",
      "epoch:28 step:27011 [D loss: 0.236988, acc.: 60.16%] [G loss: 0.303936]\n",
      "epoch:28 step:27012 [D loss: 0.238562, acc.: 60.94%] [G loss: 0.293116]\n",
      "epoch:28 step:27013 [D loss: 0.235778, acc.: 60.16%] [G loss: 0.302339]\n",
      "epoch:28 step:27014 [D loss: 0.249350, acc.: 53.91%] [G loss: 0.291179]\n",
      "epoch:28 step:27015 [D loss: 0.232782, acc.: 57.81%] [G loss: 0.282302]\n",
      "epoch:28 step:27016 [D loss: 0.250116, acc.: 52.34%] [G loss: 0.281708]\n",
      "epoch:28 step:27017 [D loss: 0.258950, acc.: 50.78%] [G loss: 0.293242]\n",
      "epoch:28 step:27018 [D loss: 0.242789, acc.: 51.56%] [G loss: 0.282812]\n",
      "epoch:28 step:27019 [D loss: 0.257965, acc.: 46.88%] [G loss: 0.318562]\n",
      "epoch:28 step:27020 [D loss: 0.241613, acc.: 60.94%] [G loss: 0.310567]\n",
      "epoch:28 step:27021 [D loss: 0.234608, acc.: 57.03%] [G loss: 0.311466]\n",
      "epoch:28 step:27022 [D loss: 0.252795, acc.: 54.69%] [G loss: 0.316625]\n",
      "epoch:28 step:27023 [D loss: 0.236543, acc.: 61.72%] [G loss: 0.292452]\n",
      "epoch:28 step:27024 [D loss: 0.237868, acc.: 57.03%] [G loss: 0.310139]\n",
      "epoch:28 step:27025 [D loss: 0.246135, acc.: 59.38%] [G loss: 0.299334]\n",
      "epoch:28 step:27026 [D loss: 0.247467, acc.: 55.47%] [G loss: 0.271830]\n",
      "epoch:28 step:27027 [D loss: 0.239587, acc.: 60.16%] [G loss: 0.268998]\n",
      "epoch:28 step:27028 [D loss: 0.250769, acc.: 52.34%] [G loss: 0.301514]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:28 step:27029 [D loss: 0.244224, acc.: 57.81%] [G loss: 0.292082]\n",
      "epoch:28 step:27030 [D loss: 0.254522, acc.: 51.56%] [G loss: 0.300085]\n",
      "epoch:28 step:27031 [D loss: 0.243697, acc.: 56.25%] [G loss: 0.286045]\n",
      "epoch:28 step:27032 [D loss: 0.237028, acc.: 57.03%] [G loss: 0.309818]\n",
      "epoch:28 step:27033 [D loss: 0.245680, acc.: 52.34%] [G loss: 0.284257]\n",
      "epoch:28 step:27034 [D loss: 0.255316, acc.: 48.44%] [G loss: 0.300484]\n",
      "epoch:28 step:27035 [D loss: 0.239766, acc.: 57.03%] [G loss: 0.291394]\n",
      "epoch:28 step:27036 [D loss: 0.239706, acc.: 54.69%] [G loss: 0.290832]\n",
      "epoch:28 step:27037 [D loss: 0.236230, acc.: 58.59%] [G loss: 0.275609]\n",
      "epoch:28 step:27038 [D loss: 0.260779, acc.: 53.91%] [G loss: 0.289850]\n",
      "epoch:28 step:27039 [D loss: 0.229018, acc.: 64.84%] [G loss: 0.294996]\n",
      "epoch:28 step:27040 [D loss: 0.240938, acc.: 57.03%] [G loss: 0.282698]\n",
      "epoch:28 step:27041 [D loss: 0.253115, acc.: 53.12%] [G loss: 0.297001]\n",
      "epoch:28 step:27042 [D loss: 0.234634, acc.: 60.94%] [G loss: 0.297354]\n",
      "epoch:28 step:27043 [D loss: 0.235182, acc.: 56.25%] [G loss: 0.291773]\n",
      "epoch:28 step:27044 [D loss: 0.228019, acc.: 59.38%] [G loss: 0.309225]\n",
      "epoch:28 step:27045 [D loss: 0.238206, acc.: 62.50%] [G loss: 0.319478]\n",
      "epoch:28 step:27046 [D loss: 0.241996, acc.: 55.47%] [G loss: 0.301901]\n",
      "epoch:28 step:27047 [D loss: 0.238626, acc.: 55.47%] [G loss: 0.310140]\n",
      "epoch:28 step:27048 [D loss: 0.243479, acc.: 60.16%] [G loss: 0.310492]\n",
      "epoch:28 step:27049 [D loss: 0.247189, acc.: 53.12%] [G loss: 0.302511]\n",
      "epoch:28 step:27050 [D loss: 0.238397, acc.: 55.47%] [G loss: 0.283489]\n",
      "epoch:28 step:27051 [D loss: 0.255450, acc.: 51.56%] [G loss: 0.277594]\n",
      "epoch:28 step:27052 [D loss: 0.237984, acc.: 58.59%] [G loss: 0.301748]\n",
      "epoch:28 step:27053 [D loss: 0.217112, acc.: 67.97%] [G loss: 0.318498]\n",
      "epoch:28 step:27054 [D loss: 0.233388, acc.: 64.84%] [G loss: 0.310696]\n",
      "epoch:28 step:27055 [D loss: 0.247555, acc.: 57.03%] [G loss: 0.305485]\n",
      "epoch:28 step:27056 [D loss: 0.251705, acc.: 53.91%] [G loss: 0.290895]\n",
      "epoch:28 step:27057 [D loss: 0.245202, acc.: 55.47%] [G loss: 0.282992]\n",
      "epoch:28 step:27058 [D loss: 0.235174, acc.: 59.38%] [G loss: 0.281372]\n",
      "epoch:28 step:27059 [D loss: 0.258192, acc.: 54.69%] [G loss: 0.290461]\n",
      "epoch:28 step:27060 [D loss: 0.250953, acc.: 53.91%] [G loss: 0.310035]\n",
      "epoch:28 step:27061 [D loss: 0.228714, acc.: 60.16%] [G loss: 0.310597]\n",
      "epoch:28 step:27062 [D loss: 0.234029, acc.: 59.38%] [G loss: 0.292266]\n",
      "epoch:28 step:27063 [D loss: 0.240866, acc.: 55.47%] [G loss: 0.281958]\n",
      "epoch:28 step:27064 [D loss: 0.234223, acc.: 58.59%] [G loss: 0.312348]\n",
      "epoch:28 step:27065 [D loss: 0.228739, acc.: 58.59%] [G loss: 0.284111]\n",
      "epoch:28 step:27066 [D loss: 0.249746, acc.: 54.69%] [G loss: 0.292288]\n",
      "epoch:28 step:27067 [D loss: 0.246340, acc.: 57.03%] [G loss: 0.309052]\n",
      "epoch:28 step:27068 [D loss: 0.222559, acc.: 65.62%] [G loss: 0.322331]\n",
      "epoch:28 step:27069 [D loss: 0.250012, acc.: 58.59%] [G loss: 0.284263]\n",
      "epoch:28 step:27070 [D loss: 0.246781, acc.: 58.59%] [G loss: 0.310945]\n",
      "epoch:28 step:27071 [D loss: 0.260942, acc.: 45.31%] [G loss: 0.288723]\n",
      "epoch:28 step:27072 [D loss: 0.248969, acc.: 50.78%] [G loss: 0.284555]\n",
      "epoch:28 step:27073 [D loss: 0.241482, acc.: 57.81%] [G loss: 0.315662]\n",
      "epoch:28 step:27074 [D loss: 0.250247, acc.: 56.25%] [G loss: 0.280748]\n",
      "epoch:28 step:27075 [D loss: 0.233069, acc.: 61.72%] [G loss: 0.280591]\n",
      "epoch:28 step:27076 [D loss: 0.241593, acc.: 59.38%] [G loss: 0.302635]\n",
      "epoch:28 step:27077 [D loss: 0.217672, acc.: 64.84%] [G loss: 0.305498]\n",
      "epoch:28 step:27078 [D loss: 0.256453, acc.: 53.12%] [G loss: 0.294360]\n",
      "epoch:28 step:27079 [D loss: 0.254940, acc.: 53.12%] [G loss: 0.301797]\n",
      "epoch:28 step:27080 [D loss: 0.232465, acc.: 67.19%] [G loss: 0.343156]\n",
      "epoch:28 step:27081 [D loss: 0.246158, acc.: 56.25%] [G loss: 0.294258]\n",
      "epoch:28 step:27082 [D loss: 0.260161, acc.: 56.25%] [G loss: 0.305860]\n",
      "epoch:28 step:27083 [D loss: 0.248175, acc.: 55.47%] [G loss: 0.281975]\n",
      "epoch:28 step:27084 [D loss: 0.237693, acc.: 55.47%] [G loss: 0.301372]\n",
      "epoch:28 step:27085 [D loss: 0.243935, acc.: 53.91%] [G loss: 0.282562]\n",
      "epoch:28 step:27086 [D loss: 0.236099, acc.: 62.50%] [G loss: 0.310589]\n",
      "epoch:28 step:27087 [D loss: 0.239078, acc.: 55.47%] [G loss: 0.293505]\n",
      "epoch:28 step:27088 [D loss: 0.224375, acc.: 60.16%] [G loss: 0.300932]\n",
      "epoch:28 step:27089 [D loss: 0.234455, acc.: 63.28%] [G loss: 0.301603]\n",
      "epoch:28 step:27090 [D loss: 0.226970, acc.: 56.25%] [G loss: 0.305281]\n",
      "epoch:28 step:27091 [D loss: 0.239379, acc.: 56.25%] [G loss: 0.286590]\n",
      "epoch:28 step:27092 [D loss: 0.235594, acc.: 58.59%] [G loss: 0.304654]\n",
      "epoch:28 step:27093 [D loss: 0.235785, acc.: 63.28%] [G loss: 0.302830]\n",
      "epoch:28 step:27094 [D loss: 0.254935, acc.: 55.47%] [G loss: 0.300572]\n",
      "epoch:28 step:27095 [D loss: 0.234291, acc.: 64.06%] [G loss: 0.297019]\n",
      "epoch:28 step:27096 [D loss: 0.248035, acc.: 56.25%] [G loss: 0.305794]\n",
      "epoch:28 step:27097 [D loss: 0.246517, acc.: 53.12%] [G loss: 0.309569]\n",
      "epoch:28 step:27098 [D loss: 0.253372, acc.: 53.12%] [G loss: 0.287797]\n",
      "epoch:28 step:27099 [D loss: 0.238312, acc.: 64.06%] [G loss: 0.311108]\n",
      "epoch:28 step:27100 [D loss: 0.240481, acc.: 59.38%] [G loss: 0.309998]\n",
      "epoch:28 step:27101 [D loss: 0.232792, acc.: 57.03%] [G loss: 0.303533]\n",
      "epoch:28 step:27102 [D loss: 0.240408, acc.: 57.81%] [G loss: 0.295958]\n",
      "epoch:28 step:27103 [D loss: 0.236160, acc.: 63.28%] [G loss: 0.286329]\n",
      "epoch:28 step:27104 [D loss: 0.236014, acc.: 63.28%] [G loss: 0.291478]\n",
      "epoch:28 step:27105 [D loss: 0.253941, acc.: 54.69%] [G loss: 0.286989]\n",
      "epoch:28 step:27106 [D loss: 0.237829, acc.: 60.16%] [G loss: 0.307396]\n",
      "epoch:28 step:27107 [D loss: 0.231584, acc.: 56.25%] [G loss: 0.302124]\n",
      "epoch:28 step:27108 [D loss: 0.235071, acc.: 55.47%] [G loss: 0.310180]\n",
      "epoch:28 step:27109 [D loss: 0.219617, acc.: 67.19%] [G loss: 0.327423]\n",
      "epoch:28 step:27110 [D loss: 0.227808, acc.: 71.09%] [G loss: 0.302183]\n",
      "epoch:28 step:27111 [D loss: 0.259516, acc.: 50.00%] [G loss: 0.282664]\n",
      "epoch:28 step:27112 [D loss: 0.250586, acc.: 56.25%] [G loss: 0.325227]\n",
      "epoch:28 step:27113 [D loss: 0.251033, acc.: 51.56%] [G loss: 0.291545]\n",
      "epoch:28 step:27114 [D loss: 0.239781, acc.: 58.59%] [G loss: 0.304491]\n",
      "epoch:28 step:27115 [D loss: 0.246050, acc.: 53.12%] [G loss: 0.321155]\n",
      "epoch:28 step:27116 [D loss: 0.254389, acc.: 47.66%] [G loss: 0.311422]\n",
      "epoch:28 step:27117 [D loss: 0.233340, acc.: 62.50%] [G loss: 0.336443]\n",
      "epoch:28 step:27118 [D loss: 0.220040, acc.: 64.84%] [G loss: 0.295984]\n",
      "epoch:28 step:27119 [D loss: 0.240364, acc.: 58.59%] [G loss: 0.298796]\n",
      "epoch:28 step:27120 [D loss: 0.229693, acc.: 57.03%] [G loss: 0.307532]\n",
      "epoch:28 step:27121 [D loss: 0.228972, acc.: 62.50%] [G loss: 0.322968]\n",
      "epoch:28 step:27122 [D loss: 0.227789, acc.: 63.28%] [G loss: 0.300026]\n",
      "epoch:28 step:27123 [D loss: 0.243370, acc.: 54.69%] [G loss: 0.300034]\n",
      "epoch:28 step:27124 [D loss: 0.227905, acc.: 64.06%] [G loss: 0.289421]\n",
      "epoch:28 step:27125 [D loss: 0.235597, acc.: 58.59%] [G loss: 0.290376]\n",
      "epoch:28 step:27126 [D loss: 0.228432, acc.: 61.72%] [G loss: 0.291980]\n",
      "epoch:28 step:27127 [D loss: 0.250639, acc.: 57.81%] [G loss: 0.290349]\n",
      "epoch:28 step:27128 [D loss: 0.253765, acc.: 55.47%] [G loss: 0.307835]\n",
      "epoch:28 step:27129 [D loss: 0.219712, acc.: 67.97%] [G loss: 0.302512]\n",
      "epoch:28 step:27130 [D loss: 0.231085, acc.: 65.62%] [G loss: 0.324570]\n",
      "epoch:28 step:27131 [D loss: 0.206165, acc.: 75.00%] [G loss: 0.327740]\n",
      "epoch:28 step:27132 [D loss: 0.240824, acc.: 54.69%] [G loss: 0.289589]\n",
      "epoch:28 step:27133 [D loss: 0.236207, acc.: 60.94%] [G loss: 0.299713]\n",
      "epoch:28 step:27134 [D loss: 0.220207, acc.: 64.06%] [G loss: 0.303966]\n",
      "epoch:28 step:27135 [D loss: 0.241479, acc.: 58.59%] [G loss: 0.288400]\n",
      "epoch:28 step:27136 [D loss: 0.232977, acc.: 58.59%] [G loss: 0.303841]\n",
      "epoch:28 step:27137 [D loss: 0.246561, acc.: 50.78%] [G loss: 0.283885]\n",
      "epoch:28 step:27138 [D loss: 0.237067, acc.: 58.59%] [G loss: 0.308309]\n",
      "epoch:28 step:27139 [D loss: 0.240993, acc.: 60.16%] [G loss: 0.301683]\n",
      "epoch:28 step:27140 [D loss: 0.232556, acc.: 63.28%] [G loss: 0.303740]\n",
      "epoch:28 step:27141 [D loss: 0.234570, acc.: 55.47%] [G loss: 0.317418]\n",
      "epoch:28 step:27142 [D loss: 0.237227, acc.: 55.47%] [G loss: 0.300907]\n",
      "epoch:28 step:27143 [D loss: 0.250396, acc.: 53.91%] [G loss: 0.303435]\n",
      "epoch:28 step:27144 [D loss: 0.223966, acc.: 57.81%] [G loss: 0.307499]\n",
      "epoch:28 step:27145 [D loss: 0.244296, acc.: 52.34%] [G loss: 0.260037]\n",
      "epoch:28 step:27146 [D loss: 0.239590, acc.: 58.59%] [G loss: 0.267073]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:28 step:27147 [D loss: 0.226810, acc.: 63.28%] [G loss: 0.314033]\n",
      "epoch:28 step:27148 [D loss: 0.265849, acc.: 48.44%] [G loss: 0.275371]\n",
      "epoch:28 step:27149 [D loss: 0.208457, acc.: 71.88%] [G loss: 0.288735]\n",
      "epoch:28 step:27150 [D loss: 0.223667, acc.: 64.06%] [G loss: 0.313408]\n",
      "epoch:28 step:27151 [D loss: 0.230614, acc.: 60.94%] [G loss: 0.340984]\n",
      "epoch:28 step:27152 [D loss: 0.227541, acc.: 67.97%] [G loss: 0.307639]\n",
      "epoch:28 step:27153 [D loss: 0.238609, acc.: 57.03%] [G loss: 0.298436]\n",
      "epoch:28 step:27154 [D loss: 0.243194, acc.: 58.59%] [G loss: 0.295946]\n",
      "epoch:28 step:27155 [D loss: 0.241052, acc.: 53.91%] [G loss: 0.310975]\n",
      "epoch:28 step:27156 [D loss: 0.228942, acc.: 60.16%] [G loss: 0.308113]\n",
      "epoch:28 step:27157 [D loss: 0.238692, acc.: 57.81%] [G loss: 0.328263]\n",
      "epoch:28 step:27158 [D loss: 0.235020, acc.: 60.94%] [G loss: 0.297096]\n",
      "epoch:28 step:27159 [D loss: 0.268326, acc.: 46.88%] [G loss: 0.301162]\n",
      "epoch:28 step:27160 [D loss: 0.241724, acc.: 57.81%] [G loss: 0.300933]\n",
      "epoch:28 step:27161 [D loss: 0.253771, acc.: 49.22%] [G loss: 0.311700]\n",
      "epoch:28 step:27162 [D loss: 0.243098, acc.: 54.69%] [G loss: 0.328922]\n",
      "epoch:28 step:27163 [D loss: 0.226215, acc.: 57.81%] [G loss: 0.319049]\n",
      "epoch:28 step:27164 [D loss: 0.238567, acc.: 64.06%] [G loss: 0.327816]\n",
      "epoch:28 step:27165 [D loss: 0.238963, acc.: 60.94%] [G loss: 0.312055]\n",
      "epoch:28 step:27166 [D loss: 0.233533, acc.: 60.94%] [G loss: 0.319087]\n",
      "epoch:28 step:27167 [D loss: 0.248459, acc.: 56.25%] [G loss: 0.312669]\n",
      "epoch:28 step:27168 [D loss: 0.251912, acc.: 55.47%] [G loss: 0.301818]\n",
      "epoch:28 step:27169 [D loss: 0.240189, acc.: 61.72%] [G loss: 0.329710]\n",
      "epoch:28 step:27170 [D loss: 0.244271, acc.: 55.47%] [G loss: 0.273844]\n",
      "epoch:28 step:27171 [D loss: 0.228665, acc.: 60.16%] [G loss: 0.291488]\n",
      "epoch:28 step:27172 [D loss: 0.239671, acc.: 56.25%] [G loss: 0.293275]\n",
      "epoch:28 step:27173 [D loss: 0.255086, acc.: 52.34%] [G loss: 0.314297]\n",
      "epoch:29 step:27174 [D loss: 0.247269, acc.: 60.16%] [G loss: 0.302696]\n",
      "epoch:29 step:27175 [D loss: 0.240673, acc.: 59.38%] [G loss: 0.273839]\n",
      "epoch:29 step:27176 [D loss: 0.257137, acc.: 47.66%] [G loss: 0.289191]\n",
      "epoch:29 step:27177 [D loss: 0.232612, acc.: 58.59%] [G loss: 0.307292]\n",
      "epoch:29 step:27178 [D loss: 0.226556, acc.: 65.62%] [G loss: 0.304195]\n",
      "epoch:29 step:27179 [D loss: 0.249012, acc.: 56.25%] [G loss: 0.277604]\n",
      "epoch:29 step:27180 [D loss: 0.244808, acc.: 60.16%] [G loss: 0.307348]\n",
      "epoch:29 step:27181 [D loss: 0.242678, acc.: 60.16%] [G loss: 0.309881]\n",
      "epoch:29 step:27182 [D loss: 0.241423, acc.: 55.47%] [G loss: 0.299915]\n",
      "epoch:29 step:27183 [D loss: 0.250934, acc.: 53.91%] [G loss: 0.290157]\n",
      "epoch:29 step:27184 [D loss: 0.201489, acc.: 74.22%] [G loss: 0.317301]\n",
      "epoch:29 step:27185 [D loss: 0.239111, acc.: 57.81%] [G loss: 0.300693]\n",
      "epoch:29 step:27186 [D loss: 0.256606, acc.: 54.69%] [G loss: 0.295547]\n",
      "epoch:29 step:27187 [D loss: 0.221416, acc.: 67.19%] [G loss: 0.293557]\n",
      "epoch:29 step:27188 [D loss: 0.237324, acc.: 62.50%] [G loss: 0.273081]\n",
      "epoch:29 step:27189 [D loss: 0.243184, acc.: 58.59%] [G loss: 0.298963]\n",
      "epoch:29 step:27190 [D loss: 0.229399, acc.: 58.59%] [G loss: 0.316095]\n",
      "epoch:29 step:27191 [D loss: 0.235651, acc.: 59.38%] [G loss: 0.307865]\n",
      "epoch:29 step:27192 [D loss: 0.230368, acc.: 63.28%] [G loss: 0.296231]\n",
      "epoch:29 step:27193 [D loss: 0.251402, acc.: 57.03%] [G loss: 0.284662]\n",
      "epoch:29 step:27194 [D loss: 0.259974, acc.: 53.91%] [G loss: 0.282231]\n",
      "epoch:29 step:27195 [D loss: 0.219230, acc.: 67.97%] [G loss: 0.315524]\n",
      "epoch:29 step:27196 [D loss: 0.234647, acc.: 57.03%] [G loss: 0.294148]\n",
      "epoch:29 step:27197 [D loss: 0.230417, acc.: 59.38%] [G loss: 0.288127]\n",
      "epoch:29 step:27198 [D loss: 0.231428, acc.: 62.50%] [G loss: 0.282221]\n",
      "epoch:29 step:27199 [D loss: 0.253353, acc.: 53.91%] [G loss: 0.294036]\n",
      "epoch:29 step:27200 [D loss: 0.227977, acc.: 66.41%] [G loss: 0.283182]\n",
      "epoch:29 step:27201 [D loss: 0.232358, acc.: 64.84%] [G loss: 0.303297]\n",
      "epoch:29 step:27202 [D loss: 0.263828, acc.: 46.88%] [G loss: 0.283826]\n",
      "epoch:29 step:27203 [D loss: 0.234063, acc.: 64.06%] [G loss: 0.300730]\n",
      "epoch:29 step:27204 [D loss: 0.256450, acc.: 53.12%] [G loss: 0.302913]\n",
      "epoch:29 step:27205 [D loss: 0.229355, acc.: 57.81%] [G loss: 0.299846]\n",
      "epoch:29 step:27206 [D loss: 0.224967, acc.: 61.72%] [G loss: 0.303271]\n",
      "epoch:29 step:27207 [D loss: 0.240350, acc.: 63.28%] [G loss: 0.277200]\n",
      "epoch:29 step:27208 [D loss: 0.234367, acc.: 53.91%] [G loss: 0.290363]\n",
      "epoch:29 step:27209 [D loss: 0.239295, acc.: 59.38%] [G loss: 0.295291]\n",
      "epoch:29 step:27210 [D loss: 0.232975, acc.: 60.16%] [G loss: 0.328263]\n",
      "epoch:29 step:27211 [D loss: 0.236330, acc.: 57.81%] [G loss: 0.326402]\n",
      "epoch:29 step:27212 [D loss: 0.248574, acc.: 58.59%] [G loss: 0.293749]\n",
      "epoch:29 step:27213 [D loss: 0.252797, acc.: 52.34%] [G loss: 0.314205]\n",
      "epoch:29 step:27214 [D loss: 0.236752, acc.: 60.16%] [G loss: 0.293375]\n",
      "epoch:29 step:27215 [D loss: 0.229026, acc.: 59.38%] [G loss: 0.297692]\n",
      "epoch:29 step:27216 [D loss: 0.237262, acc.: 59.38%] [G loss: 0.291212]\n",
      "epoch:29 step:27217 [D loss: 0.239368, acc.: 53.91%] [G loss: 0.304555]\n",
      "epoch:29 step:27218 [D loss: 0.236957, acc.: 60.16%] [G loss: 0.297780]\n",
      "epoch:29 step:27219 [D loss: 0.258549, acc.: 47.66%] [G loss: 0.288334]\n",
      "epoch:29 step:27220 [D loss: 0.227777, acc.: 60.94%] [G loss: 0.302235]\n",
      "epoch:29 step:27221 [D loss: 0.245341, acc.: 50.78%] [G loss: 0.297557]\n",
      "epoch:29 step:27222 [D loss: 0.221798, acc.: 67.19%] [G loss: 0.334503]\n",
      "epoch:29 step:27223 [D loss: 0.235573, acc.: 62.50%] [G loss: 0.278966]\n",
      "epoch:29 step:27224 [D loss: 0.244263, acc.: 58.59%] [G loss: 0.264710]\n",
      "epoch:29 step:27225 [D loss: 0.242493, acc.: 56.25%] [G loss: 0.281064]\n",
      "epoch:29 step:27226 [D loss: 0.235139, acc.: 60.94%] [G loss: 0.289799]\n",
      "epoch:29 step:27227 [D loss: 0.232272, acc.: 59.38%] [G loss: 0.328288]\n",
      "epoch:29 step:27228 [D loss: 0.252290, acc.: 53.12%] [G loss: 0.305670]\n",
      "epoch:29 step:27229 [D loss: 0.250429, acc.: 54.69%] [G loss: 0.308033]\n",
      "epoch:29 step:27230 [D loss: 0.249404, acc.: 51.56%] [G loss: 0.271427]\n",
      "epoch:29 step:27231 [D loss: 0.222306, acc.: 64.84%] [G loss: 0.290939]\n",
      "epoch:29 step:27232 [D loss: 0.252964, acc.: 48.44%] [G loss: 0.305326]\n",
      "epoch:29 step:27233 [D loss: 0.227188, acc.: 56.25%] [G loss: 0.306908]\n",
      "epoch:29 step:27234 [D loss: 0.245385, acc.: 57.03%] [G loss: 0.294251]\n",
      "epoch:29 step:27235 [D loss: 0.255232, acc.: 53.12%] [G loss: 0.313863]\n",
      "epoch:29 step:27236 [D loss: 0.245906, acc.: 55.47%] [G loss: 0.280414]\n",
      "epoch:29 step:27237 [D loss: 0.247698, acc.: 53.12%] [G loss: 0.297565]\n",
      "epoch:29 step:27238 [D loss: 0.236218, acc.: 57.81%] [G loss: 0.285744]\n",
      "epoch:29 step:27239 [D loss: 0.238815, acc.: 52.34%] [G loss: 0.320986]\n",
      "epoch:29 step:27240 [D loss: 0.222616, acc.: 61.72%] [G loss: 0.299331]\n",
      "epoch:29 step:27241 [D loss: 0.245368, acc.: 57.81%] [G loss: 0.288344]\n",
      "epoch:29 step:27242 [D loss: 0.226779, acc.: 61.72%] [G loss: 0.318871]\n",
      "epoch:29 step:27243 [D loss: 0.252653, acc.: 51.56%] [G loss: 0.288813]\n",
      "epoch:29 step:27244 [D loss: 0.245021, acc.: 58.59%] [G loss: 0.311022]\n",
      "epoch:29 step:27245 [D loss: 0.229734, acc.: 61.72%] [G loss: 0.325241]\n",
      "epoch:29 step:27246 [D loss: 0.247827, acc.: 53.12%] [G loss: 0.312789]\n",
      "epoch:29 step:27247 [D loss: 0.220423, acc.: 60.94%] [G loss: 0.281486]\n",
      "epoch:29 step:27248 [D loss: 0.253736, acc.: 51.56%] [G loss: 0.295258]\n",
      "epoch:29 step:27249 [D loss: 0.232627, acc.: 60.94%] [G loss: 0.317830]\n",
      "epoch:29 step:27250 [D loss: 0.237771, acc.: 59.38%] [G loss: 0.291768]\n",
      "epoch:29 step:27251 [D loss: 0.242159, acc.: 56.25%] [G loss: 0.301260]\n",
      "epoch:29 step:27252 [D loss: 0.251572, acc.: 56.25%] [G loss: 0.306189]\n",
      "epoch:29 step:27253 [D loss: 0.252353, acc.: 52.34%] [G loss: 0.314147]\n",
      "epoch:29 step:27254 [D loss: 0.213242, acc.: 71.09%] [G loss: 0.306922]\n",
      "epoch:29 step:27255 [D loss: 0.234736, acc.: 61.72%] [G loss: 0.325193]\n",
      "epoch:29 step:27256 [D loss: 0.236368, acc.: 57.81%] [G loss: 0.298018]\n",
      "epoch:29 step:27257 [D loss: 0.243945, acc.: 58.59%] [G loss: 0.319627]\n",
      "epoch:29 step:27258 [D loss: 0.235833, acc.: 61.72%] [G loss: 0.319001]\n",
      "epoch:29 step:27259 [D loss: 0.237849, acc.: 60.94%] [G loss: 0.293276]\n",
      "epoch:29 step:27260 [D loss: 0.223551, acc.: 64.84%] [G loss: 0.284383]\n",
      "epoch:29 step:27261 [D loss: 0.239571, acc.: 57.81%] [G loss: 0.296273]\n",
      "epoch:29 step:27262 [D loss: 0.248116, acc.: 59.38%] [G loss: 0.291967]\n",
      "epoch:29 step:27263 [D loss: 0.221412, acc.: 60.94%] [G loss: 0.274459]\n",
      "epoch:29 step:27264 [D loss: 0.242979, acc.: 53.12%] [G loss: 0.294332]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:29 step:27265 [D loss: 0.224980, acc.: 64.06%] [G loss: 0.287783]\n",
      "epoch:29 step:27266 [D loss: 0.241192, acc.: 56.25%] [G loss: 0.284998]\n",
      "epoch:29 step:27267 [D loss: 0.239933, acc.: 57.03%] [G loss: 0.315168]\n",
      "epoch:29 step:27268 [D loss: 0.245498, acc.: 55.47%] [G loss: 0.311476]\n",
      "epoch:29 step:27269 [D loss: 0.239126, acc.: 58.59%] [G loss: 0.287112]\n",
      "epoch:29 step:27270 [D loss: 0.243202, acc.: 55.47%] [G loss: 0.321790]\n",
      "epoch:29 step:27271 [D loss: 0.247637, acc.: 57.81%] [G loss: 0.286856]\n",
      "epoch:29 step:27272 [D loss: 0.241739, acc.: 56.25%] [G loss: 0.302463]\n",
      "epoch:29 step:27273 [D loss: 0.256254, acc.: 52.34%] [G loss: 0.291275]\n",
      "epoch:29 step:27274 [D loss: 0.238109, acc.: 60.94%] [G loss: 0.301427]\n",
      "epoch:29 step:27275 [D loss: 0.243939, acc.: 57.03%] [G loss: 0.294531]\n",
      "epoch:29 step:27276 [D loss: 0.253210, acc.: 53.12%] [G loss: 0.293425]\n",
      "epoch:29 step:27277 [D loss: 0.253258, acc.: 51.56%] [G loss: 0.295238]\n",
      "epoch:29 step:27278 [D loss: 0.230112, acc.: 60.94%] [G loss: 0.290730]\n",
      "epoch:29 step:27279 [D loss: 0.259443, acc.: 54.69%] [G loss: 0.268781]\n",
      "epoch:29 step:27280 [D loss: 0.241184, acc.: 60.94%] [G loss: 0.269280]\n",
      "epoch:29 step:27281 [D loss: 0.235980, acc.: 60.16%] [G loss: 0.281682]\n",
      "epoch:29 step:27282 [D loss: 0.256613, acc.: 51.56%] [G loss: 0.302691]\n",
      "epoch:29 step:27283 [D loss: 0.266456, acc.: 49.22%] [G loss: 0.272165]\n",
      "epoch:29 step:27284 [D loss: 0.246570, acc.: 57.03%] [G loss: 0.278666]\n",
      "epoch:29 step:27285 [D loss: 0.243784, acc.: 57.81%] [G loss: 0.276596]\n",
      "epoch:29 step:27286 [D loss: 0.263150, acc.: 46.09%] [G loss: 0.329228]\n",
      "epoch:29 step:27287 [D loss: 0.252698, acc.: 52.34%] [G loss: 0.294936]\n",
      "epoch:29 step:27288 [D loss: 0.241840, acc.: 57.03%] [G loss: 0.283490]\n",
      "epoch:29 step:27289 [D loss: 0.237177, acc.: 63.28%] [G loss: 0.296849]\n",
      "epoch:29 step:27290 [D loss: 0.238374, acc.: 55.47%] [G loss: 0.266958]\n",
      "epoch:29 step:27291 [D loss: 0.225959, acc.: 61.72%] [G loss: 0.311218]\n",
      "epoch:29 step:27292 [D loss: 0.242988, acc.: 56.25%] [G loss: 0.290217]\n",
      "epoch:29 step:27293 [D loss: 0.207568, acc.: 70.31%] [G loss: 0.311096]\n",
      "epoch:29 step:27294 [D loss: 0.245470, acc.: 52.34%] [G loss: 0.295908]\n",
      "epoch:29 step:27295 [D loss: 0.255913, acc.: 55.47%] [G loss: 0.313600]\n",
      "epoch:29 step:27296 [D loss: 0.245566, acc.: 57.81%] [G loss: 0.287436]\n",
      "epoch:29 step:27297 [D loss: 0.249152, acc.: 50.78%] [G loss: 0.284619]\n",
      "epoch:29 step:27298 [D loss: 0.225158, acc.: 67.19%] [G loss: 0.308106]\n",
      "epoch:29 step:27299 [D loss: 0.238045, acc.: 55.47%] [G loss: 0.320185]\n",
      "epoch:29 step:27300 [D loss: 0.236353, acc.: 56.25%] [G loss: 0.310599]\n",
      "epoch:29 step:27301 [D loss: 0.235232, acc.: 56.25%] [G loss: 0.271001]\n",
      "epoch:29 step:27302 [D loss: 0.241342, acc.: 55.47%] [G loss: 0.279984]\n",
      "epoch:29 step:27303 [D loss: 0.232067, acc.: 60.94%] [G loss: 0.294362]\n",
      "epoch:29 step:27304 [D loss: 0.240854, acc.: 60.94%] [G loss: 0.279561]\n",
      "epoch:29 step:27305 [D loss: 0.229415, acc.: 58.59%] [G loss: 0.305385]\n",
      "epoch:29 step:27306 [D loss: 0.241536, acc.: 58.59%] [G loss: 0.303304]\n",
      "epoch:29 step:27307 [D loss: 0.224848, acc.: 64.06%] [G loss: 0.326654]\n",
      "epoch:29 step:27308 [D loss: 0.246512, acc.: 55.47%] [G loss: 0.277507]\n",
      "epoch:29 step:27309 [D loss: 0.230123, acc.: 57.81%] [G loss: 0.339312]\n",
      "epoch:29 step:27310 [D loss: 0.244523, acc.: 53.91%] [G loss: 0.292404]\n",
      "epoch:29 step:27311 [D loss: 0.232797, acc.: 60.16%] [G loss: 0.306034]\n",
      "epoch:29 step:27312 [D loss: 0.237637, acc.: 59.38%] [G loss: 0.286782]\n",
      "epoch:29 step:27313 [D loss: 0.230057, acc.: 64.06%] [G loss: 0.280468]\n",
      "epoch:29 step:27314 [D loss: 0.228862, acc.: 64.84%] [G loss: 0.300424]\n",
      "epoch:29 step:27315 [D loss: 0.223750, acc.: 62.50%] [G loss: 0.331710]\n",
      "epoch:29 step:27316 [D loss: 0.243037, acc.: 53.91%] [G loss: 0.292100]\n",
      "epoch:29 step:27317 [D loss: 0.249234, acc.: 53.12%] [G loss: 0.289236]\n",
      "epoch:29 step:27318 [D loss: 0.234074, acc.: 59.38%] [G loss: 0.282846]\n",
      "epoch:29 step:27319 [D loss: 0.219681, acc.: 65.62%] [G loss: 0.295928]\n",
      "epoch:29 step:27320 [D loss: 0.228639, acc.: 61.72%] [G loss: 0.288103]\n",
      "epoch:29 step:27321 [D loss: 0.227134, acc.: 60.16%] [G loss: 0.292167]\n",
      "epoch:29 step:27322 [D loss: 0.232696, acc.: 63.28%] [G loss: 0.302595]\n",
      "epoch:29 step:27323 [D loss: 0.251350, acc.: 52.34%] [G loss: 0.278706]\n",
      "epoch:29 step:27324 [D loss: 0.265241, acc.: 47.66%] [G loss: 0.260425]\n",
      "epoch:29 step:27325 [D loss: 0.226596, acc.: 62.50%] [G loss: 0.306712]\n",
      "epoch:29 step:27326 [D loss: 0.250973, acc.: 55.47%] [G loss: 0.300639]\n",
      "epoch:29 step:27327 [D loss: 0.235687, acc.: 59.38%] [G loss: 0.308583]\n",
      "epoch:29 step:27328 [D loss: 0.245752, acc.: 57.03%] [G loss: 0.283746]\n",
      "epoch:29 step:27329 [D loss: 0.233777, acc.: 56.25%] [G loss: 0.298808]\n",
      "epoch:29 step:27330 [D loss: 0.249792, acc.: 53.12%] [G loss: 0.267098]\n",
      "epoch:29 step:27331 [D loss: 0.230082, acc.: 64.84%] [G loss: 0.266085]\n",
      "epoch:29 step:27332 [D loss: 0.229937, acc.: 58.59%] [G loss: 0.278261]\n",
      "epoch:29 step:27333 [D loss: 0.229799, acc.: 67.97%] [G loss: 0.299766]\n",
      "epoch:29 step:27334 [D loss: 0.235254, acc.: 59.38%] [G loss: 0.317593]\n",
      "epoch:29 step:27335 [D loss: 0.239761, acc.: 58.59%] [G loss: 0.312451]\n",
      "epoch:29 step:27336 [D loss: 0.239957, acc.: 60.16%] [G loss: 0.309510]\n",
      "epoch:29 step:27337 [D loss: 0.232828, acc.: 59.38%] [G loss: 0.300669]\n",
      "epoch:29 step:27338 [D loss: 0.217729, acc.: 66.41%] [G loss: 0.300356]\n",
      "epoch:29 step:27339 [D loss: 0.230671, acc.: 59.38%] [G loss: 0.305972]\n",
      "epoch:29 step:27340 [D loss: 0.246431, acc.: 51.56%] [G loss: 0.294164]\n",
      "epoch:29 step:27341 [D loss: 0.234104, acc.: 58.59%] [G loss: 0.293525]\n",
      "epoch:29 step:27342 [D loss: 0.248582, acc.: 53.91%] [G loss: 0.302957]\n",
      "epoch:29 step:27343 [D loss: 0.242126, acc.: 57.03%] [G loss: 0.284016]\n",
      "epoch:29 step:27344 [D loss: 0.251591, acc.: 55.47%] [G loss: 0.282188]\n",
      "epoch:29 step:27345 [D loss: 0.227917, acc.: 64.06%] [G loss: 0.307029]\n",
      "epoch:29 step:27346 [D loss: 0.223625, acc.: 66.41%] [G loss: 0.298489]\n",
      "epoch:29 step:27347 [D loss: 0.235694, acc.: 63.28%] [G loss: 0.303133]\n",
      "epoch:29 step:27348 [D loss: 0.231716, acc.: 61.72%] [G loss: 0.310683]\n",
      "epoch:29 step:27349 [D loss: 0.231164, acc.: 60.16%] [G loss: 0.295623]\n",
      "epoch:29 step:27350 [D loss: 0.233810, acc.: 57.03%] [G loss: 0.299359]\n",
      "epoch:29 step:27351 [D loss: 0.248644, acc.: 56.25%] [G loss: 0.308205]\n",
      "epoch:29 step:27352 [D loss: 0.239456, acc.: 59.38%] [G loss: 0.334501]\n",
      "epoch:29 step:27353 [D loss: 0.245287, acc.: 54.69%] [G loss: 0.297065]\n",
      "epoch:29 step:27354 [D loss: 0.262056, acc.: 46.88%] [G loss: 0.315430]\n",
      "epoch:29 step:27355 [D loss: 0.226240, acc.: 67.97%] [G loss: 0.298800]\n",
      "epoch:29 step:27356 [D loss: 0.231471, acc.: 64.06%] [G loss: 0.326617]\n",
      "epoch:29 step:27357 [D loss: 0.245771, acc.: 57.03%] [G loss: 0.298239]\n",
      "epoch:29 step:27358 [D loss: 0.246956, acc.: 57.81%] [G loss: 0.333032]\n",
      "epoch:29 step:27359 [D loss: 0.251963, acc.: 51.56%] [G loss: 0.301321]\n",
      "epoch:29 step:27360 [D loss: 0.236927, acc.: 59.38%] [G loss: 0.288164]\n",
      "epoch:29 step:27361 [D loss: 0.234097, acc.: 64.84%] [G loss: 0.303264]\n",
      "epoch:29 step:27362 [D loss: 0.235227, acc.: 54.69%] [G loss: 0.319326]\n",
      "epoch:29 step:27363 [D loss: 0.249616, acc.: 52.34%] [G loss: 0.275534]\n",
      "epoch:29 step:27364 [D loss: 0.227227, acc.: 60.94%] [G loss: 0.284244]\n",
      "epoch:29 step:27365 [D loss: 0.237586, acc.: 60.94%] [G loss: 0.292060]\n",
      "epoch:29 step:27366 [D loss: 0.239764, acc.: 60.94%] [G loss: 0.303024]\n",
      "epoch:29 step:27367 [D loss: 0.249762, acc.: 49.22%] [G loss: 0.295109]\n",
      "epoch:29 step:27368 [D loss: 0.229158, acc.: 56.25%] [G loss: 0.276967]\n",
      "epoch:29 step:27369 [D loss: 0.218391, acc.: 66.41%] [G loss: 0.294501]\n",
      "epoch:29 step:27370 [D loss: 0.241181, acc.: 60.94%] [G loss: 0.286737]\n",
      "epoch:29 step:27371 [D loss: 0.251658, acc.: 54.69%] [G loss: 0.301548]\n",
      "epoch:29 step:27372 [D loss: 0.240578, acc.: 59.38%] [G loss: 0.298789]\n",
      "epoch:29 step:27373 [D loss: 0.236964, acc.: 57.03%] [G loss: 0.316236]\n",
      "epoch:29 step:27374 [D loss: 0.242064, acc.: 57.81%] [G loss: 0.320659]\n",
      "epoch:29 step:27375 [D loss: 0.235405, acc.: 57.03%] [G loss: 0.284582]\n",
      "epoch:29 step:27376 [D loss: 0.233158, acc.: 59.38%] [G loss: 0.296204]\n",
      "epoch:29 step:27377 [D loss: 0.228145, acc.: 64.84%] [G loss: 0.297713]\n",
      "epoch:29 step:27378 [D loss: 0.235829, acc.: 58.59%] [G loss: 0.301973]\n",
      "epoch:29 step:27379 [D loss: 0.254334, acc.: 53.12%] [G loss: 0.290967]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:29 step:27380 [D loss: 0.244276, acc.: 54.69%] [G loss: 0.315612]\n",
      "epoch:29 step:27381 [D loss: 0.250942, acc.: 56.25%] [G loss: 0.303378]\n",
      "epoch:29 step:27382 [D loss: 0.243383, acc.: 60.16%] [G loss: 0.329300]\n",
      "epoch:29 step:27383 [D loss: 0.241085, acc.: 60.16%] [G loss: 0.278046]\n",
      "epoch:29 step:27384 [D loss: 0.219919, acc.: 67.97%] [G loss: 0.301997]\n",
      "epoch:29 step:27385 [D loss: 0.239153, acc.: 59.38%] [G loss: 0.305796]\n",
      "epoch:29 step:27386 [D loss: 0.248626, acc.: 53.91%] [G loss: 0.297907]\n",
      "epoch:29 step:27387 [D loss: 0.245518, acc.: 50.00%] [G loss: 0.307033]\n",
      "epoch:29 step:27388 [D loss: 0.224848, acc.: 63.28%] [G loss: 0.295050]\n",
      "epoch:29 step:27389 [D loss: 0.232394, acc.: 62.50%] [G loss: 0.302992]\n",
      "epoch:29 step:27390 [D loss: 0.229016, acc.: 60.16%] [G loss: 0.293516]\n",
      "epoch:29 step:27391 [D loss: 0.256840, acc.: 53.12%] [G loss: 0.320013]\n",
      "epoch:29 step:27392 [D loss: 0.247749, acc.: 53.91%] [G loss: 0.291907]\n",
      "epoch:29 step:27393 [D loss: 0.229191, acc.: 61.72%] [G loss: 0.312502]\n",
      "epoch:29 step:27394 [D loss: 0.227720, acc.: 60.16%] [G loss: 0.331971]\n",
      "epoch:29 step:27395 [D loss: 0.244464, acc.: 56.25%] [G loss: 0.313348]\n",
      "epoch:29 step:27396 [D loss: 0.249404, acc.: 55.47%] [G loss: 0.306394]\n",
      "epoch:29 step:27397 [D loss: 0.230729, acc.: 60.94%] [G loss: 0.328531]\n",
      "epoch:29 step:27398 [D loss: 0.233072, acc.: 62.50%] [G loss: 0.309515]\n",
      "epoch:29 step:27399 [D loss: 0.270588, acc.: 51.56%] [G loss: 0.290176]\n",
      "epoch:29 step:27400 [D loss: 0.242134, acc.: 58.59%] [G loss: 0.326441]\n",
      "epoch:29 step:27401 [D loss: 0.240015, acc.: 63.28%] [G loss: 0.317667]\n",
      "epoch:29 step:27402 [D loss: 0.228075, acc.: 59.38%] [G loss: 0.299001]\n",
      "epoch:29 step:27403 [D loss: 0.232311, acc.: 61.72%] [G loss: 0.274879]\n",
      "epoch:29 step:27404 [D loss: 0.228793, acc.: 62.50%] [G loss: 0.300503]\n",
      "epoch:29 step:27405 [D loss: 0.247880, acc.: 59.38%] [G loss: 0.321812]\n",
      "epoch:29 step:27406 [D loss: 0.258222, acc.: 47.66%] [G loss: 0.315940]\n",
      "epoch:29 step:27407 [D loss: 0.239478, acc.: 59.38%] [G loss: 0.288898]\n",
      "epoch:29 step:27408 [D loss: 0.255248, acc.: 52.34%] [G loss: 0.302952]\n",
      "epoch:29 step:27409 [D loss: 0.247287, acc.: 54.69%] [G loss: 0.268779]\n",
      "epoch:29 step:27410 [D loss: 0.240488, acc.: 58.59%] [G loss: 0.338421]\n",
      "epoch:29 step:27411 [D loss: 0.240218, acc.: 57.81%] [G loss: 0.289301]\n",
      "epoch:29 step:27412 [D loss: 0.233332, acc.: 61.72%] [G loss: 0.311107]\n",
      "epoch:29 step:27413 [D loss: 0.252986, acc.: 53.91%] [G loss: 0.297644]\n",
      "epoch:29 step:27414 [D loss: 0.223389, acc.: 65.62%] [G loss: 0.309314]\n",
      "epoch:29 step:27415 [D loss: 0.235194, acc.: 62.50%] [G loss: 0.295510]\n",
      "epoch:29 step:27416 [D loss: 0.253635, acc.: 54.69%] [G loss: 0.291330]\n",
      "epoch:29 step:27417 [D loss: 0.247530, acc.: 52.34%] [G loss: 0.330058]\n",
      "epoch:29 step:27418 [D loss: 0.256302, acc.: 54.69%] [G loss: 0.301917]\n",
      "epoch:29 step:27419 [D loss: 0.229739, acc.: 64.84%] [G loss: 0.343793]\n",
      "epoch:29 step:27420 [D loss: 0.224315, acc.: 62.50%] [G loss: 0.308500]\n",
      "epoch:29 step:27421 [D loss: 0.241940, acc.: 59.38%] [G loss: 0.321381]\n",
      "epoch:29 step:27422 [D loss: 0.245137, acc.: 56.25%] [G loss: 0.301247]\n",
      "epoch:29 step:27423 [D loss: 0.251656, acc.: 53.12%] [G loss: 0.312682]\n",
      "epoch:29 step:27424 [D loss: 0.245307, acc.: 57.03%] [G loss: 0.302523]\n",
      "epoch:29 step:27425 [D loss: 0.235893, acc.: 56.25%] [G loss: 0.306220]\n",
      "epoch:29 step:27426 [D loss: 0.250336, acc.: 53.12%] [G loss: 0.298428]\n",
      "epoch:29 step:27427 [D loss: 0.241680, acc.: 61.72%] [G loss: 0.327486]\n",
      "epoch:29 step:27428 [D loss: 0.247328, acc.: 50.78%] [G loss: 0.286966]\n",
      "epoch:29 step:27429 [D loss: 0.229185, acc.: 64.06%] [G loss: 0.316501]\n",
      "epoch:29 step:27430 [D loss: 0.237770, acc.: 60.16%] [G loss: 0.298626]\n",
      "epoch:29 step:27431 [D loss: 0.237356, acc.: 60.94%] [G loss: 0.309393]\n",
      "epoch:29 step:27432 [D loss: 0.241608, acc.: 58.59%] [G loss: 0.296917]\n",
      "epoch:29 step:27433 [D loss: 0.240830, acc.: 53.91%] [G loss: 0.308178]\n",
      "epoch:29 step:27434 [D loss: 0.252075, acc.: 50.78%] [G loss: 0.308642]\n",
      "epoch:29 step:27435 [D loss: 0.252671, acc.: 54.69%] [G loss: 0.279989]\n",
      "epoch:29 step:27436 [D loss: 0.263115, acc.: 51.56%] [G loss: 0.303036]\n",
      "epoch:29 step:27437 [D loss: 0.238334, acc.: 59.38%] [G loss: 0.292978]\n",
      "epoch:29 step:27438 [D loss: 0.238132, acc.: 55.47%] [G loss: 0.322402]\n",
      "epoch:29 step:27439 [D loss: 0.250768, acc.: 52.34%] [G loss: 0.293670]\n",
      "epoch:29 step:27440 [D loss: 0.231068, acc.: 57.03%] [G loss: 0.331223]\n",
      "epoch:29 step:27441 [D loss: 0.239418, acc.: 54.69%] [G loss: 0.296018]\n",
      "epoch:29 step:27442 [D loss: 0.227003, acc.: 60.94%] [G loss: 0.303593]\n",
      "epoch:29 step:27443 [D loss: 0.250699, acc.: 53.91%] [G loss: 0.267797]\n",
      "epoch:29 step:27444 [D loss: 0.236129, acc.: 59.38%] [G loss: 0.283672]\n",
      "epoch:29 step:27445 [D loss: 0.244192, acc.: 59.38%] [G loss: 0.309730]\n",
      "epoch:29 step:27446 [D loss: 0.237106, acc.: 56.25%] [G loss: 0.336088]\n",
      "epoch:29 step:27447 [D loss: 0.236444, acc.: 55.47%] [G loss: 0.283926]\n",
      "epoch:29 step:27448 [D loss: 0.257239, acc.: 52.34%] [G loss: 0.302958]\n",
      "epoch:29 step:27449 [D loss: 0.245713, acc.: 57.81%] [G loss: 0.290326]\n",
      "epoch:29 step:27450 [D loss: 0.255808, acc.: 53.12%] [G loss: 0.301975]\n",
      "epoch:29 step:27451 [D loss: 0.244392, acc.: 59.38%] [G loss: 0.286762]\n",
      "epoch:29 step:27452 [D loss: 0.239380, acc.: 57.81%] [G loss: 0.295586]\n",
      "epoch:29 step:27453 [D loss: 0.235105, acc.: 60.94%] [G loss: 0.325156]\n",
      "epoch:29 step:27454 [D loss: 0.251111, acc.: 54.69%] [G loss: 0.299807]\n",
      "epoch:29 step:27455 [D loss: 0.249965, acc.: 53.12%] [G loss: 0.297707]\n",
      "epoch:29 step:27456 [D loss: 0.225116, acc.: 60.94%] [G loss: 0.312936]\n",
      "epoch:29 step:27457 [D loss: 0.233920, acc.: 60.94%] [G loss: 0.316053]\n",
      "epoch:29 step:27458 [D loss: 0.233913, acc.: 58.59%] [G loss: 0.291769]\n",
      "epoch:29 step:27459 [D loss: 0.243291, acc.: 56.25%] [G loss: 0.306625]\n",
      "epoch:29 step:27460 [D loss: 0.242790, acc.: 57.03%] [G loss: 0.301318]\n",
      "epoch:29 step:27461 [D loss: 0.253862, acc.: 48.44%] [G loss: 0.293743]\n",
      "epoch:29 step:27462 [D loss: 0.236074, acc.: 55.47%] [G loss: 0.305667]\n",
      "epoch:29 step:27463 [D loss: 0.233770, acc.: 60.16%] [G loss: 0.305932]\n",
      "epoch:29 step:27464 [D loss: 0.248558, acc.: 57.81%] [G loss: 0.300953]\n",
      "epoch:29 step:27465 [D loss: 0.225481, acc.: 64.06%] [G loss: 0.334978]\n",
      "epoch:29 step:27466 [D loss: 0.235413, acc.: 60.16%] [G loss: 0.323983]\n",
      "epoch:29 step:27467 [D loss: 0.239890, acc.: 58.59%] [G loss: 0.307633]\n",
      "epoch:29 step:27468 [D loss: 0.237625, acc.: 55.47%] [G loss: 0.311582]\n",
      "epoch:29 step:27469 [D loss: 0.234279, acc.: 60.16%] [G loss: 0.303158]\n",
      "epoch:29 step:27470 [D loss: 0.241889, acc.: 59.38%] [G loss: 0.293408]\n",
      "epoch:29 step:27471 [D loss: 0.251798, acc.: 53.91%] [G loss: 0.284441]\n",
      "epoch:29 step:27472 [D loss: 0.233203, acc.: 66.41%] [G loss: 0.322562]\n",
      "epoch:29 step:27473 [D loss: 0.225452, acc.: 62.50%] [G loss: 0.305542]\n",
      "epoch:29 step:27474 [D loss: 0.235163, acc.: 58.59%] [G loss: 0.288627]\n",
      "epoch:29 step:27475 [D loss: 0.235118, acc.: 59.38%] [G loss: 0.313161]\n",
      "epoch:29 step:27476 [D loss: 0.241893, acc.: 53.12%] [G loss: 0.293643]\n",
      "epoch:29 step:27477 [D loss: 0.256338, acc.: 53.12%] [G loss: 0.273292]\n",
      "epoch:29 step:27478 [D loss: 0.245644, acc.: 59.38%] [G loss: 0.309159]\n",
      "epoch:29 step:27479 [D loss: 0.243766, acc.: 56.25%] [G loss: 0.283333]\n",
      "epoch:29 step:27480 [D loss: 0.246988, acc.: 55.47%] [G loss: 0.308067]\n",
      "epoch:29 step:27481 [D loss: 0.243977, acc.: 55.47%] [G loss: 0.269945]\n",
      "epoch:29 step:27482 [D loss: 0.243197, acc.: 54.69%] [G loss: 0.295871]\n",
      "epoch:29 step:27483 [D loss: 0.228369, acc.: 60.16%] [G loss: 0.290730]\n",
      "epoch:29 step:27484 [D loss: 0.240897, acc.: 58.59%] [G loss: 0.276557]\n",
      "epoch:29 step:27485 [D loss: 0.237880, acc.: 58.59%] [G loss: 0.282151]\n",
      "epoch:29 step:27486 [D loss: 0.226855, acc.: 59.38%] [G loss: 0.292995]\n",
      "epoch:29 step:27487 [D loss: 0.242660, acc.: 57.81%] [G loss: 0.283006]\n",
      "epoch:29 step:27488 [D loss: 0.239008, acc.: 56.25%] [G loss: 0.317309]\n",
      "epoch:29 step:27489 [D loss: 0.226968, acc.: 58.59%] [G loss: 0.290696]\n",
      "epoch:29 step:27490 [D loss: 0.248043, acc.: 53.12%] [G loss: 0.302151]\n",
      "epoch:29 step:27491 [D loss: 0.238658, acc.: 62.50%] [G loss: 0.311782]\n",
      "epoch:29 step:27492 [D loss: 0.244315, acc.: 56.25%] [G loss: 0.264757]\n",
      "epoch:29 step:27493 [D loss: 0.231288, acc.: 62.50%] [G loss: 0.290706]\n",
      "epoch:29 step:27494 [D loss: 0.221419, acc.: 66.41%] [G loss: 0.300884]\n",
      "epoch:29 step:27495 [D loss: 0.244077, acc.: 58.59%] [G loss: 0.317691]\n",
      "epoch:29 step:27496 [D loss: 0.237846, acc.: 57.03%] [G loss: 0.305831]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:29 step:27497 [D loss: 0.235117, acc.: 55.47%] [G loss: 0.291522]\n",
      "epoch:29 step:27498 [D loss: 0.236413, acc.: 59.38%] [G loss: 0.286196]\n",
      "epoch:29 step:27499 [D loss: 0.240284, acc.: 58.59%] [G loss: 0.302854]\n",
      "epoch:29 step:27500 [D loss: 0.253006, acc.: 50.78%] [G loss: 0.298200]\n",
      "epoch:29 step:27501 [D loss: 0.228627, acc.: 63.28%] [G loss: 0.302081]\n",
      "epoch:29 step:27502 [D loss: 0.249567, acc.: 53.12%] [G loss: 0.271526]\n",
      "epoch:29 step:27503 [D loss: 0.238198, acc.: 58.59%] [G loss: 0.281855]\n",
      "epoch:29 step:27504 [D loss: 0.231312, acc.: 59.38%] [G loss: 0.291687]\n",
      "epoch:29 step:27505 [D loss: 0.237576, acc.: 56.25%] [G loss: 0.341549]\n",
      "epoch:29 step:27506 [D loss: 0.246406, acc.: 59.38%] [G loss: 0.315917]\n",
      "epoch:29 step:27507 [D loss: 0.248662, acc.: 57.03%] [G loss: 0.308095]\n",
      "epoch:29 step:27508 [D loss: 0.236384, acc.: 58.59%] [G loss: 0.310907]\n",
      "epoch:29 step:27509 [D loss: 0.233746, acc.: 64.06%] [G loss: 0.276617]\n",
      "epoch:29 step:27510 [D loss: 0.244716, acc.: 60.16%] [G loss: 0.309112]\n",
      "epoch:29 step:27511 [D loss: 0.242638, acc.: 55.47%] [G loss: 0.297632]\n",
      "epoch:29 step:27512 [D loss: 0.246325, acc.: 55.47%] [G loss: 0.275839]\n",
      "epoch:29 step:27513 [D loss: 0.224644, acc.: 59.38%] [G loss: 0.304590]\n",
      "epoch:29 step:27514 [D loss: 0.241674, acc.: 53.12%] [G loss: 0.312685]\n",
      "epoch:29 step:27515 [D loss: 0.242171, acc.: 56.25%] [G loss: 0.315042]\n",
      "epoch:29 step:27516 [D loss: 0.243335, acc.: 58.59%] [G loss: 0.290572]\n",
      "epoch:29 step:27517 [D loss: 0.230073, acc.: 61.72%] [G loss: 0.305677]\n",
      "epoch:29 step:27518 [D loss: 0.230954, acc.: 67.97%] [G loss: 0.305443]\n",
      "epoch:29 step:27519 [D loss: 0.223679, acc.: 64.06%] [G loss: 0.298799]\n",
      "epoch:29 step:27520 [D loss: 0.235196, acc.: 62.50%] [G loss: 0.276442]\n",
      "epoch:29 step:27521 [D loss: 0.250729, acc.: 52.34%] [G loss: 0.305732]\n",
      "epoch:29 step:27522 [D loss: 0.232590, acc.: 64.84%] [G loss: 0.276144]\n",
      "epoch:29 step:27523 [D loss: 0.252185, acc.: 53.12%] [G loss: 0.299953]\n",
      "epoch:29 step:27524 [D loss: 0.221354, acc.: 60.16%] [G loss: 0.278626]\n",
      "epoch:29 step:27525 [D loss: 0.237696, acc.: 55.47%] [G loss: 0.290520]\n",
      "epoch:29 step:27526 [D loss: 0.230898, acc.: 62.50%] [G loss: 0.279935]\n",
      "epoch:29 step:27527 [D loss: 0.237076, acc.: 60.16%] [G loss: 0.303160]\n",
      "epoch:29 step:27528 [D loss: 0.233465, acc.: 58.59%] [G loss: 0.278072]\n",
      "epoch:29 step:27529 [D loss: 0.232621, acc.: 60.94%] [G loss: 0.287182]\n",
      "epoch:29 step:27530 [D loss: 0.237953, acc.: 62.50%] [G loss: 0.290952]\n",
      "epoch:29 step:27531 [D loss: 0.241467, acc.: 55.47%] [G loss: 0.275354]\n",
      "epoch:29 step:27532 [D loss: 0.229494, acc.: 63.28%] [G loss: 0.326837]\n",
      "epoch:29 step:27533 [D loss: 0.246864, acc.: 53.12%] [G loss: 0.316833]\n",
      "epoch:29 step:27534 [D loss: 0.245962, acc.: 56.25%] [G loss: 0.277910]\n",
      "epoch:29 step:27535 [D loss: 0.230229, acc.: 64.84%] [G loss: 0.307467]\n",
      "epoch:29 step:27536 [D loss: 0.219663, acc.: 67.19%] [G loss: 0.299184]\n",
      "epoch:29 step:27537 [D loss: 0.250401, acc.: 51.56%] [G loss: 0.305109]\n",
      "epoch:29 step:27538 [D loss: 0.254065, acc.: 55.47%] [G loss: 0.313587]\n",
      "epoch:29 step:27539 [D loss: 0.203037, acc.: 71.09%] [G loss: 0.334474]\n",
      "epoch:29 step:27540 [D loss: 0.232811, acc.: 64.06%] [G loss: 0.314086]\n",
      "epoch:29 step:27541 [D loss: 0.232334, acc.: 57.03%] [G loss: 0.314071]\n",
      "epoch:29 step:27542 [D loss: 0.244205, acc.: 56.25%] [G loss: 0.300573]\n",
      "epoch:29 step:27543 [D loss: 0.232355, acc.: 60.16%] [G loss: 0.314923]\n",
      "epoch:29 step:27544 [D loss: 0.238783, acc.: 61.72%] [G loss: 0.303965]\n",
      "epoch:29 step:27545 [D loss: 0.239167, acc.: 60.94%] [G loss: 0.299122]\n",
      "epoch:29 step:27546 [D loss: 0.229429, acc.: 57.81%] [G loss: 0.312599]\n",
      "epoch:29 step:27547 [D loss: 0.251917, acc.: 50.78%] [G loss: 0.317476]\n",
      "epoch:29 step:27548 [D loss: 0.231147, acc.: 60.94%] [G loss: 0.283627]\n",
      "epoch:29 step:27549 [D loss: 0.245116, acc.: 55.47%] [G loss: 0.292375]\n",
      "epoch:29 step:27550 [D loss: 0.233661, acc.: 64.84%] [G loss: 0.329956]\n",
      "epoch:29 step:27551 [D loss: 0.236177, acc.: 55.47%] [G loss: 0.306505]\n",
      "epoch:29 step:27552 [D loss: 0.217788, acc.: 69.53%] [G loss: 0.338507]\n",
      "epoch:29 step:27553 [D loss: 0.231385, acc.: 61.72%] [G loss: 0.309858]\n",
      "epoch:29 step:27554 [D loss: 0.238578, acc.: 58.59%] [G loss: 0.302436]\n",
      "epoch:29 step:27555 [D loss: 0.226240, acc.: 65.62%] [G loss: 0.289341]\n",
      "epoch:29 step:27556 [D loss: 0.235769, acc.: 57.03%] [G loss: 0.283835]\n",
      "epoch:29 step:27557 [D loss: 0.253687, acc.: 57.03%] [G loss: 0.308395]\n",
      "epoch:29 step:27558 [D loss: 0.241927, acc.: 53.12%] [G loss: 0.308433]\n",
      "epoch:29 step:27559 [D loss: 0.230930, acc.: 64.84%] [G loss: 0.310525]\n",
      "epoch:29 step:27560 [D loss: 0.227052, acc.: 65.62%] [G loss: 0.289892]\n",
      "epoch:29 step:27561 [D loss: 0.238842, acc.: 59.38%] [G loss: 0.306246]\n",
      "epoch:29 step:27562 [D loss: 0.243631, acc.: 57.03%] [G loss: 0.299702]\n",
      "epoch:29 step:27563 [D loss: 0.236998, acc.: 57.03%] [G loss: 0.312761]\n",
      "epoch:29 step:27564 [D loss: 0.242760, acc.: 59.38%] [G loss: 0.296119]\n",
      "epoch:29 step:27565 [D loss: 0.228173, acc.: 62.50%] [G loss: 0.293743]\n",
      "epoch:29 step:27566 [D loss: 0.249636, acc.: 50.78%] [G loss: 0.277132]\n",
      "epoch:29 step:27567 [D loss: 0.249110, acc.: 49.22%] [G loss: 0.262094]\n",
      "epoch:29 step:27568 [D loss: 0.247502, acc.: 55.47%] [G loss: 0.303846]\n",
      "epoch:29 step:27569 [D loss: 0.220155, acc.: 67.97%] [G loss: 0.290142]\n",
      "epoch:29 step:27570 [D loss: 0.246587, acc.: 61.72%] [G loss: 0.315109]\n",
      "epoch:29 step:27571 [D loss: 0.231745, acc.: 63.28%] [G loss: 0.289420]\n",
      "epoch:29 step:27572 [D loss: 0.240458, acc.: 64.06%] [G loss: 0.319284]\n",
      "epoch:29 step:27573 [D loss: 0.242878, acc.: 54.69%] [G loss: 0.336083]\n",
      "epoch:29 step:27574 [D loss: 0.235840, acc.: 55.47%] [G loss: 0.302328]\n",
      "epoch:29 step:27575 [D loss: 0.227621, acc.: 57.81%] [G loss: 0.329563]\n",
      "epoch:29 step:27576 [D loss: 0.226559, acc.: 67.97%] [G loss: 0.314810]\n",
      "epoch:29 step:27577 [D loss: 0.218156, acc.: 67.19%] [G loss: 0.322944]\n",
      "epoch:29 step:27578 [D loss: 0.238414, acc.: 56.25%] [G loss: 0.299166]\n",
      "epoch:29 step:27579 [D loss: 0.236688, acc.: 61.72%] [G loss: 0.296201]\n",
      "epoch:29 step:27580 [D loss: 0.246948, acc.: 56.25%] [G loss: 0.295426]\n",
      "epoch:29 step:27581 [D loss: 0.257444, acc.: 52.34%] [G loss: 0.300509]\n",
      "epoch:29 step:27582 [D loss: 0.231948, acc.: 58.59%] [G loss: 0.304590]\n",
      "epoch:29 step:27583 [D loss: 0.246473, acc.: 57.81%] [G loss: 0.311761]\n",
      "epoch:29 step:27584 [D loss: 0.232679, acc.: 60.94%] [G loss: 0.309092]\n",
      "epoch:29 step:27585 [D loss: 0.258077, acc.: 47.66%] [G loss: 0.297509]\n",
      "epoch:29 step:27586 [D loss: 0.238536, acc.: 59.38%] [G loss: 0.280624]\n",
      "epoch:29 step:27587 [D loss: 0.236100, acc.: 60.16%] [G loss: 0.307104]\n",
      "epoch:29 step:27588 [D loss: 0.231482, acc.: 61.72%] [G loss: 0.291484]\n",
      "epoch:29 step:27589 [D loss: 0.255275, acc.: 50.78%] [G loss: 0.298609]\n",
      "epoch:29 step:27590 [D loss: 0.253881, acc.: 56.25%] [G loss: 0.283953]\n",
      "epoch:29 step:27591 [D loss: 0.248712, acc.: 57.03%] [G loss: 0.295035]\n",
      "epoch:29 step:27592 [D loss: 0.241052, acc.: 57.03%] [G loss: 0.300623]\n",
      "epoch:29 step:27593 [D loss: 0.242509, acc.: 58.59%] [G loss: 0.304290]\n",
      "epoch:29 step:27594 [D loss: 0.249563, acc.: 52.34%] [G loss: 0.331965]\n",
      "epoch:29 step:27595 [D loss: 0.248728, acc.: 50.00%] [G loss: 0.286814]\n",
      "epoch:29 step:27596 [D loss: 0.255185, acc.: 50.78%] [G loss: 0.292354]\n",
      "epoch:29 step:27597 [D loss: 0.238725, acc.: 52.34%] [G loss: 0.299284]\n",
      "epoch:29 step:27598 [D loss: 0.230147, acc.: 60.16%] [G loss: 0.305689]\n",
      "epoch:29 step:27599 [D loss: 0.247100, acc.: 51.56%] [G loss: 0.302146]\n",
      "epoch:29 step:27600 [D loss: 0.224152, acc.: 63.28%] [G loss: 0.347169]\n",
      "epoch:29 step:27601 [D loss: 0.231858, acc.: 65.62%] [G loss: 0.278983]\n",
      "epoch:29 step:27602 [D loss: 0.247998, acc.: 59.38%] [G loss: 0.305218]\n",
      "epoch:29 step:27603 [D loss: 0.254825, acc.: 52.34%] [G loss: 0.312478]\n",
      "epoch:29 step:27604 [D loss: 0.232977, acc.: 60.94%] [G loss: 0.280022]\n",
      "epoch:29 step:27605 [D loss: 0.228822, acc.: 62.50%] [G loss: 0.329110]\n",
      "epoch:29 step:27606 [D loss: 0.241534, acc.: 58.59%] [G loss: 0.316080]\n",
      "epoch:29 step:27607 [D loss: 0.247726, acc.: 57.03%] [G loss: 0.296880]\n",
      "epoch:29 step:27608 [D loss: 0.224353, acc.: 60.94%] [G loss: 0.321410]\n",
      "epoch:29 step:27609 [D loss: 0.243541, acc.: 55.47%] [G loss: 0.289008]\n",
      "epoch:29 step:27610 [D loss: 0.244830, acc.: 57.81%] [G loss: 0.282149]\n",
      "epoch:29 step:27611 [D loss: 0.235407, acc.: 62.50%] [G loss: 0.303267]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:29 step:27612 [D loss: 0.223570, acc.: 61.72%] [G loss: 0.276573]\n",
      "epoch:29 step:27613 [D loss: 0.254337, acc.: 54.69%] [G loss: 0.284142]\n",
      "epoch:29 step:27614 [D loss: 0.238584, acc.: 55.47%] [G loss: 0.324689]\n",
      "epoch:29 step:27615 [D loss: 0.239223, acc.: 60.16%] [G loss: 0.301426]\n",
      "epoch:29 step:27616 [D loss: 0.237731, acc.: 58.59%] [G loss: 0.303437]\n",
      "epoch:29 step:27617 [D loss: 0.254487, acc.: 55.47%] [G loss: 0.300516]\n",
      "epoch:29 step:27618 [D loss: 0.228307, acc.: 59.38%] [G loss: 0.297725]\n",
      "epoch:29 step:27619 [D loss: 0.245569, acc.: 53.91%] [G loss: 0.319861]\n",
      "epoch:29 step:27620 [D loss: 0.225223, acc.: 65.62%] [G loss: 0.304817]\n",
      "epoch:29 step:27621 [D loss: 0.223732, acc.: 65.62%] [G loss: 0.314801]\n",
      "epoch:29 step:27622 [D loss: 0.234379, acc.: 57.03%] [G loss: 0.296888]\n",
      "epoch:29 step:27623 [D loss: 0.251222, acc.: 54.69%] [G loss: 0.269067]\n",
      "epoch:29 step:27624 [D loss: 0.237465, acc.: 59.38%] [G loss: 0.333868]\n",
      "epoch:29 step:27625 [D loss: 0.218418, acc.: 65.62%] [G loss: 0.309937]\n",
      "epoch:29 step:27626 [D loss: 0.214576, acc.: 64.06%] [G loss: 0.305840]\n",
      "epoch:29 step:27627 [D loss: 0.226754, acc.: 65.62%] [G loss: 0.316523]\n",
      "epoch:29 step:27628 [D loss: 0.206591, acc.: 71.09%] [G loss: 0.332854]\n",
      "epoch:29 step:27629 [D loss: 0.238624, acc.: 54.69%] [G loss: 0.311772]\n",
      "epoch:29 step:27630 [D loss: 0.241692, acc.: 56.25%] [G loss: 0.323735]\n",
      "epoch:29 step:27631 [D loss: 0.237729, acc.: 59.38%] [G loss: 0.290561]\n",
      "epoch:29 step:27632 [D loss: 0.237643, acc.: 61.72%] [G loss: 0.279493]\n",
      "epoch:29 step:27633 [D loss: 0.229274, acc.: 60.16%] [G loss: 0.329288]\n",
      "epoch:29 step:27634 [D loss: 0.241105, acc.: 57.03%] [G loss: 0.305856]\n",
      "epoch:29 step:27635 [D loss: 0.245064, acc.: 50.00%] [G loss: 0.296229]\n",
      "epoch:29 step:27636 [D loss: 0.240050, acc.: 53.12%] [G loss: 0.306044]\n",
      "epoch:29 step:27637 [D loss: 0.229160, acc.: 63.28%] [G loss: 0.310710]\n",
      "epoch:29 step:27638 [D loss: 0.238135, acc.: 60.16%] [G loss: 0.284244]\n",
      "epoch:29 step:27639 [D loss: 0.248913, acc.: 54.69%] [G loss: 0.295737]\n",
      "epoch:29 step:27640 [D loss: 0.231113, acc.: 64.84%] [G loss: 0.301269]\n",
      "epoch:29 step:27641 [D loss: 0.218136, acc.: 65.62%] [G loss: 0.307653]\n",
      "epoch:29 step:27642 [D loss: 0.239723, acc.: 58.59%] [G loss: 0.293797]\n",
      "epoch:29 step:27643 [D loss: 0.240314, acc.: 61.72%] [G loss: 0.264703]\n",
      "epoch:29 step:27644 [D loss: 0.258674, acc.: 50.00%] [G loss: 0.283272]\n",
      "epoch:29 step:27645 [D loss: 0.258008, acc.: 45.31%] [G loss: 0.303736]\n",
      "epoch:29 step:27646 [D loss: 0.226212, acc.: 58.59%] [G loss: 0.293306]\n",
      "epoch:29 step:27647 [D loss: 0.242278, acc.: 51.56%] [G loss: 0.291880]\n",
      "epoch:29 step:27648 [D loss: 0.244601, acc.: 63.28%] [G loss: 0.302124]\n",
      "epoch:29 step:27649 [D loss: 0.232336, acc.: 60.94%] [G loss: 0.301907]\n",
      "epoch:29 step:27650 [D loss: 0.238558, acc.: 53.12%] [G loss: 0.282785]\n",
      "epoch:29 step:27651 [D loss: 0.224200, acc.: 60.94%] [G loss: 0.270814]\n",
      "epoch:29 step:27652 [D loss: 0.253081, acc.: 54.69%] [G loss: 0.289570]\n",
      "epoch:29 step:27653 [D loss: 0.229478, acc.: 58.59%] [G loss: 0.311956]\n",
      "epoch:29 step:27654 [D loss: 0.239888, acc.: 60.94%] [G loss: 0.305430]\n",
      "epoch:29 step:27655 [D loss: 0.249348, acc.: 50.78%] [G loss: 0.263753]\n",
      "epoch:29 step:27656 [D loss: 0.234327, acc.: 59.38%] [G loss: 0.309893]\n",
      "epoch:29 step:27657 [D loss: 0.213836, acc.: 64.84%] [G loss: 0.312593]\n",
      "epoch:29 step:27658 [D loss: 0.255595, acc.: 52.34%] [G loss: 0.281718]\n",
      "epoch:29 step:27659 [D loss: 0.244532, acc.: 58.59%] [G loss: 0.295117]\n",
      "epoch:29 step:27660 [D loss: 0.233677, acc.: 57.03%] [G loss: 0.303357]\n",
      "epoch:29 step:27661 [D loss: 0.243269, acc.: 52.34%] [G loss: 0.317583]\n",
      "epoch:29 step:27662 [D loss: 0.241295, acc.: 57.03%] [G loss: 0.310190]\n",
      "epoch:29 step:27663 [D loss: 0.228624, acc.: 65.62%] [G loss: 0.320326]\n",
      "epoch:29 step:27664 [D loss: 0.241421, acc.: 60.16%] [G loss: 0.307593]\n",
      "epoch:29 step:27665 [D loss: 0.235446, acc.: 61.72%] [G loss: 0.299928]\n",
      "epoch:29 step:27666 [D loss: 0.247013, acc.: 57.03%] [G loss: 0.300017]\n",
      "epoch:29 step:27667 [D loss: 0.213756, acc.: 73.44%] [G loss: 0.320117]\n",
      "epoch:29 step:27668 [D loss: 0.243913, acc.: 57.03%] [G loss: 0.310621]\n",
      "epoch:29 step:27669 [D loss: 0.224497, acc.: 59.38%] [G loss: 0.291587]\n",
      "epoch:29 step:27670 [D loss: 0.239754, acc.: 56.25%] [G loss: 0.301051]\n",
      "epoch:29 step:27671 [D loss: 0.227451, acc.: 60.16%] [G loss: 0.287645]\n",
      "epoch:29 step:27672 [D loss: 0.243242, acc.: 59.38%] [G loss: 0.288252]\n",
      "epoch:29 step:27673 [D loss: 0.250913, acc.: 55.47%] [G loss: 0.319851]\n",
      "epoch:29 step:27674 [D loss: 0.222855, acc.: 64.84%] [G loss: 0.296215]\n",
      "epoch:29 step:27675 [D loss: 0.231168, acc.: 64.06%] [G loss: 0.322488]\n",
      "epoch:29 step:27676 [D loss: 0.244635, acc.: 57.81%] [G loss: 0.310637]\n",
      "epoch:29 step:27677 [D loss: 0.224136, acc.: 66.41%] [G loss: 0.303794]\n",
      "epoch:29 step:27678 [D loss: 0.236322, acc.: 56.25%] [G loss: 0.331993]\n",
      "epoch:29 step:27679 [D loss: 0.245232, acc.: 53.91%] [G loss: 0.303105]\n",
      "epoch:29 step:27680 [D loss: 0.259620, acc.: 57.81%] [G loss: 0.288160]\n",
      "epoch:29 step:27681 [D loss: 0.247570, acc.: 53.91%] [G loss: 0.284734]\n",
      "epoch:29 step:27682 [D loss: 0.228886, acc.: 60.16%] [G loss: 0.321108]\n",
      "epoch:29 step:27683 [D loss: 0.230723, acc.: 60.94%] [G loss: 0.286580]\n",
      "epoch:29 step:27684 [D loss: 0.247470, acc.: 57.03%] [G loss: 0.283863]\n",
      "epoch:29 step:27685 [D loss: 0.244159, acc.: 57.81%] [G loss: 0.295548]\n",
      "epoch:29 step:27686 [D loss: 0.235816, acc.: 63.28%] [G loss: 0.307226]\n",
      "epoch:29 step:27687 [D loss: 0.239872, acc.: 59.38%] [G loss: 0.301697]\n",
      "epoch:29 step:27688 [D loss: 0.226712, acc.: 63.28%] [G loss: 0.287622]\n",
      "epoch:29 step:27689 [D loss: 0.261317, acc.: 46.88%] [G loss: 0.273154]\n",
      "epoch:29 step:27690 [D loss: 0.222667, acc.: 64.06%] [G loss: 0.338917]\n",
      "epoch:29 step:27691 [D loss: 0.235464, acc.: 60.94%] [G loss: 0.305888]\n",
      "epoch:29 step:27692 [D loss: 0.237397, acc.: 61.72%] [G loss: 0.294967]\n",
      "epoch:29 step:27693 [D loss: 0.241832, acc.: 62.50%] [G loss: 0.297574]\n",
      "epoch:29 step:27694 [D loss: 0.228483, acc.: 66.41%] [G loss: 0.321422]\n",
      "epoch:29 step:27695 [D loss: 0.241274, acc.: 55.47%] [G loss: 0.317547]\n",
      "epoch:29 step:27696 [D loss: 0.234168, acc.: 62.50%] [G loss: 0.280115]\n",
      "epoch:29 step:27697 [D loss: 0.212887, acc.: 68.75%] [G loss: 0.304570]\n",
      "epoch:29 step:27698 [D loss: 0.223789, acc.: 67.19%] [G loss: 0.314474]\n",
      "epoch:29 step:27699 [D loss: 0.239819, acc.: 56.25%] [G loss: 0.295940]\n",
      "epoch:29 step:27700 [D loss: 0.229056, acc.: 57.81%] [G loss: 0.277490]\n",
      "epoch:29 step:27701 [D loss: 0.239895, acc.: 64.06%] [G loss: 0.288819]\n",
      "epoch:29 step:27702 [D loss: 0.245902, acc.: 53.91%] [G loss: 0.307795]\n",
      "epoch:29 step:27703 [D loss: 0.241577, acc.: 53.12%] [G loss: 0.290706]\n",
      "epoch:29 step:27704 [D loss: 0.237186, acc.: 56.25%] [G loss: 0.285597]\n",
      "epoch:29 step:27705 [D loss: 0.239902, acc.: 57.03%] [G loss: 0.278950]\n",
      "epoch:29 step:27706 [D loss: 0.246835, acc.: 57.03%] [G loss: 0.294353]\n",
      "epoch:29 step:27707 [D loss: 0.256126, acc.: 50.00%] [G loss: 0.286022]\n",
      "epoch:29 step:27708 [D loss: 0.236351, acc.: 60.94%] [G loss: 0.303241]\n",
      "epoch:29 step:27709 [D loss: 0.249787, acc.: 50.00%] [G loss: 0.301190]\n",
      "epoch:29 step:27710 [D loss: 0.228790, acc.: 58.59%] [G loss: 0.286564]\n",
      "epoch:29 step:27711 [D loss: 0.246216, acc.: 50.00%] [G loss: 0.285860]\n",
      "epoch:29 step:27712 [D loss: 0.234669, acc.: 57.81%] [G loss: 0.280464]\n",
      "epoch:29 step:27713 [D loss: 0.241582, acc.: 57.81%] [G loss: 0.272994]\n",
      "epoch:29 step:27714 [D loss: 0.217066, acc.: 70.31%] [G loss: 0.295607]\n",
      "epoch:29 step:27715 [D loss: 0.228740, acc.: 58.59%] [G loss: 0.313387]\n",
      "epoch:29 step:27716 [D loss: 0.229590, acc.: 60.16%] [G loss: 0.263121]\n",
      "epoch:29 step:27717 [D loss: 0.247843, acc.: 54.69%] [G loss: 0.290612]\n",
      "epoch:29 step:27718 [D loss: 0.241796, acc.: 57.03%] [G loss: 0.301262]\n",
      "epoch:29 step:27719 [D loss: 0.242759, acc.: 55.47%] [G loss: 0.283243]\n",
      "epoch:29 step:27720 [D loss: 0.247708, acc.: 57.81%] [G loss: 0.266749]\n",
      "epoch:29 step:27721 [D loss: 0.246862, acc.: 52.34%] [G loss: 0.317042]\n",
      "epoch:29 step:27722 [D loss: 0.224681, acc.: 62.50%] [G loss: 0.326169]\n",
      "epoch:29 step:27723 [D loss: 0.235630, acc.: 60.94%] [G loss: 0.318760]\n",
      "epoch:29 step:27724 [D loss: 0.252581, acc.: 53.91%] [G loss: 0.310944]\n",
      "epoch:29 step:27725 [D loss: 0.242740, acc.: 59.38%] [G loss: 0.315259]\n",
      "epoch:29 step:27726 [D loss: 0.254557, acc.: 53.91%] [G loss: 0.295388]\n",
      "epoch:29 step:27727 [D loss: 0.230439, acc.: 67.19%] [G loss: 0.300487]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:29 step:27728 [D loss: 0.248860, acc.: 52.34%] [G loss: 0.291416]\n",
      "epoch:29 step:27729 [D loss: 0.246736, acc.: 53.12%] [G loss: 0.308587]\n",
      "epoch:29 step:27730 [D loss: 0.246337, acc.: 52.34%] [G loss: 0.311971]\n",
      "epoch:29 step:27731 [D loss: 0.253754, acc.: 54.69%] [G loss: 0.284614]\n",
      "epoch:29 step:27732 [D loss: 0.227588, acc.: 66.41%] [G loss: 0.317332]\n",
      "epoch:29 step:27733 [D loss: 0.259398, acc.: 52.34%] [G loss: 0.304399]\n",
      "epoch:29 step:27734 [D loss: 0.258776, acc.: 50.00%] [G loss: 0.279473]\n",
      "epoch:29 step:27735 [D loss: 0.229678, acc.: 64.84%] [G loss: 0.308380]\n",
      "epoch:29 step:27736 [D loss: 0.236584, acc.: 55.47%] [G loss: 0.330344]\n",
      "epoch:29 step:27737 [D loss: 0.234718, acc.: 53.12%] [G loss: 0.295251]\n",
      "epoch:29 step:27738 [D loss: 0.237228, acc.: 60.94%] [G loss: 0.297667]\n",
      "epoch:29 step:27739 [D loss: 0.256924, acc.: 49.22%] [G loss: 0.284459]\n",
      "epoch:29 step:27740 [D loss: 0.231195, acc.: 61.72%] [G loss: 0.304719]\n",
      "epoch:29 step:27741 [D loss: 0.234898, acc.: 61.72%] [G loss: 0.303247]\n",
      "epoch:29 step:27742 [D loss: 0.239459, acc.: 56.25%] [G loss: 0.297017]\n",
      "epoch:29 step:27743 [D loss: 0.247843, acc.: 57.03%] [G loss: 0.277615]\n",
      "epoch:29 step:27744 [D loss: 0.237178, acc.: 55.47%] [G loss: 0.262801]\n",
      "epoch:29 step:27745 [D loss: 0.249792, acc.: 53.91%] [G loss: 0.303013]\n",
      "epoch:29 step:27746 [D loss: 0.240008, acc.: 56.25%] [G loss: 0.293838]\n",
      "epoch:29 step:27747 [D loss: 0.239677, acc.: 61.72%] [G loss: 0.342133]\n",
      "epoch:29 step:27748 [D loss: 0.240275, acc.: 58.59%] [G loss: 0.319599]\n",
      "epoch:29 step:27749 [D loss: 0.225369, acc.: 64.06%] [G loss: 0.297406]\n",
      "epoch:29 step:27750 [D loss: 0.250820, acc.: 57.03%] [G loss: 0.319419]\n",
      "epoch:29 step:27751 [D loss: 0.233905, acc.: 61.72%] [G loss: 0.267758]\n",
      "epoch:29 step:27752 [D loss: 0.222426, acc.: 63.28%] [G loss: 0.323009]\n",
      "epoch:29 step:27753 [D loss: 0.244553, acc.: 53.12%] [G loss: 0.299210]\n",
      "epoch:29 step:27754 [D loss: 0.230710, acc.: 61.72%] [G loss: 0.286872]\n",
      "epoch:29 step:27755 [D loss: 0.229003, acc.: 62.50%] [G loss: 0.311638]\n",
      "epoch:29 step:27756 [D loss: 0.225225, acc.: 68.75%] [G loss: 0.315001]\n",
      "epoch:29 step:27757 [D loss: 0.236016, acc.: 55.47%] [G loss: 0.279813]\n",
      "epoch:29 step:27758 [D loss: 0.238453, acc.: 56.25%] [G loss: 0.291087]\n",
      "epoch:29 step:27759 [D loss: 0.229741, acc.: 60.16%] [G loss: 0.320536]\n",
      "epoch:29 step:27760 [D loss: 0.240883, acc.: 57.03%] [G loss: 0.360033]\n",
      "epoch:29 step:27761 [D loss: 0.243020, acc.: 56.25%] [G loss: 0.318068]\n",
      "epoch:29 step:27762 [D loss: 0.232643, acc.: 59.38%] [G loss: 0.305571]\n",
      "epoch:29 step:27763 [D loss: 0.239327, acc.: 58.59%] [G loss: 0.298755]\n",
      "epoch:29 step:27764 [D loss: 0.245384, acc.: 57.03%] [G loss: 0.294050]\n",
      "epoch:29 step:27765 [D loss: 0.242701, acc.: 61.72%] [G loss: 0.337328]\n",
      "epoch:29 step:27766 [D loss: 0.252274, acc.: 53.91%] [G loss: 0.300230]\n",
      "epoch:29 step:27767 [D loss: 0.239723, acc.: 57.81%] [G loss: 0.292117]\n",
      "epoch:29 step:27768 [D loss: 0.241422, acc.: 56.25%] [G loss: 0.333051]\n",
      "epoch:29 step:27769 [D loss: 0.238346, acc.: 61.72%] [G loss: 0.310781]\n",
      "epoch:29 step:27770 [D loss: 0.229154, acc.: 64.84%] [G loss: 0.315827]\n",
      "epoch:29 step:27771 [D loss: 0.227646, acc.: 60.94%] [G loss: 0.286098]\n",
      "epoch:29 step:27772 [D loss: 0.228606, acc.: 58.59%] [G loss: 0.297770]\n",
      "epoch:29 step:27773 [D loss: 0.226055, acc.: 66.41%] [G loss: 0.311021]\n",
      "epoch:29 step:27774 [D loss: 0.257265, acc.: 51.56%] [G loss: 0.287006]\n",
      "epoch:29 step:27775 [D loss: 0.229531, acc.: 67.19%] [G loss: 0.297066]\n",
      "epoch:29 step:27776 [D loss: 0.236485, acc.: 57.03%] [G loss: 0.299696]\n",
      "epoch:29 step:27777 [D loss: 0.244499, acc.: 55.47%] [G loss: 0.323515]\n",
      "epoch:29 step:27778 [D loss: 0.244332, acc.: 53.12%] [G loss: 0.321604]\n",
      "epoch:29 step:27779 [D loss: 0.238308, acc.: 63.28%] [G loss: 0.302462]\n",
      "epoch:29 step:27780 [D loss: 0.238025, acc.: 60.16%] [G loss: 0.296277]\n",
      "epoch:29 step:27781 [D loss: 0.237533, acc.: 60.94%] [G loss: 0.317203]\n",
      "epoch:29 step:27782 [D loss: 0.256761, acc.: 50.00%] [G loss: 0.283263]\n",
      "epoch:29 step:27783 [D loss: 0.226833, acc.: 68.75%] [G loss: 0.291294]\n",
      "epoch:29 step:27784 [D loss: 0.237357, acc.: 61.72%] [G loss: 0.303051]\n",
      "epoch:29 step:27785 [D loss: 0.230950, acc.: 58.59%] [G loss: 0.295367]\n",
      "epoch:29 step:27786 [D loss: 0.239758, acc.: 51.56%] [G loss: 0.290432]\n",
      "epoch:29 step:27787 [D loss: 0.220888, acc.: 64.06%] [G loss: 0.319091]\n",
      "epoch:29 step:27788 [D loss: 0.226270, acc.: 60.16%] [G loss: 0.325426]\n",
      "epoch:29 step:27789 [D loss: 0.240514, acc.: 58.59%] [G loss: 0.292994]\n",
      "epoch:29 step:27790 [D loss: 0.247437, acc.: 59.38%] [G loss: 0.298591]\n",
      "epoch:29 step:27791 [D loss: 0.244172, acc.: 52.34%] [G loss: 0.303530]\n",
      "epoch:29 step:27792 [D loss: 0.235249, acc.: 57.81%] [G loss: 0.314936]\n",
      "epoch:29 step:27793 [D loss: 0.252482, acc.: 48.44%] [G loss: 0.289917]\n",
      "epoch:29 step:27794 [D loss: 0.248721, acc.: 53.91%] [G loss: 0.291560]\n",
      "epoch:29 step:27795 [D loss: 0.244657, acc.: 57.03%] [G loss: 0.360270]\n",
      "epoch:29 step:27796 [D loss: 0.242133, acc.: 56.25%] [G loss: 0.281378]\n",
      "epoch:29 step:27797 [D loss: 0.252158, acc.: 50.78%] [G loss: 0.294145]\n",
      "epoch:29 step:27798 [D loss: 0.258280, acc.: 50.00%] [G loss: 0.308503]\n",
      "epoch:29 step:27799 [D loss: 0.238402, acc.: 63.28%] [G loss: 0.301521]\n",
      "epoch:29 step:27800 [D loss: 0.246077, acc.: 55.47%] [G loss: 0.310169]\n",
      "epoch:29 step:27801 [D loss: 0.242801, acc.: 57.81%] [G loss: 0.304132]\n",
      "epoch:29 step:27802 [D loss: 0.245193, acc.: 56.25%] [G loss: 0.291410]\n",
      "epoch:29 step:27803 [D loss: 0.245337, acc.: 60.94%] [G loss: 0.275922]\n",
      "epoch:29 step:27804 [D loss: 0.228919, acc.: 63.28%] [G loss: 0.310569]\n",
      "epoch:29 step:27805 [D loss: 0.243613, acc.: 60.94%] [G loss: 0.290461]\n",
      "epoch:29 step:27806 [D loss: 0.239994, acc.: 57.81%] [G loss: 0.310709]\n",
      "epoch:29 step:27807 [D loss: 0.235563, acc.: 57.03%] [G loss: 0.265870]\n",
      "epoch:29 step:27808 [D loss: 0.215003, acc.: 67.97%] [G loss: 0.309110]\n",
      "epoch:29 step:27809 [D loss: 0.265582, acc.: 50.78%] [G loss: 0.300234]\n",
      "epoch:29 step:27810 [D loss: 0.239052, acc.: 58.59%] [G loss: 0.307248]\n",
      "epoch:29 step:27811 [D loss: 0.251714, acc.: 55.47%] [G loss: 0.295320]\n",
      "epoch:29 step:27812 [D loss: 0.235703, acc.: 59.38%] [G loss: 0.295834]\n",
      "epoch:29 step:27813 [D loss: 0.237527, acc.: 59.38%] [G loss: 0.309396]\n",
      "epoch:29 step:27814 [D loss: 0.236636, acc.: 57.81%] [G loss: 0.309303]\n",
      "epoch:29 step:27815 [D loss: 0.239901, acc.: 57.81%] [G loss: 0.292199]\n",
      "epoch:29 step:27816 [D loss: 0.267713, acc.: 49.22%] [G loss: 0.301192]\n",
      "epoch:29 step:27817 [D loss: 0.255958, acc.: 54.69%] [G loss: 0.299544]\n",
      "epoch:29 step:27818 [D loss: 0.230478, acc.: 64.84%] [G loss: 0.289623]\n",
      "epoch:29 step:27819 [D loss: 0.261976, acc.: 46.88%] [G loss: 0.290448]\n",
      "epoch:29 step:27820 [D loss: 0.245042, acc.: 60.16%] [G loss: 0.288326]\n",
      "epoch:29 step:27821 [D loss: 0.222694, acc.: 64.06%] [G loss: 0.303141]\n",
      "epoch:29 step:27822 [D loss: 0.233311, acc.: 61.72%] [G loss: 0.319562]\n",
      "epoch:29 step:27823 [D loss: 0.239907, acc.: 56.25%] [G loss: 0.304563]\n",
      "epoch:29 step:27824 [D loss: 0.237136, acc.: 57.81%] [G loss: 0.294709]\n",
      "epoch:29 step:27825 [D loss: 0.236898, acc.: 56.25%] [G loss: 0.325557]\n",
      "epoch:29 step:27826 [D loss: 0.234317, acc.: 59.38%] [G loss: 0.287289]\n",
      "epoch:29 step:27827 [D loss: 0.246428, acc.: 53.12%] [G loss: 0.274334]\n",
      "epoch:29 step:27828 [D loss: 0.247383, acc.: 57.03%] [G loss: 0.293624]\n",
      "epoch:29 step:27829 [D loss: 0.254023, acc.: 54.69%] [G loss: 0.309870]\n",
      "epoch:29 step:27830 [D loss: 0.227701, acc.: 64.06%] [G loss: 0.308528]\n",
      "epoch:29 step:27831 [D loss: 0.246123, acc.: 50.78%] [G loss: 0.276045]\n",
      "epoch:29 step:27832 [D loss: 0.232961, acc.: 60.16%] [G loss: 0.319216]\n",
      "epoch:29 step:27833 [D loss: 0.253263, acc.: 53.91%] [G loss: 0.304773]\n",
      "epoch:29 step:27834 [D loss: 0.234096, acc.: 60.94%] [G loss: 0.292313]\n",
      "epoch:29 step:27835 [D loss: 0.240473, acc.: 59.38%] [G loss: 0.291254]\n",
      "epoch:29 step:27836 [D loss: 0.251272, acc.: 55.47%] [G loss: 0.302520]\n",
      "epoch:29 step:27837 [D loss: 0.229201, acc.: 61.72%] [G loss: 0.302762]\n",
      "epoch:29 step:27838 [D loss: 0.245254, acc.: 59.38%] [G loss: 0.298092]\n",
      "epoch:29 step:27839 [D loss: 0.213878, acc.: 66.41%] [G loss: 0.314197]\n",
      "epoch:29 step:27840 [D loss: 0.234542, acc.: 60.16%] [G loss: 0.270815]\n",
      "epoch:29 step:27841 [D loss: 0.251899, acc.: 51.56%] [G loss: 0.278451]\n",
      "epoch:29 step:27842 [D loss: 0.241429, acc.: 60.16%] [G loss: 0.280672]\n",
      "epoch:29 step:27843 [D loss: 0.228423, acc.: 63.28%] [G loss: 0.295463]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:29 step:27844 [D loss: 0.254037, acc.: 57.03%] [G loss: 0.272160]\n",
      "epoch:29 step:27845 [D loss: 0.232758, acc.: 61.72%] [G loss: 0.315437]\n",
      "epoch:29 step:27846 [D loss: 0.262062, acc.: 52.34%] [G loss: 0.288914]\n",
      "epoch:29 step:27847 [D loss: 0.216369, acc.: 67.19%] [G loss: 0.283871]\n",
      "epoch:29 step:27848 [D loss: 0.244513, acc.: 58.59%] [G loss: 0.280490]\n",
      "epoch:29 step:27849 [D loss: 0.224546, acc.: 60.94%] [G loss: 0.303668]\n",
      "epoch:29 step:27850 [D loss: 0.241524, acc.: 59.38%] [G loss: 0.302371]\n",
      "epoch:29 step:27851 [D loss: 0.257502, acc.: 51.56%] [G loss: 0.281279]\n",
      "epoch:29 step:27852 [D loss: 0.238511, acc.: 55.47%] [G loss: 0.319071]\n",
      "epoch:29 step:27853 [D loss: 0.264003, acc.: 53.91%] [G loss: 0.285870]\n",
      "epoch:29 step:27854 [D loss: 0.256095, acc.: 49.22%] [G loss: 0.286427]\n",
      "epoch:29 step:27855 [D loss: 0.230689, acc.: 64.84%] [G loss: 0.297078]\n",
      "epoch:29 step:27856 [D loss: 0.232676, acc.: 60.94%] [G loss: 0.303495]\n",
      "epoch:29 step:27857 [D loss: 0.244874, acc.: 58.59%] [G loss: 0.301096]\n",
      "epoch:29 step:27858 [D loss: 0.220377, acc.: 68.75%] [G loss: 0.316429]\n",
      "epoch:29 step:27859 [D loss: 0.254347, acc.: 49.22%] [G loss: 0.297163]\n",
      "epoch:29 step:27860 [D loss: 0.246613, acc.: 55.47%] [G loss: 0.302928]\n",
      "epoch:29 step:27861 [D loss: 0.230254, acc.: 64.84%] [G loss: 0.305810]\n",
      "epoch:29 step:27862 [D loss: 0.263663, acc.: 45.31%] [G loss: 0.305639]\n",
      "epoch:29 step:27863 [D loss: 0.240557, acc.: 59.38%] [G loss: 0.308884]\n",
      "epoch:29 step:27864 [D loss: 0.246979, acc.: 57.03%] [G loss: 0.298812]\n",
      "epoch:29 step:27865 [D loss: 0.229434, acc.: 64.06%] [G loss: 0.299618]\n",
      "epoch:29 step:27866 [D loss: 0.231209, acc.: 57.81%] [G loss: 0.300715]\n",
      "epoch:29 step:27867 [D loss: 0.235955, acc.: 56.25%] [G loss: 0.309772]\n",
      "epoch:29 step:27868 [D loss: 0.235339, acc.: 59.38%] [G loss: 0.302174]\n",
      "epoch:29 step:27869 [D loss: 0.228190, acc.: 63.28%] [G loss: 0.302341]\n",
      "epoch:29 step:27870 [D loss: 0.229011, acc.: 61.72%] [G loss: 0.306153]\n",
      "epoch:29 step:27871 [D loss: 0.241104, acc.: 58.59%] [G loss: 0.293550]\n",
      "epoch:29 step:27872 [D loss: 0.236370, acc.: 61.72%] [G loss: 0.335771]\n",
      "epoch:29 step:27873 [D loss: 0.227347, acc.: 64.84%] [G loss: 0.301096]\n",
      "epoch:29 step:27874 [D loss: 0.246430, acc.: 53.91%] [G loss: 0.324262]\n",
      "epoch:29 step:27875 [D loss: 0.214941, acc.: 70.31%] [G loss: 0.313799]\n",
      "epoch:29 step:27876 [D loss: 0.236713, acc.: 57.03%] [G loss: 0.319320]\n",
      "epoch:29 step:27877 [D loss: 0.243003, acc.: 59.38%] [G loss: 0.295172]\n",
      "epoch:29 step:27878 [D loss: 0.233785, acc.: 57.81%] [G loss: 0.316452]\n",
      "epoch:29 step:27879 [D loss: 0.233673, acc.: 60.94%] [G loss: 0.316941]\n",
      "epoch:29 step:27880 [D loss: 0.251121, acc.: 50.78%] [G loss: 0.296799]\n",
      "epoch:29 step:27881 [D loss: 0.240975, acc.: 60.94%] [G loss: 0.269744]\n",
      "epoch:29 step:27882 [D loss: 0.257145, acc.: 50.78%] [G loss: 0.304113]\n",
      "epoch:29 step:27883 [D loss: 0.255711, acc.: 52.34%] [G loss: 0.295039]\n",
      "epoch:29 step:27884 [D loss: 0.233372, acc.: 64.06%] [G loss: 0.302819]\n",
      "epoch:29 step:27885 [D loss: 0.242180, acc.: 58.59%] [G loss: 0.312460]\n",
      "epoch:29 step:27886 [D loss: 0.240405, acc.: 55.47%] [G loss: 0.301213]\n",
      "epoch:29 step:27887 [D loss: 0.260487, acc.: 51.56%] [G loss: 0.279704]\n",
      "epoch:29 step:27888 [D loss: 0.249905, acc.: 59.38%] [G loss: 0.282495]\n",
      "epoch:29 step:27889 [D loss: 0.229089, acc.: 62.50%] [G loss: 0.267226]\n",
      "epoch:29 step:27890 [D loss: 0.232411, acc.: 57.81%] [G loss: 0.331567]\n",
      "epoch:29 step:27891 [D loss: 0.207561, acc.: 69.53%] [G loss: 0.313200]\n",
      "epoch:29 step:27892 [D loss: 0.244947, acc.: 57.03%] [G loss: 0.296512]\n",
      "epoch:29 step:27893 [D loss: 0.268002, acc.: 50.00%] [G loss: 0.292670]\n",
      "epoch:29 step:27894 [D loss: 0.238133, acc.: 60.94%] [G loss: 0.333811]\n",
      "epoch:29 step:27895 [D loss: 0.255714, acc.: 54.69%] [G loss: 0.303116]\n",
      "epoch:29 step:27896 [D loss: 0.244770, acc.: 60.94%] [G loss: 0.287657]\n",
      "epoch:29 step:27897 [D loss: 0.227460, acc.: 62.50%] [G loss: 0.279490]\n",
      "epoch:29 step:27898 [D loss: 0.233771, acc.: 63.28%] [G loss: 0.265835]\n",
      "epoch:29 step:27899 [D loss: 0.239619, acc.: 61.72%] [G loss: 0.301939]\n",
      "epoch:29 step:27900 [D loss: 0.241081, acc.: 51.56%] [G loss: 0.305727]\n",
      "epoch:29 step:27901 [D loss: 0.240742, acc.: 56.25%] [G loss: 0.313144]\n",
      "epoch:29 step:27902 [D loss: 0.233682, acc.: 65.62%] [G loss: 0.296203]\n",
      "epoch:29 step:27903 [D loss: 0.233768, acc.: 60.94%] [G loss: 0.320716]\n",
      "epoch:29 step:27904 [D loss: 0.241502, acc.: 56.25%] [G loss: 0.314324]\n",
      "epoch:29 step:27905 [D loss: 0.267104, acc.: 47.66%] [G loss: 0.290498]\n",
      "epoch:29 step:27906 [D loss: 0.234558, acc.: 58.59%] [G loss: 0.333184]\n",
      "epoch:29 step:27907 [D loss: 0.223550, acc.: 59.38%] [G loss: 0.278578]\n",
      "epoch:29 step:27908 [D loss: 0.260094, acc.: 46.09%] [G loss: 0.281851]\n",
      "epoch:29 step:27909 [D loss: 0.231731, acc.: 58.59%] [G loss: 0.305063]\n",
      "epoch:29 step:27910 [D loss: 0.231989, acc.: 63.28%] [G loss: 0.299924]\n",
      "epoch:29 step:27911 [D loss: 0.245162, acc.: 53.91%] [G loss: 0.283086]\n",
      "epoch:29 step:27912 [D loss: 0.258483, acc.: 48.44%] [G loss: 0.296352]\n",
      "epoch:29 step:27913 [D loss: 0.249322, acc.: 62.50%] [G loss: 0.306886]\n",
      "epoch:29 step:27914 [D loss: 0.242355, acc.: 56.25%] [G loss: 0.280155]\n",
      "epoch:29 step:27915 [D loss: 0.247387, acc.: 57.81%] [G loss: 0.302548]\n",
      "epoch:29 step:27916 [D loss: 0.248841, acc.: 60.94%] [G loss: 0.284915]\n",
      "epoch:29 step:27917 [D loss: 0.232354, acc.: 62.50%] [G loss: 0.291282]\n",
      "epoch:29 step:27918 [D loss: 0.247732, acc.: 53.91%] [G loss: 0.304083]\n",
      "epoch:29 step:27919 [D loss: 0.235758, acc.: 60.16%] [G loss: 0.290428]\n",
      "epoch:29 step:27920 [D loss: 0.249093, acc.: 52.34%] [G loss: 0.335859]\n",
      "epoch:29 step:27921 [D loss: 0.232314, acc.: 60.94%] [G loss: 0.324636]\n",
      "epoch:29 step:27922 [D loss: 0.235342, acc.: 55.47%] [G loss: 0.314637]\n",
      "epoch:29 step:27923 [D loss: 0.245455, acc.: 62.50%] [G loss: 0.276776]\n",
      "epoch:29 step:27924 [D loss: 0.232311, acc.: 64.06%] [G loss: 0.326898]\n",
      "epoch:29 step:27925 [D loss: 0.245738, acc.: 57.81%] [G loss: 0.321684]\n",
      "epoch:29 step:27926 [D loss: 0.237731, acc.: 52.34%] [G loss: 0.286496]\n",
      "epoch:29 step:27927 [D loss: 0.214930, acc.: 65.62%] [G loss: 0.300371]\n",
      "epoch:29 step:27928 [D loss: 0.239116, acc.: 57.81%] [G loss: 0.331756]\n",
      "epoch:29 step:27929 [D loss: 0.242654, acc.: 55.47%] [G loss: 0.311131]\n",
      "epoch:29 step:27930 [D loss: 0.253774, acc.: 54.69%] [G loss: 0.284745]\n",
      "epoch:29 step:27931 [D loss: 0.249255, acc.: 52.34%] [G loss: 0.309184]\n",
      "epoch:29 step:27932 [D loss: 0.232159, acc.: 59.38%] [G loss: 0.312096]\n",
      "epoch:29 step:27933 [D loss: 0.230501, acc.: 57.03%] [G loss: 0.326330]\n",
      "epoch:29 step:27934 [D loss: 0.259724, acc.: 50.00%] [G loss: 0.289303]\n",
      "epoch:29 step:27935 [D loss: 0.236790, acc.: 60.16%] [G loss: 0.291677]\n",
      "epoch:29 step:27936 [D loss: 0.237388, acc.: 57.03%] [G loss: 0.298556]\n",
      "epoch:29 step:27937 [D loss: 0.241849, acc.: 55.47%] [G loss: 0.314995]\n",
      "epoch:29 step:27938 [D loss: 0.243458, acc.: 58.59%] [G loss: 0.305266]\n",
      "epoch:29 step:27939 [D loss: 0.232214, acc.: 58.59%] [G loss: 0.275033]\n",
      "epoch:29 step:27940 [D loss: 0.248281, acc.: 59.38%] [G loss: 0.317563]\n",
      "epoch:29 step:27941 [D loss: 0.228486, acc.: 66.41%] [G loss: 0.326139]\n",
      "epoch:29 step:27942 [D loss: 0.221902, acc.: 67.19%] [G loss: 0.311395]\n",
      "epoch:29 step:27943 [D loss: 0.252201, acc.: 54.69%] [G loss: 0.307141]\n",
      "epoch:29 step:27944 [D loss: 0.252650, acc.: 56.25%] [G loss: 0.292919]\n",
      "epoch:29 step:27945 [D loss: 0.246413, acc.: 50.00%] [G loss: 0.290117]\n",
      "epoch:29 step:27946 [D loss: 0.253326, acc.: 53.12%] [G loss: 0.312047]\n",
      "epoch:29 step:27947 [D loss: 0.235861, acc.: 58.59%] [G loss: 0.303329]\n",
      "epoch:29 step:27948 [D loss: 0.232094, acc.: 63.28%] [G loss: 0.308629]\n",
      "epoch:29 step:27949 [D loss: 0.232185, acc.: 64.06%] [G loss: 0.311700]\n",
      "epoch:29 step:27950 [D loss: 0.247527, acc.: 55.47%] [G loss: 0.304178]\n",
      "epoch:29 step:27951 [D loss: 0.237027, acc.: 59.38%] [G loss: 0.310944]\n",
      "epoch:29 step:27952 [D loss: 0.237728, acc.: 55.47%] [G loss: 0.312304]\n",
      "epoch:29 step:27953 [D loss: 0.254465, acc.: 54.69%] [G loss: 0.295600]\n",
      "epoch:29 step:27954 [D loss: 0.248473, acc.: 54.69%] [G loss: 0.273485]\n",
      "epoch:29 step:27955 [D loss: 0.254941, acc.: 52.34%] [G loss: 0.277316]\n",
      "epoch:29 step:27956 [D loss: 0.248097, acc.: 53.91%] [G loss: 0.284718]\n",
      "epoch:29 step:27957 [D loss: 0.228514, acc.: 63.28%] [G loss: 0.318567]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:29 step:27958 [D loss: 0.236608, acc.: 60.16%] [G loss: 0.297376]\n",
      "epoch:29 step:27959 [D loss: 0.256101, acc.: 47.66%] [G loss: 0.326319]\n",
      "epoch:29 step:27960 [D loss: 0.242134, acc.: 58.59%] [G loss: 0.292994]\n",
      "epoch:29 step:27961 [D loss: 0.218967, acc.: 67.19%] [G loss: 0.317870]\n",
      "epoch:29 step:27962 [D loss: 0.243834, acc.: 55.47%] [G loss: 0.295037]\n",
      "epoch:29 step:27963 [D loss: 0.233329, acc.: 60.16%] [G loss: 0.319277]\n",
      "epoch:29 step:27964 [D loss: 0.234817, acc.: 65.62%] [G loss: 0.269106]\n",
      "epoch:29 step:27965 [D loss: 0.228295, acc.: 60.94%] [G loss: 0.290270]\n",
      "epoch:29 step:27966 [D loss: 0.220361, acc.: 70.31%] [G loss: 0.307096]\n",
      "epoch:29 step:27967 [D loss: 0.228037, acc.: 60.94%] [G loss: 0.270761]\n",
      "epoch:29 step:27968 [D loss: 0.246017, acc.: 54.69%] [G loss: 0.280902]\n",
      "epoch:29 step:27969 [D loss: 0.234121, acc.: 64.06%] [G loss: 0.311308]\n",
      "epoch:29 step:27970 [D loss: 0.247857, acc.: 53.91%] [G loss: 0.286980]\n",
      "epoch:29 step:27971 [D loss: 0.229503, acc.: 60.94%] [G loss: 0.309144]\n",
      "epoch:29 step:27972 [D loss: 0.246143, acc.: 54.69%] [G loss: 0.309981]\n",
      "epoch:29 step:27973 [D loss: 0.231306, acc.: 61.72%] [G loss: 0.280747]\n",
      "epoch:29 step:27974 [D loss: 0.233664, acc.: 64.84%] [G loss: 0.285291]\n",
      "epoch:29 step:27975 [D loss: 0.261517, acc.: 47.66%] [G loss: 0.285446]\n",
      "epoch:29 step:27976 [D loss: 0.243583, acc.: 55.47%] [G loss: 0.314805]\n",
      "epoch:29 step:27977 [D loss: 0.252478, acc.: 52.34%] [G loss: 0.285548]\n",
      "epoch:29 step:27978 [D loss: 0.228648, acc.: 63.28%] [G loss: 0.278930]\n",
      "epoch:29 step:27979 [D loss: 0.239800, acc.: 57.03%] [G loss: 0.308131]\n",
      "epoch:29 step:27980 [D loss: 0.258673, acc.: 50.00%] [G loss: 0.312424]\n",
      "epoch:29 step:27981 [D loss: 0.231146, acc.: 60.16%] [G loss: 0.316780]\n",
      "epoch:29 step:27982 [D loss: 0.248116, acc.: 50.00%] [G loss: 0.288721]\n",
      "epoch:29 step:27983 [D loss: 0.226986, acc.: 60.94%] [G loss: 0.311466]\n",
      "epoch:29 step:27984 [D loss: 0.248760, acc.: 57.03%] [G loss: 0.268442]\n",
      "epoch:29 step:27985 [D loss: 0.227753, acc.: 61.72%] [G loss: 0.291234]\n",
      "epoch:29 step:27986 [D loss: 0.248377, acc.: 52.34%] [G loss: 0.291927]\n",
      "epoch:29 step:27987 [D loss: 0.253475, acc.: 53.12%] [G loss: 0.326830]\n",
      "epoch:29 step:27988 [D loss: 0.248478, acc.: 53.91%] [G loss: 0.302559]\n",
      "epoch:29 step:27989 [D loss: 0.242760, acc.: 58.59%] [G loss: 0.247030]\n",
      "epoch:29 step:27990 [D loss: 0.232996, acc.: 64.06%] [G loss: 0.313098]\n",
      "epoch:29 step:27991 [D loss: 0.249649, acc.: 56.25%] [G loss: 0.289233]\n",
      "epoch:29 step:27992 [D loss: 0.258799, acc.: 53.91%] [G loss: 0.287234]\n",
      "epoch:29 step:27993 [D loss: 0.235545, acc.: 59.38%] [G loss: 0.296897]\n",
      "epoch:29 step:27994 [D loss: 0.247955, acc.: 55.47%] [G loss: 0.301738]\n",
      "epoch:29 step:27995 [D loss: 0.218123, acc.: 62.50%] [G loss: 0.275878]\n",
      "epoch:29 step:27996 [D loss: 0.262963, acc.: 51.56%] [G loss: 0.281155]\n",
      "epoch:29 step:27997 [D loss: 0.244894, acc.: 52.34%] [G loss: 0.314783]\n",
      "epoch:29 step:27998 [D loss: 0.236762, acc.: 60.16%] [G loss: 0.280663]\n",
      "epoch:29 step:27999 [D loss: 0.236362, acc.: 60.94%] [G loss: 0.293003]\n",
      "epoch:29 step:28000 [D loss: 0.233813, acc.: 63.28%] [G loss: 0.287935]\n",
      "epoch:29 step:28001 [D loss: 0.258586, acc.: 53.91%] [G loss: 0.307148]\n",
      "epoch:29 step:28002 [D loss: 0.229639, acc.: 62.50%] [G loss: 0.308351]\n",
      "epoch:29 step:28003 [D loss: 0.237785, acc.: 60.94%] [G loss: 0.290546]\n",
      "epoch:29 step:28004 [D loss: 0.231098, acc.: 57.03%] [G loss: 0.332426]\n",
      "epoch:29 step:28005 [D loss: 0.244633, acc.: 53.12%] [G loss: 0.314674]\n",
      "epoch:29 step:28006 [D loss: 0.239296, acc.: 63.28%] [G loss: 0.288248]\n",
      "epoch:29 step:28007 [D loss: 0.246125, acc.: 53.12%] [G loss: 0.319116]\n",
      "epoch:29 step:28008 [D loss: 0.241349, acc.: 60.16%] [G loss: 0.322639]\n",
      "epoch:29 step:28009 [D loss: 0.245465, acc.: 53.91%] [G loss: 0.310018]\n",
      "epoch:29 step:28010 [D loss: 0.250188, acc.: 53.12%] [G loss: 0.299828]\n",
      "epoch:29 step:28011 [D loss: 0.245306, acc.: 58.59%] [G loss: 0.289075]\n",
      "epoch:29 step:28012 [D loss: 0.219991, acc.: 65.62%] [G loss: 0.298258]\n",
      "epoch:29 step:28013 [D loss: 0.255493, acc.: 50.00%] [G loss: 0.319718]\n",
      "epoch:29 step:28014 [D loss: 0.257126, acc.: 50.78%] [G loss: 0.286607]\n",
      "epoch:29 step:28015 [D loss: 0.248667, acc.: 56.25%] [G loss: 0.286482]\n",
      "epoch:29 step:28016 [D loss: 0.251187, acc.: 50.00%] [G loss: 0.269465]\n",
      "epoch:29 step:28017 [D loss: 0.256813, acc.: 50.78%] [G loss: 0.321182]\n",
      "epoch:29 step:28018 [D loss: 0.241868, acc.: 56.25%] [G loss: 0.286355]\n",
      "epoch:29 step:28019 [D loss: 0.245574, acc.: 57.81%] [G loss: 0.302818]\n",
      "epoch:29 step:28020 [D loss: 0.227008, acc.: 67.19%] [G loss: 0.268676]\n",
      "epoch:29 step:28021 [D loss: 0.220748, acc.: 71.09%] [G loss: 0.276384]\n",
      "epoch:29 step:28022 [D loss: 0.243450, acc.: 57.81%] [G loss: 0.281791]\n",
      "epoch:29 step:28023 [D loss: 0.241677, acc.: 56.25%] [G loss: 0.310912]\n",
      "epoch:29 step:28024 [D loss: 0.259552, acc.: 50.00%] [G loss: 0.303334]\n",
      "epoch:29 step:28025 [D loss: 0.226434, acc.: 61.72%] [G loss: 0.324442]\n",
      "epoch:29 step:28026 [D loss: 0.243855, acc.: 55.47%] [G loss: 0.305487]\n",
      "epoch:29 step:28027 [D loss: 0.233605, acc.: 60.16%] [G loss: 0.291709]\n",
      "epoch:29 step:28028 [D loss: 0.250585, acc.: 53.91%] [G loss: 0.293510]\n",
      "epoch:29 step:28029 [D loss: 0.231973, acc.: 63.28%] [G loss: 0.314010]\n",
      "epoch:29 step:28030 [D loss: 0.248618, acc.: 50.78%] [G loss: 0.297333]\n",
      "epoch:29 step:28031 [D loss: 0.243762, acc.: 60.94%] [G loss: 0.293182]\n",
      "epoch:29 step:28032 [D loss: 0.234762, acc.: 61.72%] [G loss: 0.319077]\n",
      "epoch:29 step:28033 [D loss: 0.228677, acc.: 60.94%] [G loss: 0.302061]\n",
      "epoch:29 step:28034 [D loss: 0.238053, acc.: 57.03%] [G loss: 0.329250]\n",
      "epoch:29 step:28035 [D loss: 0.246508, acc.: 53.91%] [G loss: 0.320796]\n",
      "epoch:29 step:28036 [D loss: 0.243328, acc.: 53.12%] [G loss: 0.310573]\n",
      "epoch:29 step:28037 [D loss: 0.251426, acc.: 51.56%] [G loss: 0.285718]\n",
      "epoch:29 step:28038 [D loss: 0.241348, acc.: 57.81%] [G loss: 0.298471]\n",
      "epoch:29 step:28039 [D loss: 0.241203, acc.: 48.44%] [G loss: 0.315404]\n",
      "epoch:29 step:28040 [D loss: 0.243084, acc.: 52.34%] [G loss: 0.321099]\n",
      "epoch:29 step:28041 [D loss: 0.215187, acc.: 71.09%] [G loss: 0.311849]\n",
      "epoch:29 step:28042 [D loss: 0.231314, acc.: 62.50%] [G loss: 0.323595]\n",
      "epoch:29 step:28043 [D loss: 0.247194, acc.: 54.69%] [G loss: 0.325524]\n",
      "epoch:29 step:28044 [D loss: 0.231147, acc.: 58.59%] [G loss: 0.328445]\n",
      "epoch:29 step:28045 [D loss: 0.255436, acc.: 52.34%] [G loss: 0.311353]\n",
      "epoch:29 step:28046 [D loss: 0.231925, acc.: 57.81%] [G loss: 0.283797]\n",
      "epoch:29 step:28047 [D loss: 0.244796, acc.: 57.81%] [G loss: 0.294686]\n",
      "epoch:29 step:28048 [D loss: 0.227990, acc.: 64.84%] [G loss: 0.286604]\n",
      "epoch:29 step:28049 [D loss: 0.237920, acc.: 61.72%] [G loss: 0.303975]\n",
      "epoch:29 step:28050 [D loss: 0.232127, acc.: 60.16%] [G loss: 0.320678]\n",
      "epoch:29 step:28051 [D loss: 0.249151, acc.: 51.56%] [G loss: 0.300785]\n",
      "epoch:29 step:28052 [D loss: 0.243126, acc.: 60.16%] [G loss: 0.287238]\n",
      "epoch:29 step:28053 [D loss: 0.247181, acc.: 56.25%] [G loss: 0.327850]\n",
      "epoch:29 step:28054 [D loss: 0.222988, acc.: 64.06%] [G loss: 0.321001]\n",
      "epoch:29 step:28055 [D loss: 0.227333, acc.: 62.50%] [G loss: 0.292366]\n",
      "epoch:29 step:28056 [D loss: 0.236685, acc.: 59.38%] [G loss: 0.334283]\n",
      "epoch:29 step:28057 [D loss: 0.227034, acc.: 58.59%] [G loss: 0.318779]\n",
      "epoch:29 step:28058 [D loss: 0.238556, acc.: 57.03%] [G loss: 0.282628]\n",
      "epoch:29 step:28059 [D loss: 0.218243, acc.: 64.84%] [G loss: 0.320036]\n",
      "epoch:29 step:28060 [D loss: 0.228202, acc.: 60.16%] [G loss: 0.291935]\n",
      "epoch:29 step:28061 [D loss: 0.243421, acc.: 55.47%] [G loss: 0.296643]\n",
      "epoch:29 step:28062 [D loss: 0.247134, acc.: 53.91%] [G loss: 0.321198]\n",
      "epoch:29 step:28063 [D loss: 0.238136, acc.: 60.16%] [G loss: 0.312114]\n",
      "epoch:29 step:28064 [D loss: 0.236418, acc.: 57.81%] [G loss: 0.270406]\n",
      "epoch:29 step:28065 [D loss: 0.238812, acc.: 56.25%] [G loss: 0.285746]\n",
      "epoch:29 step:28066 [D loss: 0.240390, acc.: 55.47%] [G loss: 0.321652]\n",
      "epoch:29 step:28067 [D loss: 0.236789, acc.: 61.72%] [G loss: 0.314785]\n",
      "epoch:29 step:28068 [D loss: 0.245146, acc.: 54.69%] [G loss: 0.305765]\n",
      "epoch:29 step:28069 [D loss: 0.247448, acc.: 57.81%] [G loss: 0.302124]\n",
      "epoch:29 step:28070 [D loss: 0.259128, acc.: 46.09%] [G loss: 0.290176]\n",
      "epoch:29 step:28071 [D loss: 0.235615, acc.: 61.72%] [G loss: 0.303316]\n",
      "epoch:29 step:28072 [D loss: 0.239310, acc.: 59.38%] [G loss: 0.311538]\n",
      "epoch:29 step:28073 [D loss: 0.238259, acc.: 57.03%] [G loss: 0.314450]\n",
      "epoch:29 step:28074 [D loss: 0.238178, acc.: 60.94%] [G loss: 0.291935]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:29 step:28075 [D loss: 0.240728, acc.: 56.25%] [G loss: 0.296979]\n",
      "epoch:29 step:28076 [D loss: 0.219959, acc.: 61.72%] [G loss: 0.303307]\n",
      "epoch:29 step:28077 [D loss: 0.235550, acc.: 57.03%] [G loss: 0.295460]\n",
      "epoch:29 step:28078 [D loss: 0.236826, acc.: 53.91%] [G loss: 0.312813]\n",
      "epoch:29 step:28079 [D loss: 0.233449, acc.: 59.38%] [G loss: 0.315479]\n",
      "epoch:29 step:28080 [D loss: 0.257266, acc.: 44.53%] [G loss: 0.342355]\n",
      "epoch:29 step:28081 [D loss: 0.251608, acc.: 53.12%] [G loss: 0.289008]\n",
      "epoch:29 step:28082 [D loss: 0.238285, acc.: 61.72%] [G loss: 0.279425]\n",
      "epoch:29 step:28083 [D loss: 0.245371, acc.: 55.47%] [G loss: 0.288582]\n",
      "epoch:29 step:28084 [D loss: 0.234167, acc.: 60.94%] [G loss: 0.303122]\n",
      "epoch:29 step:28085 [D loss: 0.255069, acc.: 52.34%] [G loss: 0.296591]\n",
      "epoch:29 step:28086 [D loss: 0.226119, acc.: 63.28%] [G loss: 0.281657]\n",
      "epoch:29 step:28087 [D loss: 0.220553, acc.: 65.62%] [G loss: 0.302427]\n",
      "epoch:29 step:28088 [D loss: 0.240813, acc.: 62.50%] [G loss: 0.277560]\n",
      "epoch:29 step:28089 [D loss: 0.231937, acc.: 60.94%] [G loss: 0.306335]\n",
      "epoch:29 step:28090 [D loss: 0.239292, acc.: 62.50%] [G loss: 0.309328]\n",
      "epoch:29 step:28091 [D loss: 0.229604, acc.: 62.50%] [G loss: 0.317215]\n",
      "epoch:29 step:28092 [D loss: 0.242370, acc.: 58.59%] [G loss: 0.301569]\n",
      "epoch:29 step:28093 [D loss: 0.251488, acc.: 55.47%] [G loss: 0.290113]\n",
      "epoch:29 step:28094 [D loss: 0.243796, acc.: 55.47%] [G loss: 0.299334]\n",
      "epoch:29 step:28095 [D loss: 0.226680, acc.: 59.38%] [G loss: 0.300457]\n",
      "epoch:29 step:28096 [D loss: 0.274258, acc.: 44.53%] [G loss: 0.304135]\n",
      "epoch:29 step:28097 [D loss: 0.242928, acc.: 60.94%] [G loss: 0.315207]\n",
      "epoch:29 step:28098 [D loss: 0.251824, acc.: 53.12%] [G loss: 0.315326]\n",
      "epoch:29 step:28099 [D loss: 0.249505, acc.: 52.34%] [G loss: 0.310896]\n",
      "epoch:29 step:28100 [D loss: 0.230995, acc.: 64.06%] [G loss: 0.296970]\n",
      "epoch:29 step:28101 [D loss: 0.244438, acc.: 58.59%] [G loss: 0.276969]\n",
      "epoch:29 step:28102 [D loss: 0.234812, acc.: 60.94%] [G loss: 0.287793]\n",
      "epoch:29 step:28103 [D loss: 0.237328, acc.: 56.25%] [G loss: 0.301441]\n",
      "epoch:29 step:28104 [D loss: 0.234915, acc.: 57.81%] [G loss: 0.300270]\n",
      "epoch:29 step:28105 [D loss: 0.243805, acc.: 57.81%] [G loss: 0.278528]\n",
      "epoch:29 step:28106 [D loss: 0.266164, acc.: 55.47%] [G loss: 0.308811]\n",
      "epoch:29 step:28107 [D loss: 0.256367, acc.: 52.34%] [G loss: 0.299327]\n",
      "epoch:29 step:28108 [D loss: 0.221596, acc.: 64.84%] [G loss: 0.300347]\n",
      "epoch:29 step:28109 [D loss: 0.236186, acc.: 61.72%] [G loss: 0.295157]\n",
      "epoch:29 step:28110 [D loss: 0.255076, acc.: 47.66%] [G loss: 0.268869]\n",
      "epoch:30 step:28111 [D loss: 0.258575, acc.: 53.91%] [G loss: 0.282152]\n",
      "epoch:30 step:28112 [D loss: 0.249677, acc.: 55.47%] [G loss: 0.303519]\n",
      "epoch:30 step:28113 [D loss: 0.231725, acc.: 60.16%] [G loss: 0.288478]\n",
      "epoch:30 step:28114 [D loss: 0.246800, acc.: 53.12%] [G loss: 0.284862]\n",
      "epoch:30 step:28115 [D loss: 0.245384, acc.: 56.25%] [G loss: 0.313815]\n",
      "epoch:30 step:28116 [D loss: 0.255225, acc.: 51.56%] [G loss: 0.284652]\n",
      "epoch:30 step:28117 [D loss: 0.250972, acc.: 57.03%] [G loss: 0.251888]\n",
      "epoch:30 step:28118 [D loss: 0.235002, acc.: 57.03%] [G loss: 0.295237]\n",
      "epoch:30 step:28119 [D loss: 0.241945, acc.: 60.94%] [G loss: 0.303492]\n",
      "epoch:30 step:28120 [D loss: 0.231448, acc.: 60.94%] [G loss: 0.287414]\n",
      "epoch:30 step:28121 [D loss: 0.238016, acc.: 57.81%] [G loss: 0.305198]\n",
      "epoch:30 step:28122 [D loss: 0.240588, acc.: 57.81%] [G loss: 0.313870]\n",
      "epoch:30 step:28123 [D loss: 0.248029, acc.: 56.25%] [G loss: 0.290621]\n",
      "epoch:30 step:28124 [D loss: 0.251460, acc.: 57.03%] [G loss: 0.284407]\n",
      "epoch:30 step:28125 [D loss: 0.226772, acc.: 68.75%] [G loss: 0.283898]\n",
      "epoch:30 step:28126 [D loss: 0.229597, acc.: 60.16%] [G loss: 0.294557]\n",
      "epoch:30 step:28127 [D loss: 0.235367, acc.: 62.50%] [G loss: 0.313009]\n",
      "epoch:30 step:28128 [D loss: 0.229083, acc.: 64.84%] [G loss: 0.303044]\n",
      "epoch:30 step:28129 [D loss: 0.233110, acc.: 58.59%] [G loss: 0.296007]\n",
      "epoch:30 step:28130 [D loss: 0.248026, acc.: 53.12%] [G loss: 0.303969]\n",
      "epoch:30 step:28131 [D loss: 0.228880, acc.: 61.72%] [G loss: 0.290088]\n",
      "epoch:30 step:28132 [D loss: 0.241459, acc.: 57.81%] [G loss: 0.302998]\n",
      "epoch:30 step:28133 [D loss: 0.236841, acc.: 60.94%] [G loss: 0.294842]\n",
      "epoch:30 step:28134 [D loss: 0.230581, acc.: 61.72%] [G loss: 0.299905]\n",
      "epoch:30 step:28135 [D loss: 0.247756, acc.: 53.12%] [G loss: 0.321270]\n",
      "epoch:30 step:28136 [D loss: 0.219677, acc.: 66.41%] [G loss: 0.298746]\n",
      "epoch:30 step:28137 [D loss: 0.238628, acc.: 61.72%] [G loss: 0.300405]\n",
      "epoch:30 step:28138 [D loss: 0.246169, acc.: 54.69%] [G loss: 0.321117]\n",
      "epoch:30 step:28139 [D loss: 0.234731, acc.: 60.16%] [G loss: 0.301768]\n",
      "epoch:30 step:28140 [D loss: 0.233105, acc.: 61.72%] [G loss: 0.310201]\n",
      "epoch:30 step:28141 [D loss: 0.240482, acc.: 61.72%] [G loss: 0.295851]\n",
      "epoch:30 step:28142 [D loss: 0.236492, acc.: 59.38%] [G loss: 0.289237]\n",
      "epoch:30 step:28143 [D loss: 0.246894, acc.: 57.03%] [G loss: 0.292431]\n",
      "epoch:30 step:28144 [D loss: 0.256219, acc.: 58.59%] [G loss: 0.290092]\n",
      "epoch:30 step:28145 [D loss: 0.236842, acc.: 60.16%] [G loss: 0.280540]\n",
      "epoch:30 step:28146 [D loss: 0.247808, acc.: 60.16%] [G loss: 0.296985]\n",
      "epoch:30 step:28147 [D loss: 0.234525, acc.: 61.72%] [G loss: 0.302142]\n",
      "epoch:30 step:28148 [D loss: 0.242711, acc.: 57.03%] [G loss: 0.262858]\n",
      "epoch:30 step:28149 [D loss: 0.239674, acc.: 59.38%] [G loss: 0.297124]\n",
      "epoch:30 step:28150 [D loss: 0.246198, acc.: 58.59%] [G loss: 0.313032]\n",
      "epoch:30 step:28151 [D loss: 0.237771, acc.: 53.91%] [G loss: 0.283110]\n",
      "epoch:30 step:28152 [D loss: 0.258148, acc.: 58.59%] [G loss: 0.305568]\n",
      "epoch:30 step:28153 [D loss: 0.245614, acc.: 55.47%] [G loss: 0.270929]\n",
      "epoch:30 step:28154 [D loss: 0.225690, acc.: 66.41%] [G loss: 0.307914]\n",
      "epoch:30 step:28155 [D loss: 0.229306, acc.: 62.50%] [G loss: 0.312822]\n",
      "epoch:30 step:28156 [D loss: 0.244311, acc.: 53.12%] [G loss: 0.297547]\n",
      "epoch:30 step:28157 [D loss: 0.230532, acc.: 62.50%] [G loss: 0.318556]\n",
      "epoch:30 step:28158 [D loss: 0.235451, acc.: 60.16%] [G loss: 0.312249]\n",
      "epoch:30 step:28159 [D loss: 0.242824, acc.: 60.16%] [G loss: 0.309626]\n",
      "epoch:30 step:28160 [D loss: 0.241963, acc.: 58.59%] [G loss: 0.327823]\n",
      "epoch:30 step:28161 [D loss: 0.234385, acc.: 54.69%] [G loss: 0.270247]\n",
      "epoch:30 step:28162 [D loss: 0.215566, acc.: 71.88%] [G loss: 0.327010]\n",
      "epoch:30 step:28163 [D loss: 0.244844, acc.: 53.91%] [G loss: 0.286751]\n",
      "epoch:30 step:28164 [D loss: 0.233000, acc.: 66.41%] [G loss: 0.288341]\n",
      "epoch:30 step:28165 [D loss: 0.239703, acc.: 54.69%] [G loss: 0.282707]\n",
      "epoch:30 step:28166 [D loss: 0.231139, acc.: 64.06%] [G loss: 0.309148]\n",
      "epoch:30 step:28167 [D loss: 0.263952, acc.: 50.00%] [G loss: 0.307470]\n",
      "epoch:30 step:28168 [D loss: 0.226489, acc.: 62.50%] [G loss: 0.304412]\n",
      "epoch:30 step:28169 [D loss: 0.238073, acc.: 58.59%] [G loss: 0.313940]\n",
      "epoch:30 step:28170 [D loss: 0.245589, acc.: 52.34%] [G loss: 0.307238]\n",
      "epoch:30 step:28171 [D loss: 0.274714, acc.: 47.66%] [G loss: 0.290675]\n",
      "epoch:30 step:28172 [D loss: 0.247810, acc.: 53.91%] [G loss: 0.281815]\n",
      "epoch:30 step:28173 [D loss: 0.231770, acc.: 64.84%] [G loss: 0.316282]\n",
      "epoch:30 step:28174 [D loss: 0.237748, acc.: 60.16%] [G loss: 0.293902]\n",
      "epoch:30 step:28175 [D loss: 0.229740, acc.: 64.84%] [G loss: 0.299586]\n",
      "epoch:30 step:28176 [D loss: 0.233844, acc.: 64.06%] [G loss: 0.316257]\n",
      "epoch:30 step:28177 [D loss: 0.257719, acc.: 51.56%] [G loss: 0.346427]\n",
      "epoch:30 step:28178 [D loss: 0.242424, acc.: 58.59%] [G loss: 0.281598]\n",
      "epoch:30 step:28179 [D loss: 0.232706, acc.: 56.25%] [G loss: 0.302477]\n",
      "epoch:30 step:28180 [D loss: 0.241385, acc.: 55.47%] [G loss: 0.293720]\n",
      "epoch:30 step:28181 [D loss: 0.242887, acc.: 58.59%] [G loss: 0.308203]\n",
      "epoch:30 step:28182 [D loss: 0.237728, acc.: 58.59%] [G loss: 0.284348]\n",
      "epoch:30 step:28183 [D loss: 0.219915, acc.: 65.62%] [G loss: 0.326557]\n",
      "epoch:30 step:28184 [D loss: 0.238852, acc.: 56.25%] [G loss: 0.308345]\n",
      "epoch:30 step:28185 [D loss: 0.243336, acc.: 56.25%] [G loss: 0.321382]\n",
      "epoch:30 step:28186 [D loss: 0.233437, acc.: 59.38%] [G loss: 0.290130]\n",
      "epoch:30 step:28187 [D loss: 0.218917, acc.: 65.62%] [G loss: 0.310737]\n",
      "epoch:30 step:28188 [D loss: 0.230266, acc.: 62.50%] [G loss: 0.303706]\n",
      "epoch:30 step:28189 [D loss: 0.249499, acc.: 50.78%] [G loss: 0.280228]\n",
      "epoch:30 step:28190 [D loss: 0.227863, acc.: 65.62%] [G loss: 0.317083]\n",
      "epoch:30 step:28191 [D loss: 0.241880, acc.: 53.12%] [G loss: 0.325694]\n",
      "epoch:30 step:28192 [D loss: 0.226358, acc.: 59.38%] [G loss: 0.304116]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:30 step:28193 [D loss: 0.227495, acc.: 60.16%] [G loss: 0.302366]\n",
      "epoch:30 step:28194 [D loss: 0.249215, acc.: 57.03%] [G loss: 0.297337]\n",
      "epoch:30 step:28195 [D loss: 0.234475, acc.: 63.28%] [G loss: 0.312171]\n",
      "epoch:30 step:28196 [D loss: 0.245780, acc.: 56.25%] [G loss: 0.312423]\n",
      "epoch:30 step:28197 [D loss: 0.253573, acc.: 57.81%] [G loss: 0.309027]\n",
      "epoch:30 step:28198 [D loss: 0.233702, acc.: 60.16%] [G loss: 0.333294]\n",
      "epoch:30 step:28199 [D loss: 0.240896, acc.: 53.12%] [G loss: 0.288694]\n",
      "epoch:30 step:28200 [D loss: 0.233220, acc.: 61.72%] [G loss: 0.278964]\n",
      "epoch:30 step:28201 [D loss: 0.244070, acc.: 55.47%] [G loss: 0.308780]\n",
      "epoch:30 step:28202 [D loss: 0.241960, acc.: 55.47%] [G loss: 0.289362]\n",
      "epoch:30 step:28203 [D loss: 0.227929, acc.: 62.50%] [G loss: 0.292247]\n",
      "epoch:30 step:28204 [D loss: 0.248789, acc.: 57.81%] [G loss: 0.302398]\n",
      "epoch:30 step:28205 [D loss: 0.208573, acc.: 70.31%] [G loss: 0.304062]\n",
      "epoch:30 step:28206 [D loss: 0.245970, acc.: 57.81%] [G loss: 0.317993]\n",
      "epoch:30 step:28207 [D loss: 0.267005, acc.: 51.56%] [G loss: 0.315791]\n",
      "epoch:30 step:28208 [D loss: 0.235246, acc.: 63.28%] [G loss: 0.302485]\n",
      "epoch:30 step:28209 [D loss: 0.243659, acc.: 57.03%] [G loss: 0.272855]\n",
      "epoch:30 step:28210 [D loss: 0.251623, acc.: 52.34%] [G loss: 0.294962]\n",
      "epoch:30 step:28211 [D loss: 0.230097, acc.: 64.06%] [G loss: 0.321614]\n",
      "epoch:30 step:28212 [D loss: 0.250569, acc.: 51.56%] [G loss: 0.316770]\n",
      "epoch:30 step:28213 [D loss: 0.229767, acc.: 64.84%] [G loss: 0.325720]\n",
      "epoch:30 step:28214 [D loss: 0.250302, acc.: 55.47%] [G loss: 0.311915]\n",
      "epoch:30 step:28215 [D loss: 0.234677, acc.: 60.16%] [G loss: 0.322046]\n",
      "epoch:30 step:28216 [D loss: 0.242682, acc.: 53.12%] [G loss: 0.253911]\n",
      "epoch:30 step:28217 [D loss: 0.239511, acc.: 64.06%] [G loss: 0.310123]\n",
      "epoch:30 step:28218 [D loss: 0.253958, acc.: 46.88%] [G loss: 0.277967]\n",
      "epoch:30 step:28219 [D loss: 0.236725, acc.: 56.25%] [G loss: 0.304410]\n",
      "epoch:30 step:28220 [D loss: 0.228596, acc.: 57.81%] [G loss: 0.344985]\n",
      "epoch:30 step:28221 [D loss: 0.235026, acc.: 63.28%] [G loss: 0.299206]\n",
      "epoch:30 step:28222 [D loss: 0.217489, acc.: 63.28%] [G loss: 0.290060]\n",
      "epoch:30 step:28223 [D loss: 0.250124, acc.: 50.78%] [G loss: 0.300165]\n",
      "epoch:30 step:28224 [D loss: 0.252395, acc.: 49.22%] [G loss: 0.285572]\n",
      "epoch:30 step:28225 [D loss: 0.237744, acc.: 55.47%] [G loss: 0.293325]\n",
      "epoch:30 step:28226 [D loss: 0.240485, acc.: 58.59%] [G loss: 0.307849]\n",
      "epoch:30 step:28227 [D loss: 0.244464, acc.: 57.81%] [G loss: 0.333627]\n",
      "epoch:30 step:28228 [D loss: 0.223423, acc.: 68.75%] [G loss: 0.325364]\n",
      "epoch:30 step:28229 [D loss: 0.242419, acc.: 57.03%] [G loss: 0.299460]\n",
      "epoch:30 step:28230 [D loss: 0.245990, acc.: 57.81%] [G loss: 0.275141]\n",
      "epoch:30 step:28231 [D loss: 0.230580, acc.: 62.50%] [G loss: 0.281272]\n",
      "epoch:30 step:28232 [D loss: 0.255380, acc.: 52.34%] [G loss: 0.280704]\n",
      "epoch:30 step:28233 [D loss: 0.242993, acc.: 57.81%] [G loss: 0.299414]\n",
      "epoch:30 step:28234 [D loss: 0.234756, acc.: 57.81%] [G loss: 0.295571]\n",
      "epoch:30 step:28235 [D loss: 0.247952, acc.: 57.81%] [G loss: 0.286852]\n",
      "epoch:30 step:28236 [D loss: 0.232185, acc.: 56.25%] [G loss: 0.300625]\n",
      "epoch:30 step:28237 [D loss: 0.237873, acc.: 61.72%] [G loss: 0.312159]\n",
      "epoch:30 step:28238 [D loss: 0.235913, acc.: 60.94%] [G loss: 0.314297]\n",
      "epoch:30 step:28239 [D loss: 0.242185, acc.: 58.59%] [G loss: 0.311368]\n",
      "epoch:30 step:28240 [D loss: 0.231983, acc.: 59.38%] [G loss: 0.320123]\n",
      "epoch:30 step:28241 [D loss: 0.227533, acc.: 64.06%] [G loss: 0.309410]\n",
      "epoch:30 step:28242 [D loss: 0.239598, acc.: 57.81%] [G loss: 0.316832]\n",
      "epoch:30 step:28243 [D loss: 0.269540, acc.: 46.88%] [G loss: 0.287788]\n",
      "epoch:30 step:28244 [D loss: 0.235099, acc.: 62.50%] [G loss: 0.298399]\n",
      "epoch:30 step:28245 [D loss: 0.246586, acc.: 52.34%] [G loss: 0.278241]\n",
      "epoch:30 step:28246 [D loss: 0.241941, acc.: 55.47%] [G loss: 0.298959]\n",
      "epoch:30 step:28247 [D loss: 0.242611, acc.: 56.25%] [G loss: 0.302279]\n",
      "epoch:30 step:28248 [D loss: 0.240997, acc.: 58.59%] [G loss: 0.299497]\n",
      "epoch:30 step:28249 [D loss: 0.244279, acc.: 57.81%] [G loss: 0.303969]\n",
      "epoch:30 step:28250 [D loss: 0.243200, acc.: 56.25%] [G loss: 0.303802]\n",
      "epoch:30 step:28251 [D loss: 0.236144, acc.: 58.59%] [G loss: 0.326393]\n",
      "epoch:30 step:28252 [D loss: 0.225732, acc.: 67.97%] [G loss: 0.266635]\n",
      "epoch:30 step:28253 [D loss: 0.241837, acc.: 59.38%] [G loss: 0.274197]\n",
      "epoch:30 step:28254 [D loss: 0.252053, acc.: 50.78%] [G loss: 0.294883]\n",
      "epoch:30 step:28255 [D loss: 0.235750, acc.: 57.81%] [G loss: 0.306433]\n",
      "epoch:30 step:28256 [D loss: 0.230645, acc.: 59.38%] [G loss: 0.323175]\n",
      "epoch:30 step:28257 [D loss: 0.237993, acc.: 53.91%] [G loss: 0.282060]\n",
      "epoch:30 step:28258 [D loss: 0.239556, acc.: 57.81%] [G loss: 0.289594]\n",
      "epoch:30 step:28259 [D loss: 0.240165, acc.: 55.47%] [G loss: 0.291672]\n",
      "epoch:30 step:28260 [D loss: 0.255084, acc.: 57.81%] [G loss: 0.279928]\n",
      "epoch:30 step:28261 [D loss: 0.239261, acc.: 62.50%] [G loss: 0.301541]\n",
      "epoch:30 step:28262 [D loss: 0.242637, acc.: 59.38%] [G loss: 0.320009]\n",
      "epoch:30 step:28263 [D loss: 0.231784, acc.: 55.47%] [G loss: 0.313927]\n",
      "epoch:30 step:28264 [D loss: 0.244180, acc.: 54.69%] [G loss: 0.293075]\n",
      "epoch:30 step:28265 [D loss: 0.244255, acc.: 57.03%] [G loss: 0.326199]\n",
      "epoch:30 step:28266 [D loss: 0.240730, acc.: 55.47%] [G loss: 0.328494]\n",
      "epoch:30 step:28267 [D loss: 0.239568, acc.: 57.03%] [G loss: 0.314930]\n",
      "epoch:30 step:28268 [D loss: 0.250602, acc.: 53.12%] [G loss: 0.281611]\n",
      "epoch:30 step:28269 [D loss: 0.214675, acc.: 66.41%] [G loss: 0.302349]\n",
      "epoch:30 step:28270 [D loss: 0.225857, acc.: 61.72%] [G loss: 0.319310]\n",
      "epoch:30 step:28271 [D loss: 0.232703, acc.: 57.81%] [G loss: 0.310082]\n",
      "epoch:30 step:28272 [D loss: 0.235080, acc.: 60.16%] [G loss: 0.278884]\n",
      "epoch:30 step:28273 [D loss: 0.236937, acc.: 60.16%] [G loss: 0.303450]\n",
      "epoch:30 step:28274 [D loss: 0.237990, acc.: 58.59%] [G loss: 0.341550]\n",
      "epoch:30 step:28275 [D loss: 0.232859, acc.: 62.50%] [G loss: 0.315014]\n",
      "epoch:30 step:28276 [D loss: 0.245635, acc.: 55.47%] [G loss: 0.340264]\n",
      "epoch:30 step:28277 [D loss: 0.221858, acc.: 60.94%] [G loss: 0.288288]\n",
      "epoch:30 step:28278 [D loss: 0.234810, acc.: 62.50%] [G loss: 0.296315]\n",
      "epoch:30 step:28279 [D loss: 0.229369, acc.: 64.84%] [G loss: 0.298272]\n",
      "epoch:30 step:28280 [D loss: 0.251064, acc.: 50.78%] [G loss: 0.274666]\n",
      "epoch:30 step:28281 [D loss: 0.227457, acc.: 60.94%] [G loss: 0.301102]\n",
      "epoch:30 step:28282 [D loss: 0.215971, acc.: 68.75%] [G loss: 0.332403]\n",
      "epoch:30 step:28283 [D loss: 0.237576, acc.: 53.12%] [G loss: 0.306039]\n",
      "epoch:30 step:28284 [D loss: 0.229865, acc.: 60.16%] [G loss: 0.305177]\n",
      "epoch:30 step:28285 [D loss: 0.250465, acc.: 53.91%] [G loss: 0.269307]\n",
      "epoch:30 step:28286 [D loss: 0.235524, acc.: 57.03%] [G loss: 0.291384]\n",
      "epoch:30 step:28287 [D loss: 0.226958, acc.: 65.62%] [G loss: 0.320680]\n",
      "epoch:30 step:28288 [D loss: 0.247933, acc.: 57.81%] [G loss: 0.283551]\n",
      "epoch:30 step:28289 [D loss: 0.246543, acc.: 57.03%] [G loss: 0.303205]\n",
      "epoch:30 step:28290 [D loss: 0.234177, acc.: 59.38%] [G loss: 0.265777]\n",
      "epoch:30 step:28291 [D loss: 0.220644, acc.: 67.19%] [G loss: 0.302031]\n",
      "epoch:30 step:28292 [D loss: 0.241946, acc.: 50.78%] [G loss: 0.313862]\n",
      "epoch:30 step:28293 [D loss: 0.221818, acc.: 64.06%] [G loss: 0.320659]\n",
      "epoch:30 step:28294 [D loss: 0.252693, acc.: 57.81%] [G loss: 0.293162]\n",
      "epoch:30 step:28295 [D loss: 0.228290, acc.: 61.72%] [G loss: 0.314624]\n",
      "epoch:30 step:28296 [D loss: 0.234172, acc.: 57.81%] [G loss: 0.310476]\n",
      "epoch:30 step:28297 [D loss: 0.249983, acc.: 53.12%] [G loss: 0.328090]\n",
      "epoch:30 step:28298 [D loss: 0.234888, acc.: 62.50%] [G loss: 0.283345]\n",
      "epoch:30 step:28299 [D loss: 0.236504, acc.: 60.16%] [G loss: 0.279479]\n",
      "epoch:30 step:28300 [D loss: 0.255217, acc.: 50.00%] [G loss: 0.293432]\n",
      "epoch:30 step:28301 [D loss: 0.242070, acc.: 58.59%] [G loss: 0.301941]\n",
      "epoch:30 step:28302 [D loss: 0.238380, acc.: 64.06%] [G loss: 0.298070]\n",
      "epoch:30 step:28303 [D loss: 0.258810, acc.: 50.00%] [G loss: 0.281359]\n",
      "epoch:30 step:28304 [D loss: 0.240265, acc.: 61.72%] [G loss: 0.288098]\n",
      "epoch:30 step:28305 [D loss: 0.254513, acc.: 55.47%] [G loss: 0.281664]\n",
      "epoch:30 step:28306 [D loss: 0.239968, acc.: 59.38%] [G loss: 0.315722]\n",
      "epoch:30 step:28307 [D loss: 0.241124, acc.: 59.38%] [G loss: 0.288947]\n",
      "epoch:30 step:28308 [D loss: 0.219966, acc.: 64.84%] [G loss: 0.279045]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:30 step:28309 [D loss: 0.218890, acc.: 67.19%] [G loss: 0.288081]\n",
      "epoch:30 step:28310 [D loss: 0.244074, acc.: 51.56%] [G loss: 0.296555]\n",
      "epoch:30 step:28311 [D loss: 0.223465, acc.: 58.59%] [G loss: 0.285777]\n",
      "epoch:30 step:28312 [D loss: 0.243987, acc.: 63.28%] [G loss: 0.319181]\n",
      "epoch:30 step:28313 [D loss: 0.264041, acc.: 47.66%] [G loss: 0.245923]\n",
      "epoch:30 step:28314 [D loss: 0.241153, acc.: 57.03%] [G loss: 0.292902]\n",
      "epoch:30 step:28315 [D loss: 0.251925, acc.: 51.56%] [G loss: 0.305110]\n",
      "epoch:30 step:28316 [D loss: 0.236769, acc.: 55.47%] [G loss: 0.300150]\n",
      "epoch:30 step:28317 [D loss: 0.243595, acc.: 53.12%] [G loss: 0.294534]\n",
      "epoch:30 step:28318 [D loss: 0.225795, acc.: 59.38%] [G loss: 0.293554]\n",
      "epoch:30 step:28319 [D loss: 0.220703, acc.: 66.41%] [G loss: 0.259236]\n",
      "epoch:30 step:28320 [D loss: 0.237385, acc.: 63.28%] [G loss: 0.307071]\n",
      "epoch:30 step:28321 [D loss: 0.241362, acc.: 61.72%] [G loss: 0.318816]\n",
      "epoch:30 step:28322 [D loss: 0.233999, acc.: 64.06%] [G loss: 0.313132]\n",
      "epoch:30 step:28323 [D loss: 0.237845, acc.: 60.16%] [G loss: 0.319220]\n",
      "epoch:30 step:28324 [D loss: 0.234746, acc.: 62.50%] [G loss: 0.317858]\n",
      "epoch:30 step:28325 [D loss: 0.249175, acc.: 56.25%] [G loss: 0.274105]\n",
      "epoch:30 step:28326 [D loss: 0.234459, acc.: 60.16%] [G loss: 0.292639]\n",
      "epoch:30 step:28327 [D loss: 0.217473, acc.: 63.28%] [G loss: 0.316212]\n",
      "epoch:30 step:28328 [D loss: 0.234664, acc.: 60.94%] [G loss: 0.281856]\n",
      "epoch:30 step:28329 [D loss: 0.244672, acc.: 50.78%] [G loss: 0.289993]\n",
      "epoch:30 step:28330 [D loss: 0.232016, acc.: 63.28%] [G loss: 0.282178]\n",
      "epoch:30 step:28331 [D loss: 0.245932, acc.: 54.69%] [G loss: 0.303521]\n",
      "epoch:30 step:28332 [D loss: 0.249033, acc.: 55.47%] [G loss: 0.292562]\n",
      "epoch:30 step:28333 [D loss: 0.247089, acc.: 54.69%] [G loss: 0.303025]\n",
      "epoch:30 step:28334 [D loss: 0.234974, acc.: 62.50%] [G loss: 0.298219]\n",
      "epoch:30 step:28335 [D loss: 0.242318, acc.: 54.69%] [G loss: 0.301263]\n",
      "epoch:30 step:28336 [D loss: 0.241908, acc.: 57.03%] [G loss: 0.291770]\n",
      "epoch:30 step:28337 [D loss: 0.247764, acc.: 56.25%] [G loss: 0.335149]\n",
      "epoch:30 step:28338 [D loss: 0.228045, acc.: 63.28%] [G loss: 0.310236]\n",
      "epoch:30 step:28339 [D loss: 0.235126, acc.: 62.50%] [G loss: 0.293077]\n",
      "epoch:30 step:28340 [D loss: 0.231389, acc.: 62.50%] [G loss: 0.280937]\n",
      "epoch:30 step:28341 [D loss: 0.238904, acc.: 59.38%] [G loss: 0.308011]\n",
      "epoch:30 step:28342 [D loss: 0.238972, acc.: 54.69%] [G loss: 0.309329]\n",
      "epoch:30 step:28343 [D loss: 0.253910, acc.: 51.56%] [G loss: 0.280321]\n",
      "epoch:30 step:28344 [D loss: 0.250091, acc.: 49.22%] [G loss: 0.329471]\n",
      "epoch:30 step:28345 [D loss: 0.262174, acc.: 48.44%] [G loss: 0.288551]\n",
      "epoch:30 step:28346 [D loss: 0.233760, acc.: 58.59%] [G loss: 0.278937]\n",
      "epoch:30 step:28347 [D loss: 0.229711, acc.: 60.94%] [G loss: 0.291665]\n",
      "epoch:30 step:28348 [D loss: 0.243557, acc.: 56.25%] [G loss: 0.313091]\n",
      "epoch:30 step:28349 [D loss: 0.224735, acc.: 64.84%] [G loss: 0.297692]\n",
      "epoch:30 step:28350 [D loss: 0.260239, acc.: 50.78%] [G loss: 0.283469]\n",
      "epoch:30 step:28351 [D loss: 0.246290, acc.: 54.69%] [G loss: 0.298738]\n",
      "epoch:30 step:28352 [D loss: 0.247669, acc.: 51.56%] [G loss: 0.288103]\n",
      "epoch:30 step:28353 [D loss: 0.252006, acc.: 50.78%] [G loss: 0.264190]\n",
      "epoch:30 step:28354 [D loss: 0.237131, acc.: 60.94%] [G loss: 0.309663]\n",
      "epoch:30 step:28355 [D loss: 0.241543, acc.: 57.81%] [G loss: 0.296192]\n",
      "epoch:30 step:28356 [D loss: 0.240927, acc.: 58.59%] [G loss: 0.295219]\n",
      "epoch:30 step:28357 [D loss: 0.241584, acc.: 54.69%] [G loss: 0.289143]\n",
      "epoch:30 step:28358 [D loss: 0.253512, acc.: 53.12%] [G loss: 0.281613]\n",
      "epoch:30 step:28359 [D loss: 0.242677, acc.: 57.81%] [G loss: 0.313820]\n",
      "epoch:30 step:28360 [D loss: 0.255393, acc.: 50.00%] [G loss: 0.287402]\n",
      "epoch:30 step:28361 [D loss: 0.233775, acc.: 59.38%] [G loss: 0.268391]\n",
      "epoch:30 step:28362 [D loss: 0.228594, acc.: 65.62%] [G loss: 0.316222]\n",
      "epoch:30 step:28363 [D loss: 0.231307, acc.: 62.50%] [G loss: 0.319411]\n",
      "epoch:30 step:28364 [D loss: 0.232640, acc.: 64.06%] [G loss: 0.305030]\n",
      "epoch:30 step:28365 [D loss: 0.244502, acc.: 58.59%] [G loss: 0.312642]\n",
      "epoch:30 step:28366 [D loss: 0.250899, acc.: 54.69%] [G loss: 0.282077]\n",
      "epoch:30 step:28367 [D loss: 0.255313, acc.: 53.12%] [G loss: 0.295136]\n",
      "epoch:30 step:28368 [D loss: 0.247404, acc.: 55.47%] [G loss: 0.296697]\n",
      "epoch:30 step:28369 [D loss: 0.231796, acc.: 60.94%] [G loss: 0.291924]\n",
      "epoch:30 step:28370 [D loss: 0.256347, acc.: 51.56%] [G loss: 0.293978]\n",
      "epoch:30 step:28371 [D loss: 0.239549, acc.: 60.94%] [G loss: 0.280676]\n",
      "epoch:30 step:28372 [D loss: 0.219283, acc.: 64.06%] [G loss: 0.303172]\n",
      "epoch:30 step:28373 [D loss: 0.250416, acc.: 53.12%] [G loss: 0.319561]\n",
      "epoch:30 step:28374 [D loss: 0.243400, acc.: 56.25%] [G loss: 0.321850]\n",
      "epoch:30 step:28375 [D loss: 0.225098, acc.: 62.50%] [G loss: 0.302903]\n",
      "epoch:30 step:28376 [D loss: 0.231310, acc.: 62.50%] [G loss: 0.329211]\n",
      "epoch:30 step:28377 [D loss: 0.230634, acc.: 60.94%] [G loss: 0.283768]\n",
      "epoch:30 step:28378 [D loss: 0.229804, acc.: 62.50%] [G loss: 0.298310]\n",
      "epoch:30 step:28379 [D loss: 0.234567, acc.: 60.16%] [G loss: 0.297902]\n",
      "epoch:30 step:28380 [D loss: 0.239097, acc.: 57.03%] [G loss: 0.288196]\n",
      "epoch:30 step:28381 [D loss: 0.231223, acc.: 61.72%] [G loss: 0.314551]\n",
      "epoch:30 step:28382 [D loss: 0.233226, acc.: 62.50%] [G loss: 0.278854]\n",
      "epoch:30 step:28383 [D loss: 0.237738, acc.: 52.34%] [G loss: 0.281245]\n",
      "epoch:30 step:28384 [D loss: 0.222176, acc.: 63.28%] [G loss: 0.325295]\n",
      "epoch:30 step:28385 [D loss: 0.235510, acc.: 67.19%] [G loss: 0.294514]\n",
      "epoch:30 step:28386 [D loss: 0.239234, acc.: 62.50%] [G loss: 0.312572]\n",
      "epoch:30 step:28387 [D loss: 0.232690, acc.: 58.59%] [G loss: 0.297388]\n",
      "epoch:30 step:28388 [D loss: 0.262679, acc.: 48.44%] [G loss: 0.287280]\n",
      "epoch:30 step:28389 [D loss: 0.256225, acc.: 51.56%] [G loss: 0.288780]\n",
      "epoch:30 step:28390 [D loss: 0.238773, acc.: 56.25%] [G loss: 0.302661]\n",
      "epoch:30 step:28391 [D loss: 0.236042, acc.: 59.38%] [G loss: 0.344284]\n",
      "epoch:30 step:28392 [D loss: 0.243538, acc.: 59.38%] [G loss: 0.315191]\n",
      "epoch:30 step:28393 [D loss: 0.241413, acc.: 55.47%] [G loss: 0.290729]\n",
      "epoch:30 step:28394 [D loss: 0.225398, acc.: 64.06%] [G loss: 0.299162]\n",
      "epoch:30 step:28395 [D loss: 0.239113, acc.: 57.03%] [G loss: 0.297451]\n",
      "epoch:30 step:28396 [D loss: 0.244707, acc.: 57.03%] [G loss: 0.315039]\n",
      "epoch:30 step:28397 [D loss: 0.240459, acc.: 57.81%] [G loss: 0.296233]\n",
      "epoch:30 step:28398 [D loss: 0.226315, acc.: 60.94%] [G loss: 0.301332]\n",
      "epoch:30 step:28399 [D loss: 0.237840, acc.: 57.81%] [G loss: 0.330245]\n",
      "epoch:30 step:28400 [D loss: 0.250056, acc.: 56.25%] [G loss: 0.294602]\n",
      "epoch:30 step:28401 [D loss: 0.218752, acc.: 67.19%] [G loss: 0.306632]\n",
      "epoch:30 step:28402 [D loss: 0.249379, acc.: 51.56%] [G loss: 0.322132]\n",
      "epoch:30 step:28403 [D loss: 0.243365, acc.: 57.81%] [G loss: 0.296663]\n",
      "epoch:30 step:28404 [D loss: 0.238057, acc.: 57.81%] [G loss: 0.294843]\n",
      "epoch:30 step:28405 [D loss: 0.234651, acc.: 56.25%] [G loss: 0.283333]\n",
      "epoch:30 step:28406 [D loss: 0.218877, acc.: 67.19%] [G loss: 0.310800]\n",
      "epoch:30 step:28407 [D loss: 0.241840, acc.: 57.81%] [G loss: 0.289493]\n",
      "epoch:30 step:28408 [D loss: 0.237733, acc.: 59.38%] [G loss: 0.298216]\n",
      "epoch:30 step:28409 [D loss: 0.253264, acc.: 58.59%] [G loss: 0.317696]\n",
      "epoch:30 step:28410 [D loss: 0.231328, acc.: 65.62%] [G loss: 0.291502]\n",
      "epoch:30 step:28411 [D loss: 0.221470, acc.: 62.50%] [G loss: 0.282606]\n",
      "epoch:30 step:28412 [D loss: 0.238861, acc.: 56.25%] [G loss: 0.290011]\n",
      "epoch:30 step:28413 [D loss: 0.224654, acc.: 65.62%] [G loss: 0.333842]\n",
      "epoch:30 step:28414 [D loss: 0.233673, acc.: 58.59%] [G loss: 0.301243]\n",
      "epoch:30 step:28415 [D loss: 0.257541, acc.: 52.34%] [G loss: 0.314423]\n",
      "epoch:30 step:28416 [D loss: 0.254136, acc.: 57.03%] [G loss: 0.287331]\n",
      "epoch:30 step:28417 [D loss: 0.256928, acc.: 46.09%] [G loss: 0.290386]\n",
      "epoch:30 step:28418 [D loss: 0.230031, acc.: 60.16%] [G loss: 0.296494]\n",
      "epoch:30 step:28419 [D loss: 0.216516, acc.: 62.50%] [G loss: 0.311948]\n",
      "epoch:30 step:28420 [D loss: 0.248094, acc.: 54.69%] [G loss: 0.292543]\n",
      "epoch:30 step:28421 [D loss: 0.237602, acc.: 58.59%] [G loss: 0.322201]\n",
      "epoch:30 step:28422 [D loss: 0.236490, acc.: 59.38%] [G loss: 0.315268]\n",
      "epoch:30 step:28423 [D loss: 0.250527, acc.: 58.59%] [G loss: 0.298207]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:30 step:28424 [D loss: 0.227221, acc.: 60.16%] [G loss: 0.290946]\n",
      "epoch:30 step:28425 [D loss: 0.249234, acc.: 56.25%] [G loss: 0.285431]\n",
      "epoch:30 step:28426 [D loss: 0.264657, acc.: 51.56%] [G loss: 0.285003]\n",
      "epoch:30 step:28427 [D loss: 0.234002, acc.: 54.69%] [G loss: 0.296609]\n",
      "epoch:30 step:28428 [D loss: 0.241684, acc.: 59.38%] [G loss: 0.286775]\n",
      "epoch:30 step:28429 [D loss: 0.229204, acc.: 63.28%] [G loss: 0.294111]\n",
      "epoch:30 step:28430 [D loss: 0.231772, acc.: 60.16%] [G loss: 0.281636]\n",
      "epoch:30 step:28431 [D loss: 0.232902, acc.: 60.16%] [G loss: 0.293890]\n",
      "epoch:30 step:28432 [D loss: 0.245552, acc.: 54.69%] [G loss: 0.293870]\n",
      "epoch:30 step:28433 [D loss: 0.247781, acc.: 57.81%] [G loss: 0.266797]\n",
      "epoch:30 step:28434 [D loss: 0.221087, acc.: 63.28%] [G loss: 0.312750]\n",
      "epoch:30 step:28435 [D loss: 0.233518, acc.: 56.25%] [G loss: 0.273425]\n",
      "epoch:30 step:28436 [D loss: 0.233659, acc.: 57.03%] [G loss: 0.288173]\n",
      "epoch:30 step:28437 [D loss: 0.241163, acc.: 55.47%] [G loss: 0.285852]\n",
      "epoch:30 step:28438 [D loss: 0.232141, acc.: 60.16%] [G loss: 0.296500]\n",
      "epoch:30 step:28439 [D loss: 0.240089, acc.: 58.59%] [G loss: 0.289445]\n",
      "epoch:30 step:28440 [D loss: 0.222152, acc.: 67.19%] [G loss: 0.285182]\n",
      "epoch:30 step:28441 [D loss: 0.245704, acc.: 60.16%] [G loss: 0.285976]\n",
      "epoch:30 step:28442 [D loss: 0.240641, acc.: 56.25%] [G loss: 0.279813]\n",
      "epoch:30 step:28443 [D loss: 0.248710, acc.: 57.03%] [G loss: 0.275717]\n",
      "epoch:30 step:28444 [D loss: 0.241005, acc.: 59.38%] [G loss: 0.285476]\n",
      "epoch:30 step:28445 [D loss: 0.233407, acc.: 62.50%] [G loss: 0.301886]\n",
      "epoch:30 step:28446 [D loss: 0.223350, acc.: 66.41%] [G loss: 0.297740]\n",
      "epoch:30 step:28447 [D loss: 0.229753, acc.: 64.06%] [G loss: 0.317945]\n",
      "epoch:30 step:28448 [D loss: 0.242833, acc.: 57.03%] [G loss: 0.291788]\n",
      "epoch:30 step:28449 [D loss: 0.225593, acc.: 63.28%] [G loss: 0.296771]\n",
      "epoch:30 step:28450 [D loss: 0.243251, acc.: 58.59%] [G loss: 0.293147]\n",
      "epoch:30 step:28451 [D loss: 0.254550, acc.: 53.12%] [G loss: 0.313050]\n",
      "epoch:30 step:28452 [D loss: 0.222928, acc.: 63.28%] [G loss: 0.324999]\n",
      "epoch:30 step:28453 [D loss: 0.250091, acc.: 53.91%] [G loss: 0.325164]\n",
      "epoch:30 step:28454 [D loss: 0.255886, acc.: 53.12%] [G loss: 0.298463]\n",
      "epoch:30 step:28455 [D loss: 0.229658, acc.: 63.28%] [G loss: 0.296873]\n",
      "epoch:30 step:28456 [D loss: 0.255746, acc.: 54.69%] [G loss: 0.319040]\n",
      "epoch:30 step:28457 [D loss: 0.235037, acc.: 58.59%] [G loss: 0.267781]\n",
      "epoch:30 step:28458 [D loss: 0.237858, acc.: 57.81%] [G loss: 0.313888]\n",
      "epoch:30 step:28459 [D loss: 0.244286, acc.: 55.47%] [G loss: 0.306994]\n",
      "epoch:30 step:28460 [D loss: 0.240612, acc.: 57.03%] [G loss: 0.277949]\n",
      "epoch:30 step:28461 [D loss: 0.228347, acc.: 60.94%] [G loss: 0.321727]\n",
      "epoch:30 step:28462 [D loss: 0.225506, acc.: 65.62%] [G loss: 0.330069]\n",
      "epoch:30 step:28463 [D loss: 0.237578, acc.: 55.47%] [G loss: 0.304018]\n",
      "epoch:30 step:28464 [D loss: 0.221480, acc.: 66.41%] [G loss: 0.304126]\n",
      "epoch:30 step:28465 [D loss: 0.250775, acc.: 50.78%] [G loss: 0.272114]\n",
      "epoch:30 step:28466 [D loss: 0.218049, acc.: 65.62%] [G loss: 0.283722]\n",
      "epoch:30 step:28467 [D loss: 0.238960, acc.: 57.03%] [G loss: 0.295653]\n",
      "epoch:30 step:28468 [D loss: 0.220208, acc.: 63.28%] [G loss: 0.318881]\n",
      "epoch:30 step:28469 [D loss: 0.239224, acc.: 57.81%] [G loss: 0.337781]\n",
      "epoch:30 step:28470 [D loss: 0.244036, acc.: 53.91%] [G loss: 0.317721]\n",
      "epoch:30 step:28471 [D loss: 0.241270, acc.: 65.62%] [G loss: 0.283248]\n",
      "epoch:30 step:28472 [D loss: 0.249638, acc.: 57.03%] [G loss: 0.284638]\n",
      "epoch:30 step:28473 [D loss: 0.230097, acc.: 62.50%] [G loss: 0.282951]\n",
      "epoch:30 step:28474 [D loss: 0.248589, acc.: 56.25%] [G loss: 0.306470]\n",
      "epoch:30 step:28475 [D loss: 0.244160, acc.: 57.03%] [G loss: 0.321946]\n",
      "epoch:30 step:28476 [D loss: 0.227445, acc.: 60.94%] [G loss: 0.330295]\n",
      "epoch:30 step:28477 [D loss: 0.229290, acc.: 60.94%] [G loss: 0.320664]\n",
      "epoch:30 step:28478 [D loss: 0.240384, acc.: 60.16%] [G loss: 0.288803]\n",
      "epoch:30 step:28479 [D loss: 0.241362, acc.: 57.03%] [G loss: 0.281219]\n",
      "epoch:30 step:28480 [D loss: 0.246125, acc.: 56.25%] [G loss: 0.297336]\n",
      "epoch:30 step:28481 [D loss: 0.228543, acc.: 64.06%] [G loss: 0.314600]\n",
      "epoch:30 step:28482 [D loss: 0.238640, acc.: 57.03%] [G loss: 0.282210]\n",
      "epoch:30 step:28483 [D loss: 0.240761, acc.: 62.50%] [G loss: 0.298265]\n",
      "epoch:30 step:28484 [D loss: 0.252763, acc.: 54.69%] [G loss: 0.294513]\n",
      "epoch:30 step:28485 [D loss: 0.248218, acc.: 53.91%] [G loss: 0.290174]\n",
      "epoch:30 step:28486 [D loss: 0.246570, acc.: 55.47%] [G loss: 0.287933]\n",
      "epoch:30 step:28487 [D loss: 0.217904, acc.: 64.84%] [G loss: 0.271852]\n",
      "epoch:30 step:28488 [D loss: 0.243209, acc.: 57.03%] [G loss: 0.286101]\n",
      "epoch:30 step:28489 [D loss: 0.247606, acc.: 53.12%] [G loss: 0.255286]\n",
      "epoch:30 step:28490 [D loss: 0.246360, acc.: 57.81%] [G loss: 0.267460]\n",
      "epoch:30 step:28491 [D loss: 0.238995, acc.: 61.72%] [G loss: 0.273504]\n",
      "epoch:30 step:28492 [D loss: 0.229930, acc.: 63.28%] [G loss: 0.302630]\n",
      "epoch:30 step:28493 [D loss: 0.225548, acc.: 63.28%] [G loss: 0.284215]\n",
      "epoch:30 step:28494 [D loss: 0.255519, acc.: 58.59%] [G loss: 0.276025]\n",
      "epoch:30 step:28495 [D loss: 0.235575, acc.: 58.59%] [G loss: 0.285798]\n",
      "epoch:30 step:28496 [D loss: 0.241219, acc.: 56.25%] [G loss: 0.283971]\n",
      "epoch:30 step:28497 [D loss: 0.228633, acc.: 60.16%] [G loss: 0.322284]\n",
      "epoch:30 step:28498 [D loss: 0.238417, acc.: 59.38%] [G loss: 0.313781]\n",
      "epoch:30 step:28499 [D loss: 0.253153, acc.: 50.78%] [G loss: 0.281341]\n",
      "epoch:30 step:28500 [D loss: 0.249574, acc.: 56.25%] [G loss: 0.290378]\n",
      "epoch:30 step:28501 [D loss: 0.222683, acc.: 58.59%] [G loss: 0.303887]\n",
      "epoch:30 step:28502 [D loss: 0.245212, acc.: 57.03%] [G loss: 0.313254]\n",
      "epoch:30 step:28503 [D loss: 0.245781, acc.: 55.47%] [G loss: 0.335764]\n",
      "epoch:30 step:28504 [D loss: 0.233857, acc.: 58.59%] [G loss: 0.310060]\n",
      "epoch:30 step:28505 [D loss: 0.226765, acc.: 67.97%] [G loss: 0.289303]\n",
      "epoch:30 step:28506 [D loss: 0.241183, acc.: 54.69%] [G loss: 0.313299]\n",
      "epoch:30 step:28507 [D loss: 0.255373, acc.: 45.31%] [G loss: 0.298994]\n",
      "epoch:30 step:28508 [D loss: 0.230235, acc.: 57.81%] [G loss: 0.290877]\n",
      "epoch:30 step:28509 [D loss: 0.230181, acc.: 61.72%] [G loss: 0.294796]\n",
      "epoch:30 step:28510 [D loss: 0.235492, acc.: 58.59%] [G loss: 0.306179]\n",
      "epoch:30 step:28511 [D loss: 0.241704, acc.: 54.69%] [G loss: 0.291836]\n",
      "epoch:30 step:28512 [D loss: 0.239576, acc.: 60.16%] [G loss: 0.283520]\n",
      "epoch:30 step:28513 [D loss: 0.218974, acc.: 65.62%] [G loss: 0.297505]\n",
      "epoch:30 step:28514 [D loss: 0.232498, acc.: 58.59%] [G loss: 0.281336]\n",
      "epoch:30 step:28515 [D loss: 0.223107, acc.: 64.06%] [G loss: 0.301230]\n",
      "epoch:30 step:28516 [D loss: 0.218195, acc.: 64.06%] [G loss: 0.323844]\n",
      "epoch:30 step:28517 [D loss: 0.231339, acc.: 66.41%] [G loss: 0.299422]\n",
      "epoch:30 step:28518 [D loss: 0.229462, acc.: 65.62%] [G loss: 0.282271]\n",
      "epoch:30 step:28519 [D loss: 0.239386, acc.: 59.38%] [G loss: 0.301777]\n",
      "epoch:30 step:28520 [D loss: 0.259675, acc.: 50.00%] [G loss: 0.298742]\n",
      "epoch:30 step:28521 [D loss: 0.242650, acc.: 58.59%] [G loss: 0.299390]\n",
      "epoch:30 step:28522 [D loss: 0.242824, acc.: 55.47%] [G loss: 0.316202]\n",
      "epoch:30 step:28523 [D loss: 0.231297, acc.: 61.72%] [G loss: 0.257652]\n",
      "epoch:30 step:28524 [D loss: 0.218989, acc.: 65.62%] [G loss: 0.334874]\n",
      "epoch:30 step:28525 [D loss: 0.238645, acc.: 57.81%] [G loss: 0.284394]\n",
      "epoch:30 step:28526 [D loss: 0.232296, acc.: 58.59%] [G loss: 0.290839]\n",
      "epoch:30 step:28527 [D loss: 0.250852, acc.: 53.91%] [G loss: 0.320175]\n",
      "epoch:30 step:28528 [D loss: 0.237327, acc.: 58.59%] [G loss: 0.289428]\n",
      "epoch:30 step:28529 [D loss: 0.220077, acc.: 70.31%] [G loss: 0.325149]\n",
      "epoch:30 step:28530 [D loss: 0.211603, acc.: 68.75%] [G loss: 0.285829]\n",
      "epoch:30 step:28531 [D loss: 0.234919, acc.: 61.72%] [G loss: 0.297828]\n",
      "epoch:30 step:28532 [D loss: 0.237966, acc.: 58.59%] [G loss: 0.284359]\n",
      "epoch:30 step:28533 [D loss: 0.246219, acc.: 57.03%] [G loss: 0.299362]\n",
      "epoch:30 step:28534 [D loss: 0.221259, acc.: 65.62%] [G loss: 0.287255]\n",
      "epoch:30 step:28535 [D loss: 0.252440, acc.: 51.56%] [G loss: 0.264612]\n",
      "epoch:30 step:28536 [D loss: 0.241476, acc.: 57.81%] [G loss: 0.313571]\n",
      "epoch:30 step:28537 [D loss: 0.240176, acc.: 60.94%] [G loss: 0.327042]\n",
      "epoch:30 step:28538 [D loss: 0.244819, acc.: 58.59%] [G loss: 0.316562]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:30 step:28539 [D loss: 0.247682, acc.: 51.56%] [G loss: 0.316624]\n",
      "epoch:30 step:28540 [D loss: 0.247973, acc.: 56.25%] [G loss: 0.278339]\n",
      "epoch:30 step:28541 [D loss: 0.228324, acc.: 61.72%] [G loss: 0.317079]\n",
      "epoch:30 step:28542 [D loss: 0.225967, acc.: 66.41%] [G loss: 0.298626]\n",
      "epoch:30 step:28543 [D loss: 0.228797, acc.: 63.28%] [G loss: 0.302786]\n",
      "epoch:30 step:28544 [D loss: 0.250178, acc.: 60.16%] [G loss: 0.288157]\n",
      "epoch:30 step:28545 [D loss: 0.224662, acc.: 63.28%] [G loss: 0.303127]\n",
      "epoch:30 step:28546 [D loss: 0.255392, acc.: 49.22%] [G loss: 0.309938]\n",
      "epoch:30 step:28547 [D loss: 0.238118, acc.: 60.16%] [G loss: 0.316093]\n",
      "epoch:30 step:28548 [D loss: 0.241734, acc.: 60.94%] [G loss: 0.318826]\n",
      "epoch:30 step:28549 [D loss: 0.215929, acc.: 64.84%] [G loss: 0.275616]\n",
      "epoch:30 step:28550 [D loss: 0.235422, acc.: 60.94%] [G loss: 0.311087]\n",
      "epoch:30 step:28551 [D loss: 0.249986, acc.: 55.47%] [G loss: 0.318301]\n",
      "epoch:30 step:28552 [D loss: 0.243642, acc.: 58.59%] [G loss: 0.292198]\n",
      "epoch:30 step:28553 [D loss: 0.216214, acc.: 67.19%] [G loss: 0.334327]\n",
      "epoch:30 step:28554 [D loss: 0.229102, acc.: 62.50%] [G loss: 0.283069]\n",
      "epoch:30 step:28555 [D loss: 0.246414, acc.: 57.03%] [G loss: 0.301990]\n",
      "epoch:30 step:28556 [D loss: 0.244805, acc.: 53.91%] [G loss: 0.272576]\n",
      "epoch:30 step:28557 [D loss: 0.234542, acc.: 62.50%] [G loss: 0.315123]\n",
      "epoch:30 step:28558 [D loss: 0.231140, acc.: 62.50%] [G loss: 0.309266]\n",
      "epoch:30 step:28559 [D loss: 0.249392, acc.: 56.25%] [G loss: 0.290761]\n",
      "epoch:30 step:28560 [D loss: 0.252835, acc.: 51.56%] [G loss: 0.295780]\n",
      "epoch:30 step:28561 [D loss: 0.237091, acc.: 64.06%] [G loss: 0.271930]\n",
      "epoch:30 step:28562 [D loss: 0.246835, acc.: 57.03%] [G loss: 0.309361]\n",
      "epoch:30 step:28563 [D loss: 0.229419, acc.: 62.50%] [G loss: 0.315210]\n",
      "epoch:30 step:28564 [D loss: 0.231231, acc.: 61.72%] [G loss: 0.300805]\n",
      "epoch:30 step:28565 [D loss: 0.236683, acc.: 58.59%] [G loss: 0.285679]\n",
      "epoch:30 step:28566 [D loss: 0.255519, acc.: 54.69%] [G loss: 0.286865]\n",
      "epoch:30 step:28567 [D loss: 0.260296, acc.: 48.44%] [G loss: 0.295015]\n",
      "epoch:30 step:28568 [D loss: 0.234667, acc.: 57.81%] [G loss: 0.306825]\n",
      "epoch:30 step:28569 [D loss: 0.239560, acc.: 57.81%] [G loss: 0.280361]\n",
      "epoch:30 step:28570 [D loss: 0.232066, acc.: 60.16%] [G loss: 0.274555]\n",
      "epoch:30 step:28571 [D loss: 0.247749, acc.: 53.12%] [G loss: 0.303881]\n",
      "epoch:30 step:28572 [D loss: 0.226419, acc.: 59.38%] [G loss: 0.303010]\n",
      "epoch:30 step:28573 [D loss: 0.251709, acc.: 53.12%] [G loss: 0.287568]\n",
      "epoch:30 step:28574 [D loss: 0.234997, acc.: 60.94%] [G loss: 0.317758]\n",
      "epoch:30 step:28575 [D loss: 0.256658, acc.: 57.03%] [G loss: 0.290168]\n",
      "epoch:30 step:28576 [D loss: 0.242570, acc.: 56.25%] [G loss: 0.285749]\n",
      "epoch:30 step:28577 [D loss: 0.239212, acc.: 56.25%] [G loss: 0.320378]\n",
      "epoch:30 step:28578 [D loss: 0.247521, acc.: 58.59%] [G loss: 0.296763]\n",
      "epoch:30 step:28579 [D loss: 0.238537, acc.: 57.81%] [G loss: 0.288444]\n",
      "epoch:30 step:28580 [D loss: 0.243605, acc.: 57.81%] [G loss: 0.328218]\n",
      "epoch:30 step:28581 [D loss: 0.250959, acc.: 57.81%] [G loss: 0.279125]\n",
      "epoch:30 step:28582 [D loss: 0.248363, acc.: 53.12%] [G loss: 0.294945]\n",
      "epoch:30 step:28583 [D loss: 0.222180, acc.: 61.72%] [G loss: 0.289210]\n",
      "epoch:30 step:28584 [D loss: 0.244222, acc.: 54.69%] [G loss: 0.306059]\n",
      "epoch:30 step:28585 [D loss: 0.226340, acc.: 63.28%] [G loss: 0.308025]\n",
      "epoch:30 step:28586 [D loss: 0.235893, acc.: 60.16%] [G loss: 0.341908]\n",
      "epoch:30 step:28587 [D loss: 0.242364, acc.: 64.06%] [G loss: 0.283885]\n",
      "epoch:30 step:28588 [D loss: 0.248259, acc.: 56.25%] [G loss: 0.285614]\n",
      "epoch:30 step:28589 [D loss: 0.241698, acc.: 53.91%] [G loss: 0.306379]\n",
      "epoch:30 step:28590 [D loss: 0.237295, acc.: 60.94%] [G loss: 0.306313]\n",
      "epoch:30 step:28591 [D loss: 0.255175, acc.: 53.12%] [G loss: 0.312672]\n",
      "epoch:30 step:28592 [D loss: 0.239572, acc.: 55.47%] [G loss: 0.310839]\n",
      "epoch:30 step:28593 [D loss: 0.257370, acc.: 50.78%] [G loss: 0.302075]\n",
      "epoch:30 step:28594 [D loss: 0.231558, acc.: 62.50%] [G loss: 0.287399]\n",
      "epoch:30 step:28595 [D loss: 0.236900, acc.: 60.16%] [G loss: 0.301688]\n",
      "epoch:30 step:28596 [D loss: 0.228971, acc.: 60.16%] [G loss: 0.271669]\n",
      "epoch:30 step:28597 [D loss: 0.230073, acc.: 64.84%] [G loss: 0.314529]\n",
      "epoch:30 step:28598 [D loss: 0.243200, acc.: 59.38%] [G loss: 0.297544]\n",
      "epoch:30 step:28599 [D loss: 0.237439, acc.: 59.38%] [G loss: 0.299641]\n",
      "epoch:30 step:28600 [D loss: 0.239526, acc.: 58.59%] [G loss: 0.318796]\n",
      "epoch:30 step:28601 [D loss: 0.227420, acc.: 59.38%] [G loss: 0.299228]\n",
      "epoch:30 step:28602 [D loss: 0.222742, acc.: 64.06%] [G loss: 0.295334]\n",
      "epoch:30 step:28603 [D loss: 0.235821, acc.: 57.03%] [G loss: 0.297483]\n",
      "epoch:30 step:28604 [D loss: 0.246357, acc.: 53.91%] [G loss: 0.318658]\n",
      "epoch:30 step:28605 [D loss: 0.236505, acc.: 60.94%] [G loss: 0.293294]\n",
      "epoch:30 step:28606 [D loss: 0.239659, acc.: 57.03%] [G loss: 0.325475]\n",
      "epoch:30 step:28607 [D loss: 0.243999, acc.: 56.25%] [G loss: 0.300685]\n",
      "epoch:30 step:28608 [D loss: 0.243346, acc.: 55.47%] [G loss: 0.324936]\n",
      "epoch:30 step:28609 [D loss: 0.254448, acc.: 53.91%] [G loss: 0.289399]\n",
      "epoch:30 step:28610 [D loss: 0.235663, acc.: 60.16%] [G loss: 0.307645]\n",
      "epoch:30 step:28611 [D loss: 0.225029, acc.: 67.19%] [G loss: 0.281105]\n",
      "epoch:30 step:28612 [D loss: 0.246656, acc.: 53.12%] [G loss: 0.304360]\n",
      "epoch:30 step:28613 [D loss: 0.240500, acc.: 53.91%] [G loss: 0.318877]\n",
      "epoch:30 step:28614 [D loss: 0.235207, acc.: 56.25%] [G loss: 0.304695]\n",
      "epoch:30 step:28615 [D loss: 0.225808, acc.: 61.72%] [G loss: 0.320693]\n",
      "epoch:30 step:28616 [D loss: 0.240484, acc.: 60.94%] [G loss: 0.278261]\n",
      "epoch:30 step:28617 [D loss: 0.237214, acc.: 57.81%] [G loss: 0.308401]\n",
      "epoch:30 step:28618 [D loss: 0.232673, acc.: 63.28%] [G loss: 0.323098]\n",
      "epoch:30 step:28619 [D loss: 0.252618, acc.: 53.91%] [G loss: 0.318447]\n",
      "epoch:30 step:28620 [D loss: 0.237252, acc.: 57.03%] [G loss: 0.289017]\n",
      "epoch:30 step:28621 [D loss: 0.230053, acc.: 60.94%] [G loss: 0.284582]\n",
      "epoch:30 step:28622 [D loss: 0.239289, acc.: 57.03%] [G loss: 0.284255]\n",
      "epoch:30 step:28623 [D loss: 0.229400, acc.: 62.50%] [G loss: 0.312464]\n",
      "epoch:30 step:28624 [D loss: 0.242175, acc.: 57.81%] [G loss: 0.309450]\n",
      "epoch:30 step:28625 [D loss: 0.254075, acc.: 55.47%] [G loss: 0.291187]\n",
      "epoch:30 step:28626 [D loss: 0.234560, acc.: 59.38%] [G loss: 0.326967]\n",
      "epoch:30 step:28627 [D loss: 0.237939, acc.: 58.59%] [G loss: 0.312011]\n",
      "epoch:30 step:28628 [D loss: 0.247829, acc.: 54.69%] [G loss: 0.309074]\n",
      "epoch:30 step:28629 [D loss: 0.229481, acc.: 62.50%] [G loss: 0.315080]\n",
      "epoch:30 step:28630 [D loss: 0.234413, acc.: 58.59%] [G loss: 0.322759]\n",
      "epoch:30 step:28631 [D loss: 0.245288, acc.: 57.03%] [G loss: 0.295646]\n",
      "epoch:30 step:28632 [D loss: 0.252418, acc.: 56.25%] [G loss: 0.292550]\n",
      "epoch:30 step:28633 [D loss: 0.252131, acc.: 54.69%] [G loss: 0.301433]\n",
      "epoch:30 step:28634 [D loss: 0.215799, acc.: 67.19%] [G loss: 0.318323]\n",
      "epoch:30 step:28635 [D loss: 0.230139, acc.: 59.38%] [G loss: 0.307016]\n",
      "epoch:30 step:28636 [D loss: 0.251897, acc.: 51.56%] [G loss: 0.289006]\n",
      "epoch:30 step:28637 [D loss: 0.250341, acc.: 52.34%] [G loss: 0.297203]\n",
      "epoch:30 step:28638 [D loss: 0.247801, acc.: 56.25%] [G loss: 0.345339]\n",
      "epoch:30 step:28639 [D loss: 0.238638, acc.: 56.25%] [G loss: 0.305990]\n",
      "epoch:30 step:28640 [D loss: 0.267322, acc.: 47.66%] [G loss: 0.312054]\n",
      "epoch:30 step:28641 [D loss: 0.240020, acc.: 59.38%] [G loss: 0.301134]\n",
      "epoch:30 step:28642 [D loss: 0.236671, acc.: 65.62%] [G loss: 0.292893]\n",
      "epoch:30 step:28643 [D loss: 0.244851, acc.: 56.25%] [G loss: 0.315470]\n",
      "epoch:30 step:28644 [D loss: 0.250874, acc.: 56.25%] [G loss: 0.320007]\n",
      "epoch:30 step:28645 [D loss: 0.243205, acc.: 54.69%] [G loss: 0.292120]\n",
      "epoch:30 step:28646 [D loss: 0.241382, acc.: 59.38%] [G loss: 0.284429]\n",
      "epoch:30 step:28647 [D loss: 0.245630, acc.: 58.59%] [G loss: 0.325699]\n",
      "epoch:30 step:28648 [D loss: 0.262340, acc.: 49.22%] [G loss: 0.276932]\n",
      "epoch:30 step:28649 [D loss: 0.230604, acc.: 66.41%] [G loss: 0.303274]\n",
      "epoch:30 step:28650 [D loss: 0.236346, acc.: 60.16%] [G loss: 0.294385]\n",
      "epoch:30 step:28651 [D loss: 0.220758, acc.: 65.62%] [G loss: 0.315824]\n",
      "epoch:30 step:28652 [D loss: 0.227254, acc.: 61.72%] [G loss: 0.308900]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:30 step:28653 [D loss: 0.226861, acc.: 61.72%] [G loss: 0.291862]\n",
      "epoch:30 step:28654 [D loss: 0.248783, acc.: 57.03%] [G loss: 0.300789]\n",
      "epoch:30 step:28655 [D loss: 0.238299, acc.: 60.94%] [G loss: 0.306679]\n",
      "epoch:30 step:28656 [D loss: 0.224235, acc.: 63.28%] [G loss: 0.309030]\n",
      "epoch:30 step:28657 [D loss: 0.251603, acc.: 56.25%] [G loss: 0.304003]\n",
      "epoch:30 step:28658 [D loss: 0.234129, acc.: 55.47%] [G loss: 0.297197]\n",
      "epoch:30 step:28659 [D loss: 0.252270, acc.: 54.69%] [G loss: 0.316874]\n",
      "epoch:30 step:28660 [D loss: 0.225145, acc.: 61.72%] [G loss: 0.312048]\n",
      "epoch:30 step:28661 [D loss: 0.244609, acc.: 54.69%] [G loss: 0.329205]\n",
      "epoch:30 step:28662 [D loss: 0.255733, acc.: 57.03%] [G loss: 0.279533]\n",
      "epoch:30 step:28663 [D loss: 0.236842, acc.: 60.94%] [G loss: 0.311242]\n",
      "epoch:30 step:28664 [D loss: 0.243519, acc.: 54.69%] [G loss: 0.308937]\n",
      "epoch:30 step:28665 [D loss: 0.240905, acc.: 58.59%] [G loss: 0.280873]\n",
      "epoch:30 step:28666 [D loss: 0.254936, acc.: 47.66%] [G loss: 0.267086]\n",
      "epoch:30 step:28667 [D loss: 0.238468, acc.: 63.28%] [G loss: 0.288875]\n",
      "epoch:30 step:28668 [D loss: 0.231616, acc.: 60.94%] [G loss: 0.294499]\n",
      "epoch:30 step:28669 [D loss: 0.257115, acc.: 53.91%] [G loss: 0.311644]\n",
      "epoch:30 step:28670 [D loss: 0.252410, acc.: 55.47%] [G loss: 0.282280]\n",
      "epoch:30 step:28671 [D loss: 0.236493, acc.: 62.50%] [G loss: 0.308917]\n",
      "epoch:30 step:28672 [D loss: 0.263021, acc.: 49.22%] [G loss: 0.297446]\n",
      "epoch:30 step:28673 [D loss: 0.229178, acc.: 60.16%] [G loss: 0.288621]\n",
      "epoch:30 step:28674 [D loss: 0.227244, acc.: 62.50%] [G loss: 0.299319]\n",
      "epoch:30 step:28675 [D loss: 0.238494, acc.: 55.47%] [G loss: 0.325518]\n",
      "epoch:30 step:28676 [D loss: 0.235201, acc.: 62.50%] [G loss: 0.277255]\n",
      "epoch:30 step:28677 [D loss: 0.240964, acc.: 57.81%] [G loss: 0.308719]\n",
      "epoch:30 step:28678 [D loss: 0.251907, acc.: 57.81%] [G loss: 0.301546]\n",
      "epoch:30 step:28679 [D loss: 0.220674, acc.: 61.72%] [G loss: 0.320980]\n",
      "epoch:30 step:28680 [D loss: 0.261317, acc.: 45.31%] [G loss: 0.328817]\n",
      "epoch:30 step:28681 [D loss: 0.227692, acc.: 60.94%] [G loss: 0.303337]\n",
      "epoch:30 step:28682 [D loss: 0.235452, acc.: 53.91%] [G loss: 0.291223]\n",
      "epoch:30 step:28683 [D loss: 0.255434, acc.: 53.12%] [G loss: 0.289474]\n",
      "epoch:30 step:28684 [D loss: 0.238221, acc.: 57.03%] [G loss: 0.258331]\n",
      "epoch:30 step:28685 [D loss: 0.248381, acc.: 55.47%] [G loss: 0.289242]\n",
      "epoch:30 step:28686 [D loss: 0.241799, acc.: 51.56%] [G loss: 0.307186]\n",
      "epoch:30 step:28687 [D loss: 0.246623, acc.: 57.03%] [G loss: 0.292247]\n",
      "epoch:30 step:28688 [D loss: 0.236531, acc.: 59.38%] [G loss: 0.284120]\n",
      "epoch:30 step:28689 [D loss: 0.230152, acc.: 60.94%] [G loss: 0.306224]\n",
      "epoch:30 step:28690 [D loss: 0.237175, acc.: 64.06%] [G loss: 0.304068]\n",
      "epoch:30 step:28691 [D loss: 0.240692, acc.: 57.81%] [G loss: 0.307269]\n",
      "epoch:30 step:28692 [D loss: 0.238780, acc.: 57.03%] [G loss: 0.294386]\n",
      "epoch:30 step:28693 [D loss: 0.229269, acc.: 59.38%] [G loss: 0.281245]\n",
      "epoch:30 step:28694 [D loss: 0.257949, acc.: 50.78%] [G loss: 0.304655]\n",
      "epoch:30 step:28695 [D loss: 0.243394, acc.: 57.03%] [G loss: 0.293562]\n",
      "epoch:30 step:28696 [D loss: 0.230466, acc.: 62.50%] [G loss: 0.308811]\n",
      "epoch:30 step:28697 [D loss: 0.247375, acc.: 53.12%] [G loss: 0.286841]\n",
      "epoch:30 step:28698 [D loss: 0.241174, acc.: 51.56%] [G loss: 0.327814]\n",
      "epoch:30 step:28699 [D loss: 0.232107, acc.: 60.16%] [G loss: 0.293063]\n",
      "epoch:30 step:28700 [D loss: 0.234712, acc.: 55.47%] [G loss: 0.306582]\n",
      "epoch:30 step:28701 [D loss: 0.231749, acc.: 62.50%] [G loss: 0.296573]\n",
      "epoch:30 step:28702 [D loss: 0.235475, acc.: 57.03%] [G loss: 0.300130]\n",
      "epoch:30 step:28703 [D loss: 0.244731, acc.: 53.12%] [G loss: 0.310121]\n",
      "epoch:30 step:28704 [D loss: 0.231491, acc.: 60.94%] [G loss: 0.282667]\n",
      "epoch:30 step:28705 [D loss: 0.241412, acc.: 50.00%] [G loss: 0.273592]\n",
      "epoch:30 step:28706 [D loss: 0.242021, acc.: 60.94%] [G loss: 0.310460]\n",
      "epoch:30 step:28707 [D loss: 0.246671, acc.: 53.12%] [G loss: 0.306667]\n",
      "epoch:30 step:28708 [D loss: 0.251931, acc.: 56.25%] [G loss: 0.316109]\n",
      "epoch:30 step:28709 [D loss: 0.229447, acc.: 63.28%] [G loss: 0.329315]\n",
      "epoch:30 step:28710 [D loss: 0.228498, acc.: 60.94%] [G loss: 0.285578]\n",
      "epoch:30 step:28711 [D loss: 0.250602, acc.: 53.91%] [G loss: 0.284408]\n",
      "epoch:30 step:28712 [D loss: 0.231059, acc.: 60.94%] [G loss: 0.298032]\n",
      "epoch:30 step:28713 [D loss: 0.242156, acc.: 58.59%] [G loss: 0.278955]\n",
      "epoch:30 step:28714 [D loss: 0.252324, acc.: 53.91%] [G loss: 0.274328]\n",
      "epoch:30 step:28715 [D loss: 0.248557, acc.: 51.56%] [G loss: 0.308595]\n",
      "epoch:30 step:28716 [D loss: 0.269400, acc.: 50.78%] [G loss: 0.290039]\n",
      "epoch:30 step:28717 [D loss: 0.237938, acc.: 57.03%] [G loss: 0.323981]\n",
      "epoch:30 step:28718 [D loss: 0.247695, acc.: 58.59%] [G loss: 0.321295]\n",
      "epoch:30 step:28719 [D loss: 0.222898, acc.: 64.84%] [G loss: 0.326139]\n",
      "epoch:30 step:28720 [D loss: 0.231073, acc.: 61.72%] [G loss: 0.335587]\n",
      "epoch:30 step:28721 [D loss: 0.238723, acc.: 57.81%] [G loss: 0.299348]\n",
      "epoch:30 step:28722 [D loss: 0.233375, acc.: 60.94%] [G loss: 0.299561]\n",
      "epoch:30 step:28723 [D loss: 0.224157, acc.: 64.06%] [G loss: 0.329128]\n",
      "epoch:30 step:28724 [D loss: 0.238356, acc.: 57.03%] [G loss: 0.296214]\n",
      "epoch:30 step:28725 [D loss: 0.223610, acc.: 65.62%] [G loss: 0.303426]\n",
      "epoch:30 step:28726 [D loss: 0.227184, acc.: 64.84%] [G loss: 0.304291]\n",
      "epoch:30 step:28727 [D loss: 0.231174, acc.: 60.16%] [G loss: 0.313200]\n",
      "epoch:30 step:28728 [D loss: 0.244707, acc.: 57.81%] [G loss: 0.293645]\n",
      "epoch:30 step:28729 [D loss: 0.240313, acc.: 57.03%] [G loss: 0.289959]\n",
      "epoch:30 step:28730 [D loss: 0.239845, acc.: 53.12%] [G loss: 0.323348]\n",
      "epoch:30 step:28731 [D loss: 0.254428, acc.: 52.34%] [G loss: 0.277280]\n",
      "epoch:30 step:28732 [D loss: 0.233909, acc.: 61.72%] [G loss: 0.305349]\n",
      "epoch:30 step:28733 [D loss: 0.238105, acc.: 60.16%] [G loss: 0.300276]\n",
      "epoch:30 step:28734 [D loss: 0.236734, acc.: 63.28%] [G loss: 0.283401]\n",
      "epoch:30 step:28735 [D loss: 0.250143, acc.: 58.59%] [G loss: 0.297241]\n",
      "epoch:30 step:28736 [D loss: 0.251934, acc.: 53.91%] [G loss: 0.306105]\n",
      "epoch:30 step:28737 [D loss: 0.227188, acc.: 63.28%] [G loss: 0.320122]\n",
      "epoch:30 step:28738 [D loss: 0.252441, acc.: 51.56%] [G loss: 0.313514]\n",
      "epoch:30 step:28739 [D loss: 0.248733, acc.: 55.47%] [G loss: 0.287959]\n",
      "epoch:30 step:28740 [D loss: 0.238410, acc.: 61.72%] [G loss: 0.286155]\n",
      "epoch:30 step:28741 [D loss: 0.224095, acc.: 62.50%] [G loss: 0.317412]\n",
      "epoch:30 step:28742 [D loss: 0.230771, acc.: 61.72%] [G loss: 0.310936]\n",
      "epoch:30 step:28743 [D loss: 0.225662, acc.: 60.94%] [G loss: 0.315602]\n",
      "epoch:30 step:28744 [D loss: 0.239294, acc.: 53.91%] [G loss: 0.307145]\n",
      "epoch:30 step:28745 [D loss: 0.226610, acc.: 63.28%] [G loss: 0.302376]\n",
      "epoch:30 step:28746 [D loss: 0.222583, acc.: 65.62%] [G loss: 0.348071]\n",
      "epoch:30 step:28747 [D loss: 0.242510, acc.: 55.47%] [G loss: 0.293075]\n",
      "epoch:30 step:28748 [D loss: 0.237360, acc.: 61.72%] [G loss: 0.298547]\n",
      "epoch:30 step:28749 [D loss: 0.265255, acc.: 50.00%] [G loss: 0.278253]\n",
      "epoch:30 step:28750 [D loss: 0.243093, acc.: 57.03%] [G loss: 0.293784]\n",
      "epoch:30 step:28751 [D loss: 0.249488, acc.: 56.25%] [G loss: 0.289556]\n",
      "epoch:30 step:28752 [D loss: 0.240658, acc.: 57.03%] [G loss: 0.313375]\n",
      "epoch:30 step:28753 [D loss: 0.245450, acc.: 56.25%] [G loss: 0.304611]\n",
      "epoch:30 step:28754 [D loss: 0.235913, acc.: 61.72%] [G loss: 0.288910]\n",
      "epoch:30 step:28755 [D loss: 0.237492, acc.: 61.72%] [G loss: 0.307443]\n",
      "epoch:30 step:28756 [D loss: 0.251690, acc.: 53.12%] [G loss: 0.282403]\n",
      "epoch:30 step:28757 [D loss: 0.233218, acc.: 57.03%] [G loss: 0.295648]\n",
      "epoch:30 step:28758 [D loss: 0.226931, acc.: 64.84%] [G loss: 0.314679]\n",
      "epoch:30 step:28759 [D loss: 0.223817, acc.: 65.62%] [G loss: 0.283236]\n",
      "epoch:30 step:28760 [D loss: 0.237268, acc.: 56.25%] [G loss: 0.267364]\n",
      "epoch:30 step:28761 [D loss: 0.244414, acc.: 56.25%] [G loss: 0.299673]\n",
      "epoch:30 step:28762 [D loss: 0.244758, acc.: 57.81%] [G loss: 0.295558]\n",
      "epoch:30 step:28763 [D loss: 0.242058, acc.: 57.81%] [G loss: 0.305500]\n",
      "epoch:30 step:28764 [D loss: 0.244795, acc.: 58.59%] [G loss: 0.288234]\n",
      "epoch:30 step:28765 [D loss: 0.236077, acc.: 58.59%] [G loss: 0.310994]\n",
      "epoch:30 step:28766 [D loss: 0.230436, acc.: 61.72%] [G loss: 0.294505]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:30 step:28767 [D loss: 0.246787, acc.: 55.47%] [G loss: 0.334649]\n",
      "epoch:30 step:28768 [D loss: 0.249640, acc.: 53.91%] [G loss: 0.309377]\n",
      "epoch:30 step:28769 [D loss: 0.228809, acc.: 62.50%] [G loss: 0.319310]\n",
      "epoch:30 step:28770 [D loss: 0.220960, acc.: 66.41%] [G loss: 0.305624]\n",
      "epoch:30 step:28771 [D loss: 0.248759, acc.: 53.12%] [G loss: 0.283293]\n",
      "epoch:30 step:28772 [D loss: 0.243848, acc.: 56.25%] [G loss: 0.297897]\n",
      "epoch:30 step:28773 [D loss: 0.242209, acc.: 57.03%] [G loss: 0.302984]\n",
      "epoch:30 step:28774 [D loss: 0.247930, acc.: 56.25%] [G loss: 0.328291]\n",
      "epoch:30 step:28775 [D loss: 0.263958, acc.: 47.66%] [G loss: 0.273226]\n",
      "epoch:30 step:28776 [D loss: 0.239493, acc.: 55.47%] [G loss: 0.255571]\n",
      "epoch:30 step:28777 [D loss: 0.240675, acc.: 55.47%] [G loss: 0.304085]\n",
      "epoch:30 step:28778 [D loss: 0.244770, acc.: 58.59%] [G loss: 0.287359]\n",
      "epoch:30 step:28779 [D loss: 0.233814, acc.: 57.81%] [G loss: 0.287974]\n",
      "epoch:30 step:28780 [D loss: 0.235835, acc.: 63.28%] [G loss: 0.316285]\n",
      "epoch:30 step:28781 [D loss: 0.230922, acc.: 67.19%] [G loss: 0.289168]\n",
      "epoch:30 step:28782 [D loss: 0.229637, acc.: 61.72%] [G loss: 0.297282]\n",
      "epoch:30 step:28783 [D loss: 0.247852, acc.: 55.47%] [G loss: 0.302121]\n",
      "epoch:30 step:28784 [D loss: 0.226853, acc.: 60.94%] [G loss: 0.295893]\n",
      "epoch:30 step:28785 [D loss: 0.239426, acc.: 56.25%] [G loss: 0.327504]\n",
      "epoch:30 step:28786 [D loss: 0.229715, acc.: 64.84%] [G loss: 0.316180]\n",
      "epoch:30 step:28787 [D loss: 0.225608, acc.: 63.28%] [G loss: 0.314073]\n",
      "epoch:30 step:28788 [D loss: 0.241237, acc.: 57.03%] [G loss: 0.298229]\n",
      "epoch:30 step:28789 [D loss: 0.241823, acc.: 59.38%] [G loss: 0.296690]\n",
      "epoch:30 step:28790 [D loss: 0.234344, acc.: 60.16%] [G loss: 0.310620]\n",
      "epoch:30 step:28791 [D loss: 0.230788, acc.: 61.72%] [G loss: 0.332584]\n",
      "epoch:30 step:28792 [D loss: 0.237594, acc.: 55.47%] [G loss: 0.289864]\n",
      "epoch:30 step:28793 [D loss: 0.253423, acc.: 52.34%] [G loss: 0.272666]\n",
      "epoch:30 step:28794 [D loss: 0.228634, acc.: 60.16%] [G loss: 0.301119]\n",
      "epoch:30 step:28795 [D loss: 0.225534, acc.: 60.16%] [G loss: 0.315626]\n",
      "epoch:30 step:28796 [D loss: 0.247871, acc.: 53.12%] [G loss: 0.279034]\n",
      "epoch:30 step:28797 [D loss: 0.243899, acc.: 59.38%] [G loss: 0.315070]\n",
      "epoch:30 step:28798 [D loss: 0.256022, acc.: 53.12%] [G loss: 0.289279]\n",
      "epoch:30 step:28799 [D loss: 0.258351, acc.: 52.34%] [G loss: 0.301133]\n",
      "epoch:30 step:28800 [D loss: 0.239276, acc.: 57.81%] [G loss: 0.297751]\n",
      "epoch:30 step:28801 [D loss: 0.233338, acc.: 60.16%] [G loss: 0.302714]\n",
      "epoch:30 step:28802 [D loss: 0.228546, acc.: 65.62%] [G loss: 0.291567]\n",
      "epoch:30 step:28803 [D loss: 0.231914, acc.: 60.94%] [G loss: 0.307080]\n",
      "epoch:30 step:28804 [D loss: 0.231702, acc.: 60.16%] [G loss: 0.250540]\n",
      "epoch:30 step:28805 [D loss: 0.238413, acc.: 63.28%] [G loss: 0.295043]\n",
      "epoch:30 step:28806 [D loss: 0.249814, acc.: 54.69%] [G loss: 0.277243]\n",
      "epoch:30 step:28807 [D loss: 0.235445, acc.: 62.50%] [G loss: 0.273416]\n",
      "epoch:30 step:28808 [D loss: 0.241612, acc.: 54.69%] [G loss: 0.261960]\n",
      "epoch:30 step:28809 [D loss: 0.251775, acc.: 55.47%] [G loss: 0.316497]\n",
      "epoch:30 step:28810 [D loss: 0.243077, acc.: 59.38%] [G loss: 0.295661]\n",
      "epoch:30 step:28811 [D loss: 0.225728, acc.: 64.06%] [G loss: 0.281227]\n",
      "epoch:30 step:28812 [D loss: 0.258066, acc.: 48.44%] [G loss: 0.292906]\n",
      "epoch:30 step:28813 [D loss: 0.228675, acc.: 60.16%] [G loss: 0.300492]\n",
      "epoch:30 step:28814 [D loss: 0.252268, acc.: 51.56%] [G loss: 0.315497]\n",
      "epoch:30 step:28815 [D loss: 0.231546, acc.: 61.72%] [G loss: 0.312166]\n",
      "epoch:30 step:28816 [D loss: 0.245084, acc.: 57.81%] [G loss: 0.289471]\n",
      "epoch:30 step:28817 [D loss: 0.222852, acc.: 64.06%] [G loss: 0.297400]\n",
      "epoch:30 step:28818 [D loss: 0.237759, acc.: 59.38%] [G loss: 0.305811]\n",
      "epoch:30 step:28819 [D loss: 0.261006, acc.: 49.22%] [G loss: 0.290636]\n",
      "epoch:30 step:28820 [D loss: 0.234872, acc.: 58.59%] [G loss: 0.295815]\n",
      "epoch:30 step:28821 [D loss: 0.231726, acc.: 60.94%] [G loss: 0.304057]\n",
      "epoch:30 step:28822 [D loss: 0.234378, acc.: 57.81%] [G loss: 0.335630]\n",
      "epoch:30 step:28823 [D loss: 0.240949, acc.: 57.03%] [G loss: 0.299059]\n",
      "epoch:30 step:28824 [D loss: 0.229571, acc.: 66.41%] [G loss: 0.288465]\n",
      "epoch:30 step:28825 [D loss: 0.253372, acc.: 56.25%] [G loss: 0.312138]\n",
      "epoch:30 step:28826 [D loss: 0.234943, acc.: 55.47%] [G loss: 0.291105]\n",
      "epoch:30 step:28827 [D loss: 0.236931, acc.: 58.59%] [G loss: 0.293529]\n",
      "epoch:30 step:28828 [D loss: 0.219640, acc.: 66.41%] [G loss: 0.309564]\n",
      "epoch:30 step:28829 [D loss: 0.249696, acc.: 53.12%] [G loss: 0.286741]\n",
      "epoch:30 step:28830 [D loss: 0.225953, acc.: 64.06%] [G loss: 0.327821]\n",
      "epoch:30 step:28831 [D loss: 0.220611, acc.: 65.62%] [G loss: 0.300074]\n",
      "epoch:30 step:28832 [D loss: 0.244322, acc.: 50.78%] [G loss: 0.306669]\n",
      "epoch:30 step:28833 [D loss: 0.233890, acc.: 57.03%] [G loss: 0.339291]\n",
      "epoch:30 step:28834 [D loss: 0.237045, acc.: 56.25%] [G loss: 0.307615]\n",
      "epoch:30 step:28835 [D loss: 0.240228, acc.: 53.12%] [G loss: 0.316027]\n",
      "epoch:30 step:28836 [D loss: 0.248165, acc.: 58.59%] [G loss: 0.310292]\n",
      "epoch:30 step:28837 [D loss: 0.214894, acc.: 65.62%] [G loss: 0.282586]\n",
      "epoch:30 step:28838 [D loss: 0.230948, acc.: 64.06%] [G loss: 0.332144]\n",
      "epoch:30 step:28839 [D loss: 0.231670, acc.: 60.16%] [G loss: 0.287125]\n",
      "epoch:30 step:28840 [D loss: 0.238757, acc.: 57.03%] [G loss: 0.314547]\n",
      "epoch:30 step:28841 [D loss: 0.229293, acc.: 63.28%] [G loss: 0.318334]\n",
      "epoch:30 step:28842 [D loss: 0.232956, acc.: 59.38%] [G loss: 0.285766]\n",
      "epoch:30 step:28843 [D loss: 0.210448, acc.: 68.75%] [G loss: 0.307641]\n",
      "epoch:30 step:28844 [D loss: 0.246349, acc.: 57.81%] [G loss: 0.307282]\n",
      "epoch:30 step:28845 [D loss: 0.237474, acc.: 57.81%] [G loss: 0.293178]\n",
      "epoch:30 step:28846 [D loss: 0.229966, acc.: 58.59%] [G loss: 0.334857]\n",
      "epoch:30 step:28847 [D loss: 0.246515, acc.: 53.12%] [G loss: 0.281509]\n",
      "epoch:30 step:28848 [D loss: 0.245159, acc.: 57.81%] [G loss: 0.288144]\n",
      "epoch:30 step:28849 [D loss: 0.238004, acc.: 54.69%] [G loss: 0.320105]\n",
      "epoch:30 step:28850 [D loss: 0.238822, acc.: 52.34%] [G loss: 0.296731]\n",
      "epoch:30 step:28851 [D loss: 0.251121, acc.: 52.34%] [G loss: 0.263543]\n",
      "epoch:30 step:28852 [D loss: 0.234725, acc.: 63.28%] [G loss: 0.324564]\n",
      "epoch:30 step:28853 [D loss: 0.263457, acc.: 47.66%] [G loss: 0.304424]\n",
      "epoch:30 step:28854 [D loss: 0.241211, acc.: 57.03%] [G loss: 0.292235]\n",
      "epoch:30 step:28855 [D loss: 0.220729, acc.: 63.28%] [G loss: 0.337270]\n",
      "epoch:30 step:28856 [D loss: 0.227094, acc.: 64.84%] [G loss: 0.291451]\n",
      "epoch:30 step:28857 [D loss: 0.254090, acc.: 53.91%] [G loss: 0.301169]\n",
      "epoch:30 step:28858 [D loss: 0.235066, acc.: 66.41%] [G loss: 0.316397]\n",
      "epoch:30 step:28859 [D loss: 0.235480, acc.: 59.38%] [G loss: 0.273197]\n",
      "epoch:30 step:28860 [D loss: 0.242888, acc.: 55.47%] [G loss: 0.289736]\n",
      "epoch:30 step:28861 [D loss: 0.237508, acc.: 53.91%] [G loss: 0.270611]\n",
      "epoch:30 step:28862 [D loss: 0.221234, acc.: 64.84%] [G loss: 0.301984]\n",
      "epoch:30 step:28863 [D loss: 0.237407, acc.: 55.47%] [G loss: 0.315913]\n",
      "epoch:30 step:28864 [D loss: 0.218641, acc.: 66.41%] [G loss: 0.319188]\n",
      "epoch:30 step:28865 [D loss: 0.226405, acc.: 63.28%] [G loss: 0.316876]\n",
      "epoch:30 step:28866 [D loss: 0.249234, acc.: 54.69%] [G loss: 0.313114]\n",
      "epoch:30 step:28867 [D loss: 0.231181, acc.: 62.50%] [G loss: 0.281304]\n",
      "epoch:30 step:28868 [D loss: 0.249735, acc.: 55.47%] [G loss: 0.301624]\n",
      "epoch:30 step:28869 [D loss: 0.233784, acc.: 60.94%] [G loss: 0.277726]\n",
      "epoch:30 step:28870 [D loss: 0.252288, acc.: 53.91%] [G loss: 0.283464]\n",
      "epoch:30 step:28871 [D loss: 0.255885, acc.: 53.91%] [G loss: 0.275998]\n",
      "epoch:30 step:28872 [D loss: 0.231279, acc.: 59.38%] [G loss: 0.317327]\n",
      "epoch:30 step:28873 [D loss: 0.259012, acc.: 50.78%] [G loss: 0.293615]\n",
      "epoch:30 step:28874 [D loss: 0.238275, acc.: 56.25%] [G loss: 0.302299]\n",
      "epoch:30 step:28875 [D loss: 0.230381, acc.: 59.38%] [G loss: 0.272118]\n",
      "epoch:30 step:28876 [D loss: 0.245520, acc.: 54.69%] [G loss: 0.283220]\n",
      "epoch:30 step:28877 [D loss: 0.244886, acc.: 59.38%] [G loss: 0.323798]\n",
      "epoch:30 step:28878 [D loss: 0.242539, acc.: 56.25%] [G loss: 0.265253]\n",
      "epoch:30 step:28879 [D loss: 0.243749, acc.: 55.47%] [G loss: 0.323282]\n",
      "epoch:30 step:28880 [D loss: 0.226796, acc.: 64.06%] [G loss: 0.303969]\n",
      "epoch:30 step:28881 [D loss: 0.229867, acc.: 62.50%] [G loss: 0.303050]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:30 step:28882 [D loss: 0.249370, acc.: 58.59%] [G loss: 0.298064]\n",
      "epoch:30 step:28883 [D loss: 0.242205, acc.: 60.16%] [G loss: 0.290108]\n",
      "epoch:30 step:28884 [D loss: 0.224341, acc.: 59.38%] [G loss: 0.295048]\n",
      "epoch:30 step:28885 [D loss: 0.220601, acc.: 60.16%] [G loss: 0.288023]\n",
      "epoch:30 step:28886 [D loss: 0.225532, acc.: 59.38%] [G loss: 0.311704]\n",
      "epoch:30 step:28887 [D loss: 0.233742, acc.: 57.81%] [G loss: 0.292395]\n",
      "epoch:30 step:28888 [D loss: 0.240501, acc.: 57.81%] [G loss: 0.304686]\n",
      "epoch:30 step:28889 [D loss: 0.240941, acc.: 58.59%] [G loss: 0.302816]\n",
      "epoch:30 step:28890 [D loss: 0.240520, acc.: 59.38%] [G loss: 0.308652]\n",
      "epoch:30 step:28891 [D loss: 0.246400, acc.: 57.81%] [G loss: 0.335086]\n",
      "epoch:30 step:28892 [D loss: 0.235964, acc.: 58.59%] [G loss: 0.296868]\n",
      "epoch:30 step:28893 [D loss: 0.244269, acc.: 61.72%] [G loss: 0.307117]\n",
      "epoch:30 step:28894 [D loss: 0.245148, acc.: 54.69%] [G loss: 0.323550]\n",
      "epoch:30 step:28895 [D loss: 0.220846, acc.: 64.84%] [G loss: 0.307870]\n",
      "epoch:30 step:28896 [D loss: 0.243654, acc.: 54.69%] [G loss: 0.298088]\n",
      "epoch:30 step:28897 [D loss: 0.204888, acc.: 71.88%] [G loss: 0.319896]\n",
      "epoch:30 step:28898 [D loss: 0.235848, acc.: 58.59%] [G loss: 0.315026]\n",
      "epoch:30 step:28899 [D loss: 0.245471, acc.: 56.25%] [G loss: 0.294268]\n",
      "epoch:30 step:28900 [D loss: 0.233485, acc.: 57.03%] [G loss: 0.297749]\n",
      "epoch:30 step:28901 [D loss: 0.247097, acc.: 56.25%] [G loss: 0.280385]\n",
      "epoch:30 step:28902 [D loss: 0.253059, acc.: 53.91%] [G loss: 0.303150]\n",
      "epoch:30 step:28903 [D loss: 0.238035, acc.: 58.59%] [G loss: 0.284450]\n",
      "epoch:30 step:28904 [D loss: 0.236414, acc.: 64.06%] [G loss: 0.291731]\n",
      "epoch:30 step:28905 [D loss: 0.228321, acc.: 60.94%] [G loss: 0.305403]\n",
      "epoch:30 step:28906 [D loss: 0.241497, acc.: 57.81%] [G loss: 0.290544]\n",
      "epoch:30 step:28907 [D loss: 0.243194, acc.: 57.81%] [G loss: 0.310241]\n",
      "epoch:30 step:28908 [D loss: 0.250563, acc.: 59.38%] [G loss: 0.287570]\n",
      "epoch:30 step:28909 [D loss: 0.233400, acc.: 58.59%] [G loss: 0.312661]\n",
      "epoch:30 step:28910 [D loss: 0.233709, acc.: 59.38%] [G loss: 0.293173]\n",
      "epoch:30 step:28911 [D loss: 0.234910, acc.: 58.59%] [G loss: 0.305099]\n",
      "epoch:30 step:28912 [D loss: 0.255696, acc.: 56.25%] [G loss: 0.294964]\n",
      "epoch:30 step:28913 [D loss: 0.225153, acc.: 62.50%] [G loss: 0.285962]\n",
      "epoch:30 step:28914 [D loss: 0.228312, acc.: 60.16%] [G loss: 0.311841]\n",
      "epoch:30 step:28915 [D loss: 0.261557, acc.: 53.91%] [G loss: 0.311731]\n",
      "epoch:30 step:28916 [D loss: 0.229034, acc.: 60.94%] [G loss: 0.292108]\n",
      "epoch:30 step:28917 [D loss: 0.225652, acc.: 60.16%] [G loss: 0.303415]\n",
      "epoch:30 step:28918 [D loss: 0.217677, acc.: 67.19%] [G loss: 0.309705]\n",
      "epoch:30 step:28919 [D loss: 0.251150, acc.: 53.91%] [G loss: 0.290674]\n",
      "epoch:30 step:28920 [D loss: 0.230482, acc.: 59.38%] [G loss: 0.296881]\n",
      "epoch:30 step:28921 [D loss: 0.241468, acc.: 57.03%] [G loss: 0.291121]\n",
      "epoch:30 step:28922 [D loss: 0.253025, acc.: 56.25%] [G loss: 0.312187]\n",
      "epoch:30 step:28923 [D loss: 0.234144, acc.: 62.50%] [G loss: 0.277339]\n",
      "epoch:30 step:28924 [D loss: 0.223337, acc.: 65.62%] [G loss: 0.316190]\n",
      "epoch:30 step:28925 [D loss: 0.230245, acc.: 64.84%] [G loss: 0.310012]\n",
      "epoch:30 step:28926 [D loss: 0.232167, acc.: 64.06%] [G loss: 0.290687]\n",
      "epoch:30 step:28927 [D loss: 0.245553, acc.: 57.03%] [G loss: 0.294556]\n",
      "epoch:30 step:28928 [D loss: 0.225134, acc.: 62.50%] [G loss: 0.291951]\n",
      "epoch:30 step:28929 [D loss: 0.248297, acc.: 57.81%] [G loss: 0.272488]\n",
      "epoch:30 step:28930 [D loss: 0.236615, acc.: 59.38%] [G loss: 0.299257]\n",
      "epoch:30 step:28931 [D loss: 0.236984, acc.: 54.69%] [G loss: 0.289586]\n",
      "epoch:30 step:28932 [D loss: 0.252568, acc.: 55.47%] [G loss: 0.274034]\n",
      "epoch:30 step:28933 [D loss: 0.243576, acc.: 60.94%] [G loss: 0.294633]\n",
      "epoch:30 step:28934 [D loss: 0.238410, acc.: 57.81%] [G loss: 0.282603]\n",
      "epoch:30 step:28935 [D loss: 0.247224, acc.: 54.69%] [G loss: 0.301694]\n",
      "epoch:30 step:28936 [D loss: 0.247528, acc.: 55.47%] [G loss: 0.322197]\n",
      "epoch:30 step:28937 [D loss: 0.257250, acc.: 54.69%] [G loss: 0.279036]\n",
      "epoch:30 step:28938 [D loss: 0.252276, acc.: 50.78%] [G loss: 0.304495]\n",
      "epoch:30 step:28939 [D loss: 0.230738, acc.: 56.25%] [G loss: 0.314752]\n",
      "epoch:30 step:28940 [D loss: 0.241521, acc.: 56.25%] [G loss: 0.298789]\n",
      "epoch:30 step:28941 [D loss: 0.238904, acc.: 54.69%] [G loss: 0.334502]\n",
      "epoch:30 step:28942 [D loss: 0.229742, acc.: 60.94%] [G loss: 0.312630]\n",
      "epoch:30 step:28943 [D loss: 0.238990, acc.: 60.16%] [G loss: 0.294395]\n",
      "epoch:30 step:28944 [D loss: 0.223523, acc.: 61.72%] [G loss: 0.281548]\n",
      "epoch:30 step:28945 [D loss: 0.257740, acc.: 50.78%] [G loss: 0.299349]\n",
      "epoch:30 step:28946 [D loss: 0.247802, acc.: 60.16%] [G loss: 0.298230]\n",
      "epoch:30 step:28947 [D loss: 0.239662, acc.: 62.50%] [G loss: 0.297935]\n",
      "epoch:30 step:28948 [D loss: 0.246110, acc.: 53.12%] [G loss: 0.317392]\n",
      "epoch:30 step:28949 [D loss: 0.258325, acc.: 54.69%] [G loss: 0.327081]\n",
      "epoch:30 step:28950 [D loss: 0.225794, acc.: 58.59%] [G loss: 0.300397]\n",
      "epoch:30 step:28951 [D loss: 0.226907, acc.: 61.72%] [G loss: 0.310226]\n",
      "epoch:30 step:28952 [D loss: 0.229074, acc.: 60.94%] [G loss: 0.315164]\n",
      "epoch:30 step:28953 [D loss: 0.231097, acc.: 58.59%] [G loss: 0.319371]\n",
      "epoch:30 step:28954 [D loss: 0.267590, acc.: 40.62%] [G loss: 0.311006]\n",
      "epoch:30 step:28955 [D loss: 0.231502, acc.: 63.28%] [G loss: 0.300869]\n",
      "epoch:30 step:28956 [D loss: 0.260633, acc.: 50.00%] [G loss: 0.265776]\n",
      "epoch:30 step:28957 [D loss: 0.235111, acc.: 63.28%] [G loss: 0.294628]\n",
      "epoch:30 step:28958 [D loss: 0.240789, acc.: 53.12%] [G loss: 0.274223]\n",
      "epoch:30 step:28959 [D loss: 0.244110, acc.: 58.59%] [G loss: 0.297322]\n",
      "epoch:30 step:28960 [D loss: 0.235416, acc.: 60.94%] [G loss: 0.299038]\n",
      "epoch:30 step:28961 [D loss: 0.260000, acc.: 54.69%] [G loss: 0.330393]\n",
      "epoch:30 step:28962 [D loss: 0.239143, acc.: 57.03%] [G loss: 0.282875]\n",
      "epoch:30 step:28963 [D loss: 0.244456, acc.: 60.16%] [G loss: 0.260717]\n",
      "epoch:30 step:28964 [D loss: 0.241578, acc.: 59.38%] [G loss: 0.296044]\n",
      "epoch:30 step:28965 [D loss: 0.246336, acc.: 53.12%] [G loss: 0.260296]\n",
      "epoch:30 step:28966 [D loss: 0.240001, acc.: 61.72%] [G loss: 0.294815]\n",
      "epoch:30 step:28967 [D loss: 0.246783, acc.: 56.25%] [G loss: 0.287756]\n",
      "epoch:30 step:28968 [D loss: 0.246005, acc.: 52.34%] [G loss: 0.316647]\n",
      "epoch:30 step:28969 [D loss: 0.247103, acc.: 58.59%] [G loss: 0.295156]\n",
      "epoch:30 step:28970 [D loss: 0.232301, acc.: 60.94%] [G loss: 0.316321]\n",
      "epoch:30 step:28971 [D loss: 0.242501, acc.: 59.38%] [G loss: 0.277571]\n",
      "epoch:30 step:28972 [D loss: 0.252434, acc.: 58.59%] [G loss: 0.294619]\n",
      "epoch:30 step:28973 [D loss: 0.233477, acc.: 62.50%] [G loss: 0.284054]\n",
      "epoch:30 step:28974 [D loss: 0.249937, acc.: 53.12%] [G loss: 0.324203]\n",
      "epoch:30 step:28975 [D loss: 0.235998, acc.: 60.16%] [G loss: 0.334954]\n",
      "epoch:30 step:28976 [D loss: 0.242489, acc.: 57.03%] [G loss: 0.309751]\n",
      "epoch:30 step:28977 [D loss: 0.238497, acc.: 60.16%] [G loss: 0.300393]\n",
      "epoch:30 step:28978 [D loss: 0.226272, acc.: 67.19%] [G loss: 0.299874]\n",
      "epoch:30 step:28979 [D loss: 0.239023, acc.: 60.16%] [G loss: 0.321449]\n",
      "epoch:30 step:28980 [D loss: 0.229379, acc.: 61.72%] [G loss: 0.301561]\n",
      "epoch:30 step:28981 [D loss: 0.228228, acc.: 64.84%] [G loss: 0.312392]\n",
      "epoch:30 step:28982 [D loss: 0.248260, acc.: 57.81%] [G loss: 0.311563]\n",
      "epoch:30 step:28983 [D loss: 0.247149, acc.: 54.69%] [G loss: 0.290914]\n",
      "epoch:30 step:28984 [D loss: 0.249204, acc.: 53.12%] [G loss: 0.300062]\n",
      "epoch:30 step:28985 [D loss: 0.220664, acc.: 64.84%] [G loss: 0.306386]\n",
      "epoch:30 step:28986 [D loss: 0.226064, acc.: 67.19%] [G loss: 0.284216]\n",
      "epoch:30 step:28987 [D loss: 0.235078, acc.: 59.38%] [G loss: 0.286418]\n",
      "epoch:30 step:28988 [D loss: 0.236419, acc.: 59.38%] [G loss: 0.308298]\n",
      "epoch:30 step:28989 [D loss: 0.244464, acc.: 55.47%] [G loss: 0.312040]\n",
      "epoch:30 step:28990 [D loss: 0.235797, acc.: 60.94%] [G loss: 0.289398]\n",
      "epoch:30 step:28991 [D loss: 0.231324, acc.: 58.59%] [G loss: 0.307995]\n",
      "epoch:30 step:28992 [D loss: 0.236969, acc.: 56.25%] [G loss: 0.268411]\n",
      "epoch:30 step:28993 [D loss: 0.246669, acc.: 51.56%] [G loss: 0.318048]\n",
      "epoch:30 step:28994 [D loss: 0.217848, acc.: 64.84%] [G loss: 0.317350]\n",
      "epoch:30 step:28995 [D loss: 0.234320, acc.: 63.28%] [G loss: 0.345459]\n",
      "epoch:30 step:28996 [D loss: 0.248022, acc.: 54.69%] [G loss: 0.313822]\n",
      "epoch:30 step:28997 [D loss: 0.245098, acc.: 54.69%] [G loss: 0.314630]\n",
      "epoch:30 step:28998 [D loss: 0.238572, acc.: 61.72%] [G loss: 0.332310]\n",
      "epoch:30 step:28999 [D loss: 0.237060, acc.: 61.72%] [G loss: 0.297247]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:30 step:29000 [D loss: 0.236337, acc.: 58.59%] [G loss: 0.304092]\n",
      "epoch:30 step:29001 [D loss: 0.246826, acc.: 53.91%] [G loss: 0.299513]\n",
      "epoch:30 step:29002 [D loss: 0.244932, acc.: 56.25%] [G loss: 0.301315]\n",
      "epoch:30 step:29003 [D loss: 0.263346, acc.: 50.00%] [G loss: 0.280434]\n",
      "epoch:30 step:29004 [D loss: 0.248790, acc.: 59.38%] [G loss: 0.304971]\n",
      "epoch:30 step:29005 [D loss: 0.246077, acc.: 57.03%] [G loss: 0.330811]\n",
      "epoch:30 step:29006 [D loss: 0.243296, acc.: 57.81%] [G loss: 0.299882]\n",
      "epoch:30 step:29007 [D loss: 0.256462, acc.: 57.81%] [G loss: 0.291236]\n",
      "epoch:30 step:29008 [D loss: 0.230469, acc.: 59.38%] [G loss: 0.307598]\n",
      "epoch:30 step:29009 [D loss: 0.256387, acc.: 50.78%] [G loss: 0.272669]\n",
      "epoch:30 step:29010 [D loss: 0.247191, acc.: 50.78%] [G loss: 0.284343]\n",
      "epoch:30 step:29011 [D loss: 0.256456, acc.: 50.00%] [G loss: 0.250581]\n",
      "epoch:30 step:29012 [D loss: 0.241936, acc.: 56.25%] [G loss: 0.316408]\n",
      "epoch:30 step:29013 [D loss: 0.251059, acc.: 57.81%] [G loss: 0.330380]\n",
      "epoch:30 step:29014 [D loss: 0.237496, acc.: 57.03%] [G loss: 0.311756]\n",
      "epoch:30 step:29015 [D loss: 0.235859, acc.: 55.47%] [G loss: 0.303335]\n",
      "epoch:30 step:29016 [D loss: 0.243608, acc.: 55.47%] [G loss: 0.280267]\n",
      "epoch:30 step:29017 [D loss: 0.243180, acc.: 54.69%] [G loss: 0.322799]\n",
      "epoch:30 step:29018 [D loss: 0.249972, acc.: 54.69%] [G loss: 0.351738]\n",
      "epoch:30 step:29019 [D loss: 0.227853, acc.: 63.28%] [G loss: 0.306968]\n",
      "epoch:30 step:29020 [D loss: 0.234964, acc.: 56.25%] [G loss: 0.278712]\n",
      "epoch:30 step:29021 [D loss: 0.260103, acc.: 52.34%] [G loss: 0.294847]\n",
      "epoch:30 step:29022 [D loss: 0.247017, acc.: 52.34%] [G loss: 0.334276]\n",
      "epoch:30 step:29023 [D loss: 0.224652, acc.: 63.28%] [G loss: 0.292745]\n",
      "epoch:30 step:29024 [D loss: 0.239055, acc.: 56.25%] [G loss: 0.318876]\n",
      "epoch:30 step:29025 [D loss: 0.239239, acc.: 52.34%] [G loss: 0.257898]\n",
      "epoch:30 step:29026 [D loss: 0.228036, acc.: 63.28%] [G loss: 0.311110]\n",
      "epoch:30 step:29027 [D loss: 0.225553, acc.: 65.62%] [G loss: 0.297927]\n",
      "epoch:30 step:29028 [D loss: 0.238396, acc.: 59.38%] [G loss: 0.313762]\n",
      "epoch:30 step:29029 [D loss: 0.238815, acc.: 57.03%] [G loss: 0.292651]\n",
      "epoch:30 step:29030 [D loss: 0.238873, acc.: 59.38%] [G loss: 0.333457]\n",
      "epoch:30 step:29031 [D loss: 0.254923, acc.: 53.12%] [G loss: 0.305830]\n",
      "epoch:30 step:29032 [D loss: 0.252549, acc.: 53.91%] [G loss: 0.305754]\n",
      "epoch:30 step:29033 [D loss: 0.237444, acc.: 61.72%] [G loss: 0.304778]\n",
      "epoch:30 step:29034 [D loss: 0.237676, acc.: 57.81%] [G loss: 0.292572]\n",
      "epoch:30 step:29035 [D loss: 0.237186, acc.: 57.81%] [G loss: 0.308501]\n",
      "epoch:30 step:29036 [D loss: 0.256632, acc.: 54.69%] [G loss: 0.309200]\n",
      "epoch:30 step:29037 [D loss: 0.243499, acc.: 56.25%] [G loss: 0.279915]\n",
      "epoch:30 step:29038 [D loss: 0.222999, acc.: 71.09%] [G loss: 0.317693]\n",
      "epoch:30 step:29039 [D loss: 0.221926, acc.: 63.28%] [G loss: 0.293228]\n",
      "epoch:30 step:29040 [D loss: 0.243854, acc.: 53.12%] [G loss: 0.297891]\n",
      "epoch:30 step:29041 [D loss: 0.245251, acc.: 56.25%] [G loss: 0.302867]\n",
      "epoch:30 step:29042 [D loss: 0.257986, acc.: 53.91%] [G loss: 0.315968]\n",
      "epoch:30 step:29043 [D loss: 0.249110, acc.: 56.25%] [G loss: 0.294288]\n",
      "epoch:30 step:29044 [D loss: 0.242813, acc.: 56.25%] [G loss: 0.308475]\n",
      "epoch:30 step:29045 [D loss: 0.225374, acc.: 59.38%] [G loss: 0.280905]\n",
      "epoch:30 step:29046 [D loss: 0.235274, acc.: 60.16%] [G loss: 0.291486]\n",
      "epoch:30 step:29047 [D loss: 0.234449, acc.: 60.16%] [G loss: 0.303463]\n",
      "epoch:31 step:29048 [D loss: 0.247821, acc.: 57.03%] [G loss: 0.305595]\n",
      "epoch:31 step:29049 [D loss: 0.237526, acc.: 62.50%] [G loss: 0.294175]\n",
      "epoch:31 step:29050 [D loss: 0.249214, acc.: 53.12%] [G loss: 0.301290]\n",
      "epoch:31 step:29051 [D loss: 0.232953, acc.: 60.94%] [G loss: 0.312932]\n",
      "epoch:31 step:29052 [D loss: 0.243375, acc.: 57.03%] [G loss: 0.310393]\n",
      "epoch:31 step:29053 [D loss: 0.234535, acc.: 61.72%] [G loss: 0.329352]\n",
      "epoch:31 step:29054 [D loss: 0.238595, acc.: 59.38%] [G loss: 0.312159]\n",
      "epoch:31 step:29055 [D loss: 0.240036, acc.: 56.25%] [G loss: 0.293384]\n",
      "epoch:31 step:29056 [D loss: 0.229965, acc.: 63.28%] [G loss: 0.297804]\n",
      "epoch:31 step:29057 [D loss: 0.251280, acc.: 54.69%] [G loss: 0.295369]\n",
      "epoch:31 step:29058 [D loss: 0.238119, acc.: 56.25%] [G loss: 0.304888]\n",
      "epoch:31 step:29059 [D loss: 0.251522, acc.: 55.47%] [G loss: 0.286737]\n",
      "epoch:31 step:29060 [D loss: 0.242070, acc.: 57.03%] [G loss: 0.279076]\n",
      "epoch:31 step:29061 [D loss: 0.249795, acc.: 53.91%] [G loss: 0.295227]\n",
      "epoch:31 step:29062 [D loss: 0.217677, acc.: 67.97%] [G loss: 0.311787]\n",
      "epoch:31 step:29063 [D loss: 0.235114, acc.: 61.72%] [G loss: 0.301683]\n",
      "epoch:31 step:29064 [D loss: 0.244723, acc.: 56.25%] [G loss: 0.302971]\n",
      "epoch:31 step:29065 [D loss: 0.223333, acc.: 66.41%] [G loss: 0.315190]\n",
      "epoch:31 step:29066 [D loss: 0.218325, acc.: 71.88%] [G loss: 0.306277]\n",
      "epoch:31 step:29067 [D loss: 0.229025, acc.: 62.50%] [G loss: 0.306468]\n",
      "epoch:31 step:29068 [D loss: 0.244742, acc.: 58.59%] [G loss: 0.295208]\n",
      "epoch:31 step:29069 [D loss: 0.225214, acc.: 68.75%] [G loss: 0.310062]\n",
      "epoch:31 step:29070 [D loss: 0.244779, acc.: 60.16%] [G loss: 0.309581]\n",
      "epoch:31 step:29071 [D loss: 0.239856, acc.: 60.16%] [G loss: 0.325243]\n",
      "epoch:31 step:29072 [D loss: 0.250243, acc.: 55.47%] [G loss: 0.279999]\n",
      "epoch:31 step:29073 [D loss: 0.232661, acc.: 60.16%] [G loss: 0.311249]\n",
      "epoch:31 step:29074 [D loss: 0.210216, acc.: 68.75%] [G loss: 0.286069]\n",
      "epoch:31 step:29075 [D loss: 0.231887, acc.: 60.16%] [G loss: 0.270853]\n",
      "epoch:31 step:29076 [D loss: 0.247022, acc.: 57.81%] [G loss: 0.291655]\n",
      "epoch:31 step:29077 [D loss: 0.246337, acc.: 47.66%] [G loss: 0.282344]\n",
      "epoch:31 step:29078 [D loss: 0.246852, acc.: 51.56%] [G loss: 0.313519]\n",
      "epoch:31 step:29079 [D loss: 0.230093, acc.: 60.16%] [G loss: 0.317760]\n",
      "epoch:31 step:29080 [D loss: 0.251849, acc.: 51.56%] [G loss: 0.294270]\n",
      "epoch:31 step:29081 [D loss: 0.232535, acc.: 60.16%] [G loss: 0.291335]\n",
      "epoch:31 step:29082 [D loss: 0.216505, acc.: 65.62%] [G loss: 0.293402]\n",
      "epoch:31 step:29083 [D loss: 0.236002, acc.: 60.94%] [G loss: 0.306144]\n",
      "epoch:31 step:29084 [D loss: 0.235615, acc.: 59.38%] [G loss: 0.280979]\n",
      "epoch:31 step:29085 [D loss: 0.236810, acc.: 61.72%] [G loss: 0.323191]\n",
      "epoch:31 step:29086 [D loss: 0.235618, acc.: 65.62%] [G loss: 0.304192]\n",
      "epoch:31 step:29087 [D loss: 0.241932, acc.: 58.59%] [G loss: 0.296857]\n",
      "epoch:31 step:29088 [D loss: 0.235809, acc.: 57.03%] [G loss: 0.303161]\n",
      "epoch:31 step:29089 [D loss: 0.233158, acc.: 64.06%] [G loss: 0.313072]\n",
      "epoch:31 step:29090 [D loss: 0.228545, acc.: 61.72%] [G loss: 0.307407]\n",
      "epoch:31 step:29091 [D loss: 0.225678, acc.: 60.94%] [G loss: 0.320982]\n",
      "epoch:31 step:29092 [D loss: 0.243901, acc.: 56.25%] [G loss: 0.289635]\n",
      "epoch:31 step:29093 [D loss: 0.243920, acc.: 57.03%] [G loss: 0.329228]\n",
      "epoch:31 step:29094 [D loss: 0.246204, acc.: 57.81%] [G loss: 0.284025]\n",
      "epoch:31 step:29095 [D loss: 0.241656, acc.: 61.72%] [G loss: 0.311959]\n",
      "epoch:31 step:29096 [D loss: 0.223280, acc.: 64.06%] [G loss: 0.304859]\n",
      "epoch:31 step:29097 [D loss: 0.236639, acc.: 64.84%] [G loss: 0.318025]\n",
      "epoch:31 step:29098 [D loss: 0.239009, acc.: 53.91%] [G loss: 0.294226]\n",
      "epoch:31 step:29099 [D loss: 0.225979, acc.: 67.97%] [G loss: 0.288781]\n",
      "epoch:31 step:29100 [D loss: 0.239337, acc.: 54.69%] [G loss: 0.304652]\n",
      "epoch:31 step:29101 [D loss: 0.214498, acc.: 64.84%] [G loss: 0.308621]\n",
      "epoch:31 step:29102 [D loss: 0.243126, acc.: 57.81%] [G loss: 0.299008]\n",
      "epoch:31 step:29103 [D loss: 0.265082, acc.: 53.12%] [G loss: 0.283936]\n",
      "epoch:31 step:29104 [D loss: 0.249263, acc.: 56.25%] [G loss: 0.273306]\n",
      "epoch:31 step:29105 [D loss: 0.248479, acc.: 54.69%] [G loss: 0.290100]\n",
      "epoch:31 step:29106 [D loss: 0.221356, acc.: 64.06%] [G loss: 0.307536]\n",
      "epoch:31 step:29107 [D loss: 0.237626, acc.: 64.84%] [G loss: 0.300675]\n",
      "epoch:31 step:29108 [D loss: 0.263524, acc.: 42.97%] [G loss: 0.295243]\n",
      "epoch:31 step:29109 [D loss: 0.242229, acc.: 58.59%] [G loss: 0.314302]\n",
      "epoch:31 step:29110 [D loss: 0.226679, acc.: 67.19%] [G loss: 0.303787]\n",
      "epoch:31 step:29111 [D loss: 0.251530, acc.: 53.12%] [G loss: 0.297779]\n",
      "epoch:31 step:29112 [D loss: 0.230991, acc.: 60.16%] [G loss: 0.312615]\n",
      "epoch:31 step:29113 [D loss: 0.241872, acc.: 54.69%] [G loss: 0.291422]\n",
      "epoch:31 step:29114 [D loss: 0.236082, acc.: 58.59%] [G loss: 0.309629]\n",
      "epoch:31 step:29115 [D loss: 0.247028, acc.: 52.34%] [G loss: 0.309995]\n",
      "epoch:31 step:29116 [D loss: 0.239806, acc.: 57.81%] [G loss: 0.292918]\n",
      "epoch:31 step:29117 [D loss: 0.246138, acc.: 52.34%] [G loss: 0.281138]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:31 step:29118 [D loss: 0.231459, acc.: 58.59%] [G loss: 0.297262]\n",
      "epoch:31 step:29119 [D loss: 0.241641, acc.: 56.25%] [G loss: 0.319180]\n",
      "epoch:31 step:29120 [D loss: 0.225912, acc.: 65.62%] [G loss: 0.313271]\n",
      "epoch:31 step:29121 [D loss: 0.237795, acc.: 56.25%] [G loss: 0.298708]\n",
      "epoch:31 step:29122 [D loss: 0.238850, acc.: 57.03%] [G loss: 0.315503]\n",
      "epoch:31 step:29123 [D loss: 0.246384, acc.: 59.38%] [G loss: 0.291268]\n",
      "epoch:31 step:29124 [D loss: 0.255616, acc.: 53.91%] [G loss: 0.277903]\n",
      "epoch:31 step:29125 [D loss: 0.229666, acc.: 57.81%] [G loss: 0.326769]\n",
      "epoch:31 step:29126 [D loss: 0.263786, acc.: 49.22%] [G loss: 0.297621]\n",
      "epoch:31 step:29127 [D loss: 0.276440, acc.: 47.66%] [G loss: 0.276407]\n",
      "epoch:31 step:29128 [D loss: 0.270025, acc.: 45.31%] [G loss: 0.286857]\n",
      "epoch:31 step:29129 [D loss: 0.221936, acc.: 64.84%] [G loss: 0.322472]\n",
      "epoch:31 step:29130 [D loss: 0.234001, acc.: 58.59%] [G loss: 0.299036]\n",
      "epoch:31 step:29131 [D loss: 0.254585, acc.: 48.44%] [G loss: 0.313006]\n",
      "epoch:31 step:29132 [D loss: 0.254901, acc.: 53.12%] [G loss: 0.281141]\n",
      "epoch:31 step:29133 [D loss: 0.237486, acc.: 60.16%] [G loss: 0.304635]\n",
      "epoch:31 step:29134 [D loss: 0.225130, acc.: 65.62%] [G loss: 0.335244]\n",
      "epoch:31 step:29135 [D loss: 0.250188, acc.: 50.78%] [G loss: 0.294714]\n",
      "epoch:31 step:29136 [D loss: 0.239648, acc.: 61.72%] [G loss: 0.321749]\n",
      "epoch:31 step:29137 [D loss: 0.248316, acc.: 58.59%] [G loss: 0.313094]\n",
      "epoch:31 step:29138 [D loss: 0.233390, acc.: 61.72%] [G loss: 0.314468]\n",
      "epoch:31 step:29139 [D loss: 0.219254, acc.: 63.28%] [G loss: 0.300821]\n",
      "epoch:31 step:29140 [D loss: 0.229422, acc.: 63.28%] [G loss: 0.282711]\n",
      "epoch:31 step:29141 [D loss: 0.228331, acc.: 64.84%] [G loss: 0.294279]\n",
      "epoch:31 step:29142 [D loss: 0.229754, acc.: 60.94%] [G loss: 0.303004]\n",
      "epoch:31 step:29143 [D loss: 0.253117, acc.: 50.00%] [G loss: 0.291273]\n",
      "epoch:31 step:29144 [D loss: 0.244262, acc.: 50.78%] [G loss: 0.287586]\n",
      "epoch:31 step:29145 [D loss: 0.250317, acc.: 54.69%] [G loss: 0.280433]\n",
      "epoch:31 step:29146 [D loss: 0.258327, acc.: 47.66%] [G loss: 0.321212]\n",
      "epoch:31 step:29147 [D loss: 0.236389, acc.: 57.03%] [G loss: 0.313080]\n",
      "epoch:31 step:29148 [D loss: 0.226714, acc.: 59.38%] [G loss: 0.315212]\n",
      "epoch:31 step:29149 [D loss: 0.233875, acc.: 57.81%] [G loss: 0.277793]\n",
      "epoch:31 step:29150 [D loss: 0.229818, acc.: 59.38%] [G loss: 0.302936]\n",
      "epoch:31 step:29151 [D loss: 0.239804, acc.: 64.84%] [G loss: 0.288264]\n",
      "epoch:31 step:29152 [D loss: 0.235016, acc.: 57.03%] [G loss: 0.333416]\n",
      "epoch:31 step:29153 [D loss: 0.240073, acc.: 58.59%] [G loss: 0.288049]\n",
      "epoch:31 step:29154 [D loss: 0.226571, acc.: 64.06%] [G loss: 0.303565]\n",
      "epoch:31 step:29155 [D loss: 0.245489, acc.: 54.69%] [G loss: 0.308470]\n",
      "epoch:31 step:29156 [D loss: 0.224780, acc.: 67.97%] [G loss: 0.314390]\n",
      "epoch:31 step:29157 [D loss: 0.241542, acc.: 58.59%] [G loss: 0.310111]\n",
      "epoch:31 step:29158 [D loss: 0.246133, acc.: 50.00%] [G loss: 0.321831]\n",
      "epoch:31 step:29159 [D loss: 0.238675, acc.: 58.59%] [G loss: 0.277199]\n",
      "epoch:31 step:29160 [D loss: 0.237130, acc.: 58.59%] [G loss: 0.316024]\n",
      "epoch:31 step:29161 [D loss: 0.228862, acc.: 65.62%] [G loss: 0.279358]\n",
      "epoch:31 step:29162 [D loss: 0.249816, acc.: 52.34%] [G loss: 0.315837]\n",
      "epoch:31 step:29163 [D loss: 0.255905, acc.: 53.12%] [G loss: 0.285795]\n",
      "epoch:31 step:29164 [D loss: 0.239939, acc.: 57.81%] [G loss: 0.324506]\n",
      "epoch:31 step:29165 [D loss: 0.235352, acc.: 56.25%] [G loss: 0.331238]\n",
      "epoch:31 step:29166 [D loss: 0.234611, acc.: 59.38%] [G loss: 0.281791]\n",
      "epoch:31 step:29167 [D loss: 0.257195, acc.: 55.47%] [G loss: 0.309164]\n",
      "epoch:31 step:29168 [D loss: 0.247472, acc.: 53.12%] [G loss: 0.289707]\n",
      "epoch:31 step:29169 [D loss: 0.239116, acc.: 55.47%] [G loss: 0.285471]\n",
      "epoch:31 step:29170 [D loss: 0.231132, acc.: 59.38%] [G loss: 0.300181]\n",
      "epoch:31 step:29171 [D loss: 0.247546, acc.: 56.25%] [G loss: 0.278816]\n",
      "epoch:31 step:29172 [D loss: 0.222729, acc.: 65.62%] [G loss: 0.311083]\n",
      "epoch:31 step:29173 [D loss: 0.240705, acc.: 58.59%] [G loss: 0.305718]\n",
      "epoch:31 step:29174 [D loss: 0.244753, acc.: 54.69%] [G loss: 0.297757]\n",
      "epoch:31 step:29175 [D loss: 0.253664, acc.: 55.47%] [G loss: 0.288575]\n",
      "epoch:31 step:29176 [D loss: 0.227118, acc.: 64.84%] [G loss: 0.281156]\n",
      "epoch:31 step:29177 [D loss: 0.240705, acc.: 59.38%] [G loss: 0.288087]\n",
      "epoch:31 step:29178 [D loss: 0.233317, acc.: 53.91%] [G loss: 0.284043]\n",
      "epoch:31 step:29179 [D loss: 0.247770, acc.: 52.34%] [G loss: 0.307216]\n",
      "epoch:31 step:29180 [D loss: 0.244425, acc.: 60.16%] [G loss: 0.320319]\n",
      "epoch:31 step:29181 [D loss: 0.229247, acc.: 58.59%] [G loss: 0.296944]\n",
      "epoch:31 step:29182 [D loss: 0.248477, acc.: 57.03%] [G loss: 0.270949]\n",
      "epoch:31 step:29183 [D loss: 0.258209, acc.: 53.91%] [G loss: 0.273568]\n",
      "epoch:31 step:29184 [D loss: 0.248847, acc.: 58.59%] [G loss: 0.294987]\n",
      "epoch:31 step:29185 [D loss: 0.244966, acc.: 53.12%] [G loss: 0.316370]\n",
      "epoch:31 step:29186 [D loss: 0.233868, acc.: 61.72%] [G loss: 0.288049]\n",
      "epoch:31 step:29187 [D loss: 0.254838, acc.: 46.88%] [G loss: 0.276237]\n",
      "epoch:31 step:29188 [D loss: 0.257118, acc.: 47.66%] [G loss: 0.318189]\n",
      "epoch:31 step:29189 [D loss: 0.216537, acc.: 64.84%] [G loss: 0.297566]\n",
      "epoch:31 step:29190 [D loss: 0.239548, acc.: 58.59%] [G loss: 0.310149]\n",
      "epoch:31 step:29191 [D loss: 0.230562, acc.: 61.72%] [G loss: 0.301977]\n",
      "epoch:31 step:29192 [D loss: 0.232647, acc.: 59.38%] [G loss: 0.301544]\n",
      "epoch:31 step:29193 [D loss: 0.226367, acc.: 64.06%] [G loss: 0.266571]\n",
      "epoch:31 step:29194 [D loss: 0.244261, acc.: 57.03%] [G loss: 0.286655]\n",
      "epoch:31 step:29195 [D loss: 0.224833, acc.: 64.06%] [G loss: 0.288260]\n",
      "epoch:31 step:29196 [D loss: 0.239177, acc.: 60.94%] [G loss: 0.282452]\n",
      "epoch:31 step:29197 [D loss: 0.239167, acc.: 60.94%] [G loss: 0.281151]\n",
      "epoch:31 step:29198 [D loss: 0.255894, acc.: 51.56%] [G loss: 0.291876]\n",
      "epoch:31 step:29199 [D loss: 0.248598, acc.: 54.69%] [G loss: 0.299426]\n",
      "epoch:31 step:29200 [D loss: 0.228919, acc.: 62.50%] [G loss: 0.320936]\n",
      "epoch:31 step:29201 [D loss: 0.218196, acc.: 64.84%] [G loss: 0.321077]\n",
      "epoch:31 step:29202 [D loss: 0.239709, acc.: 58.59%] [G loss: 0.302994]\n",
      "epoch:31 step:29203 [D loss: 0.243050, acc.: 56.25%] [G loss: 0.299744]\n",
      "epoch:31 step:29204 [D loss: 0.219911, acc.: 60.94%] [G loss: 0.316773]\n",
      "epoch:31 step:29205 [D loss: 0.245841, acc.: 57.03%] [G loss: 0.298846]\n",
      "epoch:31 step:29206 [D loss: 0.239506, acc.: 60.94%] [G loss: 0.294262]\n",
      "epoch:31 step:29207 [D loss: 0.210143, acc.: 64.06%] [G loss: 0.309515]\n",
      "epoch:31 step:29208 [D loss: 0.227114, acc.: 64.06%] [G loss: 0.341083]\n",
      "epoch:31 step:29209 [D loss: 0.238522, acc.: 58.59%] [G loss: 0.293265]\n",
      "epoch:31 step:29210 [D loss: 0.236247, acc.: 58.59%] [G loss: 0.324454]\n",
      "epoch:31 step:29211 [D loss: 0.259483, acc.: 52.34%] [G loss: 0.287721]\n",
      "epoch:31 step:29212 [D loss: 0.244130, acc.: 56.25%] [G loss: 0.281897]\n",
      "epoch:31 step:29213 [D loss: 0.244030, acc.: 53.91%] [G loss: 0.285500]\n",
      "epoch:31 step:29214 [D loss: 0.233817, acc.: 57.81%] [G loss: 0.328502]\n",
      "epoch:31 step:29215 [D loss: 0.240297, acc.: 57.81%] [G loss: 0.300844]\n",
      "epoch:31 step:29216 [D loss: 0.211033, acc.: 68.75%] [G loss: 0.312767]\n",
      "epoch:31 step:29217 [D loss: 0.245790, acc.: 55.47%] [G loss: 0.299997]\n",
      "epoch:31 step:29218 [D loss: 0.257332, acc.: 53.12%] [G loss: 0.304949]\n",
      "epoch:31 step:29219 [D loss: 0.231639, acc.: 61.72%] [G loss: 0.278712]\n",
      "epoch:31 step:29220 [D loss: 0.233648, acc.: 59.38%] [G loss: 0.301979]\n",
      "epoch:31 step:29221 [D loss: 0.239543, acc.: 62.50%] [G loss: 0.341906]\n",
      "epoch:31 step:29222 [D loss: 0.237487, acc.: 60.94%] [G loss: 0.328510]\n",
      "epoch:31 step:29223 [D loss: 0.237111, acc.: 59.38%] [G loss: 0.299115]\n",
      "epoch:31 step:29224 [D loss: 0.228762, acc.: 66.41%] [G loss: 0.308970]\n",
      "epoch:31 step:29225 [D loss: 0.236486, acc.: 60.16%] [G loss: 0.286956]\n",
      "epoch:31 step:29226 [D loss: 0.235762, acc.: 60.94%] [G loss: 0.299959]\n",
      "epoch:31 step:29227 [D loss: 0.235231, acc.: 58.59%] [G loss: 0.304882]\n",
      "epoch:31 step:29228 [D loss: 0.231590, acc.: 58.59%] [G loss: 0.302383]\n",
      "epoch:31 step:29229 [D loss: 0.237834, acc.: 60.94%] [G loss: 0.279894]\n",
      "epoch:31 step:29230 [D loss: 0.242067, acc.: 55.47%] [G loss: 0.327383]\n",
      "epoch:31 step:29231 [D loss: 0.246076, acc.: 54.69%] [G loss: 0.294480]\n",
      "epoch:31 step:29232 [D loss: 0.246356, acc.: 52.34%] [G loss: 0.270094]\n",
      "epoch:31 step:29233 [D loss: 0.225402, acc.: 64.06%] [G loss: 0.313642]\n",
      "epoch:31 step:29234 [D loss: 0.232914, acc.: 62.50%] [G loss: 0.327000]\n",
      "epoch:31 step:29235 [D loss: 0.251616, acc.: 52.34%] [G loss: 0.320451]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:31 step:29236 [D loss: 0.235839, acc.: 60.94%] [G loss: 0.293542]\n",
      "epoch:31 step:29237 [D loss: 0.239433, acc.: 60.16%] [G loss: 0.304923]\n",
      "epoch:31 step:29238 [D loss: 0.251421, acc.: 55.47%] [G loss: 0.290197]\n",
      "epoch:31 step:29239 [D loss: 0.251493, acc.: 53.12%] [G loss: 0.318415]\n",
      "epoch:31 step:29240 [D loss: 0.243963, acc.: 59.38%] [G loss: 0.290712]\n",
      "epoch:31 step:29241 [D loss: 0.229552, acc.: 57.03%] [G loss: 0.329469]\n",
      "epoch:31 step:29242 [D loss: 0.246204, acc.: 59.38%] [G loss: 0.277864]\n",
      "epoch:31 step:29243 [D loss: 0.241607, acc.: 56.25%] [G loss: 0.300060]\n",
      "epoch:31 step:29244 [D loss: 0.232492, acc.: 64.06%] [G loss: 0.283828]\n",
      "epoch:31 step:29245 [D loss: 0.225462, acc.: 64.06%] [G loss: 0.295367]\n",
      "epoch:31 step:29246 [D loss: 0.256185, acc.: 56.25%] [G loss: 0.272559]\n",
      "epoch:31 step:29247 [D loss: 0.247501, acc.: 53.91%] [G loss: 0.278864]\n",
      "epoch:31 step:29248 [D loss: 0.226183, acc.: 60.16%] [G loss: 0.300718]\n",
      "epoch:31 step:29249 [D loss: 0.241509, acc.: 53.12%] [G loss: 0.312359]\n",
      "epoch:31 step:29250 [D loss: 0.247836, acc.: 53.91%] [G loss: 0.327788]\n",
      "epoch:31 step:29251 [D loss: 0.226788, acc.: 65.62%] [G loss: 0.305751]\n",
      "epoch:31 step:29252 [D loss: 0.253456, acc.: 51.56%] [G loss: 0.283450]\n",
      "epoch:31 step:29253 [D loss: 0.231084, acc.: 57.03%] [G loss: 0.290014]\n",
      "epoch:31 step:29254 [D loss: 0.239997, acc.: 56.25%] [G loss: 0.298006]\n",
      "epoch:31 step:29255 [D loss: 0.230211, acc.: 61.72%] [G loss: 0.319749]\n",
      "epoch:31 step:29256 [D loss: 0.250215, acc.: 50.78%] [G loss: 0.289318]\n",
      "epoch:31 step:29257 [D loss: 0.223612, acc.: 61.72%] [G loss: 0.313338]\n",
      "epoch:31 step:29258 [D loss: 0.236302, acc.: 62.50%] [G loss: 0.294118]\n",
      "epoch:31 step:29259 [D loss: 0.252069, acc.: 50.00%] [G loss: 0.307348]\n",
      "epoch:31 step:29260 [D loss: 0.240582, acc.: 60.16%] [G loss: 0.299718]\n",
      "epoch:31 step:29261 [D loss: 0.237317, acc.: 54.69%] [G loss: 0.321897]\n",
      "epoch:31 step:29262 [D loss: 0.226791, acc.: 60.16%] [G loss: 0.321082]\n",
      "epoch:31 step:29263 [D loss: 0.254469, acc.: 57.03%] [G loss: 0.283304]\n",
      "epoch:31 step:29264 [D loss: 0.226462, acc.: 64.06%] [G loss: 0.306839]\n",
      "epoch:31 step:29265 [D loss: 0.250137, acc.: 53.12%] [G loss: 0.291433]\n",
      "epoch:31 step:29266 [D loss: 0.233237, acc.: 58.59%] [G loss: 0.314407]\n",
      "epoch:31 step:29267 [D loss: 0.223779, acc.: 66.41%] [G loss: 0.317253]\n",
      "epoch:31 step:29268 [D loss: 0.239112, acc.: 58.59%] [G loss: 0.289241]\n",
      "epoch:31 step:29269 [D loss: 0.255510, acc.: 52.34%] [G loss: 0.258266]\n",
      "epoch:31 step:29270 [D loss: 0.241192, acc.: 59.38%] [G loss: 0.300408]\n",
      "epoch:31 step:29271 [D loss: 0.236209, acc.: 57.03%] [G loss: 0.299514]\n",
      "epoch:31 step:29272 [D loss: 0.251251, acc.: 53.91%] [G loss: 0.319311]\n",
      "epoch:31 step:29273 [D loss: 0.258069, acc.: 46.88%] [G loss: 0.310365]\n",
      "epoch:31 step:29274 [D loss: 0.241675, acc.: 50.78%] [G loss: 0.290501]\n",
      "epoch:31 step:29275 [D loss: 0.241000, acc.: 57.81%] [G loss: 0.312811]\n",
      "epoch:31 step:29276 [D loss: 0.239096, acc.: 57.81%] [G loss: 0.307720]\n",
      "epoch:31 step:29277 [D loss: 0.236702, acc.: 55.47%] [G loss: 0.265234]\n",
      "epoch:31 step:29278 [D loss: 0.219382, acc.: 65.62%] [G loss: 0.306807]\n",
      "epoch:31 step:29279 [D loss: 0.239812, acc.: 59.38%] [G loss: 0.314730]\n",
      "epoch:31 step:29280 [D loss: 0.242111, acc.: 59.38%] [G loss: 0.307490]\n",
      "epoch:31 step:29281 [D loss: 0.245282, acc.: 59.38%] [G loss: 0.274963]\n",
      "epoch:31 step:29282 [D loss: 0.224474, acc.: 67.19%] [G loss: 0.274743]\n",
      "epoch:31 step:29283 [D loss: 0.247588, acc.: 53.91%] [G loss: 0.317856]\n",
      "epoch:31 step:29284 [D loss: 0.212098, acc.: 68.75%] [G loss: 0.279013]\n",
      "epoch:31 step:29285 [D loss: 0.239514, acc.: 60.16%] [G loss: 0.315689]\n",
      "epoch:31 step:29286 [D loss: 0.239991, acc.: 58.59%] [G loss: 0.292286]\n",
      "epoch:31 step:29287 [D loss: 0.253533, acc.: 52.34%] [G loss: 0.300744]\n",
      "epoch:31 step:29288 [D loss: 0.224036, acc.: 64.84%] [G loss: 0.291084]\n",
      "epoch:31 step:29289 [D loss: 0.251435, acc.: 55.47%] [G loss: 0.274182]\n",
      "epoch:31 step:29290 [D loss: 0.240795, acc.: 59.38%] [G loss: 0.330584]\n",
      "epoch:31 step:29291 [D loss: 0.244727, acc.: 55.47%] [G loss: 0.311698]\n",
      "epoch:31 step:29292 [D loss: 0.237693, acc.: 57.81%] [G loss: 0.289543]\n",
      "epoch:31 step:29293 [D loss: 0.232189, acc.: 58.59%] [G loss: 0.295067]\n",
      "epoch:31 step:29294 [D loss: 0.240607, acc.: 60.94%] [G loss: 0.308153]\n",
      "epoch:31 step:29295 [D loss: 0.254672, acc.: 55.47%] [G loss: 0.292926]\n",
      "epoch:31 step:29296 [D loss: 0.237623, acc.: 60.16%] [G loss: 0.299973]\n",
      "epoch:31 step:29297 [D loss: 0.249583, acc.: 54.69%] [G loss: 0.298243]\n",
      "epoch:31 step:29298 [D loss: 0.238885, acc.: 57.81%] [G loss: 0.280605]\n",
      "epoch:31 step:29299 [D loss: 0.238961, acc.: 60.94%] [G loss: 0.273451]\n",
      "epoch:31 step:29300 [D loss: 0.237979, acc.: 57.03%] [G loss: 0.278367]\n",
      "epoch:31 step:29301 [D loss: 0.247077, acc.: 61.72%] [G loss: 0.290599]\n",
      "epoch:31 step:29302 [D loss: 0.218227, acc.: 65.62%] [G loss: 0.318358]\n",
      "epoch:31 step:29303 [D loss: 0.239857, acc.: 53.91%] [G loss: 0.303340]\n",
      "epoch:31 step:29304 [D loss: 0.250381, acc.: 53.91%] [G loss: 0.278800]\n",
      "epoch:31 step:29305 [D loss: 0.246260, acc.: 53.12%] [G loss: 0.293407]\n",
      "epoch:31 step:29306 [D loss: 0.234184, acc.: 57.03%] [G loss: 0.300653]\n",
      "epoch:31 step:29307 [D loss: 0.232352, acc.: 66.41%] [G loss: 0.294354]\n",
      "epoch:31 step:29308 [D loss: 0.256163, acc.: 53.12%] [G loss: 0.298941]\n",
      "epoch:31 step:29309 [D loss: 0.221860, acc.: 64.06%] [G loss: 0.306987]\n",
      "epoch:31 step:29310 [D loss: 0.246894, acc.: 54.69%] [G loss: 0.292996]\n",
      "epoch:31 step:29311 [D loss: 0.216003, acc.: 67.19%] [G loss: 0.346056]\n",
      "epoch:31 step:29312 [D loss: 0.222810, acc.: 63.28%] [G loss: 0.306298]\n",
      "epoch:31 step:29313 [D loss: 0.232315, acc.: 61.72%] [G loss: 0.317002]\n",
      "epoch:31 step:29314 [D loss: 0.244476, acc.: 60.16%] [G loss: 0.300051]\n",
      "epoch:31 step:29315 [D loss: 0.242027, acc.: 55.47%] [G loss: 0.294790]\n",
      "epoch:31 step:29316 [D loss: 0.235882, acc.: 58.59%] [G loss: 0.279465]\n",
      "epoch:31 step:29317 [D loss: 0.240200, acc.: 61.72%] [G loss: 0.322746]\n",
      "epoch:31 step:29318 [D loss: 0.233374, acc.: 58.59%] [G loss: 0.299905]\n",
      "epoch:31 step:29319 [D loss: 0.228444, acc.: 63.28%] [G loss: 0.323551]\n",
      "epoch:31 step:29320 [D loss: 0.249360, acc.: 54.69%] [G loss: 0.295579]\n",
      "epoch:31 step:29321 [D loss: 0.247207, acc.: 53.12%] [G loss: 0.285983]\n",
      "epoch:31 step:29322 [D loss: 0.226475, acc.: 64.84%] [G loss: 0.289956]\n",
      "epoch:31 step:29323 [D loss: 0.262249, acc.: 53.91%] [G loss: 0.302303]\n",
      "epoch:31 step:29324 [D loss: 0.250119, acc.: 60.16%] [G loss: 0.329240]\n",
      "epoch:31 step:29325 [D loss: 0.245172, acc.: 57.81%] [G loss: 0.296961]\n",
      "epoch:31 step:29326 [D loss: 0.252111, acc.: 55.47%] [G loss: 0.283254]\n",
      "epoch:31 step:29327 [D loss: 0.231573, acc.: 67.19%] [G loss: 0.313905]\n",
      "epoch:31 step:29328 [D loss: 0.252939, acc.: 56.25%] [G loss: 0.315565]\n",
      "epoch:31 step:29329 [D loss: 0.242888, acc.: 57.81%] [G loss: 0.296963]\n",
      "epoch:31 step:29330 [D loss: 0.239485, acc.: 58.59%] [G loss: 0.316260]\n",
      "epoch:31 step:29331 [D loss: 0.245970, acc.: 57.03%] [G loss: 0.278681]\n",
      "epoch:31 step:29332 [D loss: 0.253242, acc.: 54.69%] [G loss: 0.320326]\n",
      "epoch:31 step:29333 [D loss: 0.245302, acc.: 58.59%] [G loss: 0.309085]\n",
      "epoch:31 step:29334 [D loss: 0.232597, acc.: 51.56%] [G loss: 0.323476]\n",
      "epoch:31 step:29335 [D loss: 0.224741, acc.: 60.94%] [G loss: 0.301524]\n",
      "epoch:31 step:29336 [D loss: 0.237539, acc.: 57.81%] [G loss: 0.290239]\n",
      "epoch:31 step:29337 [D loss: 0.243080, acc.: 56.25%] [G loss: 0.296636]\n",
      "epoch:31 step:29338 [D loss: 0.246556, acc.: 55.47%] [G loss: 0.304423]\n",
      "epoch:31 step:29339 [D loss: 0.233660, acc.: 65.62%] [G loss: 0.324003]\n",
      "epoch:31 step:29340 [D loss: 0.245678, acc.: 52.34%] [G loss: 0.291442]\n",
      "epoch:31 step:29341 [D loss: 0.235773, acc.: 65.62%] [G loss: 0.301306]\n",
      "epoch:31 step:29342 [D loss: 0.239747, acc.: 60.94%] [G loss: 0.289218]\n",
      "epoch:31 step:29343 [D loss: 0.242421, acc.: 56.25%] [G loss: 0.277914]\n",
      "epoch:31 step:29344 [D loss: 0.236873, acc.: 60.94%] [G loss: 0.308206]\n",
      "epoch:31 step:29345 [D loss: 0.245220, acc.: 53.12%] [G loss: 0.296220]\n",
      "epoch:31 step:29346 [D loss: 0.227167, acc.: 64.84%] [G loss: 0.290240]\n",
      "epoch:31 step:29347 [D loss: 0.234860, acc.: 60.16%] [G loss: 0.314112]\n",
      "epoch:31 step:29348 [D loss: 0.246140, acc.: 59.38%] [G loss: 0.307612]\n",
      "epoch:31 step:29349 [D loss: 0.251682, acc.: 55.47%] [G loss: 0.294610]\n",
      "epoch:31 step:29350 [D loss: 0.232561, acc.: 61.72%] [G loss: 0.300928]\n",
      "epoch:31 step:29351 [D loss: 0.246403, acc.: 56.25%] [G loss: 0.293734]\n",
      "epoch:31 step:29352 [D loss: 0.234515, acc.: 61.72%] [G loss: 0.278683]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:31 step:29353 [D loss: 0.228823, acc.: 63.28%] [G loss: 0.291927]\n",
      "epoch:31 step:29354 [D loss: 0.253346, acc.: 47.66%] [G loss: 0.300006]\n",
      "epoch:31 step:29355 [D loss: 0.212924, acc.: 64.84%] [G loss: 0.305106]\n",
      "epoch:31 step:29356 [D loss: 0.226889, acc.: 65.62%] [G loss: 0.297309]\n",
      "epoch:31 step:29357 [D loss: 0.246632, acc.: 51.56%] [G loss: 0.299753]\n",
      "epoch:31 step:29358 [D loss: 0.226332, acc.: 63.28%] [G loss: 0.330737]\n",
      "epoch:31 step:29359 [D loss: 0.235150, acc.: 60.16%] [G loss: 0.288550]\n",
      "epoch:31 step:29360 [D loss: 0.240584, acc.: 53.91%] [G loss: 0.290443]\n",
      "epoch:31 step:29361 [D loss: 0.226365, acc.: 62.50%] [G loss: 0.295303]\n",
      "epoch:31 step:29362 [D loss: 0.238636, acc.: 54.69%] [G loss: 0.328675]\n",
      "epoch:31 step:29363 [D loss: 0.229631, acc.: 63.28%] [G loss: 0.314481]\n",
      "epoch:31 step:29364 [D loss: 0.238944, acc.: 61.72%] [G loss: 0.269018]\n",
      "epoch:31 step:29365 [D loss: 0.241485, acc.: 57.03%] [G loss: 0.286496]\n",
      "epoch:31 step:29366 [D loss: 0.241563, acc.: 54.69%] [G loss: 0.301576]\n",
      "epoch:31 step:29367 [D loss: 0.240874, acc.: 61.72%] [G loss: 0.300344]\n",
      "epoch:31 step:29368 [D loss: 0.247533, acc.: 57.03%] [G loss: 0.280156]\n",
      "epoch:31 step:29369 [D loss: 0.263359, acc.: 48.44%] [G loss: 0.279598]\n",
      "epoch:31 step:29370 [D loss: 0.236691, acc.: 56.25%] [G loss: 0.278908]\n",
      "epoch:31 step:29371 [D loss: 0.254740, acc.: 47.66%] [G loss: 0.281535]\n",
      "epoch:31 step:29372 [D loss: 0.223772, acc.: 66.41%] [G loss: 0.293891]\n",
      "epoch:31 step:29373 [D loss: 0.237460, acc.: 59.38%] [G loss: 0.285518]\n",
      "epoch:31 step:29374 [D loss: 0.247763, acc.: 52.34%] [G loss: 0.303303]\n",
      "epoch:31 step:29375 [D loss: 0.220260, acc.: 67.19%] [G loss: 0.322237]\n",
      "epoch:31 step:29376 [D loss: 0.256138, acc.: 51.56%] [G loss: 0.283779]\n",
      "epoch:31 step:29377 [D loss: 0.243496, acc.: 55.47%] [G loss: 0.325778]\n",
      "epoch:31 step:29378 [D loss: 0.245864, acc.: 56.25%] [G loss: 0.281750]\n",
      "epoch:31 step:29379 [D loss: 0.254085, acc.: 57.03%] [G loss: 0.276236]\n",
      "epoch:31 step:29380 [D loss: 0.242025, acc.: 57.03%] [G loss: 0.293249]\n",
      "epoch:31 step:29381 [D loss: 0.234981, acc.: 57.81%] [G loss: 0.292019]\n",
      "epoch:31 step:29382 [D loss: 0.247790, acc.: 55.47%] [G loss: 0.288133]\n",
      "epoch:31 step:29383 [D loss: 0.241015, acc.: 61.72%] [G loss: 0.297187]\n",
      "epoch:31 step:29384 [D loss: 0.223548, acc.: 64.84%] [G loss: 0.291553]\n",
      "epoch:31 step:29385 [D loss: 0.222463, acc.: 66.41%] [G loss: 0.288229]\n",
      "epoch:31 step:29386 [D loss: 0.234186, acc.: 60.16%] [G loss: 0.314685]\n",
      "epoch:31 step:29387 [D loss: 0.241601, acc.: 60.16%] [G loss: 0.313936]\n",
      "epoch:31 step:29388 [D loss: 0.235742, acc.: 57.81%] [G loss: 0.295295]\n",
      "epoch:31 step:29389 [D loss: 0.241108, acc.: 56.25%] [G loss: 0.301873]\n",
      "epoch:31 step:29390 [D loss: 0.247977, acc.: 52.34%] [G loss: 0.307896]\n",
      "epoch:31 step:29391 [D loss: 0.241275, acc.: 57.03%] [G loss: 0.307144]\n",
      "epoch:31 step:29392 [D loss: 0.228852, acc.: 66.41%] [G loss: 0.291118]\n",
      "epoch:31 step:29393 [D loss: 0.235355, acc.: 59.38%] [G loss: 0.301361]\n",
      "epoch:31 step:29394 [D loss: 0.253559, acc.: 57.03%] [G loss: 0.298727]\n",
      "epoch:31 step:29395 [D loss: 0.239952, acc.: 56.25%] [G loss: 0.320638]\n",
      "epoch:31 step:29396 [D loss: 0.252077, acc.: 51.56%] [G loss: 0.309286]\n",
      "epoch:31 step:29397 [D loss: 0.252502, acc.: 51.56%] [G loss: 0.298112]\n",
      "epoch:31 step:29398 [D loss: 0.237049, acc.: 58.59%] [G loss: 0.273066]\n",
      "epoch:31 step:29399 [D loss: 0.233357, acc.: 62.50%] [G loss: 0.303706]\n",
      "epoch:31 step:29400 [D loss: 0.234165, acc.: 60.94%] [G loss: 0.272089]\n",
      "epoch:31 step:29401 [D loss: 0.250743, acc.: 51.56%] [G loss: 0.297697]\n",
      "epoch:31 step:29402 [D loss: 0.211961, acc.: 66.41%] [G loss: 0.316277]\n",
      "epoch:31 step:29403 [D loss: 0.222815, acc.: 67.19%] [G loss: 0.292558]\n",
      "epoch:31 step:29404 [D loss: 0.241936, acc.: 56.25%] [G loss: 0.284518]\n",
      "epoch:31 step:29405 [D loss: 0.239938, acc.: 60.16%] [G loss: 0.270989]\n",
      "epoch:31 step:29406 [D loss: 0.236663, acc.: 59.38%] [G loss: 0.302536]\n",
      "epoch:31 step:29407 [D loss: 0.231873, acc.: 57.81%] [G loss: 0.316427]\n",
      "epoch:31 step:29408 [D loss: 0.242345, acc.: 53.91%] [G loss: 0.276659]\n",
      "epoch:31 step:29409 [D loss: 0.231619, acc.: 63.28%] [G loss: 0.319321]\n",
      "epoch:31 step:29410 [D loss: 0.236654, acc.: 53.12%] [G loss: 0.305832]\n",
      "epoch:31 step:29411 [D loss: 0.227358, acc.: 64.84%] [G loss: 0.294516]\n",
      "epoch:31 step:29412 [D loss: 0.227623, acc.: 64.84%] [G loss: 0.303508]\n",
      "epoch:31 step:29413 [D loss: 0.232726, acc.: 59.38%] [G loss: 0.276612]\n",
      "epoch:31 step:29414 [D loss: 0.253821, acc.: 55.47%] [G loss: 0.292976]\n",
      "epoch:31 step:29415 [D loss: 0.251186, acc.: 55.47%] [G loss: 0.308887]\n",
      "epoch:31 step:29416 [D loss: 0.226993, acc.: 63.28%] [G loss: 0.302341]\n",
      "epoch:31 step:29417 [D loss: 0.248454, acc.: 56.25%] [G loss: 0.332628]\n",
      "epoch:31 step:29418 [D loss: 0.238674, acc.: 57.03%] [G loss: 0.310693]\n",
      "epoch:31 step:29419 [D loss: 0.239435, acc.: 56.25%] [G loss: 0.303751]\n",
      "epoch:31 step:29420 [D loss: 0.242354, acc.: 57.03%] [G loss: 0.298489]\n",
      "epoch:31 step:29421 [D loss: 0.242851, acc.: 60.16%] [G loss: 0.282147]\n",
      "epoch:31 step:29422 [D loss: 0.250356, acc.: 57.81%] [G loss: 0.300407]\n",
      "epoch:31 step:29423 [D loss: 0.252966, acc.: 56.25%] [G loss: 0.320670]\n",
      "epoch:31 step:29424 [D loss: 0.233417, acc.: 62.50%] [G loss: 0.322427]\n",
      "epoch:31 step:29425 [D loss: 0.237196, acc.: 57.81%] [G loss: 0.283847]\n",
      "epoch:31 step:29426 [D loss: 0.237005, acc.: 60.16%] [G loss: 0.320851]\n",
      "epoch:31 step:29427 [D loss: 0.238515, acc.: 60.16%] [G loss: 0.299098]\n",
      "epoch:31 step:29428 [D loss: 0.230692, acc.: 63.28%] [G loss: 0.326795]\n",
      "epoch:31 step:29429 [D loss: 0.247366, acc.: 56.25%] [G loss: 0.326026]\n",
      "epoch:31 step:29430 [D loss: 0.252698, acc.: 54.69%] [G loss: 0.276667]\n",
      "epoch:31 step:29431 [D loss: 0.259019, acc.: 50.00%] [G loss: 0.287363]\n",
      "epoch:31 step:29432 [D loss: 0.238955, acc.: 57.03%] [G loss: 0.289256]\n",
      "epoch:31 step:29433 [D loss: 0.240251, acc.: 56.25%] [G loss: 0.289021]\n",
      "epoch:31 step:29434 [D loss: 0.245505, acc.: 57.81%] [G loss: 0.294672]\n",
      "epoch:31 step:29435 [D loss: 0.243394, acc.: 63.28%] [G loss: 0.281651]\n",
      "epoch:31 step:29436 [D loss: 0.225530, acc.: 62.50%] [G loss: 0.325932]\n",
      "epoch:31 step:29437 [D loss: 0.228966, acc.: 63.28%] [G loss: 0.310609]\n",
      "epoch:31 step:29438 [D loss: 0.234174, acc.: 61.72%] [G loss: 0.308867]\n",
      "epoch:31 step:29439 [D loss: 0.234985, acc.: 59.38%] [G loss: 0.292022]\n",
      "epoch:31 step:29440 [D loss: 0.233831, acc.: 60.94%] [G loss: 0.319204]\n",
      "epoch:31 step:29441 [D loss: 0.242202, acc.: 53.12%] [G loss: 0.310354]\n",
      "epoch:31 step:29442 [D loss: 0.219824, acc.: 67.97%] [G loss: 0.322580]\n",
      "epoch:31 step:29443 [D loss: 0.244153, acc.: 57.03%] [G loss: 0.311878]\n",
      "epoch:31 step:29444 [D loss: 0.252291, acc.: 49.22%] [G loss: 0.305722]\n",
      "epoch:31 step:29445 [D loss: 0.227503, acc.: 65.62%] [G loss: 0.310017]\n",
      "epoch:31 step:29446 [D loss: 0.214819, acc.: 70.31%] [G loss: 0.319339]\n",
      "epoch:31 step:29447 [D loss: 0.220163, acc.: 69.53%] [G loss: 0.303744]\n",
      "epoch:31 step:29448 [D loss: 0.239268, acc.: 58.59%] [G loss: 0.312174]\n",
      "epoch:31 step:29449 [D loss: 0.224412, acc.: 60.94%] [G loss: 0.292303]\n",
      "epoch:31 step:29450 [D loss: 0.257144, acc.: 53.12%] [G loss: 0.289956]\n",
      "epoch:31 step:29451 [D loss: 0.234522, acc.: 59.38%] [G loss: 0.296980]\n",
      "epoch:31 step:29452 [D loss: 0.236464, acc.: 60.94%] [G loss: 0.299372]\n",
      "epoch:31 step:29453 [D loss: 0.243659, acc.: 53.91%] [G loss: 0.290460]\n",
      "epoch:31 step:29454 [D loss: 0.234957, acc.: 53.91%] [G loss: 0.290604]\n",
      "epoch:31 step:29455 [D loss: 0.235277, acc.: 57.81%] [G loss: 0.320212]\n",
      "epoch:31 step:29456 [D loss: 0.251565, acc.: 51.56%] [G loss: 0.291354]\n",
      "epoch:31 step:29457 [D loss: 0.227288, acc.: 60.16%] [G loss: 0.286807]\n",
      "epoch:31 step:29458 [D loss: 0.253876, acc.: 50.00%] [G loss: 0.305486]\n",
      "epoch:31 step:29459 [D loss: 0.253221, acc.: 50.00%] [G loss: 0.304595]\n",
      "epoch:31 step:29460 [D loss: 0.237381, acc.: 53.12%] [G loss: 0.302547]\n",
      "epoch:31 step:29461 [D loss: 0.246439, acc.: 59.38%] [G loss: 0.271717]\n",
      "epoch:31 step:29462 [D loss: 0.241212, acc.: 58.59%] [G loss: 0.315904]\n",
      "epoch:31 step:29463 [D loss: 0.240378, acc.: 55.47%] [G loss: 0.319777]\n",
      "epoch:31 step:29464 [D loss: 0.249748, acc.: 53.12%] [G loss: 0.290822]\n",
      "epoch:31 step:29465 [D loss: 0.237848, acc.: 62.50%] [G loss: 0.313983]\n",
      "epoch:31 step:29466 [D loss: 0.218551, acc.: 64.06%] [G loss: 0.317453]\n",
      "epoch:31 step:29467 [D loss: 0.223130, acc.: 67.19%] [G loss: 0.305479]\n",
      "epoch:31 step:29468 [D loss: 0.238743, acc.: 60.16%] [G loss: 0.281602]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:31 step:29469 [D loss: 0.220573, acc.: 66.41%] [G loss: 0.296950]\n",
      "epoch:31 step:29470 [D loss: 0.228144, acc.: 64.06%] [G loss: 0.273197]\n",
      "epoch:31 step:29471 [D loss: 0.251205, acc.: 57.03%] [G loss: 0.305276]\n",
      "epoch:31 step:29472 [D loss: 0.247168, acc.: 53.12%] [G loss: 0.288748]\n",
      "epoch:31 step:29473 [D loss: 0.236444, acc.: 57.81%] [G loss: 0.329471]\n",
      "epoch:31 step:29474 [D loss: 0.240486, acc.: 56.25%] [G loss: 0.277969]\n",
      "epoch:31 step:29475 [D loss: 0.248452, acc.: 56.25%] [G loss: 0.301916]\n",
      "epoch:31 step:29476 [D loss: 0.229817, acc.: 62.50%] [G loss: 0.312079]\n",
      "epoch:31 step:29477 [D loss: 0.247851, acc.: 57.81%] [G loss: 0.269296]\n",
      "epoch:31 step:29478 [D loss: 0.238023, acc.: 57.81%] [G loss: 0.270318]\n",
      "epoch:31 step:29479 [D loss: 0.219338, acc.: 64.06%] [G loss: 0.310522]\n",
      "epoch:31 step:29480 [D loss: 0.261466, acc.: 44.53%] [G loss: 0.293887]\n",
      "epoch:31 step:29481 [D loss: 0.247285, acc.: 53.12%] [G loss: 0.314452]\n",
      "epoch:31 step:29482 [D loss: 0.233398, acc.: 63.28%] [G loss: 0.302121]\n",
      "epoch:31 step:29483 [D loss: 0.250345, acc.: 50.00%] [G loss: 0.298331]\n",
      "epoch:31 step:29484 [D loss: 0.236698, acc.: 59.38%] [G loss: 0.299615]\n",
      "epoch:31 step:29485 [D loss: 0.251682, acc.: 52.34%] [G loss: 0.309678]\n",
      "epoch:31 step:29486 [D loss: 0.233784, acc.: 58.59%] [G loss: 0.333645]\n",
      "epoch:31 step:29487 [D loss: 0.243371, acc.: 56.25%] [G loss: 0.323421]\n",
      "epoch:31 step:29488 [D loss: 0.247082, acc.: 50.00%] [G loss: 0.304433]\n",
      "epoch:31 step:29489 [D loss: 0.225601, acc.: 62.50%] [G loss: 0.299282]\n",
      "epoch:31 step:29490 [D loss: 0.252660, acc.: 52.34%] [G loss: 0.313291]\n",
      "epoch:31 step:29491 [D loss: 0.223421, acc.: 62.50%] [G loss: 0.289008]\n",
      "epoch:31 step:29492 [D loss: 0.224722, acc.: 61.72%] [G loss: 0.287401]\n",
      "epoch:31 step:29493 [D loss: 0.260028, acc.: 49.22%] [G loss: 0.286701]\n",
      "epoch:31 step:29494 [D loss: 0.234163, acc.: 61.72%] [G loss: 0.300524]\n",
      "epoch:31 step:29495 [D loss: 0.258868, acc.: 51.56%] [G loss: 0.281256]\n",
      "epoch:31 step:29496 [D loss: 0.250802, acc.: 56.25%] [G loss: 0.259152]\n",
      "epoch:31 step:29497 [D loss: 0.243585, acc.: 58.59%] [G loss: 0.313065]\n",
      "epoch:31 step:29498 [D loss: 0.216028, acc.: 65.62%] [G loss: 0.301652]\n",
      "epoch:31 step:29499 [D loss: 0.231841, acc.: 64.84%] [G loss: 0.281187]\n",
      "epoch:31 step:29500 [D loss: 0.238364, acc.: 59.38%] [G loss: 0.285478]\n",
      "epoch:31 step:29501 [D loss: 0.238397, acc.: 53.91%] [G loss: 0.322328]\n",
      "epoch:31 step:29502 [D loss: 0.238939, acc.: 60.94%] [G loss: 0.333322]\n",
      "epoch:31 step:29503 [D loss: 0.245692, acc.: 57.03%] [G loss: 0.312161]\n",
      "epoch:31 step:29504 [D loss: 0.245578, acc.: 57.81%] [G loss: 0.300228]\n",
      "epoch:31 step:29505 [D loss: 0.237124, acc.: 60.94%] [G loss: 0.306979]\n",
      "epoch:31 step:29506 [D loss: 0.233145, acc.: 61.72%] [G loss: 0.322097]\n",
      "epoch:31 step:29507 [D loss: 0.241071, acc.: 57.81%] [G loss: 0.286176]\n",
      "epoch:31 step:29508 [D loss: 0.235686, acc.: 58.59%] [G loss: 0.307025]\n",
      "epoch:31 step:29509 [D loss: 0.250169, acc.: 55.47%] [G loss: 0.267248]\n",
      "epoch:31 step:29510 [D loss: 0.243577, acc.: 57.03%] [G loss: 0.313139]\n",
      "epoch:31 step:29511 [D loss: 0.251867, acc.: 56.25%] [G loss: 0.310818]\n",
      "epoch:31 step:29512 [D loss: 0.237883, acc.: 60.94%] [G loss: 0.287584]\n",
      "epoch:31 step:29513 [D loss: 0.250837, acc.: 60.94%] [G loss: 0.262878]\n",
      "epoch:31 step:29514 [D loss: 0.234373, acc.: 62.50%] [G loss: 0.305790]\n",
      "epoch:31 step:29515 [D loss: 0.229323, acc.: 60.16%] [G loss: 0.286834]\n",
      "epoch:31 step:29516 [D loss: 0.245559, acc.: 55.47%] [G loss: 0.266939]\n",
      "epoch:31 step:29517 [D loss: 0.254882, acc.: 57.81%] [G loss: 0.279665]\n",
      "epoch:31 step:29518 [D loss: 0.243819, acc.: 57.81%] [G loss: 0.280345]\n",
      "epoch:31 step:29519 [D loss: 0.243240, acc.: 55.47%] [G loss: 0.280962]\n",
      "epoch:31 step:29520 [D loss: 0.238378, acc.: 59.38%] [G loss: 0.269025]\n",
      "epoch:31 step:29521 [D loss: 0.244997, acc.: 60.94%] [G loss: 0.272689]\n",
      "epoch:31 step:29522 [D loss: 0.242121, acc.: 56.25%] [G loss: 0.286064]\n",
      "epoch:31 step:29523 [D loss: 0.236546, acc.: 55.47%] [G loss: 0.300257]\n",
      "epoch:31 step:29524 [D loss: 0.229637, acc.: 62.50%] [G loss: 0.279563]\n",
      "epoch:31 step:29525 [D loss: 0.238234, acc.: 59.38%] [G loss: 0.320305]\n",
      "epoch:31 step:29526 [D loss: 0.235308, acc.: 64.84%] [G loss: 0.291492]\n",
      "epoch:31 step:29527 [D loss: 0.263558, acc.: 50.78%] [G loss: 0.298973]\n",
      "epoch:31 step:29528 [D loss: 0.229662, acc.: 59.38%] [G loss: 0.284540]\n",
      "epoch:31 step:29529 [D loss: 0.249932, acc.: 58.59%] [G loss: 0.282070]\n",
      "epoch:31 step:29530 [D loss: 0.242950, acc.: 56.25%] [G loss: 0.284062]\n",
      "epoch:31 step:29531 [D loss: 0.242036, acc.: 56.25%] [G loss: 0.297129]\n",
      "epoch:31 step:29532 [D loss: 0.247555, acc.: 55.47%] [G loss: 0.311959]\n",
      "epoch:31 step:29533 [D loss: 0.222340, acc.: 60.94%] [G loss: 0.298416]\n",
      "epoch:31 step:29534 [D loss: 0.252883, acc.: 53.91%] [G loss: 0.285918]\n",
      "epoch:31 step:29535 [D loss: 0.247202, acc.: 51.56%] [G loss: 0.259481]\n",
      "epoch:31 step:29536 [D loss: 0.235699, acc.: 56.25%] [G loss: 0.318176]\n",
      "epoch:31 step:29537 [D loss: 0.243785, acc.: 57.03%] [G loss: 0.286865]\n",
      "epoch:31 step:29538 [D loss: 0.255094, acc.: 55.47%] [G loss: 0.292784]\n",
      "epoch:31 step:29539 [D loss: 0.240386, acc.: 60.94%] [G loss: 0.298536]\n",
      "epoch:31 step:29540 [D loss: 0.221405, acc.: 64.06%] [G loss: 0.279033]\n",
      "epoch:31 step:29541 [D loss: 0.250417, acc.: 50.00%] [G loss: 0.294328]\n",
      "epoch:31 step:29542 [D loss: 0.245347, acc.: 54.69%] [G loss: 0.283413]\n",
      "epoch:31 step:29543 [D loss: 0.245280, acc.: 53.12%] [G loss: 0.305887]\n",
      "epoch:31 step:29544 [D loss: 0.235634, acc.: 60.16%] [G loss: 0.306246]\n",
      "epoch:31 step:29545 [D loss: 0.245665, acc.: 59.38%] [G loss: 0.298215]\n",
      "epoch:31 step:29546 [D loss: 0.237149, acc.: 57.03%] [G loss: 0.328581]\n",
      "epoch:31 step:29547 [D loss: 0.249602, acc.: 55.47%] [G loss: 0.265518]\n",
      "epoch:31 step:29548 [D loss: 0.223352, acc.: 61.72%] [G loss: 0.323357]\n",
      "epoch:31 step:29549 [D loss: 0.233585, acc.: 63.28%] [G loss: 0.287294]\n",
      "epoch:31 step:29550 [D loss: 0.240884, acc.: 61.72%] [G loss: 0.285881]\n",
      "epoch:31 step:29551 [D loss: 0.246804, acc.: 56.25%] [G loss: 0.286429]\n",
      "epoch:31 step:29552 [D loss: 0.230239, acc.: 59.38%] [G loss: 0.321290]\n",
      "epoch:31 step:29553 [D loss: 0.213786, acc.: 67.97%] [G loss: 0.308483]\n",
      "epoch:31 step:29554 [D loss: 0.235962, acc.: 56.25%] [G loss: 0.298450]\n",
      "epoch:31 step:29555 [D loss: 0.237043, acc.: 57.03%] [G loss: 0.308510]\n",
      "epoch:31 step:29556 [D loss: 0.245056, acc.: 60.94%] [G loss: 0.302859]\n",
      "epoch:31 step:29557 [D loss: 0.238347, acc.: 53.91%] [G loss: 0.297813]\n",
      "epoch:31 step:29558 [D loss: 0.229257, acc.: 62.50%] [G loss: 0.299797]\n",
      "epoch:31 step:29559 [D loss: 0.232669, acc.: 65.62%] [G loss: 0.297489]\n",
      "epoch:31 step:29560 [D loss: 0.246324, acc.: 60.94%] [G loss: 0.291101]\n",
      "epoch:31 step:29561 [D loss: 0.224922, acc.: 64.84%] [G loss: 0.335768]\n",
      "epoch:31 step:29562 [D loss: 0.255853, acc.: 53.12%] [G loss: 0.310492]\n",
      "epoch:31 step:29563 [D loss: 0.239546, acc.: 57.03%] [G loss: 0.297264]\n",
      "epoch:31 step:29564 [D loss: 0.237503, acc.: 56.25%] [G loss: 0.302273]\n",
      "epoch:31 step:29565 [D loss: 0.238248, acc.: 53.91%] [G loss: 0.310518]\n",
      "epoch:31 step:29566 [D loss: 0.216721, acc.: 64.84%] [G loss: 0.318264]\n",
      "epoch:31 step:29567 [D loss: 0.231929, acc.: 58.59%] [G loss: 0.311587]\n",
      "epoch:31 step:29568 [D loss: 0.262397, acc.: 50.78%] [G loss: 0.282688]\n",
      "epoch:31 step:29569 [D loss: 0.248495, acc.: 51.56%] [G loss: 0.321248]\n",
      "epoch:31 step:29570 [D loss: 0.259443, acc.: 49.22%] [G loss: 0.308027]\n",
      "epoch:31 step:29571 [D loss: 0.243095, acc.: 57.81%] [G loss: 0.328830]\n",
      "epoch:31 step:29572 [D loss: 0.232038, acc.: 61.72%] [G loss: 0.275773]\n",
      "epoch:31 step:29573 [D loss: 0.249766, acc.: 52.34%] [G loss: 0.312523]\n",
      "epoch:31 step:29574 [D loss: 0.236542, acc.: 57.81%] [G loss: 0.288591]\n",
      "epoch:31 step:29575 [D loss: 0.244597, acc.: 56.25%] [G loss: 0.284343]\n",
      "epoch:31 step:29576 [D loss: 0.248847, acc.: 54.69%] [G loss: 0.281957]\n",
      "epoch:31 step:29577 [D loss: 0.241272, acc.: 56.25%] [G loss: 0.276212]\n",
      "epoch:31 step:29578 [D loss: 0.228248, acc.: 61.72%] [G loss: 0.307490]\n",
      "epoch:31 step:29579 [D loss: 0.251192, acc.: 57.03%] [G loss: 0.296459]\n",
      "epoch:31 step:29580 [D loss: 0.230683, acc.: 61.72%] [G loss: 0.309144]\n",
      "epoch:31 step:29581 [D loss: 0.244600, acc.: 60.94%] [G loss: 0.279138]\n",
      "epoch:31 step:29582 [D loss: 0.229249, acc.: 64.06%] [G loss: 0.299980]\n",
      "epoch:31 step:29583 [D loss: 0.244710, acc.: 54.69%] [G loss: 0.276107]\n",
      "epoch:31 step:29584 [D loss: 0.236113, acc.: 59.38%] [G loss: 0.295922]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:31 step:29585 [D loss: 0.240223, acc.: 57.03%] [G loss: 0.309867]\n",
      "epoch:31 step:29586 [D loss: 0.241716, acc.: 56.25%] [G loss: 0.294861]\n",
      "epoch:31 step:29587 [D loss: 0.217952, acc.: 66.41%] [G loss: 0.321100]\n",
      "epoch:31 step:29588 [D loss: 0.233547, acc.: 60.16%] [G loss: 0.308768]\n",
      "epoch:31 step:29589 [D loss: 0.242135, acc.: 54.69%] [G loss: 0.282542]\n",
      "epoch:31 step:29590 [D loss: 0.227976, acc.: 61.72%] [G loss: 0.324429]\n",
      "epoch:31 step:29591 [D loss: 0.260010, acc.: 52.34%] [G loss: 0.324433]\n",
      "epoch:31 step:29592 [D loss: 0.226154, acc.: 60.16%] [G loss: 0.307779]\n",
      "epoch:31 step:29593 [D loss: 0.251179, acc.: 61.72%] [G loss: 0.315469]\n",
      "epoch:31 step:29594 [D loss: 0.250546, acc.: 54.69%] [G loss: 0.331299]\n",
      "epoch:31 step:29595 [D loss: 0.246950, acc.: 59.38%] [G loss: 0.300576]\n",
      "epoch:31 step:29596 [D loss: 0.231672, acc.: 57.81%] [G loss: 0.315446]\n",
      "epoch:31 step:29597 [D loss: 0.231326, acc.: 57.81%] [G loss: 0.302287]\n",
      "epoch:31 step:29598 [D loss: 0.238788, acc.: 51.56%] [G loss: 0.317450]\n",
      "epoch:31 step:29599 [D loss: 0.217835, acc.: 65.62%] [G loss: 0.344343]\n",
      "epoch:31 step:29600 [D loss: 0.238593, acc.: 53.91%] [G loss: 0.317304]\n",
      "epoch:31 step:29601 [D loss: 0.226156, acc.: 58.59%] [G loss: 0.296391]\n",
      "epoch:31 step:29602 [D loss: 0.234466, acc.: 62.50%] [G loss: 0.301918]\n",
      "epoch:31 step:29603 [D loss: 0.226289, acc.: 62.50%] [G loss: 0.308932]\n",
      "epoch:31 step:29604 [D loss: 0.231966, acc.: 64.84%] [G loss: 0.309408]\n",
      "epoch:31 step:29605 [D loss: 0.231885, acc.: 62.50%] [G loss: 0.312213]\n",
      "epoch:31 step:29606 [D loss: 0.248760, acc.: 57.81%] [G loss: 0.300362]\n",
      "epoch:31 step:29607 [D loss: 0.247285, acc.: 56.25%] [G loss: 0.314122]\n",
      "epoch:31 step:29608 [D loss: 0.228169, acc.: 64.06%] [G loss: 0.307884]\n",
      "epoch:31 step:29609 [D loss: 0.238651, acc.: 59.38%] [G loss: 0.299206]\n",
      "epoch:31 step:29610 [D loss: 0.246680, acc.: 56.25%] [G loss: 0.293743]\n",
      "epoch:31 step:29611 [D loss: 0.218704, acc.: 69.53%] [G loss: 0.271514]\n",
      "epoch:31 step:29612 [D loss: 0.245770, acc.: 52.34%] [G loss: 0.317136]\n",
      "epoch:31 step:29613 [D loss: 0.235411, acc.: 58.59%] [G loss: 0.281584]\n",
      "epoch:31 step:29614 [D loss: 0.242569, acc.: 60.16%] [G loss: 0.293176]\n",
      "epoch:31 step:29615 [D loss: 0.232005, acc.: 59.38%] [G loss: 0.295806]\n",
      "epoch:31 step:29616 [D loss: 0.225238, acc.: 60.94%] [G loss: 0.339196]\n",
      "epoch:31 step:29617 [D loss: 0.241983, acc.: 58.59%] [G loss: 0.287851]\n",
      "epoch:31 step:29618 [D loss: 0.234818, acc.: 62.50%] [G loss: 0.302680]\n",
      "epoch:31 step:29619 [D loss: 0.217593, acc.: 68.75%] [G loss: 0.310338]\n",
      "epoch:31 step:29620 [D loss: 0.241570, acc.: 58.59%] [G loss: 0.326080]\n",
      "epoch:31 step:29621 [D loss: 0.248192, acc.: 59.38%] [G loss: 0.315493]\n",
      "epoch:31 step:29622 [D loss: 0.228933, acc.: 64.06%] [G loss: 0.269681]\n",
      "epoch:31 step:29623 [D loss: 0.225972, acc.: 65.62%] [G loss: 0.316095]\n",
      "epoch:31 step:29624 [D loss: 0.238938, acc.: 60.94%] [G loss: 0.296980]\n",
      "epoch:31 step:29625 [D loss: 0.247223, acc.: 59.38%] [G loss: 0.295028]\n",
      "epoch:31 step:29626 [D loss: 0.240858, acc.: 55.47%] [G loss: 0.314875]\n",
      "epoch:31 step:29627 [D loss: 0.262754, acc.: 43.75%] [G loss: 0.316716]\n",
      "epoch:31 step:29628 [D loss: 0.240594, acc.: 57.03%] [G loss: 0.271353]\n",
      "epoch:31 step:29629 [D loss: 0.247273, acc.: 53.12%] [G loss: 0.295424]\n",
      "epoch:31 step:29630 [D loss: 0.252412, acc.: 50.78%] [G loss: 0.308134]\n",
      "epoch:31 step:29631 [D loss: 0.248184, acc.: 54.69%] [G loss: 0.283288]\n",
      "epoch:31 step:29632 [D loss: 0.235795, acc.: 59.38%] [G loss: 0.333217]\n",
      "epoch:31 step:29633 [D loss: 0.231331, acc.: 62.50%] [G loss: 0.315573]\n",
      "epoch:31 step:29634 [D loss: 0.232850, acc.: 61.72%] [G loss: 0.297956]\n",
      "epoch:31 step:29635 [D loss: 0.264090, acc.: 51.56%] [G loss: 0.294288]\n",
      "epoch:31 step:29636 [D loss: 0.241565, acc.: 53.12%] [G loss: 0.298139]\n",
      "epoch:31 step:29637 [D loss: 0.233524, acc.: 54.69%] [G loss: 0.314331]\n",
      "epoch:31 step:29638 [D loss: 0.243042, acc.: 53.91%] [G loss: 0.297383]\n",
      "epoch:31 step:29639 [D loss: 0.251540, acc.: 52.34%] [G loss: 0.306710]\n",
      "epoch:31 step:29640 [D loss: 0.239337, acc.: 60.16%] [G loss: 0.280145]\n",
      "epoch:31 step:29641 [D loss: 0.221266, acc.: 67.97%] [G loss: 0.297630]\n",
      "epoch:31 step:29642 [D loss: 0.236342, acc.: 57.03%] [G loss: 0.315777]\n",
      "epoch:31 step:29643 [D loss: 0.247052, acc.: 57.03%] [G loss: 0.278449]\n",
      "epoch:31 step:29644 [D loss: 0.232778, acc.: 60.94%] [G loss: 0.302257]\n",
      "epoch:31 step:29645 [D loss: 0.240792, acc.: 57.03%] [G loss: 0.283928]\n",
      "epoch:31 step:29646 [D loss: 0.244770, acc.: 57.81%] [G loss: 0.291606]\n",
      "epoch:31 step:29647 [D loss: 0.233579, acc.: 57.03%] [G loss: 0.332866]\n",
      "epoch:31 step:29648 [D loss: 0.249036, acc.: 53.91%] [G loss: 0.317621]\n",
      "epoch:31 step:29649 [D loss: 0.243706, acc.: 55.47%] [G loss: 0.295771]\n",
      "epoch:31 step:29650 [D loss: 0.230834, acc.: 64.06%] [G loss: 0.312389]\n",
      "epoch:31 step:29651 [D loss: 0.256495, acc.: 51.56%] [G loss: 0.300161]\n",
      "epoch:31 step:29652 [D loss: 0.246366, acc.: 58.59%] [G loss: 0.293455]\n",
      "epoch:31 step:29653 [D loss: 0.229662, acc.: 63.28%] [G loss: 0.278079]\n",
      "epoch:31 step:29654 [D loss: 0.234624, acc.: 60.16%] [G loss: 0.340852]\n",
      "epoch:31 step:29655 [D loss: 0.237074, acc.: 60.94%] [G loss: 0.296745]\n",
      "epoch:31 step:29656 [D loss: 0.256854, acc.: 53.12%] [G loss: 0.301850]\n",
      "epoch:31 step:29657 [D loss: 0.223067, acc.: 61.72%] [G loss: 0.342778]\n",
      "epoch:31 step:29658 [D loss: 0.242955, acc.: 55.47%] [G loss: 0.313237]\n",
      "epoch:31 step:29659 [D loss: 0.244708, acc.: 57.81%] [G loss: 0.282790]\n",
      "epoch:31 step:29660 [D loss: 0.237714, acc.: 62.50%] [G loss: 0.326636]\n",
      "epoch:31 step:29661 [D loss: 0.231294, acc.: 64.06%] [G loss: 0.289217]\n",
      "epoch:31 step:29662 [D loss: 0.229403, acc.: 58.59%] [G loss: 0.300016]\n",
      "epoch:31 step:29663 [D loss: 0.233390, acc.: 60.94%] [G loss: 0.325864]\n",
      "epoch:31 step:29664 [D loss: 0.259436, acc.: 55.47%] [G loss: 0.269993]\n",
      "epoch:31 step:29665 [D loss: 0.216514, acc.: 64.84%] [G loss: 0.297497]\n",
      "epoch:31 step:29666 [D loss: 0.241741, acc.: 55.47%] [G loss: 0.270536]\n",
      "epoch:31 step:29667 [D loss: 0.241721, acc.: 62.50%] [G loss: 0.326419]\n",
      "epoch:31 step:29668 [D loss: 0.255679, acc.: 53.91%] [G loss: 0.278249]\n",
      "epoch:31 step:29669 [D loss: 0.226518, acc.: 57.81%] [G loss: 0.298484]\n",
      "epoch:31 step:29670 [D loss: 0.225505, acc.: 63.28%] [G loss: 0.297355]\n",
      "epoch:31 step:29671 [D loss: 0.235658, acc.: 58.59%] [G loss: 0.300499]\n",
      "epoch:31 step:29672 [D loss: 0.244760, acc.: 52.34%] [G loss: 0.317336]\n",
      "epoch:31 step:29673 [D loss: 0.244125, acc.: 54.69%] [G loss: 0.293498]\n",
      "epoch:31 step:29674 [D loss: 0.227251, acc.: 65.62%] [G loss: 0.319835]\n",
      "epoch:31 step:29675 [D loss: 0.240799, acc.: 55.47%] [G loss: 0.318781]\n",
      "epoch:31 step:29676 [D loss: 0.236764, acc.: 60.94%] [G loss: 0.295272]\n",
      "epoch:31 step:29677 [D loss: 0.232454, acc.: 62.50%] [G loss: 0.333208]\n",
      "epoch:31 step:29678 [D loss: 0.229700, acc.: 64.84%] [G loss: 0.339974]\n",
      "epoch:31 step:29679 [D loss: 0.239421, acc.: 56.25%] [G loss: 0.316873]\n",
      "epoch:31 step:29680 [D loss: 0.237605, acc.: 57.81%] [G loss: 0.311672]\n",
      "epoch:31 step:29681 [D loss: 0.243858, acc.: 57.03%] [G loss: 0.311035]\n",
      "epoch:31 step:29682 [D loss: 0.243739, acc.: 58.59%] [G loss: 0.319604]\n",
      "epoch:31 step:29683 [D loss: 0.237962, acc.: 64.06%] [G loss: 0.280793]\n",
      "epoch:31 step:29684 [D loss: 0.238122, acc.: 60.94%] [G loss: 0.301545]\n",
      "epoch:31 step:29685 [D loss: 0.227562, acc.: 65.62%] [G loss: 0.303501]\n",
      "epoch:31 step:29686 [D loss: 0.224516, acc.: 64.84%] [G loss: 0.308299]\n",
      "epoch:31 step:29687 [D loss: 0.246285, acc.: 55.47%] [G loss: 0.294220]\n",
      "epoch:31 step:29688 [D loss: 0.248995, acc.: 56.25%] [G loss: 0.315569]\n",
      "epoch:31 step:29689 [D loss: 0.227605, acc.: 62.50%] [G loss: 0.308470]\n",
      "epoch:31 step:29690 [D loss: 0.235070, acc.: 58.59%] [G loss: 0.309249]\n",
      "epoch:31 step:29691 [D loss: 0.239402, acc.: 62.50%] [G loss: 0.296129]\n",
      "epoch:31 step:29692 [D loss: 0.235813, acc.: 53.91%] [G loss: 0.311426]\n",
      "epoch:31 step:29693 [D loss: 0.232487, acc.: 63.28%] [G loss: 0.311077]\n",
      "epoch:31 step:29694 [D loss: 0.262377, acc.: 49.22%] [G loss: 0.286835]\n",
      "epoch:31 step:29695 [D loss: 0.224439, acc.: 61.72%] [G loss: 0.306790]\n",
      "epoch:31 step:29696 [D loss: 0.238591, acc.: 60.16%] [G loss: 0.301279]\n",
      "epoch:31 step:29697 [D loss: 0.236910, acc.: 60.16%] [G loss: 0.327336]\n",
      "epoch:31 step:29698 [D loss: 0.222496, acc.: 63.28%] [G loss: 0.318861]\n",
      "epoch:31 step:29699 [D loss: 0.240687, acc.: 59.38%] [G loss: 0.298649]\n",
      "epoch:31 step:29700 [D loss: 0.218476, acc.: 68.75%] [G loss: 0.286917]\n",
      "epoch:31 step:29701 [D loss: 0.243901, acc.: 59.38%] [G loss: 0.301512]\n",
      "epoch:31 step:29702 [D loss: 0.268115, acc.: 48.44%] [G loss: 0.301650]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:31 step:29703 [D loss: 0.225389, acc.: 65.62%] [G loss: 0.295978]\n",
      "epoch:31 step:29704 [D loss: 0.230560, acc.: 65.62%] [G loss: 0.323773]\n",
      "epoch:31 step:29705 [D loss: 0.249833, acc.: 54.69%] [G loss: 0.306278]\n",
      "epoch:31 step:29706 [D loss: 0.248318, acc.: 58.59%] [G loss: 0.292038]\n",
      "epoch:31 step:29707 [D loss: 0.239214, acc.: 64.84%] [G loss: 0.290621]\n",
      "epoch:31 step:29708 [D loss: 0.246334, acc.: 53.91%] [G loss: 0.325169]\n",
      "epoch:31 step:29709 [D loss: 0.228849, acc.: 60.94%] [G loss: 0.350034]\n",
      "epoch:31 step:29710 [D loss: 0.246708, acc.: 56.25%] [G loss: 0.303466]\n",
      "epoch:31 step:29711 [D loss: 0.219887, acc.: 65.62%] [G loss: 0.299969]\n",
      "epoch:31 step:29712 [D loss: 0.246584, acc.: 57.03%] [G loss: 0.300318]\n",
      "epoch:31 step:29713 [D loss: 0.249470, acc.: 54.69%] [G loss: 0.308969]\n",
      "epoch:31 step:29714 [D loss: 0.242906, acc.: 55.47%] [G loss: 0.307492]\n",
      "epoch:31 step:29715 [D loss: 0.243878, acc.: 59.38%] [G loss: 0.269267]\n",
      "epoch:31 step:29716 [D loss: 0.236616, acc.: 60.94%] [G loss: 0.304585]\n",
      "epoch:31 step:29717 [D loss: 0.240241, acc.: 61.72%] [G loss: 0.295640]\n",
      "epoch:31 step:29718 [D loss: 0.234971, acc.: 55.47%] [G loss: 0.298162]\n",
      "epoch:31 step:29719 [D loss: 0.239561, acc.: 60.16%] [G loss: 0.319011]\n",
      "epoch:31 step:29720 [D loss: 0.249400, acc.: 50.78%] [G loss: 0.289412]\n",
      "epoch:31 step:29721 [D loss: 0.243338, acc.: 57.03%] [G loss: 0.278588]\n",
      "epoch:31 step:29722 [D loss: 0.235797, acc.: 62.50%] [G loss: 0.326946]\n",
      "epoch:31 step:29723 [D loss: 0.240088, acc.: 58.59%] [G loss: 0.327332]\n",
      "epoch:31 step:29724 [D loss: 0.234787, acc.: 64.06%] [G loss: 0.298182]\n",
      "epoch:31 step:29725 [D loss: 0.228633, acc.: 62.50%] [G loss: 0.297877]\n",
      "epoch:31 step:29726 [D loss: 0.253892, acc.: 50.78%] [G loss: 0.292389]\n",
      "epoch:31 step:29727 [D loss: 0.241735, acc.: 52.34%] [G loss: 0.298217]\n",
      "epoch:31 step:29728 [D loss: 0.242600, acc.: 60.94%] [G loss: 0.291483]\n",
      "epoch:31 step:29729 [D loss: 0.234645, acc.: 58.59%] [G loss: 0.314055]\n",
      "epoch:31 step:29730 [D loss: 0.256564, acc.: 54.69%] [G loss: 0.289578]\n",
      "epoch:31 step:29731 [D loss: 0.254419, acc.: 53.91%] [G loss: 0.303503]\n",
      "epoch:31 step:29732 [D loss: 0.230777, acc.: 61.72%] [G loss: 0.305494]\n",
      "epoch:31 step:29733 [D loss: 0.240145, acc.: 59.38%] [G loss: 0.284307]\n",
      "epoch:31 step:29734 [D loss: 0.249192, acc.: 56.25%] [G loss: 0.320308]\n",
      "epoch:31 step:29735 [D loss: 0.233390, acc.: 57.81%] [G loss: 0.321967]\n",
      "epoch:31 step:29736 [D loss: 0.249778, acc.: 58.59%] [G loss: 0.306616]\n",
      "epoch:31 step:29737 [D loss: 0.227017, acc.: 62.50%] [G loss: 0.284583]\n",
      "epoch:31 step:29738 [D loss: 0.251363, acc.: 55.47%] [G loss: 0.314404]\n",
      "epoch:31 step:29739 [D loss: 0.238295, acc.: 60.94%] [G loss: 0.269816]\n",
      "epoch:31 step:29740 [D loss: 0.256479, acc.: 47.66%] [G loss: 0.305756]\n",
      "epoch:31 step:29741 [D loss: 0.233223, acc.: 62.50%] [G loss: 0.296380]\n",
      "epoch:31 step:29742 [D loss: 0.242068, acc.: 54.69%] [G loss: 0.317009]\n",
      "epoch:31 step:29743 [D loss: 0.247943, acc.: 52.34%] [G loss: 0.263049]\n",
      "epoch:31 step:29744 [D loss: 0.228800, acc.: 60.94%] [G loss: 0.332335]\n",
      "epoch:31 step:29745 [D loss: 0.235424, acc.: 60.16%] [G loss: 0.291645]\n",
      "epoch:31 step:29746 [D loss: 0.249885, acc.: 53.91%] [G loss: 0.315655]\n",
      "epoch:31 step:29747 [D loss: 0.248961, acc.: 52.34%] [G loss: 0.314742]\n",
      "epoch:31 step:29748 [D loss: 0.220723, acc.: 65.62%] [G loss: 0.299105]\n",
      "epoch:31 step:29749 [D loss: 0.210544, acc.: 67.19%] [G loss: 0.310249]\n",
      "epoch:31 step:29750 [D loss: 0.251341, acc.: 54.69%] [G loss: 0.315115]\n",
      "epoch:31 step:29751 [D loss: 0.270813, acc.: 46.09%] [G loss: 0.312884]\n",
      "epoch:31 step:29752 [D loss: 0.236834, acc.: 61.72%] [G loss: 0.300402]\n",
      "epoch:31 step:29753 [D loss: 0.261396, acc.: 50.00%] [G loss: 0.282167]\n",
      "epoch:31 step:29754 [D loss: 0.226348, acc.: 64.84%] [G loss: 0.305252]\n",
      "epoch:31 step:29755 [D loss: 0.251223, acc.: 55.47%] [G loss: 0.296680]\n",
      "epoch:31 step:29756 [D loss: 0.272975, acc.: 46.88%] [G loss: 0.284597]\n",
      "epoch:31 step:29757 [D loss: 0.224871, acc.: 63.28%] [G loss: 0.336818]\n",
      "epoch:31 step:29758 [D loss: 0.246137, acc.: 55.47%] [G loss: 0.289917]\n",
      "epoch:31 step:29759 [D loss: 0.255327, acc.: 50.78%] [G loss: 0.288455]\n",
      "epoch:31 step:29760 [D loss: 0.233970, acc.: 60.94%] [G loss: 0.364643]\n",
      "epoch:31 step:29761 [D loss: 0.231145, acc.: 61.72%] [G loss: 0.324806]\n",
      "epoch:31 step:29762 [D loss: 0.237326, acc.: 60.94%] [G loss: 0.306222]\n",
      "epoch:31 step:29763 [D loss: 0.224494, acc.: 64.84%] [G loss: 0.288742]\n",
      "epoch:31 step:29764 [D loss: 0.234820, acc.: 60.16%] [G loss: 0.293106]\n",
      "epoch:31 step:29765 [D loss: 0.223498, acc.: 55.47%] [G loss: 0.287476]\n",
      "epoch:31 step:29766 [D loss: 0.250502, acc.: 51.56%] [G loss: 0.303227]\n",
      "epoch:31 step:29767 [D loss: 0.239295, acc.: 57.81%] [G loss: 0.294744]\n",
      "epoch:31 step:29768 [D loss: 0.233996, acc.: 61.72%] [G loss: 0.322783]\n",
      "epoch:31 step:29769 [D loss: 0.252682, acc.: 52.34%] [G loss: 0.297052]\n",
      "epoch:31 step:29770 [D loss: 0.236119, acc.: 58.59%] [G loss: 0.319009]\n",
      "epoch:31 step:29771 [D loss: 0.225968, acc.: 61.72%] [G loss: 0.321676]\n",
      "epoch:31 step:29772 [D loss: 0.237531, acc.: 57.81%] [G loss: 0.285060]\n",
      "epoch:31 step:29773 [D loss: 0.233606, acc.: 57.81%] [G loss: 0.326382]\n",
      "epoch:31 step:29774 [D loss: 0.244798, acc.: 52.34%] [G loss: 0.304934]\n",
      "epoch:31 step:29775 [D loss: 0.231309, acc.: 61.72%] [G loss: 0.321356]\n",
      "epoch:31 step:29776 [D loss: 0.235152, acc.: 59.38%] [G loss: 0.283916]\n",
      "epoch:31 step:29777 [D loss: 0.233621, acc.: 60.16%] [G loss: 0.293252]\n",
      "epoch:31 step:29778 [D loss: 0.239399, acc.: 57.81%] [G loss: 0.306343]\n",
      "epoch:31 step:29779 [D loss: 0.234934, acc.: 61.72%] [G loss: 0.311462]\n",
      "epoch:31 step:29780 [D loss: 0.229890, acc.: 62.50%] [G loss: 0.321319]\n",
      "epoch:31 step:29781 [D loss: 0.219005, acc.: 70.31%] [G loss: 0.325433]\n",
      "epoch:31 step:29782 [D loss: 0.235060, acc.: 59.38%] [G loss: 0.333802]\n",
      "epoch:31 step:29783 [D loss: 0.228978, acc.: 60.94%] [G loss: 0.301119]\n",
      "epoch:31 step:29784 [D loss: 0.238612, acc.: 64.06%] [G loss: 0.305871]\n",
      "epoch:31 step:29785 [D loss: 0.231779, acc.: 61.72%] [G loss: 0.318606]\n",
      "epoch:31 step:29786 [D loss: 0.263435, acc.: 46.09%] [G loss: 0.297035]\n",
      "epoch:31 step:29787 [D loss: 0.240378, acc.: 58.59%] [G loss: 0.272742]\n",
      "epoch:31 step:29788 [D loss: 0.240480, acc.: 58.59%] [G loss: 0.292183]\n",
      "epoch:31 step:29789 [D loss: 0.240787, acc.: 53.91%] [G loss: 0.306279]\n",
      "epoch:31 step:29790 [D loss: 0.265069, acc.: 52.34%] [G loss: 0.293004]\n",
      "epoch:31 step:29791 [D loss: 0.227496, acc.: 64.06%] [G loss: 0.306700]\n",
      "epoch:31 step:29792 [D loss: 0.242701, acc.: 53.12%] [G loss: 0.276131]\n",
      "epoch:31 step:29793 [D loss: 0.253631, acc.: 50.78%] [G loss: 0.295302]\n",
      "epoch:31 step:29794 [D loss: 0.241768, acc.: 57.03%] [G loss: 0.318386]\n",
      "epoch:31 step:29795 [D loss: 0.218814, acc.: 63.28%] [G loss: 0.348682]\n",
      "epoch:31 step:29796 [D loss: 0.226109, acc.: 63.28%] [G loss: 0.294526]\n",
      "epoch:31 step:29797 [D loss: 0.217195, acc.: 66.41%] [G loss: 0.309621]\n",
      "epoch:31 step:29798 [D loss: 0.243532, acc.: 59.38%] [G loss: 0.301735]\n",
      "epoch:31 step:29799 [D loss: 0.257467, acc.: 50.00%] [G loss: 0.318383]\n",
      "epoch:31 step:29800 [D loss: 0.240858, acc.: 56.25%] [G loss: 0.327588]\n",
      "epoch:31 step:29801 [D loss: 0.245404, acc.: 53.91%] [G loss: 0.312035]\n",
      "epoch:31 step:29802 [D loss: 0.240720, acc.: 57.03%] [G loss: 0.323572]\n",
      "epoch:31 step:29803 [D loss: 0.245733, acc.: 56.25%] [G loss: 0.318940]\n",
      "epoch:31 step:29804 [D loss: 0.239784, acc.: 56.25%] [G loss: 0.276263]\n",
      "epoch:31 step:29805 [D loss: 0.254773, acc.: 48.44%] [G loss: 0.295199]\n",
      "epoch:31 step:29806 [D loss: 0.238768, acc.: 58.59%] [G loss: 0.265620]\n",
      "epoch:31 step:29807 [D loss: 0.238815, acc.: 59.38%] [G loss: 0.305839]\n",
      "epoch:31 step:29808 [D loss: 0.240610, acc.: 56.25%] [G loss: 0.288762]\n",
      "epoch:31 step:29809 [D loss: 0.246136, acc.: 54.69%] [G loss: 0.292830]\n",
      "epoch:31 step:29810 [D loss: 0.228524, acc.: 66.41%] [G loss: 0.311318]\n",
      "epoch:31 step:29811 [D loss: 0.234687, acc.: 61.72%] [G loss: 0.288706]\n",
      "epoch:31 step:29812 [D loss: 0.255782, acc.: 54.69%] [G loss: 0.281628]\n",
      "epoch:31 step:29813 [D loss: 0.228977, acc.: 56.25%] [G loss: 0.339060]\n",
      "epoch:31 step:29814 [D loss: 0.212101, acc.: 70.31%] [G loss: 0.326439]\n",
      "epoch:31 step:29815 [D loss: 0.233123, acc.: 60.16%] [G loss: 0.317614]\n",
      "epoch:31 step:29816 [D loss: 0.247321, acc.: 57.03%] [G loss: 0.281604]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:31 step:29817 [D loss: 0.250505, acc.: 53.12%] [G loss: 0.311424]\n",
      "epoch:31 step:29818 [D loss: 0.234639, acc.: 57.03%] [G loss: 0.299283]\n",
      "epoch:31 step:29819 [D loss: 0.233584, acc.: 60.94%] [G loss: 0.314703]\n",
      "epoch:31 step:29820 [D loss: 0.258245, acc.: 46.09%] [G loss: 0.306458]\n",
      "epoch:31 step:29821 [D loss: 0.233413, acc.: 59.38%] [G loss: 0.273789]\n",
      "epoch:31 step:29822 [D loss: 0.248605, acc.: 54.69%] [G loss: 0.328694]\n",
      "epoch:31 step:29823 [D loss: 0.239971, acc.: 60.16%] [G loss: 0.301350]\n",
      "epoch:31 step:29824 [D loss: 0.246974, acc.: 58.59%] [G loss: 0.283484]\n",
      "epoch:31 step:29825 [D loss: 0.231197, acc.: 63.28%] [G loss: 0.308025]\n",
      "epoch:31 step:29826 [D loss: 0.243440, acc.: 55.47%] [G loss: 0.302108]\n",
      "epoch:31 step:29827 [D loss: 0.270271, acc.: 48.44%] [G loss: 0.289896]\n",
      "epoch:31 step:29828 [D loss: 0.243021, acc.: 55.47%] [G loss: 0.305875]\n",
      "epoch:31 step:29829 [D loss: 0.235770, acc.: 67.19%] [G loss: 0.320236]\n",
      "epoch:31 step:29830 [D loss: 0.225105, acc.: 62.50%] [G loss: 0.293657]\n",
      "epoch:31 step:29831 [D loss: 0.228536, acc.: 62.50%] [G loss: 0.324712]\n",
      "epoch:31 step:29832 [D loss: 0.249378, acc.: 46.88%] [G loss: 0.300007]\n",
      "epoch:31 step:29833 [D loss: 0.240335, acc.: 55.47%] [G loss: 0.302374]\n",
      "epoch:31 step:29834 [D loss: 0.232591, acc.: 60.94%] [G loss: 0.314715]\n",
      "epoch:31 step:29835 [D loss: 0.250387, acc.: 54.69%] [G loss: 0.277114]\n",
      "epoch:31 step:29836 [D loss: 0.257088, acc.: 54.69%] [G loss: 0.304888]\n",
      "epoch:31 step:29837 [D loss: 0.234471, acc.: 58.59%] [G loss: 0.273955]\n",
      "epoch:31 step:29838 [D loss: 0.248141, acc.: 54.69%] [G loss: 0.303679]\n",
      "epoch:31 step:29839 [D loss: 0.239674, acc.: 57.03%] [G loss: 0.306959]\n",
      "epoch:31 step:29840 [D loss: 0.238646, acc.: 60.16%] [G loss: 0.320512]\n",
      "epoch:31 step:29841 [D loss: 0.243055, acc.: 56.25%] [G loss: 0.314508]\n",
      "epoch:31 step:29842 [D loss: 0.245334, acc.: 57.03%] [G loss: 0.301658]\n",
      "epoch:31 step:29843 [D loss: 0.247273, acc.: 56.25%] [G loss: 0.269697]\n",
      "epoch:31 step:29844 [D loss: 0.248454, acc.: 51.56%] [G loss: 0.327963]\n",
      "epoch:31 step:29845 [D loss: 0.225878, acc.: 65.62%] [G loss: 0.306868]\n",
      "epoch:31 step:29846 [D loss: 0.242114, acc.: 59.38%] [G loss: 0.289945]\n",
      "epoch:31 step:29847 [D loss: 0.237017, acc.: 56.25%] [G loss: 0.316209]\n",
      "epoch:31 step:29848 [D loss: 0.239824, acc.: 53.12%] [G loss: 0.285212]\n",
      "epoch:31 step:29849 [D loss: 0.239418, acc.: 60.94%] [G loss: 0.320953]\n",
      "epoch:31 step:29850 [D loss: 0.225223, acc.: 61.72%] [G loss: 0.305733]\n",
      "epoch:31 step:29851 [D loss: 0.234992, acc.: 60.94%] [G loss: 0.287581]\n",
      "epoch:31 step:29852 [D loss: 0.240497, acc.: 52.34%] [G loss: 0.312625]\n",
      "epoch:31 step:29853 [D loss: 0.249655, acc.: 54.69%] [G loss: 0.301242]\n",
      "epoch:31 step:29854 [D loss: 0.243953, acc.: 56.25%] [G loss: 0.283552]\n",
      "epoch:31 step:29855 [D loss: 0.243274, acc.: 57.81%] [G loss: 0.291798]\n",
      "epoch:31 step:29856 [D loss: 0.211892, acc.: 67.97%] [G loss: 0.319979]\n",
      "epoch:31 step:29857 [D loss: 0.239000, acc.: 57.81%] [G loss: 0.296646]\n",
      "epoch:31 step:29858 [D loss: 0.240794, acc.: 57.81%] [G loss: 0.303820]\n",
      "epoch:31 step:29859 [D loss: 0.237754, acc.: 60.94%] [G loss: 0.309421]\n",
      "epoch:31 step:29860 [D loss: 0.223625, acc.: 63.28%] [G loss: 0.307001]\n",
      "epoch:31 step:29861 [D loss: 0.242609, acc.: 56.25%] [G loss: 0.306997]\n",
      "epoch:31 step:29862 [D loss: 0.236353, acc.: 61.72%] [G loss: 0.317766]\n",
      "epoch:31 step:29863 [D loss: 0.223084, acc.: 65.62%] [G loss: 0.287632]\n",
      "epoch:31 step:29864 [D loss: 0.236695, acc.: 63.28%] [G loss: 0.278587]\n",
      "epoch:31 step:29865 [D loss: 0.227450, acc.: 63.28%] [G loss: 0.301901]\n",
      "epoch:31 step:29866 [D loss: 0.239454, acc.: 58.59%] [G loss: 0.303749]\n",
      "epoch:31 step:29867 [D loss: 0.220565, acc.: 66.41%] [G loss: 0.282499]\n",
      "epoch:31 step:29868 [D loss: 0.256952, acc.: 52.34%] [G loss: 0.318302]\n",
      "epoch:31 step:29869 [D loss: 0.241525, acc.: 59.38%] [G loss: 0.302527]\n",
      "epoch:31 step:29870 [D loss: 0.226514, acc.: 57.81%] [G loss: 0.291785]\n",
      "epoch:31 step:29871 [D loss: 0.238823, acc.: 57.81%] [G loss: 0.296979]\n",
      "epoch:31 step:29872 [D loss: 0.246368, acc.: 57.81%] [G loss: 0.290769]\n",
      "epoch:31 step:29873 [D loss: 0.241904, acc.: 58.59%] [G loss: 0.276020]\n",
      "epoch:31 step:29874 [D loss: 0.224866, acc.: 63.28%] [G loss: 0.331847]\n",
      "epoch:31 step:29875 [D loss: 0.223437, acc.: 64.06%] [G loss: 0.311067]\n",
      "epoch:31 step:29876 [D loss: 0.243070, acc.: 57.81%] [G loss: 0.294906]\n",
      "epoch:31 step:29877 [D loss: 0.240247, acc.: 61.72%] [G loss: 0.276513]\n",
      "epoch:31 step:29878 [D loss: 0.240591, acc.: 56.25%] [G loss: 0.284158]\n",
      "epoch:31 step:29879 [D loss: 0.245090, acc.: 52.34%] [G loss: 0.296139]\n",
      "epoch:31 step:29880 [D loss: 0.246471, acc.: 54.69%] [G loss: 0.299573]\n",
      "epoch:31 step:29881 [D loss: 0.244100, acc.: 57.03%] [G loss: 0.269419]\n",
      "epoch:31 step:29882 [D loss: 0.233555, acc.: 64.06%] [G loss: 0.286642]\n",
      "epoch:31 step:29883 [D loss: 0.245963, acc.: 57.03%] [G loss: 0.289016]\n",
      "epoch:31 step:29884 [D loss: 0.251127, acc.: 57.81%] [G loss: 0.300613]\n",
      "epoch:31 step:29885 [D loss: 0.246386, acc.: 57.81%] [G loss: 0.273300]\n",
      "epoch:31 step:29886 [D loss: 0.242927, acc.: 57.03%] [G loss: 0.300777]\n",
      "epoch:31 step:29887 [D loss: 0.231988, acc.: 60.16%] [G loss: 0.295477]\n",
      "epoch:31 step:29888 [D loss: 0.229461, acc.: 64.06%] [G loss: 0.272912]\n",
      "epoch:31 step:29889 [D loss: 0.244905, acc.: 57.81%] [G loss: 0.291591]\n",
      "epoch:31 step:29890 [D loss: 0.247160, acc.: 53.91%] [G loss: 0.301045]\n",
      "epoch:31 step:29891 [D loss: 0.255981, acc.: 50.00%] [G loss: 0.285976]\n",
      "epoch:31 step:29892 [D loss: 0.237850, acc.: 61.72%] [G loss: 0.287677]\n",
      "epoch:31 step:29893 [D loss: 0.243963, acc.: 58.59%] [G loss: 0.305166]\n",
      "epoch:31 step:29894 [D loss: 0.229787, acc.: 64.84%] [G loss: 0.296155]\n",
      "epoch:31 step:29895 [D loss: 0.228915, acc.: 62.50%] [G loss: 0.271326]\n",
      "epoch:31 step:29896 [D loss: 0.241061, acc.: 59.38%] [G loss: 0.295169]\n",
      "epoch:31 step:29897 [D loss: 0.247369, acc.: 51.56%] [G loss: 0.309941]\n",
      "epoch:31 step:29898 [D loss: 0.267482, acc.: 46.88%] [G loss: 0.313764]\n",
      "epoch:31 step:29899 [D loss: 0.240298, acc.: 57.03%] [G loss: 0.286325]\n",
      "epoch:31 step:29900 [D loss: 0.239591, acc.: 53.12%] [G loss: 0.294484]\n",
      "epoch:31 step:29901 [D loss: 0.245253, acc.: 53.12%] [G loss: 0.297813]\n",
      "epoch:31 step:29902 [D loss: 0.252849, acc.: 54.69%] [G loss: 0.268863]\n",
      "epoch:31 step:29903 [D loss: 0.218804, acc.: 64.84%] [G loss: 0.259166]\n",
      "epoch:31 step:29904 [D loss: 0.244132, acc.: 58.59%] [G loss: 0.309616]\n",
      "epoch:31 step:29905 [D loss: 0.244991, acc.: 59.38%] [G loss: 0.322878]\n",
      "epoch:31 step:29906 [D loss: 0.226012, acc.: 60.16%] [G loss: 0.317670]\n",
      "epoch:31 step:29907 [D loss: 0.234765, acc.: 59.38%] [G loss: 0.294763]\n",
      "epoch:31 step:29908 [D loss: 0.218386, acc.: 60.94%] [G loss: 0.320166]\n",
      "epoch:31 step:29909 [D loss: 0.231801, acc.: 62.50%] [G loss: 0.316212]\n",
      "epoch:31 step:29910 [D loss: 0.242145, acc.: 60.94%] [G loss: 0.277268]\n",
      "epoch:31 step:29911 [D loss: 0.218237, acc.: 60.94%] [G loss: 0.290620]\n",
      "epoch:31 step:29912 [D loss: 0.235041, acc.: 61.72%] [G loss: 0.286163]\n",
      "epoch:31 step:29913 [D loss: 0.237594, acc.: 59.38%] [G loss: 0.295650]\n",
      "epoch:31 step:29914 [D loss: 0.236085, acc.: 59.38%] [G loss: 0.316776]\n",
      "epoch:31 step:29915 [D loss: 0.221548, acc.: 66.41%] [G loss: 0.309908]\n",
      "epoch:31 step:29916 [D loss: 0.238814, acc.: 60.94%] [G loss: 0.295717]\n",
      "epoch:31 step:29917 [D loss: 0.242802, acc.: 58.59%] [G loss: 0.308368]\n",
      "epoch:31 step:29918 [D loss: 0.235476, acc.: 55.47%] [G loss: 0.310314]\n",
      "epoch:31 step:29919 [D loss: 0.235690, acc.: 56.25%] [G loss: 0.315575]\n",
      "epoch:31 step:29920 [D loss: 0.230317, acc.: 62.50%] [G loss: 0.303084]\n",
      "epoch:31 step:29921 [D loss: 0.248110, acc.: 62.50%] [G loss: 0.299073]\n",
      "epoch:31 step:29922 [D loss: 0.241156, acc.: 55.47%] [G loss: 0.324441]\n",
      "epoch:31 step:29923 [D loss: 0.230600, acc.: 57.03%] [G loss: 0.299391]\n",
      "epoch:31 step:29924 [D loss: 0.228129, acc.: 60.16%] [G loss: 0.311483]\n",
      "epoch:31 step:29925 [D loss: 0.247853, acc.: 57.03%] [G loss: 0.333027]\n",
      "epoch:31 step:29926 [D loss: 0.242753, acc.: 59.38%] [G loss: 0.322711]\n",
      "epoch:31 step:29927 [D loss: 0.245038, acc.: 55.47%] [G loss: 0.281938]\n",
      "epoch:31 step:29928 [D loss: 0.242402, acc.: 57.03%] [G loss: 0.304115]\n",
      "epoch:31 step:29929 [D loss: 0.228516, acc.: 64.84%] [G loss: 0.312758]\n",
      "epoch:31 step:29930 [D loss: 0.249817, acc.: 52.34%] [G loss: 0.327399]\n",
      "epoch:31 step:29931 [D loss: 0.234295, acc.: 58.59%] [G loss: 0.319461]\n",
      "epoch:31 step:29932 [D loss: 0.224028, acc.: 63.28%] [G loss: 0.296690]\n",
      "epoch:31 step:29933 [D loss: 0.243207, acc.: 59.38%] [G loss: 0.306388]\n",
      "epoch:31 step:29934 [D loss: 0.229174, acc.: 61.72%] [G loss: 0.281377]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:31 step:29935 [D loss: 0.236242, acc.: 57.81%] [G loss: 0.309075]\n",
      "epoch:31 step:29936 [D loss: 0.239621, acc.: 57.03%] [G loss: 0.312774]\n",
      "epoch:31 step:29937 [D loss: 0.233041, acc.: 57.03%] [G loss: 0.310884]\n",
      "epoch:31 step:29938 [D loss: 0.237343, acc.: 58.59%] [G loss: 0.346601]\n",
      "epoch:31 step:29939 [D loss: 0.246639, acc.: 57.81%] [G loss: 0.306934]\n",
      "epoch:31 step:29940 [D loss: 0.224233, acc.: 67.19%] [G loss: 0.323129]\n",
      "epoch:31 step:29941 [D loss: 0.247274, acc.: 60.16%] [G loss: 0.264889]\n",
      "epoch:31 step:29942 [D loss: 0.240247, acc.: 57.81%] [G loss: 0.329538]\n",
      "epoch:31 step:29943 [D loss: 0.222333, acc.: 65.62%] [G loss: 0.291434]\n",
      "epoch:31 step:29944 [D loss: 0.228989, acc.: 57.81%] [G loss: 0.346989]\n",
      "epoch:31 step:29945 [D loss: 0.249514, acc.: 50.00%] [G loss: 0.298507]\n",
      "epoch:31 step:29946 [D loss: 0.218994, acc.: 66.41%] [G loss: 0.311357]\n",
      "epoch:31 step:29947 [D loss: 0.228659, acc.: 65.62%] [G loss: 0.300900]\n",
      "epoch:31 step:29948 [D loss: 0.230940, acc.: 60.16%] [G loss: 0.283500]\n",
      "epoch:31 step:29949 [D loss: 0.250523, acc.: 49.22%] [G loss: 0.282065]\n",
      "epoch:31 step:29950 [D loss: 0.246697, acc.: 51.56%] [G loss: 0.288141]\n",
      "epoch:31 step:29951 [D loss: 0.226098, acc.: 62.50%] [G loss: 0.304331]\n",
      "epoch:31 step:29952 [D loss: 0.242527, acc.: 57.81%] [G loss: 0.290887]\n",
      "epoch:31 step:29953 [D loss: 0.232966, acc.: 60.94%] [G loss: 0.294334]\n",
      "epoch:31 step:29954 [D loss: 0.238205, acc.: 57.81%] [G loss: 0.292365]\n",
      "epoch:31 step:29955 [D loss: 0.244305, acc.: 58.59%] [G loss: 0.300710]\n",
      "epoch:31 step:29956 [D loss: 0.239027, acc.: 57.81%] [G loss: 0.314092]\n",
      "epoch:31 step:29957 [D loss: 0.263506, acc.: 50.00%] [G loss: 0.280220]\n",
      "epoch:31 step:29958 [D loss: 0.237122, acc.: 60.94%] [G loss: 0.301960]\n",
      "epoch:31 step:29959 [D loss: 0.265223, acc.: 54.69%] [G loss: 0.305093]\n",
      "epoch:31 step:29960 [D loss: 0.252944, acc.: 53.91%] [G loss: 0.315618]\n",
      "epoch:31 step:29961 [D loss: 0.237634, acc.: 57.81%] [G loss: 0.304507]\n",
      "epoch:31 step:29962 [D loss: 0.250532, acc.: 46.09%] [G loss: 0.312241]\n",
      "epoch:31 step:29963 [D loss: 0.236851, acc.: 57.03%] [G loss: 0.296585]\n",
      "epoch:31 step:29964 [D loss: 0.240020, acc.: 58.59%] [G loss: 0.306419]\n",
      "epoch:31 step:29965 [D loss: 0.236144, acc.: 58.59%] [G loss: 0.300907]\n",
      "epoch:31 step:29966 [D loss: 0.245699, acc.: 57.81%] [G loss: 0.298321]\n",
      "epoch:31 step:29967 [D loss: 0.238815, acc.: 58.59%] [G loss: 0.310612]\n",
      "epoch:31 step:29968 [D loss: 0.251654, acc.: 53.91%] [G loss: 0.293354]\n",
      "epoch:31 step:29969 [D loss: 0.230369, acc.: 56.25%] [G loss: 0.320985]\n",
      "epoch:31 step:29970 [D loss: 0.237109, acc.: 59.38%] [G loss: 0.306858]\n",
      "epoch:31 step:29971 [D loss: 0.220072, acc.: 66.41%] [G loss: 0.303398]\n",
      "epoch:31 step:29972 [D loss: 0.238043, acc.: 62.50%] [G loss: 0.313000]\n",
      "epoch:31 step:29973 [D loss: 0.233305, acc.: 60.16%] [G loss: 0.288878]\n",
      "epoch:31 step:29974 [D loss: 0.268582, acc.: 50.00%] [G loss: 0.298048]\n",
      "epoch:31 step:29975 [D loss: 0.230107, acc.: 56.25%] [G loss: 0.334342]\n",
      "epoch:31 step:29976 [D loss: 0.232643, acc.: 60.16%] [G loss: 0.284636]\n",
      "epoch:31 step:29977 [D loss: 0.232973, acc.: 59.38%] [G loss: 0.299265]\n",
      "epoch:31 step:29978 [D loss: 0.230120, acc.: 60.94%] [G loss: 0.307520]\n",
      "epoch:31 step:29979 [D loss: 0.243151, acc.: 60.16%] [G loss: 0.315426]\n",
      "epoch:31 step:29980 [D loss: 0.236972, acc.: 67.19%] [G loss: 0.295908]\n",
      "epoch:31 step:29981 [D loss: 0.241669, acc.: 57.81%] [G loss: 0.306906]\n",
      "epoch:31 step:29982 [D loss: 0.244853, acc.: 58.59%] [G loss: 0.292897]\n",
      "epoch:31 step:29983 [D loss: 0.233898, acc.: 63.28%] [G loss: 0.299139]\n",
      "epoch:31 step:29984 [D loss: 0.254432, acc.: 51.56%] [G loss: 0.279535]\n",
      "epoch:32 step:29985 [D loss: 0.233795, acc.: 59.38%] [G loss: 0.309749]\n",
      "epoch:32 step:29986 [D loss: 0.240617, acc.: 54.69%] [G loss: 0.291840]\n",
      "epoch:32 step:29987 [D loss: 0.248436, acc.: 51.56%] [G loss: 0.302986]\n",
      "epoch:32 step:29988 [D loss: 0.231614, acc.: 61.72%] [G loss: 0.293452]\n",
      "epoch:32 step:29989 [D loss: 0.245123, acc.: 59.38%] [G loss: 0.315224]\n",
      "epoch:32 step:29990 [D loss: 0.230331, acc.: 66.41%] [G loss: 0.290318]\n",
      "epoch:32 step:29991 [D loss: 0.238381, acc.: 60.16%] [G loss: 0.270862]\n",
      "epoch:32 step:29992 [D loss: 0.231402, acc.: 61.72%] [G loss: 0.299914]\n",
      "epoch:32 step:29993 [D loss: 0.221872, acc.: 64.06%] [G loss: 0.316815]\n",
      "epoch:32 step:29994 [D loss: 0.242895, acc.: 53.91%] [G loss: 0.316353]\n",
      "epoch:32 step:29995 [D loss: 0.214674, acc.: 65.62%] [G loss: 0.300731]\n",
      "epoch:32 step:29996 [D loss: 0.248559, acc.: 56.25%] [G loss: 0.278933]\n",
      "epoch:32 step:29997 [D loss: 0.238560, acc.: 57.03%] [G loss: 0.317719]\n",
      "epoch:32 step:29998 [D loss: 0.251230, acc.: 57.03%] [G loss: 0.284433]\n",
      "epoch:32 step:29999 [D loss: 0.232591, acc.: 67.97%] [G loss: 0.297906]\n",
      "epoch:32 step:30000 [D loss: 0.234953, acc.: 64.84%] [G loss: 0.329547]\n",
      "epoch:32 step:30001 [D loss: 0.240646, acc.: 56.25%] [G loss: 0.323427]\n",
      "epoch:32 step:30002 [D loss: 0.241533, acc.: 60.94%] [G loss: 0.307501]\n",
      "epoch:32 step:30003 [D loss: 0.243837, acc.: 56.25%] [G loss: 0.294369]\n",
      "epoch:32 step:30004 [D loss: 0.227255, acc.: 63.28%] [G loss: 0.316252]\n",
      "epoch:32 step:30005 [D loss: 0.249756, acc.: 53.91%] [G loss: 0.285489]\n",
      "epoch:32 step:30006 [D loss: 0.232724, acc.: 62.50%] [G loss: 0.309287]\n",
      "epoch:32 step:30007 [D loss: 0.241130, acc.: 62.50%] [G loss: 0.298094]\n",
      "epoch:32 step:30008 [D loss: 0.236678, acc.: 62.50%] [G loss: 0.297194]\n",
      "epoch:32 step:30009 [D loss: 0.247271, acc.: 57.81%] [G loss: 0.286638]\n",
      "epoch:32 step:30010 [D loss: 0.234399, acc.: 64.84%] [G loss: 0.324164]\n",
      "epoch:32 step:30011 [D loss: 0.238593, acc.: 55.47%] [G loss: 0.284369]\n",
      "epoch:32 step:30012 [D loss: 0.244690, acc.: 54.69%] [G loss: 0.314157]\n",
      "epoch:32 step:30013 [D loss: 0.238796, acc.: 57.81%] [G loss: 0.295945]\n",
      "epoch:32 step:30014 [D loss: 0.249948, acc.: 52.34%] [G loss: 0.312457]\n",
      "epoch:32 step:30015 [D loss: 0.229380, acc.: 57.03%] [G loss: 0.314615]\n",
      "epoch:32 step:30016 [D loss: 0.215580, acc.: 64.84%] [G loss: 0.319311]\n",
      "epoch:32 step:30017 [D loss: 0.252120, acc.: 47.66%] [G loss: 0.290547]\n",
      "epoch:32 step:30018 [D loss: 0.225710, acc.: 60.16%] [G loss: 0.299875]\n",
      "epoch:32 step:30019 [D loss: 0.236623, acc.: 56.25%] [G loss: 0.274620]\n",
      "epoch:32 step:30020 [D loss: 0.221473, acc.: 64.06%] [G loss: 0.319329]\n",
      "epoch:32 step:30021 [D loss: 0.239389, acc.: 57.81%] [G loss: 0.306501]\n",
      "epoch:32 step:30022 [D loss: 0.242744, acc.: 57.81%] [G loss: 0.297734]\n",
      "epoch:32 step:30023 [D loss: 0.246528, acc.: 57.03%] [G loss: 0.297103]\n",
      "epoch:32 step:30024 [D loss: 0.247728, acc.: 47.66%] [G loss: 0.284670]\n",
      "epoch:32 step:30025 [D loss: 0.223976, acc.: 60.16%] [G loss: 0.335696]\n",
      "epoch:32 step:30026 [D loss: 0.237285, acc.: 59.38%] [G loss: 0.275543]\n",
      "epoch:32 step:30027 [D loss: 0.237125, acc.: 64.06%] [G loss: 0.310880]\n",
      "epoch:32 step:30028 [D loss: 0.248107, acc.: 60.16%] [G loss: 0.290949]\n",
      "epoch:32 step:30029 [D loss: 0.236419, acc.: 60.94%] [G loss: 0.271047]\n",
      "epoch:32 step:30030 [D loss: 0.232696, acc.: 60.94%] [G loss: 0.294424]\n",
      "epoch:32 step:30031 [D loss: 0.234591, acc.: 60.94%] [G loss: 0.293997]\n",
      "epoch:32 step:30032 [D loss: 0.220610, acc.: 60.94%] [G loss: 0.315755]\n",
      "epoch:32 step:30033 [D loss: 0.240220, acc.: 59.38%] [G loss: 0.287866]\n",
      "epoch:32 step:30034 [D loss: 0.226197, acc.: 60.94%] [G loss: 0.315380]\n",
      "epoch:32 step:30035 [D loss: 0.229100, acc.: 66.41%] [G loss: 0.267919]\n",
      "epoch:32 step:30036 [D loss: 0.240106, acc.: 56.25%] [G loss: 0.286242]\n",
      "epoch:32 step:30037 [D loss: 0.237020, acc.: 58.59%] [G loss: 0.281798]\n",
      "epoch:32 step:30038 [D loss: 0.213610, acc.: 67.97%] [G loss: 0.291250]\n",
      "epoch:32 step:30039 [D loss: 0.239636, acc.: 53.91%] [G loss: 0.297770]\n",
      "epoch:32 step:30040 [D loss: 0.254830, acc.: 54.69%] [G loss: 0.300481]\n",
      "epoch:32 step:30041 [D loss: 0.234172, acc.: 62.50%] [G loss: 0.308138]\n",
      "epoch:32 step:30042 [D loss: 0.255603, acc.: 52.34%] [G loss: 0.288270]\n",
      "epoch:32 step:30043 [D loss: 0.229512, acc.: 64.06%] [G loss: 0.303162]\n",
      "epoch:32 step:30044 [D loss: 0.234975, acc.: 60.94%] [G loss: 0.306400]\n",
      "epoch:32 step:30045 [D loss: 0.248496, acc.: 56.25%] [G loss: 0.299033]\n",
      "epoch:32 step:30046 [D loss: 0.242891, acc.: 56.25%] [G loss: 0.303322]\n",
      "epoch:32 step:30047 [D loss: 0.244902, acc.: 57.81%] [G loss: 0.291538]\n",
      "epoch:32 step:30048 [D loss: 0.248192, acc.: 54.69%] [G loss: 0.300832]\n",
      "epoch:32 step:30049 [D loss: 0.233528, acc.: 57.81%] [G loss: 0.319884]\n",
      "epoch:32 step:30050 [D loss: 0.241419, acc.: 57.03%] [G loss: 0.296125]\n",
      "epoch:32 step:30051 [D loss: 0.236637, acc.: 58.59%] [G loss: 0.302110]\n",
      "epoch:32 step:30052 [D loss: 0.255601, acc.: 52.34%] [G loss: 0.264997]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:32 step:30053 [D loss: 0.221953, acc.: 67.19%] [G loss: 0.321103]\n",
      "epoch:32 step:30054 [D loss: 0.242810, acc.: 57.81%] [G loss: 0.314339]\n",
      "epoch:32 step:30055 [D loss: 0.245733, acc.: 57.81%] [G loss: 0.268673]\n",
      "epoch:32 step:30056 [D loss: 0.224419, acc.: 63.28%] [G loss: 0.295034]\n",
      "epoch:32 step:30057 [D loss: 0.250597, acc.: 53.91%] [G loss: 0.263488]\n",
      "epoch:32 step:30058 [D loss: 0.235713, acc.: 62.50%] [G loss: 0.313424]\n",
      "epoch:32 step:30059 [D loss: 0.254867, acc.: 49.22%] [G loss: 0.319715]\n",
      "epoch:32 step:30060 [D loss: 0.233145, acc.: 61.72%] [G loss: 0.298014]\n",
      "epoch:32 step:30061 [D loss: 0.236496, acc.: 61.72%] [G loss: 0.311565]\n",
      "epoch:32 step:30062 [D loss: 0.260601, acc.: 51.56%] [G loss: 0.279005]\n",
      "epoch:32 step:30063 [D loss: 0.250482, acc.: 56.25%] [G loss: 0.302385]\n",
      "epoch:32 step:30064 [D loss: 0.245516, acc.: 57.81%] [G loss: 0.312951]\n",
      "epoch:32 step:30065 [D loss: 0.221034, acc.: 65.62%] [G loss: 0.310107]\n",
      "epoch:32 step:30066 [D loss: 0.218126, acc.: 64.84%] [G loss: 0.316260]\n",
      "epoch:32 step:30067 [D loss: 0.252576, acc.: 52.34%] [G loss: 0.284674]\n",
      "epoch:32 step:30068 [D loss: 0.239395, acc.: 60.94%] [G loss: 0.308910]\n",
      "epoch:32 step:30069 [D loss: 0.230143, acc.: 57.03%] [G loss: 0.289351]\n",
      "epoch:32 step:30070 [D loss: 0.253298, acc.: 53.12%] [G loss: 0.293253]\n",
      "epoch:32 step:30071 [D loss: 0.238856, acc.: 55.47%] [G loss: 0.300048]\n",
      "epoch:32 step:30072 [D loss: 0.245002, acc.: 56.25%] [G loss: 0.301516]\n",
      "epoch:32 step:30073 [D loss: 0.254972, acc.: 49.22%] [G loss: 0.295295]\n",
      "epoch:32 step:30074 [D loss: 0.234599, acc.: 57.81%] [G loss: 0.300062]\n",
      "epoch:32 step:30075 [D loss: 0.251369, acc.: 53.12%] [G loss: 0.295603]\n",
      "epoch:32 step:30076 [D loss: 0.244234, acc.: 55.47%] [G loss: 0.279027]\n",
      "epoch:32 step:30077 [D loss: 0.228640, acc.: 61.72%] [G loss: 0.308991]\n",
      "epoch:32 step:30078 [D loss: 0.244728, acc.: 53.12%] [G loss: 0.280509]\n",
      "epoch:32 step:30079 [D loss: 0.238788, acc.: 62.50%] [G loss: 0.281918]\n",
      "epoch:32 step:30080 [D loss: 0.225105, acc.: 63.28%] [G loss: 0.346525]\n",
      "epoch:32 step:30081 [D loss: 0.250413, acc.: 55.47%] [G loss: 0.277151]\n",
      "epoch:32 step:30082 [D loss: 0.239696, acc.: 58.59%] [G loss: 0.286336]\n",
      "epoch:32 step:30083 [D loss: 0.233326, acc.: 64.84%] [G loss: 0.297284]\n",
      "epoch:32 step:30084 [D loss: 0.242916, acc.: 57.03%] [G loss: 0.288824]\n",
      "epoch:32 step:30085 [D loss: 0.231113, acc.: 59.38%] [G loss: 0.307822]\n",
      "epoch:32 step:30086 [D loss: 0.228349, acc.: 60.94%] [G loss: 0.305355]\n",
      "epoch:32 step:30087 [D loss: 0.232627, acc.: 61.72%] [G loss: 0.318660]\n",
      "epoch:32 step:30088 [D loss: 0.251287, acc.: 55.47%] [G loss: 0.298215]\n",
      "epoch:32 step:30089 [D loss: 0.238080, acc.: 60.94%] [G loss: 0.302415]\n",
      "epoch:32 step:30090 [D loss: 0.215847, acc.: 67.19%] [G loss: 0.322656]\n",
      "epoch:32 step:30091 [D loss: 0.259513, acc.: 55.47%] [G loss: 0.310709]\n",
      "epoch:32 step:30092 [D loss: 0.253641, acc.: 56.25%] [G loss: 0.299971]\n",
      "epoch:32 step:30093 [D loss: 0.223559, acc.: 63.28%] [G loss: 0.290123]\n",
      "epoch:32 step:30094 [D loss: 0.256136, acc.: 53.12%] [G loss: 0.276580]\n",
      "epoch:32 step:30095 [D loss: 0.242485, acc.: 58.59%] [G loss: 0.282051]\n",
      "epoch:32 step:30096 [D loss: 0.235572, acc.: 62.50%] [G loss: 0.315542]\n",
      "epoch:32 step:30097 [D loss: 0.225922, acc.: 60.94%] [G loss: 0.290615]\n",
      "epoch:32 step:30098 [D loss: 0.239966, acc.: 59.38%] [G loss: 0.297732]\n",
      "epoch:32 step:30099 [D loss: 0.236426, acc.: 56.25%] [G loss: 0.283334]\n",
      "epoch:32 step:30100 [D loss: 0.238651, acc.: 52.34%] [G loss: 0.270696]\n",
      "epoch:32 step:30101 [D loss: 0.248790, acc.: 56.25%] [G loss: 0.311700]\n",
      "epoch:32 step:30102 [D loss: 0.248867, acc.: 55.47%] [G loss: 0.294537]\n",
      "epoch:32 step:30103 [D loss: 0.236704, acc.: 64.84%] [G loss: 0.306867]\n",
      "epoch:32 step:30104 [D loss: 0.236084, acc.: 54.69%] [G loss: 0.297369]\n",
      "epoch:32 step:30105 [D loss: 0.220926, acc.: 64.84%] [G loss: 0.331466]\n",
      "epoch:32 step:30106 [D loss: 0.247951, acc.: 53.91%] [G loss: 0.287569]\n",
      "epoch:32 step:30107 [D loss: 0.244766, acc.: 53.12%] [G loss: 0.305362]\n",
      "epoch:32 step:30108 [D loss: 0.230059, acc.: 59.38%] [G loss: 0.321320]\n",
      "epoch:32 step:30109 [D loss: 0.251102, acc.: 48.44%] [G loss: 0.320760]\n",
      "epoch:32 step:30110 [D loss: 0.217379, acc.: 67.19%] [G loss: 0.321589]\n",
      "epoch:32 step:30111 [D loss: 0.236258, acc.: 60.16%] [G loss: 0.271833]\n",
      "epoch:32 step:30112 [D loss: 0.247985, acc.: 53.91%] [G loss: 0.295370]\n",
      "epoch:32 step:30113 [D loss: 0.237260, acc.: 60.16%] [G loss: 0.329662]\n",
      "epoch:32 step:30114 [D loss: 0.226506, acc.: 62.50%] [G loss: 0.316477]\n",
      "epoch:32 step:30115 [D loss: 0.240594, acc.: 54.69%] [G loss: 0.301510]\n",
      "epoch:32 step:30116 [D loss: 0.269324, acc.: 49.22%] [G loss: 0.294169]\n",
      "epoch:32 step:30117 [D loss: 0.239806, acc.: 53.91%] [G loss: 0.295822]\n",
      "epoch:32 step:30118 [D loss: 0.222632, acc.: 62.50%] [G loss: 0.295838]\n",
      "epoch:32 step:30119 [D loss: 0.245036, acc.: 60.94%] [G loss: 0.310143]\n",
      "epoch:32 step:30120 [D loss: 0.242135, acc.: 57.81%] [G loss: 0.259482]\n",
      "epoch:32 step:30121 [D loss: 0.246706, acc.: 55.47%] [G loss: 0.324826]\n",
      "epoch:32 step:30122 [D loss: 0.248274, acc.: 55.47%] [G loss: 0.299407]\n",
      "epoch:32 step:30123 [D loss: 0.227957, acc.: 61.72%] [G loss: 0.303459]\n",
      "epoch:32 step:30124 [D loss: 0.227373, acc.: 57.81%] [G loss: 0.312207]\n",
      "epoch:32 step:30125 [D loss: 0.235353, acc.: 57.81%] [G loss: 0.322131]\n",
      "epoch:32 step:30126 [D loss: 0.227480, acc.: 60.16%] [G loss: 0.276936]\n",
      "epoch:32 step:30127 [D loss: 0.220250, acc.: 67.19%] [G loss: 0.280419]\n",
      "epoch:32 step:30128 [D loss: 0.243403, acc.: 60.16%] [G loss: 0.299063]\n",
      "epoch:32 step:30129 [D loss: 0.242312, acc.: 56.25%] [G loss: 0.302172]\n",
      "epoch:32 step:30130 [D loss: 0.237591, acc.: 62.50%] [G loss: 0.325869]\n",
      "epoch:32 step:30131 [D loss: 0.246321, acc.: 54.69%] [G loss: 0.287341]\n",
      "epoch:32 step:30132 [D loss: 0.253706, acc.: 53.12%] [G loss: 0.291739]\n",
      "epoch:32 step:30133 [D loss: 0.245632, acc.: 57.03%] [G loss: 0.329616]\n",
      "epoch:32 step:30134 [D loss: 0.232579, acc.: 60.16%] [G loss: 0.290369]\n",
      "epoch:32 step:30135 [D loss: 0.257710, acc.: 53.12%] [G loss: 0.291790]\n",
      "epoch:32 step:30136 [D loss: 0.245082, acc.: 53.91%] [G loss: 0.318086]\n",
      "epoch:32 step:30137 [D loss: 0.248857, acc.: 55.47%] [G loss: 0.310731]\n",
      "epoch:32 step:30138 [D loss: 0.228670, acc.: 57.81%] [G loss: 0.299761]\n",
      "epoch:32 step:30139 [D loss: 0.239521, acc.: 61.72%] [G loss: 0.293616]\n",
      "epoch:32 step:30140 [D loss: 0.258145, acc.: 53.91%] [G loss: 0.258191]\n",
      "epoch:32 step:30141 [D loss: 0.226831, acc.: 59.38%] [G loss: 0.321228]\n",
      "epoch:32 step:30142 [D loss: 0.228884, acc.: 62.50%] [G loss: 0.305191]\n",
      "epoch:32 step:30143 [D loss: 0.235776, acc.: 57.81%] [G loss: 0.306971]\n",
      "epoch:32 step:30144 [D loss: 0.240661, acc.: 58.59%] [G loss: 0.303051]\n",
      "epoch:32 step:30145 [D loss: 0.238622, acc.: 57.81%] [G loss: 0.311093]\n",
      "epoch:32 step:30146 [D loss: 0.234315, acc.: 58.59%] [G loss: 0.307062]\n",
      "epoch:32 step:30147 [D loss: 0.237620, acc.: 57.03%] [G loss: 0.307565]\n",
      "epoch:32 step:30148 [D loss: 0.220605, acc.: 62.50%] [G loss: 0.291673]\n",
      "epoch:32 step:30149 [D loss: 0.235085, acc.: 62.50%] [G loss: 0.279165]\n",
      "epoch:32 step:30150 [D loss: 0.261274, acc.: 52.34%] [G loss: 0.291466]\n",
      "epoch:32 step:30151 [D loss: 0.229020, acc.: 59.38%] [G loss: 0.308252]\n",
      "epoch:32 step:30152 [D loss: 0.250689, acc.: 52.34%] [G loss: 0.291229]\n",
      "epoch:32 step:30153 [D loss: 0.243855, acc.: 57.03%] [G loss: 0.315432]\n",
      "epoch:32 step:30154 [D loss: 0.221555, acc.: 67.97%] [G loss: 0.316113]\n",
      "epoch:32 step:30155 [D loss: 0.241021, acc.: 53.91%] [G loss: 0.307411]\n",
      "epoch:32 step:30156 [D loss: 0.249258, acc.: 51.56%] [G loss: 0.274176]\n",
      "epoch:32 step:30157 [D loss: 0.222291, acc.: 65.62%] [G loss: 0.313618]\n",
      "epoch:32 step:30158 [D loss: 0.243990, acc.: 54.69%] [G loss: 0.292527]\n",
      "epoch:32 step:30159 [D loss: 0.240637, acc.: 60.16%] [G loss: 0.312504]\n",
      "epoch:32 step:30160 [D loss: 0.227225, acc.: 65.62%] [G loss: 0.295701]\n",
      "epoch:32 step:30161 [D loss: 0.232605, acc.: 60.94%] [G loss: 0.309296]\n",
      "epoch:32 step:30162 [D loss: 0.246595, acc.: 55.47%] [G loss: 0.300197]\n",
      "epoch:32 step:30163 [D loss: 0.238508, acc.: 58.59%] [G loss: 0.330098]\n",
      "epoch:32 step:30164 [D loss: 0.238917, acc.: 63.28%] [G loss: 0.284915]\n",
      "epoch:32 step:30165 [D loss: 0.243802, acc.: 57.81%] [G loss: 0.300130]\n",
      "epoch:32 step:30166 [D loss: 0.224317, acc.: 64.06%] [G loss: 0.313394]\n",
      "epoch:32 step:30167 [D loss: 0.251622, acc.: 53.91%] [G loss: 0.314299]\n",
      "epoch:32 step:30168 [D loss: 0.237923, acc.: 61.72%] [G loss: 0.304993]\n",
      "epoch:32 step:30169 [D loss: 0.237099, acc.: 59.38%] [G loss: 0.325601]\n",
      "epoch:32 step:30170 [D loss: 0.227895, acc.: 67.97%] [G loss: 0.317242]\n",
      "epoch:32 step:30171 [D loss: 0.222572, acc.: 61.72%] [G loss: 0.326277]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:32 step:30172 [D loss: 0.228394, acc.: 62.50%] [G loss: 0.314334]\n",
      "epoch:32 step:30173 [D loss: 0.223224, acc.: 63.28%] [G loss: 0.303775]\n",
      "epoch:32 step:30174 [D loss: 0.241792, acc.: 54.69%] [G loss: 0.302532]\n",
      "epoch:32 step:30175 [D loss: 0.233587, acc.: 61.72%] [G loss: 0.323887]\n",
      "epoch:32 step:30176 [D loss: 0.242172, acc.: 53.91%] [G loss: 0.297713]\n",
      "epoch:32 step:30177 [D loss: 0.246227, acc.: 53.91%] [G loss: 0.274461]\n",
      "epoch:32 step:30178 [D loss: 0.245926, acc.: 56.25%] [G loss: 0.293015]\n",
      "epoch:32 step:30179 [D loss: 0.247273, acc.: 55.47%] [G loss: 0.300640]\n",
      "epoch:32 step:30180 [D loss: 0.226476, acc.: 64.84%] [G loss: 0.292667]\n",
      "epoch:32 step:30181 [D loss: 0.244663, acc.: 56.25%] [G loss: 0.301769]\n",
      "epoch:32 step:30182 [D loss: 0.232462, acc.: 61.72%] [G loss: 0.324721]\n",
      "epoch:32 step:30183 [D loss: 0.256763, acc.: 54.69%] [G loss: 0.256719]\n",
      "epoch:32 step:30184 [D loss: 0.236693, acc.: 60.16%] [G loss: 0.295457]\n",
      "epoch:32 step:30185 [D loss: 0.227686, acc.: 59.38%] [G loss: 0.296089]\n",
      "epoch:32 step:30186 [D loss: 0.255510, acc.: 50.00%] [G loss: 0.298953]\n",
      "epoch:32 step:30187 [D loss: 0.231763, acc.: 56.25%] [G loss: 0.283027]\n",
      "epoch:32 step:30188 [D loss: 0.235914, acc.: 58.59%] [G loss: 0.302903]\n",
      "epoch:32 step:30189 [D loss: 0.237115, acc.: 62.50%] [G loss: 0.303916]\n",
      "epoch:32 step:30190 [D loss: 0.229551, acc.: 60.16%] [G loss: 0.308656]\n",
      "epoch:32 step:30191 [D loss: 0.255658, acc.: 53.91%] [G loss: 0.300994]\n",
      "epoch:32 step:30192 [D loss: 0.235522, acc.: 64.06%] [G loss: 0.301975]\n",
      "epoch:32 step:30193 [D loss: 0.237102, acc.: 57.03%] [G loss: 0.317944]\n",
      "epoch:32 step:30194 [D loss: 0.225318, acc.: 65.62%] [G loss: 0.303344]\n",
      "epoch:32 step:30195 [D loss: 0.247735, acc.: 49.22%] [G loss: 0.295161]\n",
      "epoch:32 step:30196 [D loss: 0.230619, acc.: 58.59%] [G loss: 0.318843]\n",
      "epoch:32 step:30197 [D loss: 0.241727, acc.: 58.59%] [G loss: 0.314444]\n",
      "epoch:32 step:30198 [D loss: 0.240000, acc.: 57.03%] [G loss: 0.303124]\n",
      "epoch:32 step:30199 [D loss: 0.244115, acc.: 60.94%] [G loss: 0.315916]\n",
      "epoch:32 step:30200 [D loss: 0.243431, acc.: 60.94%] [G loss: 0.317524]\n",
      "epoch:32 step:30201 [D loss: 0.217404, acc.: 61.72%] [G loss: 0.301866]\n",
      "epoch:32 step:30202 [D loss: 0.254494, acc.: 51.56%] [G loss: 0.277928]\n",
      "epoch:32 step:30203 [D loss: 0.250201, acc.: 55.47%] [G loss: 0.305691]\n",
      "epoch:32 step:30204 [D loss: 0.234877, acc.: 58.59%] [G loss: 0.298130]\n",
      "epoch:32 step:30205 [D loss: 0.229050, acc.: 57.81%] [G loss: 0.307581]\n",
      "epoch:32 step:30206 [D loss: 0.228137, acc.: 60.94%] [G loss: 0.311135]\n",
      "epoch:32 step:30207 [D loss: 0.231895, acc.: 59.38%] [G loss: 0.286362]\n",
      "epoch:32 step:30208 [D loss: 0.237308, acc.: 62.50%] [G loss: 0.307602]\n",
      "epoch:32 step:30209 [D loss: 0.243280, acc.: 57.03%] [G loss: 0.314828]\n",
      "epoch:32 step:30210 [D loss: 0.238457, acc.: 60.16%] [G loss: 0.308023]\n",
      "epoch:32 step:30211 [D loss: 0.257157, acc.: 51.56%] [G loss: 0.292578]\n",
      "epoch:32 step:30212 [D loss: 0.230995, acc.: 60.94%] [G loss: 0.264897]\n",
      "epoch:32 step:30213 [D loss: 0.225493, acc.: 65.62%] [G loss: 0.308138]\n",
      "epoch:32 step:30214 [D loss: 0.236788, acc.: 59.38%] [G loss: 0.326736]\n",
      "epoch:32 step:30215 [D loss: 0.246266, acc.: 57.81%] [G loss: 0.309286]\n",
      "epoch:32 step:30216 [D loss: 0.238682, acc.: 59.38%] [G loss: 0.293193]\n",
      "epoch:32 step:30217 [D loss: 0.238060, acc.: 58.59%] [G loss: 0.286746]\n",
      "epoch:32 step:30218 [D loss: 0.244701, acc.: 61.72%] [G loss: 0.306221]\n",
      "epoch:32 step:30219 [D loss: 0.248888, acc.: 57.81%] [G loss: 0.256626]\n",
      "epoch:32 step:30220 [D loss: 0.251450, acc.: 50.78%] [G loss: 0.274087]\n",
      "epoch:32 step:30221 [D loss: 0.241269, acc.: 58.59%] [G loss: 0.281584]\n",
      "epoch:32 step:30222 [D loss: 0.241720, acc.: 60.16%] [G loss: 0.284620]\n",
      "epoch:32 step:30223 [D loss: 0.236441, acc.: 64.84%] [G loss: 0.303629]\n",
      "epoch:32 step:30224 [D loss: 0.225612, acc.: 69.53%] [G loss: 0.309924]\n",
      "epoch:32 step:30225 [D loss: 0.241542, acc.: 56.25%] [G loss: 0.283942]\n",
      "epoch:32 step:30226 [D loss: 0.249712, acc.: 52.34%] [G loss: 0.293648]\n",
      "epoch:32 step:30227 [D loss: 0.245172, acc.: 56.25%] [G loss: 0.285323]\n",
      "epoch:32 step:30228 [D loss: 0.247422, acc.: 56.25%] [G loss: 0.294644]\n",
      "epoch:32 step:30229 [D loss: 0.252262, acc.: 55.47%] [G loss: 0.308356]\n",
      "epoch:32 step:30230 [D loss: 0.239457, acc.: 57.81%] [G loss: 0.303424]\n",
      "epoch:32 step:30231 [D loss: 0.259381, acc.: 51.56%] [G loss: 0.299671]\n",
      "epoch:32 step:30232 [D loss: 0.239916, acc.: 60.16%] [G loss: 0.274221]\n",
      "epoch:32 step:30233 [D loss: 0.230571, acc.: 60.94%] [G loss: 0.311444]\n",
      "epoch:32 step:30234 [D loss: 0.247509, acc.: 53.91%] [G loss: 0.329520]\n",
      "epoch:32 step:30235 [D loss: 0.254203, acc.: 57.81%] [G loss: 0.279027]\n",
      "epoch:32 step:30236 [D loss: 0.249688, acc.: 53.91%] [G loss: 0.298717]\n",
      "epoch:32 step:30237 [D loss: 0.232619, acc.: 57.03%] [G loss: 0.290411]\n",
      "epoch:32 step:30238 [D loss: 0.237123, acc.: 60.16%] [G loss: 0.280747]\n",
      "epoch:32 step:30239 [D loss: 0.237075, acc.: 56.25%] [G loss: 0.313692]\n",
      "epoch:32 step:30240 [D loss: 0.239379, acc.: 59.38%] [G loss: 0.309153]\n",
      "epoch:32 step:30241 [D loss: 0.224007, acc.: 63.28%] [G loss: 0.328525]\n",
      "epoch:32 step:30242 [D loss: 0.235524, acc.: 57.03%] [G loss: 0.281965]\n",
      "epoch:32 step:30243 [D loss: 0.231933, acc.: 64.06%] [G loss: 0.316597]\n",
      "epoch:32 step:30244 [D loss: 0.238073, acc.: 53.91%] [G loss: 0.290067]\n",
      "epoch:32 step:30245 [D loss: 0.228640, acc.: 66.41%] [G loss: 0.327814]\n",
      "epoch:32 step:30246 [D loss: 0.243045, acc.: 52.34%] [G loss: 0.317790]\n",
      "epoch:32 step:30247 [D loss: 0.256148, acc.: 53.12%] [G loss: 0.293483]\n",
      "epoch:32 step:30248 [D loss: 0.239642, acc.: 58.59%] [G loss: 0.306986]\n",
      "epoch:32 step:30249 [D loss: 0.230342, acc.: 61.72%] [G loss: 0.316827]\n",
      "epoch:32 step:30250 [D loss: 0.247961, acc.: 51.56%] [G loss: 0.312560]\n",
      "epoch:32 step:30251 [D loss: 0.234854, acc.: 58.59%] [G loss: 0.277219]\n",
      "epoch:32 step:30252 [D loss: 0.230846, acc.: 57.81%] [G loss: 0.304369]\n",
      "epoch:32 step:30253 [D loss: 0.241591, acc.: 57.81%] [G loss: 0.291880]\n",
      "epoch:32 step:30254 [D loss: 0.244737, acc.: 54.69%] [G loss: 0.305948]\n",
      "epoch:32 step:30255 [D loss: 0.231548, acc.: 57.03%] [G loss: 0.311883]\n",
      "epoch:32 step:30256 [D loss: 0.245230, acc.: 55.47%] [G loss: 0.297848]\n",
      "epoch:32 step:30257 [D loss: 0.237848, acc.: 58.59%] [G loss: 0.315345]\n",
      "epoch:32 step:30258 [D loss: 0.256812, acc.: 52.34%] [G loss: 0.281446]\n",
      "epoch:32 step:30259 [D loss: 0.246702, acc.: 50.78%] [G loss: 0.304252]\n",
      "epoch:32 step:30260 [D loss: 0.230602, acc.: 58.59%] [G loss: 0.290266]\n",
      "epoch:32 step:30261 [D loss: 0.239883, acc.: 63.28%] [G loss: 0.286699]\n",
      "epoch:32 step:30262 [D loss: 0.233009, acc.: 59.38%] [G loss: 0.335770]\n",
      "epoch:32 step:30263 [D loss: 0.247588, acc.: 57.03%] [G loss: 0.299050]\n",
      "epoch:32 step:30264 [D loss: 0.233487, acc.: 60.94%] [G loss: 0.278409]\n",
      "epoch:32 step:30265 [D loss: 0.233783, acc.: 60.94%] [G loss: 0.302785]\n",
      "epoch:32 step:30266 [D loss: 0.254114, acc.: 50.78%] [G loss: 0.266271]\n",
      "epoch:32 step:30267 [D loss: 0.245572, acc.: 58.59%] [G loss: 0.309677]\n",
      "epoch:32 step:30268 [D loss: 0.247634, acc.: 54.69%] [G loss: 0.289728]\n",
      "epoch:32 step:30269 [D loss: 0.251485, acc.: 54.69%] [G loss: 0.291148]\n",
      "epoch:32 step:30270 [D loss: 0.238400, acc.: 60.16%] [G loss: 0.293383]\n",
      "epoch:32 step:30271 [D loss: 0.233316, acc.: 57.81%] [G loss: 0.302072]\n",
      "epoch:32 step:30272 [D loss: 0.237932, acc.: 58.59%] [G loss: 0.317291]\n",
      "epoch:32 step:30273 [D loss: 0.244298, acc.: 51.56%] [G loss: 0.266238]\n",
      "epoch:32 step:30274 [D loss: 0.252243, acc.: 52.34%] [G loss: 0.335523]\n",
      "epoch:32 step:30275 [D loss: 0.254911, acc.: 51.56%] [G loss: 0.299830]\n",
      "epoch:32 step:30276 [D loss: 0.239166, acc.: 54.69%] [G loss: 0.288104]\n",
      "epoch:32 step:30277 [D loss: 0.243269, acc.: 60.94%] [G loss: 0.336512]\n",
      "epoch:32 step:30278 [D loss: 0.236147, acc.: 58.59%] [G loss: 0.325580]\n",
      "epoch:32 step:30279 [D loss: 0.238920, acc.: 60.16%] [G loss: 0.301477]\n",
      "epoch:32 step:30280 [D loss: 0.230491, acc.: 56.25%] [G loss: 0.291334]\n",
      "epoch:32 step:30281 [D loss: 0.241226, acc.: 56.25%] [G loss: 0.334738]\n",
      "epoch:32 step:30282 [D loss: 0.243505, acc.: 60.16%] [G loss: 0.299714]\n",
      "epoch:32 step:30283 [D loss: 0.261707, acc.: 46.88%] [G loss: 0.277579]\n",
      "epoch:32 step:30284 [D loss: 0.237785, acc.: 55.47%] [G loss: 0.332939]\n",
      "epoch:32 step:30285 [D loss: 0.229879, acc.: 68.75%] [G loss: 0.305557]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:32 step:30286 [D loss: 0.244381, acc.: 52.34%] [G loss: 0.304807]\n",
      "epoch:32 step:30287 [D loss: 0.236785, acc.: 60.16%] [G loss: 0.333773]\n",
      "epoch:32 step:30288 [D loss: 0.231232, acc.: 62.50%] [G loss: 0.308014]\n",
      "epoch:32 step:30289 [D loss: 0.245662, acc.: 55.47%] [G loss: 0.308222]\n",
      "epoch:32 step:30290 [D loss: 0.238108, acc.: 60.16%] [G loss: 0.301155]\n",
      "epoch:32 step:30291 [D loss: 0.240049, acc.: 57.03%] [G loss: 0.306872]\n",
      "epoch:32 step:30292 [D loss: 0.245241, acc.: 51.56%] [G loss: 0.294578]\n",
      "epoch:32 step:30293 [D loss: 0.247815, acc.: 50.78%] [G loss: 0.301724]\n",
      "epoch:32 step:30294 [D loss: 0.251205, acc.: 54.69%] [G loss: 0.289488]\n",
      "epoch:32 step:30295 [D loss: 0.234194, acc.: 59.38%] [G loss: 0.301170]\n",
      "epoch:32 step:30296 [D loss: 0.246775, acc.: 57.03%] [G loss: 0.290240]\n",
      "epoch:32 step:30297 [D loss: 0.258754, acc.: 55.47%] [G loss: 0.284978]\n",
      "epoch:32 step:30298 [D loss: 0.251296, acc.: 53.12%] [G loss: 0.270908]\n",
      "epoch:32 step:30299 [D loss: 0.250700, acc.: 50.78%] [G loss: 0.301832]\n",
      "epoch:32 step:30300 [D loss: 0.239386, acc.: 60.16%] [G loss: 0.296146]\n",
      "epoch:32 step:30301 [D loss: 0.233566, acc.: 57.03%] [G loss: 0.290843]\n",
      "epoch:32 step:30302 [D loss: 0.254838, acc.: 53.91%] [G loss: 0.303793]\n",
      "epoch:32 step:30303 [D loss: 0.257941, acc.: 53.12%] [G loss: 0.296199]\n",
      "epoch:32 step:30304 [D loss: 0.236471, acc.: 61.72%] [G loss: 0.317361]\n",
      "epoch:32 step:30305 [D loss: 0.248163, acc.: 50.78%] [G loss: 0.275485]\n",
      "epoch:32 step:30306 [D loss: 0.247031, acc.: 52.34%] [G loss: 0.297145]\n",
      "epoch:32 step:30307 [D loss: 0.250467, acc.: 58.59%] [G loss: 0.299326]\n",
      "epoch:32 step:30308 [D loss: 0.222977, acc.: 64.06%] [G loss: 0.311504]\n",
      "epoch:32 step:30309 [D loss: 0.255397, acc.: 46.88%] [G loss: 0.277176]\n",
      "epoch:32 step:30310 [D loss: 0.241584, acc.: 55.47%] [G loss: 0.306952]\n",
      "epoch:32 step:30311 [D loss: 0.241070, acc.: 57.81%] [G loss: 0.333280]\n",
      "epoch:32 step:30312 [D loss: 0.238984, acc.: 54.69%] [G loss: 0.313730]\n",
      "epoch:32 step:30313 [D loss: 0.243473, acc.: 60.94%] [G loss: 0.324111]\n",
      "epoch:32 step:30314 [D loss: 0.230946, acc.: 61.72%] [G loss: 0.306004]\n",
      "epoch:32 step:30315 [D loss: 0.247522, acc.: 55.47%] [G loss: 0.305431]\n",
      "epoch:32 step:30316 [D loss: 0.230992, acc.: 64.06%] [G loss: 0.290438]\n",
      "epoch:32 step:30317 [D loss: 0.245028, acc.: 53.12%] [G loss: 0.312945]\n",
      "epoch:32 step:30318 [D loss: 0.235959, acc.: 62.50%] [G loss: 0.276432]\n",
      "epoch:32 step:30319 [D loss: 0.249936, acc.: 53.12%] [G loss: 0.257024]\n",
      "epoch:32 step:30320 [D loss: 0.246647, acc.: 54.69%] [G loss: 0.295171]\n",
      "epoch:32 step:30321 [D loss: 0.244286, acc.: 55.47%] [G loss: 0.303973]\n",
      "epoch:32 step:30322 [D loss: 0.230613, acc.: 64.84%] [G loss: 0.312289]\n",
      "epoch:32 step:30323 [D loss: 0.249071, acc.: 55.47%] [G loss: 0.303897]\n",
      "epoch:32 step:30324 [D loss: 0.229341, acc.: 58.59%] [G loss: 0.306763]\n",
      "epoch:32 step:30325 [D loss: 0.235254, acc.: 61.72%] [G loss: 0.299161]\n",
      "epoch:32 step:30326 [D loss: 0.255326, acc.: 56.25%] [G loss: 0.315447]\n",
      "epoch:32 step:30327 [D loss: 0.230821, acc.: 60.16%] [G loss: 0.303239]\n",
      "epoch:32 step:30328 [D loss: 0.237437, acc.: 60.16%] [G loss: 0.318351]\n",
      "epoch:32 step:30329 [D loss: 0.246939, acc.: 53.91%] [G loss: 0.297960]\n",
      "epoch:32 step:30330 [D loss: 0.238987, acc.: 56.25%] [G loss: 0.307649]\n",
      "epoch:32 step:30331 [D loss: 0.251084, acc.: 50.78%] [G loss: 0.294457]\n",
      "epoch:32 step:30332 [D loss: 0.223656, acc.: 65.62%] [G loss: 0.284043]\n",
      "epoch:32 step:30333 [D loss: 0.235411, acc.: 59.38%] [G loss: 0.271658]\n",
      "epoch:32 step:30334 [D loss: 0.239975, acc.: 63.28%] [G loss: 0.294087]\n",
      "epoch:32 step:30335 [D loss: 0.234780, acc.: 60.94%] [G loss: 0.297195]\n",
      "epoch:32 step:30336 [D loss: 0.236626, acc.: 57.81%] [G loss: 0.311097]\n",
      "epoch:32 step:30337 [D loss: 0.243099, acc.: 59.38%] [G loss: 0.298086]\n",
      "epoch:32 step:30338 [D loss: 0.230072, acc.: 59.38%] [G loss: 0.273890]\n",
      "epoch:32 step:30339 [D loss: 0.246676, acc.: 57.03%] [G loss: 0.303090]\n",
      "epoch:32 step:30340 [D loss: 0.240875, acc.: 57.81%] [G loss: 0.293231]\n",
      "epoch:32 step:30341 [D loss: 0.245968, acc.: 63.28%] [G loss: 0.307715]\n",
      "epoch:32 step:30342 [D loss: 0.249223, acc.: 62.50%] [G loss: 0.304077]\n",
      "epoch:32 step:30343 [D loss: 0.249292, acc.: 57.81%] [G loss: 0.308940]\n",
      "epoch:32 step:30344 [D loss: 0.226162, acc.: 66.41%] [G loss: 0.299760]\n",
      "epoch:32 step:30345 [D loss: 0.248091, acc.: 50.78%] [G loss: 0.334986]\n",
      "epoch:32 step:30346 [D loss: 0.238077, acc.: 59.38%] [G loss: 0.305381]\n",
      "epoch:32 step:30347 [D loss: 0.226828, acc.: 68.75%] [G loss: 0.264692]\n",
      "epoch:32 step:30348 [D loss: 0.229677, acc.: 64.84%] [G loss: 0.315179]\n",
      "epoch:32 step:30349 [D loss: 0.240383, acc.: 60.16%] [G loss: 0.280740]\n",
      "epoch:32 step:30350 [D loss: 0.233772, acc.: 63.28%] [G loss: 0.304609]\n",
      "epoch:32 step:30351 [D loss: 0.231169, acc.: 59.38%] [G loss: 0.321347]\n",
      "epoch:32 step:30352 [D loss: 0.249286, acc.: 53.12%] [G loss: 0.323213]\n",
      "epoch:32 step:30353 [D loss: 0.248102, acc.: 52.34%] [G loss: 0.302012]\n",
      "epoch:32 step:30354 [D loss: 0.249277, acc.: 54.69%] [G loss: 0.303742]\n",
      "epoch:32 step:30355 [D loss: 0.234458, acc.: 62.50%] [G loss: 0.283746]\n",
      "epoch:32 step:30356 [D loss: 0.230905, acc.: 64.06%] [G loss: 0.313810]\n",
      "epoch:32 step:30357 [D loss: 0.232743, acc.: 64.06%] [G loss: 0.295119]\n",
      "epoch:32 step:30358 [D loss: 0.245113, acc.: 60.94%] [G loss: 0.269954]\n",
      "epoch:32 step:30359 [D loss: 0.244564, acc.: 59.38%] [G loss: 0.302552]\n",
      "epoch:32 step:30360 [D loss: 0.233093, acc.: 57.03%] [G loss: 0.331828]\n",
      "epoch:32 step:30361 [D loss: 0.241299, acc.: 60.94%] [G loss: 0.309158]\n",
      "epoch:32 step:30362 [D loss: 0.253109, acc.: 52.34%] [G loss: 0.298311]\n",
      "epoch:32 step:30363 [D loss: 0.241853, acc.: 53.12%] [G loss: 0.278392]\n",
      "epoch:32 step:30364 [D loss: 0.236357, acc.: 61.72%] [G loss: 0.308397]\n",
      "epoch:32 step:30365 [D loss: 0.241675, acc.: 54.69%] [G loss: 0.278765]\n",
      "epoch:32 step:30366 [D loss: 0.241123, acc.: 57.03%] [G loss: 0.312587]\n",
      "epoch:32 step:30367 [D loss: 0.213454, acc.: 71.88%] [G loss: 0.284247]\n",
      "epoch:32 step:30368 [D loss: 0.237250, acc.: 57.03%] [G loss: 0.295268]\n",
      "epoch:32 step:30369 [D loss: 0.239522, acc.: 56.25%] [G loss: 0.311617]\n",
      "epoch:32 step:30370 [D loss: 0.212721, acc.: 63.28%] [G loss: 0.318719]\n",
      "epoch:32 step:30371 [D loss: 0.241510, acc.: 57.03%] [G loss: 0.307473]\n",
      "epoch:32 step:30372 [D loss: 0.252313, acc.: 51.56%] [G loss: 0.299366]\n",
      "epoch:32 step:30373 [D loss: 0.238541, acc.: 57.03%] [G loss: 0.288147]\n",
      "epoch:32 step:30374 [D loss: 0.244570, acc.: 57.81%] [G loss: 0.324638]\n",
      "epoch:32 step:30375 [D loss: 0.232949, acc.: 59.38%] [G loss: 0.301310]\n",
      "epoch:32 step:30376 [D loss: 0.246961, acc.: 51.56%] [G loss: 0.287286]\n",
      "epoch:32 step:30377 [D loss: 0.242198, acc.: 60.94%] [G loss: 0.277368]\n",
      "epoch:32 step:30378 [D loss: 0.240879, acc.: 62.50%] [G loss: 0.320932]\n",
      "epoch:32 step:30379 [D loss: 0.231608, acc.: 60.16%] [G loss: 0.306201]\n",
      "epoch:32 step:30380 [D loss: 0.221550, acc.: 64.84%] [G loss: 0.290759]\n",
      "epoch:32 step:30381 [D loss: 0.239749, acc.: 57.03%] [G loss: 0.284190]\n",
      "epoch:32 step:30382 [D loss: 0.229550, acc.: 60.16%] [G loss: 0.311873]\n",
      "epoch:32 step:30383 [D loss: 0.236063, acc.: 60.94%] [G loss: 0.295292]\n",
      "epoch:32 step:30384 [D loss: 0.235349, acc.: 57.03%] [G loss: 0.294910]\n",
      "epoch:32 step:30385 [D loss: 0.230427, acc.: 57.81%] [G loss: 0.317703]\n",
      "epoch:32 step:30386 [D loss: 0.243220, acc.: 59.38%] [G loss: 0.283123]\n",
      "epoch:32 step:30387 [D loss: 0.249947, acc.: 54.69%] [G loss: 0.314267]\n",
      "epoch:32 step:30388 [D loss: 0.242682, acc.: 57.03%] [G loss: 0.316802]\n",
      "epoch:32 step:30389 [D loss: 0.230103, acc.: 57.81%] [G loss: 0.290511]\n",
      "epoch:32 step:30390 [D loss: 0.240493, acc.: 57.81%] [G loss: 0.281761]\n",
      "epoch:32 step:30391 [D loss: 0.256736, acc.: 53.91%] [G loss: 0.295568]\n",
      "epoch:32 step:30392 [D loss: 0.221075, acc.: 60.16%] [G loss: 0.300188]\n",
      "epoch:32 step:30393 [D loss: 0.229922, acc.: 61.72%] [G loss: 0.312687]\n",
      "epoch:32 step:30394 [D loss: 0.241447, acc.: 58.59%] [G loss: 0.276544]\n",
      "epoch:32 step:30395 [D loss: 0.250145, acc.: 53.91%] [G loss: 0.291254]\n",
      "epoch:32 step:30396 [D loss: 0.245735, acc.: 55.47%] [G loss: 0.308880]\n",
      "epoch:32 step:30397 [D loss: 0.249767, acc.: 53.12%] [G loss: 0.305072]\n",
      "epoch:32 step:30398 [D loss: 0.230219, acc.: 60.94%] [G loss: 0.303691]\n",
      "epoch:32 step:30399 [D loss: 0.242563, acc.: 56.25%] [G loss: 0.341903]\n",
      "epoch:32 step:30400 [D loss: 0.244980, acc.: 56.25%] [G loss: 0.293882]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:32 step:30401 [D loss: 0.226280, acc.: 60.16%] [G loss: 0.280686]\n",
      "epoch:32 step:30402 [D loss: 0.242060, acc.: 57.03%] [G loss: 0.304917]\n",
      "epoch:32 step:30403 [D loss: 0.221471, acc.: 67.97%] [G loss: 0.273001]\n",
      "epoch:32 step:30404 [D loss: 0.233031, acc.: 60.16%] [G loss: 0.302240]\n",
      "epoch:32 step:30405 [D loss: 0.247861, acc.: 54.69%] [G loss: 0.321685]\n",
      "epoch:32 step:30406 [D loss: 0.254534, acc.: 53.12%] [G loss: 0.289458]\n",
      "epoch:32 step:30407 [D loss: 0.228507, acc.: 62.50%] [G loss: 0.303491]\n",
      "epoch:32 step:30408 [D loss: 0.251753, acc.: 50.00%] [G loss: 0.274576]\n",
      "epoch:32 step:30409 [D loss: 0.252162, acc.: 56.25%] [G loss: 0.281913]\n",
      "epoch:32 step:30410 [D loss: 0.237230, acc.: 55.47%] [G loss: 0.282074]\n",
      "epoch:32 step:30411 [D loss: 0.235467, acc.: 60.16%] [G loss: 0.291414]\n",
      "epoch:32 step:30412 [D loss: 0.273088, acc.: 44.53%] [G loss: 0.274617]\n",
      "epoch:32 step:30413 [D loss: 0.248303, acc.: 57.03%] [G loss: 0.291250]\n",
      "epoch:32 step:30414 [D loss: 0.233347, acc.: 59.38%] [G loss: 0.293798]\n",
      "epoch:32 step:30415 [D loss: 0.243653, acc.: 57.03%] [G loss: 0.285152]\n",
      "epoch:32 step:30416 [D loss: 0.240154, acc.: 58.59%] [G loss: 0.272898]\n",
      "epoch:32 step:30417 [D loss: 0.252452, acc.: 57.03%] [G loss: 0.283633]\n",
      "epoch:32 step:30418 [D loss: 0.241838, acc.: 56.25%] [G loss: 0.295345]\n",
      "epoch:32 step:30419 [D loss: 0.235981, acc.: 55.47%] [G loss: 0.284451]\n",
      "epoch:32 step:30420 [D loss: 0.233130, acc.: 61.72%] [G loss: 0.314766]\n",
      "epoch:32 step:30421 [D loss: 0.249256, acc.: 60.16%] [G loss: 0.305363]\n",
      "epoch:32 step:30422 [D loss: 0.237425, acc.: 59.38%] [G loss: 0.325352]\n",
      "epoch:32 step:30423 [D loss: 0.241706, acc.: 55.47%] [G loss: 0.269731]\n",
      "epoch:32 step:30424 [D loss: 0.250835, acc.: 51.56%] [G loss: 0.304881]\n",
      "epoch:32 step:30425 [D loss: 0.227683, acc.: 66.41%] [G loss: 0.320357]\n",
      "epoch:32 step:30426 [D loss: 0.249561, acc.: 53.12%] [G loss: 0.288265]\n",
      "epoch:32 step:30427 [D loss: 0.248871, acc.: 55.47%] [G loss: 0.269749]\n",
      "epoch:32 step:30428 [D loss: 0.247449, acc.: 55.47%] [G loss: 0.308553]\n",
      "epoch:32 step:30429 [D loss: 0.235115, acc.: 57.03%] [G loss: 0.259508]\n",
      "epoch:32 step:30430 [D loss: 0.254418, acc.: 50.78%] [G loss: 0.283295]\n",
      "epoch:32 step:30431 [D loss: 0.237052, acc.: 60.16%] [G loss: 0.295242]\n",
      "epoch:32 step:30432 [D loss: 0.233795, acc.: 58.59%] [G loss: 0.296895]\n",
      "epoch:32 step:30433 [D loss: 0.253215, acc.: 48.44%] [G loss: 0.267489]\n",
      "epoch:32 step:30434 [D loss: 0.253083, acc.: 48.44%] [G loss: 0.288156]\n",
      "epoch:32 step:30435 [D loss: 0.242951, acc.: 55.47%] [G loss: 0.282696]\n",
      "epoch:32 step:30436 [D loss: 0.249685, acc.: 53.91%] [G loss: 0.288886]\n",
      "epoch:32 step:30437 [D loss: 0.230566, acc.: 60.16%] [G loss: 0.305689]\n",
      "epoch:32 step:30438 [D loss: 0.249100, acc.: 56.25%] [G loss: 0.289910]\n",
      "epoch:32 step:30439 [D loss: 0.255039, acc.: 55.47%] [G loss: 0.298708]\n",
      "epoch:32 step:30440 [D loss: 0.224152, acc.: 67.19%] [G loss: 0.329538]\n",
      "epoch:32 step:30441 [D loss: 0.245796, acc.: 53.91%] [G loss: 0.317939]\n",
      "epoch:32 step:30442 [D loss: 0.227437, acc.: 64.06%] [G loss: 0.308905]\n",
      "epoch:32 step:30443 [D loss: 0.243038, acc.: 50.00%] [G loss: 0.320828]\n",
      "epoch:32 step:30444 [D loss: 0.238878, acc.: 60.16%] [G loss: 0.297046]\n",
      "epoch:32 step:30445 [D loss: 0.239573, acc.: 54.69%] [G loss: 0.319870]\n",
      "epoch:32 step:30446 [D loss: 0.233186, acc.: 64.06%] [G loss: 0.254340]\n",
      "epoch:32 step:30447 [D loss: 0.245557, acc.: 56.25%] [G loss: 0.288832]\n",
      "epoch:32 step:30448 [D loss: 0.230422, acc.: 57.81%] [G loss: 0.308957]\n",
      "epoch:32 step:30449 [D loss: 0.245919, acc.: 62.50%] [G loss: 0.334298]\n",
      "epoch:32 step:30450 [D loss: 0.244783, acc.: 56.25%] [G loss: 0.283943]\n",
      "epoch:32 step:30451 [D loss: 0.224456, acc.: 61.72%] [G loss: 0.269272]\n",
      "epoch:32 step:30452 [D loss: 0.214938, acc.: 64.84%] [G loss: 0.277318]\n",
      "epoch:32 step:30453 [D loss: 0.229250, acc.: 65.62%] [G loss: 0.288529]\n",
      "epoch:32 step:30454 [D loss: 0.261682, acc.: 50.00%] [G loss: 0.296249]\n",
      "epoch:32 step:30455 [D loss: 0.237931, acc.: 61.72%] [G loss: 0.291348]\n",
      "epoch:32 step:30456 [D loss: 0.233575, acc.: 59.38%] [G loss: 0.314834]\n",
      "epoch:32 step:30457 [D loss: 0.249585, acc.: 54.69%] [G loss: 0.282884]\n",
      "epoch:32 step:30458 [D loss: 0.241601, acc.: 58.59%] [G loss: 0.287791]\n",
      "epoch:32 step:30459 [D loss: 0.231153, acc.: 61.72%] [G loss: 0.303564]\n",
      "epoch:32 step:30460 [D loss: 0.223654, acc.: 64.84%] [G loss: 0.305574]\n",
      "epoch:32 step:30461 [D loss: 0.243751, acc.: 50.78%] [G loss: 0.294185]\n",
      "epoch:32 step:30462 [D loss: 0.248427, acc.: 50.00%] [G loss: 0.282114]\n",
      "epoch:32 step:30463 [D loss: 0.225396, acc.: 63.28%] [G loss: 0.293288]\n",
      "epoch:32 step:30464 [D loss: 0.234592, acc.: 58.59%] [G loss: 0.302320]\n",
      "epoch:32 step:30465 [D loss: 0.247324, acc.: 52.34%] [G loss: 0.325304]\n",
      "epoch:32 step:30466 [D loss: 0.235413, acc.: 64.06%] [G loss: 0.315360]\n",
      "epoch:32 step:30467 [D loss: 0.242669, acc.: 55.47%] [G loss: 0.294438]\n",
      "epoch:32 step:30468 [D loss: 0.222917, acc.: 61.72%] [G loss: 0.287638]\n",
      "epoch:32 step:30469 [D loss: 0.212833, acc.: 64.84%] [G loss: 0.306083]\n",
      "epoch:32 step:30470 [D loss: 0.234464, acc.: 57.81%] [G loss: 0.290855]\n",
      "epoch:32 step:30471 [D loss: 0.225902, acc.: 63.28%] [G loss: 0.345625]\n",
      "epoch:32 step:30472 [D loss: 0.251104, acc.: 56.25%] [G loss: 0.293421]\n",
      "epoch:32 step:30473 [D loss: 0.241044, acc.: 60.94%] [G loss: 0.324481]\n",
      "epoch:32 step:30474 [D loss: 0.230524, acc.: 64.06%] [G loss: 0.310658]\n",
      "epoch:32 step:30475 [D loss: 0.233925, acc.: 59.38%] [G loss: 0.300525]\n",
      "epoch:32 step:30476 [D loss: 0.247565, acc.: 52.34%] [G loss: 0.303113]\n",
      "epoch:32 step:30477 [D loss: 0.242649, acc.: 50.78%] [G loss: 0.298233]\n",
      "epoch:32 step:30478 [D loss: 0.230857, acc.: 57.03%] [G loss: 0.314848]\n",
      "epoch:32 step:30479 [D loss: 0.264284, acc.: 44.53%] [G loss: 0.301466]\n",
      "epoch:32 step:30480 [D loss: 0.229091, acc.: 60.16%] [G loss: 0.339143]\n",
      "epoch:32 step:30481 [D loss: 0.232061, acc.: 61.72%] [G loss: 0.328407]\n",
      "epoch:32 step:30482 [D loss: 0.232190, acc.: 60.16%] [G loss: 0.290507]\n",
      "epoch:32 step:30483 [D loss: 0.244609, acc.: 54.69%] [G loss: 0.296001]\n",
      "epoch:32 step:30484 [D loss: 0.260141, acc.: 52.34%] [G loss: 0.294790]\n",
      "epoch:32 step:30485 [D loss: 0.238245, acc.: 57.81%] [G loss: 0.311226]\n",
      "epoch:32 step:30486 [D loss: 0.232667, acc.: 61.72%] [G loss: 0.304298]\n",
      "epoch:32 step:30487 [D loss: 0.241129, acc.: 51.56%] [G loss: 0.301031]\n",
      "epoch:32 step:30488 [D loss: 0.234580, acc.: 57.03%] [G loss: 0.321520]\n",
      "epoch:32 step:30489 [D loss: 0.240070, acc.: 64.06%] [G loss: 0.319625]\n",
      "epoch:32 step:30490 [D loss: 0.230961, acc.: 62.50%] [G loss: 0.309281]\n",
      "epoch:32 step:30491 [D loss: 0.257370, acc.: 50.78%] [G loss: 0.270429]\n",
      "epoch:32 step:30492 [D loss: 0.252471, acc.: 50.78%] [G loss: 0.274373]\n",
      "epoch:32 step:30493 [D loss: 0.243200, acc.: 58.59%] [G loss: 0.273714]\n",
      "epoch:32 step:30494 [D loss: 0.241517, acc.: 56.25%] [G loss: 0.277414]\n",
      "epoch:32 step:30495 [D loss: 0.234917, acc.: 60.16%] [G loss: 0.316345]\n",
      "epoch:32 step:30496 [D loss: 0.241270, acc.: 59.38%] [G loss: 0.335864]\n",
      "epoch:32 step:30497 [D loss: 0.240221, acc.: 53.91%] [G loss: 0.304068]\n",
      "epoch:32 step:30498 [D loss: 0.249305, acc.: 50.78%] [G loss: 0.319708]\n",
      "epoch:32 step:30499 [D loss: 0.241371, acc.: 52.34%] [G loss: 0.312308]\n",
      "epoch:32 step:30500 [D loss: 0.225883, acc.: 60.16%] [G loss: 0.330976]\n",
      "epoch:32 step:30501 [D loss: 0.255760, acc.: 57.03%] [G loss: 0.303577]\n",
      "epoch:32 step:30502 [D loss: 0.234063, acc.: 63.28%] [G loss: 0.323604]\n",
      "epoch:32 step:30503 [D loss: 0.227443, acc.: 61.72%] [G loss: 0.286270]\n",
      "epoch:32 step:30504 [D loss: 0.237862, acc.: 57.81%] [G loss: 0.295322]\n",
      "epoch:32 step:30505 [D loss: 0.251815, acc.: 52.34%] [G loss: 0.291586]\n",
      "epoch:32 step:30506 [D loss: 0.251329, acc.: 52.34%] [G loss: 0.305999]\n",
      "epoch:32 step:30507 [D loss: 0.228491, acc.: 62.50%] [G loss: 0.284492]\n",
      "epoch:32 step:30508 [D loss: 0.248012, acc.: 52.34%] [G loss: 0.287446]\n",
      "epoch:32 step:30509 [D loss: 0.242659, acc.: 59.38%] [G loss: 0.281937]\n",
      "epoch:32 step:30510 [D loss: 0.243289, acc.: 58.59%] [G loss: 0.302268]\n",
      "epoch:32 step:30511 [D loss: 0.263862, acc.: 47.66%] [G loss: 0.294895]\n",
      "epoch:32 step:30512 [D loss: 0.256378, acc.: 53.12%] [G loss: 0.275764]\n",
      "epoch:32 step:30513 [D loss: 0.236747, acc.: 63.28%] [G loss: 0.308838]\n",
      "epoch:32 step:30514 [D loss: 0.230678, acc.: 63.28%] [G loss: 0.309394]\n",
      "epoch:32 step:30515 [D loss: 0.234109, acc.: 58.59%] [G loss: 0.317473]\n",
      "epoch:32 step:30516 [D loss: 0.239954, acc.: 57.81%] [G loss: 0.295330]\n",
      "epoch:32 step:30517 [D loss: 0.252238, acc.: 53.91%] [G loss: 0.304541]\n",
      "epoch:32 step:30518 [D loss: 0.239544, acc.: 53.91%] [G loss: 0.305232]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:32 step:30519 [D loss: 0.245379, acc.: 52.34%] [G loss: 0.282720]\n",
      "epoch:32 step:30520 [D loss: 0.241595, acc.: 60.16%] [G loss: 0.308010]\n",
      "epoch:32 step:30521 [D loss: 0.234648, acc.: 60.94%] [G loss: 0.292076]\n",
      "epoch:32 step:30522 [D loss: 0.262109, acc.: 49.22%] [G loss: 0.275524]\n",
      "epoch:32 step:30523 [D loss: 0.241311, acc.: 57.81%] [G loss: 0.317745]\n",
      "epoch:32 step:30524 [D loss: 0.244237, acc.: 54.69%] [G loss: 0.303527]\n",
      "epoch:32 step:30525 [D loss: 0.224727, acc.: 59.38%] [G loss: 0.313104]\n",
      "epoch:32 step:30526 [D loss: 0.253979, acc.: 57.81%] [G loss: 0.306759]\n",
      "epoch:32 step:30527 [D loss: 0.232481, acc.: 58.59%] [G loss: 0.279438]\n",
      "epoch:32 step:30528 [D loss: 0.228823, acc.: 60.16%] [G loss: 0.283990]\n",
      "epoch:32 step:30529 [D loss: 0.247160, acc.: 54.69%] [G loss: 0.310356]\n",
      "epoch:32 step:30530 [D loss: 0.249695, acc.: 53.91%] [G loss: 0.301222]\n",
      "epoch:32 step:30531 [D loss: 0.244321, acc.: 57.81%] [G loss: 0.300064]\n",
      "epoch:32 step:30532 [D loss: 0.245220, acc.: 55.47%] [G loss: 0.301578]\n",
      "epoch:32 step:30533 [D loss: 0.225318, acc.: 63.28%] [G loss: 0.305543]\n",
      "epoch:32 step:30534 [D loss: 0.239349, acc.: 57.81%] [G loss: 0.286962]\n",
      "epoch:32 step:30535 [D loss: 0.232576, acc.: 60.16%] [G loss: 0.310991]\n",
      "epoch:32 step:30536 [D loss: 0.243288, acc.: 62.50%] [G loss: 0.293599]\n",
      "epoch:32 step:30537 [D loss: 0.247328, acc.: 55.47%] [G loss: 0.301645]\n",
      "epoch:32 step:30538 [D loss: 0.223636, acc.: 61.72%] [G loss: 0.312269]\n",
      "epoch:32 step:30539 [D loss: 0.233712, acc.: 60.16%] [G loss: 0.286605]\n",
      "epoch:32 step:30540 [D loss: 0.224879, acc.: 59.38%] [G loss: 0.311293]\n",
      "epoch:32 step:30541 [D loss: 0.217731, acc.: 63.28%] [G loss: 0.287209]\n",
      "epoch:32 step:30542 [D loss: 0.246016, acc.: 53.12%] [G loss: 0.316670]\n",
      "epoch:32 step:30543 [D loss: 0.245441, acc.: 56.25%] [G loss: 0.256557]\n",
      "epoch:32 step:30544 [D loss: 0.241074, acc.: 56.25%] [G loss: 0.303557]\n",
      "epoch:32 step:30545 [D loss: 0.243524, acc.: 57.81%] [G loss: 0.307382]\n",
      "epoch:32 step:30546 [D loss: 0.251402, acc.: 52.34%] [G loss: 0.283736]\n",
      "epoch:32 step:30547 [D loss: 0.241712, acc.: 55.47%] [G loss: 0.298847]\n",
      "epoch:32 step:30548 [D loss: 0.229224, acc.: 63.28%] [G loss: 0.283695]\n",
      "epoch:32 step:30549 [D loss: 0.228625, acc.: 61.72%] [G loss: 0.265484]\n",
      "epoch:32 step:30550 [D loss: 0.255073, acc.: 51.56%] [G loss: 0.304561]\n",
      "epoch:32 step:30551 [D loss: 0.237284, acc.: 61.72%] [G loss: 0.320323]\n",
      "epoch:32 step:30552 [D loss: 0.240004, acc.: 60.94%] [G loss: 0.305027]\n",
      "epoch:32 step:30553 [D loss: 0.241080, acc.: 60.94%] [G loss: 0.283414]\n",
      "epoch:32 step:30554 [D loss: 0.241380, acc.: 60.16%] [G loss: 0.296327]\n",
      "epoch:32 step:30555 [D loss: 0.239403, acc.: 57.03%] [G loss: 0.276737]\n",
      "epoch:32 step:30556 [D loss: 0.237025, acc.: 57.03%] [G loss: 0.303523]\n",
      "epoch:32 step:30557 [D loss: 0.249178, acc.: 60.16%] [G loss: 0.330019]\n",
      "epoch:32 step:30558 [D loss: 0.247434, acc.: 51.56%] [G loss: 0.281990]\n",
      "epoch:32 step:30559 [D loss: 0.246494, acc.: 53.91%] [G loss: 0.278972]\n",
      "epoch:32 step:30560 [D loss: 0.228649, acc.: 62.50%] [G loss: 0.293149]\n",
      "epoch:32 step:30561 [D loss: 0.245622, acc.: 57.03%] [G loss: 0.306292]\n",
      "epoch:32 step:30562 [D loss: 0.246104, acc.: 55.47%] [G loss: 0.296339]\n",
      "epoch:32 step:30563 [D loss: 0.230920, acc.: 62.50%] [G loss: 0.307998]\n",
      "epoch:32 step:30564 [D loss: 0.234633, acc.: 62.50%] [G loss: 0.295682]\n",
      "epoch:32 step:30565 [D loss: 0.259056, acc.: 54.69%] [G loss: 0.293429]\n",
      "epoch:32 step:30566 [D loss: 0.235352, acc.: 62.50%] [G loss: 0.278763]\n",
      "epoch:32 step:30567 [D loss: 0.243091, acc.: 59.38%] [G loss: 0.305257]\n",
      "epoch:32 step:30568 [D loss: 0.224002, acc.: 61.72%] [G loss: 0.278151]\n",
      "epoch:32 step:30569 [D loss: 0.239446, acc.: 59.38%] [G loss: 0.322199]\n",
      "epoch:32 step:30570 [D loss: 0.240244, acc.: 63.28%] [G loss: 0.314635]\n",
      "epoch:32 step:30571 [D loss: 0.255504, acc.: 48.44%] [G loss: 0.288247]\n",
      "epoch:32 step:30572 [D loss: 0.250768, acc.: 58.59%] [G loss: 0.317361]\n",
      "epoch:32 step:30573 [D loss: 0.257355, acc.: 48.44%] [G loss: 0.287701]\n",
      "epoch:32 step:30574 [D loss: 0.246228, acc.: 49.22%] [G loss: 0.285535]\n",
      "epoch:32 step:30575 [D loss: 0.236746, acc.: 57.81%] [G loss: 0.283679]\n",
      "epoch:32 step:30576 [D loss: 0.238865, acc.: 56.25%] [G loss: 0.255308]\n",
      "epoch:32 step:30577 [D loss: 0.250940, acc.: 53.91%] [G loss: 0.313417]\n",
      "epoch:32 step:30578 [D loss: 0.235934, acc.: 60.16%] [G loss: 0.268808]\n",
      "epoch:32 step:30579 [D loss: 0.222559, acc.: 65.62%] [G loss: 0.283233]\n",
      "epoch:32 step:30580 [D loss: 0.238327, acc.: 55.47%] [G loss: 0.275193]\n",
      "epoch:32 step:30581 [D loss: 0.232269, acc.: 60.16%] [G loss: 0.326495]\n",
      "epoch:32 step:30582 [D loss: 0.255415, acc.: 50.78%] [G loss: 0.332685]\n",
      "epoch:32 step:30583 [D loss: 0.226094, acc.: 63.28%] [G loss: 0.304870]\n",
      "epoch:32 step:30584 [D loss: 0.245270, acc.: 58.59%] [G loss: 0.276315]\n",
      "epoch:32 step:30585 [D loss: 0.249329, acc.: 60.16%] [G loss: 0.306641]\n",
      "epoch:32 step:30586 [D loss: 0.224344, acc.: 64.06%] [G loss: 0.314195]\n",
      "epoch:32 step:30587 [D loss: 0.245390, acc.: 60.94%] [G loss: 0.291129]\n",
      "epoch:32 step:30588 [D loss: 0.234954, acc.: 61.72%] [G loss: 0.328278]\n",
      "epoch:32 step:30589 [D loss: 0.254883, acc.: 50.00%] [G loss: 0.303055]\n",
      "epoch:32 step:30590 [D loss: 0.233957, acc.: 62.50%] [G loss: 0.299283]\n",
      "epoch:32 step:30591 [D loss: 0.240092, acc.: 53.12%] [G loss: 0.289048]\n",
      "epoch:32 step:30592 [D loss: 0.230488, acc.: 61.72%] [G loss: 0.279259]\n",
      "epoch:32 step:30593 [D loss: 0.236645, acc.: 58.59%] [G loss: 0.315220]\n",
      "epoch:32 step:30594 [D loss: 0.235641, acc.: 60.94%] [G loss: 0.317116]\n",
      "epoch:32 step:30595 [D loss: 0.258183, acc.: 52.34%] [G loss: 0.284760]\n",
      "epoch:32 step:30596 [D loss: 0.249795, acc.: 53.91%] [G loss: 0.311467]\n",
      "epoch:32 step:30597 [D loss: 0.220432, acc.: 61.72%] [G loss: 0.303188]\n",
      "epoch:32 step:30598 [D loss: 0.244113, acc.: 57.03%] [G loss: 0.286735]\n",
      "epoch:32 step:30599 [D loss: 0.246963, acc.: 57.03%] [G loss: 0.301079]\n",
      "epoch:32 step:30600 [D loss: 0.245817, acc.: 57.03%] [G loss: 0.300598]\n",
      "epoch:32 step:30601 [D loss: 0.234092, acc.: 61.72%] [G loss: 0.329865]\n",
      "epoch:32 step:30602 [D loss: 0.237534, acc.: 57.03%] [G loss: 0.311935]\n",
      "epoch:32 step:30603 [D loss: 0.237984, acc.: 60.16%] [G loss: 0.302511]\n",
      "epoch:32 step:30604 [D loss: 0.229934, acc.: 65.62%] [G loss: 0.286595]\n",
      "epoch:32 step:30605 [D loss: 0.241360, acc.: 60.16%] [G loss: 0.284834]\n",
      "epoch:32 step:30606 [D loss: 0.238355, acc.: 56.25%] [G loss: 0.320313]\n",
      "epoch:32 step:30607 [D loss: 0.232352, acc.: 63.28%] [G loss: 0.302247]\n",
      "epoch:32 step:30608 [D loss: 0.241034, acc.: 58.59%] [G loss: 0.294319]\n",
      "epoch:32 step:30609 [D loss: 0.245611, acc.: 55.47%] [G loss: 0.315742]\n",
      "epoch:32 step:30610 [D loss: 0.234256, acc.: 60.94%] [G loss: 0.322656]\n",
      "epoch:32 step:30611 [D loss: 0.226062, acc.: 65.62%] [G loss: 0.294438]\n",
      "epoch:32 step:30612 [D loss: 0.248145, acc.: 60.16%] [G loss: 0.272738]\n",
      "epoch:32 step:30613 [D loss: 0.237510, acc.: 60.94%] [G loss: 0.317954]\n",
      "epoch:32 step:30614 [D loss: 0.255095, acc.: 55.47%] [G loss: 0.287590]\n",
      "epoch:32 step:30615 [D loss: 0.228841, acc.: 60.16%] [G loss: 0.319904]\n",
      "epoch:32 step:30616 [D loss: 0.243145, acc.: 58.59%] [G loss: 0.306006]\n",
      "epoch:32 step:30617 [D loss: 0.239769, acc.: 55.47%] [G loss: 0.306322]\n",
      "epoch:32 step:30618 [D loss: 0.228655, acc.: 63.28%] [G loss: 0.306378]\n",
      "epoch:32 step:30619 [D loss: 0.236191, acc.: 60.16%] [G loss: 0.275146]\n",
      "epoch:32 step:30620 [D loss: 0.244892, acc.: 59.38%] [G loss: 0.324065]\n",
      "epoch:32 step:30621 [D loss: 0.232116, acc.: 62.50%] [G loss: 0.325441]\n",
      "epoch:32 step:30622 [D loss: 0.224305, acc.: 67.97%] [G loss: 0.299739]\n",
      "epoch:32 step:30623 [D loss: 0.216700, acc.: 68.75%] [G loss: 0.305189]\n",
      "epoch:32 step:30624 [D loss: 0.255506, acc.: 51.56%] [G loss: 0.318388]\n",
      "epoch:32 step:30625 [D loss: 0.245015, acc.: 55.47%] [G loss: 0.297537]\n",
      "epoch:32 step:30626 [D loss: 0.247512, acc.: 52.34%] [G loss: 0.274222]\n",
      "epoch:32 step:30627 [D loss: 0.246225, acc.: 56.25%] [G loss: 0.284006]\n",
      "epoch:32 step:30628 [D loss: 0.237752, acc.: 61.72%] [G loss: 0.323820]\n",
      "epoch:32 step:30629 [D loss: 0.241274, acc.: 58.59%] [G loss: 0.296425]\n",
      "epoch:32 step:30630 [D loss: 0.239077, acc.: 60.94%] [G loss: 0.298957]\n",
      "epoch:32 step:30631 [D loss: 0.257057, acc.: 53.12%] [G loss: 0.288174]\n",
      "epoch:32 step:30632 [D loss: 0.235964, acc.: 59.38%] [G loss: 0.276508]\n",
      "epoch:32 step:30633 [D loss: 0.252731, acc.: 59.38%] [G loss: 0.329149]\n",
      "epoch:32 step:30634 [D loss: 0.255565, acc.: 53.91%] [G loss: 0.296907]\n",
      "epoch:32 step:30635 [D loss: 0.237565, acc.: 60.16%] [G loss: 0.344443]\n",
      "epoch:32 step:30636 [D loss: 0.231430, acc.: 59.38%] [G loss: 0.280073]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:32 step:30637 [D loss: 0.233239, acc.: 59.38%] [G loss: 0.331529]\n",
      "epoch:32 step:30638 [D loss: 0.243335, acc.: 56.25%] [G loss: 0.266954]\n",
      "epoch:32 step:30639 [D loss: 0.241105, acc.: 58.59%] [G loss: 0.290077]\n",
      "epoch:32 step:30640 [D loss: 0.241702, acc.: 53.91%] [G loss: 0.274226]\n",
      "epoch:32 step:30641 [D loss: 0.254064, acc.: 50.78%] [G loss: 0.302451]\n",
      "epoch:32 step:30642 [D loss: 0.244363, acc.: 57.03%] [G loss: 0.321676]\n",
      "epoch:32 step:30643 [D loss: 0.250079, acc.: 55.47%] [G loss: 0.303532]\n",
      "epoch:32 step:30644 [D loss: 0.240287, acc.: 58.59%] [G loss: 0.301181]\n",
      "epoch:32 step:30645 [D loss: 0.240044, acc.: 57.03%] [G loss: 0.267154]\n",
      "epoch:32 step:30646 [D loss: 0.223785, acc.: 64.84%] [G loss: 0.312275]\n",
      "epoch:32 step:30647 [D loss: 0.243064, acc.: 56.25%] [G loss: 0.290482]\n",
      "epoch:32 step:30648 [D loss: 0.240827, acc.: 57.81%] [G loss: 0.304020]\n",
      "epoch:32 step:30649 [D loss: 0.231530, acc.: 61.72%] [G loss: 0.298717]\n",
      "epoch:32 step:30650 [D loss: 0.247326, acc.: 57.81%] [G loss: 0.268949]\n",
      "epoch:32 step:30651 [D loss: 0.224297, acc.: 64.06%] [G loss: 0.303644]\n",
      "epoch:32 step:30652 [D loss: 0.248126, acc.: 56.25%] [G loss: 0.270173]\n",
      "epoch:32 step:30653 [D loss: 0.240146, acc.: 58.59%] [G loss: 0.281674]\n",
      "epoch:32 step:30654 [D loss: 0.236686, acc.: 58.59%] [G loss: 0.308753]\n",
      "epoch:32 step:30655 [D loss: 0.235976, acc.: 64.06%] [G loss: 0.341731]\n",
      "epoch:32 step:30656 [D loss: 0.246868, acc.: 51.56%] [G loss: 0.316943]\n",
      "epoch:32 step:30657 [D loss: 0.234425, acc.: 57.81%] [G loss: 0.296352]\n",
      "epoch:32 step:30658 [D loss: 0.212595, acc.: 65.62%] [G loss: 0.328821]\n",
      "epoch:32 step:30659 [D loss: 0.243832, acc.: 59.38%] [G loss: 0.276687]\n",
      "epoch:32 step:30660 [D loss: 0.231930, acc.: 64.06%] [G loss: 0.290254]\n",
      "epoch:32 step:30661 [D loss: 0.240265, acc.: 57.03%] [G loss: 0.279300]\n",
      "epoch:32 step:30662 [D loss: 0.243054, acc.: 56.25%] [G loss: 0.307270]\n",
      "epoch:32 step:30663 [D loss: 0.234433, acc.: 60.94%] [G loss: 0.320638]\n",
      "epoch:32 step:30664 [D loss: 0.245609, acc.: 57.03%] [G loss: 0.341506]\n",
      "epoch:32 step:30665 [D loss: 0.221912, acc.: 64.06%] [G loss: 0.330521]\n",
      "epoch:32 step:30666 [D loss: 0.231780, acc.: 63.28%] [G loss: 0.325493]\n",
      "epoch:32 step:30667 [D loss: 0.232881, acc.: 53.12%] [G loss: 0.294720]\n",
      "epoch:32 step:30668 [D loss: 0.235890, acc.: 60.16%] [G loss: 0.300465]\n",
      "epoch:32 step:30669 [D loss: 0.236678, acc.: 61.72%] [G loss: 0.276295]\n",
      "epoch:32 step:30670 [D loss: 0.230698, acc.: 62.50%] [G loss: 0.294034]\n",
      "epoch:32 step:30671 [D loss: 0.232686, acc.: 62.50%] [G loss: 0.316322]\n",
      "epoch:32 step:30672 [D loss: 0.241568, acc.: 58.59%] [G loss: 0.275438]\n",
      "epoch:32 step:30673 [D loss: 0.256358, acc.: 53.12%] [G loss: 0.333450]\n",
      "epoch:32 step:30674 [D loss: 0.244911, acc.: 58.59%] [G loss: 0.301492]\n",
      "epoch:32 step:30675 [D loss: 0.234398, acc.: 57.03%] [G loss: 0.328893]\n",
      "epoch:32 step:30676 [D loss: 0.229089, acc.: 60.16%] [G loss: 0.293052]\n",
      "epoch:32 step:30677 [D loss: 0.249087, acc.: 57.03%] [G loss: 0.317546]\n",
      "epoch:32 step:30678 [D loss: 0.249248, acc.: 52.34%] [G loss: 0.295434]\n",
      "epoch:32 step:30679 [D loss: 0.224603, acc.: 62.50%] [G loss: 0.307186]\n",
      "epoch:32 step:30680 [D loss: 0.233609, acc.: 62.50%] [G loss: 0.308816]\n",
      "epoch:32 step:30681 [D loss: 0.240082, acc.: 54.69%] [G loss: 0.294740]\n",
      "epoch:32 step:30682 [D loss: 0.230511, acc.: 64.06%] [G loss: 0.292387]\n",
      "epoch:32 step:30683 [D loss: 0.242351, acc.: 60.16%] [G loss: 0.304242]\n",
      "epoch:32 step:30684 [D loss: 0.229173, acc.: 61.72%] [G loss: 0.279445]\n",
      "epoch:32 step:30685 [D loss: 0.242339, acc.: 57.03%] [G loss: 0.325350]\n",
      "epoch:32 step:30686 [D loss: 0.207124, acc.: 70.31%] [G loss: 0.343345]\n",
      "epoch:32 step:30687 [D loss: 0.233549, acc.: 60.16%] [G loss: 0.291713]\n",
      "epoch:32 step:30688 [D loss: 0.261209, acc.: 54.69%] [G loss: 0.283913]\n",
      "epoch:32 step:30689 [D loss: 0.244829, acc.: 58.59%] [G loss: 0.301985]\n",
      "epoch:32 step:30690 [D loss: 0.243849, acc.: 54.69%] [G loss: 0.279895]\n",
      "epoch:32 step:30691 [D loss: 0.237850, acc.: 57.03%] [G loss: 0.297657]\n",
      "epoch:32 step:30692 [D loss: 0.254638, acc.: 50.78%] [G loss: 0.297606]\n",
      "epoch:32 step:30693 [D loss: 0.249486, acc.: 54.69%] [G loss: 0.287007]\n",
      "epoch:32 step:30694 [D loss: 0.229429, acc.: 62.50%] [G loss: 0.304815]\n",
      "epoch:32 step:30695 [D loss: 0.231323, acc.: 58.59%] [G loss: 0.301719]\n",
      "epoch:32 step:30696 [D loss: 0.238925, acc.: 61.72%] [G loss: 0.314155]\n",
      "epoch:32 step:30697 [D loss: 0.239146, acc.: 61.72%] [G loss: 0.282737]\n",
      "epoch:32 step:30698 [D loss: 0.229783, acc.: 64.06%] [G loss: 0.322708]\n",
      "epoch:32 step:30699 [D loss: 0.243072, acc.: 53.12%] [G loss: 0.277018]\n",
      "epoch:32 step:30700 [D loss: 0.228804, acc.: 66.41%] [G loss: 0.336447]\n",
      "epoch:32 step:30701 [D loss: 0.246422, acc.: 57.81%] [G loss: 0.290162]\n",
      "epoch:32 step:30702 [D loss: 0.238182, acc.: 60.94%] [G loss: 0.322945]\n",
      "epoch:32 step:30703 [D loss: 0.242447, acc.: 55.47%] [G loss: 0.311578]\n",
      "epoch:32 step:30704 [D loss: 0.246450, acc.: 57.03%] [G loss: 0.271403]\n",
      "epoch:32 step:30705 [D loss: 0.254487, acc.: 53.12%] [G loss: 0.301380]\n",
      "epoch:32 step:30706 [D loss: 0.226600, acc.: 60.94%] [G loss: 0.316678]\n",
      "epoch:32 step:30707 [D loss: 0.235732, acc.: 61.72%] [G loss: 0.321843]\n",
      "epoch:32 step:30708 [D loss: 0.260880, acc.: 57.03%] [G loss: 0.309708]\n",
      "epoch:32 step:30709 [D loss: 0.240540, acc.: 58.59%] [G loss: 0.287286]\n",
      "epoch:32 step:30710 [D loss: 0.252333, acc.: 53.12%] [G loss: 0.277528]\n",
      "epoch:32 step:30711 [D loss: 0.236561, acc.: 60.94%] [G loss: 0.272539]\n",
      "epoch:32 step:30712 [D loss: 0.252979, acc.: 55.47%] [G loss: 0.278185]\n",
      "epoch:32 step:30713 [D loss: 0.259464, acc.: 52.34%] [G loss: 0.296609]\n",
      "epoch:32 step:30714 [D loss: 0.232825, acc.: 60.94%] [G loss: 0.308201]\n",
      "epoch:32 step:30715 [D loss: 0.239984, acc.: 55.47%] [G loss: 0.305508]\n",
      "epoch:32 step:30716 [D loss: 0.250227, acc.: 53.12%] [G loss: 0.303058]\n",
      "epoch:32 step:30717 [D loss: 0.243240, acc.: 55.47%] [G loss: 0.301810]\n",
      "epoch:32 step:30718 [D loss: 0.233854, acc.: 59.38%] [G loss: 0.268046]\n",
      "epoch:32 step:30719 [D loss: 0.239933, acc.: 59.38%] [G loss: 0.313560]\n",
      "epoch:32 step:30720 [D loss: 0.230782, acc.: 64.06%] [G loss: 0.304905]\n",
      "epoch:32 step:30721 [D loss: 0.244538, acc.: 60.94%] [G loss: 0.295707]\n",
      "epoch:32 step:30722 [D loss: 0.237354, acc.: 57.81%] [G loss: 0.290892]\n",
      "epoch:32 step:30723 [D loss: 0.252992, acc.: 57.81%] [G loss: 0.276435]\n",
      "epoch:32 step:30724 [D loss: 0.245372, acc.: 53.91%] [G loss: 0.269611]\n",
      "epoch:32 step:30725 [D loss: 0.233510, acc.: 56.25%] [G loss: 0.288637]\n",
      "epoch:32 step:30726 [D loss: 0.233501, acc.: 59.38%] [G loss: 0.308241]\n",
      "epoch:32 step:30727 [D loss: 0.242886, acc.: 56.25%] [G loss: 0.326716]\n",
      "epoch:32 step:30728 [D loss: 0.227724, acc.: 61.72%] [G loss: 0.327849]\n",
      "epoch:32 step:30729 [D loss: 0.238860, acc.: 56.25%] [G loss: 0.316125]\n",
      "epoch:32 step:30730 [D loss: 0.234811, acc.: 56.25%] [G loss: 0.287634]\n",
      "epoch:32 step:30731 [D loss: 0.233940, acc.: 59.38%] [G loss: 0.284095]\n",
      "epoch:32 step:30732 [D loss: 0.230589, acc.: 62.50%] [G loss: 0.317409]\n",
      "epoch:32 step:30733 [D loss: 0.242183, acc.: 59.38%] [G loss: 0.298037]\n",
      "epoch:32 step:30734 [D loss: 0.237396, acc.: 60.94%] [G loss: 0.296244]\n",
      "epoch:32 step:30735 [D loss: 0.257203, acc.: 53.12%] [G loss: 0.256658]\n",
      "epoch:32 step:30736 [D loss: 0.245630, acc.: 56.25%] [G loss: 0.286891]\n",
      "epoch:32 step:30737 [D loss: 0.247859, acc.: 56.25%] [G loss: 0.302078]\n",
      "epoch:32 step:30738 [D loss: 0.236319, acc.: 60.16%] [G loss: 0.326267]\n",
      "epoch:32 step:30739 [D loss: 0.243876, acc.: 56.25%] [G loss: 0.291067]\n",
      "epoch:32 step:30740 [D loss: 0.243723, acc.: 58.59%] [G loss: 0.341198]\n",
      "epoch:32 step:30741 [D loss: 0.219709, acc.: 67.19%] [G loss: 0.308192]\n",
      "epoch:32 step:30742 [D loss: 0.252560, acc.: 56.25%] [G loss: 0.308086]\n",
      "epoch:32 step:30743 [D loss: 0.232947, acc.: 61.72%] [G loss: 0.282918]\n",
      "epoch:32 step:30744 [D loss: 0.237072, acc.: 59.38%] [G loss: 0.275754]\n",
      "epoch:32 step:30745 [D loss: 0.246521, acc.: 58.59%] [G loss: 0.274759]\n",
      "epoch:32 step:30746 [D loss: 0.256331, acc.: 49.22%] [G loss: 0.279418]\n",
      "epoch:32 step:30747 [D loss: 0.230567, acc.: 61.72%] [G loss: 0.282132]\n",
      "epoch:32 step:30748 [D loss: 0.249702, acc.: 57.81%] [G loss: 0.305977]\n",
      "epoch:32 step:30749 [D loss: 0.250449, acc.: 50.00%] [G loss: 0.284948]\n",
      "epoch:32 step:30750 [D loss: 0.242177, acc.: 55.47%] [G loss: 0.298161]\n",
      "epoch:32 step:30751 [D loss: 0.242559, acc.: 56.25%] [G loss: 0.284150]\n",
      "epoch:32 step:30752 [D loss: 0.247610, acc.: 55.47%] [G loss: 0.286092]\n",
      "epoch:32 step:30753 [D loss: 0.255798, acc.: 50.00%] [G loss: 0.276252]\n",
      "epoch:32 step:30754 [D loss: 0.243716, acc.: 60.94%] [G loss: 0.314559]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:32 step:30755 [D loss: 0.242034, acc.: 62.50%] [G loss: 0.324789]\n",
      "epoch:32 step:30756 [D loss: 0.246791, acc.: 60.16%] [G loss: 0.255144]\n",
      "epoch:32 step:30757 [D loss: 0.245096, acc.: 55.47%] [G loss: 0.297543]\n",
      "epoch:32 step:30758 [D loss: 0.246525, acc.: 59.38%] [G loss: 0.301003]\n",
      "epoch:32 step:30759 [D loss: 0.236042, acc.: 60.16%] [G loss: 0.313616]\n",
      "epoch:32 step:30760 [D loss: 0.244530, acc.: 57.03%] [G loss: 0.327289]\n",
      "epoch:32 step:30761 [D loss: 0.237494, acc.: 58.59%] [G loss: 0.302894]\n",
      "epoch:32 step:30762 [D loss: 0.237781, acc.: 58.59%] [G loss: 0.287454]\n",
      "epoch:32 step:30763 [D loss: 0.245828, acc.: 53.12%] [G loss: 0.279427]\n",
      "epoch:32 step:30764 [D loss: 0.238564, acc.: 59.38%] [G loss: 0.300301]\n",
      "epoch:32 step:30765 [D loss: 0.239022, acc.: 59.38%] [G loss: 0.295683]\n",
      "epoch:32 step:30766 [D loss: 0.249530, acc.: 47.66%] [G loss: 0.313649]\n",
      "epoch:32 step:30767 [D loss: 0.237658, acc.: 59.38%] [G loss: 0.317570]\n",
      "epoch:32 step:30768 [D loss: 0.236139, acc.: 58.59%] [G loss: 0.294742]\n",
      "epoch:32 step:30769 [D loss: 0.256844, acc.: 53.12%] [G loss: 0.286758]\n",
      "epoch:32 step:30770 [D loss: 0.243109, acc.: 58.59%] [G loss: 0.293101]\n",
      "epoch:32 step:30771 [D loss: 0.245685, acc.: 55.47%] [G loss: 0.301900]\n",
      "epoch:32 step:30772 [D loss: 0.251465, acc.: 55.47%] [G loss: 0.289645]\n",
      "epoch:32 step:30773 [D loss: 0.237985, acc.: 60.16%] [G loss: 0.349813]\n",
      "epoch:32 step:30774 [D loss: 0.245397, acc.: 54.69%] [G loss: 0.290925]\n",
      "epoch:32 step:30775 [D loss: 0.238539, acc.: 61.72%] [G loss: 0.302193]\n",
      "epoch:32 step:30776 [D loss: 0.245487, acc.: 57.03%] [G loss: 0.282240]\n",
      "epoch:32 step:30777 [D loss: 0.245766, acc.: 57.81%] [G loss: 0.302110]\n",
      "epoch:32 step:30778 [D loss: 0.235495, acc.: 59.38%] [G loss: 0.280512]\n",
      "epoch:32 step:30779 [D loss: 0.240434, acc.: 56.25%] [G loss: 0.296979]\n",
      "epoch:32 step:30780 [D loss: 0.234495, acc.: 60.16%] [G loss: 0.277684]\n",
      "epoch:32 step:30781 [D loss: 0.250077, acc.: 51.56%] [G loss: 0.280624]\n",
      "epoch:32 step:30782 [D loss: 0.241329, acc.: 60.94%] [G loss: 0.314825]\n",
      "epoch:32 step:30783 [D loss: 0.239568, acc.: 59.38%] [G loss: 0.289602]\n",
      "epoch:32 step:30784 [D loss: 0.242230, acc.: 57.03%] [G loss: 0.304143]\n",
      "epoch:32 step:30785 [D loss: 0.221952, acc.: 67.19%] [G loss: 0.315951]\n",
      "epoch:32 step:30786 [D loss: 0.239857, acc.: 61.72%] [G loss: 0.307713]\n",
      "epoch:32 step:30787 [D loss: 0.237809, acc.: 60.94%] [G loss: 0.281172]\n",
      "epoch:32 step:30788 [D loss: 0.230614, acc.: 65.62%] [G loss: 0.292526]\n",
      "epoch:32 step:30789 [D loss: 0.239549, acc.: 54.69%] [G loss: 0.290354]\n",
      "epoch:32 step:30790 [D loss: 0.220171, acc.: 63.28%] [G loss: 0.296346]\n",
      "epoch:32 step:30791 [D loss: 0.251652, acc.: 54.69%] [G loss: 0.281407]\n",
      "epoch:32 step:30792 [D loss: 0.221749, acc.: 60.94%] [G loss: 0.303150]\n",
      "epoch:32 step:30793 [D loss: 0.227872, acc.: 64.06%] [G loss: 0.291585]\n",
      "epoch:32 step:30794 [D loss: 0.238595, acc.: 60.16%] [G loss: 0.289283]\n",
      "epoch:32 step:30795 [D loss: 0.240927, acc.: 59.38%] [G loss: 0.258065]\n",
      "epoch:32 step:30796 [D loss: 0.246790, acc.: 55.47%] [G loss: 0.327522]\n",
      "epoch:32 step:30797 [D loss: 0.229774, acc.: 58.59%] [G loss: 0.288807]\n",
      "epoch:32 step:30798 [D loss: 0.242269, acc.: 52.34%] [G loss: 0.320377]\n",
      "epoch:32 step:30799 [D loss: 0.245279, acc.: 60.16%] [G loss: 0.291846]\n",
      "epoch:32 step:30800 [D loss: 0.248684, acc.: 53.12%] [G loss: 0.303241]\n",
      "epoch:32 step:30801 [D loss: 0.229502, acc.: 62.50%] [G loss: 0.298411]\n",
      "epoch:32 step:30802 [D loss: 0.224699, acc.: 61.72%] [G loss: 0.334580]\n",
      "epoch:32 step:30803 [D loss: 0.243604, acc.: 59.38%] [G loss: 0.316360]\n",
      "epoch:32 step:30804 [D loss: 0.246791, acc.: 57.81%] [G loss: 0.311307]\n",
      "epoch:32 step:30805 [D loss: 0.236437, acc.: 60.16%] [G loss: 0.324179]\n",
      "epoch:32 step:30806 [D loss: 0.249291, acc.: 56.25%] [G loss: 0.291364]\n",
      "epoch:32 step:30807 [D loss: 0.244064, acc.: 56.25%] [G loss: 0.312165]\n",
      "epoch:32 step:30808 [D loss: 0.240434, acc.: 57.81%] [G loss: 0.317015]\n",
      "epoch:32 step:30809 [D loss: 0.237806, acc.: 60.16%] [G loss: 0.299242]\n",
      "epoch:32 step:30810 [D loss: 0.245652, acc.: 56.25%] [G loss: 0.334259]\n",
      "epoch:32 step:30811 [D loss: 0.235911, acc.: 58.59%] [G loss: 0.288820]\n",
      "epoch:32 step:30812 [D loss: 0.248024, acc.: 56.25%] [G loss: 0.308632]\n",
      "epoch:32 step:30813 [D loss: 0.253284, acc.: 53.12%] [G loss: 0.293846]\n",
      "epoch:32 step:30814 [D loss: 0.230313, acc.: 60.94%] [G loss: 0.302084]\n",
      "epoch:32 step:30815 [D loss: 0.233886, acc.: 58.59%] [G loss: 0.296516]\n",
      "epoch:32 step:30816 [D loss: 0.249841, acc.: 48.44%] [G loss: 0.287405]\n",
      "epoch:32 step:30817 [D loss: 0.246716, acc.: 53.91%] [G loss: 0.284370]\n",
      "epoch:32 step:30818 [D loss: 0.240572, acc.: 60.94%] [G loss: 0.312949]\n",
      "epoch:32 step:30819 [D loss: 0.259477, acc.: 53.12%] [G loss: 0.276069]\n",
      "epoch:32 step:30820 [D loss: 0.249399, acc.: 57.81%] [G loss: 0.286946]\n",
      "epoch:32 step:30821 [D loss: 0.252707, acc.: 51.56%] [G loss: 0.297679]\n",
      "epoch:32 step:30822 [D loss: 0.243435, acc.: 50.78%] [G loss: 0.268512]\n",
      "epoch:32 step:30823 [D loss: 0.254075, acc.: 52.34%] [G loss: 0.297765]\n",
      "epoch:32 step:30824 [D loss: 0.232361, acc.: 54.69%] [G loss: 0.302711]\n",
      "epoch:32 step:30825 [D loss: 0.245577, acc.: 57.03%] [G loss: 0.289716]\n",
      "epoch:32 step:30826 [D loss: 0.249295, acc.: 57.03%] [G loss: 0.310377]\n",
      "epoch:32 step:30827 [D loss: 0.228450, acc.: 61.72%] [G loss: 0.280185]\n",
      "epoch:32 step:30828 [D loss: 0.247203, acc.: 53.91%] [G loss: 0.306057]\n",
      "epoch:32 step:30829 [D loss: 0.241608, acc.: 57.81%] [G loss: 0.311060]\n",
      "epoch:32 step:30830 [D loss: 0.258203, acc.: 57.81%] [G loss: 0.288755]\n",
      "epoch:32 step:30831 [D loss: 0.249496, acc.: 54.69%] [G loss: 0.276233]\n",
      "epoch:32 step:30832 [D loss: 0.270835, acc.: 50.78%] [G loss: 0.293060]\n",
      "epoch:32 step:30833 [D loss: 0.237458, acc.: 58.59%] [G loss: 0.281326]\n",
      "epoch:32 step:30834 [D loss: 0.247108, acc.: 54.69%] [G loss: 0.293803]\n",
      "epoch:32 step:30835 [D loss: 0.250824, acc.: 53.12%] [G loss: 0.286885]\n",
      "epoch:32 step:30836 [D loss: 0.231688, acc.: 62.50%] [G loss: 0.286602]\n",
      "epoch:32 step:30837 [D loss: 0.241709, acc.: 57.03%] [G loss: 0.298874]\n",
      "epoch:32 step:30838 [D loss: 0.264058, acc.: 51.56%] [G loss: 0.302992]\n",
      "epoch:32 step:30839 [D loss: 0.244597, acc.: 57.03%] [G loss: 0.294924]\n",
      "epoch:32 step:30840 [D loss: 0.231224, acc.: 64.84%] [G loss: 0.298180]\n",
      "epoch:32 step:30841 [D loss: 0.241882, acc.: 60.94%] [G loss: 0.309398]\n",
      "epoch:32 step:30842 [D loss: 0.243165, acc.: 54.69%] [G loss: 0.299842]\n",
      "epoch:32 step:30843 [D loss: 0.235612, acc.: 58.59%] [G loss: 0.286808]\n",
      "epoch:32 step:30844 [D loss: 0.250586, acc.: 53.91%] [G loss: 0.305177]\n",
      "epoch:32 step:30845 [D loss: 0.237911, acc.: 61.72%] [G loss: 0.329289]\n",
      "epoch:32 step:30846 [D loss: 0.233752, acc.: 59.38%] [G loss: 0.318826]\n",
      "epoch:32 step:30847 [D loss: 0.225324, acc.: 62.50%] [G loss: 0.310597]\n",
      "epoch:32 step:30848 [D loss: 0.227224, acc.: 60.94%] [G loss: 0.297313]\n",
      "epoch:32 step:30849 [D loss: 0.237736, acc.: 57.03%] [G loss: 0.279412]\n",
      "epoch:32 step:30850 [D loss: 0.224995, acc.: 63.28%] [G loss: 0.298076]\n",
      "epoch:32 step:30851 [D loss: 0.225224, acc.: 63.28%] [G loss: 0.304803]\n",
      "epoch:32 step:30852 [D loss: 0.235235, acc.: 57.81%] [G loss: 0.307613]\n",
      "epoch:32 step:30853 [D loss: 0.226090, acc.: 60.94%] [G loss: 0.276786]\n",
      "epoch:32 step:30854 [D loss: 0.254702, acc.: 54.69%] [G loss: 0.280261]\n",
      "epoch:32 step:30855 [D loss: 0.230473, acc.: 64.06%] [G loss: 0.314858]\n",
      "epoch:32 step:30856 [D loss: 0.259624, acc.: 45.31%] [G loss: 0.300246]\n",
      "epoch:32 step:30857 [D loss: 0.237827, acc.: 60.94%] [G loss: 0.302212]\n",
      "epoch:32 step:30858 [D loss: 0.229895, acc.: 67.19%] [G loss: 0.300065]\n",
      "epoch:32 step:30859 [D loss: 0.228767, acc.: 60.16%] [G loss: 0.315292]\n",
      "epoch:32 step:30860 [D loss: 0.238616, acc.: 56.25%] [G loss: 0.312387]\n",
      "epoch:32 step:30861 [D loss: 0.235182, acc.: 59.38%] [G loss: 0.295815]\n",
      "epoch:32 step:30862 [D loss: 0.233386, acc.: 58.59%] [G loss: 0.286508]\n",
      "epoch:32 step:30863 [D loss: 0.254598, acc.: 54.69%] [G loss: 0.276927]\n",
      "epoch:32 step:30864 [D loss: 0.237752, acc.: 60.16%] [G loss: 0.303474]\n",
      "epoch:32 step:30865 [D loss: 0.256245, acc.: 50.00%] [G loss: 0.293235]\n",
      "epoch:32 step:30866 [D loss: 0.225629, acc.: 60.94%] [G loss: 0.296077]\n",
      "epoch:32 step:30867 [D loss: 0.243920, acc.: 49.22%] [G loss: 0.296502]\n",
      "epoch:32 step:30868 [D loss: 0.247084, acc.: 55.47%] [G loss: 0.270646]\n",
      "epoch:32 step:30869 [D loss: 0.237778, acc.: 63.28%] [G loss: 0.307196]\n",
      "epoch:32 step:30870 [D loss: 0.239897, acc.: 54.69%] [G loss: 0.302925]\n",
      "epoch:32 step:30871 [D loss: 0.228381, acc.: 60.16%] [G loss: 0.325333]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:32 step:30872 [D loss: 0.240204, acc.: 56.25%] [G loss: 0.309024]\n",
      "epoch:32 step:30873 [D loss: 0.246760, acc.: 55.47%] [G loss: 0.300312]\n",
      "epoch:32 step:30874 [D loss: 0.263563, acc.: 53.91%] [G loss: 0.276160]\n",
      "epoch:32 step:30875 [D loss: 0.256718, acc.: 53.91%] [G loss: 0.309382]\n",
      "epoch:32 step:30876 [D loss: 0.242552, acc.: 56.25%] [G loss: 0.289196]\n",
      "epoch:32 step:30877 [D loss: 0.245910, acc.: 56.25%] [G loss: 0.297674]\n",
      "epoch:32 step:30878 [D loss: 0.246550, acc.: 57.03%] [G loss: 0.315237]\n",
      "epoch:32 step:30879 [D loss: 0.232080, acc.: 64.06%] [G loss: 0.286619]\n",
      "epoch:32 step:30880 [D loss: 0.253624, acc.: 50.78%] [G loss: 0.276676]\n",
      "epoch:32 step:30881 [D loss: 0.240243, acc.: 58.59%] [G loss: 0.292256]\n",
      "epoch:32 step:30882 [D loss: 0.224420, acc.: 65.62%] [G loss: 0.301705]\n",
      "epoch:32 step:30883 [D loss: 0.239803, acc.: 58.59%] [G loss: 0.299480]\n",
      "epoch:32 step:30884 [D loss: 0.216026, acc.: 67.97%] [G loss: 0.281441]\n",
      "epoch:32 step:30885 [D loss: 0.241645, acc.: 60.16%] [G loss: 0.276769]\n",
      "epoch:32 step:30886 [D loss: 0.255253, acc.: 54.69%] [G loss: 0.289255]\n",
      "epoch:32 step:30887 [D loss: 0.241300, acc.: 57.81%] [G loss: 0.318187]\n",
      "epoch:32 step:30888 [D loss: 0.235415, acc.: 59.38%] [G loss: 0.308082]\n",
      "epoch:32 step:30889 [D loss: 0.249174, acc.: 49.22%] [G loss: 0.309129]\n",
      "epoch:32 step:30890 [D loss: 0.230119, acc.: 60.94%] [G loss: 0.300803]\n",
      "epoch:32 step:30891 [D loss: 0.248648, acc.: 50.00%] [G loss: 0.269181]\n",
      "epoch:32 step:30892 [D loss: 0.250324, acc.: 57.03%] [G loss: 0.325335]\n",
      "epoch:32 step:30893 [D loss: 0.251657, acc.: 49.22%] [G loss: 0.298994]\n",
      "epoch:32 step:30894 [D loss: 0.240965, acc.: 60.16%] [G loss: 0.282122]\n",
      "epoch:32 step:30895 [D loss: 0.241923, acc.: 53.12%] [G loss: 0.256490]\n",
      "epoch:32 step:30896 [D loss: 0.249269, acc.: 55.47%] [G loss: 0.313964]\n",
      "epoch:32 step:30897 [D loss: 0.245959, acc.: 53.91%] [G loss: 0.299742]\n",
      "epoch:32 step:30898 [D loss: 0.246606, acc.: 50.78%] [G loss: 0.281532]\n",
      "epoch:32 step:30899 [D loss: 0.237286, acc.: 58.59%] [G loss: 0.304500]\n",
      "epoch:32 step:30900 [D loss: 0.249923, acc.: 55.47%] [G loss: 0.291863]\n",
      "epoch:32 step:30901 [D loss: 0.243444, acc.: 56.25%] [G loss: 0.279926]\n",
      "epoch:32 step:30902 [D loss: 0.254788, acc.: 50.00%] [G loss: 0.277812]\n",
      "epoch:32 step:30903 [D loss: 0.249676, acc.: 57.03%] [G loss: 0.290994]\n",
      "epoch:32 step:30904 [D loss: 0.235703, acc.: 57.03%] [G loss: 0.310099]\n",
      "epoch:32 step:30905 [D loss: 0.250150, acc.: 53.12%] [G loss: 0.311128]\n",
      "epoch:32 step:30906 [D loss: 0.225701, acc.: 64.84%] [G loss: 0.319033]\n",
      "epoch:32 step:30907 [D loss: 0.227869, acc.: 60.94%] [G loss: 0.307441]\n",
      "epoch:32 step:30908 [D loss: 0.238163, acc.: 59.38%] [G loss: 0.326117]\n",
      "epoch:32 step:30909 [D loss: 0.240068, acc.: 53.12%] [G loss: 0.286665]\n",
      "epoch:32 step:30910 [D loss: 0.226271, acc.: 65.62%] [G loss: 0.324292]\n",
      "epoch:32 step:30911 [D loss: 0.238240, acc.: 62.50%] [G loss: 0.281008]\n",
      "epoch:32 step:30912 [D loss: 0.223975, acc.: 61.72%] [G loss: 0.298033]\n",
      "epoch:32 step:30913 [D loss: 0.238713, acc.: 56.25%] [G loss: 0.276865]\n",
      "epoch:32 step:30914 [D loss: 0.231472, acc.: 60.16%] [G loss: 0.296893]\n",
      "epoch:32 step:30915 [D loss: 0.255257, acc.: 50.00%] [G loss: 0.284811]\n",
      "epoch:32 step:30916 [D loss: 0.230723, acc.: 62.50%] [G loss: 0.298853]\n",
      "epoch:32 step:30917 [D loss: 0.263727, acc.: 49.22%] [G loss: 0.306775]\n",
      "epoch:32 step:30918 [D loss: 0.257701, acc.: 50.00%] [G loss: 0.283226]\n",
      "epoch:32 step:30919 [D loss: 0.225356, acc.: 60.94%] [G loss: 0.283296]\n",
      "epoch:32 step:30920 [D loss: 0.246700, acc.: 57.81%] [G loss: 0.292720]\n",
      "epoch:32 step:30921 [D loss: 0.242671, acc.: 58.59%] [G loss: 0.283971]\n",
      "epoch:33 step:30922 [D loss: 0.238007, acc.: 60.16%] [G loss: 0.283104]\n",
      "epoch:33 step:30923 [D loss: 0.234956, acc.: 65.62%] [G loss: 0.305810]\n",
      "epoch:33 step:30924 [D loss: 0.244900, acc.: 53.12%] [G loss: 0.288425]\n",
      "epoch:33 step:30925 [D loss: 0.237275, acc.: 60.16%] [G loss: 0.282868]\n",
      "epoch:33 step:30926 [D loss: 0.233512, acc.: 54.69%] [G loss: 0.327492]\n",
      "epoch:33 step:30927 [D loss: 0.260653, acc.: 47.66%] [G loss: 0.269610]\n",
      "epoch:33 step:30928 [D loss: 0.257145, acc.: 48.44%] [G loss: 0.293870]\n",
      "epoch:33 step:30929 [D loss: 0.248877, acc.: 55.47%] [G loss: 0.332251]\n",
      "epoch:33 step:30930 [D loss: 0.232787, acc.: 60.16%] [G loss: 0.289811]\n",
      "epoch:33 step:30931 [D loss: 0.243661, acc.: 58.59%] [G loss: 0.333828]\n",
      "epoch:33 step:30932 [D loss: 0.244743, acc.: 53.12%] [G loss: 0.295476]\n",
      "epoch:33 step:30933 [D loss: 0.224199, acc.: 62.50%] [G loss: 0.310530]\n",
      "epoch:33 step:30934 [D loss: 0.211957, acc.: 70.31%] [G loss: 0.304694]\n",
      "epoch:33 step:30935 [D loss: 0.236552, acc.: 55.47%] [G loss: 0.309698]\n",
      "epoch:33 step:30936 [D loss: 0.237458, acc.: 63.28%] [G loss: 0.320256]\n",
      "epoch:33 step:30937 [D loss: 0.254716, acc.: 51.56%] [G loss: 0.293892]\n",
      "epoch:33 step:30938 [D loss: 0.245230, acc.: 60.94%] [G loss: 0.307956]\n",
      "epoch:33 step:30939 [D loss: 0.262700, acc.: 51.56%] [G loss: 0.277227]\n",
      "epoch:33 step:30940 [D loss: 0.242834, acc.: 58.59%] [G loss: 0.335381]\n",
      "epoch:33 step:30941 [D loss: 0.227496, acc.: 61.72%] [G loss: 0.307805]\n",
      "epoch:33 step:30942 [D loss: 0.228809, acc.: 61.72%] [G loss: 0.308947]\n",
      "epoch:33 step:30943 [D loss: 0.239639, acc.: 60.94%] [G loss: 0.304764]\n",
      "epoch:33 step:30944 [D loss: 0.229282, acc.: 56.25%] [G loss: 0.319547]\n",
      "epoch:33 step:30945 [D loss: 0.225714, acc.: 61.72%] [G loss: 0.312537]\n",
      "epoch:33 step:30946 [D loss: 0.256329, acc.: 52.34%] [G loss: 0.307390]\n",
      "epoch:33 step:30947 [D loss: 0.246888, acc.: 57.81%] [G loss: 0.297539]\n",
      "epoch:33 step:30948 [D loss: 0.260777, acc.: 53.91%] [G loss: 0.278716]\n",
      "epoch:33 step:30949 [D loss: 0.223024, acc.: 64.06%] [G loss: 0.312827]\n",
      "epoch:33 step:30950 [D loss: 0.233540, acc.: 62.50%] [G loss: 0.291530]\n",
      "epoch:33 step:30951 [D loss: 0.234424, acc.: 57.81%] [G loss: 0.308822]\n",
      "epoch:33 step:30952 [D loss: 0.248951, acc.: 57.03%] [G loss: 0.292515]\n",
      "epoch:33 step:30953 [D loss: 0.248266, acc.: 57.81%] [G loss: 0.303830]\n",
      "epoch:33 step:30954 [D loss: 0.236184, acc.: 58.59%] [G loss: 0.283041]\n",
      "epoch:33 step:30955 [D loss: 0.220999, acc.: 64.06%] [G loss: 0.293149]\n",
      "epoch:33 step:30956 [D loss: 0.241688, acc.: 54.69%] [G loss: 0.320049]\n",
      "epoch:33 step:30957 [D loss: 0.245815, acc.: 61.72%] [G loss: 0.299192]\n",
      "epoch:33 step:30958 [D loss: 0.239963, acc.: 55.47%] [G loss: 0.302942]\n",
      "epoch:33 step:30959 [D loss: 0.247330, acc.: 53.91%] [G loss: 0.292513]\n",
      "epoch:33 step:30960 [D loss: 0.251961, acc.: 53.12%] [G loss: 0.297582]\n",
      "epoch:33 step:30961 [D loss: 0.245521, acc.: 58.59%] [G loss: 0.304987]\n",
      "epoch:33 step:30962 [D loss: 0.227160, acc.: 63.28%] [G loss: 0.314509]\n",
      "epoch:33 step:30963 [D loss: 0.255966, acc.: 48.44%] [G loss: 0.306311]\n",
      "epoch:33 step:30964 [D loss: 0.240526, acc.: 57.81%] [G loss: 0.309992]\n",
      "epoch:33 step:30965 [D loss: 0.237078, acc.: 59.38%] [G loss: 0.314780]\n",
      "epoch:33 step:30966 [D loss: 0.249678, acc.: 60.94%] [G loss: 0.303006]\n",
      "epoch:33 step:30967 [D loss: 0.257859, acc.: 50.78%] [G loss: 0.304425]\n",
      "epoch:33 step:30968 [D loss: 0.247449, acc.: 50.00%] [G loss: 0.319047]\n",
      "epoch:33 step:30969 [D loss: 0.230674, acc.: 57.03%] [G loss: 0.296048]\n",
      "epoch:33 step:30970 [D loss: 0.253851, acc.: 51.56%] [G loss: 0.303678]\n",
      "epoch:33 step:30971 [D loss: 0.237685, acc.: 57.03%] [G loss: 0.300873]\n",
      "epoch:33 step:30972 [D loss: 0.243520, acc.: 56.25%] [G loss: 0.329773]\n",
      "epoch:33 step:30973 [D loss: 0.254265, acc.: 52.34%] [G loss: 0.313081]\n",
      "epoch:33 step:30974 [D loss: 0.242322, acc.: 55.47%] [G loss: 0.303555]\n",
      "epoch:33 step:30975 [D loss: 0.233508, acc.: 59.38%] [G loss: 0.282857]\n",
      "epoch:33 step:30976 [D loss: 0.240470, acc.: 59.38%] [G loss: 0.281997]\n",
      "epoch:33 step:30977 [D loss: 0.250388, acc.: 57.03%] [G loss: 0.311555]\n",
      "epoch:33 step:30978 [D loss: 0.240882, acc.: 58.59%] [G loss: 0.326356]\n",
      "epoch:33 step:30979 [D loss: 0.233913, acc.: 64.06%] [G loss: 0.287994]\n",
      "epoch:33 step:30980 [D loss: 0.212571, acc.: 65.62%] [G loss: 0.315112]\n",
      "epoch:33 step:30981 [D loss: 0.226385, acc.: 64.84%] [G loss: 0.292305]\n",
      "epoch:33 step:30982 [D loss: 0.224679, acc.: 61.72%] [G loss: 0.294640]\n",
      "epoch:33 step:30983 [D loss: 0.256651, acc.: 50.00%] [G loss: 0.296876]\n",
      "epoch:33 step:30984 [D loss: 0.254936, acc.: 52.34%] [G loss: 0.285935]\n",
      "epoch:33 step:30985 [D loss: 0.256805, acc.: 49.22%] [G loss: 0.316419]\n",
      "epoch:33 step:30986 [D loss: 0.238592, acc.: 57.03%] [G loss: 0.305004]\n",
      "epoch:33 step:30987 [D loss: 0.242459, acc.: 56.25%] [G loss: 0.289225]\n",
      "epoch:33 step:30988 [D loss: 0.241673, acc.: 57.81%] [G loss: 0.304180]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:33 step:30989 [D loss: 0.241128, acc.: 60.16%] [G loss: 0.303627]\n",
      "epoch:33 step:30990 [D loss: 0.222564, acc.: 63.28%] [G loss: 0.320897]\n",
      "epoch:33 step:30991 [D loss: 0.241314, acc.: 60.94%] [G loss: 0.291112]\n",
      "epoch:33 step:30992 [D loss: 0.225292, acc.: 63.28%] [G loss: 0.277436]\n",
      "epoch:33 step:30993 [D loss: 0.235012, acc.: 57.81%] [G loss: 0.300463]\n",
      "epoch:33 step:30994 [D loss: 0.247896, acc.: 53.12%] [G loss: 0.290798]\n",
      "epoch:33 step:30995 [D loss: 0.250390, acc.: 57.81%] [G loss: 0.284934]\n",
      "epoch:33 step:30996 [D loss: 0.251343, acc.: 53.91%] [G loss: 0.307191]\n",
      "epoch:33 step:30997 [D loss: 0.235286, acc.: 60.16%] [G loss: 0.267592]\n",
      "epoch:33 step:30998 [D loss: 0.236952, acc.: 61.72%] [G loss: 0.322968]\n",
      "epoch:33 step:30999 [D loss: 0.242373, acc.: 57.03%] [G loss: 0.320345]\n",
      "epoch:33 step:31000 [D loss: 0.237625, acc.: 58.59%] [G loss: 0.326917]\n",
      "epoch:33 step:31001 [D loss: 0.241435, acc.: 57.03%] [G loss: 0.300506]\n",
      "epoch:33 step:31002 [D loss: 0.268213, acc.: 48.44%] [G loss: 0.292797]\n",
      "epoch:33 step:31003 [D loss: 0.226937, acc.: 63.28%] [G loss: 0.295103]\n",
      "epoch:33 step:31004 [D loss: 0.251157, acc.: 53.91%] [G loss: 0.272227]\n",
      "epoch:33 step:31005 [D loss: 0.250339, acc.: 50.78%] [G loss: 0.285426]\n",
      "epoch:33 step:31006 [D loss: 0.238903, acc.: 58.59%] [G loss: 0.255024]\n",
      "epoch:33 step:31007 [D loss: 0.228034, acc.: 63.28%] [G loss: 0.284522]\n",
      "epoch:33 step:31008 [D loss: 0.239004, acc.: 60.16%] [G loss: 0.283194]\n",
      "epoch:33 step:31009 [D loss: 0.234422, acc.: 60.94%] [G loss: 0.306333]\n",
      "epoch:33 step:31010 [D loss: 0.241926, acc.: 56.25%] [G loss: 0.305334]\n",
      "epoch:33 step:31011 [D loss: 0.233942, acc.: 56.25%] [G loss: 0.301531]\n",
      "epoch:33 step:31012 [D loss: 0.246143, acc.: 57.81%] [G loss: 0.302521]\n",
      "epoch:33 step:31013 [D loss: 0.237121, acc.: 58.59%] [G loss: 0.283482]\n",
      "epoch:33 step:31014 [D loss: 0.227564, acc.: 64.84%] [G loss: 0.327516]\n",
      "epoch:33 step:31015 [D loss: 0.231140, acc.: 60.16%] [G loss: 0.280739]\n",
      "epoch:33 step:31016 [D loss: 0.234342, acc.: 55.47%] [G loss: 0.310353]\n",
      "epoch:33 step:31017 [D loss: 0.232749, acc.: 63.28%] [G loss: 0.286448]\n",
      "epoch:33 step:31018 [D loss: 0.247094, acc.: 60.16%] [G loss: 0.287649]\n",
      "epoch:33 step:31019 [D loss: 0.231433, acc.: 60.16%] [G loss: 0.280299]\n",
      "epoch:33 step:31020 [D loss: 0.230681, acc.: 57.81%] [G loss: 0.303772]\n",
      "epoch:33 step:31021 [D loss: 0.222245, acc.: 64.84%] [G loss: 0.267593]\n",
      "epoch:33 step:31022 [D loss: 0.239764, acc.: 58.59%] [G loss: 0.292661]\n",
      "epoch:33 step:31023 [D loss: 0.231511, acc.: 54.69%] [G loss: 0.332197]\n",
      "epoch:33 step:31024 [D loss: 0.233066, acc.: 60.94%] [G loss: 0.299028]\n",
      "epoch:33 step:31025 [D loss: 0.252590, acc.: 54.69%] [G loss: 0.280869]\n",
      "epoch:33 step:31026 [D loss: 0.236731, acc.: 58.59%] [G loss: 0.288261]\n",
      "epoch:33 step:31027 [D loss: 0.234523, acc.: 61.72%] [G loss: 0.272872]\n",
      "epoch:33 step:31028 [D loss: 0.231434, acc.: 64.06%] [G loss: 0.261985]\n",
      "epoch:33 step:31029 [D loss: 0.264892, acc.: 50.00%] [G loss: 0.292098]\n",
      "epoch:33 step:31030 [D loss: 0.224059, acc.: 66.41%] [G loss: 0.299629]\n",
      "epoch:33 step:31031 [D loss: 0.242884, acc.: 58.59%] [G loss: 0.296448]\n",
      "epoch:33 step:31032 [D loss: 0.255426, acc.: 50.00%] [G loss: 0.303918]\n",
      "epoch:33 step:31033 [D loss: 0.234527, acc.: 58.59%] [G loss: 0.292294]\n",
      "epoch:33 step:31034 [D loss: 0.223013, acc.: 60.94%] [G loss: 0.293818]\n",
      "epoch:33 step:31035 [D loss: 0.237756, acc.: 57.03%] [G loss: 0.277704]\n",
      "epoch:33 step:31036 [D loss: 0.247859, acc.: 53.91%] [G loss: 0.312333]\n",
      "epoch:33 step:31037 [D loss: 0.233062, acc.: 64.84%] [G loss: 0.309689]\n",
      "epoch:33 step:31038 [D loss: 0.250392, acc.: 51.56%] [G loss: 0.272914]\n",
      "epoch:33 step:31039 [D loss: 0.244570, acc.: 53.12%] [G loss: 0.289747]\n",
      "epoch:33 step:31040 [D loss: 0.245374, acc.: 54.69%] [G loss: 0.292558]\n",
      "epoch:33 step:31041 [D loss: 0.258179, acc.: 51.56%] [G loss: 0.308689]\n",
      "epoch:33 step:31042 [D loss: 0.239516, acc.: 57.81%] [G loss: 0.284488]\n",
      "epoch:33 step:31043 [D loss: 0.231216, acc.: 64.06%] [G loss: 0.289567]\n",
      "epoch:33 step:31044 [D loss: 0.232022, acc.: 59.38%] [G loss: 0.310003]\n",
      "epoch:33 step:31045 [D loss: 0.217249, acc.: 67.19%] [G loss: 0.299168]\n",
      "epoch:33 step:31046 [D loss: 0.239498, acc.: 62.50%] [G loss: 0.294014]\n",
      "epoch:33 step:31047 [D loss: 0.233042, acc.: 60.94%] [G loss: 0.302160]\n",
      "epoch:33 step:31048 [D loss: 0.244212, acc.: 56.25%] [G loss: 0.291041]\n",
      "epoch:33 step:31049 [D loss: 0.241959, acc.: 60.94%] [G loss: 0.319793]\n",
      "epoch:33 step:31050 [D loss: 0.218000, acc.: 66.41%] [G loss: 0.355383]\n",
      "epoch:33 step:31051 [D loss: 0.226546, acc.: 64.06%] [G loss: 0.300242]\n",
      "epoch:33 step:31052 [D loss: 0.232877, acc.: 58.59%] [G loss: 0.301424]\n",
      "epoch:33 step:31053 [D loss: 0.242986, acc.: 59.38%] [G loss: 0.312449]\n",
      "epoch:33 step:31054 [D loss: 0.226703, acc.: 61.72%] [G loss: 0.312991]\n",
      "epoch:33 step:31055 [D loss: 0.235735, acc.: 58.59%] [G loss: 0.301375]\n",
      "epoch:33 step:31056 [D loss: 0.236750, acc.: 57.81%] [G loss: 0.298702]\n",
      "epoch:33 step:31057 [D loss: 0.243990, acc.: 60.16%] [G loss: 0.308823]\n",
      "epoch:33 step:31058 [D loss: 0.242392, acc.: 57.81%] [G loss: 0.298662]\n",
      "epoch:33 step:31059 [D loss: 0.237076, acc.: 57.81%] [G loss: 0.312111]\n",
      "epoch:33 step:31060 [D loss: 0.257700, acc.: 50.00%] [G loss: 0.294596]\n",
      "epoch:33 step:31061 [D loss: 0.240418, acc.: 60.16%] [G loss: 0.303602]\n",
      "epoch:33 step:31062 [D loss: 0.226432, acc.: 67.19%] [G loss: 0.288108]\n",
      "epoch:33 step:31063 [D loss: 0.222024, acc.: 65.62%] [G loss: 0.319485]\n",
      "epoch:33 step:31064 [D loss: 0.268345, acc.: 46.88%] [G loss: 0.315490]\n",
      "epoch:33 step:31065 [D loss: 0.238366, acc.: 56.25%] [G loss: 0.267109]\n",
      "epoch:33 step:31066 [D loss: 0.226766, acc.: 63.28%] [G loss: 0.288258]\n",
      "epoch:33 step:31067 [D loss: 0.243887, acc.: 57.81%] [G loss: 0.282576]\n",
      "epoch:33 step:31068 [D loss: 0.225292, acc.: 63.28%] [G loss: 0.312278]\n",
      "epoch:33 step:31069 [D loss: 0.247281, acc.: 56.25%] [G loss: 0.277739]\n",
      "epoch:33 step:31070 [D loss: 0.241257, acc.: 59.38%] [G loss: 0.273880]\n",
      "epoch:33 step:31071 [D loss: 0.239634, acc.: 58.59%] [G loss: 0.279141]\n",
      "epoch:33 step:31072 [D loss: 0.231377, acc.: 59.38%] [G loss: 0.314698]\n",
      "epoch:33 step:31073 [D loss: 0.228181, acc.: 60.94%] [G loss: 0.298436]\n",
      "epoch:33 step:31074 [D loss: 0.255770, acc.: 51.56%] [G loss: 0.289485]\n",
      "epoch:33 step:31075 [D loss: 0.235360, acc.: 56.25%] [G loss: 0.292030]\n",
      "epoch:33 step:31076 [D loss: 0.247656, acc.: 51.56%] [G loss: 0.302081]\n",
      "epoch:33 step:31077 [D loss: 0.243780, acc.: 53.12%] [G loss: 0.294010]\n",
      "epoch:33 step:31078 [D loss: 0.246086, acc.: 55.47%] [G loss: 0.279720]\n",
      "epoch:33 step:31079 [D loss: 0.234313, acc.: 61.72%] [G loss: 0.277298]\n",
      "epoch:33 step:31080 [D loss: 0.246721, acc.: 53.12%] [G loss: 0.299482]\n",
      "epoch:33 step:31081 [D loss: 0.228122, acc.: 63.28%] [G loss: 0.276399]\n",
      "epoch:33 step:31082 [D loss: 0.231863, acc.: 59.38%] [G loss: 0.298911]\n",
      "epoch:33 step:31083 [D loss: 0.244822, acc.: 58.59%] [G loss: 0.313134]\n",
      "epoch:33 step:31084 [D loss: 0.247123, acc.: 53.12%] [G loss: 0.320558]\n",
      "epoch:33 step:31085 [D loss: 0.220813, acc.: 67.97%] [G loss: 0.320489]\n",
      "epoch:33 step:31086 [D loss: 0.249873, acc.: 48.44%] [G loss: 0.297146]\n",
      "epoch:33 step:31087 [D loss: 0.267370, acc.: 48.44%] [G loss: 0.279089]\n",
      "epoch:33 step:31088 [D loss: 0.230418, acc.: 62.50%] [G loss: 0.297188]\n",
      "epoch:33 step:31089 [D loss: 0.229323, acc.: 61.72%] [G loss: 0.303531]\n",
      "epoch:33 step:31090 [D loss: 0.239957, acc.: 63.28%] [G loss: 0.288115]\n",
      "epoch:33 step:31091 [D loss: 0.220421, acc.: 63.28%] [G loss: 0.322264]\n",
      "epoch:33 step:31092 [D loss: 0.233393, acc.: 60.94%] [G loss: 0.318433]\n",
      "epoch:33 step:31093 [D loss: 0.221308, acc.: 64.84%] [G loss: 0.307945]\n",
      "epoch:33 step:31094 [D loss: 0.236376, acc.: 61.72%] [G loss: 0.293258]\n",
      "epoch:33 step:31095 [D loss: 0.239529, acc.: 56.25%] [G loss: 0.316418]\n",
      "epoch:33 step:31096 [D loss: 0.244833, acc.: 58.59%] [G loss: 0.291189]\n",
      "epoch:33 step:31097 [D loss: 0.231003, acc.: 63.28%] [G loss: 0.299285]\n",
      "epoch:33 step:31098 [D loss: 0.232332, acc.: 59.38%] [G loss: 0.306592]\n",
      "epoch:33 step:31099 [D loss: 0.238128, acc.: 54.69%] [G loss: 0.287970]\n",
      "epoch:33 step:31100 [D loss: 0.242268, acc.: 55.47%] [G loss: 0.299696]\n",
      "epoch:33 step:31101 [D loss: 0.248717, acc.: 54.69%] [G loss: 0.334534]\n",
      "epoch:33 step:31102 [D loss: 0.227452, acc.: 60.94%] [G loss: 0.321923]\n",
      "epoch:33 step:31103 [D loss: 0.239680, acc.: 56.25%] [G loss: 0.287615]\n",
      "epoch:33 step:31104 [D loss: 0.247178, acc.: 55.47%] [G loss: 0.283935]\n",
      "epoch:33 step:31105 [D loss: 0.240357, acc.: 55.47%] [G loss: 0.317933]\n",
      "epoch:33 step:31106 [D loss: 0.222122, acc.: 65.62%] [G loss: 0.305335]\n",
      "epoch:33 step:31107 [D loss: 0.240545, acc.: 55.47%] [G loss: 0.304930]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:33 step:31108 [D loss: 0.224497, acc.: 65.62%] [G loss: 0.269280]\n",
      "epoch:33 step:31109 [D loss: 0.242509, acc.: 58.59%] [G loss: 0.283573]\n",
      "epoch:33 step:31110 [D loss: 0.249478, acc.: 52.34%] [G loss: 0.290622]\n",
      "epoch:33 step:31111 [D loss: 0.258910, acc.: 52.34%] [G loss: 0.300834]\n",
      "epoch:33 step:31112 [D loss: 0.228408, acc.: 61.72%] [G loss: 0.298898]\n",
      "epoch:33 step:31113 [D loss: 0.241776, acc.: 64.06%] [G loss: 0.275855]\n",
      "epoch:33 step:31114 [D loss: 0.222036, acc.: 58.59%] [G loss: 0.305583]\n",
      "epoch:33 step:31115 [D loss: 0.248214, acc.: 50.78%] [G loss: 0.304741]\n",
      "epoch:33 step:31116 [D loss: 0.251194, acc.: 50.78%] [G loss: 0.319322]\n",
      "epoch:33 step:31117 [D loss: 0.241744, acc.: 53.91%] [G loss: 0.294523]\n",
      "epoch:33 step:31118 [D loss: 0.212131, acc.: 76.56%] [G loss: 0.281763]\n",
      "epoch:33 step:31119 [D loss: 0.250991, acc.: 52.34%] [G loss: 0.296711]\n",
      "epoch:33 step:31120 [D loss: 0.229668, acc.: 62.50%] [G loss: 0.319049]\n",
      "epoch:33 step:31121 [D loss: 0.249616, acc.: 53.12%] [G loss: 0.273518]\n",
      "epoch:33 step:31122 [D loss: 0.246837, acc.: 55.47%] [G loss: 0.311244]\n",
      "epoch:33 step:31123 [D loss: 0.215174, acc.: 65.62%] [G loss: 0.322338]\n",
      "epoch:33 step:31124 [D loss: 0.247477, acc.: 58.59%] [G loss: 0.264880]\n",
      "epoch:33 step:31125 [D loss: 0.222140, acc.: 58.59%] [G loss: 0.292404]\n",
      "epoch:33 step:31126 [D loss: 0.243689, acc.: 58.59%] [G loss: 0.293646]\n",
      "epoch:33 step:31127 [D loss: 0.247578, acc.: 56.25%] [G loss: 0.297774]\n",
      "epoch:33 step:31128 [D loss: 0.233195, acc.: 59.38%] [G loss: 0.345760]\n",
      "epoch:33 step:31129 [D loss: 0.236580, acc.: 60.16%] [G loss: 0.314337]\n",
      "epoch:33 step:31130 [D loss: 0.250868, acc.: 57.03%] [G loss: 0.289016]\n",
      "epoch:33 step:31131 [D loss: 0.219958, acc.: 65.62%] [G loss: 0.281549]\n",
      "epoch:33 step:31132 [D loss: 0.243086, acc.: 52.34%] [G loss: 0.315871]\n",
      "epoch:33 step:31133 [D loss: 0.243458, acc.: 58.59%] [G loss: 0.306816]\n",
      "epoch:33 step:31134 [D loss: 0.245533, acc.: 53.91%] [G loss: 0.291250]\n",
      "epoch:33 step:31135 [D loss: 0.244889, acc.: 57.03%] [G loss: 0.313320]\n",
      "epoch:33 step:31136 [D loss: 0.236869, acc.: 57.81%] [G loss: 0.301672]\n",
      "epoch:33 step:31137 [D loss: 0.236272, acc.: 58.59%] [G loss: 0.320711]\n",
      "epoch:33 step:31138 [D loss: 0.224794, acc.: 65.62%] [G loss: 0.326893]\n",
      "epoch:33 step:31139 [D loss: 0.238642, acc.: 55.47%] [G loss: 0.288401]\n",
      "epoch:33 step:31140 [D loss: 0.231228, acc.: 58.59%] [G loss: 0.314081]\n",
      "epoch:33 step:31141 [D loss: 0.231843, acc.: 64.06%] [G loss: 0.318498]\n",
      "epoch:33 step:31142 [D loss: 0.245896, acc.: 57.81%] [G loss: 0.278036]\n",
      "epoch:33 step:31143 [D loss: 0.256288, acc.: 50.00%] [G loss: 0.307162]\n",
      "epoch:33 step:31144 [D loss: 0.234388, acc.: 55.47%] [G loss: 0.302934]\n",
      "epoch:33 step:31145 [D loss: 0.244343, acc.: 60.16%] [G loss: 0.277176]\n",
      "epoch:33 step:31146 [D loss: 0.241851, acc.: 58.59%] [G loss: 0.295821]\n",
      "epoch:33 step:31147 [D loss: 0.230811, acc.: 57.81%] [G loss: 0.298453]\n",
      "epoch:33 step:31148 [D loss: 0.236441, acc.: 60.94%] [G loss: 0.316542]\n",
      "epoch:33 step:31149 [D loss: 0.236093, acc.: 54.69%] [G loss: 0.325897]\n",
      "epoch:33 step:31150 [D loss: 0.220641, acc.: 64.84%] [G loss: 0.320904]\n",
      "epoch:33 step:31151 [D loss: 0.247893, acc.: 56.25%] [G loss: 0.301523]\n",
      "epoch:33 step:31152 [D loss: 0.244630, acc.: 59.38%] [G loss: 0.292432]\n",
      "epoch:33 step:31153 [D loss: 0.253140, acc.: 53.12%] [G loss: 0.295461]\n",
      "epoch:33 step:31154 [D loss: 0.231185, acc.: 59.38%] [G loss: 0.281390]\n",
      "epoch:33 step:31155 [D loss: 0.241311, acc.: 57.81%] [G loss: 0.294967]\n",
      "epoch:33 step:31156 [D loss: 0.241607, acc.: 57.81%] [G loss: 0.293597]\n",
      "epoch:33 step:31157 [D loss: 0.229089, acc.: 63.28%] [G loss: 0.274287]\n",
      "epoch:33 step:31158 [D loss: 0.254583, acc.: 56.25%] [G loss: 0.286924]\n",
      "epoch:33 step:31159 [D loss: 0.236660, acc.: 62.50%] [G loss: 0.292106]\n",
      "epoch:33 step:31160 [D loss: 0.242952, acc.: 56.25%] [G loss: 0.300079]\n",
      "epoch:33 step:31161 [D loss: 0.244976, acc.: 56.25%] [G loss: 0.293960]\n",
      "epoch:33 step:31162 [D loss: 0.241316, acc.: 50.00%] [G loss: 0.270367]\n",
      "epoch:33 step:31163 [D loss: 0.253280, acc.: 53.12%] [G loss: 0.290160]\n",
      "epoch:33 step:31164 [D loss: 0.250584, acc.: 53.12%] [G loss: 0.286251]\n",
      "epoch:33 step:31165 [D loss: 0.243423, acc.: 56.25%] [G loss: 0.286680]\n",
      "epoch:33 step:31166 [D loss: 0.239671, acc.: 57.03%] [G loss: 0.306817]\n",
      "epoch:33 step:31167 [D loss: 0.249957, acc.: 53.91%] [G loss: 0.263132]\n",
      "epoch:33 step:31168 [D loss: 0.233297, acc.: 58.59%] [G loss: 0.300260]\n",
      "epoch:33 step:31169 [D loss: 0.234199, acc.: 56.25%] [G loss: 0.316512]\n",
      "epoch:33 step:31170 [D loss: 0.251258, acc.: 56.25%] [G loss: 0.309132]\n",
      "epoch:33 step:31171 [D loss: 0.230559, acc.: 58.59%] [G loss: 0.324507]\n",
      "epoch:33 step:31172 [D loss: 0.259238, acc.: 57.81%] [G loss: 0.284435]\n",
      "epoch:33 step:31173 [D loss: 0.227530, acc.: 66.41%] [G loss: 0.304299]\n",
      "epoch:33 step:31174 [D loss: 0.231284, acc.: 58.59%] [G loss: 0.310823]\n",
      "epoch:33 step:31175 [D loss: 0.235038, acc.: 61.72%] [G loss: 0.320537]\n",
      "epoch:33 step:31176 [D loss: 0.215750, acc.: 62.50%] [G loss: 0.307891]\n",
      "epoch:33 step:31177 [D loss: 0.237902, acc.: 59.38%] [G loss: 0.296521]\n",
      "epoch:33 step:31178 [D loss: 0.242751, acc.: 60.16%] [G loss: 0.304173]\n",
      "epoch:33 step:31179 [D loss: 0.242671, acc.: 58.59%] [G loss: 0.311954]\n",
      "epoch:33 step:31180 [D loss: 0.247487, acc.: 50.00%] [G loss: 0.291026]\n",
      "epoch:33 step:31181 [D loss: 0.234422, acc.: 60.94%] [G loss: 0.337225]\n",
      "epoch:33 step:31182 [D loss: 0.235442, acc.: 51.56%] [G loss: 0.296704]\n",
      "epoch:33 step:31183 [D loss: 0.260519, acc.: 49.22%] [G loss: 0.287206]\n",
      "epoch:33 step:31184 [D loss: 0.245509, acc.: 51.56%] [G loss: 0.278128]\n",
      "epoch:33 step:31185 [D loss: 0.229775, acc.: 63.28%] [G loss: 0.301035]\n",
      "epoch:33 step:31186 [D loss: 0.245742, acc.: 58.59%] [G loss: 0.306261]\n",
      "epoch:33 step:31187 [D loss: 0.220339, acc.: 67.97%] [G loss: 0.295874]\n",
      "epoch:33 step:31188 [D loss: 0.244050, acc.: 56.25%] [G loss: 0.299435]\n",
      "epoch:33 step:31189 [D loss: 0.237896, acc.: 57.81%] [G loss: 0.286961]\n",
      "epoch:33 step:31190 [D loss: 0.235625, acc.: 62.50%] [G loss: 0.323952]\n",
      "epoch:33 step:31191 [D loss: 0.246556, acc.: 58.59%] [G loss: 0.310988]\n",
      "epoch:33 step:31192 [D loss: 0.244885, acc.: 56.25%] [G loss: 0.297885]\n",
      "epoch:33 step:31193 [D loss: 0.231139, acc.: 60.94%] [G loss: 0.332945]\n",
      "epoch:33 step:31194 [D loss: 0.243650, acc.: 58.59%] [G loss: 0.275857]\n",
      "epoch:33 step:31195 [D loss: 0.241922, acc.: 58.59%] [G loss: 0.312984]\n",
      "epoch:33 step:31196 [D loss: 0.238810, acc.: 59.38%] [G loss: 0.299939]\n",
      "epoch:33 step:31197 [D loss: 0.248389, acc.: 54.69%] [G loss: 0.307721]\n",
      "epoch:33 step:31198 [D loss: 0.243983, acc.: 59.38%] [G loss: 0.290481]\n",
      "epoch:33 step:31199 [D loss: 0.252915, acc.: 50.78%] [G loss: 0.309666]\n",
      "epoch:33 step:31200 [D loss: 0.242000, acc.: 57.03%] [G loss: 0.271063]\n",
      "epoch:33 step:31201 [D loss: 0.249249, acc.: 57.03%] [G loss: 0.286052]\n",
      "epoch:33 step:31202 [D loss: 0.256282, acc.: 55.47%] [G loss: 0.303032]\n",
      "epoch:33 step:31203 [D loss: 0.238559, acc.: 59.38%] [G loss: 0.288681]\n",
      "epoch:33 step:31204 [D loss: 0.229669, acc.: 63.28%] [G loss: 0.298750]\n",
      "epoch:33 step:31205 [D loss: 0.258271, acc.: 51.56%] [G loss: 0.289788]\n",
      "epoch:33 step:31206 [D loss: 0.222601, acc.: 63.28%] [G loss: 0.303809]\n",
      "epoch:33 step:31207 [D loss: 0.248162, acc.: 53.91%] [G loss: 0.295599]\n",
      "epoch:33 step:31208 [D loss: 0.248309, acc.: 53.12%] [G loss: 0.277362]\n",
      "epoch:33 step:31209 [D loss: 0.224666, acc.: 67.19%] [G loss: 0.313129]\n",
      "epoch:33 step:31210 [D loss: 0.249466, acc.: 52.34%] [G loss: 0.293729]\n",
      "epoch:33 step:31211 [D loss: 0.224157, acc.: 60.16%] [G loss: 0.292414]\n",
      "epoch:33 step:31212 [D loss: 0.243471, acc.: 53.91%] [G loss: 0.295102]\n",
      "epoch:33 step:31213 [D loss: 0.244429, acc.: 56.25%] [G loss: 0.291797]\n",
      "epoch:33 step:31214 [D loss: 0.237258, acc.: 58.59%] [G loss: 0.316261]\n",
      "epoch:33 step:31215 [D loss: 0.230552, acc.: 53.91%] [G loss: 0.295246]\n",
      "epoch:33 step:31216 [D loss: 0.249619, acc.: 55.47%] [G loss: 0.307443]\n",
      "epoch:33 step:31217 [D loss: 0.227176, acc.: 59.38%] [G loss: 0.282451]\n",
      "epoch:33 step:31218 [D loss: 0.233421, acc.: 55.47%] [G loss: 0.296095]\n",
      "epoch:33 step:31219 [D loss: 0.255990, acc.: 54.69%] [G loss: 0.326084]\n",
      "epoch:33 step:31220 [D loss: 0.243309, acc.: 56.25%] [G loss: 0.304219]\n",
      "epoch:33 step:31221 [D loss: 0.241287, acc.: 57.03%] [G loss: 0.301442]\n",
      "epoch:33 step:31222 [D loss: 0.249196, acc.: 55.47%] [G loss: 0.309748]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:33 step:31223 [D loss: 0.247537, acc.: 59.38%] [G loss: 0.293372]\n",
      "epoch:33 step:31224 [D loss: 0.242644, acc.: 60.16%] [G loss: 0.304899]\n",
      "epoch:33 step:31225 [D loss: 0.228881, acc.: 60.94%] [G loss: 0.285518]\n",
      "epoch:33 step:31226 [D loss: 0.231231, acc.: 58.59%] [G loss: 0.315419]\n",
      "epoch:33 step:31227 [D loss: 0.243371, acc.: 54.69%] [G loss: 0.291209]\n",
      "epoch:33 step:31228 [D loss: 0.222828, acc.: 64.84%] [G loss: 0.318964]\n",
      "epoch:33 step:31229 [D loss: 0.222516, acc.: 73.44%] [G loss: 0.319229]\n",
      "epoch:33 step:31230 [D loss: 0.234228, acc.: 61.72%] [G loss: 0.303083]\n",
      "epoch:33 step:31231 [D loss: 0.248065, acc.: 53.12%] [G loss: 0.313106]\n",
      "epoch:33 step:31232 [D loss: 0.243292, acc.: 57.03%] [G loss: 0.308263]\n",
      "epoch:33 step:31233 [D loss: 0.245961, acc.: 57.03%] [G loss: 0.281545]\n",
      "epoch:33 step:31234 [D loss: 0.247550, acc.: 53.12%] [G loss: 0.313407]\n",
      "epoch:33 step:31235 [D loss: 0.240986, acc.: 57.81%] [G loss: 0.303736]\n",
      "epoch:33 step:31236 [D loss: 0.233468, acc.: 62.50%] [G loss: 0.317605]\n",
      "epoch:33 step:31237 [D loss: 0.254436, acc.: 53.12%] [G loss: 0.295624]\n",
      "epoch:33 step:31238 [D loss: 0.232054, acc.: 59.38%] [G loss: 0.300388]\n",
      "epoch:33 step:31239 [D loss: 0.242492, acc.: 59.38%] [G loss: 0.332929]\n",
      "epoch:33 step:31240 [D loss: 0.235373, acc.: 57.81%] [G loss: 0.313041]\n",
      "epoch:33 step:31241 [D loss: 0.249166, acc.: 57.81%] [G loss: 0.334362]\n",
      "epoch:33 step:31242 [D loss: 0.234741, acc.: 61.72%] [G loss: 0.308534]\n",
      "epoch:33 step:31243 [D loss: 0.239005, acc.: 59.38%] [G loss: 0.297807]\n",
      "epoch:33 step:31244 [D loss: 0.245245, acc.: 60.94%] [G loss: 0.308597]\n",
      "epoch:33 step:31245 [D loss: 0.225860, acc.: 67.97%] [G loss: 0.309986]\n",
      "epoch:33 step:31246 [D loss: 0.252997, acc.: 55.47%] [G loss: 0.294871]\n",
      "epoch:33 step:31247 [D loss: 0.240883, acc.: 59.38%] [G loss: 0.273082]\n",
      "epoch:33 step:31248 [D loss: 0.225041, acc.: 60.94%] [G loss: 0.311015]\n",
      "epoch:33 step:31249 [D loss: 0.239397, acc.: 57.81%] [G loss: 0.295522]\n",
      "epoch:33 step:31250 [D loss: 0.233427, acc.: 60.94%] [G loss: 0.287239]\n",
      "epoch:33 step:31251 [D loss: 0.226007, acc.: 65.62%] [G loss: 0.303963]\n",
      "epoch:33 step:31252 [D loss: 0.224288, acc.: 67.97%] [G loss: 0.316709]\n",
      "epoch:33 step:31253 [D loss: 0.236947, acc.: 60.16%] [G loss: 0.298798]\n",
      "epoch:33 step:31254 [D loss: 0.245369, acc.: 57.03%] [G loss: 0.315096]\n",
      "epoch:33 step:31255 [D loss: 0.238915, acc.: 60.16%] [G loss: 0.316853]\n",
      "epoch:33 step:31256 [D loss: 0.237681, acc.: 56.25%] [G loss: 0.291806]\n",
      "epoch:33 step:31257 [D loss: 0.235428, acc.: 57.03%] [G loss: 0.303863]\n",
      "epoch:33 step:31258 [D loss: 0.249659, acc.: 53.12%] [G loss: 0.296949]\n",
      "epoch:33 step:31259 [D loss: 0.220702, acc.: 67.19%] [G loss: 0.301454]\n",
      "epoch:33 step:31260 [D loss: 0.216931, acc.: 65.62%] [G loss: 0.318630]\n",
      "epoch:33 step:31261 [D loss: 0.267089, acc.: 48.44%] [G loss: 0.262431]\n",
      "epoch:33 step:31262 [D loss: 0.233176, acc.: 56.25%] [G loss: 0.297268]\n",
      "epoch:33 step:31263 [D loss: 0.237015, acc.: 56.25%] [G loss: 0.304175]\n",
      "epoch:33 step:31264 [D loss: 0.249111, acc.: 53.91%] [G loss: 0.284677]\n",
      "epoch:33 step:31265 [D loss: 0.233616, acc.: 56.25%] [G loss: 0.288702]\n",
      "epoch:33 step:31266 [D loss: 0.224184, acc.: 65.62%] [G loss: 0.319889]\n",
      "epoch:33 step:31267 [D loss: 0.253532, acc.: 46.88%] [G loss: 0.294468]\n",
      "epoch:33 step:31268 [D loss: 0.257727, acc.: 53.91%] [G loss: 0.314088]\n",
      "epoch:33 step:31269 [D loss: 0.240904, acc.: 51.56%] [G loss: 0.306402]\n",
      "epoch:33 step:31270 [D loss: 0.247052, acc.: 62.50%] [G loss: 0.310111]\n",
      "epoch:33 step:31271 [D loss: 0.260925, acc.: 51.56%] [G loss: 0.312225]\n",
      "epoch:33 step:31272 [D loss: 0.237360, acc.: 60.16%] [G loss: 0.268390]\n",
      "epoch:33 step:31273 [D loss: 0.242560, acc.: 59.38%] [G loss: 0.295890]\n",
      "epoch:33 step:31274 [D loss: 0.242869, acc.: 57.03%] [G loss: 0.326095]\n",
      "epoch:33 step:31275 [D loss: 0.227831, acc.: 64.06%] [G loss: 0.309345]\n",
      "epoch:33 step:31276 [D loss: 0.244002, acc.: 57.81%] [G loss: 0.313348]\n",
      "epoch:33 step:31277 [D loss: 0.241394, acc.: 57.81%] [G loss: 0.327064]\n",
      "epoch:33 step:31278 [D loss: 0.234748, acc.: 61.72%] [G loss: 0.288720]\n",
      "epoch:33 step:31279 [D loss: 0.223451, acc.: 64.84%] [G loss: 0.283310]\n",
      "epoch:33 step:31280 [D loss: 0.246808, acc.: 56.25%] [G loss: 0.269814]\n",
      "epoch:33 step:31281 [D loss: 0.239432, acc.: 62.50%] [G loss: 0.316594]\n",
      "epoch:33 step:31282 [D loss: 0.246701, acc.: 51.56%] [G loss: 0.301488]\n",
      "epoch:33 step:31283 [D loss: 0.235896, acc.: 60.94%] [G loss: 0.314429]\n",
      "epoch:33 step:31284 [D loss: 0.226848, acc.: 63.28%] [G loss: 0.304816]\n",
      "epoch:33 step:31285 [D loss: 0.222547, acc.: 69.53%] [G loss: 0.301923]\n",
      "epoch:33 step:31286 [D loss: 0.249223, acc.: 51.56%] [G loss: 0.278760]\n",
      "epoch:33 step:31287 [D loss: 0.234829, acc.: 57.81%] [G loss: 0.317227]\n",
      "epoch:33 step:31288 [D loss: 0.228544, acc.: 63.28%] [G loss: 0.305470]\n",
      "epoch:33 step:31289 [D loss: 0.236111, acc.: 57.03%] [G loss: 0.282535]\n",
      "epoch:33 step:31290 [D loss: 0.249714, acc.: 60.94%] [G loss: 0.275224]\n",
      "epoch:33 step:31291 [D loss: 0.234695, acc.: 63.28%] [G loss: 0.282867]\n",
      "epoch:33 step:31292 [D loss: 0.246097, acc.: 55.47%] [G loss: 0.299797]\n",
      "epoch:33 step:31293 [D loss: 0.245733, acc.: 53.12%] [G loss: 0.296587]\n",
      "epoch:33 step:31294 [D loss: 0.242191, acc.: 53.91%] [G loss: 0.327554]\n",
      "epoch:33 step:31295 [D loss: 0.243144, acc.: 59.38%] [G loss: 0.275329]\n",
      "epoch:33 step:31296 [D loss: 0.237064, acc.: 57.81%] [G loss: 0.319341]\n",
      "epoch:33 step:31297 [D loss: 0.251567, acc.: 53.91%] [G loss: 0.289062]\n",
      "epoch:33 step:31298 [D loss: 0.252619, acc.: 56.25%] [G loss: 0.303872]\n",
      "epoch:33 step:31299 [D loss: 0.249355, acc.: 57.03%] [G loss: 0.273239]\n",
      "epoch:33 step:31300 [D loss: 0.248610, acc.: 52.34%] [G loss: 0.309414]\n",
      "epoch:33 step:31301 [D loss: 0.236899, acc.: 58.59%] [G loss: 0.320385]\n",
      "epoch:33 step:31302 [D loss: 0.235531, acc.: 60.94%] [G loss: 0.298262]\n",
      "epoch:33 step:31303 [D loss: 0.254795, acc.: 47.66%] [G loss: 0.296889]\n",
      "epoch:33 step:31304 [D loss: 0.240517, acc.: 57.81%] [G loss: 0.281139]\n",
      "epoch:33 step:31305 [D loss: 0.233349, acc.: 56.25%] [G loss: 0.297718]\n",
      "epoch:33 step:31306 [D loss: 0.233685, acc.: 60.94%] [G loss: 0.317435]\n",
      "epoch:33 step:31307 [D loss: 0.238651, acc.: 57.03%] [G loss: 0.305113]\n",
      "epoch:33 step:31308 [D loss: 0.241136, acc.: 56.25%] [G loss: 0.289367]\n",
      "epoch:33 step:31309 [D loss: 0.237589, acc.: 55.47%] [G loss: 0.268113]\n",
      "epoch:33 step:31310 [D loss: 0.246043, acc.: 52.34%] [G loss: 0.292134]\n",
      "epoch:33 step:31311 [D loss: 0.243039, acc.: 55.47%] [G loss: 0.302636]\n",
      "epoch:33 step:31312 [D loss: 0.220587, acc.: 64.84%] [G loss: 0.295288]\n",
      "epoch:33 step:31313 [D loss: 0.255423, acc.: 51.56%] [G loss: 0.279232]\n",
      "epoch:33 step:31314 [D loss: 0.236593, acc.: 63.28%] [G loss: 0.295419]\n",
      "epoch:33 step:31315 [D loss: 0.247031, acc.: 60.94%] [G loss: 0.276635]\n",
      "epoch:33 step:31316 [D loss: 0.225154, acc.: 65.62%] [G loss: 0.333380]\n",
      "epoch:33 step:31317 [D loss: 0.230582, acc.: 62.50%] [G loss: 0.256884]\n",
      "epoch:33 step:31318 [D loss: 0.261928, acc.: 46.09%] [G loss: 0.304216]\n",
      "epoch:33 step:31319 [D loss: 0.215772, acc.: 71.09%] [G loss: 0.321664]\n",
      "epoch:33 step:31320 [D loss: 0.237603, acc.: 60.16%] [G loss: 0.287958]\n",
      "epoch:33 step:31321 [D loss: 0.236921, acc.: 58.59%] [G loss: 0.283837]\n",
      "epoch:33 step:31322 [D loss: 0.236061, acc.: 59.38%] [G loss: 0.274691]\n",
      "epoch:33 step:31323 [D loss: 0.243721, acc.: 55.47%] [G loss: 0.303915]\n",
      "epoch:33 step:31324 [D loss: 0.244053, acc.: 52.34%] [G loss: 0.300736]\n",
      "epoch:33 step:31325 [D loss: 0.233292, acc.: 61.72%] [G loss: 0.304537]\n",
      "epoch:33 step:31326 [D loss: 0.246433, acc.: 50.78%] [G loss: 0.302943]\n",
      "epoch:33 step:31327 [D loss: 0.237381, acc.: 58.59%] [G loss: 0.300606]\n",
      "epoch:33 step:31328 [D loss: 0.236094, acc.: 57.81%] [G loss: 0.313493]\n",
      "epoch:33 step:31329 [D loss: 0.243439, acc.: 53.12%] [G loss: 0.275133]\n",
      "epoch:33 step:31330 [D loss: 0.236297, acc.: 61.72%] [G loss: 0.329622]\n",
      "epoch:33 step:31331 [D loss: 0.264741, acc.: 51.56%] [G loss: 0.300059]\n",
      "epoch:33 step:31332 [D loss: 0.233044, acc.: 62.50%] [G loss: 0.311062]\n",
      "epoch:33 step:31333 [D loss: 0.256725, acc.: 53.12%] [G loss: 0.292807]\n",
      "epoch:33 step:31334 [D loss: 0.249344, acc.: 54.69%] [G loss: 0.310765]\n",
      "epoch:33 step:31335 [D loss: 0.242694, acc.: 59.38%] [G loss: 0.275946]\n",
      "epoch:33 step:31336 [D loss: 0.241015, acc.: 56.25%] [G loss: 0.313989]\n",
      "epoch:33 step:31337 [D loss: 0.219119, acc.: 62.50%] [G loss: 0.324867]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:33 step:31338 [D loss: 0.242966, acc.: 53.91%] [G loss: 0.321123]\n",
      "epoch:33 step:31339 [D loss: 0.222585, acc.: 67.19%] [G loss: 0.273136]\n",
      "epoch:33 step:31340 [D loss: 0.239852, acc.: 58.59%] [G loss: 0.317932]\n",
      "epoch:33 step:31341 [D loss: 0.246736, acc.: 56.25%] [G loss: 0.289667]\n",
      "epoch:33 step:31342 [D loss: 0.253907, acc.: 50.78%] [G loss: 0.272400]\n",
      "epoch:33 step:31343 [D loss: 0.225055, acc.: 60.16%] [G loss: 0.302023]\n",
      "epoch:33 step:31344 [D loss: 0.224910, acc.: 60.94%] [G loss: 0.305091]\n",
      "epoch:33 step:31345 [D loss: 0.222564, acc.: 63.28%] [G loss: 0.303765]\n",
      "epoch:33 step:31346 [D loss: 0.229500, acc.: 58.59%] [G loss: 0.295099]\n",
      "epoch:33 step:31347 [D loss: 0.239746, acc.: 54.69%] [G loss: 0.293943]\n",
      "epoch:33 step:31348 [D loss: 0.242314, acc.: 62.50%] [G loss: 0.279368]\n",
      "epoch:33 step:31349 [D loss: 0.256456, acc.: 54.69%] [G loss: 0.316339]\n",
      "epoch:33 step:31350 [D loss: 0.233275, acc.: 61.72%] [G loss: 0.297185]\n",
      "epoch:33 step:31351 [D loss: 0.243121, acc.: 53.12%] [G loss: 0.302796]\n",
      "epoch:33 step:31352 [D loss: 0.255302, acc.: 52.34%] [G loss: 0.301637]\n",
      "epoch:33 step:31353 [D loss: 0.233091, acc.: 61.72%] [G loss: 0.287848]\n",
      "epoch:33 step:31354 [D loss: 0.237360, acc.: 54.69%] [G loss: 0.306274]\n",
      "epoch:33 step:31355 [D loss: 0.266665, acc.: 46.88%] [G loss: 0.290237]\n",
      "epoch:33 step:31356 [D loss: 0.232011, acc.: 59.38%] [G loss: 0.309398]\n",
      "epoch:33 step:31357 [D loss: 0.231662, acc.: 61.72%] [G loss: 0.314243]\n",
      "epoch:33 step:31358 [D loss: 0.245388, acc.: 52.34%] [G loss: 0.271833]\n",
      "epoch:33 step:31359 [D loss: 0.230246, acc.: 59.38%] [G loss: 0.287637]\n",
      "epoch:33 step:31360 [D loss: 0.233812, acc.: 63.28%] [G loss: 0.305657]\n",
      "epoch:33 step:31361 [D loss: 0.234648, acc.: 55.47%] [G loss: 0.293155]\n",
      "epoch:33 step:31362 [D loss: 0.228901, acc.: 60.94%] [G loss: 0.274463]\n",
      "epoch:33 step:31363 [D loss: 0.231631, acc.: 62.50%] [G loss: 0.306529]\n",
      "epoch:33 step:31364 [D loss: 0.238521, acc.: 64.06%] [G loss: 0.319649]\n",
      "epoch:33 step:31365 [D loss: 0.240214, acc.: 56.25%] [G loss: 0.283535]\n",
      "epoch:33 step:31366 [D loss: 0.233722, acc.: 62.50%] [G loss: 0.279728]\n",
      "epoch:33 step:31367 [D loss: 0.252900, acc.: 53.91%] [G loss: 0.286242]\n",
      "epoch:33 step:31368 [D loss: 0.221900, acc.: 67.19%] [G loss: 0.311208]\n",
      "epoch:33 step:31369 [D loss: 0.256833, acc.: 53.91%] [G loss: 0.311388]\n",
      "epoch:33 step:31370 [D loss: 0.246222, acc.: 57.03%] [G loss: 0.277229]\n",
      "epoch:33 step:31371 [D loss: 0.257271, acc.: 54.69%] [G loss: 0.295152]\n",
      "epoch:33 step:31372 [D loss: 0.243121, acc.: 57.81%] [G loss: 0.299216]\n",
      "epoch:33 step:31373 [D loss: 0.250347, acc.: 55.47%] [G loss: 0.309766]\n",
      "epoch:33 step:31374 [D loss: 0.222347, acc.: 64.06%] [G loss: 0.288988]\n",
      "epoch:33 step:31375 [D loss: 0.230080, acc.: 61.72%] [G loss: 0.298404]\n",
      "epoch:33 step:31376 [D loss: 0.242100, acc.: 58.59%] [G loss: 0.299522]\n",
      "epoch:33 step:31377 [D loss: 0.248118, acc.: 54.69%] [G loss: 0.300604]\n",
      "epoch:33 step:31378 [D loss: 0.231632, acc.: 60.94%] [G loss: 0.311945]\n",
      "epoch:33 step:31379 [D loss: 0.247282, acc.: 55.47%] [G loss: 0.298365]\n",
      "epoch:33 step:31380 [D loss: 0.246062, acc.: 52.34%] [G loss: 0.292981]\n",
      "epoch:33 step:31381 [D loss: 0.229063, acc.: 58.59%] [G loss: 0.310482]\n",
      "epoch:33 step:31382 [D loss: 0.244081, acc.: 57.03%] [G loss: 0.311475]\n",
      "epoch:33 step:31383 [D loss: 0.252042, acc.: 48.44%] [G loss: 0.316597]\n",
      "epoch:33 step:31384 [D loss: 0.250040, acc.: 53.91%] [G loss: 0.286671]\n",
      "epoch:33 step:31385 [D loss: 0.222912, acc.: 64.06%] [G loss: 0.301030]\n",
      "epoch:33 step:31386 [D loss: 0.226856, acc.: 65.62%] [G loss: 0.301646]\n",
      "epoch:33 step:31387 [D loss: 0.239510, acc.: 60.94%] [G loss: 0.292648]\n",
      "epoch:33 step:31388 [D loss: 0.233684, acc.: 64.06%] [G loss: 0.266752]\n",
      "epoch:33 step:31389 [D loss: 0.248438, acc.: 53.91%] [G loss: 0.290985]\n",
      "epoch:33 step:31390 [D loss: 0.240698, acc.: 56.25%] [G loss: 0.277241]\n",
      "epoch:33 step:31391 [D loss: 0.251770, acc.: 53.12%] [G loss: 0.309698]\n",
      "epoch:33 step:31392 [D loss: 0.246578, acc.: 57.03%] [G loss: 0.310444]\n",
      "epoch:33 step:31393 [D loss: 0.246973, acc.: 57.03%] [G loss: 0.306674]\n",
      "epoch:33 step:31394 [D loss: 0.242636, acc.: 55.47%] [G loss: 0.297869]\n",
      "epoch:33 step:31395 [D loss: 0.218437, acc.: 66.41%] [G loss: 0.300265]\n",
      "epoch:33 step:31396 [D loss: 0.249380, acc.: 60.94%] [G loss: 0.317079]\n",
      "epoch:33 step:31397 [D loss: 0.222559, acc.: 67.19%] [G loss: 0.335909]\n",
      "epoch:33 step:31398 [D loss: 0.230480, acc.: 61.72%] [G loss: 0.313430]\n",
      "epoch:33 step:31399 [D loss: 0.258702, acc.: 51.56%] [G loss: 0.273121]\n",
      "epoch:33 step:31400 [D loss: 0.230293, acc.: 59.38%] [G loss: 0.297025]\n",
      "epoch:33 step:31401 [D loss: 0.236859, acc.: 57.81%] [G loss: 0.291164]\n",
      "epoch:33 step:31402 [D loss: 0.236831, acc.: 60.16%] [G loss: 0.310749]\n",
      "epoch:33 step:31403 [D loss: 0.246813, acc.: 54.69%] [G loss: 0.283821]\n",
      "epoch:33 step:31404 [D loss: 0.250581, acc.: 51.56%] [G loss: 0.299654]\n",
      "epoch:33 step:31405 [D loss: 0.246619, acc.: 53.91%] [G loss: 0.322603]\n",
      "epoch:33 step:31406 [D loss: 0.238507, acc.: 57.81%] [G loss: 0.283623]\n",
      "epoch:33 step:31407 [D loss: 0.229008, acc.: 57.81%] [G loss: 0.319801]\n",
      "epoch:33 step:31408 [D loss: 0.229711, acc.: 60.94%] [G loss: 0.301396]\n",
      "epoch:33 step:31409 [D loss: 0.227888, acc.: 57.03%] [G loss: 0.294090]\n",
      "epoch:33 step:31410 [D loss: 0.254356, acc.: 54.69%] [G loss: 0.295728]\n",
      "epoch:33 step:31411 [D loss: 0.234215, acc.: 62.50%] [G loss: 0.298689]\n",
      "epoch:33 step:31412 [D loss: 0.234877, acc.: 57.81%] [G loss: 0.297705]\n",
      "epoch:33 step:31413 [D loss: 0.246082, acc.: 53.12%] [G loss: 0.284670]\n",
      "epoch:33 step:31414 [D loss: 0.235303, acc.: 60.94%] [G loss: 0.285197]\n",
      "epoch:33 step:31415 [D loss: 0.242525, acc.: 54.69%] [G loss: 0.306327]\n",
      "epoch:33 step:31416 [D loss: 0.255947, acc.: 53.12%] [G loss: 0.312308]\n",
      "epoch:33 step:31417 [D loss: 0.241001, acc.: 58.59%] [G loss: 0.307293]\n",
      "epoch:33 step:31418 [D loss: 0.241484, acc.: 59.38%] [G loss: 0.300631]\n",
      "epoch:33 step:31419 [D loss: 0.245691, acc.: 54.69%] [G loss: 0.309655]\n",
      "epoch:33 step:31420 [D loss: 0.249716, acc.: 53.91%] [G loss: 0.304853]\n",
      "epoch:33 step:31421 [D loss: 0.249604, acc.: 54.69%] [G loss: 0.291424]\n",
      "epoch:33 step:31422 [D loss: 0.230082, acc.: 60.94%] [G loss: 0.293145]\n",
      "epoch:33 step:31423 [D loss: 0.222108, acc.: 67.97%] [G loss: 0.330503]\n",
      "epoch:33 step:31424 [D loss: 0.255566, acc.: 56.25%] [G loss: 0.317556]\n",
      "epoch:33 step:31425 [D loss: 0.223649, acc.: 66.41%] [G loss: 0.296571]\n",
      "epoch:33 step:31426 [D loss: 0.228643, acc.: 60.16%] [G loss: 0.323708]\n",
      "epoch:33 step:31427 [D loss: 0.253618, acc.: 56.25%] [G loss: 0.284885]\n",
      "epoch:33 step:31428 [D loss: 0.243029, acc.: 62.50%] [G loss: 0.316902]\n",
      "epoch:33 step:31429 [D loss: 0.246847, acc.: 53.91%] [G loss: 0.273378]\n",
      "epoch:33 step:31430 [D loss: 0.229270, acc.: 62.50%] [G loss: 0.313704]\n",
      "epoch:33 step:31431 [D loss: 0.228299, acc.: 62.50%] [G loss: 0.295056]\n",
      "epoch:33 step:31432 [D loss: 0.248591, acc.: 50.78%] [G loss: 0.280039]\n",
      "epoch:33 step:31433 [D loss: 0.258658, acc.: 53.12%] [G loss: 0.294090]\n",
      "epoch:33 step:31434 [D loss: 0.244353, acc.: 57.03%] [G loss: 0.306478]\n",
      "epoch:33 step:31435 [D loss: 0.234377, acc.: 60.16%] [G loss: 0.315885]\n",
      "epoch:33 step:31436 [D loss: 0.233941, acc.: 60.16%] [G loss: 0.281377]\n",
      "epoch:33 step:31437 [D loss: 0.239922, acc.: 57.03%] [G loss: 0.337802]\n",
      "epoch:33 step:31438 [D loss: 0.260235, acc.: 49.22%] [G loss: 0.260318]\n",
      "epoch:33 step:31439 [D loss: 0.242641, acc.: 57.81%] [G loss: 0.294297]\n",
      "epoch:33 step:31440 [D loss: 0.242131, acc.: 57.03%] [G loss: 0.311942]\n",
      "epoch:33 step:31441 [D loss: 0.250953, acc.: 54.69%] [G loss: 0.291945]\n",
      "epoch:33 step:31442 [D loss: 0.236194, acc.: 57.81%] [G loss: 0.341278]\n",
      "epoch:33 step:31443 [D loss: 0.250570, acc.: 56.25%] [G loss: 0.326790]\n",
      "epoch:33 step:31444 [D loss: 0.241535, acc.: 54.69%] [G loss: 0.313027]\n",
      "epoch:33 step:31445 [D loss: 0.240023, acc.: 63.28%] [G loss: 0.321192]\n",
      "epoch:33 step:31446 [D loss: 0.232462, acc.: 60.94%] [G loss: 0.328986]\n",
      "epoch:33 step:31447 [D loss: 0.228906, acc.: 64.06%] [G loss: 0.336903]\n",
      "epoch:33 step:31448 [D loss: 0.251436, acc.: 56.25%] [G loss: 0.282857]\n",
      "epoch:33 step:31449 [D loss: 0.237526, acc.: 54.69%] [G loss: 0.319253]\n",
      "epoch:33 step:31450 [D loss: 0.225892, acc.: 64.06%] [G loss: 0.300803]\n",
      "epoch:33 step:31451 [D loss: 0.247057, acc.: 52.34%] [G loss: 0.291017]\n",
      "epoch:33 step:31452 [D loss: 0.220473, acc.: 64.06%] [G loss: 0.321474]\n",
      "epoch:33 step:31453 [D loss: 0.233301, acc.: 64.84%] [G loss: 0.304510]\n",
      "epoch:33 step:31454 [D loss: 0.236546, acc.: 63.28%] [G loss: 0.313165]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:33 step:31455 [D loss: 0.249237, acc.: 57.81%] [G loss: 0.295308]\n",
      "epoch:33 step:31456 [D loss: 0.245177, acc.: 61.72%] [G loss: 0.304372]\n",
      "epoch:33 step:31457 [D loss: 0.233038, acc.: 61.72%] [G loss: 0.296202]\n",
      "epoch:33 step:31458 [D loss: 0.256499, acc.: 53.12%] [G loss: 0.294403]\n",
      "epoch:33 step:31459 [D loss: 0.234613, acc.: 64.84%] [G loss: 0.302830]\n",
      "epoch:33 step:31460 [D loss: 0.228054, acc.: 63.28%] [G loss: 0.290830]\n",
      "epoch:33 step:31461 [D loss: 0.225159, acc.: 60.94%] [G loss: 0.297806]\n",
      "epoch:33 step:31462 [D loss: 0.233538, acc.: 60.94%] [G loss: 0.301698]\n",
      "epoch:33 step:31463 [D loss: 0.248371, acc.: 55.47%] [G loss: 0.291806]\n",
      "epoch:33 step:31464 [D loss: 0.243548, acc.: 59.38%] [G loss: 0.331222]\n",
      "epoch:33 step:31465 [D loss: 0.241605, acc.: 55.47%] [G loss: 0.283063]\n",
      "epoch:33 step:31466 [D loss: 0.244721, acc.: 53.12%] [G loss: 0.319210]\n",
      "epoch:33 step:31467 [D loss: 0.236259, acc.: 57.03%] [G loss: 0.314133]\n",
      "epoch:33 step:31468 [D loss: 0.272905, acc.: 48.44%] [G loss: 0.304834]\n",
      "epoch:33 step:31469 [D loss: 0.242017, acc.: 54.69%] [G loss: 0.291687]\n",
      "epoch:33 step:31470 [D loss: 0.229684, acc.: 60.94%] [G loss: 0.278535]\n",
      "epoch:33 step:31471 [D loss: 0.241409, acc.: 57.03%] [G loss: 0.308036]\n",
      "epoch:33 step:31472 [D loss: 0.257330, acc.: 49.22%] [G loss: 0.296008]\n",
      "epoch:33 step:31473 [D loss: 0.230899, acc.: 67.19%] [G loss: 0.314810]\n",
      "epoch:33 step:31474 [D loss: 0.239838, acc.: 53.12%] [G loss: 0.330592]\n",
      "epoch:33 step:31475 [D loss: 0.249458, acc.: 56.25%] [G loss: 0.297227]\n",
      "epoch:33 step:31476 [D loss: 0.242874, acc.: 57.81%] [G loss: 0.274033]\n",
      "epoch:33 step:31477 [D loss: 0.234615, acc.: 58.59%] [G loss: 0.315419]\n",
      "epoch:33 step:31478 [D loss: 0.258889, acc.: 50.78%] [G loss: 0.328558]\n",
      "epoch:33 step:31479 [D loss: 0.237807, acc.: 58.59%] [G loss: 0.289805]\n",
      "epoch:33 step:31480 [D loss: 0.240124, acc.: 57.03%] [G loss: 0.295732]\n",
      "epoch:33 step:31481 [D loss: 0.242093, acc.: 56.25%] [G loss: 0.284097]\n",
      "epoch:33 step:31482 [D loss: 0.239548, acc.: 57.81%] [G loss: 0.319290]\n",
      "epoch:33 step:31483 [D loss: 0.226553, acc.: 64.06%] [G loss: 0.311301]\n",
      "epoch:33 step:31484 [D loss: 0.240839, acc.: 57.81%] [G loss: 0.301226]\n",
      "epoch:33 step:31485 [D loss: 0.226850, acc.: 63.28%] [G loss: 0.293209]\n",
      "epoch:33 step:31486 [D loss: 0.251997, acc.: 53.91%] [G loss: 0.290568]\n",
      "epoch:33 step:31487 [D loss: 0.244954, acc.: 56.25%] [G loss: 0.310968]\n",
      "epoch:33 step:31488 [D loss: 0.236133, acc.: 61.72%] [G loss: 0.291508]\n",
      "epoch:33 step:31489 [D loss: 0.245125, acc.: 57.81%] [G loss: 0.290640]\n",
      "epoch:33 step:31490 [D loss: 0.251860, acc.: 53.91%] [G loss: 0.295085]\n",
      "epoch:33 step:31491 [D loss: 0.244991, acc.: 55.47%] [G loss: 0.316730]\n",
      "epoch:33 step:31492 [D loss: 0.231899, acc.: 62.50%] [G loss: 0.304396]\n",
      "epoch:33 step:31493 [D loss: 0.241088, acc.: 57.81%] [G loss: 0.306783]\n",
      "epoch:33 step:31494 [D loss: 0.245560, acc.: 55.47%] [G loss: 0.310521]\n",
      "epoch:33 step:31495 [D loss: 0.258652, acc.: 51.56%] [G loss: 0.279304]\n",
      "epoch:33 step:31496 [D loss: 0.228825, acc.: 62.50%] [G loss: 0.305090]\n",
      "epoch:33 step:31497 [D loss: 0.223676, acc.: 64.06%] [G loss: 0.310455]\n",
      "epoch:33 step:31498 [D loss: 0.247233, acc.: 56.25%] [G loss: 0.299526]\n",
      "epoch:33 step:31499 [D loss: 0.232503, acc.: 61.72%] [G loss: 0.325680]\n",
      "epoch:33 step:31500 [D loss: 0.235730, acc.: 64.06%] [G loss: 0.291579]\n",
      "epoch:33 step:31501 [D loss: 0.242310, acc.: 50.78%] [G loss: 0.304695]\n",
      "epoch:33 step:31502 [D loss: 0.245038, acc.: 53.91%] [G loss: 0.306762]\n",
      "epoch:33 step:31503 [D loss: 0.240316, acc.: 58.59%] [G loss: 0.326381]\n",
      "epoch:33 step:31504 [D loss: 0.222137, acc.: 64.06%] [G loss: 0.269784]\n",
      "epoch:33 step:31505 [D loss: 0.252135, acc.: 51.56%] [G loss: 0.318671]\n",
      "epoch:33 step:31506 [D loss: 0.245370, acc.: 57.81%] [G loss: 0.266833]\n",
      "epoch:33 step:31507 [D loss: 0.242628, acc.: 54.69%] [G loss: 0.269765]\n",
      "epoch:33 step:31508 [D loss: 0.240605, acc.: 56.25%] [G loss: 0.320180]\n",
      "epoch:33 step:31509 [D loss: 0.236447, acc.: 58.59%] [G loss: 0.290910]\n",
      "epoch:33 step:31510 [D loss: 0.232737, acc.: 64.84%] [G loss: 0.292795]\n",
      "epoch:33 step:31511 [D loss: 0.244580, acc.: 57.03%] [G loss: 0.291019]\n",
      "epoch:33 step:31512 [D loss: 0.223335, acc.: 63.28%] [G loss: 0.294366]\n",
      "epoch:33 step:31513 [D loss: 0.247942, acc.: 51.56%] [G loss: 0.321536]\n",
      "epoch:33 step:31514 [D loss: 0.247346, acc.: 56.25%] [G loss: 0.297914]\n",
      "epoch:33 step:31515 [D loss: 0.245031, acc.: 57.81%] [G loss: 0.310666]\n",
      "epoch:33 step:31516 [D loss: 0.244433, acc.: 59.38%] [G loss: 0.303237]\n",
      "epoch:33 step:31517 [D loss: 0.250865, acc.: 55.47%] [G loss: 0.267412]\n",
      "epoch:33 step:31518 [D loss: 0.234911, acc.: 60.94%] [G loss: 0.308613]\n",
      "epoch:33 step:31519 [D loss: 0.238564, acc.: 56.25%] [G loss: 0.275133]\n",
      "epoch:33 step:31520 [D loss: 0.220028, acc.: 63.28%] [G loss: 0.312030]\n",
      "epoch:33 step:31521 [D loss: 0.238980, acc.: 57.81%] [G loss: 0.309997]\n",
      "epoch:33 step:31522 [D loss: 0.235741, acc.: 62.50%] [G loss: 0.285196]\n",
      "epoch:33 step:31523 [D loss: 0.233889, acc.: 62.50%] [G loss: 0.281307]\n",
      "epoch:33 step:31524 [D loss: 0.229599, acc.: 61.72%] [G loss: 0.287084]\n",
      "epoch:33 step:31525 [D loss: 0.243844, acc.: 56.25%] [G loss: 0.324855]\n",
      "epoch:33 step:31526 [D loss: 0.227269, acc.: 65.62%] [G loss: 0.320414]\n",
      "epoch:33 step:31527 [D loss: 0.252782, acc.: 50.00%] [G loss: 0.321706]\n",
      "epoch:33 step:31528 [D loss: 0.220093, acc.: 62.50%] [G loss: 0.300048]\n",
      "epoch:33 step:31529 [D loss: 0.228079, acc.: 61.72%] [G loss: 0.294979]\n",
      "epoch:33 step:31530 [D loss: 0.234131, acc.: 62.50%] [G loss: 0.277520]\n",
      "epoch:33 step:31531 [D loss: 0.231511, acc.: 59.38%] [G loss: 0.307607]\n",
      "epoch:33 step:31532 [D loss: 0.248673, acc.: 56.25%] [G loss: 0.266386]\n",
      "epoch:33 step:31533 [D loss: 0.248652, acc.: 55.47%] [G loss: 0.279020]\n",
      "epoch:33 step:31534 [D loss: 0.226896, acc.: 65.62%] [G loss: 0.278684]\n",
      "epoch:33 step:31535 [D loss: 0.240022, acc.: 58.59%] [G loss: 0.301934]\n",
      "epoch:33 step:31536 [D loss: 0.241134, acc.: 56.25%] [G loss: 0.274435]\n",
      "epoch:33 step:31537 [D loss: 0.231482, acc.: 65.62%] [G loss: 0.294245]\n",
      "epoch:33 step:31538 [D loss: 0.249602, acc.: 53.91%] [G loss: 0.296011]\n",
      "epoch:33 step:31539 [D loss: 0.234886, acc.: 57.03%] [G loss: 0.328939]\n",
      "epoch:33 step:31540 [D loss: 0.225137, acc.: 65.62%] [G loss: 0.296149]\n",
      "epoch:33 step:31541 [D loss: 0.261381, acc.: 48.44%] [G loss: 0.287136]\n",
      "epoch:33 step:31542 [D loss: 0.238686, acc.: 57.03%] [G loss: 0.286238]\n",
      "epoch:33 step:31543 [D loss: 0.250002, acc.: 49.22%] [G loss: 0.295933]\n",
      "epoch:33 step:31544 [D loss: 0.238571, acc.: 60.94%] [G loss: 0.297831]\n",
      "epoch:33 step:31545 [D loss: 0.279373, acc.: 41.41%] [G loss: 0.288659]\n",
      "epoch:33 step:31546 [D loss: 0.222952, acc.: 66.41%] [G loss: 0.299265]\n",
      "epoch:33 step:31547 [D loss: 0.247885, acc.: 55.47%] [G loss: 0.306919]\n",
      "epoch:33 step:31548 [D loss: 0.237024, acc.: 60.16%] [G loss: 0.289254]\n",
      "epoch:33 step:31549 [D loss: 0.249257, acc.: 53.91%] [G loss: 0.290927]\n",
      "epoch:33 step:31550 [D loss: 0.250497, acc.: 49.22%] [G loss: 0.292846]\n",
      "epoch:33 step:31551 [D loss: 0.245521, acc.: 53.91%] [G loss: 0.310717]\n",
      "epoch:33 step:31552 [D loss: 0.244665, acc.: 58.59%] [G loss: 0.280510]\n",
      "epoch:33 step:31553 [D loss: 0.232352, acc.: 60.94%] [G loss: 0.296990]\n",
      "epoch:33 step:31554 [D loss: 0.242109, acc.: 59.38%] [G loss: 0.305484]\n",
      "epoch:33 step:31555 [D loss: 0.232778, acc.: 63.28%] [G loss: 0.301396]\n",
      "epoch:33 step:31556 [D loss: 0.222980, acc.: 64.84%] [G loss: 0.335701]\n",
      "epoch:33 step:31557 [D loss: 0.238358, acc.: 55.47%] [G loss: 0.315354]\n",
      "epoch:33 step:31558 [D loss: 0.247970, acc.: 56.25%] [G loss: 0.308116]\n",
      "epoch:33 step:31559 [D loss: 0.243031, acc.: 53.91%] [G loss: 0.314021]\n",
      "epoch:33 step:31560 [D loss: 0.232403, acc.: 57.81%] [G loss: 0.318424]\n",
      "epoch:33 step:31561 [D loss: 0.227548, acc.: 58.59%] [G loss: 0.312243]\n",
      "epoch:33 step:31562 [D loss: 0.236965, acc.: 57.03%] [G loss: 0.309438]\n",
      "epoch:33 step:31563 [D loss: 0.248042, acc.: 50.00%] [G loss: 0.319449]\n",
      "epoch:33 step:31564 [D loss: 0.247445, acc.: 53.91%] [G loss: 0.275716]\n",
      "epoch:33 step:31565 [D loss: 0.221326, acc.: 64.84%] [G loss: 0.288638]\n",
      "epoch:33 step:31566 [D loss: 0.244906, acc.: 54.69%] [G loss: 0.291538]\n",
      "epoch:33 step:31567 [D loss: 0.250462, acc.: 55.47%] [G loss: 0.292863]\n",
      "epoch:33 step:31568 [D loss: 0.239223, acc.: 59.38%] [G loss: 0.328938]\n",
      "epoch:33 step:31569 [D loss: 0.235009, acc.: 57.03%] [G loss: 0.295103]\n",
      "epoch:33 step:31570 [D loss: 0.232752, acc.: 60.16%] [G loss: 0.298382]\n",
      "epoch:33 step:31571 [D loss: 0.232794, acc.: 67.19%] [G loss: 0.311466]\n",
      "epoch:33 step:31572 [D loss: 0.240169, acc.: 57.03%] [G loss: 0.272126]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:33 step:31573 [D loss: 0.231549, acc.: 67.19%] [G loss: 0.306626]\n",
      "epoch:33 step:31574 [D loss: 0.234608, acc.: 67.19%] [G loss: 0.314605]\n",
      "epoch:33 step:31575 [D loss: 0.237817, acc.: 60.16%] [G loss: 0.305761]\n",
      "epoch:33 step:31576 [D loss: 0.252721, acc.: 51.56%] [G loss: 0.261044]\n",
      "epoch:33 step:31577 [D loss: 0.227423, acc.: 60.94%] [G loss: 0.283446]\n",
      "epoch:33 step:31578 [D loss: 0.251965, acc.: 52.34%] [G loss: 0.298184]\n",
      "epoch:33 step:31579 [D loss: 0.237484, acc.: 57.03%] [G loss: 0.296934]\n",
      "epoch:33 step:31580 [D loss: 0.238518, acc.: 60.16%] [G loss: 0.284898]\n",
      "epoch:33 step:31581 [D loss: 0.248062, acc.: 50.78%] [G loss: 0.244760]\n",
      "epoch:33 step:31582 [D loss: 0.238252, acc.: 59.38%] [G loss: 0.318408]\n",
      "epoch:33 step:31583 [D loss: 0.257385, acc.: 49.22%] [G loss: 0.290815]\n",
      "epoch:33 step:31584 [D loss: 0.246721, acc.: 50.78%] [G loss: 0.321183]\n",
      "epoch:33 step:31585 [D loss: 0.228395, acc.: 65.62%] [G loss: 0.274653]\n",
      "epoch:33 step:31586 [D loss: 0.243638, acc.: 54.69%] [G loss: 0.267346]\n",
      "epoch:33 step:31587 [D loss: 0.242365, acc.: 50.00%] [G loss: 0.303228]\n",
      "epoch:33 step:31588 [D loss: 0.249873, acc.: 53.91%] [G loss: 0.277306]\n",
      "epoch:33 step:31589 [D loss: 0.232888, acc.: 60.16%] [G loss: 0.295534]\n",
      "epoch:33 step:31590 [D loss: 0.257136, acc.: 51.56%] [G loss: 0.291813]\n",
      "epoch:33 step:31591 [D loss: 0.237262, acc.: 60.16%] [G loss: 0.309667]\n",
      "epoch:33 step:31592 [D loss: 0.245160, acc.: 59.38%] [G loss: 0.292977]\n",
      "epoch:33 step:31593 [D loss: 0.232522, acc.: 60.94%] [G loss: 0.307610]\n",
      "epoch:33 step:31594 [D loss: 0.253982, acc.: 57.03%] [G loss: 0.280749]\n",
      "epoch:33 step:31595 [D loss: 0.238073, acc.: 58.59%] [G loss: 0.293678]\n",
      "epoch:33 step:31596 [D loss: 0.252191, acc.: 55.47%] [G loss: 0.289711]\n",
      "epoch:33 step:31597 [D loss: 0.248602, acc.: 54.69%] [G loss: 0.298050]\n",
      "epoch:33 step:31598 [D loss: 0.237996, acc.: 60.94%] [G loss: 0.267054]\n",
      "epoch:33 step:31599 [D loss: 0.228674, acc.: 65.62%] [G loss: 0.307946]\n",
      "epoch:33 step:31600 [D loss: 0.252985, acc.: 53.12%] [G loss: 0.339403]\n",
      "epoch:33 step:31601 [D loss: 0.245716, acc.: 57.03%] [G loss: 0.299278]\n",
      "epoch:33 step:31602 [D loss: 0.245933, acc.: 55.47%] [G loss: 0.281349]\n",
      "epoch:33 step:31603 [D loss: 0.238452, acc.: 56.25%] [G loss: 0.297610]\n",
      "epoch:33 step:31604 [D loss: 0.250999, acc.: 57.03%] [G loss: 0.301261]\n",
      "epoch:33 step:31605 [D loss: 0.253476, acc.: 55.47%] [G loss: 0.284311]\n",
      "epoch:33 step:31606 [D loss: 0.245465, acc.: 55.47%] [G loss: 0.277750]\n",
      "epoch:33 step:31607 [D loss: 0.252880, acc.: 55.47%] [G loss: 0.321608]\n",
      "epoch:33 step:31608 [D loss: 0.238230, acc.: 57.81%] [G loss: 0.297676]\n",
      "epoch:33 step:31609 [D loss: 0.225285, acc.: 62.50%] [G loss: 0.282520]\n",
      "epoch:33 step:31610 [D loss: 0.243855, acc.: 56.25%] [G loss: 0.298122]\n",
      "epoch:33 step:31611 [D loss: 0.230481, acc.: 63.28%] [G loss: 0.280834]\n",
      "epoch:33 step:31612 [D loss: 0.250236, acc.: 54.69%] [G loss: 0.290010]\n",
      "epoch:33 step:31613 [D loss: 0.244276, acc.: 60.94%] [G loss: 0.275791]\n",
      "epoch:33 step:31614 [D loss: 0.255171, acc.: 51.56%] [G loss: 0.285481]\n",
      "epoch:33 step:31615 [D loss: 0.243815, acc.: 53.12%] [G loss: 0.291476]\n",
      "epoch:33 step:31616 [D loss: 0.231927, acc.: 58.59%] [G loss: 0.296923]\n",
      "epoch:33 step:31617 [D loss: 0.239202, acc.: 57.81%] [G loss: 0.277977]\n",
      "epoch:33 step:31618 [D loss: 0.234839, acc.: 60.16%] [G loss: 0.310367]\n",
      "epoch:33 step:31619 [D loss: 0.219607, acc.: 65.62%] [G loss: 0.300984]\n",
      "epoch:33 step:31620 [D loss: 0.241280, acc.: 56.25%] [G loss: 0.291827]\n",
      "epoch:33 step:31621 [D loss: 0.231373, acc.: 64.84%] [G loss: 0.312720]\n",
      "epoch:33 step:31622 [D loss: 0.240018, acc.: 59.38%] [G loss: 0.314314]\n",
      "epoch:33 step:31623 [D loss: 0.222898, acc.: 64.06%] [G loss: 0.312352]\n",
      "epoch:33 step:31624 [D loss: 0.233774, acc.: 56.25%] [G loss: 0.315053]\n",
      "epoch:33 step:31625 [D loss: 0.256369, acc.: 50.00%] [G loss: 0.265470]\n",
      "epoch:33 step:31626 [D loss: 0.231707, acc.: 58.59%] [G loss: 0.280585]\n",
      "epoch:33 step:31627 [D loss: 0.252112, acc.: 52.34%] [G loss: 0.304255]\n",
      "epoch:33 step:31628 [D loss: 0.233556, acc.: 58.59%] [G loss: 0.323593]\n",
      "epoch:33 step:31629 [D loss: 0.234521, acc.: 58.59%] [G loss: 0.294777]\n",
      "epoch:33 step:31630 [D loss: 0.244906, acc.: 57.81%] [G loss: 0.289640]\n",
      "epoch:33 step:31631 [D loss: 0.228493, acc.: 61.72%] [G loss: 0.291430]\n",
      "epoch:33 step:31632 [D loss: 0.247519, acc.: 56.25%] [G loss: 0.304758]\n",
      "epoch:33 step:31633 [D loss: 0.245751, acc.: 55.47%] [G loss: 0.275688]\n",
      "epoch:33 step:31634 [D loss: 0.235492, acc.: 62.50%] [G loss: 0.298077]\n",
      "epoch:33 step:31635 [D loss: 0.236718, acc.: 60.16%] [G loss: 0.305507]\n",
      "epoch:33 step:31636 [D loss: 0.234070, acc.: 60.94%] [G loss: 0.321673]\n",
      "epoch:33 step:31637 [D loss: 0.221374, acc.: 64.06%] [G loss: 0.295416]\n",
      "epoch:33 step:31638 [D loss: 0.266293, acc.: 49.22%] [G loss: 0.299723]\n",
      "epoch:33 step:31639 [D loss: 0.240365, acc.: 59.38%] [G loss: 0.284408]\n",
      "epoch:33 step:31640 [D loss: 0.225584, acc.: 61.72%] [G loss: 0.286968]\n",
      "epoch:33 step:31641 [D loss: 0.242865, acc.: 58.59%] [G loss: 0.289032]\n",
      "epoch:33 step:31642 [D loss: 0.235836, acc.: 57.81%] [G loss: 0.294244]\n",
      "epoch:33 step:31643 [D loss: 0.241732, acc.: 62.50%] [G loss: 0.310765]\n",
      "epoch:33 step:31644 [D loss: 0.234470, acc.: 61.72%] [G loss: 0.270400]\n",
      "epoch:33 step:31645 [D loss: 0.266646, acc.: 50.78%] [G loss: 0.290439]\n",
      "epoch:33 step:31646 [D loss: 0.238818, acc.: 58.59%] [G loss: 0.299226]\n",
      "epoch:33 step:31647 [D loss: 0.223037, acc.: 66.41%] [G loss: 0.286189]\n",
      "epoch:33 step:31648 [D loss: 0.245718, acc.: 53.91%] [G loss: 0.287430]\n",
      "epoch:33 step:31649 [D loss: 0.233200, acc.: 57.81%] [G loss: 0.294167]\n",
      "epoch:33 step:31650 [D loss: 0.224066, acc.: 59.38%] [G loss: 0.302172]\n",
      "epoch:33 step:31651 [D loss: 0.254726, acc.: 54.69%] [G loss: 0.290789]\n",
      "epoch:33 step:31652 [D loss: 0.263925, acc.: 47.66%] [G loss: 0.276247]\n",
      "epoch:33 step:31653 [D loss: 0.237758, acc.: 59.38%] [G loss: 0.268966]\n",
      "epoch:33 step:31654 [D loss: 0.221724, acc.: 66.41%] [G loss: 0.298801]\n",
      "epoch:33 step:31655 [D loss: 0.242769, acc.: 60.16%] [G loss: 0.274494]\n",
      "epoch:33 step:31656 [D loss: 0.239401, acc.: 56.25%] [G loss: 0.297774]\n",
      "epoch:33 step:31657 [D loss: 0.238822, acc.: 53.12%] [G loss: 0.302718]\n",
      "epoch:33 step:31658 [D loss: 0.265179, acc.: 46.88%] [G loss: 0.327303]\n",
      "epoch:33 step:31659 [D loss: 0.249801, acc.: 57.81%] [G loss: 0.302514]\n",
      "epoch:33 step:31660 [D loss: 0.255202, acc.: 52.34%] [G loss: 0.314846]\n",
      "epoch:33 step:31661 [D loss: 0.234786, acc.: 61.72%] [G loss: 0.286318]\n",
      "epoch:33 step:31662 [D loss: 0.240924, acc.: 56.25%] [G loss: 0.313027]\n",
      "epoch:33 step:31663 [D loss: 0.233488, acc.: 62.50%] [G loss: 0.303070]\n",
      "epoch:33 step:31664 [D loss: 0.232646, acc.: 60.94%] [G loss: 0.303371]\n",
      "epoch:33 step:31665 [D loss: 0.231291, acc.: 64.06%] [G loss: 0.281503]\n",
      "epoch:33 step:31666 [D loss: 0.227315, acc.: 64.06%] [G loss: 0.267947]\n",
      "epoch:33 step:31667 [D loss: 0.235181, acc.: 60.94%] [G loss: 0.298769]\n",
      "epoch:33 step:31668 [D loss: 0.247635, acc.: 53.12%] [G loss: 0.308039]\n",
      "epoch:33 step:31669 [D loss: 0.231884, acc.: 60.16%] [G loss: 0.301471]\n",
      "epoch:33 step:31670 [D loss: 0.230515, acc.: 64.84%] [G loss: 0.304021]\n",
      "epoch:33 step:31671 [D loss: 0.229793, acc.: 62.50%] [G loss: 0.295859]\n",
      "epoch:33 step:31672 [D loss: 0.260929, acc.: 50.00%] [G loss: 0.266359]\n",
      "epoch:33 step:31673 [D loss: 0.246965, acc.: 57.81%] [G loss: 0.267579]\n",
      "epoch:33 step:31674 [D loss: 0.239537, acc.: 59.38%] [G loss: 0.270521]\n",
      "epoch:33 step:31675 [D loss: 0.231090, acc.: 62.50%] [G loss: 0.330365]\n",
      "epoch:33 step:31676 [D loss: 0.249956, acc.: 57.81%] [G loss: 0.291873]\n",
      "epoch:33 step:31677 [D loss: 0.211282, acc.: 65.62%] [G loss: 0.281826]\n",
      "epoch:33 step:31678 [D loss: 0.237274, acc.: 57.03%] [G loss: 0.282368]\n",
      "epoch:33 step:31679 [D loss: 0.240522, acc.: 57.03%] [G loss: 0.320126]\n",
      "epoch:33 step:31680 [D loss: 0.233298, acc.: 57.81%] [G loss: 0.321744]\n",
      "epoch:33 step:31681 [D loss: 0.228046, acc.: 66.41%] [G loss: 0.293185]\n",
      "epoch:33 step:31682 [D loss: 0.242510, acc.: 58.59%] [G loss: 0.299142]\n",
      "epoch:33 step:31683 [D loss: 0.249478, acc.: 51.56%] [G loss: 0.325092]\n",
      "epoch:33 step:31684 [D loss: 0.234931, acc.: 59.38%] [G loss: 0.307221]\n",
      "epoch:33 step:31685 [D loss: 0.221013, acc.: 65.62%] [G loss: 0.305577]\n",
      "epoch:33 step:31686 [D loss: 0.257305, acc.: 60.16%] [G loss: 0.290733]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:33 step:31687 [D loss: 0.233226, acc.: 59.38%] [G loss: 0.319554]\n",
      "epoch:33 step:31688 [D loss: 0.236756, acc.: 62.50%] [G loss: 0.283915]\n",
      "epoch:33 step:31689 [D loss: 0.243713, acc.: 57.03%] [G loss: 0.293202]\n",
      "epoch:33 step:31690 [D loss: 0.249610, acc.: 52.34%] [G loss: 0.286480]\n",
      "epoch:33 step:31691 [D loss: 0.257200, acc.: 56.25%] [G loss: 0.289737]\n",
      "epoch:33 step:31692 [D loss: 0.229677, acc.: 63.28%] [G loss: 0.291683]\n",
      "epoch:33 step:31693 [D loss: 0.224497, acc.: 60.16%] [G loss: 0.329318]\n",
      "epoch:33 step:31694 [D loss: 0.241066, acc.: 54.69%] [G loss: 0.301612]\n",
      "epoch:33 step:31695 [D loss: 0.252404, acc.: 53.91%] [G loss: 0.299808]\n",
      "epoch:33 step:31696 [D loss: 0.240427, acc.: 55.47%] [G loss: 0.319096]\n",
      "epoch:33 step:31697 [D loss: 0.246860, acc.: 55.47%] [G loss: 0.289113]\n",
      "epoch:33 step:31698 [D loss: 0.243922, acc.: 57.81%] [G loss: 0.321259]\n",
      "epoch:33 step:31699 [D loss: 0.231972, acc.: 57.03%] [G loss: 0.323586]\n",
      "epoch:33 step:31700 [D loss: 0.235114, acc.: 60.16%] [G loss: 0.303194]\n",
      "epoch:33 step:31701 [D loss: 0.240487, acc.: 56.25%] [G loss: 0.293235]\n",
      "epoch:33 step:31702 [D loss: 0.262834, acc.: 47.66%] [G loss: 0.281514]\n",
      "epoch:33 step:31703 [D loss: 0.236261, acc.: 57.03%] [G loss: 0.296252]\n",
      "epoch:33 step:31704 [D loss: 0.236995, acc.: 59.38%] [G loss: 0.295599]\n",
      "epoch:33 step:31705 [D loss: 0.223007, acc.: 60.94%] [G loss: 0.283373]\n",
      "epoch:33 step:31706 [D loss: 0.245609, acc.: 53.12%] [G loss: 0.322960]\n",
      "epoch:33 step:31707 [D loss: 0.232633, acc.: 60.16%] [G loss: 0.315088]\n",
      "epoch:33 step:31708 [D loss: 0.237127, acc.: 53.91%] [G loss: 0.275779]\n",
      "epoch:33 step:31709 [D loss: 0.224329, acc.: 63.28%] [G loss: 0.305883]\n",
      "epoch:33 step:31710 [D loss: 0.226259, acc.: 63.28%] [G loss: 0.288740]\n",
      "epoch:33 step:31711 [D loss: 0.230051, acc.: 63.28%] [G loss: 0.291798]\n",
      "epoch:33 step:31712 [D loss: 0.237621, acc.: 55.47%] [G loss: 0.272120]\n",
      "epoch:33 step:31713 [D loss: 0.218812, acc.: 60.94%] [G loss: 0.291251]\n",
      "epoch:33 step:31714 [D loss: 0.238633, acc.: 57.81%] [G loss: 0.289775]\n",
      "epoch:33 step:31715 [D loss: 0.231424, acc.: 58.59%] [G loss: 0.293513]\n",
      "epoch:33 step:31716 [D loss: 0.244151, acc.: 52.34%] [G loss: 0.247541]\n",
      "epoch:33 step:31717 [D loss: 0.248009, acc.: 58.59%] [G loss: 0.300499]\n",
      "epoch:33 step:31718 [D loss: 0.237075, acc.: 58.59%] [G loss: 0.288217]\n",
      "epoch:33 step:31719 [D loss: 0.235870, acc.: 63.28%] [G loss: 0.313728]\n",
      "epoch:33 step:31720 [D loss: 0.241230, acc.: 57.81%] [G loss: 0.236689]\n",
      "epoch:33 step:31721 [D loss: 0.250065, acc.: 50.00%] [G loss: 0.303746]\n",
      "epoch:33 step:31722 [D loss: 0.237947, acc.: 56.25%] [G loss: 0.311105]\n",
      "epoch:33 step:31723 [D loss: 0.244438, acc.: 52.34%] [G loss: 0.288811]\n",
      "epoch:33 step:31724 [D loss: 0.240569, acc.: 59.38%] [G loss: 0.319317]\n",
      "epoch:33 step:31725 [D loss: 0.233084, acc.: 60.16%] [G loss: 0.270385]\n",
      "epoch:33 step:31726 [D loss: 0.226836, acc.: 62.50%] [G loss: 0.294924]\n",
      "epoch:33 step:31727 [D loss: 0.225889, acc.: 62.50%] [G loss: 0.288376]\n",
      "epoch:33 step:31728 [D loss: 0.259737, acc.: 50.00%] [G loss: 0.262723]\n",
      "epoch:33 step:31729 [D loss: 0.204770, acc.: 68.75%] [G loss: 0.290142]\n",
      "epoch:33 step:31730 [D loss: 0.255656, acc.: 55.47%] [G loss: 0.284633]\n",
      "epoch:33 step:31731 [D loss: 0.237704, acc.: 57.03%] [G loss: 0.296524]\n",
      "epoch:33 step:31732 [D loss: 0.244983, acc.: 58.59%] [G loss: 0.308536]\n",
      "epoch:33 step:31733 [D loss: 0.239001, acc.: 58.59%] [G loss: 0.276171]\n",
      "epoch:33 step:31734 [D loss: 0.241237, acc.: 59.38%] [G loss: 0.307450]\n",
      "epoch:33 step:31735 [D loss: 0.239611, acc.: 57.03%] [G loss: 0.279654]\n",
      "epoch:33 step:31736 [D loss: 0.248920, acc.: 53.12%] [G loss: 0.274842]\n",
      "epoch:33 step:31737 [D loss: 0.215483, acc.: 69.53%] [G loss: 0.312056]\n",
      "epoch:33 step:31738 [D loss: 0.222221, acc.: 65.62%] [G loss: 0.315778]\n",
      "epoch:33 step:31739 [D loss: 0.237049, acc.: 59.38%] [G loss: 0.305603]\n",
      "epoch:33 step:31740 [D loss: 0.239443, acc.: 57.03%] [G loss: 0.288196]\n",
      "epoch:33 step:31741 [D loss: 0.222761, acc.: 62.50%] [G loss: 0.302717]\n",
      "epoch:33 step:31742 [D loss: 0.261425, acc.: 44.53%] [G loss: 0.294105]\n",
      "epoch:33 step:31743 [D loss: 0.245652, acc.: 57.03%] [G loss: 0.314944]\n",
      "epoch:33 step:31744 [D loss: 0.254220, acc.: 53.91%] [G loss: 0.308598]\n",
      "epoch:33 step:31745 [D loss: 0.232543, acc.: 60.94%] [G loss: 0.327741]\n",
      "epoch:33 step:31746 [D loss: 0.241893, acc.: 58.59%] [G loss: 0.327616]\n",
      "epoch:33 step:31747 [D loss: 0.258572, acc.: 50.00%] [G loss: 0.294625]\n",
      "epoch:33 step:31748 [D loss: 0.249439, acc.: 53.91%] [G loss: 0.287954]\n",
      "epoch:33 step:31749 [D loss: 0.249388, acc.: 55.47%] [G loss: 0.285816]\n",
      "epoch:33 step:31750 [D loss: 0.226218, acc.: 62.50%] [G loss: 0.312362]\n",
      "epoch:33 step:31751 [D loss: 0.235323, acc.: 59.38%] [G loss: 0.278464]\n",
      "epoch:33 step:31752 [D loss: 0.237046, acc.: 60.16%] [G loss: 0.279148]\n",
      "epoch:33 step:31753 [D loss: 0.246234, acc.: 56.25%] [G loss: 0.314691]\n",
      "epoch:33 step:31754 [D loss: 0.231668, acc.: 63.28%] [G loss: 0.317702]\n",
      "epoch:33 step:31755 [D loss: 0.236709, acc.: 58.59%] [G loss: 0.316541]\n",
      "epoch:33 step:31756 [D loss: 0.235731, acc.: 60.16%] [G loss: 0.289984]\n",
      "epoch:33 step:31757 [D loss: 0.248913, acc.: 53.12%] [G loss: 0.305314]\n",
      "epoch:33 step:31758 [D loss: 0.237120, acc.: 61.72%] [G loss: 0.315168]\n",
      "epoch:33 step:31759 [D loss: 0.244475, acc.: 57.03%] [G loss: 0.304043]\n",
      "epoch:33 step:31760 [D loss: 0.250719, acc.: 55.47%] [G loss: 0.311553]\n",
      "epoch:33 step:31761 [D loss: 0.244417, acc.: 55.47%] [G loss: 0.306771]\n",
      "epoch:33 step:31762 [D loss: 0.247993, acc.: 56.25%] [G loss: 0.291831]\n",
      "epoch:33 step:31763 [D loss: 0.236805, acc.: 58.59%] [G loss: 0.305018]\n",
      "epoch:33 step:31764 [D loss: 0.243687, acc.: 57.03%] [G loss: 0.295452]\n",
      "epoch:33 step:31765 [D loss: 0.231311, acc.: 63.28%] [G loss: 0.309338]\n",
      "epoch:33 step:31766 [D loss: 0.242876, acc.: 56.25%] [G loss: 0.292446]\n",
      "epoch:33 step:31767 [D loss: 0.245523, acc.: 49.22%] [G loss: 0.297725]\n",
      "epoch:33 step:31768 [D loss: 0.233197, acc.: 64.06%] [G loss: 0.305223]\n",
      "epoch:33 step:31769 [D loss: 0.225784, acc.: 58.59%] [G loss: 0.315421]\n",
      "epoch:33 step:31770 [D loss: 0.231024, acc.: 60.16%] [G loss: 0.300864]\n",
      "epoch:33 step:31771 [D loss: 0.225093, acc.: 66.41%] [G loss: 0.277324]\n",
      "epoch:33 step:31772 [D loss: 0.238460, acc.: 60.94%] [G loss: 0.293930]\n",
      "epoch:33 step:31773 [D loss: 0.216446, acc.: 65.62%] [G loss: 0.321791]\n",
      "epoch:33 step:31774 [D loss: 0.243293, acc.: 59.38%] [G loss: 0.312664]\n",
      "epoch:33 step:31775 [D loss: 0.237250, acc.: 60.94%] [G loss: 0.285985]\n",
      "epoch:33 step:31776 [D loss: 0.248125, acc.: 57.81%] [G loss: 0.310999]\n",
      "epoch:33 step:31777 [D loss: 0.234205, acc.: 61.72%] [G loss: 0.273961]\n",
      "epoch:33 step:31778 [D loss: 0.232170, acc.: 62.50%] [G loss: 0.330755]\n",
      "epoch:33 step:31779 [D loss: 0.234496, acc.: 58.59%] [G loss: 0.307805]\n",
      "epoch:33 step:31780 [D loss: 0.239901, acc.: 56.25%] [G loss: 0.302193]\n",
      "epoch:33 step:31781 [D loss: 0.232758, acc.: 57.03%] [G loss: 0.291312]\n",
      "epoch:33 step:31782 [D loss: 0.241130, acc.: 56.25%] [G loss: 0.287521]\n",
      "epoch:33 step:31783 [D loss: 0.230355, acc.: 60.94%] [G loss: 0.327722]\n",
      "epoch:33 step:31784 [D loss: 0.240709, acc.: 55.47%] [G loss: 0.307157]\n",
      "epoch:33 step:31785 [D loss: 0.244011, acc.: 57.81%] [G loss: 0.341038]\n",
      "epoch:33 step:31786 [D loss: 0.237813, acc.: 60.16%] [G loss: 0.283792]\n",
      "epoch:33 step:31787 [D loss: 0.245885, acc.: 54.69%] [G loss: 0.293557]\n",
      "epoch:33 step:31788 [D loss: 0.258546, acc.: 55.47%] [G loss: 0.295487]\n",
      "epoch:33 step:31789 [D loss: 0.240866, acc.: 58.59%] [G loss: 0.320621]\n",
      "epoch:33 step:31790 [D loss: 0.244886, acc.: 54.69%] [G loss: 0.319744]\n",
      "epoch:33 step:31791 [D loss: 0.244083, acc.: 54.69%] [G loss: 0.305122]\n",
      "epoch:33 step:31792 [D loss: 0.236116, acc.: 61.72%] [G loss: 0.308656]\n",
      "epoch:33 step:31793 [D loss: 0.242646, acc.: 57.81%] [G loss: 0.310227]\n",
      "epoch:33 step:31794 [D loss: 0.242812, acc.: 56.25%] [G loss: 0.290947]\n",
      "epoch:33 step:31795 [D loss: 0.234422, acc.: 61.72%] [G loss: 0.307908]\n",
      "epoch:33 step:31796 [D loss: 0.230350, acc.: 58.59%] [G loss: 0.308326]\n",
      "epoch:33 step:31797 [D loss: 0.233852, acc.: 62.50%] [G loss: 0.282577]\n",
      "epoch:33 step:31798 [D loss: 0.236528, acc.: 57.03%] [G loss: 0.295630]\n",
      "epoch:33 step:31799 [D loss: 0.232272, acc.: 64.06%] [G loss: 0.305601]\n",
      "epoch:33 step:31800 [D loss: 0.251119, acc.: 51.56%] [G loss: 0.299654]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:33 step:31801 [D loss: 0.228912, acc.: 66.41%] [G loss: 0.285728]\n",
      "epoch:33 step:31802 [D loss: 0.240068, acc.: 60.94%] [G loss: 0.281216]\n",
      "epoch:33 step:31803 [D loss: 0.212111, acc.: 68.75%] [G loss: 0.312071]\n",
      "epoch:33 step:31804 [D loss: 0.234620, acc.: 61.72%] [G loss: 0.303102]\n",
      "epoch:33 step:31805 [D loss: 0.237625, acc.: 60.16%] [G loss: 0.291318]\n",
      "epoch:33 step:31806 [D loss: 0.239704, acc.: 58.59%] [G loss: 0.310804]\n",
      "epoch:33 step:31807 [D loss: 0.237930, acc.: 60.16%] [G loss: 0.309816]\n",
      "epoch:33 step:31808 [D loss: 0.241528, acc.: 60.94%] [G loss: 0.298582]\n",
      "epoch:33 step:31809 [D loss: 0.237334, acc.: 57.03%] [G loss: 0.283587]\n",
      "epoch:33 step:31810 [D loss: 0.237789, acc.: 57.81%] [G loss: 0.307446]\n",
      "epoch:33 step:31811 [D loss: 0.246793, acc.: 56.25%] [G loss: 0.301785]\n",
      "epoch:33 step:31812 [D loss: 0.247739, acc.: 51.56%] [G loss: 0.317420]\n",
      "epoch:33 step:31813 [D loss: 0.250428, acc.: 53.12%] [G loss: 0.300939]\n",
      "epoch:33 step:31814 [D loss: 0.242360, acc.: 60.94%] [G loss: 0.274887]\n",
      "epoch:33 step:31815 [D loss: 0.251735, acc.: 53.12%] [G loss: 0.297253]\n",
      "epoch:33 step:31816 [D loss: 0.248443, acc.: 59.38%] [G loss: 0.308929]\n",
      "epoch:33 step:31817 [D loss: 0.226762, acc.: 65.62%] [G loss: 0.287348]\n",
      "epoch:33 step:31818 [D loss: 0.221198, acc.: 67.97%] [G loss: 0.330961]\n",
      "epoch:33 step:31819 [D loss: 0.214935, acc.: 70.31%] [G loss: 0.316000]\n",
      "epoch:33 step:31820 [D loss: 0.235754, acc.: 60.16%] [G loss: 0.281992]\n",
      "epoch:33 step:31821 [D loss: 0.223536, acc.: 63.28%] [G loss: 0.312639]\n",
      "epoch:33 step:31822 [D loss: 0.237128, acc.: 57.81%] [G loss: 0.322754]\n",
      "epoch:33 step:31823 [D loss: 0.240924, acc.: 59.38%] [G loss: 0.279206]\n",
      "epoch:33 step:31824 [D loss: 0.220562, acc.: 63.28%] [G loss: 0.323123]\n",
      "epoch:33 step:31825 [D loss: 0.229701, acc.: 60.94%] [G loss: 0.320036]\n",
      "epoch:33 step:31826 [D loss: 0.243053, acc.: 54.69%] [G loss: 0.333686]\n",
      "epoch:33 step:31827 [D loss: 0.234607, acc.: 57.03%] [G loss: 0.302509]\n",
      "epoch:33 step:31828 [D loss: 0.239896, acc.: 55.47%] [G loss: 0.293305]\n",
      "epoch:33 step:31829 [D loss: 0.244496, acc.: 58.59%] [G loss: 0.302663]\n",
      "epoch:33 step:31830 [D loss: 0.250567, acc.: 55.47%] [G loss: 0.319771]\n",
      "epoch:33 step:31831 [D loss: 0.257036, acc.: 56.25%] [G loss: 0.288165]\n",
      "epoch:33 step:31832 [D loss: 0.238888, acc.: 54.69%] [G loss: 0.293160]\n",
      "epoch:33 step:31833 [D loss: 0.240373, acc.: 55.47%] [G loss: 0.291311]\n",
      "epoch:33 step:31834 [D loss: 0.232026, acc.: 59.38%] [G loss: 0.311763]\n",
      "epoch:33 step:31835 [D loss: 0.224916, acc.: 63.28%] [G loss: 0.348111]\n",
      "epoch:33 step:31836 [D loss: 0.237231, acc.: 57.81%] [G loss: 0.303854]\n",
      "epoch:33 step:31837 [D loss: 0.243788, acc.: 57.81%] [G loss: 0.305357]\n",
      "epoch:33 step:31838 [D loss: 0.242333, acc.: 56.25%] [G loss: 0.322864]\n",
      "epoch:33 step:31839 [D loss: 0.257318, acc.: 53.12%] [G loss: 0.285514]\n",
      "epoch:33 step:31840 [D loss: 0.212763, acc.: 68.75%] [G loss: 0.325770]\n",
      "epoch:33 step:31841 [D loss: 0.242083, acc.: 59.38%] [G loss: 0.275138]\n",
      "epoch:33 step:31842 [D loss: 0.237633, acc.: 60.94%] [G loss: 0.304503]\n",
      "epoch:33 step:31843 [D loss: 0.254775, acc.: 52.34%] [G loss: 0.300506]\n",
      "epoch:33 step:31844 [D loss: 0.237173, acc.: 57.03%] [G loss: 0.285318]\n",
      "epoch:33 step:31845 [D loss: 0.231508, acc.: 61.72%] [G loss: 0.329381]\n",
      "epoch:33 step:31846 [D loss: 0.247287, acc.: 56.25%] [G loss: 0.326820]\n",
      "epoch:33 step:31847 [D loss: 0.242831, acc.: 60.16%] [G loss: 0.288914]\n",
      "epoch:33 step:31848 [D loss: 0.247999, acc.: 50.00%] [G loss: 0.289962]\n",
      "epoch:33 step:31849 [D loss: 0.226146, acc.: 65.62%] [G loss: 0.300002]\n",
      "epoch:33 step:31850 [D loss: 0.258864, acc.: 57.03%] [G loss: 0.308753]\n",
      "epoch:33 step:31851 [D loss: 0.253056, acc.: 57.03%] [G loss: 0.296761]\n",
      "epoch:33 step:31852 [D loss: 0.244458, acc.: 56.25%] [G loss: 0.295932]\n",
      "epoch:33 step:31853 [D loss: 0.224903, acc.: 66.41%] [G loss: 0.311251]\n",
      "epoch:33 step:31854 [D loss: 0.230665, acc.: 62.50%] [G loss: 0.259342]\n",
      "epoch:33 step:31855 [D loss: 0.229013, acc.: 64.06%] [G loss: 0.296019]\n",
      "epoch:33 step:31856 [D loss: 0.246041, acc.: 53.91%] [G loss: 0.307012]\n",
      "epoch:33 step:31857 [D loss: 0.247395, acc.: 56.25%] [G loss: 0.283013]\n",
      "epoch:33 step:31858 [D loss: 0.252707, acc.: 55.47%] [G loss: 0.287094]\n",
      "epoch:34 step:31859 [D loss: 0.238152, acc.: 60.16%] [G loss: 0.303392]\n",
      "epoch:34 step:31860 [D loss: 0.236233, acc.: 55.47%] [G loss: 0.297133]\n",
      "epoch:34 step:31861 [D loss: 0.234126, acc.: 60.94%] [G loss: 0.316176]\n",
      "epoch:34 step:31862 [D loss: 0.234536, acc.: 60.16%] [G loss: 0.290707]\n",
      "epoch:34 step:31863 [D loss: 0.220738, acc.: 65.62%] [G loss: 0.305353]\n",
      "epoch:34 step:31864 [D loss: 0.265323, acc.: 43.75%] [G loss: 0.302307]\n",
      "epoch:34 step:31865 [D loss: 0.252400, acc.: 53.12%] [G loss: 0.305326]\n",
      "epoch:34 step:31866 [D loss: 0.229863, acc.: 54.69%] [G loss: 0.319914]\n",
      "epoch:34 step:31867 [D loss: 0.240900, acc.: 59.38%] [G loss: 0.258797]\n",
      "epoch:34 step:31868 [D loss: 0.251621, acc.: 53.91%] [G loss: 0.292460]\n",
      "epoch:34 step:31869 [D loss: 0.228254, acc.: 60.16%] [G loss: 0.308222]\n",
      "epoch:34 step:31870 [D loss: 0.236888, acc.: 57.81%] [G loss: 0.302549]\n",
      "epoch:34 step:31871 [D loss: 0.251002, acc.: 57.81%] [G loss: 0.261786]\n",
      "epoch:34 step:31872 [D loss: 0.233953, acc.: 64.84%] [G loss: 0.307605]\n",
      "epoch:34 step:31873 [D loss: 0.237708, acc.: 54.69%] [G loss: 0.304455]\n",
      "epoch:34 step:31874 [D loss: 0.233037, acc.: 64.06%] [G loss: 0.280820]\n",
      "epoch:34 step:31875 [D loss: 0.235522, acc.: 60.16%] [G loss: 0.314400]\n",
      "epoch:34 step:31876 [D loss: 0.239341, acc.: 57.03%] [G loss: 0.301642]\n",
      "epoch:34 step:31877 [D loss: 0.242337, acc.: 51.56%] [G loss: 0.301331]\n",
      "epoch:34 step:31878 [D loss: 0.246214, acc.: 56.25%] [G loss: 0.299243]\n",
      "epoch:34 step:31879 [D loss: 0.234966, acc.: 61.72%] [G loss: 0.329762]\n",
      "epoch:34 step:31880 [D loss: 0.236389, acc.: 57.81%] [G loss: 0.310033]\n",
      "epoch:34 step:31881 [D loss: 0.244725, acc.: 53.91%] [G loss: 0.311036]\n",
      "epoch:34 step:31882 [D loss: 0.230799, acc.: 58.59%] [G loss: 0.285339]\n",
      "epoch:34 step:31883 [D loss: 0.240982, acc.: 52.34%] [G loss: 0.276846]\n",
      "epoch:34 step:31884 [D loss: 0.250996, acc.: 55.47%] [G loss: 0.298364]\n",
      "epoch:34 step:31885 [D loss: 0.234277, acc.: 61.72%] [G loss: 0.290284]\n",
      "epoch:34 step:31886 [D loss: 0.255697, acc.: 47.66%] [G loss: 0.285246]\n",
      "epoch:34 step:31887 [D loss: 0.248827, acc.: 57.81%] [G loss: 0.310324]\n",
      "epoch:34 step:31888 [D loss: 0.249545, acc.: 57.03%] [G loss: 0.297741]\n",
      "epoch:34 step:31889 [D loss: 0.245102, acc.: 54.69%] [G loss: 0.284345]\n",
      "epoch:34 step:31890 [D loss: 0.235804, acc.: 57.81%] [G loss: 0.296671]\n",
      "epoch:34 step:31891 [D loss: 0.234322, acc.: 60.16%] [G loss: 0.272218]\n",
      "epoch:34 step:31892 [D loss: 0.226764, acc.: 64.84%] [G loss: 0.337850]\n",
      "epoch:34 step:31893 [D loss: 0.223552, acc.: 64.84%] [G loss: 0.302116]\n",
      "epoch:34 step:31894 [D loss: 0.234322, acc.: 62.50%] [G loss: 0.304012]\n",
      "epoch:34 step:31895 [D loss: 0.220973, acc.: 70.31%] [G loss: 0.283798]\n",
      "epoch:34 step:31896 [D loss: 0.234066, acc.: 63.28%] [G loss: 0.300137]\n",
      "epoch:34 step:31897 [D loss: 0.245510, acc.: 51.56%] [G loss: 0.287106]\n",
      "epoch:34 step:31898 [D loss: 0.233291, acc.: 58.59%] [G loss: 0.328271]\n",
      "epoch:34 step:31899 [D loss: 0.241244, acc.: 59.38%] [G loss: 0.304104]\n",
      "epoch:34 step:31900 [D loss: 0.229028, acc.: 63.28%] [G loss: 0.291202]\n",
      "epoch:34 step:31901 [D loss: 0.235852, acc.: 58.59%] [G loss: 0.292324]\n",
      "epoch:34 step:31902 [D loss: 0.241129, acc.: 62.50%] [G loss: 0.309327]\n",
      "epoch:34 step:31903 [D loss: 0.229366, acc.: 57.81%] [G loss: 0.292316]\n",
      "epoch:34 step:31904 [D loss: 0.253754, acc.: 52.34%] [G loss: 0.273656]\n",
      "epoch:34 step:31905 [D loss: 0.243886, acc.: 56.25%] [G loss: 0.304190]\n",
      "epoch:34 step:31906 [D loss: 0.243432, acc.: 58.59%] [G loss: 0.308673]\n",
      "epoch:34 step:31907 [D loss: 0.249356, acc.: 58.59%] [G loss: 0.311408]\n",
      "epoch:34 step:31908 [D loss: 0.246082, acc.: 54.69%] [G loss: 0.291394]\n",
      "epoch:34 step:31909 [D loss: 0.233488, acc.: 62.50%] [G loss: 0.293470]\n",
      "epoch:34 step:31910 [D loss: 0.243600, acc.: 53.91%] [G loss: 0.293252]\n",
      "epoch:34 step:31911 [D loss: 0.227695, acc.: 57.81%] [G loss: 0.309287]\n",
      "epoch:34 step:31912 [D loss: 0.257903, acc.: 52.34%] [G loss: 0.301211]\n",
      "epoch:34 step:31913 [D loss: 0.245369, acc.: 57.03%] [G loss: 0.304121]\n",
      "epoch:34 step:31914 [D loss: 0.249870, acc.: 53.91%] [G loss: 0.265613]\n",
      "epoch:34 step:31915 [D loss: 0.242623, acc.: 58.59%] [G loss: 0.314016]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:34 step:31916 [D loss: 0.233649, acc.: 58.59%] [G loss: 0.300781]\n",
      "epoch:34 step:31917 [D loss: 0.230604, acc.: 57.03%] [G loss: 0.331601]\n",
      "epoch:34 step:31918 [D loss: 0.236335, acc.: 55.47%] [G loss: 0.324574]\n",
      "epoch:34 step:31919 [D loss: 0.227836, acc.: 61.72%] [G loss: 0.315314]\n",
      "epoch:34 step:31920 [D loss: 0.253435, acc.: 54.69%] [G loss: 0.282754]\n",
      "epoch:34 step:31921 [D loss: 0.240373, acc.: 60.16%] [G loss: 0.286520]\n",
      "epoch:34 step:31922 [D loss: 0.240064, acc.: 54.69%] [G loss: 0.292544]\n",
      "epoch:34 step:31923 [D loss: 0.226804, acc.: 64.06%] [G loss: 0.323755]\n",
      "epoch:34 step:31924 [D loss: 0.235912, acc.: 59.38%] [G loss: 0.332145]\n",
      "epoch:34 step:31925 [D loss: 0.263545, acc.: 51.56%] [G loss: 0.286288]\n",
      "epoch:34 step:31926 [D loss: 0.258371, acc.: 53.91%] [G loss: 0.294102]\n",
      "epoch:34 step:31927 [D loss: 0.229702, acc.: 58.59%] [G loss: 0.321457]\n",
      "epoch:34 step:31928 [D loss: 0.243561, acc.: 57.03%] [G loss: 0.294252]\n",
      "epoch:34 step:31929 [D loss: 0.240273, acc.: 57.81%] [G loss: 0.285516]\n",
      "epoch:34 step:31930 [D loss: 0.219768, acc.: 64.84%] [G loss: 0.291562]\n",
      "epoch:34 step:31931 [D loss: 0.240909, acc.: 58.59%] [G loss: 0.309104]\n",
      "epoch:34 step:31932 [D loss: 0.253468, acc.: 53.91%] [G loss: 0.274972]\n",
      "epoch:34 step:31933 [D loss: 0.254996, acc.: 51.56%] [G loss: 0.305387]\n",
      "epoch:34 step:31934 [D loss: 0.240621, acc.: 61.72%] [G loss: 0.297945]\n",
      "epoch:34 step:31935 [D loss: 0.244453, acc.: 56.25%] [G loss: 0.306016]\n",
      "epoch:34 step:31936 [D loss: 0.258465, acc.: 51.56%] [G loss: 0.295551]\n",
      "epoch:34 step:31937 [D loss: 0.244493, acc.: 58.59%] [G loss: 0.300252]\n",
      "epoch:34 step:31938 [D loss: 0.225790, acc.: 58.59%] [G loss: 0.303875]\n",
      "epoch:34 step:31939 [D loss: 0.225860, acc.: 65.62%] [G loss: 0.285826]\n",
      "epoch:34 step:31940 [D loss: 0.224564, acc.: 60.16%] [G loss: 0.333604]\n",
      "epoch:34 step:31941 [D loss: 0.253121, acc.: 56.25%] [G loss: 0.321560]\n",
      "epoch:34 step:31942 [D loss: 0.236869, acc.: 63.28%] [G loss: 0.293250]\n",
      "epoch:34 step:31943 [D loss: 0.230693, acc.: 60.94%] [G loss: 0.307221]\n",
      "epoch:34 step:31944 [D loss: 0.262253, acc.: 51.56%] [G loss: 0.286158]\n",
      "epoch:34 step:31945 [D loss: 0.235574, acc.: 58.59%] [G loss: 0.319838]\n",
      "epoch:34 step:31946 [D loss: 0.243321, acc.: 55.47%] [G loss: 0.336471]\n",
      "epoch:34 step:31947 [D loss: 0.251003, acc.: 56.25%] [G loss: 0.284571]\n",
      "epoch:34 step:31948 [D loss: 0.251924, acc.: 53.12%] [G loss: 0.318941]\n",
      "epoch:34 step:31949 [D loss: 0.229759, acc.: 61.72%] [G loss: 0.311132]\n",
      "epoch:34 step:31950 [D loss: 0.226440, acc.: 68.75%] [G loss: 0.310230]\n",
      "epoch:34 step:31951 [D loss: 0.233763, acc.: 56.25%] [G loss: 0.315619]\n",
      "epoch:34 step:31952 [D loss: 0.234850, acc.: 61.72%] [G loss: 0.305300]\n",
      "epoch:34 step:31953 [D loss: 0.243334, acc.: 57.81%] [G loss: 0.303498]\n",
      "epoch:34 step:31954 [D loss: 0.239857, acc.: 56.25%] [G loss: 0.295963]\n",
      "epoch:34 step:31955 [D loss: 0.264003, acc.: 50.78%] [G loss: 0.274668]\n",
      "epoch:34 step:31956 [D loss: 0.221050, acc.: 64.06%] [G loss: 0.300785]\n",
      "epoch:34 step:31957 [D loss: 0.231257, acc.: 60.16%] [G loss: 0.260911]\n",
      "epoch:34 step:31958 [D loss: 0.241140, acc.: 55.47%] [G loss: 0.303524]\n",
      "epoch:34 step:31959 [D loss: 0.251865, acc.: 53.12%] [G loss: 0.305032]\n",
      "epoch:34 step:31960 [D loss: 0.242245, acc.: 53.91%] [G loss: 0.304519]\n",
      "epoch:34 step:31961 [D loss: 0.254968, acc.: 51.56%] [G loss: 0.306740]\n",
      "epoch:34 step:31962 [D loss: 0.250236, acc.: 52.34%] [G loss: 0.282475]\n",
      "epoch:34 step:31963 [D loss: 0.244416, acc.: 57.81%] [G loss: 0.288150]\n",
      "epoch:34 step:31964 [D loss: 0.253815, acc.: 48.44%] [G loss: 0.299321]\n",
      "epoch:34 step:31965 [D loss: 0.234917, acc.: 64.06%] [G loss: 0.299383]\n",
      "epoch:34 step:31966 [D loss: 0.217223, acc.: 60.94%] [G loss: 0.301261]\n",
      "epoch:34 step:31967 [D loss: 0.233340, acc.: 59.38%] [G loss: 0.304196]\n",
      "epoch:34 step:31968 [D loss: 0.249174, acc.: 55.47%] [G loss: 0.280383]\n",
      "epoch:34 step:31969 [D loss: 0.226431, acc.: 64.06%] [G loss: 0.309785]\n",
      "epoch:34 step:31970 [D loss: 0.246396, acc.: 56.25%] [G loss: 0.317211]\n",
      "epoch:34 step:31971 [D loss: 0.247340, acc.: 53.12%] [G loss: 0.285194]\n",
      "epoch:34 step:31972 [D loss: 0.235612, acc.: 56.25%] [G loss: 0.305190]\n",
      "epoch:34 step:31973 [D loss: 0.249785, acc.: 54.69%] [G loss: 0.314738]\n",
      "epoch:34 step:31974 [D loss: 0.256822, acc.: 54.69%] [G loss: 0.299062]\n",
      "epoch:34 step:31975 [D loss: 0.224166, acc.: 61.72%] [G loss: 0.297835]\n",
      "epoch:34 step:31976 [D loss: 0.249352, acc.: 56.25%] [G loss: 0.322205]\n",
      "epoch:34 step:31977 [D loss: 0.265298, acc.: 50.78%] [G loss: 0.298229]\n",
      "epoch:34 step:31978 [D loss: 0.245242, acc.: 52.34%] [G loss: 0.315148]\n",
      "epoch:34 step:31979 [D loss: 0.237820, acc.: 56.25%] [G loss: 0.298959]\n",
      "epoch:34 step:31980 [D loss: 0.239281, acc.: 58.59%] [G loss: 0.285973]\n",
      "epoch:34 step:31981 [D loss: 0.235881, acc.: 57.81%] [G loss: 0.271455]\n",
      "epoch:34 step:31982 [D loss: 0.244289, acc.: 58.59%] [G loss: 0.326270]\n",
      "epoch:34 step:31983 [D loss: 0.214028, acc.: 67.19%] [G loss: 0.304973]\n",
      "epoch:34 step:31984 [D loss: 0.237236, acc.: 60.16%] [G loss: 0.346875]\n",
      "epoch:34 step:31985 [D loss: 0.223145, acc.: 66.41%] [G loss: 0.313640]\n",
      "epoch:34 step:31986 [D loss: 0.233044, acc.: 60.94%] [G loss: 0.283578]\n",
      "epoch:34 step:31987 [D loss: 0.246967, acc.: 53.12%] [G loss: 0.297452]\n",
      "epoch:34 step:31988 [D loss: 0.221823, acc.: 64.84%] [G loss: 0.291294]\n",
      "epoch:34 step:31989 [D loss: 0.237608, acc.: 60.94%] [G loss: 0.301700]\n",
      "epoch:34 step:31990 [D loss: 0.243327, acc.: 55.47%] [G loss: 0.312936]\n",
      "epoch:34 step:31991 [D loss: 0.243624, acc.: 62.50%] [G loss: 0.293373]\n",
      "epoch:34 step:31992 [D loss: 0.225860, acc.: 60.94%] [G loss: 0.291289]\n",
      "epoch:34 step:31993 [D loss: 0.234117, acc.: 55.47%] [G loss: 0.304701]\n",
      "epoch:34 step:31994 [D loss: 0.273405, acc.: 46.09%] [G loss: 0.275966]\n",
      "epoch:34 step:31995 [D loss: 0.238190, acc.: 57.03%] [G loss: 0.344982]\n",
      "epoch:34 step:31996 [D loss: 0.260280, acc.: 50.00%] [G loss: 0.309424]\n",
      "epoch:34 step:31997 [D loss: 0.253309, acc.: 52.34%] [G loss: 0.323790]\n",
      "epoch:34 step:31998 [D loss: 0.239515, acc.: 60.16%] [G loss: 0.296938]\n",
      "epoch:34 step:31999 [D loss: 0.236921, acc.: 58.59%] [G loss: 0.310209]\n",
      "epoch:34 step:32000 [D loss: 0.251091, acc.: 55.47%] [G loss: 0.303827]\n",
      "epoch:34 step:32001 [D loss: 0.239031, acc.: 62.50%] [G loss: 0.303764]\n",
      "epoch:34 step:32002 [D loss: 0.243145, acc.: 54.69%] [G loss: 0.308307]\n",
      "epoch:34 step:32003 [D loss: 0.244909, acc.: 58.59%] [G loss: 0.303489]\n",
      "epoch:34 step:32004 [D loss: 0.246538, acc.: 58.59%] [G loss: 0.289088]\n",
      "epoch:34 step:32005 [D loss: 0.244815, acc.: 54.69%] [G loss: 0.324348]\n",
      "epoch:34 step:32006 [D loss: 0.220686, acc.: 57.03%] [G loss: 0.302381]\n",
      "epoch:34 step:32007 [D loss: 0.228492, acc.: 62.50%] [G loss: 0.329659]\n",
      "epoch:34 step:32008 [D loss: 0.226378, acc.: 60.16%] [G loss: 0.296797]\n",
      "epoch:34 step:32009 [D loss: 0.246588, acc.: 56.25%] [G loss: 0.290947]\n",
      "epoch:34 step:32010 [D loss: 0.247298, acc.: 57.03%] [G loss: 0.293442]\n",
      "epoch:34 step:32011 [D loss: 0.221544, acc.: 63.28%] [G loss: 0.288746]\n",
      "epoch:34 step:32012 [D loss: 0.244905, acc.: 53.91%] [G loss: 0.290559]\n",
      "epoch:34 step:32013 [D loss: 0.236415, acc.: 61.72%] [G loss: 0.320940]\n",
      "epoch:34 step:32014 [D loss: 0.258783, acc.: 48.44%] [G loss: 0.284319]\n",
      "epoch:34 step:32015 [D loss: 0.236219, acc.: 57.03%] [G loss: 0.298456]\n",
      "epoch:34 step:32016 [D loss: 0.238839, acc.: 59.38%] [G loss: 0.270583]\n",
      "epoch:34 step:32017 [D loss: 0.214987, acc.: 68.75%] [G loss: 0.320553]\n",
      "epoch:34 step:32018 [D loss: 0.242960, acc.: 54.69%] [G loss: 0.298228]\n",
      "epoch:34 step:32019 [D loss: 0.254226, acc.: 57.81%] [G loss: 0.293986]\n",
      "epoch:34 step:32020 [D loss: 0.248444, acc.: 53.12%] [G loss: 0.324834]\n",
      "epoch:34 step:32021 [D loss: 0.235216, acc.: 60.16%] [G loss: 0.337400]\n",
      "epoch:34 step:32022 [D loss: 0.236167, acc.: 62.50%] [G loss: 0.271959]\n",
      "epoch:34 step:32023 [D loss: 0.236479, acc.: 62.50%] [G loss: 0.293773]\n",
      "epoch:34 step:32024 [D loss: 0.250935, acc.: 50.00%] [G loss: 0.316860]\n",
      "epoch:34 step:32025 [D loss: 0.224398, acc.: 59.38%] [G loss: 0.293393]\n",
      "epoch:34 step:32026 [D loss: 0.252374, acc.: 52.34%] [G loss: 0.297461]\n",
      "epoch:34 step:32027 [D loss: 0.228392, acc.: 60.94%] [G loss: 0.287096]\n",
      "epoch:34 step:32028 [D loss: 0.225493, acc.: 67.19%] [G loss: 0.280953]\n",
      "epoch:34 step:32029 [D loss: 0.253154, acc.: 56.25%] [G loss: 0.292845]\n",
      "epoch:34 step:32030 [D loss: 0.233318, acc.: 58.59%] [G loss: 0.348380]\n",
      "epoch:34 step:32031 [D loss: 0.237942, acc.: 58.59%] [G loss: 0.338096]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:34 step:32032 [D loss: 0.227370, acc.: 67.19%] [G loss: 0.336896]\n",
      "epoch:34 step:32033 [D loss: 0.258856, acc.: 50.78%] [G loss: 0.315319]\n",
      "epoch:34 step:32034 [D loss: 0.236946, acc.: 60.94%] [G loss: 0.298476]\n",
      "epoch:34 step:32035 [D loss: 0.222600, acc.: 66.41%] [G loss: 0.275028]\n",
      "epoch:34 step:32036 [D loss: 0.230056, acc.: 61.72%] [G loss: 0.329169]\n",
      "epoch:34 step:32037 [D loss: 0.246209, acc.: 57.03%] [G loss: 0.319834]\n",
      "epoch:34 step:32038 [D loss: 0.250168, acc.: 51.56%] [G loss: 0.308482]\n",
      "epoch:34 step:32039 [D loss: 0.225501, acc.: 64.06%] [G loss: 0.322473]\n",
      "epoch:34 step:32040 [D loss: 0.250183, acc.: 54.69%] [G loss: 0.303377]\n",
      "epoch:34 step:32041 [D loss: 0.260549, acc.: 52.34%] [G loss: 0.334252]\n",
      "epoch:34 step:32042 [D loss: 0.236748, acc.: 53.91%] [G loss: 0.304657]\n",
      "epoch:34 step:32043 [D loss: 0.227320, acc.: 58.59%] [G loss: 0.322620]\n",
      "epoch:34 step:32044 [D loss: 0.226107, acc.: 65.62%] [G loss: 0.335524]\n",
      "epoch:34 step:32045 [D loss: 0.238174, acc.: 57.03%] [G loss: 0.303375]\n",
      "epoch:34 step:32046 [D loss: 0.248032, acc.: 55.47%] [G loss: 0.275572]\n",
      "epoch:34 step:32047 [D loss: 0.234593, acc.: 59.38%] [G loss: 0.309723]\n",
      "epoch:34 step:32048 [D loss: 0.241003, acc.: 61.72%] [G loss: 0.316259]\n",
      "epoch:34 step:32049 [D loss: 0.220923, acc.: 64.06%] [G loss: 0.288510]\n",
      "epoch:34 step:32050 [D loss: 0.249124, acc.: 60.16%] [G loss: 0.300377]\n",
      "epoch:34 step:32051 [D loss: 0.238709, acc.: 59.38%] [G loss: 0.337012]\n",
      "epoch:34 step:32052 [D loss: 0.239999, acc.: 57.81%] [G loss: 0.321840]\n",
      "epoch:34 step:32053 [D loss: 0.234414, acc.: 62.50%] [G loss: 0.317107]\n",
      "epoch:34 step:32054 [D loss: 0.248958, acc.: 53.91%] [G loss: 0.284152]\n",
      "epoch:34 step:32055 [D loss: 0.247783, acc.: 58.59%] [G loss: 0.274560]\n",
      "epoch:34 step:32056 [D loss: 0.229479, acc.: 62.50%] [G loss: 0.295421]\n",
      "epoch:34 step:32057 [D loss: 0.225239, acc.: 64.06%] [G loss: 0.294394]\n",
      "epoch:34 step:32058 [D loss: 0.263088, acc.: 53.12%] [G loss: 0.291060]\n",
      "epoch:34 step:32059 [D loss: 0.239481, acc.: 56.25%] [G loss: 0.289610]\n",
      "epoch:34 step:32060 [D loss: 0.229645, acc.: 59.38%] [G loss: 0.311891]\n",
      "epoch:34 step:32061 [D loss: 0.234571, acc.: 59.38%] [G loss: 0.289618]\n",
      "epoch:34 step:32062 [D loss: 0.225642, acc.: 60.94%] [G loss: 0.297586]\n",
      "epoch:34 step:32063 [D loss: 0.234689, acc.: 62.50%] [G loss: 0.294156]\n",
      "epoch:34 step:32064 [D loss: 0.264271, acc.: 50.00%] [G loss: 0.310763]\n",
      "epoch:34 step:32065 [D loss: 0.231840, acc.: 59.38%] [G loss: 0.319164]\n",
      "epoch:34 step:32066 [D loss: 0.231465, acc.: 59.38%] [G loss: 0.295138]\n",
      "epoch:34 step:32067 [D loss: 0.257850, acc.: 52.34%] [G loss: 0.270191]\n",
      "epoch:34 step:32068 [D loss: 0.240486, acc.: 58.59%] [G loss: 0.290811]\n",
      "epoch:34 step:32069 [D loss: 0.225058, acc.: 64.06%] [G loss: 0.293174]\n",
      "epoch:34 step:32070 [D loss: 0.225330, acc.: 66.41%] [G loss: 0.304246]\n",
      "epoch:34 step:32071 [D loss: 0.243922, acc.: 56.25%] [G loss: 0.297382]\n",
      "epoch:34 step:32072 [D loss: 0.241665, acc.: 58.59%] [G loss: 0.305914]\n",
      "epoch:34 step:32073 [D loss: 0.242821, acc.: 57.81%] [G loss: 0.302476]\n",
      "epoch:34 step:32074 [D loss: 0.235001, acc.: 56.25%] [G loss: 0.304529]\n",
      "epoch:34 step:32075 [D loss: 0.232974, acc.: 60.16%] [G loss: 0.279194]\n",
      "epoch:34 step:32076 [D loss: 0.257963, acc.: 52.34%] [G loss: 0.312641]\n",
      "epoch:34 step:32077 [D loss: 0.244319, acc.: 59.38%] [G loss: 0.323883]\n",
      "epoch:34 step:32078 [D loss: 0.234814, acc.: 61.72%] [G loss: 0.307727]\n",
      "epoch:34 step:32079 [D loss: 0.230690, acc.: 61.72%] [G loss: 0.311784]\n",
      "epoch:34 step:32080 [D loss: 0.242629, acc.: 57.03%] [G loss: 0.310016]\n",
      "epoch:34 step:32081 [D loss: 0.233386, acc.: 60.16%] [G loss: 0.308886]\n",
      "epoch:34 step:32082 [D loss: 0.220762, acc.: 70.31%] [G loss: 0.337714]\n",
      "epoch:34 step:32083 [D loss: 0.236546, acc.: 57.03%] [G loss: 0.290693]\n",
      "epoch:34 step:32084 [D loss: 0.254098, acc.: 53.12%] [G loss: 0.299284]\n",
      "epoch:34 step:32085 [D loss: 0.247747, acc.: 57.03%] [G loss: 0.284541]\n",
      "epoch:34 step:32086 [D loss: 0.233285, acc.: 58.59%] [G loss: 0.304686]\n",
      "epoch:34 step:32087 [D loss: 0.230731, acc.: 62.50%] [G loss: 0.300389]\n",
      "epoch:34 step:32088 [D loss: 0.221568, acc.: 60.94%] [G loss: 0.315350]\n",
      "epoch:34 step:32089 [D loss: 0.235312, acc.: 64.06%] [G loss: 0.322465]\n",
      "epoch:34 step:32090 [D loss: 0.245925, acc.: 55.47%] [G loss: 0.304614]\n",
      "epoch:34 step:32091 [D loss: 0.237690, acc.: 61.72%] [G loss: 0.308514]\n",
      "epoch:34 step:32092 [D loss: 0.237262, acc.: 64.84%] [G loss: 0.287267]\n",
      "epoch:34 step:32093 [D loss: 0.244719, acc.: 56.25%] [G loss: 0.303456]\n",
      "epoch:34 step:32094 [D loss: 0.255564, acc.: 57.03%] [G loss: 0.331919]\n",
      "epoch:34 step:32095 [D loss: 0.231855, acc.: 62.50%] [G loss: 0.301627]\n",
      "epoch:34 step:32096 [D loss: 0.234383, acc.: 61.72%] [G loss: 0.330409]\n",
      "epoch:34 step:32097 [D loss: 0.229159, acc.: 60.94%] [G loss: 0.324075]\n",
      "epoch:34 step:32098 [D loss: 0.251338, acc.: 53.91%] [G loss: 0.328664]\n",
      "epoch:34 step:32099 [D loss: 0.243266, acc.: 59.38%] [G loss: 0.292657]\n",
      "epoch:34 step:32100 [D loss: 0.232538, acc.: 60.16%] [G loss: 0.296856]\n",
      "epoch:34 step:32101 [D loss: 0.231335, acc.: 58.59%] [G loss: 0.279187]\n",
      "epoch:34 step:32102 [D loss: 0.241556, acc.: 55.47%] [G loss: 0.290828]\n",
      "epoch:34 step:32103 [D loss: 0.240530, acc.: 53.91%] [G loss: 0.298483]\n",
      "epoch:34 step:32104 [D loss: 0.244606, acc.: 55.47%] [G loss: 0.266371]\n",
      "epoch:34 step:32105 [D loss: 0.252990, acc.: 53.12%] [G loss: 0.270852]\n",
      "epoch:34 step:32106 [D loss: 0.263314, acc.: 49.22%] [G loss: 0.270478]\n",
      "epoch:34 step:32107 [D loss: 0.242658, acc.: 57.03%] [G loss: 0.282079]\n",
      "epoch:34 step:32108 [D loss: 0.226746, acc.: 63.28%] [G loss: 0.291838]\n",
      "epoch:34 step:32109 [D loss: 0.237555, acc.: 57.03%] [G loss: 0.258293]\n",
      "epoch:34 step:32110 [D loss: 0.224972, acc.: 59.38%] [G loss: 0.283242]\n",
      "epoch:34 step:32111 [D loss: 0.253937, acc.: 50.78%] [G loss: 0.281883]\n",
      "epoch:34 step:32112 [D loss: 0.254447, acc.: 51.56%] [G loss: 0.280623]\n",
      "epoch:34 step:32113 [D loss: 0.243419, acc.: 58.59%] [G loss: 0.299376]\n",
      "epoch:34 step:32114 [D loss: 0.238277, acc.: 60.16%] [G loss: 0.287922]\n",
      "epoch:34 step:32115 [D loss: 0.239886, acc.: 59.38%] [G loss: 0.276684]\n",
      "epoch:34 step:32116 [D loss: 0.262371, acc.: 46.88%] [G loss: 0.291624]\n",
      "epoch:34 step:32117 [D loss: 0.253658, acc.: 53.91%] [G loss: 0.296961]\n",
      "epoch:34 step:32118 [D loss: 0.225473, acc.: 60.94%] [G loss: 0.322680]\n",
      "epoch:34 step:32119 [D loss: 0.230464, acc.: 60.16%] [G loss: 0.328002]\n",
      "epoch:34 step:32120 [D loss: 0.234989, acc.: 57.81%] [G loss: 0.335115]\n",
      "epoch:34 step:32121 [D loss: 0.249026, acc.: 57.03%] [G loss: 0.311266]\n",
      "epoch:34 step:32122 [D loss: 0.234052, acc.: 63.28%] [G loss: 0.284936]\n",
      "epoch:34 step:32123 [D loss: 0.227385, acc.: 60.16%] [G loss: 0.310383]\n",
      "epoch:34 step:32124 [D loss: 0.229310, acc.: 64.84%] [G loss: 0.327961]\n",
      "epoch:34 step:32125 [D loss: 0.235646, acc.: 66.41%] [G loss: 0.309440]\n",
      "epoch:34 step:32126 [D loss: 0.244177, acc.: 58.59%] [G loss: 0.324388]\n",
      "epoch:34 step:32127 [D loss: 0.229758, acc.: 62.50%] [G loss: 0.321314]\n",
      "epoch:34 step:32128 [D loss: 0.242362, acc.: 57.03%] [G loss: 0.288504]\n",
      "epoch:34 step:32129 [D loss: 0.239403, acc.: 56.25%] [G loss: 0.300580]\n",
      "epoch:34 step:32130 [D loss: 0.235072, acc.: 59.38%] [G loss: 0.323546]\n",
      "epoch:34 step:32131 [D loss: 0.244490, acc.: 57.81%] [G loss: 0.276411]\n",
      "epoch:34 step:32132 [D loss: 0.246593, acc.: 55.47%] [G loss: 0.288667]\n",
      "epoch:34 step:32133 [D loss: 0.238331, acc.: 60.16%] [G loss: 0.341679]\n",
      "epoch:34 step:32134 [D loss: 0.250687, acc.: 58.59%] [G loss: 0.304670]\n",
      "epoch:34 step:32135 [D loss: 0.239222, acc.: 66.41%] [G loss: 0.342447]\n",
      "epoch:34 step:32136 [D loss: 0.223567, acc.: 63.28%] [G loss: 0.334553]\n",
      "epoch:34 step:32137 [D loss: 0.252438, acc.: 57.81%] [G loss: 0.283616]\n",
      "epoch:34 step:32138 [D loss: 0.251061, acc.: 56.25%] [G loss: 0.289847]\n",
      "epoch:34 step:32139 [D loss: 0.235556, acc.: 57.81%] [G loss: 0.309661]\n",
      "epoch:34 step:32140 [D loss: 0.249792, acc.: 53.12%] [G loss: 0.265259]\n",
      "epoch:34 step:32141 [D loss: 0.238148, acc.: 58.59%] [G loss: 0.284444]\n",
      "epoch:34 step:32142 [D loss: 0.231467, acc.: 64.84%] [G loss: 0.315095]\n",
      "epoch:34 step:32143 [D loss: 0.232339, acc.: 63.28%] [G loss: 0.307614]\n",
      "epoch:34 step:32144 [D loss: 0.258006, acc.: 50.00%] [G loss: 0.286417]\n",
      "epoch:34 step:32145 [D loss: 0.229849, acc.: 64.06%] [G loss: 0.328322]\n",
      "epoch:34 step:32146 [D loss: 0.255304, acc.: 55.47%] [G loss: 0.295603]\n",
      "epoch:34 step:32147 [D loss: 0.247577, acc.: 53.91%] [G loss: 0.291712]\n",
      "epoch:34 step:32148 [D loss: 0.227250, acc.: 61.72%] [G loss: 0.292781]\n",
      "epoch:34 step:32149 [D loss: 0.242795, acc.: 55.47%] [G loss: 0.262166]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:34 step:32150 [D loss: 0.240493, acc.: 54.69%] [G loss: 0.281194]\n",
      "epoch:34 step:32151 [D loss: 0.214133, acc.: 65.62%] [G loss: 0.297451]\n",
      "epoch:34 step:32152 [D loss: 0.233580, acc.: 59.38%] [G loss: 0.275290]\n",
      "epoch:34 step:32153 [D loss: 0.250094, acc.: 52.34%] [G loss: 0.267563]\n",
      "epoch:34 step:32154 [D loss: 0.226176, acc.: 64.06%] [G loss: 0.310509]\n",
      "epoch:34 step:32155 [D loss: 0.243948, acc.: 57.03%] [G loss: 0.296311]\n",
      "epoch:34 step:32156 [D loss: 0.263959, acc.: 45.31%] [G loss: 0.291480]\n",
      "epoch:34 step:32157 [D loss: 0.234427, acc.: 59.38%] [G loss: 0.347095]\n",
      "epoch:34 step:32158 [D loss: 0.239963, acc.: 54.69%] [G loss: 0.283080]\n",
      "epoch:34 step:32159 [D loss: 0.243101, acc.: 61.72%] [G loss: 0.304426]\n",
      "epoch:34 step:32160 [D loss: 0.233558, acc.: 59.38%] [G loss: 0.290671]\n",
      "epoch:34 step:32161 [D loss: 0.250255, acc.: 56.25%] [G loss: 0.303650]\n",
      "epoch:34 step:32162 [D loss: 0.226656, acc.: 62.50%] [G loss: 0.301238]\n",
      "epoch:34 step:32163 [D loss: 0.243593, acc.: 57.81%] [G loss: 0.271339]\n",
      "epoch:34 step:32164 [D loss: 0.244257, acc.: 54.69%] [G loss: 0.294314]\n",
      "epoch:34 step:32165 [D loss: 0.237425, acc.: 55.47%] [G loss: 0.315360]\n",
      "epoch:34 step:32166 [D loss: 0.239834, acc.: 60.16%] [G loss: 0.305484]\n",
      "epoch:34 step:32167 [D loss: 0.254205, acc.: 49.22%] [G loss: 0.297594]\n",
      "epoch:34 step:32168 [D loss: 0.225333, acc.: 65.62%] [G loss: 0.277164]\n",
      "epoch:34 step:32169 [D loss: 0.236650, acc.: 56.25%] [G loss: 0.324246]\n",
      "epoch:34 step:32170 [D loss: 0.234980, acc.: 60.16%] [G loss: 0.314202]\n",
      "epoch:34 step:32171 [D loss: 0.258140, acc.: 48.44%] [G loss: 0.276956]\n",
      "epoch:34 step:32172 [D loss: 0.234701, acc.: 54.69%] [G loss: 0.300244]\n",
      "epoch:34 step:32173 [D loss: 0.246894, acc.: 53.12%] [G loss: 0.332810]\n",
      "epoch:34 step:32174 [D loss: 0.250100, acc.: 52.34%] [G loss: 0.314401]\n",
      "epoch:34 step:32175 [D loss: 0.240371, acc.: 57.03%] [G loss: 0.284910]\n",
      "epoch:34 step:32176 [D loss: 0.254380, acc.: 52.34%] [G loss: 0.284424]\n",
      "epoch:34 step:32177 [D loss: 0.245929, acc.: 53.91%] [G loss: 0.301519]\n",
      "epoch:34 step:32178 [D loss: 0.256347, acc.: 47.66%] [G loss: 0.265709]\n",
      "epoch:34 step:32179 [D loss: 0.230899, acc.: 61.72%] [G loss: 0.289451]\n",
      "epoch:34 step:32180 [D loss: 0.256585, acc.: 54.69%] [G loss: 0.282313]\n",
      "epoch:34 step:32181 [D loss: 0.247204, acc.: 53.12%] [G loss: 0.304079]\n",
      "epoch:34 step:32182 [D loss: 0.237240, acc.: 55.47%] [G loss: 0.297274]\n",
      "epoch:34 step:32183 [D loss: 0.247140, acc.: 58.59%] [G loss: 0.272318]\n",
      "epoch:34 step:32184 [D loss: 0.232451, acc.: 57.81%] [G loss: 0.302100]\n",
      "epoch:34 step:32185 [D loss: 0.224576, acc.: 65.62%] [G loss: 0.290818]\n",
      "epoch:34 step:32186 [D loss: 0.209267, acc.: 70.31%] [G loss: 0.299148]\n",
      "epoch:34 step:32187 [D loss: 0.226683, acc.: 60.94%] [G loss: 0.330297]\n",
      "epoch:34 step:32188 [D loss: 0.228209, acc.: 66.41%] [G loss: 0.293098]\n",
      "epoch:34 step:32189 [D loss: 0.239683, acc.: 59.38%] [G loss: 0.313966]\n",
      "epoch:34 step:32190 [D loss: 0.237359, acc.: 60.94%] [G loss: 0.299274]\n",
      "epoch:34 step:32191 [D loss: 0.250054, acc.: 50.78%] [G loss: 0.322143]\n",
      "epoch:34 step:32192 [D loss: 0.228517, acc.: 64.06%] [G loss: 0.283475]\n",
      "epoch:34 step:32193 [D loss: 0.242709, acc.: 54.69%] [G loss: 0.275641]\n",
      "epoch:34 step:32194 [D loss: 0.225427, acc.: 65.62%] [G loss: 0.314864]\n",
      "epoch:34 step:32195 [D loss: 0.253935, acc.: 56.25%] [G loss: 0.307887]\n",
      "epoch:34 step:32196 [D loss: 0.232291, acc.: 57.81%] [G loss: 0.306517]\n",
      "epoch:34 step:32197 [D loss: 0.228438, acc.: 57.81%] [G loss: 0.312662]\n",
      "epoch:34 step:32198 [D loss: 0.255264, acc.: 50.00%] [G loss: 0.297035]\n",
      "epoch:34 step:32199 [D loss: 0.249314, acc.: 55.47%] [G loss: 0.291502]\n",
      "epoch:34 step:32200 [D loss: 0.258600, acc.: 51.56%] [G loss: 0.308756]\n",
      "epoch:34 step:32201 [D loss: 0.241249, acc.: 56.25%] [G loss: 0.296929]\n",
      "epoch:34 step:32202 [D loss: 0.237373, acc.: 60.94%] [G loss: 0.322702]\n",
      "epoch:34 step:32203 [D loss: 0.245113, acc.: 57.81%] [G loss: 0.313726]\n",
      "epoch:34 step:32204 [D loss: 0.246137, acc.: 53.91%] [G loss: 0.308750]\n",
      "epoch:34 step:32205 [D loss: 0.243852, acc.: 60.16%] [G loss: 0.285088]\n",
      "epoch:34 step:32206 [D loss: 0.241341, acc.: 53.91%] [G loss: 0.263544]\n",
      "epoch:34 step:32207 [D loss: 0.225645, acc.: 66.41%] [G loss: 0.291858]\n",
      "epoch:34 step:32208 [D loss: 0.244013, acc.: 57.81%] [G loss: 0.353007]\n",
      "epoch:34 step:32209 [D loss: 0.259162, acc.: 46.09%] [G loss: 0.301654]\n",
      "epoch:34 step:32210 [D loss: 0.239738, acc.: 54.69%] [G loss: 0.285814]\n",
      "epoch:34 step:32211 [D loss: 0.247680, acc.: 53.12%] [G loss: 0.292383]\n",
      "epoch:34 step:32212 [D loss: 0.236041, acc.: 57.03%] [G loss: 0.313570]\n",
      "epoch:34 step:32213 [D loss: 0.244928, acc.: 54.69%] [G loss: 0.285969]\n",
      "epoch:34 step:32214 [D loss: 0.223250, acc.: 63.28%] [G loss: 0.300090]\n",
      "epoch:34 step:32215 [D loss: 0.235447, acc.: 57.81%] [G loss: 0.314839]\n",
      "epoch:34 step:32216 [D loss: 0.240275, acc.: 60.94%] [G loss: 0.263594]\n",
      "epoch:34 step:32217 [D loss: 0.235627, acc.: 63.28%] [G loss: 0.291734]\n",
      "epoch:34 step:32218 [D loss: 0.227542, acc.: 59.38%] [G loss: 0.294958]\n",
      "epoch:34 step:32219 [D loss: 0.234918, acc.: 64.06%] [G loss: 0.291342]\n",
      "epoch:34 step:32220 [D loss: 0.248095, acc.: 56.25%] [G loss: 0.293967]\n",
      "epoch:34 step:32221 [D loss: 0.238790, acc.: 53.12%] [G loss: 0.269715]\n",
      "epoch:34 step:32222 [D loss: 0.224790, acc.: 65.62%] [G loss: 0.325184]\n",
      "epoch:34 step:32223 [D loss: 0.254161, acc.: 54.69%] [G loss: 0.285851]\n",
      "epoch:34 step:32224 [D loss: 0.246532, acc.: 57.81%] [G loss: 0.275865]\n",
      "epoch:34 step:32225 [D loss: 0.235674, acc.: 60.94%] [G loss: 0.288457]\n",
      "epoch:34 step:32226 [D loss: 0.216058, acc.: 75.00%] [G loss: 0.299676]\n",
      "epoch:34 step:32227 [D loss: 0.243375, acc.: 55.47%] [G loss: 0.283102]\n",
      "epoch:34 step:32228 [D loss: 0.230543, acc.: 63.28%] [G loss: 0.302472]\n",
      "epoch:34 step:32229 [D loss: 0.236656, acc.: 60.94%] [G loss: 0.305206]\n",
      "epoch:34 step:32230 [D loss: 0.219904, acc.: 67.19%] [G loss: 0.296220]\n",
      "epoch:34 step:32231 [D loss: 0.243845, acc.: 56.25%] [G loss: 0.313912]\n",
      "epoch:34 step:32232 [D loss: 0.245623, acc.: 54.69%] [G loss: 0.316798]\n",
      "epoch:34 step:32233 [D loss: 0.240243, acc.: 60.94%] [G loss: 0.284165]\n",
      "epoch:34 step:32234 [D loss: 0.249354, acc.: 47.66%] [G loss: 0.293384]\n",
      "epoch:34 step:32235 [D loss: 0.249162, acc.: 54.69%] [G loss: 0.308310]\n",
      "epoch:34 step:32236 [D loss: 0.254721, acc.: 53.91%] [G loss: 0.286180]\n",
      "epoch:34 step:32237 [D loss: 0.237384, acc.: 63.28%] [G loss: 0.305014]\n",
      "epoch:34 step:32238 [D loss: 0.233116, acc.: 64.06%] [G loss: 0.279910]\n",
      "epoch:34 step:32239 [D loss: 0.246062, acc.: 54.69%] [G loss: 0.278626]\n",
      "epoch:34 step:32240 [D loss: 0.241774, acc.: 62.50%] [G loss: 0.284899]\n",
      "epoch:34 step:32241 [D loss: 0.229953, acc.: 62.50%] [G loss: 0.293995]\n",
      "epoch:34 step:32242 [D loss: 0.264832, acc.: 46.09%] [G loss: 0.324191]\n",
      "epoch:34 step:32243 [D loss: 0.243405, acc.: 58.59%] [G loss: 0.326375]\n",
      "epoch:34 step:32244 [D loss: 0.253505, acc.: 52.34%] [G loss: 0.288263]\n",
      "epoch:34 step:32245 [D loss: 0.244773, acc.: 52.34%] [G loss: 0.267322]\n",
      "epoch:34 step:32246 [D loss: 0.252481, acc.: 49.22%] [G loss: 0.327042]\n",
      "epoch:34 step:32247 [D loss: 0.211602, acc.: 67.97%] [G loss: 0.309277]\n",
      "epoch:34 step:32248 [D loss: 0.259469, acc.: 53.91%] [G loss: 0.275779]\n",
      "epoch:34 step:32249 [D loss: 0.246694, acc.: 58.59%] [G loss: 0.299458]\n",
      "epoch:34 step:32250 [D loss: 0.259948, acc.: 53.91%] [G loss: 0.281324]\n",
      "epoch:34 step:32251 [D loss: 0.243993, acc.: 56.25%] [G loss: 0.298938]\n",
      "epoch:34 step:32252 [D loss: 0.219128, acc.: 66.41%] [G loss: 0.299465]\n",
      "epoch:34 step:32253 [D loss: 0.231751, acc.: 62.50%] [G loss: 0.363116]\n",
      "epoch:34 step:32254 [D loss: 0.241564, acc.: 56.25%] [G loss: 0.302334]\n",
      "epoch:34 step:32255 [D loss: 0.253576, acc.: 53.91%] [G loss: 0.314322]\n",
      "epoch:34 step:32256 [D loss: 0.250971, acc.: 51.56%] [G loss: 0.311958]\n",
      "epoch:34 step:32257 [D loss: 0.223731, acc.: 69.53%] [G loss: 0.294933]\n",
      "epoch:34 step:32258 [D loss: 0.250685, acc.: 51.56%] [G loss: 0.303811]\n",
      "epoch:34 step:32259 [D loss: 0.233659, acc.: 64.84%] [G loss: 0.325242]\n",
      "epoch:34 step:32260 [D loss: 0.218639, acc.: 67.19%] [G loss: 0.309118]\n",
      "epoch:34 step:32261 [D loss: 0.249243, acc.: 54.69%] [G loss: 0.287120]\n",
      "epoch:34 step:32262 [D loss: 0.249507, acc.: 51.56%] [G loss: 0.293734]\n",
      "epoch:34 step:32263 [D loss: 0.235585, acc.: 60.94%] [G loss: 0.309546]\n",
      "epoch:34 step:32264 [D loss: 0.232975, acc.: 58.59%] [G loss: 0.290481]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:34 step:32265 [D loss: 0.237986, acc.: 58.59%] [G loss: 0.353865]\n",
      "epoch:34 step:32266 [D loss: 0.232592, acc.: 60.16%] [G loss: 0.302392]\n",
      "epoch:34 step:32267 [D loss: 0.242103, acc.: 53.12%] [G loss: 0.309706]\n",
      "epoch:34 step:32268 [D loss: 0.247764, acc.: 53.91%] [G loss: 0.289925]\n",
      "epoch:34 step:32269 [D loss: 0.249033, acc.: 53.91%] [G loss: 0.309008]\n",
      "epoch:34 step:32270 [D loss: 0.248232, acc.: 56.25%] [G loss: 0.250058]\n",
      "epoch:34 step:32271 [D loss: 0.237309, acc.: 60.94%] [G loss: 0.292550]\n",
      "epoch:34 step:32272 [D loss: 0.251095, acc.: 54.69%] [G loss: 0.274329]\n",
      "epoch:34 step:32273 [D loss: 0.230355, acc.: 61.72%] [G loss: 0.306787]\n",
      "epoch:34 step:32274 [D loss: 0.231530, acc.: 63.28%] [G loss: 0.334790]\n",
      "epoch:34 step:32275 [D loss: 0.251469, acc.: 50.78%] [G loss: 0.295240]\n",
      "epoch:34 step:32276 [D loss: 0.233945, acc.: 60.94%] [G loss: 0.288461]\n",
      "epoch:34 step:32277 [D loss: 0.244488, acc.: 60.16%] [G loss: 0.291527]\n",
      "epoch:34 step:32278 [D loss: 0.231662, acc.: 63.28%] [G loss: 0.298266]\n",
      "epoch:34 step:32279 [D loss: 0.238840, acc.: 59.38%] [G loss: 0.286438]\n",
      "epoch:34 step:32280 [D loss: 0.210164, acc.: 69.53%] [G loss: 0.330067]\n",
      "epoch:34 step:32281 [D loss: 0.239642, acc.: 60.16%] [G loss: 0.300521]\n",
      "epoch:34 step:32282 [D loss: 0.228049, acc.: 66.41%] [G loss: 0.347011]\n",
      "epoch:34 step:32283 [D loss: 0.236405, acc.: 58.59%] [G loss: 0.287781]\n",
      "epoch:34 step:32284 [D loss: 0.232761, acc.: 61.72%] [G loss: 0.299027]\n",
      "epoch:34 step:32285 [D loss: 0.246585, acc.: 55.47%] [G loss: 0.345817]\n",
      "epoch:34 step:32286 [D loss: 0.244612, acc.: 58.59%] [G loss: 0.298495]\n",
      "epoch:34 step:32287 [D loss: 0.237570, acc.: 60.16%] [G loss: 0.318356]\n",
      "epoch:34 step:32288 [D loss: 0.250678, acc.: 55.47%] [G loss: 0.279311]\n",
      "epoch:34 step:32289 [D loss: 0.216606, acc.: 65.62%] [G loss: 0.316905]\n",
      "epoch:34 step:32290 [D loss: 0.247042, acc.: 56.25%] [G loss: 0.286507]\n",
      "epoch:34 step:32291 [D loss: 0.258349, acc.: 53.12%] [G loss: 0.281595]\n",
      "epoch:34 step:32292 [D loss: 0.235954, acc.: 56.25%] [G loss: 0.265979]\n",
      "epoch:34 step:32293 [D loss: 0.241037, acc.: 59.38%] [G loss: 0.271695]\n",
      "epoch:34 step:32294 [D loss: 0.244043, acc.: 51.56%] [G loss: 0.280389]\n",
      "epoch:34 step:32295 [D loss: 0.248830, acc.: 53.12%] [G loss: 0.295374]\n",
      "epoch:34 step:32296 [D loss: 0.243815, acc.: 55.47%] [G loss: 0.284332]\n",
      "epoch:34 step:32297 [D loss: 0.244568, acc.: 53.12%] [G loss: 0.281268]\n",
      "epoch:34 step:32298 [D loss: 0.233321, acc.: 56.25%] [G loss: 0.298338]\n",
      "epoch:34 step:32299 [D loss: 0.244782, acc.: 57.81%] [G loss: 0.300711]\n",
      "epoch:34 step:32300 [D loss: 0.224378, acc.: 64.84%] [G loss: 0.318234]\n",
      "epoch:34 step:32301 [D loss: 0.247845, acc.: 57.03%] [G loss: 0.287875]\n",
      "epoch:34 step:32302 [D loss: 0.239068, acc.: 61.72%] [G loss: 0.297746]\n",
      "epoch:34 step:32303 [D loss: 0.225612, acc.: 59.38%] [G loss: 0.314881]\n",
      "epoch:34 step:32304 [D loss: 0.249870, acc.: 52.34%] [G loss: 0.302902]\n",
      "epoch:34 step:32305 [D loss: 0.214774, acc.: 65.62%] [G loss: 0.299538]\n",
      "epoch:34 step:32306 [D loss: 0.230820, acc.: 62.50%] [G loss: 0.295121]\n",
      "epoch:34 step:32307 [D loss: 0.230295, acc.: 58.59%] [G loss: 0.281464]\n",
      "epoch:34 step:32308 [D loss: 0.245102, acc.: 53.12%] [G loss: 0.277268]\n",
      "epoch:34 step:32309 [D loss: 0.225317, acc.: 60.16%] [G loss: 0.311959]\n",
      "epoch:34 step:32310 [D loss: 0.250685, acc.: 57.03%] [G loss: 0.286171]\n",
      "epoch:34 step:32311 [D loss: 0.238251, acc.: 58.59%] [G loss: 0.296635]\n",
      "epoch:34 step:32312 [D loss: 0.239728, acc.: 60.94%] [G loss: 0.292011]\n",
      "epoch:34 step:32313 [D loss: 0.236988, acc.: 60.16%] [G loss: 0.303642]\n",
      "epoch:34 step:32314 [D loss: 0.234368, acc.: 57.03%] [G loss: 0.303467]\n",
      "epoch:34 step:32315 [D loss: 0.239450, acc.: 57.03%] [G loss: 0.303002]\n",
      "epoch:34 step:32316 [D loss: 0.246147, acc.: 57.81%] [G loss: 0.295707]\n",
      "epoch:34 step:32317 [D loss: 0.235990, acc.: 59.38%] [G loss: 0.275091]\n",
      "epoch:34 step:32318 [D loss: 0.235329, acc.: 57.81%] [G loss: 0.290692]\n",
      "epoch:34 step:32319 [D loss: 0.250989, acc.: 52.34%] [G loss: 0.289297]\n",
      "epoch:34 step:32320 [D loss: 0.243296, acc.: 53.91%] [G loss: 0.288834]\n",
      "epoch:34 step:32321 [D loss: 0.246405, acc.: 56.25%] [G loss: 0.282127]\n",
      "epoch:34 step:32322 [D loss: 0.253391, acc.: 55.47%] [G loss: 0.293839]\n",
      "epoch:34 step:32323 [D loss: 0.246903, acc.: 53.12%] [G loss: 0.299362]\n",
      "epoch:34 step:32324 [D loss: 0.236814, acc.: 58.59%] [G loss: 0.301196]\n",
      "epoch:34 step:32325 [D loss: 0.207526, acc.: 71.09%] [G loss: 0.324769]\n",
      "epoch:34 step:32326 [D loss: 0.238669, acc.: 57.03%] [G loss: 0.309130]\n",
      "epoch:34 step:32327 [D loss: 0.229768, acc.: 58.59%] [G loss: 0.310112]\n",
      "epoch:34 step:32328 [D loss: 0.254526, acc.: 54.69%] [G loss: 0.283536]\n",
      "epoch:34 step:32329 [D loss: 0.243874, acc.: 51.56%] [G loss: 0.275469]\n",
      "epoch:34 step:32330 [D loss: 0.227974, acc.: 61.72%] [G loss: 0.302846]\n",
      "epoch:34 step:32331 [D loss: 0.232843, acc.: 54.69%] [G loss: 0.279218]\n",
      "epoch:34 step:32332 [D loss: 0.236985, acc.: 59.38%] [G loss: 0.294221]\n",
      "epoch:34 step:32333 [D loss: 0.230510, acc.: 62.50%] [G loss: 0.288773]\n",
      "epoch:34 step:32334 [D loss: 0.240809, acc.: 59.38%] [G loss: 0.295982]\n",
      "epoch:34 step:32335 [D loss: 0.251381, acc.: 56.25%] [G loss: 0.327982]\n",
      "epoch:34 step:32336 [D loss: 0.234106, acc.: 57.81%] [G loss: 0.308796]\n",
      "epoch:34 step:32337 [D loss: 0.234640, acc.: 60.16%] [G loss: 0.320349]\n",
      "epoch:34 step:32338 [D loss: 0.243068, acc.: 63.28%] [G loss: 0.330900]\n",
      "epoch:34 step:32339 [D loss: 0.241388, acc.: 59.38%] [G loss: 0.296748]\n",
      "epoch:34 step:32340 [D loss: 0.240149, acc.: 60.16%] [G loss: 0.312888]\n",
      "epoch:34 step:32341 [D loss: 0.246320, acc.: 57.03%] [G loss: 0.306868]\n",
      "epoch:34 step:32342 [D loss: 0.230206, acc.: 63.28%] [G loss: 0.294001]\n",
      "epoch:34 step:32343 [D loss: 0.254268, acc.: 47.66%] [G loss: 0.302162]\n",
      "epoch:34 step:32344 [D loss: 0.225910, acc.: 64.06%] [G loss: 0.291723]\n",
      "epoch:34 step:32345 [D loss: 0.227382, acc.: 64.84%] [G loss: 0.302478]\n",
      "epoch:34 step:32346 [D loss: 0.240174, acc.: 59.38%] [G loss: 0.327549]\n",
      "epoch:34 step:32347 [D loss: 0.242752, acc.: 53.12%] [G loss: 0.306378]\n",
      "epoch:34 step:32348 [D loss: 0.246427, acc.: 57.03%] [G loss: 0.294857]\n",
      "epoch:34 step:32349 [D loss: 0.249477, acc.: 54.69%] [G loss: 0.309226]\n",
      "epoch:34 step:32350 [D loss: 0.238174, acc.: 60.16%] [G loss: 0.326507]\n",
      "epoch:34 step:32351 [D loss: 0.248337, acc.: 56.25%] [G loss: 0.304388]\n",
      "epoch:34 step:32352 [D loss: 0.228275, acc.: 60.94%] [G loss: 0.296507]\n",
      "epoch:34 step:32353 [D loss: 0.241784, acc.: 60.94%] [G loss: 0.306149]\n",
      "epoch:34 step:32354 [D loss: 0.240967, acc.: 53.91%] [G loss: 0.275231]\n",
      "epoch:34 step:32355 [D loss: 0.239973, acc.: 57.81%] [G loss: 0.312184]\n",
      "epoch:34 step:32356 [D loss: 0.225968, acc.: 61.72%] [G loss: 0.302121]\n",
      "epoch:34 step:32357 [D loss: 0.244419, acc.: 58.59%] [G loss: 0.308002]\n",
      "epoch:34 step:32358 [D loss: 0.242819, acc.: 55.47%] [G loss: 0.279353]\n",
      "epoch:34 step:32359 [D loss: 0.230879, acc.: 64.06%] [G loss: 0.275572]\n",
      "epoch:34 step:32360 [D loss: 0.224127, acc.: 63.28%] [G loss: 0.287394]\n",
      "epoch:34 step:32361 [D loss: 0.224791, acc.: 64.06%] [G loss: 0.289513]\n",
      "epoch:34 step:32362 [D loss: 0.227041, acc.: 63.28%] [G loss: 0.296599]\n",
      "epoch:34 step:32363 [D loss: 0.255264, acc.: 52.34%] [G loss: 0.269774]\n",
      "epoch:34 step:32364 [D loss: 0.221966, acc.: 67.19%] [G loss: 0.301843]\n",
      "epoch:34 step:32365 [D loss: 0.241832, acc.: 57.81%] [G loss: 0.315494]\n",
      "epoch:34 step:32366 [D loss: 0.247879, acc.: 57.03%] [G loss: 0.281657]\n",
      "epoch:34 step:32367 [D loss: 0.248617, acc.: 54.69%] [G loss: 0.298823]\n",
      "epoch:34 step:32368 [D loss: 0.236737, acc.: 62.50%] [G loss: 0.307860]\n",
      "epoch:34 step:32369 [D loss: 0.234562, acc.: 61.72%] [G loss: 0.313777]\n",
      "epoch:34 step:32370 [D loss: 0.242526, acc.: 54.69%] [G loss: 0.296203]\n",
      "epoch:34 step:32371 [D loss: 0.243519, acc.: 60.16%] [G loss: 0.290974]\n",
      "epoch:34 step:32372 [D loss: 0.234211, acc.: 60.94%] [G loss: 0.311308]\n",
      "epoch:34 step:32373 [D loss: 0.249663, acc.: 59.38%] [G loss: 0.314174]\n",
      "epoch:34 step:32374 [D loss: 0.230872, acc.: 63.28%] [G loss: 0.303038]\n",
      "epoch:34 step:32375 [D loss: 0.232356, acc.: 60.94%] [G loss: 0.297014]\n",
      "epoch:34 step:32376 [D loss: 0.253370, acc.: 53.91%] [G loss: 0.286181]\n",
      "epoch:34 step:32377 [D loss: 0.225266, acc.: 66.41%] [G loss: 0.302698]\n",
      "epoch:34 step:32378 [D loss: 0.246468, acc.: 55.47%] [G loss: 0.303390]\n",
      "epoch:34 step:32379 [D loss: 0.251528, acc.: 56.25%] [G loss: 0.270608]\n",
      "epoch:34 step:32380 [D loss: 0.247790, acc.: 58.59%] [G loss: 0.303211]\n",
      "epoch:34 step:32381 [D loss: 0.249274, acc.: 57.03%] [G loss: 0.282503]\n",
      "epoch:34 step:32382 [D loss: 0.241781, acc.: 60.94%] [G loss: 0.306155]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:34 step:32383 [D loss: 0.226999, acc.: 62.50%] [G loss: 0.316860]\n",
      "epoch:34 step:32384 [D loss: 0.238859, acc.: 60.94%] [G loss: 0.308020]\n",
      "epoch:34 step:32385 [D loss: 0.232338, acc.: 64.06%] [G loss: 0.313449]\n",
      "epoch:34 step:32386 [D loss: 0.248313, acc.: 51.56%] [G loss: 0.297623]\n",
      "epoch:34 step:32387 [D loss: 0.241282, acc.: 55.47%] [G loss: 0.323198]\n",
      "epoch:34 step:32388 [D loss: 0.244879, acc.: 52.34%] [G loss: 0.324466]\n",
      "epoch:34 step:32389 [D loss: 0.234101, acc.: 63.28%] [G loss: 0.288289]\n",
      "epoch:34 step:32390 [D loss: 0.246319, acc.: 54.69%] [G loss: 0.306552]\n",
      "epoch:34 step:32391 [D loss: 0.256252, acc.: 51.56%] [G loss: 0.294620]\n",
      "epoch:34 step:32392 [D loss: 0.252154, acc.: 54.69%] [G loss: 0.315892]\n",
      "epoch:34 step:32393 [D loss: 0.244344, acc.: 55.47%] [G loss: 0.325056]\n",
      "epoch:34 step:32394 [D loss: 0.252209, acc.: 53.12%] [G loss: 0.306468]\n",
      "epoch:34 step:32395 [D loss: 0.244274, acc.: 59.38%] [G loss: 0.282173]\n",
      "epoch:34 step:32396 [D loss: 0.239849, acc.: 60.94%] [G loss: 0.287425]\n",
      "epoch:34 step:32397 [D loss: 0.221133, acc.: 58.59%] [G loss: 0.307970]\n",
      "epoch:34 step:32398 [D loss: 0.225064, acc.: 66.41%] [G loss: 0.305064]\n",
      "epoch:34 step:32399 [D loss: 0.212820, acc.: 71.88%] [G loss: 0.285411]\n",
      "epoch:34 step:32400 [D loss: 0.230917, acc.: 60.16%] [G loss: 0.315520]\n",
      "epoch:34 step:32401 [D loss: 0.234148, acc.: 60.94%] [G loss: 0.294632]\n",
      "epoch:34 step:32402 [D loss: 0.253440, acc.: 51.56%] [G loss: 0.303984]\n",
      "epoch:34 step:32403 [D loss: 0.235527, acc.: 61.72%] [G loss: 0.318003]\n",
      "epoch:34 step:32404 [D loss: 0.241895, acc.: 53.91%] [G loss: 0.294858]\n",
      "epoch:34 step:32405 [D loss: 0.232981, acc.: 60.16%] [G loss: 0.303894]\n",
      "epoch:34 step:32406 [D loss: 0.249558, acc.: 54.69%] [G loss: 0.316343]\n",
      "epoch:34 step:32407 [D loss: 0.235776, acc.: 62.50%] [G loss: 0.305768]\n",
      "epoch:34 step:32408 [D loss: 0.236219, acc.: 57.03%] [G loss: 0.298298]\n",
      "epoch:34 step:32409 [D loss: 0.238870, acc.: 62.50%] [G loss: 0.292723]\n",
      "epoch:34 step:32410 [D loss: 0.248656, acc.: 54.69%] [G loss: 0.304909]\n",
      "epoch:34 step:32411 [D loss: 0.237322, acc.: 59.38%] [G loss: 0.281193]\n",
      "epoch:34 step:32412 [D loss: 0.224834, acc.: 63.28%] [G loss: 0.307406]\n",
      "epoch:34 step:32413 [D loss: 0.229884, acc.: 60.16%] [G loss: 0.289738]\n",
      "epoch:34 step:32414 [D loss: 0.256263, acc.: 50.78%] [G loss: 0.282824]\n",
      "epoch:34 step:32415 [D loss: 0.243090, acc.: 58.59%] [G loss: 0.293636]\n",
      "epoch:34 step:32416 [D loss: 0.230898, acc.: 60.16%] [G loss: 0.296679]\n",
      "epoch:34 step:32417 [D loss: 0.227638, acc.: 64.84%] [G loss: 0.276777]\n",
      "epoch:34 step:32418 [D loss: 0.232398, acc.: 66.41%] [G loss: 0.301162]\n",
      "epoch:34 step:32419 [D loss: 0.242928, acc.: 51.56%] [G loss: 0.287979]\n",
      "epoch:34 step:32420 [D loss: 0.247338, acc.: 53.91%] [G loss: 0.322227]\n",
      "epoch:34 step:32421 [D loss: 0.235730, acc.: 59.38%] [G loss: 0.310831]\n",
      "epoch:34 step:32422 [D loss: 0.233235, acc.: 59.38%] [G loss: 0.301878]\n",
      "epoch:34 step:32423 [D loss: 0.232753, acc.: 62.50%] [G loss: 0.276564]\n",
      "epoch:34 step:32424 [D loss: 0.239404, acc.: 53.12%] [G loss: 0.302790]\n",
      "epoch:34 step:32425 [D loss: 0.254855, acc.: 55.47%] [G loss: 0.304139]\n",
      "epoch:34 step:32426 [D loss: 0.251207, acc.: 54.69%] [G loss: 0.336854]\n",
      "epoch:34 step:32427 [D loss: 0.244370, acc.: 54.69%] [G loss: 0.307185]\n",
      "epoch:34 step:32428 [D loss: 0.240934, acc.: 54.69%] [G loss: 0.312451]\n",
      "epoch:34 step:32429 [D loss: 0.235073, acc.: 60.94%] [G loss: 0.298114]\n",
      "epoch:34 step:32430 [D loss: 0.221779, acc.: 64.84%] [G loss: 0.302757]\n",
      "epoch:34 step:32431 [D loss: 0.259226, acc.: 49.22%] [G loss: 0.304658]\n",
      "epoch:34 step:32432 [D loss: 0.246459, acc.: 57.03%] [G loss: 0.312611]\n",
      "epoch:34 step:32433 [D loss: 0.252211, acc.: 57.03%] [G loss: 0.305067]\n",
      "epoch:34 step:32434 [D loss: 0.230000, acc.: 60.16%] [G loss: 0.285481]\n",
      "epoch:34 step:32435 [D loss: 0.220160, acc.: 60.94%] [G loss: 0.315947]\n",
      "epoch:34 step:32436 [D loss: 0.253505, acc.: 53.12%] [G loss: 0.275003]\n",
      "epoch:34 step:32437 [D loss: 0.231494, acc.: 57.81%] [G loss: 0.300651]\n",
      "epoch:34 step:32438 [D loss: 0.218832, acc.: 64.06%] [G loss: 0.329358]\n",
      "epoch:34 step:32439 [D loss: 0.262089, acc.: 52.34%] [G loss: 0.271568]\n",
      "epoch:34 step:32440 [D loss: 0.242389, acc.: 54.69%] [G loss: 0.276553]\n",
      "epoch:34 step:32441 [D loss: 0.247713, acc.: 59.38%] [G loss: 0.290609]\n",
      "epoch:34 step:32442 [D loss: 0.229494, acc.: 58.59%] [G loss: 0.295454]\n",
      "epoch:34 step:32443 [D loss: 0.261843, acc.: 53.12%] [G loss: 0.293615]\n",
      "epoch:34 step:32444 [D loss: 0.222836, acc.: 59.38%] [G loss: 0.305490]\n",
      "epoch:34 step:32445 [D loss: 0.237747, acc.: 57.81%] [G loss: 0.302139]\n",
      "epoch:34 step:32446 [D loss: 0.243225, acc.: 56.25%] [G loss: 0.325935]\n",
      "epoch:34 step:32447 [D loss: 0.241800, acc.: 59.38%] [G loss: 0.280176]\n",
      "epoch:34 step:32448 [D loss: 0.241144, acc.: 58.59%] [G loss: 0.317201]\n",
      "epoch:34 step:32449 [D loss: 0.236758, acc.: 61.72%] [G loss: 0.293336]\n",
      "epoch:34 step:32450 [D loss: 0.223248, acc.: 61.72%] [G loss: 0.337107]\n",
      "epoch:34 step:32451 [D loss: 0.248122, acc.: 55.47%] [G loss: 0.288719]\n",
      "epoch:34 step:32452 [D loss: 0.218456, acc.: 60.16%] [G loss: 0.327934]\n",
      "epoch:34 step:32453 [D loss: 0.240848, acc.: 56.25%] [G loss: 0.305386]\n",
      "epoch:34 step:32454 [D loss: 0.240511, acc.: 61.72%] [G loss: 0.299659]\n",
      "epoch:34 step:32455 [D loss: 0.239076, acc.: 61.72%] [G loss: 0.321941]\n",
      "epoch:34 step:32456 [D loss: 0.239487, acc.: 56.25%] [G loss: 0.296722]\n",
      "epoch:34 step:32457 [D loss: 0.213901, acc.: 69.53%] [G loss: 0.327953]\n",
      "epoch:34 step:32458 [D loss: 0.247446, acc.: 53.91%] [G loss: 0.303634]\n",
      "epoch:34 step:32459 [D loss: 0.247326, acc.: 54.69%] [G loss: 0.325673]\n",
      "epoch:34 step:32460 [D loss: 0.248366, acc.: 52.34%] [G loss: 0.281062]\n",
      "epoch:34 step:32461 [D loss: 0.241489, acc.: 61.72%] [G loss: 0.298168]\n",
      "epoch:34 step:32462 [D loss: 0.256571, acc.: 46.88%] [G loss: 0.287445]\n",
      "epoch:34 step:32463 [D loss: 0.251683, acc.: 55.47%] [G loss: 0.338727]\n",
      "epoch:34 step:32464 [D loss: 0.242216, acc.: 56.25%] [G loss: 0.288763]\n",
      "epoch:34 step:32465 [D loss: 0.233419, acc.: 59.38%] [G loss: 0.285960]\n",
      "epoch:34 step:32466 [D loss: 0.232241, acc.: 58.59%] [G loss: 0.314902]\n",
      "epoch:34 step:32467 [D loss: 0.238682, acc.: 56.25%] [G loss: 0.311746]\n",
      "epoch:34 step:32468 [D loss: 0.245156, acc.: 58.59%] [G loss: 0.320215]\n",
      "epoch:34 step:32469 [D loss: 0.250095, acc.: 57.03%] [G loss: 0.303056]\n",
      "epoch:34 step:32470 [D loss: 0.246098, acc.: 59.38%] [G loss: 0.333702]\n",
      "epoch:34 step:32471 [D loss: 0.243482, acc.: 56.25%] [G loss: 0.286669]\n",
      "epoch:34 step:32472 [D loss: 0.247771, acc.: 52.34%] [G loss: 0.294218]\n",
      "epoch:34 step:32473 [D loss: 0.258634, acc.: 53.91%] [G loss: 0.274246]\n",
      "epoch:34 step:32474 [D loss: 0.220133, acc.: 68.75%] [G loss: 0.282435]\n",
      "epoch:34 step:32475 [D loss: 0.245079, acc.: 54.69%] [G loss: 0.325250]\n",
      "epoch:34 step:32476 [D loss: 0.239306, acc.: 53.91%] [G loss: 0.325717]\n",
      "epoch:34 step:32477 [D loss: 0.238741, acc.: 60.94%] [G loss: 0.289836]\n",
      "epoch:34 step:32478 [D loss: 0.242305, acc.: 57.81%] [G loss: 0.304128]\n",
      "epoch:34 step:32479 [D loss: 0.237007, acc.: 60.94%] [G loss: 0.322293]\n",
      "epoch:34 step:32480 [D loss: 0.242708, acc.: 57.81%] [G loss: 0.295085]\n",
      "epoch:34 step:32481 [D loss: 0.225634, acc.: 63.28%] [G loss: 0.291528]\n",
      "epoch:34 step:32482 [D loss: 0.232476, acc.: 58.59%] [G loss: 0.278397]\n",
      "epoch:34 step:32483 [D loss: 0.218580, acc.: 66.41%] [G loss: 0.313556]\n",
      "epoch:34 step:32484 [D loss: 0.237257, acc.: 56.25%] [G loss: 0.291056]\n",
      "epoch:34 step:32485 [D loss: 0.234849, acc.: 63.28%] [G loss: 0.312738]\n",
      "epoch:34 step:32486 [D loss: 0.226265, acc.: 60.16%] [G loss: 0.303559]\n",
      "epoch:34 step:32487 [D loss: 0.249869, acc.: 53.91%] [G loss: 0.294017]\n",
      "epoch:34 step:32488 [D loss: 0.250851, acc.: 53.12%] [G loss: 0.310613]\n",
      "epoch:34 step:32489 [D loss: 0.231923, acc.: 62.50%] [G loss: 0.297815]\n",
      "epoch:34 step:32490 [D loss: 0.257195, acc.: 48.44%] [G loss: 0.293460]\n",
      "epoch:34 step:32491 [D loss: 0.237562, acc.: 57.81%] [G loss: 0.307598]\n",
      "epoch:34 step:32492 [D loss: 0.232239, acc.: 61.72%] [G loss: 0.317662]\n",
      "epoch:34 step:32493 [D loss: 0.245817, acc.: 53.91%] [G loss: 0.296589]\n",
      "epoch:34 step:32494 [D loss: 0.237664, acc.: 59.38%] [G loss: 0.268540]\n",
      "epoch:34 step:32495 [D loss: 0.248194, acc.: 55.47%] [G loss: 0.283575]\n",
      "epoch:34 step:32496 [D loss: 0.241407, acc.: 57.03%] [G loss: 0.274813]\n",
      "epoch:34 step:32497 [D loss: 0.251646, acc.: 52.34%] [G loss: 0.290631]\n",
      "epoch:34 step:32498 [D loss: 0.223895, acc.: 61.72%] [G loss: 0.308945]\n",
      "epoch:34 step:32499 [D loss: 0.256105, acc.: 53.91%] [G loss: 0.286582]\n",
      "epoch:34 step:32500 [D loss: 0.231571, acc.: 64.84%] [G loss: 0.291573]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:34 step:32501 [D loss: 0.254803, acc.: 53.91%] [G loss: 0.271729]\n",
      "epoch:34 step:32502 [D loss: 0.237523, acc.: 58.59%] [G loss: 0.302655]\n",
      "epoch:34 step:32503 [D loss: 0.235658, acc.: 59.38%] [G loss: 0.302112]\n",
      "epoch:34 step:32504 [D loss: 0.225556, acc.: 63.28%] [G loss: 0.297057]\n",
      "epoch:34 step:32505 [D loss: 0.250926, acc.: 57.03%] [G loss: 0.302100]\n",
      "epoch:34 step:32506 [D loss: 0.243969, acc.: 57.81%] [G loss: 0.286165]\n",
      "epoch:34 step:32507 [D loss: 0.229688, acc.: 61.72%] [G loss: 0.317247]\n",
      "epoch:34 step:32508 [D loss: 0.247192, acc.: 53.91%] [G loss: 0.315882]\n",
      "epoch:34 step:32509 [D loss: 0.229199, acc.: 60.94%] [G loss: 0.315779]\n",
      "epoch:34 step:32510 [D loss: 0.236199, acc.: 55.47%] [G loss: 0.300945]\n",
      "epoch:34 step:32511 [D loss: 0.253876, acc.: 51.56%] [G loss: 0.306357]\n",
      "epoch:34 step:32512 [D loss: 0.245817, acc.: 58.59%] [G loss: 0.304205]\n",
      "epoch:34 step:32513 [D loss: 0.245291, acc.: 56.25%] [G loss: 0.282235]\n",
      "epoch:34 step:32514 [D loss: 0.247265, acc.: 59.38%] [G loss: 0.282197]\n",
      "epoch:34 step:32515 [D loss: 0.242984, acc.: 55.47%] [G loss: 0.300941]\n",
      "epoch:34 step:32516 [D loss: 0.235048, acc.: 59.38%] [G loss: 0.303248]\n",
      "epoch:34 step:32517 [D loss: 0.252764, acc.: 52.34%] [G loss: 0.280906]\n",
      "epoch:34 step:32518 [D loss: 0.250971, acc.: 46.09%] [G loss: 0.281267]\n",
      "epoch:34 step:32519 [D loss: 0.224848, acc.: 62.50%] [G loss: 0.288021]\n",
      "epoch:34 step:32520 [D loss: 0.242610, acc.: 57.81%] [G loss: 0.304996]\n",
      "epoch:34 step:32521 [D loss: 0.233422, acc.: 57.03%] [G loss: 0.302120]\n",
      "epoch:34 step:32522 [D loss: 0.240148, acc.: 51.56%] [G loss: 0.317838]\n",
      "epoch:34 step:32523 [D loss: 0.253680, acc.: 50.00%] [G loss: 0.276663]\n",
      "epoch:34 step:32524 [D loss: 0.228985, acc.: 58.59%] [G loss: 0.295761]\n",
      "epoch:34 step:32525 [D loss: 0.252316, acc.: 54.69%] [G loss: 0.268701]\n",
      "epoch:34 step:32526 [D loss: 0.234976, acc.: 60.16%] [G loss: 0.308919]\n",
      "epoch:34 step:32527 [D loss: 0.239026, acc.: 64.06%] [G loss: 0.295275]\n",
      "epoch:34 step:32528 [D loss: 0.233412, acc.: 57.03%] [G loss: 0.277830]\n",
      "epoch:34 step:32529 [D loss: 0.249570, acc.: 58.59%] [G loss: 0.328353]\n",
      "epoch:34 step:32530 [D loss: 0.249485, acc.: 59.38%] [G loss: 0.296331]\n",
      "epoch:34 step:32531 [D loss: 0.238625, acc.: 56.25%] [G loss: 0.292704]\n",
      "epoch:34 step:32532 [D loss: 0.240318, acc.: 60.16%] [G loss: 0.285171]\n",
      "epoch:34 step:32533 [D loss: 0.227338, acc.: 66.41%] [G loss: 0.294892]\n",
      "epoch:34 step:32534 [D loss: 0.223977, acc.: 67.19%] [G loss: 0.324250]\n",
      "epoch:34 step:32535 [D loss: 0.245984, acc.: 53.12%] [G loss: 0.307111]\n",
      "epoch:34 step:32536 [D loss: 0.241317, acc.: 57.03%] [G loss: 0.283914]\n",
      "epoch:34 step:32537 [D loss: 0.230928, acc.: 57.81%] [G loss: 0.273183]\n",
      "epoch:34 step:32538 [D loss: 0.248696, acc.: 53.91%] [G loss: 0.304586]\n",
      "epoch:34 step:32539 [D loss: 0.242280, acc.: 55.47%] [G loss: 0.301327]\n",
      "epoch:34 step:32540 [D loss: 0.258094, acc.: 51.56%] [G loss: 0.297799]\n",
      "epoch:34 step:32541 [D loss: 0.248489, acc.: 52.34%] [G loss: 0.308050]\n",
      "epoch:34 step:32542 [D loss: 0.226421, acc.: 66.41%] [G loss: 0.310413]\n",
      "epoch:34 step:32543 [D loss: 0.244798, acc.: 56.25%] [G loss: 0.286115]\n",
      "epoch:34 step:32544 [D loss: 0.211959, acc.: 65.62%] [G loss: 0.311894]\n",
      "epoch:34 step:32545 [D loss: 0.227075, acc.: 64.06%] [G loss: 0.309015]\n",
      "epoch:34 step:32546 [D loss: 0.238557, acc.: 57.81%] [G loss: 0.309978]\n",
      "epoch:34 step:32547 [D loss: 0.248382, acc.: 48.44%] [G loss: 0.302953]\n",
      "epoch:34 step:32548 [D loss: 0.260449, acc.: 47.66%] [G loss: 0.283309]\n",
      "epoch:34 step:32549 [D loss: 0.251083, acc.: 57.03%] [G loss: 0.288725]\n",
      "epoch:34 step:32550 [D loss: 0.238573, acc.: 60.94%] [G loss: 0.286249]\n",
      "epoch:34 step:32551 [D loss: 0.228299, acc.: 64.84%] [G loss: 0.327865]\n",
      "epoch:34 step:32552 [D loss: 0.249830, acc.: 49.22%] [G loss: 0.296514]\n",
      "epoch:34 step:32553 [D loss: 0.246686, acc.: 53.12%] [G loss: 0.272790]\n",
      "epoch:34 step:32554 [D loss: 0.246039, acc.: 51.56%] [G loss: 0.282522]\n",
      "epoch:34 step:32555 [D loss: 0.232282, acc.: 62.50%] [G loss: 0.289284]\n",
      "epoch:34 step:32556 [D loss: 0.234589, acc.: 61.72%] [G loss: 0.315060]\n",
      "epoch:34 step:32557 [D loss: 0.241046, acc.: 60.16%] [G loss: 0.285615]\n",
      "epoch:34 step:32558 [D loss: 0.226796, acc.: 61.72%] [G loss: 0.288515]\n",
      "epoch:34 step:32559 [D loss: 0.223885, acc.: 63.28%] [G loss: 0.288815]\n",
      "epoch:34 step:32560 [D loss: 0.245215, acc.: 56.25%] [G loss: 0.319317]\n",
      "epoch:34 step:32561 [D loss: 0.235927, acc.: 57.03%] [G loss: 0.305814]\n",
      "epoch:34 step:32562 [D loss: 0.248502, acc.: 52.34%] [G loss: 0.284582]\n",
      "epoch:34 step:32563 [D loss: 0.220054, acc.: 67.19%] [G loss: 0.306557]\n",
      "epoch:34 step:32564 [D loss: 0.261844, acc.: 54.69%] [G loss: 0.267941]\n",
      "epoch:34 step:32565 [D loss: 0.246841, acc.: 53.91%] [G loss: 0.304341]\n",
      "epoch:34 step:32566 [D loss: 0.217877, acc.: 65.62%] [G loss: 0.289029]\n",
      "epoch:34 step:32567 [D loss: 0.263528, acc.: 49.22%] [G loss: 0.309633]\n",
      "epoch:34 step:32568 [D loss: 0.235250, acc.: 55.47%] [G loss: 0.311448]\n",
      "epoch:34 step:32569 [D loss: 0.236498, acc.: 60.16%] [G loss: 0.291212]\n",
      "epoch:34 step:32570 [D loss: 0.242742, acc.: 57.81%] [G loss: 0.306077]\n",
      "epoch:34 step:32571 [D loss: 0.254602, acc.: 54.69%] [G loss: 0.314283]\n",
      "epoch:34 step:32572 [D loss: 0.251233, acc.: 53.12%] [G loss: 0.293020]\n",
      "epoch:34 step:32573 [D loss: 0.257673, acc.: 51.56%] [G loss: 0.302245]\n",
      "epoch:34 step:32574 [D loss: 0.222700, acc.: 65.62%] [G loss: 0.286712]\n",
      "epoch:34 step:32575 [D loss: 0.248812, acc.: 49.22%] [G loss: 0.319921]\n",
      "epoch:34 step:32576 [D loss: 0.208279, acc.: 69.53%] [G loss: 0.336970]\n",
      "epoch:34 step:32577 [D loss: 0.229357, acc.: 64.84%] [G loss: 0.317937]\n",
      "epoch:34 step:32578 [D loss: 0.249406, acc.: 53.91%] [G loss: 0.319722]\n",
      "epoch:34 step:32579 [D loss: 0.250406, acc.: 53.91%] [G loss: 0.280362]\n",
      "epoch:34 step:32580 [D loss: 0.257373, acc.: 52.34%] [G loss: 0.301640]\n",
      "epoch:34 step:32581 [D loss: 0.224629, acc.: 61.72%] [G loss: 0.311360]\n",
      "epoch:34 step:32582 [D loss: 0.236887, acc.: 63.28%] [G loss: 0.299681]\n",
      "epoch:34 step:32583 [D loss: 0.219087, acc.: 67.19%] [G loss: 0.310269]\n",
      "epoch:34 step:32584 [D loss: 0.227672, acc.: 60.16%] [G loss: 0.302768]\n",
      "epoch:34 step:32585 [D loss: 0.243451, acc.: 59.38%] [G loss: 0.305226]\n",
      "epoch:34 step:32586 [D loss: 0.249770, acc.: 53.12%] [G loss: 0.284738]\n",
      "epoch:34 step:32587 [D loss: 0.248073, acc.: 59.38%] [G loss: 0.298033]\n",
      "epoch:34 step:32588 [D loss: 0.244643, acc.: 56.25%] [G loss: 0.308477]\n",
      "epoch:34 step:32589 [D loss: 0.265191, acc.: 48.44%] [G loss: 0.279950]\n",
      "epoch:34 step:32590 [D loss: 0.243617, acc.: 60.16%] [G loss: 0.287051]\n",
      "epoch:34 step:32591 [D loss: 0.240668, acc.: 60.94%] [G loss: 0.322624]\n",
      "epoch:34 step:32592 [D loss: 0.222882, acc.: 63.28%] [G loss: 0.313618]\n",
      "epoch:34 step:32593 [D loss: 0.237293, acc.: 64.84%] [G loss: 0.292382]\n",
      "epoch:34 step:32594 [D loss: 0.225917, acc.: 64.06%] [G loss: 0.276452]\n",
      "epoch:34 step:32595 [D loss: 0.235451, acc.: 59.38%] [G loss: 0.310366]\n",
      "epoch:34 step:32596 [D loss: 0.247275, acc.: 58.59%] [G loss: 0.303525]\n",
      "epoch:34 step:32597 [D loss: 0.249227, acc.: 53.91%] [G loss: 0.296284]\n",
      "epoch:34 step:32598 [D loss: 0.243492, acc.: 60.94%] [G loss: 0.313642]\n",
      "epoch:34 step:32599 [D loss: 0.229111, acc.: 61.72%] [G loss: 0.322024]\n",
      "epoch:34 step:32600 [D loss: 0.244974, acc.: 54.69%] [G loss: 0.284232]\n",
      "epoch:34 step:32601 [D loss: 0.237655, acc.: 60.16%] [G loss: 0.308946]\n",
      "epoch:34 step:32602 [D loss: 0.226942, acc.: 60.94%] [G loss: 0.312893]\n",
      "epoch:34 step:32603 [D loss: 0.238208, acc.: 58.59%] [G loss: 0.337130]\n",
      "epoch:34 step:32604 [D loss: 0.239931, acc.: 56.25%] [G loss: 0.303879]\n",
      "epoch:34 step:32605 [D loss: 0.237528, acc.: 59.38%] [G loss: 0.319485]\n",
      "epoch:34 step:32606 [D loss: 0.241718, acc.: 54.69%] [G loss: 0.297134]\n",
      "epoch:34 step:32607 [D loss: 0.247859, acc.: 51.56%] [G loss: 0.290177]\n",
      "epoch:34 step:32608 [D loss: 0.240842, acc.: 53.12%] [G loss: 0.310099]\n",
      "epoch:34 step:32609 [D loss: 0.241248, acc.: 60.94%] [G loss: 0.307882]\n",
      "epoch:34 step:32610 [D loss: 0.238773, acc.: 57.03%] [G loss: 0.302359]\n",
      "epoch:34 step:32611 [D loss: 0.247124, acc.: 57.03%] [G loss: 0.305381]\n",
      "epoch:34 step:32612 [D loss: 0.233475, acc.: 59.38%] [G loss: 0.324428]\n",
      "epoch:34 step:32613 [D loss: 0.215404, acc.: 67.19%] [G loss: 0.282321]\n",
      "epoch:34 step:32614 [D loss: 0.241527, acc.: 60.16%] [G loss: 0.295695]\n",
      "epoch:34 step:32615 [D loss: 0.228287, acc.: 63.28%] [G loss: 0.314195]\n",
      "epoch:34 step:32616 [D loss: 0.243115, acc.: 60.16%] [G loss: 0.311697]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:34 step:32617 [D loss: 0.241227, acc.: 61.72%] [G loss: 0.305741]\n",
      "epoch:34 step:32618 [D loss: 0.233253, acc.: 60.94%] [G loss: 0.298138]\n",
      "epoch:34 step:32619 [D loss: 0.264364, acc.: 46.88%] [G loss: 0.263203]\n",
      "epoch:34 step:32620 [D loss: 0.241594, acc.: 57.03%] [G loss: 0.314791]\n",
      "epoch:34 step:32621 [D loss: 0.225809, acc.: 61.72%] [G loss: 0.298416]\n",
      "epoch:34 step:32622 [D loss: 0.249960, acc.: 53.12%] [G loss: 0.303507]\n",
      "epoch:34 step:32623 [D loss: 0.273298, acc.: 44.53%] [G loss: 0.305431]\n",
      "epoch:34 step:32624 [D loss: 0.248271, acc.: 52.34%] [G loss: 0.294750]\n",
      "epoch:34 step:32625 [D loss: 0.234555, acc.: 60.94%] [G loss: 0.317588]\n",
      "epoch:34 step:32626 [D loss: 0.234457, acc.: 58.59%] [G loss: 0.286391]\n",
      "epoch:34 step:32627 [D loss: 0.254559, acc.: 51.56%] [G loss: 0.310819]\n",
      "epoch:34 step:32628 [D loss: 0.245409, acc.: 55.47%] [G loss: 0.285660]\n",
      "epoch:34 step:32629 [D loss: 0.252117, acc.: 51.56%] [G loss: 0.327186]\n",
      "epoch:34 step:32630 [D loss: 0.246883, acc.: 58.59%] [G loss: 0.299964]\n",
      "epoch:34 step:32631 [D loss: 0.236292, acc.: 62.50%] [G loss: 0.313976]\n",
      "epoch:34 step:32632 [D loss: 0.239475, acc.: 60.16%] [G loss: 0.337863]\n",
      "epoch:34 step:32633 [D loss: 0.236448, acc.: 57.81%] [G loss: 0.307527]\n",
      "epoch:34 step:32634 [D loss: 0.240454, acc.: 60.94%] [G loss: 0.304629]\n",
      "epoch:34 step:32635 [D loss: 0.237711, acc.: 56.25%] [G loss: 0.282577]\n",
      "epoch:34 step:32636 [D loss: 0.238694, acc.: 62.50%] [G loss: 0.295287]\n",
      "epoch:34 step:32637 [D loss: 0.240470, acc.: 59.38%] [G loss: 0.278663]\n",
      "epoch:34 step:32638 [D loss: 0.264221, acc.: 51.56%] [G loss: 0.301676]\n",
      "epoch:34 step:32639 [D loss: 0.233385, acc.: 55.47%] [G loss: 0.326859]\n",
      "epoch:34 step:32640 [D loss: 0.228894, acc.: 63.28%] [G loss: 0.320123]\n",
      "epoch:34 step:32641 [D loss: 0.250223, acc.: 53.91%] [G loss: 0.265947]\n",
      "epoch:34 step:32642 [D loss: 0.258037, acc.: 54.69%] [G loss: 0.287532]\n",
      "epoch:34 step:32643 [D loss: 0.233825, acc.: 60.16%] [G loss: 0.285323]\n",
      "epoch:34 step:32644 [D loss: 0.236903, acc.: 57.03%] [G loss: 0.308629]\n",
      "epoch:34 step:32645 [D loss: 0.235640, acc.: 60.16%] [G loss: 0.296796]\n",
      "epoch:34 step:32646 [D loss: 0.246537, acc.: 54.69%] [G loss: 0.310320]\n",
      "epoch:34 step:32647 [D loss: 0.244690, acc.: 54.69%] [G loss: 0.298775]\n",
      "epoch:34 step:32648 [D loss: 0.242260, acc.: 55.47%] [G loss: 0.307201]\n",
      "epoch:34 step:32649 [D loss: 0.235665, acc.: 63.28%] [G loss: 0.308550]\n",
      "epoch:34 step:32650 [D loss: 0.236222, acc.: 59.38%] [G loss: 0.276352]\n",
      "epoch:34 step:32651 [D loss: 0.255163, acc.: 50.00%] [G loss: 0.328037]\n",
      "epoch:34 step:32652 [D loss: 0.237896, acc.: 58.59%] [G loss: 0.308863]\n",
      "epoch:34 step:32653 [D loss: 0.228907, acc.: 57.81%] [G loss: 0.289146]\n",
      "epoch:34 step:32654 [D loss: 0.250533, acc.: 55.47%] [G loss: 0.293244]\n",
      "epoch:34 step:32655 [D loss: 0.223971, acc.: 67.19%] [G loss: 0.308484]\n",
      "epoch:34 step:32656 [D loss: 0.252586, acc.: 58.59%] [G loss: 0.307507]\n",
      "epoch:34 step:32657 [D loss: 0.248639, acc.: 60.16%] [G loss: 0.305084]\n",
      "epoch:34 step:32658 [D loss: 0.242173, acc.: 55.47%] [G loss: 0.281059]\n",
      "epoch:34 step:32659 [D loss: 0.252700, acc.: 55.47%] [G loss: 0.275449]\n",
      "epoch:34 step:32660 [D loss: 0.244093, acc.: 60.16%] [G loss: 0.295925]\n",
      "epoch:34 step:32661 [D loss: 0.232723, acc.: 58.59%] [G loss: 0.333919]\n",
      "epoch:34 step:32662 [D loss: 0.242404, acc.: 55.47%] [G loss: 0.303734]\n",
      "epoch:34 step:32663 [D loss: 0.234883, acc.: 60.16%] [G loss: 0.282551]\n",
      "epoch:34 step:32664 [D loss: 0.221072, acc.: 64.06%] [G loss: 0.277107]\n",
      "epoch:34 step:32665 [D loss: 0.255004, acc.: 53.91%] [G loss: 0.310326]\n",
      "epoch:34 step:32666 [D loss: 0.215429, acc.: 66.41%] [G loss: 0.299297]\n",
      "epoch:34 step:32667 [D loss: 0.236072, acc.: 55.47%] [G loss: 0.297429]\n",
      "epoch:34 step:32668 [D loss: 0.257115, acc.: 53.12%] [G loss: 0.310943]\n",
      "epoch:34 step:32669 [D loss: 0.234164, acc.: 62.50%] [G loss: 0.278648]\n",
      "epoch:34 step:32670 [D loss: 0.220941, acc.: 64.06%] [G loss: 0.296016]\n",
      "epoch:34 step:32671 [D loss: 0.235152, acc.: 62.50%] [G loss: 0.286565]\n",
      "epoch:34 step:32672 [D loss: 0.245975, acc.: 55.47%] [G loss: 0.304999]\n",
      "epoch:34 step:32673 [D loss: 0.227422, acc.: 59.38%] [G loss: 0.302728]\n",
      "epoch:34 step:32674 [D loss: 0.230016, acc.: 62.50%] [G loss: 0.290392]\n",
      "epoch:34 step:32675 [D loss: 0.226823, acc.: 62.50%] [G loss: 0.302370]\n",
      "epoch:34 step:32676 [D loss: 0.239614, acc.: 60.94%] [G loss: 0.297564]\n",
      "epoch:34 step:32677 [D loss: 0.239495, acc.: 56.25%] [G loss: 0.309312]\n",
      "epoch:34 step:32678 [D loss: 0.256670, acc.: 55.47%] [G loss: 0.296293]\n",
      "epoch:34 step:32679 [D loss: 0.239256, acc.: 58.59%] [G loss: 0.292193]\n",
      "epoch:34 step:32680 [D loss: 0.210195, acc.: 65.62%] [G loss: 0.324107]\n",
      "epoch:34 step:32681 [D loss: 0.238750, acc.: 57.81%] [G loss: 0.283848]\n",
      "epoch:34 step:32682 [D loss: 0.219794, acc.: 65.62%] [G loss: 0.293502]\n",
      "epoch:34 step:32683 [D loss: 0.236247, acc.: 60.16%] [G loss: 0.301548]\n",
      "epoch:34 step:32684 [D loss: 0.241464, acc.: 57.81%] [G loss: 0.277109]\n",
      "epoch:34 step:32685 [D loss: 0.224766, acc.: 60.94%] [G loss: 0.319598]\n",
      "epoch:34 step:32686 [D loss: 0.245631, acc.: 58.59%] [G loss: 0.271182]\n",
      "epoch:34 step:32687 [D loss: 0.229552, acc.: 62.50%] [G loss: 0.302505]\n",
      "epoch:34 step:32688 [D loss: 0.241224, acc.: 61.72%] [G loss: 0.291721]\n",
      "epoch:34 step:32689 [D loss: 0.257564, acc.: 53.91%] [G loss: 0.297267]\n",
      "epoch:34 step:32690 [D loss: 0.234657, acc.: 57.81%] [G loss: 0.272429]\n",
      "epoch:34 step:32691 [D loss: 0.251402, acc.: 52.34%] [G loss: 0.270825]\n",
      "epoch:34 step:32692 [D loss: 0.232212, acc.: 58.59%] [G loss: 0.310368]\n",
      "epoch:34 step:32693 [D loss: 0.266299, acc.: 48.44%] [G loss: 0.266807]\n",
      "epoch:34 step:32694 [D loss: 0.259821, acc.: 50.78%] [G loss: 0.256079]\n",
      "epoch:34 step:32695 [D loss: 0.227490, acc.: 64.84%] [G loss: 0.277678]\n",
      "epoch:34 step:32696 [D loss: 0.240808, acc.: 57.03%] [G loss: 0.278808]\n",
      "epoch:34 step:32697 [D loss: 0.226109, acc.: 64.06%] [G loss: 0.313954]\n",
      "epoch:34 step:32698 [D loss: 0.248553, acc.: 53.91%] [G loss: 0.260216]\n",
      "epoch:34 step:32699 [D loss: 0.247845, acc.: 60.16%] [G loss: 0.308569]\n",
      "epoch:34 step:32700 [D loss: 0.260401, acc.: 47.66%] [G loss: 0.280534]\n",
      "epoch:34 step:32701 [D loss: 0.240696, acc.: 60.16%] [G loss: 0.266663]\n",
      "epoch:34 step:32702 [D loss: 0.251756, acc.: 57.03%] [G loss: 0.277197]\n",
      "epoch:34 step:32703 [D loss: 0.230672, acc.: 57.03%] [G loss: 0.290016]\n",
      "epoch:34 step:32704 [D loss: 0.235563, acc.: 60.16%] [G loss: 0.323663]\n",
      "epoch:34 step:32705 [D loss: 0.251273, acc.: 60.94%] [G loss: 0.283751]\n",
      "epoch:34 step:32706 [D loss: 0.220531, acc.: 60.94%] [G loss: 0.292763]\n",
      "epoch:34 step:32707 [D loss: 0.254977, acc.: 50.00%] [G loss: 0.269910]\n",
      "epoch:34 step:32708 [D loss: 0.251162, acc.: 53.12%] [G loss: 0.288325]\n",
      "epoch:34 step:32709 [D loss: 0.243690, acc.: 56.25%] [G loss: 0.301563]\n",
      "epoch:34 step:32710 [D loss: 0.229423, acc.: 64.84%] [G loss: 0.304681]\n",
      "epoch:34 step:32711 [D loss: 0.234977, acc.: 57.81%] [G loss: 0.304627]\n",
      "epoch:34 step:32712 [D loss: 0.242990, acc.: 60.94%] [G loss: 0.270846]\n",
      "epoch:34 step:32713 [D loss: 0.260484, acc.: 54.69%] [G loss: 0.303328]\n",
      "epoch:34 step:32714 [D loss: 0.233446, acc.: 60.94%] [G loss: 0.288348]\n",
      "epoch:34 step:32715 [D loss: 0.246800, acc.: 60.94%] [G loss: 0.275757]\n",
      "epoch:34 step:32716 [D loss: 0.232547, acc.: 57.03%] [G loss: 0.257917]\n",
      "epoch:34 step:32717 [D loss: 0.239644, acc.: 53.91%] [G loss: 0.295727]\n",
      "epoch:34 step:32718 [D loss: 0.249750, acc.: 54.69%] [G loss: 0.284091]\n",
      "epoch:34 step:32719 [D loss: 0.217988, acc.: 67.97%] [G loss: 0.297183]\n",
      "epoch:34 step:32720 [D loss: 0.251412, acc.: 53.91%] [G loss: 0.275156]\n",
      "epoch:34 step:32721 [D loss: 0.253786, acc.: 47.66%] [G loss: 0.302442]\n",
      "epoch:34 step:32722 [D loss: 0.238699, acc.: 56.25%] [G loss: 0.307487]\n",
      "epoch:34 step:32723 [D loss: 0.240241, acc.: 57.81%] [G loss: 0.256817]\n",
      "epoch:34 step:32724 [D loss: 0.241187, acc.: 56.25%] [G loss: 0.286191]\n",
      "epoch:34 step:32725 [D loss: 0.251979, acc.: 54.69%] [G loss: 0.315358]\n",
      "epoch:34 step:32726 [D loss: 0.232120, acc.: 63.28%] [G loss: 0.298673]\n",
      "epoch:34 step:32727 [D loss: 0.237265, acc.: 58.59%] [G loss: 0.279611]\n",
      "epoch:34 step:32728 [D loss: 0.249039, acc.: 57.81%] [G loss: 0.290502]\n",
      "epoch:34 step:32729 [D loss: 0.246115, acc.: 54.69%] [G loss: 0.291939]\n",
      "epoch:34 step:32730 [D loss: 0.236992, acc.: 55.47%] [G loss: 0.307303]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:34 step:32731 [D loss: 0.238083, acc.: 56.25%] [G loss: 0.294402]\n",
      "epoch:34 step:32732 [D loss: 0.235721, acc.: 58.59%] [G loss: 0.308974]\n",
      "epoch:34 step:32733 [D loss: 0.242867, acc.: 60.16%] [G loss: 0.306511]\n",
      "epoch:34 step:32734 [D loss: 0.265112, acc.: 52.34%] [G loss: 0.288238]\n",
      "epoch:34 step:32735 [D loss: 0.245791, acc.: 55.47%] [G loss: 0.326371]\n",
      "epoch:34 step:32736 [D loss: 0.230799, acc.: 60.16%] [G loss: 0.288519]\n",
      "epoch:34 step:32737 [D loss: 0.251626, acc.: 49.22%] [G loss: 0.293031]\n",
      "epoch:34 step:32738 [D loss: 0.237062, acc.: 57.81%] [G loss: 0.294087]\n",
      "epoch:34 step:32739 [D loss: 0.234554, acc.: 61.72%] [G loss: 0.311243]\n",
      "epoch:34 step:32740 [D loss: 0.245570, acc.: 53.12%] [G loss: 0.293108]\n",
      "epoch:34 step:32741 [D loss: 0.241947, acc.: 52.34%] [G loss: 0.277841]\n",
      "epoch:34 step:32742 [D loss: 0.240786, acc.: 56.25%] [G loss: 0.296445]\n",
      "epoch:34 step:32743 [D loss: 0.246571, acc.: 57.81%] [G loss: 0.315611]\n",
      "epoch:34 step:32744 [D loss: 0.225154, acc.: 60.16%] [G loss: 0.279501]\n",
      "epoch:34 step:32745 [D loss: 0.242705, acc.: 57.03%] [G loss: 0.307531]\n",
      "epoch:34 step:32746 [D loss: 0.244233, acc.: 53.12%] [G loss: 0.287700]\n",
      "epoch:34 step:32747 [D loss: 0.245022, acc.: 57.81%] [G loss: 0.333363]\n",
      "epoch:34 step:32748 [D loss: 0.246356, acc.: 54.69%] [G loss: 0.299417]\n",
      "epoch:34 step:32749 [D loss: 0.246849, acc.: 55.47%] [G loss: 0.314941]\n",
      "epoch:34 step:32750 [D loss: 0.253956, acc.: 52.34%] [G loss: 0.301186]\n",
      "epoch:34 step:32751 [D loss: 0.238721, acc.: 57.03%] [G loss: 0.311436]\n",
      "epoch:34 step:32752 [D loss: 0.239197, acc.: 56.25%] [G loss: 0.319753]\n",
      "epoch:34 step:32753 [D loss: 0.248379, acc.: 53.91%] [G loss: 0.285584]\n",
      "epoch:34 step:32754 [D loss: 0.256441, acc.: 50.78%] [G loss: 0.301167]\n",
      "epoch:34 step:32755 [D loss: 0.233772, acc.: 63.28%] [G loss: 0.310201]\n",
      "epoch:34 step:32756 [D loss: 0.216801, acc.: 70.31%] [G loss: 0.302273]\n",
      "epoch:34 step:32757 [D loss: 0.246663, acc.: 54.69%] [G loss: 0.283125]\n",
      "epoch:34 step:32758 [D loss: 0.241803, acc.: 53.12%] [G loss: 0.316334]\n",
      "epoch:34 step:32759 [D loss: 0.241057, acc.: 55.47%] [G loss: 0.294490]\n",
      "epoch:34 step:32760 [D loss: 0.239880, acc.: 55.47%] [G loss: 0.309662]\n",
      "epoch:34 step:32761 [D loss: 0.237578, acc.: 58.59%] [G loss: 0.297285]\n",
      "epoch:34 step:32762 [D loss: 0.224500, acc.: 64.84%] [G loss: 0.302385]\n",
      "epoch:34 step:32763 [D loss: 0.246715, acc.: 57.81%] [G loss: 0.315977]\n",
      "epoch:34 step:32764 [D loss: 0.243433, acc.: 57.81%] [G loss: 0.301792]\n",
      "epoch:34 step:32765 [D loss: 0.221247, acc.: 66.41%] [G loss: 0.331637]\n",
      "epoch:34 step:32766 [D loss: 0.247001, acc.: 55.47%] [G loss: 0.313122]\n",
      "epoch:34 step:32767 [D loss: 0.256657, acc.: 53.12%] [G loss: 0.296657]\n",
      "epoch:34 step:32768 [D loss: 0.237758, acc.: 60.94%] [G loss: 0.290662]\n",
      "epoch:34 step:32769 [D loss: 0.241231, acc.: 53.12%] [G loss: 0.308685]\n",
      "epoch:34 step:32770 [D loss: 0.246936, acc.: 54.69%] [G loss: 0.305568]\n",
      "epoch:34 step:32771 [D loss: 0.245349, acc.: 55.47%] [G loss: 0.306411]\n",
      "epoch:34 step:32772 [D loss: 0.228537, acc.: 59.38%] [G loss: 0.311387]\n",
      "epoch:34 step:32773 [D loss: 0.223330, acc.: 66.41%] [G loss: 0.297229]\n",
      "epoch:34 step:32774 [D loss: 0.246181, acc.: 56.25%] [G loss: 0.279611]\n",
      "epoch:34 step:32775 [D loss: 0.224640, acc.: 65.62%] [G loss: 0.317486]\n",
      "epoch:34 step:32776 [D loss: 0.242669, acc.: 54.69%] [G loss: 0.319445]\n",
      "epoch:34 step:32777 [D loss: 0.232048, acc.: 61.72%] [G loss: 0.317609]\n",
      "epoch:34 step:32778 [D loss: 0.223002, acc.: 64.84%] [G loss: 0.291198]\n",
      "epoch:34 step:32779 [D loss: 0.269671, acc.: 46.88%] [G loss: 0.296781]\n",
      "epoch:34 step:32780 [D loss: 0.255030, acc.: 53.91%] [G loss: 0.304810]\n",
      "epoch:34 step:32781 [D loss: 0.253868, acc.: 50.78%] [G loss: 0.273743]\n",
      "epoch:34 step:32782 [D loss: 0.238501, acc.: 58.59%] [G loss: 0.310616]\n",
      "epoch:34 step:32783 [D loss: 0.246871, acc.: 51.56%] [G loss: 0.311506]\n",
      "epoch:34 step:32784 [D loss: 0.228252, acc.: 62.50%] [G loss: 0.310295]\n",
      "epoch:34 step:32785 [D loss: 0.241736, acc.: 60.16%] [G loss: 0.281805]\n",
      "epoch:34 step:32786 [D loss: 0.241223, acc.: 57.03%] [G loss: 0.290240]\n",
      "epoch:34 step:32787 [D loss: 0.238238, acc.: 57.03%] [G loss: 0.314702]\n",
      "epoch:34 step:32788 [D loss: 0.230906, acc.: 63.28%] [G loss: 0.294185]\n",
      "epoch:34 step:32789 [D loss: 0.232724, acc.: 62.50%] [G loss: 0.297213]\n",
      "epoch:34 step:32790 [D loss: 0.232467, acc.: 55.47%] [G loss: 0.314754]\n",
      "epoch:34 step:32791 [D loss: 0.252548, acc.: 53.12%] [G loss: 0.281420]\n",
      "epoch:34 step:32792 [D loss: 0.242382, acc.: 59.38%] [G loss: 0.309926]\n",
      "epoch:34 step:32793 [D loss: 0.236053, acc.: 56.25%] [G loss: 0.292770]\n",
      "epoch:34 step:32794 [D loss: 0.227694, acc.: 63.28%] [G loss: 0.277611]\n",
      "epoch:34 step:32795 [D loss: 0.242083, acc.: 58.59%] [G loss: 0.291018]\n",
      "epoch:35 step:32796 [D loss: 0.238920, acc.: 62.50%] [G loss: 0.330500]\n",
      "epoch:35 step:32797 [D loss: 0.255920, acc.: 57.03%] [G loss: 0.291834]\n",
      "epoch:35 step:32798 [D loss: 0.249970, acc.: 53.12%] [G loss: 0.265276]\n",
      "epoch:35 step:32799 [D loss: 0.237048, acc.: 59.38%] [G loss: 0.270097]\n",
      "epoch:35 step:32800 [D loss: 0.254170, acc.: 53.12%] [G loss: 0.289795]\n",
      "epoch:35 step:32801 [D loss: 0.242453, acc.: 54.69%] [G loss: 0.295296]\n",
      "epoch:35 step:32802 [D loss: 0.231584, acc.: 60.94%] [G loss: 0.289832]\n",
      "epoch:35 step:32803 [D loss: 0.233189, acc.: 63.28%] [G loss: 0.268167]\n",
      "epoch:35 step:32804 [D loss: 0.225837, acc.: 58.59%] [G loss: 0.285729]\n",
      "epoch:35 step:32805 [D loss: 0.225297, acc.: 62.50%] [G loss: 0.299401]\n",
      "epoch:35 step:32806 [D loss: 0.241145, acc.: 61.72%] [G loss: 0.299437]\n",
      "epoch:35 step:32807 [D loss: 0.249079, acc.: 57.81%] [G loss: 0.289337]\n",
      "epoch:35 step:32808 [D loss: 0.241655, acc.: 58.59%] [G loss: 0.308467]\n",
      "epoch:35 step:32809 [D loss: 0.240304, acc.: 54.69%] [G loss: 0.305789]\n",
      "epoch:35 step:32810 [D loss: 0.232882, acc.: 61.72%] [G loss: 0.295617]\n",
      "epoch:35 step:32811 [D loss: 0.232785, acc.: 57.81%] [G loss: 0.278653]\n",
      "epoch:35 step:32812 [D loss: 0.237635, acc.: 53.12%] [G loss: 0.298040]\n",
      "epoch:35 step:32813 [D loss: 0.221847, acc.: 65.62%] [G loss: 0.332587]\n",
      "epoch:35 step:32814 [D loss: 0.255444, acc.: 53.12%] [G loss: 0.297287]\n",
      "epoch:35 step:32815 [D loss: 0.253907, acc.: 52.34%] [G loss: 0.293329]\n",
      "epoch:35 step:32816 [D loss: 0.255377, acc.: 57.03%] [G loss: 0.277838]\n",
      "epoch:35 step:32817 [D loss: 0.230561, acc.: 64.06%] [G loss: 0.285441]\n",
      "epoch:35 step:32818 [D loss: 0.243218, acc.: 56.25%] [G loss: 0.308476]\n",
      "epoch:35 step:32819 [D loss: 0.232140, acc.: 57.81%] [G loss: 0.325776]\n",
      "epoch:35 step:32820 [D loss: 0.238152, acc.: 60.16%] [G loss: 0.300770]\n",
      "epoch:35 step:32821 [D loss: 0.242841, acc.: 53.91%] [G loss: 0.301634]\n",
      "epoch:35 step:32822 [D loss: 0.245833, acc.: 57.81%] [G loss: 0.305657]\n",
      "epoch:35 step:32823 [D loss: 0.242235, acc.: 60.16%] [G loss: 0.275617]\n",
      "epoch:35 step:32824 [D loss: 0.241767, acc.: 57.81%] [G loss: 0.299897]\n",
      "epoch:35 step:32825 [D loss: 0.246740, acc.: 56.25%] [G loss: 0.312828]\n",
      "epoch:35 step:32826 [D loss: 0.231387, acc.: 59.38%] [G loss: 0.314621]\n",
      "epoch:35 step:32827 [D loss: 0.233911, acc.: 59.38%] [G loss: 0.294134]\n",
      "epoch:35 step:32828 [D loss: 0.233140, acc.: 62.50%] [G loss: 0.288236]\n",
      "epoch:35 step:32829 [D loss: 0.244007, acc.: 53.12%] [G loss: 0.290042]\n",
      "epoch:35 step:32830 [D loss: 0.241510, acc.: 56.25%] [G loss: 0.282072]\n",
      "epoch:35 step:32831 [D loss: 0.233175, acc.: 59.38%] [G loss: 0.308813]\n",
      "epoch:35 step:32832 [D loss: 0.234945, acc.: 61.72%] [G loss: 0.282440]\n",
      "epoch:35 step:32833 [D loss: 0.249740, acc.: 53.91%] [G loss: 0.296812]\n",
      "epoch:35 step:32834 [D loss: 0.256330, acc.: 46.88%] [G loss: 0.324616]\n",
      "epoch:35 step:32835 [D loss: 0.238089, acc.: 62.50%] [G loss: 0.291565]\n",
      "epoch:35 step:32836 [D loss: 0.234940, acc.: 60.94%] [G loss: 0.298551]\n",
      "epoch:35 step:32837 [D loss: 0.256254, acc.: 52.34%] [G loss: 0.287148]\n",
      "epoch:35 step:32838 [D loss: 0.245276, acc.: 54.69%] [G loss: 0.306125]\n",
      "epoch:35 step:32839 [D loss: 0.244278, acc.: 57.81%] [G loss: 0.306838]\n",
      "epoch:35 step:32840 [D loss: 0.221804, acc.: 67.19%] [G loss: 0.310592]\n",
      "epoch:35 step:32841 [D loss: 0.235022, acc.: 60.16%] [G loss: 0.299127]\n",
      "epoch:35 step:32842 [D loss: 0.232392, acc.: 58.59%] [G loss: 0.301269]\n",
      "epoch:35 step:32843 [D loss: 0.242202, acc.: 53.91%] [G loss: 0.285638]\n",
      "epoch:35 step:32844 [D loss: 0.231363, acc.: 57.81%] [G loss: 0.318505]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:35 step:32845 [D loss: 0.230589, acc.: 60.94%] [G loss: 0.310995]\n",
      "epoch:35 step:32846 [D loss: 0.217466, acc.: 64.06%] [G loss: 0.302884]\n",
      "epoch:35 step:32847 [D loss: 0.239409, acc.: 60.16%] [G loss: 0.273283]\n",
      "epoch:35 step:32848 [D loss: 0.233270, acc.: 61.72%] [G loss: 0.299587]\n",
      "epoch:35 step:32849 [D loss: 0.233759, acc.: 60.94%] [G loss: 0.313181]\n",
      "epoch:35 step:32850 [D loss: 0.232518, acc.: 60.16%] [G loss: 0.303161]\n",
      "epoch:35 step:32851 [D loss: 0.264895, acc.: 47.66%] [G loss: 0.292794]\n",
      "epoch:35 step:32852 [D loss: 0.250066, acc.: 57.03%] [G loss: 0.280689]\n",
      "epoch:35 step:32853 [D loss: 0.237761, acc.: 60.16%] [G loss: 0.277248]\n",
      "epoch:35 step:32854 [D loss: 0.230603, acc.: 65.62%] [G loss: 0.291617]\n",
      "epoch:35 step:32855 [D loss: 0.229679, acc.: 60.94%] [G loss: 0.274305]\n",
      "epoch:35 step:32856 [D loss: 0.247541, acc.: 51.56%] [G loss: 0.304701]\n",
      "epoch:35 step:32857 [D loss: 0.242464, acc.: 59.38%] [G loss: 0.291523]\n",
      "epoch:35 step:32858 [D loss: 0.255916, acc.: 57.03%] [G loss: 0.312855]\n",
      "epoch:35 step:32859 [D loss: 0.246043, acc.: 55.47%] [G loss: 0.275667]\n",
      "epoch:35 step:32860 [D loss: 0.240381, acc.: 60.16%] [G loss: 0.296157]\n",
      "epoch:35 step:32861 [D loss: 0.249827, acc.: 55.47%] [G loss: 0.314641]\n",
      "epoch:35 step:32862 [D loss: 0.251365, acc.: 50.00%] [G loss: 0.324022]\n",
      "epoch:35 step:32863 [D loss: 0.250058, acc.: 53.12%] [G loss: 0.322942]\n",
      "epoch:35 step:32864 [D loss: 0.221476, acc.: 70.31%] [G loss: 0.301236]\n",
      "epoch:35 step:32865 [D loss: 0.232627, acc.: 62.50%] [G loss: 0.292236]\n",
      "epoch:35 step:32866 [D loss: 0.244014, acc.: 55.47%] [G loss: 0.271719]\n",
      "epoch:35 step:32867 [D loss: 0.233683, acc.: 65.62%] [G loss: 0.298111]\n",
      "epoch:35 step:32868 [D loss: 0.226676, acc.: 65.62%] [G loss: 0.297191]\n",
      "epoch:35 step:32869 [D loss: 0.233038, acc.: 57.81%] [G loss: 0.311834]\n",
      "epoch:35 step:32870 [D loss: 0.248379, acc.: 58.59%] [G loss: 0.304308]\n",
      "epoch:35 step:32871 [D loss: 0.230450, acc.: 63.28%] [G loss: 0.327341]\n",
      "epoch:35 step:32872 [D loss: 0.255539, acc.: 57.03%] [G loss: 0.290667]\n",
      "epoch:35 step:32873 [D loss: 0.251133, acc.: 57.81%] [G loss: 0.280531]\n",
      "epoch:35 step:32874 [D loss: 0.245356, acc.: 57.03%] [G loss: 0.289244]\n",
      "epoch:35 step:32875 [D loss: 0.231591, acc.: 62.50%] [G loss: 0.319531]\n",
      "epoch:35 step:32876 [D loss: 0.256799, acc.: 53.12%] [G loss: 0.278728]\n",
      "epoch:35 step:32877 [D loss: 0.227373, acc.: 64.84%] [G loss: 0.282917]\n",
      "epoch:35 step:32878 [D loss: 0.238325, acc.: 63.28%] [G loss: 0.318241]\n",
      "epoch:35 step:32879 [D loss: 0.227864, acc.: 64.84%] [G loss: 0.321836]\n",
      "epoch:35 step:32880 [D loss: 0.250896, acc.: 56.25%] [G loss: 0.277110]\n",
      "epoch:35 step:32881 [D loss: 0.243571, acc.: 55.47%] [G loss: 0.270772]\n",
      "epoch:35 step:32882 [D loss: 0.241119, acc.: 59.38%] [G loss: 0.280710]\n",
      "epoch:35 step:32883 [D loss: 0.248055, acc.: 57.03%] [G loss: 0.296616]\n",
      "epoch:35 step:32884 [D loss: 0.242697, acc.: 53.12%] [G loss: 0.314126]\n",
      "epoch:35 step:32885 [D loss: 0.242248, acc.: 53.91%] [G loss: 0.321476]\n",
      "epoch:35 step:32886 [D loss: 0.242995, acc.: 58.59%] [G loss: 0.307259]\n",
      "epoch:35 step:32887 [D loss: 0.250672, acc.: 54.69%] [G loss: 0.298883]\n",
      "epoch:35 step:32888 [D loss: 0.242906, acc.: 55.47%] [G loss: 0.299320]\n",
      "epoch:35 step:32889 [D loss: 0.246722, acc.: 53.91%] [G loss: 0.317746]\n",
      "epoch:35 step:32890 [D loss: 0.242368, acc.: 61.72%] [G loss: 0.291875]\n",
      "epoch:35 step:32891 [D loss: 0.231754, acc.: 57.03%] [G loss: 0.316884]\n",
      "epoch:35 step:32892 [D loss: 0.228404, acc.: 64.06%] [G loss: 0.326065]\n",
      "epoch:35 step:32893 [D loss: 0.229442, acc.: 63.28%] [G loss: 0.303036]\n",
      "epoch:35 step:32894 [D loss: 0.252066, acc.: 54.69%] [G loss: 0.282621]\n",
      "epoch:35 step:32895 [D loss: 0.244882, acc.: 53.91%] [G loss: 0.295782]\n",
      "epoch:35 step:32896 [D loss: 0.246075, acc.: 60.94%] [G loss: 0.335349]\n",
      "epoch:35 step:32897 [D loss: 0.245258, acc.: 56.25%] [G loss: 0.317075]\n",
      "epoch:35 step:32898 [D loss: 0.229579, acc.: 63.28%] [G loss: 0.289795]\n",
      "epoch:35 step:32899 [D loss: 0.249315, acc.: 51.56%] [G loss: 0.298893]\n",
      "epoch:35 step:32900 [D loss: 0.222503, acc.: 63.28%] [G loss: 0.287819]\n",
      "epoch:35 step:32901 [D loss: 0.249177, acc.: 53.91%] [G loss: 0.275752]\n",
      "epoch:35 step:32902 [D loss: 0.244827, acc.: 57.03%] [G loss: 0.301174]\n",
      "epoch:35 step:32903 [D loss: 0.241665, acc.: 60.94%] [G loss: 0.315300]\n",
      "epoch:35 step:32904 [D loss: 0.240000, acc.: 57.81%] [G loss: 0.293618]\n",
      "epoch:35 step:32905 [D loss: 0.245765, acc.: 55.47%] [G loss: 0.287959]\n",
      "epoch:35 step:32906 [D loss: 0.224073, acc.: 65.62%] [G loss: 0.279357]\n",
      "epoch:35 step:32907 [D loss: 0.244637, acc.: 53.12%] [G loss: 0.285517]\n",
      "epoch:35 step:32908 [D loss: 0.261495, acc.: 48.44%] [G loss: 0.276329]\n",
      "epoch:35 step:32909 [D loss: 0.231304, acc.: 64.84%] [G loss: 0.315045]\n",
      "epoch:35 step:32910 [D loss: 0.232994, acc.: 55.47%] [G loss: 0.288528]\n",
      "epoch:35 step:32911 [D loss: 0.247242, acc.: 60.16%] [G loss: 0.305866]\n",
      "epoch:35 step:32912 [D loss: 0.248312, acc.: 54.69%] [G loss: 0.292000]\n",
      "epoch:35 step:32913 [D loss: 0.230349, acc.: 61.72%] [G loss: 0.290282]\n",
      "epoch:35 step:32914 [D loss: 0.232556, acc.: 65.62%] [G loss: 0.297704]\n",
      "epoch:35 step:32915 [D loss: 0.257824, acc.: 53.12%] [G loss: 0.291533]\n",
      "epoch:35 step:32916 [D loss: 0.233268, acc.: 61.72%] [G loss: 0.292239]\n",
      "epoch:35 step:32917 [D loss: 0.236433, acc.: 63.28%] [G loss: 0.289111]\n",
      "epoch:35 step:32918 [D loss: 0.251598, acc.: 53.12%] [G loss: 0.301129]\n",
      "epoch:35 step:32919 [D loss: 0.243318, acc.: 57.81%] [G loss: 0.286792]\n",
      "epoch:35 step:32920 [D loss: 0.219155, acc.: 64.84%] [G loss: 0.295651]\n",
      "epoch:35 step:32921 [D loss: 0.247122, acc.: 55.47%] [G loss: 0.266026]\n",
      "epoch:35 step:32922 [D loss: 0.238317, acc.: 53.91%] [G loss: 0.299982]\n",
      "epoch:35 step:32923 [D loss: 0.242023, acc.: 57.81%] [G loss: 0.279313]\n",
      "epoch:35 step:32924 [D loss: 0.246715, acc.: 53.12%] [G loss: 0.282812]\n",
      "epoch:35 step:32925 [D loss: 0.231705, acc.: 61.72%] [G loss: 0.299310]\n",
      "epoch:35 step:32926 [D loss: 0.236530, acc.: 60.94%] [G loss: 0.259949]\n",
      "epoch:35 step:32927 [D loss: 0.223469, acc.: 64.06%] [G loss: 0.274687]\n",
      "epoch:35 step:32928 [D loss: 0.233929, acc.: 61.72%] [G loss: 0.296928]\n",
      "epoch:35 step:32929 [D loss: 0.251640, acc.: 54.69%] [G loss: 0.310487]\n",
      "epoch:35 step:32930 [D loss: 0.234396, acc.: 58.59%] [G loss: 0.321754]\n",
      "epoch:35 step:32931 [D loss: 0.245132, acc.: 57.03%] [G loss: 0.281273]\n",
      "epoch:35 step:32932 [D loss: 0.234540, acc.: 57.81%] [G loss: 0.291955]\n",
      "epoch:35 step:32933 [D loss: 0.244717, acc.: 57.81%] [G loss: 0.290649]\n",
      "epoch:35 step:32934 [D loss: 0.224954, acc.: 63.28%] [G loss: 0.304006]\n",
      "epoch:35 step:32935 [D loss: 0.236159, acc.: 62.50%] [G loss: 0.302260]\n",
      "epoch:35 step:32936 [D loss: 0.247490, acc.: 53.91%] [G loss: 0.301938]\n",
      "epoch:35 step:32937 [D loss: 0.250698, acc.: 55.47%] [G loss: 0.275133]\n",
      "epoch:35 step:32938 [D loss: 0.254653, acc.: 57.81%] [G loss: 0.270378]\n",
      "epoch:35 step:32939 [D loss: 0.238228, acc.: 56.25%] [G loss: 0.289246]\n",
      "epoch:35 step:32940 [D loss: 0.255662, acc.: 52.34%] [G loss: 0.272002]\n",
      "epoch:35 step:32941 [D loss: 0.230286, acc.: 62.50%] [G loss: 0.305052]\n",
      "epoch:35 step:32942 [D loss: 0.263341, acc.: 49.22%] [G loss: 0.294853]\n",
      "epoch:35 step:32943 [D loss: 0.236969, acc.: 58.59%] [G loss: 0.304538]\n",
      "epoch:35 step:32944 [D loss: 0.237424, acc.: 58.59%] [G loss: 0.290877]\n",
      "epoch:35 step:32945 [D loss: 0.227468, acc.: 64.84%] [G loss: 0.262727]\n",
      "epoch:35 step:32946 [D loss: 0.241233, acc.: 60.16%] [G loss: 0.286517]\n",
      "epoch:35 step:32947 [D loss: 0.225522, acc.: 66.41%] [G loss: 0.285909]\n",
      "epoch:35 step:32948 [D loss: 0.252295, acc.: 56.25%] [G loss: 0.306003]\n",
      "epoch:35 step:32949 [D loss: 0.243860, acc.: 50.78%] [G loss: 0.289584]\n",
      "epoch:35 step:32950 [D loss: 0.252313, acc.: 55.47%] [G loss: 0.312917]\n",
      "epoch:35 step:32951 [D loss: 0.237069, acc.: 55.47%] [G loss: 0.278309]\n",
      "epoch:35 step:32952 [D loss: 0.246730, acc.: 57.03%] [G loss: 0.280732]\n",
      "epoch:35 step:32953 [D loss: 0.250277, acc.: 52.34%] [G loss: 0.300431]\n",
      "epoch:35 step:32954 [D loss: 0.231801, acc.: 65.62%] [G loss: 0.299128]\n",
      "epoch:35 step:32955 [D loss: 0.232105, acc.: 58.59%] [G loss: 0.308302]\n",
      "epoch:35 step:32956 [D loss: 0.241217, acc.: 57.81%] [G loss: 0.291369]\n",
      "epoch:35 step:32957 [D loss: 0.245447, acc.: 54.69%] [G loss: 0.283217]\n",
      "epoch:35 step:32958 [D loss: 0.237652, acc.: 60.94%] [G loss: 0.285774]\n",
      "epoch:35 step:32959 [D loss: 0.228269, acc.: 64.84%] [G loss: 0.305391]\n",
      "epoch:35 step:32960 [D loss: 0.251417, acc.: 51.56%] [G loss: 0.313421]\n",
      "epoch:35 step:32961 [D loss: 0.245531, acc.: 55.47%] [G loss: 0.312706]\n",
      "epoch:35 step:32962 [D loss: 0.241632, acc.: 56.25%] [G loss: 0.291445]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:35 step:32963 [D loss: 0.231471, acc.: 58.59%] [G loss: 0.277034]\n",
      "epoch:35 step:32964 [D loss: 0.241871, acc.: 54.69%] [G loss: 0.306154]\n",
      "epoch:35 step:32965 [D loss: 0.248326, acc.: 58.59%] [G loss: 0.319340]\n",
      "epoch:35 step:32966 [D loss: 0.242776, acc.: 57.03%] [G loss: 0.327723]\n",
      "epoch:35 step:32967 [D loss: 0.242639, acc.: 58.59%] [G loss: 0.325538]\n",
      "epoch:35 step:32968 [D loss: 0.245014, acc.: 56.25%] [G loss: 0.284804]\n",
      "epoch:35 step:32969 [D loss: 0.227107, acc.: 60.16%] [G loss: 0.297783]\n",
      "epoch:35 step:32970 [D loss: 0.239794, acc.: 55.47%] [G loss: 0.326840]\n",
      "epoch:35 step:32971 [D loss: 0.245071, acc.: 54.69%] [G loss: 0.293638]\n",
      "epoch:35 step:32972 [D loss: 0.240323, acc.: 55.47%] [G loss: 0.336057]\n",
      "epoch:35 step:32973 [D loss: 0.239280, acc.: 58.59%] [G loss: 0.322877]\n",
      "epoch:35 step:32974 [D loss: 0.243313, acc.: 57.81%] [G loss: 0.328890]\n",
      "epoch:35 step:32975 [D loss: 0.221256, acc.: 63.28%] [G loss: 0.300475]\n",
      "epoch:35 step:32976 [D loss: 0.243702, acc.: 53.91%] [G loss: 0.288292]\n",
      "epoch:35 step:32977 [D loss: 0.242479, acc.: 53.91%] [G loss: 0.311518]\n",
      "epoch:35 step:32978 [D loss: 0.222887, acc.: 63.28%] [G loss: 0.328733]\n",
      "epoch:35 step:32979 [D loss: 0.257739, acc.: 51.56%] [G loss: 0.305978]\n",
      "epoch:35 step:32980 [D loss: 0.229024, acc.: 64.06%] [G loss: 0.307888]\n",
      "epoch:35 step:32981 [D loss: 0.237118, acc.: 61.72%] [G loss: 0.303151]\n",
      "epoch:35 step:32982 [D loss: 0.219580, acc.: 65.62%] [G loss: 0.303511]\n",
      "epoch:35 step:32983 [D loss: 0.241444, acc.: 57.03%] [G loss: 0.342226]\n",
      "epoch:35 step:32984 [D loss: 0.234835, acc.: 60.94%] [G loss: 0.293695]\n",
      "epoch:35 step:32985 [D loss: 0.252508, acc.: 52.34%] [G loss: 0.284932]\n",
      "epoch:35 step:32986 [D loss: 0.246102, acc.: 53.12%] [G loss: 0.298655]\n",
      "epoch:35 step:32987 [D loss: 0.230601, acc.: 62.50%] [G loss: 0.295487]\n",
      "epoch:35 step:32988 [D loss: 0.227910, acc.: 61.72%] [G loss: 0.300136]\n",
      "epoch:35 step:32989 [D loss: 0.256013, acc.: 52.34%] [G loss: 0.295361]\n",
      "epoch:35 step:32990 [D loss: 0.252490, acc.: 57.03%] [G loss: 0.329413]\n",
      "epoch:35 step:32991 [D loss: 0.235574, acc.: 57.03%] [G loss: 0.298874]\n",
      "epoch:35 step:32992 [D loss: 0.255717, acc.: 51.56%] [G loss: 0.298787]\n",
      "epoch:35 step:32993 [D loss: 0.244793, acc.: 59.38%] [G loss: 0.283268]\n",
      "epoch:35 step:32994 [D loss: 0.231238, acc.: 60.16%] [G loss: 0.291974]\n",
      "epoch:35 step:32995 [D loss: 0.237711, acc.: 57.81%] [G loss: 0.303357]\n",
      "epoch:35 step:32996 [D loss: 0.208728, acc.: 68.75%] [G loss: 0.311940]\n",
      "epoch:35 step:32997 [D loss: 0.236423, acc.: 57.81%] [G loss: 0.302427]\n",
      "epoch:35 step:32998 [D loss: 0.238994, acc.: 60.16%] [G loss: 0.279761]\n",
      "epoch:35 step:32999 [D loss: 0.231447, acc.: 57.81%] [G loss: 0.318196]\n",
      "epoch:35 step:33000 [D loss: 0.237883, acc.: 57.03%] [G loss: 0.310790]\n",
      "epoch:35 step:33001 [D loss: 0.236798, acc.: 61.72%] [G loss: 0.291533]\n",
      "epoch:35 step:33002 [D loss: 0.254843, acc.: 49.22%] [G loss: 0.302956]\n",
      "epoch:35 step:33003 [D loss: 0.236930, acc.: 58.59%] [G loss: 0.289022]\n",
      "epoch:35 step:33004 [D loss: 0.237743, acc.: 57.81%] [G loss: 0.311786]\n",
      "epoch:35 step:33005 [D loss: 0.225565, acc.: 60.94%] [G loss: 0.313013]\n",
      "epoch:35 step:33006 [D loss: 0.230428, acc.: 61.72%] [G loss: 0.300894]\n",
      "epoch:35 step:33007 [D loss: 0.251088, acc.: 52.34%] [G loss: 0.329496]\n",
      "epoch:35 step:33008 [D loss: 0.243975, acc.: 57.81%] [G loss: 0.295417]\n",
      "epoch:35 step:33009 [D loss: 0.241508, acc.: 57.81%] [G loss: 0.314381]\n",
      "epoch:35 step:33010 [D loss: 0.234473, acc.: 65.62%] [G loss: 0.320015]\n",
      "epoch:35 step:33011 [D loss: 0.236896, acc.: 55.47%] [G loss: 0.298334]\n",
      "epoch:35 step:33012 [D loss: 0.225993, acc.: 64.84%] [G loss: 0.293087]\n",
      "epoch:35 step:33013 [D loss: 0.245502, acc.: 58.59%] [G loss: 0.288557]\n",
      "epoch:35 step:33014 [D loss: 0.239199, acc.: 58.59%] [G loss: 0.290943]\n",
      "epoch:35 step:33015 [D loss: 0.219680, acc.: 67.19%] [G loss: 0.291521]\n",
      "epoch:35 step:33016 [D loss: 0.223129, acc.: 71.09%] [G loss: 0.313175]\n",
      "epoch:35 step:33017 [D loss: 0.261994, acc.: 48.44%] [G loss: 0.298289]\n",
      "epoch:35 step:33018 [D loss: 0.235967, acc.: 63.28%] [G loss: 0.300357]\n",
      "epoch:35 step:33019 [D loss: 0.254452, acc.: 55.47%] [G loss: 0.292935]\n",
      "epoch:35 step:33020 [D loss: 0.233962, acc.: 60.94%] [G loss: 0.297457]\n",
      "epoch:35 step:33021 [D loss: 0.244192, acc.: 57.81%] [G loss: 0.299638]\n",
      "epoch:35 step:33022 [D loss: 0.222200, acc.: 65.62%] [G loss: 0.288780]\n",
      "epoch:35 step:33023 [D loss: 0.238181, acc.: 57.81%] [G loss: 0.324649]\n",
      "epoch:35 step:33024 [D loss: 0.244845, acc.: 57.81%] [G loss: 0.298891]\n",
      "epoch:35 step:33025 [D loss: 0.251438, acc.: 56.25%] [G loss: 0.315617]\n",
      "epoch:35 step:33026 [D loss: 0.249752, acc.: 53.91%] [G loss: 0.294025]\n",
      "epoch:35 step:33027 [D loss: 0.250084, acc.: 54.69%] [G loss: 0.283772]\n",
      "epoch:35 step:33028 [D loss: 0.239016, acc.: 57.81%] [G loss: 0.286104]\n",
      "epoch:35 step:33029 [D loss: 0.247225, acc.: 55.47%] [G loss: 0.287860]\n",
      "epoch:35 step:33030 [D loss: 0.224971, acc.: 60.94%] [G loss: 0.303095]\n",
      "epoch:35 step:33031 [D loss: 0.247385, acc.: 55.47%] [G loss: 0.253328]\n",
      "epoch:35 step:33032 [D loss: 0.225014, acc.: 63.28%] [G loss: 0.323403]\n",
      "epoch:35 step:33033 [D loss: 0.228035, acc.: 66.41%] [G loss: 0.286990]\n",
      "epoch:35 step:33034 [D loss: 0.239839, acc.: 56.25%] [G loss: 0.296144]\n",
      "epoch:35 step:33035 [D loss: 0.252716, acc.: 54.69%] [G loss: 0.266120]\n",
      "epoch:35 step:33036 [D loss: 0.231036, acc.: 60.16%] [G loss: 0.301667]\n",
      "epoch:35 step:33037 [D loss: 0.229417, acc.: 61.72%] [G loss: 0.327024]\n",
      "epoch:35 step:33038 [D loss: 0.227531, acc.: 64.84%] [G loss: 0.280021]\n",
      "epoch:35 step:33039 [D loss: 0.248503, acc.: 57.03%] [G loss: 0.285448]\n",
      "epoch:35 step:33040 [D loss: 0.234441, acc.: 57.81%] [G loss: 0.268994]\n",
      "epoch:35 step:33041 [D loss: 0.242262, acc.: 58.59%] [G loss: 0.289276]\n",
      "epoch:35 step:33042 [D loss: 0.235095, acc.: 59.38%] [G loss: 0.293133]\n",
      "epoch:35 step:33043 [D loss: 0.243524, acc.: 56.25%] [G loss: 0.320252]\n",
      "epoch:35 step:33044 [D loss: 0.228047, acc.: 62.50%] [G loss: 0.325821]\n",
      "epoch:35 step:33045 [D loss: 0.234877, acc.: 59.38%] [G loss: 0.317756]\n",
      "epoch:35 step:33046 [D loss: 0.241305, acc.: 54.69%] [G loss: 0.269790]\n",
      "epoch:35 step:33047 [D loss: 0.222942, acc.: 61.72%] [G loss: 0.309184]\n",
      "epoch:35 step:33048 [D loss: 0.236981, acc.: 60.16%] [G loss: 0.283296]\n",
      "epoch:35 step:33049 [D loss: 0.254079, acc.: 51.56%] [G loss: 0.300714]\n",
      "epoch:35 step:33050 [D loss: 0.241066, acc.: 56.25%] [G loss: 0.289470]\n",
      "epoch:35 step:33051 [D loss: 0.232976, acc.: 61.72%] [G loss: 0.305861]\n",
      "epoch:35 step:33052 [D loss: 0.238690, acc.: 57.03%] [G loss: 0.296977]\n",
      "epoch:35 step:33053 [D loss: 0.233822, acc.: 60.94%] [G loss: 0.289809]\n",
      "epoch:35 step:33054 [D loss: 0.243968, acc.: 53.91%] [G loss: 0.298548]\n",
      "epoch:35 step:33055 [D loss: 0.230721, acc.: 59.38%] [G loss: 0.272456]\n",
      "epoch:35 step:33056 [D loss: 0.236871, acc.: 62.50%] [G loss: 0.297662]\n",
      "epoch:35 step:33057 [D loss: 0.216456, acc.: 65.62%] [G loss: 0.325179]\n",
      "epoch:35 step:33058 [D loss: 0.254371, acc.: 53.91%] [G loss: 0.290556]\n",
      "epoch:35 step:33059 [D loss: 0.243911, acc.: 53.91%] [G loss: 0.308614]\n",
      "epoch:35 step:33060 [D loss: 0.221565, acc.: 67.97%] [G loss: 0.304686]\n",
      "epoch:35 step:33061 [D loss: 0.222299, acc.: 65.62%] [G loss: 0.306300]\n",
      "epoch:35 step:33062 [D loss: 0.249076, acc.: 50.00%] [G loss: 0.297360]\n",
      "epoch:35 step:33063 [D loss: 0.240711, acc.: 58.59%] [G loss: 0.316178]\n",
      "epoch:35 step:33064 [D loss: 0.240549, acc.: 57.81%] [G loss: 0.287282]\n",
      "epoch:35 step:33065 [D loss: 0.234466, acc.: 58.59%] [G loss: 0.305744]\n",
      "epoch:35 step:33066 [D loss: 0.249975, acc.: 50.78%] [G loss: 0.307368]\n",
      "epoch:35 step:33067 [D loss: 0.227383, acc.: 62.50%] [G loss: 0.316450]\n",
      "epoch:35 step:33068 [D loss: 0.225369, acc.: 63.28%] [G loss: 0.310738]\n",
      "epoch:35 step:33069 [D loss: 0.233503, acc.: 59.38%] [G loss: 0.297442]\n",
      "epoch:35 step:33070 [D loss: 0.238444, acc.: 57.81%] [G loss: 0.308514]\n",
      "epoch:35 step:33071 [D loss: 0.254388, acc.: 50.00%] [G loss: 0.295117]\n",
      "epoch:35 step:33072 [D loss: 0.219516, acc.: 66.41%] [G loss: 0.294125]\n",
      "epoch:35 step:33073 [D loss: 0.252740, acc.: 52.34%] [G loss: 0.277098]\n",
      "epoch:35 step:33074 [D loss: 0.254083, acc.: 53.12%] [G loss: 0.307070]\n",
      "epoch:35 step:33075 [D loss: 0.250900, acc.: 52.34%] [G loss: 0.319765]\n",
      "epoch:35 step:33076 [D loss: 0.246562, acc.: 57.81%] [G loss: 0.295916]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:35 step:33077 [D loss: 0.246716, acc.: 58.59%] [G loss: 0.288193]\n",
      "epoch:35 step:33078 [D loss: 0.223500, acc.: 67.97%] [G loss: 0.270139]\n",
      "epoch:35 step:33079 [D loss: 0.242975, acc.: 61.72%] [G loss: 0.316058]\n",
      "epoch:35 step:33080 [D loss: 0.217565, acc.: 67.19%] [G loss: 0.303354]\n",
      "epoch:35 step:33081 [D loss: 0.230855, acc.: 56.25%] [G loss: 0.296379]\n",
      "epoch:35 step:33082 [D loss: 0.237704, acc.: 60.16%] [G loss: 0.287663]\n",
      "epoch:35 step:33083 [D loss: 0.244101, acc.: 55.47%] [G loss: 0.302025]\n",
      "epoch:35 step:33084 [D loss: 0.239531, acc.: 62.50%] [G loss: 0.326116]\n",
      "epoch:35 step:33085 [D loss: 0.225411, acc.: 64.06%] [G loss: 0.307562]\n",
      "epoch:35 step:33086 [D loss: 0.236322, acc.: 59.38%] [G loss: 0.301376]\n",
      "epoch:35 step:33087 [D loss: 0.241532, acc.: 58.59%] [G loss: 0.265945]\n",
      "epoch:35 step:33088 [D loss: 0.245276, acc.: 52.34%] [G loss: 0.271065]\n",
      "epoch:35 step:33089 [D loss: 0.250944, acc.: 56.25%] [G loss: 0.310426]\n",
      "epoch:35 step:33090 [D loss: 0.234345, acc.: 60.16%] [G loss: 0.311594]\n",
      "epoch:35 step:33091 [D loss: 0.245443, acc.: 53.12%] [G loss: 0.299681]\n",
      "epoch:35 step:33092 [D loss: 0.242697, acc.: 60.94%] [G loss: 0.307274]\n",
      "epoch:35 step:33093 [D loss: 0.238612, acc.: 54.69%] [G loss: 0.314001]\n",
      "epoch:35 step:33094 [D loss: 0.244639, acc.: 53.12%] [G loss: 0.308723]\n",
      "epoch:35 step:33095 [D loss: 0.236348, acc.: 65.62%] [G loss: 0.288134]\n",
      "epoch:35 step:33096 [D loss: 0.255819, acc.: 51.56%] [G loss: 0.295020]\n",
      "epoch:35 step:33097 [D loss: 0.241687, acc.: 50.00%] [G loss: 0.284383]\n",
      "epoch:35 step:33098 [D loss: 0.251926, acc.: 57.03%] [G loss: 0.296687]\n",
      "epoch:35 step:33099 [D loss: 0.244662, acc.: 52.34%] [G loss: 0.295305]\n",
      "epoch:35 step:33100 [D loss: 0.244017, acc.: 63.28%] [G loss: 0.274279]\n",
      "epoch:35 step:33101 [D loss: 0.234945, acc.: 59.38%] [G loss: 0.310394]\n",
      "epoch:35 step:33102 [D loss: 0.239948, acc.: 61.72%] [G loss: 0.290711]\n",
      "epoch:35 step:33103 [D loss: 0.232812, acc.: 57.81%] [G loss: 0.285452]\n",
      "epoch:35 step:33104 [D loss: 0.237479, acc.: 58.59%] [G loss: 0.304583]\n",
      "epoch:35 step:33105 [D loss: 0.247836, acc.: 53.91%] [G loss: 0.276527]\n",
      "epoch:35 step:33106 [D loss: 0.255054, acc.: 53.91%] [G loss: 0.293491]\n",
      "epoch:35 step:33107 [D loss: 0.241704, acc.: 60.94%] [G loss: 0.299914]\n",
      "epoch:35 step:33108 [D loss: 0.244422, acc.: 56.25%] [G loss: 0.276018]\n",
      "epoch:35 step:33109 [D loss: 0.233084, acc.: 64.06%] [G loss: 0.294242]\n",
      "epoch:35 step:33110 [D loss: 0.242678, acc.: 54.69%] [G loss: 0.283190]\n",
      "epoch:35 step:33111 [D loss: 0.241995, acc.: 61.72%] [G loss: 0.316455]\n",
      "epoch:35 step:33112 [D loss: 0.225343, acc.: 63.28%] [G loss: 0.297695]\n",
      "epoch:35 step:33113 [D loss: 0.251703, acc.: 50.78%] [G loss: 0.307344]\n",
      "epoch:35 step:33114 [D loss: 0.239856, acc.: 58.59%] [G loss: 0.319435]\n",
      "epoch:35 step:33115 [D loss: 0.221808, acc.: 65.62%] [G loss: 0.296609]\n",
      "epoch:35 step:33116 [D loss: 0.231582, acc.: 63.28%] [G loss: 0.287677]\n",
      "epoch:35 step:33117 [D loss: 0.247966, acc.: 57.03%] [G loss: 0.317777]\n",
      "epoch:35 step:33118 [D loss: 0.256037, acc.: 53.12%] [G loss: 0.329633]\n",
      "epoch:35 step:33119 [D loss: 0.234989, acc.: 62.50%] [G loss: 0.306115]\n",
      "epoch:35 step:33120 [D loss: 0.229340, acc.: 60.94%] [G loss: 0.298814]\n",
      "epoch:35 step:33121 [D loss: 0.255348, acc.: 51.56%] [G loss: 0.296163]\n",
      "epoch:35 step:33122 [D loss: 0.221967, acc.: 60.94%] [G loss: 0.310613]\n",
      "epoch:35 step:33123 [D loss: 0.235678, acc.: 60.16%] [G loss: 0.291565]\n",
      "epoch:35 step:33124 [D loss: 0.242201, acc.: 60.16%] [G loss: 0.303809]\n",
      "epoch:35 step:33125 [D loss: 0.236735, acc.: 57.03%] [G loss: 0.310408]\n",
      "epoch:35 step:33126 [D loss: 0.226530, acc.: 64.84%] [G loss: 0.330088]\n",
      "epoch:35 step:33127 [D loss: 0.228707, acc.: 62.50%] [G loss: 0.320426]\n",
      "epoch:35 step:33128 [D loss: 0.240628, acc.: 59.38%] [G loss: 0.316657]\n",
      "epoch:35 step:33129 [D loss: 0.236212, acc.: 58.59%] [G loss: 0.297116]\n",
      "epoch:35 step:33130 [D loss: 0.239343, acc.: 60.94%] [G loss: 0.322896]\n",
      "epoch:35 step:33131 [D loss: 0.238177, acc.: 60.94%] [G loss: 0.272891]\n",
      "epoch:35 step:33132 [D loss: 0.247073, acc.: 52.34%] [G loss: 0.278606]\n",
      "epoch:35 step:33133 [D loss: 0.231208, acc.: 60.16%] [G loss: 0.326662]\n",
      "epoch:35 step:33134 [D loss: 0.226643, acc.: 61.72%] [G loss: 0.336652]\n",
      "epoch:35 step:33135 [D loss: 0.243123, acc.: 55.47%] [G loss: 0.297014]\n",
      "epoch:35 step:33136 [D loss: 0.238517, acc.: 54.69%] [G loss: 0.284281]\n",
      "epoch:35 step:33137 [D loss: 0.224924, acc.: 66.41%] [G loss: 0.315438]\n",
      "epoch:35 step:33138 [D loss: 0.236641, acc.: 63.28%] [G loss: 0.327356]\n",
      "epoch:35 step:33139 [D loss: 0.244287, acc.: 57.03%] [G loss: 0.293425]\n",
      "epoch:35 step:33140 [D loss: 0.245265, acc.: 53.12%] [G loss: 0.301511]\n",
      "epoch:35 step:33141 [D loss: 0.256782, acc.: 57.03%] [G loss: 0.305586]\n",
      "epoch:35 step:33142 [D loss: 0.252372, acc.: 51.56%] [G loss: 0.320606]\n",
      "epoch:35 step:33143 [D loss: 0.240615, acc.: 58.59%] [G loss: 0.292513]\n",
      "epoch:35 step:33144 [D loss: 0.236305, acc.: 58.59%] [G loss: 0.293553]\n",
      "epoch:35 step:33145 [D loss: 0.255122, acc.: 50.78%] [G loss: 0.269249]\n",
      "epoch:35 step:33146 [D loss: 0.231152, acc.: 63.28%] [G loss: 0.340198]\n",
      "epoch:35 step:33147 [D loss: 0.260354, acc.: 50.78%] [G loss: 0.303448]\n",
      "epoch:35 step:33148 [D loss: 0.249876, acc.: 55.47%] [G loss: 0.317055]\n",
      "epoch:35 step:33149 [D loss: 0.233735, acc.: 62.50%] [G loss: 0.293123]\n",
      "epoch:35 step:33150 [D loss: 0.244595, acc.: 53.91%] [G loss: 0.293312]\n",
      "epoch:35 step:33151 [D loss: 0.223218, acc.: 62.50%] [G loss: 0.289531]\n",
      "epoch:35 step:33152 [D loss: 0.251013, acc.: 56.25%] [G loss: 0.282110]\n",
      "epoch:35 step:33153 [D loss: 0.252355, acc.: 50.78%] [G loss: 0.294461]\n",
      "epoch:35 step:33154 [D loss: 0.256926, acc.: 52.34%] [G loss: 0.278508]\n",
      "epoch:35 step:33155 [D loss: 0.248311, acc.: 53.91%] [G loss: 0.299468]\n",
      "epoch:35 step:33156 [D loss: 0.226670, acc.: 64.84%] [G loss: 0.282775]\n",
      "epoch:35 step:33157 [D loss: 0.243834, acc.: 53.12%] [G loss: 0.273416]\n",
      "epoch:35 step:33158 [D loss: 0.245153, acc.: 57.81%] [G loss: 0.310958]\n",
      "epoch:35 step:33159 [D loss: 0.233368, acc.: 60.16%] [G loss: 0.299299]\n",
      "epoch:35 step:33160 [D loss: 0.245325, acc.: 57.81%] [G loss: 0.306181]\n",
      "epoch:35 step:33161 [D loss: 0.240871, acc.: 54.69%] [G loss: 0.309824]\n",
      "epoch:35 step:33162 [D loss: 0.230538, acc.: 60.16%] [G loss: 0.274436]\n",
      "epoch:35 step:33163 [D loss: 0.221248, acc.: 64.84%] [G loss: 0.299232]\n",
      "epoch:35 step:33164 [D loss: 0.248885, acc.: 54.69%] [G loss: 0.303605]\n",
      "epoch:35 step:33165 [D loss: 0.254924, acc.: 50.78%] [G loss: 0.316379]\n",
      "epoch:35 step:33166 [D loss: 0.222416, acc.: 64.06%] [G loss: 0.320620]\n",
      "epoch:35 step:33167 [D loss: 0.254427, acc.: 53.91%] [G loss: 0.286083]\n",
      "epoch:35 step:33168 [D loss: 0.238967, acc.: 54.69%] [G loss: 0.302972]\n",
      "epoch:35 step:33169 [D loss: 0.247848, acc.: 53.91%] [G loss: 0.301995]\n",
      "epoch:35 step:33170 [D loss: 0.262952, acc.: 46.88%] [G loss: 0.288225]\n",
      "epoch:35 step:33171 [D loss: 0.235872, acc.: 64.06%] [G loss: 0.294726]\n",
      "epoch:35 step:33172 [D loss: 0.226533, acc.: 59.38%] [G loss: 0.279241]\n",
      "epoch:35 step:33173 [D loss: 0.224316, acc.: 61.72%] [G loss: 0.314076]\n",
      "epoch:35 step:33174 [D loss: 0.224336, acc.: 63.28%] [G loss: 0.284678]\n",
      "epoch:35 step:33175 [D loss: 0.235256, acc.: 57.81%] [G loss: 0.308264]\n",
      "epoch:35 step:33176 [D loss: 0.256098, acc.: 53.91%] [G loss: 0.292792]\n",
      "epoch:35 step:33177 [D loss: 0.245241, acc.: 57.03%] [G loss: 0.266930]\n",
      "epoch:35 step:33178 [D loss: 0.248107, acc.: 51.56%] [G loss: 0.292582]\n",
      "epoch:35 step:33179 [D loss: 0.233121, acc.: 57.03%] [G loss: 0.308641]\n",
      "epoch:35 step:33180 [D loss: 0.249548, acc.: 55.47%] [G loss: 0.294808]\n",
      "epoch:35 step:33181 [D loss: 0.241605, acc.: 57.81%] [G loss: 0.310642]\n",
      "epoch:35 step:33182 [D loss: 0.232268, acc.: 63.28%] [G loss: 0.295433]\n",
      "epoch:35 step:33183 [D loss: 0.256218, acc.: 54.69%] [G loss: 0.288651]\n",
      "epoch:35 step:33184 [D loss: 0.231074, acc.: 61.72%] [G loss: 0.306045]\n",
      "epoch:35 step:33185 [D loss: 0.251882, acc.: 54.69%] [G loss: 0.292109]\n",
      "epoch:35 step:33186 [D loss: 0.255240, acc.: 54.69%] [G loss: 0.293854]\n",
      "epoch:35 step:33187 [D loss: 0.235904, acc.: 57.81%] [G loss: 0.289741]\n",
      "epoch:35 step:33188 [D loss: 0.241164, acc.: 55.47%] [G loss: 0.305910]\n",
      "epoch:35 step:33189 [D loss: 0.248984, acc.: 53.91%] [G loss: 0.312778]\n",
      "epoch:35 step:33190 [D loss: 0.242117, acc.: 57.81%] [G loss: 0.292498]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:35 step:33191 [D loss: 0.249725, acc.: 53.91%] [G loss: 0.309383]\n",
      "epoch:35 step:33192 [D loss: 0.242747, acc.: 60.16%] [G loss: 0.306798]\n",
      "epoch:35 step:33193 [D loss: 0.244399, acc.: 53.91%] [G loss: 0.315719]\n",
      "epoch:35 step:33194 [D loss: 0.233205, acc.: 58.59%] [G loss: 0.297342]\n",
      "epoch:35 step:33195 [D loss: 0.237134, acc.: 60.16%] [G loss: 0.311554]\n",
      "epoch:35 step:33196 [D loss: 0.222832, acc.: 65.62%] [G loss: 0.290070]\n",
      "epoch:35 step:33197 [D loss: 0.226270, acc.: 60.16%] [G loss: 0.327348]\n",
      "epoch:35 step:33198 [D loss: 0.236657, acc.: 60.94%] [G loss: 0.294605]\n",
      "epoch:35 step:33199 [D loss: 0.235741, acc.: 64.84%] [G loss: 0.288119]\n",
      "epoch:35 step:33200 [D loss: 0.240433, acc.: 55.47%] [G loss: 0.292123]\n",
      "epoch:35 step:33201 [D loss: 0.262538, acc.: 50.78%] [G loss: 0.293131]\n",
      "epoch:35 step:33202 [D loss: 0.236121, acc.: 58.59%] [G loss: 0.279854]\n",
      "epoch:35 step:33203 [D loss: 0.228980, acc.: 60.94%] [G loss: 0.295941]\n",
      "epoch:35 step:33204 [D loss: 0.242457, acc.: 62.50%] [G loss: 0.313273]\n",
      "epoch:35 step:33205 [D loss: 0.235815, acc.: 57.81%] [G loss: 0.288497]\n",
      "epoch:35 step:33206 [D loss: 0.250359, acc.: 56.25%] [G loss: 0.291073]\n",
      "epoch:35 step:33207 [D loss: 0.237210, acc.: 60.16%] [G loss: 0.331879]\n",
      "epoch:35 step:33208 [D loss: 0.232781, acc.: 63.28%] [G loss: 0.310122]\n",
      "epoch:35 step:33209 [D loss: 0.234873, acc.: 57.81%] [G loss: 0.294880]\n",
      "epoch:35 step:33210 [D loss: 0.226553, acc.: 59.38%] [G loss: 0.289916]\n",
      "epoch:35 step:33211 [D loss: 0.232678, acc.: 60.16%] [G loss: 0.315251]\n",
      "epoch:35 step:33212 [D loss: 0.247323, acc.: 56.25%] [G loss: 0.305256]\n",
      "epoch:35 step:33213 [D loss: 0.242237, acc.: 60.94%] [G loss: 0.304844]\n",
      "epoch:35 step:33214 [D loss: 0.234840, acc.: 57.81%] [G loss: 0.284481]\n",
      "epoch:35 step:33215 [D loss: 0.230963, acc.: 62.50%] [G loss: 0.313723]\n",
      "epoch:35 step:33216 [D loss: 0.235714, acc.: 62.50%] [G loss: 0.312632]\n",
      "epoch:35 step:33217 [D loss: 0.227749, acc.: 60.94%] [G loss: 0.323552]\n",
      "epoch:35 step:33218 [D loss: 0.258107, acc.: 46.88%] [G loss: 0.280222]\n",
      "epoch:35 step:33219 [D loss: 0.244527, acc.: 58.59%] [G loss: 0.290932]\n",
      "epoch:35 step:33220 [D loss: 0.231074, acc.: 57.03%] [G loss: 0.305899]\n",
      "epoch:35 step:33221 [D loss: 0.239269, acc.: 58.59%] [G loss: 0.337659]\n",
      "epoch:35 step:33222 [D loss: 0.242198, acc.: 58.59%] [G loss: 0.296530]\n",
      "epoch:35 step:33223 [D loss: 0.246618, acc.: 50.78%] [G loss: 0.333500]\n",
      "epoch:35 step:33224 [D loss: 0.241192, acc.: 55.47%] [G loss: 0.316051]\n",
      "epoch:35 step:33225 [D loss: 0.259892, acc.: 49.22%] [G loss: 0.288483]\n",
      "epoch:35 step:33226 [D loss: 0.227817, acc.: 64.84%] [G loss: 0.288200]\n",
      "epoch:35 step:33227 [D loss: 0.232696, acc.: 56.25%] [G loss: 0.287890]\n",
      "epoch:35 step:33228 [D loss: 0.222112, acc.: 66.41%] [G loss: 0.314754]\n",
      "epoch:35 step:33229 [D loss: 0.243208, acc.: 60.16%] [G loss: 0.277338]\n",
      "epoch:35 step:33230 [D loss: 0.240874, acc.: 57.81%] [G loss: 0.318747]\n",
      "epoch:35 step:33231 [D loss: 0.232085, acc.: 58.59%] [G loss: 0.295019]\n",
      "epoch:35 step:33232 [D loss: 0.244293, acc.: 57.03%] [G loss: 0.288266]\n",
      "epoch:35 step:33233 [D loss: 0.236462, acc.: 64.06%] [G loss: 0.338206]\n",
      "epoch:35 step:33234 [D loss: 0.255419, acc.: 56.25%] [G loss: 0.288740]\n",
      "epoch:35 step:33235 [D loss: 0.235614, acc.: 57.03%] [G loss: 0.341834]\n",
      "epoch:35 step:33236 [D loss: 0.233732, acc.: 57.03%] [G loss: 0.311407]\n",
      "epoch:35 step:33237 [D loss: 0.247426, acc.: 57.81%] [G loss: 0.276306]\n",
      "epoch:35 step:33238 [D loss: 0.236178, acc.: 62.50%] [G loss: 0.329646]\n",
      "epoch:35 step:33239 [D loss: 0.244924, acc.: 53.91%] [G loss: 0.323758]\n",
      "epoch:35 step:33240 [D loss: 0.233546, acc.: 60.94%] [G loss: 0.312554]\n",
      "epoch:35 step:33241 [D loss: 0.252071, acc.: 50.78%] [G loss: 0.298178]\n",
      "epoch:35 step:33242 [D loss: 0.243730, acc.: 62.50%] [G loss: 0.297928]\n",
      "epoch:35 step:33243 [D loss: 0.240541, acc.: 61.72%] [G loss: 0.298281]\n",
      "epoch:35 step:33244 [D loss: 0.255056, acc.: 51.56%] [G loss: 0.271146]\n",
      "epoch:35 step:33245 [D loss: 0.235370, acc.: 63.28%] [G loss: 0.302664]\n",
      "epoch:35 step:33246 [D loss: 0.240448, acc.: 57.81%] [G loss: 0.298911]\n",
      "epoch:35 step:33247 [D loss: 0.243620, acc.: 53.12%] [G loss: 0.292578]\n",
      "epoch:35 step:33248 [D loss: 0.236180, acc.: 60.16%] [G loss: 0.303215]\n",
      "epoch:35 step:33249 [D loss: 0.232656, acc.: 65.62%] [G loss: 0.302695]\n",
      "epoch:35 step:33250 [D loss: 0.258218, acc.: 52.34%] [G loss: 0.279815]\n",
      "epoch:35 step:33251 [D loss: 0.250805, acc.: 50.78%] [G loss: 0.281924]\n",
      "epoch:35 step:33252 [D loss: 0.227453, acc.: 67.97%] [G loss: 0.332263]\n",
      "epoch:35 step:33253 [D loss: 0.259514, acc.: 48.44%] [G loss: 0.308508]\n",
      "epoch:35 step:33254 [D loss: 0.253520, acc.: 55.47%] [G loss: 0.292461]\n",
      "epoch:35 step:33255 [D loss: 0.245278, acc.: 59.38%] [G loss: 0.320200]\n",
      "epoch:35 step:33256 [D loss: 0.245069, acc.: 53.91%] [G loss: 0.303701]\n",
      "epoch:35 step:33257 [D loss: 0.233390, acc.: 57.03%] [G loss: 0.323504]\n",
      "epoch:35 step:33258 [D loss: 0.241006, acc.: 53.12%] [G loss: 0.337526]\n",
      "epoch:35 step:33259 [D loss: 0.238137, acc.: 59.38%] [G loss: 0.313970]\n",
      "epoch:35 step:33260 [D loss: 0.243350, acc.: 53.91%] [G loss: 0.278333]\n",
      "epoch:35 step:33261 [D loss: 0.248699, acc.: 51.56%] [G loss: 0.282895]\n",
      "epoch:35 step:33262 [D loss: 0.246943, acc.: 56.25%] [G loss: 0.320168]\n",
      "epoch:35 step:33263 [D loss: 0.238739, acc.: 62.50%] [G loss: 0.299495]\n",
      "epoch:35 step:33264 [D loss: 0.224073, acc.: 59.38%] [G loss: 0.315806]\n",
      "epoch:35 step:33265 [D loss: 0.237724, acc.: 60.94%] [G loss: 0.325225]\n",
      "epoch:35 step:33266 [D loss: 0.246549, acc.: 53.91%] [G loss: 0.262917]\n",
      "epoch:35 step:33267 [D loss: 0.241533, acc.: 51.56%] [G loss: 0.293458]\n",
      "epoch:35 step:33268 [D loss: 0.233084, acc.: 59.38%] [G loss: 0.272338]\n",
      "epoch:35 step:33269 [D loss: 0.250121, acc.: 56.25%] [G loss: 0.290449]\n",
      "epoch:35 step:33270 [D loss: 0.248669, acc.: 52.34%] [G loss: 0.274671]\n",
      "epoch:35 step:33271 [D loss: 0.249609, acc.: 57.81%] [G loss: 0.307380]\n",
      "epoch:35 step:33272 [D loss: 0.244024, acc.: 53.91%] [G loss: 0.278263]\n",
      "epoch:35 step:33273 [D loss: 0.230486, acc.: 66.41%] [G loss: 0.318168]\n",
      "epoch:35 step:33274 [D loss: 0.241655, acc.: 53.12%] [G loss: 0.304504]\n",
      "epoch:35 step:33275 [D loss: 0.244469, acc.: 53.91%] [G loss: 0.293619]\n",
      "epoch:35 step:33276 [D loss: 0.243417, acc.: 59.38%] [G loss: 0.292880]\n",
      "epoch:35 step:33277 [D loss: 0.244408, acc.: 53.91%] [G loss: 0.299397]\n",
      "epoch:35 step:33278 [D loss: 0.262464, acc.: 50.78%] [G loss: 0.296876]\n",
      "epoch:35 step:33279 [D loss: 0.233266, acc.: 60.94%] [G loss: 0.280015]\n",
      "epoch:35 step:33280 [D loss: 0.232185, acc.: 61.72%] [G loss: 0.303306]\n",
      "epoch:35 step:33281 [D loss: 0.222547, acc.: 62.50%] [G loss: 0.304695]\n",
      "epoch:35 step:33282 [D loss: 0.247379, acc.: 56.25%] [G loss: 0.307705]\n",
      "epoch:35 step:33283 [D loss: 0.227139, acc.: 66.41%] [G loss: 0.296459]\n",
      "epoch:35 step:33284 [D loss: 0.247989, acc.: 57.03%] [G loss: 0.285764]\n",
      "epoch:35 step:33285 [D loss: 0.231927, acc.: 60.16%] [G loss: 0.294706]\n",
      "epoch:35 step:33286 [D loss: 0.229961, acc.: 64.84%] [G loss: 0.290869]\n",
      "epoch:35 step:33287 [D loss: 0.246988, acc.: 55.47%] [G loss: 0.323448]\n",
      "epoch:35 step:33288 [D loss: 0.226487, acc.: 64.06%] [G loss: 0.274235]\n",
      "epoch:35 step:33289 [D loss: 0.232476, acc.: 60.16%] [G loss: 0.336615]\n",
      "epoch:35 step:33290 [D loss: 0.252537, acc.: 55.47%] [G loss: 0.288460]\n",
      "epoch:35 step:33291 [D loss: 0.249876, acc.: 52.34%] [G loss: 0.268786]\n",
      "epoch:35 step:33292 [D loss: 0.218798, acc.: 68.75%] [G loss: 0.284920]\n",
      "epoch:35 step:33293 [D loss: 0.244157, acc.: 58.59%] [G loss: 0.277548]\n",
      "epoch:35 step:33294 [D loss: 0.240110, acc.: 57.81%] [G loss: 0.291212]\n",
      "epoch:35 step:33295 [D loss: 0.271553, acc.: 44.53%] [G loss: 0.297351]\n",
      "epoch:35 step:33296 [D loss: 0.246297, acc.: 56.25%] [G loss: 0.287723]\n",
      "epoch:35 step:33297 [D loss: 0.241072, acc.: 58.59%] [G loss: 0.298547]\n",
      "epoch:35 step:33298 [D loss: 0.249981, acc.: 57.03%] [G loss: 0.282311]\n",
      "epoch:35 step:33299 [D loss: 0.244800, acc.: 53.91%] [G loss: 0.263650]\n",
      "epoch:35 step:33300 [D loss: 0.251534, acc.: 49.22%] [G loss: 0.289868]\n",
      "epoch:35 step:33301 [D loss: 0.233521, acc.: 60.94%] [G loss: 0.276981]\n",
      "epoch:35 step:33302 [D loss: 0.232917, acc.: 60.16%] [G loss: 0.298817]\n",
      "epoch:35 step:33303 [D loss: 0.236626, acc.: 58.59%] [G loss: 0.298263]\n",
      "epoch:35 step:33304 [D loss: 0.240600, acc.: 54.69%] [G loss: 0.325532]\n",
      "epoch:35 step:33305 [D loss: 0.246599, acc.: 51.56%] [G loss: 0.296725]\n",
      "epoch:35 step:33306 [D loss: 0.257810, acc.: 53.12%] [G loss: 0.275852]\n",
      "epoch:35 step:33307 [D loss: 0.234931, acc.: 62.50%] [G loss: 0.296659]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:35 step:33308 [D loss: 0.233556, acc.: 62.50%] [G loss: 0.288220]\n",
      "epoch:35 step:33309 [D loss: 0.225379, acc.: 63.28%] [G loss: 0.299614]\n",
      "epoch:35 step:33310 [D loss: 0.245422, acc.: 52.34%] [G loss: 0.325244]\n",
      "epoch:35 step:33311 [D loss: 0.235808, acc.: 60.16%] [G loss: 0.282300]\n",
      "epoch:35 step:33312 [D loss: 0.227169, acc.: 60.94%] [G loss: 0.279046]\n",
      "epoch:35 step:33313 [D loss: 0.248414, acc.: 55.47%] [G loss: 0.318694]\n",
      "epoch:35 step:33314 [D loss: 0.231940, acc.: 59.38%] [G loss: 0.301506]\n",
      "epoch:35 step:33315 [D loss: 0.244996, acc.: 58.59%] [G loss: 0.296710]\n",
      "epoch:35 step:33316 [D loss: 0.236253, acc.: 59.38%] [G loss: 0.273090]\n",
      "epoch:35 step:33317 [D loss: 0.247213, acc.: 48.44%] [G loss: 0.324285]\n",
      "epoch:35 step:33318 [D loss: 0.247437, acc.: 52.34%] [G loss: 0.308956]\n",
      "epoch:35 step:33319 [D loss: 0.238644, acc.: 57.81%] [G loss: 0.325876]\n",
      "epoch:35 step:33320 [D loss: 0.224974, acc.: 66.41%] [G loss: 0.308947]\n",
      "epoch:35 step:33321 [D loss: 0.234283, acc.: 60.16%] [G loss: 0.285072]\n",
      "epoch:35 step:33322 [D loss: 0.272289, acc.: 47.66%] [G loss: 0.311095]\n",
      "epoch:35 step:33323 [D loss: 0.232655, acc.: 57.81%] [G loss: 0.294092]\n",
      "epoch:35 step:33324 [D loss: 0.231020, acc.: 60.16%] [G loss: 0.315700]\n",
      "epoch:35 step:33325 [D loss: 0.237626, acc.: 56.25%] [G loss: 0.344864]\n",
      "epoch:35 step:33326 [D loss: 0.235415, acc.: 57.81%] [G loss: 0.293494]\n",
      "epoch:35 step:33327 [D loss: 0.237325, acc.: 58.59%] [G loss: 0.306989]\n",
      "epoch:35 step:33328 [D loss: 0.236151, acc.: 59.38%] [G loss: 0.334144]\n",
      "epoch:35 step:33329 [D loss: 0.243204, acc.: 52.34%] [G loss: 0.311506]\n",
      "epoch:35 step:33330 [D loss: 0.224265, acc.: 63.28%] [G loss: 0.291226]\n",
      "epoch:35 step:33331 [D loss: 0.235168, acc.: 61.72%] [G loss: 0.310342]\n",
      "epoch:35 step:33332 [D loss: 0.261000, acc.: 54.69%] [G loss: 0.312433]\n",
      "epoch:35 step:33333 [D loss: 0.253212, acc.: 53.91%] [G loss: 0.292386]\n",
      "epoch:35 step:33334 [D loss: 0.236226, acc.: 63.28%] [G loss: 0.307122]\n",
      "epoch:35 step:33335 [D loss: 0.221582, acc.: 66.41%] [G loss: 0.332400]\n",
      "epoch:35 step:33336 [D loss: 0.226294, acc.: 60.16%] [G loss: 0.306262]\n",
      "epoch:35 step:33337 [D loss: 0.228582, acc.: 60.16%] [G loss: 0.282410]\n",
      "epoch:35 step:33338 [D loss: 0.228198, acc.: 61.72%] [G loss: 0.290976]\n",
      "epoch:35 step:33339 [D loss: 0.249674, acc.: 57.03%] [G loss: 0.284632]\n",
      "epoch:35 step:33340 [D loss: 0.245035, acc.: 61.72%] [G loss: 0.286825]\n",
      "epoch:35 step:33341 [D loss: 0.243024, acc.: 55.47%] [G loss: 0.291679]\n",
      "epoch:35 step:33342 [D loss: 0.235323, acc.: 59.38%] [G loss: 0.310342]\n",
      "epoch:35 step:33343 [D loss: 0.249325, acc.: 53.91%] [G loss: 0.289995]\n",
      "epoch:35 step:33344 [D loss: 0.241680, acc.: 59.38%] [G loss: 0.314768]\n",
      "epoch:35 step:33345 [D loss: 0.235249, acc.: 58.59%] [G loss: 0.273209]\n",
      "epoch:35 step:33346 [D loss: 0.230991, acc.: 62.50%] [G loss: 0.295582]\n",
      "epoch:35 step:33347 [D loss: 0.244853, acc.: 53.91%] [G loss: 0.288629]\n",
      "epoch:35 step:33348 [D loss: 0.240214, acc.: 57.81%] [G loss: 0.284134]\n",
      "epoch:35 step:33349 [D loss: 0.240165, acc.: 57.03%] [G loss: 0.243262]\n",
      "epoch:35 step:33350 [D loss: 0.244721, acc.: 50.00%] [G loss: 0.318481]\n",
      "epoch:35 step:33351 [D loss: 0.219513, acc.: 68.75%] [G loss: 0.300675]\n",
      "epoch:35 step:33352 [D loss: 0.255317, acc.: 51.56%] [G loss: 0.298656]\n",
      "epoch:35 step:33353 [D loss: 0.256111, acc.: 53.91%] [G loss: 0.303986]\n",
      "epoch:35 step:33354 [D loss: 0.255062, acc.: 52.34%] [G loss: 0.284108]\n",
      "epoch:35 step:33355 [D loss: 0.237124, acc.: 58.59%] [G loss: 0.307555]\n",
      "epoch:35 step:33356 [D loss: 0.244096, acc.: 53.91%] [G loss: 0.288671]\n",
      "epoch:35 step:33357 [D loss: 0.260602, acc.: 55.47%] [G loss: 0.289834]\n",
      "epoch:35 step:33358 [D loss: 0.224841, acc.: 64.84%] [G loss: 0.307404]\n",
      "epoch:35 step:33359 [D loss: 0.236834, acc.: 56.25%] [G loss: 0.330997]\n",
      "epoch:35 step:33360 [D loss: 0.243267, acc.: 54.69%] [G loss: 0.289535]\n",
      "epoch:35 step:33361 [D loss: 0.243153, acc.: 53.91%] [G loss: 0.292715]\n",
      "epoch:35 step:33362 [D loss: 0.230329, acc.: 61.72%] [G loss: 0.300996]\n",
      "epoch:35 step:33363 [D loss: 0.249079, acc.: 60.16%] [G loss: 0.314964]\n",
      "epoch:35 step:33364 [D loss: 0.244710, acc.: 58.59%] [G loss: 0.292870]\n",
      "epoch:35 step:33365 [D loss: 0.249274, acc.: 54.69%] [G loss: 0.295372]\n",
      "epoch:35 step:33366 [D loss: 0.242411, acc.: 60.16%] [G loss: 0.306393]\n",
      "epoch:35 step:33367 [D loss: 0.269034, acc.: 50.00%] [G loss: 0.278637]\n",
      "epoch:35 step:33368 [D loss: 0.250285, acc.: 55.47%] [G loss: 0.309163]\n",
      "epoch:35 step:33369 [D loss: 0.243849, acc.: 54.69%] [G loss: 0.291049]\n",
      "epoch:35 step:33370 [D loss: 0.259589, acc.: 50.00%] [G loss: 0.300539]\n",
      "epoch:35 step:33371 [D loss: 0.244963, acc.: 60.94%] [G loss: 0.285312]\n",
      "epoch:35 step:33372 [D loss: 0.238227, acc.: 59.38%] [G loss: 0.292602]\n",
      "epoch:35 step:33373 [D loss: 0.253140, acc.: 48.44%] [G loss: 0.302470]\n",
      "epoch:35 step:33374 [D loss: 0.245433, acc.: 57.81%] [G loss: 0.307225]\n",
      "epoch:35 step:33375 [D loss: 0.238100, acc.: 65.62%] [G loss: 0.318622]\n",
      "epoch:35 step:33376 [D loss: 0.237547, acc.: 58.59%] [G loss: 0.301947]\n",
      "epoch:35 step:33377 [D loss: 0.244178, acc.: 55.47%] [G loss: 0.264279]\n",
      "epoch:35 step:33378 [D loss: 0.255652, acc.: 46.88%] [G loss: 0.259706]\n",
      "epoch:35 step:33379 [D loss: 0.259911, acc.: 50.78%] [G loss: 0.287038]\n",
      "epoch:35 step:33380 [D loss: 0.242245, acc.: 56.25%] [G loss: 0.266668]\n",
      "epoch:35 step:33381 [D loss: 0.252357, acc.: 51.56%] [G loss: 0.270503]\n",
      "epoch:35 step:33382 [D loss: 0.241792, acc.: 60.16%] [G loss: 0.290410]\n",
      "epoch:35 step:33383 [D loss: 0.233996, acc.: 56.25%] [G loss: 0.285645]\n",
      "epoch:35 step:33384 [D loss: 0.237508, acc.: 57.03%] [G loss: 0.314635]\n",
      "epoch:35 step:33385 [D loss: 0.233892, acc.: 58.59%] [G loss: 0.279447]\n",
      "epoch:35 step:33386 [D loss: 0.243736, acc.: 53.91%] [G loss: 0.274335]\n",
      "epoch:35 step:33387 [D loss: 0.250445, acc.: 55.47%] [G loss: 0.283743]\n",
      "epoch:35 step:33388 [D loss: 0.255160, acc.: 56.25%] [G loss: 0.285226]\n",
      "epoch:35 step:33389 [D loss: 0.236632, acc.: 60.94%] [G loss: 0.276060]\n",
      "epoch:35 step:33390 [D loss: 0.243317, acc.: 57.81%] [G loss: 0.267061]\n",
      "epoch:35 step:33391 [D loss: 0.249092, acc.: 51.56%] [G loss: 0.316136]\n",
      "epoch:35 step:33392 [D loss: 0.246433, acc.: 57.81%] [G loss: 0.327546]\n",
      "epoch:35 step:33393 [D loss: 0.261460, acc.: 49.22%] [G loss: 0.244882]\n",
      "epoch:35 step:33394 [D loss: 0.239425, acc.: 61.72%] [G loss: 0.299079]\n",
      "epoch:35 step:33395 [D loss: 0.234758, acc.: 55.47%] [G loss: 0.332915]\n",
      "epoch:35 step:33396 [D loss: 0.262300, acc.: 46.88%] [G loss: 0.325057]\n",
      "epoch:35 step:33397 [D loss: 0.242369, acc.: 58.59%] [G loss: 0.300306]\n",
      "epoch:35 step:33398 [D loss: 0.244828, acc.: 53.12%] [G loss: 0.310199]\n",
      "epoch:35 step:33399 [D loss: 0.237485, acc.: 55.47%] [G loss: 0.301773]\n",
      "epoch:35 step:33400 [D loss: 0.247618, acc.: 53.12%] [G loss: 0.290290]\n",
      "epoch:35 step:33401 [D loss: 0.244087, acc.: 59.38%] [G loss: 0.271979]\n",
      "epoch:35 step:33402 [D loss: 0.234263, acc.: 61.72%] [G loss: 0.287473]\n",
      "epoch:35 step:33403 [D loss: 0.224946, acc.: 60.16%] [G loss: 0.295211]\n",
      "epoch:35 step:33404 [D loss: 0.246996, acc.: 51.56%] [G loss: 0.273549]\n",
      "epoch:35 step:33405 [D loss: 0.218699, acc.: 67.19%] [G loss: 0.302740]\n",
      "epoch:35 step:33406 [D loss: 0.254609, acc.: 50.78%] [G loss: 0.307167]\n",
      "epoch:35 step:33407 [D loss: 0.250252, acc.: 59.38%] [G loss: 0.283796]\n",
      "epoch:35 step:33408 [D loss: 0.235170, acc.: 57.03%] [G loss: 0.292397]\n",
      "epoch:35 step:33409 [D loss: 0.260256, acc.: 53.91%] [G loss: 0.295322]\n",
      "epoch:35 step:33410 [D loss: 0.243088, acc.: 57.03%] [G loss: 0.301103]\n",
      "epoch:35 step:33411 [D loss: 0.244692, acc.: 56.25%] [G loss: 0.313196]\n",
      "epoch:35 step:33412 [D loss: 0.254332, acc.: 59.38%] [G loss: 0.253532]\n",
      "epoch:35 step:33413 [D loss: 0.232070, acc.: 60.16%] [G loss: 0.297007]\n",
      "epoch:35 step:33414 [D loss: 0.235876, acc.: 59.38%] [G loss: 0.280418]\n",
      "epoch:35 step:33415 [D loss: 0.232397, acc.: 62.50%] [G loss: 0.306021]\n",
      "epoch:35 step:33416 [D loss: 0.238565, acc.: 55.47%] [G loss: 0.307626]\n",
      "epoch:35 step:33417 [D loss: 0.230232, acc.: 60.94%] [G loss: 0.297531]\n",
      "epoch:35 step:33418 [D loss: 0.234919, acc.: 59.38%] [G loss: 0.290698]\n",
      "epoch:35 step:33419 [D loss: 0.230901, acc.: 61.72%] [G loss: 0.337757]\n",
      "epoch:35 step:33420 [D loss: 0.244732, acc.: 57.03%] [G loss: 0.290691]\n",
      "epoch:35 step:33421 [D loss: 0.227100, acc.: 64.06%] [G loss: 0.314436]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:35 step:33422 [D loss: 0.230870, acc.: 67.19%] [G loss: 0.318709]\n",
      "epoch:35 step:33423 [D loss: 0.250819, acc.: 57.81%] [G loss: 0.293796]\n",
      "epoch:35 step:33424 [D loss: 0.241831, acc.: 55.47%] [G loss: 0.282940]\n",
      "epoch:35 step:33425 [D loss: 0.227105, acc.: 63.28%] [G loss: 0.293265]\n",
      "epoch:35 step:33426 [D loss: 0.245850, acc.: 55.47%] [G loss: 0.291747]\n",
      "epoch:35 step:33427 [D loss: 0.253014, acc.: 53.91%] [G loss: 0.262401]\n",
      "epoch:35 step:33428 [D loss: 0.240772, acc.: 56.25%] [G loss: 0.318938]\n",
      "epoch:35 step:33429 [D loss: 0.241320, acc.: 53.91%] [G loss: 0.292030]\n",
      "epoch:35 step:33430 [D loss: 0.218829, acc.: 65.62%] [G loss: 0.298947]\n",
      "epoch:35 step:33431 [D loss: 0.241694, acc.: 55.47%] [G loss: 0.289877]\n",
      "epoch:35 step:33432 [D loss: 0.226021, acc.: 64.06%] [G loss: 0.282699]\n",
      "epoch:35 step:33433 [D loss: 0.249979, acc.: 53.91%] [G loss: 0.310340]\n",
      "epoch:35 step:33434 [D loss: 0.255692, acc.: 53.12%] [G loss: 0.292661]\n",
      "epoch:35 step:33435 [D loss: 0.248492, acc.: 60.16%] [G loss: 0.305960]\n",
      "epoch:35 step:33436 [D loss: 0.242460, acc.: 57.81%] [G loss: 0.300714]\n",
      "epoch:35 step:33437 [D loss: 0.256989, acc.: 53.91%] [G loss: 0.300813]\n",
      "epoch:35 step:33438 [D loss: 0.247482, acc.: 51.56%] [G loss: 0.296279]\n",
      "epoch:35 step:33439 [D loss: 0.252887, acc.: 53.91%] [G loss: 0.305089]\n",
      "epoch:35 step:33440 [D loss: 0.243691, acc.: 53.91%] [G loss: 0.315665]\n",
      "epoch:35 step:33441 [D loss: 0.227746, acc.: 58.59%] [G loss: 0.306251]\n",
      "epoch:35 step:33442 [D loss: 0.257638, acc.: 51.56%] [G loss: 0.310499]\n",
      "epoch:35 step:33443 [D loss: 0.238003, acc.: 57.81%] [G loss: 0.274338]\n",
      "epoch:35 step:33444 [D loss: 0.240072, acc.: 55.47%] [G loss: 0.272637]\n",
      "epoch:35 step:33445 [D loss: 0.246566, acc.: 53.91%] [G loss: 0.309367]\n",
      "epoch:35 step:33446 [D loss: 0.223662, acc.: 59.38%] [G loss: 0.290266]\n",
      "epoch:35 step:33447 [D loss: 0.245713, acc.: 58.59%] [G loss: 0.288878]\n",
      "epoch:35 step:33448 [D loss: 0.255885, acc.: 49.22%] [G loss: 0.297151]\n",
      "epoch:35 step:33449 [D loss: 0.240745, acc.: 61.72%] [G loss: 0.282692]\n",
      "epoch:35 step:33450 [D loss: 0.255057, acc.: 57.03%] [G loss: 0.285968]\n",
      "epoch:35 step:33451 [D loss: 0.234642, acc.: 63.28%] [G loss: 0.291607]\n",
      "epoch:35 step:33452 [D loss: 0.232440, acc.: 61.72%] [G loss: 0.291466]\n",
      "epoch:35 step:33453 [D loss: 0.239423, acc.: 53.91%] [G loss: 0.284111]\n",
      "epoch:35 step:33454 [D loss: 0.248017, acc.: 55.47%] [G loss: 0.294392]\n",
      "epoch:35 step:33455 [D loss: 0.238432, acc.: 57.03%] [G loss: 0.291190]\n",
      "epoch:35 step:33456 [D loss: 0.213549, acc.: 67.97%] [G loss: 0.302040]\n",
      "epoch:35 step:33457 [D loss: 0.234519, acc.: 54.69%] [G loss: 0.283780]\n",
      "epoch:35 step:33458 [D loss: 0.243806, acc.: 56.25%] [G loss: 0.327989]\n",
      "epoch:35 step:33459 [D loss: 0.261993, acc.: 46.09%] [G loss: 0.286733]\n",
      "epoch:35 step:33460 [D loss: 0.250836, acc.: 55.47%] [G loss: 0.294441]\n",
      "epoch:35 step:33461 [D loss: 0.232689, acc.: 60.94%] [G loss: 0.300768]\n",
      "epoch:35 step:33462 [D loss: 0.220641, acc.: 67.97%] [G loss: 0.298365]\n",
      "epoch:35 step:33463 [D loss: 0.220647, acc.: 63.28%] [G loss: 0.262043]\n",
      "epoch:35 step:33464 [D loss: 0.242406, acc.: 57.81%] [G loss: 0.274958]\n",
      "epoch:35 step:33465 [D loss: 0.235052, acc.: 59.38%] [G loss: 0.296351]\n",
      "epoch:35 step:33466 [D loss: 0.243446, acc.: 61.72%] [G loss: 0.297359]\n",
      "epoch:35 step:33467 [D loss: 0.253263, acc.: 50.00%] [G loss: 0.323425]\n",
      "epoch:35 step:33468 [D loss: 0.246611, acc.: 53.91%] [G loss: 0.299850]\n",
      "epoch:35 step:33469 [D loss: 0.246637, acc.: 53.91%] [G loss: 0.290496]\n",
      "epoch:35 step:33470 [D loss: 0.243595, acc.: 57.03%] [G loss: 0.305433]\n",
      "epoch:35 step:33471 [D loss: 0.238741, acc.: 58.59%] [G loss: 0.296375]\n",
      "epoch:35 step:33472 [D loss: 0.255478, acc.: 52.34%] [G loss: 0.301959]\n",
      "epoch:35 step:33473 [D loss: 0.246662, acc.: 56.25%] [G loss: 0.310167]\n",
      "epoch:35 step:33474 [D loss: 0.249592, acc.: 53.12%] [G loss: 0.306802]\n",
      "epoch:35 step:33475 [D loss: 0.250670, acc.: 57.81%] [G loss: 0.295756]\n",
      "epoch:35 step:33476 [D loss: 0.261343, acc.: 45.31%] [G loss: 0.263388]\n",
      "epoch:35 step:33477 [D loss: 0.231064, acc.: 59.38%] [G loss: 0.299058]\n",
      "epoch:35 step:33478 [D loss: 0.248909, acc.: 59.38%] [G loss: 0.313835]\n",
      "epoch:35 step:33479 [D loss: 0.258395, acc.: 48.44%] [G loss: 0.259344]\n",
      "epoch:35 step:33480 [D loss: 0.231287, acc.: 60.16%] [G loss: 0.293559]\n",
      "epoch:35 step:33481 [D loss: 0.238254, acc.: 56.25%] [G loss: 0.297261]\n",
      "epoch:35 step:33482 [D loss: 0.232873, acc.: 60.16%] [G loss: 0.309484]\n",
      "epoch:35 step:33483 [D loss: 0.245751, acc.: 52.34%] [G loss: 0.305600]\n",
      "epoch:35 step:33484 [D loss: 0.261155, acc.: 46.88%] [G loss: 0.295470]\n",
      "epoch:35 step:33485 [D loss: 0.231653, acc.: 61.72%] [G loss: 0.272671]\n",
      "epoch:35 step:33486 [D loss: 0.225503, acc.: 68.75%] [G loss: 0.294118]\n",
      "epoch:35 step:33487 [D loss: 0.217654, acc.: 63.28%] [G loss: 0.295587]\n",
      "epoch:35 step:33488 [D loss: 0.246825, acc.: 53.12%] [G loss: 0.297721]\n",
      "epoch:35 step:33489 [D loss: 0.246015, acc.: 54.69%] [G loss: 0.304853]\n",
      "epoch:35 step:33490 [D loss: 0.238975, acc.: 62.50%] [G loss: 0.306832]\n",
      "epoch:35 step:33491 [D loss: 0.249033, acc.: 53.12%] [G loss: 0.302314]\n",
      "epoch:35 step:33492 [D loss: 0.223559, acc.: 62.50%] [G loss: 0.299130]\n",
      "epoch:35 step:33493 [D loss: 0.233852, acc.: 58.59%] [G loss: 0.283458]\n",
      "epoch:35 step:33494 [D loss: 0.233322, acc.: 60.16%] [G loss: 0.314343]\n",
      "epoch:35 step:33495 [D loss: 0.235915, acc.: 52.34%] [G loss: 0.270879]\n",
      "epoch:35 step:33496 [D loss: 0.244584, acc.: 56.25%] [G loss: 0.275146]\n",
      "epoch:35 step:33497 [D loss: 0.231024, acc.: 62.50%] [G loss: 0.319748]\n",
      "epoch:35 step:33498 [D loss: 0.235737, acc.: 61.72%] [G loss: 0.289998]\n",
      "epoch:35 step:33499 [D loss: 0.256177, acc.: 51.56%] [G loss: 0.299620]\n",
      "epoch:35 step:33500 [D loss: 0.228662, acc.: 61.72%] [G loss: 0.278599]\n",
      "epoch:35 step:33501 [D loss: 0.253176, acc.: 56.25%] [G loss: 0.294176]\n",
      "epoch:35 step:33502 [D loss: 0.247497, acc.: 57.81%] [G loss: 0.314517]\n",
      "epoch:35 step:33503 [D loss: 0.238622, acc.: 60.16%] [G loss: 0.292434]\n",
      "epoch:35 step:33504 [D loss: 0.250732, acc.: 54.69%] [G loss: 0.292696]\n",
      "epoch:35 step:33505 [D loss: 0.233505, acc.: 57.81%] [G loss: 0.306653]\n",
      "epoch:35 step:33506 [D loss: 0.219643, acc.: 66.41%] [G loss: 0.304169]\n",
      "epoch:35 step:33507 [D loss: 0.229019, acc.: 61.72%] [G loss: 0.300460]\n",
      "epoch:35 step:33508 [D loss: 0.248986, acc.: 54.69%] [G loss: 0.300913]\n",
      "epoch:35 step:33509 [D loss: 0.251162, acc.: 53.12%] [G loss: 0.293532]\n",
      "epoch:35 step:33510 [D loss: 0.246114, acc.: 57.03%] [G loss: 0.311918]\n",
      "epoch:35 step:33511 [D loss: 0.237902, acc.: 59.38%] [G loss: 0.298142]\n",
      "epoch:35 step:33512 [D loss: 0.242858, acc.: 59.38%] [G loss: 0.278165]\n",
      "epoch:35 step:33513 [D loss: 0.227007, acc.: 64.06%] [G loss: 0.312472]\n",
      "epoch:35 step:33514 [D loss: 0.230012, acc.: 61.72%] [G loss: 0.302199]\n",
      "epoch:35 step:33515 [D loss: 0.238252, acc.: 57.03%] [G loss: 0.292029]\n",
      "epoch:35 step:33516 [D loss: 0.235090, acc.: 55.47%] [G loss: 0.315390]\n",
      "epoch:35 step:33517 [D loss: 0.258214, acc.: 53.12%] [G loss: 0.286876]\n",
      "epoch:35 step:33518 [D loss: 0.223805, acc.: 63.28%] [G loss: 0.310491]\n",
      "epoch:35 step:33519 [D loss: 0.220927, acc.: 67.19%] [G loss: 0.317889]\n",
      "epoch:35 step:33520 [D loss: 0.235821, acc.: 57.03%] [G loss: 0.329442]\n",
      "epoch:35 step:33521 [D loss: 0.237031, acc.: 61.72%] [G loss: 0.304562]\n",
      "epoch:35 step:33522 [D loss: 0.244862, acc.: 53.91%] [G loss: 0.310087]\n",
      "epoch:35 step:33523 [D loss: 0.248630, acc.: 54.69%] [G loss: 0.319249]\n",
      "epoch:35 step:33524 [D loss: 0.241651, acc.: 60.94%] [G loss: 0.294109]\n",
      "epoch:35 step:33525 [D loss: 0.237733, acc.: 61.72%] [G loss: 0.282229]\n",
      "epoch:35 step:33526 [D loss: 0.263429, acc.: 47.66%] [G loss: 0.308650]\n",
      "epoch:35 step:33527 [D loss: 0.243677, acc.: 53.91%] [G loss: 0.290889]\n",
      "epoch:35 step:33528 [D loss: 0.242414, acc.: 60.16%] [G loss: 0.295337]\n",
      "epoch:35 step:33529 [D loss: 0.247351, acc.: 57.81%] [G loss: 0.281843]\n",
      "epoch:35 step:33530 [D loss: 0.237659, acc.: 52.34%] [G loss: 0.290598]\n",
      "epoch:35 step:33531 [D loss: 0.231659, acc.: 64.06%] [G loss: 0.317186]\n",
      "epoch:35 step:33532 [D loss: 0.255642, acc.: 55.47%] [G loss: 0.268958]\n",
      "epoch:35 step:33533 [D loss: 0.238883, acc.: 58.59%] [G loss: 0.306541]\n",
      "epoch:35 step:33534 [D loss: 0.247230, acc.: 50.78%] [G loss: 0.285225]\n",
      "epoch:35 step:33535 [D loss: 0.238095, acc.: 58.59%] [G loss: 0.317423]\n",
      "epoch:35 step:33536 [D loss: 0.244823, acc.: 60.16%] [G loss: 0.316321]\n",
      "epoch:35 step:33537 [D loss: 0.248912, acc.: 57.03%] [G loss: 0.286280]\n",
      "epoch:35 step:33538 [D loss: 0.254295, acc.: 53.91%] [G loss: 0.314452]\n",
      "epoch:35 step:33539 [D loss: 0.233360, acc.: 57.81%] [G loss: 0.300881]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:35 step:33540 [D loss: 0.216770, acc.: 67.19%] [G loss: 0.310196]\n",
      "epoch:35 step:33541 [D loss: 0.207535, acc.: 70.31%] [G loss: 0.343947]\n",
      "epoch:35 step:33542 [D loss: 0.250594, acc.: 58.59%] [G loss: 0.298228]\n",
      "epoch:35 step:33543 [D loss: 0.250168, acc.: 54.69%] [G loss: 0.304716]\n",
      "epoch:35 step:33544 [D loss: 0.254847, acc.: 56.25%] [G loss: 0.323396]\n",
      "epoch:35 step:33545 [D loss: 0.252235, acc.: 51.56%] [G loss: 0.289324]\n",
      "epoch:35 step:33546 [D loss: 0.248395, acc.: 50.78%] [G loss: 0.319354]\n",
      "epoch:35 step:33547 [D loss: 0.240514, acc.: 57.81%] [G loss: 0.316397]\n",
      "epoch:35 step:33548 [D loss: 0.256393, acc.: 50.00%] [G loss: 0.287026]\n",
      "epoch:35 step:33549 [D loss: 0.241089, acc.: 59.38%] [G loss: 0.308348]\n",
      "epoch:35 step:33550 [D loss: 0.245645, acc.: 58.59%] [G loss: 0.294809]\n",
      "epoch:35 step:33551 [D loss: 0.231541, acc.: 63.28%] [G loss: 0.296251]\n",
      "epoch:35 step:33552 [D loss: 0.233353, acc.: 60.94%] [G loss: 0.313686]\n",
      "epoch:35 step:33553 [D loss: 0.255974, acc.: 52.34%] [G loss: 0.324322]\n",
      "epoch:35 step:33554 [D loss: 0.236357, acc.: 60.94%] [G loss: 0.302121]\n",
      "epoch:35 step:33555 [D loss: 0.240877, acc.: 57.03%] [G loss: 0.329254]\n",
      "epoch:35 step:33556 [D loss: 0.250553, acc.: 51.56%] [G loss: 0.302191]\n",
      "epoch:35 step:33557 [D loss: 0.228164, acc.: 63.28%] [G loss: 0.271240]\n",
      "epoch:35 step:33558 [D loss: 0.238569, acc.: 59.38%] [G loss: 0.306950]\n",
      "epoch:35 step:33559 [D loss: 0.235239, acc.: 63.28%] [G loss: 0.293472]\n",
      "epoch:35 step:33560 [D loss: 0.242640, acc.: 53.12%] [G loss: 0.304221]\n",
      "epoch:35 step:33561 [D loss: 0.226340, acc.: 63.28%] [G loss: 0.314250]\n",
      "epoch:35 step:33562 [D loss: 0.236120, acc.: 61.72%] [G loss: 0.282808]\n",
      "epoch:35 step:33563 [D loss: 0.240177, acc.: 59.38%] [G loss: 0.302392]\n",
      "epoch:35 step:33564 [D loss: 0.239911, acc.: 59.38%] [G loss: 0.301841]\n",
      "epoch:35 step:33565 [D loss: 0.246664, acc.: 58.59%] [G loss: 0.298303]\n",
      "epoch:35 step:33566 [D loss: 0.246495, acc.: 56.25%] [G loss: 0.292476]\n",
      "epoch:35 step:33567 [D loss: 0.235123, acc.: 59.38%] [G loss: 0.293206]\n",
      "epoch:35 step:33568 [D loss: 0.249854, acc.: 55.47%] [G loss: 0.293321]\n",
      "epoch:35 step:33569 [D loss: 0.228488, acc.: 62.50%] [G loss: 0.296139]\n",
      "epoch:35 step:33570 [D loss: 0.229009, acc.: 64.84%] [G loss: 0.300072]\n",
      "epoch:35 step:33571 [D loss: 0.230749, acc.: 62.50%] [G loss: 0.296125]\n",
      "epoch:35 step:33572 [D loss: 0.252367, acc.: 52.34%] [G loss: 0.290444]\n",
      "epoch:35 step:33573 [D loss: 0.228127, acc.: 68.75%] [G loss: 0.294564]\n",
      "epoch:35 step:33574 [D loss: 0.256580, acc.: 54.69%] [G loss: 0.294594]\n",
      "epoch:35 step:33575 [D loss: 0.253054, acc.: 51.56%] [G loss: 0.279706]\n",
      "epoch:35 step:33576 [D loss: 0.235945, acc.: 58.59%] [G loss: 0.267005]\n",
      "epoch:35 step:33577 [D loss: 0.242170, acc.: 57.03%] [G loss: 0.314627]\n",
      "epoch:35 step:33578 [D loss: 0.229149, acc.: 61.72%] [G loss: 0.313832]\n",
      "epoch:35 step:33579 [D loss: 0.234330, acc.: 57.81%] [G loss: 0.297780]\n",
      "epoch:35 step:33580 [D loss: 0.239793, acc.: 58.59%] [G loss: 0.262731]\n",
      "epoch:35 step:33581 [D loss: 0.254542, acc.: 50.00%] [G loss: 0.287082]\n",
      "epoch:35 step:33582 [D loss: 0.216164, acc.: 67.19%] [G loss: 0.322665]\n",
      "epoch:35 step:33583 [D loss: 0.248079, acc.: 55.47%] [G loss: 0.258796]\n",
      "epoch:35 step:33584 [D loss: 0.219963, acc.: 65.62%] [G loss: 0.296971]\n",
      "epoch:35 step:33585 [D loss: 0.250027, acc.: 53.12%] [G loss: 0.293204]\n",
      "epoch:35 step:33586 [D loss: 0.223271, acc.: 65.62%] [G loss: 0.321459]\n",
      "epoch:35 step:33587 [D loss: 0.226324, acc.: 62.50%] [G loss: 0.288100]\n",
      "epoch:35 step:33588 [D loss: 0.240951, acc.: 57.03%] [G loss: 0.310014]\n",
      "epoch:35 step:33589 [D loss: 0.242443, acc.: 60.16%] [G loss: 0.297074]\n",
      "epoch:35 step:33590 [D loss: 0.244669, acc.: 53.91%] [G loss: 0.298711]\n",
      "epoch:35 step:33591 [D loss: 0.248897, acc.: 56.25%] [G loss: 0.297113]\n",
      "epoch:35 step:33592 [D loss: 0.226345, acc.: 63.28%] [G loss: 0.315966]\n",
      "epoch:35 step:33593 [D loss: 0.209858, acc.: 71.09%] [G loss: 0.319089]\n",
      "epoch:35 step:33594 [D loss: 0.269467, acc.: 44.53%] [G loss: 0.303962]\n",
      "epoch:35 step:33595 [D loss: 0.230407, acc.: 57.81%] [G loss: 0.314663]\n",
      "epoch:35 step:33596 [D loss: 0.238424, acc.: 60.16%] [G loss: 0.298637]\n",
      "epoch:35 step:33597 [D loss: 0.238924, acc.: 64.06%] [G loss: 0.312006]\n",
      "epoch:35 step:33598 [D loss: 0.245444, acc.: 59.38%] [G loss: 0.278864]\n",
      "epoch:35 step:33599 [D loss: 0.252839, acc.: 57.81%] [G loss: 0.283390]\n",
      "epoch:35 step:33600 [D loss: 0.254425, acc.: 48.44%] [G loss: 0.312026]\n",
      "epoch:35 step:33601 [D loss: 0.232957, acc.: 60.16%] [G loss: 0.299920]\n",
      "epoch:35 step:33602 [D loss: 0.252381, acc.: 55.47%] [G loss: 0.262984]\n",
      "epoch:35 step:33603 [D loss: 0.260179, acc.: 44.53%] [G loss: 0.267976]\n",
      "epoch:35 step:33604 [D loss: 0.228659, acc.: 60.16%] [G loss: 0.309706]\n",
      "epoch:35 step:33605 [D loss: 0.243761, acc.: 57.81%] [G loss: 0.315085]\n",
      "epoch:35 step:33606 [D loss: 0.243001, acc.: 56.25%] [G loss: 0.281405]\n",
      "epoch:35 step:33607 [D loss: 0.244013, acc.: 59.38%] [G loss: 0.286537]\n",
      "epoch:35 step:33608 [D loss: 0.245639, acc.: 50.78%] [G loss: 0.288743]\n",
      "epoch:35 step:33609 [D loss: 0.239697, acc.: 62.50%] [G loss: 0.307211]\n",
      "epoch:35 step:33610 [D loss: 0.250759, acc.: 53.91%] [G loss: 0.256600]\n",
      "epoch:35 step:33611 [D loss: 0.238635, acc.: 57.03%] [G loss: 0.288084]\n",
      "epoch:35 step:33612 [D loss: 0.238521, acc.: 60.94%] [G loss: 0.297879]\n",
      "epoch:35 step:33613 [D loss: 0.247117, acc.: 58.59%] [G loss: 0.320620]\n",
      "epoch:35 step:33614 [D loss: 0.227878, acc.: 61.72%] [G loss: 0.315377]\n",
      "epoch:35 step:33615 [D loss: 0.233846, acc.: 59.38%] [G loss: 0.283337]\n",
      "epoch:35 step:33616 [D loss: 0.244532, acc.: 56.25%] [G loss: 0.270188]\n",
      "epoch:35 step:33617 [D loss: 0.212659, acc.: 68.75%] [G loss: 0.287682]\n",
      "epoch:35 step:33618 [D loss: 0.256969, acc.: 53.12%] [G loss: 0.297485]\n",
      "epoch:35 step:33619 [D loss: 0.239713, acc.: 52.34%] [G loss: 0.312427]\n",
      "epoch:35 step:33620 [D loss: 0.240255, acc.: 57.03%] [G loss: 0.278821]\n",
      "epoch:35 step:33621 [D loss: 0.239597, acc.: 60.94%] [G loss: 0.281268]\n",
      "epoch:35 step:33622 [D loss: 0.242006, acc.: 59.38%] [G loss: 0.289576]\n",
      "epoch:35 step:33623 [D loss: 0.258955, acc.: 50.78%] [G loss: 0.303647]\n",
      "epoch:35 step:33624 [D loss: 0.237319, acc.: 57.81%] [G loss: 0.317341]\n",
      "epoch:35 step:33625 [D loss: 0.240889, acc.: 59.38%] [G loss: 0.294823]\n",
      "epoch:35 step:33626 [D loss: 0.238122, acc.: 60.94%] [G loss: 0.297222]\n",
      "epoch:35 step:33627 [D loss: 0.251623, acc.: 53.91%] [G loss: 0.289832]\n",
      "epoch:35 step:33628 [D loss: 0.240420, acc.: 53.91%] [G loss: 0.318616]\n",
      "epoch:35 step:33629 [D loss: 0.270489, acc.: 49.22%] [G loss: 0.265684]\n",
      "epoch:35 step:33630 [D loss: 0.239195, acc.: 60.94%] [G loss: 0.285933]\n",
      "epoch:35 step:33631 [D loss: 0.239991, acc.: 57.81%] [G loss: 0.296939]\n",
      "epoch:35 step:33632 [D loss: 0.235705, acc.: 57.81%] [G loss: 0.283048]\n",
      "epoch:35 step:33633 [D loss: 0.218713, acc.: 69.53%] [G loss: 0.306600]\n",
      "epoch:35 step:33634 [D loss: 0.232307, acc.: 61.72%] [G loss: 0.310097]\n",
      "epoch:35 step:33635 [D loss: 0.231844, acc.: 59.38%] [G loss: 0.275074]\n",
      "epoch:35 step:33636 [D loss: 0.243055, acc.: 60.94%] [G loss: 0.283986]\n",
      "epoch:35 step:33637 [D loss: 0.241971, acc.: 54.69%] [G loss: 0.291066]\n",
      "epoch:35 step:33638 [D loss: 0.260840, acc.: 51.56%] [G loss: 0.294171]\n",
      "epoch:35 step:33639 [D loss: 0.242424, acc.: 55.47%] [G loss: 0.296933]\n",
      "epoch:35 step:33640 [D loss: 0.247837, acc.: 51.56%] [G loss: 0.294110]\n",
      "epoch:35 step:33641 [D loss: 0.250296, acc.: 53.91%] [G loss: 0.290358]\n",
      "epoch:35 step:33642 [D loss: 0.228847, acc.: 62.50%] [G loss: 0.321747]\n",
      "epoch:35 step:33643 [D loss: 0.248564, acc.: 45.31%] [G loss: 0.312094]\n",
      "epoch:35 step:33644 [D loss: 0.238455, acc.: 53.91%] [G loss: 0.279156]\n",
      "epoch:35 step:33645 [D loss: 0.221262, acc.: 67.97%] [G loss: 0.281659]\n",
      "epoch:35 step:33646 [D loss: 0.222085, acc.: 66.41%] [G loss: 0.286552]\n",
      "epoch:35 step:33647 [D loss: 0.232519, acc.: 59.38%] [G loss: 0.286502]\n",
      "epoch:35 step:33648 [D loss: 0.233183, acc.: 58.59%] [G loss: 0.310868]\n",
      "epoch:35 step:33649 [D loss: 0.228619, acc.: 60.94%] [G loss: 0.302336]\n",
      "epoch:35 step:33650 [D loss: 0.250063, acc.: 53.91%] [G loss: 0.287282]\n",
      "epoch:35 step:33651 [D loss: 0.226297, acc.: 60.16%] [G loss: 0.288076]\n",
      "epoch:35 step:33652 [D loss: 0.225129, acc.: 68.75%] [G loss: 0.308578]\n",
      "epoch:35 step:33653 [D loss: 0.241126, acc.: 61.72%] [G loss: 0.294851]\n",
      "epoch:35 step:33654 [D loss: 0.229654, acc.: 63.28%] [G loss: 0.295404]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:35 step:33655 [D loss: 0.217270, acc.: 67.97%] [G loss: 0.312862]\n",
      "epoch:35 step:33656 [D loss: 0.243107, acc.: 58.59%] [G loss: 0.314872]\n",
      "epoch:35 step:33657 [D loss: 0.248955, acc.: 57.03%] [G loss: 0.294815]\n",
      "epoch:35 step:33658 [D loss: 0.257287, acc.: 48.44%] [G loss: 0.272563]\n",
      "epoch:35 step:33659 [D loss: 0.261920, acc.: 48.44%] [G loss: 0.303561]\n",
      "epoch:35 step:33660 [D loss: 0.240292, acc.: 57.03%] [G loss: 0.310520]\n",
      "epoch:35 step:33661 [D loss: 0.248905, acc.: 55.47%] [G loss: 0.295542]\n",
      "epoch:35 step:33662 [D loss: 0.259434, acc.: 49.22%] [G loss: 0.305338]\n",
      "epoch:35 step:33663 [D loss: 0.232392, acc.: 58.59%] [G loss: 0.281492]\n",
      "epoch:35 step:33664 [D loss: 0.230992, acc.: 60.94%] [G loss: 0.326284]\n",
      "epoch:35 step:33665 [D loss: 0.235728, acc.: 57.81%] [G loss: 0.348123]\n",
      "epoch:35 step:33666 [D loss: 0.248359, acc.: 53.91%] [G loss: 0.295722]\n",
      "epoch:35 step:33667 [D loss: 0.254314, acc.: 52.34%] [G loss: 0.314173]\n",
      "epoch:35 step:33668 [D loss: 0.243417, acc.: 55.47%] [G loss: 0.306617]\n",
      "epoch:35 step:33669 [D loss: 0.216508, acc.: 66.41%] [G loss: 0.303214]\n",
      "epoch:35 step:33670 [D loss: 0.239086, acc.: 58.59%] [G loss: 0.309207]\n",
      "epoch:35 step:33671 [D loss: 0.238475, acc.: 60.94%] [G loss: 0.262519]\n",
      "epoch:35 step:33672 [D loss: 0.233041, acc.: 58.59%] [G loss: 0.311904]\n",
      "epoch:35 step:33673 [D loss: 0.248050, acc.: 54.69%] [G loss: 0.326917]\n",
      "epoch:35 step:33674 [D loss: 0.225780, acc.: 63.28%] [G loss: 0.300166]\n",
      "epoch:35 step:33675 [D loss: 0.225970, acc.: 60.94%] [G loss: 0.301945]\n",
      "epoch:35 step:33676 [D loss: 0.231238, acc.: 62.50%] [G loss: 0.312106]\n",
      "epoch:35 step:33677 [D loss: 0.225601, acc.: 60.94%] [G loss: 0.318364]\n",
      "epoch:35 step:33678 [D loss: 0.241189, acc.: 60.16%] [G loss: 0.335460]\n",
      "epoch:35 step:33679 [D loss: 0.231564, acc.: 57.81%] [G loss: 0.307729]\n",
      "epoch:35 step:33680 [D loss: 0.252223, acc.: 55.47%] [G loss: 0.307781]\n",
      "epoch:35 step:33681 [D loss: 0.227514, acc.: 65.62%] [G loss: 0.324273]\n",
      "epoch:35 step:33682 [D loss: 0.247978, acc.: 53.12%] [G loss: 0.286142]\n",
      "epoch:35 step:33683 [D loss: 0.230555, acc.: 65.62%] [G loss: 0.323385]\n",
      "epoch:35 step:33684 [D loss: 0.242847, acc.: 53.12%] [G loss: 0.306821]\n",
      "epoch:35 step:33685 [D loss: 0.236556, acc.: 60.16%] [G loss: 0.297927]\n",
      "epoch:35 step:33686 [D loss: 0.234092, acc.: 57.03%] [G loss: 0.320264]\n",
      "epoch:35 step:33687 [D loss: 0.233662, acc.: 54.69%] [G loss: 0.282180]\n",
      "epoch:35 step:33688 [D loss: 0.233650, acc.: 62.50%] [G loss: 0.332134]\n",
      "epoch:35 step:33689 [D loss: 0.255284, acc.: 51.56%] [G loss: 0.316758]\n",
      "epoch:35 step:33690 [D loss: 0.249548, acc.: 50.78%] [G loss: 0.296107]\n",
      "epoch:35 step:33691 [D loss: 0.232849, acc.: 62.50%] [G loss: 0.282271]\n",
      "epoch:35 step:33692 [D loss: 0.215904, acc.: 65.62%] [G loss: 0.318285]\n",
      "epoch:35 step:33693 [D loss: 0.250578, acc.: 53.91%] [G loss: 0.288849]\n",
      "epoch:35 step:33694 [D loss: 0.240811, acc.: 55.47%] [G loss: 0.286839]\n",
      "epoch:35 step:33695 [D loss: 0.233968, acc.: 60.94%] [G loss: 0.310429]\n",
      "epoch:35 step:33696 [D loss: 0.241070, acc.: 61.72%] [G loss: 0.298799]\n",
      "epoch:35 step:33697 [D loss: 0.228418, acc.: 61.72%] [G loss: 0.294135]\n",
      "epoch:35 step:33698 [D loss: 0.236717, acc.: 57.03%] [G loss: 0.314051]\n",
      "epoch:35 step:33699 [D loss: 0.230006, acc.: 58.59%] [G loss: 0.272982]\n",
      "epoch:35 step:33700 [D loss: 0.235276, acc.: 60.94%] [G loss: 0.294774]\n",
      "epoch:35 step:33701 [D loss: 0.236692, acc.: 54.69%] [G loss: 0.298013]\n",
      "epoch:35 step:33702 [D loss: 0.249827, acc.: 57.03%] [G loss: 0.288456]\n",
      "epoch:35 step:33703 [D loss: 0.235118, acc.: 60.16%] [G loss: 0.317007]\n",
      "epoch:35 step:33704 [D loss: 0.239984, acc.: 61.72%] [G loss: 0.301660]\n",
      "epoch:35 step:33705 [D loss: 0.234844, acc.: 56.25%] [G loss: 0.293251]\n",
      "epoch:35 step:33706 [D loss: 0.247065, acc.: 56.25%] [G loss: 0.296970]\n",
      "epoch:35 step:33707 [D loss: 0.252371, acc.: 54.69%] [G loss: 0.331859]\n",
      "epoch:35 step:33708 [D loss: 0.254624, acc.: 54.69%] [G loss: 0.276251]\n",
      "epoch:35 step:33709 [D loss: 0.230729, acc.: 62.50%] [G loss: 0.268688]\n",
      "epoch:35 step:33710 [D loss: 0.239458, acc.: 59.38%] [G loss: 0.308607]\n",
      "epoch:35 step:33711 [D loss: 0.235531, acc.: 60.94%] [G loss: 0.296154]\n",
      "epoch:35 step:33712 [D loss: 0.236885, acc.: 57.81%] [G loss: 0.317928]\n",
      "epoch:35 step:33713 [D loss: 0.216280, acc.: 65.62%] [G loss: 0.289446]\n",
      "epoch:35 step:33714 [D loss: 0.222246, acc.: 59.38%] [G loss: 0.306236]\n",
      "epoch:35 step:33715 [D loss: 0.243893, acc.: 56.25%] [G loss: 0.316615]\n",
      "epoch:35 step:33716 [D loss: 0.248202, acc.: 54.69%] [G loss: 0.285269]\n",
      "epoch:35 step:33717 [D loss: 0.250424, acc.: 56.25%] [G loss: 0.297632]\n",
      "epoch:35 step:33718 [D loss: 0.220560, acc.: 67.19%] [G loss: 0.333190]\n",
      "epoch:35 step:33719 [D loss: 0.239157, acc.: 57.03%] [G loss: 0.299315]\n",
      "epoch:35 step:33720 [D loss: 0.232015, acc.: 65.62%] [G loss: 0.302495]\n",
      "epoch:35 step:33721 [D loss: 0.236046, acc.: 58.59%] [G loss: 0.271989]\n",
      "epoch:35 step:33722 [D loss: 0.232887, acc.: 57.81%] [G loss: 0.311244]\n",
      "epoch:35 step:33723 [D loss: 0.236146, acc.: 59.38%] [G loss: 0.273426]\n",
      "epoch:35 step:33724 [D loss: 0.242008, acc.: 57.81%] [G loss: 0.327364]\n",
      "epoch:35 step:33725 [D loss: 0.239439, acc.: 55.47%] [G loss: 0.277223]\n",
      "epoch:35 step:33726 [D loss: 0.247558, acc.: 52.34%] [G loss: 0.302686]\n",
      "epoch:35 step:33727 [D loss: 0.225722, acc.: 63.28%] [G loss: 0.327415]\n",
      "epoch:35 step:33728 [D loss: 0.234304, acc.: 64.06%] [G loss: 0.275141]\n",
      "epoch:35 step:33729 [D loss: 0.234454, acc.: 59.38%] [G loss: 0.303679]\n",
      "epoch:35 step:33730 [D loss: 0.252783, acc.: 51.56%] [G loss: 0.287410]\n",
      "epoch:35 step:33731 [D loss: 0.217823, acc.: 71.09%] [G loss: 0.316822]\n",
      "epoch:35 step:33732 [D loss: 0.255622, acc.: 48.44%] [G loss: 0.264950]\n",
      "epoch:36 step:33733 [D loss: 0.234943, acc.: 55.47%] [G loss: 0.270574]\n",
      "epoch:36 step:33734 [D loss: 0.220177, acc.: 67.97%] [G loss: 0.286612]\n",
      "epoch:36 step:33735 [D loss: 0.237385, acc.: 58.59%] [G loss: 0.330822]\n",
      "epoch:36 step:33736 [D loss: 0.238620, acc.: 56.25%] [G loss: 0.300679]\n",
      "epoch:36 step:33737 [D loss: 0.247792, acc.: 55.47%] [G loss: 0.309746]\n",
      "epoch:36 step:33738 [D loss: 0.252441, acc.: 51.56%] [G loss: 0.300725]\n",
      "epoch:36 step:33739 [D loss: 0.238409, acc.: 55.47%] [G loss: 0.280304]\n",
      "epoch:36 step:33740 [D loss: 0.245661, acc.: 56.25%] [G loss: 0.308306]\n",
      "epoch:36 step:33741 [D loss: 0.224806, acc.: 64.84%] [G loss: 0.303010]\n",
      "epoch:36 step:33742 [D loss: 0.230794, acc.: 61.72%] [G loss: 0.334632]\n",
      "epoch:36 step:33743 [D loss: 0.225438, acc.: 62.50%] [G loss: 0.292331]\n",
      "epoch:36 step:33744 [D loss: 0.227195, acc.: 60.16%] [G loss: 0.329507]\n",
      "epoch:36 step:33745 [D loss: 0.247295, acc.: 51.56%] [G loss: 0.294244]\n",
      "epoch:36 step:33746 [D loss: 0.249074, acc.: 56.25%] [G loss: 0.279722]\n",
      "epoch:36 step:33747 [D loss: 0.228284, acc.: 62.50%] [G loss: 0.300973]\n",
      "epoch:36 step:33748 [D loss: 0.235518, acc.: 60.16%] [G loss: 0.317910]\n",
      "epoch:36 step:33749 [D loss: 0.248595, acc.: 56.25%] [G loss: 0.296167]\n",
      "epoch:36 step:33750 [D loss: 0.226113, acc.: 65.62%] [G loss: 0.321806]\n",
      "epoch:36 step:33751 [D loss: 0.230768, acc.: 60.16%] [G loss: 0.288633]\n",
      "epoch:36 step:33752 [D loss: 0.231365, acc.: 62.50%] [G loss: 0.293668]\n",
      "epoch:36 step:33753 [D loss: 0.244928, acc.: 53.12%] [G loss: 0.297447]\n",
      "epoch:36 step:33754 [D loss: 0.243252, acc.: 58.59%] [G loss: 0.318451]\n",
      "epoch:36 step:33755 [D loss: 0.250959, acc.: 53.12%] [G loss: 0.292369]\n",
      "epoch:36 step:33756 [D loss: 0.235331, acc.: 61.72%] [G loss: 0.286826]\n",
      "epoch:36 step:33757 [D loss: 0.242015, acc.: 59.38%] [G loss: 0.280854]\n",
      "epoch:36 step:33758 [D loss: 0.247600, acc.: 57.03%] [G loss: 0.318649]\n",
      "epoch:36 step:33759 [D loss: 0.251592, acc.: 54.69%] [G loss: 0.279123]\n",
      "epoch:36 step:33760 [D loss: 0.243035, acc.: 50.78%] [G loss: 0.287960]\n",
      "epoch:36 step:33761 [D loss: 0.242592, acc.: 58.59%] [G loss: 0.269319]\n",
      "epoch:36 step:33762 [D loss: 0.238234, acc.: 60.94%] [G loss: 0.303084]\n",
      "epoch:36 step:33763 [D loss: 0.251020, acc.: 50.00%] [G loss: 0.257085]\n",
      "epoch:36 step:33764 [D loss: 0.250792, acc.: 51.56%] [G loss: 0.263991]\n",
      "epoch:36 step:33765 [D loss: 0.257225, acc.: 51.56%] [G loss: 0.300243]\n",
      "epoch:36 step:33766 [D loss: 0.234166, acc.: 58.59%] [G loss: 0.284944]\n",
      "epoch:36 step:33767 [D loss: 0.221905, acc.: 64.84%] [G loss: 0.305342]\n",
      "epoch:36 step:33768 [D loss: 0.244344, acc.: 56.25%] [G loss: 0.296623]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:36 step:33769 [D loss: 0.223007, acc.: 63.28%] [G loss: 0.311430]\n",
      "epoch:36 step:33770 [D loss: 0.248917, acc.: 53.12%] [G loss: 0.280794]\n",
      "epoch:36 step:33771 [D loss: 0.242724, acc.: 59.38%] [G loss: 0.303305]\n",
      "epoch:36 step:33772 [D loss: 0.240166, acc.: 58.59%] [G loss: 0.293524]\n",
      "epoch:36 step:33773 [D loss: 0.228820, acc.: 59.38%] [G loss: 0.281474]\n",
      "epoch:36 step:33774 [D loss: 0.232574, acc.: 63.28%] [G loss: 0.283501]\n",
      "epoch:36 step:33775 [D loss: 0.241736, acc.: 53.12%] [G loss: 0.298979]\n",
      "epoch:36 step:33776 [D loss: 0.239330, acc.: 62.50%] [G loss: 0.294825]\n",
      "epoch:36 step:33777 [D loss: 0.230524, acc.: 64.06%] [G loss: 0.300431]\n",
      "epoch:36 step:33778 [D loss: 0.240766, acc.: 57.81%] [G loss: 0.317283]\n",
      "epoch:36 step:33779 [D loss: 0.244937, acc.: 55.47%] [G loss: 0.307149]\n",
      "epoch:36 step:33780 [D loss: 0.248444, acc.: 59.38%] [G loss: 0.325399]\n",
      "epoch:36 step:33781 [D loss: 0.235515, acc.: 58.59%] [G loss: 0.313364]\n",
      "epoch:36 step:33782 [D loss: 0.240552, acc.: 58.59%] [G loss: 0.287299]\n",
      "epoch:36 step:33783 [D loss: 0.233596, acc.: 58.59%] [G loss: 0.299891]\n",
      "epoch:36 step:33784 [D loss: 0.224052, acc.: 60.94%] [G loss: 0.312988]\n",
      "epoch:36 step:33785 [D loss: 0.226306, acc.: 67.97%] [G loss: 0.296382]\n",
      "epoch:36 step:33786 [D loss: 0.221377, acc.: 60.94%] [G loss: 0.320247]\n",
      "epoch:36 step:33787 [D loss: 0.230883, acc.: 60.16%] [G loss: 0.311204]\n",
      "epoch:36 step:33788 [D loss: 0.258645, acc.: 54.69%] [G loss: 0.287440]\n",
      "epoch:36 step:33789 [D loss: 0.233265, acc.: 60.94%] [G loss: 0.313365]\n",
      "epoch:36 step:33790 [D loss: 0.243544, acc.: 54.69%] [G loss: 0.308021]\n",
      "epoch:36 step:33791 [D loss: 0.232728, acc.: 58.59%] [G loss: 0.304269]\n",
      "epoch:36 step:33792 [D loss: 0.214937, acc.: 68.75%] [G loss: 0.303946]\n",
      "epoch:36 step:33793 [D loss: 0.237874, acc.: 60.16%] [G loss: 0.267094]\n",
      "epoch:36 step:33794 [D loss: 0.237094, acc.: 60.16%] [G loss: 0.288062]\n",
      "epoch:36 step:33795 [D loss: 0.242614, acc.: 56.25%] [G loss: 0.283831]\n",
      "epoch:36 step:33796 [D loss: 0.236803, acc.: 59.38%] [G loss: 0.287983]\n",
      "epoch:36 step:33797 [D loss: 0.235029, acc.: 60.16%] [G loss: 0.290346]\n",
      "epoch:36 step:33798 [D loss: 0.243354, acc.: 57.81%] [G loss: 0.296438]\n",
      "epoch:36 step:33799 [D loss: 0.239312, acc.: 60.94%] [G loss: 0.266696]\n",
      "epoch:36 step:33800 [D loss: 0.254118, acc.: 57.03%] [G loss: 0.270287]\n",
      "epoch:36 step:33801 [D loss: 0.226368, acc.: 66.41%] [G loss: 0.312308]\n",
      "epoch:36 step:33802 [D loss: 0.244768, acc.: 58.59%] [G loss: 0.310775]\n",
      "epoch:36 step:33803 [D loss: 0.247780, acc.: 51.56%] [G loss: 0.305106]\n",
      "epoch:36 step:33804 [D loss: 0.244349, acc.: 53.12%] [G loss: 0.319638]\n",
      "epoch:36 step:33805 [D loss: 0.232292, acc.: 58.59%] [G loss: 0.311306]\n",
      "epoch:36 step:33806 [D loss: 0.214785, acc.: 70.31%] [G loss: 0.287073]\n",
      "epoch:36 step:33807 [D loss: 0.230327, acc.: 60.94%] [G loss: 0.297927]\n",
      "epoch:36 step:33808 [D loss: 0.238754, acc.: 59.38%] [G loss: 0.300241]\n",
      "epoch:36 step:33809 [D loss: 0.231620, acc.: 61.72%] [G loss: 0.336009]\n",
      "epoch:36 step:33810 [D loss: 0.242711, acc.: 56.25%] [G loss: 0.275186]\n",
      "epoch:36 step:33811 [D loss: 0.247190, acc.: 59.38%] [G loss: 0.312752]\n",
      "epoch:36 step:33812 [D loss: 0.224159, acc.: 64.84%] [G loss: 0.319172]\n",
      "epoch:36 step:33813 [D loss: 0.242274, acc.: 55.47%] [G loss: 0.292665]\n",
      "epoch:36 step:33814 [D loss: 0.237190, acc.: 60.16%] [G loss: 0.274078]\n",
      "epoch:36 step:33815 [D loss: 0.248701, acc.: 58.59%] [G loss: 0.294037]\n",
      "epoch:36 step:33816 [D loss: 0.250820, acc.: 51.56%] [G loss: 0.274770]\n",
      "epoch:36 step:33817 [D loss: 0.230802, acc.: 56.25%] [G loss: 0.307676]\n",
      "epoch:36 step:33818 [D loss: 0.259312, acc.: 48.44%] [G loss: 0.284348]\n",
      "epoch:36 step:33819 [D loss: 0.237899, acc.: 64.06%] [G loss: 0.251758]\n",
      "epoch:36 step:33820 [D loss: 0.254065, acc.: 57.81%] [G loss: 0.290266]\n",
      "epoch:36 step:33821 [D loss: 0.244769, acc.: 54.69%] [G loss: 0.288208]\n",
      "epoch:36 step:33822 [D loss: 0.236265, acc.: 60.94%] [G loss: 0.305196]\n",
      "epoch:36 step:33823 [D loss: 0.234282, acc.: 62.50%] [G loss: 0.299619]\n",
      "epoch:36 step:33824 [D loss: 0.233445, acc.: 53.91%] [G loss: 0.284457]\n",
      "epoch:36 step:33825 [D loss: 0.252033, acc.: 57.81%] [G loss: 0.288913]\n",
      "epoch:36 step:33826 [D loss: 0.238525, acc.: 57.03%] [G loss: 0.306418]\n",
      "epoch:36 step:33827 [D loss: 0.239365, acc.: 64.84%] [G loss: 0.312780]\n",
      "epoch:36 step:33828 [D loss: 0.240691, acc.: 54.69%] [G loss: 0.288824]\n",
      "epoch:36 step:33829 [D loss: 0.226459, acc.: 60.16%] [G loss: 0.290240]\n",
      "epoch:36 step:33830 [D loss: 0.235402, acc.: 58.59%] [G loss: 0.311646]\n",
      "epoch:36 step:33831 [D loss: 0.256141, acc.: 53.12%] [G loss: 0.298015]\n",
      "epoch:36 step:33832 [D loss: 0.238801, acc.: 55.47%] [G loss: 0.283442]\n",
      "epoch:36 step:33833 [D loss: 0.239547, acc.: 53.91%] [G loss: 0.321502]\n",
      "epoch:36 step:33834 [D loss: 0.238074, acc.: 53.91%] [G loss: 0.304287]\n",
      "epoch:36 step:33835 [D loss: 0.234585, acc.: 62.50%] [G loss: 0.322811]\n",
      "epoch:36 step:33836 [D loss: 0.242072, acc.: 57.81%] [G loss: 0.313706]\n",
      "epoch:36 step:33837 [D loss: 0.223377, acc.: 60.94%] [G loss: 0.300438]\n",
      "epoch:36 step:33838 [D loss: 0.225585, acc.: 64.84%] [G loss: 0.325773]\n",
      "epoch:36 step:33839 [D loss: 0.224187, acc.: 65.62%] [G loss: 0.295385]\n",
      "epoch:36 step:33840 [D loss: 0.251354, acc.: 53.91%] [G loss: 0.313818]\n",
      "epoch:36 step:33841 [D loss: 0.260933, acc.: 53.91%] [G loss: 0.310787]\n",
      "epoch:36 step:33842 [D loss: 0.259141, acc.: 53.12%] [G loss: 0.293952]\n",
      "epoch:36 step:33843 [D loss: 0.247526, acc.: 57.03%] [G loss: 0.319623]\n",
      "epoch:36 step:33844 [D loss: 0.254039, acc.: 54.69%] [G loss: 0.279448]\n",
      "epoch:36 step:33845 [D loss: 0.239325, acc.: 54.69%] [G loss: 0.296985]\n",
      "epoch:36 step:33846 [D loss: 0.245770, acc.: 54.69%] [G loss: 0.288275]\n",
      "epoch:36 step:33847 [D loss: 0.244635, acc.: 57.81%] [G loss: 0.316852]\n",
      "epoch:36 step:33848 [D loss: 0.243562, acc.: 56.25%] [G loss: 0.301977]\n",
      "epoch:36 step:33849 [D loss: 0.252164, acc.: 55.47%] [G loss: 0.271491]\n",
      "epoch:36 step:33850 [D loss: 0.246148, acc.: 59.38%] [G loss: 0.304089]\n",
      "epoch:36 step:33851 [D loss: 0.243598, acc.: 55.47%] [G loss: 0.289352]\n",
      "epoch:36 step:33852 [D loss: 0.236239, acc.: 58.59%] [G loss: 0.311212]\n",
      "epoch:36 step:33853 [D loss: 0.227321, acc.: 60.94%] [G loss: 0.275730]\n",
      "epoch:36 step:33854 [D loss: 0.241627, acc.: 54.69%] [G loss: 0.300669]\n",
      "epoch:36 step:33855 [D loss: 0.243986, acc.: 53.12%] [G loss: 0.282464]\n",
      "epoch:36 step:33856 [D loss: 0.233564, acc.: 64.84%] [G loss: 0.299803]\n",
      "epoch:36 step:33857 [D loss: 0.248284, acc.: 54.69%] [G loss: 0.326702]\n",
      "epoch:36 step:33858 [D loss: 0.240395, acc.: 56.25%] [G loss: 0.286008]\n",
      "epoch:36 step:33859 [D loss: 0.245113, acc.: 51.56%] [G loss: 0.293505]\n",
      "epoch:36 step:33860 [D loss: 0.233523, acc.: 55.47%] [G loss: 0.294769]\n",
      "epoch:36 step:33861 [D loss: 0.242986, acc.: 57.81%] [G loss: 0.294239]\n",
      "epoch:36 step:33862 [D loss: 0.235984, acc.: 60.16%] [G loss: 0.269656]\n",
      "epoch:36 step:33863 [D loss: 0.233492, acc.: 63.28%] [G loss: 0.312134]\n",
      "epoch:36 step:33864 [D loss: 0.244958, acc.: 54.69%] [G loss: 0.308405]\n",
      "epoch:36 step:33865 [D loss: 0.215781, acc.: 67.97%] [G loss: 0.309405]\n",
      "epoch:36 step:33866 [D loss: 0.216815, acc.: 67.97%] [G loss: 0.305415]\n",
      "epoch:36 step:33867 [D loss: 0.240337, acc.: 56.25%] [G loss: 0.292606]\n",
      "epoch:36 step:33868 [D loss: 0.255968, acc.: 50.78%] [G loss: 0.313101]\n",
      "epoch:36 step:33869 [D loss: 0.238552, acc.: 57.81%] [G loss: 0.319338]\n",
      "epoch:36 step:33870 [D loss: 0.245670, acc.: 60.16%] [G loss: 0.292466]\n",
      "epoch:36 step:33871 [D loss: 0.254060, acc.: 50.00%] [G loss: 0.279091]\n",
      "epoch:36 step:33872 [D loss: 0.248967, acc.: 53.91%] [G loss: 0.302378]\n",
      "epoch:36 step:33873 [D loss: 0.258578, acc.: 51.56%] [G loss: 0.275692]\n",
      "epoch:36 step:33874 [D loss: 0.225250, acc.: 64.06%] [G loss: 0.305456]\n",
      "epoch:36 step:33875 [D loss: 0.243681, acc.: 62.50%] [G loss: 0.295298]\n",
      "epoch:36 step:33876 [D loss: 0.245103, acc.: 55.47%] [G loss: 0.329347]\n",
      "epoch:36 step:33877 [D loss: 0.221596, acc.: 64.84%] [G loss: 0.305779]\n",
      "epoch:36 step:33878 [D loss: 0.233337, acc.: 65.62%] [G loss: 0.286396]\n",
      "epoch:36 step:33879 [D loss: 0.228132, acc.: 58.59%] [G loss: 0.312755]\n",
      "epoch:36 step:33880 [D loss: 0.238240, acc.: 61.72%] [G loss: 0.293147]\n",
      "epoch:36 step:33881 [D loss: 0.252885, acc.: 54.69%] [G loss: 0.304108]\n",
      "epoch:36 step:33882 [D loss: 0.244066, acc.: 62.50%] [G loss: 0.282116]\n",
      "epoch:36 step:33883 [D loss: 0.247221, acc.: 54.69%] [G loss: 0.272339]\n",
      "epoch:36 step:33884 [D loss: 0.249985, acc.: 57.03%] [G loss: 0.283363]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:36 step:33885 [D loss: 0.238844, acc.: 56.25%] [G loss: 0.288772]\n",
      "epoch:36 step:33886 [D loss: 0.248771, acc.: 54.69%] [G loss: 0.263021]\n",
      "epoch:36 step:33887 [D loss: 0.247946, acc.: 55.47%] [G loss: 0.275103]\n",
      "epoch:36 step:33888 [D loss: 0.241377, acc.: 58.59%] [G loss: 0.304290]\n",
      "epoch:36 step:33889 [D loss: 0.227011, acc.: 60.16%] [G loss: 0.323892]\n",
      "epoch:36 step:33890 [D loss: 0.230007, acc.: 61.72%] [G loss: 0.296343]\n",
      "epoch:36 step:33891 [D loss: 0.232611, acc.: 61.72%] [G loss: 0.308677]\n",
      "epoch:36 step:33892 [D loss: 0.257211, acc.: 48.44%] [G loss: 0.286263]\n",
      "epoch:36 step:33893 [D loss: 0.247389, acc.: 53.91%] [G loss: 0.290398]\n",
      "epoch:36 step:33894 [D loss: 0.258850, acc.: 52.34%] [G loss: 0.296646]\n",
      "epoch:36 step:33895 [D loss: 0.230341, acc.: 59.38%] [G loss: 0.290399]\n",
      "epoch:36 step:33896 [D loss: 0.240746, acc.: 57.03%] [G loss: 0.341561]\n",
      "epoch:36 step:33897 [D loss: 0.230880, acc.: 57.81%] [G loss: 0.267670]\n",
      "epoch:36 step:33898 [D loss: 0.231074, acc.: 59.38%] [G loss: 0.271043]\n",
      "epoch:36 step:33899 [D loss: 0.225444, acc.: 62.50%] [G loss: 0.309270]\n",
      "epoch:36 step:33900 [D loss: 0.239266, acc.: 56.25%] [G loss: 0.309966]\n",
      "epoch:36 step:33901 [D loss: 0.243393, acc.: 64.06%] [G loss: 0.318319]\n",
      "epoch:36 step:33902 [D loss: 0.245210, acc.: 53.91%] [G loss: 0.306381]\n",
      "epoch:36 step:33903 [D loss: 0.233761, acc.: 64.06%] [G loss: 0.306695]\n",
      "epoch:36 step:33904 [D loss: 0.221572, acc.: 65.62%] [G loss: 0.281346]\n",
      "epoch:36 step:33905 [D loss: 0.229228, acc.: 60.94%] [G loss: 0.308239]\n",
      "epoch:36 step:33906 [D loss: 0.235202, acc.: 59.38%] [G loss: 0.286280]\n",
      "epoch:36 step:33907 [D loss: 0.233459, acc.: 59.38%] [G loss: 0.307301]\n",
      "epoch:36 step:33908 [D loss: 0.231970, acc.: 63.28%] [G loss: 0.295253]\n",
      "epoch:36 step:33909 [D loss: 0.238838, acc.: 62.50%] [G loss: 0.287146]\n",
      "epoch:36 step:33910 [D loss: 0.231037, acc.: 66.41%] [G loss: 0.310201]\n",
      "epoch:36 step:33911 [D loss: 0.234672, acc.: 62.50%] [G loss: 0.285698]\n",
      "epoch:36 step:33912 [D loss: 0.229205, acc.: 63.28%] [G loss: 0.275716]\n",
      "epoch:36 step:33913 [D loss: 0.245240, acc.: 54.69%] [G loss: 0.292533]\n",
      "epoch:36 step:33914 [D loss: 0.248791, acc.: 53.12%] [G loss: 0.306167]\n",
      "epoch:36 step:33915 [D loss: 0.237206, acc.: 56.25%] [G loss: 0.319349]\n",
      "epoch:36 step:33916 [D loss: 0.237420, acc.: 58.59%] [G loss: 0.322478]\n",
      "epoch:36 step:33917 [D loss: 0.254465, acc.: 53.12%] [G loss: 0.289969]\n",
      "epoch:36 step:33918 [D loss: 0.226451, acc.: 62.50%] [G loss: 0.288072]\n",
      "epoch:36 step:33919 [D loss: 0.238450, acc.: 55.47%] [G loss: 0.293543]\n",
      "epoch:36 step:33920 [D loss: 0.265173, acc.: 49.22%] [G loss: 0.302780]\n",
      "epoch:36 step:33921 [D loss: 0.245416, acc.: 53.91%] [G loss: 0.279458]\n",
      "epoch:36 step:33922 [D loss: 0.264687, acc.: 46.09%] [G loss: 0.279147]\n",
      "epoch:36 step:33923 [D loss: 0.237724, acc.: 53.12%] [G loss: 0.298590]\n",
      "epoch:36 step:33924 [D loss: 0.236918, acc.: 56.25%] [G loss: 0.309714]\n",
      "epoch:36 step:33925 [D loss: 0.238587, acc.: 58.59%] [G loss: 0.256844]\n",
      "epoch:36 step:33926 [D loss: 0.237727, acc.: 59.38%] [G loss: 0.303654]\n",
      "epoch:36 step:33927 [D loss: 0.266357, acc.: 51.56%] [G loss: 0.289935]\n",
      "epoch:36 step:33928 [D loss: 0.237004, acc.: 63.28%] [G loss: 0.317187]\n",
      "epoch:36 step:33929 [D loss: 0.239714, acc.: 55.47%] [G loss: 0.309863]\n",
      "epoch:36 step:33930 [D loss: 0.249799, acc.: 57.03%] [G loss: 0.306590]\n",
      "epoch:36 step:33931 [D loss: 0.239436, acc.: 61.72%] [G loss: 0.268378]\n",
      "epoch:36 step:33932 [D loss: 0.242805, acc.: 57.81%] [G loss: 0.279731]\n",
      "epoch:36 step:33933 [D loss: 0.211048, acc.: 70.31%] [G loss: 0.288630]\n",
      "epoch:36 step:33934 [D loss: 0.228492, acc.: 64.06%] [G loss: 0.276935]\n",
      "epoch:36 step:33935 [D loss: 0.235443, acc.: 60.16%] [G loss: 0.290769]\n",
      "epoch:36 step:33936 [D loss: 0.251439, acc.: 49.22%] [G loss: 0.279142]\n",
      "epoch:36 step:33937 [D loss: 0.234197, acc.: 60.94%] [G loss: 0.276115]\n",
      "epoch:36 step:33938 [D loss: 0.241319, acc.: 57.03%] [G loss: 0.314129]\n",
      "epoch:36 step:33939 [D loss: 0.237086, acc.: 60.94%] [G loss: 0.288129]\n",
      "epoch:36 step:33940 [D loss: 0.235133, acc.: 60.94%] [G loss: 0.279939]\n",
      "epoch:36 step:33941 [D loss: 0.236667, acc.: 62.50%] [G loss: 0.290796]\n",
      "epoch:36 step:33942 [D loss: 0.242845, acc.: 55.47%] [G loss: 0.292214]\n",
      "epoch:36 step:33943 [D loss: 0.230373, acc.: 64.06%] [G loss: 0.284703]\n",
      "epoch:36 step:33944 [D loss: 0.252829, acc.: 58.59%] [G loss: 0.326364]\n",
      "epoch:36 step:33945 [D loss: 0.249096, acc.: 49.22%] [G loss: 0.305650]\n",
      "epoch:36 step:33946 [D loss: 0.236543, acc.: 53.91%] [G loss: 0.320188]\n",
      "epoch:36 step:33947 [D loss: 0.238684, acc.: 64.84%] [G loss: 0.328552]\n",
      "epoch:36 step:33948 [D loss: 0.251697, acc.: 50.00%] [G loss: 0.294413]\n",
      "epoch:36 step:33949 [D loss: 0.242753, acc.: 59.38%] [G loss: 0.291029]\n",
      "epoch:36 step:33950 [D loss: 0.234363, acc.: 57.81%] [G loss: 0.282029]\n",
      "epoch:36 step:33951 [D loss: 0.234349, acc.: 59.38%] [G loss: 0.301813]\n",
      "epoch:36 step:33952 [D loss: 0.252584, acc.: 53.91%] [G loss: 0.273507]\n",
      "epoch:36 step:33953 [D loss: 0.250397, acc.: 57.03%] [G loss: 0.271147]\n",
      "epoch:36 step:33954 [D loss: 0.258657, acc.: 51.56%] [G loss: 0.280290]\n",
      "epoch:36 step:33955 [D loss: 0.247101, acc.: 53.91%] [G loss: 0.277562]\n",
      "epoch:36 step:33956 [D loss: 0.243712, acc.: 57.03%] [G loss: 0.292662]\n",
      "epoch:36 step:33957 [D loss: 0.240951, acc.: 57.03%] [G loss: 0.311735]\n",
      "epoch:36 step:33958 [D loss: 0.228360, acc.: 60.94%] [G loss: 0.299186]\n",
      "epoch:36 step:33959 [D loss: 0.237949, acc.: 57.81%] [G loss: 0.258654]\n",
      "epoch:36 step:33960 [D loss: 0.237125, acc.: 57.81%] [G loss: 0.282822]\n",
      "epoch:36 step:33961 [D loss: 0.246089, acc.: 57.03%] [G loss: 0.294088]\n",
      "epoch:36 step:33962 [D loss: 0.244584, acc.: 56.25%] [G loss: 0.294195]\n",
      "epoch:36 step:33963 [D loss: 0.237928, acc.: 60.94%] [G loss: 0.296990]\n",
      "epoch:36 step:33964 [D loss: 0.248829, acc.: 51.56%] [G loss: 0.279469]\n",
      "epoch:36 step:33965 [D loss: 0.244743, acc.: 60.94%] [G loss: 0.293168]\n",
      "epoch:36 step:33966 [D loss: 0.237225, acc.: 63.28%] [G loss: 0.283085]\n",
      "epoch:36 step:33967 [D loss: 0.246714, acc.: 55.47%] [G loss: 0.286458]\n",
      "epoch:36 step:33968 [D loss: 0.244959, acc.: 59.38%] [G loss: 0.290599]\n",
      "epoch:36 step:33969 [D loss: 0.249266, acc.: 50.78%] [G loss: 0.294575]\n",
      "epoch:36 step:33970 [D loss: 0.231046, acc.: 63.28%] [G loss: 0.301658]\n",
      "epoch:36 step:33971 [D loss: 0.233179, acc.: 59.38%] [G loss: 0.249262]\n",
      "epoch:36 step:33972 [D loss: 0.242633, acc.: 60.16%] [G loss: 0.281039]\n",
      "epoch:36 step:33973 [D loss: 0.244432, acc.: 53.12%] [G loss: 0.327591]\n",
      "epoch:36 step:33974 [D loss: 0.255209, acc.: 51.56%] [G loss: 0.313137]\n",
      "epoch:36 step:33975 [D loss: 0.244062, acc.: 54.69%] [G loss: 0.284411]\n",
      "epoch:36 step:33976 [D loss: 0.233572, acc.: 64.06%] [G loss: 0.297360]\n",
      "epoch:36 step:33977 [D loss: 0.224446, acc.: 64.06%] [G loss: 0.290605]\n",
      "epoch:36 step:33978 [D loss: 0.228124, acc.: 63.28%] [G loss: 0.322595]\n",
      "epoch:36 step:33979 [D loss: 0.222608, acc.: 63.28%] [G loss: 0.301892]\n",
      "epoch:36 step:33980 [D loss: 0.251149, acc.: 53.12%] [G loss: 0.316309]\n",
      "epoch:36 step:33981 [D loss: 0.234205, acc.: 56.25%] [G loss: 0.329909]\n",
      "epoch:36 step:33982 [D loss: 0.249589, acc.: 57.03%] [G loss: 0.311330]\n",
      "epoch:36 step:33983 [D loss: 0.237820, acc.: 63.28%] [G loss: 0.319163]\n",
      "epoch:36 step:33984 [D loss: 0.246501, acc.: 57.03%] [G loss: 0.301723]\n",
      "epoch:36 step:33985 [D loss: 0.245715, acc.: 56.25%] [G loss: 0.280070]\n",
      "epoch:36 step:33986 [D loss: 0.257774, acc.: 48.44%] [G loss: 0.282137]\n",
      "epoch:36 step:33987 [D loss: 0.251521, acc.: 51.56%] [G loss: 0.280510]\n",
      "epoch:36 step:33988 [D loss: 0.250841, acc.: 53.12%] [G loss: 0.290490]\n",
      "epoch:36 step:33989 [D loss: 0.231377, acc.: 60.94%] [G loss: 0.280595]\n",
      "epoch:36 step:33990 [D loss: 0.241537, acc.: 61.72%] [G loss: 0.305345]\n",
      "epoch:36 step:33991 [D loss: 0.235548, acc.: 58.59%] [G loss: 0.300990]\n",
      "epoch:36 step:33992 [D loss: 0.234619, acc.: 59.38%] [G loss: 0.278354]\n",
      "epoch:36 step:33993 [D loss: 0.238108, acc.: 53.12%] [G loss: 0.289918]\n",
      "epoch:36 step:33994 [D loss: 0.254800, acc.: 53.12%] [G loss: 0.295621]\n",
      "epoch:36 step:33995 [D loss: 0.234793, acc.: 59.38%] [G loss: 0.314187]\n",
      "epoch:36 step:33996 [D loss: 0.248697, acc.: 54.69%] [G loss: 0.274969]\n",
      "epoch:36 step:33997 [D loss: 0.229346, acc.: 58.59%] [G loss: 0.310476]\n",
      "epoch:36 step:33998 [D loss: 0.247271, acc.: 57.81%] [G loss: 0.305326]\n",
      "epoch:36 step:33999 [D loss: 0.239464, acc.: 57.03%] [G loss: 0.283351]\n",
      "epoch:36 step:34000 [D loss: 0.226176, acc.: 62.50%] [G loss: 0.287442]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:36 step:34001 [D loss: 0.241153, acc.: 56.25%] [G loss: 0.324812]\n",
      "epoch:36 step:34002 [D loss: 0.249248, acc.: 54.69%] [G loss: 0.311307]\n",
      "epoch:36 step:34003 [D loss: 0.226640, acc.: 67.97%] [G loss: 0.293280]\n",
      "epoch:36 step:34004 [D loss: 0.234169, acc.: 60.94%] [G loss: 0.290525]\n",
      "epoch:36 step:34005 [D loss: 0.213780, acc.: 73.44%] [G loss: 0.314992]\n",
      "epoch:36 step:34006 [D loss: 0.236620, acc.: 58.59%] [G loss: 0.312372]\n",
      "epoch:36 step:34007 [D loss: 0.255840, acc.: 56.25%] [G loss: 0.307339]\n",
      "epoch:36 step:34008 [D loss: 0.245003, acc.: 57.81%] [G loss: 0.316386]\n",
      "epoch:36 step:34009 [D loss: 0.252476, acc.: 50.00%] [G loss: 0.259769]\n",
      "epoch:36 step:34010 [D loss: 0.214099, acc.: 70.31%] [G loss: 0.304713]\n",
      "epoch:36 step:34011 [D loss: 0.238748, acc.: 60.16%] [G loss: 0.338303]\n",
      "epoch:36 step:34012 [D loss: 0.257298, acc.: 50.78%] [G loss: 0.280405]\n",
      "epoch:36 step:34013 [D loss: 0.246391, acc.: 53.91%] [G loss: 0.299499]\n",
      "epoch:36 step:34014 [D loss: 0.237259, acc.: 62.50%] [G loss: 0.307549]\n",
      "epoch:36 step:34015 [D loss: 0.225095, acc.: 58.59%] [G loss: 0.294040]\n",
      "epoch:36 step:34016 [D loss: 0.242365, acc.: 55.47%] [G loss: 0.291642]\n",
      "epoch:36 step:34017 [D loss: 0.253658, acc.: 50.00%] [G loss: 0.292889]\n",
      "epoch:36 step:34018 [D loss: 0.238474, acc.: 58.59%] [G loss: 0.285233]\n",
      "epoch:36 step:34019 [D loss: 0.222787, acc.: 61.72%] [G loss: 0.317922]\n",
      "epoch:36 step:34020 [D loss: 0.240508, acc.: 58.59%] [G loss: 0.292034]\n",
      "epoch:36 step:34021 [D loss: 0.241399, acc.: 61.72%] [G loss: 0.295061]\n",
      "epoch:36 step:34022 [D loss: 0.255312, acc.: 52.34%] [G loss: 0.273426]\n",
      "epoch:36 step:34023 [D loss: 0.241050, acc.: 57.03%] [G loss: 0.318587]\n",
      "epoch:36 step:34024 [D loss: 0.240530, acc.: 58.59%] [G loss: 0.294673]\n",
      "epoch:36 step:34025 [D loss: 0.226385, acc.: 60.16%] [G loss: 0.312907]\n",
      "epoch:36 step:34026 [D loss: 0.226538, acc.: 62.50%] [G loss: 0.305553]\n",
      "epoch:36 step:34027 [D loss: 0.250319, acc.: 55.47%] [G loss: 0.297187]\n",
      "epoch:36 step:34028 [D loss: 0.246297, acc.: 58.59%] [G loss: 0.300239]\n",
      "epoch:36 step:34029 [D loss: 0.239513, acc.: 58.59%] [G loss: 0.274631]\n",
      "epoch:36 step:34030 [D loss: 0.253410, acc.: 54.69%] [G loss: 0.315735]\n",
      "epoch:36 step:34031 [D loss: 0.249402, acc.: 54.69%] [G loss: 0.306209]\n",
      "epoch:36 step:34032 [D loss: 0.217764, acc.: 66.41%] [G loss: 0.322588]\n",
      "epoch:36 step:34033 [D loss: 0.259268, acc.: 52.34%] [G loss: 0.251786]\n",
      "epoch:36 step:34034 [D loss: 0.235088, acc.: 60.16%] [G loss: 0.279993]\n",
      "epoch:36 step:34035 [D loss: 0.246069, acc.: 55.47%] [G loss: 0.287566]\n",
      "epoch:36 step:34036 [D loss: 0.238026, acc.: 59.38%] [G loss: 0.285965]\n",
      "epoch:36 step:34037 [D loss: 0.242892, acc.: 60.94%] [G loss: 0.301612]\n",
      "epoch:36 step:34038 [D loss: 0.247360, acc.: 55.47%] [G loss: 0.278292]\n",
      "epoch:36 step:34039 [D loss: 0.254890, acc.: 53.91%] [G loss: 0.300228]\n",
      "epoch:36 step:34040 [D loss: 0.238263, acc.: 55.47%] [G loss: 0.310434]\n",
      "epoch:36 step:34041 [D loss: 0.227351, acc.: 63.28%] [G loss: 0.288042]\n",
      "epoch:36 step:34042 [D loss: 0.229503, acc.: 65.62%] [G loss: 0.296712]\n",
      "epoch:36 step:34043 [D loss: 0.237635, acc.: 60.16%] [G loss: 0.283911]\n",
      "epoch:36 step:34044 [D loss: 0.239737, acc.: 55.47%] [G loss: 0.293540]\n",
      "epoch:36 step:34045 [D loss: 0.238596, acc.: 54.69%] [G loss: 0.328817]\n",
      "epoch:36 step:34046 [D loss: 0.231965, acc.: 58.59%] [G loss: 0.326086]\n",
      "epoch:36 step:34047 [D loss: 0.251363, acc.: 53.12%] [G loss: 0.292823]\n",
      "epoch:36 step:34048 [D loss: 0.249423, acc.: 53.12%] [G loss: 0.288968]\n",
      "epoch:36 step:34049 [D loss: 0.248477, acc.: 57.03%] [G loss: 0.314130]\n",
      "epoch:36 step:34050 [D loss: 0.230056, acc.: 60.94%] [G loss: 0.285158]\n",
      "epoch:36 step:34051 [D loss: 0.223019, acc.: 66.41%] [G loss: 0.274570]\n",
      "epoch:36 step:34052 [D loss: 0.253204, acc.: 50.78%] [G loss: 0.297058]\n",
      "epoch:36 step:34053 [D loss: 0.221464, acc.: 69.53%] [G loss: 0.295501]\n",
      "epoch:36 step:34054 [D loss: 0.252428, acc.: 46.88%] [G loss: 0.315569]\n",
      "epoch:36 step:34055 [D loss: 0.243001, acc.: 57.81%] [G loss: 0.281165]\n",
      "epoch:36 step:34056 [D loss: 0.239235, acc.: 55.47%] [G loss: 0.299115]\n",
      "epoch:36 step:34057 [D loss: 0.237921, acc.: 57.03%] [G loss: 0.297167]\n",
      "epoch:36 step:34058 [D loss: 0.238770, acc.: 59.38%] [G loss: 0.305159]\n",
      "epoch:36 step:34059 [D loss: 0.236885, acc.: 61.72%] [G loss: 0.283345]\n",
      "epoch:36 step:34060 [D loss: 0.228196, acc.: 64.06%] [G loss: 0.294108]\n",
      "epoch:36 step:34061 [D loss: 0.238630, acc.: 57.03%] [G loss: 0.284392]\n",
      "epoch:36 step:34062 [D loss: 0.234600, acc.: 62.50%] [G loss: 0.315479]\n",
      "epoch:36 step:34063 [D loss: 0.218821, acc.: 65.62%] [G loss: 0.321908]\n",
      "epoch:36 step:34064 [D loss: 0.235347, acc.: 58.59%] [G loss: 0.298456]\n",
      "epoch:36 step:34065 [D loss: 0.237102, acc.: 56.25%] [G loss: 0.294950]\n",
      "epoch:36 step:34066 [D loss: 0.244923, acc.: 57.03%] [G loss: 0.307321]\n",
      "epoch:36 step:34067 [D loss: 0.219366, acc.: 65.62%] [G loss: 0.312954]\n",
      "epoch:36 step:34068 [D loss: 0.236093, acc.: 55.47%] [G loss: 0.306737]\n",
      "epoch:36 step:34069 [D loss: 0.246318, acc.: 57.81%] [G loss: 0.292317]\n",
      "epoch:36 step:34070 [D loss: 0.230684, acc.: 60.94%] [G loss: 0.308544]\n",
      "epoch:36 step:34071 [D loss: 0.237024, acc.: 57.81%] [G loss: 0.305948]\n",
      "epoch:36 step:34072 [D loss: 0.225797, acc.: 59.38%] [G loss: 0.302028]\n",
      "epoch:36 step:34073 [D loss: 0.240861, acc.: 60.16%] [G loss: 0.296055]\n",
      "epoch:36 step:34074 [D loss: 0.240301, acc.: 55.47%] [G loss: 0.280729]\n",
      "epoch:36 step:34075 [D loss: 0.240831, acc.: 56.25%] [G loss: 0.321692]\n",
      "epoch:36 step:34076 [D loss: 0.235673, acc.: 60.16%] [G loss: 0.334657]\n",
      "epoch:36 step:34077 [D loss: 0.245044, acc.: 57.81%] [G loss: 0.310174]\n",
      "epoch:36 step:34078 [D loss: 0.246453, acc.: 59.38%] [G loss: 0.302532]\n",
      "epoch:36 step:34079 [D loss: 0.228796, acc.: 62.50%] [G loss: 0.323438]\n",
      "epoch:36 step:34080 [D loss: 0.243810, acc.: 57.03%] [G loss: 0.253481]\n",
      "epoch:36 step:34081 [D loss: 0.240036, acc.: 56.25%] [G loss: 0.327939]\n",
      "epoch:36 step:34082 [D loss: 0.265642, acc.: 50.00%] [G loss: 0.313132]\n",
      "epoch:36 step:34083 [D loss: 0.222149, acc.: 63.28%] [G loss: 0.302441]\n",
      "epoch:36 step:34084 [D loss: 0.246878, acc.: 57.81%] [G loss: 0.279949]\n",
      "epoch:36 step:34085 [D loss: 0.234072, acc.: 60.94%] [G loss: 0.301942]\n",
      "epoch:36 step:34086 [D loss: 0.241179, acc.: 56.25%] [G loss: 0.297507]\n",
      "epoch:36 step:34087 [D loss: 0.248776, acc.: 57.03%] [G loss: 0.277623]\n",
      "epoch:36 step:34088 [D loss: 0.239375, acc.: 52.34%] [G loss: 0.292696]\n",
      "epoch:36 step:34089 [D loss: 0.250816, acc.: 54.69%] [G loss: 0.311823]\n",
      "epoch:36 step:34090 [D loss: 0.233144, acc.: 62.50%] [G loss: 0.311645]\n",
      "epoch:36 step:34091 [D loss: 0.252466, acc.: 51.56%] [G loss: 0.270279]\n",
      "epoch:36 step:34092 [D loss: 0.231406, acc.: 60.94%] [G loss: 0.305223]\n",
      "epoch:36 step:34093 [D loss: 0.230937, acc.: 63.28%] [G loss: 0.301444]\n",
      "epoch:36 step:34094 [D loss: 0.234286, acc.: 58.59%] [G loss: 0.291420]\n",
      "epoch:36 step:34095 [D loss: 0.235155, acc.: 62.50%] [G loss: 0.284600]\n",
      "epoch:36 step:34096 [D loss: 0.235154, acc.: 57.81%] [G loss: 0.272002]\n",
      "epoch:36 step:34097 [D loss: 0.228741, acc.: 60.16%] [G loss: 0.325208]\n",
      "epoch:36 step:34098 [D loss: 0.228719, acc.: 60.16%] [G loss: 0.332170]\n",
      "epoch:36 step:34099 [D loss: 0.242401, acc.: 57.81%] [G loss: 0.303230]\n",
      "epoch:36 step:34100 [D loss: 0.237834, acc.: 59.38%] [G loss: 0.334274]\n",
      "epoch:36 step:34101 [D loss: 0.253669, acc.: 53.12%] [G loss: 0.291379]\n",
      "epoch:36 step:34102 [D loss: 0.231791, acc.: 59.38%] [G loss: 0.316796]\n",
      "epoch:36 step:34103 [D loss: 0.247370, acc.: 53.12%] [G loss: 0.300841]\n",
      "epoch:36 step:34104 [D loss: 0.239472, acc.: 59.38%] [G loss: 0.301544]\n",
      "epoch:36 step:34105 [D loss: 0.226914, acc.: 61.72%] [G loss: 0.318366]\n",
      "epoch:36 step:34106 [D loss: 0.252988, acc.: 57.03%] [G loss: 0.299828]\n",
      "epoch:36 step:34107 [D loss: 0.239069, acc.: 59.38%] [G loss: 0.281075]\n",
      "epoch:36 step:34108 [D loss: 0.238605, acc.: 63.28%] [G loss: 0.311008]\n",
      "epoch:36 step:34109 [D loss: 0.244459, acc.: 53.91%] [G loss: 0.293833]\n",
      "epoch:36 step:34110 [D loss: 0.231794, acc.: 61.72%] [G loss: 0.327327]\n",
      "epoch:36 step:34111 [D loss: 0.235694, acc.: 60.16%] [G loss: 0.311989]\n",
      "epoch:36 step:34112 [D loss: 0.249605, acc.: 54.69%] [G loss: 0.276351]\n",
      "epoch:36 step:34113 [D loss: 0.258247, acc.: 51.56%] [G loss: 0.299642]\n",
      "epoch:36 step:34114 [D loss: 0.232272, acc.: 61.72%] [G loss: 0.294332]\n",
      "epoch:36 step:34115 [D loss: 0.242952, acc.: 54.69%] [G loss: 0.324601]\n",
      "epoch:36 step:34116 [D loss: 0.233398, acc.: 61.72%] [G loss: 0.279975]\n",
      "epoch:36 step:34117 [D loss: 0.248235, acc.: 52.34%] [G loss: 0.278204]\n",
      "epoch:36 step:34118 [D loss: 0.242045, acc.: 62.50%] [G loss: 0.297680]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:36 step:34119 [D loss: 0.235577, acc.: 64.84%] [G loss: 0.295466]\n",
      "epoch:36 step:34120 [D loss: 0.254099, acc.: 50.78%] [G loss: 0.320643]\n",
      "epoch:36 step:34121 [D loss: 0.245911, acc.: 51.56%] [G loss: 0.297490]\n",
      "epoch:36 step:34122 [D loss: 0.240980, acc.: 57.81%] [G loss: 0.304859]\n",
      "epoch:36 step:34123 [D loss: 0.260500, acc.: 56.25%] [G loss: 0.278278]\n",
      "epoch:36 step:34124 [D loss: 0.242152, acc.: 53.91%] [G loss: 0.289863]\n",
      "epoch:36 step:34125 [D loss: 0.244828, acc.: 52.34%] [G loss: 0.319443]\n",
      "epoch:36 step:34126 [D loss: 0.231564, acc.: 60.94%] [G loss: 0.300616]\n",
      "epoch:36 step:34127 [D loss: 0.248338, acc.: 55.47%] [G loss: 0.312591]\n",
      "epoch:36 step:34128 [D loss: 0.233468, acc.: 59.38%] [G loss: 0.278444]\n",
      "epoch:36 step:34129 [D loss: 0.235707, acc.: 58.59%] [G loss: 0.285093]\n",
      "epoch:36 step:34130 [D loss: 0.234455, acc.: 57.03%] [G loss: 0.299234]\n",
      "epoch:36 step:34131 [D loss: 0.252452, acc.: 51.56%] [G loss: 0.306629]\n",
      "epoch:36 step:34132 [D loss: 0.240967, acc.: 58.59%] [G loss: 0.318896]\n",
      "epoch:36 step:34133 [D loss: 0.241929, acc.: 57.81%] [G loss: 0.292604]\n",
      "epoch:36 step:34134 [D loss: 0.237688, acc.: 60.16%] [G loss: 0.304935]\n",
      "epoch:36 step:34135 [D loss: 0.245753, acc.: 56.25%] [G loss: 0.300002]\n",
      "epoch:36 step:34136 [D loss: 0.258420, acc.: 51.56%] [G loss: 0.317256]\n",
      "epoch:36 step:34137 [D loss: 0.241939, acc.: 62.50%] [G loss: 0.288242]\n",
      "epoch:36 step:34138 [D loss: 0.245897, acc.: 50.00%] [G loss: 0.304263]\n",
      "epoch:36 step:34139 [D loss: 0.242393, acc.: 59.38%] [G loss: 0.281565]\n",
      "epoch:36 step:34140 [D loss: 0.231554, acc.: 67.19%] [G loss: 0.328769]\n",
      "epoch:36 step:34141 [D loss: 0.235753, acc.: 60.94%] [G loss: 0.300626]\n",
      "epoch:36 step:34142 [D loss: 0.250534, acc.: 56.25%] [G loss: 0.293620]\n",
      "epoch:36 step:34143 [D loss: 0.248711, acc.: 57.81%] [G loss: 0.320298]\n",
      "epoch:36 step:34144 [D loss: 0.260177, acc.: 51.56%] [G loss: 0.309520]\n",
      "epoch:36 step:34145 [D loss: 0.235159, acc.: 61.72%] [G loss: 0.340992]\n",
      "epoch:36 step:34146 [D loss: 0.250948, acc.: 56.25%] [G loss: 0.282532]\n",
      "epoch:36 step:34147 [D loss: 0.250628, acc.: 52.34%] [G loss: 0.294467]\n",
      "epoch:36 step:34148 [D loss: 0.237693, acc.: 62.50%] [G loss: 0.281214]\n",
      "epoch:36 step:34149 [D loss: 0.238542, acc.: 52.34%] [G loss: 0.296231]\n",
      "epoch:36 step:34150 [D loss: 0.251299, acc.: 51.56%] [G loss: 0.259303]\n",
      "epoch:36 step:34151 [D loss: 0.230102, acc.: 58.59%] [G loss: 0.301660]\n",
      "epoch:36 step:34152 [D loss: 0.254364, acc.: 47.66%] [G loss: 0.299883]\n",
      "epoch:36 step:34153 [D loss: 0.248545, acc.: 53.12%] [G loss: 0.292193]\n",
      "epoch:36 step:34154 [D loss: 0.230974, acc.: 60.94%] [G loss: 0.306327]\n",
      "epoch:36 step:34155 [D loss: 0.250799, acc.: 53.12%] [G loss: 0.308281]\n",
      "epoch:36 step:34156 [D loss: 0.237723, acc.: 56.25%] [G loss: 0.280588]\n",
      "epoch:36 step:34157 [D loss: 0.230642, acc.: 56.25%] [G loss: 0.301089]\n",
      "epoch:36 step:34158 [D loss: 0.246641, acc.: 55.47%] [G loss: 0.285092]\n",
      "epoch:36 step:34159 [D loss: 0.248171, acc.: 50.78%] [G loss: 0.306284]\n",
      "epoch:36 step:34160 [D loss: 0.246003, acc.: 57.03%] [G loss: 0.316275]\n",
      "epoch:36 step:34161 [D loss: 0.266488, acc.: 48.44%] [G loss: 0.268808]\n",
      "epoch:36 step:34162 [D loss: 0.241987, acc.: 56.25%] [G loss: 0.306034]\n",
      "epoch:36 step:34163 [D loss: 0.247428, acc.: 55.47%] [G loss: 0.256771]\n",
      "epoch:36 step:34164 [D loss: 0.221186, acc.: 66.41%] [G loss: 0.282342]\n",
      "epoch:36 step:34165 [D loss: 0.247152, acc.: 59.38%] [G loss: 0.316893]\n",
      "epoch:36 step:34166 [D loss: 0.255902, acc.: 50.00%] [G loss: 0.278936]\n",
      "epoch:36 step:34167 [D loss: 0.219285, acc.: 68.75%] [G loss: 0.280199]\n",
      "epoch:36 step:34168 [D loss: 0.237893, acc.: 62.50%] [G loss: 0.300905]\n",
      "epoch:36 step:34169 [D loss: 0.236383, acc.: 64.06%] [G loss: 0.273891]\n",
      "epoch:36 step:34170 [D loss: 0.230585, acc.: 60.94%] [G loss: 0.303904]\n",
      "epoch:36 step:34171 [D loss: 0.263820, acc.: 46.09%] [G loss: 0.265763]\n",
      "epoch:36 step:34172 [D loss: 0.246395, acc.: 55.47%] [G loss: 0.260640]\n",
      "epoch:36 step:34173 [D loss: 0.228519, acc.: 64.06%] [G loss: 0.285016]\n",
      "epoch:36 step:34174 [D loss: 0.251863, acc.: 49.22%] [G loss: 0.316088]\n",
      "epoch:36 step:34175 [D loss: 0.220643, acc.: 62.50%] [G loss: 0.321133]\n",
      "epoch:36 step:34176 [D loss: 0.233101, acc.: 59.38%] [G loss: 0.294878]\n",
      "epoch:36 step:34177 [D loss: 0.246370, acc.: 55.47%] [G loss: 0.286895]\n",
      "epoch:36 step:34178 [D loss: 0.237480, acc.: 60.16%] [G loss: 0.321544]\n",
      "epoch:36 step:34179 [D loss: 0.237729, acc.: 60.16%] [G loss: 0.327249]\n",
      "epoch:36 step:34180 [D loss: 0.239531, acc.: 59.38%] [G loss: 0.282575]\n",
      "epoch:36 step:34181 [D loss: 0.273514, acc.: 48.44%] [G loss: 0.299934]\n",
      "epoch:36 step:34182 [D loss: 0.259632, acc.: 50.78%] [G loss: 0.287156]\n",
      "epoch:36 step:34183 [D loss: 0.242046, acc.: 52.34%] [G loss: 0.282602]\n",
      "epoch:36 step:34184 [D loss: 0.248274, acc.: 53.91%] [G loss: 0.281752]\n",
      "epoch:36 step:34185 [D loss: 0.227167, acc.: 59.38%] [G loss: 0.297225]\n",
      "epoch:36 step:34186 [D loss: 0.235821, acc.: 60.94%] [G loss: 0.312523]\n",
      "epoch:36 step:34187 [D loss: 0.239202, acc.: 59.38%] [G loss: 0.321647]\n",
      "epoch:36 step:34188 [D loss: 0.249508, acc.: 53.12%] [G loss: 0.306305]\n",
      "epoch:36 step:34189 [D loss: 0.260388, acc.: 54.69%] [G loss: 0.273498]\n",
      "epoch:36 step:34190 [D loss: 0.265715, acc.: 42.19%] [G loss: 0.286216]\n",
      "epoch:36 step:34191 [D loss: 0.233733, acc.: 59.38%] [G loss: 0.295684]\n",
      "epoch:36 step:34192 [D loss: 0.235538, acc.: 57.81%] [G loss: 0.290843]\n",
      "epoch:36 step:34193 [D loss: 0.245835, acc.: 53.91%] [G loss: 0.289277]\n",
      "epoch:36 step:34194 [D loss: 0.251396, acc.: 53.12%] [G loss: 0.291091]\n",
      "epoch:36 step:34195 [D loss: 0.239314, acc.: 54.69%] [G loss: 0.269587]\n",
      "epoch:36 step:34196 [D loss: 0.243790, acc.: 60.16%] [G loss: 0.309747]\n",
      "epoch:36 step:34197 [D loss: 0.228605, acc.: 64.06%] [G loss: 0.280735]\n",
      "epoch:36 step:34198 [D loss: 0.243080, acc.: 53.12%] [G loss: 0.277872]\n",
      "epoch:36 step:34199 [D loss: 0.234827, acc.: 63.28%] [G loss: 0.268965]\n",
      "epoch:36 step:34200 [D loss: 0.240986, acc.: 59.38%] [G loss: 0.272244]\n",
      "epoch:36 step:34201 [D loss: 0.235028, acc.: 58.59%] [G loss: 0.309326]\n",
      "epoch:36 step:34202 [D loss: 0.237022, acc.: 59.38%] [G loss: 0.258096]\n",
      "epoch:36 step:34203 [D loss: 0.252533, acc.: 50.78%] [G loss: 0.295656]\n",
      "epoch:36 step:34204 [D loss: 0.250430, acc.: 54.69%] [G loss: 0.286668]\n",
      "epoch:36 step:34205 [D loss: 0.241778, acc.: 57.81%] [G loss: 0.330988]\n",
      "epoch:36 step:34206 [D loss: 0.230503, acc.: 59.38%] [G loss: 0.312731]\n",
      "epoch:36 step:34207 [D loss: 0.231538, acc.: 67.19%] [G loss: 0.315739]\n",
      "epoch:36 step:34208 [D loss: 0.246238, acc.: 54.69%] [G loss: 0.305611]\n",
      "epoch:36 step:34209 [D loss: 0.251573, acc.: 56.25%] [G loss: 0.283689]\n",
      "epoch:36 step:34210 [D loss: 0.228873, acc.: 62.50%] [G loss: 0.296045]\n",
      "epoch:36 step:34211 [D loss: 0.253846, acc.: 57.03%] [G loss: 0.305747]\n",
      "epoch:36 step:34212 [D loss: 0.230900, acc.: 63.28%] [G loss: 0.338399]\n",
      "epoch:36 step:34213 [D loss: 0.245718, acc.: 56.25%] [G loss: 0.298778]\n",
      "epoch:36 step:34214 [D loss: 0.223179, acc.: 61.72%] [G loss: 0.311048]\n",
      "epoch:36 step:34215 [D loss: 0.226144, acc.: 60.16%] [G loss: 0.314518]\n",
      "epoch:36 step:34216 [D loss: 0.238238, acc.: 57.03%] [G loss: 0.326879]\n",
      "epoch:36 step:34217 [D loss: 0.259101, acc.: 53.12%] [G loss: 0.282021]\n",
      "epoch:36 step:34218 [D loss: 0.249472, acc.: 56.25%] [G loss: 0.304408]\n",
      "epoch:36 step:34219 [D loss: 0.247686, acc.: 53.91%] [G loss: 0.313505]\n",
      "epoch:36 step:34220 [D loss: 0.210904, acc.: 67.97%] [G loss: 0.311662]\n",
      "epoch:36 step:34221 [D loss: 0.237336, acc.: 60.16%] [G loss: 0.306859]\n",
      "epoch:36 step:34222 [D loss: 0.238748, acc.: 56.25%] [G loss: 0.298216]\n",
      "epoch:36 step:34223 [D loss: 0.247729, acc.: 49.22%] [G loss: 0.302482]\n",
      "epoch:36 step:34224 [D loss: 0.265463, acc.: 50.00%] [G loss: 0.262386]\n",
      "epoch:36 step:34225 [D loss: 0.226657, acc.: 64.06%] [G loss: 0.302476]\n",
      "epoch:36 step:34226 [D loss: 0.255737, acc.: 54.69%] [G loss: 0.306328]\n",
      "epoch:36 step:34227 [D loss: 0.257854, acc.: 46.88%] [G loss: 0.288350]\n",
      "epoch:36 step:34228 [D loss: 0.236750, acc.: 57.03%] [G loss: 0.310243]\n",
      "epoch:36 step:34229 [D loss: 0.225737, acc.: 63.28%] [G loss: 0.294319]\n",
      "epoch:36 step:34230 [D loss: 0.239087, acc.: 61.72%] [G loss: 0.286394]\n",
      "epoch:36 step:34231 [D loss: 0.228870, acc.: 62.50%] [G loss: 0.300264]\n",
      "epoch:36 step:34232 [D loss: 0.234425, acc.: 60.94%] [G loss: 0.292903]\n",
      "epoch:36 step:34233 [D loss: 0.248217, acc.: 50.00%] [G loss: 0.284608]\n",
      "epoch:36 step:34234 [D loss: 0.246316, acc.: 56.25%] [G loss: 0.327749]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:36 step:34235 [D loss: 0.233477, acc.: 62.50%] [G loss: 0.293890]\n",
      "epoch:36 step:34236 [D loss: 0.237334, acc.: 59.38%] [G loss: 0.277461]\n",
      "epoch:36 step:34237 [D loss: 0.226774, acc.: 64.84%] [G loss: 0.296282]\n",
      "epoch:36 step:34238 [D loss: 0.240084, acc.: 58.59%] [G loss: 0.307131]\n",
      "epoch:36 step:34239 [D loss: 0.250371, acc.: 51.56%] [G loss: 0.305199]\n",
      "epoch:36 step:34240 [D loss: 0.245297, acc.: 60.16%] [G loss: 0.310543]\n",
      "epoch:36 step:34241 [D loss: 0.241507, acc.: 59.38%] [G loss: 0.317297]\n",
      "epoch:36 step:34242 [D loss: 0.247799, acc.: 50.00%] [G loss: 0.280207]\n",
      "epoch:36 step:34243 [D loss: 0.239216, acc.: 56.25%] [G loss: 0.287791]\n",
      "epoch:36 step:34244 [D loss: 0.241843, acc.: 61.72%] [G loss: 0.300543]\n",
      "epoch:36 step:34245 [D loss: 0.241548, acc.: 59.38%] [G loss: 0.291896]\n",
      "epoch:36 step:34246 [D loss: 0.250605, acc.: 53.12%] [G loss: 0.282504]\n",
      "epoch:36 step:34247 [D loss: 0.232009, acc.: 60.16%] [G loss: 0.301594]\n",
      "epoch:36 step:34248 [D loss: 0.248129, acc.: 55.47%] [G loss: 0.299394]\n",
      "epoch:36 step:34249 [D loss: 0.244220, acc.: 54.69%] [G loss: 0.291034]\n",
      "epoch:36 step:34250 [D loss: 0.237924, acc.: 58.59%] [G loss: 0.303092]\n",
      "epoch:36 step:34251 [D loss: 0.236519, acc.: 59.38%] [G loss: 0.289212]\n",
      "epoch:36 step:34252 [D loss: 0.232323, acc.: 64.06%] [G loss: 0.313983]\n",
      "epoch:36 step:34253 [D loss: 0.245539, acc.: 53.91%] [G loss: 0.312950]\n",
      "epoch:36 step:34254 [D loss: 0.253389, acc.: 54.69%] [G loss: 0.295700]\n",
      "epoch:36 step:34255 [D loss: 0.230336, acc.: 62.50%] [G loss: 0.305068]\n",
      "epoch:36 step:34256 [D loss: 0.243248, acc.: 53.91%] [G loss: 0.291961]\n",
      "epoch:36 step:34257 [D loss: 0.231001, acc.: 59.38%] [G loss: 0.312376]\n",
      "epoch:36 step:34258 [D loss: 0.241320, acc.: 62.50%] [G loss: 0.287839]\n",
      "epoch:36 step:34259 [D loss: 0.245081, acc.: 57.81%] [G loss: 0.300230]\n",
      "epoch:36 step:34260 [D loss: 0.255646, acc.: 50.00%] [G loss: 0.283097]\n",
      "epoch:36 step:34261 [D loss: 0.236581, acc.: 61.72%] [G loss: 0.320669]\n",
      "epoch:36 step:34262 [D loss: 0.239379, acc.: 60.94%] [G loss: 0.281199]\n",
      "epoch:36 step:34263 [D loss: 0.227967, acc.: 60.94%] [G loss: 0.296281]\n",
      "epoch:36 step:34264 [D loss: 0.258955, acc.: 49.22%] [G loss: 0.313711]\n",
      "epoch:36 step:34265 [D loss: 0.238069, acc.: 57.03%] [G loss: 0.306461]\n",
      "epoch:36 step:34266 [D loss: 0.248088, acc.: 56.25%] [G loss: 0.314653]\n",
      "epoch:36 step:34267 [D loss: 0.215513, acc.: 66.41%] [G loss: 0.317032]\n",
      "epoch:36 step:34268 [D loss: 0.246042, acc.: 57.03%] [G loss: 0.290323]\n",
      "epoch:36 step:34269 [D loss: 0.229701, acc.: 65.62%] [G loss: 0.281856]\n",
      "epoch:36 step:34270 [D loss: 0.242464, acc.: 59.38%] [G loss: 0.290706]\n",
      "epoch:36 step:34271 [D loss: 0.231861, acc.: 63.28%] [G loss: 0.263990]\n",
      "epoch:36 step:34272 [D loss: 0.247470, acc.: 53.91%] [G loss: 0.300186]\n",
      "epoch:36 step:34273 [D loss: 0.241887, acc.: 54.69%] [G loss: 0.286064]\n",
      "epoch:36 step:34274 [D loss: 0.253682, acc.: 50.00%] [G loss: 0.282109]\n",
      "epoch:36 step:34275 [D loss: 0.240304, acc.: 56.25%] [G loss: 0.266974]\n",
      "epoch:36 step:34276 [D loss: 0.225789, acc.: 64.84%] [G loss: 0.287369]\n",
      "epoch:36 step:34277 [D loss: 0.238500, acc.: 59.38%] [G loss: 0.291158]\n",
      "epoch:36 step:34278 [D loss: 0.230359, acc.: 60.16%] [G loss: 0.305585]\n",
      "epoch:36 step:34279 [D loss: 0.250958, acc.: 59.38%] [G loss: 0.302601]\n",
      "epoch:36 step:34280 [D loss: 0.262012, acc.: 44.53%] [G loss: 0.283212]\n",
      "epoch:36 step:34281 [D loss: 0.237453, acc.: 61.72%] [G loss: 0.300361]\n",
      "epoch:36 step:34282 [D loss: 0.242267, acc.: 60.94%] [G loss: 0.282444]\n",
      "epoch:36 step:34283 [D loss: 0.234260, acc.: 60.94%] [G loss: 0.318009]\n",
      "epoch:36 step:34284 [D loss: 0.247086, acc.: 54.69%] [G loss: 0.318188]\n",
      "epoch:36 step:34285 [D loss: 0.245828, acc.: 60.16%] [G loss: 0.315075]\n",
      "epoch:36 step:34286 [D loss: 0.245205, acc.: 56.25%] [G loss: 0.297902]\n",
      "epoch:36 step:34287 [D loss: 0.227898, acc.: 61.72%] [G loss: 0.317848]\n",
      "epoch:36 step:34288 [D loss: 0.249219, acc.: 56.25%] [G loss: 0.315270]\n",
      "epoch:36 step:34289 [D loss: 0.238153, acc.: 56.25%] [G loss: 0.312367]\n",
      "epoch:36 step:34290 [D loss: 0.247438, acc.: 47.66%] [G loss: 0.307413]\n",
      "epoch:36 step:34291 [D loss: 0.243346, acc.: 59.38%] [G loss: 0.342646]\n",
      "epoch:36 step:34292 [D loss: 0.240454, acc.: 57.03%] [G loss: 0.314942]\n",
      "epoch:36 step:34293 [D loss: 0.233798, acc.: 60.94%] [G loss: 0.290908]\n",
      "epoch:36 step:34294 [D loss: 0.239239, acc.: 61.72%] [G loss: 0.304416]\n",
      "epoch:36 step:34295 [D loss: 0.233616, acc.: 60.94%] [G loss: 0.296926]\n",
      "epoch:36 step:34296 [D loss: 0.237246, acc.: 60.16%] [G loss: 0.277670]\n",
      "epoch:36 step:34297 [D loss: 0.236441, acc.: 59.38%] [G loss: 0.295246]\n",
      "epoch:36 step:34298 [D loss: 0.235833, acc.: 62.50%] [G loss: 0.304557]\n",
      "epoch:36 step:34299 [D loss: 0.225077, acc.: 63.28%] [G loss: 0.303207]\n",
      "epoch:36 step:34300 [D loss: 0.236439, acc.: 55.47%] [G loss: 0.281300]\n",
      "epoch:36 step:34301 [D loss: 0.248194, acc.: 56.25%] [G loss: 0.299292]\n",
      "epoch:36 step:34302 [D loss: 0.231989, acc.: 61.72%] [G loss: 0.298212]\n",
      "epoch:36 step:34303 [D loss: 0.229855, acc.: 63.28%] [G loss: 0.297850]\n",
      "epoch:36 step:34304 [D loss: 0.227615, acc.: 64.84%] [G loss: 0.272926]\n",
      "epoch:36 step:34305 [D loss: 0.241448, acc.: 61.72%] [G loss: 0.308546]\n",
      "epoch:36 step:34306 [D loss: 0.260825, acc.: 53.12%] [G loss: 0.280134]\n",
      "epoch:36 step:34307 [D loss: 0.271781, acc.: 48.44%] [G loss: 0.326183]\n",
      "epoch:36 step:34308 [D loss: 0.226047, acc.: 58.59%] [G loss: 0.291076]\n",
      "epoch:36 step:34309 [D loss: 0.251215, acc.: 53.91%] [G loss: 0.298660]\n",
      "epoch:36 step:34310 [D loss: 0.241913, acc.: 61.72%] [G loss: 0.304828]\n",
      "epoch:36 step:34311 [D loss: 0.246037, acc.: 54.69%] [G loss: 0.282375]\n",
      "epoch:36 step:34312 [D loss: 0.250684, acc.: 57.03%] [G loss: 0.293416]\n",
      "epoch:36 step:34313 [D loss: 0.237816, acc.: 55.47%] [G loss: 0.276448]\n",
      "epoch:36 step:34314 [D loss: 0.236401, acc.: 57.81%] [G loss: 0.305996]\n",
      "epoch:36 step:34315 [D loss: 0.215298, acc.: 71.09%] [G loss: 0.285528]\n",
      "epoch:36 step:34316 [D loss: 0.232292, acc.: 56.25%] [G loss: 0.310931]\n",
      "epoch:36 step:34317 [D loss: 0.238371, acc.: 57.81%] [G loss: 0.302652]\n",
      "epoch:36 step:34318 [D loss: 0.223835, acc.: 64.06%] [G loss: 0.295715]\n",
      "epoch:36 step:34319 [D loss: 0.246582, acc.: 54.69%] [G loss: 0.272225]\n",
      "epoch:36 step:34320 [D loss: 0.220068, acc.: 64.84%] [G loss: 0.282222]\n",
      "epoch:36 step:34321 [D loss: 0.238578, acc.: 60.94%] [G loss: 0.303730]\n",
      "epoch:36 step:34322 [D loss: 0.241045, acc.: 55.47%] [G loss: 0.303412]\n",
      "epoch:36 step:34323 [D loss: 0.224356, acc.: 65.62%] [G loss: 0.326720]\n",
      "epoch:36 step:34324 [D loss: 0.241658, acc.: 61.72%] [G loss: 0.299979]\n",
      "epoch:36 step:34325 [D loss: 0.243102, acc.: 57.81%] [G loss: 0.309885]\n",
      "epoch:36 step:34326 [D loss: 0.242544, acc.: 58.59%] [G loss: 0.310526]\n",
      "epoch:36 step:34327 [D loss: 0.231037, acc.: 61.72%] [G loss: 0.293018]\n",
      "epoch:36 step:34328 [D loss: 0.253645, acc.: 55.47%] [G loss: 0.287118]\n",
      "epoch:36 step:34329 [D loss: 0.237197, acc.: 58.59%] [G loss: 0.325736]\n",
      "epoch:36 step:34330 [D loss: 0.237484, acc.: 58.59%] [G loss: 0.288293]\n",
      "epoch:36 step:34331 [D loss: 0.247368, acc.: 57.81%] [G loss: 0.307652]\n",
      "epoch:36 step:34332 [D loss: 0.237915, acc.: 64.06%] [G loss: 0.303757]\n",
      "epoch:36 step:34333 [D loss: 0.240927, acc.: 57.03%] [G loss: 0.261081]\n",
      "epoch:36 step:34334 [D loss: 0.219581, acc.: 61.72%] [G loss: 0.335899]\n",
      "epoch:36 step:34335 [D loss: 0.243104, acc.: 56.25%] [G loss: 0.286548]\n",
      "epoch:36 step:34336 [D loss: 0.238963, acc.: 63.28%] [G loss: 0.281751]\n",
      "epoch:36 step:34337 [D loss: 0.242145, acc.: 60.94%] [G loss: 0.300417]\n",
      "epoch:36 step:34338 [D loss: 0.239321, acc.: 57.81%] [G loss: 0.290241]\n",
      "epoch:36 step:34339 [D loss: 0.223978, acc.: 64.84%] [G loss: 0.303647]\n",
      "epoch:36 step:34340 [D loss: 0.242530, acc.: 57.81%] [G loss: 0.301138]\n",
      "epoch:36 step:34341 [D loss: 0.229133, acc.: 61.72%] [G loss: 0.302397]\n",
      "epoch:36 step:34342 [D loss: 0.232311, acc.: 59.38%] [G loss: 0.286175]\n",
      "epoch:36 step:34343 [D loss: 0.236764, acc.: 59.38%] [G loss: 0.302002]\n",
      "epoch:36 step:34344 [D loss: 0.231048, acc.: 60.94%] [G loss: 0.302266]\n",
      "epoch:36 step:34345 [D loss: 0.236575, acc.: 56.25%] [G loss: 0.297960]\n",
      "epoch:36 step:34346 [D loss: 0.242699, acc.: 58.59%] [G loss: 0.268034]\n",
      "epoch:36 step:34347 [D loss: 0.242527, acc.: 57.81%] [G loss: 0.301660]\n",
      "epoch:36 step:34348 [D loss: 0.241075, acc.: 58.59%] [G loss: 0.294628]\n",
      "epoch:36 step:34349 [D loss: 0.255823, acc.: 53.91%] [G loss: 0.303952]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:36 step:34350 [D loss: 0.233073, acc.: 63.28%] [G loss: 0.321080]\n",
      "epoch:36 step:34351 [D loss: 0.226985, acc.: 58.59%] [G loss: 0.281864]\n",
      "epoch:36 step:34352 [D loss: 0.238257, acc.: 55.47%] [G loss: 0.316100]\n",
      "epoch:36 step:34353 [D loss: 0.235113, acc.: 55.47%] [G loss: 0.292834]\n",
      "epoch:36 step:34354 [D loss: 0.233546, acc.: 59.38%] [G loss: 0.289155]\n",
      "epoch:36 step:34355 [D loss: 0.235948, acc.: 61.72%] [G loss: 0.266159]\n",
      "epoch:36 step:34356 [D loss: 0.235621, acc.: 57.81%] [G loss: 0.266644]\n",
      "epoch:36 step:34357 [D loss: 0.252965, acc.: 49.22%] [G loss: 0.269777]\n",
      "epoch:36 step:34358 [D loss: 0.225326, acc.: 60.16%] [G loss: 0.282408]\n",
      "epoch:36 step:34359 [D loss: 0.224961, acc.: 63.28%] [G loss: 0.302090]\n",
      "epoch:36 step:34360 [D loss: 0.258567, acc.: 50.78%] [G loss: 0.264544]\n",
      "epoch:36 step:34361 [D loss: 0.238914, acc.: 61.72%] [G loss: 0.298083]\n",
      "epoch:36 step:34362 [D loss: 0.236595, acc.: 60.16%] [G loss: 0.297404]\n",
      "epoch:36 step:34363 [D loss: 0.232554, acc.: 64.06%] [G loss: 0.308403]\n",
      "epoch:36 step:34364 [D loss: 0.238569, acc.: 58.59%] [G loss: 0.303976]\n",
      "epoch:36 step:34365 [D loss: 0.233178, acc.: 61.72%] [G loss: 0.300055]\n",
      "epoch:36 step:34366 [D loss: 0.219978, acc.: 64.06%] [G loss: 0.291123]\n",
      "epoch:36 step:34367 [D loss: 0.237806, acc.: 57.81%] [G loss: 0.283478]\n",
      "epoch:36 step:34368 [D loss: 0.225715, acc.: 62.50%] [G loss: 0.312624]\n",
      "epoch:36 step:34369 [D loss: 0.237242, acc.: 62.50%] [G loss: 0.292955]\n",
      "epoch:36 step:34370 [D loss: 0.239887, acc.: 62.50%] [G loss: 0.301972]\n",
      "epoch:36 step:34371 [D loss: 0.241771, acc.: 53.12%] [G loss: 0.310601]\n",
      "epoch:36 step:34372 [D loss: 0.237869, acc.: 58.59%] [G loss: 0.305729]\n",
      "epoch:36 step:34373 [D loss: 0.237448, acc.: 55.47%] [G loss: 0.307367]\n",
      "epoch:36 step:34374 [D loss: 0.253627, acc.: 53.91%] [G loss: 0.286140]\n",
      "epoch:36 step:34375 [D loss: 0.254036, acc.: 52.34%] [G loss: 0.302611]\n",
      "epoch:36 step:34376 [D loss: 0.257819, acc.: 53.12%] [G loss: 0.293727]\n",
      "epoch:36 step:34377 [D loss: 0.249456, acc.: 55.47%] [G loss: 0.265420]\n",
      "epoch:36 step:34378 [D loss: 0.240199, acc.: 57.81%] [G loss: 0.266994]\n",
      "epoch:36 step:34379 [D loss: 0.252016, acc.: 50.78%] [G loss: 0.296764]\n",
      "epoch:36 step:34380 [D loss: 0.233279, acc.: 60.94%] [G loss: 0.270886]\n",
      "epoch:36 step:34381 [D loss: 0.250223, acc.: 49.22%] [G loss: 0.308605]\n",
      "epoch:36 step:34382 [D loss: 0.237390, acc.: 64.06%] [G loss: 0.321580]\n",
      "epoch:36 step:34383 [D loss: 0.251049, acc.: 55.47%] [G loss: 0.295733]\n",
      "epoch:36 step:34384 [D loss: 0.260247, acc.: 52.34%] [G loss: 0.296802]\n",
      "epoch:36 step:34385 [D loss: 0.238886, acc.: 56.25%] [G loss: 0.275512]\n",
      "epoch:36 step:34386 [D loss: 0.232569, acc.: 62.50%] [G loss: 0.333815]\n",
      "epoch:36 step:34387 [D loss: 0.242026, acc.: 54.69%] [G loss: 0.294632]\n",
      "epoch:36 step:34388 [D loss: 0.224545, acc.: 62.50%] [G loss: 0.304271]\n",
      "epoch:36 step:34389 [D loss: 0.227245, acc.: 61.72%] [G loss: 0.320190]\n",
      "epoch:36 step:34390 [D loss: 0.243985, acc.: 55.47%] [G loss: 0.287047]\n",
      "epoch:36 step:34391 [D loss: 0.227690, acc.: 64.06%] [G loss: 0.309562]\n",
      "epoch:36 step:34392 [D loss: 0.229370, acc.: 62.50%] [G loss: 0.298667]\n",
      "epoch:36 step:34393 [D loss: 0.236091, acc.: 57.81%] [G loss: 0.280957]\n",
      "epoch:36 step:34394 [D loss: 0.250680, acc.: 56.25%] [G loss: 0.304101]\n",
      "epoch:36 step:34395 [D loss: 0.268718, acc.: 44.53%] [G loss: 0.267367]\n",
      "epoch:36 step:34396 [D loss: 0.249884, acc.: 53.91%] [G loss: 0.279036]\n",
      "epoch:36 step:34397 [D loss: 0.253653, acc.: 60.94%] [G loss: 0.292104]\n",
      "epoch:36 step:34398 [D loss: 0.235059, acc.: 58.59%] [G loss: 0.277988]\n",
      "epoch:36 step:34399 [D loss: 0.248675, acc.: 53.12%] [G loss: 0.280044]\n",
      "epoch:36 step:34400 [D loss: 0.256907, acc.: 50.78%] [G loss: 0.290410]\n",
      "epoch:36 step:34401 [D loss: 0.230549, acc.: 64.06%] [G loss: 0.303224]\n",
      "epoch:36 step:34402 [D loss: 0.250886, acc.: 53.12%] [G loss: 0.311663]\n",
      "epoch:36 step:34403 [D loss: 0.245100, acc.: 52.34%] [G loss: 0.285010]\n",
      "epoch:36 step:34404 [D loss: 0.231858, acc.: 59.38%] [G loss: 0.250598]\n",
      "epoch:36 step:34405 [D loss: 0.251016, acc.: 51.56%] [G loss: 0.305701]\n",
      "epoch:36 step:34406 [D loss: 0.226907, acc.: 60.94%] [G loss: 0.302244]\n",
      "epoch:36 step:34407 [D loss: 0.241935, acc.: 56.25%] [G loss: 0.292644]\n",
      "epoch:36 step:34408 [D loss: 0.221907, acc.: 63.28%] [G loss: 0.288896]\n",
      "epoch:36 step:34409 [D loss: 0.232894, acc.: 63.28%] [G loss: 0.277139]\n",
      "epoch:36 step:34410 [D loss: 0.247062, acc.: 57.81%] [G loss: 0.278873]\n",
      "epoch:36 step:34411 [D loss: 0.243161, acc.: 56.25%] [G loss: 0.298250]\n",
      "epoch:36 step:34412 [D loss: 0.249980, acc.: 56.25%] [G loss: 0.302523]\n",
      "epoch:36 step:34413 [D loss: 0.231962, acc.: 61.72%] [G loss: 0.318093]\n",
      "epoch:36 step:34414 [D loss: 0.226069, acc.: 60.94%] [G loss: 0.293588]\n",
      "epoch:36 step:34415 [D loss: 0.241549, acc.: 56.25%] [G loss: 0.302543]\n",
      "epoch:36 step:34416 [D loss: 0.249862, acc.: 55.47%] [G loss: 0.271848]\n",
      "epoch:36 step:34417 [D loss: 0.234584, acc.: 61.72%] [G loss: 0.270296]\n",
      "epoch:36 step:34418 [D loss: 0.221017, acc.: 66.41%] [G loss: 0.316339]\n",
      "epoch:36 step:34419 [D loss: 0.245610, acc.: 50.78%] [G loss: 0.290747]\n",
      "epoch:36 step:34420 [D loss: 0.227142, acc.: 66.41%] [G loss: 0.296899]\n",
      "epoch:36 step:34421 [D loss: 0.246086, acc.: 57.03%] [G loss: 0.298765]\n",
      "epoch:36 step:34422 [D loss: 0.232345, acc.: 62.50%] [G loss: 0.310901]\n",
      "epoch:36 step:34423 [D loss: 0.227821, acc.: 57.81%] [G loss: 0.296569]\n",
      "epoch:36 step:34424 [D loss: 0.234834, acc.: 58.59%] [G loss: 0.296943]\n",
      "epoch:36 step:34425 [D loss: 0.250490, acc.: 53.91%] [G loss: 0.290441]\n",
      "epoch:36 step:34426 [D loss: 0.250582, acc.: 54.69%] [G loss: 0.321529]\n",
      "epoch:36 step:34427 [D loss: 0.257265, acc.: 50.00%] [G loss: 0.274320]\n",
      "epoch:36 step:34428 [D loss: 0.247055, acc.: 55.47%] [G loss: 0.296092]\n",
      "epoch:36 step:34429 [D loss: 0.226694, acc.: 63.28%] [G loss: 0.293508]\n",
      "epoch:36 step:34430 [D loss: 0.248418, acc.: 55.47%] [G loss: 0.282747]\n",
      "epoch:36 step:34431 [D loss: 0.244636, acc.: 57.81%] [G loss: 0.284489]\n",
      "epoch:36 step:34432 [D loss: 0.227027, acc.: 67.19%] [G loss: 0.309476]\n",
      "epoch:36 step:34433 [D loss: 0.259813, acc.: 50.78%] [G loss: 0.314097]\n",
      "epoch:36 step:34434 [D loss: 0.234387, acc.: 59.38%] [G loss: 0.297956]\n",
      "epoch:36 step:34435 [D loss: 0.229530, acc.: 58.59%] [G loss: 0.301963]\n",
      "epoch:36 step:34436 [D loss: 0.246072, acc.: 55.47%] [G loss: 0.285882]\n",
      "epoch:36 step:34437 [D loss: 0.240078, acc.: 60.16%] [G loss: 0.294307]\n",
      "epoch:36 step:34438 [D loss: 0.255365, acc.: 53.12%] [G loss: 0.317188]\n",
      "epoch:36 step:34439 [D loss: 0.237235, acc.: 55.47%] [G loss: 0.288921]\n",
      "epoch:36 step:34440 [D loss: 0.248487, acc.: 56.25%] [G loss: 0.297343]\n",
      "epoch:36 step:34441 [D loss: 0.264610, acc.: 53.12%] [G loss: 0.310616]\n",
      "epoch:36 step:34442 [D loss: 0.237125, acc.: 51.56%] [G loss: 0.308885]\n",
      "epoch:36 step:34443 [D loss: 0.237184, acc.: 58.59%] [G loss: 0.337658]\n",
      "epoch:36 step:34444 [D loss: 0.251297, acc.: 52.34%] [G loss: 0.277380]\n",
      "epoch:36 step:34445 [D loss: 0.244164, acc.: 55.47%] [G loss: 0.329337]\n",
      "epoch:36 step:34446 [D loss: 0.238053, acc.: 55.47%] [G loss: 0.281511]\n",
      "epoch:36 step:34447 [D loss: 0.246709, acc.: 56.25%] [G loss: 0.302198]\n",
      "epoch:36 step:34448 [D loss: 0.226867, acc.: 66.41%] [G loss: 0.315287]\n",
      "epoch:36 step:34449 [D loss: 0.234511, acc.: 60.94%] [G loss: 0.298270]\n",
      "epoch:36 step:34450 [D loss: 0.222757, acc.: 64.84%] [G loss: 0.290499]\n",
      "epoch:36 step:34451 [D loss: 0.244369, acc.: 54.69%] [G loss: 0.316090]\n",
      "epoch:36 step:34452 [D loss: 0.259503, acc.: 53.91%] [G loss: 0.270710]\n",
      "epoch:36 step:34453 [D loss: 0.230873, acc.: 63.28%] [G loss: 0.298002]\n",
      "epoch:36 step:34454 [D loss: 0.252115, acc.: 51.56%] [G loss: 0.286778]\n",
      "epoch:36 step:34455 [D loss: 0.234576, acc.: 57.03%] [G loss: 0.314449]\n",
      "epoch:36 step:34456 [D loss: 0.237321, acc.: 59.38%] [G loss: 0.307968]\n",
      "epoch:36 step:34457 [D loss: 0.233848, acc.: 61.72%] [G loss: 0.297433]\n",
      "epoch:36 step:34458 [D loss: 0.251196, acc.: 50.78%] [G loss: 0.322547]\n",
      "epoch:36 step:34459 [D loss: 0.223363, acc.: 64.06%] [G loss: 0.311575]\n",
      "epoch:36 step:34460 [D loss: 0.243605, acc.: 57.81%] [G loss: 0.308209]\n",
      "epoch:36 step:34461 [D loss: 0.238503, acc.: 57.03%] [G loss: 0.296731]\n",
      "epoch:36 step:34462 [D loss: 0.233685, acc.: 57.03%] [G loss: 0.266707]\n",
      "epoch:36 step:34463 [D loss: 0.248772, acc.: 50.78%] [G loss: 0.297058]\n",
      "epoch:36 step:34464 [D loss: 0.241405, acc.: 58.59%] [G loss: 0.321608]\n",
      "epoch:36 step:34465 [D loss: 0.252851, acc.: 51.56%] [G loss: 0.352120]\n",
      "epoch:36 step:34466 [D loss: 0.227592, acc.: 63.28%] [G loss: 0.320512]\n",
      "epoch:36 step:34467 [D loss: 0.256140, acc.: 46.88%] [G loss: 0.298264]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:36 step:34468 [D loss: 0.250659, acc.: 53.91%] [G loss: 0.290456]\n",
      "epoch:36 step:34469 [D loss: 0.221366, acc.: 65.62%] [G loss: 0.327383]\n",
      "epoch:36 step:34470 [D loss: 0.241628, acc.: 57.03%] [G loss: 0.286739]\n",
      "epoch:36 step:34471 [D loss: 0.247598, acc.: 54.69%] [G loss: 0.298880]\n",
      "epoch:36 step:34472 [D loss: 0.259708, acc.: 52.34%] [G loss: 0.287371]\n",
      "epoch:36 step:34473 [D loss: 0.241522, acc.: 57.81%] [G loss: 0.319206]\n",
      "epoch:36 step:34474 [D loss: 0.247019, acc.: 58.59%] [G loss: 0.276608]\n",
      "epoch:36 step:34475 [D loss: 0.246929, acc.: 55.47%] [G loss: 0.305922]\n",
      "epoch:36 step:34476 [D loss: 0.252301, acc.: 53.91%] [G loss: 0.306620]\n",
      "epoch:36 step:34477 [D loss: 0.219024, acc.: 64.84%] [G loss: 0.294452]\n",
      "epoch:36 step:34478 [D loss: 0.247983, acc.: 52.34%] [G loss: 0.297426]\n",
      "epoch:36 step:34479 [D loss: 0.231800, acc.: 59.38%] [G loss: 0.311147]\n",
      "epoch:36 step:34480 [D loss: 0.239099, acc.: 56.25%] [G loss: 0.290711]\n",
      "epoch:36 step:34481 [D loss: 0.258067, acc.: 48.44%] [G loss: 0.287779]\n",
      "epoch:36 step:34482 [D loss: 0.232588, acc.: 64.06%] [G loss: 0.318595]\n",
      "epoch:36 step:34483 [D loss: 0.247479, acc.: 53.91%] [G loss: 0.324901]\n",
      "epoch:36 step:34484 [D loss: 0.237479, acc.: 63.28%] [G loss: 0.306598]\n",
      "epoch:36 step:34485 [D loss: 0.226337, acc.: 58.59%] [G loss: 0.299942]\n",
      "epoch:36 step:34486 [D loss: 0.225164, acc.: 61.72%] [G loss: 0.296467]\n",
      "epoch:36 step:34487 [D loss: 0.243696, acc.: 53.12%] [G loss: 0.310074]\n",
      "epoch:36 step:34488 [D loss: 0.247828, acc.: 58.59%] [G loss: 0.277236]\n",
      "epoch:36 step:34489 [D loss: 0.215553, acc.: 64.84%] [G loss: 0.307290]\n",
      "epoch:36 step:34490 [D loss: 0.238094, acc.: 56.25%] [G loss: 0.279381]\n",
      "epoch:36 step:34491 [D loss: 0.257181, acc.: 61.72%] [G loss: 0.312324]\n",
      "epoch:36 step:34492 [D loss: 0.225764, acc.: 62.50%] [G loss: 0.266567]\n",
      "epoch:36 step:34493 [D loss: 0.238390, acc.: 58.59%] [G loss: 0.287118]\n",
      "epoch:36 step:34494 [D loss: 0.249536, acc.: 50.00%] [G loss: 0.288413]\n",
      "epoch:36 step:34495 [D loss: 0.239932, acc.: 60.94%] [G loss: 0.296293]\n",
      "epoch:36 step:34496 [D loss: 0.237632, acc.: 60.16%] [G loss: 0.269359]\n",
      "epoch:36 step:34497 [D loss: 0.242722, acc.: 57.81%] [G loss: 0.289692]\n",
      "epoch:36 step:34498 [D loss: 0.244057, acc.: 58.59%] [G loss: 0.303111]\n",
      "epoch:36 step:34499 [D loss: 0.251925, acc.: 53.91%] [G loss: 0.281645]\n",
      "epoch:36 step:34500 [D loss: 0.231157, acc.: 59.38%] [G loss: 0.291153]\n",
      "epoch:36 step:34501 [D loss: 0.232405, acc.: 58.59%] [G loss: 0.299530]\n",
      "epoch:36 step:34502 [D loss: 0.271005, acc.: 41.41%] [G loss: 0.309067]\n",
      "epoch:36 step:34503 [D loss: 0.238977, acc.: 54.69%] [G loss: 0.298687]\n",
      "epoch:36 step:34504 [D loss: 0.235319, acc.: 59.38%] [G loss: 0.301484]\n",
      "epoch:36 step:34505 [D loss: 0.253096, acc.: 53.12%] [G loss: 0.299449]\n",
      "epoch:36 step:34506 [D loss: 0.234604, acc.: 58.59%] [G loss: 0.326519]\n",
      "epoch:36 step:34507 [D loss: 0.220995, acc.: 63.28%] [G loss: 0.329330]\n",
      "epoch:36 step:34508 [D loss: 0.223986, acc.: 65.62%] [G loss: 0.268016]\n",
      "epoch:36 step:34509 [D loss: 0.237488, acc.: 60.16%] [G loss: 0.290882]\n",
      "epoch:36 step:34510 [D loss: 0.255109, acc.: 52.34%] [G loss: 0.293928]\n",
      "epoch:36 step:34511 [D loss: 0.229945, acc.: 59.38%] [G loss: 0.321498]\n",
      "epoch:36 step:34512 [D loss: 0.260094, acc.: 49.22%] [G loss: 0.309247]\n",
      "epoch:36 step:34513 [D loss: 0.241903, acc.: 54.69%] [G loss: 0.280095]\n",
      "epoch:36 step:34514 [D loss: 0.252844, acc.: 53.91%] [G loss: 0.294322]\n",
      "epoch:36 step:34515 [D loss: 0.231872, acc.: 60.16%] [G loss: 0.300236]\n",
      "epoch:36 step:34516 [D loss: 0.248486, acc.: 53.12%] [G loss: 0.314670]\n",
      "epoch:36 step:34517 [D loss: 0.247957, acc.: 53.91%] [G loss: 0.291954]\n",
      "epoch:36 step:34518 [D loss: 0.256314, acc.: 53.91%] [G loss: 0.321498]\n",
      "epoch:36 step:34519 [D loss: 0.251905, acc.: 54.69%] [G loss: 0.276143]\n",
      "epoch:36 step:34520 [D loss: 0.238057, acc.: 59.38%] [G loss: 0.308256]\n",
      "epoch:36 step:34521 [D loss: 0.240545, acc.: 60.16%] [G loss: 0.309443]\n",
      "epoch:36 step:34522 [D loss: 0.237488, acc.: 57.03%] [G loss: 0.334676]\n",
      "epoch:36 step:34523 [D loss: 0.269874, acc.: 50.00%] [G loss: 0.295277]\n",
      "epoch:36 step:34524 [D loss: 0.243692, acc.: 53.91%] [G loss: 0.291290]\n",
      "epoch:36 step:34525 [D loss: 0.222454, acc.: 63.28%] [G loss: 0.321447]\n",
      "epoch:36 step:34526 [D loss: 0.227819, acc.: 60.94%] [G loss: 0.285307]\n",
      "epoch:36 step:34527 [D loss: 0.233339, acc.: 62.50%] [G loss: 0.334070]\n",
      "epoch:36 step:34528 [D loss: 0.235094, acc.: 56.25%] [G loss: 0.303406]\n",
      "epoch:36 step:34529 [D loss: 0.232106, acc.: 60.94%] [G loss: 0.321021]\n",
      "epoch:36 step:34530 [D loss: 0.242774, acc.: 60.16%] [G loss: 0.308704]\n",
      "epoch:36 step:34531 [D loss: 0.250781, acc.: 51.56%] [G loss: 0.306390]\n",
      "epoch:36 step:34532 [D loss: 0.241152, acc.: 53.12%] [G loss: 0.269873]\n",
      "epoch:36 step:34533 [D loss: 0.257430, acc.: 54.69%] [G loss: 0.283589]\n",
      "epoch:36 step:34534 [D loss: 0.244243, acc.: 57.03%] [G loss: 0.292265]\n",
      "epoch:36 step:34535 [D loss: 0.234327, acc.: 64.84%] [G loss: 0.285455]\n",
      "epoch:36 step:34536 [D loss: 0.246507, acc.: 55.47%] [G loss: 0.283923]\n",
      "epoch:36 step:34537 [D loss: 0.249884, acc.: 57.81%] [G loss: 0.274519]\n",
      "epoch:36 step:34538 [D loss: 0.229692, acc.: 65.62%] [G loss: 0.295366]\n",
      "epoch:36 step:34539 [D loss: 0.252977, acc.: 50.78%] [G loss: 0.308111]\n",
      "epoch:36 step:34540 [D loss: 0.228350, acc.: 66.41%] [G loss: 0.286278]\n",
      "epoch:36 step:34541 [D loss: 0.245356, acc.: 51.56%] [G loss: 0.293251]\n",
      "epoch:36 step:34542 [D loss: 0.236181, acc.: 61.72%] [G loss: 0.330338]\n",
      "epoch:36 step:34543 [D loss: 0.247058, acc.: 59.38%] [G loss: 0.298261]\n",
      "epoch:36 step:34544 [D loss: 0.234458, acc.: 65.62%] [G loss: 0.313993]\n",
      "epoch:36 step:34545 [D loss: 0.240565, acc.: 56.25%] [G loss: 0.281522]\n",
      "epoch:36 step:34546 [D loss: 0.224210, acc.: 64.06%] [G loss: 0.294451]\n",
      "epoch:36 step:34547 [D loss: 0.235422, acc.: 60.94%] [G loss: 0.308320]\n",
      "epoch:36 step:34548 [D loss: 0.236478, acc.: 57.81%] [G loss: 0.296667]\n",
      "epoch:36 step:34549 [D loss: 0.230146, acc.: 62.50%] [G loss: 0.285859]\n",
      "epoch:36 step:34550 [D loss: 0.240082, acc.: 59.38%] [G loss: 0.303766]\n",
      "epoch:36 step:34551 [D loss: 0.224815, acc.: 64.84%] [G loss: 0.321602]\n",
      "epoch:36 step:34552 [D loss: 0.236149, acc.: 61.72%] [G loss: 0.298568]\n",
      "epoch:36 step:34553 [D loss: 0.262875, acc.: 52.34%] [G loss: 0.276879]\n",
      "epoch:36 step:34554 [D loss: 0.255753, acc.: 55.47%] [G loss: 0.298528]\n",
      "epoch:36 step:34555 [D loss: 0.247415, acc.: 54.69%] [G loss: 0.298769]\n",
      "epoch:36 step:34556 [D loss: 0.238645, acc.: 58.59%] [G loss: 0.301738]\n",
      "epoch:36 step:34557 [D loss: 0.238120, acc.: 58.59%] [G loss: 0.315949]\n",
      "epoch:36 step:34558 [D loss: 0.219855, acc.: 64.06%] [G loss: 0.300603]\n",
      "epoch:36 step:34559 [D loss: 0.243911, acc.: 54.69%] [G loss: 0.309367]\n",
      "epoch:36 step:34560 [D loss: 0.233783, acc.: 60.16%] [G loss: 0.301505]\n",
      "epoch:36 step:34561 [D loss: 0.238679, acc.: 60.94%] [G loss: 0.268517]\n",
      "epoch:36 step:34562 [D loss: 0.246254, acc.: 57.81%] [G loss: 0.293660]\n",
      "epoch:36 step:34563 [D loss: 0.241995, acc.: 60.94%] [G loss: 0.269467]\n",
      "epoch:36 step:34564 [D loss: 0.235872, acc.: 57.81%] [G loss: 0.298252]\n",
      "epoch:36 step:34565 [D loss: 0.252839, acc.: 49.22%] [G loss: 0.283159]\n",
      "epoch:36 step:34566 [D loss: 0.243567, acc.: 57.03%] [G loss: 0.301185]\n",
      "epoch:36 step:34567 [D loss: 0.242880, acc.: 50.00%] [G loss: 0.290592]\n",
      "epoch:36 step:34568 [D loss: 0.246119, acc.: 54.69%] [G loss: 0.294711]\n",
      "epoch:36 step:34569 [D loss: 0.245659, acc.: 52.34%] [G loss: 0.286714]\n",
      "epoch:36 step:34570 [D loss: 0.244843, acc.: 52.34%] [G loss: 0.290712]\n",
      "epoch:36 step:34571 [D loss: 0.228660, acc.: 60.94%] [G loss: 0.293438]\n",
      "epoch:36 step:34572 [D loss: 0.247471, acc.: 50.00%] [G loss: 0.314525]\n",
      "epoch:36 step:34573 [D loss: 0.231183, acc.: 58.59%] [G loss: 0.276319]\n",
      "epoch:36 step:34574 [D loss: 0.251966, acc.: 51.56%] [G loss: 0.302443]\n",
      "epoch:36 step:34575 [D loss: 0.245511, acc.: 54.69%] [G loss: 0.313966]\n",
      "epoch:36 step:34576 [D loss: 0.238937, acc.: 60.94%] [G loss: 0.283597]\n",
      "epoch:36 step:34577 [D loss: 0.239695, acc.: 53.12%] [G loss: 0.263378]\n",
      "epoch:36 step:34578 [D loss: 0.232307, acc.: 54.69%] [G loss: 0.301476]\n",
      "epoch:36 step:34579 [D loss: 0.226716, acc.: 64.84%] [G loss: 0.316566]\n",
      "epoch:36 step:34580 [D loss: 0.232856, acc.: 62.50%] [G loss: 0.276793]\n",
      "epoch:36 step:34581 [D loss: 0.244911, acc.: 58.59%] [G loss: 0.303731]\n",
      "epoch:36 step:34582 [D loss: 0.237545, acc.: 61.72%] [G loss: 0.306241]\n",
      "epoch:36 step:34583 [D loss: 0.245559, acc.: 57.03%] [G loss: 0.281528]\n",
      "epoch:36 step:34584 [D loss: 0.237005, acc.: 63.28%] [G loss: 0.273126]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:36 step:34585 [D loss: 0.235952, acc.: 64.84%] [G loss: 0.266064]\n",
      "epoch:36 step:34586 [D loss: 0.229670, acc.: 60.94%] [G loss: 0.297622]\n",
      "epoch:36 step:34587 [D loss: 0.237033, acc.: 54.69%] [G loss: 0.294720]\n",
      "epoch:36 step:34588 [D loss: 0.238172, acc.: 51.56%] [G loss: 0.294935]\n",
      "epoch:36 step:34589 [D loss: 0.226842, acc.: 60.94%] [G loss: 0.302472]\n",
      "epoch:36 step:34590 [D loss: 0.240111, acc.: 53.91%] [G loss: 0.309004]\n",
      "epoch:36 step:34591 [D loss: 0.246270, acc.: 53.91%] [G loss: 0.303787]\n",
      "epoch:36 step:34592 [D loss: 0.233938, acc.: 61.72%] [G loss: 0.300378]\n",
      "epoch:36 step:34593 [D loss: 0.228099, acc.: 62.50%] [G loss: 0.335286]\n",
      "epoch:36 step:34594 [D loss: 0.239759, acc.: 59.38%] [G loss: 0.292383]\n",
      "epoch:36 step:34595 [D loss: 0.245308, acc.: 52.34%] [G loss: 0.296952]\n",
      "epoch:36 step:34596 [D loss: 0.271828, acc.: 49.22%] [G loss: 0.277460]\n",
      "epoch:36 step:34597 [D loss: 0.243112, acc.: 55.47%] [G loss: 0.289284]\n",
      "epoch:36 step:34598 [D loss: 0.221733, acc.: 61.72%] [G loss: 0.321991]\n",
      "epoch:36 step:34599 [D loss: 0.248129, acc.: 58.59%] [G loss: 0.273504]\n",
      "epoch:36 step:34600 [D loss: 0.231582, acc.: 58.59%] [G loss: 0.301217]\n",
      "epoch:36 step:34601 [D loss: 0.239663, acc.: 56.25%] [G loss: 0.326448]\n",
      "epoch:36 step:34602 [D loss: 0.239355, acc.: 60.16%] [G loss: 0.312485]\n",
      "epoch:36 step:34603 [D loss: 0.241242, acc.: 53.12%] [G loss: 0.303635]\n",
      "epoch:36 step:34604 [D loss: 0.245553, acc.: 55.47%] [G loss: 0.285311]\n",
      "epoch:36 step:34605 [D loss: 0.225996, acc.: 63.28%] [G loss: 0.319702]\n",
      "epoch:36 step:34606 [D loss: 0.245093, acc.: 52.34%] [G loss: 0.308582]\n",
      "epoch:36 step:34607 [D loss: 0.246004, acc.: 56.25%] [G loss: 0.292967]\n",
      "epoch:36 step:34608 [D loss: 0.251996, acc.: 47.66%] [G loss: 0.301760]\n",
      "epoch:36 step:34609 [D loss: 0.230116, acc.: 60.16%] [G loss: 0.301444]\n",
      "epoch:36 step:34610 [D loss: 0.255570, acc.: 51.56%] [G loss: 0.306586]\n",
      "epoch:36 step:34611 [D loss: 0.237208, acc.: 60.94%] [G loss: 0.300379]\n",
      "epoch:36 step:34612 [D loss: 0.232827, acc.: 60.16%] [G loss: 0.309107]\n",
      "epoch:36 step:34613 [D loss: 0.234350, acc.: 60.94%] [G loss: 0.296206]\n",
      "epoch:36 step:34614 [D loss: 0.225763, acc.: 60.94%] [G loss: 0.316809]\n",
      "epoch:36 step:34615 [D loss: 0.249736, acc.: 56.25%] [G loss: 0.311556]\n",
      "epoch:36 step:34616 [D loss: 0.228213, acc.: 62.50%] [G loss: 0.322988]\n",
      "epoch:36 step:34617 [D loss: 0.230082, acc.: 60.94%] [G loss: 0.306140]\n",
      "epoch:36 step:34618 [D loss: 0.228265, acc.: 63.28%] [G loss: 0.302387]\n",
      "epoch:36 step:34619 [D loss: 0.241534, acc.: 59.38%] [G loss: 0.317270]\n",
      "epoch:36 step:34620 [D loss: 0.248666, acc.: 52.34%] [G loss: 0.300162]\n",
      "epoch:36 step:34621 [D loss: 0.246655, acc.: 50.78%] [G loss: 0.278449]\n",
      "epoch:36 step:34622 [D loss: 0.260411, acc.: 48.44%] [G loss: 0.293108]\n",
      "epoch:36 step:34623 [D loss: 0.243200, acc.: 53.91%] [G loss: 0.301283]\n",
      "epoch:36 step:34624 [D loss: 0.242469, acc.: 58.59%] [G loss: 0.290035]\n",
      "epoch:36 step:34625 [D loss: 0.245155, acc.: 55.47%] [G loss: 0.286921]\n",
      "epoch:36 step:34626 [D loss: 0.233067, acc.: 59.38%] [G loss: 0.288313]\n",
      "epoch:36 step:34627 [D loss: 0.224693, acc.: 64.84%] [G loss: 0.292472]\n",
      "epoch:36 step:34628 [D loss: 0.236979, acc.: 57.81%] [G loss: 0.284829]\n",
      "epoch:36 step:34629 [D loss: 0.260524, acc.: 50.00%] [G loss: 0.290829]\n",
      "epoch:36 step:34630 [D loss: 0.241864, acc.: 57.03%] [G loss: 0.312260]\n",
      "epoch:36 step:34631 [D loss: 0.255730, acc.: 54.69%] [G loss: 0.309481]\n",
      "epoch:36 step:34632 [D loss: 0.246756, acc.: 50.78%] [G loss: 0.286776]\n",
      "epoch:36 step:34633 [D loss: 0.251528, acc.: 53.91%] [G loss: 0.320780]\n",
      "epoch:36 step:34634 [D loss: 0.251170, acc.: 51.56%] [G loss: 0.295207]\n",
      "epoch:36 step:34635 [D loss: 0.221866, acc.: 65.62%] [G loss: 0.301748]\n",
      "epoch:36 step:34636 [D loss: 0.255025, acc.: 54.69%] [G loss: 0.289725]\n",
      "epoch:36 step:34637 [D loss: 0.240330, acc.: 55.47%] [G loss: 0.287431]\n",
      "epoch:36 step:34638 [D loss: 0.254017, acc.: 54.69%] [G loss: 0.280073]\n",
      "epoch:36 step:34639 [D loss: 0.237980, acc.: 57.03%] [G loss: 0.296460]\n",
      "epoch:36 step:34640 [D loss: 0.263649, acc.: 46.09%] [G loss: 0.302550]\n",
      "epoch:36 step:34641 [D loss: 0.234036, acc.: 63.28%] [G loss: 0.306572]\n",
      "epoch:36 step:34642 [D loss: 0.255538, acc.: 51.56%] [G loss: 0.293214]\n",
      "epoch:36 step:34643 [D loss: 0.226071, acc.: 64.06%] [G loss: 0.296680]\n",
      "epoch:36 step:34644 [D loss: 0.247799, acc.: 55.47%] [G loss: 0.302594]\n",
      "epoch:36 step:34645 [D loss: 0.240845, acc.: 53.12%] [G loss: 0.307319]\n",
      "epoch:36 step:34646 [D loss: 0.236863, acc.: 57.03%] [G loss: 0.258476]\n",
      "epoch:36 step:34647 [D loss: 0.249949, acc.: 56.25%] [G loss: 0.306919]\n",
      "epoch:36 step:34648 [D loss: 0.227733, acc.: 64.06%] [G loss: 0.298332]\n",
      "epoch:36 step:34649 [D loss: 0.224996, acc.: 60.94%] [G loss: 0.311157]\n",
      "epoch:36 step:34650 [D loss: 0.234861, acc.: 61.72%] [G loss: 0.310482]\n",
      "epoch:36 step:34651 [D loss: 0.248682, acc.: 52.34%] [G loss: 0.273379]\n",
      "epoch:36 step:34652 [D loss: 0.227669, acc.: 62.50%] [G loss: 0.279218]\n",
      "epoch:36 step:34653 [D loss: 0.235309, acc.: 61.72%] [G loss: 0.308196]\n",
      "epoch:36 step:34654 [D loss: 0.238025, acc.: 56.25%] [G loss: 0.307175]\n",
      "epoch:36 step:34655 [D loss: 0.230980, acc.: 64.06%] [G loss: 0.289027]\n",
      "epoch:36 step:34656 [D loss: 0.239632, acc.: 59.38%] [G loss: 0.304854]\n",
      "epoch:36 step:34657 [D loss: 0.226655, acc.: 61.72%] [G loss: 0.294008]\n",
      "epoch:36 step:34658 [D loss: 0.232730, acc.: 57.81%] [G loss: 0.292585]\n",
      "epoch:36 step:34659 [D loss: 0.252679, acc.: 51.56%] [G loss: 0.298369]\n",
      "epoch:36 step:34660 [D loss: 0.234764, acc.: 55.47%] [G loss: 0.304999]\n",
      "epoch:36 step:34661 [D loss: 0.240440, acc.: 59.38%] [G loss: 0.289455]\n",
      "epoch:36 step:34662 [D loss: 0.246574, acc.: 50.78%] [G loss: 0.289540]\n",
      "epoch:36 step:34663 [D loss: 0.235337, acc.: 64.06%] [G loss: 0.288553]\n",
      "epoch:36 step:34664 [D loss: 0.219084, acc.: 66.41%] [G loss: 0.320023]\n",
      "epoch:36 step:34665 [D loss: 0.243013, acc.: 60.94%] [G loss: 0.294439]\n",
      "epoch:36 step:34666 [D loss: 0.222689, acc.: 62.50%] [G loss: 0.308947]\n",
      "epoch:36 step:34667 [D loss: 0.234489, acc.: 59.38%] [G loss: 0.291064]\n",
      "epoch:36 step:34668 [D loss: 0.244302, acc.: 60.16%] [G loss: 0.285995]\n",
      "epoch:36 step:34669 [D loss: 0.231325, acc.: 57.03%] [G loss: 0.315024]\n",
      "epoch:37 step:34670 [D loss: 0.229189, acc.: 59.38%] [G loss: 0.333752]\n",
      "epoch:37 step:34671 [D loss: 0.247641, acc.: 53.12%] [G loss: 0.306021]\n",
      "epoch:37 step:34672 [D loss: 0.255634, acc.: 54.69%] [G loss: 0.272535]\n",
      "epoch:37 step:34673 [D loss: 0.230473, acc.: 65.62%] [G loss: 0.292557]\n",
      "epoch:37 step:34674 [D loss: 0.232473, acc.: 64.84%] [G loss: 0.311940]\n",
      "epoch:37 step:34675 [D loss: 0.245603, acc.: 60.16%] [G loss: 0.290570]\n",
      "epoch:37 step:34676 [D loss: 0.245118, acc.: 53.12%] [G loss: 0.308406]\n",
      "epoch:37 step:34677 [D loss: 0.241227, acc.: 57.81%] [G loss: 0.306208]\n",
      "epoch:37 step:34678 [D loss: 0.247210, acc.: 52.34%] [G loss: 0.305617]\n",
      "epoch:37 step:34679 [D loss: 0.241300, acc.: 54.69%] [G loss: 0.315221]\n",
      "epoch:37 step:34680 [D loss: 0.227696, acc.: 63.28%] [G loss: 0.268228]\n",
      "epoch:37 step:34681 [D loss: 0.240965, acc.: 59.38%] [G loss: 0.295982]\n",
      "epoch:37 step:34682 [D loss: 0.242187, acc.: 55.47%] [G loss: 0.335652]\n",
      "epoch:37 step:34683 [D loss: 0.233001, acc.: 61.72%] [G loss: 0.308197]\n",
      "epoch:37 step:34684 [D loss: 0.262903, acc.: 47.66%] [G loss: 0.301396]\n",
      "epoch:37 step:34685 [D loss: 0.242727, acc.: 57.03%] [G loss: 0.301158]\n",
      "epoch:37 step:34686 [D loss: 0.235416, acc.: 60.94%] [G loss: 0.308252]\n",
      "epoch:37 step:34687 [D loss: 0.248717, acc.: 54.69%] [G loss: 0.286969]\n",
      "epoch:37 step:34688 [D loss: 0.242419, acc.: 61.72%] [G loss: 0.296949]\n",
      "epoch:37 step:34689 [D loss: 0.231002, acc.: 65.62%] [G loss: 0.317487]\n",
      "epoch:37 step:34690 [D loss: 0.254720, acc.: 52.34%] [G loss: 0.287032]\n",
      "epoch:37 step:34691 [D loss: 0.247166, acc.: 53.12%] [G loss: 0.307084]\n",
      "epoch:37 step:34692 [D loss: 0.242477, acc.: 61.72%] [G loss: 0.297799]\n",
      "epoch:37 step:34693 [D loss: 0.244304, acc.: 57.03%] [G loss: 0.304008]\n",
      "epoch:37 step:34694 [D loss: 0.231361, acc.: 64.06%] [G loss: 0.308462]\n",
      "epoch:37 step:34695 [D loss: 0.232089, acc.: 60.16%] [G loss: 0.337189]\n",
      "epoch:37 step:34696 [D loss: 0.237673, acc.: 56.25%] [G loss: 0.297775]\n",
      "epoch:37 step:34697 [D loss: 0.231397, acc.: 61.72%] [G loss: 0.306016]\n",
      "epoch:37 step:34698 [D loss: 0.251017, acc.: 57.81%] [G loss: 0.305103]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:37 step:34699 [D loss: 0.253961, acc.: 55.47%] [G loss: 0.298766]\n",
      "epoch:37 step:34700 [D loss: 0.252364, acc.: 53.91%] [G loss: 0.300311]\n",
      "epoch:37 step:34701 [D loss: 0.228528, acc.: 66.41%] [G loss: 0.326047]\n",
      "epoch:37 step:34702 [D loss: 0.247669, acc.: 53.91%] [G loss: 0.293929]\n",
      "epoch:37 step:34703 [D loss: 0.247947, acc.: 52.34%] [G loss: 0.273631]\n",
      "epoch:37 step:34704 [D loss: 0.251833, acc.: 54.69%] [G loss: 0.289132]\n",
      "epoch:37 step:34705 [D loss: 0.247111, acc.: 56.25%] [G loss: 0.291537]\n",
      "epoch:37 step:34706 [D loss: 0.239518, acc.: 63.28%] [G loss: 0.283472]\n",
      "epoch:37 step:34707 [D loss: 0.239647, acc.: 59.38%] [G loss: 0.285010]\n",
      "epoch:37 step:34708 [D loss: 0.254718, acc.: 48.44%] [G loss: 0.290771]\n",
      "epoch:37 step:34709 [D loss: 0.238960, acc.: 57.03%] [G loss: 0.293035]\n",
      "epoch:37 step:34710 [D loss: 0.222078, acc.: 60.16%] [G loss: 0.312726]\n",
      "epoch:37 step:34711 [D loss: 0.252499, acc.: 55.47%] [G loss: 0.289994]\n",
      "epoch:37 step:34712 [D loss: 0.223929, acc.: 64.06%] [G loss: 0.322045]\n",
      "epoch:37 step:34713 [D loss: 0.238857, acc.: 61.72%] [G loss: 0.316912]\n",
      "epoch:37 step:34714 [D loss: 0.253593, acc.: 57.03%] [G loss: 0.276969]\n",
      "epoch:37 step:34715 [D loss: 0.247794, acc.: 51.56%] [G loss: 0.284722]\n",
      "epoch:37 step:34716 [D loss: 0.229482, acc.: 66.41%] [G loss: 0.303244]\n",
      "epoch:37 step:34717 [D loss: 0.254643, acc.: 48.44%] [G loss: 0.301638]\n",
      "epoch:37 step:34718 [D loss: 0.228356, acc.: 63.28%] [G loss: 0.304834]\n",
      "epoch:37 step:34719 [D loss: 0.237268, acc.: 64.06%] [G loss: 0.299465]\n",
      "epoch:37 step:34720 [D loss: 0.228456, acc.: 67.97%] [G loss: 0.288032]\n",
      "epoch:37 step:34721 [D loss: 0.250772, acc.: 57.81%] [G loss: 0.281939]\n",
      "epoch:37 step:34722 [D loss: 0.238623, acc.: 57.03%] [G loss: 0.297146]\n",
      "epoch:37 step:34723 [D loss: 0.227417, acc.: 64.06%] [G loss: 0.291626]\n",
      "epoch:37 step:34724 [D loss: 0.238943, acc.: 57.81%] [G loss: 0.240348]\n",
      "epoch:37 step:34725 [D loss: 0.232770, acc.: 61.72%] [G loss: 0.276111]\n",
      "epoch:37 step:34726 [D loss: 0.245685, acc.: 56.25%] [G loss: 0.295780]\n",
      "epoch:37 step:34727 [D loss: 0.226788, acc.: 61.72%] [G loss: 0.293096]\n",
      "epoch:37 step:34728 [D loss: 0.243249, acc.: 56.25%] [G loss: 0.296930]\n",
      "epoch:37 step:34729 [D loss: 0.226442, acc.: 61.72%] [G loss: 0.311020]\n",
      "epoch:37 step:34730 [D loss: 0.244710, acc.: 53.12%] [G loss: 0.311719]\n",
      "epoch:37 step:34731 [D loss: 0.227261, acc.: 59.38%] [G loss: 0.303291]\n",
      "epoch:37 step:34732 [D loss: 0.241329, acc.: 62.50%] [G loss: 0.288698]\n",
      "epoch:37 step:34733 [D loss: 0.241941, acc.: 60.94%] [G loss: 0.279138]\n",
      "epoch:37 step:34734 [D loss: 0.260242, acc.: 48.44%] [G loss: 0.308132]\n",
      "epoch:37 step:34735 [D loss: 0.241059, acc.: 53.91%] [G loss: 0.270231]\n",
      "epoch:37 step:34736 [D loss: 0.239849, acc.: 57.03%] [G loss: 0.293742]\n",
      "epoch:37 step:34737 [D loss: 0.213452, acc.: 67.19%] [G loss: 0.319346]\n",
      "epoch:37 step:34738 [D loss: 0.233207, acc.: 58.59%] [G loss: 0.306404]\n",
      "epoch:37 step:34739 [D loss: 0.256665, acc.: 53.91%] [G loss: 0.302955]\n",
      "epoch:37 step:34740 [D loss: 0.237584, acc.: 59.38%] [G loss: 0.276850]\n",
      "epoch:37 step:34741 [D loss: 0.231314, acc.: 62.50%] [G loss: 0.311763]\n",
      "epoch:37 step:34742 [D loss: 0.247348, acc.: 57.03%] [G loss: 0.280507]\n",
      "epoch:37 step:34743 [D loss: 0.234488, acc.: 61.72%] [G loss: 0.281018]\n",
      "epoch:37 step:34744 [D loss: 0.237440, acc.: 59.38%] [G loss: 0.289195]\n",
      "epoch:37 step:34745 [D loss: 0.247158, acc.: 57.03%] [G loss: 0.257365]\n",
      "epoch:37 step:34746 [D loss: 0.232434, acc.: 56.25%] [G loss: 0.306678]\n",
      "epoch:37 step:34747 [D loss: 0.257736, acc.: 51.56%] [G loss: 0.305842]\n",
      "epoch:37 step:34748 [D loss: 0.255933, acc.: 54.69%] [G loss: 0.276013]\n",
      "epoch:37 step:34749 [D loss: 0.245079, acc.: 53.12%] [G loss: 0.275197]\n",
      "epoch:37 step:34750 [D loss: 0.252830, acc.: 53.12%] [G loss: 0.253810]\n",
      "epoch:37 step:34751 [D loss: 0.243376, acc.: 58.59%] [G loss: 0.271689]\n",
      "epoch:37 step:34752 [D loss: 0.230545, acc.: 60.16%] [G loss: 0.336728]\n",
      "epoch:37 step:34753 [D loss: 0.244892, acc.: 57.03%] [G loss: 0.290523]\n",
      "epoch:37 step:34754 [D loss: 0.239507, acc.: 62.50%] [G loss: 0.324206]\n",
      "epoch:37 step:34755 [D loss: 0.229348, acc.: 60.94%] [G loss: 0.310240]\n",
      "epoch:37 step:34756 [D loss: 0.239418, acc.: 56.25%] [G loss: 0.331596]\n",
      "epoch:37 step:34757 [D loss: 0.250867, acc.: 53.12%] [G loss: 0.284033]\n",
      "epoch:37 step:34758 [D loss: 0.247643, acc.: 50.78%] [G loss: 0.279350]\n",
      "epoch:37 step:34759 [D loss: 0.237383, acc.: 57.81%] [G loss: 0.317417]\n",
      "epoch:37 step:34760 [D loss: 0.234249, acc.: 58.59%] [G loss: 0.315670]\n",
      "epoch:37 step:34761 [D loss: 0.249646, acc.: 51.56%] [G loss: 0.276924]\n",
      "epoch:37 step:34762 [D loss: 0.243417, acc.: 63.28%] [G loss: 0.307619]\n",
      "epoch:37 step:34763 [D loss: 0.251297, acc.: 57.03%] [G loss: 0.305641]\n",
      "epoch:37 step:34764 [D loss: 0.218882, acc.: 67.19%] [G loss: 0.326047]\n",
      "epoch:37 step:34765 [D loss: 0.256921, acc.: 53.12%] [G loss: 0.289647]\n",
      "epoch:37 step:34766 [D loss: 0.228834, acc.: 63.28%] [G loss: 0.296097]\n",
      "epoch:37 step:34767 [D loss: 0.232855, acc.: 64.06%] [G loss: 0.316964]\n",
      "epoch:37 step:34768 [D loss: 0.244237, acc.: 53.91%] [G loss: 0.302425]\n",
      "epoch:37 step:34769 [D loss: 0.249114, acc.: 57.03%] [G loss: 0.312997]\n",
      "epoch:37 step:34770 [D loss: 0.244168, acc.: 53.91%] [G loss: 0.283298]\n",
      "epoch:37 step:34771 [D loss: 0.241672, acc.: 54.69%] [G loss: 0.279655]\n",
      "epoch:37 step:34772 [D loss: 0.242740, acc.: 60.16%] [G loss: 0.298828]\n",
      "epoch:37 step:34773 [D loss: 0.241581, acc.: 58.59%] [G loss: 0.304147]\n",
      "epoch:37 step:34774 [D loss: 0.236895, acc.: 57.81%] [G loss: 0.330812]\n",
      "epoch:37 step:34775 [D loss: 0.239885, acc.: 57.81%] [G loss: 0.251419]\n",
      "epoch:37 step:34776 [D loss: 0.241224, acc.: 59.38%] [G loss: 0.296353]\n",
      "epoch:37 step:34777 [D loss: 0.211048, acc.: 69.53%] [G loss: 0.293837]\n",
      "epoch:37 step:34778 [D loss: 0.231002, acc.: 62.50%] [G loss: 0.278752]\n",
      "epoch:37 step:34779 [D loss: 0.228922, acc.: 57.03%] [G loss: 0.301118]\n",
      "epoch:37 step:34780 [D loss: 0.242890, acc.: 52.34%] [G loss: 0.300438]\n",
      "epoch:37 step:34781 [D loss: 0.234230, acc.: 57.81%] [G loss: 0.286205]\n",
      "epoch:37 step:34782 [D loss: 0.245516, acc.: 55.47%] [G loss: 0.279573]\n",
      "epoch:37 step:34783 [D loss: 0.222614, acc.: 63.28%] [G loss: 0.301232]\n",
      "epoch:37 step:34784 [D loss: 0.243494, acc.: 60.94%] [G loss: 0.258878]\n",
      "epoch:37 step:34785 [D loss: 0.228443, acc.: 60.16%] [G loss: 0.282634]\n",
      "epoch:37 step:34786 [D loss: 0.257831, acc.: 50.78%] [G loss: 0.301647]\n",
      "epoch:37 step:34787 [D loss: 0.243455, acc.: 55.47%] [G loss: 0.281141]\n",
      "epoch:37 step:34788 [D loss: 0.255204, acc.: 55.47%] [G loss: 0.309413]\n",
      "epoch:37 step:34789 [D loss: 0.225446, acc.: 62.50%] [G loss: 0.290732]\n",
      "epoch:37 step:34790 [D loss: 0.247967, acc.: 56.25%] [G loss: 0.305616]\n",
      "epoch:37 step:34791 [D loss: 0.235321, acc.: 60.94%] [G loss: 0.290393]\n",
      "epoch:37 step:34792 [D loss: 0.252365, acc.: 57.81%] [G loss: 0.289150]\n",
      "epoch:37 step:34793 [D loss: 0.240455, acc.: 58.59%] [G loss: 0.291031]\n",
      "epoch:37 step:34794 [D loss: 0.247919, acc.: 54.69%] [G loss: 0.304644]\n",
      "epoch:37 step:34795 [D loss: 0.238501, acc.: 58.59%] [G loss: 0.303270]\n",
      "epoch:37 step:34796 [D loss: 0.231934, acc.: 60.94%] [G loss: 0.277632]\n",
      "epoch:37 step:34797 [D loss: 0.229433, acc.: 64.84%] [G loss: 0.298600]\n",
      "epoch:37 step:34798 [D loss: 0.231611, acc.: 64.06%] [G loss: 0.303852]\n",
      "epoch:37 step:34799 [D loss: 0.229317, acc.: 65.62%] [G loss: 0.302805]\n",
      "epoch:37 step:34800 [D loss: 0.221601, acc.: 60.94%] [G loss: 0.280492]\n",
      "epoch:37 step:34801 [D loss: 0.241005, acc.: 57.03%] [G loss: 0.295362]\n",
      "epoch:37 step:34802 [D loss: 0.243535, acc.: 60.16%] [G loss: 0.294984]\n",
      "epoch:37 step:34803 [D loss: 0.222341, acc.: 68.75%] [G loss: 0.311682]\n",
      "epoch:37 step:34804 [D loss: 0.242824, acc.: 53.91%] [G loss: 0.278958]\n",
      "epoch:37 step:34805 [D loss: 0.238614, acc.: 57.81%] [G loss: 0.291866]\n",
      "epoch:37 step:34806 [D loss: 0.250903, acc.: 54.69%] [G loss: 0.293628]\n",
      "epoch:37 step:34807 [D loss: 0.235182, acc.: 59.38%] [G loss: 0.290024]\n",
      "epoch:37 step:34808 [D loss: 0.237443, acc.: 59.38%] [G loss: 0.309180]\n",
      "epoch:37 step:34809 [D loss: 0.242307, acc.: 60.16%] [G loss: 0.296724]\n",
      "epoch:37 step:34810 [D loss: 0.241222, acc.: 55.47%] [G loss: 0.303654]\n",
      "epoch:37 step:34811 [D loss: 0.240798, acc.: 57.03%] [G loss: 0.305749]\n",
      "epoch:37 step:34812 [D loss: 0.234916, acc.: 62.50%] [G loss: 0.295063]\n",
      "epoch:37 step:34813 [D loss: 0.237187, acc.: 59.38%] [G loss: 0.301900]\n",
      "epoch:37 step:34814 [D loss: 0.226097, acc.: 65.62%] [G loss: 0.312362]\n",
      "epoch:37 step:34815 [D loss: 0.234887, acc.: 60.94%] [G loss: 0.314400]\n",
      "epoch:37 step:34816 [D loss: 0.227624, acc.: 58.59%] [G loss: 0.288872]\n",
      "epoch:37 step:34817 [D loss: 0.245846, acc.: 60.16%] [G loss: 0.292820]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:37 step:34818 [D loss: 0.236096, acc.: 57.03%] [G loss: 0.288341]\n",
      "epoch:37 step:34819 [D loss: 0.228846, acc.: 59.38%] [G loss: 0.280339]\n",
      "epoch:37 step:34820 [D loss: 0.212820, acc.: 69.53%] [G loss: 0.317842]\n",
      "epoch:37 step:34821 [D loss: 0.243368, acc.: 60.16%] [G loss: 0.297646]\n",
      "epoch:37 step:34822 [D loss: 0.247619, acc.: 53.91%] [G loss: 0.301657]\n",
      "epoch:37 step:34823 [D loss: 0.245603, acc.: 58.59%] [G loss: 0.291959]\n",
      "epoch:37 step:34824 [D loss: 0.242157, acc.: 55.47%] [G loss: 0.292296]\n",
      "epoch:37 step:34825 [D loss: 0.225334, acc.: 64.06%] [G loss: 0.307351]\n",
      "epoch:37 step:34826 [D loss: 0.241169, acc.: 56.25%] [G loss: 0.297428]\n",
      "epoch:37 step:34827 [D loss: 0.224671, acc.: 64.06%] [G loss: 0.288275]\n",
      "epoch:37 step:34828 [D loss: 0.238205, acc.: 61.72%] [G loss: 0.276497]\n",
      "epoch:37 step:34829 [D loss: 0.244371, acc.: 57.81%] [G loss: 0.283490]\n",
      "epoch:37 step:34830 [D loss: 0.239747, acc.: 54.69%] [G loss: 0.287246]\n",
      "epoch:37 step:34831 [D loss: 0.252886, acc.: 51.56%] [G loss: 0.263183]\n",
      "epoch:37 step:34832 [D loss: 0.215460, acc.: 68.75%] [G loss: 0.318644]\n",
      "epoch:37 step:34833 [D loss: 0.218131, acc.: 60.94%] [G loss: 0.273972]\n",
      "epoch:37 step:34834 [D loss: 0.229390, acc.: 55.47%] [G loss: 0.284793]\n",
      "epoch:37 step:34835 [D loss: 0.267246, acc.: 43.75%] [G loss: 0.265162]\n",
      "epoch:37 step:34836 [D loss: 0.234871, acc.: 63.28%] [G loss: 0.324605]\n",
      "epoch:37 step:34837 [D loss: 0.233047, acc.: 57.81%] [G loss: 0.323027]\n",
      "epoch:37 step:34838 [D loss: 0.233196, acc.: 58.59%] [G loss: 0.296412]\n",
      "epoch:37 step:34839 [D loss: 0.235135, acc.: 60.16%] [G loss: 0.316437]\n",
      "epoch:37 step:34840 [D loss: 0.278281, acc.: 42.19%] [G loss: 0.295426]\n",
      "epoch:37 step:34841 [D loss: 0.247725, acc.: 49.22%] [G loss: 0.306726]\n",
      "epoch:37 step:34842 [D loss: 0.232900, acc.: 60.16%] [G loss: 0.294595]\n",
      "epoch:37 step:34843 [D loss: 0.224317, acc.: 61.72%] [G loss: 0.315962]\n",
      "epoch:37 step:34844 [D loss: 0.239882, acc.: 55.47%] [G loss: 0.309584]\n",
      "epoch:37 step:34845 [D loss: 0.229635, acc.: 63.28%] [G loss: 0.310051]\n",
      "epoch:37 step:34846 [D loss: 0.243347, acc.: 54.69%] [G loss: 0.305728]\n",
      "epoch:37 step:34847 [D loss: 0.237965, acc.: 58.59%] [G loss: 0.300888]\n",
      "epoch:37 step:34848 [D loss: 0.239087, acc.: 56.25%] [G loss: 0.277224]\n",
      "epoch:37 step:34849 [D loss: 0.244395, acc.: 57.81%] [G loss: 0.314611]\n",
      "epoch:37 step:34850 [D loss: 0.236342, acc.: 54.69%] [G loss: 0.295937]\n",
      "epoch:37 step:34851 [D loss: 0.226913, acc.: 60.94%] [G loss: 0.309707]\n",
      "epoch:37 step:34852 [D loss: 0.219007, acc.: 71.88%] [G loss: 0.295452]\n",
      "epoch:37 step:34853 [D loss: 0.258208, acc.: 50.00%] [G loss: 0.307191]\n",
      "epoch:37 step:34854 [D loss: 0.245734, acc.: 57.03%] [G loss: 0.324149]\n",
      "epoch:37 step:34855 [D loss: 0.253499, acc.: 50.78%] [G loss: 0.342434]\n",
      "epoch:37 step:34856 [D loss: 0.222315, acc.: 61.72%] [G loss: 0.328419]\n",
      "epoch:37 step:34857 [D loss: 0.236099, acc.: 60.16%] [G loss: 0.305645]\n",
      "epoch:37 step:34858 [D loss: 0.241661, acc.: 56.25%] [G loss: 0.329756]\n",
      "epoch:37 step:34859 [D loss: 0.253547, acc.: 52.34%] [G loss: 0.299055]\n",
      "epoch:37 step:34860 [D loss: 0.235933, acc.: 58.59%] [G loss: 0.338218]\n",
      "epoch:37 step:34861 [D loss: 0.247324, acc.: 57.03%] [G loss: 0.281042]\n",
      "epoch:37 step:34862 [D loss: 0.226109, acc.: 62.50%] [G loss: 0.286855]\n",
      "epoch:37 step:34863 [D loss: 0.236500, acc.: 57.81%] [G loss: 0.312490]\n",
      "epoch:37 step:34864 [D loss: 0.241370, acc.: 58.59%] [G loss: 0.302045]\n",
      "epoch:37 step:34865 [D loss: 0.239313, acc.: 56.25%] [G loss: 0.282718]\n",
      "epoch:37 step:34866 [D loss: 0.243293, acc.: 57.81%] [G loss: 0.313506]\n",
      "epoch:37 step:34867 [D loss: 0.248780, acc.: 53.12%] [G loss: 0.299001]\n",
      "epoch:37 step:34868 [D loss: 0.239807, acc.: 59.38%] [G loss: 0.289210]\n",
      "epoch:37 step:34869 [D loss: 0.247229, acc.: 52.34%] [G loss: 0.294821]\n",
      "epoch:37 step:34870 [D loss: 0.239527, acc.: 57.81%] [G loss: 0.280083]\n",
      "epoch:37 step:34871 [D loss: 0.231330, acc.: 60.94%] [G loss: 0.274022]\n",
      "epoch:37 step:34872 [D loss: 0.226969, acc.: 64.06%] [G loss: 0.296950]\n",
      "epoch:37 step:34873 [D loss: 0.235633, acc.: 57.81%] [G loss: 0.299556]\n",
      "epoch:37 step:34874 [D loss: 0.234764, acc.: 60.16%] [G loss: 0.301483]\n",
      "epoch:37 step:34875 [D loss: 0.237842, acc.: 59.38%] [G loss: 0.320441]\n",
      "epoch:37 step:34876 [D loss: 0.255313, acc.: 49.22%] [G loss: 0.303518]\n",
      "epoch:37 step:34877 [D loss: 0.255778, acc.: 51.56%] [G loss: 0.272968]\n",
      "epoch:37 step:34878 [D loss: 0.226635, acc.: 68.75%] [G loss: 0.315539]\n",
      "epoch:37 step:34879 [D loss: 0.234673, acc.: 58.59%] [G loss: 0.289066]\n",
      "epoch:37 step:34880 [D loss: 0.234637, acc.: 60.16%] [G loss: 0.309501]\n",
      "epoch:37 step:34881 [D loss: 0.237219, acc.: 57.81%] [G loss: 0.328071]\n",
      "epoch:37 step:34882 [D loss: 0.234948, acc.: 61.72%] [G loss: 0.298201]\n",
      "epoch:37 step:34883 [D loss: 0.236785, acc.: 58.59%] [G loss: 0.332660]\n",
      "epoch:37 step:34884 [D loss: 0.241485, acc.: 60.16%] [G loss: 0.283396]\n",
      "epoch:37 step:34885 [D loss: 0.240079, acc.: 60.94%] [G loss: 0.299907]\n",
      "epoch:37 step:34886 [D loss: 0.219246, acc.: 64.84%] [G loss: 0.278547]\n",
      "epoch:37 step:34887 [D loss: 0.227410, acc.: 60.94%] [G loss: 0.298433]\n",
      "epoch:37 step:34888 [D loss: 0.229622, acc.: 60.94%] [G loss: 0.305990]\n",
      "epoch:37 step:34889 [D loss: 0.239431, acc.: 60.16%] [G loss: 0.297045]\n",
      "epoch:37 step:34890 [D loss: 0.248588, acc.: 57.81%] [G loss: 0.297023]\n",
      "epoch:37 step:34891 [D loss: 0.256596, acc.: 56.25%] [G loss: 0.287949]\n",
      "epoch:37 step:34892 [D loss: 0.237028, acc.: 61.72%] [G loss: 0.296974]\n",
      "epoch:37 step:34893 [D loss: 0.251741, acc.: 50.78%] [G loss: 0.287808]\n",
      "epoch:37 step:34894 [D loss: 0.260625, acc.: 53.12%] [G loss: 0.281103]\n",
      "epoch:37 step:34895 [D loss: 0.242325, acc.: 50.78%] [G loss: 0.339468]\n",
      "epoch:37 step:34896 [D loss: 0.225921, acc.: 60.94%] [G loss: 0.303613]\n",
      "epoch:37 step:34897 [D loss: 0.237434, acc.: 64.06%] [G loss: 0.309232]\n",
      "epoch:37 step:34898 [D loss: 0.219443, acc.: 65.62%] [G loss: 0.296594]\n",
      "epoch:37 step:34899 [D loss: 0.239852, acc.: 61.72%] [G loss: 0.287494]\n",
      "epoch:37 step:34900 [D loss: 0.238252, acc.: 58.59%] [G loss: 0.303574]\n",
      "epoch:37 step:34901 [D loss: 0.246590, acc.: 53.12%] [G loss: 0.304305]\n",
      "epoch:37 step:34902 [D loss: 0.245570, acc.: 54.69%] [G loss: 0.285282]\n",
      "epoch:37 step:34903 [D loss: 0.245309, acc.: 60.16%] [G loss: 0.271933]\n",
      "epoch:37 step:34904 [D loss: 0.242230, acc.: 53.91%] [G loss: 0.265710]\n",
      "epoch:37 step:34905 [D loss: 0.235457, acc.: 61.72%] [G loss: 0.309584]\n",
      "epoch:37 step:34906 [D loss: 0.248114, acc.: 53.12%] [G loss: 0.293153]\n",
      "epoch:37 step:34907 [D loss: 0.255118, acc.: 52.34%] [G loss: 0.324290]\n",
      "epoch:37 step:34908 [D loss: 0.256521, acc.: 51.56%] [G loss: 0.317418]\n",
      "epoch:37 step:34909 [D loss: 0.252028, acc.: 50.78%] [G loss: 0.309749]\n",
      "epoch:37 step:34910 [D loss: 0.237194, acc.: 56.25%] [G loss: 0.306324]\n",
      "epoch:37 step:34911 [D loss: 0.259781, acc.: 49.22%] [G loss: 0.279902]\n",
      "epoch:37 step:34912 [D loss: 0.250471, acc.: 49.22%] [G loss: 0.291216]\n",
      "epoch:37 step:34913 [D loss: 0.234913, acc.: 57.81%] [G loss: 0.289518]\n",
      "epoch:37 step:34914 [D loss: 0.233752, acc.: 59.38%] [G loss: 0.290985]\n",
      "epoch:37 step:34915 [D loss: 0.214998, acc.: 67.97%] [G loss: 0.310484]\n",
      "epoch:37 step:34916 [D loss: 0.256811, acc.: 55.47%] [G loss: 0.297569]\n",
      "epoch:37 step:34917 [D loss: 0.254863, acc.: 47.66%] [G loss: 0.281954]\n",
      "epoch:37 step:34918 [D loss: 0.248232, acc.: 50.78%] [G loss: 0.306079]\n",
      "epoch:37 step:34919 [D loss: 0.237363, acc.: 60.16%] [G loss: 0.305848]\n",
      "epoch:37 step:34920 [D loss: 0.242246, acc.: 57.81%] [G loss: 0.312919]\n",
      "epoch:37 step:34921 [D loss: 0.232094, acc.: 58.59%] [G loss: 0.304703]\n",
      "epoch:37 step:34922 [D loss: 0.244458, acc.: 55.47%] [G loss: 0.294653]\n",
      "epoch:37 step:34923 [D loss: 0.237802, acc.: 64.84%] [G loss: 0.295644]\n",
      "epoch:37 step:34924 [D loss: 0.239869, acc.: 62.50%] [G loss: 0.316058]\n",
      "epoch:37 step:34925 [D loss: 0.243211, acc.: 57.03%] [G loss: 0.291183]\n",
      "epoch:37 step:34926 [D loss: 0.247806, acc.: 56.25%] [G loss: 0.306015]\n",
      "epoch:37 step:34927 [D loss: 0.223628, acc.: 64.84%] [G loss: 0.282251]\n",
      "epoch:37 step:34928 [D loss: 0.266808, acc.: 42.19%] [G loss: 0.295095]\n",
      "epoch:37 step:34929 [D loss: 0.249116, acc.: 54.69%] [G loss: 0.291274]\n",
      "epoch:37 step:34930 [D loss: 0.227597, acc.: 63.28%] [G loss: 0.295719]\n",
      "epoch:37 step:34931 [D loss: 0.244030, acc.: 57.03%] [G loss: 0.313136]\n",
      "epoch:37 step:34932 [D loss: 0.268002, acc.: 52.34%] [G loss: 0.318057]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:37 step:34933 [D loss: 0.219355, acc.: 64.06%] [G loss: 0.272311]\n",
      "epoch:37 step:34934 [D loss: 0.227665, acc.: 66.41%] [G loss: 0.286635]\n",
      "epoch:37 step:34935 [D loss: 0.228953, acc.: 55.47%] [G loss: 0.276596]\n",
      "epoch:37 step:34936 [D loss: 0.228292, acc.: 60.16%] [G loss: 0.308550]\n",
      "epoch:37 step:34937 [D loss: 0.229734, acc.: 65.62%] [G loss: 0.306272]\n",
      "epoch:37 step:34938 [D loss: 0.236594, acc.: 58.59%] [G loss: 0.299546]\n",
      "epoch:37 step:34939 [D loss: 0.226176, acc.: 63.28%] [G loss: 0.309736]\n",
      "epoch:37 step:34940 [D loss: 0.245315, acc.: 58.59%] [G loss: 0.343638]\n",
      "epoch:37 step:34941 [D loss: 0.230676, acc.: 57.81%] [G loss: 0.340504]\n",
      "epoch:37 step:34942 [D loss: 0.249351, acc.: 60.16%] [G loss: 0.285470]\n",
      "epoch:37 step:34943 [D loss: 0.256238, acc.: 54.69%] [G loss: 0.289361]\n",
      "epoch:37 step:34944 [D loss: 0.241819, acc.: 57.03%] [G loss: 0.281692]\n",
      "epoch:37 step:34945 [D loss: 0.233294, acc.: 60.94%] [G loss: 0.333260]\n",
      "epoch:37 step:34946 [D loss: 0.252786, acc.: 52.34%] [G loss: 0.308736]\n",
      "epoch:37 step:34947 [D loss: 0.262047, acc.: 46.88%] [G loss: 0.278498]\n",
      "epoch:37 step:34948 [D loss: 0.238716, acc.: 57.03%] [G loss: 0.290082]\n",
      "epoch:37 step:34949 [D loss: 0.223227, acc.: 67.19%] [G loss: 0.330930]\n",
      "epoch:37 step:34950 [D loss: 0.251906, acc.: 53.91%] [G loss: 0.283390]\n",
      "epoch:37 step:34951 [D loss: 0.246810, acc.: 57.81%] [G loss: 0.304508]\n",
      "epoch:37 step:34952 [D loss: 0.233314, acc.: 57.81%] [G loss: 0.317681]\n",
      "epoch:37 step:34953 [D loss: 0.224971, acc.: 63.28%] [G loss: 0.277933]\n",
      "epoch:37 step:34954 [D loss: 0.236771, acc.: 58.59%] [G loss: 0.290408]\n",
      "epoch:37 step:34955 [D loss: 0.241262, acc.: 57.03%] [G loss: 0.282890]\n",
      "epoch:37 step:34956 [D loss: 0.233994, acc.: 62.50%] [G loss: 0.314233]\n",
      "epoch:37 step:34957 [D loss: 0.239172, acc.: 57.03%] [G loss: 0.306692]\n",
      "epoch:37 step:34958 [D loss: 0.245786, acc.: 61.72%] [G loss: 0.293438]\n",
      "epoch:37 step:34959 [D loss: 0.224191, acc.: 64.84%] [G loss: 0.339443]\n",
      "epoch:37 step:34960 [D loss: 0.258206, acc.: 52.34%] [G loss: 0.294677]\n",
      "epoch:37 step:34961 [D loss: 0.229629, acc.: 64.84%] [G loss: 0.283357]\n",
      "epoch:37 step:34962 [D loss: 0.241995, acc.: 54.69%] [G loss: 0.302793]\n",
      "epoch:37 step:34963 [D loss: 0.236740, acc.: 57.03%] [G loss: 0.292508]\n",
      "epoch:37 step:34964 [D loss: 0.246433, acc.: 56.25%] [G loss: 0.301126]\n",
      "epoch:37 step:34965 [D loss: 0.236121, acc.: 60.16%] [G loss: 0.287682]\n",
      "epoch:37 step:34966 [D loss: 0.236022, acc.: 64.06%] [G loss: 0.301820]\n",
      "epoch:37 step:34967 [D loss: 0.247173, acc.: 57.81%] [G loss: 0.279832]\n",
      "epoch:37 step:34968 [D loss: 0.236016, acc.: 61.72%] [G loss: 0.320623]\n",
      "epoch:37 step:34969 [D loss: 0.238958, acc.: 54.69%] [G loss: 0.289335]\n",
      "epoch:37 step:34970 [D loss: 0.228875, acc.: 64.84%] [G loss: 0.290321]\n",
      "epoch:37 step:34971 [D loss: 0.255590, acc.: 55.47%] [G loss: 0.265212]\n",
      "epoch:37 step:34972 [D loss: 0.245242, acc.: 57.81%] [G loss: 0.291437]\n",
      "epoch:37 step:34973 [D loss: 0.241897, acc.: 53.12%] [G loss: 0.315445]\n",
      "epoch:37 step:34974 [D loss: 0.229603, acc.: 62.50%] [G loss: 0.285770]\n",
      "epoch:37 step:34975 [D loss: 0.259882, acc.: 52.34%] [G loss: 0.314179]\n",
      "epoch:37 step:34976 [D loss: 0.260918, acc.: 46.09%] [G loss: 0.291138]\n",
      "epoch:37 step:34977 [D loss: 0.241337, acc.: 58.59%] [G loss: 0.292039]\n",
      "epoch:37 step:34978 [D loss: 0.244973, acc.: 53.12%] [G loss: 0.305930]\n",
      "epoch:37 step:34979 [D loss: 0.242073, acc.: 59.38%] [G loss: 0.281882]\n",
      "epoch:37 step:34980 [D loss: 0.218878, acc.: 66.41%] [G loss: 0.287281]\n",
      "epoch:37 step:34981 [D loss: 0.263298, acc.: 45.31%] [G loss: 0.290356]\n",
      "epoch:37 step:34982 [D loss: 0.242772, acc.: 59.38%] [G loss: 0.307069]\n",
      "epoch:37 step:34983 [D loss: 0.239130, acc.: 56.25%] [G loss: 0.308856]\n",
      "epoch:37 step:34984 [D loss: 0.233482, acc.: 61.72%] [G loss: 0.289544]\n",
      "epoch:37 step:34985 [D loss: 0.246980, acc.: 54.69%] [G loss: 0.288370]\n",
      "epoch:37 step:34986 [D loss: 0.238779, acc.: 60.16%] [G loss: 0.287322]\n",
      "epoch:37 step:34987 [D loss: 0.237595, acc.: 60.94%] [G loss: 0.265045]\n",
      "epoch:37 step:34988 [D loss: 0.256104, acc.: 49.22%] [G loss: 0.281781]\n",
      "epoch:37 step:34989 [D loss: 0.230853, acc.: 58.59%] [G loss: 0.329747]\n",
      "epoch:37 step:34990 [D loss: 0.264939, acc.: 47.66%] [G loss: 0.278095]\n",
      "epoch:37 step:34991 [D loss: 0.232260, acc.: 63.28%] [G loss: 0.273441]\n",
      "epoch:37 step:34992 [D loss: 0.234314, acc.: 60.94%] [G loss: 0.310211]\n",
      "epoch:37 step:34993 [D loss: 0.238717, acc.: 60.16%] [G loss: 0.292305]\n",
      "epoch:37 step:34994 [D loss: 0.236744, acc.: 54.69%] [G loss: 0.288109]\n",
      "epoch:37 step:34995 [D loss: 0.229097, acc.: 65.62%] [G loss: 0.300510]\n",
      "epoch:37 step:34996 [D loss: 0.231556, acc.: 61.72%] [G loss: 0.300317]\n",
      "epoch:37 step:34997 [D loss: 0.240470, acc.: 56.25%] [G loss: 0.296278]\n",
      "epoch:37 step:34998 [D loss: 0.250646, acc.: 58.59%] [G loss: 0.302096]\n",
      "epoch:37 step:34999 [D loss: 0.238773, acc.: 58.59%] [G loss: 0.282945]\n",
      "epoch:37 step:35000 [D loss: 0.232652, acc.: 58.59%] [G loss: 0.288792]\n",
      "epoch:37 step:35001 [D loss: 0.250619, acc.: 56.25%] [G loss: 0.302301]\n",
      "epoch:37 step:35002 [D loss: 0.244087, acc.: 53.12%] [G loss: 0.298581]\n",
      "epoch:37 step:35003 [D loss: 0.224070, acc.: 66.41%] [G loss: 0.320908]\n",
      "epoch:37 step:35004 [D loss: 0.227050, acc.: 71.09%] [G loss: 0.296693]\n",
      "epoch:37 step:35005 [D loss: 0.220344, acc.: 67.97%] [G loss: 0.267459]\n",
      "epoch:37 step:35006 [D loss: 0.249539, acc.: 55.47%] [G loss: 0.300164]\n",
      "epoch:37 step:35007 [D loss: 0.237391, acc.: 57.81%] [G loss: 0.285808]\n",
      "epoch:37 step:35008 [D loss: 0.236614, acc.: 58.59%] [G loss: 0.304326]\n",
      "epoch:37 step:35009 [D loss: 0.232079, acc.: 63.28%] [G loss: 0.298404]\n",
      "epoch:37 step:35010 [D loss: 0.243470, acc.: 57.81%] [G loss: 0.281583]\n",
      "epoch:37 step:35011 [D loss: 0.239383, acc.: 60.16%] [G loss: 0.319072]\n",
      "epoch:37 step:35012 [D loss: 0.247509, acc.: 51.56%] [G loss: 0.312720]\n",
      "epoch:37 step:35013 [D loss: 0.235453, acc.: 60.16%] [G loss: 0.300216]\n",
      "epoch:37 step:35014 [D loss: 0.247637, acc.: 57.03%] [G loss: 0.295337]\n",
      "epoch:37 step:35015 [D loss: 0.246100, acc.: 53.12%] [G loss: 0.271324]\n",
      "epoch:37 step:35016 [D loss: 0.252756, acc.: 54.69%] [G loss: 0.309346]\n",
      "epoch:37 step:35017 [D loss: 0.241400, acc.: 58.59%] [G loss: 0.299631]\n",
      "epoch:37 step:35018 [D loss: 0.224013, acc.: 60.16%] [G loss: 0.312603]\n",
      "epoch:37 step:35019 [D loss: 0.238606, acc.: 53.12%] [G loss: 0.313499]\n",
      "epoch:37 step:35020 [D loss: 0.228110, acc.: 63.28%] [G loss: 0.286104]\n",
      "epoch:37 step:35021 [D loss: 0.247901, acc.: 59.38%] [G loss: 0.291252]\n",
      "epoch:37 step:35022 [D loss: 0.262490, acc.: 56.25%] [G loss: 0.303513]\n",
      "epoch:37 step:35023 [D loss: 0.239599, acc.: 57.81%] [G loss: 0.298837]\n",
      "epoch:37 step:35024 [D loss: 0.229983, acc.: 61.72%] [G loss: 0.300602]\n",
      "epoch:37 step:35025 [D loss: 0.225659, acc.: 61.72%] [G loss: 0.306564]\n",
      "epoch:37 step:35026 [D loss: 0.248390, acc.: 51.56%] [G loss: 0.311123]\n",
      "epoch:37 step:35027 [D loss: 0.234421, acc.: 64.84%] [G loss: 0.280846]\n",
      "epoch:37 step:35028 [D loss: 0.238861, acc.: 58.59%] [G loss: 0.301055]\n",
      "epoch:37 step:35029 [D loss: 0.247780, acc.: 62.50%] [G loss: 0.282728]\n",
      "epoch:37 step:35030 [D loss: 0.230395, acc.: 65.62%] [G loss: 0.298919]\n",
      "epoch:37 step:35031 [D loss: 0.231911, acc.: 57.03%] [G loss: 0.301508]\n",
      "epoch:37 step:35032 [D loss: 0.217260, acc.: 63.28%] [G loss: 0.301178]\n",
      "epoch:37 step:35033 [D loss: 0.234672, acc.: 56.25%] [G loss: 0.292300]\n",
      "epoch:37 step:35034 [D loss: 0.237227, acc.: 59.38%] [G loss: 0.266935]\n",
      "epoch:37 step:35035 [D loss: 0.243105, acc.: 55.47%] [G loss: 0.280807]\n",
      "epoch:37 step:35036 [D loss: 0.244072, acc.: 60.16%] [G loss: 0.300120]\n",
      "epoch:37 step:35037 [D loss: 0.252652, acc.: 53.91%] [G loss: 0.289294]\n",
      "epoch:37 step:35038 [D loss: 0.231462, acc.: 64.06%] [G loss: 0.302124]\n",
      "epoch:37 step:35039 [D loss: 0.253125, acc.: 50.00%] [G loss: 0.310670]\n",
      "epoch:37 step:35040 [D loss: 0.250280, acc.: 55.47%] [G loss: 0.292584]\n",
      "epoch:37 step:35041 [D loss: 0.232515, acc.: 57.03%] [G loss: 0.323158]\n",
      "epoch:37 step:35042 [D loss: 0.236951, acc.: 59.38%] [G loss: 0.314410]\n",
      "epoch:37 step:35043 [D loss: 0.255219, acc.: 56.25%] [G loss: 0.308422]\n",
      "epoch:37 step:35044 [D loss: 0.242583, acc.: 62.50%] [G loss: 0.269703]\n",
      "epoch:37 step:35045 [D loss: 0.237790, acc.: 57.81%] [G loss: 0.309831]\n",
      "epoch:37 step:35046 [D loss: 0.235130, acc.: 61.72%] [G loss: 0.260987]\n",
      "epoch:37 step:35047 [D loss: 0.224148, acc.: 67.19%] [G loss: 0.317198]\n",
      "epoch:37 step:35048 [D loss: 0.249249, acc.: 59.38%] [G loss: 0.251503]\n",
      "epoch:37 step:35049 [D loss: 0.235578, acc.: 60.16%] [G loss: 0.309585]\n",
      "epoch:37 step:35050 [D loss: 0.253465, acc.: 53.91%] [G loss: 0.312321]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:37 step:35051 [D loss: 0.237246, acc.: 60.16%] [G loss: 0.299487]\n",
      "epoch:37 step:35052 [D loss: 0.236230, acc.: 57.81%] [G loss: 0.315876]\n",
      "epoch:37 step:35053 [D loss: 0.247691, acc.: 53.12%] [G loss: 0.292275]\n",
      "epoch:37 step:35054 [D loss: 0.233977, acc.: 61.72%] [G loss: 0.299811]\n",
      "epoch:37 step:35055 [D loss: 0.247021, acc.: 55.47%] [G loss: 0.282480]\n",
      "epoch:37 step:35056 [D loss: 0.234033, acc.: 60.94%] [G loss: 0.303340]\n",
      "epoch:37 step:35057 [D loss: 0.233693, acc.: 60.16%] [G loss: 0.276178]\n",
      "epoch:37 step:35058 [D loss: 0.235945, acc.: 63.28%] [G loss: 0.311079]\n",
      "epoch:37 step:35059 [D loss: 0.262439, acc.: 51.56%] [G loss: 0.291130]\n",
      "epoch:37 step:35060 [D loss: 0.235189, acc.: 59.38%] [G loss: 0.297534]\n",
      "epoch:37 step:35061 [D loss: 0.250042, acc.: 50.00%] [G loss: 0.307081]\n",
      "epoch:37 step:35062 [D loss: 0.242698, acc.: 57.03%] [G loss: 0.260593]\n",
      "epoch:37 step:35063 [D loss: 0.231608, acc.: 60.16%] [G loss: 0.296317]\n",
      "epoch:37 step:35064 [D loss: 0.245467, acc.: 55.47%] [G loss: 0.296121]\n",
      "epoch:37 step:35065 [D loss: 0.241579, acc.: 60.94%] [G loss: 0.320943]\n",
      "epoch:37 step:35066 [D loss: 0.236379, acc.: 58.59%] [G loss: 0.311495]\n",
      "epoch:37 step:35067 [D loss: 0.227984, acc.: 60.94%] [G loss: 0.307679]\n",
      "epoch:37 step:35068 [D loss: 0.233392, acc.: 57.03%] [G loss: 0.311490]\n",
      "epoch:37 step:35069 [D loss: 0.220395, acc.: 64.06%] [G loss: 0.299751]\n",
      "epoch:37 step:35070 [D loss: 0.228439, acc.: 65.62%] [G loss: 0.307803]\n",
      "epoch:37 step:35071 [D loss: 0.224880, acc.: 66.41%] [G loss: 0.244274]\n",
      "epoch:37 step:35072 [D loss: 0.228120, acc.: 61.72%] [G loss: 0.311761]\n",
      "epoch:37 step:35073 [D loss: 0.240459, acc.: 57.81%] [G loss: 0.338585]\n",
      "epoch:37 step:35074 [D loss: 0.242100, acc.: 57.81%] [G loss: 0.290238]\n",
      "epoch:37 step:35075 [D loss: 0.227470, acc.: 60.94%] [G loss: 0.290979]\n",
      "epoch:37 step:35076 [D loss: 0.252398, acc.: 53.12%] [G loss: 0.275347]\n",
      "epoch:37 step:35077 [D loss: 0.226678, acc.: 65.62%] [G loss: 0.303172]\n",
      "epoch:37 step:35078 [D loss: 0.248459, acc.: 56.25%] [G loss: 0.294792]\n",
      "epoch:37 step:35079 [D loss: 0.236971, acc.: 57.03%] [G loss: 0.291128]\n",
      "epoch:37 step:35080 [D loss: 0.261862, acc.: 49.22%] [G loss: 0.308675]\n",
      "epoch:37 step:35081 [D loss: 0.234733, acc.: 57.03%] [G loss: 0.285793]\n",
      "epoch:37 step:35082 [D loss: 0.243933, acc.: 54.69%] [G loss: 0.318542]\n",
      "epoch:37 step:35083 [D loss: 0.241605, acc.: 60.94%] [G loss: 0.291782]\n",
      "epoch:37 step:35084 [D loss: 0.247208, acc.: 57.03%] [G loss: 0.303698]\n",
      "epoch:37 step:35085 [D loss: 0.243636, acc.: 57.81%] [G loss: 0.297786]\n",
      "epoch:37 step:35086 [D loss: 0.239664, acc.: 57.81%] [G loss: 0.306481]\n",
      "epoch:37 step:35087 [D loss: 0.250664, acc.: 52.34%] [G loss: 0.315035]\n",
      "epoch:37 step:35088 [D loss: 0.257773, acc.: 50.78%] [G loss: 0.300431]\n",
      "epoch:37 step:35089 [D loss: 0.226702, acc.: 63.28%] [G loss: 0.309305]\n",
      "epoch:37 step:35090 [D loss: 0.241588, acc.: 60.94%] [G loss: 0.305197]\n",
      "epoch:37 step:35091 [D loss: 0.219204, acc.: 63.28%] [G loss: 0.284967]\n",
      "epoch:37 step:35092 [D loss: 0.258584, acc.: 52.34%] [G loss: 0.277419]\n",
      "epoch:37 step:35093 [D loss: 0.250941, acc.: 52.34%] [G loss: 0.302936]\n",
      "epoch:37 step:35094 [D loss: 0.242982, acc.: 54.69%] [G loss: 0.291138]\n",
      "epoch:37 step:35095 [D loss: 0.249274, acc.: 55.47%] [G loss: 0.311834]\n",
      "epoch:37 step:35096 [D loss: 0.236636, acc.: 60.16%] [G loss: 0.302556]\n",
      "epoch:37 step:35097 [D loss: 0.244303, acc.: 60.16%] [G loss: 0.285531]\n",
      "epoch:37 step:35098 [D loss: 0.248054, acc.: 53.12%] [G loss: 0.288470]\n",
      "epoch:37 step:35099 [D loss: 0.258565, acc.: 53.12%] [G loss: 0.295811]\n",
      "epoch:37 step:35100 [D loss: 0.249015, acc.: 56.25%] [G loss: 0.274037]\n",
      "epoch:37 step:35101 [D loss: 0.245639, acc.: 54.69%] [G loss: 0.328363]\n",
      "epoch:37 step:35102 [D loss: 0.229799, acc.: 64.06%] [G loss: 0.303103]\n",
      "epoch:37 step:35103 [D loss: 0.233762, acc.: 59.38%] [G loss: 0.287200]\n",
      "epoch:37 step:35104 [D loss: 0.235775, acc.: 60.16%] [G loss: 0.289531]\n",
      "epoch:37 step:35105 [D loss: 0.227493, acc.: 60.94%] [G loss: 0.308337]\n",
      "epoch:37 step:35106 [D loss: 0.240034, acc.: 58.59%] [G loss: 0.297830]\n",
      "epoch:37 step:35107 [D loss: 0.239085, acc.: 59.38%] [G loss: 0.305384]\n",
      "epoch:37 step:35108 [D loss: 0.225188, acc.: 61.72%] [G loss: 0.322145]\n",
      "epoch:37 step:35109 [D loss: 0.220676, acc.: 64.06%] [G loss: 0.294348]\n",
      "epoch:37 step:35110 [D loss: 0.223146, acc.: 64.06%] [G loss: 0.303144]\n",
      "epoch:37 step:35111 [D loss: 0.259139, acc.: 52.34%] [G loss: 0.308592]\n",
      "epoch:37 step:35112 [D loss: 0.249533, acc.: 52.34%] [G loss: 0.304620]\n",
      "epoch:37 step:35113 [D loss: 0.245746, acc.: 56.25%] [G loss: 0.312218]\n",
      "epoch:37 step:35114 [D loss: 0.221584, acc.: 64.06%] [G loss: 0.330516]\n",
      "epoch:37 step:35115 [D loss: 0.247466, acc.: 49.22%] [G loss: 0.302177]\n",
      "epoch:37 step:35116 [D loss: 0.242286, acc.: 60.16%] [G loss: 0.304830]\n",
      "epoch:37 step:35117 [D loss: 0.247898, acc.: 55.47%] [G loss: 0.303716]\n",
      "epoch:37 step:35118 [D loss: 0.253439, acc.: 50.78%] [G loss: 0.315370]\n",
      "epoch:37 step:35119 [D loss: 0.252826, acc.: 56.25%] [G loss: 0.291435]\n",
      "epoch:37 step:35120 [D loss: 0.201389, acc.: 73.44%] [G loss: 0.316581]\n",
      "epoch:37 step:35121 [D loss: 0.273642, acc.: 44.53%] [G loss: 0.296974]\n",
      "epoch:37 step:35122 [D loss: 0.212652, acc.: 68.75%] [G loss: 0.284110]\n",
      "epoch:37 step:35123 [D loss: 0.248947, acc.: 52.34%] [G loss: 0.278888]\n",
      "epoch:37 step:35124 [D loss: 0.243640, acc.: 61.72%] [G loss: 0.304073]\n",
      "epoch:37 step:35125 [D loss: 0.276347, acc.: 45.31%] [G loss: 0.283116]\n",
      "epoch:37 step:35126 [D loss: 0.240851, acc.: 53.91%] [G loss: 0.289570]\n",
      "epoch:37 step:35127 [D loss: 0.228599, acc.: 61.72%] [G loss: 0.299868]\n",
      "epoch:37 step:35128 [D loss: 0.243692, acc.: 60.94%] [G loss: 0.282396]\n",
      "epoch:37 step:35129 [D loss: 0.249451, acc.: 55.47%] [G loss: 0.269376]\n",
      "epoch:37 step:35130 [D loss: 0.244529, acc.: 57.81%] [G loss: 0.276288]\n",
      "epoch:37 step:35131 [D loss: 0.235702, acc.: 56.25%] [G loss: 0.290884]\n",
      "epoch:37 step:35132 [D loss: 0.241997, acc.: 58.59%] [G loss: 0.278355]\n",
      "epoch:37 step:35133 [D loss: 0.218515, acc.: 62.50%] [G loss: 0.295616]\n",
      "epoch:37 step:35134 [D loss: 0.255271, acc.: 55.47%] [G loss: 0.302044]\n",
      "epoch:37 step:35135 [D loss: 0.261656, acc.: 48.44%] [G loss: 0.297780]\n",
      "epoch:37 step:35136 [D loss: 0.247190, acc.: 60.94%] [G loss: 0.247016]\n",
      "epoch:37 step:35137 [D loss: 0.237878, acc.: 61.72%] [G loss: 0.305097]\n",
      "epoch:37 step:35138 [D loss: 0.234514, acc.: 63.28%] [G loss: 0.276746]\n",
      "epoch:37 step:35139 [D loss: 0.249264, acc.: 57.03%] [G loss: 0.262311]\n",
      "epoch:37 step:35140 [D loss: 0.229506, acc.: 60.94%] [G loss: 0.267107]\n",
      "epoch:37 step:35141 [D loss: 0.240408, acc.: 58.59%] [G loss: 0.303921]\n",
      "epoch:37 step:35142 [D loss: 0.232503, acc.: 61.72%] [G loss: 0.300746]\n",
      "epoch:37 step:35143 [D loss: 0.234884, acc.: 60.16%] [G loss: 0.305797]\n",
      "epoch:37 step:35144 [D loss: 0.226344, acc.: 61.72%] [G loss: 0.298976]\n",
      "epoch:37 step:35145 [D loss: 0.250948, acc.: 48.44%] [G loss: 0.301091]\n",
      "epoch:37 step:35146 [D loss: 0.227495, acc.: 61.72%] [G loss: 0.290954]\n",
      "epoch:37 step:35147 [D loss: 0.224886, acc.: 63.28%] [G loss: 0.283913]\n",
      "epoch:37 step:35148 [D loss: 0.247557, acc.: 57.03%] [G loss: 0.276704]\n",
      "epoch:37 step:35149 [D loss: 0.242350, acc.: 54.69%] [G loss: 0.283768]\n",
      "epoch:37 step:35150 [D loss: 0.239549, acc.: 53.91%] [G loss: 0.334060]\n",
      "epoch:37 step:35151 [D loss: 0.221464, acc.: 64.84%] [G loss: 0.295075]\n",
      "epoch:37 step:35152 [D loss: 0.233490, acc.: 64.06%] [G loss: 0.278610]\n",
      "epoch:37 step:35153 [D loss: 0.226964, acc.: 58.59%] [G loss: 0.261282]\n",
      "epoch:37 step:35154 [D loss: 0.245061, acc.: 58.59%] [G loss: 0.285472]\n",
      "epoch:37 step:35155 [D loss: 0.231855, acc.: 58.59%] [G loss: 0.306022]\n",
      "epoch:37 step:35156 [D loss: 0.221165, acc.: 67.19%] [G loss: 0.294901]\n",
      "epoch:37 step:35157 [D loss: 0.226661, acc.: 64.06%] [G loss: 0.295384]\n",
      "epoch:37 step:35158 [D loss: 0.221648, acc.: 67.19%] [G loss: 0.306684]\n",
      "epoch:37 step:35159 [D loss: 0.242885, acc.: 57.81%] [G loss: 0.279446]\n",
      "epoch:37 step:35160 [D loss: 0.241718, acc.: 52.34%] [G loss: 0.283738]\n",
      "epoch:37 step:35161 [D loss: 0.236444, acc.: 65.62%] [G loss: 0.278029]\n",
      "epoch:37 step:35162 [D loss: 0.228812, acc.: 63.28%] [G loss: 0.302215]\n",
      "epoch:37 step:35163 [D loss: 0.232604, acc.: 64.06%] [G loss: 0.307455]\n",
      "epoch:37 step:35164 [D loss: 0.245478, acc.: 58.59%] [G loss: 0.277761]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:37 step:35165 [D loss: 0.240393, acc.: 54.69%] [G loss: 0.280097]\n",
      "epoch:37 step:35166 [D loss: 0.236910, acc.: 54.69%] [G loss: 0.303639]\n",
      "epoch:37 step:35167 [D loss: 0.246819, acc.: 57.81%] [G loss: 0.279731]\n",
      "epoch:37 step:35168 [D loss: 0.237114, acc.: 58.59%] [G loss: 0.290430]\n",
      "epoch:37 step:35169 [D loss: 0.243144, acc.: 56.25%] [G loss: 0.300126]\n",
      "epoch:37 step:35170 [D loss: 0.230335, acc.: 63.28%] [G loss: 0.303742]\n",
      "epoch:37 step:35171 [D loss: 0.229235, acc.: 64.06%] [G loss: 0.314674]\n",
      "epoch:37 step:35172 [D loss: 0.244518, acc.: 56.25%] [G loss: 0.282518]\n",
      "epoch:37 step:35173 [D loss: 0.247226, acc.: 54.69%] [G loss: 0.293604]\n",
      "epoch:37 step:35174 [D loss: 0.238588, acc.: 59.38%] [G loss: 0.300475]\n",
      "epoch:37 step:35175 [D loss: 0.239038, acc.: 57.03%] [G loss: 0.298845]\n",
      "epoch:37 step:35176 [D loss: 0.227059, acc.: 64.84%] [G loss: 0.327846]\n",
      "epoch:37 step:35177 [D loss: 0.252330, acc.: 52.34%] [G loss: 0.308591]\n",
      "epoch:37 step:35178 [D loss: 0.230901, acc.: 61.72%] [G loss: 0.301775]\n",
      "epoch:37 step:35179 [D loss: 0.270938, acc.: 48.44%] [G loss: 0.272782]\n",
      "epoch:37 step:35180 [D loss: 0.247516, acc.: 56.25%] [G loss: 0.310989]\n",
      "epoch:37 step:35181 [D loss: 0.238701, acc.: 61.72%] [G loss: 0.301364]\n",
      "epoch:37 step:35182 [D loss: 0.237295, acc.: 63.28%] [G loss: 0.317208]\n",
      "epoch:37 step:35183 [D loss: 0.231037, acc.: 58.59%] [G loss: 0.278910]\n",
      "epoch:37 step:35184 [D loss: 0.249099, acc.: 55.47%] [G loss: 0.315161]\n",
      "epoch:37 step:35185 [D loss: 0.241229, acc.: 57.03%] [G loss: 0.265917]\n",
      "epoch:37 step:35186 [D loss: 0.230132, acc.: 60.16%] [G loss: 0.315747]\n",
      "epoch:37 step:35187 [D loss: 0.240157, acc.: 57.03%] [G loss: 0.295462]\n",
      "epoch:37 step:35188 [D loss: 0.233497, acc.: 60.16%] [G loss: 0.315058]\n",
      "epoch:37 step:35189 [D loss: 0.248798, acc.: 53.91%] [G loss: 0.315131]\n",
      "epoch:37 step:35190 [D loss: 0.222083, acc.: 68.75%] [G loss: 0.298533]\n",
      "epoch:37 step:35191 [D loss: 0.238262, acc.: 60.16%] [G loss: 0.307431]\n",
      "epoch:37 step:35192 [D loss: 0.244337, acc.: 57.03%] [G loss: 0.298258]\n",
      "epoch:37 step:35193 [D loss: 0.231582, acc.: 61.72%] [G loss: 0.292530]\n",
      "epoch:37 step:35194 [D loss: 0.224081, acc.: 63.28%] [G loss: 0.311403]\n",
      "epoch:37 step:35195 [D loss: 0.235121, acc.: 58.59%] [G loss: 0.306005]\n",
      "epoch:37 step:35196 [D loss: 0.233819, acc.: 63.28%] [G loss: 0.328527]\n",
      "epoch:37 step:35197 [D loss: 0.231348, acc.: 59.38%] [G loss: 0.311909]\n",
      "epoch:37 step:35198 [D loss: 0.240386, acc.: 56.25%] [G loss: 0.287280]\n",
      "epoch:37 step:35199 [D loss: 0.239328, acc.: 57.03%] [G loss: 0.308570]\n",
      "epoch:37 step:35200 [D loss: 0.240485, acc.: 53.91%] [G loss: 0.319732]\n",
      "epoch:37 step:35201 [D loss: 0.242856, acc.: 57.03%] [G loss: 0.297826]\n",
      "epoch:37 step:35202 [D loss: 0.242199, acc.: 60.16%] [G loss: 0.292505]\n",
      "epoch:37 step:35203 [D loss: 0.233341, acc.: 60.16%] [G loss: 0.302020]\n",
      "epoch:37 step:35204 [D loss: 0.244781, acc.: 57.03%] [G loss: 0.291397]\n",
      "epoch:37 step:35205 [D loss: 0.244444, acc.: 55.47%] [G loss: 0.315599]\n",
      "epoch:37 step:35206 [D loss: 0.233290, acc.: 56.25%] [G loss: 0.301277]\n",
      "epoch:37 step:35207 [D loss: 0.243111, acc.: 53.12%] [G loss: 0.266165]\n",
      "epoch:37 step:35208 [D loss: 0.265090, acc.: 46.09%] [G loss: 0.273353]\n",
      "epoch:37 step:35209 [D loss: 0.226274, acc.: 60.16%] [G loss: 0.324482]\n",
      "epoch:37 step:35210 [D loss: 0.240353, acc.: 59.38%] [G loss: 0.323239]\n",
      "epoch:37 step:35211 [D loss: 0.239700, acc.: 56.25%] [G loss: 0.309825]\n",
      "epoch:37 step:35212 [D loss: 0.239650, acc.: 58.59%] [G loss: 0.314696]\n",
      "epoch:37 step:35213 [D loss: 0.245807, acc.: 53.91%] [G loss: 0.302979]\n",
      "epoch:37 step:35214 [D loss: 0.247575, acc.: 53.91%] [G loss: 0.275557]\n",
      "epoch:37 step:35215 [D loss: 0.232437, acc.: 61.72%] [G loss: 0.269066]\n",
      "epoch:37 step:35216 [D loss: 0.250831, acc.: 50.78%] [G loss: 0.296960]\n",
      "epoch:37 step:35217 [D loss: 0.275720, acc.: 43.75%] [G loss: 0.279662]\n",
      "epoch:37 step:35218 [D loss: 0.248345, acc.: 55.47%] [G loss: 0.269499]\n",
      "epoch:37 step:35219 [D loss: 0.253426, acc.: 48.44%] [G loss: 0.303939]\n",
      "epoch:37 step:35220 [D loss: 0.221589, acc.: 65.62%] [G loss: 0.303562]\n",
      "epoch:37 step:35221 [D loss: 0.257378, acc.: 46.09%] [G loss: 0.299121]\n",
      "epoch:37 step:35222 [D loss: 0.244865, acc.: 57.03%] [G loss: 0.282447]\n",
      "epoch:37 step:35223 [D loss: 0.229986, acc.: 62.50%] [G loss: 0.278985]\n",
      "epoch:37 step:35224 [D loss: 0.227671, acc.: 61.72%] [G loss: 0.285969]\n",
      "epoch:37 step:35225 [D loss: 0.244417, acc.: 58.59%] [G loss: 0.265500]\n",
      "epoch:37 step:35226 [D loss: 0.263353, acc.: 50.00%] [G loss: 0.268183]\n",
      "epoch:37 step:35227 [D loss: 0.245950, acc.: 55.47%] [G loss: 0.294473]\n",
      "epoch:37 step:35228 [D loss: 0.245284, acc.: 57.03%] [G loss: 0.293589]\n",
      "epoch:37 step:35229 [D loss: 0.226210, acc.: 61.72%] [G loss: 0.275606]\n",
      "epoch:37 step:35230 [D loss: 0.245242, acc.: 55.47%] [G loss: 0.275884]\n",
      "epoch:37 step:35231 [D loss: 0.241040, acc.: 59.38%] [G loss: 0.273770]\n",
      "epoch:37 step:35232 [D loss: 0.227171, acc.: 58.59%] [G loss: 0.276610]\n",
      "epoch:37 step:35233 [D loss: 0.231761, acc.: 62.50%] [G loss: 0.279217]\n",
      "epoch:37 step:35234 [D loss: 0.243601, acc.: 57.81%] [G loss: 0.309491]\n",
      "epoch:37 step:35235 [D loss: 0.235745, acc.: 53.91%] [G loss: 0.313775]\n",
      "epoch:37 step:35236 [D loss: 0.227793, acc.: 66.41%] [G loss: 0.297859]\n",
      "epoch:37 step:35237 [D loss: 0.229909, acc.: 60.94%] [G loss: 0.294597]\n",
      "epoch:37 step:35238 [D loss: 0.246033, acc.: 57.81%] [G loss: 0.315381]\n",
      "epoch:37 step:35239 [D loss: 0.246543, acc.: 57.03%] [G loss: 0.304503]\n",
      "epoch:37 step:35240 [D loss: 0.231331, acc.: 62.50%] [G loss: 0.295944]\n",
      "epoch:37 step:35241 [D loss: 0.232297, acc.: 60.94%] [G loss: 0.284458]\n",
      "epoch:37 step:35242 [D loss: 0.248530, acc.: 57.81%] [G loss: 0.294864]\n",
      "epoch:37 step:35243 [D loss: 0.256584, acc.: 50.78%] [G loss: 0.289035]\n",
      "epoch:37 step:35244 [D loss: 0.241332, acc.: 56.25%] [G loss: 0.303139]\n",
      "epoch:37 step:35245 [D loss: 0.231574, acc.: 63.28%] [G loss: 0.306828]\n",
      "epoch:37 step:35246 [D loss: 0.237518, acc.: 57.03%] [G loss: 0.307792]\n",
      "epoch:37 step:35247 [D loss: 0.261494, acc.: 52.34%] [G loss: 0.285833]\n",
      "epoch:37 step:35248 [D loss: 0.234696, acc.: 60.94%] [G loss: 0.299514]\n",
      "epoch:37 step:35249 [D loss: 0.254697, acc.: 48.44%] [G loss: 0.310577]\n",
      "epoch:37 step:35250 [D loss: 0.260342, acc.: 51.56%] [G loss: 0.306594]\n",
      "epoch:37 step:35251 [D loss: 0.242507, acc.: 54.69%] [G loss: 0.329167]\n",
      "epoch:37 step:35252 [D loss: 0.240909, acc.: 56.25%] [G loss: 0.308329]\n",
      "epoch:37 step:35253 [D loss: 0.242634, acc.: 57.03%] [G loss: 0.297401]\n",
      "epoch:37 step:35254 [D loss: 0.251170, acc.: 50.00%] [G loss: 0.286631]\n",
      "epoch:37 step:35255 [D loss: 0.240521, acc.: 57.81%] [G loss: 0.304882]\n",
      "epoch:37 step:35256 [D loss: 0.232431, acc.: 60.94%] [G loss: 0.294565]\n",
      "epoch:37 step:35257 [D loss: 0.261857, acc.: 49.22%] [G loss: 0.307770]\n",
      "epoch:37 step:35258 [D loss: 0.244082, acc.: 55.47%] [G loss: 0.266922]\n",
      "epoch:37 step:35259 [D loss: 0.255084, acc.: 46.88%] [G loss: 0.296799]\n",
      "epoch:37 step:35260 [D loss: 0.230403, acc.: 63.28%] [G loss: 0.305057]\n",
      "epoch:37 step:35261 [D loss: 0.205193, acc.: 72.66%] [G loss: 0.303879]\n",
      "epoch:37 step:35262 [D loss: 0.246243, acc.: 55.47%] [G loss: 0.302986]\n",
      "epoch:37 step:35263 [D loss: 0.248115, acc.: 54.69%] [G loss: 0.302049]\n",
      "epoch:37 step:35264 [D loss: 0.252149, acc.: 58.59%] [G loss: 0.284664]\n",
      "epoch:37 step:35265 [D loss: 0.240665, acc.: 56.25%] [G loss: 0.310526]\n",
      "epoch:37 step:35266 [D loss: 0.227485, acc.: 57.81%] [G loss: 0.331026]\n",
      "epoch:37 step:35267 [D loss: 0.234185, acc.: 60.94%] [G loss: 0.299846]\n",
      "epoch:37 step:35268 [D loss: 0.239879, acc.: 58.59%] [G loss: 0.306759]\n",
      "epoch:37 step:35269 [D loss: 0.231235, acc.: 59.38%] [G loss: 0.331670]\n",
      "epoch:37 step:35270 [D loss: 0.252874, acc.: 54.69%] [G loss: 0.245139]\n",
      "epoch:37 step:35271 [D loss: 0.228973, acc.: 67.97%] [G loss: 0.287308]\n",
      "epoch:37 step:35272 [D loss: 0.261463, acc.: 52.34%] [G loss: 0.309072]\n",
      "epoch:37 step:35273 [D loss: 0.237164, acc.: 59.38%] [G loss: 0.262880]\n",
      "epoch:37 step:35274 [D loss: 0.228798, acc.: 58.59%] [G loss: 0.305764]\n",
      "epoch:37 step:35275 [D loss: 0.272301, acc.: 50.00%] [G loss: 0.292987]\n",
      "epoch:37 step:35276 [D loss: 0.257274, acc.: 54.69%] [G loss: 0.286336]\n",
      "epoch:37 step:35277 [D loss: 0.239159, acc.: 56.25%] [G loss: 0.297445]\n",
      "epoch:37 step:35278 [D loss: 0.240591, acc.: 57.81%] [G loss: 0.321505]\n",
      "epoch:37 step:35279 [D loss: 0.217517, acc.: 66.41%] [G loss: 0.333573]\n",
      "epoch:37 step:35280 [D loss: 0.252406, acc.: 55.47%] [G loss: 0.301070]\n",
      "epoch:37 step:35281 [D loss: 0.251528, acc.: 54.69%] [G loss: 0.340523]\n",
      "epoch:37 step:35282 [D loss: 0.219357, acc.: 71.09%] [G loss: 0.295496]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:37 step:35283 [D loss: 0.251673, acc.: 57.03%] [G loss: 0.313522]\n",
      "epoch:37 step:35284 [D loss: 0.264386, acc.: 47.66%] [G loss: 0.278243]\n",
      "epoch:37 step:35285 [D loss: 0.237710, acc.: 60.94%] [G loss: 0.295010]\n",
      "epoch:37 step:35286 [D loss: 0.237252, acc.: 60.94%] [G loss: 0.295692]\n",
      "epoch:37 step:35287 [D loss: 0.236485, acc.: 56.25%] [G loss: 0.296727]\n",
      "epoch:37 step:35288 [D loss: 0.236082, acc.: 60.94%] [G loss: 0.308162]\n",
      "epoch:37 step:35289 [D loss: 0.251152, acc.: 48.44%] [G loss: 0.280762]\n",
      "epoch:37 step:35290 [D loss: 0.244132, acc.: 62.50%] [G loss: 0.299794]\n",
      "epoch:37 step:35291 [D loss: 0.231337, acc.: 60.94%] [G loss: 0.299435]\n",
      "epoch:37 step:35292 [D loss: 0.232903, acc.: 57.03%] [G loss: 0.287958]\n",
      "epoch:37 step:35293 [D loss: 0.240882, acc.: 56.25%] [G loss: 0.293368]\n",
      "epoch:37 step:35294 [D loss: 0.228801, acc.: 64.06%] [G loss: 0.300091]\n",
      "epoch:37 step:35295 [D loss: 0.238600, acc.: 60.94%] [G loss: 0.291537]\n",
      "epoch:37 step:35296 [D loss: 0.237959, acc.: 58.59%] [G loss: 0.321524]\n",
      "epoch:37 step:35297 [D loss: 0.238952, acc.: 56.25%] [G loss: 0.293720]\n",
      "epoch:37 step:35298 [D loss: 0.233271, acc.: 58.59%] [G loss: 0.280595]\n",
      "epoch:37 step:35299 [D loss: 0.239330, acc.: 61.72%] [G loss: 0.286957]\n",
      "epoch:37 step:35300 [D loss: 0.237715, acc.: 57.03%] [G loss: 0.317245]\n",
      "epoch:37 step:35301 [D loss: 0.229358, acc.: 67.97%] [G loss: 0.286071]\n",
      "epoch:37 step:35302 [D loss: 0.233009, acc.: 61.72%] [G loss: 0.306572]\n",
      "epoch:37 step:35303 [D loss: 0.238984, acc.: 56.25%] [G loss: 0.296606]\n",
      "epoch:37 step:35304 [D loss: 0.241458, acc.: 53.12%] [G loss: 0.288742]\n",
      "epoch:37 step:35305 [D loss: 0.237932, acc.: 53.91%] [G loss: 0.314201]\n",
      "epoch:37 step:35306 [D loss: 0.245825, acc.: 57.03%] [G loss: 0.312500]\n",
      "epoch:37 step:35307 [D loss: 0.236684, acc.: 54.69%] [G loss: 0.298653]\n",
      "epoch:37 step:35308 [D loss: 0.243404, acc.: 57.81%] [G loss: 0.290548]\n",
      "epoch:37 step:35309 [D loss: 0.233670, acc.: 59.38%] [G loss: 0.305451]\n",
      "epoch:37 step:35310 [D loss: 0.246013, acc.: 57.81%] [G loss: 0.302159]\n",
      "epoch:37 step:35311 [D loss: 0.231105, acc.: 60.94%] [G loss: 0.289414]\n",
      "epoch:37 step:35312 [D loss: 0.249933, acc.: 56.25%] [G loss: 0.281598]\n",
      "epoch:37 step:35313 [D loss: 0.237269, acc.: 59.38%] [G loss: 0.317334]\n",
      "epoch:37 step:35314 [D loss: 0.230497, acc.: 61.72%] [G loss: 0.306780]\n",
      "epoch:37 step:35315 [D loss: 0.245551, acc.: 56.25%] [G loss: 0.279657]\n",
      "epoch:37 step:35316 [D loss: 0.246863, acc.: 58.59%] [G loss: 0.300346]\n",
      "epoch:37 step:35317 [D loss: 0.241463, acc.: 61.72%] [G loss: 0.297837]\n",
      "epoch:37 step:35318 [D loss: 0.248994, acc.: 53.91%] [G loss: 0.279916]\n",
      "epoch:37 step:35319 [D loss: 0.224213, acc.: 68.75%] [G loss: 0.314339]\n",
      "epoch:37 step:35320 [D loss: 0.235575, acc.: 60.94%] [G loss: 0.292277]\n",
      "epoch:37 step:35321 [D loss: 0.227999, acc.: 61.72%] [G loss: 0.305992]\n",
      "epoch:37 step:35322 [D loss: 0.241726, acc.: 61.72%] [G loss: 0.297485]\n",
      "epoch:37 step:35323 [D loss: 0.257408, acc.: 53.12%] [G loss: 0.322529]\n",
      "epoch:37 step:35324 [D loss: 0.232008, acc.: 64.06%] [G loss: 0.303358]\n",
      "epoch:37 step:35325 [D loss: 0.228977, acc.: 67.97%] [G loss: 0.307453]\n",
      "epoch:37 step:35326 [D loss: 0.241306, acc.: 57.03%] [G loss: 0.299053]\n",
      "epoch:37 step:35327 [D loss: 0.259668, acc.: 51.56%] [G loss: 0.268496]\n",
      "epoch:37 step:35328 [D loss: 0.235556, acc.: 63.28%] [G loss: 0.293232]\n",
      "epoch:37 step:35329 [D loss: 0.234787, acc.: 57.03%] [G loss: 0.284470]\n",
      "epoch:37 step:35330 [D loss: 0.241065, acc.: 57.81%] [G loss: 0.276549]\n",
      "epoch:37 step:35331 [D loss: 0.242123, acc.: 55.47%] [G loss: 0.324734]\n",
      "epoch:37 step:35332 [D loss: 0.248692, acc.: 55.47%] [G loss: 0.273954]\n",
      "epoch:37 step:35333 [D loss: 0.238157, acc.: 57.81%] [G loss: 0.271328]\n",
      "epoch:37 step:35334 [D loss: 0.241540, acc.: 57.03%] [G loss: 0.279179]\n",
      "epoch:37 step:35335 [D loss: 0.232185, acc.: 64.06%] [G loss: 0.293681]\n",
      "epoch:37 step:35336 [D loss: 0.254051, acc.: 49.22%] [G loss: 0.262555]\n",
      "epoch:37 step:35337 [D loss: 0.243436, acc.: 60.94%] [G loss: 0.310370]\n",
      "epoch:37 step:35338 [D loss: 0.225126, acc.: 64.06%] [G loss: 0.283034]\n",
      "epoch:37 step:35339 [D loss: 0.242754, acc.: 56.25%] [G loss: 0.287258]\n",
      "epoch:37 step:35340 [D loss: 0.249379, acc.: 53.12%] [G loss: 0.281950]\n",
      "epoch:37 step:35341 [D loss: 0.239690, acc.: 61.72%] [G loss: 0.276622]\n",
      "epoch:37 step:35342 [D loss: 0.254544, acc.: 50.78%] [G loss: 0.303791]\n",
      "epoch:37 step:35343 [D loss: 0.233068, acc.: 60.16%] [G loss: 0.292588]\n",
      "epoch:37 step:35344 [D loss: 0.243328, acc.: 53.91%] [G loss: 0.301493]\n",
      "epoch:37 step:35345 [D loss: 0.249510, acc.: 55.47%] [G loss: 0.295134]\n",
      "epoch:37 step:35346 [D loss: 0.245014, acc.: 57.03%] [G loss: 0.273485]\n",
      "epoch:37 step:35347 [D loss: 0.244745, acc.: 57.03%] [G loss: 0.305622]\n",
      "epoch:37 step:35348 [D loss: 0.248806, acc.: 53.91%] [G loss: 0.282298]\n",
      "epoch:37 step:35349 [D loss: 0.246322, acc.: 59.38%] [G loss: 0.310461]\n",
      "epoch:37 step:35350 [D loss: 0.245105, acc.: 57.03%] [G loss: 0.302987]\n",
      "epoch:37 step:35351 [D loss: 0.236985, acc.: 60.16%] [G loss: 0.316303]\n",
      "epoch:37 step:35352 [D loss: 0.253722, acc.: 55.47%] [G loss: 0.274483]\n",
      "epoch:37 step:35353 [D loss: 0.253339, acc.: 53.12%] [G loss: 0.274104]\n",
      "epoch:37 step:35354 [D loss: 0.241767, acc.: 59.38%] [G loss: 0.300601]\n",
      "epoch:37 step:35355 [D loss: 0.225389, acc.: 61.72%] [G loss: 0.286239]\n",
      "epoch:37 step:35356 [D loss: 0.240340, acc.: 54.69%] [G loss: 0.292112]\n",
      "epoch:37 step:35357 [D loss: 0.239119, acc.: 58.59%] [G loss: 0.289600]\n",
      "epoch:37 step:35358 [D loss: 0.242782, acc.: 55.47%] [G loss: 0.295434]\n",
      "epoch:37 step:35359 [D loss: 0.236888, acc.: 59.38%] [G loss: 0.299691]\n",
      "epoch:37 step:35360 [D loss: 0.243072, acc.: 55.47%] [G loss: 0.282385]\n",
      "epoch:37 step:35361 [D loss: 0.232034, acc.: 63.28%] [G loss: 0.301867]\n",
      "epoch:37 step:35362 [D loss: 0.239731, acc.: 60.16%] [G loss: 0.303312]\n",
      "epoch:37 step:35363 [D loss: 0.239645, acc.: 57.81%] [G loss: 0.263893]\n",
      "epoch:37 step:35364 [D loss: 0.223643, acc.: 63.28%] [G loss: 0.305005]\n",
      "epoch:37 step:35365 [D loss: 0.249756, acc.: 56.25%] [G loss: 0.292457]\n",
      "epoch:37 step:35366 [D loss: 0.222692, acc.: 67.19%] [G loss: 0.310960]\n",
      "epoch:37 step:35367 [D loss: 0.237502, acc.: 59.38%] [G loss: 0.309567]\n",
      "epoch:37 step:35368 [D loss: 0.241500, acc.: 61.72%] [G loss: 0.297999]\n",
      "epoch:37 step:35369 [D loss: 0.231290, acc.: 58.59%] [G loss: 0.301534]\n",
      "epoch:37 step:35370 [D loss: 0.234108, acc.: 63.28%] [G loss: 0.281619]\n",
      "epoch:37 step:35371 [D loss: 0.235987, acc.: 57.81%] [G loss: 0.291062]\n",
      "epoch:37 step:35372 [D loss: 0.243803, acc.: 54.69%] [G loss: 0.287856]\n",
      "epoch:37 step:35373 [D loss: 0.259000, acc.: 56.25%] [G loss: 0.276841]\n",
      "epoch:37 step:35374 [D loss: 0.236940, acc.: 61.72%] [G loss: 0.270624]\n",
      "epoch:37 step:35375 [D loss: 0.248244, acc.: 53.12%] [G loss: 0.306567]\n",
      "epoch:37 step:35376 [D loss: 0.235570, acc.: 63.28%] [G loss: 0.303389]\n",
      "epoch:37 step:35377 [D loss: 0.246206, acc.: 56.25%] [G loss: 0.309343]\n",
      "epoch:37 step:35378 [D loss: 0.256118, acc.: 50.00%] [G loss: 0.274663]\n",
      "epoch:37 step:35379 [D loss: 0.248146, acc.: 57.81%] [G loss: 0.310029]\n",
      "epoch:37 step:35380 [D loss: 0.235632, acc.: 62.50%] [G loss: 0.311973]\n",
      "epoch:37 step:35381 [D loss: 0.242385, acc.: 57.81%] [G loss: 0.292296]\n",
      "epoch:37 step:35382 [D loss: 0.245382, acc.: 58.59%] [G loss: 0.288633]\n",
      "epoch:37 step:35383 [D loss: 0.220858, acc.: 65.62%] [G loss: 0.315849]\n",
      "epoch:37 step:35384 [D loss: 0.250999, acc.: 53.12%] [G loss: 0.300981]\n",
      "epoch:37 step:35385 [D loss: 0.268012, acc.: 43.75%] [G loss: 0.277908]\n",
      "epoch:37 step:35386 [D loss: 0.247721, acc.: 53.12%] [G loss: 0.276350]\n",
      "epoch:37 step:35387 [D loss: 0.224937, acc.: 57.81%] [G loss: 0.303044]\n",
      "epoch:37 step:35388 [D loss: 0.231405, acc.: 58.59%] [G loss: 0.318864]\n",
      "epoch:37 step:35389 [D loss: 0.240098, acc.: 55.47%] [G loss: 0.311241]\n",
      "epoch:37 step:35390 [D loss: 0.245787, acc.: 56.25%] [G loss: 0.296986]\n",
      "epoch:37 step:35391 [D loss: 0.235367, acc.: 59.38%] [G loss: 0.297796]\n",
      "epoch:37 step:35392 [D loss: 0.225320, acc.: 63.28%] [G loss: 0.298464]\n",
      "epoch:37 step:35393 [D loss: 0.224984, acc.: 64.84%] [G loss: 0.297215]\n",
      "epoch:37 step:35394 [D loss: 0.223553, acc.: 61.72%] [G loss: 0.296083]\n",
      "epoch:37 step:35395 [D loss: 0.259222, acc.: 48.44%] [G loss: 0.286094]\n",
      "epoch:37 step:35396 [D loss: 0.226895, acc.: 62.50%] [G loss: 0.292694]\n",
      "epoch:37 step:35397 [D loss: 0.258078, acc.: 50.00%] [G loss: 0.301421]\n",
      "epoch:37 step:35398 [D loss: 0.229544, acc.: 60.94%] [G loss: 0.272799]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:37 step:35399 [D loss: 0.235444, acc.: 58.59%] [G loss: 0.288209]\n",
      "epoch:37 step:35400 [D loss: 0.240108, acc.: 58.59%] [G loss: 0.304043]\n",
      "epoch:37 step:35401 [D loss: 0.208641, acc.: 68.75%] [G loss: 0.295114]\n",
      "epoch:37 step:35402 [D loss: 0.239574, acc.: 57.81%] [G loss: 0.269522]\n",
      "epoch:37 step:35403 [D loss: 0.246097, acc.: 58.59%] [G loss: 0.307528]\n",
      "epoch:37 step:35404 [D loss: 0.249499, acc.: 53.91%] [G loss: 0.301636]\n",
      "epoch:37 step:35405 [D loss: 0.232829, acc.: 53.91%] [G loss: 0.302233]\n",
      "epoch:37 step:35406 [D loss: 0.246008, acc.: 53.91%] [G loss: 0.310331]\n",
      "epoch:37 step:35407 [D loss: 0.248472, acc.: 58.59%] [G loss: 0.325108]\n",
      "epoch:37 step:35408 [D loss: 0.244961, acc.: 53.12%] [G loss: 0.308025]\n",
      "epoch:37 step:35409 [D loss: 0.254446, acc.: 53.12%] [G loss: 0.276208]\n",
      "epoch:37 step:35410 [D loss: 0.217686, acc.: 67.97%] [G loss: 0.311134]\n",
      "epoch:37 step:35411 [D loss: 0.230707, acc.: 63.28%] [G loss: 0.291409]\n",
      "epoch:37 step:35412 [D loss: 0.212587, acc.: 70.31%] [G loss: 0.325378]\n",
      "epoch:37 step:35413 [D loss: 0.239340, acc.: 57.81%] [G loss: 0.301308]\n",
      "epoch:37 step:35414 [D loss: 0.256398, acc.: 50.78%] [G loss: 0.296259]\n",
      "epoch:37 step:35415 [D loss: 0.246565, acc.: 53.91%] [G loss: 0.304016]\n",
      "epoch:37 step:35416 [D loss: 0.228187, acc.: 58.59%] [G loss: 0.280592]\n",
      "epoch:37 step:35417 [D loss: 0.231756, acc.: 58.59%] [G loss: 0.323099]\n",
      "epoch:37 step:35418 [D loss: 0.227529, acc.: 68.75%] [G loss: 0.308484]\n",
      "epoch:37 step:35419 [D loss: 0.243221, acc.: 60.16%] [G loss: 0.275932]\n",
      "epoch:37 step:35420 [D loss: 0.235224, acc.: 54.69%] [G loss: 0.281093]\n",
      "epoch:37 step:35421 [D loss: 0.245612, acc.: 54.69%] [G loss: 0.248013]\n",
      "epoch:37 step:35422 [D loss: 0.225951, acc.: 61.72%] [G loss: 0.284768]\n",
      "epoch:37 step:35423 [D loss: 0.227398, acc.: 65.62%] [G loss: 0.315543]\n",
      "epoch:37 step:35424 [D loss: 0.236793, acc.: 59.38%] [G loss: 0.296596]\n",
      "epoch:37 step:35425 [D loss: 0.248763, acc.: 57.81%] [G loss: 0.305113]\n",
      "epoch:37 step:35426 [D loss: 0.225138, acc.: 67.97%] [G loss: 0.287597]\n",
      "epoch:37 step:35427 [D loss: 0.231491, acc.: 61.72%] [G loss: 0.294440]\n",
      "epoch:37 step:35428 [D loss: 0.247385, acc.: 57.03%] [G loss: 0.298447]\n",
      "epoch:37 step:35429 [D loss: 0.238945, acc.: 58.59%] [G loss: 0.306693]\n",
      "epoch:37 step:35430 [D loss: 0.257296, acc.: 45.31%] [G loss: 0.288450]\n",
      "epoch:37 step:35431 [D loss: 0.241768, acc.: 59.38%] [G loss: 0.304584]\n",
      "epoch:37 step:35432 [D loss: 0.221562, acc.: 64.06%] [G loss: 0.303111]\n",
      "epoch:37 step:35433 [D loss: 0.244072, acc.: 66.41%] [G loss: 0.284728]\n",
      "epoch:37 step:35434 [D loss: 0.236439, acc.: 54.69%] [G loss: 0.277477]\n",
      "epoch:37 step:35435 [D loss: 0.225952, acc.: 61.72%] [G loss: 0.284814]\n",
      "epoch:37 step:35436 [D loss: 0.228231, acc.: 59.38%] [G loss: 0.313007]\n",
      "epoch:37 step:35437 [D loss: 0.244452, acc.: 57.03%] [G loss: 0.297818]\n",
      "epoch:37 step:35438 [D loss: 0.222031, acc.: 64.06%] [G loss: 0.298110]\n",
      "epoch:37 step:35439 [D loss: 0.237728, acc.: 64.84%] [G loss: 0.328506]\n",
      "epoch:37 step:35440 [D loss: 0.223683, acc.: 66.41%] [G loss: 0.296401]\n",
      "epoch:37 step:35441 [D loss: 0.228215, acc.: 65.62%] [G loss: 0.294773]\n",
      "epoch:37 step:35442 [D loss: 0.253134, acc.: 52.34%] [G loss: 0.289794]\n",
      "epoch:37 step:35443 [D loss: 0.238943, acc.: 55.47%] [G loss: 0.300498]\n",
      "epoch:37 step:35444 [D loss: 0.234744, acc.: 57.81%] [G loss: 0.306107]\n",
      "epoch:37 step:35445 [D loss: 0.237186, acc.: 60.16%] [G loss: 0.306141]\n",
      "epoch:37 step:35446 [D loss: 0.254424, acc.: 49.22%] [G loss: 0.278783]\n",
      "epoch:37 step:35447 [D loss: 0.237721, acc.: 60.16%] [G loss: 0.289999]\n",
      "epoch:37 step:35448 [D loss: 0.236395, acc.: 54.69%] [G loss: 0.289596]\n",
      "epoch:37 step:35449 [D loss: 0.249457, acc.: 53.91%] [G loss: 0.294339]\n",
      "epoch:37 step:35450 [D loss: 0.236162, acc.: 57.03%] [G loss: 0.273113]\n",
      "epoch:37 step:35451 [D loss: 0.235000, acc.: 57.81%] [G loss: 0.290065]\n",
      "epoch:37 step:35452 [D loss: 0.245015, acc.: 53.12%] [G loss: 0.307906]\n",
      "epoch:37 step:35453 [D loss: 0.239318, acc.: 57.81%] [G loss: 0.314279]\n",
      "epoch:37 step:35454 [D loss: 0.234805, acc.: 55.47%] [G loss: 0.281675]\n",
      "epoch:37 step:35455 [D loss: 0.258430, acc.: 54.69%] [G loss: 0.312682]\n",
      "epoch:37 step:35456 [D loss: 0.237553, acc.: 62.50%] [G loss: 0.271256]\n",
      "epoch:37 step:35457 [D loss: 0.236625, acc.: 60.16%] [G loss: 0.301695]\n",
      "epoch:37 step:35458 [D loss: 0.254397, acc.: 56.25%] [G loss: 0.291390]\n",
      "epoch:37 step:35459 [D loss: 0.239687, acc.: 57.03%] [G loss: 0.293617]\n",
      "epoch:37 step:35460 [D loss: 0.235047, acc.: 60.94%] [G loss: 0.295550]\n",
      "epoch:37 step:35461 [D loss: 0.232729, acc.: 61.72%] [G loss: 0.300774]\n",
      "epoch:37 step:35462 [D loss: 0.249513, acc.: 52.34%] [G loss: 0.312884]\n",
      "epoch:37 step:35463 [D loss: 0.253528, acc.: 47.66%] [G loss: 0.285632]\n",
      "epoch:37 step:35464 [D loss: 0.233206, acc.: 64.84%] [G loss: 0.319927]\n",
      "epoch:37 step:35465 [D loss: 0.250091, acc.: 53.91%] [G loss: 0.281474]\n",
      "epoch:37 step:35466 [D loss: 0.243916, acc.: 56.25%] [G loss: 0.293314]\n",
      "epoch:37 step:35467 [D loss: 0.233928, acc.: 63.28%] [G loss: 0.310422]\n",
      "epoch:37 step:35468 [D loss: 0.232155, acc.: 55.47%] [G loss: 0.311114]\n",
      "epoch:37 step:35469 [D loss: 0.234407, acc.: 59.38%] [G loss: 0.288155]\n",
      "epoch:37 step:35470 [D loss: 0.252234, acc.: 53.91%] [G loss: 0.301674]\n",
      "epoch:37 step:35471 [D loss: 0.240494, acc.: 54.69%] [G loss: 0.313489]\n",
      "epoch:37 step:35472 [D loss: 0.237511, acc.: 54.69%] [G loss: 0.304154]\n",
      "epoch:37 step:35473 [D loss: 0.235546, acc.: 62.50%] [G loss: 0.302012]\n",
      "epoch:37 step:35474 [D loss: 0.241142, acc.: 59.38%] [G loss: 0.319707]\n",
      "epoch:37 step:35475 [D loss: 0.225616, acc.: 60.94%] [G loss: 0.302278]\n",
      "epoch:37 step:35476 [D loss: 0.232209, acc.: 60.94%] [G loss: 0.297806]\n",
      "epoch:37 step:35477 [D loss: 0.239231, acc.: 60.94%] [G loss: 0.303833]\n",
      "epoch:37 step:35478 [D loss: 0.231150, acc.: 63.28%] [G loss: 0.301033]\n",
      "epoch:37 step:35479 [D loss: 0.240061, acc.: 59.38%] [G loss: 0.272146]\n",
      "epoch:37 step:35480 [D loss: 0.247205, acc.: 55.47%] [G loss: 0.308472]\n",
      "epoch:37 step:35481 [D loss: 0.226398, acc.: 64.84%] [G loss: 0.288817]\n",
      "epoch:37 step:35482 [D loss: 0.218116, acc.: 63.28%] [G loss: 0.296206]\n",
      "epoch:37 step:35483 [D loss: 0.246444, acc.: 60.16%] [G loss: 0.317195]\n",
      "epoch:37 step:35484 [D loss: 0.258084, acc.: 49.22%] [G loss: 0.282460]\n",
      "epoch:37 step:35485 [D loss: 0.243050, acc.: 56.25%] [G loss: 0.306987]\n",
      "epoch:37 step:35486 [D loss: 0.232089, acc.: 63.28%] [G loss: 0.284526]\n",
      "epoch:37 step:35487 [D loss: 0.229343, acc.: 64.84%] [G loss: 0.280595]\n",
      "epoch:37 step:35488 [D loss: 0.249550, acc.: 48.44%] [G loss: 0.318311]\n",
      "epoch:37 step:35489 [D loss: 0.243319, acc.: 57.03%] [G loss: 0.281053]\n",
      "epoch:37 step:35490 [D loss: 0.245822, acc.: 60.16%] [G loss: 0.310791]\n",
      "epoch:37 step:35491 [D loss: 0.238268, acc.: 59.38%] [G loss: 0.299503]\n",
      "epoch:37 step:35492 [D loss: 0.239441, acc.: 59.38%] [G loss: 0.280397]\n",
      "epoch:37 step:35493 [D loss: 0.237678, acc.: 59.38%] [G loss: 0.309740]\n",
      "epoch:37 step:35494 [D loss: 0.244678, acc.: 53.12%] [G loss: 0.283940]\n",
      "epoch:37 step:35495 [D loss: 0.229979, acc.: 62.50%] [G loss: 0.292136]\n",
      "epoch:37 step:35496 [D loss: 0.260605, acc.: 49.22%] [G loss: 0.283410]\n",
      "epoch:37 step:35497 [D loss: 0.251186, acc.: 54.69%] [G loss: 0.289984]\n",
      "epoch:37 step:35498 [D loss: 0.229952, acc.: 60.94%] [G loss: 0.321148]\n",
      "epoch:37 step:35499 [D loss: 0.227842, acc.: 63.28%] [G loss: 0.317041]\n",
      "epoch:37 step:35500 [D loss: 0.233536, acc.: 60.94%] [G loss: 0.300146]\n",
      "epoch:37 step:35501 [D loss: 0.233874, acc.: 64.84%] [G loss: 0.307002]\n",
      "epoch:37 step:35502 [D loss: 0.254679, acc.: 53.12%] [G loss: 0.274171]\n",
      "epoch:37 step:35503 [D loss: 0.240992, acc.: 63.28%] [G loss: 0.286656]\n",
      "epoch:37 step:35504 [D loss: 0.226177, acc.: 63.28%] [G loss: 0.301990]\n",
      "epoch:37 step:35505 [D loss: 0.226675, acc.: 71.09%] [G loss: 0.272887]\n",
      "epoch:37 step:35506 [D loss: 0.255334, acc.: 52.34%] [G loss: 0.287402]\n",
      "epoch:37 step:35507 [D loss: 0.235825, acc.: 58.59%] [G loss: 0.296470]\n",
      "epoch:37 step:35508 [D loss: 0.242985, acc.: 60.16%] [G loss: 0.331310]\n",
      "epoch:37 step:35509 [D loss: 0.229313, acc.: 64.06%] [G loss: 0.286874]\n",
      "epoch:37 step:35510 [D loss: 0.250796, acc.: 55.47%] [G loss: 0.293993]\n",
      "epoch:37 step:35511 [D loss: 0.259327, acc.: 48.44%] [G loss: 0.298647]\n",
      "epoch:37 step:35512 [D loss: 0.240448, acc.: 56.25%] [G loss: 0.280705]\n",
      "epoch:37 step:35513 [D loss: 0.233858, acc.: 60.16%] [G loss: 0.290077]\n",
      "epoch:37 step:35514 [D loss: 0.249450, acc.: 54.69%] [G loss: 0.307249]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:37 step:35515 [D loss: 0.262359, acc.: 51.56%] [G loss: 0.307848]\n",
      "epoch:37 step:35516 [D loss: 0.249670, acc.: 57.03%] [G loss: 0.313961]\n",
      "epoch:37 step:35517 [D loss: 0.234761, acc.: 63.28%] [G loss: 0.263754]\n",
      "epoch:37 step:35518 [D loss: 0.223971, acc.: 61.72%] [G loss: 0.304607]\n",
      "epoch:37 step:35519 [D loss: 0.233399, acc.: 63.28%] [G loss: 0.296369]\n",
      "epoch:37 step:35520 [D loss: 0.264492, acc.: 50.00%] [G loss: 0.288313]\n",
      "epoch:37 step:35521 [D loss: 0.242501, acc.: 53.91%] [G loss: 0.279636]\n",
      "epoch:37 step:35522 [D loss: 0.244095, acc.: 58.59%] [G loss: 0.306320]\n",
      "epoch:37 step:35523 [D loss: 0.229687, acc.: 64.84%] [G loss: 0.304934]\n",
      "epoch:37 step:35524 [D loss: 0.237768, acc.: 57.03%] [G loss: 0.310061]\n",
      "epoch:37 step:35525 [D loss: 0.223547, acc.: 64.84%] [G loss: 0.318979]\n",
      "epoch:37 step:35526 [D loss: 0.232021, acc.: 63.28%] [G loss: 0.292468]\n",
      "epoch:37 step:35527 [D loss: 0.265492, acc.: 54.69%] [G loss: 0.269244]\n",
      "epoch:37 step:35528 [D loss: 0.248966, acc.: 53.12%] [G loss: 0.269093]\n",
      "epoch:37 step:35529 [D loss: 0.237031, acc.: 56.25%] [G loss: 0.273569]\n",
      "epoch:37 step:35530 [D loss: 0.243882, acc.: 56.25%] [G loss: 0.302724]\n",
      "epoch:37 step:35531 [D loss: 0.250503, acc.: 47.66%] [G loss: 0.312783]\n",
      "epoch:37 step:35532 [D loss: 0.251644, acc.: 54.69%] [G loss: 0.281256]\n",
      "epoch:37 step:35533 [D loss: 0.244135, acc.: 60.94%] [G loss: 0.282617]\n",
      "epoch:37 step:35534 [D loss: 0.238377, acc.: 60.16%] [G loss: 0.314758]\n",
      "epoch:37 step:35535 [D loss: 0.230421, acc.: 58.59%] [G loss: 0.309195]\n",
      "epoch:37 step:35536 [D loss: 0.222039, acc.: 64.06%] [G loss: 0.312909]\n",
      "epoch:37 step:35537 [D loss: 0.248789, acc.: 58.59%] [G loss: 0.338147]\n",
      "epoch:37 step:35538 [D loss: 0.237674, acc.: 60.16%] [G loss: 0.295465]\n",
      "epoch:37 step:35539 [D loss: 0.249810, acc.: 48.44%] [G loss: 0.306974]\n",
      "epoch:37 step:35540 [D loss: 0.224751, acc.: 60.16%] [G loss: 0.314086]\n",
      "epoch:37 step:35541 [D loss: 0.246947, acc.: 46.88%] [G loss: 0.312704]\n",
      "epoch:37 step:35542 [D loss: 0.249904, acc.: 55.47%] [G loss: 0.281042]\n",
      "epoch:37 step:35543 [D loss: 0.227979, acc.: 63.28%] [G loss: 0.321712]\n",
      "epoch:37 step:35544 [D loss: 0.251618, acc.: 50.78%] [G loss: 0.304294]\n",
      "epoch:37 step:35545 [D loss: 0.232609, acc.: 60.16%] [G loss: 0.294288]\n",
      "epoch:37 step:35546 [D loss: 0.225083, acc.: 62.50%] [G loss: 0.304021]\n",
      "epoch:37 step:35547 [D loss: 0.222106, acc.: 61.72%] [G loss: 0.302700]\n",
      "epoch:37 step:35548 [D loss: 0.224383, acc.: 62.50%] [G loss: 0.293462]\n",
      "epoch:37 step:35549 [D loss: 0.222947, acc.: 68.75%] [G loss: 0.324301]\n",
      "epoch:37 step:35550 [D loss: 0.235526, acc.: 57.81%] [G loss: 0.314871]\n",
      "epoch:37 step:35551 [D loss: 0.226037, acc.: 58.59%] [G loss: 0.307834]\n",
      "epoch:37 step:35552 [D loss: 0.244582, acc.: 59.38%] [G loss: 0.318549]\n",
      "epoch:37 step:35553 [D loss: 0.222785, acc.: 64.84%] [G loss: 0.305380]\n",
      "epoch:37 step:35554 [D loss: 0.238539, acc.: 57.81%] [G loss: 0.284437]\n",
      "epoch:37 step:35555 [D loss: 0.230072, acc.: 60.94%] [G loss: 0.309331]\n",
      "epoch:37 step:35556 [D loss: 0.239648, acc.: 63.28%] [G loss: 0.330064]\n",
      "epoch:37 step:35557 [D loss: 0.229196, acc.: 61.72%] [G loss: 0.276795]\n",
      "epoch:37 step:35558 [D loss: 0.255814, acc.: 53.12%] [G loss: 0.299432]\n",
      "epoch:37 step:35559 [D loss: 0.255917, acc.: 53.91%] [G loss: 0.305226]\n",
      "epoch:37 step:35560 [D loss: 0.241766, acc.: 60.16%] [G loss: 0.313728]\n",
      "epoch:37 step:35561 [D loss: 0.236094, acc.: 63.28%] [G loss: 0.279588]\n",
      "epoch:37 step:35562 [D loss: 0.262215, acc.: 50.00%] [G loss: 0.311910]\n",
      "epoch:37 step:35563 [D loss: 0.246208, acc.: 58.59%] [G loss: 0.291843]\n",
      "epoch:37 step:35564 [D loss: 0.253632, acc.: 54.69%] [G loss: 0.269215]\n",
      "epoch:37 step:35565 [D loss: 0.243159, acc.: 55.47%] [G loss: 0.328678]\n",
      "epoch:37 step:35566 [D loss: 0.241584, acc.: 60.16%] [G loss: 0.301270]\n",
      "epoch:37 step:35567 [D loss: 0.232251, acc.: 60.94%] [G loss: 0.291106]\n",
      "epoch:37 step:35568 [D loss: 0.236124, acc.: 57.03%] [G loss: 0.301965]\n",
      "epoch:37 step:35569 [D loss: 0.238089, acc.: 57.81%] [G loss: 0.308964]\n",
      "epoch:37 step:35570 [D loss: 0.246324, acc.: 55.47%] [G loss: 0.266201]\n",
      "epoch:37 step:35571 [D loss: 0.243773, acc.: 50.78%] [G loss: 0.304418]\n",
      "epoch:37 step:35572 [D loss: 0.241511, acc.: 59.38%] [G loss: 0.264897]\n",
      "epoch:37 step:35573 [D loss: 0.232358, acc.: 57.03%] [G loss: 0.296864]\n",
      "epoch:37 step:35574 [D loss: 0.257917, acc.: 47.66%] [G loss: 0.290911]\n",
      "epoch:37 step:35575 [D loss: 0.251121, acc.: 57.03%] [G loss: 0.305133]\n",
      "epoch:37 step:35576 [D loss: 0.255315, acc.: 50.78%] [G loss: 0.286377]\n",
      "epoch:37 step:35577 [D loss: 0.257118, acc.: 51.56%] [G loss: 0.334310]\n",
      "epoch:37 step:35578 [D loss: 0.261833, acc.: 50.78%] [G loss: 0.287215]\n",
      "epoch:37 step:35579 [D loss: 0.257077, acc.: 52.34%] [G loss: 0.262721]\n",
      "epoch:37 step:35580 [D loss: 0.253364, acc.: 57.81%] [G loss: 0.281422]\n",
      "epoch:37 step:35581 [D loss: 0.241035, acc.: 56.25%] [G loss: 0.282175]\n",
      "epoch:37 step:35582 [D loss: 0.248679, acc.: 53.91%] [G loss: 0.293679]\n",
      "epoch:37 step:35583 [D loss: 0.234608, acc.: 58.59%] [G loss: 0.270436]\n",
      "epoch:37 step:35584 [D loss: 0.231494, acc.: 62.50%] [G loss: 0.297350]\n",
      "epoch:37 step:35585 [D loss: 0.233877, acc.: 61.72%] [G loss: 0.280678]\n",
      "epoch:37 step:35586 [D loss: 0.246437, acc.: 53.91%] [G loss: 0.293405]\n",
      "epoch:37 step:35587 [D loss: 0.239156, acc.: 63.28%] [G loss: 0.293936]\n",
      "epoch:37 step:35588 [D loss: 0.218442, acc.: 66.41%] [G loss: 0.314834]\n",
      "epoch:37 step:35589 [D loss: 0.228805, acc.: 58.59%] [G loss: 0.282729]\n",
      "epoch:37 step:35590 [D loss: 0.252306, acc.: 50.78%] [G loss: 0.306171]\n",
      "epoch:37 step:35591 [D loss: 0.240896, acc.: 60.16%] [G loss: 0.288944]\n",
      "epoch:37 step:35592 [D loss: 0.247824, acc.: 55.47%] [G loss: 0.285587]\n",
      "epoch:37 step:35593 [D loss: 0.251141, acc.: 55.47%] [G loss: 0.298383]\n",
      "epoch:37 step:35594 [D loss: 0.259609, acc.: 49.22%] [G loss: 0.278338]\n",
      "epoch:37 step:35595 [D loss: 0.245580, acc.: 54.69%] [G loss: 0.301709]\n",
      "epoch:37 step:35596 [D loss: 0.260601, acc.: 46.88%] [G loss: 0.284929]\n",
      "epoch:37 step:35597 [D loss: 0.220431, acc.: 64.84%] [G loss: 0.304257]\n",
      "epoch:37 step:35598 [D loss: 0.221049, acc.: 64.06%] [G loss: 0.290373]\n",
      "epoch:37 step:35599 [D loss: 0.237588, acc.: 58.59%] [G loss: 0.313767]\n",
      "epoch:37 step:35600 [D loss: 0.256663, acc.: 53.12%] [G loss: 0.311185]\n",
      "epoch:37 step:35601 [D loss: 0.242425, acc.: 60.94%] [G loss: 0.320648]\n",
      "epoch:37 step:35602 [D loss: 0.240211, acc.: 60.94%] [G loss: 0.291754]\n",
      "epoch:37 step:35603 [D loss: 0.250459, acc.: 58.59%] [G loss: 0.287349]\n",
      "epoch:37 step:35604 [D loss: 0.239051, acc.: 52.34%] [G loss: 0.315792]\n",
      "epoch:37 step:35605 [D loss: 0.241469, acc.: 53.91%] [G loss: 0.296010]\n",
      "epoch:37 step:35606 [D loss: 0.227876, acc.: 60.94%] [G loss: 0.325026]\n",
      "epoch:38 step:35607 [D loss: 0.231541, acc.: 59.38%] [G loss: 0.289865]\n",
      "epoch:38 step:35608 [D loss: 0.254593, acc.: 53.91%] [G loss: 0.332805]\n",
      "epoch:38 step:35609 [D loss: 0.245063, acc.: 55.47%] [G loss: 0.295574]\n",
      "epoch:38 step:35610 [D loss: 0.237624, acc.: 60.94%] [G loss: 0.297924]\n",
      "epoch:38 step:35611 [D loss: 0.225503, acc.: 61.72%] [G loss: 0.297962]\n",
      "epoch:38 step:35612 [D loss: 0.257025, acc.: 46.88%] [G loss: 0.271449]\n",
      "epoch:38 step:35613 [D loss: 0.254727, acc.: 53.12%] [G loss: 0.298710]\n",
      "epoch:38 step:35614 [D loss: 0.250151, acc.: 56.25%] [G loss: 0.268799]\n",
      "epoch:38 step:35615 [D loss: 0.226677, acc.: 66.41%] [G loss: 0.305365]\n",
      "epoch:38 step:35616 [D loss: 0.246223, acc.: 54.69%] [G loss: 0.285453]\n",
      "epoch:38 step:35617 [D loss: 0.224905, acc.: 60.16%] [G loss: 0.314865]\n",
      "epoch:38 step:35618 [D loss: 0.227485, acc.: 62.50%] [G loss: 0.319025]\n",
      "epoch:38 step:35619 [D loss: 0.228870, acc.: 61.72%] [G loss: 0.301702]\n",
      "epoch:38 step:35620 [D loss: 0.224074, acc.: 61.72%] [G loss: 0.303309]\n",
      "epoch:38 step:35621 [D loss: 0.223952, acc.: 63.28%] [G loss: 0.296008]\n",
      "epoch:38 step:35622 [D loss: 0.228838, acc.: 62.50%] [G loss: 0.291239]\n",
      "epoch:38 step:35623 [D loss: 0.221071, acc.: 66.41%] [G loss: 0.325464]\n",
      "epoch:38 step:35624 [D loss: 0.248011, acc.: 51.56%] [G loss: 0.317177]\n",
      "epoch:38 step:35625 [D loss: 0.252503, acc.: 50.00%] [G loss: 0.312454]\n",
      "epoch:38 step:35626 [D loss: 0.228050, acc.: 68.75%] [G loss: 0.296229]\n",
      "epoch:38 step:35627 [D loss: 0.235784, acc.: 59.38%] [G loss: 0.333570]\n",
      "epoch:38 step:35628 [D loss: 0.240049, acc.: 57.81%] [G loss: 0.290872]\n",
      "epoch:38 step:35629 [D loss: 0.242493, acc.: 58.59%] [G loss: 0.284967]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:38 step:35630 [D loss: 0.221498, acc.: 64.84%] [G loss: 0.312217]\n",
      "epoch:38 step:35631 [D loss: 0.249959, acc.: 59.38%] [G loss: 0.313122]\n",
      "epoch:38 step:35632 [D loss: 0.257867, acc.: 51.56%] [G loss: 0.292320]\n",
      "epoch:38 step:35633 [D loss: 0.229580, acc.: 65.62%] [G loss: 0.308032]\n",
      "epoch:38 step:35634 [D loss: 0.229608, acc.: 57.03%] [G loss: 0.286736]\n",
      "epoch:38 step:35635 [D loss: 0.249507, acc.: 53.12%] [G loss: 0.295738]\n",
      "epoch:38 step:35636 [D loss: 0.242649, acc.: 57.03%] [G loss: 0.273623]\n",
      "epoch:38 step:35637 [D loss: 0.235865, acc.: 61.72%] [G loss: 0.314003]\n",
      "epoch:38 step:35638 [D loss: 0.259772, acc.: 49.22%] [G loss: 0.303026]\n",
      "epoch:38 step:35639 [D loss: 0.233609, acc.: 61.72%] [G loss: 0.309960]\n",
      "epoch:38 step:35640 [D loss: 0.237932, acc.: 61.72%] [G loss: 0.313366]\n",
      "epoch:38 step:35641 [D loss: 0.240275, acc.: 62.50%] [G loss: 0.282550]\n",
      "epoch:38 step:35642 [D loss: 0.238007, acc.: 56.25%] [G loss: 0.331345]\n",
      "epoch:38 step:35643 [D loss: 0.250280, acc.: 53.12%] [G loss: 0.298427]\n",
      "epoch:38 step:35644 [D loss: 0.246687, acc.: 58.59%] [G loss: 0.297260]\n",
      "epoch:38 step:35645 [D loss: 0.253332, acc.: 49.22%] [G loss: 0.300900]\n",
      "epoch:38 step:35646 [D loss: 0.236142, acc.: 58.59%] [G loss: 0.292434]\n",
      "epoch:38 step:35647 [D loss: 0.239701, acc.: 66.41%] [G loss: 0.287884]\n",
      "epoch:38 step:35648 [D loss: 0.243701, acc.: 57.03%] [G loss: 0.300507]\n",
      "epoch:38 step:35649 [D loss: 0.240589, acc.: 63.28%] [G loss: 0.290423]\n",
      "epoch:38 step:35650 [D loss: 0.241683, acc.: 56.25%] [G loss: 0.293532]\n",
      "epoch:38 step:35651 [D loss: 0.236947, acc.: 61.72%] [G loss: 0.308197]\n",
      "epoch:38 step:35652 [D loss: 0.237637, acc.: 58.59%] [G loss: 0.271391]\n",
      "epoch:38 step:35653 [D loss: 0.224793, acc.: 62.50%] [G loss: 0.315405]\n",
      "epoch:38 step:35654 [D loss: 0.238917, acc.: 57.81%] [G loss: 0.306683]\n",
      "epoch:38 step:35655 [D loss: 0.239441, acc.: 51.56%] [G loss: 0.320172]\n",
      "epoch:38 step:35656 [D loss: 0.238945, acc.: 58.59%] [G loss: 0.290961]\n",
      "epoch:38 step:35657 [D loss: 0.238738, acc.: 60.94%] [G loss: 0.271617]\n",
      "epoch:38 step:35658 [D loss: 0.258564, acc.: 53.12%] [G loss: 0.277849]\n",
      "epoch:38 step:35659 [D loss: 0.240201, acc.: 60.94%] [G loss: 0.284959]\n",
      "epoch:38 step:35660 [D loss: 0.242618, acc.: 53.91%] [G loss: 0.299343]\n",
      "epoch:38 step:35661 [D loss: 0.234567, acc.: 60.16%] [G loss: 0.279753]\n",
      "epoch:38 step:35662 [D loss: 0.243885, acc.: 57.81%] [G loss: 0.288333]\n",
      "epoch:38 step:35663 [D loss: 0.249657, acc.: 53.12%] [G loss: 0.288484]\n",
      "epoch:38 step:35664 [D loss: 0.249160, acc.: 51.56%] [G loss: 0.296660]\n",
      "epoch:38 step:35665 [D loss: 0.221385, acc.: 62.50%] [G loss: 0.280310]\n",
      "epoch:38 step:35666 [D loss: 0.244347, acc.: 58.59%] [G loss: 0.301943]\n",
      "epoch:38 step:35667 [D loss: 0.240531, acc.: 59.38%] [G loss: 0.300172]\n",
      "epoch:38 step:35668 [D loss: 0.236435, acc.: 56.25%] [G loss: 0.294005]\n",
      "epoch:38 step:35669 [D loss: 0.243327, acc.: 57.03%] [G loss: 0.331527]\n",
      "epoch:38 step:35670 [D loss: 0.239999, acc.: 60.94%] [G loss: 0.310229]\n",
      "epoch:38 step:35671 [D loss: 0.261807, acc.: 47.66%] [G loss: 0.312291]\n",
      "epoch:38 step:35672 [D loss: 0.240865, acc.: 57.81%] [G loss: 0.283202]\n",
      "epoch:38 step:35673 [D loss: 0.232453, acc.: 62.50%] [G loss: 0.303337]\n",
      "epoch:38 step:35674 [D loss: 0.263497, acc.: 49.22%] [G loss: 0.307564]\n",
      "epoch:38 step:35675 [D loss: 0.246036, acc.: 54.69%] [G loss: 0.337767]\n",
      "epoch:38 step:35676 [D loss: 0.239744, acc.: 57.81%] [G loss: 0.293800]\n",
      "epoch:38 step:35677 [D loss: 0.258185, acc.: 48.44%] [G loss: 0.264084]\n",
      "epoch:38 step:35678 [D loss: 0.245996, acc.: 54.69%] [G loss: 0.318265]\n",
      "epoch:38 step:35679 [D loss: 0.231714, acc.: 60.16%] [G loss: 0.298702]\n",
      "epoch:38 step:35680 [D loss: 0.228911, acc.: 60.16%] [G loss: 0.290856]\n",
      "epoch:38 step:35681 [D loss: 0.239519, acc.: 56.25%] [G loss: 0.299809]\n",
      "epoch:38 step:35682 [D loss: 0.222347, acc.: 60.94%] [G loss: 0.321056]\n",
      "epoch:38 step:35683 [D loss: 0.248716, acc.: 55.47%] [G loss: 0.255153]\n",
      "epoch:38 step:35684 [D loss: 0.245180, acc.: 59.38%] [G loss: 0.280220]\n",
      "epoch:38 step:35685 [D loss: 0.243509, acc.: 60.16%] [G loss: 0.303881]\n",
      "epoch:38 step:35686 [D loss: 0.226765, acc.: 59.38%] [G loss: 0.284944]\n",
      "epoch:38 step:35687 [D loss: 0.241177, acc.: 55.47%] [G loss: 0.320080]\n",
      "epoch:38 step:35688 [D loss: 0.250697, acc.: 52.34%] [G loss: 0.276344]\n",
      "epoch:38 step:35689 [D loss: 0.243764, acc.: 55.47%] [G loss: 0.314455]\n",
      "epoch:38 step:35690 [D loss: 0.237720, acc.: 56.25%] [G loss: 0.290691]\n",
      "epoch:38 step:35691 [D loss: 0.229373, acc.: 64.06%] [G loss: 0.289772]\n",
      "epoch:38 step:35692 [D loss: 0.244405, acc.: 53.12%] [G loss: 0.302787]\n",
      "epoch:38 step:35693 [D loss: 0.248647, acc.: 53.12%] [G loss: 0.282760]\n",
      "epoch:38 step:35694 [D loss: 0.247335, acc.: 55.47%] [G loss: 0.283654]\n",
      "epoch:38 step:35695 [D loss: 0.241641, acc.: 61.72%] [G loss: 0.290276]\n",
      "epoch:38 step:35696 [D loss: 0.229039, acc.: 57.81%] [G loss: 0.296775]\n",
      "epoch:38 step:35697 [D loss: 0.240897, acc.: 60.94%] [G loss: 0.274009]\n",
      "epoch:38 step:35698 [D loss: 0.228496, acc.: 64.06%] [G loss: 0.308293]\n",
      "epoch:38 step:35699 [D loss: 0.251999, acc.: 56.25%] [G loss: 0.288282]\n",
      "epoch:38 step:35700 [D loss: 0.222121, acc.: 66.41%] [G loss: 0.294763]\n",
      "epoch:38 step:35701 [D loss: 0.247525, acc.: 50.78%] [G loss: 0.321769]\n",
      "epoch:38 step:35702 [D loss: 0.230764, acc.: 63.28%] [G loss: 0.285707]\n",
      "epoch:38 step:35703 [D loss: 0.239516, acc.: 60.16%] [G loss: 0.290654]\n",
      "epoch:38 step:35704 [D loss: 0.224374, acc.: 67.97%] [G loss: 0.267051]\n",
      "epoch:38 step:35705 [D loss: 0.250456, acc.: 57.03%] [G loss: 0.295127]\n",
      "epoch:38 step:35706 [D loss: 0.248613, acc.: 60.16%] [G loss: 0.287286]\n",
      "epoch:38 step:35707 [D loss: 0.242031, acc.: 57.03%] [G loss: 0.307276]\n",
      "epoch:38 step:35708 [D loss: 0.251464, acc.: 58.59%] [G loss: 0.275125]\n",
      "epoch:38 step:35709 [D loss: 0.244426, acc.: 59.38%] [G loss: 0.289120]\n",
      "epoch:38 step:35710 [D loss: 0.238065, acc.: 59.38%] [G loss: 0.302513]\n",
      "epoch:38 step:35711 [D loss: 0.251856, acc.: 51.56%] [G loss: 0.287060]\n",
      "epoch:38 step:35712 [D loss: 0.226362, acc.: 62.50%] [G loss: 0.293050]\n",
      "epoch:38 step:35713 [D loss: 0.246435, acc.: 53.91%] [G loss: 0.321595]\n",
      "epoch:38 step:35714 [D loss: 0.245735, acc.: 55.47%] [G loss: 0.300017]\n",
      "epoch:38 step:35715 [D loss: 0.237067, acc.: 60.94%] [G loss: 0.303847]\n",
      "epoch:38 step:35716 [D loss: 0.233169, acc.: 60.16%] [G loss: 0.310274]\n",
      "epoch:38 step:35717 [D loss: 0.243999, acc.: 53.91%] [G loss: 0.263961]\n",
      "epoch:38 step:35718 [D loss: 0.240923, acc.: 59.38%] [G loss: 0.308201]\n",
      "epoch:38 step:35719 [D loss: 0.249438, acc.: 59.38%] [G loss: 0.285098]\n",
      "epoch:38 step:35720 [D loss: 0.244596, acc.: 51.56%] [G loss: 0.287819]\n",
      "epoch:38 step:35721 [D loss: 0.251951, acc.: 59.38%] [G loss: 0.284403]\n",
      "epoch:38 step:35722 [D loss: 0.229271, acc.: 59.38%] [G loss: 0.268657]\n",
      "epoch:38 step:35723 [D loss: 0.243910, acc.: 58.59%] [G loss: 0.275364]\n",
      "epoch:38 step:35724 [D loss: 0.239741, acc.: 56.25%] [G loss: 0.317789]\n",
      "epoch:38 step:35725 [D loss: 0.247557, acc.: 56.25%] [G loss: 0.309562]\n",
      "epoch:38 step:35726 [D loss: 0.238831, acc.: 55.47%] [G loss: 0.294155]\n",
      "epoch:38 step:35727 [D loss: 0.242148, acc.: 62.50%] [G loss: 0.269495]\n",
      "epoch:38 step:35728 [D loss: 0.226477, acc.: 60.16%] [G loss: 0.326152]\n",
      "epoch:38 step:35729 [D loss: 0.248613, acc.: 56.25%] [G loss: 0.295125]\n",
      "epoch:38 step:35730 [D loss: 0.244833, acc.: 56.25%] [G loss: 0.297017]\n",
      "epoch:38 step:35731 [D loss: 0.236722, acc.: 63.28%] [G loss: 0.290532]\n",
      "epoch:38 step:35732 [D loss: 0.251021, acc.: 51.56%] [G loss: 0.280368]\n",
      "epoch:38 step:35733 [D loss: 0.248430, acc.: 53.91%] [G loss: 0.282890]\n",
      "epoch:38 step:35734 [D loss: 0.246228, acc.: 60.16%] [G loss: 0.296739]\n",
      "epoch:38 step:35735 [D loss: 0.251635, acc.: 56.25%] [G loss: 0.295341]\n",
      "epoch:38 step:35736 [D loss: 0.238959, acc.: 57.03%] [G loss: 0.297310]\n",
      "epoch:38 step:35737 [D loss: 0.238639, acc.: 58.59%] [G loss: 0.287883]\n",
      "epoch:38 step:35738 [D loss: 0.243418, acc.: 57.03%] [G loss: 0.273445]\n",
      "epoch:38 step:35739 [D loss: 0.249543, acc.: 53.12%] [G loss: 0.302727]\n",
      "epoch:38 step:35740 [D loss: 0.237981, acc.: 56.25%] [G loss: 0.289057]\n",
      "epoch:38 step:35741 [D loss: 0.255262, acc.: 57.81%] [G loss: 0.284141]\n",
      "epoch:38 step:35742 [D loss: 0.263344, acc.: 51.56%] [G loss: 0.310461]\n",
      "epoch:38 step:35743 [D loss: 0.223525, acc.: 64.84%] [G loss: 0.300284]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:38 step:35744 [D loss: 0.247535, acc.: 57.81%] [G loss: 0.316355]\n",
      "epoch:38 step:35745 [D loss: 0.236448, acc.: 60.94%] [G loss: 0.304927]\n",
      "epoch:38 step:35746 [D loss: 0.253000, acc.: 52.34%] [G loss: 0.306475]\n",
      "epoch:38 step:35747 [D loss: 0.242702, acc.: 57.03%] [G loss: 0.300998]\n",
      "epoch:38 step:35748 [D loss: 0.247313, acc.: 55.47%] [G loss: 0.282901]\n",
      "epoch:38 step:35749 [D loss: 0.247091, acc.: 53.91%] [G loss: 0.305701]\n",
      "epoch:38 step:35750 [D loss: 0.242986, acc.: 59.38%] [G loss: 0.300084]\n",
      "epoch:38 step:35751 [D loss: 0.215970, acc.: 68.75%] [G loss: 0.305618]\n",
      "epoch:38 step:35752 [D loss: 0.241237, acc.: 58.59%] [G loss: 0.296152]\n",
      "epoch:38 step:35753 [D loss: 0.228199, acc.: 59.38%] [G loss: 0.294064]\n",
      "epoch:38 step:35754 [D loss: 0.227694, acc.: 67.19%] [G loss: 0.314644]\n",
      "epoch:38 step:35755 [D loss: 0.232964, acc.: 60.94%] [G loss: 0.296917]\n",
      "epoch:38 step:35756 [D loss: 0.236507, acc.: 60.16%] [G loss: 0.330668]\n",
      "epoch:38 step:35757 [D loss: 0.234097, acc.: 60.94%] [G loss: 0.328486]\n",
      "epoch:38 step:35758 [D loss: 0.237164, acc.: 64.84%] [G loss: 0.290308]\n",
      "epoch:38 step:35759 [D loss: 0.240456, acc.: 54.69%] [G loss: 0.296978]\n",
      "epoch:38 step:35760 [D loss: 0.244307, acc.: 57.81%] [G loss: 0.301006]\n",
      "epoch:38 step:35761 [D loss: 0.254304, acc.: 50.78%] [G loss: 0.297794]\n",
      "epoch:38 step:35762 [D loss: 0.233697, acc.: 60.16%] [G loss: 0.296005]\n",
      "epoch:38 step:35763 [D loss: 0.251904, acc.: 50.78%] [G loss: 0.279980]\n",
      "epoch:38 step:35764 [D loss: 0.261260, acc.: 53.91%] [G loss: 0.293135]\n",
      "epoch:38 step:35765 [D loss: 0.231127, acc.: 63.28%] [G loss: 0.287819]\n",
      "epoch:38 step:35766 [D loss: 0.226429, acc.: 66.41%] [G loss: 0.294316]\n",
      "epoch:38 step:35767 [D loss: 0.234212, acc.: 57.81%] [G loss: 0.276107]\n",
      "epoch:38 step:35768 [D loss: 0.253543, acc.: 53.91%] [G loss: 0.294927]\n",
      "epoch:38 step:35769 [D loss: 0.253807, acc.: 59.38%] [G loss: 0.289880]\n",
      "epoch:38 step:35770 [D loss: 0.253325, acc.: 54.69%] [G loss: 0.295796]\n",
      "epoch:38 step:35771 [D loss: 0.231319, acc.: 58.59%] [G loss: 0.298511]\n",
      "epoch:38 step:35772 [D loss: 0.235669, acc.: 57.81%] [G loss: 0.303232]\n",
      "epoch:38 step:35773 [D loss: 0.223464, acc.: 67.97%] [G loss: 0.304178]\n",
      "epoch:38 step:35774 [D loss: 0.231407, acc.: 58.59%] [G loss: 0.312920]\n",
      "epoch:38 step:35775 [D loss: 0.229197, acc.: 60.94%] [G loss: 0.305316]\n",
      "epoch:38 step:35776 [D loss: 0.253914, acc.: 56.25%] [G loss: 0.325526]\n",
      "epoch:38 step:35777 [D loss: 0.237693, acc.: 57.81%] [G loss: 0.309414]\n",
      "epoch:38 step:35778 [D loss: 0.217482, acc.: 62.50%] [G loss: 0.298984]\n",
      "epoch:38 step:35779 [D loss: 0.241933, acc.: 56.25%] [G loss: 0.300064]\n",
      "epoch:38 step:35780 [D loss: 0.235479, acc.: 60.94%] [G loss: 0.277045]\n",
      "epoch:38 step:35781 [D loss: 0.265836, acc.: 48.44%] [G loss: 0.312381]\n",
      "epoch:38 step:35782 [D loss: 0.238678, acc.: 55.47%] [G loss: 0.312277]\n",
      "epoch:38 step:35783 [D loss: 0.217986, acc.: 67.97%] [G loss: 0.284703]\n",
      "epoch:38 step:35784 [D loss: 0.218504, acc.: 59.38%] [G loss: 0.294831]\n",
      "epoch:38 step:35785 [D loss: 0.240915, acc.: 54.69%] [G loss: 0.314350]\n",
      "epoch:38 step:35786 [D loss: 0.238793, acc.: 53.12%] [G loss: 0.289073]\n",
      "epoch:38 step:35787 [D loss: 0.230935, acc.: 62.50%] [G loss: 0.278918]\n",
      "epoch:38 step:35788 [D loss: 0.243182, acc.: 56.25%] [G loss: 0.301346]\n",
      "epoch:38 step:35789 [D loss: 0.230107, acc.: 63.28%] [G loss: 0.305091]\n",
      "epoch:38 step:35790 [D loss: 0.253650, acc.: 51.56%] [G loss: 0.299226]\n",
      "epoch:38 step:35791 [D loss: 0.253690, acc.: 51.56%] [G loss: 0.313403]\n",
      "epoch:38 step:35792 [D loss: 0.237552, acc.: 64.06%] [G loss: 0.294285]\n",
      "epoch:38 step:35793 [D loss: 0.231501, acc.: 59.38%] [G loss: 0.304479]\n",
      "epoch:38 step:35794 [D loss: 0.262599, acc.: 51.56%] [G loss: 0.283729]\n",
      "epoch:38 step:35795 [D loss: 0.247368, acc.: 55.47%] [G loss: 0.304198]\n",
      "epoch:38 step:35796 [D loss: 0.238196, acc.: 52.34%] [G loss: 0.279209]\n",
      "epoch:38 step:35797 [D loss: 0.241790, acc.: 57.03%] [G loss: 0.302456]\n",
      "epoch:38 step:35798 [D loss: 0.252628, acc.: 52.34%] [G loss: 0.294224]\n",
      "epoch:38 step:35799 [D loss: 0.246806, acc.: 57.81%] [G loss: 0.255635]\n",
      "epoch:38 step:35800 [D loss: 0.254444, acc.: 52.34%] [G loss: 0.289201]\n",
      "epoch:38 step:35801 [D loss: 0.226395, acc.: 64.06%] [G loss: 0.300468]\n",
      "epoch:38 step:35802 [D loss: 0.251289, acc.: 53.91%] [G loss: 0.295496]\n",
      "epoch:38 step:35803 [D loss: 0.242063, acc.: 56.25%] [G loss: 0.289837]\n",
      "epoch:38 step:35804 [D loss: 0.236843, acc.: 57.81%] [G loss: 0.294714]\n",
      "epoch:38 step:35805 [D loss: 0.233979, acc.: 56.25%] [G loss: 0.306492]\n",
      "epoch:38 step:35806 [D loss: 0.254845, acc.: 53.12%] [G loss: 0.282280]\n",
      "epoch:38 step:35807 [D loss: 0.232206, acc.: 65.62%] [G loss: 0.291459]\n",
      "epoch:38 step:35808 [D loss: 0.226145, acc.: 64.06%] [G loss: 0.270546]\n",
      "epoch:38 step:35809 [D loss: 0.247026, acc.: 55.47%] [G loss: 0.300632]\n",
      "epoch:38 step:35810 [D loss: 0.231785, acc.: 57.81%] [G loss: 0.291720]\n",
      "epoch:38 step:35811 [D loss: 0.230366, acc.: 60.94%] [G loss: 0.311426]\n",
      "epoch:38 step:35812 [D loss: 0.239418, acc.: 53.12%] [G loss: 0.279306]\n",
      "epoch:38 step:35813 [D loss: 0.239800, acc.: 55.47%] [G loss: 0.290358]\n",
      "epoch:38 step:35814 [D loss: 0.236624, acc.: 59.38%] [G loss: 0.279405]\n",
      "epoch:38 step:35815 [D loss: 0.237004, acc.: 63.28%] [G loss: 0.302210]\n",
      "epoch:38 step:35816 [D loss: 0.238659, acc.: 59.38%] [G loss: 0.275278]\n",
      "epoch:38 step:35817 [D loss: 0.241993, acc.: 57.03%] [G loss: 0.298937]\n",
      "epoch:38 step:35818 [D loss: 0.243366, acc.: 57.03%] [G loss: 0.311023]\n",
      "epoch:38 step:35819 [D loss: 0.243908, acc.: 53.91%] [G loss: 0.318029]\n",
      "epoch:38 step:35820 [D loss: 0.246663, acc.: 52.34%] [G loss: 0.300876]\n",
      "epoch:38 step:35821 [D loss: 0.243426, acc.: 56.25%] [G loss: 0.290939]\n",
      "epoch:38 step:35822 [D loss: 0.254614, acc.: 52.34%] [G loss: 0.284787]\n",
      "epoch:38 step:35823 [D loss: 0.244842, acc.: 57.03%] [G loss: 0.287804]\n",
      "epoch:38 step:35824 [D loss: 0.252938, acc.: 49.22%] [G loss: 0.322182]\n",
      "epoch:38 step:35825 [D loss: 0.245063, acc.: 57.81%] [G loss: 0.302562]\n",
      "epoch:38 step:35826 [D loss: 0.235430, acc.: 58.59%] [G loss: 0.301246]\n",
      "epoch:38 step:35827 [D loss: 0.232919, acc.: 57.03%] [G loss: 0.295158]\n",
      "epoch:38 step:35828 [D loss: 0.255386, acc.: 52.34%] [G loss: 0.307811]\n",
      "epoch:38 step:35829 [D loss: 0.242666, acc.: 57.81%] [G loss: 0.298888]\n",
      "epoch:38 step:35830 [D loss: 0.241048, acc.: 54.69%] [G loss: 0.311432]\n",
      "epoch:38 step:35831 [D loss: 0.259735, acc.: 47.66%] [G loss: 0.309815]\n",
      "epoch:38 step:35832 [D loss: 0.243840, acc.: 57.03%] [G loss: 0.311212]\n",
      "epoch:38 step:35833 [D loss: 0.239386, acc.: 57.03%] [G loss: 0.294133]\n",
      "epoch:38 step:35834 [D loss: 0.230775, acc.: 62.50%] [G loss: 0.308405]\n",
      "epoch:38 step:35835 [D loss: 0.228791, acc.: 60.94%] [G loss: 0.329781]\n",
      "epoch:38 step:35836 [D loss: 0.232805, acc.: 67.97%] [G loss: 0.294150]\n",
      "epoch:38 step:35837 [D loss: 0.248706, acc.: 59.38%] [G loss: 0.298178]\n",
      "epoch:38 step:35838 [D loss: 0.251212, acc.: 51.56%] [G loss: 0.277374]\n",
      "epoch:38 step:35839 [D loss: 0.258816, acc.: 49.22%] [G loss: 0.297617]\n",
      "epoch:38 step:35840 [D loss: 0.232402, acc.: 61.72%] [G loss: 0.328024]\n",
      "epoch:38 step:35841 [D loss: 0.251202, acc.: 51.56%] [G loss: 0.292725]\n",
      "epoch:38 step:35842 [D loss: 0.235407, acc.: 58.59%] [G loss: 0.276172]\n",
      "epoch:38 step:35843 [D loss: 0.252230, acc.: 50.00%] [G loss: 0.276048]\n",
      "epoch:38 step:35844 [D loss: 0.239425, acc.: 54.69%] [G loss: 0.303769]\n",
      "epoch:38 step:35845 [D loss: 0.224227, acc.: 62.50%] [G loss: 0.295593]\n",
      "epoch:38 step:35846 [D loss: 0.234593, acc.: 57.81%] [G loss: 0.284755]\n",
      "epoch:38 step:35847 [D loss: 0.232093, acc.: 57.81%] [G loss: 0.301525]\n",
      "epoch:38 step:35848 [D loss: 0.258385, acc.: 51.56%] [G loss: 0.294290]\n",
      "epoch:38 step:35849 [D loss: 0.262407, acc.: 58.59%] [G loss: 0.277479]\n",
      "epoch:38 step:35850 [D loss: 0.247132, acc.: 56.25%] [G loss: 0.298158]\n",
      "epoch:38 step:35851 [D loss: 0.243604, acc.: 57.03%] [G loss: 0.302386]\n",
      "epoch:38 step:35852 [D loss: 0.232080, acc.: 60.94%] [G loss: 0.292703]\n",
      "epoch:38 step:35853 [D loss: 0.233102, acc.: 57.81%] [G loss: 0.330294]\n",
      "epoch:38 step:35854 [D loss: 0.242315, acc.: 57.81%] [G loss: 0.275802]\n",
      "epoch:38 step:35855 [D loss: 0.231658, acc.: 61.72%] [G loss: 0.319214]\n",
      "epoch:38 step:35856 [D loss: 0.233686, acc.: 60.94%] [G loss: 0.282436]\n",
      "epoch:38 step:35857 [D loss: 0.240023, acc.: 55.47%] [G loss: 0.297327]\n",
      "epoch:38 step:35858 [D loss: 0.237303, acc.: 59.38%] [G loss: 0.311909]\n",
      "epoch:38 step:35859 [D loss: 0.230336, acc.: 57.81%] [G loss: 0.292502]\n",
      "epoch:38 step:35860 [D loss: 0.254174, acc.: 50.00%] [G loss: 0.314062]\n",
      "epoch:38 step:35861 [D loss: 0.222915, acc.: 64.06%] [G loss: 0.320531]\n",
      "epoch:38 step:35862 [D loss: 0.227141, acc.: 60.16%] [G loss: 0.302958]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:38 step:35863 [D loss: 0.234871, acc.: 63.28%] [G loss: 0.300653]\n",
      "epoch:38 step:35864 [D loss: 0.247636, acc.: 58.59%] [G loss: 0.288688]\n",
      "epoch:38 step:35865 [D loss: 0.239923, acc.: 56.25%] [G loss: 0.270288]\n",
      "epoch:38 step:35866 [D loss: 0.243001, acc.: 55.47%] [G loss: 0.338264]\n",
      "epoch:38 step:35867 [D loss: 0.238288, acc.: 60.16%] [G loss: 0.322791]\n",
      "epoch:38 step:35868 [D loss: 0.235351, acc.: 60.94%] [G loss: 0.336407]\n",
      "epoch:38 step:35869 [D loss: 0.257951, acc.: 50.00%] [G loss: 0.285110]\n",
      "epoch:38 step:35870 [D loss: 0.238875, acc.: 57.03%] [G loss: 0.296081]\n",
      "epoch:38 step:35871 [D loss: 0.248416, acc.: 59.38%] [G loss: 0.287286]\n",
      "epoch:38 step:35872 [D loss: 0.258821, acc.: 50.78%] [G loss: 0.278030]\n",
      "epoch:38 step:35873 [D loss: 0.250352, acc.: 53.91%] [G loss: 0.281684]\n",
      "epoch:38 step:35874 [D loss: 0.222474, acc.: 62.50%] [G loss: 0.291413]\n",
      "epoch:38 step:35875 [D loss: 0.234260, acc.: 60.16%] [G loss: 0.309718]\n",
      "epoch:38 step:35876 [D loss: 0.247826, acc.: 51.56%] [G loss: 0.285442]\n",
      "epoch:38 step:35877 [D loss: 0.241534, acc.: 61.72%] [G loss: 0.313287]\n",
      "epoch:38 step:35878 [D loss: 0.242674, acc.: 58.59%] [G loss: 0.283869]\n",
      "epoch:38 step:35879 [D loss: 0.240058, acc.: 61.72%] [G loss: 0.300341]\n",
      "epoch:38 step:35880 [D loss: 0.236718, acc.: 59.38%] [G loss: 0.294806]\n",
      "epoch:38 step:35881 [D loss: 0.252327, acc.: 51.56%] [G loss: 0.266491]\n",
      "epoch:38 step:35882 [D loss: 0.246709, acc.: 52.34%] [G loss: 0.292406]\n",
      "epoch:38 step:35883 [D loss: 0.250947, acc.: 50.00%] [G loss: 0.297906]\n",
      "epoch:38 step:35884 [D loss: 0.232328, acc.: 57.81%] [G loss: 0.299591]\n",
      "epoch:38 step:35885 [D loss: 0.235217, acc.: 58.59%] [G loss: 0.321424]\n",
      "epoch:38 step:35886 [D loss: 0.237332, acc.: 60.16%] [G loss: 0.275574]\n",
      "epoch:38 step:35887 [D loss: 0.247924, acc.: 56.25%] [G loss: 0.320332]\n",
      "epoch:38 step:35888 [D loss: 0.243966, acc.: 56.25%] [G loss: 0.314558]\n",
      "epoch:38 step:35889 [D loss: 0.245343, acc.: 57.81%] [G loss: 0.278228]\n",
      "epoch:38 step:35890 [D loss: 0.210158, acc.: 70.31%] [G loss: 0.323713]\n",
      "epoch:38 step:35891 [D loss: 0.246052, acc.: 57.81%] [G loss: 0.278311]\n",
      "epoch:38 step:35892 [D loss: 0.241504, acc.: 52.34%] [G loss: 0.306577]\n",
      "epoch:38 step:35893 [D loss: 0.236861, acc.: 60.16%] [G loss: 0.303282]\n",
      "epoch:38 step:35894 [D loss: 0.247019, acc.: 58.59%] [G loss: 0.312096]\n",
      "epoch:38 step:35895 [D loss: 0.256287, acc.: 51.56%] [G loss: 0.315565]\n",
      "epoch:38 step:35896 [D loss: 0.262321, acc.: 42.19%] [G loss: 0.258869]\n",
      "epoch:38 step:35897 [D loss: 0.240520, acc.: 60.16%] [G loss: 0.278887]\n",
      "epoch:38 step:35898 [D loss: 0.252629, acc.: 57.03%] [G loss: 0.302693]\n",
      "epoch:38 step:35899 [D loss: 0.238604, acc.: 59.38%] [G loss: 0.304536]\n",
      "epoch:38 step:35900 [D loss: 0.254593, acc.: 57.03%] [G loss: 0.288525]\n",
      "epoch:38 step:35901 [D loss: 0.241140, acc.: 60.16%] [G loss: 0.309696]\n",
      "epoch:38 step:35902 [D loss: 0.227969, acc.: 64.06%] [G loss: 0.257301]\n",
      "epoch:38 step:35903 [D loss: 0.237460, acc.: 60.94%] [G loss: 0.297451]\n",
      "epoch:38 step:35904 [D loss: 0.267209, acc.: 45.31%] [G loss: 0.311124]\n",
      "epoch:38 step:35905 [D loss: 0.252400, acc.: 52.34%] [G loss: 0.286238]\n",
      "epoch:38 step:35906 [D loss: 0.227540, acc.: 64.06%] [G loss: 0.290047]\n",
      "epoch:38 step:35907 [D loss: 0.264443, acc.: 48.44%] [G loss: 0.283838]\n",
      "epoch:38 step:35908 [D loss: 0.241600, acc.: 57.81%] [G loss: 0.304661]\n",
      "epoch:38 step:35909 [D loss: 0.246945, acc.: 51.56%] [G loss: 0.279794]\n",
      "epoch:38 step:35910 [D loss: 0.249017, acc.: 50.00%] [G loss: 0.305959]\n",
      "epoch:38 step:35911 [D loss: 0.253203, acc.: 53.91%] [G loss: 0.294272]\n",
      "epoch:38 step:35912 [D loss: 0.238594, acc.: 60.94%] [G loss: 0.295449]\n",
      "epoch:38 step:35913 [D loss: 0.251969, acc.: 51.56%] [G loss: 0.299199]\n",
      "epoch:38 step:35914 [D loss: 0.254924, acc.: 57.81%] [G loss: 0.320934]\n",
      "epoch:38 step:35915 [D loss: 0.238377, acc.: 58.59%] [G loss: 0.291864]\n",
      "epoch:38 step:35916 [D loss: 0.240728, acc.: 57.81%] [G loss: 0.306326]\n",
      "epoch:38 step:35917 [D loss: 0.239656, acc.: 60.16%] [G loss: 0.287051]\n",
      "epoch:38 step:35918 [D loss: 0.250570, acc.: 54.69%] [G loss: 0.305896]\n",
      "epoch:38 step:35919 [D loss: 0.244150, acc.: 54.69%] [G loss: 0.302648]\n",
      "epoch:38 step:35920 [D loss: 0.243499, acc.: 56.25%] [G loss: 0.267388]\n",
      "epoch:38 step:35921 [D loss: 0.250817, acc.: 53.12%] [G loss: 0.273057]\n",
      "epoch:38 step:35922 [D loss: 0.253928, acc.: 53.91%] [G loss: 0.286832]\n",
      "epoch:38 step:35923 [D loss: 0.231563, acc.: 58.59%] [G loss: 0.288397]\n",
      "epoch:38 step:35924 [D loss: 0.240607, acc.: 50.00%] [G loss: 0.289995]\n",
      "epoch:38 step:35925 [D loss: 0.246949, acc.: 51.56%] [G loss: 0.260311]\n",
      "epoch:38 step:35926 [D loss: 0.234918, acc.: 59.38%] [G loss: 0.286543]\n",
      "epoch:38 step:35927 [D loss: 0.235310, acc.: 57.81%] [G loss: 0.285727]\n",
      "epoch:38 step:35928 [D loss: 0.259849, acc.: 52.34%] [G loss: 0.279326]\n",
      "epoch:38 step:35929 [D loss: 0.239504, acc.: 60.16%] [G loss: 0.301163]\n",
      "epoch:38 step:35930 [D loss: 0.233447, acc.: 60.16%] [G loss: 0.271753]\n",
      "epoch:38 step:35931 [D loss: 0.236757, acc.: 59.38%] [G loss: 0.320996]\n",
      "epoch:38 step:35932 [D loss: 0.241791, acc.: 60.94%] [G loss: 0.277399]\n",
      "epoch:38 step:35933 [D loss: 0.243871, acc.: 57.81%] [G loss: 0.285437]\n",
      "epoch:38 step:35934 [D loss: 0.229459, acc.: 63.28%] [G loss: 0.286784]\n",
      "epoch:38 step:35935 [D loss: 0.252043, acc.: 54.69%] [G loss: 0.283517]\n",
      "epoch:38 step:35936 [D loss: 0.229461, acc.: 63.28%] [G loss: 0.325197]\n",
      "epoch:38 step:35937 [D loss: 0.236356, acc.: 55.47%] [G loss: 0.278603]\n",
      "epoch:38 step:35938 [D loss: 0.256677, acc.: 56.25%] [G loss: 0.313181]\n",
      "epoch:38 step:35939 [D loss: 0.251349, acc.: 54.69%] [G loss: 0.308567]\n",
      "epoch:38 step:35940 [D loss: 0.241125, acc.: 60.94%] [G loss: 0.276727]\n",
      "epoch:38 step:35941 [D loss: 0.239764, acc.: 60.94%] [G loss: 0.310646]\n",
      "epoch:38 step:35942 [D loss: 0.245252, acc.: 54.69%] [G loss: 0.284134]\n",
      "epoch:38 step:35943 [D loss: 0.234444, acc.: 63.28%] [G loss: 0.292165]\n",
      "epoch:38 step:35944 [D loss: 0.237373, acc.: 58.59%] [G loss: 0.308054]\n",
      "epoch:38 step:35945 [D loss: 0.243028, acc.: 53.12%] [G loss: 0.303967]\n",
      "epoch:38 step:35946 [D loss: 0.244186, acc.: 50.78%] [G loss: 0.312979]\n",
      "epoch:38 step:35947 [D loss: 0.243041, acc.: 53.12%] [G loss: 0.280031]\n",
      "epoch:38 step:35948 [D loss: 0.238118, acc.: 60.16%] [G loss: 0.274012]\n",
      "epoch:38 step:35949 [D loss: 0.252315, acc.: 54.69%] [G loss: 0.305797]\n",
      "epoch:38 step:35950 [D loss: 0.235338, acc.: 57.81%] [G loss: 0.302853]\n",
      "epoch:38 step:35951 [D loss: 0.234904, acc.: 59.38%] [G loss: 0.311806]\n",
      "epoch:38 step:35952 [D loss: 0.228955, acc.: 60.16%] [G loss: 0.296667]\n",
      "epoch:38 step:35953 [D loss: 0.258765, acc.: 52.34%] [G loss: 0.296730]\n",
      "epoch:38 step:35954 [D loss: 0.230306, acc.: 62.50%] [G loss: 0.259765]\n",
      "epoch:38 step:35955 [D loss: 0.225485, acc.: 64.84%] [G loss: 0.273365]\n",
      "epoch:38 step:35956 [D loss: 0.236678, acc.: 59.38%] [G loss: 0.286112]\n",
      "epoch:38 step:35957 [D loss: 0.252051, acc.: 50.00%] [G loss: 0.309577]\n",
      "epoch:38 step:35958 [D loss: 0.262486, acc.: 45.31%] [G loss: 0.292083]\n",
      "epoch:38 step:35959 [D loss: 0.246393, acc.: 54.69%] [G loss: 0.300528]\n",
      "epoch:38 step:35960 [D loss: 0.244418, acc.: 55.47%] [G loss: 0.275601]\n",
      "epoch:38 step:35961 [D loss: 0.235388, acc.: 60.16%] [G loss: 0.311115]\n",
      "epoch:38 step:35962 [D loss: 0.231317, acc.: 57.03%] [G loss: 0.306532]\n",
      "epoch:38 step:35963 [D loss: 0.251422, acc.: 56.25%] [G loss: 0.293080]\n",
      "epoch:38 step:35964 [D loss: 0.224898, acc.: 67.19%] [G loss: 0.289950]\n",
      "epoch:38 step:35965 [D loss: 0.234908, acc.: 55.47%] [G loss: 0.289274]\n",
      "epoch:38 step:35966 [D loss: 0.225275, acc.: 64.84%] [G loss: 0.274312]\n",
      "epoch:38 step:35967 [D loss: 0.241396, acc.: 58.59%] [G loss: 0.297147]\n",
      "epoch:38 step:35968 [D loss: 0.240224, acc.: 59.38%] [G loss: 0.302629]\n",
      "epoch:38 step:35969 [D loss: 0.247662, acc.: 53.91%] [G loss: 0.279272]\n",
      "epoch:38 step:35970 [D loss: 0.234334, acc.: 62.50%] [G loss: 0.314290]\n",
      "epoch:38 step:35971 [D loss: 0.243027, acc.: 58.59%] [G loss: 0.278623]\n",
      "epoch:38 step:35972 [D loss: 0.256449, acc.: 53.91%] [G loss: 0.297017]\n",
      "epoch:38 step:35973 [D loss: 0.238202, acc.: 62.50%] [G loss: 0.285177]\n",
      "epoch:38 step:35974 [D loss: 0.222917, acc.: 61.72%] [G loss: 0.322813]\n",
      "epoch:38 step:35975 [D loss: 0.242187, acc.: 59.38%] [G loss: 0.295081]\n",
      "epoch:38 step:35976 [D loss: 0.247902, acc.: 52.34%] [G loss: 0.287717]\n",
      "epoch:38 step:35977 [D loss: 0.240196, acc.: 58.59%] [G loss: 0.298518]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:38 step:35978 [D loss: 0.235254, acc.: 57.81%] [G loss: 0.279315]\n",
      "epoch:38 step:35979 [D loss: 0.223752, acc.: 54.69%] [G loss: 0.298356]\n",
      "epoch:38 step:35980 [D loss: 0.229269, acc.: 62.50%] [G loss: 0.301134]\n",
      "epoch:38 step:35981 [D loss: 0.242741, acc.: 59.38%] [G loss: 0.304811]\n",
      "epoch:38 step:35982 [D loss: 0.251963, acc.: 54.69%] [G loss: 0.272129]\n",
      "epoch:38 step:35983 [D loss: 0.232291, acc.: 58.59%] [G loss: 0.254538]\n",
      "epoch:38 step:35984 [D loss: 0.248166, acc.: 52.34%] [G loss: 0.270932]\n",
      "epoch:38 step:35985 [D loss: 0.237811, acc.: 62.50%] [G loss: 0.311459]\n",
      "epoch:38 step:35986 [D loss: 0.233427, acc.: 57.81%] [G loss: 0.291222]\n",
      "epoch:38 step:35987 [D loss: 0.236072, acc.: 58.59%] [G loss: 0.272081]\n",
      "epoch:38 step:35988 [D loss: 0.254852, acc.: 54.69%] [G loss: 0.293705]\n",
      "epoch:38 step:35989 [D loss: 0.228501, acc.: 60.16%] [G loss: 0.275803]\n",
      "epoch:38 step:35990 [D loss: 0.231940, acc.: 57.81%] [G loss: 0.300979]\n",
      "epoch:38 step:35991 [D loss: 0.231765, acc.: 60.16%] [G loss: 0.279703]\n",
      "epoch:38 step:35992 [D loss: 0.213076, acc.: 66.41%] [G loss: 0.300083]\n",
      "epoch:38 step:35993 [D loss: 0.240897, acc.: 57.81%] [G loss: 0.273145]\n",
      "epoch:38 step:35994 [D loss: 0.247209, acc.: 56.25%] [G loss: 0.306627]\n",
      "epoch:38 step:35995 [D loss: 0.251789, acc.: 50.78%] [G loss: 0.306853]\n",
      "epoch:38 step:35996 [D loss: 0.261107, acc.: 52.34%] [G loss: 0.301901]\n",
      "epoch:38 step:35997 [D loss: 0.235015, acc.: 64.06%] [G loss: 0.308493]\n",
      "epoch:38 step:35998 [D loss: 0.243197, acc.: 56.25%] [G loss: 0.284294]\n",
      "epoch:38 step:35999 [D loss: 0.249582, acc.: 53.91%] [G loss: 0.303122]\n",
      "epoch:38 step:36000 [D loss: 0.247274, acc.: 58.59%] [G loss: 0.313204]\n",
      "epoch:38 step:36001 [D loss: 0.220500, acc.: 70.31%] [G loss: 0.296957]\n",
      "epoch:38 step:36002 [D loss: 0.232001, acc.: 63.28%] [G loss: 0.293961]\n",
      "epoch:38 step:36003 [D loss: 0.237078, acc.: 53.12%] [G loss: 0.325553]\n",
      "epoch:38 step:36004 [D loss: 0.233032, acc.: 58.59%] [G loss: 0.301036]\n",
      "epoch:38 step:36005 [D loss: 0.241057, acc.: 60.94%] [G loss: 0.293828]\n",
      "epoch:38 step:36006 [D loss: 0.235470, acc.: 63.28%] [G loss: 0.315044]\n",
      "epoch:38 step:36007 [D loss: 0.228040, acc.: 62.50%] [G loss: 0.309279]\n",
      "epoch:38 step:36008 [D loss: 0.239533, acc.: 54.69%] [G loss: 0.277701]\n",
      "epoch:38 step:36009 [D loss: 0.223164, acc.: 62.50%] [G loss: 0.317540]\n",
      "epoch:38 step:36010 [D loss: 0.255966, acc.: 52.34%] [G loss: 0.318520]\n",
      "epoch:38 step:36011 [D loss: 0.243859, acc.: 57.81%] [G loss: 0.315283]\n",
      "epoch:38 step:36012 [D loss: 0.247726, acc.: 57.81%] [G loss: 0.305606]\n",
      "epoch:38 step:36013 [D loss: 0.249045, acc.: 54.69%] [G loss: 0.328863]\n",
      "epoch:38 step:36014 [D loss: 0.226825, acc.: 64.84%] [G loss: 0.307478]\n",
      "epoch:38 step:36015 [D loss: 0.233561, acc.: 59.38%] [G loss: 0.287177]\n",
      "epoch:38 step:36016 [D loss: 0.235566, acc.: 55.47%] [G loss: 0.321525]\n",
      "epoch:38 step:36017 [D loss: 0.247829, acc.: 54.69%] [G loss: 0.285524]\n",
      "epoch:38 step:36018 [D loss: 0.233785, acc.: 57.81%] [G loss: 0.294145]\n",
      "epoch:38 step:36019 [D loss: 0.238227, acc.: 58.59%] [G loss: 0.289225]\n",
      "epoch:38 step:36020 [D loss: 0.240173, acc.: 57.03%] [G loss: 0.289809]\n",
      "epoch:38 step:36021 [D loss: 0.220502, acc.: 60.94%] [G loss: 0.307531]\n",
      "epoch:38 step:36022 [D loss: 0.254258, acc.: 54.69%] [G loss: 0.297833]\n",
      "epoch:38 step:36023 [D loss: 0.232051, acc.: 62.50%] [G loss: 0.307379]\n",
      "epoch:38 step:36024 [D loss: 0.254350, acc.: 49.22%] [G loss: 0.284749]\n",
      "epoch:38 step:36025 [D loss: 0.237035, acc.: 58.59%] [G loss: 0.288327]\n",
      "epoch:38 step:36026 [D loss: 0.243833, acc.: 53.91%] [G loss: 0.290744]\n",
      "epoch:38 step:36027 [D loss: 0.231172, acc.: 59.38%] [G loss: 0.312368]\n",
      "epoch:38 step:36028 [D loss: 0.235872, acc.: 61.72%] [G loss: 0.274123]\n",
      "epoch:38 step:36029 [D loss: 0.245040, acc.: 52.34%] [G loss: 0.274822]\n",
      "epoch:38 step:36030 [D loss: 0.246496, acc.: 57.03%] [G loss: 0.309856]\n",
      "epoch:38 step:36031 [D loss: 0.235330, acc.: 60.94%] [G loss: 0.258702]\n",
      "epoch:38 step:36032 [D loss: 0.251932, acc.: 52.34%] [G loss: 0.292228]\n",
      "epoch:38 step:36033 [D loss: 0.228297, acc.: 64.06%] [G loss: 0.309705]\n",
      "epoch:38 step:36034 [D loss: 0.231538, acc.: 59.38%] [G loss: 0.300013]\n",
      "epoch:38 step:36035 [D loss: 0.252292, acc.: 56.25%] [G loss: 0.295770]\n",
      "epoch:38 step:36036 [D loss: 0.246733, acc.: 54.69%] [G loss: 0.293320]\n",
      "epoch:38 step:36037 [D loss: 0.252894, acc.: 53.91%] [G loss: 0.293886]\n",
      "epoch:38 step:36038 [D loss: 0.258385, acc.: 46.88%] [G loss: 0.287364]\n",
      "epoch:38 step:36039 [D loss: 0.236232, acc.: 56.25%] [G loss: 0.297755]\n",
      "epoch:38 step:36040 [D loss: 0.250896, acc.: 54.69%] [G loss: 0.297731]\n",
      "epoch:38 step:36041 [D loss: 0.216904, acc.: 64.06%] [G loss: 0.296733]\n",
      "epoch:38 step:36042 [D loss: 0.227048, acc.: 61.72%] [G loss: 0.312175]\n",
      "epoch:38 step:36043 [D loss: 0.239279, acc.: 59.38%] [G loss: 0.320588]\n",
      "epoch:38 step:36044 [D loss: 0.233840, acc.: 62.50%] [G loss: 0.318655]\n",
      "epoch:38 step:36045 [D loss: 0.242972, acc.: 56.25%] [G loss: 0.274482]\n",
      "epoch:38 step:36046 [D loss: 0.228967, acc.: 60.16%] [G loss: 0.308529]\n",
      "epoch:38 step:36047 [D loss: 0.250255, acc.: 57.81%] [G loss: 0.297891]\n",
      "epoch:38 step:36048 [D loss: 0.229428, acc.: 58.59%] [G loss: 0.305496]\n",
      "epoch:38 step:36049 [D loss: 0.232404, acc.: 66.41%] [G loss: 0.277677]\n",
      "epoch:38 step:36050 [D loss: 0.237715, acc.: 60.16%] [G loss: 0.288258]\n",
      "epoch:38 step:36051 [D loss: 0.233030, acc.: 58.59%] [G loss: 0.297258]\n",
      "epoch:38 step:36052 [D loss: 0.234544, acc.: 61.72%] [G loss: 0.308787]\n",
      "epoch:38 step:36053 [D loss: 0.235589, acc.: 56.25%] [G loss: 0.299798]\n",
      "epoch:38 step:36054 [D loss: 0.246970, acc.: 57.81%] [G loss: 0.280462]\n",
      "epoch:38 step:36055 [D loss: 0.254573, acc.: 53.91%] [G loss: 0.299670]\n",
      "epoch:38 step:36056 [D loss: 0.232752, acc.: 60.94%] [G loss: 0.305817]\n",
      "epoch:38 step:36057 [D loss: 0.241916, acc.: 58.59%] [G loss: 0.303253]\n",
      "epoch:38 step:36058 [D loss: 0.237525, acc.: 60.16%] [G loss: 0.290163]\n",
      "epoch:38 step:36059 [D loss: 0.223917, acc.: 64.06%] [G loss: 0.290295]\n",
      "epoch:38 step:36060 [D loss: 0.231475, acc.: 64.06%] [G loss: 0.287717]\n",
      "epoch:38 step:36061 [D loss: 0.243805, acc.: 57.81%] [G loss: 0.265105]\n",
      "epoch:38 step:36062 [D loss: 0.274129, acc.: 52.34%] [G loss: 0.301153]\n",
      "epoch:38 step:36063 [D loss: 0.254571, acc.: 51.56%] [G loss: 0.310388]\n",
      "epoch:38 step:36064 [D loss: 0.247442, acc.: 53.91%] [G loss: 0.262381]\n",
      "epoch:38 step:36065 [D loss: 0.236328, acc.: 59.38%] [G loss: 0.315621]\n",
      "epoch:38 step:36066 [D loss: 0.244825, acc.: 57.81%] [G loss: 0.325255]\n",
      "epoch:38 step:36067 [D loss: 0.229240, acc.: 63.28%] [G loss: 0.296347]\n",
      "epoch:38 step:36068 [D loss: 0.243595, acc.: 50.78%] [G loss: 0.289267]\n",
      "epoch:38 step:36069 [D loss: 0.240159, acc.: 58.59%] [G loss: 0.305322]\n",
      "epoch:38 step:36070 [D loss: 0.256050, acc.: 52.34%] [G loss: 0.278882]\n",
      "epoch:38 step:36071 [D loss: 0.254846, acc.: 54.69%] [G loss: 0.277736]\n",
      "epoch:38 step:36072 [D loss: 0.253018, acc.: 51.56%] [G loss: 0.285931]\n",
      "epoch:38 step:36073 [D loss: 0.237332, acc.: 62.50%] [G loss: 0.278449]\n",
      "epoch:38 step:36074 [D loss: 0.234866, acc.: 54.69%] [G loss: 0.322741]\n",
      "epoch:38 step:36075 [D loss: 0.245310, acc.: 58.59%] [G loss: 0.274910]\n",
      "epoch:38 step:36076 [D loss: 0.252900, acc.: 52.34%] [G loss: 0.309115]\n",
      "epoch:38 step:36077 [D loss: 0.263944, acc.: 46.88%] [G loss: 0.313123]\n",
      "epoch:38 step:36078 [D loss: 0.229017, acc.: 63.28%] [G loss: 0.298541]\n",
      "epoch:38 step:36079 [D loss: 0.228014, acc.: 66.41%] [G loss: 0.293757]\n",
      "epoch:38 step:36080 [D loss: 0.232301, acc.: 58.59%] [G loss: 0.272620]\n",
      "epoch:38 step:36081 [D loss: 0.234582, acc.: 57.81%] [G loss: 0.316558]\n",
      "epoch:38 step:36082 [D loss: 0.243693, acc.: 50.00%] [G loss: 0.285692]\n",
      "epoch:38 step:36083 [D loss: 0.257756, acc.: 48.44%] [G loss: 0.304336]\n",
      "epoch:38 step:36084 [D loss: 0.237379, acc.: 61.72%] [G loss: 0.305224]\n",
      "epoch:38 step:36085 [D loss: 0.256111, acc.: 51.56%] [G loss: 0.298572]\n",
      "epoch:38 step:36086 [D loss: 0.241735, acc.: 56.25%] [G loss: 0.309625]\n",
      "epoch:38 step:36087 [D loss: 0.224787, acc.: 69.53%] [G loss: 0.300509]\n",
      "epoch:38 step:36088 [D loss: 0.257195, acc.: 53.91%] [G loss: 0.305182]\n",
      "epoch:38 step:36089 [D loss: 0.244719, acc.: 56.25%] [G loss: 0.289598]\n",
      "epoch:38 step:36090 [D loss: 0.224964, acc.: 64.06%] [G loss: 0.273928]\n",
      "epoch:38 step:36091 [D loss: 0.238632, acc.: 55.47%] [G loss: 0.305584]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:38 step:36092 [D loss: 0.234045, acc.: 58.59%] [G loss: 0.296513]\n",
      "epoch:38 step:36093 [D loss: 0.245155, acc.: 57.81%] [G loss: 0.277496]\n",
      "epoch:38 step:36094 [D loss: 0.229462, acc.: 60.16%] [G loss: 0.296999]\n",
      "epoch:38 step:36095 [D loss: 0.245631, acc.: 56.25%] [G loss: 0.299549]\n",
      "epoch:38 step:36096 [D loss: 0.232008, acc.: 59.38%] [G loss: 0.276789]\n",
      "epoch:38 step:36097 [D loss: 0.247041, acc.: 57.03%] [G loss: 0.297159]\n",
      "epoch:38 step:36098 [D loss: 0.237596, acc.: 61.72%] [G loss: 0.317148]\n",
      "epoch:38 step:36099 [D loss: 0.228352, acc.: 64.84%] [G loss: 0.314710]\n",
      "epoch:38 step:36100 [D loss: 0.239909, acc.: 57.03%] [G loss: 0.282817]\n",
      "epoch:38 step:36101 [D loss: 0.237695, acc.: 60.16%] [G loss: 0.291791]\n",
      "epoch:38 step:36102 [D loss: 0.239900, acc.: 50.78%] [G loss: 0.312432]\n",
      "epoch:38 step:36103 [D loss: 0.223990, acc.: 64.06%] [G loss: 0.314892]\n",
      "epoch:38 step:36104 [D loss: 0.228767, acc.: 63.28%] [G loss: 0.308897]\n",
      "epoch:38 step:36105 [D loss: 0.232596, acc.: 60.94%] [G loss: 0.297885]\n",
      "epoch:38 step:36106 [D loss: 0.239402, acc.: 60.94%] [G loss: 0.279376]\n",
      "epoch:38 step:36107 [D loss: 0.225176, acc.: 62.50%] [G loss: 0.286070]\n",
      "epoch:38 step:36108 [D loss: 0.236953, acc.: 60.94%] [G loss: 0.310682]\n",
      "epoch:38 step:36109 [D loss: 0.244677, acc.: 58.59%] [G loss: 0.295019]\n",
      "epoch:38 step:36110 [D loss: 0.212280, acc.: 67.19%] [G loss: 0.330020]\n",
      "epoch:38 step:36111 [D loss: 0.226596, acc.: 67.19%] [G loss: 0.302528]\n",
      "epoch:38 step:36112 [D loss: 0.256820, acc.: 51.56%] [G loss: 0.316615]\n",
      "epoch:38 step:36113 [D loss: 0.241174, acc.: 55.47%] [G loss: 0.296564]\n",
      "epoch:38 step:36114 [D loss: 0.241008, acc.: 55.47%] [G loss: 0.270598]\n",
      "epoch:38 step:36115 [D loss: 0.240197, acc.: 53.91%] [G loss: 0.279060]\n",
      "epoch:38 step:36116 [D loss: 0.238245, acc.: 57.81%] [G loss: 0.291633]\n",
      "epoch:38 step:36117 [D loss: 0.250025, acc.: 52.34%] [G loss: 0.286992]\n",
      "epoch:38 step:36118 [D loss: 0.250191, acc.: 51.56%] [G loss: 0.306512]\n",
      "epoch:38 step:36119 [D loss: 0.219446, acc.: 64.06%] [G loss: 0.291160]\n",
      "epoch:38 step:36120 [D loss: 0.260260, acc.: 49.22%] [G loss: 0.296558]\n",
      "epoch:38 step:36121 [D loss: 0.213608, acc.: 67.19%] [G loss: 0.299751]\n",
      "epoch:38 step:36122 [D loss: 0.231732, acc.: 61.72%] [G loss: 0.302833]\n",
      "epoch:38 step:36123 [D loss: 0.237947, acc.: 57.81%] [G loss: 0.329832]\n",
      "epoch:38 step:36124 [D loss: 0.238953, acc.: 54.69%] [G loss: 0.316198]\n",
      "epoch:38 step:36125 [D loss: 0.235385, acc.: 62.50%] [G loss: 0.290152]\n",
      "epoch:38 step:36126 [D loss: 0.232823, acc.: 60.94%] [G loss: 0.323373]\n",
      "epoch:38 step:36127 [D loss: 0.235474, acc.: 58.59%] [G loss: 0.304464]\n",
      "epoch:38 step:36128 [D loss: 0.231894, acc.: 58.59%] [G loss: 0.321170]\n",
      "epoch:38 step:36129 [D loss: 0.241239, acc.: 59.38%] [G loss: 0.306377]\n",
      "epoch:38 step:36130 [D loss: 0.219787, acc.: 67.97%] [G loss: 0.279452]\n",
      "epoch:38 step:36131 [D loss: 0.232241, acc.: 60.94%] [G loss: 0.311728]\n",
      "epoch:38 step:36132 [D loss: 0.223886, acc.: 64.84%] [G loss: 0.311598]\n",
      "epoch:38 step:36133 [D loss: 0.247899, acc.: 48.44%] [G loss: 0.313376]\n",
      "epoch:38 step:36134 [D loss: 0.223618, acc.: 66.41%] [G loss: 0.290454]\n",
      "epoch:38 step:36135 [D loss: 0.240169, acc.: 59.38%] [G loss: 0.316152]\n",
      "epoch:38 step:36136 [D loss: 0.249250, acc.: 54.69%] [G loss: 0.303201]\n",
      "epoch:38 step:36137 [D loss: 0.248755, acc.: 54.69%] [G loss: 0.282922]\n",
      "epoch:38 step:36138 [D loss: 0.250143, acc.: 50.78%] [G loss: 0.289982]\n",
      "epoch:38 step:36139 [D loss: 0.235980, acc.: 60.16%] [G loss: 0.323331]\n",
      "epoch:38 step:36140 [D loss: 0.249429, acc.: 53.12%] [G loss: 0.315837]\n",
      "epoch:38 step:36141 [D loss: 0.238210, acc.: 60.94%] [G loss: 0.291823]\n",
      "epoch:38 step:36142 [D loss: 0.248979, acc.: 53.12%] [G loss: 0.282809]\n",
      "epoch:38 step:36143 [D loss: 0.252058, acc.: 54.69%] [G loss: 0.279689]\n",
      "epoch:38 step:36144 [D loss: 0.248591, acc.: 58.59%] [G loss: 0.258428]\n",
      "epoch:38 step:36145 [D loss: 0.248989, acc.: 55.47%] [G loss: 0.279074]\n",
      "epoch:38 step:36146 [D loss: 0.244176, acc.: 55.47%] [G loss: 0.289062]\n",
      "epoch:38 step:36147 [D loss: 0.245652, acc.: 57.81%] [G loss: 0.265157]\n",
      "epoch:38 step:36148 [D loss: 0.252451, acc.: 53.91%] [G loss: 0.294458]\n",
      "epoch:38 step:36149 [D loss: 0.232235, acc.: 60.94%] [G loss: 0.292510]\n",
      "epoch:38 step:36150 [D loss: 0.251205, acc.: 50.00%] [G loss: 0.275468]\n",
      "epoch:38 step:36151 [D loss: 0.233482, acc.: 58.59%] [G loss: 0.293742]\n",
      "epoch:38 step:36152 [D loss: 0.239835, acc.: 56.25%] [G loss: 0.288718]\n",
      "epoch:38 step:36153 [D loss: 0.262987, acc.: 44.53%] [G loss: 0.288775]\n",
      "epoch:38 step:36154 [D loss: 0.238089, acc.: 53.12%] [G loss: 0.277706]\n",
      "epoch:38 step:36155 [D loss: 0.236402, acc.: 56.25%] [G loss: 0.280283]\n",
      "epoch:38 step:36156 [D loss: 0.238714, acc.: 54.69%] [G loss: 0.273693]\n",
      "epoch:38 step:36157 [D loss: 0.239377, acc.: 50.00%] [G loss: 0.299327]\n",
      "epoch:38 step:36158 [D loss: 0.258009, acc.: 57.03%] [G loss: 0.307271]\n",
      "epoch:38 step:36159 [D loss: 0.241749, acc.: 55.47%] [G loss: 0.272816]\n",
      "epoch:38 step:36160 [D loss: 0.239753, acc.: 56.25%] [G loss: 0.312171]\n",
      "epoch:38 step:36161 [D loss: 0.232767, acc.: 57.81%] [G loss: 0.314374]\n",
      "epoch:38 step:36162 [D loss: 0.230983, acc.: 60.16%] [G loss: 0.270482]\n",
      "epoch:38 step:36163 [D loss: 0.250737, acc.: 53.12%] [G loss: 0.312681]\n",
      "epoch:38 step:36164 [D loss: 0.252873, acc.: 50.78%] [G loss: 0.294620]\n",
      "epoch:38 step:36165 [D loss: 0.237337, acc.: 60.16%] [G loss: 0.324259]\n",
      "epoch:38 step:36166 [D loss: 0.248520, acc.: 55.47%] [G loss: 0.281421]\n",
      "epoch:38 step:36167 [D loss: 0.242675, acc.: 55.47%] [G loss: 0.295561]\n",
      "epoch:38 step:36168 [D loss: 0.236274, acc.: 57.81%] [G loss: 0.306331]\n",
      "epoch:38 step:36169 [D loss: 0.230198, acc.: 64.84%] [G loss: 0.275513]\n",
      "epoch:38 step:36170 [D loss: 0.235482, acc.: 60.16%] [G loss: 0.284047]\n",
      "epoch:38 step:36171 [D loss: 0.251513, acc.: 54.69%] [G loss: 0.284522]\n",
      "epoch:38 step:36172 [D loss: 0.241754, acc.: 60.94%] [G loss: 0.296578]\n",
      "epoch:38 step:36173 [D loss: 0.236279, acc.: 55.47%] [G loss: 0.316329]\n",
      "epoch:38 step:36174 [D loss: 0.251466, acc.: 57.81%] [G loss: 0.290680]\n",
      "epoch:38 step:36175 [D loss: 0.245947, acc.: 58.59%] [G loss: 0.287052]\n",
      "epoch:38 step:36176 [D loss: 0.237212, acc.: 56.25%] [G loss: 0.299991]\n",
      "epoch:38 step:36177 [D loss: 0.247762, acc.: 54.69%] [G loss: 0.320443]\n",
      "epoch:38 step:36178 [D loss: 0.232219, acc.: 60.16%] [G loss: 0.285198]\n",
      "epoch:38 step:36179 [D loss: 0.238433, acc.: 64.06%] [G loss: 0.283720]\n",
      "epoch:38 step:36180 [D loss: 0.257484, acc.: 51.56%] [G loss: 0.296199]\n",
      "epoch:38 step:36181 [D loss: 0.250812, acc.: 54.69%] [G loss: 0.269712]\n",
      "epoch:38 step:36182 [D loss: 0.230764, acc.: 62.50%] [G loss: 0.298266]\n",
      "epoch:38 step:36183 [D loss: 0.238917, acc.: 60.16%] [G loss: 0.291359]\n",
      "epoch:38 step:36184 [D loss: 0.251626, acc.: 57.03%] [G loss: 0.304324]\n",
      "epoch:38 step:36185 [D loss: 0.241263, acc.: 57.81%] [G loss: 0.288873]\n",
      "epoch:38 step:36186 [D loss: 0.231913, acc.: 63.28%] [G loss: 0.282156]\n",
      "epoch:38 step:36187 [D loss: 0.243742, acc.: 57.03%] [G loss: 0.289647]\n",
      "epoch:38 step:36188 [D loss: 0.246708, acc.: 60.16%] [G loss: 0.288521]\n",
      "epoch:38 step:36189 [D loss: 0.258816, acc.: 46.09%] [G loss: 0.275530]\n",
      "epoch:38 step:36190 [D loss: 0.233187, acc.: 63.28%] [G loss: 0.276700]\n",
      "epoch:38 step:36191 [D loss: 0.240127, acc.: 53.12%] [G loss: 0.331114]\n",
      "epoch:38 step:36192 [D loss: 0.223529, acc.: 67.97%] [G loss: 0.271747]\n",
      "epoch:38 step:36193 [D loss: 0.241974, acc.: 61.72%] [G loss: 0.292515]\n",
      "epoch:38 step:36194 [D loss: 0.250242, acc.: 53.12%] [G loss: 0.277409]\n",
      "epoch:38 step:36195 [D loss: 0.228975, acc.: 66.41%] [G loss: 0.284509]\n",
      "epoch:38 step:36196 [D loss: 0.243644, acc.: 53.12%] [G loss: 0.295611]\n",
      "epoch:38 step:36197 [D loss: 0.231126, acc.: 62.50%] [G loss: 0.305238]\n",
      "epoch:38 step:36198 [D loss: 0.250692, acc.: 52.34%] [G loss: 0.289836]\n",
      "epoch:38 step:36199 [D loss: 0.223724, acc.: 64.84%] [G loss: 0.312993]\n",
      "epoch:38 step:36200 [D loss: 0.246076, acc.: 57.81%] [G loss: 0.286679]\n",
      "epoch:38 step:36201 [D loss: 0.233624, acc.: 57.03%] [G loss: 0.318732]\n",
      "epoch:38 step:36202 [D loss: 0.232725, acc.: 56.25%] [G loss: 0.305408]\n",
      "epoch:38 step:36203 [D loss: 0.226233, acc.: 63.28%] [G loss: 0.281877]\n",
      "epoch:38 step:36204 [D loss: 0.235942, acc.: 58.59%] [G loss: 0.352979]\n",
      "epoch:38 step:36205 [D loss: 0.233099, acc.: 60.16%] [G loss: 0.301428]\n",
      "epoch:38 step:36206 [D loss: 0.244413, acc.: 56.25%] [G loss: 0.318979]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:38 step:36207 [D loss: 0.243352, acc.: 64.06%] [G loss: 0.314539]\n",
      "epoch:38 step:36208 [D loss: 0.228811, acc.: 61.72%] [G loss: 0.331105]\n",
      "epoch:38 step:36209 [D loss: 0.267754, acc.: 47.66%] [G loss: 0.288865]\n",
      "epoch:38 step:36210 [D loss: 0.242130, acc.: 57.81%] [G loss: 0.285575]\n",
      "epoch:38 step:36211 [D loss: 0.249533, acc.: 57.03%] [G loss: 0.282858]\n",
      "epoch:38 step:36212 [D loss: 0.246811, acc.: 52.34%] [G loss: 0.287686]\n",
      "epoch:38 step:36213 [D loss: 0.241705, acc.: 57.81%] [G loss: 0.311095]\n",
      "epoch:38 step:36214 [D loss: 0.230374, acc.: 63.28%] [G loss: 0.293158]\n",
      "epoch:38 step:36215 [D loss: 0.231876, acc.: 58.59%] [G loss: 0.302661]\n",
      "epoch:38 step:36216 [D loss: 0.232286, acc.: 58.59%] [G loss: 0.292808]\n",
      "epoch:38 step:36217 [D loss: 0.250407, acc.: 56.25%] [G loss: 0.278549]\n",
      "epoch:38 step:36218 [D loss: 0.255413, acc.: 53.12%] [G loss: 0.300160]\n",
      "epoch:38 step:36219 [D loss: 0.233840, acc.: 60.94%] [G loss: 0.310388]\n",
      "epoch:38 step:36220 [D loss: 0.241667, acc.: 55.47%] [G loss: 0.282463]\n",
      "epoch:38 step:36221 [D loss: 0.245569, acc.: 54.69%] [G loss: 0.265781]\n",
      "epoch:38 step:36222 [D loss: 0.237715, acc.: 58.59%] [G loss: 0.301177]\n",
      "epoch:38 step:36223 [D loss: 0.257992, acc.: 51.56%] [G loss: 0.273520]\n",
      "epoch:38 step:36224 [D loss: 0.242855, acc.: 57.03%] [G loss: 0.307615]\n",
      "epoch:38 step:36225 [D loss: 0.247321, acc.: 56.25%] [G loss: 0.282034]\n",
      "epoch:38 step:36226 [D loss: 0.251581, acc.: 54.69%] [G loss: 0.306547]\n",
      "epoch:38 step:36227 [D loss: 0.272444, acc.: 39.84%] [G loss: 0.294971]\n",
      "epoch:38 step:36228 [D loss: 0.234646, acc.: 62.50%] [G loss: 0.275281]\n",
      "epoch:38 step:36229 [D loss: 0.234720, acc.: 57.03%] [G loss: 0.287399]\n",
      "epoch:38 step:36230 [D loss: 0.251081, acc.: 51.56%] [G loss: 0.289485]\n",
      "epoch:38 step:36231 [D loss: 0.229769, acc.: 62.50%] [G loss: 0.294399]\n",
      "epoch:38 step:36232 [D loss: 0.236047, acc.: 56.25%] [G loss: 0.314950]\n",
      "epoch:38 step:36233 [D loss: 0.252207, acc.: 53.12%] [G loss: 0.268852]\n",
      "epoch:38 step:36234 [D loss: 0.250948, acc.: 55.47%] [G loss: 0.290114]\n",
      "epoch:38 step:36235 [D loss: 0.258434, acc.: 52.34%] [G loss: 0.281493]\n",
      "epoch:38 step:36236 [D loss: 0.243644, acc.: 54.69%] [G loss: 0.296042]\n",
      "epoch:38 step:36237 [D loss: 0.252304, acc.: 54.69%] [G loss: 0.283294]\n",
      "epoch:38 step:36238 [D loss: 0.255390, acc.: 51.56%] [G loss: 0.292387]\n",
      "epoch:38 step:36239 [D loss: 0.228937, acc.: 59.38%] [G loss: 0.301888]\n",
      "epoch:38 step:36240 [D loss: 0.224681, acc.: 64.06%] [G loss: 0.314606]\n",
      "epoch:38 step:36241 [D loss: 0.234699, acc.: 57.03%] [G loss: 0.300662]\n",
      "epoch:38 step:36242 [D loss: 0.226735, acc.: 61.72%] [G loss: 0.311721]\n",
      "epoch:38 step:36243 [D loss: 0.237580, acc.: 60.94%] [G loss: 0.312191]\n",
      "epoch:38 step:36244 [D loss: 0.229749, acc.: 59.38%] [G loss: 0.293880]\n",
      "epoch:38 step:36245 [D loss: 0.232853, acc.: 60.94%] [G loss: 0.306254]\n",
      "epoch:38 step:36246 [D loss: 0.244656, acc.: 57.81%] [G loss: 0.271932]\n",
      "epoch:38 step:36247 [D loss: 0.222240, acc.: 63.28%] [G loss: 0.310779]\n",
      "epoch:38 step:36248 [D loss: 0.249189, acc.: 50.00%] [G loss: 0.287903]\n",
      "epoch:38 step:36249 [D loss: 0.258533, acc.: 48.44%] [G loss: 0.278628]\n",
      "epoch:38 step:36250 [D loss: 0.243104, acc.: 54.69%] [G loss: 0.304524]\n",
      "epoch:38 step:36251 [D loss: 0.225792, acc.: 60.16%] [G loss: 0.323826]\n",
      "epoch:38 step:36252 [D loss: 0.242828, acc.: 57.03%] [G loss: 0.319417]\n",
      "epoch:38 step:36253 [D loss: 0.247969, acc.: 50.78%] [G loss: 0.277468]\n",
      "epoch:38 step:36254 [D loss: 0.230282, acc.: 57.03%] [G loss: 0.284804]\n",
      "epoch:38 step:36255 [D loss: 0.239064, acc.: 60.94%] [G loss: 0.302198]\n",
      "epoch:38 step:36256 [D loss: 0.237173, acc.: 59.38%] [G loss: 0.296852]\n",
      "epoch:38 step:36257 [D loss: 0.244055, acc.: 56.25%] [G loss: 0.307951]\n",
      "epoch:38 step:36258 [D loss: 0.242856, acc.: 59.38%] [G loss: 0.302629]\n",
      "epoch:38 step:36259 [D loss: 0.249454, acc.: 55.47%] [G loss: 0.286467]\n",
      "epoch:38 step:36260 [D loss: 0.253093, acc.: 55.47%] [G loss: 0.293803]\n",
      "epoch:38 step:36261 [D loss: 0.233308, acc.: 62.50%] [G loss: 0.295544]\n",
      "epoch:38 step:36262 [D loss: 0.215416, acc.: 60.94%] [G loss: 0.260494]\n",
      "epoch:38 step:36263 [D loss: 0.236695, acc.: 61.72%] [G loss: 0.265557]\n",
      "epoch:38 step:36264 [D loss: 0.250950, acc.: 56.25%] [G loss: 0.302171]\n",
      "epoch:38 step:36265 [D loss: 0.231783, acc.: 60.94%] [G loss: 0.286796]\n",
      "epoch:38 step:36266 [D loss: 0.229836, acc.: 63.28%] [G loss: 0.296832]\n",
      "epoch:38 step:36267 [D loss: 0.236633, acc.: 63.28%] [G loss: 0.298003]\n",
      "epoch:38 step:36268 [D loss: 0.244381, acc.: 60.94%] [G loss: 0.303715]\n",
      "epoch:38 step:36269 [D loss: 0.245027, acc.: 56.25%] [G loss: 0.317821]\n",
      "epoch:38 step:36270 [D loss: 0.249425, acc.: 53.91%] [G loss: 0.277433]\n",
      "epoch:38 step:36271 [D loss: 0.255492, acc.: 56.25%] [G loss: 0.277393]\n",
      "epoch:38 step:36272 [D loss: 0.230702, acc.: 65.62%] [G loss: 0.270364]\n",
      "epoch:38 step:36273 [D loss: 0.218079, acc.: 69.53%] [G loss: 0.284639]\n",
      "epoch:38 step:36274 [D loss: 0.229178, acc.: 62.50%] [G loss: 0.292319]\n",
      "epoch:38 step:36275 [D loss: 0.249334, acc.: 57.03%] [G loss: 0.306885]\n",
      "epoch:38 step:36276 [D loss: 0.229505, acc.: 63.28%] [G loss: 0.299633]\n",
      "epoch:38 step:36277 [D loss: 0.248617, acc.: 54.69%] [G loss: 0.282898]\n",
      "epoch:38 step:36278 [D loss: 0.249991, acc.: 51.56%] [G loss: 0.295262]\n",
      "epoch:38 step:36279 [D loss: 0.257747, acc.: 52.34%] [G loss: 0.288645]\n",
      "epoch:38 step:36280 [D loss: 0.235898, acc.: 62.50%] [G loss: 0.295461]\n",
      "epoch:38 step:36281 [D loss: 0.223388, acc.: 62.50%] [G loss: 0.313375]\n",
      "epoch:38 step:36282 [D loss: 0.241082, acc.: 57.03%] [G loss: 0.301504]\n",
      "epoch:38 step:36283 [D loss: 0.238917, acc.: 56.25%] [G loss: 0.274537]\n",
      "epoch:38 step:36284 [D loss: 0.235644, acc.: 60.16%] [G loss: 0.309467]\n",
      "epoch:38 step:36285 [D loss: 0.230685, acc.: 61.72%] [G loss: 0.301996]\n",
      "epoch:38 step:36286 [D loss: 0.243832, acc.: 56.25%] [G loss: 0.299711]\n",
      "epoch:38 step:36287 [D loss: 0.224603, acc.: 63.28%] [G loss: 0.293038]\n",
      "epoch:38 step:36288 [D loss: 0.223954, acc.: 63.28%] [G loss: 0.295503]\n",
      "epoch:38 step:36289 [D loss: 0.248739, acc.: 53.91%] [G loss: 0.293927]\n",
      "epoch:38 step:36290 [D loss: 0.250680, acc.: 50.00%] [G loss: 0.280839]\n",
      "epoch:38 step:36291 [D loss: 0.237267, acc.: 62.50%] [G loss: 0.298572]\n",
      "epoch:38 step:36292 [D loss: 0.240582, acc.: 60.16%] [G loss: 0.293337]\n",
      "epoch:38 step:36293 [D loss: 0.246124, acc.: 53.12%] [G loss: 0.280868]\n",
      "epoch:38 step:36294 [D loss: 0.229767, acc.: 63.28%] [G loss: 0.312536]\n",
      "epoch:38 step:36295 [D loss: 0.244597, acc.: 60.94%] [G loss: 0.278653]\n",
      "epoch:38 step:36296 [D loss: 0.241528, acc.: 54.69%] [G loss: 0.287026]\n",
      "epoch:38 step:36297 [D loss: 0.223967, acc.: 65.62%] [G loss: 0.303665]\n",
      "epoch:38 step:36298 [D loss: 0.255603, acc.: 53.12%] [G loss: 0.306308]\n",
      "epoch:38 step:36299 [D loss: 0.239410, acc.: 57.03%] [G loss: 0.305438]\n",
      "epoch:38 step:36300 [D loss: 0.261698, acc.: 49.22%] [G loss: 0.265670]\n",
      "epoch:38 step:36301 [D loss: 0.234965, acc.: 57.03%] [G loss: 0.326510]\n",
      "epoch:38 step:36302 [D loss: 0.240764, acc.: 54.69%] [G loss: 0.285879]\n",
      "epoch:38 step:36303 [D loss: 0.239137, acc.: 56.25%] [G loss: 0.291006]\n",
      "epoch:38 step:36304 [D loss: 0.231196, acc.: 64.06%] [G loss: 0.311041]\n",
      "epoch:38 step:36305 [D loss: 0.257167, acc.: 54.69%] [G loss: 0.273831]\n",
      "epoch:38 step:36306 [D loss: 0.230372, acc.: 60.94%] [G loss: 0.285511]\n",
      "epoch:38 step:36307 [D loss: 0.248791, acc.: 56.25%] [G loss: 0.312697]\n",
      "epoch:38 step:36308 [D loss: 0.218238, acc.: 69.53%] [G loss: 0.321976]\n",
      "epoch:38 step:36309 [D loss: 0.237529, acc.: 53.12%] [G loss: 0.289353]\n",
      "epoch:38 step:36310 [D loss: 0.248785, acc.: 51.56%] [G loss: 0.289609]\n",
      "epoch:38 step:36311 [D loss: 0.232859, acc.: 61.72%] [G loss: 0.283992]\n",
      "epoch:38 step:36312 [D loss: 0.237332, acc.: 56.25%] [G loss: 0.279620]\n",
      "epoch:38 step:36313 [D loss: 0.218531, acc.: 65.62%] [G loss: 0.312017]\n",
      "epoch:38 step:36314 [D loss: 0.246885, acc.: 53.91%] [G loss: 0.294323]\n",
      "epoch:38 step:36315 [D loss: 0.246184, acc.: 55.47%] [G loss: 0.281525]\n",
      "epoch:38 step:36316 [D loss: 0.216694, acc.: 65.62%] [G loss: 0.296095]\n",
      "epoch:38 step:36317 [D loss: 0.228470, acc.: 60.16%] [G loss: 0.287935]\n",
      "epoch:38 step:36318 [D loss: 0.242628, acc.: 57.81%] [G loss: 0.300559]\n",
      "epoch:38 step:36319 [D loss: 0.227052, acc.: 60.16%] [G loss: 0.292920]\n",
      "epoch:38 step:36320 [D loss: 0.252612, acc.: 55.47%] [G loss: 0.306889]\n",
      "epoch:38 step:36321 [D loss: 0.240027, acc.: 57.81%] [G loss: 0.311192]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:38 step:36322 [D loss: 0.233324, acc.: 62.50%] [G loss: 0.301227]\n",
      "epoch:38 step:36323 [D loss: 0.239194, acc.: 63.28%] [G loss: 0.294071]\n",
      "epoch:38 step:36324 [D loss: 0.216367, acc.: 71.09%] [G loss: 0.306425]\n",
      "epoch:38 step:36325 [D loss: 0.244727, acc.: 56.25%] [G loss: 0.299706]\n",
      "epoch:38 step:36326 [D loss: 0.241787, acc.: 55.47%] [G loss: 0.283229]\n",
      "epoch:38 step:36327 [D loss: 0.244801, acc.: 51.56%] [G loss: 0.294091]\n",
      "epoch:38 step:36328 [D loss: 0.254059, acc.: 53.91%] [G loss: 0.279017]\n",
      "epoch:38 step:36329 [D loss: 0.235221, acc.: 59.38%] [G loss: 0.289025]\n",
      "epoch:38 step:36330 [D loss: 0.243366, acc.: 60.94%] [G loss: 0.285340]\n",
      "epoch:38 step:36331 [D loss: 0.236331, acc.: 63.28%] [G loss: 0.283730]\n",
      "epoch:38 step:36332 [D loss: 0.241950, acc.: 55.47%] [G loss: 0.288073]\n",
      "epoch:38 step:36333 [D loss: 0.242020, acc.: 50.00%] [G loss: 0.314483]\n",
      "epoch:38 step:36334 [D loss: 0.243173, acc.: 59.38%] [G loss: 0.277266]\n",
      "epoch:38 step:36335 [D loss: 0.236708, acc.: 59.38%] [G loss: 0.280814]\n",
      "epoch:38 step:36336 [D loss: 0.249917, acc.: 53.91%] [G loss: 0.330359]\n",
      "epoch:38 step:36337 [D loss: 0.239623, acc.: 58.59%] [G loss: 0.298912]\n",
      "epoch:38 step:36338 [D loss: 0.246324, acc.: 54.69%] [G loss: 0.296379]\n",
      "epoch:38 step:36339 [D loss: 0.242453, acc.: 55.47%] [G loss: 0.273877]\n",
      "epoch:38 step:36340 [D loss: 0.231482, acc.: 61.72%] [G loss: 0.284670]\n",
      "epoch:38 step:36341 [D loss: 0.246323, acc.: 56.25%] [G loss: 0.286745]\n",
      "epoch:38 step:36342 [D loss: 0.226211, acc.: 62.50%] [G loss: 0.288002]\n",
      "epoch:38 step:36343 [D loss: 0.243547, acc.: 53.91%] [G loss: 0.315598]\n",
      "epoch:38 step:36344 [D loss: 0.253253, acc.: 55.47%] [G loss: 0.286048]\n",
      "epoch:38 step:36345 [D loss: 0.227644, acc.: 66.41%] [G loss: 0.304032]\n",
      "epoch:38 step:36346 [D loss: 0.238740, acc.: 64.06%] [G loss: 0.284826]\n",
      "epoch:38 step:36347 [D loss: 0.251454, acc.: 53.12%] [G loss: 0.290402]\n",
      "epoch:38 step:36348 [D loss: 0.230573, acc.: 62.50%] [G loss: 0.280875]\n",
      "epoch:38 step:36349 [D loss: 0.241213, acc.: 57.81%] [G loss: 0.276478]\n",
      "epoch:38 step:36350 [D loss: 0.265309, acc.: 50.00%] [G loss: 0.305867]\n",
      "epoch:38 step:36351 [D loss: 0.233630, acc.: 60.94%] [G loss: 0.320666]\n",
      "epoch:38 step:36352 [D loss: 0.251486, acc.: 55.47%] [G loss: 0.271201]\n",
      "epoch:38 step:36353 [D loss: 0.230496, acc.: 62.50%] [G loss: 0.287173]\n",
      "epoch:38 step:36354 [D loss: 0.236184, acc.: 60.94%] [G loss: 0.311332]\n",
      "epoch:38 step:36355 [D loss: 0.242066, acc.: 58.59%] [G loss: 0.291889]\n",
      "epoch:38 step:36356 [D loss: 0.244566, acc.: 54.69%] [G loss: 0.307378]\n",
      "epoch:38 step:36357 [D loss: 0.247185, acc.: 53.12%] [G loss: 0.281654]\n",
      "epoch:38 step:36358 [D loss: 0.223317, acc.: 64.84%] [G loss: 0.317027]\n",
      "epoch:38 step:36359 [D loss: 0.246145, acc.: 52.34%] [G loss: 0.310143]\n",
      "epoch:38 step:36360 [D loss: 0.252869, acc.: 53.12%] [G loss: 0.295210]\n",
      "epoch:38 step:36361 [D loss: 0.254364, acc.: 50.78%] [G loss: 0.305976]\n",
      "epoch:38 step:36362 [D loss: 0.245435, acc.: 52.34%] [G loss: 0.285707]\n",
      "epoch:38 step:36363 [D loss: 0.231529, acc.: 58.59%] [G loss: 0.305115]\n",
      "epoch:38 step:36364 [D loss: 0.234175, acc.: 62.50%] [G loss: 0.293898]\n",
      "epoch:38 step:36365 [D loss: 0.247484, acc.: 57.81%] [G loss: 0.304592]\n",
      "epoch:38 step:36366 [D loss: 0.240813, acc.: 57.81%] [G loss: 0.291962]\n",
      "epoch:38 step:36367 [D loss: 0.217945, acc.: 66.41%] [G loss: 0.295257]\n",
      "epoch:38 step:36368 [D loss: 0.254594, acc.: 49.22%] [G loss: 0.280718]\n",
      "epoch:38 step:36369 [D loss: 0.242057, acc.: 59.38%] [G loss: 0.310269]\n",
      "epoch:38 step:36370 [D loss: 0.257211, acc.: 53.91%] [G loss: 0.278801]\n",
      "epoch:38 step:36371 [D loss: 0.235797, acc.: 56.25%] [G loss: 0.300238]\n",
      "epoch:38 step:36372 [D loss: 0.246347, acc.: 56.25%] [G loss: 0.306746]\n",
      "epoch:38 step:36373 [D loss: 0.232796, acc.: 60.16%] [G loss: 0.312733]\n",
      "epoch:38 step:36374 [D loss: 0.244930, acc.: 53.91%] [G loss: 0.302412]\n",
      "epoch:38 step:36375 [D loss: 0.225681, acc.: 63.28%] [G loss: 0.301437]\n",
      "epoch:38 step:36376 [D loss: 0.250788, acc.: 53.91%] [G loss: 0.281465]\n",
      "epoch:38 step:36377 [D loss: 0.223677, acc.: 64.06%] [G loss: 0.313691]\n",
      "epoch:38 step:36378 [D loss: 0.217804, acc.: 68.75%] [G loss: 0.291980]\n",
      "epoch:38 step:36379 [D loss: 0.251020, acc.: 53.12%] [G loss: 0.271663]\n",
      "epoch:38 step:36380 [D loss: 0.231030, acc.: 60.94%] [G loss: 0.302888]\n",
      "epoch:38 step:36381 [D loss: 0.234289, acc.: 60.16%] [G loss: 0.304640]\n",
      "epoch:38 step:36382 [D loss: 0.244436, acc.: 55.47%] [G loss: 0.304049]\n",
      "epoch:38 step:36383 [D loss: 0.230009, acc.: 64.06%] [G loss: 0.299686]\n",
      "epoch:38 step:36384 [D loss: 0.246745, acc.: 57.81%] [G loss: 0.286625]\n",
      "epoch:38 step:36385 [D loss: 0.234098, acc.: 57.81%] [G loss: 0.313797]\n",
      "epoch:38 step:36386 [D loss: 0.239369, acc.: 59.38%] [G loss: 0.311909]\n",
      "epoch:38 step:36387 [D loss: 0.220814, acc.: 67.97%] [G loss: 0.323419]\n",
      "epoch:38 step:36388 [D loss: 0.252091, acc.: 57.03%] [G loss: 0.295114]\n",
      "epoch:38 step:36389 [D loss: 0.243111, acc.: 52.34%] [G loss: 0.305496]\n",
      "epoch:38 step:36390 [D loss: 0.238727, acc.: 59.38%] [G loss: 0.303928]\n",
      "epoch:38 step:36391 [D loss: 0.244929, acc.: 57.03%] [G loss: 0.315728]\n",
      "epoch:38 step:36392 [D loss: 0.255942, acc.: 50.00%] [G loss: 0.306853]\n",
      "epoch:38 step:36393 [D loss: 0.243243, acc.: 63.28%] [G loss: 0.313870]\n",
      "epoch:38 step:36394 [D loss: 0.222664, acc.: 67.19%] [G loss: 0.288613]\n",
      "epoch:38 step:36395 [D loss: 0.242999, acc.: 57.81%] [G loss: 0.273993]\n",
      "epoch:38 step:36396 [D loss: 0.258590, acc.: 51.56%] [G loss: 0.319983]\n",
      "epoch:38 step:36397 [D loss: 0.255103, acc.: 53.91%] [G loss: 0.293735]\n",
      "epoch:38 step:36398 [D loss: 0.244231, acc.: 55.47%] [G loss: 0.279235]\n",
      "epoch:38 step:36399 [D loss: 0.260677, acc.: 47.66%] [G loss: 0.272497]\n",
      "epoch:38 step:36400 [D loss: 0.229504, acc.: 60.16%] [G loss: 0.304838]\n",
      "epoch:38 step:36401 [D loss: 0.244867, acc.: 53.91%] [G loss: 0.289152]\n",
      "epoch:38 step:36402 [D loss: 0.239362, acc.: 62.50%] [G loss: 0.306739]\n",
      "epoch:38 step:36403 [D loss: 0.258314, acc.: 50.78%] [G loss: 0.283309]\n",
      "epoch:38 step:36404 [D loss: 0.246409, acc.: 53.91%] [G loss: 0.294960]\n",
      "epoch:38 step:36405 [D loss: 0.242435, acc.: 55.47%] [G loss: 0.291869]\n",
      "epoch:38 step:36406 [D loss: 0.253562, acc.: 49.22%] [G loss: 0.289588]\n",
      "epoch:38 step:36407 [D loss: 0.242078, acc.: 63.28%] [G loss: 0.252875]\n",
      "epoch:38 step:36408 [D loss: 0.248824, acc.: 57.03%] [G loss: 0.300559]\n",
      "epoch:38 step:36409 [D loss: 0.250587, acc.: 52.34%] [G loss: 0.270739]\n",
      "epoch:38 step:36410 [D loss: 0.223002, acc.: 64.84%] [G loss: 0.293829]\n",
      "epoch:38 step:36411 [D loss: 0.244770, acc.: 53.12%] [G loss: 0.287755]\n",
      "epoch:38 step:36412 [D loss: 0.235286, acc.: 55.47%] [G loss: 0.282108]\n",
      "epoch:38 step:36413 [D loss: 0.246134, acc.: 53.12%] [G loss: 0.302752]\n",
      "epoch:38 step:36414 [D loss: 0.249571, acc.: 57.81%] [G loss: 0.285255]\n",
      "epoch:38 step:36415 [D loss: 0.235309, acc.: 60.16%] [G loss: 0.259065]\n",
      "epoch:38 step:36416 [D loss: 0.223345, acc.: 60.94%] [G loss: 0.342465]\n",
      "epoch:38 step:36417 [D loss: 0.241396, acc.: 55.47%] [G loss: 0.292401]\n",
      "epoch:38 step:36418 [D loss: 0.248868, acc.: 57.81%] [G loss: 0.327504]\n",
      "epoch:38 step:36419 [D loss: 0.233844, acc.: 59.38%] [G loss: 0.294262]\n",
      "epoch:38 step:36420 [D loss: 0.247871, acc.: 53.12%] [G loss: 0.302105]\n",
      "epoch:38 step:36421 [D loss: 0.247473, acc.: 55.47%] [G loss: 0.307598]\n",
      "epoch:38 step:36422 [D loss: 0.243144, acc.: 60.16%] [G loss: 0.331664]\n",
      "epoch:38 step:36423 [D loss: 0.234420, acc.: 62.50%] [G loss: 0.321532]\n",
      "epoch:38 step:36424 [D loss: 0.242048, acc.: 52.34%] [G loss: 0.316878]\n",
      "epoch:38 step:36425 [D loss: 0.248629, acc.: 52.34%] [G loss: 0.306980]\n",
      "epoch:38 step:36426 [D loss: 0.240214, acc.: 59.38%] [G loss: 0.297847]\n",
      "epoch:38 step:36427 [D loss: 0.231572, acc.: 61.72%] [G loss: 0.301023]\n",
      "epoch:38 step:36428 [D loss: 0.239806, acc.: 59.38%] [G loss: 0.308038]\n",
      "epoch:38 step:36429 [D loss: 0.250499, acc.: 54.69%] [G loss: 0.293389]\n",
      "epoch:38 step:36430 [D loss: 0.235241, acc.: 63.28%] [G loss: 0.298482]\n",
      "epoch:38 step:36431 [D loss: 0.244356, acc.: 57.81%] [G loss: 0.302593]\n",
      "epoch:38 step:36432 [D loss: 0.229335, acc.: 64.84%] [G loss: 0.293369]\n",
      "epoch:38 step:36433 [D loss: 0.236812, acc.: 60.16%] [G loss: 0.290045]\n",
      "epoch:38 step:36434 [D loss: 0.260020, acc.: 50.78%] [G loss: 0.286519]\n",
      "epoch:38 step:36435 [D loss: 0.255523, acc.: 52.34%] [G loss: 0.269789]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:38 step:36436 [D loss: 0.230566, acc.: 58.59%] [G loss: 0.308702]\n",
      "epoch:38 step:36437 [D loss: 0.264655, acc.: 50.00%] [G loss: 0.313627]\n",
      "epoch:38 step:36438 [D loss: 0.254541, acc.: 53.12%] [G loss: 0.312069]\n",
      "epoch:38 step:36439 [D loss: 0.222332, acc.: 64.06%] [G loss: 0.296512]\n",
      "epoch:38 step:36440 [D loss: 0.257510, acc.: 51.56%] [G loss: 0.246049]\n",
      "epoch:38 step:36441 [D loss: 0.242091, acc.: 52.34%] [G loss: 0.292142]\n",
      "epoch:38 step:36442 [D loss: 0.235444, acc.: 63.28%] [G loss: 0.294979]\n",
      "epoch:38 step:36443 [D loss: 0.230425, acc.: 61.72%] [G loss: 0.314040]\n",
      "epoch:38 step:36444 [D loss: 0.237822, acc.: 58.59%] [G loss: 0.314105]\n",
      "epoch:38 step:36445 [D loss: 0.238838, acc.: 57.81%] [G loss: 0.278700]\n",
      "epoch:38 step:36446 [D loss: 0.246207, acc.: 53.12%] [G loss: 0.299824]\n",
      "epoch:38 step:36447 [D loss: 0.231621, acc.: 64.84%] [G loss: 0.296702]\n",
      "epoch:38 step:36448 [D loss: 0.257522, acc.: 53.12%] [G loss: 0.291880]\n",
      "epoch:38 step:36449 [D loss: 0.259750, acc.: 55.47%] [G loss: 0.282873]\n",
      "epoch:38 step:36450 [D loss: 0.245668, acc.: 56.25%] [G loss: 0.308898]\n",
      "epoch:38 step:36451 [D loss: 0.255333, acc.: 50.00%] [G loss: 0.274667]\n",
      "epoch:38 step:36452 [D loss: 0.231537, acc.: 60.16%] [G loss: 0.281109]\n",
      "epoch:38 step:36453 [D loss: 0.246912, acc.: 53.12%] [G loss: 0.281539]\n",
      "epoch:38 step:36454 [D loss: 0.252232, acc.: 53.12%] [G loss: 0.306662]\n",
      "epoch:38 step:36455 [D loss: 0.254807, acc.: 51.56%] [G loss: 0.291712]\n",
      "epoch:38 step:36456 [D loss: 0.232776, acc.: 60.16%] [G loss: 0.313300]\n",
      "epoch:38 step:36457 [D loss: 0.258600, acc.: 46.09%] [G loss: 0.276709]\n",
      "epoch:38 step:36458 [D loss: 0.232792, acc.: 63.28%] [G loss: 0.306077]\n",
      "epoch:38 step:36459 [D loss: 0.227020, acc.: 59.38%] [G loss: 0.326686]\n",
      "epoch:38 step:36460 [D loss: 0.239293, acc.: 58.59%] [G loss: 0.281695]\n",
      "epoch:38 step:36461 [D loss: 0.248312, acc.: 53.12%] [G loss: 0.287431]\n",
      "epoch:38 step:36462 [D loss: 0.242952, acc.: 57.03%] [G loss: 0.300586]\n",
      "epoch:38 step:36463 [D loss: 0.240179, acc.: 63.28%] [G loss: 0.307463]\n",
      "epoch:38 step:36464 [D loss: 0.243089, acc.: 57.81%] [G loss: 0.305312]\n",
      "epoch:38 step:36465 [D loss: 0.234999, acc.: 56.25%] [G loss: 0.299474]\n",
      "epoch:38 step:36466 [D loss: 0.231974, acc.: 56.25%] [G loss: 0.306891]\n",
      "epoch:38 step:36467 [D loss: 0.226034, acc.: 64.84%] [G loss: 0.298281]\n",
      "epoch:38 step:36468 [D loss: 0.244484, acc.: 57.81%] [G loss: 0.302164]\n",
      "epoch:38 step:36469 [D loss: 0.249416, acc.: 52.34%] [G loss: 0.287915]\n",
      "epoch:38 step:36470 [D loss: 0.224367, acc.: 61.72%] [G loss: 0.283075]\n",
      "epoch:38 step:36471 [D loss: 0.228934, acc.: 62.50%] [G loss: 0.263985]\n",
      "epoch:38 step:36472 [D loss: 0.229741, acc.: 62.50%] [G loss: 0.292791]\n",
      "epoch:38 step:36473 [D loss: 0.262324, acc.: 53.12%] [G loss: 0.297199]\n",
      "epoch:38 step:36474 [D loss: 0.219488, acc.: 66.41%] [G loss: 0.311071]\n",
      "epoch:38 step:36475 [D loss: 0.232099, acc.: 60.16%] [G loss: 0.292716]\n",
      "epoch:38 step:36476 [D loss: 0.249429, acc.: 56.25%] [G loss: 0.281128]\n",
      "epoch:38 step:36477 [D loss: 0.246888, acc.: 51.56%] [G loss: 0.305857]\n",
      "epoch:38 step:36478 [D loss: 0.259710, acc.: 50.78%] [G loss: 0.281959]\n",
      "epoch:38 step:36479 [D loss: 0.232943, acc.: 57.03%] [G loss: 0.294679]\n",
      "epoch:38 step:36480 [D loss: 0.235652, acc.: 59.38%] [G loss: 0.316915]\n",
      "epoch:38 step:36481 [D loss: 0.230843, acc.: 64.06%] [G loss: 0.301736]\n",
      "epoch:38 step:36482 [D loss: 0.238506, acc.: 60.16%] [G loss: 0.310086]\n",
      "epoch:38 step:36483 [D loss: 0.225807, acc.: 60.94%] [G loss: 0.282809]\n",
      "epoch:38 step:36484 [D loss: 0.246733, acc.: 50.78%] [G loss: 0.287435]\n",
      "epoch:38 step:36485 [D loss: 0.234801, acc.: 55.47%] [G loss: 0.298285]\n",
      "epoch:38 step:36486 [D loss: 0.230834, acc.: 64.06%] [G loss: 0.315818]\n",
      "epoch:38 step:36487 [D loss: 0.223248, acc.: 67.97%] [G loss: 0.304562]\n",
      "epoch:38 step:36488 [D loss: 0.250215, acc.: 53.91%] [G loss: 0.291140]\n",
      "epoch:38 step:36489 [D loss: 0.244887, acc.: 53.12%] [G loss: 0.325894]\n",
      "epoch:38 step:36490 [D loss: 0.244944, acc.: 57.03%] [G loss: 0.288353]\n",
      "epoch:38 step:36491 [D loss: 0.247725, acc.: 58.59%] [G loss: 0.287999]\n",
      "epoch:38 step:36492 [D loss: 0.241579, acc.: 56.25%] [G loss: 0.314536]\n",
      "epoch:38 step:36493 [D loss: 0.232294, acc.: 57.81%] [G loss: 0.304409]\n",
      "epoch:38 step:36494 [D loss: 0.251638, acc.: 53.91%] [G loss: 0.285365]\n",
      "epoch:38 step:36495 [D loss: 0.246799, acc.: 54.69%] [G loss: 0.314561]\n",
      "epoch:38 step:36496 [D loss: 0.227553, acc.: 60.94%] [G loss: 0.310571]\n",
      "epoch:38 step:36497 [D loss: 0.245022, acc.: 50.78%] [G loss: 0.298723]\n",
      "epoch:38 step:36498 [D loss: 0.230380, acc.: 61.72%] [G loss: 0.311944]\n",
      "epoch:38 step:36499 [D loss: 0.240963, acc.: 57.81%] [G loss: 0.312367]\n",
      "epoch:38 step:36500 [D loss: 0.237360, acc.: 60.94%] [G loss: 0.291140]\n",
      "epoch:38 step:36501 [D loss: 0.235155, acc.: 58.59%] [G loss: 0.298475]\n",
      "epoch:38 step:36502 [D loss: 0.243161, acc.: 56.25%] [G loss: 0.297864]\n",
      "epoch:38 step:36503 [D loss: 0.230622, acc.: 64.84%] [G loss: 0.290827]\n",
      "epoch:38 step:36504 [D loss: 0.229994, acc.: 60.16%] [G loss: 0.308334]\n",
      "epoch:38 step:36505 [D loss: 0.237251, acc.: 56.25%] [G loss: 0.295210]\n",
      "epoch:38 step:36506 [D loss: 0.246826, acc.: 53.91%] [G loss: 0.296401]\n",
      "epoch:38 step:36507 [D loss: 0.236428, acc.: 57.81%] [G loss: 0.288299]\n",
      "epoch:38 step:36508 [D loss: 0.247471, acc.: 54.69%] [G loss: 0.287285]\n",
      "epoch:38 step:36509 [D loss: 0.226119, acc.: 67.97%] [G loss: 0.297803]\n",
      "epoch:38 step:36510 [D loss: 0.248479, acc.: 52.34%] [G loss: 0.301515]\n",
      "epoch:38 step:36511 [D loss: 0.225449, acc.: 64.06%] [G loss: 0.321902]\n",
      "epoch:38 step:36512 [D loss: 0.243025, acc.: 56.25%] [G loss: 0.306308]\n",
      "epoch:38 step:36513 [D loss: 0.256642, acc.: 53.12%] [G loss: 0.316595]\n",
      "epoch:38 step:36514 [D loss: 0.241263, acc.: 55.47%] [G loss: 0.272553]\n",
      "epoch:38 step:36515 [D loss: 0.227130, acc.: 58.59%] [G loss: 0.318313]\n",
      "epoch:38 step:36516 [D loss: 0.256727, acc.: 53.91%] [G loss: 0.274876]\n",
      "epoch:38 step:36517 [D loss: 0.243415, acc.: 57.81%] [G loss: 0.297467]\n",
      "epoch:38 step:36518 [D loss: 0.237067, acc.: 59.38%] [G loss: 0.286834]\n",
      "epoch:38 step:36519 [D loss: 0.246299, acc.: 54.69%] [G loss: 0.297669]\n",
      "epoch:38 step:36520 [D loss: 0.259305, acc.: 52.34%] [G loss: 0.257365]\n",
      "epoch:38 step:36521 [D loss: 0.250495, acc.: 50.78%] [G loss: 0.273239]\n",
      "epoch:38 step:36522 [D loss: 0.239116, acc.: 58.59%] [G loss: 0.294773]\n",
      "epoch:38 step:36523 [D loss: 0.260219, acc.: 49.22%] [G loss: 0.283339]\n",
      "epoch:38 step:36524 [D loss: 0.241607, acc.: 58.59%] [G loss: 0.297813]\n",
      "epoch:38 step:36525 [D loss: 0.234860, acc.: 57.81%] [G loss: 0.297879]\n",
      "epoch:38 step:36526 [D loss: 0.246481, acc.: 57.03%] [G loss: 0.311569]\n",
      "epoch:38 step:36527 [D loss: 0.242365, acc.: 59.38%] [G loss: 0.309112]\n",
      "epoch:38 step:36528 [D loss: 0.230978, acc.: 61.72%] [G loss: 0.304138]\n",
      "epoch:38 step:36529 [D loss: 0.248197, acc.: 56.25%] [G loss: 0.296418]\n",
      "epoch:38 step:36530 [D loss: 0.248248, acc.: 52.34%] [G loss: 0.265699]\n",
      "epoch:38 step:36531 [D loss: 0.240339, acc.: 60.94%] [G loss: 0.290383]\n",
      "epoch:38 step:36532 [D loss: 0.236820, acc.: 60.16%] [G loss: 0.299013]\n",
      "epoch:38 step:36533 [D loss: 0.253014, acc.: 50.78%] [G loss: 0.285624]\n",
      "epoch:38 step:36534 [D loss: 0.224260, acc.: 62.50%] [G loss: 0.324265]\n",
      "epoch:38 step:36535 [D loss: 0.220390, acc.: 63.28%] [G loss: 0.295282]\n",
      "epoch:38 step:36536 [D loss: 0.243620, acc.: 55.47%] [G loss: 0.275554]\n",
      "epoch:38 step:36537 [D loss: 0.237147, acc.: 59.38%] [G loss: 0.309637]\n",
      "epoch:38 step:36538 [D loss: 0.247309, acc.: 53.12%] [G loss: 0.290936]\n",
      "epoch:38 step:36539 [D loss: 0.233890, acc.: 59.38%] [G loss: 0.320490]\n",
      "epoch:38 step:36540 [D loss: 0.226638, acc.: 62.50%] [G loss: 0.307368]\n",
      "epoch:38 step:36541 [D loss: 0.234796, acc.: 60.16%] [G loss: 0.291611]\n",
      "epoch:38 step:36542 [D loss: 0.233000, acc.: 61.72%] [G loss: 0.295854]\n",
      "epoch:38 step:36543 [D loss: 0.236295, acc.: 55.47%] [G loss: 0.284795]\n",
      "epoch:39 step:36544 [D loss: 0.241241, acc.: 56.25%] [G loss: 0.303486]\n",
      "epoch:39 step:36545 [D loss: 0.227925, acc.: 64.84%] [G loss: 0.307354]\n",
      "epoch:39 step:36546 [D loss: 0.242069, acc.: 60.16%] [G loss: 0.272756]\n",
      "epoch:39 step:36547 [D loss: 0.235927, acc.: 57.03%] [G loss: 0.304015]\n",
      "epoch:39 step:36548 [D loss: 0.230512, acc.: 65.62%] [G loss: 0.325164]\n",
      "epoch:39 step:36549 [D loss: 0.251555, acc.: 57.03%] [G loss: 0.300675]\n",
      "epoch:39 step:36550 [D loss: 0.242082, acc.: 50.00%] [G loss: 0.291023]\n",
      "epoch:39 step:36551 [D loss: 0.240208, acc.: 57.03%] [G loss: 0.301303]\n",
      "epoch:39 step:36552 [D loss: 0.230686, acc.: 59.38%] [G loss: 0.280488]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:39 step:36553 [D loss: 0.252716, acc.: 55.47%] [G loss: 0.274201]\n",
      "epoch:39 step:36554 [D loss: 0.211161, acc.: 68.75%] [G loss: 0.297632]\n",
      "epoch:39 step:36555 [D loss: 0.241045, acc.: 60.94%] [G loss: 0.270236]\n",
      "epoch:39 step:36556 [D loss: 0.249380, acc.: 58.59%] [G loss: 0.311219]\n",
      "epoch:39 step:36557 [D loss: 0.231862, acc.: 59.38%] [G loss: 0.268924]\n",
      "epoch:39 step:36558 [D loss: 0.231280, acc.: 56.25%] [G loss: 0.326820]\n",
      "epoch:39 step:36559 [D loss: 0.252972, acc.: 52.34%] [G loss: 0.299760]\n",
      "epoch:39 step:36560 [D loss: 0.233690, acc.: 60.94%] [G loss: 0.298311]\n",
      "epoch:39 step:36561 [D loss: 0.237641, acc.: 56.25%] [G loss: 0.301308]\n",
      "epoch:39 step:36562 [D loss: 0.227526, acc.: 64.06%] [G loss: 0.319856]\n",
      "epoch:39 step:36563 [D loss: 0.243321, acc.: 54.69%] [G loss: 0.303404]\n",
      "epoch:39 step:36564 [D loss: 0.254930, acc.: 54.69%] [G loss: 0.291232]\n",
      "epoch:39 step:36565 [D loss: 0.232821, acc.: 59.38%] [G loss: 0.307449]\n",
      "epoch:39 step:36566 [D loss: 0.219031, acc.: 63.28%] [G loss: 0.287130]\n",
      "epoch:39 step:36567 [D loss: 0.231267, acc.: 60.94%] [G loss: 0.296521]\n",
      "epoch:39 step:36568 [D loss: 0.233496, acc.: 62.50%] [G loss: 0.292161]\n",
      "epoch:39 step:36569 [D loss: 0.231340, acc.: 61.72%] [G loss: 0.304962]\n",
      "epoch:39 step:36570 [D loss: 0.237384, acc.: 58.59%] [G loss: 0.324263]\n",
      "epoch:39 step:36571 [D loss: 0.235998, acc.: 57.81%] [G loss: 0.285848]\n",
      "epoch:39 step:36572 [D loss: 0.251767, acc.: 50.00%] [G loss: 0.282595]\n",
      "epoch:39 step:36573 [D loss: 0.245911, acc.: 61.72%] [G loss: 0.312885]\n",
      "epoch:39 step:36574 [D loss: 0.256181, acc.: 50.00%] [G loss: 0.281638]\n",
      "epoch:39 step:36575 [D loss: 0.229197, acc.: 62.50%] [G loss: 0.298375]\n",
      "epoch:39 step:36576 [D loss: 0.248136, acc.: 53.12%] [G loss: 0.311558]\n",
      "epoch:39 step:36577 [D loss: 0.232872, acc.: 60.94%] [G loss: 0.293245]\n",
      "epoch:39 step:36578 [D loss: 0.232312, acc.: 59.38%] [G loss: 0.300862]\n",
      "epoch:39 step:36579 [D loss: 0.228734, acc.: 63.28%] [G loss: 0.291426]\n",
      "epoch:39 step:36580 [D loss: 0.244793, acc.: 60.16%] [G loss: 0.287921]\n",
      "epoch:39 step:36581 [D loss: 0.219970, acc.: 67.19%] [G loss: 0.331923]\n",
      "epoch:39 step:36582 [D loss: 0.241552, acc.: 58.59%] [G loss: 0.348310]\n",
      "epoch:39 step:36583 [D loss: 0.256871, acc.: 49.22%] [G loss: 0.294622]\n",
      "epoch:39 step:36584 [D loss: 0.232735, acc.: 60.94%] [G loss: 0.306362]\n",
      "epoch:39 step:36585 [D loss: 0.232624, acc.: 61.72%] [G loss: 0.315202]\n",
      "epoch:39 step:36586 [D loss: 0.241930, acc.: 57.03%] [G loss: 0.299502]\n",
      "epoch:39 step:36587 [D loss: 0.223490, acc.: 67.97%] [G loss: 0.279608]\n",
      "epoch:39 step:36588 [D loss: 0.228594, acc.: 58.59%] [G loss: 0.288115]\n",
      "epoch:39 step:36589 [D loss: 0.243840, acc.: 53.91%] [G loss: 0.279214]\n",
      "epoch:39 step:36590 [D loss: 0.239015, acc.: 57.81%] [G loss: 0.284941]\n",
      "epoch:39 step:36591 [D loss: 0.241752, acc.: 58.59%] [G loss: 0.305323]\n",
      "epoch:39 step:36592 [D loss: 0.248263, acc.: 50.00%] [G loss: 0.285166]\n",
      "epoch:39 step:36593 [D loss: 0.236219, acc.: 56.25%] [G loss: 0.281498]\n",
      "epoch:39 step:36594 [D loss: 0.242954, acc.: 58.59%] [G loss: 0.297898]\n",
      "epoch:39 step:36595 [D loss: 0.243780, acc.: 55.47%] [G loss: 0.297203]\n",
      "epoch:39 step:36596 [D loss: 0.232202, acc.: 60.94%] [G loss: 0.309211]\n",
      "epoch:39 step:36597 [D loss: 0.222772, acc.: 59.38%] [G loss: 0.352013]\n",
      "epoch:39 step:36598 [D loss: 0.250433, acc.: 57.81%] [G loss: 0.285161]\n",
      "epoch:39 step:36599 [D loss: 0.240825, acc.: 57.81%] [G loss: 0.300961]\n",
      "epoch:39 step:36600 [D loss: 0.248222, acc.: 55.47%] [G loss: 0.312659]\n",
      "epoch:39 step:36601 [D loss: 0.260806, acc.: 45.31%] [G loss: 0.269934]\n",
      "epoch:39 step:36602 [D loss: 0.232968, acc.: 58.59%] [G loss: 0.304102]\n",
      "epoch:39 step:36603 [D loss: 0.229729, acc.: 64.06%] [G loss: 0.316269]\n",
      "epoch:39 step:36604 [D loss: 0.234930, acc.: 60.16%] [G loss: 0.291611]\n",
      "epoch:39 step:36605 [D loss: 0.247063, acc.: 54.69%] [G loss: 0.287292]\n",
      "epoch:39 step:36606 [D loss: 0.248157, acc.: 54.69%] [G loss: 0.279784]\n",
      "epoch:39 step:36607 [D loss: 0.250159, acc.: 56.25%] [G loss: 0.277536]\n",
      "epoch:39 step:36608 [D loss: 0.250311, acc.: 53.12%] [G loss: 0.304747]\n",
      "epoch:39 step:36609 [D loss: 0.260369, acc.: 44.53%] [G loss: 0.277879]\n",
      "epoch:39 step:36610 [D loss: 0.247474, acc.: 57.81%] [G loss: 0.309949]\n",
      "epoch:39 step:36611 [D loss: 0.249854, acc.: 57.81%] [G loss: 0.295529]\n",
      "epoch:39 step:36612 [D loss: 0.239748, acc.: 64.06%] [G loss: 0.284827]\n",
      "epoch:39 step:36613 [D loss: 0.243604, acc.: 53.12%] [G loss: 0.314897]\n",
      "epoch:39 step:36614 [D loss: 0.244810, acc.: 57.03%] [G loss: 0.289448]\n",
      "epoch:39 step:36615 [D loss: 0.245216, acc.: 52.34%] [G loss: 0.283867]\n",
      "epoch:39 step:36616 [D loss: 0.233374, acc.: 58.59%] [G loss: 0.286991]\n",
      "epoch:39 step:36617 [D loss: 0.249831, acc.: 50.78%] [G loss: 0.298968]\n",
      "epoch:39 step:36618 [D loss: 0.237462, acc.: 58.59%] [G loss: 0.290270]\n",
      "epoch:39 step:36619 [D loss: 0.234887, acc.: 60.94%] [G loss: 0.298690]\n",
      "epoch:39 step:36620 [D loss: 0.240178, acc.: 56.25%] [G loss: 0.309135]\n",
      "epoch:39 step:36621 [D loss: 0.249472, acc.: 54.69%] [G loss: 0.306720]\n",
      "epoch:39 step:36622 [D loss: 0.238345, acc.: 57.03%] [G loss: 0.286336]\n",
      "epoch:39 step:36623 [D loss: 0.250993, acc.: 57.03%] [G loss: 0.290079]\n",
      "epoch:39 step:36624 [D loss: 0.232215, acc.: 60.94%] [G loss: 0.319760]\n",
      "epoch:39 step:36625 [D loss: 0.219570, acc.: 61.72%] [G loss: 0.311026]\n",
      "epoch:39 step:36626 [D loss: 0.253846, acc.: 59.38%] [G loss: 0.295473]\n",
      "epoch:39 step:36627 [D loss: 0.248580, acc.: 53.91%] [G loss: 0.293387]\n",
      "epoch:39 step:36628 [D loss: 0.249890, acc.: 56.25%] [G loss: 0.281887]\n",
      "epoch:39 step:36629 [D loss: 0.248151, acc.: 49.22%] [G loss: 0.304990]\n",
      "epoch:39 step:36630 [D loss: 0.241670, acc.: 60.94%] [G loss: 0.311187]\n",
      "epoch:39 step:36631 [D loss: 0.251571, acc.: 54.69%] [G loss: 0.286365]\n",
      "epoch:39 step:36632 [D loss: 0.235943, acc.: 57.81%] [G loss: 0.278872]\n",
      "epoch:39 step:36633 [D loss: 0.236346, acc.: 58.59%] [G loss: 0.307121]\n",
      "epoch:39 step:36634 [D loss: 0.228420, acc.: 59.38%] [G loss: 0.282016]\n",
      "epoch:39 step:36635 [D loss: 0.242548, acc.: 54.69%] [G loss: 0.269196]\n",
      "epoch:39 step:36636 [D loss: 0.250372, acc.: 51.56%] [G loss: 0.290307]\n",
      "epoch:39 step:36637 [D loss: 0.237061, acc.: 60.94%] [G loss: 0.293914]\n",
      "epoch:39 step:36638 [D loss: 0.280480, acc.: 42.19%] [G loss: 0.271356]\n",
      "epoch:39 step:36639 [D loss: 0.230567, acc.: 60.94%] [G loss: 0.294547]\n",
      "epoch:39 step:36640 [D loss: 0.240531, acc.: 55.47%] [G loss: 0.323824]\n",
      "epoch:39 step:36641 [D loss: 0.248199, acc.: 57.03%] [G loss: 0.295738]\n",
      "epoch:39 step:36642 [D loss: 0.235127, acc.: 60.94%] [G loss: 0.316462]\n",
      "epoch:39 step:36643 [D loss: 0.238875, acc.: 60.16%] [G loss: 0.281245]\n",
      "epoch:39 step:36644 [D loss: 0.246788, acc.: 53.91%] [G loss: 0.283808]\n",
      "epoch:39 step:36645 [D loss: 0.240482, acc.: 58.59%] [G loss: 0.320244]\n",
      "epoch:39 step:36646 [D loss: 0.241404, acc.: 58.59%] [G loss: 0.289924]\n",
      "epoch:39 step:36647 [D loss: 0.244318, acc.: 57.81%] [G loss: 0.298666]\n",
      "epoch:39 step:36648 [D loss: 0.243869, acc.: 57.81%] [G loss: 0.287273]\n",
      "epoch:39 step:36649 [D loss: 0.222886, acc.: 62.50%] [G loss: 0.318679]\n",
      "epoch:39 step:36650 [D loss: 0.238528, acc.: 56.25%] [G loss: 0.296408]\n",
      "epoch:39 step:36651 [D loss: 0.233486, acc.: 60.16%] [G loss: 0.304366]\n",
      "epoch:39 step:36652 [D loss: 0.254500, acc.: 51.56%] [G loss: 0.287078]\n",
      "epoch:39 step:36653 [D loss: 0.255816, acc.: 46.88%] [G loss: 0.307350]\n",
      "epoch:39 step:36654 [D loss: 0.256964, acc.: 50.00%] [G loss: 0.270266]\n",
      "epoch:39 step:36655 [D loss: 0.241736, acc.: 54.69%] [G loss: 0.298704]\n",
      "epoch:39 step:36656 [D loss: 0.227118, acc.: 60.16%] [G loss: 0.304911]\n",
      "epoch:39 step:36657 [D loss: 0.231013, acc.: 64.06%] [G loss: 0.303616]\n",
      "epoch:39 step:36658 [D loss: 0.240680, acc.: 58.59%] [G loss: 0.304095]\n",
      "epoch:39 step:36659 [D loss: 0.240305, acc.: 58.59%] [G loss: 0.308480]\n",
      "epoch:39 step:36660 [D loss: 0.242488, acc.: 55.47%] [G loss: 0.296434]\n",
      "epoch:39 step:36661 [D loss: 0.243135, acc.: 58.59%] [G loss: 0.312631]\n",
      "epoch:39 step:36662 [D loss: 0.244333, acc.: 56.25%] [G loss: 0.308280]\n",
      "epoch:39 step:36663 [D loss: 0.254621, acc.: 56.25%] [G loss: 0.298443]\n",
      "epoch:39 step:36664 [D loss: 0.247420, acc.: 55.47%] [G loss: 0.303953]\n",
      "epoch:39 step:36665 [D loss: 0.253350, acc.: 52.34%] [G loss: 0.301489]\n",
      "epoch:39 step:36666 [D loss: 0.239776, acc.: 60.16%] [G loss: 0.290358]\n",
      "epoch:39 step:36667 [D loss: 0.241217, acc.: 55.47%] [G loss: 0.277855]\n",
      "epoch:39 step:36668 [D loss: 0.244254, acc.: 58.59%] [G loss: 0.295675]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:39 step:36669 [D loss: 0.230087, acc.: 60.16%] [G loss: 0.278874]\n",
      "epoch:39 step:36670 [D loss: 0.246856, acc.: 54.69%] [G loss: 0.315870]\n",
      "epoch:39 step:36671 [D loss: 0.250135, acc.: 52.34%] [G loss: 0.279101]\n",
      "epoch:39 step:36672 [D loss: 0.238884, acc.: 60.94%] [G loss: 0.306033]\n",
      "epoch:39 step:36673 [D loss: 0.227717, acc.: 64.06%] [G loss: 0.314558]\n",
      "epoch:39 step:36674 [D loss: 0.241289, acc.: 63.28%] [G loss: 0.296188]\n",
      "epoch:39 step:36675 [D loss: 0.232399, acc.: 62.50%] [G loss: 0.262960]\n",
      "epoch:39 step:36676 [D loss: 0.235401, acc.: 59.38%] [G loss: 0.298884]\n",
      "epoch:39 step:36677 [D loss: 0.237792, acc.: 64.84%] [G loss: 0.268856]\n",
      "epoch:39 step:36678 [D loss: 0.229659, acc.: 64.06%] [G loss: 0.301523]\n",
      "epoch:39 step:36679 [D loss: 0.216489, acc.: 66.41%] [G loss: 0.305660]\n",
      "epoch:39 step:36680 [D loss: 0.226065, acc.: 62.50%] [G loss: 0.284733]\n",
      "epoch:39 step:36681 [D loss: 0.228618, acc.: 60.94%] [G loss: 0.315781]\n",
      "epoch:39 step:36682 [D loss: 0.255349, acc.: 54.69%] [G loss: 0.300269]\n",
      "epoch:39 step:36683 [D loss: 0.231182, acc.: 58.59%] [G loss: 0.300533]\n",
      "epoch:39 step:36684 [D loss: 0.262103, acc.: 54.69%] [G loss: 0.274424]\n",
      "epoch:39 step:36685 [D loss: 0.228901, acc.: 60.16%] [G loss: 0.298487]\n",
      "epoch:39 step:36686 [D loss: 0.238249, acc.: 60.16%] [G loss: 0.289205]\n",
      "epoch:39 step:36687 [D loss: 0.261765, acc.: 47.66%] [G loss: 0.291036]\n",
      "epoch:39 step:36688 [D loss: 0.227810, acc.: 60.16%] [G loss: 0.302267]\n",
      "epoch:39 step:36689 [D loss: 0.249053, acc.: 51.56%] [G loss: 0.288264]\n",
      "epoch:39 step:36690 [D loss: 0.223896, acc.: 62.50%] [G loss: 0.300076]\n",
      "epoch:39 step:36691 [D loss: 0.237870, acc.: 54.69%] [G loss: 0.322184]\n",
      "epoch:39 step:36692 [D loss: 0.251703, acc.: 53.91%] [G loss: 0.306592]\n",
      "epoch:39 step:36693 [D loss: 0.244338, acc.: 55.47%] [G loss: 0.293761]\n",
      "epoch:39 step:36694 [D loss: 0.252233, acc.: 53.91%] [G loss: 0.299685]\n",
      "epoch:39 step:36695 [D loss: 0.240055, acc.: 57.81%] [G loss: 0.293223]\n",
      "epoch:39 step:36696 [D loss: 0.251353, acc.: 53.91%] [G loss: 0.274194]\n",
      "epoch:39 step:36697 [D loss: 0.229302, acc.: 60.94%] [G loss: 0.295953]\n",
      "epoch:39 step:36698 [D loss: 0.247727, acc.: 52.34%] [G loss: 0.291604]\n",
      "epoch:39 step:36699 [D loss: 0.242735, acc.: 59.38%] [G loss: 0.310626]\n",
      "epoch:39 step:36700 [D loss: 0.247760, acc.: 54.69%] [G loss: 0.296831]\n",
      "epoch:39 step:36701 [D loss: 0.250408, acc.: 49.22%] [G loss: 0.295103]\n",
      "epoch:39 step:36702 [D loss: 0.237351, acc.: 57.81%] [G loss: 0.288169]\n",
      "epoch:39 step:36703 [D loss: 0.236555, acc.: 60.16%] [G loss: 0.337202]\n",
      "epoch:39 step:36704 [D loss: 0.223558, acc.: 67.19%] [G loss: 0.278279]\n",
      "epoch:39 step:36705 [D loss: 0.228457, acc.: 58.59%] [G loss: 0.307645]\n",
      "epoch:39 step:36706 [D loss: 0.248494, acc.: 60.94%] [G loss: 0.317416]\n",
      "epoch:39 step:36707 [D loss: 0.225242, acc.: 61.72%] [G loss: 0.311399]\n",
      "epoch:39 step:36708 [D loss: 0.239728, acc.: 58.59%] [G loss: 0.310436]\n",
      "epoch:39 step:36709 [D loss: 0.238607, acc.: 58.59%] [G loss: 0.327742]\n",
      "epoch:39 step:36710 [D loss: 0.224834, acc.: 66.41%] [G loss: 0.303382]\n",
      "epoch:39 step:36711 [D loss: 0.227246, acc.: 64.84%] [G loss: 0.307890]\n",
      "epoch:39 step:36712 [D loss: 0.238643, acc.: 57.03%] [G loss: 0.301638]\n",
      "epoch:39 step:36713 [D loss: 0.237993, acc.: 53.91%] [G loss: 0.313004]\n",
      "epoch:39 step:36714 [D loss: 0.246023, acc.: 53.12%] [G loss: 0.308309]\n",
      "epoch:39 step:36715 [D loss: 0.247365, acc.: 56.25%] [G loss: 0.294906]\n",
      "epoch:39 step:36716 [D loss: 0.239968, acc.: 60.94%] [G loss: 0.297839]\n",
      "epoch:39 step:36717 [D loss: 0.225333, acc.: 60.16%] [G loss: 0.289124]\n",
      "epoch:39 step:36718 [D loss: 0.243883, acc.: 60.16%] [G loss: 0.299798]\n",
      "epoch:39 step:36719 [D loss: 0.260126, acc.: 50.78%] [G loss: 0.288148]\n",
      "epoch:39 step:36720 [D loss: 0.214684, acc.: 67.19%] [G loss: 0.313878]\n",
      "epoch:39 step:36721 [D loss: 0.237282, acc.: 60.94%] [G loss: 0.306372]\n",
      "epoch:39 step:36722 [D loss: 0.233438, acc.: 64.06%] [G loss: 0.284045]\n",
      "epoch:39 step:36723 [D loss: 0.242897, acc.: 55.47%] [G loss: 0.321567]\n",
      "epoch:39 step:36724 [D loss: 0.231572, acc.: 60.94%] [G loss: 0.296654]\n",
      "epoch:39 step:36725 [D loss: 0.221565, acc.: 64.06%] [G loss: 0.285206]\n",
      "epoch:39 step:36726 [D loss: 0.248806, acc.: 53.12%] [G loss: 0.277641]\n",
      "epoch:39 step:36727 [D loss: 0.262527, acc.: 51.56%] [G loss: 0.302872]\n",
      "epoch:39 step:36728 [D loss: 0.236247, acc.: 62.50%] [G loss: 0.297014]\n",
      "epoch:39 step:36729 [D loss: 0.243384, acc.: 54.69%] [G loss: 0.283086]\n",
      "epoch:39 step:36730 [D loss: 0.223895, acc.: 61.72%] [G loss: 0.321055]\n",
      "epoch:39 step:36731 [D loss: 0.253242, acc.: 55.47%] [G loss: 0.295259]\n",
      "epoch:39 step:36732 [D loss: 0.256076, acc.: 48.44%] [G loss: 0.281849]\n",
      "epoch:39 step:36733 [D loss: 0.252782, acc.: 54.69%] [G loss: 0.324955]\n",
      "epoch:39 step:36734 [D loss: 0.240925, acc.: 62.50%] [G loss: 0.274167]\n",
      "epoch:39 step:36735 [D loss: 0.250796, acc.: 57.81%] [G loss: 0.291297]\n",
      "epoch:39 step:36736 [D loss: 0.236316, acc.: 59.38%] [G loss: 0.287812]\n",
      "epoch:39 step:36737 [D loss: 0.242368, acc.: 59.38%] [G loss: 0.280174]\n",
      "epoch:39 step:36738 [D loss: 0.256215, acc.: 50.00%] [G loss: 0.280348]\n",
      "epoch:39 step:36739 [D loss: 0.245296, acc.: 53.12%] [G loss: 0.300344]\n",
      "epoch:39 step:36740 [D loss: 0.242960, acc.: 55.47%] [G loss: 0.299741]\n",
      "epoch:39 step:36741 [D loss: 0.236033, acc.: 59.38%] [G loss: 0.302935]\n",
      "epoch:39 step:36742 [D loss: 0.231715, acc.: 64.06%] [G loss: 0.288883]\n",
      "epoch:39 step:36743 [D loss: 0.246474, acc.: 52.34%] [G loss: 0.320433]\n",
      "epoch:39 step:36744 [D loss: 0.231120, acc.: 60.16%] [G loss: 0.289810]\n",
      "epoch:39 step:36745 [D loss: 0.232566, acc.: 60.94%] [G loss: 0.319147]\n",
      "epoch:39 step:36746 [D loss: 0.235930, acc.: 58.59%] [G loss: 0.284502]\n",
      "epoch:39 step:36747 [D loss: 0.230602, acc.: 63.28%] [G loss: 0.264849]\n",
      "epoch:39 step:36748 [D loss: 0.260355, acc.: 49.22%] [G loss: 0.273453]\n",
      "epoch:39 step:36749 [D loss: 0.252065, acc.: 53.12%] [G loss: 0.295511]\n",
      "epoch:39 step:36750 [D loss: 0.247422, acc.: 52.34%] [G loss: 0.293611]\n",
      "epoch:39 step:36751 [D loss: 0.241216, acc.: 60.16%] [G loss: 0.289568]\n",
      "epoch:39 step:36752 [D loss: 0.243883, acc.: 57.81%] [G loss: 0.270282]\n",
      "epoch:39 step:36753 [D loss: 0.246084, acc.: 57.03%] [G loss: 0.282596]\n",
      "epoch:39 step:36754 [D loss: 0.242802, acc.: 57.81%] [G loss: 0.315893]\n",
      "epoch:39 step:36755 [D loss: 0.252385, acc.: 55.47%] [G loss: 0.317335]\n",
      "epoch:39 step:36756 [D loss: 0.234886, acc.: 53.91%] [G loss: 0.316991]\n",
      "epoch:39 step:36757 [D loss: 0.253718, acc.: 50.78%] [G loss: 0.302548]\n",
      "epoch:39 step:36758 [D loss: 0.246827, acc.: 62.50%] [G loss: 0.300696]\n",
      "epoch:39 step:36759 [D loss: 0.241034, acc.: 53.91%] [G loss: 0.311618]\n",
      "epoch:39 step:36760 [D loss: 0.238577, acc.: 55.47%] [G loss: 0.288608]\n",
      "epoch:39 step:36761 [D loss: 0.230937, acc.: 64.06%] [G loss: 0.305796]\n",
      "epoch:39 step:36762 [D loss: 0.228872, acc.: 62.50%] [G loss: 0.290355]\n",
      "epoch:39 step:36763 [D loss: 0.238547, acc.: 53.91%] [G loss: 0.293494]\n",
      "epoch:39 step:36764 [D loss: 0.252639, acc.: 52.34%] [G loss: 0.327888]\n",
      "epoch:39 step:36765 [D loss: 0.242831, acc.: 57.03%] [G loss: 0.298666]\n",
      "epoch:39 step:36766 [D loss: 0.233273, acc.: 60.16%] [G loss: 0.338277]\n",
      "epoch:39 step:36767 [D loss: 0.249410, acc.: 53.12%] [G loss: 0.293657]\n",
      "epoch:39 step:36768 [D loss: 0.239925, acc.: 60.94%] [G loss: 0.317088]\n",
      "epoch:39 step:36769 [D loss: 0.242490, acc.: 53.12%] [G loss: 0.311514]\n",
      "epoch:39 step:36770 [D loss: 0.254618, acc.: 54.69%] [G loss: 0.278297]\n",
      "epoch:39 step:36771 [D loss: 0.252560, acc.: 53.12%] [G loss: 0.276383]\n",
      "epoch:39 step:36772 [D loss: 0.232762, acc.: 54.69%] [G loss: 0.282505]\n",
      "epoch:39 step:36773 [D loss: 0.236923, acc.: 64.84%] [G loss: 0.275681]\n",
      "epoch:39 step:36774 [D loss: 0.247163, acc.: 58.59%] [G loss: 0.303040]\n",
      "epoch:39 step:36775 [D loss: 0.239763, acc.: 63.28%] [G loss: 0.292929]\n",
      "epoch:39 step:36776 [D loss: 0.245632, acc.: 57.81%] [G loss: 0.275540]\n",
      "epoch:39 step:36777 [D loss: 0.228792, acc.: 57.81%] [G loss: 0.294480]\n",
      "epoch:39 step:36778 [D loss: 0.229825, acc.: 64.84%] [G loss: 0.334172]\n",
      "epoch:39 step:36779 [D loss: 0.220747, acc.: 64.06%] [G loss: 0.318334]\n",
      "epoch:39 step:36780 [D loss: 0.225393, acc.: 64.84%] [G loss: 0.273521]\n",
      "epoch:39 step:36781 [D loss: 0.235650, acc.: 61.72%] [G loss: 0.267012]\n",
      "epoch:39 step:36782 [D loss: 0.243453, acc.: 60.16%] [G loss: 0.302946]\n",
      "epoch:39 step:36783 [D loss: 0.247114, acc.: 56.25%] [G loss: 0.303690]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:39 step:36784 [D loss: 0.256099, acc.: 50.00%] [G loss: 0.295848]\n",
      "epoch:39 step:36785 [D loss: 0.232231, acc.: 60.94%] [G loss: 0.295816]\n",
      "epoch:39 step:36786 [D loss: 0.229522, acc.: 63.28%] [G loss: 0.297378]\n",
      "epoch:39 step:36787 [D loss: 0.248899, acc.: 52.34%] [G loss: 0.271044]\n",
      "epoch:39 step:36788 [D loss: 0.226288, acc.: 60.94%] [G loss: 0.277188]\n",
      "epoch:39 step:36789 [D loss: 0.237161, acc.: 60.94%] [G loss: 0.299411]\n",
      "epoch:39 step:36790 [D loss: 0.235007, acc.: 58.59%] [G loss: 0.310391]\n",
      "epoch:39 step:36791 [D loss: 0.226789, acc.: 59.38%] [G loss: 0.297820]\n",
      "epoch:39 step:36792 [D loss: 0.266222, acc.: 49.22%] [G loss: 0.286881]\n",
      "epoch:39 step:36793 [D loss: 0.234430, acc.: 57.81%] [G loss: 0.301001]\n",
      "epoch:39 step:36794 [D loss: 0.230021, acc.: 69.53%] [G loss: 0.281217]\n",
      "epoch:39 step:36795 [D loss: 0.225868, acc.: 62.50%] [G loss: 0.305089]\n",
      "epoch:39 step:36796 [D loss: 0.236356, acc.: 58.59%] [G loss: 0.295999]\n",
      "epoch:39 step:36797 [D loss: 0.241971, acc.: 55.47%] [G loss: 0.302244]\n",
      "epoch:39 step:36798 [D loss: 0.210114, acc.: 67.97%] [G loss: 0.288217]\n",
      "epoch:39 step:36799 [D loss: 0.249715, acc.: 53.91%] [G loss: 0.306428]\n",
      "epoch:39 step:36800 [D loss: 0.213425, acc.: 67.97%] [G loss: 0.318743]\n",
      "epoch:39 step:36801 [D loss: 0.236841, acc.: 57.03%] [G loss: 0.308556]\n",
      "epoch:39 step:36802 [D loss: 0.231075, acc.: 61.72%] [G loss: 0.301280]\n",
      "epoch:39 step:36803 [D loss: 0.242379, acc.: 56.25%] [G loss: 0.295189]\n",
      "epoch:39 step:36804 [D loss: 0.247872, acc.: 53.12%] [G loss: 0.322635]\n",
      "epoch:39 step:36805 [D loss: 0.244932, acc.: 52.34%] [G loss: 0.280754]\n",
      "epoch:39 step:36806 [D loss: 0.265203, acc.: 49.22%] [G loss: 0.295533]\n",
      "epoch:39 step:36807 [D loss: 0.250892, acc.: 53.12%] [G loss: 0.307948]\n",
      "epoch:39 step:36808 [D loss: 0.247283, acc.: 57.03%] [G loss: 0.283783]\n",
      "epoch:39 step:36809 [D loss: 0.247783, acc.: 58.59%] [G loss: 0.303612]\n",
      "epoch:39 step:36810 [D loss: 0.228469, acc.: 63.28%] [G loss: 0.297698]\n",
      "epoch:39 step:36811 [D loss: 0.252559, acc.: 58.59%] [G loss: 0.292283]\n",
      "epoch:39 step:36812 [D loss: 0.231769, acc.: 57.03%] [G loss: 0.317884]\n",
      "epoch:39 step:36813 [D loss: 0.251713, acc.: 51.56%] [G loss: 0.317625]\n",
      "epoch:39 step:36814 [D loss: 0.237379, acc.: 62.50%] [G loss: 0.326907]\n",
      "epoch:39 step:36815 [D loss: 0.229078, acc.: 63.28%] [G loss: 0.281266]\n",
      "epoch:39 step:36816 [D loss: 0.240597, acc.: 56.25%] [G loss: 0.288934]\n",
      "epoch:39 step:36817 [D loss: 0.240445, acc.: 60.16%] [G loss: 0.315295]\n",
      "epoch:39 step:36818 [D loss: 0.240769, acc.: 60.16%] [G loss: 0.329772]\n",
      "epoch:39 step:36819 [D loss: 0.250377, acc.: 54.69%] [G loss: 0.313104]\n",
      "epoch:39 step:36820 [D loss: 0.257604, acc.: 57.81%] [G loss: 0.282567]\n",
      "epoch:39 step:36821 [D loss: 0.246917, acc.: 54.69%] [G loss: 0.306821]\n",
      "epoch:39 step:36822 [D loss: 0.259697, acc.: 48.44%] [G loss: 0.273678]\n",
      "epoch:39 step:36823 [D loss: 0.250084, acc.: 53.91%] [G loss: 0.293415]\n",
      "epoch:39 step:36824 [D loss: 0.230854, acc.: 63.28%] [G loss: 0.297299]\n",
      "epoch:39 step:36825 [D loss: 0.224881, acc.: 60.94%] [G loss: 0.297097]\n",
      "epoch:39 step:36826 [D loss: 0.239246, acc.: 59.38%] [G loss: 0.301323]\n",
      "epoch:39 step:36827 [D loss: 0.230418, acc.: 59.38%] [G loss: 0.292472]\n",
      "epoch:39 step:36828 [D loss: 0.239639, acc.: 53.12%] [G loss: 0.279744]\n",
      "epoch:39 step:36829 [D loss: 0.238049, acc.: 60.16%] [G loss: 0.298203]\n",
      "epoch:39 step:36830 [D loss: 0.231436, acc.: 60.94%] [G loss: 0.288747]\n",
      "epoch:39 step:36831 [D loss: 0.250370, acc.: 58.59%] [G loss: 0.315196]\n",
      "epoch:39 step:36832 [D loss: 0.247191, acc.: 55.47%] [G loss: 0.300318]\n",
      "epoch:39 step:36833 [D loss: 0.245114, acc.: 55.47%] [G loss: 0.310725]\n",
      "epoch:39 step:36834 [D loss: 0.255793, acc.: 50.78%] [G loss: 0.293347]\n",
      "epoch:39 step:36835 [D loss: 0.238325, acc.: 57.03%] [G loss: 0.304455]\n",
      "epoch:39 step:36836 [D loss: 0.223498, acc.: 65.62%] [G loss: 0.303565]\n",
      "epoch:39 step:36837 [D loss: 0.243034, acc.: 54.69%] [G loss: 0.277036]\n",
      "epoch:39 step:36838 [D loss: 0.232023, acc.: 57.81%] [G loss: 0.301612]\n",
      "epoch:39 step:36839 [D loss: 0.226543, acc.: 60.16%] [G loss: 0.289748]\n",
      "epoch:39 step:36840 [D loss: 0.242644, acc.: 62.50%] [G loss: 0.285288]\n",
      "epoch:39 step:36841 [D loss: 0.238738, acc.: 59.38%] [G loss: 0.302015]\n",
      "epoch:39 step:36842 [D loss: 0.265244, acc.: 49.22%] [G loss: 0.287805]\n",
      "epoch:39 step:36843 [D loss: 0.242795, acc.: 58.59%] [G loss: 0.294172]\n",
      "epoch:39 step:36844 [D loss: 0.260853, acc.: 47.66%] [G loss: 0.305317]\n",
      "epoch:39 step:36845 [D loss: 0.231144, acc.: 57.81%] [G loss: 0.301722]\n",
      "epoch:39 step:36846 [D loss: 0.240342, acc.: 54.69%] [G loss: 0.282237]\n",
      "epoch:39 step:36847 [D loss: 0.226719, acc.: 67.97%] [G loss: 0.289503]\n",
      "epoch:39 step:36848 [D loss: 0.235421, acc.: 60.16%] [G loss: 0.285586]\n",
      "epoch:39 step:36849 [D loss: 0.247947, acc.: 55.47%] [G loss: 0.273002]\n",
      "epoch:39 step:36850 [D loss: 0.234201, acc.: 64.06%] [G loss: 0.290863]\n",
      "epoch:39 step:36851 [D loss: 0.218829, acc.: 67.97%] [G loss: 0.307400]\n",
      "epoch:39 step:36852 [D loss: 0.229489, acc.: 62.50%] [G loss: 0.281045]\n",
      "epoch:39 step:36853 [D loss: 0.239249, acc.: 57.03%] [G loss: 0.309289]\n",
      "epoch:39 step:36854 [D loss: 0.231670, acc.: 62.50%] [G loss: 0.287825]\n",
      "epoch:39 step:36855 [D loss: 0.234189, acc.: 58.59%] [G loss: 0.283060]\n",
      "epoch:39 step:36856 [D loss: 0.257740, acc.: 49.22%] [G loss: 0.305062]\n",
      "epoch:39 step:36857 [D loss: 0.235402, acc.: 60.94%] [G loss: 0.263587]\n",
      "epoch:39 step:36858 [D loss: 0.232227, acc.: 58.59%] [G loss: 0.305500]\n",
      "epoch:39 step:36859 [D loss: 0.249421, acc.: 53.12%] [G loss: 0.271512]\n",
      "epoch:39 step:36860 [D loss: 0.251926, acc.: 57.81%] [G loss: 0.265689]\n",
      "epoch:39 step:36861 [D loss: 0.249319, acc.: 55.47%] [G loss: 0.302834]\n",
      "epoch:39 step:36862 [D loss: 0.229066, acc.: 60.94%] [G loss: 0.292437]\n",
      "epoch:39 step:36863 [D loss: 0.235200, acc.: 58.59%] [G loss: 0.300367]\n",
      "epoch:39 step:36864 [D loss: 0.236550, acc.: 60.16%] [G loss: 0.287064]\n",
      "epoch:39 step:36865 [D loss: 0.238801, acc.: 59.38%] [G loss: 0.309758]\n",
      "epoch:39 step:36866 [D loss: 0.263706, acc.: 52.34%] [G loss: 0.293301]\n",
      "epoch:39 step:36867 [D loss: 0.213504, acc.: 69.53%] [G loss: 0.287562]\n",
      "epoch:39 step:36868 [D loss: 0.228497, acc.: 65.62%] [G loss: 0.299940]\n",
      "epoch:39 step:36869 [D loss: 0.228812, acc.: 58.59%] [G loss: 0.303172]\n",
      "epoch:39 step:36870 [D loss: 0.248560, acc.: 54.69%] [G loss: 0.283703]\n",
      "epoch:39 step:36871 [D loss: 0.238395, acc.: 57.03%] [G loss: 0.316332]\n",
      "epoch:39 step:36872 [D loss: 0.229905, acc.: 62.50%] [G loss: 0.334731]\n",
      "epoch:39 step:36873 [D loss: 0.221933, acc.: 67.97%] [G loss: 0.307580]\n",
      "epoch:39 step:36874 [D loss: 0.232982, acc.: 67.19%] [G loss: 0.309535]\n",
      "epoch:39 step:36875 [D loss: 0.249647, acc.: 52.34%] [G loss: 0.296520]\n",
      "epoch:39 step:36876 [D loss: 0.242732, acc.: 57.03%] [G loss: 0.296555]\n",
      "epoch:39 step:36877 [D loss: 0.251055, acc.: 54.69%] [G loss: 0.297572]\n",
      "epoch:39 step:36878 [D loss: 0.225640, acc.: 62.50%] [G loss: 0.315957]\n",
      "epoch:39 step:36879 [D loss: 0.243123, acc.: 55.47%] [G loss: 0.314272]\n",
      "epoch:39 step:36880 [D loss: 0.230723, acc.: 60.16%] [G loss: 0.309070]\n",
      "epoch:39 step:36881 [D loss: 0.232428, acc.: 59.38%] [G loss: 0.298453]\n",
      "epoch:39 step:36882 [D loss: 0.239293, acc.: 57.03%] [G loss: 0.279256]\n",
      "epoch:39 step:36883 [D loss: 0.245080, acc.: 53.91%] [G loss: 0.290121]\n",
      "epoch:39 step:36884 [D loss: 0.229291, acc.: 55.47%] [G loss: 0.277203]\n",
      "epoch:39 step:36885 [D loss: 0.235712, acc.: 60.16%] [G loss: 0.308311]\n",
      "epoch:39 step:36886 [D loss: 0.252323, acc.: 52.34%] [G loss: 0.302030]\n",
      "epoch:39 step:36887 [D loss: 0.243168, acc.: 57.03%] [G loss: 0.326864]\n",
      "epoch:39 step:36888 [D loss: 0.238549, acc.: 56.25%] [G loss: 0.296762]\n",
      "epoch:39 step:36889 [D loss: 0.223201, acc.: 64.06%] [G loss: 0.316401]\n",
      "epoch:39 step:36890 [D loss: 0.253612, acc.: 53.12%] [G loss: 0.303035]\n",
      "epoch:39 step:36891 [D loss: 0.262248, acc.: 50.78%] [G loss: 0.307772]\n",
      "epoch:39 step:36892 [D loss: 0.221072, acc.: 64.84%] [G loss: 0.285087]\n",
      "epoch:39 step:36893 [D loss: 0.245182, acc.: 54.69%] [G loss: 0.270585]\n",
      "epoch:39 step:36894 [D loss: 0.232762, acc.: 57.81%] [G loss: 0.316087]\n",
      "epoch:39 step:36895 [D loss: 0.232352, acc.: 58.59%] [G loss: 0.276509]\n",
      "epoch:39 step:36896 [D loss: 0.247017, acc.: 55.47%] [G loss: 0.319352]\n",
      "epoch:39 step:36897 [D loss: 0.219994, acc.: 64.84%] [G loss: 0.290939]\n",
      "epoch:39 step:36898 [D loss: 0.242838, acc.: 55.47%] [G loss: 0.282048]\n",
      "epoch:39 step:36899 [D loss: 0.231923, acc.: 59.38%] [G loss: 0.263137]\n",
      "epoch:39 step:36900 [D loss: 0.235859, acc.: 60.94%] [G loss: 0.288571]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:39 step:36901 [D loss: 0.232966, acc.: 60.94%] [G loss: 0.286723]\n",
      "epoch:39 step:36902 [D loss: 0.247844, acc.: 56.25%] [G loss: 0.308274]\n",
      "epoch:39 step:36903 [D loss: 0.252167, acc.: 53.91%] [G loss: 0.328635]\n",
      "epoch:39 step:36904 [D loss: 0.262947, acc.: 50.78%] [G loss: 0.279324]\n",
      "epoch:39 step:36905 [D loss: 0.230655, acc.: 60.94%] [G loss: 0.303401]\n",
      "epoch:39 step:36906 [D loss: 0.234089, acc.: 58.59%] [G loss: 0.279319]\n",
      "epoch:39 step:36907 [D loss: 0.270114, acc.: 46.09%] [G loss: 0.256324]\n",
      "epoch:39 step:36908 [D loss: 0.228832, acc.: 65.62%] [G loss: 0.287416]\n",
      "epoch:39 step:36909 [D loss: 0.238044, acc.: 57.81%] [G loss: 0.283919]\n",
      "epoch:39 step:36910 [D loss: 0.226213, acc.: 57.81%] [G loss: 0.310458]\n",
      "epoch:39 step:36911 [D loss: 0.235712, acc.: 58.59%] [G loss: 0.317019]\n",
      "epoch:39 step:36912 [D loss: 0.226504, acc.: 59.38%] [G loss: 0.292073]\n",
      "epoch:39 step:36913 [D loss: 0.249072, acc.: 56.25%] [G loss: 0.313137]\n",
      "epoch:39 step:36914 [D loss: 0.247724, acc.: 57.03%] [G loss: 0.262721]\n",
      "epoch:39 step:36915 [D loss: 0.226625, acc.: 63.28%] [G loss: 0.279974]\n",
      "epoch:39 step:36916 [D loss: 0.267885, acc.: 46.88%] [G loss: 0.281608]\n",
      "epoch:39 step:36917 [D loss: 0.242579, acc.: 59.38%] [G loss: 0.319425]\n",
      "epoch:39 step:36918 [D loss: 0.247162, acc.: 58.59%] [G loss: 0.303331]\n",
      "epoch:39 step:36919 [D loss: 0.241735, acc.: 59.38%] [G loss: 0.272505]\n",
      "epoch:39 step:36920 [D loss: 0.233849, acc.: 61.72%] [G loss: 0.283763]\n",
      "epoch:39 step:36921 [D loss: 0.240070, acc.: 58.59%] [G loss: 0.303289]\n",
      "epoch:39 step:36922 [D loss: 0.236728, acc.: 57.03%] [G loss: 0.305508]\n",
      "epoch:39 step:36923 [D loss: 0.241541, acc.: 58.59%] [G loss: 0.292685]\n",
      "epoch:39 step:36924 [D loss: 0.230362, acc.: 59.38%] [G loss: 0.309167]\n",
      "epoch:39 step:36925 [D loss: 0.234763, acc.: 63.28%] [G loss: 0.287448]\n",
      "epoch:39 step:36926 [D loss: 0.235108, acc.: 58.59%] [G loss: 0.300782]\n",
      "epoch:39 step:36927 [D loss: 0.220640, acc.: 67.19%] [G loss: 0.290868]\n",
      "epoch:39 step:36928 [D loss: 0.226034, acc.: 60.94%] [G loss: 0.314947]\n",
      "epoch:39 step:36929 [D loss: 0.233488, acc.: 58.59%] [G loss: 0.301710]\n",
      "epoch:39 step:36930 [D loss: 0.234048, acc.: 61.72%] [G loss: 0.289426]\n",
      "epoch:39 step:36931 [D loss: 0.248631, acc.: 58.59%] [G loss: 0.279040]\n",
      "epoch:39 step:36932 [D loss: 0.246223, acc.: 53.12%] [G loss: 0.273543]\n",
      "epoch:39 step:36933 [D loss: 0.247418, acc.: 53.91%] [G loss: 0.293617]\n",
      "epoch:39 step:36934 [D loss: 0.246775, acc.: 56.25%] [G loss: 0.267272]\n",
      "epoch:39 step:36935 [D loss: 0.237642, acc.: 59.38%] [G loss: 0.322579]\n",
      "epoch:39 step:36936 [D loss: 0.262387, acc.: 51.56%] [G loss: 0.306961]\n",
      "epoch:39 step:36937 [D loss: 0.237273, acc.: 62.50%] [G loss: 0.296451]\n",
      "epoch:39 step:36938 [D loss: 0.216624, acc.: 71.88%] [G loss: 0.306520]\n",
      "epoch:39 step:36939 [D loss: 0.232217, acc.: 59.38%] [G loss: 0.317430]\n",
      "epoch:39 step:36940 [D loss: 0.254516, acc.: 53.12%] [G loss: 0.287046]\n",
      "epoch:39 step:36941 [D loss: 0.230050, acc.: 60.94%] [G loss: 0.272408]\n",
      "epoch:39 step:36942 [D loss: 0.224538, acc.: 60.16%] [G loss: 0.295809]\n",
      "epoch:39 step:36943 [D loss: 0.232095, acc.: 62.50%] [G loss: 0.324571]\n",
      "epoch:39 step:36944 [D loss: 0.243740, acc.: 54.69%] [G loss: 0.304358]\n",
      "epoch:39 step:36945 [D loss: 0.234382, acc.: 57.03%] [G loss: 0.293875]\n",
      "epoch:39 step:36946 [D loss: 0.248358, acc.: 52.34%] [G loss: 0.275549]\n",
      "epoch:39 step:36947 [D loss: 0.244783, acc.: 57.81%] [G loss: 0.265296]\n",
      "epoch:39 step:36948 [D loss: 0.239705, acc.: 56.25%] [G loss: 0.291469]\n",
      "epoch:39 step:36949 [D loss: 0.229588, acc.: 57.81%] [G loss: 0.285782]\n",
      "epoch:39 step:36950 [D loss: 0.254865, acc.: 57.03%] [G loss: 0.282282]\n",
      "epoch:39 step:36951 [D loss: 0.259340, acc.: 53.91%] [G loss: 0.326363]\n",
      "epoch:39 step:36952 [D loss: 0.223656, acc.: 63.28%] [G loss: 0.285477]\n",
      "epoch:39 step:36953 [D loss: 0.236554, acc.: 59.38%] [G loss: 0.332268]\n",
      "epoch:39 step:36954 [D loss: 0.241310, acc.: 60.16%] [G loss: 0.290231]\n",
      "epoch:39 step:36955 [D loss: 0.245212, acc.: 56.25%] [G loss: 0.283705]\n",
      "epoch:39 step:36956 [D loss: 0.238935, acc.: 54.69%] [G loss: 0.307157]\n",
      "epoch:39 step:36957 [D loss: 0.235068, acc.: 61.72%] [G loss: 0.285854]\n",
      "epoch:39 step:36958 [D loss: 0.239248, acc.: 58.59%] [G loss: 0.294073]\n",
      "epoch:39 step:36959 [D loss: 0.244390, acc.: 54.69%] [G loss: 0.267713]\n",
      "epoch:39 step:36960 [D loss: 0.233084, acc.: 57.81%] [G loss: 0.309065]\n",
      "epoch:39 step:36961 [D loss: 0.235559, acc.: 58.59%] [G loss: 0.305113]\n",
      "epoch:39 step:36962 [D loss: 0.231053, acc.: 64.06%] [G loss: 0.302131]\n",
      "epoch:39 step:36963 [D loss: 0.236222, acc.: 56.25%] [G loss: 0.283203]\n",
      "epoch:39 step:36964 [D loss: 0.230679, acc.: 62.50%] [G loss: 0.319874]\n",
      "epoch:39 step:36965 [D loss: 0.227531, acc.: 60.16%] [G loss: 0.297436]\n",
      "epoch:39 step:36966 [D loss: 0.226570, acc.: 64.06%] [G loss: 0.299119]\n",
      "epoch:39 step:36967 [D loss: 0.255242, acc.: 48.44%] [G loss: 0.292077]\n",
      "epoch:39 step:36968 [D loss: 0.237670, acc.: 58.59%] [G loss: 0.297635]\n",
      "epoch:39 step:36969 [D loss: 0.239736, acc.: 60.16%] [G loss: 0.306454]\n",
      "epoch:39 step:36970 [D loss: 0.240900, acc.: 57.81%] [G loss: 0.289762]\n",
      "epoch:39 step:36971 [D loss: 0.245150, acc.: 59.38%] [G loss: 0.292770]\n",
      "epoch:39 step:36972 [D loss: 0.244563, acc.: 57.81%] [G loss: 0.303881]\n",
      "epoch:39 step:36973 [D loss: 0.244812, acc.: 50.00%] [G loss: 0.274447]\n",
      "epoch:39 step:36974 [D loss: 0.235958, acc.: 56.25%] [G loss: 0.322651]\n",
      "epoch:39 step:36975 [D loss: 0.234876, acc.: 60.94%] [G loss: 0.305766]\n",
      "epoch:39 step:36976 [D loss: 0.247511, acc.: 57.03%] [G loss: 0.294972]\n",
      "epoch:39 step:36977 [D loss: 0.252889, acc.: 50.78%] [G loss: 0.285547]\n",
      "epoch:39 step:36978 [D loss: 0.242201, acc.: 57.03%] [G loss: 0.314073]\n",
      "epoch:39 step:36979 [D loss: 0.236985, acc.: 60.94%] [G loss: 0.294042]\n",
      "epoch:39 step:36980 [D loss: 0.247977, acc.: 53.91%] [G loss: 0.309994]\n",
      "epoch:39 step:36981 [D loss: 0.240175, acc.: 55.47%] [G loss: 0.291321]\n",
      "epoch:39 step:36982 [D loss: 0.234250, acc.: 57.81%] [G loss: 0.307229]\n",
      "epoch:39 step:36983 [D loss: 0.248759, acc.: 57.03%] [G loss: 0.309270]\n",
      "epoch:39 step:36984 [D loss: 0.232940, acc.: 60.16%] [G loss: 0.316858]\n",
      "epoch:39 step:36985 [D loss: 0.243149, acc.: 53.91%] [G loss: 0.294980]\n",
      "epoch:39 step:36986 [D loss: 0.239118, acc.: 57.81%] [G loss: 0.287008]\n",
      "epoch:39 step:36987 [D loss: 0.261337, acc.: 50.00%] [G loss: 0.284935]\n",
      "epoch:39 step:36988 [D loss: 0.228774, acc.: 61.72%] [G loss: 0.306141]\n",
      "epoch:39 step:36989 [D loss: 0.244713, acc.: 57.03%] [G loss: 0.307872]\n",
      "epoch:39 step:36990 [D loss: 0.230717, acc.: 58.59%] [G loss: 0.324440]\n",
      "epoch:39 step:36991 [D loss: 0.252734, acc.: 49.22%] [G loss: 0.285032]\n",
      "epoch:39 step:36992 [D loss: 0.233665, acc.: 57.03%] [G loss: 0.313240]\n",
      "epoch:39 step:36993 [D loss: 0.231567, acc.: 62.50%] [G loss: 0.299434]\n",
      "epoch:39 step:36994 [D loss: 0.232152, acc.: 63.28%] [G loss: 0.285118]\n",
      "epoch:39 step:36995 [D loss: 0.222595, acc.: 64.06%] [G loss: 0.302207]\n",
      "epoch:39 step:36996 [D loss: 0.227179, acc.: 62.50%] [G loss: 0.313356]\n",
      "epoch:39 step:36997 [D loss: 0.243795, acc.: 56.25%] [G loss: 0.309621]\n",
      "epoch:39 step:36998 [D loss: 0.227901, acc.: 61.72%] [G loss: 0.316977]\n",
      "epoch:39 step:36999 [D loss: 0.252298, acc.: 57.03%] [G loss: 0.311857]\n",
      "epoch:39 step:37000 [D loss: 0.241478, acc.: 57.81%] [G loss: 0.281907]\n",
      "epoch:39 step:37001 [D loss: 0.238171, acc.: 59.38%] [G loss: 0.293694]\n",
      "epoch:39 step:37002 [D loss: 0.239709, acc.: 60.16%] [G loss: 0.311063]\n",
      "epoch:39 step:37003 [D loss: 0.253040, acc.: 56.25%] [G loss: 0.301373]\n",
      "epoch:39 step:37004 [D loss: 0.249176, acc.: 60.16%] [G loss: 0.331004]\n",
      "epoch:39 step:37005 [D loss: 0.234640, acc.: 61.72%] [G loss: 0.305883]\n",
      "epoch:39 step:37006 [D loss: 0.237573, acc.: 59.38%] [G loss: 0.300004]\n",
      "epoch:39 step:37007 [D loss: 0.218174, acc.: 68.75%] [G loss: 0.292777]\n",
      "epoch:39 step:37008 [D loss: 0.235325, acc.: 63.28%] [G loss: 0.320255]\n",
      "epoch:39 step:37009 [D loss: 0.248176, acc.: 57.03%] [G loss: 0.282764]\n",
      "epoch:39 step:37010 [D loss: 0.239806, acc.: 55.47%] [G loss: 0.309118]\n",
      "epoch:39 step:37011 [D loss: 0.235807, acc.: 57.03%] [G loss: 0.319742]\n",
      "epoch:39 step:37012 [D loss: 0.235323, acc.: 62.50%] [G loss: 0.282788]\n",
      "epoch:39 step:37013 [D loss: 0.240089, acc.: 58.59%] [G loss: 0.293868]\n",
      "epoch:39 step:37014 [D loss: 0.237791, acc.: 59.38%] [G loss: 0.290834]\n",
      "epoch:39 step:37015 [D loss: 0.235399, acc.: 58.59%] [G loss: 0.276273]\n",
      "epoch:39 step:37016 [D loss: 0.225473, acc.: 66.41%] [G loss: 0.316528]\n",
      "epoch:39 step:37017 [D loss: 0.241973, acc.: 55.47%] [G loss: 0.286297]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:39 step:37018 [D loss: 0.216793, acc.: 68.75%] [G loss: 0.301259]\n",
      "epoch:39 step:37019 [D loss: 0.232478, acc.: 60.16%] [G loss: 0.311886]\n",
      "epoch:39 step:37020 [D loss: 0.238343, acc.: 57.81%] [G loss: 0.286879]\n",
      "epoch:39 step:37021 [D loss: 0.244193, acc.: 60.16%] [G loss: 0.315087]\n",
      "epoch:39 step:37022 [D loss: 0.239217, acc.: 57.03%] [G loss: 0.293187]\n",
      "epoch:39 step:37023 [D loss: 0.227991, acc.: 65.62%] [G loss: 0.326859]\n",
      "epoch:39 step:37024 [D loss: 0.237153, acc.: 60.16%] [G loss: 0.292318]\n",
      "epoch:39 step:37025 [D loss: 0.245087, acc.: 56.25%] [G loss: 0.278605]\n",
      "epoch:39 step:37026 [D loss: 0.267024, acc.: 49.22%] [G loss: 0.324827]\n",
      "epoch:39 step:37027 [D loss: 0.246767, acc.: 53.12%] [G loss: 0.322403]\n",
      "epoch:39 step:37028 [D loss: 0.242923, acc.: 52.34%] [G loss: 0.292234]\n",
      "epoch:39 step:37029 [D loss: 0.212507, acc.: 70.31%] [G loss: 0.324244]\n",
      "epoch:39 step:37030 [D loss: 0.250160, acc.: 56.25%] [G loss: 0.293429]\n",
      "epoch:39 step:37031 [D loss: 0.243573, acc.: 57.03%] [G loss: 0.306441]\n",
      "epoch:39 step:37032 [D loss: 0.242622, acc.: 59.38%] [G loss: 0.304870]\n",
      "epoch:39 step:37033 [D loss: 0.233209, acc.: 60.94%] [G loss: 0.298796]\n",
      "epoch:39 step:37034 [D loss: 0.257829, acc.: 57.81%] [G loss: 0.302270]\n",
      "epoch:39 step:37035 [D loss: 0.235966, acc.: 59.38%] [G loss: 0.305251]\n",
      "epoch:39 step:37036 [D loss: 0.234467, acc.: 61.72%] [G loss: 0.319470]\n",
      "epoch:39 step:37037 [D loss: 0.231818, acc.: 53.12%] [G loss: 0.295282]\n",
      "epoch:39 step:37038 [D loss: 0.253490, acc.: 50.78%] [G loss: 0.307992]\n",
      "epoch:39 step:37039 [D loss: 0.221782, acc.: 65.62%] [G loss: 0.286059]\n",
      "epoch:39 step:37040 [D loss: 0.245579, acc.: 56.25%] [G loss: 0.314987]\n",
      "epoch:39 step:37041 [D loss: 0.245483, acc.: 53.91%] [G loss: 0.287709]\n",
      "epoch:39 step:37042 [D loss: 0.238997, acc.: 59.38%] [G loss: 0.309220]\n",
      "epoch:39 step:37043 [D loss: 0.253121, acc.: 52.34%] [G loss: 0.298011]\n",
      "epoch:39 step:37044 [D loss: 0.230494, acc.: 59.38%] [G loss: 0.319519]\n",
      "epoch:39 step:37045 [D loss: 0.231236, acc.: 60.94%] [G loss: 0.303572]\n",
      "epoch:39 step:37046 [D loss: 0.241660, acc.: 53.12%] [G loss: 0.293222]\n",
      "epoch:39 step:37047 [D loss: 0.243981, acc.: 55.47%] [G loss: 0.296809]\n",
      "epoch:39 step:37048 [D loss: 0.254050, acc.: 53.91%] [G loss: 0.322580]\n",
      "epoch:39 step:37049 [D loss: 0.240934, acc.: 58.59%] [G loss: 0.298233]\n",
      "epoch:39 step:37050 [D loss: 0.252736, acc.: 48.44%] [G loss: 0.320095]\n",
      "epoch:39 step:37051 [D loss: 0.271926, acc.: 46.09%] [G loss: 0.303874]\n",
      "epoch:39 step:37052 [D loss: 0.235925, acc.: 60.16%] [G loss: 0.275273]\n",
      "epoch:39 step:37053 [D loss: 0.256394, acc.: 53.12%] [G loss: 0.318214]\n",
      "epoch:39 step:37054 [D loss: 0.245443, acc.: 51.56%] [G loss: 0.293804]\n",
      "epoch:39 step:37055 [D loss: 0.219692, acc.: 67.19%] [G loss: 0.305027]\n",
      "epoch:39 step:37056 [D loss: 0.221818, acc.: 65.62%] [G loss: 0.297402]\n",
      "epoch:39 step:37057 [D loss: 0.246836, acc.: 59.38%] [G loss: 0.321493]\n",
      "epoch:39 step:37058 [D loss: 0.223722, acc.: 64.06%] [G loss: 0.301763]\n",
      "epoch:39 step:37059 [D loss: 0.234809, acc.: 59.38%] [G loss: 0.309178]\n",
      "epoch:39 step:37060 [D loss: 0.235099, acc.: 60.16%] [G loss: 0.306668]\n",
      "epoch:39 step:37061 [D loss: 0.253898, acc.: 50.00%] [G loss: 0.299408]\n",
      "epoch:39 step:37062 [D loss: 0.233280, acc.: 57.03%] [G loss: 0.307245]\n",
      "epoch:39 step:37063 [D loss: 0.240910, acc.: 58.59%] [G loss: 0.293286]\n",
      "epoch:39 step:37064 [D loss: 0.235419, acc.: 64.06%] [G loss: 0.274275]\n",
      "epoch:39 step:37065 [D loss: 0.263622, acc.: 49.22%] [G loss: 0.301639]\n",
      "epoch:39 step:37066 [D loss: 0.234896, acc.: 58.59%] [G loss: 0.288906]\n",
      "epoch:39 step:37067 [D loss: 0.232619, acc.: 56.25%] [G loss: 0.303638]\n",
      "epoch:39 step:37068 [D loss: 0.226604, acc.: 60.16%] [G loss: 0.294234]\n",
      "epoch:39 step:37069 [D loss: 0.236989, acc.: 59.38%] [G loss: 0.320645]\n",
      "epoch:39 step:37070 [D loss: 0.256224, acc.: 51.56%] [G loss: 0.294965]\n",
      "epoch:39 step:37071 [D loss: 0.227672, acc.: 63.28%] [G loss: 0.324386]\n",
      "epoch:39 step:37072 [D loss: 0.232434, acc.: 60.94%] [G loss: 0.303142]\n",
      "epoch:39 step:37073 [D loss: 0.245808, acc.: 53.12%] [G loss: 0.301260]\n",
      "epoch:39 step:37074 [D loss: 0.243274, acc.: 59.38%] [G loss: 0.296604]\n",
      "epoch:39 step:37075 [D loss: 0.237999, acc.: 58.59%] [G loss: 0.296493]\n",
      "epoch:39 step:37076 [D loss: 0.252916, acc.: 49.22%] [G loss: 0.285191]\n",
      "epoch:39 step:37077 [D loss: 0.235161, acc.: 60.16%] [G loss: 0.318554]\n",
      "epoch:39 step:37078 [D loss: 0.225061, acc.: 64.84%] [G loss: 0.311114]\n",
      "epoch:39 step:37079 [D loss: 0.256749, acc.: 48.44%] [G loss: 0.287331]\n",
      "epoch:39 step:37080 [D loss: 0.253826, acc.: 50.78%] [G loss: 0.293994]\n",
      "epoch:39 step:37081 [D loss: 0.246555, acc.: 54.69%] [G loss: 0.303788]\n",
      "epoch:39 step:37082 [D loss: 0.242146, acc.: 56.25%] [G loss: 0.269205]\n",
      "epoch:39 step:37083 [D loss: 0.235806, acc.: 61.72%] [G loss: 0.308964]\n",
      "epoch:39 step:37084 [D loss: 0.235819, acc.: 60.94%] [G loss: 0.293710]\n",
      "epoch:39 step:37085 [D loss: 0.254634, acc.: 53.12%] [G loss: 0.296324]\n",
      "epoch:39 step:37086 [D loss: 0.250566, acc.: 54.69%] [G loss: 0.309971]\n",
      "epoch:39 step:37087 [D loss: 0.234027, acc.: 60.94%] [G loss: 0.322637]\n",
      "epoch:39 step:37088 [D loss: 0.235515, acc.: 60.16%] [G loss: 0.293421]\n",
      "epoch:39 step:37089 [D loss: 0.243862, acc.: 57.81%] [G loss: 0.286560]\n",
      "epoch:39 step:37090 [D loss: 0.257115, acc.: 53.12%] [G loss: 0.312936]\n",
      "epoch:39 step:37091 [D loss: 0.253863, acc.: 57.81%] [G loss: 0.312447]\n",
      "epoch:39 step:37092 [D loss: 0.231454, acc.: 57.03%] [G loss: 0.329887]\n",
      "epoch:39 step:37093 [D loss: 0.241120, acc.: 57.03%] [G loss: 0.289094]\n",
      "epoch:39 step:37094 [D loss: 0.242003, acc.: 56.25%] [G loss: 0.276940]\n",
      "epoch:39 step:37095 [D loss: 0.259776, acc.: 52.34%] [G loss: 0.280242]\n",
      "epoch:39 step:37096 [D loss: 0.231244, acc.: 61.72%] [G loss: 0.333676]\n",
      "epoch:39 step:37097 [D loss: 0.235943, acc.: 62.50%] [G loss: 0.305122]\n",
      "epoch:39 step:37098 [D loss: 0.243900, acc.: 58.59%] [G loss: 0.297489]\n",
      "epoch:39 step:37099 [D loss: 0.241473, acc.: 51.56%] [G loss: 0.321291]\n",
      "epoch:39 step:37100 [D loss: 0.228054, acc.: 65.62%] [G loss: 0.328392]\n",
      "epoch:39 step:37101 [D loss: 0.258144, acc.: 55.47%] [G loss: 0.289069]\n",
      "epoch:39 step:37102 [D loss: 0.251343, acc.: 52.34%] [G loss: 0.292246]\n",
      "epoch:39 step:37103 [D loss: 0.249275, acc.: 53.91%] [G loss: 0.284702]\n",
      "epoch:39 step:37104 [D loss: 0.241229, acc.: 54.69%] [G loss: 0.304515]\n",
      "epoch:39 step:37105 [D loss: 0.252092, acc.: 52.34%] [G loss: 0.318821]\n",
      "epoch:39 step:37106 [D loss: 0.227526, acc.: 60.16%] [G loss: 0.291328]\n",
      "epoch:39 step:37107 [D loss: 0.229626, acc.: 60.16%] [G loss: 0.300669]\n",
      "epoch:39 step:37108 [D loss: 0.226109, acc.: 64.06%] [G loss: 0.311528]\n",
      "epoch:39 step:37109 [D loss: 0.241084, acc.: 60.94%] [G loss: 0.284808]\n",
      "epoch:39 step:37110 [D loss: 0.227343, acc.: 61.72%] [G loss: 0.313892]\n",
      "epoch:39 step:37111 [D loss: 0.253407, acc.: 50.00%] [G loss: 0.290334]\n",
      "epoch:39 step:37112 [D loss: 0.236841, acc.: 56.25%] [G loss: 0.287071]\n",
      "epoch:39 step:37113 [D loss: 0.253056, acc.: 53.12%] [G loss: 0.302128]\n",
      "epoch:39 step:37114 [D loss: 0.232988, acc.: 60.16%] [G loss: 0.315150]\n",
      "epoch:39 step:37115 [D loss: 0.222448, acc.: 65.62%] [G loss: 0.326657]\n",
      "epoch:39 step:37116 [D loss: 0.241628, acc.: 59.38%] [G loss: 0.295241]\n",
      "epoch:39 step:37117 [D loss: 0.234896, acc.: 60.94%] [G loss: 0.299206]\n",
      "epoch:39 step:37118 [D loss: 0.227840, acc.: 61.72%] [G loss: 0.307722]\n",
      "epoch:39 step:37119 [D loss: 0.214952, acc.: 69.53%] [G loss: 0.323874]\n",
      "epoch:39 step:37120 [D loss: 0.255041, acc.: 53.12%] [G loss: 0.290074]\n",
      "epoch:39 step:37121 [D loss: 0.232265, acc.: 60.94%] [G loss: 0.304241]\n",
      "epoch:39 step:37122 [D loss: 0.240863, acc.: 57.81%] [G loss: 0.280184]\n",
      "epoch:39 step:37123 [D loss: 0.227128, acc.: 58.59%] [G loss: 0.292361]\n",
      "epoch:39 step:37124 [D loss: 0.239289, acc.: 62.50%] [G loss: 0.299180]\n",
      "epoch:39 step:37125 [D loss: 0.236251, acc.: 60.16%] [G loss: 0.268641]\n",
      "epoch:39 step:37126 [D loss: 0.261026, acc.: 47.66%] [G loss: 0.299160]\n",
      "epoch:39 step:37127 [D loss: 0.220744, acc.: 68.75%] [G loss: 0.300753]\n",
      "epoch:39 step:37128 [D loss: 0.262036, acc.: 54.69%] [G loss: 0.296001]\n",
      "epoch:39 step:37129 [D loss: 0.232479, acc.: 60.94%] [G loss: 0.264230]\n",
      "epoch:39 step:37130 [D loss: 0.240755, acc.: 58.59%] [G loss: 0.291291]\n",
      "epoch:39 step:37131 [D loss: 0.260578, acc.: 50.00%] [G loss: 0.268263]\n",
      "epoch:39 step:37132 [D loss: 0.253573, acc.: 58.59%] [G loss: 0.300233]\n",
      "epoch:39 step:37133 [D loss: 0.245114, acc.: 55.47%] [G loss: 0.278983]\n",
      "epoch:39 step:37134 [D loss: 0.250961, acc.: 52.34%] [G loss: 0.272943]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:39 step:37135 [D loss: 0.242357, acc.: 58.59%] [G loss: 0.312795]\n",
      "epoch:39 step:37136 [D loss: 0.256999, acc.: 49.22%] [G loss: 0.301623]\n",
      "epoch:39 step:37137 [D loss: 0.235874, acc.: 61.72%] [G loss: 0.309560]\n",
      "epoch:39 step:37138 [D loss: 0.262673, acc.: 47.66%] [G loss: 0.294862]\n",
      "epoch:39 step:37139 [D loss: 0.240840, acc.: 57.81%] [G loss: 0.270221]\n",
      "epoch:39 step:37140 [D loss: 0.254728, acc.: 54.69%] [G loss: 0.302596]\n",
      "epoch:39 step:37141 [D loss: 0.246777, acc.: 53.12%] [G loss: 0.301021]\n",
      "epoch:39 step:37142 [D loss: 0.256664, acc.: 49.22%] [G loss: 0.300711]\n",
      "epoch:39 step:37143 [D loss: 0.241063, acc.: 53.91%] [G loss: 0.300633]\n",
      "epoch:39 step:37144 [D loss: 0.242585, acc.: 59.38%] [G loss: 0.292376]\n",
      "epoch:39 step:37145 [D loss: 0.242022, acc.: 59.38%] [G loss: 0.280909]\n",
      "epoch:39 step:37146 [D loss: 0.234591, acc.: 60.94%] [G loss: 0.291926]\n",
      "epoch:39 step:37147 [D loss: 0.235799, acc.: 56.25%] [G loss: 0.302257]\n",
      "epoch:39 step:37148 [D loss: 0.248406, acc.: 52.34%] [G loss: 0.317941]\n",
      "epoch:39 step:37149 [D loss: 0.230508, acc.: 62.50%] [G loss: 0.283381]\n",
      "epoch:39 step:37150 [D loss: 0.247992, acc.: 56.25%] [G loss: 0.310507]\n",
      "epoch:39 step:37151 [D loss: 0.232655, acc.: 62.50%] [G loss: 0.308629]\n",
      "epoch:39 step:37152 [D loss: 0.228077, acc.: 64.84%] [G loss: 0.296353]\n",
      "epoch:39 step:37153 [D loss: 0.226262, acc.: 62.50%] [G loss: 0.325296]\n",
      "epoch:39 step:37154 [D loss: 0.247013, acc.: 53.91%] [G loss: 0.306828]\n",
      "epoch:39 step:37155 [D loss: 0.242937, acc.: 60.94%] [G loss: 0.322856]\n",
      "epoch:39 step:37156 [D loss: 0.229287, acc.: 62.50%] [G loss: 0.276960]\n",
      "epoch:39 step:37157 [D loss: 0.248970, acc.: 52.34%] [G loss: 0.289605]\n",
      "epoch:39 step:37158 [D loss: 0.237533, acc.: 59.38%] [G loss: 0.295709]\n",
      "epoch:39 step:37159 [D loss: 0.247006, acc.: 57.81%] [G loss: 0.284755]\n",
      "epoch:39 step:37160 [D loss: 0.247865, acc.: 51.56%] [G loss: 0.288460]\n",
      "epoch:39 step:37161 [D loss: 0.233242, acc.: 59.38%] [G loss: 0.276303]\n",
      "epoch:39 step:37162 [D loss: 0.236152, acc.: 62.50%] [G loss: 0.291175]\n",
      "epoch:39 step:37163 [D loss: 0.245272, acc.: 53.12%] [G loss: 0.312438]\n",
      "epoch:39 step:37164 [D loss: 0.237097, acc.: 57.81%] [G loss: 0.293550]\n",
      "epoch:39 step:37165 [D loss: 0.221202, acc.: 62.50%] [G loss: 0.287682]\n",
      "epoch:39 step:37166 [D loss: 0.232781, acc.: 61.72%] [G loss: 0.299545]\n",
      "epoch:39 step:37167 [D loss: 0.254472, acc.: 51.56%] [G loss: 0.287249]\n",
      "epoch:39 step:37168 [D loss: 0.250306, acc.: 50.78%] [G loss: 0.307674]\n",
      "epoch:39 step:37169 [D loss: 0.228822, acc.: 61.72%] [G loss: 0.279580]\n",
      "epoch:39 step:37170 [D loss: 0.214599, acc.: 68.75%] [G loss: 0.298407]\n",
      "epoch:39 step:37171 [D loss: 0.233163, acc.: 67.19%] [G loss: 0.333358]\n",
      "epoch:39 step:37172 [D loss: 0.254385, acc.: 53.91%] [G loss: 0.325455]\n",
      "epoch:39 step:37173 [D loss: 0.254798, acc.: 49.22%] [G loss: 0.264501]\n",
      "epoch:39 step:37174 [D loss: 0.250783, acc.: 52.34%] [G loss: 0.294614]\n",
      "epoch:39 step:37175 [D loss: 0.243062, acc.: 55.47%] [G loss: 0.287411]\n",
      "epoch:39 step:37176 [D loss: 0.227698, acc.: 61.72%] [G loss: 0.299308]\n",
      "epoch:39 step:37177 [D loss: 0.243069, acc.: 53.12%] [G loss: 0.321139]\n",
      "epoch:39 step:37178 [D loss: 0.255919, acc.: 47.66%] [G loss: 0.288157]\n",
      "epoch:39 step:37179 [D loss: 0.251845, acc.: 54.69%] [G loss: 0.274741]\n",
      "epoch:39 step:37180 [D loss: 0.241666, acc.: 53.91%] [G loss: 0.308709]\n",
      "epoch:39 step:37181 [D loss: 0.255105, acc.: 50.78%] [G loss: 0.304299]\n",
      "epoch:39 step:37182 [D loss: 0.249184, acc.: 55.47%] [G loss: 0.309939]\n",
      "epoch:39 step:37183 [D loss: 0.230457, acc.: 62.50%] [G loss: 0.312043]\n",
      "epoch:39 step:37184 [D loss: 0.236124, acc.: 59.38%] [G loss: 0.316662]\n",
      "epoch:39 step:37185 [D loss: 0.240254, acc.: 53.91%] [G loss: 0.308484]\n",
      "epoch:39 step:37186 [D loss: 0.249535, acc.: 53.12%] [G loss: 0.300869]\n",
      "epoch:39 step:37187 [D loss: 0.243988, acc.: 55.47%] [G loss: 0.296039]\n",
      "epoch:39 step:37188 [D loss: 0.235543, acc.: 58.59%] [G loss: 0.301862]\n",
      "epoch:39 step:37189 [D loss: 0.231448, acc.: 64.84%] [G loss: 0.307238]\n",
      "epoch:39 step:37190 [D loss: 0.244686, acc.: 55.47%] [G loss: 0.300579]\n",
      "epoch:39 step:37191 [D loss: 0.229349, acc.: 66.41%] [G loss: 0.288594]\n",
      "epoch:39 step:37192 [D loss: 0.246340, acc.: 53.12%] [G loss: 0.290164]\n",
      "epoch:39 step:37193 [D loss: 0.255028, acc.: 49.22%] [G loss: 0.281670]\n",
      "epoch:39 step:37194 [D loss: 0.232134, acc.: 60.16%] [G loss: 0.297171]\n",
      "epoch:39 step:37195 [D loss: 0.253030, acc.: 57.03%] [G loss: 0.294176]\n",
      "epoch:39 step:37196 [D loss: 0.249351, acc.: 51.56%] [G loss: 0.270343]\n",
      "epoch:39 step:37197 [D loss: 0.236668, acc.: 56.25%] [G loss: 0.307764]\n",
      "epoch:39 step:37198 [D loss: 0.223619, acc.: 63.28%] [G loss: 0.314009]\n",
      "epoch:39 step:37199 [D loss: 0.222431, acc.: 61.72%] [G loss: 0.305075]\n",
      "epoch:39 step:37200 [D loss: 0.238933, acc.: 53.91%] [G loss: 0.277509]\n",
      "epoch:39 step:37201 [D loss: 0.249598, acc.: 57.81%] [G loss: 0.280382]\n",
      "epoch:39 step:37202 [D loss: 0.243030, acc.: 57.81%] [G loss: 0.289114]\n",
      "epoch:39 step:37203 [D loss: 0.246144, acc.: 54.69%] [G loss: 0.281788]\n",
      "epoch:39 step:37204 [D loss: 0.235361, acc.: 63.28%] [G loss: 0.290043]\n",
      "epoch:39 step:37205 [D loss: 0.240007, acc.: 58.59%] [G loss: 0.329781]\n",
      "epoch:39 step:37206 [D loss: 0.253045, acc.: 52.34%] [G loss: 0.313001]\n",
      "epoch:39 step:37207 [D loss: 0.243032, acc.: 53.91%] [G loss: 0.312516]\n",
      "epoch:39 step:37208 [D loss: 0.245116, acc.: 56.25%] [G loss: 0.277342]\n",
      "epoch:39 step:37209 [D loss: 0.237382, acc.: 59.38%] [G loss: 0.288171]\n",
      "epoch:39 step:37210 [D loss: 0.239816, acc.: 58.59%] [G loss: 0.284125]\n",
      "epoch:39 step:37211 [D loss: 0.237705, acc.: 57.03%] [G loss: 0.276235]\n",
      "epoch:39 step:37212 [D loss: 0.240262, acc.: 59.38%] [G loss: 0.300117]\n",
      "epoch:39 step:37213 [D loss: 0.249280, acc.: 56.25%] [G loss: 0.277916]\n",
      "epoch:39 step:37214 [D loss: 0.260394, acc.: 52.34%] [G loss: 0.293040]\n",
      "epoch:39 step:37215 [D loss: 0.244570, acc.: 60.94%] [G loss: 0.284574]\n",
      "epoch:39 step:37216 [D loss: 0.241152, acc.: 59.38%] [G loss: 0.286785]\n",
      "epoch:39 step:37217 [D loss: 0.246391, acc.: 58.59%] [G loss: 0.285514]\n",
      "epoch:39 step:37218 [D loss: 0.231953, acc.: 56.25%] [G loss: 0.288199]\n",
      "epoch:39 step:37219 [D loss: 0.239780, acc.: 59.38%] [G loss: 0.291096]\n",
      "epoch:39 step:37220 [D loss: 0.244080, acc.: 57.81%] [G loss: 0.304090]\n",
      "epoch:39 step:37221 [D loss: 0.226319, acc.: 63.28%] [G loss: 0.306990]\n",
      "epoch:39 step:37222 [D loss: 0.239951, acc.: 60.94%] [G loss: 0.283057]\n",
      "epoch:39 step:37223 [D loss: 0.244012, acc.: 57.81%] [G loss: 0.300968]\n",
      "epoch:39 step:37224 [D loss: 0.233793, acc.: 60.16%] [G loss: 0.292517]\n",
      "epoch:39 step:37225 [D loss: 0.245066, acc.: 53.12%] [G loss: 0.276790]\n",
      "epoch:39 step:37226 [D loss: 0.241966, acc.: 58.59%] [G loss: 0.284932]\n",
      "epoch:39 step:37227 [D loss: 0.238393, acc.: 61.72%] [G loss: 0.301763]\n",
      "epoch:39 step:37228 [D loss: 0.238366, acc.: 58.59%] [G loss: 0.311350]\n",
      "epoch:39 step:37229 [D loss: 0.232173, acc.: 65.62%] [G loss: 0.283187]\n",
      "epoch:39 step:37230 [D loss: 0.227165, acc.: 63.28%] [G loss: 0.289295]\n",
      "epoch:39 step:37231 [D loss: 0.236222, acc.: 55.47%] [G loss: 0.304768]\n",
      "epoch:39 step:37232 [D loss: 0.237655, acc.: 57.81%] [G loss: 0.293656]\n",
      "epoch:39 step:37233 [D loss: 0.246922, acc.: 52.34%] [G loss: 0.277974]\n",
      "epoch:39 step:37234 [D loss: 0.237105, acc.: 55.47%] [G loss: 0.313096]\n",
      "epoch:39 step:37235 [D loss: 0.238450, acc.: 60.16%] [G loss: 0.292939]\n",
      "epoch:39 step:37236 [D loss: 0.255921, acc.: 54.69%] [G loss: 0.275266]\n",
      "epoch:39 step:37237 [D loss: 0.255993, acc.: 50.78%] [G loss: 0.287306]\n",
      "epoch:39 step:37238 [D loss: 0.248303, acc.: 50.00%] [G loss: 0.311838]\n",
      "epoch:39 step:37239 [D loss: 0.232300, acc.: 60.94%] [G loss: 0.309415]\n",
      "epoch:39 step:37240 [D loss: 0.219906, acc.: 62.50%] [G loss: 0.309449]\n",
      "epoch:39 step:37241 [D loss: 0.259552, acc.: 51.56%] [G loss: 0.292074]\n",
      "epoch:39 step:37242 [D loss: 0.266043, acc.: 43.75%] [G loss: 0.294847]\n",
      "epoch:39 step:37243 [D loss: 0.227733, acc.: 61.72%] [G loss: 0.300664]\n",
      "epoch:39 step:37244 [D loss: 0.223967, acc.: 60.16%] [G loss: 0.329660]\n",
      "epoch:39 step:37245 [D loss: 0.248203, acc.: 55.47%] [G loss: 0.307924]\n",
      "epoch:39 step:37246 [D loss: 0.252135, acc.: 53.91%] [G loss: 0.279217]\n",
      "epoch:39 step:37247 [D loss: 0.237989, acc.: 57.81%] [G loss: 0.336768]\n",
      "epoch:39 step:37248 [D loss: 0.250971, acc.: 54.69%] [G loss: 0.292226]\n",
      "epoch:39 step:37249 [D loss: 0.252687, acc.: 51.56%] [G loss: 0.332925]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:39 step:37250 [D loss: 0.235529, acc.: 60.16%] [G loss: 0.310245]\n",
      "epoch:39 step:37251 [D loss: 0.263144, acc.: 46.09%] [G loss: 0.279170]\n",
      "epoch:39 step:37252 [D loss: 0.278815, acc.: 42.97%] [G loss: 0.278677]\n",
      "epoch:39 step:37253 [D loss: 0.238932, acc.: 58.59%] [G loss: 0.331993]\n",
      "epoch:39 step:37254 [D loss: 0.238271, acc.: 64.06%] [G loss: 0.296673]\n",
      "epoch:39 step:37255 [D loss: 0.227463, acc.: 57.81%] [G loss: 0.336926]\n",
      "epoch:39 step:37256 [D loss: 0.240341, acc.: 58.59%] [G loss: 0.298338]\n",
      "epoch:39 step:37257 [D loss: 0.240885, acc.: 57.81%] [G loss: 0.280013]\n",
      "epoch:39 step:37258 [D loss: 0.250582, acc.: 57.81%] [G loss: 0.296980]\n",
      "epoch:39 step:37259 [D loss: 0.238034, acc.: 62.50%] [G loss: 0.297243]\n",
      "epoch:39 step:37260 [D loss: 0.236230, acc.: 57.81%] [G loss: 0.294221]\n",
      "epoch:39 step:37261 [D loss: 0.226189, acc.: 63.28%] [G loss: 0.299840]\n",
      "epoch:39 step:37262 [D loss: 0.249712, acc.: 52.34%] [G loss: 0.267438]\n",
      "epoch:39 step:37263 [D loss: 0.248611, acc.: 60.16%] [G loss: 0.300749]\n",
      "epoch:39 step:37264 [D loss: 0.252844, acc.: 53.12%] [G loss: 0.278518]\n",
      "epoch:39 step:37265 [D loss: 0.263139, acc.: 50.78%] [G loss: 0.293480]\n",
      "epoch:39 step:37266 [D loss: 0.215783, acc.: 71.09%] [G loss: 0.305233]\n",
      "epoch:39 step:37267 [D loss: 0.220548, acc.: 67.19%] [G loss: 0.336265]\n",
      "epoch:39 step:37268 [D loss: 0.238238, acc.: 59.38%] [G loss: 0.296750]\n",
      "epoch:39 step:37269 [D loss: 0.241475, acc.: 55.47%] [G loss: 0.337084]\n",
      "epoch:39 step:37270 [D loss: 0.228122, acc.: 58.59%] [G loss: 0.309223]\n",
      "epoch:39 step:37271 [D loss: 0.248142, acc.: 57.81%] [G loss: 0.296751]\n",
      "epoch:39 step:37272 [D loss: 0.250019, acc.: 50.78%] [G loss: 0.312635]\n",
      "epoch:39 step:37273 [D loss: 0.240734, acc.: 56.25%] [G loss: 0.276621]\n",
      "epoch:39 step:37274 [D loss: 0.248729, acc.: 53.91%] [G loss: 0.272406]\n",
      "epoch:39 step:37275 [D loss: 0.254778, acc.: 50.78%] [G loss: 0.275883]\n",
      "epoch:39 step:37276 [D loss: 0.243971, acc.: 55.47%] [G loss: 0.290605]\n",
      "epoch:39 step:37277 [D loss: 0.212702, acc.: 65.62%] [G loss: 0.338312]\n",
      "epoch:39 step:37278 [D loss: 0.244772, acc.: 56.25%] [G loss: 0.306315]\n",
      "epoch:39 step:37279 [D loss: 0.239099, acc.: 57.81%] [G loss: 0.311050]\n",
      "epoch:39 step:37280 [D loss: 0.233389, acc.: 58.59%] [G loss: 0.288869]\n",
      "epoch:39 step:37281 [D loss: 0.233131, acc.: 63.28%] [G loss: 0.279191]\n",
      "epoch:39 step:37282 [D loss: 0.248264, acc.: 54.69%] [G loss: 0.274016]\n",
      "epoch:39 step:37283 [D loss: 0.268627, acc.: 50.78%] [G loss: 0.298692]\n",
      "epoch:39 step:37284 [D loss: 0.234540, acc.: 61.72%] [G loss: 0.284411]\n",
      "epoch:39 step:37285 [D loss: 0.237432, acc.: 64.84%] [G loss: 0.287517]\n",
      "epoch:39 step:37286 [D loss: 0.243510, acc.: 59.38%] [G loss: 0.307207]\n",
      "epoch:39 step:37287 [D loss: 0.240434, acc.: 61.72%] [G loss: 0.282175]\n",
      "epoch:39 step:37288 [D loss: 0.225148, acc.: 67.19%] [G loss: 0.274491]\n",
      "epoch:39 step:37289 [D loss: 0.238949, acc.: 59.38%] [G loss: 0.271494]\n",
      "epoch:39 step:37290 [D loss: 0.246709, acc.: 55.47%] [G loss: 0.298377]\n",
      "epoch:39 step:37291 [D loss: 0.256878, acc.: 52.34%] [G loss: 0.290436]\n",
      "epoch:39 step:37292 [D loss: 0.221410, acc.: 71.09%] [G loss: 0.326673]\n",
      "epoch:39 step:37293 [D loss: 0.247328, acc.: 55.47%] [G loss: 0.297482]\n",
      "epoch:39 step:37294 [D loss: 0.222209, acc.: 63.28%] [G loss: 0.308146]\n",
      "epoch:39 step:37295 [D loss: 0.234676, acc.: 56.25%] [G loss: 0.313978]\n",
      "epoch:39 step:37296 [D loss: 0.245879, acc.: 55.47%] [G loss: 0.293768]\n",
      "epoch:39 step:37297 [D loss: 0.240512, acc.: 57.81%] [G loss: 0.293639]\n",
      "epoch:39 step:37298 [D loss: 0.237740, acc.: 62.50%] [G loss: 0.273219]\n",
      "epoch:39 step:37299 [D loss: 0.243718, acc.: 57.03%] [G loss: 0.296099]\n",
      "epoch:39 step:37300 [D loss: 0.242930, acc.: 57.81%] [G loss: 0.298623]\n",
      "epoch:39 step:37301 [D loss: 0.249214, acc.: 53.91%] [G loss: 0.308544]\n",
      "epoch:39 step:37302 [D loss: 0.233246, acc.: 58.59%] [G loss: 0.295797]\n",
      "epoch:39 step:37303 [D loss: 0.231847, acc.: 54.69%] [G loss: 0.312906]\n",
      "epoch:39 step:37304 [D loss: 0.255488, acc.: 51.56%] [G loss: 0.269509]\n",
      "epoch:39 step:37305 [D loss: 0.254114, acc.: 48.44%] [G loss: 0.314496]\n",
      "epoch:39 step:37306 [D loss: 0.252033, acc.: 56.25%] [G loss: 0.290745]\n",
      "epoch:39 step:37307 [D loss: 0.242161, acc.: 63.28%] [G loss: 0.296414]\n",
      "epoch:39 step:37308 [D loss: 0.241434, acc.: 57.03%] [G loss: 0.301074]\n",
      "epoch:39 step:37309 [D loss: 0.240705, acc.: 58.59%] [G loss: 0.313752]\n",
      "epoch:39 step:37310 [D loss: 0.225010, acc.: 60.94%] [G loss: 0.308095]\n",
      "epoch:39 step:37311 [D loss: 0.222210, acc.: 65.62%] [G loss: 0.304957]\n",
      "epoch:39 step:37312 [D loss: 0.231494, acc.: 57.03%] [G loss: 0.308525]\n",
      "epoch:39 step:37313 [D loss: 0.253060, acc.: 50.78%] [G loss: 0.279736]\n",
      "epoch:39 step:37314 [D loss: 0.245167, acc.: 55.47%] [G loss: 0.282917]\n",
      "epoch:39 step:37315 [D loss: 0.245313, acc.: 53.91%] [G loss: 0.289900]\n",
      "epoch:39 step:37316 [D loss: 0.234957, acc.: 60.16%] [G loss: 0.299277]\n",
      "epoch:39 step:37317 [D loss: 0.237590, acc.: 57.03%] [G loss: 0.287045]\n",
      "epoch:39 step:37318 [D loss: 0.229416, acc.: 60.16%] [G loss: 0.308746]\n",
      "epoch:39 step:37319 [D loss: 0.251155, acc.: 50.78%] [G loss: 0.289354]\n",
      "epoch:39 step:37320 [D loss: 0.235288, acc.: 56.25%] [G loss: 0.298892]\n",
      "epoch:39 step:37321 [D loss: 0.225249, acc.: 66.41%] [G loss: 0.306576]\n",
      "epoch:39 step:37322 [D loss: 0.228731, acc.: 60.16%] [G loss: 0.286561]\n",
      "epoch:39 step:37323 [D loss: 0.241404, acc.: 58.59%] [G loss: 0.319971]\n",
      "epoch:39 step:37324 [D loss: 0.230972, acc.: 61.72%] [G loss: 0.305672]\n",
      "epoch:39 step:37325 [D loss: 0.235058, acc.: 59.38%] [G loss: 0.289704]\n",
      "epoch:39 step:37326 [D loss: 0.232081, acc.: 64.06%] [G loss: 0.279675]\n",
      "epoch:39 step:37327 [D loss: 0.237353, acc.: 54.69%] [G loss: 0.299898]\n",
      "epoch:39 step:37328 [D loss: 0.257098, acc.: 49.22%] [G loss: 0.255820]\n",
      "epoch:39 step:37329 [D loss: 0.245438, acc.: 53.91%] [G loss: 0.285850]\n",
      "epoch:39 step:37330 [D loss: 0.234638, acc.: 59.38%] [G loss: 0.294607]\n",
      "epoch:39 step:37331 [D loss: 0.241435, acc.: 57.03%] [G loss: 0.287102]\n",
      "epoch:39 step:37332 [D loss: 0.235656, acc.: 63.28%] [G loss: 0.322501]\n",
      "epoch:39 step:37333 [D loss: 0.223055, acc.: 64.84%] [G loss: 0.296366]\n",
      "epoch:39 step:37334 [D loss: 0.249414, acc.: 53.12%] [G loss: 0.323628]\n",
      "epoch:39 step:37335 [D loss: 0.251769, acc.: 54.69%] [G loss: 0.263951]\n",
      "epoch:39 step:37336 [D loss: 0.250148, acc.: 54.69%] [G loss: 0.306365]\n",
      "epoch:39 step:37337 [D loss: 0.230774, acc.: 56.25%] [G loss: 0.315500]\n",
      "epoch:39 step:37338 [D loss: 0.233535, acc.: 57.81%] [G loss: 0.297160]\n",
      "epoch:39 step:37339 [D loss: 0.248479, acc.: 55.47%] [G loss: 0.280257]\n",
      "epoch:39 step:37340 [D loss: 0.228958, acc.: 61.72%] [G loss: 0.276570]\n",
      "epoch:39 step:37341 [D loss: 0.232548, acc.: 61.72%] [G loss: 0.280996]\n",
      "epoch:39 step:37342 [D loss: 0.234251, acc.: 55.47%] [G loss: 0.304190]\n",
      "epoch:39 step:37343 [D loss: 0.239163, acc.: 57.03%] [G loss: 0.284826]\n",
      "epoch:39 step:37344 [D loss: 0.235275, acc.: 60.16%] [G loss: 0.300806]\n",
      "epoch:39 step:37345 [D loss: 0.245933, acc.: 59.38%] [G loss: 0.287803]\n",
      "epoch:39 step:37346 [D loss: 0.236928, acc.: 58.59%] [G loss: 0.287404]\n",
      "epoch:39 step:37347 [D loss: 0.248753, acc.: 58.59%] [G loss: 0.281840]\n",
      "epoch:39 step:37348 [D loss: 0.233033, acc.: 63.28%] [G loss: 0.278048]\n",
      "epoch:39 step:37349 [D loss: 0.235369, acc.: 61.72%] [G loss: 0.285476]\n",
      "epoch:39 step:37350 [D loss: 0.246942, acc.: 55.47%] [G loss: 0.302631]\n",
      "epoch:39 step:37351 [D loss: 0.237971, acc.: 54.69%] [G loss: 0.298547]\n",
      "epoch:39 step:37352 [D loss: 0.236111, acc.: 61.72%] [G loss: 0.302828]\n",
      "epoch:39 step:37353 [D loss: 0.242693, acc.: 57.81%] [G loss: 0.274070]\n",
      "epoch:39 step:37354 [D loss: 0.241858, acc.: 59.38%] [G loss: 0.294596]\n",
      "epoch:39 step:37355 [D loss: 0.236466, acc.: 59.38%] [G loss: 0.295728]\n",
      "epoch:39 step:37356 [D loss: 0.253815, acc.: 58.59%] [G loss: 0.295469]\n",
      "epoch:39 step:37357 [D loss: 0.246105, acc.: 53.12%] [G loss: 0.316986]\n",
      "epoch:39 step:37358 [D loss: 0.248677, acc.: 48.44%] [G loss: 0.279778]\n",
      "epoch:39 step:37359 [D loss: 0.229867, acc.: 57.03%] [G loss: 0.302157]\n",
      "epoch:39 step:37360 [D loss: 0.256510, acc.: 54.69%] [G loss: 0.306839]\n",
      "epoch:39 step:37361 [D loss: 0.242246, acc.: 56.25%] [G loss: 0.292371]\n",
      "epoch:39 step:37362 [D loss: 0.237135, acc.: 60.94%] [G loss: 0.317702]\n",
      "epoch:39 step:37363 [D loss: 0.250374, acc.: 53.91%] [G loss: 0.308635]\n",
      "epoch:39 step:37364 [D loss: 0.241925, acc.: 56.25%] [G loss: 0.286575]\n",
      "epoch:39 step:37365 [D loss: 0.239348, acc.: 57.03%] [G loss: 0.304689]\n",
      "epoch:39 step:37366 [D loss: 0.243696, acc.: 53.12%] [G loss: 0.298994]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:39 step:37367 [D loss: 0.236147, acc.: 63.28%] [G loss: 0.265060]\n",
      "epoch:39 step:37368 [D loss: 0.238891, acc.: 62.50%] [G loss: 0.286946]\n",
      "epoch:39 step:37369 [D loss: 0.235617, acc.: 57.81%] [G loss: 0.269940]\n",
      "epoch:39 step:37370 [D loss: 0.221494, acc.: 66.41%] [G loss: 0.298223]\n",
      "epoch:39 step:37371 [D loss: 0.247174, acc.: 50.00%] [G loss: 0.309491]\n",
      "epoch:39 step:37372 [D loss: 0.243384, acc.: 60.16%] [G loss: 0.278943]\n",
      "epoch:39 step:37373 [D loss: 0.240911, acc.: 61.72%] [G loss: 0.286737]\n",
      "epoch:39 step:37374 [D loss: 0.256259, acc.: 43.75%] [G loss: 0.277729]\n",
      "epoch:39 step:37375 [D loss: 0.258666, acc.: 48.44%] [G loss: 0.312664]\n",
      "epoch:39 step:37376 [D loss: 0.257817, acc.: 49.22%] [G loss: 0.308015]\n",
      "epoch:39 step:37377 [D loss: 0.244178, acc.: 57.81%] [G loss: 0.329987]\n",
      "epoch:39 step:37378 [D loss: 0.233697, acc.: 65.62%] [G loss: 0.322862]\n",
      "epoch:39 step:37379 [D loss: 0.241943, acc.: 55.47%] [G loss: 0.284953]\n",
      "epoch:39 step:37380 [D loss: 0.248061, acc.: 53.12%] [G loss: 0.306999]\n",
      "epoch:39 step:37381 [D loss: 0.221096, acc.: 66.41%] [G loss: 0.303268]\n",
      "epoch:39 step:37382 [D loss: 0.252750, acc.: 53.91%] [G loss: 0.341056]\n",
      "epoch:39 step:37383 [D loss: 0.228976, acc.: 57.81%] [G loss: 0.300154]\n",
      "epoch:39 step:37384 [D loss: 0.243858, acc.: 56.25%] [G loss: 0.293610]\n",
      "epoch:39 step:37385 [D loss: 0.258695, acc.: 53.12%] [G loss: 0.298044]\n",
      "epoch:39 step:37386 [D loss: 0.241563, acc.: 57.81%] [G loss: 0.280858]\n",
      "epoch:39 step:37387 [D loss: 0.255620, acc.: 48.44%] [G loss: 0.325600]\n",
      "epoch:39 step:37388 [D loss: 0.241962, acc.: 59.38%] [G loss: 0.298576]\n",
      "epoch:39 step:37389 [D loss: 0.240205, acc.: 59.38%] [G loss: 0.295391]\n",
      "epoch:39 step:37390 [D loss: 0.220468, acc.: 64.06%] [G loss: 0.297704]\n",
      "epoch:39 step:37391 [D loss: 0.237177, acc.: 61.72%] [G loss: 0.284494]\n",
      "epoch:39 step:37392 [D loss: 0.243207, acc.: 59.38%] [G loss: 0.315204]\n",
      "epoch:39 step:37393 [D loss: 0.256655, acc.: 50.00%] [G loss: 0.328009]\n",
      "epoch:39 step:37394 [D loss: 0.241823, acc.: 59.38%] [G loss: 0.286625]\n",
      "epoch:39 step:37395 [D loss: 0.225985, acc.: 64.84%] [G loss: 0.305561]\n",
      "epoch:39 step:37396 [D loss: 0.244132, acc.: 63.28%] [G loss: 0.319216]\n",
      "epoch:39 step:37397 [D loss: 0.252732, acc.: 53.91%] [G loss: 0.250902]\n",
      "epoch:39 step:37398 [D loss: 0.233489, acc.: 58.59%] [G loss: 0.315987]\n",
      "epoch:39 step:37399 [D loss: 0.240460, acc.: 62.50%] [G loss: 0.299468]\n",
      "epoch:39 step:37400 [D loss: 0.235785, acc.: 66.41%] [G loss: 0.316846]\n",
      "epoch:39 step:37401 [D loss: 0.255111, acc.: 50.78%] [G loss: 0.284065]\n",
      "epoch:39 step:37402 [D loss: 0.232053, acc.: 64.06%] [G loss: 0.301920]\n",
      "epoch:39 step:37403 [D loss: 0.256101, acc.: 53.91%] [G loss: 0.294225]\n",
      "epoch:39 step:37404 [D loss: 0.235193, acc.: 60.94%] [G loss: 0.319703]\n",
      "epoch:39 step:37405 [D loss: 0.246441, acc.: 57.81%] [G loss: 0.285238]\n",
      "epoch:39 step:37406 [D loss: 0.244571, acc.: 60.16%] [G loss: 0.292779]\n",
      "epoch:39 step:37407 [D loss: 0.238273, acc.: 60.16%] [G loss: 0.309654]\n",
      "epoch:39 step:37408 [D loss: 0.242745, acc.: 57.03%] [G loss: 0.288574]\n",
      "epoch:39 step:37409 [D loss: 0.236870, acc.: 53.12%] [G loss: 0.286160]\n",
      "epoch:39 step:37410 [D loss: 0.252155, acc.: 55.47%] [G loss: 0.292946]\n",
      "epoch:39 step:37411 [D loss: 0.226199, acc.: 64.84%] [G loss: 0.318978]\n",
      "epoch:39 step:37412 [D loss: 0.234653, acc.: 58.59%] [G loss: 0.305560]\n",
      "epoch:39 step:37413 [D loss: 0.250812, acc.: 53.91%] [G loss: 0.295589]\n",
      "epoch:39 step:37414 [D loss: 0.266134, acc.: 51.56%] [G loss: 0.283616]\n",
      "epoch:39 step:37415 [D loss: 0.254708, acc.: 50.00%] [G loss: 0.306908]\n",
      "epoch:39 step:37416 [D loss: 0.235369, acc.: 61.72%] [G loss: 0.286703]\n",
      "epoch:39 step:37417 [D loss: 0.226657, acc.: 62.50%] [G loss: 0.271476]\n",
      "epoch:39 step:37418 [D loss: 0.245222, acc.: 57.03%] [G loss: 0.311640]\n",
      "epoch:39 step:37419 [D loss: 0.242890, acc.: 61.72%] [G loss: 0.288619]\n",
      "epoch:39 step:37420 [D loss: 0.245410, acc.: 53.91%] [G loss: 0.302586]\n",
      "epoch:39 step:37421 [D loss: 0.244189, acc.: 58.59%] [G loss: 0.288213]\n",
      "epoch:39 step:37422 [D loss: 0.238538, acc.: 59.38%] [G loss: 0.316658]\n",
      "epoch:39 step:37423 [D loss: 0.237611, acc.: 60.94%] [G loss: 0.307599]\n",
      "epoch:39 step:37424 [D loss: 0.231662, acc.: 53.12%] [G loss: 0.288352]\n",
      "epoch:39 step:37425 [D loss: 0.249899, acc.: 57.81%] [G loss: 0.293586]\n",
      "epoch:39 step:37426 [D loss: 0.242079, acc.: 53.12%] [G loss: 0.304523]\n",
      "epoch:39 step:37427 [D loss: 0.247301, acc.: 54.69%] [G loss: 0.304973]\n",
      "epoch:39 step:37428 [D loss: 0.253687, acc.: 50.78%] [G loss: 0.269804]\n",
      "epoch:39 step:37429 [D loss: 0.248320, acc.: 54.69%] [G loss: 0.308819]\n",
      "epoch:39 step:37430 [D loss: 0.252288, acc.: 48.44%] [G loss: 0.286722]\n",
      "epoch:39 step:37431 [D loss: 0.250918, acc.: 56.25%] [G loss: 0.304091]\n",
      "epoch:39 step:37432 [D loss: 0.226108, acc.: 63.28%] [G loss: 0.292028]\n",
      "epoch:39 step:37433 [D loss: 0.233179, acc.: 60.94%] [G loss: 0.278473]\n",
      "epoch:39 step:37434 [D loss: 0.243295, acc.: 59.38%] [G loss: 0.297377]\n",
      "epoch:39 step:37435 [D loss: 0.255889, acc.: 49.22%] [G loss: 0.311971]\n",
      "epoch:39 step:37436 [D loss: 0.232817, acc.: 63.28%] [G loss: 0.301652]\n",
      "epoch:39 step:37437 [D loss: 0.237952, acc.: 58.59%] [G loss: 0.311187]\n",
      "epoch:39 step:37438 [D loss: 0.229727, acc.: 61.72%] [G loss: 0.294171]\n",
      "epoch:39 step:37439 [D loss: 0.251003, acc.: 51.56%] [G loss: 0.301077]\n",
      "epoch:39 step:37440 [D loss: 0.237138, acc.: 61.72%] [G loss: 0.307549]\n",
      "epoch:39 step:37441 [D loss: 0.228521, acc.: 58.59%] [G loss: 0.318326]\n",
      "epoch:39 step:37442 [D loss: 0.249833, acc.: 56.25%] [G loss: 0.288897]\n",
      "epoch:39 step:37443 [D loss: 0.220525, acc.: 65.62%] [G loss: 0.304750]\n",
      "epoch:39 step:37444 [D loss: 0.235506, acc.: 60.16%] [G loss: 0.279243]\n",
      "epoch:39 step:37445 [D loss: 0.258689, acc.: 48.44%] [G loss: 0.304883]\n",
      "epoch:39 step:37446 [D loss: 0.258016, acc.: 49.22%] [G loss: 0.308456]\n",
      "epoch:39 step:37447 [D loss: 0.229519, acc.: 59.38%] [G loss: 0.308672]\n",
      "epoch:39 step:37448 [D loss: 0.254944, acc.: 50.00%] [G loss: 0.270686]\n",
      "epoch:39 step:37449 [D loss: 0.227614, acc.: 67.19%] [G loss: 0.281792]\n",
      "epoch:39 step:37450 [D loss: 0.251923, acc.: 51.56%] [G loss: 0.292691]\n",
      "epoch:39 step:37451 [D loss: 0.247155, acc.: 53.12%] [G loss: 0.292647]\n",
      "epoch:39 step:37452 [D loss: 0.238915, acc.: 56.25%] [G loss: 0.290137]\n",
      "epoch:39 step:37453 [D loss: 0.216097, acc.: 67.19%] [G loss: 0.310202]\n",
      "epoch:39 step:37454 [D loss: 0.252108, acc.: 51.56%] [G loss: 0.275267]\n",
      "epoch:39 step:37455 [D loss: 0.244891, acc.: 53.91%] [G loss: 0.289104]\n",
      "epoch:39 step:37456 [D loss: 0.250707, acc.: 54.69%] [G loss: 0.291223]\n",
      "epoch:39 step:37457 [D loss: 0.229895, acc.: 60.16%] [G loss: 0.297342]\n",
      "epoch:39 step:37458 [D loss: 0.242850, acc.: 52.34%] [G loss: 0.330472]\n",
      "epoch:39 step:37459 [D loss: 0.243814, acc.: 55.47%] [G loss: 0.284554]\n",
      "epoch:39 step:37460 [D loss: 0.235716, acc.: 60.16%] [G loss: 0.317322]\n",
      "epoch:39 step:37461 [D loss: 0.259263, acc.: 53.12%] [G loss: 0.285763]\n",
      "epoch:39 step:37462 [D loss: 0.228564, acc.: 60.94%] [G loss: 0.295394]\n",
      "epoch:39 step:37463 [D loss: 0.225036, acc.: 61.72%] [G loss: 0.315316]\n",
      "epoch:39 step:37464 [D loss: 0.251599, acc.: 50.78%] [G loss: 0.310337]\n",
      "epoch:39 step:37465 [D loss: 0.249175, acc.: 53.12%] [G loss: 0.287521]\n",
      "epoch:39 step:37466 [D loss: 0.248129, acc.: 52.34%] [G loss: 0.292114]\n",
      "epoch:39 step:37467 [D loss: 0.230529, acc.: 61.72%] [G loss: 0.291763]\n",
      "epoch:39 step:37468 [D loss: 0.231505, acc.: 60.94%] [G loss: 0.310159]\n",
      "epoch:39 step:37469 [D loss: 0.244711, acc.: 57.81%] [G loss: 0.285584]\n",
      "epoch:39 step:37470 [D loss: 0.257460, acc.: 54.69%] [G loss: 0.283702]\n",
      "epoch:39 step:37471 [D loss: 0.248910, acc.: 55.47%] [G loss: 0.275209]\n",
      "epoch:39 step:37472 [D loss: 0.240096, acc.: 58.59%] [G loss: 0.283019]\n",
      "epoch:39 step:37473 [D loss: 0.228432, acc.: 67.19%] [G loss: 0.299861]\n",
      "epoch:39 step:37474 [D loss: 0.255182, acc.: 53.12%] [G loss: 0.301342]\n",
      "epoch:39 step:37475 [D loss: 0.234555, acc.: 60.16%] [G loss: 0.284885]\n",
      "epoch:39 step:37476 [D loss: 0.262176, acc.: 47.66%] [G loss: 0.284664]\n",
      "epoch:39 step:37477 [D loss: 0.249319, acc.: 54.69%] [G loss: 0.278465]\n",
      "epoch:39 step:37478 [D loss: 0.227664, acc.: 59.38%] [G loss: 0.283577]\n",
      "epoch:39 step:37479 [D loss: 0.230303, acc.: 62.50%] [G loss: 0.296643]\n",
      "epoch:39 step:37480 [D loss: 0.240982, acc.: 55.47%] [G loss: 0.293654]\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function, division\n",
    "\n",
    "from keras.datasets import mnist,fashion_mnist\n",
    "from keras.layers import Input, Dense, Reshape, Flatten, Dropout\n",
    "from keras.layers import BatchNormalization, Activation, ZeroPadding2D\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "from keras.layers.convolutional import UpSampling2D, Conv2D\n",
    "from keras.models import Sequential, Model\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import sys\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "class LSGAN():\n",
    "    def __init__(self):\n",
    "        self.img_rows = 28\n",
    "        self.img_cols = 28\n",
    "        self.channels = 1\n",
    "        self.img_shape = (self.img_rows, self.img_cols, self.channels)\n",
    "        self.latent_dim = 100\n",
    "\n",
    "        optimizer = Adam(0.0002, 0.5)\n",
    "\n",
    "        # Build and compile the discriminator\n",
    "        self.discriminator = self.build_discriminator()\n",
    "        self.discriminator.compile(loss='mse',\n",
    "            optimizer=optimizer,\n",
    "            metrics=['accuracy'])\n",
    "\n",
    "        # Build the generator\n",
    "        self.generator = self.build_generator()\n",
    "\n",
    "        # The generator takes noise as input and generated imgs\n",
    "        z = Input(shape=(self.latent_dim,))\n",
    "        img = self.generator(z)\n",
    "\n",
    "        # For the combined model we will only train the generator\n",
    "        self.discriminator.trainable = False\n",
    "\n",
    "        # The valid takes generated images as input and determines validity\n",
    "        valid = self.discriminator(img)\n",
    "\n",
    "        # The combined model  (stacked generator and discriminator)\n",
    "        # Trains generator to fool discriminator\n",
    "        self.combined = Model(z, valid)\n",
    "        # (!!!) Optimize w.r.t. MSE loss instead of crossentropy\n",
    "        self.combined.compile(loss='mse', optimizer=optimizer)\n",
    "\n",
    "    def build_generator(self):\n",
    "        model = Sequential()\n",
    "\n",
    "        model.add(Dense(128 * 7 * 7, activation=\"relu\", input_dim=self.latent_dim))\n",
    "        model.add(Reshape((7, 7, 128)))\n",
    "        model.add(BatchNormalization(momentum=0.8))\n",
    "        model.add(UpSampling2D())\n",
    "        model.add(Conv2D(128, kernel_size=3, padding=\"same\"))\n",
    "        model.add(Activation(\"relu\"))\n",
    "        model.add(BatchNormalization(momentum=0.8))\n",
    "        model.add(UpSampling2D())\n",
    "        model.add(Conv2D(64, kernel_size=3, padding=\"same\"))\n",
    "        model.add(Activation(\"relu\"))\n",
    "        model.add(BatchNormalization(momentum=0.8))\n",
    "        model.add(Conv2D(self.channels, kernel_size=3, padding='same'))\n",
    "        model.add(Activation(\"tanh\"))\n",
    "\n",
    "        model.summary()\n",
    "\n",
    "        noise = Input(shape=(self.latent_dim,))\n",
    "        img = model(noise)\n",
    "\n",
    "        return Model(noise, img)\n",
    "\n",
    "    def build_discriminator(self):\n",
    "\n",
    "        model = Sequential()\n",
    "\n",
    "        model.add(Conv2D(16, kernel_size=3, strides=2, input_shape=self.img_shape, padding=\"same\"))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(Dropout(0.25))\n",
    "        model.add(Conv2D(32, kernel_size=3, strides=2, padding=\"same\"))\n",
    "        model.add(ZeroPadding2D(padding=((0, 1), (0, 1))))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(Dropout(0.25))\n",
    "        model.add(BatchNormalization(momentum=0.8))\n",
    "        model.add(Conv2D(64, kernel_size=3, strides=2, padding=\"same\"))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(Dropout(0.25))\n",
    "        model.add(BatchNormalization(momentum=0.8))\n",
    "        model.add(Conv2D(128, kernel_size=3, strides=1, padding=\"same\"))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(Dropout(0.25))\n",
    "        model.add(Flatten())\n",
    "        model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "        model.summary()\n",
    "\n",
    "        img = Input(shape=self.img_shape)\n",
    "        validity = model(img)\n",
    "\n",
    "        return Model(img, validity)\n",
    "\n",
    "    def train(self, epochs, batch_size=128, sample_interval=50):\n",
    "\n",
    "        # Load the dataset\n",
    "        (X_train, _), (_, _) = fashion_mnist.load_data()\n",
    "\n",
    "        # Rescale -1 to 1\n",
    "        X_train = (X_train.astype(np.float32) - 127.5) / 127.5\n",
    "        X_train = np.expand_dims(X_train, axis=3)\n",
    "\n",
    "        # Adversarial ground truths\n",
    "        valid = np.ones((batch_size, 1))\n",
    "        fake = np.zeros((batch_size, 1))\n",
    "\n",
    "        nb_batches = int(X_train.shape[0] / batch_size)\n",
    "        global_step = 0\n",
    "\n",
    "        for epoch in range(epochs):\n",
    "\n",
    "            for index in range(nb_batches):\n",
    "                global_step += 1\n",
    "                imgs = X_train[index * batch_size:(index + 1) * batch_size]\n",
    "                # Sample noise as generator input\n",
    "                noise = np.random.normal(0, 1, (batch_size, self.latent_dim))\n",
    "\n",
    "                # Generate a batch of new images\n",
    "                gen_imgs = self.generator.predict(noise)\n",
    "\n",
    "                # Train the discriminator\n",
    "                d_loss_real = self.discriminator.train_on_batch(imgs, valid)\n",
    "                d_loss_fake = self.discriminator.train_on_batch(gen_imgs, fake)\n",
    "                d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)\n",
    "\n",
    "                # ---------------------\n",
    "                #  Train Generator\n",
    "                # ---------------------\n",
    "\n",
    "                g_loss = self.combined.train_on_batch(noise, valid)\n",
    "\n",
    "                # Plot the progress\n",
    "                print(\"epoch:%d step:%d [D loss: %f, acc.: %.2f%%] [G loss: %f]\" % (epoch, global_step,d_loss[0], 100 * d_loss[1], g_loss))\n",
    "\n",
    "                # If at save interval => save generated image samples\n",
    "                if global_step % sample_interval == 0:\n",
    "                    self.sample_images(epoch,global_step)\n",
    "\n",
    "\n",
    "\n",
    "    def sample_images(self, epoch,global_step):\n",
    "        r, c = 10, 10\n",
    "        noise = np.random.normal(0, 1, (r * c, self.latent_dim))\n",
    "        gen_imgs = self.generator.predict(noise)\n",
    "\n",
    "        # Rescale images 0 - 1\n",
    "        gen_imgs = 0.5 * gen_imgs + 0.5\n",
    "\n",
    "        fig, axs = plt.subplots(r, c)\n",
    "        cnt = 0\n",
    "        for i in range(r):\n",
    "            for j in range(c):\n",
    "                axs[i,j].imshow(gen_imgs[cnt, :,:,0], cmap='gray')\n",
    "                axs[i,j].axis('off')\n",
    "                cnt += 1\n",
    "        if not os.path.isdir('images_lsgan_fashion_mnist'):\n",
    "            os.mkdir('images_lsgan_fashion_mnist')\n",
    "        fig.savefig(\"images_lsgan_fashion_mnist/epoch_%d_step_%d.png\" % (epoch,global_step))\n",
    "        plt.close()\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    gan = LSGAN()\n",
    "    gan.train(epochs=40, batch_size=64, sample_interval=200)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pppppppp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
